import os
import json
from tqdm import tqdm

def format_for_llama_factory(dataset_path, output_path, max_input_length=50000, min_input_length=10000):
    """å°†æ•°æ®é›†æ ¼å¼åŒ–ä¸ºLlama Factoryæ‰€éœ€çš„æ ¼å¼ï¼Œå¹¶è¿‡æ»¤æ‰è¿‡é•¿æˆ–è¿‡çŸ­çš„è¾“å…¥"""
    # åŠ è½½æ•°æ®é›†
    with open(dataset_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # è½¬æ¢ä¸ºLlama Factoryæ ¼å¼
    llama_factory_data = []
    filtered_long_count = 0
    filtered_short_count = 0
    
    print(f"æ­£åœ¨å¤„ç†æ•°æ®é›†ï¼Œå…± {len(data)} æ¡è®°å½•...")
    
    for item in tqdm(data, desc="æ ¼å¼åŒ–å¹¶è¿‡æ»¤æ•°æ®"):
        # è·å–å¹³å‡è¯„åˆ†å’Œç½®ä¿¡åº¦
        rating = item.get('avg_rating', 0)
        confidence = item.get('avg_confidence', 0)
        
        # æ„å»ºæç¤ºå’Œå›å¤
        prompt = f"""Paper Details:
- Title: {item['title']}

- Conference: {item['conference']} {item['year']}

- Content: {item['paper_content']}"""

        # æ„å»ºæ ‡å‡†åŒ–çš„è¾“å‡ºæ ¼å¼
        response = f"{item['aggregated_review']}\n### Rating\nOverall Quality: {rating:.1f}\nReview Confidence: {confidence:.1f}"
        
        llama_factory_item = {
            "instruction": f"""You are an academic paper reviewer. Please write a structured review of the following paper based solely on its content. Do not include any content beyond the four sections below. Your tone should be professional, constructive, and objective. Base your assessment on typical academic criteria such as novelty, clarity, significance, methodology, and empirical results:

### Key Points  
Summarize the main contributions and key ideas of the paper. Focus on what the paper claims to achieve, its novel aspects, and core methodologies used.

### Strengths and Weaknesses  
**Strengths:**  
- List the paper's most important strengths, such as novelty, strong experiments, theoretical insights, or impactful findings.  

**Weaknesses:**  
- Point out any limitations, unclear assumptions, weak evaluation, missing baselines, or overclaims.

### Suggestions for Improvement
Provide specific and constructive suggestions. Consider aspects such as clarity of writing, experimental design, additional ablation studies, missing citations, or improved motivation.

### Rating  
**Overall Quality:** (1â€“10, where 10 is a top-tier paper)
**Review Confidence:** (1â€“5ï¼Œ where 5 is very confident)
""",
            "input": prompt,
            "output": response
        }
        
        # æ£€æŸ¥è¾“å…¥é•¿åº¦
        input_length = len(prompt)
        if input_length > max_input_length:
            filtered_long_count += 1
            continue
        elif input_length < min_input_length:
            filtered_short_count += 1
            continue
        
        llama_factory_data.append(llama_factory_item)
    
    # ä¿å­˜Llama Factoryæ ¼å¼æ•°æ®
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
       json.dump(llama_factory_data, f, ensure_ascii=False, indent=2)
    
    print(f"å·²åˆ›å»ºLlama Factoryæ ¼å¼æ•°æ®é›†ï¼ŒåŒ…å« {len(llama_factory_data)} æ¡è®°å½•")
    if filtered_long_count > 0:
        print(f"å·²è¿‡æ»¤ {filtered_long_count} æ¡è¿‡é•¿è¾“å…¥ (è¶…è¿‡ {max_input_length} å­—ç¬¦)")
    if filtered_short_count > 0:
        print(f"å·²è¿‡æ»¤ {filtered_short_count} æ¡è¿‡çŸ­è¾“å…¥ (å°‘äº {min_input_length} å­—ç¬¦)")
    
    return llama_factory_data

def create_train_dpo_test_split(dataset_path, train_path, dpo_path, test_path, train_ratio=0.75, dpo_ratio=0.23, test_ratio=0.02):
    """æŒ‰ 75/23/2 åˆ’åˆ†è®­ç»ƒé›†ï¼ˆQLoRAï¼‰ã€DPOé›†ã€æµ‹è¯•é›†"""
    with open(dataset_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    total = len(data)
    test_size = max(1, int(total * test_ratio))
    dpo_size = max(1, int(total * dpo_ratio))
    train_size = total - dpo_size - test_size

    # é¡ºåºåˆ†é…ï¼ˆå¦‚éœ€éšæœºå¯æ‰“ä¹±ï¼‰
    train_data = data[:train_size]
    dpo_data = data[train_size:train_size + dpo_size]
    test_data = data[train_size + dpo_size:]

    # ä¿å­˜
    os.makedirs(os.path.dirname(train_path), exist_ok=True)
    with open(train_path, 'w', encoding='utf-8') as f:
        json.dump(train_data, f, ensure_ascii=False, indent=2)

    os.makedirs(os.path.dirname(dpo_path), exist_ok=True)
    with open(dpo_path, 'w', encoding='utf-8') as f:
        json.dump(dpo_data, f, ensure_ascii=False, indent=2)

    os.makedirs(os.path.dirname(test_path), exist_ok=True)
    with open(test_path, 'w', encoding='utf-8') as f:
        json.dump(test_data, f, ensure_ascii=False, indent=2)

    print(f"å·²åˆ›å»ºè®­ç»ƒé›† ({len(train_data)} æ¡è®°å½•)ã€DPOé›† ({len(dpo_data)} æ¡è®°å½•)ã€æµ‹è¯•é›† ({len(test_data)} æ¡è®°å½•)")

    return train_data, dpo_data, test_data


def build_dpo_dataset_from_split(accepted_path, rejected_path, output_path):
    """
    æ„é€  DPO æ ¼å¼æ•°æ®é›†ï¼š
    - accepted_path: å·²åˆ‡åˆ†å¥½çš„ dpo setï¼Œæ¯æ¡æœ‰ instruction/input/output
    - rejected_path: æ¨¡å‹ç”Ÿæˆçš„ outputï¼ŒæŒ‰é¡ºåºå¯¹é½
    - output_path: è¾“å‡ºæˆ {prompt, chosen, rejected} æ ¼å¼
    """
    with open(accepted_path, 'r', encoding='utf-8') as f:
        accepted = json.load(f)

    with open(rejected_path, 'r', encoding='utf-8') as f:
        rejected = json.load(f)

    assert len(accepted) == len(rejected), f"âŒ Accepted({len(accepted)}) å’Œ Rejected({len(rejected)}) æ•°é‡ä¸ä¸€è‡´"

    dpo_data = []
    for a, r in tqdm(zip(accepted, rejected), total=len(accepted), desc="æ„é€  DPO å¯¹"):
        prompt = f"{a['instruction']}\n\n{a['input']}".strip()
        dpo_data.append({
            "prompt": prompt,
            "chosen": a["output"],
            "rejected": r["output"]
        })

    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(dpo_data, f, ensure_ascii=False, indent=2)

    print(f"âœ… DPO æ•°æ®å·²ä¿å­˜åˆ°: {output_path}ï¼ˆå…± {len(dpo_data)} æ¡ï¼‰")



def filter_long_inputs(input_path, output_path, max_length=150000):
    """è¿‡æ»¤æ‰è¾“å…¥é•¿åº¦è¶…è¿‡æŒ‡å®šé•¿åº¦çš„æ•°æ®é›†æ¡ç›®"""
    print(f"æ­£åœ¨åŠ è½½æ•°æ®é›†: {input_path}")
    
    # åŠ è½½æ•°æ®é›†
    with open(input_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    original_count = len(data)
    print(f"åŸå§‹æ•°æ®é›†åŒ…å« {original_count} æ¡è®°å½•")
    
    # è¿‡æ»¤é•¿è¾“å…¥
    filtered_data = []
    removed_count = 0
    
    for item in tqdm(data, desc="è¿‡æ»¤é•¿è¾“å…¥"):
        # è®¡ç®—inputå­—æ®µçš„é•¿åº¦
        input_length = len(item.get("input", ""))
        
        # å¦‚æœé•¿åº¦åœ¨å…è®¸èŒƒå›´å†…ï¼Œä¿ç•™è¯¥æ¡ç›®
        if input_length <= max_length:
            filtered_data.append(item)
        else:
            removed_count += 1
    
    # ä¿å­˜è¿‡æ»¤åçš„æ•°æ®é›†
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(filtered_data, f, ensure_ascii=False, indent=2)
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print(f"\nè¿‡æ»¤å®Œæˆ!")
    print(f"ç§»é™¤äº† {removed_count} æ¡é•¿è¾“å…¥è®°å½• ({removed_count/original_count:.2%})")
    print(f"ä¿ç•™äº† {len(filtered_data)} æ¡è®°å½•")
    print(f"è¿‡æ»¤åçš„æ•°æ®é›†å·²ä¿å­˜åˆ°: {output_path}")
    
    return filtered_data

if __name__ == "__main__":
    # è®¾ç½®è·¯å¾„
    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    input_dataset_path = os.path.join(base_dir, "data", "paper_review_dataset", "paper_review_dataset.json")
    output_dir = os.path.join(base_dir, "model", "llama_factory_dataset")
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    # è®¾ç½®è¾“å‡ºæ–‡ä»¶è·¯å¾„
    llama_factory_output = os.path.join(output_dir, "llama_factory_format.json")
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_dataset_path):
        print(f"è¾“å…¥æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {input_dataset_path}")
        print("è¯·å…ˆè¿è¡Œ create_llama_factory_dataset.py åˆ›å»ºæ•°æ®é›†")
        exit(1)
    
    # åˆ›å»ºLlama Factoryæ ¼å¼æ•°æ®
    print("åˆ›å»ºLlama Factoryæ ¼å¼æ•°æ®...")
    llama_factory_data = format_for_llama_factory(input_dataset_path, llama_factory_output)
    
    # è‡ªåŠ¨åˆ›å»ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†åˆ†å‰²
    qlora_output = os.path.join(output_dir, "llama_factory_qlora.json")
    dpo_output = os.path.join(output_dir, "llama_factory_dpo.json")
    eval_output = os.path.join(output_dir, "llama_factory_eval.json")

    print("åˆ›å»ºè®­ç»ƒé›†ã€DPOé›†å’Œæµ‹è¯•é›†åˆ†å‰²...")
    qlora_data, dpo_data, eval_data = create_train_dpo_test_split(
        llama_factory_output, qlora_output, dpo_output, eval_output
    )
    
    # print(f"Llama Factoryæ ¼å¼æ•°æ®å·²ä¿å­˜åˆ°: {llama_factory_output}")
    print(f"QLoraè®­ç»ƒé›†å·²ä¿å­˜åˆ°: {qlora_output} ({len(qlora_data)} æ¡è®°å½•)")
    print(f"DPOè®­ç»ƒé›†å·²ä¿å­˜åˆ°: {dpo_output} ({len(dpo_data)} æ¡è®°å½•)")
    print(f"æµ‹è¯•é›†å·²ä¿å­˜åˆ°: {eval_output} ({len(eval_data)} æ¡è®°å½•)")
    
    rejected_sources = {
        # "qlora": "outputs/qlora_dpo_outputs.json",
        # "llama3": "outputs/llama3_dpo_outputs.json",
        # "gpt4o": "outputs/chatgpt4o_dpo_outputs.json"
    }

    for name, rejected_path in rejected_sources.items():
        output_path = os.path.join(output_dir, f"dpo_pair_{name}.json")
        build_dpo_dataset_from_split(dpo_output, rejected_path, output_path)

    for path in [llama_factory_output, dpo_output]:
        if os.path.exists(path):
            os.remove(path)
            print(f"ğŸ§¹ å·²åˆ é™¤ä¸­é—´æ–‡ä»¶: {path}")


    print("è½¬æ¢å®Œæˆï¼")