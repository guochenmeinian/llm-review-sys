# Bayesian Online Natural Gradient (BONG)

 Matt Jones

University of Colorado

mcjones@colorado.edu &Peter Chang

MIT

gyuyoung@mit.edu &Kevin Murphy

Google DeepMind

kpmurphy@google.com

###### Abstract

We propose a novel approach to sequential Bayesian inference based on variational Bayes (VB). The key insight is that, in the online setting, we do not need to add the KL term to regularize to the prior (which comes from the posterior at the previous timestep); instead we can optimize just the expected log-likelihood, performing a single step of natural gradient descent starting at the prior predictive. We prove this method recovers exact Bayesian inference if the model is conjugate. We also show how to compute an efficient deterministic approximation to the VB objective, as well as our simplified objective, when the variational distribution is Gaussian or a sub-family, including the case of a diagonal plus low-rank precision matrix. We show empirically that our method outperforms other online VB methods in the non-conjugate setting, such as online learning for neural networks, especially when controlling for computational costs.

## 1 Introduction

Bayesian methods for neural network (NN) training aim to minimize the Kullback-Leibler divergence between true and estimated posterior distributions. This is equivalent to minimizing the variational loss (or negative ELBO)

\[\mathcal{L}(\mathbf{\psi})=-\mathbb{E}_{\mathbf{\theta}\sim q_{\mathbf{\psi}}}[\log p( \mathcal{D}|\mathbf{\theta})]+D_{\text{KL}}(q_{\mathbf{\psi}}|p_{0}) \tag{1}\]

Here \(\mathbf{\theta}\) are the network parameters, \(\mathbf{\psi}\) are the variational parameters of the approximate posterior \(q_{\mathbf{\psi}}(\mathbf{\theta})\), \(\mathcal{D}\) is the training dataset, and \(p_{0}(\mathbf{\theta})\) is the prior. The two terms in the variational loss correspond to data fit and regularization to the prior, the latter being analogous to a regularizer \(r(\mathbf{\theta})=-\log p_{0}(\mathbf{\theta})\) in traditional point estimation methods like SGD.

An important set of approaches learns the variational parameters by gradient descent on \(\mathcal{L}(\mathbf{\psi})\)(Blundell et al., 2015). More recently Khan and colleagues (Khan et al., 2018; Khan and Rue, 2023; Shen et al., 2024) have proposed using the natural gradient \(\mathbf{F}_{\mathbf{\psi}}^{-1}\nabla_{\mathbf{\psi}}\mathcal{L}(\mathbf{\psi})\) where \(\mathbf{F}_{\mathbf{\psi}}\) is the Fisher information matrix of the variational family evaluated at \(q_{\mathbf{\psi}}\). Natural gradient descent (NGD) is often more efficient than vanilla GD because it accounts for the intrinsic geometry of the variational family (Amari, 1998). Khan and Rue (2023) call this approach the "Bayesian Learning Rule" or BLR. Using various choices for the variational distribution, generalized losses replacing negative log-likelihood, and other approximations, they reproduce many standard optimization methods such as Adam, and derive new ones.

We study Bayesian NN optimization in online learning, where the data are observed in sequence, \(\mathcal{D}_{t}=\{(\mathbf{x}_{k},\mathbf{y}_{k})_{k=1}^{t}\}\), and the algorithm maintains an approximate posterior \(q_{\mathbf{\psi}_{t}}(\mathbf{\theta}_{t})\approx p(\mathbf{\theta}_{t}|\mathcal{D}_{t})\), which it updates at each step. Fast updates (in terms of both computational speed and statistical efficiency) are critical for many online learning applications (Zhang et al., 2024). To allow for nonstationarity in the datastream, we include a time index on \(\mathbf{\theta}_{t}\), to represent that the parameters may change over time, as is standard for approaches based on state-space models and the extended Kalman filter (see e.g., (Sarkka and Svensson, 2023)). The belief state is updated recursively usingthe prior \(q_{\mathbf{\psi}_{t|t-1}}\) derived from the previous time step so that the variational loss becomes

\[\mathcal{L}(\mathbf{\psi}_{t})=-\mathbb{E}_{\mathbf{\theta}_{t}\sim q_{\mathbf{\psi}_{t}}}[ \log p(\mathbf{y}_{t}|\mathbf{x}_{t},\mathbf{\theta}_{t})]+D_{\mathbb{KL}}\big{(}q_{\mathbf{ \psi}_{t}}|q_{\mathbf{\psi}_{t|t-1}}\big{)} \tag{2}\]

One option for this online learning problem is to apply NGD on \(\mathcal{L}(\mathbf{\psi}_{t})\) at each time step, iterating until \(\mathbf{\psi}_{t}\) converges before consuming the next observation. Our first contribution is a proposal for skipping this inner loop by (a) performing a single natural gradient step with unit learning rate and (b) omitting the \(D_{\mathbb{KL}}\) term in Eq. (2) so that learning is based only on expected loglikelihood:

\[\mathbf{\psi}_{t}=\mathbf{\psi}_{t|t-1}+\mathbf{F}_{\mathbf{\psi}_{t|t-1}}^{-1}\nabla_{ \mathbf{\psi}_{t|t-1}}\mathbb{E}_{\mathbf{\theta}_{t}\sim q_{\mathbf{\psi}_{t|t-1}}}[\log p \left(\mathbf{y}_{t}|\mathbf{x}_{t},\mathbf{\theta}_{t}\right)] \tag{3}\]

These two modifications work together: instead of regularizing toward the prior explicitly using \(D_{\mathbb{KL}}\big{(}q_{\mathbf{\psi}_{t}}|q_{\mathbf{\psi}_{t|t-1}}\big{)}\), we do so implicitly by using \(\mathbf{\psi}_{t|t-1}\) as the starting point of our single natural gradient step. This may appear as a heuristic but we prove in Proposition 4.1 that it yields exact Bayesian inference when \(q_{\mathbf{\psi}}\) and \(p\left(\mathbf{y}|\mathbf{x},\mathbf{\theta}\right)\) are conjugate and \(q_{\mathbf{\psi}}\) is an exponential family with natural parameter \(\mathbf{\psi}\). Thus our proposed update can be viewed as a relaxation of the Bayesian update to the non-conjugate variational case. As is common in work on variational inference, we view the result for the conjugate case as a motivating foundation that ensures our method is exact in certain simple settings. The experiments reported in Section 5 and Appendix B complement the theory by showing our method also works well in more general settings. We call Eq. (3) the Bayesian online natural gradient (bong).

Our second contribution concerns ways of computing the expectation in Eqs. (1) to (3). This is intractable for NNs, even for variational distributions that are easy to compute, since the likelihood takes the form \(p(\mathbf{y}_{t}|\mathbf{x}_{t},\mathbf{\theta}_{t})=p(\mathbf{y}_{t}|f(\mathbf{x}_{t},\mathbf{\theta }_{t}))\) with \(f(\mathbf{x}_{t},\mathbf{\theta}_{t})\), representing the function computed by the network, is a complex, nonlinear function of \(\mathbf{\theta}_{t}\). Many previous approaches have approximated the expected loglikelihood by sampling methods which add variance and computation time depending on the number of samples (Blundell et al., 2015; Shen et al., 2024). We propose a deterministic, closed-form update that applies when the variational distribution is Gaussian (or a sub-family) and the likelihood is an exponential family with natural parameter \(f(\mathbf{x}_{t},\mathbf{\theta}_{t})\) and mean parameter \(h(\mathbf{x}_{t},\mathbf{\theta}_{t})\) (e.g., for classification, \(f\) returns the vector of class logits, \(h\) returns class probabilities, and \(h=\mathrm{softmax}(f)\)). This update can be derived in two equivalent ways. First, we use a local linear approximation of the network \(h(\mathbf{x}_{t},\mathbf{\theta}_{t})\approx\bar{h}_{t}(\mathbf{\theta}_{t})\)(Immer et al., 2021) and a Gaussian approximation of the likelihood \(\mathcal{N}(\mathbf{y}_{t}|\bar{h}_{t}(\mathbf{\theta}_{t}),\mathbf{R}_{t})\)(Ollivier, 2018; Tronarp et al., 2018). Under these assumptions the expectation in Eq. (3) can be calculated analytically. Alternatively, we use a different linear approximation \(f(\mathbf{x}_{t},\mathbf{\theta}_{t})\approx f_{t}(\mathbf{\theta}_{t})\) and a delta approximation \(q_{\mathbf{\psi}_{t|t-1}}(\mathbf{\theta}_{t})\approx\delta_{\mathbf{\mu}_{t|t-1}}(\mathbf{ \theta}_{t})\) where \(\mathbf{\mu}_{t|t-1}=\mathbb{E}_{q_{\mathbf{\psi}_{t|t-1}}}[\mathbf{\theta}_{t}]\) is the prior mean, so that the expectation in Eq. (3) is replaced by a plugin prediction. The linear(\(h\))-Gaussian approximation is previously known but the linear(\(f\))-delta approximation is new, and we prove in Proposition 4.2 that they yield the same update, which we call linearized bong, or bong-lin. Finally, we discuss different ways of approximating the Hessian of the objective, which is needed for NGD.

Our bong framework unifies several existing methods for Bayesian online learning, and it offers new algorithms based on alternative variational families or parameterizations. We define a large space of methods by combining 4 different update rules with 4 different ways of computing the relevant expected gradients and Hessians and 3 different variational families (Gaussians with full, diagonal, and diagonal-plus-low rank precision matrices). We conduct experiments systematically testing how these factors affect performance. We find support for all three principles of our approach-- NGD, implicit regularization to the prior, and linearization-- in terms of both statistical and computational efficiency. Code for our experiments is available at [https://github.com/petergchang/bong/](https://github.com/petergchang/bong/).

## 2 Related work

Variational inference approximates the Bayesian posterior from within some suitable family in a way that bypasses the normalization term (Zellner, 1988; Jordan et al., 1999). A common choice for the variational family is a Gaussian. For online learning, the exact update equations for Gaussian variational filtering are given by the rvga method of (Lambert et al., 2021). This update is implicit but can be approximated by an explicit rvga update which we show arises as a special case of bong. Most applications of Gaussian VI use a mean-field approximation defined by diagonal covariance, which scales linearly with model size. More expressive but still linear in the model size are methodsthat express the covariance (Tomczak et al., 2020) or precision (Mishkin et al., 2018; Lambert et al., 2023; Chang et al., 2023) as a sum of diagonal and low rank matrices (DLR). In this paper, we consider variational families defined by full covariance, diagonal covariance, and DLR covariance.

For NNs and other complicated models, even the variational approximation can be intractable, so methods have been developed to approximately minimize the VI loss. Bayes by backprop (bbb)(Blundell et al., 2015) learns a variational distribution on NN weights by iterated GD on the VI loss of Eq. (1). They focus on mean-field Gaussian approximations but the approach also applies to other variational families. Here we adapt bbb to online learning to compare to our methods.

The Bayesian learning rule (blr) replaces bbb's GD with NGD (Khan and Rue, 2023). Several variants of blr have been developed including von and vogn for a mean-field Gaussian prior (Khan et al., 2018) and slang for a dlr Gaussian (Mishkin et al., 2018). blr has also been used to derive versions of many classic optimizers including SGD, RMSprop and Adam (Khan et al., 2018; Khan and Rue, 2023; Lin et al., 2024; Shen et al., 2024). Although blr has been applied to online learning, we are particularly interested in Bayesian filtering including in nonstationary environments, where observations must be processed one at time and updates are based on the posterior from the previous step, often in conjunction with parameter dynamics. We therefore develop filtering versions of blr to compare to bong, some of which reduce to von, vogn and slang in the batch setting, while others are novel. We also note blr is a mature theory including several clever tricks we have not yet incorporated into our framework.

Khan and Rue (2023) observe that conjugate updating is equivalent to one step of blr with learning rate 1. This is similar to our Proposition 4.1 except that blr retains the KL term in the variational loss. blr and bong agree in this case because the gradient of the KL is zero on blr's first iteration: \(\nabla_{\psi=\psi_{t|-1}}D_{\mathbb{KL}}\left(q_{\psi}|q_{\psi_{t|-1}}\right)=0\). Therefore bong can be seen as a special case of blr with one update step per observation and learning rate 1. Our contribution is to recognize that doing a single update step allows the KL term to be dropped entirely, yielding a substantially simpler algorithm which our experiments show also performs better.

While blr allows alternative losses in place of the NLL in Eq. (2), we can also replacing the KL term with other divergences (Knoblauch et al., 2022). Our approach fits within that "generalized VB" framework in that it drops the divergence altogether. Our approach of implicitly regularizing to the prior using a single NGD step is also similar to the implicit MAP filter of (Bencomo et al., 2023) which performs truncated GD from the prior mode. The principal difference is they perform GD on model parameters (\(\mathbf{\theta}_{t}\)) while we do NGD on the variational parameters (\(\mathbf{\psi}_{t}\)). Thus bong maintains a full prior and posterior while IMAP is more concerned with how the choice of optimizer can substitute for explicit tracking of covariance.

We show two other ways to derive the bong update in Appendix D, one of which is to replace the expected NLL in Eq. (2) with a linear approximation and solve the resulting equation exactly. Several past works have taken this approach, arriving at updates similar to ours. Cherief-Abdellatif et al. (2019) study streaming variational Bayes and propose solving Eq. (2) with a linearized expected NLL. When the variational family is an exponential family their update becomes NGD (Khan and Lin, 2017) and matches the bong update. Hoeven et al. (2018) show how mirror descent can be derived as a special case of Exponential Weights (Littlestone and Warmuth, 1994), which is closely related to Bayesian updating. The resulting algorithm is similar to bong and follows from linearizing the NLL instead of expected NLL, with an additional delta assumption at the prior mean. Lyu and Tsang (2021) study relaxed block-box optimization where the objective is \(\arg\min_{\psi}\mathbb{E}_{\mathbf{x}\sim q_{\psi}}[f(\mathbf{x})]\) for some target function \(f\). They use a mirror descent formulation with linearized expected loss and KL regularizer and show the resulting update is NGD on expected loss, formally equivalent to our BONG update. From the perspective of this prior work, our contribution is to express the bong update simply as NGD on the expected NLL, motivated by replacing the KL with implicit regularization, and to show how this yields a variety of known and novel algorithms for Bayesian filtering.

EKF applications to NNs apply Bayesian filtering using a local linear approximation of the network, leading to simple closed form updates (Singhal and Wu, 1989; Puskorius and Feldkamp, 1991). The classic EKF assumes a Gaussian observation distribution but it has been extended to other exponential families (e.g. for classification) by matching the mean and covariance in what we call the conditional moments EKF (cm-ekf)(Ollivier, 2018; Tronarp et al., 2018). Applying a KL projection to diagonal covariance yields the variational diagonal EKF (vd-ekf)(Chang et al., 2022).

Alternatively, projecting to diagonal plus low rank precision using SVD gives Lo-fi(Chang et al., 2023). We derive all these methods as special cases of bong-lin. Further developments in this direction include the method of (Titsias et al., 2024) which does Bayesian filtering on only the final weight layer, and WoLF(Duran-Martin et al., 2024) which achieves robustness to outliers through data-dependent weighting of the loglikelihood.

## 3 Background

We study online supervised learning where the agent receives input \(\mathbf{x}_{t}\in\mathbb{R}^{D}\) and observation \(\mathbf{y}_{t}\in\mathbb{R}^{C}\) on each time step, which it aims to model with a function \(f_{t}(\mathbf{\theta}_{t})=f(\mathbf{x}_{t},\mathbf{\theta}_{t})\) such as a NN with weights \(\mathbf{\theta}_{t}\in\mathbb{R}^{P}\). The predictions for \(\mathbf{y}_{t}\) are given by some observation distribution \(p(\mathbf{y}_{t}|f_{t}(\mathbf{\theta}_{t}))\). For example, \(f\) may compute the mean for regression or the class logits for classification.

We work in a Bayesian framework where the agent maintains an approximate posterior distribution over \(\mathbf{\theta}_{t}\) after observing data \(\mathcal{D}_{t}=\{(\mathbf{x}_{k},\mathbf{y}_{k})_{k=1}^{t}\}\). The filtering posterior \(q_{\mathbf{\psi}_{t}}(\mathbf{\theta}_{t})\approx p(\mathbf{\theta}_{t}|\mathcal{D}_{t})\) is approximated within some parametric family indexed by the variational parameter \(\mathbf{\psi}_{t}\). We allow for nonstationarity by assuming \(\mathbf{\theta}\) changes over time according to some dynamic model \(p(\mathbf{\theta}_{t}|\mathbf{\theta}_{t-1})\). By pushing the posterior from step \(t-1\) through the dynamics we obtain a prior for step \(t\) given by \(q_{\mathbf{\psi}_{t|t-1}}(\mathbf{\theta}_{t})\approx p(\mathbf{\theta}_{t}|\mathcal{D}_{t-1})\). For example suppose the variational posterior from the previous step is Gaussian, \(q_{\mathbf{\psi}_{t-1}}(\mathbf{\theta}_{t-1})=\mathcal{N}(\mathbf{\theta}_{t-1}|\mathbf{\mu}_{ t-1},\mathbf{\Sigma}_{t-1})\), and the dynamics model is an Ornstein-Uhlenbeck process, as proposed in prior work (Kurle et al., 2020; Titsias et al., 2024) to handle non-stationarity, i.e., the dynamics model has the form \(\mathbf{\theta}_{t}\sim\mathcal{N}(\gamma_{t}\mathbf{\theta}_{t-1}+(1-\gamma_{t})\mathbf{ \mu}_{0},\mathbf{Q}_{t})\), where \(\mathbf{Q}_{t}=(1-\gamma_{t}^{2})\mathbf{\Sigma}_{0}\) is the covariance of the noise process, \(0\leq\gamma_{t}\leq 1\) is the degree of drift, and \(p(\mathbf{\theta}_{0})=\mathcal{N}(\mathbf{\mu}_{0},\mathbf{\Sigma}_{0})\) is the prior. In this case, the parameters of the prior predictive distribution are \(\mathbf{\mu}_{t|t-1}=\gamma_{t}\mathbf{\mu}_{t-1}+(1-\gamma_{t})\mathbf{\mu}_{0}\) and \(\mathbf{\Sigma}_{t|t-1}=\gamma_{t}^{2}\mathbf{\Sigma}_{t-1}+\mathbf{Q}_{t}\). In general the predict step may require approximation to stay in the variational family (e.g., if the dynamics are nonlinear). In this paper, our focus is the update step from \(\mathbf{\psi}_{t|t-1}\) to \(\mathbf{\psi}_{t}\) upon observing \((\mathbf{x}_{t},\mathbf{y}_{t})\), so for simplicity we assume constant (static) parameters, i.e., \(p(\mathbf{\theta}_{t}|\mathbf{\theta}_{-1})=\delta(\mathbf{\theta}_{t}-\mathbf{\theta}_{t-1})\) (equivalently \(\gamma_{t}=1\)), so \(\mathbf{\psi}_{t|t-1}=\mathbf{\psi}_{t-1}\); however, our method can trivially handle non-stationary parameters.

Variational inference seeks an approximate posterior that minimizes the KL divergence from the exact Bayesian update from the prior. In the online setting this becomes

\[\mathbf{\psi}_{t}^{*}=\operatorname*{arg\,min}_{\mathbf{\psi}}D_{\text{KL}}\big{(}q_{ \mathbf{\psi}}(\mathbf{\theta}_{t})|Z_{t}^{-1}q_{\mathbf{\psi}_{t|t-1}}(\mathbf{\theta}_{t})\,p (\mathbf{y}_{t}|f_{t}(\mathbf{\theta}_{t}))\big{)}=\operatorname*{arg\,min}_{\mathbf{\psi} }\mathcal{L}_{t}(\mathbf{\psi}) \tag{4}\]

where \(\mathcal{L}_{t}\) is the online VI loss defined in Eq. (2), and the normalization term \(Z_{t}\) (which depends on \(\mathbf{x}_{t}\)) drops out as an additive constant. Our goal is an efficient approximate solution to this variational optimization problem.

We will sometimes assume the variational posterior \(q_{\mathbf{\psi}}\) is an exponential family distribution with natural parameter \(\mathbf{\psi}\) so that \(q_{\mathbf{\psi}_{t}}(\mathbf{\theta}_{t})=\exp\big{(}\mathbf{\psi}_{t}^{*}T(\mathbf{\theta}_{ t})-\Phi(\mathbf{\psi}_{t})\big{)}\), with log-partition function \(\Phi\) and sufficient statistics \(T(\mathbf{\theta}_{t})\). Assuming \(\Phi\) is strictly convex (which holds in the cases we study) there is a bijection between \(\mathbf{\psi}_{t}\) and the dual (or expectation) parameter \(\mathbf{\rho}_{t}=\mathbb{E}_{\mathbf{\theta}_{t}\sim\mathbf{\psi}_{t}}[T(\mathbf{\theta}_{t})]\). Classical thermodynamic identities imply that the Fisher information matrix has the form \(\mathbf{F}_{\mathbf{\psi}_{t}}=\partial\mathbf{\rho}_{t}/\partial\mathbf{\psi}_{t}\). This has important implications for NGD on exponential families (Khan and Rue, 2023) because it implies that for any function \(\ell\) defined on the variational parameter space the natural gradient wrt natural parameters \(\mathbf{\psi}_{t}\) is the regular gradient wrt the dual parameters \(\mathbf{\rho}_{t}\), i.e., \(\mathbf{F}_{\mathbf{\psi}_{t}}^{-1}\nabla_{\mathbf{\psi}_{t}}\ell=\nabla_{\mathbf{\rho}_{ t}}\ell\).

## 4 Methods

We propose to approximate the variational optimization problem in Eq. (4) using the bong update in Eq. (3). When \(q_{\mathbf{\psi}}\) is an exponential family, the fact that the natural gradient wrt the natural parameters \(\mathbf{\psi}_{t}\) is the regular gradient wrt the dual parameters \(\mathbf{\rho}_{t}\) implies an equivalent mirror descent form (see Appendix D for further analysis of bong from the MD perspective):

\[\mathbf{\psi}_{t}=\mathbf{\psi}_{t|t-1}+\nabla_{\mathbf{\rho}_{t|t-1}}\mathbb{E}_{\mathbf{ \theta}_{t}\sim q_{\mathbf{\psi}_{t|t-1}}}[\log p(\mathbf{y}_{t}|\mathbf{x}_{t},\mathbf{\theta }_{t})] \tag{5}\]

This is NGD with unit learning rate on the variational loss in Eq. (2) but ignoring the \(D_{\text{KL}}\big{(}q_{\mathbf{\psi}}|q_{\mathbf{\psi}_{t|t-1}}\big{)}\) term. In this section we first prove this method is optimal when the model is conjugate and then describe extensions to more complex cases of practical interest.

### Conjugate case

Our approach is motivated by the following result which states that bong matches exact Bayesian inference when the variational distribution and the likelihood are conjugate exponential families:

**Proposition 4.1**.: _Let the observation distribution (likelihood) be an exponential family with natural parameter \(\mathbf{\theta}_{t}\) (where \(T_{l}(\mathbf{y}_{t})=\mathbf{y}_{t}\) is the sufficient statistics for the likelihood and \(A(\mathbf{\theta}_{t})\) is the log-partition function)_

\[p_{t}(\mathbf{y}_{t}|\mathbf{\theta}_{t})=\exp\left(\mathbf{\theta}_{t}^{\intercal}\mathbf{y}_{ t}-A(\mathbf{\theta}_{t})-b(\mathbf{y}_{t})\right) \tag{6}\]

_and let the prior be the conjugate exponential family_

\[q_{\mathbf{\psi}_{t|t-1}}(\mathbf{\theta}_{t})=\exp\left(\mathbf{\psi}_{t|t-1}^{\intercal}T (\mathbf{\theta}_{t})-\Phi(\mathbf{\psi}_{t|t-1})\right) \tag{7}\]

_with \(T(\mathbf{\theta}_{t})=[\mathbf{\theta}_{t};-A(\mathbf{\theta}_{t})]\). Then the exact Bayesian update agrees with Eq. (5)._

The proof is in Appendix C. Writing the natural parameters of the prior as \(\mathbf{\psi}_{t|t-1}=[\mathbf{\chi}_{t|t-1};\nu_{t|t-1}]\), we show the Bayesian update and bong both yield \(\mathbf{\chi}_{t}=\mathbf{\chi}_{t|t-1}+\mathbf{y}_{t}\) and \(\nu_{t}=\nu_{t|t-1}+1\). Intuitively, we are just accumulating a sum of the observed sufficient statistics, and a counter of the sample size (number of observations seen so far).

### Variational case

In practical settings the conjugacy assumption of Proposition 4.1 will not be met, so Eqs. (3) and (5) will only approximate the Bayesian update. In this paper we restrict to Gaussian variational families. We refer to the unrestricted case as FC (full covariance), defined by the variational distribution

\[q_{\mathbf{\psi}_{t|t-1}}(\mathbf{\theta}_{t})=\mathcal{N}\left(\mathbf{\theta}_{t}|\mathbf{ \mu}_{t|t-1},\mathbf{\Sigma}_{t|t-1}\right) \tag{8}\]

where \(\mathbf{\Sigma}_{t|t-1}\) can be any positive semi-definite (PSD) matrix. The natural and dual parameters are \(\mathbf{\psi}=(\mathbf{\Sigma}^{-1}\mathbf{\mu},-\frac{1}{2}\mathrm{vec}(\mathbf{\Sigma}^{-1}))\) and \(\mathbf{\rho}=(\mathbf{\mu},\mathrm{vec}(\mathbf{\mu}\mathbf{\mu}^{\intercal}+\mathbf{\Sigma}))\). Appendix E.1.1 shows that Eq. (5) translated back to \((\mathbf{\mu},\mathbf{\Sigma})\) gives the following bong update for the FC case:

\[\mathbf{\mu}_{t} =\mathbf{\mu}_{t|t-1}+\mathbf{\Sigma}_{t}\underbrace{\mathbb{E}_{\mathbf{ \theta}_{t}\sim q_{\mathbf{\psi}_{t|t-1}}}[\nabla_{\mathbf{\theta}_{t}}\log p(\mathbf{y}_{ t}|f_{t}(\mathbf{\theta}_{t}))]}_{\mathbf{g}_{t}} \tag{9}\] \[\mathbf{\Sigma}_{t}^{-1} =\mathbf{\Sigma}_{t|t-1}^{-1}-\underbrace{\mathbb{E}_{\mathbf{\theta}_{t }\sim q_{\mathbf{\psi}_{t|t-1}}}[\nabla_{\mathbf{\theta}_{t}}^{2}\log p(\mathbf{y}_{t}|f_{ t}(\mathbf{\theta}_{t}))]}_{\mathbf{G}_{t}} \tag{10}\]

which matches the explicit update in the RVGA method of (Lambert et al., 2021).

### Monte Carlo approximation

The integrals over the prior \(q_{\mathbf{\psi}_{t|t-1}}\) in Eqs. (9) and (10) are generally intractable and must be approximated. One option is to use Monte Carlo, in what we call bong-mc. Given \(M\) independent samples \(\hat{\mathbf{\theta}}_{t}^{(m)}\sim q_{\mathbf{\psi}_{t|t-1}}\), we estimate the expected gradient \(\mathbf{g}_{t}=\mathbb{E}_{\mathbf{\theta}_{t}\sim q_{\mathbf{\psi}_{t|t-1}}}[\nabla_{\bm {\theta}_{t}}\log p(\mathbf{y}_{t}|f_{t}(\mathbf{\theta}_{t}))]\) and expected Hessian \(\mathbf{G}_{t}=\mathbb{E}_{\mathbf{\theta}_{t}\sim q_{\mathbf{\psi}_{t|t-1}}}\big{[}\nabla _{\mathbf{\theta}_{t}}^{2}\log p\left(\mathbf{y}_{t}|f_{t}\left(\mathbf{\theta}_{t}\right) \right)\big{]}\) as the empirical means

\[\mathbf{g}_{t}^{\text{\tiny{MC}-\text{\tiny{HESS}}}} =\frac{1}{M}\sum_{m=1}^{M}\hat{\mathbf{g}}_{t}^{(m)}, \hat{\mathbf{g}}_{t}^{(m)}=\nabla_{\mathbf{\theta}_{t}=\hat{\mathbf{\theta}}_{t}^{(m)}} \log p(\mathbf{y}_{t}|f_{t}(\mathbf{\theta}_{t})) \tag{11}\] \[\mathbf{G}_{t}^{\text{\tiny{MC-\text{\tiny{HESS}}}}} =\frac{1}{M}\sum_{m=1}^{M}\hat{\mathbf{G}}_{t}^{(m)}, \hat{\mathbf{G}}_{t}^{(m)}=\nabla_{\mathbf{\theta}_{t}=\hat{\mathbf{\theta}}_{t}^{(m)}} ^{2}\log p(\mathbf{y}_{t}|f_{t}(\mathbf{\theta}_{t})) \tag{12}\]

We use \(\mathbf{G}^{\text{\tiny{MC-\text{\tiny{HESS}}}}}\) only for small models. Otherwise we use empirical Fisher (Section 4.5).

### Linearized bong

As an alternative to bong-mc, we propose a linear approximation we call bong-lin that yields a deterministic and closed-form update. Assume the likelihood is an exponential family as in Proposition 4.1 but with natural parameter predicted by some function \(f_{t}(\mathbf{\theta}_{t})=f(\mathbf{x}_{t},\mathbf{\theta}_{t})\):

\[p(\mathbf{y}_{t}|\mathbf{x}_{t},\mathbf{\theta}_{t})=\exp\left(f_{t}(\mathbf{\theta}_{t})^{ \intercal}\mathbf{y}_{t}-A(f_{t}(\mathbf{\theta}_{t}))-b(\mathbf{y}_{t})\right) \tag{13}\]We also define the dual (moment) parameter of the likelihood as \(h_{t}(\mathbf{\theta}_{t})=\mathbb{E}\left[\mathbf{y}_{t}|f_{t}(\mathbf{\theta}_{t})\right]\). In a NN, \(f_{t}\) and \(h_{t}\) are related by the final response layer. For example in classification \(f_{t}\) and \(h_{t}\) give the class logits and probabilities, with \(h_{t}(\mathbf{\theta}_{t})=\operatorname{softmax}(f_{t}(\mathbf{\theta}_{t}))\), with \(\mathbf{y}_{t}\) being the one-hot encoding.

We now define two methods for approximating the expected gradient \(\mathbf{g}_{t}\) and expected Hessian \(\mathbf{G}_{t}\), based on linearizing the predictive model at the prior mean \(\mathbf{\mu}_{t|t-1}\) in terms of either \(f_{t}(\mathbf{\theta}_{t})\) or \(h_{t}(\mathbf{\theta}_{t})\), and then prove their equivalence.

The **linear(\(h\))-Gaussian** approximation (Ollivier, 2018; Tronarp et al., 2018) linearizes \(h_{t}(\mathbf{\theta}_{t})\)

\[\bar{h}_{t}(\mathbf{\theta}_{t}) =\hat{\mathbf{y}}_{t}+\mathbf{H}_{t}(\mathbf{\theta}_{t}-\mathbf{\mu}_{t|t-1}) \tag{14}\] \[\hat{\mathbf{y}}_{t} =h_{t}(\mathbf{\mu}_{t|t-1})\] (15) \[\mathbf{H}_{t} =\frac{\partial h_{t}}{\partial\mathbf{\theta}_{t}}_{|\mathbf{\theta}_{t }=\mathbf{\mu}_{t|t-1}} \tag{16}\]

and approximates the likelihood by a Gaussian with variance based at \(\mathbf{\mu}_{t|t-1}\)

\[\bar{p}_{t}^{\mathrm{LG}}(\mathbf{y}_{t}|\mathbf{\theta}_{t})=\mathcal{N}(\mathbf{y}_{t}| \bar{h}_{t}(\mathbf{\theta}_{t}),\mathbf{R}_{t}),\quad\mathbf{R}_{t}=\mathbb{V} \left[\mathbf{y}_{t}|\mathbf{\theta}_{t}=\mathbf{\mu}_{t|t-1}\right] \tag{17}\]

The **linear(\(f\))-delta approximation** linearizes \(f_{t}(\mathbf{\theta}_{t})\) and maintains the original exponential family likelihood distribution in Eq. (13)

\[\bar{f}_{t}(\mathbf{\theta}_{t}) =f_{t}(\mathbf{\mu}_{t|t-1})+\mathbf{F}_{t}(\mathbf{\theta}_{t}-\mathbf{\mu}_ {t|t-1}) \tag{18}\] \[\mathbf{F}_{t} =\frac{\partial f_{t}}{\partial\mathbf{\theta}_{t}}_{|\mathbf{\theta}_{t} =\mathbf{\mu}_{t|t-1}}\] (19) \[\bar{p}_{t}^{\mathrm{LD}}(\mathbf{y}_{t}|\mathbf{\theta}_{t}) \propto\exp\left(\bar{f}_{t}(\mathbf{\theta}_{t})^{\intercal}\mathbf{y}_{ t}-A(\bar{f}_{t}(\mathbf{\theta}_{t}))-b(\mathbf{y}_{t})\right) \tag{20}\]

It also uses a plug-in approximation that replaces \(q_{\mathbf{\psi}_{t|t-1}}(\mathbf{\theta}_{t})\) with a point mass \(\delta_{\mathbf{\mu}_{t|t-1}}(\mathbf{\theta}_{t})\) so that the expected gradient and Hessian are approximated by their values at the prior mean, i.e., \(\nabla_{\mathbf{\theta}_{t}=\mathbf{\mu}_{t|t-1}}\log\bar{p}_{t}^{\mathrm{LD}}(\mathbf{y} _{t}|\mathbf{\theta}_{t})\) and \(\nabla_{\mathbf{\theta}_{t}=\mathbf{\mu}_{t|t-1}}^{2}\log\bar{p}_{t}^{\mathrm{LD}}(\bm {y}_{t}|\mathbf{\theta}_{t})\), rather than being sampled.

**Proposition 4.2**.: _Under a Gaussian variational distribution, the linear(\(h\))-Gaussian and linear(\(f\))-delta approximations yield the same values for the expected gradient and Hessian_

\[\mathbf{g}_{t}^{\mathrm{LIN}} =\mathbf{H}_{t}^{\intercal}\mathbf{R}_{t}^{-1}(\mathbf{y}_{t}-\hat{ \mathbf{y}}_{t}) \tag{21}\] \[\mathbf{G}_{t}^{\mathrm{LIN-HESS}} =-\mathbf{H}_{t}^{\intercal}\mathbf{R}_{t}^{-1}\mathbf{H}_{t} \tag{22}\]

See Appendix C for the proof. The main idea for the \(\mathbf{g}_{t}^{\mathrm{LIN}}\) part is that the linear-Gaussian assumptions make the gradient linear in \(\mathbf{\theta}_{t}\) so the expected gradient equals the gradient at the mean. The main idea for the \(\mathbf{G}_{t}^{\mathrm{LIN-HESS}}\) part is that eliminating the Hessian of the NN requires different linearizing assumptions for the Gaussian and delta approximations, and the remaining nonlinear terms (from the log-likelihood in Eq. (13)) agree because of the property of exponential families that the Hessian of the log-partition \(A\) equals the conditional variance \(\mathbf{R}_{t}\).

Applying Proposition 4.2 to Eqs. (9) and (10) gives the bong-lin update for a FC Gaussian prior

\[\mathbf{\mu}_{t} =\mathbf{\mu}_{t|t-1}+\mathbf{K}_{t}(\mathbf{y}_{t}-\hat{\mathbf{y}}_{t}) \tag{23}\] \[\mathbf{\Sigma}_{t} =\mathbf{\Sigma}_{t|t-1}-\mathbf{K}_{t}\mathbf{H}_{t}\mathbf{\Sigma}_{t| t-1}\] (24) \[\mathbf{K}_{t} =\mathbf{\Sigma}_{t|t-1}\mathbf{H}_{t}^{\intercal}\left(\mathbf{R} _{t}+\mathbf{H}_{t}\mathbf{\Sigma}_{t|t-1}\mathbf{H}_{t}^{\intercal}\right)^{-1} \tag{25}\]

where \(\mathbf{K}_{t}\) is the Kalman gain matrix (see Appendix E.1.2). This matches the cm-ekf(Tronarp et al., 2018; Ollivier, 2018).

### Empirical Fisher

The methods in Sections 4.3 and 4.4 require explicitly computing the Hessian of the loss (mc-hess) or the Jacobian of the network (lin-hess). These are too expensive for large models or high-dimensional observations. Instead we can use an empirical Fisher approximation that replaces the Hessian with the outer product of the gradient (see e.g, (Martens, 2020)).

\begin{table}
\begin{tabular}{c c} \hline Name & Eqs. \\ \hline mc-hess & (11), (12) \\ lin-hess & (21), (22) \\ mc-ef & (11), (26) \\ lin-ef & (28), (29) \\ \hline \end{tabular}
\end{table}
Table 1: The 4 Hessian approximations.

For the mc-ef variant, we make the following approximation:

\[\mathbf{G}_{t}^{\textsc{mc-ef}}=-\frac{1}{M}\hat{\mathbf{G}}_{t}^{(1:M)}\hat{ \mathbf{G}}_{t}^{(1:M)^{\intercal}} \tag{26}\]

where \(\hat{\mathbf{G}}_{t}^{(1:M)}=[\hat{\mathbf{g}}_{t}^{(1)},\ldots,\hat{\mathbf{g}}_{t}^{(M )}]\) is the \(P\times M\) matrix of gradients from the MC samples.

We can also consider a similar approach for the lin-ef variant that is Jacobian-free and sampling-free. Note that if \(\hat{\mathbf{y}}_{t}\) were the true value of \(\mathbb{E}\left[\mathbf{y}_{t}|\mathbf{x}_{t}\right]\) (i.e., if the model were correct) then we would have \(\mathbb{E}\left[(\mathbf{y}_{t}-\hat{\mathbf{y}}_{t})(\mathbf{y}_{t}-\hat{\mathbf{y}}_{t})^{ \intercal}\right]=\mathbf{R}_{t}\), implying \(\mathbb{E}\left[\mathbf{g}_{t}^{\textsc{lin}}\left(\mathbf{g}_{t}^{\textsc{lin}}\right) ^{\intercal}\right]=-\mathbf{G}_{t}^{\textsc{lin-hits}}\). This suggests using

\[\mathbf{g}_{t}^{\textsc{lin-ef}} =\nabla_{\mathbf{\theta}_{t}=\mathbf{\mu}_{t|t-1}}\left[-\tfrac{1}{2} \left(\mathbf{y}_{t}-h_{t}(\mathbf{\theta}_{t})\right)^{\intercal}\mathbf{R}_{t}^{-1}( \mathbf{y}_{t}-h_{t}(\mathbf{\theta}_{t}))\right] \tag{27}\] \[=\left(\frac{\partial h_{t}(\mathbf{\theta}_{t})}{\partial\mathbf{\theta} _{t}}\right)^{\intercal}_{\mathbf{\theta}_{t}=\mathbf{\mu}_{t|t-1}}\mathbf{R}_{t}^{-1}( \mathbf{y}_{t}-h_{t}(\mathbf{\mu}_{t|t-1}))=\mathbf{g}_{t}^{\textsc{lin}}\] (28) \[\mathbf{G}_{t}^{\textsc{lin-ef}} =-\mathbf{g}_{t}^{\textsc{lin}}\left(\mathbf{g}_{t}^{\textsc{lin}}\right) ^{\intercal} \tag{29}\]

where Eq. (29) is the EF approximation to Eq. (22).

A more accurate EF approximation is possible by sampling virtual observations \(\tilde{\mathbf{y}}_{t}\) from \(p(\cdot|f_{t}(\hat{\mathbf{\theta}}_{t}^{(m)}))\) or \(p(\cdot|f_{t}(\mathbf{\mu}_{t|t-1}))\) and using them for the gradients in Eq. (26) or Eq. (29) (respectively) (Martens, 2020; Kunstner et al., 2020). However, in our experiments we use the actual observations \(\mathbf{y}_{t}\) which is faster and follows previous work (e.g., (Khan et al., 2018)).

### Update rules

In addition to the four ways of approximating the expected Hessian (summarized in Table 1), we also consider four variants of bong, based on what kind of loss we optimize and what kind of update we perform, as we describe below. See Table 2 for a summary.

**bong** (Bayesian online natural gradient) performs one step of NGD on the expected log-likelihood. We set learning rate to \(\alpha_{t}=1\) since this is optimal for conjugate models. The update (for an exponential variational family) is as in Eq. (5):

\[\mathbf{\psi}_{t}=\mathbf{\psi}_{t|t-1}+\nabla_{\mathbf{\rho}_{t|t-1}}\mathbb{E}_{\mathbf{ \theta}_{t}\sim q_{\mathbf{\psi}_{t|t-1}}}[\log p(\mathbf{y}_{t}|\mathbf{x}_{t},\mathbf{\theta }_{t})] \tag{30}\]

**bog** (Bayesian online gradient) performs one step of GD (instead of NGD) on the expected log-likelihood. We include a learning rate \(\alpha\) because GD does not have the scale-invariance of NGD:

\[\mathbf{\psi}_{t}=\mathbf{\psi}_{t}+\alpha_{t}\nabla_{\mathbf{\psi}_{t}}\mathbb{E}_{\mathbf{ \theta}_{t}\sim q_{\mathbf{\psi}_{t}}}[\log p(\mathbf{y}_{t}|f_{t}(\mathbf{\theta}_{t}))] \tag{31}\]

**blr** (Bayesian learning rule, (Khan and Rue, 2023)) uses NGD (like bong) but optimizes the VI loss using multiple iterations, instead of optimizing the expected NLL with a single step. When modified to the online setting, blr starts an inner loop at each time step with \(\mathbf{\psi}_{t,0}=\mathbf{\psi}_{t|t-1}\) and iterates

\[\mathbf{\psi}_{t,i}=\mathbf{\psi}_{t,i-1}+\alpha_{t}\mathbf{F}_{\mathbf{\psi}_{t,i-1}} \nabla_{\mathbf{\psi}_{t,i-1}}\Big{(}\mathbb{E}_{\mathbf{\theta}_{t}\sim q_{\mathbf{\psi}_ {t,i-1}}}[\log p(\mathbf{y}_{t}|f_{t}(\mathbf{\theta}_{t}))]-D_{\mathbb{KL}}\big{(}q_{ \mathbf{\psi}_{t,i-1}}|q_{\mathbf{\psi}_{t|t-1}}\big{)}\Big{)} \tag{32}\]

For an exponential variational family this can be written in mirror descent form

\[\mathbf{\psi}_{t,i}=\mathbf{\psi}_{t,i-1}+\alpha_{t}\nabla_{\mathbf{\rho}_{t,i-1}}\Big{(} \mathbb{E}_{\mathbf{\theta}_{t}\sim q_{\mathbf{\psi}_{t,i-1}}}[\log p(\mathbf{y}_{t}|f_{t} (\mathbf{\theta}_{t}))]-D_{\mathbb{KL}}\big{(}q_{\mathbf{\psi}_{t,i-1}}|q_{\mathbf{\psi}_{ t|t-1}}\big{)}\Big{)} \tag{33}\]

**bbb** (Bayes By Backprop, (Blundell et al., 2015)) is like blr but uses GD instead of NGD. When adapted to online learning, it starts each time step at \(\mathbf{\psi}_{t,0}=\mathbf{\psi}_{t|t-1}\) and iterates with GD:

\[\mathbf{\psi}_{t,i}=\mathbf{\psi}_{t,i-1}+\alpha_{t}\nabla_{\mathbf{\psi}_{t,i-1}}\Big{(} \mathbb{E}_{\mathbf{\theta}_{t}\sim q_{\mathbf{\psi}_{t,i-1}}}[\log p(\mathbf{y}_{t}|f_{t}( \mathbf{\theta}_{t}))]-D_{\mathbb{KL}}\big{(}q_{\mathbf{\psi}_{t,i-1}}|q_{\mathbf{\psi}_{t|t -1}}\big{)}\Big{)} \tag{34}\]

\begin{table}
\begin{tabular}{c c c} \hline Name & Loss & Update \\ \hline bong & \(\mathbb{E}\left[\textsc{NLL}\right]\) & NGD(\(I=1\)) \\ bog & \(\mathbb{E}\left[\textsc{NLL}\right]\) & GD(\(I=1\)) \\ blr & VI & NGD(\(I\geq 1\)) \\ bbb & VI & GD(\(I\geq 1\)) \\ \hline \end{tabular}
\end{table}
Table 2: The 4 update algorithms.

### Variational families and their parameterizations

We investigate five variational families for the posterior distribution: (1) FC Gaussian using natural parameters \(\mathbf{\psi}=(\mathbf{\Sigma}^{-1}\mathbf{\mu},-\frac{1}{2}\mathbf{\Sigma}^{-1})\), (2) FC Gaussian using central moment parameters \(\mathbf{\psi}=(\mathbf{\mu},\mathbf{\Sigma})\), (3) diagonal Gaussian using natural parameters \(\mathbf{\psi}=(\mathbf{\sigma}^{-2}\mathbf{\mu},-\frac{1}{2}\mathbf{\sigma}^{-2})\) (using elementwise exponents and products), (4) diagonal Gaussian using central moment parameters \(\mathbf{\psi}=(\mathbf{\mu},\mathbf{\sigma}^{2})\), and (5) DLR Gaussian with parameters \(\mathbf{\psi}=(\mathbf{\mu},\mathbf{\Upsilon},\mathbf{\bar{W}})\) and precision \(\mathbf{\Sigma}^{-1}=\mathbf{\Upsilon}+\mathbf{\bar{W}}\mathbf{\bar{W}}^{\mathsf{T}}\) where \(\mathbf{\Upsilon}\in\mathbb{R}^{P\times P}\) is diagonal and \(\mathbf{\bar{W}}\in\mathbb{R}^{P\times\bar{W}}\) with \(R\ll P\). The moment parameterizations are included to test the importance of using natural parameters per Proposition 4.1. The diagonal family allows learning of large models because it scales linearly in the model size \(P\). DLR also scales linearly but is more expressive than diagonal, maintaining some of the correlation information between parameters that is lost in the mean field (diagonal) approximation (Lambert et al., 2023; Mishkin et al., 2018; Chang et al., 2023).

Optimizing the bong objective wrt \((\mathbf{\mu},\mathbf{\Upsilon},\mathbf{\bar{W}})\) using NGD methods is challenging because the Fisher information matrix in this parameterization cannot be efficiently inverted. Instead we first derive the update wrt the FC natural parameters (leveraging the fact that the prior \(\mathbf{\Sigma}^{-1}_{t|t=1}\) is DLR to make this efficient), and then use SVD to project the posterior precision back to low-rank form, following our prior lo-fi work (Chang et al., 2023). However, if we omit the Fisher preconditioning matrix and use GD as in bog and bbb, we can directly optimize the objective wrt \((\mathbf{\mu},\mathbf{\Upsilon},\mathbf{\bar{W}})\) (see Appendix E.5).

### Overall space of methods

Crossing the four algorithms in Table 2, the four methods of approximating the Hessian in Table 1, and the five variational families yields 80 algorithms. Table 3 shows the 36 based on the three tractable Hessian approximations and the three variational families that use natural parameters. Update equations for all the algorithms are derived in Appendix E. Pseudocode is given in Appendix A.

\begin{table}
\begin{tabular}{l l c c c} \hline \hline  & & \multicolumn{4}{c}{Variational Family} \\ \cline{3-5} Update & Hessian & \multicolumn{2}{c}{Full} & \multicolumn{1}{c}{Diag} & \multicolumn{1}{c}{DLR} \\ \hline BONG & MC-EF & \(O(MP^{2})\) [rwga] & \(O(MP)\) & \(O((R+M)^{2}P)\) \\ BLR & MC-EF & \(O(I^{3})\) & \(O(IMP)\) [von] & \(O(I(R+M)^{2}P\) [slang] \\ BOG & MC-EF & \(O(P^{3})\) & \(O(MP)\) & \(O(RMP)\) \\ BBB & MC-EF & \(O(I^{3})\) & \(O(IMP)\) [bbb] & \(O(IR(R+M)P)\) \\ \hline BONG & LIN-HESS & \(O(CP^{2})\) [cm-ekf] & \(O(C^{2}P)\) [vd-ekf] & \(O((R+C)^{2}P)\) [lo-fi] \\ BLR & LIN-HESS & \(O(I^{3})\) & \(O(IC^{2}P)\) & \(O(I(2R+C)^{2}P)\) \\ BOG & LIN-HESS & \(O(P^{3})\) & \(O(C^{2}P)\) & \(O(C(C+R)P)\) \\ BBB & LIN-HESS & \(O(IP^{3})\) & \(O(IC^{2}P)\) & \(O(I(C+R)RP)\) \\ \hline BONG & LIN-EF & \(O(P^{2})\) & \(O(P)\) & \(O(R^{2}P)\) \\ BLR & LIN-EF & \(O(IP^{3})\) & \(O(IP)\) & \(O(IR^{2}P)\) \\ BOG & LIN-EF & \(O(P^{3})\) & \(O(P)\) & \(O(RP)\) \\ BBB & LIN-EF & \(O(IP^{3})\) & \(O(IP)\) & \(O(IR^{2}P)\) \\ \hline \hline \end{tabular}
\end{table}
Table 3: Time complexity of the algorithms. \(P\): params, \(C\): observation dim, \(M\): MC samples, \(I\): iterations, \(R\): DLR rank. We assume \(P\gg\{I,C,R,M\}\) so display only the terms of leading order in \(P\). Time complexities for mc-hess algorithms (not shown) are always at least as great as for the corresponding mc-ef. Full (full covariance) and Diag (diagonal covariance) columns indicate natural parameters; corresponding algorithms using moment parameters have the same complexities except bog-fc.mom which is \(O(MP^{2})\) for mc-ef, \(O(CP^{2})\) for lin-hess, and \(O(P^{2})\) for lin-ef. [Names] correspond to the following existing methods (or variants thereof) in the literature: rvga: (Lambert et al., 2021) (explicit update version); von: (Khan et al., 2018b) (modified for online); slang: (Mishkin et al., 2018) (modified for online); bbb: (Blundell et al., 2015) (modified for online and uses moment parameters); cm-ekf: (Ollivier, 2018; Tronarp et al., 2018); vd-ekf: (Chang et al., 2022); lo-fi: (Chang et al., 2023).

Experiments

This section presents our primary experimental results. These are based on mnist (\(D=784\), \(N_{\text{train}}=60\)k, \(N_{\text{test}}=10\)k, \(C=10\) classes) [LeCun et al., 2010]. See Appendix B for more details on these experiments, and more results on MNIST and other datasets. We focus on training on a prefix of the first \(T=2000\) examples from each dataset, since our main interest is in online learning from potentially nonstationary distributions, where rapid adaptation of a model in response to a small number of new data points is critical.

Our primary evaluation objective is the negative log predictive density (NLPD) of the test set as a function of the number of training points observed so far.1 It is defined as \(\text{NLPD}_{t}=-\frac{1}{N_{\text{test}}}\sum_{i\in\mathcal{D}^{\text{pos}}} \log\left[\int p(\mathbf{y}_{i}|f(\mathbf{x}_{i},\mathbf{\theta}_{t}))q_{\mathbf{\psi}_{t}}( \mathbf{\theta}_{t})\mathrm{d}\mathbf{\theta}_{t}\right]\). We approximate this integral in two main ways: (1) using Monte Carlo sampling2,or (2) using a plugin approximation, where we replace the posterior \(q_{\mathbf{\psi}_{t}}(\mathbf{\theta}_{t})\) with a delta function centered at the mean, \(\delta(\mathbf{\theta}_{t}-\mathbf{\mu}_{t})\).

Footnote 1: We assume the training and test sets are drawn from the same static distribution. Alternatively, if there is only one stream of data coming from a potential notstationary source, we can use the prequential or one-step-ahead log predictive density Gama et al. [2013]. We leave studying the non-stationary case to future work.

Footnote 2: That is, we compute \(S=100\) posterior samples \(\mathbf{\theta}_{t}^{*}\sim p(\mathbf{\theta}_{t}|\mathcal{D}_{1\text{\text{\text{ \text{\text{\text{\text{\text{\text{\text{\text{\text{\text* EF methods (lin-ef) are a bit faster than methods that compute the Hessian exactly (lin-hess), especially for diagonal family. (This speedup is larger when the output dimensionality \(C\) is big.) 

## 6 Conclusions, limitations and future work

Our experiment results show benefits of bong's three main principles: NGD, implicit regularization to the prior, and linearization. The clear winner across datasets and variational families is bong-lin-hess, which embodies all three principles. Blr-lin-hess nearly matches its performance but is much slower. Several of the best-performing algorithms are previously known (notably cm-ekf and lo-fi) but we explain these results within a systematic theory that also offers new methods (including blr-lin-hess).

Bong is motivated by Proposition 4.1 which applies only in the idealized setting of a conjugate prior. Nevertheless we find it performs well in non-conjugate settings. On the other hand our experiments are based on relatively small models and datasets. It will be important to test how our methods scale up, especially using the promising DLR representation.

Figure 2: Performance on MNIST using Lin-MC posterior predictive, where the posterior is computed using bong with different variational families, namely diagonal (natural and moment), blr-1, blr-10.

Figure 1: Performance on MNIST using Lin-MC posterior predictive, where the posterior is computed using bong, bog, bbb and blr and the 3 tractable Hessian approximations with blr-10 variational family.

## Acknowledgments and Disclosure of Funding

Thanks to Gerardo Duran-Martin and Alex Shestopaloff for helpful input. MJ was supported by NSF grant 2020-906.

## References

* Amari (1998) S Amari. Natural gradient works efficiently in learning. _Neural Comput._, 10(2):251-276, 1998. URL [http://dx.doi.org/10.1162/089976698300017746](http://dx.doi.org/10.1162/089976698300017746).
* Bencomo et al. (2023) Gianluca M Bencomo, Jake C Snell, and Thomas L Griffiths. Implicit maximum a posteriori filtering via adaptive optimization. _arXiv preprint arXiv:2311.10580_, 2023.
* Blundell et al. (2015) Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. Weight uncertainty in neural networks. In _ICML_, 2015. URL [http://arxiv.org/abs/1505.05424](http://arxiv.org/abs/1505.05424).
* Bonnet (1964) Georges Bonnet. Transformations des signaux aleatoires a travers les systemes non lineaires sans memoire. In _Annales des Telecommunications_, volume 19, pages 203-220. Springer, 1964.
* Chang et al. (2022) Peter G Chang, Kevin Patrick Murphy, and Matt Jones. On diagonal approximations to the extended kalman filter for online training of bayesian neural networks. In _Continual Lifelong Learning Workshop at ACML 2022_, December 2022. URL [https://openreview.net/forum?id=asgeEt25kk](https://openreview.net/forum?id=asgeEt25kk).
* Chang et al. (2023) Peter G Chang, Gerardo Duran-Martin, Alexander Y Shestopaloff, Matt Jones, and Kevin Murphy. Low-rank extended Kalman filtering for online learning of neural networks from streaming data. In _COLLAS_, May 2023. URL [http://arxiv.org/abs/2305.19535](http://arxiv.org/abs/2305.19535).
* Cherief-Abdellatif et al. (2019) Badr-Eddine Cherief-Abdellatif, Pierre Alquier, and Mohammad Emtiyaz Khan. A generalization bound for online variational inference. In _Asian conference on machine learning_, pages 662-677. PMLR, 2019.
* Duran-Martin et al. (2024) Gerardo Duran-Martin, Matias Altamirano, Alexander Y Shestopaloff, Leandro Sanchez-Betancourt, Jeremias Knoblauch, Matt Jones, Francois-Xavier Briol, and Kevin Murphy. Outlier-robust kalman filtering through generalised bayes. _arXiv preprint arXiv:2405.05646_, 2024.
* Gama et al. (2013) Joao Gama, Raquel Sebastiao, and Pedro Pereira Rodrigues. On evaluating stream learning algorithms. _MLJ_, 90(3):317-346, March 2013. URL [https://tinyurl.com/mrxfk4ww](https://tinyurl.com/mrxfk4ww).
* Halko et al. (2011) Nathan Halko, Per-Gunnar Martinsson, and Joel A Tropp. Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions. _SIAM review_, 53(2):217-288, 2011.
* Hoeven et al. (2018) Dirk Hoeven, Tim Erven, and Wojciech Kotlowski. The many faces of exponential weights in online learning. In _Conference On Learning Theory_, pages 2067-2092. PMLR, 2018.
* Hutchinson (1989) Michael F Hutchinson. A stochastic estimator of the trace of the influence matrix for laplacian smoothing splines. _Communications in Statistics-Simulation and Computation_, 18(3):1059-1076, 1989.
* Immer et al. (2021a) Alexander Immer, Maciej Korzepa, and Matthias Bauer. Improving predictions of bayesian neural nets via local linearization. In Arindam Banerjee and Kenji Fukumizu, editors, _AISTATS_, volume 130 of _Proceedings of Machine Learning Research_, pages 703-711. PMLR, 2021a. URL [https://proceedings.mlr.press/v130/immer21a.html](https://proceedings.mlr.press/v130/immer21a.html).
* Immer et al. (2021b) Alexander Immer, Maciej Korzepa, and Matthias Bauer. Improving predictions of bayesian neural nets via local linearization. In _Proceedings of The 24th International Conference on Artificial Intelligence and Statistics_, pages 703-711. PMLR, 2021b. URL [https://proceedings.mlr.press/v130/immer21a.html](https://proceedings.mlr.press/v130/immer21a.html).
* Jordan et al. (1999) Michael I Jordan, Zoubin Ghahramani, Tommi S Jaakkola, and Lawrence K Saul. An introduction to variational methods for graphical models. _Machine learning_, 37:183-233, 1999.
* Jordan et al. (2018)Mohammad Khan and Wu Lin. Conjugate-computation variational inference: Converting variational inference in non-conjugate models to inferences in conjugate models. In _Artificial Intelligence and Statistics_, pages 878-887. PMLR, 2017.
* Khan et al. (2018a) Mohammad Khan, Didrik Nielsen, Voot Tangkaratt, Wu Lin, Yarin Gal, and Akash Srivastava. Fast and scalable bayesian deep learning by weight-perturbation in adam. In _International conference on machine learning_, pages 2611-2620. PMLR, 2018a.
* Emityaz Khan and Rue (2023) Mohammad Emtiyaz Khan and Havard Rue. The bayesian learning rule. _J. Mach. Learn. Res._, 2023. URL [http://arxiv.org/abs/2107.04562](http://arxiv.org/abs/2107.04562).
* Khan et al. (2018b) Mohammad Emtiyaz Khan, Didrik Nielsen, Voot Tangkaratt, Wu Lin, Yarin Gal, and Akash Srivastava. Fast and scalable bayesian deep learning by Weight-Perturbation in adam. In _ICML_, 2018b. URL [http://arxiv.org/abs/1806.04854](http://arxiv.org/abs/1806.04854).
* Knoblauch et al. (2022) Jeremias Knoblauch, Jack Jewson, and Theodoros Damoulas. An optimization-centric view on bayes' rule: Reviewing and generalizing variational inference. _Journal of Machine Learning Research_, 23(132):1-109, 2022.
* Kunstner et al. (2020) Frederik Kunstner, Lukas Balles, and Philipp Hennig. Limitations of the empirical fisher approximation for natural gradient descent, 2020.
* Kurle et al. (2020) Richard Kurle, Botond Cseke, Alexej Klushyn, Patrick van der Smagt, and Stephan Gunnemann. Continual learning with bayesian neural networks for non-stationary data. In _ICLR_, March 2020. URL [https://openreview.net/forum?id=SJJsFpVtDB](https://openreview.net/forum?id=SJJsFpVtDB).
* Lambert et al. (2021) Marc Lambert, Silvere Bonnabel, and Francis Bach. The recursive variational gaussian approximation (R-VGA). _Stat. Comput._, 32(1):10, December 2021. URL [https://hal.inria.fr/hal-03086627/document](https://hal.inria.fr/hal-03086627/document).
* Lambert et al. (2023) Marc Lambert, Silvere Bonnabel, and Francis Bach. The limited-memory recursive variational gaussian approximation (l-rvga). _Statistics and Computing_, 33(3):70, 2023.
* LeCun et al. (2010) Yann LeCun, Corinna Cortes, and CJ Burges. Mnist handwritten digit database. _ATT Labs [Online]. Available: [http://yann.lecun.com/exdb/mnist_](http://yann.lecun.com/exdb/mnist_), 2, 2010.
* Lin et al. (2024) Wu Lin, Felix Dangel, Runa Eschenhagen, Juhan Bae, Richard E Turner, and Alireza Makhzani. Can we remove the square-root in adaptive gradient methods? a second-order perspective. _arXiv preprint arXiv:2402.03496_, 2024.
* Littlestone and Warmuth (1994) Nick Littlestone and Manfred K Warmuth. The weighted majority algorithm. _Information and computation_, 108(2):212-261, 1994.
* Lyu and Tsang (2021) Yueming Lyu and Ivor W Tsang. Black-box optimizer with stochastic implicit natural gradient. In _Machine Learning and Knowledge Discovery in Databases. Research Track: European Conference, ECML PKDD 2021, Bilbao, Spain, September 13-17, 2021, Proceedings, Part III 21_, pages 217-232. Springer, 2021.
* Martens (2020) James Martens. New insights and perspectives on the natural gradient method. _Journal of Machine Learning Research_, 21(146):1-76, 2020.
* Mishkin et al. (2018) Aaron Mishkin, Frederik Kunstner, Didrik Nielsen, Mark Schmidt, and Mohammad Emtiyaz Khan. SLANG: Fast structured covariance approximations for bayesian deep learning with natural gradient. In _NIPS_, pages 6245-6255. Curran Associates, Inc., 2018.
* Ollivier (2018) Yann Ollivier. Online natural gradient as a kalman filter. _Electron. J. Stat._, 12(2):2930-2961, 2018. URL [https://projecteuclid.org/euclid.ejs/1537257630](https://projecteuclid.org/euclid.ejs/1537257630).
* Price (1958) Robert Price. A useful theorem for nonlinear devices having gaussian inputs. _IRE Transactions on Information Theory_, 4(2):69-72, 1958.
* Puskorius and Feldkamp (1991) G V Puskorius and L A Feldkamp. Decoupled extended kalman filter training of feedforward layered networks. In _International Joint Conference on Neural Networks_, volume i, pages 771-777 vol.1, 1991. URL [http://dx.doi.org/10.1109/IJCNN.1991.155276](http://dx.doi.org/10.1109/IJCNN.1991.155276).
* Puskorius and Feldkamp (2018)Carl Edward Rasmussen and Christopher K. I. Williams. _Gaussian Processes for Machine Learning_. MIT Press, 2006.
* Sarkka and Svensson (2023) Simo Sarkka and Lennart Svensson. _Bayesian Filtering and Smoothing (2nd edition)_. Cambridge University Press, 2023.
* Shen et al. (2024) Yuesong Shen, Nico Dabeim, Bai Cong, Peter Nickl, Gian Maria Marconi, Clement Bazan, Rio Yokota, Iryna Gurevych, Daniel Cremers, Mohammad Emtiyaz Khan, and Thomas Mollenhoff. Variational learning is effective for large deep networks. _arXiv preprint arXiv:2402.17641_, 2024.
* Singhal and Wu (1989) Sharad Singhal and Lance Wu. Training multilayer perceptrons with the extended kalman algorithm. In _NIPS_, volume 1, 1989.
* Titsias et al. (2024) Michalis K Titsias, Alexandre Galashov, Amal Rannen-Triki, Razvan Pascanu, Yee Whye Teh, and Jorg Bornschein. Kalman filter for online classification of non-stationary data. In _ICLR_, 2024.
* Tomczak et al. (2020) Marcin B Tomczak, Siddharth Swaroop, and Richard E Turner. Efficient low rank gaussian variational inference for neural networks. In _NIPS_, 2020. URL [https://proceedings.neurips.cc/paper/2020/file/310cc7ca5a76a446f85c1a0d641ba96d-Paper.pdf](https://proceedings.neurips.cc/paper/2020/file/310cc7ca5a76a446f85c1a0d641ba96d-Paper.pdf).
* Tronarp et al. (2018) Filip Tronarp, Angel F Garcia-Fernandez, and Simo Sarkka. Iterative filtering and smoothing in nonlinear and Non-Gaussian systems using conditional moments. _IEEE Signal Process. Lett._, 25(3):408-412, 2018. URL [https://acris.aalto.fi/ws/portalfiles/portal/17669270/cm_parapub.pdf](https://acris.aalto.fi/ws/portalfiles/portal/17669270/cm_parapub.pdf).
* Yao et al. (2021) Zhewei Yao, Amir Gholami, Sheng Shen, Mustafa Mustafa, Kurt Keutzer, and Michael W Mahoney. ADAHESSIAN: An adaptive second order optimizer for machine learning. In _AAAI_, 2021. URL [http://arxiv.org/abs/2006.00719](http://arxiv.org/abs/2006.00719).
* Zellner (1988) Arnold Zellner. Optimal information processing and bayes's theorem. _The American Statistician_, 42(4):278-280, 1988.
* Zhang et al. (2024) Wenxuan Zhang, Youssef Mohamed, Bernard Ghanem, Philip Torr, Adel Bibi, and Mohamed Elhoseiny. Continual learning on a diet: Learning from sparsely labeled streams under constrained computation. In _ICLR_, 2024. URL [https://openreview.net/pdf?id=Xvfz8NHmCj](https://openreview.net/pdf?id=Xvfz8NHmCj).

Abstract pseudocode

Algorithms 1 to 7 give pseudocode for applying the methods we study. For the predict step, we assume the dynamics model has the form \(\mathbf{\theta}_{t}\sim\mathcal{N}(\mathbf{F}_{t}\mathbf{\theta}_{t-1}+\mathbf{b}_{t}, \mathbf{Q}_{t})\). The update step in Algorithm 3 calls one of four grad functions (Algorithms 4 to 7) that estimate the expected gradient and Hessian using either MC or linearization combined with either the direct Hessian (or Jacobian and observation covariance) or EF. The update step also calls an inner step function that implements bong, blr, bog or bbb on some variational family corresponding to the encoding of \(\mathbf{\psi}\) (not shown). In practice the grad-fn and inner-step-fn are not as cleanly separated because the full matrix \(\tilde{\mathbf{G}}_{t,i}\) is not passed between them except when the variational family is FC. When the family is diagonal, grad-fn only needs to return \(\mathrm{diag}(\tilde{\mathbf{G}}_{t,i})\). When grad-fn uses EF, it only needs to return \(\tilde{\mathbf{G}}_{t,i}^{(1:M)}\) (grad-mc-ef) or \(\mathbf{g}_{t,i}^{\textsc{lin}}\) (grad-lin-ef) and inner-step-fn will implicitly use the outer product of this output as \(\tilde{\mathbf{G}}_{t,1}\). Finally, note the expressions for \(\mathbf{g}_{t,i}^{\textsc{lin}}\) in Algorithms 6 and 7 are equivalent ways of computing the same quantity, as explained after Eq. (28).

```
for\(t=1:\infty\)do \(\mathbf{\psi}_{t|t-1}=\text{predict}(\mathbf{\psi}_{t-1})\) \(\mathbf{\psi}_{t}=\text{update}(\mathbf{\psi}_{t|t-1},\mathbf{x}_{t},\mathbf{y}_{t})\)  end for
```

**Algorithm 1**Main loop.

```
def\(\text{predict}(\mathbf{\psi}_{t-1}=(\mathbf{\mu}_{t-1},\mathbf{\Sigma}_{t-1}))\): \(\mathbf{\mu}_{t|t-1}=\mathbf{F}_{t}\mathbf{\mu}_{t-1}+\mathbf{b}_{t}\) \(\mathbf{\Sigma}_{t|t-1}=\mathbf{F}_{t}\mathbf{\Sigma}_{t-1}\mathbf{F}_{t}^{\top}+ \mathbf{Q}_{t}\)  Return \(\mathbf{\psi}_{t|t-1}=(\mathbf{\mu}_{t|t-1},\mathbf{\Sigma}_{t|t-1})\)
```

**Algorithm 2**Predict step.

## Appendix B Additional experiment results

In this section, we give a more thorough set of experimental results.

### Running time measures

The running times of the methods for the experiments in Figs. 1 and 2, where we fit a CNN to MNIST, are shown in Fig. 3.

The running times of the methods for the FC and DLR case, where we fit an MLP to a synthetic regression dataset, are shown in Fig. 4. The slower speed of blr (even with \(I=1\)) relative to bong is at least partly attributable to the fact that blr must compute the SVD of a larger matrix (see Appendices E.5.3 and E.5.4).

[MISSING_PAGE_EMPTY:15]

### Detailed results for CNN on MNIST

Here we report further metrics for the experiments in Figs. 1 and 2. We show 3 approximations to the NLPD: plugin, MC, and Linearized MC.4 For each of these approximations to the posterior predictive, we also measure the corresponding misclassification rate based on picking the most probable predicted class. Results are shown in Figs. 5 and 6. We see that the plugin and lin-MC approximations are similar, and both are generally much better than standard MC.

Footnote 4: Lin-MC is defined in Footnote 2. The motivation for this approximation (from Immer et al. [2021]) is the following: If we push posterior samples through a nonlinear predictive model, the results can be poor if the samples are far from the mean, but if we linearize the predictive model, extrapolations away from the mean are more sensible. This is true even if the posterior was not explicitly computed using a linear approximation.

Finally, in Fig. 7 and Fig. 8, we report the test-set expected calibration error (ECE) at time steps [250, 500, 1,000, 2,000], computed using \(20\) bins. Note that among the lin-hess variants, bong-dlr-10

Figure 4: Running time (seconds) vs number of parameters \(P\) (size of state space) on a synthetic regression problem. For bbb and blr, we show results using \(I=1\) and \(I=10\) iterations per step. Hessian approximations are denoted as follows: EF0-Lin0 = MC-Hess, EF1-Lin0 = EF-Hess, EF0-Lin1 = Lin-Hess. (a) Full Covariance representation. (b) DLR representation. The BLR plot is truncated due to out of memory problem.

Figure 3: Runtimes for methods on MNIST. Left: Corresponding to Fig. 1 using different algorithms on dlr-10 family. Right: Corresponding to Fig. 2, using bong on different variational families.

method is the most well-calibrated (in addition to exhibiting the strongest plugin and linearized-MC NLPD results), when compared to other dlr-10 methods as well as other bong variants.

Figure 5: MNIST results for methods using DLR family. Left column shows misclassification rate, right column shows NLL. First row uses plugin approximation to the posterior predictive, second row uses linearized MC approximation, and third row uses standard MC approximation.

Figure 6: MNIST results for bong variants. Left column shows misclassification rate, right column shows NLL. First row uses plugin approximation to the posterior predictive, second row uses linearized MC approximation, and third row uses standard MC approximation.

### sarcos dataset

In addition to mnist, we report experiments on the sarcos regression dataset (\(D=22\), \(N_{\text{train}}=44\),\(484\), \(N_{\text{test}}=4449\), \(C=1\)). This dataset derives from an inverse dynamics problem for a seven degrees-of-freedom SARCOS anthropomorphic robot arm. The task is to map from a 21-dimensional input space (7 joint positions, 7 joint velocities, 7 joint accelerations) to the corresponding 7 joint torques. Following Rasmussen and Williams (2006), we pick a single target output dimension, so \(C=1\). The data is from [https://gaussianprocess.org/gpml/data/](https://gaussianprocess.org/gpml/data/).

We use a small MLP of size 21-20-20-1, so there are \(P=881\) parameters. For optimizing learning rates for sarcos, we use grid search on NLPD-PI. We fix the variance of the prior belief state

Figure 8: MNIST expected calibration error (ECE) results at selected timesteps for bong variants. We see that bong and bog are both well calibrated, as least when combined with lin-hess, with bong have a slight edge, especially for small sample sizes, where there is more posterior uncertainty.

Figure 7: MNIST expected calibration error (ECE) results at selected timesteps for methods using DLR family.

to \(\sigma_{0}^{2}=1.0\), which represents a mild degree of regularization.5 We fix the observation variance to \(R_{t}=0.1\hat{R}\), where \(\hat{R}=\text{Var}(y_{1:T})\) is the maximum likelihood estimate based on the training sequence; we can think of this as a simple empirical Bayes approximation, and the factor of 0.1 accounts for the fact that the variance of the residuals from the learned model will be smaller than from the unconditional baseline. We focus on DLR approximation of rank 10. This gives similar results to full covariance, but is much faster to compute. We also focus on the plugin approximation to NLPD, since the MC approximation gives much worse results (not shown).

Footnote 5: This value was based on a small amount of trial and error. Using a smaller value of \(\sigma_{0}\) results in underfitting relative to a linear least squares baseline, and using a much larger value results in unstable posterior covariances, causing the NLPD-MC samples to result in NaNs after a few hundred steps.

#### b.3.1 Comparison of bong, blr, bbb and bog

In Fig. 9 we show the results of using the lin-hess approximation. For 1 iteration per step, we see that bong and blr are indistinguishable in performance, and bbb and bog are also indistinguishable, but much worse. For 10 iterations per step, we see that bbb improves significantly, and approaches bong and blr. However, blr and bbb are now about 10 times slower. (In practice, the slowdown is less than 10, due to constant factors of the implementation.) (Note that bong and bog always use a single iteration, so their performance does not change.)

In Fig. 10 we show the results of using the mc-ef approximation with \(\text{mc}=100\) samples. The trends are similar to the lin-hess case. In particular, for \(I=1\), bong and blr are similar, with bong having a slight edge; and for \(I=10\), bbb catches up with both bong and blr, with bog always in last place. Finally, we see that the performance of mc-ef is slightly worse than lin-hess when \(I=1\), but catches up with \(I=10\). However, in larger scale experiments, we usually find that lin-hess is significantly better than mc-ef, even with \(I=10\).

#### b.3.2 Learning rate sensitivity

In Fig. 11 we show the test set performance for blr (with lin-hess approximation) for 5 different learning rates (namely \(5\times 10^{-3}\), \(1\times 10^{-2}\), \(5\times 10^{-2}\), \(1\times 10^{-1}\), and \(5\times 10^{-1}\)).

When using 1 iteration per step, the best learning rate is \(\alpha=0.5\), which is also the value chosen based on validation set performance. With this value, blr matches bong. For other learning rates, blr performance is much worse. When using 10 iterations per step, there are several learning rates all of which give performance as good as bong.

Figure 9: Predictive performance on sarcos using MLP 21-20-20-1 with DLR rank 10. Error bars represent \(\pm 1\) standard deviation computed from 3 random trials, randomizing over data order and initial state \(\mathbf{\mu}_{0}\). (a) We show all 4 algorithms combined with lin-hess approximation and \(I=1\). (b) Same as (a) but with \(I=10\).

In Fig. 12, we show the analogous plot for bbb. When using 1 iteration per step, all learning rates result in poor performance, with many resulting in NaNs. When using 10 iterations per step, there are some learning rates that enable bbb to get close to (but still not match) the performance of bong.

Figure 11: Same setup as Fig. 9, except now we plot performance for blr for 5 different learning rates. We also show bong as a baseline, which uses a fixed learning rate step size of 1.0.

Figure 12: Same setup as Fig. 9, except now we plot performance for bbb for 5 different learning rates. We also show bong as a baseline.

Figure 10: Same as Fig. 9 except we use MC-EF approximation with \(\text{MC}=100\).

Finally, in Fig. 12(a), we show the analogous plot for bog with lin-hess, and in Fig. 12(b) with mc-ef, where results are much worse.

Overall we conclude that all the methods (except bong) are quite sensitive to the learning rate. In our experiments, we pick a value based on performance on a validation set, but in the truly online setting, where there is just a single data stream, picking an optimal learning rate is difficult, which is an additional advantage of bong.

## Appendix C Proof of Propositions 4.1 and 4.2

**Proposition 4.1**.: To ease notation we write the natural parameters of the prior as \(\mathbf{\psi}_{t|t-1}=[\mathbf{\chi}_{t|t-1};\nu_{t|t-1}]\), which can be interpreted as the prior sufficient statistics and prior sample size. Note that \(\mathbf{x}_{t}\) can be omitted as a constant. Based on the prior \(q_{\mathbf{\psi}_{t|t-1}}(\mathbf{\theta}_{t})\) the exact posterior is

\[p(\mathbf{\theta}_{t}|\mathcal{D}_{t}) \propto q_{\mathbf{\psi}_{t|t-1}}(\mathbf{\theta}_{t})\,p_{t}(\mathbf{y}_{t} |\mathbf{\theta}_{t}) \tag{35}\] \[\propto\exp\left(\mathbf{\chi}_{t|t-1}^{\mathsf{T}}\mathbf{\theta}_{t}- \nu_{t|t-1}A(\mathbf{\theta}_{t})\right)\exp\left(\mathbf{\theta}_{t}^{\mathsf{T}}\mathbf{ y}_{t}-A(\mathbf{\theta}_{t})\right)\] (36) \[\propto q_{\mathbf{\psi}_{t}}(\mathbf{\theta}_{t})\] (37) \[\mathbf{\psi}_{t} =\left[\begin{array}{c}\mathbf{\chi}_{t|t-1}+\mathbf{y}_{t}\\ \nu_{t|t-1}+1\end{array}\right] \tag{38}\]

For bong, we first note the dual parameter is given by

\[\mathbf{\rho}_{t|t-1} =\mathbb{E}_{\mathbf{\theta}_{t}\sim q_{\mathbf{\psi}_{t|t-1}}}[T(\mathbf{ \theta}_{t})] \tag{39}\] \[=\mathbb{E}_{\mathbf{\theta}_{t}\sim q_{\mathbf{\psi}_{t|t-1}}}\left[ \begin{array}{c}\mathbf{\theta}_{t}\\ -A(\mathbf{\theta}_{t})\end{array}\right] \tag{40}\]

Therefore the natural gradient in Eq. (5) is

\[\nabla_{\mathbf{\rho}_{t|t-1}}\mathbb{E}_{\mathbf{\theta}_{t}\sim q_{\mathbf{ \psi}_{t|t-1}}}[\log p\left(\mathbf{y}_{t}|\mathbf{\theta}_{t}\right)] =\nabla_{\mathbf{\rho}_{t|t-1}}\mathbb{E}_{\mathbf{\theta}_{t}\sim q_{\bm {\psi}_{t|t-1}}}\left[\mathbf{\theta}_{t}^{\mathsf{T}}\mathbf{y}_{t}-A\left(\mathbf{\theta }_{t}\right)\right] \tag{41}\] \[=\nabla_{\mathbf{\rho}_{t|t-1}}\mathbf{\rho}_{t|t-1}^{\mathsf{T}}\left[ \begin{array}{c}\mathbf{y}_{t}\\ 1\end{array}\right]\] (42) \[=\left[\begin{array}{c}\mathbf{y}_{t}\\ 1\end{array}\right] \tag{43}\]

Therefore the bong update yields \(\mathbf{\psi}_{t}=[\mathbf{\chi}_{t|t-1}+\mathbf{y}_{t};\nu_{t|t-1}+1]\) in agreement with Eq. (38). 

**Proposition 4.2**.: The intuition behind this proof is as follows. For the mean update in Eq. (9) \(\nabla_{\mathbf{\theta}_{t}}\ell_{t}\) is linear in \(\mathbf{\theta}_{t}\) so the expectation equals the value at the mean. For the covariance update in Eq. (10)

Figure 13: We plot performance for bog for 5 different learning rates. We also show bong as a baseline. (a) lin-hess approximation. (b) mc-ef approximation.

\(\nabla^{2}_{\mathbf{\theta}_{t}}\ell_{t}\) is independent of \(\mathbf{\theta}_{t}\) so we can drop the expectation operator. The tricky part is why we need different linearizations for the Hessians to agree. It has to do with making the Hessian of the NN disappear (as in GGN). In the Gaussian approximation this happens when the predicted mean (\(\hat{\mathbf{y}}_{t}=f_{t}(\mathbf{\theta}_{t})\)) is linear in \(\mathbf{\theta}_{t}\). In the plugin approximation it happens when the outcome-dependent part of the loglikelihood (\(h_{t}(\mathbf{\theta}_{t})^{\intercal}\mathbf{y}_{t}\)) is linear in \(\mathbf{\theta}_{t}\). In the latter case the only nonlinear term remaining in the log-likelihood is the log-partition \(A\), and the two methods end up agreeing because of the property that the Hessian of the log-partition equals the conditional variance \(\mathbf{R}_{t}\).

Formally, under the linear(\(h\))-Gaussian approximation in Eqs. (14) and (17) the expected gradient and Hessian can be calculated directly:

\[\mathbb{E}_{\mathbf{\theta}_{t}\sim q_{\mathbf{\psi}_{t|t-1}}}\left[\nabla _{\mathbf{\theta}_{t}}\log\bar{p}_{t}^{\mathrm{LG}}(\mathbf{y}_{t}|\mathbf{\theta}_{t})\right] =\mathbb{E}_{\mathbf{\theta}_{t}\sim q_{\mathbf{\psi}_{t|t-1}}}\left[ \mathbf{H}_{t}^{\intercal}\mathbf{R}_{t}^{-1}(\mathbf{y}_{t}-\hat{\mathbf{y}}_{t}- \mathbf{H}_{t}(\mathbf{\theta}_{t}-\mathbf{\mu}_{t|t-1})\right] \tag{44}\] \[=\mathbf{H}_{t}^{\intercal}\mathbf{R}_{t}^{-1}(\mathbf{y}_{t}-\hat{ \mathbf{y}}_{t})\] (45) \[=\mathbf{E}_{\mathbf{\theta}_{t}\sim q_{\mathbf{\psi}_{t|t-1}}}\left[- \mathbf{H}_{t}^{\intercal}\mathbf{R}_{t}^{-1}\mathbf{H}_{t}\right]\] (46) \[=-\mathbf{H}_{t}^{\intercal}\mathbf{R}_{t}^{-1}\mathbf{H}_{t} \tag{47}\]

For the linear(\(f\))-delta approximation we use the properties of exponential families that (1) the gradient of the log-partition \(A\) with respect to the natural parameter \(f_{t}(\mathbf{\theta}_{t})\) equals the expectation parameter \(h_{t}(\mathbf{\theta}_{t})\), (2) the Hessian of the log-partition with respect to the natural parameter equals the conditional variance, and consequently (3) the Jacobian of the expectation parameter with respect to the natural parameter equals the conditional variance \(\mathbf{R}_{t}\):

\[\nabla_{\mathbf{\eta}=f_{t}(\mathbf{\mu}_{t|t-1})}A(\mathbf{\eta}) =h_{t}(\mathbf{\mu}_{t|t-1})=\hat{\mathbf{y}} \tag{48}\] \[\nabla^{2}_{\mathbf{\eta}=f_{t}(\mathbf{\mu}_{t|t-1})}A(\mathbf{\eta}) =\mathbb{V}\left[\mathbf{y}_{t}|\mathbf{\theta}_{t}=\mathbf{\mu}_{t|t-1} \right]=\mathbf{R}_{t}\] (49) \[\frac{\partial h_{t}(\mathbf{\theta}_{t})}{\partial f_{t}(\mathbf{\theta} _{t})\left|\mathbf{\theta}_{t}=\mathbf{\mu}_{t|t-1}\right.} =\mathbf{R}_{t} \tag{50}\]

The last of these implies \(\mathbf{F}_{t}=\mathbf{R}_{t}^{-1}\mathbf{H}_{t}\). Therefore the expected gradient and Hessian can be calculated as

\[\mathbb{E}_{\mathbf{\theta}_{t}\sim\delta_{\mathbf{\mu}_{t|t-1}}}\left[ \nabla_{\mathbf{\theta}_{t}}\log\bar{p}_{t}^{\mathrm{LD}}(\mathbf{y}_{t}|\mathbf{\theta}_ {t})\right] =\nabla_{\mathbf{\theta}_{t}=\mathbf{\mu}_{t|t-1}}\log\bar{p}_{t}^{ \mathrm{LD}}(\mathbf{y}_{t}|\mathbf{\theta}_{t}) \tag{51}\] \[=\mathbf{F}_{t}^{\intercal}\mathbf{y}_{t}-\mathbf{F}_{t}^{\intercal} \nabla_{\mathbf{\eta}=f_{t}(\mathbf{\mu}_{t|t-1})}A(\mathbf{\eta})\] (52) \[=\mathbf{F}_{t}^{\intercal}(\mathbf{y}_{t}-\hat{\mathbf{y}}_{t})\] (53) \[=\mathbf{H}_{t}^{\intercal}\mathbf{R}_{t}^{-1}(\mathbf{y}_{t}-\hat{ \mathbf{y}}_{t})\] (54) \[\mathbb{E}_{\mathbf{\theta}_{t}\sim\delta_{\mathbf{\mu}_{t|t-1}}}\left[ \nabla^{2}_{\mathbf{\theta}_{t}}\log\bar{p}_{t}^{\mathrm{LD}}(\mathbf{y}_{t}|\mathbf{\theta }_{t})\right] =\nabla^{2}_{\mathbf{\theta}_{t}=\mathbf{\mu}_{t|t-1}}\log\bar{p}_{t}^{ \mathrm{LD}}(\mathbf{y}_{t}|\mathbf{\theta}_{t})\] (55) \[=-\mathbf{F}_{t}^{\intercal}\left(\nabla^{2}_{\mathbf{\eta}=f_{t}( \mathbf{\mu}_{t|t-1})}A(\mathbf{\eta})\right)\mathbf{F}_{t}\] (56) \[=-\mathbf{F}_{t}^{\intercal}\mathbf{R}_{t}\mathbf{F}_{t}\] (57) \[=-\mathbf{H}_{t}^{\intercal}\mathbf{R}_{t}^{-1}\mathbf{H}_{t} \tag{58}\]

## Appendix D Mirror descent formulation

In this section we give a more detailed derivation of bong as mirror descent and use this to give two alternative interpretations of how bong approximates exact VB: (1) by approximating the expected NLL as linear in the expectation parameter \(\mathbf{\rho}\), or (2) by replacing an implicit update with an explicit one.

Assume the variational family is an exponential one as introduced at the end of Section 3, with natural and dual parameters \(\mathbf{\psi}\) and \(\mathbf{\rho}\), sufficient statistics \(T(\mathbf{\theta})\), and log-partition \(\Phi(\mathbf{\psi})\):

\[q_{\mathbf{\psi}}(\mathbf{\theta}) =\exp\left(\mathbf{\psi}^{\intercal}T(\mathbf{\theta})-\Phi(\mathbf{\psi})\right) \tag{59}\] \[\mathbf{\rho} =\mathbb{E}_{\mathbf{\theta}\sim q_{\mathbf{\psi}}}[T(\mathbf{\theta})] \tag{60}\]We first review how NGD on an exponential family is a special case of mirror descent (Khan and Rue, 2023; Martens, 2020). The mirror map is the gradient of the log-partition, which satisfies the thermodynamic identity

\[\mathbf{\rho}=\nabla\Phi(\mathbf{\psi}) \tag{61}\]

This is a bijection when \(\Phi\) is convex (which includes the cases we study), so we can implicitly treat \(\mathbf{\psi}\) and \(\mathbf{\rho}\) as functions of each other. Given a loss function \(L(\mathbf{\psi})\), MD iteratively solves the local optimization problem

\[\mathbf{\psi}_{i+1}=\operatorname*{arg\,min}_{\mathbf{\psi}}\left\langle\nabla_{\mathbf{ \rho}_{i}}L(\mathbf{\psi}_{i}),\mathbf{\rho}\right\rangle+\frac{1}{\alpha}\mathbb{D}_{ \Phi}(\mathbf{\psi}_{i},\mathbf{\psi}) \tag{62}\]

The first term is a linear (in \(\mathbf{\rho}\)) approximation of \(L\) about the previous iteration \(\mathbf{\psi}_{i}\) and the second term is the Bregman divergence

\[\mathbb{D}_{\Phi}(\mathbf{\psi}_{i},\mathbf{\psi}_{i+1})=\Phi(\mathbf{\psi}_{i})-\Phi(\bm {\psi}_{i+1})-(\mathbf{\psi}_{i}-\mathbf{\psi}_{i+1})^{\mathsf{T}}\,\mathbf{\rho}_{i+1} \tag{63}\]

The Bregman divergence acts as a regularizer toward \(\mathbf{\psi}_{i}\) and captures the intrinsic geometry of the parameter space because of its equivalence with the (reverse) KL divergence

\[D_{\mathbb{KL}}\big{(}q_{\mathbf{\psi}_{i+1}}|q_{\mathbf{\psi}_{i}}\big{)} =\mathbb{E}_{\mathbf{\theta}\sim q_{\mathbf{\psi}_{i+1}}}[(\mathbf{\psi}_{i+1 }-\mathbf{\psi}_{i})^{\mathsf{T}}\,T(\mathbf{\theta})+\Phi(\mathbf{\psi}_{i})-\Phi(\mathbf{ \psi}_{i+1})] \tag{64}\] \[=\mathbb{D}_{\Phi}(\mathbf{\psi}_{i},\mathbf{\psi}_{i+1}) \tag{65}\]

Importantly, this recursive regularizer is not part of the loss and serves only to define an iterated algorithm that converges to a local minimum of \(L\). Solving Eq. (62) by differentiating by \(\mathbf{\rho}\) yields the MD update

\[\mathbf{\psi}_{i+1}=\mathbf{\psi}_{i}-\alpha\nabla_{\mathbf{\rho}_{i}}L(\mathbf{\psi}_{i}) \tag{66}\]

Because the Fisher matrix for an exponential family is \(\mathbf{F}_{\mathbf{\psi}}=\partial\mathbf{\rho}/\partial\mathbf{\psi}\), this is equivalent to NGD with respect to \(\mathbf{\psi}\). Khan and Rue (2023) offer this as a derivation of the BLR, when \(L(\mathbf{\psi})\) is taken to be the variational loss from Eq. (1).

By applying this analysis to the online setting, our approach can be seen to follow from two insights. First, the online variational loss in Eq. (2) already includes KL divergence from the previous step, so we do not need the artificial regularizer in Eq. (62). That is, if we start from the online variational problem in Eq. (4) and define \(L_{t}(\mathbf{\psi})\) as the expected NLL,

\[L_{t}(\mathbf{\psi})=-\mathbb{E}_{\mathbf{\theta}_{t}\sim q_{\mathbf{\psi}}}[\log p(\mathbf{y} _{t}|f_{t}(\mathbf{\theta}_{t}))] \tag{67}\]

then replacing \(L_{t}(\mathbf{\psi})\) with a linear approximation based at \(\mathbf{\psi}_{t|t-1}\) and applying Eq. (65) leads to

\[\mathbf{\psi}_{t}=\operatorname*{arg\,min}_{\mathbf{\psi}}\left\langle\nabla_{\mathbf{ \rho}_{t|t-1}}L_{t}(\mathbf{\psi}_{t|t-1}),\mathbf{\rho}\right\rangle+\mathbb{D}_{\Phi }(\mathbf{\psi}_{t|t-1},\mathbf{\psi}) \tag{68}\]

By comparing to Eq. (62) we see this defines an MD algorithm with unit learning rate that works in a single step rather than by iterating. Paralleling the derivation of Eq. (66) from Eq. (62) we get

\[\mathbf{\psi}_{t}=\mathbf{\psi}_{t|t-1}-\nabla_{\mathbf{\rho}_{t|t-1}}L_{t}(\mathbf{\psi}_{t|t -1}) \tag{69}\]

which matches the bong update in Eq. (5). Thus bong can be seen as an approximate solution of the online variational problem in Eq. (4) based on linearizing the expected NLL wrt \(\mathbf{\rho}\). (Note this is different from the assumption underlying bong-lin that \(f_{t}(\mathbf{\theta}_{t})\) or \(h_{t}(\mathbf{\theta}_{t})\) is linear in \(\mathbf{\theta}_{t}\).)

Second, in the conjugate case, this linearity assumption is true: \(L_{t}\) is linear in \(\mathbf{\rho}\) (see proof of Proposition 4.1). Therefore 68 is equivalent to solving Eq. (4) exactly:

\[\mathbf{\psi}_{t}=\operatorname*{arg\,min}_{\mathbf{\psi}}L_{t}(\mathbf{\psi})+\mathbb{D}_ {\Phi}(\mathbf{\psi}_{t|t-1},\mathbf{\psi}) \tag{70}\]

This recapitulates Proposition 4.1 that bong is Bayes optimal in the conjugate case. In general the exact solution to Eq. (70) is

\[\mathbf{\psi}_{t}=\mathbf{\psi}_{t|t-1}-\nabla_{\mathbf{\rho}_{t}}L_{t}(\mathbf{\psi}_{t}) \tag{71}\]

This is an implicit update because the gradient is evaluated at the (unknown) posterior, whereas Eq. (69) is an explicit update because it evaluates the gradient at the prior. (In the Gaussian case these can be shown to match the implicit and explicit RVGA updates of (Lambert et al., 2021).) Therefore bong can be also interpreted as an approximation of exact VB that replaces the implicit update, Eq. (71), with an explicit update, Eq. (69).

Derivations

This section derives the update equations for all 80 algorithms we investigate (Table 3 plus the mc-hess and lin-ef variants). In Appendix E.6 we also translate the blr algorithms from our online setting back to the batch setting used in Khan and Rue (2023).

For an exponential variational family with natural parameters \(\mathbf{\psi}\) and dual parameters \(\mathbf{\rho}\), we can derive all 16 methods (bong, blr, bog, bbb under all four Hessian approximations) from four quantities:

\[\nabla_{\mathbf{\rho}_{t,i-1}}\mathbb{E}_{\mathbf{\theta}_{t}\sim q_{\mathbf{ \psi}_{t,i-1}}}[\log p\left(\mathbf{y}_{t}|f_{t}\left(\mathbf{\theta}_{t}\right)\right)] \tag{72}\] \[\nabla_{\mathbf{\rho}_{t,i-1}}D_{\mathbb{KL}}\left(q_{\mathbf{\psi}_{t,i- 1}}|q_{\mathbf{\psi}_{t|i-1}}\right)\] (73) \[\nabla_{\mathbf{\psi}_{t,i-1}}\mathbb{E}_{\mathbf{\theta}_{t}\sim q_{\mathbf{ \psi}_{t,i-1}}}[\log p\left(\mathbf{y}_{t}|f_{t}\left(\mathbf{\theta}_{t}\right)\right)]\] (74) \[\nabla_{\mathbf{\psi}_{t,i-1}}D_{\mathbb{KL}}\left(q_{\mathbf{\psi}_{t,i- 1}}|q_{\mathbf{\psi}_{t|i-1}}\right) \tag{75}\]

The NGD methods (bong and blr) use gradients with respect to \(\mathbf{\rho}_{t,t-i}\) while the GD methods (bog and bbb) use gradients with respect to \(\mathbf{\psi}_{t,i-1}\). For bong and bog the \(D_{\mathbb{KL}}\) term is not relevant, and there is no inner loop so \(\mathbf{\psi}_{t,i-1}=\mathbf{\psi}_{t|t-1}\) and \(\mathbf{g}_{t,i}=\mathbf{g}_{t}\), \(\mathbf{G}_{t,i}=\mathbf{G}_{t}\).

When \(\mathbf{\psi}\) is not the natural parameter of an exponential family we must explicitly compute the inverse-Fisher preconditioner for the NGD methods. Therefore the updates can be derived from these three quantities:

\[\mathbf{F}_{\mathbf{\psi}_{t,i-1}} \tag{76}\] \[\nabla_{\mathbf{\psi}_{t,i-1}}\mathbb{E}_{\mathbf{\theta}_{t}\sim q_{\mathbf{ \psi}_{t,i-1}}}[\log p\left(\mathbf{y}_{t}|f_{t}\left(\mathbf{\theta}_{t}\right)\right)]\] (77) \[\nabla_{\mathbf{\psi}_{t,i-1}}D_{\mathbb{KL}}\left(q_{\mathbf{\psi}_{t,i- 1}}|q_{\mathbf{\psi}_{t|i-1}}\right) \tag{78}\]

We will frequently use Bonnet's and Price's theorems (Bonnet, 1964; Price, 1958)

\[\nabla_{\mathbf{\mu}_{t,i-1}}\mathbb{E}_{\mathcal{N}\left(\mathbf{\mu}_{ t,i-1},\mathbf{\Sigma}_{t,i-1}\right)}[\log p\left(\mathbf{y}_{t}|f_{t}\left(\mathbf{ \theta}_{t}\right)\right)] =\mathbb{E}_{\mathcal{N}\left(\mathbf{\mu}_{t,i-1},\mathbf{\Sigma}_{t,i- 1}\right)}[\nabla_{\mathbf{\theta}_{t}}\log p\left(\mathbf{y}_{t}|f_{t}\left(\mathbf{ \theta}_{t}\right)\right)] \tag{79}\] \[=\mathbf{g}_{t,i}\] (80) \[\nabla_{\mathbf{\Sigma}_{t,i-1}}\mathbb{E}_{\mathcal{N}\left(\mathbf{\mu} _{t,i-1},\mathbf{\Sigma}_{t,i-1}\right)}[\log p\left(\mathbf{y}_{t}|f_{t}\left(\mathbf{ \theta}_{t}\right)\right)] =\tfrac{1}{2}\mathbb{E}_{\mathcal{N}\left(\mathbf{\mu}_{t,i-1},\mathbf{ \Sigma}_{t,i-1}\right)}\big{[}\nabla_{\mathbf{\theta}_{t}}^{2}\log p\left(\mathbf{y}_{ t}|f_{t}\left(\mathbf{\theta}_{t}\right)\right)\big{]}\] (81) \[=\tfrac{1}{2}\mathbf{G}_{t,i} \tag{82}\]

For diagonal Gaussians with covariance \(\mathrm{Diag}\left(\mathbf{\sigma}^{2}\right)\), Price's theorem also implies6

Footnote 6: We use \(\mathrm{diag}(\mathbf{A})\) to denote the vector of diagonal elements of matrix \(\mathbf{A}\) and \(\mathrm{Diag}(\mathbf{v})\) to denote the matrix whose diagonal entries are \(\mathbf{v}\) and off-diagonal entries are \(0\).

\[\nabla_{\mathbf{\sigma}^{2}_{t,i-1}}\mathbb{E}_{\mathbf{\theta}_{t}\sim \mathcal{N}\left(\mathbf{\mu}_{t,i-1},\mathbf{\Sigma}_{t,i-1}\right)}[\log p\left(\mathbf{ y}_{t}|f_{t}\left(\mathbf{\theta}_{t}\right)\right)]=\tfrac{1}{2}\mathrm{diag}\left( \mathbf{G}_{t,i}\right) \tag{83}\]

Update equations for mc-hess, mc-ef and lin-ef methods are displayed together in the subsections that follow, because for the most part they differ only in the choice of \(\mathbf{G}_{t}^{\textsc{mc-frees}}\), \(\mathbf{G}_{t}^{\textsc{mc-ef}}\) or \(\mathbf{G}_{t}^{\textsc{lin-ef}}\) to approximate \(\mathbf{G}_{t}\) and \(\mathbf{g}_{t}^{\textsc{mc}}\) or \(\mathbf{g}_{t}^{\textsc{lin}}\) to approximate \(\mathbf{g}_{t}\). We note cases where decomposing \(\mathbf{G}_{t}^{\textsc{mc-ef}}=-\frac{1}{M}\hat{\mathbf{G}}_{t}^{\textsc{ 1}:M}\hat{\mathbf{G}}_{t}^{\textsc{1}:M})^{\intercal}\) or \(\mathbf{G}_{t}^{\textsc{lin-ef}}=-\mathbf{g}_{t}^{\textsc{lin}}\left(\mathbf{g}_{t}^{ \textsc{lin}}\right)^{\intercal}\) allows a more efficient update.

We derive updates for bong-lin-hess and bog-lin-hess from the corresponding bong-mc-hess and bog-mc-hess updates using Proposition 4.2 which entails substituting

\[\mathbf{g}_{t} \rightarrow\mathbf{H}_{t}^{\intercal}\mathbf{R}_{t}^{-1}(\mathbf{y}_{t }-\hat{\mathbf{y}}_{t}) \tag{84}\] \[\mathbf{G}_{t} \rightarrow-\mathbf{H}_{t}^{\intercal}\mathbf{R}_{t}^{-1}\mathbf{H }_{t} \tag{85}\]

For the algorithms with inner loops (blr and bbb) we adapt the notation of Section 4.4 as follows:

\[\mathbf{y}_{t,i} =h_{t}\left(\mathbf{\mu}_{t,i-1}\right) \tag{86}\] \[\mathbf{H}_{t,i} =\frac{\partial h_{t}}{\partial\mathbf{\theta}_{t}}_{|\mathbf{\theta}=\mathbf{ \mu}_{t,i-1}}\] (87) \[\mathbf{R}_{t,i} =\mathbb{V}\left[\mathbf{y}_{t}|\mathbf{\theta}_{t}=\mathbf{\mu}_{t,i-1}\right]\] (88) \[\mathbf{g}_{t,i} =\mathbf{H}_{t,i}^{\intercal}\mathbf{R}_{t,i}^{-1}\left(\mathbf{y}_{ t}-\hat{\mathbf{y}}_{t,i}\right)\] (89) \[\mathbf{G}_{t,i} =-\mathbf{H}_{t,i}^{\intercal}\mathbf{R}_{t,i}^{-1}\mathbf{H}_{t,i} \tag{90}\]This corresponds to basing the linear(\(f\))-Gaussian and linear(\(h\))-delta approximations at \(\mathbf{\mu}_{t,i-1}\) instead of \(\mathbf{\mu}_{t|t-1}\). Thus the updates for blr-lin-hess and bbb-lin-hess are obtained by substituting

\[\mathbf{g}_{t,i} \rightarrow\mathbf{H}_{t,i}^{\intercal}\mathbf{R}_{t,i}^{-1}(\mathbf{y }_{t}-\hat{\mathbf{y}}_{t,i}) \tag{91}\] \[\mathbf{G}_{t,i} \rightarrow-\mathbf{H}_{t,i}^{\intercal}\mathbf{R}_{t,i}^{-1} \mathbf{H}_{t,i} \tag{92}\]

### Full covariance Gaussian, natural parameters

The natural and dual parameters for a general Gaussian are given by

\[\mathbf{\psi}_{t,i-1}^{(1)} =\mathbf{\Sigma}_{t,i-1}^{-1}\mathbf{\mu}_{t,i-1} \mathbf{\rho}_{t,i-1}^{(1)} =\mathbf{\mu}_{t,i-1} \tag{93}\] \[\mathbf{\psi}_{t,i-1}^{(2)} =-\tfrac{1}{2}\mathbf{\Sigma}_{t,i-1}^{-1} \mathbf{\rho}_{t,i-1}^{(2)} =\mathbf{\mu}_{t,i-1}\mathbf{\mu}_{t,i-1}^{\intercal}+\mathbf{\Sigma}_{t,i-1} \tag{94}\]

Inverting these relationships gives

\[\mathbf{\mu}_{t,i-1} =-\tfrac{1}{2}\mathbf{\psi}_{t,i-1}^{(2)-1}\mathbf{\psi}_{t,i-1}^{(1)} =\mathbf{\rho}_{t,i-1}^{(1)}\] (95) \[\mathbf{\Sigma}_{t,i-1} =-\tfrac{1}{2}\mathbf{\psi}_{t,i-1}^{(2)-1} =\mathbf{\rho}_{t,i-1}^{(2)} -\mathbf{\rho}_{t,i-1}^{(1)}\mathbf{\rho}_{t,i-1}^{(1Therefore

\[\nabla_{\mathbf{\psi}_{t,i-1}^{(1)}}\mathbb{E}_{\mathbf{g}_{t}\sim q_{\mathbf{ \psi}_{t,i-1}}}[\log p\left(\mathbf{y}_{t}|f_{t}\left(\mathbf{\theta}_{t}\right)\right)] =\mathbf{\Sigma}_{t,i-1}\mathbf{g}_{t,i} \tag{114}\] \[\nabla_{\mathbf{\psi}_{t,i-1}^{(2)}}\mathbb{E}_{\mathbf{g}_{t}\sim q_{\bm {\psi}_{t,i-1}}}[\log p\left(\mathbf{y}_{t}|f_{t}\left(\mathbf{\theta}_{t}\right)\right)] =2\mathbf{\Sigma}_{t,i-1}\mathbf{g}_{t,i}\mathbf{\mu}_{t,i-1}^{\intercal}+\mathbf{ \Sigma}_{t,i-1}\mathbf{G}_{t,i}\mathbf{\Sigma}_{t,i-1} \tag{115}\]

and

\[\nabla_{\mathbf{\psi}_{t,i-1}^{(1)}}D_{\text{KL}}\big{(}q_{\mathbf{\psi}_ {t,i-1}}|q_{\mathbf{\psi}_{t|t-1}}\big{)} =\mathbf{\Sigma}_{t,i-1}\mathbf{\Sigma}_{t|t-1}^{-1}\left(\mathbf{\mu}_{t,i-1 }-\mathbf{\mu}_{t|t-1}\right) \tag{116}\] \[\nabla_{\mathbf{\psi}_{t,i-1}^{(2)}}D_{\text{KL}}\big{(}q_{\mathbf{\psi}_ {t,i-1}}|q_{\mathbf{\psi}_{t|t-1}}\big{)} =2\mathbf{\Sigma}_{t,i-1}\mathbf{\Sigma}_{t|t-1}^{-1}\left(\mathbf{\mu}_{t,i- 1}-\mathbf{\mu}_{t|t-1}\right)\mathbf{\mu}_{t,i-1}^{\intercal}\] \[\quad+\mathbf{\Sigma}_{t,i-1}\left(\mathbf{\Sigma}_{t|t-1}^{-1}-\mathbf{ \Sigma}_{t,i-1}^{-1}\right)\mathbf{\Sigma}_{t,i-1} \tag{117}\]

#### e.1.1 Bong FC (explicit rvga)

Substituting Eqs. (104) and (105) into Eq. (5) gives

\[\mathbf{\psi}_{t}^{(1)} =\mathbf{\psi}_{t|t-1}^{(1)}+\mathbf{g}_{t}-\mathbf{G}_{t}\mathbf{\mu}_{t|t-1} \tag{118}\] \[\mathbf{\psi}_{t}^{(2)} =\mathbf{\psi}_{t|t-1}^{(2)}+\tfrac{1}{2}\mathbf{G}_{t} \tag{119}\]

Translating to \((\mathbf{\mu}_{t},\mathbf{\Sigma}_{t})\) gives the bong-fc update

\[\mathbf{\mu}_{t} =\mathbf{\mu}_{t|t-1}+\mathbf{\Sigma}_{t}\mathbf{g}_{t} \tag{120}\] \[\mathbf{\Sigma}_{t}^{-1} =\mathbf{\Sigma}_{t|t-1}^{-1}-\mathbf{G}_{t} \tag{121}\]

This is equivalent to the explicit update form of RVGA (Lambert et al., 2021). Using \(\mathbf{G}_{t}^{\text{MC-HESS}}\) this update takes \(O(P^{3})\) because of the matrix inversion. Using \(\mathbf{G}_{t}^{\text{MC-EF}}\) and the Woodbury matrix identity we can write the update in a form that takes \(O(MP^{2}+M^{3})\):

\[\mathbf{\mu}_{t} =\mathbf{\mu}_{t|t-1}+\mathbf{K}_{t}\mathbf{I}_{M} \tag{122}\] \[\mathbf{\Sigma}_{t} =\mathbf{\Sigma}_{t|t-1}-\mathbf{K}_{t}\hat{\mathbf{G}}_{t}^{(1:M)^{ \intercal}}\mathbf{\Sigma}_{t|t-1}\] (123) \[\mathbf{K}_{t} =\mathbf{\Sigma}_{t|t-1}\hat{\mathbf{G}}_{t}^{(1:M)}\left(M\mathbf{I} _{M}+\hat{\mathbf{G}}_{t}^{(1:M)^{\intercal}}\mathbf{\Sigma}_{t|t-1}\hat{\mathbf{ G}}_{t}^{(1:M)}\right)^{-1} \tag{124}\]

Likewise using \(\mathbf{G}_{t}^{\text{LIN-EF}}\) takes \(O(P^{2})\):

\[\mathbf{\mu}_{t} =\mathbf{\mu}_{t|t-1}+\mathbf{K}_{t} \tag{125}\] \[\mathbf{\Sigma}_{t} =\mathbf{\Sigma}_{t|t-1}-\mathbf{K}_{t}\left(\mathbf{g}_{t}^{\text{LIN}} \right)^{\intercal}\mathbf{\Sigma}_{t|t-1}\] (126) \[\mathbf{K}_{t} =\frac{\mathbf{\Sigma}_{t|t-1}\mathbf{g}_{t}^{\text{LIN}}}{1+(\mathbf{g}_{t}^{ \text{LIN}})^{\intercal}\mathbf{\Sigma}_{t|t-1}\mathbf{g}_{t}^{\text{LIN}}} \tag{127}\]

#### e.1.2 Bong-lin-hess FC (cm-ekf)

Applying Proposition 4.2 to Eqs. (120) and (121) gives the bong-lin-hess-fc update

\[\mathbf{\mu}_{t} =\mathbf{\mu}_{t|t-1}+\mathbf{\Sigma}_{t}\mathbf{H}_{t}^{\intercal} \mathbf{R}_{t}^{-1}\left(\mathbf{y}_{t}-\mathbf{\hat{y}}_{t}\right) \tag{128}\] \[\mathbf{\Sigma}_{t}^{-1} =\mathbf{\Sigma}_{t|t-1}^{-1}+\mathbf{H}_{t}^{\intercal}\mathbf{R}_{t }^{-1}\mathbf{H}_{t} \tag{129}\]

This is equivalent to cm-ekf(Tronarp et al., 2018; Ollivier, 2018) and can be rewritten using the Woodbury identity in a form that takes \(O(CP^{2}+C^{3})\):

\[\mathbf{\mu}_{t} =\mathbf{\mu}_{t|t-1}+\mathbf{K}_{t}(\mathbf{y}_{t}-\mathbf{\hat{y}}_{t}) \tag{130}\] \[\mathbf{\Sigma}_{t} =\mathbf{\Sigma}_{t|t-1}-\mathbf{K}_{t}\mathbf{H}_{t}\mathbf{\Sigma}_{t|t -1}\] (131) \[\mathbf{K}_{t} =\mathbf{\Sigma}_{t|t-1}\mathbf{H}_{t}^{\intercal}\left(\mathbf{R}_{t }+\mathbf{H}_{t}\mathbf{\Sigma}_{t|t-1}\mathbf{H}_{t}^{\intercal}\right)^{-1} \tag{132}\]

#### e.1.3 Blr Fc

Substituting Eqs. (104) to (107) into Eq. (33) gives

\[\mathbf{\psi}_{t,i}^{(1)} =\mathbf{\psi}_{t,i-1}^{(1)}+\alpha\left(\mathbf{g}_{t,i}-\mathbf{G}_{t,i} \mathbf{\mu}_{t,i-1}-\mathbf{\Sigma}_{t,i-1}^{-1}\mathbf{\mu}_{t,i-1}+\mathbf{\Sigma}_{t|t-1}^{ -1}\mathbf{\mu}_{t|t-1}\right) \tag{133}\] \[\mathbf{\psi}_{t,i}^{(2)} =\mathbf{\psi}_{t,i-1}^{(2)}+\frac{\alpha}{2}\left(\mathbf{G}_{t,i}+ \mathbf{\Sigma}_{t,i-1}^{-1}-\mathbf{\Sigma}_{t|t-1}^{-1}\right) \tag{134}\]

Translating to \(\left(\mathbf{\mu}_{t,i},\mathbf{\Sigma}_{t,i}\right)\) gives the blr-fc update

\[\mathbf{\mu}_{t,i} =\mathbf{\mu}_{t,i-1}+\alpha\mathbf{\Sigma}_{t,i}\mathbf{\Sigma}_{t|t-1}^{-1} \left(\mathbf{\mu}_{t|t-1}-\mathbf{\mu}_{t,i-1}\right)+\alpha\mathbf{\Sigma}_{t,i}\mathbf{g}_{ t,i} \tag{135}\] \[\mathbf{\Sigma}_{t,i}^{-1} =\left(1-\alpha\right)\mathbf{\Sigma}_{t,i-1}^{-1}+\alpha\mathbf{\Sigma}_ {t|t-1}^{-1}-\alpha\mathbf{G}_{t,i} \tag{136}\]

This update takes \(O(P^{3})\) per iteration because of the matrix inversion. In Appendix E.1.1 we were able to use the Woodbury identity to exploit the low rank of \(\mathbf{G}_{t}^{\text{MC-EF}}\) and \(\mathbf{G}_{t}^{\text{LIN-EF}}\) and obtain bong updates with complexity quadratic in \(P\). This does not appear possible with Eq. (136) because of the extra precision term on the RHS (applying Woodbury would require inverting \((1-\alpha)\mathbf{\Sigma}_{t,i-1}^{-1}+\alpha\mathbf{\Sigma}_{t|t-1}^{-1}\)). Therefore unlike bong-fc, blr-fc requires time cubic in the model size, for reasons that can be traced back to the KL term in Eq. (33).

#### e.1.4 Blr-lin-hess Fc

Applying Proposition 4.2 to Eqs. (135) and (136) gives the blr-lin-hess-fc update

\[\mathbf{\mu}_{t,i} =\mathbf{\mu}_{t,i-1}+\alpha\mathbf{\Sigma}_{t,i}\mathbf{\Sigma}_{t|t-1}^{-1} \left(\mathbf{\mu}_{t|t-1}-\mathbf{\mu}_{t,i-1}\right)+\alpha\mathbf{\Sigma}_{t,i}\mathbf{ H}_{t,i}^{\intercal}\mathbf{R}_{t,i}^{-1}\left(\mathbf{y}_{t}-\hat{\mathbf{y}}_{t,i}\right) \tag{137}\] \[\mathbf{\Sigma}_{t,i}^{-1} =\left(1-\alpha\right)\mathbf{\Sigma}_{t,i-1}^{-1}+\alpha\mathbf{\Sigma}_ {t|t-1}^{-1}+\alpha\mathbf{H}_{t,i}^{\intercal}\mathbf{R}_{t,i}^{-1}\mathbf{H} _{t,i} \tag{138}\]

This update takes \(O(P^{3})\) per iteration because of the matrix inversion.

#### e.1.5 Bog Fc

Substituting Eqs. (114) and (115) into Eq. (31) gives

\[\mathbf{\psi}_{t}^{(1)} =\mathbf{\psi}_{t|t-1}^{(1)}+\alpha\mathbf{\Sigma}_{t|t-1}\mathbf{g}_{t} \tag{139}\] \[\mathbf{\psi}_{t}^{(2)} =\mathbf{\psi}_{t|t-1}^{(2)}+2\alpha\mathbf{\Sigma}_{t|t-1}\mathbf{g}_{t}\mathbf{ \mu}_{t|t-1}^{\intercal}+\alpha\mathbf{\Sigma}_{t|t-1}\mathbf{G}_{t}\mathbf{\Sigma}_{t |t-1} \tag{140}\]

Translating to \(\left(\mathbf{\mu}_{t},\mathbf{\Sigma}_{t}\right)\) gives the bog-fc update

\[\mathbf{\mu}_{t} =\mathbf{\Sigma}_{t}\mathbf{\Sigma}_{t|t-1}^{-1}\mathbf{\mu}_{t|t-1}+\alpha \mathbf{\Sigma}_{t}\mathbf{\Sigma}_{t|t-1}\mathbf{g}_{t} \tag{141}\] \[\mathbf{\Sigma}_{t}^{-1} =\mathbf{\Sigma}_{t|t-1}^{-1}-4\alpha\mathbf{\Sigma}_{t|t-1}\mathbf{g}_{t}\mathbf{ \mu}_{t|t-1}^{\intercal}-2\alpha\mathbf{\Sigma}_{t|t-1}\mathbf{G}_{t}\mathbf{\Sigma}_{t |t-1} \tag{142}\]

This update takes \(O(P^{3})\) because of the matrix inversion. The greater cost of the bog-fc update relative to bong-fc can be traced to the difference between GD and NGD: the NLL gradients wrt \(\mathbf{\psi}_{t|t-1}\) in Eqs. (114) and (115) are more complicated than the gradients wrt \(\mathbf{\rho}_{t|t-1}\) in Eqs. (104) and (105).

#### e.1.6 Bog-lin-hess Fc

Applying Proposition 4.2 to Eqs. (141) and (142) gives the bog-lin-hess-fc update

\[\mathbf{\mu}_{t} =\mathbf{\Sigma}_{t}\mathbf{\Sigma}_{t|t-1}^{-1}\mathbf{\mu}_{t|t-1}+\alpha\bm {\Sigma}_{t}\mathbf{\Sigma}_{t|t-1}\mathbf{H}_{t}^{\intercal}\mathbf{R}_{t}^{-1} \left(\mathbf{y}_{t}-\hat{\mathbf{y}}_{t}\right) \tag{143}\] \[\mathbf{\Sigma}_{t}^{-1} =\mathbf{\Sigma}_{t|t-1}^{-1}-4\alpha\mathbf{\Sigma}_{t|t-1}\mathbf{H}_{t} ^{\intercal}\mathbf{R}_{t}^{-1}\left(\mathbf{y}_{t}-\hat{\mathbf{y}}_{t}\right)\mathbf{\mu} _{t|t-1}^{\intercal}+2\alpha\mathbf{\Sigma}_{t|t-1}\mathbf{H}_{t}^{\intercal} \mathbf{R}_{t}^{-1}\mathbf{H}_{t}\mathbf{\Sigma}_{t|t-1} \tag{144}\]

This update takes \(O(P^{3})\) because of the matrix inversion.

#### e.1.7 Bbb Fc

Substituting Eqs. (114) to (117) into Eq. (34) gives

\[\mathbf{\psi}_{t,i}^{(1)} =\mathbf{\psi}_{t,i-1}^{(1)}+\alpha\mathbf{\Sigma}_{t,i-1}\mathbf{g}_{t,i}- \alpha\mathbf{\Sigma}_{t,i-1}\mathbf{\Sigma}_{t|t-1}^{-1}\left(\mathbf{\mu}_{t,i-1}-\mathbf{\mu }_{t|t-1}\right) \tag{145}\] \[\mathbf{\psi}_{t}^{(2)} =\mathbf{\psi}_{t,i-1}^{(2)}+2\alpha\mathbf{\Sigma}_{t,i-1}\mathbf{g}_{t,i}\bm {\mu}_{t,i-1}^{\intercal}+\alpha\mathbf{\Sigma}_{t|t-1}\mathbf{G}_{t}\mathbf{\Sigma}_{t|t-1}\] \[\quad-2\alpha\mathbf{\Sigma}_{t,i-1}\mathbf{\Sigma}_{t|t-1}^{-1}\left(\bm {\mu}_{t,i-1}-\mathbf{\mu}_{t|t-1}\right)\mathbf{\mu}_{t,i-1}^{\intercal}-\alpha\mathbf{ \Sigma}_{t,i-1}\left(\mathbf{\Sigma}_{t|t-1}^{-1}-\mathbf{\Sigma}_{t,i-1}^{-1}\right) \mathbf{\Sigma}_{t,i-1} \tag{146}\]

Translating to \((\mathbf{\mu}_{t,i},\mathbf{\Sigma}_{t,i})\) gives the bbb-fc update

\[\mathbf{\mu}_{t,i} =\mathbf{\Sigma}_{t,i}\mathbf{\Sigma}_{t,i-1}^{-1}\mathbf{\mu}_{t,i-1}+\alpha \mathbf{\Sigma}_{t,i}\mathbf{\Sigma}_{t,i-1}\left(\mathbf{g}_{t,i}+\mathbf{\Sigma}_{t|t-1}^{-1 }\left(\mathbf{\mu}_{t|t-1}-\mathbf{\mu}_{t,i-1}\right)\right) \tag{147}\] \[\mathbf{\Sigma}_{t,i}^{-1} =\mathbf{\Sigma}_{t,i-1}^{-1}-2\alpha\mathbf{\Sigma}_{t,i-1}\left(\begin{array}[ ]{c}2\mathbf{\Sigma}_{t|t-1}^{-1}\left(\mathbf{\mu}_{t|t-1}-\mathbf{\mu}_{t,i-1}\right)\bm {\mu}_{t,i-1}^{\intercal}+\mathbf{I}_{P}\\ +2\mathbf{g}_{t,i}\mathbf{\mu}_{t,i-1}^{\intercal}+\left(\mathbf{G}_{t,i}-\mathbf{\Sigma}_{t|t- 1}^{-1}\right)\mathbf{\Sigma}_{t,i-1}\end{array}\right) \tag{148}\]

This update takes \(O(P^{3})\) per iteration because of the matrix inversion.

#### e.1.8 Bbb-lin-hess Fc

Applying Proposition 4.2 to Eqs. (147) and (148) gives the bbb-lin-hess-fc update

\[\mathbf{\mu}_{t,i} =\mathbf{\Sigma}_{t,i}\mathbf{\Sigma}_{t,i-1}^{-1}\mathbf{\mu}_{t,i-1}\] \[\quad+\alpha\mathbf{\Sigma}_{t,i}\mathbf{\Sigma}_{t,i-1}\left(\mathbf{H}_{t,i} ^{\intercal}\mathbf{R}_{t,i}^{-1}\left(\mathbf{y}_{t}-\hat{\mathbf{y}}_{t,i}\right)+\mathbf{ \Sigma}_{t|t-1}^{-1}\left(\mathbf{\mu}_{t|t-1}-\mathbf{\mu}_{t,i-1}\right)\right)\] (149) \[\mathbf{\Sigma}_{t,i}^{-1} =\mathbf{\Sigma}_{t,i-1}^{-1}-2\alpha\mathbf{\Sigma}_{t,i-1}\left(\begin{array} []{c}2\mathbf{\Sigma}_{t|t-1}^{-1}\left(\mathbf{\mu}_{t|t-1}-\mathbf{\mu}_{t,i-1}\right) \mathbf{\mu}_{t,i-1}^{\intercal}+\mathbf{I}_{P}\\ +2\mathbf{H}_{t,i}^{\intercal}\mathbf{R}_{t,i}^{-1}\left(\mathbf{y}_{t}-\hat{\mathbf{y}}_{t,i} \right)\mathbf{\mu}_{t,i-1}^{\intercal}\\ -\left(\mathbf{H}_{t,i}^{\intercal}\mathbf{R}_{t,i}^{-1}\mathbf{H}_{t,i}+\mathbf{\Sigma}_{t|t -1}^{-1}\right)

[MISSING_PAGE_EMPTY:30]

#### e.2.4 Blr-lin-hess FC, Moment

Applying Proposition 4.2 to Eqs. (173) and (174) gives the blr-lin-hess-fc_mom update

\[\mathbf{\mu}_{t,i} =\mathbf{\mu}_{t,i-1}+\alpha\mathbf{\Sigma}_{t,i-1}\mathbf{\Sigma}_{t|t-1}^{-1} \left(\mathbf{\mu}_{t|t-1}-\mathbf{\mu}_{t,i-1}\right)+\alpha\mathbf{\Sigma}_{t,i-1}\mathbf{ \Pi}_{t,i}^{\intercal}\mathbf{\mathrm{R}}_{t,i}^{-1}(\mathbf{y}_{t}-\hat{\mathbf{y}}_{t,i}) \tag{175}\] \[\mathbf{\Sigma}_{t,i} =\left(1+\alpha\right)\mathbf{\Sigma}_{t,i-1}-\alpha\mathbf{\Sigma}_{t,i- 1}\left(\mathbf{\Sigma}_{t|t-1}^{-1}+\mathbf{\Pi}_{t,i}^{\intercal}\mathbf{\mathrm{R}}_{t, i}^{-1}\mathbf{\mathrm{H}}_{t,i}\right)\mathbf{\Sigma}_{t,i-1} \tag{176}\]

This update takes \(O(P^{3})\) per iteration because of the matrix inversion in the \(\mathbf{\Sigma}_{t|t-1}^{-1}\) term that comes from the KL divergence in the VI objective.

#### e.2.5 Bog FC, Moment

Substituting Eqs. (151) and (152) into Eq. (31) gives the bog-fc_mom update

\[\mathbf{\mu}_{t} =\mathbf{\mu}_{t|t-1}+\alpha\mathbf{g}_{t} \tag{177}\] \[\mathbf{\Sigma}_{t} =\mathbf{\Sigma}_{t|t-1}+\frac{\alpha}{2}\mathbf{\mathrm{G}}_{t} \tag{178}\]

Note the mean update is vanilla online gradient descent (OGD) and does not depend on the covariance. This update takes \(O(MP^{2})\) using \(\mathbf{G}_{t}^{\textsc{mc-hess}}\) or \(\mathbf{G}_{t}^{\textsc{tc-ef}}\) and \(O(P^{2})\) using \(\mathbf{G}_{t}^{\textsc{ll-ef}}\).

#### e.2.6 Bog-lin-hess FC, Moment

Applying Proposition 4.2 to Eqs. (177) and (178) gives the bog-lin-hess-fc_mom update

\[\mathbf{\mu}_{t} =\mathbf{\mu}_{t|t-1}+\alpha\mathbf{\Pi}_{t}^{\intercal}\mathbf{\mathrm{R}}_{ t}^{-1}(\mathbf{y}_{t}-\hat{\mathbf{y}}_{t}) \tag{179}\] \[\mathbf{\Sigma}_{t} =\mathbf{\Sigma}_{t|t-1}-\frac{\alpha}{2}\mathbf{\Pi}_{t}^{\intercal}\mathbf{ \mathrm{R}}_{t}^{-1}\mathbf{\mathrm{H}}_{t} \tag{180}\]

This update takes \(O(CP^{2})\).

#### e.2.7 Bbb FC, Moment

Substituting Eqs. (151) to (154) into Eq. (34) gives the bbb-fc_mom

\[\mathbf{\mu}_{t,i} =\mathbf{\mu}_{t,i-1}+\alpha\mathbf{\Sigma}_{t|t-1}^{-1}\left(\mathbf{\mu}_{t| t-1}-\mathbf{\mu}_{t,i-1}\right)+\alpha\mathbf{g}_{t,i} \tag{181}\] \[\mathbf{\Sigma}_{t,i} =\mathbf{\Sigma}_{t,i-1}+\frac{\alpha}{2}\left(\mathbf{\Sigma}_{t,i-1}^{- 1}-\mathbf{\Sigma}_{t|t-1}^{-1}+\mathbf{\mathrm{G}}_{t,i}\right) \tag{182}\]

This update takes \(O(P^{3})\) per iteration because of the matrix inversion, which traces back to the VI objective. Comparing to the bog-fc_mom update in Eqs. (177) and (178) (which has quadratic complexity in \(P\)), the extra terms here come from the KL part of Eq. (34).

#### e.2.8 Bbb-lin-hess FC, Moment

Applying Proposition 4.2 to Eqs. (181) and (182) gives the bbb-lin-hess-fc_mom update

\[\mathbf{\mu}_{t,i} =\mathbf{\mu}_{t,i-1}+\alpha\mathbf{\Sigma}_{t|t-1}^{-1}\left(\mathbf{\mu}_{t| t-1}-\mathbf{\mu}_{t,i-1}\right)+\alpha\mathbf{\Pi}_{t,i}^{\intercal}\mathbf{\mathrm{R}}_{ t,i}^{-1}(\mathbf{y}_{t}-\hat{\mathbf{y}}_{t,i}) \tag{183}\] \[\mathbf{\Sigma}_{t} =\mathbf{\Sigma}_{t,i-1}+\frac{\alpha}{2}\left(\mathbf{\Sigma}_{t,i-1}^{- 1}-\mathbf{\Sigma}_{t|t-1}^{-1}-\mathbf{\Pi}_{t,i}^{\intercal}\mathbf{\mathrm{R}}_{t,i}^{- 1}\mathbf{\mathrm{H}}_{t,i}\right) \tag{184}\]

This update takes \(O(P^{3})\) per iteration because of the matrix inversion. Comparing to the bog-lin-hess-fc_mom update in Eqs. (179) and (180) (which has quadratic complexity in \(P\)), the extra terms here come from the KL part of Eq. (34).

### Diagonal Gaussian, Natural parameters

Throughout this subsection, vector multiplication and exponents are elementwise.

The natural and dual parameters for a diagonal Gaussian are given by

\[\mathbf{\psi}_{t,i-1}^{(1)} =\mathbf{\sigma}_{t,i-1}^{-2}\mathbf{\mu}_{t,i-1} \mathbf{\rho}_{t,i-1}^{(1)} =\mathbf{\mu}_{t,i-1} \tag{185}\] \[\mathbf{\psi}_{t,i-1}^{(2)} =-\tfrac{1}{2}\mathbf{\sigma}_{t,i-1}^{-2} \mathbf{\rho}_{t,i-1}^{(2)} =\mathbf{\mu}_{t,i-1}\mathbf{\mu}_{t,i-1}^{\intercal}+\mathbf{\sigma}_{t,i-1}^ {2} \tag{186}\]Inverting these relationships gives

\[\mathbf{\mu}_{t,i-1} =-\tfrac{1}{2}\left(\mathbf{\psi}_{t,i-1}^{(2)}\right)^{-1}\mathbf{\psi}_{t, i-1}^{(1)} =\mathbf{\rho}_{t,i-1}^{(1)} \tag{187}\] \[\mathbf{\sigma}_{t,i-1}^{2} =-\tfrac{1}{2}\left(\mathbf{\psi}_{t,i-1}^{(2)}\right)^{-1} =\mathbf{\rho}_{t,i-1}^{(2)}-\left(\mathbf{\rho}_{t,i-1}^{(1)}\right)^{2} \tag{188}\]

The KL divergence in the VI loss is

\[D_{\mathbb{KL}}\big{(}q_{\mathbf{\psi}_{t,i-1}}|q_{\mathbf{\psi}_{t|t-1}} \big{)} =\tfrac{1}{2}\left(\mathbf{\mu}_{t,i-1}-\mathbf{\mu}_{t|t-1}\right)^{2} \mathbf{\sigma}_{t|t-1}^{-2} +\tfrac{1}{2}\sum\left(\mathbf{\sigma}_{t|t-1}^{-2}\mathbf{\sigma}_{t,i-1}^{2}-\log \mathbf{\sigma}_{t,i-1}^{2}\right)+\text{const} \tag{189}\]

with gradients

\[\nabla_{\mathbf{\mu}_{t,i-1}}D_{\mathbb{KL}}\big{(}q_{\mathbf{\psi}_{t,i- 1}}|q_{\mathbf{\psi}_{t|t-1}}\big{)} =\mathbf{\sigma}_{t|t-1}^{-2}\left(\mathbf{\mu}_{t,i-1}-\mathbf{\mu}_{t|t-1}\right) \tag{190}\] \[\nabla_{\mathbf{\sigma}_{t,i-1}^{2}}D_{\mathbb{KL}}\big{(}q_{\mathbf{\psi }_{t,i-1}}|q_{\mathbf{\psi}_{t|t-1}}\big{)} =\tfrac{1}{2}\left(\mathbf{\sigma}_{t|t-1}^{-2}-\mathbf{\sigma}_{t,i-1}^{ -2}\right) \tag{191}\]

For any scalar function \(\mathbf{\ell}\) the chain rule gives

\[\nabla_{\mathbf{\rho}_{t,i-1}^{(1)}}\ell =\frac{\partial\mathbf{\mu}_{t,i-1}}{\partial\mathbf{\rho}_{t,i-1}^{(1)}} \nabla_{\mathbf{\mu}_{t,i-1}}\ell+\frac{\partial\mathbf{\sigma}_{t,i-1}^{2}}{\partial \mathbf{\rho}_{t,i-1}^{(1)}}\nabla_{\mathbf{\sigma}_{t,i-1}^{2}}\ell \tag{192}\] \[=\nabla_{\mathbf{\mu}_{t,i-1}}\ell-2\mathbf{\mu}_{t,i-1}\nabla_{\mathbf{ \sigma}_{t,i-1}^{2}}\ell\] (193) \[\nabla_{\mathbf{\rho}_{t,i-1}^{(2)}}\ell =\frac{\partial\mathbf{\mu}_{t,i-1}}{\partial\mathbf{\rho}_{t,i-1}^{(2)}} \nabla_{\mathbf{\mu}_{t,i-1}}\ell+\frac{\partial\mathbf{\sigma}_{t,i-1}^{2}}{\partial \mathbf{\rho}_{t,i-1}^{(2)}}\nabla_{\mathbf{\sigma}_{t,i-1}^{2}}\ell\] (194) \[=\nabla_{\mathbf{\sigma}_{t,i-1}^{2}}\ell \tag{195}\]

Therefore

\[\nabla_{\mathbf{\rho}_{t,i-1}^{(1)}}\mathbb{E}_{\mathbf{\theta}_{t}\sim q _{\mathbf{\psi}_{t,i-1}}}[\log p\left(\mathbf{y}_{t}|f_{t}\left(\mathbf{\theta}_{t}\right) \right)] =\mathbf{g}_{t,i}-\text{diag}\left(\mathbf{G}_{t,i}\right)\mathbf{\mu}_{t,i-1} \tag{196}\] \[\nabla_{\mathbf{\rho}_{t,i-1}^{(2)}}\mathbb{E}_{\mathbf{\theta}_{t}\sim q _{\mathbf{\psi}_{t,i-1}}}[\log p\left(\mathbf{y}_{t}|f_{t}\left(\mathbf{\theta}_{t}\right) \right)] =\tfrac{1}{2}\text{diag}\left(\mathbf{G}_{t,i}\right) \tag{197}\]

and

\[\nabla_{\mathbf{\rho}_{t,i-1}^{(1)}}D_{\mathbb{KL}}\big{(}q_{\mathbf{\psi }_{t,i-1}}|q_{\mathbf{\psi}_{t|t-1}}\big{)} =\mathbf{\sigma}_{t,i-1}^{-2}\mathbf{\mu}_{t,i-1}-\mathbf{\sigma}_{t|t-1}^{-2} \mathbf{\mu}_{t|t-1} \tag{198}\] \[\nabla_{\mathbf{\rho}_{t,i-1}^{(2)}}D_{\mathbb{KL}}\big{(}q_{\mathbf{\psi }_{t,i-1}}|q_{\mathbf{\psi}_{t|t-1}}\big{)} =\tfrac{1}{2}\left(\mathbf{\sigma}_{t|t-1}^{-2}-\mathbf{\sigma}_{t,i-1}^{ -2}\right) \tag{199}\]

Following the same approach for \(\mathbf{\psi}\) gives

\[\nabla_{\mathbf{\psi}_{t,i-1}^{(1)}}\ell =\frac{\partial\mathbf{\mu}_{t,i-1}}{\partial\mathbf{\psi}_{t,i-1}^{(1)}} \nabla_{\mathbf{\mu}_{t,i-1}}\ell+\frac{\partial\mathbf{\sigma}_{t,i-1}^{2}}{\partial \mathbf{\psi}_{t,i-1}^{(1)}}\nabla_{\mathbf{\Sigma}_{t,i-1}}\ell \tag{200}\] \[=-\tfrac{1}{2}\left(\mathbf{\psi}_{t,i-1}^{(2)}\right)^{-1}\nabla_{ \mathbf{\mu}_{t,i-1}}\ell\] (201) \[=\mathbf{\sigma}_{t,i-1}^{2}\nabla_{\mathbf{\mu}_{t,i-1}}\ell\] (202) \[\nabla_{\mathbf{\psi}_{t,i-1}^{(2)}}\ell =\frac{\partial\mathbf{\mu}_{t,i-1}}{\partial\mathbf{\psi}_{t,i-1}^{(2)}} \nabla_{\mathbf{\mu}_{t,i-1}}\ell+\frac{\partial\mathbf{\sigma}_{t,i-1}^{2}}{\partial \mathbf{\psi}_{t,i-1}^{(2)}}\nabla_{\mathbf{\sigma}_{t,i-1}^{2}}\ell\] (203) \[=\tfrac{1}{2}\left(\mathbf{\psi}_{t,i-1}^{(2)}\right)^{-2}\mathbf{\psi}_{ t,i-1}^{(1)}\nabla_{\mathbf{\mu}_{t,i-1}}\ell+\tfrac{1}{2}\left(\mathbf{\psi}_{t,i-1}^{(2)} \right)^{-2}\nabla_{\mathbf{\sigma}_{t,i-1}^{2}}\ell\] (204) \[=2\mathbf{\sigma}_{t,i-1}^{2}\mathbf{\mu}_{t,i-1}\nabla_{\mathbf{\mu}_{t,i-1 }}\ell+2\mathbf{\sigma}_{t,i-1}^{4}\nabla_{\mathbf{\sigma}_{t,i-1}^{2}}\ell \tag{205}\]

Therefore

\[\nabla_{\mathbf{\psi}_{t,i-1}^{(1)}}\mathbb{E}_{\mathbf{\theta}_{t}\sim q _{\mathbf{\psi}_{t,i-1}}}[\log p\left(\mathbf{y}_{t}|f_{t}\left(\mathbf{\theta}_{t} \right)\right)] =\mathbf{\sigma}_{t,i-1}^{2}\mathbf{g}_{t,i} \tag{206}\] \[\nabla_{\mathbf{\psi}_{t,i-1}^{(2)}}\mathbb{E}_{\mathbf{\theta}_{t}\sim q _{\mathbf{\psi}_{t,i-1}}}[\log p\left(\mathbf{y}_{t}|f_{t}\left(\mathbf{\theta}_{t} \right)\right)] =2\mathbf{\sigma}_{t,i-1}^{2}\mathbf{\mu}_{t,i-1}\mathbf{g}_{t,i}+\mathbf{ \sigma}_{t,i-1}^{4}\text{diag}\left(\mathbf{G}_{t,i}\right) \tag{207}\]and

\[\nabla_{\mathbf{\psi}_{t,i-1}^{(1)}}D_{\text{KL}}\big{(}q_{\mathbf{\psi}_{t,i- 1}}|q_{\mathbf{\psi}_{t|t-1}}\big{)} =\mathbf{\sigma}_{t,i-1}^{2}\mathbf{\sigma}_{t|t-1}^{-2}\left(\mathbf{\mu}_{t, i-1}-\mathbf{\mu}_{t|t-1}\right) \tag{208}\] \[\nabla_{\mathbf{\psi}_{t,i-1}^{(2)}}D_{\text{KL}}\big{(}q_{\mathbf{\psi}_{ t,i-1}}|q_{\mathbf{\psi}_{t|t-1}}\big{)} =2\mathbf{\sigma}_{t,i-1}^{2}\mathbf{\sigma}_{t|t-1}^{-2}\mathbf{\mu}_{t,i-1 }\left(\mathbf{\mu}_{t,i-1}-\mathbf{\mu}_{t|t-1}\right)\] \[\qquad+\mathbf{\sigma}_{t,i-1}^{4}\left(\mathbf{\sigma}_{t|t-1}^{-2}-\bm {\sigma}_{t,i-1}^{-2}\right) \tag{209}\]

Our implementations often make use of the following trick: Suppose \(\mathbf{A}\in\mathbb{R}^{n\times m}\) and \(\mathbf{B}\in\mathbb{R}^{m\times n}\). Then we can efficiently compute \(\operatorname{diag}(\mathbf{A}\mathbf{B})\) in \(O(mn)\) time using \((\mathbf{A}\mathbf{B})_{ii}=\sum_{j=1}^{M}A_{ij}B_{ji}\).

For mc-hess methods, we approximate the diagonal of the Hessian for each MC sample \(\hat{\mathbf{\theta}}_{t}^{(m)}\) using Hutchinson's trace estimation method (Hutchinson, 1989) which has been used in other DNN optimization papers such as adahessian Yao et al. (2021). This involves an extra inner loop with size denoted \(N\).

#### e.3.1 Bong Diag

Substituting Eqs. (196) and (197) into Eq. (5) gives

\[\mathbf{\psi}_{t}^{(1)} =\mathbf{\psi}_{t|t-1}^{(1)}+\mathbf{g}_{t}-\operatorname{diag}\left( \mathbf{G}_{t}\right)\mathbf{\mu}_{t|t-1} \tag{210}\] \[\mathbf{\psi}_{t}^{(2)} =\mathbf{\psi}_{t|t-1}^{(2)}+\tfrac{1}{2}\operatorname{diag}\left( \mathbf{G}_{t}\right) \tag{211}\]

Translating to \(\left(\mathbf{\mu}_{t},\mathbf{\sigma}_{t}^{2}\right)\) gives the bong-diag update

\[\mathbf{\mu}_{t} =\mathbf{\mu}_{t|t-1}+\mathbf{\sigma}_{t}^{2}\mathbf{g}_{t} \tag{212}\] \[\mathbf{\sigma}_{t}^{-2} =\mathbf{\sigma}_{t|t-1}^{-2}-\operatorname{diag}\left(\mathbf{G}_{t}\right) \tag{213}\]

This update takes \(O(MP)\) to estimate \(\mathbf{G}_{t}\) using \(\mathbf{G}_{t}^{\text{\tiny MC-EF}}\), \(O(NMP)\) using \(\mathbf{G}_{t}^{\text{\tiny MC-HESS}}\) and Hutchinson's method, and \(O(P)\) using \(\mathbf{G}_{t}^{\text{\tiny IN-EF}}\).

#### e.3.2 Bong-lin-hess Diag (vd-ekf)

Applying Proposition 4.2 to Eqs. (210) and (211) gives the bong-lin-hess-diag update

\[\mathbf{\mu}_{t} =\mathbf{\mu}_{t|t-1}+\mathbf{\sigma}_{t}^{2}\left(\mathbf{H}_{t}^{ \intercal}\mathbf{R}_{t}^{-1}\left(\mathbf{y}_{t}-\hat{\mathbf{y}}_{t}\right)\right) \tag{214}\] \[\mathbf{\sigma}_{t}^{-2} =\mathbf{\sigma}_{t|t-1}^{-2}+\operatorname{diag}\left(\mathbf{H}_{t }^{\intercal}\mathbf{R}_{t}^{-1}\mathbf{H}_{t}\right) \tag{215}\]

This update is equivalent to vd-ekf(Chang et al., 2022) and takes \(O(C^{2}P)\).

#### e.3.3 Blr Diag (von)

Substituting Eqs. (196) to (199) into Eq. (33) gives

\[\mathbf{\psi}_{t,i}^{(1)} =\mathbf{\psi}_{t,i-1}^{(1)}+\alpha\left(\mathbf{g}_{t,i}-\operatorname{ diag}\left(\mathbf{G}_{t,i}\right)\mathbf{\mu}_{t,i-1}-\mathbf{\sigma}_{t,i-1}^{-2} \mathbf{\mu}_{t,i-1}+\mathbf{\sigma}_{t|t-1}^{-2}\mathbf{\mu}_{t|t-1}\right) \tag{216}\] \[\mathbf{\psi}_{t,i}^{(2)} =\mathbf{\psi}_{t,i-1}^{(2)}+\frac{\alpha}{2}\left(\operatorname{diag} \left(\mathbf{G}_{t,i}\right)+\mathbf{\sigma}_{t,i-1}^{-2}-\mathbf{\sigma}_{t|t-1}^{-2 }\right) \tag{217}\]

Translating to \(\left(\mathbf{\mu}_{t,i},\mathbf{\sigma}_{t,i}^{2}\right)\) gives the blr-diag update

\[\mathbf{\mu}_{t,i} =\mathbf{\mu}_{t,i-1}+\alpha\mathbf{\sigma}_{t,i}^{2}\mathbf{\sigma}_{t|t-1}^{ -2}\left(\mathbf{\mu}_{t|t-1}-\mathbf{\mu}_{t,i-1}\right)+\alpha\mathbf{\sigma}_{t,i}^{2} \mathbf{g}_{t,i} \tag{218}\] \[\mathbf{\sigma}_{t,i}^{-2} =(1-\alpha)\,\mathbf{\sigma}_{t,i-1}^{-2}+\alpha\mathbf{\sigma}_{t|t-1}^{ -2}-\alpha\operatorname{diag}\left(\mathbf{G}_{t,i}\right) \tag{219}\]

This update takes \(O(MP)\) per iteration to estimate \(\mathbf{G}_{t}\) using \(\mathbf{G}_{t}^{\text{\tiny MC-EF}}\), \(O(NMP)\) per iteration using \(\mathbf{G}_{t}^{\text{\tiny MC-HESS}}\) and Hutchinson's method, and \(O(P)\) per iteration using \(\mathbf{G}_{t}^{\text{\tiny IN-EF}}\).

The mc-hess and mc-ef versions of this update are respectively equivalent to von and vogn(Khan et al., 2018) in the batch setting where we replace \(q_{\mathbf{\psi}_{t|t-1}}\) with a spherical prior \(\mathcal{N}(\mathbf{0},\lambda^{-1}\mathbf{I}_{P})\)(see Appendix E.6).

#### e.3.4 Blr-lin-hess Diag

Applying Proposition 4.2 to Eqs. (218) and (219) gives the blr-lin-hess-diag update

\[\boldsymbol{\mu}_{t,i} =\boldsymbol{\mu}_{t,i-1}+\alpha\boldsymbol{\sigma}_{t,i}^{2} \boldsymbol{\sigma}_{t|t-1}^{-2}\left(\boldsymbol{\mu}_{t|t-1}-\boldsymbol{\mu }_{t,i-1}\right)+\alpha\boldsymbol{\sigma}_{t,i}^{2}\left(\mathbf{H}_{t,i}^{ \intercal}\mathbf{R}_{t,i}^{-1}\left(\boldsymbol{y}_{t}-\hat{\boldsymbol{y}}_{ t,i}\right)\right) \tag{220}\] \[\boldsymbol{\sigma}_{t,i}^{-2} =\left(1-\alpha\right)\boldsymbol{\sigma}_{t,i-1}^{-2}+\alpha \boldsymbol{\sigma}_{t|t-1}^{-2}+\alpha\operatorname{diag}\left(\mathbf{H}_{t, i}^{\intercal}\mathbf{R}_{t,i}^{-1}\mathbf{H}_{t,i}\right) \tag{221}\]

This update takes \(O(C^{2}P)\) per iteration.

#### e.3.5 Bog Diag

Substituting Eqs. (206) and (207) into Eq. (31) gives

\[\boldsymbol{\psi}_{t}^{(1)} =\boldsymbol{\psi}_{t|t-1}^{(1)}+\alpha\boldsymbol{\sigma}_{t|t-1 }^{2}\boldsymbol{g}_{t} \tag{222}\] \[\boldsymbol{\psi}_{t}^{(2)} =\boldsymbol{\psi}_{t|t-1}^{(2)}+2\alpha\boldsymbol{\sigma}_{t|t- 1}^{2}\boldsymbol{\mu}_{t|t-1}\boldsymbol{g}_{t}+\alpha\boldsymbol{\sigma}_{t| t-1}^{4}\mathrm{diag}\left(\mathbf{G}_{t}\right) \tag{223}\]

Translating to \(\left(\boldsymbol{\mu}_{t},\boldsymbol{\sigma}_{t}^{2}\right)\) gives the bog-diag update

\[\boldsymbol{\mu}_{t} =\boldsymbol{\sigma}_{t}^{2}\boldsymbol{\sigma}_{t|t-1}^{-2} \boldsymbol{\mu}_{t|t-1}+\alpha\boldsymbol{\sigma}_{t}^{2}\boldsymbol{\sigma}_ {t|t-1}^{2}\boldsymbol{g}_{t} \tag{224}\] \[\boldsymbol{\sigma}_{t}^{-2} =\boldsymbol{\sigma}_{t|t-1}^{-2}-4\alpha\boldsymbol{\sigma}_{t|t -1}^{2}\boldsymbol{\mu}_{t|t-1}\boldsymbol{g}_{t}-2\alpha\boldsymbol{\sigma}_ {t|t-1}^{4}\mathrm{diag}\left(\mathbf{G}_{t}\right) \tag{225}\]

This update takes \(O(MP)\) to estimate \(\mathbf{G}_{t}\) using \(\mathbf{G}_{t}^{\text{MC-EF}}\), \(O(NMP)\) using \(\mathbf{G}_{t}^{\text{MC-HESS}}\) and Hutchinson's method, and \(O(P)\) using \(\mathbf{G}_{t}^{\text{MC-EF}}\).

#### e.3.6 Bog-lin-hess Diag

Applying Proposition 4.2 to Eqs. (224) and (225) gives the bog-lin-hess-diag update

\[\boldsymbol{\mu}_{t} =\boldsymbol{\sigma}_{t}^{2}\boldsymbol{\sigma}_{t|t-1}^{-2} \boldsymbol{\mu}_{t|t-1}+\alpha\boldsymbol{\sigma}_{t}^{2}\boldsymbol{\sigma}_ {t|t-1}^{2}\left(\mathbf{H}_{t}^{\intercal}\mathbf{R}_{t}^{-1}\left( \boldsymbol{y}_{t}-\hat{\boldsymbol{y}}_{t}\right)\right) \tag{226}\] \[\boldsymbol{\sigma}_{t}^{-2} =\boldsymbol{\sigma}_{t|t-1}^{-2}-4\alpha\boldsymbol{\sigma}_{t|t -1}^{2}\boldsymbol{\mu}_{t|t-1}\left(\mathbf{H}_{t}^{\intercal}\mathbf{R}_{t} ^{-1}\left(\boldsymbol{y}_{t}-\hat{\boldsymbol{y}}_{t}\right)\right)+2\alpha \boldsymbol{\sigma}_{t|t-1}^{4}\mathrm{diag}\left(\mathbf{H}_{t}^{\intercal} \mathbf{R}_{t}^{-1}\mathbf{H}_{t}\right) \tag{227}\]

This update takes \(O(C^{2}P)\).

#### e.3.7 Bbb Diag

Substituting Eqs. (206) to (209) into Eq. (34) gives

\[\boldsymbol{\psi}_{t,i}^{(1)} =\boldsymbol{\psi}_{t,i-1}^{(1)}+\alpha\boldsymbol{\sigma}_{t,i-1} ^{2}\boldsymbol{g}_{t,i}-\alpha\boldsymbol{\sigma}_{t,i-1}^{2}\boldsymbol{ \sigma}_{t|t-1}^{-2}\left(\boldsymbol{\mu}_{t,i-1}-\boldsymbol{\mu}_{t|t-1}\right) \tag{228}\] \[\boldsymbol{\psi}_{t}^{(2)} =\boldsymbol{\psi}_{t,i-1}^{(2)}+2\alpha\boldsymbol{\sigma}_{t,i-1 }^{2}\boldsymbol{\mu}_{t,i-1}\boldsymbol{g}_{t,i}+\alpha\boldsymbol{\sigma}_{t, i-1}^{4}\mathrm{diag}\left(\mathbf{G}_{t,i}\right)\] \[\quad-2\alpha\boldsymbol{\sigma}_{t,i-1}^{2}\boldsymbol{\sigma}_ {t|t-1}^{-2}\boldsymbol{\mu}_{t,i-1}\left(\boldsymbol{\mu}_{t,i-1}-\boldsymbol{ \mu}_{t|t-1}\right)-\alpha\boldsymbol{\sigma}_{t,i-1}^{4}\left(\boldsymbol{ \sigma}_{t|t-1}^{-2}-\boldsymbol{\sigma}_{t,i-1}^{-2}\right) \tag{229}\]

Translating to \(\left(\boldsymbol{\mu}_{t,i},\boldsymbol{\Sigma}_{t}\right)\) gives the bbb-diag update

\[\boldsymbol{\mu}_{t,i} =\boldsymbol{\sigma}_{t,i}^{2}\boldsymbol{\sigma}_{t,i-1}^{2} \boldsymbol{\mu}_{t,i-1}+\alpha\boldsymbol{\sigma}_{t,i}^{2}\boldsymbol{\sigma} _{t,i-1}^{2}\boldsymbol{g}_{t,i}+\alpha\boldsymbol{\sigma}_{t,i}^{2} \boldsymbol{\sigma}_{t,i-1}^{2}\boldsymbol{\sigma}_{t|t-1}^{-2}\left( \boldsymbol{\mu}_{t|t-1}-\boldsymbol{\mu}_{t,i-1}\right) \tag{230}\] \[\boldsymbol{\sigma}_{t,i}^{-2} =\boldsymbol{\sigma}_{t,i-1}^{-2}-4\alpha\boldsymbol{\sigma}_{t,i-1 }^{2}\boldsymbol{\mu}_{t,i-1}\boldsymbol{g}_{t,i}-2\alpha\boldsymbol{\sigma}_ {t,i-1}^{4}\mathrm{diag}\left(\mathbf{G}_{t,i}\right)\] \[\quad+4\alpha\boldsymbol{\sigma}_{t,i-1}^{2}\boldsymbol{\sigma}_ {t|t-1}^{-2}\boldsymbol{\mu}_{t,i-1}\left(\boldsymbol{\mu}_{t,i-1}-\boldsymbol{ \mu}_{t|t-1}\right)+2\alpha\boldsymbol{\sigma}_{t,i-1}^{4}\left(\boldsymbol{ \sigma}_{t|t-1}^{-2}-\boldsymbol{\sigma}_{t,i-1}^{-2}\right) \tag{231}\]

This update takes \(O(MP)\) per iteration to estimate \(\mathbf{G}_{t}\) using \(\mathbf{G}_{t}^{\text{MC-EF}}\), \(O(NMP)\) per iteration using \(\mathbf{G}_{t}^{\text{MC-HESS}}\) and Hutchinson's method, and \(O(P)\) per iteration using \(\mathbf{G}_{t}^{\text{MC-HESS}}\).

#### e.3.8 Bbb-lin-hess Diag

Applying Proposition 4.2 to Eqs. (230) and (231) gives the bbb-lin-hess-diag update

\[\boldsymbol{\mu}_{t,i} =\boldsymbol{\sigma}_{t,i}^{2}\boldsymbol{\sigma}_{t,i-1}^{-2} \boldsymbol{\mu}_{t,i-1}+\alpha\boldsymbol{\sigma}_{t,i}^{2}\boldsymbol{\sigma}_ {t,i-1}^{2}\left(\mathbf{H}_{t,i}^{\intercal}\mathbf{R}_{t,i}^{-1}\left( \boldsymbol{y}_{t}-\hat{\boldsymbol{y}}_{t,i}\right)\right)\] \[\quad+\alpha\boldsymbol{\sigma}_{t,i}^{2}\boldsymbol{\sigma}_{t,i- 1}^{2}\boldsymbol{\sigma}_{t|t-1}^{-2}\left(\boldsymbol{\mu}_{t|t-1}- \boldsymbol{\mu}_{t,i-1}\right) \tag{232}\] \[\boldsymbol{\sigma}_{t,i}^{-2} =\boldsymbol{\sigma}_{t,i-1}^{-2}-4\alpha\boldsymbol{\sigma}_{t,i- 1}^{2}\boldsymbol{\mu}_{t,i-1}-\left(\boldsymbol{\mu}_{t,i}^{\intercal} \mathbf{R}_{t,i}^{-1}\left(\boldsymbol{y}_{t}-\hat{\boldsymbol{y}}_{t,i}\right) \right)+2\alpha\boldsymbol{\sigma}_{t,i-1}^{4}\mathrm{diag}\left(\mathbf{H}_{t, i}^{\intercal}\mathbf{R}_{t,i}^{-1}\mathbf{H}_{t,i}\right)\] \[\quad+4\alpha\boldsymbol{\sigma}_{t,i-1}^{2}\boldsymbol{\sigma}_ {t|t-1}^{-2}\boldsymbol{\mu}_{t,i-1}\left(\boldsymbol{\mu}_{t,i-1}-\boldsymbol{ \mu}_{t|t-1}\right)+2\alpha\boldsymbol{\sigma}_{t,i-1}^{4}\boldsymbol{\sigma}_{t| t-1}^{-2}-2\alpha\boldsymbol{\sigma}_{t,i-1}^{2} \tag{233}\]

This update takes \(O(C^{2}P)\) per iteration.

### Diagonal Gaussian, Moment parameters

Throughout this subsection, vector multiplication and exponents are elementwise.

The Bonnet and Price theorems give

\[\nabla_{\mathbf{\mu}_{t,i-1}}\mathbb{E}_{\mathbf{\theta}_{t}\sim q_{\mathbf{ \varphi}_{t,i-1}}}[\log p\left(\mathbf{y}_{t}|f_{t}\left(\mathbf{\theta}_{t}\right) \right)]=\mathbf{g}_{t,i} \tag{234}\] \[\nabla_{\mathbf{\sigma}_{t,i-1}^{2}}\mathbb{E}_{\mathbf{\theta}_{t}\sim q_ {\mathbf{\varphi}_{t,i-1}}}[\log p\left(\mathbf{y}_{t}|f_{t}\left(\mathbf{\theta}_{t} \right)\right)]=\tfrac{1}{2}\mathrm{diag}\left(\mathbf{G}_{t,i}\right) \tag{235}\]

From Appendix E.3 we have

\[\nabla_{\mathbf{\mu}_{t,i-1}}D_{\mathbb{KL}}\big{(}q_{\mathbf{\psi}_{t,i- 1}}|q_{\mathbf{\psi}_{t|t-1}}\big{)}=\mathbf{\sigma}_{t|t-1}^{-2}\left(\mathbf{\mu}_{t,i- 1}-\mathbf{\mu}_{t|t-1}\right) \tag{236}\] \[\nabla_{\mathbf{\sigma}_{t,i-1}^{2}}D_{\mathbb{KL}}\big{(}q_{\mathbf{ \psi}_{t,i-1}}|q_{\mathbf{\psi}_{t|t-1}}\big{)}=\tfrac{1}{2}\left(\mathbf{\sigma}_{t| t-1}^{-2}-\mathbf{\sigma}_{t,i-1}^{-2}\right) \tag{237}\]

We write the Fisher with respect to the moment parameters \(\mathbf{\psi}=(\mathbf{\mu},\mathbf{\sigma}^{2})\) as a block matrix:

\[\mathbf{F}_{\mathbf{\psi}}=\left[\begin{array}{cc}\mathbf{F}_{\mathbf{ \mu},\mathbf{\mu}}&\mathbf{F}_{\mathbf{\mu},\mathbf{\sigma}^{2}}\\ \mathbf{F}_{\mathbf{\sigma}^{2},\mathbf{\mu}}&\mathbf{F}_{\mathbf{\sigma}^{2},\mathbf{\sigma}^{ 2}}\end{array}\right] \tag{238}\]

The blocks can be calculated by the second-order Fisher formula

\[\mathbf{F}_{\mathbf{\mu},\mathbf{\mu}} =-\mathbb{E}_{q_{\mathbf{\psi}}}[\nabla_{\mathbf{\mu},\mathbf{\mu}}\log q_{ \mathbf{\psi}}(\mathbf{\theta})] \tag{239}\] \[=\mathrm{Diag}\left(\mathbf{\sigma}^{-2}\right)\] (240) \[\mathbf{F}_{\mathbf{\mu},\mathbf{\sigma}^{2}} =-\mathbb{E}_{q_{\mathbf{\psi}}}\big{[}\nabla_{\mathbf{\mu},\mathbf{\sigma}^ {2}}\log q_{\mathbf{\psi}}(\mathbf{\theta})\big{]}\] (241) \[=\mathbb{E}_{q_{\mathbf{\psi}}}\big{[}\mathrm{Diag}\left((\mathbf{\theta }-\mathbf{\mu})\mathbf{\sigma}^{-4}\right)\big{]}\] (242) \[=\mathbf{0}\] (243) \[\mathbf{F}_{\mathbf{\sigma}^{2},\mathbf{\sigma}^{2}} =-\mathbb{E}_{q_{\mathbf{\psi}}}\big{[}\nabla_{\mathbf{\sigma}^{2},\mathbf{ \sigma}^{2}}\log q_{\mathbf{\psi}}(\mathbf{\theta})\big{]}\] (244) \[=-\mathbb{E}_{q_{\mathbf{\psi}}}\big{[}\mathrm{Diag}\left(-\left(\bm {\mu}-\mathbf{\theta}\right)^{2}\mathbf{\sigma}^{-6}+\tfrac{1}{2}\mathbf{\sigma}^{-4} \right)\big{]}\] (245) \[=\tfrac{1}{2}\mathrm{Diag}\left(\mathbf{\sigma}^{-4}\right) \tag{246}\]

Therefore the preconditioner for the NGD methods is

\[\mathbf{F}_{\mathbf{\psi}_{t,i-1}}^{-1}=\left[\begin{array}{cc}\mathrm{Diag} \left(\sigma_{t,i-1}^{2}\right)&\mathbf{0}\\ \mathbf{0}&2\mathrm{Diag}\left(\sigma_{t,i-1}^{4}\right)\end{array}\right] \tag{247}\]

#### e.4.1 Bong Diag, Moment

Substituting Eqs. (234), (235) and (247) into Eq. (3) gives the bong-diag_mom update

\[\mathbf{\mu}_{t} =\mathbf{\mu}_{t|t-1}+\mathbf{\sigma}_{t|t-1}^{2}\mathbf{g}_{t} \tag{248}\] \[\mathbf{\sigma}_{t}^{2} =\mathbf{\sigma}_{t|t-1}^{2}+\mathbf{\sigma}_{t|t-1}^{4}\mathrm{diag} \left(\mathbf{G}_{t}\right) \tag{249}\]

This update takes \(O(MP)\) to estimate \(\mathbf{G}_{t}\) using \(\mathbf{G}_{t}^{\textsc{mc-f}}\), \(O(NMP)\) using \(\mathbf{G}_{t}^{\textsc{mc-f}}\) and Hutchinson's method, and \(O(P)\) using \(\mathbf{G}_{t}^{\textsc{lm-f}}\).

#### e.4.2 Bong-lin-hess Diag, Moment

Applying Proposition 4.2 to Eqs. (248) and (249) gives the bong-lin-hess-diag_mom update

\[\mathbf{\mu}_{t} =\mathbf{\mu}_{t|t-1}+\mathbf{\sigma}_{t|t-1}^{2}\left(\mathbf{H}_{t}^{ \intercal}\mathbf{R}_{t}^{-1}(\mathbf{y}_{t}-\hat{\mathbf{y}}_{t})\right) \tag{250}\] \[\mathbf{\sigma}_{t}^{2} =\mathbf{\sigma}_{t|t-1}^{2}-\mathbf{\sigma}_{t|t-1}^{4}\mathrm{diag} \left(\mathbf{H}_{t}^{\intercal}\mathbf{R}_{t}^{-1}\mathbf{H}_{t}\right) \tag{251}\]

This update takes \(O(C^{2}P)\).

#### e.4.3 Blr Diag, Moment

Substituting Eqs. (234) to (237) and (247) into Eq. (3) gives the blr-diag_mom update

\[\mathbf{\mu}_{t,i} =\mathbf{\mu}_{t,i-1}+\alpha\mathbf{\sigma}_{t,i-1}^{2}\mathbf{\sigma}_{t|t- 1}^{-2}\left(\mathbf{\mu}_{t|t-1}-\mathbf{\mu}_{t,i-1}\right)+\alpha\mathbf{\sigma}_{t,i -1}^{2}\mathbf{g}_{t,i} \tag{252}\] \[\mathbf{\sigma}_{t,i}^{2} =\mathbf{\sigma}_{t,i-1}^{2}+\alpha\mathbf{\sigma}_{t,i-1}^{4}\left(\mathbf{ \sigma}_{t,i-1}^{-2}-\mathbf{\sigma}_{t|t-1}^{-2}\right)+\alpha\mathbf{\sigma}_{t,i-1} ^{4}\mathrm{diag}\left(\mathbf{G}_{t,i}\right) \tag{253}\]

This update takes \(O(MP)\) per iteration to estimate \(\mathbf{G}_{t}\) using \(\mathbf{G}_{t}^{\textsc{mc-f}}\), \(O(NMP)\) per iteration using \(\mathbf{G}_{t}^{\textsc{mc-f}}\) and Hutchinson's method, and \(O(P)\) per iteration using \(\mathbf{G}_{t}^{\textsc{lm-f}}\).

#### e.4.4 Blr-lin-hess Diag, Moment

Applying Proposition 4.2 to Eqs. (252) and (253) gives the blr-lin-hess-diag.mom update

\[\mathbf{\mu}_{t,i} =\mathbf{\mu}_{t,i-1}+\alpha\mathbf{\sigma}_{t,i-1}^{2}\mathbf{\sigma}_{t|t-1} ^{-2}\left(\mathbf{\mu}_{t|t-1}-\mathbf{\mu}_{t,i-1}\right)+\alpha\mathbf{\sigma}_{t,i-1}^{ 2}\left(\mathbf{H}_{t,i}^{\intercal}\mathbf{R}_{t,i}^{-1}(\mathbf{y}_{t}-\hat{\mathbf{ y}}_{t,i})\right) \tag{254}\] \[\mathbf{\sigma}_{t,i}^{2} =\mathbf{\sigma}_{t,i-1}^{2}+\alpha\mathbf{\sigma}_{t,i-1}^{4}\left(\mathbf{ \sigma}_{t,i-1}^{-2}-\mathbf{\sigma}_{t|t-1}^{-2}\right)-\alpha\mathbf{\sigma}_{t,i-1} ^{4}\mathrm{diag}\left(\mathbf{H}_{t,i}^{\intercal}\mathbf{R}_{t,i}^{-1} \mathbf{H}_{t,i}\right) \tag{255}\]

This update takes \(O(C^{2}P)\) per iteration.

#### e.4.5 Bog Diag, Moment

Substituting Eqs. (234) and (235) into Eq. (31) gives the bog-diag.mom update

\[\mathbf{\mu}_{t} =\mathbf{\mu}_{t|t-1}+\alpha\mathbf{g}_{t} \tag{256}\] \[\mathbf{\sigma}_{t}^{2} =\mathbf{\sigma}_{t|t-1}^{2}+\frac{\alpha}{2}\mathrm{diag}\left( \mathbf{G}_{t}\right) \tag{257}\]

This update takes \(O(MP)\) to estimate \(\mathbf{G}_{t}\) using \(\mathbf{G}_{t}^{\text{\tiny{MC-EF}}}\), \(O(NMP)\) using \(\mathbf{G}_{t}^{\text{\tiny{MC-HESS}}}\) and Hutchinson's method, and \(O(P)\) using \(\mathbf{G}_{t}^{\text{\tiny{LIN-EF}}}\).

#### e.4.6 Bog-lin-hess Diag, Moment

Applying Proposition 4.2 to Eqs. (256) and (257) gives the bog-lin-hess-diag.mom update

\[\mathbf{\mu}_{t} =\mathbf{\mu}_{t|t-1}+\alpha\mathbf{H}_{t}^{\intercal}\mathbf{R}_{t}^ {-1}(\mathbf{y}_{t}-\hat{\mathbf{y}}_{t}) \tag{258}\] \[\mathbf{\sigma}_{t}^{2} =\mathbf{\sigma}_{t|t-1}^{2}-\frac{\alpha}{2}\mathrm{diag}\left( \mathbf{H}_{t}^{\intercal}\mathbf{R}_{t}^{-1}\mathbf{H}_{t}\right) \tag{259}\]

This update takes \(O(C^{2}P)\).

#### e.4.7 Bbb Diag, Moment

Substituting Eqs. (234) to (237) into Eq. (34) gives the bbb-diag.mom

\[\mathbf{\mu}_{t,i} =\mathbf{\mu}_{t,i-1}+\alpha\mathbf{\sigma}_{t|t-1}^{-2}\left(\mathbf{\mu}_{t |t-1}-\mathbf{\mu}_{t,i-1}\right)+\alpha\mathbf{g}_{t,i} \tag{260}\] \[\mathbf{\sigma}_{t}^{2} =\mathbf{\sigma}_{t,i-1}^{2}+\frac{\alpha}{2}\left(\mathbf{\sigma}_{t,i-1} ^{-2}-\mathbf{\sigma}_{t|t-1}^{-2}\right)+\frac{\alpha}{2}\mathrm{diag}\left( \mathbf{G}_{t,i}\right) \tag{261}\]

This update takes \(O(MP)\) per iteration to estimate \(\mathbf{G}_{t}\) using \(\mathbf{G}_{t}^{\text{\tiny{MC-EF}}}\), \(O(NMP)\) per iteration using \(\mathbf{G}_{t}^{\text{\tiny{MC-HESS}}}\) and Hutchinson's method, and \(O(P)\) per iteration using \(\mathbf{G}_{t}^{\text{\tiny{LIN-EF}}}\).

This is similar to the original diagonal Gaussian method in [Blundell et al., 2015] except (1) they reparameterize \(\mathbf{\sigma}=\log(1+\exp(\mathbf{\rho}))\) (elementwise) and do GD on \((\mathbf{\mu},\mathbf{\rho})\) instead of \((\mathbf{\mu},\mathbf{\sigma}^{2})\), and (2) they use the reparameterization trick instead of Price's theorem for calculating the gradient with respect to \(\mathbf{\rho}\) (via \(\mathbf{\sigma}\)).

#### e.4.8 Bbb-lin-hess Diag, Moment

Applying Proposition 4.2 to Eqs. (260) and (261) gives the bbb-lin-hess-diag.mom update

\[\mathbf{\mu}_{t,i} =\mathbf{\mu}_{t,i-1}+\alpha\mathbf{\sigma}_{t|t-1}^{-2}\left(\mathbf{\mu}_{t |t-1}-\mathbf{\mu}_{t,i-1}\right)+\alpha\mathbf{H}_{t,i}^{\intercal}\mathbf{R}_{t,i}^{-1}(\mathbf{y}_{t}-\hat{\mathbf{y}}_{t,i}) \tag{262}\] \[\mathbf{\sigma}_{t}^{2} =\mathbf{\sigma}_{t,i-1}^{2}+\frac{\alpha}{2}\left(\mathbf{\sigma}_{t,i-1} ^{-2}-\mathbf{\sigma}_{t|t-1}^{-2}\right)-\frac{\alpha}{2}\mathrm{diag}\left( \mathbf{H}_{t,i}^{\intercal}\mathbf{R}_{t,i}^{-1}\mathbf{H}_{t,i}\right) \tag{263}\]

This update takes \(O(C^{2}P)\) per iteration.

### Diagonal plus low rank

Assume the prior is given by

\[q_{\mathbf{\psi}_{t|t-1}}\left(\mathbf{\theta}_{t}\right)=\mathcal{N}\left(\mathbf{\theta}_{ t}|\mathbf{\mu}_{t|t-1},\left(\mathbf{\Upsilon}_{t|t-1}+\mathbf{W}_{t|t-1}\mathbf{W}_{t|t-1}^{ \intercal}\right)^{-1}\right) \tag{264}\]with \(\mathbf{W}\in\mathbb{R}^{P\times R}\) and diagonal \(\boldsymbol{\Upsilon}_{t|t-1}\in\mathbb{R}^{P\times P}\). We sometimes abuse notation by writing \(\boldsymbol{\Upsilon}_{t|t-1}\) for the vector \(\mathrm{diag}\left(\boldsymbol{\Upsilon}_{t|t-1}\right)\) when the meaning is clear from context.

Substituting the DLR form in the gradients for the KL divergence derived in Appendix E.2 gives

\[\nabla_{\boldsymbol{\mu}_{t,i-1}}D_{\mathbb{KL}}\big{(}q_{\boldsymbol{ \psi}_{t,i-1}}|q_{\boldsymbol{\psi}_{t|t-1}}\big{)} =\left(\boldsymbol{\Upsilon}_{t|t-1}+\mathbf{W}_{t|t-1}\mathbf{W} _{t|t-1}^{\intercal}\right)\left(\boldsymbol{\mu}_{t,i-1}-\boldsymbol{\mu}_{ t|t-1}\right) \tag{265}\] \[\nabla_{\boldsymbol{\Sigma}_{t,i-1}}D_{\mathbb{KL}}\big{(}q_{ \boldsymbol{\psi}_{t,i-1}}|q_{\boldsymbol{\psi}_{t|t-1}}\big{)} =\tfrac{1}{2}\left(\boldsymbol{\Upsilon}_{t|t-1}-\boldsymbol{ \Upsilon}_{t,i-1}+\mathbf{W}_{t|t-1}\mathbf{W}_{t|t-1}^{\intercal}-\mathbf{W} _{t,i-1}\mathbf{W}_{t,i-1}^{\intercal}\right) \tag{266}\]

For any function \(\ell\) the chain rule gives

\[\nabla_{\boldsymbol{\Upsilon}_{t|t-1}}\ell =-\mathrm{diag}\left(\left(\boldsymbol{\Upsilon}_{t|t-1}+\mathbf{W }_{t|t-1}\mathbf{W}_{t|t-1}^{\intercal}\right)^{-1}\left(\nabla_{\boldsymbol{ \Sigma}_{t|t-1}}\ell\right)\left(\boldsymbol{\Upsilon}_{t|t-1}+\mathbf{W}_{t|t -1}\mathbf{W}_{t|t-1}^{\intercal}\right)^{-1}\right) \tag{267}\] \[\nabla_{\mathbf{W}_{t|t-1}}\ell =-2\left(\boldsymbol{\Upsilon}_{t|t-1}+\mathbf{W}_{t|t-1}\mathbf{ W}_{t|t-1}^{\intercal}\right)^{-1}\left(\nabla_{\boldsymbol{\Sigma}_{t|t-1}} \ell\right)\left(\boldsymbol{\Upsilon}_{t|t-1}+\mathbf{W}_{t|t-1}\mathbf{W}_{t |t-1}^{\intercal}\right)^{-1}\mathbf{W}_{t|t-1} \tag{268}\]

Therefore the gradients we need are

\[\nabla_{\boldsymbol{\mu}_{t,i-1}}\mathbb{E}_{\boldsymbol{\theta}_{ t}\sim q_{\boldsymbol{\psi}_{t,i-1}}}[\log p\left(\boldsymbol{y}_{t}|h_{t}\left( \boldsymbol{\theta}_{t}\right)\right)] =\boldsymbol{g}_{\boldsymbol{\psi}_{t,i}} \tag{269}\] \[\nabla_{\boldsymbol{\Upsilon}_{t,i-1}}\mathbb{E}_{\boldsymbol{ \theta}_{t}\sim q_{\boldsymbol{\psi}_{t,i-1}}}[\log p\left(\boldsymbol{y}_{t}|h _{t}\left(\boldsymbol{\theta}_{t}\right)\right)] =-\tfrac{1}{2}\mathrm{diag}\left(\begin{array}{c}\left( \boldsymbol{\Upsilon}_{t,i-1}+\mathbf{W}_{t,i-1}\mathbf{W}_{t,i-1}^{\intercal }\right)^{-1}\mathbf{G}_{t,i}\\ \times\left(\boldsymbol{\Upsilon}_{t,i-1}+\mathbf{W}_{t,i-1}\mathbf{W}_{t,i-1} ^{\intercal}\right)^{-1}\end{array}\right)\] (270) \[\nabla_{\mathbf{W}_{t,i-1}}\mathbb{E}_{\boldsymbol{\theta}_{t} \sim q_{\boldsymbol{\psi}_{t,i-1}}}[\log p\left(\boldsymbol{y}_{t}|h_{t}\left( \boldsymbol{\theta}_{t}\right)\right)] =-\left(\boldsymbol{\Upsilon}_{t,i-1}+\mathbf{W}_{t,i-1}\mathbf{ W}_{t,i-1}^{\intercal}\right)^{-1}\mathbf{G}_{t,i}\] \[\qquad\times\left(\boldsymbol{\Upsilon}_{t,i-1}+\mathbf{W}_{t,i- 1}\mathbf{W}_{t,i-1}^{\intercal}\right)^{-1}\mathbf{W}_{t,i-1} \tag{271}\]

and

\[\nabla_{\boldsymbol{\Upsilon}_{t,i-1}}D_{\mathbb{KL}}\big{(}q_{ \boldsymbol{\psi}_{t,i-1}}|q_{\boldsymbol{\psi}_{t|t-1}}\big{)}=\] \[\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad \qquad\qquad\qquad\qquad\qquad\qquad\times\left(\boldsymbol{\Upsilon}_{t,i-1}+ \mathbf{W}_{t,i-1}\mathbf{W}_{t,i-1}^{\intercal}\right)^{-1}\] (272) \[\nabla_{\mathbf{W}_{t,i-1}}D_{\mathbb{KL}}\big{(}q_{\boldsymbol{ \psi}_{t,i-1}}|q_{\boldsymbol{\psi}_{t|t-1}}\big{)}=\] \[\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad \qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad \qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad \qquad\qquad\qquad\qquad\qquad\qquadso that \(\mathbf{W}_{t,i}\) contains the top \(R\) singular vectors and values of the FC posterior and the diagonal is preserved: \(\mathrm{diag}\left(\mathbf{\Upsilon}_{t,i}+\mathbf{W}_{t,i}\mathbf{W}_{t,i}^{ \intercal}\right)=\mathrm{diag}\left(\tilde{\mathbf{\Sigma}}_{t,i}^{-1}\right)\). This approach works for mc-ef and lin-ef methods but not mc-hess, which we omit.

Finally, in the mc-ef methods we sample from the DLR prior using the routine in (Mishkin et al., 2018; Lambert et al., 2023) which takes \(O(R(R+M)P)\).

#### e.5.1 Bong Dlr

Substituting the DLR prior from Eq. (264) into the FC precision update from Eq. (121) and using the mc-ef approximation yields the posterior precision

\[\tilde{\mathbf{\Sigma}}_{t}^{-1} =\mathbf{\Upsilon}_{t|t-1}+\mathbf{W}_{t|t-1}\mathbf{W}_{t|t-1}^{ \intercal}-\mathbf{G}_{t}^{\textsc{mc-ef}} \tag{278}\] \[=\tilde{\mathbf{\Upsilon}}_{t}+\tilde{\mathbf{W}}_{t}\tilde{ \mathbf{W}}_{t}^{\intercal}\] (279) \[\tilde{\mathbf{\Upsilon}}_{t} =\mathbf{\Upsilon}_{t|t-1}\] (280) \[\tilde{\mathbf{W}}_{t} =\left[\mathbf{W}_{t|t-1},\frac{1}{\sqrt{M}}\hat{\mathbf{G}}_{t} ^{(1:M)}\right] \tag{281}\]

Note \(\tilde{\mathbf{W}}_{t}\in\mathbb{R}^{P\times(R+M)}\). Using this posterior precision in the mean update from Eq. (120) yields

\[\boldsymbol{\mu}_{t} =\boldsymbol{\mu}_{t|t-1}+\left(\mathbf{\Upsilon}_{t|t-1}+\tilde{ \mathbf{W}}_{t}\tilde{\mathbf{W}}_{t}^{\intercal}\right)^{-1}\boldsymbol{g}_{t} \tag{282}\] \[=\boldsymbol{\mu}_{t|t-1}+\left(\mathbf{\Upsilon}_{t|t-1}^{-1}- \mathbf{\Upsilon}_{t|t-1}^{-1}\tilde{\mathbf{W}}_{t}\left(\mathbf{I}_{R+M}+ \tilde{\mathbf{W}}_{t}^{\intercal}\mathbf{\Upsilon}_{t|t-1}^{-1}\tilde{\mathbf{ W}}_{t}\right)^{-1}\tilde{\mathbf{W}}_{t}^{\intercal}\mathbf{\Upsilon}_{t|t-1}^{-1} \right)\boldsymbol{g}_{t} \tag{283}\]

where the second line comes from the Woodbury identity and can be computed in \(O((R+M)^{2}P+(R+M)^{3})\). Applying the SVD projection gives

\[\mathbf{W}_{t} =\mathbf{U}_{t}\left[:.:R\right]\mathbf{\Lambda}_{t}\left[:R,:R\right] \tag{284}\] \[\mathbf{\Upsilon}_{t} =\mathbf{\Upsilon}_{t|t-1}+\mathrm{diag}\left(\tilde{\mathbf{W} }_{t}\tilde{\mathbf{W}}_{t}^{\intercal}-\mathbf{W}_{t}\mathbf{W}_{t}^{ \intercal}\right)\] (285) \[(\mathbf{U}_{t},\mathbf{\Lambda}_{t},\_) =\mathrm{SVD}\left(\tilde{\mathbf{W}}_{t}\right) \tag{286}\]

which takes \(O((R+M)^{2}P)\) for the SVD. Therefore the bong-mc-ef-dlr update is defined by Eqs. (281) and (283) to (286) and takes \(O((R+M)^{2}P+(R+M)^{3})\).

The bong-lin-ef-dlr update comes from replacing \(\frac{1}{\sqrt{M}}\hat{\mathbf{G}}_{t}^{(1:M)}\) with \(\boldsymbol{g}_{t}^{\textsc{lin}}\) in Eq. (281) and replacing \(\mathbf{I}_{R+M}\) with \(\mathbf{I}_{R+1}\) in Eq. (283). This update takes \(O((R+1)^{2}P+(R+1)^{3})\).

#### e.5.2 Bong-lin-hess Dlr (lo-fi)

Applying Proposition 4.2 to Eqs. (281) and (283) gives the bong-lin-hess-dlr update:

\[\boldsymbol{\mu}_{t} =\boldsymbol{\mu}_{t|t-1}+\left(\mathbf{\Upsilon}_{t|t-1}^{-1}- \mathbf{\Upsilon}_{t|t-1}^{-1}\tilde{\mathbf{W}}_{t}\left(\mathbf{I}_{R+C}+ \tilde{\mathbf{W}}_{t}^{\intercal}\mathbf{\Upsilon}_{t|t-1}^{-1}\tilde{ \mathbf{W}}_{t}\right)^{-1}\tilde{\mathbf{W}}_{t}^{\intercal}\mathbf{\Upsilon} _{t|t-1}^{-1}\right)\] \[\quad\quad\times\mathbf{H}_{t}^{\intercal}\mathbf{R}_{t}^{-1} \left(\boldsymbol{y}_{t}-\hat{\boldsymbol{y}}_{t}\right) \tag{287}\] \[\mathbf{W}_{t} =\mathbf{U}_{t}\left[:,:R\right]\mathbf{\Lambda}_{t}\left[:R,:R\right]\] (288) \[\mathbf{\Upsilon}_{t} =\mathbf{\Upsilon}_{t|t-1}+\mathrm{diag}\left(\tilde{\mathbf{W} }_{t}\tilde{\mathbf{W}}_{t}^{\intercal}-\mathbf{W}_{t}\mathbf{W}_{t}^{\intercal}\right)\] (289) \[(\mathbf{U}_{t},\mathbf{\Lambda}_{t},\_) =\mathrm{SVD}\left(\tilde{\mathbf{W}}_{t}\right)\] (290) \[\tilde{\mathbf{W}}_{t} =\left[\mathbf{W}_{t|t-1},\mathbf{H}_{t}^{\intercal}\mathbf{ \Lambda}_{t}^{\intercal}\right]\] (291) \[\mathbf{\Lambda}_{t} =\mathrm{chol}\left(\mathbf{R}_{t}^{-1}\right) \tag{292}\]

This is equivalent to lo-fi (Chang et al., 2023) and takes \(O((R+C)^{2}P+(R+C)^{3})\).

#### e.5.3 Blr Dlr (slang)

Substituting DLR forms for \(q_{\mathbf{\psi}_{t|t-1}}\) and \(q_{\mathbf{\psi}_{t,i-1}}\) into the FC precision update from Eq. (136) and using the mc-ef approximation yields the posterior precision

\[\tilde{\mathbf{\Sigma}}_{t,i}^{-1} =(1-\alpha)\left(\mathbf{\Upsilon}_{t,i-1}+\mathbf{W}_{t,i-1}\mathbf{W }_{t,i-1}^{\intercal}\right)+\alpha\left(\mathbf{\Upsilon}_{t|t-1}+\mathbf{W}_{t|t -1}\mathbf{W}_{t|t-1}^{\intercal}\right)-\alpha\mathbf{G}_{t,i}^{\textsc{mc- ef}} \tag{293}\] \[=\tilde{\mathbf{\Upsilon}}_{t,i}+\tilde{\mathbf{W}}_{t,i}\tilde{ \mathbf{W}}_{t,i}^{\intercal}\] (294) \[\tilde{\mathbf{\Upsilon}}_{t,i} =(1-\alpha)\,\mathbf{\Upsilon}_{t,i-1}+\alpha\mathbf{\Upsilon}_{t|t-1}\] (295) \[\tilde{\mathbf{W}}_{t,i} =\left[\sqrt{1-\alpha}\mathbf{W}_{t,i-1},\sqrt{\alpha}\mathbf{W} _{t|t-1},\sqrt{\frac{\alpha}{M}}\hat{\mathbf{G}}_{t,i}^{(1:M)}\right] \tag{296}\]

Note \(\tilde{\mathbf{W}}_{t}\in\mathbb{R}^{P\times(2R+M)}\). Using this posterior precision in the mean update from Eq. (135) yields

\[\mathbf{\mu}_{t,i} =\mathbf{\mu}_{t,i-1}+\alpha\left(\tilde{\mathbf{\Upsilon}}_{t,i}+\tilde{ \mathbf{W}}_{t,i}\tilde{\mathbf{W}}_{t,i}^{\intercal}\right)^{-1} \tag{297}\] \[\qquad\times\left(\left(\mathbf{\Upsilon}_{t|t-1}+\mathbf{W}_{t|t-1} \mathbf{W}_{t|t-1}^{\intercal}\right)\left(\mathbf{\mu}_{t|t-1}-\mathbf{\mu}_{t,i-1} \right)+\mathbf{g}_{t,i}\right)\] \[=\mathbf{\mu}_{t,i-1}+\alpha\left(\tilde{\mathbf{\Upsilon}}_{t,i}^{-1}- \tilde{\mathbf{\Upsilon}}_{t,i}^{-1}\tilde{\mathbf{W}}_{t,i}\left(\mathbf{I}_{2R+M }+\tilde{\mathbf{W}}_{t,i}^{\intercal}\tilde{\mathbf{\Upsilon}}_{t,i}^{-1}\tilde{ \mathbf{W}}_{t,i}\right)^{-1}\tilde{\mathbf{W}}_{t,i}^{\intercal}\tilde{\mathbf{ \Upsilon}}_{t,i}^{-1}\right)\] \[\qquad\times\left(\left(\mathbf{\Upsilon}_{t|t-1}+\mathbf{W}_{t|t-1} \mathbf{W}_{t|t-1}^{\intercal}\right)\left(\mathbf{\mu}_{t|t-1}-\mathbf{\mu}_{t,i-1} \right)+\mathbf{g}_{t,i}\right) \tag{298}\]

where the second line comes from the Woodbury identity and can be computed in \(O((2R+M)^{2}P+(2R+M)^{3})\). Applying the SVD projection gives

\[\mathbf{W}_{t,i} =\mathbf{U}_{t,i}\left[\mathbf{:},\mathbf{:}\,R\right]\mathbf{\Lambda} _{t,i}\left[\mathbf{:}\,\mathbf{:}\,R\right] \tag{299}\] \[\mathbf{\Upsilon}_{t,i} =\tilde{\mathbf{\Upsilon}}_{t,i}+\operatorname{diag}\left(\tilde{ \mathbf{W}}_{t,i}\tilde{\mathbf{W}}_{t,i}^{\intercal}-\mathbf{W}_{t,i}\mathbf{ W}_{t,i}^{\intercal}\right)\] (300) \[(\mathbf{U}_{t,i},\mathbf{\Lambda}_{t,i},\_) =\operatorname{SVD}\left(\tilde{\mathbf{W}}_{t,i}\right) \tag{301}\]

which takes \(O((2R+M)^{2}P)\) for the SVD. Therefore the blr-mc-ef-dlr update is defined by Eqs. (295), (296) and (298) to (301) and takes \(O((2R+M)^{2}P+(2R+M)^{3})\) per iteration. Notice \(\tilde{\mathbf{W}}_{t}\) has larger rank for blr than for bong (\(2R+M\) vs. \(R+M\)) because of the extra \(\sqrt{\alpha}\mathbf{W}_{t|t-1}\) term that originates in the KL part of the VI loss. This difference will slow blr-mc-ef-dlr relative to bong-mc-ef-dlr especially when \(R\) is not small relative to \(M\).

This method closely resembles slang Mishkin et al. (2018) in the batch setting where we replace \(q_{\mathbf{\psi}_{t|t-1}}\) with a spherical prior \(\mathcal{N}(\mathbf{0},\lambda^{-1}\mathbf{I}_{P})\) (see Appendix E.6).

We can also define a blr-lin-ef-dlr method by replacing \(\sqrt{\frac{\alpha}{M}}\hat{\mathbf{G}}_{t}^{(1:M)}\) with \(\sqrt{\alpha}\mathbf{g}_{t}^{\textsc{lm}}\) in Eq. (296) and \(\mathbf{I}_{2R+M}\) with \(\mathbf{I}_{2R+1}\) in Eq. (298). This update takes \(O((2R+1)^{2}P+(2R+1)^{3})\) per iteration.

#### e.5.4 Blr-lin-hess Dlr

Applying Proposition 4.2 to Eqs. (296) and (298) gives the blr-lin-hess-dlr update:

\[\mathbf{\mu}_{t,i} =\mathbf{\mu}_{t,i-1}+\alpha\left(\tilde{\mathbf{\Upsilon}}_{t,i}^{-1}- \tilde{\mathbf{\Upsilon}}_{t,i}^{-1}\tilde{\mathbf{W}}_{t,i}\left(\mathbf{I}_{2R+ C}+\tilde{\mathbf{W}}_{t,i}^{\intercal}\tilde{\mathbf{\Upsilon}}_{t,i}^{-1}\tilde{ \mathbf{W}}_{t,i}\right)^{-1}\tilde{\mathbf{W}}_{t,i}^{\intercal}\tilde{\mathbf{ \Upsilon}}_{t,i}^{-1}\right) \tag{302}\] \[\qquad\times\left(\left(\mathbf{\Upsilon}_{t|t-1}+\mathbf{W}_{t|t-1} \mathbf{W}_{t|t-1}^{\intercal}\right)\left(\mathbf{\mu}_{t|t-1}-\mathbf{\mu}_{t,i-1} \right)+\mathbf{H}_{t,i}^{\intercal}\mathbf{R}_{t,i}^{-1}\left(\mathbf{y}_{t}- \hat{\mathbf{y}}_{t,i}\right)\right)\] \[\mathbf{W}_{t,i} =\mathbf{U}_{t,i}\left[\mathbf{:},\mathbf{:}\,R\right]\mathbf{\Lambda }_{t,i}\left[\mathbf{:}\,\mathbf{:}\,R,\mathbf{:}\,R\right]\] (303) \[\mathbf{\Upsilon}_{t,i} =\tilde{\mathbf{\Upsilon}}_{t,i}+\operatorname{diag}\left(\tilde{ \mathbf{W}}_{t,i}\tilde{\mathbf{W}}_{t,i}^{\intercal}-\mathbf{W}_{t,i}\mathbf{ W}_{t,i}^{\intercal}\right)\] (304) \[(\mathbf{U}_{t,i},\mathbf{\Lambda}_{t,i},\_) =\operatorname{SVD}\left(\tilde{\mathbf{W}}_{t,i}\right)\] (305) \[\tilde{\mathbf{W}}_{t,i} =\left[\sqrt{1-\alpha}\mathbf{W}_{t,i-1},\sqrt{\alpha}\mathbf{W }_{t|t-1},\sqrt{\alpha}\mathbf{H}_{t,i}^{\intercal}\mathbf{\Lambda}_{t,i}^{ \intercal}\right]\] (306) \[\mathbf{A}_{t,i} =\operatorname{chol}\left(\mathbf{R}_{t,i}^{-1}\right)\] (307) \[\tilde{\mathbf{\Upsilon}}_{t,i} =(1-\alpha)\,\mathbf{\Upsilon}_{t,i-1}+\alpha\mathbf{\Upsilon}_{t|t-1} \tag{308}\]This update takes \(O((2R+C)^{2}P+(2R+C)^{3})\) per iteration. As with the ef versions of blr-dlr, \(\hat{\mathbf{W}}_{t}\) has larger rank for blr-lin-hess-dlr than for bong-lin-hess-dlr (\(2R+C\) vs. \(R+C\)). This difference will slow blr-lin-hess-dlr relative to bong-lin-hess-dlr especially when \(R\) is not small relative to \(C\).

#### e.5.5 Bog Dlr

Substituting Eqs. (269) to (271) into Eq. (31) gives the bog-dlr update

\[\boldsymbol{\mu}_{t} =\boldsymbol{\mu}_{t|t-1}+\alpha\boldsymbol{g}_{t} \tag{309}\] \[\boldsymbol{\Upsilon}_{t} =\boldsymbol{\Upsilon}_{t|t-1}-\frac{\alpha}{2}\mathrm{diag} \left(\left(\boldsymbol{\Upsilon}_{t|t-1}+\mathbf{W}_{t|t-1}\mathbf{W}_{t|t-1} ^{\intercal}\right)^{-1}\mathbf{G}_{t}\left(\boldsymbol{\Upsilon}_{t|t-1}+ \mathbf{W}_{t|t-1}\mathbf{W}_{t|t-1}^{\intercal}\right)^{-1}\right)\] (310) \[\mathbf{W}_{t} =\mathbf{W}_{t|t-1}-\alpha\left(\boldsymbol{\Upsilon}_{t|t-1}+ \mathbf{W}_{t|t-1}\mathbf{W}_{t|t-1}^{\intercal}\right)^{-1}\mathbf{G}_{t} \left(\boldsymbol{\Upsilon}_{t|t-1}+\mathbf{W}_{t|t-1}\mathbf{W}_{t|t-1}^{ \intercal}\right)^{-1}\mathbf{W}_{t|t-1} \tag{311}\]

Using the EF approximation and Woodbury, the bog-mc-ef-dlr update can be rewritten as

\[\boldsymbol{\Upsilon}_{t} =\boldsymbol{\Upsilon}_{t|t-1}+\frac{\alpha}{2M}\mathrm{diag} \left(\mathbf{B}_{t}\mathbf{B}_{t}^{\intercal}\right) \tag{312}\] \[\mathbf{W}_{t} =\mathbf{W}_{t|t-1}+\frac{\alpha}{M}\mathbf{B}_{t}\mathbf{B}_{t} ^{\intercal}\mathbf{W}_{t|t-1}\] (313) \[\mathbf{B}_{t} =\left(\boldsymbol{\Upsilon}_{t|t-1}^{-1}-\boldsymbol{\Upsilon}_{ t|t-1}^{-1}\mathbf{W}_{t|t-1}\left(\mathbf{I}_{R}+\mathbf{W}_{t|t-1}^{\intercal }\boldsymbol{\Upsilon}_{t|t-1}^{-1}\mathbf{W}_{t|t-1}\right)^{-1}\mathbf{W}_{ t|t-1}^{\intercal}\boldsymbol{\Upsilon}_{t|t-1}^{-1}\right)\hat{\mathbf{G}}_{t}^{(1:M)} \tag{314}\]

which takes \(O(RMP+MR^{2}+R^{3})\).

The bog-lin-ef-dlr update comes from replacing \(\hat{\mathbf{G}}_{t}^{(1:M)}\) with \(\boldsymbol{g}_{t}^{\text{\tiny{LIN}}}\) in Eq. (314) and dropping the \(M^{-1}\) factors in Eqs. (312) and (313). This update takes \(O(RP+R^{3})\).

#### e.5.6 Bog-lin-hess Dlr

Applying Proposition 4.2 to Eqs. (309) and (312) to (314) gives the bog-lin-hess-dlr update

\[\boldsymbol{\mu}_{t} =\boldsymbol{\mu}_{t|t-1}+\alpha\mathbf{H}_{t}^{\intercal}\mathbf{ R}_{t}^{-1}(\boldsymbol{y}_{t}-\hat{\boldsymbol{y}}_{t}) \tag{315}\] \[\boldsymbol{\Upsilon}_{t} =\boldsymbol{\Upsilon}_{t|t-1}+\frac{\alpha}{2}\mathrm{diag} \left(\mathbf{B}_{t}\mathbf{B}_{t}^{\intercal}\right)\] (316) \[\mathbf{W}_{t} =\mathbf{W}_{t|t-1}+\alpha\mathbf{B}_{t}\mathbf{B}_{t}^{\intercal }\mathbf{W}_{t|t-1}\] (317) \[\mathbf{B}_{t} =\left(\boldsymbol{\Upsilon}_{t|t-1}^{-1}-\boldsymbol{\Upsilon}_ {t|t-1}^{-1}\mathbf{W}_{t|t-1}\left(\mathbf{I}_{R}+\mathbf{W}_{t|t-1}^{\intercal }\boldsymbol{\Upsilon}_{t|t-1}^{-1}\mathbf{W}_{t|t-1}\right)^{-1}\mathbf{W}_{t| t-1}^{\intercal}\boldsymbol{\Upsilon}_{t|t-1}^{-1}\right)\mathbf{H}_{t}^{\intercal}\mathbf{A}_{t}^{\intercal} \tag{318}\]

This update takes \(O(C(C+R)P+CR^{2}+R^{3})\).

#### e.5.7 Bbb Dlr

Substituting Eqs. (265) and (269) to (273) into Eq. (34) gives the bbb-dlr update

\[\boldsymbol{\mu}_{t,i} =\boldsymbol{\mu}_{t,i-1}+\alpha\left(\boldsymbol{\Upsilon}_{t|t- 1}+\mathbf{W}_{t|t-1}\mathbf{W}_{t|t-1}^{\intercal}\right)\left(\boldsymbol{ \mu}_{t|t-1}-\boldsymbol{\mu}_{t,i-1}\right)+\alpha\boldsymbol{g}_{t} \tag{319}\] \[\boldsymbol{\Upsilon}_{t,i} =\boldsymbol{\Upsilon}_{t,i-1}\] \[\quad+\frac{\alpha}{2}\mathrm{diag}\left(\boldsymbol{\Sigma}_{t,i-1}\left(\boldsymbol{\Upsilon}_{t|t-1}-\boldsymbol{\Upsilon}_{t,i-1}+ \mathbf{W}_{t|t-1}\mathbf{W}_{t|t-1}^{\intercal}-\mathbf{W}_{t,i-1}\mathbf{W}_ {t,i-1}^{\intercal}-\mathbf{G}_{t,i}\right)\boldsymbol{\Sigma}_{t,i-1}\right)\] (320) \[\mathbf{W}_{t,i} =\mathbf{W}_{t,i-1}\] \[\quad+\alpha\boldsymbol{\Sigma}_{t,i-1}\left(\boldsymbol{\Upsilon}_ {t|t-1}-\boldsymbol{\Upsilon}_{t,i-1}+\mathbf{W}_{t|t-1}\mathbf{W}_{t|t-1}^{ \intercal}-\mathbf{W}_{t,i-1}\mathbf{W}_{t,i-1}^{\intercal}-\mathbf{G}_{t,i} \right)\boldsymbol{\Sigma}_{t,i-1}\mathbf{W}_{t,i-1} \tag{321}\]The previous covariance can be written using Woodbury as

\[\mathbf{\Sigma}_{t,i-1}=\mathbf{\Upsilon}_{t,i-1}^{-1}-\mathbf{\Upsilon}_{t,i-1}^{-1}\mathbf{W }_{t,i-1}\left(\mathbf{I}_{R}+\mathbf{W}_{t,i-1}^{\intercal}\mathbf{\Upsilon}_{t,i-1 }^{-1}\mathbf{W}_{t,i-1}\right)^{-1}\mathbf{W}_{t,i-1}^{\intercal}\mathbf{\Upsilon }_{t,i-1}^{-1} \tag{322}\]

The bbb-mc-ef-dlr update can be computed efficiently by expanding terms in Eqs. (320) to (322). For example the terms involving \(\mathbf{G}_{t,i}\) can be calculated as

\[\mathrm{diag}\left(-\mathbf{\Sigma}_{t,i-1}\mathbf{G}_{t,i}^{\text{ MC-ef}}\mathbf{\Sigma}_{t,i-1}\right) =\frac{1}{M}\mathrm{diag}\left(\begin{array}{c}\mathbf{\Upsilon}_{t -1}^{-1}\hat{\mathbf{G}}_{t,i}^{(1:M)}\hat{\mathbf{G}}_{t,i}^{(1:M)^{\intercal }}\mathbf{\Upsilon}_{t,i-1}^{-1}\\ -\mathbf{\Upsilon}_{t,i-1}^{-1}\hat{\mathbf{G}}_{t,i}^{(1:M)}\mathbf{\Upsilon}_{t,i-1} ^{\intercal}+\mathbf{B}_{t,i}\mathbf{B}_{t,i}^{\intercal}\\ -\mathbf{\Sigma}_{t,i-1}\hat{\mathbf{G}}_{t,i}^{(1:M)^{\intercal}}\mathbf{\Upsilon}_{t,i-1}^{-1}+\mathbf{B}_{t,i}\mathbf{B}_{t,i}^{\intercal}\end{array}\right) \tag{323}\] \[-\mathbf{\Sigma}_{t,i-1}\mathbf{G}_{t,i}^{\text{MC-ef}}\mathbf{\Sigma}_{t,i-1}\mathbf{W}_{t,i-1} =\frac{1}{M}\mathbf{\Upsilon}_{t,i-1}^{-1}\hat{\mathbf{G}}_{t,i}^{(1: M)}\hat{\mathbf{G}}_{t,i}^{(1:M)^{\intercal}}\mathbf{\Upsilon}_{t,i-1}^{-1}\mathbf{W}_{t,i-1}\] \[\quad-\frac{1}{M}\mathbf{\Upsilon}_{t,i-1}^{-1}\hat{\mathbf{G}}_{t,i}^ {(1:M)}\mathbf{B}_{t,i}^{\intercal}\mathbf{W}_{t,i-1}\] \[\quad-\frac{1}{M}\mathbf{B}_{t,i}\hat{\mathbf{G}}_{t,i}^{(1:M)^{ \intercal}}\mathbf{\Upsilon}_{t,i-1}^{-1}\mathbf{W}_{t,i-1}+\frac{1}{M}\mathbf{B}_ {t,i}\mathbf{B}_{t,i}^{\intercal}\mathbf{W}_{t,i-1}\] (324) \[\mathbf{B}_{t,i} =\mathbf{\Upsilon}_{t,i-1}^{-1}\mathbf{W}_{t,i-1}\left(\mathbf{I}_{R }+\mathbf{W}_{t,i-1}^{\intercal}\mathbf{\Upsilon}_{t,i-1}^{-1}\mathbf{W}_{t,i-1} \right)^{-1}\] \[\quad\times\mathbf{W}_{t,i-1}^{\intercal}\mathbf{\Upsilon}_{t,i-1}^{- 1}\hat{\mathbf{G}}_{t,i}^{(1:M)} \tag{325}\]

Using this strategy the update takes \(O((R+M)RP+MR^{2}+R^{3})\).

The bbb-lin-ef-dlr update comes from replacing \(\hat{\mathbf{G}}_{t}^{(1:M)}\) with \(\mathbf{g}_{t}^{\text{\tiny IN}}\) and dropping the \(M^{-1}\) factors in Eqs. (323) to (325). This update takes \(O(R^{2}P+R^{3})\).

#### e.5.8 Bbb-lin-hess Dlr

Applying Proposition 4.2 to Eqs. (319) to (321) gives the bbb-lin-hess-dlr update

\[\mathbf{\mu}_{t,i} =\mathbf{\mu}_{t,i-1}+\alpha\left(\mathbf{\Upsilon}_{t|t-1}+\mathbf{W}_{ t|t-1}\mathbf{W}_{t|t-1}^{\intercal}\right)\left(\mathbf{\mu}_{t|t-1}-\mathbf{\mu}_{t,i-1 }\right)+\alpha\mathbf{H}_{t,i}^{\intercal}\mathbf{R}_{t,i}^{-1}(\mathbf{y}_{t}- \hat{\mathbf{y}}_{t,i}) \tag{326}\] \[\mathbf{\Upsilon}_{t,i} =\mathbf{\Upsilon}_{t,i-1}+\frac{\alpha}{2}\mathrm{diag}\left(\mathbf{ \Sigma}_{t,i-1}\left(\begin{array}{c}\mathbf{\Upsilon}_{t|t-1}-\mathbf{\Upsilon}_{t,i-1}+\mathbf{W}_{t|t-1}\mathbf{W}_{t|t-1}^{\intercal}\\ -\mathbf{W}_{t,i-1}\mathbf{W}_{t,i-1}^{\intercal}+\mathbf{H}_{t,i}^{\intercal} \mathbf{R}_{t,i}^{-1}\mathbf{H}_{t,i}\end{array}\right)\mathbf{\Sigma}_{t,i-1}\right)\] (327) \[\mathbf{W}_{t,i} =\mathbf{W}_{t,i-1}+\alpha\mathbf{\Sigma}_{t,i-1}\left(\begin{array} []{c}\mathbf{\Upsilon}_{t|t-1}-\mathbf{\Upsilon}_{t,i-1}+\mathbf{W}_{t|t-1}\mathbf{W} _{t|t-1}^{\intercal}\\ -\mathbf{W}_{t,i-1}\mathbf{W}_{t,i-1}^{\intercal}+\mathbf{H}_{t,i}^{\intercal} \mathbf{R}_{t,i}^{-1}\mathbf{H}_{t,i}\end{array}\right)\mathbf{\Sigma}_{t,i-1} \mathbf{W}_{t,i-1} \tag{328}\]

This can be computed in \(O((C+R)^{2}P+CR^{2}+R^{3})\) using Eq. (322) and following a computational approach similar to Eqs. (323) to (325).

### Batch blr

It is interesting to translate the blr updates derived here back to the batch setting where blr was developed [111], by replacing \(\mathcal{N}\left(\mathbf{\mu}_{t|t-1},\mathbf{\Sigma}_{t|t-1}\right)\) with a centered spherical prior \(\mathcal{N}\left(\mathbf{0},\lambda^{-1}\mathbf{I}_{P}\right)\).

The batch blr-fc update becomes

\[\mathbf{\mu}_{i} =\mathbf{\mu}_{i-1}+\alpha\mathbf{\Sigma}_{i}\left(\mathbf{g}_{i}-\lambda\mathbf{ \mu}_{i-1}\right) \tag{329}\] \[\mathbf{\Sigma}_{i}^{-1} =(1-\alpha)\mathbf{\Sigma}_{i-1}^{-1}+\alpha\left(\lambda\mathbf{I}_ {P}-\mathbf{G}_{i}\right) \tag{330}\]

The batch blr-lin-hess-fc update becomes

\[\mathbf{\mu}_{i} =\mathbf{\mu}_{i-1}+\alpha\mathbf{\Sigma}_{i}\left(\mathbf{h}_{i}^{\intercal }\mathbf{R}_{i}^{-1}(\mathbf{y}_{t}-\hat{\mathbf{y}}_{i})-\lambda\mathbf{\mu}_{i-1}\right) \tag{331}\] \[\mathbf{\Sigma}_{i}^{-1} =(1-\alpha)\mathbf{\Sigma}_{i-1}^{-1}+\alpha\left(\lambda\mathbf{I}_ {P}+\mathbf{H}_{i}^{\intercal}\mathbf{R}_{i}^{-1}\mathbf{H}_{i}\right) \tag{332}\]

The batch blr-fc_mom update becomes

\[\mathbf{\mu}_{i} =\mathbf{\mu}_{i-1}+\alpha\mathbf{\Sigma}_{i-1}\left(\mathbf{g}_{i}-\lambda\bm {\mu}_{i-1}\right) \tag{333}\] \[\mathbf{\Sigma}_{i} =(1+\alpha)\mathbf{\Sigma}_{i-1}+\alpha\mathbf{\Sigma}_{i-1}\left(\mathbf{ G}_{i}-\lambda\mathbf{I}_{P}\right)\mathbf{\Sigma}_{i-1} \tag{334}\]The batch blr-lin-hess-fcc.mom update becomes

\[\mathbf{\mu}_{i} =\mathbf{\mu}_{i-1}+\alpha\mathbf{\Sigma}_{i-1}\left(\mathbf{H}_{i}^{\intercal }\mathbf{R}_{i}^{-1}(\mathbf{y}_{t}-\hat{\mathbf{y}}_{i})-\lambda\mathbf{\mu}_{i-1}\right) \tag{335}\] \[\mathbf{\Sigma}_{i} =(1+\alpha)\mathbf{\Sigma}_{i-1}-\alpha\mathbf{\Sigma}_{i-1}\left(\lambda \mathbf{I}_{P}+\mathbf{H}_{i}^{\intercal}\mathbf{R}_{i}^{-1}\mathbf{H}_{i} \right)\mathbf{\Sigma}_{i-1} \tag{336}\]

The batch blr-diag update becomes

\[\mathbf{\mu}_{i} =\mathbf{\mu}_{i-1}+\alpha\mathbf{\sigma}_{i}^{2}\left(\mathbf{g}_{i}-\lambda \mathbf{\mu}_{i-1}\right) \tag{337}\] \[\mathbf{\sigma}_{i}^{-2} =(1-\alpha)\mathbf{\sigma}_{i-1}^{-2}+\alpha\operatorname{diag}\left( \lambda\mathbf{I}_{P}-\mathbf{G}_{i}\right) \tag{338}\]

The mc-hess version of this update is equivalent to von(Khan et al., 2018b) if we use MC approximation with \(M=1\). The mc-ef version with \(M=1\) is equivalent to vogn(Khan et al., 2018b).

The batch blr-lin-hess-diag update becomes

\[\mathbf{\mu}_{i} =\mathbf{\mu}_{i-1}+\alpha\mathbf{\sigma}_{i}^{2}\left(\mathbf{g}_{i}-\lambda \mathbf{\mu}_{i-1}\right) \tag{339}\] \[\mathbf{\sigma}_{i}^{-2} =(1-\alpha)\mathbf{\sigma}_{i-1}^{-2}+\alpha\operatorname{diag}\left( \lambda\mathbf{I}_{P}+\mathbf{H}_{i}^{\intercal}\mathbf{R}_{i}^{-1}\mathbf{H}_ {i}\right) \tag{340}\]

The batch blr-diag.mom update becomes

\[\mathbf{\mu}_{i} =\mathbf{\mu}_{i-1}+\alpha\mathbf{\sigma}_{i-1}^{2}\left(\mathbf{g}_{i}- \lambda\mathbf{\mu}_{i-1}\right) \tag{341}\] \[\mathbf{\sigma}_{i}^{2} =(1+\alpha)\mathbf{\sigma}_{i-1}^{2}-\alpha\mathbf{\sigma}_{i-1}^{4} \operatorname{diag}\left(\mathbf{G}_{i}-\lambda\mathbf{I}_{P}\right) \tag{342}\]

The batch blr-lin-hess-diag.mom update becomes

\[\mathbf{\mu}_{i} =\mathbf{\mu}_{i-1}+\alpha\mathbf{\sigma}_{i-1}^{2}\left(\mathbf{H}_{i}^{ \intercal}\mathbf{R}_{i}^{-1}(\mathbf{y}_{t}-\hat{\mathbf{y}}_{i})-\lambda\mathbf{\mu}_{i- 1}\right) \tag{343}\] \[\mathbf{\sigma}_{i}^{2} =(1+\alpha)\mathbf{\sigma}_{i-1}^{2}-\alpha\mathbf{\sigma}_{i-1}^{4} \operatorname{diag}\left(\lambda\mathbf{I}_{P}+\mathbf{H}_{i}^{\intercal} \mathbf{R}_{i}^{-1}\mathbf{H}_{i}\right) \tag{344}\]

The batch blr-dlr update becomes

\[\mathbf{\mu}_{i} =\mathbf{\mu}_{i-1}+\alpha\left(\widehat{\mathbf{\Upsilon}}_{i}^{-1}- \widehat{\mathbf{\Upsilon}}_{i}^{-1}\tilde{\mathbf{W}}_{i}\left(\mathbf{I}_{R +M}+\tilde{\mathbf{W}}_{i}^{\intercal}\widehat{\mathbf{\Upsilon}}_{i}^{-1} \tilde{\mathbf{W}}_{i}\right)^{-1}\tilde{\mathbf{W}}_{i}^{\intercal}\widehat{ \mathbf{\Upsilon}}_{i}^{-1}\right)\] \[\quad\times\left(\mathbf{g}_{t}-\lambda\mathbf{\mu}_{i-1}\right) \tag{345}\] \[\mathbf{W}_{i} =\mathbf{U}_{i}\left[::R\right]\mathbf{\Lambda}_{i}\left[:R,:R\right]\] (346) \[\mathbf{\Upsilon}_{i} =\widehat{\mathbf{\Upsilon}}_{i}+\operatorname{diag}\left( \tilde{\mathbf{W}}_{i}\tilde{\mathbf{W}}_{i}^{\intercal}-\mathbf{W}_{i} \mathbf{W}_{i}^{\intercal}\right)\] (347) \[(\mathbf{U}_{i},\mathbf{\Lambda}_{i},\_{-}) =\operatorname{SVD}\left(\tilde{\mathbf{W}}_{i}\right)\] (348) \[\tilde{\mathbf{W}}_{i} =\left[\sqrt{1-\alpha}\mathbf{W}_{i-1},\sqrt{\frac{\alpha}{M}} \tilde{\mathbf{G}}_{i}^{(1:M)}\right]\] (349) \[\mathbf{A}_{i} =\operatorname{chol}\left(\mathbf{R}_{i}^{-1}\right)\] (350) \[\tilde{\mathbf{\Upsilon}}_{i} =(1-\alpha)\mathbf{\Upsilon}_{i-1}+\alpha\lambda\mathbf{I}_{P} \tag{351}\]

This is equivalent to slang except for the following differences. Slang processes a minibatch of \(M\) examples at each iteration, using a single sample \(\tilde{\mathbf{\theta}}\sim q_{\phi_{i-1}}\) for each minibatch. It uses a different SVD routine which is slightly faster but stochastic, taken from (Halko et al., 2011). Most significantly, slang applies the SVD before the mean update, meaning \(\mathbf{\mu}_{i}\) is calculated using the rank-\(R\)\(\mathbf{W}_{i}\) and \(\mathbf{\Upsilon}_{i}\) instead of the rank-\((R+M)\)\(\tilde{\mathbf{W}}_{i}\) and \(\widehat{\mathbf{\Upsilon}}_{i}\), thus ignoring the non-diagonal information in the \(M\) discarded singular vectors from \(\tilde{\mathbf{W}}_{i}\).

The batch blr-lin-hess-dlr update becomes

\[\boldsymbol{\mu}_{i} =\boldsymbol{\mu}_{i-1}+\alpha\left(\tilde{\boldsymbol{\Upsilon}}_{i }^{-1}-\tilde{\boldsymbol{\Upsilon}}_{i}^{-1}\tilde{\boldsymbol{\Psi}}_{i} \left(\mathbf{I}_{R+C}+\tilde{\boldsymbol{\Psi}}_{i}^{\intercal}\tilde{ \boldsymbol{\Upsilon}}_{i}^{-1}\tilde{\boldsymbol{\Psi}}_{i}\right)^{-1}\tilde {\boldsymbol{\Psi}}_{i}^{\intercal}\tilde{\boldsymbol{\Upsilon}}_{i}^{-1}\right)\] \[\qquad\times\left(\mathbf{H}_{i}^{\intercal}\mathbf{R}_{i}^{-1}( \boldsymbol{y}_{t}-\hat{\boldsymbol{y}}_{i})-\lambda\boldsymbol{\mu}_{i-1}\right) \tag{352}\] \[\mathbf{W}_{i} =\mathbf{U}_{i}\left[:,:R\right]\boldsymbol{\Lambda}_{i}\left[:R,:R\right]\] (353) \[\boldsymbol{\Upsilon}_{i} =\tilde{\boldsymbol{\Upsilon}}_{i}+\operatorname{diag}\left( \tilde{\boldsymbol{\Psi}}_{i}\tilde{\boldsymbol{\Psi}}_{i}^{\intercal}-\mathbf{ W}_{i}\boldsymbol{\Psi}_{i}^{\intercal}\right)\] (354) \[(\mathbf{U}_{i},\boldsymbol{\Lambda}_{i},\_\)\()\)\(=\operatorname{SVD}\left(\tilde{\boldsymbol{\Psi}}_{i}\right)\] (355) \[\tilde{\mathbf{W}}_{i} =\left[\sqrt{1-\alpha}\mathbf{W}_{i-1},\sqrt{\alpha}\mathbf{H}_ {i}^{\intercal}\mathbf{A}_{i}^{\intercal}\right]\] (356) \[\mathbf{A}_{i} =\operatorname{chol}\left(\mathbf{R}_{i}^{-1}\right)\] (357) \[\tilde{\boldsymbol{\Upsilon}}_{i} =(1-\alpha)\boldsymbol{\Upsilon}_{i-1}+\alpha\lambda\mathbf{I}_{P} \tag{358}\]

This algorithm could be called slang-lin-hess and would be deterministic and faster than slang since it does not need MC sampling. We can also define slang-lin-ef which would be even faster, by replacing \(\sqrt{\frac{\alpha}{M}}\hat{\mathbf{G}}_{i}^{(1:M)}\) with \(\sqrt{\alpha}\boldsymbol{g}_{i}^{\text{\tiny{lin}}}\) in Eq. (349) and \(\mathbf{I}_{R+M}\) with \(\mathbf{I}_{R}\) in Eq. (345).

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: Section 1 states two main theoretical contributions (proved in Propositions 4.1 and 4.2 and summarizes the experiment findings reported in Section 5. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: We discuss limitations in Section 6. We report asymptotic efficiency in Table 3 and report actual running time in Fig. 4. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof?Answer: [Yes]

Justification: We state two formal theorems and provide complete proofs in Appendix C which we sketch in the main text in Sections 4.1 and 4.4.

Guidelines:

* The answer NA means that the paper does not include theoretical results.
* All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
* All assumptions should be clearly stated or referenced in the statement of any theorems.
* The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.
* Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.
* Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: We give pseudocode for the main methods in Appendix A and complete update equations for all algorithms in Appendix E. We give full details of the experiment methods in Section 5. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.

5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: We will post our code on github after the blind review period, including scripts for exactly reproducing all experiments. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines ([https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy)) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines ([https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy)) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: Section 5 provides links to the data and reports hyperparameters and architecture details. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: Plots show \(\pm 1\) SE shading based on empirical SD across trials. Trials vary randomly in network initialization, data ordering and MC samples. This is stated in Section 5. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ** The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).
* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: We report running times. Experiments all run on any standard GPU/TPU so further details are not necessary. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics [https://neurips.cc/public/EthicsGuidelines?](https://neurips.cc/public/EthicsGuidelines?) Answer: [Yes] Justification: We have read the Code of Ethics and affirm our research adheres to all points therein. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [No] Justification: We believe there are no direct societal impacts (positive or negative) beyond the generic impacts of foundational work on training neural networks. Guidelines: ** The answer NA means that there is no societal impact of the work performed.
* If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.
* Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.
* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: The paper poses no such risks. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: We provide citations and URLs for the two datasets we use in Section 5. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. ** If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: There are no new data. As noted above, we will post our model code after the blind review period. Guidelines: * The answer NA means that the paper does not release new assets. * Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. * The paper should discuss whether and how consent was obtained from people whose asset is used. * At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. * According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.

* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.