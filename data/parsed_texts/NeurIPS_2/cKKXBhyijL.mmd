# No-Regret Bandit Exploration

based on Soft Tree Ensemble Model

Shogo Iwazaki

LY Corporation

Tokyo, Japan

siwazaki@ycorp.co.jp

&Shinya Suzumura

LY Corporation

Tokyo, Japan

suzumur@lycorp.co.jp

###### Abstract

We propose a novel stochastic bandit algorithm that employs reward estimates using a tree ensemble model. Specifically, our focus is on a soft tree model, a variant of the conventional decision tree that has undergone both practical and theoretical scrutiny in recent years. By deriving several non-trivial properties of soft trees, we extend the existing analytical techniques used for neural bandit algorithms to our soft tree-based algorithm. We demonstrate that our algorithm achieves a smaller cumulative regret compared to the existing ReLU-based neural bandit algorithms. We also show that this advantage comes with a trade-off: the hypothesis space of the soft tree ensemble model is more constrained than that of a ReLU-based neural network.

## 1 Introduction

The stochastic bandit framework is a powerful tool for addressing sequential decision-making tasks in uncertain environments. A significant challenge in applying stochastic bandits is managing large action spaces. For example, in recommendation systems, there is often a vast action space generated by various combinations of users and items [38]. Standard algorithms designed for finite-armed bandits are inadequate in these scenarios. Consequently, numerous studies have focused on structurally modeling the reward process and using limited observed data to estimate rewards for unobserved actions. These approaches include algorithms that employ estimation methods such as linear models [3, 5, 12], kernel regression [11, 32], and neural networks [30, 41], which are referred to as linear bandit (LB), kernel bandit (KB), and neural bandit (NB) respectively. The effectiveness of these algorithms largely depends on the accuracy of the underlying reward models. Therefore, developing the bandit algorithms that leverage suitable reward estimation models is crucial.

Motivated by these considerations, this paper explores the stochastic bandit algorithm using tree ensembles, a model type that has gained popularity following neural networks but remains relatively underexplored in the bandit context. Specifically, we focus on the soft tree ensemble model, which has recently been the subject of both practical and theoretical investigations and has demonstrated strong empirical performance on tabular data [18, 21, 22, 25, 28]. Unlike hard trees, which update decision rules greedily and sequentially, soft trees employ gradient descent to update decision rules for the entire tree. This characteristic of soft trees facilitates the extension of existing analyses of NB and ensures a no-regret performance under suitable assumptions.

Related works.In the field of stochastic bandits, prior research has established various structural assumptions about underlying rewards. For instance, the assumption of Lipschitz continuity of rewards is explored in Lipschitz bandits [8], linearity of rewards is examined in LB [3, 5, 12], and more generally, the assumption that rewards lie in a known reproducing kernel Hilbert space (RKHS) is studied in KB [11, 32].

Our paper studies a type of bandit algorithm that employs a tree structure model, a topic with limited prior exploration. Feraud et al. [15] proposed a bandit algorithm using random forests, but the theory of their algorithm exhibits linear dependence on the number of actions, making it unsuitable for large action spaces. Elmachtoub et al. [14] introduced a Thompson sampling-style algorithm utilizing decision trees; however, their algorithm's construction relies on heuristics and does not provide a regret guarantee.

Additionally, our theory is closely related to NB. Zhou et al. [41] proposed an upper confidence bound (UCB) algorithm using a deep neural net (DNN) regressor, and Zhang et al. [40] extended this analysis to Thompson sampling. Their analysis yields a regret upper bound of \(\tilde{\mathcal{O}}(\tilde{d}\sqrt{T})\), where \(\tilde{d}\) denotes the effective dimension of the problem, and \(\tilde{\mathcal{O}}(\cdot)\) represents an order notation that ignores logarithmic dependence. However, generally, DNNs employing ReLU activation functions lead to \(\tilde{d}=\tilde{\mathcal{O}}(T^{(d-1)/d})\), resulting in super-linear growth of \(\mathcal{O}(\tilde{d}\sqrt{T})\) regret, which becomes meaningless [23]. Several studies address this issue by employing algorithms in the form of a sup-variant of UCB [37] or phased elimination-style algorithms [7; 26], proving a regret upper bound of \(\tilde{\mathcal{O}}(T^{(2d-1)/(2d)})\)[23; 24; 30]. These studies combine theoretical analysis via the neural tangent kernel (NTK) [4; 19] for DNN regression with regret analysis techniques from KB, constructing algorithms and performing regret analysis. Our proposed algorithm can be seen as a generalization of NB theory using a soft-tree regressor from DNN.

Contributions.Our contributions are as follows:

* In Sec. 3.1, we introduce a new UCB-based algorithm: soft tree-based upper confidence bound (ST-UCB), which leverages the soft tree ensemble model. This algorithm can be considered an extension of the existing NN-UCB algorithm [41], incorporating the theory of the tree neural tangent kernel (TNTK) in soft trees [21; 22]. To our knowledge, this paper represents the first effort to extend the theory of NB to a tree-based structural model.
* In Sec. 3.2, we derive several non-trivial properties of the soft tree ensemble model. These include the decay rates of eigenvalues of the TNTK (Lemma 3.1), concentration properties of TNTK (Lemma 3.2), and upper bounds on the spectral norm of the Hessian matrix (Lemma 3.3). Leveraging these results, we demonstrate that the ST-UCB algorithm achieves a regret of \(\tilde{\mathcal{O}}(\sqrt{T})\) under appropriate regularity conditions.
* In Sec. 4, we elucidate the distinctions in properties and assumptions between the existing NN-UCB and ST-UCB algorithms. Specifically, while NN-UCB generally lacks a no-regret guarantee in general action (or context) spaces, ST-UCB consistently offers a no-regret guarantee across general action spaces. Additionally, we examine the relation between the hypothesis spaces induced by the TNTK and those induced by the NTK using ReLU activation. This comparison reveals that the hypothesis space derived from soft trees, although more constrained, may lead to lower regret.

## 2 Preliminaries

Problem setting.We consider a sequential decision-making problem whose goal is to maximize the total reward under bandit feedback. Let \(f:\mathcal{X}\rightarrow\mathbb{R}\) be an unknown reward function, where \(\mathcal{X}\subset\mathbb{R}^{d}\) is a finite set of action candidates. At each time step \(t\), the environment reveals an action set \(\mathcal{X}_{t}\subset\mathcal{X}\); thereafter, the learner chooses an action \(\mathbf{x}_{t}\) and receives the corresponding reward \(y_{t}=f(\mathbf{x}_{t})+\epsilon_{t}\), where \(\epsilon_{t}\) is a noise random variable whose mean is zero. As a performance metric, we adopt the pseudo cumulative regret \(R_{T}\coloneqq\sum_{t=1}^{T}\left[f(\mathbf{x}_{t}^{*})-f(\mathbf{x}_{t})\right]\), where \(\mathbf{x}_{t}^{*}\in\operatorname*{arg\,max}_{\mathbf{x}\in\mathcal{X}_{t}}f(\mathbf{x})\). In our problem setup, the action set \(\mathcal{X}_{t}\) is allowed to change at each step \(t\). In addition to the standard bandit setup that assumes \(\mathcal{X}_{t}=\mathcal{X}_{t}\), this formulation includes a contextual bandit setup by setting \(\mathcal{X}_{t}=\{(\mathbf{c}_{t},\mathbf{a})\mid\mathbf{a}\in\mathcal{A}(\mathbf{c}_{t})\}\), where \(\mathbf{c}_{t}\) is a context vector at step \(t\), and \(\mathcal{A}(\mathbf{c}_{t})\) is the corresponding action set.

Soft tree ensemble.At each time step \(t\), our algorithm constructs a soft tree-based estimator of the reward function \(f\). We describe the definition of soft trees based on Kanoh and Sugiyama [21]. Now, let us consider \(M\in\mathbb{N}_{+}\) perfect binary trees whose depths are \(\mathcal{D}\in\mathbb{N}_{+}\). Note that each tree has \(\mathcal{N}\coloneqq 2^{\mathcal{D}}-1\) internal nodes and \(\mathcal{L}\coloneqq 2^{\mathcal{D}}\) leaf nodes. Furthermore, for technical reasons, we assume that \(M\) is an even number. Let \(\mathbf{w}_{n}^{(m)}\in\mathbb{R}^{d}\) and \(\pi_{l}^{(m)}\in\mathbb{R}\) be the parameters of the \(n\)-th internal and \(l\)-th leaf node of the \(m\)-th tree, respectively. We index these parameters according to breadth-first ordering, as described in the left plot of Fig. 1. Moreover, we also denote all internal and leaf node parameters as \(\mathbf{w}^{(m)}\coloneqq(\mathbf{w}_{1}^{(m)\top},\ldots,\mathbf{w}_{\mathcal{N}}^{(m)\top })^{\top}\in\mathbb{R}^{\mathcal{X}d}\) and \(\mathbf{\pi}^{(m)}\coloneqq(\pi_{1}^{(m)},\ldots,\pi_{\mathcal{L}}^{(m)})^{\top} \in\mathbb{R}^{\mathcal{L}}\). The output of a standard decision tree is obtained as the parameter of some leaf node, which is chosen deterministically based on the hard-splitting rules of internal nodes. On the other hand, the output of the soft tree is given by replacing the hard-splitting operation of the standard decision tree with a probabilistic one. Specifically, given parameters \(\mathbf{\theta}^{(m)}\coloneqq(\mathbf{w}^{(m)\top},\mathbf{\pi}^{(m)\top})^{\top}\) and any input \(\mathbf{x}\in\mathcal{X}\), the corresponding output \(\tilde{h}(\mathbf{x};\mathbf{\theta}^{(m)})\) of the \(m\)-th soft tree is defined as

\[\tilde{h}(\mathbf{x};\mathbf{\theta}^{(m)})=\sum_{l=1}^{\mathcal{L}}\pi_{l}^{(m)}p_{l} (\mathbf{x};\mathbf{w}^{(m)}),\;\;\text{where}\;\;p_{l}(\mathbf{x};\mathbf{w})=\prod_{n=1}^{ \mathcal{N}}\sigma(\mathbf{w}_{n}^{\top}\mathbf{x})^{\mathds{1}_{l\sim^{n}}}\left[1- \sigma(\mathbf{w}_{n}^{\top}\mathbf{x})\right]^{\mathds{1}_{n\sim^{l}}}.\]

Here, \(\mathds{1}_{l\sim^{n}}\) and \(\mathds{1}_{n\sim^{l}}\) are indicator functions. If the \(l\)-th leaf node belongs to the left (resp. right) sub-tree whose root is the \(n\)-th internal node, \(\mathds{1}_{l\sim^{n}}\) (resp. \(\mathds{1}_{n\sim^{l}}\)) is one; otherwise, zero. Furthermore, \(\sigma(\cdot):\mathbb{R}\rightarrow[0,1]\) is a _soft_ decision function. The right plot of Fig. 1 shows an illustrative image of the calculation of \(p_{l}(\cdot)\). As with [21], we use the scaled error function \(\sigma(\mathbf{w}_{n}^{\top}\mathbf{x})\coloneqq\frac{1}{2}\text{erf}(\alpha\mathbf{w}_{n }^{\top}\mathbf{x})+\frac{1}{2}\) with some pre-specified scaling parameter \(\alpha\geq 0\), where \(\text{erf}(b)=\frac{2}{\sqrt{\pi}}\int_{0}^{b}\exp(-z^{2})\text{d}z\) for any \(b\in\mathbb{R}\). By aggregating \(M\) soft trees, the whole output \(h(\mathbf{x};\mathbf{\theta})\) of the soft tree ensemble model is defined as \(h(\mathbf{x};\mathbf{\theta})=\sum_{m=1}^{M}\tilde{h}(\mathbf{x};\mathbf{\theta}^{(m)})/\sqrt {M}\), where \(\mathbf{\theta}\coloneqq(\mathbf{\theta}^{(1)\top},\ldots,\mathbf{\theta}^{(M)\top})^{ \top}\in\mathbb{R}^{M(d\mathcal{N}+\mathcal{L})}\). Under the model structures as described above, the training of the model parameters \(\mathbf{\theta}\) is conducted based on the gradient descent optimizer, which aims to minimize some pre-specified loss functions. In our algorithm, we adopt a regularized square loss, whose detailed definition is given in Sec. 3.1.

Neural tangent kernel theory for overparameterized model.The neural tangent kernel (NTK) [19] is an effective theoretical tool for understanding the learning properties of overparameterized neural networks. Let \(h_{\text{NN}}(\cdot;\mathbf{\theta}):\mathbb{R}^{d}\rightarrow\mathbb{R}\) be a feed-forward neural network with a ReLU activation function, \(L\) hidden layers whose width is \(M\), and network parameters \(\mathbf{\theta}\). Given any fixed inputs \(\mathbf{x},\tilde{\mathbf{x}}\in\mathbb{R}^{d}\), and \(\tilde{\mathbf{\theta}}_{0}\sim\mathcal{N}(\mathbf{0},\mathbf{I})\), it has been shown that the inner product \(\langle\nabla_{\mathbf{\theta}}h_{\text{NN}}(\mathbf{x};\tilde{\mathbf{\theta}}_{0}), \nabla_{\mathbf{\theta}}h_{\text{NN}}(\tilde{\mathbf{x}};\tilde{\mathbf{\theta}}_{0})\rangle\) of gradients converges to a fixed kernel function \(k_{\text{NTK}}(\mathbf{x},\tilde{\mathbf{x}})\) (i.e., \(\langle\nabla_{\mathbf{\theta}}h_{\text{NN}}(\mathbf{x};\tilde{\mathbf{\theta}}_{0}),\nabla _{\mathbf{\theta}}h_{\text{NN}}(\tilde{\mathbf{x}};\tilde{\mathbf{\theta}}_{0})\rangle\)\(\xrightarrow{p}k_{\text{NTK}}(\mathbf{x},\tilde{\mathbf{x}})\) as \(M\rightarrow\infty\)). The kernel function \(k_{\text{NTK}}\) is called the NTK. Moreover, in the overparameterized regime, \(h_{\text{NN}}(\mathbf{x};\mathbf{\theta})\) trained with gradient descent with an infinitesimally small learning rate coincides with the kernel ridge-less regressor \(h_{\text{NTK}}(\mathbf{x})\), whose kernel function is \(k_{\text{NTK}}\)[4]. This property motivates us to analyze NB problems by bridging original NB to KB problems whose underlying kernel function is the NTK. Indeed, some existing works [23, 24, 30, 41] show the regret upper bound of NB problems by carefully combining NTK theory with existing theoretical tools of KB. In our paper, we consider soft tree variants of these existing works.

Recently, Kanoh and Sugiyama [21] generalized the NTK theory to the soft tree ensemble model. Let \(\mathbf{g}(\mathbf{x},\mathbf{\theta})\coloneqq\nabla_{\mathbf{\theta}}h(\mathbf{x};\mathbf{\theta})\in \mathbb{R}^{p}\) be the gradient vector of the soft tree ensemble model at parameter

Figure 1: An illustrative image of a soft tree structure with \(\mathcal{D}=3\). As shown in the left plot, we have \(\mathcal{N}\coloneqq 2^{\mathcal{D}}-1\) internal nodes (green) and \(\mathcal{L}\coloneqq 2^{\mathcal{D}}\) leaf nodes (orange), indexed using breadth-first ordering. The right plot shows an illustrative example where a soft tree calculates the weight probabilities \(p_{l}(\cdot)\) for the leaf nodes.

\(\mathbf{\theta}\in\mathbb{R}^{p}\), where \(p\coloneqq M(d\mathcal{N}+\mathcal{L})\) denotes the total number of parameters. Then, given fixed inputs \(\mathbf{x},\tilde{\mathbf{x}}\in\mathcal{X}\) and \(\tilde{\mathbf{\theta}}_{0}\sim\mathcal{N}(0,\mathbf{I}_{p})\), the inner product \(\langle\mathbf{g}(\mathbf{x},\tilde{\mathbf{\theta}}_{0}),\mathbf{g}(\tilde{\mathbf{x}},\tilde{\bm {\theta}}_{0})\rangle\) has also been shown to converge in probability to some kernel function \(k_{\text{TNTK}}(\mathbf{x},\tilde{\mathbf{x}})\) as the number of ensemble models \(M\) grows infinitely (see Theorem 1 in [21]). This limiting kernel \(k_{\text{TNTK}}\) is called the _tree neural tangent kernel_ (TNTK) as an analogy to the NTK and is defined as follows:

\[k_{\text{TNTK}}(\mathbf{x},\tilde{\mathbf{x}})=2^{\mathcal{D}}\mathbf{x}^{\top}\tilde{\mathbf{ x}}(\mathcal{T}(\mathbf{x},\tilde{\mathbf{x}}))^{\mathcal{D}-1}\dot{\mathcal{T}}(\mathbf{x}, \tilde{\mathbf{x}})+(2\mathcal{T}(\mathbf{x},\tilde{\mathbf{x}}))^{\mathcal{D}}, \tag{1}\]

where:

\[\mathcal{T}(\mathbf{x},\tilde{\mathbf{x}}) =\frac{1}{2\pi}\arcsin\left(\frac{\alpha^{2}\mathbf{x}^{\top}\tilde{ \mathbf{x}}}{\sqrt{(\alpha^{2}\mathbf{x}^{\top}\mathbf{x}+0.5)(\alpha^{2}\tilde{\mathbf{x}}^{ \top}\tilde{\mathbf{x}}+0.5)}}\right)+\frac{1}{4}, \tag{2}\] \[\dot{\mathcal{T}}(\mathbf{x},\tilde{\mathbf{x}}) =\frac{\alpha^{2}}{\pi}\frac{1}{\sqrt{(1+2\alpha^{2}\mathbf{x}^{\top} \mathbf{x})(1+2\alpha^{2}\tilde{\mathbf{x}}^{\top}\tilde{\mathbf{x}})-4\alpha^{4}(\mathbf{x}^{ \top}\tilde{\mathbf{x}})^{2}}}. \tag{3}\]

It should be noted that even if we follow the existing NTK-based techniques of NB, generalizing the result of Kanoh and Sugiyama [21] to the analysis of sequential decision-making tasks is non-trivial. Specifically, the existing analysis of NB heavily relies on the following results of ReLU-based NTK: i) non-asymptotic bounds of NTK [4], ii) the spectral properties of the Hessian matrix around the initial model parameters [27], and iii) the upper bounds of maximum information gain (MIG) of NTK [35], which measure the complexity of the KB problem depending on the underlying kernel. These results are unique to DNN architectures with a ReLU-based activation function and are not applicable to the soft tree ensemble model.

## 3 UCB strategy based on soft tree ensemble model

### Proposed algorithm: ST-UCB

The pseudo-code of our proposed algorithm, soft tree-based UCB (ST-UCB), is shown in Algorithm 1. ST-UCB is interpreted as the soft tree-based variant of NN-UCB [41]. We summarize each part of ST-UCB below.

Initialization.ST-UCB first chooses the initial parameter \(\mathbf{\theta}_{0}\in\mathbb{R}^{p}\) for the gradient descent method as follows. Let \(\mathbf{\theta}_{\text{base}}\sim\mathcal{N}(0,\mathbf{I}_{\text{p}/2})\) be a base initial parameter, with \(p=M(d\mathcal{N}+\mathcal{L})\). Using \(\mathbf{\theta}_{\text{base}}\), we set the initial parameters \(\mathbf{\theta}_{0}\) as \(\mathbf{\theta}_{0}=(\mathbf{\theta}_{0+}^{\top},\mathbf{\theta}_{0-}^{\top})^{\top}\), where \(\mathbf{\theta}_{0+}\in\mathbb{R}^{p/2}\) and \(\mathbf{\theta}_{0-}\in\mathbb{R}^{p/2}\) are defined as \(\mathbf{\theta}_{0+}=(\mathbf{w}_{\text{base}}^{(1)\top},\mathbf{\pi}_{\text{base}}^{(1) \top},\ldots,\mathbf{w}_{\text{base}}^{(M/2)\top},\mathbf{\pi}_{\text{base}}^{(M/2) \top})^{\top}\) and \(\mathbf{\theta}_{0-}=(\mathbf{w}_{\text{base}}^{(M/2+1)\top},-\mathbf{\pi}_{\text{base}}^ {(M/2+1)\top},\ldots,\mathbf{w}_{\text{base}}^{(M)\top},-\mathbf{\pi}_{\text{base}}^{ (M)\top})^{\top}\), respectively. This initialization procedure ensures that the initial model output is \(0\) (i.e., \(h(\mathbf{x};\mathbf{\theta}_{0})=0\) for all \(\mathbf{x}\in\mathcal{X}\)), which is essential for our theoretical analysis.

Learning.At each step \(t\), ST-UCB learns the model parameter \(\mathbf{\theta}_{t}\) based on a regularized squared loss \(L_{t}(\mathbf{\theta})\coloneqq\sum_{i=1}^{t}(h(\mathbf{x}_{i};\mathbf{\theta})-y_{i})^{2} +\rho\|\mathbf{\theta}-\mathbf{\theta}_{0}\|_{2}^{2}\), where \(\rho>0\) is a regularization parameter.

UCB-based selection of \(\mathbf{x}_{t}\).At each step \(t\), ST-UCB selects \(\mathbf{x}_{t}\) as follows:

\[\mathbf{x}_{t}\in\operatorname*{arg\,max}_{\mathbf{x}\in\mathcal{X}_{t}}[h(\mathbf{x};\bm {\theta}_{t-1})+\beta\tilde{\sigma}_{t-1}(\mathbf{x})], \tag{4}\]

where \(\tilde{\sigma}_{t-1}^{2}(\mathbf{x})=\mathbf{g}(\mathbf{x};\mathbf{\theta}_{0})^{\top}\left( \mathbf{I}_{p}+\rho^{-1}\mathbf{G}_{t-1}\mathbf{G}_{t-1}^{\top}\right)^{-1}\mathbf{g}(\mathbf{x}; \mathbf{\theta}_{0})\) with \(\mathbf{g}(\mathbf{x};\mathbf{\theta})\coloneqq\nabla_{\mathbf{\theta}}h(\mathbf{x};\mathbf{\theta}) \in\mathbb{R}^{p}\) and \(\mathbf{G}_{t-1}\coloneqq(\mathbf{g}(\mathbf{x}_{1};\mathbf{\theta}_{0}),\ldots,\mathbf{g}(\mathbf{x} _{t-1};\mathbf{\theta}_{0}))\in\mathbb{R}^{p\times t}\). In ST-UCB, the quantity \(\tilde{\sigma}_{t-1}^{2}(\mathbf{x})\) quantifies the uncertainty of the model output \(h(\mathbf{x};\mathbf{\theta}_{t})\) and is essential for the construction of confidence bounds. Furthermore, the quantity \(\tilde{\sigma}_{t-1}^{2}(\mathbf{x})\) is interpreted as the predictive variance of a Bayesian linear regression whose feature map is the gradient of the initial model output \(h(\mathbf{x};\mathbf{\theta}_{0})\). We note that a similar quantity is leveraged in existing NB algorithms [23; 30; 41].

### Theory of ST-UCB

Assumptions for theoretical analysis.We make the following assumptions for our theory:

**Assumption 3.1**.: _(i) The output noise \(\epsilon_{t}\) is conditionally \(\sigma\)-sub-Gaussian for some \(\sigma>0\). Specifically, \(\mathbb{E}[\exp(\lambda\epsilon_{t})\mid\mathcal{H}_{t-1}]\leq\exp(\lambda^{2} \sigma^{2}/2)\) holds for any \(t\in[T]\coloneqq\{1,\ldots,T\}\) and any history \(\mathcal{H}_{t-1}\coloneqq(\mathbf{x}_{1},y_{1},\ldots,\mathbf{x}_{t-1},y_{t-1})\). (ii) The input space \(\mathcal{X}\subset\mathbb{R}^{d}\) is a subset of the hyper-sphere \(\mathbb{S}^{d-1}\coloneqq\{\mathbf{x}\in\mathbb{R}^{d}\mid\|\mathbf{x}\|_{2}=1\}\). (iii) The underlying reward function \(f\) is an element of the RKHS corresponding to \(k_{\text{TNTK}}\), where \(k_{\text{TNTK}}\) is the TNTK induced by the same soft tree structure used in ST-UCB. (iv) The RKHS norm of \(f\) is bounded by a known constant \(B<\infty\). That is, \(\|f\|_{\text{TNTK}}\leq B\) holds, where \(\|\cdot\|_{\text{TNTK}}\) denotes the RKHS norm corresponding to \(k_{\text{TNTK}}\)._

**Remark 3.1**.: _In Assumption 3.1, (i) is the standard assumption for the stochastic bandit problem and is quite mild. For example, Bernoulli, Gaussian, and any bounded reward models are included in this assumption. Assumption (ii) is often assumed in existing NB literature [23; 24; 30; 40; 41] and holds without loss of generality by transforming the original input space through a bijection map. For example, given any original input space \(\tilde{\mathcal{X}}\subset\mathbb{R}^{d}\), we can construct a new input space \(\mathcal{X}\) on the hyper sphere \(\mathbb{S}^{d}\) as \(\mathcal{X}=\left\{\left(\overline{l}^{-1}\tilde{\mathbf{x}}^{\top},(1-\|\tilde{ \mathbf{x}}\|_{2}^{2}\overline{l}^{-2})^{1/2}\right)^{\top}\mid\tilde{\mathbf{x}}\in \tilde{\mathcal{X}}\right\}\subset\mathbb{S}^{d}\), where \(\overline{l}=\max_{\tilde{\mathbf{x}}\in\tilde{\mathcal{X}}}\|\tilde{\mathbf{x}}\|_{2}\). Assumptions (iii) and (iv) are similar to those in existing NB works [23; 24; 30]. The only difference is that we use TNTK instead of NTK to define the hypothesis space (RKHS) to which \(f\) belongs. We omit the basic definition and properties of RKHS; see, e.g., [20] for details. In Sec. 4, we further discuss the relationship between the RKHSs corresponding to NTK and TNTK._

Similar to NB with ReLU, our theoretical guarantees rely on two crucial tools in the context of KB. The first is the maximum information gain (MIG) [32], which quantifies the complexity of the problem in the context of kernel-based sequential decision-making tasks. MIGs depend on the underlying kernels, and their upper bounds have been provided when using well-known kernels, including the NTK corresponding to NNs with ReLU [23; 35; 36]. We show the upper bound of MIG when the underlying kernel is TNTK. The second tool is the confidence bound. Constructing valid confidence bounds is crucial for obtaining meaningful regret bounds in stochastic bandit algorithms. These two elements are not only essential for the theoretical analysis of ST-UCB but also of independent interest in general sequential decision-making problems. Hereafter, we present our MIG and confidence bounds results for our ST-UCB algorithm, concluding with the regret upper bound for ST-UCB.

Maximum information gain (MIG) of TNTK.Let us define the quantity \(\gamma_{T}\) as

\[\gamma_{T}=\frac{1}{2}\max_{\mathbf{x}_{1},\ldots,\mathbf{x}_{T}\in\mathcal{X}}\ln\det \left(\mathbf{I}_{T}+\rho^{-1}\mathbf{K}_{T}\right), \tag{5}\]where \(\mathbf{K}_{T}\) is the \(T\times T\) kernel matrix whose \((i,j)\)-th entry is \(k_{\rm TNTK}(\mathbf{x}_{i},\mathbf{x}_{j})\). This \(\gamma_{T}\) is called the maximum information gain (MIG) since the quantity \(0.5\ln\det(\mathbf{I}_{T}+\rho^{-1}\mathbf{K}_{T})\) is equal to the information gain from \(T\) observations in a Gaussian process regression model, characterized by the covariance function \(k_{\rm TNTK}\) and the noise variance parameter \(\rho\)[32]. The following Theorem 3.1 is our main result about MIG, which shows that \(\gamma_{T}\) grows logarithmically.

**Theorem 3.1** (Upper bound of MIG of TNTK).: _Fix any \(\alpha\in(0,\infty)\), \(d\geq 2\), \(\mathcal{D}\in\mathbb{N}_{+}\), and \(\mathcal{X}\subset\mathbb{S}^{d-1}\). Then, \(\gamma_{T}=\mathcal{O}(\ln^{d}T)\). Here, the implied constant depends on \(d\), \(\alpha\), and \(\mathcal{D}\)._

The proof of Theorem 3.1 is given in Appendix A.2. The analysis of MIG is well-studied in existing KB literature [32, 36]. The key component to quantify the upper bound of MIG is the decaying rate of the eigenvalues of the underlying kernel. The following lemma gives the decay rate of TNTK eigenvalues, which plays a central role in the proof of Theorem 3.1.

**Lemma 3.1** (Eigendecomposition of TNTK).: _Fix any \(d\geq 2\), \(\alpha\in(0,\infty)\), and \(\mathcal{D}\in\mathbb{N}_{+}\). Furthermore, let us define \(N_{d,n}\) as \(N_{d,n}=\frac{2n+d-2}{n}\begin{pmatrix}n+d-3\\ d-2\end{pmatrix}\), for any \(n\in\mathbb{N}\), where \(\begin{pmatrix}a\\ b\end{pmatrix}\coloneqq\frac{a!}{b!(a-b)!}\) is a binomial coefficient. Then, for any \(\mathbf{x},\tilde{\mathbf{x}}\in\mathbb{S}^{d-1}\), the TNTK corresponding to \(\alpha\) and \(\mathcal{D}\) satisfies_

\[k_{\rm TNTK}(\mathbf{x},\tilde{\mathbf{x}})=\sum_{n=0}^{\infty}\sum_{j=1}^{N_{d,n}} \lambda_{n}Y_{n,j}(\mathbf{x})Y_{n,j}(\tilde{\mathbf{x}}), \tag{6}\]

_where \((\lambda_{n})_{n\in\mathbb{N}}\) and \((Y_{n,j})_{n\in\mathbb{N},j\in[N_{d,n}]}\) are eigenvalues and eigenfunctions of (the integral operator of) TNTK that satisfy \(\lambda_{0}\geq\lambda_{1}\geq\cdots\geq 0\). In addition, for any \(n\in\mathbb{N}\), the eigenvalue \(\lambda_{n}\) satisfies_

\[\lambda_{n}\leq C^{(1)}_{\alpha,\mathcal{D}}\exp\left(-n\mathcal{D}\ln\left(1+ \frac{1}{4\alpha^{2}}\right)\right), \tag{7}\]

_where \(C^{(1)}_{\alpha,\mathcal{D}}>0\) is a constant, which depends on \(\alpha\) and \(\mathcal{D}\)._

**Remark 3.2**.: _The eigenfunctions \((Y_{n,j})_{j\in[N_{d,n}]}\) are known as spherical harmonics of degree \(n\) with multiplicity \(N_{d,n}\) (see, e.g., [13]). Furthermore, on the hyper-sphere \(\mathbb{S}^{d-1}\), the kernels that have rotationally invariant form can be represented in the form of Eq. (6). TNTK and NTK with ReLU activation function are included in the rotationally invariant class of kernels; therefore, NTK can also be decomposed as Eq. (6) [35], while corresponding eigenvalues differ from those of TNTK._

The proof of Lemma 3.1 is given in Appendix A.1. Lemma 3.1 demonstrates the exponential eigenvalue decay of TNTK, in contrast to the polynomial eigenvalue decay of NTK with ReLU activation [6, 35]. This difference leads to faster convergence of ST-UCB compared to NN-UCB, albeit with a smaller corresponding RKHS of TNTK. We discuss more details in Sec. 4.

Confidence bound.The following shows the confidence bounds for the soft tree-based model.

**Theorem 3.2** (Confidence bounds based on the soft tree ensemble model).: _Suppose Assumption 3.1 holds. Fix any \(\delta\in(0,1)\), \(\rho>0\), \(\alpha\geq 1\), and \(\mathcal{D}\geq 2\). Let \(\mathbf{K}_{\rm TNTK}(\mathcal{X})\coloneqq[k_{\rm TNTK}(\mathbf{x},\tilde{\mathbf{x}})]_ {\mathbf{x},\tilde{\mathbf{x}}\in\mathcal{X}}\in\mathbb{R}^{|\mathcal{X}|\times| \mathcal{X}|}\) and \(\lambda_{0}=\lambda_{\min}(\mathbf{K}_{\rm TNTK}(\mathcal{X}))>0\) be the kernel matrix over \(\mathcal{X}\times\mathcal{X}\) and the minimum eigenvalue of \(\mathbf{K}_{\rm TNTK}(\mathcal{X})\), respectively. If the number of soft tree ensemble models \(M\) is sufficiently large to satisfy \(M\geq\mathrm{Poly}(T,\rho^{-1},B,\alpha,2^{\mathcal{D}},\lambda_{0}^{-1},| \mathcal{X}|,\ln(1/\delta))\) and the learning rate \(\eta\) satisfies \(\eta\leq\mathcal{O}((T^{2}2^{\mathcal{D}}\alpha^{2}\ln(M/\delta)+\rho)^{-1})\), then, the following event holds with probability at least \(1-\delta\):_

\[\forall t\in[T],\forall\mathbf{x}\in\mathcal{X},|f(\mathbf{x})-h(\mathbf{x};\mathbf{\theta}_{t -1})|\leq\mathcal{O}\left(\frac{T^{2}(\ln T)^{2}(\ln M)}{\sqrt{M}}\right)+ \beta\tilde{\sigma}_{t-1}(\mathbf{x}), \tag{8}\]

_where:_

\[\beta=\mathcal{O}\left(\sqrt{\gamma_{T}+\frac{T^{3/2}}{M^{1/2}}}+\frac{T^{3}( \ln T)(\ln M^{3/2})}{\sqrt{M}}+T^{3/2}(\ln T)(\ln M)(1-2\eta\rho)^{J/2}\right). \tag{9}\]

**Remark 3.3**.: _The minimum eigenvalue \(\lambda_{0}\) of the kernel matrix of TNTK is guaranteed to be strictly positive if \(\mathcal{X}\subset\mathbb{S}^{d-1}\). See Proposition 1 in [21]._We provide the proof of Theorem 3.2 in Appendix B.3 with the precise conditions about \(M\) and the dependence of constant factors. Our proof strategy for Theorem 3.2 follows the existing analysis of confidence bounds in NB works; however, the application of their proof techniques to the soft tree regressor is not straightforward. Specifically, the existing proof of the confidence bounds in NB depends on the concentration results of NTK (Theorem 3.1 in [4]), and the spectral norm bounds of the Hessian matrix of NN (Theorem 3.2 in [27]). To prove Theorem 3.2, we provide the following soft tree versions of their results.

**Lemma 3.2** (Concentration to TNTK).: _Fix any \(\mathbf{x}\), \(\tilde{\mathbf{x}}\in\mathbb{S}^{d-1}\), \(\delta\in(0,1)\), and \(\epsilon\in(0,C^{(2)}_{\alpha,\mathcal{D}})\) with \(C^{(2)}_{\alpha,\mathcal{D}}=2^{2\mathcal{D}+2}\alpha^{2}C\). If \(M\geq\tilde{C}\max\{C^{(2)}_{\alpha,\mathcal{D}},2^{2\mathcal{D}}\}\epsilon^{ -2}\ln(16/\delta)\), then,_

\[\mathbb{P}(|k_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x}})-\langle\mathbf{g}(\mathbf{x},\mathbf{ \theta}_{0}),\mathbf{g}(\tilde{\mathbf{x}},\mathbf{\theta}_{0})\rangle|\leq 4\epsilon)\geq 1-\delta, \tag{10}\]

_where \(\mathbf{\theta}_{0}\) is the initial parameter of ST-UCB, and \(C\), \(\tilde{C}>0\) are absolute constants._

**Lemma 3.3** (Spectral norm upper bound).: _For any \(\delta\in(0,1)\) and \(\alpha\geq 1\), with probability at least \(1-\delta\), the following holds for any \(R>0\), \(\mathbf{\theta}\in\mathbb{R}^{p}\), and \(\mathbf{x}\in\mathbb{S}^{d-1}\):_

\[\|\mathbf{\theta}-\mathbf{\theta}_{0}\|_{2}\leq R\Rightarrow\|\mathbf{H}(\mathbf{x},\mathbf{\theta })\|\leq\frac{C^{(3)}_{\alpha,\mathcal{D}}(R+\sqrt{2})^{2}}{\sqrt{M}}\ln\frac{ 2^{\mathcal{D}+2}M}{\delta}, \tag{11}\]

_where \(\mathbf{H}(\mathbf{x},\mathbf{\theta})\coloneqq\nabla_{\mathbf{\theta}}^{2}h(\mathbf{x};\mathbf{\theta })\in\mathbb{R}^{p\times p}\) is the Hessian matrix of the model output, and \(C^{(3)}_{\alpha,\mathcal{D}}=\sqrt{6}\alpha^{2}2^{2\mathcal{D}}\). Furthermore, for any \(\mathbf{A}\in\mathbb{R}^{p\times p}\), \(\|\mathbf{A}\|\coloneqq\max_{\mathbf{x}\in\mathbb{S}^{p-1}}\|\mathbf{A}\mathbf{z}\|_{2}\) denotes the spectral norm._

The proofs of Lemma 3.2 and Lemma 3.3 are given in Appendix B. By carefully combining Lemma 3.2 and Lemma 3.3 with the existing proof strategy of NB, we derive Theorem 3.2. The overview of the proof is summarized in Appendix B.3.1.

Regret upper bound of ST-UCB.By combining Theorem 3.1 and Theorem 3.2 with the standard proof technique of the kernelized UCB algorithm, we obtain the \(\tilde{\mathcal{O}}(\sqrt{T})\) regret upper bound for ST-UCB as stated in the following theorem. The proof is provided in Appendix C.

**Theorem 3.3**.: _Suppose that Assumption 3.1 holds. Fix any \(\delta\in(0,1)\), \(\alpha\geq 1\), \(\rho>0\), and \(\mathcal{D}\geq 2\). Furthermore, assume that the confidence width parameter \(\beta\) satisfies Eq. (9). If the number of soft tree ensemble models \(M\) and the total step size \(J\) of the gradient descent are sufficiently large to satisfy \(M\geq\mathrm{Poly}(T,\rho^{-1},B,\alpha,2^{\mathcal{D}},\lambda_{0}^{-1},| \mathcal{X}|,\ln(1/\delta))\), and the learning rate \(\eta\) satisfies \(\eta\leq\mathcal{O}((T^{2}2^{4\mathcal{D}}\alpha^{2}\ln(M/\delta)+\rho)^{-1})\), then, the following holds with probability at least \(1-\delta\):_

\[R_{T}\leq 1+\left(\sqrt{2}B+1+\frac{\sigma}{\sqrt{\rho}}\sqrt{2\left(\gamma_{T} +1+\ln\frac{6}{\delta}\right)}\right)\sqrt{\frac{8T(\gamma_{T}+1)}{\ln(1+\rho ^{-2})}}=\mathcal{O}\left(\sqrt{T}\ln^{d}T\right). \tag{12}\]

## 4 Comparison of NN-UCB and ST-UCB

Comparison of regret.In the existing NN-UCB algorithm [41], a regret upper bound of \(\mathcal{O}(\tilde{d}\sqrt{T})\) is provided, where \(\tilde{d}\) represents the effective dimension of ReLU-based NTK. It is generally known that the worst-case bound of the effective dimension and MIG are equivalent up to logarithmic dependencies [37]. Considering the upper bound on MIG of NTK, \(\gamma_{T}^{(\text{NTK})}=\tilde{\mathcal{O}}(T^{(d-1)/d})\)[23; 35], the regret of NN-UCB becomes \(\tilde{\mathcal{O}}(T^{(d-1)/d+1/2})(=\tilde{\mathcal{O}}(\gamma_{T}^{(\text {NTK})}\sqrt{T}))\). This results in a super-linear regret, and meaningful guarantees for NN-UCB are not achievable without further restricted assumptions on the input set \(\mathcal{X}_{t}\) (e.g., see the discussion in Appendix D in [40]). To address these issues in a general setting, it is necessary to construct more complex algorithms that incorporate concepts such as a sup-variant of UCB [23; 30] or phased elimination [24], yielding a regret upper bound of \(\mathcal{O}(\sqrt{\gamma_{T}^{(\text{NTK})}T})\). In contrast, due to Theorem 3.1, the MIG of TNTK \(\gamma_{T}^{(\text{NTK})}\) diverges on a logarithmic scale. Therefore, ST-UCB achieves a regret bound of \(\tilde{\mathcal{O}}(\sqrt{T})\) without requiring additional assumptions on the input set \(\mathcal{X}_{t}\), maintaining a simple UCB-style algorithmic structure.

Comparison of hypothesis space.In our analysis, we assume in Assumption 3.1 that the reward function \(f\) belongs to the RKHS \(\mathcal{H}_{\text{TNTK}}\) associated with TNTK. Conversely, in existing NB research, it is assumed that \(f\) belongs to the RKHS \(\mathcal{H}_{\text{NTK}}\) associated with NTK. By combining Lemma 3.1 with the well-known Mercer's representation theorem (e.g., Theorem 4.51 in [33]), we derive the following lemma, which describes the relationship between \(\mathcal{H}_{\text{TNTK}}\) and \(\mathcal{H}_{\text{NTK}}\).

**Lemma 4.1**.: _Fix any \(\alpha\geq 0\) and \(\mathcal{D}\in\mathbb{N}_{+}\), and define the corresponding TNTK as \(k_{\mathrm{TNTK}}:\mathbb{S}^{d-1}\times\mathbb{S}^{d-1}\to\mathbb{R}\). Let \(k_{\mathrm{NTK}}:\mathbb{S}^{d-1}\times\mathbb{S}^{d-1}\to\mathbb{R}\) be an NTK corresponding to a ReLU-based \(L\)-layer neural network structure, where \(L\) is any natural number. Then, \(\mathcal{H}_{\mathrm{TNTK}}\subset\mathcal{H}_{\mathrm{NTK}}\) holds, where \(\mathcal{H}_{\mathrm{NTK}}\) and \(\mathcal{H}_{\mathrm{TNTK}}\) are RKHSs corresponding to \(k_{\mathrm{NTK}}\) and \(k_{\mathrm{TNTK}}\), respectively._

The proof of Lemma 4.1 is provided in Appendix D. Lemma 4.1 indicates that the regret upper bound of ST-UCB is guaranteed in a more constrained hypothesis space compared to NN-UCB. While NN-UCB generally does not guarantee a no-regret property, the \(\tilde{\mathcal{O}}(\sqrt{T})\) guarantee in ST-UCB can be interpreted as being due to focusing on a more constrained hypothesis space.

It should be noted that whether this property is specific to the tree structure of the model or depends on the choice of the soft-decision function is unknown. We constructed and analyzed our algorithm based on the definition of soft trees from [21]; however, we conjecture that by using a more non-smooth soft decision function, although the regret may degrade to a level similar to NN-UCB, we can align the hypothesis spaces used in NN-UCB and ST-UCB to be almost the same. We leave the detailed analysis to future work.

## 5 Numerical experiments

In this section, we compare ST-UCB and NN-UCB to empirically demonstrate the usefulness of the tree-based model. Additionally, to evaluate the characteristics of UCB-based algorithms, we include \(\epsilon\)-greedy based ST-greedy and NN-greedy as comparative methods.

Real-world dataset.We use _Energy Efficiency_ dataset [34] registered in UCI Machine Learning Repository [1]. This dataset provides the load required to maintain comfortable indoor air conditions for each of the 768 residential buildings - two types of data are provided as non-negative real values: heating load (HL) and cooling load (CL). For each building, eight types of context are included as explanatory variables. We randomly sample residential buildings without replacement to create a dataset of \(\tilde{K}\leq 768\) arms, where \(\tilde{K}\) is a hyperparameter. The inputs are denoted as \(\mathbf{x}=(\tilde{\mathbf{x}}_{\text{building}},\tilde{\mathbf{x}})\in\mathcal{X}\), where \(\tilde{\mathbf{x}}_{\text{building}}\) is a \(\tilde{K}\)-dimensional one-hot vector used to identify the arms, and \(\tilde{\mathbf{x}}\) is a vector that aggregates the eight types of context. In most real-world data, the rewards depend not only on the observable context \(\tilde{\mathbf{x}}\) but also on other information. To account for arm-specific characteristics that cannot be represented by \(\tilde{\mathbf{x}}\) alone, we use \(\tilde{\mathbf{x}}_{\text{building}}\) as part of the input.

We consider each arm of the multi-armed bandit problem as an individual residential building, and we define the reward of the arm selected in each round as \(f_{t}=-(\text{HL}_{t}+\text{CL}_{t})\). Additionally, we standardize the rewards across \(\tilde{K}\) arms to have a mean of 0 and a standard deviation of 1.

Synthetic dataset.We evaluate the algorithms using synthetic data similar to that used in [41]. Here, the number of arms is set to 20, and the dimension of the input vector \(\mathbf{x}\) for each arm is set to 50. Additionally, the input vectors are chosen uniformly at random from the unit ball. We consider the three reward functions: (i) \(f^{(1)}(\mathbf{x})=10(\mathbf{x}^{\top}\mathbf{a})^{2}\), (ii) \(f^{(2)}(\mathbf{x})=\mathbf{x}^{\top}\mathbf{A}^{\top}\mathbf{A}\mathbf{x}\), and (iii) \(f^{(3)}(\mathbf{x})=\cos(3\mathbf{x}^{\top}\mathbf{a})\) where \(\mathbf{a}\in\mathbb{R}^{50}\) is randomly generated from uniform distribution over unit ball, and each entry of \(\mathbf{A}\in\mathbb{R}^{50\times 50}\) is randomly generated from standard normal distribution. Similar to the real-world dataset, we standardize the rewards across all arms.

Setup.We define the cumulative regret up to round \(T\) as \(R_{T}=\sum_{t=1}^{T}f^{*}-f_{t}\) where \(f^{*}\) represents the maximum reward among all arms. We assume that the response used for training the machine learning model is generated from \(y_{t}=f_{t}+\epsilon_{t}\) where \(\epsilon_{t}\) is randomly drawn from a normal distribution with mean \(0\) and standard deviation \(\sigma_{\text{noise}}=0.2\). Since the rewards are standardized, this setting of \(\sigma_{\text{noise}}\) effectively acts as noise.

In this experiment, we will use an \(\epsilon\)-greedy based algorithm as an additional comparative method; In each round, an arm is selected randomly with a probability of \(\epsilon\), while the arm with the highest predicted value from the machine learning model is selected with a probability of \(1-\epsilon\). Here, we will perform a grid search to choose the value of \(\epsilon\) from the three candidates \(\epsilon\in\{0.05,0.1,0.2\}\). Meanwhile, in UCB-based algorithms, \(\beta\) is provided as a parameter to control the degree of exploration. We use a grid search to select the value of \(\beta\) from the three candidates \(\beta\in\{0.01,0.1,1\}\).

We employ a fully connected neural network model with two intermediate layers. Including the input and output layers, the total number of layers is four. Each of the two intermediate layers contains 33 units, one of which is a bias term. As for the tree-based model, we consider an ensemble of four soft-trees, the depth of each soft-tree is three. The regularization coefficient \(\lambda\) for the parameters is fixed at \(10^{-4}\), regardless of the machine learning model. Supplementary details related to the implementation of the algorithms are summarized in Appendix F.1.

Results.The results for each algorithm are shown in Fig. 2. In real-world dataset, three different numbers of arms were considered, with \(\tilde{K}\) being one of {20, 40, 60}. These experiments were conducted over 10 episodes with different initial parameters \(\mathbf{\theta}_{0}\) for the model. Additional results without the grid search for \(\epsilon,\beta\) are summarized in Appendix F.2.

In all settings of real-world dataset, the regret of ST-UCB was not smaller in the early rounds, but the increase in the cumulative regret became more gradual as the rounds progressed. For example, in the setting of \(\tilde{K}=60\), after round 150, there was no change in the cumulative regret of ST-UCB. However, from round 1 to 70, the regret of ST-UCB was relatively high compared to other methods. In our experiment, UCB-based policies (NN-UCB, ST-UCB) tended to actively select arms that had not been chosen before in the early rounds. As the rounds increased, exploratory behavior was suppressed, and there was a stronger tendency to select only arms with high rewards. On the other hand, in policies based on \(\epsilon\)-greedy (NN-greedy, ST-greedy), the exploration rate is kept at \(\epsilon\) across all rounds. Therefore, the regret continues to accumulate gradually as the rounds increase, raising concerns about worsening cumulative regret over extended long rounds. In the \(f^{(1)}\) and \(f^{(2)}\) settings of synthetic dataset, ST-UCB outperformed the other policies, and the convergence stability of cumulative regret in \(f^{(3)}\) was comparable between ST-UCB and NN-UCB.

## 6 Conclusion and future direction

In this paper, we propose a new regret-minimization algorithm based on a soft tree ensemble model. Our analysis extends the theoretical framework of existing neural bandit (NB) approaches to the soft tree ensemble model, demonstrating, under appropriate assumptions, the achievement of \(\tilde{\mathcal{O}}(\sqrt{T})\) regret. To our knowledge, this is the first application of NB theory to models other than neural networks; we believe that our work marks an important first step toward developing exploration and exploitation theory using various complex models beyond neural nets.

Figure 2: The average cumulative regret with one standard error. The experiment was conducted over 10 episodes with different initial parameters for the model.

Our future research directions are outlined below. Firstly, it is important to study the extension when employing hard decision trees. In this paper, as the scale parameter \(\alpha\) approaches infinity, the soft tree regressor approaches that of a hard tree. We conjecture that our algorithm also works in this regime; however, since our regret analysis assumes a fixed \(\alpha\), our proposed method is not guaranteed to maintain the no-regret property with a varying scale parameter \(\alpha\). Hence, a more careful theoretical treatment is needed for this extension. Secondly, we plan to generalize the theory to encompass more common learning methods of the ensemble tree model. Specifically, learning algorithms using hard trees often utilize optimization methods in a greedy format rather than gradient descent. Therefore, developing theoretical foundations for ensemble tree learning methods that are more practically applicable is crucial.

## References

* [1] UCI Machine Learning Repository -- archive.ics.uci.edu. [https://archive.ics.uci.edu/](https://archive.ics.uci.edu/). [Accessed 25-04-2024].
* [2] Yasin Abbasi-Yadkori. Online learning for linearly parametrized control problems. 2013.
* [3] Yasin Abbasi-Yadkori, David Pal, and Csaba Szepesvari. Improved algorithms for linear stochastic bandits. _Proc. Neural Information Processing Systems (NeurIPS)_, 2011.
* [4] Sanjeev Arora, Simon S Du, Wei Hu, Zhiyuan Li, Russ R Salakhutdinov, and Ruosong Wang. On exact computation with an infinitely wide neural net. _Proc. Neural Information Processing Systems (NeurIPS)_, 2019.
* [5] Peter Auer. Using confidence bounds for exploitation-exploration trade-offs. _Journal of Machine Learning Research_, 2002.
* [6] Alberto Bietti and Francis Bach. Deep equals shallow for ReLU networks in kernel regimes. In _Proc. International Conference on Learning Representations (ICLR)_, 2021.
* [7] Ilija Bogunovic and Andreas Krause. Misspecified Gaussian process bandit optimization. In _Proc. Neural Information Processing Systems (NeurIPS)_, 2021.
* [8] Sebastien Bubeck, Remi Munos, Gilles Stoltz, and Csaba Szepesvari. X-armed bandits. _Journal of Machine Learning Research_, 12(5), 2011.
* [9] Daniele Calandriello, Alessandro Lazaric, and Michal Valko. Second-order kernel online convex optimization with adaptive sketching. In _Proc. International Conference on Machine Learning (ICML)_, 2017.
* [10] Daniele Calandriello, Luigi Carratino, Alessandro Lazaric, Michal Valko, and Lorenzo Rosasco. Gaussian process optimization with adaptive sketching: Scalable and no regret. In _Proc. Conference on Learning Theory (COLT)_, 2019.
* [11] Sayak Ray Chowdhury and Aditya Gopalan. On kernelized multi-armed bandits. In _Proc. International Conference on Machine Learning (ICML)_, 2017.
* [12] Varsha Dani, Thomas P Hayes, and Sham M Kakade. Stochastic linear optimization under bandit feedback. In _Proc. Conference on Learning Theory (COLT)_, 2008.
* [13] Costas Efthimiou and Christopher Frye. _Spherical harmonics in p dimensions_. World Scientific, 2014.
* [14] Adam N Elmachtoub, Ryan McNellis, Sechan Oh, and Marek Petrik. A practical method for solving contextual bandit problems using decision trees. In _Conference on Uncertainty in Artificial Intelligence (UAI)_, 2017.
* [15] Raphael Feraud, Robin Allesiardo, Tanguy Urvoy, and Fabrice Clerot. Random forest for the contextual bandit problem. In _Proc. International Conference on Artificial Intelligence and Statistics (AISTATS)_, 2016.
* [16] Guillaume Garrigos and Robert M Gower. Handbook of convergence theorems for (stochastic) gradient methods. _arXiv preprint arXiv:2301.11235_, 2023.

* [17] Xavier Glorot and Yoshua Bengio. Understanding the difficulty of training deep feedforward neural networks. In _Proc. International Conference on Artificial Intelligence and Statistics (AISTATS)_, 2010.
* [18] Hussein Hazimeh, Natalia Ponomareva, Petros Mol, Zhenyu Tan, and Rahul Mazumder. The tree ensemble layer: Differentiability meets conditional computation. In _Proc. International Conference on Machine Learning (ICML)_, 2020.
* [19] Arthur Jacot, Franck Gabriel, and Clement Hongler. Neural tangent kernel: Convergence and generalization in neural networks. _Proc. Neural Information Processing Systems (NeurIPS)_, 31, 2018.
* [20] Motonobu Kanagawa, Philipp Hennig, Dino Sejdinovic, and Bharath K Sriperumbudur. Gaussian processes and kernel methods: A review on connections and equivalences. _arXiv preprint arXiv:1807.02582_, 2018.
* [21] Ryuichi Kanoh and Mahito Sugiyama. A neural tangent kernel perspective of infinite tree ensembles. In _Proc. International Conference on Learning Representations (ICLR)_, 2021.
* [22] Ryuichi Kanoh and Mahito Sugiyama. Analyzing tree architectures in ensembles via neural tangent kernel. In _Proc. International Conference on Learning Representations (ICLR)_, 2022.
* [23] Parnian Kassraie and Andreas Krause. Neural contextual bandits without regret. In _Proc. International Conference on Artificial Intelligence and Statistics (AISTATS)_, 2022.
* [24] Parnian Kassraie, Andreas Krause, and Ilija Bogunovic. Graph neural network bandits. In _Proc. Neural Information Processing Systems (NeurIPS)_, December 2022.
* [25] Peter Kontschieder, Madalina Fiterau, Antonio Criminisi, and Samuel Rota Bulo. Deep neural decision forests. In _Proceedings of the IEEE international conference on computer vision_, 2015.
* [26] Zihan Li and Jonathan Scarlett. Gaussian process bandit optimization with few batches. In _Proc. International Conference on Artificial Intelligence and Statistics (AISTATS)_, 2022.
* [27] Chaoyue Liu, Libin Zhu, and Misha Belkin. On the linearity of large non-linear models: when and why the tangent kernel is constant. _Proc. Neural Information Processing Systems (NeurIPS)_, 2020.
* [28] Sergei Popov, Stanislav Morozov, and Artem Babenko. Neural oblivious decision ensembles for deep learning on tabular data. _Proc. International Conference on Learning Representations (ICLR)_, 2020.
* [29] Sayak Ray Chowdhury and Aditya Gopalan. Bayesian optimization under heavy-tailed payoffs. In _Proc. Neural Information Processing Systems (NeurIPS)_, 2019.
* [30] Sudeep Salgia. Provably and practically efficient neural contextual bandits. In _Proc. International Conference on Machine Learning (ICML)_, 2023.
* [31] Meyer Scetbon and Zaid Harchaoui. A spectral analysis of dot-product kernels. In _Proc. International Conference on Artificial Intelligence and Statistics (AISTATS)_, 2021.
* [32] Niranjan Srinivas, Andreas Krause, Sham Kakade, and Matthias Seeger. Gaussian process optimization in the bandit setting: No regret and experimental design. In _Proc. International Conference on Machine Learning (ICML)_, 2010.
* [33] Ingo Steinwart and Andreas Christmann. _Support vector machines_. Springer Science & Business Media, 2008.
* [34] Athanasios Tsanas and Angeliki Xifara. Accurate quantitative estimation of energy performance of residential buildings using statistical machine learning tools. _Energy and buildings_, 49: 560-567, 2012.
* [35] Sattar Vakili, Michael Bromberg, Jezabel Garcia, Da-shan Shiu, and Alberto Bernacchia. Uniform generalization bounds for overparameterized neural networks. _arXiv preprint arXiv:2109.06099_, 2021.

* [36] Sattar Vakili, Kia Khezeli, and Victor Picheny. On information gain and regret bounds in Gaussian process bandits. In _Proc. International Conference on Artificial Intelligence and Statistics (AISTATS)_, 2021.
* [37] Michal Valko, Nathaniel Korda, Remi Munos, Ilias Flaounas, and Nelo Cristianini. Finite-time analysis of kernelised contextual bandits. In _Conference on Uncertainty in Artificial Intelligence (UAI)_, 2013.
* [38] Hastagiri P Vanchinathan, Isidor Nikolic, Fabio De Bona, and Andreas Krause. Explore-exploit in top-n recommender systems via Gaussian processes. In _Proceedings of the 8th ACM Conference on Recommender systems_, 2014.
* [39] Roman Vershynin. _High-dimensional probability: An introduction with applications in data science_, volume 47. Cambridge university press, 2018.
* [40] Weitong Zhang, Dongruo Zhou, Lihong Li, and Quanquan Gu. Neural Thompson sampling. In _Proc. International Conference on Learning Representations (ICLR)_, 2021.
* [41] Dongruo Zhou, Lihong Li, and Quanquan Gu. Neural contextual bandits with ucb-based exploration. In _Proc. International Conference on Machine Learning (ICML)_, 2020.

Information gain of TNTK

### Proof of Lemma 3.1

Firstly, we formally define the dot product kernel on the sphere.

**Definition A.1** (Dot product kernel on the sphere [31]).: _Let \(d\geq 2\) and \(\mathbb{S}^{d-1}\) be the unit sphere of \(\mathbb{R}^{d}\). Then, a kernel \(k:\mathbb{S}^{d-1}\times\mathbb{S}^{d-1}\rightarrow\mathbb{R}\) of the following form is called a dot product kernel on the sphere \(\mathbb{S}^{d-1}\):_

\[k(\mathbf{x},\tilde{\mathbf{x}})=\sum_{n=0}^{\infty}b_{n}(\mathbf{x}^{\top}\tilde{\mathbf{x}})^ {n}\ \operatorname{for\ all}\ \mathbf{x},\tilde{\mathbf{x}}\in\mathbb{S}^{d-1}, \tag{13}\]

_where \((b_{n})_{n\in\mathbb{N}}\) is an absolutely summable sequence. Furthermore, if \(b_{n}\geq 0\) for any \(n\in\mathbb{N}\), \(k\) is a continuous positive semi-definite kernel on the sphere \(\mathbb{S}^{d-1}\)._

As described in Sec. 2 in [31], continuous positive semi-definite dot-product kernels are decomposed as Eq. (6) by using spherical harmonics \((Y_{n,j})\).

The following lemma shows the eigendecay of dot product kernels depending on coefficients \((b_{n})_{n\in\mathbb{N}}\).

**Lemma A.1** (Proposition 2.3 in [31]).: _Let \(d\geq 2\) and \((Y_{n,j})_{j\in[N_{4,n}]}\) be the spherical harmonics of degree \(n\). Furthermore, let \(k(\mathbf{x},\tilde{\mathbf{x}})\coloneqq\sum_{n=1}^{\infty}b_{n}(\mathbf{x}^{\top}\tilde{ \mathbf{x}})^{n}\) be a continuous positive semi-definite dot-product kernel on \(\mathbb{S}^{d-1}\). Here, if there exist \(r\in(0,1)\) and \(c>0\) such that \(b_{n}\leq cr^{n}\) holds for any \(n\in\mathbb{N}\), then, there exists constant \(C>0\) and \((\lambda_{n})_{n\in\mathbb{N}}\) such that \(\lambda_{n}\leq Cr^{n}\) and \(k(\mathbf{x},\tilde{\mathbf{x}})=\sum_{n=0}^{\infty}\sum_{j=1}^{N_{4,n}}\lambda_{n}Y_{n,j}(\mathbf{x})Y_{n,j}(\tilde{\mathbf{x}})\) hold for all \(\mathbf{x},\tilde{\mathbf{x}}\in\mathbb{S}^{d-1}\), and \(n\in\mathbb{N}\)._

To prove Lemma 3.1, we consider the Maclaurin series expansion of TNTK; then, Lemma 3.1 is given from Lemma A.1.

Proof of Lemma 3.1.: First, we respectively define functions \(f_{1}:[-1,1]\rightarrow\mathbb{R}\) and \(f_{2}:[-1,1]\rightarrow\mathbb{R}\) as

\[f_{1}(a) =\frac{1}{2\pi}\text{arcsin}\left(\frac{\alpha^{2}a}{\alpha^{2}+ 0.5}\right)+\frac{1}{4}, \tag{14}\] \[f_{2}(a) =\frac{\alpha^{2}}{\pi}\frac{1}{\sqrt{(1+2\alpha^{2})^{2}-4\alpha ^{4}a^{2}}}. \tag{15}\]

Then, since \(\mathbf{x},\tilde{\mathbf{x}}\in\mathbb{S}^{d-1}\), the following holds directly from the analytical expression of TNTK [21]:

\[k_{\text{TNTK}}(\mathbf{x},\tilde{\mathbf{x}})=2^{\mathcal{D}}\mathcal{D}(\mathbf{x}^{\top }\tilde{\mathbf{x}})f_{1}(\mathbf{x}^{\top}\tilde{\mathbf{x}})^{\mathcal{D}-1}f_{2}(\mathbf{ x}^{\top}\tilde{\mathbf{x}})+2^{\mathcal{D}}f_{1}(\mathbf{x}^{\top}\tilde{\mathbf{x}})^{ \mathcal{D}}. \tag{16}\]

Here, since \(-1<\frac{\alpha^{2}a}{\alpha^{2}+0.5}<1\) holds for any \(a\in[-1,1]\),

\[f_{1}(a) =\frac{1}{2\pi}\text{arcsin}\left(\frac{\alpha^{2}a}{\alpha^{2}+ 0.5}\right)+\frac{1}{4} \tag{17}\] \[=\frac{1}{2\pi}\sum_{n=0}^{\infty}\frac{(2n)!}{4^{n}(n!)^{2}(2n+ 1)}\left(\frac{\alpha^{2}}{\alpha^{2}+0.5}\right)^{2n+1}a^{2n+1}+\frac{1}{4}, \tag{18}\]

from the Maclaurin series expansion of the inverse sine function. Furthermore, since \(-1<\left(\frac{2\alpha^{2}a}{1+2\alpha^{2}}\right)^{2}<1\) holds for any \(a\in[-1,1]\),

\[f_{2}(a) =\frac{\alpha^{2}}{\pi}\frac{1}{\sqrt{(1+2\alpha^{2})^{2}-4\alpha ^{4}a^{2}}} \tag{19}\] \[=\frac{\alpha^{2}}{\pi(1+2\alpha^{2})}\frac{1}{\sqrt{1-\left( \frac{2\alpha^{2}}{1+2\alpha^{2}}\right)^{2}a^{2}}}\] (20) \[=\frac{\alpha^{2}}{\pi(1+2\alpha^{2})}\sum_{n=0}^{\infty}(-1)^{n }\begin{pmatrix}-0.5\\ n\end{pmatrix}\left(\frac{\alpha^{2}}{\alpha^{2}+0.5}\right)^{2n}a^{2n}, \tag{21}\]where the last line follows from the fact that \((1+x)^{c}=\sum_{n=0}^{\infty}\begin{pmatrix}c\\ n\end{pmatrix}x^{n}\) holds for any \(c\in\mathbb{R}\) and \(x\in(-1,1)\). Here, \(\begin{pmatrix}c\\ n\end{pmatrix}\) denotes a generalized binomial coefficient, which is defined as \(\begin{pmatrix}c\\ n\end{pmatrix}=1\) if \(n=0\); otherwise, \(\begin{pmatrix}c\\ n\end{pmatrix}=\frac{c(c-1)\cdots(c-n+1)}{n!}\). By rearranging Eq. (18) and Eq. (21), \(f_{1}\) and \(f_{2}\) can respectively be rewritten as \(f_{1}(a)=\sum_{i=1}^{\infty}b_{i}^{(1)}a^{i}\) and \(f_{2}(a)=\sum_{i=1}^{\infty}b_{i}^{(2)}a^{i}\), where the coefficients \(b_{i}^{(1)}\) and \(b_{i}^{(2)}\) are defined as

\[b_{i}^{(1)} =\begin{cases}\frac{1}{4}&\text{ if }i=0,\\ \frac{(i-1)!}{(2\pi)2^{i-1}i(((-1)/2)!)^{2}}\left(\frac{\alpha^{2}}{\alpha^{2 }+0.5}\right)^{i}&\text{ if }\exists n\in\mathbb{N},\;i=2n+1,\,,\\ 0&\text{ otherwise},\end{cases} \tag{22}\] \[b_{i}^{(2)} =\begin{cases}\frac{\alpha^{2}}{\pi(1+2\alpha^{2})}&\text{ if }i=0,\\ \frac{\alpha^{2}}{\pi(1+2\alpha^{2})}\left(\frac{\alpha^{2}}{\alpha^{2}+0.5} \right)^{i}\frac{1}{(i/2)!}\left[0.5\cdot 1.5\cdots(0.5+0.5i-1)\right]&\text{ if }\exists n\in\mathbb{N},\;i=2n,\\ 0&\text{ otherwise}.\end{cases} \tag{23}\]

From the Stirling's inequality: \(e(n/e)^{n}\leq n!\leq en(n/e)^{n}\), for any \(i\) such that \(i=2n+1\) holds,

\[\frac{(i-1)!}{(2\pi)2^{i-1}i(((i-1)/2)!)^{2}} =\frac{(2n)!}{(2\pi)2^{2n}(2n+1)(n!)^{2}} \tag{24}\] \[\leq\frac{2en(2n/e)^{2n}}{(2\pi)2^{2n}(2n+1)e^{2}(n/e)^{2n}}\] (25) \[\leq\frac{2n}{(2\pi)(2n+1)e}\] (26) \[\leq\frac{1}{(2\pi)e}\] (27) \[\leq\frac{1}{e}. \tag{28}\]

Therefore, \(0\leq b_{i}^{(1)}\leq e^{-By combining Eq. (34) with the upper bounds of \(b_{i}^{(1)}\) and \(b_{i}^{(2)}\),

\[\begin{split} b_{i}&\leq 2^{\mathcal{D}}\mathcal{D} \left(\frac{1}{e}\right)^{\mathcal{D}-1}\frac{\alpha^{2}}{\pi(1+2\alpha^{2})} \left(\frac{\alpha^{2}}{\alpha^{2}+0.5}\right)^{i\mathcal{D}}\sum_{i_{2}=0}^{i -1}\sum_{i_{3}=0}^{i_{2}}\cdots\sum_{i_{\mathcal{D}-1}=0}^{i_{\mathcal{D}-2}} \sum_{i_{\mathcal{D}}=0}^{i_{\mathcal{D}-1}}1\\ &\quad+2^{\mathcal{D}}\left(\frac{1}{e}\right)^{\mathcal{D}}\left( \frac{\alpha^{2}}{\alpha^{2}+0.5}\right)^{i\mathcal{D}}\sum_{i_{2}=0}^{i}\sum _{i_{3}=0}^{i_{2}}\cdots\sum_{i_{\mathcal{D}-1}=0}^{i_{\mathcal{D}-2}}\sum_{i_ {\mathcal{D}}=0}^{i_{\mathcal{D}-1}}1\\ &\leq 2^{\mathcal{D}}\mathcal{D}\left(\frac{1}{e}\right)^{\mathcal{D}- 1}\frac{\alpha^{2}}{\pi(1+2\alpha^{2})}\left(\frac{\alpha^{2}}{\alpha^{2}+0.5 }\right)^{i\mathcal{D}}(i-1)^{\mathcal{D}}+2^{\mathcal{D}}\left(\frac{1}{e} \right)^{\mathcal{D}}\left(\frac{\alpha^{2}}{\alpha^{2}+0.5}\right)^{i \mathcal{D}}i^{\mathcal{D}}\\ &\leq\left[2^{\mathcal{D}}\mathcal{D}\left(\frac{1}{e}\right)^{ \mathcal{D}-1}\frac{\alpha^{2}}{\pi(1+2\alpha^{2})}+2^{\mathcal{D}}\left(\frac {1}{e}\right)^{\mathcal{D}}\right]\left(\frac{\alpha^{2}}{\alpha^{2}+0.5} \right)^{i\mathcal{D}}i^{\mathcal{D}}.\end{split} \tag{36}\]

Therefore, there exist constant \(\tilde{C}_{\alpha,\mathcal{D}}>0\) such that

\[b_{i}\leq\tilde{C}_{\alpha,\mathcal{D}}\left(\frac{\alpha^{2}}{\alpha^{2}+0.25 }\right)^{i\mathcal{D}} \tag{38}\]

holds for any \(i\in\mathbb{N}\). By applying Lemma A.1 with Eq. (38), we have

\[\lambda_{i} \leq C_{\alpha,\mathcal{D}}^{(1)}\left(\frac{\alpha^{2}}{\alpha^{ 2}+0.25}\right)^{i\mathcal{D}} \tag{39}\] \[=C_{\alpha,\mathcal{D}}^{(1)}\exp\left(i\mathcal{D}\ln\left(\frac {\alpha^{2}}{\alpha^{2}+0.25}\right)\right)\] (40) \[=C_{\alpha,\mathcal{D}}^{(1)}\exp\left(-i\mathcal{D}\ln\left(1+ \frac{1}{4\alpha^{2}}\right)\right) \tag{41}\]

for some constant \(C_{\alpha,\mathcal{D}}^{(1)}>0\). 

### Proof of Theorem 3.1

Our proof strategy of Theorem 3.1 is adapted from [23; 35].

Proof of Theorem 3.1.: Fix any deterministic sequence \(\mathbf{x}_{1},\ldots,\mathbf{x}_{t}\in\mathcal{X}\subset\mathbb{S}^{d-1}\). For any \(M\in\mathbb{N}+\), let us define kernel functions \(k_{\text{TNTK}}^{(M)}\) and \(\tilde{k}_{\text{TNTK}}^{(M)}\) as

\[k_{\text{TNTK}}^{(M)}(\mathbf{x},\tilde{\mathbf{x}}) =\sum_{n=0}^{M}\sum_{j=1}^{N_{d,n}}\lambda_{n}Y_{n,j}(\mathbf{x})Y_{n,j}(\tilde{\mathbf{x}}), \tag{42}\] \[\tilde{k}_{\text{TNTK}}^{(M)}(\mathbf{x},\tilde{\mathbf{x}}) =\sum_{n=M+1}^{\infty}\sum_{j=1}^{N_{d,n}}\lambda_{n}Y_{n,j}(\mathbf{ x})Y_{n,j}(\tilde{\mathbf{x}}). \tag{43}\]

Furthermore, let \(\mathbf{K}_{\text{TNTK}}^{(M)}\) and \(\tilde{\mathbf{K}}_{\text{TNTK}}^{(M)}\) be \(t\times t\)-kernel matrices whose \((i,j)\)-th entry are \(k_{\text{TNTK}}^{(M)}(\mathbf{x}_{i},\mathbf{x}_{j})\) and \(\tilde{k}_{\text{TNTK}}^{(M)}(\mathbf{x}_{i},\mathbf{x}_{j})\), respectively. As with the proof of Theorem 3 in [36], we have the following decomposition:

\[\begin{split}&\frac{1}{2}\ln\det\left(\mathbf{I}_{t}+\rho^{-1}\mathbf{K}_{ \text{TNTK}}\right)\\ &=\frac{1}{2}\ln\det\left(\mathbf{I}_{t}+\rho^{-1}\mathbf{K}_{\text{TNTK }}^{(M)}\right)+\frac{1}{2}\ln\det\left(\mathbf{I}_{t}+\rho^{-1}\left(\mathbf{I}_{t}+ \rho^{-1}\mathbf{K}_{\text{TNTK}}^{(M)}\right)^{-1}\tilde{\mathbf{K}}_{\text{TNTK}}^{ (M)}\right).\end{split} \tag{44}\]

By following the same argument as the proof of Theorem 2 in [35], the first term of Eq. (44) is bounded from above as follows:

\[\frac{1}{2}\ln\det\left(\mathbf{I}_{t}+\rho^{-1}\mathbf{K}_{\text{TNTK}}^{(M)}\right) \leq\frac{N_{M}}{2}\ln\left(1+\frac{\overline{k}t}{\rho N_{M}}\right). \tag{45}\]where \(N_{M}=\sum_{n=1}^{M}N_{d,n}\) and \(\overline{k}=\max_{\mathbf{x}\in\mathcal{X}}k_{\text{TNTK}}(\mathbf{x},\mathbf{x})\). Furthermore, by following the same argument as the proof of Theorem 3.2 in [23], the second term of Eq. (44) is bounded from above as follows:

\[\frac{1}{2}\ln\det\left(\mathbf{I}_{t}+\rho^{-1}\left(\mathbf{I}_{t}+\rho ^{-1}\mathbf{K}_{\text{TNTK}}^{(M)}\right)^{-1}\tilde{\mathbf{K}}_{\text{TNTK}}^{(M)}\right) \tag{46}\] \[\leq\frac{t}{2}\ln\left(1+\frac{\rho^{-1}\text{tr}\left(\tilde{ \mathbf{K}}_{\text{TNTK}}^{(M)}\right)}{t}\right)\] (47) \[\leq\frac{t}{2}\ln\left(1+\rho^{-1}\sum_{n=M+1}^{\infty}\lambda_ {n}N_{d,n}\right)\] (48) \[\leq\frac{t}{2\rho}\sum_{n=M+1}^{\infty}\lambda_{n}N_{d,n}. \tag{49}\]

Then, from Lemma 3.1, there exists some constants \(C>0\) and \(C_{\alpha,d}>0\) such that

\[\sum_{n=M+1}^{\infty}\lambda_{n}N_{d,n} \leq\sum_{n=M+1}^{\infty}C_{\alpha,\mathcal{D}}^{(1)}C\exp\left( -C_{\alpha}\mathcal{D}n\right)n^{d-2} \tag{50}\] \[\leq\sum_{n=M+1}^{\infty}C_{\alpha,\mathcal{D}}^{(1)}CC_{\alpha, d}\exp\left(-0.5C_{\alpha}\mathcal{D}n\right). \tag{51}\]

where we set \(C_{\alpha}\) as \(C_{\alpha}=\ln(1+1/(4\alpha^{2}))\). Furthermore, Eq. (50) follows from \(N_{d,n}=\Theta(n^{d-2})\) (see, e.g., [23]). Therefore,

\[\sum_{n=M+1}^{\infty}\lambda_{n}N_{d,n} \leq C_{\alpha,\mathcal{D}}^{(1)}CC_{\alpha,d}\int_{M}^{\infty} \exp\left(-0.5C_{\alpha}\mathcal{D}x\right)\text{d}x \tag{52}\] \[\leq\tilde{C}_{\alpha,\mathcal{D},d}\exp\left(-\frac{C_{\alpha} \mathcal{D}M}{2}\right), \tag{53}\]

where we set \(\tilde{C}_{\alpha,\mathcal{D},

[MISSING_PAGE_FAIL:17]

Here, \(\overline{\mathbf{w}}^{(m),(T)}\), \(\overline{\mathbf{w}}^{(m),(L)}\), and \(\overline{\mathbf{w}}^{(m),(R)}\) represent the parameters of the root (top) node, all internal nodes of the left subtree, and all internal nodes of the right subtree of the \(m\)-th tree at the initial values, respectively. Now, we define \(k^{(T)}_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x}})\), \(k^{(L)}_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x}})\), \(k^{(R)}_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x}})\), and \(k^{(B)}_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x}})\) as follows:

\[k^{(T)}_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x}}) =\mathbb{E}\left[\left\langle\nabla_{\overline{\mathbf{w}}^{(m),(T)}} h^{(m)}\left(\mathbf{x};\mathbf{\theta}^{(m)}_{0}\right),\nabla_{\overline{\mathbf{w}}^{(m),(T )}}h^{(m)}\left(\tilde{\mathbf{x}};\mathbf{\theta}^{(m)}_{0}\right)\right)\right], \tag{71}\] \[k^{(L)}_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x}}) =\mathbb{E}\left[\left\langle\nabla_{\overline{\mathbf{w}}^{(m),(L)}} h^{(m)}\left(\mathbf{x};\mathbf{\theta}^{(m)}_{0}\right),\nabla_{\overline{\mathbf{w}}^{(m),(L)} }h^{(m)}\left(\tilde{\mathbf{x}};\mathbf{\theta}^{(m)}_{0}\right)\right\rangle\right],\] (72) \[k^{(R)}_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x}}) =\mathbb{E}\left[\left\langle\nabla_{\overline{\mathbf{w}}^{(m),(R)}} h^{(m)}\left(\mathbf{x};\mathbf{\theta}^{(m)}_{0}\right),\nabla_{\overline{\mathbf{w}}^{(m),(R)} }h^{(m)}\left(\tilde{\mathbf{x}};\mathbf{\theta}^{(m)}_{0}\right)\right\rangle\right],\] (73) \[k^{(B)}_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x}}) =\mathbb{E}\left[\left\langle\nabla_{\overline{\mathbf{w}}^{(m)}}h^{ (m)}\left(\mathbf{x};\mathbf{\theta}^{(m)}_{0}\right),\nabla_{\overline{\mathbf{w}}^{(m)}} h^{(m)}\left(\tilde{\mathbf{x}};\mathbf{\theta}^{(m)}_{0}\right)\right\rangle\right]. \tag{74}\]

Note that, since the initial parameters of each tree follow the same distribution, the definitions mentioned above do not depend on the choice of \(m\). Now, assuming that the initial parameters follow a multivariate normal distribution independent across dimensions, by using the law of large numbers, Eqs. (68), (69), and (70) converge in probability, respectively, to \(k^{(T)}_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x}})\), \(k^{(L)}_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x}})+k^{(R)}_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x}})\), and \(k^{(B)}_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x}})\). From the continuous mapping theorem, it follows that \(k_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x}})=k^{(T)}_{\mathrm{TNTK}}(\mathbf{x}, \tilde{\mathbf{x}})+k^{(L)}_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x}})+k^{(R)}_{ \mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x}})+k^{(B)}_{\mathrm{TNTK}}(\mathbf{x},\tilde{ \mathbf{x}})\) can be expressed [21]. Note that the convergence to the above TNTK also holds for the initialization strategy of ST-UCB. Actually, regarding Eq. (68), we have

\[\frac{1}{M}\sum_{m=1}^{M}\left\langle\nabla_{\overline{\mathbf{w}}^{ (m),(T)}}h^{(m)}\left(\mathbf{x};\mathbf{\theta}^{(m)}_{0}\right),\nabla_{\overline{ \mathbf{w}}^{(m),(T)}}h^{(m)}\left(\tilde{\mathbf{x}};\mathbf{\theta}^{(m)}_{0}\right)\right\rangle \tag{75}\] \[=\frac{1}{2}\Big{[}\frac{2}{M}\sum_{m=1}^{M/2}\left\langle\nabla_ {\overline{\mathbf{w}}^{(m),(T)}}h^{(m)}\left(\mathbf{x};\mathbf{\theta}^{(m)}_{0}\right), \nabla_{\overline{\mathbf{w}}^{(m),(T)}}h^{(m)}\left(\tilde{\mathbf{x}};\mathbf{\theta}^{(m )}_{0}\right)\right\rangle\] \[\quad+\frac{2}{M}\sum_{m=1}^{M/2}\left\langle\nabla_{\overline{ \mathbf{w}}^{(M/2+m),(T)}}h^{(M/2+m)}\left(\mathbf{x};\mathbf{\theta}^{(M/2+m)}_{0}\right), \nabla_{\overline{\mathbf{w}}^{(M/2+m),(T)}}h^{(m)}\left(\tilde{\mathbf{x}};\mathbf{ \theta}^{(M/2+m)}_{0}\right)\right\rangle\Big{]}. \tag{76}\]

The first and second terms correspond to the inner products of gradients when initializing \(M/2\) soft trees with the standard normal distribution and converge in probability to \(k^{(T)}_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x}})\). Therefore, by the continuous mapping theorem, Eq. (75) converges in probability to \(k^{(T)}_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x}})\). Similar arguments apply to \(k^{(L)}_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x}})+k^{(R)}_{\mathrm{TNTK}}(\mathbf{x}, \tilde{\mathbf{x}})\) and \(k^{(B)}_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x}})\), indicating that in the initialization strategy of ST-UCB, \(\langle\nabla_{\mathbf{\theta}_{0}}h(\mathbf{x};\mathbf{\theta}_{0}),\nabla_{\mathbf{\theta}_{0 }}h\left(\tilde{\mathbf{x}};\mathbf{\theta}_{0}\right)\rangle\) also converges in probability to \(k_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x}})\). The following three lemmas each evaluate the concentration to \(k^{(T)}_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x}})\), \(k^{(L)}_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x}})+k^{(R)}_{\mathrm{TNTK}}(\mathbf{x}, \tilde{\mathbf{x}})\), and \(k^{(B)}_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x}})\) for Eqs. (68), (69), and (70), respectively.

**Lemma B.1**.: _For any \(\mathbf{x},\tilde{\mathbf{x}}\in\mathbb{S}^{d-1}\) and \(\epsilon\geq 0\), we have_

\[\mathbb{P}\left(\left|k^{(T)}_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x }})-\frac{1}{M}\sum_{m=1}^{M}\left\langle\nabla_{\overline{\mathbf{w}}^{(m),(T)} }h^{(m)}\left(\mathbf{x};\mathbf{\theta}^{(m)}_{0}\right),\nabla_{\overline{\mathbf{w}}^{(m),( T)}}h^{(m)}\left(\tilde{\mathbf{x}};\mathbf{\theta}^{(m)}_{0}\right)\right\rangle\right|\leq\epsilon\right)\] \[\geq 1-4\exp\left(-c\min\left\{\frac{\epsilon^{2}}{K^{2}},\frac{ \epsilon}{K}\right\}M\right), \tag{77}\]

_where \(K=4\alpha^{2}C\mathcal{L}^{2}\). Furthermore, \(C,c>0\) are absolute constants._

**Lemma B.2**.: _For any \(\mathbf{x},\tilde{\mathbf{x}}\in\mathbb{S}^{d-1}\), \(\epsilon\geq 0\), and \(\mathcal{D}\geq 2\), we have_

\[\mathbb{P}\left(\left|k^{(L)}_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x} })-\frac{1}{M}\sum_{m=1}^{M}\left\langle\nabla_{\overline{\mathbf{w}}^{(m),(L)}}h ^{(m)}\left(\mathbf{x};\mathbf{\theta}^{(m)}_{0}\right),\nabla_{\overline{\mathbf{w}}^{(m),(L)}}h^{(m)}\left(\tilde{\mathbf{x}};\mathbf{\theta}^{(m)}_{0}\right)\right\rangle \right|\leq\epsilon\right)\] \[\geq 1-4\exp\left(-c\min\left\{\frac{\epsilon^{2}}{K^{2}},\frac{ \epsilon}{K}\right\}M\right). \tag{78}\]

_Furthermore, we have_

\[\mathbb{P}\left(\left|k^{(R)}_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x }})-\frac{1}{M}\sum_{m=1}^{M}\left\langle\nabla_{\overline{\mathbf{w}}^{(m),(R)}}h ^{(m)}\left(\mathbf{x};\mathbf{\theta}^{(m)}_{0}\right),\nabla_{\overline{\mathbf{w}}^{(m),(R)}}h^{(m)}\left(\tilde{\mathbf{x}};\mathbf{\theta}^{(m)}_{0}\right)\right\rangle \right|\leq\epsilon\right)\] \[\geq 1-4\exp\left(-c\min\left\{\frac{\epsilon^{2}}{K^{2}},\frac{ \epsilon}{K}\right\}M\right). \tag{79}\]

**Lemma B.3**.: _For any \(\mathbf{x},\tilde{\mathbf{x}}\in\mathbb{S}^{d-1}\) and \(\epsilon\geq 0\), we have_

\[\mathbb{P}\left(\left|k^{(B)}_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x }})-\frac{1}{M}\sum_{m=1}^{M}\left\langle\nabla_{\overline{\mathbf{x}}^{(m)}}h^{(m )}\left(\mathbf{x};\mathbf{\theta}^{(m)}_{0}\right),\nabla_{\overline{\mathbf{x}}^{(m)}}h^{ (m)}\left(\tilde{\mathbf{x}};\mathbf{\theta}^{(m)}_{0}\right)\right\rangle\right|\leq \epsilon\right) \tag{80}\] \[\geq 1-4\exp\left(-\frac{\tilde{\epsilon}\epsilon^{2}M}{\mathcal{L }^{2}}\right).\]

_Here, \(\tilde{c}>0\) is an absolute constant._

In proving the above lemmas, following [21], we denote a single soft tree of depth \(\tilde{\mathcal{D}}\) determined by the internal node parameters \(\mathbf{w}\in\mathbb{R}^{d(2^{\mathcal{D}}-1)}\) and leaf node parameters \(\mathbf{\pi}\in\mathbb{R}^{2^{\tilde{\mathcal{D}}}}\) as \(h_{\tilde{\mathcal{D}}}(\cdot,\mathbf{w},\mathbf{\pi})\).

Proof of Lemma b.1.: Fix any \(\tilde{\mathcal{D}}\leq\mathcal{D}\), \(\mathbf{w}\in\mathbb{R}^{d(2^{\tilde{\mathcal{D}}}-1)}\), and \(\mathbf{\pi}\in\mathbb{R}^{2^{\tilde{\mathcal{D}}}}\). From the definition of the soft tree, the following recursive formula holds [21]:

\[h_{\tilde{\mathcal{D}}}(\mathbf{x},\mathbf{w},\mathbf{\pi}) \tag{81}\] \[=\sigma\left(\mathbf{w}^{(T)\top}\mathbf{x}\right)h_{\tilde{\mathcal{D}}- 1}\left(\mathbf{x},\mathbf{w}^{(L)},\mathbf{\pi}^{(L)}\right)+\left[1-\sigma\left(\mathbf{w}^ {(T)\top}\mathbf{x}\right)\right]h_{\tilde{\mathcal{D}}-1}\left(\mathbf{x},\mathbf{w}^{(R )},\mathbf{\pi}^{(R)}\right).\]

Note that \(h^{(m)}(\mathbf{x};\mathbf{\theta}^{(m)})=h_{\mathcal{D}}\left(\mathbf{x},\mathbf{w}^{(m)},\bm {\pi}^{(m)}\right)\). Here, \(\mathbf{\pi}^{(L)},\mathbf{\pi}^{(R)}\) represent the parameters of the leaves belonging to the left and right subtrees, respectively. From Eq. (81), we have

\[\nabla_{\mathbf{w}^{(T)}}h_{\tilde{\mathcal{D}}}(\mathbf{x},\mathbf{w},\mathbf{ \pi})=\mathbf{x}\dot{\sigma}\left(\mathbf{w}^{(T)\top}\mathbf{x}\right)\left[h_{\tilde{ \mathcal{D}}-1}\left(\mathbf{x},\mathbf{w}^{(L)},\mathbf{\pi}^{(L)}\right)-h_{\tilde{ \mathcal{D}}-1}\left(\mathbf{x},\mathbf{w}^{(R)},\mathbf{\pi}^{(R)}\right)\right], \tag{82}\]

where \(\dot{\sigma}(b)\coloneqq\alpha\exp(-\alpha^{2}b^{2})/\sqrt{\pi}\) is the derivative of \(\sigma(\cdot)\). Therefore,

\[\langle\nabla_{\mathbf{w}^{(T)}}h_{\tilde{\mathcal{D}}}(\mathbf{x},\mathbf{w },\mathbf{\pi}),\nabla_{\mathbf{w}^{(T)}}h_{\tilde{\mathcal{D}}}(\tilde{\mathbf{x}},\mathbf{w}, \mathbf{\pi})\rangle \tag{83}\] \[=\mathbf{x}^{\top}\tilde{\mathbf{x}}\dot{\sigma}\left(\mathbf{w}^{(T)\top}\mathbf{ x}\right)\dot{\sigma}\left(\mathbf{w}^{(T)\top}\tilde{\mathbf{x}}\right)\left[h_{\tilde{ \mathcal{D}}-1}\left(\mathbf{x},\mathbf{w}^{(L)},\mathbf{\pi}^{(L)}\right)h_{\tilde{ \mathcal{D}}-1}\left(\tilde{\mathbf{x}},\mathbf{w}^{(L)},\mathbf{\pi}^{(L)}\right)\right.\] \[\quad-h_{\tilde{\mathcal{D}}-1}\left(\mathbf{x},\mathbf{w}^{(L)},\mathbf{ \pi}^{(L)}\right)h_{\tilde{\mathcal{D}}-1}\left(\tilde{\mathbf{x}},\mathbf{w}^{(R)}, \mathbf{\pi}^{(R)}\right)\] \[\quad-h_{\tilde{\mathcal{D}}-1}\left(\mathbf{x},\mathbf{w}^{(R)},\mathbf{\pi }^{(R)}\right)h_{\tilde{\mathcal{D}}-1}\left(\tilde{\mathbf{x}},\mathbf{w}^{(L)},\bm {\pi}^{(L)}\right)\] \[\quad+h_{\tilde{\mathcal{D}}-1}\left(\mathbf{x},\mathbf{w}^{(R)},\mathbf{\pi }^{(R)}\right)h_{\tilde{\mathcal{D}}-1}\left(\tilde{\mathbf{x}},\mathbf{w}^{(R)},\mathbf{ \pi}^{(R)}\right)\right]\!.\]

Here, let us define \(p_{\tilde{\mathcal{D}},l}(\mathbf{x},\mathbf{w})\coloneqq\prod_{n=1}^{2^{\mathcal{D}}-1 }\sigma\left(\mathbf{w}_{n}^{\top}\mathbf{x}\right)^{\frac{1}{l_{i^{\prime}n^{\prime}}} }\left[1-\sigma\left(\mathbf{w}_{n}^{\top}\mathbf{x}\right)\right]^{\frac{1}{l_{i^{ \prime}n^{\prime}}}}\) as the weight probability function of leaf \(l\) in a soft tree of depth \(\tilde{\mathcal{D}}\); then, we have

\[h_{\tilde{\mathcal{D}}-1}\left(\mathbf{x},\mathbf{w}^{(L)},\mathbf{\pi}^{(L)}\right)=\sum_{ l=1}^{2^{\tilde{\mathcal{D}}-1}}\pi_{l}^{(L)}p_{\tilde{\mathcal{D}}-1,l}\left(\mathbf{x},\mathbf{w}^{(L)} \right). \tag{84}\]Since the sub-Gaussian norm of the normal distribution is bounded from above by a constant multiple of its standard deviation (see, e.g., Example 2.5.6 in [39]), for any \(m\in[M]\), we have

\[\left\|h_{\mathcal{D}-1}\left(\mathbf{x},\overline{\mathbf{w}}^{(m),(L)}, \overline{\mathbf{\pi}}^{(m),(L)}\right)\right\|_{\psi_{2}} =\left\|\sum_{l=1}^{2^{D-1}}\overline{\pi}_{l}^{(m),(L)}p_{\mathcal{ D}-1,l}\left(\mathbf{x},\overline{\mathbf{w}}^{(m),(L)}\right)\right\|_{\psi_{2}} \tag{85}\] \[\leq\left\|\sum_{l=1}^{2^{D-1}}\overline{\pi}_{l}^{(m),(L)}\right\| _{\psi_{2}}\] (86) \[\leq C\mathcal{L}, \tag{87}\]

where the first inequality follows from \(\left|p_{\mathcal{D}-1,l}\left(\mathbf{x},\overline{\mathbf{w}}^{(m),(L)}\right) \right|\leq 1\). Similarly,

\[\left\|h_{\mathcal{D}-1}\left(\mathbf{x},\overline{\mathbf{w}}^{(m),(R)},\overline{ \mathbf{\pi}}^{(m),(R)}\right)\right\|_{\psi_{2}}\leq C\mathcal{L}. \tag{88}\]

Due to \(\|\hat{\sigma}(\cdot)\|_{\infty}\leq\alpha/\sqrt{\pi}\), \(\left|\mathbf{x}^{\top}\tilde{\mathbf{x}}\right|\leq 1\), and Lemma E.4, we obtain

\[\left\|\left\langle\nabla_{\overline{\mathbf{w}}^{(T)}}h^{(m)}\left(\mathbf{x}; \overline{\mathbf{\theta}}^{(m)}\right),\nabla_{\overline{\mathbf{w}}^{(T)}}h^{(m)} \left(\tilde{\mathbf{x}};\overline{\mathbf{\theta}}^{(m)}\right)\right\rangle\right\|_ {\psi_{1}}\leq\frac{4C^{2}\mathcal{L}^{2}\alpha^{2}}{\pi}. \tag{89}\]

From the centering lemma (Lemma E.3), there exists an absolute constant \(\tilde{C}>0\) such that

\[\left\|k_{\mathrm{TNTK}}^{(T)}(\mathbf{x},\tilde{\mathbf{x}})-\left\langle \nabla_{\overline{\mathbf{w}}^{(T)}}h^{(m)}\left(\mathbf{x};\overline{\mathbf{\theta}}^{( m)}\right),\nabla_{\overline{\mathbf{w}}^{(T)}}h^{(m)}\left(\tilde{\mathbf{x}}; \overline{\mathbf{\theta}}^{(m)}\right)\right\rangle\right\|_{\psi_{1}} \leq\frac{4\tilde{C}C^{2}\mathcal{L}^{2}\alpha^{2}}{\pi} \tag{90}\] \[\leq 4\tilde{C}C^{2}\mathcal{L}^{2}\alpha^{2}. \tag{91}\]

Therefore, taking \(\tilde{C}C^{2}\) as a new absolute constant \(C\) and using the independence of parameters for each \(m\in[M/2]\), the application of Bernstein's inequality (Lemma E.2) yields

\[\mathbb{P}\left(\left|k_{\mathrm{TNTK}}^{(T)}(\mathbf{x},\tilde{\mathbf{ x}})-\frac{2}{M}\sum_{m=1}^{M/2}\left\langle\nabla_{\overline{\mathbf{w}}^{(m),(T)}}h ^{(m)}\left(\mathbf{x};\mathbf{\theta}_{0}^{(m)}\right),\nabla_{\overline{\mathbf{w}}^{(m),(T)}}h^{(m)}\left(\tilde{\mathbf{x}};\mathbf{\theta}_{0}^{(m)}\right)\right\rangle \right|\geq\epsilon\right)\] \[\leq 2\exp\left(-c\min\left\{\frac{\epsilon^{2}}{2K^{2}},\frac{ \epsilon}{2K}\right\}M\right). \tag{92}\]

Note that the similar inequality also holds for \(m\in[M]\setminus[M/2]\):

\[\mathbb{P}\left(\left|k_{\mathrm{TNTK}}^{(T)}(\mathbf{x},\tilde{\bm {x}})-\frac{2}{M}\sum_{m=M/2+1}^{M}\left\langle\nabla_{\overline{\mathbf{w}}^{(m),(T)}}h^{(m)}\left(\mathbf{x};\mathbf{\theta}_{0}^{(m)}\right),\nabla_{\overline{\mathbf{ w}}^{(m),(T)}}h^{(m)}\left(\tilde{\mathbf{x}};\mathbf{\theta}_{0}^{(m)}\right) \right\rangle\right|\geq\epsilon\right)\] \[\leq 2\exp\left(-c\min\left\{\frac{\epsilon^{2}}{2K^{2}},\frac{ \epsilon}{2K}\right\}M\right). \tag{93}\]

By taking union bound in Eqs. (92) and (93) and taking \(c/2\) as an new absolute constant \(c\), we obtain the desired result.

Proof of Lemma b.2.: We only show Eq. (78) for simplicity. Fix any \(\mathbf{w}\in\mathbb{R}^{d\mathcal{N}}\) and \(\mathbf{\pi}\in\mathbb{R}^{\mathcal{L}}\) corresponding to the parameters of a soft tree of depth \(\mathcal{D}\). Furthermore, let \(\mathbf{w}_{i:}\) and \(\mathbf{\pi}_{i:}\)\((1\leq i\leq\mathcal{N})\) represent the internal node parameter vectors and the leaf node parameter vectors, respectively, for the subtree rooted at the \(i\)-th internal node (note that the parameter indices are assigned in breadth-first order, hence by definition, \(\mathbf{w}_{2:}=\mathbf{w}^{(L)}\), \(\mathbf{w}_{3:}=\mathbf{w}^{(R)}\)). From Eq. (81), we have:

\[\nabla_{\mathbf{w}^{(L)}}h_{\mathcal{D}}(\mathbf{x},\mathbf{w},\mathbf{\pi})=\sigma\left(\mathbf{w} ^{(T)\top}\mathbf{x}\right)\nabla_{\mathbf{w}^{(L)}}h_{\mathcal{D}-1}\left(\mathbf{x},\mathbf{ w}^{(L)},\mathbf{\pi}^{(L)}\right). \tag{94}\]Given that \(\|\sigma(\cdot)\|_{\infty}\leq 1\), for any \(m\in[M]\), we have:

\[\left\|\left\langle\nabla_{\overline{\mathbf{w}}^{(m),(L)}}h^{(m)}\left( \mathbf{x};\mathbf{\theta}_{0}^{(m)}\right),\nabla_{\mathbf{w}^{(m),(L)}}h^{(m)}\left( \tilde{\mathbf{x}};\mathbf{\theta}_{0}^{(m)}\right)\right\rangle\right\|_{\psi_{1}}\] \[\leq\left\|\left\langle\nabla_{\overline{\mathbf{w}}^{(m),(L)}}h_{ \mathcal{D}-1}\left(\mathbf{x},\overline{\mathbf{w}}^{(m),(L)},\overline{\mathbf{\pi}}^{(m ),(L)}\right),\nabla_{\overline{\mathbf{w}}^{(m),(L)}}h_{\mathcal{D}-1}\left( \tilde{\mathbf{x}},\overline{\mathbf{w}}^{(m),(L)},\overline{\mathbf{\pi}}^{(m),(L)} \right)\right\rangle\right\|_{\psi_{1}}. \tag{95}\]

Now, decomposing the gradient of the subtree rooted at the left child of the root node, we have:

\[\left\langle\nabla_{\mathbf{w}^{(L)}}h_{\mathcal{D}-1}\left(\mathbf{x}, \mathbf{w}^{(L)},\mathbf{\pi}^{(L)}\right),\nabla_{\mathbf{w}^{(L)}}h_{\mathcal{D}-1}\left( \tilde{\mathbf{x}},\mathbf{w}^{(L)},\mathbf{\pi}^{(L)}\right)\right\rangle \tag{96}\] \[=\left\langle\nabla_{\mathbf{w}_{2:}}h_{\mathcal{D}-1}\left(\mathbf{x}, \mathbf{w}_{2:},\mathbf{\pi}_{2:}\right),\nabla_{\mathbf{w}_{2:}}h_{\mathcal{D}-1}\left( \tilde{\mathbf{x}},\mathbf{w}_{2:},\mathbf{\pi}_{2:}\right)\right\rangle\] (97) \[=\left\langle\nabla_{\mathbf{w}_{2:}^{(T)}}h_{\mathcal{D}-1}\left(\mathbf{ x},\mathbf{w}_{2:},\mathbf{\pi}_{2:}\right),\nabla_{\mathbf{w}_{2:}^{(T)}}h_{\mathcal{D}-1} \left(\tilde{\mathbf{x}},\mathbf{w}_{2:},\mathbf{\pi}_{2:}\right)\right\rangle\] \[+\left\langle\nabla_{\mathbf{w}_{2:}^{(L)}}h_{\mathcal{D}-1}\left(\mathbf{ x},\mathbf{w}_{2:},\mathbf{\pi}_{2:}\right),\nabla_{\mathbf{w}_{2:}^{(L)}}h_{\mathcal{D}-1} \left(\tilde{\mathbf{x}},\mathbf{w}_{2:},\mathbf{\pi}_{2:}\right)\right\rangle\] (98) \[+\left\langle\nabla_{\mathbf{w}_{2:}^{(R)}}h_{\mathcal{D}-1}\left(\mathbf{ x},\mathbf{w}_{2:},\mathbf{\pi}_{2:}\right),\nabla_{\mathbf{w}_{2:}^{(R)}}h_{\mathcal{D}-1} \left(\tilde{\mathbf{x}},\mathbf{w}_{2:},\mathbf{\pi}_{2:}\right)\right\rangle.\]

Considering that \(\mathbf{w}_{2:}\) are parameters for a soft tree with \(\mathcal{L}/2\) leaves, similar to the proof of Lemma B.1, there exists an absolute constant \(C\) such that for any \(m\in[M]\):

\[\left\|\left\langle\nabla_{\overline{\mathbf{w}}_{2:}^{(m),(T)}}h_{ \mathcal{D}-1}\left(\mathbf{x},\overline{\mathbf{w}}_{2:}^{(m)},\overline{\mathbf{\pi}}_{2 :}^{(m)}\right),\nabla_{\overline{\mathbf{w}}_{2:}^{(m),(T)}}h_{\mathcal{D}-1} \left(\tilde{\mathbf{x}},\overline{\mathbf{w}}_{2:}^{(m)},\overline{\mathbf{\pi}}_{2:}^{( m)}\right)\right\rangle\right\|_{\psi_{1}}\leq 4\alpha^{2}C\pi^{-1}(\mathcal{L}/2)^{2}. \tag{99}\]

Similarly to Eq. (95), we have:

\[\left\|\left\langle\nabla_{\overline{\mathbf{w}}_{2:}^{(m),(L)}}h_{ \mathcal{D}-1}\left(\mathbf{x},\overline{\mathbf{w}}_{2:}^{(m)},\overline{\mathbf{\pi}}_{2 :}^{(m)}\right),\nabla_{\overline{\mathbf{w}}_{2:}^{(m),(L)}}h_{\mathcal{D}-1}\left( \tilde{\mathbf{x}},\overline{\mathbf{w}}_{2:}^{(m)},\overline{\mathbf{\pi}}_{2:}^{(m)} \right)\right\rangle\right\|_{\psi_{1}}\] \[\leq\left\|\left\langle\nabla_{\overline{\mathbf{w}}_{2:}^{(m),(L)}}h _{\mathcal{D}-2}\left(\mathbf{x},\overline{\mathbf{w}}_{2:}^{(m),(L)},\overline{\mathbf{\pi}} _{2:}^{(m),(L)}\right),\nabla_{\overline{\mathbf{w}}_{2:}^{(m),(L)}}h_{\mathcal{D}-2 }\left(\tilde{\mathbf{x}},\overline{\mathbf{w}}_{2:}^{(m),(L)},\overline{\mathbf{\pi}}_{2 :}^{(m),(L)}\right)\right\rangle\right\|_{\psi_{1}}. \tag{100}\]

Similarly, for the right subtree:

\[\left\|\left\langle\nabla_{\overline{\mathbf{w}}_{2:}^{(m),(R)}}h_{ \mathcal{D}-1}\left(\mathbf{x},\overline{\mathbf{w}}_{2:}^{(m)},\overline{\mathbf{\pi}}_{2 :}^{(m)}\right),\nabla_{\overline{\mathbf{w}}_{2:}^{(m),(R)}}h_{\mathcal{D}-1} \left(\tilde{\mathbf{x}},\overline{\mathbf{w}}_{2:}^{(m)},\overline{\mathbf{\pi}}_{2:}^{(m)} \right)\right\rangle\right\|_{\psi_{1}}\] \[\leq\left\|\left\langle\nabla_{\overline{\mathbf{w}}_{2:}^{(m),(R)}}h _{\mathcal{D}-2}\left(\mathbf{x},\overline{\mathbf{w}}_{2:}^{(m),(R)},\overline{\mathbf{\pi}}_{2 :}^{(m),(R)}\right),\nabla_{\overline{\mathbf{w}}_{2:}^{(m),(R)}}h_{\mathcal{D}-2} \left(\tilde{\mathbf{x}},\overline{\mathbf{w}}_{2:}^{(m),(R)},\overline{\mathbf{\pi}}_{2:}^{( m),(R)}\right)\right\rangle\right\|_{\psi_{1}}. \tag{101}\]

Therefore,

\[\left\|\left\langle\nabla_{\overline{\mathbf{w}}^{(m),(L)}}h_{\mathcal{D}-1} \left(\mathbf{x},\overline{\mathbf{w}}^{(m),(L)},\overline{\mathbf{\pi}}^{(m),(L)}\right), \nabla_{\overline{\mathbf{w}}^{(m),(L)}}h_{\mathcal{D}-1}\left(\tilde{\mathbf{x}}, \overline{\mathbf{w}}^{(m),(L)},\overline{\mathbf{\pi}}^{(m),(L)}\right)\right\rangle \right\|_{\psi_{1}}\] \[\leq 4\alpha^{2}C\pi^{-1}(\mathcal{L}/2)^{2}\] \[\quad+\left\|\left\langle\nabla_{\overline{\mathbf{w}}_{2:}^{(m),(L)}}h _{\mathcal{D}-2}\left(\mathbf{x},\overline{\mathbf{w}}_{2:}^{(m),(L)},\overline{\mathbf{\pi}}_{2 :}^{(m),(L)}\right),\nabla_{\overline{\mathbf{w}}_{2:}^{(m),(L)}}h_{\mathcal{D}-2} \left(\tilde{\mathbf{x}},\overline{\mathbf{w}}_{2:}^{(m),(L)},\overline{\mathbf{\pi}}_{2:}^{( m),(L)}\right)\right\rangle\right\|_{\psi_{1}}\] \[\quad+\left\|\left\langle\nabla_{\overline{\mathbf{w}}_{2:}^{(m),(R)}}h _{\mathcal{D}-2}\left(\mathbf{x},\overline{\mathbf{w}}_{2:}^{(m),(R)},\overline{\mathbf{\pi}}_{2 :}^{(m),(R)}\right),\nabla_{\overline{\mathbf{w}}_{2:}^{(m),(R)}}h_{\mathcal{D}-2} \left(\tilde{\mathbf{x}},\overline{\mathbf{w}}_{2:}^{(m),(R)},\overline{\mathbf{\pi}}_{2 :}^{(m),(R)}\right)\right\rangle\right\|_{\psi_{1}}. \tag{102}\]

By repeating the above described argument, we can further decompose the second and third term of Eq. (102) as follows:\[\left\|\left\langle\nabla_{\overline{\mathbf{w}}^{(m),(L)}}h_{\mathcal{D}-1} \left(\mathbf{x},\overline{\mathbf{w}}^{(m),(L)},\overline{\mathbf{\pi}}^{(m),(L)}\right), \nabla_{\overline{\mathbf{w}}^{(m),(L)}}h_{\mathcal{D}-1}\left(\tilde{\mathbf{x}}, \overline{\mathbf{w}}^{(m),(L)},\overline{\mathbf{\pi}}^{(m),(L)}\right)\right\rangle \right\|_{\psi_{1}} \tag{103}\] \[\leq 4\alpha^{2}C\pi^{-1}(\mathcal{L}/2)^{2}\] (104) \[\quad+2\times 4\alpha^{2}C\pi^{-1}(\mathcal{L}/4)^{2}\] (105) \[\quad+\left\|\left\langle\nabla_{\overline{\mathbf{w}}^{(m)}_{\mathrm{ s}}:}h_{\mathcal{D}-3}\left(\mathbf{x},\overline{\mathbf{w}}^{(m)}_{\mathrm{s}},\overline{ \mathbf{\pi}}^{(m)}_{\mathrm{s}}\right),\nabla_{\overline{\mathbf{w}}^{(m)}_{\mathrm{s} }}h_{\mathcal{D}-3}\left(\tilde{\mathbf{x}},\overline{\mathbf{w}}^{(m)}_{\mathrm{s}}, \overline{\mathbf{\pi}}^{(m)}_{\mathrm{s}}\right)\right\rangle\right\|_{\psi_{1}}\] (106) \[\quad+\left\|\left\langle\nabla_{\overline{\mathbf{w}}^{(m)}_{\mathrm{ s}}:}h_{\mathcal{D}-3}\left(\mathbf{x},\overline{\mathbf{w}}^{(m)}_{\mathrm{s}}, \overline{\mathbf{\pi}}^{(m)}_{\mathrm{s}}\right),\nabla_{\overline{\mathbf{w}}^{(m)}_{ \mathrm{s}}}h_{\mathcal{D}-3}\left(\tilde{\mathbf{x}},\overline{\mathbf{w}}^{(m)}_{ \mathrm{s}},\overline{\mathbf{\pi}}^{(m)}_{\mathrm{s}}\right)\right\rangle\right\|_ {\psi_{1}}\] (107) \[\quad+\left\|\left\langle\nabla_{\overline{\mathbf{w}}^{(m)}_{\mathrm{ 10}}:}h_{\mathcal{D}-3}\left(\mathbf{x},\overline{\mathbf{w}}^{(m)}_{\mathrm{10}}, \overline{\mathbf{\pi}}^{(m)}_{\mathrm{10}}\right),\nabla_{\overline{\mathbf{w}}^{(m)} _{\mathrm{10}}}h_{\mathcal{D}-3}\left(\tilde{\mathbf{x}},\overline{\mathbf{w}}^{(m)}_{ \mathrm{10}},\overline{\mathbf{\pi}}^{(m)}_{\mathrm{10}}\right)\right\rangle\right\|_ {\psi_{1}}\] (108) \[\quad+\left\|\left\langle\nabla_{\overline{\mathbf{w}}^{(m)}_{\mathrm{ 11}}:}h_{\mathcal{D}-3}\left(\mathbf{x},\overline{\mathbf{w}}^{(m)}_{\mathrm{11}}, \overline{\mathbf{\pi}}^{(m)}_{\mathrm{11}}\right),\nabla_{\overline{\mathbf{w}}^{(m)} _{\mathrm{11}}:}h_{\mathcal{D}-3}\left(\tilde{\mathbf{x}},\overline{\mathbf{w}}^{(m)}_{ \mathrm{11}},\overline{\mathbf{\pi}}^{(m)}_{\mathrm{11}}\right)\right\rangle\right\|_ {\psi_{1}}. \tag{109}\]

By recursively applying the above discussion until reaching the leaves of the tree, we find:

\[\left\|\left\langle\nabla_{\overline{\mathbf{w}}^{(m),(L)}}h_{ \mathcal{D}-1}\left(\mathbf{x},\overline{\mathbf{w}}^{(m),(L)},\overline{\mathbf{\pi}}^{( m),(L)}\right),\nabla_{\overline{\mathbf{w}}^{(m),(L)}}h_{\mathcal{D}-1}\left( \tilde{\mathbf{x}},\overline{\mathbf{w}}^{(m),(L)},\overline{\mathbf{\pi}}^{(m),(L)}\right) \right\rangle\right\|_{\psi_{1}}\] \[\leq 4\alpha^{2}C\pi^{-1}\left(\frac{\mathcal{L}}{2}\right)^{2}+2 \times 4\alpha^{2}C\pi^{-1}\left(\frac{\mathcal{L}}{4}\right)^{2}+\cdots+2^{ \mathcal{D}-2}\times 4\alpha^{2}C\pi^{-1}\left(\frac{\mathcal{L}}{2^{\mathcal{D}-1}} \right)^{2}. \tag{110}\]

Thus, we conclude:

\[\left\|\left\langle\nabla_{\overline{\mathbf{w}}^{(m),(L)}}h^{(m)} \left(\mathbf{x};\mathbf{\theta}^{(m)}_{0}\right),\nabla_{\mathbf{w}^{(m),(L)}}h^{(m)} \left(\tilde{\mathbf{x}};\mathbf{\theta}^{(m)}_{0}\right)\right\rangle\right\|_{\psi_{1}}\] (111) \[\leq\frac{4\alpha^{2}C}{\pi}\sum_{i=1}^{\mathcal{D}-1}2^{i-1}\frac {\mathcal{L}^{2}}{2^{2i}}\] (112) \[\leq\frac{2\alpha^{2}C\mathcal{L}^{2}}{\pi}\sum_{i=1}^{\mathcal{D }-1}2^{-i}\] (113) \[\leq\frac{2\alpha^{2}C\mathcal{L}^{2}}

Proof of Lemma 3.2.: Fix any \(\epsilon>0\) such that \(\epsilon\leq K\). Then, \(\min\left\{\frac{\mathcal{L}^{2}}{K^{2}},\frac{\epsilon}{K}\right\}=\frac{ \epsilon^{2}}{K^{2}}\). Now,

\[M\geq\frac{K^{2}}{c\epsilon^{2}}\ln\frac{16}{\delta}\Rightarrow 1-4\exp\left(-c \frac{\epsilon^{2}}{K^{2}}M\right)\geq 1-\frac{\delta}{4}, \tag{120}\]

\[M\geq\frac{\mathcal{L}^{2}}{\tilde{c}\epsilon^{2}}\ln\frac{16}{\delta} \Rightarrow 1-4\exp\left(-\frac{\tilde{c}\epsilon^{2}M}{\mathcal{L}^{2}}\right) \geq 1-\frac{\delta}{4}. \tag{121}\]

Therefore, from Lemma B.1, Lemma B.2, and Lemma B.3, by applying the union bound,

\[M\geq\max\left\{\frac{K^{2}}{c},\frac{\mathcal{L}^{2}}{\tilde{c} }\right\}\epsilon^{-2}\ln\frac{16}{\delta} \tag{122}\] \[\Rightarrow\mathbb{P}\left(|k_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{ x}})-\langle g(\mathbf{x},\mathbf{\theta}_{0}),g(\tilde{\mathbf{x}},\mathbf{\theta}_{0})\rangle| \leq 4\varepsilon\right)\geq 1-\delta. \tag{123}\]

Finally, let \(\tilde{C}=\max\{1/c,1/\tilde{c}\}\), then

\[M\geq\tilde{C}\max\left\{K^{2},\mathcal{L}^{2}\right\}\epsilon^{-2}\ln\frac{1 6}{\delta} \tag{124}\]

\[\Rightarrow M\geq\max\left\{\frac{K^{2}}{c},\frac{\mathcal{L}^{2}}{\tilde{c}} \right\}\epsilon^{-2}\ln\frac{16}{\delta}. \tag{125}\]

By defining \(C^{(2)}_{\alpha,\mathcal{D}}\) as \(C^{(2)}_{\alpha,\mathcal{D}}=K\), the desired result is obtained. 

### Proof of Lemma 3.3

Proof scketchSince the parameters of the different soft trees are independent, we can confirm that the Hessian \(\mathbf{H}(\mathbf{x},\mathbf{\theta})\) is given as the block diagonal matrix. Since we know the fact that the spectral norm of the block diagonal matrix equals the maximum over the spectral norms of the block matrix, the remaining interest is the upper bound of the spectral norm of each block matrix. Then, we obtain Lemma 3.3 by carefully evaluating the upper bound of the spectral norm of each block matrix with its Frobenius norm.

Proof of Lemma 3.3.: Define \(\mathbf{H}^{(m)}\left(\mathbf{x},\mathbf{\theta}^{(m)}\right)=\nabla^{2}_{\mathbf{\theta}^{(m) }}h^{(m)}\left(\mathbf{x};\mathbf{\theta}^{(m)}\right)\in\mathbb{R}^{\tilde{p}\times \tilde{p}}\), where \(\tilde{p}=d\mathcal{N}+\mathcal{L}\). Then, \(\mathbf{H}(\mathbf{x},\mathbf{\theta})\) is represented by the following block diagonal matrix:

\[\mathbf{H}(\mathbf{x},\mathbf{\theta})=\frac{1}{\sqrt{M}}\begin{pmatrix}\mathbf{H}^{(1)}\left( \mathbf{x},\mathbf{\theta}^{(1)}\right)&\mathbf{0}_{\tilde{p}\times\tilde{p}}&\ldots&\mathbf{ 0}_{\tilde{p}\times\tilde{p}}\\ \mathbf{0}_{\tilde{p}\times\tilde{p}}&\mathbf{H}^{(2)}\left(\mathbf{x},\mathbf{\theta}^{(2)} \right)&\ldots&\mathbf{0}_{\tilde{p}\times\tilde{p}}\\ \vdots&\vdots&\ddots&\vdots\\ \mathbf{0}_{\tilde{p}\times\tilde{p}}&\mathbf{0}_{\tilde{p}\times\tilde{p}}&\ldots&\bm {H}^{(M)}\left(\mathbf{x},\mathbf{\theta}^{(M)}\right)\end{pmatrix}, \tag{126}\]

where \(\mathbf{0}_{\tilde{p}\times\tilde{p}}\) represents a \(\tilde{p}\times\tilde{p}\) zero matrix. Therefore,

\[\left\|\mathbf{H}(\mathbf{x},\mathbf{\theta})\right\|=\frac{1}{\sqrt{M}}\max_{m\in[M]} \left\|\mathbf{H}_{m}\left(\mathbf{x},\mathbf{\theta}^{(m)}\right)\right\|. \tag{127}\]

Here, assume the following event holds:

\[\forall m\in[M],\ \forall l\in[\mathcal{L}],\ \forall n\in[\mathcal{N}], \tag{128}\]

Since \(\mathbf{\theta}_{0}\) is initialized by a standard normal distribution, by the union bound, the above event occurs with probability at least \(1-\delta\). Therefore, it is sufficient to show that Eq. (11) holds under the event (128).

Now, the derivatives of \(h^{(m)}(\mathbf{x};\mathbf{\theta}^{(m)})\) up to the second order are given by:

\[\frac{\partial^{2}h^{(m)}\left(\mathbf{x};\mathbf{\theta}^{(m)}\right)}{ \partial\mathbf{w}^{(m)}_{n}\partial\mathbf{w}^{(m)}_{n}} =\sum_{l=1}^{\mathcal{L}}\pi^{(m)}_{l}\frac{\partial^{2}p_{l}( \mathbf{x};\mathbf{w}^{(m)})}{\partial\mathbf{w}^{(m)}_{n}\partial\mathbf{w}^{(m)}_{n}}, \tag{129}\] \[\frac{\partial^{2}h^{(m)}\left(\mathbf{x};\mathbf{\theta}^{(m)}\right)}{ \partial\mathbf{w}^{(m)}_{n}\partial\pi^{(m)}_{l}} =\frac{\partial p_{l}(\mathbf{x};\mathbf{w}^{(m)})}{\partial\mathbf{w}^{(m)} _{n}},\] (130) \[\frac{\partial^{2}h^{(m)}\left(\mathbf{x};\mathbf{\theta}^{(m)}\right)}{ \partial\pi^{(m)}_{l}\partial\pi^{(m)}_{l}} =0. \tag{131}\]

[MISSING_PAGE_EMPTY:24]

Moreover, we have

\[\left\|\frac{\partial^{2}h^{(m)}\left(\mathbf{x};\mathbf{\theta}^{(m)}\right) }{\partial\mathbf{w}_{n}^{(m)}\partial\mathbf{w}_{n}^{(m)}}\right\|_{F} \leq\sum_{l=1}^{\mathcal{L}}\left|\pi_{l}^{(m)}\right|\left\|\frac{ \partial^{2}p_{l}\left(\mathbf{x};\mathbf{w}^{(m)}\right)}{\partial\mathbf{w}_{n}^{(m)} \partial\mathbf{w}_{n}^{(m)}}\right\|_{F} \tag{144}\] \[\leq\sum_{l=1}^{\mathcal{L}}\left(\left|\pi_{l}^{(m)}-\overline{ \pi}_{l}^{(m)}\right|+\left|\overline{\pi}_{l}^{(m)}\right|\right)\left\|\frac{ \partial^{2}p_{l}\left(\mathbf{x};\mathbf{w}^{(m)}\right)}{\partial\mathbf{w}_{n}^{(m)} \partial\mathbf{w}_{n}^{(m)}}\right\|_{F}\] (145) \[\leq\sum_{l=1}^{\mathcal{L}}\left(R+\sqrt{2\ln\frac{2M(\mathcal{L }+\mathcal{N})}{\delta}}\right)\left\|\frac{\partial^{2}p_{l}\left(\mathbf{x};\bm {w}^{(m)}\right)}{\partial\mathbf{w}_{n}^{(m)}\partial\mathbf{w}_{n}^{(m)}}\right\|_{ F}. \tag{146}\]

Therefore,

\[\left\|\mathbf{H}^{(m)}\left(\mathbf{x},\mathbf{\theta}^{(m)}\right)\right\|^ {2}\] (147) \[\leq\left\|\mathbf{H}^{(m)}\left(\mathbf{x},\mathbf{\theta}^{(m)}\right) \right\|_{F}^{2}\] (148) \[=\sum_{n=1}^{\mathcal{N}}\sum_{\hat{n}=1}^{\mathcal{N}}\left\| \frac{\partial^{2}h^{(m)}\left(\mathbf{x};\mathbf{\theta}^{(m)}\right)}{\partial\mathbf{w }_{n}^{(m)}\partial\mathbf{w}_{n}^{(m)}}\right\|_{F}^{2}+2\sum_{n=1}^{\mathcal{N}} \sum_{l=1}^{\mathcal{L}}\left\|\frac{\partial^{2}h^{(m)}\left(\mathbf{x};\mathbf{ \theta}^{(m)}\right)}{\partial\mathbf{w}_{n}^{(m)}\partial\pi_{l}^{(m)}}\right\|_ {F}^{2}\] (149) \[\leq\sum_{n=1}^{\mathcal{N}}\left\|\frac{\partial^{2}h^{(m)} \left(\mathbf{x};\mathbf{\theta}^{(m)}\right)}{\partial\mathbf{w}_{n}^{(m)}\partial\mathbf{w} _{n}^{(m)}}\right\|_{F}^{2}+\sum_{n\neq\hat{n}}\left\|\frac{\partial^{2}h^{(m )}\left(\mathbf{x};\mathbf{\theta}^{(m)}\right)}{\partial\mathbf{w}_{n}^{(m)}\partial\mathbf{w }_{n}^{(m)}}\right\|_{F}^{2}+2\sum_{n=1}^{\mathcal{N}}\sum_{l=1}^{\mathcal{L}} \left\|\frac{\partial^{2}h^{(m)}\left(\mathbf{x};\mathbf{\theta}^{(m)}\right)}{\partial \mathbf{w}_{n}^{(m)}\partial\pi_{l}^{(m)}}\right\|_{F}^{2}\] (150) \[\leq\sum_{n=1}^{\mathcal{N}}\left[\sum_{l=1}^{\mathcal{L}}\left( R+\sqrt{2\ln\frac{2M(\mathcal{L}+\mathcal{N})}{\delta}}\right)\left\|\frac{ \partial^{2}p_{l}\left(\mathbf{x};\mathbf{w}^{(m)}\right)}{\partial\mathbf{w}_{n}^{(m)} \partial\mathbf{w}_{

[MISSING_PAGE_EMPTY:26]

[MISSING_PAGE_EMPTY:27]

[MISSING_PAGE_FAIL:28]

[MISSING_PAGE_FAIL:29]

* Eq. (190) follows from \(\sqrt{\ln 2}\geq\ln 2\geq 0.5\).
* Eq. (191) follows from the fact that \(\ln(M/\delta)\geq\ln 2\) holds under \(M\geq 2\).

**Lemma B.5**.: _Fix any \(\delta\in(0,1)\) and \(f\in\mathcal{H}_{\rm TNTK}\) with \(\|f\|_{\rm TNTK}\leq B\). Furthermore, suppose that \(\epsilon_{t}\) is a \(\sigma\)-sub-Gauss random variable for any \(t\in[T]\). Then, with probability at least \(1-\delta\), the following inequality holds for any \(t\in[T]\):_

\[\|\mathbf{y}_{t}\|_{2}\leq\left(\overline{k}B+\sigma\sqrt{2\ln\frac{2T}{\delta}} \right)\sqrt{t}, \tag{193}\]

_where \(\overline{k}=\max_{\mathbf{x}\in\mathcal{X}}\sqrt{k_{\rm TNTK}(\mathbf{x},\mathbf{x})}\)._

Proof.: From the reproducing property of RKHS and Schwarz's inequality, for any \(\mathbf{x}\in\mathcal{X}\), we have

\[f(\mathbf{x}) =\langle f,k_{\rm TNTK}(\mathbf{x},\cdot)\rangle_{\mathcal{H}_{\rm TNTK}} \tag{194}\] \[=\|f\|_{\rm TNTK}\|k_{\rm TNTK}(\mathbf{x},\cdot)\|_{\rm TNTK}\] (195) \[=\|f\|_{\rm TNTK}\sqrt{k_{\rm TNTK}(\mathbf{x},\mathbf{x})}\] (196) \[\leq B\overline{k}. \tag{197}\]

Thus,

\[\|\mathbf{y}_{t}\|_{2}^{2} =\sum_{i=1}^{t}[f(\mathbf{x}_{i})+\epsilon_{i}]^{2} \tag{198}\] \[\leq\sum_{i=1}^{t}\left(B\overline{k}+|\epsilon_{i}|\right)^{2}. \tag{199}\]

By using the concentration property of \(\sigma\)-sub-Gauss random variable, for any \(t\in[T]\) and \(\tilde{\delta}

Here, we set \(\varepsilon\) as \(\varepsilon=\min\{\lambda_{0}/(8|\mathcal{X}|),\sqrt{C_{\alpha,\mathcal{D}}^{(6)}\ln( 16|\mathcal{X}|^{2}/\delta)/M},C_{\alpha,\mathcal{D}}^{(2)}\}\); then, \(\varepsilon\in(0,C_{\alpha,\mathcal{D}}^{(2)})\). Therefore, by using Eq. (203), we have

\[M\geq C_{\alpha,\mathcal{D}}^{(6)}\min\left\{\frac{\lambda_{0}}{ 8|\mathcal{X}|},\sqrt{\frac{C_{\alpha,\mathcal{D}}^{(6)}}{M}\ln\frac{16| \mathcal{X}|^{2}}{\delta}},C_{\alpha,\mathcal{D}}^{(2)}\right\}^{-2}\ln\frac{1 6|\mathcal{X}|^{2}}{\delta} \tag{204}\] \[\Rightarrow\mathbb{P}\left(\forall\mathbf{x},\tilde{\mathbf{x}}\in \mathcal{X},|k_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x}})-\tilde{k}(\mathbf{x},\tilde {\mathbf{x}})|\leq\min\left\{\frac{\lambda_{0}}{2|\mathcal{X}|},\sqrt{\frac{4C_{ \alpha,\mathcal{D}}^{(6)}}{M}\ln\frac{16|\mathcal{X}|^{2}}{\delta}},4C_{\alpha,\mathcal{D}}^{(2)}\right\}\right)\] \[\geq 1-\delta. \tag{205}\]

Furthermore,

\[M\geq 64C_{\alpha,\mathcal{D}}^{(6)}|\mathcal{X}|^{2}\lambda_{0} ^{-2}\ln\frac{16|\mathcal{X}|^{2}}{\delta}\text{ and }\,M\geq C_{\alpha, \mathcal{D}}^{(6)}C_{\alpha,\mathcal{D}}^{(2)-2}\ln\frac{16|\mathcal{X}|^{2}} {\delta} \tag{206}\] \[\Rightarrow M\geq C_{\alpha,\mathcal{D}}^{(6)}\min\left\{\frac{ \lambda_{0}}{8|\mathcal{X}|},\sqrt{\frac{C_{\alpha,\mathcal{D}}^{(6)}}{M}\ln \frac{16|\mathcal{X}|^{2}}{\delta}},C_{\alpha,\mathcal{D}}^{(2)}\right\}^{-2} \ln\frac{16|\mathcal{X}|^{2}}{\delta}.\]

By combining the above implication with Eq. (203), we complete the proof. 

**Lemma B.7**.: _Fix any \(\delta\in(0,1)\) and \(f\in\mathcal{H}_{\mathrm{TNTK}}\) with \(\|f\|_{\mathrm{TNTK}}\leq B\). Let us define \(\tilde{k}\) as \(\tilde{k}(\mathbf{x},\tilde{\mathbf{x}})=\langle\mathbf{g}(\mathbf{x};\mathbf{\theta}_{0}),\mathbf{g}( \tilde{\mathbf{x}};\mathbf{\theta}_{0})\rangle\). Furthermore, suppose that \((\epsilon_{t})_{t\in\mathbb{N}_{+}}\) are conditionally \(\sigma\)-sub-Gaussian random variables. Then, under the event \(\mathcal{E}_{5}\), with probability at least \(1-\delta\),_

\[\forall t\in\mathbb{N}_{+},\forall\mathbf{x}\in\mathcal{X},|f(\mathbf{x})-\tilde{\mu}_ {t-1}(\mathbf{x})|\leq\left(\sqrt{2}B+\frac{\sigma}{\sqrt{\rho}}\sqrt{2\left( \tilde{\gamma}_{t}+\ln\frac{1}{\delta}\right)}\right)\tilde{\sigma}_{t-1}(\bm {x}). \tag{207}\]

_Here, we respectively define \(\tilde{\mu}_{t-1}(\mathbf{x})\) and \(\tilde{\gamma}_{t}\) as_

\[\tilde{\mu}_{t}(\mathbf{x}) =\tilde{\mathbf{k}}_{t}^{\top}(\mathbf{x})\left(\tilde{\mathbf{K}}_{t}+\rho \mathbf{I}_{t}\right)^{-1}\mathbf{y}_{t}, \tag{208}\] \[\tilde{\gamma}_{t} =\frac{1}{2}\max_{\mathbf{z}_{1},\ldots,\mathbf{z}_{t}}\ln\det\left(\mathbf{ I}_{t}+\rho^{-1}\tilde{\mathbf{K}}_{t}\right), \tag{209}\]

_where \(\tilde{\mathbf{k}}_{t}(\mathbf{x})=[\tilde{k}(\mathbf{x},\mathbf{x}_{i})]_{i\in[t]}\in\mathbb{ R}^{t}\) and \(\tilde{\mathbf{K}}_{t}=[\tilde{k}(\mathbf{x}_{i},\mathbf{x}_{j})]_{i,j\in[t]}\in\mathbb{R}^{t \times t}\) with \(\tilde{k}(\mathbf{x},\tilde{\mathbf{x}})=\langle\mathbf{g}(\mathbf{x};\mathbf{\theta}_{0}),\mathbf{g}( \tilde{\mathbf{x}};\mathbf{\theta}_{0})\rangle\)._

Proof.: From the definition of \(\mathcal{E}_{5}\), we have \(|k_{\mathrm{TNTK}}(\mathbf{x},\tilde{\mathbf{x}})-\langle\mathbf{g}(\mathbf{x},\mathbf{\theta}_{0} ),\mathbf{g}(\tilde{\mathbf{x}},\mathbf{\theta}_{0})\rangle|\leq\lambda_{0}/(2|\mathcal{X}|)\) for any \(\mathbf{x},\tilde{\mathbf{x}}\in\mathcal{X}\). Therefore, \(\sqrt{\sum_{\mathbf{x},\tilde{\mathbf{x}}\in\mathcal{X}}|k_{\mathrm{TNTK}}(\mathbf{x}, \tilde{\mathbf{x}})-\langle\mathbf{g}(\mathbf{x},\mathbf{\theta}_{0}),\mathbf{g}(\tilde{\mathbf{x}}, \mathbf{\theta}_{0})\rangle|^{2}}\leq\lambda_{0}/2\). Here, by combining this inequality with the arguments of the proof of Lemma C.5 in [24], under the event \(\mathcal{E}_{5}\), we have \(f\in\mathcal{H}_{\tilde{k}}\) with \(\|f\|_{\tilde{k}}\leq\sqrt{2}B\). Therefore, since \(\tilde{\mu}_{t}\) and \(\tilde{\sigma}_{t}\) are defined as the posterior mean and the posterior variance of Gaussian process characterized by the kernel function \(\tilde{k}\), we obtain the desired result by applying Lemma 3.11 in [2]. 

**Lemma B.8**.: _Fix any \(\delta\in(0,1)\); then, \(\mathbb{P}(\cap_{i\in[6]}\mathcal{E}_{i})\geq 1-\delta\) holds._

Proof.: From Lemma 3.3, B.5, and B.6, we have \(\mathbb{P}(\mathcal{E}_{i}^{c})\leq\delta/6\) for any \(i\in[5]/\{2,3\}\). In addition, from Lemma B.4, we have \(\mathbb{P}(\mathcal{E}_{5}^{c}\cup\mathcal{E}_{5}^{c})\leq\delta/6\). Here, from Lemma B.6 and Lemma B.7, we have

\[\mathbb{P}(\mathcal{E}_{6}^{c}) =\mathbb{P}(\mathcal{E}_{6}^{c}\mid\mathcal{E}_{5})\mathbb{P}( \mathcal{E}_{5})+\mathbb{P}(\mathcal{E}_{6}^{c}\mid\mathcal{E}_{5}^{c}) \mathbb{P}(\mathcal{E}_{5}^{c}) \tag{210}\] \[\leq\frac{\delta}{6}+\frac{\delta}{6}\] (211) \[=\frac{\delta}{3}. \tag{212}\]Therefore, by taking the union bound, we have

\[\mathbb{P}(\cap_{i\in[6]}\mathcal{E}_{i}) =1-\mathbb{P}(\cup_{i\in[6]}\mathcal{E}_{i}^{c}) \tag{213}\] \[\geq 1-\left[\mathbb{P}(\mathcal{E}_{1}^{c})+\mathbb{P}(\mathcal{E }_{2}^{c}\cup\mathcal{E}_{3}^{c})+\mathbb{P}(\mathcal{E}_{4}^{c})+\mathbb{P}( \mathcal{E}_{5}^{c})+\mathbb{P}(\mathcal{E}_{6}^{c})\right]\] (214) \[\geq 1-\delta. \tag{215}\]

### Lemmas for the upper bounds of Eq. (170)

**Definition B.1**.: _Define \(\tilde{L}_{t}(\mathbf{\theta})\) for any \(t\in\mathbb{N}_{+}\):_

\[\tilde{L}_{t}(\mathbf{\theta})=\left\|\mathbf{G}_{t}^{\top}\left(\mathbf{\theta}-\mathbf{ \theta}_{0}\right)-\mathbf{y}_{t}\right\|_{2}^{2}+\rho\left\|\mathbf{\theta}-\mathbf{ \theta}_{0}\right\|_{2}^{2}. \tag{216}\]

_Furthermore, let us define \(\tilde{\mathbf{\theta}}_{t;1},\ldots,\tilde{\mathbf{\theta}}_{t;J}\) as_

\[\tilde{\mathbf{\theta}}_{t;j}=\tilde{\mathbf{\theta}}_{t;j-1}-\eta\left\{2\mathbf{G}_{t} \left[\mathbf{G}_{t}^{\top}\left(\tilde{\mathbf{\theta}}_{t;j-1}-\mathbf{\theta}_{0}\right) -\mathbf{y}_{t}\right]+2\rho\left(\tilde{\mathbf{\theta}}_{t;j-1}-\mathbf{\theta}_{0} \right)\right\}, \tag{217}\]

_where \(\tilde{\mathbf{\theta}}_{t;0}=\mathbf{\theta}_{0}\)._

**Lemma B.9** (Adapted from Lemma C.4 in [41]).: _Suppose that the events \(\mathcal{E}_{2}\) and \(\mathcal{E}_{4}\) simultaneously hold. Furthermore, assume that \(\eta\leq 2^{-1}\left(T\hat{C}^{2}2^{2\mathcal{D}}C^{(4)}_{\alpha,\mathcal{D}} \ln(6M/\delta)+\rho\right)^{-1}\) holds. Then, the following inequalities hold for any \(t\in[T]\) and \(j\in[J]\):_

\[\left\|\tilde{\mathbf{\theta}}_{t;j}-\mathbf{\theta}_{0}\right\|_{2}\leq \left(\overline{k}B+\sigma\sqrt{2\ln\frac{12T}{\delta}}\right)\sqrt{\frac{t}{ \rho}}, \tag{218}\] \[\left\|\tilde{\mathbf{\theta}}_{t;j}-\mathbf{\theta}_{0}-\left(\rho\mathbf{I} _{p}+\mathbf{G}_{t}\mathbf{G}_{t}^{\top}\right)^{-1}\mathbf{G}_{t}\mathbf{y}_{t}\right\|_{2} \leq(1-2\eta\rho)^{j/2}\left(\overline{k}B+\sigma\sqrt{2\ln\frac{12T}{\delta}} \right)\sqrt{\frac{t}{\rho}}, \tag{219}\]

_where \(\overline{k}\) is defined in Lemma B.5. Furthermore, the constants \(\hat{C}\) and \(C^{(4)}_{\alpha,\mathcal{D}}\) are defined in Lemma B.4._

Proof.: From the definition of \(\tilde{L}_{t}(\mathbf{\theta})\), we have

\[\nabla_{\mathbf{\theta}}^{2}\tilde{L}_{t}(\mathbf{\theta}) =2\mathbf{G}_{t}\mathbf{G}_{t}^{\top}+2\rho\mathbf{I}_{p} \tag{220}\] \[\preceq 2\left(\|\mathbf{G}_{t}\|_{2}^{2}+\rho\right)\mathbf{I}_{p}\] (221) \[\preceq 2\left(t\hat{C}^{2}2^{2\mathcal{D}}C^{(4)}_{\alpha, \mathcal{D}}\ln\frac{6M}{\delta}+\rho\right)\mathbf{I}_{p}, \tag{222}\]

where Eq. (222) follows from Lemma B.13. Therefore, \(\tilde{L}_{t}(\mathbf{\theta})\) is \(2\left(t\hat{C}^{2}2^{2\mathcal{D}}C^{(4)}_{\alpha,\mathcal{D}}\ln\frac{6M}{ \delta}+\rho\right)\)-smooth function. Furthermore, \(\tilde{L}_{t}(\mathbf{\theta})\) is \(2\rho\)-strong convex because \(\nabla_{\mathbf{\theta}}^{2}\tilde{L}_{t}(\mathbf{\theta})\succeq 2\rho\mathbf{I}_{p}\) holds. By combining the definition of \(\eta\) with the standard result of gradient descent for the strongly convex and smooth objective function (e.g., Theorem 3.6 in [16]), \(\tilde{L}_{t}(\tilde{\mathbf{\theta}}_{t;j})\geq\tilde{L}_{t}(\tilde{\mathbf{\theta}}_{ t;j-1})\) holds for any \(j\in[J]\). Therefore,

\[\rho\left\|\tilde{\mathbf{\theta}}_{t;J}-\mathbf{\theta}_{0}\right\|_{2}^ {2} \leq\left\|\mathbf{G}_{t}^{\top}\left(\tilde{\mathbf{\theta}}_{t;J}-\mathbf{ \theta}_{0}\right)-\mathbf{y}_{t}\right\|_{2}^{2}+\rho\left\|\tilde{\mathbf{\theta}}_ {t;J}-\mathbf{\theta}_{0}\right\|_{2}^{2} \tag{223}\] \[\leq\left\|\mathbf{G}_{t}^{\top}\left(\tilde{\mathbf{\theta}}_{t;0}-\mathbf{ \theta}_{0}\right)-\mathbf{y}_{t}\right\|_{2}^{2}+\rho\left\|\tilde{\mathbf{\theta}}_ {t;0}-\mathbf{\theta}_{0}\right\|_{2}^{2}\] (224) \[\leq\left\|\mathbf{y}_{t}\right\|_{2}^{2}\] (225) \[\leq\left(\overline{k}B+\sigma\sqrt{2\ln\frac{12T}{\delta}} \right)^{2}t, \tag{226}\]

where Eq. (226) follows from the event \(\mathcal{E}_{4}\). Furthermore, since the unique minimum of \(\tilde{L}_{t}(\mathbf{\theta})\) is given as \(\mathbf{\theta}^{*}\coloneqq\mathbf{\theta}_{0}+\left(\rho\mathbf{I}_{p}+\mathbf{G}_{t}\mathbf{G}_ {t}^{\top}\right)^{-1}\mathbf{G}_{t}\mathbf{y}_{t}\), we have the following inequalities from Theorem 3.6

[MISSING_PAGE_FAIL:33]

[MISSING_PAGE_EMPTY:34]

Furthermore, from \(\|\mathbf{h}_{t;j}-\mathbf{y}_{t}\|_{2}\leq\left(\overline{k}B+\sigma\sqrt{2\ln\frac{12T}{ \delta}}\right)\sqrt{3t}\), we have

\[\|\mathbf{\theta}_{t;j+1}-\mathbf{\theta}_{t;j}\| =\eta\|\nabla_{\mathbf{\theta}_{t;j}}L_{t}(\mathbf{\theta}_{t;j})\|_{2} \tag{252}\] \[\leq\frac{1}{4\rho}\|2\mathbf{G}_{t;j}(\mathbf{h}_{t;j}-\mathbf{y}_{t})+2( \mathbf{\theta}_{t;j}-\mathbf{\theta}_{0})\|_{2}\] (253) \[\leq\frac{1}{2\rho}\left(\|\mathbf{G}_{t;j}\|\|\mathbf{h}_{t;j}-\mathbf{y}_{t }\|_{2}+\|\mathbf{\theta}_{t;j}-\mathbf{\theta}_{0}\|_{2}\right)\] (254) \[\leq\frac{1}{2\rho}\left[(2R+2^{\mathcal{D}})\sqrt{tC_{\alpha, \mathcal{D}}^{(4)}\ln\frac{6M}{\delta}}\left(\overline{k}B+\sigma\sqrt{2\ln \frac{12T}{\delta}}\right)\sqrt{3t}+R\right]\] (255) \[\Rightarrow\|\mathbf{\theta}_{t;j+1}-\mathbf{\theta}_{0}\| \leq\overline{R}. \tag{256}\]

Combining the above inequality with Lemma B.15, we have

\[\left\|\mathbf{e}(\mathbf{\theta}_{t;j+1},\mathbf{\theta}_{t;j})\right\|_{2}^{2}\leq\frac{ 4t\overline{R}^{4}(\overline{R}+2)^{4}C_{\alpha,\mathcal{D}}^{(3)2}}{M}\left( \ln\frac{6\cdot 2^{\mathcal{D}+2}M}{\delta}\right)^{2}. \tag{257}\]

Therefore,

\[8c\eta\rho\|\mathbf{e}(\mathbf{\theta}_{0},\mathbf{\theta}_{t;j})\|_{2}^{2}+ \frac{2}{c\eta\rho}\|\mathbf{e}(\mathbf{\theta}_{t;j+1},\mathbf{\theta}_{t;j})\|_{2}^{2}+2 \|\mathbf{e}(\mathbf{\theta}_{t;j+1},\mathbf{\theta}_{t;j})\|_{2}^{2} \tag{258}\] \[\leq\left(8c\eta\rho+\frac{2}{c\eta\rho}+2\right)\frac{4t\overline {R}^{4}(\overline{R}+2)^{4}C_{\alpha,\mathcal{D}}^{(3)2}}{M}\left(\ln\frac{6 \cdot 2^{\mathcal{D}+2}M}{\delta}\right)^{2}\] (259) \[\leq\frac{3}{c\eta\rho}\frac{4t\overline{R}^{4}(\overline{R}+2)^{ 4}C_{\alpha,\mathcal{D}}^{(3)2}}{M}\left(\ln\frac{6\cdot 2^{\mathcal{D}+2}M}{ \delta}\right)^{2}\] (260) \[\leq c\eta\rho\left(\overline{k}B+\sigma\sqrt{2\ln\frac{12T}{ \delta}}\right)^{2}t, \tag{261}\]

where the second line follows from the fact that \(8c\eta\rho+2\leq 1/(c\eta\rho)\) holds due to \(\eta\rho\leq 1/4\) and \(c\in(0,1)\). Furthermore, the last line follows from the condition (233) with \(c\geq 3/4\). By combining Eq. (245) with Eq. (261), we have

\[\left\|\mathbf{h}_{t;j+1}-\mathbf{y}_{t}\right\|_{2}^{2}-\|\mathbf{y}_{t}\|_{ 2}^{2} \tag{262}\] \[=L_{t}(\mathbf{\theta}_{t;j+1})-L_{t}(\mathbf{\theta}_{0})\] (263) \[\leq(1-c\eta\rho)[L_{t}(\mathbf{\theta}_{t;j})-L_{t}(\mathbf{\theta}_{0}) ]+2c\eta\rho\left(\overline{k}B+\sigma\sqrt{2\ln\frac{12T}{\delta}}\right)^{2}t\] (264) \[\leq\frac{2c\eta\rho\left(\overline{k}B+\sigma\sqrt{2\ln\frac{12T }{\delta}}\right)^{2}t}{1-(1-c\eta\rho)}\] (265) \[=2\left(\overline{k}B+\sigma\sqrt{2\ln\frac{12T}{\delta}}\right) ^{2}t. \tag{266}\]

By combining the event \(\mathcal{E}_{4}\) with the above inequality, we obtain the desired inequality.

Finally, we check the assumption \(\|\mathbf{h}_{t;j}-\mathbf{y}_{t}\|_{2}\leq\left(\overline{k}B+\sigma\sqrt{2\ln\frac{1 2T}{\delta}}\right)\sqrt{3t}\). If \(\tilde{j}=0\), \(\|\mathbf{h}_{t;\tilde{j}}-\mathbf{y}_{t}\|_{2}\leq\left(\overline{k}B+\sigma\sqrt{2 \ln\frac{12T}{\delta}}\right)\sqrt{3t}\) clearly holds from the event \(\mathcal{E}_{2}\) and \(\mathbf{h}_{t;0}=\mathbf{0}\). Here, by applying the aforementioned arguments, we can also verify \(\|\mathbf{h}_{t;\tilde{j}}-\mathbf{y}_{t}\|_{2}\leq\left(\overline{k}B+\sigma\sqrt{2\ln \frac{12T}{\delta}}\right)\sqrt{3t}\) for \(\tilde{j}=1\). Repeating the same arguments for \(\tilde{j}=2,3,\ldots,j\), we obtain the inequality \(\|\mathbf{h}_{t;j}-\mathbf{y}_{t}\|_{2}\leq\left(\overline{k}B+\sigma\sqrt{2\ln\frac{ 12T}{\delta}}\right)\sqrt{3t}\).

[MISSING_PAGE_FAIL:36]

[MISSING_PAGE_EMPTY:37]

[MISSING_PAGE_EMPTY:38]

[MISSING_PAGE_EMPTY:39]

Proof of Theorem b.1.: Suppose that the events \(\mathcal{E}_{1}\)-\(\mathcal{E}_{6}\) hold. As proposed in [30], we decompose the error term \(|f(\mathbf{x})-h(\mathbf{x};\mathbf{\theta}_{t})|\):

\[\begin{split}&|f(\mathbf{x})-h(\mathbf{x};\mathbf{\theta}_{t})|\\ &\leq|f(\mathbf{x})-\tilde{\mu}_{t}(\mathbf{x})|+|\tilde{\mu}_{t}(\mathbf{x}) -\langle\mathbf{g}(\mathbf{x};\mathbf{\theta}_{0}),\mathbf{\theta}_{t}-\mathbf{\theta}_{0}\rangle| +|\langle\mathbf{g}(\mathbf{x};\mathbf{\theta}_{0}),\mathbf{\theta}_{t}-\mathbf{\theta}_{0}\rangle -h(\mathbf{x}_{t};\mathbf{\theta}_{t})|.\end{split} \tag{317}\]

By combining the event \(\mathcal{E}_{6}\) with Lemma B.12, the first term of Eq. (317) is bounded from above as follows:

\[|f(\mathbf{x})-\tilde{\mu}_{t}(\mathbf{x})| \tag{318}\] \[\leq\left(\sqrt{2}B+\frac{\sigma}{\sqrt{\rho}}\sqrt{2\left(\tilde {\gamma}_{t}+\ln\frac{6}{\delta}\right)}\right)\tilde{\sigma}_{t-1}(\mathbf{x})\] (319) \[\leq\left(\sqrt{2}B+\frac{\sigma}{\sqrt{\rho}}\sqrt{2\left(\gamma _{t}+\frac{t\sqrt{tC_{\alpha,\mathcal{D}}^{(6)}\ln(96|\mathcal{X}|^{2}/\delta) }}{\rho\sqrt{M}}+\ln\frac{6}{\delta}\right)}\right)\tilde{\sigma}_{t-1}(\mathbf{x}). \tag{320}\]

Furthermore, we obtain the following inequalities for the second term:

\[|\tilde{\mu}_{t}(\mathbf{x})-\langle\mathbf{g}(\mathbf{x};\mathbf{\theta}_{0}), \mathbf{\theta}_{t}-\mathbf{\theta}_{0}\rangle| \tag{321}\] \[=\left|g(\mathbf{x};\mathbf{\theta}_{0})^{\top}\left(\rho\mathbf{I}_{p}+\mathbf{G }_{t}\mathbf{G}_{t}^{\top}\right)^{-1}\mathbf{G}_{t}\mathbf{y}_{t}-\langle\mathbf{g}(\mathbf{x}; \mathbf{\theta}_{0}),\mathbf{\theta}_{t}-\mathbf{\theta}_{0}\rangle\right|\] (322) \[\leq\rho^{-1}\left\|\mathbf{\theta}_{t}-\mathbf{\theta}_{0}-\left(\rho\bm {I}_{p}+\mathbf{G}_{t}\mathbf{G}_{t}^{\top}\right)^{-1}\mathbf{G}_{t}\mathbf{y}_{t}\right\|_{ 2}\left\|\rho\mathbf{I}_{p}+\mathbf{G}_{t}\mathbf{G}_{t}^{\top}\right\|\tilde{\sigma}_{t}^ {2}(\mathbf{x})\] (323) \[\leq\rho^{-1}\sqrt{\overline{k}^{2}+4C_{\alpha,\mathcal{D}}^{(2)} }\left\|\mathbf{\theta}_{t}-\mathbf{\theta}_{0}-\left(\rho\mathbf{I}_{p}+\mathbf{G}_{t}\mathbf{G}_{ t}^{\top}\right)^{-1}\mathbf{G}_{t}\mathbf{y}_{t}\right\|_{2}\left\|\rho\mathbf{I}_{p}+\mathbf{G}_{t }\mathbf{G}_{t}^{\top}\right\|\tilde{\sigma}_{t}(\mathbf{x})\] (324) \[\leq\rho^{-1}\sqrt{\overline{k}^{2}+4C_{\alpha,\mathcal{D}}^{(2)} }\left[\frac{C_{\alpha,\mathcal{D},T}^{(7)}}{\sqrt{M}}\left(\overline{k}B+ \sigma\sqrt{2\ln\frac{12T}{\delta}}\right)^{2}\left(\ln\frac{6\cdot 2^{ \mathcal{D}+2}M}{\delta}\right)\sqrt{\ln\frac{6M}{\delta}}\right.\] \[\quad+\left(1-2\eta\rho\right)^{J/2}\left(\overline{k}B+\sigma \sqrt{2\ln\frac{12T}{\delta}}\right)^{2}\sqrt{\frac{T}{\rho}}\] (325) \[\quad\times\left(\rho+TC_{\alpha,\mathcal{D}}^{(4)}2^{2\mathcal{D} }\hat{C}^{2}\ln\frac{6M}{\delta}\right)\tilde{\sigma}_{t}(\mathbf{x}),\]

where:

* Eq. (322) follows from the feature space representation of \(\tilde{\mu}_{t}\). Actually, we have \(\tilde{\mu}_{t}(\mathbf{x})=\mathbf{g}(\mathbf{x};\mathbf{\theta}_{0})^{\top}\mathbf{G}_{t}(\rho \mathbf{I}_{t}+\mathbf{G}_{t}^{\top}\mathbf{G}_{t})^{-1}\mathbf{y}_{t}=g(\mathbf{x};\mathbf{\theta}_{ 0})^{\top}\left(\rho\mathbf{I}_{p}+\mathbf{G}_{t}\mathbf{G}_{t}^{\top}\right)^{-1}\mathbf{G}_{ t}\mathbf{y}_{t}\), where the last equality follows from the matrix identity \(\mathbf{G}_{t}(\rho\mathbf{I}_{t}+\mathbf{G}_{t}^{\top}\mathbf{G}_{t})^{-1}=\left(\rho\mathbf{I}_{p}+\mathbf{G}_{t}\mathbf{G}_{ t}^{\top}\right)^{-1}\mathbf{G}_{t}\) (e.g., Lemma 3 in [29]).
* Eq. (323) follows from the fact that \(\langle\mathbf{z}_{1},\mathbf{z}_{2}\rangle\leq(\mathbf{z}_{1}^{\top}A^{-1}\mathbf{z}_{1}) \cdot(\mathbf{z}_{2}^{\top}A\mathbf{z}_{2})\leq(\mathbf{z}_{1}^{\top}\mathbf{A}^{-1}\mathbf{z}_{1} )\|\mathbf{A}\|_{2}\|\mathbf{z}_{2}\|_{2}\) holds for any positive definite matrix \(\mathbf{A}\in\mathbb{R}^{p\times p}\) and \(\mathbf{z}_{1},\mathbf{z}_{2}\in\mathbb{R}^{p}\).
* Eq. (324) follows from \(\tilde{\sigma}_{t}(\mathbf{x})\leq\sqrt{\tilde{k}(\mathbf{x},\mathbf{x})}\leq\sqrt{\overline {k}^{2}+4C_{\alpha,\mathcal{D}}^{(2)}}\), where the last inequality follows from the event \(\mathcal{E}_{5}\).
* Eq. (325) follows from Lemma B.9 and Lemma B.11.

[MISSING_PAGE_EMPTY:41]

[MISSING_PAGE_EMPTY:42]

According to Bietti and Bach [6], \(\tilde{\lambda}_{n}=\Theta(n^{-d})\) and there exists a constant \(C_{d,L}>0\) such that \(C_{d,L}n^{-d}\leq\tilde{\lambda}_{n}\). Combining this with Lemma 3.1, we have:

\[\|f\|_{\rm NTK}^{2}\leq\sum_{n=0}^{\infty}\sum_{j=1}^{N_{d,n}}w_{n,j}^{2}C_{ \alpha,\mathcal{D}}^{(1)}C_{d,L}^{-1}n^{d}\exp\left(-\ln\left(1+\frac{1}{4 \alpha^{2}}\right)\mathcal{D}n\right). \tag{346}\]

Since \(n^{d}\exp\left(-\ln\left(1+\frac{1}{4\alpha^{2}}\right)\mathcal{D}n\right)\to 0\) (as \(n\to\infty\)), there exists a constant \(C_{\alpha,d}>0\) such that \(n^{d}\exp\left(-\ln\left(1+\frac{1}{4\alpha^{2}}\right)\mathcal{D}n\right)\leq C _{\alpha,d}\) holds for any \(n\in\mathbb{N}\). Thus,

\[\|f\|_{\rm NTK}^{2}\leq C_{\alpha,\mathcal{D}}^{(1)}C_{d,L}^{-1}C_{\alpha,d} \sum_{n=0}^{\infty}\sum_{j=1}^{N_{d,n}}w_{n,j}^{2}=C_{\alpha,\mathcal{D}}^{(1) }C_{d,L}^{-1}C_{\alpha,d}\|f\|_{\rm NTTK}^{2}<\infty. \tag{347}\]

From the above, it follows that \(\mathcal{H}_{\rm NTTK}\subset\mathcal{H}_{\rm NTK}\). 

## Appendix E Helper Lemmas

**Definition E.1** (Sub-Gaussian norm, Definition 2.5.6 in [39]).: _Let \(X\) be a real-valued random variable. Then, the following quantity \(\|X\|_{\psi_{2}}\) is called the sub-Gaussian norm of \(X\):_

\[\|X\|_{\psi_{2}}=\inf\left\{t\geq 0\;\bigg{|}\;\mathbb{E}\left[\exp\left( \frac{X^{2}}{t^{2}}\right)\right]\leq 2\right\}. \tag{348}\]

_Moreover, if \(\|X\|_{\psi_{2}}<\infty\) holds, we call the random variable \(X\) a sub-Gaussian random variable._

**Definition E.2** (Sub-exponential norm, Definition 2.7.5 in [39]).: _Let \(X\) be a real-valued random variable. Then, the following quantity \(\|X\|_{\psi_{1}}\) is called the sub-exponential norm of \(X\):_

\[\|X\|_{\psi_{1}}=\inf\left\{t\geq 0\;\bigg{|}\;\mathbb{E}\left[\exp\left( \frac{|X|}{t}\right)\right]\leq 2\right\}. \tag{349}\]

_Moreover, if \(\|X\|_{\psi_{1}}<\infty\) holds, we call the random variable \(X\) a sub-exponential random variable._

**Lemma E.1** (General Hoeffding's inequality, Theorem 2.6.2 in [39]).: _Let \(X_{1},\ldots,X_{N}\) be independent, mean-zero, sub-Gaussian random variables. Then, for every \(t\geq 0\), the following holds:_

\[\mathbb{P}\left(\left|\sum_{i=1}^{N}X_{i}\right|\geq t\right)\leq 2\exp\left(- \frac{ct^{2}}{\sum_{i=1}^{N}\|X\|_{\psi_{2}}^{2}}\right), \tag{350}\]

_where \(c>0\) is an absolute constant._

**Lemma E.2** (Bernstain's inequality, Theorem 2.8.1 in [39]).: _Let \(X_{1},\ldots,X_{N}\) be independent, mean-zero, sub-exponential random variables. Then, for every \(t\geq 0\), the following holds:_

\[\mathbb{P}\left(\left|\sum_{i=1}^{N}X_{i}\right|\geq t\right)\leq 2\exp\left(-c \min\left\{\frac{t^{2}}{\sum_{i=1}^{N}\|X_{i}\|_{\psi_{1}}^{2}},\frac{t}{\max _{i\in[N]}\|X_{i}\|_{\psi_{1}}}\right\}\right), \tag{351}\]

_where \(c>0\) is an absolute constant._

**Lemma E.3** (Centering, Lemma 2.6.8 and Exercise 2.7.10 in [39]).: _For any sub-Gaussian random variable \(X\), \(\|X-\mathbb{E}[X]\|_{\psi_{2}}\leq C\|X\|_{\psi_{2}}\) holds. Furthermore, for any sub-exponential random variable \(Y\), \(\|Y-\mathbb{E}[Y]\|_{\psi_{1}}\leq C\|Y\|_{\psi_{1}}\) holds, where \(C>0\) is an absolute constant._

**Lemma E.4** (Product of sub-Gaussians is sub-exponential, Lemma 2.7.7 in [39]).: _Let \(X\) and \(Y\) be sub-Gaussian random variables. Then, \(XY\) is a sub-exponential random variable whose sub-exponential norm satisfies \(\|XY\|_{\psi_{1}}\leq\|X\|_{\psi_{2}}\|Y\|_{\psi_{2}}\)._

## Appendix F Details of numerical experiments

### Our implementation of algorithms

Here, we provide additional information on the implementation of the ST-UCB and NN-UCB algorithms. Our implementation includes the following three simplifications:1. In the calculation of the gradient in line 5 of Algorithm 1, we use \(\mathbf{g}(\mathbf{x};\mathbf{\theta}_{t-1})\) from the previous round, rather than the initial gradient \(\mathbf{g}(\mathbf{x};\mathbf{\theta}_{0})\).
2. In the regularization of parameters in line 3 of Algorithm 3, we do not consider the residual from the initial parameters \(\mathbf{\theta}_{0}\). In other words, we apply L2 regularization directly to the parameters themselves.
3. Instead of initializing \(\mathbf{\theta}_{0}\) as described in Sec. 3.1, we initialized \(\mathbf{\theta}_{0}\) by the Glorot's uniform initializer [17].

It should be noted that the simplification (a) is the same implementation as the original NN-UCB, while the other simplifications are for the sake of simplicity in implementation. We train two models (ST, NN) using stochastic gradient descent (SGD) with a momentum term. The learning rate and the momentum are set to 0.01 and 0.9, respectively. When the momentum is greater than zero, past gradients are considered as a weighted average. SGD is performed in all rounds, with a mini-batch size of 64 and 5 epochs, and we do not use early stopping.

### Parameter sensitivity

In the results shown in Fig. 2 of the experimental section, we presented the outcomes with optimal hyperparameters of \(\epsilon,\beta\). Here, the experimental results for each parameter \(\epsilon\in\{0.05,0.1,0.2\},\beta\in\{0.01,0.1,1\}\) are summarized in Fig. 3 (real-world dataset) and Fig. 4 (synthetic dataset). In most cases with the real-world dataset, as the rounds progressed, ST-UCB demonstrated better performance than NN-UCB, and UCB-based policies outperformed \(\epsilon\)-greedy based policies when \(\beta=0.01\). In the \(f^{(1)}\) setting for the synthetic data, the regret of ST-UCB converged the fastest. On the other hand, in the \(f^{(2)}\) and \(f^{(3)}\) settings, NN-UCB sometimes performed well, however the trend of cumulative regret over the rounds was comparable between ST-UCB and NN-UCB.

## Appendix G Summary of the existing works

### Derivation of TNTK

Our analysis relies on the TNTK derived by Kanoh and Sugiyama [21]. From the definition of the soft tree ensemble model, we have

\[\langle\nabla_{\mathbf{\theta}}h(\mathbf{x};\mathbf{\theta}),\nabla_{\mathbf{\theta}}h(\mathbf{x}; \mathbf{\theta})\rangle=\frac{1}{M}\sum_{m=1}^{M}\langle\nabla_{\mathbf{\theta}^{(m)} }\tilde{h}(\mathbf{x};\mathbf{\theta}^{(m)}),\nabla_{\mathbf{\theta}^{(m)}}\tilde{h}(\mathbf{x };\mathbf{\theta}^{(m)})\rangle. \tag{352}\]

If \(\mathbf{\theta}\sim\mathcal{N}(\mathbf{0},\mathbf{I}_{p})\), \((\langle\nabla_{\mathbf{\theta}^{(m)}}\tilde{h}(\mathbf{x};\mathbf{\theta}^{(m)}),\nabla_{ \mathbf{\theta}^{(m)}}\tilde{h}(\mathbf{x};\mathbf{\theta}^{(m)})\rangle)_{m\in[M]}\) is mutually independent; therefore, from the law of large number, the inner product \(\langle\nabla_{\mathbf{\theta}}h(\mathbf{x};\mathbf{\theta}),\nabla_{\mathbf{\theta}}h(\mathbf{x };\mathbf{\theta})\rangle\) converges to \(\mathbb{E}[\langle\nabla_{\mathbf{\theta}^{(m)}}\tilde{h}(\mathbf{x};\mathbf{\theta}^{(m) }),\nabla_{\mathbf{\theta}^{(m)}}\tilde{h}(\mathbf{x};\mathbf{\theta}^{(m)})\rangle]\) in probability as \(M\rightarrow\infty\). Kanoh and Sugiyama [21] shows that \(\mathbb{E}[\langle\nabla_{\mathbf{\theta}^{(m)}}\tilde{h}(\mathbf{x};\mathbf{\theta}^{(m) }),\nabla_{\mathbf{\theta}^{(m)}}\tilde{h}(\mathbf{x};\mathbf{\theta}^{(m)})\rangle]\) equals the expression in Eq. (1) by relying on the recursive expressions of the soft tree (such as Eq. (81)).

### MIG and effective dimension

As described in Section 3.2, MIG is commonly used as the problem complexity parameter of the kernel-based decision-making problem. On the other hand, instead of MIG, some existing works quantify the problem complexity based on the following _effective dimension_\(\tilde{d}\)[10; 37; 40; 41]:

\[\tilde{d}=\operatorname{Tr}(\mathbf{K}_{T}(\mathbf{K}_{T}+\rho\mathbf{I}_{T})^{-1}). \tag{353}\]

Due to the following inequality [9; 10], the MIG is bounded from above by the worst-case effective dimension up to logarithmic scale:

\[\ln\det(\rho^{-1}\mathbf{K}_{T}+\mathbf{I}_{T})\leq\operatorname{Tr}(\mathbf{K}_{T}(\mathbf{K} _{T}+\rho\mathbf{I}_{T})^{-1})(1+\ln(\rho^{-1}\|\mathbf{K}_{T}\|+1)). \tag{354}\]Figure 4: The average cumulative regret with one standard error in the synthetic dataset.

Figure 3: The average cumulative regret with one standard error in the real-world dataset.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: The details of our contributions summarized in the abstract and introduction are given in Sec. 3.2 and Sec. 4. The sections in which the details of each contribution are described are explicitly stated in the introduction. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: The assumptions for our main result are given in Assumption 3.1, and the discussions of their validities are described in Remark 3.1. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof?Answer: [Yes] Justification: The assumptions for our main result is given in Assumption 3.1. The complete proofs of our main results are given in Appendix A, B, C, and D. Guidelines:

* The answer NA means that the paper does not include theoretical results.
* All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
* All assumptions should be clearly stated or referenced in the statement of any theorems.
* The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.
* Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.
* Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: The detailed information for our experiment is given in Sec. 5 and Appendix F.1. Guidelines:

* The answer NA means that the paper does not include experiments.
* If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.
* If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.
* Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.
* While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code**Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [No] Justification: We are not yet ready to release the required codes and will do so as soon as our paper is accepted. Furthermore, we believe that the lack of experimental codes is not problematic because our experiment are not too complex, and the information given in Sec. 5 and Appendix F.1 is sufficient to reproduce numerical experiments. Guidelines:

* The answer NA means that paper does not include experiments requiring code.
* Please see the NeurIPS code and data submission guidelines ([https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy)) for more details.
* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines ([https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy)) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: The information of our model hyperparameter is given in Sec. 5 and Appendix F.1. Guidelines:

* The answer NA means that the paper does not include experiments.
* The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them.
* The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: The error bars, which represent one standard errors, are given in our experimental results. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.

* The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).
* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [No] Justification: Since our experiments are limited to simple problem setups and our contributions are primarily theoretical, the computational resources used are not significant. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics [https://neurips.cc/public/EthicsGuidelines?](https://neurips.cc/public/EthicsGuidelines?) Answer: [Yes] Justification: We confirmed that our paper conforms, in every respect, with the NeurIPS Code of Ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: There is no societal impact of the work performed. Guidelines: * The answer NA means that there is no societal impact of the work performed.

* If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.
* Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.
* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).

11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: Our paper poses no such risks. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: Our paper cited the original papers to use UCI-Machine Learning Repository in Sec. 5. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. ** If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: Our paper does not release new assets. Guidelines: * The answer NA means that the paper does not release new assets. * Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. * The paper should discuss whether and how consent was obtained from people whose asset is used. * At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: Our paper does not involve crowdsourcing nor research with human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. * According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: Our paper does not involve crowdsourcing nor research with human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.

* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.