# Optimization or Architecture:

How to Hack Kalman Filtering

 Ido Greenberg

Technion

gido@campus.technion.ac.il &Netanel Yannay

ELTA Systems

natiy4@gmail.com &Shie Mannor

Technion, Nvidia Research

shie@ee.technion.ac.il

###### Abstract

In non-linear filtering, it is traditional to compare non-linear architectures such as neural networks to the standard linear Kalman Filter (KF). We observe that this mixes the evaluation of two separate components: the non-linear architecture, and the parameters optimization method. In particular, the non-linear model is often optimized, whereas the reference KF model is not. We argue that _both_ should be optimized similarly, and to that end present the Optimized KF (**OKF**). We demonstrate that the KF may become competitive to neural models - if optimized using OKF. This implies that experimental conclusions of certain previous studies were derived from a flawed process. The advantage of OKF over the standard KF is further studied theoretically and empirically, in a variety of problems. Conveniently, OKF can replace the KF in real-world systems by merely updating the parameters. Our experiments are published in \(\underline{\text{Github}}\), and the OKF in \(\underline{\text{PyPI}}\).

## 1 Introduction

The Kalman Filter (KF) [17] is a celebrated method for linear filtering and prediction, with applications in many fields including tracking, navigation, control and reinforcement learning [13, 14, 15]. The KF provides optimal predictions under certain assumptions (namely, linear models with i.i.d noise). In practical problems, these assumptions are often violated, rendering the KF sub-optimal and motivating the growing field of non-linear filtering. Many studies demonstrated the benefits of non-linear models over the KF [11, 12].

Originally, we sought to join this line of works. Motivated by a real-world Doppler radar problem, we developed a dedicated non-linear Neural KF (NKF) based on the LSTM sequential model. NKF achieved significantly better accuracy than the linear KF.

Then, during ablation tests, we noticed that the KF and NKF differ in _both architecture and optimization_. Specifically, the KF's noise parameters are traditionally determined by noise estimation [1]; whereas NKF's parameters are optimized using supervised learning. To fairly evaluate the two architectures, we wished to apply the same optimization to both. To that end, we devised an Optimized KF (**OKF**, Section 3). KF and OKF have the same linear architecture: OKF only changes the noise parameters values. Yet, unlike KF, OKF _outperformed_ NKF, which reversed the whole experimental conclusion, and made the neural network unnecessary for this problem (Section 4).

Our original error was comparing two different model architectures (KF and NKF) that were not optimized similarly. A review of the non-linear filtering literature reveals that this methodology is used in many studies. Specifically, for a baseline KF model, the parameters are often tuned by noise estimation [18, 12]; by heuristics [13, 14, 15]; or are simply ignored [16, 17, 18], often without public code for examination. Hussein [15]even discusses the (Extended-)KF sensitivity to its parameters, and suggests a neural network with supervised learning - yet never considers the same supervised learning for the KF itself. In all these 10 studies, the non-linear model's added value cannot be inferred from the experimental evidence.

So far, OKF is presented as a _methodological contribution_: for comparison with non-linear methods, it forms a more coherent baseline than KF. In addition, OKF provides a _practical contribution_: it achieves more accurate filtering than the KF, using identical architecture. This is demonstrated extensively in Section 5 and Appendix B - in different domains, over different problem variations, using different KF baselines, with different data sizes, and even under distributional shifts.

**Discrepancy of objectives**: The advantage of OKF over KF may come as a surprise: KF's standard noise estimation is known to already obtain the MSE-optimal parameters! However, this optimality relies on unrealistic assumptions, often considered "fairy tales for undergraduates" [Thomson, 1994]. When violated, a conflict emerges between noise estimation and MSE optimization. We study this in detail: (a) Section 5 analyzes the conflict theoretically under certain assumption violations; (b) Appendix B.1 shows that even oracle noise estimation cannot optimize the MSE; (c) Appendix B.2 shows that when using noise estimation, **the MSE may degrade with more data**. In this light, all our findings can be summarized as follows (also see Fig. 1):

**Contribution:** (a) We observe that in most scenarios, since the KF assumptions do not hold, noise estimation is _not_ a proxy to MSE optimization. (b) We thus present the Optimized KF (OKF), also available as a PyPI package. We analyze (theoretically and empirically) the consequences of neglecting to optimize the KF: (c) the standard KF tuning method leads to sub-optimal predictions; (d) the standard methodology in the literature compares an optimized model to a non-optimized KF, hence may produce misleading conclusions. Note that we _do not_ argue against the non-linear models; rather, we claim that their added value cannot be deduced from flawed experiments.

**Scope: We focus on the supervised filtering setting**, where training data includes both observations and the true system states (whose prediction is usually the objective). Such data is available in many practical applications. For example, the states may be provided by external accurate sensors such as GPS fa Dai et al. [2020]; by manual object labeling in computer vision [Wojke et al., 2017]; by controlled experiments of radar targets; or by simulations of known dynamic systems.

As demonstrated in the 10 studies cited above, this supervised setting is common in non-linear filtering. In linear Kalman filtering, this setting seems to be solved by trivial noise estimation; thus, the literature tends to overlook it, and instead focuses on settings that do not permit trivial noise estimation, e.g., learning from observations alone. Nevertheless, we argue that even in the supervised setting, noise estimation is often not a proxy to MSE optimization, and thus should often be avoided.

## 2 Preliminaries

Consider the KF model for a dynamic system with no control signal [Kalman, 1960]:

\[X_{t+1}=F_{t}X_{t}+\omega_{t}\quad(\omega_{t}\sim\mathcal{N}(0,Q)),\qquad\quad Z _{t}=H_{t}X_{t}+\nu_{t}\quad(\nu_{t}\sim\mathcal{N}(0,R)). \tag{1}\]

\(X_{t}\) is the system state at time \(t\), and its estimation is usually the goal. Its dynamics are modeled by the linear operator \(F_{t}\), with random noise \(\omega_{t}\) whose covariance is \(Q\). \(Z_{t}\) is the observation, modeled by the operator \(HThe KF represents \(X_{t}\) via estimation of the mean \(\hat{x}_{t}\) and covariance \(\hat{P}_{t}\). As shown in Fig. 2, the KF alternately predicts the next state (_prediction_ step), and processes new information from incoming observations (_update_ or _filtering_ step). The KF relies on the matrices \(\tilde{F}_{t},\tilde{H}_{t},\hat{Q},\hat{R}\), intended to represent \(F_{t},H_{t},Q,R\) of Eq. (1). Whenever \(F_{t},H_{t}\) are known and stationary, we may simplify the notation to \(\tilde{F}_{t}=F\), \(\tilde{H}_{t}=H\).

The KF estimator \(\hat{x}_{t}\) is optimal in terms of mean square errors (MSE) - but only under a restrictive set of assumptions (Kalman, 1960):

**Assumption 1** (KF assumptions).: \(\tilde{F}_{t}=F_{t},\,\tilde{H}_{t}=H_{t}\) are known and independent of \(X_{t}\) (linear models); each sequence \(\{\omega_{t}\},\{\nu_{t}\}\) is i.i.d; the covariances \(\hat{Q}=Q,\,\hat{R}=R\) are known; and \(\hat{x}_{0},\hat{P}_{0}\) correspond to the mean and covariance of the initial \(X_{0}\).

**Theorem 1** (KF optimality; e.g., see Jazwinski (2007); Humpherys et al. (2012)).: Under Assumption 1, the KF estimator \(\hat{x}_{t}\) minimizes the MSE w.r.t. \(X_{t}\).

The KF accuracy strongly depends on its parameters \(\hat{Q}\) and \(\hat{R}\)(Formentin and Bittanti, 2014). As motivated by Theorem 1, these parameters are usually identified with the noise covariance \(Q,R\) and are set accordingly: "the systematic and preferable approach to determine the filter gain is to estimate the covariances from data" (Odelson et al., 2006). In absence of system state data \(\{x_{t}\}\) (the "ground truth"), many methods were suggested to estimate the covariances from observations \(\{z_{t}\}\) alone (Mehra, 1970; Zanni et al., 2017; Park et al., 2019; Feng et al., 2014). We focus on the supervised setting, where the states \(\{x_{t}\}\) are available in the training-data (but not in inference).

**Definition 1** (Supervised data).: Consider \(K\) trajectories of a dynamic system, with lengths \(\{T_{k}\}_{k=1}^{K}\). We define their supervised data as the sequences of true system states \(x_{k,t}\in\mathbb{R}^{d_{x}}\) and observations \(z_{k,t}\in\mathbb{R}^{d_{z}}\): \(\{\{(x_{k,t},z_{k,t})\}_{t=1}^{T_{k}}\}_{k=1}^{K}\).

If \(F_{t},H_{t}\) are known, the supervised setting permits a direct calculation of the sample covariance matrices of the noise (Lacey, 1998):

\[\hat{Q}\coloneqq Cov(\{x_{k,t+1}-F_{t}x_{k,t}\}_{k,t}),\qquad\hat{R}\coloneqq Cov (\{z_{k,t}-H_{t}x_{k,t}\}_{k,t}). \tag{2}\]

Since Theorem 1 guarantees optimality when \(\hat{Q}=Q,\hat{R}=R\), and Eq. (2) provides a simple estimator for \(Q\) and \(R\), Algorithm 1 has become the gold-standard tuning method for KF from supervised data.

**Algorithm 1** (KF noise estimation).: Given supervised data \(\{(x_{k,t},z_{k,t})\}\), return \(\hat{Q}\) and \(\hat{R}\) of Eq. (2).

While Algorithm 1 is indeed trivial to apply in the supervised setting, we show below that when Assumption 1 is violated, it no longer provides optimal predictions. Violation of Assumption 1 can be partially handled by certain variations of the KF, such as Extended KF (EKF) (Sorenson, 1985) and Unscented KF (UKF) (Wan and Van Der Merwe, 2000).

## 3 Optimized Kalman Filter

Estimation of the KF noise parameters \(\hat{Q},\hat{R}\) has been studied extensively in various settings; yet, in our supervised setting it is trivially solved by Algorithm 1. However, once Assumption 1 is violated,

Figure 2: The KF algorithm. The prediction step is based on the motion model \(\tilde{F}_{t}\) with noise \(\hat{Q}\), whereas the update step is based on the observation model \(\tilde{H}_{t}\) with noise \(\hat{R}\).

such noise estimation is no longer a proxy to MSE optimization - despite Theorem 1. Instead, in this section we propose to determine \(\hat{Q}\) and \(\hat{R}\) via explicit MSE optimization. We rely on standard optimization methods for sequential supervised learning; as discussed below, the main challenge is to maintain the Symmetric and Positive Definite (SPD) structure of \(\hat{Q},\hat{R}\) as covariance matrices.

Formally, we consider the KF (Fig. 2) as a prediction model \(\hat{x}_{k,t}(\{z_{k,\tau}\}_{\tau=1}^{t};\,\hat{Q},\hat{R})\), which estimates \(x_{k,t}\) given the observations \(\{z_{k,\tau}\}_{\tau=1}^{t}\) and parameters \(\hat{Q},\hat{R}\). We define the KF optimization problem:

\[\operatorname*{argmin}_{Q^{\prime},R^{\prime}}\sum_{k=1}^{K}\sum_{t=1}^{T_{k}} \operatorname*{loss}\left(\hat{x}_{k,t}\left(\{z_{k,\tau}\}_{\tau=1}^{t};\,Q^ {\prime},R^{\prime}\right),\;x_{k,t}\right),\qquad\text{s.t. }Q^{\prime}\in S_{++}^{d_{x}},\;R^{ \prime}\in S_{++}^{d_{z}}, \tag{3}\]

where \(S_{++}^{d}\subset\mathbb{R}^{d\times d}\) is the space of Symmetric and Positive Definite matrices (SPD), and \(\operatorname*{loss}(\cdot)\) is the objective function (e.g., \(\operatorname*{loss}(\hat{x},x)=||\hat{x}-x||^{2}\) for MSE). Prediction of future states can be expressed using the same Eq. (3), by changing the observed input from \(\{z_{k,\tau}\}_{\tau=1}^{t}\) to \(\{z_{k,\tau}\}_{\tau=1}^{t-1}\).

A significant challenge in solving Eq. (3) is the SPD constraint. Standard numeric supervised optimization methods (e.g., Adam (Diederik P. Kingma, 2014)) may violate the constraint. While the SPD constraint is often bypassed using diagonal restriction (Li et al., 2019; Formentin and Bittanti, 2014), this may significantly degrade the predictions, as demonstrated in the ablation tests in Appendix B.4. Instead, to maintain the complete expressiveness of \(\hat{Q}\) and \(\hat{R}\), we use the Cholesky parameterization (Pinheiro and Bates, 1996).

```
1Input: training data \(\{(x_{k,t},z_{k,t})\}_{k=1}^{K}\) (Definition 1); batch size \(b\); loss function (e.g., MSE); optimization_step function (e.g., Adam)
2\(d_{x}\leftarrow\operatorname*{len}(x_{1,1}),\quad d_{z}\leftarrow\operatorname* {len}(z_{1,1})\) Initialize \(\theta_{Q}\in\mathbb{R}^{\frac{1}{2}d_{x}(d_{x}+1)},\;\theta_{R}\in\mathbb{R}^{ \frac{1}{2}d_{z}(d_{x}+1)}\)whiletraining not finished do// Get\(Q,R\)using Eq. (4) \(\hat{Q}\gets L(\theta_{Q})L(\theta_{Q})^{\top},\quad\hat{R}\gets L( \theta_{R})L(\theta_{R})^{\top}\)\(\mathcal{K}\leftarrow\operatorname*{sample}(\{1,...,K\},\) size=\(b)\)\(C\gets 0\)for\(k\)in\(\mathcal{K}\)do Initialize \(\hat{x}\in\mathbb{R}^{d_{x}}\)for\(t\)in \(1:T_{k}\)do// KFsteps (Fig. 2) \(\hat{x}\leftarrow\text{KF\_predict}(\hat{x};\,\hat{Q})\)\(\hat{x}\leftarrow\text{KF\_update}(\hat{x},z_{k,t};\,\hat{R})\)\(C\gets C+\operatorname*{loss}(\hat{x},\,x_{k,t})\)\(\theta_{Q},\theta_{R}\leftarrow\text{optimization\_step}(C,\,(\theta_{Q},\theta_{R}))\) Return \(\hat{Q},\,\hat{R}\)
```

**Algorithm 2**Optimized Kalman Filter (OKF)

The parameterization relies on Cholesky decomposition: any SPD matrix \(A\in\mathbb{R}^{d\times d}\) can be written as \(A=LL^{\top}\), where \(L\) is lower-triangular with positive entries along its diagonal. Reversely, for any lower-triangular \(L\) with positive diagonal, \(LL^{\top}\) is SPD. Thus, to represent an SPD \(A\in\mathbb{R}^{d\times d}\), we define \(A(L)\coloneqq LL^{\top}\) and parameterize \(L(\theta)\) to be lower-triangular, have positive diagonal, and be differentiable in the parameters \(\theta\):

\[(L(\theta))_{ij}\coloneqq\begin{cases}0&\text{if }i<j,\\ e^{\theta_{d(d-1)/2+i}}&\text{if }i=j,\\ \theta_{(i-2)(i-1)/2+j}&\text{if }i>j,\end{cases} \tag{4}\]

where \(\theta\in\mathbb{R}^{d(d+1)/2}\).

Both Cholesky parameterization and sequential optimization methods are well known tools. Yet, for KF optimization _from supervised data_, we are not aware of any previous attempts to apply them together, as noise estimation (Algorithm 1) is typically preferred.

We wrap the optimization process in the Optimized KF (**OKF**) in Algorithm 2, which outputs optimized parameters \(\hat{Q},\hat{R}\) for Fig. 2. Note that Algorithm 2 optimizes the state estimation at _current_ time \(t\). By switching Line 12 and Line 13, the optimization will instead be shifted to state prediction at the _next_ time-step (as \(\hat{x}\) becomes oblivious to the current observation \(z_{k,t}\)).

**Lack of theoretical guarantees:** If Assumption 1 cannot be trusted, neither noise estimation (Algorithm 1) nor OKF (Algorithm 2) can guarantee global optimality. Still, OKF pursues the MSE objective using standard optimization tools, which achieved successful results in many non-convex problems (Zhong et al., 2020) over millions of parameters (Devlin et al., 2019). On the other hand, noise estimation pursues a _conflicting_ objective, and guarantees significant sub-optimality in certain scenarios, as analyzed in Section 5.

## 4 OKF vs. Neural KF: Is the Non-Linearity Helpful?

In this section, we demonstrate that comparing an optimized neural network to a non-optimized baseline may lead to incorrect conclusions: the network may seem superior even if the complicated architecture has no added value. The implied message is not against neural networks, but rather that evaluating them against a non-optimized baseline carries a crucial flaw.

**The Doppler radar problem:** We consider a variant of the classic Doppler radar problem [Barton, 1988, Roy and Mitra, 2016], where various targets trajectories are tracked in a homogeneous 3D space, given regular observations of a Doppler radar. The state \(X=(x_{x},x_{y},x_{z},x_{ux},x_{uy},x_{uz})^{\top}\in\mathbb{R}^{6}\) consists of 3D location and velocity. The goal is to minimize the MSE over the 3 location coordinates. While the true dynamics \(F\) are unknown to the KF, a constant-velocity model \(\tilde{F}\) can be used:

\[\tilde{F}=\left(\begin{smallmatrix}1&\begin{smallmatrix}1&\\ &1&1\\ &&1&1\\ &&1&1\end{smallmatrix}\\ &&1&1\end{smallmatrix}\right). \tag{5}\]

An observation \(Z\in\mathbb{R}^{4}\) consists of the location in spherical coordinates (range, azimuth, elevation) and the radial velocity (the Doppler signal), with an additive i.i.d Gaussian noise. After transformation to Cartesian coordinates, the observation model can be written as:

\[H=H(X)=\left(\begin{smallmatrix}1&\\ &1&\\ &&\frac{x_{x}}{\tau}&\frac{x_{y}}{\tau}&\frac{x_{z}}{\tau}\end{smallmatrix} \right), \tag{6}\]

where \(r=\sqrt{x_{x}^{2}+x_{y}^{2}+x_{z}^{2}}\). Since \(H=H(X)\) relies on the unknown location \((x_{x},x_{y},x_{z})\), we instead substitute \(\tilde{H}\coloneqq H(Z)\) in the KF update step in Fig. 2.

**Neural KF:** The Neural Kalman Filter (NKF) incorporates an LSTM model into the KF framework, as presented in Appendix C and Fig. 16. We originally developed NKF to improve the prediction of the non-linear highly-maneuvering targets in the Doppler problem (e.g., Fig. 3), and made honest efforts to engineer a well-motivated architecture. Regardless, we stress that this section demonstrates a methodological flaw when comparing _any_ optimized filtering method to the KF; this methodological argument stands regardless of the technical quality of NKF. In addition, Appendix C presents similar results for other variants of NKF.

**Experiments:** We train NKF and OKF on a dataset of simulated trajectories, representing realistic targets with free motion (as displayed in Fig. 3). As a second benchmark, we also train on a dataset of simplified trajectories, with speed changes but with no turns. The two benchmarks are specified in detail in Appendix B.1, and correspond to Fig. 11(d) and Fig. 11(e). We tune the KF from the same datasets using Algorithm 1. In addition to out-of-sample test trajectories, we also test generalization to out-of-distribution trajectories, generated using different ranges of target accelerations (affecting both speed changes and turns radiuses).

Figure 4: Test errors and 95% confidence intervals, over targets with different accelerations. The middle acceleration range coincides with the training accelerations (24-48 in (a) and 8-16 in (b)), and the other ranges correspond to out-of-distribution generalization.

Figure 3: A sample trajectory and the corresponding predictions (projected onto XY plane), in the Freedom benchmark. The standard KF provides inaccurate predictions in certain turns.

Fig. 4 summarizes the test results. Compared to KF, NKF reduces the errors in both benchmarks, suggesting that the non-linear architecture pays off. However, optimization of the KF (using OKF) reduces the errors even further, and thus reverses the conclusion. That is, the advantage of NKF in this problem comes _exclusively_ from optimization, and _not at all_ from the expressive architecture.

## 5 OKF vs. KF:

Section 4 presents the methodological contribution of OKF for non-linear filtering, as an optimized baseline for comparison, instead of the standard KF. In this section, we study the advantage of OKF over the KF more generally. We show that OKF consistently outperforms the KF in a variety of scenarios from 3 different domains. This carries considerable practical significance: unlike neural models, shifting from KF to OKF merely requires change of the parameters \(\hat{Q}\), \(\hat{R}\), hence can be deployed to real-world systems without additional overhead, complexity or latency on inference.

Recall that by Theorem 1, the KF is already optimal unless Assumption 1 is violated. Thus, the violations are discussed in depth, and the effects of certain violations are analyzed theoretically.

### Doppler Radar Tracking

Theorem 1 guarantees the optimality of Algorithm 1 (KF). Yet, in Section 4, OKF outperforms the KF. This is made possible by the violation of Assumption 1: while the Doppler problem of Section 4 may not seem complex, the trajectories follow a non-linear motion model (as displayed in Fig. 3).

Imagine that we simplified the problem by only simulating constant-velocity targets, making the true motion model \(F\) linear. Would this recover Assumption 1 and make OKF unnecessary? The answer is _no_; the adventurous reader may attempt to list all the remaining violations before reading on.

The simulated targets move mostly horizontally, with limited elevation changes. This is not expressed by the KF's initial state distribution (\(\hat{x}_{0},\hat{P}_{0}\)). To remedy this, one may simulate motion uniformly in all directions. A third violation comes from the observation noise. While the radar noise is i.i.d in spherical coordinates (as mentioned in Section 4), it is not i.i.d in _Cartesian_ coordinates (see discussion in Appendix A.2). To overcome this, one may simulate a radar with (physically-impossible) Cartesian i.i.d noise. This results in the unrealistically-simplified problem visualized in Fig. 5.

Despite the simplifications, it turns out that Assumption 1 is still not met, as the observation model in Eq. (6) is still not linear (i.e., \(H=H(X)\) is not constant). As shown by Proposition 1, this single violation alone results in a significant deviation of Algorithm 1 from the optimal parameters.

We first define the simplified problem.

**Problem 1** (The toy Doppler problem).: The toy Doppler problem is the filtering problem modeled by Eq. (1), with constant-velocity dynamics \(F\) (Eq. (5)), Doppler observation \(H\) (Eq. (6)), and

\[Q=\boldsymbol{0}\in\mathbb{R}^{6\times 6},\qquad R=\left(\begin{smallmatrix} \sigma_{x}^{2}&\sigma_{y}^{2}\\ &\sigma_{x}^{2}&\\ &&\sigma_{x}^{2}\end{smallmatrix}\right),\]

where \(\sigma_{x},\sigma_{y},\sigma_{z},\sigma_{D}>0\).

Recall that \(H=H(X)\) in Eq. (6) depends on the state \(X\), which is unknown to the model. Thus, we assume that \(\hat{H}=H(\hat{X})\) is used in the KF update step (Fig. 2), with some estimator \(\hat{X}\approx X\) (e.g.,

Figure 5: The original Doppler problem (left) is simplified to a toy problem (right), with linear motion, isotropic flying directions and physically-impossible radar. After all the simplifications, Assumption 1 still does not hold, thus Algorithm 1 is still sub-optimal and outperformed by OKF.

\(\tilde{H}=H(Z)\) in Section 4). Hence, the _effective_ noise is \(\tilde{R}:=Cov(Z-\tilde{H}X)\neq Cov(Z-HX)=R\). Proposition 1 analyzes the difference between \(\tilde{R}\) and \(R\). To simplify the analysis, we further assume that the error \(\tilde{X}-X\) within \(\tilde{H}\) (e.g., \(Z-X\)) is independent of the target velocity.

**Proposition 1**.: In the toy Doppler Problem 1 with the estimated observation model \(\tilde{H}\), the effective observation noise \(\tilde{R}=Cov(Z-\tilde{H}X)\) is:

\[\tilde{R}=\left(\begin{smallmatrix}\sigma_{x}^{2}&\sigma_{y}^{2}\\ &\sigma_{y}^{2}\\ &&\sigma_{z}^{2}+C\end{smallmatrix}\right)=R+\left(\begin{smallmatrix}0&0\\ &0\\ &&0\\ &&C\end{smallmatrix}\right), \tag{7}\]

where \(C=\Omega(\mathbb{E}[||u||^{2}])\) is the asymptotic lower bound ("big omega") of the expected square velocity \(u\). In particular, \(C>0\) and is unbounded as the typical velocity grows.

Proof sketch (see complete proof in Appendix A.1).: We have \(Cov(Z-\tilde{H}X)=Cov(Z-HX+(H-\tilde{H})X)=R+Cov((H-\tilde{H})X)\), where the last equality relies on the independence between the target velocity and the estimation error \(\tilde{X}-X\). We then calculate \(Cov((H-\tilde{H})X)\). 

Proposition 1 has an intuitive interpretation: when measuring the velocity, Algorithm 1 only considers the inherent Doppler signal noise \(\sigma_{D}\). However, the _effective_ noise \(\sigma_{D}+C\) also includes the _transformation error_ from Doppler to the Cartesian coordinates, caused by the uncertainty in \(H(X)\) itself. Notice that heuristic solutions such as inflation of \(R\) would not recover the effective noise \(\tilde{R}\), which only differs from \(R\) in one specific entry.

Yet, as demonstrated below, OKF captures the effective noise \(\tilde{R}\) successfully. Critically, it does so from mere data: OKF does not require the user to specify the model correctly, or to even be aware of the violation of Assumption 1.

**Experiments:** We test KF and OKF on the toy Problem 1 using the same methodology as in Section 4. In accordance with Proposition 1, OKF adapts the Doppler noise parameter: as shown in Fig. 6, it increases \(\sigma_{D}\) in proportion to the location noise by a factor of \(\approx 13\). Note that we refer to the proportion instead of absolute values due to scale-invariance in the toy problem, as discussed in Appendix A.1. Following the optimization, **OKF reduces the test MSE by 44%** - from 152 to 84.

**Extended experiments:** This section and Section 4 test OKF against KF in three specific variants of the Doppler problem. One may wonder if OKF's advantage generalizes to other scenarios, such as:

* Different subsets of violations of Assumption 1;
* Other baseline models than KF, e.g., Optimized Extended-KF;
* Small training datasets;
* Generalization to out-of-distribution test data.

The extended experiments in Appendix B address _all_ of the concerns above by examining a wide range of problem variations in the Doppler radar domain. In addition, other domains are experimented below. **In all of these experiments, OKF outperforms Algorithm 1 in terms of MSE**.

Finally, the goal-misalignment of Algorithm 1 is demonstrated directly by two results: even oracle noise estimation fails to optimize the MSE (Appendix B.1); and feeding more data to Algorithm 1 may _degrade_ the MSE (Appendix B.2). Fig. 7 presents a sample of the results of Appendix B.2.

Figure 6: The parameters \(\hat{R}\) learned by KF and OKF in the toy Doppler problem. The rows and columns’ entries correspond to location (\(x,y,z\)) and radial velocity (\(Doppler\)). The simulated noise variance is \(100^{2}\) for the positional dimensions and \(5^{2}\) for velocity, and is estimated accurately by the KF. However, OKF increases the noise associated with velocity, in accordance with Proposition 1. The decrease in the positional variance comes from scale-invariance in the toy problem, as discussed in Appendix A.1.

Figure 7: Different train data sizes in the Doppler problem (Fig. 3). Due to objective misalignment, Algorithm 1 deteriorates with more train data.

### Video Tracking

The MOT20 dataset (Dendorfer et al., 2020) contains videos of real-world targets (mostly pedestrians, as shown in Fig. 8), along with their true location and size in every frame. For our experimental setup, since object detection is out of the scope, we assume that the true locations are known in real-time. The objective is to predict of the target location in the next frame. The state space corresponds to the 2D location, size and velocity, and the observations include only the location and size. The underlying dynamics \(F\) of the pedestrians are naturally unknown, and the standard constant-velocity model is used for \(\tilde{F}\). This results in the following model:

\[\tilde{F}=\left(\begin{smallmatrix}1&1&1&1\\ &1&1&1\\ &&1&1\\ &&1&1\end{smallmatrix}\right),\quad\tilde{H}=H=\left(\begin{smallmatrix}1&1&0 &0\\ &1&1&0&0\\ &1&0&0\end{smallmatrix}\right).\]

Notice that the known observation model \(\tilde{H}=H\) is _linear_ (\(H\) is independent of \(X\)), hence poses a substantial difference from Section 5.1 in terms of violations of Assumption 1.

The first three videos with 1117 trajectories are used for training, and the last video with 1208 trajectories for testing. As shown in Fig. 7(a), OKF reduces the test MSE by 18% with high statistical significance.

### Lidar-based State Estimation in Self Driving

Consider the problem of state-estimation in self-driving, based on lidar measurements with respect to known landmarks (Moreira et al., 2020). The objective is to estimate the current vehicle location. We assume a single landmark (since the landmark matching problem is out of scope). We simulate driving trajectories consisting of multiple segments, with different accelerations and turn radiuses

Figure 8: A sample of 2 trajectories in the first frame of MOT20 test video, along with the predictions of KF and OKF.

Figure 9: Summary of the test errors in the video and lidar problems. The dashed lines correspond to MSE. Both z-values correspond to p-value \(<10^{-6}\). Each z-value is calculated over \(N\) test trajectories as follows: \(z=\frac{\mathrm{mean}(\{\Delta_{i}\})}{\mathrm{std}(\{\Delta_{i}\})}\sqrt{N}\), where \(\Delta_{i}=err_{i}(KF)^{2}-err_{i}(OKF)^{2}\) is the square-error difference on trajectory \(1\leq i\leq N\).

(see Fig. 14(a) in the appendix). The state is the vehicle's 2D location and velocity, and \(\tilde{F}\) is modeled according to constant-velocity. The observation (both true \(H\) and modeled \(\tilde{H}\)) corresponds to the location, with an additive Gaussian i.i.d noise in polar coordinates. This results in the following model:

\[\tilde{F}=\left(\begin{smallmatrix}1&0&1&0\\ 0&1&0&1\\ 0&0&0&0\\ 0&0&0&1\end{smallmatrix}\right),\quad\tilde{H}=H=\left(\begin{smallmatrix}1&0 &0&0\\ 0&1&0&0\end{smallmatrix}\right).\]

We train KF and OKF over 1400 trajectories and test them on 600 trajectories. As shown in Fig. 7(b), OKF reduces the test MSE by 10% with high statistical significance.

Notice that the lidar problem differs from Section 5.1 in the linear observation model \(H\), and from Section 5.2 in the additive noise. Both properties have a major impact on the problem, as analyzed in Proposition 1 and below, respectively.

**Theoretical analysis:** As mentioned in Section 5.1 and discussed in Appendix A.2, the i.i.d noise in polar coordinates is not i.i.d in Cartesian ones. To isolate the i.i.d violation and study its effect, we define a simplified toy model - with simplified states, no-motion model \(F\), isotropic motion noise \(Q\) and only radial observation noise. Note that in contrast to Section 5.1, the observation model is already linear.

**Problem 2** (The toy lidar problem).: The toy lidar problem is the filtering problem modeled by Eq. (1) with the following parameters:

\[F=H=\begin{pmatrix}1&0\\ 0&1\end{pmatrix},\;Q=\begin{pmatrix}q&0\\ 0&q\end{pmatrix},\;R_{polar}=\begin{pmatrix}r_{0}&0\\ 0&0\end{pmatrix},\]

for some unknown \(q,r_{0}>0\), with observation noise drawn i.i.d from \(\mathcal{N}(0,R_{polar})\) in _polar_ coordinates. The initial state \(X_{0}\) follows a radial distribution (i.e., with a PDF of the form \(f(||x_{0}||)\)).

**Proposition 2**.: As the number \(N\) of train trajectories in Problem 2 grows, the noise parameter \(\hat{R}_{N}(KF)\) estimated by Algorithm 1 converges almost surely:

\[\hat{R}_{N}(KF)\xrightarrow{\text{a.s.}}\hat{R}_{est}=\begin{pmatrix}r_{0}/2& 0\\ 0&r_{0}/2\end{pmatrix}.\]

On the other hand, under regularity assumptions, the MSE is minimized by the parameter \(\hat{R}_{opt}=\left(\begin{smallmatrix}r&0\\ 0&r\end{smallmatrix}\right)\), where \(r<r_{0}/2\).

Proof sketch (see complete proof in Appendix A.2).: For \(\hat{R}_{est}\), we calculate \(\mathbb{E}[\hat{R}_{N}(KF)]\) and use the law of large numbers. For the calculation, we transform \(R_{polar}\) to Cartesian coordinates using the random direction variable \(\theta\), and take the expectation over \(\theta\sim U([0,2\pi))\). The uniform distribution of \(\theta\) comes from the radial symmetry of the problem. For \(\hat{R}_{opt}\), we calculate and minimize the expected square error directly. 

Intuitively, Proposition 2 shows that the i.i.d violation reduces the _effective_ noise. Note that the analysis only holds for the unrealistic toy Problem 2. The empirical setting in this section is less simplistic, and generalizing Proposition 2 is not trivial. Fortunately, OKF optimizes directly from the data, and does not require such theoretical analysis. Fig. 10 shows that indeed, in accordance with the intuition of Proposition 2, OKF learns to reduce the values of \(\hat{R}\) in comparison to KF. This results in reduced test errors as specified above.

Figure 10: The parameters \(\hat{R}\) learned in the lidar problem. From data alone, OKF learns to decrease the noise parameters, consistently with Proposition 2.

Related Work

**Noise estimation** of the KF parameters from observations alone has been studied for decades, as supervised data (Definition 1) is often unavailable. Various methods were studied, based on autocorrelation (Mehra, 1970; Carew and Belanger, 1973), EM (Shumway and Stoffer, 2005) and others (Odelson et al., 2006; Feng et al., 2014; Park et al., 2019). When supervised data _is_ available, noise estimation reduces to Eq. (2) and is considered a solved problem (Odelson et al., 2006). We show that while noise estimation is indeed easy from supervised data, it may be the wrong objective to pursue.

**Optimization:** We apply gradient-based optimization to the KF with respect to its errors. In absence of supervised data, gradient-based optimization was suggested for other losses, such as smoothness (Barratt and Boyd, 2020). In the supervised setting, noise estimation is typically preferred (Odelson et al., 2006), although optimization without gradients was suggested in Abbeel et al. (2005). In practice, "optimization" of KF is sometimes handled by trial and error (Jamil et al., 2020) or grid search (Formentin and Bittanti, 2014; Coskun et al., 2017). In other cases, \(Q\) and \(R\) are restricted to be diagonal (Li et al., 2019; Formentin and Bittanti, 2014). However, such heuristics may not suffice when the optimal parameters take a non-trivial form.

**Neural Networks (NNs) in filtering:** The NKF in Section 4 relies on a recurrent NN. NNs are widely used in non-linear filtering, e.g., for online prediction (Gao et al., 2019; Iter et al., 2016; Coskun et al., 2017; fa Dai et al., 2020; Belogolovsky et al., 2022), near-online prediction (Kim et al., 2018), and offline prediction (Liu et al., 2019). Learning visual features for tracking via a NN was suggested by Wojke et al. (2017). NNs were also considered for related problems such as data association (Liu et al., 2019), model switching (Deng et al., 2020), and sensors fusion (Sengupta et al., 2019).

In addition, all the 10 studies cited in Section 1 used a NN model for non-linear filtering, with either KF or EKF as a baseline for comparison. As discussed above, none has optimized the baseline model to a similar extent as the NN. As demonstrated in Section 4, such methodology could lead to unjustified conclusions.

## 7 Summary

We observed that violation of the KF assumptions is common, and is potentially difficult to notice or model. Under such violation, we analyzed (theoretically and empirically) that the standard noise estimation of the KF parameters conflicts with MSE optimization. An immediate consequence is that the KF is often used sub-optimally. A second consequence is that in many works in the literature, where a neural network is compared to the KF, the experiments become inconclusive: they cannot decide whether the network succeeded due to superior architecture, or merely because its parameters were optimized. We presented the Optimized KF (OKF), and demonstrated that it can solve both issues (Section 5 and Section 4, respectively).

From a practical point of view, the OKF is available on PyPI and is easily applicable to new problems. Since its architecture is identical to the KF, and only the parameters are changed, the learned model causes neither inference-time delays nor deployment overhead. All these properties make the OKF a powerful practical tool for both linear and non-linear filtering problems.

#### Acknowledgements

The authors thank Tal Malinovich, Ophir Nabati, Zahar Chikishev, Mark Kozdoba, Eli Meirom, Elad Sharony, Itai Shufaro and Shirli Di-Castro for their helpful advice. This work was partially funded by the European Union's Horizon Europe Programme, under grant number 101070568.

## References

* Abbeel et al. (2005) Pieter Abbeel, Adam Coates, Michael Montemerlo, Andrew Ng, and Sebastian Thrun. Discriminative training of kalman filters. _Robotics: Science and systems_, pages 289-296, 06 2005.
* Aydogmus & Aydogmus (2015) Zafer Aydogmus and Omur Aydogmus. A comparison of artificial neural network and extended kalman filter based sensorless speed estimation. _Measurement_, 63:152-158, 2015. ISSN 0263-2241.
* Bai et al. (2020) Yu-ting Bai, Xiao-yi Wang, Xue-bo Jin, Zhi-yao Zhao, and Bai-hai Zhang. A neuron-based kalman filter with nonlinear autoregressive model. _Sensors_, 20(1):299, 2020.
* Barratt & Boyd (2020) S. T. Barratt and S. P. Boyd. Fitting a kalman smoother to data. In _2020 American Control Conference (ACC)_, pages 1526-1531, 2020.
* Barton (1988) David K Barton. Modern radar system analysis. _Norwood_, 1988.
* Belogolovsky et al. (2022) Stav Belogolovsky, Ido Greenberg, Danny Eitan, and Shie Mannor. Continuous forecasting via neural eigen decomposition of stochastic dynamics. _arXiv preprint arXiv:2202.00117_, 2022.
* Carew & Belanger (1973) B. Carew and P. Belanger. Identification of optimum filter steady-state gain for systems with unknown noise covariances. _IEEE Transactions on Automatic Control_, 18(6):582-587, 1973.
* Coskun et al. (2017) Huseyin Coskun, Felix Achilles, Robert DiPietro, Nassir Navab, and Federico Tombari. Long short-term memory kalman filters: Recurrent neural estimators for pose regularization. _ICCV_, 2017.
* Dendorfer et al. (2020) Patrick Dendorfer, Hamid Rezatofighi, Anton Milan, Javen Shi, Daniel Cremers, Ian Reid, Stefan Roth, Konrad Schindler, and Laura Leal-Taixe. Mot20: A benchmark for multi object tracking in crowded scenes, 2020. URL [https://motchallenge.net/data/MOT20/](https://motchallenge.net/data/MOT20/).
* Deng et al. (2020) Lichuan Deng, Da Li, and Ruifang Li. Improved IMM Algorithm based on RNNs. _Journal of Physics Conference Series_, 1518:012055, April 2020.
* Devlin et al. (2019) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding, 2019.
* Diederik P. Kingma (2014) Jimmy Ba Diederik P. Kingma. Adam: A method for stochastic optimization, 2014. URL [https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980).
* Dai et al. (2020) Hai fa Dai, Hong wei Bian, Rong ying Wang, and Heng Ma. An ins/gnss integrated navigation in gnss denied environment using recurrent neural network. _Defence Technology_, 16(2):334-340, 2020. ISSN 2214-9147.
* Feng et al. (2014) B. Feng, M. Fu, H. Ma, Y. Xia, and B. Wang. Kalman filter with recursive covariance estimation--sequentially estimating process noise covariance. _IEEE Transactions on Industrial Electronics_, 61(11):6253-6263, 2014.
* Formentin & Bittanti (2014) Simone Formentin and Sergio Bittanti. An insight into noise covariance estimation for kalman filter design. _IFAC Proceedings Volumes_, 47(3):2358-2363, 2014. ISSN 1474-6670. 19th IFAC World Congress.
* Gao et al. (2019) Chang Gao, Junkun Yan, Shenghua Zhou, Bo Chen, and Hongwei Liu. Long short-term memory-based recurrent neural networks for nonlinear target tracking. _Signal Processing_, 164, 05 2019.
* Geist & Pietquin (2011) Matthieu Geist and Olivier Pietquin. Kalman filtering colored noises: the (autoregressive) moving-average case. In _MLASA 2011_, pages 1-4, Honolulu, United States, December 2011.
* Hochreiter & Schmidhuber (1997) Sepp Hochreiter and Jurgen Schmidhuber. Long short-term memory. _Neural Computation_, 1997.
* Humpherys et al. (2012) Jeffrey Humpherys, Preston Redd, and Jeremy West. A fresh look at the kalman filter. _SIAM Review_, 54(4):801-823, 2012.
* Hussein (2014) Ala A. Hussein. Kalman filters versus neural networks in battery state-of-charge estimation: A comparative study. _International Journal of Modern Nonlinear Theory and Application_, 2014.
* Huang et al. (2019)Dan Iter, Jonathan Kuck, and Philip Zhuang. Target tracking with kalman filtering, knn and lstms, 2016.
* Jamil et al. (2020) Faisal Jamil et al. Toward accurate position estimation using learning to prediction algorithm in indoor navigation. Sensors, 2020.
* Jazwinski (2007) Andrew H Jazwinski. _Stochastic processes and filtering theory_. Courier Corporation, 2007.
* Kalman (1960) R. E. Kalman. A New Approach to Linear Filtering and Prediction Problems. _Journal of Basic Engineering_, 82(1):35-45, 03 1960. ISSN 0021-9223.
* Kaufmann et al. (2023) Elia Kaufmann, Leonard Bauersfeld, Antonio Loquercio, Matthias Muller, Vladlen Koltun, and Davide Scaramuzza. Champion-level drone racing using deep reinforcement learning. _Nature_, 2023.
* Kim et al. (2018) Chanho Kim, Fuxin Li, and James M. Rehg. Multi-object tracking with neural gating using bilinear lstm. _ECCV_, September 2018.
* Bar-Shalom et al. (2002) Yaakov Bar-Shalom X.-Rong Li Thiagalingam Kirubarajan. _Estimation with Applications to Tracking and Navigation: Theory, Algorithms and Software_. John Wiley and Sons, Inc., 2002.
* Lacey (1998) Tony Lacey. Tutorial: The kalman filter, 1998. URL "[http://web.mit.edu/kirtley/kirtley/binlustuff/literature/control/Kalmanfilter.pdf](http://web.mit.edu/kirtley/kirtley/binlustuff/literature/control/Kalmanfilter.pdf)".
* Li et al. (2019) S. Li, C. De Wagter, and G. C. H. E. de Croon. Unsupervised tuning of filter parameters without ground-truth applied to aerial robots. _IEEE Robotics and Automation Letters_, 4(4):4102-4107, 2019.
* Liu et al. (2019a) Huajun Liu, Hui Zhang, and Christoph Mertz. Deepda: Lstm-based deep data association network for multi-targets tracking in clutter. _CoRR_, abs/1907.09915, 2019a.
* Liu et al. (2019b) Jingxian Liu, Zulin Wang, and Mai Xu. Deepmtt: A deep learning maneuvering target-tracking algorithm based on bidirectional lstm network. _Information Fusion_, 53, 06 2019b.
* Mehra (1970) R. Mehra. On the identification of variances and adaptive kalman filtering. _IEEE Transactions on Automatic Control_, 15(2):175-184, 1970.
* Moreira et al. (2020) A. Paulo Moreira, Paulo Costa, and Jose Lima. New approach for beacons based mobile robot localization using kalman filters. _Procedia Manufacturing_, 51:512-519, 2020. 30th International Conference on Flexible Automation and Intelligent Manufacturing (FAIM2021).
* Neu et al. (2021) Dominic A. Neu, Johannes Lahann, and Peter Fettke. A systematic literature review on state-of-the-art deep learning methods for process prediction. _CoRR_, abs/2101.09320, 2021.
* 540, 06 2006.
* Park et al. (2019) Sebin Park et al. Measurement noise recommendation for efficient kalman filtering over a large amount of sensor data. _Sensors_, 2019.
* Pinheiro and Bates (1996) Jose C. Pinheiro and Douglas M. Bates. Unconstrained parameterizations for variance-covariance matrices. _Statistics and Computing_, 6:289-296, 1996.
* Revach et al. (2022) Guy Revach, Nir Shlezinger, Xiaoyong Ni, Adria Lopez Escoriza, Ruud JG Van Sloun, and Yonina C Eldar. Kalmannet: Neural network aided kalman filtering for partially known dynamics. _IEEE Transactions on Signal Processing_, 70:1532-1547, 2022.
* Roy and Mitra (2016) Anirban Roy and Debjani Mitra. Multi-target trackers using cubature kalman filter for doppler radar tracking in clutter. _IET Signal Processing_, 10(8):888-901, 2016.
* Rumelhart et al. (1986) David E. Rumelhart et al. Learning representations by back-propagating errors. _Nature_, 1986.
* Sengupta et al. (2019) A. Sengupta, F. Jin, and S. Cao. A dnn-lstm based target tracking approach using mmwave radar and camera sensor fusion. _2019 IEEE National Aerospace and Electronics Conference (NAECON)_, pages 688-693, 2019.
* Sengupta et al. (2019)Robert H. Shumway and David S. Stoffer. Time Series Analysis and Its Applications (Springer Texts in Statistics). Springer-Verlag, Berlin, Heidelberg, 2005. ISBN 0387989501.
* Sorenson (1985) Harold Wayne Sorenson. Kalman Filtering: Theory and Application. IEEE Press, 1985.
* Thomson (1994) D. J. Thomson. Jackknifing multiple-window spectra. In _Proceedings of ICASSP '94. IEEE International Conference on Acoustics, Speech and Signal Processing_, volume vi, pages VI/73-VI/76 vol.6, 1994.
* Ullah et al. (2019) Israr Ullah, Muhammad Fayaz, and DoHyeun Kim. Improving accuracy of the kalman filter algorithm in dynamic conditions using ann-based learning module. _Symmetry_, 11(1), 2019. ISSN 2073-8994.
* Wan and Van Der Merwe (2000) E. A. Wan and R. Van Der Merwe. The unscented kalman filter for nonlinear estimation. _Proceedings of the IEEE 2000 Adaptive Systems for Signal Processing_, pages 153-158, 2000.
* Wojke et al. (2017) Nicolai Wojke, Alex Bewley, and Dietrich Paulus. Simple online and realtime tracking with a deep association metric. In _2017 IEEE International Conference on Image Processing (ICIP)_, pages 3645-3649, 2017.
* Zanni et al. (2017) L. Zanni, J. Le Boudec, R. Cherkaoui, and M. Paolone. A prediction-error covariance estimator for adaptive kalman filtering in step-varying processes: Application to power-system state estimation. _IEEE Transactions on Control Systems Technology_, 25(5):1683-1697, 2017.
* Zarchan and Musoff (2000) Paul Zarchan and Howard Musoff. _Fundamentals of Kalman Filtering: A Practical Approach_. American Institute of Aeronautics and Astronautics, 2000.
* Zheng et al. (2019) Tianyu Zheng, Yu Yao, Fenghua He, and Xinran Zhang. An rnn-based learnable extended kalman filter design and application. In _2019 18th European Control Conference (ECC)_, pages 3304-3309, 2019.
* Zhong et al. (2020) Hui Zhong, Zaiyi Chen, Chuan Qin, Zai Huang, Vincent W. Zheng, Tong Xu, and Enhong Chen. Adam revisited: a weighted past gradients perspective. _Frontiers of Computer Science_, 2020.

###### Contents

* 1 Introduction
* 2 Preliminaries
* 3 Optimized Kalman Filter
* 4 OKF vs. Neural KF: Is the Non-Linearity Helpful?
* 5 OKF vs. KF:
* 6 Related Work
* 7 Summary
* A Theoretical Analysis
* B OKF: Extended Experiments
* C Neural KF: Extended Discussion and Experiments

Theoretical Analysis

### Non-linear Observation

In this section, we discuss the relation between the theoretical analysis of Proposition 1 and the empirical results shown in Fig. 6. Then, we provide the proof of Proposition 1.

**Fig. 6 vs. Proposition 1:** Fig. 6 displays the noise parameters \(\hat{R}\) learned by OKF in the toy problem. In accordance with Proposition 1, the noise \(\sigma_{D}\) associated with Doppler is increased compared to the true measurement noise \(R\). In fact, not only \(\sigma_{D}\) is increased, but also the positional variances are decreased, which is not explained by Proposition 1. This phenomenon origins in the absence of dynamics noise in this toy problem (\(Q\equiv 0\)), which leads to scale-invariance w.r.t. the absolute values of \(\hat{R}\). That is, if we multiply the whole matrix \(\hat{R}\) by a constant factor, the filtering errors are unaffected. Specifically, if we multiply \(\hat{R}\) of Fig. 5(b) by a factor of \(\approx 3\), the positional variances become aligned with those of Fig. 5(a), and \(\sigma_{D}\) is increased by a factor of \(\approx 13\) - in accordance with Proposition 1. We repeated the tests with this modified \(\hat{R}\), and indeed, the results were indistinguishable from the original OKF.

Proof of Proposition 1.: Recall that in this problem, the KF applies the update step using an estimated observation model \(\tilde{H}=H(\tilde{X})\):

\[\tilde{H}=\begin{pmatrix}1&1&&\\ &1&\\ &&1&\\ &&\tilde{x}_{x}/\tilde{r}&\tilde{x}_{y}/\tilde{r}&\tilde{x}_{z}/\tilde{r}\\ \end{pmatrix}.\]

Denoting the normalized estimation error \(dx^{\prime}=\frac{\tilde{x}}{\tilde{r}}-\frac{x}{r}\), we can rewrite \(\tilde{H}\) as

\[\tilde{H}=H+\begin{pmatrix}0&0&\\ &0&\\ &&dx^{\prime}_{x}&dx^{\prime}_{y}&dx^{\prime}_{z}\\ \end{pmatrix}.\]

By shifting the observation model in Eq. (1) from \(H\) to \(\tilde{H}\), and denoting the noise by \(\nu=(\nu_{x},\nu_{y},\nu_{z},\nu_{D})^{\top}\), we receive

\[Z= HX+\nu=\tilde{H}X+\begin{pmatrix}\nu_{x}\\ \nu_{y}\\ \nu_{D}-dx^{\prime}_{x}u_{x}-dx^{\prime}_{y}u_{y}-dx^{\prime}_{z}u_{z}\\ \end{pmatrix}=\tilde{H}X+\begin{pmatrix}\nu_{x}\\ \nu_{y}\\ \nu_{x}\\ \nu_{D}-dx^{\prime}\cdot u\\ \end{pmatrix},\]

where \(u\) denotes the current target velocity. We see that the effective observation noise is \(\tilde{\nu}=Z-\tilde{H}X=(\nu_{x},\nu_{y},\nu_{z},\nu_{D}-dx^{\prime}\cdot u)^ {\top}\).

To show that all the off-diagonal entries of \(\tilde{R}=Cov(\tilde{\nu})\) vanish, recall that the estimation error \(dx^{\prime}\) is assumed to be independent of the velocity \(u\). According to Eq. (1), \(\nu\) is also independent of \(u\). Hence, \(Cov(dx^{\prime}_{x}\cdot u_{x},\ \nu_{x})=E(dx^{\prime}_{x}\cdot u_{x}\cdot\nu_{x})=E (dx^{\prime}_{x}\nu_{x})E(u_{x})\) which vanishes by symmetry (\(E(u_{x})=0\)). The same result holds for coordinates \(y,z\). Thus, \(\tilde{R}\) is diagonal. Finally, by denoting \(C=Var(dx^{\prime}\cdot u)>0\) we have \(Cov(\tilde{\nu})=\tilde{R}\) as required.

Relying again on symmetry \(E(u),E(dx^{\prime})=0\), we can further calculate \(C=Var(dx^{\prime}\cdot u)=E(||dx^{\prime}||^{2})E(||u||^{2})=\Omega(E(||u||^{ 2}))\), where \(\Omega\) ("big-omega") corresponds to an asymptotic lower bound. 

### Non-i.i.d Noise

The assumption of i.i.d noise in Assumption 1 is violated in many practical scenarios. Certain models with non-i.i.d noise can be solved analytically, if modeled correctly. For example, if the noise is auto-regressive with a known order \(p\), an adjusted KF model may consider the last \(p\) values of the noise itself as part of the system state [Geist and Pietquin, 2011]. However, the actual noise model is often unknown or infeasible to solve analytically.

Furthermore, the violation of the i.i.d assumption may even go unnoticed. We discuss a potential example in Section 5, where the noise is i.i.d in _spherical_ coordinates - but is not so after the transformation to _Cartesian_ coordinates. To see that, consider a radar with noiseless angular estimation (i.e.,only radial noise), and a low target (\(x_{z}\approx 0\)). Clearly, most of the noise concentrates on the XY plane - both in the current time-step and in the following ones (until the target moves away from the plane). Hence, the noise is statistically-dependent over time-steps.

We may formalize this intuition for the toy Problem 2. Denote the system state at time \(t\) by \(X_{t}=((X_{t})_{1},(X_{t})_{2})^{\top}\), and denote \(\tan\theta_{t}=\frac{(X_{t})_{2}}{(X_{t})_{1}}\). By transforming \(R_{polar}\) of Problem 2 to Cartesian coordinates, the observation noise is drawn from the distribution \(\nu_{t}\sim\mathcal{N}(0,R(\theta_{t}))\), where

\[R(\theta)=\begin{pmatrix}r_{0}\cos^{2}(\theta)&r_{0}\cos(\theta)\sin(\theta)\\ r_{0}\cos(\theta)\sin(\theta)&r_{0}\sin^{2}(\theta)\end{pmatrix}. \tag{8}\]

Since consecutive time steps are likely to have similar values of \(\theta_{t}\), the noise \(\nu_{t}\) is no longer independent across time steps.

The effect of this violation of the i.i.d assumption is analyzed in Proposition 2, whose proof is provided below.

Proof of Proposition 2.: **Noise estimation:** First, notice that the whole setting of Problem 2 is invariant to the target direction \(\theta\): the initial state distribution is radial, and the motion noise \(Q\) is isotropic. Hence, for any target at any time-step, \(\theta_{t}\sim[0,2\pi)\) is uniformly distributed. By direct calculation,

\[E_{\theta}\left[\hat{R}_{N}(KF)_{11}\right] =E_{\theta}\left[r_{0}\cos^{2}\theta\right]=\int_{0}^{2\pi}\frac {r_{0}}{2\pi}\cos^{2}\theta d\theta=\frac{r_{0}}{2}\] \[E_{\theta}\left[\hat{R}_{N}(KF)_{22}\right] =E_{\theta}\left[r_{0}\sin^{2}\theta\right]=\int_{0}^{2\pi}\frac {r_{0}}{2\pi}\sin^{2}\theta d\theta=\frac{r_{0}}{2}\] \[E_{\theta}\left[\hat{R}_{N}(KF)_{12}\right] =E_{\theta}\left[\hat{R}_{N}(KF)_{21}\right]=E_{\theta}\left[r_{0} \cos\theta\sin\theta\right]=0.\]

Since the targets in the data are i.i.d, the noise estimation of Algorithm 1 converges almost surely according to the law of large numbers, as required:

\[\hat{R}_{N}(KF)\xrightarrow{\text{a.s.}}\hat{R}_{est}=\begin{pmatrix}r_{0}/2& 0\\ 0&r_{0}/2\end{pmatrix}.\]

**Optimization:** We use again the radial symmetry and invariance to rotations in the problem: w.l.o.g, we assume that the optimal noise covariance parameter is diagonal, i.e., \(\hat{R}_{opt}(r)=\left(\begin{smallmatrix}0&0\\ 0&r\end{smallmatrix}\right)\) for some \(r>0\). Our goal is to find \(r\), and in particular to compare it to \(r_{0}/2\).

At a certain time \(t\), where the system state is \(X_{t}\), denote \(E[X_{t}]=x_{0}=(x_{1},x_{2})^{\top}\) and \(Cov(X_{t})=P_{0}=\left(\begin{smallmatrix}p&0\\ 0&p\end{smallmatrix}\right)\) (where \(p>0\)). Denote the observation received at time \(t\) by \(z=(x_{1}+dx_{1},x_{2}+dx_{2})^{\top}\). We are interested in the point-estimate \(\hat{x}\) of the KF following the update step (Fig. 2). By substituting \(x_{0}\), \(P_{0}\), the observation \(z\) and the noise parameter \(\hat{R}_{opt}(r)\) in the update step, we have

\[\hat{x} =x_{0}+P_{0}H^{\top}(HP_{0}H^{\top}+\hat{R}_{opt}(r))^{-1}(z-Hx_ {0})=x_{0}+P_{0}(P_{0}+\hat{R}_{opt}(r))^{-1}(z-x_{0})\] \[=x_{0}+\begin{pmatrix}\frac{p}{p+r}&0\\ 0&\frac{p}{p+r}\end{pmatrix}\begin{pmatrix}dx_{1}\\ dx_{2}\end{pmatrix}=\begin{pmatrix}x_{1}+\frac{p}{p+r}dx_{1}\\ x_{2}+\frac{p}{p+r}dx_{2}\end{pmatrix}.\]

On the other hand, the _true_ observation noise covariance at time \(t\) is \(R(\theta_{t})\) of Eq. (8) (for the random variable \(\theta_{t}\)). If we add the assumption that the state \(X_{t}\) is normally distributed (\(X_{t}\sim\mathcal{N}(x_{0},P_{0})\)), and use the true noise covariance \(R(\theta_{t})\), then the update step of Fig. 2 gives us the true posterior expected state:

\[x_{true} =x_{0}+P_{0}(P_{0}+R(\theta_{t}))^{-1}(z-x_{0})\] \[=x_{0}+\begin{pmatrix}\frac{r_{0}\sin^{2}\theta+p}{p+r_{0}}&- \frac{r_{0}\cos\theta\sin\theta}{p+r_{0}}\\ -\frac{r_{0}\cos\theta\sin\theta}{p+r_{0}}&\frac{r_{0}\cos\theta+p}{p+r_{0}} \end{pmatrix}\begin{pmatrix}dx_{1}\\ dx_{2}\end{pmatrix}\] \[=\begin{pmatrix}x_{1}+\frac{(r_{0}\sin^{2}\theta+p)dx_{1}-(r_{0} \cos\theta\sin\theta)dx_{2}}{p+r_{0}}\\ x_{2}+\frac{(r_{0}\cos^{2}\theta+p)dx_{2}-(r_{0}\cos\theta\sin\theta)dx_{1}}{p +r_{0}}\end{pmatrix}.\]

[MISSING_PAGE_FAIL:17]

Assumption 1. The _Free Motion_ benchmark is intended to represent a realistic Doppler radar problem, with targets and observations simulated as in Section 4: each target trajectory consists of multiple segments of different turns and accelerations. On the other extreme, the _Toy_ benchmark (Problem 1) introduces multiple simplifications (as visualized in Fig. 5). In the Toy benchmark, the only violation of Assumption 1 is the non-linear observation \(H\), as discussed in Section 5.1. Note that Section 5.2 and Section 5.3 experiment with settings of a linear observation model.

We design 5 benchmarks within the spectrum of complexity between Toy and Free Motion. Each benchmark is defined as a subset of the following properties, as specified in Table 1 and visualized in Fig. 11:

* _anisotropic_: horizontal motion is more likely than vertical (otherwise direction is distributed uniformly).
* _polar_: radar noise is generated i.i.d in spherical coordinates (otherwise noise is Cartesian i.i.d).
* _uncentered_: targets are dispersed in different locations far from the radar (otherwise they are concentrated in the center).
* _acceleration_: speed change is allowed (through intervals of constant acceleration).
* _turns_: non-straight motion is allowed.

**Baselines (KF variants):** All the experiments above compare OKF to the standard KF baseline. In practice, other variants of the KF are often in use. Here we define 4 such variants as different baselines to the experiments. In each experiment, we compare the baseline tuned by Algorithm 1 to its Optimized version trained by Algorithm 2 (denoted with the prefix "O" in its name). For Algorithm 2, we use the Adam optimizer with a single training epoch over the 1500 training trajectories, 10 trajectories per training batch, and learning rate of 0.01. The optimization was run for all baselines in parallel and required a few minutes per benchmark, on eight i9-10900X CPU cores in a single Ubuntu machine.

The different baselines are designed as follows. _EKF_ baselines use the non-linear Extended KF model (Sorenson, 1985). The EKF replaces the approximation \(H\approx H(z)\) of Section 4 with \(H\approx\nabla_{x}h(\tilde{z})\), where \(h(x)=H(x)\cdot x\) and \(\tilde{x}\) is the current state estimate. _Polar_ baselines (denoted with "p") represent the observation noise \(R\) with spherical coordinates, in which the polar radar noise is i.i.d.

**Results:** Table 2 summarizes the test errors (MSE) in all the experiments. In each cell, the left column corresponds to the baseline Algorithm 1, and the right to Algorithm 2. In the model names,

\begin{table}
\begin{tabular}{|c|c c c c c|} \hline Benchmark & & & & & & \\ \hline Toy & O & O & O & O & O \\ Close & V & V & O & O & O \\ Const\_v & V & V & V & O & O \\ Const\_a & V & V & V & V & O \\ Free & V & V & V & V & V \\ \hline \end{tabular}
\end{table}
Table 1: Benchmarks and the properties that define them. “V” means that the benchmark satisfies the property.

Figure 11: Samples of targets trajectories in the various benchmarks, projected onto the XY plane.

[MISSING_PAGE_FAIL:19]

Since the best KF variant per benchmark seems hard to predict in advance, a practical system cannot rely on choosing the KF variant optimally - and should rather be robust to this choice.

**OKF is more accurate _and_ more baseline-robust:** For _every_ benchmark and _every_ baseline (20 experiments in total), OKF (right column) outperformed noise estimation (left column). In addition, the variance between the baselines reduces under optimization, i.e., OKF makes the KF more robust to the selected configuration.

**OKF outperforms an _oracle_ baseline:** We designed an "oracle" KF baseline - with perfect knowledge of the observation noise covariance \(R\) in spherical coordinates. We used it for all benchmarks except for Toy (in which the radar noise is not generated in spherical coordinates). Note that in the constant-speed benchmarks (Close and Const_v), \(Q=0\) and is estimated quite accurately; hence, in these benchmarks the oracle has a practically perfect knowledge of both noise covariances. Nevertheless, the oracle yields very similar results to Algorithm 1. This indicates that **the benefit of OKF is not in a better estimation accuracy of \(Q\) and \(R\), but rather in optimizing the desired objective**.

### Sensitivity to Train Dataset Size

Each benchmark in the case-study of Appendix B.1 has 1500 targets in its train data. One may argue that numeric optimization may be more sensitive to smaller datasets than noise estimation; and even more so, when taking into account that the optimization procedure "wastes" a portion of the train data as a validation set.

In this section we test this concern empirically, by repeating some of the experiments of Appendix B.1 with smaller subsets of the train datasets - beginning from as few as 20 training trajectories. Fig. 13 shows that the advantage of OKF over KF holds consistently for all sizes of train datasets, although it is indeed increases with the size. Interestingly, in the Free Motion benchmark, **the test errors of KF and KFp _increase_ with the amount of train data!**

### Generalization: Sensitivity to Distributional Shifts

In Appendix B.1, we demonstrate the robustness of OKF in different tracking scenarios: in every benchmark, OKF outperformed the standard KF over **out-of-sample test data**. This means that OKF did not overfit the noise in the training data. What about **out-of-distribution test data?** OKF learns patterns from the specific distribution of the train data - how well will it generalize to different distributions?

Section 4 already addresses this question to some extent, as OKF outperformes both KF and NKF over out-of-distribution target accelerations (affecting both speed changes and turns radius). In terms of Eq. (1), the modified acceleration corresponds to different magnitudes of motion noise \(Q\); that is, we change the noise _after_ OKF optimized the noise parameters. Yet, OKF adapted to the change without further optimization, with better accuracy than the standard KF. Thus, the results of Section 4 already provide a significant evidence for the robustness of OKF to certain distributional shifts.

In this section, we present a yet stronger evidence for the robustness of OKF - not over a parametric distributional shift, but over **entirely different benchmarks**. Specifically, we consider the 5

Figure 13: The advantage of OKF over KF holds consistently for all sizes of train datasets – including as small datasets as 20 trajectories. The shadowed areas correspond to 95% confidence intervals.

benchmarks (or scenarios) of Appendix B.1. For every pair (train-scenario, test-scenario), we train both KF and OKF on data of the train-scenario, then test them on data of the test-scenario. For every such pair of scenarios, we measure the generalization advantage of OKF over KF through \(MSE\_ratio=MSE(KF)/MSE(OKF)\) (where \(MSE\_ratio>1\) indicates advantage to OKF). To measure the total generalization advantage of a model trained on a certain scenario, we calculate the geometric mean of \(MSE\_ratio\) over all the test-scenarios (or equivalently, the standard mean over the logs of the ratios). The logarithmic scale guarantees a symmetric view of this metric of ratio between two scores.

This test is quite noisy, since a model optimized for a certain scenario may legitimately be inferior in other scenarios. Yet, considering all the results together in Fig. 14, it is evident that OKF provides more robust models: it generalizes better in most cases, sometimes by a large margin; and loses only in a few cases, always by a small margin.

### Ablation Test: Diagonal Optimization

The main challenge in Section 3 and Algorithm 2 is to apply standard numeric optimization while keeping the symmetric and positive-definite constraints (SPD) of the parameters \(Q,R\). To that end, we apply the Cholesky parameterization to \(Q\) and \(R\). In this section, we study the importance of this parameterization via an ablation test.

For the ablation, we define a naive version of OKF with a diagonal parameterization of \(Q\) and \(R\). Such parameterization is common in the literature: "since both the covariance matrices must be constrained to be positive semi-definite, \(Q\) and \(R\) are often parameterized as diagonal matrices" (Formentin and Bittanti, 2014). We denote the diagonal variant by \(DKF\), and test it on all 5 Doppler benchmarks of Appendix B.1.

Table 3 displays the results. In the first 3 benchmarks, where the target motion is linear, DKF is indistinguishable from OKF. However, in the 2 non-linear benchmarks (which are also the same benchmarks used in Section 4), DKF is inferior to OKF, though still outperforms the standard KF.

Figure 14: Generalization tests: OKF vs. KF under distributional shifts between scenarios.

### Video Tracking: Dataset License

The MOT20 video dataset [4] is available under _Creative Commons Attribution-NonCommercial-ShareAlike 3.0_ License. In Section 5.2, we used the videos MOT20-01, MOT20-02 and MOT20-03 for training, and MOT20-05 for testing.

### Lidar-based State Estimation: Visualization

Fig. 15 visualizes a sample of the simulated trajectories and the model predictions in the lidar-based state estimation of Section 5.3.

## Appendix C Neural KF: Extended Discussion and Experiments

**Preliminaries - RNN and LSTM:**_Recurrent neural networks_ (RNN) [12] are neural networks that are intended to be iteratively fed with sequential data samples, and that pass information (the _hidden state_) over iterations. Every iteration, the hidden state is fed to the next copy of the network as part of its input, along with the new data sample. _Long Short Term Memory_ (LSTM) [13] is an architecture of RNN that is particularly popular due to the linear flow of the hidden state over iterations, which allows to capture memory for relatively long term. The parameters of a RNN are usually optimized in a supervised manner with respect to a training dataset of input-output pairs.

**Neural Kalman Filter:** We introduce the Neural Kalman Filter (NKF), which incorporates an LSTM model into the KF framework. The framework provides a probabilistic representation (rather than point estimate) and a separation between the prediction and update steps. The LSTM is an architecture of recurrent neural networks, and is a key component in many SOTA algorithms for non-linear sequential prediction [20]. We use it for the non-linear motion prediction.

As shown in Fig. 16, NKF uses separate LSTM networks for prediction and update steps. In the prediction step, the target _acceleration_ is predicted on top of the linear motion model, instead of predicting the state directly. This regularized formulation is intended to express our domain knowledge about the kinematic motion of physical targets.

**Extended experiments:** We extend the experiments of Section 4 with additional versions of NKF:

* Predicted-acceleration KF (**aKF**): a variant of NKF that predicts the acceleration but not the covariances \(Q\) and \(R\).

Figure 15: (a) A sample of simulated self-driving trajectories. (b) Segments of turns within a sample trajectory, and the corresponding lidar-based estimations.

\begin{table}
\begin{tabular}{|c|c c c|} \hline Benchmark & KF & DKF & OKF \\ \hline Toy & 151.7 & 84.2 & 84.2 \\ Close & 25.0 & 24.8 & 24.8 \\ Const\_v & 90.2 & 90.1 & 90.0 \\ Const\_a & 107.5 & 106.1 & 101.6 \\ Free & 125.9 & 121.1 & 118.8 \\ \hline \end{tabular}
\end{table}
Table 3: Ablation test: Diagonal optimized KF, tested on the 5 benchmarks of Appendix B.1.

* Neural KF (**NKF**): the model used in Section 4 and illustrated in Fig. 16.
* Neural KF with H-prediction (**NKFH**): a variant of NKF that also predicts the observation model \(H\) in every step.

In addition, while we still train with MSE loss, we add the test metric of Negative-Log-Likelihood (NLL) - of the true state w.r.t the estimated distribution. Note that the NLL has an important role in the multi-target matching problem (which is out of the scope of this work).

For each benchmark and each model, we train the model on train data with a certain range of targets acceleration (note that acceleration affects both speed changes and turns sharpness), and tested it on targets with different acceleration ranges, some of them account for distributional shifts. For each model we train two variants - one with Cartesian representation of the observation noise \(R\), and one with spherical representation (as in the baselines of Appendix B.1) - and we select the one with the higher validation MSE (where the validation data is a portion of the data assigned for training).

Figure 16: The Neural Kalman Filter (NKF). Differences from Fig. 2 are highlighted. \(\Delta t\) is constant; \(G,Q\) are the outputs of an LSTM network with hidden state \(h_{a}\); and \(R\) is the output of an LSTM with hidden state \(h_{r}\).

Figure 17: The _relative_ MSE and NLL results of various models in comparison to the standard KF model. The textual labels specify the _absolute_ MSE and NLL. Note that certain bars of NLL are of entirely different scale and thus are cropped in the figure (their values can be seen in the labels). In each benchmark, the models were trained with relation to MSE loss, on train data of the middle acceleration-range: the two other acceleration ranges in each benchmark correspond to generalization over distributional shifts.

Fig. 17a shows that in the free-motion benchmark, all the 3 neural models improve the MSE in comparison to the standard KF, yet are outperformed by OKF. Furthermore, while OKF has the best NLL, the more complicated models NKF and NKFH increase the NLL in orders of magnitude. Note that the instability of NKFH is expressed in poor generalization to lower accelerations in addition to the extremely high NLL score.

Fig. 17b shows that in Const_a benchmark, all the 3 neural models improve the MSE in comparison to the standard KF, but only NKFH improves in comparison to OKF as well. On the other hand, NKFH still suffers from very high NLL.

In summary, all 3 variants of NKF outperform the standard KF in both benchmarks in terms of MSE. However, when comparing to OKF instead, aKF and NKF become inferior, and the comparison between NKFH and OKF depends on the selected benchmark and metric.