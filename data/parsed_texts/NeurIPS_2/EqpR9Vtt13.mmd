# Does Invariant Graph Learning via Environment Augmentation Learn Invariance?

Yongqiang Chen\({}^{1}\), Yatao Bian\({}^{2}\), Kaiwen Zhou\({}^{1}\)

\({}^{1}\)The Chinese University of Hong Kong \({}^{2}\)Tencent AI Lab

{yqchen,kwzhou}@cse.cuhk.eduhk yatao.bian@gmail.com

Binghui Xie\({}^{1}\), Bo Han\({}^{3}\), James Cheng\({}^{1}\)

\({}^{3}\)Hong Kong Baptist University

bhanm1@comp.hkbue.eduhk {bhxie21,jcheng}@cse.cuhk.eduhk

Work done during an internship at Tencent AI Lab.Code is available at [https://github.com/LFhase/GALA](https://github.com/LFhase/GALA).

###### Abstract

Invariant graph representation learning aims to learn the invariance among data from different environments for out-of-distribution generalization on graphs. As the graph environment partitions are usually expensive to obtain, augmenting the environment information has become the _de facto_ approach. However, the _usefulness_ of the augmented environment information has never been verified. In this work, we find that it is fundamentally _impossible_ to learn invariant graph representations via environment augmentation without additional assumptions. Therefore, we develop a set of _minimal assumptions_, including variation sufficiency and variation consistency, for feasible invariant graph learning. We then propose a new framework **G**raph inv**A**riant **L**earning **A**ssistant (GALA). GALA incorporates an assistant model that needs to be sensitive to graph environment changes or distribution shifts. The correctness of the proxy predictions by the assistant model hence can differentiate the variations in spurious subgraphs. We show that extracting the maximally invariant subgraph to the proxy predictions provably identifies the underlying invariant subgraph for successful OOD generalization under the established minimal assumptions. Extensive experiments on \(12\) datasets including DrugOOD with various graph distribution shifts confirm the effectiveness of GALA1.

Footnote 1: Code is available at [https://github.com/LFhase/GALA](https://github.com/LFhase/GALA).

## 1 Introduction

Graph representation learning with graph neural networks (GNNs) has proven to be highly successful in tasks involving relational information [24, 35, 68, 74, 75]. However, it assumes that the training and test graphs are independently drawn from the identical distribution (iid.), which can hardly hold for many graph applications such as in Social Network, and Drug Discovery [25, 26, 37, 70, 86, 94]. The performance of GNNs could be seriously degenerated by _graph distribution shifts_, i.e., mismatches between the training and test graph distributions caused by some underlying environmental factors during the graph data collection process [16, 21, 28, 70, 87, 94]. To overcome the Out-of-Distribution (OOD) generalization failure, recently there has been a growing surge of interest in incorporating the invariance principle from causality [60] into GNNs [8, 17, 41, 45, 55, 72, 73, 77, 73]. The rationale of the invariant graph learning approaches is to identify the underlying _invariant subgraph_ of the input graph, which shares an invariant correlation with the target labels across multiple graphdistributions from different environments [8, 72]. Thus, the predictions made merely based on the invariant subgraphs can be generalized to OOD graphs that come from a new environment [60].

As the environment labels or partitions on graphs are often expensive to obtain [8], augmenting the environment information, such as generating new environments [45, 72, 73] and inferring the environment labels [41, 77], has become the _de facto_ approach for invariant graph learning. However, little attention has been paid to verifying the _fidelity_ (or _faithfulness_2) of the augmented environment information. For example, if the generated environments or inferred environment labels induce a higher bias or noise, it would make the learning of graph invariance even harder. Although it looks appealing to _learn both_ the environment information and the graph invariance, the existing approaches could easily run into the "no free lunch" dilemma [71]. In fact, Lin et al. [43] found that there exist negative cases in the Euclidean regime where it is impossible to identify the invariant features without environment partitions. When it comes to the graph regime where the OOD generalization is fundamentally more difficult [8] than the Euclidean regime, it raises a challenging research question:

Footnote 2: The _fidelity_ or _faithfulness_ refers to whether the augmented environment information can actually improve the OOD generalization on graphs.

_When and how could one learn graph invariance without the environment labels?_

In this work, we present a theoretical investigation of the problem and seek a set of _minimal assumptions_ on the underlying environments for feasible invariant graph learning. Based on a family of simple graph examples (Def. 3.1), we show that existing environment generation approaches can fail to generate faithful environments, when the underlying environments are not sufficient to uncover all the variations of the spurious subgraphs (Prop. 3.2). On the contrary, incorporating the generated environments can even lead to a worse OOD performance. The failure of faithful environment generation implies the necessity of _variation sufficiency_ (Assumption 3.3). Moreover, even with sufficient environments, inferring faithful environment labels remains impossible. Since invariant and spurious subgraphs can have an arbitrary degree of correlation with labels, there exist multiple sets of training environments that have the same joint distribution of \(P(G,Y)\) but different invariant subgraphs. Any invariant graph learning algorithms will inevitably fail to identify the invariant subgraph in at least one set of training environments (Prop. 3.4). Therefore, we need to additionally ensure the _variation consistency_ (Assumption 3.5), that is, the invariant and spurious subgraphs should have a consistent relationship in the correlation strengths with the labels.

To resolve the OOD generalization challenge under the established assumptions, we propose a new framework **G**raph inv**A**riant **L**earning **A**ssistant (GALA). GALA incorporates an additional assistant model that needs to be prone to distribution shifts, to generate proxy predictions of the training samples. Different from previous environment inferring approaches [41, 77], GALA does not require explicit environment labels but merely proxy predictions to differentiate the variations in the spurious

Figure 1: An illustration of GALA with the task of classifying graphs according to whether there exists a “House” or “Cycle” motif. Given the training data where the “House” subgraph often co-occurs with a “Grid” and the “Cycle” subgraph often co-occurs with a “Hexagon”. An ERM trained environment assistant model will fit the spurious subgraph and therefore yield proxy predictions “House” or “Cycle” for any graphs containing a “Grid” (left half) or “Hexagon” (right half), respectively. GALA first separates the samples according to the correctness of the proxy predictions into the sets of positive graphs \(\{G^{p}\}\) (correct, in blue) and negative graphs \(\{G^{n}\}\) (incorrect, in green). Then, GALA extracts the maximally invariant subgraph among \(\{G^{p}\}\) and \(\{G^{n}\}\), i.e., pulling graphs with the same graph label but from \(\{G^{p}\}\) and \(\{G^{n}\}\) closer in the latent space, hence identifies the invariant subgraph.

subgraphs. As shown in Fig. 1, we first fit an environment assistant model to the training distribution and then divide the training graphs into a positive set \(\{G^{p}\}\) and a negative \(\{G^{n}\}\), according to whether the proxy predictions are correct or not, respectively. As spurious correlations tend to vary more easily than invariant correlations, the variations in spurious subgraphs are further differentiated and increased between \(\{G^{p}\}\) and \(\{G^{n}\}\). Then, only the invariant subgraph holds an invariant correlation with the label among \(\{G^{p}\}\) and \(\{G^{n}\}\), and hence can be identified by extracting the subgraphs that maximize the intra-class subgraph mutual information among \(\{G^{p}\}\) and \(\{G^{n}\}\) (Theorem 4.1).

We conduct extensive experiments to validate the effectiveness of GALA using \(12\) datasets with various graph distribution shifts. Notably, GALA brings improvements up to \(30\%\) in multiple graph datasets.

Our contributions can be summarized as follows:

* We identify failure cases of existing invariant graph learning approaches and establish the minimal assumptions for feasible invariant graph learning;
* We develop a novel framework GALA with provable identifiability of the invariant subgraph for OOD generalization on graphs under the assumptions;
* We conduct extensive experiments to verify both our theoretical results and the superiority of GALA;

Notably, both our theory and solution differ from Lin et al. [43] fundamentally, as we do not rely on the auxiliary information and are compatible with the existing interpretable and generalizable GNN architecture for OOD generalization on graphs. Meanwhile, we provide a new theoretical framework that resolves the counterexample in Lin et al. [43] while enjoying provable identifiability.

## 2 Background and Preliminaries

We begin by introducing the key concepts and backgrounds of invariant graph learning, and leave more details in Appendix C. The notations used in the paper are given in Appendix A.

OOD generalization on graphs.

This work focuses on graph classification, while the results generalize to node classification as well using the same setting as in Wu et al. [72]. Specifically, we are given a set of graph datasets \(\mathcal{D}=\{\mathcal{D}_{e}\}_{e\in\mathcal{E}_{\text{all}}}\) collected from multiple environments \(\mathcal{E}_{\text{all}}\). Samples \((G^{e}_{i},Y^{e}_{i})\in\mathcal{D}^{e}\) from the environment \(e\) are drawn independently from an identical distribution \(\mathbb{P}^{e}\). The goal of OOD generalization on graphs is to find a GNN \(f\) that minimizes the maximal loss among all environments, i.e., to minimize \(\max_{e\in\mathcal{E}_{\text{all}}}R^{e}\), where \(R^{e}\) is the risk of \(f\) under environment \(e\). We consider the same graph generation process proposed by Chen et al. [8] which is inspired by real-world drug discovery task [57] and covers a broad case of graph distribution shifts. As shown in Fig. 2, the generation of the observed graphs \(G\) and labels \(Y\) are controlled by a latent causal variable \(C\) and a spurious variable \(S\). \(C\) and \(S\) control \(Y\) and \(G\) by controlling the generation of the underlying invariant subgraph \(G_{c}\) and spurious subgraph \(G_{s}\), respectively. Since \(S\) can be affected by the environment \(E\), the correlation between \(Y\) and \(G_{s}\) can change arbitrarily when the environment changes. Besides, the interaction among \(C\), \(S\) and \(Y\) at the latent space can be further categorized into _Full Informative Invariant Features_ (_PIIF_) when \(Y\perp S|C\), and _Partially Informative Invariant Features_ (_PIIF_) when \(Y\perp S|C\).

To tackle the OOD generalization challenge on graphs from Fig. 2, the existing invariant graph learning approaches are generically designed to identify the underlying invariant subgraph \(G_{c}\) to predict the label \(Y\)[72, 8]. Specifically, the goal of OOD generalization on graphs is to learn an _invariant GNN_\(f\coloneqq f_{c}\circ g\), which is composed of: a) a featurizer \(g:\mathcal{G}\rightarrow\mathcal{G}_{c}\) that estimates the invariant subgraph \(\widehat{G}_{c}\); b) a classifier \(f_{c}:\mathcal{G}_{c}\rightarrow\mathcal{Y}\) that predicts the label \(Y\) based on the extracted \(\widehat{G}_{c}\), where \(\mathcal{G}_{c}\) refers to the space of subgraphs of \(\mathcal{G}\). The learning objectives of \(f_{c}\) and \(g\) are formulated as

\[\max_{f_{c},~{}g}I(\widehat{G}_{c};Y),~{}\text{s.t.}~{}\widehat{G}_{c}\perp E,~{}\widehat{G}_{c}=g(G). \tag{1}\]

Since \(E\) is not observed, many strategies are proposed to impose the independence of \(\widehat{G}_{c}\) and \(E\). A prevalent approach is to augment the environment information. Based on the estimated invariant

Figure 2: SCMs on graph distribution shifts [8].

subgraphs \(\widehat{G}_{c}\) and spurious subgraphs \(\widehat{G}_{s}\), Liu et al. [45], Wu et al. [72; 73] propose to generate new environments, while Li et al. [41], Yang et al. [77] propose to infer the underlying environment labels. However, we show that they all fail to augment faithful environment information in Sec. 3.

Besides, Miao et al. [55; 56], Yu et al. [81; 82; 83] adopt graph information bottleneck to tackle FIFF graph shifts, but they cannot generalize to PIIF shifts, while Our work focuses on PIIF shifts as it is more challenging when without environment labels [43]. Fan et al. [17] generalize [40] to tackle severe graph biases, i.e., when \(H(S|Y)<H(C|Y)\). Chen et al. [8] propose a contrastive framework to tackle both FIFF and PIFF graph shifts, but is limited to \(H(S|Y)>H(C|Y)\). In practice, as it is usually unknown which correlation is stronger, we need a unified solution to tackle both cases.

**Invariant learning without environment labels.** In the Euclidean regime, there are plentiful studies in invariant learning without environment labels. Creager et al. [12] propose a minmax formulation to infer the environment labels. Liu et al. [46] propose a self-boosting framework based on the estimated invariant and variant features. Deng et al. [14], Liu et al. [44], Pezeshki et al. [61], Zhang et al. [85] propose to infer labels based on the failures of an ERM model. However, Lin et al. [43] find failure cases of the aforementioned approaches that it is impossible to identify the invariant features without given environment labels in Euclidean data, and propose a solution that leverages auxiliary environment information for invariant learning. As the OOD generalization on graphs poses more challenges [8], whether it is feasible to learn invariant graph representations without any auxiliary environment information remains elusive.

## 3 Pitfalls of Environment Augmentation

Given only the mixed training data without environment partitions, is it possible to learn to generate faithful environments or infer the underlying environment labels that facilitate OOD generalization on graphs? In the discussion below, we adopt the two-piece graphs to instantiate the problem, which is the simplistic version of the PIIF distribution shifts in Fig. 2(c), motivated by Kamath et al. [30].

**Definition 3.1** (Two-piece graphs).: _Each environment \(e\) is defined with two parameters, \(\alpha_{e},\beta_{e}\in[0,1]\), and the dataset \((G^{e},Y^{e})\in\mathcal{D}_{c}\) is generated as follows:_

1. _[label=()]_
2. _Sample_ \(Y^{e}\in\{-1,1\}\) _uniformly;_
3. _Generate_ \(G_{c}\) _and_ \(G_{s}\) _via :_ \(G_{c}\coloneqq f^{G_{e}}_{\text{gen}}(Y^{e}\cdot\text{Rad}(\alpha_{e})),\ G_{s} \coloneqq f^{G_{s}}_{\text{gen}}(Y^{e}\cdot\text{Rad}(\beta_{e})),\) _where_ \(f^{G_{e}}_{\text{gen}},f^{G_{s}}_{\text{gen}}\) _map the input_ \(\{-1,1\}\) _to a corresponding graph selected from a given set, and_ \(\text{Rad}(\alpha)\) _is a random variable taking value_ \(-1\) _with probability_ \(\alpha\) _and_ \(+1\) _with_ \(1-\alpha\)_;_
4. _Synthesize_ \(G^{e}\) _by randomly assembling_ \(G_{c}\) _and_ \(G_{s}\)_:_ \(G^{e}\coloneqq f^{G}_{\text{gen}}(G_{c},G_{s})\)_._

We denote an environment \(e\) with \((\alpha,\beta_{e})\) for simplicity. Different environments will have a different \(\beta_{e}\), thus \(P(Y|G_{s})\) will change across different environments, while \(P(Y|G_{c})\) remains invariant.

### Pitfalls of environment generation

We begin by discussing the cases where there are few environments, and generating new environments is necessary [72; 73; 45]. Environment generation aims to provide some additional "virtual" environments \(\mathcal{E}_{v}\) such that the invariant subgraph can be identified via applying an OOD risk to the joint dataset with the augmented data \(\mathcal{D}^{v}_{\text{tr}}=\{\mathcal{D}_{e}|e\in\mathcal{E}_{v}\cup \mathcal{E}_{v}\}\).

The generation of "virtual" environments is primarily based on the intermediate estimation of the invariant and spurious subgraphs, denoted as \(\widehat{G}_{c}\) and \(\widehat{G}_{s}\), respectively. Liu et al. [45], Wu et al. [73] propose DIR and GREA to construct new graphs by assembling \(\widehat{G}_{c}\) and \(\widehat{G}_{s}\) from different graphs. Specifically, given \(n\) samples \(\{G^{i},Y^{i}\}_{n=1}^{n}\)3 the new graph samples in \(\mathcal{E}_{v}\) is generated as follows:

Footnote 3: We slightly abuse the superscript and subscript when denoting the \(i\)th sample to avoid confusion of double superscripts or subscripts.

\[G^{i,j}=f^{G}_{\text{gen}}(\widehat{G}_{c}^{i},\widehat{G}_{s}^{j}),\ \forall i,j\in\{1...n\},\ Y^{i,j}=Y^{i},\]

which generates a new environment \(\mathcal{E}_{v}\) with \(n^{2}\) samples. Although both DIR and GREA gain some empirical success, the faithfulness of \(\mathcal{E}_{v}\) remains questionable, as the generation is merely based on _inaccurate_ estimations of the invariant and spurious subgraphs. Specifically, when \(\widehat{G}_{c}\) contains parts of \(G_{s}\), assigning the same labels to the generated graph is more likely to _strengthen_ the spurious correlation between \(G_{s}\) and \(Y\). For example, when the model yields a reversed estimation, i.e., \(\widehat{G}_{c}=G_{s}\) and \(\widehat{G}_{s}=G_{c}\), the generated environment will destroy the invariant correlations.

**Proposition 3.2**.: _Consider the two-piece graph dataset \(\mathcal{E}_{\text{tr}}=\{(\alpha,\beta_{1}),(\alpha,\beta_{2})\}\) with \(\alpha\geq\beta_{1},\beta_{2}\) (e.g., \(\mathcal{E}_{\text{tr}}=\{(0.25,0.1),(0.25,0.2)\}\)), and its corresponding mixed environment \(\mathcal{E}_{\text{tr}}^{\text{mix}}=\{(\alpha,(\beta_{1}+\beta_{2})/2)\}\) (e.g., \(\mathcal{E}_{\text{tr}}^{\text{mix}}=\{(0.25,0.15)\}\)). When \(\widehat{G}_{c}=G_{s}\) and \(\widehat{G}_{s}=G_{c}\), it holds that the augmented environment \(\mathcal{E}_{v}\) is also a two-piece graph dataset with_

\[\mathcal{E}_{v}=\{(0.5,(\beta_{1}+\beta_{2})/2)\}\text{ (e.g., }\mathcal{E}_{v}=\{(0.5,0.15)\}\}.\]

The proof is given in Appendix E.1. This also extends to the adversarial augmentation [72; 83], which will destroy the actual \(\widehat{G}_{c}\). As both DIR and GREA adopt the same environment generation procedure, we verify the failures of environment generation with GREA in Table 2 of Sec. 5, where GREA can perform comparably with ERM. In fact, when the underlying environments are insufficient to differentiate the variations of the spurious features, it is fundamentally impossible to identify the underlying invariant graph from the spurious subgraph. More formally, if \(\exists G_{s}\), such that \(P^{e_{1}}(Y|G_{s})=P^{e_{2}}(Y|G_{s})\) for any \(e_{1},e_{2}\in\mathcal{E}_{\text{tr}}\), where \(P^{e}(Y|G_{s})\) is the conditional distribution \(P(Y|G_{s})\) under environment \(e\in\mathcal{E}_{\text{all}}\), it is impossible for any graph learning algorithm to identify \(G_{c}\). We provide a formal discussion in Appendix E.2. The failure implies a fundamental requirement that \(\mathcal{E}_{\text{tr}}\) should uncover all the potential variations in the spurious subgraph.

**Assumption 3.3**.: _(Variation sufficiency) For graphs generated following Fig. 2, for any \(G_{s}\), \(\exists e_{1},e_{2}\in\mathcal{E}_{\text{tr}}\), such that \(P^{e_{1}}(Y|G_{s})\neq P^{e_{2}}(Y|G_{s})\), and \(P^{e_{1}}(Y|G_{c})=P^{e_{2}}(Y|G_{c})\)._

Assumption 3.3 aligns with the definition of invariance [8; 30] that the invariant subgraph \(G_{c}\) is expected to satisfy \(P^{e_{1}}(Y|G_{c})=P^{e_{2}}(Y|G_{c})\) for \(e_{1},e_{2}\in\mathcal{E}_{\text{all}}\). If there exists \(G_{s}\) satisfying the invariance condition as well, then it is impossible to tell \(G_{c}\) from \(G_{s}\) even with environment labels.

### Pitfalls of environment inferring

Although environment sufficiency (Assumption 3.3) relieves the need for generating new environments, is it possible to infer the underlying environment labels via approaches such as MoleOOD[77] and GIL[41], to facilitate invariant graph learning? Unfortunately, we find a negative answer.

Considering the two-piece graph examples \(\mathcal{E}_{\text{tr}}=\{(0.2,0.1),(0.2,0.3)\}\), when given the underlying environment labels, it is easy to identify the invariant subgraphs from spurious subgraphs. However, when the environment labels are not available, we have the mixed data as \(\mathcal{E}_{\text{tr}}=\{(0.2,0.2)\}\), where \(P(Y|G_{c})=P(Y|G_{s})\). The identifiability of \(G_{s}\) is _ill-posed_, as it does not affect the \(\mathcal{E}_{\text{tr}}\) even if we swap \(G_{c}\) and \(G_{s}\). More formally, considering the environment mixed from two two-piece graph environments \(\{(\alpha,\beta_{1})\}\) and \(\{(\alpha,\beta_{2})\}\), then we have \(\mathcal{E}_{\text{tr}}=\{(\alpha,(\beta_{1}+\beta_{2})/2\}\). For each \(\mathcal{E}_{\text{tr}}\), we can also find a corresponding \(\mathcal{E}_{\text{tr}}^{\prime}=\{((\beta_{1}^{\prime}+\beta_{1}^{\prime})/2,\alpha^{\prime})\}\) with \(\{(\beta_{1}^{\prime},\alpha^{\prime})\}\) and \(\{(\beta_{2}^{\prime},\alpha^{\prime})\}\). Then, let

\[\alpha=(\beta_{1}^{\prime}+\beta_{1}^{\prime})/2=\alpha^{\prime}=(\beta_{1}+ \beta_{2})/2. \tag{2}\]

We now obtain \(\mathcal{E}_{\text{tr}}\) and \(\mathcal{E}_{\text{tr}}^{\prime}\) which share the same joint distribution \(P(Y,G)\) while the underlying \(G_{c}\) is completely different. More generally, we have the following proposition.

**Proposition 3.4**.: _There exist \(2\) two-piece graph training environments \(\mathcal{E}_{\text{tr}}\) and \(\mathcal{E}_{\text{tr}}^{\prime}\) that share the same joint distribution \(P(Y,G)\). Any learning algorithm will fail in either \(\mathcal{E}_{\text{tr}}\) or \(\mathcal{E}_{\text{tr}}^{\prime}\)._

The proof is given in Appendix E.3. The experiments in Sec. 5 validate that both MoleOOD and GIL fail to infer faithful environment labels and even underperform ERM. It implies that whenever it allows the existence of an identical training distribution by mixing the environments, invariant graph learning is impossible. Therefore, we need an additional assumption that excludes the unidentifiable case. We propose to constrain the relationship between \(\alpha\) (i.e., \(H(Y|G_{c})\) ) and \(\beta_{c}\) (i.e., \(H(Y|G_{s})\)).

**Assumption 3.5**.: _(Variation consistency) For all environments in \(\mathcal{E}_{\text{tr}}\), \(H(C|Y)\neq H(S|Y)\)._

Intuitively, Assumption 3.5 imposes the consistency requirement on the correlation strengths between invariant and spurious subgraphs with labels. For two-piece graphs with consistent variations, mixing up the environments will yield a new environment with the same variation strength relationships.

Thus, Assumption 3.5 gets rid of the previous unidentifiable cases. Moreover, Assumption 3.5 also aligns with many realistic cases. For example, the relation of a specific functional group (e.g., -OH) with a molecule can hardly be reversed to that held upon the scaffold of the molecule, due to the data collection process. Therefore, Assumption 3.5 also resolves the counterexample proposed by Lin et al. [43]. Different from our work, Lin et al. [43] propose to incorporate additional auxiliary information that satisfies certain requirements to mitigate the unidentifiable case. However, such auxiliary information is often unavailable and expensive to obtain on graphs. More importantly, the requirements are also unverifiable without more assumptions, which motivates us to consider the relaxed case implied by Assumption 3.5.

### Challenges of environment augmentation

To summarize, the two assumptions constitute the minimal assumptions for feasible invariant graph learning. Failing to satisfy either one of them while lacking additional inductive biases will result in the "no free lunch" dilemma [71] and suffer from the unidentifiability issue.

**Corollary 3.6**.: _(No Free Graph OOD Lunch) Without Assumption 3.3 or Assumption 3.5, there does not exist a learning algorithm that captures the invariance of the two-piece graph environments._

Corollary 3.6 is a natural conclusion from the previous discussion. The proof is straightforward and given in Appendix E.4. Assumption 3.3 and Assumption 3.5 establish the minimal premises for identifying the underlying invariant subgraphs. However, it also raises new challenges, as shown in Table. 1. Chen et al. [8] propose CIGA to maximize the intra-class mutual information of the estimated invariant subgraphs to tackle the case when \(H(C|Y)<H(S|Y)\). While for the case when \(H(S|Y)<H(C|Y)\), Fan et al. [17] propose DisC that adopts GCE loss [40] to extract the spurious subgraph with a larger learning step size such that the left subgraph is invariant. However, both of them can fail when there is no prior knowledge about the relations between \(H(C|Y)\) and \(H(S|Y)\). We verify the failures of DisC and CIGA in Table. 2. The failure thus raises a challenging question:

_Given the established minimal assumptions, is there a unified framework that tackles both cases when \(H(C|Y)<H(S|Y)\) and \(H(C|Y)>H(S|Y)\)?_

## 4 Learning Invariant Graph Representations with Environment Assistant

We give an affirmative answer by proposing a new framework, GALA: Graph invAriant Learning Assistant, which adopts an assistant model to provide proxy information about the environments.

### Learning with An Environment Assistant

Intuitively, a straightforward approach to tackle the aforementioned challenge is to extend the framework of either DisC [17] or CIGA [8] to resolve the other case. As DisC always destroys the first learned features and tends to be more difficult to extend (which is empirically verified in Sec. 5), we are motivated to extend the framework of CIGA to resolve the case when \(H(S|Y)<H(C|Y)\).

**Understanding the success and failure of CIGA.** The principle of CIGA lies in maximizing the intra-class mutual information of the estimated invariant subgraphs, i.e.,

\[\max_{f_{c},g}\;I(\widehat{G}_{c};Y),\;\text{s.t.}\;\widehat{G}_{c}\in\operatorname {arg\,max}_{\widehat{G}_{c}=g(G),|\widehat{G}_{c}|\leq s_{c}}I(\widehat{G}_{c };\widehat{G}_{c}^{s}|Y), \tag{3}\]

where \(\widehat{G}_{c}^{s}=g(G^{s})\) and \(G^{s}\sim\mathbb{P}(G|Y)\), i.e., \(\widehat{G}\) is sampled from training graphs that share the same label \(Y\) as \(\widehat{G}\). The key reason for the success of Eq. 3 is that, given the data generation process as in Fig. 2 and the same \(C\), the underlying invariant subgraph \(G_{c}\) maximizes the mutual information of subgraphs from any two environments, i.e., \(\forall e_{1},e_{2}\in\mathcal{E}_{\text{all}}\),

\[G_{c}^{e_{1}}\in\operatorname{arg\,max}_{\widehat{G}_{c}^{e_{1}}}\;I( \widehat{G}_{c}^{e_{1}};\widehat{G}_{c}^{e_{2}}|C), \tag{4}\]

\begin{table}
\begin{tabular}{c|c|c} \hline  & \(H(S|Y)<H(C|Y)\) & \(H(S|Y)>H(C|Y)\) \\ \hline DisC & ✓ & ✗ \\ \hline CIGA & ✗ & ✓ \\ \hline GALA (Ours) & ✓ & ✓ \\ \hline \end{tabular}
\end{table}
Table 1: Remaining challenges of invariant graph learning: no existing works can handle both cases.

where \(\widehat{G}_{c}^{e_{1}}\) and \(\widehat{G}_{c}^{e_{2}}\) are the estimated invariant subgraphs corresponding to the same latent causal variable \(C=c\) under the environments \(e_{1},e_{2}\), respectively. Since \(C\) is not observable, CIGA adopts \(Y\) as a proxy for \(C\), as when \(H(S|Y)>H(C|Y)\), \(G_{c}\) maximizes \(I(\widehat{G}_{c}^{e_{1}};\widehat{G}_{c}^{e_{2}}|Y)\) and thus \(I(\widehat{G}_{c};\widehat{G}_{c}^{s}|Y)\). However, when \(H(S|Y)<H(C|Y)\), the proxy no longer holds. Given the absence of \(E\), simply maximizing intra-class mutual information favors the spurious subgraph \(G_{s}\) instead, i.e.,

\[G_{s}\in\arg\max_{\widehat{G}_{c}}(I(\widehat{G}_{c};\widehat{G}_{c}^{s}|Y). \tag{5}\]

**Invalidating spuriousness dominance.** To mitigate the issue, we are motivated to find a new proxy that samples \(\widehat{G}_{c}\) for Eq. 5, while preserving only the \(G_{c}\) as the solution under both cases.

To begin with, we consider the case of \(H(S|Y)<H(C|Y)\). Although the correlation between \(G_{s}\) and \(Y\) dominates the intra-class mutual information, Assumption 3.3 implies that there exists a subset of training data where \(P(Y|G_{s})\) varies, while \(P(Y|G_{c})\) remains invariant. Therefore, the dominance of spurious correlations no longer holds for samples from the subset. Incorporating samples from the subset into Eq. 3 as \(\widehat{G}_{c}^{s}\) invalidates the dominance of \(G_{s}\). Denote the subset as \(\{\widehat{G}_{c}^{n}\}\), then

\[G_{c}\in\arg\max_{\widehat{G}_{c}^{p}}I(\widehat{G}_{c}^{p};\widehat{G}_{c}^{n }|Y), \tag{6}\]

where \(\widehat{G}_{c}^{p}\in\{\widehat{G}_{c}^{p}\}\) is sampled from the subset \(\{\widehat{G}_{c}^{p}\}\) dominated by spurious correlations, while \(\widehat{G}_{c}^{n}\in\{\widehat{G}_{c}^{n}\}\) is sampled from the subset \(\{\widehat{G}_{c}^{n}\}\) where spurious correlation no long dominates, or is dominated by invariant correlations. We prove the effectiveness of Eq. 6 in Theorem 4.1.

**Environment assistant model \(A\).** To find the desired subsets \(\{\widehat{G}_{c}^{p}\}\) and \(\{\widehat{G}_{c}^{n}\}\), inspired by the success in tackling spuriousness-dominated OOD generalization via learning from a biased predictors [40, 44, 58, 85], we propose to incorporate an assistant model \(A\) that is prone to spurious correlations. Simply training \(A\) with ERM using the spuriousness-dominated data enables \(A\) to learn spurious correlations, and hence identifies the subsets where the spurious correlations hold or shift, according to whether the predictions of \(A\) are correct or not, respectively. Let \(A=\arg\max_{\widehat{A}}I(\widehat{A}(G);Y)\), we have

\[\{\widehat{G}_{c}^{p}\}=\{g(G_{i}^{p})|A(G_{i}^{p})=Y_{i}\},\;\{\widehat{G}_{c }^{n}\}=\{g(G_{i}^{n})|A(G_{i}^{n})\neq Y_{i}\}. \tag{7}\]

**Reducing to invariance dominance case.** After showing that Eq. 6 resolves the spuriousness dominance case, we still need to show that Eq. 6 preserves \(G_{c}\) as the only solution when \(H(S|Y)>H(C|Y)\). Considering training \(A\) with ERM using the invariance-dominated data, \(A\) will learn both invariant correlations and spurious correlations [10, 17]. Therefore, \(\{\widehat{G}_{c}^{n}\}\) switches to the subset that is dominated by spurious correlations, while \(\{\widehat{G}_{c}^{p}\}\) switches to the subset dominated by invariant correlations. Then, Eq. 6 establishes a lower bound for the intra-class mutual information, i.e.,

\[I(\widehat{G}_{c}^{p};\widehat{G}_{c}^{n}|Y)\leq I(\widehat{G}_{c};\widehat{G} _{c}^{s}|Y), \tag{8}\]

where \(\widehat{G}_{c}^{p}\in\{\widehat{G}_{c}^{p}\},\widehat{G}_{c}^{n}\in\{\widehat {G}_{c}^{n}\}\), and \(\widehat{G}_{c},\widehat{G}_{c}^{s}\) are the same as in Eq. 3. The inequality in Eq. 8 holds as any subgraph maximizes the left hand side can also be incorporated in right hand side, while the sampling space of \(\widehat{G}_{c}\) and \(\widehat{G}_{c}^{s}\) in the right hand side (i.e., both \(\widehat{G}_{c}\) and \(\widehat{G}_{c}^{s}\) are sampled from the whole train set) is larger than that of the left hand side. The equality is achieved by taking the ground truth \(G_{c}\) as the solution for the featurizer \(g\). We verify the correctness of Eq. 6 and Eq. 8 in Fig. 3(a).

### Practical implementations.

The detailed algorithm description of GALA is shown as in Algorithm 1. In practice, the environment assistant can have multiple implementation choices so long as it is prone to distribution shifts. As discussed in Sec. 4.1, ERM trained model can serve as a reliable environment assistant, since ERM tends to learn the dominant features no matter whether the features are invariant or spurious. For example, when \(H(S|Y)<H(C|Y)\), ERM will first learn to use spurious subgraphs \(G_{s}\) to make predictions. Therefore, we can obtain \(\{G^{p}\}\) by finding samples where ERM correctly predicts the labels, and \(\{G^{n}\}\) for samples where ERM predicts incorrect labels. In addition to label predictions, the clustering predictions of the hidden representations yielded by environment assistant models can also be used for sampling \(\{G^{p}\}\) and \(\{G^{n}\}\)[85]. Besides, we can also incorporate models that are easier to overfit to the first dominant features to better differentiate \(\{G^{p}\}\) from \(\{G^{n}\}\). When the number of positive or negative samples is imbalanced, we can upsample the minor group to avoid trivial solutions. In addition, the final GALA objective is given in Eq. 9 and implemented as in Eq. 18. We provide more discussions about the implementation options in Appendix F.

### Theoretical analysis

In the following theorem, we show that the GALA objective derived in Sec. 4.1 can identify the underlying invariant subgraph and yields an invariant GNN defined in Sec. 2.

**Theorem 4.1**.: _Given i) the same data generation process as in Fig. 2; ii) \(\mathcal{D}_{\mathrm{tr}}\) that satisfies variation sufficiency (Assumption 3.3) and variation consistency (Assumption 3.5); iii) \(\{G^{p}\}\) and \(\{G^{n}\}\) are distinct subsets of \(\mathcal{D}_{\mathrm{tr}}\) such that \(I(G^{p}_{s};G^{n}_{s}|Y)=0\), \(\forall G^{p}_{s}=\arg\max_{\tilde{G}^{p}_{s}}I(\tilde{G}^{p}_{s};Y)\) under \(\{G^{p}\}\), and \(\forall G^{n}_{s}=\arg\max_{\tilde{G}^{n}_{s}}I(\tilde{G}^{n}_{s};Y)\) under \(\{G^{n}\}\); suppose \(|G_{c}|=s_{c},\;\forall G_{c}\), resolving the following GALA objective elicits an invariant GNN defined via Eq. 1,_

\[\max_{f_{c},g}\;I(\widehat{G}_{c};Y),\;\text{s.t.}\;g\in\operatorname*{arg\, max}_{\hat{g},|\widehat{G}^{p}_{c}|\leq s_{c}}I(\widehat{G}^{p}_{c};\widehat{G }^{n}_{c}|Y), \tag{9}\]

_where \(\widehat{G}^{p}_{c}\in\{\widehat{G}^{p}_{c}=g(G^{p})\}\) and \(\widehat{G}^{n}_{c}\in\{\widehat{G}^{n}_{c}=g(G^{n})\}\) are the estimated invariant subgraphs via \(g\) from \(\{G^{p}\}\) and \(\{G^{n}\}\), respectively._

The proof is given in Appendix E.5. Essentially, assumption iii) in Theorem 4.1 is an implication of the variation sufficiency (Assumption 3.3). When given the distinct subsets \(\{G^{p}\}\) and \(\{G^{n}\}\) with different relations of \(H(C|Y)\) and \(H(S|Y)\), since \(H(C|Y)\) remains invariant across different subsets, the variation happens mostly to the spurious correlations between \(S\) and \(Y\). By differentiating spurious correlations into distinct subsets, maximizing the intra-class mutual information helps identify the true invariance. The fundamental rationale for why GALA resolves two seemingly conversed cases essentially relies on the commutative law of mutual information.

## 5 Experiments

We evaluated GALA with both synthetic and realistic graph distribution shifts. Specifically, we are interested in the following two questions: (a) Can GALA improve over the state-of-the-art invariant graph learning methods when the spurious subgraph has a stronger correlation with the labels? (b) Will GALA affect the performance when the invariant correlations are stronger?

### Datasets and experiment setup

We prepare both synthetic and realistic graph datasets containing various distribution shifts to evaluate GALA. We will briefly introduce each dataset and leave more details in Appendix G.1.

**Two-piece graph datasets.** We adopt BA-2motifs [50] to implement \(4\) variants of \(3\)-class two-piece graph (Def. 3.1) datasets. The datasets contain different relationships of \(H(C|Y)\) and \(H(S|Y)\) by controlling the \(\alpha\) and \(\beta\) in the mixed environment, respectively. We consider \(4\) cases of \(\alpha-\beta\), ranging from \(\{+0.2,+0.1,-0.1,-0.2\}\), to verify our discussion in Sec. 4.3.

**Realistic datasets.** We also adopt datasets containing various realistic graph distribution shifts to comprehensively evaluate the OOD performance of GALA. We adopt \(6\) datasets from DrugOOD benchmark [28], which focuses on the challenging real-world task of AI-aided drug affinity prediction. The DrugOOD datasets include splits using Assay, Scaffold, and Size from the EC50 category (denoted as **EC50-***) and the Ki category (denoted as **Ki-***). We also adopt graphs converted from the ColoredMNIST dataset [3] using the algorithm from Knyazev et al. [36], which contains distribution 

[MISSING_PAGE_FAIL:9]

**OOD generalization in realistic graphs.** The results in realistic datasets are reported in Table 3. Aligned with our previous discussion, existing environment augmentation approaches sometimes yield better performance than ERM, such as CAL in EC50-Size, MoeOOD in Ki-Assay, GIL in Graph-SST2, or CIGA in EC50-Size, however, inevitably fail to bring consistent improvements than ERM, due to the existence of failure cases. DisC is suspected to work only for graph distribution shifts on node features and bring impressive improvements in CMNIST-sp, but can destroy the learned information under more challenging settings. In contrast, GALA consistently outperform ERM by a non-trivial margin in all datasets. Notably, GALA achieves near oracle performance in CMNIST-sp and improves CIGA by \(53\%\). The consistent improvements of GALA confirm the effectiveness of GALA.

**Correlation strengths of \(\{G^{p}\}\) and \(\{G^{n}\}\).** We conduct experiments with the two-piece graph datasets evaluated in Table 2 to verify the correctness of Eq. 6 and Eq. 8. Eq. 6 and Eq. 8 imply that the underlying invariant subgraph will be the subgraph that maximizes the mutual information among subgraphs from \(\{G^{p}\}\) and \(\{G^{n}\}\), no matter whether the dominant correlation is spurious or not. We measure the invariant and spurious correlation strengths in terms of co-occur probability of the invariant and spurious subgraphs with the labels. The results are shown in Fig. 3(a). It can be found that, under both cases, the underlying invariant subgraph maintains the predictivity with the label in an invariant manner. Hence, maximizing the intra-class subgraph mutual information between \(\{G^{p}\}\) and \(\{G^{n}\}\) in GALA succeeds in identifying the underlying invariant subgraph.

**CIGAv2 compatibility.** Although GALA focuses on the contrastive term in CIGA, both GALA and CIGA are compatible with the additional CIGAv2 term that facilitates constraining the graph sizes. To verify, we compare the OOD performances of CIGA, CIGAv2, GALA, and GALA +CIGAv2 using two challenging datasets, Ki-Scaffold and CMNIST-sp. The results are given in Fig. 3(b). It can be found that, despite incorporating the additional CIGAv2 constraint, CIGA can not outperform GALA, while GALA can bring more improvements with the additional CIGAv2 constraint. In CMNIST-sp, since GALA already achieve the upper bound, incorporating CIGAv2 can only achieve a similar result.

**Hyperparameter sensitivity.** We also test the hyperparameter sensitivity of GALA to the contrastive penalty weights as well as the upsampling times that are introduced to mitigate the imbalance of positive and negative graphs. We conduct the experiments with two-piece graph dataset \(\{0.7,0.9\}\). As shown in Fig. 3(c), it can be found that GALA is generically robust to different hyperparameter choices. In addition, when the penalty weight or the upsampling times turn to \(0\), the performance will decrease a lot, which serves as strong evidence for the effectiveness of GALA.

**Computational analysis.** We also conduct computational analysis of GALA and other methods, and defer the results to Table. 6 in Appendix G.4, due to space constraints. The results show that GALA costs only a competitive training time as environment generation based methods, while achieving much better OOD generalization performance.

## 6 Conclusions

We conducted a retrospective study on the faithfulness of the augmented environment information for OOD generalization on graphs. By showing hardness cases and impossibility results of the existing approaches, we developed a set of minimal assumptions for feasible invariant graph learning. Built upon the assumptions, we proposed GALA to learn the invariant graph representations guided by an environment assistant model. Extensive experiments with \(12\) datasets verified the superiority of GALA.

Figure 3: Ablation studies.

## Acknowledgements

We thank the reviewers for their valuable comments. This work was supported by CUHK direct grant 4055146. BH was supported by the NSFC Young Scientists Fund No. 62006202, NSFC General Program No. 62376235, Guangdong Basic and Applied Basic Research Foundation No. 2022A1515011652, HKBU Faculty Niche Research Areas No. RC-FNRA-IG/22-23/SCI/04, and Tencent AI Lab Rhino-Bird Gift Fund.

## References

* Ahmad and Lin [1976] I. Ahmad and P.-E. Lin. A nonparametric estimation of the entropy for absolutely continuous distributions (corresp.). _IEEE Transactions on Information Theory_, 22(3):372-375, 1976. (Cited on page 27).
* Ahuja et al. [2021] K. Ahuja, E. Caballero, D. Zhang, J.-C. Gagnon-Audet, Y. Bengio, I. Mitliagkas, and I. Rish. Invariance principle meets information bottleneck for out-of-distribution generalization. In _Advances in Neural Information Processing Systems_, 2021. (Cited on pages 9 and 32).
* Arjovsky et al. [2019] M. Arjovsky, L. Bottou, I. Gulrajani, and D. Lopez-Paz. Invariant risk minimization. _arXiv preprint arXiv:1907.02893_, 2019.
* Belghazi et al. [2018] M. I. Belghazi, A. Baratin, S. Rajeshwar, S. Ozair, Y. Bengio, A. Courville, and D. Hjelm. Mutual information neural estimation. In _International Conference on Machine Learning_, volume 80, pages 531-540, 10-15 Jul 2018.
* Bevilacqua et al. [2021] B. Bevilacqua, Y. Zhou, and B. Ribeiro. Size-invariant graph representations for graph classification extrapolations. In _International Conference on Machine Learning_, pages 837-851, 2021. (Cited on page 21).
* Chen et al. [2022] G. Chen, Y. Wang, F. Guo, Q. Guo, J. Shao, H. Shen, and X. Cheng. Causality and independence enhancement for biased node classification. In _ACM International Conference on Information and Knowledge Management_, pages 203-212, 2022.
* Chen et al. [2022] Y. Chen, H. Yang, Y. Zhang, K. Ma, T. Liu, B. Han, and J. Cheng. Understanding and improving graph injection attack by promoting unnoticeability. In _International Conference on Learning Representations_, 2022.
* Chen et al. [2022] Y. Chen, Y. Zhang, Y. Bian, H. Yang, K. Ma, B. Xie, T. Liu, B. Han, and J. Cheng. Learning causally invariant representations for out-of-distribution generalization on graphs. In _Advances in Neural Information Processing Systems_, 2022. (Cited on pages 1, 2, 3, 4, 5, 6, 9, 19, 20, 21, 22, 25, 27, 31, 32 and 33).
* Chen et al. [2022] Y. Chen, K. Zhou, Y. Bian, B. Xie, K. Ma, Y. Zhang, H. Yang, B. Han, and J. Cheng. Pareto invariant risk minimization. _arXiv preprint_, arXiv:2206.07766, 2022.
* Chen et al. [2023] Y. Chen, W. Huang, K. Zhou, Y. Bian, B. Han, and J. Cheng. Towards understanding feature learning in out-of-distribution generalization. _arXiv preprint arXiv:2304.11327_, 2023. (Cited on page 7).
* Chopra et al. [2005] S. Chopra, R. Hadsell, and Y. LeCun. Learning a similarity metric discriminatively, with application to face verification. In _2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR 2005), 20-26 June 2005, San Diego, CA, USA_, pages 539-546, 2005.
* Creager et al. [2021] E. Creager, J. Jacobsen, and R. S. Zemel. Environment inference for invariant learning. In _International Conference on Machine Learning_, pages 2189-2200, 2021.
* Creager et al. [2021] E. Creager, J. Jacobsen, and R. S. Zemel. Environment inference for invariant learning. In _International Conference on Machine Learning_, volume 139, pages 2189-2200, 2021. (Cited on pages 9 and 32).

* [14] Y. Deng, Y. Yang, B. Mirzasoleiman, and Q. Gu. Robust learning with progressive data expansion against spurious correlation. _arXiv preprint_, arXiv:2306.04949, 2023.
* [15] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. BERT: Pre-training of deep bidirectional transformers for language understanding. In _Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)_, pages 4171-4186, 2019.
* [16] M. Ding, K. Kong, J. Chen, J. Kirchenbauer, M. Goldblum, D. Wipf, F. Huang, and T. Goldstein. A closer look at distribution shifts and out-of-distribution generalization on graphs. In _NeurIPS 2021 Workshop on Distribution Shifts: Connecting Methods and Applications_, 2021.
* [17] S. Fan, X. Wang, Y. Mo, C. Shi, and J. Tang. Debiasing graph neural networks via learning disentangled causal substructure. In _Advances in Neural Information Processing Systems_, 2022. (Cited on pages 1, 4, 6, 7, 9, 21, 22 and 32)
* [18] M. Fey and J. E. Lenssen. Fast graph representation learning with PyTorch Geometric. In _ICLR Workshop on Representation Learning on Graphs and Manifolds_, 2019.
* [19] J. Gao, Y. Zhou, J. Zhou, and B. Ribeiro. Double equivariance for inductive link prediction for both new nodes and new relation types. volume arXiv:2302.01313, 2023.
* [20] M. Gardner, J. Grus, M. Neumann, O. Tafjord, P. Dasigi, N. F. Liu, M. E. Peters, M. Schmitz, and L. Zettlemoyer. Allennlp: A deep semantic natural language processing platform. _arXiv preprint_, arXiv:1803.07640, 2018.
* [21] S. Gui, X. Li, L. Wang, and S. Ji. GOOD: A graph out-of-distribution benchmark. In _Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track_, 2022. (Cited on page 1)
* [22] S. Gui, M. Liu, X. Li, Y. Luo, and S. Ji. Joint learning of label and environment causal independence for graph out-of-distribution generalization. _arXiv preprint_, arXiv:2306.01103, 2023.
* [23] I. Gulrajani and D. Lopez-Paz. In search of lost domain generalization. In _International Conference on Learning Representations_, 2021.
* [24] W. L. Hamilton, Z. Ying, and J. Leskovec. Inductive representation learning on large graphs. In _Advances in Neural Information Processing Systems_, pages 1024-1034, 2017.
* [25] W. Hu, M. Fey, M. Zitnik, Y. Dong, H. Ren, B. Liu, M. Catasta, and J. Leskovec. Open graph benchmark: Datasets for machine learning on graphs. In _Advances in Neural Information Processing Systems_, 2020.
* [26] K. Huang, T. Fu, W. Gao, Y. Zhao, Y. H. Roohani, J. Leskovec, C. W. Coley, C. Xiao, J. Sun, and M. Zitnik. Therapeutics data commons: Machine learning datasets and tasks for drug discovery and development. In _Advances in Neural Information Processing Systems Datasets and Benchmarks Track (Round 1)_, 2021.
* [27] S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In _International Conference on Machine Learning_, volume 37, pages 448-456, 2015.
* A Focus on Affinity Prediction Problems with Noise Annotations. _arXiv preprint_, arXiv:2201.09637, 2022.
* [29] M. Gordner, J. Grus, M. Neumann, O. Tafjord, P. Dasigi, N. F. Liu, M. E. Peters, M. Schmitz, and L. Zettlemoyer. Allennlp: A deep semantic natural language processing platform. _arXiv preprint_, arXiv:1803.07640, 2018.
* [30] M. Gordner, J. Grus, M. Neumann, O. Tafjord, P. Dasigi, N. F. Liu, M. E. Peters, M. Schmitz, and L. Zettlemoyer. Allennlp: A deep semantic natural language processing platform. _arXiv preprint_, arXiv:1803.07640, 2018.
* [31] S. Gui, X. Li, L. Wang, and S. Ji. GOOD: A graph out-of-distribution benchmark. In _Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track_, 2022.
* [32] S. Gui, M. Liu, X. Li, Y. Luo, and S. Ji. Joint learning of label and environment causal independence for graph out-of-distribution generalization. _arXiv preprint_, arXiv:2306.01103, 2023.
* [33] I. Gulrajani and D. Lopez-Paz. In search of lost domain generalization. In _International Conference on Learning Representations_, 2021.
* [34] W. L. Hamilton, Z. Ying, and J. Leskovec. Inductive representation learning on large graphs. In _Advances in Neural Information Processing Systems_, pages 1024-1034, 2017.
* [35] W. Hu, M. Fey, M. Zitnik, Y. Dong, H. Ren, B. Liu, M. Catasta, and J. Leskovec. Open graph benchmark: Datasets for machine learning on graphs. In _Advances in Neural Information Processing Systems_, 2020.
* [36] K. Huang, T. Fu, W. Gao, Y. Zhao, Y. H. Roohani, J. Leskovec, C. W. Coley, C. Xiao, J. Sun, and M. Zitnik. Therapeutics data commons: Machine learning datasets and tasks for drug discovery and development. In _Advances in Neural Information Processing Systems Datasets and Benchmarks Track (Round 1)_, 2021.
* [37] S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In _International Conference on Machine Learning_, volume 37, pages 448-456, 2015.
* A Focus on Affinity Prediction Problems with Noise Annotations. _arXiv preprint_, arXiv:2201.09637, 2022.
* [29] W. Jin, T. Zhao, J. Ding, Y. Liu, J. Tang, and N. Shah. Empowering graph representation learning with test-time graph transformation. _arXiv preprint_, arXiv:2210.03561, 2022.
* [30] P. Kamath, A. Tangella, D. Sutherland, and N. Srebro. Does invariant risk minimization capture invariance? In _International Conference on Artificial Intelligence and Statistics_, pages 4069-4077, 2021.
* [31] B. F. Kamhoua, L. Zhang, Y. Chen, H. Yang, M. KAILI, B. Han, B. Li, and J. Cheng. Exact shape correspondence via 2d graph convolution. In _Advances in Neural Information Processing Systems_, 2022.
* [32] K. Kandasamy, A. Krishnamurthy, B. Poczos, L. Wasserman, and j. m. robins. Nonparametric von mises estimators for entropies, divergences and mutual informations. In _Advances in Neural Information Processing Systems_, volume 28, 2015.
* [33] P. Khosla, P. Teterwak, C. Wang, A. Sarna, Y. Tian, P. Isola, A. Maschinot, C. Liu, and D. Krishnan. Supervised contrastive learning. In _Advances in Neural Information Processing Systems_, volume 33, pages 18661-18673, 2020.
* [34] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. In _International Conference on Learning Representations_, 2015.
* [35] T. N. Kipf and M. Welling. Semi-supervised classification with graph convolutional networks. In _International Conference on Learning Representations_, 2017.
* [36] B. Knyazev, G. W. Taylor, and M. R. Amer. Understanding attention and generalization in graph neural networks. In _Advances in Neural Information Processing Systems_, pages 4204-4214, 2019.
* [37] P. W. Koh, S. Sagawa, H. Marklund, S. M. Xie, M. Zhang, A. Balsubramani, W. Hu, M. Yasunaga, R. L. Phillips, I. Gao, T. Lee, E. David, I. Stavness, W. Guo, B. Earnshaw, I. Haque, S. M. Beery, J. Leskovec, A. Kundaje, E. Pierson, S. Levine, C. Finn, and P. Liang. WILDS: A benchmark of in-the-wild distribution shifts. In _International Conference on Machine Learning,_, pages 5637-5664, 2021.
* [38] D. Krueger, E. Caballero, J. Jacobsen, A. Zhang, J. Binas, D. Zhang, R. L. Priol, and A. C. Courville. Out-of-distribution generalization via risk extrapolation (rex). In _International Conference on Machine Learning_, pages 5815-5826, 2021.
* [39] H. Lee, H. Park, and K. Yoon. Towards better generalization with flexible representation of multi-module graph neural networks. _arXiv preprint_, arXiv:2209.06589, 2022.
* [40] J. Lee, E. Kim, J. Lee, J. Lee, and J. Choo. Learning debiased representation via disentangled feature augmentation. In _Advances in Neural Information Processing Systems_, 2021.
* [41] H. Li, Z. Zhang, X. Wang, and W. Zhu. Learning invariant graph representations for out-of-distribution generalization. In _Advances in Neural Information Processing Systems_, 2022.
* [42] X. Li, S. Gui, Y. Luo, and S. Ji. Graph structure and feature extrapolation for out-of-distribution generalization. _arXiv preprint_, arXiv:2306.08076, 2023.
* [43] Y. Lin, S. Zhu, L. Tan, and P. Cui. ZIN: When and how to learn invariance without environment partition? In _Advances in Neural Information Processing Systems_, 2022.
* [44] E. Z. Liu, B. Haghgoo, A. S. Chen, A. Raghunathan, P. W. Koh, S. Sagawa, P. Liang, and C. Finn. Just train twice: Improving group robustness without training group information. In _International Conference on Machine Learning_, pages 6781-6792, 2021.
** [45] G. Liu, T. Zhao, J. Xu, T. Luo, and M. Jiang. Graph rationalization with environment-based augmentations. _arXiv preprint arXiv:2206.02886_, 2022.
* [46] J. Liu, Z. Hu, P. Cui, B. Li, and Z. Shen. Heterogeneous risk minimization. In _International Conference on Machine Learning_, volume 139, pages 6804-6814, 2021.
* [47] S. Liu, T. Li, Y. Feng, N. Tran, H. Zhao, Q. Qiu, and P. Li. Structural re-weighting improves graph domain adaptation. In _International Conference on Machine Learning_, Proceedings of Machine Learning Research, pages 21778-21793, 2023.
* [48] Y. Liu, X. Ao, F. Feng, Y. Ma, K. Li, T. Chua, and Q. He. FLOOD: A flexible invariant learning framework for out-of-distribution generalization on graphs. In _Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining_, pages 1548-1558, 2023.
* [49] A. Lucic, M. A. Ter Hoeve, G. Tolomei, M. De Rijke, and F. Silvestri. Cf-gnnexplainer: Counterfactual explanations for graph neural networks. In _International Conference on Artificial Intelligence and Statistics_, pages 4499-4511, 2022.
* [50] D. Luo, W. Cheng, D. Xu, W. Yu, B. Zong, H. Chen, and X. Zhang. Parameterized explainer for graph neural network. In _Advances in Neural Information Processing Systems_, pages 19620-19631, 2020.
* [51] K. Ma, G. Yang, H. Yang, Y. Chen, and J. Cheng. Calibrating and improving graph contrastive learning. _Transactions on Machine Learning Research_, 2023. ISSN 2835-8856.
* [52] S. Mahdavi, K. Swersky, T. Kipf, M. Hashemi, C. Thrampoulidis, and R. Liao. Towards better out-of-distribution generalization of neural algorithmic reasoning tasks. _arXiv preprint arXiv:2211.00692_, 2022.
* [53] L. McInnes, J. Healy, N. Saul, and L. Grossberger. Umap: Uniform manifold approximation and projection. _The Journal of Open Source Software_, 3(29):861, 2018.
* [54] D. Mendez, A. Gaulton, A. P. Bento, J. Chambers, M. D. Veij, E. Felix, M. P. Magarinos, J. F. Mosquera, P. Mutowo-Meullenet, M. Nowotka, M. Gordillo-Maranon, F. M. I. Hunter, L. Junco, G. Mugumbate, M. Rodriguez-Lopez, F. Atkinson, N. Bosc, C. J. Radoux, A. Segura-Cabrera, A. Hersey, and A. R. Leach. Chembl: towards direct deposition of bioassay data. _Nucleic Acids Research_, 47(Database-Issue):D930-D940, 2019.
* [55] S. Miao, M. Liu, and P. Li. Interpretable and generalizable graph learning via stochastic attention mechanism. _arXiv preprint arXiv:2201.12987_, 2022.
* [56] S. Miao, Y. Luo, M. Liu, and P. Li. Interpretable geometric deep learning via learnable randomness injection. In _International Conference on Learning Representations_, 2023.
* [57] C. Murray and D. Rees. The rise of fragment-based drug discovery. _Nature chemistry_, 1:187-92, 06 2009.
* [58] J. Nam, H. Cha, S. Ahn, J. Lee, and J. Shin. Learning from failure: Training debiased classifier from biased classifier. In _Advances in Neural Information Processing Systems_, 2020.
* [59] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin, N. Gimelshein, L. Antiga, A. Desmaison, A. Kopf, E. Yang, Z. DeVito, M. Raison, A. Tejani, S. Chilamkurthy, B. Steiner, L. Fang, J. Bai, and S. Chintala. Pytorch: An imperative style, high-performance deep learning library. In _Advances in Neural Information Processing Systems_, pages 8024-8035, 2019.

* [60] J. Peters, P. Buhlmann, and N. Meinshausen. Causal inference by using invariant prediction: identification and confidence intervals. _Journal of the Royal Statistical Society: Series B (Statistical Methodology)_, 78(5):947-1012, 2016.
* [61] M. Pezeshki, D. Bouchacourt, M. Ibrahim, N. Ballas, P. Vincent, and D. Lopez-Paz. Discovering environments with XRM. _arXiv preprint_, arXiv:2309.16748, 2023.
* [62] R. Salakhutdinov and G. E. Hinton. Learning a nonlinear embedding by preserving class neighbourhood structure. In _International Conference on Artificial Intelligence and Statistics_, pages 412-419, 2007.
* [63] R. Socher, A. Perelygin, J. Wu, J. Chuang, C. D. Manning, A. Y. Ng, and C. Potts. Recursive deep models for semantic compositionality over a sentiment treebank. In _Conference on Empirical Methods in Natural Language Processing_, pages 1631-1642, 2013.
* [64] Y. Sui, X. Wang, J. Wu, M. Lin, X. He, and T.-S. Chua. Causal attention for interpretable and generalizable graph classification. In _Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining_, page 1696-1705, 2022.
* [65] S. Tao, Q. Cao, H. Shen, Y. Wu, B. Xu, and X. Cheng. Idea: Invariant causal defense for graph adversarial robustness. _arXiv preprint_, arXiv:2305.15792, 2023.
* [66] D. Ulyanov, A. Vedaldi, and V. S. Lempitsky. Instance normalization: The missing ingredient for fast stylization. _arXiv preprint_, arXiv:1607.08022, 2016.
* [67] A. van den Oord, Y. Li, and O. Vinyals. Representation learning with contrastive predictive coding. _arXiv preprint_, arXiv:1807.03748, 2018.
* [68] P. Velickovic, G. Cucurull, A. Casanova, A. Romero, P. Lio, and Y. Bengio. Graph attention networks. In _International Conference on Learning Representations_, 2018.
* [69] T. Wang and P. Isola. Understanding contrastive representation learning through alignment and uniformity on the hypersphere. In _International Conference on Machine Learning_, pages 9929-9939, 2020.
* [70] Z. Wang, Y. Chen, Y. Duan, W. Li, B. Han, J. Cheng, and H. Tong. Towards out-of-distribution generalizable predictions of chemical kinetics properties. _arXiv preprint_, arXiv:2310.03152, 2023.
* [71] D. Wolpert and W. Macready. No free lunch theorems for optimization. _IEEE Transactions on Evolutionary Computation_, 1(1):67-82, 1997.
* [72] Q. Wu, H. Zhang, J. Yan, and D. Wipf. Handling distribution shifts on graphs: An invariance perspective. In _International Conference on Learning Representations_, 2022.
* [73] Y. Wu, X. Wang, A. Zhang, X. He, and T.-S. Chua. Discovering invariant rationales for graph neural networks. In _International Conference on Learning Representations_, 2022.
* [74] K. Xu, C. Li, Y. Tian, T. Sonobe, K. Kawarabayashi, and S. Jegelka. Representation learning on graphs with jumping knowledge networks. In _International Conference on Machine Learning_, pages 5449-5458, 2018.
* [75] K. Xu, W. Hu, J. Leskovec, and S. Jegelka. How powerful are graph neural networks? In _International Conference on Learning Representations_, 2019.
* [76] K. Xu, M. Zhang, J. Li, S. S. Du, K. Kawarabayashi, and S. Jegelka. How neural networks extrapolate: From feedforward to graph neural networks. In _International Conference on Learning Representations_, 2021.

* Yang et al. [2022] N. Yang, K. Zeng, Q. Wu, X. Jia, and J. Yan. Learning substructure invariance for out-of-distribution molecular representations. In _Advances in Neural Information Processing Systems_, 2022. (Cited on pages 1, 2, 4, 5, 9, 21, 22, 32 and 33)
* Yehudai et al. [2021] G. Yehudai, E. Fetaya, E. Meirom, G. Chechik, and H. Maron. From local structures to size generalization in graph neural networks. In _International Conference on Machine Learning_, pages 11975-11986, 2021. (Cited on page 21)
* Yeung [2008] R. Yeung. _Information Theory and Network Coding_. Springer New York, NY, 01 2008. ISBN 978-0-387-79233-0. (Cited on page 25)
* You et al. [2023] Y. You, T. Chen, Z. Wang, and Y. Shen. Graph domain adaptation via theory-grounded spectral regularization. In _The Eleventh International Conference on Learning Representations_, 2023. (Cited on page 21)
* Yu et al. [2021] J. Yu, T. Xu, Y. Rong, Y. Bian, J. Huang, and R. He. Graph information bottleneck for subgraph recognition. In _International Conference on Learning Representations_, 2021. (Cited on pages 4, 9 and 21)
* Yu et al. [2021] J. Yu, T. Xu, Y. Rong, Y. Bian, J. Huang, and R. He. Recognizing predictive substructures with subgraph information bottleneck. _IEEE transactions on pattern analysis and machine intelligence_, 2021. (Cited on pages 4 and 21)
* Yu et al. [2023] J. Yu, J. Liang, and R. He. Mind the label shift of augmentation-based graph OOD generalization. In _IEEE/CVF Conference on Computer Vision and Pattern Recognition_, 2023. (Cited on pages 1, 4, 5 and 21)
* Yuan et al. [2020] H. Yuan, H. Yu, S. Gui, and S. Ji. Explainability in graph neural networks: A taxonomic survey. _arXiv preprint_, arXiv:2012.15445, 2020. (Cited on pages 9 and 30)
* Zhang et al. [2022] M. Zhang, N. S. Sohoni, H. R. Zhang, C. Finn, and C. Re. Correct-n-contrast: A contrastive approach for improving robustness to spurious correlations. _arXiv preprint_, arXiv:2203.01517, 2022. (Cited on pages 4, 7, 8, 21 and 27)
* Zhang et al. [2023] X. Zhang, L. Wang, J. Helwig, Y. Luo, C. Fu, Y. Xie, M. Liu, Y. Lin, Z. Xu, K. Yan, K. Adams, M. Weiler, X. Li, T. Fu, Y. Wang, H. Yu, Y. Xie, X. Fu, A. Strasser, S. Xu, Y. Liu, Y. Du, A. Saxton, H. Ling, H. Lawrence, H. Stark, S. Gui, C. Edwards, N. Gao, A. Ladera, T. Wu, E. F. Hofgard, A. M. Tehrani, R. Wang, A. Daigavane, M. Bohde, J. Kurtin, Q. Huang, T. Phung, M. Xu, C. K. Joshi, S. V. Mathis, K. Azizzadenesheli, A. Fang, A. Aspuru-Guzik, E. Bekkers, M. M. Bronstein, M. Zitnik, A. Anandkumar, S. Ermon, P. Lio, R. Yu, S. Gunnemann, J. Leskovec, H. Ji, J. Sun, R. Barzilay, T. S. Jaakkola, C. W. Coley, X. Qian, X. Qian, T. E. Smidt, and S. Ji. Artificial intelligence for science in quantum, atomistic, and continuum systems. _arXiv preprint_, arXiv:2307.08423, 2023. (Cited on page 1)
* Zhang et al. [2022] Y. Zhang, M. Gong, T. Liu, G. Niu, X. Tian, B. Han, B. Scholkopf, and K. Zhang. Adversarial robustness through the lens of causality. In _International Conference on Learning Representations_, 2022. (Cited on page 1)
* Zhou et al. [2023] J. Zhou, B. Bevilacqua, and B. Ribeiro. An ood multi-task perspective for link prediction with new relation types and nodes. _arXiv preprint_, arXiv:2307.06046, 2023. (Cited on page 21)
* Zhou et al. [2022] Y. Zhou, G. Kutyniok, and B. Ribeiro. OOD link prediction generalization capabilities of message-passing GNNs in larger test graphs. In _Advances in Neural Information Processing Systems_, 2022. (Cited on page 21)
* Zhou et al. [2022] Y. Zhou, G. Kutyniok, and B. Ribeiro. OOD link prediction generalization capabilities of message-passing GNNs in larger test graphs. In _Advances in Neural Information Processing Systems_, 2022. (Cited on page 21)
* Zhou et al. [2023] Z. Zhou, J. Yao, J. Liu, X. Guo, Q. Yao, L. He, L. Wang, B. Zheng, and B. Han. Combating bilateral edge noise for robust link prediction. In _Advances in Neural Information Processing Systems_, 2023.

* [92] Z. Zhou, C. Zhou, X. Li, J. Yao, Q. Yao, and B. Han. On strengthening and defending graph reconstruction attack with markov chain approximation. In _International Conference on Machine Learning_, 2023.
* [93] Q. Zhu, Y. Jiao, N. Ponomareva, J. Han, and B. Perozzi. Explaining and adapting graph conditional shift. _arXiv preprint_, arXiv:2306.03256, 2023.
* [94] D. Zou, S. Liu, S. Miao, V. Fung, S. Chang, and P. Li. GDL-DS: A benchmark for geometric deep learning under distribution shifts. _arXiv preprint_, abs/2310.08677, 2023.

**Appendix of GALA**

###### Contents

* A Notations
* B Limitations and Future Directions
* C Full Details of the Background
* D More Details about the Failure Cases
* E Proofs for Theorems and Propositions
* E.1 Proof of Proposition 3.2
* E.2 Complementary discussion for Sec. 3.1
* E.3 Proof of Proposition 3.4
* E.4 Proof of Corollary 3.6
* E.5 Proof of Theorem 4.1
* F More Discussions on Practical Implementations of GALA
* G More Details about the Experiments
* G.1 Datasets
* G.2 Baselines and Evaluation Setup
* G.3 Software and Hardware
* G.4 Computational analysis
Notations

Typically, for graphs that appeared in the discussion, we will use the superscript to denote the sampling process (e.g., \(G^{p}\) is the positive graph), and the subscript to denote the specific invariant (i.e., \(G_{c}\)) or spurious subgraph (i.e., \(G_{s}\)). Graph symbols with \(\widehat{G}\) are the predicted graphs of a model (i.e., the estimated invariant subgraph \(\widehat{G}_{c}\). Below, we list some examples of graphs involved in this paper.

## Appendix B Limitations and Future Directions

Although our work establishes a set of minimal assumptions for feasible invariant graph learning when the environment partitions and auxiliary information about the environment are both not available, our work is built upon the minimal availability of the environment knowledge. Nevertheless, there could exist some additional information that may be helpful for environment augmentation. Therefore, it remains interesting to explore more theoretically grounded strategies to discover and leverage more environment information for identifying the graph invariance. When the direct environment augmentation is not feasible, GALA provides a suitable framework that one could easily manipulate the environment assistant model or the partitioning of the positive and negative graphs, to select the spurious features via the additional information and better identify the graph invariance.

In addition to the correlation strengths discussed in this work, there exist other factors, such as the size of spurious and invariant subgraphs, that affect the fitting of spurious and invariant patterns, another promising future direction is to discuss the influence of these factors to the design of environment assistant model and OOD generalization on graphs.

Besides, a better data partitioning strategy can be developed with uncertainty measures [51].

## Appendix C Full Details of the Background

We give a more detailed background introduction about GNNs and Invariant Learning in this section.

**Graph Neural Networks.** Let \(G=(A,X)\) denote a graph with \(n\) nodes and \(m\) edges, where \(A\in\{0,1\}^{n\times n}\) is the adjacency matrix, and \(X\in\mathbb{R}^{n\times d}\) is the node feature matrix with a node feature dimension of \(d\). In graph classification, we are given a set of \(N\) graphs \(\{G_{i}\}_{i=1}^{N}\subseteq\mathcal{G}\) and their labels

\begin{table}
\begin{tabular}{l l} \hline \hline
**Symbols** & **Definitions** \\ \hline \(\mathcal{G}\) & the graph space \\ \(\mathcal{G}_{c}\) & the space of subgraphs with respect to the graphs from \(\mathcal{G}\) \\ \(\mathcal{Y}\) & the label space \\ \(G\in\mathcal{G}\) & a graph \\ \(G=(A,X)\) & a graph with the adjacency matrix \(A\in\{0,1\}^{n\times n}\) and node feature matrix \(X\in\mathbb{R}^{n\times d}\) \\ \(\{G\}\) & a set of graphs \\ \hline \(G^{p}\) & a graph sampled as positive samples \\ \(G^{n}\) & a graph sampled as negative samples \\ \(G^{s}\) & a graph sampled according to CIGA [8] \\ \(G_{c}\) & the invariant subgraph with respect to \(G\) \\ \(G_{s}\) & the spurious subgraph with respect to \(G\) \\ \(G_{p}^{p}\) & the invariant subgraph of a positive graph \(G^{p}\) \\ \(G_{s}^{p}\) & the spurious subgraph of a positive graph \(G^{p}\) \\ \hline \(\widehat{G}_{c}\) & the estimated invariant subgraph \\ \(\widehat{G}_{s}\) & the estimated spurious subgraph \\ \(\widehat{G}_{p}^{p}\) & the estimated invariant subgraph of a positive graph \(G^{p}\) \\ \(\widehat{G}_{c}\subseteq G_{c}\) & the part of the underlying invariant subgraph \(G_{c}\) appeared in \(\widehat{G}_{c}\) \\ \(\overline{\Delta}\widehat{G}_{c}=G_{c}-\triangle\widehat{G}_{c}\) & the complementary part of \(\triangle\widehat{G}_{c}\) with respect to the invariant subgraph \(G_{c}\) \\ \hline \hline \end{tabular}
\end{table}
Table 4: Notations for graphs involved in this paper \(\{Y_{i}\}_{i=1}^{N}\subseteq\mathcal{Y}=\mathbb{R}^{c}\) from \(c\) classes. Then, we train a GNN \(\rho\circ h\) with an encoder \(h:\mathcal{G}\rightarrow\mathbb{R}^{h}\) that learns a meaningful representation \(h_{G}\) for each graph \(G\) to help predict their labels \(y_{G}=\rho(h_{G})\) with a downstream classifier \(\rho:\mathbb{R}^{h}\rightarrow\mathcal{Y}\). The representation \(h_{G}\) is typically obtained by performing pooling with a READOUT function on the learned node representations:

\[h_{G}=\text{READOUT}(\{h_{u}^{(K)}|u\in V\}), \tag{10}\]

where the READOUT is a permutation invariant function (e.g., SUM, MEAN) [75], and \(h_{u}^{(K)}\) stands for the node representation of \(u\in V\) at \(K\)-th layer that is obtained by neighbor aggregation:

\[h_{u}^{(K)}=\sigma(W_{K}\cdot a(\{h_{v}^{(K-1)}\}|v\in\mathcal{N}(u)\cup\{u\})), \tag{11}\]

where \(\mathcal{N}(u)\) is the set of neighbors of node \(u\), \(\sigma(\cdot)\) is an activation function, e.g., ReLU, and \(a(\cdot)\) is an aggregation function over neighbors, e.g., MEAN.

Graph generation process.This work focuses on graph classification, while the results generalize to node classification as well using the same setting as in Wu et al. [72]. Specifically, we are given a set of graph datasets \(\mathcal{D}=\{\mathcal{D}_{e}\}_{e}\) collected from multiple environments \(\mathcal{E}_{\text{all}}\). Samples \((G_{i}^{e},Y_{i}^{e})\in\mathcal{D}^{e}\) from the same environment are considered as drawn independently from an identical distribution \(\mathbb{P}^{e}\). We consider the graph generation process proposed by Chen et al. [8] that covers a broad case of graph distribution shifts. Fig. 4 shows the full graph generation process considered in Chen et al. [8]. The generation of the observed graph \(G\) and labels \(Y\) are controlled by a set of latent causal variable \(C\) and spurious variable \(S\), i.e.,

\[G\coloneqq f_{\text{gen}}(C,S).\]

\(C\) and \(S\) control the generation of \(G\) by controlling the underlying invariant subgraph \(G_{c}\) and spurious subgraph \(G_{s}\), respectively. Since \(S\) can be affected by the environment \(E\), the correlation between \(Y\), \(S\) and \(G_{s}\) can change arbitrarily when the environment changes. \(C\) and \(S\) control the generation of the underlying invariant subgraph \(G_{c}\) and spurious subgraph \(G_{s}\), respectively. Since \(S\) can be affected by the environment \(E\), the correlation between \(Y\), \(S\) and \(G_{s}\) can change arbitrarily when the environment changes. Besides, the latent interaction among \(C\), \(S\) and \(Y\) can be further categorized into _Full Informative Invariant Features (FIIF)_ when \(Y\perp\!\!\!\perp S|C\) and _Partially Informative Invariant Features (PIIF)_ when \(Y\not\perp\!\!\!\perp S|C\). Furthermore, PIIF and FIIF shifts can be mixed together and yield _Mixed Informative Invariant Features (MIIF)_, as shown in Fig. 4. We refer interested readers to Chen et al. [8] for a detailed introduction of the graph generation process.

Invariant graph representation learning.To tackle the OOD generalization challenge on graphs from Fig. 4, the existing invariant graph learning approaches generically aim to identify the underlying invariant subgraph \(G_{c}\) to predict the label \(Y\)[8, 72]. Specifically, the goal of OOD generalization on graphs is to learn an _invariant GNN_\(f\coloneqq f_{c}\circ g\), which is composed of two modules: a) a featurizer \(g:\mathcal{G}\rightarrow\mathcal{G}_{c}\) that extracts the invariant subgraph \(G_{c}\); b) a classifier \(f_{c}:\mathcal{G}_{c}\rightarrow\mathcal{Y}\) that predicts the label \(Y\) based on the extracted \(G_{c}\), where \(\mathcal{G}_{c}\) refers to the space of subgraphs of \(\mathcal{G}\). The learning objectives of \(f_{c}\) and \(g\) are formulated as

\[\max_{f_{c},\ g}\ I(\widehat{G}_{c};Y),\ \text{s.t.}\ \widehat{G}_{c}\perp\!\!\!\perp E,\ \widehat{G}_{c}=g(G). \tag{12}\]

Since \(E\) is not observed, many strategies are proposed to impose the independence of \(\widehat{G}_{c}\) and \(E\). A common approach is to augment the environment information. For example, based on the

Figure 4: Full SCMs on Graph Distribution Shifts [8].

estimated invariant subgraphs \(\widehat{G}_{e}\) and spurious subgraphs \(\widehat{G}_{s}\), Liu et al. [45], Wu et al. [72; 73] proposed to generate new environments, while Li et al. [41], Yang et al. [77] proposed to infer the underlying environment labels. However, we show that it is fundamentally impossible to augment faithful environment information in Sec. 3. Miao et al. [55; 56], Yu et al. [81; 82; 83] adopt graph information bottleneck to tackle FIIF graph shifts, and they cannot generalize to PIIF shifts. Our work focuses on PIIF shifts, as it is more challenging when without environment labels [43]. Fan et al. [17] generalized [40] to tackle severe graph biases, i.e., when \(H(S|Y)<H(C|Y)\). Chen et al. [8] proposed a contrastive framework to tackle both FIIF and PIFF graph shifts, but limited to \(H(S|Y)>H(C|Y)\). However, in practice it is usually unknown whether \(H(S|Y)<H(C|Y)\) or \(H(S|Y)>H(C|Y)\) without environment information.

More OOD generalization on graphs.In addition to the aforementioned invariant learning approaches, Bevilacqua et al. [5], Li et al. [42], Yehudai et al. [78], Zhou et al. [89] study the OOD generalization as an extrapolation from small graphs to larger graphs in the task of graph classification and link prediction. In contrast, we study OOD generalization against various graph distribution shifts formulated in Fig. 4. In addition to the standard OOD generalization tasks studied in this paper, Mahdavi et al. [52], Xu et al. [76] study the OOD generalization in tasks of algorithmic reasoning on graphs. Jin et al. [29] study the test-time adaption in the graph regime. Kamhou et al. [31] study the 3D shape matching under the presence of noises. Gui et al. [22] propose an independence constraint onto the target label and environment label to improve the OOD generalization when environment labels are available. Liu et al. [48] adopt a flexible framework to tackle shifting graph distributions. Chen et al. [7], Tao et al. [65], Zhou et al. [91; 92] study the OOD generalization on graphs from the adversarial robustness perspective.

In addition to graph classification, Chen et al. [6], Wu et al. [72] study node classification. Liu et al. [47] propose a structural reweighting strategy to improve the OOD generalization of node classification. Lee et al. [39] propose to incorporate multiple modules to handle different degree modes in OOD node classification. You et al. [80], Zhu et al. [93] study unsupervised graph domain adaption.Gao et al. [19], Zhou et al. [88; 90] study the OOD link prediction.

Besides, Lucic et al. [49] aims to find counterfactual subgraphs for explaining GNNs, which focuses on post-hoc explainability while this work focuses on intrinsic interpretability.

Invariant learning without environment labels.There are also plentiful studies in invariant learning without environment labels. Creager et al. [12] proposed a minmax formulation to infer the environment labels. Liu et al. [46] proposed a self-boosting framework based on the estimated invariant and variant features. Liu et al. [44], Zhang et al. [85] proposed to infer labels based the predictions of an ERM trained model. Deng et al. [14], Pezeshki et al. [61] improve the inference of group labels based on feature learning and prediction correctness. However, Lin et al. [43] found failure cases in Euclidean data where it is impossible to identify the invariant features without given environment labels. Moreover, as the OOD generalization on graphs is fundamentally more difficult than Euclidean data [8], the question about the feasibility of learning invariant subgraphs without environment labels remains unanswered.

## Appendix D More Details about the Failure Cases

We provide more empirical results and details about the failure case verification experiments in complementary to Sec. 3. The results are shown in Fig. 5. We compared different environment augmentation approaches the vanilla GNN model trained with ERM (termed ERM), and an interpretable GNN model trained with ERM (termed XGNN).

The failure cases are constructed according to the two-piece graph generation models. The specific description is given as the following.

**Definition D.1** (3-class two-piece graphs).: _Each environment is defined with two parameters, \(\alpha_{e},\beta_{e}\in[0,1]\), and the dataset \(\mathcal{D}_{e}\) is generated as follows:_

1. _Sample_ \(y^{e}\in\{0,1,2\}\) _uniformly;_
2. _Generate_ \(G_{c}\) _and_ \(G_{s}\) _via :_ \[G_{c}\coloneqq f^{G_{c}}_{gen}(Y\cdot\text{Rad}(\alpha_{e})),\;G_{s}\coloneqq f ^{G_{s}}_{gen}(Y\cdot\text{Rad}(\beta_{e})),\]_where_ \(f_{gen}^{G_{c}},f_{gen}^{G_{s}}\) _respectively map input_ \(\{0,1,2\}\) _to a specific graph selected from a given set, and Rad_\((\alpha)\) _is a random variable with probability_ \(\alpha\) _taking a uniformly random value from_ \(\{0,1,2\}\)_, and a probability of_ \(1-\alpha\) _taking the value of_ \(+1\)_;_
3. _Synthesize_ \(G\) _by randomly concatenating_ \(G_{c}\) _and_ \(G_{s}\)_:_ \[G\coloneqq f_{gen}^{G}(G_{c},G_{s}).\]

In experiments, we implement the \(3\)-class two-piece graphs with the BA-motifs [50] model.

In experiments, we adopt a \(3\)-layer GIN [75] with a hidden dimension of \(32\) and a dropout rate of \(0.0\) as the GNN encoder. The XGNN architecture is implemented via two GNNs following the original implementation as CIGA. The optimization is proceeded with Adam [34] using a learning rate of \(1e-3\). All experiments are repeated with \(5\) different random seeds of \(\{1,2,3,4,5\}\). The mean and standard deviation are reported from the \(5\) runs.

We implement DIR [73], GREA [45], MoleOOD [77], GIL [41], DisC [17], and CIGA [8], according to the author provided codes (if available). As for the hyperparameters in each method, we use a penalty weight of \(1e-2\) for DIR following its original experiment in spurious motif datasets generated similarly using BA-motifs [73]. We use a penalty weight of \(1\) for GREA as we empirically it does not affect the performance by changing to different weights. For MoleOOD and GIL, we set the number of environments as \(3\). We tune the penalty weights of MoleOOD with values from \(\{1e-2,1e-1,1,10\}\) but did not observe much performance differences. We tune the penalty weights of GIL with values from \(\{1e-5,1e-3,1e-1\}\) recommended by the authors. For DisC, we tune only the \(q\) weight from \(\{0.9,0.7,0.5\}\) in the GCE loss as we did not observe performance differences by changing the weight of the other term. We tune the penalty weight of CIGA with values from \(\{0.5,1,2,4,8,16,32\}\) as recommended by the authors.

Figure 5: Failures of finding faithful environment information. Results shown in the figure are based on the \(3\) class two-piece graphs (Def. D.1), where the invariant correlation strength is fixed as \(0.7\) while the spurious correlation strength is varied from \(0.5\) to \(0.7\). We can find that both environment augmentation and inferring approaches suffer from severe performance decreases or even underperform ERM and XGNN when the dominated correlation is not suitable for the method. In contrast, GALA maintains strong OOD performance for both cases.

Proofs for Theorems and Propositions

### Proof of Proposition 3.2

**Proposition E.1**.: _(Restatement of Proposition 3.2) Consider the two-piece graph dataset \(\mathcal{E}_{\text{tr}}=\{(\alpha,\beta_{1}),(\alpha,\beta_{2})\}\) with \(\alpha\geq\beta_{1},\beta_{2}\) (e.g., \(\mathcal{E}_{\text{tr}}=\{(0.25,0.1),(0.25,0.2)\}\)), and its corresponding mixed environment \(\mathcal{E}_{\text{tr}}^{\text{mix}}=\{(\alpha,(\beta_{1}+\beta_{2})/2\}\) (e.g., \(\mathcal{E}_{\text{tr}}^{\text{mix}}=\{(0.25,0.15)\}\)). When \(\widehat{G}_{c}=G_{s}\) and \(\widehat{G}_{s}=G_{c}\), it holds that the augmented environment \(\mathcal{E}_{v}\) is also a two-piece graph dataset with_

\[\mathcal{E}_{v}=\{(0.5,(\beta_{1}+\beta_{2})/2)\}\text{ (e.g., }\mathcal{E}_{v}=\{(0.5,0.15)\}\)_)._

Proof.: From Definition 3.1, we known that for each graph \(G_{i}\sim\mathcal{E}_{\text{tr}}^{\text{mix}}=\{(\alpha,(\beta_{1}+\beta_{2}) /2)\}\), \(G_{i}\) is the concatenation of the \(G_{c}^{i}\) and \(G_{s}^{i}\) defined as

\[G_{c}^{i}\coloneqq f_{\text{gen}}^{G_{c}}(Y_{i}\cdot\text{Rad}(\alpha)_{i}), \quad G_{s}^{i}\coloneqq f_{\text{gen}}^{G_{s}}(Y_{i}\cdot\text{Rad}((\beta_{1} +\beta_{2})/2)_{i}),\]

where \(\text{Rad}(\cdot)_{i}\) denotes the \(i\)th sample of the random variable \(\text{Rad}(\cdot)\).

Denote

\[G_{A}=f_{\text{gen}}^{G_{c}}(+1),\;G_{B}=f_{\text{gen}}^{G_{c}}(-1),\]

and

\[G_{C}=f_{\text{gen}}^{G_{c}}(+1),\;G_{D}=f_{\text{gen}}^{G_{c}}(-1),\]

Considering applying the augmentation to \(2n\) samples randomly sampled from \(\mathcal{E}_{\text{tr}}^{\text{mix}}\), since the featurizer \(g\) separates each \(G\in\mathcal{E}_{\text{tr}}^{\text{mix}}\) into \(\widehat{G}_{c}=G_{s}\) and \(\widehat{G}_{s}=G_{c}\), and the augmented graph \(G^{i}\) is obtained by

\[G^{i,j}=f_{\text{gen}}^{G}(\widehat{G}_{c}^{i},\;\widehat{G}_{s}^{j}),\forall i,j\in\{1...n\}.\]

Then, the new \(\alpha_{v},\beta_{v}\) in \(\mathcal{E}_{v}\) can be obtained by summing up the overall numbers of \(G_{A},G_{B},G_{C},G_{D}\) concatenated into \(2n^{2}\) samples in \(\mathcal{E}_{v}\).

Specifically, we can inspect the changes of the distributions of motifs and labels. Let \(\bar{\beta}=(\beta_{1}+\beta_{2})/2\), without loss of generality, we focus on inspecting the changes given \(Y=+1\), since the changes given \(Y=-1\) is symmetric as \(Y=+1\). The original distribution is shown as follows:

\begin{tabular}{|c|c|c|} \hline \(Y=+1\) & \(G_{A}\) & \(G_{B}\) \\ \hline \(G_{C}\) & \((1-\alpha)(1-\beta)n\) & \(\alpha(1-\bar{\beta})n\) \\ \hline \(G_{D}\) & \((1-\alpha)\beta n\) & \(\alpha\beta n\) \\ \hline \end{tabular}

Then, new distributions of the motifs and labels are determined by the number of original motifs identified as \(\widehat{G}_{c}\) and \(\widehat{G}_{s}\), respectively. When \(\widehat{G}_{c}=G_{s}\) and \(\widehat{G}_{s}=G_{c}\), in the new environment \(\mathcal{E}_{v}\), given \(Y=+1\), \(G_{C}\) contributes \((1-\bar{\beta})n*2n\) samples as the "invariant" subgraph. More specifically, \(G_{C}\) will be concatenated with \(G_{A}\) and \(G_{B}\) by \(n\) times, respectively. Then we have the new distribution tables shown as follows:

\begin{tabular}{|c|c|c|} \hline \(Y=+1\) & \(G_{A}\) & \(G_{B}\) \\ \hline \(G_{C}\) & \((1-\beta)n^{2}\) & \((1-\beta)n^{2}\) \\ \hline \(G_{D}\) & \(\beta n^{2}\) & \(\beta n^{2}\) \\ \hline \end{tabular}

Since given the same \(Y\), the spurious subgraph \(G_{C}\) and \(G_{D}\) will still have the same chance being flipped, we have \(\beta_{v}=\bar{\beta}\). While as \(G_{A}\) and \(G_{B}\) appear the same times given the same \(Y\), it suffices to know that \(\alpha_{v}=0.5\). 

### Complementary discussion for Sec. 3.1

**Proposition E.2**.: _Given the same graph generation process as in Fig. 2, when there exists spurious subgraph \(G_{s}\) such that \(P^{e_{1}}(Y|G_{s})=P^{e_{2}}(Y|G_{s})\) for any two environments \(e_{1},e_{2}\in\mathcal{E}_{\text{tr}}\), where \(P^{e}(Y|G_{s})\) is the conditional distribution \(P(Y|G_{s})\) under environment \(e\in\mathcal{E}_{\text{all}}\), it is impossible for any learning algorithm applied to \(f_{c}\circ g\) to differentiate \(G_{c}\) from \(G_{s}\)._Proof.: Let \(G_{s}^{\prime}\) be the spurious subgraph such that \(P^{e_{1}}(Y|G_{s})=P^{e_{2}}(Y|G_{s})\) for any two environments \(e_{1},e_{2}\in\mathcal{E}_{\text{tr}}\), and \(G_{c}\) be the invariant subgraph which \(P^{e_{1}}(Y|G_{c})=P^{e_{2}}(Y|G_{c}),\,\forall e_{1},e_{2}\in\mathcal{E}_{ \text{tr}}\) by definition. Consider a learning algorithm applied to \(f_{c}\circ g\) that accepts the input of \(\mathcal{E}_{\text{tr}}^{\text{mix}}\), and extracts a subgraph \(\widehat{G}_{c}=g(Y)\) as an estimation of the invariant subgraph for any \(G\) to predict \(Y\) via \(f_{c}(\widehat{G}_{c})\) in a deterministic manner. If the algorithm succeed to extract \(G_{c}\) from \(\mathcal{E}_{\text{tr}}^{\text{mix}}\), then there always exists a \(\mathcal{E}_{\text{tr}}^{\text{mix}^{\prime}}\) with the desired spurious subgraph \(G_{s}^{\prime}\) and a underlying invariant subgraph \(G_{c}^{\prime}\), such that \(G_{s}^{\prime}=G_{c}\) and \(G_{c}^{\prime}=G_{s}^{*}\). Due to the deterministic nature, the algorithm fails to identify \(G_{c}^{\prime}\) in \(\mathcal{E}_{\text{tr}}^{\text{mix}^{\prime}}\). 

### Proof of Proposition 3.4

**Proposition E.3**.: _(Restatement of Proposition 3.4) There exist \(2\) two-piece graph training environments \(\mathcal{E}_{\text{tr}}\) and \(\mathcal{E}_{\text{tr}}^{\prime}\) that share the same joint distribution \(P(Y,G)\). Any learning algorithm will fail in either \(\mathcal{E}_{\text{tr}}\) or \(\mathcal{E}_{\text{tr}}^{\prime}\)._

Proof.: Let the mixed training environment of \(\mathcal{E}_{\text{tr}}\) and \(\mathcal{E}_{\text{tr}}^{\prime}\) be \(\mathcal{E}_{\text{tr}}^{\text{mix}}=\{(\alpha,\beta)\}\). Based on the definition of two-piece graphs (Definition 3.1), the joint distribution of the mixed training dataset \((G=\text{Concat}[G_{c},G_{s}],Y)\) can be computed as

\[\begin{cases}Y=+1,&\text{with probability }0.5,\\ Y=-1,&\text{with probability }0.5,\\ \text{Bit}^{G_{c}}(G_{c})=\text{Bit}^{G_{s}}(G_{s})=Y,&\text{with probability }(1-\alpha)(1-\beta),\\ \text{Bit}^{G_{c}}(G_{c})\neq\text{Bit}^{G_{s}}(G_{s})=Y,&\text{with probability }\alpha(1-\beta),\\ \text{Bit}^{G_{c}}(G_{s})\neq\text{Bit}^{G_{c}}(G_{c})=Y,&\text{with probability }(1-\alpha)\beta,\\ \text{Bit}^{G_{c}}(G_{c})=\text{Bit}^{G_{s}}(G_{s})\neq Y,&\text{with probability }\alpha\beta.\end{cases}\]

Here we use \(\text{Bit}^{G_{c}}(G_{c})\) to obtain the input bit of a subgraph \(G_{c}\) (or \((f_{\text{gen}}^{G_{c}})^{-1}\)), and \(\text{Bit}^{G_{s}}(G_{s})\) for \(G_{s}\), respectively.

Any learning algorithm that tries to identify the invariant subgraph from this training dataset will compute a model that uses subgraph \(G_{c}\), or subgraph \(G_{s}\), or both \(G_{c}\) and \(G_{s}\) to predict \(Y\) deterministically. Thus, as long as the joint distribution does not change, the resulting model will always identify the same invariant subgraph. Without loss of generality, let us assume that the model correctly identifies \(G_{c}\) as the invariant subgraph for \(\mathcal{E}_{\text{tr}}=\{(\alpha,\beta_{1}),(\alpha,\beta_{2})\}\) with \(\beta=(\beta_{1}+\beta_{2})/2\).

Now let the other training environment be \(\mathcal{E}_{\text{tr}}^{\prime}=\{(\alpha_{1},\beta),(\alpha_{2},\beta)\}\) with \(\alpha=(\alpha_{1}+\alpha_{2})/2\). It is clear that since the mixed training environment of \(\mathcal{E}_{\text{tr}}^{\prime}\) is still \(\{(\alpha,\beta)\}\), the model keeps regarding \(G_{c}\) as the invariant subgraph. However, for \(\mathcal{E}_{\text{tr}}^{\prime}\), the model fails to identify the invariance since now the invariant subgraph is \(G_{s}\).

### Proof of Corollary 3.6

**Corollary E.4**.: _(Restatement of Corollary 3.6) Without Assumption 3.3 or Assumption 3.5, there does not exist a learning algorithm that captures the invariance of the two-piece graph environments._

Proof.: The proof for lacking Assumption 3.3 is identical to the proof for Proposition E.2. Consider a learning algorithm applied to \(f_{c}\circ g\) that accepts the input of \(\mathcal{E}_{\text{tr}}^{\text{mix}}\), and extracts a subgraph \(\widehat{G}_{c}=g(Y)\) as an estimation of the invariant subgraph for any \(G\) to predict \(Y\) via \(f_{c}(\widehat{G}_{c})\) in a deterministic manner. Without the holding of Assumption 3.5, due to Proposition 3.4, there exists \(\mathcal{E}_{\text{tr}}^{\text{mix}^{\prime}}\) for each \(\mathcal{E}_{\text{tr}}^{\text{mix}}\) that have the identical joint distribution but different underlying invariant subgraph. Thus, any learning algorithm that succeeds in either \(\mathcal{E}_{\text{tr}}^{\text{mix}}\) or \(\mathcal{E}_{\text{tr}}^{\text{mix}^{\prime}}\) will fail in the other. 

### Proof of Theorem 4.1

**Theorem E.5**.: _(Restatement of Theorem 4.1) Given, i) the same data generation process as in Fig. 2; ii) \(\mathcal{D}_{\text{tr}}\) that satisfies variation sufficiency (Assumption 3.3) and variation consistency (Assumption 3.5); iii) \(\{G^{p}\}\) and \(\{G^{n}\}\) are distinct subsets of \(\mathcal{D}_{\mathrm{tr}}\) such that \(I(G^{p}_{s};G^{n}_{s}|Y)=0\), \(\forall G^{p}_{s}=\arg\max_{\hat{G}^{p}_{s}}I(\widehat{G}^{p}_{s};Y)\) under \(\{G^{p}\}\), and \(\forall G^{n}_{s}=\arg\max_{\hat{G}^{n}_{s}}I(\widehat{G}^{n}_{s};Y)\) under \(\{G^{n}\}\); suppose \(|G_{c}|=s_{c},\ \forall G_{c}\), resolving the following GAL objective elicits an invariant GNN defined via Eq. 12,_

\[\max_{f_{c},g}\ I(\widehat{G}_{c};Y),\text{ s.t. }g\in\underset{\hat{g}, \hat{G}^{p}_{c}|\leq s_{c}}{\arg\max}I(\widehat{G}^{p}_{c};\widehat{G}^{n}_{c} |Y), \tag{13}\]

_where \(\widehat{G}^{p}_{c}\in\{\widehat{G}^{p}_{c}=g(G^{p})\}\) and \(\widehat{G}^{n}_{c}\in\{\widehat{G}^{n}_{c}=g(G^{n})\}\) are the estimated invariant subgraphs via \(g\) from \(\{G^{p}\}\) and \(\{G^{n}\}\), respectively._

Proof.: Without loss of generality, we assume that \(\{G^{p}\}\) has the same spurious dominance situation as \(\mathcal{E}_{\mathbf{r}}\). In other words, when \(\hat{H}(S|Y)<H(C|Y)\), the data distribution in \(\{G^{p}\}\) also follows \(H(S|Y)<H(C|Y)\), while \(H(S|Y)>H(C|Y)\) in \(\{G^{n}\}\). To proceed, we will use the language of Chen et al. [8].

We begin by discussing the case of \(H(S|Y)<H(C|Y)\). Given \(H(S|Y)<H(C|Y)\), we have \(H(S|Y)<H(C|Y)\) in \(\{G^{p}\}\) and \(H(S|Y)>H(C|Y)\) in \(\{G^{n}\}\). Then, we claim that

\[G_{c}\in\underset{\hat{G}^{p}_{c},|\hat{G}^{p}_{c}|\leq s_{c}}{\arg\max}\ I( \widehat{G}^{p}_{c};\widehat{G}^{n}_{c}|Y). \tag{14}\]

Otherwise, consider there exists a subgraph of the spurious subgraph \(\triangle\widehat{G}^{p}_{s}\subseteq G^{p}_{s}\) in \(\widehat{G}^{p}_{c}\), which takes up the space of \(\triangle\widehat{G}^{p}_{c}\subseteq G^{p}_{c}\) from \(\widehat{G}^{p}_{c}\). Then, let \(\overline{\triangle}\widehat{G}^{p}_{c}=G^{p}_{c}-\triangle\widehat{G}^{p}_{c}\) we can inspect the changes to \(I(\widehat{G}^{p}_{c};\widehat{G}^{n}_{c}|Y)\) led by \(\triangle\widehat{G}^{p}_{s}\):

\[\triangle I(\widehat{G}^{p}_{c};\widehat{G}^{n}_{c}|Y) \tag{15}\] \[=\triangle H(\widehat{G}^{p}_{c}|Y)-\triangle H(\widehat{G}^{p}_ {c}|\widehat{G}^{n}_{c},Y)\] \[=\left[H(\overline{\triangle}\widehat{G}^{p}_{c},\triangle \widehat{G}^{p}_{s}|Y)-H(\overline{\triangle}\widehat{G}^{p}_{c},\triangle \widehat{G}^{p}_{c}|Y)\right]-\left[H(\overline{\triangle}\widehat{G}^{p}_{c },\triangle\widehat{G}^{p}_{s}|\widehat{G}^{n}_{c},Y)-H(\overline{\triangle} \widehat{G}^{p}_{c},\triangle\widehat{G}^{p}_{c}|\widehat{G}^{n}_{c},Y)\right]\] \[=\left[H(\triangle\widehat{G}^{p}_{s}|\overline{\triangle} \widehat{G}^{p}_{c},Y)-H(\triangle\widehat{G}^{p}_{c}|\overline{\triangle} \widehat{G}^{p}_{c},Y)\right]-\left[H(\triangle\widehat{G}^{p}_{s}|\overline{ \triangle}\widehat{G}^{p}_{c},\widehat{G}^{n}_{c},Y)-H(\triangle\widehat{G}^{ p}_{c}|\overline{\triangle}\widehat{G}^{p}_{c},\widehat{G}^{n}_{c},Y)\right],\]

where the last equality is obtained via expanding the conditional entropy. Then, considering the contents in \(\widehat{G}^{n}_{c}\), without loss of generality, we can divide all of the possible cases into two:

1. \(\widehat{G}^{n}_{c}\) contains only the corresponding invariant subgraph \(G^{n}_{c}\);
2. \(\widehat{G}^{n}_{c}\) contains subgraph from the corresponding spurious subgraph \(G^{n}_{s}\), denoted as \(\triangle\widehat{G}^{n}_{s}\subseteq G^{n}_{s}\);

For case (i), it is easy to write Eq. 15 as:

\[\triangle I(\widehat{G}^{p}_{c};\widehat{G}^{n}_{c}|Y) \tag{16}\] \[=\left[H(\triangle\widehat{G}^{p}_{s}|\overline{\triangle} \widehat{G}^{p}_{c},Y)-H(\triangle\widehat{G}^{p}_{c}|\overline{\triangle} \widehat{G}^{p}_{c},Y)\right]-\left[H(\triangle\widehat{G}^{p}_{s}|\overline{ \triangle}\widehat{G}^{p}_{c},\widehat{G}^{n}_{c},Y)-H(\triangle\widehat{G}^{ p}_{c}|\overline{\triangle}\widehat{G}^{p}_{c},\widehat{G}^{n}_{c},Y)\right],\] \[=-H(\triangle\widehat{G}^{p}_{c}|\overline{\triangle}\widehat{G} ^{p}_{c},Y)+H(\widehat{G}^{p}_{c}|\overline{\triangle}\widehat{G}^{p}_{c}, \widehat{G}^{n}_{c},\widehat{G}^{n}_{c},Y),\]

since \(H(\triangle\widehat{G}^{p}_{s}|\overline{\triangle}\widehat{G}^{p}_{c},Y)=H( \triangle\widehat{G}^{p}_{s}|\widehat{G}^{n}_{s},\overline{\triangle}\widehat {G}^{p}_{c},Y)=H(\triangle\widehat{G}^{p}_{s}|Y)\) given \(C\perp S|Y\) for PIIF Shifts. Then, it suffices to know that \(\triangle I(\widehat{G}^{p}_{c};\widehat{G}^{n}_{c}|Y)\leq 0\) as conditioning on new variables will not increase the entropy [79].

For case (ii), we have :

\[\triangle I(\widehat{G}^{p}_{c};\widehat{G}^{n}_{c}|Y) \tag{17}\] \[=\left[H(\triangle\widehat{G}^{p}_{s}|\overline{\triangle} \widehat{G}^{p}_{c},Y)-H(\triangle\widehat{G}^{p}_{c}|\overline{\triangle} \widehat{G}^{p}_{c},Y)\right]-\left[H(\triangle\widehat{G}^{p}_{s}|\overline{ \triangle}\widehat{G}^{p}_{c},\widehat{G}^{n}_{c},Y)-H(\triangle\widehat{G}^{ p}_{c}|\overline{\triangle}\widehat{G}^{p}_{c},\widehat{G}^{n}_{c},Y)\right],\] \[=\left[-H(\triangle\widehat{G}^{p}_{c}|\overline{\triangle} \widehat{G}^{p}_{c},Y)+H(\triangle\widehat{G}^{p}_{c}|\overline{\triangle} \widehat{G}^{p}_{c},\widehat{G}^{n}_{c},Y)\right]+\left[H(\triangle\widehat{G}^{ p}_{s}|\overline{\triangle}\widehat{G}^{p}_{c},Y)-H(\triangle\widehat{G}^{p}_{s}| \overline{\triangle}\widehat{G}^{p}_{c},\widehat{G}^{n}_{c},Y)\right],\]where we claim that \(H(\triangle\widehat{G}^{p}_{s}|\widehat{\triangle}\widehat{G}^{p}_{c},Y)-H( \triangle\widehat{G}^{p}_{s}|\widehat{\triangle}\widehat{G}^{p}_{c},\widehat{G} ^{n}_{c},Y)=0\), and similarly conclude that \(\triangle I(\widehat{G}^{p}_{c};\widehat{G}^{n}_{c}|Y)\leq 0\). More specifically, we can rewrite the first term in Eq. 17 as

\[H(\triangle\widehat{G}^{p}_{s}|\widehat{\triangle}\widehat{G}^{p} _{c},Y)-H(\triangle\widehat{G}^{p}_{s}|\widehat{\triangle}\widehat{G}^{p}_{c}, \widehat{G}^{n}_{c},Y) =H(\triangle\widehat{G}^{p}_{s}|Y)-H(\triangle\widehat{G}^{p}_{s} |\triangle\widehat{G}^{n}_{s},Y)\] \[=I(\triangle\widehat{G}^{p}_{s};\triangle\widehat{G}^{n}_{s}|Y)=0,\]

using the variation condition (i.e., assumption iii)) for \(\triangle\widehat{G}^{p}_{s}\) under \(\{G^{p}\}\), and \(\triangle\widehat{G}^{n}_{s}\) under \(\{G^{n}\}\).

After showing the success of GALA in tackling \(H(S|Y)<H(C|Y)\), it also suffices to know that the aforementioned discussion also generalizes to the other case, i.e., when \(H(S|Y)>H(C|Y)\) in \(\{G^{p}\}\) and \(H(S|Y)<H(C|Y)\) in \(\{G^{n}\}\).

More Discussions on Practical Implementations of GALA

In this section, we provide more implementation discussions about GALA in complementary to Sec. 4.

Objective implementation.As the estimation of mutual information could be highly expensive [67, 4], inspired by Chen et al. [8], we adopt the contrastive learning to approximates the mutual information between subgraphs in Eq. 9 [67, 4, 11, 33, 62, 4]:

\[\begin{split} I(\widehat{G}_{c}^{p};\widehat{G}_{c}^{n}|Y)\approx& \mathbb{E}_{\{\widehat{G}_{c}^{p},\widehat{G}_{c}^{n}\}\rightarrow\mathbb{P}_ {g}(G|\mathcal{Y}=Y)}\\ &\log\frac{e^{\phi(h_{\widehat{G}_{c}^{p}},h_{\widehat{G}_{c}^{p}} )}}{e^{\phi(h_{\widehat{G}_{c}^{p}},h_{\widehat{G}_{c}^{p}})}+\sum_{i=1}^{M}e^ {\phi(h_{\widehat{G}_{c}^{p}},h_{\widehat{G}_{c}^{i}})}},\end{split} \tag{18}\]

where \((\widehat{G}_{c}^{p},\widehat{G}_{c}^{n})\) are subgraphs extracted by \(g\) from \(\{G^{p}\},\{G^{n}\}\) that share the same label, respectively. \(\{G_{c}^{i}\}_{i=1}^{M}\) are subgraphs extracted by \(g\) from \(G\) that has a different label. \(\mathbb{P}_{g}(G|\mathcal{Y}=Y)\) is the push-forward distribution of \(\mathbb{P}(G|\mathcal{Y}=Y)\) by featurizer \(g\), \(\mathbb{P}(G|\mathcal{Y}=Y)\) refers to the distribution of \(G\) given the label \(Y\), \(\mathbb{P}(G|\mathcal{Y}\neq Y)\) refers to the distribution of \(G\) given the label that is different from \(Y\), \(\widehat{G}_{c}=g(\widehat{G}),\widehat{G}_{c}=g(\widehat{G}),G_{c}^{i}=g(G^{i})\) are the estimated subgraphs, \(h_{\widehat{G}_{c}^{p}},h_{\widehat{G}_{c}^{n}},h_{G_{c}^{i}}\) are the graph presentations of the extracted subgraphs. \(\phi\) is a similarity measure. As \(M\rightarrow\infty\), Eq. 18 approximates \(I(\widehat{G}_{c}^{p};\widehat{G}_{c}^{n}|Y)\)[1, 32, 69].

Environment assistant implementation.Theorem 4.1 shows the effectiveness of GALA when given proper subsets of \(\{G^{p}\}\) and \(\{G^{n}\}\). In practice, we can implement the environment assistant into multiple forms. As discussed in Sec. 4.1, ERM trained model can serve as a reliable proxy. Since ERM tends to learn the first dominant features, when \(H(S|Y)<H(C|Y)\), ERM will firstly learn to extract spurious subgraphs \(G_{s}\) to make predictions. Therefore, we can obtain \(\{G^{p}\}\) by finding samples where ERM correctly predicts the labels, while \(\{G^{n}\}\) for samples that ERM predicts an incorrect label. In addition to direct label predictions, we can also adopt clustering [85] to yield environment assistant predictions for better contrastive sampling. We provide the detailed description of the clustering based variant of GALA in Algorithm 2.

```
1:Input: Training data \(\mathcal{D}_{\mathrm{tr}}\); environment assistant \(A\); featurizer \(g\); classifier \(f_{c}\); length of maximum training epochs \(e\); batch size \(b\);
2:Initialize environment assistant \(A\);
3:for\(p\in[1,\dots,e]\)do
4: Sample a batch of data \(\{G_{i},Y_{i}\}_{i=1}^{b}\) from \(\mathcal{D}_{\mathrm{tr}}\);
5: Obtain Environment Assistant predictions \(\{\widehat{c}_{i}^{e}\}_{i=1}^{b}\) using \(k\)-means clustering on the graph representations yielded by \(A\);
6:for each sample \(G_{i},y_{i}\in\{G_{i},Y_{i}\}_{i=1}^{b}\)do
7: Find _positive_ graphs with same \(y_{i}\) and different \(\widehat{c}_{i}^{e}\);
8: Find _negative_ graphs with different \(y_{i}\) but same environment assistant prediction \(\widehat{c}_{i}^{e}\);
9: Calculate GALA risk via Eq. 18;
10: Update \(f_{c},g\) via gradients from GALA risk;
11:endfor
12:endfor
13:return final model \(f_{c}\circ g\);
```

**Algorithm 2** GALA: Clustering based Graph inv**A**riant **Learning** Assistant

Empirically, we find clustering based variants can provide better performance when the spurious correlations are well learned by the environment assistant model. More concretely, we plot the unap visualizations [53] of ERM trained environment assistant model as in Fig. 6, where we can find that clustering predictions provide better approximations to the underlying group labels.

Besides, we can also incorporate models that are easier to overfit to the first dominant features to better differentiate \(\{G^{p}\}\) from \(\{G^{n}\}\). To demonstrate the influence of different environment assistant implementations, we conduct more studies with interpretable GNNs with an interpretable ratio of \(30\%\) trained with ERM and also with a CIGAv1 penalty of 4.

Figure 8: Umap visualizations of learned graph representations in an interpretable GNN model (ratio=\(30\%\)) trained with ERM based on the \(3\)-class two-piece graph \(\{0.7,0.9\}\).

Figure 6: Umap visualizations of learned graph representations in ERM trained environment assistant model based on the \(3\)-class two-piece graph \(\{0.7,0.9\}\).

Figure 7: Umap visualizations of learned graph representations in an interpretable GNN model (ratio=\(30\%\)) trained with ERM based on the \(3\)-class two-piece graph \(\{0.7,0.9\}\).

Figure 9: Umap visualizations of learned graph representations of a interpretable GNN trained by ERM on EC50-Assay.

[MISSING_PAGE_FAIL:29]

extremely small number of negative samples for contrastive learning, the resulting mutual information estimation will be collapsed to trivial solutions. Therefore, we propose a simple strategy to mitigate the issue. We directly upsample the minority group samples. The minority group of samples will be repeated \(k\) times within the training set.

## Appendix G More Details about the Experiments

In this section, we provide more details about the experiments, including the dataset preparation, baseline implementations, models and hyperparameters selection as well as the evaluation protocols.

### Datasets

We provide more details about the motivation and construction method of the datasets that are used in our experiments. Statistics of the datasets are presented in Table 5.

**Two-piece graph datasets.** We construct 3-class synthetic datasets based on BAMoif [50] following Def. D.1, where the model needs to tell which one of three motifs (House, Cycle, Crane) the graph contains. For each dataset, we generate \(3000\) graphs for each class at the training set, \(1000\) graphs for each class at the validation set and testing set, respectively. Each dataset is defined with two variables \(\{a,b\}\) referring to the strength of invariant and spurious correlations. Given \(\{a,b\}\), we generate the training data following the precise generation process as Def. D.1. While for the generation of validation sets, we use a \(b_{v}=\max(1/3,b-0.2)\) that facilitates the model selection for OOD generalization [9, 23]. While for the generation of test datasets, we merely use a \(b=0.33\) that contains no distribution shifts, to fully examine to what extent the model learns the invariant correlations. During the construction, we merely inject the distribution shifts in the training data while keeping the testing data and validation data without the biases.

**CMNIST-sp.** To study the effects of PIIF shifts, we select the ColoredMNIST dataset created in IRM [3]. We convert the ColoredMnist into graphs using the superpixel algorithm introduced by Knyazev et al. [36]. Specifically, the original Mnist dataset is assigned to binary labels where images with digits \(0-4\) are assigned to \(y=0\) and those with digits \(5-9\) are assigned to \(y=1\). Then, \(y\) will be flipped with a probability of \(0.25\). Thirdly, green and red colors will be respectively assigned to images with labels \(0\) and \(1\) an averaged probability of \(0.15\) (since we do not have environment splits) for the training data. While for the validation and testing data, the probability is flipped to \(0.9\).

**Graph-SST2.** Inspired by the data splits generation for studying distribution shifts on graph sizes, we split the data curated from sentiment graph data [84], that converts sentiment sentence classification datasets **Graph-SST2**[63] into graphs, where node features are generated using BERT [15] and the edges are parsed by a Biaffine parser [20]. Our splits are created according to the averaged degrees of each graph. Specifically, we assign the graphs as follows: Those that have smaller or equal to \(50\)-th percentile averaged degree are assigned to training, those that have averaged degree large than

\begin{table}
\begin{tabular}{l|c c c c c c c} \hline \hline
**Datasets** & **\# Training** & **\# Validation** & **\# Testing** & **\# Classes** & **\# Nodes** & **\# Edges** & **Metrics** \\ \hline Two-piece graphs \(\{0.8,0.6\}\) & \(9,000\) & \(3,000\) & \(3,000\) & \(3\) & \(26.14\) & \(36.21\) & ACC \\ Two-piece graphs \(\{0.8,0.7\}\) & \(9,000\) & \(3,000\) & \(3,000\) & \(3\) & \(26.18\) & \(36.27\) & ACC \\ Two-piece graphs \(\{0.8,0.9\}\) & \(9,000\) & \(3,000\) & \(3,000\) & \(3\) & \(26.13\) & \(36.22\) & ACC \\ Two-piece graphs \(\{0.7,0.9\}\) & \(9,000\) & \(3,000\) & \(3,000\) & \(3\) & \(26.13\) & \(36.22\) & ACC \\ \hline CMNIST-sp & \(40,000\) & \(5,000\) & \(15,000\) & \(2\) & \(56.90\) & \(373.85\) & ACC \\ Graph-SST2 & \(24,881\) & \(7,004\) & \(12,893\) & \(2\) & \(10.20\) & \(18.40\) & ACC \\ \hline EC50-Assay & \(4,978\) & \(2,761\) & \(2,725\) & \(2\) & \(40.89\) & \(87.18\) & ROC-AUC \\ EC50-Scaffold & \(2,743\) & \(2,723\) & \(2,762\) & \(2\) & \(35.54\) & \(75.56\) & ROC-AUC \\ EC50-Size & \(5,189\) & \(2,495\) & \(2,505\) & \(2\) & \(35.12\) & \(75.30\) & ROC-AUC \\ Ki-Assay & \(8,490\) & \(4,741\) & \(4,720\) & \(2\) & \(32.66\) & \(71.38\) & ROC-AUC \\ Ki-Scaffold & \(5,389\) & \(4,805\) & \(4,463\) & \(2\) & \(29.96\) & \(65.11\) & ROC-AUC \\ Ki-Size & \(8,605\) & \(4,486\) & \(4,558\) & \(2\) & \(30.35\) & \(66.49\) & ROC-AUC \\ \hline \hline \end{tabular}
\end{table}
Table 5: Information about the datasets used in experiments. The number of nodes and edges are respectively taking average among all graphs.

\(50\)-th percentile while smaller than \(80\)-th percentile are assigned to the validation set, and the left are assigned to test set.

**DrugOOD datasets.** To evaluate the OOD performance in realistic scenarios with realistic distribution shifts, we also include three datasets from DrugOOD benchmark [28]. DrugOOD is a systematic OOD benchmark for AI-aided drug discovery, focusing on the task of drug target binding affinity prediction for both macromolecule (protein target) and small-molecule (drug compound). The molecule data and the notations are curated from realistic ChEMBL database [54]. Complicated distribution shifts can happen on different assays, scaffolds and molecule sizes. In particular, we select DrugOOD-lbap-core-ec50-assay, DrugOOD-lbap-core-ec50-scaffold, DrugOOD-lbap-core-ki-assay, DrugOOD-lbap-core-ki-scaffold, DrugOOD-lbap-core-ki-size, from the task of Ligand Based Affinity Prediction which uses ic50 measurement type and contains core level annotation noises. We directly use the data files provided by the authors.4 For more details, we refer interested readers to Ji et al. [28].

Footnote 4: [https://drugood.github.io/](https://drugood.github.io/)

### Baselines and Evaluation Setup

During the experiments, we do not tune the hyperparameters exhaustively while following the common recipes for optimizing GNNs. Details are as follows.

**GNN encoder.** For a fair comparison, we use the same GNN architecture as graph encoders for all methods. By default, we use \(3\)-layer GIN [75] with Batch Normalization [27] between layers and JK residual connections at the last layer [74]. The hidden dimension is set to \(32\) for Two-piece graphs, CMNIST-sp, and \(128\) for SST2, and DrugOOD datasets. The pooling is by default a mean function over all nodes. The only exception is DrugOOD datasets, where we follow the backbone used in the paper [28], i.e., \(4\)-layer GIN with sum readout.

**Interpretable GNN backbone.** As mentioned in Sec. 2 that most of the existing invariant graph learning approaches adopt the interpretable GNN as the basic backbone model for the whole predictor \(f=f_{c}\circ g\), where \(g:\mathcal{G}\rightarrow\mathcal{G}_{c}\) is a featurizer GNN and \(f_{c}:\mathcal{G}_{c}\rightarrow\mathcal{Y}\) is a classifier GNN. \(g\) first calculates the sampling weights as in \(\widehat{G}_{c}\) for each edge. More formally, given a graph \(G\) containing \(n\) nodes, a soft mask is predicted through the following equation:

\[Z=\text{GNN}(G)\in\mathbb{R}^{n\times h},\ M=\text{a}(Z,A)\in\mathbb{R}^{n \times n},\]

where \(a\) calculates the sampling weights for each edge using a MLP: \(M_{ij}=\text{MLP}([Z_{i},Z_{j}])\). Based on the continuous sampling score \(M\), \(g\) could sample discrete edges according to the predicted scores [55]. For two-piece graph datasets and DrugOOD datasets, we will directly use the score to reweight the messaging passing process along the edge, as we empirically find it yields more stable performance. While for CMNIST-sp and Graph-SST2, we will sample a ratio \(r\%\) of all edges for each graph. The ratios adopted are \(80\%\) and \(60\%\), respectively, following previous works [8, 28]. Meanwhile, to improve the stability of the subgraph extractor, we adopt a layenorm [66] following the practice of [55].

Besides, we also have various implementation options for obtaining the features in \(\widehat{G}_{c}\), for further obtaining \(h_{\widehat{G}_{c}}\), as well as for obtaining predictions based on \(\widehat{G}_{s}\). Following previous works [55], we will adopt the same GNN encoder for the two GNNs in the interpretable GNN backbone, and feed the raw graph inputs to the classifier GNN. The contrastive loss is obtained via the graph representations of the sampled subgraph by the classifier GNN. For classifying \(G\) based on \(\widehat{G}_{s}\), we use a separate MLP downstream classifier in the classifier GNN \(f_{c}\).

**Optimization and model selection.** By default, we use Adam optimizer [34] with a learning rate of \(1e-3\) and a batch size of \(128\) for all models at all datasets. Except for CMNIST-sp, we use a batch size of \(256\) to facilitate the evaluation following previous works [55]. To avoid underfitting, we pre-train models for \(20\) epochs for all datasets by default. While in two-piece graphs, we find pre-training by \(100\) epochs yields more stable performance. To avoid overfitting, we also employ an early stopping of \(5\) epochs according to the validation performance. Meanwhile, dropout is also adopted for some datasets. Specifically, we use a dropout rate of \(0.5\) for all of the realistic graph datasets, following previous works [8, 28].

The final model is selected according to the performance at the validation set. All experiments are repeated with \(5\) different random seeds of \(\{1,2,3,4,5\}\). The mean and standard deviation are reported from the \(5\) runs.

**Implementations of Euclidean OOD methods.** When implementing IRM [3], V-Rex [38] and IB-IRM [2], we refer the implementations from DomainBed [23]. Since the environment information is not available, we perform random partitions on the training data to obtain two equally large environments for these objectives following previous works [8, 12]. Moreover, we select the weights for the corresponding regularization from \(\{0.01,0.1,1,10,100\}\) for these objectives according to the validation performances of IRM and stick to it for others, since we empirically observe that they perform similarly with respect to the regularization weight choice. For EIIL [13], we use the author-released implementations about assigning different samples the weights for being put in each environment and calculating the IRM loss.

**Implementations of invariant graph learning methods.** We implement GSAT [55], GREA [45], CAL [64], MoleOOD [77], GIL [41], DisC [17], and CIGA [8], according to the author provided codes (if available).

* GREA [45]: We use a penalty weight of \(1\) for GREA as we empirically it does not affect the performance by changing to different weights.
* Interpretable ratio: same as others;
* Penalty weight: \(1\);
* Number of environments: N/A;
* GSAT [55]: We follow the recommendations of the released implementations by the authors.
* Interpretable ratio: \(70\%\);
* Penalty weight: \(1\);
* Decay ratio: \(10\%\);
* Decay interval: \(\texttt{pretrain epoch}//2\);
* Number of environments: N/A;
* CAL [64]: We follow the recommendations of the released implementations by the authors.
* Interpretable ratio: same as others;
* Penalty weight: \(\{0.1,0.5,1.0\}\);
* Number of environments: N/A;
* MoleOOD [77]: We tune the penalty weights of MoleOOD with values from \(\{1e-2,1e-1,1,10\}\) but did not observe much performance differences. Hence we stick the penalty weight as \(1\) for all datasets.
* Interpretable ratio: N/A;
* Penalty weight: \(1\);
* Number of environments: same as others;
* GIL [41]: We follow the recommendations of the paper.
* Interpretable ratio: same as others;
* Penalty weight: \(\{1e-5,1e-3,1e-1\}\);
* Number of environments: same as others;
* DisC [17]: We tune only the \(q\) weight from \(\{0.9,0.7,0.5\}\) in the GCE loss as we did not observe performance differences by changing the weight of the other terms.
* Interpretable ratio: same as others;
* \(q\) weight: \(\{0.9,0.7,0.5\}\);
* Number of environments: same as others;
* CIGA [8]: We follow the recommendations of the released implementations by the authors..
* Interpretable ratio: same as others;
* Penalty weight: \(\{0.5,1,2,4,8,16,32\}\);
* Number of environments: N/A;

* Interpretable ratio: same as others;
* Penalty weight: \(\{0.5,1,2,4,8,16,32\}\);
* Environment assistant: {vanilla GNN, XGNN};
* Sampling proxy: {label predictions, cluster predictions};
* Number of environments: same as others;

All of the graph learning methods adopt an interpretable GNN as the backbone by default. The only exception is MoleOOD, we follow the original implementation while using a shared GNN encoder for the variational losses to ensure the fairness of comparison. Besides, for DisC, we find the soft masking implementation in two-piece graphs will incur a severe performance degeneration hence we use a ratio of \(25\%\) for the interpretable GNN backbone.

For environment inferring methods, we search the number of environments

* Two-piece graphs: fixed as \(3\) (since there are \(3\) spurious graphs);
* CMNIST-sp: \(2\) (since there are \(2\) environments);
* Graph-SST2: \(\{2,3,4\}\) following previous practice [41];
* DrugOOD datasets: \(\{2,3,5,10,20\}\) following previous practice [77].;

**Implementations of GALA.** For a fair comparison, GALA uses the same GNN architecture for GNN encoders as the baseline methods. By default, we fix the temperature to be \(1\) in the contrastive loss, and merely search the penalty weight of the contrastive loss from \(\{0.5,1,2,4,8,16,32\}\) according to the validation performances, following the CIGA implementations [8]. By default, we implement the environment assistant as a ERM model, and adopt directly the environment assistant predictions to sample possible and negative graph pairs. Nevertheless, as discussed in Sec. 4 that there could be multiple implementation choices for the environment assistant and the use of its predictions. We hence also try with XGNN based environment assistant model and clustering based proxy predictions. By default, the selection of the environment assistant model is performed via best training performance, as which encourages a better fit to the dominant subgraph patterns, while we also try the model selection with best validation performance in DrugOOD datasets and find it empirically sometimes leads to better performance. All the options for the selection of the environment assistant models depend on the validation performance. For Two piece graphs, EC50-Scaffold, EC50-Size, Ki-Assay, Ki-Scaffold, CMNIST-sp and Graph-SST2, we find implementing the environment assistant as a ERM model already yield impressive improvements. While for the other DrugOOD datasets, we implement the environment assistant as an interpretable GNN trained with ERM and cluster the learned graph representations of the model to sample positive and negative pairs.

Since GALA imposes a strong regularization to the data that may hinder the learning of graph representations, we pre-train the model by \(10\) epochs using ERM and then impose the GALA penalty implemented as one-side contrastive loss as discussed in Sec. F. When the numbers of positive and negative pairs are extremely imbalanced, we will upsample the minor groups by a factor of \(\{2,3,4\}\), depending on the validation performance.

### Software and Hardware

We implement our methods with PyTorch [59] and PyTorch Geometric [18]. We ran our experiments on Linux Servers installed with V100 graphics cards and CUDA 10.2.

[MISSING_PAGE_FAIL:34]