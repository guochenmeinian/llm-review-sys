# Rethinking Semi-Supervised Imbalanced Node Classification from Bias-Variance Decomposition

Divin Yan\({}^{\dagger}\), Gengchen Wei\({}^{\dagger}\), Chen Yang\({}^{\dagger}\), Shengzhong Zhang\({}^{\dagger}\), Zengfeng Huang\({}^{\dagger}\)

\({}^{\dagger}\)Fudan University, {yanl21, gcwei22, yanc22}@m.fudan.edu.cn

{szzhang17, huangzf}@fudan.edu.cn

Corresponding Author.

###### Abstract

This paper introduces a new approach to address the issue of class imbalance in graph neural networks (GNNs) for learning on graph-structured data. Our approach integrates imbalanced node classification and Bias-Variance Decomposition, establishing a theoretical framework that closely relates data imbalance to model variance. We also leverage graph augmentation technique to estimate the variance, and design a regularization term to alleviate the impact of imbalance. Exhaustive tests are conducted on multiple benchmarks, including naturally imbalanced datasets and public-split class-imbalanced datasets, demonstrating that our approach outperforms state-of-the-art methods in various imbalanced scenarios. This work provides a novel theoretical perspective for addressing the problem of imbalanced node classification in GNNs.

## 1 Introduction

Graphs are ubiquitous in the real world, encompassing social networks, financial networks, chemical molecules [22, 46, 9] and so on. Recently, graph neural networks (GNNs) [16, 35, 9] have shown exceptional proficiency in representation learning on graphs, facilitating their broad application in various fields. Nevertheless, the process of learning on graphs, analogous to its counterparts in computer vision and natural language processing, frequently encounters significant obstacles in the form of skewed or insufficient data, leading to the prevalent issue of class imbalance. It is undeniable that real-world data often exhibits biases and numerous categories, which entail data limitations and distribution shifts to be common. Furthermore, coupled with the fact that GNNs often feature shallow architectures to prevent "over-smoothing" or "information loss", training with such datasets leads to severe over-fitting problems in minor classes.

Designing GNN imbalanced learning schemes for graph-structured data poses unique challenges, unlike image data. Graph-structured data often requires consideration of the data's topology and environment, and empirical evidence [6, 24, 31] shows that topological asymmetries can also affect the model's performance. However, due to the extremely irregular and structured nature of the data, quantifying and solving topological asymmetry is difficult and computationally intensive. As a result, existing methods such as oversampling [28, 50, 24] and loss function engineering [6, 31] are problematic for achieving satisfactory outcomes. In depth, the modeling approach for data personalization exhibits very poor scalability and generalization capability. Furthermore, the prevalence of this problem has prompted the community to seek a more effective framework for imbalanced learning. _Thus, a more fundamental and theoretical perspective is urgently needed when considering the imbalance node classification problem._Following the idea, in this work, we propose a novel viewpoint to understand graph imbalance through the lens of _Bias-Variance Decomposition_. The Bias-Variance Decomposition [1; 2; 23; 45] has long been applied in terms of model complexity and fitting capacity. Our theoretical analyses have confirmed the relationship between model variance and the degree of dataset imbalance, whereby an imbalanced training set can lead to poor prediction accuracy due to the resulting increase in variance. Furthermore, we conducted some experiments on real-world dataset and the results demonstrate a significant relationship between the variance and the imbalance ratio of the dataset. As far as we know, we were the first to establish a connection between imbalanced node classification and model variance, which conducts theoretical analysis in this field.

Moreover, we have devised a regularization term for approximating the variance of model, drawing on our theoretical analysis. The main challenge of this idea lies in estimating the expectation across different training sets. Our key insight is to leverage graph data augmentation to model the different training sets in the distribution, which has not been explored before. Our empirical evaluations have consistently demonstrated that our algorithm, leveraging three basic GNN models [16; 35; 9], yields markedly superior performance in diverse imbalanced data settings, surpassing the current state-of-the-art methods by a substantial margin. Notably, we have conducted meticulous experiments on two naturally imbalanced datasets, which serve as the realistic and representative benchmarks for real-world scenarios.

Our contribution can be succinctly summarized as follows: **(i)** We are the first to integrate imbalanced node classification and _Bias-Variance Decomposition_. Our work establishes the close relationship between data imbalance and model variance, based on theoretical analysis. **(ii)** Moreover, we are the first to conduct a detailed theoretical analysis for imbalanced node classification domain. **(iii)** Our principal insight is to leverage graph data augmentation as a means of representing the varied training sets that lie within the distribution, whilst simultaneously designing a regularization term that approximates the model's variance. **(iv)** We conduct exhaustive tests on multiple benchmarks, such as the naturally imbalanced datasets and the public-split class-imbalanced datasets. The numerical results demonstrate that our model consistently outperforms state-of-the-art machine learning methods and significantly outperforms them in heavily-imbalanced scenarios.

## 2 Preliminaries

### Notations

We concentrates on the task of semi-supervised imbalanced node classification within an undirected and unweighted graph, denoted as \(\mathbf{G}=(\mathbf{V},\mathbf{E},\mathbf{V_{L}})\). \(\mathbf{V}\) represents the node set, \(\mathbf{E}\) stands for the edge set, and \(\mathbf{V_{L}}\subset\mathbf{V}\) denotes the set of labeled nodes. The set of unlabeled nodes is denoted as \(\mathbf{V_{U}}:=\mathbf{V}\setminus\mathbf{V_{L}}\). The feature matrix is \(\mathbf{X}\in\mathbb{R}^{n\times f}\), where \(n\) is the number of nodes and \(f\) is the feature dimension. The adjacency matrix is denoted by \(\mathbf{A}\in\{0,1\}^{n\times n}\). Let \(\mathbf{N}(v)\) represent set of adjacent nodes to node \(v\). The labeled sets for each class are denoted as \((\mathbf{C}_{1},\mathbf{C}_{2},\ldots,\mathbf{C}_{k})\), where \(\mathbf{C}_{i}\) represents the labeled set for class \(i\). The imbalance ratio \(\rho\), is defined as \(\rho=\max_{i}\left|\mathbf{C}_{i}\right|/\min_{i}\left|\mathbf{C}_{i}\right|\).

### Graph Dataset Augmentations

To craft diversified perspectives of the graph dataset, we deploy advanced graph augmentation methodologies, leading to the formation of \(\mathbf{\tilde{G}}=(\tilde{\mathbf{A}},\tilde{\mathbf{X}})\) and \(\mathbf{\tilde{G}^{\prime}}=(\tilde{\mathbf{A}}^{\prime},\tilde{\mathbf{X}}^{ \prime})\). Elements such as node attributes and connections within the foundational graph are selectively obfuscated. These augmented perspectives are subsequently channeled through a common Graph Neural Network (GNN) encoder, symbolized as \(f_{\theta}:\mathbb{R}^{n\times n}\times\mathbb{R}^{n\times f}\rightarrow\mathbb{ R}^{n\times d}\), in order to distill compact node-centric embeddings: \(f_{\theta}(\tilde{\mathbf{A}},\tilde{\mathbf{X}})=\mathrm{h}\in\mathbb{R}^{n \times d}\) and \(f_{\theta}(\tilde{\mathbf{A}}^{\prime},\tilde{\mathbf{X}}^{\prime})=\mathrm{h}^ {\prime}\in\mathbb{R}^{n\times d}\).

### Related Work

Semi-Supervised Imbalanced Node Classification.Numerous innovative approaches[28; 40; 50; 19; 25; 6; 24; 31; 43] have been proposed to tackle the difficulties arising from imbalanced node classification on graph data. GraphSMOTE [50] employs the SMOTE [5] algorithm to perform interpolation at the low dimensional embedding space to synthesize the minority nodes, while ImGAGN [25] introduces GAN [8] for the same purpose. Another work GraphENS [24] synthesizesmixed nodes by combining the ego network of minor nodes with target nodes. To address topology imbalance in imbalanced node classification task, ReNode [6] adjusts node weights based on their proximity to class boundaries. TAM [31] leverages local topology that automatically adapts the margins of minor nodes. Due to spatial constraints, we provide a comprehensive exposition of other relevant literature in Appendix A.

## 3 Theory

### Theoretical Motivation

This section presents a succinct overview of the classical Bias-variance Decomposition [1; 2; 23; 45] and its application to semi-supervised node classification. Furthermore, we illustrate the influence of imbalance on classification results, which subsequently amplifies the variance.

Bias-variance Decomposition.Let \(x\in X\) and \(y\in Y\) denote the input and label, respectively. Consider an underlying mapping \(f:X\to Y\) and the label can be expressed as \(y=f(x)+\epsilon\), where \(\epsilon\) is some noise. Given a training set \(D=(x_{i},y_{i})\), we train a model \(\hat{f}(x)=\hat{f}(x;D)\) using the samples in \(D\).

**Definition 1**: _Bias-Variance Decomposition is that the expected predicted error of \(f\) can be decomposed into Eq(1),_

\[\mathbb{E}_{D,x}\left[(y-\hat{f}(x;D))^{2}\right]=\left(\mathrm{ Bias}[\hat{f}(x)]\right)^{2}+\mathrm{Var}_{D}[\hat{f}(x;D)]+\mathrm{Irreducible}\; \mathrm{error}, \tag{1}\]

_where \(\mathrm{Bias}[\hat{f}(x)]=\mathbb{E}_{x}[\hat{f}(x;D)-f(x)]=\mathbb{E}_{D}[ \hat{f}(x;D)]-\mathrm{E}[y(x)]\), and \(\mathrm{Var}_{D}[\hat{f}(x;D)]=\mathbb{E}_{D}\left[\left(\mathbb{E}_{D}[\hat{ f}(x;D)]-\hat{f}(x;D)\right)^{2}\right].\)_

It is important to note that this expectation is taken with respect to both the training sets \(D\) and the predicted data \(x\). The bias term reflects the model's ability to fit the given data, while the variance term indicates the stability of the model's results with different training sets. In other words, the variance describes the model's generalization performance.

Next, we consider the specific formulation of variance in the setting of semi-supervised node classification on graph. First, we make some assumptions to simplify the analysis.

Assumptions.We make two assumptions in our approach. Firstly, we assume that the node embeddings \(h^{i}\) of node \(x^{i}\) extracted by a graph neural network for nodes belonging to class \(i\) follow a multivariate normal distribution \(h^{i}\sim N(\mu^{i},\Lambda^{i})\), where \(\Lambda^{i}\) is a diagonal matrix for all \(i=1,2,\ldots,c\). Here, let \(\epsilon^{i}=h^{i}-\mu^{i}\) which follows the distribution \(\epsilon^{i}\sim N(0,\Lambda^{i})\).

Secondly, we consider a simple classifier that estimates the probability of a node belonging to a particular class based the distance \(h^{T}C^{i}\). Here, \(C^{i}=C^{i}(D)=\frac{1}{n_{i}}\left(h^{i}_{1}+\cdots+h^{i}_{n_{i}}\right)\) is the average of labeled node embedding in training set \(D\), where \(n_{i}\) is the number of nodes in class \(i\). \(C^{i}\) follows the distribution \(C^{i}\sim N\left(\mu^{i},\frac{1}{n_{i}}\Lambda^{i}\right)\). Similarly, we denote \(e^{i}=C^{i}-\mu^{i}\) and it follows that \(e^{i}\sim N\left(0,\frac{1}{n_{i}}\Lambda^{i}\right)\).

Variance for Semi-supervised Node Classification.Under the above assumption, we can write the variance generated by different sampling training set explicitly. For a node \(x\) that belongs to class \(j\), the variance can be written:

\[\text{Var}(x) =\sum_{i=1}^{c}\mathbb{E}_{D}\left[\left(h^{T}(x)C^{i}-\mathbb{E }_{D}\left[h^{T}(x)C^{i}\right]\right)^{2}\right] \tag{2}\] \[=\sum_{i=1}^{c}\mathbb{E}_{e^{i}}\left[\left(h^{T}(x)(\mu^{i}+e^ {i})-h^{T}(x)\mu^{i}\right)^{2}\right]\] \[=\sum_{i=1}^{c}\mathbb{E}_{e^{i}}\left[\left(h^{T}(x)e^{i} \right)^{2}\right]\;=\sum_{i=1}^{c}\frac{1}{n_{i}}h^{T}(x)\Lambda^{i}h(x)\]The last equation is derived from the variance of multivariate normal distribution. The variance over the whole graph \(\sum_{i=1}^{c}\mathbb{E}_{x}\left[\mathrm{Var}(x)\right]=\sum_{i=1}^{c}\mathbb{E}_ {x}\left[\frac{1}{n_{i}}h^{T}(x)\Lambda^{i}h(x)\right]\) is the expectation of Equation 2 on node \(x\).

Variance and Imbalance.In Equation 2, we notice that the variance of a specific class \(i\) is proportional to \(\frac{1}{n_{i}}\). This reveals a relation between _imbalance_ and variance. If we assume \(\mathbb{E}_{x}[h^{T}(x)\Lambda^{i}h(x)]\) is the same for different \(i\), then the following theorem holds:

**Theorem 1**: _Under the condition that \(\sum_{i}n_{i}\) is a constant, the variance \(\sum_{i=1}^{c}\mathbb{E}_{x}\left[\frac{1}{n_{i}}h^{T}(x)\Lambda^{i}h(x)\right]\) reach its minimum when all \(n_{i}\) equal._

The proof is include in Appendix B.1. As the ratio of imbalance increases, the minority class exhibits a smaller sample size \(n_{i}\), which consequently makes a greater contribution to the overall variance. This result gives an new perspective of explanation about why the model shows poor performance under imbalance training, that variance will increase as the training set becomes imbalanced. To substantiate our analysis, we conducted an experimental study to show the relation between imbalance and the variance. The result is shown in Figure 1.

### Variance Regularization

Optimize Variance during Training.Both our analysis and the experimental results show that the increase of variance is a reason for the deterioration of performance for imbalance training set. Therefore, We propose to estimate the variance and use it as a regularization during training. We decompose the model into two parts. A GNN \(E\) is utilized as a feature extractor, and a classifier \(P\) predict the probability based on the feature extracted by GNN. We define the _variance of \(P\)_ conditioning on \(E\) of as Equation 2 evaluated for a fixed GNN \(E\). Then we can take this as regularization. By optimizing this term, we allow the model to automatically search for the feature extractor that yields the smallest variance during the optimization process.

Estimate the Expectation with Labeled Nodes. The most challenging aspect lies in the estimation of variance, as we lack access to other training sets. Therefore, we propose Lemma 1 to estimate the variance on training set with the variance on labeled data. The proof is included in Appendix B.2.1.

**Lemma 1**: _Under the above assumption for \(h^{i}\sim N(\mu^{i},\Lambda^{i})\), \(C^{i}\sim N\left(\mu^{i},\frac{1}{n_{i}}\Lambda^{i}\right)\), minimizing the \(\sum_{i=1}^{c}\mathbb{E}_{x}\left[\mathrm{Var}(x)\right]\) is equivalent to minimizing Equation 3:_

\[\frac{1}{N}\sum_{x\in G}\sum_{i=1}^{c}\left(h(x)^{T}\frac{1}{\sqrt{2n_{i}}} \left(h_{1}^{i}-h_{2}^{i}\right)\right)^{2}=\frac{1}{N}\sum_{k=1}^{n_{j}}\sum _{j=1}^{c}\sum_{i=1}^{c}\left((\mu_{k}^{j}+\epsilon_{k}^{j})^{T}\frac{1}{\sqrt {2n_{i}}}\left(\epsilon_{1}^{i}-\epsilon_{2}^{i}\right)\right)^{2}. \tag{3}\]

Figure 1: We examine the alteration in variance concerning node classification as the imbalance ratio increases on and plot the regression curves for variance and imbalance ratio. We conduct this experiment using a fixed number of training set nodes but different ones, to mitigate the influence of the number of training set nodes on variance. Detailed experimental setup is in Appendix D.2.

Estimate the Expectation with Unlabeled Nodes.Lemma 1 allows us to replace the sampling on training set with sampling on labeled node pairs \((h_{1}^{i},h_{2}^{i})\) of class \(i\). However, to evaluate Equation 3 it still needs to have access to embedding pair \((h_{1}^{i},h_{2}^{i})\) that belong to the same class \(i\). Since labels are scarce, such node pairs is difficult to obtain. To make our algorithm more practical, a way of utilizing unlabeled nodes for estimating Equation 3 is required. We accomplish this goal through two steps. In the first step, we use graph augmentation to obtain pseudo embedding pair \((h_{1},h_{2})\). Graph augmentation is a typical used technique in graph contrastive learning. It generate new view \(G^{\prime}\) of a graph \(G\) by adding noise to the graph structure. For a node \(x\) in two different views \(G,G^{\prime}\), the resulting embedding \(h,h^{\prime}\) can be seen as that of two different nodes. Thus, they can be used to replace true embedding pair in Equation 3.

However, these pseudo node pairs give no information about which class it belongs to. Thus it prohibits us from assign proper \(\frac{1}{\sqrt{2n_{i}}}\) for different \(i\) in Equation 3. It is such coefficients that compensate on the minority class, so it's crucial to reintroduce the message about class number for constructing variance regularization. Therefore, in the second step, we use the class center \(C^{i}\) to replace \(h\) in Equation 3, as shown in Equation 4. Since \(C^{i}=\mu^{i}+e^{i}\) and the variance of \(e^{i}\) is proportional to \(\frac{1}{n_{i}}\), using Equation 4 to estimate Lemma 1 can apply the similar compensatory for the minority class. More mathematical details are presented in Appendix B.2.1.

\[\begin{split}&\frac{1}{N}\sum_{xG}\sum_{i=1}^{c}\Big{(}(C^{i})^{T} h(x)-(C^{i^{\prime}})^{T}h^{\prime}(x)\Big{)}^{2}\\ &=\frac{1}{N}\sum_{k=1}^{n_{j}}\sum_{j=1}^{c}\sum_{i=1}^{c}\Big{(} (\mu^{i})^{T}(\epsilon_{k}^{j}-\epsilon_{k}^{j^{\prime}})+(e^{i})^{T}\epsilon_ {k}^{j}-(e^{i^{\prime}})^{T}\epsilon_{k}^{j^{\prime}}\Big{)}^{2}\end{split} \tag{4}\]

From the Viewpoint of Graph Sampling.We notice that an alternative perspective can be adopted to interpret this regularization term. Given a graph data \(G\), we should acknowledge that there exists some noise in its structure or feature, as a result of measuring. This randomness also attribute to the variance of classification. Assume each graph \(G\) in our dataset is a sample drawn from an underlying true graph \(\bar{G}\). Denote the classification result trained on \(G\) as \(f(x;G)\). Then the variance on \(G\) can be written as

\[\mathrm{Var}_{G}=\mathbb{E}_{x\in G}\left[\mathbb{E}_{G}\left[[f(x;G)-\mathbb{ E}_{G}[f(x;G)]^{2}]\right]\right] \tag{5}\]

Taking \(f(x)=h^{T}(x)C\), it is straitforward to show that Equation 4 and Equation 5 are same.

Despite the algorithm obtained through this new interpretation being identical to the previous one, it is worth noting that the two interpretations differ significantly. The former incorporates information from unlabeled nodes and assumes the variance originates from selecting different nodes as the training set. Graph augmentation facilitates the sampling of node pairs belonging to the same class. The latter, on the other hand, considers the same training set, but the variance originates from the entire graph's information. Graph augmentation is used to simulate the process of sampling the training graph from the underlying true graph.

## 4 The Final Algorithm

In this section, we introduce our ReVar (**R**egularize **V**ariance) framework which is based on previous theoretical frameworks for optimizing model variance. We explain our innovative approach to approximating the model's variance and using it as a regularization term in our algorithm in Section 4.1. In Section 4.2, we discuss how we integrate the GCL framework with a new contrastive learning term designed for semi-supervised learning tasks. Lastly, we present the final formulation of our optimization objective in Section 4.3, which optimizes both the cross-entropy loss function and our variance-constrained regularization term, providing a comprehensive approach to improve the performance of semi-supervised imbalanced node classification tasks.

### Variance-constrained Optimization with Adaptive Regularization

To initiate, we elucidate the methodology underpinning the computation of Equation 4. Initially, we calculate the class center \(C_{i}\) corresponding to each class. Following this, we systematically construct a probability distribution reference matrix, denoted by \(\mathcal{S}:=\left[C_{1};C_{2};\ldots;C_{k}\right]\). It's worth noting that the assemblage of class centers is represented by \(C:=\left(C_{1};C_{2};\ldots;C_{k}\right)\).

Given a node \(i\) with its associated embedding \(h_{i}\), the label probability distribution \(\pi_{i}\) pertaining to node \(i\) is ascertainable via the subsequent equation:

\[\pi_{i}^{j}=\frac{\exp\left(\operatorname{sim}\left(h_{i},C_{j}\right)/\tau \right)}{\sum_{l=1}^{k}\exp\left(\operatorname{sim}\left(h_{i},C_{l}\right)/ \tau\right)} \tag{6}\]

In the aforementioned equation, \(\pi_{i}^{j}\) signifies the \(j\)-th dimensional component of \(\pi_{i}\), \(\operatorname{sim}(\cdot,\cdot)\) denotes the function to compute the cosine similarity between a pair of vectors, and \(\tau\) is a specified temperature hyperparameter.

Subsequent to this, for every node \(i\in V\), we determine the label probability distribution. Distinctively, \(\tilde{\pi}_{i}\) and \(\tilde{\pi}_{i}^{\prime}\) are derived from \(\tilde{G}\) and \(\tilde{G}^{\prime}\), respectively. The former acts as the prediction distribution, whereas the latter represents the target distribution. Our approach then aims to minimize the cross-entropy between these two distributions.

It's paramount to underscore that for each labeled node within \(\tilde{G}^{\prime}\), its one-hot label vector is directly assigned as \(\tilde{\pi}_{i}^{\prime}=y_{i}\) for all \(i\in V_{L}\). This diverges from the procedure of deducing the predicted class distribution as described in Equation 6. This methodology is purposed to optimally leverage the extant label information.

However, a simplistic minimization of the aforementioned loss might engender confirmation bias. This is attributed to the potentially inaccurate \(\tilde{\pi}_{i}^{\prime}\) estimated for the unlabeled nodes (i.e., \(V_{U}\)), an aspect that can deleteriously impact the efficacy of pseudo-labeling-oriented semi-supervised methodologies. To address this concern, we introduce a confidence-based label-guided consistency regularization [41, 30, 48], as detailed below:

\[\mathcal{L}_{\text{VR}}=\frac{1}{|V_{\text{conf}}|}\sum_{i\in V_{\text{conf}} }CE\left(\tilde{\pi}_{i}^{\prime},\tilde{\pi}_{i}\right)+\frac{1}{|V_{L}|} \sum_{i\in V_{L}}CE\left(y_{i},\tilde{\pi}_{i}\right) \tag{7}\]

where \(V_{\text{conf}}=\{v_{i}\mid\mathbf{1}_{\{\max(\tilde{\pi}_{i}^{\prime})>v\}}= 1,\forall i\in V_{U}\}\) represents the set of nodes with confident predictions, \(v\) is the threshold for determining whether a node has a confident prediction, and \(\mathbf{1}_{\{\ldots\}}\) is an indicator function.

Figure 2: Overall pipeline of ReVar. (a) Two different views of the graph \(\tilde{\mathbf{G}},\tilde{\mathbf{G}}^{\prime}\) are obtained by graph augmentation \(transform\), and are subsequently fed into GNN encoder \(f_{\theta}\). (b) Intra-class and inter-class representations are aggregated, which means, for labeled nodes, it’s positive samples not only belong to the same class in both view but also in the other view. (c) Variance is estimated by Equation 4. Specifically, the label probability distribution is computed for each node in two views based on it’s similarity with each class center. And the difference between two probability distributions is used to approximate the model’s variance and also optimized as one term in the loss function.

In the context of confidence determination for \(\tilde{\pi}_{i}^{\prime}\), we employ a criterion wherein a value is appraised as confident if its maximum constituent surpasses a stipulated threshold. We postulate that a heightened threshold, represented by \(v\), acts as a safeguard against confirmation bias. This stratagem ensures that only high-caliber target distributions, specifically \(\tilde{\pi}_{i}^{\prime}\), have a pivotal influence on Equation 7.

### Intra-Class Aggregation Regularization

In this section, we propose an extension to the concept of graph contrastive learning that emphasizes the invariance of node representations in semi-supervised scenarios. To achieve this, we partition the nodes into two groups: labeled and unlabeled. Specifically, for the unlabeled nodes, we learn node representation invariance through the use of positive examples exclusively. For each labeled node in both views, its positive sample no longer includes itself in the other view, but instead encompasses all labeled nodes in both views belonging to the same class. Through this approach, labeled nodes belonging to the same class can be aggregated, enabling the model to learn that representation invariance now applies not to a single node, but to the complete class representation.

\[\mathcal{L}_{\mathrm{IR}}=-\frac{1}{|V_{U}|}\sum_{\mathrm{h}_{i},\mathrm{h}_{i}^{\prime}\in V_{U}}\mathrm{sim}\left(\mathrm{h}_{i}\cdot \mathrm{h}_{i}^{\prime}\right)-\frac{1}{N_{all}}(\sum_{l=1}^{k}\sum_{ \mathrm{h}_{i},\mathrm{h}_{j}^{\prime}\in\mathcal{C}_{l}}\mathrm{sim}\left( \mathrm{h}_{i}\cdot\mathrm{h}_{j}^{\prime}\right)+\sum_{l=1}^{k}\sum_{ \mathrm{h}_{i},\mathrm{h}_{j}\in\mathcal{C}_{l}}\mathrm{sim}\left(\mathrm{h} _{i}\cdot\mathrm{h}_{j}\right)) \tag{8}\]

where \(N_{all}\) = \(\sum_{i=1}^{k}\left|\mathbf{C}_{i}\right|\left(\left|\mathbf{C}_{i}\right|-1 \right)\), \(\mathrm{h}_{i}\) and \(\mathrm{h}_{i}^{\prime}\) represent feature embedding in \(\tilde{G}\) and \(\tilde{G}^{\prime}\) respectively for node \(i\). To the best of our knowledge, we are the first to introduce label information into the contrastive learning paradigm to obtain invariant representations within the context of intra-class variation and address the challenge of semi-supervised imbalanced node classification. Notably, our approach only utilizes positive examples, which significantly reduces the model's training complexity and enhances its scalability and generalization capabilities.

### Objective Function

To derive our ultimate objective function, we incorporate both \(\mathcal{L}_{\mathrm{VR}}\) and \(\mathcal{L}_{\mathrm{IR}}\). These are weighted by coefficients \(\lambda_{1}\) and \(\lambda_{2}\), respectively. Formally, the amalgamation can be represented as:

\[\mathcal{L}_{\mathrm{composite}}=\lambda_{1}\mathcal{L}_{\mathrm{VR}}+\lambda_ {2}\mathcal{L}_{\mathrm{IR}}+\mathcal{L}_{\mathrm{sup}} \tag{9}\]

Additionally, we introduce the cross-entropy loss denoted by \(\mathcal{L}_{\mathrm{sup}}\), which is established over a collection of labeled nodes, denominated as \(V_{L}\).

## 5 Experiment

### Experimental Setups

Datasets and Baselines.We have demonstrated the efficacy of our method on five commonly used benchmark datasets across various imbalance scenarios. For the conventional setting (\(\rho\)=10) of imbalanced node classification in [50; 24; 31], we conducted experiments on Cora, CiteSeer, Pubmed, and Amazon-Computers. More precisely, we select half of the classes as the minority classes and randomly convert labeled nodes into unlabeled ones until the training set reaches an imbalance ratio of \(\rho\). To be more precise, for the three citation networks, we adopt the standard splits proposed by [44] as our initial splits, with an initial imbalance ratio of \(\rho\). In order to better reflect real-world scenarios, we conducted representative experiments on the naturally imbalanced datasets Amazon-Computers and Coauthor-CS. For this setting, we utilize random sampling to construct a training set that adheres to the true label distribution of the entire graph. The comprehensive experimental settings, including the evaluation protocol and implementation details of our algorithm, are explicated in Appendix E. For baselines, we evaluate our method against classic techniques, including cross-entropy loss with re-weighting [13], PC Softmax [12], and Balanced Softmax [26], as well as state-of-the-art methods for imbalanced node classification, such as GraphSMOTE [50], GraphENS [24], ReNode [6], and TAM [31]. See Appendix E for implementation details of the baselines.

[MISSING_PAGE_FAIL:8]

[MISSING_PAGE_FAIL:9]

Conclusion and Future Work

This paper presents a novel approach to address imbalanced node classification. Our method integrates imbalanced node classification and the Bias-Variance Decomposition framework, establishing a theoretical foundation that closely links data imbalance to model variance. Additionally, we employ graph augmentation techniques to estimate model variance and design a regularization term to mitigate the impact of class imbalance. We conduct exhaustive testing to demonstrate superior performance compared to state-of-the-art methods in various imbalanced scenarios. Future work includes extending ReVar and its theories to the fields of computer vision and natural language processing. Moreover, we anticipate the emergence of more effective theories and algorithms to be developed and flourish.

## Acknowledgements

This work is supported by National Natural Science Foundation of China No.U2241212, No.62276066.

## Reproducibility Statements

The model implementation and data is released at [https://github.com/yanliang3612/ReVar](https://github.com/yanliang3612/ReVar).

## References

* [1] Mikhail Belkin, Daniel Hsu, Siyuan Ma, and Soumik Mandal. Reconciling modern machine-learning practice and the classical bias-variance trade-off. _Proceedings of the National Academy of Sciences_, 116(32):15849-15854, 2019.
* [2] Erica Briscoe and Jacob Feldman. Conceptual complexity and the bias/variance tradeoff. _Cognition_, 118(1):2-16, 2011.
* [3] Jiarui Cai, Yizhou Wang, and Jenq-Neng Hwang. Ace: Ally complementary experts for solving long-tailed recognition in one-shot. In _Proceedings of the IEEE/CVF International Conference on Computer Vision_, pages 112-121, 2021.
* [4] Kaidi Cao, Colin Wei, Adrien Gaidon, Nikos Arechiga, and Tengyu Ma. Learning imbalanced datasets with label-distribution-aware margin loss. _Advances in neural information processing systems_, 32, 2019.
* [5] Nitesh V Chawla, Kevin W Bowyer, Lawrence O Hall, and W Philip Kegelmeyer. Smote: synthetic minority over-sampling technique. _Journal of artificial intelligence research_, 16:321-357, 2002.
* [6] Deli Chen, Yankai Lin, Guangxiang Zhao, Xuancheng Ren, Peng Li, Jie Zhou, and Xu Sun. Topology-imbalance learning for semi-supervised node classification. _Advances in Neural Information Processing Systems_, 34:29885-29897, 2021.
* [7] Yoav Freund and Robert E Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. _Journal of computer and system sciences_, 55(1):119-139, 1997.
* [8] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial networks. _Communications of the ACM_, 63(11):139-144, 2020.
* [9] Will Hamilton, Zhitao Ying, and Jure Leskovec. Inductive representation learning on large graphs. _Advances in neural information processing systems_, 30, 2017.
* [10] Hui Han, Wen-Yuan Wang, and Bing-Huan Mao. Borderline-smote: a new over-sampling method in imbalanced data sets learning. In _International conference on intelligent computing_, pages 878-887. Springer, 2005.
* [11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectifiers: Surpassing human-level performance on imagenet classification. In _Proceedings of the IEEE international conference on computer vision_, pages 1026-1034, 2015.

* [12] Youngkyu Hong, Seungju Han, Kwanghee Choi, Seokjun Seo, Beomsu Kim, and Buru Chang. Disentangling label distribution for long-tailed visual recognition. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pages 6626-6636, 2021.
* [13] Nathalie Japkowicz and Shaju Stephen. The class imbalance problem: A systematic study. _Intelligent data analysis_, 6(5):429-449, 2002.
* [14] Bingyi Kang, Saining Xie, Marcus Rohrbach, Zhicheng Yan, Albert Gordo, Jiashi Feng, and Yannis Kalantidis. Decoupling representation and classifier for long-tailed recognition. In _International Conference on Learning Representations_, 2019.
* [15] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. _arXiv preprint arXiv:1412.6980_, 2014.
* [16] Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. _arXiv preprint arXiv:1609.02907_, 2016.
* [17] Bolian Li, Baoyu Jing, and Hanghang Tong. Graph communal contrastive learning. In _The Web Conference_, 2022.
* [18] Xu-Ying Liu, Jianxin Wu, and Zhi-Hua Zhou. Exploratory undersampling for class-imbalance learning. _IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)_, 39(2):539-550, 2008.
* [19] Yang Liu, Xiang Ao, Zidi Qin, Jianfeng Chi, Jinghua Feng, Hao Yang, and Qing He. Pick and choose: a gnn-based imbalanced learning approach for fraud detection. In _Proceedings of the Web Conference 2021_, pages 3168-3177, 2021.
* [20] Zhining Liu, Pengfei Wei, Jing Jiang, Wei Cao, Jiang Bian, and Yi Chang. Mesa: boost ensemblable imbalanced learning with meta-sampler. _Advances in Neural Information Processing Systems_, 33:14463-14474, 2020.
* [21] Aditya Krishna Menon, Sadeep Jayasumana, Ankit Singh Rawat, Himanshu Jain, Andreas Veit, and Sanjiv Kumar. Long-tail learning via logit adjustment. _arXiv preprint arXiv:2007.07314_, 2020.
* [22] Mohammadreza Mohammadrezaei, Mohammad Ebrahim Shiri, and Amir Masoud Rahmani. Identifying fake accounts on social networks based on graph analysis and classification algorithms. _Security and Communication Networks_, 2018, 2018.
* [23] Brady Neal, Sarthak Mittal, Aristide Baratin, Vinayak Tantia, Matthew Scicluna, Simon Lacoste-Julien, and Ioannis Mitliagkas. A modern take on the bias-variance tradeoff in neural networks. _arXiv preprint arXiv:1810.08591_, 2018.
* [24] Joonhyung Park, Jaeyun Song, and Eunho Yang. Graphens: Neighbor-aware ego network synthesis for class-imbalanced node classification. In _International Conference on Learning Representations_, 2021.
* [25] Liang Qu, Huaisheng Zhu, Ruiqi Zheng, Yuhui Shi, and Hongzhi Yin. Imgagn: Imbalanced network embedding via generative adversarial graph networks. In _Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining_, pages 1390-1398, 2021.
* [26] Jiawei Ren, Cunjun Yu, Xiao Ma, Haiyu Zhao, Shuai Yi, et al. Balanced meta-softmax for long-tailed visual recognition. _Advances in neural information processing systems_, 33:4175-4186, 2020.
* [27] Jose A Saez, Julian Luengo, Jerzy Stefanowski, and Francisco Herrera. Smote-ipf: Addressing the noisy and borderline examples problem in imbalanced classification by a re-sampling method with filtering. _Information Sciences_, 291:184-203, 2015.
* [28] Min Shi, Yufei Tang, Xingquan Zhu, David Wilson, and Jianxun Liu. Multi-class imbalanced graph convolutional network learning. In _Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence (IJCAI-20)_, 2020.

* [29] Michael R Smith, Tony Martinez, and Christophe Giraud-Carrier. An instance level analysis of data complexity. _Machine learning_, 95(2):225-256, 2014.
* [30] Kihyuk Sohn, David Berthelot, Nicholas Carlini, Zizhao Zhang, Han Zhang, Colin A Raffel, Ekin Dogus Cubuk, Alexey Kurakin, and Chun-Liang Li. Fixmatch: Simplifying semi-supervised learning with consistency and confidence. _Advances in neural information processing systems_, 33:596-608, 2020.
* [31] Jaeyun Song, Joonhyung Park, and Eunho Yang. Tam: Topology-aware margin loss for class-imbalanced node classification. In _International Conference on Machine Learning_, pages 20369-20383. PMLR, 2022.
* [32] Kaihua Tang, Jianqiang Huang, and Hanwang Zhang. Long-tailed classification by keeping the good and removing the bad momentum causal effect. _Advances in Neural Information Processing Systems_, 33:1513-1524, 2020.
* [33] Yuchun Tang, Yan-Qing Zhang, Nitesh V Chawla, and Sven Krasser. Svms modeling for highly imbalanced classification. _IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)_, 39(1):281-288, 2008.
* [34] Junjiao Tian, Yen-Cheng Liu, Nathaniel Glaser, Yen-Chang Hsu, and Zsolt Kira. Posterior re-calibration for imbalanced datasets. _Advances in Neural Information Processing Systems_, 33:8101-8113, 2020.
* [35] Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. Graph attention networks. _arXiv preprint arXiv:1710.10903_, 2017.
* [36] Petar Velickovic, William Fedus, William L Hamilton, Pietro Lio, Yoshua Bengio, and R Devon Hjelm. Deep graph infomax. 2018.
* [37] Jianfeng Wang, Thomas Lukasiewicz, Xiaolin Hu, Jianfei Cai, and Zhenghua Xu. Rsg: A simple but effective module for learning imbalanced datasets. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pages 3784-3793, 2021.
* [38] Tong Wang, Yousong Zhu, Chaoyang Zhao, Wei Zeng, Jinqiao Wang, and Ming Tang. Adaptive class suppression loss for long-tail object detection. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pages 3103-3112, 2021.
* [39] Xudong Wang, Long Lian, Zhongqi Miao, Ziwei Liu, and Stella X Yu. Long-tailed recognition by routing diverse distribution-aware experts. _arXiv preprint arXiv:2010.01809_, 2020.
* [40] Zheng Wang, Xiaojun Ye, Chaokun Wang, Jian Cui, and S Yu Philip. Network embedding with completely-imbalanced labels. _IEEE Transactions on Knowledge and Data Engineering_, 33(11):3634-3647, 2020.
* [41] Qizhe Xie, Zihang Dai, Eduard Hovy, Thang Luong, and Quoc Le. Unsupervised data augmentation for consistency training. _Advances in neural information processing systems_, 33:6256-6268, 2020.
* [42] Ziyu Xu, Chen Dan, Justin Khim, and Pradeep Ravikumar. Class-weighted classification: Trade-offs and robust approaches. In _International Conference on Machine Learning_, pages 10544-10554. PMLR, 2020.
* [43] Liang Yan, Shengzhong Zhang, Bisheng Li, min zhou, and Zengfeng Huang. UNREAL: Unlabeled nodes retrieval and labeling for heavily-imbalanced node classification, 2023.
* [44] Zhilin Yang, William Cohen, and Ruslan Salakhudinov. Revisiting semi-supervised learning with graph embeddings. In _International conference on machine learning_, pages 40-48. PMLR, 2016.
* [45] Zitong Yang, Yaodong Yu, Chong You, Jacob Steinhardt, and Yi Ma. Rethinking bias-variance trade-off for generalization of neural networks. In _International Conference on Machine Learning_, pages 10767-10777. PMLR, 2020.

* [46] Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. Graph convolutional neural networks for web-scale recommender systems. In _Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining_, pages 974-983, 2018.
* [47] Yuning You, Tianlong Chen, Yongduo Sui, Ting Chen, Zhangyang Wang, and Yang Shen. Graph contrastive learning with augmentations. _Advances in neural information processing systems_, 33:5812-5823, 2020.
* [48] Bowen Zhang, Yidong Wang, Wenxin Hou, Hao Wu, Jindong Wang, Manabu Okumura, and Takahiro Shinozaki. Flexmatch: Boosting semi-supervised learning with curriculum pseudo labeling. _Advances in Neural Information Processing Systems_, 34:18408-18419, 2021.
* [49] Hengrui Zhang, Qitian Wu, Junchi Yan, David Wipf, and Philip S. Yu. From canonical correlation analysis to self-supervised graph neural networks. In _Advances in Neural Information Processing Systems_, 2021.
* [50] Tianxiang Zhao, Xiang Zhang, and Suhang Wang. Graphsmote: Imbalanced node classification on graphs with graph neural networks. In _Proceedings of the 14th ACM international conference on web search and data mining_, pages 833-841, 2021.
* [51] Yizhen Zheng, Shirui Pan, Vincent C. S. Lee, Yu Zheng, and Philip S. Yu. Rethinking and scaling up graph contrastive learning: An extremely efficient approach with group discrimination. In _Advances in Neural Information Processing Systems_, 2022.
* [52] Boyan Zhou, Quan Cui, Xiu-Shen Wei, and Zhao-Min Chen. Bbn: Bilateral-branch network with cumulative learning for long-tailed visual recognition. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pages 9719-9728, 2020.
* [53] Zhi-Hua Zhou and Xu-Ying Liu. Training cost-sensitive neural networks with methods addressing the class imbalance problem. _IEEE Transactions on knowledge and data engineering_, 18(1):63-77, 2005.
* [54] Yanqiao Zhu, Yichen Xu, Feng Yu, Qiang Liu, Shu Wu, and Liang Wang. Deep graph contrastive representation learning. In _International Conference on Machine Learning Workshop on Graph Representation Learning and Beyond_, 2020.
* [55] Yanqiao Zhu, Yichen Xu, Feng Yu, Qiang Liu, Shu Wu, and Liang Wang. Graph contrastive learning with adaptive augmentation. In _The Web Conference_, 2021.

Other related work

Imbalanced Learning in Traditional ML.Most real-world data is naturally imbalanced, presenting a significant challenge in training fair models that are not biased towards majority classes. To address this problem, various approaches have been commonly utilized. Ensemble learning [7, 18, 52, 39, 20, 3] combines the outputs of multiple weak classifiers. Data re-sampling methods [5, 10, 29, 27, 14, 37] aim to adjust the label distribution in the training set by synthesizing or duplicating samples from the minority class. Another approach tackles the imbalance issue by modifying the loss function, assigning larger weights to minority classes or adjusting the margins between different classes [53, 33, 4, 32, 42, 26, 38]. Post-hoc correction methods compensate for the imbalanced classes during the inference step, after completing the model training [14, 34, 21, 12]. Although these techniques have been extensively applied to i.i.d. data, extending them to graph-structured data poses non-trivial challenges.

Graph Contrastive Learning.Contrastive methods, which have proven effective for unsupervised learning in vision, have also been adapted for graph data. One notable approach is DGI [36], which presents a framework for unsupervised node-level representation learning that maximizes global mutual information. Other approaches, such as GRACE [54], GCA [55], and GraphCL [47], utilize augmented graphs to optimize the similarity between positive node pairs and minimize negative pairs. CCA-SSG [49] introduces an efficient loss function based on canonical correlation analysis, eliminating the need for negative samples. Incorporating community information, gCooL [17] enhances node representations and downstream task performance. GGD [51] simplifies the mutual information loss function by directly discriminating between two sets of node samples, resulting in faster computation and lower memory usage. These contrastive methods exhibit potential for improving unsupervised learning on graph data. However, it is important to note that our model operates within the context of semi-supervised learning, which significantly differs from the mechanisms employed by these models.

Proofs

### Proofs of Theorem 1

**Theorem 1**: _Under the condition that \(\sum_{i=1}^{c}n_{i}\) is a constant, the variance \(\sum_{i=1}^{c}\mathbb{E}_{x}\left[\frac{1}{n_{i}}h^{T}(x)\Lambda^{i}h(x)\right]\) reach its minimum when all \(n_{i}\) equal._

_Proof_ The expression \(\sum_{i=1}^{c}\mathbb{E}_{x}\left[\frac{1}{n_{i}}h^{T}(x)\Lambda^{i}h(x)\right]\) can be equivalently expressed as \(\sum_{i=1}^{c}\frac{1}{n_{i}}\mathbb{E}_{x}\left[h^{T}(x)\Lambda^{i}h(x)\right]\). As previously assumed, the \(\mathbb{E}_{x}[h^{T}(x)\Lambda^{i}h(x)]\) is the same for different \(i\), which implies that our goal is to demonstrate that \(\sum_{i=1}^{c}\frac{1}{n_{i}}\) is minimized when all \(n_{i}\) are equal.

Let \(m\) be \(\sum_{i=1}^{c}n_{i}\). We wish to find the extremum of the sum of their reciprocals, which is given by

\[S=\frac{1}{n_{1}}+\frac{1}{n_{2}}+\cdots+\frac{1}{n_{c}}. \tag{10}\]

Using the inequality of arithmetic and harmonic means, we have

\[\frac{c}{\frac{1}{n_{1}}+\frac{1}{n_{2}}+\cdots+\frac{1}{n_{c}}}\leq\frac{n_{1 }+n_{2}+\cdots+n_{c}}{c}, \tag{11}\]

with equality if and only if \(n_{1}=n_{2}=\cdots=n_{c}\). Rearranging, we get

\[\frac{c^{2}}{n_{1}+n_{2}+\cdots+n_{c}}\leq S, \tag{12}\]

with equality if and only if \(n_{1}=n_{2}=\cdots=n_{c}\). Since \(m=n_{1}+n_{2}+\cdots+n_{c}\), we have

\[\frac{c^{2}}{m}\leq S, \tag{13}\]

with equality if and only if \(n_{1}=n_{2}=\cdots=n_{c}=\frac{m}{c}\). Therefore, when all the \(c\) numbers are equal, the sum of their reciprocals is minimized and given by \(S=\frac{c^{2}}{m}\).

We can also use the method of Lagrange multipliers. Let \(f(n_{1},n_{2},\ldots,a_{c})=\frac{1}{n_{1}}+\frac{1}{n_{2}}+\ldots+\frac{1}{ n_{c}}\) be the function that we want to extremize. Then, the Lagrangian is:

\[\mathcal{L}(n_{1},n_{2},\ldots,n_{c},\lambda)=f(n_{1},n_{2},\ldots,n_{c})+ \lambda(n_{1}+n_{2}+\ldots+n_{c}-m). \tag{14}\]

Taking the partial derivatives of \(\mathcal{L}\) with respect to \(a_{i}\) and \(\lambda\), we get:

\[\begin{split}\frac{\partial\mathcal{L}}{\partial n_{i}}& =-\frac{1}{n_{i}^{2}}+\lambda\\ \frac{\partial\mathcal{L}}{\partial\lambda}&=n_{1}+n_ {2}+\ldots+n_{c}-m.\end{split} \tag{15}\]

Setting these partial derivatives to zero, we get:

\[n_{1}=n_{2}=\ldots=n_{c}=\frac{m}{c},\lambda=\frac{c^{2}}{m^{2}}. \tag{16}\]

Thus, when the \(c\) numbers are equal, their reciprocal sum is minimized and is equal to \(\frac{c^{2}}{m}\). Moreover, since \(S\) is a continuously differentiable function of \(n_{1},n_{2},\ldots,n_{c}\), this extremum is a minimum.

Therefore, we have shown that the reciprocal sum of \(c\) numbers with a sum of \(m\) is minimized and equal to \(\frac{c^{2}}{m}\) when the \(c\) numbers are equal.

Proofs of Lemma 1 and More Details for Estimating the Expectation with Unlabeled Nodes (Section 3.2)

#### b.2.1 Proofs of Lemma 1

**Lemma 1**: _Under the above assumption for \(h^{i}\sim N(\mu^{i},\Lambda^{i})\), \(C^{i}\sim N\left(\mu^{i},\frac{1}{n_{i}}\Lambda^{i}\right)\), minimizing the \(\sum_{i=1}^{c}\mathbb{E}_{x}\left[\mathrm{Var}(x)\right]\) is equivalent to minimizing Equation 17:_

\[\frac{1}{N}\sum_{x\in G}\sum_{i=1}^{c}\left(h(x)^{T}\frac{1}{\sqrt{2n_{i}}} \left(h_{1}^{i}-h_{2}^{i}\right)\right)^{2}=\frac{1}{N}\sum_{k=1}^{n_{j}}\sum _{j=1}^{c}\sum_{i=1}^{c}\left((\mu_{k}^{j}+\epsilon_{k}^{j})^{T}\frac{1}{\sqrt {2n_{i}}}\left(\epsilon_{1}^{i}-\epsilon_{2}^{i}\right)\right)^{2}. \tag{17}\]

_Proof_ Let \(\epsilon^{i}\) denote \(h^{i}-\mu^{i}\), which follows the distribution \(\epsilon^{i}\sim N(0,\Lambda^{i})\). Similarly, we denote \(e^{i}=C^{i}-\mu^{i}\) and it follows that \(e^{i}\sim N\left(0,\frac{1}{n_{i}}\Lambda^{i}\right)\).

We know

\[\text{Var}(x) =\sum_{i=1}^{c}\mathbb{E}_{D}\left[\left(h^{T}(x)C^{i}-\mathbb{E} _{D}\left[h^{T}(x)C^{i}\right]\right)^{2}\right]\] \[=\sum_{i=1}^{c}\mathbb{E}_{e^{i}}\left[\left(h^{T}(x)(\mu^{i}+e^{ i})-h^{T}(x)\mu^{i}\right)^{2}\right] \tag{18}\] \[=\sum_{i=1}^{c}\mathbb{E}_{e^{i}}\left[\left(h^{T}(x)e^{i}\right) ^{2}\right]\;=\sum_{i=1}^{c}\frac{1}{n_{i}}h^{T}(x)\Lambda^{i}h(x),\]

so we get

\[\sum_{i=1}^{c}\mathbb{E}_{x}\left[\mathrm{Var}(x)\right]=\sum_{i=1}^{c}\mathbb{ E}_{x}\left[\frac{1}{n_{i}}h^{T}(x)\Lambda^{i}h(x)\right]. \tag{19}\]

Motivated by stochastic gradient descent, we opt to sample an \(e^{i}\) on each occasion and compute, as opposed to directly calculating the expectation \(\mathbb{E}_{D\subset G}\).

At present, we remain uncertain about how to sample the noise term \(e^{i}\) associated with the class center \(C_{i}\). We put forth a proposition to estimate the class center noise \(e\) utilizing the feature noise \(\epsilon\). Under the supposition that when \(v\in C_{k}\), the \(j_{th}\) element of the feature \(f(v)\) adheres to a Gaussian distribution:

\[\epsilon^{i}\sim N\left(0,\Lambda^{i}\right),\;e^{i}\;\sim\;N\left(0,\frac{1}{ n_{i}}\Lambda^{i}\right). \tag{20}\]

Consequently, multiplying the noise term \(\epsilon^{i}\) in Equation 20 by \(\frac{1}{\sqrt{n_{i}}}\) yields a random variable that exhibits an identical distribution to \(e^{i}\):

\[\frac{1}{\sqrt{n_{i}}}\epsilon^{i}\sim N\left(0,\frac{1}{n_{i}}\Lambda^{i}\right) \tag{21}\]

Moreover, how might we compute \(\varepsilon_{i}\)? In practical scenarios, we merely possess the feature \(h\). However, we are able to calculate the disparity between two features, \(h_{1}^{i}\) and \(h_{2}^{i}\), originating from the same class \(i\):

\[\frac{1}{\sqrt{2n_{i}}}\;\left(h_{1}^{i}-h_{2}^{i}\right)=\frac{1}{\sqrt{2n_{ i}}}(\epsilon_{1}-\epsilon_{2})\sim N\left(0,\frac{1}{n_{i}}\Lambda^{i} \right). \tag{22}\]

Incorporating this into Equation 19, the loss is expressed as:

\[\frac{1}{N}\sum_{x\in G}\sum_{i=1}^{c}\left(h(x)^{T}\frac{1}{\sqrt{2n_{i}}}\; \left(h_{1}^{i}-h_{2}^{i}\right)\right)^{2}. \tag{23}\]

\(\square\)

#### b.2.2 More Details for Estimating the Expectation with Unlabeled Nodes (Section 3.2)

Lemma 1 suggests that \(\sum_{i=1}^{c}\mathbb{E}_{x}\left[\mathrm{Var}(x)\right]\) can be estimated by sampling labeled node pairs \((h_{1}^{i},h_{2}^{i})\) from the same class \(i\). However, due to the scarcity of data in the minority class, this can often be challenging. In Section 3.2, we address this issue by utilizing random data augmentation and defining nodes from different views as members of the same class, enabling us to sample node pairs for Equation 3 and perform embedding subtraction.

However, as we mentioned, the pseudo node pairs lack information regarding their class membership, making it impossible to assign appropriate \(\frac{\Gamma}{\sqrt{2n_{i}}}\) values for different \(i\) in Equation 3. These coefficients play a crucial role in compensating for the minority class, making it imperative to reintroduce information about the class number when constructing variance regularization. Therefore, in the second step, we replace \(h\) in Equation 3 with the class center \(C^{i}\), as demonstrated in Equation 4. As \(C^{i}=\mu^{i}+e^{i}\) and the variance of \(e^{i}\) is proportional to \(\frac{1}{n_{i}}\), using Equation 4 to estimate Lemma 1 can provide similar compensatory effects for the minority class. We present the proof for the aforementioned propositions below.

_Proof_ Firstly, the \(\sum_{i=1}^{c}\mathbb{E}_{x}\left[\mathrm{Var}(x)\right]\) can be decomposed as follows:

\[\sum_{i=1}^{c}\mathbb{E}_{x}\left[\mathrm{Var}(x)\right]=\frac{1} {N}\sum_{x\in G}\sum_{i=1}^{c}\left(h(x)^{T}\frac{1}{\sqrt{2n_{i}}}\ \left(h_{1}^{i}-h_{2}^{i}\right)\right)^{2} \tag{24}\] \[=\frac{1}{N}\sum_{k=1}^{n_{j}}\sum_{j=1}^{c}\sum_{i=1}^{c}\left( \left(\mu_{k}^{j}+\epsilon_{k}^{j}\right)^{T}\frac{1}{\sqrt{2n_{i}}}\ \left(h_{1}^{i}-h_{2}^{i}\right)\right)^{2}\] \[=\frac{1}{N}\sum_{k=1}^{n_{j}}\sum_{j=1}^{c}\sum_{i=1}^{c}\left( \left(\mu_{k}^{j}\right)^{T}\frac{1}{\sqrt{2n_{i}}}\ \left(\epsilon_{1}^{i}- \epsilon_{2}^{i}\right)+(\epsilon_{k}^{j})^{T}\frac{1}{\sqrt{2n_{i}}}\ \left( \epsilon_{1}^{i}-\epsilon_{2}^{i}\right)\right)^{2}\] \[=\underbrace{\frac{1}{2N}\sum_{k=1}^{n_{j}}\sum_{j=1}^{c}\sum_{i= 1}^{c}\left(\frac{1}{n_{i}}\left[\left(\mu_{k}^{j}\right)^{T}\ \left(\epsilon_{1}^{i}-\epsilon_{2}^{i}\right)\right]^{2}\right)}_{\mathcal{T}_{i}}+ \underbrace{\frac{1}{2N}\sum_{k=1}^{n_{j}}\sum_{j=1}^{c}\sum_{i=1}^{c}\left( \frac{1}{n_{i}}\left[\left(\epsilon_{k}^{j}\right)^{T}\ \left(\epsilon_{1}^{i}-\epsilon_{2}^{i}\right)\right]^{2}\right)}_{\mathcal{T}_{2}}\] \[+\underbrace{\frac{1}{N}\sum_{k=1}^{n_{j}}\sum_{j=1}^{c}\sum_{i= 1}^{c}\left(\frac{1}{n_{i}}\left[\left(\mu_{k}^{j}\right)^{T}\ \left(\epsilon_{1}^{i}-\epsilon_{2}^{i}\right)\left(\epsilon_{k}^{j}\right)^{T}\ \left(\epsilon_{1}^{i}-\epsilon_{2}^{i}\right)\right]\right)}_{\mathcal{T}_{3}}\]

The above Equation can be decomposed into three parts, namely \(\mathcal{T}_{1}\), \(\mathcal{T}_{2}\), and \(\mathcal{T}_{3}\). Notably, each of these parts is associated with weight \(\frac{1}{n_{i}}\). This observation supports Theorem 1 and Lemma 1, which suggest that the variance of a model is highly dependent on the distribution of the dataset's sample size, and that the extent of sample imbalance can significantly increase the model's variance.

Note that \(\epsilon^{i}\sim N(0,\Lambda^{i})\), \(e^{i}\sim N\left(0,\frac{1}{n_{i}}\Lambda^{i}\right)\), and so \(\frac{1}{\sqrt{n_{i}}}\epsilon^{i}\sim N\left(0,\frac{1}{n_{i}}\Lambda^{i}\right)\). So, if we use the class center \(C^{i}\) to replace \(h\) in Equation 3, then we can get the following expression,\[\begin{split}&\frac{1}{N}\sum_{x\in G}\sum_{i=1}^{c}\left((C^{i})^{T}h( x)-(C^{i^{\prime}})^{T}h^{\prime}(x)\right)^{2}\\ =&\frac{1}{N}\sum_{k=1}^{n_{j}}\sum_{j=1}^{c}\sum_{i= 1}^{c}\left((\mu^{i})^{T}(\epsilon_{k}^{j}-\epsilon_{k}^{j^{\prime}})+(e^{i})^{ T}\epsilon_{k}^{j}-(e^{i^{\prime}})^{T}\epsilon_{k}^{j^{\prime}}\right)^{2}\\ =&\frac{1}{N}\sum_{k=1}^{n_{j}}\sum_{j=1}^{c}\sum_{i= 1}^{c}\left((\mu^{i})^{T}(\epsilon_{k}^{j}-\epsilon_{k}^{j^{\prime}})+(\ \frac{1}{\sqrt{n_{i}}}\epsilon^{i})^{T}\epsilon_{k}^{j}-(\ \frac{1}{\sqrt{n_{i}}}\epsilon^{i})^{T}\epsilon_{k}^{j^{\prime}}\right)^{2}\\ =&\frac{1}{N}\sum_{k=1}^{n_{i}}\sum_{i=1}^{c}\sum_{j= 1}^{c}\left((\mu^{j})^{T}(\epsilon_{k}^{i}-\epsilon_{k}^{i^{\prime}})+(\ \frac{1}{\sqrt{n_{j}}}\epsilon^{j})^{T}\epsilon_{k}^{i}-(\ \frac{1}{\sqrt{n_{j}}}\epsilon^{j})^{T}\epsilon_{k}^{i^{\prime}}\right)^{2}\\ =&\frac{1}{N}\sum_{k=1}^{n_{i}}\sum_{i=1}^{c}\sum_{j= 1}^{c}\left((\mu^{j})^{T}(\epsilon_{k}^{i}-\epsilon_{k}^{i^{\prime}})+(\ \frac{1}{\sqrt{n_{j}}}\epsilon^{j})^{T}(\epsilon_{k}^{i}-\epsilon_{k}^{i^{ \prime}})\right)^{2}\\ =&\underbrace{\frac{1}{N}\sum_{k=1}^{n_{i}}\sum_{i= 1}^{c}\sum_{j=1}^{c}\left(\left[(\mu^{j})^{T}(\epsilon_{k}^{i}-\epsilon_{k}^{i^{ \prime}})\right]^{2}\right)}_{\mathcal{L}_{1}}+\underbrace{\frac{1}{N}\sum_{k=1}^{n_{i}} \sum_{i=1}^{c}\sum_{j=1}^{c}\left(\frac{1}{n_{j}}\left[(\ \epsilon^{j})^{T}(\epsilon_{k}^{i}-\epsilon_{k}^{i^{\prime}})\right]^{2}\right)} _{\mathcal{L}_{2}}\\ &+\underbrace{\frac{2}{N}\sum_{k=1}^{n_{i}}\sum_{i=1}^{c}\sum_{j= 1}^{c}\left(\frac{1}{\sqrt{n_{j}}}\left[(\mu^{j})^{T}(\epsilon_{k}^{i}- \epsilon_{k}^{i^{\prime}})(\ \epsilon^{j})^{T}(\epsilon_{k}^{i}-\epsilon_{k}^{i^{\prime}})\right]\right)}_{ \mathcal{L}_{3}}\end{split} \tag{25}\]

Like the previous Equation 24, Equation 25 can be decomposed into three parts: \(\mathcal{L}_{1}\), \(\mathcal{L}_{2}\), and \(\mathcal{L}_{3}\). If we substitute the class center \(C^{i}\) for \(h\), we can observe that even though \(\mathcal{L}_{1}\) is insensitive to class imbalance, variables \(\mathcal{L}_{2}\) and \(\mathcal{L}_{3}\), which respectively incorporate weights \(\frac{1}{n_{j}}\) and \(\frac{1}{\sqrt{n_{j}}}\), can still provide the following support: when optimizing the variance of the model, more attention can be given to the variance introduced by the minority classes, which also provides an innovative perspective for understanding class imbalance on graphs.

[MISSING_PAGE_FAIL:19]

demonstrating that our model still achieves state-of-the-art performance. In contrast, oversampling methods such as GraphSMOTE perform poorly on this dataset due to overfitting limitations. We believe that our model's ability to regularize variance from a bottom-up perspective contributes to its superior performance on naturally imbalanced graphs, while also demonstrating its powerful generalization capabilities.

More Analysis

### More Ablation Analysis for the Loss Function

Details of Experimental Setup.We conduct more experiments on imbalance ratio 10 (\(\rho=10\)) for the datasets CiteSeer and PubMed. For each GNN network, we add one loss regularization at a time, i.e. for GCN, we gradually add \(\mathcal{L}_{\mathrm{IR}}\), \(\mathcal{L}_{\mathrm{VR}}\) from the initial \(\mathcal{L}_{\mathrm{sup}}\). The architecture we employed consisted of a 2-layers graph neural network (GNN) with 128 hidden dimensions, using GCN [16], GAT [35], and GraphSAGE [9]. The models were trained for 2000 epochs.

Analysis.Figure 4 reports more experiments for each component in the loss function. As we have seen, each component of the loss function can bring an improvement in the training effect. It is worth noting that in most cases \(\mathcal{L}_{\mathrm{VR}}\) has a larger effect boost than \(\mathcal{L}_{\mathrm{IR}}\). We believe that \(\mathcal{L}_{\mathrm{VR}}\) plays a more important role in the loss function.

### More Experiments for Variance and Imbalance Ratio Correlation in Theorem 1

Details of Experimental Setup.In this experiment, the classifier is not MLP, which means that the probability of a node \(v\) being classified into class \(i\) depends on the distance of this node from the center of class \(i\). We classify half of the classes as majority classes and the other half as minority classes. Initially, each class in majority classes and minority classes has 200 labeled nodes. To generate different imbalance scenarios (\(\rho\)), we reduce the number of labeled nodes in the minority class by 1 and add 1 to the number of labeled nodes in the majority class each time, so as to keep the number of samples in the training set consistent and eliminate the effect of the sample size variance in the training set. To calculate the variance of the model under a certain imbalance ratio (\(\rho\)), we repeat 20 times to randomly select different but the same number of training sets, and train 2000 epochs for each fixed training set. The architecture we employed consisted of a 2-layers graph neural network (GNN) with 128 hidden dimensions, using GCN [16], GAT [35], and GraphSAGE [9].

Figure 4: More Ablation Analysis for the Loss Function.

Figure 5: More experiments for variance and imbalance ratio correlation in Theorem 1.

Hypothesis testing.To test the correlation between the variance and imbalance ratio, we computed the Pearson correlation coefficient (\(\rho\)) between variance and imbalance ratio (log), as presented in the table below. The Pearson correlation coefficient, denoted as \(r\), is a prevalent metric for gauging linear correlations. This coefficient lies between (-1) and (1),and reflects both the magnitude and direction of the correlation between two variables. An (\(r\)) value greater than (0.5) indicates a strong positive correlation. Furthermore, the p-value results from a hypothesis test with the null hypothesis (\(H_{0}:\rho=0\)) and the alternative hypothesis (\(H_{1}:\rho\neq 0\)), where represents the population correlation coefficient.

Given that the Pearson correlation coefficient between variance and imbalance ratio exceeds (0.5), and the p-value is below (0.01), we deduce that there is a robust correlation between variance and imbalance ratio. This relationship is statistically significant at the (0.01) significance level.

Analysis.Figure 5 reveals an intriguing pattern, as the majority of data points closely align along a regression curve exhibiting a positive slope. This observation provides substantial evidence that establishes a strong and direct linear relationship between the imbalance ratio (\(\rho\)) and the associated variance. Consequently, our findings provide compelling support for the hypothesis postulated in Theorem 1.

### More Experiments for Hyperparameter Sensitivity Analysis of ReVar

Details of Experimental Setup.We implemented experiments on the two datasets, CiteSeer and Amazon-Computers. In this experiment, we evaluate the F1 score when we fix one \(\lambda\) while the other changes. The architecture we employed consisted of a 2-layer graph neural network (GNN) with 128 hidden dimensions, using GCN [16], GAT [35], and GraphSAGE [9]. The models were trained for 2000 epochs.

Analysis.In Figure 6, we present the sensitivity analysis of ReVar to two weight hyperparameters (\(\lambda_{1}\), \(\lambda_{2}\)) in the loss function on the CiteSeer and Amazon-Computers. It is evident that ReVar exhibits varying degrees of sensitivity to hyperparameters on different datasets. Specifically, the model demonstrates lower sensitivity to a and b on CiteSeer, while the opposite is observed on Amazon-Computers. We postulate that the number of nodes (i.e., dataset size) may be a crucial factor in this discrepancy. Nevertheless, the optimal range of hyperparameter selection appears to be relatively narrow, indicating that significant efforts are not be required for model fine-tuning.

### More Results of loss curve and F1 score

Details of Experimental Setup.We implemented experiments on three datasets PubMed, CiteSeer and Amazon-Computers. We compare our method ReVar and other vanilla models (only using cross-entropy and not using graph augmentation). The architecture we employed for ReVar and

Figure 6: More Experiments of Hyperparameter Sensitivity Analysis for ReVar.

vanilla model consisted of a 2-layer graph neural network (GNN) with 128 hidden dimensions, using GCN [16], GAT [35], and GraphSAGE [9]. The models were trained for 2000 epochs.

Analysis.We plot the loss curve and F1 score with epoch on the PubMed and Computers datasets. By analyzing the plotted loss curves, we observe that our model demonstrates notable advantages, including faster convergence of the loss curves and improved performance across multiple datasets. For the F1 score, our model consistently outperforms alternative approaches, showcasing its superior capability in effectively capturing the complex relationships within the data and making accurate predictions.

Figure 7: More analysis of loss curve and F1 score.

Elaboration of the experimental setup

In this section, we present our approach for constructing imbalanced datasets, describe our evaluation protocol, and provide comprehensive details on our algorithm as well as the baseline methods utilized in our study. To achieve this, we leverage sophisticated techniques and utilize advanced metrics to ensure the reliability and relevance of our results.

### Construction for Imbalanced datasets

The detailed descriptions of the datasets are shown in Table 5. The details of label distribution in the training set of the five imbalanced benchmark datasets are in Table 7, and the label distribution of the full graph is provided in Table 7.

Imbalanced datasets construction for Traditional Semi-supervised Settings.For each citation dataset, we adopt the "public" split and apply a random undersampling technique to make the class distribution imbalanced until the target imbalance ratio \(\rho\) is achieved. Specifically, we convert the minority class nodes to unlabeled nodes in a random manner. Regarding the co-purchased networks Amazon-Computers, we conduct replicated experiments by randomly selecting nodes as the training set in each trial. We create a random validation set that contains 30 nodes in each class, and the remaining nodes are used as the testing set.

Imbalanced datasets construction for Naturally Imbalanced Datasets.For _Computers-Random_ and _CS-Random_, we constructed a training set with equal proportions based on the label distribution of the complete graph (Amazon-Computers). The label distributions for the training sets of _Computers-Random_ and _CS-Random_ are presented in Table 7. To achieve this, we employed a stratified sampling approach that ensured an unbiased representation of all labels in the training set.

### Architecture of GNNs

We conducted evaluations using three classic GNN architectures, namely GCN [16], GAT [35], and GraphSAGE [9]. The GNN models were constructed with different numbers of layers, namely \(L=1,2,3\). To enhance the learning process, each GNN layer was accompanied by a BatchNorm layer with a momentum of 0.99, followed by a PRelu activation function [11]. For the GAT architecture, we employed multi-head attention with 8 heads. We search for the best model on the validation set. The available choices for the hidden unit sizes were 64, 128, and 256.

\begin{table}
\begin{tabular}{l|c c c c c c c c c c c c c} \hline \hline
**Dataset** & **Nodes** & **Edges** & **Features** & **Classes** \\ \hline _Cora_ & 2,708 & 5,429 & 1,433 & 7 \\ _Citeseer_ & 3,327 & 4,732 & 3,703 & 6 \\ _Pubmed_ & 19,717 & 44,338 & 500 & 3 \\ _Amazon-Computers_ & 13,752 & 491,722 & 767 & 10 \\ _CountuM-CS_ & 18,333 & 163,788 & 6,805 & 15 \\ \hline \hline \end{tabular}
\end{table}
Table 5: Summary of the datasets used in this work.

\begin{table}
\begin{tabular}{l|c c c c c c c c c c c c c} \hline \hline
**Dataset** & \(G_{0}\) & \(C_{1}\) & \(C_{2}\) & \(C_{3}\) & \(C_{4}\) & \(C_{5}\) & \(C_{6}\) & \(C_{7}\) & \(C_{8}\) & \(C_{9}\) & \(C_{10}\) & \(C_{11}\) & \(C_{12}\) & \(C_{13}\) & \(C_{14}\

### Evaluation Protocol

We utilized the Adam optimizer [15] with an initial learning rate of 0.01 or 0.005. To manage the learning rate, we employed a scheduler based on the approach outlined in [31], which reduced the learning rate by half when there was no decrease in validation loss for 100 consecutive epochs. Weight decay with a rate of 0.0005 was applied to all learnable parameters in the model. In the initial training iteration, we trained the model for 200 epochs using the original training set for Cora, CiteSeer, PubMed, or Amazon-Computers. However, for Flickr, the training was extended to 2000 epochs in the first iteration. Subsequently, in the remaining iterations, we trained the models for 2000 epochs using the aforementioned optimizer and scheduler. The best models were selected based on validation accuracy, and we employed early stopping with a patience of 300 epochs.

### Technical Details of ReVar

For all datasets _Cora-Semi_, _CiteSeer-Semi_, _PubMed-Semi_, _Computers-Semi_, _Computers-Random_ and _CS-Random_, the learning rate \(\eta\) is chosen from \(\{0.0001,0.0005,0.001,0.005,0.01,0.1\}\). The temperature hyperparameter \(\tau\) is chosen from \(\{0.05,0.08,0.13,0.16,0.21,0.23,0.26\}\). The threshold \(v\) is chosen from \(\{0.6,0.63,0.66,0.7,0.8,0.83,0.9,0.93,0.96,0.99\}\). The factor \(\lambda_{1}\) of \(\mathcal{L}_{\mathrm{VR}}\) is chosen from \(\{0.25,0.35,0.5,0.85,1,1.5,2,2.15,2.65,3\}\). The factor \(\lambda_{2}\) of \(\mathcal{L}_{\mathrm{IR}}\) is chosen from \(\{0.35,0.5,1,1.25,1.5,2.85,3\}\). The factors of mask node properties and edges in \(\tilde{G}\) are chosen from \(\{0.4,0.45,0.5,0.6,0.65,0.7\}\) and \(\{0.4,0.45,0.5,0.55,0.6,0.65,0.7\}\). The factors of mask node properties and edges in \(\tilde{G}^{\prime}\) are chosen from \(\{0.1,0.15,0.2,0.3,0.4,0.45\}\) and \(\{0.1,0.15,0.2,0.3,0.35,0.4,0.45\}\).

### Technical Details of Baselines

For the GraphSMOTE method [50], we employed the branched algorithms whose edge predictions are discrete-valued, which have achieved superior performance over other variants in most experiments. Regarding the ReNode method [6], we search hyperparameters within the lower bound of cosine annealing, \(w_{\min}\in 0.25,0.5,0.75\), and the upper bound range, \(w_{\max}\in 1.25,1.5,1.75\), as suggested in [6]. The PageRank teleport probability was fixed at \(\alpha=0.15\), which is the default setting in the released codes. As for TAM [31], we performed a hyperparameter search for the coefficient of the ACM term, \(\alpha\in 1.25,1.5,1.75\), the coefficient of the ADM term, \(\beta\in 0.125,0.25,0.5\), and the minimum temperature of the class-wise temperature, \(\phi\in 0.8,1.2\), following the approach described in [31]. The sensitivity to the imbalance ratio of the class-wise temperature, \(\delta\), was fixed at 0.4 for all the main experiments. Additionally, consistent with [31], we implemented a warmup phase for 5 iterations, as we utilized model predictions for unlabeled nodes.

### Configuration

All the algorithms and models are implemented in Python and PyTorch Geometric. Experiments are conducted on a server with an NVIDIA 3090 GPU (24 GB memory) and an Intel(R) Xeon(R) Silver 4210R CPU @ 2.40GHz.

Algorithm

```
1:Imbalanced Graph \(\mathbf{G}=(\mathbf{V},\mathbf{E},\mathbf{V_{L}})\), feature matrix \(\mathbf{X}\), adjacency matrix \(\mathbf{A}\), unlabeled set \(\mathbf{V_{U}}=\mathbf{V}-\mathbf{V_{L}}\), label matrix \(\mathbf{Y}\), feature matrix of labeled nodes and unlabeled nodes \(\mathbf{X_{L}}\) and \(\mathbf{X_{U}}\), the number of classes \(\mathbf{k}\), the threshold \(v\) for determining whether a node has confident prediction, temperature hyperparameter \(\tau\), GNN model \(f_{\theta}\), the classifier \(h_{\theta}\), learning rate \(\eta\), The total number \(T\) of epochs for model training. The \(\mathrm{sim}(\cdot,\cdot)\) computes the cosine similarity between two vectors, \(\mathit{CE}\) represents the cross-entropy loss function, and \(\mathbb{I}(\cdot)\) is an indicator function.
2:for\(t=0,1,\ldots,T\)do
3: Generate two differently augmented views \(\tilde{G}=(\tilde{\Lambda},\tilde{\mathrm{X}})\) and \(\tilde{G}^{\prime}=(\tilde{\Lambda}^{\prime},\tilde{\mathrm{X}}^{\prime})\) from original graph \(\mathbf{G}\).
4:\(\tilde{\mathbf{O}}_{L}\gets f_{\theta}(\tilde{\Lambda},\tilde{\mathrm{X} }_{L})\), \(\tilde{\mathbf{O}}_{U}\gets f_{\theta}(\tilde{\Lambda},\tilde{\mathrm{X}} _{U})\)
5:\(\tilde{\mathbf{O}}_{L}^{\prime}\leftarrow f_{\theta}(\tilde{\Lambda}^{\prime}, \tilde{\mathrm{X}}_{L}^{\prime})\), \(\tilde{\mathbf{O}}_{U}^{\prime}\leftarrow f_{\theta}(\tilde{\Lambda}^{\prime},\tilde{\mathrm{X}}_{U}^{\prime})\)
6:% Component 1: Supervised Loss
7:\(\mathcal{L}_{sup}\leftarrow\frac{1}{2}\mathit{CE}(h_{\theta}(\tilde{\mathbf{O} }_{L}),\mathrm{Y})+\frac{1}{2}\mathit{CE}(h_{\theta}(\tilde{\mathbf{O}}_{U}^{ \prime}),\mathrm{Y})\)
8:% Component 2: Intra-Class Aggregation Regularization
9:\(\mathcal{L}_{\mathrm{IR}}\leftarrow-\frac{1}{N_{U}}\sum_{i=1}^{N_{U}}\mathrm{ sim}(\tilde{\mathbf{O}}_{i},\tilde{\mathbf{O}}_{i}^{\prime})\)\(-\)\(\frac{1}{N_{all}}(\sum_{i=1}^{N_{L}}\sum_{{{}_{(i,j)\in same}}}^{N_{L}}\mathrm{sim}(\tilde{ \mathbf{O}}_{i},\tilde{\mathbf{O}}_{j}^{\prime})\)\(+\)\(\sum_{i=1}^{N_{L}}\sum_{{{}_{(i,j)\in same}}}^{N_{L}}\mathrm{sim}(\tilde{\mathbf{O}}_{i},\tilde{ \mathbf{O}}_{j})\)
10:% Component 3: Variance-constrained Optimization with Adaptive Regularization
11:for i = 1, 2,..., \(k\)do
12: Compute the class centers \(\tilde{\mathbf{C}}_{i}\) and \(\tilde{\mathbf{C}^{\prime}}_{i}\) for class \(i\)
13:endfor
14:\(\triangleright\) Obtain the Label Probability for Each Node
15:for\(i=1,2,\ldots,|\mathbf{V}|\)do
16:\(\tilde{\mathbf{p}}_{i}\leftarrow\mathrm{Softmax}(\tilde{\mathbf{O}}_{i}\cdot \left[\tilde{\mathbf{C}}_{1},\ldots,\tilde{\mathbf{C}}_{k}\right]^{T})\)
17:\(\tilde{\mathbf{p}}_{i}^{\prime}\leftarrow\mathrm{Softmax}\left(\tilde{\mathbf{O} }_{i}^{\prime}\cdot\left[\tilde{\mathbf{C}^{\prime}}_{1},\ldots,\tilde{\mathbf{ C}^{\prime}}_{k}\right]^{T}\right)\)
18:endfor
19:\(\triangleright\) Eliminate Nodes with Low Confidence.
20:\(\mathbf{V}_{\text{conf}}\leftarrow\{i\mid\mathbb{I}\left(\mathrm{max}(\tilde{ \mathbf{p}}_{i}^{\prime})>v\right)=1,\forall i\in V_{U}\}\)
21:\(\triangleright\) Replace Labeled Node Prediction
22:for\(i=1,2,\ldots,|\mathbf{V_{L}}|\)do
23:\(\tilde{\mathbf{p}}_{i}^{\prime}\leftarrow\mathbf{Y}_{i}\)
24:endfor
25:\(\mathcal{L}_{\mathbf{VR}}\leftarrow\frac{1}{|\mathbf{V_{\text{conf}}}|}\sum_ {i\in V_{\text{conf}}}\mathit{CE}(\tilde{\mathbf{p}}_{i}^{\prime},\tilde{ \mathbf{p}}_{i})+\frac{1}{|V_{L}|}\sum_{v_{i}\in V_{L}}\mathit{CE}(\mathbf{Y} _{i},\tilde{\mathbf{p}}_{i})\)
26:\(\mathcal{L}_{Training}\leftarrow\mathcal{L}_{sup}+\lambda_{1}\mathcal{L}_{VR}+ \lambda_{2}\mathcal{L}_{IR}\)
27:\(\theta\leftarrow\theta-\eta\left(\nabla\mathcal{L}_{Training}\right)\)
28:endfor
```

**Algorithm 1**_ReVar_

[MISSING_PAGE_EMPTY:27]