# Causal Inference using LLM-Guided Discovery

Aniket Vashishtha1, Abbavaram Gowtham Reddy2, Abhinav Kumar3,

**Saketh Bachu2, Vineeth N Balasubramanian2, Amit Sharma1**

###### Abstract

At the core of causal inference lies the challenge of recovering the underlying causal graphs based on observational data. Recent work aggregates the results of edge-wise prompts to infer the full graph structure using Large Language Models (LLMs). However, graph structure cannot be identified uniquely using such localized prompts for each edge since the existence of an edge depends on which other nodes are included in the node set. Therefore, we propose a simpler property of the causal graph, the _topological order_, that can be estimated reliably using localized LLM prompts. Moreover, for downstream tasks like effect inference, the topological order is sufficient to identify causal effect. Hence we LLMs as virtual domain experts and propose a novel localized prompt based on triplets to infer the causal order. Acknowledging LLMs' limitations, we also study possible techniques to integrate LLMs with established causal discovery algorithms, including constraint-based and score-based methods. Extensive experiments demonstrate that our approach significantly improves causal ordering accuracy as compared to discovery algorithms, and in turn decreases the error of downstream effect estimation algorithms.

1Microsoft Research, India

2IIT Hyderabad, India

3Massachusetts Institute of Technology, USA

{t-aniketva, amshar}@microsoft.com,

{cs19resch11002, vineethnb, saketh.bachu}@cse.iith.ac.in, akumar03@mit.edu

## 1 Introduction

A key question for studies across scientific fields such as epidemiology, economics, and atmospheric sciences is estimating the _causal effects_ of variables on an outcome variable. Inferring causal effects from observational data, however, is a difficult task because the effect estimate depends on the causal graph considered in the analysis. While there has been progress in graph discovery algorithms, especially for specific parametric settings Shimizu et al. (2006); Hoyer et al. (2008); Hyvarinen et al. (2010); Rolland et al. (2022), studies on real-world datasets such as from atmospheric science and healthcare Huang et al. (2021); Tu et al. (2019) show that inferring the causal graph from data remains a challenging problem in practice Reisach et al. (2021). Therefore, causal effect inference studies often rely on a human expert to provide the causal graph.

In this paper, based on the fact that the _topological causal order_ over the graph variables is enough for effect inference (see Proposition 4.1), we leverage LLMs as virtual domain experts to propose an automated method to obtain causal order (and hence causal effect). Moreover, providing the _order_ between variables is the right question to ask experts because it depends only on the variables under question, unlike the existence of a graph _edge_ that depends on which other variables are present (to account for direct and indirect effects). For example, consider the data-generating process, _lung cancer_\(\rightarrow\)_doctor visit_\(\rightarrow\)_positive Xray_. If asked, an expert would affirm a causal edge from _lung cancer_ to _positive Xray_ (indeed, such an edge exists in the BNLearn _Cancer_ dataset Scutari and Denis (2014)). However, if they are told that the set of observed variables additionally includes _doctor visit_, then the correct answer would be to not create a direct edge between lung cancer and positive Xray, but rather create edges mediated through _doctor visit_. Note that the causal order, _lung cancer_\(\rightarrow\)_positive Xray_ remains invariant in both settings.

This observation has implications on using LLMs for inferring graph structure, where existing work prompts the LLM about each causal edge separately Kociman et al. (2023); Long et al. (2022). As we argued above, accuracy of such pairwise prompting is not reliable since it depends critically on which other nodes are included in the node set. The simple solution of constructing a prompt that includes all other nodes may be infeasible, especially for large graphs. As a result, we argue that graph structure may not be a suitable output to expect from LLMs (or any other expert). Instead, our main insight is that a simpler graph property, the causal order, can be inferred locally and is not affected by availability of other nodes. Moreover, for downstream tasks like effect inference, the causal order is sufficient to identify the causal effect; full graph structure is not necessary. Our empirical results on six benchmark datasets show that LLMs like GPT-3.5 and GPT-4 can approximate experts' causal order capabilities. To do so, we propose a novel triplet-based prompting strategy that performs better than pairwise prompts Kociman et al. (2023); Willig et al. (2022); Long et al. (2022) for determining the causal order. The triplet prompt also produces significantly lesser cycles in the output graph.

Still, LLMs can exhibit unknown failure modes. Therefore, we propose two algorithms to combine existing graph discovery algorithms with LLMs: one employs LLM causal order to guide a constraint-based algorithm (e.g., PC) in orienting undirected edges, while the second incorporates LLM causal order as a prior for a score-based algorithm like CaMML. We find that LLM-enhanced algorithms outperform base causal discovery methods in inferring causal order. The methodology is illustrated in Figure 1. Our contributions include,

* We propose prompting strategies for estimating the order using LLMs, which is more reliable than estimating the graph structure using LLMs.
* We propose algorithms for inferring causal order using a novel triplet prompting strategy, using only LLMs and combining them with existing discovery algorithms.

## 2 Related Work

Historically, causal discovery [1, 16, 17, 18] and causal effect inference [15] have been studied separately. Instead of using the learned graph for effect inference [1, 16, 17, 18], demonstrate a simpler combination of approaches: causal order suffices instead of the entire graph.

Our work is related to LLM-based knowledge-driven causal discovery [15, 16, 17, 18]. Unlike causal discovery algorithms that use statistical patterns in the data, LLM-based algorithms use metadata such as variable names. These methods use LLMs to predict causal structure over a set of variables by aggregating the results of an edge-wise prompt for each pair of variables [15, 16, 17, 18]. Instead, we show that the existence of an edge may not be identified if we do not know other existing variables; hence causal order is a more suitable output to elicit from LLMs. We also propose a triplet-based prompt for inferring the causal order, which may be of independent interest in prompting LLMs for causality.

Since LLMs may exhibit errors, a more principled approach may be to combine LLMs with existing discovery algorithms. [16] use LLM to improve the output of a constraint-based algorithm for full graph discovery and [16] use LLMs as priors for existing score-based causal discovery methods. We extend this idea to causal order estimation by proposing LLM-adaptations for constraint- and score-based algorithms.

## 3 Background and Problem Formulation

Let \(\mathcal{G}(\mathbf{X},\mathbf{E})\) be a causal directed acyclic graph (DAG) consisting of a set of variables \(\mathbf{X}=\{X_{1},\ldots,X_{n}\}\) and a set of directed edges \(\mathbf{E}\) among the variables in \(\mathbf{X}\). A directed edge \(X_{i}\to X_{j}\in\mathbf{E}\) denotes the _direct_ causal influence of the variable \(X_{i}\) on the variable \(X_{j}\). Let \(pa(X_{i})=\{X_{k}|X_{k}\to X_{i}\}\), \(de(X_{i})=\{X_{k}|X_{k}\leftarrow\cdots\gets X_{i}\}\) denote the set of _parents_ and _descendants_ of \(X_{i}\) respectively. A sequence \(\pi\) of variables \(\mathbf{X}\) is said to be a topological order iff for each edge \(X_{i}\to X_{j}\in\mathbf{E}\), \(\pi_{i}<\pi_{j}\).

We focus on a downstream application of causal graph discovery called causal effect inference. The average causal effect (ACE) of a variable \(X_{i}\) on a variable \(X_{j}\) is defined as \(ACE_{X_{i}}^{X_{j}}=\mathbb{E}[X_{j}|do(X_{i}=x_{i})]-\mathbb{E}[X_{j}|do(X_{i }=x_{i}^{*})]\)[15]. Here, \(X_{i}\) is called the _treatment_ variable and \(X_{j}\) is called the _target_ variable. \(do(X_{i}=x_{i})\) denotes an external intervention to the variable \(X_{i}\) with the value \(x_{i}\). The interventional quantity \(\mathbb{E}[X_{j}|do(X_{i}=x_{i})]\) is different from conditional \(\mathbb{E}[X_{j}|X_{i}=x_{i}]\) since it involves setting the value of \(X_{i}\) rather than conditioning on it. To estimate the quantity \(\mathbb{E}[X_{j}|do(X_{i}=x_{i})]\) from observational data, the back-door adjustment formula [15] is used. Given a DAG \(\mathcal{G}\), a set of variables \(\mathbf{Z}\) satisfies back-door criterion relative to a pair of treatment and

Figure 1: The _LLM-augmented_ causal inference process based on inferring causal order. We propose a triplet-based prompting technique to infer all three-variable subgraphs and aggregate them using majority voting to produce a causal order. The causal order (optionally combined with discovery algorithms like PC or CaMML) can then be used to identify a valid back-door adjustment set. Ties in causal order are broken using GPT-4.

target variables (\(X_{i},X_{j}\)) if (i) no variable in \(\mathbf{Z}\) is a descendant of \(X_{i}\); and (ii) \(\mathbf{Z}\) blocks every path between \(X_{i}\) and \(X_{j}\) that contains an arrow into \(X_{i}\). Where a _path_ in a causal DAG is a sequence of unique vertices \(X_{i},X_{i+1},\ldots,X_{j}\) with a directed edge between each consecutive vertices \(X_{k}\) and \(X_{k+1}\) (either \(X_{k}\to X_{k+1}\) or \(X_{k+1}\to X_{k}\)). If a set of variables \(\mathbf{Z}\) satisfies the back-door criterion relative to \((X_{i},X_{j})\), \(\mathbb{E}[X_{j}|do(X_{i}=x_{i})]\) can be computed using the formula: \(\mathbb{E}[X_{j}|do(X_{i}=x_{i})]=\mathbb{E}_{\mathbf{z}\sim\mathbf{Z}} \mathbb{E}[X_{j}|X_{i}=x_{i},\mathbf{Z}=\mathbf{z}]\) (Theorem 3.3.2 of Pearl (2009)). To ensure causal effect identifiability, we make the no-latent confounding assumption.

## 4 Causal Order Suffices for Effect Estimation

We start with the fact in Proposition 4.1 that the causal order is sufficient to find a valid back-door set and discuss why causal order is easier to elicit from experts than the DAG.

### Causal Order Provides a Valid Back-Door Set

**Proposition 4.1**.: _(Pearl 2009; Cinelli, Forney, and Pearl 2022a) Under the no-latent confounding assumption, given a pair of treatment and target variables \((X_{i},X_{j})\), \(\mathbf{Z}=\{X_{k}|\pi_{k}<\pi_{i}\}\) is a valid adjustment set relative to \((X_{i},X_{j})\) for any topological order \(\pi\) of nodes \(X_{i},\ldots,X_{n}\)._

Proofs of all propositions are in Appendix SSA. Prop. 4.1 states that all the variables that precede the treatment variable in a topological order \(\pi\) of \(\mathcal{G}\) constitute a valid adjustment set. Note that the set \(\mathbf{Z}\) may contain variables that are not necessary to adjust for, e.g., ancestors of only treatment or only target variables. For statistical estimation, ancestors of target variable are beneficial for precision whereas ancestors of treatment can be harmful (Cinelli, Forney, and Pearl 2022b). On balance though, causal effect practitioners tend to include all confounders that do not violate the back-door criterion; we are following the same principle. In practice, however, we may not know the true order. To evaluate the goodness of a given causal order, we use the topological divergence metric from (Rolland et al., 2022) (for an example, see Fig. 3). The topological divergence of an estimated topological order \(\hat{\pi}\) with ground truth adjacency matrix \(A\), denoted by \(D_{top}(\hat{\pi},A)\), is defined as \(D_{top}(\hat{\pi},A)=\sum_{i=1}^{n}\sum_{j:\hat{\pi}_{i}>\hat{\pi}_{j}}A_{ij}\). Where \(A_{ij}=1\) if there is a directed arrow from node \(i\) to \(j\) else \(A_{ij}=0\). \(D_{top}(\hat{\pi},A)\) counts the number of edges that cannot be recovered due to the estimated topological order \(\hat{\pi}\).

### \(\mathbf{D_{top}}\) Is a Valid Metric for Effect Estimation

Below, we show that \(D_{top}\) is a valid metric to check the correctness of the estimated causal effects. That is \(D_{top}(\hat{\pi},A)\) being \(0\) is equivalent to obtaining the correct back-door adjustment set from \(\hat{\pi}\) (Proposition 4.1).

**Proposition 4.2**.: _For an estimated topological order \(\hat{\pi}\) and a true topological order \(\pi\) of a causal DAG \(\mathcal{G}\) with the corresponding adjacency matrix \(A\), \(D_{top}(\hat{\pi},A)=0\) iff \(\mathbf{Z}=\{X_{k}|\hat{\pi}_{k}<\hat{\pi}_{i}\}\) is a valid adjustment set relative to \((X_{i},X_{j})\), \(\forall\pi_{i}<\pi_{j}\)._

We now compare \(D_{top}\) to structural hamming distance (SHD), a common metric for evaluating graph discovery algorithms. Given a true causal DAG \(\mathcal{G}\) and an estimated causal DAG \(\hat{\mathcal{G}}\), SHD counts the number of missing, falsely detected, and falsely directed edges in \(\hat{\mathcal{G}}\). We note that SHD can be very high even when \(D_{top}=0\) and a valid back-door set can still be inferred. This result is of significance since most estimated graphs (included those that are LLM-generated (Ban et al., 2023; Long et al., 2023)) are evaluated on SHD.

**Proposition 4.3**.: _In a causal DAG \(\mathcal{G}\) with \(N\) levels in the level-ordering of variables where the level \(i\) contains \(n_{i}\) variables,\(\exists\,\hat{\mathcal{G}}\) s.t. \(SHD(\hat{\mathcal{G}},\mathcal{G})\geq\sum\limits_{i=1}^{N-1}(n_{i}\times \sum\limits_{j=i+1}^{N}n_{j})-|\mathbf{E}|\) and \(D_{top}(\hat{\pi},A)=0\)\(\forall\hat{\pi}\) of \(\hat{\mathcal{G}}\)._

where a level order refers to a systematic assignment of levels to variables. This assignment begins with the set of variables \(\{X_{i}|\text{pa}(X_{i})=\emptyset\}\) at level 0. Subsequently, each of the remaining variables is assigned a level \(i\) such that all nodes within a given level \(i\) has a directed path of length \(i\) from one/more nodes in level 0. Figure 2 shows the limitations of SHD empirically. Given a fixed number of nodes, we sample a graph at random as the 'ground-truth' and then consider all graph orientations of the same size (number of nodes) such that \(D_{top}=0\) with respect to ground-truth graph. For this set of graphs, we compute the SHD with respect to the ground-truth graph. Notice that SHD exhibits high variance. For graphs with six nodes, SHD can vary from 0 to 14 even as \(D_{top}=0\) and back-door set validity stays the same. Fig. 3 shows this phenomenon on a real-world BNLearn dataset, _Cancer_. The estimated graph (right panel) has \(D_{top}=0\) with respect to the true graph (left) and yields valid back-door identification sets. However, its SHD is high (6), showing the disconnect between SHD and causal effect identification.

Figure 3: **Left:** Causal graph of Cancer dataset. **Right:** GPT-3.5’s estimated causal graph. GPT-3.5 gets causal order correct at the cost of higher SHD score Here \(D_{top}=0\) and \(SHD=6\)

Figure 2: Variability of SHD with consistent \(D_{top}=0\).

[MISSING_PAGE_FAIL:4]

### Prompt Technique Based on Triplets

As we shall see, while pairwise prompts are conceptually simple, they are prone to yielding higher number of cycles in the graph since they decide about each edge separately. Taking inspiration from the PC algorithm that employs constraints over three variables, we now describe a prompting technique based on iterating over all possible triplets given a set of nodes. Once the LLM has provided subgraphs for each triplet, we determine causal order between a pair by aggregating over all triplet LLM answers where the pair was included.

The algorithm has the following steps after generating all possible triplets from a set of nodes. **1)** Generate subgraphs over all triplets through LLMs by prompting them to orient the three causal edges for each triplet. **2)** Merge the resultant structure between any two nodes by aggregating the number of LLM answers for the three orientations: (A \(\rightarrow\) B; B \(\rightarrow\) A; No connection) and choosing the majority answer. If there's a tie in edge orientation, GPT-4 is used with a CoT prompt to make the final decision. Then the causal order is extracted from the graph.

## 6 LLM-Guided Discovery Algorithms

Causal order from LLMs may exhibit unknown failure modes [10]. Hence we now provide algorithms for combining LLMs with causal discovery paradigms.

* **Constraint-based Algorithm**: Given a graph from constraint based algorithm like PC where some edges are not oriented, we use the causal order \(\hat{\pi}\) from LLM to orient the undirected edges. Iterating over the undirected edges, we first check if the nodes of that edge are occurring in \(\hat{\pi}\). If yes, we orient the edge according to the causal order. Since there is a possibility that LLM's final graph might have some isolated nodes which won't be in \(\hat{\pi}\), therefore if either (or both) nodes of the undirected edge are not included in \(\hat{\pi}\), we query GPT-4 using pairwise CoT prompt (from Sec. 5.1) to finalise a direction between the pair. Refer to Algorithm 1 in Appendix.
* **Score-based Algorithm**: We provide the level order of the causal graph returned by LLM as a prior for a score-based algorithm. Optionally, we can provide prior probability to control the influence of prior on the algorithm. Algorithm 2 in Appendix outlines the steps to combine score based method and the prior level order of variables.

## 7 Experiments and Results

To evaluate the accuracy of LLM-based algorithms on inferring causal order, we perform experiments on the benchmark datasets from Bayesian network repository [13]: Earthquake, Cancer, Survey, Asia, Asia modified (Asia-M), and Child (see AppendixS D for details). We also used a medium sized subset graph from the Neuropathic dataset [23] used for pain diagnosis.

\(\mathbf{D_{top}}\)**correlates with effect estimation error:** Before comparing methods on the \(D_{top}\) metric, we first show that \(D_{top}\) has a strong correlation with effect estimation error and hence is the correct metric for effect inference. Specifically, we study how the error in causal effect, \(\epsilon_{ACE}\), changes as values of the metrics \(SHD,D_{top}\) change. In each graph, we evaluate causal effects of each variable on a specified target variable. We iterate through estimated causal graphs with different values of SHD and \(D_{top}\) and report the mean absolute difference between estimated and true causal effects. As Table 2 shows, when \(D_{top}\) is zero, effect error \(\epsilon_{ACE}\) is also zero. And as \(D_{top}\) increases (right panel), effect error increases. In contrast, SHD has no correlation with the \(\epsilon_{ACE}\).

**Triplet prompting is most accurate for causal order:** Comparing prompting techniques (Tab. 3), we observe limitations with pairwise prompts as graph size increases. They often lead to significantly high cycles, making \(D_{top}\) calculation infeasible. Notably, for the 20-node Child dataset, pairwise prompts result in thousands of cycles. Similar trends can be seen for Neuropathic graph as well. Among pairwise prompts, the chain-of-thought prompt achieves the lowest SHD for the small graphs and the fewest cycles for Child and Neuropathic. This highlights the effectiveness of in-context examples and chain-of-thought reasoning in improving causal order accuracy. The triplet prompt yields highly accurate causal order predictions. For all small graphs, number of cycles are 0 and \(D_{top}\) is either 0 or 1. Additionally, the LLM output has lowest SHD. While the number of cycles increases when scaled to larger graphs (Child and Neuropathic), the numer is still significantly much smaller than cycles in pairwise output (all setups included).

Since pairwise orientations yielded substantially more cycles then triplet (see Table 3), we applied a cycle removal algorithm to triplet output only, to use it as prior for discovery algorithms. Our cycle removal algorithm is inspired from [11]. In the original approach, the algorithm minimizes edges to form a weighted DAG. As our noisy expert graphs lack edge weights, we leverage triplet pipeline votes to establish a probability distribution for edge orientations. Using this, we calculate the entropy for eachedge, removing those with higher entropy (lower confidence). To minimize \(D_{top}\), we pruned edges with entropy below the mean of all entropies. However, optimizing the threshold and minimizing edges for a DAG increased connected nodes but also led to a higher \(D_{top}\), diminishing the quality of the prior and causing poor causal discovery performance. Since pruning edges to remove cycles in the pairwise case would have resulted in a non-significant prior, we only apply this on triplet prompting where cycle removal is feasible.

**LLMs improve causal order accuracy of existing discovery algorithms:** We investigate if LLM output enhances causal order inference accuracy in discovery algorithms. We compare against widely used methods: PC (Spirtes, Glymour, and Scheines 2000), SCORE (Rolland et al. 2022), ICA-LiNGAM (Shimizu et al. 2006), Direct-LiNGAM (Shimizu et al. 2011), NOTEARS (Zheng et al. 2018), and CaMML (Wallace, Korb, and Dai 1996) across sample sizes: \(250,500,1000,5000,10000\) (refer Table 1 for full results). We employ the triplet prompt with LLM. Table 1 presents the \(D_{top}\) metric for different algorithms and compares it with PC+LLM and CaMML+LLM. PC and CaMML exhibit superior performance with the lowest \(D_{top}\) among the discovery algorithms.LLM output reduces \(D_{top}\) in both algorithms. PC+LLM exhibits substantial improvements, particularly at lower sample sizes, implying LLM's significance in limited data settings. Transitioning from CaMML to CaMML+LLM also shows significant \(D_{top}\) reductions, with benefits even at higher sample sizes. For instance, at sample size 10000, CaMML+LLM outperforms CaMML by a factor of three for Child and five for Asia. These findings underscore the substantial enhancement LLMs provide to causal discovery algorithms.

## 8 Limitations and Conclusions

We presented causal order as a suitable metric for evaluating quality of causal graphs for downstream effect inference tasks. Using a novel formulation of LLM prompts based on triplets, we showed that LLMs can be useful in the generating accurate causal order, both individually and in combination with existing discovery algorithms. That said, one limitation is that we studied LLMs utility on popular benchmarks which may have been partially memorized. It will be interesting to extend our experiments to more datasets and tasks. Also, we focused on one causal task, viz. effect inference, in this work; identifying suitable metrics for tasks such as causal prediction and counterfactual inference and extending to other tasks in causal inference may be useful directions for future work.

## References

* Tan et al. (2023) Ban, T.; Chen, L.; Wang, X.; and Chen, H. 2023. From Query Tools to Causal Architects: Harnessing Large Language Models for Advanced Causal Discovery from Data. _arXiv preprint arXiv:2306.16902_.
* Brown et al. (2016) Brown, T. B.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J.; Dhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell, A.; Agarwal, S.; Herbert-Voss, A.; Krueger, G.; Henighan, T.; Child, R.; Ramesh, A.; Ziegler, D. M.; Wu, J.; Winter, C.; Hesse, C.; Chen, M.; Sigler, E.; Litwin, M.; Gray, S.;

\begin{table}
\begin{tabular}{l|c c c c} \hline \hline
**Dataset** & **D\({}_{\text{top}}\)** & **SHD** & **IN/TN** & **Cycles** \\ \hline \multicolumn{5}{c}{Base Prompt} \\ \hline Earthquake & 0 & 7 & 0/5 & 0 \\ Cancer & 0 & 6 & 0/5 & 0 \\ Survey & 3 & 12 & 0/6 & 0 \\ Asia & - & 21 & 0/8 & 1 \\ Asia-M & - & 15 & 0/7 & 7 \\ Child & - & 177 & 0/20 & \(>>\)3k \\ Neuropathic & - & 212 & 0/22 & \(>>\)5k \\ \hline \multicolumn{5}{c}{All Directed Edges} \\ \hline Earthquake & 1 & 9 & 0/5 & 0 \\ Cancer & 1 & 7 & 0/5 & 0 \\ Survey & 2 & 11 & 0/6 & 0 \\ Asia & - & 21 & 0/8 & 6 \\ Asia-M & 0 & 13 & 0/7 & 0 \\ Child & - & 139 & 0/20 & \(>>\)300 \\ Neuropathic & - & 194 & 0/22 & \(>>\)1k \\ \hline \multicolumn{5}{c}{Markov Blanket} \\ \hline Earthquake & 0 & 8 & 0/5 & 0 \\ Cancer & 0 & 6 & 0/5 & 0 \\ Survey & 3 & 12 & 0/6 & 0 \\ Asia & - & 21 & 0/8 & 1 \\ Asia-M & 0 & 14 & 0/7 & 0 \\ Child & - & 167 & 0/20 & \(>>\)400 \\ Neuropathic & - & 204 & 0/22 & \(>>\)4k \\ \hline \multicolumn{5}{c}{Chain of Thought} \\ \hline Earthquake & 0 & 4 & 0/5 & 0 \\ Survey & 1 & 9 & 2/6 & 0 \\ Asia & - & 18 & 0/8 & 1 \\ Asia-M & - & 13 & 0/7 & 1 \\ Child & - & 138 & 0/20 & \(>>\)500 \\ Neuropathic & - & 64 & 0/22 & \(>\)4 \\ \hline \multicolumn{5}{c}{Triplet Prompt} \\ \hline Earthquake & 0 & 4 & 0/5 & 0 \\ Cancer & 1 & 6 & 0/5 & 0 \\ Survey & 0 & 9 & 0/6 & 0 \\ Asia & 1 & 14 & 0/8 & 0 \\ Asia-M & 1 & 11 & 0/7 & 0 \\ Child & - & 138 & 0/20 & \(>\)63 \\ Child (+ Cycle Remover) & 1 & 28 & 10/20 & 0 \\ Neuropathic & - & 151 & 0/22 & \(>\)145 \\ Neuropathic(+ Cycle remover) & 3 & 24 & 13/20 & 0 \\ \hline \hline \end{tabular}
\end{table}
Table 3: Comparison of various prompting strategies for only LLM based setups. IN: Isolated Nodes, TN:Total Nodes. CoT (Cancer not included since CoT prompt has examples from this graph). Calculating total cycles in a DAG is NP-Hard. We estimate a lower bound using cycles of length k (k=5). Scaling k increases unique cycles in the graph significantly. However, Triplet setup gives significantly lesser cycles, with total number of cycles for Child = 391 and Neuropathic = 772.

Cited by: SS2.2.
* B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, and D. Amodei (2020)Language models are few-shot learners. CoRRabs/2005.14165. External Links: Link, 2005.14165 Cited by: SS2.2.
* C. Cinelli, A. Forney, and J. Pearl (2022)A crash course in good and bad controls. Sociological Methods & Research, pp. 00491241221099552. External Links: Link, 2005.14165 Cited by: SS2.2.
* C. Glymour, K. Zhang, and P. Spirtes (2019)Review of causal discovery methods based on graphical models. Frontiers in genetics10, pp. 524. External Links: Link, Document Cited by: SS2.2.
* S. Gupta, D. Childers, and Z. C. Lipton (2022)Local causal discovery for estimating causal effects. In NeurIPS 2022 Workshop on Causality for Real-world Impact, Cited by: SS2.2.
* P. Hoyer, D. Janzing, J. M. Mooij, J. Peters, and B. Scholkopf (2008)Nonlinear causal discovery with additive noise models. In Advances in Neural Information Processing Systems, H. Koller, D. Schuurmans, Y. Bengio, and L. Bottou (Eds.), pp.. External Links: Link Cited by: SS2.2.
* Y. Huang, M. Kleindessner, A. Munishkin, D. Varshney, P. Guo, and J. Wang (2021)Benchmarking of data-driven causality discovery approaches in the interactions of arctic sea ice and atmosphere. Frontiers in big Data4, pp. 642182. External Links: Link, 2005.14165 Cited by: SS2.2.
* A. Hyvarinen, K. Zhang, S. Shimizu, and P. O. Hoyer (2010)Estimation of a structural vector autoregression model using non-Gaussianity. Journal of Machine Learning Research11 (56), pp. 1709-1731. External Links: Link, Document Cited by: SS2.2.
* E. Kiciman, R. Ness, A. Sharma, and C. Tan (2023)Causal reasoning and large language models: opening a new frontier for causality. arXiv preprint arXiv:2305.00050. Cited by: SS2.2.
* S. Lachapelle, P. Brouillard, T. Deleu, and S. Lacoste-Julien (2020)Gradient-based neural DAG learning. In ICLR, Cited by: SS2.2.
* S. Long, A. Piche, V. Zantedeschi, T. Schuster, and A. Drouin (2023)Causal discovery with language models as imperfect experts. In ICML 2023 Workshop on Structured Probabilistic Inference & Generative Modeling, Cited by: SS2.2.
* S. Long, T. Schuster, and A. Piche (2022)Can large language models build causal graphs?. In NeurIPS 2022 Workshop on Causality for Real-world Impact, Cited by: SS2.2.
* M. H. Maathuis, D. Colombo, M. Kalisch, and P. Buhlmann (2010)Predicting causal effects in large-scale systems from observational data. Nature methods7 (4), pp. 247-248. External Links: Link, 1004.12412 Cited by: SS2.2.
* J. M. Mooij, J. Peters, D. Janzing, J. Zscheischler, and B. Scholkopf (2016)Distinguishing cause from effect using observational data: methods and benchmarks. The Journal of Machine Learning Research17 (1), pp. 1103-1204. External Links: Link, 1602.02101 Cited by: SS2.2.
* J. Pearl (2009)Causality. Cambridge university press. External Links: Link Cited by: SS2.2.
* J. Peters and P. Buhlmann (2015)Structural intervention distance for evaluating causal graphs. Neural computation27 (3), pp. 771-799. External Links: Link, 1506.00050 Cited by: SS2.2.
* A. Reisach, C. Seiler, and S. Weichwald (2021)Beware of the Simulated DAG! Causal Discovery Benchmarks May Be Easy to Game. In NeurIPS, H. Ranzato, A. Beygelzimer, Y. Dauphin, P. Liang, and J. W. Vaughan (Eds.), pp. 27772-27784. External Links: Link, 2104.1241 Cited by: SS2.2.
* P. Rolland, V. Cevher, M. Kleindessner, C. Russell, D. Janzing, B. Scholkopf, and F. Locatello (2022)Score matching enables causal discovery of nonlinear additive noise models. In ICML, Cited by: SS2.2.
* M. Scutari and J. Denis (2014)Bayesian networks: with examples in R. Chapman & Hall/CRC Texts in Statistical Science, Taylor & Francis. External Links: Link Cited by: SS2.2.
* S. Shimizu, P. O. Hoyer, A. Hyvarinen, A. Kerminen, and M. Jordan (2006)A linear non-Gaussian acyclic model for causal discovery. JMLR7 (10). Cited by: SS2.2.
* S. Shimizu, T. Inazumi, Y. Sogawa, A. Hyvarinen, Y. Kawahara, T. Washio, P. O. Hoyer, K. Bollen, and P. Hoyer (2011)DirectLiNGAM: a direct method for learning a linear non-Gaussian structural equation model. JMLR12 (Apr), pp. 1225-1248. External Links: Link, 1106.00050 Cited by: SS2.2.
* P. Spirtes, C. N. Glymour, and R. Scheines (2000)Causation, prediction, and search. MIT press. External Links: Link Cited by: SS2.2.
* M. Teyssier and D. Koller (2005)Ordering-based search: a simple and effective algorithm for learning Bayesian networks. In UAI, UAI'05, pp. 584-590. External Links: Link, Document Cited by: SS2.2.
* R. Tu, K. Zhang, B. Bertilson, H. Kjellstrom, and C. Zhang (2019)Neuropathtic pain diagnosis simulator for causal discovery algorithm evaluation. Advances in Neural Information Processing Systems32, pp.. External Links: Link, 1905.00050 Cited by: SS2.2.
* C. Wallace, K. B. Korb, and H. Dai (1996)Causal discovery via mdl. In ICML, Vol. 96, pp. 516-524. External Links: Link, Document Cited by: SS2.2.
* J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D. Zhou, et al. (2022)Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems35, pp. 24824-24837. External Links: Link, 2202.2022 Cited by: SS2.2.
* M. Willing, M. Zecevic, D. S. Dhami, and K. Kersting (2022)Probing for correlations of causal facts: large language models and causality. External Links: Link, 2202.0220 Cited by: SS2.2.
* X. Zheng, B. Aragam, P. K. Ravikumar, and E. P. Xing (2018)Dags with no tears: continuous optimization for structure learning. NeurIPS31. External Links: Link, 1805.00050 Cited by: SS2.2.

**Appendix**

## Appendix A Proofs of Propositions

**Proposition A.1**.: _(Pearl 2009; Cinelli, Forney, and Pearl 2022a) Under the no-latent confounding assumption, given a pair of treatment and target variables \((X_{i},X_{j})\), \(\mathbf{Z}=\{X_{k}|\pi_{k}<\pi_{i}\}\) is a valid adjustment set relative to \((X_{i},X_{j})\) for any topological order \(\pi\) of nodes \(X_{i},\ldots,X_{n}\)._

Proof.: We need to show that the set \(\mathbf{Z}=\{X_{k}|\pi_{k}<\pi_{i}\}\) satisfies the conditions (i) and (ii) in the definition of backdoor adjustment set. For any variable \(X_{k}\) such that \(\pi_{k}<\pi_{i}\), we have \(X_{k}\not\in de(X_{i})\) and hence the condition (i) is satisfied. Additionally, for each \(X_{k}\in pa(X_{i})\) we have \(\pi_{k}<\pi_{i}\) and hence \(pa(X_{i})\subseteq\mathbf{Z}\). Since \(pa(X_{i})\) blocks all paths from \(X_{i}\) to \(X_{j}\) that contains an arrow into \(X_{i}\) (Peters and Buhlmann 2015), \(\mathbf{Z}\) satisfies condition (ii). 

**Proposition A.2**.: _For an estimated topological order \(\hat{\pi}\) and a true topological order \(\pi\) of a causal DAG \(\mathcal{G}\) with the corresponding adjacency matrix \(A\), \(D_{top}(\hat{\pi},A)=0\) iff \(\mathbf{Z}=\{X_{k}|\hat{\pi}_{k}<\hat{\pi}_{i}\}\) is a valid adjustment set relative to \((X_{i},X_{j}),\;\forall\pi_{i}<\pi_{j}\)._

Proof.: The statement of proposition is of the form \(A\iff B\) with \(A\) being "\(D_{top}(\hat{\pi},A)=0\)" and \(B\) being "\(\mathbf{Z}=\{X_{k}|\hat{\pi}_{k}<\hat{\pi}_{i}\}\) is a valid adjustment set relative to \((X_{i},X_{j}),\;\forall i,j\)". We prove \(A\iff B\) by proving (i) \(A\implies B\) and (ii) \(B\implies A\).

(i) Proof of \(A\implies B\): If \(D_{top}(\hat{\pi},A)=0\), for all pairs of nodes \((X_{i},X_{j})\), we have \(\hat{\pi}_{i}<\hat{\pi}_{j}\) whenever \(\pi_{i}<\pi_{j}\). That is, causal order in estimated graph is same that of the causal order in true graph. Hence, from Prop A.1, \(\mathbf{Z}=\{X_{k}|\hat{\pi}_{k}<\hat{\pi}_{i}\}\) is a valid adjustment set relative to \((X_{i},X_{j}),\;\forall i,j\).

(ii) Proof of \(B\implies A\): we prove the logical equivalent form of \(B\implies A\) i.e., \(\neg A\implies\neg B\), the _contrapositive_ of \(B\implies A\). To this end, assume \(D_{top}(\hat{\pi},A)\neq 0\), then there will be at least one edge \(X_{i}\to X_{j}\) that cannot be oriented correctly due to the estimated topological order \(\hat{\pi}\). i.e., \(\hat{\pi}_{j}<\hat{\pi}_{i}\) but \(\pi_{j}>\pi_{i}\). Hence, to find the causal effect of \(X_{i}\) on \(X_{i};\;l\neq j\), \(X_{j}\) is included in the back-door adjustment set \(\mathbf{Z}\) relative to \((X_{i},X_{l})\). Adding \(X_{j}\) to \(\mathbf{Z}\) renders \(\mathbf{Z}\) an invalid adjustment set because it violates the condition (i). 

**Proposition A.3**.: _In a causal DAG \(\mathcal{G}\) with \(N\) levels in the level-ordering of variables where the level \(i\) contains \(n_{i}\) variables,\(\exists\;\hat{\mathcal{G}}\) s.t. \(SHD(\hat{\mathcal{G}},\mathcal{G})\geq\sum\limits_{i=1}^{N-1}(n_{i}\times \sum\limits_{j=i+1}^{N}n_{j})-|\mathbf{E}|\) and \(D_{top}(\hat{\pi},A)=0\;\forall\hat{\pi}\) of \(\hat{\mathcal{G}}\)._

Proof.: Recall that SHD counts the number of missing, falsely detected, and falsely directed edges in the estimated causal graph as compared to the ground truth graph. Since we want \(D_{top}(\hat{\pi},A)=0;\;\forall\hat{\pi}\) of \(\hat{\mathcal{G}}\), there cannot be an edge \(X_{i}\to X_{j}\) in \(\hat{\mathcal{G}}\) such that \(X_{i}\gets X_{j}\) is in \(\mathcal{G}\). This constraint avoids the possibility of having falsely directed edges in \(\hat{\mathcal{G}}\). Consider a \(\hat{\mathcal{G}}\) with all the edges in \(\mathcal{G}\) and in addition, each variable in level \(i\) having a directed edge to each variable in all levels below level \(i\). All such edges contribute to the SHD score while still obeying the causal ordering in \(\mathcal{G}\). This number will be equal to \(\sum\limits_{i=1}^{N-1}(n_{i}\times\sum\limits_{j=i+1}^{N}n_{j})-|\mathbf{E}|\). The quantity \(\sum\limits_{i=1}^{N-1}(n_{i}\times\sum\limits_{j=i+1}^{N}n_{j})\) is the number of edges possible from each node to the every other node in the levels below it. We need to subtract the number of existing edges in \(\mathbf{E}\) to count the newly added edges that contribute to the SHD score. Now, we can remove some of the edges \(X_{i}\to X_{j}\) from \(\hat{\mathcal{G}}\) such that \(X_{i}\to X_{j}\) is in \(\mathcal{G}\) while still leading to same causal ordering of variables. This leads to increased SHD score due to missing edges in \(\hat{\mathcal{G}}\). Since it will only increase the SHD score, we ignore such corner cases. 

## Appendix B Additional Results

Tab. 2 shows the correlation between \(D_{top}\) and \(\epsilon_{ACE}\), where for the datasets Cancer, Asia and Survey, we consider \(dyspnoea\), \(dyspnoea\), and \(Travel\) respectively as the target variables. Whereas, there is no correlation between SHD and \(\epsilon_{ACE}\).

Each experiment was conducted three times, with reported results as mean and standard deviation values. In experiments involving Child and Insurance datasets (Algorithm 2), we averaged over prior probabilities \(0.5,0.6,0.7,0.8,0.9\). Table 1 demonstrates the superior performance of our proposed methods compared to the baselines.

### LLMs used in post-processing for graph discovery

We conducted some experiments where we utilised discovery algorithms like PC for creating skeletons of the graph and employed LLMs for orienting the undirected edges. The idea was to utilise LLMs ability to correctly estimate the causal direction while leveraging PC algorithm's ability to give a skeleton which could be oriented in a post processing setup. We saw that LLM ended up giving improved results as compared to PC alone.

## Appendix C Algorithms

Algorithms 1 and 2 outlines the procedures to combine LLMs with existing constraint-based and score-based methods.

[MISSING_PAGE_EMPTY:9]

Figure A3: Survey Bayesian network. Abbreviations: A=_Age/Age of people using transport_, S=_Sex/male or female_, E=_Education/up to high school or university degree_, O=_Occupation/employee or self-employed_, R=_Residence/the size of the city the individual lives in, recorded as either small or big_, T=_Travel/the means of transport favoured by the individual_.

Figure A5: Child Bayesian network. Abbreviations: BirthAsphyxia: _Lack of oxygen to the blood during the infant’s birth_, HypDistirb: _Low oxygen areas equally distributed around the body_, HypoxiaInO2: _Hypoxia when breathing oxygen_, CO2: _Level of carbon dioxide in the body_, ChestXray: _Having a chest x-ray_, Grunting: _Grunting in infants_, LVHeport: _Report_: _Report of having left ventricular hypertrophy_, LowerBodyO2: _Level of oxygen in the lower body_, RUOO2: _Level of oxygen in the right upper quadriceps muscle_, CO2Report: _A document reporting high levels of CO2 levels in blood_, XrayReport: _Report of having a chest x-ray_, Disease: _Presence of an illness_, GruntingReport: _Report of infant granting_, Age: _Age of infant at disease presentation_, LVH: _Thickening of the left ventricle_, DuctFlow: _Blood flow across the nucleus arterosus_, CardiacMixing: _Mixing of oxygenated and deoxygenated blood_, LungParench: _The state of the blood vessels in the lungs_, LungFlow: _Low blood flow in the lungs_, Sick: _Presence of an illness_

Figure A6: For Neuropathatic dataset, we consider a sub-graph induced by one of the root nodes, containing the following 22 nodes and corresponding edges taken from [https://observableq.com/@turuibo/the-complete-causal-graph-of-neuropathic-pain-diagnosis](https://observableq.com/@turuibo/the-complete-causal-graph-of-neuropathic-pain-diagnosis): 'right C7’, 'right elbow trouble', 'left shoulder trouble’, 'left bend of arm problem’, 'right shoulder trouble’, 'right hand problem’, 'left medial elbow problems’, 'right finger trouble’, 'left neck problems’, 'left wrist problems’, 'left shoulder problem’, 'right neck', 'right wrist problem’, 'right shoulder problem’, 'discoligment injury C6 C7’, 'left hand problem’, 'left C7’, 'right arm band’, 'left lower arm disorders’, 'neck pain’, 'left finger trouble’, 'left arm’. We did not use descriptions for the nodes of Neuropathatic graph.

Question: For a causal graph used to model relationship of various factors and outcomes related to cancer with the following nodes: ['Pollution', 'Cancer', 'Smoker', 'Xray', 'Dyspnoea'], Which cause-and-effect relationship is more likely between nodes'smoker' and 'cancer'?

A. changing the state of node'smoker' causally effects a change in another node 'cancer'.

B. changing the state of node 'cancer' causally effects a change in another node'smoker'.

C. There is no causal relation between the nodes 'cancer' and'smoker'.

Make sure to first provide a grounded reasoning for your answer and then provide the answer in the following format: <Answer>A/B/C</Answer>. It is very important that you output the final Causal graph within the tags like <Answer>A/B/C</Answer> otherwise your answer will not be processed.

Answer: The causal effect of "smoker" directing to "cancer" is based on the strong evidence from epidemiological studies linking smoking to an increased risk of developing cancer. Smoking introduces harmful substances into the respiratory system, leading to cellular damage and mutation, which significantly raises the likelihood of cancer development in the lungs or respiratory tract, subsequently impacting the occurrence of respiratory problems like shortness of breath. Therefore answer is <Answer>A</Answer>

Question: For a causal graph used to model relationship of various factors and outcomes related to cancer with the following nodes: ['Pollution', 'Cancer', 'Smoker', 'Xray', 'Dyspnoea'], Which cause-and-effect relationship is more likely between nodes 'xray' and 'dyspnoea'?

A. changing the state of node 'xray' causally effects a change in another node 'dyspnoea'.

B. changing the state of node 'dyspnoea' causally effects a change in another node 'xray'.

C. There is no causal relation between the nodes 'xray' and 'dyspnoea'.

Make sure to first provide a grounded reasoning for your answer and then provide the answer in the following format: <Answer>A/B/C</Answer>. It is very important that you output the final Causal graph within the tags like <Answer>A/B/C</Answer> otherwise your answer will not be processed.

Answer: Reasoning behind the lack of causal relation between X-ray and dyspnoea is that X-ray and dyspnoea are both effects of having cancer, but they do not directly cause or affect each other. X-ray is a diagnostic test that can help detect cancer in the lungs or other organs, while dyspnoea is a symptom of cancer that involves feeling short of breath. Therefore, X-ray and dyspnoea are not causally related, but they are both associated with cancer. Therefore answer is <Answer>C</Answer>

Question: For a causal graph used to model relationship of various factors and outcomes related to cancer with the following nodes: ['Pollution', 'Cancer', 'Smoker', 'Xray', 'Dyspnoea'], Which cause-and-effect relationship is more likely between nodes 'xray' and 'cancer'?

A. changing the state of node 'xray' causally effects a change in another node 'cancer'.

B. changing the state of node 'cancer' causally effects a change in another node 'xray'.

C. There is no causal relation between the nodes 'xray' and 'cancer'.

Make sure to first provide a grounded reasoning for your answer and then provide the answer in the following format: <Answer>A/B/C</Answer>. It is very important that you output the final Causal graph within the tags like <Answer>A/B/C</Answer> otherwise your answer will not be processed.

Answer: The causal effect of cancer on X-ray is that X-rays are often used to diagnose or detect cancer in different parts of the body, such as the bones, lungs, breasts, or kidneys123. X-rays use low doses of radiation to create pictures of the inside of the body and show the presence, size, and location of tumors. X-rays can also help monitor the response to treatment or check for signs of recurrence. Therefore, having cancer may increase the likelihood of getting an X-ray as part of the diagnostic process or follow-up care. Therefore answer is <Answer>B</Answer>

Question: For a causal graph used to model relationship of various factors and outcomes related to cancer with the following nodes: ['Pollution', 'Cancer', 'Smoker', 'Xray', 'Dyspnoea'], Which cause-and-effect relationship is more likely between nodes 'pollution' and 'cancer'?

A. changing the state of node 'pollution' causally effects a change in another node 'cancer'.

B. changing the state of node 'cancer' causally effects a change in another node 'pollution'.

C. There is no causal relation between the nodes 'pollution' and 'cancer'.

Make sure to first provide a grounded reasoning for your answer and then provide the answer in the following format: <Answer>A/B/C</Answer>. It is very important that you output the final Causal graph within the tags like <Answer>A/B/C</Answer> otherwise your answer will not be processed.

Answer: The causal effect of pollution on cancer is that air pollution contains carcinogens (cancer-causing substances) that may be absorbed into the body when inhaled and damage the DNA of cells. Another possible reasoning is that particulate matter (tiny dust-like particles) in air pollution may cause physical damage to the cells in the lungs, leading to inflammation and oxidative stress and eventually cell mutations. A third possible reasoning is that air pollution may create an inflamed environment in the lungs that encourages the proliferation of cells with existing cancer-driving mutations. These are some of the hypotheses that researchers have proposed to explain how air pollution may cause cancer, but more studies are needed to confirm them. Therefore answer is <Answer>A</Answer>

Question: For a causal graph used to model relationship of various factors and outcomes related to cancer with the following nodes: ['Pollution', 'Cancer', 'Smoker', 'Xray', 'Dyspnoea'], Which cause-and-effect relationship is more likely between nodes 'pollution' and'smoker'?

A. changing the state of node 'pollution' causally effects a change in another node'smoker'.

B. changing the state of node'smoker' causally effects a change in another node 'pollution'.

C. There is no causal relation between the nodes 'pollution' and'smoker'.

Make sure to first provide a grounded reasoning for your answer and then provide the answer in the following format: <Answer>A/B/C</Answer>. It is very important that you output the final Causal graph within the tags like <Answer>A/B/C</Answer> otherwise your answer will not be processed.

Answer: Reason behind the lack of causal relation between pollution and smoker is that pollution and smoking are both independent risk factors for respiratory problems, but they do not directly cause or affect each other. Pollution and smoking both contribute to air pollution, which can harm the health of people and the environment. However, pollution is mainly caused by human activities such as burning fossil fuels, deforestation, or industrial processes, while smoking is a personal choice that involves inhaling tobacco smoke. Therefore, pollution and smoker are not causally related, but they are both associated with respiratory problems. Therefore answer is <Answer>C</Answer>.

Question: For a causal graph used for modeling factors causing Coronary Heart Diseases with the following nodes: ['Family Disease', 'Gene', 'Smoking', 'Blood Pressure', 'Coronary Heart Disease', 'Headache'], Which cause-and-effect relationship is more likely between nodes 'Family Disease' and 'Gene'?

A. changing the state of node 'Family Disease' causally effects a change in another node 'Gene'.

B. changing the state of node 'Gene' causally effects a change in another node 'Family Disease'.

C. There is no causal relation between the nodes 'Family Disease' and 'Gene'.

Make sure to first provide a grounded reasoning for your answer and then provide the answer in the following format: <Answer>A/B/C</Answer>. It is very important that you output the final Causal graph within the tags like <Answer>A/B/C</Answer> otherwise your answer will not be processed.

Answer: Reason behind the causal effect of family disease on gene is that family disease is a term that refers to diseases or health conditions that run in the family, meaning that they are influenced by genetic factors. Gene is a term that refers to the basic unit of heredity that carries information for a specific trait or function. Family disease can affect gene by altering the type or frequency of genes that are inherited by the offspring from their parents. For example, some family diseases are caused by deterministic genes, which are genes that guarantee the development of a disease if they are present in a person's genome. Other family diseases are influenced by risk genes, which are genes that increase the likelihood of developing a disease but do not guarantee it. Therefore, family disease can causally direct to gene by changing the genetic makeup of a person or a population. Therefore answer is <Answer>A</Answer>.

Question: For a causal graph used for modeling factors causing Coronary Heart Diseases with the following nodes: ['Family Disease', 'Gene', 'Smoking', 'Blood Pressure', 'Coronary Heart Disease', 'Headache'], Which cause-and-effect relationship is more likely between nodes 'Coronary Heart Disease' and 'Gene'?

A. changing the state of node 'Coronary Heart Disease' causally effects a change in another node 'Gene'.

B. changing the state of node 'Gene' causally effects a change in another node 'Coronary Heart Disease'.

C. There is no causal relation between the nodes 'Coronary Heart Disease' and 'Gene'.

Make sure to first provide a grounded reasoning for your answer and then provide the answer in the following format: <Answer>A/B/C</Answer>. It is very important that you output the final Causal graph within the tags like <Answer>A/B/C</Answer> otherwise your answer will not be processed.

Answer: Possible reasoning behind the causal effect of gene on coronary heart disease is that gene is a term that refers to the basic unit of heredity that carries information for a specific trait or function. Gene can affect coronary heart disease by influencing the structure and function of the blood vessels, the metabolism and transport of lipids (fats) in the blood, the inflammation and clotting processes, or the response to environmental factors such as smoking or diet. For example, some genes code for proteins that regulate the cell cycle and growth of the cells that line the arteries, which can affect their susceptibility to damage or plaque formation. Other genes code for proteins that control the synthesis and clearance of cholesterol or other lipids, which can affect their levels and deposition in the arteries. Therefore, gene can causally direct to coronary heart disease by modifying the biological pathways that contribute to the development or progression of the disease. Therefore answer is <Answer>B</Answer>Question: For a causal graph used for modeling factors causing Coronary Heart Diseases with the following nodes: ['Family Disease', 'Gene', 'Smoking', 'Blood Pressure', 'Coronary Heart Disease', 'Headache'], Which cause-and-effect relationship is more likely between nodes 'Blood Pressure' and 'Smoking'?

A. changing the state of node 'Blood Pressure' causally effects a change in another node 'Smoking'.

B. changing the state of node 'Smoking' causally effects a change in another node 'Blood Pressure'.

C. There is no causal relation between the nodes 'Blood Pressure' and 'Smoking'.

Make sure to first provide a grounded reasoning for your answer and then provide the answer in the following format: <Answer>A/B/C</Answer>. It is very important that you output the final Causal graph within the tags like <Answer>A/B/C</Answer> otherwise your answer will not be processed.

Answer: Possible reasoning behind the causal effect of smoking on blood pressure is that smoking is a habit that involves inhaling tobacco smoke, which contains nicotine and other harmful chemicals. Smoking can affect blood pressure by activating the sympathetic nervous system (SNS), which is the part of the nervous system that controls the body's response to stress or danger. When the SNS is activated, it releases hormones such as adrenaline and noradrenaline, which cause the heart to beat faster and harder, and the blood vessels to construct. This results in a temporary increase in blood pressure, which can last for 15 to 20 minutes after each cigarette. Therefore, smoking can causally direct to blood pressure by stimulating the SNS and increasing the cardiac output and vascular resistance. Therefore answer is <Answer>B</Answer>.

Question: For a causal graph used for modeling factors causing Coronary Heart Diseases with the following nodes: ['Family Disease', 'Gene', 'Smoking', 'Blood Pressure', 'Coronary Heart Disease', 'Headache'], Which cause-and-effect relationship is more likely between nodes 'Headache' and 'Smoking'?

A. changing the state of node 'Headache' causally effects a change in another node 'Smoking'.

B. changing the state of node 'Smoking' causally effects a change in another node 'Headache'.

C. There is no causal relation between the nodes 'Headache' and 'Smoking'.

Make sure to first provide a grounded reasoning for your answer and then provide the answer in the following format: <Answer>A/B/C</Answer>. It is very important that you output the final Causal graph within the tags like <Answer>A/B/C</Answer> otherwise your answer will not be processed.

Answer: One possible reasoning behind the lack of causal relation between headache and smoking is that headache and smoking are both associated with various health conditions, but they do not directly cause or affect each other12. Headache is a term that refers to pain or discomfort in the head, scalp, or neck, which can have many possible causes, such as stress, dehydration, infection, injury, or medication. Smoking is a habit that involves inhaling tobacco smoke, which contains nicotine and other harmful chemicals, which can increase the risk of diseases such as cancer, heart disease, stroke, and lung disease. Therefore, headache and smoking are not causally related, but they are both linked to different health problems. Therefore the answer is <Answer>C</Answer>Question: For a causal graph used for modeling factors causing Coronary Heart Diseases with the following nodes: ['Family Disease', 'Gene', 'Smoking', 'Blood Pressure', 'Coronary Heart Disease', 'Headache'], Which cause-and-effect relationship is more likely between nodes 'Headache' and 'Smoking'?

A. changing the state of node 'Headache' causally effects a change in another node 'Smoking'.

B. changing the state of node 'Smoking' causally effects a change in another node 'Headache'.

C. There is no causal relation between the nodes 'Headache' and 'Smoking'.

Make sure to first provide a grounded reasoning for your answer and then provide the answer in the following format: <Answer>A/B/C</Answer>. It is very important that you output the final Causal graph within the tags like <Answer>A/B/C</Answer> otherwise your answer will not be processed.

Answer: One possible reasoning behind the lack of causal relation between headache and smoking is that headache and smoking are both associated with various health conditions, but they do not directly cause or affect each other. Headache is a term that refers to pain or discomfort in the head, scalp, or neck, which can have many possible causes, such as stress, dehydration, infection, injury, or medication. Smoking is a habit that involves inhaling tobacco smoke, which contains nicotine and other harmful chemicals, which can increase the risk of diseases such as cancer, heart disease, stroke, and lung disease. Therefore, headache and smoking are not causally related, but they are both linked to different health problems. Therefore the answer is <Answer>C</Answer>

Question: For a causal graph used for modeling factors causing Coronary Heart Diseases with the following nodes: ['Family Disease', 'Gene', 'Smoking', 'Blood Pressure', 'Coronary Heart Disease', 'Headache'], Which cause-and-effect relationship is more likely between nodes 'Coronary Heart Disease' and 'Smoking'?

A. changing the state of node 'Smoking' causally effects a change in another node 'Coronary Heart Disease'.

B. changing the state of node 'Coronary Heart Disease' causally effects a change in another node 'Smoking'.

C. There is no causal relation between the nodes 'Coronary Heart Disease' and 'Smoking'.

Make sure to first provide a grounded reasoning for your answer and then provide the answer in the following format: <Answer>A/B/C</Answer>. It is very important that you output the final Causal graph within the tags like <Answer>A/B/C</Answer> otherwise your answer will not be processed.

Answer: Possible reasoning behind the causal effect of smoking on coronary heart disease is smoking damages the heart and blood vessels by raising triglycerides, lowering HDL, increasing blood clotting, and impairing blood flow to the heart. This can lead to plaque buildup, heart attacks, and death. Therefore answer is <Answer>A</Answer>.

Question: For a causal graph used for context with the following nodes: nodes, Which cause-and-effect relationship is more likely between nodes X and Y?

A. changing the state of node X causally effects a change in another node Y.

B. changing the state of node Y causally effects a change in another node X.

C. There is no causal relation between the nodes X and Y.

Make sure to first provide a grounded reasoning for your answer and then provide the answer in the following format: <Answer>A/B/C</Answer>. It is very important that you output the final Causal graph within the tags like <Answer>A/B/C</Answer> otherwise your answer will not be processed.

[MISSING_PAGE_FAIL:18]

[MISSING_PAGE_FAIL:19]

_Identify the causal relationships between the given variables and create a directed acyclic graph to context. Make sure to give a reasoning for your answer and then output the directed graph in the form of a list of tuples, where each tuple is a directed edge. The desired output should be in the following form: [( 'A','B'), ('B','C')] where first tuple represents a directed edge from Node 'A' to Node 'B', second tuple represents a directed edge from Node 'B' to Node 'C'and so on. If a node should not form any causal relationship with other nodes, then you can add it as an isolated node of the graph by adding it seperately. For example, if 'C' should be an isolated node in a graph with nodes 'A', 'B', 'C', then the final DAG representation should be like [('A','B'), ('C')]. Use the description about the node provided with the nodes in brackets to form a better decision about the causal direction orientation between the nodes. It is very important that you output the final Causal graph within the tags <Answer></Answer>otherwise your answer will not be processed. Example: Input: Nodes: ['A', 'B', 'C', 'D']; Description of Nodes: [(description of Node A), (description of Node B), (description of Node C), (description of Node D)] Output: <Answer>[('A','B'),('C','D')]</Answer> Question: Input: Nodes: nodes Description of Nodes: Output: ```

\begin{table}
\begin{tabular}{l} \hline \hline Input: (**‘Right C7’,’Discoligment injury C6-C7’)** \\ Answer: Discoligment injury C6-C7 can cause compression of the nerve roots that exit the spinal cord at the C7 level, which can lead to symptoms such as pain, numbness, and weakness in the right C7 dermatome. Therefore, the answer is <Answer>B</Answer>. Input: (**‘Right C7’, ‘Left C7’)** \\ Answer: Right C7 and left C7 are both parts of the cervical spine and are not known to directly influence each other. Therefore, the answer is <Answer>C</Answer>. Input: (**‘Right elbow trouble’, ‘Left shoulder trouble’)** \\ Answer: There is no direct causal relationship between right elbow trouble and left shoulder trouble. They may both be symptoms of a larger underlying condition, but they do not directly cause or affect each other. Therefore the answer is <Answer>C</Answer>. \\ \hline \hline \end{tabular}
\end{table}
Table 13: Example LLM (GPT-3.5-turbo) reasoning outputs for estimating causal directionality between different pairs of nodes using CoT Prompt (refer Table 13 for the prompt) for Neuropathic subgraph (used for pain diagnosis).