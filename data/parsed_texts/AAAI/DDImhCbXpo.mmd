# CycleTrans: a transformer-based clinical foundation model for safer prescription

 Yuhan Zheng\({}^{2,\,3}\), Xiaotao Lin\({}^{2,\,4}\), Kevuan Chen\({}^{1,\,2}\), Shengxin Zhu\({}^{1,\,2}\)

###### Abstract

Deep learning techniques are extensively utilized in prescribing drug combinations, drawing on extensive electronic medical records (EMRs). A prescription assistant may be able to provide immediate guidance on drug combinations for some urgent clinical situations. A well-controlled drug-drug interaction (DDI) rate and high recommendation precision are of great importance for a safe prescription. A lower DDI often implies the set of drug combinations should be as small as possible, which is challenging because EMR prescriptions for certain symptom(s) are often highly noised due to the diversity side symptoms of individuals. We propose a model comprised of cycle transformers (CycleTrans) to handle these challenges. CycleTrans employs cross-attention and transformers, integrates patients' longitudinal EMRs, enhances knowledge representations through the so-called cycle-embedding module, and thus predicts safer and better essential drug combinations for new-coming cases. The new model achieves the state-of-the-art in three dimensions: high precision (89%), low DDI rate (0.34%), and small drug set size (3.02) on the MIMIC-III benchmark dataset, surpassing previous bests of 73%, 5%, and 17 in each dimension, respectively. Such a significant advancement makes a much safer clinic prescription possible. The idea of the cycle transformer we proposed has considerable potential for other domains besides clinics, such as set recommendations, translation, and unsupervised representation learning in knowledge graphs.

1Research Centers for Mathematics, Advanced Institute of Natural Science,

Beijing Normal University, Zhuhai 519087, P.R.China

2Guangdong Provincial Key Laboratory of Interdisciplinary Research and Application for Data Science,

BNU-HKBU United International College, Zhuhai 519087, P.R. China

3School of Informatics, The University of Edinburgh

4Department of Mathematics, The University of Hong Kong

Shengxin.Zhu@bnu.edu.cn

## Introduction

Foundation models (FMs), a recent innovation in machine learning, are trained on vast datasets across multiple domains. They exhibit impressive performance in addressing various real-world AI challenges [1, 13]. Among the most notable models is OpenAI's ChatGPT, a predominantly text-based large language model (LLM) that has extended its capabilities to include image processing and data analysis [1]. Remarkably, ChatGPT has demonstrated the capability to achieve passing scores in the United States Medical Licensing Examinations [1]. This accomplishment hints at its readiness in diverse fields such as clinical environments [16, 17, 18, 19, 20, 21, 22, 23] and clinical foundation models [10, 23].

LLMs like ChatGPT, though trained on general datasets, have proven effective in medical examinations [1]. However, success in passing written examinations does not necessarily imply clinical competence [1]. The clinical requirements for experience, timeliness, accuracy, and supervision pose significant challenges for the application of medical foundation models. There is currently no paradigm that adequately addresses the application of these models in the medical field, making their practical deployment contentious. Multiple articles have pointed out that these foundation models should be utilized as tools under supervision [23]. Our study is predicated on developing a clinical foundation model that matches patients with appropriate medications based on their specific symptom information. This approach aims to achieve precision, safety and expedited healing for patients.

Existing models, such as GatorTron and the Biomed-CLIP model, offer valuable insights for our research [10, 11]. Meanwhile, a plethora of studies utilizing the MIMIC-III dataset provide extensive analysis and benchmarks [10, 11]. Currently, an overemphasis on better predictive performance in many articles neglects a broader set of crucial factors. These include less labeled data, simplified model deployment, emergent clinical applications, multimodality, and novel human-AI interfaces [24].

Not only do the results and model factors play a crucial role, but the dataset also significantly impacts the overall framework. To address the limitations of general LLMs in clinical practicality and the existing gaps in a comprehensive analysis of dataset and evaluation standards in MIMIC-III, a more nuanced approach is required. MIMIC-III is particularly noteworthy as it encompasses a vast collection of nearly 2 million patient notes from 2001 to 2012, documented in the ICU of the Beth Israel Deaconess Medical Center [1]. In the fast-paced environment of the ICU, quick decision-making is as essential as precision. In such settings, a minor oversight can lead to severe consequences, making manual evaluation crucial. This aspect of urgency and precision in real-world decision-making is often overlooked in many high-accuracy applications of the MIMIC-III model [24].

To more effectively address the challenges previously outlined, we introduce the CycleTrans model. The principal contributions of this work are as follows:

1. This work has developed the CycleTrans model to predict specific medications for patients, according to their disease diagnoses. The model introduces a cycle-embedding module that enhances symptom and drug embeddings, which can be developed as a foundational model for many downstream tasks, such as "Clinical Trial Matching" and "Treatment Recommendation".

2. Cross-attention and transformers are employed to integrate patients' longitudinal data, alongside a drug attention mapping matrix for effectively mapping drug interactions.

3. The model achieves a state-of-the-art precision of **89.26%**, a low DDI rate of **0.34%**, and a minimum main drug set size of **3.02**.

## Related Works

Among deep learning approaches to drug recommendation, the most classical implementation is the instance-based approach, which focuses solely on the current health state information. Representative models include SMR [14] and LEAP [15]. For example, LEAP deals with label dependency and label instance mapping by combining a recursive decoder and content-based attention. However, such an approach does not incorporate well the information contained in the patient's historical health records [23]. On the other hand, longitudinal drug recommendation methods can utilize the time dependency implicitly with longitudinal patient records [13, 15]. Based on this idea, many models have also begun to consider the effect of DDIs on the outcome of drug recommendations, thus making drug recommendation models more reliable [15, 16, 17, 18]. For example, GAMENet [15] is building graph models based on the co-occurrence of drugs in EMR through memory networks and graph neural networks. COGNet [23] is determining whether predictive medications require a new drug or merely follow the medical history based on the patient's historical health records and the DDI matrix. MEGACare [23] discerns complex relationships in the data by constructing an EMR hypergraph. Most of the existing longitudinal models conform to the encoder-decoder architecture, where first the encoder generates patient-level representations of known medical and patient data, and the decoder performs drug recommendation based on the embedding of the information[23]. For more references, the reader can refer to [1].

## Methodology

In clinical trials, drug recommending requires accurate diagnosis, comprehensive knowledge of drug effects and interactions, and consideration of patient preferences and characteristics. Our model consists of two key components as shown in Figure 1, and a new fusion loss in (6) to capture all the information, enhancing the precision and reducing the DDI rate. The whole framework is shown in Figure 1.

In this model, Symptom and drug sets are treated akin to words and thus ideas for translation such as cycleGAN [15] can be borrowed. However, for a clinic emergency, drug combination recommendation should be as safe as possible and higher precision is desired. Therefore, we design a new loss such that high precision and low DDI can be achieved.

### Symptoms and Historical Diagnosis Fusion Module

This module is referred to as the "Drug Transformer" in _Figure 1_. Considering that the procedure recommendation must account for patient preferences and characteristics, including historical data, a fusion module employing a multi-head attention mechanism has been designed [16]:

\[\mathbf{z}_{d}^{i}=Attention(\mathbf{h_{t}W}_{q}^{i},\mathbf{h_{1:t-1}W}_{k}^{i},\mathbf{h_{1: t-1}W}_{v}^{i}) \tag{1}\]

where \(\mathbf{z}_{d}^{i}\in\mathbb{R}^{N\times\frac{D}{k}}\) represents the response from the \(i^{th}\) attention head, managing \(N\) symptom types across \(h\) total heads. The term \(\mathbf{h}_{t}\) denotes the current diagnosis, while \(\mathbf{h}_{1:t-1}\) embodies the historical diagnosis data. Additionally, \(\mathbf{W}_{q}^{i},\mathbf{W}_{k}^{i},\mathbf{W}_{v}^{i}\in\mathbb{R}^{D\times\frac{D}{k}}\) are designated as the weight matrices for the \(i^{th}\) query, key, and value within the \(D\) dimensional embedding space of the multi-head attention mechanism.

Finally, we concatenate and transform \(h\) heads to form the representation of diagnosis \(z_{d}\) by

\[\mathbf{z}_{d}=Concat(\mathbf{z}_{d}^{1},\dots,\mathbf{z}_{d}^{h})\mathbf{W}_{o}, \tag{2}\]

where \(\mathbf{W}_{o}\in\mathbb{R}^{D\times D}\) denotes the weight matrix that integrates the final output, while \(Concat(\mathbf{z}_{d}^{1},\dots,\mathbf{z}_{d}^{h})\in\mathbb{R}^{N\times D}\) represents the concatenated outputs of the \(h\) attention heads. Subsequently, a cross-attention mechanism is applied, utilizing historical diagnoses as the "key" and current symptoms as the "query", to merge this information for a certain patient. This approach enables the model to assimilate comprehensive data, encompassing both the doctors' current diagnosis and historical patient information.

### Cycle-embedding Module

As this system assists doctors in decision-making, it is important to improve the predicting precision of the key drugs, and other minor drugs can be left to the doctors' discretion based on the possible drug interactions and the patients' conditions. Consequently, this approach allows the system to offer more precise and tailored recommendations for optimal treatment strategies.

The sets of symptoms and drugs are conceptualized as two distinct distributions, with a Cycle-embedding module, inspired by CycleGAN [16], facilitating the primary model's training. Minor drugs are considered random perturbations, while key drugs represent the primary distribution. The objective is to transform one distribution into another, akin to a translation task where an accurate translation between languages should be reversible.

The "Symptom Transformer", as depicted in Figure 1, represents the cycle assisting module. This module processes the currently inferred drug as input, converting it back into symptoms to enhance embedding quality. The associated loss is quantified by the distance between actual and predicted symptoms:

\[\mathbf{\mathcal{L}}_{cycle}=\frac{1}{\mathbf{N}}\sum_{n=1}^{N}\|\mathbf{h}_{s}^{n}-\hat{\mathbf{ h}}_{s}^{n}\|, \tag{3}\]

where \(h_{s}^{n}\) is the embedding of the \(n^{th}\) patient's symptoms. \(N\) denotes the number of samples.

### Safe Drug Loss Design

In light of the need for high precision and a low DDI rate, the DDI loss has been restructured, drawing inspiration from 4SDrug [22], which also expedites the training process.

\[\mathbf{\mathcal{L}}_{ddi}=\frac{1}{\mathbf{N}}\sum_{n=1}^{N}\mathbf{p}_{n}\cdot\mathbf{M}_{DDI}, \tag{4}\]

where \(\mathbf{M}_{DDI}\) is the adjacent matrix of DDI, and the \(\mathbf{p}\) is the prediction of drugs set for the \(n^{th}\) patient. In addition to the DDI loss, it also requires a set classification loss to enhance the precision:

\[\alpha\mathbf{\mathcal{L}}_{cls}=\alpha_{1}\mathbf{\mathcal{L}}_{CrossEntropy}+ \alpha_{2}\mathbf{\mathcal{L}}_{EMD} \tag{5}\]

where the \(\mathbf{\mathcal{L}}_{EMD}\) is the earth mover's distance loss that measures the difference that a set \(A\) transfers to a set \(B\).

Combining the above three parts, the final loss is formulated as follows:

\[\mathbf{\mathcal{L}}=\alpha\mathbf{\mathcal{L}}_{cls}+\beta\mathbf{\mathcal{L}}_{cycle}+ \gamma\mathbf{\mathcal{L}}_{ddi}, \tag{6}\]

where \(\alpha,\beta,\) and \(\gamma\) are hyperparameters that control the relative importance of different objectives, such as reducing the DDI rate or increasing the precision.

## Results

The experiment utilized a composite loss function with weights assigned as follows: cycle loss at 0.2, classification losses at 0.3 and 0.02 (\(\alpha_{1}=0.3\), \(\alpha_{2}=0.02\)), and DDI loss at 0.1. The RAdam optimizer was employed with an initial

\begin{table}
\begin{tabular}{l|c c c} \hline \hline
**Datasets** & \multicolumn{3}{c}{**MIMIC III**} \\ \hline
**Model (year)** & **Precision(\%)** & **DDI rate** & **Avg \#** \\ \hline LEAP (17) & \(65.49\pm 0.33\) & \(0.073\pm 8\)e-4 & \(18.71\pm 0.07\) \\ GAMENet (19) & \(76.31\pm 0.30\) & \(0.086\pm 6\)e-4 & \(27.21\pm 0.11\) \\ SafeDrug (21) & \(76.47\pm 0.25\) & \(0.059\pm 5\)e-4 & \(19.92\pm 0.16\) \\
4SDrug (22) & \(76.04\pm 0.16\) & \(0.054\pm 4\)e-4 & \(14.64\pm 0.07\) \\ SHAPE (23) & \(79.06\pm 0.09\) & \(0.068\pm 3\)e-4 & \(20.99\pm 0.12\) \\ ACDNet (24) & \(79.04\pm 0.21\) & \(0.086\pm 1\)e-3 & \(20.49\pm 0.12\) \\ \hline
**CycleTrans** & **89.24\(\pm\)**2e-3** & **0.008\(\pm\)**8e-3** & **2.81\(\pm\)**0.80** \\ \hline \hline \end{tabular}
\end{table}
Table 1: Experimental results. Bold and underlined texts indicate the best and the second-best scores. Avg # refers to the average number of drugs used in a case. Results of the above models except CycleTrans are from the SHAPE and ACDNet papers. [19, 18]

Figure 1: The CycleTrans architecture comprises two key modules: the Drug Transformer Module, which suggests drugs, and the Symptom Transformer Module, which converts predicted drugs back into symptoms for cycle checking, thereby improving the embeddings’ quality for both symptoms and drugs.

learning rate of 5e-4, and training spanned 20 epochs with a batch size of 50. The results are presented in Table 1.

In the results presented in Figure 2, we illustrate an example of an attention (sub)matrix applied to model prediction, where the 3d bar graph on the left represents the attention weights, which indicate the relevance of certain diagnoses and drugs. The right part represents a prediction example where diagnoses are known inputs and drugs are model-predicted outputs. For instance, the status of other artificial openings of the gastrointestinal tract (V444), which involves surgically-created openings in the digestive system, shows a significant correlation with Acetaminophen in the model's predictions. This suggests that the model emphasizes the management of post-surgical pain, a condition that can be alleviated by Acetaminophen (U.S. Food and Drug Administration 2023). The CycleTrans not only shows a high capacity of capturing the relationships between diagnoses and medical treatments, but also offers a view of the factors influencing its predictions.

## Discussion

In this paper, we have developed CycleTrans for utilizing the extensive MIMIC-III corpus. Our model excels in multiple dimensions, achieving a high clinical precision rating of 89.26%, a low DDI rate of 0.34%, and a minimum main drug set size of 3.02.

There are other standards that CycleTrans can improve, such as evaluation by medical professionals. The traditional NLP metrics have been shown to correlate poorly with human judgments [14, 15, 16]. Despite recognizing the need for diverse evaluative standards, especially in terms of precision and rapid response required in medical and clinical settings, we find that larger, domain-specific pre-trained models (e.g. GatorTron) excel in modeling longer phrases and identifying semantic categories [13]. However, for complex NLP tasks like clinical reasoning judgments and specialized medical questions, even LLMs like GatorTron struggle to discern key information from longer paragraphs. Similarly, our model also necessitates additional data, particularly recent clinical domain data, to substantiate and validate.

There are follow-up questions worth considering. Not just for Clinical FMs, but across neural network models, still lack clear AI explainability. Transferring these models to the medical field for analysis and evaluation doesn't suffice to understand their true practical value. Additionally, ethical and moral concerns about AI-generated conclusions remain a critical topic. LLMs' outputs are increasingly preferred for their quality and empathy, even when compared to responses from real doctors on social media [1]. Furthermore, clinical foundation models like ClinicalBERT, Med-PaLM 2, and GatorTron have even exceeded the capabilities of these general LLMs [15]. However, in all medical disciplines, interpersonal communication is a vital component of patient care. LLMs have been proven to replicate existing biases and are prone to disseminating incorrect information and perpetuating errors in AI decision-making [12]. How to interpret Clinical FMs in a way that ensures they do not produce ethical biases remains an unresolved issue. Safety, efficacy, and ethical concerns remain unresolved. Enhancing the transparency and explainability of models is imperative in medicine to foster understanding, trust, and effective management among users of these systems [12]. Undoubtedly, both LLMs and Clinical FMs are transforming the fields of medicine and clinical practice.

In the future, we will consider larger datasets, such as the MIMIC-IV dataset, as well as more other diverse multimodal datasets, to further pretrain our model enhancing its robustness.

Figure 2: Attention matrix of drug-diagnosis correlations applied to visualization of predictions. The left side shows a three-dimensional histogram of the attention matrix, with the height indicating the size of the weights, while the right side shows the predicted sample (HADM_ID: 167243).

## Acknowledgement

The authors would like to thank support from the Interdisciplinary Intelligence Super Computer Center of Beijing Normal University at Zhuhai. This work was partially supported by the Natural Science Foundation of China (12271047); UIC research grant (R0400001-22; UICR0400008-21; UICR04202405-21); Guangdong College Enhancement and Innovation Program (2021ZDZX1046).

## References

* Z. Ali, Y. Huang, I. Ullah, J. Feng, C. Deng, N. Thierry, A. Khan, A. Jan, X. Shen, W. Rui, et al. (2023)Deep learning for medication recommendation: a systematic survey. Data Intelligence5 (2), pp. 303-354. Cited by: SS1.
* J. W. Ayers, et al. (2023)Comparing physician and artificial intelligence chatbot responses to patient questions posted to a public social media forum. JAMA Internal Medicine183, pp. 589-596. Cited by: SS1.
* R. Bommasani, et al. (2022)On the opportunities and risks of foundation models. arXiv2108.07258. Cited by: SS1.
* J. Clusmann, F. R. Kolbinger, H. S. Muti, et al. (2023)The future landscape of large language models in medicine. Communications Medicine3, pp. 141. Cited by: SS1.
* G. Eysenbach (2023)The role of chat GPT, generative language models, and artificial intelligence in medical education: a conversation with chat GPT and a call for papers. JMIR Medical Education9, pp. e46885. Cited by: SS1.
* F. Gong, M. Wang, H. Wang, S. Wang, and M. Liu (2021)SMR: medical knowledge graph embedding for safe medicine recommendation. Big Data Research23, pp. 100174. Cited by: SS1.
* X. Hu, et al. (2022)Correlating automated and human evaluation of code documentation generation quality. ACM Transactions on Software Engineering and Methodology31, pp. 1-28. Cited by: SS1.
* A. E. Johnson, T. J. Pollard, L. Shen, L. Lehman, H. H. Feng, M. Ghassemi, B. Moody, P. Szolovits, L. A. Celi, and R. G. Mark (2016)MIMIC-III, a freely accessible critical care database. Scientific data3, pp. 160035. Cited by: SS1.
* T. Kim, J. Heo, H. Kim, K. Shin, and S. Kim (2023)VITA:"Carefully chosen and weighted less' is better in Medication Recommendation. arXiv preprint arXiv:2312.12100. Cited by: SS1.
* T. H. Kung, et al. (2023)Performance of chat GPT on tps offline: potential for ai-assisted medical education using large language models. PLoS Digital Health2, pp. e0000198. Cited by: SS1.
* H. Le, T. Tran, and S. Venkatesh (2018)Dual memory neural computer for asynchronous two-view sequential learning. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining, pp. 1637-1645. Cited by: SS1.
* S. Liu, X. Wang, J. Du, Y. Hou, X. Zhao, H. Xu, Y. Wang, Y. Xiang, and B. Tang (2023)SHAPE: a sample-adaptive hierarchical prediction network for medication recommendation. IEEE Journal of Biomedical and Health Informatics27 (12), pp. 6018-6028. Cited by: SS1.
* Y. Liu, D. Iter, Y. Xu, S. Wang, R. Xu, and C. Zhu (2023)Gpteval: nlg evaluation using gpt-4 with better human alignment. arXiv preprint arXiv:2303.16634. Cited by: SS1.
* J. Mi, Y. Zu, Z. Wang, and J. He (2024)ACDNet: attention-guided collaborative decision network for effective medication recommendation. Journal of Biomedical Informatics149, pp. 149. Cited by: SS1.
* M. Moor, O. Banerjee, Z. S. Abad, et al. (2023)Foundation models for generalist medical artificial intelligence. Nature616, pp. 259-265. Cited by: SS1.
* A. OpenAI (2023)GPT-4 technical report. arXiv preprint arXiv:2303.08774. Cited by: SS1.
* E. Reiter (2018)A structured review of the validity of BLEU. Computational Linguistics4, pp. 393-401. Cited by: SS1.
* P. Robert (2023)5 ways chat GPT will change healthcare forever, for better. Forbes Magazine. Cited by: SS1.
* J. Shang, C. Xiao, T. Ma, H. Li, and J. Sun (2019)GAMENet: graph augmented mcmory networks for recommending medication combination. In proceedings of the AAAI Conference on Artificial Intelligence, pp. 1126-1133. Cited by: SS1.
* K. Singhal, T. Tu, J. Gottweis, R. Sayres, E. Wulczyn, L. Hou, et al. (2023)Towards expert-level medical question answering with large language models. arXiv preprint arXiv:2305.09617. Cited by: SS1.
* E. Steinberg, Y. Xu, J. Fries, and N. Shah (2023)Self-supervised time-to-event modeling with structured medical records. arXiv preprint arXiv:2301.03150. Cited by: SS1.
* Y. Tan, C. Kong, L. Yu, P. Li, C. Chen, X. Zheng, V. S. Hertzberg, and C. Yang (2022)4SDrug: symptom-based set-to-set small and safe drug recommendation. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD '22, New York, NY, USA, pp. 3970-3980. External Links: ISBN 9781450393850 Cited by: SS1.
* A. J. Thirunavukarasu, D. S. J. Ting, K. Elangovan, et al. (2023)Large language models in medicine. Nature Medicine29, pp. 1930-1940. Cited by: SS1.
* A. J. Thirunavukarasu, et al. (2023)Trialling a large language model (chat GPT) in general practice with the applied knowledge test: observational study demonstrating opportunities and limitations in primary care. JMIR Medical Education9, pp. e46599. Cited by: SS1.
* U. S. Food and D. Administration (2023)Information on acetaminophen. Note: [https://www.fda.gov/drugs/information-drug-class/acetaminophenAccessed](https://www.fda.gov/drugs/information-drug-class/acetaminophenAccessed): 2024-01-24 Cited by: SS1.
* A. J. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin (2017)Attention is all you need. In Advances in Neural Information Processing Systems, H. Dy, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.), pp. 30. Cited by: SS1.
* S. Wang, P. Ren, Z. Chen, Z. Ren, J. Ma, and M. de Rijke (2019)Order-free medicine combination prediction with graph convolutional reinforcement learning. In Proceedings of the 28th ACM international conference on information and knowledge management, pp. 1623-1632. Cited by: SS1.

Wang, Y.; Chen, W.; Pi, D.; Yue, L.; Wang, S.; and Xu, M. 2021a. Self-Supervised Adversarial Distribution Regularization for Medication Recommendation. In _IJCAI_, 3134-3140.
* [Wang et al.2021b] Wang, Y.; Chen, W.; Pi, D.; Yue, L.; Xu, M.; and Li, X. 2021b. Multi-hop reading on memory neural network with selective coverage for medication recommendation. In _Proceedings of the 30th ACM International Conference on Information & Knowledge Management_, 2020-2029.
* [Wornow et al.2023] Wornow, M.; et al. 2023. The shaky foundations of large language models and foundation models for electronic health records. _npj Digital Medicine_.
* [Wu et al.2023] Wu, J.; He, K.; Mao, R.; Li, C.; and Cambria, E. 2023. MEGACare: Knowledge-guided multi-view hypergraph predictive framework for healthcare. _Information Fusion_, 100: 101939.
* [Wu et al.2022] Wu, R.; Qiu, Z.; Jiang, J.; Qi, G.; and Wu, X. 2022. Conditional generation net for medication recommendation. In _Proceedings of the ACM Web Conference 2022_, 935-945.
* [Yang et al.2021] Yang, C.; Xiao, C.; Ma, F.; Glass, L.; and Sun, J. 2021. Safe-Drug: Dual Molecular Graph Encoders for Recommending Effective and Safe Drug Combinations. In Zhou, Z.-H., ed., _Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21_, 3735-3741. International Joint Conferences on Artificial Intelligence Organization. Main Track.
* [Yang et al.2023] Yang, N.; Zeng, K.; Wu, Q.; and Yan, J. 2023. Molerec: Combinatorial drug recommendation with substructure-aware molecular representation learning. In _Proceedings of the ACM Web Conference 2023_, 4075-4085.
* [Yang et al.2022] Yang, X.; Chen, A.; PourNejatian, N.; et al. 2022. A large language model for electronic health records. _npj Digital Medicine_, 5: 194.
* [Zhang et al.2023a] Zhang, S.; Xu, Y.; Usuyama, N.; Bagga, J.; Tinn, R.; Preston, S.;...; and Poon, H. 2023a. Large-scale domain-specific pretraining for biomedical vision-language processing. _arXiv preprint_, arXiv:2303.00915.
* [Zhang et al.2023b] Zhang, S.; et al. 2023b. Large-Scale Domain-Specific Pretraining for Biomedical Vision-Language Processing. _arXiv_, 2303.00915.
* [Zhang et al.2017] Zhang, Y.; Chen, R.; Tang, J.; Stewart, W. F.; and Sun, J. 2017. LEAP: learning to prescribe effective and safe treatment combinations for multimorbidity. In _proceedings of the 23rd ACM SIGKDD international conference on knowledge Discovery and data Mining_, 1315-1324.
* [Zhu et al.2017] Zhu, J.-Y.; Park, T.; Isola, P.; and Efros, A. A. 2017. Unpaired image-to-image translation using cycle-consistent adversarial networks. In _Proceedings of the IEEE international conference on computer vision_, 2223-2232.

## Appendix

### Definitions

* **Precision** Precision denotes the proportion of the intersection of model-recommended drugs and real-labelled drugs to the model-predicted drugs. the higher the value of precision, the more accurate the model-recommended drugs are. In this definition, we use the average Precision of all samples as a judgement criterion, so there exists a process of finding the mean. The calculation method of **Precision** is shown as follows: \[\frac{1}{N}\sum_{i}^{N}\frac{|\mathbf{p^{(i)}}\cap\mathbf{D^{(i)}}|}{|\mathbf{D^{(i)}}|}\] where \(p^{(i)}\) denotes the predicted drug set of the model, \(D^{(i)}\) the number of drugs in the basic real drug set, and \(i\) denotes the index of the test drug set.
* **Drug-Drug-Interaction rate (DDI rate)** Drug-drug interactions (DDIs) refer to the phenomenon where two or more drugs interact with each other and negatively affect the way they work in the body. This can lead to a variety of outcomes such as reduced efficacy, increased side effects, or even toxicity of a particular drug. In our work, we define the DDI rate as a measure that implies the proportion of drug combinations provided by the model that result in a DDI situation. The **DDI rate** can be calculated by the following method: \[\frac{1}{N\sum_{x,y}\mathbf{1}}\sum_{i}^{N}\left|\left\{(d_{x},d_{y})\in\left(\mathbf{ D}^{(i)}\ \&\ \mathbf{\mathcal{E}}_{ddi}\right)\right\}\right|\] In the formula above, each drug pair \((d_{x},d_{y})\) will be counted in the set if this pair exist in the drug knowledge base, which represented as \(\mathcal{E}_{ddi}\).

### Source code

The source code can be found on the repository1.

Footnote 1: [https://github.com/Undefeated-man/Cycletrans/blob/main/README.md](https://github.com/Undefeated-man/Cycletrans/blob/main/README.md)