# Towards Generalization in Subitizing with Neuro-Symbolic Loss using

Holographic Reduced Representations

Mohammad Mahmudul Alam \({}^{1}\), Edward Raff \({}^{1,2,3}\), Tim Oates \({}^{1}\)

\({}^{1}\) University of Maryland, Baltimore County

\({}^{2}\) Booz Allen Hamilton

\({}^{3}\) Syracuse University

###### Abstract

While deep learning has enjoyed significant success in computer vision tasks over the past decade, many shortcomings still exist from a Cognitive Science (CogSci) perspective. In particular, the ability to subitize, i.e., quickly and accurately identify the small (\(\leq 6\)) count of items, is not well learned by current Convolutional Neural Networks (CNNs) or Vision Transformers (ViTs) when using a standard cross-entropy (CE) loss. In this paper, we demonstrate that adapting tools used in CogSci research can improve the subitizing generalization of CNNs and ViTs by developing an alternative loss function using Holographic Reduced Representations (HRRs). We investigate how this neuro-symbolic approach to learning affects the subitizing capability of CNNs and ViTs, and so we focus on specially crafted problems that isolate generalization to specific aspects of subitizing. Via saliency maps and out-of-distribution performance, we are able to empirically observe that the proposed HRR loss improves subitizing generalization though it does not completely solve the problem. In addition, we find that ViTs perform considerably worse compared to CNNs in most respects on subitizing, except on one axis where an HRR-based loss provides improvement. Code is available on GitHub.1

Footnote 1: GitHub: [https://github.com/MahmudulAlam/Subitizing](https://github.com/MahmudulAlam/Subitizing)

## Introduction

Subitizing, also referred to as numerosity, is the ability to recognize small counts nearly instantaneously [13], allowing for fast, accurate, and confident identification of an object's count in limited space. The ability to recognize drops quickly after four items [12]. Subitizing is a cognitive function distinct from explicit counting [10], and recent work has shown that Convolutional Neural networks (CNNs) fail to subitize on simple MNIST-like tasks [23].

The failure is astonishing because a simple, hard-coded convolutional kernel is capable of perfectly solving the subitizing tasks [23]. This means a CNN captures the hypothesis space of a valid solution, so it is unclear what component is unable to reach this target goal. Seemingly there are two options: the need for better optimization strategies, or alternative loss functions. While a different loss function may sound implausible when using cross-entropy (CE) on a simple, clean dataset, we explore changing the loss function as the strategy in this work.

The goal of this work is to investigate how a neuro-symbolic approach affects the generalization of subitizing in a CNN, but not to solve the problem. We devise a prediction and loss strategy built from the Holographic Reduced Representations (HRRs) [14] which has a long successful history of its use in Cognitive Science (CogSci) research.

The proposed loss function is applied to the same set of experiments as proposed by [23] where a CNN failed to subitize. Our results indicate an improvement in generalization on most of the tasks under consideration but are not yet a complete answer to the subitizing task. Favorably, the errors in generalization with our approach are more congruent with the expectation that performance will decrease after 5 objects are present, though the accuracy is still lower than human performance. Moreover, the same set of experiments is performed on a Vision Transformer (ViT) [15] where the proposed loss function demonstrates improvement in generalization over CE loss and results are more in accordance with subitization expectation as well.

In summary, our contributions are: 1) An adaption of the HRR into a loss function for classification. 2) A empirical evaluation of the impact of subitizing, and a qualitative evaluation of the cases where subitizing is improved or hindered based on the loss function. Note that improved predictive accuracy is not a goal, and difficult to deconflate from subitization performance due to background items. In addition, classic object detection methods (e.g., FasterRCNN [14]) are not a proxy of subitizing because such methods perform explicit object counting, where subitizing is a task of instantaneous recognition of numerosity -- not a sequential process of identification and counting.

The remainder of the paper is organized as follows. First, different types of vector symbolic architectures, related works, and our motivation for using HRRs are covered. Next, a brief overview of HRRs is provided and the methodology of the proposed HRR loss function is described. Afterward, all the experiments and the corresponding results are described. Finally, concluding remarks, limitations, and future work are presented.

## Related Work

Vector Symbolic Architectures (VSA) have been researched since seminal work by [14], who made an ever-green argument for their use. In short, VSAs provide a foundation for combining the benefits of connectionist architectures (robustness to deviations in input, and learning) with the benefits of symbolic AI (reasoning, logical inference). This is made possible by defining a system in which arbitrary concepts are assigned to specific vectors, and a set of _binding_ and _unbinding_ operations are defined, which associate or disassociate two vectors respectively [13]. Most VSAs use a fixed feature space for their representation, and thus necessarily introduce noise as more items are bound/unbound. Barring this noise they can symbolically manipulate the concepts associated with the original vectors.

Many such VSAs exist today [15, 16, 17, 18]. For example, given vectors representing running, sleeping, cat, and dog, one can compose a vector \(\mathbf{x}=\text{bind({running}, cat)}+\text{bind({sleeping}, dog)}\), and then generally determine which animal was sleeping by computing \(\text{unbind({\mathbf{x}},sleeping)}\approx dog\). While the specifics vary between VSAs, we will use the Holographic Reduced Representation proposed by [10], which is both commutative and associative in the binding and unbinding operations and has been used successfully in multiple differentiable applications [1, 16, 15].

The motivation for using HRR is that it may specifically engender better subitizing which is inspired by current literature in CogSci research that leverages the HRR. The seminal work by [13] developed "Spaun,"[1] a visual input-based brain model implemented using HRRs and able to perform several cognitive tasks like counting, question answering, rapid variable creation, and others. The HRR has been implemented in a spiking infrastructure [1] for biological plausibility, but has also shown utility in analogy reasoning [12], and solving Raven's Progressive Matrices [14].

Little work has been done investigating subitizing via machine learning. Early work by [10] treated the classification task from a purely ML perspective looking for enhanced performance. Later work showed that endowing an object segmentation network with the subitizing task improved the saliency of individual object recognition [15, 16]. Our work is concerned with the generalization of subitizing in simple images, which a CNN is not able to do, as shown by [20]. We use their MNIST-like shape, color, and edge generalization tasks to measure if an HRR-based loss function can improve the generalization of subitizing in simple CNNs [20]. This allows us to isolate the problem to just subitization, and show that the HRR loss does improve results for most generalization tasks.

Due to the severe deficiency of modern CNNs to subitize simple images, we consider many possible related tasks out of scope in our study. This includes prior work in other visual aspects like foveation [16] and visual reasoning [15], which intersect machine learning and CogSci. Our goal is only to study how a tool in CogSci modeling, the HRR, impacts CNNs' robustness to the cognitive task of subitizing. Because CNNs cannot yet perform the task at human levels, we also consider matching human reaction times and performance matters for future work.

## Methodology

### Background

Before diving into the construction of our loss function, we will first review the details of the HRR. HRRs are a type of VSA that represent compositional structure using circular convolution in distributed representations [10]. Given vectors \(\mathbf{x}_{i}\) and \(\mathbf{y}_{i}\) in a \(d\)-dimensional space \(\mathbb{R}^{d}\), Plate [11] used a circular convolution to define a _binding_ operation between these two vectors sampled from a Normal distribution. This can be specified more succinctly using the Fourier transform \(\mathcal{F}(\cdot)\) and its inverse \(\mathcal{F}^{-1}(\cdot)\). Specifically, the resulting vector \(\mathcal{B}\in\mathbb{R}^{d}\) of binding \(\mathbf{x}_{i}\) and \(\mathbf{y}_{i}\) is given by \(\mathcal{B}=\mathbf{x}_{i}\)\(\mathbf{\overleftarrow{\mathcal{B}}}\)\(\mathbf{y}_{i}=\mathcal{F}^{-1}(\mathcal{F}(\mathbf{x}_{i})\odot\mathcal{F}(\mathbf{y}_{i}))\) where \(\odot\) indicates element-wise multiplication. Here we use the symbol \(\mathbf{\overleftarrow{\mathcal{B}}}\) to denote the binding operation.

The retrieval of bound components is referred to as _unbinding_. A vector can be retrieved by constructing an inverse function \(\dagger:\mathbb{R}^{d}\rightarrow\mathbb{R}^{d}\) so that it complies with the identity function \(\mathcal{F}(\mathbf{z}_{i}^{\dagger})\cdot\mathcal{F}(\mathbf{z}_{i})=\vec{1}\) where \(\mathbf{z}_{i}^{\dagger}\) is the inverse of the vector \(\mathbf{z}\) given by \(\mathbf{z}_{i}^{\dagger}=\mathcal{F}^{-1}\left(1/\mathcal{F}(\mathbf{z}_{i})\right)\). To unbind \(\mathbf{x}_{i}\) from \(\mathcal{B}\), we circularly convolve its inverse: \(\mathcal{B}\)\(\mathbf{\overleftarrow{\mathcal{B}}}\)\(\mathbf{x}_{i}{}^{\dagger}\approx\mathbf{y}_{i}\). The necessary condition for these operations to behave as expected is an initialization procedure. As originally proposed by [10], each vector is sampled from a Normal distribution as \(\mathbf{z}_{i}\sim\mathcal{N}(0,1/d)\). This sampling means that in expectation, the above binding and unbinding steps will work for random pairs of vectors. However, the inversion operation is numerically unstable, and originally a pseudo-inverse was proposed that traded a large numerical error for a smaller approximation error. However, more recently [1] proposed a projection operation \(\pi(\cdot)\) to enforce that the inverse will be numerically stable, and exactly equal to the faster pseudo-inverse of [10]. This is done by a projection \(\pi(\cdot)\) onto the ball of complex unit magnitude, \(\pi(\mathbf{z}_{i})=\mathcal{F}^{-1}\left(\left.\mathcal{F}(\mathbf{z}_{i})/|\mathcal{ F}(\mathbf{z}_{i})|\right.\right)\). We make use of this projection step to initialize the vectors in our work.

### HRR Loss Function

In this paper, experiments are performed using both CNN and ViT models that take an image as input and predict the number of objects present in that image. To train such models, a standard softmax cross entropy (CE) loss can approximate the one-hot representation of the associated class/count. In our approach, we have taken a different strategy to devise the HRR loss function. We re-interpret the logits of CNN and ViT as an HRR vector instead of approximating a one-hot encoding. We then convert the logits to a class prediction by associating each class with its own unique HRR

[MISSING_PAGE_FAIL:3]

[MISSING_PAGE_FAIL:4]

figure, it is obvious that the changes in the test images are immense compared to the training images from a network's perspective. From a human perspective, this is quite an easy task to generalize after learning from the training images. Both of the methods also fail the subitizing test. A human being can count a lower number of objects with less effort than a higher number of objects. Nevertheless, the CE classification approach has achieved \(16\%\) accuracy for class \(1\) and \(25\%\) for class \(6\). Likewise, the HRR-based method has achieved \(9.3\%\) for class \(1\) and \(12.2\%\) for class \(6\). However, in the case of the ViT, while the performance using both losses degrades and degenerates, the HRR loss shows better generalization compared to the CE approach.

### Experiment of Region-Boundary Duality

Differentiating between objects from the boundary representation is vital to recognition [10]. Humans can easily identify objects, separate and count objects given just their boundaries. To examine the network's ability to generalize across the region-boundary duality, the network is

\begin{table}
\begin{tabular}{c c c c c c c c c c c} \hline \hline  & \multicolumn{2}{c}{50\% Larger} & \multicolumn{2}{c}{Triangles} & \multicolumn{2}{c}{Squares} & \multicolumn{2}{c}{Color Swap} & \multicolumn{2}{c}{White Rings} \\ \cline{2-11} Target & HRR & CE & HRR & CE & HRR & CE & HRR & CE & HRR & CE \\ \hline
1 & 1.000 & 1.000 & **0.997** & 0.327 & **1.000** & 0.876 & 0.093 & 0.160 & 0.033 & 0.004 \\
2 & 0.920 & **0.997** & **0.787** & 0.441 & **0.914** & 0.811 & 0.228 & **0.340** & 0.007 & 0.002 \\
3 & 0.967 & **0.990** & **0.715** & 0.361 & **0.964** & 0.641 & 0.388 & **0.680** & 0.000 & 0.010 \\
4 & 0.953 & **0.959** & **0.541** & 0.287 & **0.944** & 0.686 & 0.370 & **0.670** & 0.003 & 0.096 \\
5 & **0.904** & 0.672 & **0.619** & 0.364 & **0.900** & 0.549 & 0.251 & **0.420** & 0.019 & **0.194** \\
6 & **0.815** & 0.549 & 0.883 & _0.930_ & 0.888 & _0.978_ & 0.122 & **0.250** & _1.000_ & _0.989_ \\ \hline \hline \end{tabular}
\end{table}
Table 1: Results of the CNN where **bold** are best unless the result is due to consistent _over/under accounting at the boundary_. No result is marked “best” when performance is worse than random guessing (\(\leq 16.7\%\)) or similar. The HRR approach generalizes better for the first three tasks (or is closely behind) but degrades on the color swap task. Both methods fail on the last test.

\begin{table}
\begin{tabular}{c c c c c c c c c c c} \hline \hline  & \multicolumn{2}{c}{50\% Larger} & \multicolumn{2}{c}{Triangles} & \multicolumn{2}{c}{Squares} & \multicolumn{2}{c}{Color Swap} & \multicolumn{2}{c}{White Rings} \\ \cline{2-11} Target & HRR & CE & HRR & CE & HRR & CE & HRR & CE & HRR & CE \\ \hline
1 & 1.000 & 1.000 & **0.997** & 0.327 & **1.000** & 0.876 & 0.093 & 0.160 & 0.033 & 0.004 \\
2 & 0.920 & **0.997** & **0.787** & 0.441 & **0.914** & 0.811 & 0.228 & **0.340** & 0.007 & 0.002 \\
3 & 0.967 & **0.990** & **0.715** & 0.361 & **0.964** & 0.641 & 0.388 & **0.680** & 0.000 & 0.010 \\
4 & 0.953 & **0.959** & **0.541** & 0.287 & **0.944** & 0.686 & 0.370 & **0.670** & 0.003 & 0.096 \\
5 & **0.904** & 0.672 & **0.619** & 0.364 & **0.900** & 0.549 & 0.251 & **0.420** & 0.019 & **0.194** \\
6 & **0.815** & 0.549 & 0.883 & _0.930_ & 0.888 & _0.978_ & 0.122 & **0.250** & _1.000_ & _0.989_ \\ \hline \hline \end{tabular}
\end{table}
Table 1: Results of the CNN where **bold** are best unless the result is due to consistent _over/under accounting at the boundary_. No result is marked “best” when performance is worse than random guessing (\(\leq 16.7\%\)) or similar. The HRR approach generalizes better for the first three tasks (or is closely behind) but degrades on the color swap task. Both methods fail on the last test.

Figure 3: Sample images of experiment 2 where circles of classes \(1\) to \(6\) are replaced by triangles and squares shown in (a). Filters that rely on the curvature of a circle explicitly will perform poorly on this task, which is evident in the CE approach’s lower accuracy. Saliency maps of the experiment 2 images are shown in (b) for HRR loss and (c) for CE loss. HRR’s attention is concentrated on the informative regions, i.e., boundary regions whereas attention is more distributive in the case of CE.

tested using images of white circle rings on a black background. Examples of these test images along with saliency maps are presented in Figure 5, and the results are in the 'White Rings' columns of Table 1 and Table 2.

Recall that the network is originally trained on the images in Figure 1. From the network's perspective, the rings of white circles are completely new images. As a result, both the CE classification approach with softmax activation and the HRR classification approach with the key-value transformation layer approach degrade in performance. In the case of CNN, we can see degeneracy for both CE and HRR losses except for class \(6\) where both methods overcount and have achieved \(98.9\%\) and \(100\%\) accuracy, respectively. This is peculiar from the subitizing point of view because the accuracy for classes with a single ring of a circle in each approach is \(0.4\%\) and \(3.3\%\), respectively. However, in the case of the ViT, we can see the effectiveness of the HRR loss over CE loss for classes \(1\) to \(4\) with a big margin ranging from \(4\%\) to \(58\%\). For classes \(5\) and \(6\), HRR loss remains consistent with the subitizing pattern with lower accuracy than CE loss, but for class \(6\) the CE loss overcounts. In conclusion, the CNN lacks the ability to generalize across the region-boundary duality and fails on this more complex subitizing task. On the other hand, the ViT with HRR loss shows robust performance in generalization on this complex subitizing task.

### Boundary Representation Tests

Experiments 1 to 4 demonstrate CNN's lack of generalization in learning. To improve the abstraction ability of CNNs, Wu et. al. Wu et al. (2019) suggested learning from the boundary representation of objects. Instead of learning from single-shaped images, each class is built with different-shaped polygons with n sides. This should eliminate the shape bias in test results. The size will be altered to allow isolation of generalization to fundamental subitizing ability rather than change the re-use of shape patterns. Moreover, each object is represented by its boundary which bridges the representation of the black object on a white background and the white object on a black background. Figure 6 illustrates sample images of different shapes and sizes of objects with the boundary representation.

The network is re-trained using \(80\%\) of the images of Figure 6 and the remaining \(20\%\) of the images is used for testing. The accuracy on a test set of in-distribution is shown in Table 3. While the CE loss appears to obtain better training accuracy, the goal of this study is the generalization of subitizing ability. As such the results in Table 3 are more interesting because the in-distribution results are seen to imply that the HRR loss is worse, but we will see that it has a meaningful impact on generalization. This nuance would be difficult to identify in standard computer vision datasets.

To inspect how much generalization is achieved by training the network with images of object boundaries, the test

Figure 4: Sample images of experiment 3 where the circle and background colors are swapped in the test images shown in (a). Saliency maps of the HRR and CE loss are shown in (b) and (c), respectively. The attention of the network is more focused on the boundary region in the case of HRR.

Figure 5: Sample images of experiment 4 where the circles are represented by the boundary edges shown in (a). This is the most challenging generalization task, as it changes the ratio of white and black pixels. Saliency maps for object region-boundary duality are shown in (b) and (c) for HRR and CE, respectively.

Figure 6: Sample images of boundary representation of the various shaped objects are shown in (a). In all cases with the CE loss shown in (c), we see spurious attention placed on empty regions of the input - generally increasing in magnitude with more items. By contrast, the HRR loss shown in (b) keeps activations focused on the actual object edges and appears to suffer only for large \(n\) when objects are placed too close together.

images are scaled up and down by \(50\%\). Next, we will examine how boundary representation helps towards generalization. Intriguingly, the CE method does not follow the expected subitizing degradation pattern, though our HRR approach is closer to achieving it for the 50% larger case.

Table 4 reveals how the results deteriorate by only changing the scale of the object. However, in the case of scaling up, both of the methods show solid evidence of human-like subitizing, i.e., the accuracy decreases as the number of objects in the image increases. The proposed HRR loss approach has achieved an average accuracy of \(49\%\) whereas the CE approach has achieved an average accuracy of \(45.6\%\), but the CE's performance is inflated in the sense that it has a higher training accuracy and drops precipitously.

In the case of scaling down, no apparent subitizing pattern is present for either method. The proposed method achieved \(100\%\) accuracy for class \(1\) due to under-counting and failed to generalize for the rest of the classes. Conversely, the CE approach has achieved \(98.8\%\) accuracy due to over-counting for class \(6\) and failed to generalize for the rest of the classes. Overall, the boundary representation has helped the network's abstraction ability of subitizing but failed to generalize, especially in the case of scaling down.

The saliency maps of the boundary representation test images are presented in Figure 6. In the boundary representation tests, decisions are supposed to be made by the edge/boundary representation. The saliency maps reveal how HRR loss is concentrating networks' attention in the boundary regions whereas attention is much diffused in the case of CE loss. Moreover, based on the observation of saliency maps of correct and incorrect predictions following conclusions (see Appendix A for details) are made:

* Even when the CE-based model is **correct**, its saliency map indicates it uses the inside region of an object and the area around the object/background toward its prediction in almost all cases.
* When the HRR loss-based model is **correct**, it rarely activates for anything besides the object boundary and does not tend to focus on the inside content of an object.
* When the HRR-based model is **correct**, the edges of the objects in the saliency map are usually nearly-complete, and large noisy activations can be observed surrounding the boundary regions.
* When the CE-based model is **incorrect**, it often has two objects that are nearby each other. When this happens, the CE saliency map tends to produce especially large activations between the objects, creating an artificial "bridge" between the two objects.
* When the HRR-based loss is **incorrect**, it tends to have a saliency map that is either 1) activating on the inside content of the object, or 2) has large broken/incomplete edges detected for the object.

## Conclusion and Future Work

In this paper, a neuro-symbolic loss function is proposed using HRR to investigate the subitizing ability of deep learning networks such as CNN and ViT. In the four experiments, the HRR-based loss appears to improve the results, especially toward higher subitizing generalization. ViT performed comparatively worse than CNN, however, in general, ViT with HRR loss shows better generalization. In one case of CNN, HRR's performance has degraded, but still non-trivial performance, and in one case both the HRR loss and CE loss have degenerated worse-than-random guessing. In the case of ViT, HRR's effectiveness in generalization remains consistent particularly in 'white rings' where it outperformed CE over a big margin ranging from \(4\%\) to \(58\%\).

Our results are intriguing in that we did not design the HRR loss to be biased toward numerosity via symbolic manipulation, but instead defined a simple loss function as a counterpart to the CE loss that retains a classification focus. This may imply some unique benefit to the HRR operator in improving generalization and supports the years of prior work using it for CogSci research.

While more work remains to improve innate subitizing generalization, we are not yet ready to move past these simplistic benchmarks. While [22] have thoroughly accounted for many potential information leakage sources, the under and over-counting bias remains a limitation to our work and others. This need for improved experimental design of simple tasks also highlights the general need to thoroughly test CNN and ViT broadly and the limitations and likelihood of encountering out-of-distribution data.

\begin{table}
\begin{tabular}{c c c c c} \hline \hline  & \multicolumn{2}{c}{50\% Larger} & \multicolumn{2}{c}{50\% Smaller} \\ \cline{2-5} Target & HRR & CE & HRR & CE \\ \hline
1 & 0.935 & **0.991** & _1.000_ & 0.687 \\
2 & 0.715 & **0.984** & 0.005 & **0.390** \\
3 & **0.585** & 0.496 & 0.005 & 0.021 \\
4 & **0.300** & 0.207 & 0.000 & 0.014 \\
5 & **0.225** & 0.032 & 0.000 & 0.043 \\
6 & **0.180** & 0.026 & 0.000 & _0.988_ \\ \hline \hline \end{tabular}
\end{table}
Table 4: Generalization results for the boundary edge maps. **Bold** results are the best unless the result is due to _over/under accounting at the boundary_. No result is marked “best” when worse than random guessing (\(\leq 16.7\%\)).

\begin{table}
\begin{tabular}{c c c} \hline \hline  & \multicolumn{2}{c}{Boundary Edge Representation} \\ \cline{2-3} Target & HRR & CE \\ \hline
1 & 1.000 & 1.000 \\
2 & 0.985 & 1.000 \\
3 & 0.950 & 0.970 \\
4 & 0.855 & 0.930 \\
5 & 0.635 & 0.790 \\
6 & 0.795 & 0.920 \\ \hline \hline \end{tabular}
\end{table}
Table 3: In distribution results, show baseline training performance of the HRR and CE-based loss functions on the edge-map distribution, rather than testing generalization. In practice, while the HRR has a lower training accuracy, it has better generalization.

[MISSING_PAGE_FAIL:8]

Schlegel, K.; Neubert, P.; and Protzel, P. 2021. A comparison of vector symbolic architectures. _Artificial Intelligence Review_.
* Simonyan et al. (2013) Simonyan, K.; Vedaldi, A.; and Zisserman, A. 2013. Deep inside convolutional networks: Visualising image classification models and saliency maps. _arXiv preprint arXiv:1312.6034_.
* Smolensky (1990) Smolensky, P. 1990. Tensor product variable binding and the representation of symbolic structures in connectionist systems. _Artificial Intelligence_, 46(1): 159-216.
* Tokita and Ishiguchi (2010) Tokita, M.; and Ishiguchi, A. 2010. How might the discrepancy in the effects of perceptual variables on numerosity judgment be reconciled? _Attention, Perception, & Psychophysics_, 72(7): 1839-1853.
* Trick and Pylyshyn (1994) Trick, L. M.; and Pylyshyn, Z. W. 1994. Why are small and large numbers enumerated differently? A limited-capacity preattentive stage in vision. _Psychological Review_, 101(1): 80-102.
* Wu, Zhang, and Shu (2019) Wu, X.; Zhang, X.; and Shu, X. 2019. Cognitive deficit of deep learning in numerosity. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 33, 1303-1310.
* Zhang et al. (2015) Zhang, J.; Ma, S.; Sameki, M.; Sclaroff, S.; Betke, M.; Zhe Lin; Xiaohui Shen; Price, B.; and Mech, R. 2015. Salient Object Subitizing. In _2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)_, 4045-4054. IEEE. ISBN 978-1-4673-6964-0.

### Saliency Maps Reviews

The saliency maps of the correct and incorrect predictions by the network both in the case of CE and HRR loss are observed. Example images along with saliency maps for CE loss are given in Figure 7 for correct prediction and in Figure 8 for incorrect predictions. When a network trained with CE loss makes a correct prediction, its saliency maps show it uses the inside region of an object and the area around the object/background toward its prediction in almost all cases.

However, when a CE-based model makes an incorrect prediction, often its saliency map tends to produce large activations between the multiple objects, creating an artificial "bridge" among them.

Saliency maps along with sample images for HRR-based loss are given in Figure 9 for correct predictions and in Figure 10 for incorrect predictions. While making correct predictions, the edges of the objects in the saliency map of the HRR-based model are usually nearly-complete and we can observe large noisy activations surrounding the boundary regions.

Nevertheless, when the HRR-based model makes an incorrect prediction, it tends to have a saliency map that is either 1) activating on the inside content of the object, or 2) has large broken/incomplete edges detected for the object.

Figure 8: Sample images with saliency maps in a CE-based model for **incorrect** predictions.

Figure 10: Sample images with saliency maps in a HRR-based model for **incorrect** predictions.

Figure 7: Sample images with saliency maps in a CE-based model for **correct** predictions.

Figure 9: Sample images with saliency maps in a HRR-based model for **correct** predictions.