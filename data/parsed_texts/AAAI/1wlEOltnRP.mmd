# TaxoKnow: Taxonomy as Prior Knowledge in the Loss Function of Multi-class Classification

Mohsen Pourvali, Yao Meng, Chen Sheng, Yangzhou Du

Lenovo Research, Beijing, China

{mpourvali, mengyao1, shengchen1, duyz1}@lenovo.com

###### Abstract

In this paper, we investigate the effectiveness of integrating a hierarchical taxonomy of labels as prior knowledge into the learning algorithm of a flat classifier. We introduce two methods to integrate the hierarchical taxonomy as an explicit regularizer into the loss function of learning algorithms. By reasoning on a hierarchical taxonomy, a neural network alleviates its output distributions over the classes, allowing conditioning on upper concepts for a minority class. We limit ourselves to the flat classification task and provide our experimental results on two industrial in-house datasets and two public benchmarks, RCV1 and Amazon product reviews. Our obtained results show the significant effect of a taxonomy in increasing the performance of a learner in semi-supervised multi-class classification and the considerable results obtained in a fully supervised fashion.

## Introduction

Large Language Models (LLMs), e.g., BERT and GPT-3, have made significant advances in Natural Language Processing (NLP). In general, pre-training, where a model first trains on massive amounts of data before being fine-tuned for a specific task, has proven to be an efficient technique for improving the performance of a wide range of language tasks [16].

If we break down the architecture of LLMs, we can categorize their components into two general concepts: Deep Neural Network (DNN) as a part of Machine Learning (ML), and Training Data. Despite all the advantages of LLMs, they come with some limitations. Starting from the very beginning, machine learning has its own limitations, from supervised ML which heavily relies on large amounts of human-labeled data to Reinforcement Learning (RL) which requires a very large number of interactions between the agent and the environment. The brittleness of deep learning systems is largely due to machine learning models being based on the independent and identically distributed (i.i.d.) assumption, which is not a realistic assumption in the real world. In general, Multi-Layer Perceptrons (MLPs) are good at generalizing within the space of training examples, but they perform poorly at generalizing outside the space of training examples, and this limitation is not improved even by adding more layers. So, the question is, what can be done? Can increasing the size of training data solve these shortcomings?

Another shortcoming, which is not addressed by simply using more data, is _curve fitting_[10], mapping inputs to outputs. If our systems rely solely on curve-fitting and statistical approximation, their inferences will necessarily be shallow [1]. Instead of inducing a more abstract and causal understanding of the world, they try to approximate the statistical curves of how words are used to infer how the world works.

Let us take a step back and explore another approach to training a machine, which is _Symbolic Machine_ learning. A symbolic machine combines a sophisticated reasoner with a large-scale knowledge base. Knowledge can be formulated in a logical function with symbolic variables, for example, \(\delta_{22}\) in Figure 1 expresses that for the set of variables \(<X_{1},X_{2},..,X_{6}>\), one and exactly one of \(X_{3},X_{4},\) or \(X_{5}\) must be true, with the rest being false. One well-known ex

Figure 1: A symbolic representation/sentence for node \(a_{2}\) in a higher level \(l_{2}\) of a hierarchical taxonomy for multi-class classificationample of a symbolic machine is CYC 1, It was launched in 1984 by Doug Lenat and required thousands of person-years of effort to capture facts about psychology, politics, economics, biology, and various other domains in a precise logical form. One famous test of CYC is the Romeo and Juliet quiz, in which CYC demonstrates an internal distillation of a complex scenario and provides an example of rich cognition. However, despite the extensive efforts put into CYC, it falls short compared to the remarkable results achieved by transformers and GPT-2, even without explicit knowledge engineering.

Footnote 1: www.cyc.com

What Gary Marcus (Marcus, 2020) believes is that symbol manipulation could be the solution, particularly for extrapolating beyond a training regime. Symbol manipulation, specifically the machinery of operations over variables, offers a natural albeit incomplete solution to the challenge of extrapolating beyond a training regime. It also provides a clear basis for representing structured representations (such as the tree structures foundational to generative linguistics) and records of individuals and their properties. It can bring a hybrid approach that combines the best of both worlds: the ability to learn from large-scale datasets and the capacity to represent abstract concepts. The power of combining statistical and symbolic artificial intelligence techniques to accelerate learning and improve transparency is exemplified by Mao et al. (2019).

In this work, we aim to integrate abstract/prior knowledge (Hierarchical Taxonomy of labels) into the structure of machine learning. As one of our contributions, we leverage symbolic manipulation to represent the taxonomy. According to Henry Kautz's proposal on Neural-Symbolic Computing (NSC) Garcez and Lamb (2023), our work can be categorized as type 5; \(NOURO_{SYMBOLIC}\); a tightly-coupled neural-symbolic system where a symbolic logic rule is mapped onto a distributed representation (an embedding) and acts as a soft-constraint (a regularizer) on the network's loss function. Additionally, we combine type 5 with a method from type 1; _SYMBOLIC NEURO SYMBOLIC_; which involves standard deep learning in which input and output of a neural network can be made of symbols. Our target is an imbalanced classification problem where we have a Hierarchical Taxonomy of labels as our prior knowledge.

Many real-world classification problems exhibit imbalanced class distributions. In current fully supervised classification tasks, models are trained on labeled datasets where labels are primarily injected into the objective function (e.g., cross-entropy) as prior knowledge. These labels typically originate from a larger hierarchical taxonomy, allowing for comprehensive reasoning over the labels. Labels in Machine Learning (ML), especially in supervised ML, play an important role. However, labels often present challenges. Despite the human cost required for labeling, labels are frequently incomplete, ambiguous, and redundant. Using a hierarchical taxonomy for labels can provide more information that leads to improved labels and ultimately enhances model quality in supervised learning, and even yields further gains in semi-supervised learning.

In this paper, we introduce two methods to represent and incorporate the hierarchical taxonomy. The first method (Section ) represents the taxonomy as constraints in Boolean logic. For example, Figure 1 illustrates a hierarchical taxonomy for class labels, where leaves at level \(l_{1}\) indicate the actual class labels used in the loss function (e.g., cross-entropy), and nodes at a higher level \(l_{2}\) indicate a higher level of conceptualization for the labels, which are typically not used in the classification algorithm. The second method (Section ) involves using Graph Convolutional Networks (GNN) to represent and incorporate the hierarchical taxonomy into the loss function. Our experimental results for both methods demonstrate the significant effect of higher levels of the hierarchical taxonomy in alleviating the unequal distribution of classes in severely imbalanced classification problems2.

Footnote 2: The code and datasets will be hosted on [https://github.com/mpourvali/TaxoKnow](https://github.com/mpourvali/TaxoKnow).

Our contributions in this paper focus on flat/general classification, referring to the standard multi-class classification problem. This differs from hierarchical classification, where the class set to be predicted is organized into a class hierarchy, typically represented as a tree or a Directed Acyclic Graph (DAG).

## Related Work

Imbalanced Classification:Approaches for dealing with imbalanced classification problems can be categorized into three groups: data-level approaches, algorithm-level techniques, and hybrid methods Johnson and Khoshgoftaar (2019). Data-level approaches aim to address the unequal distribution of classes by employing sampling techniques such as over-sampling the minority class or under-sampling the majority class. However, under-sampling may result in the loss of important information for the model to learn from, while over-sampling can increase training time and lead to overfitting Johnson and Khoshgoftaar (2019). Algorithm-level techniques, on the other hand, adjust the learning or decision process to give more importance to the minority class. Hybrid methods combine data-level and algorithm-level approaches in various ways to tackle the class imbalance problem Seiffert et al. (2009); Chen et al. (2021).

Taxonomy-aware Classification:The use of hierarchical concepts in classification has been explored in various studies. For example, Brust and Denzler (2020) leverages a publicly available hierarchy like WordNet to integrate additional domain knowledge into classification.

Existing works on integrating taxonomy into machine learning can generally be grouped into two approaches. The first approach involves _indirectly_ incorporating taxonomy information into the ML model, such as label expansion Li et al. (2017). The second approach focuses on _directly_ integrating taxonomy information into the model architecture Karamanolakis et al. (2020); Jenkins et al. (2021); Ong et al. (2022). Ong et al. (2022) demonstrates that using taxonomy information of plant species can alleviate class sparsity issues when optimizing for a large number of classes. In the domain of semi-supervised learning, [21] proposes techniques for incorporating coarse taxonomic labels to train image classifiers in fine-grained domains.

While previous works have explored the effectiveness of label taxonomies in hierarchical classification, our paper emphasizes the positive impact of hierarchical taxonomies in flat classification problems. To the best of our knowledge, our work is the first to propose injecting hierarchical taxonomies of labels as prior knowledge into flat classification problems. Our approach falls under algorithm-level techniques for addressing imbalanced classification problems, as we directly inject a hierarchical taxonomy of class labels as prior knowledge into the existing loss function (i.e., data-driven) of a deep neural network.

## Proposed Methods

We propose two approaches to represent and integrate the hierarchical taxonomy as prior knowledge into the loss function of a learning algorithm.

### Symbolic-based Approach

To integrate the hierarchical taxonomy of the classes into the loss function, we first represent the taxonomy as symbolic logical constraints. Building on the work of [21] we derive a differentiable semantic loss function that captures how well the neural network satisfies the constraints on its output.

General Notation.We employ concepts in propositional logic to formally define taxonomy and semantic loss. Boolean variables are written in uppercase letters (\(X,Y\)), and their instantiation (\(X=0\) or \(X=1\)) are written in lowercase (\(\mathbf{x},y\)). We write sets of variables in bold uppercase (\(\mathbf{X},\mathbf{Y}\)), and their joint instantiation in bold lowercase (\(\mathbf{x},\mathbf{y}\)). A literal is a variable (\(X\)) or its negation (\(\neg X\)). A logical sentence (\(\alpha\) or \(\beta\)) is created by variables and logical connectives (\(\wedge\), \(\vee\), etc.), and is also called a formula or constraint. A state \(\mathbf{x}\) satisfies a sentence \(\alpha\), denoted as \(\mathbf{x}\models\alpha\), if the sentence evaluates to be true in that world, as defined in the usual way. The output vector of a neural network is denoted by \(\mathsf{p}\), where each value in \(\mathsf{p}\) represents a probability of an output in \([0,1]\). The output vector of a set of sentences is denoted by \(\mathbf{s}\), where each value in \(\mathsf{s}\) represents a satisfaction value in \([0,1]\).

Taxonomy.Each level of concepts in a taxonomy is denoted as \(l_{i},i\in[1,K]\), where \(K\) is node-based length of the taxonomy and \(l_{1}\) indicates the leaves of the taxonomy, which is associated with the class labels. Each node in taxonomy except nodes in the leaves is denoted as \(a_{i}\). For instance, in Figure 1, for a taxonomy used in multi-class classification, sentence \(\delta_{22}\) states that for a set of indicators \(\mathbf{X}=\{X_{1},..,X_{6}\}\), one and exactly one of \(X_{3},X_{4},X_{5}\) must be true, while the rest must be false. This statement indeed represents node \(a_{2}\) of the taxonomy in terms of its children/variables (\(X_{3}\), \(X_{4}\), \(X_{5}\)). To represent hierarchical nature of the taxonomy, a set of variables \(\mathbf{B}=\{B_{1},B_{2},..,B_{K-1}\}\) is defined over the taxonomy levels. \(B_{1},...,B_{K-1}\) correspond to the variables of each non-leaf node in the taxonomy tree, where each variable of \(\mathbf{B}\) corresponds to a set of one-hot vectors \(b_{j}\), e.g., \(b_{1}\) and \(b_{2}\) correspond to level 1 and level 2, as shown in Figure 2 and Figure 3. \(b_{j}\) corresponds to one-hot vector over \(a_{0},a_{1},...,a_{m}\), where \(m\) is number of nodes in level \(l_{j}\), e.g., as it is shown in Figure 1\(a_{1},a_{2},a_{3}\) for level \(l_{2}\). A logical sentence \(\beta\) is created from variables \(\mathbf{B}\) and logical connective \(\wedge\). For a given taxonomy there would be a sentence \(\delta_{ij}\) corresponding to the node \(a_{i}\) (i.e., propositional logic) which all sentences for each level \(l_{j}\) are stored in \(d_{j}\) (\(d_{1}\) and \(d_{2}\) as it's shown in Figure 2), and sentence \(\alpha\) is defined over \(d_{1},d_{2},...,d_{K-1}\).

Semantic Loss.The semantic loss \(L^{s}(\alpha,\beta,\mathsf{p},\mathsf{s})\) is defined as a function of sentences (\(\alpha\),\(\beta\)) in propositional logic, which is defined over variables \(\mathbf{X}=\{X_{1},X_{2},..,X_{n}\}\) and \(\mathbf{B}=\{B_{1},B_{2},..,B_{K-1}\}\), a vector of probabilities \(\mathsf{p}\) for variables \(\mathbf{X}\), and a satisfaction vector \(\mathsf{s}\) for variables \(\mathbf{B}=\{B_{1},B_{2},..,B_{K-1}\}\). The element \(\mathsf{p}_{i}\) denotes the predicted probability of variable \(X_{i}\), corresponding to a single output of the neural network. The element \(\mathsf{s}_{i}\) represents the satisfaction score of variable \(B_{i}\), corresponding to the output of a sentence \(\alpha\). Similar to [21], we provide two examples of integrating semantic loss \(L^{s}\) into an existing loss function as an additional regularization term, in both supervised and semi-supervised manners. Specifically, with a weight \(w\), Equation 1 shows the new loss.

\[existing\_loss+w\cdot semantic\_loss \tag{1}\]

Supervised-based Definition.In the Supervised-based definition, we assume that all the training dataset is labeled, and the hierarchical taxonomy is complete, meaning that for labeled class, all the upper parents are known. Formally, for a class label \(cl_{i}\), its \(K-1\) upper concepts in the taxonomy are given. With this assumption, let \(\mathsf{p}\) be a vector of probabilities, one for each variable in \(\mathbf{X}\), let \(\alpha\) be a sentence over \(\mathbf{X}\), and \(\beta\) be a sentence over \(\mathbf{B}\). Equation 2 represents the hierarchical taxonomy as a logical constraint.

\[L^{s}(\alpha,\beta,\mathsf{p},\mathsf{s})\propto-\log\prod_{\mathbf{y}\models \beta}\sum_{\mathbf{x}\models\alpha}\prod_{i:\mathbf{X}\models X_{i}}\mathsf{ p}_{i}\prod_{i:\mathbf{X}\models X_{i}}(1-\mathsf{p}_{i}) \tag{2}\]

Figure 2: An illustration for supervised semantic loss. \(\iota_{1}\) is the matrix of model output for a batch, \(\iota_{2}\) is the matrix of one-hot vectors over nodes in level \(l_{2}\) in the batch, and \(\iota_{3}\) is the matrix of one-hot vectors over nodes in level \(l_{3}\) in the batch. \(|b_{i}|=|d_{i}|\) since each element in one-hot vector \(b\) is corresponding to a sentence \(\delta\) in \(d\).

where \(\mathbf{y}\) is a state that satisfies \(\beta\). By applying the negative logarithm, we enforce the training model to satisfy the constraint. Figure 2 provides an illustration of Equation 2.

Our goal is to develop a tractable loss for computing both semantic loss and its gradient. From propositional logic theories, we know that a Model is a solution to a given propositional formula \(\Delta\), and Model Counting or #SAT is the problem of computing the number of models for \(\Delta\). In case of mapping literals of the variables to non-negative real-valued weights, we will have Weighted Model Counting (WMC) [14, 15]. The well-known task of model counting corresponds to the special case where all literal weights are 1 (and counts thus restricted to the natural numbers), whereas probabilistic inference (Prob) in a setting where all variables are independently assigned truth values at random restricts the weight function \(\omega\) of WMC to values from [0, 1] such that weights of positive and negative literals for each var sum to one, i.e., for every variable \(\upsilon\), \(\omega(\upsilon)\in[0,1]\) and \(\omega(\neg\upsilon)=1-\omega(\upsilon)\)[16].

From [1], we know about differential circuit languages that compute WMCs, which are amenable to backpropagation. Following [14], the circuit compilation techniques from [1], namely the Sentential Decision Diagram (SDD), to construct a Boolean circuit representing semantic loss. The SDD circuit form exhibits two main properties: determinism and decomposability, allowing us to compute both the values and gradients of the semantic loss in time linear to the size of the circuit [1].

#### Semi-supervised-based Definition.

In this section, we demonstrate the integration of a hierarchical taxonomy with unlabeled data. In the Semi-supervised-based definition, the assumption is that there is unlabeled data and the hierarchical taxonomy is not complete. The semantic loss is defined for unlabeled data using an incomplete taxonomy. The labeled data is directly used in an existing loss function (e.g., cross entropy). For the unlabeled data, we employ the available deepest concepts/nodes from the root, and the upper node is considered in case of a missing lower node. In this definition of the semantic loss, since there are no conflicts between different levels of concepts in the hierarchical taxonomy, there is no need for a sentence \(\beta\) over **B**. The intuition behind this is to emphasize the information carried by unlabeled data and provide a level-based weighting for the incomplete taxonomy.

\[L^{s}(\alpha,\beta,\mathsf{p},\mathsf{s})\propto-\log\sum_{j\in\{1,K\}}\sum_{ \mathbf{X}|=\alpha}\prod_{i:\mathbf{X}|=X_{i}}\mathsf{p}_{i}\prod_{i:\mathbf{ X}|=X_{i}}(1-\mathsf{p}_{i}) \tag{3}\]

Equation 3 is illustrated in Figure 3, including the training batch and SDDs.

In essence, Equation 2 and 3 expand semantic loss [14] over hierarchical structure. They are proportional to the negative logarithm of the probability of generating a state that satisfies the constraint when sampling values according to \(\mathsf{p}\).

### GCN-based Approach

Graph Convolutional Networks is a powerful method presented for semi-supervised learning on graph-structured data [14], in which the authors introduced GCN to address the problem of classifying nodes, such as documents, in a graph, such as a citation network, where labels are only available for a small subset of nodes. Similarly, in representing hierarchical taxonomy in semi-supervised learning, we deal with the labeling concept in different levels of the hierarchy. Our objective is to identify representations for some nodes in the taxonomy, given the labels of other nodes. Moreover, the ability of GCN to handle symbolic inputs/outputs offers a differentiable alternative for semantic loss and logical constraints. These two reasons led us to utilize a graph neural network (GCN) for knowledge integration. We consider a hierarchical taxonomy as a labeled graph and seek the GCN encoding of any externally connected node to this graph. Figure 4 illustrates the 2-Dimensional GCN encoding of the nodes in the sample taxonomy.

One issue with GCN is the large memory requirement when encoding a big graph-structured data to provide representations for each node. Moreover, using GCN on the entire graph data avoids the need for explicit regularization with another supervised loss function, such as Cross Entropy. In this section, we propose a method to incorporate the hierarchical taxonomy of a classification task as prior knowledge into the loss function through a Batch-based Graph Convolutional Networks (BGCN). A representation for a graph \(A\) in GCN is defined as:

\[H^{(l+1)}=\sigma(\tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}H^{( l)}W^{(l)}) \tag{4}\]

where \(\tilde{A}=A+L_{N}\) is the adjacency matrix of the undirected graph \(A\) with added self-connections. \(I_{N}\) is the identity matrix, \(\tilde{D}_{ii}=\sum_{j}\tilde{A}_{ij}\) and \(W^{(l)}\) is a layer-specific trainable weight matrix. \(\sigma(.)\) Denotes an activation function (we used \(ReLU\) in our experiments). \(H^{(l)}\in R\) is the matrix of activations in the \(l^{th}\) layer; \(H^{0}=X\), \(\tilde{H}^{2}=softmax(H^{1})\).

We provide a taxonomy backbone graph for each batch, which is consistent across all batches and is generated from

Figure 3: An illustration for semi-supervised semantic loss. \(\iota_{1}\) is the matrix of model output for the labeled (i.e., leaves in taxonomy) data, \(\iota_{2}\) is the matrix of one-hot vectors over nodes in level \(l_{2}\) without labels in leaves, and \(\iota_{3}\) is the matrix of one-hot vectors over nodes in level \(l_{2}\) without labels in leaves and level \(l_{2}\).

the taxonomy tree. Our method aims to mimic the Knowledge Distillation Hinton, Vinyals, and Dean (2015) approach, where the hierarchical taxonomy serves as knowledge transferred from a teacher model (i.e., GCN model) to a student model (i.e., Symbolic-based model). In this method, we want the training algorithm (DNN) to not only rely on a supervised loss function but also consider prior domain knowledge encoded in a taxonomy tree. Therefore, a batch includes a few documents from the training data along with the taxonomy tree representing the hierarchical categories of the classification, which serves as the backbone of a larger graph \(A\). In other words, \(A\) is a graph generated by connecting the documents of a batch to the taxonomy tree. The workflow of the end-to-end training of BGCN is shown in Figure 5. The regularization term \(\mathcal{L}_{reg}\), explicitly added to the existing loss function, is defined as:

\[\mathcal{L}_{reg}=\parallel P-H\parallel_{2}^{2} \tag{5}\]

The generated graph \(A\) is used to provide representations \(H\) for batch of document in the same space of the predicted probabilities from a supervised DNN. Euclidean distance is measured as the regularization loss to be added to the training loss. The final loss function is:

\[\mathcal{L}=\mathcal{L}_{0}+w\times\mathcal{L}_{reg} \tag{6}\]

where \(\mathcal{L}_{0}\) is a Cross Entropy loss and \(\mathcal{L}_{reg}\) is the regularization loss.

## Experimental Results

### Taxonomy

To demonstrate the impact of taxonomy on both fine-grained and general classification, we adopt a policy. Our aim is to incorporate a wide range of categories at the top-1 level (excluding the root), while avoiding excessive depth in the taxonomy hierarchy. Specifically, we limit the taxonomy to three levels, thereby preventing the task from becoming solely focused on fine-grained classification.

### Data

In our experiments, we utilize datasets in two languages: Chinese,i.e., In-house datasets, and English,i.e., RCV1 and Amazon Product Review.

#### In-house Data:

We utilize two imbalanced Chinese datasets from a private company. The first dataset comprises user query logs from a Shopping Mall, consisting of 84 classes. The taxonomy associated with this dataset has three levels: level 1 encompasses 18 domains, level 2 comprises 45 intents, and level 3 includes 84 sub-intents. The second dataset consists of user query logs from a Call Center Service, which consists of 134 classes. The hierarchical taxonomy for this dataset also has three levels: level 1 contains 5 domains, level 2 includes 24 intents, and level 3 (leaves/labels) contains 134 sub-intents.

#### Rcv1:

The Reuters Corpus Volume I (RCV1) is a widely recognized archive of over 800,000 manually categorized newswire stories provided by Reuters, Ltd. A new version of RCV1(RCV1-v2/LYRL2004) was provided by Lewis et al. (2004), regarding this version of RCV1, we have generated a new dataset and a corresponding hierarchical taxonomy suitable for multi-class classification. We have created a hierarchical taxonomy with three levels tailored for multi-class classification. The first level comprises four categories, the second level consists of 33 categories, and the third level (leaves/labels) includes 53 sub-categories.

#### Amazon Product Review:

This dataset consists of reviews from Amazon Since our focus is on multi-class flat classification, similar to the Reuters dataset, we filter out documents with multiple labels and create an adjusted hierarchical taxonomy accordingly. The updated taxonomy is

Figure 4: An illustration for GCN encoding of the nodes in the taxonomy with labeled nodes \(a_{0},..,a_{3}\), and unlabeled nodes \(X_{1},..,X_{6}\).

Figure 5: An illustration of BGCN training workflow on documents \(D=\{d_{1},d_{2},..,d_{7}\}\) which are inter connected through a backbone graph, i.e., taxonomy.

[MISSING_PAGE_FAIL:6]

Tax-L1-based:This variant of our base model includes only the first level \(l_{1}\) of the taxonomy. Essentially, this variant is equivalent to the One-hot Constraint, as it represents the same formula proposed in [22]. In this model variant, all upper levels of the taxonomy are removed, and only the leaf nodes are considered. To ensure a fair comparison with the One-hot Constraint, we evaluate the results only in a supervised fashion. To ensure reproducibility of our evaluation, we set all the _seeds_ and run for one epoch. The average performance improvements, measured by three metrics across all four datasets, are presented in Table 5.

### Evaluation Measure

We use three measures: _Accuracy_, _Macro Average F1-score_, and _Weighted Average F1-score_ to evaluate the obtained results. Specifically, for evaluating the effect of hierarchical taxonomy in imbalanced classification, we use _Macro Average F1-score_, which is the arithmetic mean of F1-scores per class. It does not use weights (i.e., number of true labels of each class) for aggregation of F1-scores per class, and this results in a bigger penalization when a model does not perform well with the minority classes.In all experiments, we obtain the results with/without injecting taxonomy into the existing data-driven loss function. We run all experiments for 10 epochs, with a batch size of 32. The experiments are repeated 3 times, and the best result for each method and baseline is selected.

In semi-supervised learning, we define a policy to generate datasets in which some of the target labels, i.e., leaves in taxonomy, for documents and some of internal nodes in the taxonomies, are randomly masked/removed. For example, 20% semi-supervised learning means that in the leaves of the taxonomy, which also correspond to the target labels, 80% of the data rely on the taxonomy. Moreover, from the 80% unlabeled data in this case, 40% of it relies on level 2 of the taxonomy, and the rest relies on first level. Respectively, in 30% and 40% semi-supervised learning, it is increased by 10% less relying on taxonomy in the leaves, and 20% on level 2. To examine the pure effect of taxonomy, we do not consider the taxonomy knowledge for both the labeled and unlabeled data in semi-supervised learning (Tables 6, 7, 8, and 9). We only take the knowledge from taxonomy into account for unlabeled data, and separately in different experiments (Tables 1, 2, 3, and 4), it is considered for all data.

Injecting the abstracted taxonomy into the existing loss function provides a learning signal on unlabeled samples by forcing the underlying learner to make decisions that satisfy the constraint. Figure 6 shows the satisfiability of the regularization term (i.e., WMC in semantic loss) of the training loss function in the first epoch, together with the training loss and the accuracy. The results indicate that as we reason on the hierarchical taxonomy, we will see improvement in categorizing documents.

Overall, the proposed methods consistently yield superior results in both supervised and semi-supervised scenarios when compared to the baseline. Notably, the substantial impact of the taxonomy becomes evident in the semi-supervised context, as demonstrated in tables (Tables 6, 7, 8, and 9), with a clear emphasis on improving the Macro Average F1-score. While _Symbolic-based_ method demonstrates superior results, particularly in the accuracy of learners in supervised and semi-supervised scenarios, Tables 2, 3, 7, and 8 reveal that the _GCN-based_ method outperforms in terms of Macro Average F1-score. This observation holds true even when considering that the size of the hierarchical taxonomies generated for the Shopping Mall and Reuters datasets is smaller than that of the other two datasets in our experiments, all while using a fixed batch size. These observations offer valuable insights from our experiments, highlighting two key takeaways. First, the _Symbolic-based_ approach exhibits scalability for larger hierarchical taxonomies, showcasing its potential for handling more extensive taxonomic structures. Second, the _GCN-based_ method proves to be particularly effective in addressing long-tailed problems, showcasing its utility in scenarios with imbalanced data distributions.

However, as shown in our experiments, the effect of the taxonomy on the model's performance reduces increasing of the labeled samples. As Table 5 shows, the one-hot constraint does not significantly affect performance, and it is almost zero because the constraint is always satisfied by existing data-driven loss, and it can perfectly fit training data. Despite this satisfaction, we can still see the effect of the taxonomy on overall performance, specially in minor classes, even in fully supervised learning Table 1 and 2. This is because of the hierarchical structure of the constraint, which alleviates model output distributions over the classes to allow conditioning on upper concepts.

## Conclusion

In this paper, we aimed to explore several key challenges in deep learning: reasoning, semi-supervised learning, and the long-tailed issue. We developed two methods to represent and integrate a hierarchical taxonomy of labels into the loss function of a flat classifier. We demonstrated the effect of these methods in supervised and semi-supervised learning. Moreover, our experimental evaluations show that integrating a well-designed hierarchical taxonomy into the learning

Figure 6: The satisfiability of WMC in semantic loss, training loss, and accuracy in first epoch.

algorithm of a neural network effectively guides the learner to achieve significant results on long-tailed problems.

## References

* E. M. Bender and A. Koller (2020)Climbing towards nlu: on meaning, form, and understanding in the age of data. In Proceedings of the 58th annual meeting of the association for computational linguistics, pp. 5185-5198. Cited by: SS1.
* C. Brust and J. Denzler (2020)Integrating domain knowledge: using hierarchies to improve deep classifiers. In Pattern Recognition: 5th Asian Conference, ACPR 2019, Auckland, New Zealand, November 26-29, 2019, Revised Selected Papers, Part I, pp. 3-16. Cited by: SS1.
* M. Chavira and A. Darwiche (2008)On probabilistic inference by weighted model counting. Artificial Intelligence172 (6-7), pp. 772-799. Cited by: SS1.
* Z. Chen, J. Duan, L. Kang, and G. Qiu (2021)A hybrid data-level ensemble to enable learning from highly imbalanced dataset. Information Sciences554, pp. 157-176. Cited by: SS1.
* A. Darwiche (2003)A differential approach to inference in bayesian networks. Journal of the ACM (JACM)50 (3), pp. 280-305. Cited by: SS1.
* A. D. Darwiche (2011)SDD: a new canonical representation of propositional knowledge bases. In Twenty-Second International Joint Conference on Artificial Intelligence, Cited by: SS1.
* A. Darwiche and P. Marquis (2002)A knowledge compilation map. Journal of Artificial Intelligence Research17, pp. 229-264. Cited by: SS1.
* A. d. Garcez and L. C. Lamb (2023)Neurosymbolic ai: the 3 rd wave. Artificial Intelligence Review1-20. Cited by: SS1.
* G. Hinton, O. Vinyals, and J. Dean (2015)Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531. Cited by: SS1.
* S. Jenkins, J. Bloom, and K. Zhang (2021)Taxonomy-aware neural network classification of variable stars. In American Astronomical Society Meeting Abstracts, Vol. 53, pp. 541-14. Cited by: SS1.
* J. M. Johnson and T. M. Khoshgoftaar (2019)Survey on deep learning with class imbalance. Journal of Big Data6 (1), pp. 1-54. Cited by: SS1.
* G. Karamanolakis, J. Ma, and X. L. Dong (2020)Txtract: taxonomy-aware knowledge extraction for thousands of product categories. arXiv preprint arXiv:2004.13852. Cited by: SS1.
* A. Kimmig, G. Van den Broeck, and L. De Raedt (2017)Algebraic model counting. Journal of Applied Logic22, pp. 46-62. Cited by: SS1.
* T. N. Kipf and M. Welling (2016)Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907. Cited by: SS1.
* D. D. Lewis, Y. Yang, T. Russell-Rose, and F. Li (2004)Rev1: a new benchmark collection for text categorization research. Journal of machine learning research5 (Apr), pp. 361-397. Cited by: SS1.
* Y. Li, J. Yang, Y. Song, L. Cao, J. Luo, and L. Li (2017)Learning from noisy labels with distillation. In Proceedings of the IEEE international conference on computer vision, pp. 1910-1918. Cited by: SS1.
* J. Mao, C. Gan, P. Kohli, J. B. Tenenbaum, and J. Wu (2019)The neuro-symbolic concept learner: interpreting scenes, words, and sentences from natural supervision. arXiv preprint arXiv:1904.12584. Cited by: SS1.
* G. Marcus (2020)The next decade in ai: four steps towards robust artificial intelligence. arXiv preprint arXiv:2002.06177. Cited by: SS1.
* B. Min, H. Ross, E. Sulem, A. P. B. Veyseh, T. H. Nguyen, O. Sainz, E. Agirre, I. Heinz, and D. Roth (2021)Recent advances in natural language processing via large pre-trained language models: a survey. arXiv preprint arXiv:2111.01243. Cited by: SS1.
* J. M. Ong, S. J. Yang, K. W. Ng, and C. S. Chan (2022)Image-based plant identification with taxonomy aware architecture. Working Notes of CLEF. Cited by: SS1.
* J. Pearl (2019)The limitations of opaque learning machines. Possible minds25, pp. 13-19. Cited by: SS1.
* T. Sang, P. Beame, and H. A. Kautz (2005)Performing bayesian inference by weighted model counting. In AAAI, Vol. 5, pp. 475-481. Cited by: SS1.
* C. Seiffert, T. M. Khoshgoftaar, J. Van Hulse, and A. Napolitano (2009)RUSBoost: a hybrid approach to alleviating class imbalance. IEEE Transactions on Systems, Man, and Cybernetics-Part A: Systems and Humans40 (1), pp. 185-197. Cited by: SS1.
* J. Su and S. Maji (2021)Semi-supervised learning with taxonomic labels. arXiv preprint arXiv:2111.11595. Cited by: SS1.
* J. Xu, Z. Zhang, T. Friedman, Y. Liang, and G. Broeck (2018)A semantic loss function for deep learning with symbolic knowledge. In International conference on machine learning, pp. 5502-5511. Cited by: SS1.