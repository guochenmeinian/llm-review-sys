# Differentially Private Attention Computation

Yeqi Gao

The University of Washington

a916755226@gmail.com &Zhao Song

The Simons Institute for the Theory of Computing

at the University of California, Berkeley

magic.linuxkde@gmail.com &Xin Yang

The University of Washington

yangxin199207@gmail.com &Yufa Zhou

University of Pennsylvania

yufazhou@seas.upenn.edu

###### Abstract

Large language models (LLMs), especially those based on the Transformer architecture, have had a profound impact on various aspects of daily life, such as natural language processing, content generation, research methodologies, and more. Nevertheless, a crucial concern regarding the inference results of large language models is the issue of security and privacy. Given that large language models can generate results that may leak sensitive confidential or copyright information in many scenarios, it is crucial to compute the attention matrix with provable privacy guarantees, as attention is all you need.

In this work, we propose a novel and efficient algorithm for approximating the attention matrix while providing differential privacy (DP) guarantees. To achieve this, we build on recent advancements in fast attention computation and differentially private matrix publishing.

## 1 Introduction

The development of large language models (LLMs) has been rapid and significant in recent years, with numerous breakthroughs and advancements in the field. BERT [4] achieved state-of-the-art performance on a wide range of language tasks by training on a massive amount of text data in 2018. Since then, the GPT (Generative Pre-trained Transformer) family of models has further advanced the field. GPT-2 [19] and GPT-3 [2], with billions of parameters, are able to generate highly coherent and human-like text. Other notable LLMs include XLNet [20], which addresses some of the limitations of BERT [4], and RoBERTa [1], which improves upon BERT [4]'s training methods to achieve better performance. The rapid development of LLMs has been fueled by advancements in hardware, software, and data availability, allowing researchers and companies to train and deploy these models at an unprecedented scale.

As a result of their development, LLMs have found a wide range of applications in various fields. In the field of natural language processing (NLP) [23, 18, 4, 1], LLMs are used for tasks such as language translation [10], sentiment analysis [15], and creative writing [11]. In addition, LLMs are being used to develop chatbots and virtual assistants that can understand and respond to natural language queries [2, 11]. Outside of NLP, LLMs are being used in scientific research to generate new hypotheses and discover novel patterns in large datasets. The applications of LLMs are expanding rapidly, and it is likely that they will play an increasingly important role in many fields, such as computer vision [14], robotics [17], and autonomous vehicles [2, 18].

[MISSING_PAGE_FAIL:2]

**Definition 1.2**.: _Given \(X\in\mathbb{R}^{n\times d}\), the goal is to find some \(Y\in\mathbb{R}^{n\times m}\) such that_

\[\|D(XX^{\top})^{-1}\exp(XX^{\top})-D(YY^{\top})^{-1}\exp(YY^{\top})\|\leq\mathrm{ small}\]

_where \(\|\cdot\|\) is some certain norm and \(D(XX^{\top})=\mathrm{diag}(\exp(XX^{\top})\cdot\mathbf{1}_{n})\)._

One recent work [21] choose the angle of near access-freeness to study the privacy concerns in LLMs. However, in this work, we use the differential privacy concept [13], and the formal definition of differential privacy can be written as follows.

**Definition 1.3** (Differential Privacy [14, 15]).: _A randomized mechanism \(\mathcal{M}\) is \((\epsilon,\delta)\)-differentially private if for any event \(\mathcal{O}\in\mathrm{Range}(\mathcal{M})\) and for any pair of neighboring databases \(S,S^{\prime}\) that differ in a single data element, one has_

\[\Pr[\mathcal{M}(S)\in\mathcal{O}]\leq\exp(\epsilon)\cdot\Pr[\mathcal{M}(S^{ \prime})\in\mathcal{O}]+\delta.\]

Finally, we're ready to define our differentially private attention computation problem.

**Definition 1.4** (General Differentially Private Attention).: _Let \(f:\mathbb{R}\rightarrow\mathbb{R}\) denote some fixed function. For a given matrix \(X\in\mathbb{R}^{n\times d}\) with \(d\gg n\), let \(\mathcal{M}\) denote some mapping that maps \(\mathbb{R}^{n\times d}\) to \(\mathbb{R}^{n\times n}\), let \(A=\mathcal{M}(X)\), for parameter \(\epsilon,\delta\in(0,0.1)\), the goal is to design an \((\epsilon,\delta)\)-differentially private algorithm that takes \(X\in\mathbb{R}^{n\times d}\) as input and generates a PSD matrix \(B\in\mathbb{R}^{n\times n}\) such that_

\[\|\operatorname{\mathsf{D}}(A)^{-1}f(A)-\operatorname{\mathsf{D}}(B)^{-1}f(B )\|\leq g(\epsilon,\delta)\]

_where \(f(A)_{i,j}=f(A_{i,j})\), \(\operatorname{\mathsf{D}}(A)=\mathrm{diag}(f(A)\mathbf{1}_{n})\) and where \(g\) is some function._

Definition 1.4 is very general, and covers the standard self-attention computation. In particular, when \(\mathcal{M}(X)=XX^{\top}\) and \(f(z)=\exp(z)\), then above definition recovers the standard self-attention in LLMs.

### Our Result

Our results rely on good properties of the input data, which are defined as follows. They play a crucial role in the analysis of sensitivity with respect to \(\mathcal{M}(X)=XX^{\top}\) (See Section 4.3).

**Definition 1.5** (Dataset).: _Fix \(\eta>0,\alpha>0\). We say our dataset \(X\in\mathbb{R}^{n\times d}\) is \((\alpha,\eta)\)-good if \(XX^{\top}\succeq\eta\cdot I_{n}\) and for all \(i\in[d]\), \(\|X_{*,i}\|_{2}\leq\alpha\)._

In addition, we will introduce our proposed definition of neighboring data as follows.

**Definition 1.6** (Neighboring data).: _Let \(X,\widetilde{X}\in\mathbb{R}^{n\times d}\) denote two datasets from distribution \(\mathcal{D}\), we say that \(X\) and \(\widetilde{X}\) are \(\beta\)-close if there exists exact one \(i\in[d]\) so that \(\|X_{*,i}-\widetilde{X}_{*,i}\|_{2}\leq\beta\) and for all \(j\in[d]\backslash\{i\}\), \(X_{*,j}=\widetilde{X}_{*,j}\). In this work, we consider two datasets to be neighboring if they are \(\beta\)-close._

The above definition facilitates a more straightforward analysis of the sensitivity of attention matrix computations. By regulating \(\beta\)-closeness, we can establish bounds on how the attention matrix responds to minor variations in input data, which is essential for ensuring differential privacy guarantees. Furthermore, in practical scenarios, assessing dataset similarity based on feature-wise differences rather than individual data points can be more practical and aligns better with real-world considerations.

Based on the aforementioned definitions, our work demonstrates the sensitivity property of \(\mathcal{M}(X)=XX^{\top}\) (attention matrix computation). Furthermore, we present a novel and efficient algorithm for approximating the attention matrix, which combines error analysis on matrix perturbation with provable privacy guarantees. We state our result as follows:

**Theorem 1.7** (Main result, informal of Theorem 3.1).: _Let \(d\geq n\). Let \(X\in\mathbb{R}^{n\times d}\). Let \(f(z)\in\{\exp(z),\cosh(z)\}\). Let \(r,\epsilon,\delta\in(0,0.1)\). Let \(\Delta=0.1\min\{\frac{\epsilon}{\sqrt{k\log(1/\delta)}},\frac{\epsilon}{\log( 1/\delta)}\}\). Let \(A=\mathcal{M}(X)=XX^{\top}\) and \(\|A\|_{\infty}\leq r\). Let \(f(A)\) and \(\operatorname{\mathsf{D}}(A)\) be defined as Definition 1.4. For all \(X\) sampled from \(\mathcal{D}\), \(X\) is \((\alpha,\eta)\)-good (see Definition 1.5). Let \(\eta<r\). Let \(\beta\) be the parameter for the neighboring dataset. Let \(2\alpha\beta\sqrt{n}/\eta<\Delta\). Suppose \(\|\mathcal{M}(X)^{1/2}\mathcal{M}(\widetilde{X})^{-1}\mathcal{M}(X)^{1/2}-I\| _{F}\leq\Delta\)_for all \(X\in\mathbb{R}^{n\times d},\tilde{X}\in\mathbb{R}^{n\times d}\) (see Definition 1.6). Let \(\rho=\sqrt{(n^{2}+\log(1/\gamma))/k}+(n^{2}+\log(1/\gamma))/k<0.1\epsilon\). Then, there is an algorithm (Algorithm 1) that takes \(X\) as input and produces the matrix \(B\in\mathbb{R}^{n\times n}\) and also general attention \(\mathsf{D}(B)^{-1}f(B)\) as output such that_

\[\|\,\mathsf{D}(A)^{-1}f(A)-\mathsf{D}(B)^{-1}f(B)\|_{\infty}\leq 4\cdot(1+ \epsilon+2r)\cdot r\]

_which holds with probability \(1-\gamma\). With respect to \(X\), the algorithm is \((\epsilon,\delta)\)-differential private._

### Related Work

Differential Privacy and Deep Learning.Differential privacy (DP) is a rigorous and quantifiable notion of privacy that ensures individual data entries cannot be distinguished within a dataset. It has become the go-to standard for understanding information leakage [14]. This widely recognized framework is increasingly being adopted in industry and has many real-world applications [21, 22, 23, 24, 25]. There has been extensive research on applying differential privacy in deep learning [1, 1, 1, 20, 1, 21, 22, 23, 24, 25]. Recent works [22], LTLH21[1] have applied DP-SGD [1] to large language models (LLMs) for private fine-tuning. Our research, however, is orthogonal to these works as we focus on attention computation and consider general differential privacy mechanisms, not just DP-SGD.

Roadmap.Our paper is organized as follows. Section 2 presents the notations that are used throughout our paper. Our main result is presented in Section 3. We provide an overview of our techniques in Section 4. In Section 5, we give our conclusion of the paper.

## 2 Notations

\(\mathbb{E}[X]\) represents the expected value (or mean) of a random variable \(X\). We use \(\chi^{2}_{d}\) to denote a Chi-squared random variable with \(d\) degrees of freedom. If \(M\) and \(N\) are symmetric matrices, we define \(M\succeq N\) to mean that for all vectors \(x\), the inequality \(x^{\top}Mx\geq x^{\top}Nx\) holds. If \(M\) is a symmetric matrix of dimension \(n\times n\), we define \(M\) to be positive semidefinite (\(M\succeq 0\)) if the inequality \(x^{\top}Mx\geq 0\) holds for all vectors \(x\in\mathbb{R}^{n}\). We use the notation \(\mathbf{0}_{n}\) to denote an \(n\)-dimensional vector whose entries are all zero, and \(\mathbf{1}_{n}\) to denote an \(n\)-dimensional vector whose entries are all one. The symbol \(I_{n}\) represents the \(n\times n\) identity matrix, which is a square matrix with ones on the main diagonal and zeros elsewhere. Let \(x\) be an arbitrary vector in \(\mathbb{R}^{n}\). We define \(\exp(x)\in\mathbb{R}^{n}\) as a vector whose \(i\)-th entry \(\exp(x)_{i}\) is equal to \(\exp(x_{i})\), where \(\exp(\cdot)\) denotes the exponential function. We use \(\langle x,y\rangle\) to denote \(\sum_{i=1}^{n}x_{i}y_{i}\). For any matrix \(A\), we use \(\|A\|\) to denote the spectral norm of \(A\), i.e., \(\|A\|=\max_{\|x\|_{2}=1}\|Ax\|_{2}\), \(\|A\|_{F}\) to denote its Frobenius norm and \(\|A\|_{\infty}\) to denote the infinity norm. \(A_{i,j}\) represents the element in the \(i\)-th row and \(j\)-th column of matrix \(A\)._

## 3 Main Result

```
1:procedureDPAttention(\(X\))
2:\(A\gets XX^{\top}\)
3:\(B\leftarrow\textsc{DPCovariance}(A,k)\)\(\triangleright\) See Algorithm 2.
4: Compute \(f(B)\)
5: Compute \(\mathsf{D}(B)^{-1}f(B)\)
6:endprocedure
```

**Algorithm 1** Differential privacy algorithm

In this section, we provide a theoretical analysis of Algorithm 1, our primary algorithm for differentially private general attention computation. Our analysis leverages the tools established in Section 4.1, Section 4.2, and Section 4.3. From our previous proofs, it is evident that our algorithm possesses a rigorous differential privacy property, offering new insights into both differential privacy and attention mechanisms.

**Theorem 3.1** (Main result).: _If all of the following requirements are met Let \(d\geq n\), \(X\in\mathbb{R}^{n\times d}\), and \(f(z)\in\{\exp(z),\cosh(z)\}\). We define \(r\in(0,0.1)\) as bounded ratio and \(\epsilon,\delta\in(0,0.1)\) as the parameter of DP. Let \(\Delta=0.1\min\{\frac{\epsilon}{\sqrt{k\log(1/\delta)}},\frac{\epsilon}{\log(1/ \delta)}\}\). Let \(A=\mathcal{M}(X)=XX^{\top}\) and \(\|A\|_{\infty}\leq r\). For all \(X\) sampled from \(\mathcal{D}\), \(X\) is \((\alpha,\eta)\)-good (see Definition 1.5). Let \(\eta<r\). Let \(\beta\) be the parameter for neighboring dataset. Let \(2\alpha\beta\sqrt{\eta}/\eta<\Delta\). Let \(\Delta\) denote the sensitivity parameter that \(\mathcal{M}\) satisfies a sensitivity bound that \(\|\mathcal{M}(X)^{1/2}\mathcal{M}(\widetilde{X})^{-1}\mathcal{M}(X)^{1/2}-I\| _{F}\leq\Delta\) for any neighboring datasets \(X\in\mathbb{R}^{n\times d},\widetilde{X}\in\mathbb{R}^{n\times d}\) (see Definition 1.6). Let \(\rho=\sqrt{(n^{2}+\log(1/\gamma))/k}+(n^{2}+\log(1/\gamma))/k\) and \(\rho<0.1\epsilon\). There is an algorithm (Algorithm 1) that takes \(X\) as input and produces the matrix \(B\in\mathbb{R}^{n\times n}\) and also attention \(\mathsf{D}(B)^{-1}f(B)\) as output such that_

* **Part 1.**__\(\|\,\mathsf{D}(A)^{-1}f(A)-\mathsf{D}(B)^{-1}f(B)\|_{\infty}\leq 4\cdot(1+ \epsilon+2r)\cdot r\)_._
* **Part 2.** _With respect to_ \(X\)_, the algorithm is_ \((\epsilon,\delta)\)_-differential private._
* **Part 3.** _It holds with probability_ \(1-\gamma\)_._

Proof of Theorem 3.1.: The proof can be divided into two parts as follows.

Proof of Part 1 and Part 3.Our proof focus on the function \(\mathcal{M}(X):=XX^{\top}\) first. Let \(\alpha\) and \(\eta\) be denoted in Definition 1.5 and \(\beta\) be denoted as Definition 1.6. Based on the assumption on dataset above, we can obtain \(X\) is \((\eta,\alpha)\)-good (See Definition 1.5) while \(X\) and \(\widetilde{X}\) are \(\beta\)-close (See Definition 1.6). According to **Part 1** of Lemma 4.11, we can conclude the property on \(\mathcal{M}(X)=XX^{\top}\) such that

\[\|(XX^{\top})^{-1/2}\widetilde{X}\widetilde{X}^{\top}(XX^{\top})^{-1/2}-I\|_{ F}\leq 2\sqrt{n}\alpha\beta/\eta\]

Let \(\mathcal{M}\) be the function denoted in the theorem statement and let \(\rho\) be denoted as follows:

\[\rho:=O(\sqrt{(n^{2}+\log(1/\gamma))/k}+(n^{2}+\log(1/\gamma))/k)\]

Now, we will apply the conclusion drawn in Section 4.2. In order to satisfy the requirement specified in **Requirement 4** of Theorem 4.9, we need \(\mathcal{M}(X)\) to meet the following assumption:

\[\|\mathcal{M}(X)^{1/2}\mathcal{M}(\widetilde{X})^{-1}\mathcal{M}(X)^{1/2}-I\| _{F}\leq\Delta.\]

Now, if we choose \(2\alpha\beta\sqrt{n}/\eta<\Delta\). we will guarantee that our \(\mathcal{M}(X)\) satisfies the assumption specified in **Requirement 4** of Theorem 4.3. According to **Part 3** of Theorem 4.3, there exists Algorithm 2 which can produce a matrix \(B\in\mathbb{R}^{n\times n}\) such that, with probability at least \(1-\gamma\)

\[(1-\rho)A\preceq B\preceq(1+\rho)A \tag{1}\]

By choosing \(\rho\in(0,0.1)\epsilon\), we will have

\[(1-\epsilon)B\preceq A\preceq(1+\epsilon)B \tag{2}\]

Now according to Theorem 4.3 and Eq. (2), we have

\[\|\,\mathsf{D}(A)^{-1}f(A)-\mathsf{D}(B)^{-1}f(B)\|_{\infty}\leq 4\cdot(1+ \epsilon+2r)\cdot r\]

Now, the proofs of **Part 1** and **Part 3** are completed.

Proof of Part 2.It simply follows from **Part 1** of Theorem 4.9. 

The main result implies that we can design an algorithm that computes a private approximation of the attention mechanism used in neural networks for functions like \(f(z)=\exp(z)\) or \(f(z)=\cosh(z)\). Specifically, under certain conditions on the input matrix \(X\) and parameters \(\epsilon,\delta\), and with a small bounded ratio \(r\), the algorithm produces a matrix \(B\) such that the normalized attention matrices derived from \(A=XX^{\top}\) and \(B\) are close in the infinity norm. This closeness is quantified by a bound proportional to \(r\), ensuring that the utility of the attention mechanism is preserved. Additionally, the algorithm is \((\epsilon,\delta)\)-differentially private with respect to \(X\), meaning it protects individual data entries from being inferred. The privacy and utility guarantees hold with high probability \(1-\gamma\), demonstrating that it is possible to implement attention mechanisms in a way that maintains both model performance and data privacy.

Technique Overview

The objective of our research is to develop a differentially private algorithm that addresses the challenges of computing attention on large datasets. Specifically, we focus on scenarios where the size of the data matrix \(X\) is extremely large, with the number of features \(d\) significantly exceeding the number of samples \(n\) (i.e., \(d\gg n\)). In these cases, the attention matrix \(A\) is obtained as the output of the function \(\mathcal{M}(X)=XX^{\top}\), and our goal is to ensure that the computation of \(A\) is performed in a differentially private [16, 17] manner.

Perturb PSD Matrix.We define the attention computation \(\mathsf{D}(X)\) as Definition 4.2. By employing a more general version of Perturbation analysis presented in [16], we select \(f\) as specified in Definition 4.1. To complete the error analysis of attention computation, we will utilize the perturbation analysis of the diagonal normalization matrix and the PSD matrix presented in Appendix C. Under the assumption the relative error between input matrix \(\mathcal{M}(X):=A\) and privacy required matrix output \(B\) is less than or equal to \(\epsilon\in(0,0.1)\) where \((1-\epsilon)B\preceq A\preceq(1+\epsilon)B\). To establish an upper bound for \(\|\,\mathsf{D}(A)^{-1}f(A)-\mathsf{D}(B)^{-1}f(B)\|_{\infty}\), we first derive the following bound:

* **Part 1.**\(|\,\mathsf{D}(A)_{i,i}-\mathsf{D}(B)_{i,i}|\leq c_{1}\cdot r\cdot\min\{\mathsf{ D}(A)_{i,i},\mathsf{D}(B)_{i,i}\}\;\;\forall i\in[n]\),
* **Part 2.**\(|f(A_{i,j})-f(B_{i,j})|\leq c_{2}\cdot r\cdot\min\{f(A_{i,j}),f(B_{i,j})\}\; \;\forall i,j\in[n]\times[n]\)

And with the error of attention computation under control as mentioned above, we can obtain:

\[\|\,\mathsf{D}(A)^{-1}f(A)-\mathsf{D}(B)^{-1}f(B)\|_{\infty}\leq 4\cdot(1+ \epsilon+2r)\cdot r\]

Sensitivity for PSD Matrix.Our work relies on the basic assumptions that \(X\in\mathbb{R}^{n\times d}\) is a \((\eta,\alpha)\)-good dataset (See Definition 1.5) and that \(X\) and \(\widetilde{X}\) are \(\beta\)-close to each other (See Definition 1.6). We choose \(\mathcal{M}(X):=XX^{\top}\). Now we will demonstrate the property of our function \(\mathcal{M}(X)=XX^{\top}\) based on the given assumptions. Since \(X\) and \(\widetilde{X}\) are neighbor datasets, we have the following:

\[\|\mathcal{M}(X)^{1/2}\mathcal{M}(\widetilde{X})^{-1}\mathcal{M}(X)^{1/2}-I\| _{F}\leq 2\alpha\beta\sqrt{n}\]

The proof details can be found in Section E. Let us denote \(\Delta\) as defined in Definition 4.5. By choosing \(2\alpha\beta\sqrt{n}/\eta<\Delta\), we will have

\[\|(\underbrace{XX^{\top}}_{:=\mathcal{M}(X)})^{1/2}(\underbrace{\widetilde{ X}\widetilde{X}^{\top}}_{:=\mathcal{M}(\widetilde{X})})^{-1}(\underbrace{XX^{ \top}}_{:=\mathcal{M}(X)})^{1/2}-I\|_{F}\leq\Delta \tag{3}\]

The assumption specified in the **Requirement 5** of Theorem D.7 will be satisfied. Next, we will introduce our main algorithm using Eq. (3).

Differential Privacy Algorithm.Next we give the differential privacy algorithm described in Theorem 1.7. And we will demonstrate that our algorithm (Algorithm 1) is able to output a matrix that satisfies the **Part 1** of our formal main result (See Theorem 3.1).

To begin with, we demonstrate that there exists an algorithm capable of taking input \(A\) and producing a matrix \(B\) as output such that the difference between \(A\) and \(B\) is small enough, which can be seen as a small error resulting from the perturbation of \(A\) by \(\rho:=O(\sqrt{(n^{2}+\log(1/\gamma))/k}+(n^{2}+\log(1/\gamma))/k)\). In other words, we have \((1-\rho)A\preceq B\preceq(1+\rho)A\). The above equation holds with probability \(1-\gamma\). Note that \(k\) and \(\gamma\) can be chosen according to our requirements. We can ensure that a satisfactory \(\rho\) is obtained. By choosing a small enough \(\rho\leq 0.1\epsilon\) and using the conclusions on perturbed PSD matrices, the algorithm can certainly output a satisfactory \(B\) which promises our attention computation is privacy [16, 17].

### Error Control from Logit Matrix to Attention Matrix

In this section, we analyze the perturbations in the attention computation, which are used to control the error. First, we define the followings.

**Definition 4.1**.: _Let \(f(z)\) denote one of the following functions \(\exp(z)\) and \(\cosh(z)\)._

[MISSING_PAGE_EMPTY:7]

**Definition 4.7**.: _Let \(\mathcal{M}\) be denoted in Definition 4.4 and \(\Sigma(\mathcal{Y}):=\mathcal{M}(\mathcal{Y})\). We define \(\Sigma_{1}:=\Sigma(\mathcal{Y})\), \(\Sigma_{2}:=\Sigma(\mathcal{Y}^{\prime})\)._

**Definition 4.8**.: _Let \(g_{1},g_{2},\cdots,g_{k}\) be i.i.d samples from \(\mathcal{N}(0,\Sigma_{1})\) output by Algorithm 2. Then, we define \(h_{i,j}:=\langle\Sigma_{1}^{-1/2}g_{i},v_{j}\rangle\), \(Z:=\sum_{i=1}^{k}\log(\frac{f_{\Sigma_{1}}(g_{i})}{f_{\Sigma_{2}}(g_{i})})\) where \(\Sigma_{1},\Sigma_{2}\) are defined by Definition 4.7. Note that the random variables \(h_{i,j}\) are i.i.d copies of \(\mathcal{N}(0,1)\)._

We will now present our theorem for Algorithm 2. The proof is delayed to Section D.6.

**Theorem 4.9** (Informal version of Theorem D.7).: _If all of the following requirements are met:_

**Requirement 1.** _Let \(\epsilon\in(0,1)\) and \(\delta\in(0,1)\)._

**Requirement 2.** _Let \(\Delta\) be denoted as Definition 4.5 and \(\Delta<1\)._

**Requirement 4.** _Let \(M,\mathcal{M}\) be denoted as Definition 4.4 and \(M\leq\Delta\)._

**Requirement 5.** _An input \(\Sigma=\mathcal{M}(\mathcal{Y})\)._

**Requirement 6.** _\(\rho=O(\sqrt{(n^{2}+\log(1/\gamma))/k}+(n^{2}+\log(1/\gamma))/k)\)._

_Then, there is an algorithm (Algorithm 2) such that_

* _Part 1. Algorithm 2 is_ \((\epsilon,\delta)\)_-DP (with respect to the original dataset_ \(\mathcal{Y}\)_)._
* _Part 2. outputs_ \(\widehat{\Sigma}\) _such that with probability at least_ \(1-\gamma\)_,_ \(\|\Sigma^{-1/2}\widehat{\Sigma}\Sigma^{-1/2}-I_{n}\|_{F}\leq\rho\)_._
* _Part 3._ \((1-\rho)\Sigma\preceq\widehat{\Sigma}\preceq(1+\rho)\Sigma\)_._

Using this theorem, we can see our Algorithm 2 is DP, which ensures the DP of Algorithm 1.

### Sensitivity for PSD Matrix

We have demonstrated the existence of a differential privacy algorithm under the assumption on \(\mathcal{M}(X)=XX^{\top}\) introduced in Section 4.2. In this section, we show that \(\mathcal{M}(X)=XX^{\top}\) satisfies the assumption specified in **Requirement 4** of Theorem 4.9 for \(\mathcal{M}(X)\). The lemma following is based on the assumption on datasets \(X,\widetilde{X}\) (See Definition 1.5 and Definition 1.6).

**Lemma 4.10** (Informal version of Lemma E.1).: _If \(X\in\mathbb{R}^{n\times d}\) and \(\widetilde{X}\in\mathbb{R}^{n\times d}\) are neighboring dataset (see Definition 1.5 and Definition 1.6), then \((1-2\alpha\beta/\eta)XX^{\top}\preceq\widetilde{X}\widetilde{X}^{\top}\preceq (1+2\alpha\beta/\eta)XX^{\top}\)._

Now, we can have the following lemma. The subsequent lemma can be viewed as a variation of Lemma 4.10, yet it presents a more apparent result that can be directly employed in subsequent analyses.

**Lemma 4.11**.: _Let \(\alpha\) and \(\eta\) be defined in Definition 1.5. Let \(\beta\) be defined in Definition 1.6. Let \(X\) and \(\widetilde{X}\) be neighboring datasets such that \((1-2\alpha\beta/\eta)XX^{\top}\preceq\widetilde{X}\widetilde{X}^{\top}\preceq (1+2\alpha\beta/\eta)XX^{\top}\). Then, we have \(\|(XX^{\top})^{-1/2}\widetilde{X}\widetilde{X}^{\top}(XX^{\top})^{-1/2}-I\| \leq 2\alpha\beta/\eta\) and \(\|(XX^{\top})^{-1/2}\widetilde{X}\widetilde{X}^{\top}(XX^{\top})^{-1/2}-I\|_{ F}\leq 2\sqrt{n}\alpha\beta/\eta\)._

The proof of Lemma 4.11 follows directly from the Lemma 4.10.

Presently, we have delved into the sensitivity property of attention computation. We are able to illustrate that the computation of the attention matrix aligns with the assumptions introduced in Section 4.2. Building upon this foundation, we will subsequently address our primary result in Section 3.

## 5 Conclusion

In this work, we propose a differentially private algorithm for approximating the attention matrix. Our algorithm is built upon recent advances in fast attention computation and private matrix releasing. To the best of our knowledge, this is the first work of accelerating attention computation in the DP setting. Given the dominating presence of Transformer based language models, we hope our work can stand as a starting point for fully DP training and inferring algorithms on large language models. It is also an interesting open problem to approximate asymmetric attention computation with differential privacy.

## References

* [ACG\({}^{+}\)16] Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. Deep learning with differential privacy. In _Proceedings of the 2016 ACM SIGSAC conference on computer and communications security_, pages 308-318, 2016.
* [AKT\({}^{+}\)22] Daniel Alabi, Pravesh K Kothari, Pranay Tankala, Prayaag Venkat, and Fred Zhang. Privately estimating a gaussian: Efficient, robust and optimal. _arXiv preprint arXiv:2212.08018_, 2022.
* [AS23] Josh Alman and Zhao Song. Fast attention requires bounded entries. _arXiv preprint arXiv:2302.13214_, 2023.
* [AS24a] Josh Alman and Zhao Song. The fine-grained complexity of gradient computation for training large language models. _arXiv preprint arXiv:2402.04497_, 2024.
* [AS24b] Josh Alman and Zhao Song. How to capture higher-order correlations? generalizing matrix softmax attention to kronecker computation. In _The Twelfth International Conference on Learning Representations_, 2024.
* [BEPP22] Rouzbeh Behnia, Mohammadreza Reza Ebrahimi, Jason Pacheco, and Balaji Padmanabhan. Ew-tune: A framework for privately fine-tuning large language models with differential privacy. In _2022 IEEE International Conference on Data Mining Workshops (ICDMW)_, pages 560-566. IEEE, 2022.
* [BKO18] Mayank Bansal, Alex Krizhevsky, and Abhijit Ogale. Chauffeurnet: Learning to drive by imitating the best and synthesizing the worst. _arXiv preprint arXiv:1812.03079_, 2018.
* [BMR\({}^{+}\)20] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. _Advances in neural information processing systems_, 33:1877-1901, 2020.
* [Bra20] Jan van den Brand. A deterministic linear program solver in current matrix multiplication time. In _Proceedings of the Fourteenth Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)_, pages 259-278. SIAM, 2020.
* [BS16] Mark Bun and Thomas Steinke. Concentrated differential privacy: Simplifications, extensions, and lower bounds. In _Theory of Cryptography: 14th International Conference, TCC 2016-B, Beijing, China, October 31-November 3, 2016, Proceedings, Part I_, pages 635-658. Springer, 2016.
* [BSZ23] Jan van den Brand, Zhao Song, and Tianyi Zhou. Algorithm and hardness for dynamic attention maintenance in large language models. _arXiv preprint arXiv:2304.02207_, 2023.
* [CLS19] Michael B Cohen, Yin Tat Lee, and Zhao Song. Solving linear programs in the current matrix multiplication time. In _STOC_, 2019.
* [CLS\({}^{+}\)24] Bo Chen, Yingyu Liang, Zhizhou Sha, Zhenmei Shi, and Zhao Song. Hsr-enhanced sparse attention acceleration, 2024.
* [CSY23] Timothy Chu, Zhao Song, and Chiwun Yang. How to protect copyright data in optimization of large language models? _arXiv preprint arXiv:2308.12247_, 2023.
* [DBK\({}^{+}\)20] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. An image is worth 16x16 words: Transformers for image recognition at scale. _arXiv preprint arXiv:2010.11929_, 2020.
* [DCLT18] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. _arXiv preprint arXiv:1810.04805_, 2018.

* [Dir22] Differential Privacy Team, Apple. Learning with privacy at scale. [https://docs-assets.developer.apple.com/ml-research/papers/learning-with-privacy-at-scale.pdf](https://docs-assets.developer.apple.com/ml-research/papers/learning-with-privacy-at-scale.pdf), 2022. Online; accessed 30 November 2022.
* [DKM\({}^{+}\)06] Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya Mironov, and Moni Naor. Our data, ourselves: Privacy via distributed noise generation. In _Annual International Conference on the Theory and Applications of Cryptographic Techniques_, pages 486-503. Springer, 2006.
* [DLS23] Yichuan Deng, Zhihang Li, and Zhao Song. Attention scheme inspired softmax regression. _arXiv preprint arXiv:2304.10411_, 2023.
* [DMNS06] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in private data analysis. In _Theory of Cryptography: Third Theory of Cryptography Conference, TCC 2006, New York, NY, USA, March 4-7, 2006. Proceedings 3_, pages 265-284. Springer, 2006.
* [DMS23] Yichuan Deng, Sridhar Mahadevan, and Zhao Song. Randomized and deterministic attention sparsification algorithms for over-parameterized feature dimension. _arxiv preprint: arxiv 2304.03426_, 2023.
* [DR\({}^{+}\)14] Cynthia Dwork, Aaron Roth, et al. The algorithmic foundations of differential privacy. _Foundations and Trends(r) in Theoretical Computer Science_, 9(3-4):211-407, 2014.
* [EMM\({}^{+}\)23] Alessandro Epasto, Jieming Mao, Andres Munoz Medina, Vahab Mirrokni, Sergei Vassilvitskii, and Peilin Zhong. Differentially private continual releases of streaming frequency moment estimations. _arXiv preprint arXiv:2301.05605_, 2023.
* [ERLD17] Javid Ebrahimi, Anyi Rao, Daniel Lowd, and Dejing Dou. Hotflip: White-box adversarial examples for text classification. _arXiv preprint arXiv:1712.06751_, 2017.
* [Fac22] Facebook. Protecting privacy in facebook mobility data during the covid-19 response, 2022.
* [FJR15] Matt Fredrikson, Somesh Jha, and Thomas Ristenpart. Model inversion attacks that exploit confidence information and basic countermeasures. In _Proceedings of the 22nd ACM SIGSAC conference on computer and communications security_, pages 1322-1333, 2015.
* [GGK\({}^{+}\)21] Badih Ghazi, Noah Golowich, Ravi Kumar, Pasin Manurangsi, and Chiyuan Zhang. Deep learning with label differential privacy. _Advances in neural information processing systems_, 34:27131-27145, 2021.
* [GMS23] Yeqi Gao, Sridhar Mahadevan, and Zhao Song. An over-parameterized exponential regression. _arXiv preprint arXiv:2303.16504_, 2023.
* [GS22] Yuzhou Gu and Zhao Song. A faster small treewidth sdp solver. _arXiv preprint arXiv:2211.06033_, 2022.
* [GSY23] Yeqi Gao, Zhao Song, and Junze Yin. An iterative algorithm for rescaled hyperbolic functions regression. _arXiv preprint arXiv:2305.00660_, 2023.
* [HCL\({}^{+}\)24] Jerry Yao-Chieh Hu, Pei-Hsuan Chang, Haozheng Luo, Hong-Yu Chen, Weijian Li, Wei-Po Wang, and Han Liu. Outlier-efficient hopfield layers for large transformer-based models. In _Forty-first International Conference on Machine Learning (ICML)_, 2024.
* [HCW\({}^{+}\)24] Jerry Yao-Chieh Hu, Bo-Yu Chen, Dennis Wu, Feng Ruan, and Han Liu. Nonparametric modern hopfield models. _arXiv preprint arXiv:2404.03900_, 2024.
* [HLSL24] Jerry Yao-Chieh Hu, Thomas Lin, Zhao Song, and Han Liu. On computational limits of modern hopfield models: A fine-grained complexity analysis. In _Forty-first International Conference on Machine Learning (ICML)_, 2024.

* [HWL21] Weihua He, Yongyun Wu, and Xiaohua Li. Attention mechanism for neural machine translation: A survey. In _2021 IEEE 5th Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)_, volume 5, pages 1485-1489. IEEE, 2021.
* [HWSL24] Jerry Yao-Chieh Hu, Weimin Wu, Zhao Song, and Han Liu. On statistical rates and provably efficient criteria of latent diffusion transformers (dits). _arXiv preprint arXiv:2407.01079_, 2024.
* [HYW\({}^{+}\)23] Jerry Yao-Chieh Hu, Donglin Yang, Dennis Wu, Chenwei Xu, Bo-Yu Chen, and Han Liu. On sparse modern hopfield model. In _Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS)_, 2023.
* [JSWZ21] Shunhua Jiang, Zhao Song, Omri Weinstein, and Hengjie Zhang. Faster dynamic matrix inverse for faster lps. In _STOC_, 2021.
* [KGW\({}^{+}\)23] John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers, and Tom Goldstein. A watermark for large language models. _arXiv preprint arXiv:2301.10226_, 2023.
* [KKM\({}^{+}\)20] Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and Ananda Theertha Suresh. Scaffold: Stochastic controlled averaging for federated learning. In _International Conference on Machine Learning_, pages 5132-5143. PMLR, 2020.
* [KNK21] Oliver Kroemer, Scott Niekum, and George Konidaris. A review of robot learning for manipulation: Challenges, representations, and algorithms. _The Journal of Machine Learning Research_, 22(1):1395-1476, 2021.
* [LLS\({}^{+}\)24a] Chenyang Li, Yingyu Liang, Zhenmei Shi, Zhao Song, and Tianyi Zhou. Fourier circuits in neural networks: Unlocking the potential of large language models in mathematical reasoning and modular arithmetic. _arXiv preprint arXiv:2402.09469_, 2024.
* [LLS\({}^{+}\)24b] Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song, and Junwei Yu. Fast john ellipsoid computation with differential privacy optimization. _arXiv preprint arXiv:2408.06395_, 2024.
* [LLS\({}^{+}\)24c] Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song, and Yufa Zhou. Fine-grained attention i/o complexity: Comprehensive analysis for backward passes, 2024.
* [LLS\({}^{+}\)24d] Yingyu Liang, Jiangxuan Long, Zhenmei Shi, Zhao Song, and Yufa Zhou. Beyond linear approximations: A novel pruning approach for attention matrix, 2024.
* [LLSS24] Xiaoyu Li, Yingyu Liang, Zhenmei Shi, and Zhao Song. A tighter complexity analysis of sparsegpt. _arXiv preprint arXiv:2408.12151_, 2024.
* [LOG\({}^{+}\)19] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining approach. _arXiv preprint arXiv:1907.11692_, 2019.
* [LSS\({}^{+}\)24a] Yingyu Liang, Zhizhou Sha, Zhenmei Shi, Zhao Song, and Yufa Zhou. Looped relu mlps may be all you need as practical programmable computers, 2024.
* [LSS\({}^{+}\)24b] Yingyu Liang, Zhizhou Sha, Zhenmei Shi, Zhao Song, and Yufa Zhou. Multi-layer transformers gradient can be approximated in almost linear time. _arXiv preprint arXiv:2408.13233_, 2024.
* [LSSS24] Yingyu Liang, Zhizhou Sha, Zhenmei Shi, and Zhao Song. Differential privacy mechanisms in neural tangent kernel regression. _arXiv preprint arXiv:2407.13621_, 2024.
* [LSSY24] Yingyu Liang, Zhenmei Shi, Zhao Song, and Chiwun Yang. Toward infinite-long prefix in transformer. _arXiv preprint arXiv:2406.14036_, 2024.
* [LSSZ24a] Yingyu Liang, Zhenmei Shi, Zhao Song, and Yufa Zhou. Differential privacy of cross-attention with provable guarantee. _arXiv preprint arXiv:2407.14717_, 2024.

* [LSSZ24b] Yingyu Liang, Zhenmei Shi, Zhao Song, and Yufa Zhou. Tensor attention training: Provably efficient learning of higher-order transformers. _arXiv preprint arXiv:2405.16411_, 2024.
* [LSSZ24c] Yingyu Liang, Zhenmei Shi, Zhao Song, and Yufa Zhou. Unraveling the smoothness properties of diffusion models: A gaussian mixture perspective. _arXiv preprint arXiv:2405.16418_, 2024.
* [LSY24] Xiaoyu Li, Zhao Song, and Junwei Yu. Quantum speedups for approximating the john ellipsoid. _arXiv preprint arXiv:2408.14018_, 2024.
* [LSZ19] Yin Tat Lee, Zhao Song, and Qiuyi Zhang. Solving empirical risk minimization in the current matrix multiplication time. In _Conference on Learning Theory (COLT)_, pages 2140-2157. PMLR, 2019.
* [LSZ23] Zhihang Li, Zhao Song, and Tianyi Zhou. Solving regularized exp, cosh and sinh regression problems. _arXiv preprint, 2303.15725_, 2023.
* [LTLH21] Xuechen Li, Florian Tramer, Percy Liang, and Tatsunori Hashimoto. Large language models can be strong differentially private learners. _arXiv preprint arXiv:2110.05679_, 2021.
* [Ope23] OpenAI. Gpt-4 technical report. _arXiv preprint arXiv:2303.08774_, 2023.
* [PX23] William Peebles and Saining Xie. Scalable diffusion models with transformers. In _Proceedings of the IEEE/CVF International Conference on Computer Vision_, pages 4195-4205, 2023.
* [QSZZ23] Lianke Qin, Zhao Song, Lichen Zhang, and Danyang Zhuo. An online and unified algorithm for projection matrix vector multiplication with application to empirical risk minimization. In _AISTATS_, 2023.
* [RBL\({}^{+}\)22] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bjorn Ommer. High-resolution image synthesis with latent diffusion models. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pages 10684-10695, 2022.
* [RF18] Joseph Redmon and Ali Farhadi. Yolov3: An incremental improvement. _arXiv preprint arXiv:1804.02767_, 2018.
* [RNS\({}^{+}\)18] Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al. Improving language understanding by generative pre-training. 2018.
* [RSR\({}^{+}\)20] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. _The Journal of Machine Learning Research_, 21(1):5485-5551, 2020.
* [RSY\({}^{+}\)21] V. Ruehle, R. Sim, Sergey Yekhanin, D. Jones, K. Laine, B. Kopf, J. Teevan, J. Kleewein, and S. Rajmohan. Privacy preserving machine learning: Maintaining confidentiality and preserving trust. 2021.
* [RWC\({}^{+}\)19] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. _OpenAI blog_, 1(8):9, 2019.
* [Sag18] Matthew Sag. The new legal landscape for text mining and machine learning. _J. Copyright Soc'y USA_, 66:291, 2018.
* [SMN\({}^{+}\)24] Zhenmei Shi, Yifei Ming, Xuan-Phi Nguyen, Yingyu Liang, and Shafiq Joty. Discovering the gems in early layers: Accelerating long-context llms with 1000x input token reduction. _arXiv preprint arXiv:2409.17422_, 2024.
* [Sna22] Snapchat. Differential privacy at snapchat, 2022.

* [Son19] Zhao Song. _Matrix theory: optimization, concentration, and algorithms_. The University of Texas at Austin, 2019.
* [SSC\({}^{+}\)22] Weiyan Shi, Ryan Shea, Si Chen, Chiyuan Zhang, Ruoxi Jia, and Zhou Yu. Just fine-tune twice: Selective differential privacy for large language models. In _Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing_, pages 6327-6340, 2022.
* [SWXL24] Zhenmei Shi, Junyi Wei, Zhuoyan Xu, and Yingyu Liang. Why larger language models do in-context learning differently? _arXiv preprint arXiv:2405.19592_, 2024.
* [SYYZ23] Zhao Song, Xin Yang, Yuanyuan Yang, and Lichen Zhang. Sketching meets differential privacy: Fast algorithm for dynamic kronecker projection maintenance. In _ICML_, 2023.
* [TM22] Abhradeep Thakurta and Brendan McMahan. Federated learning with formal differential privacy guarantees. 2022.
* [TPG\({}^{+}\)17] Florian Tramer, Nicolas Papernot, Ian Goodfellow, Dan Boneh, and Patrick McDaniel. The space of transferable adversarial examples. _arXiv preprint arXiv:1704.03453_, 2017.
* [UAS\({}^{+}\)20] Mohd Usama, Belal Ahmad, Enmin Song, M Shamim Hossain, Mubarak Alrashoud, and Ghulam Muhammad. Attention-based sentiment analysis using convolutional and recurrent neural network. _Future Generation Computer Systems_, 113:571-578, 2020.
* [Vad17] Salil Vadhan. The complexity of differential privacy. _Tutorials on the Foundations of Cryptography: Dedicated to Oded Goldreich_, pages 347-450, 2017.
* [Ver18] Roman Vershynin. _High-dimensional probability: An introduction with applications in data science_, volume 47. Cambridge university press, 2018.
* [VKB23] Nikhil Vyas, Sham Kakade, and Boaz Barak. Provable copyright protection for generative models. _arXiv preprint arXiv:2302.10870_, 2023.
* [VSP\({}^{+}\)17] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. _Advances in neural information processing systems_, 30, 2017.
* [Wai19] Martin J Wainwright. _High-dimensional statistics: A non-asymptotic viewpoint_, volume 48. Cambridge university press, 2019.
* [WCZ\({}^{+}\)23] Yilin Wang, Zeyuan Chen, Liangjun Zhong, Zheng Ding, Zhizhou Sha, and Zhuowen Tu. Dolfin: Diffusion layout transformers without autoencoder. _arXiv preprint arXiv:2310.16305_, 2023.
* [WHHL24] Dennis Wu, Jerry Yao-Chieh Hu, Teng-Yun Hsiao, and Han Liu. Uniform memory retrieval with larger capacity for modern hopfield models. In _Forty-first International Conference on Machine Learning (ICML)_, 2024.
* [WHL\({}^{+}\)24] Dennis Wu, Jerry Yao-Chieh Hu, Weijian Li, Bo-Yu Chen, and Han Liu. STanhop: Sparse tandem hopfield model for memory-enhanced time series prediction. In _The Twelfth International Conference on Learning Representations (ICLR)_, 2024.
* [WMS\({}^{+}\)24] Jiayu Wang, Yifei Ming, Zhenmei Shi, Vibhav Vineet, Xin Wang, and Neel Joshi. Is a picture worth a thousand words? delving into spatial reasoning for vision language models. _arXiv preprint arXiv:2406.14852_, 2024.
* [WSD\({}^{+}\)23] Zirui Wang, Zhizhou Sha, Zheng Ding, Yilin Wang, and Zhuowen Tu. Tokencompose: Grounding diffusion with token-level supervision. _arXiv preprint arXiv:2312.03626_, 2023.
* [WXZ\({}^{+}\)24] Yilin Wang, Haiyang Xu, Xiang Zhang, Zeyuan Chen, Zhizhou Sha, Zirui Wang, and Zhuowen Tu. Omnicontrolnet: Dual-stage integration for conditional image generation. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pages 7436-7448, 2024.

* [XGH\({}^{+}\)21] Hu Xu, Gargi Ghosh, Po-Yao Huang, Prahal Arora, Masoumeh Aminzadeh, Christoph Feichtenhofer, Florian Metze, and Luke Zettlemoyer. Vlm: Task-agnostic video-language model pre-training for video understanding. _arXiv preprint arXiv:2105.09996_, 2021.
* [XHH\({}^{+}\)24] Chenwei Xu, Yu-Chao Huang, Jerry Yao-Chieh Hu, Weijian Li, Ammar Gilani, Hsi-Sheng Goan, and Han Liu. Bishop: Bi-directional cellular learning for tabular data with generalized sparse modern hopfield model. In _Forty-first International Conference on Machine Learning (ICML)_, 2024.
* [XSL24] Zhuoyan Xu, Zhenmei Shi, and Yingyu Liang. Do large language models have compositional ability? an investigation into limitations and scalability. In _ICLR 2024 Workshop on Mathematical and Empirical Understanding of Foundation Models_, 2024.
* [XSW\({}^{+}\)23] Zhuoyan Xu, Zhenmei Shi, Junyi Wei, Fangzhou Mu, Yin Li, and Yingyu Liang. Towards few-shot adaptation of foundation models via multitask finetuning. In _The Twelfth International Conference on Learning Representations_, 2023.
* [XZA\({}^{+}\)23] Zheng Xu, Yanxiang Zhang, Galen Andrew, Christopher A Choquette-Choo, Peter Kairouz, H Brendan McMahan, Jesse Rosenstock, and Yuanbo Zhang. Federated learning of gboard language models with differential privacy. _arXiv preprint arXiv:2305.18465_, 2023.
* [YDY\({}^{+}\)19] Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R Salakhutdinov, and Quoc V Le. Xlnet: Generalized autoregressive pretraining for language understanding. _Advances in neural information processing systems_, 32, 2019.
* [YNB\({}^{+}\)21] Da Yu, Saurabh Naik, Arturs Backurs, Sivakanth Gopi, Huseyin A Inan, Gautam Kamath, Janardhan Kulkarni, Yin Tat Lee, Andre Manoel, Lukas Wutschitz, et al. Differentially private fine-tuning of language models. _arXiv preprint arXiv:2110.06500_, 2021.
* [ZHDK23] Amir Zandieh, Insu Han, Majid Daliri, and Amin Karbasi. Kdeformer: Accelerating transformers via kernel density estimation. _arXiv preprint arXiv:2302.02451_, 2023.
* [ZHJL24] Jingyi Zhang, Jiaxing Huang, Sheng Jin, and Shijian Lu. Vision-language models for vision tasks: A survey. _IEEE Transactions on Pattern Analysis and Machine Intelligence_, 2024.
* [ZTL\({}^{+}\)17] Jingwei Zhang, Lei Tai, Ming Liu, Joschka Boedecker, and Wolfram Burgard. Neural slam: Learning to explore with external memory. _arXiv preprint arXiv:1706.09520_, 2017.

**Appendix**

###### Contents

* 1 Introduction
	* 1.1 Key Definitions
	* 1.2 Our Result
	* 1.3 Related Work
* 2 Notations
* 3 Main Result
* 4 Technique Overview
	* 4.1 Error Control from Logit Matrix to Attention Matrix
	* 4.2 Analysis of Gaussian Sampling Mechanism
	* 4.3 Sensitivity for PSD Matrix
* 5 Conclusion
* A More Related Work
* B Preminary
* B.1 Notations
* B.2 Basic Algebra
* B.3 Previous Tools
* C Error Control from Logit Matrix to Attention Matrix
* C.1 Perturb PSD Matrix
* C.2 Error Control for Normalization
* C.3 Error of Attention Matrix
* C.4 Error Control
* D Analysis of Gaussian Sampling Mechanism
* D.1 Computation Tools
* D.2 Spectral Decomposition
* D.3 The Transformation for Output
* D.4 The Upper Bound for Expectation
* D.5 Sub-Exponential
* D.6 Analysis of Gaussian Sampling
* E More Sensitivity Lemma

Roadmap.Section A provides more related work. In Section B, we present preliminaries for the paper. In Section C, we analyze the perturbations in attention computation. Section D presents the proof of the existence of differential privacy using our Gaussian sampling mechanism. In Section E, we provide more Lemma about sensitivity.

## Appendix A More Related Work

Attention Mechanism.Attention mechanisms are foundational in modern neural networks, gaining widespread adoption since their introduction in [23]. They are crucial in decoder-only LLMs [24] and the Vision Transformer (ViT) [1], driving significant progress in language models and computer vision [13, 12, 25, 26]. Additionally, attention mechanisms have been applied to multi-modal models [1, 1, 2, 3, 4], mathematical reasoning [11, 15, 16], diffusion models [17, 18, 19], differential privacy [1, 20, 21, 22, 3, 19], Hopfield models [15, 14, 16, 17], and various other techniques [1, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39].

Softmax Computation and Regression.With the rapid development of large language models and attention schemes, many works have focused on softmax computation and regression in this field. [1, 22] shows that a faster attention algorithm can be designed by leveraging the matrix implicitly. [18] proposes a more efficient algorithm for computing dynamic attention by employing the method of lazy update. To solve \(\exp\), \(\cosh\), and \(\sinh\) regressions with input sparsity, [19] use an approximate Newton method that operates in near-linear time. In their work on softmax regression, [17] conduct a further analysis of attention schemes based on prior research in regression. In contrast, [2] focus on the convergence analysis of overparameterized two-layer networks with exponential activation functions. To compute the attention matrix more efficiently for large feature dimensions, [2] propose a randomized algorithm.

## Appendix B Preminary

Section B.1 presents the notations that are used throughout our paper. These notations are essential for a clear and concise presentation of our work. In Section B.2, we provide an introduction to some basic algebraic concepts that are relevant to our research. This includes fundamental mathematical operations and properties that are used in the analysis and development of our differential privacy algorithm. In Section B.3, we provide the previous tools that help our proofs.

### Notations

For a event \(C\), \(\Pr[C]\) represents the probability of event \(C\) occurring. \(\mathbb{E}[X]\) represents the expected value (or mean) of a random variable \(X\).

We use \(\chi^{2}_{d}\) to denote a Chi-squared random variable with \(d\) degrees of freedom. \(\mathbb{N}\) represents the set of natural numbers, which consists of all positive integers including 1, 2, 3, and so on.

If \(M\) and \(N\) are symmetric matrices, we define \(M\succeq N\) to mean that for all vectors \(x\), the inequality \(x^{\top}Mx\geq x^{\top}Nx\) holds.

If \(M\) is a symmetric matrix of dimension \(n\times n\), we define \(M\) to be positive semidefinite (\(M\succeq 0\)) if the inequality \(x^{\top}Mx\geq 0\) holds for all vectors \(x\in\mathbb{R}^{n}\).

We use the notation \(\mathbf{0}_{n}\) to denote an \(n\)-dimensional vector whose entries are all zero, and \(\mathbf{1}_{n}\) to denote an \(n\)-dimensional vector whose entries are all one. The symbol \(I_{n}\) represents the \(n\times n\) identity matrix, which is a square matrix with ones on the main diagonal and zeros elsewhere.

Let \(x\) be an arbitrary vector in \(\mathbb{R}^{n}\). We define \(\exp(x)\in\mathbb{R}^{n}\) as a vector whose \(i\)-th entry \(\exp(x)_{i}\) is equal to \(\exp(x_{i})\), where \(\exp(\cdot)\) denotes the exponential function. We use \(\langle x,y\rangle\) to denote \(\sum_{i=1}^{n}x_{i}y_{i}\).

For any matrix \(A\), we use \(\|A\|\) to denote the spectral norm of \(A\), i.e., \(\|A\|=\max_{\|x\|_{2}=1}\|Ax\|_{2}\), \(\|A\|_{F}\) to denote its Frobenius norm and \(\|A\|_{\infty}\) to denote the infinity norm. \(A_{i,j}\) represents the element in the \(i\)-th row and \(j\)-th column of matrix \(A\). \(\det(A)\) represents the determinant of matrix \(A\). For a square and symmetric matrix \(A\in\mathbb{R}^{n\times n}\), we say \(A\) positive semi-definite (\(A\succeq 0\)) if for all vectors \(x\in\mathbb{R}^{n}\), we have \(x^{\top}Ax\geq 0\).

We denote the inverse of a matrix \(M\) as \(M^{-1}\) and its transpose as \(M^{\top}\). We refer to \(\lambda_{i}\) as the \(i\)-th eigenvalue of \(N\).

\(\mathbb{S}_{+}^{n}\) denotes the set of \(n\times n\) positive semidefinite (PSD) matrices.

### Basic Algebra

In this section, we offer an introduction to fundamental algebraic concepts.

**Fact B.1**.: _We have_

* _Part 1. Let_ \(A\in\mathbb{R}^{n\times n}\)_, then we have_ \(\|A\|_{F}\leq\sqrt{n}\|A\|\)_._
* _Part 2. Let_ \(A\in\mathbb{R}^{n\times n}\)_, then we have_ \(\|A\|\leq\|A\|_{F}\)__
* _Part 3. For two vectors_ \(a,b\in\mathbb{R}^{n}\)_, then we have_ \(\|ab^{\top}\|\leq\|a\|_{2}\cdot\|b\|_{2}\)__

**Fact B.2**.: _We have_

* _Part 1._ \(\cosh(x)=\sum_{i=0}^{\infty}(1/(2i)!)\cdot x^{2i}\)_._
* _Part 2._ \(\exp(x)=\sum_{i=0}^{\infty}(1/(i!))\cdot x^{i}\)_._
* _Part 3. We have_ \(|\exp(x)-1|\leq|x|+x^{2}\)_,_ \(\forall x\in(-0.1,0.1)\)_._
* _Part 4._ \(|\exp(x)-\exp(y)|\leq\exp(x)\cdot(|x-y|+|x-y|^{2})\) _for_ \(|x-y|\leq 0.1\)_._
* _Part 5. We have_ \(|\cosh(x)-1|\leq x^{2}\)_,_ \(\forall x\in(-0.1,0.1)\)_._
* _Part 6._ \(|\cosh(x)-\cosh(y)|\leq\cosh(x)\cdot|x-y|^{2}\) _for_ \(|x-y|\leq 0.1\)_._

### Previous Tools

This section introduces several differential privacy tools. These tools are essential for demonstrating the differential privacy properties of our algorithm.

**Theorem B.3** (Empirical covariance estimator for Gaussian [20]).: _Let \(\Sigma\in\mathbb{R}^{d\times d}\) be PSD, \(X_{1},\cdots,X_{n}\sim\mathcal{N}(0,\Sigma)\) be i.i.d and \(\widetilde{\Sigma}=\frac{1}{n}\sum_{i=1}^{n}X_{i}X_{i}^{\top}\). Then with probability \(1-\gamma\), it holds that \(\|\Sigma^{-1/2}\widetilde{\Sigma}\Sigma^{-1/2}-I\|_{F}\leq\rho\) for some \(\rho=O(\sqrt{\frac{d^{2}+\log(1/\gamma)}{n}}+\frac{d^{2}+\log(1/\gamma)}{n})\)._

**Theorem B.4** (Lemma 1.5 in [21], Section 1.1 of [21]).: _For a (randomized) mechanism \(\mathcal{M}\) and datasets \(x,y\), define the function \(f_{xy}(z):=\log(\frac{\Pr[\mathcal{M}(x)=z]}{\Pr[\mathcal{M}(y)=z]})\) If \(\Pr[f_{xy}(\mathcal{M}(x))>\epsilon]\leq\delta\) for all adjacent datasets \(x,y\), then \(\mathcal{M}\) is \((\epsilon,\delta)\)-DP._

**Lemma B.5** (Sub-exponential tail bound, Proposition 2.9 in [23]).: _Suppose that \(X\) is sub-exponential with parameters \((\nu,\alpha)\). Then \(\Pr[X-\mu\geq t]\leq\max\{\exp(-\frac{t^{2}}{2v^{2}}),\exp(\frac{t}{2\alpha})\}\)._

**Lemma B.6** (\(\chi_{1}^{2}\) sub-exponential parameters, Example 2.11 in [23]).: _A chi-squared random variable with \(1\) degree of freedom \((\chi_{1}^{2})\) is sub-exponential with parameters \((\nu,\alpha)=(2,4)\)_

**Lemma B.7** (Sub-exponential parameters of independent sum, Chapter 2 of [23]).: _Consider an independent sequence \(X_{1},\cdots,X_{k}\) of random variables, such that \(X_{i}\) is sub-exponential with parameters \((\nu_{i},\alpha_{i})\). Then the variable \(\sum_{i=1}^{k}X_{i}\) is sub-exponential with parameters \((\nu_{*},\alpha_{*})\), where \(a_{*}=\max_{i\in[k]}\alpha_{i}\) and \(\nu_{*}=(\sum_{i=1}^{k}\nu_{i}^{2})^{1/2}\)._

## Appendix C Error Control from Logit Matrix to Attention Matrix

In Section C.1, we discuss the perturbation of positive semi-definite (psd) matrices, which is a crucial step in ensuring the differential privacy of our algorithm. Section C.2 focuses on the perturbation of diagonal normalization matrices, which is another important aspect of our error control approach. In Section C.3, we analyze the error in the attention matrix computation that arises from these perturbations. Finally, in Section C.4, we present the main result of Section C, which summarizes the effectiveness of our error control mechanisms in achieving differential privacy for the computation of the attention matrix.

### Perturb PSD Matrix

In Section C.1, we discuss the perturbation of positive semi-definite (psd) matrices. This is a crucial step in ensuring the differential privacy of our algorithm.

**Lemma C.1** (Lemma 3.1 in [1]).: _We denote \(A\in\mathbb{R}^{n\times n}\) and \(B\in\mathbb{R}^{n\times n}\) as psd matrices._

_If all of the following requirements are met_

* **Requirement 1.** _We have_ \(-r\leq A_{i,j}\leq r\)_,_ \(\forall(i,j)\in[n]\times[n]\)_._
* **Requirement 2.**__\((1-\epsilon)B\preceq A\preceq(1+\epsilon)B\)_;_

_Then, it follows that_

\[B_{i,j}\in[-(1+\epsilon)r,(1+\epsilon)r].\]

**Lemma C.2** (A general version of Lemma 3.2 in [1]).: _If all of the following requirements are met_

* **Requirement 1.**__\(A_{i,j}\in[-r,r]\)_._
* **Requirement 2.**__\(B_{i,j}\in[-(1+\epsilon)r,(1+\epsilon)r]\)_._
* **Requirement 3.**__\(r\in(0,0.1)\)_,_ \(\epsilon\in(0,0.1)\)_._
* **Requirement 4.** _Let_ \(f(z)\in\{\exp(z),\cosh(z)\}\)_._

_It follows that_

* **Part 1.**__ \[|f(A_{i,j})-f(B_{i,j})|\leq f(A_{i,j})\cdot(2+2\epsilon+4r)\cdot r\;\;\forall i,j\in[n]\times[n].\]
* **Part 2.**__ \[|f(A_{i,j})-f(B_{i,j})|\leq f(B_{i,j})\cdot(2+2\epsilon+4r)\cdot r\;\;\forall i,j\in[n]\times[n].\]

Proof.: According to **Requirement 1.**, **Requirement 2.** and **Requirement 3.**, we have

\[|A_{i,j}-B_{i,j}|\leq(2+\epsilon)r. \tag{4}\]

Proof of Part 1.It follows that

\[|f(A_{i,j})-f(B_{i,j})| \leq f(A_{i,j})\cdot(|A_{i,j}-B_{i,j}|+|A_{i,j}-B_{i,j}|^{2})\] \[\leq f(A_{i,j})\cdot|A_{i,j}-B_{i,j}|\cdot(1+|A_{i,j}-B_{i,j}|)\] \[\leq f(A_{i,j})\cdot|A_{i,j}-B_{i,j}|\cdot(1+(2+\epsilon)r)\] \[\leq f(A_{i,j})\cdot(2+\epsilon)r\cdot(1+(2+\epsilon)r)\] \[=f(A_{i,j})\cdot(2+\epsilon+(2+\epsilon)^{2}r)r\] \[\leq f(A_{i,j})\cdot(2+2\epsilon+4r)r\]

where the 1st step is the result of Fact B.2, the 2nd step follows from straightforward algebraic manipulations, the 3rd step is a consequence of Eq.(4), the 4th step is a consequence of Eq.(4), the 5th step follows from algebraic manipulations, and the 6th step is a result of satisfying **Requirement 3** in the Lemma statement.

Proof of Part 2.Similarly, we can prove it.

### Error Control for Normalization

This section focuses on the perturbation of diagonal normalization matrices, which is another important aspect of our error control approach.

**Lemma C.3** (Error Control for Normalization, A general version Lemma 3.3 in [3]).: _If the following condition holds_

* **Requirement 1**.: _We define_ \(f\) _as Definition_ 4.1_._
* **Requirement 2**.: _We define_ \(\mathsf{D}\) _as Definition_ 4.2_._
* **Requirement 3**.: \(\forall(i,j)\in[n]\times[n]\)_, we have_ \(|f(A_{i,j})-f(B_{i,j})|\leq f(A_{i,j})\cdot c_{0}r\)_._
* **Requirement 4**.: \(\forall(i,j)\in[n]\times[n]\)_, we have_ \(f(A_{i,j})-f(B_{i,j})|\leq f(B_{i,j})\cdot c_{0}r\)_._

_Then, it follows that,_

* **Part 1**. \[|\,\mathsf{D}(A)_{i,i}-\mathsf{D}(B)_{i,i}| \leq\mathsf{D}(A)_{i,i}\cdot c_{0}r\;\;\forall i\in[n]\]
* **Part 2**. \[|\,\mathsf{D}(A)_{i,i}-\mathsf{D}(B)_{i,i}| \leq\mathsf{D}(B)_{i,i}\cdot c_{0}r\;\;\forall i\in[n]\]

Proof.: **Proof of Part 1.** From the above conditions in the lemma statement, it follows that

\[|\,\mathsf{D}(A)_{i,i}-\mathsf{D}(B)_{i,i}| =|(f(A_{i,*})-f(B_{i,*}))\cdot\mathbf{1}_{n}|\] \[=|\sum_{j=1}^{n}(f(A_{i,j})-f(B_{i,j}))|\] \[\leq\sum_{j=1}^{n}|f(A_{i,j})-f(B_{i,j})|\] \[\leq\sum_{j=1}^{n}f(A_{i,j})\cdot c_{0}r\] \[=f(A_{i,*})\mathbf{1}_{n}\cdot c_{0}r\] \[=\mathsf{D}(A)_{i,i}\cdot c_{0}r\]

where the 1st step follows from algebraic manipulations, the 2nd step is due to algebraic manipulations, the 3rd step is the result of triangle inequality, the 4th step is based on **Requirement 2** in Lemma statement, the 5th step comes from algebraic manipulations and the last step is the result of algebraic manipulations.

**Proof of Part 2.**

The proof is similar to Part 1. So we omit the details here.

### Error of Attention Matrix

In this section, we analyze the error in the attention matrix computation that arises from the perturbations of psd and diagonal normalization matrices.

**Lemma C.4** (A general version of Lemma 3.4 in [3]).: _Let \(c_{1}>0\) and \(c_{2}>0\). If all of the following requirements are met_

* **Requirement 1**.: _We define_ \(f\) _as Definition_ 4.1_._
* **Requirement 2**.: _We define_ \(\mathsf{D}\) _as Definition_ 4.2_._* **Requirement 3.** \[|\operatorname{\mathsf{D}}(A)_{i,i}-\operatorname{\mathsf{D}}(B)_{i,i}|\leq c_{1} \cdot r\cdot\min\{\operatorname{\mathsf{D}}(A)_{i,i},\operatorname{\mathsf{D}}( B)_{i,i}\}\;\;\forall i\in[n],\]
* **Requirement 4.** \[|f(A_{i,j})-f(B_{i,j})|\leq c_{2}\cdot r\cdot\min\{f(A_{i,j}),f(B_{i,j})\}\;\; \forall i,j\in[n]\times[n]\]

_It follows that_

\[\|\operatorname{\mathsf{D}}(A)^{-1}f(A)-\operatorname{\mathsf{D}}(B)^{-1}f(B) \|_{\infty}\leq(c_{1}+c_{2})\cdot r.\]

Proof.: We first decompose the difference into

\[\|\operatorname{\mathsf{D}}(A)^{-1}f(A)-\operatorname{\mathsf{D} }(B)^{-1}f(B)\|_{\infty}\] \[\leq\|\operatorname{\mathsf{D}}(A)^{-1}f(A)-\operatorname{ \mathsf{D}}(B)^{-1}f(B)\|_{\infty}+\|\operatorname{\mathsf{D}}(B)^{-1}f(B)- \operatorname{\mathsf{D}}(B)^{-1}f(B)\|_{\infty}\] \[=Z_{1}+Z_{2}\]

where last step is obtained by

\[Z_{1}:=\|\operatorname{\mathsf{D}}(B)^{-1}f(B)-\operatorname{\mathsf{D}}(B)^{ -1}f(B)\|_{\infty},\]

and

\[Z_{2}:=\|\operatorname{\mathsf{D}}(A)^{-1}f(A)-\operatorname{\mathsf{D}}(B)^{ -1}f(B)\|_{\infty}.\]

We will present the proof in two parts.

The first term.\(\;\;\forall(i,j)\in[n]\times[n]\), it follows that

\[Z_{1} =|(\operatorname{\mathsf{D}}(A)^{-1}f(A)-\operatorname{\mathsf{D} }(B)^{-1}f(B))_{i,j}|\] \[=|\operatorname{\mathsf{D}}(A)^{-1}_{i,i}\cdot(f(A)_{i,j}-f(B)_{i,j})|\] \[\leq\operatorname{\mathsf{D}}(A)^{-1}_{i,i}\cdot|f(A)_{i,j}-f(B)_{ i,j})|\] \[\leq\operatorname{\mathsf{D}}(A)^{-1}_{i,i}\cdot c_{2}\cdot r\cdot f (A)_{i,j}\] \[\leq c_{2}r\cdot(\operatorname{\mathsf{D}}(A)^{-1}f(A))_{i,j}\] \[\leq c_{2}r,\]

where the 1st step comes from definition, the 2nd step is the result of algebraic manipulations, the 3rd step comes from triangle inequality, the 4th step is based on **Requirement 4** in the lemma statement, the 5th step is the result of algebraic manipulations, and the last step is according to the definition of \(\operatorname{\mathsf{D}}\).

The second term.\(\;\;\forall(i,j)\in[n]\times[n]\), it follows that

\[Z_{2} =|(\operatorname{\mathsf{D}}(B)^{-1}f(B)-\operatorname{\mathsf{D} }(B)^{-1}f(B))_{i,j}|\] \[=|(\operatorname{\mathsf{D}}(A)^{-1}_{i,i}-\operatorname{\mathsf{ D}}(A)^{-1}_{i,i})f(B)_{i,j}|\] \[=|\frac{\operatorname{\mathsf{D}}(A)_{i,i}-\operatorname{\mathsf{ D}}(B)_{i,i}}{\operatorname{\mathsf{D}}(A)_{i,i}\operatorname{\mathsf{D}}(B)_{i,i}}f(B) _{i,j}|\] \[\leq|\frac{\operatorname{\mathsf{D}}(A)_{i,i}-\operatorname{ \mathsf{D}}(B)_{i,i}}{\operatorname{\mathsf{D}}(A)_{i,i}\operatorname{\mathsf{ D}}(B)_{i,i}}|\cdot|f(B)_{i,j}|\] \[\leq|\frac{c_{1}r\operatorname{\mathsf{D}}(A)_{i,i}}{\operatorname {\mathsf{D}}(A)_{i,i}\operatorname{\mathsf{D}}(B)_{i,i}}|\cdot|f(B)_{i,j}|\] \[=c_{1}r\cdot|\operatorname{\mathsf{D}}(B)^{-1}_{i,i}|\cdot|f(B)_{ i,j}|\]

where the 1st step based on definition, the 2nd steps follow from algebraic manipulations, the 3rd step is the result of algebraic manipulations, the 4th step is due to triangle inequality, the 5th step is due to **Requirement 3** in the lemma statement, the last step is due to algebraic manipulations.

[MISSING_PAGE_EMPTY:21]

Analysis of Gaussian Sampling Mechanism

We denote the output of our privacy algorithm as \(Z\). In Section D.1, we present the computation tools that we use to implement our approach. In Section D.2, we perform spectral decomposition of \(A:=\mathcal{M}(\mathcal{Y})^{1/2}\mathcal{M}(\mathcal{Y}^{\prime})^{-1}\mathcal{ M}(\mathcal{Y})^{1/2}\) and derive some important conclusions from it. Then, in Section D.3, we transform \(Z\) into a format that is based on the spectral decomposition of \(A\). In Section D.4, we present the upper bound of \(\mathbb{E}[Z]\), which is useful in the following section. In Section D.5, we demonstrate that \(Z\) is sub-exponential, which allows us to control the upper bound of \(\Pr[Z\geq\epsilon]\) where \(\epsilon\in(0,1)\). Finally, we present our main result in Section D.6, which is that our Algorithm 2 is differential privacy.

### Computation Tools

This section is dedicated to presenting the computational tools that we use to implement our approach.

**Definition D.1**.: _We define \(\Sigma_{1},\Sigma_{2}\) as Definition 4.7. Let us define_

* \(A:=\Sigma_{1}^{1/2}\Sigma_{2}^{-1}\Sigma_{1}^{1/2}\)__
* \(B:=\Sigma_{2}^{1/2}\Sigma_{1}^{-1}\Sigma_{2}^{-1/2}\)__
* \(C:=\Sigma_{1}^{-1/2}\Sigma_{2}^{1/2}\)__

**Lemma D.2**.: _Let \(A,B\) and \(C\) be defined as Definition D.1. Then we have_

* **Part 1.**__\(A^{-1}=CC^{\top}\)_._
* **Part 2.**__\(B=C^{\top}C\)_._
* **Part 3.**__\(A^{-1},B\) _have the same eigenvalue._

Proof.: Note that \(\Sigma_{1}\) and \(\Sigma_{2}\) are symmetric, we can easily have the proof as follows.

**Proof of Part 1.**

\[A^{-1} =(\Sigma_{1}^{1/2}\Sigma_{2}^{-1}\Sigma_{1}^{1/2})^{-1}\] \[=(\Sigma_{1}^{1/2}\Sigma_{2}^{-1/2}\Sigma_{2}^{-1/2}\Sigma_{1}^{1 /2})^{-1}\] \[=(\Sigma_{2}^{-1/2}\Sigma_{1}^{1/2})^{-1}(\Sigma_{1}^{1/2}\Sigma_{ 2}^{-1/2})^{-1}\] \[=(\Sigma_{1}^{1/2}\Sigma_{2}^{-1/2})(\Sigma_{2}^{-1/2}\Sigma_{1}^ {1/2})\] \[=CC^{\top} \tag{6}\]

**Proof of Part 2.**

\[B =\Sigma_{2}^{-1/2}\Sigma_{1}\Sigma_{2}^{-1/2}\] \[=(\Sigma_{2}^{-1/2}\Sigma_{1}^{1/2})(\Sigma_{1}^{1/2}\Sigma_{2}^{ -1/2})\] \[=C^{T}C \tag{7}\]

**Proof of Part 3.** It simply follows from Eq.(6) and Eq.(7). 

### Spectral Decomposition

This section is focused on the spectral decomposition of \(A\), which we perform to gain insights into its properties. By analyzing the spectral decomposition, we are able to draw important conclusions about \(A\) that are relevant to our approach.

**Lemma D.3**.: _If all of the following requirements are met_

* **Requirement 1**.: _We define_ \(A\) _as Definition D.1._* **Requirement 2**.: _Let \(\lambda_{1}\cdots\lambda_{n}\) be eigenvalues of \(A\)._
* **Requirement 3**.: _Let \(A=\sum_{j=1}^{n}\lambda_{j}v_{j}v_{j}^{\top}\) be spectral decomposition for \(A\)._
* **Requirement 4**.: _Let \(\Delta\) be denoted as Definition 4.5._
* **Requirement 5**.: _Let \(M,\mathcal{M}\) be denoted as Definition 4.4 and \(M\leq\Delta\)._

_We have_

* \(\sum_{j=1}^{n}(\lambda_{j}-1)^{2}\leq\Delta^{2}\)_._
* \(\sum_{j=1}^{n}(1-\frac{1}{\lambda_{j}})^{2}\leq\Delta^{2}\)_._

Proof.: we have

\[\sum_{j=1}^{n}(\lambda_{j}-1)^{2} =\|A-I\|_{F}^{2}\] \[\leq\Delta^{2}\]

where the 1st step is based on **Requirement 3** in the lemma statement and the last step is due to **Requirement 5** in lemma statement.

Similarly, we have

\[\sum_{j=1}^{n}(1-\frac{1}{\lambda_{j}})^{2} =\|I-A^{-1}\|_{F}^{2}\] \[=\|I-B\|_{F}^{2}\] \[\leq\Delta^{2}\]

where the 1st step is due to **Requirement 3** in the lemma statement, the 2nd step follows from swapping the roles of \(\mathcal{Y},\mathcal{Y}^{{}^{\prime}}\) and the last step is due to Lemma D.2. 

### The Transformation for Output

In Section D.3, we describe the process of transforming the output \(Z\) of our privacy algorithm into a format that is based on the spectral decomposition of \(A\).

**Lemma D.4**.: _If all of the following requirements are met_

* **Requirement 1.**_We define_ \(Z\) _and_ \(h_{i,j}\) _as Definition_ 4.8_._
* **Requirement 2**.: _Let_ \(A\) _be denoted as Definition_ D.1_._
* **Requirement 3**.: _Let_ \(\lambda_{1},\cdots,\lambda_{n}\) _denote the eigenvalue of_ \(A\)_._

_Then we have_

\[Z=\frac{1}{2}\sum_{i=1}^{k}\sum_{j=1}^{n}\left((\lambda_{j}-1)h_{ i,j}^{2}-\log(\lambda_{j})\right)\]

Proof.: The privacy loss random variable \(Z\) can be expressed as follows:

\[Z =\sum_{i=1}^{k}\log\left(\frac{\det(\Sigma_{1})^{-\frac{1}{2}}\exp (-\frac{1}{2}g_{i}^{\top}\Sigma_{1}^{-1}g_{i})}{\det(\Sigma_{2})^{-\frac{1}{2} }\exp(-\frac{1}{2}g_{i}^{\top}\Sigma_{2}^{-1}g_{i})}\right)\] \[=\sum_{i=1}^{k}\left(\frac{1}{2}g_{i}^{\top}(\Sigma_{2}^{-1}- \Sigma_{1}^{-1})g_{i}-\frac{1}{2}\log\left(\frac{\det(\Sigma_{1})}{\det(\Sigma _{2})}\right)\right)\] \[=\frac{1}{2}\sum_{i=1}^{k}\left(\left(\Sigma_{1}^{-1/2}g_{i} \right)^{\top}(A-I)\bigg{(}\Sigma_{1}^{-1/2}g_{i}\bigg{)}-\log\det(A)\right)\]\[=\frac{1}{2}\sum_{i=1}^{k}\sum_{j=1}^{n}\left((\lambda_{j}-1)h_{i,j}^{2}- \log(\lambda_{j})\right)\]

where the 1st step is based on **Requirement 1** in the lemma statement, the 2nd step follows from rearranging the terms, the 3rd step is based on **Requirement 2** in the lemma statement, and the last step is by taking the spectral decomposition of \(A\). 

### The Upper Bound for Expectation

In Section D.4, we provide an upper bound on the expected value of \(Z\), which is a useful result for the subsequent section.

**Lemma D.5**.: _If all of the following requirements are met_

* **Requirement 1** _We define_ \(Z\) _as Definition_ 4.8_._
* **Requirement 2** _Let_ \(\epsilon\in(0,1)\) _and_ \(k\in\mathbb{N}\)_._
* **Requirement 3.** _Let_ \(A\) _be denoted as Definition_ D.1_._
* **Requirement 4.** _Let_ \(\lambda_{1},\cdots,\lambda_{n}\) _denote the eigenvalue of_ \(A\)_._
* **Requirement 5.** _Let_ \(\Delta\) _be denoted as Definition_ 4.5_._
* **Requirement 6.** _Let_ \(M,\mathcal{M}\) _be denoted as Definition_ 4.4 _and_ \(M\leq\Delta\)_._

_we have_

\[\mathbb{E}[Z]\leq\frac{\epsilon}{2}\]

Proof.: \[\mathbb{E}[Z] =\frac{k}{2}\sum_{j=1}^{n}(\lambda_{j}-1-\log(\lambda_{j}))\] \[\leq\frac{k}{2}\sum_{j=1}^{n}(\lambda_{j}-2+\frac{1}{\lambda_{j}})\] \[=\frac{k}{2}\sum_{j=1}^{n}(\lambda_{j}-1)(1-\frac{1}{\lambda_{j}})\] \[\leq\|A-I\|_{F}\cdot\|I-A^{-1}\|_{F}\] \[\leq\frac{k}{2}\Delta^{2}\] \[\leq\frac{\epsilon}{2}\]

where the 1st step follows from linearity of expectation and Lemma D.4, the 2nd step is the result of \(\lambda_{j}>0\) and \(\log(x)>1-\frac{1}{x}\) for \(x>0\), the 3rd step follows from simple factorization, the fourth step follows from Cauchy-Schwarz, the fifth step follows from Lemma D.3 and **Requirement 6** in the lemma statement, and the last step follows from \(\Delta<\frac{\epsilon}{\sqrt{k}}\) and \(\epsilon<1\). 

### Sub-Exponential

In Section D.5, evidence is provided that supports the claim that \(Z\) is sub-exponential. This is significant because it enables us to limit the maximum probability of the event \(Z\geq\epsilon\), which is crucial in ensuring differential privacy.

**Lemma D.6**.: _If all of the following requirements are met_

* **Requirement 1.**_We define_ \(Z\) _as Definition_ 4.8_._* **Requirement 2**.: _Let \(\epsilon\in(0,1)\) and \(\delta\in(0,1)\)._
* **Requirement 3**.: _Let \(\Delta\) be denoted as Definition 4.5 and \(\Delta<1\)._
* **Requirement 4**.: _Let \(M,\mathcal{M}\) be denoted as Definition 4.4 and \(M\leq\Delta\)._
* **Requirement 5**.: \(k\in\mathbb{N}\)_._

_we have_

\[\Pr[Z>\epsilon]\leq\delta\]

Proof.: First, we will prove \(Z\) is sub-exponential.

Proof of Sub ExponentialLet \(A\) be dented as Definition D.1 and \(h_{i,j}\) be denoted as Definition 4.8. Since \(h_{i,j}\sim\chi_{1}^{2}\), Lemma B.7 and Lemma B.6, we can say \(Z\) is sub-exponential with

* \(\nu=\sqrt{k}\|I-A\|_{F}\)
* \(\alpha=2\|I-A\|_{F}\)

By Lemma D.3, we have

* \(\nu=\sqrt{k}\|A-I\|_{F}\leq\sqrt{k}\Delta\)
* \(\alpha=2\|A-I\|_{F}\leq 2\Delta\)

Proof of Upper Bound for \(\mathbb{E}[Z]\).: Under **Requirement 3** and **Requirement 4**, by using Lemma D.5, we have

\[\mathbb{E}[Z]\leq\epsilon/2 \tag{8}\]

Proof of Upper BoundBy using Lemma B.5 (sub-exponential tail bound), we have

\[\Pr[Z>\epsilon] < \Pr[Z-\mathbb{E}[Z]>\epsilon/2]\] \[\leq \max\left\{\exp(-\frac{(\epsilon/2)^{2}}{2\nu^{2}}),\exp(-\frac {\epsilon/2}{2\alpha})\right\}\] \[\leq \delta\]

where the 1st step is the reuslt of Eq. (8), the 2nd step is the reuslt of Lemma B.5, and the last step follows from **Requirement 3** in the lemma statement. 

### Analysis of Gaussian Sampling

This section contains our main result in Section D, which we present as follows. The following theorem statement can be viewed as a variation of Theorem 5.1 in [AKT\({}^{+}\)22].

**Theorem D.7** (Formal version of Theorem 4.9, Analysis of the Gaussian Sampling Mechanism ).: _If all of the following requirements are met_

* **Requirement 1**.: _Let \(\epsilon\in(0,1)\) and \(\delta\in(0,1)\)._
* **Requirement 2**.: \(k\in\mathbb{N}\)_._
* **Requirement 3**.: _Let \(\Delta\) be denoted as Definition 4.5 and \(\Delta<1\)._
* **Requirement 4**.: _Let \(M,\mathcal{M}\) be denoted as Definition 4.4 and \(M\leq\Delta\)._
* **Requirement 5**.: _An input \(\Sigma=\mathcal{M}(\mathcal{Y})\)._
* **Requirement 6**.: \(\rho=O(\sqrt{(n^{2}+\log(1/\gamma))/k}+(n^{2}+\log(1/\gamma))/k)\)_._

_Then, there exists an algorithm 2 such that_

[MISSING_PAGE_EMPTY:26]

[MISSING_PAGE_FAIL:27]