# Fractal Patterns May Illuminate the Success of Next-Token Prediction

 Ibrahim Alabdulmohsin

Google Deepmind

Zurich, Switzerland

ibomohsin@google.com

&Vinh Q. Tran

Google Deepmind

New York, USA

vqtran@google.com

&Mostafa Dehghani

Google Deepmind

Mountain View, USA

dehghani@google.com

Corresponding author.

###### Abstract

We study the fractal structure of language, aiming to provide a precise formalism for quantifying properties that may have been previously suspected but not formally shown. We establish that language is: (1) _self-similar_, exhibiting complexities at all levels of granularity, with no particular characteristic context length, and (2) _long-range dependent_ (LRD), with a Hurst parameter of approximately \(\mathrm{H}=0.70\pm 0.09\). Based on these findings, we argue that short-term patterns/dependencies in language, such as in paragraphs, mirror the patterns/dependencies over larger scopes, like entire documents. This may shed some light on how next-token prediction can capture the structure of text across multiple levels of granularity, from words and clauses to broader contexts and intents. In addition, we carry out an extensive analysis across different domains and architectures, showing that fractal parameters are robust. Finally, we demonstrate that the tiny variations in fractal parameters seen across LLMs improve upon perplexity-based bits-per-byte (BPB) in predicting their downstream performance. We hope these findings offer a fresh perspective on language and the mechanisms underlying the success of LLMs.

## 1 Introduction

How does the training objective of predicting the next token in large language models (LLMs) yield remarkable capabilities? Consider, for instance, the two models: Gemini [5] and GPT4 [50]. These models have demonstrated capabilities that extend to quantitative reasoning, summarization, and even coding, which has led some researchers to ponder if there was more to intelligence than "on-the-fly improvisation" [11]. While providing a satisfactory explanation is a difficult endeavor, a possible insight can be drawn from fractals and self-similarity. We elucidate the connection in this work.

**Self-Similarity.** Self-similar processes were introduced by Kolmogorov in 1940 [36]. The notion garnered considerable attention during the late 1960s, thanks to the extensive works of Mandelbrot and his peers [19]. Broadly speaking, an object is called "self-similar" if it is invariant across scales, meaning its statistical or geometric properties stay consistent irrespective of the magnification applied to it (see Figure 1). Nature and geometry furnish us with many such patterns, such as coastlines, snowflakes, the Cantor set and the Kuch curve. Despite the distinction, self-similarity is often discussed in the context of "fractals," another term popularized by Mandelbrot in his seminal book _The Fractal Geometry of Nature_[45]. However, the two concepts are different [26]. See Section 2.

In language, in particular, there have been studies arguing for the presence of a self-similar structure. Nevertheless, due to computational constraints, it was not feasible to holistically model the joint probability distribution of language. As such, linguists often resorted to rudimentary approximations in their arguments, such as by substituting a word with its frequency or length [9], or by focusing onthe recurrence of a specific, predetermined word [49, 3]. These studies fall short of fully capturing the structure of language due to the simplifying assumptions they make, as discussed in Section 4.

Highlighting the self-similar nature of a process can have profound implications. For instance, conventional Poisson models for Ethernet traffic were shown to fail because traffic was self-similar [16, 39, 51, 69]. In such cases, recognizing and quantifying self-similarity had practical applications, such as in the design of buffers [40]. Similarly in language, we argue that self-similarity may offer a fresh perspective on the mechanisms underlying the success of LLMs. Consider the illustrative example shown in Figure 1, where the task is to predict the subsequent measurement in a time series, specifically predicting next tokens in a Wikipedia article (see Section 2 for details). The three plots in Figure 1 (left) represent different manifestations of the same process observed across three distinct time scales. Notably, we observe rich, self-similar details, such as burstiness, in _all_ of them. A well-established approach for quantifying self-similarity is the Holder exponent [66], which we denote by \(\mathrm{S}\). In language, we find it to be \(\mathrm{S}=0.59\pm 0.08\), confirming statistical self-similarity.

Why is this important? We hypothesize that since LLMs are trained to predict the future of a self-similar process, they develop proficiency in capturing patterns across multiple levels of granularity for two interconnected reasons. First, self-similarity implies that the patterns at the level of a paragraph are reflective of the patterns seen at the level of a whole text, which is reminiscent of the _recursive_ structure of language [53]. Thus, recognizing short-term patterns can aide in learning broader contexts. Second, because language displays intricate patterns at all levels of granularity, it would not be enough to rely only on the immediate context of a sentence to predict the next token. Instead, the model needs to identify patterns at higher levels of granularity; e.g. follow the direction of the argument and the broader intent. It must balance between short- and long-term contexts. Willinger et al. [68] and Altmann et al. [3] argue for self-similarity in language due to this hierarchical nature.

**Long-range dependence.** However, self-similarity alone is not sufficient for a predictive model to exhibit anything resembling "intelligent" behavior. In fact, some self-similar processes, despite their intricate details, remain entirely unpredictable. A quintessential example is the simple Brownian motion, which is a Wiener process with independent increments. Its discrete analog is \(B_{n}=\sum_{i=1}^{n}\varepsilon_{i}\), where \(\varepsilon_{i}\sim\mathcal{N}(0,\sigma^{2})\). Despite possessing rich details at all granularities, a model trained to predict \(B_{n}\) cannot learn anything useful from data since the process itself has _independent_ increments.

Thus, for strong capabilities to emerge, the process must have some degree of predictability or dependence as well. One classical metric for quantifying predictability in a stochastic process is the Hurst parameter [31], developed by the hydrologist H. E. Hurst in 1951 while studying the Nile river. It is generally considered to be a robust metric [68], unlike the wavelet estimator [1] and the periodogram method [24] that can be sensitive to errors [54]. As discussed in Section 2.3, we find the Hurst parameter in language to be \(\mathrm{H}=0.70\pm 0.09\). For context, \(\mathrm{H}\) only takes values in \([0,1]\). A value \(\mathrm{H}>0.5\) implies predictability in the data, while \(\mathrm{H}=0.5\) indicates random increments.

While it is compelling that our estimate of \(\mathrm{H}\) in language lies nearly _midway_ between predictability (\(\mathrm{H}=1\)) and noise (\(\mathrm{H}=0.5\)), a Hurst parameter of about \(0.75\) turns out to occur commonly in nature, including in river discharges, Ethernet traffic, temperatures, precipitation, and tree rings [16, 21, 8]. For agents that learn from data, such as LLMs, this value is also reminiscent of processing-based

Figure 1: Manifestations of processes across different time scales. A region marked in red corresponds to the magnified plot beneath it. left: The process exhibits self-similarity with rich details at all levels of granularity. It is an integral process \((X_{t})_{t\in\mathbb{N}}\) calculated from Wikipedia (see Section 2). right: Example of a process that is not self-similar, looking smoother at larger time scales.

theories of curiosity, which suggest that a sweet spot of complexity exists (not too simple, nor too unpredictable) that facilities or accelerates learning [34].

Importantly, predictability and self-similarity _together_ imply long-range dependence (LRD). This follows from the definition of self-similarity, where the patterns at small scales mirror those at larger scales so, for example, the correlations established at micro levels are also pertinent at macro levels. LRD is arguably crucial for enhancing the functionality of predictive models because processes with only short-range dependence could be forecasted (somewhat trivially) with lookup tables that provide the likelihood of transitions over brief sequences. By contrast, this is not possible in LRD processes whose contexts extend indefinitely into the past.

Information Theoretic Complexity.To define fractal parameters, we follow recent works such as [28, 22, 41, 47, 25] in adopting an _information-theoretic_ characterization of the complexity in language using minimal-length codes or surprise. This corresponds to an intrinsic, _irreducible_ description of language and the minimum compute overhead to comprehend/decode it [22], which also correlates well with actual reading times [28, 41]. In this context, self-similarity means that the intrinsic complexity or surprise in language (measured in bits) cannot be smoothed out, even as we look into broader narratives. That is, surprising paragraphs will follow predictable paragraphs, in a manner that is statistically similar to how surprising sentences follow predictable sentences.

Analysis.How robust are these findings? To answer this question, we carry out an extensive empirical analysis across various model architectures and scales, ranging from 1B to over 500B parameters. We find that fractal parameters are quite robust to the choice of the architecture.

However, there exists _tiny_ variations across LLMs. Interestingly, we demonstrate that from a practical standpoint, these differences help in predicting downstream performance in LLMs compared to using perplexity-based metrics alone, such as bits-per-byte (BPB). Specifically, we introduce a new metric and show that using it to predict downstream performance can increase the adjusted \(R^{2}\) from approximately \(0.65\) when using solely BPB, to over \(0.86\) with the new metric2.

Footnote 2: We release the code for calculating fractal parameters at: [https://github.com/google-research/google-research/tree/master/fractals_language](https://github.com/google-research/google-research/tree/master/fractals_language)

**Statement of Contribution.** In summary, we:

1. highlight how the fractal structure of language can offer a new perspective on the capabilities of LLMs, and provide a formalism to quantify properties, such as long-range dependence.
2. establish that language is self-similar and long-range dependent. We provide concrete estimates in language of the three parameters: the self-similarity (Holder) exponent, the Hurst parameter, and the fractal dimension. We also estimate the related Joseph exponent.
3. carry out a comparative study across different model architectures and scales, and different domains, such as ArXiv and GitHub, demonstrating that fractal parameters are robust.
4. connect fractal patterns with learning. Notably, we show that a "median" Hurst exponent improves upon perplexity-based bits-per-byte (BPB) in predicting downstream performance.

## 2 Fractal Structure of Language

### Preliminaries

Suppose we have a discrete-time, stationary stochastic process \((x_{t})_{t\in\mathbb{N}}\), with \(\mathbb{E}[x_{t}]=0\) and \(\mathbb{E}[x_{t}^{2}]=1\). We will refer to \((x_{t})_{t\in\mathbb{N}}\) as the _increment process_ to distinguish it from the _integral process_\((X_{t})_{t\in\mathbb{N}}\) defined by \(X_{t}=\sum_{k=0}^{t}x_{k}\). While \((x_{t})_{t\in\mathbb{N}}\) and \((X_{t})_{t\in\mathbb{N}}\) are merely different representations of the same data, it is useful to keep both representations in mind. For example, self-similarity is typically studied in the context of integral processes whereas LRD is defined on increment processes.

In the literature, it is not uncommon to mistakenly equate parameters that are generally different. For example, the Hurst parameter H has had many definitions in the past that were not equivalent, and Mandelbrot himself cautioned against this [44]. The reason behind this is because different parameters can agree in the idealized fractional Brownian motion, leading some researchers to equate them in general [66]. We will keep the self-similarity exponent \(\mathrm{S}\) and \(\mathrm{H}\) separate in our discussion.

Experimental Setup.In order to establish self-similarity and LRD in language, we convert texts into sequences of bits using a large language model (LLM). Specifically, we use PaLM2-L (Unicorn) [6] to calculate the probability of the next token \(w_{t}\) conditioned on its entire prefix \(w_{[t-1]}=(w_{0},w_{1},\ldots,w_{t-1})\). As discussed in Section 1, this captures its intrinsic, irreducible description [22]. By the chain rule [15], the corresponding number of bits assigned to \(w_{t}\) is \(z_{t}=-\log p(w_{t}|w_{[t-1]})\). Unlike in prior works, which rely on simplifications such as by substituting a word with its length [9] or by focusing on the recurrence of a single word [49, 3], we use the LLM to approximate the full joint distribution of language since LLMs are known to produce calibrated probability scores at the token level [33]. We carry out these calculations for prefixes of up to 2048 tokens (\(\approx 8\) pages of text). With a suitable normalization, such as bits-per-byte (BPB), one obtains a standardized description of text, consistent across tokenizers. BPB is widely used as a tokenizer-agnostic metric to compare LM modeling performance, e.g. for The Pile [23].

Besides PaLM2, we also experiment and report on various model sizes of PaLM [12] and decoder-only T5 [55]. Namely, we report results for models: PaLM2 XXS (Gecko), XS (Otter), S (Bison), M, and L (Unicorn); PaLM 8B, 62B, 540B; and decoder-only T5.1.1 at Base (110M), Large (341M), XL (1.2B), and XXL (5B) sizes. For PaLM and PaLM2, we use the checkpoints pretrained in Chowdhery et al. [12] and Anil et al. [6]. All T5.1.1 decoder baselines, on the other hand, are trained with a casual language modeling objective for 262B tokens of C4 [55]. All experiments are executed on Tensor Processing Units (TPUs). More details on how we train T5.1.1 baselines are in Appendix A.

Once \(z_{t}\) is computed for a document, we follow standard definitions in constructing the increment process \((x_{t})_{t\in\mathbb{N}}\) by normalizing \(z_{t}\) to have a zero-mean and unit variance. Intuitively, fractal parameters are intended to measure a fundamental property of the process (e.g. LRD) that should not be affected by scale, hence the normalization. The integral process \((X_{t})_{t\in\mathbb{N}}\) is calculated based on \((x_{t})_{t\in\mathbb{N}}\), as described earlier and depicted in Figure 1 (top). Normalizing bits (to have zero mean and unit variance) models language as a random walk. It is a standard approach used extensively in the literature in various contexts, such as in DNA sequences [52, 57, 48, 35, 59].

Figure 3: Rescaled range \(R(n)/S(n)\) is plotted against the number of normalized bits \(n\). We observe a power law \(R(n)/S(n)\sim n^{\mathrm{H}}\) in all domains. When aggregating all datasets, \(\mathrm{H}=0.70\pm 0.09\).

Figure 2: Peak probability \(p_{e}(\tau)\) is plotted against the granularity level \(\tau\) (see Section 2.2). We observe power laws \(p_{e}(\tau)\sim\tau^{-\mathcal{S}}\), indicating self-similarity, with a median exponent of \(\mathrm{S}=0.59\pm 0.08\).

For analysis, we use The Pile validation split [23], consisting of 22 subdomains such as Wikipedia and GitHub. We restrict analysis to sufficiently-long documents of length \(>4K\) tokens and use the first 2K tokens only, to sidestep potential effects of the finite length of documents and the model context. To mitigate noise, only domains with \(>1K\) documents are compared; we report results for them separately and their median. We use bootstrapping [17] to estimate the error margin.

**Notation.** We write \(f(x)\sim x^{c}\) if \(f(x)=x^{c}L(x)\) for some function \(L\) that satisfies \(L(tx)/L(x)\to 1\) as \(x\to\infty\) for all \(t>0\). Examples of slowly varying functions are constants \(L(x)=c\) and \(L(x)=\log x\). When \(f(x)\sim x^{c}\), we abuse terminology slightly by referring to \(f(x)\) as a power law.

### Self-similarity exponent -- Scale invariance

An integral process is said to be self-similar if it exhibits _statistical_ self-similarity. More precisely, \((X_{t})_{t\in\mathbb{N}}\) is self-similar if \((X_{\tau t})_{t\in\mathbb{N}}\) is distributionally equivalent to \((\tau^{S}X_{t})_{t\in\mathbb{N}}\) for some exponent \(\mathrm{S}\). Thus, scaling of time is equivalent to an appropriate scaling of space. We will refer to \(\tau\) as the _granularity level_ and to the exponent \(\mathrm{S}\) as the self-similarity or Holder exponent [66]. Many time series in nature exhibit self-similar structures, such as human blood pressure and heart rate [27].

One approach for calculating \(\mathrm{S}\) is as follows. Fix \(\epsilon\ll 1\) and denote the \(\tau\)-increments by \((X_{t+\tau}-X_{t})_{t\in\mathbb{N}}\). These would correspond, for instance, to the number of bits used for clauses, sentences, paragraphs and longer texts as \(\tau\) increases. In terms of the increment process \((x_{t})_{t\in\mathbb{N}}\), this corresponds to aggregating increments into "bursts". Let \(p_{\epsilon}(\tau)\) be the probability mass of the event \(\{|X_{t+\tau}-X_{t}|\leq\epsilon\}_{t\in\mathbb{N}}\). Then, \(\mathrm{S}\) can be estimated by fitting a power law relation \(p_{\epsilon}(\tau)\sim\tau^{-S}\)[66]. Generally, \(\mathrm{S}\) is robust to the choice of \(\epsilon\in[10^{-3},10^{-2}]\) as shown in Figure 4 (left) so we fix it to \(\epsilon=5\times 10^{-3}\).

Figure 2 plots the probability \(p_{\epsilon}(\tau)\) against \(\tau\) using PaLM2-L. We indeed observe a power law relation over at least two orders of magnitude; i.e. linear in a log-log scale, with a median self-similarity exponent of \(\mathrm{S}=0.59\pm 0.08\). Section 3 shows that the median \(\mathrm{S}\) is robust to the choice of the LLM.

### Hurst parameter -- Long-range dependence

The Hurst parameter \(\mathrm{H}\in[0,1]\) quantifies the degree of predictability or dependence over time [31]. It is calculated using the so-called rescaled-range (R/S) analysis. Let \((x_{t})_{t\in\mathbb{N}}\) be an increment process. For each \(n\in\mathbb{N}\), write \(y_{t}=x_{t}-\frac{1}{t}\sum_{k=0}^{t}x_{k}\) and \(Y_{t}=\sum_{k=0}^{t}y_{t}\). The range and scale are defined, respectively, as \(R(n)=\max_{t\leq n}Y_{t}-\min_{t\leq n}Y_{t}\) and \(S(n)=\sigma\left(\{x_{k}\}_{k\leq n}\right)\), where \(\sigma\) is the standard deviation. Then, the Hurst parameter \(\mathrm{H}\) is estimated by fitting a power law relation \(R(n)/S(n)\sim n^{\mathrm{H}}\). As stated earlier, for completely random processes, such as a simple Brownian motion, it can be shown that \(\mathrm{H}=1/2\). In addition, \(H>1/2\) implies dependence over time [16, 68, 8].

Writing \(\rho_{n}=\mathbb{E}[(x_{t+n}x_{t}]\) for the autocovariance function of the increment process \((x_{t})_{t\in\mathbb{N}}\), the Hurst parameter satisfies \(\mathrm{H}=1-\beta/2\) when \(\rho_{n}\sim n^{-\beta}\) as \(n\to\infty\)[26, 16]. Since in self-similar processes, \(\mathrm{H}>1/2\) implies long-range dependence (LRD), LRD is equivalent to the condition that the autocovariances are not summable. In terms of the integral process, it can be shown that [58]: \(\lim_{n\to\infty}\frac{\mathrm{Var}(X_{n})}{n}=1+2\sum_{i=1}^{\infty}\rho_{i}\). Hence, if \(\mathrm{H}<1/2\), the auto-covariances are summable and

Figure 4: left: Estimates of the self-similarity exponent \(\mathrm{S}\) are generally robust to the choice of \(\epsilon\). right: The partial auto-correlation function calculated across domains. DM Mathematics has a much shorter dependence compared to the rest of the domains, in agreement with its Hurst parameter.

\(\mathrm{Var}(X_{n})\) grows, at most, linearly fast on \(n\). On the other hand, if the process has LRD, \(\mathrm{Var}(X_{n})\) grows superlinearly on \(n\). In particular, using the Euler-Maclaurin summation formula [7; 2], one obtains \(\mathrm{Var}(X_{n})\sim n^{2H}\) if \(H>1/2\). Figure 3 plots the rescaled range \(R(n)/S(n)\) against \(n\). We observe a power law relation with a median Hurst parameter of \(\mathrm{H}=0.70\pm 0.09\).

### Fractal dimension -- Complexity at all levels

Broadly speaking, the fractal dimension of an object describes its _local_ complexity. For a geometric object \(Z\), such as the Koch curve, let \(\tau\) be a chosen scale (e.g. a short ruler for measuring lengths or a small square for areas). Let \(N(\tau)\) be the minimum number of objects of scale \(\tau\) that cover \(Z\); i.e. contain it entirely. Then, the fractal dimension of \(Z\), also called its Hausdorff dimension, is: \(\mathrm{D}=-\lim_{\tau\to 0}\left\{\frac{\log N(\tau)}{\log\tau}\right\}\)[54]. For example, a line has a fractal dimension \(1\), in agreement with its topological dimension, because \(N(\tau)=C/\tau\) for some constant \(C>0\).

By convention, an object is referred to as "fractal" if \(\mathrm{D}\) is different from its topological dimension. For example, the fractal dimension of the Koch curve is about 1.26 when its topological dimension is 1. Fractals explain some puzzling observations, such as why estimates of the length of the coast of Britain varied significantly from one study to another, because lengths in fractals are scale-sensitive. Mandelbrot estimated the fractal dimension of the coast of Britain to be 1.25 [43].

The definition above for the fractal dimension \(\mathrm{D}\) applies to geometric shapes, but an analogous definition has been introduced for stochastic processes. Let \((x_{t})_{t\in\mathbb{R}}\) be a stationary process with autocovariance \(\rho_{n}\). Then, its fractal dimension \(\mathrm{D}\) is determined according to the local behavior of \(\rho_{n}\) at the vicinity of \(n=0\), by first normalizing \((x_{t})_{t\in\mathbb{R}}\) to have a zero-mean and a unit variance, and modeling \(\rho_{n}\) using a power law \(\rho_{n}\sim 1-n^{\alpha}\) as \(n\to 0^{+}\), for \(\alpha\in(0,2]\). Then, the fractal dimension \(\mathrm{D}\in[1,\,2]\) of \((x_{t})_{t\in\mathbb{R}}\) is defined by \(\mathrm{D}=2-\alpha/2\)[26]. It can be shown that \(\mathrm{D}=2-\mathrm{S}\)[26]. For language, this gives a median fractal dimension of \(\mathrm{D}=1.41\pm 0.08\).

### Joseph effect -- Burstiness

Finally, we examine another related parameter that is commonly studied in self-similar processes. The motivation behind it comes from the fact that in processes with LRD, one often observes _burstiness_ as shown in Figure 1; i.e. clusters over time in which the process fully resides on one side of the mean, before switching to the other. This is quite unlike random noise, for instance, where measurements are evenly distributed on both sides of the mean. The effect is often referred to as the Joseph effect, named after the biblical story of the seven fat years and seven lean years [68; 46; 66].

A common way to quantify the Joseph effect for integral processes \((X_{t})_{t\in\mathbb{N}}\) is as follows [66]. First, let \(\sigma_{\tau}\) be the standard deviation of the \(\tau\)-increments \(X_{t+\tau}-X_{t}\). Then, fit a power law relation \(\sigma_{\tau}\sim\tau^{\mathrm{J}}\). The exponent \(\mathrm{J}\) here is called the Joseph exponent. In an idealized fractional Brownian motion, both \(\mathrm{J}\) and the self-similarity exponent \(\mathrm{S}\) coincide. Figure 5 provides the detailed empirical results. Overall, we find that \(\mathrm{J}=0.49\pm 0.08\).

## 3 Analysis

Comparative Analysis.Table 1 compares fractal parameters across different domains, such as ArXiv, Github and Wikipedia. In general, most domains share similar self-similarity and Hurst exponents with a few exceptions. The first notable exception is DM-Mathematics, which has a Hurst parameter of about 0.5, indicating a lack of LRD. Upon closer inspection, however, a value of \(\mathrm{H}=0.5\)

\begin{table}
\begin{tabular}{c|c c c c c c c c} \hline  & **OpenWeb** & **GitHub** & **FreeLaw** & **PileCC** & **Wiki** & **PubMed** & **Math** & **ArXiv** \\ \hline \hline \(\mathrm{S}\) & \(0.53\pm.05\) & \(0.60\pm.05\) & \(0.61\pm.05\) & \(0.56\pm.03\) & \(0.62\pm.02\) & \(0.60\pm.07\) & \(0.42\pm.03\) & \(0.70\pm.03\) \\ \(\mathrm{H}\) & \(0.68\pm.01\) & \(0.79\pm.01\) & \(0.68\pm.00\) & \(0.70\pm.00\) & \(0.74\pm.01\) & \(0.65\pm.00\) & \(0.50\pm.01\) & \(0.72\pm.01\) \\ \(\mathrm{J}\) & \(0.46\pm.01\) & \(0.49\pm.00\) & \(0.49\pm.00\) & \(0.50\pm.00\) & \(0.52\pm.00\) & \(0.44\pm.00\) & \(0.28\pm.00\) & \(0.49\pm.00\) \\ \hline \end{tabular}
\end{table}
Table 1: A comparison of the fractal parameters across 8 different domains with \(>1000\) documents each in The Pile benchmark (see Section 2.1 for selection criteria). DM-Mathematics is markedly different because each document consists of questions, with no LRD.

[MISSING_PAGE_FAIL:7]

[MISSING_PAGE_FAIL:8]

of the document's length [29]. However, both Zipf's and Heap's laws are invariant to the semantic ordering of text, so they do not capture important aspects, such as long-range dependence (LRD) [49].

In terms of self-similarity in language, the Menzerath-Altmann law stipulates a self-similar behavior in the following sense: when the size of a language construct increases, the size of its constituents decreases, and this happens at all scales [49; 4]. In Ausloos [9], the authors model texts as a time series by replacing a word with its length. After that, they study the fractal behavior of language. However, as mentioned in [22], replacing a word with its length is invalid because it is not translation-independent (i.e. one could map every word to an arbitrary token, including tokens of equal length). In our work, we model language as a series of bits calculated from conditional entropies, reflecting the intrinsic structure of the language itself, inspired by findings in linguistics such as [28; 22; 41]. The existence of self-similarity in language is attributed to its hierarchical nature [68; 3], such as duality of patterning [37].

In Najafi and Darooneh [49], the authors define a fractal dimension for each word. Informally, they examine the recurrence of a single, predetermined word as a binary series, similar to the approach used in Altmann et al. [3]. However, this only applies to individual words and cannot model higher-level clauses. For instance, it does not distinguish between "time" in the phrase "once upon a time" and "time" in "space and time." Kokol and Podgorelec [35] estimate LRD in natural language, and suggest that its LRD is close to that of pure noise! They conjecture this was due to their use of ASCII encoding. In computer languages, they observe LRD and suggest it is because they are formal.

Besides the above concerns in prior studies that examined the self-similar structure in language, another concern is that they sometimes give extremely large values of the fractal dimension, sometimes exceeding 10 [4]! Such values are difficult to interpret because the fractal dimension \(\mathrm{D}\) should fall in \(\mathrm{D}\in[1,2]\) for time series. We do not observe such issues in our analysis. In our case, \(\mathrm{D}=1.41\pm 0.08\).

Limitations and Future Research.Our analysis is currently limited to the English language so it may not apply to other languages that differ significantly. For instance, some languages such as Piraha (spoken in the Amazon) do not have a recursive structure like most languages do [20]. We also do not model the semantic or lexical form of language. While our information-theoretic approach is well-founded and captures the intrinsic complexity of language, it does not account for the semantic nuances that contribute to meaning. Thirdly, self-similarity may explain why parameter sharing, such as in ALBERT [38], can be successful but exploiting self-similarity more directly in LLMs could lead to further optimizations. Exploring these aspects are promising directions for future research.

## 5 Concluding Remarks

In this work, we highlight intriguing insights into the underlying fractal structure of language and how it may be interconnected with the remarkable capabilities of LLMs. Our formalism quantifies properties of language that may have been suspected, but not previously formally shown. In particular, the need in LLMs to balance between short- and long-term contexts is reflected in the self-similar

Figure 7: Downstream metric, indicated by bubble size where larger is better, is plotted vs. the median Hurst and the median BPB for all 12 language models.

structure of language, while long-range dependence is quantifiable using the Hurst parameter. For instance, the absence of LRD in DM-Mathematics is reflected in its Hurst parameter of \(\mathrm{H}\approx 0.5\). Interestingly, the estimated median Hurst value of \(\mathrm{H}=0.70\pm 0.09\) in language reflects an intriguing balance between predictability and noise that is similar to many other phenomena, and combining both H with BPP together yields a stronger predictor of downstream performance. We carry out an extensive comparative analysis across different domains and model architectures, revealing that fractal parameters are generally robust. We hope that future research can further probe into these fractal properties, unearthing deeper understandings of the relation between intelligence and language.

## Acknowledgement

The authors would like to thank Justin Gilmer and Olivier Bousquet for their feedback on earlier drafts of this manuscript, and both Google Deepmind and Google Research teams at large for the insightful discussions and providing a supportive research environment.

## References

* [1] Abry, P., Goncalves, P., and Flandrin, P. (1995). Wavelets, spectrum analysis and 1/f processes. _Wavelets and statistics_, pages 15-29.
* [2] Alabdulmohsin, I. M. (2018). _Summability calculus: A comprehensive theory of fractional finite sums_. Springer.
* [3] Altmann, E. G., Cristadoro, G., and Esposti, M. D. (2012). On the origin of long-range correlations in texts. _Proceedings of the National Academy of Sciences_, 109(29):11582-11587.
* [4] Andres, J. (2009). On de Saussure's principle of linearity and visualization of language structures. _Glottotheory_, 2(2):1-14.
* [5] Anil, R., Borgeaud, S., Wu, Y., Alayrac, J.-B., Yu, J., Soricut, R., Schalkwyk, J., Dai, A. M., Hauth, A., Millican, K., Silver, D., Petrov, S., Johnson, M., Antonoglou, I., Schrittwieser, J., Glaese, A., Chen, J., Priter, E., et al. (2023a). Gemini: A family of highly capable multimodal models. _arXiv:2312.11805v1 [cs.CL]_.
* [6] Anil, R., Dai, A. M., Firat, O., Johnson, M., Lepikhin, D., Passos, A., Shakeri, S., Taropa, E., Bailey, P., Chen, Z., Chu, E., Clark, J. H., Shafey, L. E., Huang, Y., Meier-Hellstern, K., Mishra, G., Moreira, E., Omernick, M., Robinson, K., Ruder, S., Tay, Y., Xiao, K., Xu, Y., Zhang, Y., Abrego, G. H., Ahn, J., Austin, J., Barham, P., Botha, J., Bradbury, J., Brahma, S., Brooks, K., Catasta, M., Cheng, Y., Cherry, C., Choquette-Choo, A., Chowdhary, A., Crepy, C., Dave, S., Dehghani, M., Dev, S., Devlin, J., Diaz, M., Wu, N., Dyer, E., Feinberg, V., Feng, F., Fienber, V., Freitag, M., Garcia, X., Gehrmann, S., Gonzalez, L., Gur-Ari, G., Hand, S., Hashemi, H., Hou, L., Howland, J., Hu, A., Hui, J., Hurwitz, J., Isard, M., Ittycheriah, A., Jagielski, M., Jia, W., Kenealy, K., Krikun, M., Kudugunta, S., Lan, C., Lee, K., Lee, B., Li, E., Li, M., Li, W., Li, Y., Li, J., Lim, H., Lin, H., Liu, Z., Liu, F., Maggioni, M., Mahendru, A., Maynez, J., Misra, V., Moussalem, M., Nado, Z., Nham, J., Ni, E., Nystrom, A., Parrish, A., Pellat, M., Polacek, M., Polozov, A., Pope, R., Qiao, S., Reif, E., Richter, B., Riley, P., Ros, A. C., Roy, A., Saeta, B., Samuel, R., Shelby, R., Slone, A., Smilkov, D., So, D. R., Sohn, D., Tokumine, S., Valter, D., Vasudevan, V., Vodrahalli, K., Wang, X., Wang, P., Wang, Z., Wang, T., Wieting, J., Wu, Y., Xu, K., Xu, Y., Xue, L., Yin, P., Yu, J., Zhang, Q., Zheng, S., Zheng, C., Zhou, W., Zhou, D., Petrov, S., and Wu, Y. (2023b). PaLM 2 technical report. _arXiv:2305.10403v3 [cs.CL]_.
* [7] Apostol, T. M. (1999). An elementary view of Euler's summation formula. _The American Mathematical Monthly_, 106(5):409-418.
* [8] Aref, S. (1998). Hurst phenomenon and fractal dimensions in long-term yield data. In _Conference on Applied Statistics in Agriculture_.
* [9] Ausloos, M. (2012). Generalized Hurst exponent and multifractal function of original and translated texts mapped into frequency and length time series. _Physical Review E_, 86(3):031108.

* [10] Bradbury, J., Frostig, R., Hawkins, P., Johnson, M. J., Leary, C., Maclaurin, D., Necula, G., Paszke, A., VanderPlas, J., Wanderman-Milne, S., and Zhang, Q. (2018). JAX: composable transformations of Python+NumPy programs.
* [11] Bubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., Horvitz, E., Kamar, E., Lee, P., Lee, Y. T., Li, Y., Lundberg, S., Nori, H., Palangi, H., Ribeiro, M. T., and Zhang, Y. (2023). Sparks of artificial general intelligence: Early experiments with GPT-4.
* [12] Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., et al. (2022). PaLM: Scaling language modeling with pathways. _arXiv preprint arXiv:2204.02311_.
* [13] Chung, H. W., Hou, Le and, L. S., Zoph, B., Tay, Y., Fedus, W., and et al. (2022). Scaling instruction-finetuned language models. _arXiv:2210.11416v5 [cs.LG]_.
* [14] Cobbe, K., Kosaraju, V., Bavarian, M., Hilton, J., Nakano, R., Hesse, C., and Schulman, J. (2021). Training verifiers to solve math word problems. _arXiv:2110.14168v2 [cs.LG]_.
* [15] Cover, T. M. (1999). _Elements of information theory_. John Wiley & Sons.
* [16] Crovella, M. E. and Bestavros, A. (1995). Explaining world wide web traffic self-similarity. Technical report, Boston University Computer Science Department.
* [17] Efron, B. and Tibshirani, R. J. (1994). _An introduction to the bootstrap_. CRC press.
* [18] Eftekhari, A. (2006). Fractal geometry of texts: An initial application to the works of Shakespeare. _Journal of Quantitative Linguistics_, 13(2-3):177-193.
* [19] Embrechts, P. and Maejima, M. (2000). An introduction to the theory of self-similar stochastic processes. _International journal of modern physics B_, 14(12n13):1399-1420.
* [20] Everett, D. (2005). Cultural constraints on grammar and cognition in pirha: Another look at the design features of human language. _Current anthropology_, 46(4):621-646.

* [22] Futrell, R. and Hahn, M. (2022). Information theory as a bridge between language function and language form. _Frontiers in Communication_, 7:657725.
* [23] Gao, L., Biderman, S., Black, S., Golding, L., Hoppe, T., Foster, C., Phang, J., He, H., Thite, A., Nabeshima, N., Presser, S., and Leahy, C. (2020). The Pile: An 800GB dataset of diverse text for language modeling. _arXiv:2101.00027v1 [cs.CL]_.
* [24] Geweke, J. and Porter-Hudak, S. (1983). The estimation and application of long memory time series models. _Journal of time series analysis_, 4(4):221-238.
* [25] Gibson, E., Futrell, R., Piantadosi, S. P., Dautriche, I., Mahowald, K., Bergen, L., and Levy, R. (2019). How efficiency shapes human language. _Trends in cognitive sciences_, 23(5):389-407.
* [26] Gneiting, T. and Schlather, M. (2004). Stochastic models that separate fractal dimension and the Hurst effect. _SIAM Review_, 46(2):269-282.
* [27] Goldberger, A. L., Amaral, L. A., Hausdorff, J. M., Ivanov, P. C., Peng, C.-K., and Stanley, H. E. (2002). Fractal dynamics in physiology: alterations with disease and aging. _Proceedings of the national academy of sciences_, 99(suppl_1):2466-2472.
* [28] Hale, J. (2001). A probabilistic earley parser as a psycholinguistic model. In _Second meeting of the north american chapter of the association for computational linguistics_.
* [29] Heaps, H. S. (1978). _Information retrieval, computational and theoretical aspects_. Academic Press.
* [30] Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., and Steinhardt, J. (2020). Measuring massive multitask language understanding. _arXiv preprint arXiv:2009.03300_.

* [31] Hurst, H. E. (1951). Long-term storage capacity of reservoirs. _Transactions of the American society of civil engineers_, 116(1):770-799.
* [32] Jouppi, N. P., Yoon, D. H., Kurian, G., Li, S., Patil, N., Laudon, J., Young, C., and Patterson, D. (2020). A domain-specific supercomputer for training deep neural networks. _Communications of the ACM_, 63(7):67-78.
* [33] Kadavath, S., Conerly, T., Askell, A., Henighan, T., Drain, D., Perez, E., Schiefer, N., Hatfield-Dodds, Z., DasSarma, N., Tran-Johnson, E., et al. (2022). Language models (mostly) know what they know. _arXiv preprint arXiv:2207.05221_.
* [34] Kidd, C. and Hayden, B. Y. (2015). The psychology and neuroscience of curiosity. _Neuron_, 88(3):449-460.
* [35] Kokol, P. and Podgorelec, V. (2000). Complexity and human writings. _Complexity_, 7:1-6.
* [36] Kolmogorov, A. N. (1940). Wienersche spiralen und einige andere interessante kurven in hilbertscen raum, cr (doklady). _Acad. Sci. URSS (NS)_, 26:115-118.
* [37] Ladd, D. R. (2012). What is duality of patterning, anyway? _Language and Cognition_, 4(4):261-273.
* [38] Lan, Z., Chen, M., Goodman, S., Gimpel, K., Sharma, P., and Soricut, R. (2019). ALBERT: A lite BERT for self-supervised learning of language representations. _arXiv preprint arXiv:1909.11942_.
* [39] Leland, W. E., Taqqu, M. S., Willinger, W., and Wilson, D. V. (1994). On the self-similar nature of Ethernet traffic. _IEEE/ACM Transactions on networking_, 2(1):1-15.
* [40] Leland, W. E. and Wilson, D. V. (1991). High time-resolution measurement and analysis of LAN traffic: Implications for LAN interconnection. In _IEEE INFOCOM_.
* [41] Levy, R. (2008). Expectation-based syntactic comprehension. _Cognition_, 106(3):1126-1177.
* [42] Longpre, S., Hou, L., Vu, T., Webson, A., Chung, H. W., Tay, Y., Zhou, D., Le, Q. V., Zoph, B., Wei, J., and Roberts, A. (2023). The flan collection: designing data and methods for effective instruction tuning. In _Proceedings of the 40th International Conference on Machine Learning_, ICML'23. JMLR.org.
* [43] Mandelbrot, B. (1967). How long is the coast of Britain? Statistical self-similarity and fractional dimension. _science_, 156(3775):636-638.
* [44] Mandelbrot, B. (2002). _Gaussian self-affinity and fractals: globality, the earth, 1/f noise, and R/S_. Springer Science and Business Media.
* [45] Mandelbrot, B. B. (1982). _The fractal geometry of nature_. WH freeman New York.
* [46] Mandelbrot, B. B. and Wallis, J. R. (1968). Noah, Joseph, and operational hydrology. _Water resources research_, 4(5):909-918.
* [47] Mollica, F., Bacon, G., Zaslavsky, N., Xu, Y., Regier, T., and Kemp, C. (2021). The forms and meanings of grammatical markers support efficient communication. _Proceedings of the National Academy of Sciences_, 118(49):e2025993118.
* [48] Montemurro, M. A. and Pury, P. A. (2002). Long-range fractal correlations in literary corpora. _Fractals_, 10(04):451-461.
* [49] Najafi, E. and Darooneh, A. H. (2015). The fractal patterns of words in a text: a method for automatic keyword extraction. _PloS one_, 10(6):e0130617.
* [50] OpenAI (2023). GPT-4 technical report. _arXiv:2303.08774v4 [cs.CL]_.

* [51] Paxson, V. and Floyd, S. (1995). Wide area traffic: the failure of Poisson modeling. _IEEE/ACM Transactions on networking_, 3(3):226-244.
* [52] Peng, C.-K., Buldyrev, S. V., Goldberger, A. L., Havlin, S., Sciortino, F., Simons, M., and Stanley, H. E. (1992). Long-range correlations in nucleotide sequences. _Nature_, 356(6365):168-170.
* [53] Perfors, A., Tenenbaum, J., Gibson, E., and Regier, T. (2010). How recursive is language? a bayesian exploration. _Recursion and human language_, pages 159-175.
* [54] Pilgrim, I. and Taylor, R. P. (2018). Fractal analysis of time-series data sets: Methods and challenges. In Ouadfeul, S.-A., editor, _Fractal Analysis_, chapter 2. IntechOpen, Rijeka.
* [55] Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P. J. (2019). Exploring the limits of transfer learning with a unified text-to-text transformer. _arXiv:1910.10683v4 [cs.LG]_.
* [56] Roberts, A., Chung, H. W., Levskaya, A., Mishra, G., Bradbury, J., Andor, D., Narang, S., Lester, B., Gaffney, C., Mohiuddin, A., Hawthorne, C., Lewkowycz, A., Salcianu, A., van Zee, M., Austin, J., Goodman, S., Soares, L. B., Hu, H., Tsvyshchenko, S., Chowdhery, A., Bastings, J., Bulian, J., Garcia, X., Ni, J., Chen, A., Kenealy, K., Clark, J. H., Lee, S., Garrette, D., Lee-Thorp, J., Raffel, C., Shazeer, N., Ritter, M., Bosma, M., Passos, A., Maitin-Shepard, J., Fiedel, N., Omernick, M., Saeta, B., Sepassi, R., Spiridonov, A., Newlan, J., and Gesmundo, A. (2022). Scaling up models and data with t5x and seqio.
* [57] Roche, S., Bicout, D., Macia, E., and Kats, E. (2003). Long range correlations in DNA: scaling properties and charge transfer efficiency. _Physical review letters_, 91(22):228101.
* [58] Samorodnitsky, G. (2006). Long memory and self-similar processes. In _Annales de la Faculte des sciences de Toulouse: Mathematiques_, volume 15, pages 107-123.
* [59] Schenkel, A., Zhang, J., and Zhang, Y.-C. (1993). Long range correlation in human writings. _Fractals_, 1(01):47-57.
* [60] Shannon, C. E. (1951). Prediction and entropy of printed English. _Bell system technical journal_, 30(1):50-64.
* [61] Shazeer, N. and Stern, M. (2018). Adafactor: Adaptive learning rates with sublinear memory cost. In _International Conference on Machine Learning_, pages 4596-4604. PMLR.
* [62] Soboleva, D., Al-Khateeb, F., Myers, R., Steeves, J. R., Hestness, J., and Dey, N. (2023). SlimPajama: A 627B token cleaned and deduplicated version of RedPajama.
* [63] Srivastava, A., Rastogi, A., Rao, A., Shoeb, A. A. M., Abid, A., Fisch, A., Brown, A. R., Santoro, A., Gupta, A., Garriga-Alonso, A., et al. (2022). Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. _arXiv preprint arXiv:2206.04615_.
* [64] Suzgun, M., Scales, N., Scharli, N., Gehrmann, S., Tay, Y., Chung, H. W., Chowdhery, A., Le, Q. V., Chi, E. H., Zhou, D., and Wei, J. (2022). Challenging BIG-Bench tasks and whether chain-of-thought can solve them. _arXiv:2210.09261v1 [cs.CL]_.
* [65] Team, G., Mesnard, T., Hardin, C., Dadashi, R., Bhupatiraju, S., Pathak, S., Sifre, L., Riviere, M., Kale, M. S., Love, J., et al. (2024). Gemma: Open models based on gemini research and technology. _arXiv preprint arXiv:2403.08295_.
* [66] Watkins, N. (2019). Mandelbrot's stochastic time series models. _Earth and Space Science_, 6(11):2044-2056.
* [67] Wikimedia (2023). Downloads.
* [68] Willinger, W., Taqqu, M. S., Leland, W. E., and Wilson, D. V. (1995). Self-similarity in high-speed packet traffic: analysis and modeling of Ethernet traffic measurements. _Statistical science_, pages 67-85.
* [69] Willinger, W., Taqqu, M. S., Sherman, R., and Wilson, D. V. (1997). Self-similarity through high-variability: statistical analysis of Ethernet LAN traffic at the source level. _IEEE/ACM Transactions on networking_, 5(1):71-86.

Experiment Details

All of our experiments are conducted in JAX/Flax [10] using the open source T5X framework [56].

T5 baselines in Table 2 and 3 are pretrained from scratch using the open source T5.1.1 decoder-only architecture from the T5X library.3. We pretrain using a causal language modeling objective over the C4 corpus with the default T5 vocabulary as per Raffel et al. [55]. Training is done for 500k steps with a sequence length of 1024 and batch size of 512, resulting in a total of 262B tokens seen during pretraining. We optimize our model with the Adafactor [61] optimizer with an inverse square root learning rate schedule, 1k warmup steps, and an initial learning rate of 1e-2. Models are trained using 256 TPUv5e chips [32].

Footnote 3: [https://github.com/google-research/tsx/tree/main/t5x/examples/decoder_only/models](https://github.com/google-research/tsx/tree/main/t5x/examples/decoder_only/models)

T5 context length ablation experiments in Table 3 are trained with the same pretraining objective but over the SlimPajama-627B corpus [62] and using a modified version of the T5 vocabulary that preserves whitespace and introduces byte-fallback for out of vocabulary tokens. This is similar to Chowdhery et al. [12], but preserving the original T5 vocabulary. Models with sequence lengths 2048, 4096, 8192 are trained with batch sizes of 512, 256, and 128 respectively to preserve the number of tokens seen per batch and overall training steps. We train all models for 100k steps, using the same learning rate schedule described above. Hence, all models observe 100B tokens.

[MISSING_PAGE_EMPTY:15]

[MISSING_PAGE_FAIL:16]

[MISSING_PAGE_FAIL:17]

(wikipedia/20230601.en) dataset [67]. We split each document of length >4K words along _word boundaries_ and constrain the context length during inference in PaLM-8B to \(n\) words, for \(n\in\{1,16,32,64,128,256,512,1024,2048\}\). Hence, the language model now resembles an \(n\)-gram model. We calculate probability scores and calculate fractal parameters accordingly. Figure 10 shows how both the self-similarity exponent S and the Hurst parameter H change as a function of \(n\).

We observe that H increases monotonically with context length as expected, since it implies more predictability. However, even in a 1-gram model, H can be larger than 1/2 because the words themselves are not independent of each other, so the sequence of probability scores can still contain dependence over time in a 1-gram model.

Figure 8: Here, we follow a similar setup to Figure 2, but using the publicly released Gemma-2B checkpoint [65], where the \(y\)-axis is the peak probability. We continue to observe linear fits in a log-log scale over at least two orders of magnitude, thus confirming a self-similar structure.

Figure 9: Here, we follow a similar setup to Figure 3, but using the publicly released Gemma-2B checkpoint [65], where the \(y\)-axis is the rescaled-range (R/S). We continue to observe linear fits in a log-log scale over at least two orders of magnitude.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: See Section 4 Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.

\begin{table}
\begin{tabular}{c c c c c c c c} \hline \hline OpenWebText2 & Github & FreeLaw & File-CC & Wikipedia & PubMed & Mathematics & ArXiv \\ \hline \multicolumn{8}{c}{S} \\ \hline \(0.55\pm 0.02\) & \(0.63\pm 0.01\) & \(0.60\pm 0.02\) & \(0.58\pm 0.02\) & \(0.57\pm 0.02\) & \(0.57\pm 0.02\) & \(0.50\pm 0.02\) & \(0.61\pm 0.02\) \\ \hline \multicolumn{8}{c}{H} \\ \hline \(0.65\pm 0.01\) & \(0.83\pm 0.01\) & \(0.67\pm 0.01\) & \(0.68\pm 0.01\) & \(0.65\pm 0.01\) & \(0.64\pm 0.01\) & \(0.58\pm 0.01\) & \(0.69\pm 0.01\) \\ \hline \hline \end{tabular}
\end{table}
Table 10: Self-similarity exponent (S) and the Hurst parameter (H) when using Gemma-2B. These values compare well to the ones obtained using the other models.

Figure 10: S and H plotted for different constructions of bits, as we vary the prefix length during inference.

* The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.
* The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.
* The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.
* If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.
* While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [NA] Guidelines: We follow well-established definitions throughout our analysis. * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.

* While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [No] Justification: We only release a portion of the code that can be used to calculate fractal parameters. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines ([https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy)) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines ([https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy)) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: See Section 2.1 and Appendix A. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. ** The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: We use the bootstrap method to estimate error margins and report those in the paper. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors). * It should be clear whether the error bar is the standard deviation or the standard error of the mean. * It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified. * For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). * If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: See Appendix A. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics [https://neurips.cc/public/EthicsGuidelines?](https://neurips.cc/public/EthicsGuidelines?) Answer: [Yes] Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.

* If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.
* The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: Our work studies the fractal structure of language. We do not foresee any potential negative societal impact this work. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. * If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected?Answer: [Yes]

Justification: We cite the original creators/owners of all datasets and model checkpoints that we use in our analysis.

Guidelines:

* The answer NA means that the paper does not use existing assets.
* The authors should cite the original paper that produced the code package or dataset.
* The authors should state which version of the asset is used and, if possible, include a URL.
* The name of the license (e.g., CC-BY 4.0) should be included for each asset.
* For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.
* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [Yes] Guidelines: * The answer NA means that the paper does not release new assets. * Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. * The paper should discuss whether and how consent was obtained from people whose asset is used. * At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. * According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained?Answer: [NA]

Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.