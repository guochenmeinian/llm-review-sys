# Perturbation Towards Easy Samples Improves Targeted Adversarial Transferability

Junqi Gao\({}^{*,1}\), Biqing Qi\({}^{*,2,3,4}\), Yao Li\({}^{\dagger,1}\), Zhichang Guo\({}^{1}\), Dong Li\({}^{1}\), Yuming Xing\({}^{1}\), Dazhi Zhang\({}^{1}\)

\({}^{1}\)School of Mathematics, Harbin Institute of Technology

\({}^{2}\)Department of Control Science and Engineering, Harbin Institute of Technology

\({}^{3}\)C\({}^{3}\)I, Department of Electronic Engineering, Tsinghua University

\({}^{4}\)Frontis.AI

\(*\) Equal contribution, \(\dagger\) Corresponding author.

{gjunqi97, qibiqing7, mathgzc, arvinlee826}@gmail.com

{yaoli0508, xyuming, zhangdazhi}@hit.edu.cn

###### Abstract

The transferability of adversarial perturbations provides an effective shortcut for black-box attacks. Targeted perturbations have greater practicality but are more difficult to transfer between models. In this paper, we experimentally and theoretically demonstrated that neural networks trained on the same dataset have more consistent performance in _High-Sample-Density-Regions_ (HSDR) of each class instead of low sample density regions. Therefore, in the target setting, adding perturbations towards HSDR of the target class is more effective in improving transferability. However, density estimation is challenging in high-dimensional scenarios. Further theoretical and experimental verification demonstrates that easy samples with low loss are more likely to be located in HSDR. Perturbations towards such easy samples in the target class can avoid density estimation for HSDR location. Based on the above facts, we verified that adding perturbations to easy samples in the target class improves targeted adversarial transferability of existing attack methods. A generative targeted attack strategy named Easy Sample Matching Attack (**ESMA**) is proposed, which has a higher success rate for targeted attacks and outperforms the SOTA generative method. Moreover, ESMA requires only \(5\%\) of the storage space and much less computation time comparing to the current SOTA, as ESMA attacks all classes with only one model instead of seperate models for each class. Our code is available at [https://github.com/gjq100/ESMA](https://github.com/gjq100/ESMA)

## 1 Introduction

Deep learning models exhibits substantial computational capacity in many downstream tasks, but are vulnerable to adversarial attacks [1, 2]. Such attacks tend to be transferable [3, 4] as well as real-world achievable [5], which makes it implementable in black-box scenarios. Targeted attacks are known to be more difficult to transfer [4, 6] compared with non-targeted attacks.

Intuitively, directions and transferability of adversarial attacks are closely related, but their relationship is rarely discussed. [7] found that samples in low density regions of ground truth distribution are more susceptible to adversarial attacks. They also verified that adversarial perturbations that aligned with the low density direction of ground truth distribution can lead to better transferability. For targeted attack scenarios, the direction that can bring more transferability has not been fully researched yet is not clear.

Findings and arguments.In non-targeted scenarios, directing towards low-density regions of the ground-truth distribution can improve adversarial transferability [7]. However, this approach is not direct enough for targeted attacks. As shown in Figure 1, perturbations pointing at _High-Sample-Density-Regions_ (_HSDR_) of the target domain are more effective than that pointing at low-density regions of the ground-truth distribution, it perturbates samples more directly to the target discrimination region. Moreover, we demonstrate and theoretically prove that neural networks tend to have more consistent outputs in the HSDR of each class, which means that perturbations pointing to the HSDR of the target class are also transferable between different models. However, density estimation for samples in high dimension is challenging. Fortunately, by the definitions of hard samples and easy samples in [8], we found a fact that helps, in each category, easy samples with smaller losses are more likely to locate in HSDR. We provide theoretical and experimental assurance for this fact. Based on this fact, we can directly perturbate towards such easy samples of the target domain to improve transferability without density estimation.

Related works.Adversarial attacks can be divided into white-box attacks and black-box attacks. In the white-box setting, attackers have access to the model's structure and parameters, while in the black-box setting, they have no such information but only access to the input and output of the model. This is typically the scenario encountered in real-world situations. Black-box attacks include query-based attacks [9; 10; 11] and transfer-based attacks [12; 13; 14]. Conducting too many queries is impractical in real-world applications. In contrast, transfer-based attacks are more feasible as they do not require queries. Transfer-based attacks often require the use of a white-box surrogate model to produce adversarial perturbations. In terms of the way adversarial perturbations are generated, there are two approaches: iterative instance-specific methods and generative methods. Iterative instance-specific methods utilize model gradients to iteratively add perturbations to specified samples (e.g., FGSM [3], C&W [5], PGD [15]). To enhance the transferability of adversarial samples, subsequent work combines these methods with various techniques, such as introducing momentum [12; 13] and considering input transformations [13; 14; 16; 17] during iterations, training auxiliary classifiers [18; 19], or substituting different loss functions [20; 21; 22]. However, instance-specific methods are primarily designed for non-targeted scenarios, often lacking effectiveness in targeted settings. Although relatively good results have been achieved for targeted attacks [20; 21; 23], instance-specific methods still require iteratively creating perturbations for each specified sample, while generators trained for generating adversarial perturbations can be generalized on more samples after training [24; 25; 26; 27].

The leading perturbation generative method currently is TTP [24], which employs a target-specific GAN to align clean and augmented data from the source domain with the target domain data. However, TTP necessitate training a dedicated generator for each class. This significantly increases storage requirements and training time. In our work, we design a generator for simultaneous attacks on all target classes, which uses class embedding information for each target class. To construct these embeddings, we adopt techniques similar to SNE [28] to align the surrogate model's output logits for target classes with the generator's embeddings. This enables latent features learned by the surrogate model to guide the construction of well-structured class embeddings. Building on our findings, we train a multi-class perturbation generator to simultaneously perturb the source domain samples towards easy samples with low loss of each target class. Experiments on the ImageNet dataset shown that our method can obtain a better target transfer success rate than TTP, while requiring much less storage. Our method also has certain advantages in training time.

Therefore, our contribution can be summarized as follows:

* We found that deep learning models have more consistent outputs in HSDR of each class, as demonstrated theoretically and through experiments (Section 2.1). This implies that adding

Figure 1: A schematic example of our motivation, plotting the probability density (darker the color represents larger the density) and samples for three populations (orange, cyan, and green). The black line indicates the Bayesian discriminant boundary.

adversarial perturbations pointing to the HSDR of the target class results in better targeted adversarial transferability.
* We experimentally and theoretically verified that easy samples with low loss in early-stopping models are likely to be located in HSDR, which allows us to directly add perturbations pointing to such samples of the target class to improve targeted adversarial transferability (Section 2.2). This avoids density estimation of high-dimensional samples, which is challenging and computationally expensive.
* We introduced the Easy Sample Matching Attack (ESMA) (Section 3). ESMA achieves a higher targeted transfer success rate compared to SOTA generative attacks TTP. Furthermore, it only needs one model to perform attacks for all target classes (Section 4), which requires much less storage space than TTP (only about 1/20 of the storage space in 10 targets case), and requires less training time.

Our findings and conclusions can not only provide guidance for target transfer attacks, but more importantly, they reveal the consistency of deep learning models in the HSDR, and the correlation between sample difficulty and local sample density. Not only that, the design of our multi-target perturbation generative model can provide a new reference for subsequent related research.

## 2 Main conclusions

In this section, we combine illustrative experiments and theoretical proofs to illustrate our two conclusions in turn, and we use the following notations and definitions. \(\mathcal{Z}=\mathcal{X}\times\mathcal{Y}\in\mathbb{R}^{d}\times\mathbb{R}\) is the sample space. The i.i.d. dataset \(S=\left\{x_{i},y_{i}\right\}_{i=1}^{n}\) consists of \(n\) sample pairs \((x_{i},y_{i}),1\leq i\leq n\). Given \(y\), the conditional distribution of \(x\) is \(\mathcal{D}_{x|y}\). Feature mapping \(f:\mathcal{X}\rightarrow\mathbb{R}^{K}\), where \(K\) is the number of class, the class of feature mapping \(f\in\mathcal{F}\). Specifically, the parametrized class \(\mathcal{F}_{\mathbf{w}}:=\left\{f_{\mathbf{w}}:\mathcal{X}\rightarrow\mathbb{R}^{K},\mathbf{w}\in\mathcal{W}\right\}\), where \(\mathcal{W}\) is the parameter space. Define \(\mathcal{F}_{\mathbf{w}}^{\mathcal{S}}:=\left\{f_{\mathbf{w}}^{\mathcal{S}}=\mathcal{S }\circ f_{\mathbf{w}}:f_{\mathbf{w}}\in\mathcal{F}_{\mathbf{w}},\mathcal{S}\circ f_{\mathbf{w }}(x)=\mathcal{S}(f_{\mathbf{w}}(x))\right\}\), \(\mathcal{S}\) denotes Softmax-transformation. The Softmax-Cross-Entropy loss is denoted as \(\ell_{sce}(\cdot,\cdot):\mathbb{R}^{K}\times\mathbb{R}\rightarrow\mathbb{R}\). Let \(S_{j}:=\left\{(x,y)\in S:y=j\right\}\), \(\mathcal{I}_{j}:=\left\{i:(x_{i},y_{i})\in S^{j}\right\}\), \(\mathcal{C}_{j}:=\left\{x\in\mathcal{X}:(x,y)\in\mathcal{Z},y=j\right\}\).

**Definition 1** (\((j,x_{0},r)\)-Local sample density): _Given a class \(j\in[K]\), \((x_{0},y_{0})\in S_{j}\), the \((j,x_{0},r)\)-Local sample density:_

\[\rho_{(j,x_{0},r)}=\frac{\sum_{i\in\mathcal{I}_{j}}\mathbbm{1}\left(x_{i}\in \mathcal{B}(x_{0},r)\right)}{\mathrm{vol}\mathcal{B}(x_{0},r)}\]

_where \(\mathcal{B}(x_{0},r):=\left\{x\in\mathbb{R}^{d}:\|x-x_{0}\|\leq r\right\}\), \(\mathrm{vol}\mathcal{B}(x_{0},r)\) denotes the volume of \(\mathcal{B}(x_{0},r)\)._

Now we use the notation \(\mathcal{I}_{(j,x_{0},r)}=\left\{i:(x_{i},y_{i})\in S_{j},x_{i}\in\mathcal{B} (x_{0},r),(x_{0},y_{0})\in S_{j}\right\}\), \(\mathcal{C}_{(j,x_{0},r)}=\left\{x:x\in\mathcal{C}_{j},x_{i}\in\mathcal{B}(x_ {0},r),(x_{0},y_{0})\in S_{j}\right\}\). For simplicity, we denote \(\ell_{sce}(f_{\mathbf{w}}(x),y)\) as \(\ell(\mathbf{w},x)\) and define the local empirical risk \(R_{(j,x_{0},r)}(\mathbf{w})=\frac{1}{\left|\mathcal{I}_{(j,x_{0},r)}\right|}\sum_{ i\in\mathcal{I}_{(j,x_{0},r)}}\ell(\mathbf{w},x_{i})\).

### The Output Consistency of Different Deep Learning Models in HSDR

We conduct an experiment to explain why samples in low-density regions of ground-truth distribution are vulnerable to attacks, and verify the consistency of the output of the deep learning model in HSDR. A dataset consist of \(200\) samples is constructed by sampling from two \(2\)-d Gaussian distributions with equal probability, which is then used to train a neural network for classification. Subsequently, we plot the discriminant region of the Bayes' criterion (which has the minimum error rate) for the known ground truth prior distribution and compared it with the discriminant region of the trained classifier. In addition, we train two other neural networks with different structures and parameter quantities, and plot the output differences of the three neural networks (Figure 2). The discriminant region in Figure 2(a) can reach the Bayesian error rate. The intersection of the two population distributions in the middle of the probability density curve (as shown in Figure 2(b)) belongs to the low-density region of the ground-truth distribution and also to the misclassified region. In such a region, even with minimal expected error, the Bayesian discriminant criterion will classify samples with relatively small probability density of a single population into another class. These samples can be thought of as "outliers". The trained NN classifier discriminates samples into their original categories, causing a difference in decision boundaries from the Bayesian prior classifier and creating small pits as shown in Figure 2(a). Most of the samples around the pit (Figure 2(c)) belong to another class due to its lower population density compared to the other class. Hence, perturbing the samples from this pit (i.e. outliers) towards the discriminant region of the other class becomes easier. If other trained neural networks can accurately classify such outliers, they will also generate similar pits. By adding perturbations pointing these pits to samples from another class, they will be perturbed into such pits, enabling the transfer of adversarial samples between different classifiers, which explained the findings of [7].

However, as we stated in Figure 1, perturbations towards the low-density regions of the ground-truth distribution are not direct enough for targeted attacks, while perturbations towards the HSDR of the target class are more direct. Combining this with Figure 2(d), we observe that different classifiers have more consistent outputs in the HSDR. With Theorem 1, we theoretically verified this, which also implies that perturbing samples to the HSDR of the target class leads to better targeted adversarial transferability.

**Theorem 1** (Local output consistency): _For a target class \(j\in[K]\), and two different parametrized class \(\mathcal{F}_{\boldsymbol{w}_{1}}:=\{f_{\boldsymbol{w}_{1}}\!:\!\boldsymbol{w}_ {1}\!\in\!\mathcal{W}_{1}\}\), \(\mathcal{F}_{\boldsymbol{w}_{2}}:=\{f_{\boldsymbol{w}_{2}}\!:\!\boldsymbol{w} _{2}\!\in\!\mathcal{W}_{2}\}\), assume that \(\frac{1}{\left|\mathcal{I}_{(j,x_{0},r)}\right|}\left|\sum_{i\in\mathcal{I}_{(j,x_{0},r)}}\left(f_{\boldsymbol{w}_{1}}^{\mathcal{S}_{k}}(x_{i})-f_{ \boldsymbol{w}_{2}}^{\mathcal{S}_{k}}(x_{i})\right)\right|\leq\gamma\), then for any sample \((x_{0},y_{0})\in S_{j}\), in the neighborhood \(\mathcal{B}(x_{0},r)\), with probability at least \(1-\delta\), the following holds:_

\[\left\|\mathbb{E}_{x\sim\mathcal{D}_{x|y}}\left[f_{\boldsymbol{w} _{1}}^{\mathcal{S}}(x)-f_{\boldsymbol{w}_{2}}^{\mathcal{S}}(x)\mid x\in \mathcal{C}_{(j,x_{0},r)}\right]\right\|_{\infty}\] \[\leq\mathcal{O}\left(\sqrt{\frac{Kd^{d/2}}{\rho_{(j,x_{0},r)}2^{d} r^{d}}}\log^{2}\left(r^{d}\sqrt{\rho_{(j,x_{0},r)}}\right)+\sqrt{\frac{d^{d/2} \log(2K/\delta)}{\rho_{(j,x_{0},r)}2^{d+1}r^{d}}}\right)+\gamma.\]

Remark.Theorem 1 suggests that different models have a more consistent output near the samples in HSDR, specifically, the difference between the outputs has a bound of order \(\tilde{O}\left(\sqrt{\frac{Kd^{d/2}}{\rho_{(j,x_{0},r)}2^{d}r^{d}}}\right)\). When the number of classes and dimensions are fixed, a larger sample density results in more consistent performance, a weaker consistency within smaller neighborhoods. Note that this local consistency is weakened as the dimension increases, but the relative output consistency between HSDR and LSDR does not change.

However, a very practical problem is that sample points in high-dimensional space tend to be very discrete due to the _curse of dimentionality_[29], which makes it difficult to find a suitable local neighborhood size to calculate the local density of samples, moreover, in the case of large datasets, calculating local density can be computationally expensive. But the conclusion of the next section can help us find the sample located in the HSDR using early-stopping models without directly calculating the local density of the sample.

### Correlation between Local Sample Density and Sample Difficulty

In this section we illustrate the correlation between sample density and sample difficulty. Hard samples have attracted much attention in various tasks because of their significance for training

Figure 2: (a): Bayesian discriminant region, darker the color indicate higher the confidence probability. (b): Classifier discriminant region, the probability density curves of the two population distributions are plotted, the white part represents the low-density region of ground truth joint distribution, and we boxed out the small pits in the Bayesian misclassified region. (c): Classifier discriminant region with samples. We boxed an outlier. (d): Output differences between three different classifiers, darker purple indicates greater difference in output between different classifiers

convergence and model generalization [8, 30, 31, 32]. [8] proposed that for the convergent model, the difficulty of the sample can be measured by the loss gradient norm of the sample, easy samples has a relatively small loss gradient norm, while the loss gradient norm of difficult samples is relatively large, especially, those with too large gradient norm may be outliers.

We use the following theoretical analysis to illustrate that for a trained classifier, the samples in the HSDR tend to have a smaller local empirical risk. At the same time, smaller loss gradient norms ensure that losses are more consistent in small neighborhoods, which implies those samples with both smaller loss and loss gradient norms guarantee less local empirical risk in the neighborhood where the sample is located. To illustrate the following conclusions, we make several mild assumptions:

**Assumption 1** (Smoothness assumption): \(\ell(\mathbf{w},x)\) _satisfies the following conditions of Lipschitz continuous gradient:_

\[\left\|\nabla_{\mathbf{w}}\ell(\mathbf{w}_{1},x)-\nabla_{\mathbf{w}}\ell(\bm {w}_{2},x)\right\|\leq L_{1}\left\|\mathbf{w}_{1}-\mathbf{w}_{2}\right\|,\forall\mathbf{w} _{1},\mathbf{w}_{2}\in\mathcal{W},\] \[\left\|\nabla_{x}\ell(\mathbf{w},x_{1})-\nabla_{x}\ell(\mathbf{w},x_{2}) \right\|\leq L_{2}\left\|x_{1}-x_{2}\right\|,\forall x_{1},x_{2}\in\mathcal{X}.\]

**Assumption 2**: \(\left\|\nabla_{\mathbf{w}}\ell(\mathbf{w},x)\right\|\leq G\) _for all \(\mathbf{w}\in\mathcal{W}\)._

**Assumption 3** (Polyak-Lojasiewicz Condition): \(R_{(j,x_{0},r)}(\mathbf{w})\) _satisfies the PL-condition:_

\[\frac{1}{2}\left\|\nabla_{\mathbf{w}}R_{(j,x_{0},r)}(\mathbf{w})\right\|^{2}\geq\mu \left(R_{(j,x_{0},r)}(\mathbf{w})-R_{(j,x_{0},r)}^{*}\right),\]

_where \(R_{(j,x_{0},r)}(\mathbf{w})=\frac{1}{\left|\mathcal{I}_{(j,x_{0},r)}\right|}\sum_{i \in\mathcal{I}_{(j,x_{0},r)}}\ell(\mathbf{w},x_{i})\) is the local empirical risk, \(R_{(j,x_{0},r)}^{*}=\inf_{\mathbf{w}\in\mathcal{W}}R_{(j,x_{0},r)}(\mathbf{w})\)._

**Assumption 4**: _For \(\forall i\in\mathcal{I}_{(j,x_{0},r)}\), the following holds:_

\[\left\langle\nabla_{\mathbf{w}}R_{(j,x_{0},r)}(\mathbf{w}),\nabla_{\mathbf{w}}\ell(\mathbf{w},x _{i})\right\rangle\geq\beta\left\|\nabla_{\mathbf{w}}R_{(j,x_{0},r)}(\mathbf{w}) \right\|^{2}\]

Assumption 1 and 2 were made in [33], [34] and [35], where Assumption 2 can actually be derived from Assumption 1 when the input space is bounded, which is usually satisfied. Even a non-convex function can still satisfy Assumption 3 [34], the inequality in Assumption 3 implies that all stationary points are global minimum [36], which is proved in recently works [37, 38] for over-parameterized DNNs. Assumption 4 is reasonable when local neighborhood radius \(r\) is small.

```
0: Initialized weights \(\mathbf{w}^{1}\), total steps \(T\), sample set \(S\), batch size \(M\) and step size \(\eta_{t}\).
1:for\(t=1\gets T\)do
2: Randomly sample \(M\) different samples \(B^{t}\) from \(S\), where batch size \(|B_{t}|=M\), corresponding indicator set denote as \(\mathcal{I}_{B^{t}}\).
3:\(\mathbf{w}^{t+1}=\mathbf{w}^{t}-\frac{1}{M}\sum_{i\in\mathcal{I}_{B^{t}}}\nabla_{\mathbf{w} }\ell(\mathbf{w}^{t},x_{i})\)
4:endfor Return:\(\mathbf{w}^{T+1}\)
```

**Algorithm 1** Mini-batch SGD

Consider the local empirical risk under Algorithm 1, we use Theorem 2 to illustrate the convergence rate relies on local density.

**Theorem 2** (Optimization relies on local density): _Given a learnable parametrized class \(\mathcal{F}_{\mathbf{w}}:=\left\{f_{\mathbf{w}}:\mathcal{X}\rightarrow\mathbb{R}^{K}, \mathbf{w}\in\mathcal{W}\right\}\), let \(\mathbf{w}^{t}\) updated by Algorithm 1, under Assumption 1, 2, 3 and 4, set \(\eta_{t}=\frac{1}{\beta\mu t}\) and \(T\leq\frac{L_{1}}{2\beta\mu}\), then with probability at least \(1-\delta\), holds_

\[R_{(j,x_{0},r)}(\mathbf{w}^{t+1})-R_{(j,x_{0},r)}^{*}\leq\left(1-\frac{2}{t}\tau \left(\rho_{(j,x_{0},r)}\right)\right)\left(R_{(j,x_{0},r)}(\mathbf{w}^{t})-R_{(j,x_{0},r)}^{*}\right)+o\left(\frac{1}{t^{2}}\right),\]

_where \(\tau\left(\rho_{(j,x_{0},r)}\right)=\max\left\{\left(\frac{\rho_{(j,x_{0},r)} \pi^{d/2}r^{d}}{\Gamma\left(\frac{d}{2}+1\right)M}-\sqrt{\frac{\ln(T/\delta)}{ 2M}}\right),0\right\}\), which is a non-descending function of \(\rho_{(j,x_{0},r)}\)._According to theorem 2, the local empirical risk \(R_{(j,x_{0},r)}(\mathbf{w})\) will reach a more faster convergence rate in HSDR and, relatively, a relatively slower convergence rate in LSDR, thus for early-stopping models, they has a lower local empirical risk in HSDR. Combined with the following Proposition 1, we show that a smaller gradient norm guarantees a smaller local empirical risk. For overfitting models, the local empirical risk of each neighborhood where samples are located may be very small, but for early-stopping models, this relativity of local empirical risk with respect to local sample density can be maintained.

**Proposition 1**: _Under Assumption 1, given any \((x_{i},y_{i})\in S\), for any \(x\in\mathcal{X}\) that satisfies \(\left\|x_{i}-x\right\|\leq r\), the following holds:_

\[\frac{\left|\ell\left(\mathbf{w},x_{i}\right)-\ell\left(\mathbf{w},x\right)\right|}{r} -\frac{3L_{2}r}{2}\leq\left\|\nabla_{x}\ell\left(\mathbf{w},x_{i}\right)\right\| \leq\frac{\ell\left(\mathbf{w},x_{i}\right)}{r}+\frac{3L_{2}r}{2}.\]

Remark.Proposition 1 suggests that minimizing the loss leads to a smaller norm of the loss gradient. However, this constraint becomes less tight as the neighborhood radius \(r\) decreases. Compared with the loss itself, the loss gradient norm further guarantees the proximity of local loss, especially when \(r\) is small. Therefore, samples with smaller loss and smaller loss gradient norm are more likely to be in a neighborhood with smaller local empirical risk.

Using the above conclusion, for an early-stopping model, samples with smaller losses and loss gradient norms tend to be located in HSDR. Still in the example in the previous section, we train three models with early-stopping, and the learning rate adjusted with the number of steps, and then plotted Figure 3. The model has more consistent outputs in HSDR. When the loss and gradient norms of a sample are small, the region where the sample is located has smaller local empirical risk. Samples in HSDR have smaller local empirical risk, which is consistent with our theoretical analysis. Additionally, the rightmost graph of Figure 3 shows that samples with smaller loss and gradient norms often locate in HSDR, validating our conclusions.

Therefore, we can determine whether a sample is more likely to located in HSDR or LSDR by evaluating whether it has smaller loss and gradient norms simultaneously. This eliminates the need to calculate local sample densities to find samples in HSDR.

We conduct transfer attack experiments on three baselines on the CIFAR10 dataset, three different models are chosen as victims. Combining our perspectives above, we use algorithm 2 to select the anchor of each target class for guiding the addition of adversarial perturbations. We implement our strategy by simply using squared loss to match anchor points, i.e. minimizing \(\left\|f(x_{i}^{adv})-a_{\text{target}_{i}}\right\|^{2}\) (choosing \(q=10\) and \(\epsilon=16\) pixels). For comparison, we also use cross-entropy (CE) loss to calculate adversarial examples in the vanilla way, as well as using squared error without a screening mechanism (i.e., randomly selecting the target anchor in the target class) to exclude the influence of different losses. The results are shown in Table 1, our strategy indeed helps to enhance the transferability of target attacks, which further confirms our viewpoints.

Figure 3: The first figure depicts the difference in output of three models under different local sample densities \(\rho_{(y_{i},x_{i},r)}\) divided into different bins. The second figure shows the local empirical risk \(R_{(y_{i},x_{i},r)}\) of samples under different sum of loss and gradient norms (**Loss+Gradnorm**). For Loss+Gradnorm, we first normalize both variables separately and then add them up to eliminate magnitude differences. The third figure represents the local empirical risk of local sample densities in different values. The fourth figure displays the local density under different Loss+Gradnorms. The neighborhood radius \(r\) is taken as \(0.4\).

```
0: Early-stopping classifier \(f_{\mathbf{w}}\), screening parameter \(q\) and sample set \(S\).
1:for\(i=1\gets n\)do
2:\(\text{loss}_{i}=\ell_{sce}(f(x_{i}),y_{i}),\text{gradnorm}_{i}=\|\nabla_{x}\ell_ {sce}(f(x_{i}),y_{i})\|\).
3:endfor
4: For each class \(k\in[K]\), select the \(q\)-th smallest loss and the gradient norm among the samples in that class as thresholds \(\text{thr}_{k}^{\text{loss}}\) and \(\text{thr}_{k}^{\text{gradnorm}}\)
5:for\(k=1\gets K\)do
6:\(A_{k}:=\Big{\{}i\in\mathcal{I}_{k}:\text{loss}_{i}<\text{thr}_{k}^{\text{ loss}},\text{gradnorm}_{i}<\text{thr}_{k}^{\text{gradnorm}}\Big{\}}\), \(a_{k}=\frac{1}{|A_{k}|}\sum_{j\in A_{k}}f_{\mathbf{w}}(x_{j})\):
7:endfor
```

**Algorithm 2** Target Anchor Screening

## 3 Training Strategy of ESMA

We present our training strategy in this section, as shown in Figure 4. Our training strategy is carried out in two steps, the first step we pre-train the generator's embedding representations, and the second step is to find easy samples of each target class based on our previous conclusions, and then use these samples to guide the generator to generate perturbations from the source domain to the target domain.

Pre-trained Embeddings Guided by Latent FeaturesTo obtain better embeddings that more effectively represents inter-class information, since the latent space of deep learning models often extracts enough class information [39], we treat the output features of the local model as a set of a priori embedding. In order to make the generator embedding have a similar structure to such a priori embedding, we refer to the idea of manifold learning, using a strategy similar to the SNE algorithm [28]. Let \(\mu_{j}=\frac{1}{|Z_{j}|}\sum_{i\in\mathcal{I}_{j}}l_{i}\), where \(l_{i}=f(x_{i})\), and then we design the following manifold matching loss. Generator embeddings of various class were pulled to the manifold that output features in to obtain embeddings with a better structure.

Next, we denote the generator embedding of class \(j\) as \(e_{j}\). The four matrices \(M^{S_{euc}},M^{E_{euc}},M^{S_{euc}}\), \(M^{E_{euc}}\) satisfy \(M^{S_{euc}}_{i,j}=\|\mu_{i}-\mu_{j}\|\), \(M^{E_{euc}}_{i,j}=\|e_{i}-e_{j}\|\), \(M^{S_{euc}}_{i,j}=\frac{\mu_{i}\mu_{j}}{\|\mu_{i}\|\|\mu_{j}\|}\), \(M^{E_{euc}}_{i,j}=\frac{e_{i}+e_{j}}{\|e_{i}\|\|e_{j}\|}\), respectively. Let

\[\overline{M}^{S_{\text{euc}}}_{i,j} =\frac{\exp\left(M^{S_{\text{euc}}}_{i,j}\right)}{\sum_{k=1}^{K} \exp\left(M^{S_{\text{euc}}}_{i,j}\right)},\overline{M}^{E_{\text{euc}}}_{i, j}=\frac{\exp\left(M^{E_{\text{euc}}}_{i,j}\right)}{\sum_{k=1}^{K}\exp\left(M^{S_{ \text{euc}}}_{i,j}\right)},\] \[\overline{M}^{S_{\text{euc}}}_{i,j} =\frac{\exp\left(M^{S_{\text{euc}}}_{i,j}\right)}{\sum_{k=1}^{K} \exp\left(M^{S_{\text{euc}}}_{i,k}\right)},\overline{M}^{E_{\text{euc}}}_{i, j}=\frac{\exp\left(M^{S_{\text{euc}}}_{i,j}\right)}{\sum_{k=1}^{K}\exp\left(M^{S_{ \text{euc}}}_{i,k}\right)},\]

then our manifold matching loss is as follows:

\begin{table}
\begin{tabular}{l|c c c c c c c c c} \hline \hline \multirow{2}{*}{Atual} & \multicolumn{3}{c}{Src:Res43(95,44\%)} & \multicolumn{3}{c}{Src:VGG16(94,27\%)} & \multicolumn{3}{c}{Src:Dense12(95,47\%)} \\  & \(\rightarrow\)VGG16 & \(\rightarrow\)Dense121 & \(\rightarrow\)Res34 & \(\rightarrow\)Dense121 & \(\rightarrow\)Res34 & \(\rightarrow\)VGG16 \\ \hline MIM & 14.325/12.944/**14.44** & 19.815/19.09/**20.00** & 14.800/13.788/**45.13** & 13.415/12.115/**13.83** & 17.136/14.175/**17.27** & 11.236/10.275/**11.25** \\ TIM & 13.539/12.50/**13.80** & 15.239/14.56/**15.75** & 11.249/11.78/\[\mathcal{L}_{\mathcal{M}}=\sum_{i,j}\overline{M}_{i,j}^{S_{\text{core}}} \,\log\frac{\overline{M}_{i,j}^{S_{\text{core}}}}{\overline{M}_{i,j}^{S_{\text{ core}}}}+\sum_{i,j}\overline{M}_{i,j}^{E_{\text{core}}}\,\log\frac{\overline{M}_{i,j}^{E_{ \text{core}}}}{\overline{M}_{i,j}^{S_{\text{core}}}}\] \[+\lambda_{1}\left[\sum_{i,j}\overline{M}_{i,j}^{S_{\text{core}}} \,\log\frac{\overline{M}_{i,j}^{S_{\text{core}}}}{\overline{M}_{i,j}^{S_{\text {core}}}}+\sum_{i,j}\overline{M}_{i,j}^{E_{\text{core}}}\,\log\frac{\overline{ M}_{i,j}}{\overline{M}_{i,j}}\right]+\lambda_{2}\sum_{i=1}^{K}\left\|e^{i}\right\|.\]

The last regular term is to prevent losses from collapsing. \(\lambda_{1}\) and \(\lambda_{2}\) are hyperparameters. The pre-trained embedding with our strategy has a larger Euclidean distance and a smaller cosine similarity, which greatly alleviates the previous clustering phenomenon. More detailed analysis and discussion are provided in Appendix B.

Training of Multi-target Adversarial Perturbation GeneratorsAfter pre-training embedding, we freeze the parameters of the embedding layer, combined with our previous conclusions, we select several easy samples in each class to form target anchor sets \(A_{i}\), and match them with the output of our generator in feature space, the generator we use is a Unet with Resblocks. We propose the following objective easy sample feature matching loss to train the multi-class adversarial generator.

\[\mathcal{L}_{EM}=\sum_{j=1}^{K}\frac{1}{\sum_{i\in[n]}\mathbbm{1}\left(i\notin \mathcal{I}_{j}\right)}\sum_{i\notin\mathcal{I}_{j}}d\left(f\left(a_{j}\right),f\left(\operatorname{clip}_{\epsilon}\left(\mathbf{W}*\mathcal{G}_{\theta} \left(x_{i}\right)\right)\right)\right),\]

where \(\operatorname{clip}_{\epsilon}(x)=\operatorname{clip}\left(\min\left(x+ \epsilon,\max\left(x,x-\epsilon\right)\right)\right)\), \(\mathbf{W}\) is a differentiable Gaussian kernel with size \(3*3\), such smoothing operations have been demonstrated to further improve transferability[24]. The measure of the distance between the two features \(d(\cdot,\cdot)\) is Smooth L1 loss, which has a unique optimal solution that is not sensitive to exceptional values [40]. Then, our final training strategy can be represented by algorithm 3.

```
1:Generator \(\mathcal{G}_{\theta}\) with pre-trained embeddings, anchors \(a_{k},k\in[K]\) and Total epochs \(N\).
2:for\(t=1\gets N\)do
3:for\(i=1\gets n\)do
4:\(\text{target}_{i}\sim\text{Uniform}(\{1,\dots,K\})\).
5:if\(y_{i}\neq\text{target}_{i}\)then
6: Random choice an anchor \(a_{j}\) from \(A_{j}\),
7: Gradient descent step on \(\mathcal{L}_{EM}\).
8:endif
9:endfor
10:endfor
```

**Algorithm 3** Training Strategy of ESMA

## 4 Experiments

In this section, we verify the effectiveness of our method through experiments on ILSVRC2012 dataset [41]. To evaluate the effectiveness of different components in our strategy, we conduct ablation experiments in Section 4.3. Other ablation experiments can be found in Appendix C.

### Experiment Setup

DatasetThe dataset we used comes from the ILSVRC2012 dataset [41], in which we selected ten classes as the training set, which refer to the ten classes used for TTP training in [24], they are \(24\), \(99\), \(198\), \(245\), \(344\), \(471\), \(661\), \(701\), \(802\), \(919\). We train generators using images of these ten classes in the training set (\(1300\) images per class), and use the images in the validation set (\(50\) images per class) as the validation dataset for the targeted attack.

ModelsWe use the four networks used in [24] as source models --ResNet-50 [42] (Res50), VGG-19-bn [43] (VGG19bn), DenseNet-121 [44] (Dense121), ResNet-152 [42] (Res152). Except the above four models, we also select three models from the Inception series: Inception-v3 [45] (Inc-v3), Inception-v4 [46] (Inc-v4), Inception-ResNet-v2 [46] (IncRes-v2) and a transformer vision model, VIT [47]. As the analysis and fundamental assumptions of this paper are based on the condition of training data from the same distribution, in order to explore the transferability between models trained on training data with different distribution, we conduct additional transfer attack on two adversarially trained models, Inc-v3-adv [48] and IncRes-v2-ens [49]. Results are shown in E.2. In addition, we also test the adversarial transferability of ESMA on the scenario where the source model is an ensemble of different models, corresponded results are reported in E.1.

BaselinesWe select many iterative instance-specific attack benchmarks, MIM [12], SI-NIM [13], TIM [14], DIM [16], and advanced iterative instance-specific attacks that are competitive in target setting, Po-TI-Trip [20], Logit [21], Rap-LS [23], FGS\({}^{2}\)M [50], DMTI-Logit-SU [51], S\({}^{2}\)I-SI-TI-DIM [52]. Generative adversarial attacks HGN [53] and TTP [24] also included in our comparision, where TTP is the current SOTA generative method. As a generative attack, TTP requires training a class-dependent generator specifically for each class.

Parameter SettingFor the parameter settings of different attack methods, we refer to the default settings in [20], total iteration number \(T=20\), step size \(\alpha=\epsilon/T\), where the \(\ell_{\infty}\) perturbation restriction \(\epsilon\) is set to \(16\). Momentum factors \(\mu\) is set to \(1\), for the stochastic input diversity in DIM, we set the probability of applying input diversity as \(0.7\). For TIM, the kernel-length is set to \(7\), which is more suitable for targeted attacks. For Po-TI-Trip, the weight of triplet loss \(\lambda\) is set to \(0.01\), while the margin \(\gamma\) is set to \(0.007\). Referring to [21], the number of iteration steps of Logit is set to \(300\), and for RAP-LS, we choose \(400\) iteration steps, \(K_{LS}\) is set to \(100\), and \(\epsilon_{n}\) is set to \(12/255\)[23]. Then for TTP, since we used a relatively small training set, we added \(10\) epochs to the original paper [24] settings to ensure the performance of the model, and the learning rate of Adam optimizer is \(1e-4\) (\(\beta_{1}=.5\), \(\beta_{2}=.999\)). Finally, for our model, we used the AdamW optimizer to train \(300\) epochs with a learning rate of \(1e-4\) (\(350\) for cases where the source model is VGG19bn or Dense121), the value of \(q\) used for sample screening is set to \(2\).

Evaluation SettingWe train the generator on the training set of the selected ten classes, verify the targeted transferality on the validation set, for each target class, we use the \(450\) images of the remaining classes as the source data and perturb them to the target class. For the iterative instance-specific attacks, we directly attack these instances and test their targeted transfer success rate. All methods (including training) were implemented on a single NVIDIA RTX A5000 GPU.

### Results

The results of our experiments, reported in Table 3, ESMA outperforms current SOTA generative attack TTP in targeted transfer success rates. Our approach demonstrates significant advantages in terms of efficiency and effectiveness, with TTP having a parameter count of \(7.84\)M per model compared to ESMA's \(4.40\)M. Additionally, ESMA achieves an average training time that is \(78.4\%\) of TTP. The experimental results also strongly supports our viewpoint.

### Ablation Studies

To validate the effectiveness of the two components in our strategy design, we compared the cases with (w/) and without (w/o) pre-trained embeddings and target anchor screening. The results are shown in Figure 5. In the case without pre-trained embeddings, the performance is significantly weaker than the case with pre-trained embeddings across different training durations. Moreover, the case with target anchor screening shows a noticeable improvement compared to randomly selecting target anchors.

To verify that ESMA can indeed increase the sample density of the target class for the original samples, we use the samples used for adversarial testing in table 3. First, we calculate the sample density of the target class for the clean samples \(\rho_{(\text{target},x_{i},r)}\) (here \(r\) is set to \(600\)). Then, we apply ESMA to generate adversarial samples \(x_{i}^{adv}\), and calculate the sample density of the target class for these adversarial samples \(\rho_{(\text{target},x_{i}^{adv},r)}\). In both cases, the density calculation results were averaged across all target classes for each sample. We normalize the results by dividing them by the maximum value among all results in both cases. Additionally, we further bin and count the number of test samples in different intervals under different perturbation constraints. The results are shown in Table 2. The

Figure 5: Comparison of targeted attack transfer success rates with (w) pre-trained embeddings and without (w/o) pre-trained embeddings at different training epochs. Src:Res50.

[MISSING_PAGE_EMPTY:10]

## References

* [1] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian J. Goodfellow, and Rob Fergus. Intriguing properties of neural networks. In _ICLR_, 2014.
* [2] Biqing Qi, Bowen Zhou, Weinan Zhang, Jianxing Liu, and Ligang Wu. Improving robustness of intent detection under adversarial attacks: A geometric constraint perspective. _IEEE transactions on neural networks and learning systems_, PP, 2023.
* [3] Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. In _ICLR_, 2015.
* [4] Yanpei Liu, Xinyun Chen, Chang Liu, and Dawn Song. Delving into transferable adversarial examples and black-box attacks. In _ICLR_. OpenReview.net, 2017.
* [5] Nicholas Carlini and David A. Wagner. Towards evaluating the robustness of neural networks. In _IEEE S&P_, 2017.
* [6] Nathan Inkawhich, Wei Wen, Hai (Helen) Li, and Yiran Chen. Feature space perturbations yield more transferable adversarial examples. In _CVPR_, 2019.
* [7] Yao Zhu, Jiacheng Sun, and Zhenguo Li. Rethinking adversarial transferability from a data distribution perspective. In _ICLR_, 2022.
* [8] Buyu Li, Yu Liu, and Xiaogang Wang. Gradient harmonized single-stage detector. In _AAAI_, 2019.
* [9] Nicolas Papernot, Patrick D. McDaniel, Ian J. Goodfellow, Somesh Jha, Z. Berkay Celik, and Ananthram Swami. Practical black-box attacks against machine learning. In _ACM_, 2017.
* [10] Andrew Ilyas, Logan Engstrom, Anish Athalye, and Jessy Lin. Black-box adversarial attacks with limited queries and information. In _ICML_, 2018.
* [11] Jiawei Su, Danilo Vasconcellos Vargas, and Kouichi Sakurai. One pixel attack for fooling deep neural networks. _IEEE Trans. Evol. Comput._, 23(5):828-841, 2019.
* [12] Yinpeng Dong, Fangzhou Liao, Tianyu Pang, Hang Su, Jun Zhu, Xiaolin Hu, and Jianguo Li. Boosting adversarial attacks with momentum. In _CVPR_, 2018.
* [13] Jiadong Lin, Chuanbiao Song, Kun He, Liwei Wang, and John E. Hopcroft. Nesterov accelerated gradient and scale invariance for adversarial attacks. In _ICLR_, 2020.
* [14] Yinpeng Dong, Tianyu Pang, Hang Su, and Jun Zhu. Evading defenses to transferable adversarial examples by translation-invariant attacks. In _CVPR_, 2019.
* [15] Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. Towards deep learning models resistant to adversarial attacks. In _ICLR_, 2018.
* [16] Junhua Zou, Zhisong Pan, Junyang Qiu, Xin Liu, Ting Rui, and Wei Li. Improving the transferability of adversarial examples with resized-diverse-inputs, diversity-ensemble and region fitting. In _ECCV_, 2020.
* [17] Junyoung Byun, Seungju Cho, Myung-Joon Kwon, Heeseon Kim, and Changick Kim. Improving the transferability of targeted adversarial examples through object-based diverse input. In _CVPR_, 2022.
* [18] Nathan Inkawhich, Kevin J. Liang, Lawrence Carin, and Yiran Chen. Transferable perturbations of deep feature distributions. In _ICLR_, 2020.
* [19] Nathan Inkawhich, Kevin J. Liang, Binghui Wang, Matthew Inkawhich, Lawrence Carin, and Yiran Chen. Perturbing across the feature hierarchy to improve standard and strict black-box attack transferability. In _NeurIPS_, 2020.
* [20] Maosen Li, Cheng Deng, Tengjiao Li, Junchi Yan, Xinbo Gao, and Heng Huang. Towards transferable targeted attack. In _CVPR_, 2020.
* [21] Zhengyu Zhao, Zhuoran Liu, and Martha A. Larson. On success and simplicity: A second look at transferable targeted attacks. In _NeurIPS_, 2021.
* [22] Chaoning Zhang, Philipp Benz, Adil Karjauv, Jae-Won Cho, Kang Zhang, and In So Kweon. Investigating top-k white-box and transferable black-box attack. In _CVPR_, 2022.

* [23] Zeyu Qin, Yanbo Fan, Yi Liu, Li Shen, Yong Zhang, Jue Wang, and Baoyuan Wu. Boosting the transferability of adversarial attacks with reverse adversarial perturbation. In _NeurIPS_, 2022.
* [24] Muzammal Naseer, Salman H. Khan, Munawar Hayat, Fahad Shahbaz Khan, and Fatih Porikli. On generating transferable targeted perturbations. In _ICCV_, 2021.
* [25] Omid Poursaeed, Isay Katsman, Bicheng Gao, and Serge J. Belongie. Generative adversarial perturbations. In _CVPR_, 2018.
* [26] Konda Reddy Mopuri, Utkarsh Ojha, Utsav Garg, and R. Venkatesh Babu. NAG: network for adversary generation. In _CVPR_, 2018.
* [27] Muzammal Naseer, Salman H. Khan, Muhammad Haris Khan, Fahad Shahbaz Khan, and Fatih Porikli. Cross-domain transferability of adversarial perturbations. In _NeurIPS_, 2019.
* [28] Geoffrey E. Hinton and Sam T. Roweis. Stochastic neighbor embedding. In Suzanna Becker, Sebastian Thrun, and Klaus Obermayer, editors, _NeurIPS_, 2002.
* [29] Trevor Hastie, Robert Tibshirani, and Jerome H. Friedman. _The Elements of Statistical Learning: Data Mining, Inference, and Prediction, 2nd Edition_. 2009.
* [30] Abhinav Shrivastava, Abhinav Gupta, and Ross B. Girshick. Training region-based object detectors with online hard example mining. In _CVPR_, 2016.
* [31] Xiaolong Wang, Abhinav Shrivastava, and Abhinav Gupta. A-fast-rcnn: Hard positive generation via adversary for object detection. In _CVPR_, 2017.
* [32] Tsung-Yi Lin, Priya Goyal, Ross B. Girshick, Kaiming He, and Piotr Dollar. Focal loss for dense object detection. In _ICCV_, 2017.
* [33] Aman Sinha, Hongseok Namkoong, and John C. Duchi. Certifying some distributional robustness with principled adversarial training. In _ICLR_, 2018.
* [34] Maher Nouiehed, Maziar Sanjabi, Tianjian Huang, Jason D. Lee, and Meisam Razaviyayn. Solving a class of non-convex min-max games using iterative first order methods. In _NeurIPS_, 2019.
* [35] Yisen Wang, Xingjun Ma, James Bailey, Jinfeng Yi, Bowen Zhou, and Quanquan Gu. On the convergence and robustness of adversarial training. In _ICML_, 2019.
* [36] Hamed Karimi, Julie Nutini, and Mark Schmidt. Linear convergence of gradient and proximal-gradient methods under the polyak-lojasiewicz condition. In _ECML/PKDD_, 2016.
* [37] Simon S. Du, Jason D. Lee, Haochuan Li, Liwei Wang, and Xiyu Zhai. Gradient descent finds global minima of deep neural networks. In _ICML_, 2019.
* [38] Zeyuan Allen-Zhu, Yuanzhi Li, and Zhao Song. A convergence theory for deep learning via over-parameterization. In _ICML_, 2019.
* [39] Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, and Antonio Torralba. Learning deep features for discriminative localization. In _CVPR_, 2016.
* [40] Ross B. Girshick. Fast R-CNN. In _ICCV_, 2015.
* [41] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In _CVPR_, pages 248-255, 2009.
* [42] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In _CVPR_, 2016.
* [43] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. In _ICLR_, 2015.
* [44] Gao Huang, Zhuang Liu, Laurens van der Maaten, and Kilian Q. Weinberger. Densely connected convolutional networks. In _CVPR_, 2017.
* [45] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna. Rethinking the inception architecture for computer vision. In _CVPR_, 2016.
* [46] Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, and Alexander A. Alemi. Inception-v4, inception-resnet and the impact of residual connections on learning. In _AAAI_, 2017.

* [47] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. In _ICLR_, 2021.
* [48] Florian Tramer, Alexey Kurakin, Nicolas Papernot, Ian J. Goodfellow, Dan Boneh, and Patrick D. McDaniel. Ensemble adversarial training: Attacks and defenses. In _ICLR_, 2018.
* [49] Alexey Kurakin, Ian J. Goodfellow, Samy Bengio, Yinpeng Dong, Fangzhou Liao, Ming Liang, Tianyu Pang, Jun Zhu, Xiaolin Hu, Cihang Xie, Jianyu Wang, Zhishuai Zhang, Zhou Ren, Alan L. Yuille, Sangxia Huang, Yao Zhao, Yuzhe Zhao, Zhonglin Han, Junjiaja Long, Yerkebulan Berdibekov, Takuya Akiba, Seiya Tokui, and Motoki Abe. Adversarial attacks and defences competition. _CoRR_, abs/1804.00097, 2018.
* [50] Lianli Gao, Qilong Zhang, Xiaosu Zhu, Jingkuan Song, and Heng Tao Shen. Staircase sign method for boosting adversarial attacks. _CoRR_, abs/2104.09722, 2021.
* [51] Zhipeng Wei, Jingjing Chen, Zuxuan Wu, and Yu-Gang Jiang. Enhancing the self-universality for transferable targeted attacks. In _CVPR_, 2023.
* [52] Yuyang Long, Qilong Zhang, Boheng Zeng, Lianli Gao, Xianglong Liu, Jian Zhang, and Jingkuan Song. Frequency domain model augmentation for adversarial attack. In _ECCV_, 2022.
* [53] Xiao Yang, Yinpeng Dong, Tianyu Pang, Hang Su, and Jun Zhu. Boosting transferability of targeted adversarial examples via hierarchical generative networks. In Shai Avidan, Gabriel J. Brostow, Moustapha Cisse, Giovanni Maria Farinella, and Tal Hassner, editors, _ECCV_, 2022.
* [54] Dylan J. Foster and Alexander Rakhlin. \(\ell_{\infty}\)vector contraction for rademacher complexity. _CoRR_, abs/1911.06468, 2019.
* [55] Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar. _Foundations of Machine Learning_. MIT Press, 2012.
* From Theory to Algorithms_. Cambridge University Press, 2014.
* [57] Yunwen Lei, Urun Dogan, Ding-Xuan Zhou, and Marius Kloft. Data-dependent generalization bounds for multi-class classification. _IEEE Trans. Inf. Theory_, 65(5):2995-3021, 2019.
* [58] Yong Liu. Refined learning bounds for kernel and approximate \(k\)-means. In Marc'Aurelio Ranzato, Alina Beygelzimer, Yann N. Dauphin, Percy Liang, and Jennifer Wortman Vaughan, editors, _Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual_, 2021.
* [59] Wassily Hoeffding. Probability inequalities for sums of bounded random variables. _Journal of the American Statistical Association_, 58(301):13-30, 1963.

**Supplementary Material:**

**Perturbation Towards Easy Samples Improves Targeted Adversarial Transferability**

## Appendix A Proofs

### Proof of Theorem 1

First, we need the definition below:

**Definition 2** (\((j,k,x_{0},r)\)-Local Output Rademacher Complexity): _Let \(f_{\mathbf{w}}^{\mathcal{S}}=(f_{\mathbf{w}}^{\mathcal{S}_{1}},\ldots,f_{\mathbf{w}}^{ \mathcal{S}_{K}})\in[0,1]^{K}\), \(\mathcal{F}_{\mathbf{w}}^{\mathcal{S}_{k}}:=\big{\{}f_{\mathbf{w}}^{\mathcal{S}_{k}}: \mathbf{w}\in\mathcal{W}\big{\}}\), given \(\mathcal{B}(x_{0},r)=\{x:\|x-x_{0}\|\leq r\}\), \((x_{0},y_{0})\in S_{j}\), then the empirical \((j,k,x_{0},r)\)-local output Rademacher Complexity is defined by:_

\[\mathcal{R}_{n}^{(j,x_{0},r)}(\mathcal{F}_{\mathbf{w}}^{\mathcal{S}_{k}}):=\mathbb{ E}_{\mathbf{\sigma}}\left[\sup_{f_{\mathbf{w}}^{\mathcal{S}_{k}}\in\mathcal{F}_{\mathbf{w}}^{ \mathcal{S}_{k}}}\left|\sum_{i\in\mathcal{I}_{(j,x_{0},r)}}\sigma_{i}f_{\mathbf{w} }^{\mathcal{S}_{k}}(x_{i})\right|\right],\]

where \(\sigma_{i},i\in\mathcal{I}_{(j,x_{0},r)}\) are i.i.d random variables satisfies \(\mathbb{P}\left(\sigma_{i}=1\right)=\mathbb{P}\left(\sigma_{i}=-1\right)= \frac{1}{2}\). Correspondingly, the expected \((j,k,x_{0},r)\)-local output Rademacher complexity is defined as \(\mathcal{R}^{(j,x_{0},r)}(\mathcal{F}_{\mathbf{w}}^{\mathcal{S}_{k}})=\mathbb{E}_{ S_{(j,x_{0},r)}}\left[\mathcal{R}_{n}^{(j,x_{0},r)}(\mathcal{F}_{\mathbf{w}}^{ \mathcal{S}_{k}})\mid x_{i}\in\mathcal{C}_{(j,x_{0},r)}\right]\), where \(S_{(j,x_{0},r)}=\{(x,y)\in S_{j}:x\in\mathcal{B}(x_{0},r),(x_{0},y_{0})\in S\}\).

We first prove the lemma 1 and use it to prove theorem 1, and we need lemma 2 and 3 before proving the lemma 1.

**Lemma 1**: _Given \(\mathcal{B}(x_{0},r)\), \((x_{0},y_{0})\in S_{j}\), \(S_{(j,x_{0},r)}\), and \(f_{\mathbf{w}}^{\mathcal{S}_{k}}\in\mathcal{F}_{\mathbf{w}}^{\mathcal{S}_{k}}\), then with probability at least \(1-\delta\), the following holds for any \(f_{\mathbf{w}}^{\mathcal{S}_{k}}\in\mathcal{F}_{\mathbf{w}}^{\mathcal{S}_{k}}\) and \(k\in[K]\):_

\[\left|\mathbb{E}_{x\sim\mathcal{D}_{x|y}}\left[f_{\mathbf{w}}^{\mathcal{ S}_{k}}(x)\mid x\in\mathcal{C}_{(j,x_{0},r)}\right]-\mathbb{E}_{S_{(j,x_{0},r)}} \left[f_{\mathbf{w}}^{\mathcal{S}_{k}}\right]\right|\] \[\leq 4C^{\mathbf{w}}\sqrt{\frac{K}{\left|\mathcal{I}_{(j,x_{0},r)} \right|}}\log^{2}\left(\frac{\sqrt{2\left|\mathcal{I}_{(j,x_{0},r)}\right|}}{ b^{\mathbf{w}}}\right)+3\sqrt{\frac{\log(2/\delta)}{2\left|\mathcal{I}_{(j,x_{0},r)} \right|}},\]

_where \(K\) is the number of classes, \(C^{\mathbf{w}}\) and \(b^{\mathbf{w}}\) are constants._

**Lemma 2** (\(l_{\infty}\) Contraction Inequality [54] ): _Let \(\mathcal{F}\subseteq\left\{f:\mathcal{X}\rightarrow\mathbb{R}^{K}\right\}\), and let \(\phi:\mathbb{R}^{K}\rightarrow\mathbb{R}\) be \(L\)-Lipschitz with respect to the \(l_{\infty}\) norm, i.e. \(\left\|\phi(v)-\phi\left(v^{\prime}\right)\right\|_{\infty}\leq L\cdot\left\| v-v^{\prime}\right\|_{\infty},\forall v,v^{\prime}\in\mathbb{R}^{K}\). For any \(a>0\), there exists a constant \(C>0\) such that if \(\left|\phi(f(x))\right|\vee\left\|f(x)\right\|_{\infty}\leq\zeta\), then_

\[\mathcal{R}_{n}(\phi\circ\mathcal{F})\leq C\cdot L\sqrt{K}\max_{i}\tilde{ \mathcal{R}}_{n}\left(\mathcal{F}_{i}\right)\log^{\frac{3}{2}+a}\left(\frac{ \zeta n}{\max_{i}\tilde{\mathcal{R}}_{n}\left(\mathcal{F}_{i}\right)}\right),\]

_where \(\mathcal{R}_{n}(\phi\circ\mathcal{F})=\mathbb{E}_{\mathbf{\sigma}}\left[\sup_{f \in\mathcal{F}}|\sum_{i=1}^{n}\sigma_{i}\phi\left(f\left(\mathbf{x}_{i}\right) \right)|\right]\), \(\tilde{\mathcal{R}}_{n}\left(\mathcal{F}_{i}\right)=\sup_{S\in\mathcal{X}^{n}} \mathcal{R}_{n}\left(\mathcal{F}_{i}\right).\)_

**Lemma 3**: _Given \(\mathcal{B}(x_{0},r)\), \((x_{0},y_{0})\in S_{j}\), \(S_{(j,x_{0},r)}\) and \(\mathcal{F}_{\mathbf{w}}^{\mathcal{S}_{k}}\), with probability at least \(1-\delta\), holds:_

\[\mathcal{R}^{(j,x_{0},r)}(\mathcal{F}_{\mathbf{w}}^{\mathcal{S}_{k}})\leq\mathcal{ R}_{n}^{(j,x_{0},r)}(\mathcal{F}_{\mathbf{w}}^{\mathcal{S}_{k}})+\sqrt{\frac{ \left|\mathcal{I}_{(j,x_{0},r)}\right|\log(1/\delta)}{2}}.\]

_Proof of Lemma 3_ Let \(S_{(j,x_{0},r)}^{\prime}\) be a dataset that has at most one element different with \(S_{(j,x_{0},r)}\), its elements are \(x_{i}^{\prime},i\in\mathcal{I}_{(j,x_{0},r)}\), then\[\mathbb{E}_{\mathbf{\sigma}}\left[\sup_{f^{\mathcal{S}_{k}}_{\mathbf{w}}\in \mathcal{F}^{\mathcal{S}_{k}}_{\mathbf{w}}}\left|\sum_{i\in\mathcal{I}_{(j,x_{0},r)}} \sigma_{i}f^{\mathcal{S}_{k}}_{\mathbf{w}}(x_{i})\right|\right]-\mathbb{E}_{\mathbf{ \sigma}}\left[\sup_{f^{\mathcal{S}_{k}}_{\mathbf{w}}\in\mathcal{F}^{\mathcal{S}_{k}}_ {\mathbf{w}}}\left|\sum_{i\in\mathcal{I}_{(j,x_{0},r)}}\sigma_{i}f^{\mathcal{S}_{k} }_{\mathbf{w}}(x^{\prime}_{i})\right|\right]\] \[\leq \mathbb{E}_{\mathbf{\sigma}}\left[\sup_{f^{\mathcal{S}_{k}}_{\mathbf{w}} \in\mathcal{F}^{\mathcal{S}_{k}}_{\mathbf{w}}}\left|\left[\sum_{i\in\mathcal{I}_{( j,x_{0},r)}}\sigma_{i}f^{\mathcal{S}_{k}}_{\mathbf{w}}(x_{i})\right|-\left|\sum_{i\in \mathcal{I}_{(j,x_{0},r)}}\sigma_{i}f^{\mathcal{S}_{k}}_{\mathbf{w}}(x^{\prime}_{ i})\right|\right]\right]\] \[\leq \mathbb{E}_{\mathbf{\sigma}}\left[\sup_{f^{\mathcal{S}_{k}}_{\mathbf{w}} \in\mathcal{F}^{\mathcal{S}_{k}}_{\mathbf{w}}}\left|\sum_{i\in\mathcal{I}_{(j,x_{0 },r)}}\sigma_{i}\left(f^{\mathcal{S}_{k}}_{\mathbf{w}}(x_{i})-f^{\mathcal{S}_{k}}_{ \mathbf{w}}(x^{\prime}_{i})\right)\right|\right]\leq 1,\]

the last inequality is because \(S^{\prime}_{(j,x_{0},r)}\) differs from \(S_{(j,x_{0},r)}\) with at most one element, and \(f^{\mathcal{S}_{k}}_{\mathbf{w}}\in[0,1]\). Then use McDiarmid's inequality ([55], Theorem D.3), we have

\[\mathcal{R}^{(j,x_{0},r)}(\mathcal{F}^{\mathcal{S}_{k}}_{\mathbf{w}})\leq\mathcal{ R}^{(j,x_{0},r)}_{n}(\mathcal{F}^{\mathcal{S}_{k}}_{\mathbf{w}})+\sqrt{\frac{\left| \mathcal{I}_{(j,x_{0},r)}\right|\log(1/\delta)}{2}}\]

holds with probability at least \(1-\delta\).

In the following we use the notation: \(\hat{\mathbb{E}}_{S_{(j,x_{0},r)}}\left[f^{\mathcal{S}_{k}}_{\mathbf{w}}\right]= \frac{1}{\left|\mathcal{I}_{(j,x_{0},r)}\right|}\sum_{i\in\mathcal{I}_{(j,x_{0 },r)}}f^{\mathcal{S}_{k}}_{\mathbf{w}}(x_{i})\), then define:

\[\Phi(S_{(j,x_{0},r)})=\sup_{f^{\mathcal{S}_{k}}_{\mathbf{w}}\in\mathcal{F}^{ \mathcal{S}_{k}}_{\mathbf{w}}}\left|\mathbb{E}_{x\sim\mathcal{D}_{x|y}}\left[f^{ \mathcal{S}_{k}}_{\mathbf{w}}(x)\mid x\in\mathcal{C}_{(j,x_{0},r)}\right]-\hat{ \mathbb{E}}_{S_{(j,x_{0},r)}}\left[f^{\mathcal{S}_{k}}_{\mathbf{w}}\right]\right|.\]

**Lemma 4**: _Given \(\mathcal{B}(x_{0},r)\), \((x_{0},y_{0})\in S_{j}\) and \(f^{\mathcal{S}_{k}}_{\mathbf{w}}\in\mathcal{F}^{\mathcal{S}_{k}}_{\mathbf{w}}\), with probability at least \(1-\delta\), the following holds for any \(f^{\mathcal{S}_{k}}_{\mathbf{w}}\in\mathcal{F}^{\mathcal{S}_{k}}_{\mathbf{w}}\):_

\[\left|\mathbb{E}_{x\sim\mathcal{D}_{x|y}}\left[f^{\mathcal{S}_{k}}_{\mathbf{w}}(x) \mid x\in\mathcal{C}_{(j,x_{0},r)}\right]-\hat{\mathbb{E}}_{S_{(j,x_{0},r)}} \left[f^{\mathcal{S}_{k}}_{\mathbf{w}}\right]\right|\leq\frac{2}{\left|\mathcal{I }_{(j,x_{0},r)}\right|}\mathcal{R}^{(j,x_{0},r)}(\mathcal{F}^{\mathcal{S}_{k}}_ {\mathbf{w}})+\sqrt{\frac{\log(1/\delta)}{2\left|\mathcal{I}_{(j,x_{0},r)}\right|}}\]

_Proof of Lemma 4_ Similarly, let \(S^{\prime}_{(j,x_{0},r)}\) be a dataset that has at most one element different with \(S_{(j,x_{0},r)}\), then we have

\[\Phi(S^{\prime}_{(j,x_{0},r)})-\Phi(S_{(j,x_{0},r)}) =\sup_{f^{\mathcal{S}_{k}}_{\mathbf{w}}\in\mathcal{F}^{\mathcal{S}_{ k}}_{\mathbf{w}}}\left|\mathbb{E}_{x\sim\mathcal{D}_{x|y}}\left[f^{\mathcal{S}_{k}}_{ \mathbf{w}}(x)\mid x\in\mathcal{C}_{(j,x_{0},r)}\right]-\hat{\mathbb{E}}_{S^{\prime }_{(j,x_{0},r)}}\left[f^{\mathcal{S}_{k}}_{\mathbf{w}}\right]\right|\] \[-\sup_{f^{\mathcal{S}_{k}}_{\mathbf{w}}\in\mathcal{F}^{\mathcal{S}_{ k}}_{\mathbf{w}}}\left|\mathbb{E}_{x\sim\mathcal{D}_{x|y}}\left[f^{\mathcal{S}_{k}}_{ \mathbf{w}}(x)\mid x\in\mathcal{C}_{(j,x_{0},r)}\right]-\hat{\mathbb{E}}_{S_{(j,x_ {0},r)}}\left[f^{\mathcal{S}_{k}}_{\mathbf{w}}\right]\right|\] \[\leq\sup_{f^{\mathcal{S}_{k}}_{\mathbf{w}}\in\mathcal{F}^{\mathcal{S} _{k}}_{\mathbf{w}}}\left|\hat{\mathbb{E}}_{S^{\prime}_{(j,x_{0},r)}}\left[f^{ \mathcal{S}_{k}}_{\mathbf{w}}\right]-\hat{\mathbb{E}}_{S_{(j,x_{0},r)}}\left[f^{ \mathcal{S}_{k}}_{\mathbf{w}}\right]\right|\] \[=\sup_{f^{\mathcal{S}_{k}}_{\mathbf{w}}\in\mathcal{F}^{\mathcal{S}_{ k}}_{\mathbf{w}}}\left|\frac{1}{\left|\mathcal{I}_{(j,x_{0},r)}\right|}\sum_{i\in \mathcal{I}_{(j,x_{0},r)}}\left(f^{\mathcal{S}_{k}}_{\mathbf{w}}(x^{\prime}_{i})-f^ {\mathcal{S}_{k}}_{\mathbf{w}}(x_{i})\right)\right|\] \[\leq\frac{1}{\left|\mathcal{I}_{(j,x_{0},r)}\right|},\]

then use McDiarmid's inequality, with probability at least \(1-\delta\), the following holds:

\[\Phi(S_{(j,x_{0},r)})\leq\mathbb{E}_{S_{(j,x_{0},r)}}\left[\Phi(S_{(j,x_{0},r)}) \mid x_{i}\in\mathcal{C}_{(j,x_{0},r)}\right]+\sqrt{\frac{\log(1/\delta)}{2 \left|\mathcal{I}_{(j,x_{0},r)}\right|}}, \tag{1}\]then we could use the standard symmetrization technique ([56], Theorem 3.1) to derive the following:

\[\mathbb{E}_{S_{(j,x_{0},r)}}\left[\Phi(S_{(j,x_{0},r)})\mid x_{i}\in \mathcal{C}_{(j,x_{0},r)}\right]\] \[=\mathbb{E}_{S_{(j,x_{0},r)}}\left[\sup_{f_{\mathbf{w}}^{\mathcal{S}_{ k}}\in\mathcal{F}_{\mathbf{w}}^{\mathcal{S}_{k}}}\left|\mathbb{E}_{\mathbf{z}\sim\mathcal{D} _{x|y}}\left[f_{\mathbf{w}}^{\mathcal{S}_{k}}(x)\mid x\in\mathcal{C}_{(j,x_{0},r)} \right]-\hat{\mathbb{E}}_{S_{(j,x_{0},r)}}\left[f_{\mathbf{w}}^{\mathcal{S}_{k}} \right]\right|\mid x_{i}\in\mathcal{C}_{(j,x_{0},r)}\right]\] \[=\mathbb{E}_{S_{(j,x_{0},r)}}\left[\sup_{f_{\mathbf{w}}^{\mathcal{S}_{ k}}\in\mathcal{F}_{\mathbf{w}}^{\mathcal{S}_{k}}}\left|\mathbb{E}_{S^{\prime}_{(j,x_{0},r)}}\left[\hat{\mathbb{E}}_{S^{\prime}_{(j,x_{0},r)}}\left[f_{\mathbf{w}}^{ \mathcal{S}_{k}}\right]-\hat{\mathbb{E}}_{S_{(j,x_{0},r)}}\left[f_{\mathbf{w}}^{ \mathcal{S}_{k}}\right]\mid x^{\prime}_{i}\in\mathcal{C}_{(j,x_{0},r)}\right] \right|\mid x_{i}\in\mathcal{C}_{(j,x_{0},r)}\right]\] \[\underset{Jensen}{\leq}\mathbb{E}_{S_{(j,x_{0},r)},S^{\prime}_{(j,x_{0},r)}}\left[\sup_{f_{\mathbf{w}}^{\mathcal{S}_{k}}\in\mathcal{F}_{\mathbf{w}}^{ \mathcal{S}_{k}}}\left|\hat{\mathbb{E}}_{S^{\prime}_{(j,x_{0},r)}}\left[f_{\mathbf{ w}}^{\mathcal{S}_{k}}\right]-\hat{\mathbb{E}}_{S_{(j,x_{0},r)}}\left[f_{\mathbf{w}}^{ \mathcal{S}_{k}}\right]\right|\mid x_{i},x^{\prime}_{i}\in\mathcal{C}_{(j,x_{0 },r)}\right]\] \[=\mathbb{E}_{S_{(j,x_{0},r)},S^{\prime}_{(j,x_{0},r)}}\left[\sup_{ f_{\mathbf{w}}^{\mathcal{S}_{k}}\in\mathcal{F}_{\mathbf{w}}^{\mathcal{S}_{k}}}\frac{1}{ \left|\mathcal{I}_{(j,x_{0},r)}\right|}\left|\sum_{i\in\mathcal{I}_{(j,x_{0},r )}}\left(f_{\mathbf{w}}^{\mathcal{S}_{k}}(x^{\prime}_{i})-f_{\mathbf{w}}^{\mathcal{S}_ {k}}(x_{i})\right)\right|\mid x_{i},x^{\prime}_{i}\in\mathcal{C}_{(j,x_{0},r)}\right]\]

\[=\mathbb{E}_{S_{(j,x_{0},r)},S^{\prime}_{(j,x_{0},r)}}\left[\sup_{f_{\mathbf{w}}^{ \mathcal{S}_{k}}\in\mathcal{F}_{\mathbf{w}}^{\mathcal{S}_{k}}}\frac{1}{\left| \mathcal{I}_{(j,x_{0},r)}\right|}\left|\mathbb{E}_{\mathbf{\sigma}}\left[\sum_{i\in \mathcal{I}_{(j,x_{0},r)}}\sigma_{i}\left(f_{\mathbf{w}}^{\mathcal{S}_{k}}(x^{ \prime}_{i})-f_{\mathbf{w}}^{\mathcal{S}_{k}}(x_{i})\right)\right]\right|\mid x_{i}, x^{\prime}_{i}\in\mathcal{C}_{(j,x_{0},r)}\right]\]

(Since \(S\) and \(S^{\prime}\) have same distribution)

\[\underset{Jensen}{\leq}\mathbb{E}_{S_{(j,x_{0},r)},S^{\prime}_{(j,x_{0},r)},\sigma}\left[\sup_{f_{\mathbf{w}}^{\mathcal{S}_{k}}\in\mathcal{F}_{\mathbf{ w}}^{\mathcal{S}_{k}}}\frac{1}{\left|\mathcal{I}_{(j,x_{0},r)}\right|}\left|\sum_{i \in\mathcal{I}_{(j,x_{0},r)}}\sigma_{i}\left(f_{\mathbf{w}}^{\mathcal{S}_{k}}(x^{ \prime}_{i})-f_{\mathbf{w}}^{\mathcal{S}_{k}}(x_{i})\right)\right|\mid x_{i},x^{ \prime}_{i}\in\mathcal{C}_{(j,x_{0},r)}\right]\] \[\leq 2\mathbb{E}_{S_{(j,x_{0},r)},\sigma}\left[\sup_{f_{\mathbf{w}}^{ \mathcal{S}_{k}}\in\mathcal{F}_{\mathbf{w}}^{\mathcal{S}_{k}}}\frac{1}{\left| \mathcal{I}_{(j,x_{0},r)}\right|}\left|\sum_{i\in\mathcal{I}_{(j,x_{0},r)}} \sigma_{i}f_{\mathbf{w}}^{\mathcal{S}_{k}}(x_{i})\right|\mid x_{i}\in\mathcal{C}_{ (j,x_{0},r)}\right]\] \[=\frac{2}{\left|\mathcal{I}_{(j,x_{0},r)}\right|}\mathcal{R}^{(j,x_{0},r)}(\mathcal{F}_{\mathbf{w}}^{\mathcal{S}_{k}}),\]

combine with (1), we can get:

\[\left|\mathbb{E}_{x\sim\mathcal{D}_{x|y}}\left[f_{\mathbf{w}}^{\mathcal{S}_{k}}(x) \mid x\in\mathcal{C}_{(j,x_{0},r)}\right]-\hat{\mathbb{E}}_{S_{(j,x_{0},r)}} \left[f_{\mathbf{w}}^{\mathcal{S}_{k}}\right]\right|\leq\frac{2}{\left|\mathcal{I}_ {(j,x_{0},r)}\right|}\mathcal{R}^{(j,x_{0},r)}(\mathcal{F}_{\mathbf{w}}^{\mathcal{ S}_{k}})+\sqrt{\frac{\log(1/\delta)}{2\left|\mathcal{I}_{(j,x_{0},r)}\right|}}\]

holds with probability at least \(1-\delta\).

_Proof of Lemma 1_ Let \(\phi_{k}:\mathbb{R}^{K}\rightarrow\mathbb{R}\) satisfies \(\phi_{k}(v)=v_{k}\), where \(v=(v_{1},\ldots,v_{k})\in\mathbb{R}^{K}\). Then

\[\mathcal{R}_{n}^{(j,x_{0},r)}(\mathcal{F}_{\mathbf{w}}^{\mathcal{S}_{k}})=\mathcal{R }_{n}^{(j,x_{0},r)}(\phi_{k}\circ\mathcal{F}_{\mathbf{w}}^{\mathcal{S}}),\]

since \(\left|\phi_{k}(v)-\phi_{k}(v^{\prime})\right|=\left|v_{k}-v^{\prime}_{k}\right| \leq\left\|v-v^{\prime}\right\|_{\infty},\forall v,v^{\prime}\in\mathbb{R}^{K}\), i.e. \(\phi_{k}\) is \(1\)-Lipschitz. For \(f_{\mathbf{w}}^{\mathcal{S}}\in\mathcal{F}_{\mathbf{w}}^{\mathcal{S}}\), we have \(\left\|f_{\mathbf{w}}^{\mathcal{S}}\right\|_{\infty}\leq 1\), therefore, \(\left|\phi_{k}\left(f_{\mathbf{w}}^{\mathcal{S}}(x)\right)\right|\vee\left\|f_{\mathbf{w}} ^{\mathcal{S}}(x)\right\|_{\infty}\leq 1\), then use Lemma 2, choose \(L=1,\zeta=1,a=\frac{1}{2}\), there exists a constant \(C_{k}^{\mathbf{w}}>0\) such that

\[\mathcal{R}_{n}^{(j,x_{0},r)}(\phi_{k}\circ\mathcal{F}_{\mathbf{w}}^{\mathcal{S}})\leq C _{k}^{\mathbf{w}}\cdot\sqrt{K}\max_{k}\widetilde{\mathcal{R}}_{n}^{(j,x_{0},r)} \left(\mathcal{F}_{\mathbf{w}}^{\mathcal{S}_{k}}\right)\log^{2}\left(\frac{\left| \mathcal{I}_{(j,x_{0},r)}\right|}{\max_{k}\widetilde{R}_{n}^{(j,x_{0},r)} \left(\mathcal{F}_{\mathbf{w}}^{\mathcal{S}_{k}}\right)}\right), \tag{2}\]

where \(\tilde{\mathcal{R}}_{n}^{(j,x_{0},r)}\left(\mathcal{F}_{\mathbf{w}}^{\mathcal{S}_{k}} \right)=\sup_{S_{(j,x_{0},r)}\in\mathcal{E}_{(j,x_{0},r)}^{\left|x_{(j,x_{0},r)} \right|}}\mathcal{R}_{n}^{(j,x_{0},r)}\left(\mathcal{F}_{\mathbf{w}}^{\mathcal{S}_{ k}}\right)\), and we denote \(\left\{(x,y)\in\mathcal{Z}:x\in\mathcal{C}_{(j,x_{0},r)}\right\}\) as \(\mathcal{Z}_{(j,x_{0},r)}\).

For \(\forall S_{(j,x_{0},r)}\in\mathcal{Z}_{(j,x_{0},r)}^{[\mathcal{I}_{(j,x_{0},r)}]}, \forall f_{\mathbf{w}}^{\mathcal{S}_{k}}\in\mathcal{F}_{\mathbf{w}}^{\mathcal{S}_{k}}\), we have

\[\mathbb{E}_{\mathbf{\sigma}}\left[\left|\sum_{i\in\mathcal{I}_{(j,x_{0 },r)}}\sigma_{i}f_{\mathbf{w}}^{\mathcal{S}_{k}}(x_{i})\right|\right] =\mathbb{E}_{\mathbf{\sigma}}\left[\sqrt{\left|\sum_{i\in\mathcal{I}_ {(j,x_{0},r)}}\sigma_{i}f_{\mathbf{w}}^{\mathcal{S}_{k}}(x_{i})\right|^{2}}\right]\] \[\leq\sqrt{\sum_{i\in\mathcal{I}_{(j,x_{0},r)}}\left|f_{\mathbf{w}}^{ \mathcal{S}_{k}}(x_{i})\right|^{2}}\leq\sqrt{n},\]

the penultimate inequality uses the Khintchine-Kahane Inequality [57]. Therefore,

\[\mathcal{R}_{n}^{(j,x_{0},r)}\left(\mathcal{F}_{\mathbf{w}}^{\mathcal{S}_{k}} \right)=\mathbb{E}_{\mathbf{\sigma}}\left[\sup_{f_{\mathbf{w}}^{\mathcal{S}_{k}}\in \mathcal{F}_{\mathbf{w}}^{\mathcal{S}_{k}}}\left|\sum_{i\in\mathcal{I}_{(j,x_{0}, r)}}\sigma_{i}f_{\mathbf{w}}^{\mathcal{S}_{k}}(x_{i})\right|\right]\leq\sqrt{n},\]

which means \(\tilde{\mathcal{R}}_{n}^{(j,x_{0},r)}\left(\mathcal{F}_{\mathbf{w}}^{\mathcal{S}_{k }}\right)\leq\sqrt{n}\).

Choose \((\tilde{x},\tilde{y})\in\mathcal{Z}_{(j,x_{0},r)},\tilde{f}_{\mathbf{w}}^{ \mathcal{S}_{k}}\in\tilde{\mathcal{F}}_{\mathbf{w}}^{\mathcal{S}_{k}}\) satisfies

\[\mathbb{E}_{\mathbf{\sigma}}\left[\left|\sum_{i\in\mathcal{I}_{(j,x_{0},r)}}\sigma _{i}\tilde{f}_{\mathbf{w}}^{\mathcal{S}_{k}}(\tilde{x})\right|\right]=\sup_{z\in \mathcal{Z}_{(j,x_{0},r)},f_{\mathbf{w}}^{\mathcal{S}_{k}}\in\mathcal{F}_{\mathbf{w}}^ {\mathcal{S}_{k}}}\mathbb{E}_{\mathbf{\sigma}}\left[\left|\sum_{i\in\mathcal{I}_{(j,x_{0},r)}}\sigma_{i}f_{\mathbf{w}}^{\mathcal{S}_{k}}(x)\right|\right],\]

then, similar to Lemma 3 in [58], we have

\[\sup_{S_{(j,x_{0},r)}\in\mathcal{Z}_{(j,x_{0},r)}^{[\mathcal{I}_{ (j,x_{0},r)}]}}\mathcal{R}_{n}^{(j,x_{0},r)}\left(\mathcal{F}_{\mathbf{w}}^{ \mathcal{S}_{k}}\right) =\sup_{S_{(j,x_{0},r)}\in\mathcal{Z}_{(j,x_{0},r)}^{[\mathcal{I}_ {(j,x_{0},r)}]}}\mathbb{E}_{\mathbf{\sigma}}\left[\sup_{f_{\mathbf{w}}^{\mathcal{S}_{k }}\in\mathcal{F}_{\mathbf{w}}^{\mathcal{S}_{k}}}\left|\sum_{i\in\mathcal{I}_{(j,x_{0 },r)}}\sigma_{i}f_{\mathbf{w}}^{\mathcal{S}_{k}}(x_{i})\right|\right]\] \[\geq\sup_{z\in\mathcal{Z}_{(j,x_{0},r)}}\mathbb{E}_{\mathbf{\sigma}} \left[\sup_{f_{\mathbf{w}}^{\mathcal{S}_{k}}\in\mathcal{F}_{\mathbf{w}}^{\mathcal{S}_{k }}}\left|\sum_{i\in\mathcal{I}_{(j,x_{0},r)}}\sigma_{i}f_{\mathbf{w}}^{\mathcal{S}_ {k}}(x)\right|\right]\] \[\geq\sup_{Jensen}\sup_{z\in\mathcal{Z}_{(j,x_{0},r)},f_{\mathbf{w}}^ {\mathcal{S}_{k}}\in\mathcal{F}_{\mathbf{w}}^{\mathcal{S}_{k}}}\mathbb{E}_{\mathbf{ \sigma}}\left[\left|\sum_{i\in\mathcal{I}_{(j,x_{0},r)}}\sigma_{i}f_{\mathbf{w}}^{ \mathcal{S}_{k}}(x)\right|\right]\] \[=\mathbb{E}_{\mathbf{\sigma}}\left[\left|\sum_{i\in\mathcal{I}_{(j,x_ {0},r)}}\sigma_{i}\tilde{f}_{\mathbf{w}}^{\mathcal{S}_{k}}(\tilde{x})\right|\right]\] \[\geq\frac{\sqrt{2}}{2}\sqrt{\sum_{i\in\mathcal{I}_{(j,x_{0},r)}} \left|\tilde{f}_{\mathbf{w}}^{\mathcal{S}_{k}}(\tilde{x})\right|^{2}}\] \[=\frac{\sqrt{2\left|\mathcal{I}_{(j,x_{0},r)}\right|}}{2}\left| \tilde{f}_{\mathbf{w}}^{\mathcal{S}_{k}}(\tilde{x})\right|,\]

similarly, the penultimate inequality also uses the Khintchine-Kahane Inequality [57]. Below we denote \(\left|\tilde{f}_{\mathbf{w}}^{\mathcal{S}_{k}}(\tilde{x})\right|\) as \(b^{\mathbf{w},k}\). Choose \(b^{\mathbf{w}}=\max_{1\leq k\leq K}b^{\mathbf{w},k}\), which satisfies \(\max_{k}\tilde{R}_{n}^{(j,x_{0},r)}\geq\frac{\sqrt{2\left|\mathcal{I}_{(j,x_{0},r)}\right|}b^{\mathbf{w}}}{2}\), and \(C^{\mathbf{w}}=\max_{1\leq k\leq K}C_{k}^{\mathbf{w}}\), combine with (2), we have

\[\mathcal{R}_{n}^{(j,x_{0},r)}(\phi_{k}\circ\mathcal{F}_{\mathbf{w}}^{\mathcal{S}}) \leq C^{\mathbf{w}}\cdot\sqrt{K\left|\mathcal{I}_{(j,x_{0},r)}\right|}\log^{2} \left(\frac{\sqrt{2\left|\mathcal{I}_{(j,x_{0},r)}\right|}}{b^{\mathbf{w}}}\right) \tag{3}\]holds for all \(k\in[K]\). Then use Lemma 3 and Lemma 4, with probability at least \(1-\delta\), holds

\[\left|\mathbb{E}_{x\sim\mathcal{D}_{x|y}}\left[f_{\mathbf{w}}^{S_{k}}(x )\mid x\in\mathcal{C}_{(j,x_{0},r)}\right]-\hat{\mathbb{E}}_{S_{(j,x_{0},r)}} \left[f_{\mathbf{w}}^{S_{k}}\right]\right|\] \[\leq\frac{2}{\left|\mathcal{I}_{(j,x_{0},r)}\right|}\mathcal{R}_{ n}^{(j,x_{0},r)}(\mathcal{F}_{\mathbf{w}}^{S_{k}})+3\sqrt{\frac{\log(2/\delta)}{2 \left|\mathcal{I}_{(j,x_{0},r)}\right|}}\]

then combine with (3), we have

\[\left|\mathbb{E}_{x\sim\mathcal{D}_{x|y}}\left[f_{\mathbf{w}}^{S_{k}} (x)\mid x\in\mathcal{C}_{(j,x_{0},r)}\right]-\hat{\mathbb{E}}_{S_{(j,x_{0},r)} }\left[f_{\mathbf{w}}^{S_{k}}\right]\right|\] \[\leq 4C^{\mathbf{w}}\sqrt{\frac{K}{\left|\mathcal{I}_{(j,x_{0},r)} \right|}}\log^{2}\left(\frac{\sqrt{2\left|\mathcal{I}_{(j,x_{0},r)}\right|}}{b ^{\mathbf{w}}}\right)+3\sqrt{\frac{\log(2/\delta)}{2\left|\mathcal{I}_{(j,x_{0},r) }\right|}}\]

holds with probability at least \(1-\delta\).

Proof of Theroem 1For the inequality in Lemma 1, by taking \(\delta^{\prime}=\frac{\delta}{K}\) for each \(k\in[K]\), we can guarantee with probability at least \(1-\delta\), the inequality

\[\left|\mathbb{E}_{x\sim\mathcal{D}_{x|y}}\left[f_{\mathbf{w}}^{S_{k}}( x)\mid x\in\mathcal{C}_{(j,x_{0},r)}\right]-\hat{\mathbb{E}}_{S_{(j,x_{0},r)}} \left[f_{\mathbf{w}}^{S_{k}}\right]\right|\] \[\leq 4C^{\mathbf{w}}\sqrt{\frac{K}{\left|\mathcal{I}_{(j,x_{0},r)} \right|}}\log^{2}\left(\frac{\sqrt{2\left|\mathcal{I}_{(j,x_{0},r)}\right|}}{b ^{\mathbf{w}}}\right)+3\sqrt{\frac{\log(2K/\delta)}{2\left|\mathcal{I}_{(j,x_{0},r )}\right|}}\]

simultaneously holds for each \(k\in[K]\). Then for two different parametrized class \(\mathcal{F}_{\mathbf{w}_{1}}^{S_{k}}:=\left\{f_{\mathbf{w}_{1}}^{S_{k}}:\mathbf{w}_{1} \in\mathcal{W}_{1}\right\}\) and \(\mathcal{F}_{\mathbf{w}}^{S_{k}}:=\left\{f_{\mathbf{w}}^{S_{k}}:\mathbf{w}\in\mathcal{W}\right\}\), just take \(C=\max\left\{C^{\mathbf{w}_{1}},C^{\mathbf{w}}\right\}\) and \(b=\min\left\{b^{\mathbf{w}_{1}},b^{\mathbf{w}}\right\}\), the following simultaneously holds for any \(i\in\{1,2\}\) and \(k\in[K]\):

\[\left|\mathbb{E}_{x\sim\mathcal{D}_{x|y}}\left[f_{\mathbf{w}_{i}}^{ S_{k}}(x)\mid x\in\mathcal{C}_{(j,x_{0},r)}\right]-\hat{\mathbb{E}}_{S_{(j,x_{0},r )}}\left[f_{\mathbf{w}_{1}}^{S_{k}}\right]\right|\] \[\leq 4C\sqrt{\frac{K}{\left|\mathcal{I}_{(j,x_{0},r)}\right|}} \log^{2}\left(\frac{\sqrt{2\left|\mathcal{I}_{(j,x_{0},r)}\right|}}{b}\right) +3\sqrt{\frac{\log(2K/\delta)}{2\left|\mathcal{I}_{(j,x_{0},r)}\right|}}.\]

According to the assumption \(\frac{1}{\left|\mathcal{I}_{(j,x_{0},r)}\right|}\left|\sum_{i\in\mathcal{I}_{(j,x_{0},r)}}\left(f_{\mathbf{w}_{1}}^{S_{k}}(x_{i})-f_{\mathbf{w}}^{S_{k}}(x_{i})\right) \right|\leq\gamma\), which means \(\left|\hat{\mathbb{E}}_{S_{(j,x_{0},r)}}\left[f_{\mathbf{w}_{1}}^{S_{k}}\right]- \hat{\mathbb{E}}_{S_{(j,x_{0},r)}}\left[f_{\mathbf{w}}^{S_{k}}\right]\right|\leq\gamma\), then we have

\[\left|\mathbb{E}_{x\sim\mathcal{D}_{x|y}}\left[f_{\mathbf{w}_{1}}^{ S_{k}}(x)\mid x\in\mathcal{C}_{(j,x_{0},r)}\right]-\mathbb{E}_{x\sim\mathcal{D}_{x|y}} \left[f_{\mathbf{w}}^{S_{k}}(x)\mid x\in\mathcal{C}_{(j,x_{0},r)}\right]\right|\] \[\leq\left|\mathbb{E}_{x\sim\mathcal{D}_{x|y}}\left[f_{\mathbf{w}_{1}}^ {S_{k}}(x)\mid x\in\mathcal{C}_{(j,x_{0},r)}\right]-\hat{\mathbb{E}}_{S_{(j,x_ {0},r)}}\left[f_{\mathbf{w}_{1}}^{S_{k}}\right]\right|\] \[+\left|\hat{\mathbb{E}}_{S_{(j,x_{0},r)}}\left[f_{\mathbf{w}_{1}}^{ S_{k}}\right]-\hat{\mathbb{E}}_{S_{(j,x_{0},r)}}\left[f_{\mathbf{w}}^{S_{k}}\right]\right|\] \[+\left|\mathbb{E}_{x\sim\mathcal{D}_{x|y}}\left[f_{\mathbf{w}}^{S_{k} }(x)\mid x\in\mathcal{C}_{(j,x_{0},r)}\right]-\hat{\mathbb{E}}_{S_{(j,x_{0},r)}} \left[f_{\mathbf{w}}^{S_{k}}\right]\right|\] \[\leq 8C\sqrt{\frac{K}{\left|\mathcal{I}_{(j,x_{0},r)}\right|}}\log ^{2}\left(\frac{\sqrt{2\left|\mathcal{I}_{(j,x_{0},r)}\right|}}{b}\right)+6 \sqrt{\frac{\log(2K/\delta)}{2\left|\mathcal{I}_{(j,x_{0},r)}\right|}}+\gamma,\]

thus,

\[\left|\mathbb{E}_{x\sim\mathcal{D}_{x|y}}\left[f_{\mathbf{w}_{1}}^{ S}(x)\mid x\in\mathcal{C}_{(j,x_{0},r)}\right]-\mathbb{E}_{x\sim\mathcal{D}_{x|y}} \left[f_{\mathbf{w}}^{S}(x)\mid x\in\mathcal{C}_{(j,x_{0},r)}\right]\right\|_{\infty}\] \[=\max_{k\in[K]}\left|\mathbb{E}_{x\sim\mathcal{D}_{x|y}}\left[f_{ \mathbf{w}_{1}}^{S_{k}}(x)\mid x\in\mathcal{C}_{(j,x_{0},r)}\right]-\mathbb{E}_{x \sim\mathcal{D}_{x|y}}\left[f_{\mathbf{w}}^{S_{k}}(x)\mid x\in\mathcal{C}_{(j,x_{0},r)}\right]\right|\]\] \[\leq 8C\sqrt{\frac{K}{\left|\mathcal{I}_{(j,x_{0},r)}\right|}} \log^{2}\left(\frac{\sqrt{2\left|\mathcal{I}_{(j,x_{0},r)}\right|}}{b}\right) +6\sqrt{\frac{\log(2K/\delta)}{2\left|\mathcal{I}_{(j,x_{0},r)}\right|}}+\gamma.\]

By the definition, we have \(\left|\mathcal{I}_{(j,x_{0},r)}\right|=\rho_{(j,x_{0},r)}\cdot\mathrm{vol} \mathcal{B}(x_{0},r)\), and note that \[\left(\frac{2r}{\sqrt{d}}\right)^{d}\leq\mathrm{vol}\mathcal{B}(x_{0},r)=\frac{\pi^ {\frac{d}{2}}}{\Gamma(\frac{d}{2}+1)}r^{d}\leq 6r^{d},\]

therefore we can derive that with probability at least \(1-\delta\), the following holds:

\[\left\|\mathbb{E}_{x\sim\mathcal{D}_{x|y}}\left[f_{\mathbf{w}_{1}}^{ \mathcal{S}}(x)\mid x\in\mathcal{C}_{(j,x_{0},r)}\right]-\mathbb{E}_{x\sim \mathcal{D}_{x|y}}\left[f_{\mathbf{w}}^{\mathcal{S}}(x)\mid x\in\mathcal{C}_{(j,x_ {0},r)}\right]\right\|_{\infty}\] \[\leq 8C\sqrt{\frac{Kd^{d/2}}{\rho_{(j,x_{0},r)}2^{d}r^{d}}}\log^{2 }\left(\frac{2r^{d}\sqrt{3\rho_{j}(x_{0},r)}}{b}\right)+6\sqrt{\frac{d^{d/2} \log(2K/\delta)}{\rho_{(j,x_{0},r)}2^{d+1}r^{d}}}+\gamma,\]

which completes the proof.

### Proof of Theorem 2

First, note that

\[\left\|R_{(j,x_{0},r)}(\mathbf{w}_{1})-R_{(j,x_{0},r)}(\mathbf{w}_{2})\right\| =\left\|\frac{1}{\left|\mathcal{I}_{(j,x_{0},r)}\right|}\sum_{i \in\mathcal{I}_{(j,x_{0},r)}}\left(\ell\left(\mathbf{w}_{1},x_{i}\right)-\ell\left( \mathbf{w}_{2},x_{i}\right)\right)\right\|\] \[\leq\frac{1}{\left|\mathcal{I}_{(j,x_{0},r)}\right|}\sum_{i\in \mathcal{I}_{(j,x_{0},r)}}\left\|\ell\left(\mathbf{w}_{1},x_{i}\right)-\ell\left( \mathbf{w}_{2},x_{i}\right)\right\|\] \[\leq L_{1}\left\|\mathbf{w}_{1}-\mathbf{w}_{2}\right\|,\]

the second inequality holds because of Assumption 1. Then due to the Lipschitz continuous gradient of \(R_{(j,x_{0},r)}(\mathbf{w})\), we have

\[R_{(j,x_{0},r)}(\mathbf{w}^{t+1})-R_{(j,x_{0},r)}(\mathbf{w}^{t}) \leq\left\langle\nabla_{\mathbf{w}}R_{(j,x_{0},r)}(\mathbf{w}^{t}),\mathbf{w} ^{t+1}-\mathbf{w}^{t}\right\rangle+\frac{L_{1}}{2}\left\|\mathbf{w}^{t+1}-\mathbf{w}^{t} \right\|^{2}\] \[=-\eta_{t}\left\langle\nabla_{\mathbf{w}}R_{(j,x_{0},r)}(\mathbf{w}^{t}),\frac{1}{M}\sum_{i\in\mathcal{I}_{B^{t}}}\nabla_{\mathbf{w}}\ell(\mathbf{w}^{t},x_{i} )\right\rangle\] \[+\frac{L_{1}\eta_{t}^{2}}{2}\left\|\frac{1}{M}\sum_{i\in\mathcal{ I}_{B^{t}}}\nabla_{\mathbf{w}}\ell(\mathbf{w}^{t},x_{i})\right\|^{2}\] \[\leq-\eta_{t}\left\langle\nabla_{\mathbf{w}}R_{(j,x_{0},r)}(\mathbf{w}^{ t}),\frac{1}{M}\sum_{i\in\mathcal{I}_{B^{t}}}\nabla_{\mathbf{w}}\ell(\mathbf{w}^{t},x_{i} )\right\rangle+\frac{L_{1}\eta_{t}^{2}G^{2}}{2},\]

the inequality holds because of Assumption 2, prescribe notation \(\xi_{t}=\left|\mathcal{I}_{B^{t}}\cap\mathcal{I}_{(j,x_{0},r)}\right|\), combined with Assumption 3, 4, we have

\[-\eta_{t}\left\langle\nabla_{\mathbf{w}}R_{(j,x_{0},r)}(\mathbf{w}^{t}), \frac{1}{M}\sum_{i\in\mathcal{I}_{B^{t}}}\nabla_{\mathbf{w}}\ell(\mathbf{w}^{t},x_{i} )\right\rangle\] \[=-\frac{\eta_{t}}{M}\left\langle\nabla_{\mathbf{w}}R_{(j,x_{0},r)}( \mathbf{w}^{t}),\sum_{i\in\mathcal{I}_{B^{t}}\cap\mathcal{I}_{(j,x_{0},r)}}\nabla _{\mathbf{w}}\ell(\mathbf{w}^{t},x_{i})\right\rangle\] \[-\frac{\eta_{t}}{M}\left\langle\nabla_{\mathbf{w}}R_{(j,x_{0},r)}(\bm {w}^{t}),\sum_{i\in\mathcal{I}_{B^{t}}\setminus\mathcal{I}_{(j,x_{0},r)}}\nabla _{\mathbf{w}}\ell(\mathbf{w}^{t},x_{i})\right\rangle\] \[\leq-\frac{\beta\eta_{t}\xi_{t}}{M}\left\|\nabla_{\mathbf{w}}R_{(j,x _{0},r)}(\mathbf{w}^{t})\right\|^{2}+\frac{(M-\xi_{t})\,\eta_{t}G^{2}}{M}\] \[\leq-\frac{2\beta\eta_{t}\xi_{t}}{M}\left(R_{(j,x_{0},r)}(\mathbf{w }^{t})-R_{(j,x_{0},r)}^{*}\right)+\eta_{t}G^{2},\]

choose \(\eta_{t}=\frac{1}{\beta\mu t}\), due to \(T\leq\frac{L_{1}}{2\beta\mu}\), \(\eta_{t}G^{2}\leq\frac{L_{1}\eta_{t}^{2}G^{2}}{2}\).

[MISSING_PAGE_FAIL:20]

[MISSING_PAGE_FAIL:21]

To prevent \(\overline{M}_{i,j}^{E_{\text{\tiny max}}}\) from becoming too small, we need to ensure:

\[\frac{1}{K\max\limits_{1\leq k\leq K}\exp\left(M_{i,k}^{E_{\text{\tiny max}}}-M_ {i,j}^{E_{\text{\tiny max}}}\right)}>0,\]

which means we need to ensure that

\[\max\limits_{1\leq k\leq K}\exp\left(M_{i,k}^{E_{\text{\tiny max}}}\right)\neq+ \infty,\forall 1\leq i\leq K,\]

since \(M_{i,k}^{E_{\text{\tiny max}}},M_{i,j}^{E_{\text{\tiny max}}}\) are non-negative. Also, note that \(M_{i,k}^{E_{\text{\tiny max}}}=\left|e^{i}-e^{k}\right|\leq\left|e^{i}\right| +\left|e^{k}\right|\). Therefore, by imposing the following constraint in the optimization:

\[\begin{cases}\min\mathcal{L_{M}}\\ s.t.\left\|e^{i}\right\|\leq U,1\leq i\leq K\end{cases}\]

We can ensure that \(M_{i,k}^{E_{\text{\tiny max}}}\leq 2U\), which in turn guarantees \(\max\limits_{1\leq k\leq K}\exp M_{i,k}^{E_{\text{\tiny max}}}\neq+\infty, \forall 1\leq i\leq K\), thus avoiding the issue of \(\overline{M}_{i,j}^{E_{\text{\tiny max}}}\) becoming too small and causing loss collapse.

By explicitly incorporating the above constraint as a regularizer into the optimization objective, we obtain the final manifold matching loss:

\[\begin{array}{c}\mathcal{L_{M}}=\sum_{i,j}\overline{M}_{i,j}^{S_{\text{\tiny max }}}\,\log\frac{\overline{M}_{i,j}^{S_{\text{\tiny max}}}}{\overline{M}_{i,j}^ {E_{\text{\tiny max}}}}+\sum_{i,j}\overline{M}_{i,j}^{E_{\text{\tiny max}}}\, \log\frac{\overline{M}_{i,j}^{E_{\text{\tiny max}}}}{\overline{M}_{i,j}^{E_{ \text{\tiny max}}}}\\ +\lambda_{1}\left[\sum_{i,j}\overline{M}_{i,j}^{S_{\text{\tiny max}}}\,\log \frac{\overline{M}_{i,j}^{S_{\text{\tiny max}}}}{\overline{M}_{i,j}^{E_{\text{ \tiny max}}}}+\sum_{i,j}\overline{M}_{i,j}^{E_{\text{\tiny max}}}\log\frac{ \overline{M}_{i,j}}{\overline{M}_{i,j}}\right]+\lambda_{2}\sum_{i=1}^{K}\left\| e^{i}\right\|.\end{array}\]

In our experiments, we use the AdamW optimizer with a learning rate of \(1.5e-5\) for \(15000\) epochs to optimize the embeddings, while setting \(\lambda_{1}\) to \(5\) and \(\lambda_{2}\) to \(0.01\). The results, as shown in Figure 7, demonstrate a significant improvement in the clustering of embeddings between different classes.

The trained embedding is denoted as \(e_{j}\in\mathbb{R}^{d_{1}},j\in[K]\), where \(e_{j}\in\mathbb{R}^{d_{1}},j\in[K]\). For the utilized Resblock, let the input and output channels be \(C_{in}\) and \(C_{out}\) respectively. The fully connected layer

Figure 6: The top row displays the result of directly trained for \(9\) epochs, while the bottom row shows the result of directly trained for \(49\) epochs. The numbers \(0-9\) represent different class labels in sequential order. The two heatmaps on the left depict the Euclidean distance and cosine similarity between the embeddings of each class. The two images on the right display the distances after PCA projection onto a \(2\)-dimensional plane (normalized and unnormalized, representing cosine similarity and Euclidean distance, respectively).

\(\mathrm{MLP}(\cdot)\in\mathbb{R}^{d_{1}}\rightarrow\mathbb{R}^{C_{out}}\). Firstly, we employ the initial convolution kernel \(\text{Conv}_{1}\) to map the raw data from the input \(h\) of the current layer, transitioning it from [\(C_{in}\), H, W] to [\(C_{out}\), H, W]. Then we perform an addition operation between this mapped result and the embedding transformation obtained through the MLP. Formally expressed as:

\[h^{\prime}=\text{Conv}_{1}(h)+\mathrm{MLP}(e_{y})\]

where \(y\) is the label of the input. Subsequently, we apply a second convolution to this output, followed by a LayerNorm operation, and finally, pass it through an attention operation before adding it to the residual. Formally stated as:

\[\mathrm{output}=\text{Attention}(\mathrm{LN}(\text{Conv}_{2}(h^{\prime}))+h)\]

## Appendix C Additional Ablation Studies

To investigate the impact of different settings during the training phase, we conduct several experiments. First, we investigate the output consistency of the model for different values of \(q\) used for sample screening, as shown in Figure 8. A smaller \(q\) implies a stricter selection, which leads to an increase in output consistency (in terms of mean), but also results in a larger standard deviation. In this case, \(q=5\) is a relatively suitable choice.

Then we validate the impact of different choices of \(d(\cdot,\cdot)\) on targeted transferability. The results are shown in Figure 9, where \(d(\cdot,\cdot)\) was chosen as the Smooth L1 loss, which significantly improves the targeted transferability compared to L1 and L2 losses.

## Appendix D Implementation Details

In the exploratory experiments conducted in Section 2, the three different network architectures we employed are depicted in Table 4.

For the experiments on CIFAR10 mentioned in Section 2, we used the PyTorch framework. The optimizer is SGD, with an initial learning rate of \(0.1\), weight decay of \(5e-4\), and momentum of \(0.9\). We apply cosine annealing learning rate decay, with a maximum number of epochs (\(T_{max}\)) set to \(200\). Tolerance of Early-stopping is set to \(30\). Additionally, we used a batch size of \(128\) during training and applied the following data augmentations:

* Randomly crops the input image to a size of \(32\times 32\) pixels with padding of \(4\) pixels.

\begin{table}
\begin{tabular}{c c c c} \hline \hline
**Model** & **Hidden Layer 1** & **Hidden Layer 2** & **Hidden Layer 3** \\ \hline \multirow{2}{*}{Model 1} & Linear(2, 500) & Linear(500, 500) & Linear(500, 2) \\  & ReLU & ReLU & ReLU \\ \hline \multirow{2}{*}{Model 2} & Linear(2, 50) & Linear(50, 100) & Linear(100, 150) \\  & ReLU & ReLU & ReLU \\  & Linear(150, 2) & & \\ \hline \multirow{2}{*}{Model 3} & Linear(2, 20) & Linear(20, 20) & Linear(20, 20) \\  & ReLU & ReLU & ReLU \\  & Linear(20, 2) & & \\ \hline \hline \end{tabular}
\end{table}
Table 4: Architectures of NN Classifiers

Figure 7: The results obtained by optimizing \(\mathcal{L_{M}}\).

* Randomly flips the input image horizontally with a probability of 0.5.

After data augmentation, the input is then transformed into a tensor and normalized with a mean of \((0.4914,0.4822,0.4465)\) and a standard deviation of \((0.2023,0.1994,0.2010)\).

For the experiments in Section 4, we used the structure of following models: ResNet-50, VGG19bn, DenseNet-121, ResNet-152 from the torchvision 1 library, and others from the timm 2 library. The torchattacks 3 library is utilized for MIM, SI-NIM, TIM, and DIM.

Footnote 1: [https://github.com/pytorch/vision](https://github.com/pytorch/vision)

Footnote 2: [https://github.com/huggingface/pytorch-image-models](https://github.com/huggingface/pytorch-image-models)

Footnote 3: [https://github.com/Harry24k/adversarial-attacks-pytorch](https://github.com/Harry24k/adversarial-attacks-pytorch)

## Appendix E Additional Experimental Results

### Ensemble Model as Source

In Table 5, we report the results of the case of an ensemble model as the source model. The selected ensemble model are consist of three models: Res-50, Inc-v3, and Inc-v4, while the other models

Figure 8: Density plots of output similarity between models under different \(q\) selections. For the screened data, we calculate the cosine similarity between the output of the source model and the output of all target models, and take the average to represent the output similarity of the data across different models. q=all indicates no screening, and the dashed line represents the average for different values of \(q\).

Figure 9: Targeted transferability (Src:Res50) with different chosen of \(d(\cdot,\cdot)\).

[MISSING_PAGE_FAIL:25]

Figure 10: The original image is of a French Bulldog, which can be intentionally perturbed to yield different search results, such as a goose in the second row and a hippopotamus in the third row.

Figure 11: The original image is of a Ford Model T, which can be intentionally perturbed to yield different search results, such as a cannon in the second row and a gray owl in the third row.