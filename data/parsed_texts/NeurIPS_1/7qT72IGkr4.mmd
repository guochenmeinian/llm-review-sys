# Performative Control for Linear Dynamical Systems

 Songfu Cai, Fei Han, Xuanyu Cao

Department of Electronic and Computer Engineering

The Hong Kong University of Science and Technology

eesfcai@ust.hk, fhanac@connect.ust.hk, eexcao@ust.hk

Equal contribution.Corresponding author.

###### Abstract

We introduce the framework of performative control, where the policy chosen by the controller affects the underlying dynamics of the control system. This results in a sequence of policy-dependent system state data with policy-dependent temporal correlations. Following the recent literature on performative prediction [21], we introduce the concept of a performatively stable control (PSC) solution. We first propose a sufficient condition for the performative control problem to admit a unique PSC solution with a problem-specific structure of distributional sensitivity propagation and aggregation. We further analyze the impacts of system stability on the existence of the PSC solution. Specifically, for almost surely strongly stable policy-dependent dynamics, the PSC solution exists if the sum of the distributional sensitivities is small enough. However, for almost surely unstable policy-dependent dynamics, the existence of the PSC solution will necessitate a temporally backward decaying of the distributional sensitivities. We finally provide a repeated stochastic gradient descent scheme that converges to the PSC solution and analyze its non-asymptotic convergence rate. Numerical results validate our theoretical analysis.

## 1 Introduction

Control theory is a fundamental field of study in engineering and mathematics that centers on coordinating the behaviors of dynamical systems. It has extensive applications in aerospace, robotics, manufacturing, economics, natural sciences, etc. It provides a framework for designing control policies that regulate the system states, enabling them to evolve in a desired manner over time dynamically. The linear state space model is a powerful tool for representing dynamical systems, which employs a set of difference equations to describe the Markovian system state process with a linear state transition model. Many of the existing works on control of linear dynamical systems (LDSs) [26, 9, 31, 7, 17, 28, 32, 31] are developed based on the key assumption that the system state transition model is static. However, in many real world applications, such a static dynamics assumption usually does not hold because system state transition model can be changed by control policies. For instance, in the stock market, the investment policy of well-known investors can impact the actions of the general public investors, resulting in famed investment strategy-dependent changes to the dynamics of stock prices. Another example is autonomous vehicle (AV). A deployed AV might change how the pedestrians and other neighboring cars behave, and the resulting traffic environment might be quite different from what the designers of the AV had in mind [20]. Such interplay between decision-making and decision-dependent system dynamics is a pervasive phenomenon in a multitude of domains, including finance, transportation, and public policy, among others.

Most of the existing works on the control of linear systems with non-static state transition model are primarily focused on the additive random perturbations to the system state transition matrix,where policy optimization methods are employed to find the optimal control policy that minimizes quadratic costs [10; 1; 11; 8]. This type of problem also includes the control of linear systems with additive state-dependent noise [15; 6] or action-dependent noise [30; 4], which is equivalent to having additive perturbations on the state transition matrix or the control input gain matrix, respectively. Some other works on jump/switched linear systems formulate the variation of system model as stochastic model jumps among multiple linear modes, where the jumping law is governed by a finite time-homogeneous Markov process. However, in all these works, the changes of the system model are unrelated to the control policy.

_Performative prediction_ provides a systematic way to model the interaction between decision-making and data via decision-dependent data distribution maps [23]. The pioneering work by [21] has led to a growing body of research dedicated to performative prediction problems. Most of these studies are focused on establishing the conditions for the existence and uniqueness of the performative stable point and designing learning algorithms with provable convergence to such a unique performative stable point [13; 14; 5; 3; 18; 29; 25], or algorithms to find a stationary solution of the performative risk [12; 19; 25].

An open question follows: Can the idea of performative prediction, which tackles decision-dependent data in the learning/prediction domain, be employed to address the decision-dependent dynamics in the control domain? Notice that in all the aforementioned performative prediction works [21; 13; 14; 5; 3; 18; 29; 25; 12; 19; 25], the data input to the learning algorithms are independently generated based on the decision-dependent distributions. No temporal correlation is considered or exploited between two consecutive sets of input data. However, in the context of control, the situation is different as the changing system dynamics introduce various additional complexities. This is because the data of the system state at each time the step will depend on the decision-dependent state transition matrices in all previous time steps. The expected total cost function to be optimized will depend on all the decision-dependent state transition matrices across the entire control time horizon. This implies that we need a framework of _performative control_ that is more general than the framework of performative prediction, and that can accommodate a sequence of decision-dependent data with temporal correlations, where the temporal correlations are again decision-dependent.

In this work, we provide an affirmative answer to the above question. Our idea hinges on adopting the concept of performative stable solution [21], which is a fixed point solution for the interplay between the controller and the system dynamics that react to the controller's decisions. The condition for the existence of such a performative stable solution is obtained by analyzing the propagation and aggregation of sensitivities associated with the distributions of policy-dependent system dynamics over the entire control time horizon. In particular, we follow existing studies [1; 11; 8] and focus on the disturbance-action policy, which allows the consideration of general convex control costs instead of only quadratic control costs.

To the best of our knowledge, this paper provides the first study and analysis of performative control of linear systems where the system dynamics are constantly changing in a control-policy-dependent manner. We highlight the following key contributions:

* We introduce the notion of performative control, where the deployed control policy affects the underlying dynamics of the control system. We provide sufficient conditions for the existence and uniqueness of the performative stable control (PSC) solution. The sufficient condition is expressed in terms of a weighted sum of all the distributional sensitivities associated with the policy-dependent system state transition matrices over the entire control horizon. An interesting finding is that the sufficient condition exhibits a structure of sensitivity propagation and aggregation, implying that it is preferable for sensitivities to be relatively small in the early stages of the system state evolution.
* We analyze the impacts of system stability on the existence and uniqueness of the PSC solution. We show that when the policy-dependent dynamics are almost surely strongly stable, the PSC solution exists if the sum of all distributional sensitivities is below a certain threshold. On the other hand, when the policy-dependent dynamics are almost surely unstable, the proposed sufficient condition for the existence of the PSC solution will place a necessary requirement on a temporally backwards decaying of the distributional sensitivities.
* We propose a repeated stochastic gradient descent (RSGD) scheme and analyze its convergence towards the PSC solution. We show that the scheme is convergent under the same sufficient condition for the existence of the PSC solution. With an appropriate step size rule, the expected squared distance between the PSC solution and the iterates decays as \(\mathcal{O}\left(\frac{1}{N}\right),\) where \(N\) is the iteration number.

Finally, we conduct experiments on policy-dependent stock investment risk minimization problem. The numerical results validate the effectiveness of our algorithm and theoretical analysis.

### Related Work

**Performative Prediction.** The notion of performative prediction is initiated by [21], where performative stability is first introduced, and a sufficient and necessary condition is provided so that the performative stable point can be reached via iterative risk minimization algorithms. Since then, there has been a growing literature analyzing the performative prediction problem and studying the convergence of learning algorithms to the performative stable point [18; 5; 3; 13; 29].There are also some other papers that find algorithms that converge to a stationary solution of the performative risk [12; 19; 25]. Our problem poses entirely new challenges because the decision-dependent data of system state and control costs also have decision-dependent temporal correlations. Such a two-layer decision-dependent structure cannot be incorporated into the existing performative prediction framework.

There are some very recent works on _performative reinforcement learning_, where a Markov decision process (MDP) is considered and the deployed policy not only changes the costs but also the underlying state transition kernel [16; 24]. However, these works only considered the tabular MDP, where the state and action space are finite. The LDS considered in our work may also be viewed as a Markov decision process with a decision-dependent linear transition kernel and decision-dependent costs. But both the state and action space are continuous and there are infinitely many admissible state-action pairs, which are beyond the scopes of [16; 24].

**Stateful Performative Prediction.** Note that most of the existing performative prediction works [21; 18; 18; 5; 13; 29; 5; 3; 13; 29] are non-stateful in the sense that, for any deployed policy \(\theta\), the data sample \(Z\) follows a static distribution \(\mathcal{D}\left(\theta\right),\) i.e., \(Z\sim\mathcal{D}\left(\theta\right).\) The seminal work [3] generalizes the stateless framework of [21] and proposes a more general framework of stateful performative prediction via a stateful distribution transition map \(f\left(\cdot\right)\). Specifically, the observed data distribution in [3] is time-varying and depends on the history of previously deployed polices, i.e., \(\mathcal{D}_{t+1}=f\left(\mathcal{D}_{t},\theta_{t}\right)\). Consequently, in comparison to the conventional non-stateful performative prediction works [21; 18; 18; 5; 13; 29; 5; 3; 13; 29], this framework is capable of encapsulating the phenomenon of strategic decision-making with outdated information, and serves as a foundation for investigations of the disparate effects of performativity (please refer to Examples 1-3 in [3] for more details). The interconnections and generalizations between our work and the stateful performative prediction will be substantiated in Section 2.

**Nonstochastic Control.** Another line of relevant works pertains to non-stochastic control, which is initiated by [1]. Various applications of non-stochastic control can be found in [10; 1; 11; 8]. At the core of non-stochastic control is the disturbance-action control policy, which chooses the action as a linear map of the past disturbances [11]. Such a disturbance-action policy facilitates efficient algorithms for control problems with arbitrary additive disturbances in the dynamics and arbitrary convex control costs instead of quadratic costs only. In this paper, we adopt the disturbance-action control policy for analysis. However, in contrast to [1; 10; 1; 11; 8], where the system dynamics are static, our analysis involves policy-dependent nonstationary dynamics.

## 2 Motivations

In this section, we discuss the key motivations for our performative linear control framework. We also outline the key connections and generalizations of our proposed framework to the stateful performative prediction framework of [3].

**Connections between Static Stateful Distribution Transition Maps and LDS.** The LDS modeling via control theory in our work is closely aligned with the static stateful distribution maps within the state performative prediction framework [3]. Let us first consider a static stateful distribution transition map \(f\left(\cdot\right)\) with \(\mathcal{D}_{t+1}=f\left(\mathcal{D}_{t},\theta_{t}\right),\forall t\geq 0.\) To facilitate the analysis, we use a performative data sample \(Z_{t}\sim\mathcal{D}_{t}\) to equivalently characterize the performative distribution \(\mathcal{D}_{t}.\) If the properties of \(f\left(\cdot\right)\) are nice enough, then from the perspective of random variables, there will exist a corresponding mapping \(\widetilde{f}\left(\cdot\right)\) such that

\[Z_{t+1}\overset{\mathrm{d}}{=}\widetilde{f}\left(Z_{t},\theta_{t}\right),Z_{t+1} \sim\mathcal{D}_{t+1},Z_{t}\sim\mathcal{D}_{t},\forall t\geq 0, \tag{1}\]

where \(\overset{\mathrm{d}}{=}\) denotes equal in distribution. Linearizing \(\widetilde{f}\left(\cdot\right)\) at some equilibrium point \(\left(\overline{Z},\overline{\theta}\right)\) with \(\overline{Z}\sim\overline{\mathcal{D}}\) and ignoring the higher order terms will lead to

\[Z_{t+1}\overset{\mathrm{d}}{=}\mathbf{A}Z_{t}+\mathbf{B}\theta_{t}+\mathbf{w}, \tag{2}\]

where \(\mathbf{A}=\left[\frac{\partial\widetilde{f}}{\partial d}\right]_{\left( \overline{d},\overline{\theta}\right)}\) and \(\mathbf{B}=\left[\frac{\partial\widetilde{f}}{\partial\overline{\theta}}\right] _{\left(\overline{d},\overline{\theta}\right)}\) are the static Jacobin matrices at the equilibrium point \(\left(\overline{d},\overline{\theta}\right)\) and \(\mathbf{w}=\widetilde{f}\left(\overline{Z},\overline{\theta}\right)-\mathbf{A }\overline{Z}-\mathbf{B}\overline{\theta}\). Consider the performative data sample \(Z_{t}\), the deployed policy \(\theta_{t}\) and the residual \(\mathbf{w}\) in (2) as the state variable \(\mathbf{x}_{t}\), the control input action \(\mathbf{u}_{t}\) and the additive system noise \(\mathbf{w}_{t}\sim\mathbf{w}\) of an LDS, respectively. The linearized static stateful distribution map model in (2) is thus precisely connected to a LDS with system dynamics given by

\[\mathbf{x}_{t+1}=\mathbf{A}\mathbf{x}_{t}+\mathbf{B}\mathbf{u}_{t}+\mathbf{w}_ {t}. \tag{3}\]

**Extension to Performative Stateful Distribution Transition Maps via Performative LDS.** Further consider a more complicated case of _performance distribution transition maps_\(f_{\theta_{t}}\left(\cdot\right)\) with \(\mathcal{D}_{t+1}=f_{\theta_{t}}\left(\mathcal{D}_{t},\theta_{t}\right),\forall t \geq 0,\) where the specific form of the distribution transition map \(f_{\theta_{t}}\) is time-varying and depends on the deployed policy \(\theta_{t}\). Employing a similar linearization for \(\widetilde{f}_{\theta_{t}}\left(\cdot\right)\) and neglecting the higher order terms, we obtain

\[Z_{t+1}\overset{\mathrm{d}}{=}\mathbf{A}_{\theta_{t}}Z_{t}+\mathbf{B}_{\theta _{t}}\theta_{t}+\mathbf{w}_{\theta_{t}}, \tag{4}\]

where \(\mathbf{A}_{\theta_{t}}=\left[\frac{\partial\widetilde{f}_{\theta_{t}}}{ \partial d}\right]_{\left(\overline{d},\overline{\theta}\right)}\) and \(\mathbf{B}_{\theta_{t}}=\left[\frac{\partial\widetilde{f}_{\theta_{t}}}{ \partial\overline{\theta}}\right]_{\left(\overline{d},\overline{\theta}\right)}\) are the performative Jacobin matrices, and \(\mathbf{w}_{t}=\widetilde{f}_{\theta_{t}}\left(\overline{Z},\overline{\theta} \right)-\mathbf{A}_{\theta_{t}}\overline{Z}-\mathbf{B}_{\theta_{t}}\overline {\theta}\). This results in an equivalent performative LDS given by

\[\mathbf{x}_{t+1}=\mathbf{A}_{\mathbf{u}_{t}}\mathbf{x}_{t}+\mathbf{B}_{ \mathbf{u}_{t}}\mathbf{u}_{t}+\mathbf{w}_{\mathbf{u}_{t}}. \tag{5}\]

In contrast to (3), where the system dyanmics are static, the state transition matrix \(\mathbf{A}_{\mathbf{u}_{t}}\), control input gain matrix \(\mathbf{B}_{\mathbf{u}_{t}}\) and additive noise \(\mathbf{w}_{\mathbf{u}_{t}}\) in (5) are all performative and depend on the deployed control policy \(\mathbf{u}_{t}\).

In conclusion, the LDS modeling presented in our paper allows for the _performance transition maps of performative distributions_, thereby extending the technical results previously obtained for fixed performative distribution transition maps in the stateful performative prediction work [3]. As a result, our proposed performative LDS framework has the potential to enhance the understanding of general performative prediction.

## 3 Problem Setup

We consider the control of a linear dynamic system with per stage cost \(c_{t}\left(\mathbf{x}_{t},\mathbf{u}_{t}\right)\). A control policy \(\pi\) is a mapping \(\pi:\mathbb{R}^{d_{x}\times 1}\rightarrow\mathbb{R}^{d_{u}\times 1},\) which maps the system state \(\mathbf{x}_{t}\) to the control action \(\mathbf{u}_{t}\), i.e., \(\mathbf{u}_{t}=\pi\left(\mathbf{x}_{t}\right)\). For each control policy \(\pi\), we attribute a finite time horizon expected cost defined as

\[C_{T}^{\pi}=\mathbb{E}_{\mathbf{x}_{0},\left\{\mathbf{A}_{t}\right\},\left\{ \mathbf{w}_{t}\right\}}\left[\sum_{t=0}^{T}c_{t}\left(\mathbf{x}_{t},\mathbf{ u}_{t}\right)\right], \tag{6}\]

where \(\mathbf{x}_{t+1}=\mathbf{A}_{t}\mathbf{x}_{t}+\mathbf{B}\mathbf{u}_{t}+ \mathbf{w}_{t}\), the initial system state \(\mathbf{x}_{0}\) follows a general distribution of \(\mathcal{D}_{x_{0}}\) with bounded support \(\left\|\mathbf{x}_{0}\right\|\leq x_{0}\), and \(\mathbb{E}_{\mathbf{x}_{0},\left\{\mathbf{A}_{t}\right\},\left\{\mathbf{w}_{t }\right\}}\) represents the expectation over \(\mathbf{x}_{0},\) the entire policy-dependent state transition matrix sequence \(\left\{\mathbf{A}_{t},\right.\)\(\left.1\leq t\leq T\right\}\) and the entire disturbance sequence \(\left\{\mathbf{w}_{t},1\leq t<T\right\}\).

To the best of our knowledge, this paper is the very first work to investigate the performative LDS, and we intend to provide a thorough theoretical investigation and aim at establishing various new theoretical results. Therefore, we opt to construct our performative LDS theoretical framework upon the performative state transition matrix \(\mathbf{A}_{t}\), while maintaining the control input gain matrix \(\mathbf{B}\) and additive disturbance \(\mathbf{w}_{t}\) as non-performative. This facilitates us to streamline the theoretical analysis and consolidates the system design insights.

We have the following assumption on the additive disturbances \(\left\{\mathbf{w}_{t},1\leq t\leq T\right\}.\)

**A1**: _The additive disturbance per time step \(\mathbf{w}_{t}\) is bounded, i.i.d, and zero-mean with a lower bounded covariance i.e., \(\mathbf{w}_{t}\sim\mathcal{D}_{\mathbf{w}},\mathbb{E}[\mathbf{w}_{t}]=\mathbf{ 0},\mathbb{E}[\mathbf{w}_{t}\mathbf{w}_{t}^{\top}]\succeq\sigma^{2}\mathbf{I}\), \(\|\mathbf{w}_{t}\|\leq W,\forall 0\leq t<T\), and \(\mathbb{E}[\mathbf{w}_{t_{1}}\mathbf{w}_{t_{2}}^{\top}]=\mathbf{0},\forall 0 \leq t_{1}\neq t_{2}<T\)._

**Disturbance-Action Control Policy.** We work with the following class of disturbance-action control policy throughout this paper, which is commonly used in nonstochastic control [10, 1, 11, 8] to address general convex control cost functions.

**Definition 1**: _(Disturbance-Action Policy). For a disturbance-action control policy, the mapping \(\pi\), \(\forall 0\leq t<T\), is uniquely characterized by a set of matrices \(\left\{\mathbf{M}^{(1)},\cdots,\mathbf{M}^{(H)}\right\}\). At every time step \(t\), such a disturbance-action control policy assigns a control action \(\mathbf{u}_{t}^{(\mathbf{M})}\) in the form of_

\[\mathbf{u}_{t}^{(\mathbf{M})}=\pi\left(\mathbf{x}_{t}\right)=-\mathbf{K} \mathbf{x}_{t}+\sum_{i=1}^{H}\mathbf{M}^{(i)}\mathbf{w}_{t-i}=-\mathbf{K} \mathbf{x}_{t}+\mathbf{M}\left[\mathbf{w}\right]_{t-1}^{H}, \tag{7}\]

_where \(\mathbf{M}=\left[\mathbf{M}^{(1)},\mathbf{M}^{(2)},\cdots,\mathbf{M}^{(H)}\right]\) belongs to a convex set \(\mathbb{M}\) with bounded support \(\|\mathbf{M}\|_{F}\leq M\), \([\mathbf{w}]_{t-1}^{H}\) is short for \(\left[\mathbf{w}_{t-1}^{\top},\cdots\mathbf{w}_{t-1-H}^{\top}\right]^{\top}\), \(H<T\) is a constant and \(\mathbf{w}_{i}=\mathbf{0}\) for all \(i<0\)._

In the disturbance-action policy (7), we adopt a class of linear controller \(\mathbf{K}\) defined as follows.

**Definition 2**: _(Strongly Stabilizing Linear Controller [1, 10, 11, 8]). Given \(\mathbf{A}\) and \(\mathbf{B}\), a linear controller \(\mathbf{K}\) is \((\kappa,\gamma)\) almost surely strongly stable for real numbers \(\kappa\geq 1,\gamma<1\), if \(\|\mathbf{K}\|\leq\kappa\), and there exists matrices \(\mathbf{Q}\) and \(\mathbf{L}\) such that \(\widetilde{\mathbf{A}}:=\mathbf{A}-\mathbf{B}\mathbf{K}:=\mathbf{QLQ}^{-1}\), with \(\|\mathbf{L}\|\leq 1-\gamma\) and \(\|\mathbf{Q}\|,\left\|\mathbf{Q}^{-1}\right\|\leq\kappa\)._

It is worth noting that the disturbance-action policy is only parameterized by the matrix \(\mathbf{M}\). Whereas the state feedback gain \(\mathbf{K}\), which is a fixed matrix, is not part of the parameterization of the policy. As pointed out in [2], a typical choice of the parameter \(H\) is \(H=\gamma^{-1}\log(T\kappa^{2})\). With an appropriate choice of the policy \(\mathbf{M}\), the control action \(\mathbf{u}_{t}^{(\mathbf{M})}\) in (7) is capable of approximating any linear state feedback control policy in terms of the total cost suffered with a finite time horizon of \(H\)[10, 1, 11, 8].

**Policy-dependent Dynamics.** Without loss of generality, at any time step \(t\), the impact of the disturbance-action control policy \(\mathbf{u}_{t}^{(\mathbf{M})}\) to the dynamics of the linear system is modeled as a policy-dependent additive perturbation \(\mathbf{\Delta}_{t}\) to a common state transition matrix \(\mathbf{A}\).

**A2**: _(Policy-dependent State Transition Matrix). The disturbance-action policy-dependent state transition matrix \(\mathbf{A}_{t}\) takes the form of_

\[\mathbf{A}_{t}=\mathbf{A}+\mathbf{\Delta}_{t},\mathbf{\Delta}_{t}\sim\mathcal{D }_{t}\left(\mathbf{M}\right),\forall 0\leq t<T, \tag{8}\]

_where \(\mathbf{A}\) is the mean value of \(\mathbf{A}_{t}\), and \(\mathbf{\Delta}_{t}\) is the policy-dependent state transition perturbation with zero mean and bounded support, i.e., \(\mathbb{E}\left[\mathbf{\Delta}_{t}\right]\)=\(\mathbf{0}\) and there exists a bounded constant \(\xi_{t}\) such that \(\|\mathbf{\Delta}_{t}\|\leq\xi_{t}\), \(\forall 0\leq t<T\). For different time steps \(t_{1}\) and \(t_{2}\), \(\mathbf{\Delta}_{t_{1}}\) and \(\mathbf{\Delta}_{t_{2}}\) are mutually independent. Besides, \(\left\{\mathbf{\Delta}_{t},0\leq t<T\right\}\) and \(\left\{\mathbf{w}_{t},0\leq t<T\right\}\) are mutually independent._

**Remark 1**: _(Non-zero Mean \(\mathbf{\Delta}_{t}\)). If the mean of the disturbance is non-zero and time-varying, i.e., \(\mathbb{E}\left[\mathbf{\Delta}_{t}\right]=\Theta_{t}\), we will have a new equivalent \(\mathbf{A}_{t}^{\prime}=\mathbf{A}+\Theta_{t}\) with zero mean disturbances. We only need to choose a new linear controller \(\mathbf{K}_{t}^{\prime}\) such that \(\mathbf{A}_{t}^{\prime}-\mathbf{B}\mathbf{K}_{t}^{\prime}\) is \((\kappa_{t},\gamma_{t})\)-strongly stabilizing. As a result, without loss of generality, we assume \(\mathbf{\Delta}_{t}\) is zero mean throughout this paper._

**Remark 2**: _(Policy-dependent Control Input Gain Matrix \(\mathbf{B}\)). Note that under the DAP (7), the disturbance-action is given by \(\mathbf{BM}[\mathbf{w}]_{t-1}^{H}\), which is linear in policy \(\mathbf{M}\). Such kind of linear disturbance-action control policy has various nice theoretical performance guarantees as substantiated in [10, 1, 11, 8]. On the other hand, if \(\mathbf{B}\) is also performative, we will have a generalized disturbance-action \(\mathbf{B}_{t}(\mathbf{M})\mathbf{M}[\mathbf{w}]_{t-1}^{H}\), which can be possibly nonlinear in policy \(\mathbf{M}\). Such kind of generalized nonlinear disturbance-action control policy has received very few research attention, and it can serve as a very interesting future research direction._

We make the following sensitivity assumption on the distributions \(\left\{\mathcal{D}_{t}\left(\mathbf{M}\right),0\leq t<T\right\}.\)

**A3**: _(\(\varepsilon\)-Sensitivity). For any \(t=0,1,\cdots,T-1\), there exists a constant \(\varepsilon_{t}>0\) such that_

\[\mathcal{W}^{1}\left(\mathcal{D}_{t}\left(\mathbf{M}\right),\mathcal{D}_{t} \left(\mathbf{M}^{\prime}\right)\right)\leq\varepsilon_{t}\left\|\mathbf{M}- \mathbf{M}^{\prime}\right\|_{F},\;\forall\mathbf{M},\mathbf{M}^{\prime}\in \mathbb{M}, \tag{9}\]

_where \(\mathcal{W}^{1}\left(\mathcal{D},\mathcal{D}^{\prime}\right)\) denotes the Wasserstein-1 distance between the distributions \(\mathcal{D}\) and \(\mathcal{D}^{\prime}\)._

Assumption A3 imposes a regularity requirement on the distributions \(\left\{\mathcal{D}_{t}\left(\mathbf{M}\right),0\leq t<T\right\}.\) Intuitively, if the disturbance-action control policies are made according to similar policy parameterizations \(\mathbf{M}\), then the resulting distributions of the policy-dependent state transition perturbations should also be similar.

**System State Evolutions.** Under the disturbance-action policy (7), the following lemma shows that the system state \(\mathbf{x}_{t},\forall 1\leq t\leq T,\) can be uniquely determined by \(\mathbf{x}_{0}\), \(\mathbf{\tilde{A}}\), \(\mathbf{M}\), \(\left\{\mathbf{\Delta}_{t},0\leq t<T\right\}\) and \(\left\{\mathbf{w}_{t},-H\leq t<T\right\}.\)

**Lemma 1**: _Given a disturbance-action policy \(\mathbf{M}\), the system state \(\mathbf{x}_{t}\), \(\forall 1\leq t\leq T\), can be represented as_

\[\mathbf{x}_{t}=\mathbf{x}_{t}^{(\mathbf{M})}= \prod_{i=0}^{t-1}\left(\mathbf{\tilde{A}}+\mathbf{\Delta}_{i} \right)\mathbf{x}_{0}+\sum_{i=0}^{t-1}\prod_{j=i+1}^{t-1}\left(\mathbf{1}_{j <t}\left(\mathbf{\tilde{A}}+\mathbf{\Delta}_{j}\right)+\mathbf{1}_{j=t} \mathbf{I}\right)\mathbf{BM}\left[\mathbf{w}\right]_{i-1}^{H} \tag{10}\] \[+\sum_{i=0}^{t-1}\prod_{j=i+1}^{t-1}\left(\mathbf{1}_{j<t}\left( \mathbf{\tilde{A}}+\mathbf{\Delta}_{j}\right)+\mathbf{1}_{j=t}\mathbf{I} \right)\mathbf{w}_{i}.\]

_Besides, let the \(\mathbf{K}\) in DAP (7) be a strongly stabilizing linear controller, the norm of \(\mathbf{x}_{t}\) is upper bounded as \(\left\|\mathbf{x}_{t}\right\|\leq x_{0}\kappa^{2}\alpha_{t}+\kappa^{2}W\left( \left\|\mathbf{B}\right\|HM+1\right)\beta_{t},\) where \(\alpha_{t}=\prod_{i=0}^{t-1}\left(1-\gamma+\kappa^{2}\xi_{i}\right)\) and \(\beta_{t}=\sum_{i=0}^{t-1}\prod_{j=i+1}^{t-1}\left(\mathbf{1}_{j<t}\left(1- \gamma+\kappa^{2}\xi_{j}\right)+\mathbf{1}_{j=t}\right).\)_

The _performative optimal control (POC)_ problem can therefore be formulated as:

\[\min_{\mathbf{M}\in\mathbb{M}}\quad C_{T}^{\mathbf{M}}=\mathbb{E}_{\mathbf{x} _{0},\left\{\mathbf{\Delta}_{t}\sim\mathcal{D}_{t}\left(\mathbf{M}\right), \left\{\mathbf{w}_{t}\right\}\left[\sum_{t=0}^{T}c_{t}\left(\mathbf{x}_{t}^{( \mathbf{M})},\mathbf{u}_{t}^{(\mathbf{M})}\right)\right]. \tag{11}\]

The _POC_ problem (11) comprises of a stochastic objective function with policy-dependent distributions. Due to non-convexity, the performative optimal solution \(\mathbf{M}^{PO}\) to (11) is usually difficult to obtain. Alternatively, in this paper, we are interested in the _performance stable control (PSC)_ solution:

\[\mathbf{M}^{PS}=\Phi(\mathbf{M}^{PS}):=\arg\min_{\mathbf{M}\in\mathbb{M}} \mathbb{E}_{\mathbf{x}_{0},\left\{\mathbf{\Delta}_{t}\sim\mathcal{D}_{t}( \mathbf{M}^{PS})\right\},\left\{\mathbf{w}_{t}\right\}}\left[\sum_{t=0}^{T}c_{ t}\left(\mathbf{x}_{t}^{(\mathbf{M})},\mathbf{u}_{t}^{(\mathbf{M})}\right) \right]. \tag{12}\]

Notice that \(\mathbf{M}^{PS}\) is defined to be a fixed point of the map \(\Phi\). Compared to the _POC_ (11), the distribution of \(\mathbf{\Delta}_{t}\) in _PSC_ (12) changes from \(\mathbf{\Delta}_{t}\sim\mathcal{D}_{t}\left(\mathbf{M}\right)\) to \(\mathbf{\Delta}_{t}\sim\mathcal{D}_{t}\left(\mathbf{M}^{PS}\right),\forall 0\leq t<T.\) The existence and uniqueness of \(\mathbf{M}^{PS}\) will be dicsussed in Lemma 4.

**Comparison to Existing Works.** Most of the existing performative prediction works [21, 13, 14, 5, 3, 18, 29, 25, 12, 19, 25] consider the cost in the form of \(l\left(\theta;Z\right),\) where \(\theta\) is the decision variable. Then the relationship between data samples \(Z\) and decision \(\theta\) is parameterizedby a fixed distribution \(Z\sim\mathcal{D}\left(\theta\right)\) with fixed sensitivity \(\varepsilon\). However, in our work, the relationship between system state data samples \(\mathbf{x}_{t}\) and policy \(\mathbf{M}\) is characterized by a time-varying distribution \(\mathbf{x}_{t}\sim f_{t}\left(\mathcal{D}_{0}\left(\mathbf{M}\right),\cdots, \mathcal{D}_{t-1}\left(\mathbf{M}\right)\right)\) with a time-varying sequence of joint sensitivities \(\left\{\varepsilon_{0},\cdots,\varepsilon_{t}\right\},\,\forall 0\leq t<T\). The total cost \(\sum_{t=0}^{T}c_{t}\) depends on all the policy-dependent distributions \(\left\{\mathcal{D}_{0}\left(\mathbf{M}\right),\cdots,\mathcal{D}_{T-1}\left( \mathbf{M}\right)\right\}\) with a collection of sensitivities \(\left\{\varepsilon_{0},\cdots,\varepsilon_{T-1}\right\}\). These key differences lead to a more complicated analysis in our work.

**RSGD Scheme.** We propose a repeated stochastic gradient descent (RSGD) scheme in Algorithm 1 to find a PSC solution to (12). The metric of the projection in line 9 of Algorithm 1 is the matrix Frobenius norm. Specifically, \(\mathrm{Proj}_{\mathbb{M}}\left\{\mathbf{M}\right\}=\arg\min_{\mathbf{M}^{ \prime}\in\mathbb{M}}\left\|\mathbf{M}-\mathbf{M}^{\prime}\right\|_{F}^{2}\). Note that such a projection is computationally tractable because the Frobenius norm square minimization is a convex optimization problem. The RSGD scheme first computes the stochastic gradient of the total cost w.r.t. policy \(\sum_{t=0}^{T}\nabla_{\mathbf{M}_{n}}c_{t}\left(\mathbf{x}_{t},\mathbf{u}_{t}\right)\) and then perform stochastic gradient descent on \(\mathbf{M}\). The detailed steps for computation of the stochastic gradient \(\nabla_{\mathbf{M}_{n}}c_{t}\left(\mathbf{x}_{t},\mathbf{u}_{t}\right)\) are provided in Appendix B.

```
1:Step sizes \(\left\{\eta_{n},0\leq n\leq N\right\}\), parameters \(\mathbf{K},H\). Define \(\mathbb{M}=\left\{\mathbf{M}:\left\|\mathbf{M}\right\|\leq M\right\}.\) Initialize \(\mathbf{M}_{0}\in\mathbb{M}\) arbitrarily.
2:for\(n=0,\cdots,N,\)do
3: Initialize \(\nabla J_{T}=\mathbf{0}\).
4:for\(t=0,\cdots,T-1,\)do
5: Use control \(\mathbf{u}_{t}=-\mathbf{K}\mathbf{x}_{t}+\mathbf{M}_{n}\left[\mathbf{w}\right]_ {t-1}^{H}.\)
6: Observe \(\mathbf{A}_{t},\,\mathbf{x}_{t+1}\); compute noise \(\mathbf{w}_{t}=\mathbf{x}_{t+1}-\mathbf{A}_{t}\mathbf{x}_{t}-\mathbf{B}\mathbf{ u}_{t}\).
7: Compute the gradient \(\nabla_{\mathbf{M}_{n}}c_{t}\left(\mathbf{x}_{t},\mathbf{u}_{t}\right)\) and update \(\nabla J_{T}\leftarrow\nabla J_{T}+\nabla_{\mathbf{M}_{n}}c_{t}\left(\mathbf{x }_{t},\mathbf{u}_{t}\right).\)
8:endfor
9: Update \(\mathbf{M}_{n+1}\leftarrow\mathrm{Proj}_{\mathbb{M}}\{\mathbf{M}_{n}-\eta_{n} \nabla J_{T}\}\).
10:endfor
```

**Algorithm 1** Repeated Stochastic Gradient Descent (RSGD)

## 4 Main Results

This section investigates the existence of a PSC solution \(\mathbf{M}^{PS}\) to (12) and the convergence of the RSGD scheme to \(\mathbb{M}^{PS}\). We require the following assumptions on the per stage cost \(c_{t}\)[1, 10, 1, 11, 8].

**A4**: _(Strongly Convex). The per stage cost function \(c_{t}\left(\mathbf{x},\mathbf{u}\right)\) is \(\mu\)-strongly convex such that_

\[c_{t}\left(\mathbf{x}_{1},\mathbf{u}_{1}\right) \geq c_{t}\left(\mathbf{x}_{2},\mathbf{u}_{2}\right)+\nabla_{ \mathbf{x}}^{\top}c_{t}\left(\mathbf{x}_{2},\mathbf{u}_{2}\right)\left( \mathbf{x}_{1}-\mathbf{x}_{2}\right)+\nabla_{\mathbf{u}}^{\top}c_{t}\left( \mathbf{x}_{2},\mathbf{u}_{2}\right)\left(\mathbf{u}_{1}-\mathbf{u}_{2}\right)\] \[+\frac{\mu}{2}\left(\left\|\mathbf{x}_{1}-\mathbf{x}_{2}\right\|^ {2}+\left\|\mathbf{u}_{1}-\mathbf{u}_{2}\right\|^{2}\right),\forall\mathbf{x}_ {1},\mathbf{x}_{2}\in\mathbb{R}^{d_{x}},\mathbf{u}_{1},\mathbf{u}_{2}\in \mathbb{R}^{d_{u}}.\]
**A5**: _(Smoothness). The per stage cost function \(c_{t}\left(\mathbf{x},\mathbf{u}\right)\) is \(\varsigma\) smooth such that_

\[\left\|\nabla_{\mathbf{x}}c_{t}\left(\mathbf{x}_{1},\mathbf{u}_{1} \right)-\nabla_{\mathbf{x}}c_{t}\left(\mathbf{x}_{2},\mathbf{u}_{1}\right) \right\|+\left\|\nabla_{\mathbf{u}}c_{t}\left(\mathbf{x}_{1},\mathbf{u}_{1} \right)-\nabla_{\mathbf{u}}c_{t}\left(\mathbf{x}_{1},\mathbf{u}_{2}\right)\right\|\] \[\leq\varsigma\left(\left\|\mathbf{x}_{1}-\mathbf{x}_{2}\right\|+ \left\|\mathbf{u}_{1}-\mathbf{u}_{2}\right\|\right),\forall\mathbf{x}_{1}, \mathbf{x}_{2}\in\mathbb{R}^{d_{x}},\mathbf{u}_{1},\mathbf{u}_{2}\in\mathbb{ R}^{d_{u}}.\]
**A6**: _(Boundedness). There exists a positive constant \(G\) such that_

\[\left\|\nabla_{\mathbf{x}}c_{t}\left(\mathbf{x},\mathbf{u}\right)\right\|, \left\|\nabla_{\mathbf{u}}c_{t}\left(\mathbf{x},\mathbf{u}\right)\right\|\leq GD,\forall\left\|\mathbf{x}\right\|,\left\|\mathbf{u}\right\|\leq D.\]

The above Assumptions A4-A6 on the per stage cost function \(c_{t}\left(\mathbf{x},\mathbf{u}\right)\) are quite standard, which hold for broad classes of costs such as the quadratic costs.

To facilitate our discussions, we define an expected total cost with distribution shift as

\[C_{T}\left(\mathbf{M};\mathbf{M}^{\prime}\right)\coloneqq\mathbb{E}_{\mathbf{x }_{0},\left\{\mathbf{\Delta}_{t}\sim\mathcal{D}_{t}\left(\mathbf{M}^{\prime }\right)\right\},\left\{\mathbf{w}_{t}\right\}}\left[\sum_{t=0}^{T}c_{t} \left(\mathbf{x}_{t}^{(\mathbf{M})},\mathbf{u}_{t}^{(\mathbf{M})}\right) \right],\]where, under policy \(\mathbf{M}\), the distribution of policy-dependent perturbation is changed from \(\mathbf{\Delta}_{t}\sim\mathcal{D}_{t}\left(\mathbf{M}\right)\) to \(\mathbf{\Delta}_{t}\sim\mathcal{D}_{t}\left(\mathbf{M}^{\prime}\right)\), \(\forall 0\leq t<T\). For the rest of this paper, unless otherwisespecified, \(\nabla C_{T}\left(\mathbf{M};\mathbf{M}^{\prime}\right)\) denote the gradients taken w.r.t. the first argument \(\mathbf{M}\).

Our main results rely on the strong convexity of the expected total cost \(C_{T}\left(\mathbf{M};\mathbf{M}^{\prime}\right)\) with respect to its first argument \(\mathbf{M}\). However, the strong convexity of the per stage cost function \(c_{t}\left(\mathbf{x},\mathbf{u}\right)\) over the state-action space in Assumption A4 does not by itself imply the strong convexity of the expected total cost \(C_{T}\left(\mathbf{M};\mathbf{M}^{\prime}\right)\) over the space of policies \(\mathbf{M}\). This is becasue the policy \(\mathbf{M}\), which maps from a space of dimensionality \(H\times d_{x}\times d_{u}\) to that of \(d_{x}+d_{u}\), is not necessarily full column-rank. Our next lemma, which forms the core of our analysis, shows that this is not the case using the inherent stochastic nature of the policy-dependent dynamics.

**Lemma 2**: _Under A1-A6, fix any \(\mathbf{M}^{\prime}\in\mathbb{M},\) the expected total cost \(C_{T}\left(\mathbf{M};\mathbf{M}^{\prime}\right)\) is \(\widetilde{\mu}\)-strongly convex in its first argument \(\mathbf{M}\) such that \(\forall\mathbf{M}_{1},\mathbf{M}_{2}\in\mathbb{M},\)_

\[C_{T}\left(\mathbf{M}_{1};\mathbf{M}^{\prime}\right)\geq C_{T}\left(\mathbf{M }_{2};\mathbf{M}^{\prime}\right)+\mathrm{Tr}\left(\left(\nabla C_{T}\left( \mathbf{M}_{2};\mathbf{M}^{\prime}\right)\right)^{\top}\left(\mathbf{M}_{1}- \mathbf{M}_{2}\right)\right)+\frac{\widetilde{\mu}}{2}\left\|\mathbf{M}_{1}- \mathbf{M}_{2}\right\|_{F}^{2}, \tag{13}\]

_where \(\widetilde{\mu}=\min\left\{\frac{(T-H+1)\mu\sigma^{2}}{2},\frac{(T-H+1)\mu \sigma^{2}\gamma^{2}}{64\epsilon^{10}}\right\}.\)_

For a concise presentation of the smoothness of expected total control cost, we next define a collection of constants as follows:

\[c_{1} \coloneqq d_{x}\varsigma H^{\frac{3}{2}}W\left(1+\left(\kappa^{2 }+\kappa^{3}\right)\left\|\mathbf{B}\right\|\right)\left(\kappa^{2}+\kappa^{3 }\right)\left(1-\gamma\right)^{-1},\] \[c_{2} \coloneqq d_{x}H^{\frac{3}{2}}WG\left(1-\gamma\right)^{-1}\left( \kappa^{4}+\kappa^{5}\right)\left\|\mathbf{B}\right\|,c_{3}\coloneqq\left(HM \left\|\mathbf{B}\right\|+1\right)W,c_{4}\coloneqq HW\left(1-\gamma\right)c_{ 1},\] \[c_{5} \coloneqq HW\left(\kappa^{2}+\kappa^{3}\right)^{-1}\left(1-\gamma \right)c_{1}.\]

The smoothness of the expected total cost \(C_{T}\left(\mathbf{M};\mathbf{M}^{\prime}\right)\) is summarized below.

**Lemma 3**: _Under A1-A6, the expected total cost \(C_{T}\) is smooth in the sense that, for any \(\mathbf{M},\mathbf{M}^{\prime},\mathbf{M}_{1},\mathbf{M}_{2}\in\mathbb{M}\) and \(\forall 1\leq t\leq T\), the following inequality holds_

\[\left\|\nabla C_{T}\left(\mathbf{M}_{1};\mathbf{M}\right)-\nabla C _{T}\left(\mathbf{M}_{2};\mathbf{M}^{\prime}\right)\right\|_{F}\] \[\leq\sum_{t=1}^{T}\lambda_{t}\left\|\mathbf{M}_{1}-\mathbf{M}_{2 }\right\|_{F}+\sum_{t=0}^{T-1}\left(\varepsilon_{t}\sum_{i=t+1}^{T}\nu_{i} \right)\left\|\mathbf{M}-\mathbf{M}^{\prime}\right\|_{F}, \tag{14}\]

_where \(\lambda_{t}=c_{1}\left(c_{4}\beta_{t}+c_{5}\right),\nu_{t}=\left(c_{1}+c_{2} \beta_{t}\right)\left(x_{0}\alpha_{t}+c_{3}\beta_{t}\right),\forall 1\leq t\leq T,\) and we recall that \(\alpha_{t}=\prod_{i=0}^{t-1}\left(1-\gamma+\kappa^{2}\xi_{i}\right)\) and \(\beta_{t}=\sum_{i=0}^{t-1}\prod_{j=t+1}^{t-1}\left(\mathbf{1}_{j<t}\left(1- \gamma+\kappa^{2}\xi_{j}\right)+\mathbf{1}_{j=t}\right)\) from Lemma 1, which characterize the growth of the norm of system state \(\left\|\mathbf{x}_{t}\right\|.\)_

**Existence and Uniqueness of \(\mathbf{M}^{PS}\).** Our first main result establishes a sufficient condition for the existence and uniqueness of the performative stable policy \(\mathbf{M}^{PS}\) that solves the _PSC_ problem (12).

**Lemma 4**: _Under A1-A6, consider the fixed-point iteration_

\[\mathbf{M}_{n+1}= \Phi\left(\mathbf{M}_{n}\right),\forall n\geq 0, \tag{15}\]

_where the map \(\Phi\) is defined in (12). If the following condition is satisfied_

\[\sum_{t=0}^{T-1}\left(\varepsilon_{t}\sum_{i=t+1}^{T}\nu_{i}\right)<\widetilde {\mu}, \tag{16}\]

_then iterates \(\mathbf{M}_{n}\) converge to a unique performatively stable point \(\mathbf{M}^{PS}\) at a linear rate, i.e.,_

\[\left\|\mathbf{M}_{n}-\mathbf{M}^{PS}\right\|_{F}\leq\rho\text{ for }n\geq\left(1-\frac{\sum_{t=0}^{T-1}\left(\varepsilon_{t}\sum_{i=t+1}^{T}\nu_{i} \right)}{\widetilde{\mu}}\right)^{-1}\log\left(\frac{1}{\rho}\left\|\mathbf{M}_{0}- \mathbf{M}^{PS}\right\|_{F}\right).\]The sufficient condition (16) delivers a fact that that the existence and uniqueness of \(\mathbf{M}^{PS}\) is jointly determined by all the sensitivities \(\{\varepsilon_{t},0\leq t<T\}\) in the temporal domain. The sensitivity \(\varepsilon_{t}\) at the \(t\)-th time step is propagated starting from time step \(t+1\) to the last time step \(T\) with a sequence of weights \(\{\nu_{t+1},\cdots,\nu_{T}\}\). The aggregated impact of all the policy-dependent disturbances \(\{\mathbf{\Delta}_{t},0\leq t<T\}\) is captured by total sum in L.H.S. of (16). This is very different from the existing performative prediction works [21, 18, 5, 3, 13, 29, 12, 19, 25], where only one distribution \(\mathcal{D}\) and one sensitivity \(\varepsilon\) are involved.

The sufficient condition (16) also implies that it is preferable for the initial policy-dependent disturbance \(\mathbf{\Delta}_{0}\) to be small because it propagates and aggregates for the longest time steps of \(T\).

**Impacts of System Stability.** The sufficient condition (16) also reveals the impacts of system stability on the existence and uniqueness of the performative stable solution \(\mathbf{M}^{PS},\) which are summarized below.

**Proposition 1**: _(Almost Surely Strongly Stable Case) Let A1-A6 hold. If policy-dependent state transition matrix \(\mathbf{A}_{t}\) is \(\left(\kappa,\gamma-\kappa^{2}\xi_{t}\right)\)-strongly stable for real numbers \(\kappa\geq 1,\gamma-\kappa^{2}\xi_{t}<1,\forall 0\leq t<T\), almost surely. Let \(\zeta=\max\left\{1-\gamma+\kappa^{2}\xi_{t},\forall 0\leq t<T\right\}\), then \(\mathbf{M}^{PS}\) exists and is unique if \(\sum_{t=0}^{T-1}\varepsilon_{t}<\phi\big{(}1-\frac{H}{T}\big{)}\overline{\mu},\) where \(\overline{\mu}=\min\left\{\frac{\mu\sigma^{2}}{2},\frac{\mu\sigma^{2}\gamma^{2 }}{64\kappa^{10}}\right\}\) and \(\phi\) is some positive constant._

Proposition 1 points out that when the policy-dependent dynamics are almost surely strongly stable, we only need to make sure that the sum of all the sensitivities \(\{\varepsilon_{t},0\leq t<T\}\) is below a certain threshold.

**Proposition 2**: _(Almost Surely Unstable Case) Let A1-A6 hold. If the policy-dependent state transition matrix \(\mathbf{A}_{t}\) is almost surely unstable, i.e., there exists a positive constant \(\widetilde{\zeta}>1\) such that \(\widetilde{\zeta}\leq\|\mathbf{A}_{t}\|\leq 1-\gamma+\kappa^{2}\xi_{t},\forall 0 \leq t<T.\) In this case, to guarantee the sufficient condition (16) can be satifsed, we must have \(\varepsilon_{t}<\frac{\overline{\phi}(T-H+1)\overline{\mu}}{\widetilde{ \zeta}^{T-t-1}},\forall 0\leq t<T,\) where \(\overline{\phi}\) is some positive constant._

For unstable policy-dependent dynamics, condition (16) will impose a necessary requirement on the temporally backwards decaying of the sensitivities. Particularly, more restrictive requirements are placed on the the sensitivities in the early time steps, i.e., smallt, which should decay exponentially fast w.r.t. the control time horizon \(T\).

For more general applications, where \(\mathbf{A}_{t}\) can be either stable or unstable for different time steps, the weighted sum requirement of the sensitivities \(\{\varepsilon_{t},0\leq t<T\}\) in (16) is sufficient to guarantee the existence and uniqueness of the performative stable solution \(\mathbf{M}^{PS}\).

**Convergence of RSGD Scheme.** Our next theorem establishes the convergence rate of the proposed RSGD algorithm.

**Theorem 1**: _Choose two positive constants \(\phi_{1}>0\) and \(\phi_{2}\geq 1\) such that the following two conditions are satisfied simualnteously_

\[\frac{\phi_{1}}{\phi_{2}}\leq\min\left\{\frac{\widetilde{\mu}-\sum _{t=0}^{T-1}\left(\varepsilon_{t}\sum_{i=t+1}^{T}\nu_{i}\right)}{2\left(\sum_{ t=1}^{T}\lambda_{t}+\sum_{t=0}^{T-1}\left(\varepsilon_{t}\sum_{i=t+1}^{T}\nu_{i} \right)\right)^{2}},\frac{1}{\widetilde{\mu}-\sum_{t=0}^{T-1}\left(\varepsilon _{t}\sum_{i=t+1}^{T}\nu_{i}\right)}\right\}, \tag{17}\] \[\frac{\phi_{1}}{1+\frac{1}{\phi_{2}}}\geq\frac{2}{\widetilde{\mu} -\sum_{t=0}^{T-1}\left(\varepsilon_{t}\sum_{i=t+1}^{T}\nu_{i}\right)}. \tag{18}\]

_Consider a sequence of non-negative step sizes \(\left\{\eta_{n}=\frac{\phi_{1}}{n+\phi_{2}},n\geq 0\right\}\). Then, the iterates generated by RSGD admit the following bound for any \(N\geq 1\):_

\[\mathbb{E}\left[\left\|\mathbf{M}_{N}-\mathbf{M}^{PS}\right\|_{F}^{2}\right] \leq\mathrm{e}^{-\sum_{n=1}^{N}\frac{\phi_{1}}{n}\left(\widetilde{\mu}-\sum_{t =0}^{T-1}\left(\varepsilon_{t}\sum_{i=t+1}^{T}\nu_{i}\right)\right)}\mathbb{E} \left[\left\|\mathbf{M}_{0}-\mathbf{M}^{PS}\right\|_{F}^{2}\right]+\frac{\phi_{ 3}}{N}, \tag{19}\]

_where \(\vartheta_{t}=\kappa^{3}G\left(\left(HW+\kappa^{2}\right)\kappa\left\|\mathbf{ B}\right\|\beta_{t}+1\right)\left(x_{0}\alpha_{t}+c_{3}\beta_{t}\right)+GHWM\left( \kappa^{3}\beta_{t}+1\right),\forall 1\leq t\leq T,\) and \(\phi_{3}=\frac{4\phi_{1}T\sum_{t=1}^{T}\phi_{t}^{2}}{\widetilde{\mu}-\sum_{t=0 }^{T-1}\left(\varepsilon_{t}\sum_{i=t+1}^{T}\nu_{i}\right)}\) is a positive constant._

Note that, under the sufficient condition (16) in Lemma 4, there always exists a pair of \(\left(\phi_{1},\phi_{2}\right)\) that satisfies (17) and (18) simultaneously by letting \(\phi_{2}\) be sufficiently large. The first term on the R. H. S. of (19) decays at the rate of \(\mathcal{O}(\mathrm{e}^{-\sum_{n=1}^{N}\frac{\phi_{1}}{n}\left(\widetilde{\mu }-\sum_{t=0}^{T-1}\left(\varepsilon_{t}\sum_{i=t+1}^{T}\nu_{i}\right)\right)})\) and is scaled by the initial error \(\mathbb{E}\left[\left\|\mathbf{M}_{0}-\mathbf{M}^{PS}\right\|_{F}^{2}\right].\) The second term is a fluctuation term that only depends on the variance of the stochastic gradient, which decays at the rate \(\mathcal{O}\left(1/N\right)\). For more general types of step sizes and the associated nonasymptotic convergence rate analysis, please refer to Lemma 5 in the appendix G.1.

## 5 Numerical Experiments

We consider an application of stock investment risk minimization problem to verify our algorithm and theoretical results. Consider an investor trading a total number of 10 stocks over a period of \(T=60\) trading days. The detailed system setups are described in Example 1 in AppendixA of the supplementary. We compare the performative error (PS error) \(\left\|\mathbf{M}_{N}-\mathbf{M}^{PS}\right\|_{F}^{2}\) and the expected total cost \(C_{T}\left(\mathbf{M}_{N};\mathbf{M}_{N}\right)\) against the iteration number \(N\), respectively. We consider a fixed distributional sensitivity value set \(\boldsymbol{\varepsilon}=\left\{\varepsilon_{i},i=0,1,\ldots,T-1\right\}\). We assign three different patterns of the sensitivity sequence as \(\varepsilon_{\mathrm{d}}=\mathrm{descend}\left(\boldsymbol{\varepsilon}\right)\), \(\varepsilon_{\mathrm{a}}=\mathrm{ascend}\left(\boldsymbol{\varepsilon}\right)\) and \(\varepsilon_{\mathrm{r}}=\mathrm{random}\left(\boldsymbol{\varepsilon}\right)\) in descending, ascending, and random order, respectively, over the time steps. We first observe from Figure 1 (left) and Figure 2 (left) that when the policy-dependent system dynamics \(\mathbf{A}_{t},\forall 0\leq t<T,\) are almost surely strongly stable, the gap \(\left\|\mathbf{M}_{N}-\mathbf{M}^{PS}\right\|_{F}^{2}\) of three different patterns \(\varepsilon_{\mathrm{d}},\)\(\varepsilon_{\mathrm{a}}\) and \(\varepsilon_{\mathrm{r}}\) all decay at \(\mathcal{O}\left(\frac{1}{N}\right)\) as \(N\rightarrow\infty\), and the expected total control cost also converges. These coincide exactly with Proposition 1 and Theorem 1, where the existence of \(\mathbf{M}^{PS}\) only requires that the sum of the distributional sensitivities \(\sum_{t=0}^{T-1}\varepsilon_{t}\) is small enough, and the temporal order of each \(\varepsilon_{t}\) is negligible. We next observe from Figure 1 (middle) and Figure 2 (middle), that when the \(\mathbf{A}_{t},\forall 0\leq t<T,\) are almost surely unstable, the iterates \(\mathbf{M}_{n}\) of both \(\varepsilon_{\mathrm{d}}\) and \(\varepsilon_{\mathrm{r}}\) diverge. The expected total control costs associated with \(\varepsilon_{\mathrm{d}}\) and \(\varepsilon_{\mathrm{r}}\) are significantly larger than that of \(\varepsilon_{\mathrm{a}}\). This is because large initial distributional sensitivities in \(\varepsilon_{\mathrm{d}}\) and \(\varepsilon_{\mathrm{r}}\) rule out the existence of \(\mathbf{M}^{PS}\), which matches Proposition 2. For the general case of \(\mathbf{A}_{t}\) in Figure 1 (right) and Figure 2 (right), all three cases converge due to the relatively mild sufficient condition (16).

## Conclusion

In this work, we have introduced the framework of performative control and studied the conditions under which a PSC policy exists. We have analyzed the impact of system stability on the existence of the PSC policy, and proposed a condition on the sum of the distributional sensitivities and the temporally backwards decaying of sensitivities for almost surely strongly stable and almost surely unstable systems, respectively. We have also proposed an RSGD algorithm that converges to the PSC policy in a mean-square sense. The extension of our current results to general control policies and general control costs [cf. A4], will be explored in future work.

## References

* Agarwal et al. [2019] Naman Agarwal, Brian Bullins, Elad Hazan, Sham Kakade, and Karan Singh. Online control with adversarial disturbances. In _International Conference on Machine Learning_, pages 111-119. PMLR, 2019.
* Agarwal et al. [2019] Naman Agarwal, Elad Hazan, and Karan Singh. Logarithmic regret for online control. _Advances in Neural Information Processing Systems_, 32, 2019.
* Brown et al. [2022] Gavin Brown, Shlomi Hod, and Iden Kalemaj. Performative prediction in a stateful world. In _International conference on artificial intelligence and statistics_, pages 6045-6061. PMLR, 2022.
* Carlos et al. [2018] Hugo Carlos, Jean-Bernard Hayet, and Rafael Murrieta-Cid. An analysis of policies from stochastic linear quadratic gaussian in robotics problems with state-and control-dependent noise. _Journal of Intelligent & Robotic Systems_, 92(1):85-106, 2018.
* Drusvyatskiy and Xiao [2023] Dmitriy Drusvyatskiy and Lin Xiao. Stochastic optimization with decision-dependent distributions. _Mathematics of Operations Research_, 48(2):954-998, 2023.
* Duncan and Pasik-Duncan [2017] TE Duncan and B Pasik-Duncan. Stochastic linear-quadratic control with state dependent fractional brownian noise and stochastic coefficients. _IFAC-PapersOnLine_, 50(2):199-202, 2017.
* Fazel et al. [2018] Maryam Fazel, Rong Ge, Sham Kakade, and Mehran Mesbahi. Global convergence of policy gradient methods for the linear quadratic regulator. In _International conference on machine learning_, pages 1467-1476. PMLR, 2018.
* Ghai et al. [2024] Udaya Ghai, Arushi Gupta, Wenhan Xia, Karan Singh, and Elad Hazan. Online nonstochastic model-free reinforcement learning. _Advances in Neural Information Processing Systems_, 36, 2024.
* Gravell et al. [2020] Benjamin Gravell, Peyman Mohajerin Esfahani, and Tyler Summers. Learning optimal controllers for linear systems with multiplicative noise via policy gradient. _IEEE Transactions on Automatic Control_, 66(11):5283-5298, 2020.
* Hambly et al. [2021] Ben Hambly, Renyuan Xu, and Huining Yang. Policy gradient methods for the noisy linear quadratic regulator over a finite horizon. _SIAM Journal on Control and Optimization_, 59(5):3359-3391, 2021.
* Hazan et al. [2020] Elad Hazan, Sham Kakade, and Karan Singh. The nonstochastic control problem. In _Algorithmic Learning Theory_, pages 408-421. PMLR, 2020.
* Izzo et al. [2021] Zachary Izzo, Lexing Ying, and James Zou. How to learn when data reacts to your model: performative gradient descent. In _International Conference on Machine Learning_, pages 4641-4650. PMLR, 2021.
* Li and Wai [2022] Qiang Li and Hoi-To Wai. State dependent performative prediction with stochastic approximation. In _International Conference on Artificial Intelligence and Statistics_, pages 3164-3186. PMLR, 2022.
* Li et al. [2022] Qiang Li, Chung-Yiu Yau, and Hoi-To Wai. Multi-agent performative prediction with greedy deployment and consensus seeking agents, 2022. _URL https://arxiv. org/abs/2209.03811_.
* Liu et al. [2023] Rui Liu, Guangyao Shi, and Pratap Tokekar. Data-driven distributionally robust optimal control with state-dependent noise. In _2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)_, pages 9986-9991. IEEE, 2023.
* Mandal et al. [2023] Debmalya Mandal, Stelios Triantafyllou, and Goran Radanovic. Performative reinforcement learning. In _International Conference on Machine Learning_, pages 23642-23680. PMLR, 2023.
* Mania et al. [2019] Horia Mania, Stephen Tu, and Benjamin Recht. Certainty equivalence is efficient for linear quadratic control. _Advances in Neural Information Processing Systems_, 32, 2019.

* [18] Celestine Mendler-Dunner, Juan Perdomo, Tijana Zrnic, and Moritz Hardt. Stochastic optimization for performative prediction. _Advances in Neural Information Processing Systems_, 33:4929-4939, 2020.
* [19] John P Miller, Juan C Perdomo, and Tijana Zrnic. Outside the echo chamber: Optimizing the performative risk. In _International Conference on Machine Learning_, pages 7710-7720. PMLR, 2021.
* [20] Stefanos Nikolaidis, Swaprava Nath, Ariel D Procaccia, and Siddhartha Srinivasa. Game-theoretic modeling of human adaptation in human-robot collaboration. In _Proceedings of the 2017 ACM/IEEE international conference on human-robot interaction_, pages 323-331, 2017.
* [21] Juan Perdomo, Tijana Zrnic, Celestine Mendler-Dunner, and Moritz Hardt. Performative prediction. In _International Conference on Machine Learning_, pages 7599-7609. PMLR, 2020.
* [22] Huyen Pham, Marco Corsi, and Wolfgang J Runggaldier. Numerical approximation by quantization of control problems in finance under partial observations. In _Handbook of Numerical Analysis_, volume 15, pages 325-360. Elsevier, 2009.
* [23] Joaquin Quinonero-Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil D Lawrence. _Dataset shift in machine learning_. Mit Press, 2022.
* [24] Ben Rank, Stelios Triantafyllou, Debmalya Mandal, and Goran Radanovic. Performative reinforcement learning in gradually shifting environments. _arXiv preprint arXiv:2402.09838_, 2024.
* [25] Mitas Ray, Lillian J Ratliff, Dmitriy Drusvyatskiy, and Maryam Fazel. Decision-dependent risk minimization in geometrically decaying dynamic environments. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 36, pages 8081-8088, 2022.
* [26] Benjamin Recht. A tour of reinforcement learning: The view from continuous control. _Annual Review of Control, Robotics, and Autonomous Systems_, 2:253-279, 2019.
* [27] Roberto Reno. Nonparametric estimation of stochastic volatility models. _Economics Letters_, 90(3):390-395, 2006.
* [28] Harish K Venkataraman and Peter J Seiler. Recovering robustness in model-free reinforcement learning. In _2019 American Control Conference (ACC)_, pages 4210-4216. IEEE, 2019.
* [29] Killian Wood, Gianluca Bianchin, and Emiliano DallAnese. Online projected gradient descent for stochastic optimization with decision-dependent distributions. _IEEE Control Systems Letters_, 6:1646-1651, 2021.
* [30] Farnaz Adiy Yaghmaie, Fredrik Gustafsson, and Lennart Ljung. Linear quadratic control using model-free reinforcement learning. _IEEE Transactions on Automatic Control_, 68(2):737-752, 2022.
* [31] Peng Zhao, Yu-Hu Yan, Yu-Xiang Wang, and Zhi-Hua Zhou. Non-stationary online learning with memory and non-stochastic control. _The Journal of Machine Learning Research_, 24(1):9831-9900, 2023.
* [32] Hongyu Zhou, Zirui Xu, and Vasileios Tzoumas. Efficient online learning with memory via frank-wolfe optimization: Algorithms with bounded dynamic regret and applications to control. In _2023 62nd IEEE Conference on Decision and Control (CDC)_, pages 8266-8273. IEEE, 2023.

Application Example and Experiment Detail.

In this section, we elaborate a concrete example of stock market risk minimization to justify the policy-dependent state transition model in (8). We also conduct numerical experiment based on this example to demonstrate the efficacy of our developed theory.

**Example 1**: _(Stock Market Risk Minimization). We describe a risk minimization problem for stock market investment to illustrate the application of (11). Consider an investor trading a total number of \(L\) stocks over a period of \(T\) trading days. The observed market price \(s_{t}^{(l)}\) of the \(n\)-th stock at the \(t\)-th day follows a stochastic volatility model of \(\log s_{t+1}^{(l)}=\log s_{t}^{(l)}+\frac{r-\frac{1}{2}\left(v_{t}^{(l)}\right) ^{2}}{T}+\frac{v_{t}^{(l)}}{\sqrt{T}},s_{1}^{(l)}>0,\forall 1\leq t<T,1 \leq l\leq L\), where \(r>0\) is the riskless interest rate per day, \(v_{t}^{(l)}\) and \(s_{1}^{(l)}\) are the unobservable independent random volatility process and the constant initial stock price associated with the \(l\)-th stock, respectively [22, 27]. Let \(q_{t}^{(l)}\) and \(q_{1}^{(l)}\) be the the total return at the \(t\)-th day before the market opens and the initial investment associated with the \(l\)-th stock, respectively. The investor maintains a portfolio for each \(q_{t}^{(l)},\) which is parameterized by a row vector \(\mathbf{m}^{(l)}=\left[m^{l,1},\cdots,m^{l,M}\right]\) with \(m^{l,i}\in\left[0,1\right],\forall 1\leq i\leq L,\) being the weight of allocation and \(\sum_{i=1}^{L}m^{l,i}=1\). Specifically, at the \(t\)-th day when the market opens, the investor immediately allocates \(q_{t}^{(l)}\) proportionally to buy the \(N\) stocks according to the weight vector \(\mathbf{m}^{(l)}\). The total systemic risk associated with \(q_{t}^{l}\) during the period between the \(t\)-th day right before market opening and the \((t+1)\)-th day right before market opening is \(\sum_{i=1}^{L}\left(m^{l,i}w_{t}^{(i)}h\right)+1\cdot w_{t+1}^{(l)}\left(24-h \right),\) where \(w_{t}^{i}\) is the per hour risk associated with the \(i\)-th stock in the \(t\)-th day and \(h\) is the total number of trading hours per day. is \(\sum_{i=1}^{L}m^{l,i}e\left(\left(r-\frac{1}{2}\left(v_{t}^{(i)}\right)^{2} \right)\frac{1}{T}+v_{t}^{(i)}\frac{1}{\sqrt{T}}\right)q_{t}^{l}\). The investor then spends all this amount to buy back the \(l\)-th stock and then the \(t\)-th trading day ends. Each stock in the portfolio suffers from a proportionate random i.i.d. systemic risk \(w_{t}^{i}\) per hour, i.e., holding the \(i\)-th stock with a ratio of \(m^{l,i}\) in a portfolio for a total number of \(h\) trading hours in the \(t\)-th day will incur a systemic risk of \(m^{l,i}w_{t}^{(i)}h\). Denote the mean-shifted return as \(\mathbf{r}_{t}=\mathbf{q}_{t}-\mathbb{E}\left[\mathbf{q}_{t}\right]\) and let \(\mathbf{x}_{t}=\left[\begin{array}{c}\mathbf{r}_{t}\\ \mathbf{q}_{t}\end{array}\right]\)._

_The evolution of \(\mathbf{x}_{t}\) can be characterized by the canonical form of_

\[\mathbf{x}_{t+1}=\left(\mathbf{A}+\mathbf{\Delta}_{t}\right) \mathbf{x}_{t}+\mathbf{u}_{t}^{(\mathbf{M})}+\widetilde{\mathbf{w}}_{t}, \tag{20}\] \[\mathbf{u}_{t}^{(\mathbf{M})}=\mathbf{M}\widetilde{\mathbf{w}}_{t -1}\;\;with\;\;\mathbf{B}=\mathbf{I},\mathbf{K}=\mathbf{0},\forall 1\leq t<T. \tag{21}\]

_where \(\mathbf{M}=\frac{h}{24-h}\left[\mathbf{m}^{(1)};\cdots;\mathbf{m}^{(L)} \right],\;\;\mathbf{w}_{t-1}=\left(24-h\right)\left[w_{t}^{(1)},\cdots,w_{t}^ {(L)}\right]^{T},\;\;\widetilde{\mathbf{w}}_{t}=\left[\begin{array}{c} \mathbf{w}_{t}-\mathbb{E}\left[\mathbf{w}_{t}\right]\\ \mathbf{w}_{t}\end{array}\right],\) the state transition matrix \(\mathbf{A}=\mathbf{I}_{2L\times 2L}\) and the policy-dependent state transition perturbation \(\mathbf{\Delta}_{t}\) is given by (22) and (23)._

\[\mathbf{\Delta}_{t}=\left[\begin{array}{cc}\mathbb{E}\left[ \mathbf{V}_{t}^{(\mathbf{M})}\right]-\mathbf{I}_{L\times L}&\mathbf{V}_{t}^{( \mathbf{M})}-\mathbb{E}\left[\mathbf{V}_{t}^{(\mathbf{M})}\right]\\ \mathbf{0}_{L\times L}&\mathbf{V}_{t}^{(\mathbf{M})}-\mathbf{I}_{L\times L} \end{array}\right], \tag{22}\] \[\mathbf{V}_{t}^{(\mathbf{M})}=\mathrm{diag}\left(\left[\sum_{i= 1}^{L}m^{1,i}e^{\left(\frac{r-\frac{1}{2}\left(v_{t}^{(i)}\right)^{2}}{T}+ \frac{v_{t}^{(i)}}{\sqrt{T}}\right)},\cdots,\sum_{i=1}^{L}m^{L,i}e^{\left( \frac{r-\frac{1}{2}\left(v_{t}^{(i)}\right)^{2}}{T}+\frac{v_{t}^{(i)}}{\sqrt {T}}\right)}\right]\right). \tag{23}\]

_The investment risk minimization problem can thus be casted as_

\[\min_{\mathbf{M}\in\mathbb{M}}\;\;C_{T}^{\mathbf{M}}=\mathbb{E}_{\{\mathbf{ \Delta}_{t}\},\{\widetilde{\mathbf{w}}_{t}\}}\left[\sum_{t=1}^{T}\left(\|[ \mathbf{I}_{L},\mathbf{0}_{L\times L}]\cdot\mathbf{x}_{t}\|^{2}+\left\|[ \mathbf{I}_{L},\mathbf{0}_{L\times L}]\cdot\mathbf{u}_{t}^{(\mathbf{M})}\right\| ^{2}\right)\right],\quad s.t.\;(\ref{eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq: eq: eq: eq: eq: eq: eq: eq: eq: eq: eq: eq: eq: eq: eq: eq: eq: eq: eq: eq: eq: eq: eq: eq: eq: eq: eq: eq: eq eq: eq: eq: eq: eq eq: eq: eq: eq eq: eq eq: eq: eq eq: eq: eq: eq: eq eq: eq: eq eq: eq: eq eq: eq: eq eq: eq eq: eq: eq eq: eq: eq eq: eq: eq eq: eq: eq eq: eq: eq eq: eq eq: eq: eq eq: eq: eq eq: eq: eq eq: eq eq: eq: eq eq: eq: eq: eq eq: eq: eq eq: eq eq: eq eq: eq eq: eq eq: eq eq: eqIn the simulation, we set the number of stocks \(L=10\) and the number of trading days \(T=60\). The initial policy \(\mathbf{M}_{0}\) is randomly chosen within the feasible set \(\mathbb{M}=\{\mathbf{M}:\sum_{i=1}^{10}m^{l,i}=1,\forall 1\leq l\leq 10\}\). The entries of noise term \(\mathbf{w}_{t}\) are independently and uniformly drawn from the interval \([0,1]\). For each \(1\leq i\leq 10\) and each \(0\leq t<60\), we first obtain \(\tilde{v}_{t}^{(i)}\) by sampling from a Gaussian distribution, i.e., \(\tilde{v}_{t}^{(i)}\sim\mathcal{N}(\log(\varepsilon_{t}),0.2)\), where \(\varepsilon_{t}\) denotes the sensitivity at \(t\)-th trading day. The \(\tilde{v}_{t}^{(i)}\) is then projected to the interval \([-0.6,0.6]\) to obtain \(v_{t}^{(i)}\) in (23). We let the total number iterations \(N=1000\), and the stepsize \(\eta_{n}\) in Algorithm 1 is set to be \(0.01\), \(\forall 0\leq n\leq 1000\).

The sensitivities are shown as follows:

**Sensitivities with Ascending Sequence.**\(\varepsilon_{\mathrm{a}}\)=[1.25797477e-07 5.03189910e-07 1.13217730e-06 2.01275964e-06 3.14493693e-06 4.52870919e-06 6.16407639e-06 8.05103855e-06 1.01895957e-05 1.25797477e-05 1.52214948e-05 1.81148367e-05 2.12597737e-05 2.46563056e-05 2.83044324e-05 3.22041542e-05 3.63554710e-05 4.07583827e-05 4.54128893e-05 5.03189910e-05 4.66004175e-03 5.35796616e-03 6.12231163e-03 6.95609731e-03 7.86234234e-03 8.84406585e-03 9.90428699e-03 1.10460249e-02 1.22722987e-02 1.35861276e-02 1.49905306e-02 1.64885270e-02 1.80831358e-02 1.97773762e-02 2.15742674e-02 2.34768284e-02 2.54880785e-02 2.76110367e-02 2.98487222e-02 3.22041542e-02 3.3504397e-02 4.66004175e-02 5.00089002e-02 5.35796616e-02 5.73164756e-02 6.12231163e-02 6.53033575e-02 6.95609731e-02 7.39997371e-02 7.86234234e-02 8.34358059e-02 8.84406585e-02 9.36417552e-02 9.90428699e-02 1.04647776e-01 1.10460249e-01 1.16484061e-01 1.22722987e-01 1.16484061e-01 1.29180801e-01 1.35861276e-01

**Sensitivities with Descending Sequence.**\(\varepsilon_{\mathrm{d}}\)=[1.35861276e-01 1.29180801e-01.122722987e-01 1.16484061e-01 1.10460249e-01 1.04647776e-01 9.90428699e-02 9.36417552e-02 8.84406585e-02 8.34358059e-02 7.86234234e-02 7.39997371e-02 6.95609731e-02 6.53033575e-02 6.12231163e-02 5.73164756e-02 5.35796616e-02 5.00089002e-02 4.66004175e-02 4.33504397e-02 3.22041542e-02 2.98487222e-02 2.76110367e-02 2.54880785e-02 2.34768284e-02 2.15742674e-02 1.97773762e-02 1.80831358e-02 1.64885270e-02 1.49095306e-02 1.35861276e-02 1.22722987e-02 1.10460249e-02 9.90428695-03 8.84406585e-03 7.86234234e-03 6.95609731e-03 6.12231163e-03 5.35796616e-03 4.66004175e-03 5.03189190e-05 4.54128893e-05 4.07583827e-05 3.63554710e-05 3.22041542e-05 2.8304324e-05 2.46563056e-05 2.12597737e-05 1.81148367e-05 1.52214948e-05 1.25797477e-05 1.01895957e-05 8.01038555e-06 6.16407639e-06 4.52870919e-06 3.14493693e-06 2.01275964e-06 1.13217730e-06 5.03189910e-07 1.25797477e-07

**Sensitivities with Random Sequence.**\(\varepsilon_{\mathrm{r}}\)=[2.54880785e-02 3.63554710e-05 2.34768284e-02 1.64885270e-02 1.25797477e-07 9.36417552e-02 1.10460249e-02 6.16407639e-06 2.76110367e-02 5.00089002e-02 1.16484061e-01 1.04647776e-01 2.15742674e-02 2.46563056e-05 3.14493693e-06 4.66004175e-03 4.54128893e-05 3.22041542e-02 1.22722987e-02 4.33504397e-02 8.84406585e-03 6.95609731e-03 5.03189910e-05 1.01895957e-05 7.39997371e-02 1.97773762e-02 7.86234234e-02 1.35861276e-02 8.84406585e-02 1.22722987e-01 4.07583827e-05 8.05103855e-06 2.98487222e-02 9.90428699e-0\(\mathbf{u}_{t}^{(\mathbf{M})}\), respectively. We denote \(\nabla_{\mathbf{M}}c_{t}\left(\mathbf{x}_{t}^{(\mathbf{M})},\mathbf{u}_{t}^{( \mathbf{M})}\right)\) as the gradient of \(c_{t}\) w.r.t. the variable \(\mathbf{M}\) in \(\mathbf{x}_{t}^{(\mathbf{M})}\) and \(\mathbf{u}_{t}^{(\mathbf{M})}\) under any given realization of the policy-dependent state transition perturbations \(\left\{\mathbf{\Delta}_{i},0\leq i<t\right\}.\)

Based on the chain rule and the relationship between \(\mathbf{M}\) and the pair \(\left(\mathbf{x}_{t},\mathbf{u}_{t}\right)\) in (7) and (10), the expression of \(\nabla_{\mathbf{M}}c_{t}\left(\mathbf{x}_{t}^{(\mathbf{M})},\mathbf{u}_{t}^{( \mathbf{M})}\right)\) is given by

\[\nabla_{\mathbf{M}}c_{t}\left(\mathbf{x}_{t}^{(\mathbf{M})}, \mathbf{u}_{t}^{(\mathbf{M})}\right) \tag{24}\] \[=\sum_{i=0}^{t-1}\left(\prod_{j=i+1}^{t-1}\left(\mathbf{1}_{j<t} \left(\widetilde{\mathbf{A}}+\mathbf{\Delta}_{j}\right)+\mathbf{1}_{j=t} \mathbf{I}\right)\mathbf{B}\right)^{\top}\nabla_{\mathbf{x}}c_{t}\left( \mathbf{x}_{t}^{(\mathbf{M})},\mathbf{u}_{t}^{(\mathbf{M})}\right)\left( \left[\mathbf{w}\right]_{i-1}^{H}\right)^{\top}\] \[-\sum_{i=0}^{t-1}\left\{\left(\mathbf{K}\prod_{j=i+1}^{t-1}\left( \mathbf{1}_{j<t}\left(\widetilde{\mathbf{A}}+\mathbf{\Delta}_{j}\right)+ \mathbf{1}_{j=t}\mathbf{I}\right)\mathbf{B}\right)^{\top}\nabla_{\mathbf{u}}c_ {t}\left(\mathbf{x}_{t}^{(\mathbf{M})},\mathbf{u}_{t}^{(\mathbf{M})}\right) \left(\left[\mathbf{w}\right]_{i-1}^{H}\right)^{\top}\right\}\] \[+\nabla_{\mathbf{u}}c_{t}\left(\mathbf{x}_{t}^{(\mathbf{M})}, \mathbf{u}_{t}^{(\mathbf{M})}\right)\left(\left[\mathbf{w}\right]_{t-1}^{H} \right)^{\top}.\]

For the ease of notation, without ambiguity we also occasionally use the notation \(c_{t}\left(\mathbf{M};\left\{\mathbf{\Delta}_{i}\right\}_{0\leq i<t}\right)\) to denote \(c_{t}\left(\mathbf{x}_{t}^{(\mathbf{M})},\mathbf{u}_{t}^{(\mathbf{M})}\right)\) under a sequence of policy-dependent state transition perturbations \(\left\{\mathbf{\Delta}_{i},0\leq i<t\right\}.\) In this case, \(\nabla_{\mathbf{M}}c_{t}\left(\mathbf{M};\left\{\mathbf{\Delta}_{i}\right\}_ {0\leq i<t}\right)\) denote the gradient taken w.r.t. the first argument \(\mathbf{M}\).

Moreover, the total cost function can be represented as

\[J_{T}\left(\mathbf{M};\left\{\mathbf{\Delta}_{t}\right\}_{0\leq t<T}\right)= \sum_{t=0}^{T}c_{t}\left(\mathbf{M};\left\{\mathbf{\Delta}_{i}\right\}_{0\leq i <t}\right). \tag{25}\]

It is clear that

\[C_{T}\left(\mathbf{M};\mathbf{M}^{\prime}\right)=\mathbb{E}_{\mathbf{\Delta}_ {0},\left\{\mathbf{\Delta}_{i}\sim\mathcal{D}_{t}\left(\mathbf{M}^{\prime} \right)\right\}_{0\leq i<T},\left\{\mathbf{w}_{i}\right\}_{0\leq i<T}}J_{T} \left(\mathbf{M};\left\{\mathbf{\Delta}_{t}\right\}_{0\leq t<T}\right). \tag{26}\]

Unless otherwise specified, \(\nabla J_{T}\left(\mathbf{M};\left\{\mathbf{\Delta}_{t}\right\}_{0\leq t<T}\right)\) and \(\nabla C_{T}\left(\mathbf{M};\mathbf{M}^{\prime}\right)\) denotes the gradient taken w.r.t. the first argument \(\mathbf{M}\).

**Convexity.** Denote the per stage expected cost

\[f_{t}\left(\mathbf{M};\mathbf{M}_{1}\right)=\mathbb{E}_{\mathbf{x}_{0},\left\{ \mathbf{\Delta}_{i}\sim\mathcal{D}_{i}\left(\mathbf{M}_{1}\right)\right\}_{0 \leq i<t},\left\{\mathbf{w}_{i}\right\}_{0\leq i<t}}\left[c_{t}\left(\mathbf{M };\left\{\mathbf{\Delta}_{i}\right\}_{0\leq i<t}\right)\right],\forall 1\leq t\leq T,\]

where the distribution of policy-dependent perturbation is changed from \(\mathbf{\Delta}_{i}\sim\mathcal{D}_{i}\left(\mathbf{M}\right)\) to \(\mathbf{\Delta}_{i}\sim\mathcal{D}_{i}\left(\mathbf{M}_{1}\right)\), \(\forall 0\leq i<t\).

We have the following lemma characterizing the convexity of \(f_{t}\left(\mathbf{M};\mathbf{M}_{1}\right),\forall 1\leq t\leq T\).

**Lemma B.1**: _The per stage expected cost \(f_{t}\left(\mathbf{M};\mathbf{M}^{\prime}\right)\) is a convex function of \(\mathbf{M}\), \(\forall\mathbf{M},\mathbf{M}^{\prime}\in\mathbb{M}\), \(\forall 1\leq t\leq T\)._

_Proof._ We prove this lemma following the convex property of the function \(c_{t}\left(\mathbf{x},\mathbf{u}\right)\) in Assumption A 4. Let \(0<\theta<1\) and \(\mathbf{M}_{1},\mathbf{M}_{2},\mathbf{M}^{\prime}\in\mathbb{M}\). Consider the weighted policy \(\theta\mathbf{M}_{1}+\left(1-\theta\right)\mathbf{M}_{2}\), we have

\[\mathbf{x}_{t}^{\left(\theta\mathbf{M}_{1}+\left(1-\theta\right) \mathbf{M}_{2}\right)}=\prod_{i=0}^{t-1}\left(\widetilde{\mathbf{A}}+\mathbf{ \Delta}_{i}\right)\mathbf{x}_{0}+\sum_{i=0}^{t-1}\prod_{j=i+1}^{t-1}\left( \mathbf{1}_{j<t}\left(\widetilde{\mathbf{A}}+\mathbf{\Delta}_{j}\right)+ \mathbf{1}_{j=t}\mathbf{I}\right)\mathbf{B} \tag{27}\] \[\cdot\left(\theta\mathbf{M}_{1}+\left(1-\theta\right)\mathbf{M}_{ 2}\right)\mathbf{M}\left[\mathbf{w}\right]_{i-1}^{H}+\sum_{i=0}^{t-1}\prod_{j= i+1}^{t-1}\left(\mathbf{1}_{j<t}\left(\widetilde{\mathbf{A}}+\mathbf{\Delta}_{j} \right)+\mathbf{1}_{j=t}\mathbf{I}\right)\mathbf{w}_{i}\] \[=\theta\left(\prod_{i=0}^{t-1}\left(\widetilde{\mathbf{A}}+ \mathbf{\Delta}_{i}\right)\mathbf{x}_{0}+\sum_{i=0}^{t-1}\prod_{j=i+1}^{t-1} \left(\mathbf{1}_{j<t}\left(\widetilde{\mathbf{A}}+\mathbf{\Delta}_{j}\right) +\mathbf{1}_{j=t}\mathbf{I}\right)\mathbf{B}\mathbf{M}_{1}\left[\mathbf{w} \right]_{i-1}^{H}\] \[+\sum_{i=0}^{t-1}\prod_{j=i+1}^{t-1}\left(\mathbf{1}_{j<t}\left( \widetilde{\mathbf{A}}+\mathbf{\Delta}_{j}\right)+\mathbf{1}_{j=t}\mathbf{I} \right)\mathbf{w}_{i}\right)+\left(1-\theta\right)\] \[\cdot\left(\prod_{i=0}^{t-1}\left(\widetilde{\mathbf{A}}+ \mathbf{\Delta}_{i}\right)\mathbf{x}_{0}+\sum_{i=0}^{t-1}\prod_{j=i+1}^{t-1} \left(\mathbf{1}_{j<t}\left(\widetilde{\mathbf{A}}+\mathbf{\Delta}_{j}\right) +\mathbf{1}_{j=t}\mathbf{I}\right)\mathbf{B}\mathbf{M}_{2}\left[\mathbf{w} \right]_{i-1}^{H}\] \[+\sum_{i=0}^{t-1}\prod_{j=i+1}^{t-1}\left(\mathbf{1}_{j<t}\left( \widetilde{\mathbf{A}}+\mathbf{\Delta}_{j}\right)+\mathbf{1}_{j=t}\mathbf{I} \right)\mathbf{w}_{i}\right)\] \[=\theta\mathbf{x}_{t}^{\mathbf{M}_{1}}+\left(1-\theta\right) \mathbf{x}_{t}^{\mathbf{M}_{2}}.\]

As a result,

\[f_{t}\left(\theta\mathbf{M}_{1}+\left(1-\theta\right)\mathbf{M}_ {2};\mathbf{M}^{\prime}\right) \tag{28}\] \[=\mathbb{E}_{\mathbf{x}_{0},\left\{\mathbf{\Delta}_{i}\sim\mathcal{ D}_{i}\left(\mathbf{M}^{\prime}\right)\right\}_{0\leq i<t},\left\{\mathbf{w}_{i} \right\}_{0\leq i<t}}\left[c_{t}\left(\theta\mathbf{x}_{t}^{\mathbf{M}_{1}}+ \left(1-\theta\right)\mathbf{x}_{t}^{\mathbf{M}_{2}},\theta\mathbf{u}_{t}^{ \mathbf{M}_{1}}+\left(1-\theta\right)\mathbf{u}_{t}^{\mathbf{M}_{2}}\right)\right]\] \[\stackrel{{\left(28.a\right)}}{{\leq}}\mathbb{E}_{ \mathbf{x}_{0},\left\{\mathbf{\Delta}_{i}\sim\mathcal{D}_{i}\left(\mathbf{M}^{ \prime}\right)\right\}_{0\leq i<t},\left\{\mathbf{w}_{i}\right\}_{0\leq i<t}} \left[\theta c_{t}\left(\mathbf{x}_{t}^{\mathbf{M}_{1}},\mathbf{u}_{t}^{ \mathbf{M}_{1}}\right)+\left(1-\theta\right)c_{t}\left(\mathbf{x}_{t}^{ \mathbf{M}_{2}},\mathbf{u}_{t}^{\mathbf{M}_{2}}\right)\right]\] \[=\theta f_{t}\left(\mathbf{M}_{1};\mathbf{M}^{\prime}\right)+\left( 1-\theta\right)f_{t}\left(\mathbf{M}_{2};\mathbf{M}^{\prime}\right),\]

where inequality \(\left(28.a\right)\) holds becasue of the convexity of \(c_{t}\left(\mathbf{x},\mathbf{u}\right)\). \(\square\)

We next have a key lemma characterizing the strong convexity of \(f_{t}\left(\mathbf{M};\mathbf{M}^{\prime}\right),\forall H\leq t\leq T\).

**Lemma B.2**: _The per stage expected cost \(f_{t}\left(\mathbf{M};\mathbf{M}^{\prime}\right)\) is a \(\min\left\{\frac{\mu}{2},\frac{\mu\sigma^{2}\gamma^{2}}{64\kappa^{t}0}\right\}\)-strongly convex function of \(\mathbf{M},\,\forall\mathbf{M},\mathbf{M}^{\prime}\in\mathbb{M},\,\forall H \leq t\leq T\)._

_Proof._ We prove this lemma following the strong convexity of the function \(c_{t}\left(\mathbf{x},\mathbf{u}\right)\) in Assumption A 4. Let \(\mathbf{M}_{1},\mathbf{M}_{2},\mathbf{M}^{\prime}\in\mathbb{M}\). Consider a time step \(t\) such that \(H\leq t\leq T\). For any given realizations of \(\left\{\mathbf{\Delta}_{i}\right\}_{0\leq i<t}\), where \(\mathbf{\Delta}_{i}\sim\mathcal{D}_{i}\left(\mathbf{M}^{\prime}\right),\forall 0 \leq i<t,\) we have

\[c_{t}\left(\mathbf{x}_{t}^{\left(\mathbf{M}_{1}\right)},\mathbf{u}_ {t}^{\left(\mathbf{M}_{1}\right)}\right)-c_{t}\left(\mathbf{x}_{t}^{\left( \mathbf{M}_{2}\right)},\mathbf{u}_{t}^{\left(\mathbf{M}_{2}\right)}\right) \tag{29}\] \[\stackrel{{\left(29.a\right)}}{{\geq}}\left[\begin{array} []{c}\nabla_{\mathbf{x}}c_{t}\left(\mathbf{x}_{t}^{\left(\mathbf{M}_{2} \right)},\mathbf{u}_{t}^{\left(\mathbf{M}_{2}\right)}\right)\\ \nabla_{\mathbf{u}}c_{t}\left(\mathbf{x}_{t}^{\left(\mathbf{M}_{2}\right)}, \mathbf{u}_{t}^{\left(\mathbf{M}_{2}\right)}\right)\end{array}\right]^{T} \left[\begin{array}{c}\mathbf{x}_{t}^{\left(\mathbf{M}_{1}\right)}-\mathbf{x}_{t}^{ \left(\mathbf{M}_{2}\right)}\\ \mathbf{u}_{t}^{\left(\mathbf{M}_{1}\right)}-\mathbf{u}_{t}^{\left(\mathbf{M}_{2} \right)}\end{array}\right]+\frac{\mu}{2}\left\|\begin{array}{c}\mathbf{x}_{t}^{ \left(\mathbf{M}_{1}\right)}-\mathbf{x}_{t}^{\left(\mathbf{M}_{2}\right)}\\ \mathbf{u}_{t}^{\left(\mathbf{M}_{1}\right)}-\mathbf{u}_{t}^{\left(\mathbf{M}_{2} \right)}\end{array}\right\|^{2},\]

where inequality \(\left(29.a\right)\) holds because of the strong convexity assumption of \(c_{t}\) in Assumption A4.

Based on the representations of the pair \(\left(\mathbf{x}_{t},\mathbf{u}_{t}\right)\) in (7) and (10), it follows that

\[\mathbf{x}_{t}^{\left(\mathbf{M}_{1}\right)}-\mathbf{x}_{t}^{\left( \mathbf{M}_{2}\right)}= \sum_{i=0}^{t-1}\prod_{j=i+1}^{t-1}\left(\mathbf{1}_{j<t}\left( \widetilde{\mathbf{A}}+\mathbf{\Delta}_{j}\right)+\mathbf{1}_{j=t}\mathbf{I} \right)\mathbf{B}\left(\mathbf{M}_{1}-\mathbf{M}_{2}\right)\left[\mathbf{w} \right]_{i-1}^{H} \tag{30}\] \[\mathbf{u}_{t}^{\left(\mathbf{M}_{1}\right)}-\mathbf{u}_{t}^{ \left(\mathbf{M}_{2}\right)}= -\mathbf{K}\sum_{i=0}^{t-1}\prod_{j=i+1}^{t-1}\left(\mathbf{1}_{ j<t}\left(\widetilde{\mathbf{A}}+\mathbf{\Delta}_{j}\right)+\mathbf{1}_{j=t} \mathbf{I}\right)\mathbf{B}\left(\mathbf{M}_{1}-\mathbf{M}_{2}\right)\left[ \mathbf{w}\right]_{i-1}^{H}\] (31) \[+\left(\mathbf{M}_{1}-\mathbf{M}_{2}\right)\left[\mathbf{w} \right]_{t-1}^{H}.\]

Therefore, we obtain

\[\nabla_{\mathbf{x}}c_{t}\left(\mathbf{x}_{t}^{\left(\mathbf{M}_{2} \right)},\mathbf{u}_{t}^{\left(\mathbf{M}_{2}\right)}\right) \tag{32}\] \[= \sum_{i=0}^{t-1}\nabla_{\mathbf{x}}^{\top}c_{t}\left(\mathbf{x}_{ t}^{\left(\mathbf{M}_{2}\right)},\mathbf{u}_{t}^{\left(\mathbf{M}_{2}\right)} \right)\left(\prod_{j=i+1}^{t-1}\left(\mathbf{1}_{j<t}\left(\widetilde{\mathbf{ A}}+\mathbf{\Delta}_{j}\right)+\mathbf{1}_{j=t}\mathbf{I}\right)\mathbf{B} \left(\mathbf{M}_{1}-\mathbf{M}_{2}\right)\left[\mathbf{w}\right]_{i-1}^{H}\right)\] \[+ \sum_{i=0}^{t-1}\nabla_{\mathbf{u}}^{\top}c_{t}\left(\mathbf{x}_{ t}^{\left(\mathbf{M}_{2}\right)},\mathbf{u}_{t}^{\left(\mathbf{M}_{2}\right)} \right)\left(-\mathbf{K}\sum_{i=0}^{t-1}\prod_{j=i+1}^{t-1}\left(\mathbf{1}_{j <t}\left(\widetilde{\mathbf{A}}+\mathbf{\Delta}_{j}\right)+\mathbf{1}_{j=t} \mathbf{I}\right)\mathbf{B}\left(\mathbf{M}_{1}-\mathbf{M}_{2}\right)\left[ \mathbf{w}\right]_{i-1}^{H}\] \[+ \left(\mathbf{M}_{1}-\mathbf{M}_{2}\right)\left[\mathbf{w}\right]_ {t-1}^{H}\right)\] \[= \mathrm{Tr}\left(\left(\sum_{i=0}^{t-1}\left[\mathbf{w}\right]_{i -1}^{H}\nabla_{\mathbf{x}}^{\top}c_{t}\left(\mathbf{x}_{t}^{\left(\mathbf{M}_ {2}\right)},\mathbf{u}_{t}^{\left(\mathbf{M}_{2}\right)}\right)\prod_{j=i+1}^{ t-1}\left(\mathbf{1}_{j<t}\left(\widetilde{\mathbf{A}}+\mathbf{\Delta}_{j} \right)+\mathbf{1}_{j=t}\mathbf{I}\right)\mathbf{B}\right)\left(\mathbf{M}_{1} -\mathbf{M}_{2}\right)\right.\] \[+ \left.\left[\mathbf{w}\right]_{t-1}^{H}\nabla_{\mathbf{u}}^{\top} c_{t}\left(\mathbf{x}_{t}^{\left(\mathbf{M}_{2}\right)},\mathbf{u}_{t}^{\left( \mathbf{M}_{2}\right)}\right)\right)\left(\mathbf{M}_{1}-\mathbf{M}_{2}\right)\right)\] \[= \mathrm{Tr}\left(\nabla_{\mathbf{M}_{2}}^{\top}c_{t}\left(\mathbf{ x}_{t}^{\left(\mathbf{M}_{2}\right)},\mathbf{u}_{t}^{\left(\mathbf{M}_{2}\right)} \right)\left(\mathbf{M}_{1}-\mathbf{M}_{2}\right)\right).\]

Substitute (32) back into (29), we have

\[c_{t}\left(\mathbf{x}_{t}^{\left(\mathbf{M}_{1}\right)},\mathbf{u }_{t}^{\left(\mathbf{M}_{1}\right)}\right)-c_{t}\left(\mathbf{x}_{t}^{\left( \mathbf{M}_{2}\right)},\mathbf{u}_{t}^{\left(\mathbf{M}_{2}\right)}\right)\geq \mathrm{Tr}\left(\nabla_{\mathbf{M}_{2}}^{\top}c_{t}\left( \mathbf{x}_{t}^{\left(\mathbf{M}_{2}\right)},\mathbf{u}_{t}^{\left(\mathbf{M }_{2}\right)}\right)\left(\mathbf{M}_{1}-\mathbf{M}_{2}\right)\right) \tag{33}\] \[+\frac{\mu}{2}\left(\left\|\mathbf{x}_{t}^{\left(\mathbf{M}_{1} \right)}-\mathbf{x}_{t}^{\left(\mathbf{M}_{2}\right)}\right\|^{2}+\left\| \mathbf{u}_{t}^{\left(\mathbf{M}_{1}\right)}-\mathbf{u}_{t}^{\left(\mathbf{M}_{2 }\right)}\right\|^{2}\right).\]

Taking full expectation on both sides of (33), it follows

\[f_{t}\left(\mathbf{M}_{1};\mathbf{M}^{\prime}\right)-f_{t}\left( \mathbf{M}_{1};\mathbf{M}^{\prime}\right)\geq\mathrm{Tr}\left(\nabla^{\top}f_{t }\left(\mathbf{M}_{2};\mathbf{M}^{\prime}\right)\cdot\left(\mathbf{M}_{1}- \mathbf{M}_{2}\right)\right) \tag{34}\] \[+\frac{\mu}{2}\mathbb{E}_{\mathbf{x}_{0},\left\{\mathbf{\Delta}_{i} \sim\mathcal{D}_{i}\left(\mathbf{M}^{\prime}\right)\right\}_{0\leq i<t},\left\{ \mathbf{w}_{i}\right\}_{0\leq i<t}}\left[\left\|\mathbf{x}_{t}^{\left(\mathbf{M }_{1}\right)}-\mathbf{x}_{t}^{\left(\mathbf{M}_{2}\right)}\right\|^{2}+ \left\|\mathbf{u}_{t}^{\left(\mathbf{M}_{1}\right)}-\mathbf{u}_{t}^{\left( \mathbf{M}_{2}\right)}\right\|^{2}\right].\]

[MISSING_PAGE_FAIL:19]

where

\[\Omega= \left({\bf I}_{H}\otimes{\bf B}^{\top}\right)\Psi\left({\bf I}_{H} \otimes{\bf B}\right)+\left({\bf I}_{H}\otimes{\bf B}^{\top}\right)\widetilde{ \Psi}\left({\bf I}_{H}\otimes{\bf B}^{\top}\right) \tag{40}\] \[-\Theta\left({\bf I}_{H}\otimes{\bf B}\right)-\left({\bf I}_{H} \otimes{\bf B}^{\top}\right)\Theta^{\top}+{\bf I}_{H_{d_{u}}}.\]

Based on Lemma F.1 and F.2 in [2], we have, \(\forall H\leq t\leq T,\,\Psi\geq\frac{1}{4\kappa^{4}}{\bf I}_{Hd_{x}}\) and \(\left\|\Theta\right\|\leq\gamma^{-1}\kappa^{3}\). Therefore, if \(\left\|{\bf I}_{H}\otimes{\bf B}\right\|\geq\frac{\gamma}{4\kappa^{3}}\), then

\[\Omega\geq\frac{1}{4\kappa^{4}}{\bf I}_{Hd_{x}}\left(\frac{\gamma}{4\kappa^{3} }\right)^{2}=\frac{\gamma^{2}}{64\kappa^{10}}{\bf I}_{Hd_{x}}. \tag{41}\]

Otherwise, if \(\left\|{\bf I}_{H}\otimes{\bf B}\right\|<\frac{\gamma}{4\kappa^{3}}\), then

\[\Omega\geq{\bf I}_{Hd_{u}}-\Theta\left({\bf I}_{H}\otimes{\bf B} \right)-\left({\bf I}_{H}\otimes{\bf B}^{\top}\right)\Theta^{\top}, \tag{42}\] \[\left\|\Omega\right\|\geq 1-\gamma^{-1}\kappa^{3}\frac{\gamma}{4 \kappa^{3}}-\gamma^{-1}\kappa^{3}\frac{\gamma}{4\kappa^{3}}=\frac{1}{2}. \tag{43}\]

Combine (41) and (43), we have \(\left\|\Omega\right\|\geq\min\left\{\frac{1}{2},\frac{\gamma^{2}}{64\kappa^{10 }}\right\}\). As a result,

\[\mathbb{E}_{{\bf x}_{0},\left\{{\bf\Delta}_{i}\sim{\bf D}_{i}({ \bf M}^{\prime})\right\}_{0\leq i<t},\left\{{\bf w}_{i}\right\}_{0\leq i<t}} \left[\left\|{\bf x}_{t}^{({\bf M}_{1})}-{\bf x}_{t}^{({\bf M}_{2})}\right\|^ {2}+\left\|{\bf u}_{t}^{({\bf M}_{1})}-{\bf u}_{t}^{({\bf M}_{2})}\right\|^{2 }\right] \tag{44}\] \[=\delta_{\bf M}^{\top}\left(\Omega\otimes\mathbb{E}\left[{\bf w}_ {t}{\bf w}_{t}^{\top}\right]\right)\delta_{\bf M}\geq\delta_{\bf M}\left\| \Omega\right\|\sigma^{2}\geq\min\left\{\frac{\sigma^{2}}{2},\frac{\gamma^{2} \sigma^{2}}{64\kappa^{10}}\right\}\left\|{\bf M}_{1}-{\bf M}_{2}\right\|_{F}^{ 2}.\]

Substitute (44) back into (34), it follows that

\[f_{t}\left({\bf M}_{1};{\bf M}^{\prime}\right)-f_{t}\left({\bf M }_{1};{\bf M}^{\prime}\right)\geq\operatorname{Tr}\left(\nabla^{\top}f_{t} \left({\bf M}_{2};{\bf M}^{\prime}\right)\cdot({\bf M}_{1}-{\bf M}_{2})\right) \tag{45}\] \[+\frac{\min\left\{\frac{\omega\sigma^{2}}{2},\frac{\mu\gamma^{2} \sigma^{2}}{64\kappa^{10}}\right\}}{2}\left\|{\bf M}_{1}-{\bf M}_{2}\right\|_{ F}^{2}.\]

Therefore, Lemma B.2 is proved. \(\square\)

**Properties of Gradient.** The following lemma provides upper bounds for the norm of gradients \(\left\|\nabla_{\bf x}c_{t}\left({\bf x}_{t}^{({\bf M})},{\bf u}_{t}^{({\bf M})} \right)\right\|\) and \(\left\|\nabla_{\bf u}c_{t}\left({\bf x}_{t}^{({\bf M})},{\bf u}_{t}^{({\bf M}) }\right)\right\|.\)

**Lemma B.3**: _The gradients of the per stage cost \(c_{t}\left({\bf x}_{t}^{({\bf M})},{\bf u}_{t}^{({\bf M})}\right),\forall 1\leq t \leq T,\) satifies_

\[\left\|\nabla_{\bf x}c_{t}\left({\bf x}_{t}^{({\bf M})},{\bf u} _{t}^{({\bf M})}\right)\right\| \leq x_{0}\kappa^{2}G\alpha_{t}+\kappa^{2}GW\left(\left\|{\bf B} \right\|HM+1\right)\beta_{t}, \tag{46}\] \[\left\|\nabla_{\bf u}c_{t}\left({\bf x}_{t}^{({\bf M})},{\bf u}_{t }^{({\bf M})}\right)\right\| \leq x_{0}\kappa^{3}G\alpha_{t}+\kappa^{3}GW\left(\left\|{\bf B} \right\|HM+1\right)\beta_{t}+GMHW, \tag{47}\]

_where \(\alpha_{t}=\prod_{i=0}^{t-1}\left(1-\gamma+\kappa^{2}\xi_{i}\right)\) and \(\beta_{t}=\sum_{i=0}^{t-1}\prod_{j=i+1}^{t-1}\left({\bf 1}_{j<t}\left(1-\gamma+ \kappa^{2}\xi_{j}\right)+{\bf 1}_{j=t}\right).\)_

_Proof._ We first provide upper bounds for \(\left\|{\bf x}_{t}\right\|\) and \(\left\|{\bf u}_{t}\right\|.\) From the evolution of \({\bf x}_{t}\) in (10), we obtain

\[\left\|{\bf x}_{t}\right\|\leq\left\|\prod_{i=0}^{t-1}\left({\bf \widetilde{A}}+{\bf\Delta}_{i}\right){\bf x}_{0}\right\|+\left\|\sum_{i=0}^{t-1 }\prod_{j=i+1}^{t-1}\left({\bf 1}_{j<t}\left({\bf\widetilde{A}}+{\bf\Delta}_{j}\right)+{\bf 1}_{j=t}{ \bf I}\right){\bf B}{\bf M}\left[{\bf w}\right]_{i-1}^{H}\right\| \tag{48}\] \[+\left\|\sum_{i=0}^{t-1}\prod_{j=i+1}^{t-1}\left({\bf 1}_{j<t} \left({\bf\widetilde{A}}+{\bf\Delta}_{j}\right)+{\bf 1}_{j=t}{\bf I}\right){\bf w}_{i} \right\|\leq x_{0}\kappa^{2}\prod_{i=0}^{t-1}\left(1-\gamma+\kappa^{2}\left\|{ \bf\Delta}_{i}\right\|\right)\] \[+\kappa^{2}W\left(\left\|{\bf B}\right\|HM+1\right)\sum_{i=0}^{t-1 }\prod_{j=i+1}^{t-1}\left\|{\bf 1}_{j<t}\left(1-\gamma+\kappa^{2}\left\|{\bf\Delta}_{j} \right\|\right)+{\bf 1}_{j=t}{\bf I}\right\|,\] \[\left\|{\bf u}_{t}\right\|\leq\kappa\left\|{\bf x}_{t}\right\|+MHW. \tag{49}\]Lemma B.3 follows by noting that \(\left\|\mathbf{\Delta}_{t}\right\|\leq\xi_{t},\forall 0\leq t\leq T,\forall\mathbf{M} \in\mathbb{M}\), and whenever \(\left\|\mathbf{x}_{t}\right\|,\left\|\mathbf{u}_{t}\right\|\leq D\), we have \(\left\|\nabla_{\mathbf{x}}c_{t}\left(\mathbf{x}_{t}^{(\mathbf{M})},\mathbf{u}_ {t}^{(\mathbf{M})}\right)\right\|,\left\|\nabla_{\mathbf{u}}c_{t}\left( \mathbf{x}_{t}^{(\mathbf{M})},\mathbf{u}_{t}^{(\mathbf{M})}\right)\right\|\leq GD\). \(\square\)

We next prove that the variance of the gradient \(\nabla_{\mathbf{M}}c_{t}\left(\mathbf{x}_{t}^{(\mathbf{M})},\mathbf{u}_{t}^{( \mathbf{M})}\right)\) is bounded.

**Lemma B.4**: _There exists a \(\vartheta_{t}>0,\forall 1\leq t\leq T,\) such that_

\[\mathbb{E}_{\mathbf{x}_{0},\{\mathbf{\Delta}_{i}\sim\mathcal{D}_{ i}(\mathbf{M})\}_{0\leq i<t},\{\mathbf{w}_{i}\}_{0\leq i<t}}\left[\left\| \nabla_{\mathbf{M}}c_{t}\left(\mathbf{x}_{t}^{(\mathbf{M})},\mathbf{u}_{t}^{ (\mathbf{M})}\right)\right\|\right\| \tag{50}\] \[-\left.\left.\mathbb{E}_{\mathbf{x}_{0},\{\mathbf{\Delta}_{i} \sim\mathcal{D}_{i}(\mathbf{M})\}_{0\leq i<t}},\{\mathbf{w}_{i}\}_{0\leq i<t} \left[\nabla_{\mathbf{M}}c_{t}\left(\mathbf{x}_{t}^{(\mathbf{M})},\mathbf{u}_ {t}^{(\mathbf{M})}\right)\right]\right\|_{F}^{2}\right]\leq\vartheta_{t}.\]

_Proof._ Based on the expression of \(\nabla_{\mathbf{M}}c_{t}\left(\mathbf{x}_{t}^{(\mathbf{M})},\mathbf{u}_{t}^{( \mathbf{M})}\right)\) in (24), we have

\[\left\|\nabla_{\mathbf{M}}c_{t}\left(\mathbf{x}_{t}^{(\mathbf{M}) },\mathbf{u}_{t}^{(\mathbf{M})}\right)\right\| \tag{51}\] \[\leq\left\|\mathbf{B}\right\|HW\sum_{i=0}^{t-1}\left\|\prod_{j=i+1 }^{t-1}\left(\mathbf{1}_{j<t}\left(\widetilde{\mathbf{A}}+\mathbf{\Delta}_{j} \right)+\mathbf{1}_{j=t}\mathbf{I}\right)\right\|\left\|\nabla_{\mathbf{x}}c_ {t}\left(\mathbf{x}_{t}^{(\mathbf{M})},\mathbf{u}_{t}^{(\mathbf{M})}\right)\right\|\] \[+\kappa\left\|\mathbf{B}\right\|HW\sum_{i=0}^{t-1}\left\|\prod_{ j=i+1}^{t-1}\left(\mathbf{1}_{j<t}\left(\widetilde{\mathbf{A}}+\mathbf{ \Delta}_{j}\right)+\mathbf{1}_{j=t}\mathbf{I}\right)\right\|\left\|\nabla_{ \mathbf{u}}c_{t}\left(\mathbf{x}_{t}^{(\mathbf{M})},\mathbf{u}_{t}^{(\mathbf{ M})}\right)\right\|\] \[+HW\left\|\nabla_{\mathbf{u}}c_{t}\left(\mathbf{x}_{t}^{(\mathbf{ M})},\mathbf{u}_{t}^{(\mathbf{M})}\right)\right\|\] \[\leq\kappa^{2}\left\|\mathbf{B}\right\|HW\beta_{t}\left\|\nabla_ {\mathbf{x}}c_{t}\left(\mathbf{x}_{t}^{(\mathbf{M})},\mathbf{u}_{t}^{(\mathbf{ M})}\right)\right\|+\left(\kappa^{3}\left\|\mathbf{B}\right\|\beta_{t}+1\right)HW \left\|\nabla_{\mathbf{u}}c_{t}\left(\mathbf{x}_{t}^{(\mathbf{M})},\mathbf{u} _{t}^{(\mathbf{M})}\right)\right\|\] \[\stackrel{{\eqref{eq:w_t_t_1}}}{{\leq}}\left( \kappa\left\|\mathbf{B}\right\|HW\beta_{t}+\kappa^{3}\left\|\mathbf{B}\right\| \beta_{t}+1\right)\left(x_{0}\kappa^{3}G\alpha_{t}+\kappa^{3}GW\left(\left\| \mathbf{B}\right\|HM+1\right)\beta_{t}\right)\] \[+\left(\kappa^{3}\left\|\mathbf{B}\right\|\beta_{t}+1\right)GMHW,\]

where inequality \(\eqref{eq:w_t_t_1}\) holds because of the gradient norm bounds in Lemma B.3.

Further note that

\[\mathbb{E}\left[\left\|\nabla_{\mathbf{M}}c_{t}\left(\mathbf{x}_ {t}^{(\mathbf{M})},\mathbf{u}_{t}^{(\mathbf{M})}\right)-\mathbb{E}\left[ \nabla_{\mathbf{M}}c_{t}\left(\mathbf{x}_{t}^{(\mathbf{M})},\mathbf{u}_{t}^{( \mathbf{M})}\right)\right]\right\|_{F}^{2}\right]\leq\mathbb{E}\left[\left\| \nabla_{\mathbf{M}}c_{t}\left(\mathbf{x}_{t}^{(\mathbf{M})},\mathbf{u}_{t}^{( \mathbf{M})}\right)\right\|_{F}^{2}\right] \tag{52}\] \[\leq d_{x}^{2}H\mathbb{E}\left[\left\|\nabla_{\mathbf{M}}c_{t} \left(\mathbf{x}_{t}^{(\mathbf{M})},\mathbf{u}_{t}^{(\mathbf{M})}\right) \right\|^{2}\right]\]

The desired result follows by substituting (51) into (52) and letting

\[\vartheta_{t}=d_{x}^{2}H\left(\left(\kappa\left\|\mathbf{B} \right\|HW\beta_{t}+\kappa^{3}\left\|\mathbf{B}\right\|\beta_{t}+1\right) \left(x_{0}\kappa^{3}G\alpha_{t}+\kappa^{3}GW\left(\left\|\mathbf{B}\right\| HM+1\right)\beta_{t}\right)\right. \tag{53}\] \[+\left(\kappa^{3}\left\|\mathbf{B}\right\|\beta_{t}+1\right)GMHW \right))\,.\]

\(\square\)

The next lemma characterizes the difference between the gradients under any two different polices \(\mathbf{M}\) and \(\mathbf{M}^{\prime}\).

**Lemma B.5**: _For any given two policies \(\mathbf{M},\mathbf{M}^{\prime}\in\mathbb{M}\), the differences between the gradients satify, \(\forall 1\leq t\leq T,\)_

\[\left\|\nabla_{\mathbf{x}}c_{t}\left(\mathbf{x}_{t}^{(\mathbf{M})},\mathbf{u}_{t}^{(\mathbf{M})}\right)-\nabla_{\mathbf{x}}c_{t}\left(\mathbf{x} _{t}^{(\mathbf{M}^{\prime})},\mathbf{u}_{t}^{(\mathbf{M}^{\prime})}\right)\right\|\] \[+\left\|\nabla_{\mathbf{u}}c_{t}\left(\mathbf{x}_{t}^{(\mathbf{M})},\mathbf{u}_{t}^{(\mathbf{M})}\right)-\nabla_{\mathbf{u}}c_{t}\left(\mathbf{x} _{t}^{(\mathbf{M}^{\prime})},\mathbf{u}_{t}^{(\mathbf{M}^{\prime})}\right)\right\| \tag{54}\] \[\leq\varsigma\left(\left(1+\kappa\right)\kappa^{2}HW\beta_{t}+HW \right)\left\|\mathbf{M}-\mathbf{M}^{\prime}\right\|\] \[+\varsigma\left(1+\kappa\right)\kappa^{2}\left(1-\gamma\right)^{- 1}\left(x_{0}\alpha_{t}+\left(\left\|\mathbf{B}\right\|HM+1\right)W\beta_{t} \right)\sum_{i=0}^{t-1}\left\|\mathbf{\Delta}_{i}-\mathbf{\Delta}_{i}^{\prime }\right\|,\]

_where \(\mathbf{\Delta}_{i}\) and \(\mathbf{\Delta}_{i}^{\prime},\forall 0\leq i<t,\) denotes the policy-dependent state transition perturbations under the policy \(\mathbf{M}\) and \(\mathbf{M}^{\prime},\) respectively._

_Proof._ Recall the smoothness of the cost function \(c_{t}\left(\mathbf{x},\mathbf{u}\right)\) in A 5, i.e.,

\[\left\|\nabla_{\mathbf{x}}c_{t}\left(\mathbf{x}_{1},\mathbf{u}_{ 1}\right)-\nabla_{\mathbf{x}}c_{t}\left(\mathbf{x}_{2},\mathbf{u}_{2}\right) \right\|+\left\|\nabla_{\mathbf{u}}c_{t}\left(\mathbf{x}_{1},\mathbf{u}_{1} \right)-\nabla_{\mathbf{u}}c_{t}\left(\mathbf{x}_{2},\mathbf{u}_{2}\right)\right\| \tag{55}\] \[\leq\varsigma\left(\left\|\mathbf{x}_{1}-\mathbf{x}_{2}\right\|+ \left\|\mathbf{u}_{1}-\mathbf{u}_{2}\right\|\right).\]

To prove Lemma B.5, it suffices to quantify \(\left\|\mathbf{x}_{t}^{(\mathbf{M})}-\mathbf{x}_{t}^{(\mathbf{M}^{\prime})}\right\|\) and \(\left\|\mathbf{u}_{t}^{(\mathbf{M})}-\mathbf{u}_{t}^{(\mathbf{M}^{\prime})}\right\|\).

Based on the evolution of the system state \(\mathbf{x}_{t}^{(\mathbf{M})}\), we have

\[\mathbf{x}_{t}^{(\mathbf{M})}-\mathbf{x}_{t}^{(\mathbf{M}^{\prime})}=E_{1}+E_{ 2}+E_{3}, \tag{56}\]

where

\[E_{1}= \left(\prod_{i=0}^{t-1}\left(\widetilde{\mathbf{A}}+\mathbf{ \Delta}_{i}\right)-\prod_{i=0}^{t-1}\left(\widetilde{\mathbf{A}}+\mathbf{ \Delta}_{i}^{\prime}\right)\right)\mathbf{x}_{0}, \tag{57}\] \[E_{2}= \sum_{i=0}^{t-1}\prod_{j=i+1}^{t-1}\left(\mathbf{1}_{j<t}\left( \widetilde{\mathbf{A}}+\mathbf{\Delta}_{j}\right)+\mathbf{1}_{j=t}\mathbf{I} \right)\mathbf{B}\mathbf{M}\left[\mathbf{w}\right]_{i-1}^{H}\] (58) \[-\sum_{i=0}^{t-1}\prod_{j=i+1}^{t-1}\left(\mathbf{1}_{j<t}\left( \widetilde{\mathbf{A}}+\mathbf{\Delta}_{j}^{\prime}\right)+\mathbf{1}_{j=t} \mathbf{I}\right)\mathbf{B}\mathbf{M}^{\prime}\left[\mathbf{w}\right]_{i-1}^ {H},\] \[E_{3}= \sum_{i=0}^{t-1}\left(\prod_{j=i+1}^{t-1}\left(\mathbf{1}_{j<t} \left(\widetilde{\mathbf{A}}+\mathbf{\Delta}_{j}\right)+\mathbf{1}_{j=t} \mathbf{I}\right)-\prod_{j=i+1}^{t-1}\left(\mathbf{1}_{j<t}\left(\widetilde{ \mathbf{A}}+\mathbf{\Delta}_{j}^{\prime}\right)+\mathbf{1}_{j=t}\mathbf{I} \right)\right)\mathbf{w}_{i}. \tag{59}\]

We next analyze each term in (56) one by one. Specifically,

\[\left\|E_{1}\right\| \leq x_{0}\left\|\prod_{i=0}^{t-1}\left(\widetilde{\mathbf{A}}+ \mathbf{\Delta}_{i}\right)-\prod_{i=0}^{t-1}\left(\widetilde{\mathbf{A}}+ \mathbf{\Delta}_{i}^{\prime}\right)\right\| \tag{60}\] \[\leq x_{0}\left\|\left(\mathbf{\Delta}_{0}-\mathbf{\Delta}_{0}^{ \prime}\right)\prod_{i=1}^{t-1}\left(\widetilde{\mathbf{A}}+\mathbf{\Delta}_{ i}\right)+\left(\widetilde{\mathbf{A}}+\mathbf{\Delta}_{0}^{\prime}\right)\left( \mathbf{\Delta}_{1}-\mathbf{\Delta}_{1}^{\prime}\right)\prod_{i=2}^{t-1} \left(\widetilde{\mathbf{A}}+\mathbf{\Delta}_{i}\right)\right.\] \[+\cdots+\left.\prod_{i=0}^{t-2}\left(\widetilde{\mathbf{A}}+ \mathbf{\Delta}_{i}^{\prime}\right)\left(\mathbf{\Delta}_{t-1}-\mathbf{ \Delta}_{t-1}^{\prime}\right)\right\|\] \[\leq x_{0}\kappa^{2}\left(1-\gamma\right)^{-1}\prod_{i=0}^{t-1} \left(1-\gamma+\kappa^{2}\xi_{i}\right)\sum_{i=0}^{t-1}\left\|\mathbf{\Delta}_ {i}-\mathbf{\Delta}_{i}^{\prime}\right\|\] \[=x_{0}\kappa^{2}\left(1-\gamma\right)^{-1}\alpha_{t}\sum_{i=0}^{t- 1}\left\|\mathbf{\Delta}_{i}-\mathbf{\Delta}_{i}^{\prime}\right\|.\]For the term \(E_{2}\), we use the similar approach for analyzing \(E_{1}\) in (74) and obtain the following bound

\[\left\|E_{2}\right\| \tag{61}\] \[\leq\left\|\sum_{i=0}^{t-1}\prod_{j=i+1}^{t-1}\left(\mathbf{1}_{j< t}\left(\widetilde{\mathbf{A}}+\mathbf{\Delta}_{j}\right)+\mathbf{1}_{j=t} \mathbf{I}\right)\mathbf{B}\left(\mathbf{M}-\mathbf{M}^{\prime}\right)\left[ \mathbf{w}\right]_{i-1}^{H}\right.\] \[+\sum_{i=0}^{t-1}\left(\prod_{j=i+1}^{t-1}\left(\mathbf{1}_{j<t} \left(\widetilde{\mathbf{A}}+\mathbf{\Delta}_{j}\right)+\mathbf{1}_{j=t} \mathbf{I}\right)-\prod_{j=i+1}^{t-1}\left(\mathbf{1}_{j<t}\left(\widetilde{ \mathbf{A}}+\mathbf{\Delta}_{j}^{\prime}\right)+\mathbf{1}_{j=t}\mathbf{I} \right)\right)\mathbf{B}\mathbf{M}^{\prime}\left[\mathbf{w}\right]_{i-1}^{H}\right\|\] \[\leq\kappa^{2}HW\beta_{t}\left\|\mathbf{M}-\mathbf{M}^{\prime}\right\|\] \[+\left\|\mathbf{B}\right\|MHW\sum_{i=0}^{t-1}\left\|\prod_{j=i+1}^ {t-1}\left(\mathbf{1}_{j<t}\left(\widetilde{\mathbf{A}}+\mathbf{\Delta}_{j} \right)+\mathbf{1}_{j=t}\mathbf{I}\right)-\prod_{j=i+1}^{t-1}\left(\mathbf{1}_ {j<t}\left(\widetilde{\mathbf{A}}+\mathbf{\Delta}_{j}^{\prime}\right)+\mathbf{ 1}_{j=t}\mathbf{I}\right)\right\|\] \[\overset{\eqref{eq:E3}}{\leq}\kappa^{2}HW\beta_{t}\left\|\mathbf{ M}-\mathbf{M}^{\prime}\right\|+\kappa^{2}\left(1-\gamma\right)^{-1}\left\| \mathbf{B}\right\|MHW\beta_{t}\sum_{i=0}^{t-1}\left\|\mathbf{\Delta}_{i}- \mathbf{\Delta}_{i}^{\prime}\right\|,\]

where inequality \(\eqref{eq:E3}.a)\) is obtained by using (76).

Finally, still using (76), an upper bound of \(\left\|E_{3}\right\|\) is obtained as follows

\[\left\|E_{3}\right\|\leq W\sum_{i=0}^{t-1}\left\|\prod_{j=i+1}^{t-1}\left(\mathbf{1}_{j<t} \left(\widetilde{\mathbf{A}}+\mathbf{\Delta}_{j}\right)+\mathbf{1}_{j=t} \mathbf{I}\right)-\prod_{j=i+1}^{t-1}\left(\mathbf{1}_{j<t}\left(\widetilde{ \mathbf{A}}+\mathbf{\Delta}_{j}^{\prime}\right)+\mathbf{1}_{j=t}\mathbf{I} \right)\right\| \tag{62}\] \[\leq \kappa^{2}\left(1-\gamma\right)^{-1}W\beta_{t}\sum_{i=0}^{t-1} \left\|\mathbf{\Delta}_{i}-\mathbf{\Delta}_{i}^{\prime}\right\|.\]

It follow directly that

\[\left\|\mathbf{x}_{t}^{\left(\mathbf{M}\right)}-\mathbf{x}_{t}^{ \left(\mathbf{M}^{\prime}\right)}\right\|\leq\left\|E_{1}\right\|+\left\|E_{2 }\right\|+\left\|E_{3}\right\| \tag{63}\] \[\leq\kappa^{2}HW\beta_{t}\left\|\mathbf{M}-\mathbf{M}^{\prime} \right\|+\kappa^{2}\left(1-\gamma\right)^{-1}\left(x_{0}\alpha_{t}+\left( \left\|\mathbf{B}\right\|HM+1\right)W\beta_{t}\right)\sum_{i=0}^{t-1}\left\| \mathbf{\Delta}_{i}-\mathbf{\Delta}_{i}^{\prime}\right\|.\]

We next observe the relationship

\[\left\|\mathbf{u}_{t}^{\left(\mathbf{M}\right)}-\mathbf{u}_{t}^{ \left(\mathbf{M}^{\prime}\right)}\right\|=\left\|-\mathbf{K}\mathbf{x}_{t}^{ \left(\mathbf{M}\right)}+\mathbf{K}\mathbf{x}_{t}^{\left(\mathbf{M}^{\prime} \right)}+\mathbf{M}\left[\mathbf{w}\right]_{t-1}^{H}-\mathbf{M}^{\prime}\left[ \mathbf{w}\right]_{t-1}^{H}\right\| \tag{64}\] \[\leq\kappa\left\|\mathbf{x}_{t}^{\left(\mathbf{M}\right)}-\mathbf{ x}_{t}^{\left(\mathbf{M}^{\prime}\right)}\right\|+HW\left\|\mathbf{M}-\mathbf{M}^{ \prime}\right\|.\]

Therefore, it follows that

\[\left\|\mathbf{x}_{t}^{\left(\mathbf{M}\right)}-\mathbf{x}_{t}^{ \left(\mathbf{M}^{\prime}\right)}\right\|+\left\|\mathbf{u}_{t}^{\left( \mathbf{M}\right)}-\mathbf{u}_{t}^{\left(\mathbf{M}^{\prime}\right)}\right\| \leq\left(1+\kappa\right)\left\|\mathbf{x}_{t}^{\left(\mathbf{M}\right)}- \mathbf{x}_{t}^{\left(\mathbf{M}^{\prime}\right)}\right\|+HW\left\|\mathbf{M} -\mathbf{M}^{\prime}\right\| \tag{65}\] \[+\left(1+\kappa\right)\kappa^{2}\left(1-\gamma\right)^{-1}\left(x _{0}\alpha_{t}+\left(\left\|\mathbf{B}\right\|HM+1\right)W\beta_{t}\right) \sum_{i=0}^{t-1}\left\|\mathbf{\Delta}_{i}-\mathbf{\Delta}_{i}^{\prime}\right\|.\]

Combining (65) and (55), we obatin the desired result. 

**Smoothness**: We analyze the smoothness of the per stage cost and the per stage expected cost in the following Lemma B.6 and B.8, respectively.

**Lemma B.6**: _The per stage cost function \(c_{t}\left(\mathbf{M};\left\{\mathbf{\Delta}_{i}\right\}_{0\leq i<t}\right), \forall 1\leq t\leq T,\) is smooth in the sense that_

\[\left\|\nabla_{\mathbf{M}}c_{t}\left(\mathbf{M};\left\{\mathbf{ \Delta}_{i}\right\}_{0\leq i<t}\right)-\nabla_{\mathbf{M}^{\prime}}c_{t}\left( \mathbf{M}^{\prime};\left\{\mathbf{\Delta}_{i}^{\prime}\right\}_{0\leq i<t} \right)\right\|_{F} \tag{66}\] \[\leq\lambda_{t}\left\|\mathbf{M}-\mathbf{M}^{\prime}\right\|_{F}+ \nu_{t}\sum_{i=0}^{t-1}\left\|\mathbf{\Delta}_{i}-\mathbf{\Delta}_{i}^{\prime} \right\|_{F},\]

_where_

\[\lambda_{t}= d_{x}\sqrt{H}\varsigma H^{2}W^{2}\left(1+\left\|\mathbf{B} \right\|\left(\kappa^{2}+\kappa^{3}\right)\right)\left(\left(\kappa^{2}+\kappa ^{3}\right)\beta_{t}+1\right), \tag{67}\] \[\nu_{t}= d_{x}\sqrt{H}\left(\varsigma HW\left(1+\left\|\mathbf{B} \right\|\left(\kappa^{2}+\kappa^{3}\right)\right)\left(\kappa^{2}+\kappa^{3} \right)\left(1-\gamma\right)^{-1}+G\left(1-\gamma\right)^{-1}\right.\] (68) \[\cdot\left.\left(\kappa^{4}+\kappa^{5}\right)HW\left\|\mathbf{B} \right\|\beta_{t}\right)\left(x_{0}\alpha_{t}+\left(\left\|\mathbf{B}\right\| HM+1\right)W\beta_{t}\right),\]

_and \(\mathbf{\Delta}_{i}\) and \(\mathbf{\Delta}_{i}^{\prime},\forall 0\leq i<t,\) denotes the policy-dependent state transition perturbations under the policy \(\mathbf{M}\) and \(\mathbf{M}^{\prime},\) respectively._

_Proof._ We prove this lemma based on the smoothness of the cost function \(c_{t}\left(\mathbf{x},\mathbf{u}\right)\) in A 5, i.e.,

\[\left\|\nabla_{\mathbf{x}}c_{t}\left(\mathbf{x}_{1},\mathbf{u}_{ 1}\right)-\nabla_{\mathbf{x}}c_{t}\left(\mathbf{x}_{2},\mathbf{u}_{1}\right) \right\|+\left\|\nabla_{\mathbf{u}}c_{t}\left(\mathbf{x}_{1},\mathbf{u}_{1} \right)-\nabla_{\mathbf{u}}c_{t}\left(\mathbf{x}_{1},\mathbf{u}_{2}\right)\right\|\] \[\leq\varsigma\left(\left\|\mathbf{x}_{1}-\mathbf{x}_{2}\right\|+ \left\|\mathbf{u}_{1}-\mathbf{u}_{2}\right\|\right). \tag{69}\]

Based on the expression of \(\nabla_{\mathbf{M}}c_{t}\left(\mathbf{M};\left\{\mathbf{\Delta}_{i}\right\}_{ 0\leq i<t}\right)\) in (24), it follows that

\[\nabla_{\mathbf{M}}c_{t}\left(\mathbf{M};\left\{\mathbf{\Delta}_{i}\right\}_{ 0\leq i<t}\right)-\nabla_{\mathbf{M}^{\prime}}c_{t}\left(\mathbf{M}^{\prime}; \left\{\mathbf{\Delta}_{i}^{\prime}\right\}_{0\leq i<t}\right)\leq F_{1}+F_{2} +F_{3}, \tag{70}\]

where

\[F_{1}= \sum_{i=0}^{t-1}\left(\left(\prod_{j=i+1}^{t-1}\left(\mathbf{1}_{ j<t}\left(\widetilde{\mathbf{A}}+\mathbf{\Delta}_{j}\right)+\mathbf{1}_{j=t} \mathbf{I}\right)\mathbf{B}\right)^{\top}\nabla_{\mathbf{x}}c_{t}\left( \mathbf{x}_{t}^{\left(\mathbf{M}^{\prime}\right)},\mathbf{u}_{t}^{\left( \mathbf{M}^{\prime}\right)}\right)\right. \tag{71}\] \[-\left.\left(\prod_{j=i+1}^{t-1}\left(\mathbf{1}_{j<t}\left( \widetilde{\mathbf{A}}+\mathbf{\Delta}_{j}^{\prime}\right)+\mathbf{1}_{j=t} \mathbf{I}\right)\mathbf{B}\right)^{\top}\nabla_{\mathbf{x}}c_{t}\left( \mathbf{x}_{t}^{\left(\mathbf{M}^{\prime}\right)},\mathbf{u}_{t}^{\left( \mathbf{M}^{\prime}\right)}\right)\right)\left(\left[\mathbf{w}\right]_{i-1}^ {H}\right)^{\top},\] \[F_{2}= \sum_{i=0}^{t-1}\left(\left(\mathbf{K}\prod_{j=i+1}^{t-1}\left( \mathbf{1}_{j<t}\left(\widetilde{\mathbf{A}}+\mathbf{\Delta}_{j}\right)+ \mathbf{1}_{j=t}\mathbf{I}\right)\mathbf{B}\right)^{\top}\nabla_{\mathbf{x}}c _{t}\left(\mathbf{x}_{t}^{\left(\mathbf{M}^{\prime}\right)},\mathbf{u}_{t}^{ \left(\mathbf{M}^{\prime}\right)}\right)\right.\] (72) \[-\left.\left(\mathbf{K}\prod_{j=i+1}^{t-1}\left(\mathbf{1}_{j<t} \left(\widetilde{\mathbf{A}}+\mathbf{\Delta}_{j}^{\prime}\right)+\mathbf{1}_{j= t}\mathbf{I}\right)\mathbf{B}\right)^{\top}\nabla_{\mathbf{x}}c_{t}\left( \mathbf{x}_{t}^{\left(\mathbf{M}^{\prime}\right)},\mathbf{u}_{t}^{\left( \mathbf{M}^{\prime}\right)}\right)\right)\left(\left[\mathbf{w}\right]_{i-1}^ {H}\right)^{\top},\] \[F_{3}= \left(\nabla_{\mathbf{u}}c_{t}\left(\mathbf{x}_{t}^{\left( \mathbf{M}\right)},\mathbf{u}_{t}^{\left(\mathbf{M}\right)}\right)-\nabla_{ \mathbf{u}}c_{t}\left(\mathbf{x}_{t}^{\left(\mathbf{M}^{\prime}\right)}, \mathbf{u}_{t}^{\left(\mathbf{M}^{\prime}\right)}\right)\right)\left(\left[ \mathbf{w}\right]_{t-1}^{H}\right)^{\top}. \tag{73}\]We next analyze each term in (70) one by one. Specifically,

\[\left\|F_{1}\right\|=\left\|\sum_{i=0}^{t-1}\left(\left(\prod_{j=i+1 }^{t-1}\left(\mathbf{1}_{j<t}\left(\widetilde{\mathbf{A}}+\mathbf{\Delta}_{j} \right)+\mathbf{1}_{j=t}\mathbf{I}\right)\mathbf{B}\right)^{\top}\nabla_{ \mathbf{x}}c_{t}\left(\mathbf{x}_{t}^{(\mathbf{M})},\mathbf{u}_{t}^{(\mathbf{M })}\right)\right.\right. \tag{74}\] \[-\left(\prod_{j=i+1}^{t-1}\left(\mathbf{1}_{j<t}\left(\widetilde{ \mathbf{A}}+\mathbf{\Delta}_{j}\right)+\mathbf{1}_{j=t}\mathbf{I}\right) \mathbf{B}\right)^{\top}\nabla_{\mathbf{x}}c_{t}\left(\mathbf{x}_{t}^{(\mathbf{ M}^{\prime})},\mathbf{u}_{t}^{(\mathbf{M}^{\prime})}\right)\] \[+\left(\prod_{j=i+1}^{t-1}\left(\mathbf{1}_{j<t}\left(\widetilde{ \mathbf{A}}+\mathbf{\Delta}_{j}\right)+\mathbf{1}_{j=t}\mathbf{I}\right) \mathbf{B}\right)^{\top}\nabla_{\mathbf{x}}c_{t}\left(\mathbf{x}_{t}^{(\mathbf{ M}^{\prime})},\mathbf{u}_{t}^{(\mathbf{M}^{\prime})}\right)\] \[-\left.\left(\prod_{j=i+1}^{t-1}\left(\mathbf{1}_{j<t}\left( \widetilde{\mathbf{A}}+\mathbf{\Delta}_{j}^{\prime}\right)+\mathbf{1}_{j=t} \mathbf{I}\right)\mathbf{B}\right)^{\top}\nabla_{\mathbf{x}}c_{t}\left(\mathbf{ x}_{t}^{(\mathbf{M}^{\prime})},\mathbf{u}_{t}^{(\mathbf{M}^{\prime})}\right) \right)\left(\left[\mathbf{w}\right]_{i-1}^{H}\right)^{\top}\] \[\overset{(74,a)}{\leq}HW\left\|\mathbf{B}\right\|\kappa^{2} \beta_{t}\left\|\nabla_{\mathbf{x}}c_{t}\left(\mathbf{x}_{t}^{(\mathbf{M})}, \mathbf{u}_{t}^{(\mathbf{M})}\right)-\nabla_{\mathbf{x}}c_{t}\left(\mathbf{x} _{t}^{(\mathbf{M}^{\prime})},\mathbf{u}_{t}^{(\mathbf{M}^{\prime})}\right)\right\|\] \[+HW\left\|\mathbf{B}\right\|\kappa^{2}\left(x_{0}G\alpha_{t}+GW \left(\left\|\mathbf{B}\right\|HM+1\right)\beta_{t}\right)\] \[\cdot\sum_{i=0}^{t-1}\left\|\prod_{j=i+1}^{t-1}\left(\mathbf{1}_{ j<t}\left(\widetilde{\mathbf{A}}+\mathbf{\Delta}_{j}\right)+\mathbf{1}_{j=t} \mathbf{I}\right)-\prod_{j=i+1}^{t-1}\left(\mathbf{1}_{j<t}\left(\widetilde{ \mathbf{A}}+\mathbf{\Delta}_{j}^{\prime}\right)+\mathbf{1}_{j=t}\mathbf{I} \right)\right\|,\]

where inequality \((74.a)\) holds due to the definition of \(\beta_{t}\) and the upper bound of provided in Lemma B.3.

[MISSING_PAGE_EMPTY:26]

\[\left\|E_{3}\right\|\leq HW\left\|\nabla_{\mathbf{u}}c_{t}\left(\mathbf{x}_{t}^{( \mathbf{M})},\mathbf{u}_{t}^{(\mathbf{M})}\right)-\nabla_{\mathbf{u}}c_{t} \left(\mathbf{x}_{t}^{(\mathbf{M}^{\prime})},\mathbf{u}_{t}^{(\mathbf{M}^{ \prime})}\right)\right\|. \tag{79}\]

Substitute (77), (78) and (79) into (70), we have

\[\left\|\nabla_{\mathbf{M}}c_{t}\left(\mathbf{M};\left\{\mathbf{ \Delta}_{i}\right\}_{0\leq i<t}\right)-\nabla_{\mathbf{M}^{\prime}}c_{t}\left( \mathbf{M}^{\prime};\left\{\mathbf{\Delta}_{i}^{\prime}\right\}_{0\leq i<t} \right)\right\| \tag{80}\] \[+\left\|\nabla_{\mathbf{u}}c_{t}\left(\mathbf{x}_{t},\mathbf{u}_{t }^{(\mathbf{M})}\right)-\nabla_{\mathbf{u}}c_{t}\left(\mathbf{x}_{t},\mathbf{u }_{t}^{(\mathbf{M}^{\prime})}\right)\right\|\right)+\widetilde{\beta}_{t}\sum_ {i=0}^{t-1}\left\|\mathbf{\Delta}_{i}^{\prime}-\mathbf{\Delta}_{i}\right\|,\]

where \(\widetilde{\beta}_{t}=\left(1-\gamma\right)^{-1}\left(\kappa^{4}+\kappa^{5} \right)HW\left\|\mathbf{B}\right\|\beta_{t}\left(x_{0}G\alpha_{t}+GW\left( \left\|\mathbf{B}\right\|HM+1\right)\beta_{t}\right).\)

Applying Lemma B.5 to (80) leads to the desired result. \(\square\)

Before we proceed to analyze the gradient difference of the expected per stage cost, we cite the following tool lemma in [21].

**Lemma B.7**: _(Kantorovich-Rubinstein (Lemma D.3 in [21])) A distribution map \(\mathcal{D}\left(\cdot\right)\) is \(\varepsilon\)-sensitive if and only if for all \(\mathbf{M},\mathbf{M}^{\prime}\in\mathbb{M}:\)_

\[\sup\left\{\mathbb{E}_{\mathbf{A}\sim\mathcal{D}(\mathbf{M})}\left[ g\left(\mathbf{A}\right)\right]-\mathbb{E}_{\mathbf{A}^{\prime}\sim\mathcal{D}( \mathbf{M}^{\prime})}\left[g\left(\mathbf{A}^{\prime}\right)\right]:g:\mathbb{ R}^{d_{x}\times d_{x}}\rightarrow\mathbb{R},g\;1-Lipschitz\right\}\] \[\leq\varepsilon\left\|\mathbf{M}-\mathbf{M}^{\prime}\right\|_{F}. \tag{81}\]

The smoothness regarding the expected per stage cost is summarized below.

**Lemma B.8**: _For any \(\mathbf{M},\mathbf{M}^{\prime},\mathbf{M}_{1},\mathbf{M}_{2}\in\mathbb{M}\) and \(\forall 1\leq t\leq T,\) the following inequality holds_

\[\left\|\mathbb{E}_{\mathbf{x}_{0},\left\{\mathbf{\Delta}_{i}\sim \mathcal{D}_{i}\left(\mathbf{M}_{1}\right)\right\}_{0\leq i<t};\left\{\mathbf{ w}_{i}\right\}_{0\leq i<t}}\left[\nabla_{\mathbf{M}}c_{t}\left(\mathbf{M}; \left\{\mathbf{\Delta}_{i}\right\}_{0\leq i<t}\right)\right]\right. \tag{82}\] \[\left.-\mathbb{E}_{\mathbf{x}_{0},\left\{\mathbf{\Delta}_{i}^{ \prime}\sim\mathcal{D}_{i}\left(\mathbf{M}_{2}\right)\right\}_{0\leq i<t}; \left\{\mathbf{w}_{i}\right\}_{0\leq i<t}}\left[\nabla_{\mathbf{M}^{\prime}}c_{ t}\left(\mathbf{M}^{\prime};\left\{\mathbf{\Delta}_{i}^{\prime}\right\}_{0\leq i<t} \right)\right]\right\|_{F}\] \[\leq\lambda_{t}\left\|\mathbf{M}-\mathbf{M}^{\prime}\right\|_{F} +\nu_{t}\sum_{i=0}^{t-1}\varepsilon_{i}\left\|\mathbf{M}_{1}-\mathbf{M}_{2} \right\|_{F}.\]

_Proof._ The norm of the gradient difference in (82) can be expanded as

\[\left\|\mathbb{E}\left[\nabla_{\mathbf{M}}c_{t}\left(\mathbf{M}; \left\{\mathbf{\Delta}_{i}\right\}_{0\leq i<t}\right)\right]-\nabla_{\mathbf{M }^{\prime}}c_{t}\left(\mathbf{M}^{\prime};\left\{\mathbf{\Delta}_{i}^{\prime} \right\}_{0\leq i<t}\right)\right\|_{F} \tag{83}\] \[+\left\|\mathbb{E}\left[\nabla_{\mathbf{M}^{\prime}}c_{t}\left( \mathbf{M}^{\prime};\left\{\mathbf{\Delta}_{i}\right\}_{0\leq i<t}\right)- \nabla_{\mathbf{M}^{\prime}}c_{t}\left(\mathbf{M}^{\prime},\mathbf{\Delta}_{i}^{ \prime},\left\{\mathbf{\Delta}_{i}\right\}_{1\leq i<t}\right)\right]\right\|_{F}+\cdots\] \[+\cdots+\left\|\mathbb{E}\left[\nabla_{\mathbf{M}^{\prime}}c_{t} \left(\mathbf{M}^{\prime};\left\{\mathbf{\Delta}_{i}^{\prime}\right\}_{0\leq i<t -1},\mathbf{\Delta}_{t-1}\right)-\nabla_{\mathbf{M}^{\prime}}c_{t}\left( \mathbf{M}^{\prime};\left\{\mathbf{\Delta}_{i}^{\prime}\right\}_{0\leq i<t-1} \right)\right]\right\|_{F},\]

where we drop the subscript in \(\mathbb{E}\left[\cdot\right]\) since the associated randomness is clear from the context.

We next analyze a general term in R.H.S. of inequality (83). Specifically,

\[\left\|\mathbb{E}\left[\nabla_{\mathbf{M}^{\prime}}c_{t}\left( \mathbf{M}^{\prime},\left\{\mathbf{\Delta}^{\prime}_{j}\right\}_{0\leq j\leq k-1 },\left\{\mathbf{\Delta}_{i}\right\}_{k\leq i<t}\right)-\nabla_{\mathbf{M}^{ \prime}}c_{t}\left(\mathbf{M}^{\prime},\left\{\mathbf{\Delta}^{\prime}_{j} \right\}_{0\leq j\leq k},\left\{\mathbf{\Delta}_{i}\right\}_{k+1\leq i<t}\right) \right]\right\|_{F} \tag{84}\] \[=\left\|\mathbb{E}\left[\mathbb{E}\left[\nabla_{\mathbf{M}^{ \prime}}c_{t}\left(\mathbf{M}^{\prime},\left\{\mathbf{\Delta}^{\prime}_{j} \right\}_{0\leq j\leq k-1},\mathbf{\Delta}_{k},\left\{\mathbf{\Delta}_{i} \right\}_{k+1\leq i<t}\right)\right.\right.\right.\] \[\left.\left.\left.-\nabla_{\mathbf{M}^{\prime}}c_{t}\left( \mathbf{M}^{\prime},\left\{\mathbf{\Delta}^{\prime}_{j}\right\}_{0\leq j\leq k -1},\mathbf{\Delta}^{\prime}_{k},\left\{\mathbf{\Delta}_{i}\right\}_{k+1\leq i <t}\right)\right|\left\{\mathbf{\Delta}^{\prime}_{j}\right\}_{0\leq j\leq k-1},\left\{\mathbf{\Delta}_{i}\right\}_{k+1\leq i<t}\right]\right\|_{F}\] \[\leq\mathbb{E}\left[\left\|\mathbb{E}\left[\nabla_{\mathbf{M}^{ \prime}}c_{t}\left(\mathbf{M}^{\prime},\left\{\mathbf{\Delta}^{\prime}_{j} \right\}_{0\leq j\leq k-1},\mathbf{\Delta}_{k},\left\{\mathbf{\Delta}_{i} \right\}_{k+1\leq i<t}\right)\right.\right.\right.\right.\] \[\left.\left.\left.-\nabla_{\mathbf{M}^{\prime}}c_{t}\left( \mathbf{M}^{\prime},\left\{\mathbf{\Delta}^{\prime}_{j}\right\}_{0\leq j\leq k -1},\mathbf{\Delta}^{\prime}_{k},\left\{\mathbf{\Delta}_{i}\right\}_{k+1\leq i <t}\right)\right|\left\{\mathbf{\Delta}^{\prime}_{j}\right\}_{0\leq j\leq k-1},\left\{\mathbf{\Delta}_{i}\right\}_{k+1\leq i<t}\right]\right\|_{F}\right].\]

Given \(\left\{\left\{\mathbf{\Delta}^{\prime}_{j}\right\}_{0\leq j\leq k-1},\left\{ \mathbf{\Delta}_{i}\right\}_{k+1\leq i<t}\right\},\) for notation conciseness, we abbreviate

\[\nabla_{\mathbf{M}^{\prime}}c_{t}\left(\mathbf{M}^{\prime},\left\{\mathbf{ \Delta}^{\prime}_{j}\right\}_{0\leq j\leq k-1},\mathbf{\Delta}_{k},\left\{ \mathbf{\Delta}_{i}\right\}_{k+1\leq i<t}\right)\text{and}\nabla_{\mathbf{M}^ {\prime}}c_{t}\left(\mathbf{M}^{\prime},\left\{\mathbf{\Delta}^{\prime}_{j} \right\}_{0\leq j\leq k-1},\mathbf{\Delta}^{\prime}_{k},\left\{\mathbf{\Delta }_{i}\right\}_{k+1\leq i<t}\right)\]

as \(\nabla_{\mathbf{M}^{\prime}}c_{t}\left(\mathbf{M}^{\prime},\mathbf{\Delta}_{k}\right)\) and \(\nabla_{\mathbf{M}^{\prime}}c_{t}\left(\mathbf{M}^{\prime},\mathbf{\Delta}^{ \prime}_{k}\right),\) respectively. It follows that

\[\left\|\mathbb{E}\left[\nabla_{\mathbf{M}^{\prime}}c_{t}\left( \mathbf{M}^{\prime},\mathbf{\Delta}_{k}\right)-\nabla_{\mathbf{M}^{\prime}}c_{ t}\left(\mathbf{M}^{\prime},\mathbf{\Delta}^{\prime}_{k}\right)\right]\right\|_{F}^{2} \tag{85}\] \[=\operatorname{Tr}\left(\left(\mathbb{E}\left[\nabla_{\mathbf{M} ^{\prime}}c_{t}\left(\mathbf{M}^{\prime},\mathbf{\Delta}_{k}\right)\right]- \mathbb{E}\left[\nabla_{\mathbf{M}^{\prime}}c_{t}\left(\mathbf{M}^{\prime}, \mathbf{\Delta}^{\prime}_{k}\right)\right]\right)^{\top}\left(\mathbb{E}\left[ \nabla_{\mathbf{M}^{\prime}}c_{t}\left(\mathbf{M}^{\prime},\mathbf{\Delta}_{k} \right)\right]-\mathbb{E}\left[\nabla_{\mathbf{M}^{\prime}}c_{t}\left(\mathbf{M} ^{\prime},\mathbf{\Delta}^{\prime}_{k}\right)\right]\right)\right)\] \[=\left\|\mathbb{E}\left[\nabla_{\mathbf{M}^{\prime}}c_{t}\left( \mathbf{M}^{\prime},\mathbf{\Delta}_{k}\right)-\nabla_{\mathbf{M}^{\prime}}c_{ t}\left(\mathbf{M}^{\prime},\mathbf{\Delta}^{\prime}_{k}\right)\right]\right\|_{F} \operatorname{Tr}\left(V^{\top}\mathbb{E}\left[\nabla_{\mathbf{M}^{\prime}}c_ {t}\left(\mathbf{M}^{\prime},\mathbf{\Delta}_{k}\right)\right]-V^{\top} \mathbb{E}\left[\nabla_{\mathbf{M}^{\prime}}c_{t}\left(\mathbf{M}^{\prime}, \mathbf{\Delta}^{\prime}_{k}\right)\right]\right),\]

where

\[V=\frac{\mathbb{E}\left[\nabla_{\mathbf{M}^{\prime}}c_{t}\left(\mathbf{M}^{ \prime},\mathbf{\Delta}_{k}\right)\right]-\mathbb{E}\left[\nabla_{\mathbf{M}^ {\prime}}c_{t}\left(\mathbf{M}^{\prime},\mathbf{\Delta}^{\prime}_{k}\right) \right]}{\left\|\mathbb{E}\left[\nabla_{\mathbf{M}^{\prime}}c_{t}\left( \mathbf{M}^{\prime},\mathbf{\Delta}_{k}\right)-\nabla_{\mathbf{M}^{\prime}}c_ {t}\left(\mathbf{M}^{\prime},\mathbf{\Delta}^{\prime}_{k}\right)\right]\right\| _{F}},\;\left\|V\right\|_{F}=1. \tag{86}\]

Based on Lemma B.6, given \(\left\{\left\{\mathbf{\Delta}^{\prime}_{j}\right\}_{0\leq j\leq k-1},\left\{ \mathbf{\Delta}_{i}\right\}_{k+1\leq i<t}\right\},\) the conditional gradient \(V^{\top}\mathbb{E}\left[\nabla_{\mathbf{M}^{\prime}}c_{t}\left(\mathbf{M}^{ \prime},\mathbf{\Delta}_{k}\right)\right]\) is \(\nu_{t}\)-Lipschitz in \(\mathbf{\Delta}_{k}.\) Further note that \(\mathbf{\Delta}_{k}\sim\mathcal{D}_{k}\left(\mathbf{M}_{1}\right)\) and \(\mathbf{\Delta}^{\prime}_{k}\sim\mathcal{D}_{k}\left(\mathbf{M}_{2}\right)\), which are both \(\varepsilon_{k}\)-sensitive. Applying Lemma B.7, it follows that

\[\operatorname{Tr}\left(V^{\top}\mathbb{E}\left[\nabla_{\mathbf{M}^{\prime}}c_{t} \left(\mathbf{M}^{\prime},\mathbf{\Delta}_{k}\right)\right]-V^{\top}\mathbb{E} \left[\nabla_{\mathbf{M}^{\prime}}c_{t}\left(\mathbf{M}^{\prime},\mathbf{ \Delta}^{\prime}_{k}\right)\right]\right)\leq\nu_{t}\varepsilon_{k}\left\| \mathbf{M}_{1}-\mathbf{M}_{2}\right\|_{F}. \tag{87}\]

Substitute (87) into (85), it follows that

\[\left\|\mathbb{E}\left[\nabla_{\mathbf{M}^{\prime}}c_{t}\left(\mathbf{M}^{ \prime},\mathbf{\Delta}_{k}\right)-\nabla_{\mathbf{M}^{\prime}}c_{t}\left( \mathbf{M}^{\prime},\mathbf{\Delta}^{\prime}_{k}\right)\right]\right\|_{F}\leq \nu_{t}\varepsilon_{k}\left\|\mathbf{M}_{1}-\mathbf{M}_{2}\right\|_{F}. \tag{88}\]

Using the similar approach, we can obtain

\[\left\|\mathbb{E}\left[\nabla_{\mathbf{M}^{\prime}}c_{t}\left( \mathbf{M};\left\{\mathbf{\Delta}_{i}\right\}_{0\leq i<t}\right)-\nabla_{ \mathbf{M}^{\prime}}c_{t}\left(\mathbf{M}^{\prime},\left\{\mathbf{\Delta}_{i} \right\}_{0\leq i<t}\right)\right]\right\|\leq\lambda_{t}\left\|\mathbf{M}- \mathbf{M}^{\prime}\right\|_{F}; \tag{89}\] \[\left\|\mathbb{E}\left[\nabla_{\mathbf{M}^{\prime}}c_{t}\left( \mathbf{M}^{\prime},\left\{\mathbf{\Delta}_{i}\right\}_{0\leq i<t}\right)- \nabla_{\mathbf{M}^{\prime}}c_{t}\left(\mathbf{M}^{\prime},\mathbf{\mathbf{A}^{ \prime}_{1},\left\{\mathbf{\Delta}_{i}\right\}_{1\leq i<t}\right)}\right]\right\|\leq \nu_{t}\varepsilon_{1}\left\|\mathbf{M}_{1}-\mathbf{M}_{2}\right\|_{F};\] (90) \[\vdots\] \[\left\|\mathbb{E}\left[\nabla_{\mathbf{M}^{\prime}}c_{t}\left( \mathbf{M}^{\prime},\left\{\mathbf{\Delta}^{\prime}_{i}\right\}_{0\leq i<t-1}, \mathbf{\Delta}_{t-1}\right)-\nabla_{\mathbf{M}^{\prime}}c_{t}\left(\mathbf{M}^{ \prime},\left\{\mathbf{\Delta}^{\prime}_{i}\right\}_{0\leq i<t-1}\right)\right]\right\|\] \[\leq\nu_{t}\varepsilon_{t-1}\left\|\mathbf{M}_{1}-\mathbf{M}_{2} \right\|_{F}. \tag{91}\]

Combining (83), (89)-(91), it follow inequality (82). 

## Appendix C Properties of the Total Cost Function

We define a total cost function \(J_{T}\) as

\[J_{T}\left(\mathbf{M};\left\{\mathbf{\Delta}_{i}\right\}_{0\leq i<T}\right)= \sum_{t=0}^{T}c_{t}\left(\mathbf{M};\left\{\mathbf{\Delta}_{i}\right\}_{0\leq i<t} \right). \tag{92}\]

[MISSING_PAGE_FAIL:29]

Sum up (96) from \(t_{1}=1\) to \(t_{1}=H-1\) and (97) from \(t_{2}=H\) to \(t_{2}=T\), we obtain

\[\sum_{t_{1}=1}^{H-1}f_{t_{1}}\left(\mathbf{M};\mathbf{M}_{1}\right) +\sum_{t_{2}=H}^{T}f_{t_{1}}\left(\mathbf{M};\mathbf{M}_{1}\right)\geq\sum_{t_ {1}=1}^{H-1}f_{t_{1}}\left(\mathbf{M}^{\prime};\mathbf{M}_{1}\right)+\sum_{t_{2} =H}^{T}f_{t_{1}}\left(\mathbf{M}^{\prime};\mathbf{M}_{1}\right) \tag{98}\] \[+\operatorname{Tr}\left(\left(\nabla\left(\sum_{t_{1}=1}^{H-1}f_{ t_{1}}\left(\mathbf{M}^{\prime};\mathbf{M}_{1}\right)+\sum_{t_{2}=H}^{T}f_{t_{1}} \left(\mathbf{M}^{\prime};\mathbf{M}_{1}\right)\right)\right)^{\top}\left( \mathbf{M}-\mathbf{M}^{\prime}\right)\right)\] \[+\frac{\widetilde{\mu}}{2}\left\|\mathbf{M}-\mathbf{M}^{\prime} \right\|_{F}^{2}.\]

Inequality (13) follows directly by noting that

\[C_{T}\left(\mathbf{M};\mathbf{M}_{1}\right) =\sum_{t_{1}=1}^{H-1}f_{t_{1}}\left(\mathbf{M};\mathbf{M}_{1} \right)+\sum_{t_{2}=H}^{T}f_{t_{1}}\left(\mathbf{M};\mathbf{M}_{1}\right), \tag{99}\] \[\nabla C_{T}\left(\mathbf{M}^{\prime};\mathbf{M}_{1}\right) =\nabla\left(\sum_{t_{1}=1}^{H-1}f_{t_{1}}\left(\mathbf{M}^{ \prime};\mathbf{M}_{1}\right)+\sum_{t_{2}=H}^{T}f_{t_{1}}\left(\mathbf{M}^{ \prime};\mathbf{M}_{1}\right)\right). \tag{100}\]

## Appendix E Proof of Lemma 3

Note that \(\nabla C_{0}\left(\mathbf{M};\mathbf{M}_{1}\right)=\nabla_{\mathbf{M}}\mathbb{ E}\left[c_{t}\left(\mathbf{x}_{0},\mathbf{u}_{0}\right)\right]=\nabla_{\mathbf{M}} \mathbb{E}\left[c_{t}\left(\mathbf{x}_{0},-\mathbf{K}\mathbf{x}_{0}\right) \right]=\mathbf{0}\). Therefore, inequality (14) follows directly by combining the norm triangular inequalivand the results in Lemma B.6.

\[\left\|\nabla C_{T}\left(\mathbf{M};\mathbf{M}_{1}\right)-\nabla C _{T}\left(\mathbf{M}^{\prime};\mathbf{M}_{2}\right)\right\|_{F} \tag{101}\] \[\leq\sum_{t=1}^{T}\left\|\mathbb{E}_{\mathbf{x}_{0},\left\{ \mathbf{\Delta}_{i}\sim\mathcal{D}_{i}\left(\mathbf{M}_{1}\right)\right\}_{0 \leq i<t},\left\{\mathbf{w}_{i}\right\}_{0\leq i<t}}\left[\nabla_{\mathbf{M}} c_{t}\left(\mathbf{M};\left\{\mathbf{\Delta}_{i}\right\}_{0\leq i<t}\right)\right]\right.\] \[\left.-\mathbb{E}_{\mathbf{x}_{0},\left\{\mathbf{\Delta}_{i}^{ \prime}\sim\mathcal{D}_{1}\left(\mathbf{M}_{2}\right)\right\}_{0\leq i<t}, \left\{\mathbf{w}_{i}\right\}_{0\leq i<t}}\left[\nabla_{\mathbf{M}^{\prime}} c_{t}\left(\mathbf{M}^{\prime};\left\{\mathbf{\Delta}_{i}^{\prime}\right\}_{0 \leq i<t}\right)\right]\right\|_{F}\] \[\leq\left(\sum_{t=1}^{T}\lambda_{t}\right)\left\|\mathbf{M}- \mathbf{M}^{\prime}\right\|_{F}+\sum_{t=1}^{T}\left(\nu_{t}\sum_{i=0}^{t-1} \varepsilon_{i}\right)\left\|\mathbf{M}_{1}-\mathbf{M}_{2}\right\|_{F}\] \[=\left(\sum_{t=1}^{T}\lambda_{t}\right)\left\|\mathbf{M}- \mathbf{M}^{\prime}\right\|_{F}+\sum_{t=0}^{T-1}\varepsilon_{t}\left(\sum_{i =t+1}^{T}\nu_{i}\right)\left\|\mathbf{M}_{1}-\mathbf{M}_{2}\right\|_{F}.\]

## Appendix F Proof of Lemma 4

**Proposition 3**: _(First-order optimality condition in [18]). Let \(F(\mathbf{x})\) be convex and let \(\mathcal{X}^{n}\) be a closed convex set on which \(F(\mathbf{x})\) is differentiable, then_

\[\mathbf{x}^{*}\in\underset{\mathbf{x}\in\mathcal{X}^{n}}{\arg\min}F(\mathbf{x})\]

_if and only if_

\[\nabla F\left(\mathbf{x}^{*}\right)^{\top}\left(\mathbf{y}-\mathbf{x}^{*}\right)\geqslant 0,\quad\forall\mathbf{y}\in\mathcal{X}^{n}.\]

Fix any \(\mathbf{M},\mathbf{M}^{\prime}\in\mathbb{M}\), applying the first order optimality condition in Proposition 3, the optimality condition to (15) implies that

\[\left\langle\nabla C_{T}\left(\Phi\left(\mathbf{M}\right);\mathbf{M}\right), \Phi(\mathbf{M}^{\prime})-\Phi(\mathbf{M})\right\rangle\geq 0,\left\langle\nabla C_{T} \left(\Phi\left(\mathbf{M}^{\prime}\right);\mathbf{M}^{\prime}\right),\Phi( \mathbf{M})-\Phi(\mathbf{M}^{\prime})\right\rangle\geq 0, \tag{102}\]

where the gradients are again taken w.r.t. the first argument in the function \(C_{T}\left(\cdot,\cdot\right)\). Observe the fact

\[0\leq\left\langle\nabla C_{T}\left(\Phi\left(\mathbf{M}^{\prime}\right); \mathbf{M}^{\prime}\right)-\nabla C_{T}\left(\Phi\left(\mathbf{M}\right); \mathbf{M}\right),\Phi\left(\mathbf{M}\right)-\Phi\left(\mathbf{M}^{\prime }\right)\right\rangle. \tag{103}\]Adding and subtracting the term \(\nabla C_{T}\left(\Phi\left(\mathbf{M}\right);\mathbf{M}^{\prime}\right)\) implies the equality

\[\operatorname{Tr}\left(\left(\nabla C_{T}\left(\Phi\left(\mathbf{M }\right);\mathbf{M}^{\prime}\right)-\nabla C_{T}\left(\Phi\left(\mathbf{M} \right);\mathbf{M}\right)\right)^{\top}\left(\Phi\left(\mathbf{M}\right)-\Phi \left(\mathbf{M}^{\prime}\right)\right)\right) \tag{104}\] \[\geq\operatorname{Tr}\left(\left(\nabla C_{T}\left(\Phi\left( \mathbf{M}\right);\mathbf{M}^{\prime}\right)-\nabla C_{T}\left(\Phi\left( \mathbf{M}^{\prime}\right);\mathbf{M}^{\prime}\right)\right)^{\top}\left(\Phi \left(\mathbf{M}\right)-\Phi\left(\mathbf{M}^{\prime}\right)\right)\right).\]

Recall that \(C_{T}\left(\Phi\left(\mathbf{M}\right);\mathbf{M}^{\prime}\right)\) is \(\widetilde{\mu}\)-strongly convex w.r.t. \(\Phi\left(\mathbf{M}\right)\), it follows

\[\operatorname{Tr}\left(\left(\nabla C_{T}\left(\Phi\left(\mathbf{ M}\right);\mathbf{M}^{\prime}\right)-\nabla C_{T}\left(\Phi\left(\mathbf{M}^{ \prime}\right);\mathbf{M}^{\prime}\right)\right)^{\top}\left(\Phi\left( \mathbf{M}\right)-\Phi\left(\mathbf{M}^{\prime}\right)\right)\right) \tag{105}\] \[\geq\widetilde{\mu}\left\|\Phi\left(\mathbf{M}\right)-\Phi\left( \mathbf{M}^{\prime}\right)\right\|_{F}^{2}.\]

Meanwhile, applying Lemma 3 to the left hand side of (104) gives

\[\operatorname{Tr}\left(\left(\nabla C_{T}\left(\Phi\left(\mathbf{ M}\right);\mathbf{M}^{\prime}\right)-\nabla C_{T}\left(\Phi\left(\mathbf{M} \right);\mathbf{M}\right)\right)^{\top}\left(\Phi\left(\mathbf{M}\right)-\Phi \left(\mathbf{M}^{\prime}\right)\right)\right) \tag{106}\] \[\leq\sum_{t=0}^{T-1}\left(\varepsilon_{t}\sum_{i=t+1}^{T}\nu_{i} \right)\left\|\mathbf{M}-\mathbf{M}^{\prime}\right\|_{F}\left\|\Phi\left( \mathbf{M}\right)-\Phi\left(\mathbf{M}^{\prime}\right)\right\|_{F}.\]

Combining (104), (105) and (106), it follows

\[\left\|\Phi\left(\mathbf{M}\right)-\Phi\left(\mathbf{M}^{\prime} \right)\right\|_{F}\leq\frac{\sum_{t=0}^{T-1}\left(\varepsilon_{t}\sum_{i=t+1} ^{T}\nu_{i}\right)}{\widetilde{\mu}}\left\|\mathbf{M}-\mathbf{M}^{\prime} \right\|_{F}. \tag{107}\]

We note that \(\mathbf{M}_{n+1}=\Phi\left(\mathbf{M}_{n}\right)\) by the definition of (15), and \(\mathbf{M}^{PS}=\Phi\left(\mathbf{M}^{PS}\right)\) by the definition of performative stability. Applying (107) yields

\[\left\|\mathbf{M}_{n}-\mathbf{M}^{PS}\right\|_{F}=\left\|\Phi \left(\mathbf{M}_{n-1}\right)-\Phi\left(\mathbf{M}^{PS}\right)\right\|_{F} \leq\frac{\sum_{t=0}^{T-1}\left(\varepsilon_{t}\sum_{i=t+1}^{T}\nu_{i} \right)}{\widetilde{\mu}}\left\|\mathbf{M}_{l-1}-\mathbf{M}^{PS}\right\|_{F} \tag{108}\] \[\leq\left(\frac{\sum_{t=0}^{T-1}\left(\varepsilon_{t}\sum_{i=t+ 1}^{T}\nu_{i}\right)}{\widetilde{\mu}}\right)^{n}\left\|\mathbf{M}_{0}- \mathbf{M}^{PS}\right\|_{F}.\]

Setting \(\left(\frac{\sum_{t=0}^{T-1}\left(\varepsilon_{t}\sum_{i=t+1}^{T}\nu_{i} \right)}{\widetilde{\mu}}\right)^{n}\left\|\mathbf{M}_{0}-\mathbf{M}^{PS} \right\|_{F}\) to be at most \(\rho\) and solving for \(n\) completes the proof.

## Appendix G Convergence Analysis of Algorithm 1

### Non-asymptomatic Convergence Analysis for Algorithm 1 with General Step Sizes

We have the following Lemma 5 regarding the convergence results of the proposed RSGD in Algorithm 1.

**Lemma 5**: _Under A1-A6. Consider a sequence of non-negative step sizes \(\left\{\eta_{n},n\geq 0\right\}\) satisfy_

\[\sup_{n\geq 0}\eta_{n}\leq\min\left\{\frac{\widetilde{\mu}-\sum_{t=0}^{T-1} \left(\varepsilon_{t}\sum_{i=t+1}^{T}\nu_{i}\right)}{2\left(\sum_{t=1}^{T} \lambda_{t}+\sum_{t=0}^{T-1}\left(\varepsilon_{t}\sum_{i=t+1}^{T}\nu_{i} \right)\right)^{2}},\frac{2}{\widetilde{\mu}-\sum_{t=0}^{T-1}\left(\varepsilon_ {t}\sum_{i=t+1}^{T}\nu_{i}\right)}\right\}, \tag{109}\]

_and_

\[\frac{\eta_{n}}{\eta_{n+1}}\leq\left(1+\frac{1}{2}\left(\widetilde{\mu}-\sum_{ t=0}^{T-1}\left(\varepsilon_{t}\sum_{i=t+1}^{T}\nu_{i}\right)\right)\eta_{n+1} \right), \tag{110}\]_for any \(n\geq 0\). Then, the iterates generated by RSGD admit the following bound for any \(N\geq 1\):_

\[\mathbb{E}\left[\left\|\mathbf{M}_{N}-\mathbf{M}^{PS}\right\|_{F}^{ 2}\right] \leq\prod_{n=0}^{N-1}\left(1-\eta_{n}\left(\widetilde{\mu}-\sum_{t=0}^{T-1 }\left(\varepsilon_{t}\sum_{i=t+1}^{T}\nu_{i}\right)\right)\right)\mathbb{E} \left[\left\|\mathbf{M}_{0}-\mathbf{M}^{PS}\right\|_{F}^{2}\right] \tag{111}\] \[\quad+\frac{4\eta_{N-1}T\sum_{t=1}^{T}\vartheta_{t}^{2}}{\widetilde {\mu}-\sum_{t=0}^{T-1}\left(\varepsilon_{t}\sum_{i=t+1}^{T}\nu_{i}\right)},\]

_where \(\vartheta_{t}=\kappa^{3}G\left(\left(HW+\kappa^{2}\right)\kappa\left\|\mathbf{ B}\right\|\beta_{t}+1\right)\left(x_{0}\alpha_{t}+c_{3}\beta_{t}\right)+GHWM \left(\kappa^{3}\beta_{t}+1\right),\forall 1\leq t\leq T\)._

_Proof._ Since projecting onto a convex set can only bring two iterates closer together, it follows that

\[\mathbb{E}\left[\left\|\mathbf{M}_{n+1}-\mathbf{M}^{PS}\right\|_ {F}^{2}\right]\leq\mathbb{E}\left[\left\|\mathbf{M}_{n}-\eta_{n}\nabla J_{T} \left(\mathbf{M}_{n};\left\{\mathbf{\Delta}_{t}\right\}_{0\leq t<T}\right)- \mathbf{M}^{PS}\right\|^{2}\right] \tag{112}\] \[\leq I_{1}+I_{2}+I_{3},\]

where

\[I_{1} =\mathbb{E}\left[\left\|\mathbf{M}_{n}-\mathbf{M}^{PS}\right\|_{F }^{2}\right], \tag{113}\] \[I_{2} =-2\eta_{n}\mathbb{E}\left[\operatorname{Tr}\left(\left(\mathbf{ M}_{n}-\mathbf{M}^{PS}\right)^{\top}\nabla J_{T}\left(\mathbf{M}_{n};\left\{ \mathbf{\Delta}_{t}\right\}_{0\leq t<T}\right)\right)\right],\] (114) \[I_{3} =\eta_{n}^{2}\mathbb{E}\left[\left\|\nabla J_{T}\left(\mathbf{M}_ {n};\left\{\mathbf{\Delta}_{t}\right\}_{0\leq t<T}\right)\right\|_{F}^{2} \right], \tag{115}\]

and \(\mathbf{\Delta}_{t}\sim\mathcal{D}_{t}\left(\mathbf{M}_{n}\right),\forall 0 \leq t<T\).

We first analyze the term \(I_{2}\). Let \(\mathbb{E}_{n}\left[\cdot\right]\) be the conditional expectation on \(\mathbf{M}_{n}\). We have

\[\mathbb{E}_{n}\left[\operatorname{Tr}\left(\left(\mathbf{M}_{n}- \mathbf{M}^{PS}\right)^{\top}\nabla J_{T}\left(\mathbf{M}_{n};\left\{\mathbf{ \Delta}_{t}\right\}_{0\leq t<T}\right)\right)\right]=\operatorname{Tr}\left( \left(\mathbf{M}_{n}-\mathbf{M}^{PS}\right)^{\top}\nabla C_{T}\left(\mathbf{M }_{n};\mathbf{M}_{n}\right)\right) \tag{116}\] \[\geq\operatorname{Tr}\left(\left(\mathbf{M}_{n}-\mathbf{M}^{PS} \right)^{\top}\left(\nabla C_{T}\left(\mathbf{M}_{n};\mathbf{M}_{n}\right)- \nabla C_{T}\left(\mathbf{M}_{n};\mathbf{M}^{PS}\right)\right)\right)\] \[+\operatorname{Tr}\left(\left(\mathbf{M}_{n}-\mathbf{M}^{PS} \right)^{\top}\left(\nabla C_{T}\left(\mathbf{M}_{n};\mathbf{M}^{PS}\right)- \nabla C_{T}\left(\mathbf{M}^{PS};\mathbf{M}^{PS}\right)\right)\right),\]

where we use the first order optimality condition in Proposition 3 that \(\left\langle\nabla C_{T}\left(\mathbf{M}^{PS};\mathbf{M}^{PS}\right),\mathbf{M }_{n}-\mathbf{M}^{PS}\right\rangle\geq 0\) in the last equality of (116).

Applying the Cauchy-Schwarz inequality and Lemma 3, we obtain

\[\operatorname{Tr}\left(\left(\mathbf{M}_{n}-\mathbf{M}^{PS}\right) ^{\top}\left(\nabla C_{T}\left(\mathbf{M}_{n};\mathbf{M}_{n}\right)-\nabla C_ {T}\left(\mathbf{M}_{n};\mathbf{M}^{PS}\right)\right)\right) \tag{117}\] \[\geq-\left\|\mathbf{M}_{n}-\mathbf{M}^{PS}\right\|_{F}\left(\sum_ {t=0}^{T-1}\left(\varepsilon_{t}\sum_{i=t+1}^{T}\nu_{i}\right)\left\|\mathbf{ M}_{n}-\mathbf{M}^{PS}\right\|_{F}\right)\] \[=-\sum_{t=0}^{T-1}\left(\varepsilon_{t}\sum_{i=t+1}^{T}\nu_{i} \right)\left\|\mathbf{M}_{n}-\mathbf{M}^{PS}\right\|_{F}^{2}.\]

Meanwhile, based on strongly convexity of \(C_{T}\) in Lemma 2, we have

\[\operatorname{Tr}\left(\left(\mathbf{M}_{n}-\mathbf{M}^{PS}\right)^{\top}\left( \nabla C_{T}\left(\mathbf{M}_{n};\mathbf{M}^{PS}\right)-\nabla C_{T}\left( \mathbf{M}^{PS};\mathbf{M}^{PS}\right)\right)\right)\geq\widetilde{\mu}\left\| \mathbf{M}_{n}-\mathbf{M}^{PS}\right\|_{F}^{2}. \tag{118}\]

Substitute (117) and (118) into (116) and take the full expectation, it follows that \(I_{2}\) satisfies

\[I_{2}\leq-2\eta_{n}\left(\widetilde{\mu}-\sum_{t=0}^{T-1}\left(\varepsilon_{t} \sum_{i=t+1}^{T}\nu_{i}\right)\right)\mathbb{E}\left[\left\|\mathbf{M}_{n}- \mathbf{M}^{PS}\right\|_{F}^{2}\right]. \tag{119}\]We next analyze the term \(I_{3}\). We observe the following equivalent expression for \(I_{3}\)

\[\left\|\nabla J_{T}\left(\mathbf{M}_{n};\left\{\mathbf{\Delta}_{t} \right\}_{0\leq t<T}\right)\right\|_{F}^{2}=\left\|\nabla J_{T}\left(\mathbf{M }_{n};\left\{\mathbf{\Delta}_{t}\right\}_{0\leq t<T}\right)-\nabla C_{T}\left( \mathbf{M}_{n};\mathbf{M}_{n}\right)\right. \tag{120}\] \[+\nabla C_{T}\left(\mathbf{M}_{n};\mathbf{M}_{n}\right)-\left. \nabla C_{T}\left(\mathbf{M}^{PS};\mathbf{M}^{PS}\right)\right\|_{F}^{2}.\]

Therefore,

\[\mathbb{E}\left[\left\|\nabla J_{T}\left(\mathbf{M}_{n};\left\{ \mathbf{\Delta}_{t}\right\}_{0\leq t<T}\right)\right\|_{F}^{2}\right] \tag{121}\] \[\leq 2\mathbb{E}\left[\left\|\nabla J_{T}\left(\mathbf{M}_{l}; \left\{\mathbf{\Delta}_{t}\right\}_{0\leq t<T}\right)-\nabla C_{T}\left( \mathbf{M}_{n};\mathbf{M}_{n}\right)\right\|_{F}^{2}\right]\] \[+2\mathbb{E}\left[\left\|\nabla C_{T}\left(\mathbf{M}_{n};\mathbf{ M}_{n}\right)-\nabla C_{T}\left(\mathbf{M}^{PS};\mathbf{M}^{PS}\right)\right\|_{F}^{ 2}\right].\]

According to Lemma C.1, an upper bound of the variance of \(\nabla J_{T}\left(\mathbf{M}_{n};\left\{\mathbf{\Delta}_{t}\right\}_{0\leq t<T }\right)\) is given by (94). Moreover, based on Lemma 3, we have

\[\mathbb{E}\left[\left\|\nabla C_{T}\left(\mathbf{M}_{n};\mathbf{M} _{n}\right)-\nabla C_{T}\left(\mathbf{M}^{PS};\mathbf{M}^{PS}\right)\right\|_{ F}^{2}\right] \tag{122}\] \[\leq\left(\sum_{t=1}^{T}\lambda_{t}+\sum_{t=0}^{T-1}\left( \varepsilon_{t}\sum_{i=t+1}^{T}\nu_{i}\right)\right)^{2}\mathbb{E}\left[\left\| \mathbf{M}_{n}-\mathbf{M}^{PS}\right\|_{F}^{2}\right].\]

Substitute (94) and (122) back into (121), it follows

\[I_{3}\leq 2\eta_{n}^{2}T\sum_{t=1}^{T}\vartheta_{t}^{2}+2\eta_{n}^{2} \left(\sum_{t=1}^{T}\lambda_{t}+\sum_{t=0}^{T-1}\left(\varepsilon_{t}\sum_{i= t+1}^{T}\nu_{i}\right)\right)^{2}\mathbb{E}\left[\left\|\mathbf{M}_{n}- \mathbf{M}^{PS}\right\|_{F}^{2}\right]. \tag{123}\]

Now substitute (119) and (123) back into (112), we obtain

\[\mathbb{E}\left[\left\|\mathbf{M}_{n+1}-\mathbf{M}^{PS}\right\|_{ F}^{2}\right]\leq\mathbb{E}\left[\left\|\mathbf{M}_{n}-\mathbf{M}^{PS}\right\|_{ F}^{2}\right]-2\eta_{n}\left(\widetilde{\mu}-\sum_{t=0}^{T-1}\left( \varepsilon_{t}\sum_{i=t+1}^{T}\nu_{i}\right)\right) \tag{124}\] \[\cdot\mathbb{E}\left[\left\|\mathbf{M}_{n}-\mathbf{M}^{PS}\right\| _{F}^{2}\right]+2\eta_{n}^{2}\left(\sum_{t=1}^{T}\lambda_{t}+\sum_{t=0}^{T-1} \left(\varepsilon_{t}\sum_{i=t+1}^{T}\nu_{i}\right)\right)^{2}\mathbb{E} \left[\left\|\mathbf{M}_{n}-\mathbf{M}^{PS}\right\|_{F}^{2}\right]+2\eta_{n}^{ 2}T\sum_{t=1}^{T}\vartheta_{t}^{2}\] \[=\left(1-2\eta_{n}\left(\widetilde{\mu}-\sum_{t=0}^{T-1}\left( \varepsilon_{t}\sum_{i=t+1}^{T}\nu_{i}\right)\right)+2\eta_{n}^{2}\left(\sum_ {t=1}^{T}\lambda_{t}+\sum_{t=0}^{T-1}\left(\varepsilon_{t}\sum_{i=t+1}^{T}\nu _{i}\right)\right)^{2}\right)\mathbb{E}\left[\left\|\mathbf{M}_{n}-\mathbf{M} ^{PS}\right\|_{F}^{2}\right]\] \[+2\eta_{n}^{2}T\sum_{t=1}^{T}\vartheta_{t}^{2}.\]

Let \(\eta_{n}\) be choosen such that \(\eta_{n}\left(\widetilde{\mu}-\sum_{t=0}^{T-1}\left(\varepsilon_{t}\sum_{i=t +1}^{T}\nu_{i}\right)\right)\)\(\geq 2\eta_{n}^{2}\left(\sum_{t=1}^{T}\lambda_{t}+\sum_{t=0}^{T-1}\left( \varepsilon_{t}\sum_{i=t+1}^{T}\nu_{i}\right)\right)^{2}\). Then inequality (124) is reduced to

\[\mathbb{E}\left[\left\|\mathbf{M}_{n+1}-\mathbf{M}^{PS}\right\| _{F}^{2}\right]\leq \left(1-\eta_{n}\left(\widetilde{\mu}-\sum_{t=0}^{T-1}\left( \varepsilon_{t}\sum_{i=t+1}^{T}\nu_{i}\right)\right)\right)\mathbb{E}\left[ \left\|\mathbf{M}_{n}-\mathbf{M}^{PS}\right\|_{F}^{2}\right] \tag{125}\] \[+2\eta_{n}^{2}T\sum_{t=1}^{T}\vartheta_{t}^{2}.\]

[MISSING_PAGE_FAIL:34]

[MISSING_PAGE_EMPTY:35]

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer:[Yes] Justification: The abstract and introduction accurately reflect the paper's contributions and scope. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer:[Yes] Justification: We have discussed the limitations of the work in the Conclusion section. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes]Justification: The paper has provided the full set of assumptions and a complete and correct proof. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: We have disclosed all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.

5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [No] Justification: The paper does not provide open access to the data and code. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines ([https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy)) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so No is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines ([https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy)) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: The paper has specified all the training and test details (e.g., data splits, hyperparameters). Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: The paper has provided appropriate information about the statistical significance of the experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.

* The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).
* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer:[No] Justification: The paper does not provide the type of compute workers, memory, or time of execution. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics [https://neurips.cc/public/EthicsGuidelines?](https://neurips.cc/public/EthicsGuidelines?) Answer: [Yes] Justification: The research conducted in the paper conform with the NeurIPS Code of Ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: There is no societal impact of the work performed. Guidelines: * The answer NA means that there is no societal impact of the work performed.

* If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.
* Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.
* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).

11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: The paper poses no such risks. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [NA] Justification: The paper does not use existing assets. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.

* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: The paper does not release new assets. Guidelines: * The answer NA means that the paper does not release new assets. * Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. * The paper should discuss whether and how consent was obtained from people whose asset is used. * At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. * According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.

* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.