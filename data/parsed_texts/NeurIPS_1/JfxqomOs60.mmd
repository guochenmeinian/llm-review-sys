# Unravelling in Collaborative Learning

Aymeric Capitaine\({}^{1}\)

Etienne Boursier\({}^{2}\)

Antoine Scheid\({}^{1}\)

Eric Moulines\({}^{1}\)

Michael I. Jordan\({}^{3}\)

El-Mahdi El-Mhamdi\({}^{1}\)

Alain Durmus\({}^{1}\)

###### Abstract

Collaborative learning offers a promising avenue for leveraging decentralized data. However, collaboration in groups of strategic learners is not a given. In this work, we consider strategic agents who wish to train a model together but have sampling distributions of different quality. The collaboration is organized by a benevolent aggregator who gathers samples so as to maximize total welfare, but is unaware of data quality. This setting allows us to shed light on the deleterious effect of _adverse selection_ in collaborative learning. More precisely, we demonstrate that when data quality indices are private, the coalition may undergo a phenomenon known as _unravelling_, wherein it shrinks up to the point that it becomes empty or solely comprised of the worst agent. We show how this issue can be addressed without making use of external transfers, by proposing a novel method inspired by probabilistic verification. This approach makes the grand coalition a Nash equilibrium with high probability despite information asymmetry, thereby breaking unravelling.

## 1 Introduction

Collaborative learning is a framework in which multiple agents share their data and computational resources to address a common learning task [1, 16]. A significant challenge arises when the quality of these distributions is unknown centrally and agents are strategic. Indeed, participants may be tempted to withhold or misrepresent the quality of their data to gain a competitive advantage. These strategic behaviors and their consequences have been studied extensively in the literature on information economics [14, 15]. In particular, information asymmetry is known to result in _adverse selection_, whereby low-quality goods end up dominating the market. In the current paper we study collaborative learning from the perspective of information economics.

A vivid illustration of adverse selection is found in Akerlof's seminal work on the market for lemons [second-hand cars of low quality, 1]. Because buyers cannot properly assess the quality of cars on the second-hand market, their inclination to pay decreases. As a consequence, sellers with high-quality cars withdraw from the market, since the proposed price falls below their reservation price. This in turn lowers the buyers' expectation regarding the average quality of cars on the market, so their willingness to pay decreases even more, which _de facto_ crowds out additional cars. Themarket may therefore enter a death spiral, up to the point where only low-quality cars are exchanged in any competitive Nash equilibrium. This phenomenon is known as _unravelling_. The insurance market serves as another poignant example of this effect (Rothschild and Stiglitz, 1976; Einav and Finkelstein, 2011; Hendren, 2013). In insurance, information asymmetry arises due to the fact that insurees possess private knowledge about their individual risk profiles, which insurers lack. Individuals with higher risk are more inclined to purchase policy, while those with lower risk opt out. Consequently, insurers are left with a pool of policyholders skewed towards higher risk, leading to increased premiums to cover potential losses. This, in turn, prompts low-risk individuals to exit the market, exacerbating adverse selection further--a cycle reminiscent of the unravelling described by Akerlof.

We study the problem of whether collaborative learning could also fall victim to unravelling. We consider strategic agents who have access to sampling distributions of varying quality and wish to jointly train a model. They delegate the training process to a central authority who collects samples so as to maximize total welfare. We ask whether adverse selection can arise when data quality is private information. In particular, the presence of a low-quality data owner may harm the model, prompting high-quality owner to leave the collaboration and train a model entirely on their own. Their departure would decrease the average data quality even more, and create a vicious circle. In the worst case, the coalition of learners would reduce to the lowest data quality owner alone. This question is of prime importance from a practical point of view, because unravelling could jeopardize the long-run stability of collaborative models deployed at large scale.

Our contribution is threefold:

1. We provide a rigorous framework for analyzing collaborative learning with strategic agents having data distributions of varying quality. On the one hand, we leverage tools from domain adaptation to capture a notion of data quality formally. On the other hand, we model collaboration as a principal-agent problem, where the principal is an aggregator in charge of collecting samples so as to maximize social welfare. This setup allows us to derive the benchmark welfare-maximizing collaboration scheme when data quality is public information.
2. We show that when data quality is private, a naive aggregation strategy which consists in asking agents to declare their quality type and applying the optimal scheme results in a complete unravelling. More precisely, the set of agents willing to collaborate is either empty or made of the lowest-quality data owner alone at any pure Nash equilibrium.
3. We present solutions to unravelling. When transfers are allowed, the VCG mechanism suffices to re-establish optimality. When transfers are not possible, we leverage probabilistic verification techniques to design a mechanism which breaks unravelling. More precisely, we ensure that the optimal, grand coalition ranks with high probability among the Nash equilibria of the game induced by our mechanism. We demonstrate how to implement our mechanism practically in the setting of classification.

Related work.The issue of information asymmetry in machine learning has been an area of recent activity. Several learning settings have been considered, including bandits (Wei et al., 2024), linear regression (Donahue and Kleinberg, 2021, 2021), classification (Blum et al., 2021) and empirical risk minimization (Dorner et al., 2023; Liu et al., 2023) in a federated context (Tu et al., 2022).

Most of these studies focus on the sub-problem of _moral hazard_, where agents take actions that are unobserved by others. This situation usually results in under-provision of effort and inefficiency at the collective scale (Laffont and Martimort, 2001). This issue appears naturally in federated learning, because model updates are performed locally. For instance, Karimireddy et al. (2022) show that heterogeneity in sampling costs results in total free-riding without a proper incentive scheme. Huang et al. (2022) show that under-provision of data points in federated learning arises from privacy concerns. Yan et al. (2023) consider a federated classification game where agents can reduce the noise in their data distribution but incur a costly effort to do so. In the same vein, Huang et al. (2023) study the case of agents who are interested in different models, and may skew their sampling measure accordingly. Saig et al. (2023) and Ananthakrishnan et al. (2023) study hidden actions when a principal delegates a predictive task to another agent, and show that thresholds or linear contracts are able to approximate the optimal contracts.

_Adverse selection_ is another type of information asymmetry, where preferences of agents are unobserved rather than actions. This issue also naturally arises in collaborative learning, because the data distributions from which agents sample or about which they care may not be public. Whiledata heterogeneity is a widely explored topic in federated learning (see for instance Gao et al. 2022 for a general survey, and Fu et al. 2023 for the specific problem of _client selection_), the strategic aspect has been rarely considered. Most studies doing so focus on hidden sampling costs (see, e.g., Karimireddy et al. 2022, or Wei et al. 2024 in a bandit context), but few address the fundamental problem of distribution shift. Ananthakrishnan et al. (2023) mentions the issue of adverse selection when a principal delegates a predictive task to an agent, and provide qualitative insights about the optimal contract. However, they consider a single agent and leave aside the question of participation. Finally, Werner et al. (2024) and Tsoy and Konstantinov (2024) study the question of the stability of collaborative learning between competing agents. However, their analysis relies on ad-hoc market structures rather than information asymmetry per se. As such, our work is the first to demonstrate the effect of imperfect information on the sustainability of collaborative learning.

Organization.Section 2 presents our model and assumptions. Section 3 studies a full information benchmark, which allows us to derive the welfare-maximizing contribution scheme. In Section 4, we turn to the more realistic case where data quality is private information. We first show that in this case, a naive aggregation method leads to total unravelling. Second, we introduce a mechanism which breaks unravelling by inducing a game where the grand coalition is a pure strategy Nash equilibrium with high probability.

## 2 Model

Statistical framework.Let \((\mathsf{X},\mathcal{X})\) and \((\mathsf{Y},\mathcal{Y})\) be two measurable spaces and denote by \(\mathcal{P}\) a family of probability measures on \((\mathsf{X}\times\mathsf{Y},\mathcal{X}\otimes\mathcal{Y})\). We consider \([J]=\{1,\ldots,J\}\) agents who aim to perform a prediction task associated with a hypothesis class \(\mathscr{G}\subset\{g:\mathsf{X}\rightarrow\mathsf{Y}\}\), a loss function \(\ell:\mathsf{Y}\times\mathsf{Y}\) and a probability measure \(P_{0}\in\mathcal{P}\). Each agent seeks to minimize \(g\in\mathscr{G}\mapsto\mathcal{R}_{P_{0}}(g)\) where for any probability distribution \(P\in\mathcal{P}\), \(\mathcal{R}_{P}(g)=\int\ell(g(x),y)\mathrm{d}P(x,y)\) is the risk associated to \(g\in\mathscr{G}\) with respect to \(P\).

We leverage tools and results from statistical learning theory. Denote by \(\{(X_{i},Y_{i})\}_{i\geqslant 1}\) the canonical process on \(\mathsf{X}\times\mathsf{Y}\) and denote by \(\mathbb{P}_{P}\) and \(\mathbb{E}_{P}\) the canonical probability and expectation under which \(\{(X_{i},Y_{i})\}_{i\geqslant 1}\) are i.i.d. random variables with distribution \(P\in\mathcal{P}\). With this notation, we can introduce our assumptions on \(\mathscr{G}\) and \(\mathcal{P}\).

**H1**.: _For \(\delta\in(0,1)\), there exist \(\alpha_{\delta}>0\), \(\beta>0\) and \(\gamma>0\) such that for any distribution \(P\in\mathcal{P}\), hypothesis \(g\in\mathcal{G}\) and \(n\geqslant 1\)_

\[\mathbb{P}_{P}\Bigg{(}\bigg{|}\mathcal{R}_{P}(g)-\frac{1}{n}\sum_{i=1}^{n}\ell (g(X_{i}),Y_{i})\bigg{|}\leqslant\frac{\alpha_{\delta}}{(1+n)^{\gamma}}+\beta \Bigg{)}\geqslant 1-\delta\;.\]

This assumption covers a wide range of situations. For instance in the classification case where \(\mathsf{Y}=\{-1,1\}\) and \(\ell:(y,\bar{y})\mapsto\mathbb{1}_{\{y\bar{y}\leqslant 0\}}\), \(\alpha_{\delta}=\sqrt{\ln(1/\delta)/2}\), \(\beta=2\textsc{Rad}(\mathscr{G})\) and \(\gamma=1/2\) where \(\textsc{Rad}(\mathscr{G})\) is the empirical Rademacher complexity of \(\mathscr{G}\)(Bousquet et al., 2003). Similarly, the Bayesian PAC approach in the linear regression context with bounded loss leads to \(\alpha_{\delta}=\mathrm{KL}(\rho\|\pi)+\ln(1/\delta)\), \(\beta=\|\ell\|_{\infty}^{2}/8\) and \(\gamma=1\) where \(\rho\) and \(\pi\) are any distributions on \(\mathscr{G}\)(Shalaeva et al., 2019, Corollary 4).

For ease of notation, we let \(\mathcal{R}_{j}(g)\) serve as a shorthand for \(\mathcal{R}_{P_{j}}(g)\). It is moreover assumed that agent \(j\in[J]\) cannot directly sample from \(P_{0}\), but has instead access to a distribution \(P_{j}\in\mathcal{P}\) which deviates from \(P_{0}\) according to the \(\mathscr{G}\)-divergence:

**H2**.: _For any \(j\in[J]\), \(P_{j}\in\mathcal{P}\) has finite \(\mathscr{G}\)-divergence: \(\theta_{j}=\sup_{g\in\mathscr{G}}|\mathcal{R}_{j}(g)-\mathcal{R}_{0}(g)|<+ \infty\;\;.\)_

Intuitively, for any \(j\in[J],\,\theta_{j}\geqslant 0\) models the bias incurred by having access to samples from \(P_{j}\) instead of the target distribution \(P_{0}\). More precisely, the risk excess associated with empirical risk minimization (ERM) based on samples from \(P_{j}\) is in the worst case at least \(\theta_{j}\). A poor sampling distribution \(P_{j}\)--which corresponds to a high \(\theta_{j}\) in the previous expression--might be the consequence of low-quality sensors or degraded experimental conditions resulting in noisier data points.

The class of discrepancies appearing in **H2** has been considered in the domain adaptation literature (see, e.g., Ben-David et al., 2010, Kifer et al., 2004, Konstantinov and Lampert, 2019). It provides a natural framework to analyze the behavior of models trained on diverse distributions, and is practically appealing since it can be easily estimated in the context of classification (Ben-David et al., 2010).

We make the following assumptions on the quality indexes \((\theta_{1},\ldots,\theta_{J})\), hereafter referred to as _types_.

**H3.**_There exists \((\underline{\theta},\bar{\theta})\in\mathbb{R}_{+}^{2}\) such that \(\underline{\theta}\leqslant\theta_{1}<\theta_{2}<\ldots<\theta_{J}\leqslant\bar {\theta}\)._

**H3** The ordering assumption is just for ease of exposition but is neither used by the aggregator nor the agents. Our condition that types are strictly different is for convenience in simplifying the proofs.

Collaborative learning framework.We further suppose that agent \(j\in[J]\) can fit a model \(g\in\mathscr{G}\) based on i.i.d. samples \(\{(X_{1}^{j},Y_{1}^{j}),\ldots,(X_{n_{j}}^{j},Y_{n_{j}}^{j})\}\) of size \(n_{j}\geqslant 0\) from \(P_{j}\in\mathcal{P}\) in one of two ways: they can compute on their own, or collaborate. This is captured by the two following options:

**Option 1**: Agent \(j\) performs ERM on their own samples:

\[\widehat{g}_{j}=\operatorname*{argmin}_{g\in\mathscr{G}}\widehat{\mathcal{R} }_{j}(g)\;,\qquad\widehat{\mathcal{R}}_{j}(g)=n_{j}^{-1}\sum_{i=1}^{n_{j}} \ell(g(X_{i}^{j}),Y_{i}^{j})\;. \tag{1}\]

This non-collaborative procedure is referred to as the _outside option_.

**Option 2**: Agent \(j\) can take part in a _coalition_ orchestrated by a central data aggregator, encoded as \(\mathsf{B}=(B_{1},\ldots,B_{J})\in\{0,1\}^{J}\), where \(B_{j}=1\) means that agent \(j\) is member of the coalition. We also write \(\mathcal{B}=\{j\in[J]:\,B_{j}=1\}\). In exchange for their samples, agent \(j\) gains access to the collaborative model trained over the concatenation of samples:

\[\widehat{g}_{\mathsf{B}} =\operatorname*{argmin}_{g\in\mathscr{G}}\widehat{\mathcal{R}}_{ \mathsf{B}}(g)\;, \tag{2}\] \[\text{where}\quad\widehat{\mathcal{R}}_{\mathsf{B}}(g) =N^{-1}\sum_{j\in[J]}B_{j}\sum_{i=1}^{n_{j}}\ell(g(X_{i}^{j}),Y_{ i}^{j})\quad\text{ and }\quad N=\sum_{j\in[J]}B_{j}n_{j}\;.\]

Agent utilities.We assume that agents incur a unitary cost for sampling from their distribution and dislike statistical risk. Therefore, a baseline model for measuring the preferences associated with a model \(g\in\mathcal{G}\) and a number of samples \(n\) is based on a linear map: \((g,n)\mapsto-a\mathcal{R}_{0}(g)-cn\) for \(a,c>0\). In practice, however, \(\mathcal{R}_{0}(g)\) is typically unknown so agents instead can use a PAC bound of the form \(\mathbb{P}(\mathcal{R}_{0}(\widehat{g}_{n})\leqslant\mathcal{R}_{0}^{*}+ \varepsilon)\geqslant 1-\delta\) to a assess a model \(\widehat{g}_{n}\in\mathscr{G}\) trained over their samples, where \(\varepsilon>0\), \(\delta\in(0,1)\) and \(\mathcal{R}_{0}^{*}=\inf_{g\in\mathscr{G}}\mathcal{R}_{0}(g)\). Our next result shows that **H**1 and **H**2 allow each agent to pin down such an \(\varepsilon>0\), under either **Option**1) or **Option**2). Assuming **H**1, define the function \(\varepsilon\) for any \((\theta,n)\in\Theta\times\mathbb{R}_{+}\) by

\[\varepsilon(\theta,n)=2\big{[}\alpha_{\delta}(1+n)^{-\gamma}+\beta+\theta \big{]}\;. \tag{3}\]

**Lemma 1**.: _Assume **H**1 and **H**2._

1. _Any agent_ \(j\in[J]\) _picking the outside_ **Option**1) obtains a model_ \(\widehat{g}_{j}\in\mathscr{G}\) _achieving_ \[\mathcal{R}_{0}(\widehat{g}_{j})\leqslant\mathcal{R}_{0}^{\star}+\varepsilon (\theta_{j},n_{j})\quad\text{with probability }1-\delta\;.\]
2. _Any coalition_ \(\mathsf{B}\in\{0,1\}^{J}\) _drawing_ \(\mathbf{n}=(n_{1},\ldots,n_{J})\in\mathbb{R}_{+}^{J}\)_, samples obtains a model_ \(\widehat{g}_{\mathsf{B}}\in\mathscr{G}\) _achieving_ \[\mathcal{R}_{0}(\widehat{g}_{\mathsf{B}})\leqslant\mathcal{R}_{0}^{\star}+ \varepsilon(\vartheta,N)\quad\text{with probability }1-\delta\;,\]

_where \(N\) is the total of samples and \(\vartheta\) is the weighted average type within the coalition:_

\[N(B,\mathbf{n})=\sum_{j\in[J]}B_{j}n_{j}\;,\qquad\vartheta(\mathsf{B}, \mathbf{n})=N^{-1}\sum_{j\in[J]}B_{j}n_{j}\theta_{j}\;. \tag{4}\]

When the context is clear, we write \(\varepsilon(\mathsf{B},\mathbf{n})=\varepsilon(\vartheta(\mathsf{B},\mathbf{ n}),N(\mathsf{B},\mathbf{n}))\) to lighten notation. Based on Lemma 1, we define the utility of agent \(j\in[J]\) as

\[u_{j}:(\mathsf{B},\mathbf{n})\mapsto-a[\,\mathcal{R}_{0}^{\star}+(1-B_{j}) \varepsilon(\theta_{j},n_{j})+B_{j}\varepsilon(\mathsf{B},\mathbf{n})\,]-cn_{ j}\;. \tag{5}\]Note that for any \(j\in[J]\), we take \(n_{j}\geqslant 0\) to be a real number for ease of presentation. In (5), \(a/c>0\) captures the extent to which individuals are willing to trade off model quality against sampling cost.

For any \(j\in[J]\) and \(\mathsf{B}_{-j}=(B_{1},\ldots,B_{j-1},B_{j+1},\ldots,B_{J})\in\{0,1\}^{J-1}\), we denote by a slight abuse of notation \((B,\mathsf{B}_{-j})=(B_{1},\ldots,B_{j-1},B,B_{j+1},\ldots,B_{J})\) for any \(B\in\{0,1\}\). Similarly for \(\mathbf{n}_{-j}=(n_{1},\ldots,n_{j-1},n_{j+1},\ldots,n_{j})\in\mathbb{R}_{+}^{ J-1}\), we write \((n,\mathbf{n}_{-j})=(n_{1},\ldots,n_{j-1},n,n_{j+1},\ldots,n_{j})\) for any \(n\geqslant 0\). We can then characterize the optimal behavior of any agent picking the outside option as follows.

**Proposition 1**.: _Assume 1 and 2. For any \(j\in[J]\), \(\mathsf{B}_{-j}\in\{0,1\}^{J-1}\) and \(\mathbf{n}_{-j}\in\mathbb{R}_{+}^{J-1}\), the optimal number of samples to draw under Option 1) is \(\operatorname*{argmax}_{n\geq 0}u_{j}((0,\mathsf{B}_{-j}),(n,\mathbf{n}_{-j} )\,;\,\theta_{j})=\underline{n}\) where_

\[\underline{n}=(2ac^{-1}\gamma\alpha_{\delta})^{1/(\gamma+1)}-1\;. \tag{6}\]

In what follows, we assume \(2a/c>(\gamma\alpha_{\delta})^{-1}\) to exclude the pathological case where no agent is willing to sample data points. From now on, we denote by

\[\underline{u}_{j}=u_{j}((0,\mathsf{B}_{-j}),(\underline{n},\mathbf{n}_{-j})) \tag{7}\]

the best achievable utility under the outside option. Note that \(\underline{n}\) does not depend on \(\theta_{j}\in\Theta\) (but \(\underline{u}_{j}\) does) so all agents outside of the coalition draw a same number of data points \(\underline{n}>0\). This result, which may be surprising at first glance, comes from the fact that all agents have the same accuracy-to-sampling-cost ratio \(a/c\) in their utility.

Aggregator.We finally assume that the aggregator acts benevolently to set up a Pareto-optimal collaboration, by maximizing the total welfare under individual rationality. In other words, they solve:

\[\text{maximize}\quad W:\;(\mathsf{B},\mathbf{n})\in\{0,1\}^{J} \times\mathbb{R}_{+}^{J}\mapsto\sum_{j\in[J]}u_{j}(\mathsf{B},\mathbf{n}) \tag{8}\] \[\text{subject to}\quad\min_{j\in[J]}u_{j}(\mathsf{B},\mathbf{n}) -\underline{u}_{j}\geqslant 0\;.\]

In the Social Choice literature, \(W\) is referred to as the utilitarian social welfare function. The participation constraint ensures that no agent within the coalition finds it beneficial to switch to their outside option. Note that \(\mathbf{n}\in\mathbb{R}_{+}^{J}\) is required to have non-negative entries, which prevents the aggregator from giving away data points to agents.

## 3 Full-Information Benchmark: First-Best Collaboration

In this section, we assume that the profile of types \((\theta_{1},\ldots,\theta_{J})\in\Theta^{J}\) is public, and study how the aggregator can implement an optimal collaboration among agents under this most-favorable scenario.

Exact solution.We are looking for a solution to the aggregator's problem (8). For any \(\mathsf{B}\in\{0,1\}^{J}\) and \(\mathbf{n}\in\mathbb{R}_{+}^{J}\), denote by

\[\overline{n}_{j}(\mathsf{B},\mathbf{n}) =\max\{n\geqslant 0:\,u_{j}((1,\mathsf{B}_{-j}),(n, \mathbf{n}_{-j})\,;\,\theta_{j})\geqslant\underline{u}_{j}\}\] \[=\underline{n}-(a/c)[\varepsilon(\mathsf{B},\mathbf{n})- \varepsilon(\theta_{j},\underline{n})]\;, \tag{9}\]

the maximum number of samples that agent \(j\) can be asked to provide within the coalition under its participation constraint, where \(\underline{n}\) is defined as in (6), and \(\underline{u}_{j}\) as in (7). With this notation, problem (8) rewrites

\[\text{maximize}\quad W(\mathsf{B},\mathbf{n})\quad\text{subject to}\quad \min_{j\in\mathsf{B}}\overline{n}_{j}(\mathsf{B},\mathbf{n})-n_{j}\geqslant 0\;. \tag{10}\]

**Theorem 1**.: _Assume 1, 2, 3. Problem (8) admits a unique solution \((\mathsf{B}^{\mathrm{opt}},\mathbf{n}^{\mathrm{opt}}(\boldsymbol{\theta}))\in \{0,1\}^{J}\times\mathbb{R}_{+}^{J}\). Moreover,_

1. \(\mathsf{B}^{\mathrm{opt}}=\mathbf{1}=(1,\ldots,1)\)_,__._
2. _Denoting_ \(\mathbf{n}^{\mathrm{opt}}(\boldsymbol{\theta})=(n_{1}^{\mathrm{opt}}(\boldsymbol{ \theta}),\ldots,n_{J}^{\mathrm{opt}}(\boldsymbol{\theta}))\)_, there exists_ \(L^{\mathrm{opt}}\in[J]\) _such that for any_ \(j\in[J]\)_,_ \[n_{j}^{\mathrm{opt}}(\boldsymbol{\theta})\begin{cases}\begin{aligned} &=\overline{n}_{j}(\mathbf{1},\mathbf{n}^{\mathrm{opt}}( \boldsymbol{\theta}))&&\text{if }j<L^{\mathrm{opt}},\\ &\in[0\,,\,\overline{n}_{j}(\mathbf{1},\mathbf{n}^{\mathrm{opt}}( \boldsymbol{\theta}))\,]&&\text{if }j=L^{\mathrm{opt}},\\ &=0&&\text{otherwise}.\end{aligned}\end{cases}\] (11)

The couple \((\mathsf{B}^{\mathrm{opt}},\mathbf{n}^{\mathrm{opt}})\) is referred to as the _optimal contribution scheme_. Although implicit, the condition (11) provides insights about the optimal scheme. The aggregator makes everyone enter the coalition, but only asks the \(L^{\mathrm{opt}}>0\) first-best agents to contribute. This allows to obtain the best possible collaborative model while sparing any sampling cost to other agents. Moreover, the number of required samples \(n_{j}^{\mathrm{opt}}(\boldsymbol{\theta})\) slightly differs from \(\underline{n}\) according to the relative performance of the collaborative model with respect to agent \(j\)'s one: if the agent gets a better accuracy by collaborating, the aggregator can ask them for more data; if on the other hand the agent gets a worse model by collaborating (i.e., they are a contributor with very high quality data), the aggregator can only ask less data because of the participation constraint.

Relaxed solution.Working with the optimal scheme \((\mathsf{B}^{\mathrm{opt}},\mathbf{n}^{\mathrm{opt}})\) is difficult because \(\overline{n}_{j}(\mathbf{1},\mathbf{n}^{\mathrm{opt}}(\boldsymbol{\theta}))\) has no explicit expression. To make the analysis tractable, we slightly simply the optimal contribution scheme in Theorem 1 and consider the simplified optimal contribution scheme \((\mathsf{B}^{\star},\mathbf{n}^{\star})\) where \(\mathsf{B}^{\star}=\mathsf{B}^{\mathrm{opt}}=(1,\ldots,1)\) and for any \(j\in[J]\),

\[n_{j}^{\star}(\boldsymbol{\theta})=\mathbb{1}_{\{j\leq L^{\star} \}}\overline{n}_{j}(\mathbf{1},\mathbf{n}^{\star}(\boldsymbol{\theta})) \quad\text{and}\quad L^{\star}=\min\{j\in[J]:\,\sum_{k\leq j} \overline{n}_{k}(\mathbf{1},\mathbf{n}^{\star}(\boldsymbol{\theta}))\geqslant \bar{N}\}\;, \tag{12}\] \[\text{with}\quad\bar{N}=(\underline{n}+1)J^{\frac{1}{1+\gamma}}-1\;.\]

Note that \((\mathsf{B}^{\star},\mathbf{n}^{\star})\) only differs from \((\mathsf{B}^{\mathrm{opt}},\mathbf{n}^{\mathrm{opt}})\) in two ways. First, in \((\mathsf{B}^{\star},\mathbf{n}^{\star})\) all contributors' participation constraint bind, while in \((\mathsf{B}^{\mathrm{opt}},\mathbf{n}^{\mathrm{opt}})\) the \(L^{\mathrm{opt}}\)-the one could be slack. Second, the total number of data points required from the coalition is fixed and equal to \(\bar{N}=\Theta(J^{\frac{1}{1+\gamma}})\). The quantity \(\bar{N}\) comes from a natural relaxation of the original problem Equation (10) where we leave aside an intricate term of the objective function. This relaxation, which is formally described in Appendix A, provides a good approximation of the exact solution in reasonable settings. Indeed, the following result establishes that applying \((\mathsf{B}^{\star},\mathbf{n}^{\star})\) instead of \((\mathsf{B}^{\mathrm{opt}},\mathbf{n}^{\mathrm{opt}})\) comes at a negligible welfare cost when types are sufficiently evenly spaced.

**Lemma 2**.: _Assume **H**1, **H**2 and \(\theta_{j}-\theta_{j-1}=\mathcal{O}(1/J)\) for any \(j\in\{2,\ldots,J\}\). Then,_

\[W(\mathsf{B}^{\mathrm{opt}},\mathbf{n}^{\mathrm{opt}}(\boldsymbol{\theta}))=W( \mathsf{B}^{\star},\mathbf{n}^{\star}(\boldsymbol{\theta}))+\mathcal{O}(J^{ \frac{1}{1+\gamma}})\;.\]

Moreover, the following proposition shows that \(\mathbf{n}^{\star}(\boldsymbol{\theta})\) admits a workable expression.

**Corollary 1**.: _Assume **H**1, **H**2 and **H**3. Then \(L^{\star}=\Theta(J^{\frac{1}{1+\gamma}})\) and for any \(j\in[J]\),_

\[n_{j}^{\star}(\boldsymbol{\theta})=\mathbb{1}_{\{j\leq L^{\star} \}}\Bigg{[}\frac{\bar{N}}{L^{\star}}+\frac{2a}{c}\Bigg{(}\theta_{j}-\frac{1} {L^{\star}}\sum_{\ell=1}^{L^{\star}}\theta_{\ell}\Bigg{)}\Bigg{]}\;.\]

Since \((\mathsf{B}^{\star},\mathbf{n}^{\star})\) correctly approximates the optimal scheme while being more tractable, we work with it in the remainder to lighten proofs.

**H4**.: _The aggregator applies the simplified contribution scheme \((\mathsf{B}^{\star},\mathbf{n}^{\star})\)._

## 4 Hidden information

The welfare-maximizing contribution scheme described in (12) depends explicitly on \(\boldsymbol{\theta}\in\Theta^{J}\), so it is implementable only if types are public. This often unrealistic, either for legal or competitive reasons. We therefore turn to the problem of setting up a collaboration when types are private.

### Naive aggregation and unravelling

A naive solution to coping with the private nature of \(\mathbf{\theta}\in\Theta^{J}\) is for the aggregator to ask agents to disclose their types, and apply the simplified optimal contribution scheme defined in (12). In this setting, however, agents may declare a type \(\widetilde{\theta}_{j}\) different from their true type \(\theta_{j}\).

This approach corresponds to a direct-revelation mechanism \(\Gamma:(\mathsf{B},\widetilde{\mathbf{\theta}})\mapsto\mathbf{n}^{*}(\widetilde{ \mathbf{\theta}})\) which unfolds as follows.

1. Any agent \(j\in[J]\) declares a tuple \((B_{j},\widetilde{\theta}_{j})\in\{0,1\}\times\Theta\cup\{\dagger\}\). If \(B_{j}=1\), then agent \(j\) picks **Option**2), and enters the coalition with type \(\widetilde{\theta}_{j}\). If \(B_{j}=0\), then agent \(j\) picks **Option**1), their declared type \(\widetilde{\theta}_{j}\) is \(\dagger\) by convention.
2. Setting \(\mathsf{B}=(B_{1},\ldots,B_{J})\) and \(\widetilde{\mathbf{\theta}}\in(\Theta\cup\{\dagger\})^{J}\), then the aggregator applies the contribution scheme defined in (12), so the vector of number of contributions within the coalition is \(\mathbf{n}^{*}(\widetilde{\mathbf{\theta}})\).

\(\Gamma\) induces a direct revelation game \(([J],\mathscr{S}^{J},(v_{j})_{j\in[J]})\) where the action space is \(\mathscr{S}=\{(1,\widetilde{\theta})\,:\,\widetilde{\theta}\in\Theta\}\cup\{( 0,\dagger)\}\) and payoffs are for any \(j\in[J]\) and \(\mathbf{s}\in\mathscr{S}^{J}\),

\[v_{j}(s_{j},\mathbf{s}_{-j})=u_{j}(\mathsf{B},\mathbf{n}^{*}(\widetilde{\mathbf{ \theta}}))=B_{j}\Big{[}-a\Big{(}\mathcal{R}_{0}^{*}+\varepsilon(\mathsf{B}, \mathbf{n}^{*}(\widetilde{\mathbf{\theta}}))\Big{)}-cn_{j}^{*}(\widetilde{\mathbf{ \theta}})\Big{]}+(1-B_{j})\underline{u}_{j}\;.\]

This mechanism is obviously vulnerable to strategic manipulation, since it disregards incentive compatibility. This has severe consequences for the coalition, as shown by the following proposition.

**Theorem 2** (Unravelling).: _Assume **H1**, **H2**, **H3**, and **H4**. Let \(\mathscr{E}\subset\mathscr{S}^{J}\) be the set of pure-strategy Nash equilibria of the game induced by \(\Gamma\). We have_

1. \(\mathscr{E}\neq\emptyset\)__
2. _at any_ \(s^{*}\in\mathscr{E}\)_,_ \(\mathsf{B}=(0,\ldots,0)\) _or_ \(\mathsf{B}=(0,\ldots,0,1)\;.\)__

Theorem 2 shows that under \(\Gamma\), the coalition undergoes a full unravelling: it is either empty or comprised solely of the worst agent in any Nash equilibrium. Thus, collaborative learning is not immune to adverse selection, and may suffer from unravelling as any market characterized by information asymmetry.

Sketch of proof.: The profile of actions \(((0,\dagger),\ldots,(0,\dagger))\) corresponding to \(\mathsf{B}=(0,\ldots,0)\) is a pure Nash equilibrium, since forming a lone coalition cannot bring more utility than picking the outside option. Conversely, consider a pure-strategy Nash equilibrium \(\mathbf{s}\in\mathscr{E}\) such that \(\mathsf{B}\neq(0,\ldots,0)\). Denote by \(\mathcal{C}=\{j\in[J]:\,B_{j}=1\text{ and }n_{j}^{*}(\widetilde{\mathbf{\theta}})>0\}\) the set of contributors under this equilibrium. It can be shown that (i) for any \((j,k)\in\mathcal{C}^{2}\), \(\theta_{j}-\widetilde{\theta}_{j}=\theta_{k}-\widetilde{\theta}_{k}\), and (ii) For any \(j\in\mathcal{C}\), \((1,\widetilde{\theta}_{j})\) with \(\widetilde{\theta}_{j}>\underline{\theta}\) is strictly dominated by \((1,\underline{\theta})\) so \(\widetilde{\theta}_{j}=\underline{\theta}\) at the equilibrium. As a consequence, \(\theta_{j}=\theta_{k}\) for any \((j,k)\in\mathcal{C}^{2}\), which implies by **H3** that \(|\mathcal{C}|=1\). From the definition of the contribution scheme (12), we can deduce that \(\sum_{j\in[J]}B_{j}=|\mathcal{B}|=1\), because \(|\mathcal{B}|>1\) would entail \(|\mathcal{C}|>1\). Finally, \(B_{J}=1\) because \(v_{J}((1,\underline{\theta}),\mathbf{s}_{-J})>v_{J}((0,\dagger),\mathbf{s}_{-J})\) and \(\mathbf{s}\) is a Nash equilibrium. This leads to \(\mathsf{B}=(0,\ldots,0,1)\). 

### Breaking unravelling

The previous results motivate the design of a more sophisticated aggregation scheme that addresses adverse selection. In this section, we discuss how to design such a procedure.

Is VCG available in our framework?Unravelling occurs under \(\Gamma\) because agents do not find it beneficial to declare their true type and eventually opt for their outside option. This could be avoided by modifying \(\Gamma\) to make it

1. _individually rational_, that is \(v_{j}((1,\theta_{j}),\mathbf{s}_{-j})\geqslant v_{j}((0,\dagger),\mathbf{s}_{-j})\) for any \(j\in[J]\), \(\mathbf{s}_{-j}\in\mathscr{S}^{J-1}\),
2. and _incentive compatible_, that is \(v_{j}((1,\theta_{j}),\mathbf{s}_{-j})\geqslant v_{j}((1,\widetilde{\theta}_{j} ),\mathbf{s}_{-j})\) for any \(\widetilde{\theta}_{j}\in\Theta\).

Under these conditions, the truthful, optimal profile of actions \(((1,\theta_{1}),\ldots,(1,\theta_{J}))\) would emerge as a Nash equilibrium. Since the aggregator seeks to minimize the utilitarian function \(W\), one option would be to rely on the VCG mechanism (Vickrey, 1961; Clarke, 1971; Groves, 1973), which is the direct-revelation mechanisms fulfilling these desiderata (Green and Laffont, 1977; Holmstrom, 1979). Formally, the VCG mechanism writes \(\Gamma^{\mathrm{VCG}}:\widetilde{\mathbf{\theta}}\mapsto(\mathbf{n}^{\star}( \widetilde{\mathbf{\theta}}),\mathbf{t}(\widetilde{\mathbf{\theta}}))\) where \(\mathbf{t}(\widetilde{\mathbf{\theta}})=(t_{1}(\mathbf{\theta}),\ldots,t_{J}(\mathbf{\theta }))\in\mathbb{R}^{J}\) is a set of transfers satisfying for any \(j\in[J]\):

\[t_{j}(\widetilde{\mathbf{\theta}})=\sum_{k\neq j}u_{k}((0,\mathbf{1}_{-j}), \mathbf{n}^{\star}(\widetilde{\mathbf{\theta}}))-\sum_{k\neq j}u_{k}(\mathbf{1}, \mathbf{n}^{\star}(\widetilde{\mathbf{\theta}}))\;.\]

It re-establishes truthfulness as a dominant strategy by aligning individual payoffs \(v_{j}^{\mathrm{VCG}}(\widetilde{\mathbf{\theta}})=u_{j}(\mathbf{1},\mathbf{n}^{ \star}(\widetilde{\mathbf{\theta}}))-t_{j}(\widetilde{\mathbf{\theta}})\) with total social welfare. Unfortunately, the VCG approach is unavailable in our framework, because of the following observation.

**Lemma 3**.: _There exists \(j\in[J]\) such that \(-t_{j}(\widetilde{\mathbf{\theta}})>0\)._

Lemma 3 shows that some agent would need to receive a strictly positive transfer. This is impossible without a monetary payment-utility can only be decreased by the aggregator, for instance through _accuracy shaping_(Karimireddy et al., 2022)-, which we exclude here.

A probabilistic verification-based mechanism.We now show how to design a mechanism that recovers the optimal collaboration as a Nash equilibrium in high probability without the need for transfers. Inspired by the probabilistic verification approach (Ferraioli and Ventre, 2018; Ball and Katwinkel, 2019), we assume that the aggregator can approximately estimate \(\theta_{j}\) with few samples from \(P_{j}\) for any \(j\in[J]\):

**H5**.: _There exists a decreasing function \(\eta_{\delta}:\;\mathbb{R}^{\star}_{+}\to\mathbb{R}^{\star}_{+}\), with \(\delta\in(0,1)\) defined in **H1**, such that for any \(j\in[J]\) and i.i.d samples \((X_{1}^{j},Y_{1}^{j}),\ldots,(X_{J}^{j},Y_{J}^{j})\) of size \(q>0\) from \(P_{j}\), there exists a \((X_{1}^{j},Y_{1}^{j}),\ldots,(X_{q}^{j},Y_{q}^{j})\)-measurable estimator \(\widehat{\theta}_{j}\) satisfying_

\[\mathbb{P}(|\widehat{\theta}_{j}-\theta_{j}|\leqslant\eta_{\delta}(q)) \geqslant 1-\delta\;.\]

In Section 4.2, we show how the aggregator can design such estimators. **H5** allows us to consider a new mechanism \(\widehat{\Gamma}:\;\mathsf{B}\mapsto\mathbf{m}(\mathsf{B})\) as follows:

1. any agent \(j\in[J]\) declares \(B_{j}\in\{0,1\}\). If \(B_{j}=1\), the principal asks for \(\underline{q}\leqslant\underline{n}-2(a/c)(\widetilde{\theta}-\underline{\theta})\) i.i.d samples from \(P_{j}\) and estimates types as \(\widehat{\mathbf{\theta}}=(\widehat{\theta}_{j})_{j\in\mathcal{B}}\) following **H5**.
2. Based on the estimated types \(\widehat{\mathbf{\theta}}=(\widehat{\theta}_{j})_{j\in\mathcal{B}}\), the aggregator asks for \([\,n^{\star}_{j}(\widehat{\mathbf{\theta}}+\mathbf{\eta}_{j})-\underline{q}\,]_{+}\) additional samples from \(P_{j}\), where \(\mathbf{n}^{\star}(\,\mathbf{\cdot}\,)\) is defined as in (12) and \[\mathbf{\eta}_{j}=\eta_{\delta/J}(\underline{q})\mathbf{1}-2\mathbf{\delta}_{j}\eta_{ \delta/J}(\underline{q}),\quad\text{with}\quad\mathbf{\delta}_{j}=(0,\ldots,0,1,0,\ldots,0)^{\mathrm{T}}\;.\] Thus, the number of draws required from agent \(j\) is \(\max[\underline{q}\,,\,n^{\star}_{j}(\widehat{\mathbf{\theta}}+\mathbf{\eta}_{j})]\).
3. The aggregator keeps \(m_{j}(\widehat{\mathbf{\theta}})=\mathbb{1}\{n^{\star}_{j}(\widehat{\mathbf{\theta}}+ \mathbf{\eta}_{j})>0\}\max[\underline{q}\,,\,n^{\star}_{j}(\widehat{\mathbf{\theta}}+ \mathbf{\eta}_{j})]\) samples from agent \(j\), and trains a collaborative model with these pooled samples.

\(\hat{\Gamma}\) induces a game \(([J],\{0,1\}^{J},(\hat{v}_{j})_{j\in[J]})\) where any agent \(j\in[J]\) has a payoff function

\[\hat{v}_{j}:(B_{j},\mathsf{B}_{-j})\mapsto B_{j}\Big{[}-a\Big{(}\mathcal{R}^{ \star}_{0}+\varepsilon(\mathsf{B},\mathbf{m}(\widehat{\mathbf{\theta}}))\Big{)}-c \max[\underline{q}\,,\,n^{\star}_{j}(\widehat{\mathbf{\theta}}+\mathbf{\eta}_{j})] \Big{]}+(1-B_{j})\underline{u}_{j}\;.\]

The rationale behind this mechanism is fairly intuitive: since \(\widehat{\mathbf{\theta}}\) is a correct estimate of \(\mathbf{\theta}\), \(n^{\star}_{j}(\widehat{\mathbf{\theta}}+\mathbf{\eta}_{j})\approx n^{\star}_{j}(\widehat {\mathbf{\theta}})\) correctly approximates the optimal contribution \(n^{\star}_{j}(\mathbf{\theta})\) for any contributor \(j\in\mathcal{B}\). Note that type estimates are purposely biased by \(\mathbf{\eta}_{j}\) when asking for samples. This is a safeguard against over-estimated types, which would lead to asking to many data points and could deter agents from participating in the coalition.

Critically, \(\mathbf{m}(\widehat{\mathbf{\theta}})\) does not depend on declared type, so agents are no longer able to strategically manipulate the mechanism. Moreover, \(\hat{\Gamma}\) does not require agents to know their own types, which would be an unrealistic assumption. Finally, observe that the number of data points asked to estimate types \(\underline{q}\) is low enough to never deter agents from participating in the coalition.

**Theorem 3**.: _Assume **H1**, **H2**, **H3**, **H4** and **H5**. \(\mathsf{B}^{\star}=(1,\ldots,1)^{\mathrm{T}}\) is a Nash equilibrium under \(\hat{\Gamma}\) with probability \(1-\delta\)._

Theorem 3 shows that the optimal coalition is a sustainable equilibrium under \(\hat{\Gamma}\), which effectively breaks unravelling: the set of (approximate) Nash equilibria is no more reduced to profiles of actions where the coalition is empty, or reduced to the worst agent.

Practical implementation.We now explain how to practically implement \(\hat{\Gamma}\) in a collaborative learning setting. This requires defining a collection of estimators \((\widehat{\theta}_{j})_{j}\) satisfying **H5**. To this end, we assume that few samples from the target distribution are available.

**H6**.: _There are \(q^{\prime}>0\) i.i.d samples \(\left\{(X_{1}^{0},Y_{1}^{0}),\ldots,(X_{q^{\prime}}^{0},Y_{q^{\prime}}^{0})\right\}\) from \(P_{0}\) available to the aggregator and agents._

Under **H6**, define \(\widehat{\mathcal{R}}_{0}(g)=q^{\prime-1}\sum_{i=1}^{q^{\prime}}\ell(g(X_{i}^ {0}),Y_{i}^{0})\) for \(g\in\mathscr{G}\). This allows us to devise suitable estimators \(\widehat{\theta}_{j}\) as follows.

**Proposition 2**.: _Assume **H1**, **H2** and **H6**. For any \(j\in[J]\) the estimator_

\[\widehat{\theta}_{0,j}^{\mathrm{\textsc{rmrm}}}=\sup_{g\in\mathscr{G}}| \widehat{\mathcal{R}}_{j}(g)-\widehat{\mathcal{R}}_{0}(g)|\;,\]

_satisfies **H5** with_

\[\eta_{\delta}(q)=\alpha_{\delta/4}\big{[}(q+1)^{-\gamma}+(q^{\prime}+1)^{- \gamma}\big{]}+2\beta\;. \tag{13}\]

Proposition 2 shows that the empirical version of the \(\mathscr{G}\)-divergence defined in **H2** correctly estimate types. Note that the tighter the PAC bound in **H1**, the better the approximation term in (13). The type estimator \(\widehat{\theta}_{0,j}^{\mathrm{\textsc{rm}}}\) defined in **H5** can easily be computed in the classification case, as shown with the following example.

**H7** (Classification setting).: \(\mathcal{Y}=\{-1,1\}\)_,_ \(\ell=\ell_{0,1}:(y,y^{\prime})\in\mathcal{Y}\times\mathcal{Y}\mapsto\mathbb{1}_{ \{yy^{\prime}<0\}}\)_, and_ \(\mathscr{G}\) _is a symmetric (_\(g\in\mathscr{G}\) _if and only if_ \(-g\in\mathscr{G}\)_) class of classifiers._

**Example 4**.: _Assume **H1**, **H2**, **H6** and **H7**._

1. _Denoting_ \(\widehat{\mathcal{R}}_{j^{-}}(g)=n_{j}^{-1}\sum_{i=1}^{n_{j}}\ell_{0,1}(g(X_{ i}^{j}),-Y_{i}^{j})\)_, we have_ \[\widehat{\theta}_{0,j}^{\mathrm{\textsc{rm}}}=1-\inf_{g\in\mathscr{G}}\left\{ \widehat{\mathcal{R}}_{0}(g)+\widehat{\mathcal{R}}_{j^{-}}(g)\right\}\;.\]
2. _In_ **H1**_, assume_ \(\alpha_{\delta}=\ln(1/\delta)^{1/2}\)_,_ \(\beta=2\mathrm{\textsc{RAD}}(\mathscr{G})\) _and_ \(\gamma=1\)___[_10_]__. With_ \(\widehat{\theta}_{0,j}^{\mathrm{\textsc{rm}}}\) _defined in Proposition_ 2_, we have_ \[\eta_{\delta/J}(q)=\ln(4J/\delta)^{1/2}[(1+q)^{-\gamma}+(1+q^{\prime})^{-\gamma }]+2\mathrm{\textsc{rad}}(\mathscr{G})\;.\]

Example 4 shows that in the classification case, it is sufficient to flip the labels of the data received from each contributor, merge these samples with those from \(P_{0}\), and perform an empirical risk minimization to compute \(\widehat{\theta}_{0,j}^{\mathrm{\textsc{rm}}}\). The approximation error grows no more than logarithmically with the number of agents, while decreasing at rate \(\gamma\) with the number of samples used in the estimation.

## 5 Conclusion

In this work, we show that information asymmetry has deleterious consequences when strategic agents try to learn a collaborative model. More precisely, under a naive aggregation procedure, the ignorance of others' data quality leads the coalition of learners to be either empty or reduced to the lowest-quality agent. We introduce a transfer-free mechanism based on estimation of types. This effectively counteracts unravelling by letting the grand coalition ranks among the approximate Nash equilibria with high probability.

Several possible extensions can be considered. First, it would be interesting to relax the assumption that all agents have the same ratio \(a/c\) in their utility, and see how heterogeneity affects the results.

Second, the mechanism presented in Section 4 aims for individual rationality. A more desirable, yet difficult to achieve, property would be core stability, to ensure that no group of agents would benefit from a coordinated deviation, i.e., forming an alternative coalition. Finally, it would be interesting to check whether there exist mechanisms where the optimal collaboration not only emerges as a Nash equilibrium, but as a dominant equilibrium under imperfect information.

## Acknowledgements

Funded by the European Union (ERC, Ocean, 101071601). Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union or the European Research Council Executive Agency. Neither the European Union nor the granting authority can be held responsible for them.

## References

* Akerlof (1970) George A. Akerlof. The market for lemons: Quality uncertainty and the market mechanism. _The Quarterly Journal of Economics_, 84(3):488-500, 1970. URL [https://ideas.repec.org/a/oup/qjecon/v84y197013p488-500..html](https://ideas.repec.org/a/oup/qjecon/v84y197013p488-500..html).
* Ananthakrishnan et al. (2023) Nivasini Ananthakrishnan, Stephen Bates, Michael Jordan, and Nika Haghtalab. Delegating data collection in decentralized machine learning, 2023.
* Ball and Kattwinkel (2019) Ian Ball and Deniz Kattwinkel. Probabilistic verification in mechanism design. September 2019.
* Ben-David et al. (2010) Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Vaughan. A theory of learning from different domains. _Machine Learning_, 79:151-175, 05 2010. doi: 10.1007/s10994-009-5152-4.
* Blum et al. (2017) Avrim Blum, Nika Haghtalab, Ariel Procaccia, and Mingda Qiao. Collaborative PAC learning. In I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, _Advances in Neural Information Processing Systems_. Curran Associates, 2017.
* Blum et al. (2021) Avrim Blum, Nika Haghtalab, Richard Lanas Phillips, and Han Shao. One for one, or all for all: Equilibria and optimality of collaboration in federated learning. In Marina Meila and Tong Zhang, editors, _Proceedings of the 38th International Conference on Machine Learning_, volume 139 of _Proceedings of Machine Learning Research_, pages 1005-1014. PMLR, 18-24 Jul 2021. URL [https://proceedings.mlr.press/v139/blum21a.html](https://proceedings.mlr.press/v139/blum21a.html).
* Bousquet et al. (2003) Olivier Bousquet, Stephane Boucheron, Gabor Lugosi, Ulrike Luxburg, and Gunnar Ratsch. Introduction to statistical learning theory. _Advanced Lectures on Machine Learning, 169-207 (2004)_, 01 2003. doi: 10.1007/978-3-540-28650-9_8.
* Caragiannis et al. (2012) Ioannis Caragiannis, Edith Elkind, Mario Szegedy, and Lan Yu. Mechanism design: From partial to probabilistic verification. _Proceedings of the ACM Conference on Electronic Commerce_, 06 2012. doi: 10.1145/2229012.2229035.
* Clarke (1971) Edward Clarke. Multipart pricing of public goods. _Public Choice_, 11(1):17-33, September 1971. doi: 10.1007/BF01726210. URL [https://ideas.repec.org/a/kap/pubcho/v11y1971i1p17-33.html](https://ideas.repec.org/a/kap/pubcho/v11y1971i1p17-33.html).
* Donahue and Kleinberg (2021a) Kate Donahue and Jon Kleinberg. Optimality and stability in federated learning: A game-theoretic approach, 06 2021a.
* Donahue and Kleinberg (2021b) Kate Donahue and Jon Kleinberg. Model-sharing games: Analyzing federated learning under voluntary participation. _Proceedings of the AAAI Conference on Artificial Intelligence_, 35:5303-5311, 05 2021b. doi: 10.1609/aaai.v35i6.16669.
* Dorner et al. (2023) Florian E. Dorner, Nikola Konstantinov, Georgi Pashaliev, and Martin T. Vechev. Incentivizing honesty among competitors in collaborative learning and optimization. _ArXiv_, abs/2305.16272, 2023. URL [https://api.semanticscholar.org/CorpusID:258887502](https://api.semanticscholar.org/CorpusID:258887502).
* Donahue et al. (2018)* Einav and Finkelstein (2011) Liran Einav and Amy Finkelstein. Selection in insurance markets: Theory and empirics in pictures. _Journal of Economic Perspectives_, 25(1):115-38, March 2011. doi: 10.1257/jep.25.1.115. URL [https://www.aeaweb.org/articles?id=10.1257/jep.25.1.115](https://www.aeaweb.org/articles?id=10.1257/jep.25.1.115).
* Ferraioli and Ventre (2018) Diodato Ferraioli and Carmine Ventre. Probabilistic verification for obviously strategyproof mechanisms, 2018.
* Fu et al. (2023) Lei Fu, Huanle Zhang, Ge Gao, Mi Zhang, and Xin Liu. Client selection in federated learning: Principles, challenges, and opportunities, 2023.
* Gao et al. (2022) Dashan Gao, Xin Yao, and Qiang Yang. A survey on heterogeneous federated learning. _arXiv preprint arXiv:2210.04505_, 2022.
* Green and Laffont (1977) Jerry Green and Jean-Jacques Laffont. Characterization of satisfactory mechanisms for the revelation of preferences for public goods. _Econometrica_, 45(2):427-38, 1977. URL [https://EconPapers.repec.org/RePEc:ecm:emetrp:v:45:y:1977:i:2:p:427-38](https://EconPapers.repec.org/RePEc:ecm:emetrp:v:45:y:1977:i:2:p:427-38).
* Groves (1973) Theodore Groves. Incentives in teams. _Econometrica_, 41:617-631, 1973. URL [https://api.semanticscholar.org/CorpusID:264740987](https://api.semanticscholar.org/CorpusID:264740987).
* Hendren (2013) Nathaniel Hendren. Private Information and Insurance Rejections. _Econometrica_, 81(5):1713-1762, September 2013. doi: ECTA10931. URL [https://ideas.repec.org/a/ecm/emetrp/v81y2013i5p1713-1762.html](https://ideas.repec.org/a/ecm/emetrp/v81y2013i5p1713-1762.html).
* Holmstrom (1979) Bengt Holmstrom. Groves' scheme on restricted domains. _Econometrica_, 47(5):1137-44, 1979. URL [https://EconPapers.repec.org/RePEc:ecm:emetrp:v:47:y:1979:i:5:p:1137-44](https://EconPapers.repec.org/RePEc:ecm:emetrp:v:47:y:1979:i:5:p:1137-44).
* Huang et al. (2023) Baihe Huang, Sai Praneeth Karimireddy, and Michael I. Jordan. Evaluating and Incentivizing Diverse Data Contributions in Collaborative Learning. Papers 2306.05592, arXiv.org, June 2023. URL [https://ideas.repec.org/p/arx/papers/2306.05592.html](https://ideas.repec.org/p/arx/papers/2306.05592.html).
* Huang et al. (2022) Chao Huang, Shuqi Ke, Charles Kamhoua, Prasant Mohapatra, and Xin Liu. Incentivizing data contribution in cross-silo federated learning, 2022.
* Kairouz et al. (2021) Peter Kairouz, H. Brendan McMahan, Brendan Avent, Aurelien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, Rafael G. L. D'Oliveira, Hubert Eichner, Salim El Rouayheb, David Evans, Josh Gardner, Zachary Garrett, Adria Gascon, Badhi Ghazi, Phillip B. Gibbons, Marco Gruteser, Zaid Harchaoui, Chaoyang He, Lie He, Zhouyuan Huo, Ben Hutchinson, Justin Hsu, Martin Jaggi, Tara Javidi, Gauri Joshi, Mikhail Khodak, Jakub Konecnyu, Aleksandra Korolova, Farinaz Koushanfar, Sammi Koyejo, Tancrede Lepoint, Yang Liu, Prateek Mittal, Mehryar Mohri, Richard Nock, Ayfer Ozgur, Rasmus Pagh, Mariana Raykova, Hang Qi, Daniel Ramage, Ramesh Raskar, Dawn Song, Weikang Song, Sebastian U. Stich, Ziteng Sun, Ananda Theertha Suresh, Florian Tramer, Praneeth Vepakomma, Jianyu Wang, Li Xiong, Zheng Xu, Qiang Yang, Felix X. Yu, Han Yu, and Sen Zhao. Advances and open problems in federated learning, 2021.
* Karimireddy et al. (2022) Sai Praneeth Karimireddy, Wenshuo Guo, and Michael I. Jordan. Mechanisms that incentivize data sharing in federated learning, 2022.
* Kifer et al. (2004) Daniel Kifer, Shai Ben-David, and Johannes Gehrke. Detecting change in data streams. pages 180-191, 04 2004.
* Konstantinov and Lampert (2019) Nikola Konstantinov and Christoph Lampert. Robust learning from untrusted sources, 2019.
* Laffont and Martimort (2001) Jean-Jacques Laffont and David Martimort. _The Theory of Incentives: The Principal-Agent Model_. Princeton University Press, Princeton, NJ, USA, 2001.
* Liu et al. (2023) Shutian Liu, Tao Li, and Quanyan Zhu. Game-theoretic distributed empirical risk minimization with strategic network design. _IEEE Transactions on Signal and Information Processing over Networks_, 9:542-556, 2023. doi: 10.1109/TSIPN.2023.3306106.
* Mas-Colell et al. (1995) Andreu Mas-Colell, Michael D. Whinston, and Jerry R. Green. _Microeconomic Theory_. Number 9780195102680 in OUP Catalogue. Oxford University Press, 1995. ISBN ARRAY(0x516030e0). URL [https://ideas.repec.org/b/orp/obooks/9780195102680.html](https://ideas.repec.org/b/orp/obooks/9780195102680.html).
* Ma et al. (2018)Michael Rothschild and Joseph Stiglitz. Equilibrium in competitive insurance markets: An essay on the economics of imperfect information. _The Quarterly Journal of Economics_, 90(4):629-649, 1976. URL [https://EconPapers.repec.org/RePEc:oup:qjecon:v:90:y:1976:i:4:p:629-649](https://EconPapers.repec.org/RePEc:oup:qjecon:v:90:y:1976:i:4:p:629-649).
* Saig et al. (2023) Eden Saig, Inbal Talgam-Cohen, and Nir Rosenfeld. Delegated classification, 2023.
* Shalaeva et al. (2019) Vera Shalaeva, Alireza Fakhrizadeh Esfahani, Pascal Germain, and Mihaly Petreczky. Improved pac-bayesian bounds for linear regression. In _AAAI Conference on Artificial Intelligence_, 2019. URL [https://api.semanticscholar.org/CorpusID:208857400](https://api.semanticscholar.org/CorpusID:208857400).
* Tsoy and Konstantinov (2024) Nikita Tsoy and Nikola Konstantinov. Strategic data sharing between competitors. _Advances in Neural Information Processing Systems_, 36, 2024.
* Tu et al. (2022) Xuezhen Tu, Kun Zhu, Nguyen Cong Luong, Dusit Niyato, Yang Zhang, and Juan Li. Incentive mechanisms for federated learning: From economic and game theoretic perspective. _IEEE Transactions on Cognitive Communications and Networking_, 8(3):1566-1593, 2022. doi: 10.1109/TCCN.2022.3177522.
* Vickrey (1961) William Vickrey. Counterspeculation, auctions, and competitive sealed tenders. _Journal of Finance_, 16(1):8-37, 1961. URL [https://EconPapers.repec.org/RePEc:bla:jfinan:v:16:y:1961:i:1:p:8-37](https://EconPapers.repec.org/RePEc:bla:jfinan:v:16:y:1961:i:1:p:8-37).
* Wei et al. (2024) Zhepei Wei, Chuanhao Li, Tianze Ren, Haifeng Xu, and Hongning Wang. Incentivized truthful communication for federated bandits, 2024.
* Werner et al. (2024) Mariel Werner, Sai Praneeth Karimireddy, and Michael I. Jordan. Defection-free collaboration between competitors in a learning system, 2024. URL [https://arxiv.org/abs/2406.15898](https://arxiv.org/abs/2406.15898).
* 2023 IEEE Global Communications Conference_, pages 734-739, 2023. doi: 10.1109/GLOBECOM54140.2023.10437743.

## Appendix A Relaxation of the optimal aggregation problem.

Let \(\mathsf{B}\in\{0,1\}^{J}\) and the associated coalition \(\mathcal{B}=\{j\in[J]:\ B_{j}=1\}\) be fixed. We present in this appendix a natural relaxation of problem Equation (10) which motivates the choice \(\sum_{j\in\mathsf{B}}n_{j}^{\star}(\mathbf{\theta})=\bar{N}=(\underline{n}+1)| \mathcal{B}|^{\frac{1}{1+j}}-1\) in the simplified contribution scheme \((\mathsf{B}^{\star},\mathbf{n}^{\star})\). The optimal aggregation problem with \(\mathsf{B}\) fixed is

\[\text{maximize}\quad\mathbf{n}\in\mathbb{R}^{J}\,\mapsto\,\sum_{j\in[J]}u_{j}( \mathsf{B},\mathbf{n})\quad\text{subject to}\quad\left\{\begin{aligned} & \max_{j\in\mathsf{B}}n_{j}-\overline{n}(\mathsf{B},\mathbf{n})\leqslant 0 \\ &\max_{j\in[J]}-n_{j}\leqslant 0\end{aligned}\right.,\]

Since agents outside of the coalition maximize their utility, the problem can equivalently be stated as

\[(\mathcal{T}_{\mathsf{B}}):\quad\text{maximize}\quad\mathbf{n}\in\mathbb{R}^{ |\mathcal{B}|}\,\mapsto\,\sum_{j\in\mathcal{B}}u_{j}(\mathsf{B},\mathbf{n})+ \zeta_{\mathsf{B}}\quad\text{subject to}\quad\mathbf{n}\in\Xi_{\mathsf{B}}\;,\]

where

\[\Xi_{\mathsf{B}}=\left\{\mathbf{n}\in\mathbb{R}_{+}^{\mathcal{B}}:\quad\begin{aligned} &\max_{j\in\mathsf{B}}\{n_{j}-\overline{n}_{j}(\mathsf{B},\mathbf{n})\} \leqslant 0\\ &\max_{j\in\mathsf{B}}-n_{j}\leqslant 0\end{aligned}\right\}\quad\text{and}\quad\zeta_{\mathsf{B}}=\sum_{j\notin \mathsf{B}}\underline{u}_{j}\;. \tag{14}\]

We start by rewriting \((\mathcal{T}_{\mathsf{B}})\) in a more convenient way. Instead of working with \(\mathbf{n}\in\mathbb{R}_{+}^{|\mathcal{B}|}\) directly, we make appear (i) the total number of samples and (ii) the sharing out of samples between agents. Formally, for any \(\mathbf{n}\in\mathbb{R}_{+}^{|\mathcal{B}|}\) consider \(N=\mathbf{n}^{\mathsf{T}}\mathsf{B}\) and \(\mathbf{\lambda}=N^{-1}\mathbf{n}\in\Delta_{|\mathcal{B}|}\), where \(\Delta_{|\mathcal{B}|}\) is the simplex of dimension \(|\mathcal{B}|\). Observe that the average type in the coalition reads \(\vartheta(\mathsf{B},\mathbf{n})=\mathbf{\lambda}^{\mathsf{T}}\mathbf{\theta}\). Moreover,the welfare evaluated in \((\mathsf{B},\mathbf{n})\) rewrites

\[\sum_{j\in[J]}u_{j}(\mathsf{B},\mathbf{n}) =\sum_{j\in[J]}B_{j}[-a(\mathcal{R}_{0}^{\star}+\varepsilon( \mathsf{B},\boldsymbol{\lambda}N))-cn_{j}]+\sum_{j\in[J]}(1-B_{j})\underline{u}_ {j}\] \[=-a|\mathcal{B}|(\mathcal{R}_{0}^{\star}+\varepsilon(\mathsf{B}, \boldsymbol{\lambda}N))-cN+\zeta_{\mathsf{B}}\,\] \[=-a|\mathcal{B}|\big{[}\mathcal{R}_{0}^{\star}+2\big{(}\alpha_{ \delta}(1+N)^{-\gamma}+\beta+\boldsymbol{\lambda}^{\mathsf{T}}\boldsymbol{ \theta}\big{)}\big{]}-cN+\zeta_{\mathsf{B}}\] \[=\widetilde{W}_{\mathsf{B}}(\boldsymbol{\lambda},N)\.\]

We denote by \(\widetilde{\Xi}_{\mathsf{B}}=\big{\{}(\boldsymbol{\lambda},N)\in\Delta_{| \mathcal{B}|}\times\mathbb{R}_{+}:\ \boldsymbol{\lambda}N\in\Xi_{\mathsf{B}} \big{\}}\) and \(\widetilde{\mathcal{T}}_{\mathsf{B}}\) the problem:

\[(\widetilde{\mathcal{T}}_{\mathsf{B}}):\quad\text{minimize}\quad( \boldsymbol{\lambda},N)\in\Delta_{|\mathcal{B}|}\times\mathbb{R}_{+}\mapsto- \widetilde{W}_{\mathsf{B}}(\boldsymbol{\lambda},N)\quad\text{subject to} \quad(\boldsymbol{\lambda},N)\in\widetilde{\Xi}_{\mathsf{B}}. \tag{15}\]

By definition, if \((\boldsymbol{\lambda},N)\) is a solution to \(\widetilde{\mathcal{T}}_{\mathsf{B}}\), then \(\mathbf{n}=\boldsymbol{\lambda}N\) is a solution to \(\mathcal{T}_{\mathsf{B}}\). We can further decompose \(\widetilde{\mathcal{T}}_{\mathsf{B}}\) by observing that

\[-\widetilde{W}_{\mathsf{B}}(\boldsymbol{\lambda},N)=f(N)+g(\boldsymbol{\lambda })\,\]

with

\[f(N)=a|\mathcal{B}|(\mathcal{R}_{0}^{\star}+2\alpha_{\delta}(1+N)^{-\gamma}+2 \beta)+cN+\zeta_{\mathsf{B}}\quad\text{and}\quad g(\boldsymbol{\lambda})=2a| \mathcal{B}|\boldsymbol{\lambda}^{\mathsf{T}}\boldsymbol{\theta}\.\]

Finally, we denote a slice of \(\widetilde{\Xi}_{\mathsf{B}}\) along \(N\geqslant 0\) as \(\widetilde{\Xi}_{\mathsf{B}}(N)=\{\boldsymbol{\lambda}\in\Delta_{|\mathcal{B}| }:\ (\boldsymbol{\lambda},N)\in\widetilde{\Xi}_{\mathsf{B}}\}\) and \(\mathcal{N}=\{N\geqslant 0:\ \widetilde{\Xi}_{\mathsf{B}}(N)\neq\emptyset\}\). \(\widetilde{\mathcal{T}}_{\mathsf{B}}\) comes down to

\[\min_{(\boldsymbol{\lambda},N)\in\widetilde{\Xi}_{\mathsf{B}}}\{f(N)+g( \boldsymbol{\lambda})\}=\min_{N\in\mathcal{N}}\{f(N)+\min_{\boldsymbol{\lambda }\in\widetilde{\Xi}_{\mathsf{B}}(N)}g(\boldsymbol{\lambda})\}. \tag{16}\]

A strategy to solve Equation (16) is to (i) address the innermost problem \(\min_{\boldsymbol{\lambda}\in\widetilde{\Xi}_{\mathsf{B}}(N)}g(\boldsymbol{ \lambda})\) with \(N\in\mathcal{N}\) fixed, and denoting \(\boldsymbol{\lambda}^{(N)}\in\widetilde{\Xi}_{\mathsf{B}}(N)\) its solution, (ii) solve the outermost problem:

\[\min_{N\in\mathcal{N}}\{f(N)+g(\boldsymbol{\lambda}^{(N)})\}. \tag{17}\]

Point (i) is done in the proof of Theorem 1. However, the resulting problem in (ii) is hard to tackle because \(\boldsymbol{\lambda}^{(N)}\) has no simple form. Therefore, we leave aside the term \(g(\boldsymbol{\lambda}^{(N)})\) (which can be easily controlled, as shown in Lemma 2) to determine \(N\) and only consider the problem

\[\min_{N\geqslant 0}\ f(N). \tag{18}\]

Since \(f\) is differentiable and strictly convex, its minimizer is uniquely defined by \(f^{\prime}(\bar{N})=0\), which gives

\[\bar{N}=(\underline{n}+1)|\mathcal{B}|^{\frac{1}{1+\gamma}}-1\, \tag{19}\]

where \(\underline{n}\) is defined in Proposition 1. As the solution of the relaxed problem (18), we take \(\sum_{j\in[J]}n_{j}^{\star}(\boldsymbol{\theta})=\bar{N}\) is the simplified contribution scheme \((\mathsf{B}^{\star},\mathbf{n}^{\star})\). In many reasonable settings, this approximation is very satisfactory as shown by Lemma 2.

## Appendix B Proofs

**Lemma 1**.: _Assume **H**1 and **H**2._

1. _Any agent_ \(j\in[J]\) _picking the outside_ _Option 1_ _obtains a model_ \(\widehat{g}_{j}\in\mathscr{G}\) _achieving_ \[\mathcal{R}_{0}(\widehat{g}_{j})\leqslant\mathcal{R}_{0}^{\star}+\varepsilon( \theta_{j},n_{j})\quad\text{with probability $1-\delta$}\.\]
2. _Any coalition_ \(\mathsf{B}\in\{0,1\}^{J}\) _drawing_ \(\mathbf{n}=(n_{1},\ldots,n_{J})\in\mathbb{R}_{+}^{J}\)_, samples obtains a model_ \(\widehat{g}_{\mathsf{B}}\in\mathscr{G}\) _achieving_ \[\mathcal{R}_{0}(\widehat{g}_{\mathsf{B}})\leqslant\mathcal{R}_{0}^{\star}+ \varepsilon(\vartheta,N)\quad\text{with probability $1-\delta$}\,\] _where_ \(N\) _is the total of samples and_ \(\vartheta\) _is the weighted average type within the coalition:_ \[N(B,\mathbf{n})=\sum_{j\in[J]}B_{j}n_{j}\,\qquad\vartheta(\mathsf{B},\mathbf{n})=N^{-1} \sum_{j\in[J]}B_{j}n_{j}\theta_{j}\.\] (4)Proof.: (i) Let \(\{(X_{1}^{j},Y_{1}^{i}),\ldots,(X_{n_{j}}^{j},Y_{n_{j}}^{j})\}\) be \(n_{j}>0\) i.i.d samples from \(P_{j}\in\mathcal{P}\) and \(\widehat{g}_{j}=\inf_{g\in\mathscr{G}}\widehat{\mathcal{R}}_{j}(g)\). First, observe that

\[\mathcal{R}_{0}(\widehat{g}_{j})\leqslant\mathcal{R}_{j}(\widehat{g}_{j})+ \sup_{g\in\mathscr{G}}\lvert\mathcal{R}_{0}(g)-\mathcal{R}_{j}(g)\rvert= \mathcal{R}_{j}(\widehat{g}_{j})+\theta_{j}. \tag{20}\]

Let \(\upsilon>0\) and \(g_{j}^{\upsilon}\in\mathscr{G}\) such that \(\mathcal{R}_{j}\big{(}g_{j}^{\upsilon}\big{)}\leqslant\inf_{g\in\mathscr{G}} \mathcal{R}_{j}(g)+\upsilon\). Then with probability at least \(1-\delta\),

\[\mathcal{R}_{j}(\widehat{g}_{j}) =\mathcal{R}_{j}(\widehat{g}_{j})-\mathcal{R}_{j}\big{(}g_{j}^{ \upsilon}\big{)}+\mathcal{R}_{j}\big{(}g_{j}^{\upsilon}\big{)}\] \[\leqslant\Big{(}\widehat{\mathcal{R}}_{j}(g_{j}^{\upsilon})- \widehat{\mathcal{R}}_{j}(\widehat{g}_{j})\Big{)}+\mathcal{R}_{j}(\widehat{g }_{j})-\mathcal{R}_{j}\big{(}g_{j}^{\upsilon}\big{)}+\mathcal{R}_{j}\big{(}g_ {j}^{\upsilon}\big{)}\] \[\leqslant 2\sup_{g\in\mathscr{G}}\lvert\mathcal{R}_{j}(g)- \widehat{\mathcal{R}}_{j}(g)\rvert+\inf_{g\in\mathscr{G}}\mathcal{R}_{j}(g)+\upsilon\] \[\leqslant 2\bigg{(}\frac{\alpha_{\delta}}{(n+1)^{\gamma}}+\beta \bigg{)}+\inf_{g\in\mathscr{G}}\mathcal{R}_{j}(g)\, \tag{21}\]

where the last inequality holds taking the limit \(\upsilon\to 0\) and using **H** 1. Finally, observing that \(\inf_{g\in\mathscr{G}}\mathcal{R}_{j}(g)\ -\ \mathcal{R}_{0}^{\ast}=\inf_{g\in \mathscr{G}}\mathcal{R}_{j}(g)-\inf_{g\in\mathscr{G}}\mathcal{R}_{0}(g)\leqslant \sup_{g\in\mathscr{G}}\lvert\mathcal{R}_{j}(g)-\mathcal{R}_{0}(g)\rvert=\theta _{j}\), and combining (20) as well as (21) yields

\[\mathcal{R}_{0}(\widehat{g}_{j})\leqslant\mathcal{R}_{0}^{\ast}+2\theta_{j}+2 \bigg{(}\frac{\alpha_{\delta}}{(n+1)^{\gamma}}+\beta\bigg{)}=\mathcal{R}_{0}^{ \ast}+\varepsilon(\theta_{j},n)\, \tag{22}\]

with probability at least \(1-\delta\).

(ii) Let \(\mathsf{B}\in\{0,1\}^{J}\) and \(\mathbf{n}=(n_{1},\ldots,n_{j})\in\mathbb{R}_{+}^{J}\). For any \(j\in\mathsf{B}\), let \(\{(X_{1}^{j},Y_{1}^{i}),\ldots,(X_{n_{j}}^{j},Y_{n_{j}}^{j})\}\) be a collection of \(n_{j}>0\) i.i.d samples from \(P_{j}\in\mathcal{P}\). Denote by \(N=\sum_{j\in[J]}B_{j}n_{j}\) and consider \(\boldsymbol{\lambda}=(\lambda_{1},\ldots,\lambda_{J})\) such that \(\lambda_{j}=B_{j}n_{j}/N\). Note that \(\boldsymbol{\lambda}\) belongs to the \(J\)-dimensional simplex. For any \(g\in\mathscr{G}\), the empirical risk over contributions is

\[\widehat{\mathcal{R}}_{\mathsf{B}}(g)=\frac{1}{N}\sum_{j\in[J]}B_{j}\sum_{i=1} ^{n_{j}}\ell(g(X_{i}^{j}),Y_{i}^{j})=\sum_{j\in[J]}B_{j}\lambda_{j}\widehat{ \mathcal{R}}_{j}(g)\, \tag{23}\]

and the population risk is

\[\mathcal{R}_{\mathsf{B}}(g)=\mathbb{E}\Big{[}\widehat{\mathcal{R}}_{\mathsf{B} }(g)\Big{]}=\sum_{j\in[J]}B_{j}\lambda_{j}\mathbb{E}\Big{[}\widehat{\mathcal{R }}_{j}(g)\Big{]}=\sum_{j\in[J]}B_{j}\lambda_{j}\mathcal{R}_{j}(g). \tag{24}\]

One the one hand, the collaborative model \(\widehat{g}_{\mathsf{B}}\in\mathscr{G}\) satisfies:

\[\mathcal{R}_{0}(\widehat{g}_{\mathsf{B}})\leqslant\mathcal{R}_{ \mathsf{B}}(\widehat{g}_{\mathsf{B}})+\sup_{g\in\mathscr{G}}\lvert\mathcal{R}_{0 }(g)-\mathcal{R}_{\mathsf{B}}(g)\rvert \leqslant\mathcal{R}_{\mathsf{B}}(\widehat{g}_{\mathsf{B}})+\sup_{g \in\mathscr{G}}\Biggl{\{}\sum_{j\in[J]}\lambda_{j}\lvert\mathcal{R}_{j}(g)- \mathcal{R}_{0}(g)\rvert\Biggr{\}}\] \[\leqslant\mathcal{R}_{\mathsf{B}}(\widehat{g}_{\mathsf{B}})+\sum_ {j\in[J]}\lambda_{j}\sup_{g\in\mathscr{G}}\lvert\mathcal{R}_{j}(g)-\mathcal{R }_{0}(g)\rvert\] \[=\mathcal{R}_{\mathsf{B}}(\widehat{g}_{\mathsf{B}})+\vartheta( \mathsf{B},\mathbf{n})\, \tag{25}\]

with \(\vartheta(\mathsf{B},\mathbf{n})=N^{-1}\sum_{j\in[J]}B_{j}n_{j}\theta_{j}=\sum_{ j\in[J]}B_{j}\lambda_{j}\theta_{j}\). Now, let \(\upsilon>0\) and \(g^{\upsilon}\in\mathscr{G}\) such that \(\mathcal{R}_{\mathsf{B}}(g^{\upsilon})\leqslant\inf_{g\in\mathscr{G}}\mathcal{R }_{\mathsf{B}}(g)+\upsilon\). We also have

\[\mathcal{R}_{\mathsf{B}}(\widehat{g}_{\mathsf{B}}) =\mathcal{R}_{\mathsf{B}}(\widehat{g}_{\mathsf{B}})-\mathcal{R}_{ \mathsf{B}}(g^{\upsilon})+\mathcal{R}_{\mathsf{B}}(g^{\upsilon})\] \[\leqslant\Big{(}\widehat{\mathcal{R}}_{\mathsf{B}}(g^{\upsilon })-\widehat{\mathcal{R}}_{\mathsf{B}}(\widehat{g}_{\mathsf{B}})\Big{)}+\mathcal{R}_ {\mathsf{B}}(\widehat{g}_{\mathsf{B}})-\mathcal{R}_{\mathsf{B}}(g^{\upsilon})+ \mathcal{R}_{\mathsf{B}}(g^{\upsilon})\] \[\leqslant 2\sup_{g\in\mathscr{G}}\Bigl{\lvert}\mathcal{R}_{ \mathsf{B}}(g)-\widehat{\mathcal{R}}_{\mathsf{B}}(g)\Bigr{\rvert}+\inf_{g\in \mathscr{G}}\mathcal{R}_{\mathsf{B}}(g)+\upsilon\] \[\leqslant 2\bigg{(}\frac{\alpha_{\delta}}{(N+1)^{\gamma}}+\beta \bigg{)}+\inf_{g\in\mathscr{G}}\mathcal{R}_{\mathsf{B}}(g)\quad\text{with probability at least $1-\delta$}\, \tag{26}\]where the first inequality comes from \(\widehat{\mathcal{R}}_{\mathsf{B}}(\widehat{g}_{\mathsf{B}})=\inf_{g\in\mathscr{G}} \widehat{\mathcal{R}}_{\mathsf{B}}(g)\leqslant\widehat{\mathcal{R}}_{\mathsf{B} }(g^{\upsilon})\), and the last is obtained by taking \(\upsilon\to 0\) and applying assumption **H**1. Now, observe that \(\inf_{g\in\mathscr{G}}\mathcal{R}_{\mathsf{B}}(g)-\mathcal{R}_{0}^{\star}=\inf_ {g\in\mathscr{G}}\mathcal{R}_{\mathsf{B}}(g)-\inf_{g\in\mathscr{G}}\mathcal{R}_ {0}(g)\leqslant\sup_{g\in\mathscr{G}}\lvert\mathcal{R}_{\mathsf{B}}(g)-\mathcal{ R}_{0}(g)\rvert\leqslant\sum_{j}B_{j}\lambda_{j}\sup_{g\in\mathscr{G}}\lvert \mathcal{R}_{j}(g)-\mathcal{R}_{0}(g)\rvert=\vartheta(\mathsf{B},\mathbf{n})\). Combining this observation with Equation (25) and Equation (26) gives with probability \(1-\delta\)

\[\mathcal{R}_{0}(\widehat{g}_{\mathsf{B}})\leqslant\mathcal{R}_{0}^{\star}+2 \bigg{(}\frac{\alpha_{\delta}}{(N+1)^{\gamma}}+\beta\bigg{)}+2\vartheta( \mathsf{B},\mathbf{n})=\mathcal{R}_{0}^{\star}+\varepsilon(\vartheta(\mathsf{B},\mathbf{n}),N)\;. \tag{27}\]

**Proposition 1**.: _Assume **H**1 and **H**2. For any \(j\in[J]\), \(\mathsf{B}_{-j}\in\{0,1\}^{J-1}\) and \(\mathbf{n}_{-j}\in\mathbb{R}_{+}^{J-1}\), the optimal number of samples to draw under **Option**1) is \(\operatorname*{argmax}_{n\geq 0}u_{j}((0,\mathsf{B}_{-j}),(n,\mathbf{n}_{-j}) \,;\,\theta_{j})=\underline{n}\) where_

\[\underline{n}=(2ac^{-1}\gamma\alpha_{\delta})^{1/(\gamma+1)}-1\;. \tag{6}\]

Proof.: For any \(j\in[J]\) and \(n\geq 0\), Lemma 1 gives that

\[-u_{j}((0,\mathsf{B}_{-j}),(n,\mathbf{n}_{-j}),\theta_{j})=a[\mathcal{R}_{0}^{ \star}+2(\alpha_{\delta}(n+1)^{-\gamma}+\beta+\theta_{j})]+cn=f(n)\;.\]

Since \(f\) is strictly convex and differentiable, it admits a unique maximizer \(\underline{n}\geqslant 0\) determined by \(f^{\prime}(\underline{n})=0\). Simple algebra leads to \(\underline{n}=(2a\gamma c^{-1}\alpha_{\delta})^{1/\gamma+1}-1\). 

**Theorem 1**.: _Assume **H**1, **H**2, **H**3. Problem (8) admits a unique solution \((\mathsf{B}^{\mathrm{opt}},\mathbf{n}^{\mathrm{opt}}(\boldsymbol{\theta}))\in \{0,1\}^{J}\times\mathbb{R}_{+}^{J}\). Moreover,_

1. \(\mathsf{B}^{\mathrm{opt}}=\mathbf{1}=(1,\ldots,1)\)_,_
2. _Denoting_ \(\mathbf{n}^{\mathrm{opt}}(\boldsymbol{\theta})=(n_{1}^{\mathrm{opt}}( \boldsymbol{\theta}),\ldots,n_{J}^{\mathrm{opt}}(\boldsymbol{\theta}))\)_, there exists_ \(L^{\mathrm{opt}}\in[J]\) _such that for any_ \(j\in[J]\)_,_ \[n_{j}^{\mathrm{opt}}(\boldsymbol{\theta})\begin{cases}=\overline{n}_{j}( \mathbf{1},\mathbf{n}^{\mathrm{opt}}(\boldsymbol{\theta}))&\text{if $j<L^{ \mathrm{opt}}$},\\ \in[\,0\,,\,\overline{n}_{j}(\mathbf{1},\mathbf{n}^{\mathrm{opt}}( \boldsymbol{\theta}))\,]&\text{if $j=L^{\mathrm{opt}}$},\\ =0&\text{otherwise}.\end{cases}\] (11)

Proof.: Recall that the optimal aggregation problem reads

maximize \[W(\mathsf{B},\mathbf{n})\in\{0,1\}^{J}\times\mathbb{R}_{+}^{J} \mapsto\sum_{j\in[J]}u_{j}(\mathsf{B},\mathbf{n})\] (28) subject to \[\min_{j\in[J]}u_{j}(\mathsf{B},\mathbf{n})-\underline{u}_{j} \geqslant 0\;.\]

Define for any \(j\in[J],\mathsf{B}_{-j}\in\{0,1\}^{J-1}\), and \(\mathbf{n}_{-j}\in\mathbb{R}_{+}^{J-1}\), the maximum number of samples agent \(j\in[J]\) having \(B_{j}=1\) may be asked given their participation constraint:

\[\overline{n}_{j}(\mathsf{B},\mathbf{n})=\max\{n\geqslant 0:\,u_{j}((1,\mathsf{B}_{ -j}),(n,\mathbf{n}_{-j}))\geqslant\underline{u}_{j}\}\;.\]

Given Equation (5) and Proposition 1, we obtain

\[\overline{n}_{j}(\mathsf{B},\mathbf{n})=\underline{n}-ac^{-1}(\varepsilon( \mathsf{B},\mathbf{n})-\varepsilon(\theta_{j},\underline{n}))\;, \tag{29}\]

where \(N=\sum_{j\in[J]}B_{j}n_{j}=\mathbf{n}^{\mathsf{T}}\mathsf{B}\). Problem (28) rewrites in canonical form

\[\text{minimize}\quad-W(\mathsf{B},\mathbf{n})\quad\text{subject to}\quad \left\{\begin{aligned} &\max_{j\in\mathsf{B}}\text{$n_{j}-\overline{n}_{j}(\mathsf{B}, \mathbf{n})\leqslant 0$}\\ &\max_{j\in[J]}-\!n_{j}\leqslant 0\;,\end{aligned}\right. \tag{30}\]

where \(\mathcal{B}=\{j\in[J]:\,B_{j}=1\}\). We first show that it admits a unique minimum.

Fix a \(\mathsf{B}\in\{0,1\}^{J}\) and consider problem (30) with respect to \(\mathbf{n}\in\mathbb{R}_{+}^{J}\) only. We call this subproblem \(\mathcal{T}_{\mathsf{B}}\). First, we show that it is enough to focus on \((n_{j})_{j\in\mathcal{B}}\) rather than \((n_{j})_{j\in[J]}\) in \(\mathcal{T}_{\mathsf{B}}\). With \(\mathbf{n}_{\mathcal{B}}=(\mathrm{n}_{j})_{j\in\mathcal{B}}\) and \(\mathbf{n}_{\mathsf{B}^{\varepsilon}}=(\mathrm{n}_{j})_{j\notin\mathsf{B}}\), note that \(W(\mathsf{B},\mathbf{n})\) is decomposable in \(\mathbf{n}_{\mathcal{B}}\) and \(\mathbf{n}_{\mathsf{B}^{\varepsilon}}\):

\[W(\mathsf{B},\mathbf{n})=W(\mathsf{B},\mathbf{n}_{\mathcal{B}})+W(\mathsf{B}, \mathbf{n}_{\mathsf{B}^{\varepsilon}})\;,\]where, by a slight abuse of notation \(W(\mathsf{B},\mathbf{n}_{\mathcal{B}})=\sum_{j\in\mathsf{B}}u_{j}(\mathsf{B},\mathbf{ n})\) and \(W(\mathsf{B},\mathbf{n}_{\mathcal{B}^{c}})=\sum_{j\in\mathcal{B}^{c}}u_{j}( \mathsf{B},\mathbf{n})\). With

\[\Xi_{\mathsf{B}}=\left\{\mathbf{n}_{\mathcal{B}}\in\mathbb{R}_{+}^{\mathcal{B} }:\quad\begin{array}{c}\max_{j\in\mathcal{B}}\{n_{j}-\overline{n}_{j}( \mathsf{B},\mathbf{n})\}\leqslant 0\\ \max_{j\in\mathcal{B}}-n_{j}\leqslant 0\end{array}\right\}\,, \tag{31}\]

problem \(\mathcal{T}_{\mathsf{B}}\) is equivalent to

\[\min_{\mathbf{n}_{\mathcal{B}}\in\Xi_{\mathsf{B}}}-W(\mathsf{B},\mathbf{n}_{ \mathcal{B}})+\min_{\mathbf{n}_{\mathcal{B}^{c}}\in\mathbb{R}_{+}^{J-|\mathcal{ B}|}}-W(\mathsf{B},\mathbf{n}_{\mathcal{B}^{c}})=\min_{\mathbf{n}_{\mathcal{B}}\in \Xi_{\mathsf{B}}}-W(\mathsf{B},\mathbf{n}_{\mathcal{B}})+\sum_{j\in[J]}-(1-B_ {j})\underline{u}_{j}\;, \tag{32}\]

by Proposition 1. Since \(\sum_{j\in[J]}-(1-B_{j})\underline{u}_{j}\) is constant, by Equation (32) it is enough to focus on the existence of \(\min_{\mathbf{n}_{\mathcal{B}}\in\Xi_{\mathsf{B}}}-W(\mathsf{B},\mathbf{n}_{ \mathcal{B}})\). On the one hand, \(\Xi_{\mathsf{B}}\) is bounded. Indeed for any \(j\in\mathcal{B}\), by Equation (29) and Lemma 1

\[\overline{n}_{j}(\mathsf{B},\mathbf{n}_{\mathcal{B}}) =\underline{n}-\frac{a}{c}[\varepsilon(\mathsf{B},\mathbf{n}_{ \mathcal{B}})-\varepsilon(\theta_{j},\underline{n})]\] \[=\underline{n}-\frac{a}{c}\bigg{[}\mathcal{R}_{0}^{\star}+2\bigg{[} \frac{\alpha_{\delta}}{(1+\mathbf{n}_{\mathcal{B}}^{\mathrm{T}}\mathsf{B})^{ \gamma}}+\beta+\vartheta(\mathsf{B},\mathbf{n})\bigg{]}-\mathcal{R}_{0}^{\star} -2\bigg{[}\frac{\alpha_{\delta}}{(1+\underline{n})^{\gamma}}-\beta-\theta_{j} \bigg{]}\bigg{]}\] \[=\underline{n}-\frac{2a}{c}\big{[}\alpha_{\delta}\big{(}(1+ \mathbf{n}_{\mathcal{B}}^{\mathrm{T}}\mathsf{B})^{-\gamma}-(1+\underline{n})^{ -\gamma}\big{)}+(\vartheta(\mathsf{B},\mathbf{n})-\theta_{j})\big{]}\] \[\leqslant\underline{n}-\frac{2a}{c}\bigg{[}\alpha_{\delta}\big{(} 1-(1+\underline{n})^{-\gamma}\big{)}+\max_{j\in\mathcal{B}}\theta_{j}\bigg{]}\] \[=M \tag{33}\]

Thus, \(\Xi_{\mathsf{B}}\subset[0,M]^{|\mathcal{B}|}\). Moreover, \(\Xi_{\mathsf{B}}\) is closed and convex. For any \(j\in\mathcal{B}\), rewrite

\[\overline{n}_{j}(\mathsf{B},\mathbf{n}_{\mathcal{B}}) =\underline{n}-\frac{2a}{c}\Big{[}\alpha_{\delta}\big{(}(1+ \mathbf{n}_{\mathcal{B}}^{\mathrm{T}}\mathsf{B})^{-\gamma}-(1+\underline{n})^{ -\gamma}\big{)}+\Big{(}\big{(}\mathbf{n}_{\mathcal{B}}^{\mathrm{T}}\mathsf{B }\big{)}^{-1}\mathbf{n}_{\mathcal{B}}^{\mathrm{T}}\boldsymbol{\theta}-\theta_{j }\Big{)}\Big{]}\] \[=g_{j}(\mathbf{n}_{\mathcal{B}})\;,\]

and define \(h_{j}:\mathbf{n}_{\mathcal{B}}\mapsto\mathrm{n}_{\mathcal{B},j}-g_{j}(\mathbf{ n}_{\mathcal{B}})\). Observe that \(\Xi_{\mathsf{B}}=\{\mathbf{n}_{\mathcal{B}}\in\mathbb{R}_{+}^{|\mathcal{B}|}:\; \forall j\in\mathcal{B},\,n_{\mathcal{B},j}\geqslant 0\text{ and }h_{j}(\mathbf{n}_{ \mathcal{B}})\leqslant 0\}\), that is \(\Xi_{\mathsf{B}}=A\cap B\) with \(A=\mathbb{R}_{+}^{|\mathcal{B}|}\) and \(B=h_{1}^{-1}((-\infty,0])\cap\ldots\cap h_{1}^{-1|\mathcal{B}|}((-\infty,0])\). For any \(j\in\mathcal{B}\), \(h_{j}^{-1}((-\infty,0])\) is convex, because so is \(h_{j}\). Additionally, \(h_{j}^{-1}((-\infty,0])\) is closed as the inverse image of a closed set by a continuous function. It follows that \(\Xi_{\mathsf{B}}\) is convex and closed as the intersection of convex and closed sets.

As a consequence \(\Xi_{\mathsf{B}}\) is compact and convex, and \(-W(\mathsf{B},\,\boldsymbol{\cdot})\) is strictly convex so \(\mathcal{T}_{\mathsf{B}}\) admits a unique minimizer \(\mathbf{n}_{\mathcal{B}}^{\mathrm{opt}}\in\Xi_{\mathsf{B}}\).

Since there are finitely many \(\mathsf{B}\in\{0,1\}^{J}\), \(\min\{-W(\mathsf{B},\mathbf{n}_{\mathcal{B}}^{\mathrm{opt}})+\sum_{j\in \mathcal{B}^{c}}\underline{u}_{j},\,\mathsf{B}\in\{0,1\}^{J}\}>0\) exists and coincide with the minimum of problem (30). We show later in the proof that the optimal \(\mathsf{B}^{\mathrm{opt}}\in\{0,1\}^{J}\) is unique (see _part 1_), so the minimizer of Equation (30) is unique. This establishes the point (i) of the result.

The remainder of the proof proceeds as follows: we first characterize the optimal \(\mathsf{B}^{\mathrm{opt}}\in\{0,1\}^{J}\), and then prove that the solution \(\mathbf{n}_{\mathsf{B}^{\mathrm{opt}}}^{\mathrm{opt}}\in\mathbb{R}_{+}^{| \mathcal{B}|}\) of \(\mathcal{T}_{\mathsf{B}^{\mathrm{opt}}}\) has the form presented in point (ii) of the result.

_Part 1: Optimal \(\mathsf{B}\in\{0,1\}^{[J]}\)_

We show that \(\mathsf{B}^{\mathrm{opt}}=(1,\ldots,1)^{\mathrm{T}}\). By contradiction, assume there exists \(\mathsf{B}^{\prime}\neq(1,\ldots,1)^{\mathrm{T}}\) and \(\mathbf{n}^{\prime}\in\mathbb{R}_{+}^{J}\) such that for any \((\mathsf{B},\mathbf{n})\in\{0,1\}^{J}\times\mathbb{R}_{+}^{J}\)

\[-W(\mathsf{B}^{\prime},\mathbf{n}^{\prime})\leqslant-W(\mathsf{B},\mathbf{n})\;. \tag{34}\]

Denote by \(j\in[J]\) an agent such that \(B^{\prime}_{j}=0\), and first assume \(\theta_{j}\geqslant\vartheta(\mathsf{B}^{\prime},\mathbf{n}^{\prime})\). Consider the alternative allocation \((\mathsf{B}^{\prime\prime},\mathbf{n}^{\prime\prime})=((1,\mathsf{B}^{\prime}_{-j} ),(0,\mathbf{n}^{\prime}_{-j}))\). Observe that \(B^{\prime}_{j}n^{\prime}_{j}=B^{\prime\prime}_{j}n^{\prime\prime}_{j}=0\), so

\[N^{\prime}=\mathsf{B}^{\prime\,\mathrm{T}}\mathbf{n}^{\prime}=\mathsf{B}^{\prime \prime\,\mathrm{T}}\mathbf{n}^{\prime\prime}=N^{\prime\prime}\quad\text{and} \quad\vartheta(\mathsf{B}^{\prime},\mathbf{n}^{\prime})=\vartheta(\mathsf{B}^{ \prime\prime},\mathbf{n}^{\prime\prime})\;. \tag{35}\]This in particular implies

\[\varepsilon(\mathsf{B}^{\prime},\mathbf{n}^{\prime}) =2\big{[}\alpha_{\delta}(1+N^{\prime})^{-\gamma}+\beta+\vartheta( \mathsf{B}^{\prime},N^{\prime})\big{]}\] \[=2\big{[}\alpha_{\delta}(1+N^{\prime\prime})^{-\gamma}+\beta+ \vartheta(\mathsf{B}^{\prime\prime},N^{\prime\prime})\big{]}=\varepsilon( \mathsf{B}^{\prime\prime},\mathbf{n}^{\prime\prime})\;. \tag{36}\]

Thus by (36)

\[-u_{j}(\mathsf{B}^{\prime},\mathbf{n}^{\prime})=\underline{u}_{j} =a(\mathcal{R}_{0}^{\star}+\varepsilon(\theta_{j},\underline{n}))+c \underline{n}>a(\mathcal{R}_{0}^{\star}+\varepsilon(\theta_{j},\underline{n}))\] \[\geqslant a(\mathcal{R}_{0}^{\star}+\varepsilon(\mathsf{B}^{\prime}, \mathbf{n}^{\prime}))=a(\mathcal{R}_{0}^{\star}+\varepsilon(\mathsf{B}^{\prime \prime},\mathbf{n}^{\prime\prime}))=-u_{j}(\mathsf{B}^{\prime\prime},\mathbf{ n}^{\prime\prime})\;, \tag{37}\]

where the second inequality results from \(\theta_{j}\geqslant\vartheta(\mathsf{B}^{\prime},\mathbf{n}^{\prime})\) and \(N^{\prime}\geqslant\underline{n}\). Finally by definition of \((\mathsf{B}^{\prime\prime},\mathbf{n}^{\prime\prime})\), (35) and (36), for any \(k\neq j\) such that \(B_{k}^{\prime\prime}=1\):

\[-u_{k}(\mathsf{B}^{\prime\prime},\mathbf{n}^{\prime\prime}) =a\big{[}\mathcal{R}_{0}^{\star}+2\big{(}\alpha_{\delta}(1+N^{ \prime\prime})^{-\gamma}+\beta+\vartheta(\mathsf{B}^{\prime\prime},\mathbf{n}^ {\prime\prime})\big{)}\big{]}+cn_{k}^{\prime\prime}\] \[=a\big{[}\mathcal{R}_{0}^{\star}+2\big{(}\alpha_{\delta}(1+N^{ \prime})^{-\gamma}+\beta+\vartheta(\mathsf{B}^{\prime},\mathbf{n}^{\prime}) \big{)}\big{]}+cn_{k}^{\prime}=-u_{k}(\mathsf{B}^{\prime},\mathbf{n}^{\prime} )\;. \tag{38}\]

Hence, (38) together with (37) give

\[-W(\mathsf{B}^{\prime\prime},\mathbf{n}^{\prime\prime})=-\sum_{k \neq j}u_{k}(\mathsf{B}^{\prime\prime},\mathbf{n}^{\prime\prime})-u_{j}( \mathsf{B}^{\prime\prime},\mathbf{n}^{\prime\prime}) =-\sum_{k\neq j}u_{i}(\mathsf{B}^{\prime},\mathbf{n}^{\prime})-u _{j}(\mathsf{B}^{\prime\prime},\mathbf{n}^{\prime\prime})\] \[<-\sum_{k\neq j}u_{i}(\mathsf{B}^{\prime},\mathbf{n}^{\prime})-u _{j}(\mathsf{B}^{\prime},\mathbf{n}^{\prime})=-W(\mathsf{B}^{\prime},\mathbf{n }^{\prime})\;. \tag{39}\]

This contradicts (34). Now assume \(\theta_{j}<\vartheta(\mathsf{B}^{\prime},\mathbf{n}^{\prime})\), and let \(R\in[J]\) be such that \(\theta_{R}=\max\{\theta_{k},\,k\in\mathcal{B}\}\). Consider \((\mathsf{B}^{\prime\prime},\mathbf{n}^{\prime\prime})\in\{0,1\}^{J}\times \mathbb{R}_{+}^{J}\) where

\[\mathsf{B}^{\prime\prime} =(B_{1}^{\prime},\ldots,B_{j-1}^{\prime},\;1\,,B_{j+1}^{\prime}, \ldots,B_{J}^{\prime})^{\mathrm{T}}\] \[\text{and}\;\mathbf{n}^{\prime\prime} =(n_{1}^{\prime},\ldots,n_{j-1}^{\prime},\;\overline{n}_{j}\,,n_{j +1}^{\prime},\ldots,n_{R-1}^{\prime},\;\max(0,n_{R}^{\prime}-\overline{n}_{j })\,,n_{R+1}^{\prime},\ldots,n_{J}^{\prime})^{\mathrm{T}}\;.\]

which is feasible. Observe on the one hand that

\[N^{\prime\prime}=N^{\prime}\quad\text{ and }\quad\vartheta(\mathsf{B}^{\prime \prime},\mathbf{n}^{\prime\prime})\leqslant\vartheta(\mathsf{B}^{\prime}, \mathbf{n}^{\prime})+\frac{\overline{n}_{j}}{N^{\prime}}(\theta_{j}-\theta_{R} )<\vartheta(\mathsf{B}^{\prime},\mathbf{n}^{\prime})\;,\]

because \(\theta_{j}<\vartheta(\mathsf{B}^{\prime},\mathbf{n}^{\prime})\leqslant \theta_{R}\). In particular

\[\varepsilon(\mathsf{B}^{\prime\prime},\mathbf{n}^{\prime\prime}) =\mathcal{R}_{0}^{\star}+2\big{[}\alpha_{\delta}(N^{\prime\prime} +1)^{-\gamma}+\beta+\vartheta(\mathsf{B}^{\prime\prime},\mathbf{n}^{\prime \prime})\big{]}\] \[<\mathcal{R}_{0}^{\star}+2\big{[}\alpha_{\delta}(N^{\prime}+1)^{ -\gamma}+\beta+\vartheta(\mathsf{B}^{\prime},\mathbf{n}^{\prime})\big{]}= \varepsilon(\mathsf{B}^{\prime},\mathbf{n}^{\prime})\;. \tag{40}\]

(40) in turn implies that for any \(k\neq j\) such that \(B_{k}^{\prime\prime}=1\):

\[-u_{k}(\mathsf{B}^{\prime\prime},\mathbf{n}^{\prime\prime})=a[\mathcal{R}_{0}^ {\star}+\varepsilon(\mathsf{B}^{\prime\prime},\mathbf{n}^{\prime\prime})]+cn_{ k}^{\prime\prime}<a[\mathcal{R}_{0}^{\star}+\varepsilon(\mathsf{B}^{\prime}, \mathbf{n}^{\prime})]+cn_{k}^{\prime}=-u_{k}^{\prime}(\mathsf{B}^{\prime}, \mathbf{n}^{\prime})\;. \tag{41}\]

because \(n_{k}^{\prime}=n_{k}^{\prime\prime}\) for \(k\in\mathcal{B}\setminus\{j,R\}\) and \(n_{R}^{\prime\prime}<n_{R}^{\prime}\). On the other hand, we have

\[u_{j}(\mathsf{B}^{\prime\prime},\mathbf{n}^{\prime\prime})=\underline{u}_{j}=u_ {j}(\mathsf{B}^{\prime},\mathbf{n}^{\prime})\;, \tag{42}\]

by definition (29) of \(\overline{n}_{j}(\mathsf{B}^{\prime\prime},\mathbf{n}^{\prime\prime})\). (41) and (42) together yield

\[-W(\mathsf{B}^{\prime\prime},\mathbf{n}^{\prime\prime})=-\sum_{k \neq j}u_{k}(\mathsf{B}^{\prime\prime},\mathbf{n}^{\prime\prime})-u_{j}( \mathsf{B}^{\prime\prime},\mathbf{n}^{\prime\prime}) =-\sum_{k\neq j}u_{k}(\mathsf{B}^{\prime\prime},\mathbf{n}^{\prime \prime})-u_{j}(\mathsf{B}^{\prime},\mathbf{n}^{\prime\prime})\] \[<-\sum_{k\neq j}u_{k}(\mathsf{B}^{\prime},\mathbf{n}^{\prime})-u_{j}( \mathsf{B}^{\prime},\mathbf{n}^{\prime})=-W(\mathsf{B}^{\prime},\mathbf{n}^{ \prime})\;,\]

which once again violates (34). Thus, we obtain \(\mathsf{B}^{\mathrm{opt}}=(1,\ldots,1)^{\mathrm{T}}\), that is \(\mathcal{B}^{\mathrm{opt}}=[J]\).

_Part 2: Characterization of \(\mathbf{n}^{\mathrm{opt}}_{[J]}\in\mathbb{R}_{+}^{J}\)_

We now focus on the problem \(\mathcal{T}_{\mathsf{B}^{\mathrm{opt}}}\). To lighten notations, we write \(\mathbf{n}^{\mathrm{opt}}\in\mathbb{R}_{+}^{J}\) instead of \(\mathbf{n}^{\mathrm{opt}}_{\mathsf{B}^{\mathrm{opt}}}\), and \(\mathsf{B}\) instead of \(\mathsf{B}^{\mathrm{opt}}=(1,\ldots,1)\). We first reformulate \(\mathcal{T}_{\mathsf{B}}\) in a more convenient way. Recall that \(\mathcal{T}_{\mathsf{B}}\) reads

\[(\mathcal{T}_{\mathsf{B}}):\quad\text{minimize}\quad-W(\mathsf{B},\mathbf{n}) \quad\text{subject to}\quad\mathbf{n}\in\Xi_{\mathsf{B}}\;, \tag{43}\]where \(\Xi_{\sf B}\) is defined in (31). As explained in Appendix A, this problem can equivalently be stated as

\[(\widetilde{\mathcal{T}}_{\sf B}):\quad\text{minimize}\quad-\widetilde{W}_{\sf B} (\boldsymbol{\lambda},N)\quad\text{subject to}\quad(\boldsymbol{\lambda},N)\in \widetilde{\Xi}_{\sf B}\, \tag{44}\]

where

\[-\widetilde{W}_{\sf B}(\boldsymbol{\lambda},N)=f(N)+g(\boldsymbol{\lambda})\,\]

with

\[f(N)=aJ(\mathcal{R}_{0}^{\star}+2\alpha_{\delta}(1+N)^{-\gamma})+cN\quad\text{ and}\quad g(\boldsymbol{\lambda})=2aJ\boldsymbol{\lambda}^{\rm T}\boldsymbol{\theta}\,\]

and

\[\widetilde{\Xi}_{\sf B}=\big{\{}(\boldsymbol{\lambda},N)\in\Delta_{|\mathcal{ B}|}\times\mathbb{R}_{+}:\ \boldsymbol{\lambda}N\in\Xi_{\sf B}\big{\}}\.\]

Writing \(\widetilde{\Xi}_{\sf B}(N)=\{\boldsymbol{\lambda}\in\Delta_{J}:\ (\boldsymbol{ \lambda},N)\in\widetilde{\Xi}_{\sf B}\}\) for \(N\geqslant 0\) and \(\mathcal{N}=\{N\geqslant 0:\ \widetilde{\Xi}_{\sf B}(N)\neq\emptyset\}\), \(\widetilde{\mathcal{T}}_{\sf B}\) comes down to

\[\min_{(\boldsymbol{\lambda},N)\in\widetilde{\Xi}_{\sf B}}\{f(N)+g(\boldsymbol {\lambda})\}=\min_{N\in\mathcal{N}}\{f(N)+\min_{\boldsymbol{\lambda}\in \widetilde{\Xi}_{\sf B}(N)}g(\boldsymbol{\lambda})\}\.\]

In this proof, we address the innermost problem, which is enough to show that \(\mathbf{n}^{\rm opt}\) satisfies the point (ii) of the result. Let \(N\geqslant 0\) such that \(\widetilde{\Xi}_{\sf B}(N)\neq\emptyset\), which exists because \(\Xi_{\sf B}\neq\emptyset\) (for instance, \(((1,0,\ldots,0),(\underline{n},0,\ldots,0))\in\Xi_{\sf B}\)). By definition of \(\widetilde{\Xi}_{\sf B}\), it reads

\[(\widetilde{\mathcal{T}}^{(N)}):\quad\text{minimize}\quad\boldsymbol{\lambda} \in\Delta_{J}\mapsto 2aJ\boldsymbol{\lambda}^{\rm T}\boldsymbol{\theta}\quad\text{ subject to}\quad\left\{\begin{array}{l}\forall j\in\mathcal{B}:\lambda_{j}\geqslant 0\\ \forall j\in\mathcal{B}:\ \lambda_{j}N\leqslant\overline{n}_{j}(\sf B, \boldsymbol{\lambda}N)\\ \sum_{j\in\mathcal{B}}\lambda_{j}=1\,\end{array}\right. \tag{45}\]

The following lemma provides a necessary condition for any solution to problem (45).

**Lemma 4**.: _Let \(\boldsymbol{\lambda}^{(N)}=(\lambda_{1}^{(N)},\ldots,\lambda_{J}^{(N)})\in \Delta_{J}\) be a solution to (45). If there exists \(r\in[J]\) such that \(\lambda_{r}^{(N)}>0\), then \(\lambda_{k}^{(N)}=N^{-1}\overline{n}_{k}(\sf B,N\boldsymbol{\lambda}^{(N)})\) for any \(k<r\)._

Proof.: We denote by \(\bar{\bf n}(\sf B,\bf n)=(\overline{n}_{1}(\sf B,\bf n),\ldots,\overline{n}_{J }(\sf B,\bf n))^{\rm T}\) for any \(\bf n\in\mathbb{R}_{+}^{J}\). The Lagrangian associated to problem (45), with \(\boldsymbol{\mu}\), \(\boldsymbol{\rho}\) and \(\nu\) the associated dual variables, reads:

\[\mathcal{L}(\boldsymbol{\lambda},\boldsymbol{\mu},\boldsymbol{ \rho},\nu) =2aJ\boldsymbol{\lambda}^{\rm T}\boldsymbol{\theta}-\boldsymbol{ \mu}^{\rm T}\boldsymbol{\lambda}+\nu\big{(}1-\boldsymbol{\lambda}^{\rm T}{\bf 1} \big{)}+\boldsymbol{\rho}^{\rm T}[N\boldsymbol{\lambda}-\bar{\bf n}(\sf B,N \boldsymbol{\lambda})]\] \[=2aJ\boldsymbol{\lambda}^{\rm T}\boldsymbol{\theta}+cN- \boldsymbol{\mu}^{\rm T}\boldsymbol{\lambda}+\nu\big{(}1-\boldsymbol{\lambda}^ {\rm T}{\bf 1}\big{)}\] \[+\boldsymbol{\rho}^{\rm T}(N\boldsymbol{\lambda}-\underline{n}{ \bf 1}+\frac{2a}{c}\big{[}\alpha_{\delta}\big{(}(N+1)^{-\gamma}-(\underline{ n}+1)^{-\gamma}\big{)}{\bf 1}+\big{(}(\boldsymbol{\lambda}^{\rm T}\boldsymbol{\theta}){\bf 1}- \boldsymbol{\theta}\big{)}\big{]}\big{)}\.\]

Since the objective and the constraints are convex, \(\mathcal{L}\) admits a saddle point \((\boldsymbol{\lambda}^{(N)},\boldsymbol{\mu},\boldsymbol{\rho},\nu)\in\Delta \times\mathbb{R}^{J}\times\mathbb{R}^{J}\times\mathbb{R}\) which is solution to problem (45) and verifies the following KKT conditions:

\[\forall k\leqslant J:\ 2aJ\theta_{k}-\mu_{k}+\rho_{k}(N+2ac^{-1}\theta_{k})=\nu \tag{46}\] \[\forall k\leqslant J:\ \mu_{k}\lambda_{k}^{(N)}=0,\quad\mu_{k}\geqslant 0\] (47) \[\forall k\leqslant J:\ \rho_{k}\Big{(}\lambda_{k}^{(N)}\,N- \overline{n}_{\iota}(\sf B,\boldsymbol{\lambda}^{(N)}N)\Big{)}=0,\quad\rho_{k}\geqslant 0\] (48) \[\sum_{k\in\mathcal{B}}\lambda_{k}^{(N)}=1. \tag{49}\]

Assume there exists \(r\in\mathcal{B}\) such that \(\lambda_{r}^{(N)}>0\). By complementary slackness (47), \(\mu_{r}=0\), and (46) gives for any \(k<r\):

\[2aJ\theta_{k}-\mu_{k}+\rho_{k}(N+2ac^{-1}\theta_{k})=2aJ\theta_{r}+\rho_{r}(N+2 ac^{-1}\theta_{r})\, \tag{50}\]

That is

\[\rho_{k}=\frac{2aJ(\theta_{r}-\theta_{k})+\mu_{k}}{N+2ac^{-1}\theta_{k}}+\rho_{ r}\frac{N+2ac^{-1}\theta_{r}}{N+2ac^{-1}\theta_{k}}\.\]

By assumption \(\theta_{r}>\theta_{k}\), and since \(\mu_{k}\geqslant 0\) as well as \(\rho_{r}\geqslant 0\), we have \(\rho_{k}>0\). It follows from (48) for agent \(k\) that \(\lambda_{k}^{\rm opt}N=\overline{n}(\sf B,N\boldsymbol{\lambda}^{(N)})\).

Now, define

\[M_{j}=\sum_{k\leqslant j}\overline{n}_{k}(\mathsf{B},\boldsymbol{\lambda}^{(N)}N) \quad\text{and}\quad L=\min\{j\in\mathcal{B}\,:\ M_{j}\geqslant N\}\;. \tag{51}\]

We show that

\[\lambda_{k}^{(N)}=\overline{n}_{k}(\mathsf{B},N\boldsymbol{\lambda}^{(N)})N^{-1 }\text{ for any }k<L\quad\text{ and }\quad\lambda_{k}^{(N)}=0\text{ for any }k>L\;. \tag{52}\]

To prove the first point, assume by contradiction that there exists \(\ell<L\) such that \(\lambda_{\ell}^{(N)}<\overline{n}_{\ell}(\mathsf{B},\boldsymbol{\lambda}^{(N) }N)N^{-1}\). By the contrapositive of Lemma 4, \(\lambda_{\ell+1}^{\mathrm{opt}}=\ldots=\lambda_{J}^{\mathrm{opt}}=0\). Thus

\[\sum_{k\leqslant J}\lambda_{k}^{(N)}=\sum_{k\leqslant\ell}\lambda_{k}^{(N)} \leqslant\sum_{k\leqslant\ell}\overline{n}_{k}(\mathsf{B},\boldsymbol{\lambda }^{(N)}N)N^{-1}=M_{\ell}N^{-1}<1\;,\]

by definition of \(L\) Equation (51) and \(\ell<L\). This violates the third constraint of problem (45). For the second point, assume there exists \(\ell>L\) such that \(\lambda_{\ell}^{(N)}>0\). By Lemma 4, \(\lambda_{k}^{(N)}=\overline{n}_{k}(\mathsf{B},\boldsymbol{\lambda}^{(N)}N)N^{-1}\) for any \(k\leqslant L<\ell\), so

\[\sum_{k\leqslant J}\lambda_{k}^{(N)}\geqslant\sum_{k\leqslant L} \lambda_{k}^{(N)}+\lambda_{\ell}^{(N)} =\sum_{k\leqslant L}\overline{n}_{k}(\mathsf{B},\boldsymbol{ \lambda}^{(N)}N)N^{-1}+\lambda_{\ell}^{(N)}\] \[=M_{L}N^{-1}+\lambda_{\ell}^{(N)}\] \[\geqslant 1+\lambda_{\ell}^{(N)}>1\;,\]

which once again violates the constraints of the problem. Finally by (52),

\[\lambda_{i_{L}}^{(N)}=1-\sum_{k<L}\lambda_{k}^{(N)}-\sum_{k>L}\lambda_{k}^{(N) }=1-M_{L-1}N^{-1}\;, \tag{53}\]

by (52). By (52) and (53) we obtain for any \(j\in[J]\):

\[\lambda_{j}^{(N)}=N^{-1}\overline{n}_{j}(\mathsf{B},N\boldsymbol{\lambda}^{(N) })\mathbb{1}_{\{j<L\}}+(1-N^{-1}M_{j-1})\mathbb{1}_{\{j=L\}}\;, \tag{54}\]

Now, consider the solution \(\mathbf{n}^{\mathrm{opt}}(\boldsymbol{\theta})\in\mathbb{R}^{J}\) to the initial problem (45), and define

\[\left\{\begin{array}{ll}N^{\mathrm{opt}}&=\sum_{j\in[J]}n_{j}^{\mathrm{opt} }(\boldsymbol{\theta})\\ \boldsymbol{\lambda}^{\mathrm{opt}}(\boldsymbol{\theta})&=\frac{1}{N^{\mathrm{ opt}}}\mathbf{n}^{\mathrm{opt}}(\boldsymbol{\theta})\\ L^{\mathrm{opt}}&=\min\{j\in[J]\,:\,\sum_{k\leqslant j}\overline{n}_{k}( \mathsf{B},\mathbf{n}^{\mathrm{opt}}(\boldsymbol{\theta}))\geqslant N^{ \mathrm{opt}}\}\;.\end{array}\right.\]

\(\boldsymbol{\lambda}^{\mathrm{opt}}(\boldsymbol{\theta})\) satisfies (54), and multiplying by \(N^{\mathrm{opt}}\) yields for any \(j\in[J]\):

\[n_{j}^{\mathrm{opt}}(\boldsymbol{\theta})=\overline{n}_{j}(\mathsf{B},\mathbf{ n}^{\mathrm{opt}}(\boldsymbol{\theta}))\mathbb{1}_{\{j<L^{\mathrm{opt}}\}}+(N^{ \mathrm{opt}}-\sum_{k\leqslant j}n_{j}^{\mathrm{opt}}(\boldsymbol{\theta})) \mathbb{1}_{\{j=L^{\mathrm{opt}}\}}\;, \tag{55}\]

which establishes point (ii), and concludes the proof.

**Corollary 1**.: _Assume **H**1, **H**2 and **H**3. Then \(L^{\star}=\Theta(J^{\frac{1}{1+\gamma}})\) and for any \(j\in[J]\),_

\[n_{j}^{\star}(\boldsymbol{\theta})=\mathbb{1}_{\{j\leq L^{\star}\}}\Bigg{[} \frac{\bar{N}}{L^{\star}}+\frac{2a}{c}\Bigg{(}\theta_{j}-\frac{1}{L^{\star}} \sum_{\ell=1}^{L^{\star}}\theta_{\ell}\Bigg{)}\Bigg{]}\;.\]

Proof.: By definition of the simplified scheme (12), \(n_{j}^{\star}(\boldsymbol{\theta})=\mathbb{1}_{\{j\leq L^{\star}\}}\overline{ n}_{j}(\mathbf{1},\mathbf{n}^{\star}(\boldsymbol{\theta}))=\mathbb{1}_{\{j\leq L^{ \star}\}}[\underline{n}-(2a/c)(\varepsilon(\mathbf{1},\mathbf{n}^{\star}( \boldsymbol{\theta}))-\varepsilon(\theta_{j},\underline{n}))]\) for any \(j\leqslant L^{\star}\). Since \(\sum_{j\in[J]}n_{j}^{\star}(\boldsymbol{\theta})=\bar{N}\), we get

\[\bar{N} =L^{\star}\underline{n}-\frac{a}{c}\Bigg{[}L^{\star}\varepsilon (\mathbf{1},\mathbf{n}^{\star}(\boldsymbol{\theta}))-\sum_{j\leqslant L^{\star} }\varepsilon(\theta_{j},\underline{n})\Bigg{]}\] \[=L^{\star}\bigg{[}\underline{n}-\frac{2a}{c}\big{[}\alpha_{ \delta}\big{(}(1+\bar{N})^{-\gamma}-(1+\underline{n})^{-\gamma}\big{)}+( \vartheta(\mathbf{1},\mathbf{n}^{\star}(\boldsymbol{\theta}))-\bar{\theta}_{L^{ \star}})\big{]}\bigg{]}\;,\]By Lemma 1 and denoting \(\bar{\theta}_{L^{\star}}=L^{\star-1}\sum_{j\leqslant L^{\star}}\theta_{j}\). This yields

\[\vartheta(\mathbf{1},\mathbf{n}^{\star}(\boldsymbol{\theta}))=\bar{\theta}_{L^{ \star}}-\alpha_{\delta}((1+\bar{N})^{-\gamma}-(1+\underline{n})^{-\gamma})+(c/ 2a)(\underline{n}-\bar{N}/L^{\star})\.\]

Plugging back this value in \(\overline{n}_{j}^{\star}(\mathbf{1},\mathbf{n}^{\star}(\boldsymbol{\theta}))= \underline{n}-(2a/c)[\alpha_{\delta}\big{(}(1+\bar{N})^{-\gamma}-(1+\underline {n})^{-\gamma}\big{)}+(\vartheta(\mathbf{1},\mathbf{n}^{\star}(\boldsymbol{ \theta}))-\theta_{j})]\) gives for any \(j\in[J]\):

\[n_{j}^{\star}(\boldsymbol{\theta})=\mathbb{1}_{\{j\leqslant L^{\star}\}}\bigg{[} \frac{\bar{N}}{L^{\star}}-\frac{2a}{c}(\bar{\theta}_{L^{\star}}-\theta_{j}) \bigg{]}. \tag{56}\]

We now determine the order of magnitude of \(L^{\star}\in\{1,\ldots,J\}\). Recall on the one hand that by (33), there exists \(M>0\) such that \(0\leqslant n_{j}^{\star}(\boldsymbol{\theta})\leqslant M\) for any \(j\in[J]\), and on the other hand that \(\bar{\theta}_{L^{\star}}-\theta_{j}\leqslant\bar{\theta}-\underline{\theta}= \text{diam}(\Theta)<\infty\). Therefore by (56),

\[\frac{2a}{c}\text{diam}(\Theta)\leqslant\frac{\bar{N}}{L^{\star}}\leqslant M+ \frac{2a}{c}\text{diam}(\Theta)\quad\text{so}\quad\frac{\bar{N}}{L^{\star}}= \Theta(1). \tag{57}\]

Since \(\bar{N}=(\underline{n}+1)|\mathcal{B}^{\star}|^{\frac{1}{1+\gamma}}-1\) and \(\mathcal{B}^{\star}=[J]\), (57) results in \(L=\Theta(J^{\frac{1}{1+\gamma}})\).

**Lemma 2**.: _Assume **H**1, **H**2 and \(\theta_{j}-\theta_{j-1}=\mathcal{O}(1/J)\) for any \(j\in\{2,\ldots,J\}\). Then,_

\[W(\mathrm{B}^{\mathrm{opt}},\mathbf{n}^{\mathrm{opt}}(\boldsymbol{\theta}))=W( \mathrm{B}^{\star},\mathbf{n}^{\star}(\boldsymbol{\theta}))+\mathcal{O}(J^{ \frac{1}{1+\gamma}})\.\]

Proof.: Recall that for any admissible \(\mathbf{n}\in\Xi_{\mathsf{B}}\), we can define \(N=\mathbf{1}^{\mathrm{T}}\mathbf{n}\) and \(\boldsymbol{\lambda}=N^{-1}\mathbf{n}\) so that the social cost rewrites

\[-W(\mathsf{B},\mathbf{n})=-\widetilde{W}_{\mathsf{B}}(\boldsymbol{\lambda},N)= f(N)+g(\boldsymbol{\lambda})\,\]

with

\[f(N)=aJ(\mathcal{R}_{0}^{\star}+2\alpha_{\delta}(1+N)^{-\gamma})+cN\quad\text{ and}\quad g(\boldsymbol{\lambda})=2aJ\boldsymbol{\lambda}^{\mathrm{T}}\boldsymbol{\theta}\.\]

By definition, \(\sum_{j\in[J]}n_{j}^{\star}(\boldsymbol{\theta})=\bar{N}\) where \(\bar{N}=(\underline{n}+1)J^{\frac{1}{1+\gamma}}-1=\operatorname*{argmin}_{N \geqslant 0}f(N)\). Hence,

\[W(B^{\mathrm{opt}},\mathbf{n}^{\mathrm{opt}}(\boldsymbol{\theta}) )-W(\mathrm{B}^{\star},\mathbf{n}^{\star}(\boldsymbol{\theta})) =\widetilde{W}_{\mathsf{B}}(\boldsymbol{\lambda}^{\mathrm{opt}}, N^{\mathrm{opt}})-\widetilde{W}_{\mathsf{B}}(\boldsymbol{\lambda}^{\star},\bar{N})\] \[=f(\bar{N})+g(\boldsymbol{\lambda}^{\star})-f(N^{\mathrm{opt}} )-g(\boldsymbol{\lambda}^{\mathrm{opt}})\] \[\leqslant g(\boldsymbol{\lambda}^{\star})-g(\boldsymbol{\lambda}^{ \mathrm{opt}})=2aJ(\boldsymbol{\lambda}^{\star}-\boldsymbol{\lambda}^{\mathrm{ opt}})^{\mathrm{T}}\boldsymbol{\theta}\.\]

Since \(\theta_{j}\leqslant\theta_{L^{\star}}\) for any \(j\in[J]\) such that \(\lambda_{j}^{\star}>0\), and \(\theta_{j}\geqslant\theta_{1}\) for any \(j\in[J]\) such that \(\lambda_{j}^{\mathrm{opt}}>0\):

\[W(B^{\mathrm{opt}},\mathbf{n}^{\mathrm{opt}}(\boldsymbol{\theta}))-W(\mathrm{B} ^{\star},\mathbf{n}^{\star}(\boldsymbol{\theta}))\leqslant 2aJ(\theta_{L^{\star}}- \theta_{1})\,\]

By assumption, for any \(j\in\{2,\ldots,J\}\)\(\theta_{j}-\theta_{j-1}=\mathcal{O}(1/J)\) so there exists \(k_{j}>0\) and \(R_{j}\geqslant 0\) such that \(\theta_{j}-\theta_{j-1}\leqslant k_{j}J^{-1}\) for \(J\geqslant R_{j}\). Denoting \(R=\max_{j\in[J]}R_{j}\) and \(k=\max_{j\in[J]}k_{j}\), for any \(J\geqslant R\) we have \(\theta_{L^{\star}}-\theta_{1}\leqslant kL^{\star}\), so:

\[W(B^{\mathrm{opt}},\mathbf{n}^{\mathrm{opt}}(\boldsymbol{\theta}))-W(\mathrm{B} ^{\star},\mathbf{n}^{\star}(\boldsymbol{\theta}))\leqslant 2aJ\frac{kL^{\star}}{J}=2akL^{\star}\,\]

so \(W(B^{\mathrm{opt}},\mathbf{n}^{\mathrm{opt}}(\boldsymbol{\theta}))-W(\mathrm{B} ^{\star},\mathbf{n}^{\star}(\boldsymbol{\theta}))=\mathcal{O}(L^{\star})= \mathcal{O}(J^{\frac{1}{1+\gamma}})\) by Corollary 1.

**Theorem 2** (Unravelling).: _Assume **H**1, **H**2, **H**3, and **H**4. Let \(\mathcal{E}\subset\mathcal{S}^{J}\) be the set of pure-strategy Nash equilibria of the game induced by \(\Gamma\). We have_

1. \(\mathcal{E}\neq\emptyset\)__
2. _at any_ \(s^{\star}\in\mathcal{E}\)_,_ \(\mathsf{B}=(0,\ldots,0)\) _or_ \(\mathsf{B}=(0,\ldots,0,1)\) _._Proof.: First, we show that the situation where the coalition is empty is a Nash equilibrium. Consider \(\mathbf{s}=((0,\dagger),\ldots,(0,\dagger))\in\mathscr{S}^{N}\). For any \(j\in[J]\) and deviation \((1,\widetilde{\theta}_{j})\), \(\mathcal{B}=\{j\}\) so \(\widehat{g}_{\mathsf{B}}=\widehat{g}_{j}\) and \(v_{j}((0,\dagger),\mathbf{s}^{\star}_{-j})=\underline{u}_{j}\geqslant v_{j}((1,\widetilde{\theta}_{j}),\mathbf{s}_{-j})\) by Proposition 1. Thus, \(s^{\star}\in\mathscr{E}\).

Now, consider a pure-strategy Nash equilibrium \(s^{\star}\in\mathscr{E}\) such that \(\mathcal{B}=\{j\in[J]\,:\,B_{j}=1\}\neq\emptyset\). Denote by \(\mathcal{C}=\{j\in\mathcal{B}\,:\,n^{\star}_{j}(\widetilde{\boldsymbol{\theta} })>0\}\) the set of contributors. We start with two technical lemmas:

**Lemma 5**.: _There exists \(\Delta\in\mathbb{R}\) such that for any \((j,k)\in\mathcal{C}^{2}\)_

\[\theta_{j}-\widetilde{\theta}_{j}=\theta_{k}-\widetilde{\theta}_{k}=\Delta\;.\]

Proof.: To lighten notation, we write in this proof

\[\vartheta(\widetilde{\boldsymbol{\theta}})=N^{-1}\sum_{j\in\mathcal{C}}n^{ \star}_{j}(\widetilde{\boldsymbol{\theta}})\,\theta_{j}\quad\text{and}\quad \widetilde{\vartheta}(\widetilde{\boldsymbol{\theta}})=N^{-1}\sum_{j\in \mathcal{C}}n^{\star}_{j}(\widetilde{\boldsymbol{\theta}})\,\widetilde{ \theta}_{j},\quad\text{where}\quad N=\sum_{k\in\mathcal{C}}n^{\star}_{k}( \widetilde{\boldsymbol{\theta}})\;.\]

By Equation (12) and \(\mathbf{H}4\), for any \(j\in\mathcal{C}\), \(n^{\star}_{j}(\widetilde{\boldsymbol{\theta}})=\overline{n}_{j}(\mathsf{B}, \mathbf{n}^{\star}(\widetilde{\boldsymbol{\theta}}))=\underline{n}-\frac{a}{c }(\varepsilon(\widetilde{\vartheta}(\widetilde{\boldsymbol{\theta}}),N)- \varepsilon(\widetilde{\theta}_{j},\underline{n}))\), so their payoff reads

\[v_{j}((1,\widetilde{\theta}_{j}),\mathbf{s}_{-j}) =-a(\mathcal{R}^{\star}_{0}+\varepsilon(\vartheta(\widetilde{ \boldsymbol{\theta}}),N)-c\Big{[}\underline{n}-\frac{a}{c}\Big{(}\varepsilon( \widetilde{\vartheta}(\widetilde{\boldsymbol{\theta}}),N)-\varepsilon( \widetilde{\theta}_{j},\underline{n})\Big{)}\Big{]}\] \[=-a(\mathcal{R}^{\star}_{0}+\varepsilon(\theta_{j},\underline{n} ))-c\underline{n}\] \[+a\Big{[}\Big{(}\varepsilon(\theta_{j},\underline{n})- \varepsilon(\widetilde{\theta}_{j},\underline{n})\Big{)}-\Big{(}\varepsilon( \vartheta(\widetilde{\boldsymbol{\theta}}),N)-\varepsilon(\widetilde{\vartheta }(\widetilde{\boldsymbol{\theta}}),N)\Big{)}\Big{]}\] \[=\underline{u}_{j}+2a\Big{[}\Big{(}\theta_{j}-\widetilde{\theta }_{j}\Big{)}-\Big{(}\vartheta(\widetilde{\boldsymbol{\theta}})-\widetilde{ \vartheta}(\widetilde{\boldsymbol{\theta}})\Big{)}\Big{]}\;. \tag{58}\]

Since \(\mathbf{s}\) is a Nash equilibrium and \(\underline{u}_{j}=v_{j}((0,\dagger),\mathbf{s}_{-j})\), we have in particular that

\[2a\Big{[}\Big{(}\theta_{j}-\widetilde{\theta}_{j}\Big{)}-\Big{(}\vartheta( \widetilde{\boldsymbol{\theta}})-\widetilde{\vartheta}(\widetilde{ \boldsymbol{\theta}})\Big{)}\Big{]}\geqslant 0\;,\]

that is \(\theta_{j}-\widetilde{\theta}_{j}=\Delta_{j}\geqslant\Delta=\vartheta( \widetilde{\boldsymbol{\theta}})-\widetilde{\vartheta}(\widetilde{\boldsymbol {\theta}})\) for any \(j\in\mathcal{C}\). We now show that this holds with strict equality for any \(j\in\mathcal{C}\). By contradiction, assume there exists \(r\in\mathcal{C}\) such that \(\Delta_{r}=\Delta+\chi\) with \(\chi>0\). Then

\[\Delta=\vartheta(\widetilde{\boldsymbol{\theta}})-\widetilde{ \vartheta}(\widetilde{\boldsymbol{\theta}})=\sum_{j\in\mathcal{C}}\lambda^{ \star}_{j}(\widetilde{\boldsymbol{\theta}})\Delta_{j} =\sum_{j\in\mathcal{C}\setminus\{r\}}\lambda^{\star}_{j}( \widetilde{\boldsymbol{\theta}})\Delta_{j}+\lambda^{\star}_{r}(\widetilde{ \boldsymbol{\theta}})(\Delta+\chi)\] \[\geqslant\Delta+\lambda^{\star}_{r}(\widetilde{\boldsymbol{ \theta}})\chi>\Delta\;,\]

because \(\lambda^{\star}_{r}(\widetilde{\boldsymbol{\theta}})>0\) as \(r\in\mathcal{C}\). This is a contradiction, and establishes the result. 

**Lemma 6**.: _For any \(j\in\mathcal{C}\), \(\widetilde{\theta}_{j}=\underline{\theta}\)._

Proof.: Let \(j\in\mathcal{C}\), by (58):

\[v_{j}((1,\widetilde{\theta}_{j}),\mathbf{s}_{-j}) =\underline{u}_{j}+2a\Big{[}\Big{(}\theta_{j}-\widetilde{\theta }_{j}\Big{)}-\Big{(}\vartheta(\widetilde{\boldsymbol{\theta}})-\widetilde{ \vartheta}(\widetilde{\boldsymbol{\theta}})\Big{)}\Big{]}\] \[=\underline{u}_{j}+2a\Bigg{[}\Big{(}1-\lambda^{\star}_{j}( \widetilde{\boldsymbol{\theta}})\Big{)}\Big{(}\theta_{j}-\widetilde{\theta }_{j}\Big{)}-\sum_{k\in\mathcal{C}\setminus\{j\}}\lambda^{\star}_{k}( \widetilde{\boldsymbol{\theta}})\Big{(}\theta_{k}-\widetilde{\theta}_{k}\Big{)} \Bigg{]}\] \[=\underline{u}_{j}+2a\Bigg{[}\Bigg{(}\sum_{k\in\mathcal{C} \setminus\{j\}}\lambda^{\star}_{k}(\widetilde{\boldsymbol{\theta}})\Bigg{)} \Big{(}\theta_{j}-\widetilde{\theta}_{j}\Big{)}-\sum_{k\in\mathcal{C}\setminus\{j \}}\lambda^{\star}_{k}(\widetilde{\boldsymbol{\theta}})\Big{(}\theta_{k}- \widetilde{\theta}_{k}\Big{)}\Bigg{]}\] \[=\underline{u}_{j}+2aq_{j}(\widetilde{\theta}_{j},\widetilde{ \boldsymbol{\theta}}_{-j})\;,\]

where

\[q_{j}(\widetilde{\theta}_{j},\widetilde{\boldsymbol{\theta}}_{-j})=\sum_{k\in \mathcal{C}\setminus\{j\}}\lambda^{\star}_{k}(\widetilde{\boldsymbol{\theta}})[ (\theta_{j}-\widetilde{\theta}_{j})-(\theta_{k}-\widetilde{\theta}_{k})]\;. \tag{59}\]We prove that \(v_{j}((1,\cdot),\mathbf{s}_{-j})\) is strictly decreasing in \(\widetilde{\theta}_{j}\) for \(j\in\mathcal{C}\), by showing that \(\partial\hat{v}_{j}((1,\widetilde{\theta}_{j}),\mathbf{s}_{-i_{j}})/\partial \widetilde{\theta}_{j}<0\) For any \(j\in\mathcal{C}\). For \(v_{j}\) to be differentiable, we need \(q_{j}\) to be differentiable, that is \(\lambda_{j}^{\star}(\widetilde{\mathbf{\theta}})=(\sum_{k\in\mathcal{C}}n_{k}^{ \star}(\widetilde{\mathbf{\theta}}))^{-1}n_{j}^{\star}(\widetilde{\mathbf{\theta}})\) to be differentiable for any \(j\in\mathcal{C}\). We re-index \(\mathcal{C}\) as \(\{i_{1},\ldots,i_{|\mathcal{C}|}\}\) so that \(\widetilde{\theta}_{i_{1}}<\ldots<\widetilde{\theta}_{i_{|\mathcal{C}|}}\). Observe that for \(0<h<\delta\) for \(\delta>0\) sufficiently small, \(\widetilde{\theta}_{i_{j-1}}<\widetilde{\theta}_{j}+h<\widetilde{\theta}_{i_{ j+1}}\) because \(\widetilde{\theta}_{i_{j-1}}<\widetilde{\theta}_{j}<\widetilde{\theta}_{i_{j+1}}\) by Lemma 5 and H3. Hence, the bid ordering does not change for any infinitesimal variation \(\mathrm{d}\widetilde{\theta}_{j}>0\), nor does the indicator \(\mathbb{1}\{i_{j}\leqslant i_{|\mathcal{C}|}\}\). Consequently by Corollary 1, \(n_{j}^{\star}(\widetilde{\mathbf{\theta}})\) is differentiable in \(\widetilde{\theta}_{j}\) and so is \(\lambda^{\star}(\widetilde{\mathbf{\theta}})\). We have for any \(j\in\mathcal{C}\):

\[\frac{\partial v_{j}((1,\widetilde{\theta}_{j}),\mathbf{s}_{k})}{ \partial\widetilde{\theta}_{j}} =2a\frac{\partial q_{j}(\widetilde{\theta}_{j},\widetilde{\mathbf{ \theta}}_{-j})}{\partial\widetilde{\theta}_{j}}\] \[=2a\sum_{k\in\mathcal{C}\setminus\{j\}}\left[\frac{\partial \lambda_{k}^{\star}(\widetilde{\mathbf{\theta}})}{\partial\widetilde{\theta}_{j}} \Big{(}\Big{(}\theta_{j}-\widetilde{\theta}_{j}\Big{)}-\Big{(}\theta_{k}- \widetilde{\theta}_{k}\Big{)}\Big{)}-\lambda_{k}^{\star}(\widetilde{\mathbf{\theta }})\right]\] \[=2a\sum_{k\in\mathcal{C}\setminus\{j\}}\frac{\partial\lambda_{k}^ {\star}(\widetilde{\mathbf{\theta}})}{\partial\widetilde{\theta}_{j}}(\Delta- \Delta)-2a\sum_{k\in\mathcal{C}\setminus\{j\}}\lambda_{k}^{\star}(\widetilde{ \mathbf{\theta}}) \tag{60}\] \[<0. \tag{61}\]

where we have used Lemma 5 at the third line. This implies

\[\widetilde{\theta}_{j}=\underline{\theta}\qquad\text{for any }j\in\mathcal{C}. \tag{62}\]

To see why, assume by contradiction that there exists \(j\in\mathcal{C}\) such that \(s_{j}=(1,\widetilde{\theta}_{j})\) with \(\widetilde{\theta}_{j}>\underline{\theta}\). Then for any \(h\in(0,\widetilde{\theta}_{j}-\underline{\theta}]\), by (61):

\[v_{j}((1,\widetilde{\theta}_{j}-h),\mathbf{s}_{-j})=v_{j}((1,\widetilde{ \theta}_{j}),\mathbf{s}_{-j})-\int_{\widetilde{\theta}_{j}-h}^{\widetilde{ \theta}_{j}}\frac{\partial v_{j}((1,t),\mathbf{s}_{k})}{\partial t}dt>v_{j}((1,\widetilde{\theta}_{j}),\mathbf{s}_{k})\,\]

which contradicts \(\mathbf{s}\) being a Nash equilibrium. 

Combining Lemma 5 and Lemma 6 gives for any \((j,k)\in\mathcal{C}^{2}\):

\[\theta_{j}=\theta_{k}. \tag{63}\]

Recall that by H3, \(\theta_{m}=\theta_{n}\) if and only if \(m=n\), so (63) implies \(|\mathcal{C}|=1\). This in turn implies \(|\mathcal{B}|=1\). Indeed, assume by contradiction \(|\mathcal{C}|=1\) and \(|\mathcal{B}|\geqslant 2\). Denote \(r\in\mathcal{B}\) the only contributing agent. They are asked \(n_{r}^{\star}(\widetilde{\mathbf{\theta}})=\overline{n}_{r}(\widetilde{\mathbf{\theta }})=\underline{n}\). Moreover by (19) \(\bar{N}=\left|\mathcal{B}\right|^{1/1+\gamma}(\underline{n}+1)-1>\underline{n}\), so by definition of the contribution scheme (12), there exists \(k\in\mathcal{B}\setminus\{r\}\) such that \(n_{k}^{\star}(\widetilde{\mathbf{\theta}})>0\). This contradicts \(|\mathcal{C}|=1\).

We now show that \(\mathcal{B}=\{J\}\). By contradiction, assume \(\mathcal{B}=\{j\}\) with \(j<J\). In particular, \(s_{J}=(0,\dagger)\). Consider a deviation \(s_{J}^{\prime}=(1,\widetilde{\theta}_{J})\) with \(\widetilde{\theta}_{J}\in\Theta\), so \(\mathcal{B}=\{j,J\}\) under \((s_{J}^{\prime},\mathbf{s}_{-J})\). By Lemma 6, \(\widetilde{\theta}_{j}=\widetilde{\theta}_{J}=\underline{\theta}\), so (58) rewrites:

\[v_{k}((1,\widetilde{\theta}_{k}),\mathbf{s}_{-k})=\underline{u}_{k}+2a(\theta_ {k}-\vartheta(\mathsf{B},\mathbf{n}^{\star}(\widetilde{\mathbf{\theta}}))\, \tag{64}\]

for any \(k\in\{j,J\}\). Since \(\theta_{j}<\vartheta(\mathsf{B},\mathbf{n}^{\star}(\widetilde{\mathbf{\theta}}))< \theta_{J}\) by H3, we have

\[v_{J}((1,\widetilde{\theta}_{J}),\mathbf{s}_{-J})>\underline{u}_{J}=v_{J}((0, \dagger),\mathbf{s}_{-J})\,\]

which contradicts \(\mathbf{s}\) begin a Nash equilibrium. Hence, \(\mathcal{B}=\{J\}\). This concludes the proof. 

**Lemma 3**.: _There exists \(j\in[J]\) such that \(-t_{j}(\widetilde{\mathbf{\theta}})>0\)._

Proof.: Let \((\mathsf{B},\widetilde{\mathbf{\theta}})\in\{0,1\}^{J}\times\Theta^{N}\) be an equilibrium of the game induced by \(\Gamma^{\mathrm{VCG}}\). Since the VCG mechanism is strategyproof in dominant strategy, \(\widetilde{\mathbf{\theta}}=\mathbf{\theta}\). For any \(j\in[J]\), the VCG payment is

\[t_{j}(\widetilde{\mathbf{\theta}}) =\sum_{k\neq j}u_{k}((0,\mathbf{1}_{-j}),\mathbf{n}^{\star}( \mathbf{\theta}))-\sum_{k\neq j}u_{k}(\mathbf{1},\mathbf{n}^{\star}(\mathbf{\theta}))\] \[=\underbrace{W((0,\mathbf{1}_{-j}),\mathbf{n}^{\star}(\mathbf{\theta} ))-W(\mathbf{1},\mathbf{n}^{\star}(\mathbf{\theta}))}_{(\mathbf{I})}-[\underbrace{u_ {j}((0,\mathbf{1}_{-j}),\mathbf{n}^{\star}(\mathbf{\theta}))-u_{j}(\mathbf{1}, \mathbf{n}^{\star}(\mathbf{\theta}))}_{(\mathbf{II})}]. \tag{65}\]

[MISSING_PAGE_EMPTY:23]

**Proposition 2**.: _Assume **H1**, **H2** and **H6**. For any \(j\in[J]\) the estimator_

\[\widehat{\theta}^{\text{\tiny\rm\sc REM}}_{0,j}=\sup_{g\in\mathscr{G}}|\widehat{ \mathcal{R}}_{j}(g)-\widehat{\mathcal{R}}_{0}(g)|\;,\]

_satisfies **H5** with_

\[\eta_{\delta}(q)=\alpha_{\delta/4}\big{[}(q+1)^{-\gamma}+(q^{\prime}+1)^{- \gamma}\big{]}+2\beta\;. \tag{13}\]

Proof.: Let \(j\in[J]\) and \(g\in\mathscr{G}\), we have

\[\widehat{\theta}^{\text{\tiny\rm\sc REM}}_{0,j} =\sup_{g\in\mathscr{G}}\bigl{|}\widehat{\mathcal{R}}_{j}(g)- \widehat{\mathcal{R}}_{0}(g)\bigr{|}\] \[\leqslant\sup_{g\in\mathscr{G}}\bigl{|}\widehat{\mathcal{R}}_{j }(g)-\mathcal{R}_{j}(g)\bigr{|}+\sup_{g\in\mathscr{G}}\bigl{|}\mathcal{R}_{j} (g)-\mathcal{R}_{0}(g)\bigr{|}+\sup_{g\in\mathscr{G}}\bigl{|}\widehat{\mathcal{ R}}_{0}(g)-\mathcal{R}_{0}(g)\bigr{|}\] \[\leqslant\alpha_{\delta/4}\big{[}(q+1)^{-\gamma}+(q^{\prime}+1) ^{-\gamma}\big{]}+2\beta+\theta_{j}\;, \tag{69}\]

with probability \(1-\delta/2\) by **H2**, **H1**, **H6**, and a union bound. Similarly,

\[\theta_{j} =\sup_{g\in\mathscr{G}}\bigl{|}\mathcal{R}_{j}(g)-\mathcal{R}_{0} (g)\bigr{|}\] \[\leqslant\alpha_{\delta/4}\big{[}(q+1)^{-\gamma}+(q^{\prime}+1)^{ -\gamma}\big{]}+2\beta+\widehat{\theta}^{\text{\tiny\rm\sc REM}}_{0,j}\;, \tag{70}\]

with probability \(1-\delta/2\). Combining (68) and (70) along with an union bound yields

\[|\widehat{\theta}^{\text{\tiny\rm\sc REM}}_{0,j}-\theta_{j}|\leqslant\alpha_{ \delta/4}\big{[}(q+1)^{-\gamma}+(q^{\prime}+1)^{-\gamma}\big{]}+2\beta\;,\]

with probability \(1-\delta\). 

**Example 4**.: _Assume **H1**, **H2**, **H6** and **H7**._

1. _Denoting_ \(\widehat{\mathcal{R}}_{j^{-}}(g)=n_{j}^{-1}\sum_{i=1}^{n_{j}}\ell_{0,1}(g(X_{ i}^{j}),-Y_{i}^{j})\)_, we have_ \[\widehat{\theta}^{\text{\tiny\rm\sc REM}}_{0,j}-\theta_{j}|\leqslant\alpha_{ \delta/4}\big{[}(q+1)^{-\gamma}+(q^{\prime}+1)^{-\gamma}\big{]}+2\beta\;,\]
2. _In_ **H1**_, assume_ \(\alpha_{\delta}=\ln(1/\delta)^{1/2}\)_,_ \(\beta=2\text{\rm RAD}(\mathscr{G})\) _and_ \(\gamma=1\)___[_10_]__. With_ \(\widehat{\theta}^{\text{\tiny\rm\sc REM}}_{0,j}\) _defined in Proposition_ 2_, we have_ \[\eta_{\delta/J}(q)=\ln(4J/\delta)^{1/2}[(1+q)^{-\gamma}+(1+q^{\prime})^{- \gamma}]+2\text{\rm Rad}(\mathscr{G})\;.\]

Proof.:
1. Let \(j\in\mathcal{B}\). Observe that under **H7**,we have \[\widehat{\mathcal{R}}_{j}(-g)=n_{j}^{-1}\sum_{i=1}^{n_{j}}\mathbb{1}\{-g(X_{ i}^{j})Y_{i}^{j}<0\}=n_{j}^{-1}\sum_{i=1}^{n_{j}}(1-\mathbb{1}\{g(X_{i}^{j})Y_{i}^ {j}<0\})=1-\widehat{\mathcal{R}}_{j}(g)\;.\] Since the hypothesis class \(\mathscr{G}\) is symmetric, we have \[\widehat{\theta}^{\text{\tiny\rm\sc REM}}_{j} =\sup_{g\in\mathscr{G}}\bigl{|}\widehat{\mathcal{R}}_{j}(g)- \widehat{\mathcal{R}}_{0}(g)\bigr{|}=\sup_{g\in\mathscr{G}}\Bigl{(}\widehat{ \mathcal{R}}_{j}(g)-\widehat{\mathcal{R}}_{0}(g)\Bigr{)}\] \[=\sup_{g\in\mathscr{G}}\Bigl{(}1-\Bigl{(}\widehat{\mathcal{R}}_{ j}(-g)+\widehat{\mathcal{R}}_{0}(g)\Bigr{)}\Bigr{)}=1-\inf_{g\in\mathscr{G}}\Bigl{(} \widehat{\mathcal{R}}_{j^{-}}(g)+\widehat{\mathcal{R}}_{0}(g)\Bigr{)}\;.\]
2. Let \(j\in[J]\), we have \[\eta_{\delta/J}(q) =\alpha_{\delta/4J}[(q+1)^{-\gamma}+(1+q^{\prime})^{-\gamma}]+2\beta\] \[=\ln(4J/\delta)^{1/2}[(1+q)^{-\gamma}+(1+q^{\prime})^{-\gamma}]+2 \text{\rm Rad}(\mathscr{G})\;.\]

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: the claimed contributions are supported by proven theorems. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: all the made assumptions are clearly highlighted and discussed. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes]Justification: Assumptions are made clear and given for each theorem individually. Full proofs are given in the Appendix. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [NA] Justification: no experimental result in the paper Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?Answer: [NA] Justification: no experimental result in the paper Guidelines:

* The answer NA means that paper does not include experiments requiring code.
* Please see the NeurIPS code and data submission guidelines ([https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy)) for more details.
* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines ([https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy)) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [NA] Justification: no experimental result in the paper Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [NA] Justification: no experimental result in the paper Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors). * It should be clear whether the error bar is the standard deviation or the standard error of the mean.

* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [NA] Justification: no experimental result in the paper Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics [https://neurips.cc/public/EthicsGuidelines?](https://neurips.cc/public/EthicsGuidelines?) Answer: [Yes] Justification: no data used for this work Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: no societal impact of the work performed Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. * If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: no data Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [NA] Justification: no existing assets Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. * If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets?Answer: [NA] Justification: no new asset Guidelines:

* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: no crowdsourcing nor research with human subjects Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: no crowdsourcing nor research with human subjects Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.