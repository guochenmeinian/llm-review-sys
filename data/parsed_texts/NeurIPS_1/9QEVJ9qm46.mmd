# Robust Learning with Progressive Data Expansion

Against Spurious Correlation

Yihe Deng Yu Yang1 Baharan Mirzasoleiman Quanquan Gu

Department of Computer Science

University of California, Los Angeles

Los Angeles, CA 90095

{yihedeng,yuyang,baharan,qgu}@cs.ucla.edu

Equal contribution

Footnote 1: footnotemark:

###### Abstract

While deep learning models have shown remarkable performance in various tasks, they are susceptible to learning non-generalizable _spurious features_ rather than the core features that are genuinely correlated to the true label. In this paper, beyond existing analyses of linear models, we theoretically examine the learning process of a two-layer nonlinear convolutional neural network in the presence of spurious features. Our analysis suggests that imbalanced data groups and easily learnable spurious features can lead to the dominance of spurious features during the learning process. In light of this, we propose a new training algorithm called **PDE** that efficiently enhances the model's robustness for a better worst-group performance. PDE begins with a group-balanced subset of training data and progressively expands it to facilitate the learning of the core features. Experiments on synthetic and real-world benchmark datasets confirm the superior performance of our method on models such as ResNets and Transformers. On average, our method achieves a \(2.8\%\) improvement in worst-group accuracy compared with the state-of-the-art method, while enjoying up to \(10\times\) faster training efficiency. Codes are available at [https://github.com/uclaml/PDE](https://github.com/uclaml/PDE).

## 1 Introduction

Despite the remarkable performance of deep learning models, recent studies (Sagawa et al., 2019, 2020; Izmailov et al., 2022; Haghtalab et al., 2022; Yang et al., 2022, 2023b, c) have identified their vulnerability to spurious correlations in data distributions. A spurious correlation refers to an easily learned feature that, while unrelated to the task at hand, appears with high frequency within a specific class. For instance, waterbirds frequently appear with water backgrounds, and landbirds with land backgrounds. When training with empirical risk minimization (ERM), deep learning models tend to exploit such correlations and fail to learn the more subtle features genuinely correlated with the true labels, resulting in poor generalization performance on minority data (e.g., waterbirds with land backgrounds as shown in Figure 1). This observation raises a crucial question: _Does the model genuinely learn to classify birds, or does it merely learn to distinguish land from water?_ The issue is particularly concerning because deep learning models are being deployed in critical applications such as healthcare, finance, and autonomous vehicles, where we require a reliable predictor.

Researchers formalized the problem by considering examples with various combinations of core features (e.g., landbird/waterbird) and spurious features (e.g., land/water backgrounds) as different _groups_. The model is more likely to make mistakes on certain groups if it learns the spurious feature. The objective therefore becomes balancing and improving performance across all groups. Under this formulation, we can divide the task into two sub-problems: (1) accurately identifying the groups, which are not always known in a dataset, and (2) effectively using the group informationto finally improve the model's robustness. While numerous recent works (Nam et al., 2020; Liu et al., 2021; Creager et al., 2021; Ahmed et al., 2021; Taghanaki et al., 2021; Zhang et al., 2022) focus on the first sub-problem, the second sub-problem remains under studied. The pioneering work (Sagawa et al., 2019) still serves as the best guidance for utilizing accurate group information. In this paper, we focus on the second sub-problem and aim to provide a more effective and efficient algorithm to utilize the group information. It is worth noting that the theoretical understanding of spurious correlations lags behind the empirical advancements of mitigating spurious features. Existing theoretical studies (Sagawa et al., 2020; Chen et al., 2020; Yang et al., 2022; Ye et al., 2022) are limited to the setting of simple linear models and data distribution that are less reflective of real application scenarios.

We begin by theoretically examining the learning process of spurious features when training a two-layer nonlinear convolutional neural network (CNN) on a corresponding data model that captures the influence of spurious correlations. We illustrate that the learning of spurious features swiftly overshadows the learning of core features from the onset of training when groups are imbalanced and spurious features are more easily learned than core features. Based upon our theoretical understanding, we propose Progressive Data Expansion (**PDE**), a neat and novel training algorithm that efficiently uses group information to enhance model's robustness against spurious correlations. Existing approaches, such as GroupDRO (Sagawa et al., 2019) and upsampling techniques (Liu et al., 2021), aim to balance the data groups in each batch throughout the training process. In contrast, we employ a small balanced warm-up subset only at the beginning of the training. Following a brief period of balanced training, we progressively expand the warm-up subset by adding small random subsets of the remaining training data until using all of them, as shown in the top right of Figure 1. Here, we utilize the momentum from the warm-up subset to prevent the model from learning spurious features when adding new data. Empirical evaluations on both synthetic and real-world benchmark data validate our theoretical findings and confirm the effectiveness of PDE. Additional ablation studies also demonstrate the significance and impact of each component within our training scheme. In summary, our contributions are highlighted as follows:

* We provide a theoretical understanding of the impact of spurious correlations beyond the linear setting by considering a two-layer nonlinear CNN.
* We introduce PDE, a theory-inspired approach that effectively addresses the challenge posed by spurious correlations.
* PDE achieves the best performance on benchmark vision and language datasets for models including ResNet and Transformer. On average, it outperforms the state-of-the-art method by \(2.8\%\) in terms of worst-group accuracy.
* PDE enjoys superior training efficiency, being \(10\times\) faster than the state-of-the-art methods.

Figure 1: A overview of the problem, our proposed solution, and the resultant outcomes. (A) We demonstrate the data distribution and provide an example of the statistics of Waterbirds. (B) The overall procedure of PDE. (C) we use GradCAM (Selvaraju et al., 2017) to show the attention of the model trained with PDE as compared to ERM. While ERM focuses on the background, PDE successfully trains the model to capture the birds.

Why is Spurious Correlation Harmful to ERM?

In this section, we simplify the intricate real-world problem of spurious correlations into a theoretical framework. We provide analysis on two-layer nonlinear CNNs, extending beyond the linear setting prevalent in existing literature on this subject. Under this framework, we formally present our theory concerning the training process of empirical risk minimization (ERM) in the presence of spurious features. These theoretical insights motivate the design of our algorithm.

### Empirical Risk Minimization

We begin with the formal definition of the ERM-based training objective for a binary classification problem. Consider a training dataset \(S=\{(\mathbf{x}_{i},y_{i})\}_{i=1}^{N}\), where \(\mathbf{x}_{i}\in\mathbb{R}^{d}\) is the input and \(y\in\{\pm 1\}\) is the output label. We train a model \(f(\mathbf{x};\mathbf{W})\) with weight \(\mathbf{W}\) to minimize the empirical loss function:

\[\mathcal{L}(\mathbf{W})=\frac{1}{N}\sum_{i=1}^{N}\ell\big{(}y_{i}f(\mathbf{x}_ {i};\mathbf{W})\big{)}, \tag{2.1}\]

where \(\ell\) is the logistic loss defined as \(\ell(z)=\log(1+\exp(-z))\). The empirical risk minimizer refers to \(\mathbf{W}^{*}\) that minimizes the empirical loss: \(\mathbf{W}^{*}\coloneqq\operatorname*{argmin}_{\mathbf{W}}\mathcal{L}(\mathbf{ W})\). Typically, gradient-based optimization algorithms are employed for ERM. For example, at each iteration \(t\), gradient descent (GD) has the following update rule:

\[\mathbf{W}^{(t+1)}=\mathbf{W}^{(t)}-\eta\nabla\mathcal{L}(\mathbf{W}^{(t)}). \tag{2.2}\]

Here, \(\eta>0\) is the learning rate. In the next subsection, we will show that even for a relatively simple data model which consists of core features and spurious features, vanilla ERM will fail to learn the core features that are correlated to the true label.

### Data Distribution with Spurious Correlation Fails ERM

Previous work such as (Sagawa et al., 2020) considers a data model where the input consists of core feature, spurious feature and noise patches at fixed positions, i.e., \(\mathbf{x}=[\mathbf{x}_{\text{core}},\mathbf{x}_{\text{sgu}},\mathbf{x}_{\text {noise}}]\). In real-world applications, however, features in an image do not always appear at the same pixels. Hence, we consider a more realistic data model where the patches do not appear at fixed positions.

**Definition 2.1** (Data model).: A data point \((\mathbf{x},y,a)\in(\mathbb{R}^{d})^{P}\times\{\pm 1\}\times\{\pm 1\}\) is generated from the distribution \(\mathcal{D}\) as follows.

* Randomly generate the true label \(y\in\{\pm 1\}\).
* Generate spurious label \(a\in\{\pm y\}\), where \(a=y\) with probability \(\alpha>0.5\).
* Generate \(\mathbf{x}\) as a collection of \(P\) patches: \(\mathbf{x}=(\mathbf{x}^{(1)},\mathbf{x}^{(2)},\dots,\mathbf{x}^{(P)})\in( \mathbb{R}^{d})^{P}\), where
* **Core feature.*
* One and only one patch is given by \(\beta_{c}\cdot y\cdot\mathbf{v}_{c}\) with \(\|\mathbf{v}_{c}\|_{2}=1\).
* **Spurious feature.*
* One and only one patch is given by \(\beta_{s}\cdot a\cdot\mathbf{v}_{s}\) with \(\|\mathbf{v}_{s}\|_{2}=1\) and \(\langle\mathbf{v}_{c},\mathbf{v}_{s}\rangle=0\).
* **Random noise.*
* The rest of the \(P-2\) patches are Gaussian noises \(\mathbf{\xi}\) that are independently drawn from \(N(0,(\sigma_{p}^{2}/d)\cdot\mathbf{I}_{d})\) with \(\sigma_{p}\) as an absolute constant. And \(0<\beta_{c}\ll\beta_{s}\in\mathbb{R}\).

Similar data models have also been considered in recent works on feature learning (Allen-Zhu and Li, 2020; Zou et al., 2021; Chen et al., 2022; Jelassi and Li, 2022), where the input data is partitioned into feature and noise patches. We extend their data models by further positing that certain feature patches might be associated with the spurious label instead of the true label. In the rest of the paper, we assume \(P=3\) for simplicity. With the given data model, we consider the training dataset \(S=\{(\mathbf{x}_{i},y_{i},a_{i})\}_{i=1}^{N}\) and let \(S\) be partitioned into large group \(S_{1}\) and small group \(S_{2}\) such that \(S_{1}\) contains all the training data that can be correctly classified by the spurious feature, i.e., \(a_{i}=y_{i}\), and \(S_{2}\) contains all the training data that can only be correctly classified by the core feature, i.e., \(a_{i}=-y_{i}\). We denote \(\widehat{\alpha}=\frac{|S_{1}|}{N}\) and therefore \(1-\widehat{\alpha}=\frac{|S_{2}|}{N}\).

Visualization of our data.In Figure 2, we present the visualization in \(2\)D space of the higher-dimensional data generated from our data model using t-SNE (Van der Maaten and Hinton, 2008), where data within each class naturally segregate into large and small groups. The spurious feature is sufficient for accurate classification of the larger group data, but will lead to misclassification of the small group data.

Figure 2: Visualization of the data.

### Beyond Linear Models

We consider a two-layer nonlinear CNN defined as follows:

\[f(\mathbf{x};\mathbf{W})=\sum_{j\in[J]}\sum_{p=1}^{P}\sigma\big{(}\langle\mathbf{w }_{j},\mathbf{x}^{(p)}\rangle\big{)}, \tag{2.3}\]

where \(\mathbf{w}_{j}\in\mathbb{R}^{d}\) is the weight vector of the \(j\)-th filter, \(J\) is the number of filters (neurons) of the network, and \(\sigma(z)=z^{3}\) is the activation function. \(\mathbf{W}=[\mathbf{w}_{1},\ldots,\mathbf{w}_{J}]\in\mathbb{R}^{d\times J}\) denotes the weight matrix of the CNN. Similar two-layer CNN architectures are analyzed in in (Chen et al., 2022; Jelassi and Li, 2022) but for different problems, where the cubic activation serves a simple function that provides non-linearity. Similar to Jelassi and Li (2022); Cao et al. (2022), we assume a mild overparameterization of the CNN with \(J=\text{polylog}(d)\). We initialize \(\mathbf{W}^{(0)}\sim\mathcal{N}(0,\sigma_{0}^{2})\), where \(\sigma_{0}^{2}=\frac{\text{polylog}(d)}{d}\). Due to the CNN structure, our analysis can handle data models where each data can have arbitrary order of patches while linear models fail to do so.

### Understanding the Training Process with Spurious Correlation

In this subsection, we formally introduce our theoretical result on the training process of the two-layer CNN using gradient descent in the presence of spurious features. We first define the performance metrics. A frequently considered metric is the test accuracy: \(\text{Acc}(\mathbf{W})=\mathbb{P}_{(\mathbf{x},y,a)\sim D}\big{[}\text{sgn}(f (\mathbf{x};\mathbf{W}))=y\big{]}\). With spurious correlations, researchers are more interested in the worst-group accuracy:

\[\text{Acc}_{\text{wg}}(\mathbf{W})=\min_{y\in\{\pm 1\},a\in\{\pm 1\}}\mathbb{P}_{( \mathbf{x},y,a)\sim\mathcal{D}}\big{[}\text{sgn}(f(\mathbf{x};\mathbf{W}))=y \big{]},\]

which accesses the worst accuracy of a model among all groups defined by combinations of \(y\) and \(a\). We then summarize the learning process of ERM in the following theorem. Our analysis focuses on the learning of spurious and core features, represented by the growth of \(\langle\mathbf{w}_{i}^{(t)},\mathbf{v}_{s}\rangle\) and \(\langle\mathbf{w}_{i}^{(t)},\mathbf{v}_{c}\rangle\) respectively:

**Theorem 2.2**.: Consider the training dataset \(S=\{(\mathbf{x}_{i},y_{i})\}_{i=1}^{N}\) that follows the distribution in Definition 2.1. Consider the two-layer nonlinear CNN model as in (2.3) initialized with \(\mathbf{W}^{(0)}\sim\mathcal{N}(0,\sigma_{0}^{2})\). After training with GD in (2.2) for \(T_{0}=\widetilde{\Theta}\big{(}1/(\eta\beta_{s}^{3}\sigma_{0})\big{)}\) iterations, for all \(j\in[J]\) and \(t\in[0,T_{0})\), we have

\[\widetilde{\Theta}(\eta)\beta_{s}^{3}(2\widehat{\alpha}-1)\cdot \langle\mathbf{w}_{j}^{(t)},\mathbf{v}_{s}\rangle^{2} \leq\langle\mathbf{w}_{j}^{(t+1)},\mathbf{v}_{s}\rangle-\langle \mathbf{w}_{j}^{(t)},\mathbf{v}_{s}\rangle\leq\widetilde{\Theta}(\eta)\beta_{s }^{3}\widehat{\alpha}\cdot\langle\mathbf{w}_{j}^{(t)},\mathbf{v}_{s}\rangle^{2}, \tag{2.4}\] \[\widetilde{\Theta}(\eta)\beta_{c}^{3}\widehat{\alpha}\cdot\langle \mathbf{w}_{j}^{(t)},\mathbf{v}_{c}\rangle^{2} \leq\langle\mathbf{w}_{j}^{(t+1)},\mathbf{v}_{c}\rangle-\langle \mathbf{w}_{j}^{(t)},\mathbf{v}_{c}\rangle\leq\widetilde{\Theta}(\eta)\beta_{ c}^{3}\cdot\langle\mathbf{w}_{j}^{(t)},\mathbf{v}_{c}\rangle^{2}. \tag{2.5}\]

After training for \(T_{0}\) iterations, with high probability, the learned weight has the following properties: (1) it learns the spurious feature \(\mathbf{v}_{s}\): \(\max_{j\in[J]}\langle\mathbf{w}_{j}^{(T)},\mathbf{v}_{s}\rangle\geq\widetilde {\Omega}(1/\beta_{s})\); (2) it _almost_ does not learn the core feature \(\mathbf{v}_{c}\): \(\max_{j\in[J]}\langle\mathbf{w}_{j}^{(T)},\mathbf{v}_{c}\rangle=\widetilde{ \mathcal{O}}(\sigma_{0})\).

Discussion.The detailed proof is deferred to Appendix E, and we provide intuitive explanations of the theorem as follows. A larger value of \(\langle\mathbf{w}_{i}^{(t)},\mathbf{v}\rangle\) for \(\mathbf{v}\in\{\mathbf{v}_{s},\mathbf{v}_{c}\}\) implies better learning of the feature vector \(\mathbf{v}\) by neuron \(\mathbf{w}_{i}\) at iteration \(t\). As illustrated in (2.4) and (2.5), the updates for both spurious and core features are non-zero, as they depend on the squared terms of themselves with non-zero coefficients, while the growth rate of \(\langle\mathbf{w}_{i}^{(t)},\mathbf{v}_{s}\rangle\) is significantly faster than that of \(\langle\mathbf{w}_{i}^{(t)},\mathbf{v}_{c}\rangle\). Consequently, the neural network rapidly learns the spurious feature but barely learns the core feature, as it remains almost unchanged from initialization.

We derive the neural network's prediction after training for \(T_{0}\) iterations. For a randomly generated data example \((\mathbf{x},y,a)\sim\mathcal{D}\), the neural network's prediction is given by \(\text{sgn}\big{(}f(\mathbf{x};\mathbf{W})\big{)}=\text{sgn}\big{(}\sum_{j\in[J] }\big{(}y\beta_{c}^{3}\langle\mathbf{w}_{j},\mathbf{v}_{c}\rangle^{3}+a\beta_ {s}^{3}\langle\mathbf{w}_{j},\mathbf{v}_{s}\rangle^{3}+\langle\mathbf{w}_{j},\xi\rangle^{3}\big{)}\). Since the term \(\beta_{s}^{3}\max_{j\in[J]}\langle\mathbf{w}_{j},\mathbf{v}_{s}\rangle^{3}\) dominates the summation, the prediction will be \(\text{sgn}(f(\mathbf{x};\mathbf{W}))=a\). Consequently, we obtain the test accuracy as \(\text{Acc}(\mathbf{W})=\alpha\), since \(a=y\) with probability \(\alpha\), and the model accurately classifies the large group. However, when considering the small group and examining examples where \(y\neq a\), the models consistently make errors, resulting in \(\text{Acc}_{wg}(\mathbf{W})=0\). To circumvent this poor performance on worst-group accuracy, an algorithm that can avoid learning the spurious feature is in demand.

## 3 Theory-Inspired Two-Stage Training Algorithm

In this section, we introduce Progressive Data Expansion (PDE), a novel two-stage training algorithm inspired by our analysis to enhance robustness against spurious correlations. We begin with illustrating

[MISSING_PAGE_FAIL:5]

As accelerated gradient methods are most commonly used in applications, we jointly consider the property of momentum and our theoretical insights when designing the algorithm. For gradient descent with momentum (GD+M), at each iteration \(t\) and with momentum coefficient \(\gamma>0\), it updates as follows

\[\mathbf{g}^{(t+1)} =\gamma\mathbf{g}^{(t)}+(1-\gamma)\nabla\mathcal{L}(\mathbf{W}^{(t )}), \tag{3.1}\] \[\mathbf{W}^{(t+1)} =\mathbf{W}^{(t)}-\eta\cdot\mathbf{g}^{(t+1)}, \tag{3.2}\]

Warm-up Stage.In this stage, we create a fully balanced dataset \(S^{0}\), in which each group is randomly subsampled to match the size of the smallest group, and consider it as a warm-up dataset. We train the model on the warm-up dataset for a fixed number of epochs. During this phase, the model is anticipated to accurately learn the core feature without being influenced by the spurious feature. Note that, under our data model, a completely balanced dataset will have \(\widehat{\alpha}=1/2\). We present the following lemma as a theoretical basis for the warm-up stage.

**Lemma 3.1**.: Given the balanced training dataset \(S^{0}=\{(\mathbf{x}_{i},y_{i},a_{i})\}_{i=1}^{N_{0}}\) with \(\widehat{\alpha}=1/2\) as in Definition 2.1 and CNN as in (2.3). The gradient on \(\mathbf{v}_{s}\) will be \(0\) from the beginning of training.

In particular, with \(\widehat{\alpha}=1/2\) we have \(|S^{0}_{1}|=|S^{0}_{2}|\): an equal amount of data is positively correlated with the spurious feature as the data negatively correlated with the spurious feature. In each update, both groups contribute nearly the same amount of spurious feature gradient with different signs, resulting in cancellation. Ultimately, this prevents the model from learning the spurious feature. Detailed proofs can be found in Appendix F.

Expansion Stage.In this stage, we proceed to train the model by incrementally incorporating new data into the training dataset. The rationale for this stage is grounded in the theoretical result by the previous work (Jelassi and Li, 2022) on GD with momentum, which demonstrates that once gradient descent with momentum initially increases its correlation with a feature \(\mathbf{v}\), it retains a substantial historical gradient in the momentum containing \(\mathbf{v}\). Put it briefly, the initial learning phase has a considerable influence on subsequent training for widely-used accelerated training algorithms. While ERM learns the spurious feature \(\mathbf{v}_{s}\) and momentum does not help, as we will show in synthetic experiments, PDE avoids learning \(\mathbf{v}_{s}\) and learns \(\mathbf{v}_{c}\) in the warm-up stage. This momentum from warm-up, in turn, amplifies the core feature that is present in the gradients of newly added data, facilitating the continued learning of \(\mathbf{v}_{c}\) in the expansion stage. For a specific illustration, the learning of the core feature by GD+M will be

\[\langle\mathbf{w}_{j}^{(t+1)},\mathbf{v}_{c}\rangle=\langle\mathbf{w}_{j}^{(t) }-\eta\big{(}\gamma g^{(t)}+(1-\gamma)\nabla_{\mathbf{w}_{j}}\mathcal{L}( \mathbf{W}^{(t)})\big{)},\mathbf{v}_{c}\rangle,\]

where \(g^{(t)}\) is the additional momentum as compared to GD with \(\gamma=0\). While the current gradient along \(\mathbf{v}_{c}\) might be small (i.e., \(\beta_{c}\)), we can benefit from the historical gradient in \(g^{(t)}\) to amplify the growth of \(\langle\mathbf{w}_{j}^{(t+1)},\mathbf{v}_{c}\rangle\) and make it larger than that of the spurious feature (i.e., \(\beta_{s}\)). This learning process will then correspond to the case when the model learns the core feature discussed in Subsection 3.1. Practically, we consider randomly selecting \(m\) new examples for expansion every \(J\) epochs by attempting to draw a similar number of examples from each group. During the last few epochs of the expansion stage, we expect the newly incorporated data exclusively from the larger group, as the smaller groups have been entirely integrated into the warm-up dataset.

It is worth noting that while many works address the issue of identifying groups from datasets containing spurious correlations, we assume the group information is known and our algorithm focuses on the crucial subsequent question of optimizing group information utilization. Aiming to prevent the learning of spurious features, PDE distinguishes itself by employing a rapid and lightweight warm-up stage and ensuring continuous improvement during the expansion stage with the momentum acquired from the warm-up dataset. Our training framework is both concise and effective, resulting in computational efficiency and ease of implementation.

## 4 Experiments

In this section, we present the experiment results from both synthetic and real datasets. Notably, we report the worst-group accuracy, which assesses the minimum accuracy across all groups and is commonly used to evaluate the model's robustness against spurious correlations.
In this section, we present synthetic experiment results in verification to our theoretical findings. In Appendix A, we illustrate the detailed data distribution, hyper-parameters of the experiments and more extensive experiment results. The data used in this section is generated following Definition 2.1. We consider the worst-group and overall test accuracy. As illustrated in Table 1, ERM, whether trained with GD or GD+M, is unable to accurately predict the small group in our specified data distribution where \(\widehat{\alpha}=0.98\) and \(\beta_{c}<\beta_{s}\). In contrast, our method significantly improves worst-group accuracy while maintaining overall test accuracy comparable to ERM. Furthermore, as depicted in Figure 3(a), ERM rapidly learns the spurious feature as it minimizes the training loss, while barely learning the core feature. Meanwhile, in Figure 3(b) we show the learning of ERM when the data distribution breaks the conditions of our theory and has \(\beta_{c}>\beta_{s}\) instead. Even with the same \(\widehat{\alpha}\) as in Figure 3(a), ERM correctly learns the core feature despite the imbalanced group size. These two figures support the theoretical results we discussed to motivate our method. Consequently, on the same training dataset as in Figure 3(a), Figure 3(c) shows that our approach allows the model to initially learn the core feature using the warm-up dataset and continue learning when incorporating new data.

### Real Data

We conduct experiments on real benchmark datasets to: (1) compare our approach with state-of-the-art methods, highlighting its superior performance and efficiency, and (2) offer insights into the design of our method through ablation studies.

**Datasets.** We evaluate on three wildly used datasets across vision and language tasks for spurious correlation: (1) **Waterbirds**(Sagawa et al., 2019) contains bird images labeled as waterbird or landbird, placed against a water or land background, where the smallest subgroup is waterbirds on land background. (2) **CelebA**(Liu et al., 2015) is used to study gender as the spurious feature for hair color classification, and the smallest group in this task is blond-haired males. (3) **CivilComments-WILDS**(Koh et al., 2021) classifies toxic and non-toxic online comments while dealing with demographic information. It creates \(16\) overlapping groups for each of the \(8\) demographic identities.

**Baselines.** We compare our proposed algorithm against several state-of-the-art methods. Apart from standard ERM, we include GroupDRO (Sagawa et al., 2019) and DFR (Kirchenko et al., 2023) that assume access to the group labels. We only include \(\text{DFR}^{\text{Tr}}\) for fair comparison as all methods only use the training dataset to train and finetune the model, while \(\text{DFR}^{\text{Val}}\) also finetunes on validation data. We also design a baseline called subsample that simply trains the model on the warm-up dataset only. Additionally, we evaluate three recent methods that address spurious correlations without the need for group labels: LfF (Nam et al., 2020), EIIL (Creager et al., 2021), and JTT (Liu et al., 2021). We

\begin{table}
\begin{tabular}{c c c} \hline \hline  & Worst-group (\(\%\)) & Gap (\(\%\)) \\ \hline ERM (GD) & \(0.00\) & \(97.71\) \\ ERM (GD+M) & \(0.00\) & \(97.71\) \\ Warmup+All (Reset) & \(67.69\) & \(31.18\) \\ Warmup+All & \(74.24\) & \(24.76\) \\ PDE (Reset) & \(92.51\) & \(2.29\) \\ PDE & \(\mathbf{93.01}\) & \(\mathbf{0.03}\) \\ \hline \hline \end{tabular}
\end{table}
Table 1: Synthetic data experiments. We report the worst-group accuracy and the gap (i.e., overall - worst). We further consider several variations of PDE to demonstrate the importance of each component of our method. **Reset**: we reset the momentum to zero after the warm-up stage. **Warmup+All**: we let PDE to incorporate all of the new training data at once after the warm-up stage.

Figure 3: **Training process of ERM vs. PDE. We consider the same dataset generated from the distribution as in Definition 2.1 for ERM (case 1) and PDE. On the same training data, ERM learns the spurious feature while PDE successfully learns the core feature. We further consider ERM (case 2) when training on the data distribution where \(\beta_{c}>\beta_{s}\) and \(\widehat{\alpha}=0.98\). We show the growth of the max inner product between the modelâ€™s neuron and core/spurious signal vector and the decrease of training loss with regard to the number of iterations \(t\).**

[MISSING_PAGE_FAIL:8]

#### 4.2.3 Understanding the Two Stages

We examine each component and demonstrate their effect in PDE. In Table 4, we present the worst-group and average accuracy of the model trained following the warm-up and expansion stages. Indeed, the majority of learning occurs in the warm-up stage, during which a satisfactory worst-group accuracy is established. In the expansion stage, the model persists in learning new data along the established trajectory, leading to continued performance improvement. In Figure 5, we corroborate and emphasize that the model has acquired the appropriate features and maintains learning based on its historical gradient stored in the momentum by presenting the following evidence. As shown, if the optimizer is reset after the warm-up stage and loses all its historical gradients, it rapidly acquires spurious features, resulting in a swift decline in performance accuracy as shown in the blue line.

#### 4.2.4 Ablation Study on the Hyper-parameters of PDE

PDE is robust within a reasonable range of hyperparemeter choices, although some configurations outperform others. As shown in Table 5, it is necessary to limit the number of data points introduced during each expansion to prevent performance degradation. Similarly, in Appendix A, we emphasize the importance of gradual data expansion. In Table 6, we show that post-warmup learning rate decay is essential, though PDE exhibits a tolerance to the degree of this decay. Lastly, as illustrated in Figure 5, adopting a smaller learning rate often necessitates increased data expansions. Nonetheless, a reduced learning rate does not necessarily lead to improved performance.

\begin{table}
\begin{tabular}{l c c c} \hline \hline Exp. size & Exp. lr & Worst & Average \\ \hline
10 & 1e-2 & \(85.4_{\pm 3.1}\) & \(92.1_{\pm 2.0}\) \\
10 & 1e-3 & \(89.4_{\pm 0.7}\) & \(92.6_{\pm 0.3}\) \\
10 & 1e-5 & \(89.5_{\pm 0.2}\) & \(92.1_{\pm 0.1}\) \\ \hline \hline \end{tabular}
\end{table}
Table 6: Ablation study on Waterbirds. Exp. lr: the learning rate in expansion stage.

\begin{table}
\begin{tabular}{l c c c} \hline \hline  & Warm-up & \multicolumn{2}{c}{Addition} \\ Dataset & Worst & Avg & Worst & Avg \\ \hline Waterbirds & 86.0 & 91.9 & **90.3** & 92.4 \\ CelebA & 87.8 & 92.1 & **91.0** & 92.0 \\ CivilComm & 67.7 & 78.8 & **71.5** & 86.3 \\ \hline \hline \end{tabular}
\end{table}
Table 4: Performance of PDE after each stage. We report the worst-group and average accuracy.

Figure 4: The effect of reset the momentum to zero after the warm-up stage for PDE on Waterbirds.

Figure 5: The variations in both worst-group and average accuracy on the test set of Waterbirds during expansion stage under different expansion learning rates. Each vertical dashed line denotes an expansion and the arrow denotes the early stopping.

Related Work

Existing approaches for improving robustness against spurious correlations can be categorized into two lines of research based on the tackled subproblems. A line of research focuses on the same subproblem we tackle: effectively using the group information to improve robustness. With group information, one can use the distributionally robust optimization (DRO) framework and dynamically increase the weight of the worst-group loss in minimization (Hu et al., 2018; Oren et al., 2019; Sagawa et al., 2019; Zhang et al., 2021). Within this line of work, GroupDRO (Sagawa et al., 2019) achieves state-of-the-art performances across multiple benchmarks. Other approaches use importance weighting to reweight the groups (Shimodaira, 2000; Byrd and Lipton, 2019; Xu et al., 2021) and class balancing to downsample the majority or upsample the minority (He and Garcia, 2009; Cui et al., 2019; Sagawa et al., 2020). Alternatively, Goel et al. (2021) leverage group information to augment the minority groups with synthetic examples generated using GAN. Another strategy (Cao et al., 2019, 2020) involves imposing Lipschitz regularization around minority data points. Most recently, methods that train a model using ERM first and then only finetune the last layer on balanced data from training or validation (Kirichenko et al., 2023) or learn post-doc scaling adjustments (Wei et al., 2023) are shown to be effective.

The other line of research focuses on the setting where group information is not available during training and tackles the first subproblem we identified as accurately finding the groups. Recent notable works (Nam et al., 2020; Liu et al., 2021; Creager et al., 2021; Zhang et al., 2022; Yang et al., 2023a) mostly involve training two models, one of which is used to find group information. To finally use the found groups, many approaches (Namkoong and Duchi, 2017; Duchi et al., 2019; Oren et al., 2019; Sohoni et al., 2020) still follow the DRO framework.

The first theoretical analysis of spurious correlation is provided by Sagawa et al. (2020). For self-supervised learning, Chen et al. (2020) shows that fine-tuning with pre-trained models can reduce the harmful effects of spurious features. Ye et al. (2022) provides guarantees in the presence of label noise that core features are learned well only when less noisy than spurious features. These theoretical work only provides analyses of linear models. Meanwhile, a parallel line of work has established theoretical analysis of nonlinear CNNs in the more realistic setting Allen-Zhu and Li (2020); Zou et al. (2021); Wen and Li (2021); Chen et al. (2022); Jelassi and Li (2022). Our work builds on this line of research and generalizes it to the study of spurious features. Lastly, we notice that a concurrent work (Chen et al., 2023) also uses tensor power method (Allen-Zhu and Li, 2020) to analyze the learning of spurious features v.s. invariant features, but in the setting of out-of-distribution generalization.

## 6 Conclusion

In conclusion, this paper addressed the challenge of spurious correlations in training deep learning models and focused on the most effective use of group information to improve robustness. We provided a theoretical analysis based on a simplified data model and a two-layer nonlinear CNN. Building upon this understanding, we proposed PDE, a novel training algorithm that effectively and efficiently enhances model robustness against spurious correlations. This work contributes to both the theoretical understanding and practical application of mitigating spurious correlations, paving the way for more reliable and robust deep learning models.

**Limitations and future work.** Although beyond the linear setting, our analysis still focuses on a relatively simplified binary classification data model. To better represent real-world application scenarios, future work could involve extending to multi-class classification problems and examining the training of transformer architectures. Practically, our proposed method requires the tuning of additional hyperparameters, including the number of warm-up epochs, the number of times for dataset expansion and the number of data to be added in each expansion.

## Acknowledgements

We sincerely thank Dongruo Zhou for the constructive suggestions on the structure and writings of the paper. We also thank the anonymous reviewers for their helpful comments. YD and QG are supported in part by the National Science Foundation CAREER Award 1906169 and IIS-2008981, and the Sloan Research Fellowship. BM is supported by the National Science Foundation CAREER Award 2146492. The views and conclusions contained in this paper are those of the authors and should not be interpreted as representing any funding agencies.

## References

* Ahmed et al. (2021) Ahmed, F., Bengio, Y., Van Seijen, H., and Courville, A. Systematic generalisation with group invariant predictions. In _International Conference on Learning Representations_, 2021.
* Allen-Zhu & Li (2020) Allen-Zhu, Z. and Li, Y. Towards understanding ensemble, knowledge distillation and self-distillation in deep learning. _arXiv preprint arXiv:2012.09816_, 2020.
* Byrd & Lipton (2019) Byrd, J. and Lipton, Z. What is the effect of importance weighting in deep learning? In _International conference on machine learning_, pp. 872-881. PMLR, 2019.
* Cao et al. (2019) Cao, K., Wei, C., Gaidon, A., Arechiga, N., and Ma, T. Learning imbalanced datasets with label-distribution-aware margin loss. _Advances in neural information processing systems_, 32, 2019.
* Cao et al. (2020) Cao, K., Chen, Y., Lu, J., Arechiga, N., Gaidon, A., and Ma, T. Heteroskedastic and imbalanced deep learning with adaptive regularization. _arXiv preprint arXiv:2006.15766_, 2020.
* Cao et al. (2022) Cao, Y., Chen, Z., Belkin, M., and Gu, Q. Benign overfitting in two-layer convolutional neural networks. _Advances in neural information processing systems_, 35:25237-25250, 2022.
* Chen et al. (2020) Chen, Y., Wei, C., Kumar, A., and Ma, T. Self-training avoids using spurious features under domain shift. _Advances in Neural Information Processing Systems_, 33:21061-21071, 2020.
* Chen et al. (2023) Chen, Y., Huang, W., Zhou, K., Bian, Y., Han, B., and Cheng, J. Towards understanding feature learning in out-of-distribution generalization. _arXiv preprint arXiv:2304.11327_, 2023.
* Chen et al. (2022) Chen, Z., Deng, Y., Wu, Y., Gu, Q., and Li, Y. Towards understanding the mixture-of-experts layer in deep learning. _Advances in neural information processing systems_, 2022.
* Creager et al. (2021) Creager, E., Jacobsen, J.-H., and Zemel, R. Environment inference for invariant learning. In _International Conference on Machine Learning_, pp. 2189-2200. PMLR, 2021.
* Cui et al. (2019) Cui, Y., Jia, M., Lin, T.-Y., Song, Y., and Belongie, S. Class-balanced loss based on effective number of samples. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pp. 9268-9277, 2019.
* Duchi et al. (2019) Duchi, J. C., Hashimoto, T., and Namkoong, H. Distributionally robust losses against mixture covariate shifts. _Under review_, 2:1, 2019.
* Goel et al. (2021) Goel, K., Gu, A., Li, Y., and Re, C. Model patching: Closing the subgroup performance gap with data augmentation. In _International Conference on Learning Representations_, 2021.
* Haghtalab et al. (2022) Haghtalab, N., Jordan, M., and Zhao, E. On-demand sampling: Learning optimally from multiple distributions. In Oh, A. H., Agarwal, A., Belgrave, D., and Cho, K. (eds.), _Advances in Neural Information Processing Systems_, 2022.
* He & Garcia (2009) He, H. and Garcia, E. A. Learning from imbalanced data. _IEEE Transactions on knowledge and data engineering_, 21(9):1263-1284, 2009.
* He et al. (2016) He, K., Zhang, X., Ren, S., and Sun, J. Deep residual learning for image recognition. In _Proceedings of the IEEE conference on computer vision and pattern recognition_, pp. 770-778, 2016.
* Hu et al. (2018) Hu, W., Niu, G., Sato, I., and Sugiyama, M. Does distributionally robust supervised learning give robust classifiers? In _International Conference on Machine Learning_, pp. 2029-2037. PMLR, 2018.
* Izmailov et al. (2022) Izmailov, P., Kirichenko, P., Gruver, N., and Wilson, A. G. On feature learning in the presence of spurious correlations. _Advances in Neural Information Processing Systems_, 35:38516-38532, 2022.
* Jelassi & Li (2022) Jelassi, S. and Li, Y. Towards understanding how momentum improves generalization in deep learning. In _International Conference on Machine Learning_, pp. 9965-10040. PMLR, 2022.
* Kirichenko et al. (2023) Kirichenko, P., Izmailov, P., and Wilson, A. G. Last layer re-training is sufficient for robustness to spurious correlations. In _International Conference on Learning Representations_, 2023.
* Krizhevsky & Hinton (2012)Koh, P. W., Sagawa, S., Marklund, H., Xie, S. M., Zhang, M., Balsubramani, A., Hu, W., Yasunaga, M., Phillips, R. L., Gao, I., Lee, T., David, E., Stavness, I., Guo, W., Earnshaw, B. A., Haque, I. S., Beery, S., Leskovec, J., Kundaje, A., Pierson, E., Levine, S., Finn, C., and Liang, P. WILDS: A benchmark of in-the-wild distribution shifts. In _International Conference on Machine Learning (ICML)_, 2021a.
* Koh et al. (2021) Koh, P. W., Sagawa, S., Marklund, H., Xie, S. M., Zhang, M., Balsubramani, A., Hu, W., Yasunaga, M., Phillips, R. L., Gao, I., et al. Wilds: A benchmark of in-the-wild distribution shifts. In _International Conference on Machine Learning_, pp. 5637-5664. PMLR, 2021b.
* Liu et al. (2021) Liu, E. Z., Haghgoo, B., Chen, A. S., Raghunathan, A., Koh, P. W., Sagawa, S., Liang, P., and Finn, C. Just train twice: Improving group robustness without training group information. In _International Conference on Machine Learning_, pp. 6781-6792. PMLR, 2021.
* Liu et al. (2015) Liu, Z., Luo, P., Wang, X., and Tang, X. Deep learning face attributes in the wild. In _Proceedings of the IEEE international conference on computer vision_, pp. 3730-3738, 2015.
* Nam et al. (2020) Nam, J., Cha, H., Ahn, S., Lee, J., and Shin, J. Learning from failure: De-biasing classifier from biased classifier. _Advances in Neural Information Processing Systems_, 33:20673-20684, 2020.
* Namkoong & Duchi (2017) Namkoong, H. and Duchi, J. C. Variance-based regularization with convex objectives. _Advances in neural information processing systems_, 30, 2017.
* Oren et al. (2019) Oren, Y., Sagawa, S., Hashimoto, T. B., and Liang, P. Distributionally robust language modeling. In _Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)_, pp. 4227-4237, Hong Kong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1432.
* Paszke et al. (2019) Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, L., Desmaison, A., Kopf, A., Yang, E., DeVito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang, L., Bai, J., and Chintala, S. Pytorch: An imperative style, high-performance deep learning library. In Wallach, H., Larochelle, H., Beygelzimer, A., dAlche-Buc, F., Fox, E., and Garnett, R. (eds.), _Advances in Neural Information Processing Systems 32_, pp. 8024-8035. 2019.
* Sagawa et al. (2019) Sagawa, S., Koh, P. W., Hashimoto, T. B., and Liang, P. Distributionally robust neural networks. In _International Conference on Learning Representations_, 2019.
* Sagawa et al. (2020) Sagawa, S., Raghunathan, A., Koh, P. W., and Liang, P. An investigation of why overparameterization exacerbates spurious correlations. In _International Conference on Machine Learning_, pp. 8346-8356. PMLR, 2020.
* Selvaraju et al. (2017) Selvaraju, R. R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., and Batra, D. Grad-cam: Visual explanations from deep networks via gradient-based localization. In _Proceedings of the IEEE international conference on computer vision_, pp. 618-626, 2017.
* Shimodaira (2000) Shimodaira, H. Improving predictive inference under covariate shift by weighting the log-likelihood function. _Journal of statistical planning and inference_, 90(2):227-244, 2000.
* Sohoni et al. (2020) Sohoni, N., Dunnmon, J., Angus, G., Gu, A., and Re, C. No subclass left behind: Fine-grained robustness in coarse-grained classification problems. _Advances in Neural Information Processing Systems_, 33:19339-19352, 2020.
* Taghanaki et al. (2021) Taghanaki, S. A., Choi, K., Khasahmadi, A. H., and Goyal, A. Robust representation learning via perceptual similarity metrics. In _International Conference on Machine Learning_, pp. 10043-10053. PMLR, 2021.
* Van der Maaten & Hinton (2008) Van der Maaten, L. and Hinton, G. Visualizing data using t-sne. _Journal of machine learning research_, 9(11), 2008.
* Vaswani et al. (2017) Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., and Polosukhin, I. Attention is all you need. In _Advances in neural information processing systems_, pp. 5998-6008, 2017.
* Wang et al. (2019)Wah, C., Branson, S., Welinder, P., Perona, P., and Belongie, S. The caltech-ucsd birds-200-2011 dataset. 2011.
* Wei et al. (2023) Wei, J., Narasimhan, H., Amid, E., Chu, W.-S., Liu, Y., and Kumar, A. Distributionally robust post-hoc classifiers under prior shifts. In _International Conference on Learning Representations (ICLR)_, 2023.
* Wen & Li (2021) Wen, Z. and Li, Y. Toward understanding the feature learning process of self-supervised contrastive learning. In _International Conference on Machine Learning_, pp. 11112-11122. PMLR, 2021.
* Wolf et al. (2020) Wolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., Cistac, P., Rault, T., Louf, R., Funtowicz, M., Davison, J., Shleifer, S., von Platen, P., Ma, C., Jernite, Y., Plu, J., Xu, C., Scao, T. L., Gugger, S., Drame, M., Lhoest, Q., and Rush, A. M. Transformers: State-of-the-art natural language processing. In _Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations_, pp. 38-45, Online, October 2020. Association for Computational Linguistics. URL [https://www.aclweb.org/anthology/2020.emnlp-demos.6](https://www.aclweb.org/anthology/2020.emnlp-demos.6).
* Xu et al. (2021) Xu, D., Ye, Y., and Ruan, C. Understanding the role of importance weighting for deep learning. In _International Conference on Learning Representations_, 2021.
* Yang et al. (2023a) Yang, Y., Gan, E., Dziugaite, G. K., and Mirzasoleiman, B. Identifying spurious biases early in training through the lens of simplicity bias. _arXiv preprint arXiv:2305.18761_, 2023a.
* Yang et al. (2023b) Yang, Y., Nushi, B., Palangi, H., and Mirzasoleiman, B. Mitigating spurious correlations in multi-modal models during fine-tuning. In _International Conference on Machine Learning_, 2023b.
* Yang et al. (2023c) Yang, Y., Zhang, H., Katabi, D., and Ghassemi, M. Change is hard: A closer look at subpopulation shift. _arXiv preprint arXiv:2302.12254_, 2023c.
* Yang et al. (2022) Yang, Y.-Y., Chou, C.-N., and Chaudhuri, K. Understanding rare spurious correlations in neural networks. _arXiv preprint arXiv:2202.05189_, 2022.
* Ye et al. (2022) Ye, H., Zou, J., and Zhang, L. Freeze then train: Towards provable representation learning under spurious correlations and feature noise. _arXiv preprint arXiv:2210.11075_, 2022.
* Zhang et al. (2021) Zhang, J., Menon, A. K., Veit, A., Bhojanapalli, S., Kumar, S., and Sra, S. Coping with label shift via distributionally robust optimisation. In _International Conference on Learning Representations_, 2021.
* Zhang et al. (2022) Zhang, M., Sohoni, N. S., Zhang, H. R., Finn, C., and Re, C. Correct-n-contrast: A contrastive approach for improving robustness to spurious correlations. _arXiv preprint arXiv:2203.01517_, 2022.
* Zhou et al. (2017) Zhou, B., Lapedriza, A., Khosla, A., Oliva, A., and Torralba, A. Places: A 10 million image database for scene recognition. _IEEE Transactions on Pattern Analysis and Machine Intelligence_, 2017.
* Zou et al. (2021) Zou, D., Cao, Y., Li, Y., and Gu, Q. Understanding the generalization of adam in learning neural networks with proper regularization. _arXiv preprint arXiv:2108.11371_, 2021.