# Private Distribution Learning with Public Data:

The View from Sample Compression+
Footnote †: Authors are listed in alphabetical order. Full paper: https://arxiv.org/abs/2308.06239.

Shai Ben-David

University of Waterloo

Vector Institute

shai@uwaterloo.ca

&Alex Bie

University of Waterloo

yabie@uwaterloo.ca

&Clement L. Canonne

University of Sydney

clement.canonne@sydney.edu.au

Gautam Kamath

University of Waterloo

Vector Institute

g@csail.mit.edu

&Vikrant Singhal

University of Waterloo

vikrant.singhal@uwaterloo.ca

###### Abstract

We study the problem of private distribution learning with access to public data. In this setup, which we refer to as _public-private learning_, the learner is given public and private samples drawn from an unknown distribution \(p\) belonging to a class \(\mathcal{Q}\), with the goal of outputting an estimate of \(p\) while adhering to privacy constraints (here, pure differential privacy) only with respect to the private samples.

We show that the public-private learnability of a class \(\mathcal{Q}\) is connected to the existence of a sample compression scheme for \(\mathcal{Q}\), as well as to an intermediate notion we refer to as _list learning_. Leveraging this connection: (1) approximately recovers previous results on Gaussians over \(\mathbb{R}^{d}\); and (2) leads to new ones, including sample complexity upper bounds for arbitrary \(k\)-mixtures of Gaussians over \(\mathbb{R}^{d}\), results for agnostic and distribution-shift resistant learners, as well as closure properties for public-private learnability under taking mixtures and products of distributions. Finally, via the connection to list learning, we show that for Gaussians in \(\mathbb{R}^{d}\), at least \(d\) public samples are necessary for private learnability, which is close to the known upper bound of \(d+1\) public samples.

## 1 Introduction

Statistical analysis of sensitive data, and specifically parameter and density estimation, is a workhorse of privacy-preserving machine learning. To provide meaningful and rigorous guarantees on algorithm for these tasks, the framework of _differential privacy_ (DP) [14] has been widely adopted by both algorithm designers and machine learning practitioners [1, 2, 17], and is, by and large, one of the past decade's success stories in principled approaches to private machine learning, with a host of results and implementations [1, 2, 1, 13] for many of the flagship private learning tasks.

Yet, however usable the resulting algorithms may be, DP often comes at a steep price: namely, many estimation tasks simple without privacy constraints provably require much more data to be performed privately; even more dire, they sometimes become _impossible_ with any finite number of data points, absent some additional strong assumptions.

The prototypical example in that regard is learning a single \(d\)-dimensional Gaussian distribution from samples. In this task, a learner receives i.i.d. samples from an unknown \(d\)-dimensional Gaussianand is tasked with finding an estimate \(q\) close to \(p\) in total variation (\(\mathrm{TV}\)) distance. Without privacy constraints, it is folklore that this can be done with \(O(d^{2})\) samples; yet once privacy enters the picture, in the form of pure differential privacy, _no finite sample algorithm for this task can exist_, unless a bound on the mean vector and covariance matrix are known.

This "cost of privacy" is, unfortunately, inherent to many estimation tasks, as the positive results (algorithms) developed over the years have been complemented with matching negative results (lower bounds). In light of these strong impossibility results, it is natural to wonder if one could somehow circumvent this often steep privacy cost by leveraging other sources of _public_ data to aid the private learning process.

Recent work in finetuning machine learning models has tried to address the question whether, in situations where a vast amount of public data is available, one can combine the public data with a relatively small amount of _private_ data to somehow achieve privacy guarantees for the private data and learning guarantees that would otherwise be ruled out by the aforementioned impossibility results. We, on the other hand, address the same question, but in the opposite setting, i.e., when the amount of public data available is much smaller than the amount of private data available. In other words, we answer the following question from new perspectives.

_Can one leverage small quantities of public data to privately learn from sensitive data, even when private learning is impossible?_

This question was the focus of a recent study of Bie, Kamath, and Singhal [1], the starting point of our work. In this paper, we make significant strides in this direction, by obtaining new "plug and play" results and connections in this public-private learning setting, and using them to obtain new sample complexity bounds for a range of prototypical density estimation tasks.

### Our results

First, we establish a connection between learning (in the sense of _distribution learning_ or _density estimation_) with public and private data (Definition 2.4) and _sample compression schemes for distributions_ (Definition 2.5; see [1, Definition 4.2]), as well as an intermediate notion we refer to as _list learning_ (Definition 3.2).

**Theorem 1.1** (Sample compression schemes, public-private learning, and list learning (Informal; see Theorem D.1)).: _Let \(\mathcal{Q}\) be a class of probability distributions and \(m(\alpha,\beta)\) be a sample complexity function in terms of target error \(\alpha\) and failure probability \(\beta\). Then the following are equivalent._

1. \(\mathcal{Q}\) _has a sample compression scheme using_ \(O(m(\alpha,\beta))\) _samples._
2. \(\mathcal{Q}\) _is public-privately learnable with_ \(O(m(\alpha,\beta))\) _public samples._
3. \(\mathcal{Q}\) _is list learnable with_ \(O(m(\alpha,\beta))\) _samples._

Despite its technical simplicity, this sample complexity equivalence turns out to be quite useful, and allows us to derive new public-private learners for an array of key distribution classes by leveraging known results on sample compression schemes. In particular, from the connection to sample compression schemes we are able to obtain new public-private learners for: (1) high-dimensional Gaussian distributions (Corollary E.1); (2) arbitrary mixtures of high-dimensional Gaussians (Theorem 1.2/Corollary E.2); (3) mixtures of public-privately learnable distribution classes (Theorem 4.3/E.5); and (4) products of public-privately learnable distribution classes (Theorem 4.3/E.7). For instance, the following is a consequence of the above connection.

**Theorem 1.2** (Public-private learning for mixtures of Gaussians (Informal; see Corollary E.2)).: _The class of mixtures of \(k\) arbitrary \(d\)-dimensional Gaussians is public-privately learnable with \(m\) public samples and \(n\) private samples, where_

\[m=\tilde{O}\left(\frac{kd}{\alpha}\right)\ \ \text{and}\ \ \ n=\tilde{O}\left(\frac{kd^{2}}{\alpha^{2}}+\frac{kd^{2}}{\alpha \varepsilon}\right),\]

_in which \(\alpha\) is the target error and \(\varepsilon\) the privacy parameter._

We also examine public-private distribution learning in a setting with relaxed distributional assumptions, in which the distributions underlying the public and private data: (1) may differ (the case of public-private _distribution shift_); and (2) may not be members of the reference class of distributions, and so we instead ask for error close to the best approximation of the private data distribution by a member of the class (the _agnostic_ case). We show that _robust_ sample compression schemes for a class of distributions can be converted into public-private learners in this _agnostic and distribution-shifted_ setting. As a consequence, we have the following result for learning distributions that can be approximated by Gaussians under public-private distribution shift.

**Theorem 1.3** (Agnostic and distribution-shifted public-private learning for Gaussians (Informal; see Corollary F.1)).: _There is a public-private learner that takes \(m\) public samples and \(n\) private samples from any pair of distributions \(\tilde{p}\) and \(p\) over \(\mathbb{R}^{d}\) respectively, with \(\operatorname{TV}(\tilde{p},p)\leq\frac{1}{3}\), where_

\[m=O\left(d\right)\quad\text{and}\quad n=\tilde{O}\left(\frac{d^{2}}{\alpha}+ \frac{d^{2}}{\alpha\varepsilon}\right),\]

_in which \(\alpha\) is the target error and \(\varepsilon\) the privacy parameter. With probability \(\geq\frac{9}{10}\), the learner outputs \(q\) with \(\operatorname{TV}(q,p)\leq\operatorname{3OPT}+\alpha\), where \(\operatorname{OPT}\) is the total variation distance between \(p\) and the closest \(d\)-dimensional Gaussian to it._

Next, using the aforementioned connection to list learning, we are able to establish a fine-grained lower bound on the number of public data points required to privately learn high-dimensional Gaussians.

**Theorem 1.4** (Almost tight lower bound on privately learning Gaussians with public data (Informal; see Theorem 6.1)).: _The class of all \(d\)-dimensional Gaussians is not public-privately learnable with fewer than \(d\) public samples, regardless of the number of private samples._

[1] showed that \(d\)-dimensional Gaussians are public-privately learnable with \(\tilde{O}(\frac{d^{2}}{\alpha^{2}}+\frac{d^{2}}{\alpha\varepsilon})\) private samples, _as soon as \(d+1\) public samples are available_. Thus, our result shows a very sharp threshold for the number of public data points necessary and sufficient to make private learning possible.

We also provide a general result for public-privately learning classes of distributions whose _Yatracos class_ has finite VC dimension.

**Theorem 1.5** (VC dimension bound for public-private learning (Informal; see Theorem 7.2)).: _Let \(\mathcal{Q}\) be a class of probability distributions over a domain \(\mathcal{X}\) such that the Yatracos class of \(\mathcal{Q}\), defined as_

\[\mathcal{H}\coloneqq\{\{x\colon f(x)>g(x)\}:f,g\in\mathcal{Q}\} \subseteq 2^{\mathcal{X}}\]

_has bounded VC dimension. Denote by \(\operatorname{VC}(\mathcal{H})\) and \(\operatorname{VC}^{*}(\mathcal{H})\) the \(\operatorname{VC}\) and dual \(\operatorname{VC}\) dimensions of \(\mathcal{H}\) respectively. Then \(\mathcal{Q}\) is public-privately learnable with \(m\) public samples and \(n\) private samples, where_

\[m=\tilde{O}\left(\frac{\operatorname{VC}(\mathcal{H})}{\alpha}\right)\quad \text{and}\quad n=\tilde{O}\left(\frac{\operatorname{VC}(\mathcal{H})^{2} \operatorname{VC}^{*}(\mathcal{H})}{\varepsilon\alpha^{3}}\right),\]

_in which \(\alpha\) is the target error and \(\varepsilon\) the privacy parameter._

The \(\tilde{O}(\frac{\operatorname{VC}(\mathcal{H})}{\alpha})\) public sample requirement is less than the known \(O(\frac{\operatorname{VC}(\mathcal{H})}{\alpha^{2}})\) sample requirement to learn with only public data via the non-private analogue of this result [21, 1].

### Related work

The most closely related work is that of Bie, Kamath, and Singhal [1], which initiated the study of distribution learning with access to both public and private data. That work studied algorithms for specific canonical distribution classes, while the present paper aims to broaden our understanding of public-private distribution learning in general, via connections to other problems and providing more general approaches for devising sample efficient public-private learners. In addition, we prove the first lower bounds on the amount of public data needed for private distribution learning.

There is a long line of work on private distribution learning, especially with regards to Gaussians and mixtures of Gaussians. [13] studied univariate Gaussians, showing that logarithmic dependencies on parameter bounds are necessary and sufficient in the case of pure DP, but can be removed under approximate DP. The same is true in the multivariate setting [12, 11, 13].

KMV22, LKO22]. For mixtures of Gaussians, most studies have focused on _parameter estimation_ of mixture components [10, 13, 14, 15, 16, 17, 18], and employ component separation and mixing weight assumptions. For _density estimation_ (the setting studied in this work) [1, 1] give learnability results under various structural assumptions. The concurrent work of Azfali, Ashtiani, and Lia [1] gives the first learnability result for general high-dimensional mixtures of Gaussians under approximate differential privacy.

Outside of distribution learning, there is a significant interest in using public data to improve private algorithms. Some problems studied include private query release, synthetic data generation, classification, mean estimation, empirical risk minimization, and stochastic convex optimization [1, 15, 1, 16, 17, 18, 19, 20, 21, 22, 23]. The definition of public-private algorithms that we adopt is from [15], which studied classification in the PAC model. The VC dimension bound we give for public-private distribution learning relies on results from public-private classification [1] and uniform convergence [20].

On the technical side, we establish connections with distribution compression schemes as introduced by [1], and directly apply their results to establish new results for public-public learning. Related compression schemes for PAC learning for binary classification have been shown to be necessary and sufficient for learnability in those settings [14, 15]. For further discussion of related work, please see Appendix A.

### Limitations

Our work investigates the sample complexity of public-private learning, and does not give computationally efficient learners, or in some cases, _algorithmic_ learners that run in finite time.1 In particular, all public-private learners we obtain from sample compression run in time exponential in the sample complexity. Also, for our VC dimension upper bounds, we enumerate all realizable labellings of the input sample as per the relevant Yatracos class \(\mathcal{H}\), which is not computable for general \(\mathcal{H}\)[1]. Finally, dependence on \(\operatorname{VC}^{*}(\mathcal{H})\) in sample complexity is not ideal, as \(\operatorname{VC}^{*}(\mathcal{H})\leq 2^{\operatorname{VC}(\mathcal{H})+1}-1\) is the best possible upper bound in terms of \(\operatorname{VC}(\mathcal{H})\) for general \(\mathcal{H}\)[21].

Footnote 1: The comment of reviewer rJcv points out an approach to address the non-constructive nature of the reduction of public-privately learning mixture classes to public-privately learning the base class. To summarize: fixing the \(m\) public samples and running the public-private learner on \(n\) “null samples” repeatedly (with different random coins) produces a cover containing the true distribution with high probability. From here, we can run this procedure on all subsamples of the public data and construct a cover containing the true (mixture) distribution.

## 2 Preliminaries

### Notation

We denote by \(\mathcal{X}\) the _domain of examples_. For a domain \(\mathcal{U}\), denote by \(\Delta(\mathcal{U})\) the set of all probability distributions over \(\mathcal{U}\). We refer to a set \(\mathcal{Q}\subseteq\Delta(\mathcal{X})\) as a _class of distributions over \(\mathcal{X}\)_.

We equip \(\Delta(\mathcal{X})\) with the _total variation_ metric, which is defined as follows: for \(p,q\in\Delta(\mathcal{X})\), \(\operatorname{TV}(p,q):=\sup_{B\in\mathcal{B}}|p(B)-q(B)|\), where \(\mathcal{B}\) are the measurable sets of \(\mathcal{X}\). For \(p\in\Delta(\mathcal{X})\) and a set of distributions \(L\subseteq\Delta(\mathcal{X})\), we denote their _point-set distance_ by \(\operatorname{dist}(p,L):=\inf_{q\in L}\operatorname{TV}(p,q)\).

We will let \(\boldsymbol{\tilde{x}}=(\tilde{x}_{1},\ldots,\tilde{x}_{m})\in\mathcal{X}^{m}\) denote a _public dataset_ and \(\boldsymbol{x}=(x_{1},\ldots,x_{n})\in\mathcal{X}^{n}\) denote a _private dataset_. Their respective capital versions \(\boldsymbol{\tilde{X}}\), \(\boldsymbol{X}\) denote random variables for datasets realized by sampling from some underlying distribution. For \(p\in\Delta(\mathcal{X})\), we denote by \(p^{m}\) the distribution over \(\mathcal{X}^{m}\) obtained by concatenating \(m\) i.i.d. samples from \(p\).

### Public-private learning

**Definition 2.1** (Differential privacy [14]).: Fix an input space \(\mathcal{X}\) and an output space \(\mathcal{Y}\). Let \(\varepsilon,\delta>0\). A randomized algorithm \(\mathcal{A}:\mathcal{X}^{n}\to\Delta(\mathcal{Y})\) is _\((\varepsilon,\delta)\)-differentially private (\(\varepsilon,\delta\))-DP_, if for any private datasets \(\boldsymbol{x},\boldsymbol{x}^{\prime}\in\mathcal{X}^{n}\) differing in one entry,

\[\operatorname*{\mathbb{P}}_{Y\sim\mathcal{A}(\boldsymbol{x})}\left\{Y\in B \right\}\leq\exp(\varepsilon)\cdot\operatorname*{\mathbb{P}}_{Y^{\prime}\sim \mathcal{A}(\boldsymbol{x}^{\prime})}\left\{Y^{\prime}\in B\right\}+\delta \qquad\text{for all measurable $B\subseteq\mathcal{Y}$.}\]The case where \(\delta=0\) is referred to as _pure_ differential privacy or \(\varepsilon\)-DP.

Our focus is on understanding the public data requirements for privately learning different classes of distributions. We seek to answer the following question:

_For a class of distributions \(\mathcal{Q}\), how much public data is necessary and sufficient to render \(\mathcal{Q}\) privately learnable?_

To do so, we give the formal notion of "public-private algorithms" - algorithms that take public data samples and private data samples as input, and guarantee differential privacy with respect to the private data - as studied previously in the setting of binary classification [1, 1]. We restrict our attention to public-private algorithms that offer a pure DP guarantee to private data.

**Definition 2.2** (Public-private \(\varepsilon\)-Dp).: Fix an input space \(\mathcal{X}\) and an output space \(\mathcal{Y}\). Let \(\varepsilon>0\). A randomized algorithm \(\mathcal{A}\colon\mathcal{X}^{m}\times\mathcal{X}^{n}\to\Delta(\mathcal{Y})\) is _public-private \(\varepsilon\)-DP_ if for any public dataset \(\boldsymbol{\tilde{x}}\in\mathcal{X}^{m}\), the randomized algorithm \(\mathcal{A}(\boldsymbol{\tilde{x}},\cdot):\mathcal{X}^{n}\to\Delta(\mathcal{Y})\) is \(\varepsilon\)-DP.

**Definition 2.3** (Public-private learner).: Let \(\mathcal{Q}\subseteq\Delta(\mathcal{X})\). For \(\alpha,\beta\in(0,1]\) and \(\varepsilon>0\), an \((\alpha,\beta,\varepsilon)\)-_public-private learner for \(\mathcal{Q}\)_ is a public-private \(\varepsilon\)-DP algorithm \(\mathcal{A}:\mathcal{X}^{m}\times\mathcal{X}^{n}\to\Delta(\Delta(\mathcal{ X}))\), such that for any \(p\in\mathcal{Q}\), if we draw datasets \(\boldsymbol{\tilde{X}}=(\tilde{X}_{1},...,\tilde{X}_{m})\) and \(\boldsymbol{X}=(X_{1},...,X_{n})\) i.i.d. from \(p\) and then \(Q\sim\mathcal{A}(\boldsymbol{\tilde{X}},\boldsymbol{X})\),

\[\operatorname*{\mathbb{P}}_{\begin{subarray}{c}\boldsymbol{\tilde{X}}\sim p ^{m},\boldsymbol{X}\sim p^{n}\\ Q\sim\mathcal{A}(\boldsymbol{\tilde{X}},\boldsymbol{X})\end{subarray}}\{ \mathrm{TV}(Q,p)\leq\alpha\}\geq 1-\beta.\]

**Definition 2.4** (Public-privately learnable class).: We say that a class of distributions \(\mathcal{Q}\subseteq\Delta(\mathcal{X})\) is _public-privately learnable with \(m(\alpha,\beta,\varepsilon)\) public and \(n(\alpha,\beta,\varepsilon)\) private samples_ if for any \(\alpha,\beta\in(0,1]\) and \(\varepsilon>0\), there exists an \((\alpha,\beta,\varepsilon)\)-public-private learner for \(\mathcal{Q}\) that takes \(m=m(\alpha,\beta,\varepsilon)\) public samples and \(n=n(\alpha,\beta,\varepsilon)\) private samples.

When \(\mathcal{Q}\) satisfies the above, we may omit the private sample requirement, and say that \(\mathcal{Q}\) is _public-privately learnable with \(m(\alpha,\beta,\varepsilon)\) public samples_.

Denote by \(\text{SC}_{\mathcal{Q}}(\alpha,\beta)\) the sample complexity of learning \(\mathcal{Q}\). Our primary interest lies in determining when non-privately learnable \(\mathcal{Q}\) can be public-privately learned with \(m(\alpha,\beta,\varepsilon)=o(\text{SC}_{\mathcal{Q}}(\alpha,\beta))\) public samples (at a target \(\varepsilon\)).

### Sample compression schemes

One of the main techniques that we use in this work to create public-private learners for various distribution families is the _robust sample compression scheme_ from [1]. Roughly speaking, if every member \(q\) of a class of distributions \(\mathcal{Q}\) admits a way to encode enough information about itself in a small number of samples from \(q\) and extra bits, such that it can be approximately reconstructed by a fixed and deterministic decoder, \(\mathcal{Q}\) can be learned.

**Definition 2.5** (Robust sample compression [1, Definition 4.2]).: Let \(r\geq 0\). We say \(\mathcal{Q}\subseteq\Delta(\mathcal{X})\) admits \((\tau(\alpha,\beta),t(\alpha,\beta),m(\alpha,\beta))\)_\(r\)-robust sample compression_ if for any \(\alpha,\beta\in(0,1]\), letting \(\tau=\tau(\alpha,\beta)\), \(t=t(\alpha,\beta)\), \(m=m(\alpha,\beta)\), there exists a decoder \(g\colon\mathcal{X}^{r}\times\{0,1\}^{t}\to\Delta(\mathcal{X})\), such that the following holds:

For any \(q\in\mathcal{Q}\) there exists an encoder \(f_{q}\colon\mathcal{X}^{m}\to\mathcal{X}^{\tau}\times\{0,1\}^{t}\) satisfying for all \(\boldsymbol{x}\in\mathcal{X}^{m}\) that for all \(i\in[\tau]\), there exists \(j\in[m]\) with \(f_{q}(\boldsymbol{x})_{i}=\boldsymbol{x}_{j}\), such that for every \(p\in\Delta(\mathcal{X})\) with \(\mathrm{TV}(p,q)\leq r\), if we draw a dataset \(\boldsymbol{X}=(X_{1},...,X_{m})\) i.i.d. from \(p\),

\[\operatorname*{\mathbb{P}}_{\boldsymbol{X}\sim p^{m}}\{\mathrm{TV}(g(f_{q}( \boldsymbol{X})),q)\leq\alpha\}\geq 1-\beta.\]

When \(\mathcal{Q}\) satisfies the above, we may omit the compression size complexity function \(\tau(\alpha,\beta)\) and bit complexity function \(t(\alpha,\beta)\), and say that \(\mathcal{Q}\) is _\(r\)-robustly compressible_ with \(m(\alpha,\beta)\) samples. When \(r=0\), we say that \(\mathcal{Q}\) admits \((\tau(\alpha,\beta),t(\alpha,\beta),m(\alpha,\beta))\)_realizable compression_ and is _realizably compressible_ with \(m(\alpha,\beta)\) samples.

Both robust and realizable compression schemes satisfy certain useful properties that we use to develop public-private distribution learners in different settings. For example, the existence of a realizable compression scheme is closed under taking mixtures or products of distributions.

The connection to sample compression schemes

In this section we prove Theorem 1.1/D.1, the sample complexity equivalence between _sample compression_ (Definition 2.5), _public-private learning_ (Definition 2.4), and an intermediate notion we refer to as _list learning_ (Definition 3.2). We do so by giving sample-efficient reductions between the three notions (Propositions 3.1, 3.4, and 3.5). The propositions state the quantitative translations between: compression size \(\tau\) and number of bits \(t\), number of private samples \(n\), and list size \(\ell\).

### Compression implies public-private learning

We start by establishing that the existence of a sample compression scheme for \(\mathcal{Q}\) implies the existence of a public-private learner for \(\mathcal{Q}\).

**Proposition 3.1** (Compression \(\Longrightarrow\) public-private learning).: _Let \(\mathcal{Q}\subseteq\Delta(\mathcal{X})\). Suppose \(\mathcal{Q}\) admits \((\tau(\alpha,\beta)\), \(t(\alpha,\beta),m_{C}(\alpha,\beta))\) realizable sample compression. Then \(\mathcal{Q}\) is public-privately learnable with \(m(\alpha,\beta,\varepsilon)=m_{C}(\frac{\alpha}{6},\frac{\beta}{2})\) public and \(n(\alpha,\beta,\varepsilon)=O((\frac{1}{\alpha^{2}}+\frac{1}{\alpha \varepsilon})\cdot(t(\frac{\alpha}{6},\frac{\beta}{2})+\tau(\frac{\alpha}{6},\frac{\beta}{2})\log(m_{C}(\frac{\alpha}{6},\frac{\beta}{2}))+\log(\frac{1}{ \beta})))\) private samples._

Proof sketch.: The full proof is given in Appendix D.1, and mirrors that of Theorem 4.5 from [1] (albeit adapted to the public-private setting). Fix \(\alpha,\beta\in(0,1]\) and \(\varepsilon>0\). Let \(\tau=\tau(\frac{\alpha}{6},\frac{\beta}{2})\), \(t=t(\frac{\alpha}{6},\frac{\beta}{2})\), and \(m=m_{C}(\frac{\alpha}{6},\frac{\beta}{2})\). We draw a public sample \(\bm{\tilde{X}}\) of size \(m\), and enumerate all combinations of a size \(\tau\) subset of \(\bm{\tilde{X}}\) with a binary string of length \(t\). Essentially, we "guess" the encoding of the unknown distribution \(p\). Running the decoder on this set of possible encodings gives us a set of distributions; some of them are close to \(p\). Then, with private samples only, we use the pure DP \(3\)-agnostic learner for finite classes (Fact C.2) to pick one such out. 

### Public-private learning implies list learning

Next, we show that the existence of a public-private learner for a class of distributions implies the existence of a _list learner_ for the class. A list learner for a class \(\mathcal{Q}\) takes input samples from any \(p\in\mathcal{Q}\) and outputs a finite list of distributions, one of which is close to \(p\).

**Definition 3.2** (List learner).: Let \(\mathcal{Q}\subseteq\Delta(\mathcal{X})\). For \(\alpha,\beta\in(0,1]\) and \(\ell\in\mathbb{N}\), an \((\alpha,\beta,\ell)\)_-list learner for \(\mathcal{Q}\)_ is an algorithm \(\mathcal{L}\colon\mathcal{X}^{m}\to\{L\subseteq\Delta(\mathcal{X}):|L|\leq\ell\}\), such that for any \(p\in\mathcal{Q}\), if we draw a dataset \(\bm{X}=(X_{1},\dots,X_{m})\) i.i.d. from \(p\), then

\[\mathop{\mathbb{P}}_{\bm{X}\sim p^{m}}\left\{\mathrm{dist}(p,\mathcal{L}(\bm{X }))\leq\alpha\right\}\geq 1-\beta.\]

**Definition 3.3** (List learnable class).: A class of distributions \(\mathcal{Q}\subseteq\Delta(\mathcal{X})\) is _list learnable to list size \(\ell(\alpha,\beta)\) with \(m(\alpha,\beta)\) samples_ if for every \(\alpha,\beta\in(0,1]\), letting \(\ell=\ell(\alpha,\beta)\) and \(m=m(\alpha,\beta)\), there is an \((\alpha,\beta,\ell)\)-list-learner for \(\mathcal{Q}\) that takes \(m\) samples.

If \(\mathcal{Q}\) satisfies the above, irrespective of the list size complexity \(\ell(\alpha,\beta)\), we say \(\mathcal{Q}\) is _list learnable with \(m(\alpha,\beta)\) samples_.

Now, we state our reduction of list learning to public-private learning. The key step of our proof is showing that, upon receiving samples \(\bm{\tilde{x}}\), outputting a finite cover of the list of distributions that a public-private learner would succeed on _given public data_\(\bm{\tilde{x}}\) is a successful strategy for list learning.

**Proposition 3.4** (Public-private learning \(\Longrightarrow\) list learning).: _Let \(\mathcal{Q}\subseteq\Delta(\mathcal{X})\). Suppose \(\mathcal{Q}\) is public-privately learnable with \(m_{P}(\alpha,\beta,\varepsilon)\) public and \(n(\alpha,\beta,\varepsilon)\) private samples. Then for all \(\varepsilon>0\), \(\mathcal{Q}\) is list-learnable to list size \(\ell(\alpha,\beta)=\frac{10}{9}\exp(\varepsilon\cdot n(\frac{\alpha}{2},\frac{ \beta}{10},\varepsilon))\) with \(m(\alpha,\beta)=m_{P}(\frac{\alpha}{2},\frac{\beta}{10},\varepsilon)\) samples._

Proof.: Let \(\varepsilon>0\) be arbitrary. Fix any \(\alpha,\beta\in(0,1]\). By assumption, \(\mathcal{Q}\) admits a \((\frac{\alpha}{2},\frac{\beta}{10},\varepsilon)\)-public-private learner \(\mathcal{A}\), which uses \(m\coloneqq m_{P}(\frac{\alpha}{2},\frac{\beta}{10},\varepsilon)\) public and \(n\coloneqq n(\frac{\alpha}{2},\frac{\beta}{10},\varepsilon)\) private samples. We use \(\mathcal{A}\) to construct a \((\alpha,\beta,\frac{10}{9}\exp(\varepsilon n))\)-list learner that uses \(m\) samples. Consider any \(\bm{\tilde{x}}=(\tilde{x}_{1},\dots,\tilde{x}_{m})\in\mathcal{X}^{m}\) and the class

\[\mathcal{Q}_{\bm{\tilde{x}}}=\left\{q\in\mathcal{Q}:\mathop{\mathbb{P}}_{\bm{X} \sim q^{n}}\limits_{Q\sim\mathcal{A}(\bm{\tilde{x}},\bm{X})}\left\{\mathrm{TV}( Q,q)\leq\frac{\alpha}{2}\right\}\geq\frac{9}{10}\right\}.\]Note that by definition, \(\mathcal{Q}_{\tilde{\bm{x}}}\) has a \((\frac{\alpha}{2},\frac{1}{10})\)-learner under \(\varepsilon\)-DP that takes \(n\) samples. Hence, by Fact C.1 it follows that any \(\alpha\)-packing of \(\mathcal{Q}_{\tilde{\bm{x}}}\) must have size \(\leq\frac{10}{9}\exp(\varepsilon n)=\ell\). Let \(\widehat{Q}_{\tilde{\bm{x}}}\) be such a maximal \(\alpha\)-packing, hence it is also an \(\alpha\)-cover of \(\mathcal{Q}_{\tilde{\bm{x}}}\) with \(|\widehat{Q}_{\tilde{\bm{x}}}|\leq\ell\). We define our list learner's output, \(\mathcal{L}(\tilde{\bm{x}})=\widehat{Q}_{\tilde{\bm{x}}}\). It remains to show that for any \(p\in\mathcal{Q}\), with probability \(\geq 1-\beta\) over the sampling of \(\tilde{\bm{X}}\sim p^{m}\), \(\operatorname{dist}(p,\mathcal{L}(\tilde{\bm{X}}))\leq\alpha\). Suppose otherwise, that is, there exists \(p_{0}\in\mathcal{Q}\), such that

\[\operatorname*{\mathbb{P}}_{\tilde{\bm{X}}\sim p_{0}^{m}}\left\{ \operatorname{dist}(p_{0},\mathcal{L}(\tilde{\bm{X}}))>\alpha\right\}>\beta.\]

Since \(\mathcal{L}(\tilde{\bm{X}})\) is a \(\alpha\)-cover of \(\mathcal{Q}_{\tilde{\bm{X}}}\), we have that with probability \(>\beta\) over the sampling of \(\tilde{\bm{X}}\sim p_{0}^{m}\), \(p_{0}\not\in\mathcal{Q}_{\tilde{\bm{X}}}\). This contradicts the success guarantee of \(\mathcal{A}\):

\[\operatorname*{\mathbb{P}}_{\begin{subarray}{c}\tilde{\bm{X}} \sim p_{0}^{m},\bm{X}\sim p_{0}^{m}\\ Q\sim\mathcal{A}(\tilde{\bm{X}},\bm{X})\end{subarray}}\left\{\operatorname{TV }(Q,p_{0})>\frac{\alpha}{2}\right\} \geq\operatorname*{\mathbb{P}}\left\{\operatorname{TV}(Q,p_{0})> \frac{\alpha}{2}\Big{|}p_{0}\not\in\mathcal{Q}_{\tilde{\bm{X}}}\right\}\cdot \operatorname*{\mathbb{P}}\left\{p_{0}\not\in\mathcal{Q}_{\tilde{\bm{X}}}\right\}\] \[>\frac{1}{10}\cdot\beta=\frac{\beta}{10}.\]

The second inequality follows by the definition of \(Q_{\tilde{\bm{X}}}\): conditioned on the event \(p_{0}\not\in\mathcal{Q}_{\tilde{\bm{X}}}\), the probability, over the private samples \(\bm{X}\sim p_{0}^{n}\) and the randomness of the algorithm \(\mathcal{A}\), that the output \(Q\) of our algorithm satisfies \(\operatorname{TV}(Q,p_{0})\leq\frac{\alpha}{2}\) is \(<\frac{9}{10}\). 

### List learning implies compression

We state the final component of Theorem 1.1/D.1: the existence of a list learner for a class of distributions \(\mathcal{Q}\) implies the existence of a sample compression scheme for \(\mathcal{Q}\). This follows from the definitions: given samples \(\tilde{\bm{x}}\), the encoder of the sample compression scheme runs a list learner \(\mathcal{L}\) on \(\tilde{\bm{x}}\). It passes along \(\bm{x}\), and, with knowledge of the target distribution \(q\), the index \(i\) of the distribution in \(\mathcal{L}(\tilde{\bm{x}})\) that is close to \(q\). The decoder receives this information and outputs \(\mathcal{L}(\tilde{\bm{x}})_{i}\). The proof can be found in Appendix D.2.

**Proposition 3.5** (List learning \(\Longrightarrow\) compression).: _Let \(\mathcal{Q}\subseteq\Delta(\mathcal{X})\). Suppose \(\mathcal{Q}\) is list learnable to list size \(\ell(\alpha,\beta)\) with \(m_{L}(\alpha,\beta)\) samples. Then \(\mathcal{Q}\) admits \((\tau(\alpha,\beta),t(\alpha,\beta),m(\alpha,\beta))=(m_{L}(\alpha,\beta),\log_ {2}(\ell(\alpha,\beta)),m_{L}(\alpha,\beta))\) realizable sample compression._

## 4 Applications

Here, we state a few applications of the connections obtained via Theorem 1.1/D.1. First, we recover and extend results on the public-private learnability of high-dimensional Gaussians and mixtures of Gaussians, using known results on sample compression schemes. Second, we describe the closure properties of public-private learnability: if a class \(\mathcal{Q}\) is public-privately learnable, the class of mixtures of \(\mathcal{Q}\) and the class of products of \(\mathcal{Q}\) are also public-privately learnable.

### Public-private learnability of Gaussians and mixtures of Gaussians

There are known realizable sample compression schemes for the class of Gaussians in \(\mathbb{R}^{d}\), as well as for the class of all \(k\)-mixtures of Gaussians in \(\mathbb{R}^{d}\)[20]. Hence, these classes are public-privately learnable.

**Fact 4.1** (Robust compression scheme for Gaussians [1, Lemma 5.3]).: _The class of Gaussians over \(\mathbb{R}^{d}\) admits \((O(d),O(d^{2}\log(\frac{d}{\alpha})),O(d\log(\frac{1}{\beta}))\frac{2}{3}\)-robust sample compression._

**Fact 4.2** (Realizable compression scheme for mixtures of Gaussians [1, Lemma 4.8 applied to Lemma 5.3]).: _The class of \(k\)-mixtures of Gaussians over \(\mathbb{R}^{d}\) admits \((O(kd),O(kd^{2}\log(\frac{d}{\alpha})+\log(\frac{k}{\alpha})),O(\frac{kd\log(k /\beta)\log(1/\beta)}{\alpha}))\) realizable sample compression._

Gaussians.From Theorem 1.1/D.1 and Fact 4.1, we get a public-private learner for Gaussians over \(\mathbb{R}^{d}\) using \(O(d\log(\frac{1}{\beta}))\) public and \(\bar{O}(\frac{d^{2}+\log(1/\beta)}{\alpha^{2}}+\frac{d^{2}+\log(1/\beta)}{ \alpha\varepsilon})\) private samples (Corollary E.1). This recovers the result of [1] on Gaussians up to a factor of \(O(\log(\frac{1}{\beta}))\) in public sample complexity, and improves the private sample complexity by a \(\operatorname{polylog}(1/\beta)\) factor.

Mixtures of Gaussians.From Theorem 1.1/D.1 and Fact 4.2, we get a public-private learner for the class of \(k\)-mixtures of Gaussians in \(\mathbb{R}^{d}\) using \(\tilde{O}(\frac{kd\log^{2}(1/\beta)}{\alpha})\) public and \(\tilde{O}(\frac{kd^{2}+\log(1/\beta)}{\alpha^{2}}+\frac{kd^{2}+\log(1/\beta)}{ \alpha\varepsilon})\) private samples (Theorem 1.2/Corollary E.2).

In terms of \(k,d\), and \(\alpha\), the public sample complexity of this learner is less than the \(\tilde{\Theta}(\frac{kd^{2}}{\alpha^{2}})\) necessary and sufficient sample complexity for the problem non-privately [1]. This also implies that in the regime where \(\varepsilon>\alpha\), having more public samples (but still \(\tilde{o}(\frac{kd^{2}}{\alpha^{2}})\)) cannot improve private sample complexity. Under pure DP, no finite sample size suffices; under approximate DP, \(\tilde{O}(\frac{k^{2}d^{4}\log(1/\delta)}{\alpha^{2}\varepsilon})\) has been shown to suffice [1].

Algorithms for _parameter estimation_, like the mixture of Gaussians estimators from [1] cannot be directly compared as they target a strictly stronger success criteria under stronger assumptions on the underlying distribution. [1] gives an estimator for separated Gaussian mixtures that uses \(\tilde{O}(\frac{d\log(k)}{w_{*}})\) public and \(\tilde{O}(\frac{d^{2}}{w_{*}\alpha^{2}}+\frac{d^{2}}{w_{*}\alpha^{2}})\) private samples satisfying \(\frac{\varepsilon^{2}}{2}\)-zCDP, where \(w_{*}\) is the minimum component mixing weight. In terms of the privacy guarantee and private sample complexity, our result is a strict improvement for density estimation, since \(k=O(\frac{1}{w_{*}})\). In the setting where \(w_{*}=\Omega(\frac{1}{k})\), [1]'s algorithm uses \(\frac{1}{\alpha}\)-factor fewer public samples. Furthermore, their algorithm runs in time polynomial in the sample complexity.

### Public-private learnability of mixture and product distributions

If a class is realizably compressible, the class of its \(k\)-mixtures and the class of its \(k\)-products are also realizably compressible. Being realizably compressible with \(O(m(\alpha,\beta))\) samples is equivalent to being public-privately learnable with \(O(m(\alpha,\beta))\) public samples. Hence, we have black-box reductions of public-private learnability of mixture/product classes to public-private learnability of their base classes.

**Theorem 4.3** (Public-private learning for mixture and product distributions (Informal; see Theorems E.5 and E.7)).: _Let \(k\geq 1\). If \(\mathcal{Q}\subseteq\Delta(\mathcal{X})\) is public-privately learnable with \(m(\alpha,\beta,\varepsilon)\) public samples, then for any \(\varepsilon_{0}>0\):_

1. _The class of_ \(k\)_-mixtures of_ \(\mathcal{Q}\) _is public-privately learnable with_ \(O(\frac{k\log(k/\beta)}{\alpha}\cdot m(\alpha,\beta,\varepsilon_{0}))\) _public samples._
2. _The class of_ \(k\)_-products of_ \(\mathcal{Q}\) _(over_ \(\mathcal{X}^{k}\)_) is public-privately learnable with_ \(O(\log(\frac{k}{\beta})\cdot m(\alpha/k,\beta,\varepsilon_{0}))\) _public samples._

The full statements and proof can be found in Appendix E.2. Here, we use the non-constructive reduction of list learning to public-private learning, and hence this does not yield a finite time algorithm. Note also that the target privacy \(\varepsilon\) does not appear in the public sample complexity (it only affects the amount of private samples required).

## 5 Agnostic and distribution-shifted public-private learning

The setting we have examined thus far makes the following assumptions on the data generation process: (1) _same distribution_ - public and private data are sampled from the same underlying distribution; and (2) _realizability_ - public and private data are sampled from members of the class \(\mathcal{Q}\).

[1] shows that for Gaussians over \(\mathbb{R}^{d}\), the first condition can be relaxed: they give an algorithm for the case where the public and the private data are generated from different Gaussians with bounded TV distance. However, they do not remove the second assumption.

We show that for general classes of distributions that _robust_ compression schemes yield public-private learners, which: (1) can handle public-private distribution shifts (i.e., the setting where the public data and the private data distributions can be different); and (2) are agnostic, i.e., they do not require samples to come from a member of \(\mathcal{Q}\), and instead, promise error close to the best approximation of the private data distribution by a member of \(\mathcal{Q}\). Since Gaussians admit a robust compression scheme (Fact 4.1), we obtain public-private Gaussian learners that work under relaxed forms of these assumptions on the data generating process (Theorem 1.3/F.1).

We first formally define the notion of _agnostic and distribution-shifted public-private learning_, and then prove the main result of this section.

**Definition 5.1** (Agnostic and distribution-shifted public-private learner).: Let \(\mathcal{Q}\subseteq\Delta(\mathcal{X})\). For \(\alpha,\beta\in(0,1]\), \(\varepsilon>0\), \(\gamma\in[0,1]\), and \(c\geq 1\) a \(\gamma\)_-shifted \(c\)-agnostic \((\alpha,\beta,\varepsilon)\)-public-private learner for \(\mathcal{Q}\)_ is a public-private \(\varepsilon\)-DP algorithm \(\mathcal{A}:\mathcal{X}^{m}\times\mathcal{X}^{n}\to\Delta(\Delta(\mathcal{X}))\), such that for any \(\tilde{p},p\in\Delta(\mathcal{X})\) with \(\mathrm{TV}(\tilde{p},p)\leq\gamma\), if we draw datasets \(\tilde{\bm{X}}=(\tilde{X}_{1},\ldots,\tilde{X}_{m})\) i.i.d. from \(\tilde{p}\) and \(\bm{X}=(X_{1},\ldots,X_{n})\) i.i.d. from \(p\), and then \(Q\sim\mathcal{A}(\tilde{\bm{X}},\bm{X})\),

\[\begin{array}{l}\mathbb{P}\\ \mathop{\bm{\hat{X}}\sim\tilde{p}^{m},\bm{X}\sim p^{n}}_{Q\sim\mathcal{A}( \tilde{\bm{X}},\bm{X})}\\ \end{array}\{\mathrm{TV}(Q,p)\leq c\cdot\mathrm{dist}(p,\mathcal{Q})+\alpha \}\geq 1-\beta.\]

**Theorem 5.2** (Robust compression \(\Longrightarrow\) agnostic and distribution-shifted public-private learning).: _Let \(\mathcal{Q}\subseteq\Delta(\mathcal{X})\) and \(r>0\). If \(\mathcal{Q}\) admits \((\tau(\alpha,\beta),t(\alpha,\beta),m_{C}(\alpha,\beta))\)\(r\)-robust compression, then for every \(\alpha,\beta\in(0,1]\) and \(\varepsilon>0\), there exists a \(\frac{r}{2}\)-shifted \(\frac{r}{r}\)-agnostic \((\alpha,\beta,\varepsilon)\)-public-private learner for \(\mathcal{Q}\) that uses \(m(\alpha,\beta,\varepsilon)=m_{C}(\frac{\alpha}{12},\frac{\beta}{2})\) public samples and \(n(\alpha,\beta,\varepsilon)=O((\frac{1}{\alpha^{2}}+\frac{1}{\alpha\varepsilon })\cdot(t(\frac{\alpha}{12},\frac{\beta}{2})+\tau(\frac{\alpha}{12},\frac{ \beta}{2})\log(m_{C}(\frac{\alpha}{12},\frac{\beta}{2}))+\log(\frac{1}{\beta} )))\) private samples._

Proof.: The proof again mirrors the proof of Theorem 4.5 in [1]. The key observation (and difference from the proof in Appendix D.1) is the following: for the unknown distribution \(p\in\Delta(\mathcal{X})\), consider \(\mathrm{dist}(p,\mathcal{Q})\). If \(\mathrm{dist}(p,\mathcal{Q})\geq\frac{r}{2}\), the output \(Q\) of any algorithm satisfies \(\mathrm{TV}(p,Q)\leq 1\leq\frac{2}{r}\cdot\mathrm{dist}(p,\mathcal{Q})\). Hence, we can assume \(\mathrm{dist}(p,\mathcal{Q})<\frac{r}{2}\), and let \(q_{*}\in\mathcal{Q}\) with \(\mathrm{TV}(p,q_{*})<\min\left\{\frac{r}{2},\mathrm{dist}(p,\mathcal{Q})+\frac {\alpha}{12}\right\}\) as guaranteed by such.

By triangle inequality, \(\mathrm{TV}(\tilde{p},q_{*})<r\). This implies that when we generate hypotheses \(\widehat{\mathcal{Q}}\) to choose from using the \(r\)-robust sample compression with samples from \(\tilde{p}\), with high probability there will be some \(q\in\widehat{\mathcal{Q}}\) with \(\mathrm{TV}(q,q_{*})\leq\frac{\alpha}{12}\). We have

\[\mathrm{TV}(p,q)\leq\mathrm{TV}(p,q_{*})+\mathrm{TV}(q_{*},q)\leq\mathrm{dist }(p,\mathcal{Q})+\frac{\alpha}{12}+\frac{\alpha}{12}=\frac{\alpha}{6}.\]

Applying the 3-agnostic \(\varepsilon\)-DP learner for finite classes from [1] (Fact C.2) with the above setting of \(n\) gives us the result. 

## 6 Lower bounds

We give a lower bound on the number of public samples required to public-privately learn Gaussians in \(\mathbb{R}^{d}\). We know that Gaussians in \(\mathbb{R}^{d}\) are public-privately learnable with \(d+1\) public samples from [1]. We show that this is within \(1\) of the optimal: the class of Gaussians in \(\mathbb{R}^{d}\) is _not public-privately learnable_ with \(d-1\) public samples. The following is the formal statement of Theorem 1.4.

**Theorem 6.1**.: _The class \(\mathcal{Q}\) of all Gaussians in \(\mathbb{R}^{d}\) is not public-private learnable with \(m_{P}(\alpha,\beta,\varepsilon)=d-1\) public samples, regardless of the number of private samples. That is, there exists \(\alpha_{d},\beta_{d}>0\) such that for any \(n\in\mathbb{N}\), \(\mathcal{Q}\) does not admit a \((\alpha_{d},\beta_{d},1)\)-public-private learner using \(d-1\) public and \(n\) private samples._

Our result leverages the connection between public-private learning and list learning. The existence of such a public-private learner described above would imply the existence of a list learner for \(d\)-dimensional Gaussians taking \(d-1\) samples as input. We show, using a "no-free-lunch"-style argument (e.g. Theorem 5.1 from [1]) that such a list learner cannot exist. The proof of Theorem 6.1, given in Appendix G, goes through the following steps.

1. We reduce list learning to public-private learning, via Proposition 3.4;
2. We establish a technical lemma that relates the PAC guarantee of a list learner with its average performance over a set of problem instances, via a "no-free-lunch"-style argument (Lemma G.1);
3. For every \(d\geq 2\), we find a sequence of hard subclasses of Gaussians over \(\mathbb{R}^{d}\), which satisfy the conditions of Lemma G.1. This forms the set of hard problem instances that imply a lower bound on the error of any list learner for the class (does not receive enough samples);4. Since list learning to arbitrary error with few samples is impossible, public-private learning to arbitrary error with few public samples must also be impossible.

## 7 Learning when the Yatracos class has finite VC dimension

In this section, we describe a public-private learner for classes of distributions whose _Yatracos class_ has finite VC dimension. We start by defining the Yatracos class of a family of distributions.

**Definition 7.1** (Yatracos class).: For \(\mathcal{Q}\subseteq\Delta(\mathcal{X})\), the _Yatracos class_ of \(\mathcal{Q}\) is given by

\[\mathcal{H}=\{\{x\in\mathcal{X}:p(x)>q(x)\}:p\neq q\in\mathcal{Q}\}.\lx@note{ footnote}{This is for when the distributions in $\mathcal{Q}$ are discrete. For classes of continuous distributions, we substitute $p$ and $q$ for their respective density functions.}\]

**Theorem 7.2**.: _Let \(\mathcal{Q}\subseteq\Delta(\mathcal{X})\). Let \(\mathcal{H}\) be the Yatracos class of \(\mathcal{Q}\), denote by \(\mathrm{VC}(\mathcal{H})\) and \(\mathrm{VC}^{*}(\mathcal{H})\) the \(\mathrm{VC}\) and dual \(\mathrm{VC}\) dimension of \(\mathcal{H}\). \(\mathcal{Q}\) is public-privately learnable with \(m\) public and \(n\) private samples, where_

\[m=O\left(\frac{\mathrm{VC}(\mathcal{H})\log\left(\frac{1}{\alpha}\right)+\log \left(\frac{1}{\beta}\right)}{\alpha}\right)\quad\text{and}\quad n=O\left( \frac{\mathrm{VC}(\mathcal{H})^{2}\,\mathrm{VC}^{*}(\mathcal{H})+\log(\frac{1 }{\beta})}{\varepsilon\alpha^{3}}\right).\]

Theorem 7.2/1.5 says that classes of distributions whose Yatracos class have finite VC dimension can be public-privately learned. Note that the number of public samples used is indeed fewer than the \(O(\frac{\mathrm{VC}(\mathcal{H})}{\alpha^{2}})\) sample requirement in the non-private analogue of the result (Fact H.1).

The proof is given in Appendix H. The result is a consequence of a known public-private uniform convergence result [BCM\({}^{+}\)20, Theorem 10]. To adapt it to our setting, we (1) modify their result for pure DP (rather than approximate DP); and (2) conclude that uniform convergence over the Yatracos sets of \(\mathcal{Q}\) suffices to implement the learner from Fact H.1.

## 8 Conclusion

In this work, we connect public-private distribution learning to the notions of sample compression and list learning. In doing so, for broad classes of distributions, we introduce approaches to: (1) design sample-efficient public-private learners; (2) prove lower bounds on how much public data is required for public-private learnability. In the following, we list several questions for future study.

**Question 8.1**.: _For a class \(\mathcal{Q}\), our work examines the minimal amount of public data needed to render \(\mathcal{Q}\) pure privately learnable. How much do we need to render \(\mathcal{Q}\) approximate DP learnable?_

**Question 8.2**.: _The VC bound of Theorem 1.5/7.2, although more general, is "qualitatively" loose. For Gaussians, it yields a \(O(\frac{d^{2}}{\alpha})\) public sample complexity, though we know \(O(d)\) is possible, notably with no dependence on \(\alpha\). On the other hand, \(\Omega(1/\alpha)\) public samples are required for public-privately learning mixtures of Gaussians. What qualities of a distribution admit public-private learning with \(\alpha\)-independent public sample complexity? Stronger: can we find more illuminating characterizations of the sample complexity of list learning?_

**Question 8.3**.: _Our work studies sample complexity improvements from using public data. Can public data lead to algorithmic improvements, that is, runtime efficiency or simpler algorithms?_

## Acknowledgments and Disclosure of Funding

We thank the anonymous reviewers for their helpful feedback.

AB, GK, and VS acknowledge funding from an NSERC discovery grant. AB is supported by a David R. Cheriton Graduate Scholarship. CC is supported by an ARC DECRA and an unrestricted gift from Google. GK is supported by a Canada CIFAR AI Chair, an unrestricted gift from Google, a University of Waterloo startup grant, and an unrestricted gift from Apple.

## References

* [AAAAK21] Ishaq Aden-Ali, Hassan Ashtiani, and Gautam Kamath. On the sample complexity of privately learning unbounded high-dimensional Gaussians. In _Proceedings of the 32nd International Conference on Algorithmic Learning Theory (ALT'21)_, 2021.
* [AABD\({}^{+}\)20] Sushant Agarwal, Nivasini Ananthakrishnan, Shai Ben-David, Tosca Lechner, and Ruth Urner. On learnability wih computable learners. In _Proceedings of the 31st International Conference on Algorithmic Learning Theory (ALT'20)_, 2020.
* [AAL21] Ishaq Aden-Ali, Hassan Ashtiani, and Christopher Liaw. Privately learning mixtures of axis-aligned Gaussians. In _Advances in Neural Information Processing Systems 34 (NeurIPS'21)_, 2021.
* [AAL23a] Mohammad Afzali, Hassan Ashtiani, and Christopher Liaw. Mixtures of gaussians are privately learnable with a polynomial number of samples. _CoRR_, abs/2309.03847, 2023.
* [AAL23b] Jamil Arbas, Hassan Ashtiani, and Christopher Liaw. Polynomial time and private learning of unbounded Gaussian mixture models. In _Proceedings of the 40th International Conference on Machine Learning (ICML'23)_, 2023.
* [ABDH\({}^{+}\)20] Hassan Ashtiani, Shai Ben-David, Nicholas J. A. Harvey, Christopher Liaw, Abbas Mehrabian, and Yaniv Plan. Near-optimal sample complexity bounds for robust learning of Gaussian mixtures via compression schemes. _J. ACM_, 67(6), 2020.
* [ABM19] Noga Alon, Raef Bassily, and Shay Moran. Limits of private learning with access to public data. In _Advances in Neural Information Processing Systems 32 (NeurIPS'19)_, 2019.
* [Abo18] John M. Abowd. The U.S. Census Bureau adopts differential privacy. In _Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining_, 2018.
* [ACG\({}^{+}\)16] Martin Abadi, Andy Chu, Ian Goodfellow, H. Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. Deep learning with differential privacy. In _CCS'16: 2016 ACM SIGSAC Conference on Computer and Communications Security_, 2016.
* [ADK20] Brendan Avent, Yatharth Dubey, and Aleksandra Korolova. The power of the hybrid model for mean estimation. _Proc. Priv. Enhancing Technol._, 2020(4):48-68, 2020.
* [AGM\({}^{+}\)22] Ehsan Amid, Arun Ganesh, Rajiv Mathews, Swaroop Ramaswamy, Shuang Song, Thomas Steinke, Vinith M. Suriyakumar, Om Thakkar, and Abhradeep Thakurta. Public data-assisted mirror descent for private model training. In _Proceedings of the 39th International Conference on Machine Learning (ICML 22)_, 2022.
* [AKZ\({}^{+}\)17] Brendan Avent, Aleksandra Korolova, David Zeber, Torgeir Hovden, and Benjamin Livshits. BLENDER: Enabling local search with a hybrid differential privacy model. In _26th USENIX Security Symposium (USENIX Security'17)_, 2017.
* [AL22] Hassan Ashtiani and Christopher Liaw. Private and polynomial time algorithms for learning Gaussians and beyond. In _Proceedings of the 35th Annual Conference on Learning Theory (COLT'22)_, 2022.
* [AM18] Hassan Ashtiani and Abbas Mehrabian. Some techniques in density estimation. _arXiv preprint arXiv:1801.04003_, 2018.
* [App17] Differential Privacy Team, Apple. Learning with privacy at scale, 2017.
* [Ass83] Patrick Assouad. Densite et dimension. _Annales de l'Institut Fourier_, 33(3):233-282, 1983.
* [ASZ21] Jayadev Acharya, Ziteng Sun, and Huanyu Zhang. Differentially private assouad, fano, and le cam. In _Proceedings of the 32nd International Conference on Algorithmic Learning Theory_, ALT '21, pages 48-78. JMLR, Inc., 2021.

* [BBV08] Maria-Florina Balcan, Avrim Blum, and Santosh Vempala. A discriminative framework for clustering via similarity functions. In _Proceedings of the Fortieth Annual ACM Symposium on Theory of Computing_, STOC '08, page 671-680, New York, NY, USA, 2008. Association for Computing Machinery.
* [BCM\({}^{+}\)20] Raef Bassily, Albert Cheu, Shay Moran, Aleksandar Nikolov, Jonathan R. Ullman, and Steven Wu. Private query release assisted by public data. In _Proceedings of the 37th International Conference on Machine Learning (ICML'20)_, 2020.
* [BKS22] Alex Bie, Gautam Kamath, and Vikrant Singhal. Private estimation with public data. In _Advances in Neural Information Processing Systems 35 (NeurIPS'22)_, 2022.
* [BKSW19] Mark Bun, Gautam Kamath, Thomas Steinke, and Zhiwei Steven Wu. Private hypothesis selection. In _Advances in Neural Information Processing Systems 32_, NeurIPS '19, pages 156-167. Curran Associates, Inc., 2019.
* [BLR13] Avrim Blum, Katrina Ligett, and Aaron Roth. A learning theory approach to noninteractive database privacy. _Journal of the ACM_, 60(2):1-25, 2013.
* [BMN20] Raef Bassily, Shay Moran, and Anupama Nandi. Learning from mixtures of private and public populations. In _Advances in Neural Information Processing Systems 33_, NeurIPS '20, pages 2947-2957. Curran Associates, Inc., 2020.
* [BNS16] Amos Beimel, Kobbi Nissim, and Uri Stemmer. Private learning and sanitization: Pure vs. approximate differential privacy. _Theory of Computing_, 12(1):1-61, 2016.
* [BTGT18] Raef Bassily, Om Thakkar, and Abhradeep Guha Thakurta. Model-agnostic private learning. In _Advances in Neural Information Processing Systems 31_, NeurIPS '18, pages 7102-7112. Curran Associates, Inc., 2018.
* [CCd\({}^{+}\)23] Hongjie Chen, Vincent Cohen-Addad, Tommaso d'Orsi, Alessandro Epasto, Jacob Imola, David Steurer, and Stefan Tiegel. Private estimation algorithms for stochastic block models and mixture models. _arXiv preprint arXiv:2301.04822_, 2023.
* [CDE\({}^{+}\)23] Rachel Cummings, Damien Desfontaines, David Evans, Roxana Geambasu, Matthew Jagielski, Yangsibo Huang, Peter Kairouz, Gautam Kamath, Sewoong Oh, Olga Ohrimenko, Nicolas Papernot, Ryan Rogers, Milan Shen, Shuang Song, Weijie Su, Andreas Terzis, Abhradeep Thakurta, Sergei Vassilvitskii, Yu-Xiang Wang, Li Xiong, Sergey Yekhanin, Da Yu, Huanyu Zhang, and Wanrong Zhang. Challenges towards the next frontier in privacy. _arXiv preprint arXiv:2304.06929_, 2023.
* [CKM\({}^{+}\)21] Edith Cohen, Haim Kaplan, Yishay Mansour, Uri Stemmer, and Eliad Tsfadia. Differentially-private clustering of easy instances. In Marina Meila and Tong Zhang, editors, _Proceedings of the 38th International Conference on Machine Learning_, volume 139 of _Proceedings of Machine Learning Research_, pages 2049-2059. PMLR, 18-24 Jul 2021.
* [CSV17] Moses Charikar, Jacob Steinhardt, and Gregory Valiant. Learning from untrusted data. In _Proceedings of the 49th Annual ACM Symposium on the Theory of Computing_, STOC '17, pages 47-60, New York, NY, USA, 2017. ACM.
* [DKS18] Ilias Diakonikolas, Daniel M. Kane, and Alistair Stewart. List-decodable robust mean estimation and learning mixtures of spherical Gaussians. In _Proceedings of the 50th Annual ACM Symposium on the Theory of Computing_, STOC '18, pages 1047-1060, New York, NY, USA, 2018. ACM.
* [DL01] Luc Devroye and Gabor Lugosi. _Combinatorial Methods in Density Estimation_. Springer Series in Statistics. Springer New York, 2001.
* [DMNS06] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in private data analysis. In _Proceedings of the 3rd Conference on Theory of Cryptography (TCC'06)_, 2006.

* [DMR18] Luc Devroye, Abbas Mehrabian, and Tommy Reddad. The total variation distance between high-dimensional Gaussians. _arXiv preprint arXiv:1810.08693_, 2018.
* [DR14] Cynthia Dwork and Aaron Roth. The algorithmic foundations of differential privacy. _Foundations and Trends(r) in Theoretical Computer Science_, 9(3-4):211-407, 2014.
* [GHN\({}^{+}\)23] Arun Ganesh, Mahdi Haghifam, Milad Nasr, Sewoong Oh, Thomas Steinke, Om Thakkar, Abhradeep Guha Thakurta, and Lun Wang. Why is public pretraining necessary for private model training? In _Proceedings of the 40th International Conference on Machine Learning (ICML'23)_, 2023.
* [GKW23] Xin Gu, Gautam Kamath, and Zhiwei Steven Wu. Choosing public datasets for private machine learning via gradient subspace distance. _arXiv preprint arXiv:2303.01256_, 2023.
* [Goo19a] Google. Google's differential privacy libraries. https://github.com/google/differential-privacy, 2019. Accessed 07/31/2023.
* [Goo19b] Google. TensorFlow privacy. https://github.com/tensorflow/privacy, 2019. Accessed 07/31/2023.
* [HASP22] Frederik Harder, Milad Jalali Asadabadi, Danica J. Sutherland, and Mijung Park. Differentially private data generation needs better features. _CoRR_, abs/2205.12900, 2022.
* [HBAL19] Naoise Holohan, Stefano Braghin, Pol Mac Aonghusa, and Killian Levacher. Diff-privlib: The IBM differential privacy library. _CoRR_, abs/1907.02444, 2019.
* [JE13] Zhanglong Ji and Charles Elkan. Differential privacy based on importance weighting. _Machine Learning_, 93(1):163-183, 2013.
* [KADV23] Mikhail Khodak, Kareem Amin, Travis Dick, and Sergei Vassilvitskii. Learning-augmented private algorithms for multiple quantile release. In _Proceedings of the 40th International Conference on Machine Learning (ICML'23)_, 2023.
* [KLSU19] Gautam Kamath, Jerry Li, Vikrant Singhal, and Jonathan R. Ullman. Privately learning high-dimensional distributions. In _Proceedings of the 32nd Annual Conference on Learning Theory (COLT'19)_, 2019.
* [KMS\({}^{+}\)22] Gautam Kamath, Argyris Mouzakis, Vikrant Singhal, Thomas Steinke, and Jonathan R. Ullman. A private and computationally-efficient estimator for unbounded Gaussians. In _Proceedings of the 35th Annual Conference on Learning Theory (COLT'22)_, 2022.
* [KMV22] Pravesh K. Kothari, Pasin Manurangsi, and Ameya Velingker. Private robust estimation by stabilizing convex relaxations. In _Proceedings of the 35th Annual Conference on Learning Theory (COLT'22)_, 2022.
* [KRRT21] Peter Kairouz, Monica Ribero, Keith Rush, and Abhradeep Thakurta. (nearly) dimension independent private ERM with adagrad rates via publicly estimated subspaces. In _Proceedings of the 34th Annual Conference on Learning Theory_, COLT '21, pages 2717-2746, 2021.
* [KS17] Pravesh K. Kothari and Jacob Steinhardt. Better agnostic clustering via relaxed tensor norms, 2017.
* [KS22] Refael Kohen and Or Sheffet. Transfer learning in differential privacy's hybrid-model. In _Proceedings of the 39th International Conference on Machine Learning (ICML'22)_, 2022.
* [KSSU19] Gautam Kamath, Or Sheffet, Vikrant Singhal, and Jonathan Ullman. Differentially private algorithms for learning mixtures of separated Gaussians. In _Advances in Neural Information Processing Systems 32_, NeurIPS '19, pages 168-180. Curran Associates, Inc., 2019.

* [KV18] Vishesh Karwa and Salil P. Vadhan. Finite sample differentially private confidence intervals. In _9th Innovations in Theoretical Computer Science Conference (ITCS'18)_, 2018.
* [Li10] Shengqiao Li. Concise formulas for the area and volume of a hyperspherical cap. _Asian Journal of Mathematics & Statistics_, 4(1):66-70, 2010.
* [LKO22] Xiyang Liu, Weihao Kong, and Sewoong Oh. Differential privacy and robust statistics in high dimensions. In _Proceedings of the 35th Annual Conference on Learning Theory_, COLT '22, pages 1167-1246, 2022.
* [LLHR23] Andrew Lowy, Zeman Li, Tianjian Huang, and Meisam Razaviyayn. Optimal differentially private learning with public data. _CoRR_, abs/2306.15056, 2023.
* [LTLH22] Xuechen Li, Florian Tramer, Percy Liang, and Tatsunori Hashimoto. Large language models can be strong differentially private learners. In _Proceedings of the 10th International Conference on Learning Representations_, ICLR '22, 2022.
* [LVS\({}^{+}\)21] Terrance Liu, Giuseppe Vietri, Thomas Steinke, Jonathan Ullman, and Steven Wu. Leveraging public data for practical private query release. In _Proceedings of the 38th International Conference on Machine Learning_, ICML '21, pages 6968-6977. JMLR, Inc., 2021.
* [LW86] Nick Littlestone and Manfred Warmuth. Relating data compression and learnability, 1986.
* [LNAFF21] Zelun Luo, Daniel J Wu, Ehsan Adeli, and Li Fei-Fei. Scalable differential privacy with sparse network finetuning. In _Proceedings of the 2021 IEEE Computer Society Conference on Computer Vision and Pattern Recognition_, CVPR '21, pages 5059-5068, Washington, DC, USA, 2021. IEEE Computer Society.
* [MY16] Shay Moran and Amir Yehudayoff. Sample compression schemes for VC classes. _Journal of the ACM_, 63(3):1-10, 2016.
* [NB20] Anupama Nandi and Raef Bassily. Privately answering classification queries in the agnostic PAC model. In _Proceedings of the 31st International Conference on Algorithmic Learning Theory_, ALT '20, pages 687-703. JMLR, Inc., 2020.
* [NRS07] Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith. Smooth sensitivity and sampling in private data analysis. In _Proceedings of the 39th Annual ACM Symposium on the Theory of Computing_, STOC '07, pages 75-84, New York, NY, USA, 2007. ACM.
* [Ope20] OpenDP Team. The OpenDP white paper, 2020.
* [PAE\({}^{+}\)17] Nicolas Papernot, Martin Abadi, Ulfar Erlingsson, Ian Goodfellow, and Kunal Talwar. Semi-supervised knowledge transfer for deep learning from private training data. In _Proceedings of the 5th International Conference on Learning Representations_, ICLR '17, 2017.
* [PCS\({}^{+}\)19] Nicolas Papernot, Steve Chien, Shuang Song, Abhradeep Thakurta, and Ulfar Erlingsson. Making the shoe fit: Architectures, initializations, and tuning for learning with privacy. https://openreview.net/forum?id=rJg851rYvH, 2019.
* [PSM\({}^{+}\)18] Nicolas Papernot, Shuang Song, Ilya Mironov, Ananth Raghunathan, Kunal Talwar, and Ulfar Erlingsson. Scalable private learning with PATE. In _Proceedings of the 6th International Conference on Learning Representations_, ICLR '18, 2018.
* [RY20] Prasad Raghavendra and Morris Yau. List decodable learning via sum of squares. In Shuchi Chawla, editor, _Proceedings of the 2020 ACM-SIAM Symposium on Discrete Algorithms, SODA 2020, Salt Lake City, UT, USA, January 5-8, 2020_, pages 161-180. SIAM, 2020.

* [SSBD14] Shai Shalev-Shwartz and Shai Ben-David. _Understanding Machine Learning: From Theory to Algorithms_. Cambridge University Press, 2014.
* [TB21] Florian Tramer and Dan Boneh. Differentially private learning needs better features (or much more data). In _Proceedings of the 9th International Conference on Learning Representations_, ICLR '21, 2021.
* [TCK\({}^{+}\)22] Eliad Tsfadia, Edith Cohen, Haim Kaplan, Yishay Mansour, and Uri Stemmer. FriendlyCore: Practical differentially private aggregation. In _Proceedings of the 39th International Conference on Machine Learning (ICML '22)_, 2022.
* [TKC22] Florian Tramer, Gautam Kamath, and Nicholas Carlini. Considerations for differentially private learning with large-scale public pretraining. _arXiv preprint arXiv:2212.06470_, 2022.
* [VW02] Santosh Vempala and Grant Wang. A spectral algorithm for learning mixtures of distributions. In _Proceedings of the 43rd Annual IEEE Symposium on Foundations of Computer Science_, FOCS '02, pages 113-123, Washington, DC, USA, 2002. IEEE Computer Society.
* [XZA\({}^{+}\)23] Zheng Xu, Yanxiang Zhang, Galen Andrew, Christopher A. Choquette-Choo, Peter Kairouz, H. Brendan McMahan, Jesse Rosenstock, and Yuanbo Zhang. Federated learning of Gboard language models with differential privacy. In _Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (ACL'23)_, 2023.
* [Yat85] Yannis G. Yatracos. Rates of convergence of minimum distance estimators and Kolmogorov's entropy. _The Annals of Statistics_, 13(2):768-774, 1985.
* [YNB\({}^{+}\)22] Da Yu, Saurabh Naik, Arturs Backurs, Sivakanth Gopi, Husevin A Inan, Gautam Kamath, Janardhan Kulkarni, Yin Tat Lee, Andre Manoel, Lukas Wutschitz, Sergey Yekhanin, and Huishuai Zhang. Differentially private fine-tuning of language models. In _Proceedings of the 10th International Conference on Learning Representations_, ICLR '22, 2022.
* [YZCL21] Da Yu, Huishuai Zhang, Wei Chen, and Tie-Yan Liu. Do not let privacy overbill utility: Gradient embedding perturbation for private learning. In _Proceedings of the 9th International Conference on Learning Representations_, ICLR '21, 2021.
* [ZWB21] Yingxue Zhou, Zhiwei Steven Wu, and Arindam Banerjee. Bypassing the ambient dimension: Private SGD with gradient subspace identification. In _Proceedings of the 9th International Conference on Learning Representations_, ICLR '21, 2021.

Extended related work

Privately learning Gaussians.Our work studies the task of learning arbitrary, unbounded Gaussians while offering differential privacy guarantees. Basic private algorithms for the task (variants of "clip-and-noise") impose boundedness assumptions on the underlying parameters of the unknown Gaussian, since their sample complexities grow to infinity as the bounds widen to include more allowed distributions. Understanding these dependencies without public data has been a topic of significant study. [14] examined univariate Gaussians, showing that logarithmic dependencies on parameter bounds are necessary and sufficient in the case of pure DP, but can be removed under approximate DP. The same is true in the multivariate setting [1, 15, 16, 17, 18, 19, 20, 21] shows that instead of relaxing to approximate DP to handle arbitrary Gaussians, one can employ a small amount of public data; our lower bound tells us almost exactly how much is needed. Furthermore, our reductions between public-private learning and list learning offers the conclusion that the role of public data is precisely for bounding: distribution classes that can be privately learned with a small amount of public data _are exactly_ the distributions that can be bounded with a small amount of public data.

Privately learning mixtures of Gaussians.Another line of related work is that on privately learning mixtures of Gaussian, but without any public data. [14] provided a subsample-and-aggregate approach to learn the parameters of mixtures of spherical Gaussians based on the work by [13] under the weaker, approximate DP. Recently, [20] improved on this by weakening the separation condition required for the mixture components. [15] provided the first polynomial-time, approximate DP algorithms to learn the parameters of non-spherical Gaussians under weak boundedness assumptions. [20] improved on their work both in terms of the sample complexity and the separation assumption. [1] provided a polynomial-time reduction for privately and efficiently learning mixtures of unbounded Gaussians from the approximate DP setting to its non-private counterpart (albeit at a polynomial overhead in the sample complexity).

Our work falls into the category of private density estimation, for which [1] gave new algorithms for the special case of spherical Gaussians under approximate DP, while [1] gave (computationally inefficient) algorithms for bounded Gaussians under pure DP. For comparison, the latter would have infinite sample complexity for unbounded Gaussians, but our work provides finite private sample complexity even under pure DP using public data. On the other hand, [1] showed hardness results for privately learning mixtures of Gaussians with known covariances. The concurrent work of Azfali, Ashtiani, and Liaw [1] gives the first learnability result for general high-dimensional mixtures of Gaussians under approximate differential privacy.

Theory for private algorithms with public data.Beyond distribution learning, there is a lot more work that investigates how public data can be employed in private data analysis. Some specific areas include private query release, synthetic data generation, and classification [1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], and the results are a mix of theoretical versus empirical. The definition of public-private algorithms that we adopt is from [1], which studied classification in the PAC model. The VC dimension bound we give for public-private distribution learning relies on results from public-private classification [1] and uniform convergence [2].

A concurrent and independent work [10] also studies learning with public and private data, focusing on the problems of mean estimation, empirical risk minimization, and stochastic convex optimization. The focus of the two works is somewhat different, both in terms of the type of problems considered (we study density estimation) and the type of results targeted. That is, our objective is to draw connections between different learning concepts and exploring the resulting implications for public-private distribution learning, while their goal seems to be understanding the precise error rates for some fundamental settings.

Private machine learning with public data.Within the context of private machine learning, there has been significant interest in how to best employ public data. The most popular method is pre-training [1, 1, 10, 11, 12, 1, 13, 14, 15, 16, 17, 18, 19, 20, 21] (though some caution about this practice [14]), while other methods involve computing statistics about the private gradients [13, 15, 16, 17, 18, 19, 20], or training a student model [12, 13, 14, 15]. For more discussion of public data for private learning, see Section 3.1 of [16].

List learningWe also use the notion of _list learning_ in this work, which is a "non-robust" version of the well-known _list-decodable learning_[1, 1, 1, 1, 10, 11], where the goal is still to output a list of distributions that contains one that is accurate with respect to the true distribution, but the sampling may happen from a corrupted version of the underlying distribution.

Hybrid differential privacy.Finally, a related setting is the hybrid model, in which samples require either local or central differential privacy [1]. Some learning tasks studied in this model include mean estimation [1] and transfer learning [11].

## Appendix B Technical overview

New connections for public-private learning.Our first contribution is establishing connections between sample compression, public-private learning, and list learning, via reductions. We show that: (1) sample compression schemes yield public-private learners; (2) public-private learners yield list learners; and (3) list learners yield sample compression schemes.

(1) and (3) are straightforward to prove: (1) _compression implies public-private learning_ follows from a modification of an analogous result of [1], where we observe that in their proof, the learner's two-stage process of drawing a small _compression sample_ used to generate a finite set of hypotheses using the compression scheme, followed by _hypothesis selection_ with a larger sample, can be cleanly divided into using public and private samples respectively. In the latter stage, we employ a known pure DP hypothesis selection algorithm [1, 1]. (3) _List learning implies compression_ follows immediately from the definitions.

For (2) _public-private learning implies list learning_, we show non-constructively that there exists a list learner for a class, given a public-private learner for that class, but do not provide an algorithmic translation of the public-private learner to a list learner. For a set of samples \(S\), we show that outputting a finite cover of the list of distributions on which the public-private learner succeeds on, when using \(S\) as the public samples, is a correct output for a list learner. Hence the list learner we construct, on input \(S\), outputs this finite cover as determined by (but not explicitly constructed from) the public-private learner.

Agnostic and distribution-shifted public-private learning.We identify some distributional assumptions that can be relaxed in the public-private learning setup. We obtain agnostic and distribution-shifted public-private learners via a connection to robust compression schemes. The reduction ideas are similar to those in the case of public-private learning and non-robust sample compression described above.

Lower bound on public-private learning of Gaussians.Our lower bound for public-privately learning high-dimensional Gaussians exploits our above connection between public-private learning and list learning, and applies a "no-free-lunch"-style argument. The latter uses the fact that an algorithm's worst-case performance cannot be better than its performance when averaged across all the problem instances. In other words, we have two main steps in our proof: (1) we first claim that due to our above reduction, a lower bound for list learning high-dimensional Gaussians would imply a lower bound on the public sample complexity for public-privately learning high-dimensional Gaussians; and (2) assuming certain accuracy guarantees and a sample complexity for our list learner for high-dimensional Gaussians; we show that across a set of adversarially chosen problem instances, our average accuracy guarantee fails, which is a contradiction to our assumed worst-case guarantees.

We observe that the lower bound from Theorem 6.1 establishes that at least \(d\) public samples are necessary for public-private learning to vanishingly small error as \(d\) increases (impossibility of learning to a target error, via the application of Lemma G.1, is related to the bound on \(\eta\) from Equation (6), which decreases exponentially with \(d\)). A natural question is whether the result can be strengthened to say that there is a single target error, simultaneously for all \(d\), for which learning is impossible without \(d\) public samples.

VC dimension upper bound for public-private learning.Our proof involves invoking the existing results for public-private binary classification [1] and uniform convergence [1]. We use them to implement Yatracos' minimum distance estimator [22, 1] in a public-private way.

## Appendix C Extended preliminaries

### Notation

Covers and packings.For \(\alpha>0\) and \(\mathcal{Q}\subseteq\Delta(\mathcal{X})\), we say that \(\mathcal{C}\subseteq\Delta(\mathcal{X})\) is an _\(\alpha\)-cover of \(\mathcal{Q}\)_ if for any \(q\in\mathcal{Q}\), there exists a \(p\in\mathcal{C}\) with \(\mathrm{TV}(p,q)\leq\alpha\). For \(\alpha>0\) and \(\mathcal{Q}\subseteq\Delta(\mathcal{X})\), we say that \(\mathcal{P}\subseteq\mathcal{Q}\) is an _\(\alpha\)-packing of \(\mathcal{Q}\)_ if for any \(p\neq q\in\mathcal{P}\), \(\mathrm{TV}(p,q)>\alpha\).

Class of \(k\)-mixtures.Let \(\mathcal{Q}\subseteq\Delta(\mathcal{X})\) be a class of distributions. For any \(k\geq 1\), the _class of \(k\)-mixtures of \(\mathcal{Q}\)_ is given by

\[\mathcal{Q}^{\oplus k}\coloneqq\left\{\sum_{i=1}^{k}w_{i}q_{i}:q_{i}\in \mathcal{Q},w_{i}\geq 0\text{ for all }i\in[k]\text{ and }\sum_{i=1}^{k}w_{i}=1\right\}.\]

Class of \(k\)-products.Let \(\mathcal{Q}\subseteq\Delta(\mathcal{X})\) be a class of distributions over \(\mathcal{X}\). For any \(k\geq 1\), \(q=(q_{1},\ldots,q_{k})\) is a product distribution over \(\mathcal{X}^{k}\), if \(q_{i}\in\mathcal{Q}\) for all \(i\in[k]\) and for \(X\sim q\), the \(i\)-th component \(X_{i}\) of \(X\) is independently (of all the other coordinates) sampled from \(q_{i}\). The _class of \(k\)-products of \(\mathcal{Q}\) over \(\mathcal{X}^{k}\)_ is given by

\[\mathcal{Q}^{\otimes k}\coloneqq\left\{(q_{1},\ldots,q_{k}):q_{i}\in\mathcal{Q }\text{ for all }i\in[k]\right\}.\]

### Privacy

The following is a known hardness result on density estimation of distributions under pure differential privacy, and is based on the standard "packing lower bounds".

**Fact C.1** (Packing lower bound [1, Lemma 5.1]).: _Let \(\mathcal{Q}\subseteq\Delta(\mathcal{X})\), \(\alpha\in(0,1]\), and \(\varepsilon>0\). Let \(\widehat{\mathcal{Q}}\) be any \(\alpha\)-packing of \(\mathcal{Q}\). Any \(\varepsilon\)-DP algorithm \(\mathcal{A}\colon\mathcal{X}^{n}\to\Delta(\Delta(\mathcal{X}))\) that, upon receiving \(n\) i.i.d. samples \(X_{1},\ldots,X_{n}\) from any \(p\in\mathcal{Q}\), outputs \(Q\) with \(\mathrm{TV}(Q,p)\leq\frac{\alpha}{2}\) with probability \(\geq\frac{9}{10}\) requires_

\[n\geq\frac{\log(|\widehat{\mathcal{Q}}|)-\log(\frac{10}{9})}{\varepsilon}.\]

The next result guarantees the existence of agnostic learners for finite hypothesis classes under pure differential privacy.

**Fact C.2** (Pure DP \(3\)-agnostic learner for finite \(\mathcal{Q}\)[1, 1, Theorem 2.24]).: _Let \(\mathcal{Q}\subseteq\Delta(\mathcal{X})\) with \(|\mathcal{Q}|<\infty\). For every \(\alpha,\beta\in(0,1]\) and \(\varepsilon>0\), there exists an \(\varepsilon\)-DP algorithm \(\mathcal{A}\colon\mathcal{X}^{n}\to\Delta(\Delta(\mathcal{X}))\), such that for any \(p\in\Delta(\mathcal{X})\), if we draw a dataset \(\bm{X}=(X_{1},...,X_{n})\) i.i.d. from \(p\) and then \(Q\sim\mathcal{A}(\bm{X})\),_

\[\Pr_{\begin{subarray}{c}\bm{X}\sim p^{n}\\ Q\sim\mathcal{A}(\bm{X})\end{subarray}}\left\{\mathrm{TV}(Q,p)\leq 3\cdot \mathrm{dist}(p,\mathcal{Q})+\alpha\right\}\geq 1-\beta,\]

_where_

\[n=O\left(\frac{\log(|\mathcal{Q}|)+\log(\frac{1}{\beta})}{\alpha^{2}}+\frac{ \log(|\mathcal{Q}|)+\log(\frac{1}{\beta})}{\alpha\varepsilon}\right).\]

## Appendix D Statements and proofs for Section 3 - The connection to sample compression schemes

The following is the full formal statement of Theorem 1.1.

**Theorem D.1** (Sample complexity equivalence between sample compression, public-private learning, and list learning).: _Let \(\mathcal{Q}\subseteq\Delta(\mathcal{X})\). Let \(m:(0,1]^{2}\to\mathbb{N}\) be a sample complexity function, such that \(m(\alpha,\beta)=\mathrm{poly}(\frac{1}{\alpha},\frac{1}{\beta})\).3 Then the following are equivalent._

Footnote 3: The reductions between the learners do not need this assumption, it is only used to state the sample complexity equivalence.

1. \(\mathcal{Q}\) _is realizably compressible with_ \(m_{C}(\alpha,\beta)=O(m(\alpha,\beta))\) _samples._
2. \(\mathcal{Q}\) _is public-privately learnable with_ \(m_{P}(\alpha,\beta,\epsilon)=O(m(\alpha,\beta))\) _public samples._
3. \(\mathcal{Q}\) _is list learnable with_ \(m_{L}(\alpha,\beta)=O(m(\alpha,\beta))\) _samples._

_The functions \(m_{C}\), \(m_{P}\), and \(m_{L}\) are related to one another as: \(m_{P}(\alpha,\beta,\varepsilon)=m_{C}(\frac{\alpha}{6},\frac{\beta}{2})\); \(m_{L}(\alpha,\beta)=m_{P}(\frac{\alpha}{2},\frac{\beta}{10},\varepsilon)\) for any \(\varepsilon>0\); and \(m_{C}(\alpha,\beta)=m_{L}(\alpha,\beta)\). Hence, if there exists a polynomial \(m:(0,1]^{2}\to\mathbb{N}\), such that \(m_{C}(\alpha,\beta)=O(m(\alpha,\beta))\), then \(m_{C}(\alpha,\beta)\), \(m_{P}(\alpha,\beta)\), and \(m_{L}(\alpha,\beta)\) are all within constant factors of each other._

### Compression implies public-private learning

Proof of Proposition 3.1.: The proof this proposition closely mirrors that of Theorem 4.5 from [1]. We adapt their result to the public-private setting.

Fix \(\alpha,\beta\in(0,1]\) and \(\varepsilon>0\). Let \(\tau=\tau(\frac{\alpha}{6},\frac{\beta}{2})\), \(t=t(\frac{\alpha}{6},\frac{\beta}{2})\), and \(m=m_{C}(\frac{\alpha}{6},\frac{\beta}{2})\). We draw a public dataset \(\bm{\tilde{X}}\) of size \(m\) i.i.d. from \(p\). Consider

\[\mathcal{S}\coloneqq\left\{(\bm{S}^{\prime},b):\bm{S}^{\prime}\subseteq\bm{ \tilde{X}}\text{ where }|\bm{S}^{\prime}|=\tau,\text{ and }b\in\{0,1\}^{t}\right\}.\]

Note that the encoding \(f_{p}(\bm{\tilde{X}})\in\mathcal{S}\), so forming \(\widehat{\mathcal{Q}}=\{g(S^{\prime},b):(S^{\prime},b)\in\mathcal{S}\}\) means that with probability \(\geq 1-\frac{\beta}{2}\) over the sampling of \(\bm{\tilde{X}}\), \(q=g(f_{p}(\bm{\tilde{X}}))\in\widehat{\mathcal{Q}}\) has \(\mathrm{TV}(q,p)\leq\frac{\alpha}{6}\).

Now, we run the \(\varepsilon\)-DP \(3\)-agnostic learner from Fact C.2 on \(\widehat{\mathcal{Q}}\), targeting error \(\frac{\alpha}{2}\) and failure probability \(\frac{\beta}{2}\), which is achieved as long as we have \(n\) private samples (given in the statement of Proposition 3.1), which is logarithmic in \(|\mathcal{S}|\). With probability \(\geq 1-\beta\), we approximately recover \(p\) with the compression scheme and the DP learner succeeds, and so the output \(Q\) satisfies

\[\mathrm{TV}(Q,p) \leq 3\cdot\min_{q\in\widehat{\mathcal{Q}}}\mathrm{TV}(p,q)+ \frac{\alpha}{2}\] \[\leq 3\cdot\frac{\alpha}{6}+\frac{\alpha}{2}=\alpha.\qed\]

### List learning implies sample compression

Proof of Proposition 3.5.: Fix any \(\alpha,\beta\in(0,1]\). Let \(m=m_{L}(\alpha,\beta)\) and \(\ell=\ell(\alpha,\beta)\). By assumption, \(\mathcal{Q}\) admits an \((\alpha,\beta,\ell)\)-list learner \(\mathcal{L}:\mathcal{X}^{m}\to\{L\subseteq\Delta(\mathcal{X}):|L|\leq\ell\}\) that takes \(m\) samples. Letting \(\tau=m\) and \(t=\log_{2}(\ell)\), we define the compression scheme as follows.

* Encoder: for any \(q\in\mathcal{Q}\), the encoder \(f_{q}:\mathcal{X}^{m}\to\mathcal{X}^{\tau}\times\{0,1\}^{t}\) produces the following, given an input \(\bm{\tilde{x}}\in\mathcal{X}^{m}\). It first runs the list learner on \(\bm{\tilde{x}}\), obtaining \(\mathcal{L}(\bm{\tilde{x}})\). Then, it finds the smallest index \(i\) with \(\mathrm{TV}(q,\mathcal{L}(\bm{\tilde{x}})_{i})=\mathrm{dist}(q,\mathcal{L}(\bm {\tilde{x}}))\), where \(\mathcal{L}(\bm{\tilde{x}})_{i}\) denotes the \(i\)-th element of the the list \(\mathcal{L}(\bm{\tilde{x}})\). The output of the list learner is \((\bm{\tilde{x}},i)\). Note that \(\bm{\tilde{x}}\in\mathcal{X}^{\tau}\) and that \(i\) can be represented with \(\log_{2}(\ell)=t\) bits.
* Decoder: the fixed decoder \(g:\mathcal{X}^{\tau}\times\{0,1\}^{t}\to\Delta(\mathcal{X})\) takes \(\bm{\tilde{x}}\) and \(i\), runs the list learner \(\mathcal{L}\) on \(\bm{\tilde{x}}\), and produces \(\mathcal{L}(\bm{\tilde{x}})_{i}\).

By the guarantee of the list learner, we indeed have for any \(q\in\mathcal{Q}\), with probability \(\geq 1-\beta\) over the sampling of \(\bm{\tilde{X}}\sim q^{m}\), \(\mathrm{TV}(q,g(f_{q}(S)))\leq\alpha\)

## Appendix E Statements and proofs for Section 4 - Applications

### Public-private learnability of Gaussians and mixtures of Gaussians

**Corollary E.1** (Public-private learning for Gaussians).: _Let \(d\geq 1\). The class of Gaussians over \(\mathbb{R}^{d}\) is public-privately learnable with \(m(\alpha,\beta,\varepsilon)\) public samples and \(n(\alpha,\beta,\varepsilon)\) private samples, where_

\[m(\alpha,\beta,\varepsilon) =O\left(d\log\left(\frac{1}{\beta}\right)\right),\] \[n(\alpha,\beta,\varepsilon) =O\left(\frac{d^{2}\log\left(\frac{d}{\alpha}\right)+\log\left( \frac{1}{\beta}\right)}{\alpha^{2}}+\frac{d^{2}\log\left(\frac{d}{\alpha} \right)+\log\left(\frac{1}{\beta}\right)}{\alpha\varepsilon}\right).\]

**Corollary E.2** (Public-private learning for mixtures of Gaussians).: _Let \(d,k\geq 1\). The class of all \(k\)-mixtures of Gaussians over \(\mathbb{R}^{d}\) is public-privately learnable with \(m(\alpha,\beta,\varepsilon)\) public samples and \(n(\alpha,\beta,\varepsilon)\) private samples, where_

\[m(\alpha,\beta,\varepsilon) =O\left(\frac{kd\log\left(\frac{k}{\beta}\right)\log\left(\frac{ 1}{\beta}\right)}{\alpha}\right),\] \[n(\alpha,\beta,\varepsilon) =O\left(\left(\frac{1}{\alpha^{2}}+\frac{1}{\varepsilon\alpha} \right)\cdot\left(kd^{2}\log\left(\frac{d}{\alpha}\right)+kd\log\left(\frac{ kd\log\left(\frac{k}{\beta}\right)}{\alpha}\right)+\log\left(\frac{1}{\beta} \right)\right)\right).\]

### Public-private learnability of mixture and product distributions

Mixture distributions.We first mention a fact from [1], which says that if a compression scheme exists for a class of distributions \(\mathcal{Q}\), then there exists a compression scheme for the class of \(k\)-mixtures of \(\mathcal{Q}\).

**Fact E.3** (Compression for mixture distributions [1, Lemma 4.8]).: _If a class of distributions \(\mathcal{Q}\) admits \((\tau(\alpha,\beta),t(\alpha,\beta),m(\alpha,\beta))\) realizable sample compression, then for any \(k\geq 1\), the class of \(k\)-mixtures of \(\mathcal{Q}\) admits \((\tau_{k}(\alpha,\beta),t_{k}(\alpha,\beta),m_{k}(\alpha,\beta))\) realizable sample compression, where \(\tau_{k},t_{k},m_{k}:(0,1]^{2}\to\mathbb{N}\) are as follows:_

\[\tau_{k}(\alpha,\beta)=k\cdot\tau\left(\frac{\alpha}{3},\beta \right), t_{k}(\alpha,\beta)=k\cdot t\left(\frac{\alpha}{3},\beta\right)+\log _{2}\left(\frac{3k}{\alpha}\right),\] \[m_{k}(\alpha,\beta)=\frac{48k\log\left(\frac{6k}{\beta}\right)} {\alpha}\cdot m\left(\frac{\alpha}{3},\beta\right).\]

Next, we state a corollary of Propositions 3.4 and 3.5, which describes the existence of a compression scheme, given the existence of a public-private learner.

**Corollary E.4** (Public-private learning \(\Longrightarrow\) compression).: _Let \(\mathcal{Q}\subseteq\Delta(\mathcal{X})\) be a class of distributions. Suppose \(\mathcal{Q}\) is public-privately learnable with \(m_{P}(\alpha,\beta,\varepsilon)\) public samples and \(n(\alpha,\beta,\varepsilon)\) private samples. Then for any \(\varepsilon>0\), \(\mathcal{Q}\) admits_

\[(\tau(\alpha,\beta),t(\alpha,\beta),m(\alpha,\beta))=\left(m_{P}\left(\frac{ \alpha}{2},\frac{\beta}{10},\varepsilon\right),\frac{\log(\frac{10}{9})+ \varepsilon\cdot n\left(\frac{\alpha}{2},\frac{\beta}{10},\varepsilon\right)} {\log(2)},m_{P}\left(\frac{\alpha}{2},\frac{\beta}{10},\varepsilon\right)\right)\]

_realizable sample compression._

Proof.: Fix \(\varepsilon>0\). From Proposition 3.4, if \(\mathcal{Q}\) is public-privately learnable, then it is list learnable to list size \(\ell(\alpha,\beta)\) with \(m_{L}(\alpha,\beta)\) samples, where

\[\ell(\alpha,\beta)=\frac{10}{9}\exp\left(\varepsilon\cdot n\left(\frac{ \alpha}{2},\frac{\beta}{10},\varepsilon\right)\right)\ \ \text{and}\ \ \ m_{L}(\alpha,\beta)=m_{P}\left(\frac{\alpha}{2},\frac{\beta}{10}, \varepsilon\right).\]Proposition 3.5 implies \(\mathcal{Q}\) admits \((\tau(\alpha,\beta),t(\alpha,\beta),m_{C}(\alpha,\beta))\) sample compression, where

\[\tau(\alpha,\beta)=m_{L}(\alpha,\beta)=m_{P}\left(\frac{\alpha}{2},\frac{\beta}{10},\varepsilon\right),\] \[t(\alpha,\beta)=\log_{2}(\ell(\alpha,\beta))=\frac{\log(\frac{1 0}{9})+\varepsilon\cdot n\left(\frac{\alpha}{2},\frac{\beta}{10},\varepsilon \right)}{\log(2)},\] \[m_{C}(\alpha,\beta)=m_{L}(\alpha,\beta)=m_{P}\left(\frac{\alpha} {2},\frac{\beta}{10},\varepsilon\right).\]

This completes the proof. 

As a consequence of Corollary E.4, Fact E.3, and Proposition 3.1, we have the following result about the public-private learnability of mixture distributions.

**Theorem E.5** (Public-private learning for mixture distributions).: _Suppose \(\mathcal{Q}\subseteq\Delta(\mathcal{X})\) is public-privately learnable with \(m(\alpha,\beta,\varepsilon)\) public samples and \(n(\alpha,\beta,\varepsilon)\) private samples. Then for any \(k\geq 1\), \(\mathcal{Q}^{\oplus k}\), the class of \(k\)-mixtures of \(\mathcal{Q}\), is public-privately learnable with \(m_{k}(\alpha,\beta,\varepsilon)\) public samples and \(n_{k}(\alpha,\beta,\varepsilon)\) private samples, where_

\[m_{k}(\alpha,\beta,\varepsilon)=O\left(\frac{k\log\left(\frac{k} {\beta}\right)}{\alpha}\cdot m\left(\frac{\alpha}{36},\frac{\beta}{20}, \varepsilon_{0}\right)\right),\] \[n_{k}(\alpha,\beta,\varepsilon)=O\left(\left(\frac{1}{\alpha^{2 }}+\frac{1}{\varepsilon\alpha}\right)\cdot\left(\varepsilon_{0}k\cdot n\left( \frac{\alpha}{36},\frac{\beta}{20},\varepsilon_{0}\right)+\right.\right.\] \[\left.\left.\qquad\qquad k\log\left(\frac{k\log\left(\frac{k}{ \beta}\right)}{\alpha}\cdot m\left(\frac{\alpha}{36},\frac{\beta}{20}, \varepsilon_{0}\right)\right)\cdot m\left(\frac{\alpha}{36},\frac{\beta}{20}, \varepsilon_{0}\right)+\log\left(\frac{1}{\beta}\right)\right)\right)\]

_for any choice of \(\varepsilon_{0}>0\)._

We give an example of an application of this result. Consider the class of Gaussians over \(\mathbb{R}^{d}\), for which there exists a public-private learner that uses \(m=O(d)\) public samples and \(n=O\left(\frac{d^{2}}{\alpha^{2}}+\frac{d^{2}}{\varepsilon\alpha}\right)\cdot \operatorname{polylog}\left(d,\frac{1}{\alpha},\frac{1}{\beta}\right)\) private samples [1]. Then Theorem E.5 implies that there exists a public-private learner for the class of \(k\)-mixtures of Gaussians that uses \(m_{k}=O\left(\frac{kd\log(k/\beta)}{\alpha}\right)\) public samples and

\[n_{k}=O\left(\left(\frac{1}{\alpha^{2}}+\frac{1}{\varepsilon\alpha}\right) \cdot\left(\varepsilon_{0}k\left(\frac{d^{2}}{\alpha^{2}}+\frac{d^{2}}{ \varepsilon_{0}\alpha}\right)+kd\right)\right)\cdot\operatorname{polylog}\left( d,k,\frac{1}{\alpha},\frac{1}{\beta}\right)\]

private samples for any \(\varepsilon_{0}>0\).

With the choice of \(\varepsilon_{0}=\alpha\), we get a private sample complexity of \(n_{k}=O\left(\frac{kd^{2}}{\alpha^{3}}+\frac{kd^{2}}{\alpha^{2}\varepsilon}\right)\cdot \operatorname{polylog}\left(d,k,\frac{1}{\alpha},\frac{1}{\beta}\right)\). Notably, this private sample complexity, obtained by specializing the general result of Theorem E.5, suffers some loss compared to our learner for mixtures of Gaussians from Corollary E.2.

Product distributions.We start by mentioning a fact from [1], which says that if a compression scheme exists for a class of distributions \(\mathcal{Q}\), then there exists a compression scheme for the class of \(k\)-products of \(\mathcal{Q}\).

**Fact E.6** (Compression for product distributions [1, Lemma 4.6]).: _If a class of distributions \(\mathcal{Q}\) admits \((\tau(\alpha,\beta),t(\alpha,\beta),m(\alpha,\beta))\)\(r\)-robust sample compression, then for any \(k\geq 1\), the class of \(k\)-products of \(\mathcal{Q}\) admits \((\tau_{k}(\alpha,\beta),t_{k}(\alpha,\beta),m_{k}(\alpha,\beta))\)\(r\)-robust sample compression, where \(\tau_{k},t_{k},m_{k}:(0,1]\rightarrow\mathbb{N}\) are as follows:_

\[\tau_{k}(\alpha,\beta)=k\cdot\tau\left(\frac{\alpha}{k},\beta\right),\ \ \ t_{k}(\alpha,\beta)=k\cdot t\left(\frac{\alpha}{k},\beta\right),\ \ \ m_{k}(\alpha,\beta)=\log_{3}\left(\frac{3k}{\beta}\right)\cdot m\left(\frac{ \alpha}{k},\beta\right).\]As a consequence of Corollary E.4, Fact E.6, and Proposition 3.1, we have the following result about the public-private learnability of product distributions.

**Theorem E.7** (Public-private learning for mixture distributions).: _Suppose \(\mathcal{Q}\subseteq\Delta(\mathcal{X})\) is public-privately learnable with \(m(\alpha,\beta,\varepsilon)\) public samples and \(n(\alpha,\beta,\varepsilon)\) private samples. Then for any \(k\geq 1\), \(\mathcal{Q}^{\otimes k}\), the class of \(k\)-products of \(\mathcal{Q}\) over \(\mathcal{X}^{k}\), is public-privately learnable with \(m_{k}(\alpha,\beta,\varepsilon)\) public samples and \(n_{k}(\alpha,\beta,\varepsilon)\) private samples, where_

\[m_{k}(\alpha,\beta,\varepsilon) =O\left(\log\left(\frac{k}{\beta}\right)\cdot m\left(\frac{ \alpha}{12k},\frac{\beta}{20},\varepsilon_{0}\right)\right),\] \[n_{k}(\alpha,\beta,\varepsilon) =O\left(\left(\frac{1}{\alpha^{2}}+\frac{1}{\varepsilon\alpha} \right)\cdot\left(\varepsilon_{0}k\cdot n\left(\frac{\alpha}{12k},\frac{\beta} {20},\varepsilon_{0}\right)+\right.\right.\] \[\qquad\qquad\left.\left.k\log\left(\log\left(\frac{k}{\beta} \right)\cdot m\left(\frac{\alpha}{12k},\frac{\beta}{20},\varepsilon_{0}\right) \right)\cdot m\left(\frac{\alpha}{12k},\frac{\beta}{20},\varepsilon_{0}\right) +\log\left(\frac{1}{\beta}\right)\right)\right)\]

_for any choice of \(\varepsilon_{0}>0\)._

As an example, for the class of Gaussians over \(\mathbb{R}\), there exists a public-private learner that requires \(m=O(1)\) public samples and \(n=O\left(\frac{1}{\alpha^{2}}+\frac{1}{\varepsilon\alpha}\right)\cdot\mathrm{ polylog}\left(\frac{1}{\alpha},\frac{1}{\beta}\right)\) private samples [1]. Then Theorem E.7 implies that there exists a public-private learner for the class of \(k\)-products of Gaussians that requires \(m_{k}=O\left(\log(k/\beta)\right)\) public samples and \(n_{k}=\left(\left(\frac{1}{\alpha^{2}}+\frac{1}{\varepsilon\alpha}\right) \cdot\left(\varepsilon_{0}k\left(\frac{1}{\alpha^{2}}+\frac{1}{\varepsilon_{ 0}\alpha}\right)+k\right)\right)\cdot\mathrm{polylog}\left(k,\frac{1}{\alpha},\frac{1}{\beta}\right)\) private samples, for any choice of \(\varepsilon_{0}>0\). Note that if were to apply Fact E.6 to Fact 4.1 after setting \(d=1\) in the latter, and then apply Proposition 3.1, we would obtain a better sample complexity in terms of the private data than what we would after combining Corollary E.1 (setting \(d=1\)) and Theorem E.7 here. However, Theorem E.7 is a more versatile framework, so some loss is to be expected again.

Appendix F Statements and proofs for Section 5 - Agnostic and distribution-shifted public-private learning

Theorem 5.2 gives us an agnostic and a distribution-shifted learner for Gaussians over \(\mathbb{R}^{d}\), as stated in the following corollary.

**Corollary F.1** (Agnostic and distribution-shifted public-private learner for Gaussians).: _Let \(d\geq 1\). For any \(\alpha,\beta\in(0,1]\) and \(\varepsilon>0\), there exists \(\frac{1}{3}\)-shifted \(3\)-agnostic public-private learner for the class of Gaussians in \(\mathbb{R}^{d}\) that uses \(m\) public samples and \(n\) private samples, where_

\[m =O\left(d\log\left(\frac{1}{\beta}\right)\right),\] \[n =O\left(\frac{d^{2}\log\left(\frac{d}{\alpha}\right)+\log\left( \frac{1}{\beta}\right)}{\alpha^{2}}+\frac{d^{2}\log\left(\frac{d}{\alpha} \right)+\log\left(\frac{1}{\beta}\right)}{\alpha\varepsilon}\right).\]

## Appendix G Statements and proofs for Section 6 - Lower bounds

**Lemma G.1**.: _Let \(\mathcal{Q}\subseteq\Delta(\mathcal{X})\) and \(m\in\mathbb{N}\). For a subclass \(\mathcal{C}\subseteq\mathcal{Q}\), denote by \(\mathcal{U}(\mathcal{C})\) the uniform distribution over \(\mathcal{C}\). Suppose there exists a sequence of distribution classes \((\mathcal{Q}_{k})_{k=1}^{\infty}\), with each \(\mathcal{Q}_{k}\subseteq\mathcal{Q}\), and a set \(B\subseteq\mathcal{X}^{m}\) such that following holds:_

1. _There exists_ \(\eta\in(0,1]\) _and_ \(k_{\eta}\in\mathbb{N}\) _with_ \[\underset{\begin{subarray}{c}Q\sim\mathcal{U}(\mathcal{Q}_{k})\\ \bm{X}\sim Q^{m}\end{subarray}}{\mathbb{P}}\left\{\bm{X}\in B\right\}\geq\eta\] _for all_ \(k\geq k_{\eta}\)_._2. _There exist_ \(c>0\) _and_ \(\alpha\in(0,1]\) _such that, defining_ \((u_{k})_{k=1}^{\infty}\)_,_ \((r_{k})_{k=1}^{\infty}\)_, and_ \((s_{k})_{k=1}^{\infty}\) _as_ \[u_{k} \coloneqq\sup_{\begin{subarray}{c}\bm{x}\in B\\ \bm{x}\subset\mathbb{Q}_{k}\end{subarray}}q^{m}(\bm{x}),\] \[r_{k} \coloneqq\sup_{p\in\mathcal{Q}_{k}}\mathbb{P}_{Q\sim\mathcal{U}( \mathcal{Q}_{k})}\{\mathrm{TV}(p,Q)\leq 2\alpha\},\] \[s_{k} \coloneqq\inf_{\bm{x}\in B}\mathbb{P}_{Q\sim\mathcal{U}(\mathcal{ Q}_{k})}\{Q^{m}(\bm{x})\geq c\cdot u_{k}\},\] _we have that_ \[\lim_{k\to\infty}\frac{r_{k}}{s_{k}}=0.\]

_Then for any \(\ell\in\mathbb{N}\), there does not exist any \((\frac{\alpha\eta}{4},\frac{\alpha\eta}{4},\ell)\)-list learner for \(\mathcal{Q}\) that uses \(m\) samples._

Proof.: We provide a proof by contradiction. Suppose for some \(\ell\in\mathbb{N}\), we have an \((\frac{\alpha\eta}{4},\frac{\alpha\eta}{4},\ell)\)-list learner for \(\mathcal{Q}\) using \(m\) samples, denoted by \(\mathcal{L}:\mathcal{X}^{m}\to\{L\subseteq\Delta(\mathcal{X}):|L|\leq\ell\}\). Then for all \(k\in\mathbb{N}\), we have that

\[\mathop{\mathbb{E}}_{\begin{subarray}{c}Q\sim\mathcal{U}(\mathcal{ Q}_{k})\\ \bm{X}\sim Q^{m}\end{subarray}}[\mathrm{dist}(Q,\mathcal{L}(\bm{X}))]\leq(1- \tfrac{\alpha\eta}{4})\cdot\tfrac{\alpha\eta}{4}+\tfrac{\alpha\eta}{4}\cdot 1 \leq\tfrac{\alpha\eta}{2}.\] (1)

Now, since \(\lim_{k\to\infty}\frac{r_{k}}{s_{k}}=0\), there exists \(k_{0}\geq k_{\eta}\in\mathbb{N}\), such that

\[\frac{r_{k_{0}}\cdot u_{k_{0}}\cdot\ell}{s_{k_{0}}\cdot cu_{k_{0 }}}\leq\frac{1}{11},\] (2)

and

\[\mathop{\mathbb{P}}_{\begin{subarray}{c}Q\sim\mathcal{U}(\mathcal{ Q}_{k_{0}})\\ \bm{X}\sim Q^{m}\end{subarray}}\{\bm{X}\in B\}\geq\eta.\] (3)

Fix any \(\bm{x}\in B\), and let \(R=\{q\in\mathcal{Q}_{k_{0}}:\mathrm{dist}(q,\mathcal{L}(\bm{x}))\leq\alpha\}\) and \(S=\{q\in\mathcal{Q}_{k_{0}}:q^{m}(\bm{x})\geq cu_{k_{0}}\}\) (note that both \(R\) and \(S\) depend on \(\bm{x}\)).

For \(i\in[\ell]\), further let \(R_{i}=\{q\in\mathcal{Q}_{k_{0}}:\mathrm{TV}(q,\mathcal{L}(\bm{x})_{i})\leq\alpha\}\), so that \(R=\cup_{i=1}^{\ell}R_{i}\).

Now, fix \(i\in[\ell]\). Assuming that \(R_{i}\neq\emptyset\), consider any \(p\in R_{i}\). For any \(q\in R_{i}\), we have \(\mathrm{TV}(p,q)\leq 2\alpha\). Hence, \(R_{i}\subseteq\{q\in\mathcal{Q}_{k_{0}}:\mathrm{TV}(p,q)\leq 2\alpha\}\). Regardless of whether \(R_{i}\) is empty,

\[\mathop{\mathbb{P}}_{Q\sim\mathcal{U}(\mathcal{Q}_{k_{0}})}\{Q \in R_{i}\}\leq\sup_{p\in\mathcal{Q}_{k_{0}}}\mathop{\mathbb{P}}_{Q\sim \mathcal{U}(\mathcal{Q}_{k_{0}})}\{\mathrm{TV}(p,Q)\leq 2\alpha\}=r_{k_{0}}.\]

Moreover, we can conclude that

\[\mathop{\mathbb{P}}_{Q\sim\mathcal{U}(\mathcal{Q}_{k_{0}})}\{Q \in R\}\leq\sum_{i=1}^{\ell}\mathop{\mathbb{P}}_{Q\sim\mathcal{U}(\mathcal{Q} _{k_{0}})}\{Q\in R_{i}\}\leq r_{k_{0}}\cdot\ell.\] (4)

Observe that this implies, since \(u_{k_{0}}\geq q^{m}(\bm{x})\),

\[\int_{R}q^{m}(\bm{x})f_{Q}(q)dq\leq u_{k_{0}}\int_{R}f_{Q}(q)dq= u_{k_{0}}\mathop{\mathbb{P}}_{Q\sim\mathcal{U}(\mathcal{Q}_{k_{0}})}\{Q\in R\} \leq u_{k_{0}}\cdot r_{k_{0}}\cdot\ell\] (5)

[MISSING_PAGE_FAIL:24]

The construction of the sequence of hard subclasses.Let \(e_{d}=[0,0,\ldots,1]^{\top}\in\mathbb{R}^{d}\). We define the following sets:

\[T =\left\{\begin{bmatrix}t\\ 0\end{bmatrix}\in\mathbb{R}^{d}:t\in\mathbb{R}^{d-1}\text{ with }\|t\|_{2}\leq\frac{1}{2}\right\},\] \[C =\left\{\begin{bmatrix}t\\ \lambda\end{bmatrix}\in\mathbb{R}^{d}:t\in\mathbb{R}^{d-1}\text{ with }\|t\|_{2}\leq\frac{1}{2}\text{ and }\lambda\in[1,2]\subseteq\mathbb{R}\right\}.\]

That is, \(T\) is a \(\frac{1}{2}\)-disk (a disk with radius \(\frac{1}{2}\)) in \(\mathbb{R}^{d-1}\) embedded onto the \((d-1)\)-dimensional hyperplane in \(\mathbb{R}^{d}\) spanning the first \((d-1)\) dimensions (axes), centered at the origin. \(C\) is a cylinder of unit length and radius \(\frac{1}{2}\) placed unit distance away from \(T\) in the positive \(e_{d}\)-direction.

Let \(S^{d-1}=\{x\in\mathbb{R}^{d}:\|x\|_{2}=1\}\) be the unit-sphere, centered at the origin, in \(\mathbb{R}^{d}\), and let

\[N=\left\{u\in S^{d-1}:|u\cdot e_{d}|\leq\frac{\sqrt{3}}{2}\right\}.\]

That is, \(N\) is the set of vectors \(u\) on the unit hypersphere with angle \(\geq\frac{\pi}{6}\) from \(e_{d}\). For \(u\in N\), define the "rotation" matrix

\[R_{u}=\begin{bmatrix}|&|&&|\\ u&v_{2}&\ldots&v_{d}\\ |&|&&\end{bmatrix}\in\mathbb{R}^{d\times d}\]

where \(\{v_{2},\ldots,v_{d}\}\) is any orthonormal basis for \(\{u\}^{\perp}\) (where \(\{u\}^{\perp}\) denotes the subspace orthogonal to the subspace spanned by the set of vectors \(\{u\}\)).4

Footnote 4: Technically, \(R_{u}\) is an equivalence class of matrices since we do not specify which orthonormal basis of \(\{u\}^{\perp}\). However, as it turns out, the choice of the orthonormal basis of \(\{u\}^{\perp}\) does not matter since they all result in the same Gaussian densities in the proceeding definition of \(G(\sigma,t,u)\).

Now, for \(\sigma>0\), \(t\in T\), and \(u\in N\), define the Gaussian

\[G(\sigma,t,u)=\mathcal{N}\left(t,R_{u}\begin{bmatrix}\sigma^{2}&1&O\\ &1&O\\ O&\ddots&1\end{bmatrix}R_{u}^{\top}\right)\in\Delta(\mathbb{R}^{d}).\]

For all \(k\geq 1\), let

\[\mathcal{Q}_{k}=\left\{G\left(\frac{1}{k},t,u\right):t\in T,u\in N\right\}.\]

That is, each \(\mathcal{Q}_{k}\) is a class of "flat" (i.e., near \((d-1)\)-dimensional) Gaussians in \(\mathbb{R}^{d}\), with \(\sigma^{2}=\frac{1}{k^{2}}\) variance on a single thin direction \(u\) and unit variance in all other directions. Their mean vectors come from a point on the hyperplanar disk \(T\) (which we recall is a \((d-1)\)-dimensional disk orthogonal to \(e_{d}\)), and the thin direction \(u\) comes from \(N\) (which is \(S^{d-1}\) excluding points that form angle \(<\frac{\pi}{6}\) with \(e_{d}\)). As \(k\to\infty\), the Gaussians get flatter.

Lower bounding the weight of \(B\).We start with the following claim, which shows the probability that \(d-1\) samples drawn the uniform mixture of \(\mathcal{Q}_{k}^{d-1}\) all fall into the cylinder \(C\) can be uniformly lower bounded by an absolute constant, independent of \(k\).

**Claim G.2**.: _Let \(B\) be the set of all possible vectors of \(d-1\) points in the cylinder \(C\), i..e, \(B=C^{d-1}\in(\mathbb{R}^{d})^{d-1}\). There exists \(\eta>0\) such that for \(k\geq 10\),_

\[\begin{matrix}\operatorname*{\mathbb{P}}_{Q\times d(\mathcal{Q}_{k})}\{ \boldsymbol{X}\in B\}\geq\eta.\\ \boldsymbol{X}\sim Q^{d-1}\end{matrix}\]

Proof of Claim G.2.: Consider the inscribed cylinder \(C^{\prime}\subseteq C\)

\[C^{\prime}=\left\{\begin{bmatrix}t\\ \lambda\end{bmatrix}\in\mathbb{R}^{d}:t\in\mathbb{R}^{d-1}\text{ with }\|t\|_{2}\leq\frac{1}{3}\text{ and }\lambda\in\left[\frac{4}{3},\frac{5}{3}\right]\subseteq\mathbb{R}\right\}.\]Also, consider \(T^{\prime}\subseteq T\) and \(N^{\prime}\subseteq N\):

\[T^{\prime} =\left\{\begin{bmatrix}t\\ 0\end{bmatrix}\in\mathbb{R}^{d}:t\in\mathbb{R}^{d-1}\text{ with }\|t\|_{2}\leq\frac{1}{4}\right\},\] \[N^{\prime} =\left\{u\in S^{d-1}:|u\cdot e_{d}|\leq\frac{1}{36}\right\}.\]

Now, fix \(u\in N^{\prime}\) and \(t\in T^{\prime}\). Define the plane going through \(t\) with normal vector \(u\) as,

\[P(u,t)=\left\{t+x:x\in\mathbb{R}^{d}\text{ with }x\cdot u=0\right\}.\]

First, we show \(P(u,t)\cap C^{\prime}\) contains a \((d-1)\)-dimensional region. Consider,

\[y=\left[\begin{smallmatrix}t\\ \frac{3}{2}\end{smallmatrix}\right].\]

The projection onto \(P(u,t)\) of \(y\) is given by,

\[y^{\prime}=(y-t)-((y-t)\cdot u)u+t=\left[\begin{smallmatrix}t\\ \frac{3}{2}\end{smallmatrix}\right]-cu,\]

where \(|c|=|(y-t)\cdot u|\leq\frac{3}{2}\cdot\frac{1}{36}=\frac{1}{24}\). Since \(\|t\|_{2}\leq\frac{1}{4}\), the norm of the first \((d-1)\) dimensions of \(y^{\prime}\) is \(\leq\frac{1}{4}+\frac{1}{24}\leq\frac{1}{3}\) and \(y^{\prime}_{d}\in[\frac{3}{2}-\frac{1}{24},\frac{3}{2}+\frac{1}{24}]\), and so \(y^{\prime}\in C^{\prime}\). Moreover, adding any \(z\) with \(z\cdot u=0\) and \(\|z\|_{2}\leq\frac{1}{24}\) results in \(y^{\prime}+z\) with the norm of the first \(d-1\) dimensions being at most \(\frac{1}{4}+\frac{1}{24}+\frac{1}{24}\leq\frac{1}{3}\) and \((y^{\prime}+z)_{d}\in[\frac{3}{2}-\frac{1}{12},\frac{3}{2}+\frac{1}{12}]\). Hence, \(y^{\prime}+z\in C^{\prime}\). This shows that \(P(u,t)\cap C^{\prime}\) contains a \((d-1)\)-dimensional subspace, since it contains a \((d-1)\)-dimensional disk of radius \(\frac{1}{24}\).

Next, let

\[M=\left\{p+su:p\in C^{\prime}\cap P(u,t),s\in\left[-\frac{1}{6},\frac{1}{6} \right]\subseteq\mathbb{R}\right\}.\]

That is, \(M\) is a rectangular "extrusion" of \(C^{\prime}\cap P(u,t)\) along both its normal vectors. Indeed, we have \(M\subseteq C\), since adding a vector of length \(\leq\frac{1}{6}\) cannot take a point in \(C^{\prime}\) outside of \(C\). We also have that \(M\) is a \(d\)-dimensional region, so

\[\mathop{\mathbb{P}}_{X\sim G(1/10,t,u)}\left\{X\in C\right\}\geq\mathop{ \mathbb{P}}_{X\sim G(1/10,t,u)}\left\{X\in M\right\}>0.\]

Note that for \(\sigma\leq\frac{1}{10}\), we have

\[\mathop{\mathbb{P}}_{X\sim G(\sigma,t,u)}\left\{X\in M\right\}\geq\mathop{ \mathbb{P}}_{X\sim G(1/10,t,u)}\left\{X\in M\right\}.\]

This is because any \(x\in M\) can be written as \(t+x+cu\), where \(x\) is such that \(x\cdot u=0\), and \(|c|\leq\frac{1}{6}\). Plugging in this decomposition of \(x\) into the densities of \(G(1/10,u,t)\) and \(G(\sigma,u,t)\), and simplifying yields the above.

To conclude, for \(k\geq 10\), we have

\[\mathop{\mathbb{P}}_{\begin{subarray}{c}Q\sim\mathcal{U}(Q_{k})\\ \boldsymbol{X}\sim Q^{d-1}\end{subarray}}\left\{\begin{array}{l}\boldsymbol {X}\in C^{d-1}\right\} =\mathop{\mathbb{P}}_{\begin{subarray}{c}t\sim\mathcal{U}(T)\\ \boldsymbol{X}\sim G(1/k,t,u)^{d-1}\end{subarray}}\left\{\boldsymbol{X}\in C^{ d-1}\right\}\] \[=c\int_{T}\int_{N}\mathop{\mathbb{P}}_{\boldsymbol{X}\sim G(1/k,t,u)^{d-1}}\left\{\boldsymbol{X}\in C^{d-1}\right\}du\,dt\] \[\geq c\int_{T^{\prime}}\int_{N^{\prime}}\mathop{\mathbb{P}}_{ \boldsymbol{X}\sim G(1/k,t,u)^{d-1}}\left\{\boldsymbol{X}\in C^{d-1}\right\} du\,dt\] \[=c\int_{T^{\prime}}\int_{N^{\prime}}\left(\mathop{\mathbb{P}}_{X \sim G(1/k,t,u)}\left\{X\in C\right\}\right)^{d-1}du\,dt\] \[\geq c\int_{T^{\prime}}\int_{N^{\prime}}\left(\mathop{\mathbb{P}}_{ X\sim G(1/10,t,u)}\left\{X\in M\right\}\right)^{d-1}du\,dt\] \[=:\eta>0,\] (6)where \(c=f_{T}(t)\cdot f_{N}(u)>0\) is the uniform density over \(T\times N\). Note that the final integral is non-zero since \(T^{\prime}\times N^{\prime}\) has non-zero measure in \(T\times N\) and that \(\underset{X\sim G(1/10,t,u)}{\mathbb{P}}\left\{X\in M\right\}\) is indeed non-zero for all \(t\in T^{\prime},u\in N^{\prime}\). 

Upper bounding \(r_{k}\), the weight of \(\alpha\)-TV balls.We prove the following.

**Claim G.3**.: _For \(k\geq 1\), let_

\[r_{k}\coloneqq\sup_{p\in\mathcal{Q}_{k}}\underset{Q\sim\mathcal{U}(\mathcal{ Q}_{k})}{\mathbb{P}}\left\{\mathrm{TV}(p,Q)\leq\tfrac{1}{400}\right\}.\]

_Then we have,_

\[r_{k}=O\left(\frac{1}{k^{d}}\right)\to 0\quad\text{as }k\to\infty.\]

We use the following three facts regarding total variation distance, Gaussians, and the surface area of hyperspherical caps.

**Fact G.4** (Data-processing inequality for TV distance).: _Let \(p,q\in\Delta(\mathcal{X})\). For any measurable \(f\colon\mathcal{X}\to\mathcal{Y}\),_

\[\mathrm{TV}(f(p),f(q))\leq\mathrm{TV}(p,q),\]

_where for \(p\in\Delta(\mathcal{X})\), \(f(p)\) denotes the push-forward distribution assigning for all measurable \(A\subseteq\mathcal{Y}\), \(f(p)(A)=p(f^{-1}(A))\)._

**Fact G.5** (TV Distance between \(1\)-Dimensional Gaussians [1, Theorem 1.3]).: _Let \(\mathcal{N}(\mu_{1},\sigma_{1}^{2})\) and \(\mathcal{N}(\mu_{2},\sigma_{2}^{2})\) be Gaussians over \(\mathbb{R}\). Then_

\[\frac{1}{200}\cdot\min\left\{1,\max\left\{\frac{|\sigma_{1}^{2}- \sigma_{2}^{2}|}{\sigma_{1}^{2}},\frac{40|\mu_{1}-\mu_{2}|}{\sigma_{1}}\right\} \right\}\leq\mathrm{TV}\left(\mathcal{N}\left(\mu_{1},\sigma_{1}^{2}\right), \mathcal{N}\left(\mu_{2},\sigma_{2}^{2}\right)\right).\]

**Fact G.6** (Surface area of hyperspherical caps [11]).: _For \(u\in S^{d-1}\) and \(\theta\in[0,\frac{\pi}{2}]\), define_

\[C(u,\theta)=\left\{x\in S^{d-1}:\angle(x,u)\leq\theta\right\}\]

_where for \(u,v\in S^{d-1}\), \(\angle(u,v)\coloneqq\cos^{-1}(u\cdot v)\). We have_

\[\mathrm{Area}(C(u,\theta))=\frac{2\pi^{(d-1)/2}}{\Gamma(\tfrac{d-1}{2})}\cdot \int_{0}^{\theta}\sin^{d-2}(x)dx.\]

_Note that_

\[\mathrm{Area}(S^{d-1})=\frac{2\pi^{d/2}}{\Gamma(\tfrac{d}{2})}.\]

Proof of Claim G.3.: Let \(\sigma>0\). Let \(t_{1},t_{2}\in T\) and \(u_{1},u_{2},\in N\). We will compare the total variation distance of the Gaussians defined by these parameters. Let

\[D_{\sigma}=\begin{bmatrix}\sigma^{2}&&\\ &1&O\\ &O&\ddots\\ &&&1\end{bmatrix}.\]

By Fact G.4, taking \(f\colon\mathbb{R}^{d}\to\mathbb{R}\) to be \(f(x)=u_{1}^{\top}(x-t_{1})\),

\[\mathrm{TV}(G(\sigma,t_{1},u_{2}),G(\sigma,t_{2},u_{2})) \geq\mathrm{TV}(\mathcal{N}(u_{1}^{\top}(t_{1}-t_{1}),u_{1}^{\top }R_{u_{1}}D_{\sigma}R_{u_{1}}^{\top}u_{1}),\mathcal{N}(u_{1}^{\top}(t_{2}-t_{1 }),u_{1}^{\top}R_{u_{2}}D_{\sigma}R_{u_{2}}^{\top}u_{1}))\] \[=\mathrm{TV}(\mathcal{N}(0,\sigma^{2}),\mathcal{N}(u_{1}\cdot \Delta t,\sigma^{2}\cos^{2}(\angle(u_{1},u_{2}))+\sin^{2}(\angle(u_{1},u_{2})))),\]where \(\Delta t=t_{2}-t_{1}\). For the last line above, we take \(R_{u_{2}}=[u_{2},v_{2},\ldots,v_{d}]\), where \(\{v_{2},\ldots,v_{d}\}\) is an orthonormal basis for \(\{u_{2}\}^{\perp}\). Then the equality in the last line for the variance of the second Gaussian uses,

\[u_{1}^{\top}R_{u_{2}}D_{\sigma}R_{u_{2}}^{\top}u_{1} =\sigma^{2}(u_{1}\cdot u_{2})^{2}+(v_{2}\cdot u_{2})^{2}+\cdots+(v _{d}\cdot u_{2})^{2}\] \[=\sigma^{2}(u_{1}\cdot u_{2})^{2}+(1-(u_{1}\cdot u_{2})^{2})\] \[=\sigma^{2}\cos^{2}(\angle(u_{1},u_{2}))+(1-\cos^{2}(\angle(u_{1},u_{2})))\] \[=\sigma^{2}\cos^{2}(\angle(u_{1},u_{2}))+\sin^{2}(\angle(u_{1},u_ {2})),\]

where \(R_{u_{2}}\) being unitary implies that \((u_{1}\cdot u_{2})^{2}+(u_{1}\cdot v_{2})^{2}+\cdots+(u_{2}\cdot v_{d})^{2}=1\), yielding the second equality in the above.

We show that if \(\angle(u_{1},u_{2})\in[\frac{\sqrt{2}\pi}{2}\sigma,\pi-\frac{\sqrt{2}\pi}{2}\sigma]\), \(\mathrm{TV}(G(\sigma,t_{1},u_{1}),G(\sigma,t_{2},u_{2}))\geq\frac{1}{200}\). First, we consider the case where \(\angle(u_{1},u_{2})\in[\frac{\sqrt{2}\pi}{2}\sigma,\frac{\pi}{2}]\). Using that on \([0,\frac{\pi}{2}]\), we have \(\sin(x)\geq\frac{2}{\pi}x\) and \(\cos(x)\geq 0\), we get

\[\sigma^{2}\cos^{2}(\angle(u_{1},u_{2}))+\sin^{2}(\angle(u_{1},u_{2}))\geq\frac {4}{\pi^{2}}\angle(u_{1},u_{2})^{2}\geq 2\sigma^{2}.\] (7)

Therefore,

\[\frac{\sigma_{1}^{2}-\sigma_{2}^{2}}{\sigma_{1}^{2}}\leq\frac{\sigma^{2}-2 \sigma^{2}}{\sigma^{2}}\leq-1,\]

and by Fact G.5, we can conclude that \(\mathrm{TV}(G(\sigma,t_{1},u_{1}),G(\sigma,t_{2},u_{2}))\geq\frac{1}{200}\). Now, consider the case where \(\angle(u_{1},u_{2})\in[\frac{\pi}{2},\pi-\frac{\sqrt{2}\pi}{2}]\). Note that in this case, there exists \(u_{2}^{\prime}=-u_{2}\in[\frac{\sqrt{2}\pi}{2},\frac{\pi}{2}]\) with \(G(\sigma,t_{2},u_{2})=G(\sigma,t_{2},u_{2}^{\prime})\), bringing us back to the previous case.

Next, note that since \(\|u_{1}\|_{2}=1\) and \(|u_{1}^{(d)}|=|u_{1}\cdot e_{d}|\leq\frac{\sqrt{3}}{2}\) (by the definition of \(N\)), letting \(r=[u_{1}^{(1)},\ldots,u_{1}^{(d-1)}]^{\top}\in\mathbb{R}^{d-1}\), we have \(\|r\|_{2}\geq\frac{1}{2}\). Let \(\hat{r}=\frac{r}{\|r\|_{2}}\). We have that if \([\Delta t_{1},\ldots,\Delta t_{d-1}]^{\top}\cdot\hat{r}\geq\frac{1}{20}\sigma\), then,

\[u_{1}\cdot\Delta t =r\cdot[\Delta t_{1},\ldots,\Delta t_{d-1}]^{\top}\] \[\geq\frac{r}{2\|r\|_{2}}\cdot[\Delta t_{1},\ldots,\Delta t_{d-1} ]^{\top}\] \[\geq\frac{1}{2}\hat{r}\cdot[\Delta t_{1},\ldots,\Delta t_{d-1}]^{\top}\] \[\geq\frac{1}{40}\sigma.\]

This implies that

\[\frac{40(\mu_{1}-\mu_{2})}{\sigma_{1}}=\frac{40(-u_{1}\cdot\Delta t)}{\sigma} \leq-1,\]

and by Fact G.5, we can conclude \(\mathrm{TV}(G(\sigma,t_{1},u_{1}),G(\sigma,t_{2},u_{2}))\geq\frac{1}{200}\). Therefore, for any \(u\in N\), \(t\in T\),

\[\mathbb{P}_{Q\sim\mathcal{U}(\mathcal{Q}_{k})}\left\{\mathrm{TV} (G(\tfrac{1}{k},t,u),Q)\leq\frac{1}{400}\right\} =\mathbb{P}_{\begin{subarray}{c}t^{\prime}\sim\mathcal{U}(T)\\ u^{\prime}\sim\mathcal{U}(N)\end{subarray}}\left\{\mathrm{TV}(G(\tfrac{1}{k},t,u),G(\tfrac{1}{k},t^{\prime},u^{\prime}))\leq\frac{1}{400}\right\}\] \[\leq\mathbb{P}_{\begin{subarray}{c}t^{\prime}\sim\mathcal{U}(T)\\ u^{\prime}\sim\mathcal{U}(N)\end{subarray}}\left\{\mathrm{TV}(G(\tfrac{1}{k},t,u),G(\tfrac{1}{k},t^{\prime},u^{\prime}))<\frac{1}{200}\right\}\] \[\leq\mathbb{P}_{\begin{subarray}{c}t^{\prime}\sim\mathcal{U}(T) \\ u^{\prime}\sim\mathcal{U}(N)\end{subarray}}\left\{[\Delta t_{1},\ldots,\Delta t _{d-1}]^{\top}\cdot\hat{r}<\tfrac{1}{20k}\right\}\.\]For the first term, note that the event

\[\left\{[\Delta t_{1},\ldots,\Delta t_{d-1}]\cdot\hat{r}<\tfrac{1}{20k}\right\} \subseteq\left\{t^{\prime}\in\left\{t+\begin{bmatrix}x\\ 0\end{bmatrix}+\lambda\begin{bmatrix}\hat{r}\\ 0\end{bmatrix}:\|x\|_{2}\leq 1,x\cdot\hat{r}=0,\lambda\leq\frac{1}{20k} \right\}\right\},\]

which under \(\mathcal{U}(T)\), for some \(c_{d}>0\) depending only on \(d\), has probability \(\leq c_{d}\cdot\frac{1}{20k}\).

For the second term, note that \(\angle(u,u^{\prime})\in[0,\frac{\sqrt{2}\pi}{2k})\cup(\pi-\frac{\sqrt{2}\pi}{2 k},\pi]\) means \(u^{\prime}\in C(u,\frac{\sqrt{2}\pi}{2k})\cup C(-u,\frac{\sqrt{2}\pi}{2k})\). By Fact G.6, we know that under \(\mathcal{U}(N)\), for some \(c_{d}\) depending only on \(d\),

\[\mathop{\mathbb{P}}_{u^{\prime}\sim\mathcal{U}(N)}\left\{u^{ \prime}\in C(u,\frac{\sqrt{2}\pi}{2k})\right\} =c_{d}\cdot\int_{0}^{\sqrt{2}\pi/2k}\sin^{d-2}(x)dx\] \[\leq c_{d}\cdot\int_{0}^{\sqrt{2}\pi/2k}x^{d-2}dx\] \[=\frac{c_{d}}{d-1}\left(\frac{\sqrt{2}\pi}{2}\right)^{d-1}\frac{ 1}{k^{d-1}}.\]

The bound is the same for \(C(-u,\frac{\sqrt{2}\pi}{2k})\). Plugging these into the above, we can conclude that

\[r_{k}=\sup_{p\in\mathcal{Q}_{k}}\mathop{\mathbb{P}}_{\mathcal{Q} \sim\mathcal{U}(\mathcal{Q}_{k})}\left\{\mathrm{TV}(p,Q)\leq\frac{1}{400} \right\}\leq O\left(\frac{1}{k^{d}}\right)\to 0\quad\text{as }k\to\infty.\]

This proves the claim. 

Lower bounding \(\boldsymbol{s}_{k}\), the weight of alternative hypotheses.First, we note that

\[u_{k}=\sup_{\begin{subarray}{c}\boldsymbol{x}\in B\\ q\in\mathcal{Q}_{k}\end{subarray}}q^{d-1}(\boldsymbol{x})=\left(\frac{1}{(2 \pi)^{d/2}}k\exp(-\tfrac{1}{2})\right)^{d-1},\]

which is achieved by \(G(\frac{1}{k},\boldsymbol{0},e_{1})\) (where \(\boldsymbol{0}\in\mathbb{R}^{d}\) is the origin) and \(\boldsymbol{x}=(e_{d},\ldots,e_{d})\). Let

\[c=\frac{\exp(-5)^{d-1}}{\exp(-\tfrac{1}{2})^{d-1}}=\exp\left( \frac{9(d-1)}{2}\right).\]

**Claim G.7**.: _For \(k\geq 1\), letting \((u_{k})_{k=1}^{\infty}\) and \(c\) be defined as above, define_

\[s_{k}\coloneqq\inf_{\boldsymbol{x}\in B}\mathop{\mathbb{P}}_{ \mathcal{Q}\sim\mathcal{U}(\mathcal{Q}_{k})}\big{\{}Q^{d-1}(\boldsymbol{x}) \geq cu_{k}\big{\}}.\]

_Then we have,_

\[s_{k}=\Omega\left(\frac{1}{k^{d-1}}\right)\to 0\quad\text{as }k\to\infty.\]

Proof of Claim G.7.: Let \(k\geq 1\). Fix any \(\boldsymbol{x}=(x_{1},\ldots,x_{d-1})\in B\). For every \(t\in T\), there exists \(u\in\{x_{1}-t,x_{2}-t,\ldots,x_{d-1}-t\}^{\perp}\). We show \(\angle(u,e_{d})\geq\frac{\pi}{4}\). Suppose otherwise, that is, \(\angle(u,e_{d})<\frac{\pi}{4}\implies|u\cdot e_{d}|=|u^{(d)}|>\frac{\sqrt{2}}{2}\). Then,

\[u\cdot(x_{1}-t)=u^{(1)}(x_{1}^{(1)}-t^{(1)})+\cdots+u^{(d-1)}(x_{1}^{(d-1)}-t ^{(d-1)})+u^{(d)}x_{1}^{(d)}.\]

By our assumption on \(u^{(d)}\), and by the fact that \(x_{1}\in C\), we have that \(|u^{(d)}x_{1}^{(d)}|>\frac{\sqrt{2}}{2}\). By Cauchy-Schwarz in \(\mathbb{R}^{d-1}\), we have that,

\[|u^{(1)}(x_{1}^{(1)}-t^{(1)})+\ldots +u^{(d-1)}(x_{1}^{(d-1)}-t^{(d-1)})|\] \[\leq\|[u^{(1)},\ldots,u^{(d-1)}]^{\top}\|_{2}\cdot\|[x_{1}^{(1) },\ldots,x_{1}^{(d-1)}]^{\top}-[t^{(1),\ldots,t^{(d-1)}}]^{\top}\|_{2}\] \[<\frac{\sqrt{2}}{2}\cdot 1.\]The last inequality uses that \(\|u\|_{2}=1\) and \((u^{(d)})^{2}>\frac{1}{2}\), so the norm of the first \((d-1)\) coordinates is \(<\frac{\sqrt{2}}{2}\), and also the fact that the first \((d-1)\) coordinates of \(x\) and \(t\) are in the \(\frac{1}{2}\)-disk. This inequality, combined with the fact that \(|u^{(d)}x_{1}^{(d)}|>\frac{\sqrt{2}}{2}\) contradicts that that \((x_{1}-t)\cdot u=0\).

Now, for the \(t\) and the \(u\) from above, consider an arbitrary \(u^{\prime}\) with \(\angle(u,u^{\prime})\leq\frac{1}{k}\), and the Gaussian with mean \(t\) and normal vector \(u^{\prime}\), \(G(\frac{1}{k},t,u^{\prime})\). We will show that any such Gaussian assigns high mass to the point \(x\), and furthermore that there is a high density of such Gaussians. Note that for \(k\geq 5\), \(\frac{1}{k}\leq\frac{\pi}{3}-\frac{\pi}{4}\implies\angle(u^{\prime},e_{d})\geq \frac{\pi}{3}\implies u^{\prime}\in N\). We compute the minimum density this Gaussian assigns to \(\bm{x}\). Consider, for \(i\in[d-1]\),

\[(x_{i}-t)^{\top}(R_{u^{\prime}}D_{1/k}R_{u^{\prime}}^{\top})^{-1}( x_{i}-t) =\|D_{\sqrt{k}}R_{u^{\prime}}^{\top}(x_{i}-t)\|^{2}\] \[=k^{2}|u^{\prime}\cdot(x_{i}-t)|^{2}+|v_{2}\cdot(x_{i}-t)|^{2}+ \cdots+|v_{d}\cdot(x_{i}-t)|^{2}\] \[\leq 5(k^{2}|u^{\prime}\cdot\hat{r}|^{2}+1),\]

where \(\hat{r}=(x_{i}-t)/\|x_{i}-t\|\) and \(\{v_{2},\ldots,v_{d}\}\) is an orthonormal basis of \(\{u^{\prime}\}^{\perp}\). We have that,

\[|u^{\prime}\cdot\hat{r}|^{2} =|(u+(u-u^{\prime}))\cdot\hat{r}|^{2}\] \[\leq\|u-u^{\prime}\|_{2}^{2}\cdot\|\hat{r}\|_{2}^{2}\] \[=u\cdot u-2u\cdot u^{\prime}+u^{\prime}\cdot u^{\prime}\] \[=2-2\cos(\angle(u^{\prime},u))\] \[\leq 2-2(1-\frac{\angle(u^{\prime},u)^{2}}{2})\] \[=\angle(u^{\prime},u)^{2}\leq\frac{1}{k^{2}}.\]

Hence, the density of \(G(\frac{1}{k},t,u^{\prime})\) on \(\bm{x}\) is lower bounded by,

\[\left(\frac{1}{(2\pi)^{d/2}}k\exp(-5)\right)^{d-1}=cu_{k}.\]

For every \(t\in T\), we found a set of \(u^{\prime}\in N\) such that the density \(G(\frac{1}{k},t,u^{\prime})\) assigns to \(\bm{x}\) is greater than \(cu_{k}\). Since for some constant \(c_{d}>0\) depending only on \(d\),

\[\mathop{\mathbb{P}}_{u^{\prime}\sim\mathcal{U}(N)}\left\{u^{ \prime}\in C(u,\frac{1}{k})\right\} =c_{d}\int_{0}^{1/k}\sin^{d-2}(x)dx\] \[\geq c_{d}\int_{0}^{1/k}\left(\frac{2}{\pi}x\right)^{d-2}dx\] \[=c_{d}\left(\frac{2}{\pi}\right)^{d-2}\frac{1}{d-1}\cdot\frac{1}{ k^{d-1}},\]

and since \(\bm{x}\in B\) was arbitrary, we indeed have,

\[s_{k}=\inf_{\bm{x}\in B}\mathop{\mathbb{P}}_{Q\sim\mathcal{U}(\mathcal{Q}_{k}) }\left\{Q^{d-1}(\bm{x})\geq cu_{k}\right\}=\Omega\left(\frac{1}{k^{d-1}}\right).\]

This completes the proof of the claim. 

With the three claims, applying Lemma G.1 allows us to conclude that the class of all Gaussians in \(\mathbb{R}^{d}\) is not list learnable with \(m(\alpha,\beta)=d-1\) samples. This implies that the class is also not public-privately learnable with \(m(\alpha,\beta,\varepsilon)=d-1\) public samples. 

Appendix H Statements and proofs for Section 7 - Learning when the Yatracos class has finite VC dimension

When the VC dimension of the Yatracos class of \(\mathcal{Q}\) is finite, the following gives an upper bound on the number of samples required to non-privately learn \(\mathcal{Q}\).

**Fact H.1** ([12], [13, Theorem 6.4]).: _Let \(\mathcal{Q}\subseteq\Delta(\mathcal{X})\). Let \(\mathcal{H}\) be the Yatracos class of \(\mathcal{Q}\), and let \(d=\operatorname{VC}(\mathcal{H})\). \(\mathcal{Q}\) is learnable with_

\[m=O\left(\frac{d+\log(\frac{1}{\beta})}{\alpha^{2}}\right)\]

_samples._

For some classes of distributions, the above bound is tight. For example, it recovers the \(\Theta(\frac{d^{2}}{\alpha^{2}})\) sample complexity for learning Gaussians in \(\mathbb{R}^{d}\)[1].

To prove Theorem 7.2 we employ the following result on generating distribution-dependent covers for binary hypothesis classes with public data.

**Fact H.2** (Public data cover [1, Lemma 3.3 restated]).: _Let \(\mathcal{H}\subseteq 2^{\mathcal{X}}\) and \(\operatorname{VC}(\mathcal{H})=d\). There exists \(\mathcal{A}\colon\mathcal{X}^{*}\to\{H\subseteq 2^{\mathcal{X}}:|H|<\infty\}\), such that for any \(\alpha,\beta\in(0,1]\) there exists_

\[m=O\left(\frac{d\log(\frac{1}{\alpha})+\log(\frac{1}{\beta})}{\alpha}\right)\]

_such that for any \(p\in\Delta(\mathcal{X})\), if we draw \(\boldsymbol{X}=(X_{1},\ldots,X_{m})\) i.i.d. from \(p\), with probability \(\geq 1-\beta\), \(\mathcal{A}(\boldsymbol{X})\) outputs \(\widehat{\mathcal{H}}\subseteq 2^{\mathcal{X}}\) and a mapping \(f\colon\mathcal{H}\to\widehat{\mathcal{H}}\) with_

\[p(h\triangle f(h))\leq\alpha\qquad\text{for all }h\in\mathcal{H}\]

_(where for \(A,B\subseteq\mathcal{X}\), \(A\triangle B\) denotes the symmetric set difference \((A\setminus B)\cup(B\setminus A)\)). Furthermore, we have \(|\widehat{\mathcal{H}}|\leq\left(\frac{\varepsilon m}{d}\right)^{2d}\)._

We also use the following pure DP algorithm for answering counting queries on finite domains.

**Fact H.3** (SmallDB [1], [13, Theorem 4.5]).: _Let \(\mathcal{X}\) be a finite domain. Let \(\mathcal{H}\subseteq 2^{\mathcal{X}}\). Let \(\alpha,\beta\in(0,1]\) and \(\varepsilon>0\), There is an \(\varepsilon\)-DP randomized algorithm, that on any dataset \(\boldsymbol{x}=(x_{1},\ldots,x_{n})\) with_

\[n=\Omega\left(\frac{\log(|\mathcal{X}|)\log(|\mathcal{H}|)+\log(\frac{1}{ \beta})}{\varepsilon\alpha^{3}}\right)\]

_outputs estimates \(\hat{g}\colon\mathcal{H}\to\mathbb{R}\) such that with probability \(\geq 1-\beta\),_

\[\left|\hat{g}(h)-\frac{1}{n}\sum_{i=1}^{n}\mathds{1}_{h}(x_{i})\right|\leq \alpha\qquad\text{for all }h\in\mathcal{H}.\]

Proof of Theorem 7.2.: We use our \(m\) public samples from the unknown \(p\in\mathcal{Q}\) to generate a public data cover \(\widehat{\mathcal{H}}\) and mapping \(f\colon\mathcal{H}\to\widehat{\mathcal{H}}\) courtesy of Fact H.2, selecting \(m\) to target error \(\frac{\alpha}{6}\) and failure probability \(\frac{\beta}{3}\). Note that this implies that with probability \(\geq 1-\frac{\beta}{3}\), for every \(h\in\mathcal{H}\), \(|p(h)-p(f(h))|\leq\left|p(h\triangle f(h))\right|\leq\frac{\alpha}{6}\).

Next, we consider the representative domain of \(\mathcal{X}\) with respect to \(\widehat{\mathcal{H}}\), denoted by \(\mathcal{X}_{\widehat{\mathcal{H}}}\). In other words, for every unique behaviour \((\mathds{1}_{\hat{h}}(x))_{\hat{h}\in\widehat{\mathcal{H}}}\in\{0,1\}^{| \widehat{\mathcal{H}}|}\) induced by a point \(x\in\mathcal{X}\) on \(\widehat{\mathcal{H}}\), we include exactly one representative \([x]\) in \(\mathcal{X}_{\widehat{\mathcal{H}}}\). By Sauer's lemma we can conclude that

\[|\mathcal{X}_{\widehat{\mathcal{H}}}|\leq\left(\frac{e|\widehat{\mathcal{H}}| }{d^{*}}\right)^{d^{*}}.\]

Then, we take our \(n\) private samples \(\boldsymbol{X}=(X_{1},\ldots,X_{n})\) and map each point \(X_{i}\) to its representative \([X_{i}]\in\mathcal{X}_{\widehat{\mathcal{H}}}\), yielding a dataset of \(n\) examples \([\boldsymbol{X}]\) on the finite domain \(\mathcal{X}_{\widehat{\mathcal{H}}}\). Note that for any \(\hat{h}\in\widehat{\mathcal{H}}\), \(\frac{1}{n}\sum_{i=1}^{n}\mathds{1}_{\hat{h}}(X_{i})=\frac{1}{n}\sum_{i=1}^{ n}\mathds{1}_{\hat{h}}([X_{i}])\). Hence when we run SmallDB (Fact H.3) on the input \([\boldsymbol{X}]\) over the finite domain \(\mathcal{X}_{\widehat{\mathcal{H}}}\) with finite class \(\widehat{\mathcal{H}}\), choosing \(n\) large enough, we obtain \(\hat{g}:\widehat{\mathcal{H}}\to\mathbb{R}\) such that with probability \(\geq 1-\frac{\beta}{3},|\hat{g}(\hat{h})-\frac{1}{n}\sum_{i=1}^{n}\mathds{1}_{ \hat{h}}(X_{i})|\leq\frac{\alpha}{6}\) for all \(\hat{h}\in\widehat{\mathcal{H}}\).

We also ensure \(n\) is large enough so that we get the uniform convergence property on \(\widehat{\mathcal{H}}\), which has VC dimension \(d\), with the private samples. That is, for all \(\hat{h}\in\widehat{\mathcal{H}}\), with probability \(\geq 1-\frac{\beta}{3}\), \(|p(\hat{h})-\frac{1}{n}\sum_{i=1}^{n}\mathds{1}_{\hat{h}}(X_{i})|\leq\frac{ \alpha}{6}\).

As a post-processing of \(\hat{g}\), our learner outputs

\[\hat{q}\coloneqq\arg\min_{q\in\mathcal{Q}}\sup_{h\in\mathcal{H}}|q(h)-\hat{g} (f(h))|.\]

By the union bound, with probability \(\geq 1-\beta\), all of our good events occur. In this case, we have for all \(h\in\mathcal{H}\),

\[|p(h)-p(f(h))| \leq\tfrac{\alpha}{6}\] \[\left|p(f(h))-\tfrac{1}{n}\sum_{i=1}^{n}\mathds{1}_{f(h)}(X_{i})\right| \leq\tfrac{\alpha}{6}\] \[\left|\tfrac{1}{n}\sum_{i=1}^{n}\mathds{1}_{f(h)}(X_{i})-\hat{g} (f(h))\right| \leq\tfrac{\alpha}{6}\]

which implies \(|p(h)-\hat{g}(f(h))|\leq\frac{\alpha}{2}\). So for any \(q\in\mathcal{Q}\),

\[|q(h)-p(h)|-\frac{\alpha}{2}\leq|q(h)-\hat{g}(f(h))| \leq|q(h)-p(h)|+\frac{\alpha}{2}\] \[\implies\operatorname{TV}(q,p)-\frac{\alpha}{2}\leq\sup_{h\in \mathcal{H}}|q(h)-\hat{g}(f(h))| \leq\operatorname{TV}(q,p)+\frac{\alpha}{2}.\]

We have that

\[\sup_{h\in\mathcal{H}}|\hat{q}(h)-\hat{g}(f(h)|\leq\sup_{h\in \mathcal{H}}|p(h)-\hat{g}(f(h)|\leq\operatorname{TV}(p,p)+\frac{\alpha}{2} \leq\frac{\alpha}{2}.\]

Therefore,

\[\operatorname{TV}(\hat{q},p)\leq\sup_{h\in\mathcal{H}}|\hat{q}(h)-\hat{g}(f(h )|+\frac{\alpha}{2}\leq\alpha.\]

It can be verified that the choices of \(m\) and \(n\) in the statement of Theorem 7.2 suffice.