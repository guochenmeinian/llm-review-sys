# Global Update Tracking: A Decentralized Learning Algorithm for Heterogeneous Data

Sai Aparna Aketi Abolfazl Hashemi  Kaushik Roy

Department of Electrical and Computer Engineering

Purdue University

West Lafayette, IN 47906

{saketi, abolfazl, kaushik}@purdue.edu

###### Abstract

Decentralized learning enables training of deep learning models over large distributed datasets generated at different locations, without the need for a central server. However, in practical scenarios, the data distribution across these devices can be significantly different, leading to a degradation in model performance. In this paper, we focus on designing a decentralized learning algorithm that is less susceptible to variations in data distribution across devices. We propose Global Update Tracking (GUT), a novel tracking-based method that aims to mitigate the impact of heterogeneous data in decentralized learning without introducing any communication overhead. We demonstrate the effectiveness of the proposed technique through an exhaustive set of experiments on various Computer Vision datasets (CIFAR-10, CIFAR-100, Fashion MNIST, and ImageNet), model architectures, and network topologies. Our experiments show that the proposed method achieves state-of-the-art performance for decentralized learning on heterogeneous data via a \(1-6\%\) improvement in test accuracy compared to other existing techniques.

## 1 Introduction

Decentralized learning is a branch of distributed optimization which focuses on learning from data distributed across multiple agents without a central server. It offers many advantages over the traditional centralized approach in core aspects such as data privacy, fault tolerance, and scalability [18]. It has been demonstrated that decentralized learning algorithms [15] can perform comparable to centralized algorithms on benchmark vision datasets. Decentralized Parallel Stochastic Gradient Descent (DSGD) presented in [15] combines SGD with a gossip averaging algorithm [26]. Further, the authors analytically show that the convergence rate of DSGD is similar to its centralized counterpart [5]. A momentum version of DSGD referred to as Decentralized Momentum Stochastic Gradient Descent (DSGDm) was proposed in [3]. The authors in [2] introduce Stochastic Gradient Push (SGP) which extends DSGD to directed and time-varying graphs. Recently, a unified framework for analyzing gossip-based decentralized SGD methods and the best-known convergence guarantees was presented in [11].

One of the key assumptions to achieve state-of-the-art performance by all the above-mentioned decentralized algorithms is that the data is independently and identically distributed (IID) across the agents. In particular, the data is assumed to be distributed in a uniform and random manner across the agents. This assumption does not hold in most real-world settings where the data distributions across the agents are significantly different (non-IID/heterogeneous) [9]. The effect of heterogeneous data in a peer-to-peer decentralized setup is a relatively under-studied problem and an active area of research.

Recently, there have been few efforts to bridge the performance gap between IID and non-IID data for a decentralized setup [16; 23; 19; 7; 1; 24]. Cross Gradient Aggregation [7] and NeighborhoodGradient Clustering [1] algorithms utilize the concept of cross-gradients to reduce the impact of heterogeneous data and show significant improvement in performance (test accuracy). However, these techniques incur \(2\times\) communication cost than the standard decentralized algorithms such as DSGD. \(D^{2}\) algorithm proposed in [23] is shown to be agnostic to data heterogeneity and can be employed in deep learning tasks. One of the major limitations of \(D^{2}\) is that its convergence requires mixing topologies with negative eigenvalue bounded from below by \(-\frac{1}{3}\). Additionally, it has been shown that \(D^{2}\) performs worse than DSGD in some cases [16].

Tracking mechanisms such as Gradient Tracking (GT) [6; 19] and Momentum Tracking (MT) [22] have been proposed to tackle heterogeneous data in decentralized settings. But these algorithms improve the performance at the cost of \(2\times\) communication overhead. The authors in [16] introduce Quasi-Global Momentum (QGM), a decentralized learning method that mimics the global synchronization of momentum buffer to mitigate the difficulties of decentralized learning on heterogeneous data. Recently, RelaySGD was presented in [24] that replaces the gossip averaging step with RelaySum. Since RelaySGD deals with the gossip averaging step, it is orthogonal to the aforementioned algorithms and can be used in synergy with them. QG-DSGDm [16] which incorporates QGM into DSGDm sets the current state-of-the-art for decentralized learning on heterogeneous data without increasing the communication cost. This work investigates the following question: _Can we improve decentralized learning on heterogeneous data through a tracking mechanism without any communication overhead?_

To that effect, we present _Global Update Tracking (GUT)_, a novel decentralized learning algorithm designed to improve performance under heterogeneous data distribution. Motivated by, yet distinct from, the gradient tracking mechanism, we propose to track the consensus model (\(\bar{x}^{t}\)) by tracking global/average model updates, where \(x^{t}_{i}\) is the model parameters on agent \(i\) at time step \(t\) and \(\bar{x}\) is the averaged model parameters. In the traditional tracking-based methods [19; 22] that track average gradients, each agent communicates both model parameters \(x^{t}_{i}\) and the tracking variable \(y^{t}_{i}\) with its neighbors resulting in \(2\times\) communication overhead. The proposed _GUT_ algorithm overcomes this bottleneck by allowing agents to store a copy of their neighbors' model parameters and then tracking the model updates instead of the gradients. This results in communicating only the tracking variable \(y^{t}_{i}\) that yields the model update (\(x^{t}_{i}-x^{t-1}_{i}\)). We demonstrate the effectiveness of the proposed algorithm through an exhaustive set of experiments on various datasets, model architectures, and graph topologies. We also provide a detailed convergence analysis showing that the convergence rate of _GUT_ algorithm is consistent with the state-of-the-art decentralized learning algorithms. Further, we show that _QG-GUTm_ - Global Update Tracking with Quasi-Global momentum beats the current state-of-the-art decentralized learning algorithm (i.e., QG-DSGDm) on heterogeneous data under iso-communication cost.

### Contributions

In summary, we make the following contributions.

* We propose _Global Update Tracking (GUT)_, a novel tracking-based decentralized learning algorithm to mitigate the impact of heterogeneous data distribution.
* We theoretically establish the non-asymptotic convergence rate of the proposed algorithm to a first-order solution.
* Through an exhaustive set of experiments on various datasets, model architectures, and graph topologies, we establish that the proposed Global Update Tracking with Quasi-Global momentum (_QG-GUTm_) outperforms the current state-of-the-art decentralized learning algorithm on a spectrum of heterogeneous data.

## 2 Background

In this section, we provide the background on the decentralized setup with peer-to-peer connections.

The main goal of decentralized machine learning is to learn a global model using the knowledge extracted from the locally stored data samples across \(n\) agents while maintaining privacy constraints. In particular, we solve the optimization problem of minimizing the global loss function \(f(x)\) distributed across \(n\) agents as given in (1). Note that \(F_{i}\) is a local loss function (for example, cross-entropy loss)defined in terms of the data (\(d_{i}\)) sampled from the local dataset \(D_{i}\) at agent \(i\).

\[\begin{split}\min_{x\in\mathbb{R}^{d}}f(x)&=\frac{1}{n }\sum_{i=1}^{n}f_{i}(x),\\ \text{where}\ \ f_{i}(x)&=\mathbb{E}_{d_{i}\sim D_{i}}[F_ {i}(x;d_{i})],\ \ \text{for all}\ i.\end{split}\] (1)

The optimization problem is typically solved by combining stochastic gradient descent [4] with global consensus-based gossip averaging [26]. The communication topology is modeled as a graph \(G=([N],E)\) with edges \(\{i,j\}\in E\) if and only if agents \(i\) and \(j\) are connected by a communication link exchanging the messages directly. We represent \(\mathcal{N}(i)\) as the neighbors of agent \(i\) including itself. It is assumed that the graph \(G\) is strongly connected with self-loops i.e., there is a path from every agent to every other agent. The adjacency matrix of the graph \(G\) is referred to as a mixing matrix \(W\) where \(w_{ij}\) is the weight associated with the edge \(\{i,j\}\). Note that, weight \(0\) indicates the absence of a direct edge between the agents, and the elements of the Identity matrix are represented by \(I_{ij}\). Similar to the majority of previous works in decentralized learning, the mixing matrix is assumed to be doubly stochastic. Further, the initial models and all the hyperparameters are synchronized at the beginning of the training. The communication among the agents is assumed to be synchronous.

Traditional decentralized algorithms such as DSGD [15] assume the data across the agents to be Independent and Identically Distributed (IID). In DSGD, each agent \(i\) maintains local parameters \(x_{i}^{t}\in\mathbb{R}^{d}\) and updates them as follows.

\[\text{DSGD:}\ \ x_{i}^{t+1}=\sum_{j\in\mathcal{N}(i)}w_{ij}(x_{j}^{t}-\eta g _{j}^{t});\ \ \ \ g_{i}^{t}=\nabla F_{j}(x_{i}^{t},d_{i}^{t}).\] (2)

We focus on a decentralized setup with non-IID/heterogeneous data. In particular, the heterogeneity in the data distribution comes in the form of skewed label partition similar to [9]. Decentralized learning with the DSGD algorithm on heterogeneous data distribution results in performance degradation due to huge variations in the local gradients across the agents. To tackle this, authors in [16] propose a momentum-based optimization technique (QG-DSGDm) introducing Quasi-Global momentum as shown in (3).

\[\begin{split}\text{QG-DSGDm:}\ \ x_{i}^{t+1}=\sum_{j\in \mathcal{N}(i)}w_{ij}[x_{j}^{t}-\eta(g_{j}^{t}+\beta m_{j}^{t-1})];\ \ m_{i}^{t}=\mu m_{i}^{t-1}+(1-\mu)\frac{x_{i}^{t-1}-x_{i}^{t}}{\eta}.\end{split}\] (3)

QG-DSGDm improves the performance of decentralized learning on heterogeneous data without any communication overhead and is used as a baseline for comparison in this work.

Gradient Tracking (GT) mechanisms [19; 22] are also known to improve decentralized learning on heterogeneous data by reducing the variance between the local gradient and the averaged (global) gradient. To achieve this, the gradient tracking algorithm introduces a tracking variable \(y_{i}^{t}\) that approximates the total gradient and is used to update the local parameters \(x_{i}^{t}\) (refer to (4)).

\[\begin{split}\text{GT:}\ \ x_{i}^{t+1}=\sum_{j\in\mathcal{N}(i)}w_{ ij}(x_{j}^{t}-\eta y_{j}^{t});\ \ \ \ y_{i}^{t}=\sum_{j\in\mathcal{N}(i)}w_{ij}y_{j}^{t-1}-g_{i}^{t-1}+g_{i}^{t}. \end{split}\] (4)

The update rule of tracking variable is such that it recursively adds a correction term \(\big{(}\sum_{j\in\mathcal{N}(i)}w_{ij}y_{j}^{t-1}-g_{i}^{t-1}\big{)}\) to the local gradient \(g_{i}^{t}\), pushing \(y_{i}^{t}\) to be closer to the global gradients (\(\frac{1}{n}\sum_{j=1}^{n}g_{j}^{t}\)). This requires each agent \(i\) to communicate two sets of parameters \(x_{i}^{t}\) and \(y_{i}^{t}\) with its neighbors. Thus, the gradient tracking algorithm improves the decentralized learning on non-IID data at the cost of \(2\times\) communication overhead.

## 3 Global Update Tracking

We present _Global Update Tracking (GUT)_, a novel algorithm for decentralized deep learning on non-IID data distribution. _GUT_ is a communication-free tracking mechanism that aims to mitigate the difficulties of decentralized training when the data distributed across the agents is heterogeneous.

In order to attain the benefits of gradient tracking without communication overhead, we propose to apply the tracking mechanism with respect to the model updates \(x_{i}^{t}-x_{i}^{t-1}\) instead of the gradients\(g_{i}^{t}\). Firstly, to design a tracking mechanism without additional communication cost, each agent \(i\) communicates model updates instead of model parameters to its neighbors. An agent \(i\) stores a copy of its neighbor's parameters as \(\hat{x}_{j}\) and updates it using the received model updates to retrieve the current version of the neighbor's parameters as shown in line-9 of Algorithm 1. A memory-efficient implementation of the algorithm (Algorithm 4 in Appendix B) requires each agent to store \(s_{i}=\sum_{j\in\mathcal{N}(i)}w_{ij}\hat{x}_{j}\) instead of storing each neighbor's copy separately requiring only \(\mathcal{O}(1)\) additional memory [12].

Now, we define a variable \(\delta_{i}^{t}\) on each agent \(i\) that accumulates the local gradient update \(g_{i}^{t}\) and the gossip averaging update \(\sum_{j}(w_{ij}-I_{ij})\hat{x}_{j}^{t}\) as shown in line-5 of Algorithm 1. Note that we can recover the DSGD update defined in (2) by using \(\delta_{i}^{t}\) in the update rule i.e., \(x_{i}^{t+1}=x_{i}^{t}-\eta\delta_{i}^{t}\). We then proceed to compute the tracking variable \(y_{i}^{t}\), as described in line-6 of Algorithm 1, using the combined model update (local gradient part and gossip averaging part) reflected by \(\delta_{i}^{t}\). The gossip averaging part of the update for each agent \(i\) i.e., \(\sum_{j}w_{ij}(\hat{x}_{j}^{t}-x_{i}^{t})\) is computed with respect to its own model weights. To account for this in the computation of tracking variable \(y_{i}^{t}\), the agents have to adjust the information received from the neighbors (i.e., \(y_{j}^{t}\)'s) to change the reference to itself. This is reflected as an additional term \(\frac{1}{\eta}(\hat{x}_{j}^{t}-x_{i}^{t})\) in the update rule given by line-6 of Algorithm 1. Further, we scale the correction term of the tracking variable by a factor \(\mu\), a hyper-parameter, which is tuned to extract the maximum benefits of the proposed algorithm.

In summary, the update scheme of _GUT_ can be re-formulated in the following matrix form where \(X=[x_{1},\ldots,x_{n}]\in\mathbb{R}^{d\times n}\) are the model parameters and \(G=[g_{1},\ldots,g_{n}]\in\mathbb{R}^{d\times n}\) are stochastic gradients.

\[\begin{split} X^{t+1}&=X^{t}-\eta Y^{t},\\ Y^{t+1}&=G^{t+1}-\frac{1}{\eta}(W-I)X^{t+1}+\mu[WY^{t }-G^{t}-\frac{1}{\eta}(W-I)(X^{t+1}-X^{t})].\end{split}\] (5)

Finally, we show that integrating the proposed _GUT_ algorithm with Quasi-Global Momentum improves the current state-of-the-art significantly without any communication overhead. The pseudo-code for the momentum version of our algorithm (_QG-GUTm_) is presented in Appendix B.

## 4 Convergence Guarantees

This section provides the convergence analysis for the proposed _GUT_ Algorithm. We assume that the following standard assumptions hold:

**Assumption 1** (Lipschitz Gradients).: _Each function \(f_{i}(x)\) is L-smooth i.e., \(||\nabla f_{i}(y)-\nabla f_{i}(x)||\leq L||y-x||\)._

**Assumption 2** (Bounded Variance).: _The stochastic gradients are unbiased and their variance is assumed to be bounded._

\[\mathbb{E}_{d\sim D_{i}}||\nabla F_{i}(x;d)-\nabla f_{i}(x)||^{2}\leq\sigma^{2 }\ \ \forall i\in[1,n],\] (6)

\[\frac{1}{n}\sum_{i=1}^{n}||\nabla f_{i}(x)-\nabla f(x)||^{2}\leq\zeta^{2}.\] (7)

**Assumption 3** (Doubly Stochastic Mixing Matrix).: _The mixing matrix \(W\) is a real doubly stochastic matrix with \(\lambda_{1}(W)=1\) and_

\[\max\left\{|\lambda_{2}(W)|,|\lambda_{n}(W)|\right\}\leq 1-\rho<1,\] (8)

_where \(\lambda_{i}(W)\) is the \(i^{th}\) largest eigenvalue of W and \(\rho\) is the spectral gap._

The above assumptions are commonly used in most decentralized learning setups. Theorem 1 presents the convergence of the proposed _GUT_ algorithm and the proof is detailed in Appendix A.

**Theorem 1**.: _(Convergence of GUT algorithm) Given Assumptions 1, 2, and 3 let step size \(\eta\leq\frac{\rho}{\eta L}\) and the scaling factor \(\frac{\mu}{1-\mu}\leq\frac{\rho}{42}\). For all \(T\geq 1\), we have_

\[\frac{1}{T}\sum_{t=0}^{T-1}\mathbb{E}||\nabla f(\bar{x}^{t})||^{2}\leq\frac{4 }{\eta T}(f(\bar{x}^{0})-f^{*})+\eta\frac{4L\sigma^{2}}{n}+\eta^{2}\frac{1248L ^{2}}{\rho^{2}}(\zeta^{2}+\sigma^{2}(2-\mu)),\] (9)

_where \(f(\bar{x}^{0})-f^{*}\) is the sub-optimality gap, \(\bar{x}\) is the average/consensus model parameters._

The result of the Theorem 1 shows that the averaged gradient of the averaged model is upper-bounded by the sub-optimality gap (the difference between the initial objective function value and the optimal value), the sampling variance (\(\sigma\)), and gradient variations across the agents representing data heterogeneity (\(\zeta\)). Further, we present a corollary to show the convergence rate of _GUT_ in terms of the number of iterations.

**Corollary 1**.: _Suppose that the step size satisfies \(\eta=\mathcal{O}\Big{(}\sqrt{\frac{\mu}{T}}\Big{)}\) For a sufficiently large \(T\) we have,_

\[\frac{1}{T}\sum_{t=0}^{T-1}\mathbb{E}||\nabla f(\bar{x}^{t})||^{2}\leq\mathcal{ O}\Bigg{(}\frac{1}{\sqrt{nT}}+\frac{1}{T}\Bigg{)}.\] (10)

Corollary 1 indicates that the _GUT_ algorithm achieves linear speedup with a convergence rate of \(\mathcal{O}(\frac{1}{\sqrt{nT}})\) when \(T\) is sufficiently large and is independent of communication topology. In other words, the communication complexity to find an \(\epsilon\)-first order solution, i.e., \(\mathbb{E}\|\nabla f(\bar{x})\|^{2}\leq\epsilon\) is \(\mathcal{O}(\frac{\sigma^{2}}{ne^{2}})\). This convergence rate is similar to the well-known best result for decentralized SGD algorithms [15] in the literature.

## 5 Experiments

In this section, we analyze the performance of the proposed _GUT_ and _QG-GUTm_ techniques and compare them with the baseline DSGD algorithm [15] and the current state-of-the-art QG-DSGDm [16] respectively. The source code is available at https://github.com/aparna-aketli/global_update_tracking

### Experimental Setup

The efficiency of the proposed method is demonstrated through our experiments on a diverse set of datasets, model architectures, graph topologies, and graph sizes. We present the analysis on - (a) Datasets: CIFAR-10, CIFAR-100, Fashion MNIST, and Imagenette. (b) Model architectures: VGG-11, ResNet-20, LeNet-5 and, MobileNet-V2. All the models use Evonorm [17] as the activation-normalization layer as it is shown to be better suited for decentralized learning on heterogeneous data.

(c) Graph topologies: Ring graph with 2 peers per agent, Dyck graph with 3 peers per agent, and Torus graph with 4 peers per agent (refer Figure 1). (d) Number of agents: 16-40 agents. We use the Dirichlet distribution to generate disjoint non-IID data across the agents. The created data partition across the agents is fixed, non-overlapping, and never shuffled across agents during the training. The degree of heterogeneity is regulated by the value of \(\alpha\) - the smaller the \(\alpha\) the larger the non-IIDness across the agents. We report the test accuracy of the consensus model averaged over three randomly chosen seeds. The details of the decentralized setup and hyperparameters for all the experiments are presented in Appendix C.

### Average Consensus Task

We first consider an average consensus task that is isolated from the learning through stochastic gradient descent. Here the aim is that all the agents should reach a consensus which is the average value of the initial information each agent holds. The following equations show the simplified version of _GUT_ (11) and _QG-GUTm_ (12) after removing the gradient update part.

\[X^{t+1}=X^{t}+Y^{t};\ \ Y^{t}=(W-I)X^{t}+\mu[WY^{t-1}-(W-I)(X^{t-1}-X^{t})],\] (11)

\[X^{t+1}=X^{t}+\hat{M}^{t};\ \ \ M^{t}=\beta M^{t-1}+(1-\beta)(X^{t}-X^{t-1})\] (12)

\[\hat{M}^{t}= \beta M^{t}+(1-\beta)[(W-I)X^{t}+\mu(W\hat{M}^{t-1}-(W-I)(X^{t-1}-X ^{t}))].\]

Note that setting the hyper-parameter \(\mu\) as \(0\) in the (11), 12 gives simple gossip[26] and quasi-global gossip [16] respectively and all the agents communicate \(X^{t}-X^{t-1}\) at iteration \(t\) with their neighbors.

Figure.2 shows the average consensus error i.e., \(\frac{1}{n}||X^{t}-\bar{X}||_{F}^{2}\) over time for the average consensus task on the Ring topology with respect to various algorithms. We observe that the gossip averaging with _GUT_ converges faster than simple gossip averaging. Figure.2(c) illustrates that for graphs with a smaller spectral gap (which corresponds to more agents), the proposed _QG-GUTm_ can converge faster than quasi-global gossip (gossip with QGM) resulting in better decentralized optimization.

### Decentralized Deep Learning Results

We evaluate the efficiency of _GUT_ and its quasi-global momentum version _QG-GUTm_ with the help of an exhaustive set of experiments. We compare _GUT_ with DSGD and the momentum version _QG-GUTm_ with QG-DSGDm to show that the proposed method outperforms the current state-of-the-art.

Figure 1: Ring Graph (left), Dyck Graph (center), and Torus Graph (right).

Figure 2: Decentralized average consensus problem on an undirected ring topology

Table. 1 shows the average test accuracy for training ResNet-20 and VGG-11 models on the CIFAR-10 dataset with varying degrees of non-IIDness over ring topology of 16 and 32 agents. We observe that _GUT_ consistently outperforms DSGD for all models, graph sizes, and degree of heterogeneity with a significant performance gain varying from \(1-18\%\). The quasi-global momentum version of our algorithm, _QG-GUTm_, beats QG-DSGDm with \(1-3.5\%\) improvement in the case of the CIFAR-10 dataset partitioned with a higher degree of heterogeneity (\(\alpha=0.1,0.01\)).

We present the experimental results on various graph topologies and datasets to demonstrate the scalability and generalizability of _QG-GUTm_. We train the CIFAR-10 dataset on ResNet-20 over the Dyck graph and Torus graph to exemplify the impact of connectivity on the proposed technique. As shown in Table. 2, we obtain \(0.5-3.5\%\) performance gains with varying connectivity (or spectral gap).

\begin{table}
\begin{tabular}{l l c c c} \hline \multirow{2}{*}{Agents (\(n\))} & \multirow{2}{*}{Method} & \multicolumn{2}{c}{ResNet-20} \\ \cline{3-5}  & & \(\alpha=1\) & \(\alpha=0.1\) & \(\alpha=0.01\) \\ \hline \multirow{4}{*}{\(16\)} & DSGDm (IID) & \multirow{4}{*}{\(88.17\pm 0.32\)} & \(89.75\pm 0.29\) & \multirow{4}{*}{\(54.66\pm 4.74\)} \\  & DSGD [15] & \(84.17\pm 0.32\) & \(72.21\pm 2.37\) & \(54.66\pm 4.74\) \\  & _GUT (ours)_ & \(84.72\pm 0.20\) & \(81.86\pm 1.99\) & \(70.16\pm 4.94\) \\  & _QG-_GSDGDm [16] & \(\mathbf{88.23\pm 0.51}\) & \(\mathbf{84.21\pm 2.12}\) & \(79.85\pm 2.11\) \\  & _QG-GUTm (ours)_ & \(88.22\pm 0.36\) & \(\mathbf{86.44\pm 0.36}\) & \(\mathbf{81.04\pm 1.66}\) \\ \hline \multirow{4}{*}{\(32\)} & DSGDm (IID) & \multirow{4}{*}{\(78.25\pm 0.42\)} & \(88.52\pm 0.23\) & \multirow{4}{*}{\(42.58\pm 1.84\)} \\  & DSGD [15] & \(78.25\pm 0.42\) & \(62.97\pm 1.90\) & \(42.58\pm 1.84\) \\  & _GUT (ours)_ & \(79.24\pm 0.33\) & \(76.07\pm 0.23\) & \(60.72\pm 1.03\) \\  & QG-DSGDm [16] & \(87.15\pm 0.33\) & \(83.50\pm 1.04\) & \(69.99\pm 0.60\) \\  & _QG-GUTm (ours)_ & \(\mathbf{87.48\pm 0.33}\) & \(\mathbf{84.94\pm 0.60}\) & \(\mathbf{72.04\pm 3.18}\) \\ \hline \hline \multirow{4}{*}{Agents (\(n\))} & \multirow{4}{*}{Method} & \multicolumn{2}{c}{VGG-11} \\ \cline{3-5}  & DSGDm (IID) & \multirow{4}{*}{\(\alpha=1\)} & \(\alpha=0.1\) & \(\alpha=0.01\) \\ \cline{3-5}  & DSGD [15] & \(81.78\pm 0.29\) & \(76.20\pm 0.81\) & \(68.93\pm 1.23\) \\ \cline{3-5}  & _GUT (ours)_ & \(82.12\pm 0.09\) & \(81.24\pm 0.95\) & \(76.62\pm 1.37\) \\ \cline{3-5}  & QG-DSGDm [16] & \(84.23\pm 0.47\) & \(81.70\pm 0.79\) & \(77.08\pm 3.19\) \\ \cline{3-5}  & _QG-GUTm (ours)_ & \(\mathbf{84.46\pm 0.33}\) & \(\mathbf{83.05\pm 0.48}\) & \(\mathbf{78.32\pm 1.03}\) \\ \hline \multirow{4}{*}{\(32\)} & DSGDm (IID) & \multirow{4}{*}{\(79.75\pm 0.56\)} & \(84.75\pm 0.30\) & \multirow{4}{*}{\(73.59\pm 1.60\)} \\  & DSGD [15] & \(79.75\pm 0.56\) & \(73.37\pm 1.02\) & \(59.93\pm 1.60\) \\ \cline{1-1} \cline{3-5}  & _GUT (ours)_ & \(80.37\pm 0.33\) & \(79.55\pm 1.00\) & \(73.59\pm 1.26\) \\ \cline{1-1} \cline{3-5}  & QG-DSGDm [16] & \(83.67\pm 0.28\) & \(80.82\pm 0.19\) & \(74.25\pm 2.02\) \\ \cline{1-1} \cline{3-5}  & _QG-GUTm (ours)_ & \(\mathbf{84.32\pm 0.11}\) & \(\mathbf{83.39\pm 0.38}\) & \(\mathbf{77.41\pm 3.44}\) \\ \hline \end{tabular}
\end{table}
Table 1: Test accuracy of different decentralized algorithms evaluated on CIFAR-10, distributed with different degrees of heterogeneity (non-IID) for various models over ring topologies. The results are averaged over three seeds where the standard deviation is indicated. We also include the results of the IID baseline as DSGDm (IID) where the local data is randomly partitioned independent of \(\alpha\).

\begin{table}
\begin{tabular}{l c c c c} \hline \multirow{2}{*}{Method} & \multicolumn{2}{c}{Pshno MNIST (LeNet-5)} & \multicolumn{2}{c}{CIFAR-100 (ResNet-20)} & \multicolumn{2}{c}{Imagenet (MobileNet-V2)} \\ \cline{2-5}  & \(\alpha=0.1\) & \(\alpha=0.01\) & \(\alpha=0.01\) & \(\alpha=0.01\) & \(\alpha=0.01\) \\ \hline DSGDm [15] & \(86.59\pm 0.92\) & \(77.00\pm 0.353\) & \(47.93\pm 1.69\) & \(42.56\pm 2.71\) & \(66.02\pm 4.59\) & \(38.69\pm 11.8\) \\ QG-DSGDm [16] & \(89.94\pm 0.44\) & \(83.43\pm 0.94\) & \(53.19\pm 1.68\) & \(44.17\pm 3.64\) & \(63.60\pm 4.50\) & \(39.49\pm 4.57\) \\ _QG-GUTm_ & \(\mathbf{90.11\pm 0.02}\) & \(\mathbf{84.60\pm 1.00}\) & \(\mathbf{53.40\pm 1.23}\) & \(\mathbf{50.45\pm 1.30}\) & \(\mathbf{66.52\pm 3.68}\) & \(\mathbf{43.85\pm 8.24}\) \\ \hline \end{tabular}
\end{table}
Table 3: Average test accuracy of different decentralized algorithms evaluated on various datasets, distributed with different degrees of heterogeneity over 16 agents ring topology

\begin{table}
\begin{tabular}{l c c c c} \hline \multirow{2}{*}{Method} & \multicolumn{2}{c}{Pshno MNIST (LeNet-5)} & \multicolumn{2}{c}{CIFAR-100 (ResNet-20)} & \multicolumn{2}{c}{Imagenet (MobileNet-V2)} \\ \cline{2-5}  & \(\alpha=0.1\) & \(\alpha=0.01\) & \(\alpha=0.01\) & \(\alpha=0.01\) & \(\alpha=0.01\) \\ \hline DSGDm [15] & \(86.59\pm 0.92\) & \(77.00\pm 0.353\) & \(47.93\pm 1.69\) & \(42.56\pm 2.71\) & \(66.02\pm 4.59\) & \(38.69\pm 11.8\) \\ QG-DSGDm [16] & \(89.94\pm 0.44\) & \(83.43\pm 0.94\) & \(53.19\pm 1.68\) & \(44.17\pm 3.64\) & \(63.60\pm 4.50\) & \(39.49\pm 4.57\) \\ _QG-GUTm_ & \(\mathbf{90.11\pm 0.02}\) & \(\mathbf{84.60\pm 1.00}\) & \(\mathbf{53.40\pm 1.23}\) & \(\mathbf{50.45\pm 1.30}\) & \(\mathbf{66.52\pm 3.68}\) & \(\mathbf{43.85\pm 8.24}\) \\ \hline \end{tabular}
\end{table}
Table 1: Test accuracy of different decentralized algorithms evaluated on CIFAR-10, distributed with different degrees of heterogeneity (non-IID) for various models over ring topologies. The results are averaged over three seeds where the standard deviation is indicatedFurther, we evaluate _QG-GUTm_ on various image datasets such as Fashion MNIST, and Imagenette and on challenging datasets such as CIFAR-100. Table. 3 shows that _QG-GUTm_ outperforms QG-DSGDm by \(0.2-6.2\%\) across various datasets. Therefore, in a decentralized deep learning setup, the proposed _GUT_ and _QG-GUTm_ algorithms are more robust to heterogeneity in the data distribution and can outperform all the comparison methods with an average improvement of \(2\%\).

### Ablation Study

First, we analyze different ways of utilizing or tracking model update information as shown in Table. 4. We present two different update rules apart from _GUT_ and _DSGD_[15] and also compare them with gradient tracking [19]. Rule-a applies the proposed tracking mechanism on model updates but does not change the reference of tracking variable \(y_{j}\) received from the neighbors to itself (refer sec. 3 for details on changing the reference). In the case of Rule-b, each agent computes the difference between the averaged neighborhood model update (\(W(X^{t}-X^{t-1})\)) along with its own model update (\(X^{t}-X^{t-1}\)) and adds the difference between the two as a bias correction. Table. 4 shows that such naive ways of tracking or bias correction update rules (rule-a,b) do not improve the performance of decentralized learning on heterogeneous data. This confirms our findings that the _GUT_ technique is an effective and provable way to track the consensus model and can outperform the gradient tracking mechanism without any communication overhead.

We then proceed to investigate the effect of different variants of momentum with _GUT_. From Table. 5 (refer to Appendix D for more results), we can conclude that the quasi-global variant of Global Update Tracking always surpasses the other methods. This indicates that the proposed _GUT_ algorithm accelerates decentralized optimization and can be used in synergy with quasi-global momentum to achieve maximal performance gains.

Furthermore, Figure 3(a) illustrates the effect of scaling \(\mu\) on the test accuracy with _QG-GUTm_ and note that \(\mu=0\) shows the test accuracy for QG-DSGDm. Figure 3(b), 3(c) showcase the scalability

\begin{table}
\begin{tabular}{l l c c} \hline \multirow{2}{*}{Method} & Update & Communication & Test \\  & Rule & Parameters (Cost) & accuracy \\ \hline \multirow{2}{*}{DSGD} & \(X^{t+1}=X^{t-}y^{t}\) & \multirow{2}{*}{\(X^{t}\) (\(1\times\))} & \multirow{2}{*}{\(72.21\pm 2.37\)} \\  & \(Y^{t}=G^{t-1}\frac{1}{2}(W-I)X^{t}\) & & \\ \hline \multirow{2}{*}{Rule-a} & \(X^{t+1}=X^{t-}y^{t}\) & \multirow{2}{*}{\(Y^{t}\) (\(1\times\))} & \multirow{2}{*}{\(72.78\pm 0.80\)} \\  & \(Y^{t}=G^{t-1}\frac{1}{2}(W-I)X^{t}+\mu(WY^{t-1}-(G^{t-1}-\frac{1}{2}(W-I)X^{t-1})]\) & & \\ \hline \multirow{2}{*}{Rule-b} & \(X^{t+1}=X^{t-}y^{t}\) & \multirow{2}{*}{\(Y^{t}\) (\(1\times\))} & \multirow{2}{*}{\(72.62\pm 1.16\)} \\  & \(Y^{t}=G^{t-1}\frac{1}{2}(W-I)X^{t}+\mu(-\frac{1}{2}(W-I)(X^{t}-X^{t-1})]\) & & \\ \hline \multirow{2}{*}{GUT} & \(X^{t+1}=X^{t-}y^{t}\) & \multirow{2}{*}{\(Y^{t}\) (\(1\times\))} & \multirow{2}{*}{\(\mathbf{81.86\pm 1.99\)}} \\  & \(Y^{t}=G^{t-1}\frac{1}{2}(W-I)X^{t}+\mu(WY^{t-1}-G^{t-1}-\frac{1}{2}(W-I)(X^{t}-X ^{t-1})]\) & & \\ \hline Gradient & \(X^{t+1}=X^{t-}y^{t}[Y^{t-1}-(W-I)X^{t}]\) & & \\ Tracking & \(Y^{t}=G^{t+WY^{t-1}-G^{t-1}}\) & & \\ \hline \end{tabular}
\end{table}
Table 4: Analyzing the different variations of model updates. Evaluating test accuracy on CIFAR-10 dataset trained on ResNet-20 over a 16 agent ring topology with \(\alpha=0.1\)

\begin{table}
\begin{tabular}{l c c c c} \hline \multirow{2}{*}{Method} & Local & \multirow{2}{*}{Nesterov} & Quasi-Global & Global Update & Test Accuracy \\  & Momentum & & Momentum & Tracking & \(\alpha=0.1\) \\ \hline DSGD & x & x & x & x & \(72.21\pm 2.37\) \\ DSGDm & ✓ & x & x & \(79.87\pm 1.73\) \\ DSGDm-N & ✓ & ✓ & x & \(81.31\pm 0.51\) \\ \hline QG-DSGDm & x & x & ✓ & x & \(84.21\pm 2.12\) \\ QG-DSGDm-N & x & ✓ & ✓ & x & \(85.12\pm 1.11\) \\ \hline GUT & x & x & x & ✓ & \(81.86\pm 1.99\) \\ GUTm & ✓ & x & ✓ & \(79.95\pm 1.67\) \\ GUTm-N & ✓ & ✓ & x & ✓ & \(82.08\pm 1.74\) \\ QG-GUTm & x & x & ✓ & ✓ & \(86.44\pm 0.36\) \\ QG-GUTm-N & x & ✓ & ✓ & ✓ & \(\mathbf{86.55\pm 0.49}\) \\ \hline \end{tabular}
\end{table}
Table 5: Evaluating Global Update Tracking (GUT) with various versions of momentum using CIFAR-10 dataset trained on ResNet-20 architecture over 16 agents ring topology of _QG-GUTm_ on different graph sizes and model sizes. _QG-GUTm_ outperforms QG-DSGDm by \(\sim 1.7\%\) over different graph sizes and \(\sim 1.4\%\) over different model sizes.

## 6 Discussion and Limitations

We demonstrated the superiority of the Global Update Tracking (_GUT_) algorithm through an elaborate set of experiments and ablation studies. In our experiments, we focused on doubly-stochastic and symmetric graph structures. The proposed _GUT_ algorithm can be easily extended to directed and time-varying graphs by combining it with stochastic gradient push (SGP) [2]. Further, the additional terms added by _GUT_ can also be interpreted as a bias correction mechanism where the added bias pushes the local model towards the consensus (averaged) model. The matrix representation of this interpretation of _GUT_ is given by (13). and analyzed in Lemma 1.

\[X^{t+1}=WX^{t}-\eta(G^{t}+\mu B^{t});\quad B^{t+1}=-\frac{1}{\eta}((2W-I)(X^{t+ 1}-X^{t})+\eta G^{t}].\] (13)

**Lemma 1**.: _Given assumptions 3, we define \(\bar{b}^{t}=B^{t}\frac{1}{n}\mathbbm{1}\mathbbm{1}^{T}\), where \(\mathbbm{1}\) is a vector of all ones. For all \(t\), we have: \(\bar{b}^{t}=\mu\bar{b}^{t-1}\)._

A complete proof for Lemma 1 can be found in Appendix A.2. Lemma 1 highlights that the average bias added by _GUT_ is zero as \(\bar{b}^{0}\) is zero. Hence, the _GUT_ algorithm crucially preserves the average value of the decentralized system. A feature we leverage to establish Theorem 1.

There are two potential limitations of the _GUT_ algorithm - a) memory overhead and b) introduction of an additional hyper-parameter. _GUT_ requires the agents to keep a copy of the averaged model parameters of their neighbors which adds an extra memory buffer of the size of model parameters. The storage of the tracking variable also adds to the memory overhead, requiring additional memory equivalent to the size of model parameters. We also introduce a new hyper-parameter \(\mu\) which has to be tuned similarly to the learning rate or momentum coefficient tuning. Besides, the theoretical analysis presented for the _GUT_ algorithm does not consider momentum and assumes the communication to be synchronous. We leave the theoretical analysis of _QG-GUTm_ and formulation of the asynchronous version of _GUT_ as a future research direction.

## 7 Conclusion

Decentralized learning on heterogeneous data is the key to launching ML training on edge devices and thereby efficiently leveraging the humongous amounts of user-generated private data. In this paper, we propose _Global Update Tracking_ (_GUT_), a novel decentralized algorithm designed to improve learning over heterogeneous data distributions. The convergence analysis presented in the paper shows that the proposed algorithm matches the best-known rate for decentralized algorithms. Additionally, the paper introduces a quasi-global momentum version of the algorithm, QG-GUTm, to further enhance the performance gains. The empirical evidence from experiments on different model architectures, datasets, and topologies demonstrates the superior performance of both algorithms. In summary, the proposed algorithm and its quasi-global momentum version have the potential to facilitate more scalable and efficient decentralized learning on edge devices.

Figure 3: Ablation study on the hyper-parameter \(\mu\), number of agents \(n\) and model size. The test accuracy is reported for the CIFAR-10 dataset trained on ResNet architecture over ring topology.

## Acknowledgements

This work was supported in part by, the Center for the Co-Design of Cognitive Systems (COCOSYS), a DARPA-sponsored JUMP center, the Semiconductor Research Corporation (SRC), and the National Science Foundation.

## References

* [1]S. A. Aketi, S. Kodge, and K. Roy (2022) Neighborhood gradient clustering: an efficient decentralized learning method for non-iid data distributions. arXiv preprint arXiv:2209.14390. Cited by: SS1.
* [2]M. Assran, N. Loizou, N. Ballas, and M. Rabbat (2019) Stochastic gradient push for distributed deep learning. In International Conference on Machine Learning, pp. 344-353. Cited by: SS1.
* [3]A. Balu, Z. Jiang, S. Y. Tan, C. Hedge, Y. M. Lee, and S. Sarkar (2021) Decentralized deep learning using momentum-accelerated consensus. In ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 3675-3679. Cited by: SS1.
* [4]L. Bottou (2010) Large-scale machine learning with stochastic gradient descent. In Proceedings of COMPSTAT'2010, pp. 177-186. Cited by: SS1.
* [5]J. Dean, G. Corrado, R. Monga, K. Chen, M. Devin, M. Mao, M. Ranzato, A. Senior, P. Tucker, K. Yang, et al. (2012) Large scale distributed deep networks. Advances in neural information processing systems25. Cited by: SS1.
* [6]P. Di Lorenzo and G. Scutari (2016) Next: in-network nonconvex optimization. IEEE Transactions on Signal and Information Processing over Networks2 (2), pp. 120-136. Cited by: SS1.
* [7]Y. Esfandiari, S. Y. Tan, Z. Jiang, A. Balu, E. Herron, C. Hegde, and S. Sarkar (2021) Cross-gradient aggregation for decentralized learning from non-iid data. In International Conference on Machine Learning, pp. 3036-3046. Cited by: SS1.
* [8]K. He, X. Zhang, S. Ren, and J. Sun (2016) Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778. Cited by: SS1.
* [9]K. Hsieh, A. Phanishayee, O. Mutlu, and P. Gibbons (2020-06) The non-IID data quagmire of decentralized machine learning. In Proceedings of the 37th International Conference on Machine Learning, pp. 4387-4398. Cited by: SS1.
* a subset of 10 easily classified classes from the imagenet dataset. https://github.com/fastai/imagenette. Cited by: SS1.
* [11]A. Koloskova, N. Loizou, S. Boreiri, M. Jaggi, and S. Stich (2020) A unified theory of decentralized sgd with changing topology and local updates. In International Conference on Machine Learning, pp. 5381-5393. Cited by: SS1.
* [12]A. Koloskova, S. Stich, and M. Jaggi (2019-09-15 Jun Jun 2019) Decentralized stochastic optimization and gossip algorithms with compressed communication. In Proceedings of the 36th International Conference on Machine Learning, Vol. 97 of Proceedings of Machine Learning Research, pp. 3478-3487. Cited by: SS1.
* [13]A. Krizhevsky, V. Nair, and G. Hinton (2014) Cifar (canadian institute for advanced research). http://www.cs.toronto.edu/ kriz/cifar.html. Cited by: SS1.
* [14]Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner (1998) Gradient-based learning applied to document recognition. Proceedings of the IEEE86 (11), pp. 2278-2324. Cited by: SS1.
* [15]X. Lian, C. Zhang, H. Zhang, C. Hsieh, W. Zhang, and J. Liu (2017) Can decentralized algorithms outperform centralized algorithms? a case study for decentralized parallel stochastic gradient descent. Advances in Neural Information Processing Systems30. Cited by: SS1.
* [16]T. Lin, S. Praneeth Karimireddy, S. Stich, and M. Jaggi (2021-04 Jul 2021) Quasi-global momentum: accelerating decentralized deep learning on heterogeneous data. In Proceedings of the 38th International Conference on Machine Learning, Vol. 139 of Proceedings of Machine Learning Research, pp. 6654-6665. Cited by: SS1.
* [17]H. Liu, A. Brock, K. Simonyan, and Q. Le (2017) Evolving normalization-activation layers. In Advancesin Neural Information Processing Systems_, volume 33, pages 13539-13550. Curran Associates, Inc., 2020.
* [18] Angelia Nedic. Distributed gradient methods for convex machine learning problems in networks: Distributed optimization. _IEEE Signal Processing Magazine_, 37(3):92-101, 2020.
* [19] Shi Pu and Angelia Nedic. Distributed stochastic gradient tracking methods. _Mathematical Programming_, 187:409-457, 2021.
* [20] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen. Mobilenetv2: Inverted residuals and linear bottlenecks. In _Proceedings of the IEEE conference on computer vision and pattern recognition_, pages 4510-4520, 2018.
* [21] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. _arXiv preprint arXiv:1409.1556_, 2014.
* [22] Yuki Takezawa, Han Bao, Kenta Niwa, Ryoma Sato, and Makoto Yamada. Momentum tracking: Momentum acceleration for decentralized deep learning on heterogeneous data. _arXiv preprint arXiv:2209.15505_, 2022.
* [23] Hanlin Tang, Xiangru Lian, Ming Yan, Ce Zhang, and Ji Liu. \(d^{2}\): Decentralized training over decentralized data. In _International Conference on Machine Learning_, pages 4848-4856. PMLR, 2018.
* [24] Thijs Vogels, Lie He, Anastasiia Koloskova, Sai Praneeth Karimireddy, Tao Lin, Sebastian U Stich, and Martin Jaggi. Relaysum for decentralized deep learning on heterogeneous data. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang, and J. Wortman Vaughan, editors, _Advances in Neural Information Processing Systems_, volume 34, pages 28004-28015. Curran Associates, Inc., 2021.
* [25] Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. _arXiv preprint arXiv:1708.07747_, 2017.
* [26] Lin Xiao and Stephen Boyd. Fast linear iterations for distributed averaging. _Systems & Control Letters_, 53(1):65-78, 2004.

Convergence Rate Proof

In this work, we solve the optimization problem of minimizing global loss function \(f(x)\) distributed across \(n\) agents as given below. Note that \(F_{i}\) is a local loss function (for example, cross-entropy loss) defined in terms of the data sampled (\(d_{i}\)) from the local dataset \(D_{i}\) at agent \(i\).

\[\min_{x\in\mathbb{R}^{d}}f(x) =\frac{1}{n}\sum_{i=1}^{n}f_{i}(x),\] \[and\ \ f_{i}(x) =\mathbb{E}_{d_{i}\in D_{i}}[F_{i}(x;d_{i})]\ \ \forall i.\]

We reiterate the update scheme of _GUT_ presented in Algorithm. 1 in a matrix form:

\[X^{t+1} =X^{t}-\eta Y^{t}\] (14) \[Y^{t} =\Delta^{t}+\mu[WY^{t-1}-\frac{1}{\eta}(W-I)X^{t}-\Delta^{t-1}]\] \[\Delta^{t} =G^{t}-\frac{1}{\eta}(W-I)X^{t},\]

where \(W\) is the mixing matrix, \(I\) is the identity matrix, \(X=[x_{1},x_{2},\dots,x_{n}]\in\mathbb{R}^{d\times n}\) is the matrix containing model parameters, \(x_{i}\in\mathbb{R}^{d}\) is model parameters of agent \(i\), \(Y=[y_{1},y_{2},\dots,y_{n}]\in\mathbb{R}^{d\times n}\) is the matrix containing tracking variables, \(G=[g_{1},g_{2},\dots,g_{n}]\in\mathbb{R}^{d\times n}\) is the matrix containing local gradients, \(\mu\) is the _GUT_ scaling factor, \(\eta\) is the learning rate. Now, we rewrite the above equation in the form of a bias correction update,

\[X^{t+1} =WX^{t}-\eta(G^{t}+\mu B^{t})\] (15) \[B^{t} =-\frac{1}{\eta}[(2W-I)(X^{t}-X^{t-1})+\eta G^{t-1}].\]

### Assumptions

We assume that the following statements hold:

**Assumption 1 - Lipschitz Gradients:** Each function \(f_{i}(x)\) is L-smooth i.e., \(||\nabla f_{i}(y)-\nabla f_{i}(x)||\leq L||y-x||\). Equivalently,

\[f_{i}(y)\leq f_{i}(x)+\langle\nabla f_{i}(x),y-x\rangle+\frac{L}{2}||y-x||^{2}\] (16)

**Assumption 2 - Bounded Variance:** The variance of the stochastic gradients is assumed to be bounded.

\[\mathbb{E}_{d\sim D_{i}}||\nabla F_{i}(x;d)-\nabla f_{i}(x)||^{2}\leq\sigma^ {2}\ \ \forall i\in[1,n]\]

\[\frac{1}{n}\sum_{i=1}^{n}||\nabla f_{i}(x)-\nabla f(x)||^{2}\leq\zeta^{2}\]

**Assumption 3 - Doubly Stochastic Mixing Matrix:** The mixing matrix \(W\) is a real doubly stochastic matrix with \(\lambda_{1}(W)=1\) and

\[max\{|\lambda_{2}(W)|,|\lambda_{n}(W)|\}\leq 1-\rho<1\]

where \(\lambda_{i}(W)\) is the \(i^{th}\) largest eigenvalue of W and \(\rho\) is the spectral gap. The mixing matrix satisfies \(\mathbb{E}_{W}||ZW-\bar{Z}||_{F}^{2}\leq(1-\rho)||ZW-\bar{Z}||_{F}^{2}\), where \(\bar{Z}=Z\frac{1}{n}\mathbbm{1}\mathbbm{1}^{T}\). We also have \(W\mathbbm{1}=\mathbbm{1}\) and \(W^{T}\mathbbm{1}=\mathbbm{1}\).

Further, we define the average gradients \(\bar{g}^{t}=\frac{1}{n}\sum_{i=1}^{n}\nabla F_{i}(x_{i}^{t},d_{i}^{t})\) where \(d_{i}^{t}\) is sampled mini-batch of data on node \(i\)

### Proof of Lemma 1

**Lemma 1**: _Given assumptions 3, we define \(\bar{b}^{t}=B^{t}\frac{1}{n}\mathbbm{1}\mathbbm{1}^{T}\), where \(\mathbbm{1}\) is a vector of all ones. For all \(t\), we have: \(\bar{b}^{t}=\mu\bar{b}^{t-1}\)._

Proof.: Starting from the definition of \(B^{t}\)

\[B^{t}=-\frac{1}{\eta}[(2W-I)(X^{t}-X^{t-1})+\eta G^{t-1}]\] \[\text{multiply }\frac{1}{n}\mathbbm{1}\mathbbm{1}^{T}\text{ on both sides}\] \[\bar{b}^{t}=-\frac{1}{\eta}[\bar{x}^{t}-\bar{x}^{t-1}+\eta\bar{g }^{t-1}]\quad(\because(2W-I)\mathbbm{1}=\mathbbm{1})\] \[\text{now, multiplying }\frac{1}{n}\mathbbm{1}\mathbbm{1}^{T}\text{ to }X^{t+1}= WX^{t}-\eta(G^{t}+\mu B^{t})\] \[\bar{x}^{t+1}=\bar{x}^{t}-\eta\bar{g}^{t}-\eta\mu\bar{b}^{t} \implies\bar{x}^{t}-\bar{x}^{t-1}+\eta\bar{g}^{t-1}=-\eta\mu\bar{b}^{t-1}\] \[\implies\bar{b}^{t}=\mu\bar{b}^{t-1}\]

Given that \(\bar{b}^{0}=0\), the average bias is zero at each iteration. This indicates that the proposed algorithm _GUT_ preserves the average of the system in an average consensus task.

### Proof of Theorem 1

This section presents the detailed proof of the convergence bounds of _GUT_ algorithm given by Theorem 1. Firstly, we analyze the one-step progress of the averaged model parameters \(\bar{x}\). Note that, \(\bar{X}^{t}=[\bar{x}^{t},\bar{x}^{t},\ldots,\bar{x}^{t}]\in\mathbb{R}^{d\times n}\) and \(\bar{x}^{t}=\frac{1}{n}\sum_{i=1}^{n}x_{i}^{t}\)

**Lemma 2**: _Given assumptions 1-3 and \(\eta\leq\frac{1}{4L}\), we have \(\mathbb{E}f(\bar{x}^{t+1})\leq\mathbb{E}f(\bar{x}^{t})-\frac{\eta}{4}\mathbb{ E}||\nabla f(\bar{x}^{t})||^{2}-\frac{\eta}{4}\mathbb{E}||\frac{1}{n}\sum_{i=1}^{n} \nabla f(x_{i}^{t})||^{2}+\frac{L\eta^{2}\sigma^{2}}{n}+\frac{3L\eta^{2}}{n}|| X^{t}-\bar{X}^{t}||_{F}^{2}.\)_

Proof.: From the definition of \(X^{t+1}\), we have

\[X^{t+1}=WX^{t}-\eta[G^{t}+\mu B^{t}]\] \[\implies\bar{x}^{t+1}=\bar{x}^{t}-\eta\bar{g}^{t}\quad(\because \bar{b}^{t}=0\text{from Lemma 1})\]

using L-smoothness assumption given by (16)

\[\mathbb{E}f(\bar{x}^{t+1}) \leq\mathbb{E}f(\bar{x}^{t})+\mathbb{E}\langle\nabla f(\bar{x}^{t }),\bar{x}^{t+1}-\bar{x}^{t}\rangle+\frac{L}{2}\mathbb{E}||\bar{x}^{t+1}-\bar{ x}^{t}||^{2}\] \[=\mathbb{E}f(\bar{x}^{t})+\mathbb{E}\langle\nabla f(\bar{x}^{t}),-\eta\bar{g}^{t}\rangle+\frac{L\eta^{2}}{2}\mathbb{E}||\bar{g}^{t}||^{2}\] \[=\mathbb{E}f(\bar{x}^{t})-\eta\mathbb{E}\langle\nabla f(\bar{x}^ {t}),\mathbb{E}[\bar{g}^{t}]\rangle+\frac{L\eta^{2}}{2}\mathbb{E}||\frac{1}{n }\sum_{i=1}^{n}\nabla F_{i}(x_{i}^{t})||^{2}\] \[=\mathbb{E}f(\bar{x}^{t})-\eta\frac{1}{n}\sum_{i=1}^{n}\mathbb{ E}\langle\nabla f(\bar{x}^{t}),\nabla f_{i}(x_{i}^{t})\rangle+\frac{L\eta^{2}}{2} \mathbb{E}||\frac{1}{n}\sum_{i=1}^{n}(\nabla F_{i}(x_{i}^{t})\pm\nabla f_{i}(x _{i}^{t}))||^{2}\] \[\overset{(a)}{\leq}\mathbb{E}f(\bar{x}^{t})-\eta\mathbb{E}\langle \nabla f(\bar{x}^{t}),\frac{1}{n}\sum_{i=1}^{n}\nabla f_{i}(x_{i}^{t})\rangle+ \frac{L\eta^{2}}{2}\mathbb{E}||\frac{1}{n}\sum_{i=1}^{n}\nabla f_{i}(x_{i}^{t })||^{2}+\frac{L\eta^{2}\sigma^{2}}{n}\] \[\overset{(b)}{=}\mathbb{E}f(\bar{x}^{t})+\frac{L\eta^{2}\sigma^{ 2}}{n}+\frac{L\eta^{2}}{2}\mathbb{E}||\frac{1}{n}\sum_{i=1}^{n}\nabla f_{i}(x _{i}^{t})||^{2}-\frac{\eta}{2}\mathbb{E}||\nabla f(\bar{x}^{t})||^{2}\] \[\quad-\frac{\eta}{2}\mathbb{E}||\frac{1}{n}\sum_{i=1}^{n}\nabla f _{i}(x_{i}^{t})||^{2}+\frac{\eta}{2}\mathbb{E}||\frac{1}{n}\sum_{i=1}^{n}( \nabla f_{i}(x_{i}^{t})-\nabla f(\bar{x}^{t}))||^{2}\]\[\stackrel{{(c)}}{{\leq}} \mathbb{E}f(\bar{x}^{t})+\frac{L\eta^{2}\sigma^{2}}{n}+(\frac{L\eta^{ 2}}{2}-\frac{\eta}{2})\mathbb{E}||\frac{1}{n}\sum_{i=1}^{n}\nabla f_{i}(x_{i}^{ t})||^{2}-\frac{\eta}{2}\mathbb{E}||\nabla f(\bar{x}^{t})||^{2}\] \[+\frac{\eta}{2n}\sum_{i=1}^{n}\mathbb{E}||\nabla f_{i}(x_{i}^{t}) -\nabla f(\bar{x}^{t})||^{2}\] \[\stackrel{{(d)}}{{\leq}} \mathbb{E}f(\bar{x}^{t})+\frac{L\eta^{2}\sigma^{2}}{n}+(\frac{L \eta^{2}}{2}-\frac{\eta}{2})\mathbb{E}||\frac{1}{n}\sum_{i=1}^{n}\nabla f_{i}( x_{i}^{t})||^{2}-\frac{\eta}{2}\mathbb{E}||\nabla f(\bar{x}^{t})||^{2}\] \[+\frac{L^{2}\eta}{2n}\sum_{i=1}^{n}\mathbb{E}||x_{i}^{t}-\bar{x}^ {t}||^{2}\] \[\stackrel{{(e)}}{{\leq}} \mathbb{E}f(\bar{x}^{t})-\frac{\eta}{4}\mathbb{E}||\frac{1}{n} \sum_{i=1}^{n}\nabla f_{i}(x_{i}^{t})||^{2}-\frac{\eta}{4}\mathbb{E}||\nabla f (\bar{x}^{t})||^{2}+\frac{L\eta^{2}\sigma^{2}}{n}\] \[+\frac{3L^{2}\eta}{n}\sum_{i=1}^{n}\mathbb{E}||X^{t}-\bar{X}^{t}|| ^{2}_{F}\]

(a) uses assumption-2 ((6)). (b) uses the fact that \(-2\langle a,b\rangle=-||a||^{2}-||b||^{2}+||a-b||^{2}\). (c) uses Jensen's inequality. (d) uses L-smoothness condition. (e) follows from the assumption that \(\eta\leq\frac{1}{4L}\). 

Now, we proceed to bound the consensus error through Lemma 3.

**Lemma 3**.: _Given assumptions 1-3 and \(\eta\leq\frac{\rho}{7L}\), we have_

\(\frac{1}{n}\mathbb{E}||X^{t+1}-\bar{X}^{t+1}||^{2}_{F}\leq\frac{1-\rho/4}{n} \mathbb{E}||X^{t}-\bar{X}^{t}||^{2}_{F}+\frac{12\eta^{2}\sigma^{2}}{\rho}+4 \eta^{2}\sigma^{2}+\frac{6\eta^{2}\mu^{2}}{\rho n}\mathbb{E}||B^{t}||^{2}_{F}\)_._

Proof.: Starting from the update step 15

\[\frac{1}{n}\mathbb{E}||X^{t+1}-\bar{X}^{t+1}||^{2}_{F}= \frac{1}{n}\mathbb{E}||WX^{t}-\eta[G^{t}+\mu B^{t}]-(\bar{X}^{t}- \eta\bar{G}^{t})||^{2}_{F}\] \[= \frac{1}{n}\mathbb{E}||WX^{t}-\bar{X}^{t}-\eta(G^{t}-\bar{G}^{t} )-\eta\mu B^{t}||^{2}_{F}\] \[\leq \frac{1}{n}\mathbb{E}||WX^{t}-\bar{X}^{t}-\eta(\mathbb{E}[G^{t}]- \mathbb{E}[\bar{G}^{t}])-\eta\mu B^{t}||^{2}_{F}+4\eta^{2}\sigma^{2}\] \[\stackrel{{(a)}}{{\leq}} \frac{1+\rho/2}{n}\mathbb{E}||WX^{t}-\bar{X}^{t}||^{2}_{F}+\frac{ \eta^{2}(1+2/\rho)}{n}\mathbb{E}||\mathbb{E}[G^{t}]-\mathbb{E}[\bar{G}^{t}]- \mu B^{t}||^{2}_{F}\] \[+4\eta^{2}\sigma^{2}\] \[\stackrel{{(b)}}{{\leq}} \frac{(1-\rho)(1+\rho/2)}{n}\mathbb{E}||X^{t}-\bar{X}^{t}||^{2}_{F }+\frac{3\eta^{2}}{n\rho}\mathbb{E}||\mathbb{E}[G^{t}]-\mathbb{E}[\bar{G}^{t}] -\mu B^{t}||^{2}_{F}\] \[+4\eta^{2}\sigma^{2}\] \[\leq \frac{(1-\rho)(1+\rho/2)}{n}\mathbb{E}||X^{t}-\bar{X}^{t}||^{2}_{ F}+4\eta^{2}\sigma^{2}+\frac{6\eta^{2}}{n\rho}\mathbb{E}||\mathbb{E}[G^{t}]- \mathbb{E}[\bar{G}^{t}]||^{2}_{F}\] \[+\frac{6\eta^{2}\mu^{2}}{n\rho}\mathbb{E}||B^{t}||^{2}_{F}\] \[\leq \frac{(1-\rho/2)}{n}\mathbb{E}||X^{t}-\bar{X}^{t}||^{2}_{F}+4\eta ^{2}\sigma^{2}+\frac{6\eta^{2}}{n\rho}\mathbb{E}||\mathbb{E}[G^{t}]-\nabla f( \bar{x}^{t})||^{2}_{F}\] \[+\frac{6\eta^{2}\mu^{2}}{n\rho}\mathbb{E}||B^{t}||^{2}_{F}\] \[\leq \frac{(1-\rho/2)}{n}\mathbb{E}||X^{t}-\bar{X}^{t}||^{2}_{F}+4\eta ^{2}\sigma^{2}+\frac{6\eta^{2}\mu^{2}}{n\rho}\mathbb{E}||B^{t}||^{2}_{F}\] \[+\frac{6\eta^{2}}{n\rho}\sum_{i=1}^{n}\mathbb{E}||\nabla f_{i}(x_{i }^{t})\pm\nabla f_{i}(\bar{x}^{t})-\nabla f(\bar{x}^{t})||^{2}_{F}\]\[\stackrel{{(c)}}{{\leq}} \frac{(1-\rho/2)}{n}\mathbb{E}||X^{t}-\bar{X}^{t}||_{F}^{2}+4\eta^{2} \sigma^{2}+\frac{12\eta^{2}\zeta^{2}}{\rho}+\frac{6\eta^{2}\mu^{2}}{n\rho} \mathbb{E}||B^{t}||_{F}^{2}\] \[+\frac{12\eta^{2}}{n\rho}\sum_{i=1}^{n}\mathbb{E}||\nabla f_{i}(x_ {i}^{t})-\nabla f_{i}(\bar{x}^{t})||_{F}^{2}\] \[\stackrel{{(d)}}{{\leq}} \frac{(1-\rho/2)}{n}\mathbb{E}||X^{t}-\bar{X}^{t}||_{F}^{2}+4\eta^ {2}\sigma^{2}+\frac{12\eta^{2}\zeta^{2}}{\rho}+\frac{6\eta^{2}\mu^{2}}{n\rho} \mathbb{E}||B^{t}||_{F}^{2}\] \[+\frac{12\eta^{2}L^{2}}{n\rho}\sum_{i=1}^{n}\mathbb{E}||x_{i}^{t} -\bar{x}^{t}||_{F}^{2}\] \[= \Big{(}\frac{1-\rho/2}{n}+\frac{12\eta^{2}L^{2}}{n\rho}\Big{)} \mathbb{E}||X^{t}-\bar{X}^{t}||_{F}^{2}+4\eta^{2}\sigma^{2}+\frac{12\eta^{2} \zeta^{2}}{\rho}\] \[+\frac{6\eta^{2}\mu^{2}}{n\rho}\mathbb{E}||B^{t}||_{F}^{2}\] \[\stackrel{{(e)}}{{\leq}} \frac{1-\rho/4}{n}\mathbb{E}||X^{t}-\bar{X}^{t}||_{F}^{2}+4\eta^ {2}\sigma^{2}+\frac{12\eta^{2}\zeta^{2}}{\rho}+\frac{6\eta^{2}\mu^{2}}{n\rho} \mathbb{E}||B^{t}||_{F}^{2}\]

(a) follows from the fact that \(||a+b||^{2}\leq(1+\alpha)||a||^{2}+(1+\frac{1}{\alpha})||b||^{2}\ \ \forall\alpha>0\) and let \(\alpha=\frac{\rho}{2}\). (b) uses \(\mathbb{E}_{W}||ZW-\bar{Z}||_{F}^{2}\leq(1-\rho)||ZW-\bar{Z}||_{F}^{2}\) and \(1+\frac{2}{\rho}\leq\frac{3}{\rho}\). (c) uses assumption-2 (7). (d) uses L-smoothness condition. (e) follows from the assumption that \(\eta\leq\frac{\rho}{\tau L}\) 

The next step is to find an upper bound for the bias term \(\mathbb{E}||B^{t}||_{F}^{2}\).

**Lemma 4**.: _Given assumptions 1-3 and \(\frac{\mu}{1-\mu}\leq\frac{\rho}{42}\), we have \(\frac{6\eta^{2}\mu^{2}}{\rho n(1-\mu)}\mathbb{E}||B^{t+1}||_{F}^{2}\leq\Big{(} \frac{6\eta^{2}\mu^{2}}{\rho n(1-\mu)}-\frac{6\eta^{2}\mu^{2}}{\rho n}\Big{)} \mathbb{E}||B^{t}||_{F}^{2}+\frac{\rho}{8n}\mathbb{E}||X^{t}-\bar{X}^{t}||_{F} ^{2}+\frac{\eta^{2}\zeta^{2}\rho}{8}+\frac{\eta^{2}\sigma^{2}\rho(1-\mu)}{8}\)._

Proof.: starting from the update step 15

\[B^{t+1}= -\frac{1}{\eta}[(2W-I)(X^{t+1}-X^{t})+\eta G^{t}]\] \[= -\frac{1}{\eta}[(2W-I)(WX^{t}-\eta G^{t}-\eta\mu B^{t}-X^{t})+\eta G ^{t}]\] \[= -\frac{1}{\eta}[W(2W-I)-I]X^{t}+2(W-I)G^{t}+\mu(2W-I)B^{t}.\]

Now,

\[\frac{1}{n}\mathbb{E}||B^{t+1}||_{F}^{2}= \frac{1}{n}\mathbb{E}||-\frac{1}{\eta}(W(2W-I)-I)X^{t}+2(W-I)G^{t }+\mu(2W-I)B^{t}||_{F}^{2}\] \[= \frac{1}{n}\mathbb{E}||-\frac{1}{\eta}(W(2W-I)-I)X^{t}+2(W-I)(G^{ t}-\bar{G}^{t})+\mu(2W-I)B^{t}||_{F}^{2}\] \[= \frac{1}{n}\mathbb{E}||-\frac{1}{\eta}(W(2W-I)-I)X^{t}+2(W-I) \mathbb{E}[G^{t}-\bar{G}^{t}]+\mu(2W-I)B^{t}||_{F}^{2}\] \[+\frac{1}{n}\mathbb{E}||2(W-I)(G^{t}-\mathbb{E}[G^{t}]-(\bar{G}^{ t}-\mathbb{E}[\bar{G}^{t}]))||_{F}^{2}\] \[\leq \frac{1}{n}\mathbb{E}||\frac{1}{\eta}(I-W(2W-I))X^{t}+2(W-I) \mathbb{E}[G^{t}-\bar{G}^{t}]+\mu(2W-I)B^{t}||_{F}^{2}\] \[+8\sigma^{2}\] \[\stackrel{{(a)}}{{\leq}} \frac{1}{n}\Big{(}1+\frac{1-\mu}{\mu}\Big{)}\mathbb{E}||\mu(2W-I)B^ {t}||_{F}^{2}+8\sigma^{2}\] \[+\frac{1}{n}\Big{(}1+\frac{\mu}{1-\mu}\Big{)}\mathbb{E}||\frac{1}{ \eta}(I-W(2W-I))X^{t}+2(W-I)\mathbb{E}[G^{t}-\bar{G}^{t}]||_{F}^{2}\]\[\leq \frac{\mu}{n}\mathbb{E}||B^{t}||_{F}^{2}+8\sigma^{2}+\frac{2}{n(1- \mu)}\mathbb{E}||\mathbb{E}[G^{t}-\bar{G}^{t}]||_{F}^{2}\] \[+\frac{2}{n\eta^{2}(1-\mu)}\mathbb{E}||(I-W(2W-I))X^{t}||_{F}^{2}\] \[= \frac{1-(1-\mu)}{n}\mathbb{E}||B^{t}||_{F}^{2}+8\sigma^{2}+\frac{2 }{n(1-\mu)}\mathbb{E}||\mathbb{E}[G^{t}-\bar{G}^{t}]||_{F}^{2}\] \[+\frac{2}{n\eta^{2}(1-\mu)}\mathbb{E}||(2W+I)(I-W)X^{t}||_{F}^{2}\] \[\overset{(b)}{\leq} \frac{1-(1-\mu)}{n}\mathbb{E}||B^{t}||_{F}^{2}+8\sigma^{2}+\frac{2 }{n(1-\mu)}\mathbb{E}||\mathbb{E}[G^{t}-\bar{G}^{t}]||_{F}^{2}\] \[+\frac{18}{n\eta^{2}(1-\mu)}\mathbb{E}||(I-W)X^{t}||_{F}^{2}\] \[= \frac{1-(1-\mu)}{n}\mathbb{E}||B^{t}||_{F}^{2}+8\sigma^{2}+\frac{ 2}{n(1-\mu)}\mathbb{E}||\mathbb{E}[G^{t}-\bar{G}^{t}]||_{F}^{2}\] \[+\frac{18}{n\eta^{2}(1-\mu)}\mathbb{E}||(I-W)(X^{t}-\bar{X}^{t}) ||_{F}^{2}\] \[\leq \frac{1-(1-\mu)}{n}\mathbb{E}||B^{t}||_{F}^{2}+8\sigma^{2}+\frac {36}{n\eta^{2}(1-\mu)}\mathbb{E}||X^{t}-\bar{X}^{t}||_{F}^{2}\] \[+\frac{2}{n(1-\mu)}\mathbb{E}||\mathbb{E}[G^{t}]\pm\nabla f(\bar{ x}^{t})-\mathbb{E}[\bar{G}^{t}]||_{F}^{2}\] \[\leq \frac{1-(1-\mu)}{n}\mathbb{E}||B^{t}||_{F}^{2}+8\sigma^{2}+\frac {36}{n\eta^{2}(1-\mu)}\mathbb{E}||X^{t}-\bar{X}^{t}||_{F}^{2}\] \[+\frac{8\zeta^{2}}{1-\mu}+\frac{4L^{2}}{n(1-\mu)}\mathbb{E}||X^{t }-\bar{X}^{t}||_{F}^{2}\] \[= \frac{1-(1-\mu)}{n}\mathbb{E}||B^{t}||_{F}^{2}+8\sigma^{2}+\frac {4(9+\eta^{2}L^{2})}{n\eta^{2}(1-\mu)}\mathbb{E}||X^{t}-\bar{X}^{t}||_{F}^{2}+ \frac{8\zeta^{2}}{1-\mu}\]

Multiplying both sides with \(\frac{6\eta^{2}\mu^{2}}{\rho(1-\mu)}\)

\[\frac{6\eta^{2}\mu^{2}}{n\rho(1-\mu)}\mathbb{E}||B^{t+1}||_{F}^{2}\leq \Big{(}\frac{6\eta^{2}\mu^{2}}{n\rho(1-\mu)}-\frac{6\eta^{2}\mu^{2 }}{n\rho}\Big{)}\mathbb{E}||B^{t}||_{F}^{2}+\frac{24(9+\eta^{2}L^{2})\mu^{2}}{ n\rho(1-\mu)^{2}}\mathbb{E}||X^{t}-\bar{X}^{t}||_{F}^{2}\] \[+\frac{48\eta^{2}\mu^{2}\sigma^{2}}{\rho(1-\mu)}+\frac{48\eta^{2 }\mu^{2}\zeta^{2}}{\rho(1-\mu)^{2}}\] \[\overset{(c)}{\leq} \Big{(}\frac{6\eta^{2}\mu^{2}}{n\rho(1-\mu)}-\frac{6\eta^{2}\mu^{ 2}}{n\rho}\Big{)}\mathbb{E}||B^{t}||_{F}^{2}+\frac{\rho}{8n}\mathbb{E}||X^{t }-\bar{X}^{t}||_{F}^{2}\] \[+\frac{\eta^{2}\rho\sigma^{2}(1-\mu)}{8}+\frac{\eta^{2}\rho\zeta^{ 2}}{8}\]

Note that \(W-I<I\), \(\;\;I-W<2I\), \(\;\;(W-I)\bar{X}^{t}=0\) and \((W-I)\bar{G}^{t}=0\). (a) follows from the fact that \(||a+b||^{2}\leq(1+\alpha)||a||^{2}+(1+\frac{1}{\alpha})||b||^{2}\;\;\forall \alpha>0\) and let \(\alpha=\frac{1-\mu}{\mu}\). (b) uses the fact that \(||AB||_{F}^{2}\leq\sigma_{max}^{2}(A)||B||_{F}^{2}\) where \(A=2W+I\), \(B=(I-W)X^{t}\) and \(\sigma_{max}^{2}(A)=9\). (c) uses the assumption \(\frac{\mu}{1-\mu}\leq\frac{\rho}{42}\) and \(\eta\leq\frac{\rho}{\tau L}\). This implies that \(\frac{24(9+\eta^{2}L^{2})\mu^{2}}{\rho(1-\mu)^{2}}\leq\frac{\rho}{8}\) and \(\frac{48\mu^{2}}{\rho(1-\mu)^{2}}\leq\frac{\rho}{8}\) 

We present the proof for Theorem 1 using Lemmas. 2, 3, and 4. Adding Lemmas. 3, and 4 and simplifying, we get \[\frac{24L^{2}\eta}{n}\mathbb{E}||X^{t+1}-\bar{X}^{t+1}||_{F}^{2} +\frac{144L^{2}\eta^{3}\mu^{2}}{n\rho^{2}(1-\mu)}\mathbb{E}||B^{t+ 1}||_{F}^{2}\leq\Big{(}\frac{24L^{2}\eta}{n}-\frac{3L^{2}\eta}{n}\Big{)} \mathbb{E}||X^{t}-\bar{X}^{t}||_{F}^{2}\] (17) \[+\frac{144L^{2}\eta^{3}\mu^{2}}{n\rho^{2}(1-\mu)}\mathbb{E}||B^{t }||_{F}^{2}+\frac{312L^{2}\eta^{3}}{\rho^{2}}(\zeta^{2}+\sigma^{2}(2-\mu))\]

Finally, define a function \(\Phi^{t}\) as shown below

\[\Phi^{t}=\frac{24L^{2}\eta}{n}\mathbb{E}||X^{t}-\bar{X}^{t}||_{F}^{2}+\frac{144 L^{2}\eta^{3}\mu^{2}}{n\rho^{2}(1-\mu)}\mathbb{E}||B^{t}||_{F}^{2}+\mathbb{E}[f( \bar{x}^{t})-f^{*}]\] (18)

Now adding Lemma 2 and (17), we have the following

\[\Phi^{t+1}\leq \Phi^{t}-\frac{\eta}{4}\mathbb{E}||\frac{1}{n}\sum_{i=1}^{n}\nabla f _{i}(x_{i}^{t})||^{2}-\frac{\eta}{4}\mathbb{E}||\nabla f(\bar{x}^{t})||^{2}+ \frac{L\eta^{2}\sigma^{2}}{n}+\frac{312L^{2}\eta^{3}}{\rho^{2}}(\zeta^{2}+ \sigma^{2}(2-\mu))\] \[\leq \Phi^{t}-\frac{\eta}{4}\mathbb{E}||\nabla f(\bar{x}^{t})||^{2}+ \frac{L\eta^{2}\sigma^{2}}{n}+\frac{312L^{2}\eta^{3}}{\rho^{2}}(\zeta^{2}+ \sigma^{2}(2-\mu))\] \[\implies \frac{\eta}{4}\mathbb{E}||\nabla f(\bar{x}^{t})||^{2}\leq(\Phi^{t }-\Phi^{t+1})+\frac{L\eta^{2}\sigma^{2}}{n}+\frac{312L^{2}\eta^{3}}{\rho^{2}} (\zeta^{2}+\sigma^{2}(2-\mu))\]

Summing over t

\[\frac{1}{T}\sum_{t=0}^{T-1}\mathbb{E}||\nabla f(\bar{x}^{t})||^{2}\leq\frac{4 }{\eta T}(f(\bar{x}^{0}-f^{*})+\eta\frac{4L\sigma^{2}}{n}+\eta^{2}\frac{1248L^ {2}}{\rho^{2}}(\zeta^{2}+\sigma^{2}(2-\mu)).\] (19)

This concludes the proof of the Theorem 1.

### Proof of Corollary. 1

In the proof of Theorem 1, we assumed the following the following constraints on learning rate \(\eta\) and scaling factor \(\mu\):

\[(i) \eta\leq\min\Big{\{}\frac{1}{4L},\frac{\rho}{7L}\Big{\}}\] \[(ii) \frac{\mu}{1-\mu}\leq\frac{\rho}{42}.\]

We assume that the step size \(\eta\) is \(\mathcal{O}(\sqrt{\frac{T}{T}})\), where \(n\) is the total number of agents and \(T\) is the number of iterations. Given this assumption, we have the following order of each term in (19) of Theorem 1.

\[\frac{4}{\eta T}(f(\bar{x}^{0}-f^{*})=\mathcal{O}\Big{(}\frac{1}{\sqrt{nT}} \Big{)}.\]

For the remaining terms we have,

\[\eta\frac{4L\sigma^{2}}{n}=\mathcal{O}\Big{(}\frac{1}{\sqrt{nT}}\Big{)},\ \ \ \eta^{2}\frac{1248L^{2}}{\rho^{2}}(\zeta^{2}+\sigma^{2}(2-\mu))=\mathcal{O} \Big{(}\frac{n}{T}\Big{)}.\]

Therefore, by omitting the constant \(n\) in this context of higher order terms, there exists a constant \(C>0\) such that the overall convergence rate is as follows:

\[\frac{1}{T}\sum_{t=0}^{T-1}\mathbb{E}||\nabla f(\bar{x}^{t})||^{2}\leq C\Bigg{(} \frac{1}{\sqrt{nT}}+\frac{1}{T}\Bigg{)},\]

which suggests when \(T\) is sufficiently large, _GUT_ enables the convergence rate of \(\mathcal{O}(\frac{1}{\sqrt{nT}})\).

Algorithmic details

In this section, we present the pseudo-code for _QG-GUTm_ which combines the proposed _GUT_ algorithm with quasi-global momentum as Algorithm 2 and its PyTorch implementation version is shown in Algorithm 3. We also summarize the memory-efficient implementation of _GUT_ in Algorithm 4.

**Input:** Each agent \(i\in[1,n]\) initializes model weights \(x_{i}^{(0)}\) and neighbors' copy \(\hat{x}_{j}^{(0)}\), momentum buffer \(m_{i}^{(0)}\), step size \(\eta\), momentum coefficient \(\beta\), mixing matrix \(W=[w_{ij}]_{i,j\in[1,n]}\), _GUT_ scaling factor \(\mu\), \(I_{ij}\) are elements of \(n\times n\) identity matrix, \(\mathcal{N}(i)\) represents neighbors of \(i\) including itself, and note \(\hat{x}_{i}^{t}=x_{i}^{t}\).

Each agent simultaneously implements the Train( ) procedure

1. **procedure** Train( )

2. **for** t=\(0,1,\ldots,T-1\)**do**

3. \(d_{i}^{t}\sim D_{i}\)

4. \(g_{i}^{t}=\nabla_{x}f_{i}(d_{i}^{t};\sum_{j\in\mathcal{N}(i)}w_{ij}*\hat{x}_{j }^{t})\)

5. \(\delta_{i}^{t}=g_{i}^{t}-\frac{1}{\eta}\sum_{j\in\mathcal{N}(i)}(w_{ij}-I_{ij})* \hat{x}_{j}^{t}\)

6. \(y_{i}^{t}=\delta_{i}^{t}+\mu\big{[}\sum\limits_{j\in\mathcal{N}(i)}w_{ij}(m_{j }^{t-1}-\frac{1}{\eta}(\hat{x}_{j}^{t}-x_{i}^{t}))-\delta_{i}^{t-1}\big{]}\)

7. \(m_{i}^{t}=\beta m_{i}^{t-1}+(1-\beta)y_{i}^{t}\)

8. \(\textsc{SenRecive}(m_{i}^{t})\)

9. \(x_{i}^{t+1}=x_{i}^{t}-\eta m_{i}^{t}\)

10. \(\hat{x}_{j}^{t+1}=\hat{x}_{j}^{t}-\eta m_{j}^{t}\)\(\forall\)\(j\in N(i)\backslash i\)

11. **end**

**Algorithm 3** Global Update Tracking with momentum (_QG-GUTm_) - Pytorch Implementation

**Input:** Each agent \(i\in[1,n]\) initializes model weights \(x_{i}^{(0)}\) and neighbors' copy \(\hat{x}_{j}^{(0)}\), momentum buffer \(m_{i}^{(0)}\), step size \(\eta\), momentum coefficient \(\beta\), mixing matrix \(W=[w_{ij}]_{i,j\in[1,n]}\), _GUT_ scaling factor \(\mu\), \(I_{ij}\) are elements of \(n\times n\) identity matrix, \(\mathcal{N}(i)\) represents neighbors of \(i\) including itself, and note \(\hat{x}_{i}^{t}=x_{i}^{t}\).

Each agent simultaneously implements the Train( ) procedure

1. **procedure** Train( )

2. **for** t=\(0,1,\ldots,T-1\)**do**

3. \(d_{i}^{t}\sim D_{i}\)

4. \(g_{i}^{t}=\nabla_{x}f_{i}(d_{i}^{t};\sum_{j\in\mathcal{N}(i)}w_{ij}*\hat{x}_{j }^{t})\)

5. \(\delta_{i}^{t}=g_{i}^{t}-\frac{1}{\eta}\sum_{j\in\mathcal{N}(i)}(w_{ij}-I_{ij})* \hat{x}_{j}^{t}\)

6. \(y_{i}^{t}=\delta_{i}^{t}+\mu\big{[}\sum\limits_{j\in\mathcal{N}(i)}w_{ij}(m_{j }^{t-1}-\frac{1+\beta}{\eta}(\hat{x}_{j}^{t}-x_{i}^{t}))-\delta_{i}^{t-1} \big{]}\)

7. \(m_{i}^{t}=\beta m_{i}^{t-1}+y_{i}^{t}\)

8. \(\textsc{SenRecive}(m_{i}^{t})\)

9. \(x_{i}^{t+1}=x_{i}^{t}-\eta m_{i}^{t}\)

10. \(\hat{x}_{j}^{t+1}=\hat{x}_{j}^{t}-\eta m_{j}^{t}\)\(\forall\)\(j\in N(i)\backslash i\)

11. **end**

**Algorithm 4** Global Update Tracking with momentum (_QG-GUTm_) - Pytorch Implementation

**Input:** Each agent \(i\in[1,n]\) initializes model weights \(x_{i}^{(0)}\) and neighbors' copy \(\hat{x}_{j}^{(0)}\), momentum buffer \(m_{i}^{(0)}\), step size \(\eta\), momentum coefficient \(\beta\), mixing matrix \(W=[w_{ij}]_{i,j\in[1,n]}\), _GUT_ scaling factor \(\mu\), \(I_{ij}\) are elements of \(n\times n\) identity matrix, \(\mathcal{N}(i)\) represents neighbors of \(i\) including itself, and note \(\hat{x}_{i}^{t}=x_{i}^{t}\).

Each agent simultaneously implements the Train( ) procedure

1. **procedure** Train( )

2. **for** t=\(0,1,\ldots,T-1\)**do**

3. \(d_{i}^{t}\sim D_{i}\)

4. \(g_{i}^{t}=\nabla_{x}f_{i}(d_{i}^{t};\sum_{j\in\mathcal{N}(i)}w_{ij}*\hat{x}_{j }^{t})\)

5. \(\delta_{i}^{t}=g_{i}^{t}-\frac{1}{\eta}\sum_{j\in\mathcal{N}(i)}(w_{ij}-I_{ij})* \hat{x}_{j}^{t}\)

6. \(y_{i}^{t}=\delta_{i}^{t}+\mu\big{[}\sum\limits_{j\in\mathcal{N}(i)}w_{ij}(m_{j }^{t-1}-\frac{1+\beta}{\eta}(\hat{x}_{j}^{t}-x_{i}^{t}))-\delta_{i}^{t-1}\big{]}\)

7. \(m_{i}^{t}=\beta m_{i}^{t-1}+y_{i}^{t}\)

8. \(\textsc{SenRecive}(m_{i}^{t})\)

9. \(x_{i}^{t+1}=x_{i}^{t}-\eta m_{i}^{t}\)

10. \(\hat{x}_{j}^{t+1}=\hat{x}_{j}^{t}-\eta m_{j}^{t}\)\(\forall\)\(j\in N(i)\backslash i\)

11. **end**

**Algorithm 5** Global Update Tracking with momentum (_QG-GUTm_) - Pytorch Implementation

**Input:** Each agent \(i\in[1,n]\) initializes model parameters \(x_{i}^{0}\) and weighted model parameters of neighborhood \(s_{i}^{0}\), step size \(\eta\), _GUT_ scaling factor \(\mu\), mixing matrix \(W=[w_{ij}]_{i,j\in[1,n]}\), \(\mathcal{N}(i)\) represents neighbors of \(i\) including itself.

Each agent simultaneously implements the Train( ) procedure

1. **procedure** Train( )
2. **for** t = \(0,1,\ldots,T-1\)**do**
3. \(d_{i}^{l}\sim D_{i}\)
4. \(g_{i}^{t}=\nabla_{x}F_{i}(s_{i}^{t};d_{i}^{t})\)
5. \(\delta_{i}^{t}=g_{i}^{t}-\frac{1}{\eta}(s_{i}^{t}-x_{i}^{t})\)
6. \(y_{i}^{t}=\delta_{i}^{t}+\mu\Big{[}\sum\limits_{j\in\mathcal{N}(i)}w_{ij}y_{j}^ {t-1}-\frac{1}{\eta}(s_{i}^{t}-x_{i}^{t})-\delta_{i}^{t-1}\Big{]}\)
7. \(\textsc{SendReceive}(y_{i}^{t})\)
8. \(x_{i}^{t+1}=x_{i}^{t}-\eta y_{i}^{t}\)
9. \(s_{i}^{t+1}=s_{i}^{t}-\eta\sum_{j\in\mathcal{N}(i)}w_{ij}y_{j}\)
10. **end**
11. **return**\(\frac{1}{n}\sum_{i=1}^{n}x_{i}^{T}\)

**Algorithm 4** Global Update Tracking (Memory Efficient Implementation)

## Appendix C Decentralized Learning Setup

For the decentralized setup, we use an undirected ring, undirected Dyck graph, and undirected torus graph topologies with a uniform mixing matrix. The undirected ring topology for any graph size has 3 peers per agent including itself and each edge has a weight of \(\frac{1}{3}\). The undirected Dyck topology with 32 agents has 4 peers per agent including itself and each edge has a weight of \(\frac{1}{4}\). The undirected torus topology with 32 agents has 5 peers per agent including itself and each edge has a weight of \(\frac{1}{5}\). All our experiments were conducted on a system with Nvidia GTX 1080ti card with 4 GPUs except for ImageNette simulations. We used NVIDIA A40 card with 4 GPUs for ImageNette simulations.

### Datasets

In this section, we give a brief description of the datasets used in our experiments. We use a diverse set of datasets each originating from a different distribution of images to show the generalizability of the proposed techniques.

**CIFAR-10:** CIFAR-10 [13] is an image classification dataset with 10 classes. The image samples are colored (3 input channels) and have a resolution of \(32\times 32\). There are \(50,000\) training samples with \(5000\) samples per class and \(10,000\) test samples with \(1000\) samples per class.

**CIFAR-100:** CIFAR-100 [13] is an image classification dataset with 100 classes. The image samples are colored (3 input channels) and have a resolution of \(32\times 32\). There are \(50,000\) training samples with \(500\) samples per class and \(10,000\) test samples with \(100\) samples per class. CIFAR-100 classification is a harder task compared to CIFAR-10 as it has 100 classes with very few samples per class to learn from.

**Fashion MNIST:** Fashion MNIST [25] is an image classification dataset with 10 classes. The image samples are in greyscale (1 input channel) and have a resolution of \(28\times 28\). There are \(60,000\) training samples with \(6000\) samples per class and \(10,000\) test samples with \(1000\) samples per class.

**Imagenette:** Imagenette [10] is a 10-class subset of the ImageNet dataset. The image samples are colored (3 input channels) and have a resolution of \(224\times 224\). There are \(9469\) training samples with roughly \(950\) samples per class and \(3925\) test samples.

### Network Architecture

We replace ReLU+BatchNorm layers of all the model architectures with EvoNorm-S0 as it was shown to be better suited for decentralized learning over non-IID distributions.

**VGG-11:** We modify the standard VGG-11 [21] architecture by reducing the number of filters in each convolutional layer by \(4\times\) and using only one dense layer with 128 units. Each convolutional layer is followed by EvoNorm-S0 as the activation-normalization layer. VGG-11 has \(0.58M\) trainable parameters.

**ResNet-20:** For ResNet-20 [8], we use the standard architecture with \(0.27M\) trainable parameters except that BatchNorm+ReLU layers are replaced by EvoNorm-S0.

**LeNet-5:** For LeNet-5 [14], we use the standard architecture with \(61,706\) trainable parameters.

**MobileNet-V2:** We use the the standard MobileNet-V2 [20] architecture used for CIFAR dataset with \(2.3M\) parameters except that BatchNorm+ReLU layers are replaced by EvoNorm-S0.

### Hyper-parameters

This section presents a detailed description of the hyper-parameters used in our experiments. All the experiments were run for three randomly chosen seeds. We decay the step size by 10x after 50% and 75% of the training, unless mentioned otherwise. The hyper-parameter \(\mu\) is set to 0.9 for all the experiments using _GUT_ optimizer. We used grid search to choose the hyper-parameter \(\mu\) for _QG-GUTm_.

**Hyper-parameters for experiments in Table 1:** All the experiments have the stopping criteria set to 200 epochs. The initial learning rate is set to 0.1. We decay the step size by \(10\times\) in multiple steps at \(100^{th}\) and \(150^{th}\) epoch. Table 6 presents values of the scaling factor \(\mu\) used in the experiments. For all the experiments, we use a mini-batch size of 32 per agent. The stopping criteria is a fixed number of epochs. We have used a momentum of 0.9 for all QG-DSDm and _QG-GUTm_ experiments.

**Hyper-parameters for experiments in Table 2:** All the experiments have the stopping criteria set to 200 epochs. The initial learning rate is set to 0.1. We decay the step size by \(10\times\) in multiple steps at \(100^{th}\) and \(150^{th}\) epoch. Table 7 presents values of the scaling factor \(\mu\) used in the experiments. For all the experiments, we use a mini-batch size of 32 per agent. The stopping criteria is a fixed number of epochs. We have used a momentum of 0.9 for all QG-DSDm and _QG-GUTm_ experiments.

**Hyper-parameters for experiments in Table 3:** All the experiments with Fashion-MNIST and Imagenette datasets have the stopping criteria set to 100 epochs where as CIFAR-100 experiments

\begin{table}
\begin{tabular}{c c c c c} \hline \multirow{2}{*}{Agents (\(n\))} & \multirow{2}{*}{Method} & \multicolumn{3}{c}{ResNet-20} \\ \cline{3-5}  & & \(\alpha=1\) & \(\alpha=0.1\) & \(\alpha=0.01\) \\ \hline \multirow{5}{*}{16} & DSGD & \(0.0\) & \(0.0\) & \(0.0\) \\  & _GUT (ours)_ & \(0.9\) & \(0.9\) & \(0.9\) \\  & QG-DSGDm & \(0.0\) & \(0.0\) & \(0.0\) \\  & _QG-GUTm (ours)_ & \(0.04\) & \(0.06\) & \(0.04\) \\ \hline \multirow{5}{*}{32} & DSGD & \(0.0\) & \(0.0\) & \(0.0\) \\  & _GUT (ours)_ & \(0.9\) & \(0.9\) & \(0.9\) \\  & QG-DSGDm & \(0.0\) & \(0.0\) & \(0.0\) \\  & _QG-GUTm (ours)_ & \(0.04\) & \(0.04\) & \(0.04\) \\ \hline \hline \multirow{5}{*}{32} & DSGD & \(0.0\) & \(0.0\) & \(0.0\) \\  & _GUT (ours)_ & \(0.9\) & \(0.9\) & \(0.9\) \\  & QG-DSGDm & \(0.0\) & \(0.0\) & \(0.0\) \\  & _QG-GUTm (ours)_ & \(0.08\) & \(0.08\) & \(0.08\) \\ \hline \end{tabular}
\end{table}
Table 6: The value of scaling factor \(\mu\) used for training CIFAR-10 with non-IID data using ResNet-20 and VGG-11 model architectures presented in Table 1have the stopping criteria as 200 epochs. The initial learning rate is set to 0.1 for experiments on CIFAR-100 and Fashion MNIST datasets. The initial learning rate is set to 0.01 for experiments on the Imagenette dataset. We decay the step size by \(10\times\) in multiple steps at \(50^{th}\) and \(75^{th}\) epoch. Table 8 presents values of the scaling factor \(\mu\) used in the experiments. For all the experiments, we use a mini-batch size of 32 per agent. The stopping criteria is a fixed number of epochs. We have used a momentum of 0.9 for all QG-DSDm and _QG-GUTm_ experiments.

## Appendix D Additional Results

Table. 9 shows that the quasi-global variant of Global Update Tracking surpasses the other existing methods even for a higher degree of heterogeneity i.e., \(\alpha=0.01\). We also observe that the Nesterov momentum hurts the performance when the heterogeneity in the data distribution is high. Table. 10 compares the DSGDm baseline with the proposed _GUT_ and _QG-GUTm_. It shows that for a higher degree of heterogeneity, _GUT_ outperforms even the momentum version of DSGD. Table. 11 evaluates the proposed method on various datasets trained on same model architecture (ResNet-20).

## Appendix E Hardware Efficiency

In this section, we present the quantitative results on communication, memory, and compute overheads of the various decentralized algorithms. The communication cost incurred by the proposed _GUT_

\begin{table}
\begin{tabular}{c c c c c} \hline \multirow{2}{*}{Method} & \multicolumn{2}{c}{Dyek Graph (32 agents)} & \multicolumn{2}{c}{Torus (32 agents)} \\ \cline{2-5}  & \(\alpha=0.1\) & \(\alpha=0.01\) & \(\alpha=0.1\) & \(\alpha=0.1\) & \(\alpha=0.01\) \\ \hline QG-DSGDm & \(0.0\) & \(0.0\) & \(0.0\) & \(0.0\) \\ QG-GUTm & \(0.05\) & \(0.05\) & \(0.05\) & \(0.05\) \\ \hline \end{tabular}
\end{table}
Table 7: The value of scaling factor \(\mu\) used for training CIFAR-10 with non-IID data using ResNet-20 model architecture over varies graph topologies presented in Table 2

\begin{table}
\begin{tabular}{c c c c c c} \hline \multirow{2}{*}{Method} & \multicolumn{2}{c}{Fashion MNIST (LeNet-5)} & CIFAR-100 (ResNet-20) & \multicolumn{2}{c}{Imagenette (MobileNet-V2)} \\ \cline{2-5}  & \(\alpha=0.1\) & \(\alpha=0.01\) & \(\alpha=0.1\) & \(\alpha=0.01\) & \(\alpha=0.1\) & \(\alpha=0.01\) \\ \hline QG-DSGDm & \(0.0\) & \(0.0\) & \(0.0\) & \(0.0\) & \(0.0\) & \(0.0\) \\ _QG-GUTm_ & \(0.01\) & \(0.005\) & \(0.005\) & \(0.005\) & \(0.03\) & \(0.04\) \\ \hline \end{tabular}
\end{table}
Table 8: The value of scaling factor \(\mu\) used for training different datasets over 16 agents ring topology presented in Table 3

\begin{table}
\begin{tabular}{l c c c c c} \hline \multirow{2}{*}{Method} & \multicolumn{2}{c}{Local} & \multirow{2}{*}{Nesterov} & Quasi-Global & Global Update & Test Accuracy \\  & Momentum & & Momentum & Tracking & \(\alpha=0.01\) \\ \hline DSGD & x & x & x & x & \(54.66\pm 4.74\) \\ DSGDm & ✓ & x & x & x & \(65.62\pm 4.95\) \\ DSGDm-N & ✓ & ✓ & x & x & \(63.66\pm 4.44\) \\ \hline QG-DSGDm & x & x & ✓ & x & \(79.85\pm 2.13\) \\ QG-DSGDm-N & x & ✓ & ✓ & x & \(78.64\pm 2.14\) \\ \hline GUT & x & x & x & ✓ & \(70.16\pm 4.94\) \\ GUTm & ✓ & x & x & ✓ & \(64.25\pm 5.31\) \\ GUTm-N & ✓ & ✓ & x & ✓ & \(63.42\pm 2.74\) \\ QG-GUTm & x & x & ✓ & ✓ & \(\mathbf{81.04\pm 1.66}\) \\ QG-GUTm-N & x & ✓ & ✓ & ✓ & \(80.09\pm 3.82\) \\ \hline \end{tabular}
\end{table}
Table 9: Evaluating Global Update Tracking (GUT) with various versions of momentum using CIFAR-10 dataset trained on ResNet-20 architecture over 16 agents ring topology for \(\alpha=0.01\).

and _QG-GUTm_ methodologies is the same as the DSGD or QG-DSGDm techniques. All the above-mentioned algorithms communicate a vector with the size same as the model parameters. However, gradient tracking incurs \(2\times\) communication cost in terms of model size. The communication cost and memory requirements for all the experiments are reported in Table. 12 and 13.

We report the numbers for communication, memory, and compute overheads for the memory-efficient implementation of GUT Algorithm. 4 in Table. 14. Memory overhead is reported as the percentage of additional memory required per agent during training with a batch size of 32.

\[\text{Memory overhead}=\frac{\text{Additional memory due to {GUT}}}{\text{Total Memory}}\]

The total memory includes the memory required to store model parameters, activations, gradients, gossip buffer, tracking variable (\(y_{i}\)), and weighted neighbors' parameters (\(s_{i}\)). We observe that for compact models such as ResNet and MobileNet, the memory overhead is less than \(2\%\). However, for larger models such as VGG-11, the memory overhead shoots up to \(14\%\). The computational overhead is reported as the percentage of additional FLOPs required per sample per agent during training.

\[\text{Compute overhead}=\frac{\text{Additional compute due to {GUT}}}{\text{Total Compute}}\]

The total compute includes the forward pass, backward pass, model updates, gossip averaging, and tracking variable computation flops. We observe that for compact models such as ResNet and MobileNet, the compute overhead is around \(2\%\). However, for larger models such as VGG-11, the compute overhead shoots up to \(15\%\).

\begin{table}
\begin{tabular}{c c c c c} \hline \multirow{2}{*}{Agents (\(n\))} & \multirow{2}{*}{Method} & \multicolumn{3}{c}{ResNet-20} \\ \cline{3-5}  & & \(\alpha=1\) & \(\alpha=0.1\) & \(\alpha=0.01\) \\ \hline \multirow{3}{*}{16} & _GUT (ours)_ & \(84.72\pm 0.20\) & \(81.86\pm 1.99\) & \(70.16\pm 4.94\) \\  & DSGDm [15] & \(86.60\pm 0.54\) & \(79.87\pm 1.73\) & \(65.62\pm 4.95\) \\  & _QG-GUTm (ours)_ & \(\mathbf{88.22}\pm 0.36\) & \(\mathbf{86.44}\pm 0.36\) & \(\mathbf{81.04}\pm 1.66\) \\ \hline \multirow{3}{*}{32} & _GUT (ours)_ & \(79.24\pm 0.33\) & \(76.07\pm 0.23\) & \(60.72\pm 1.03\) \\  & DSGDm [15] & \(86.12\pm 0.32\) & \(77.43\pm 1.71\) & \(52.82\pm 4.02\) \\  & _QG-GUTm (ours)_ & \(\mathbf{87.48}\pm 0.33\) & \(\mathbf{84.94}\pm 0.60\) & \(\mathbf{72.04}\pm 3.18\) \\ \hline \hline \multirow{3}{*}{Agents (\(n\))} & \multirow{2}{*}{Method} & \multicolumn{3}{c}{VGG-11} \\ \cline{3-5}  & & \(\alpha=1\) & \(\alpha=0.1\) & \(\alpha=0.01\) \\ \hline \multirow{3}{*}{16} & _GUT (ours)_ & \(82.12\pm 0.09\) & \(81.24\pm 0.95\) & \(76.62\pm 1.37\) \\  & DSGDm [15] & \(81.77\pm 0.38\) & \(74.20\pm 1.89\) & \(584.44\pm 14.58\) \\  & _QG-GUTm (ours)_ & \(\mathbf{84.46}\pm 0.33\) & \(\mathbf{83.05}\pm 0.48\) & \(\mathbf{78.32}\pm 1.03\) \\ \hline \multirow{3}{*}{32} & _GUT (ours)_ & \(80.37\pm 0.33\) & \(79.55\pm 1.00\) & \(73.59\pm 1.26\) \\  & DSGDm [15] & \(81.89\pm 0.29\) & \(74.73\pm 0.73\) & \(61.60\pm 2.80\) \\ \cline{1-1}  & _QG-GUTm (ours)_ & \(\mathbf{84.32}\pm 0.11\) & \(\mathbf{83.39}\pm 0.38\) & \(\mathbf{77.41}\pm 3.44\) \\ \hline \end{tabular}
\end{table}
Table 10: Average test accuracy of different decentralized algorithms evaluated on CIFAR-10, distributed with different degrees of heterogeneity (non-IID) for various models over ring topologies.

\begin{table}
\begin{tabular}{l c c c c c} \hline \multirow{2}{*}{Method} & \multicolumn{2}{c}{Fashion MNIST} & \multicolumn{2}{c}{CIFAR-100} & \multicolumn{2}{c}{Imageette} \\ \cline{2-6}  & \(\alpha=0.1\) & \(\alpha=0.01\) & \(\alpha=0.1\) & \(\alpha=0.1\) & \(\alpha=0.01\) \\ \hline DSGDm [15] & \(87.89\pm 2.34\) & \(79.41\pm 3.29\) & \(47.93\pm 1.69\) & \(42.57\pm 2.71\) & \(66.89\pm 3.12\) & \(47.87\pm 4.03\) \\ QG-DSGDm [16] & \(92.21\pm 0.01\) & \(90.59\pm 0.92\) & \(53.19\pm 1.68\) & \(44.17\pm 3.64\) & \(73.93\pm 2.01\) & \(56.30\pm 5.43\) \\ _QG-GUTm_ & \(\mathbf{92.55}\pm 0.16\) & \(\mathbf{91.70}\pm 0.36\) & \(\mathbf{53.40}\pm 1.23\) & \(\mathbf{50.45}\pm 1.30\) & \(\mathbf{75.44}\pm 2.22\) & \(\mathbf{57.47}\pm 5.33\) \\ \hline \end{tabular}
\end{table}
Table 11: Average test accuracy of different decentralized algorithms evaluated with various datasets trained on ResNet-20 architecture, distributed with different degrees of heterogeneity over 16 agents ring topology.

\begin{table}
\begin{tabular}{c c c c c} \hline Dataset & Model & Method & Comm. Cost & Memory \\  & & & (GB) & (MB) \\ \hline \multirow{3}{*}{Fashion MNIST} & \multirow{3}{*}{LeNet-5} & Gradient Tracking & 11.42 & 4.86 \\  & & QG-DSGDm & 5.71 & 4.62 \\  & & _QG-GUTm_ & 5.71 & 5.10 \\ \hline \multirow{3}{*}{CIFAR-100} & \multirow{3}{*}{ResNet-20} & Gradient Tracking & 85.46 & 129.72 \\  & & QG-DSGDm & 42.73 & 128.66 \\ \cline{1-1}  & & _QG-GUTm_ & 42.73 & 130.78 \\ \hline \multirow{3}{*}{Imagenette} & \multirow{3}{*}{MobileNet-V2} & Gradient Tracking & 68.86 & 3774 \\  & & QG-DSGDm & 34.43 & 3765 \\ \cline{1-1}  & & _QG-GUTm_ & 34.43 & 3782 \\ \hline \end{tabular}
\end{table}
Table 14: Communication, memory, and compute overhead incurred per agent during training of various datasets and model architectures for the proposed _GUT_ algorithm. Note that the overheads are independent of the graph topology and graph size.

\begin{table}
\begin{tabular}{c c c c c} \hline Model & Graph & Graph Size & Method & Comm. Cost & Memory \\  & & & (GB) & (MB) \\ \hline \multirow{3}{*}{ResNet-20} & \multirow{3}{*}{Ring} & \multirow{3}{*}{16} & Gradient Tracking & 83.66 & 129.60 \\  & & & QG-DSGDm & 41.83 & 128.56 \\  & & & _QG-GUTm_ & 41.83 & 130.64 \\ \hline \multirow{3}{*}{ResNet-20} & \multirow{3}{*}{Ring} & \multirow{3}{*}{32} & Gradient Tracking & 41.93 & 129.60 \\  & & & QG-DSGDm & 20.97 & 128.56 \\  & & & _QG-GUTm_ & 20.97 & 130.64 \\ \hline \multirow{3}{*}{ResNet-20} & \multirow{3}{*}{Torus} & \multirow{3}{*}{32} & Gradient Tracking & 83.86 & 129.60 \\  & & & QG-DSGDm & 41.93 & 128.56 \\  & & & _QG-GUTm_ & 41.93 & 130.64 \\ \hline \multirow{3}{*}{ResNet-20} & \multirow{3}{*}{Dyck} & \multirow{3}{*}{32} & Gradient Tracking & 62.90 & 129.60 \\  & & & QG-DSGDm & 31.45 & 128.56 \\  & & & _QG-GUTm_ & 31.45 & 130.64 \\ \hline \multirow{3}{*}{VGG-11} & \multirow{3}{*}{Ring} & \multirow{3}{*}{16} & Gradient Tracking & 178.02 & 31.84 \\  & & & QG-DSGDm & 89.01 & 29.63 \\  & & & _QG-GUTm_ & 89.01 & 34.05 \\ \hline \multirow{3}{*}{VGG-11} & \multirow{3}{*}{Ring} & \multirow{3}{*}{32} & Gradient Tracking & 89.22 & 31.84 \\  & & & QG-DSGDm & 44.61 & 29.63 \\ \cline{1-1}  & & & _QG-GUTm_ & 44.61 & 34.05 \\ \hline \end{tabular}
\end{table}
Table 12: Communication cost and memory requirement per agent during training of CIFAR-10 dataset on various model architectures and graph topologies.

\begin{table}
\begin{tabular}{c c c c c} \hline Dataset & Model & Communication Overhead & Memory Overhead & Compute Overhead \\ \hline Fashion MNIST & LeNet-5 & 0.00 & 0.099 & 0.275 \\ CIFAR-10 & ResNet-20 & 0.00 & 0.016 & 0.021 \\ CIFAR-10 & VGG-11 & 0.00 & 0.138 & 0.149 \\ CIFAR-100 & ResNet-20 & 0.00 & 0.016 & 0.022 \\ Imagenette & MobileNet-V2 & 0.00 & 0.005 & 0.021 \\ \hline \end{tabular}
\end{table}
Table 13: Communication cost and memory requirement incurred per agent during training of various dataset and model architectures over 16 agents ring topology.