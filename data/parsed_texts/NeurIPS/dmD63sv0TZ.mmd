# Trust Your \(\nabla\): Gradient-based Intervention Targeting for Causal Discovery

Mateusz Olko\({}^{1,2,}\)1 Michal Zajac\({}^{3,}\)1 Aleksandra Nowak\({}^{2,3,4,}\)1

**Nino Scherrer\({}^{5}\) Yashas Annadani\({}^{6}\) Stefan Bauer\({}^{6}\)**

**Lukasz Kucinski\({}^{2,7}\) Piotr Milos\({}^{2,8,7}\)2**

\({}^{1}\)Warsaw University, \({}^{2}\)IDEAS NCBR,

\({}^{3}\)Jagiellonian Univeristy, Faculty of Mathematics and Computer Science,

\({}^{4}\)Jagiellonian University, Doctoral School of Exact and Natural Sciences,

\({}^{5}\)ETH Zurich, \({}^{6}\)Helmholtz, TU Munich, \({}^{7}\)deepsense.ai,

\({}^{8}\)Institute of Mathematics, Polish Academy of Sciences

Footnote 1: These authors contributed equally. Corresponding author: mateusz.olko@gmail.com

Footnote 2: footnotemark:

###### Abstract

Inferring causal structure from data is a challenging task of fundamental importance in science. Often, observational data alone is not enough to uniquely identify a system's causal structure. The use of interventional data can address this issue, however, acquiring these samples typically demands a considerable investment of time and physical or financial resources. In this work, we are concerned with the acquisition of interventional data in a targeted manner to minimize the number of required experiments. We propose a novel Gradient-based Intervention Targeting method, abbreviated GIT, that 'trusts' the gradient estimator of a gradient-based causal discovery framework to provide signals for the intervention targeting function. We provide extensive experiments in simulated and real-world datasets and demonstrate that GIT performs on par with competitive baselines, surpassing them in the low-data regime.

## 1 Introduction

Estimating causal structure from data, commonly known as causal discovery, is central to the progress of science [14]. Real-world systems can often be explained as a composition of smaller parts connected by causal relationships. Understanding this underlying structure is essential for making accurate predictions about the system's behavior after a perturbation or treatment has been applied [21]. Causal discovery methods have been successfully deployed in various fields, such as biology [22, 17, 18], medicine [23, 24, 25], earth system science [13], or neuroscience [26]. In machine learning, causal decomposition has been shown to enable sample-efficient learning and fast adaptation to distribution shifts by only updating a subset of parameters [1, 25].

_Observational data_, that is the data obtained directly from the unperturbed system, are, in general, insufficient to identify a system's causal structure and only allow to determine the structure up to the so-called Markov Equivalence Class [27, 28]. To overcome this limited identifiability problem, causal discovery algorithms commonly leverage _interventional_ data [16, 15, 17], which are acquired by gathering data from an experiment perturbing a part of the system [27, 18]. The field of _experimental design_[14, 19, 12], Tong and Koller, [15] is concerned with theacquisition of interventional data in a targeted manner to minimize the number of required experiments, which often requires spending a significant amount of time and physical or financial resources.

In this work, we introduce a simple and effective experimental design algorithm called Gradient-based Intervention Targeting, or GIT for short, see Figure 1. GIT can be easily combined with various gradient-based causal discovery frameworks to provide an efficient active selection of intervention targets. Our method, which is grounded in the ideas from active and curriculum learning (Settles et al., 2007; Graves et al., 2017; Ash et al., 2020), collects interventional data that induce the biggest gradient on parameters of causal structure. GIT leverages the gradient-based nature of the underlying causal discovery framework and achieves better performance than the contemporary baselines.

Our contributions include:

* We introduce GIT, which is to our knowledge, the first gradient-based intervention targeting method. Due to it's plug-and-play nature, our method can be easily combined with various gradient-based causal discovery frameworks.
* Our extensive experiments on synthetic and real-world graphs demonstrate that GIT effectively reduces the amount of interventional data needed to discover the causal structure, and performs well in the low-data regime. This makes GIT a compelling option when access to interventional data is limited.
* We provide a theoretical justification of GIT and a suite of analyses introspecting its behavior and performance.

## 2 Related Work

**Experimental Design / Intervention Design.** There are two major classes of methods for selecting optimal interventions for causal discovery. One class of approaches is based on graph-theoretical properties. Typically, a completed partially directed acyclic graph (CPDAG), describing an equivalence class of DAGs, is first specified. Then, either substructures, such as cliques or trees, are investigated and used to inform decisions (He and Geng, 2008; Eberhardt, 2008; Squires et al., 2020; Greenewald et al., 2019), or edges of a proposed graph are iteratively refined until reaching a prescribed budget (Ghassami et al., 2018, 2019; Kocaoglu et al., 2017; Lindgren et al., 2018). One limitation of graph-theoretical approaches is that misspecification of the CPDAG at the beginning of the process can deteriorate the final solution. Another class of methods is based on Bayesian Optimal Experiment Design (Lindley, 1956), which aims to select interventions with the highest mutual information (MI) between the observations and model parameters. MI is approximated in different ways: AIT (Scherrer et al., 2021) uses F-score inspired metric to implicitly approximate MI; CBED (Tigas et al., 2022) incorporates BALD-like estimator (Houlsby et al., 2011); ABCD (Agrawal et al., 2019) uses estimator based on weighted importance sampling. Although theoretically principled, computing mutual information suffers from approximation errors and model mismatches. Therefore, in this work, we explore using scores based on different principles.

**Gradient-based Causal Structure Learning.** The appealing properties of neural networks have sparked a flurry of gradient-based causal structure learning methods. The most prevalent approaches are self-supervised formulations that optimize a data-dependent scoring metric (for instance, penalized log-likelihood) to find the best causal graph \(G\). Existing self-supervised methods that are capable (or can be extended) of incorporating interventional data can be categorized based on

Figure 1: Overview of GIT’s usage in a gradient-based causal discovery framework. The framework infers a posterior distribution over graphs from observational and interventional data (denoted as \(\mathcal{D}_{obs}\) and \(\mathcal{D}_{int}\)) through gradient-based optimization. The distribution over graphs and the gradient estimator \(\nabla\mathcal{L}(\cdot)\) are then used by GIT in order to score the intervention targets based on the magnitude of the estimated gradients. The intervention target with the highest score is then selected, upon which the intervention is performed. New interventional data \(\mathcal{D}^{new}_{int}\) are then collected and the procedure is repeated.

the underlying optimization formulation into: (i) frameworks with a joint optimization objective (Brouillard et al., 2020; Lorch et al., 2021; Cundy et al., 2021; Annadani et al., 2021; Geffner et al., 2022; Deleu et al., 2022) and (ii) frameworks with alternating phases of optimization (Bengio et al., 2020; Ke et al., 2019; Lippe et al., 2022). While structural and functional parameters are optimized under a joint objective in the former, the latter splits the optimization into two phases with separate objectives. All the aforementioned methods allow evaluation of gradient with respect to the structural and functional parameters with a batch of (real or hypothesized) interventional samples and can serve as a base framework for our proposed _gradient-based_ intervention acquisition strategy.

**Gradients in Active and Curriculum Learning.** Gradients have been successfully used as a criterion to select data to process in previous work. Settles et al. (2007) introduce Expected Gradient Length (EGL), computed under the current belief, as a criterion for active learning. A batch active learning method introduced in Ash et al. (2020) also targets data points with high gradient magnitude, including uncertainty and diversity in the decision. In the area of curriculum learning, Graves et al. (2017) considers Gradient Prediction Gain (GPG), which is defined as the gradient's magnitude and is meant to be a proxy for expected learning progress. We take inspiration from those approaches to propose a novel usage of the gradient criterion in the field of causal discovery.

## 3 Preliminaries

### Structural Causal Models and Causal Structure Discovery

Causal relationships can be formalized using structural causal models (SCM) (Peters et al., 2017). Each of the endogenous variables \(X=(X_{1},\dots,X_{n})\) is expressed as a function \(X_{i}=f_{i}(PA_{i},U_{i})\) of its direct causes \(PA_{i}\subseteq X\) and an external independent noise \(U_{i}\). It is assumed that the assignments are acyclic and thus associated with a directed acyclic graph \(G=(V,E)\). The nodes \(V=\{1,\dots,n\}\) represent the random variables and the edges correspond to the direct causes, that is \((i,j)\in E\) if and only if \(X_{i}\in PA_{j}\). The joint distribution factorizes according to

\[\mathbb{P}(X_{1},\dots,X_{n})=\prod_{i=1}^{n}\mathbb{P}(X_{i}|PA_{i}).\] (1)

Causal structure discovery aims to recover the ground truth graph \(G\). The solution to this problem is not uniquely defined when having access only to observational data from the ground truth distribution \(\mathbb{P}\). Formally, it can be determined solely up to a Markov Equivalence Class (MEC) (Spirites et al., 2000; Peters et al., 2017) without additional restrictive assumptions. To achieve identifiability, data from additional experiments, called interventions, need to be gathered.

A single-node intervention on \(X_{i}\) replaces the conditional distribution \(\mathbb{P}(X_{i}|PA_{i})\) with a new distribution denoted as \(\widetilde{\mathbb{P}}(X_{i}|PA_{i})\), yielding a so-called interventional distribution:

\[\mathbb{P}_{i}(X)\triangleq\widetilde{\mathbb{P}}(X_{i}|PA_{i})\prod_{j\neq i }\mathbb{P}(X_{j}|PA_{j}).\] (2)

The node \(i\in V\) is called the _intervention target_. An intervention that removes the dependency of a variable \(X_{i}\) on its parents, yielding \(\widetilde{\mathbb{P}}(X_{i}|PA_{i})=\widetilde{\mathbb{P}}(X_{i})\), is called hard. In this paper, we use data gathered by performing single-node interventions.

### Online Causal Discovery and Targeting Methods

In this work, we consider an _online_ causal discovery procedure outlined in Algorithm 1. Given a causal discovery Algorithm \(\mathcal{A}\), the graph model \(\varphi_{0}\) is fitted using observational data \(\mathcal{D}_{obs}\). Following that, batches of interventional samples are acquired iteratively and are used by the algorithm to improve the belief about the causal structure (line 7). Intervention targets are chosen by _intervention targetting method_\(\mathcal{M}\) to optimize the overall performance, taking into account the current belief about the graph structure encoded in \(\varphi_{i-1}\). Below we discuss two popular choices for the method \(\mathcal{M}\) (with more details deferred to Appendix D).

causal discovery is approximating the posterior distribution over the possible causal DAGs. This allows using the framework of Bayesian Optimal Experimental Design to select the most informative intervention (experiment). The score of a new experiment is given by the mutual information (MI) between the interventional data due to the experiment and the current belief about the graph structure. Hence, such an approach requires estimating MI. For instance, Causal Bayesian Experimental Design (CBED) (Tigas et al., 2022) uses a BALD-like estimator (Houlsby et al., 2011) to sample batches of interventional targets.

## 4 Git method

In this work, we present a new _intervention targeting_ method GIT. GIT chooses intervention targets that induce the largest update of the parameters modeling the causal structure. Inspired by _hallucinated gradients_ exploited by (Ash et al., 2020) we calculate gradients on imaginary data generated by the causal model, to score possible interventions for real data acquisition.

To formally introduce our method, we first describe the requirements that need to be fulfilled by a causal algorithm \(\mathcal{A}\) in order to use it with GIT. We then explain how GIT works and follow up with a discussion about causal assumptions and theoretical justification of our approach. Finally, in Section 4.1, we present a practical implementation of our method with a causal discovery algorithm \(\mathcal{A}\), using a popular ENCO algorithm as an example.

Requirements for causal discovery algorithm \(\mathcal{A}\).The intervention targeting method GIT can be coupled with any gradient-based causal discovery algorithm \(\mathcal{A}\) (see Algorithm 1) that fulfills the following conditions:

1. \(\mathcal{A}\) models a distribution over the causal DAGs, denoted by a family of probability measures \(\mathbb{P}_{\rho}(G)\) parameterized by \(\rho\), that allows sampling.
2. For each causal graph \(G\), \(\mathcal{A}\) maintains a corresponding family of conditional distributions, \(\mathbb{P}_{G,\phi}(X_{i}|PA_{(i,G)})\), parametrized by \(\phi\), which induces the joint distribution \(\mathbb{P}_{G,\phi}\): \[\mathbb{P}_{G,\phi}(X)\triangleq\prod_{i}\mathbb{P}_{G,\phi}\left(X_{i}|PA_{ (i,G)}\right).\] (3) If \(G\) corresponds to the ground truth graph, \(\mathbb{P}_{G,\phi}\) approximates the ground truth distribution over \(X\).
3. \(\mathcal{A}\) gives access to its loss function \(\mathcal{L}\) and gradient of the loss function \(\nabla_{\rho}\mathcal{L}\) with respect to \(\rho\).

These requirements are mildly restrictive and they are fulfilled by many gradient-based discovery methods (for instance, ENCO (Lippe et al., 2022), SDI (Ke et al., 2019), DiBS (Lorch et al., 2021), DCDI (Brouillard et al., 2020) or DECI (Geffner et al., 2022)).

Method.GIT scores each possible intervention target by calculating the expected magnitude of the gradient using imaginary interventional data generated by the causal model. Gradient magnitude serves as a proxy for the size of the update that can be induced on the parameters of the causal model.

The method picks intervention that has the highest score. Formally, for a given intervention \(i\in V\) we define its score \(s_{i}\) as follows:

\[s_{i}\triangleq\mathbb{E}_{X\sim\mathbb{P}_{\rho,\phi,i}}\|\nabla_{\rho}\mathcal{ L}(X)\|.\] (4)

Note that the expected value is computed with the interventional distribution coming from the model, instead of ground truth, defined as:

\[\mathbb{P}_{\rho,\phi,i}(X)\triangleq\sum_{G}\mathbb{P}_{\rho}(G)\mathbb{P}_{G,\phi,i}(X).\] (5)

The summation in equation 5 is taken over all DAGs and \(\mathbb{P}_{G,\phi,i}\) corresponds to the joint distribution from the model for graph \(G\):

\[\mathbb{P}_{G,\phi,i}(X)\triangleq\widetilde{\mathbb{P}}(X_{i}|PA_{i})\prod_{ j\neq i}\mathbb{P}_{G,\phi}(X_{j}|PA_{(j,G)}).\] (6)

The computational procedure of GIT's intervention target selection is listed in Algorithm 2. The expected value in \(s_{i}\) is approximated using the Monte-Carlo method, see line 4 of Algorithm 2. We also use a version of Algorithm 2 where real interventional data are used in line 3 (instead of the imaginary ones from the model) and call it GIT-privileged. GIT-privileged serves as a soft upper bound in our analysis. Note however, that it is not practically useful, as collecting real interventional data would require intervention on every node in the first place.

```
0: parameters \(\rho\) of distribution over graphs, functional parameters \(\phi\), loss function \(\mathcal{L}\), graph nodes \(V\)
0: batch of intervention targets to execute: \(I\)
1:\(\mathcal{G}\leftarrow\) sample a set of DAGs according to \(\mathbb{P}_{\rho}(G)\)
2:for intervention target \(i\in V\)do
3:\(\mathcal{D}_{G,i}\leftarrow\) sample batch of data according to \(\mathbb{P}_{G,\phi,i}\)
4:\(s_{i}\leftarrow\frac{1}{|\mathcal{G}|}\sum_{G\in\mathcal{G}}\frac{1}{|\mathcal{ D}_{G,i}|}\sum_{X\in\mathcal{D}_{G,i}}\|\nabla_{\rho}\mathcal{L}(X)\|\)
5:endfor
6:\(I\leftarrow\) select a batch of targets with highest scores \(s_{i}\) ```

**Algorithm 2**GIT's Intervention target selection

Assumptions of GIT.From the causal perspective, GIT relies exclusively on the Markov property assumption, which allows factorization of joined distribution (see Equation 1). However, GIT as a plug-and-play extension for causal discovery algorithms \(\mathcal{A}\) inherits their assumptions. This may include, for instance, causal sufficiency or faithfulness. Our method does not require any additional assumptions on the variables \(X_{i}\) and allows for both discrete and continuous setups.

Theoretical justification of GIT.We show the convergence of GIT in two contexts. First, we prove that the main setup of this paper, i.e., GIT with ENCO (Lippe et al., 2022), described in Section 4.1, converges. The detailed result can be found in Appendix B, but the gist of the argument is that vertices for which the model structure is not aligned with the ground truth will have non-trivial gradients and hence will be queried by GIT, allowing the model to improve. Moreover, we show empirically that GIT gradients are well correlated with the principled GPG signal of GIT-privileged, see Appendix F.6. Second, we show that given any convergent causal discovery algorithm, GIT converges if we allow a uniform sampling of intervention with small probability \(\epsilon>0\), see Appendix A. We call this approach \(\epsilon\)-greedy GIT. Importantly, on a finite sample with small enough \(\epsilon\), GIT and \(\epsilon\)-greedy GIT are statistically indistinguishable.

### Applicability to ENCO

We choose to use ENCO as the gradient-based causal discovery framework \(\mathcal{A}\) in our main experiments (recall Algorithm 1) due to its strong empirical results and good computational performance on GPUs. ENCO maintains a parameterized distribution over graph structures, with the so-called structural parameters \(\{\rho_{i,j}\}_{i,j}\) representing the adjacency matrix and a set of parameters modeling the functional dependencies, \(\phi\). The structural parameters, \(\rho_{i,j}\), are factorized into an edge existence parameter, \(\gamma_{i,j}\), and an edge orientation parameter, \(\theta_{i,j}=-\theta_{j,i}\).

The parameters are updated by iteratively alternating between two optimization phases. The goal of the first phase is to learn functions \(f_{\phi_{i}}\left(x_{i}|PA_{(i,G)}\right)\), which model the conditional density of \(\mathbb{P}\left(X_{i}|PA_{(i,G)}\right)\). The training objective is the log-likelihood loss. The second phase aims to update the parametrized edge probabilities \(\rho_{i,j}\)'s. To this end, ENCO collects a data sample from a mixture of interventional distributions denoted by \(\mathbb{P}_{I}\). The graph parameters are optimized by minimizing \(\mathbb{E}_{X\sim\mathbb{P}_{I}}L_{\text{graph}}(X)\) where:

\[L_{\text{graph}}(X)\triangleq\mathbb{E}_{G\sim P_{\gamma,\theta}}\bigg{[}\sum_{ i=1}^{n}L_{G}(X_{i})\bigg{]},\quad L_{G}(x_{i})\triangleq-\log f_{\phi_{i}}\left(x_{i}|PA _{(i,G)}\right),\] (7)

For a detailed description of the method, distributions, and the estimators see Appendix C.1.

Git with ENCO details.The loss function \(\mathcal{L}\) utilized by Git is denoted \(L_{\text{graph}}\). We incorporate information from both structural parameters and use \(\|\nabla_{\gamma}L_{\text{graph}}(X)\|^{2}+\|\nabla_{\theta}L_{\text{graph}}( X)\|^{2}\) to compute the score for the intervention \(i\) in line 4 of Algorithm 2. In order to sample DAGs from the current graph distribution (line 1 of Algorithm 2), we use a two-phase sampling procedure proposed in (Scherrer et al., 2021, Section 3.2) as it is scalable and guarantees DAG-ness by construction opposed to Gibbs sampling or rejection sampling techniques.

## 5 Experiments

We compare Git against the following baselines: AIT, CBED, Random, and Git-privileged. AIT and CBED are competitive intervention acquisition methods for gradient-based causal discovery (which we discussed in Section 3.2). The Random method selects interventions uniformly in a round-robin fashion2. The last approach, Git-privileged, is the oracle method described in Section 4.

Footnote 2: At every step, a target node is chosen uniformly at random from the set of yet not visited nodes. After every node has been selected, the visitation counts are reset to 0.

Our main result is that Git brings substantial improvement in the low data regime, being the best among benchmarked methods for all considered synthetic graph classes and half of the considered real graphs in terms of the AUSHD metric (see Equation 9). On the remaining real graphs, our approach performs similarly to the baseline methods. Notably, in most cases, Git surpasses MI-based approaches: CBED and AIT. We present the summary in Table 1. This result is accompanied by an in-depth analysis of the relationships between different strategies and the distributions of the selected intervention targets. Additional results in the DiBS framework (Lorch et al., 2021) with continuous data are presented in Appendix F.1.

### Experimental Setup

We evaluate the different intervention targeting methods in online causal discovery, see Algorithm 1. We utilize an observational dataset of size \(5000\). We use \(T=100\) rounds, in each one acquiring an interventional batch of \(32\) samples. We distinguish two regimes: regular, with all \(100\) rounds (\(N=3200\) interventional samples), and low, with \(33\) rounds (\(N=1056\) interventional samples). We use \(|\mathcal{G}|=50\) graphs and \(|\mathcal{D}_{G,i}|=128\) data samples from each graph for the Monte-Carlo approximation of the Git score. We tested different sizes of the Monte-Carlo sample and found that it does not have a major impact on performance, see Appendix F.4. For all experiments in this section we assume, following the approach of Lippe et al. (2022), that all interventions are single-node, hard, and change the conditional distribution of the intervened node to uniform.

DatasetsWe use synthetic and real-world datasets. The synthetic dataset consists of bidiag, chain, collider, jungle, fulldag and random DAGs, each with \(25\) nodes. The variable distributions are categorical, with \(10\) categories3. The real-world dataset consists of alarm, asia, cancer, child,

\begin{table}
\begin{tabular}{l l l l l l} \hline \hline  & AIT & CBED & Random & Git (ours) & Git-privileged \\ \hline mean AUSHD & \(6\) (\(2+4\)) & \(6\) (\(4+2\)) & \(12\) (\(5+7\)) & \(18\) (\(11+7\)) & \(24\) (\(12+12\)) \\ mean SHD & \(10\) (\(4+6\)) & \(7\) (\(4+3\)) & \(22\) (\(12+10\)) & \(17\) (\(10+7\)) & \(24\) (\(12+12\)) \\ \hline \hline \end{tabular}
\end{table}
Table 1: We count the number of setups (24), where a given method was best or comparable to the other methods (AIT, CBED, Random, and Git; Git-privileged was not compared against), based on 90% confidence intervals for SHD and AUSHD. Each entry shows the total count, broken down into two data regimes, \(N=1056\) and \(N=3200\), respectively, presented in parentheses.

earthquake, and sachs graphs, taken from the BnLearn repository (Scutari, 2010). Both synthetic and real-world graphs are commonly used as benchmarking datasets (Ke et al., 2019; Lippe et al., 2022; Scherrer et al., 2021).

MetricsWe use the Structural Hamming Distance (SHD) (Tsamardinos et al., 2006) between the predicted and the ground truth graph as the main metric. SHD between two directed graphs is defined as the number of edges that need to be added, removed, or reversed in order to transform one graph into the other. More precisely, for two DAGs represented as adjacency matrices \(c\) and \(c^{\prime}\),

\[\text{SHD}(c,c^{\prime}):=\sum_{i>j}\mathbf{1}(c_{ij}+c_{ji}\neq c^{\prime}_{ ij}+c^{\prime}_{ji}\text{ or }c_{ij}\neq c^{\prime}_{ij}).\] (8)

In the experiments, we always compute SHD between the predicted and the ground truth graph. In order to aggregate SHD values over different data regimes, we introduce the area under the SHD curve (AUSHD):

\[\text{AUSHD}_{m}^{T}:=\frac{1}{T}\sum_{t=1}^{T}\text{SHD}_{m}^{t},\quad\text{ SHD}_{m}^{t}:=\text{SHD}(c_{gt},c_{m,t})\] (9)

where \(m\) is the used method, \(T\) is the number of interventional data batches, \(c_{gt}\) is the ground truth graph, and \(c_{m,t}\) is the graph fitted by the method \(m\) using \(t\) interventional data batches. Intuitively, for small to moderate values of \(T\), AUSHD captures a method's speed of convergence: the faster the SHD converges to 0, the smaller the area. For large values of \(T\), AUSHD measures the asymptotic convergence. Smaller values indicate a better method. For visualizations, we use surplus of AUSHD over Random method (SAUSHD), which compares method \(m\) the the Random baseline. Precisely,

\[\text{SAUSHD}_{m}^{T}:=\text{AUSHD}_{m}^{T}-\mathbb{E}\left[\text{AUSHD}_{Random }^{T}\right],\] (10)

where the expectation averages all randomness sources (e.g. stemming from the initialization). Again, smaller values indicate a better method.

### Main Result: Git's Empirical Performance

Git's Overall Strong PerformanceWe evaluate GIT on 24 training setups: twelve graphs (synthetic and real-world, six in each category) and two data regimes. GIT is the best or comparable to the baseline methods (excluding GIT-privileged) in 18 cases according to mean AUSHD, and 17 cases according to mean SHD, see Table 1. Additionally, GIT is stable, as the distribution of its AUSHD has most frequently the smallest variation among non-privileged methods (\(11\) out of \(24\) cases), see Table 8 and Table 9 in Appendix F.2.2. In terms of pairwise comparison with other methods, GIT is better in 45 cases and comparable in 35 cases, out of a total of 96 (\(=24\) setups \(\times 4\)

Figure 2: The distribution of SAUSHD (see equation 10), calculated using 25 seeds, for synthetic graphs (lower is better). The intense color (left-hand side of each violin plot) indicates the low data regime (\(N=1056\) samples). The faded color (right-hand side of each violin plot) represents a higher amount of data (\(N=3200\) samples). Note that even though the solution quality is improved when more samples are available, typically, SAUSHD is smaller in the low data regime. This is because it measures relative improvement over the random baseline, which is most visible for the small number of samples in most methods.

[MISSING_PAGE_FAIL:8]

We perform an additional experiment in a modified regime, where each intervention yields \(1024\) data points instead of the previous \(32\). Such a regime is relevant in scenarios where setting up an intervention with a new target is costly but obtaining the individual samples is relatively cheap. We run the experiment on synthetic graphs with \(25\) nodes and we run for \(25\) acquisition rounds. We present the AUSHD values in Table 2 and full SHD curves in Appendix F.3. In this setting, GIT outperforms all the standard baselines and is on par with GIT-privileged. Importantly, GIT reaches the SHD value of \(0\) for all graphs. Additionally, we found that GIT selects each intervention target exactly once, except for the chain graph, for which the discovery process converges already after only 15 rounds.

### Investigating GIT's intervention target distributions

In order to gain a qualitative understanding of the GIT's behavior, we analyze the node distributions generated by respective methods on the BnLearn graphs in Figure 4. We observe that GIT often selects nodes with high out-degree, as visible in the sachs and child graphs. Intuitively, interventions on such nodes bring much information, as they affect multiple other nodes. In addition, the most frequently selected nodes in the sachs, child, and asia graphs are also adjacent to the edges for which there exists a graph in the MEC that has the corresponding connection reversed (as indicated by the green color in Figure 4). Note that in general, establishing the directionality of such an edge \((v,w)\) requires performing interventions on nodes \(v,w\) (recall Section 3.1). 4

Footnote 4: For example, in the ENCO framework the directionality parameter \(\theta_{ij}\) can only be reliably detected from the data obtained by intervening either on variable \(X_{j}\) or \(X_{i}\)(Lippe et al., 2022).

We further explore the interventional targets and verify that GIT is able to target the most uncertain regions of the graph. In the considered setup, we select a node \(v\) in the graph. Let \(E_{v}\) be edges adjacent to \(v\). We set the structural parameters corresponding to edges \(e\notin E_{v}\) to the ground truth values and initialize in the standard way the parameters for \(e\in E_{v}\). Such a model is only unsure

\begin{table}
\begin{tabular}{l c c c c c} \hline \hline  & AIT & CRED & Random & GIT(ours) & GIT-privileged \\ \hline hiding & 22.6 & 17.6 & 20.4 & **16.8** & 15.4 \\ chain & 11.4 & 8.2 & 10.2 & **8.0** & 7.7 \\ collider & 11.2 & 11.4 & 9.9 & **5.0** & 4.8 \\ fill & 120.1 & 116.0 & 101.1 & **100.9** & 93.2 \\ jungle & 22.3 & 16.7 & 19.9 & **11.4** & 10.6 \\ random & 38.4 & 36.2 & 32.4 & **29.9** & 28.3 \\ \hline \hline \end{tabular}
\end{table}
Table 2: Average AUSHD values (from 5 seeds) for experiments with interventional batch size equal 1024.

Figure 4: The interventional target distributions obtained by different strategies on real-world data. The probability is represented by the intensity of the node’s color. The green color represents the edges for which there exists a graph in the Markov Equivalence Class that has the corresponding connection reversed. The number below each graph denotes the entropy of the distribution.

Figure 5: Histograms of intervention targets chosen by GIT. In this experiment, a node \(v\) was chosen (denoted by a red color; \(v\)’s parents are indicated by green). Parameters were initialized so that the model is only unsure about the neighborhood of \(v\). The solid lines denote known edges and dashed ones are to be discovered.

about the connectivity around \(v\), while the rest of the solution is given. We then run the ENCO framework with GIT and report the intervention target distributions in Figure 5.

The interventions concentrate on \(v\) (red color) and its parents (green color). This indicates the efficiency of our approach, as these are most relevant to discovering the graph structure. Indeed, to recover the solution, only the parameters for \(e\in E_{v}\) need to be found. Intervening on \(v\) changes the distributions of its descendants, providing information on the existence of edges between these variables.

## 6 Limitations and future work

* The theoretical grounding of the method involves multiple assumptions. Further work that simplifies or relaxes the assumptions and identifies fail cases would benefit the community.
* We provide proof that epsilon-greedy GIT converges with any causal discovery framework. As for pure GIT, we show its convergence only with the ENCO framework. The development of a more general theory that solidifies the approach is a promising future work direction.
* Our method can be applied in the soft-intervention case, and providing appropriate experimental evaluation would be an interesting follow-up to this work.
* Our method may need more interventions than the minimal number required to identify the causal structure. For example, GIT can be biased towards high-degree nodes, as interventions on them tend to affect a larger amount of structural parameters and result in larger gradients, which might cause suboptimal choices.
* Intervention acquisition methods (including GIT) seem to be less effective in a continuous setting. We believe investigating this area would benefit the community.

## 7 Conclusions

In this paper, we consider the problem of experimental design for causal discovery. We introduce a novel Gradient-based Intervention Targeting (GIT) method, which leverages the gradients of gradient-based causal discovery objectives to score intervention targets. We demonstrate that the method is particularly effective in the low-data regime, outperforming competitive baselines. We also provide a theoretical justification for the method and perform several analyses, confirming that GIT typically selects informative targets.

## Acknowledgments and Disclosure of Funding

The work of Piotr Milos was supported by the Polish National Science Center grant UMO-2017/26/E/ST6/00622 and UMO-2019/35/O/ST6/03464. The work of Michal Zajac was supported by the Polish National Science Center Grant No. 2021/43/B/ST6/01456. The research of Michal Zajac and Aleksandra Nowak has been supported by a flagship project entitled "Artificial Intelligence Computing Center Core Facility" from the DigiWorld Priority Research Area under the Strategic Programme Excellence Initiative at Jagiellonian University. We gratefully acknowledge Polish high-performance computing infrastructure PLGrid for providing computer facilities and support. Our experiments were managed using https://neptune.ai. We thank the Neptune team for providing us access to the team version and technical support. We thank Swedish National Supercomputing and the Berzelius Cluster for providing compute resources.

## References

* Agrawal et al. (2019) Raj Agrawal, Chandler Squires, Karren D. Yang, Karthikeyan Shanmugam, and Caroline Uhler. Abcd-strategy: Budgeted experimental design for targeted causal structure discovery. In Kamalika Chaudhuri and Masashi Sugiyama, editors, _The 22nd International Conference on Artificial Intelligence and Statistics, AISTATS 2019, 16-18 April 2019, Naha, Okinawa, Japan_, volume 89 of _Proceedings of Machine Learning Research_, pages 3400-3409. PMLR, 2019. URL http://proceedings.mlr.press/v89/agrawal19b.html. (Cited on page 2)
* Annadani et al. (2021) Yashas Annadani, Jonas Rothfuss, Alexandre Lacoste, Nino Scherrer, Anirudh Goyal, Yoshua Bengio, and Stefan Bauer. Variational causal networks: Approximate bayesian inference over causal structures. _arXiv preprint arXiv:2106.07635_, 2021. (Cited on page 3)Jordan T. Ash, Chicheng Zhang, Akshay Krishnamurthy, John Langford, and Alekh Agarwal. Deep batch active learning by diverse, uncertain gradient lower bounds. In _8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020_. OpenReview.net, 2020. URL https://openreview.net/forum?id=rygBzJBKPS. (Cited on page 2, 3, 4)
* Bengio et al. (2020) Yoshua Bengio, Tristan Deleu, Nasim Rahaman, Nan Rosemary Ke, Sebastien Lachapelle, Olexa Bilaniuk, Anirudh Goyal, and Christopher J. Pal. A meta-transfer objective for learning to disentangle causal mechanisms. In _8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020_. OpenReview.net, 2020. URL https://openreview.net/forum?id=ryxNlgRFPS. (Cited on page 1, 3)
* Brouillard et al. (2020) Philippe Brouillard, Sebastien Lachapelle, Alexandre Lacoste, Simon Lacoste-Julien, and Alexandre Drouin. Differentiable causal discovery from interventional data. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, editors, _Advances in Neural Information Processing Systems_, volume 33, pages 21865-21877. Curran Associates, Inc., 2020. (Cited on page 1, 3, 4)
* Castro et al. (2020) Daniel C Castro, Ian Walker, and Ben Glocker. Causality matters in medical imaging. _Nature Communications_, 11(1):1-10, 2020. (Cited on page 1)
* Cundy et al. (2021) Chris Cundy, Aditya Grover, and Stefano Ermon. Bcd nets: Scalable variational approaches for bayesian causal discovery. _Advances in Neural Information Processing Systems_, 34, 2021. (Cited on page 3)
* Deleu et al. (2022) Tristan Deleu, Antonio Gois, Chris Emezue, Mansi Rankawat, Simon Lacoste-Julien, Stefan Bauer, and Yoshua Bengio. Bayesian structure learning with generative flow networks. In James Cussens and Kun Zhang, editors, _Uncertainty in Artificial Intelligence, Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence, UAI 2022, 1-5 August 2022, Eindhoven, The Netherlands_, volume 180 of _Proceedings of Machine Learning Research_, pages 518-528. PMLR, 2022. URL https://proceedings.mlr.press/v180/deleu22a.html. (Cited on page 3)
* Eberhardt (2008) Frederick Eberhardt. Almost optimal intervention sets for causal discovery. In David A. McAllester and Petri Myllymaki, editors, _UAI 2008, Proceedings of the 24th Conference in Uncertainty in Artificial Intelligence, Helsinki, Finland, July 9-12, 2008_, pages 161-168. AUAI Press, 2008. URL https://dslpitt.org/uai/displayArticleDetails.jsp?mmnu=1&smnu=2&article_id=1948&proceeding_id=24. (Cited on page 2)
* Ebert-Uphoff and Deng (2012) Imme Ebert-Uphoff and Yi Deng. Causal discovery for climate research using graphical models. _Journal of Climate_, 25(17):5648-5665, 2012. (Cited on page 1)
* Geffner et al. (2022) Tomas Geffner, Javier Antoran, Adam Foster, Wenbo Gong, Chao Ma, Emre Kiciman, Amit Sharma, Angus Lamb, Martin Kukla, Nick Pawlowski, et al. Deep end-to-end causal inference. _arXiv preprint arXiv:2202.02195_, 2022. (Cited on page 3, 4)
* Ghassami et al. (2018) AmirEmad Ghassami, Saber Salehkaleybar, Negar Kiyavash, and Elias Bareinboim. Budgeted experiment design for causal structure learning. In Jennifer Dy and Andreas Krause, editors, _Proceedings of the 35th International Conference on Machine Learning_, volume 80 of _Proceedings of Machine Learning Research_, pages 1724-1733. PMLR, 10-15 Jul 2018. URL https://proceedings.mlr.press/v80/ghassami18a.html. (Cited on page 2)
* Ghassami et al. (2019) AmirEmad Ghassami, Saber Salehkaleybar, and Negar Kiyavash. Interventional experiment design for causal structure learning. _CoRR_, abs/1910.05651, 2019. URL http://arxiv.org/abs/1910.05651. (Cited on page 2)
* Glymour et al. (2019) Clark Glymour, Kun Zhang, and Peter Spirtes. Review of causal discovery methods based on graphical models. _Frontiers in genetics_, 10:524, 2019. (Cited on page 1)
* Graves et al. (2017) Alex Graves, Marc G. Bellemare, Jacob Menick, Remi Munos, and Koray Kavukcuoglu. Automated curriculum learning for neural networks. In Doina Precup and Yee Whye Teh, editors, _Proceedings of the 34th International Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017_, volume 70 of _Proceedings of Machine Learning Research_, pages 1311-1320. PMLR, 2017. URL http://proceedings.mlr.press/v70/graves17a.html. (Cited on page 2, 3)
* Goyal et al. (2019)Kristjan Greenewald, Dmitriy Katz, Karthikeyan Shanmugam, Sara Magliacane, Murat Kocaoglu, Enric Boix Adsera, and Guy Bresler. Sample efficient active learning of causal trees. In H. Wallach, H. Larochelle, A. Beygelzimer, F. dAlche-Buc, E. Fox, and R. Garnett, editors, _Advances in Neural Information Processing Systems_, volume 32. Curran Associates, Inc., 2019. URL https://proceedings.neurips.cc/paper/2019/file/5ee505917626676f6a285fa4c10f7b0-Paper.pdf.
* Hauser and Buhlmann (2012) Alain Hauser and Peter Buhlmann. Characterization and greedy learning of interventional markov equivalence classes of directed acyclic graphs. _The Journal of Machine Learning Research_, 13(1):2409-2464, 2012.
* He and Geng (2008) Yang-Bo He and Zhi Geng. Active learning of causal networks with intervention experiments and optimal designs. _Journal of Machine Learning Research_, 9(84):2523-2547, 2008. URL http://jmlr.org/papers/v9/he08a.html.
* Houlsby et al. (2011) Neil Houlsby, Ferenc Huszar, Zoubin Ghahramani, and Mate Lengyel. Bayesian active learning for classification and preference learning. _CoRR_, abs/1112.5745, 2011. URL http://arxiv.org/abs/1112.5745.
* Ke et al. (2019) Nan Rosemary Ke, Olexa Bilaniuk, Anirudh Goyal, Stefan Bauer, Hugo Larochelle, Bernhard Scholkopf, Michael C. Mozer, Chris Pal, and Yoshua Bengio. Learning neural causal models from unknown interventions, 2019. URL https://arxiv.org/abs/1910.01075.
* Kocaoglu et al. (2017) Murat Kocaoglu, Karthikeyan Shanmugam, and Elias Bareinboim. Experimental design for learning causal graphs with latent variables. In I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, _Advances in Neural Information Processing Systems_, volume 30. Curran Associates, Inc., 2017. URL https://proceedings.neurips.cc/paper/2017/file/291d43c696d8c3704cdbe0a72ade5f6c-Paper.pdf.
* Krause and Guestrin (2005) Andreas Krause and Carlos Guestrin. Near-optimal nonmyopic value of information in graphical models. In _Proceedings of the Twenty-First Conference on Uncertainty in Artificial Intelligence_, UAI'05, page 324-331, Arlington, Virginia, USA, 2005. AUAI Press. ISBN 0974903914.
* Lindgren et al. (2018) Erik M. Lindgren, Murat Kocaoglu, Alexandros G. Dimakis, and Sriram Vishwanath. Experimental design for cost-aware learning of causal graphs. In Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicolo Cesa-Bianchi, and Roman Garnett, editors, _Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montreal, Canada_, pages 5284-5294, 2018. URL https://proceedings.neurips.cc/paper/2018/hash/ba3e9b6a519cfddc560b5d53210df1bd-Abstract.html.
* Lindley (1956) David Lindley. On a measure of the information provided by an experiment. _Annals of Mathematical Statistics_, 27:986-1005, 1956.
* Lippe et al. (2022) Phillip Lippe, Taco Cohen, and Efstratios Gavves. Efficient neural causal discovery without acyclicity constraints. In _The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022_. OpenReview.net, 2022. URL https://openreview.net/forum?id=eYciPrLuUhG.
* Li and Wang (2016) Qiang Liu and Dilin Wang. Stein variational gradient descent: A general purpose bayesian inference algorithm. In D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett, editors, _Advances in Neural Information Processing Systems_, volume 29. Curran Associates, Inc., 2016. URL https://proceedings.neurips.cc/paper/2016/file/b3ba8f1bee1238a2f37603d90b58898d-Paper.pdf.
* Lorch et al. (2021) Lars Lorch, Jonas Rothfuss, Bernhard Scholkopf, and Andreas Krause. Dibs: Differentiable bayesian structure learning. _Advances in Neural Information Processing Systems_, 34:24111-24123, 2021.
* Murphy (2001) Kevin P Murphy. Active learning of causal bayes net structure. 2001. (Cited on page 1)G. L. Nemhauser, L. A. Wolsey, and M. L. Fisher. An analysis of approximations for maximizing submodular set functions--i. _Mathematical Programming_, 14(1):265-294, Dec 1978. ISSN 1436-4646. doi: 10.1007/BF01588971. URL https://doi.org/10.1007/BF01588971.
* Pearl (2009) Judea Pearl. _Causality_. Cambridge University Press, Cambridge, UK, 2 edition, 2009. ISBN 978-0-521-89560-6. doi: 10.1017/CBO9780511803161.
* Peters et al. (2016) Jonas Peters, Peter Buhlmann, and Nicolai Meinshausen. Causal inference by using invariant prediction: identification and confidence intervals. _Journal of the Royal Statistical Society: Series B (Statistical Methodology)_, 78(5):947-1012, 2016.
* Peters et al. (2017) Jonas Peters, Dominik Janzing, and Bernhard Scholkopf. _Elements of causal inference: foundations and learning algorithms_. The MIT Press, 2017.
* Sachs et al. (2005) Karen Sachs, Omar Perez, Dana Pe'er, Douglas A Lauffenburger, and Garry P Nolan. Causal protein-signaling networks derived from multiparameter single-cell data. _Science_, 308(5721):523-529, 2005.
* Sanchez-Romero et al. (2019) Ruben Sanchez-Romero, Joseph D Ramsey, Kun Zhang, Madelyn RK Glymour, Biwei Huang, and Clark Glymour. Estimating feedforward and feedback effective connections from fmri time series: Assessments of statistical methods. _Network Neuroscience_, 3(2):274-306, 2019.
* Scherrer et al. (2021) Nino Scherrer, Olexa Bilaniuk, Yashas Annadani, Anirudh Goyal, Patrick Schwab, Bernhard Scholkopf, Michael C Mozer, Yoshua Bengio, Stefan Bauer, and Nan Rosemary Ke. Learning neural causal models with active interventions. _arXiv preprint arXiv:2109.02429_, 2021.
* Scherrer et al. (2022) Nino Scherrer, Anirudh Goyal, Stefan Bauer, Yoshua Bengio, and Nan Rosemary Ke. On the generalization and adaption performance of causal models. _arXiv preprint arXiv:2206.04620_, 2022.
* Scutari (2010) Marco Scutari. Learning bayesian networks with the bnlearn r package. _Journal of Statistical Software_, 35(3):1-22, 2010. doi: 10.18637/jss.v035.i03. URL https://www.jstatsoft.org/index.php/jss/article/view/v035i03.
* Settles et al. (2007) Burr Settles, Mark Craven, and Soumya Ray. Multiple-instance active learning. In J. Platt, D. Koller, Y. Singer, and S. Roweis, editors, _Advances in Neural Information Processing Systems_, volume 20. Curran Associates, Inc., 2007. URL https://proceedings.neurips.cc/paper/2007/file/a1519de5b5d44b31a01de013b9b51a80-Paper.pdf.
* Shen et al. (2020) Xinpeng Shen, Sisi Ma, Prashanthi Vemuri, and Gyorgy Simon. Challenges and opportunities with causal discovery algorithms: application to alzheimer's pathophysiology. _Scientific reports_, 10(1):1-12, 2020.
* Spirtes et al. (2000a) P. Spirtes, C. Glymour, and R. Scheines. _Causation, Prediction, and Search_. MIT press, 2nd edition, 2000a.
* Spirtes et al. (2000b) Peter Spirtes, Clark N Glymour, Richard Scheines, David Heckerman, Christopher Meek, Gregory Cooper, and Thomas Richardson. _Causation, prediction, and search_. MIT press, 2000b.
* Squires et al. (2000) Chandler Squires, Sara Magliacane, Kristjan H. Greenewald, Dmitriy Katz, Murat Kocaoglu, and Karthikeyan Shanmugam. Active structure learning of causal dags via directed clique trees. In Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin, editors, _Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual_, 2020. URL https://proceedings.neurips.cc/paper/2020/hash/f57bd0a58e953e5c43cd4a4e5af46138-Abstract.html.
* Tigas et al. (2022) Panagiotis Tigas, Yashas Annadani, Andrew Jesson, Bernhard Scholkopf, Yarin Gal, and Stefan Bauer. Interventions, where and how? experimental design for causal models at scale, 2022. URL https://arxiv.org/abs/2203.02016.
* Togas et al. (2012)Simon Tong and Daphne Koller. Active learning for structure in bayesian networks. In Bernhard Nebel, editor, _Proceedings of the Seventeenth International Joint Conference on Artificial Intelligence, IJCAI 2001, Seattle, Washington, USA, August 4-10, 2001_, pages 863-869. Morgan Kaufmann, 2001. (Cited on page 1)
* Triantafillou et al. (2017) Sofia Triantafillou, Vincenzo Lagani, Christina Heinze-Deml, Angelika Schmidt, Jesper Tegner, and Ioannis Tsamardinos. Predicting causal relationships from biological data: Applying automated causal discovery on mass cytometry data of human immune cells. _Scientific Reports_, 7(1):12724, Oct 2017. ISSN 2045-2322. doi: 10.1038/s41598-017-08582-x. URL https://doi.org/10.1038/s41598-017-08582-x. (Cited on page 1)
* Tsamardinos et al. (2006) Ioannis Tsamardinos, Laura E. Brown, and Constantin F. Aliferis. The max-min hill-climbing bayesian network structure learning algorithm. _Machine Learning_, 65(1):31-78, Oct 2006. ISSN 1573-0565. doi: 10.1007/s10994-006-6889-7. URL https://doi.org/10.1007/s10994-006-6889-7.
* Wu et al. (2022) Ji Q. Wu, Nanda Horeweg, Marco de Bruyn, Remi A. Nout, Ina M. Jurgeniemk-Schulz, Ludy C. H. W. Lutgens, Jan J. Jobsen, Elzbieta M. van der Steen-Banasik, Hans W. Nijman, Vincent T. H. B. M. Smit, Tjalling Bosse, Carien L. Creutzberg, and Viktor H. Koelzer. Automated causal inference in application to randomized controlled clinical trials. _Nature Machine Intelligence_, 4(5):436-444, May 2022. ISSN 2522-5839. doi: 10.1038/s42256-022-00470-y. URL https://doi.org/10.1038/s42256-022-00470-y. (Cited on page 1)
* Zheng et al. (2018) Xun Zheng, Bryon Aragam, Pradeep K Ravikumar, and Eric P Xing. Dags with no tears: Continuous optimization for structure learning. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, _Advances in Neural Information Processing Systems_, volume 31. Curran Associates, Inc., 2018. URL https://proceedings.neurips.cc/paper/2018/file/e347c51419ffb23ca3fd5050202f9c3d-Paper.pdf. (Cited on page 19)

## Appendix A Convergence of causal discovery with Git

Suppose that we have some causal discovery algorithm \(\mathcal{A}\) which is guaranteed to converge to the true graph in the limit of infinite data. Here we investigate if such convergence property still holds if we extend \(\mathcal{A}\) with GIT.

Let us define \(\epsilon\)-greedy GIT as follows: every time we need to select an intervention target, we use GIT with probability \(1-\epsilon\), and otherwise, we choose randomly uniformly from all available targets.

**Proposition 1**.: _If the causal discovery algorithm \(\mathcal{A}\) is guaranteed to converge given an infinite amount of samples from each possible intervention target, then \(\mathcal{A}\) with \(\epsilon\)-greedy GIT is also guaranteed to converge._

Proof.: Since the \(\epsilon\)-exploration guarantees visiting every target infinitely many times in the limit, the proof follows from the asserted convergence of \(\mathcal{A}\). 

_Remark 2_.: ENCO with \(\epsilon\)-greedy GIT is guaranteed to converge to the true graph under the standard assumptions (Lippe et al., 2022, Appendix B.1).

_Remark 3_.: Proposition 1 is asymptotic and holds for arbitrary \(\epsilon>0\). However, in a finite setup, we can choose \(\epsilon\) small enough that \(\epsilon\)-GIT and GIT behave similarly. Our experiments show that GIT performs well (compared with other benchmarks) and is indistinguishable from an asymptotically convergent method.

## Appendix B Convergence conditions of ENCO framework with Git

### Preliminaries (ENCO recap)

In this section, we recall results from Lippe et al. (2022) for convergence of their causal discovery method ENCO. They formulate four theorems and a set of conditions that guarantee that the parameters of the structure converge to the true graph. For full proof and detailed explanation please refer to Appendix B in Lippe et al. (2022).

_Remark 4_.: ENCO identifies common conditions for correct convergence of directionality parameters. They go as follows (see theorems B.1, B.2, and appendix B.4 in ENCO):

1. For all possible sets of parents of \(X_{j}\) excluding \(X_{i}\), adding \(X_{i}\) improves the log-likelihood estimate of \(X_{j}\) under the intervention on \(X_{i}\), or leaves it unchanged. \[\forall\widehat{\text{pa}}(X_{j})\subseteq X_{-i,j}:\mathbb{E}_{I_{X_{i}}, \mathcal{X}}\left[\log p(X_{j}|\widehat{\text{pa}}(X_{j}),X_{i})-\log p(X_{j}| \widehat{\text{pa}}(X_{j}))\right]\geq 0\]
2. There exists a set of nodes \(\widehat{\text{pa}}(X_{j})\), for which the probability to be sampled as parents of \(X_{j}\) is greater than 0, and the following condition holds: \[\exists\widehat{\text{pa}}(X_{j})\subseteq X_{-i,j}:\mathbb{E}_{I_{X_{i}}, \mathcal{X}}\left[\log p(X_{j}|\widehat{\text{pa}}(X_{j}),X_{i})-\log p(X_{j}| \widehat{\text{pa}}(X_{j}))\right]>0\]
3. For all possible sets of parents of \(X_{i}\) excluding \(X_{j}\), adding \(X_{j}\) does not improves the log-likelihood estimate of \(X_{i}\) under the intervention on \(X_{j}\), or leaves it unchanged. \[\forall\widehat{\text{pa}}(X_{i})\subseteq X_{-i,j}:\mathbb{E}_{I_{X_{j}}, \mathcal{X}}\left[\log p(X_{i}|\widehat{\text{pa}}(X_{i}),X_{j})-\log p(X_{i} |\widehat{\text{pa}}(X_{i}))\right]\geq 0\] For at least one parent set \(\widehat{\text{pa}}(X_{i})\), which has a probability greater than zero to be sampled, this inequality is strictly smaller than zero.

_Remark 5_.: The following condition guarantees convergence of existence parameters (see theorem B.3 in ENCO):

\[\min_{\hat{\text{pa}}\subseteq\text{spa}_{i}(X_{j})}\mathbb{E}_{I\sim p_{I-j} (I)}\mathbb{E}_{\widehat{p}_{I}(\mathcal{X})}\big{[}\log p(X_{j}|\hat{\text{ pa}},X_{i})-\log p(X_{j}|\hat{\text{pa}})\big{]}>\lambda_{sparse}\]

where \(\text{spa}_{i}(X_{j})\) is a set of nodes excluding \(X_{i}\) which, according to the ground truth graph, could have an edge to \(X_{j}\) without introducing a cycle, \(p_{I_{-j}}(I)\) refers to the distribution over conducted interventions \(p_{I}(I)\) excluding the intervention on variable \(X_{j}\), and \(\lambda_{sparse}\) is a positive constant.

**Theorem 6**.: _(Theorem B.1 from Appendix B.4 in ENCO.) Consider the edge \(X_{i}\to X_{j}\) in the true causal graph. The orientation parameter \(\theta_{ij}\) converges to \(\sigma(\theta_{ij})=1\) if the conditions from remark 4 are fulfilled._

**Theorem 7**.: _(Theorem B.2 from Appendix B.4 in ENCO.) Consider a pair of variables \(X_{i}\), \(X_{j}\) for which \(X_{i}\) is an ancestor of \(X_{j}\) without direct edge in the true causal graph. Assume all edges that appear in the true graph have converged according to theorem 6. The orientation parameter \(\theta_{ij}\) converges to \(\sigma(\theta_{ij})=1\) if the conditions from remark 4 are fulfilled._

By Appendix B.4 from ENCO, Theorems 6, 7 hold regardless of whether we collected interventional data from node \(X_{i}\) or \(X_{j}\).

**Theorem 8**.: _Consider an edge \(X_{i}\to X_{j}\) in the true causal graph. The parameter \(\gamma_{ij}\) converges to \(\sigma(\gamma_{ij})=1\) if the condition from remark 5 holds._

**Theorem 9**.: _Assume for all edges \(X_{i}\to X_{j}\) in the true causal graph, \(\sigma(\theta_{ij})\) and \(\sigma(\gamma_{ij})\) have converged to one. Then, the likelihood of all other edges, i.e. \(\sigma(\theta_{lk})\cdot\sigma(\gamma_{lk})\) will converge to zero under the condition that \(\lambda_{\text{sparse}}>0\)._

### Git-privileged proof

We follow with proof of ENCO convergence with the GIT-privileged acquisition method under the same set of conditions from remarks 4, 5. We show that GIT-privileged collects interventional data as long as is needed for the orientation parameters to converge according to theorems 6 and 7. Then theorems 8 and 9 can be applied to show that the algorithm reached convergence.

AssumptionWe assume that in all local minima of our loss function, the existence parameters take extreme values: \(\forall_{i,j}\ \sigma(\gamma_{ij})\in\{0,1\}\), thus, when sufficient time for optimization is given, they stop contributing to the score. Hence in our analysis, we focus on describing only the behavior of orientation parameter gradients.

The proof is structured as follows:

1. We show that following GIT-privileged score allows collecting enough interventional data to direct all edges that appear in the true graph correctly, see proposition 12.
2. Then we show that, if required, additional interventional data that allows directing other edges according to theorem 7 will be collected, see proposition 13.
3. Finally, theorems 8 and 9 can be applied to show that we learned the correct graph, see proposition 14.

**Proposition 10**.: _Consider the edge \(X_{i}\to X_{j}\) in the true causal graph. The parameter \(\gamma_{ij}\) converges to \(\sigma(\gamma_{ij})=1\) under any set of interventions \(p_{I}(I)\) if_

\[\min_{\hat{p}\in\mathcal{V}_{-i}}\mathbb{E}_{\hat{I}\sim p_{I-j}(I)}\mathbb{ E}_{\hat{p}_{\hat{I}}(\bm{X})}\big{[}\log p(X_{j}|\hat{p}\hat{a},X_{i})-\log p(X_{j}|\hat{p} \hat{a})\big{]}>\lambda_{sparse}\]

_where \(\mathcal{V}_{-i}\) is the set of all nodes excluding \(X_{i}\), and \(p_{I_{-j}}(I)\) refers to the distribution over conducted interventions \(p_{I}(I)\) excluding the intervention on variable \(X_{j}\)._

Proof.: The condition guarantees that the gradient of \(\gamma_{ij}\) is positive. 

**Proposition 11**.: _Consider the edge \(X_{i}\to X_{j}\) in the true causal graph. When conditions from remark 4 are fulfilled \(\|\nabla_{\theta_{ij}}L_{\text{graph}}(X_{I_{i}})\|=\|\nabla_{\theta_{ij}}L_{ \text{graph}}(X_{I_{i}})\|=\|\nabla_{\theta_{ij}}L_{\text{graph}}(X_{I_{j}})\| =\|\nabla_{\theta_{ij}}L_{\text{graph}}(X_{I_{j}})\|=0\) and the edge converged to its true value if and only if we acquired interventional data from \(X_{i}\) or \(X_{j}\)._

Proof.: First, recall that ENCO does not update orientation parameters unless the interventional data was acquired from a neighboring node. Therefore, the gradient can only be zero before the intervention if the existence parameters converge to zero. This situation is guaranteed not to happen by proposition 10.

Second, when interventional data is acquired, based on the theorem 6, we know that the edge converges to its true value.

**Proposition 12**.: _Choosing intervention targets with GIT-privileged score allows collecting enough data to direct all edges that appear in the true graph properly if the following is true:_

* _For any pair of variables_ \(X_{i}\)_,_ \(X_{j}\) _without a direct edge in the true causal graph, when conditions from remark_ 4 _are fulfilled, and we acquired interventional data from either_ \(X_{i}\) _or_ \(X_{j}\)_, and sufficient time for the optimization process is given, then the orientation parameters will converge to extreme values_ \(\sigma(\theta_{ij})\)_,_ \(\sigma(\theta_{ji})\in\{0,1\}\) _or the existence parameters will converge to_ \(\sigma(\gamma_{ij})=\sigma(\gamma_{ji})=0\)_._

Proof.: The assumption and proposition 11 imply that after collecting interventional data from a node, edges that are connected to this node will not contribute to the score anymore. Thus we will not intervene on the same node twice. On the other hand, proposition 11 guarantees the score of edges that appear in the true graph will be positive until they are directed. 

**Proposition 13**.: _Consider a pair of variables \(X_{i}\), \(X_{j}\) for which \(X_{i}\) is an ancestor of \(X_{j}\) without a direct edge in the true causal graph. Assume all edges that appear in the true graph has converged according to theorem 6. When conditions from remark 4 are fulfilled, and if \(\|\nabla_{\theta_{ij}}L_{\text{graph}}(X_{I_{i}})\|=\|\nabla_{\theta_{ji}}L_{ \text{graph}}(X_{I_{i}})\|=\|\nabla_{\theta_{ij}}L_{\text{graph}}(X_{I_{j}}) \|=\|\nabla_{\theta_{ji}}L_{\text{graph}}(X_{I_{j}})\|=0\) then the edge converged as described in theorem 7 or its existence parameters converged to 0._

Proof.: To zero out the gradient either orientation or existence parameters had to converge. If the orientation parameters converged we had to collect interventional data from a neighboring node (because otherwise, ENCO does not update parameters). Thus, based on the theorem 7, we know that the edge converged to its true value. 

**Proposition 14**.: _Given sufficient acquisition rounds and time for optimization ENCO with GIT-privileged intervention acquisition method will recover the true graph._

Proof.: From propositions 12, 13 we have that GIT-privileged will collect interventional data from new nodes until edges that appear in the true graph are correctly directed and edges between pairs of variables \(X_{i}\), \(X_{j}\) without a direct edge in the true causal graph either disappear from the model or are directed according to theorem 7. By theorems 8, 9 we conclude that we indeed acquired enough interventional data to converge to the correct graph.

### Git convergence

**Proposition 15**.: _Given sufficient acquisition rounds and time for optimization ENCO with GIT intervention acquisition method will recover the true graph if the following is true:_

* _For any graph_ \(G\) _sampled from the structural belief_ \(\mathbb{P}_{\rho}(\cdot)\) _(recall equation_ 5_) during GIT score estimation, the theorems and propositions from sections_ B.1 _and_ B.2 _hold when we use_ \(G\) _instead of the true graph and compute gradient using data from the sampled model_ \(\mathbb{P}_{G,\phi,i}(X)\) _(recall equation_ 6_)._

Proof.: First, note that thanks to proposition 10, if there is an edge \(X_{i}\to X_{j}\) in the true graph there exists a model, that can be sampled from the belief with non-zero probability, in which this edge appears.

For each undirected edge \(X_{i}\to X_{j}\) in the structural belief for which the existence parameter converged to \(\sigma(\theta_{ij})=1\), there exists a model (with a positive probability to be sampled), that will yield a gradient of positive magnitude if and only if there is no interventional data acquired from the node connected to it. This model contains the edge \(X_{i}\to X_{j}\), thus by the assumption made above and proposition 11, it will yield a positive gradient. In consequence, expectation over all possible models, when the edge is not yet directed, will yield a positive score.

Note that, when interventional data from \(X_{i}\) or \(X_{j}\) is acquired, the edge \(X_{i}\to X_{j}\) is directed and it does not yield a gradient of positive magnitude under data sampled from \(\mathbb{P}_{G,\phi,i}(X)\) for any \(G\sim\mathbb{P}_{\rho}(\cdot)\). This stems from the fact that the gradient term zeroes out when parameter \(\sigma(\theta_{ij})\) takes extreme values (0 or 1).

Hence, \(\mathtt{GIT}\) score will allow to sequentially "eliminate" undirected edges. Since to update our structural policy \(\mathbb{P}_{\rho}(\cdot)\) we use interventional data sampled from the true graph when all edges are directed, we are guaranteed (by B.2 section) that they are directed according to theorems 6, 7. Then the same argument as for \(\mathtt{GIT}\)-privileged can be applied to show that we converged to the true graph. 

## Appendix C Details about Employed Causal Discovery Frameworks

### Enco

We extend the description of the ENCO framework (Lippe et al., 2022) from Section 4.1.

Structural Parameters.ENCO learns a distribution over the graph structures by associating with each edge \((i,j)\), for which \(i\neq j\), a probability \(p_{i,j}=\sigma(\gamma_{i,j})\sigma(\theta_{i,j})\). Intuitively, the \(\gamma_{i,j}\) parameter represents the existence of the edge, while \(\theta_{i,j}=-\theta_{j,i}\) is associated with the direction of the edge. The parameters \(\gamma_{i,j}\) and \(\theta_{i,j}\) are updated in the graph fitting stage.

Distribution Fitting Stage.The goal of the distribution fitting stage is to learn the conditional probabilities \(P(X_{i}|PA_{(i,C)})\) for each variable \(X_{i}\) given a graph represented by an adjacency matrix \(C\), sampled from \(C_{i,j}\sim\ Bernoulli(p_{i,j})\). Note that self-loops are not allowed and thus \(p_{i,i}=0\). The conditionals are modeled by neural networks \(f_{\phi_{i}}\) with an input dropout-mask defined by the adjacency matrix. In consequence, the negative log-probability of a variable can be expressed as \(L_{C}(X_{i})=-\log f_{\phi_{i}}(PA_{(i,C)})(X_{i})\), where \(PA_{(i,C)}\) is obtained by computing \(C_{.,i}\odot X\), with \(\odot\) denoting the element-wise multiplication. The optimization objective for this stage is defined as minimizing the negative log-likelihood (NLL) of the observational data over the masks \(C_{.,i}\). Under the assumption that the distributions satisfy the Markov factorization property defined in Equation 1, the NLL can be expressed as:

\[L_{D}=\mathbb{E}_{X}\mathbb{E}_{C}[\sum_{i=1}^{n}L_{C}(X_{i})].\] (11)

Graph Fitting Stage and Implementation of Interventions.The graph fitting stage updates the structural parameters \(\theta\) and \(\gamma\) defining the graph distribution. After selecting an intervention target \(I\), ENCO samples the data from the postinterventional distribution \(\widetilde{P}_{I}\). In experiments, in the current paper, where the variables are assumed to be categorical the intervention is implemented by changing the target node's conditional to uniform over the set of node's categories. As the loss, ENCO uses the graph strcuture loss \(L_{graph}\) defined in Equation 7 in the main text plus a regularization term \(\lambda L_{\gamma,\theta}^{sparse}\) that influences the sparsity of the generated adjacency matrices, where \(\lambda\) is the regularization strength.

Gradients Estimators.In order to update the structural parameters \(\gamma\) and \(\theta\) ENCO uses REINFORCE-inspired gradient estimators. For each parameter \(\gamma_{i,j}\) the gradient is defined as:

\[\frac{\partial L_{G}}{\partial\gamma_{i,j}}=\sigma^{\prime}( \gamma_{i,j})\sigma(\theta_{i,j})\cdot\] (12) \[\cdot\mathbb{E}_{\mathbf{X},C_{-ij}}[L_{X_{i}\to X_{j}}(X_{j})-L_{X_{i} \neq X_{j}}(X_{j})+\lambda],\]

where \(\mathbb{E}_{\mathbf{X},C_{-ij}}\) denotes all of the three expectations in Equation 7 (in the main text), but excluding the edge \((i,j)\) from \(C\). The term \(L_{X_{i}\neq X_{j}}(X_{j})\) describes the negative log-likelihood of the variable \(X_{j}\) under the adjacency matrix \(C_{-ij}\), while \(L_{X_{i}\to X_{j}}(X_{j})\) is the negative log-likelihood computed by including the edge \((i,j)\) in \(C_{-ij}\). For parameters \(\theta_{i,j}\) the gradient is defined as:

\[\frac{\partial L_{G}}{\partial\theta_{i,j}}=\sigma^{\prime}( \theta_{i,j})\cdot\] \[\cdot\big{(}p(I_{i})\sigma(\gamma_{i,j})\mathbb{E}_{I_{i}, \mathbf{X},C_{-ij}}[L_{X_{i}\to X_{j}}(X_{j})-L_{X_{i}\neq X_{j}}(X_{j})]-\] \[p(I_{j})\sigma(\gamma_{j,i})\mathbb{E}_{I_{j},\mathbf{X},C_{-ij }}[L_{X_{j}\to X_{i}}(X_{i})-L_{X_{j}\neq X_{i}}(X_{i})]\big{)},\] (13)

where \(p(I_{i})\) is the probability of intervening on node \(i\) (usually uniform) and \(\mathbb{E}_{I_{i},\mathbf{X},C_{-ij}}\) is the same expectation as \(\mathbb{E}_{\mathbf{X},C_{-ij}}\) but under the intervention on node \(i\).

### DiBs

DiBS (Lorch et al., 2021) is a Bayesian structure learning framework which performs posterior inference over graphs with gradient based variational inference. This is achieved by parameterising the belief about the presence of an edge between any two nodes with corresponding learnable node embeddings. This turns the problem of discrete inference over graph structures to inference over node embeddings, which are continuous, thereby opening up the possibility to use gradient based inference techniques. In order to restrict the space of distributions to DAGs, NOTEARS constraint (Zheng et al., 2018) which enforces acyclicity is introduced as a prior through a Gibbs distribution.

Formally, for any two nodes \((i,j)\), the belief about the presence of the edge from \(i\) to \(j\) is parameterised as:

\[p(g_{ij}\mid u_{i},v_{j})=\frac{1}{1+\exp(-\alpha(u_{i}^{T}v_{j}))}\] (14)

Here, \(g_{ij}\) is the random variable corresponding to the presence of an edge between \(i\) to \(j\), \(\alpha\) is a tunable hyperparameter and \(u_{i},v_{j}\in\mathbb{R}^{k}\) are embeddings corresponding to node \(i\) and \(j\). The entire set of learnable embeddings, i.e. \(\mathbf{U}=\{u_{i}\}_{i=1}^{d}\), \(\mathbf{V}=\{v_{i}\}_{i=1}^{d}\) and \(\mathbf{Z}=[\mathbf{U},\mathbf{V}]\in\mathbb{R}^{2\times d\times k}\) form the latent variables for which posterior inference needs to be performed. Such a posterior can then be used to perform Bayesian model averaging over corresponding posterior over graph structures they induce.

DiBS uses a variational inference framework and learns the posterior over the latent variables \(\mathbf{Z}\) using SVGD (Liu and Wang, 2016). SVGD uses a set of particles for each embedding \(u_{i}\) and \(v_{j}\), which form an empirical approximation of the posterior. These particles are then updated based on the gradient from Evidence Lower Bound (ELBO) of the corresponding variational inference problem, and a term which enforces diversity of the particles using kernels. The prior over the latent variable \(\mathbf{Z}\) is given by a Gibbs distribution with temperature \(\beta\) which enforces soft-acyclicty constraint:

\[p(\mathbf{Z})\propto\exp(-\beta\mathbb{E}_{p(\mathbf{G}|\mathbf{Z})}\left[h( \mathbf{G})\right])\prod_{ij}\mathcal{N}(z_{ij};0,\sigma_{z}^{2})\] (15)

Here, \(h\) is the DAG constraint function given by NOTEARS (Zheng et al., 2018).

## Appendix D Details about Intervention Targeting Methods

In this section we briefly introduce other intervention acquisition methods used for comaprison in this work.

Active Intervention Targeting (AIT)Assume that the structural graph distribution maintained by the causal discovery algorithm can be described by some parameters \(\rho\). Consider a set of graphs \(\mathcal{G}=\{\mathcal{G}_{j}\}\) sampled from this distribution. AIT assigns to each possible intervention target \(i\in V\) a discrepancy score that is computed by measuring the variance between the graphs (\(VBG\)) and variance within the graphs (\(VWG\)). The \(VBG_{i}\) for intervention \(i\) is defined as:

\[VBG_{i}=\sum_{j}\langle\mu_{j,i}-\bar{\mu_{i}},\mu_{j,i}-\bar{\mu_{i}}\rangle,\] (16)

where \(\mu_{j,i}\) is the mean of all samples drawn from graph \(\mathcal{G}_{j}\) under the intervention on target \(i\), and \(\mu_{i}\) is the mean of all samples drawn from graphs under intervention on target \(i\). The variance within graphs is described by:

\[VWG_{i}=\sum_{j}\sum_{k}\langle[S_{j,i}]_{k}-\mu_{j,i},[S_{j,i}]_{k}-\mu_{j,i}\rangle,\] (17)

where \([S_{j,i}]_{k}\) is the \(k\)-th sample from graph \(\mathcal{G}_{j}\) under the intervention on target \(i\). The AIT score is then defined as the ratio \(D_{i}=\frac{VBG_{i}}{VWG_{i}}\). The method selects then the intervention attaining the highest score \(D_{i}\).

CBED TargetingBayesian Optimal Experimental Design for Causal Discovery (BOECD) selects the intervention with the highest information gain obtained about the graph belief after observing theinterventional data. Let the tuple \((j,v)\) define the intervention, where \(j\in V\) describes the intervention target, and \(v\) represents the change in the conditional distribution of variable \(X_{j}\). Specifically, this means that the new conditional distribution of \(X_{j}\) is a distribution with point mass concentrated on \(v\). Moreover, let \(Y_{(j,v)}\) denote the interventional distribution under the intervention \((j,v)\), and let \(\psi\) denote the current belief about the graph structure (i.e. the random variable corresponding to the structural and distributional parameters \(\psi=(\rho,\phi)\)). BOECD selects the intervention that maximizes (Tigas et al., 2022):

\[(j^{*},v^{*})=\operatorname*{arg\,max}_{(j,v)}I(Y_{(j,v)};\psi\mid\mathcal{D }),\] (18)

where \(\mathcal{D}\) are the observational data. The above formulation necessities the use of an MI estimator. One possible choice is a BALD-inspired estimator Tigas et al. (2022); Houlsby et al. (2011):

\[I(Y_{(j,v)};\psi\mid\mathcal{D})=H(Y_{(j,v)}\mid\mathcal{D})-H(Y_{(j,v)};\phi \mid\mathcal{D}),\] (19)

with \(H(\cdot;\cdot)\) denoting the cross-entropy. Note that this approach allows to select not only most informative target, but also the value of the intervention.

## Appendix E Additional Experimental Details

### Synthetic Graphs Details

The synthetic graph structure is deterministic and is specified by the name of graph (chain, collider, jungle, fulldag), except for random, where the structure is sampled. Following ENCO (Lippe et al., 2022), we set the only parameter of sampling procedure, edge_prob, to \(0.3\).

The ground truth conditional distributions of the causal graphs are modeled by randomly initialized MLPs. Additionally, a randomly initialized embedding layer is applied at the input to each MLP that converts categorical values to real vectors. We used the code provided by Lippe et al. (2022). For more detailed explanation, refer to Lippe et al. (2022, Appendix C.1.1).

### ENCO Hyperparameters

For experiments on ENCO framework we used exactly the same parameters as reported by Lippe et al. (2022, Appendix C.1.1). We provide them in Table 3 for the completeness of our report.

### DiBS Hyperparameters

In Table 4, we present hyperparameters used for the DiBS framework.

### Computational Cost

We used two hardware settings, one with GPU: a single Nvidia A100, and another one with CPUs: 12 cores of Intel Xeon E5-2697 processor. In our synthetic graph experiments with ENCO on GPU, a

\begin{table}
\begin{tabular}{l c} \hline \hline parameter & value \\ \hline Sparsity regularizer \(\lambda_{sparse}\) & \(4\times 10^{-3}\) \\ Distribution model & 2 layers, hidden size 64, LeakyReLU(\(\alpha=0.1\)) \\ Batch size & 128 \\ Learning rate - model & \(5\times 10^{-3}\) \\ Weight decay - model & \(1\times 10^{-4}\) \\ Distribution fitting iterations F & \(1000\) \\ Graph fitting iterations G & \(100\) \\ Graph samples K & 100 \\ Epochs & 30 \\ Learning rate - \(\gamma\) & \(2\times 10^{-2}\) \\ Learning rate - \(\theta\) & \(1\times 10^{-1}\) \\ \hline \hline \end{tabular}
\end{table}
Table 3: Hyperparameters used for the ENCO framework.

single experiment takes on average 4 h to run, with 57 min being used by GIT to make its decisions; the rest is devoted to the underlying causal discovery algorithm (in this case, ENCO). In the case of the CPU setup, an experiment takes on average 126 h, with the GIT part taking up only 6 h. We estimate the project's overall cost to be around 50K GPUh and 2M CPUh.

## Appendix F Additional Experimental Results

### Experiments in DiBS Framework

Experimental setupThe experimental setup closely follows the one from Tigas et al. (2022). In the experiments, 10 batches of 10 data-points each are acquired. Each batch can contain various intervention targets. The acquisition method chooses intervention targets and values. For some of the methods, the GP-UCB strategy is used to select a value for a given intervention; see Tigas et al. (2022) for details. For every method, we run 40 random seeds. We compare the following methods:

* **Soft Git (ours)**: gradient magnitudes corresponding to different interventions are normalized by the maximum one, then passed to the softmax function (with temperature \(1\)). Obtained scores are used as probabilities to sample a given intervention in the current batch. GP-UCB is used for value selection.
* **Random (fixed values)**: Intervention targets are chosen uniformly randomly. The intervention value is fixed at \(0\).
* **Random (uniform values)**: Intervention targets are chosen uniformly randomly. The intervention value is chosen uniformly randomly from the variable support.
* **Soft AIT**: Intervention targets are chosen from the softmax probabilities of AIT scores (Scherrer et al., 2021), with the temperature \(2\). GP-UCB is used for value selection.
* **Soft CBED**: Intervention targets are chosen from the softmax probabilities of CBED scores (Tigas et al., 2022), with the temperature \(0.2\). GP-UCB is used for value selection.

The results are presented in Figure 6. We can see the performance of Soft Git is comparable to that of Random (uniform values) in both considered graph classes. Soft AIT and Soft CBED behave similarly for Erdos-Renyi graphs, while for Scale-Free they seem to bring a small improvement.

### Performance in ENCO Framework - All Results

#### f.2.1 Ranking Statistics

We present ranking statistics in Tables 5, 6, 7.

#### f.2.2 AUSHD Tables

We present all AUSHD results with confidence intervals in Tables 8, 9.

\begin{table}
\begin{tabular}{l c} \hline \hline parameter & value \\ \hline Number of particles & \(20\) \\ Number of particle updates & \(20\,000\) \\ Choice of Kernel & \(k([\mathbf{Z},\Theta],[\mathbf{Z}^{\prime},\Theta^{\prime}])=\sigma_{\mathbf{Z }}\exp(-\frac{1}{h_{\mathbf{Z}}}||\mathbf{Z}-\mathbf{Z}^{\prime}||_{F}^{2})+ \sigma_{\Theta}\exp(-\frac{1}{h_{\Theta}}||\Theta-\Theta^{\prime}||_{F}^{2})\) \\ \(h_{\Theta}\) & \(500\) \\ \(\sigma_{\mathbf{Z}}\) & \(1\) \\ \(\sigma_{\Theta}\) & \(1\) \\ Optimizer & RMSProp \\ Learning rate Optimizer & \(0.005\) \\ \hline \hline \end{tabular}
\end{table}
Table 4: Hyperparameters used for the DiBS framework.

#### f.2.3 SHD Tables

We present SHD results for small and large data regime with confidence intervals in Tables 10, 11.

#### f.2.4 ENCO - Training Curves

We provide SHD training curves for main experiments in Figures 7 and 8.

\begin{table}
\begin{tabular}{l l l l l l} \hline \hline  & AIT & CBED & Random & GIT (ours) & priv. GIT \\ \hline Best & 1 (0 + 1) & 1 (0 + 1) & 2 (1 + 1) & 1 (1 + 0) & 3 (1 + 2) \\ Best or comparable & 10 (4 + 6) & 7 (4 + 3) & 22 (12 + 10) & 17 (10 + 7) & 24 (12 + 12) \\ \hline \hline \end{tabular}
\end{table}
Table 7: For each method we show its pairwise performance against other methods (whether it is better, comparable, or worse) based on 90% confidence intervals for AUSHD, across two data regimes (\(N=1056\) and \(N=3200\)) and all twelve graphs (hence for each method there are \(2\times 12\times 4=96\) pairs to consider). Each entry shows the total count, broken down into two data regimes, \(N=1056\) and \(N=3200\) resp., presented in the parenthesis.

\begin{table}
\begin{tabular}{l l l l l} \hline \hline  & Better & Comparable & Worse \\ \hline AIT & 9 (3+6) & 27 (11+16) & 60 (34+26) \\ CBED & 9 (7+2) & 35 (20+15) & 52 (21+31) \\ Random & 34 (13+21) & 36 (21+15) & 26 (14+12) \\ GIT (ours) & 45 (24+21) & 35 (21+14) & 16 (3+13) \\ GIT-privileged & 57 (25+32) & 39 (23+16) & 0 (0+0) \\ \hline \hline \end{tabular}
\end{table}
Table 8: For each method we show its pairwise performance against other methods (whether it is better, comparable, or worse) based on 90% confidence intervals for AUSHD, across two data regimes (\(N=1056\) and \(N=3200\)) and all twelve graphs (hence for each method there are \(2\times 12\times 4=96\) pairs to consider). Each entry shows the total count, broken down into two data regimes, \(N=1056\) and \(N=3200\) resp., presented in the parenthesis.

Figure 6: Expected SHD metric for different acquisition methods on top of the DiBS framework, for graphs with 50 nodes and two different graph classes: Erdos-Renyi and Scale-Free. 95% bootstrap confidence intervals are shown.

\begin{table}
\begin{tabular}{l l l l l} \hline \hline  & AIT & CBED & Random & GIT (ours) & GIT-privileged \\ \hline Best & 0 (0 + 0) & 0 (0 + 0) & 2 (0 + 2) & 8 (4 + 4) & 5 (1 + 4) \\ Best or comparable & 6 (2 + 4) & 6 (4 + 2) & 12 (5 + 7) & 18 (11 + 7) & 24 (12 + 12) \\ \hline \hline \end{tabular}
\end{table}
Table 5: We count the number of training setups (24), where a given method was best or at least comparable to other methods (AIT, CBED, and Random; GIT-privileged was not compared against), basing on 90% confidence intervals for AUSHD. Each entry shows the total count, broken down into two data regimes, \(N=1056\) and \(N=3200\) resp., presented in the parenthesis.

[MISSING_PAGE_FAIL:23]

### ENCO - Large Synthetic Graphs

In order to study the scalability of our method, we perform an additional evulation on selected synthetic graphs in which we increase the number of nodes to \(100\). We comapre the performance of different acquisition methods used with ENCO in Figure 11. We observe that GIT exhibits very good results, converging to lower SHD values with significantly less acquistion steps compared to all the other methods. This confirms the superiority of GIT, even within a larger graph regime.

### ENCO - Correlation Scores

In Figure 12, we present the correlation of scores of the tested targeting methods. Importantly, the high correlation of GIT and GIT-privileged supports the hypothesis that imaginary gradients are a credible proxy of the true gradients and thus validates GIT. Otherwise, correlations are relatively small, suggesting that the studied methods use different decision mechanisms. Understanding this phenomenon is an interesting future research direction.

Below, we provide more details about computing the correlations. Let us denote by \(s^{m}_{b,i}\) the score produced by method \(m\) for the batch \(b\) and the node \(i\). In order to eliminate effects such as changing

\begin{table}
\begin{tabular}{l l l l l l l} \hline \hline  & & AIT & CBED & Random & GIT (ours) & priv. GIT \\ \hline alarm & 1056 & 35.76 (34.04, 37.52) & 28.44 (26.68, 30.16) & 26.0 (24.71, 27.29) & 19.84 (19.0, 20.68) & 25.0 (23.2, 27.0) \\  & 3200 & 26.15 (24.15, 28.22) & 24.33 (21.67, 27.20) & 16.0 (14.57, 17.14) & 20.0 (18.67, 21.33) & 15.2 (14.6, 15.8) \\ asia & 1056 & 2.0 (1.2, 2.68) & 1.96 (1.44, 2.4) & 0.96 (0.8, 1.12) & 1.2 (1.0, 1.36) & 1.2 (0.8, 1.4) \\  & 3200 & 1.56 (1.12, 1.92) & 1.28 (1.0, 1.48) & 0.88 (0.79, 1.0) & 1.12 (0.96, 1.24) & 0.8 (0.6, 1.2) \\ cancer & 1056 & 1.72 (1.48, 2.0) & 2.2 (2.0, 2.4) & 2.28 (2.04, 2.48) & 2.12 (1.84, 2.4) & 2.2 (1.8, 2.4) \\  & 3200 & 1.8 (1.6, 2.0) & 1.96 (1.72, 2.2) & 1.84 (1.6, 2.12) & 2.0 (1.76, 2.24) & 2.4 (2.0, 2.8) \\ child & 1056 & 7.32 (5.92, 8.68) & 6.36 (5.52, 1.76) & 3.52 (2.84, 4.2) & 3.72 (2.4, 2.42) & 2.8 (1.4, 4.4) \\  & 3200 & 3.2 (2.56, 3.8) & 4.68 (3.5, 5.48) & 1.04 (0.7, 1.35) & 2.16 (1.8, 2.52) & 1.8 (0.4, 3.0) \\ earthquake & 1056 & 0.12 (0.0, 0.2) & 0.12 (0.0, 0.2) & 0.0 (0.0, 0.0) & 0.24 (0.08, 0.36) & 0.0 (0.0, 0.0) \\  & 3200 & 0.04 (0.04, 0.08) & 0.0 (0.0, 0.0) & 0.0 (0.0, 0.0) & 0.2 (0.08, 0.32) & 0.0 (0.0, 0.0) \\ sachs & 1056 & 0.84 (0.08, 1.0) & 1.28 (0.96, 1.6) & 0.6 (0.4, 0.8) & 0.52 (0.32, 0.72) & 0.4 (0.0, 0.8) \\  & 3200 & 0.48 (0.32, 0.64) & 1.48 (1.16, 1.76) & 0.24 (0.08, 0.36) & 0.48 (0.28, 0.68) & 0.0 (0.0, 0.0) \\ \hline \hline \end{tabular}
\end{table}
Table 11: SHD with 90% confidence intervals (in the parenthesis), for real-world data and for low and regular data regimes (\(N=1056\) and \(N=3200\) resp.).

Figure 7: Expected SHD metric for different acquisition methods on top of the ENCO framework, for synthetic graphs with 25 nodes. 95% bootstrap confidence intervals are shown.

scores scales during the discovery process, we normalize the scores as \(\bar{s}^{m}_{b,i}:=\frac{s^{m}_{b,i}}{\sum_{j=1}^{N}s^{m}_{b,j}}\). For every pair of methods \(m\), \(m^{\prime}\) and node \(i\), we compute Spearman's rank correlation score \(r_{s}(\bar{s}^{m}_{i,i},\bar{s}^{m^{\prime}}_{i,i})\). We average over the nodes to get the scalar correlation value \(\text{corr}(m,m^{\prime}):=\frac{\sum_{i=1}^{N}r_{s}(z^{m}_{i,i},\bar{s}^{m^{ \prime}}_{i,i})}{N}\).

In addition, we present Pearson's correlations in Figure 13. Conclusions from the analysis of the Spearman's rank correlation hold; in particular, the correlation between GIT and GIT-privileged is high.

Figure 8: Expected SHD metric for different acquisition methods on top of the ENCO framework, for graphs from BnLearn dataset. 95% bootstrap confidence intervals are shown.

Figure 9: Expected SHD metric for GIT with an interventional batch size of 1024 samples. 95% bootstrap confidence intervals are shown, and results were computed using 3 random seeds.

### ENCO - Intervention Targets Distribution

In this section, we provide additional histograms and plots with regard to the interventional target distributions obtained by different intervention methods as discussed in Section 5.4 in the main text.

In Figure 14, we present the histograms of the target distributions for the real graphs for each of the intervention acquisition methods. Note that those histograms represent the same information as the node coloring in Figure 4. It may be observed that the distributions obtained by GIT concentrate on fewer nodes than those obtained by the AIT and CBED approaches. The only exceptions being the

Figure 11: Expected SHD metric for different acquisition methods on top of the ENCO framework, for synthetic graphs with \(100\) nodes. 95% bootstrap confidence intervals are shown.

Figure 10: Expected SHD metric for GIT with different numbers of graphs samples used to estimate score for interventions (see line 2 in Algorithm 2). 95% bootstrap confidence intervals are shown, results were computed using 10 random seeds.

sachs and child datasets, for which the entropy of CBED approach is smaller (recall Figure 4). Note, however, that CBED underperforms on those graphs (recall Figure 3 in the main text or see Figure 8). This is in contrast to GIT, which maintains good performance.

Finally, in Figure 15, we present the interventional target distribution on the alarm graph. We observe that each method intervenes on at least one node incident to the critical edges in the Markov

Figure 14: The histograms of chosen interventional targets in all data acquisition steps for different strategies computed on the real-world data.

Figure 12: Spearman’s rank correlation of the scores produced by different acquisition methods, averaged over nodes.

Figure 13: Pearson correlation of the scores produced by different acquisition methods, averaged over nodes. We can see similar trends as in the case of Spearman’s rank correlation, in particular, a high correlation of GIT and GIT-privileged.

Equivalence Class (as indicated by the green color in the plot). However, both AIT and CBED struggle to achieve convergence and suffer low performance, as can be observed in Figure 8.

#### f.7.1 ENCO - Obtained Synthetic Graphs

In addition, we present the results obtained for the synthetic graphs in Figure 16 and the corresponding histograms in Figure 17. Note that in this case the results are also averaged by different ground truth distributions, which means that any regularities in selecting the nodes come rather from the graph structure than from data distribution.

Figure 16: The interventional target distributions obtained by different strategies on synthetic data. The probability is represented by the intensity of the node’s color. For clarity of the presentation, we choose not to color the critical edges in the corresponding Markov Equivalence Classes. This is because _all_ edges of all the presented graphs would need to be colored. The only exception is the collider graph, which is alone in its Markov Equivalence Class.

Figure 15: The interventional target distribution for the alarm graph. The green color represents the edges for which there exists a graph in the Markov Equivalence Class that has the corresponding connection reversed. Black color is used to indicate node for each no data is collected. We may observe that each method intervenes on at least one node incident to the critical edges. However, both AIT and CBED do not converge for this dataset and struggle to achieve good results.

Interestingly, we may observe that for the jungle and chain graphs GIT often intervenes on the nodes which are the first ones in the topological order (as indicated by low node numbers in the plots). This is again intuitive, as intervening on those nodes can impact more variables lower in the hierarchy. In addition, note that for the chain graph, knowing its Markov Equivalence Class and setting the directionality of an edge automatically makes it possible to determine the directionality of edges for all subsequent nodes in the topological order. Hence intervening on the nodes which are the first ones in the ordering may convey more information and is desired.

We may also observe that the CBED seems to focus only on the first nodes in the topological order, despite the data distribution, which in some graphs (as the chain graph) may be desired, but in others seems to be an oversimplified solution. Note that CBED often struggles to converge - this may be observed in Figure 7.

#### f.7.2 Discussion on Small Real-World Graphs

We provide a more detailed discussion on the differences between the earthquake and cancer graph distributions and the way it affects the GIT method.

Consider Figure 4 in the main text. Note that the middle node in the earthquake graph corresponds to setting off a burglary alarm, an event very unlikely to happen in observational data but which, when occurs, triggers a change in the distributions of the nodes lower in the hierarchy (see the conditional distributions in Table 12). The chance of starting an alarm is also very high in case a burglary has happened (the left-most node in the graph). Hence the GIT concentrates on those two nodes as they have the largest impact on the entailed distribution.

A similar situation can be observed for the cancer graph, where the middle node corresponds to a binary variable indicating the probability of developing the illness. Even though the two parents of the cancer variable (pollution and smoke, represented by nodes 0 and 1, respectively) share a causal relationship with cancer, their impact on the cancer variable is limited. In other words, the chances of developing cancer, no matter whether being subject to high or low pollution or being a smoker or not, remain rather small (see the conditional distributions for cancer variable in Table 13). Hence, the only way in which one can gather more information about the impact of having cancer on the distributions of its child variables (nodes 3 and 4) is by performing an intervention. In consequence, it may be observed that GIT prefers to select nodes that allow to gather data that otherwise would be hard to acquire in the purely observational setting.

Figure 17: The histograms of chosen interventional targets in all data acquisition steps for different strategies computed on the synthetic data.

### ENCO - Experiments with Pre-Initialization

In addition to the discussion on the target distributions in the case of pre-initializing parts of the graph with the ground truth solution (presented in the main text for synthetic graphs in Section 5.4), we present results of the same experiment computed on the real-world graphs. The results are presented in Figure 18.

\begin{table}
\begin{tabular}{l l l l} \hline Variable & Parents & Values & Distribution \\ \hline Pollution & – & [Low, High] & \([0.9,0.1]\) \\ \hline Smoker & – & [True, False] & \([0.3,0.7]\) \\ \hline Cancer & Pollution=Low, Smoker=True & [True, False] & \([0.03,0.97]\) \\ Cancer & Pollution=High, Smoker=True & [True, False] & \([0.05,0.95]\) \\ Cancer & Pollution=Low, Smoker=False & [True, False] & \([0.001,0.999]\) \\ Cancer & Pollution=High, Smoker=False & [True, False] & \([0.02,0.98]\) \\ \hline Xray & Cancer=True & [True, False] & \([0.9,0.1]\) \\ Xray & Cancer=False & [True, False] & \([0.2,0.8]\) \\ \hline Dyspnoea & Cancer=True & [True, False] & \([0.65,0.35]\) \\ Dyspnoea & Cancer=False & [True, False] & \([0.3,0.7]\) \\ \hline \end{tabular}
\end{table}
Table 13: The conditional distribution in the cancer graph.

Figure 18: Histograms of intervention targets chosen by GIT. The red color corresponds to the selected node, while the green color indicates the node’s parents. The edges on which standard initialization was used are indicated by gray dashed lines. The rest of the solution is given in the initialization.

\begin{table}
\begin{tabular}{l l l l} \hline Variable & Parents & Values & Distribution \\ \hline Burglary & – & [True, False] & \([0.01,0.99]\) \\ \hline Earthquake & – & [True, False] & \([0.02,0.99]\) \\ \hline Alarm & Burglar=True, Earthquake=True & [True, False] & \([0.95,0.05]\) \\ Alarm & Burglar=False, Earthquake=True & [True, False] & \([0.29,0.71]\) \\ Alarm & Burglar=True, Earthquake=False & [True, False] & \([0.94,0.06]\) \\ Alarm & Burglar=False, Earthquake=False & [True, False] & \([0.001,0.999]\) \\ \hline John Calls & Alarm=True & [True, False] & \([0.9,0.1]\) \\ John Calls & Alarm=False & [True, False] & \([0.05,0.95]\) \\ \hline Mary Calls & Alarm=True & [True, False] & \([0.7,0.3]\) \\ Mary Calls & Alarm=False & [True, False] & \([0.01,0.99]\) \\ \hline \end{tabular}
\end{table}
Table 12: The conditional distribution in the earthquake graph.

Similarly as for the synthetic graphs, here we also observe that the GIT concentrates either on the selected node \(v\) or on its parents (denoted respectively by red and green colors in the plots).