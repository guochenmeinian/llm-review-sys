# Automatic Integration for Spatiotemporal

Neural Point Processes

 Zihao Zhou

Department of Computer Science

University of California, San Diego

La Jolla, CA 92092

ziz244@ucsd.edu

&Rose Yu

Department of Computer Science

University of California, San Diego

La Jolla, CA 92092

roseyu@ucsd.edu

###### Abstract

Learning continuous-time point processes is essential to many discrete event forecasting tasks. However, integration poses a major challenge, particularly for spatiotemporal point processes (STPPs), as it involves calculating the likelihood through triple integrals over space and time. Existing methods for integrating STPP either assume a parametric form of the intensity function, which lacks flexibility; or approximating the intensity with Monte Carlo sampling, which introduces numerical errors. Recent work by Omi et al. (2019) proposes a dual network approach for efficient integration of flexible intensity function. However, their method only focuses on the 1D temporal point process. In this paper, we introduce a novel paradigm: AutoSTPP (Automatic Integration for Spatiotemporal Neural Point Processes) that extends the dual network approach to 3D STPP. While previous work provides a foundation, its direct extension overly restricts the intensity function and leads to computational challenges. In response, we introduce a decomposable parametrization for the integral network using ProMNet. This approach, leveraging the product of simplified univariate graphs, effectively sidesteps the computational complexities inherent in multivariate computational graphs. We prove the consistency of AutoSTPP and validate it on synthetic data and benchmark real-world datasets. AutoSTPP shows a significant advantage in recovering complex intensity functions from irregular spatiotemporal events, particularly when the intensity is sharply localized. Our code is open-source at https://github.com/Rose-STL-Lab/AutoSTPP.

## 1 Introduction

Spatiotemporal point process (STPP) (Daley and Vere-Jones, 2007; Reinhart, 2018) is a continuous time stochastic process for modeling irregularly sampled events over space and time. STPPs are particularly well-suited for modeling epidemic outbreaks, ride-sharing trips, and earthquake occurrences. A central concept in STPP is the _intensity function_, which captures the expected rates of events occurrence. Specifically, given the event sequence over space and time \(\mathcal{H}_{t}=\{(\mathbf{s}_{1},t_{1}),\ldots,(\mathbf{s}_{n},t_{n})\}_{t_{n }\leq t}\), the joint log-likelihood of the observed events is:

\[\log p(\mathcal{H}_{t})=\sum_{i=1}^{n}\log\lambda^{*}(\mathbf{s}_{i},t_{i})- \int_{\mathcal{S}}\int_{0}^{t}\lambda^{*}(\mathbf{u},\tau)d\mathbf{u}d\tau\] (1)

\(\lambda^{*}\) is the optimal intensity, \(\mathcal{S}\) the spatial domain, \(\mathbf{u}\) and \(\tau\) the space and time, and \(t\) the time range.

Learning STPP requires multivariate integrals of the intensity function, which is numerically challenging. Traditional methods often assume a parametric form of the intensity function, such as the integralcan have a closed-form solution Daley and Vere-Jones (2007). But this also limits the expressive power of the model in describing complex spatiotemporal patterns.

Others propose to parameterize the model using neural ODE models Chen et al. (2020) and Monte Carlo sampling, but their computation is costly for high-dimensional functions. Recently, work by Zhou et al. (2022) proposes a nonparametric STPP approach. They use kernel density estimation for the intensity and model the parameters of the kernels with a deep generative model. Still, their method heavily depends on the number of background data points chosen as a hyper-parameter. Too few background points cause the intensity function to be an inflexible Gaussian mixture, while too many background points may cause overfitting on event arrival.

To reduce computational cost while maintaining expressive power, we propose a novel _automatic integration_ scheme based on dual networks to learn STPPs efficiently. Our framework models intensity function as the sum of background and influence functions. Instead of relying on closed-form integration or Monte Carlo sampling, we directly approximate the integral of the influence function with a deep neural network (DNN). Taking the partial derivative of a DNN results in a new computational graph that shares the same parameters; see Figure 1.

First, we construct an integral network whose derivative is the intensity function. Then, we train the network parameters by maximizing the data likelihood formulated in terms of the linear combinations of the integral networks. Finally, we reassemble the parameters of the integral network to obtain the intensity. This approach leads to the exact intensity function and its antiderivative without restricting its parametric forms, thereby making the integration process "automatic".

Our approach bears a resemblance with the fully NN approach by Omi et al. (2019) for 1D temporal point processes. There, automatic integration can be easily implemented by imposing monotonicity constraints on the integral network (Lindell et al., 2021; Li et al., 2019). However, due to triple integration in STPP, imposing monotonicity constraints significantly hurdles the expressivity of the integral network, leading to inaccurate intensity. As the experiments show, extending Fully NN to 3D cannot learn complex spatiotemporal intensity functions. Instead, we propose a decomposable parametrization for the integral network that bypasses this restriction.

Our approach can efficiently compute the exact likelihood of _any_ continuous influence function. We validate our approach using synthetic spatiotemporal point processes with complex intensity functions. We also demonstrate the superior performance on several real-world discrete event datasets. Compared to FullyNN by Omi et al. (2019), our approach presents a more general higher-order automatic integration scheme and is more effective in learning complex intensity functions. Also, the probability density of Omi et al. (2019) is ill-defined as its intensity integral does not diverge to infinity (Shchur et al., 2019). We fix the issue by adding a constant background intensity \(\mu\).

To summarize, our contributions include:

* We propose the first deep learning framework AutoSTPP to speed up spatiotemporal point process learning with automatic integration. We use dual networks and enforce the non-negativity of the intensity via a monotone integral network.
* We show that our automatic integration scheme empirically learns intensity functions more accurately than other integration approaches.
* We prove that the derivative network of AutoSTPP is a universal approximator of continuous functions and, therefore, is a consistent estimator under mild assumptions.

Figure 1: Illustration of AutoSTPP. \(W\) denotes the linear layer’s weight. \(\sigma\) is the nonlinear activation function. Left shows the intensity network approximating \(\lambda(\mathbf{s},t)\), and right is the integral network that computes \(\int_{\mathbf{s}}\int_{t}\lambda\). The two networks share the same parameters.

* We demonstrate that AutoSTPP can recover complex influence functions from synthetic data, enjoys high training efficiency and model interpretability, and outperforms the state-of-the-art methods on benchmark real-world data.

## 2 Related Work

**Parametrizing Point Process.** Fitting traditional STPP, such as the spatiotemporal Hawkes process, to data points with parametric models can perform poorly if the model is misspecified. To address this issue, statisticians have extensively studied semi- and non-parametric inference for STPP. Early works like Brix and Moller (2001), Brix and Diggle (2001) usually rely on Log-Gaussian Cox processes as a backbone and Epanechnikov kernels as estimators of the pair correlation function. Adams et al. (2009) propose a non-parametric approach that allows the generation of exact Poisson data from a random intensity drawn from a Gaussian Process, thus avoiding finite-dimensional approximation. These Cox process models are scalable but assume a continuous intensity change over time.

Recently, neural point processes (NPPs) that combine point processes with neural networks have received considerable attention (Yan et al., 2018; Upadhyay et al., 2018; Huang et al., 2019; Shang and Sun, 2019; Zhang et al., 2020). Under this framework, models focus more on approximating a discrete set of intensities before and after each event. The continuous intensity comes from interpolating the intensities between discrete events. For example, (Du et al., 2016) uses an RNN to generate intensities after each event. (Mei and Eisner, 2016) proposes a novel RNN architecture that generates intensities at both ends of each inter-event interval. Other works consider alternative training schema: Xiao et al. (2017) used Wasserstein distance, Guo et al. (2018) introduced noise-contrastive estimation, and Li et al. (2018) leveraged reinforcement learning. While these NPP models are more expressive than the traditional point process models, they still assume simple (continuous, usually monotonous) inter-event intensity changes and only focus on temporal point processes.

Neural STPP (Chen et al., 2020; Zhou et al., 2022) further generalizes NPP to spatiotemporal data. They use a non-negative activation function to map the hidden states to a scalar, i.e., the temporal intensity immediately after an event, and a conditional spatial distribution. The change of intensity between events is represented by a decay function or a Neural ODE. The conditional spatial distribution is represented by a kernel mixture or a normalizing flow. Nevertheless, all models assume a continuous transformation of the intensity function and have limited expressivity.

In the context of temporal point processes (TPP), closely related approaches are Omi et al. (2019) and Zhou and Yu (2023). Both propose using a Deep Neural Network (DNN) to parameterize the integral of an intensity function. The work by Omi et al. (2019) offers a more flexible formulation yet does not incorporate any specific prior assumptions about the form of the intensity changes. On the other hand, the approach by Zhou and Yu (2023) is capable of capturing more sophisticated influence functions, and it is this work that our research builds upon. However, both of these studies focus on the easier problem of learning the derivative with respect to time alone, thereby neglecting the rich amount of other features that may associated with the timestamps.

**Integration Methods.** Integration methods are largely ignored in NPP literature but are central to a model's ability to capture the complex dynamics of a system. Existing works either use an intensity function with an elementary integral (Du et al., 2016) or Monte Carlo integration (Mei and Eisner, 2016). However, we will see in the experiment section that the choice of integration method has a non-trivial effect on the model performance.

Integration is generally more complicated than differentiation, which can be mechanically solved using the chain rule. Most integration rules, e.g., integration by parts and change of variables, transform an antiderivative to another that is not necessarily easier. Elementary antiderivative only exists for a small set of functions, but not for simple composite functions such as \(\exp(x^{2})\)(Dunham, 2018). The Risch algorithm can determine such elementary antiderivative (Risch, 1969, 1970) but has never been fully implemented due to its complexity. The most commonly used integration methods are still numerical: Newton-Cotes Methods, Romberg Integration, Quadrature, and Monte Carlo integration (Davis and Rabinowitz, 2007).

Several recent works leverage automatic differentiation to speedup integration, a paradigm known as Automatic Integration (AutoInt). Liu (2020) proposes integrating the Taylor polynomial using the derivatives from Automatic Differentiation (AutoDiff). It requires partitioning of the integral limits

[MISSING_PAGE_FAIL:4]

where \(\circ\) indicates the Hadamard product, and \(\mathbf{W}_{11}\) is the first column of \(\mathbf{W}_{1}\), i.e.,

\[\mathbf{W}_{1}:=[\mathbf{W}_{11}\quad\mathbf{W}_{12}\quad\dots\quad\mathbf{W}_{ 1,M_{1}}]\]

Computing \(f_{\theta}(\mathbf{x})\) involves many repeated operations. For example, the result of \(\mathbf{W}_{1}\mathbf{x}\) is used for compute both \(\sigma(\mathbf{W}_{1}\mathbf{x})\) and \(\sigma^{\prime}(\mathbf{W}_{1}\mathbf{x})\), see Figure 1. We have developed a program that harnesses the power of dynamical programming to compute derivatives efficiently with AutoDiff. See Appendix D for the detailed algorithm.

### AutoInt Point Processes as Consistent Estimators

We show that the universal approximation theorem (UAT) holds for derivative networks. This theorem signifies that, given a sufficient number of hidden units, derivative networks can theoretically approximate any continuous functions, no matter how complex. Therefore, using derivative networks does not limit the range of influence functions that can be approximated.

**Proposition 3.1** (Universal Approximation Theorem for Derivative Networks).: _The set of derivative networks corresponding to two-layer feedforward integral networks is dense in \(C(\mathbb{R})\) with respect to the uniform norm._

For a detailed proof, see Appendix E. With UAT, it is clear that under some mild assumptions, AutoInt Point Processes are consistent estimators of point processes that take the form of Equation 5.

**Proposition 3.2** (Consistency of AutoInt Point Process).: _Under the assumption that the ground truth point process is stationary, ergodic, absolutely continuous and predictable, if the ground truth influence function is truncated (i.e., \(\exists C,f(t)=0\ \forall t>c\)), the maximum likelihood estimator \(f_{\theta}\) converges to the true influence function \(f\) in probability as \(T\to\infty\)._

Our model belongs to the class of linear self-excitation processes, whose maximum likelihood estimator properties were analyzed by Ogata et al. (1978). Under the assumptions above, two conditions are needed for the proof of consistency:

**Assumption 3.3**.: (Consistency Conditions) For any \(\theta\in\Theta\) there is a neighbourhood \(U\) of \(\theta\) such that

1. \(\sup_{\theta^{\prime}\in U}|\lambda_{\theta^{\prime}}(t,\omega)-\lambda_{ \theta^{\prime}}^{*}(t,\omega)|\to 0\) in probability as \(t\to\infty\),
2. \(\sup_{\theta^{\prime}\in U}|\log\lambda_{\theta^{\prime}}^{*}(t,\omega)|\) has, for some \(\alpha>0\), finite \((2+\alpha)\) th moment uniform bounded with respect to \(t\).

The first condition is satisfied by UAT. The second condition depends on the rate of decrease of the influence tail and is satisfied by truncation. In our experiments, we truncated the history by only including the influences of the previous 20 events. If the ground truth influence function decays over the entire time domain, our estimator may exhibit negligible bias.

### 3D Automatic Integration

AutoInt gives us an efficient way to calculate a line integral over one axis. However, for spatiotemporal point process models, we need to calculate the triple integral of the intensity function over space and time. Since we cannot evaluate the integral network with an input of infinity, we assume the spatial domain to be a rectangle, such that the triple integral is over a cuboid. We then convert the triple integral to line integrals using Divergence and Green's theorem (Marsden and Tromba, 2003).

Define \(\mathbf{s}:=(x,y)\) and \(t:=z\), we model the spatiotemporal influence \(f_{\theta}^{*}(x,y,z)\) as

\[f_{\theta}^{*}(\mathbf{s},t)=\frac{\partial P}{\partial x}+\frac{\partial Q}{ \partial y}+\frac{\partial R}{\partial z}\] (4)

The Divergence theorem relates volume and surface integrals. It states that for any \(P(x,y,z),Q(x,y,z),R(x,y,z)\) that is differentiable over the cuboid \(\Omega\), we have

\[\iiint_{\Omega}\left(\frac{\partial P}{\partial x}+\frac{\partial Q}{\partial y }+\frac{\partial R}{\partial z}\right)dv=\oiint_{\Sigma}Pdydz+Qdzdx+Rdxdy,\]

where \(\Sigma\) are the six rectangles that enclose \(\Omega\).

Using \(R\) as an example, we begin with two neural network approximators, \(L_{R}\) and \(M_{R}\). We initialize the two approximators as first-order derivative networks, whose corresponding integral networks are \(\int L_{R}dx\) and \(\int M_{R}dy\). We use the \(xy\) partial derivatives of the two networks to model \(R\), such that \(R:=\dfrac{\partial M_{R}}{\partial x}-\dfrac{\partial L_{R}}{\partial y}\). Then the \(z\) partial derivative \(\dfrac{\partial R}{\partial z}\) is \(\dfrac{\partial^{2}M_{R}}{\partial x\partial z}-\dfrac{\partial^{2}L_{R}}{ \partial y\partial z}=\dfrac{\partial^{3}\int M_{R}dy}{\partial x\partial y \partial z}-\dfrac{\partial^{3}\int L_{R}dx}{\partial x\partial y\partial z}\). We can see that \(\dfrac{\partial R}{\partial z}\) can be exactly evaluated as the third derivatives of two integral networks. In the same manner, we can model \(P\) and \(Q\) such that the intensity is parametrized by six networks: \(L_{R},L_{Q},L_{P},M_{R},M_{Q},\) and \(M_{P}\).

We use neural network pairs \(\{L,M\}\) to parametrize each intensity term in Equation 4 according to Green's theorem. It states that for any \(L\) and \(M\) differentiable over the rectangle \(D\),

\[\iint_{D}\left(\dfrac{\partial L}{\partial x}-\dfrac{\partial M}{\partial y} \right)dxdy=\oint_{L^{+}}(Ldx+Mdy),\]

where \(L^{+}\) is the counterclockwise path that encloses \(D\). \(\int Rdxdy\) is then \(\oint L_{R}dx+M_{R}dy\), and can be exactly evaluated using the integral networks.

In practice, we observe that the six networks' parametrization of intensity can be simplified. \(L_{R}\), \(L_{Q}\), \(L_{P}\) can share the same set of weights, and similarly for \(M_{R}\), \(M_{Q}\), \(M_{P}\). The influence is essentially parametrized by two different neural networks, \(L\) and \(M\). That is,

\[f_{\theta}(t,\mathbf{h}):=\left(\dfrac{\delta^{3}\int Mdy}{\delta x\delta y \delta z}-\dfrac{\delta^{3}\int Ldx}{\delta x\delta y\delta z}\right)+\left( \dfrac{\delta^{3}\int Mdz}{\delta x\delta y\delta z}-\dfrac{\delta^{3}\int Ldy }{\delta x\delta y\delta z}\right)+\left(\dfrac{\delta^{3}\int Mdx}{\delta x \delta y\delta z}-\dfrac{\delta^{3}\int Ldz}{\delta x\delta y\delta z}\right)\]

### Imposing the 3D Non-negativity Constraint

For the NPP model in Equation 3, the derivative network \(f_{\theta}\) needs to be non-negative. Imposing the non-negativity constraint for 3D AutoInt is a challenging task. It implies that the integral network \(F_{\theta}\) always has a nonnegative triple derivative.

A simple approach is to apply an activation function with a nonnegative triple derivative. An integral network that uses this activation and has nonnegative linear layer weights satisfies the condition. We call this approach "Constrained Triple AutoInt". However, the output of an integral network can grow very quickly with large input, and the gradients are likely to explode during training. Moreover, the non-negative constraint on the influence function only requires \(\dfrac{\partial F_{\theta}}{\partial\mathbf{s}\partial t}\) to be positive. But an activation function with a nonnegative triple derivative would also enforce other partial derivatives to be positive.

Such constraints are overly restrictive for STPPs, whose partial derivatives \(\dfrac{\partial F_{\theta}}{\partial\mathbf{s}\partial\mathbf{s}}\) and \(\dfrac{\partial F_{\theta}}{\partial t\partial t}\) can both be negative when the intensity is well-defined.

ProdNet.We propose a different solution to enforce the 3D non-negative constraint called _ProdNet_. Specifically, we decompose the influence function \(f_{\theta}(s_{1},s_{2},t):\mathbb{R}^{3}\rightarrow\mathbb{R}\) as \(f_{\theta}^{1}(s_{1})f_{\theta}^{2}(s_{2})f_{\theta}^{3}(t)\), the product of three \(\mathbb{R}\rightarrow\mathbb{R}\) AutoInt derivative networks. The triple antiderivative of the influence

Figure 2: Comparison of fitting a nonnegative function \(f(x,y,z)=\sin(x)\cos(y)\sin(z)+1\). Our proposed AutoInt ProdNet approach can well approximate the ground truth function. In contrast, imposing the constraint through activation function with a nonnegative triple derivative “Constrained Triple AutoInt” fails due to overly stringent constraint.

function is then \(F_{\theta}^{1}(s_{1})F_{\theta}^{2}(s_{2})F_{\theta}^{3}(t)\), the product of their respective integral networks. Then we can apply 1D non-negative constraint to each of the derivative networks. The other partial derivatives are not constrained because \(F_{\theta}^{1},F_{\theta}^{2},F_{\theta}^{3}\) can be negative.

One limitation of such decomposition is that it can only learn the joint density of marginally independent distribution. We circumvent this issue by parameterizing the influence function as the sum of \(N\) ProMedNet, \(\sum_{i=1}^{N}f_{\theta,i}^{1}(s_{1})f_{\theta,i}^{2}(s_{2})f_{\theta,i}^{3}(t)\). The formulation is no longer marginally independent since it is not multiplicative decomposable. Figure 2 shows that the sum of two ProMedNets is already sufficient to approximate a function that cannot be written as the sum of products of positive functions. In contrast, the constrained triple AutoInt's intensity is convex everywhere and fails to fit \(f\).

Increasing the number of ProMedNet improves AutoInt's flexibility at the cost of time and memory. We perform an ablation study of the number of ProMed in Appendix F.

### Model Training

Given the integral network \(F_{\theta}(t,\mathbf{h}):=\int_{\mathcal{S}}F_{\theta}(\mathbf{s},t,\mathbf{h})\) and the derivative network approximating the influence function \(f_{\theta}=\frac{\partial F_{\theta}}{\partial t\partial\mathbf{s}}\), the log-likelihood of an event sequence \(\mathcal{H}_{n}=\{(\mathbf{s}_{1},t_{1}),\cdots,(\mathbf{s}_{n},t_{n})\}\) observed in time interval \([0,T]\) with respect to the model is

\[\mathcal{L}(\mathcal{H}_{n})=\sum_{i=1}^{n}\log\left(\sum_{j=1}^{i-1}f_{\theta }(\mathbf{s}_{i}-\mathbf{s}_{j},t_{i}-t_{j},\mathbf{h}_{i})\right)-\sum_{i=1} ^{n}\left(F_{\theta}(T-t_{i},\mathbf{h}_{n})-F_{\theta}(0,\mathbf{h}_{i})\right)\]

Obtaining the above from Equation 1 is straightforward by the Fundamental Theorem of Calculus. \(F_{\theta}\) is evaluated using the Divergence theorem. We can learn the parameters \(\theta\) in both networks by maximizing the log-likelihood function. In experiments, we parametrize \(f_{\theta}\) with two AutoInt networks \(L\) and \(M\). Each network is a sum of \(N\) ProMedNets. That is,

\[f_{\theta}(\mathbf{s},t):=\sum_{i=1}^{N}f_{\theta_{i}}(\mathbf{s},t)=3\sum_{i= 1}^{N}\prod_{x\in\{s_{1},s_{2},t\}}\left[\frac{\delta^{3}\int M_{i}dx}{\delta x ^{3}}-\frac{\delta^{3}\int L_{i}dx}{\delta x^{3}}\right]\]

We name our method Automatic Spatiotemporal Point Process (AutoSTPP).

## 4 Experiments

We compare the performances of different neural STPPs using synthetic and real-world benchmark data. For synthetic data, our goal is to validate our AutoSTPP can accurately recover complex

Figure 3: Comparing the ground truth conditional intensity \(\lambda^{*}(\mathbf{s},t)\) with the learned intensity on the _ST Hawkes_ Dataset 1 and _ST Self-Correcting_ Dataset 3. **Top row:** Ground truth. **Second row:** Our AutoSTPP. **Rest of the rows:** Baselines. The crosses on top represent past events. Larger crosses indicate more recent events.

intensity functions. Additionally, we show that the errors resulting from numerical integration lead to a higher variance in the learned intensity than closed-form integration. We show that our model performs better or on par with the state-of-the-art methods for real-world data.

### Experimental Setup

Synthetic Datasets.We follow the experiment design of Zhou et al. (2022) to validate that our method can accurately recover the true intensity functions of complex STPPs. We use six synthetic point process datasets simulated using Ogata's thinning algorithm (Chen, 2016), see Appendix B for details. The first three datasets were based on spatiotemporal Hawkes processes, while the remaining three were based on spatiotemporal self-correcting processes. Each dataset spans a time range of \([0,10000)\) and is generated using a fixed set of parameters. Each dataset was divided into a training, validation, and testing set in an \(8:1:1\) ratio based on the time range.

Spatiotemporal Hawkes process (STH).A spatiotemporal Hawkes process, also known as a self-exciting process, posits that every past event exerts an additive, positive, and spatially local influence on future events. This pattern is commonly observed in social media and earthquakes. The process is characterized by the intensity function (Reinhart, 2018):

\[\lambda^{*}(\mathbf{s},t):=\mu g_{0}(\mathbf{s})+\sum_{i:t_{i}<t}g_{1}(t,t_{i} )g_{2}(\mathbf{s},\mathbf{s}_{i}):\mu>0.\] (5)

\(g_{0}\) represents the density of the background event distribution over \(\mathcal{S}\). \(g_{2}\) represents the density of the event influence distribution centered at \(\mathbf{s}_{i}\) and over \(\mathcal{S}\). \(g_{1}\) describes each event \(t_{i}\)'s influence decay over time. We implement \(g_{0}\) and \(g_{2}\) as Gaussian densities and \(g_{2}\) as exponential decay functions.

Spatiotemporal Self-Correcting process (STSC).A spatiotemporal Self-Correcting process assumes that the background intensity always increases between the event arrivals. Each event discretely reduces the intensity in the vicinity. The STSC is often used for modeling events with regular intervals, such as animal feeding times. It is characterized by:

\[\lambda^{*}(\mathbf{s},t)=\mu\exp\Big{(}g_{0}(\mathbf{s})\beta t-\sum_{i:t_{i }<t}\alpha g_{2}(\mathbf{s},\mathbf{s}_{i})\Big{)}:\alpha,\beta,\mu>0\] (6)

\(g_{0}(\mathbf{s})\) again represents the density of the background event distribution. \(g_{2}(\mathbf{s},\mathbf{s}_{i})\) represents the density of the negative event influence centered at \(\mathbf{s}_{i}\).

See the Appendix B for the simulation parameters of the six synthetic datasets.

Real-world Datasets.We follow the experiment design of Chen et al. (2020) and use two of the real-world datasets, _Earthquake Japan_ and _COVID New Jersey_. The first dataset includes information on the times and locations of all earthquakes in Japan between 1990 and 2020, with magnitudes of at least 2.5. This dataset includes 1050 sequences over a \([0,30)\) time range and is split with a ratio of \(950:50:50\). The second dataset is published by The New York Times and describes COVID-19 cases in New Jersey at the county level. This dataset includes 1650 sequences over a \([0,7)\) time range and is split with a ratio of \(1450:100:100\).

Evaluation Metrics.For real-world datasets, we report the average test log-likelihood (LL) of events. For synthetic datasets, the ground truth intensities are available, so we report the test log-likelihood

\begin{table}
\begin{tabular}{l c c c c c c c c c c c c} \hline \hline  & \multicolumn{4}{c}{Spatiotemporal Hawkes process} & \multicolumn{4}{c}{Spatiotemporal Self Correcting process} \\ \cline{2-13}  & \multicolumn{2}{c}{DS1} & \multicolumn{2}{c}{DS2} & \multicolumn{2}{c}{DS3} & \multicolumn{2}{c}{DS1} & \multicolumn{2}{c}{DS2} & \multicolumn{2}{c}{DS3} \\ \cline{2-13}  & LL & HD & LL & HD & LL & HD & LL & HD & LL & HD & LL & HD \\ NSTPP & - & - & - & - & - & - & - & - & - & - & - & - \\ DSTPP & - & - & - & - & - & - & - & - & - & - & - \\ Monte Carlo STPP & - & - & - & - & - & - & - & - & - & - & - \\ AutoSTPP & - & - & - & - & - & - & - & - & - & - & - \\ \hline \hline \end{tabular}
\end{table}
Table 1: Test log likelihood (LL) and Hellinger distance of distribution (HD) on synthetic data (LL higher is better, HD lower is better). Comparison between AutoSTPP, NSTPP, Monte Carlo STPP, on synthetic datasets from two types of spatiotemporal point processes.

(LL) and the time-average Hellinger distance between the learned conditional spatial distribution \(f^{*}(\mathbf{s}|t)\) and the ground truth distribution. The distributions are estimated as multinomial distributions \(P=\{p_{i},...,p_{k}\}\) and \(Q=\{q_{i},...,q_{k}\}\) at \(k\) discretized grid points. The Hellinger distance is then calculated as \(H(P,Q)=\frac{1}{\sqrt{2}}\sqrt{\sum_{i=1}^{k}\left(\sqrt{p_{i}}-\sqrt{q_{i}} \right)^{2}}\)

**Baselines.** We compare with two state-of-the-art neural STPP models, NSTPP (Chen et al., 2020) and Deep-STPP (Zhou et al., 2022). We also design another baseline, Monte Carlo STPP, which uses the same underlying model as AutoSTPP but applies numerical integration instead of AutoInt to calculate the loss. For a fair comparison, Monte Carlo STPP models the influence \(f^{*}_{\theta}(s,t)\) as a multi-layer perceptron instead of a derivative network. This numerical baseline aims to demonstrate the benefit of automatic integration.

### Results and Discussion

Exact Likelihood.Not all baseline methods have exact likelihood available. NSTPP (Chen et al., 2020) uses a numerical Neural-ODE solver. DeepSTPP (Zhou et al., 2022) introduces a VAE that optimizes a lower bound of likelihood. Monte Carlo STPP estimates the triple integral of intensity by Monte Carlo integration. As such, the results presented in Table 1 are estimated for these baseline models, whereas for our model, the results reflect the true likelihood.

Advantage of AutoInt.We visualize and compare two sample sets of intensities from STH Dataset 1 and STSC Dataset 3 in Figure 3. While the influence function approximator in Monte Carlo STPP can theoretically approximate more functions than Auto-STPP, the intensity it learns is "flatter" than the intensity learned by Auto-STPP. This flatness indicates a lack of information regarding future event locations.

The primary reason behind this flatness can be traced back to numerical errors inherent in the Monte Carlo method. The Monte Carlo integration performs poorly for sharply localized integrants because its samples are homogeneous over the phase space. The intensity of ST-Hawkes is a localized function; it is close to zero in most of the places but high near some event locations. As a result, Monte Carlo STPP can hardly recover the sharpness of the ground truth intensity. NSTPP also uses Monte Carlo integration and suffers the same drawback on STH Dataset 1. In contrast, AutoSTPP evaluates the integral with closed-form integration and alleviates this issue.

Synthetic Datasets Results.Table 1 compares the test LL and the Hellinger distance between AutoSTPP and the baseline models on the six synthetic datasets. For the STSC datasets, we can see that AutoSTPP accurately recovers the intensity functions compared to other models. In Figure 3, AutoSTPP is the only model whose peak intensity location is always the same as the ground truth. DeepSTPP does not perform well in learning the dynamics of the STSC dataset; it struggles to align the peak and tends to learn the flat intensity as overly sharp. The peak intensity location of NSTPP is also biased.

For the STHP datasets, DeepSTPP has a clear advantage because it uses Gaussian kernels to approximate the Gaussian ground truth. In Table 1, AutoSTPP outperforms all other models except DeepSTPP, and its performance is comparable. Figure 3 shows that Monte Carlo STPP and NSTPP

\begin{table}
\begin{tabular}{c c c} \hline \hline LL & COVID-19 NY & Earthquake JP \\ \hline NSTPP & \(2.5566_{+0.0447}\) & \(-4.4949_{+0.1172}\) \\ DSTPP & \(2.3433_{+0.0109}\) & \(-3.9852_{+0.0129}\) \\ MonteSTPP & \(2.1070_{+0.0342}\) & \(-3.6085_{+0.0436}\) \\ AutoSTPP & \(\textbf{2.6243}_{+0.5905}\) & **-3.5948\({}_{+0.0025}\)** \\ \hline \hline \end{tabular}
\end{table}
Table 2: Test log likelihood (LL) comparison for space and time on real-world benchmark data, mean and standard deviation over three runs.

Figure 4: Forward mixed (\(d/dx_{1}dx_{2}\cdots dx_{k}\)) partial derivative computation average speed comparison between our efficient implementation and PyTorch naive AutoGrad, for a two-layer MLP.

can only learn an unimodal function, whereas AutoSTPP can capture multi-modal behavior in the ground truth, especially the small bumps near the mode.

Real-world Datasets Results.Table 2 compares the test LL of AutoSTPP against the baseline models on the earthquakes and COVID datasets. Our model demonstrates superior performance, outperforming all the state-of-the-art methods. One should note that while Monte Carlo STPP shows performance comparable to ours on the Earthquake JP dataset, it falls short when applied to the COVID-19 NY dataset. We attribute this discrepancy to the large low-population-density areas in the COVID-19 NY data, which causes higher numerical error in integration.

### Computational Efficiency

Figure 4 visualizes the benefit of using our implementation of AutoInt instead of the PyTorch naive implementation. More visualizations of the forward and backward computation times can be found in Appendix A. We can see that our implementation can be extended to compute any order of partial derivative. It is significantly faster than the naive autograd. In our AutoSTPP, we calculate the intensity using the product of three first-order derivatives. Our implementation would lead to a speedup of up to 68% for computing each first-order derivative.

## 5 Conclusion

We propose Automatic Integration for neural spatiotemporal point process models (AutoSTPP) using a dual network approach. AutoSTPP can efficiently compute the exact likelihood of _any_ sophisticated intensity.

We validate the effectiveness of our method using synthetic data and real-world datasets and demonstrate that it significantly outperforms other point process models with numerical integration when the ground truth intensity function is localized.

However, like any approach, ours is not without its limitations. While AutoSTPP excels in computing the likelihood, sampling from AutoSTPP is computationally expensive as we only have the expression of the probability density. Closed-form computation of expectations is also not possible; Knowing the form of \(\int\lambda(t)\), calculating \(\int t\lambda(t)\) is still intractable.

Our work presents a new paradigm for learning continuous-time dynamics. Currently, our neural process model takes the form of Hawkes processes (self-exciting) but cannot handle the discrete decreases of intensity after events due to the difficulty of integration. Future work includes relaxing the form of the intensity network with advanced integration techniques. Another interesting direction is to increase the approximation ability of the product network.

## Acknowledgement

This work was supported in part by U. S. Army Research Office under Army-ECASE award W911NF-07-R-0003-03, the U.S. Department Of Energy, Office of Science, IARPA HAYSTAC Program, NSF Grants #2205093, #2146343, and #2134274.

## References

* Adams et al. (2009) Ryan Prescott Adams, Iain Murray, and David JC MacKay. Tractable nonparametric bayesian inference in poisson processes with gaussian process intensities. In _Proceedings of the 26th annual international conference on machine learning_, pages 9-16, 2009.
* Brix and Diggle (2001) Anders Brix and Peter J Diggle. Spatiotemporal prediction for log-gaussian cox processes. _Journal of the Royal Statistical Society: Series B (Statistical Methodology)_, 63(4):823-841, 2001.
* Brix and Moller (2001) Anders Brix and Jesper Moller. Space-time multi type log gaussian cox processes with a view to modelling weeds. _Scandinavian Journal of Statistics_, 28(3):471-488, 2001.
* Chen et al. (2020) Ricky TQ Chen, Brandon Amos, and Maximilian Nickel. Neural spatio-temporal point processes. _arXiv preprint arXiv:2011.04583_, 2020.
* Chen et al. (2019)* Chen (2016) Yuanda Chen. Thinning algorithms for simulating point processes. _Florida State University, Tallahassee, FL_, 2016.
* Daley and Vere-Jones (2007) Daryl J Daley and David Vere-Jones. _An introduction to the theory of point processes: volume II: general theory and structure_. Springer Science & Business Media, 2007.
* Daniels and Velikova (2010) Hennie Daniels and Marina Velikova. Monotone and partially monotone neural networks. _IEEE Transactions on Neural Networks_, 21(6):906-917, 2010.
* Davis and Rabinowitz (2007) Philip J Davis and Philip Rabinowitz. _Methods of numerical integration_. Courier Corporation, 2007.
* Du et al. (2016) Nan Du, Hanjun Dai, Rakshit Trivedi, Utkarsh Upadhyay, Manuel Gomez-Rodriguez, and Le Song. Recurrent marked temporal point processes: Embedding event history to vector. In _Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining_, pages 1555-1564, 2016.
* Dunham (2018) William Dunham. _The calculus gallery_. Princeton University Press, 2018.
* Guo et al. (2018) Ruocheng Guo, Jundong Li, and Huan Liu. Initiator: Noise-contrastive estimation for marked temporal point process. In _IJCAI_, pages 2191-2197, 2018.
* Huang et al. (2019) Hengguan Huang, Hao Wang, and Brian Mak. Recurrent poisson process unit for speech recognition. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 33, pages 6538-6545, 2019.
* Li et al. (2019) Haibin Li, Yangtian Li, and Shangjie Li. Dual neural network method for solving multiple definite integrals. _Neural computation_, 31(1):208-232, 2019.
* Li et al. (2018) Shuang Li, Shuai Xiao, Shixiang Zhu, Nan Du, Yao Xie, and Le Song. Learning temporal point processes via reinforcement learning. _arXiv preprint arXiv:1811.05016_, 2018.
* Lindell et al. (2021) David B Lindell, Julien NP Martel, and Gordon Wetzstein. Autoint: Automatic integration for fast neural volume rendering. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pages 14556-14565, 2021.
* Liu (2020) Keqin Liu. Automatic integration. _arXiv e-prints_, pages arXiv-2006, 2020.
* Marsden and Tromba (2003) Jerrold E. Marsden and Anthony Tromba. _Vector Calculus_. Macmillan, August 2003. ISBN 978-0-7167-4992-9. Google-Books-ID: LiRLJf2m_dwC.
* Mei and Eisner (2016) Hongyuan Mei and Jason Eisner. The neural hawkes process: A neurally self-modulating multivariate point process. _arXiv preprint arXiv:1612.09328_, 2016.
* Ogata et al. (1978) Yosihiko Ogata et al. The asymptotic behaviour of maximum likelihood estimators for stationary point processes. _Annals of the Institute of Statistical Mathematics_, 30(1):243-261, 1978.
* Omi et al. (2019) Takahiro Omi, Naonori Ueda, and Kazuyuki Aihara. Fully neural network based model for general temporal point processes. _arXiv preprint arXiv:1905.09690_, 2019.
* Reinhart (2018) Alex Reinhart. A review of self-exciting spatio-temporal point processes and their applications. _Statistical Science_, 33(3):299-318, 2018.
* Risch (1969) Robert H Risch. The problem of integration in finite terms. _Transactions of the American Mathematical Society_, 139:167-189, 1969.
* Risch (1970) Robert H Risch. The solution of the problem of integration in finite terms. _Bulletin of the American Mathematical Society_, 76(3):605-608, 1970.
* Shang and Sun (2019) Jin Shang and Mingxuan Sun. Geometric hawkes processes with graph convolutional recurrent neural networks. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 33, pages 4878-4885, 2019.
* Shchur et al. (2019) Oleksandr Shchur, Marin Bilos, and Stephan Gunnemann. Intensity-free learning of temporal point processes. _arXiv preprint arXiv:1909.12127_, 2019.
* Shchur et al. (2019)Utkarsh Upadhyay, Abir De, and Manuel Gomez-Rodriguez. Deep reinforcement learning of marked temporal point processes. _arXiv preprint arXiv:1805.09360_, 2018.
* Xiao et al. (2017) Shuai Xiao, Mehrdad Farajtabar, Xiaojing Ye, Junchi Yan, Le Song, and Hongyuan Zha. Wasserstein learning of deep generative point process models. _arXiv preprint arXiv:1705.08051_, 2017.
* Yan et al. (2018) Junchi Yan, Xin Liu, Liangliang Shi, Changsheng Li, and Hongyuan Zha. Improving maximum likelihood estimation of temporal point process via discriminative and adversarial learning. In _IJCAI_, pages 2948-2954, 2018.
* Zhang et al. (2020) Qiang Zhang, Aldo Lipani, Omer Kirnap, and Emine Yilmaz. Self-attentive hawkes process. In _International Conference on Machine Learning_, pages 11183-11193. PMLR, 2020.
* Zhou and Yu (2023) Zihao Zhou and Rose Yu. Automatic integration for fast and interpretable neural point process. In _Learning for Dynamics and Control Conference_. PMLR, 2023.
* Zhou et al. (2022) Zihao Zhou, Xingyi Yang, Ryan Rossi, Handong Zhao, and Rose Yu. Neural point process for learning spatiotemporal event dynamics. In _Learning for Dynamics and Control Conference_, pages 777-789. PMLR, 2022.

## Appendix A More Implementation Benchmarks

As the number of MLP layers increases, the lower-order derivative computation becomes faster (relative to PyTorch naive implementation), whereas the higher-order derivative computation becomes slower. This performance pattern is because our implementation uses Python for loop. Our approach is faster than the baseline in the majority of cases.

As for both forward and backward computation times, our implementation still consistently surpasses the baseline in terms of speed. Notably, our method is even more efficient when calculating univariate partial derivatives than mixed partial derivatives. This advantage is primarily due to the reduced number of iterations required by the Python for-loop in the case of univariate derivatives.

## Appendix B STSC and ST-Hawkes Introduction and Simulation Parameters

We use the same parameters as Zhou et al. (2022).

The STSCP's and the STHP's kernels \(g_{0}(\mathbf{s})\) and \(g_{2}(\mathbf{s},\mathbf{s}_{j})\) are prespecified to be Gaussian:

\[g_{0}(\mathbf{s}) :=\frac{1}{2\pi}|\Sigma_{g0}|^{-\frac{1}{2}}\exp\left(-\frac{1}{2 }(\mathbf{s}-[0,0])\Sigma_{g0}^{-1}(\mathbf{s}-[0,0])^{T}\right)\] \[g_{2}(\mathbf{s},\mathbf{s}_{j}) :=\frac{1}{2\pi}|\Sigma_{g2}|^{-\frac{1}{2}}\exp\left(-\frac{1}{2 }(\mathbf{s}-\mathbf{s}_{j})\Sigma_{g2}^{-1}(\mathbf{s}-\mathbf{s}_{j})^{T}\right)\]

The STSCP is defined on \(\mathcal{S}=[0,1]\times[0,1]\), while the STHP is defined on \(\mathcal{S}=\mathbb{R}^{2}\). The STSCP's kernel functions are normalized according to their cumulative probability on \(\mathcal{S}\). Table 4 shows thesimulation parameters. We discretized the STSCP's spatial domain as a \(101\times 101\) grid during the simulation.

Each dataset is a single, long sequence that spans over 10,000 time units. We divide each dataset into 50 sequences, each spanning 200 time units. We use 40 sequences for training, 5 for validation, and 5 for testing. Here's a summary of the total number of events found in each dataset:

The prediction task applies sliding windows to each of the datasets. We try to use historical events to predict the likelihood of the next event in the same sequence.

## Appendix C Model Setup Details

We detail the specific hyperparameter settings in Table 5. Except for the learning rate, the same set of parameters was applied across all datasets. Despite varying datasets, This consistency in performance demonstrates our model's robustness to hyperparameters.

## Appendix D Forward-pass Algorithm for Automatic Integration

**Function:**: \(\texttt{dnforward}(f,n,x,\texttt{dims})\), \(\texttt{partition}(n,k)\) finds all k-subset partitions of

\begin{table}
\begin{tabular}{c c c c} \hline \hline  & & number of events \\ \hline ST-Hawkes & DS1 & 3983 \\  & DS2 & 9017 \\  & DS3 & 11693 \\ \hline ST-Self Correcting & DS1 & 10002 \\  & DS2 & 6668 \\  & DS3 & 5004 \\ \hline \hline \end{tabular}
\end{table}
Table 4: Number of events in each synthetic dataset

\begin{table}
\begin{tabular}{c c c c c c c} \hline \hline  & & \(\alpha\) & \(\beta\) & \(\mu\) & \(\Sigma_{g0}\) & \(\Sigma_{g2}\) \\ \hline ST-Hawkes & DS1 &.5 & 1 &.2 & [.2 0; 0.2] & [0.5 0; 0 0.5] \\  & DS2 &.5 &.6 &.15 & [5 0; 0 5] & [.1 0; 0.1] \\  & DS3 &.3 & 2 & 1 & [1 0; 0 1] & [.1 0; 0.1] \\ \hline ST-Self Correcting & DS1 &.2 &.2 & 1 & [1 0; 0 1] & [0.85 0; 0 0.85] \\  & DS2 &.3 &.2 & 1 & [.4 0; 0.4] & [.3 0; 0.3] \\  & DS3 &.4 &.2 & 1 & [.25 0; 0.25] & [.2 0; 0.2] \\ \hline \hline \end{tabular}
\end{table}
Table 3: Parameter settings for the synthetic dataset

\begin{table}
\begin{tabular}{c c c} \hline \hline Name & Value & Description \\ \hline Optimizer & Adam & - \\ Learning rate & - & Depends on dataset, [0.0002, 0.004] \\ Momentum & 0.9 & Adam momentum \\ Epoch & 50 / 100 & 50 for synthetic dataset and 100 for real-world dataset \\ Batch size & 128 & - \\ Activation & tanh & Activation function in L and M (intensity parameter networks) \\ \(N\) & 2 / 10 & Number of product nets to sum in L and M \\  & & 2 for synthetic dataset and 10 for real-world dataset \\ bias & true & L and M use bias in their linear layers \\ \hline \hline \end{tabular}
\end{table}
Table 5: Hyperparameter settings for training AutoSTPP on all datasets.

**Data:**\(n\), dimension of \(f(x)\), \(x\), a tensor of shape (batch, dim), dims, list of dimensions to derive, layers, composite functions in \(f\)

**Result:**\(d^{\texttt{dim}}f/dx^{\texttt{dim}}\)

Initialize dictionary \(\texttt{dnf}\), mapping from dims to \(d^{\texttt{dim}}f/dx^{\texttt{dim}}\), empty list pd

**if**\(\texttt{idim}\) = \(I\)**then**

Procedure \(f(x)\)

\(\texttt{pd}\leftarrow\boldsymbol{\delta}_{i,\texttt{dim}}|_{i\in[1,n]}\)

**else**

**for**\(\texttt{subdims}\in\) _combination(\(\texttt{dims}\), len(\(\texttt{dims}\))-1)_**do**

Procedure \(\texttt{dnforward}\)(\(f\), \(n\), \(x\), subdims)

**end**

\(\texttt{pd}\leftarrow\boldsymbol{0}\)

**end**

**for**\(\texttt{layer}\in\) _layers_**do**

**if**\(\texttt{layer}\) _is linear_**then**

pd append last pd \(\times W^{T}\), \(W\) is the linear weight

**else if**\(\texttt{layer}\) _is activation_**then**

**if**\(\texttt{|dims}|=1\)**then**

\(\texttt{termsum}\leftarrow\texttt{last pd}\times\texttt{layer}^{\prime}(f)\)

**else**

\(\texttt{termsum}\leftarrow\texttt{0}\)

**for**\(\texttt{order}\in\) \(0,\cdots,\texttt{|dims|}\) **do**

**if**\(\texttt{order}\) = \(0\)**then**

\(\texttt{term}\leftarrow\texttt{last pd}\)

**else**

\(\texttt{term}\gets\texttt{0}\)

**for**\(\texttt{part}\in\) _partition(dims, order + 1)_**do**

\(\texttt{temp}\leftarrow\texttt{1}\)

**for**\(\texttt{subdims}\in\) _part_**do**

\(\texttt{temp}\leftarrow\texttt{temp}\times\texttt{dnforward}(f,n,x, \texttt{subdims})\) (precomputed)

**term**\(\leftarrow\texttt{term}\) **+ temp**

**end**

\(\texttt{termsum}\leftarrow\texttt{termsum}+\texttt{term}\)

**end**

**end**

**termsum**\(\leftarrow\texttt{termsum}\times\texttt{layer}^{(n)}(f)\)

**end**

**end**

**end**

**end**

**end**

**end**

**return** last pd

## Appendix E Universal Approximation Theorem for Derivative Network

Consider an AutoInt integral network with the form

\[g(x)=C\cdot(\sigma\circ(A\cdot x+b)),\qquad A\subseteq\mathbb{R}^{k\times n}, b\subseteq\mathbb{R}^{k},C\subseteq\mathbb{R}^{k},\]

where \(\sigma\) denotes a \(\mathbb{R}\rightarrow\mathbb{R}\) continuous non-polynomial function applied elementwise to each input dimension.

The derivative network thus takes the form

\[g^{\prime}(x)=C\cdot(\sigma^{\prime}\circ(A\cdot x+b)\circ A_{col}),\]

where \(A_{col}\subseteq\mathbb{R}^{k}\) is a column of \(A\) that corresponds to the deriving dimension.

Recall the universal approximation theorem [1], which says for every compact \(K\subseteq\mathbb{R}^{n}\) and \(f\in C(K,\mathbb{R}),\varepsilon>0\), there exist \(A,b,C\) such that

\[\sup_{x\in K}\|f(x)-g(x)\|<\varepsilon\]

**Proposition E.1**.: _(Universal Approximation Theorem for Derivative Network) for every compact \(K\subseteq\mathbb{R}^{n}\) and \(f\in C(K,\mathbb{R}),\varepsilon>0\), there exists \(A\in\mathbb{R}^{k\times n},b\in\mathbb{R}^{k},C\in\mathbb{R}^{k},\beta\in \mathbb{R}\) such that_

\[g(x):=C\cdot(\sigma\circ(Ax+b))-\beta x\] \[\sup_{x\in K}\|f(x)-g^{\prime}(x)\|<\varepsilon\]

Proof.: Given the mapping \(f\), by UAT, there exists \(A,b,C\) that approximate \(f(x)\). Construct \(\tilde{C}\in\mathbb{R}^{k}\) and \(\beta\in\mathbb{R}\), such that

\[\tilde{C}_{j}=\begin{cases}C_{j}/A_{col,j},&A_{col,j}\neq 0\\ 0,&A_{col,j}=0\end{cases},\qquad\text{and}\quad\beta=\sum_{j|A_{col,j}=0}C_{j} \sigma(b_{j})\]

Then,

\[\sup_{x\in K}\|f(x)-C\cdot(\sigma\circ(A\cdot x+b))\|\] \[=\sup_{x\in K}\left\|f(x)-\sum_{j=1}^{k}C_{j}(\sigma(A_{j}\cdot x +b_{j}))\right\|\] \[=\sup_{x\in K}\left\|f(x)-\sum_{j=1}^{k}\tilde{C}_{j}(\sigma(A_{ j}\cdot x+b_{j})A_{col,j})-\sum_{j|A_{col,j}=0}C_{j}\sigma(b_{j})\right\|\] \[=\sup_{x\in K}\|f(x)-\tilde{C}\cdot(\sigma^{\prime}\circ(A\cdot x +b)\circ A_{col})-\beta\|,\]

Note that \(\tilde{C}\cdot(\sigma^{\prime}\circ(A\cdot x+b)\circ A_{col})-\beta=\frac{d}{ dx_{col}}\Big{(}\tilde{C}\cdot(\sigma\circ(Ax+b))-\beta x\Big{)}\), which is the derivative net of a two-layer feedforward integral network.

## Appendix F Relationship between Number of ProNets and Model Expressivity

We applied ten summations of positive ProNets to fit the non-multiplicative-decomposable function \(\sin(x)\cos(y)\sin(z)+1\).

Each of these ProdNets consists of three MLP components, each with two hidden layers with 128 dimensions. All models underwent training with a consistent learning rate set at 0.005.

Our results, shown in Figure 9, indicate that increasing the number of ProdNets generally improves the model's performance in fitting the non-decomposable function. The model with the best MSE

Figure 9: Training MSE for fitting a positive derivative network to \(\sin(x)\cos(y)\sin(z)+1\)uses 10 ProMNets, while the model with 2 ProMNets had the second-worst performance. This result is intuitively sensible, as more linear terms are typically required to express an arbitrary function precisely. However, we observed that employing more ProMNets does not always lead to better performance, as demonstrated by the model with 8 ProMNets.