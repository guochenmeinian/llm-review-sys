# Truthfulness of Calibration Measures

 Nika Haghtalab, Mingda Qiao, Kunhe Yang, and Eric Zhao

University of California, Berkeley

{nika,mingda.qiao,kunheyang,eric.zh}@berkeley.edu

###### Abstract

We study calibration measures in a sequential prediction setup. In addition to rewarding accurate predictions (completeness) and penalizing incorrect ones (soundness), an important desideratum of calibration measures is _truthfulness_, a minimal condition for the forecaster not to be incentivized to exploit the system. Formally, a calibration measure is truthful if the forecaster (approximately) minimizes the expected penalty by predicting the conditional expectation of the next outcome, given the prior distribution of outcomes. We conduct a taxonomy of existing calibration measures. Perhaps surprisingly, all of them are far from being truthful. We introduce a new calibration measure termed the _Subsampled Smooth Calibration Error (SSCE)_, which is complete and sound, and under which truthful prediction is optimal up to a constant multiplicative factor. In contrast, under existing calibration measures, there are simple distributions on which a polylogarithmic (or even zero) penalty is achievable, while truthful prediction leads to a polynomial penalty.

## 1 Introduction

Probability forecasting is a central prediction task to a wide range of domains and applications, such as finance, meteorology, and medicine [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]. For forecasts to be useful, a common minimum requirement is that they are _calibrated_, i.e., the predictions are unbiased conditioned on the predicted value. Formally, for a sequence of \(T\) binary events, a forecaster who predicts probabilities in \([0,1]\) is _perfectly calibrated_ if for every \(\alpha\in[0,1]\), among the time steps on which \(\alpha\) is predicted, an \(\alpha\) fraction of the outcomes is indeed \(1\). Since perfectly calibrated forecasts are often unachievable, _calibration measures_ have been introduced to quantify some form of deviation from perfectly calibrated forecasts. Common examples of these measures include the expected calibration error (ECE) [10], the smooth calibration error [10], and the distance from calibration [1].

As these calibration measures are commonly used to evaluate the performance of forecasters, it is important that their use encourages forecasters to incorporate the highest quality information available to them (e.g., via their expert knowledge or side information) about the next outcome. This desideratum, formally referred to as _truthfulness_, requires that a calibration measure incentivizes the forecasters to predict truthfully when the true distribution of the next outcome is known to them. Lack of truthfulness can have severe consequences: it serves as a poor measure of quality of forecasts, tempts forecasters to make deliberately biased predictions in order to game the system, and erodes trust in predictions provided by third-party forecasters. _Given the importance of truthfulness, we set out to identify calibration measures that demonstrate truthfulness._

While truthfulness of calibration measures has not been systematically investigated to date, evidence of the lack of truthfulness of some calibration measures has emerged in recent literature. For example, [14, 15] noted that a forecaster can lower their ECE by predicting according to the past. This observation was applied in the algorithm of [14] and motivated the "sidestepping" technique in the lower bound proof of [15]. More recently, [16] highlighted a large gap in the truthfulness of a recently proposed calibration measure (called the _distance from calibration_[1]) byshowing that in a simple setup of predicting i.i.d. outcomes, the truthful forecaster incurs a distance of \(\Omega(\sqrt{T})\) from calibration but there is a forecasting algorithm that achieves \(\operatorname{polylog}(T)\) distance from calibration. We call this a \(\operatorname{polylog}(T)\)-\(\Omega(\sqrt{T})\)_truthfulness gap_. On the other hand, we say that a calibration measure is \((\alpha,\beta)\)-truthful if predicting the next outcome according to its conditional distribution incurs a measure that is no more than \(\alpha\mathsf{OPT}+\beta\), where \(\mathsf{OPT}\) is the minimum value of the calibration measure achievable by any forecaster. Faced with evidence that some calibration measures suffer from large truthfulness gaps, we will systematically examine the truthfulness (or a gap thereof) of a wide range of calibration measures.

For a truthful calibration measure to also be useful it must distinguish accurate predictions from inaccurate ones. After all, a measure that is uniformly \(0\) regardless of the quality of predictions is perfectly truthful (formally \((1,0)\)-truthful) but provides no insights into the quality of the predictions. We formalize the minimum requirement for a measure to be useful by its _completeness_ and _soundness_ when predicting i.i.d. Bernoulli outcomes. The former requires that predicting the outcomes according to the correct parameter of the generating Bernoulli distribution incurs no or \(o(T)\) penalty, whereas the latter requires the penalty to be \(\Omega(T)\) when predictions systematically deviate from the correct parameter. An equally important feature of a calibration measure is that it defines an ideal that could be asymptotically achieved for all prediction tasks. This is formalized by the existence of forecasting algorithms with an \(o(T)\) penalty in the adversarial sequential prediction setting [13], where the sequence of outcomes is produced by an adaptive adversary.

With these desiderata in place (namely truthfulness, soundness, completeness, and asymptotic calibration), we ask _whether there are calibration measures that simultaneously satisfy all these criteria?_ We answer this question in three parts:

**Part I: We show that existing calibration measures do not simultaneously meet these criteria.** We conduct a taxonomy of several existing calibration measures in terms of their completeness, soundness and truthfulness (formally defined in Section 2). We show that almost all of them have large _truthfulness gaps_: There are simple distributions on which an \(O(1)\) (or even zero) penalty is achievable, while truthful predictions lead to a \(\operatorname{poly}(T)\) penalty; see Table 1 for details.

Indeed, this lack of truthfulness is not limited to specific or contrived distributions. In the next theorem which we will prove in Appendix B, we strengthen these findings by showing that a commonly used notion of calibration systematically suffers large truthfulness gaps in most forecasting instances.

**Theorem 1.1** (Informal).: _For every product distribution with marginals bounded away from \(0\) and \(1\), the truthful forecaster incurs \(\Omega(\sqrt{T})\) smooth calibration error but there exists a forecasting algorithm that incurs only \(\operatorname{polylog}(T)\) smooth calibration error._

A notable exception in Table 1 is the class of calibration measures induced by _proper scoring rules_, i.e., loss functions for probabilistic predictions that are optimized by truthful forecasts. By definition, these calibration measures are \((1,0)\)-truthful. However, none of them is complete: as we show in Appendix A, even on i.i.d. Bernoulli trials, the optimal and truthful predictions incur an \(\Omega(T)\) penalty.

**Part II: We introduce a new calibration measure, called SSCE, that is sound, complete, and approximately truthful.** We do this using a simple adjustment to an existing notion of calibration measure: we _subsample_ a subset of the time steps and evaluate the _smooth calibration error_[12] on this sampled set only. We call this the _Subsampled Smooth Calibration Error (SSCE)_ and formally define it in Section 2. Our main result is that SSCE is \((O(1),0)\)-truthful.

**Theorem 1.2** (Main Theorem).: _There exists a universal constant \(c>0\) such that the SSCE is \((c,0)\)-truthful. Furthermore, the SSCE is complete and sound._

As shown in Table 1, to the best of our knowledge, SSCE is the first calibration measure that simultaneously achieves completeness, soundness, and non-trivial truthfulness.

While our methodology for constructing this calibration measure is simple, the analytical steps required to establish the \((O(1),0)\)-truthfulness guarantee are far from simple. We dedicate most of the main body of this paper to illustrating the proof ideas in a series of warmups to Theorem 1.2.

**Part III: There is a forecasting algorithm that achieves \(O(\sqrt{T})\) SSCE even in the adversarial setting.** While our study of truthfulness of calibration measures is necessarily focused on when the forecaster knows the conditional distribution of the next outcome, it is important to ensure that, even in the adversarial setting, a sublinear penalty can be achieved for this calibration measure. For this, we study the sequential calibration setting (e.g., [12]) where the outcome at time \(t\) is chosen by an adaptive adversary who has observed the sequence of earlier outcomes and predictions. We show that an \(O(\sqrt{T})\) SSCE is achievable.

**Theorem 1.3**.: _In the adversarial sequential calibration setting, there is a deterministic strategy for the forecaster that achieves an \(O(\sqrt{T})\) SSCE._

An interesting and important feature of this result is that it achieves an \(O(\sqrt{T})\) rate whereas an \(O(\sqrt{T})\) rate for the expected calibration error is known to be impossible to achieve [13]. Together our Theorems 1.2 and 1.3 establish that SSCE is a truthful and useful calibration measure.

### Related Work

There is a large body of work on calibration, a notion that dates back to the 1950s [1, 10, 11] and has been applied to game theory [12, 13], machine learning [10], and algorithmic fairness [1, 13, 14, 15]. We will restrict our discussion to sequential calibration and the systematic study of calibration measures, which are the closest to this work.

Sequential calibration.Foster and Vohra [12] first proved that one can achieve _asymptotic calibration_ on arbitrary and adaptive outcomes. Formally, they gave a forecasting algorithm with an \(O(T^{2/3})\) ECE in expectation, when predicting \(T\) binary outcomes chosen by an adaptive adversary. Subsequent work gave alternative and simpler proofs of the result [11, 12, 13], extended the result to other calibration measures [1, 13, 14, 15], and proved lower bounds on the optimal ECE [13]. Most closely related to our approach is the work of [12], who studied a stronger notion that requires calibration on a family of _checking rules_, where each checking rule specifies a subset of the time horizon. Despite the apparent similarity, their notion is qualitatively different from the SSCE, since we take an expectation over the subsampled horizon, whereas they take the maximum. In particular, no forecaster can be calibrated in their definition if the checking rule family contains all subsets of \([T]\), since there always exists a checking rule that strongly correlates with the outcomes.

Calibration measures.The recent work of Blasiok, Gopalan, Hu and Nakkiran [1] initiated the rigorous study of calibration measures. Their work focused on the offline setup, where there is a known marginal distribution over the feature space, and each predictor maps the feature space to \([0,1]\). They proposed to use the _distance from calibration_--the \(\ell_{1}\) distance from the predictor to the closest predictor that is perfectly calibrated--as the ground truth, and studied whether existing

\begin{table}
\begin{tabular}{|c|c|c|c|} \hline Calibration Measure & Complete? & Sound? & Truthful? \\ \hline Expected Calibration Error, Maximum Swap Regret & ✓ & ✓ & \(0\)-\(\Omega(T)\) gap \\ \hline Smooth Calibration, Distance from Calibration, & ✓ & ✓ & \(0\)-\(\Omega(\sqrt{T})\) gap \\ Interval Calibration, Laplace-Kernel Calibration & ✓ & ✓ & \(O(1)\)-\(\Omega(\sqrt{T})\) gap \\ \hline U-Calibration Error & ✓ & ✓ & \(O(1)\)-\(\Omega(\sqrt{T})\) gap \\ \hline Proper Scoring Rules & \(\times\) & ✓ & \((1,0)\)-truthful \\ \hline \hline
**Subsampled Smooth Calibration Error** & ✓ & ✓ & \((O(1),0)\)-truthful \\ \hline \end{tabular}
\end{table}
Table 1: Evaluation of existing calibration measures along with SSCE, in terms of completeness, soundness and truthfulness (Definitions 2.2 and 2.5). An \(\alpha\)-\(\beta\) truthfulness gap means that there is a prediction instance on which forecasting according to the true conditional distribution of the next outcome incurs more than \(\beta\) penalty, but there is a forecasting strategy that incurs at most \(\alpha\) penalty. See Appendix A for more details.

calibration measures are consistent with it. Note that completeness and soundness are defined differently in [1]: a calibration measure is called complete (resp., sound) if it is upper (resp., lower) bounded by a polynomial of the distance from calibration. Since the distance from calibration is far from being truthful in the online setup (as shown by [13]), our definition of completeness and soundness set up minimal conditions for an error metric to be regarded as measuring calibration, rather than enforcing closeness to the distance from calibration.

Subsampling.Our new calibration measure is derived from subsampling the time horizon. This simple idea has been shown to be effective in various different contexts, including privacy amplification in differential privacy (e.g.,[14, Section 6]), handling adversarial corruptions [1], as well as adaptive data analysis [1].

Proper scoring rules.Proper scoring rules [15] are error metrics for probabilistic forecasts that are optimized when the forecaster predicts according to the true distribution. While the error metrics induced by proper scoring rules are (perfectly) truthful by definition, as we show in Appendix A, they are qualitatively different from the usual calibration measures and, in particular, do not meet the completeness criterion. We note that a recent line of work [13, 10, 11, 12] studied the _optimization of scoring rules_, namely, finding the proper scoring rule that maximally incentivizes the forecaster to exert effort to obtain additional information.

## 2 Preliminaries

Sequential prediction.We consider the following prediction setup: First, a sequence \(x\in\{0,1\}^{T}\) is sampled from distribution \(\mathcal{D}\). At each step \(t\in[T]\), the forecaster makes a prediction \(p_{t}\in[0,1]\), after which \(x_{t}\) is revealed. Formally, a deterministic forecaster is a function \(\mathcal{A}:\bigcup_{t=1}^{T}\{0,1\}^{t-1}\to[0,1]\), where \(\mathcal{A}(b_{1},b_{2},\ldots,b_{t-1})\) specifies the forecaster's prediction at step \(t\) if the first \(t-1\) observations match \(b_{1:(t-1)}\). Distribution \(\mathcal{D}\) and forecaster \(\mathcal{A}\) naturally induce a joint distribution of \((x,p)\in\{0,1\}^{T}\times[0,1]^{T}\) via sampling \(x\sim\mathcal{D}\) and predicting \(p_{t}=\mathcal{A}(x_{1},x_{2},\ldots,x_{t-1})\).

Note that we could have defined the forecaster as a function of both the outcomes \(x_{1:(t-1)}\) and the predictions \(p_{1:(t-1)}\) in the past. This alternative definition is equivalent to ours, since \(p_{1:(t-1)}\) would be uniquely determined by \(x_{1:(t-1)}\). We could also have considered _randomized_ forecasters, which are specified by distributions over deterministic forecasters. However, as we will see later, restricting our attention to deterministic forecasters does not affect the subsequent definitions.

Calibration measures.The quality of the forecaster's predictions in the setting above is quantified by calibration measures. Formally, a calibration measure \(\mathsf{CM}\) is a family of functions \(\{\mathsf{CM}_{T}:T\in\mathbb{N}\}\), where each \(\mathsf{CM}_{T}\) maps \(\{0,1\}^{T}\times[0,1]^{T}\) to \([0,T]\). We will frequently omit the subscript \(T\), since it is usually clear from the context. With respect to calibration measure \(\mathsf{CM}\), the expected penalty incurred by forecaster \(\mathcal{A}\) on distribution \(\mathcal{D}\) is defined as \(\mathsf{err}_{\mathsf{CM}}(\mathcal{D},\mathcal{A})\coloneqq\mathbb{E}_{(x,p )\sim(\mathcal{D},\mathcal{A})}\left[\mathsf{CM}(x,p)\right]\), where \((x,p)\sim(\mathcal{D},\mathcal{A})\) denotes sampling a sequence \(x\) and predictions \(p\) from the joint distribution induced by \(\mathcal{D}\) and \(\mathcal{A}\).

One example of calibration measures is the _smooth calibration error_ introduced by [10] that is defined as \(\mathsf{smCE}(x,p)\coloneqq\sup_{f\in\mathcal{F}}\sum_{t=1}^{T}f(p_{t})(x_{t} -p_{t}),\) where \(\mathcal{F}\) is the family of \(1\)-Lipschitz functions from \([0,1]\) to \([-1,1]\). In this work, we introduce a new calibration measure called _Subsampled Smooth Calibration Error (SSCE)_ that is defined by subsampling a subset of the time horizon, and evaluating the smooth calibration error on it. We will formally define this measure next. In the following, \(\mathsf{Unif}(S)\) denotes the uniform distribution over a finite set \(S\). For a \(T\)-dimensional vector \(x\) and \(S\subseteq[T]\), \(x|_{S}\) denotes the \(|S|\)-dimensional vector formed by the entries of \(x\) indexed by \(S\).

**Definition 2.1** (Subsampled Smooth Calibration Error).: _For a sequence of outcomes \(x\in\{0,1\}^{T}\) and predictions \(p\in[0,1]^{T}\), the Subsampled Smooth Calibration Error (SSCE) is defined as_

\[\mathsf{SSCE}(x,p)\coloneqq\operatorname*{\mathbb{E}}_{S\sim\mathsf{Unif}(2^{ \lvert T\rvert})}\left[\mathsf{smCE}(x|_{S},p|_{S})\right]=\operatorname*{ \mathbb{E}}_{y\sim\mathsf{Unif}(\{0,1\}^{T})}\left[\sup_{f\in\mathcal{F}} \sum_{t=1}^{T}y_{t}\cdot f(p_{t})\cdot(x_{t}-p_{t})\right].\]

Completeness and soundness.We give minimal conditions for a calibration measure to be regarded as complete (intuitively "accurate" predictions have a small penalty) and sound (intuitively "inaccurate" predictions have a large penalty).

**Definition 2.2** (Completeness and soundness).: _A calibration measure \(\mathsf{CM}\) is complete if: (1) For any \(x\in\{0,1\}^{T}\), \(\mathsf{CM}_{T}(x,x)=0\); (2) For any \(\alpha\in[0,1]\), \(\mathbb{E}_{x_{1},\ldots,x_{T}\sim\mathsf{Bernoulli}(\alpha)}\left[\mathsf{CM}_{ T}(x,\alpha\cdot\vec{1}_{T})\right]=o_{\alpha}(T)\). The calibration measure is sound if: (1) For any \(x\in\{0,1\}^{T}\), \(\mathsf{CM}_{T}(x,\vec{1}_{T}-x)=\Omega(T)\); (2) For any \(\alpha,\beta\in[0,1]\) such that \(\alpha\neq\beta\), \(\mathbb{E}_{x_{1},\ldots,x_{T}\sim\mathsf{Bernoulli}(\alpha)}\left[\mathsf{CM} _{T}(x,\beta\cdot\vec{1}_{T})\right]=\Omega_{\alpha,\beta}(T)\). Here, \(o_{\alpha}(\cdot)\) and \(\Omega_{\alpha,\beta}(\cdot)\) may hide constant factors that depend on the parameters in the subscript._

Truthfulness.To define the truthfulness of a calibration measure, we introduce the _truthful forecaster_ and the _optimal error_ for a distribution \(\mathcal{D}\).

**Definition 2.3** (Truthful forecaster).: _With respect to distribution \(\mathcal{D}\in\Delta(\{0,1\}^{T})\), the truthful forecaster is defined as \(\mathcal{A}^{\mathrm{truthful}}(\mathcal{D})(b_{1},b_{2},\ldots,b_{t-1})\coloneqq \mathrm{Pr}_{x\sim\mathcal{D}}\left[x_{t}=1\,\left|\,x_{1:(t-1)}=b_{1:(t-1)}\right]\)._

Arguably, \(\mathcal{A}^{\mathrm{truthful}}(\mathcal{D})\) is the only forecaster that makes the "right" predictions on distribution \(\mathcal{D}\).

**Definition 2.4** (Optimal error).: _The optimal error on distribution \(\mathcal{D}\in\Delta(\{0,1\}^{T})\) with respect to calibration measure \(\mathsf{CM}\) is defined as \(\mathsf{OPT}_{\mathsf{CM}}(\mathcal{D})\coloneqq\inf_{\mathcal{A}}\mathsf{ err}_{\mathsf{CM}}(\mathcal{D},\mathcal{A})\), where \(\mathcal{A}\) ranges over all deterministic forecasters._

Note that by an averaging argument, the definition of \(\mathsf{OPT}_{\mathsf{CM}}(\mathcal{D})\) is unchanged if we take an infimum over randomized forecasters.

A calibration measure is truthful if, on every distribution, the truthful forecaster is near-optimal.

**Definition 2.5** (Truthfulness of calibration measures).: _A calibration measure \(\mathsf{CM}\) is \((\alpha,\beta)\)-truthful if, for every \(\mathcal{D}\in\Delta(\{0,1\}^{T})\), \(\mathsf{err}_{\mathsf{CM}}(\mathcal{D},\mathcal{A}^{\mathrm{truthful}}( \mathcal{D}))\leq\alpha\cdot\mathsf{OPT}_{\mathsf{CM}}(\mathcal{D})+\beta\). Conversely, \(\mathsf{CM}\) is said to have an \(\alpha\)-\(\beta\) truthfulness gap if, for some distribution \(\mathcal{D}\), \(\mathsf{OPT}_{\mathsf{CM}}(\mathcal{D})\leq\alpha\) and \(\mathsf{err}_{\mathsf{CM}}(\mathcal{D},\mathcal{A}^{\mathrm{truthful}}( \mathcal{D}))\geq\beta\)._

## 3 Technical Overview

In this section, we briefly discuss the main technical ideas and challenges behind the proofs of Theorems 1.1, 1.2, and 1.3. We provide more details on our main result, i.e., that SSCC is \((O(1),0)\)-truthful, in Sections 4 through 6. Theorem 1.3 follows from a recent result of [1] on minimizing the distance from calibration in the adversarial setup, along with a new result connecting SSCE to distance from calibration, and is proved in Section 7. We defer the proof of Theorem 1.1 to Appendix B.

A simple distribution that witnesses truthfulness gaps.Inspired by [15, Example 2], we consider the distribution \(\mathcal{D}\) specified as follows: The time horizon is divided into \(T/3\) blocks of length \(3\), each with a uniformly random bit, followed by a zero and a one. Within each block, the truthful forecaster predicts \(1/2\), \(0\) and \(1\) in order. Then, among the steps on which \(1/2\) is predicted, the frequency of ones is typically \(1/2\pm\Theta(1/\sqrt{T})\). This deviation results in a \(\Theta(\sqrt{T})\) penalty under most calibration measures (concretely, all calibration measures in the first two rows of Table 1).

However, there is a different strategy that ensures perfect calibration, and thus a zero penalty under most calibration measures. Within each block, the forecaster predicts \(1/2\) on the first step. If the bit turns out to be \(1\), the forecaster maintains perfect calibration by predicting \(1/2\) on the second step, on which the outcome is known to be \(0\); otherwise, the forecaster accomplishes the same by predicting \(1/2\) on the third step. Therefore, the distribution \(\mathcal{D}\) witnesses a \(0\)-\(\Omega(\sqrt{T})\) truthfulness gap for every calibration measure in the first two rows of Table 1.

The importance of subsampling in the SSCE becomes apparent in light of the example above. On distribution \(\mathcal{D}\), the truthful forecaster has to pay a \(\Theta(\sqrt{T})\) cost for the mild deviation from the expectation, while a strategic forecaster avoids this deviation by correlating the predictions with the biases in the past. With the subsampling, however, the forecaster is no longer sure about the biases that factor into the penalty. This ensures that, compared to truth-telling, the benefit from predicting strategically is marginal, and thus makes the truthfulness guarantee in Theorem 1.2 possible.

Establishing truthfulness via martingale inequalities.We prove that the SSCE is \((O(1),0)\)-truthful in three steps: (1) Define a complexity measure \(\sigma(\mathcal{D})\) of distribution \(\mathcal{D}\); (2) Show that \(\mathsf{err}_{\mathsf{SSCE}}(\mathcal{D},\mathcal{A}^{\mathrm{truthful}}( \mathcal{D}))=O(\sigma(\mathcal{D}))\); (3) Show that \(\mathsf{OPT}_{\mathsf{SSCE}}(\mathcal{D})=\Omega(\sigma(\mathcal{D}))\).

As we elaborate in Section 5, the crux of Step (2) is to control the expected deviation of a martingale \((M_{t})_{0\leq t\leq T}\) with respect to filtration \((\mathbb{F}_{t})\) by the its _realized variance_\(\mathrm{Var}_{t}\coloneqq\sum_{s=1}^{t}\mathrm{Var}\left[M_{s}|\mathbb{F}_{s- 1}\right]\), which is highly non-trivial as the two processes \((M_{t})\) and \((\mathrm{Var}_{t})\) are correlated. In more detail, the filtration \((\mathbb{F}_{t})\) corresponds to the randomness in \(x\sim\mathcal{D}\), while \((M_{t})\) tracks the biases in the predictions (on a subset of the time horizon) tested by a Lipschitz function. We note that such a bound would easily follow from "off-the-shelf" concentration inequalities for martingales (e.g., Freedman's inequality [10]), if the total realized variance \(\mathrm{Var}_{T}\) were uniformly bounded. However, in general, \(\mathrm{Var}_{T}\) may vary drastically, and directly applying these concentration inequalities would introduce an extra super-constant factor. Our workaround is a "doubling trick" that divides the time horizon into _epochs_, the realized variances in which grow exponentially. We then apply Freedman's inequality to each epoch separately. In Section 5, we formulate a toy random walk problem that highlights this challenge and demonstrates our solution to it, which is of independent interest.

Similarly, as we show in Section 6, the crux of Step (3) is to establish another martingale inequality. We first show that for fixed \(x\) and \(p\), we have \(\mathsf{SSCE}(x,p)=\Omega(\sqrt{N_{T}})\), where \(N_{t}\coloneqq\sum_{s=1}^{t}\mathds{1}\left[|x_{s}-p_{s}|\geq 1/2\right]\). Furthermore, over the randomness in \(x\sim\mathcal{D}\), the realized variance process \((\mathrm{Var}_{t})\) defined above is shown to lower bound \((N_{t})\), i.e., \((N_{t}-\mathrm{Var}_{t})\) is a sub-martingale. However, the desired result requires the lower bound \(\mathbb{E}\left[\sqrt{N_{T}}\right]\geq\Omega(1)\cdot\mathbb{E}\left[\sqrt{ \mathrm{Var}_{T}}\right]\), which does _not_ follow from \(\mathbb{E}\left[N_{T}-\mathrm{Var}_{T}\right]\geq 0\) in general. This challenge necessitates a more careful analysis tailored to the specific properties of the processes \((N_{t})\) and \((\mathrm{Var}_{t})\).

Deterministic forecasting strategy via reduction to \(\mathsf{smCE}\).We build on the result of [1] showing the existence of a deterministic forecasting strategy guaranteeing an \(O(\sqrt{T})\) bound on \(\mathsf{smCE}\). In particular, we show via a standard chaining argument that \(\mathsf{SSCE}\) is upper bounded by \(\mathsf{smCE}\) plus a variance term that can be upper bounded by \(O(\sqrt{T})\). The result of [1] then implies a deterministic forecasting algorithm achieving an \(O(\sqrt{T})\)\(\mathsf{SSCE}\).

## 4 Warmup: The Product Distribution Case

As a warmup, in this section, we start by showing that \(\mathsf{SSCE}\) is \((O(1),O(\log T))\)-truthful for product distributions. This is a weaker version of Theorem 1.2 in terms of both the truthfulness parameters of \(\mathsf{SSCE}\) and the restriction to product distributions. In Sections 5 and 6, we outline how we will remove these restrictions and improve the analysis of truthfulness.

For distribution \(\mathcal{D}=\prod_{t=1}^{T}\mathsf{Bernoulli}(p_{t}^{\star})\), take \(\sigma^{2}\coloneqq\mathrm{Var}_{x\sim\mathcal{D}}\left[\sum_{t=1}^{T}x_{t} \right]=\sum_{t=1}^{T}p_{t}^{\star}(1-p_{t}^{\star})\) as a complexity measure of the distribution of outcomes. We will show that \(\mathsf{err}_{\mathsf{SSCE}}(\mathcal{D},\mathcal{A}^{\mathrm{truthful}}( \mathcal{D}))=O(\sigma+\log T)\) and \(\mathsf{OPT}_{\mathsf{SSCE}}(\mathcal{D})=\Omega(\sigma)-O(1)\).

### Upper Bound the SSCE of the Truthful Forecaster

We first show that the truthful forecaster for \(\mathcal{D}\), which predicts \(p_{t}=p_{t}^{\star}\) at every step \(t\), gives \(\mathbb{E}_{x\sim\mathcal{D}}\left[\mathsf{SSCE}(x,p^{\star})\right]=O(\sigma+ \log T)\). For this purpose, it suffices to prove

\[\mathbb{E}_{x\sim\mathcal{D}}\left[\mathsf{smCE}(x,p^{\star})\right]=O(\sigma +\log T),\] (1)

since for each fixed \(S\subseteq[T]\), applying (1) to \(x|_{S}\) and \(p^{\star}|_{S}\) gives \(\mathbb{E}_{x\sim\mathcal{D}}\left[\mathsf{smCE}(x|_{S},p^{\star}|_{S})\right] \leq O(\sigma+\log T)\), and taking an expectation over \(S\sim\mathsf{Unif}(2^{[T]})\) gives the desired bound on \(\mathsf{SSCE}\).

Recall that \(\mathbb{E}\left[\mathsf{smCE}(x,p^{\star})\right]=\mathbb{E}\left[\sup_{f\in \mathcal{F}}\sum_{t=1}^{T}f(p_{t}^{\star})\cdot(x_{t}-p_{t}^{\star})\right]\). If we replace \(\mathcal{F}\) with the family of _constant_ functions from \([0,1]\) to \([-1,1]\), the right-hand side would reduce to

\[\mathbb{E}_{x\sim\mathcal{D}}\left[\left|\sum_{t=1}^{T}(x_{t}-p_{t}^{\star}) \right|\right]\leq\sqrt{\mathbb{E}_{x\sim\mathcal{D}}\left[\left(\sum_{t=1}^{T }(x_{t}-p_{t}^{\star})\right)^{2}\right]}=\sqrt{\mathrm{Var}_{x\sim\mathcal{D} }\left[\sum_{t=1}^{T}x_{t}\right]}=\sigma.\]Therefore, to prove the upper bound in (1), we need to show that the family of one-dimensional Lipschitz functions is not significantly richer than constant functions.

At a high level, this is done by taking finite coverings of Lipschitz functions and using Dudley's chaining technique [1] to upper bound the value of this stochastic process. In more detail, let \(\mathcal{F}_{\delta}\) be the smallest \(\delta\)-covering of \(\mathcal{F}\) in the uniform norm, i.e., for each \(f\in\mathcal{F}\), there exists \(f_{\delta}\in\mathcal{F}_{\delta}\) such that \(\|f-f_{\delta}\|_{\infty}\leq\delta\). It is well-known that \(|\mathcal{F}_{\delta}|=e^{O(1/\delta)}\), and a chaining argument gives

\[\operatorname*{\mathbb{E}}_{x\sim\mathcal{D}}\left[\sup_{f\in\mathcal{F}}\sum_ {t=1}^{T}f(p_{t}^{\star})\cdot(x_{t}-p_{t}^{\star})\right]\leq 1+\sum_{k=0}^{O( \log T)}\operatorname*{\mathbb{E}}_{x\sim\mathcal{D}}\left[\max_{g\in \mathcal{G}_{2^{-k}}}\sum_{t=1}^{T}g(p_{t}^{\star})\cdot(x_{t}-p_{t}^{\star}) \right],\] (2)

where \(\mathcal{G}_{\delta}\coloneqq\{f_{\delta}-f_{\delta/2}:f_{\delta}\in\mathcal{ F}_{\delta},f_{\delta/2}\in\mathcal{F}_{\delta/2},\|f_{\delta}-f_{\delta/2}\|_{ \infty}\leq 3\delta/2\}\).

It remains to bound the second term of (2). Note that for a fixed \(g\), because of the independence of \(x_{t}\)s, \(g(p_{t}^{\star})\cdot(x_{t}-p_{t}^{\star})\) is independent across \(t\in[T]\). Therefore, we can control the tail probability of \(\sum_{t=1}^{T}g(p_{t}^{\star})\cdot(x_{t}-p_{t}^{\star})\) by Bernstein inequalities. For each fixed \(\delta\), using a Bernstein tail bound, taking a union bound over \(g\in\mathcal{G}_{\delta}\), and noting that \(|\mathcal{G}_{\delta}|\leq|\mathcal{F}_{\delta}|\cdot|\mathcal{F}_{\delta/2}| =e^{O(1/\delta)}\), we have

\[\operatorname*{\mathbb{E}}_{x\sim\mathcal{D}}\left[\max_{g\in\mathcal{G}_{ \delta}}\sum_{t=1}^{T}g(p_{t}^{\star})\cdot(x_{t}-p_{t}^{\star})\right]\leq O (\delta)\cdot O\left(\sqrt{\sigma^{2}\log|\mathcal{G}_{\delta}|}+\log| \mathcal{G}_{\delta}|\right)=O(\sigma\sqrt{\delta}+1).\]

Plugging this into (2) proves (1) and thus the desired bound \(\operatorname*{\mathbb{E}}_{x\sim\mathcal{D}}\left[\mathsf{SSCE}(x,p^{\star}) \right]=O(\sigma+\log T)\).

### Lower Bound the Optimal SSCE

Next, we lower bound \(\mathsf{OPT}_{\mathsf{SSCE}}(\mathcal{D})\) by showing that _every_ forecasting strategy must incur an \(\Omega(\sigma)\) SSCE on \(\mathcal{D}\). Recall that \(\mathsf{SSCE}(x,p)\) is given by

\[\operatorname*{\mathbb{E}}_{y\sim\mathsf{Unif}(\{0,1\}^{T})}\left[\sup_{f\in \mathcal{F}}\sum_{t=1}^{T}y_{t}\cdot f(p_{t})\cdot(x_{t}-p_{t})\right]\geq \operatorname*{\mathbb{E}}_{y\sim\mathsf{Unif}(\{0,1\}^{T})}\left[\left|\sum_{ t=1}^{T}y_{t}\cdot(x_{t}-p_{t})\right|\right],\]

where we use the fact that \(\mathcal{F}\) contains the constant functions \(1\) and \(-1\).

Fix \(x\in\{0,1\}^{T}\), \(p\in[0,1]^{T}\) and let \(N\coloneqq\sum_{t=1}^{T}\mathbbm{1}\left[|x_{t}-p_{t}|\geq 1/2\right]\). Over the randomness in \(y\sim\mathsf{Unif}(\{0,1\}^{T})\), the quantity \(\sum_{t=1}^{T}y_{t}\cdot(x_{t}-p_{t})\), by the central limit theorem, is approximately distributed as a normal distribution with variance \(\sum_{t=1}^{T}\frac{1}{4}(x_{t}-p_{t})^{2}\geq\sum_{t=1}^{T}\frac{1}{16} \mathbbm{1}\left[|x_{t}-p_{t}|\geq 1/2\right]=\Omega(N)\), so its expected absolute value is \(\Omega(\sqrt{N})\).

Now it remains to lower bound the expectation of \(\sqrt{N}\) induced by an arbitrary forecaster. Conditioning on \(x_{1:(t-1)}\), \(x_{t}\) always follows \(\mathsf{Bernoulli}(p_{t}^{\star})\). Thus, regardless of the choice of \(p_{t}\in[0,1]\), the condition \(|x_{t}-p_{t}|\geq 1/2\) holds with probability at least \(\min\{p_{t}^{\star},1-p_{t}^{\star}\}\geq p_{t}^{\star}(1-p_{t}^{\star})\). Then, over the \(T\) steps, we expect that \(N\geq\Omega(\sum_{t=1}^{T}p_{t}^{\star}(1-p_{t}^{\star}))=\Omega(\sigma^{2})\) holds with probability \(\Omega(1)\), as long as \(\sigma=\Omega(1)\). This gives the desired lower bound \(\operatorname*{\mathbb{E}}\left[\mathsf{SSCE}(x,p)\right]\gtrsim\operatorname*{ \mathbb{E}}\left[\sqrt{N}\right]=\Omega(\sigma)-O(1)\).

## 5 Upper Bound the SSCE of the Truthful Forecaster

To extend the proof strategy sketched in Section 4 to non-product distributions, the first challenge is to define an appropriate complexity measure of a general distribution \(\mathcal{D}\). Consider the stochastic process \((\operatorname{Var}_{t})_{0\leq t\leq T}\) defined as \(\operatorname{Var}_{t}\coloneqq\sum_{s=1}^{t}p_{s}^{\star}(1-p_{s}^{\star})\), where \(x\sim\mathcal{D}\) and \(p_{t}^{\star}\coloneqq\operatorname*{\mathbb{E}}_{x^{\prime}\sim\mathcal{D}} \left[x_{t}^{\prime}\middle|x_{1:(t-1)}^{\prime}=x_{1:(t-1)}\right]\) is now a random variable that denotes the conditional expectation of \(x_{t}\) after observing \(x_{1:(t-1)}\). The "right" definition turns out to be roughly \(\sigma(\mathcal{D})\coloneqq\operatorname*{\mathbb{E}}\left[\sqrt{ \operatorname{Var}_{T}}\right]\). In this section, we prove the following weaker upper bound on the SSCE incurred by the truthful forecaster. We provide a stronger bound (Theorem C.1) in Appendix C.

**Theorem 5.1**.: _For any \(\mathcal{D}\in\Delta(\{0,1\}^{T})\), \(\mathsf{err}_{\mathsf{SSCE}}(\mathcal{D},\mathcal{A}^{\mathrm{truthful}}( \mathcal{D}))=O(\operatorname*{\mathbb{E}}\left[\sqrt{\operatorname{Var}_{T}} \right]+\log^{2}T)\)._

Proof sketch.: We begin by repeating the chaining argument in Section 4. Recall that, for any \(\delta>0\), there is a \(\delta\)-covering \(\mathcal{F}_{\delta}\) of \(\mathcal{F}\) in the \(\infty\)-norm that has size \(e^{O(1/\delta)}\). Letting \(\pi_{\delta}(f)\) denote the mappingof a function \(f\) onto the covering \(\mathcal{F}_{\delta}\) such that \(\left\|f-\pi_{\delta}(f)\right\|_{\infty}\leq\delta\), we can write for any \(M\in\mathbb{Z}_{+}\):

\[\mathsf{SSCE}(x,p)\leq 2^{-M}\cdot T+\underset{y\sim\mathsf{Unif}(\{0,1\}^{T})}{ \mathbb{E}}\left[\sum_{k=0}^{M}\underbrace{\sup_{f\in\mathcal{F}}\sum_{t=1}^ {T}y_{t}\cdot(\pi_{2^{-k}}(f)(p_{t})-\pi_{2^{1-k}}(f)(p_{t}))\cdot(x_{t}-p_{t} )}_{=W_{k}}\right].\]

To control the expectation of each \(W_{k}\), we note that the set \(\mathcal{G}_{k}\coloneqq\{\pi_{2^{-k}}(f)-\pi_{2^{1-k}}(f):f\in\mathcal{F}\}\) is of size at most \(|\mathcal{F}_{2^{-k}}|\cdot|\mathcal{F}_{2^{1-k}}|\). Furthermore, every function \(g\in\mathcal{G}_{k}\) satisfies

\[\|g\|_{\infty}=\|\pi_{2^{-k}}(f)-\pi_{2^{1-k}}(f)\|_{\infty}\leq\|\pi_{2^{-k} }(f)-f\|_{\infty}+\|f-\pi_{2^{1-k}}(f)\|_{\infty}=O(2^{-k})\]

for some \(f\in\mathcal{F}\). We apply the following technical lemma, which we prove in Appendix C.

**Lemma 5.2**.: _Given a function \(f:[0,1]\to[-1,1]\) and \(y\in\{0,1\}^{T}\), consider the martingale \(M_{t}(f,y)\coloneqq\sum_{s=1}^{t}y_{s}\cdot f(p_{s}^{\star})\cdot(x_{s}-p_{s} ^{\star})\) where \(x\sim\mathcal{D}\). Then, for any finite family \(\mathcal{G}\) of functions from \([0,1]\) to \([-1,1]\) and any \(y\in\{0,1\}^{T}\), we have_

\[\underset{x\sim\mathcal{D}}{\mathbb{E}}\left[\max_{f\in\mathcal{G}}M_{T}(f,y) \right]\leq O\left(\log|\mathcal{G}|\cdot\log T+\sqrt{\log|\mathcal{G}|}\cdot \underset{x\sim\mathcal{D}}{\mathbb{E}}\left[\sqrt{\mathrm{Var}_{T}}\right] \right).\]

Applying Lemma 5.2 to each \(\mathcal{G}_{k}\) scaled up by a \(\Theta(2^{k})\) factor and noting that \(\log|\mathcal{G}_{k}|\leq\log|\mathcal{F}_{2^{-k}}|+\log|\mathcal{F}_{2^{1-k} }|=O(2^{k})\) gives

\[\mathsf{err}_{\mathsf{SSCE}}(\mathcal{D},\mathcal{A}^{\mathrm{ truthful}}(\mathcal{D})) \leq 2^{-M}\cdot T+\sum_{k=0}^{M}O(2^{-k})\cdot O\left(2^{k}\log T +2^{k/2}\underset{x\sim\mathcal{D}}{\mathbb{E}}\left[\sqrt{\mathrm{Var}_{T}} \right]\right)\] \[\leq 2^{-M}\cdot T+\sum_{k=0}^{M}O\left(\log T+2^{-k/2} \underset{x\sim\mathcal{D}}{\mathbb{E}}\left[\sqrt{\mathrm{Var}_{T}}\right]\right)\] \[\leq 2^{-M}\cdot T+O\left(M\log T+\underset{x\sim\mathcal{D}}{ \mathbb{E}}\left[\sqrt{\mathrm{Var}_{T}}\right]\right).\]

Choosing \(M=\Theta(\log T)\) proves the theorem. 

We remark that the proof of Lemma 5.2 is highly non-trivial. As mentioned in Section 3, such an upper bound would follow from Freedman's inequality, if \(\mathrm{Var}_{T}\) were _always_ bounded by \(O\left(\left(\mathbb{E}\left[\sqrt{\mathrm{Var}_{T}}\right]\right)^{2}\right)\). However, in general, applying Freedman's inequality to each \(M_{T}(f,y)\) necessarily requires an additional union bound over possible values of \(\mathrm{Var}_{T}\), and introduces a super-constant multiplicative factor.

The challenge in dealing with the randomness in \(\mathrm{Var}_{T}\) is captured by the following toy problem:

**Random walk with early stopping:** Let \((X_{t})_{0\leq t\leq T}\) be the random walk such that \(X_{0}=0\) and each \(X_{t}-X_{t-1}\) independently follows \(\mathsf{Unif}(\{\pm 1\})\). Let \(\tau\) be an arbitrary stopping time with respect to \((X_{t})\). Prove that \(\mathbb{E}\left[|X_{\tau}|\right]\leq O(1)\cdot\mathbb{E}\left[\sqrt{\tau}\right]\).

Indeed, the above corresponds to a special case of Lemma 5.2 in which: (1) the sequence \(p^{\star}\) starts with entry \(1/2\), and may switch to entry \(0\) at any point, depending on the realization of \(x_{t}\)s; (2) the family \(\mathcal{G}\) consists of two constant functions \(1\) and \(-1\).

One might be tempted to prove \(\mathbb{E}\left[|X_{\tau}|\right]\leq O(1)\cdot\mathbb{E}\left[\sqrt{\tau}\right]\) by first proving \(\mathbb{E}\left[|X_{\tau}||\tau=t\right]=O(\sqrt{t})\) for all \(t\in[T]\), and then applying the law of total expectation. Such an approach is doomed to fail, because the stopping time \(\tau\) might significantly bias the conditional expectation of \(|X_{\tau}|\) on some event \(\tau=t_{0}\), e.g., by stopping at time \(t_{0}\) only if \(|X_{t_{0}}|\gg\sqrt{t_{0}}\).

Our workaround is inspired by the standard doubling trick in online learning. We break the time horizon into _epochs_ of geometrically increasing lengths: the \(k\)-th epoch contains \(2^{k}\) steps. We break \(|X_{\tau}|\) into the displacements accumulated in different epochs; their sum clearly upper bounds \(|X_{\tau}|\)Furthermore, we can show that, conditioning on reaching epoch \(k\), the displacement within the epoch is \(O(\sqrt{2^{k}})\). This allows us to establish the desired inequality via

\[\mathbb{E}\left[\left|X_{\tau}\right|\right]\leq O(1)\cdot\sum_{k=1}^{O(\log T)} \Pr\left[\tau\text{ reaches epoch }k\right]\cdot\sqrt{2^{k}}\leq O(1)\cdot \mathbb{E}\left[\sqrt{\tau}\right].\]

To prove Lemma 5.2, we extend this technique to a general martingale \(M_{T}(f,y)\) by dividing the time horizon into epochs according to the doubling of \(\operatorname{Var}_{t}\), and then applying Freedman's inequality to each epoch.

Towards a stronger upper bound.In our actual proof, we use a slightly different complexity measure \(\sigma_{\gamma}(\mathcal{D})\coloneqq\mathbb{E}\left[\gamma(\operatorname{ Var}_{T})\right]\), where \(\gamma(x)=x\) if \(x<1\) and \(\gamma(x)=\sqrt{x}\) otherwise. Roughly speaking, this definition accounts for the fact that a sum of independent Bernoulli random variables behaves quite differently when its mean is close to \(0\). To remove the extra \(\log^{2}T\) term in Theorem 5.1, our actual proof also uses a variant of Lemma 5.2, Lemma C.9, which involves a more careful application of Freedman's inequality tailored to specific coverings of Lipschitz functions.

## 6 Lower Bound the Optimal SSCE

In this section, we outline a weaker lower bound on the optimal SSCE achievable on a distribution.

**Theorem 6.1**.: _For any \(\mathcal{D}\in\Delta(\{0,1\}^{T})\), \(\mathsf{OPT}_{\mathsf{SSCE}}(\mathcal{D})=\Omega(\mathbb{E}\left[\sqrt{ \operatorname{Var}_{T}}\right])-O(1)\)._

Similar to the product distribution case (Section 4), the key quantity in the proof is the stochastic process \((N_{t})_{0\leq t\leq T}\) defined as \(N_{t}\coloneqq\sum_{s=1}^{t}n_{s}\) and \(n_{t}\coloneqq\mathbbm{1}\left[\left|x_{t}-p_{t}\right|\geq 1/2\right]\). This is formalized by the following lemma, which applies to any realization of \(x\), \(p\), and \(N_{T}=\sum_{t=1}^{T}\mathbbm{1}\left[\left|x_{t}-p_{t}\right|\geq 1/2\right]\):

**Lemma 6.2**.: _For any \(x\in\{0,1\}^{T}\) and \(p\in[0,1]^{T}\), we have \(\mathsf{SSCE}(x,p)\geq\Omega\left(\sqrt{N_{T}}\right)\)._

It remains to lower bound the quantity \(\mathbb{E}\left[\sqrt{N_{T}}\right]\) induced by an arbitrary forecaster. As argued earlier, conditioning on \(x_{1:(t-1)}\), we always have \(\Pr\left[n_{t}=1\right]\geq p_{t}^{\star}(1-p_{t}^{\star})=\operatorname{Var }_{t}-\operatorname{Var}_{t-1}\), where \(p_{t}^{\star}\) and \(\operatorname{Var}_{t}\) are defined as in Section 5. Thus, \((N_{t}-\operatorname{Var}_{t})\) is a sub-martingale, which implies \(\mathbb{E}\left[N_{T}\right]\geq\mathbb{E}\left[\operatorname{Var}_{T}\right]\). However, this does _not_ imply that \(\mathbb{E}\left[\sqrt{N_{T}}\right]\geq\Omega(\mathbb{E}\left[\sqrt{ \operatorname{Var}_{T}}\right])\). In fact, such an inequality does _not_ hold in general: When \(p_{t}^{\star}=\varepsilon\ll 1\) and \(p_{t}^{\star}=0\) for all \(t\geq 2\), \(\mathbb{E}\left[\sqrt{N_{T}}\right]\) could be \(O(\varepsilon)\), yet \(\mathbb{E}\left[\sqrt{\operatorname{Var}_{T}}\right]=\Omega(\sqrt{\varepsilon})\gg O (\varepsilon)\).

The following technical lemma circumvents this counterexample by subtracting a constant term from the right-hand side:

**Lemma 6.3**.: _The stochastic process \((N_{t})_{t\in[T]}\) satisfies \(\mathbb{E}\left[\sqrt{N_{T}}\right]\geq\Omega(\mathbb{E}\left[\sqrt{ \operatorname{Var}_{T}}\right])-O(1)\)._

Note that Theorem 6.1 directly follows from Lemmas 6.2 and 6.3, which we prove in Appendix D.1. To avoid the extra \(-O(1)\) term in the lower bound, our actual proof (deferred to Appendix D.3) works with the slightly different complexity measure \(\sigma_{\gamma}(\mathcal{D})\coloneqq\mathbb{E}\left[\gamma(\operatorname{ Var}_{T})\right]\) defined in Section 5.

## 7 Forecasting with \(O(\sqrt{T})\) Ssce

In this section, we prove Theorem 1.3, which states the existence of a deterministic forecaster that incurs an \(O(\sqrt{T})\) SSCE against all adaptive adversaries. Recall the definition of the smooth calibration error (\(\mathsf{smCE}\)) from Section 2. Using standard chaining arguments, we can show the following relation between \(\mathsf{SSCE}\) and \(\mathsf{smCE}\), whose proof we defer to Appendix F.

**Lemma 7.1**.: _For any \(x\in\{0,1\}^{T}\) and \(p\in[0,1]^{T}\),_

\[\mathsf{SSCE}(x,p)\leq\frac{1}{2}\mathsf{smCE}(x,p)+O(\sqrt{T}),\]

_where the \(O(\cdot)\) notation hides a universal constant that does not depend on \(T\), \(x\) or \(p\)._

Theorem 1.3 follows from the lemma above and a recent result of [1].

Proof of Theorem 1.3.: It was shown by [1] that there exists a deterministic forecaster with an \(O(\sqrt{T})\) distance from calibration (\(\mathsf{CalDist}(x,p)\)) against every adaptive adversary in the adversarial sequential calibration setup. Lemma 7.1 together with the inequality \(\frac{1}{2}\mathsf{smCE}(x,p)\leq\mathsf{CalDist}(x,p)\) from [1, Lemma 5.4 and Theorem 7.3] implies that

\[\mathsf{SSCE}(x,p)\leq\mathsf{CalDist}(x,p)+O(\sqrt{T}),\]

so the same forecaster incurs an SSCE of \(O(\sqrt{T})\) as well. 

## 8 Discussion

We formulate three natural desiderata of calibration measures that evaluate the quality of probabilistic forecasts: truthfulness, completeness, and soundness. They serve as minimal requirements for an error metric to be considered as measuring calibration and not to create a significant incentive for forecasters to predict untruthfully. While existing calibration measures fail to simultaneously meet all these criteria, we propose the new calibration measure (SSCE) that is shown to be approximately truthful via a non-trivial analysis. In the following, we discuss two natural directions of future work.

Inherent trade-offs among different desiderata?As shown in Table 1, the SSCE and the error metrics induced by proper scoring rules give a trade-off between truthfulness and completeness: The former is complete and approximately truthful, while the latter is perfectly truthful but not complete. Is there a calibration measure that achieves the best of both worlds? Taking a step back, while our definition of truthfulness seems natural, the completeness and soundness criteria, as defined, only serve as minimal requirements. It still remains to explore ways to formally quantify the latter two, and investigate the inherent quantitative trade-offs among truthfulness, completeness and soundness.

Truthfulness against adaptive adversaries?One may wonder whether the truthfulness guarantee of \(\mathsf{SSCE}\) can be extended to handle _adaptive_ adversaries as well. Assuming that the forecaster is given an adversary's (randomized) strategy for choosing \(x_{t}\) based on \(x_{1:(t-1)}\) and \(p_{1:(t-1)}\), is it still approximately optimal to always predict the conditional probability? Here, "adaptive" emphasizes that \(x_{t}\) may depend on both \(x_{1:(t-1)}\) and \(p_{1:(t-1)}\); the formulation in Section 2 is equivalent to that \(x_{t}\) only depends on \(x_{1:(t-1)}\).

Unfortunately, as we show in Appendix G, such a guarantee does not hold for \(\mathsf{SSCE}\), and is unlikely to hold for any natural calibration measure: An adversary can "force" the forecaster to predict untruthfully by "threatening" to increase the variance of the subsequent bits. However, this adversary is highly contrived and unrealistic for practical scenarios. We may thus identify reasonable restrictions on the adaptive adversary to sidestep this counterexample.

## 9 Acknowledgements

This work is supported in part by the National Science Foundation under grants CCF-2145898 and the Graduate Research Fellowship Program under grant DGE 2146752, the Office of Naval Research under grant N00014-24-1-2159, an Alfred P. Sloan fellowship, a Schmidt Sciences AI2050 fellowship, and a Google Research Scholars award. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the funding agencies.

## References

* [ACRS24] Eshwar Ram Arunachaleswaran, Natalie Collina, Aaron Roth, and Mirah Shi. An elementary predictor obtaining \(2\sqrt{T}\) distance to calibration. _arXiv preprint arXiv:2402.11410_, 2024.
* [BF\({}^{+}\)02] Henri Berestycki, Igor Florent, et al. Asymptotics and calibration of local volatility models. _Quantitative finance_, 2(1):61, 2002.
* [BGHN23] Jaroslaw Blasiok, Parikshit Gopalan, Lunjia Hu, and Preetum Nakkiran. A unifying theory of distance from calibration. In _Symposium on Theory of Computing (STOC)_, pages 1727-1740, 2023.
* [Bla23] Guy Blanc. Subsampling suffices for adaptive data analysis. In _Symposium on Theory of Computing (STOC)_, pages 999-1012, 2023.
* [BLMT22] Guy Blanc, Jane Lange, Ali Malik, and Li-Yang Tan. On the power of adaptivity in statistical adversaries. In _Conference on Learning Theory (COLT)_, pages 5030-5061, 2022.
* [Bri50] Glenn W. Brier. Verification of forecasts expressed in terms of probability. _Monthly Weather Review_, 78(1):1-3, 1950.
* [CAT16] Cynthia S Crowson, Elizabeth J Atkinson, and Terry M Therneau. Assessing calibration of prognostic risk scores. _Statistical methods in medical research_, 25(4):1692-1706, 2016.
* [CY21] Yiling Chen and Fang-Yi Yu. Optimal scoring rule design. _arXiv preprint arXiv:2107.07420_, 2021.
* [Daw82] A. P. Dawid. The well-calibrated bayesian. _Journal of the American Statistical Association_, 77(379):605-610, 1982.
* [Daw85] A. P. Dawid. Calibration-based empirical probability. _The Annals of Statistics_, 13(4):1251-1274, 1985.
* [DF83] Morris H DeGroot and Stephen E Fienberg. The comparison and evaluation of forecasts. _Journal of the Royal Statistical Society: Series D (The Statistician)_, 32(1-2):12-22, 1983.
* [Dud87] R. M. Dudley. Universal donsker classes and metric entropy. _The Annals of Probability_, 15(4):1306-1326, 1987.
* [FH18] Dean P. Foster and Sergiu Hart. Smooth calibration, leaky forecasts, finite recall, and nash dynamics. _Games and Economic Behavior_, 109:271-293, 2018.
* [FH21] Dean P. Foster and Sergiu Hart. Forecast hedging and calibration. _Journal of Political Economy_, 129(12):3447-3490, 2021.
* [FL99] Drew Fudenberg and David K. Levine. An easier way to calibrate. _Games and Economic Behavior_, 29(1-2):131-137, 1999.
* [Fos99] Dean P. Foster. A proof of calibration via blackwell's approachability theorem. _Games and Economic Behavior_, 29(1-2):73-78, 1999.
* [Fre75] David A. Freedman. On tail probabilities for martingales. _The Annals of Probability_, 3(1):100-118, 1975.
* [FRST11] Dean P. Foster, Alexander Rakhlin, Karthik Sridharan, and Ambuj Tewari. Complexity-based approach to calibration with checking rules. In _Conference on Learning Theory (COLT)_, pages 293-314, 2011.
* [FV97] Dean P. Foster and Rakesh V. Vohra. Calibrated learning and correlated equilibrium. _Games and Economic Behavior_, 21(1-2):40-55, 1997.

* [FV98] Dean P. Foster and Rakesh V. Vohra. Asymptotic calibration. _Biometrika_, 85(2):379-390, 1998.
* [GPSW17] Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Weinberger. On calibration of modern neural networks. In _International Conference on Machine Learning (ICML)_, pages 1321-1330, 2017.
* [Har22] Sergiu Hart. Calibrated forecasts: The minimax proof. _arXiv preprint arXiv:2209.05863_, 2022.
* [HJKRR18] Ursula Hebert-Johnson, Michael Kim, Omer Reingold, and Guy Rothblum. Multiclibration: Calibration for the (computationally-identifiable) masses. In _International Conference on Machine Learning (ICML)_, pages 1939-1948, 2018.
* [HJZ23] Nika Haghtalab, Michael Jordan, and Eric Zhao. A unifying perspective on multi-calibration: Game dynamics for multi-objective learning. In _Advances in Neural Information Processing Systems (NeurIPS)_, pages 72464-72506, 2023.
* [HPY23] Nika Haghtalab, Chara Podimata, and Kunhe Yang. Calibrated Stackelberg games: Learning optimal commitments against calibrated agents. In _Advances in Neural Information Processing Systems (NeurIPS)_, pages 61645-61677, 2023.
* [HSLW23] Jason D. Hartline, Liren Shan, Yingkai Li, and Yifan Wu. Optimal scoring rules for multi-dimensional effort. In _Conference on Learning Theory (COLT)_, pages 2624-2650, 2023.
* [HW24] Lunjia Hu and Yifan Wu. Predict to minimize swap regret for all payoff-bounded tasks. _arXiv preprint arXiv:2404.13503_, 2024.
* [JOKOM12] Xiaoqian Jiang, Melanie Osl, Jihoon Kim, and Lucila Ohno-Machado. Calibrating predictive model estimates to support personalized medicine. _Journal of the American Medical Informatics Association_, 19(2):263-274, 2012.
* [KF08] Sham M. Kakade and Dean P. Foster. Deterministic calibration and Nash equilibrium. _Journal of Computer and System Sciences_, 74(1):115-130, 2008.
* [KLST23] Robert Kleinberg, Renato Paes Leme, Jon Schneider, and Yifeng Teng. U-calibration: Forecasting for an unknown agent. In _Conference on Learning Theory (COLT)_, pages 5143-5145, 2023.
* [KMR17] Jon Kleinberg, Sendhil Mullainathan, and Manish Raghavan. Inherent trade-offs in the fair determination of risk scores. In _Innovations in Theoretical Computer Science (ITCS)_, pages 43:1-43:23, 2017.
* [KSB21] Benjamin Kompa, Jasper Snoek, and Andrew L Beam. Second opinion needed: communicating uncertainty in medical machine learning. _NPJ Digital Medicine_, 4(1):4, 2021.
* [KSJ18] Aviral Kumar, Sunita Sarawagi, and Ujjwal Jain. Trainable calibration measures for neural networks from kernel mean embeddings. In _International Conference on Machine Learning (ICML)_, pages 2805-2814, 2018.
* [LHSW22] Yingkai Li, Jason D. Hartline, Liren Shan, and Yifan Wu. Optimization of scoring rules. In _Economics and Computation (EC)_, pages 988-989, 2022.
* [MW84] Allan H Murphy and Robert L Winkler. Probability forecasting in meteorology. _Journal of the American Statistical Association_, 79(387):489-500, 1984.
* [NNW21] Eric Neyman, Georgy Noarov, and S. Matthew Weinberg. Binary scoring rules that incentivize precision. In _Economics and Computation (EC)_, pages 718-733, 2021.
* [NRRX23] Georgy Noarov, Ramya Ramalingam, Aaron Roth, and Stephan Xie. High-dimensional unbiased prediction for sequential decision making. In _OPT 2023: Optimization for Machine Learning_, 2023.

* [PRW\({}^{+}\)17] Geoff Pleiss, Manish Raghavan, Felix Wu, Jon Kleinberg, and Kilian Q. Weinberger. On fairness and calibration. _Advances in Neural Information Processing Systems (NIPS)_, pages 5680-5689, 2017.
* [PW22] Maneesha Papireddygari and Bo Waggoner. Contracts with information acquisition, via scoring rules. In _Economics and Computation (EC)_, pages 703-704, 2022.
* [QV21] Mingda Qiao and Gregory Valiant. Stronger calibration lower bounds via sidestepping. In _Symposium on Theory of Computing (STOC)_, pages 456-466, 2021.
* [QZ24] Mingda Qiao and Letian Zheng. On the distance from calibration in sequential prediction. In _Conference on Learning Theory (COLT)_, pages 4307-4357, 2024.
* [RS24] Aaron Roth and Mirah Shi. Forecasting for swap regret for all downstream agents. _arXiv preprint arXiv:2402.08753_, 2024.
* [She10] I. G. Shevtsova. An improvement of convergence rate estimates in the Lyapunov theorem. _Doklady Mathematics_, 82(3):862-864, 2010.
* [Ste22] Thomas Steinke. Composition of differential privacy & privacy amplification by subsampling. _arXiv preprint arXiv:2210.00597_, 2022.
* [VCV15] Ben Van Calster and Andrew J Vickers. Calibration of risk prediction models: impact on decision-analytic performance. _Medical decision making_, 35(2):162-169, 2015.
* [WM68] Robert L. Winkler and Allan H. Murphy. "Good" probability assessors. _Journal of Applied Meteorology and Climatology_, 7(5):751-758, 1968.

## Appendix A Taxonomy of Existing Calibration Measures

In this section, we prove that the existing calibration measures in Table 2 either have a large truthfulness gap or lack completeness.

In these proofs, the _biases_ induced by specific outcomes and predictions will be frequently used: With respect to outcomes \(x\in\{0,1\}^{T}\) and predictions \(p\in[0,1]^{T}\), the bias associated with value \(\alpha\in[0,1]\) is defined as

\[\Delta_{\alpha}\coloneqq\sum_{t=1}^{T}(x_{t}-p_{t})\cdot\mathbbm{1}\left[p_{t }=\alpha\right].\]

### Existing Calibration Measures

The expected calibration error.A common calibration measure is the sum of \(L_{1}\) errors of each level set, known as the \(L_{1}\) calibration error or the _Expected Calibration Error (ECE)_: On \(x\in\{0,1\}^{T}\) and \(p\in[0,1]^{T}\), the expected calibration error is defined as

\[\mathsf{ECE}(x,p)\coloneqq\sum_{\alpha\in[0,1]}\left|\sum_{t=1}^{T}(x_{t}-p_ {t})\cdot\mathbbm{1}[p_{t}=\alpha]\right|=\sum_{\alpha\in[0,1]}|\Delta_{ \alpha}|.\]

Note that the summand \(|\Delta_{\alpha}|\) is non-zero only if \(\alpha\in\{p_{1},p_{2},\ldots,p_{T}\}\), so the summations above are essentially finite and well-defined.

The smooth calibration error.The _smooth calibration error_[10] is defined as

\[\mathsf{smCE}(x,p)\coloneqq\sup_{f\in\mathcal{F}}\sum_{t=1}^{T}f(p_{t})\cdot (x_{t}-p_{t})=\sup_{f\in\mathcal{F}}\sum_{\alpha\in[0,1]}f(\alpha)\cdot\Delta _{\alpha},\]

where \(\mathcal{F}\) is the family of \(1\)-Lipschitz functions from \([0,1]\) to \([-1,1]\). Again, since \(\Delta_{\alpha}\neq 0\) holds only if \(\alpha\in\{p_{1},p_{2},\ldots,p_{T}\}\), the summation above is finite and well-defined.

\begin{table}
\begin{tabular}{|c|c|c|c|} \hline Calibration Measure & Complete? & Sound? & Truthful? \\ \hline Expected Calibration Error & ✓ & ✓ & \(0\)-\(\Omega(T)\) gap \\ \hline Maximum Swap Regret & ✓ & ✓ & \(0\)-\(\Omega(T)\) gap \\ \hline Smooth Calibration Error & ✓ & ✓ & \(0\)-\(\Omega(\sqrt{T})\) gap \\ \hline Distance from Calibration & ✓ & ✓ & \(0\)-\(\Omega(\sqrt{T})\) gap \\ \hline Interval Calibration Error & ✓ & ✓ & \(0\)-\(\Omega(\sqrt{T})\) gap \\ \hline Laplace-Kernel Calibration Error & ✓ & ✓ & \(0\)-\(\Omega(\sqrt{T})\) gap \\ \hline U-Calibration Error & ✓ & ✓ & \(O(1)\)-\(\Omega(\sqrt{T})\) gap \\ \hline Proper Scoring Rules & \(\times\) & ✓ & \((1,0)\)-truthful \\ \hline \(\mathsf{smCE}+\sqrt{T}\) & \(\times\) & ✓ & \((O(1),0)\)-truthful \\ \hline \hline
**Subsampled Smooth Calibration Error** & ✓ & ✓ & \((O(1),0)\)-truthful \\ \hline \end{tabular}
\end{table}
Table 2: Evaluation of previous calibration measures along with \(\mathsf{SSCE}\), in terms of completeness, soundness and truthfulness (Definitions 2.2 and 2.5). Every calibration measure, except \(\mathsf{SSCE}\), either lacks completeness or has a significant truthfulness gap.

The distance from calibration.The _distance from calibration_, introduced by [1] and extended to the sequential setup by [1], is defined as:

\[\mathsf{CallDist}(x,p)\coloneqq\min_{q\in\mathcal{C}(x)}\|p-q\|_{1},\]

where

\[\mathcal{C}(x)\coloneqq\left\{p\in[0,1]^{T}:\forall a\in[0,1],\sum_{t=1}^{T}( x_{t}-p_{t})\cdot\mathds{1}[p_{t}=\alpha]=0\right\}\]

is the set of predictions that are perfectly calibrated for \(x\).

Interval calibration.The _interval calibration error_ of [1] relaxes the ECE to a binned version while penalizing the use of long intervals. Formally, an interval partition \(\mathcal{I}\) is a finite collection of intervals \(\{I_{1},I_{2},\ldots,I_{|\mathcal{I}|}\}\) that form a partition of \([0,1]\). The interval calibration error is defined as:

\[\mathsf{intCE}(x,p)\coloneqq\inf_{\mathcal{I}}\left[\sum_{i=1}^{|\mathcal{I}| }\left|\sum_{t=1}^{T}(x_{t}-p_{t})\cdot\mathds{1}\left[p_{t}\in I_{i}\right] \right|+\sum_{t=1}^{T}\sum_{i=1}^{|\mathcal{I}|}\mathsf{len}(I_{i})\cdot \mathds{1}\left[p_{t}\in I_{i}\right]\right],\]

where the infimum is over all interval partitions \(\mathcal{I}\), and \(\mathsf{len}(I)\) denotes the length of interval \(I\). Note that the first summation inside the infimum is analogous to the ECE, except that the biases associated with all values within the same interval are added together. The second summation gives the total lengths of the intervals into which the \(T\) predictions fall.

Laplace-kernel calibration.The _Laplace-kernel calibration error_[1] is a special case of the _maximum mean calibration error_ introduced by [13]. It can be viewed as a variant of the smooth calibration error, in which the family \(\mathcal{F}\) of Lipschitz functions is replaced by

\[\widetilde{\mathcal{F}}\coloneqq\left\{f:\mathbb{R}\to\mathbb{R}:\|f\|_{2}^{2 }+\|f^{\prime}\|_{2}^{2}\leq 1\right\},\]

where \(\|\cdot\|_{2}\) denotes the \(\ell_{2}\) norm of functions, and \(f^{\prime}\) is the derivative of \(f\). Namely,

\[\mathsf{kCE}^{\mathsf{Lsp}}(x,p)\coloneqq\sup_{f\in\widetilde{\mathcal{F}}} \sum_{t=1}^{T}f(p_{t})\cdot(x_{t}-p_{t}).\]

U-calibration.The definition of the _U-calibration error_[12] is based on _proper scoring rules_. A (bounded) scoring rule is a function \(S:\{0,1\}\times[0,1]\to[-1,1]\). A scoring rule is proper if it holds for every \(\alpha\in[0,1]\) that

\[\alpha\in\operatorname*{arg\,min}_{\beta\in[0,1]}\operatorname*{\mathbb{E}}_ {x\sim\mathsf{Bernoulli}(\alpha)}\left[S(x,\beta)\right].\]

In other words, when the outcome \(x\) is drawn from follow \(\mathsf{Bernoulli}(\alpha)\), predicting the true parameter \(\alpha\) minimizes the expected loss. The U-calibration error is then defined as

\[\mathsf{UCal}(x,p)\coloneqq\sup_{S}\left[\sum_{t=1}^{T}S(x_{t},p_{t})-\inf_{ \alpha\in[0,1]}\sum_{t=1}^{T}S(x_{t},\alpha)\right],\]

where the supremum is over all proper scoring rules. Note that for each fixed \(S\), the expression inside the supremum is exactly the _external regret_ of the forecaster, i.e., the excess loss compared to the best fixed prediction in hindsight.

Maximum swap regret.A recent line of work [14, 15, 16] considers a strengthening of U-calibration, in which the external regret is replaced with the _swap regret_. In particular, [16] showed that the resulting calibration measure, termed the Maximum Swap Regret (MSR), is polynomially related to the ECE after scaling by a factor of \(1/T\):

\[\left[\frac{\mathsf{ECE}(x,p)}{T}\right]^{2}\leq\frac{\mathsf{ MSR}(x,p)}{T}\leq\frac{2\mathsf{ECE}(x,p)}{T}.\]

### \(0\)-\(\Omega(T)\) Truthfulness Gaps

We first prove the \(0\)-\(\Omega(T)\) truthfulness gaps of the ECE and the MSR.

**Proposition A.1**.: _Both the expected calibration error and the maximum swap regret have a \(0\)-\(\Omega(T)\) truthfulness gap._

To establish Proposition A.1, we follow a similar argument to the one in Section 3: We divide the time horizon into \(T/3\) triples, each containing a random bit followed by a zero and a one. The truthful forecaster would predict the true probabilities for the \(T/3\) random bits, which are designed to be close to \(1/2\) but distinct. This leads to a linear ECE. On the other hand, a strategic forecaster may always predict \(1/2\) on the random bit. Then, based on the realization of the random bit, they use the subsequent deterministic bits to offset the bias. The resulting predictions are perfectly calibrated, and thus have a zero ECE. Finally, the relation between the ECE and the MSR gives the same truthfulness gap for the MSR.

Proof of Proposition a.1.: Consider the distribution \(\mathcal{D}\) defined as follows:

* Let \(\varepsilon_{1},\varepsilon_{2},\ldots,\varepsilon_{T/3}\) be distinct values in \([-1/4,1/4]\) chosen arbitrarily.
* For each \(k\in[T/3]\), set \((p_{3k-2}^{\star},p_{3k-1}^{\star},p_{3k}^{\star})=(1/2+\varepsilon_{k},0,1)\).
* \(\mathcal{D}\) is the product distribution \(\prod_{t=1}^{T}\mathsf{Bernoulli}(p_{t}^{\star})\).

By definition, the predictions made by the truthful forecaster are exactly given by \(p^{\star}\). Then, for each \(k\in[T/3]\) and \(\alpha=1/2+\varepsilon_{k}\in[1/4,3/4]\), we have \(|\Delta_{\alpha}|=|x_{3k-2}-\alpha|\geq 1/4\). This shows \(\mathsf{err}_{\mathsf{ECE}}(\mathcal{D},\mathcal{A}^{\mathrm{truthful}}( \mathcal{D}))\geq(T/3)\cdot(1/4)=\Omega(T)\). By the inequality \(\frac{\mathsf{MSR}(x,p)}{T}\geq\left\lceil\frac{\mathsf{ECE}(x,p)}{T}\right\rceil^ {2}\), we also have \(\mathsf{err}_{\mathsf{MSR}}(\mathcal{D},\mathcal{A}^{\mathrm{truthful}}( \mathcal{D}))=\Omega(T)\).

On the other hand, consider the following alternative forecaster for \(\mathcal{D}\):

* For each \(k\in[T/3]\), predict \(p_{3k-2}=1/2\).
* If \(x_{3k-2}=0\), predict \(p_{3k-1}=0\) and \(p_{3k}=1/2\); otherwise, predict \(p_{3k-1}=1/2\) and \(p_{3k}=1\).

Clearly, for each \(k\in[T/3]\), the steps \(t\in\{3k-2,3k-1,3k\}\) have zero contribution to \(\Delta_{0}\), \(\Delta_{1}\) and \(\Delta_{1/2}\). Therefore, this forecaster achieves a zero ECE on \(\mathcal{D}\). This proves \(\mathsf{OPT}_{\mathsf{ECE}}(\mathcal{D})=0\) and establishes the \(0\)-\(\Omega(T)\) truthfulness gap for the ECE. Finally, the inequality \(\frac{\mathsf{MSR}(x,p)}{T}\leq\frac{2\mathsf{ECE}(x,p)}{T}\) implies that the same forecaster achieves a zero MSR, which establishes \(\mathsf{OPT}_{\mathsf{MSR}}(\mathcal{D})=0\) and the \(0\)-\(\Omega(T)\) truthfulness gap for the MSR. 

### \(0\)-\(\Omega(\sqrt{T})\) Truthfulness Gaps

Next, we prove the \(0\)-\(\Omega(\sqrt{T})\) truthfulness gap for several calibration measures. The proof follows the argument outlined in Section 3.

**Proposition A.2**.: _The smooth calibration error, the distance from calibration, the interval calibration error, and the Laplace-kernel calibration error all have a \(0\)-\(\Omega(\sqrt{T})\) truthfulness gap._

Proof.: The truthfulness gaps of the four calibration measures are witnessed by the same product distribution \(\mathcal{D}=\prod_{t=1}^{T}\mathsf{Bernoulli}(p_{t}^{\star})\), where \((p_{3k-2}^{\star},p_{3k-1}^{\star},p_{3k}^{\star})=(1/2,0,1)\) for every \(k\in[T/3]\).

Truthful forecaster has an \(\Omega(\sqrt{T})\) penalty.The truthful forecaster makes predictions that are identical to \(p^{\star}\). As a result, we have \(\Delta_{0}=\Delta_{1}=0\), while \(\Delta_{1/2}\) is distributed as the difference between a sample from \(\mathsf{Binomial}(T/3,1/2)\) and its mean \(T/6\). It then follows that \(|\Delta_{1/2}|\geq\Omega(\sqrt{T})\) holds with probability \(\Omega(1)\). We will show that all four calibration measures evaluate to \(\Omega(\sqrt{T})\) in expectation.

For the smooth calibration error, we have

\[\mathsf{err}_{\mathsf{smCE}}(\mathcal{D},\mathcal{A}^{\mathrm{truthful}}( \mathcal{D}))=\mathop{\mathbb{E}}_{x\sim\mathcal{D}}\big{[}|\Delta_{1/2}|\big{]} =\mathop{\mathbb{E}}_{X\sim\mathsf{Binomial}(T/3,1/2)}\big{[}|X-T/6|\big{]}= \Omega(\sqrt{T}).\]

For the distance from calibration, by [3, Lemma 5.4 and Theorem 7.3], we have the inequality \(\frac{1}{2}\mathsf{smCE}(x,p)\leq\mathsf{CallDist}(x,p)\) for any \(x\in\{0,1\}^{T}\) and \(p\in[0,1]^{T}\), so the truthful forecaster also gives \(\mathsf{err}_{\mathsf{CallDist}}(\mathcal{D},\mathcal{A}^{\mathrm{truthful}}( \mathcal{D}))=\Omega(\sqrt{T})\).

For interval calibration, let \(\mathcal{I}\) be an arbitrary interval partition, and \(I\in\mathcal{I}\) be the interval that contains \(1/2\). If \(I\) contains either \(0\) or \(1\), we must have \(\mathsf{len}(I)\geq 1/2\), and the term \(\sum_{t=1}^{T}\sum_{i=1}^{|\mathcal{I}|}\mathsf{len}(I_{i})\cdot 1\,[p_{t} \in I_{i}]\) will be at least \(2T/3\cdot 1/2=\Omega(T)\). If \(I\) does not contain \(0\) or \(1\), the summation \(\sum_{t=1}^{T}(x_{t}-p_{t})\cdot 1\,[p_{t}\in I]\) will be exactly \(\Delta_{1/2}\), and the first term in the definition will be at least \(|\Delta_{1/2}|\). It follows that \(\mathsf{intCE}(x,p)\geq\Omega(\sqrt{T})\) with probability \(\Omega(1)\), so we have the lower bound \(\mathsf{err}_{\mathsf{intCE}}(\mathcal{D},\mathcal{A}^{\mathrm{truthful}}( \mathcal{D}))=\Omega(\sqrt{T})\).

For Laplace-kernel calibration, let \(f_{0}\) be an arbitrary function in \(\widetilde{\mathcal{F}}\) such that \(f_{0}(1/2)>0\), e.g., we can take \(f_{0}(x)=ce^{-x^{2}}\) for a sufficiently small constant \(c>0\). Then, we have

\[\mathsf{kCE}^{\mathsf{Lap}}(x,p)\geq\sup_{f\in\{f_{0},-f_{0}\}}\sum_{\alpha \in[0,1]}f(\alpha)\cdot\Delta_{\alpha}\geq\Omega(1)\cdot|\Delta_{1/2}|.\]

It follows that \(\mathsf{err}_{\mathsf{kCE}^{\mathsf{Lap}}}(\mathcal{D},\mathcal{A}^{\mathrm{ truthful}}(\mathcal{D}))\geq\Omega(1)\cdot\mathop{\mathbb{E}}\big{[}|\Delta_{1/2} |\big{]}=\Omega(\sqrt{T})\).

Strategic forecaster has a zero penalty.Consider the same strategic forecaster as in the proof of Proposition A.1: For each \(k\in[T/3]\),

* Predict \(p_{3k-2}=1/2\).
* If \(x_{3k-2}=0\), predict \((p_{3k-1},p_{3k})=(0,1/2)\); otherwise, predict \((p_{3k-1},p_{3k})=(1/2,1)\).

Clearly, this guarantees that \(\Delta_{\alpha}=0\) holds for all \(\alpha\in[0,1]\). By definition, we have \(\mathsf{OPT}_{\mathsf{smCE}}(\mathcal{D})=\mathsf{OPT}_{\mathsf{CallDist}}( \mathcal{D})=0\). It also easily follows that both \(\mathsf{intCE}\) and \(\mathsf{kCE}^{\mathsf{Lap}}\) evaluate to \(0\). For \(\mathsf{intCE}\), we consider the interval partition \(\mathcal{I}=\{\{0\},(0,1/2),\{1/2\},(1/2,1),\{1\}\}\), which witnesses \(\mathsf{intCE}(x,p)=0\). For \(\mathsf{kCE}^{\mathsf{Lap}}\), the summation \(\sum_{t=1}^{T}f(p_{t})\cdot(x_{t}-p_{t})=\sum_{\alpha\in[0,1]}f(\alpha)\cdot \Delta_{\alpha}\) evaluates to \(0\) for all \(f\in\widetilde{\mathcal{F}}\). This proves \(\mathsf{OPT}_{\mathsf{intCE}}(\mathcal{D})=\mathsf{OPT}_{\mathsf{kCE}^{ \mathsf{Lap}}}(\mathcal{D})=0\). 

### \(O(1)\)-\(\Omega(\sqrt{T})\) Truthfulness Gap of U-Calibration

For the U-calibration error, we prove a slightly smaller truthfulness gap of \(O(1)\)-\(\Omega(\sqrt{T})\), via a more involved analysis.

**Proposition A.3**.: _The U-calibration error has an \(O(1)\)-\(\Omega(\sqrt{T})\) truthfulness gap._

Proof.: We use a slightly different construction: the product distribution \(\mathcal{D}=\prod_{t=1}^{T}\mathsf{Bernoulli}(p_{t}^{\star})\) where \(p_{t}^{\star}=1/2\) for \(t\leq T/2\) and \(p_{t}^{\star}=1\) for \(t>T/2\).

Truthful forecaster has an \(\Omega(\sqrt{T})\) penalty.We first show that the truthful forecaster has an \(\Omega(\sqrt{T})\) U-calibration error. Let random variable \(X\coloneqq\sum_{t=1}^{T/2}x_{t}\) denote the number of ones among the first \(T/2\) random bits. Note that \(X\) follows \(\mathsf{Binomial}(T/2,1/2)\). Consider the scoring rule defined as:

\[S(0,\alpha)=\mathrm{sgn}(\alpha-1/2)\quad\text{and}\quad S(1,\alpha)=\mathrm{ sgn}(1/2-\alpha).\]

Note that \(S\) is proper, since for any \(\alpha\in[0,1]\), we have

\[\mathop{\mathbb{E}}_{x\sim\mathsf{Bernoulli}(\alpha)}[S(x,\beta)]=(1-\alpha) \cdot\mathrm{sgn}(\beta-1/2)+\alpha\cdot\mathrm{sgn}(1/2-\beta)=(1-2\alpha) \cdot\mathrm{sgn}(\beta-1/2),\]

which is always minimized at \(\beta=\alpha\).

The total loss (w.r.t. \(S\)) incurred by the forecaster is then

\[\sum_{t=1}^{T}S(x_{t},p_{t}) =X\cdot S(1,1/2)+(T/2-X)\cdot S(0,1/2)+T/2\cdot S(1,1)\] \[=X\cdot 0+(T/2-X)\cdot 0+T/2\cdot(-1)\] \[=-T/2.\]

On the other hand, the total loss incurred by a fixed prediction \(\beta\in[0,1]\) is given by:

\[\sum_{t=1}^{T}S(x_{t},\beta) =(T/2+X)\cdot S(1,\beta)+(T/2-X)\cdot S(0,\beta)\] \[=(T/2+X)\cdot\mathrm{sgn}(1/2-\beta)+(T/2-X)\cdot\mathrm{sgn}( \beta-1/2)\] \[=2X\cdot\mathrm{sgn}(1/2-\beta).\]

By choosing \(\beta=1\), we can obtain a total loss of \(-2X\). Therefore, whenever \(X\geq T/4\), we have

\[\mathsf{UCal}(x,p)\geq-T/2-(-2X)=2(X-T/4).\]

When \(X<T/4\), we always have \(\mathsf{UCal}(x,p)\geq 0\), since the trivial scoring rule \(S\equiv 0\) is proper. This shows that the truthful forecaster gives

\[\mathsf{err_{UCal}}(\mathcal{D},\mathcal{A}^{\mathrm{truthful}}(\mathcal{D}) )\geq\mathop{\mathbb{E}}_{X\sim\mathsf{Binomial}(T/2,1/2)}[\max\{2(X-T/4),0 \}]=\Omega(\sqrt{T}).\]

Strategic forecaster with an \(O(1)\) penalty.We consider an alternative forecaster \(\mathcal{A}\), which is slightly more involved:

* At every step \(t\leq T/2\), predict \(p_{t}=5/8\).
* For \(t=T/2+1,T/2+2,\ldots,T\), predict \(p_{t}=5/8\) until \(|\Delta_{5/8}|\leq 1\) at some time \(t\). After that step, predict \(p_{t}=1\).

We first argue that the condition \(|\Delta_{5/8}|\leq 1\) must hold at some point. Recall that \(X=\sum_{t=1}^{T/2}x_{t}\). By a Chernoff bound, \(X\) falls into \([T/8,5T/16]\) except with probability \(e^{-\Omega(T)}\). Assuming this, we have \(\Delta_{5/8}=X-(T/2)\cdot(5/8)\leq 0\) at time \(t=T/2\). Furthermore, if we hypothetically predict \(5/8\) for each of the last \(T/2\) steps, we would have

\[\Delta_{5/8}=(X+T/2)-T\cdot(5/8)\geq T/8+T/2-5T/8=0\]

after all the \(T\) steps. Since \(\Delta_{5/8}\) changes by at most \(1\) at each step, we must hit the condition \(|\Delta_{5/8}|\leq 1\) at some point.

Therefore, except with an \(e^{-\Omega(T)}\) probability, we end up with \(\Delta_{5/8}\in[-1,1]\). Furthermore, we predict at most two different values: \(5/8\) and \(1\). For every fixed proper scoring rule \(S:\{0,1\}\times[0,1]\to[-1,1]\), we have

\[\sum_{t=1}^{T}S(x_{t},p_{t})-\inf_{\beta\in[0,1]}\sum_{t=1}^{T}S (x_{t},\beta)\] \[\leq\sum_{\alpha\in\{5/8,1\}}\left[\sum_{t=1}^{T}S(x_{t},p_{t}) \cdot\mathbbm{1}\left[p_{t}=\alpha\right]-\inf_{\beta\in[0,1]}\sum_{t=1}^{T}S( x_{t},\beta)\cdot\mathbbm{1}\left[p_{t}=\alpha\right]\right].\]

In the above, we divide the time horizon \([T]\) into two parts, based on whether \(5/8\) or \(1\) is predicted. The inequality holds since the right-hand side allows different values of \(\beta\) for different parts. Clearly, the term corresponding to \(\alpha=1\) has zero contribution, since it reduces to \(S(1,1)-\inf_{\beta\in[0,1]}S(1,\beta)\) times the number of times \(1\) is predicted, which evaluates to \(0\) by definition of proper scoring rules.

The term corresponding to \(\alpha=5/8\), on the other hand, is given by

\[N_{0}\cdot S(0,5/8)+N_{1}\cdot S(1,5/8)-\inf_{\beta\in[0,1]}[N_{0}\cdot S(0, \beta)+N_{1}\cdot S(1,\beta)],\]where each \(N_{b}\) denotes the number of steps on which \(5/8\) is predicted and the outcome is \(b\in\{0,1\}\). By definition of proper scoring rules, the infimum is achieved by \(\beta^{\star}=\frac{N_{1}}{N_{0}+N_{1}}\), and the above can be further simplified into

\[(N_{0}+N_{1})\cdot[S\left(\beta^{\star},5/8\right)-S\left(\beta^{\star},\beta^{ \star}\right)],\]

where \(S(\alpha,\beta)\coloneqq\alpha\cdot S(1,\beta)+(1-\alpha)\cdot S(0,\beta)\) is the linear extension of \(S\) to \([0,1]^{2}\).

Let \(\ell(\alpha)\coloneqq S(\alpha,\alpha)\) denote the _uni-variate form_ of \(S\). The following is a standard fact about proper scoring rules (see e.g., [10, Lemma 1 and Corollary 2]).

**Lemma A.4**.: _For any proper scoring rule \(S:[0,1]^{2}\to[-1,1]\) and its uni-variate form \(\ell:[0,1]\to[-1,1]\), it holds for all \(\alpha,\beta\in[0,1]\) that_

* \(S(\alpha,\beta)=\ell(\beta)+(\alpha-\beta)\cdot\ell^{\prime}(\beta)\)__
* \(|\ell^{\prime}(\alpha)|\leq 2\) _for all_ \(\alpha\in[0,1]\)_._

In particular, we have

\[|S(\beta^{\star},5/8)-S(5/8,5/8)|=|\beta^{\star}-5/8|\cdot\ell^{\prime}(5/8) \leq 2|\beta^{\star}-5/8|\]

and

\[|S(5/8,5/8)-S(\beta^{\star},\beta^{\star})|=|\ell(5/8)-\ell(\beta^{\star})| \leq 2|\beta^{\star}-5/8|.\]

It follows that, assuming \(X\in[T/8,5T/16]\),

\[\mathsf{UCal}(x,p)\leq 4(N_{0}+N_{1})|\beta^{\star}-5/8|=4\left|N_{1}-\frac{5}{ 8}(N_{0}+N_{1})\right|=4|\Delta_{5/8}|\leq 4.\]

When \(X\in[T/8,5T/16]\) does not hold (which happens with probability \(e^{-\Omega(T)}\)), the U-calibration error is trivially upper bounded by \(O(T)\). It follows that

\[\mathsf{OPT}_{\mathsf{UCal}}(\mathcal{D})\leq\mathsf{err}_{\mathsf{UCal}}( \mathcal{D},\mathcal{A})\leq 4+O(T)\cdot e^{-\Omega(T)}=O(1).\]

### Lack of Completeness

Every scoring rule \(S:\{0,1\}\times[0,1]\to[0,1]\) induces a calibration measure \(\mathsf{CM}^{(S)}(x,p)\coloneqq\sum_{t=1}^{T}S(x_{t},p_{t})\).1 When \(S\) is proper, it is easy to show that the resulting \(\mathsf{CM}^{(S)}\) is perfectly truthful, i.e., \((1,0)\)-truthful.

Footnote 1: Here, we consider scoring rules with co-domain \([0,1]\), since our definition of calibration measures (in Section 2) requires them to be bounded between \(0\) and \(T\) on length-\(T\) sequences.

A drawback of such calibration measures is that they all lack completeness. Concretely, consider the squared loss \(S(x,p)\coloneqq(x-p)^{2}\). When the outcomes \(x_{1},x_{2},\ldots,x_{T}\) are independent and uniformly random bits, the "right" prediction \(p_{t}\equiv 1/2\) gives a total penalty of \(T/4\), which is only a constant factor away from the maximum possible penalty of \(T\). This violates the completeness property in Definition 2.2. In contrast, as shown in Table 2, almost all the other calibration measures would evaluate to \(\ll T\) in this case. Such an _asymptotic gap_ better justifies the intuition that \(p_{t}\equiv 1/2\) is a much better prediction than, say, \(p_{t}\equiv 0\).

More generally, unless the proper scoring rule \(S\) is trivial, we may find \((x_{0},p_{0})\in\{0,1\}\times(0,1)\) such that \(S(x_{0},p_{0})>0\). Then, on a sequence of independent samples from \(\mathsf{Bernoulli}(p_{0})\), we have

\[\operatorname*{\mathbb{E}}_{x_{1},\ldots,x_{T}\sim\mathsf{Bernoulli }(p_{0})}\left[\mathsf{CM}^{(S)}_{T}(x,p_{0}\cdot\overline{1})\right] \geq T\cdot S(x_{0},p_{0})\cdot\operatorname*{\mathbb{Pr}}_{X\sim \mathsf{Bernoulli}(p_{0})}[X=x_{0}]\] \[\geq T\cdot S(x_{0},p_{0})\cdot\min\{p_{0},1-p_{0}\}=\Omega(T),\]

which violates the completeness condition in Definition 2.2.

We also note that \(\mathsf{smCE}(x,p)+\sqrt{T}\) gives a calibration measure that is trivially truthful: Implicit in the proof of [11, Theorem 3], the truthful forecaster gives an \(O(\sqrt{T})\) smooth calibration error on every distribution \(\mathcal{D}\in\Delta(\{0,1\}^{T})\), so it immediately gives a constant approximation of the optimal error, which is at least \(\sqrt{T}\). However, this metric is not complete in the sense of Definition 2.2, since it evaluates to \(\sqrt{T}\) instead of \(0\) when \(p=x\) (i.e., the predictions are binary and perfect). While SSCE also discourages the forecaster from "over-optimizing" the metric by introducing some additional noise, the subsampling procedure is arguably more "organic" and better-justified than adding a \(\sqrt{T}\) term.

## Appendix B Proof of Theorem 1.1

We prove Theorem 1.1, which we formally restate below.

**Theorem B.1** (Formal version of Theorem 1.1).: _For every \(p^{\star}\in[0,1]^{T}\), on the product distribution \(\mathcal{D}=\prod_{t=1}^{T}\mathsf{Bernoulli}(p_{t}^{\star})\), there is a forecaster that achieves an \(O(\log^{3/2}T)\) smooth calibration error and distance from calibration. Moreover, assuming that \(p^{\star}\in[\delta,1-\delta]^{T}\) for a fixed constant \(\delta\in(0,1/2]\), both \(\mathsf{OPT}_{\mathsf{smCE}}(\mathcal{D})\) and \(\mathsf{OPT}_{\mathsf{calDist}}(\mathcal{D})\) are \(\Omega(\sqrt{T})\)._

### The Upper Bound Part

We start by proving the upper bound part of Theorem B.1 by designing a forecasting algorithm.

The forecasting algorithm.Our proof is based on an algorithm of [10] that works for the special case that \(p_{t}^{\star}\equiv 1/2\). Their algorithm starts by predicting \(1/2\) on the first \(T/2\) steps. Depending on the realization of these \(T/2\) random bits, it predicts a slightly biased value for the next \(T/2\) steps, until the total bias (i.e., the partial sum of \(x_{t}-p_{t}\)) becomes close to \(0\) at some point. If there is still time left, the algorithm repeats the above strategy for the remainder of the time horizon.

Roughly speaking, [10] shows that a \(\operatorname{polylog}(T)\) distance from calibration can be achieved by designing a sub-routine with the following three properties:

* **Small bias:** With high probability, the total bias is \(O(1)\) in magnitude at some time \(t\in[T/2,T]\).
* **Proximity of predictions:** During the sub-routine, the values being predicted lie in a short interval of length \(\operatorname{polylog}(T)/\sqrt{T}\).
* **Sparsity of predictions:** During the sub-routine, only \(O(1)\) different values are predicted.

To handle the general case that \(p^{\star}\in[0,1]^{T}\) is arbitrary, we design an alternative sub-routine, the behavior of which depends on whether the sequence \(p^{\star}\) is "sufficiently stationary" in some sense. Let \(\mu_{\mathrm{first}}\coloneqq\frac{1}{T/2}\sum_{t=1}^{T/2}p_{t}^{\star}\) and \(\mu_{\mathrm{second}}\coloneqq\frac{1}{T/2}\sum_{t=T/2+1}^{T}p_{t}^{\star}\) be the averages of the first and the second halves of the sequence, respectively. Let \(\mu=(\mu_{\mathrm{first}}+\mu_{\mathrm{second}})/2\) be the overall average.

* **Case 1:**\(|\mu_{\mathrm{first}}-\mu|>\operatorname{polylog}(T)/\sqrt{T}\). When \(\mu_{\mathrm{first}}\) and \(\mu\) are far away, we predict \(\alpha\coloneqq\frac{\mu_{\mathrm{first}}+\mu}{2}\) at every step. Without loss of generality, suppose that \(\mu_{\mathrm{first}}<\mu\), in which case we have \[\mu_{\mathrm{first}}<\alpha<\mu,\] where both inequalities hold with a margin \(>\operatorname{polylog}(T)/\sqrt{T}\). Then, with high probability the following two events happen: (1) The total bias is negative at time \(T/2\), i.e., it holds that \(\sum_{t=1}^{T/2}x_{t}<\alpha\cdot(T/2)\); (2) If we (hypothetically) predict the same value \(\alpha\) for the second half, the bias will be positive in the end with high probability, i.e., \(\sum_{t=1}^{T}x_{t}>\alpha\cdot T\). Therefore, with high probability, the bias must be close to \(0\) at some point in \([T/2,T]\). In this case, this sub-routine has all the desired properties.
* **Case 2:**\(|\mu_{\mathrm{first}}-\mu|\leq\operatorname{polylog}(T)/\sqrt{T}\). When \(\mu_{\mathrm{first}}\) and \(\mu\) are close, we use a strategy that is more similar to the algorithm of [10]. For the first half of the sequence, we predict \(\alpha\coloneqq\mu_{\mathrm{first}}\). Let \(\Delta_{\mathrm{first}}\coloneqq\sum_{t=1}^{T/2}(x_{t}-\alpha)\) denote the total bias at time \(T/2\). Say that \(\Delta_{\mathrm{first}}\geq 0\). Then, we will predict \(\beta\coloneqq\mu_{\mathrm{second}}+\frac{\Delta_{\mathrm{first}}}{T/2}+\frac{ \operatorname{polylog}(T)}{\sqrt{T}}\) in the second half of the sequence. The value of \(\beta\) is chosen such that we can offset the bias incurred in the first half (i.e., the \(\Delta_{\mathrm{first}}/(T/2)\) term). We also introduce some additional bias (i.e.,the \(\mathrm{polylog}(T)/\sqrt{T}\) term), so that we can return to a zero bias with high probability. In this case, our sub-routine predicts two different values (\(\alpha\) and \(\beta\)), and they only differ by \(\mathrm{polylog}(T)/\sqrt{T}\) with high probability.

Formally, our algorithm is given in Algorithm 1. The actual algorithm is significantly more involved than the outline above. The complication is due to the constraint that all predictions must lie in \([0,1]\), while our choice of \(\beta\) in Case 2 above might be invalid. We circumvent this issue by noting that \(\beta\) can be invalid only if \(\mu_{\mathrm{first}}\) is too close to either \(0\) or \(1\). In that case, we will choose a different value of \(\alpha\) (i.e., the prediction for the first half), so that the sign of the bias at time \(T/2\) is more predictable, and the resulting choice of \(\beta\) will likely be valid.

``` Input: Parameters \(p_{1}^{*},p_{2}^{*},\ldots,p_{T}^{*}\). Outcomes \(x_{1},x_{2},\ldots,x_{T}\) observed sequentially. Output: Predictions \(p_{1},p_{2},\ldots,p_{T}\).
1\(t\gets 0;r\gets 0\);
2while\(t<T\)do
3\(r\gets r+1\); \(T^{(r)}\gets T-t\); \(H^{(r)}\leftarrow\lfloor T^{(r)}/2\rfloor\);
4if\(T^{(r)}=1\)then predict \(p_{T}=0\) and break;
5\(\mu_{\mathrm{first}}^{(r)}\leftarrow\frac{1}{H^{(r)}}\sum_{s=t+1}^{t+H^{(r)}}p _{s}^{*}\); \(\mu_{\mathrm{second}}^{(r)}\leftarrow\frac{1}{H^{(r)}}\sum_{s=t+H^{(r)}+1}^{t+ 2H^{(r)}}p_{s}^{*}\);
6\(\mu^{(r)}\leftarrow\lfloor\mu_{\mathrm{first}}^{(r)}+\mu_{\mathrm{second}}^{(r) }\rfloor/2;\Delta^{(r)}\gets 0\);
7if\(|\mu_{\mathrm{first}}^{(r)}-\mu^{(r)}|\geq\sqrt{\frac{2\ln T^{(r)}}{H^{(r)}}}\)then
8\(\alpha^{(r)}\leftarrow\lfloor\mu_{\mathrm{first}}^{(r)}+\mu^{(r)}\rfloor/2\);
9for\(i=1,2,\ldots,2H^{(r)}\)do
10\(t\gets t+1\); Predict \(p_{t}\leftarrow\alpha^{(r)}\);
11 Observe \(x_{t}\); \(\Delta^{(r)}\leftarrow\Delta^{(r)}+(x_{t}-p_{t})\);
12if\(i>H^{(r)}\) and \(|\Delta^{(r)}|\leq 1\)then break;
13
14 end if
15
16else
17if\(\mu_{\mathrm{first}}^{(r)}\leq 1/2\)then
18if\(\mu_{\mathrm{first}}^{(r)}\geq 10\sqrt{\frac{\ln T^{(r)}}{H^{(r)}}}\)then\(\alpha^{(r)}\leftarrow\mu_{\mathrm{first}}^{(r)}\) ;
19else\(\alpha^{(r)}\leftarrow\max\left\{\mu_{\mathrm{first}}^{(r)}-\sqrt{\frac{2\mu_{ \mathrm{first}}^{(r)}\ln T^{(r)}}{H^{(r)}}},0\right\}\) ;
20else
21if\(1-\mu_{\mathrm{first}}^{(r)}\geq 10\sqrt{\frac{\ln T^{(r)}}{H^{(r)}}}\)then\(\alpha^{(r)}\leftarrow\mu_{\mathrm{first}}^{(r)}\) ;
22else\(\alpha^{(r)}\leftarrow\min\left\{\mu_{\mathrm{first}}^{(r)}+\sqrt{\frac{2 \lceil 1-\mu_{\mathrm{first}}^{(r)}\rceil\ln T^{(r)}}{H^{(r)}}},1\right\}\) ;
23for\(i=1,2,\ldots,H^{(r)}\)do
24\(t\gets t+1\); Predict \(p_{t}\leftarrow\alpha^{(r)}\);
25 Observe \(x_{t}\); \(\Delta^{(r)}\leftarrow\Delta^{(r)}+(x_{t}-p_{t})\);
26
27if\(|\Delta^{(r)}|\leq 1\)then break;
28
29 end if
30
31 end for ```

**Algorithm 1**Forecaster for Product Distributions
The analysis.We analyze Algorithm 1 and prove the upper bound in Theorem B.1 in the following three steps:

* First, we break the execution of Algorithm 1 into different rounds of the while-loop, and show that each round brings a \(\operatorname{polylog}(T)\) smooth calibration error in expectation.
* Then, using the simple observation that the smooth calibration error is sub-additive, we obtain an upper bound on the overall smooth calibration error.
* Finally, we use a relation between \(\mathsf{smCE}(x,p)\) and \(\mathsf{CalDist}(x,p)\) when \(p\) only contains a few different values (shown by [13]) to translate the upper bound to one on the distance from calibration.

The first step is the most technical. We fix \(r\) and condition on the value of \(t\) (equivalently, the value of \(T^{(r)}\)) at the beginning of the \(r\)-th round. Note that the event \(t=t_{0}\) is solely determined by the realization of \(x_{1},x_{2},\ldots,x_{t_{0}}\), so conditioning on the value of \(t\), the subsequent bits \(x_{t+1}\) through \(x_{T}\) are still distributed according to \(\mathcal{D}\). Let sequences \(x^{(r)}\) and \(p^{(r)}\) denote the outcomes and predictions made in the \(r\)-th round. Note that the two sequences are of the same length, though the length might vary.

We classify the rounds into three different types as follows:

* **Type 1:** The condition \(|\mu^{(r)}_{\mathrm{first}}-\mu^{(r)}|\geq\sqrt{\frac{2\ln T^{(r)}}{H^{(r)}}}\) holds in the if-statement on Line 7.
* **Type 2:**\(|\mu^{(r)}_{\mathrm{first}}-\mu^{(r)}|<\sqrt{\frac{2\ln T^{(r)}}{H^{(r)}}}\), and \(\alpha^{(r)}\) is set to \(\mu^{(r)}_{\mathrm{first}}\) on either Line 16 or Line 19.
* **Type 3:**\(|\mu^{(r)}_{\mathrm{first}}-\mu^{(r)}|<\sqrt{\frac{2\ln T^{(r)}}{H^{(r)}}}\), and \(\alpha^{(r)}\) is not set to \(\mu^{(r)}_{\mathrm{first}}\).

Note that for fixed \(p^{\star}\), the type of a round is deterministic given \(r\) and \(T^{(r)}\).

The three lemmas below give high-probability bounds on the smooth calibration error incurred during each round.

**Lemma B.2**.: _Conditioning on the value of \(T^{(r)}\), if the \(r\)-th round is Type 1, it holds with probability \(1-O(1/T^{(r)})\) that_

\[\mathsf{smCE}(x^{(r)},p^{(r)})\leq 1.\]

**Lemma B.3**.: _Conditioning on the value of \(T^{(r)}\), if the \(r\)-th round is Type 2, it holds with probability \(1-O(1/T^{(r)})\) that_

\[\mathsf{smCE}(x^{(r)},p^{(r)})\leq 1+O\left(\frac{1}{T^{(r)}}\right)\cdot \left[\Delta^{(r)}_{\mathrm{first}}\right]^{2}+O\left(\sqrt{\frac{\log T^{(r) }}{T^{(r)}}}\right)\cdot\left|\Delta^{(r)}_{\mathrm{first}}\right|,\]

_where \(\Delta^{(r)}_{\mathrm{first}}\) denotes the value of \(\Delta^{(r)}\) at the end of the first for-loop (on Line 25)._

**Lemma B.4**.: _Conditioning on the value of \(T^{(r)}\), if the \(r\)-th round is Type 3, it holds with probability \(1-O(1/T^{(r)})\) that_

\[\mathsf{smCE}(x^{(r)},p^{(r)})\leq 1+O\left(\frac{1}{T^{(r)}}\right)\cdot \left[\Delta^{(r)}_{\mathrm{first}}\right]^{2}+O\left(\sqrt{\frac{\log T^{(r) }}{T^{(r)}}}\right)\cdot\left|\Delta^{(r)}_{\mathrm{first}}\right|,\]

_where \(\Delta^{(r)}_{\mathrm{first}}\) denotes the value of \(\Delta^{(r)}\) at the end of the first for-loop (on Line 25)._

We first prove the upper bound part of Theorem B.1 using the lemmas above.

Proof of Theorem B.1, the upper bound part.: By Lemmas B.2 through B.4, regardless of the type of the \(r\)-th round, it holds with probability \(1-O\left(1/T^{(r)}\right)\) that

\[\mathsf{smCE}(x^{(r)},p^{(r)})\leq 1+O\left(\frac{1}{T^{(r)}}\right)\cdot \left[\Delta^{(r)}_{\mathrm{first}}\right]^{2}+O\left(\sqrt{\frac{\log T^{(r) }}{T^{(r)}}}\right)\cdot\left|\Delta^{(r)}_{\mathrm{first}}\right|,\]where \(\Delta^{(r)}_{\rm first}\) is regarded as \(0\) if the \(r\)-th round is Type 1. We say that the round _fails_ if this upper bound on \(\mathsf{smCE}\) does not hold. Conditioning on that \(T^{(r)}=L\), we always have \(\mathsf{smCE}(x^{(r)},p^{(r)})\leq L\), since there are at most \(L\) steps in the \(r\)-th round. Therefore, we have the inequality

\[\mathsf{smCE}(x^{(r)},p^{(r)})\leq 1+O\left(\frac{1}{L}\right)\cdot\left[\Delta ^{(r)}_{\rm first}\right]^{2}+O\left(\sqrt{\frac{\log L}{L}}\right)\cdot\left| \Delta^{(r)}_{\rm first}\right|+L\cdot\mathds{1}\left[\text{round $r$ fails}\right].\]

We will upper bound the value of \(\mathbb{E}\left[\mathsf{smCE}(x^{(r)},p^{(r)})\right]\) by taking an expectation over both sides of the above. Therefore, we examine the expectation of \(|\Delta^{(r)}_{\rm first}|\) and \([\Delta^{(r)}_{\rm first}]^{2}\) conditioning on \(T^{(r)}=L\).

When the round is Type 1, there is nothing to upper bound. For Type 2 rounds, \(\Delta^{(r)}_{\rm first}\) is the difference between \(X_{\rm first}=\sum_{s=t+1}^{t+H}x_{s}\) and its mean \(\mu_{\rm first}H\). Since the variance of \(X_{\rm first}\) is \(O(L)\), we have \(\mathbb{E}\left[\left|\Delta^{(r)}_{\rm first}\right|\right]=O(\sqrt{L})\) and \(\mathbb{E}\left[\left[\Delta^{(r)}_{\rm first}\right]^{2}\right]=O(L)\).

Type 3 rounds are trickier. We assume that \(\mu_{\rm first}\leq 1/2\); this is without loss of generality since the \(\mu_{\rm first}>1/2\) case can be handled by a completely symmetric argument. Then, \(\Delta^{(r)}_{\rm first}\) is the difference between \(X_{\rm first}=\sum_{s=t+1}^{t+H}x_{s}\) and \(\alpha H\), and \(\alpha\) may differ from \(\mu_{\rm first}\) by at most \(\sqrt{\frac{2\mu_{\rm first}\ln L}{H}}\). This gives

\[\mathbb{E}\left[\left[\Delta^{(r)}_{\rm first}\right]^{2}\right] =\mathbb{E}\left[\left(X_{\rm first}-\mu_{\rm first}H\right)^{2} \right]+\left(\mu_{\rm first}H-\alpha H\right)^{2}\] \[\leq O(L)+O(\mu_{\rm first}H\ln L).\]

Now we use the fact that when \(\mu_{\rm first}\leq 1/2\), the round is Type 3 only if \(\mu_{\rm first}<10\sqrt{\frac{\ln T^{(r)}}{H}}\). This implies

\[O(\mu_{\rm first}H\ln L)\leq O(\sqrt{L}\cdot\log^{3/2}L),\]

which is dominated by the \(O(L)\) term. It then follows from Jensen's inequality that

\[\mathbb{E}\left[\left|\Delta^{(r)}_{\rm first}\right|\right]\leq\sqrt{\mathbb{ E}\left[\left[\Delta^{(r)}_{\rm first}\right]^{2}\right]}=O(\sqrt{L}).\]

Put everything together.Therefore, we have the upper bound

\[\mathbb{E}\left[\mathsf{smCE}(x^{(r)},p^{(r)})\middle|T^{(r)}=L\right]\] \[\leq 1+\mathbb{E}\left[O\left(\frac{1}{L}\right)\cdot\left[\Delta ^{(r)}_{\rm first}\right]^{2}+O\left(\sqrt{\frac{\log L}{L}}\right)\cdot\left| \Delta^{(r)}_{\rm first}\right|\middle|T^{(r)}=L\right]+L\cdot\Pr\left[\text{ round $r$ fails}\middle|T^{(r)}=L\right]\] \[\leq 1+O(\sqrt{\log L})+L\cdot O(1/L)=O(\sqrt{\log T}).\]

The second step applies our earlier conclusion that \(\mathbb{E}\left[\left|\Delta^{(r)}_{\rm first}\right|\right]=O(\sqrt{L})\) and \(\mathbb{E}\left[\left[\Delta^{(r)}_{\rm first}\right]^{2}\right]=O(L)\) conditioning on \(T^{(r)}=L\). Taking another expectation over the randomness in \(T^{(r)}\) shows that \(\mathsf{smCE}(x^{(r)},p^{(r)})=O(\sqrt{\log T})\) for every \(r\). Note that we have

\[\mathsf{smCE}(x,p) =\sup_{f\in\mathcal{F}}\sum_{t=1}^{T}f(p_{t})\cdot(x_{t}-p_{t})\] \[=\sup_{f\in\mathcal{F}}\sum_{r}\sum_{t}f(p_{t}^{(r)})\cdot(x_{t}^ {(r)}-p_{t}^{(r)})\] \[\leq\sum_{r}\sup_{f\in\mathcal{F}}\sum_{t}f(p_{t}^{(r)})\cdot(x_{t }^{(r)}-p_{t}^{(r)})\] \[=\sum_{r}\mathsf{smCE}(x^{(r)},p^{(r)}).\]Furthermore, there are at most \(O(\log T)\) rounds. It follows that \(\mathbb{E}\left[\mathsf{smCE}(x,p)\right]=O(\log^{3/2}T)\).

Finally, we note that in each round of the while-loop, the forecaster predicts at most \(2\) different values (namely, \(\alpha^{(r)}\) and \(\beta^{(r)}\)). Therefore, the predictions \(p_{1},p_{2},\ldots,p_{T}\) contain at most \(O(\log T)\) different values. By [1, Theorem 2], we conclude that

\[\mathbb{E}\left[\mathsf{CalDist}(x,p)\right]\leq O(1)\cdot\mathbb{E}\left[ \mathsf{smCE}(x,p)+|\{p_{1},p_{2},\ldots,p_{T}\}|\right]=O(\log^{3/2}T).\]

Now we prove Lemmas B.2 through B.4. In the proofs below, we frequently drop the superscript \((r)\) since we only refer to the \(r\)-th round.

Proof of Lemma b.2.: Recall that a Type 1 round is one in which the condition \(|\mu_{\mathrm{first}}-\mu|\geq\sqrt{\frac{2\ln T^{(r)}}{H}}\) holds in the if-statement. We say that the round _succeeds_, if we exit the for-loop using the "break" statement on Line 12, i.e., the condition \(i>H\) and \(|\Delta^{(r)}|\leq 1\) holds at some point (including in the last iteration where \(i=2H\)); otherwise, the round _fails_.

Note that only one value (namely, \(\alpha^{(r)}\)) is predicted within the round. Thus, if the round succeeds, we have

\[\mathsf{smCE}(x^{(r)},p^{(r)})=|\Delta_{\alpha^{(r)}}|=\left|\Delta^{(r)} \right|\leq 1.\]

It remains to control the probability for a Type 1 round to fail. Consider random variables

\[X_{\mathrm{first}}\coloneqq\sum_{s=t+1}^{t+H}x_{s}\quad\text{and}\quad X \coloneqq\sum_{s=t+1}^{t+2H}x_{s}.\]

Note that both are sums of independent Bernoulli random variables, with \(\mathbb{E}\left[X_{\mathrm{first}}\right]=\mu_{\mathrm{first}}H\) and \(\mathbb{E}\left[X\right]=2\mu H\). Also note that since \(\alpha=(\mu_{\mathrm{first}}+\mu)/2\), we have

\[|\mu_{\mathrm{first}}-\alpha|=|\mu-\alpha|=\frac{1}{2}\left|\mu_{\mathrm{ first}}-\mu|\geq\sqrt{\frac{\ln T^{(r)}}{2H}}.\]

Without loss of generality, suppose that \(\mu_{\mathrm{first}}\leq\mu\). By an additive Chernoff bound, we have

\[\Pr\left[X_{\mathrm{first}}/H\geq\alpha\right]\leq\exp\left(-2H\left(\alpha- \mu_{\mathrm{first}}\right)^{2}\right)\leq\frac{1}{T^{(r)}}.\]

and

\[\Pr\left[X/(2H)\leq\alpha\right]\leq\exp\left(-4H\left(\alpha-\mu\right)^{2} \right)\leq\frac{1}{T^{(r)}}.\]

Therefore, except with probability \(O(1/T^{(r)})\), we have both \(X_{\mathrm{first}}<\alpha H\) and \(X>2\alpha H\). In other words, if the for-loop (hypothetically) runs all the \(2H\) iterations, we would have \(\Delta^{(r)}<0\) at the end of the \(H\)-th iteration, and \(\Delta^{(r)}>0\) at the end of the \(2H\)-th iteration. Since \(\Delta^{(r)}\) changes by \(|x_{t}-p_{t}|\leq 1\) within each iteration, there must be an iteration \(i\in\{H+1,H+2,\ldots,2H\}\) at the end of which \(\Delta^{(r)}\) falls into \([0,1]\). By definition of Algorithm 1, we exit the for-loop at that time, and the \(r\)-th round succeeds. 

Proof of Lemma b.3.: Recall that in a Type 2 round, we have \(|\mu_{\mathrm{first}}-\mu|<\sqrt{\frac{2\ln T^{(r)}}{H}}\) and \(\alpha=\mu_{\mathrm{first}}\). Without loss of generality, suppose that \(\mu_{\mathrm{first}}\leq 1/2\); the case that \(\mu_{\mathrm{first}}>1/2\) follows from a completely symmetric argument. We say that a Type 2 round _succeeds_ if both conditions below are satisfied:

* When \(\beta\) is chosen, the clipping (i.e., taking the minimum with \(1\) or taking the maximum with \(0\)) is not effective.
* We exit the second for-loop through the break statement on Line 30.

Otherwise, the round _fails_.

Again, we first upper bound the smooth calibration error incurred within a successful round, and then control the probability for a round to fail. Since only \(\alpha\) and \(\beta\) are predicted in this round, we have

\[\mathsf{smCE}(x^{(r)},p^{(r)})=\sup_{f\in\mathcal{F}}[f(\alpha)\cdot\Delta_{ \alpha}+f(\beta)\cdot\Delta_{\beta}],\]

where \(\Delta_{\alpha}\) and \(\Delta_{\beta}\) are defined with respect to \(x^{(r)}\) and \(p^{(r)}\). The above is further given by

\[\sup_{f\in\mathcal{F}}[f(\beta)\cdot(\Delta_{\alpha}+\Delta_{\beta })+[f(\alpha)-f(\beta)]\cdot\Delta_{\alpha}]\] \[\leq\sup_{f\in\mathcal{F}}[f(\beta)\cdot(\Delta_{\alpha}+\Delta_{ \beta})]+\sup_{f\in\mathcal{F}}[(f(\alpha)-f(\beta))\cdot\Delta_{\alpha}]\] \[=|\Delta_{\alpha}+\Delta_{\beta}|+|\alpha-\beta|\cdot|\Delta_{ \alpha}|.\]

Note that \(\Delta_{\alpha}+\Delta_{\beta}\) is exactly the value of \(\Delta^{(r)}\) at the end of the second for-loop, while \(\Delta_{\alpha}\) is its value after the first for-loop, i.e., \(\Delta_{\mathrm{first}}^{(r)}\). Then, assuming that the round succeeds, we have \(|\Delta_{\alpha}+\Delta_{\beta}|\leq 1\) and

\[|\alpha-\beta|=|\mu_{\mathrm{first}}-\beta| \leq|\mu_{\mathrm{first}}-\mu_{\mathrm{second}}|+|\mu_{\mathrm{ second}}-\beta|\] \[\leq\sqrt{\frac{2\ln T^{(r)}}{H}}+\left(\frac{|\Delta_{\mathrm{ first}}^{(r)}|}{H}+\sqrt{\frac{\ln T^{(r)}}{2H}}\right)\] \[=O\left(\frac{1}{T^{(r)}}\right)\cdot|\Delta_{\mathrm{first}}^{(r )}|+O\left(\sqrt{\frac{\log T^{(r)}}{T^{(r)}}}\right).\]

Plugging the above back into the upper bound on \(\mathsf{smCE}(x^{(r)},p^{(r)})\) shows that in a successful Type 2 round,

\[\mathsf{smCE}(x^{(r)},p^{(r)})\leq 1+O\left(\frac{1}{T^{(r)}}\right)\cdot[ \Delta_{\mathrm{first}}^{(r)}]^{2}+O\left(\sqrt{\frac{\log T^{(r)}}{T^{(r)}} }\right)\cdot|\Delta_{\mathrm{first}}^{(r)}|.\]

In the following, we show that a Type 2 round succeeds with probability \(1-O(1/T^{(r)})\). Let \(X_{\mathrm{first}}:=\sum_{s=t+1}^{t+H}x_{s}\). Note that \(X_{\mathrm{first}}\) is a sum of \(H\) independent Bernoulli random variables and \(\mathbb{E}\left[X_{\mathrm{first}}\right]=\mu_{\mathrm{first}}H\). Furthermore, we have \(\Delta_{\mathrm{first}}^{(r)}=X_{\mathrm{first}}-\mu_{\mathrm{first}}H\). By an additive Chernoff bound, we have

\[\Pr\left[|\Delta_{\mathrm{first}}^{(r)}|\leq\sqrt{\frac{H\ln T^{(r)}}{2}} \right]=\Pr\left[|X_{\mathrm{first}}/H-\mu_{\mathrm{first}}|\leq\sqrt{\frac{ \ln T^{(r)}}{2H}}\right]\geq 1-\frac{2}{T^{(r)}}.\] (3)

Recall that we need to argue that no clipping is applied when \(\beta\) is chosen. We analyze the following two cases:

* **Case 1.**\(\Delta_{\mathrm{first}}^{(r)}\geq 0\). In this case, we need to show that \[\mu_{\mathrm{second}}+\frac{\Delta_{\mathrm{first}}^{(r)}}{H}+\sqrt{\frac{\ln T ^{(r)}}{2H}}\leq 1.\] Recall that we assumed \(\mu_{\mathrm{first}}\leq 1/2\) and \(|\mu_{\mathrm{first}}-\mu|<\sqrt{\frac{2\ln T^{(r)}}{H}}\). The latter further implies \(|\mu_{\mathrm{first}}-\mu_{\mathrm{second}}|=2|\mu_{\mathrm{first}}-\mu|<\sqrt {\frac{8\ln T^{(r)}}{H}}\). Thus, it suffices to prove that \[\sqrt{\frac{8\ln T^{(r)}}{H}}+\frac{|\Delta_{\mathrm{first}}^{(r)}|}{H}+\sqrt {\frac{\ln T^{(r)}}{2H}}\leq\frac{1}{2}.\] When \(|\Delta_{\mathrm{first}}^{(r)}|\leq\sqrt{\frac{H\ln T^{(r)}}{2}}\) (i.e., the event in Equation (3) holds), the left-hand side above is \(O\left(\sqrt{\frac{\log T^{(r)}}{T^{(r)}}}\right)\), which is below \(1/2\) as long as \(T^{(r)}\) exceeds some universal constant \(T_{0}\). Therefore, the probability that a clipping is applied is at most \(O(1/T^{(r)})\), where we absorb the constraint \(T^{(r)}\geq T_{0}\) into the hidden constant in \(O(\cdot)\).

* **Case 2.**\(\Delta_{\rm first}^{(r)}<0\). In this case, we need to show that \[\mu_{\rm second}+\frac{\Delta_{\rm first}^{(r)}}{H}-\sqrt{\frac{\ln T^{(r)}}{2H}}\geq 0.\] Recall that the definition of Type 2 rounds implies \(\mu_{\rm first}\geq 10\sqrt{\frac{\ln T^{(r)}}{H}}\). Thus, it suffices to prove that \[10\sqrt{\frac{\ln T^{(r)}}{H}}-\sqrt{\frac{2\ln T^{(r)}}{H}}-\frac{|\Delta_{ \rm first}^{(r)}|}{H}-\sqrt{\frac{\ln T^{(r)}}{2H}}\geq 0.\] The above holds whenever the event in Equation (3) happens, since \(10-\sqrt{2}-1/\sqrt{2}-1/\sqrt{2}>0\).

Finally, we argue that, with high probability, we exit the second for-loop via the break statement. Let \(X_{\rm second}\coloneqq\sum_{s=t+H+1}^{t+2H}x_{s}\) denote the total outcome in the second half. By symmetry, we only deal with the case that \(\Delta_{\rm first}^{(r)}\geq 0\), where we have \(\beta=\mu_{\rm second}+\Delta_{\rm first}^{(r)}/H+\sqrt{\frac{\ln T^{(r)}}{2 H}}\). If the second for-loop runs all the \(H\) iterations in full, at the end of it, the value of \(\Delta^{(r)}\) will be given by

\[\Delta_{\rm first}^{(r)}+X_{\rm second}-\beta H=X_{\rm second}-\mu_{\rm second }H-\sqrt{\frac{H\ln T^{(r)}}{2}}.\]

Note that the above is non-negative only if \(X_{\rm second}\leq\mu_{\rm second}H+\sqrt{\frac{H\ln T^{(r)}}{2}}\), which, by an additive Chernoff bound, holds with probability at most \(1/T^{(r)}\). Therefore, with probability \(1-1/T^{(r)}\), the value of \(\Delta^{(r)}\) must fall into \([-1,0]\) during the second for-loop, and we will take the break statement accordingly. 

Proof of Lemma b.4.: Again, without loss of generality, suppose that \(\mu_{\rm first}\leq 1/2\); the other case follows from a completely symmetric argument. In contrast to Type 1 and Type 2 rounds, we say that a Type 3 round _succeeds_ if all the following conditions hold simultaneously:

* \(\Delta_{\rm first}^{(r)}\geq 0\), i.e., \(\Delta^{(r)}\geq 0\) holds at the end of the first for-loop (on Line 25).
* When \(\beta\) is chosen, the clipping (i.e., taking the minimum with \(1\)) is not effective.
* We exit the second for-loop through the break statement on Line 30.

Otherwise, the round _fails_.

By the same argument as in the proof of Lemma B.3, in a successful Type 3 round, we have

\[\mathsf{smCE}(x^{(r)},p^{(r)})\leq 1+O\left(\frac{1}{T^{(r)}}\right)\cdot[ \Delta_{\rm first}^{(r)}]^{2}+O\left(\sqrt{\frac{\log T^{(r)}}{T^{(r)}}} \right)\cdot|\Delta_{\rm first}^{(r)}|.\]

The only change in the argument is the upper bound on \(|\alpha-\beta|\), since \(\alpha\) is no longer equal to \(\mu_{\rm first}\). Nevertheless, we still have

\[|\alpha-\beta| \leq|\alpha-\mu_{\rm first}|+|\mu_{\rm first}-\mu_{\rm second}|+ |\mu_{\rm second}-\beta|\] \[\leq\sqrt{\frac{2\mu_{\rm first}\ln T^{(r)}}{H}}+\sqrt{\frac{2 \ln T^{(r)}}{H}}+\left(\frac{|\Delta_{\rm first}^{(r)}|}{H}+\sqrt{\frac{\ln T ^{(r)}}{2H}}\right)\] \[=O\left(\frac{1}{T^{(r)}}\right)\cdot|\Delta_{\rm first}^{(r)}|+O \left(\sqrt{\frac{\log T^{(r)}}{T^{(r)}}}\right),\]

and the rest of the analysis goes through.

Thus, it remains to show that a Type 3 round succeeds with probability \(1-O(1/T^{(r)})\). Let \(X_{\rm first}\coloneqq\sum_{s=t+1}^{t+H}x_{s}\). Note that \(X_{\rm first}\) is a sum of independent Bernoulli random variables and \(\mathbb{E}\left[X_{\rm first}\right]=\mu_{\rm first}H\). By a multiplicative Chernoff bound, for any \(\delta\geq 0\), we have

\[\Pr\left[X_{\rm first}/H\leq(1-\delta)\mu_{\rm first}\right]\leq\exp\left(- \delta^{2}\mu_{\rm first}H/2\right).\]In particular, plugging \(\delta=\sqrt{\frac{2\ln T^{(r)}}{\mu_{\rm first}H}}\) into the above gives

\[\Pr\left[X_{\rm first}/H\leq\mu_{\rm first}-\sqrt{\frac{2\mu_{\rm first}\ln T^{(r )}}{H}}\right]\leq\frac{1}{T^{(r)}}.\]

Recall that \(\alpha\) is chosen as the maximum between \(\mu_{\rm first}-\sqrt{\frac{2\mu_{\rm first}\ln T^{(r)}}{H}}\) and \(0\). Thus, with probability at least \(1-1/T^{(r)}\), we have \(X_{\rm first}/H\geq\alpha\), which is equivalent to \(\Delta^{(r)}\geq 0\) at the end of the first for-loop.

Then, we need to argue that when \(\beta\) is chosen, we have \(\mu_{\rm second}+\Delta^{(r)}/H+\sqrt{\frac{\ln T^{(r)}}{2H}}\leq 1\). We will show the equivalent inequality:

\[(\mu_{\rm second}-1/2)+\Delta^{(r)}/H+\sqrt{\frac{\ln T^{(r)}}{2H}}\leq 1/2.\]

For the first term, we note that since \(\mu=(\mu_{\rm first}+\mu_{\rm second})/2\), the assumption \(|\mu_{\rm first}-\mu|<\sqrt{\frac{2\ln T^{(r)}}{H}}\) implies \(|\mu_{\rm first}-\mu_{\rm second}|=O\left(\sqrt{\frac{\log T^{(r)}}{T^{(r)} }}\right)\). With the additional assumption that \(\mu_{\rm first}\leq 1/2\), we have

\[\mu_{\rm second}-1/2\leq(\mu_{\rm first}-1/2)+|\mu_{\rm first}-\mu_{\rm second }|\leq O\left(\sqrt{\frac{\log T^{(r)}}{T^{(r)}}}\right).\]

For the second term, we note that, at the end of the first for-loop, \(\Delta^{(r)}/H\) is given by

\[\frac{X_{\rm first}-\alpha H}{H}=\left(\frac{X_{\rm first}}{H}-\mu_{\rm first }\right)+(\mu_{\rm first}-\alpha).\]

By an additive Chernoff bound, \(\frac{X_{\rm first}}{H}-\mu_{\rm first}\leq O\left(\sqrt{\frac{\log T^{(r)}}{ T^{(r)}}}\right)\) holds with probability \(1-O(1/T^{(r)})\). By our choice of \(\alpha\), \(\mu_{\rm first}-\alpha\) is always \(O\left(\sqrt{\frac{\log T^{(r)}}{T^{(r)}}}\right)\). Finally, the last term is clearly \(O\left(\sqrt{\frac{\log T^{(r)}}{T^{(r)}}}\right)\). Therefore, as long as \(T^{(r)}\) is larger than a universal constant \(T_{0}\), the total \(O\left(\sqrt{\frac{\log T^{(r)}}{T^{(r)}}}\right)\) term is upper bounded by \(1/2\). Again, we can absorb the condition \(T^{(r)}\geq T_{0}\) into the big-\(O\) notation, so the second condition (that \(\beta\) is not clipped) is satisfied with probability \(1-O(1/T^{(r)})\).

Finally, we argue that we exit the second for-loop via the break statement with high probability. Let \(X_{\rm second}\coloneqq\sum_{s=t+H+1}^{t+2H}x_{s}\) denote the total outcome in the second half. Recall that we have \(\Delta^{(r)}\geq 0\) at the end of the first for-loop, and that \(\beta=\mu_{\rm second}+\Delta^{(r)}/H+\sqrt{\frac{\ln T^{(r)}}{2H}}\). If the second for-loop runs all the \(H\) iterations in full, at the end of it, the value of \(\Delta^{(r)}\) will be given by

\[\Delta^{(r)}_{\rm first}+X_{\rm second}-\beta H=X_{\rm second}-\mu_{\rm second }H-\sqrt{\frac{H\ln T^{(r)}}{2}}.\]

Note that the above is non-negative only if \(X_{\rm second}\leq\mu_{\rm second}H+\sqrt{\frac{H\ln T^{(r)}}{2}}\), which, by an additive Chernoff bound, holds with probability at most \(1/T^{(r)}\). Therefore, with probability \(1-1/T^{(r)}\), the value of \(\Delta^{(r)}\) must fall into \([-1,0]\) during the second for-loop, and we will take the break statement accordingly. 

### The Lower Bound Part

We prove the lower bound part of Theorem B.1 via a central limit theorem.

Proof of Theorem b.1, the lower bound part.: On the product distribution \(\mathcal{D}=\prod_{t=1}^{T}\mathsf{Bernoulli}(p_{t}^{\star})\), the truthful forecaster predicts \(p_{t}=p_{t}^{\star}\) at every step \(t\). Then, we have

\[\mathop{\mathbb{E}}_{x\sim\mathcal{D}}\left[\mathsf{smCE}(x,p^{\star})\right]= \mathop{\mathbb{E}}_{x\sim\mathcal{D}}\left[\sup_{f\in\mathcal{F}}\sum_{t=1} ^{T}f(p_{t}^{\star})\cdot(x_{t}-p_{t}^{\star})\right]\geq\mathop{\mathbb{E}}_ {x\sim\mathcal{D}}\left[\left|\sum_{t=1}^{T}(x_{t}-p_{t}^{\star})\right|\right],\]

where we use the fact that \(\mathcal{F}\) contains the constant functions \(f\equiv 1\) and \(f\equiv-1\).

Applying the Berry-Esseen theorem [10] to the random variable \(X\coloneqq\sum_{t=1}^{T}(x_{t}-p_{t}^{\star})\) gives:

\[\forall x\in\mathbb{R},\;\left|\Pr\left[X\leq x\cdot\sigma_{0}\right]-\Phi(x )\right|\leq C_{0}\cdot\sigma_{0}^{-1}\cdot\rho_{0},\]

where \(\Phi(x)\) is CDF of the standard normal distribution, \(C_{0}\leq 0.56\) is a universal constant, and

\[\sigma_{0} =\sqrt{\sum_{t=1}^{T}\mathop{\mathbb{E}}\left[(x_{t}-p_{t}^{ \star})^{2}\right]}=\sqrt{\sum_{t=1}^{T}p_{t}^{\star}(1-p_{t}^{\star})}\geq \sqrt{T\delta(1-\delta)};\] \[\rho_{0} =\max_{t\in[T]}\frac{\mathop{\mathbb{E}}\left[|x_{t}-p_{t}^{ \star}|^{3}\right]}{\mathop{\mathbb{E}}\left[|x_{t}-p_{t}^{\star}|^{2}\right]} =\max_{t\in[T]}\frac{p_{t}^{\star}(1-p_{t}^{\star})\cdot[(p_{t}^{ \star})^{2}+(1-p_{t}^{\star})^{2}]}{p_{t}^{\star}(1-p_{t}^{\star})}\leq 1.\]

In particular, taking \(x=-1\) gives:

\[\Pr\left[X\leq-\sigma_{0}\right]\geq\Phi(-1)-C_{0}\cdot\sigma_{0}^{-1}\cdot \rho_{0}=\Omega(1)-O(1/\sqrt{T}).\]

For all sufficiently large \(T\), the \(O(1/\sqrt{T})\) term is dominated by the \(\Omega(1)\) term, in which case we have

\[\mathop{\mathbb{E}}_{x\sim\mathcal{D}}\left[\mathsf{smCE}(x,p^{\star})\right] \geq\mathop{\mathbb{E}}\left[\left|X\right|\right]\geq\sigma_{0}\cdot\Pr\left[ X\leq-\sigma_{0}\right]=\Omega(\sqrt{T}).\]

Finally, by the inequality \(\frac{1}{2}\mathsf{smCE}(x,p)\leq\mathsf{CalDist}(x,p)\)[1, Lemma 5.4 and Theorem 7.3], the distance from calibration incurred by the truthful forecaster is also \(\Omega(\sqrt{T})\). 

## Appendix C Supplemental Materials for Section 5

The following is a tighter version of Theorem 5.1.

**Theorem C.1**.: _For any \(\mathcal{D}\in\Delta(\{0,1\}^{T})\), \(\mathsf{err_{SSCE}}(\mathcal{D},\mathcal{A}^{truthful}(\mathcal{D}))=O( \mathop{\mathbb{E}}\left[\gamma(\mathrm{Var}_{T})\right])\), where \(\gamma(x)\coloneqq\begin{cases}x,&x<1,\\ \sqrt{x},&x\geq 1.\end{cases}\)_

Proof.: Given a function \(f:[0,1]\to[-1,1]\) and binary vector \(y\in\{0,1\}^{T}\), we define the martingale \(M_{t}(f,y)\coloneqq\sum_{s=1}^{t}y_{s}\cdot f(p_{s}^{\star})\cdot(x_{s}-p_{s}^ {\star})\) where \(x\sim\mathcal{D}\) and we use \(\mathbb{F}_{t}\) to denote the filtration describing the randomness of \(M_{T}(f,y)\) up to time \(t\) and \(p_{t}^{\star}\coloneqq\mathop{\mathbb{E}}\left[x_{t}\left|\mathbb{F}_{t-1}\right.\right]\). Note that, conditioned on \(\mathbb{F}_{t-1}\), \(x_{t}\) is distributed as a Bernoulli with parameter \(p_{t}^{\star}\).

We can write the \(\mathsf{SSCE}\) of a truthful forecaster in terms of \(M_{T}(f,y)\) as

\[\mathsf{SSCE}(x,p^{\star})\coloneqq\mathop{\mathbb{E}}_{y\sim\mathrm{Unif}\{ 0,1\}^{T}}\left[\sup_{f\in\mathcal{F}}M_{T}(f,y)\right].\]

We now proceed via chaining and define the dyadic scale \(\varepsilon_{k}=2^{1-k}\) for \(k=0,1,2,\ldots\). To cover the set of Lipschitz functions \(\mathcal{F}\), we will use the sets of piecewise constant functions \(\left\{\mathcal{F}_{\delta}\right\}_{\delta>0}\) described in Lemma C.2. For each function \(f\in\mathcal{F}\), let \(\pi_{k}(f)\) be a close function in \(\mathcal{F}_{\varepsilon_{k}}\) such that \(d(f,\pi_{k}(f))\leq 2\varepsilon_{k}\). Observe that the covering \(\mathcal{F}_{\varepsilon_{0}}\) is a singleton and that \(\pi_{k}(f)\) always exists as \(\mathcal{F}_{\varepsilon_{k}}\) is a \(2\varepsilon_{k}\)-covering of \(\mathcal{F}\). Telescoping then gives

\[f(x)=(f(x)-\pi_{M}(f)(x))+\pi_{0}(f)(x)+\sum_{i=1}^{M}\left[\pi_{i}(f)(x)-\pi_{ i-1}(f)(x)\right],\]meaning that we have

\[\mathsf{SSCE}(x,p^{\star})\leq\underbrace{\mathbb{E}}_{y\sim\mathrm{Unif }(\{0,1\}^{T})}\left[\sup_{f\in\mathcal{F}}\sum_{t=1}^{T}y_{t}\cdot(f(p_{t}^{ \star})-\pi_{M}(f)(p_{t}^{\star}))\cdot(x_{t}-p_{t}^{\star})\right]}_{\text{( Term A)}}\] \[\qquad+\underbrace{\mathbb{E}}_{y\sim\mathrm{Unif}(\{0,1\}^{T}) }\left[\sup_{f\in\mathcal{F}}\sum_{t=1}^{T}y_{t}\cdot\pi_{0}(f)(p_{t}^{\star}) \cdot(x_{t}-p_{t}^{\star})\right]}_{\text{(Term B)}}\] \[\qquad+\underbrace{\mathbb{E}}_{y\sim\mathrm{Unif}(\{0,1\}^{T}) }\left[\sup_{f\in\mathcal{F}}\sum_{i=1}^{M}\sum_{t=1}^{T}y_{t}\cdot(\pi_{i}(f )(p_{t}^{\star})-\pi_{i-1}(f)(p_{t}^{\star}))\cdot(x_{t}-p_{t}^{\star})\right] }_{\text{(Term C)}}.\] (4)

First, we can use that \(d(f(p_{t}^{\star})-\pi_{M}(f)(p_{t}^{\star}))\leq 2^{2-M}\) to deterministically bound Term A by

\[\mathbb{E}_{y\sim\mathrm{Unif}(\{0,1\}^{T})}\left[\sup_{f\in\mathcal{F}}\sum _{t=1}^{T}y_{t}\cdot(f(p_{t}^{\star})-\pi_{M}(f)(p_{t}^{\star}))\cdot(x_{t}-p_ {t}^{\star})\right]\leq 2^{2-M}\cdot T.\]

Second, we can observe that the image of \(\pi_{0}(f)\) is a singleton: \(|\left\{\pi_{0}(f)\mid f\in\mathcal{F}\right\}|=1\); let this unique function be denoted by \(f^{\star}\). Then, Term B reduces to \(\mathbb{E}_{y\sim\mathrm{Unif}(\{0,1\}^{T})}\left[M_{T}(f^{\star},y)\right]\), which evaluates to \(0\) after taking an expectation over \(x\sim\mathcal{D}\), since for every \(y\in\{0,1\}^{T}\), \((M_{t}(f^{\star},y))_{0\leq t\leq T}\) forms a martingale. Third, we can observe that \(\pi_{i}(f)-\pi_{i-1}(f)\) is a function from \([0,1]\to\left\{-2^{1-i},0,2^{1-i}\right\}\) that takes a constant value along the segments \([(j-1)2^{1-i},j2^{1-i})\) for all \(j\in[2^{i-1}]\). Thus, we can bound the summands of Term C by

\[\mathbb{E}_{y\sim\mathrm{Unif}(\{0,1\}^{T})}\left[\sup_{f\in \mathcal{F}}\sum_{t=1}^{T}y_{t}\cdot(\pi_{i}(f)(p_{t}^{\star})-\pi_{i-1}(f)(p_ {t}^{\star}))\cdot(x_{t}-p_{t}^{\star})\right]\] \[\leq\sum_{j=0}^{2^{i-1}}\mathbb{E}_{y\sim\mathrm{Unif}(\{0,1\}^{ T})}\left[\sup_{v\in\{0,\pm 2^{1-i}\}}\sum_{t=1}^{T}y_{t}\cdot v\cdot(x_{t}-p_{t}^{ \star})\cdot\mathbbm{1}\left[j2^{1-i}\leq p_{t}^{\star}<(j+1)2^{1-i}\right]\right]\] \[\leq\sum_{j=0}^{2^{i-1}}2^{1-i}\mathbb{E}_{y\sim\mathrm{Unif}(\{ 0,1\}^{T})}\left[\sup_{v\in\{\pm 1\}}\underbrace{\sum_{t=1}^{T}y_{t}\cdot v\cdot(x_{t}-p_{t}^{ \star})\cdot\mathbbm{1}\left[j2^{1-i}\leq p_{t}^{\star}<(j+1)2^{1-i}\right]}_{ =:M_{T}(v,y,i,j)}\right].\]

Invoking Lemma C.9 with \(\mathcal{G}=\{x\mapsto 1,x\mapsto-1\}\) and \(\mathcal{I}=\left[j2^{1-i},(j+1)2^{1-i}\right)\), we have that for all \(i\in[M]\), \(j\in\{0,1,\ldots,2^{i-1}\}\), and \(y\in\{0,1\}^{T}\):

\[\mathbb{E}_{x\sim\mathcal{D}}\left[\sup_{v\in\{\pm 1\}}M_{T}(v,y,i,j)\right]\leq( 48+8\ln 2)\,\mathbb{E}_{x\sim\mathcal{D}}\left[\gamma\left(\sum_{t=1}^{T}p_{t}^{ \star}(1-p_{t}^{\star})\mathbbm{1}\left[j2^{1-i}\leq p_{t}^{\star}<(j+1)2^{1-i} \right]\right)\right].\]

Plugging this into Term C, we have

\[\mathbb{E}_{x\sim\mathcal{D}}\left[\text{Term C}\right] \leq(48+8\ln 2)\sum_{i=1}^{M}2^{1-i}\sum_{j=0}^{2^{i-1}}\mathbb{E}_{x \sim\mathcal{D}}\left[\gamma\left(\sum_{t=1}^{T}p_{t}^{\star}(1-p_{t}^{\star}) \mathbbm{1}\left[j2^{1-i}\leq p_{t}^{\star}<(j+1)2^{1-i}\right]\right)\right]\] \[=(48+8\ln 2)\sum_{i=1}^{M}2^{1-i}\,\mathbb{E}_{x\sim\mathcal{D}} \left[\sum_{j=0}^{2^{i-1}}\gamma\left(\sum_{t=1}^{T}p_{t}^{\star}(1-p_{t}^{ \star})\mathbbm{1}\left[j2^{1-i}\leq p_{t}^{\star}<(j+1)2^{1-i}\right]\right) \right].\]Using Lemma C.3, we can simplify

\[\mathop{\mathbb{E}}_{x\sim\mathcal{D}}\left[\mathrm{Term\ C}\right] \leq(48+8\ln 2)\sum_{i=1}^{M}2^{1-i}\cdot\sqrt{2^{i-1}+1}\mathop{ \mathbb{E}}_{x\sim\mathcal{D}}\left[\gamma\left(\sum_{j=0}^{2^{i-1}}\sum_{t=1}^ {T}p_{t}^{\star}(1-p_{t}^{\star})\mathbbm{1}\left[j2^{1-i}\leq p_{t}^{\star}<(j +1)2^{1-i}\right]\right)\right]\] \[\leq(48+8\ln 2)\sum_{i=1}^{M}2^{1-i/2}\mathop{\mathbb{E}}_{x\sim \mathcal{D}}\left[\gamma\left(\sum_{t=1}^{T}p_{t}^{\star}(1-p_{t}^{\star}) \right)\right]\] \[=(48+8\ln 2)\cdot(2+2\sqrt{2})\cdot\mathop{\mathbb{E}}_{x\sim \mathcal{D}}\left[\gamma\left(\mathrm{Var}_{T}\right)\right].\]

Plugging this into (4) and observing that we can choose \(M\) to be arbitrarily large, we have as desired

\[\mathop{\mathbb{E}}_{x\sim\mathcal{D}}\left[\mathsf{SSCE}(x,p^{ \star})\right] \leq\inf_{M\in\mathbb{N}}\left[2^{2-M}\cdot T+\mathop{\mathbb{E}} _{x\sim\mathcal{D}}\left[\mathrm{Term\ C}\right]\right]\] \[\leq(48+8\ln 2)\cdot(2+2\sqrt{2})\cdot\mathop{\mathbb{E}}_{x \sim\mathcal{D}}\left[\gamma\left(\mathrm{Var}_{T}\right)\right].\]

### Auxiliary Lemmas

Covering Lipschitz functions.Let us first recall a standard covering of the class of Lipschitz functions \(\mathcal{F}\subseteq[-1,1]^{[0,1]}\). We will work with the metric \(d\) on the functions \(\mathcal{F}\) induced by the \(\infty\)-norm; that is, for any \(f,g\in\mathcal{F}\), \(d(f,g)\coloneqq\sup_{x\in[0,1]}|f(x)-g(x)|\). In this section, for \(\delta>0\) and \(b>a\) where \(\frac{b-a}{\delta}\in\mathbb{Z}\), we will use the shorthand \([a,b]_{\delta}\coloneqq\{a,a+\delta,\ldots,b\}\) to denote endpoints of partitioning of \([a,b]\) into segments of length \(\delta\). We will also use the shorthand \(\left\lfloor x\right\rfloor_{\delta}\coloneqq\max\left\{i\delta\mid i\delta \leq x,i\in\mathbb{Z}\right\}\) to denote rounding down to the nearest multiple of \(\delta\).

**Lemma C.2**.: _For \(\delta>0\) where \(\frac{1}{\delta}\in\mathbb{Z}\), consider all functions \(f:[0,1]\to[-1,1]\) that satisfy conditions_

\[(1) \forall x\in[0,1]_{\delta}:f(x)\in[-1,1]_{\delta}\] \[(2) \forall x\in[0,1]_{\delta}\setminus\{1\}:|f(x+\delta)-f(x)|\leq\delta\] \[(3) \forall x\in[0,1]:f(x)=f(\left\lfloor x\right\rfloor_{\delta}).\]

_This set of functions, which we will denote by \(\mathcal{F}_{\delta}\), is a \(2\delta\)-covering of the set of 1-Lipschitz functions \(\mathcal{F}:[0,1]\to[-1,1]\) in the metric \(d\)._

Proof.: Fix a 1-Lipschitz function \(f\in\mathcal{F}\). Let \(f^{\prime}\in\mathcal{F}_{\delta}\) be the function in our covering where, for all \(x\in[0,1]_{\delta}\), \(f^{\prime}(x)=\left\lfloor f(x)\right\rfloor_{\delta}\). Note that \(f^{\prime}\) is unique because the elements of \(\mathcal{F}_{\delta}\) can be identified by their image on \([0,1]_{\delta}\). For any \(x\in[0,1]\), we have

\[|f(x)-f^{\prime}(x)| \leq\left.|f(x)-f(\left\lfloor x\right\rfloor_{\delta})\right|+|f ^{\prime}(x)-f^{\prime}(\left\lfloor x\right\rfloor_{\delta})|+|f(\left\lfloor x \right\rfloor_{\delta})-f^{\prime}(\left\lfloor x\right\rfloor_{\delta})|\] \[\leq\left.|x-\left\lfloor x\right\rfloor_{\delta}\right|+0+|f( \left\lfloor x\right\rfloor_{\delta})-f^{\prime}(\left\lfloor x\right\rfloor_{ \delta})|\] \[\leq 2\delta,\]

where the first inequality is the triangle inequality, the second inequality uses the \(1\)-Lipschitzness of \(f\) and that \(f^{\prime}(x)=f^{\prime}(\left\lfloor x\right\rfloor_{\delta})\), and the third inequality uses the fact that \(|f(z)-f^{\prime}(z)|\leq\delta\) and \(|z-\left\lfloor z\right\rfloor_{\delta}|\leq\delta\) for all \(z\in[0,1]\). 

Bounding sums of \(\gamma\).Consider the piecewise function \(\gamma(x)\coloneqq\begin{cases}x,&x<1,\\ \sqrt{x},&x\geq 1.\end{cases}\)

**Lemma C.3**.: _For all values \(x_{1},\ldots,x_{n}\geq 0\), we can upper bound \(\sum_{i=1}^{n}\gamma(x_{i})\leq\sqrt{n}\cdot\gamma(\sum_{i=1}^{n}x_{i})\)._

Proof.: First, suppose that \(\sum_{i=1}^{n}x_{i}\leq 1\). Then, \(\gamma(\sum_{i=1}^{n}x_{i})=\sum_{i=1}^{n}x_{i}\) and \(x_{i}\leq 1\) for all \(i\in[n]\). The claim is therefore equivalent to the trivial statement \(\sum_{i=1}^{n}x_{i}\leq\sqrt{n}\cdot\sum_{i=1}^{n}x_{i}\).

Now suppose that \(\sum_{i=1}^{n}x_{i}>1\). The Cauchy-Schwarz inequality gives

\[\sum_{i=1}^{n}\sqrt{x_{i}}\leq\sqrt{n}\sqrt{\sum_{i=1}^{n}x_{i}}.\]

By our assumption that \(\sum_{i=1}^{n}x_{i}>1\), we have \(\gamma(\sum_{i=1}^{n}x_{i})=\sqrt{\sum_{i=1}^{n}x_{i}}\). We separately have that

\[\sum_{i=1}^{n}\gamma(x_{i})\leq\sum_{i=1}^{n}\sqrt{x_{i}},\]

because \(\gamma(x)=x\leq\sqrt{x}\) for \(x\in[0,1]\) and \(\gamma(x)=\sqrt{x}=\sqrt{x}\) for \(x\geq 1\). Thus,

\[\sum_{i=1}^{n}\gamma(x_{i})\leq\sum_{i=1}^{n}\sqrt{x_{i}}\leq\sqrt{n}\sqrt{ \sum_{i=1}^{n}x_{i}}=\sqrt{n}\cdot\gamma\left(\sum_{i=1}^{n}x_{i}\right).\]

### Epochs of Doubling Realized Variance

**Definition C.4**.: _For \(\mathcal{I}\subseteq[0,1]\), consider the stochastic process \((\mathrm{Var}_{t}(\mathcal{I}))_{0\leq t\leq T}\) defined as_

\[\mathrm{Var}_{t}(\mathcal{I})\coloneqq\sum_{s=1}^{t}p_{s}^{\star}(1-p_{s}^{ \star})\cdot 1\left[p_{s}^{\star}\in\mathcal{I}\right],\]

_where \(x\sim\mathcal{D}\) and \(p_{t}^{\star}\coloneqq\Pr_{x^{\prime}\sim\mathcal{D}}\left[x_{t}^{\prime}=1|x_ {1:(t-1)}^{\prime}=x_{1:(t-1)}\right]\). We define the epochs with respect to \(\mathcal{I}\) as the sequence \(\tau_{0},\tau_{1},\dots\in\mathbb{N}\) where \(\tau_{0}=0\) and, for each \(k\in\left[\lceil\log_{2}(T)\rceil+2\right]\),_

\[\tau_{k}\coloneqq\min\left\{t\in[\tau_{k-1}+1,T]\mid\mathrm{Var}_{t}( \mathcal{I})-\mathrm{Var}_{\tau_{k-1}}(\mathcal{I})\geq 2^{k-1}\right\}\cup\left\{ \infty\right\}.\] (5)

The epochs \(\tau_{0},\tau_{1},\dots\) defined in Definition C.4 partition the \(T\) time steps of a martingale into epochs such that the realized variance \(\mathrm{Var}_{t}(\mathcal{I})\) increases by approximately \(2^{k-1}\) within the \(k\)-th epoch. In particular, we can understand \(\tau_{k}\) as pointing to the last time step of the \(k\)th epoch. The definition of \(\tau\) ensures that:

* Epoch \(1\) starts from time step \(1\), and ends at the earliest time step \(t\) such that \(\mathrm{Var}_{t}(\mathcal{I})\geq 1=2^{0}\).
* For \(k\geq 2\), Epoch \(k\) starts from the time step after the last step of Epoch \(k-1\), and ends at the earliest time step such that the total variance within the epoch reaches \(2^{k-1}\).

We have the following technical facts about the epochs \(\tau\).

**Fact C.5**.: _The \((\lceil\log_{2}(T)\rceil+2)\)-th epoch is never complete, i.e., \(\tau_{\lceil\log_{2}(T)\rceil+2}=\infty\)._

Proof.: Our definition of \(\mathrm{Var}_{t}(\mathcal{I})\) clearly guarantees \(\mathrm{Var}_{T}(\mathcal{I})\leq T\), which implies

\[\mathrm{Var}_{T}(\mathcal{I})-\mathrm{Var}_{\tau_{\lceil\log_{2}(T)\rceil+1}}( \mathcal{I})\leq T<2^{\lceil\log_{2}(T)\rceil+1},\]

and therefore, \(\tau_{\lceil\log_{2}(T)\rceil+2}=\infty\). 

**Fact C.6**.: _For every epoch \(k\in[\lceil\log_{2}(T)\rceil+2]\), the change in realized variance in epoch \(k\) is deterministically upper bounded by \(\mathrm{Var}_{\tau_{k}}(\mathcal{I})-\mathrm{Var}_{\tau_{k-1}}(\mathcal{I})<2^{ k-1}+1\)._

Proof.: By definition, \(\mathrm{Var}_{\tau_{k}-1}(\mathcal{I})-\mathrm{Var}_{\tau_{k-1}}(\mathcal{I})<2 ^{k-1}\). Because \(p_{t}^{\star}\in[0,1]\) for all \(t\in[T]\), the realized variance increases by at most \(p_{t}^{\star}(1-p_{t}^{\star})\leq 1\) in each timestep, i.e. \(\mathrm{Var}_{\tau_{k}}(\mathcal{I})-\mathrm{Var}_{\tau_{k}-1}(\mathcal{I})\leq 1\). The fact follows by summing the two inequalities. 

**Fact C.7**.: _For any epoch \(k\in[\lceil\log_{2}(T)\rceil+2]\), the probability that the \(k\)th epoch ends is at most_

\[\Pr\left[\tau_{k}<\infty\right]\leq\min\left\{\frac{\mathbb{E}\left[1\left| \mathrm{Var}_{T}(\mathcal{I})\geq 1\right|\cdot\sqrt{\mathrm{Var}_{T}( \mathcal{I})}\right]}{\sqrt{2^{k-1}}},1\right\}.\]Proof.: The sequence of realized variances \(\operatorname{Var}_{1}(\mathcal{I}),\ldots,\operatorname{Var}_{T}(\mathcal{I})\) is deterministically non-decreasing. Thus, for every epoch \(k\in[\lceil\log_{2}(T)\rceil+2]\),

\[\Pr\left[\tau_{k}<\infty\right] \leq\Pr\left[\operatorname{Var}_{T}(\mathcal{I})-\operatorname{ Var}_{\tau_{k-1}}\geq 2^{k-1}\wedge\operatorname{Var}_{T}(\mathcal{I})\geq 1\right]\] \[\leq\Pr\left[1\left[\operatorname{Var}_{T}(\mathcal{I})\geq 1 \right]\cdot\operatorname{Var}_{T}(\mathcal{I})\geq 2^{k-1}\right]\] \[=\Pr\left[1\left[\operatorname{Var}_{T}(\mathcal{I})\geq 1 \right]\cdot\sqrt{\operatorname{Var}_{T}(\mathcal{I})}\geq\sqrt{2^{k-1}}\right],\]

with the second inequality following as \(\tau_{1}<\infty\) implies \(\operatorname{Var}_{T}(\mathcal{I})\geq 1\). We can next invoke Markov's inequality \(\Pr\left[X\geq a\right]\leq\frac{\operatorname{\mathbb{E}}[X]}{a}\) with \(a=\sqrt{2^{k-1}}\) and \(X=1\left[\operatorname{Var}_{T}(\mathcal{I})\geq 1\right]\cdot\sqrt{ \operatorname{Var}_{T}(\mathcal{I})}\) to recover

\[\Pr\left[1\left[\operatorname{Var}_{T}(\mathcal{I})\geq 1\right]\cdot \sqrt{\operatorname{Var}_{T}}\geq\sqrt{2^{k-1}}\right]\leq\min\left\{\frac{ \operatorname{\mathbb{E}}\left[1\left[\operatorname{Var}_{T}(\mathcal{I}) \geq 1\right]\cdot\sqrt{\operatorname{Var}_{T}(\mathcal{I})}\right]}{\sqrt{ 2^{k-1}}},1\right\}.\]

**Fact C.8**.: _The exponentially weighted sum of probabilities that each epoch ends is at most_

\[\sum_{k=2}^{\lceil\log_{2}(T)\rceil+2}\sqrt{2^{k-1}}\Pr[\tau_{k-1}<\infty]\leq (2\sqrt{2}+2)\operatorname{\mathbb{E}}\left[1\left[\operatorname{Var}_{T}( \mathcal{I})\geq 1\right]\cdot\sqrt{\operatorname{Var}_{T}(\mathcal{I})}\right].\]

Proof.: We will prove the deterministic inequality

\[\sum_{k=2}^{\lceil\log_{2}(T)\rceil+2}\sqrt{2^{k-1}}\cdot 1\left[\tau_{k-1}<\infty \right]\leq(2\sqrt{2}+2)1\left[\operatorname{Var}_{T}(\mathcal{I})\geq 1 \right]\cdot\sqrt{\operatorname{Var}_{T}(\mathcal{I})};\]

the fact follows from taking an expectation on both sides.

Let \(K=\max\left\{k\mid\tau_{k}<\infty\right\}\) be the number of completed epochs. When \(K=0\), we have \(\operatorname{Var}_{T}(\mathcal{I})<1\), and both sides of the above reduce to \(0\). Now, suppose that \(K\geq 1\), in which case we have \(\operatorname{Var}_{T}(\mathcal{I})\geq 1\). By telescoping, we can lower bound the realized variance by

\[\operatorname{Var}_{T}(\mathcal{I})\geq\sum_{k=1}^{K}2^{k-1}\geq 2^{K-1}.\]

Separately, by definition of \(K\), we have

\[\sum_{k=2}^{\lceil\log_{2}(T)\rceil+2}\sqrt{2^{k-1}}\cdot 1\left[\tau_{k-1}<\infty\right] =\sum_{k=2}^{K+1}\sqrt{2^{k-1}}\] \[=1\left[\operatorname{Var}_{T}(\mathcal{I})\geq 1\right]\sum_{k=2}^{K+1 }\sqrt{2^{k-1}}\] \[\leq 1\left[\operatorname{Var}_{T}(\mathcal{I})\geq 1\right]\sqrt{ 2^{K}}(\sqrt{2}+2)\]

with the second equality following from \(\operatorname{Var}_{T}(\mathcal{I})\geq 1\). Combining the previous two inequalities gives the desired inequality

\[\sum_{k=2}^{\lceil\log_{2}(T)\rceil+2}\sqrt{2^{k-1}}\cdot 1\left[\tau_{k-1}<\infty\right]\leq(2\sqrt{2}+2)1 \left[\operatorname{Var}_{T}(\mathcal{I})\geq 1\right]\cdot\sqrt{\operatorname{Var}_{T}( \mathcal{I})}.\]

### Random Walks with Early Stopping

We now prove a technical result that the magnitude of a random walk with random variance can be upper bounded by its (expected) standard deviation. Compared to Lemma 5.2, the lemma below gives a bound that depends on \(\gamma(\operatorname{Var}_{T}(\mathcal{I}))\) (rather than the square root), and avoids the extra \(\log|\mathcal{G}|\cdot\log T\) term. While the leading factor (\(\approx\log|\mathcal{G}|\)) is larger than the one in Lemma 5.2 (\(\approx\sqrt{\log|\mathcal{G}|}\)), we will only apply the bound to the case that \(|\mathcal{G}|=O(1)\), where the difference between the two is only a constant factor.

**Lemma C.9**.: _Given a function \(f:[0,1]\to[-1,1]\), \(y\in\{0,1\}^{T}\), and set \(\mathcal{I}\subseteq[0,1]\), consider the martingale \(M_{t}(f,y,\mathcal{I})\coloneqq\sum_{s=1}^{t}y_{t}\cdot f(p_{s}^{\star})\cdot( x_{s}-p_{s}^{\star})\cdot\mathbbm{1}\left[p_{s}^{\star}\in\mathcal{I}\right]\), where \(x\sim\mathcal{D}\), and \(p_{t}^{\star}=\Pr_{x^{\prime}\sim\mathcal{D}}\left[x_{t}^{\prime}=1|x_{1:(t-1) }^{\prime}=x_{1:(t-1)}\right]\). Then, for any finite family \(\mathcal{G}\) of functions from \([0,1]\) to \([-1,1]\), any \(y\in\{0,1\}^{T}\), and any \(\mathcal{I}\subseteq[0,1]\), we have_

\[\operatorname*{\mathbb{E}}_{x\sim\mathcal{D}}\left[\max_{f\in\mathcal{G}}M_{T }(f,y,\mathcal{I})\right]\leq 8\big{(}6+\log(|\mathcal{G}|)\big{)} \operatorname*{\mathbb{E}}_{x\sim\mathcal{D}}\left[\gamma(\operatorname*{ \mathrm{Var}}_{T}(\mathcal{I}))\right].\]

_where \(\operatorname*{\mathrm{Var}}_{t}(\mathcal{I})\coloneqq\sum_{s=1}^{t}p_{s}^{ \star}(1-p_{s}^{\star})\cdot\mathbbm{1}\left[p_{s}^{\star}\in\mathcal{I}\right]\) is the realized variance restricted to subset \(\mathcal{I}\), and \(\gamma(x)\coloneqq\begin{cases}x,&x<1,\\ \sqrt{x},&x\geq 1.\end{cases}\)_

Proof.: Let us decompose the horizon into epochs of doubling realized variance with respect to the subset \(\mathcal{I}\) as per Definition C.4. Using \(\tau\) as defined in (5), we will write \(I_{k}\coloneqq[\tau_{k-1}+1:\min\left\{T,\tau_{k}\right\}]\) to denote the time steps composing epoch \(k\) and write \(K\coloneqq\max\left\{k\mid\tau_{k}<\infty\right\}\) to denote the number of completed epochs.

We will separately handle the contributions of epoch 1 and those of later epochs.

First epoch.Since \(y_{t}\in\{0,1\}\) and \(\|f\|_{\infty}\leq 1\) holds for every \(f\in\mathcal{G}\), we can bound the expected contribution from the first epoch as follows:

\[\operatorname*{\mathbb{E}}_{x\sim\mathcal{D}}\left[\max_{f\in\mathcal{G}} \sum_{t=1}^{\tau_{1}}y_{t}\cdot f(p_{t}^{\star})\cdot(x_{t}-p_{t}^{\star}) \cdot\mathbbm{1}\left[p_{t}^{\star}\in\mathcal{I}\right]\right]\leq \operatorname*{\mathbb{E}}_{x\sim\mathcal{D}}\left[\sum_{t=1}^{\tau_{1}}|x_{t} -p_{t}^{\star}|\cdot\mathbbm{1}\left[p_{t}^{\star}\in\mathcal{I}\right] \right].\] (6)

Note that for any \(p\in[0,1]\) and Bernoulli random variable \(x\sim\mathsf{Bernoulli}(p)\),

\[\operatorname*{\mathbb{E}}\left[|x-p|\right]=\Pr\left[x=0\right]\cdot|0-p|+ \Pr\left[x=1\right]\cdot|1-p|=2p(1-p).\]

It thus follows that the process \((X_{t})_{0\leq t\leq T}\) where

\[X_{t}\coloneqq\sum_{s=1}^{t}\left[|x_{s}-p_{s}^{\star}|-2p_{s}^{\star}(1-p_{s} ^{\star})\right]\cdot\mathbbm{1}\left[p_{s}^{\star}\in\mathcal{I}\right]\]

is a martingale, as conditioning on any realization of \(x_{1:(t-1)}\), we have

\[\operatorname*{\mathbb{E}}_{x\sim\mathcal{D}}\left[|x_{t}-p_{t}^{\star}|-2p_{ t}^{\star}(1-p_{t}^{\star})\mid x_{1:t-1}\right]=\operatorname*{\mathbb{E}}_{x \sim\mathsf{Bernoulli}(p_{t}^{\star})}\left[|x-p_{t}^{\star}|\right]-2p_{t}^{ \star}(1-p_{t}^{\star})=0.\]

By the optional stopping theorem, we have

\[\operatorname*{\mathbb{E}}_{x\sim\mathcal{D}}\left[\sum_{t=1}^{\tau_{1}}\left[ |x_{t}-p_{t}^{\star}|-2p_{t}^{\star}(1-p_{t}^{\star})\right]\cdot\mathbbm{1} \left[p_{t}^{\star}\in\mathcal{I}\right]\right]=\operatorname*{\mathbb{E}} \left[X_{\tau_{1}}\right]=0.\]

Plugging this identity into (6) gives

\[\operatorname*{\mathbb{E}}_{x\sim\mathcal{D}}\left[\max_{f\in \mathcal{G}}\sum_{t=1}^{\tau_{1}}y_{t}\cdot f(p_{t}^{\star})\cdot(x_{t}-p_{t}^{ \star})\cdot\mathbbm{1}\left[p_{t}^{\star}\in\mathcal{I}\right]\right] \leq\operatorname*{\mathbb{E}}_{x\sim\mathcal{D}}\left[\sum_{t=1} ^{\tau_{1}}2p_{t}^{\star}(1-p_{t}^{\star})\cdot\mathbbm{1}\left[p_{t}^{\star} \in\mathcal{I}\right]\right]\] (7) \[=2\operatorname*{\mathbb{E}}_{x\sim\mathcal{D}}\left[\max_{\tau_{1 }}(\mathcal{I})\right]\] \[\leq 2\operatorname*{\mathbb{E}}_{x\sim\mathcal{D}}\left[\min\left\{ 2,\operatorname*{\mathrm{Var}}_{T}(\mathcal{I})\right\}\right]\] \[\leq 4\operatorname*{\mathbb{E}}_{x\sim\mathcal{D}}\left[\min\left\{ 1,\operatorname*{\mathrm{Var}}_{T}(\mathcal{I})\right\}\right],\]

where the third step applies Fact C.6 with \(k=1\).

Later epochs.Applying a triangle inequality and the law of total expectation gives

\[\mathop{\mathbb{E}}_{x\sim\mathcal{D}}\left[\max_{f\in\mathcal{G}} \sum_{t=\tau_{1}+1}^{T}y_{t}\cdot f(p_{t}^{\star})\cdot(x_{t}-p_{t}^{\star}) \cdot 1\left[p_{t}^{\star}\in\mathcal{I}\right]\right]\] \[= \mathop{\mathbb{E}}_{x\sim\mathcal{D}}\left[\max_{f\in\mathcal{G} }\sum_{k=2}^{K+1}\sum_{t\in I_{k}}y_{t}\cdot f(p_{t}^{\star})\cdot(x_{t}-p_{t}^ {\star})\cdot 1\left[p_{t}^{\star}\in\mathcal{I}\right]\right]\] \[\leq \mathop{\mathbb{E}}_{x\sim\mathcal{D}}\left[\sum_{k=2}^{K+1}\max_ {f\in\mathcal{G}}\sum_{t\in I_{k}}y_{t}\cdot f(p_{t}^{\star})\cdot(x_{t}-p_{t}^ {\star})\cdot 1\left[p_{t}^{\star}\in\mathcal{I}\right]\right]\] \[= \sum_{k=2}^{\lceil\log_{2}(T)\rceil+2}\mathop{\mathbb{E}}_{x \sim\mathcal{D}}\left[\max_{f\in\mathcal{G}}\sum_{t=1}^{T}y_{t}\cdot f(p_{t}^ {\star})\cdot(x_{t}-p_{t}^{\star})\cdot 1\left[p_{t}^{\star}\in\mathcal{I} \wedge t\in I_{k}\right]\right]\] \[= \sum_{k=2}^{\lceil\log_{2}(T)\rceil+2}\Pr\left[\tau_{k-1}<\infty \right]\cdot\mathop{\mathbb{E}}_{x\sim\mathcal{D}}\left[\max_{f\in\mathcal{G}} M_{T}^{k,f}\mid\tau_{k-1}<\infty\right],\]

where we define the process

\[M_{T}^{k,f}\coloneqq\sum_{t=1}^{T}y_{t}\cdot f(p_{t}^{\star})\cdot(x_{t}-p_{t}^ {\star})\cdot 1\left[p_{t}^{\star}\in\mathcal{I}\wedge t\in I_{k}\right].\] (9)

In the above, the third step uses Fact C.5, namely that \(\tau_{\lceil\log_{2}(T)\rceil+2}=\infty\). We can use Freedman's inequality to obtain a maximal inequality for each of these \(M_{T}^{k,f}\) processes.

**Fact C.10**.: _For every \(y\in\left\{0,1\right\}^{T}\) and \(k\geq 2\), we can uniformly bound the process \(M_{T}^{k,f}\) defined in (9) over a finite class \(\mathcal{G}\) of functions from \([0,1]\) to \([-1,1]\) by_

\[\mathop{\mathbb{E}}_{x\sim\mathcal{D}}\left[\max_{f\in\mathcal{G}}M_{T}^{k,f} \mid\tau_{k-1}<\infty\right]\leq\sqrt{2^{k-1}}(2+2\sqrt{\log|\mathcal{G}|})+2 +2\log|\mathcal{G}|\,.\]

Applying Fact C.10 to each of the martingales \(M_{T}^{k,f}\) in (8) gives us

\[\mathop{\mathbb{E}}_{x\sim\mathcal{D}}\left[\max_{f\in\mathcal{G} }\sum_{t=\tau_{1}+1}^{T}y_{t}\cdot f(p_{t}^{\star})\cdot(x_{t}-p_{t}^{\star}) \cdot 1\left[p_{t}^{\star}\in\mathcal{I}\right]\right]\] \[\leq \sum_{k=2}^{\lceil\log_{2}(T)\rceil+2}\Pr\left[\tau_{k-1}<\infty \right](\sqrt{2^{k-1}}(2+2\sqrt{\log|\mathcal{G}|})+2+2\log|\mathcal{G}|).\] (10)

To upper bound the right-hand side above, we use Fact C.8 to bound

\[\sum_{k=2}^{\lceil\log_{2}(T)\rceil+2}\Pr\left[\tau_{k-1}<\infty\right]\sqrt{ 2^{k-1}}\leq\mathop{\mathbb{E}}\left[1\left[\mathrm{Var}_{T}(\mathcal{I}) \geq 1\right]\cdot\sqrt{\mathrm{Var}_{T}(\mathcal{I})}\right](2+2\sqrt{2}),\]

and use Fact C.7 to bound

\[\sum_{k=2}^{\lceil\log_{2}(T)\rceil+2}\Pr\left[\tau_{k-1}<\infty\right] \leq\sum_{k=2}^{\lceil\log_{2}(T)\rceil+2}\min\left\{1,\frac{ \mathop{\mathbb{E}}\left[1\left[\mathrm{Var}_{T}(\mathcal{I})\geq 1\right]\cdot \sqrt{\mathrm{Var}_{T}(\mathcal{I})}\right]}{2^{(k-2)/2}}\right\}\] \[\leq\mathop{\mathbb{E}}\left[1\left[\mathrm{Var}_{T}(\mathcal{I })\geq 1\right]\cdot\sqrt{\mathrm{Var}_{T}(\mathcal{I})}\right](2+\sqrt{2}).\]

Plugging these into (10) gives

\[\mathop{\mathbb{E}}\left[\max_{f\in\mathcal{G}}\left[M_{T}(f,y, \mathcal{I})-M_{\tau_{1}}(f,y,\mathcal{I})\right]\right]\] \[\leq \mathop{\mathbb{E}}\left[1\left[\mathrm{Var}_{T}(\mathcal{I}) \geq 1\right]\cdot\sqrt{\mathrm{Var}_{T}(\mathcal{I})}\right](2+2\sqrt{2})(2+2 \sqrt{\log|\mathcal{G}|}+\sqrt{2}+\sqrt{2}\mathrm{log}\left|\mathcal{G}\right|)\] \[\leq \mathop{\mathbb{E}}\left[1\left[\mathrm{Var}_{T}(\mathcal{I}) \geq 1\right]\cdot\sqrt{\mathrm{Var}_{T}(\mathcal{I})}\right]8\big{(}5+ \log|\mathcal{G}|\,\big{)}.\] (11)

[MISSING_PAGE_FAIL:35]

where the first equality uses the definition of a Bernoulli's variance; the second equality uses that, conditioned on \(\mathbb{F}_{t-1}\), \(x_{t}\sim\text{Bernoulli}(p_{t}^{*})\); and the second inequality uses that \(y_{t}^{2}\leq 1\) and \(|f(x)|\leq 1\) for all \(x\in[0,1]\).

We can thus use Freedman's inequality to bound the deviation of each martingale \(M_{T}^{k,f}\). First, observe that the quadratic formula gives the inequality \(\exp\left(-\frac{x^{2}}{2(x+y)}\right)\leq p\) if \(x\geq\log(1/p)+\sqrt{\log^{2}(p)+2y\log(1/p)}\). We can therefore invoke Lemma C.11 with \(y=2^{k-1}+1\) and

\[x=2\log(1/p)+\sqrt{2y\log(1/p)}\geq\log(1/p)+\sqrt{\log^{2}(p)+2y\log(1/p)}\]

to show that

\[p\geq\Pr\left[M_{T}^{k,f}\geq x\;\wedge\;\sum_{t=1}^{T}\underset{x_{t}^{\prime }\sim\mathcal{D}_{t}}{\mathbb{E}}\left[(M_{t}^{k,f}-M_{t-1}^{k,f})^{2}\mid x_{ 1:t-1}^{\prime}=x_{1:t-1}\right]\leq 2^{k-1}+1\mid\tau_{k-1}<\infty\right].\]

Applying (12), we can simplify this to

\[p \geq\Pr\left[M_{T}^{k,f}\geq\sqrt{2(2^{k-1}+1)\log(1/p)}+2\log(1/p )\mid\tau_{k-1}<\infty\right]\] \[\geq\Pr\left[M_{T}^{k,f}\geq\sqrt{2^{k+1}\log(1/p)}+2\log(1/p) \mid\tau_{k-1}<\infty\right].\]

We can then take a union bound over \(\mathcal{G}\) for

\[p\geq\Pr\left[\max_{f\in\mathcal{G}}M_{T}^{k,f}\geq\sqrt{2^{k+1}\log(\left| \mathcal{G}\right|/p)}+2\log(\left|\mathcal{G}\right|/p)\mid\tau_{k-1}<\infty \right].\]

Using the layer cake representation of expectation, we can convert this high-probability bound into the expectation bound through a change of variables

\[\mathbb{E}\left[\max_{f\in\mathcal{G}}M_{T}^{k,f}\mid\tau_{k-1}< \infty\right] =\int_{0}^{\infty}\Pr\left[\max_{f\in\mathcal{G}}M_{T}^{k,f}\geq t \mid\tau_{k-1}<\infty\right]\;\mathrm{d}t\] \[=\int_{0}^{1}\sqrt{2^{k+1}\log(\left|\mathcal{G}\right|/p)}+2\log (\left|\mathcal{G}\right|/p)\;\mathrm{d}p\] \[=\sqrt{2^{k+1}}(\tfrac{\left|\mathcal{G}\right|}{2}\sqrt{\pi} \cdot\operatorname{erfc}(\sqrt{\log\left|\mathcal{G}\right|})+\sqrt{\log \left|\mathcal{G}\right|})+2+2\log\left|\mathcal{G}\right|,\]

where the last equality follows by Fact C.12. When \(\left|\mathcal{G}\right|>1\), we can compute the integral to be

\[\mathbb{E}\left[\max_{f\in\mathcal{G}}M_{T}^{k,f}\mid\tau_{k-1}< \infty\right] \leq\sqrt{2^{k+1}}(\tfrac{\left|\mathcal{G}\right|}{2\sqrt{\log \left|\mathcal{G}\right|}}\exp(-\log\left|\mathcal{G}\right|)+\sqrt{\log \left|\mathcal{G}\right|})+2+2\log\left|\mathcal{G}\right|\] \[\leq\sqrt{2^{k-1}}(2+2\sqrt{\log\left|\mathcal{G}\right|})+2+2 \log\left|\mathcal{G}\right|,\]

where the first inequality uses that \(\operatorname{erfc}(z)<\frac{\exp(-z^{2})}{z\sqrt{\pi}}\). When \(\left|\mathcal{G}\right|=1\), we again have

\[\mathbb{E}\left[\max_{f\in\mathcal{G}}M_{T}^{k,f}\mid\tau_{k-1}< \infty\right] \leq\sqrt{\pi}\sqrt{2^{k-1}}+2\] \[\leq\sqrt{2^{k-1}}(2+2\sqrt{\log\left|\mathcal{G}\right|})+2+2 \log\left|\mathcal{G}\right|.\]

**Fact C.12**.: _For \(k,n\in\mathbb{Z}_{+}\), the following integral equality holds_

\[\int_{0}^{1}\sqrt{2^{k+1}\log(n/p)}+2\log(n/p)\;\mathrm{d}p=\sqrt{2^{k+1}}( \tfrac{n}{2}\sqrt{\pi}\cdot\operatorname{erfc}(\sqrt{\log n})+\sqrt{\log n})+ 2+2\log n\]

where \(\operatorname{erfc}\) denotes the complementary error function.

Proof.: Let us first separate the integral into two parts:

\[\int_{0}^{1}\sqrt{2^{k+1}\log(n/p)}+2\log(n/p)\ \mathrm{d}p=\int_{0}^{1}\sqrt{2^{k+1} \log(n/p)}\ \mathrm{d}p+\int_{0}^{1}2\log(n/p)\ \mathrm{d}p.\]

We can bound the second integral easily. Since \(\log(n/p)=\log n-\log p\),

\[\int_{0}^{1}2\log(n/p)\ \mathrm{d}p =\int_{0}^{1}2(\log n-\log p)\ \mathrm{d}p\] \[=2\log n\int_{0}^{1}\mathrm{d}p-2\int_{0}^{1}\log p\ \mathrm{d}p\] \[=2\log n+2\] (13)

Now we consider the first integral. Let \(u=\log(n/p)\). Then \(p=ne^{-u}\) and \(\mathrm{d}p=-ne^{-u}\ \mathrm{d}u\). When \(p=1\), \(u=\log n\). When \(p=0\), \(u\) goes to \(\infty\). Thus, the integral becomes:

\[\int_{0}^{1}\sqrt{2^{k+1}\log(n/p)}\ \mathrm{d}p =\int_{\infty}^{\log n}\sqrt{2^{k+1}u}\cdot(-ne^{-u})\ \mathrm{d}u\] \[=n\sqrt{2^{k+1}}\int_{\log n}^{\infty}\sqrt{u}\,e^{-u}\ \mathrm{d}u.\]

The integral involving the error function \(\mathrm{erfc}(x)\) can be recognized:

\[\int_{\log n}^{\infty}\sqrt{u}\,e^{-u}\ \mathrm{d}u =-\sqrt{u}\,e^{-u}\big{|}_{\log n}^{\infty}+\int_{\log n}^{ \infty}\frac{1}{2\sqrt{u}}\,e^{-u}\ \mathrm{d}u\] \[=\lim_{u\to\infty}\left(-\sqrt{u}\,e^{-u}\right)-\left(-\sqrt{ \log n}\,e^{-\log n}\right)+\int_{\log n}^{\infty}\frac{1}{2\sqrt{u}}\,e^{-u} \ \mathrm{d}u\] \[=\sqrt{\log n}\,e^{-\log n}+\int_{\log n}^{\infty}\frac{1}{2 \sqrt{u}}\,e^{-u}\ \mathrm{d}u\] \[=\sqrt{\log n}\,e^{-\log n}+\int_{\sqrt{\log n}}^{\infty}e^{-t^{ 2}}\ \mathrm{d}t\] \[=\frac{\sqrt{\log n}}{n}+\frac{\sqrt{\pi}}{2}\mathrm{erfc}(\sqrt {\log n}).\]

Thus, the integral \(\int_{0}^{1}\sqrt{2^{k+1}\log(n/p)}\ \mathrm{d}p\) is given by

\[n\sqrt{2^{k+1}}\left(\frac{\sqrt{\pi}}{2}\mathrm{erfc}(\sqrt{\log n})+\frac{ \sqrt{\log n}}{n}\right)=\sqrt{2^{k+1}}\left(\frac{n\sqrt{\pi}}{2}\mathrm{ erfc}(\sqrt{\log n})+\sqrt{\log n}\right).\] (14)

Summing (13) and (14) gives the claim. 

### Proof of Lemma 5.2

**Lemma 5.2**.: _Given a function \(f:[0,1]\to[-1,1]\) and \(y\in\{0,1\}^{T}\), consider the martingale \(M_{t}(f,y):=\sum_{s=1}^{t}y_{s}\cdot f(p_{s}^{*})\cdot(x_{s}-p_{s}^{*})\) where \(x\sim\mathcal{D}\). Then, for any finite family \(\mathcal{G}\) of functions from \([0,1]\) to \([-1,1]\) and any \(y\in\{0,1\}^{T}\), we have_

\[\operatorname*{\mathbb{E}}_{x\sim\mathcal{D}}\left[\max_{f\in\mathcal{G}}M_{T} (f,y)\right]\leq O\left(\log|\mathcal{G}|\cdot\log T+\sqrt{\log|\mathcal{G}|} \cdot\operatorname*{\mathbb{E}}_{x\sim\mathcal{D}}\left[\sqrt{\mathrm{Var}_{T }}\right]\right).\]

Proof.: Let us decompose the martingale \(M_{T}(f,y)\) into epochs of doubling realized variance with respect to \(\mathcal{I}=[0,1]\) as per Definition C.4. Using \(\tau\) as defined in (5), we will write \(I_{k}\coloneqq[\tau_{k-1}+1,\min\left\{T,\tau_{k}\right\}]\) to denote the time steps composing epoch \(k\) and write \(K\coloneqq\max\left\{k\mid\tau_{k}<\infty\right\}\) to denote the number of completed epochs.

Applying a triangle inequality and the law of total expectation gives

\[\mathop{\mathbb{E}}_{x\sim\mathcal{D}}\left[\max_{f\in\mathcal{G}} \sum_{t=1}^{T}y_{t}\cdot f(p_{t}^{\star})\cdot(x_{t}-p_{t}^{\star})\right]\] \[= \mathop{\mathbb{E}}_{x\sim\mathcal{D}}\left[\max_{f\in\mathcal{G} }\sum_{k=1}^{K+1}\sum_{t\in I_{k}}y_{t}\cdot f(p_{t}^{\star})\cdot(x_{t}-p_{t}^ {\star})\right]\] \[\leq \mathop{\mathbb{E}}_{x\sim\mathcal{D}}\left[\sum_{k=1}^{K+1}\max_ {f\in\mathcal{G}}\sum_{t\in I_{k}}y_{t}\cdot f(p_{t}^{\star})\cdot(x_{t}-p_{t}^ {\star})\right]\] \[= \sum_{k=1}^{\lceil\log_{2}(T)\rceil+2}\mathop{\mathbb{E}}_{x \sim\mathcal{D}}\left[\max_{f\in\mathcal{G}}\sum_{t\in I_{k}}y_{t}\cdot f(p_{ t}^{\star})\cdot(x_{t}-p_{t}^{\star})\cdot\mathds{1}\left[t\in I_{k}\right]\right]\] \[= \sum_{k=1}^{\lceil\log_{2}(T)\rceil+2}\Pr\left[\tau_{k-1}<\infty \right]\cdot\mathop{\mathbb{E}}_{x\sim\mathcal{D}}\left[\max_{f\in\mathcal{G} }M_{T}^{k,f}\mid\tau_{k-1}<\infty\right].\] (15)

where we define the process \(M_{T}^{k,f}\coloneqq\sum_{t=1}^{T}y_{t}\cdot f(p_{t}^{\star})\cdot(x_{t}-p_{t} ^{\star})\cdot\mathds{1}\left[t\in I_{k}\right]\). In the above, the second equality uses Fact C.5, namely that \(\tau_{\lceil\log_{2}(T)\rceil+2}=\infty\). Applying Fact C.10 to each of the martingales \(M_{T}^{k,f}\) in (15) gives us

\[\mathop{\mathbb{E}}_{x\sim\mathcal{D}}\left[\max_{f\in\mathcal{G} }\sum_{t=1}^{T}y_{t}\cdot f(p_{t}^{\star})\cdot(x_{t}-p_{t}^{\star})\right]\] \[\leq \sum_{k=1}^{\lceil\log_{2}(T)\rceil+2}\Pr\left[\tau_{k-1}<\infty \right]\cdot\left[\sqrt{2^{k-1}}(2+2\sqrt{\log|\mathcal{G}|})+2+2\log| \mathcal{G}|\right].\]

We can upper bound some of the summands in the right-hand side by using Fact C.8 to bound

\[\sum_{k=2}^{\lceil\log_{2}(T)\rceil+2}\Pr\left[\tau_{k-1}<\infty\right]\sqrt{ 2^{k-1}}\leq\mathop{\mathbb{E}}\left[\sqrt{\mathrm{Var}}_{T}\right](2+2\sqrt {2}).\]

This gives that

\[\mathop{\mathbb{E}}_{x\sim\mathcal{D}}\left[\max_{f\in\mathcal{G} }\sum_{t=1}^{T}y_{t}\cdot f(p_{t}^{\star})\cdot(x_{t}-p_{t}^{\star})\right]\] \[\leq (2+2\log|\mathcal{G}|)(\lceil\log_{2}(T)\rceil+2)+\mathop{ \mathbb{E}}\left[\sqrt{\mathrm{Var}}_{T}\right](2+2\sqrt{2})(2+2\sqrt{\log| \mathcal{G}|}).\]

## Appendix D Supplemental Materials for Section 6

Notation.For all stochastic processes \((X_{t})\), we use \(X_{t_{1}:t_{2}}=X_{\min\{t_{2},T\}}-X_{t_{1}}\) to denote the increment within the time interval \((t_{1},t_{2}]\) (with \(X_{0}=0\) by default).

### Proof of the Weaker Lower Bound

We restate and prove Lemmas 6.2 and 6.3.

**Lemma 6.2**.: _For any \(x\in\{0,1\}^{T}\) and \(p\in[0,1]^{T}\), we have \(\mathsf{SSCE}(x,p)\geq\Omega\left(\sqrt{N_{T}}\right)\)._

Proof.: Recall that \(\mathsf{SSCE}\) is defined using \(\mathsf{smCE}\), which is in turn a supremum over the family \(\mathcal{F}\) of Lipschitz functions. Since both \(f\equiv 1\) and \(f\equiv-1\) are included in \(\mathcal{F}\), for any realized sequences \(x\) and \(p\), we can lower bound \(\mathsf{SSCE}(x,p)\) as follows:

\[\mathsf{SSCE}(x,p)\geq\mathop{\mathbb{E}}_{y\sim\mathsf{Unif}(\{0,1\}^{T})} \left[\left|\sum_{t=1}^{T}y_{t}\cdot(x_{t}-p_{t})\right|\right]=\mathop{ \mathbb{E}}_{y}\left[\left|\sum_{t=1}^{T}z_{t}+\mu\right|\right],\]where we have defined \(z_{t}\coloneqq(y_{t}-0.5)(x_{t}-p_{t})\) to be zero-mean independent random variables, and \(\mu\coloneqq\sum_{t=1}^{T}0.5(x_{t}-p_{t})\). Now we partition \([T]\) into \(T_{1}\) and \(T_{2}\), where \(T_{1}\) includes the all time steps such that \(|x_{t}-p_{t}|\geq\frac{1}{2}\), and \(T_{2}=T\setminus T_{1}\) contains the remaining time steps. From the definition of \(N_{T}\), it immediately follows that \(N_{T}=|T_{1}|\). Letting \(Z_{1}\coloneqq\sum_{t\in T_{1}}z_{t}\) and \(Z_{2}\coloneqq\sum_{t\in T_{2}}z_{t}\), it remains to lower bound \(\mathbb{E}\left[|Z_{1}+Z_{2}+\mu|\right]\) by \(\Omega(\sqrt{N_{T}})\).

We will first prove that \(\mathbb{E}\left[|Z_{1}|\right]\geq C\sqrt{N_{T}}\) for a universal constant \(C>0\). From the Berry-Esseen theorem (e.g. from [21]), the CDF of \(Z_{1}\) can be approximated by the CDF of the standard normal distribution as follows:

\[\forall x\in\mathbb{R},\ \left|\Pr\left[Z_{1}\leq x\cdot\sigma_{0}\right]- \Phi(x)\right|\leq C_{0}\cdot\sigma_{0}^{-1}\cdot\rho_{0},\]

where \(\Phi(x)\) is the standard Gaussian CDF, \(C_{0}\) is a universal constant no larger than \(0.56\), and

\[\sigma_{0} =\sqrt{\sum_{t\in T_{1}}\mathbb{E}\left[z_{t}^{2}\right]}=\sqrt {\frac{1}{4}\sum_{t\in T_{1}}(x_{t}-p_{t})^{2}}\geq\frac{1}{4}\sqrt{N_{T}};\] \[\rho_{0} =\max_{t\in T_{1}}\frac{\mathbb{E}\left[|z_{t}|^{3}\right]}{ \mathbb{E}\left[|z_{t}|^{2}\right]}=\max_{t\in T_{1}}\frac{|x_{t}-p_{t}|^{3}/8 }{|x_{t}-p_{t}|^{2}/4}\leq\frac{1}{2}.\]

As a result, we can lower bound the probability of \(|Z_{1}|\geq 0.05\sqrt{N_{T}}\) as follows:

\[\Pr\left[|Z_{1}|\geq 0.05\sqrt{N_{T}}\right] \geq\Pr\left[|Z_{1}|>0.2\cdot\sigma_{0}\right]\] ( \[\rho_{0} \geq\frac{1}{4}\sqrt{N_{T}}\] ) \[=2\left(1-\Pr\left[Z_{1}\leq 0.2\cdot\sigma_{0}\right]\right)\] ( \[Z_{1}\] is symmetric) \[\geq 2\left(1-\Phi(0.2)-2C_{0}/\sqrt{N_{T}}\right).\] (Berry-Esseen theorem)

Since \(C_{0}\leq 0.56\) and \(\Phi(0.2)\leq 0.58\), we can guarantee \(\Pr\left[|Z_{1}|\geq 0.05\sqrt{N_{T}}\right]\geq\Omega(1)\) for all \(N_{T}\geq 8\). When \(N_{T}\leq 7\), we have \(|Z_{1}|=N_{T}/2\geq 0.05\sqrt{N_{T}}\) when all \(\{z_{t}\mid t\in T_{1}\}\) are positive, which happens with probability \(2^{-N_{T}}\geq 2^{-7}=\Omega(1)\). Therefore, we can always conclude that

\[\mathbb{E}\left[|Z_{1}|\right]\geq 0.05\sqrt{N_{T}}\cdot\Pr\left[|Z_{1}|\geq 0. 05\sqrt{N_{T}}\right]\geq C\sqrt{N_{T}}\]

for some universal constant \(C>0\).

Finally, we consider the randomness of \(Z_{2}\) and show that \(\mathbb{E}\left[|Z_{1}+Z_{2}+\mu|\right]\geq\frac{C}{2}\sqrt{N_{T}}\). Applying the tower property of expectations, we have

\[\mathbb{E}\left[|Z_{1}+Z_{2}+\mu|\right]=\mathbb{E}\left[\mathbb{E}\left[|Z_ {1}+Z_{2}+\mu|\ \big{|}\ Z_{2}\right]\right].\]

Consider the following two cases for the conditional expectation inside:

* When \(|Z_{2}+\mu|\geq\frac{C}{2}\sqrt{N_{T}}\), we use Jensen's inequality and \(\mathbb{E}\left[Z_{1}\right]=0\) to obtain \(\mathbb{E}\left[|Z_{1}+Z_{2}+\mu|\mid Z_{2}\right]\geq|\mathbb{E}\left[Z_{1}+ Z_{2}+\mu\mid Z_{2}\right]|=|Z_{2}+\mu|\geq\frac{C}{2}\sqrt{N_{T}}\).
* When \(|Z_{2}+\mu|<\frac{C}{2}\sqrt{N_{T}}\), we apply the triangle inequality and have \[\mathbb{E}\left[|Z_{1}+Z_{2}+\mu|\mid Z_{2}\right]\geq\mathbb{E}\left[|Z_{1}| \right]-|Z_{2}+\mu|>C\sqrt{N_{T}}-\frac{C}{2}\sqrt{N_{T}}=\frac{C}{2}\sqrt{N_ {T}}.\]

Therefore, regardless of the realization of \(Z_{2}\), we always have \(\mathbb{E}\left[|Z_{1}+Z_{2}+\mu_{0}|\mid Z_{2}\right]\geq\frac{C}{2}\sqrt{N_{ T}}\). Taking an expectation over the randomness of \(Z_{2}\) gives the desired bound \(\mathsf{SSCE}(x,p)\geq\frac{C}{2}\sqrt{N_{T}}\). 

**Lemma 6.3**.: _The stochastic process \((N_{t})_{t\in[T]}\) satisfies \(\mathbb{E}\left[\sqrt{N_{T}}\right]\geq\Omega(\mathbb{E}\left[\sqrt{\mathrm{ Var}_{T}}\right])-O(1)\)._

Proof.: Since \(N_{T}\geq\mathrm{Var}_{T}/16\) implies \(\sqrt{N_{T}}\geq\sqrt{\mathrm{Var}_{T}}/4\), we have

\[\sqrt{N_{T}}\geq\frac{\sqrt{\mathrm{Var}_{T}}}{4}\cdot\mathbb{1}\left[N_{T} \geq\frac{\mathrm{Var}_{T}}{16}\right]=\frac{\sqrt{\mathrm{Var}_{T}}}{4}-\frac {\sqrt{\mathrm{Var}_{T}}}{4}\cdot\mathbb{1}\left[N_{T}<\frac{\mathrm{Var}_{T}}{1 6}\right].\]Therefore, to establish the inequality \(\mathbb{E}\left[\sqrt{N_{T}}\right]\geq\Omega(\mathbb{E}\left[\sqrt{\mathrm{Var}_{T }}\right])-O(1)\), it suffices to prove that the expectation of the second term--which we denote with \(M\)--is upper bounded by \(O(1)\), i.e.,

\[M\coloneqq\mathbb{E}\left[\sqrt{\mathrm{Var}_{T}}\cdot\mathds{1}\left[N_{T}< \mathrm{Var}_{T}/16\right]\right]\leq O(1).\] (16)

We proceed by partitioning the range of \(\mathrm{Var}_{T}\) into subintervals of geometrically increasing length and enumerating all possibilities for which subinterval \(\mathrm{Var}_{T}\) falls into. If \(\mathrm{Var}_{T}\leq 1\), its contribution to \(M\) is clearly \(O(1)\). Otherwise, we must have \(\mathrm{Var}_{T}\in[2^{l},2^{l+1})\) for some \(l\in\mathbb{N}\), which implies that \(N_{T}<\mathrm{Var}_{T}/16<2^{l-3}\). Therefore, we bound \(M\) by taking a union bound over all such \(l\)'s:

\[M \leq O(1)+\sum_{l\in\mathbb{N}}\mathbb{E}\left[\sqrt{\mathrm{Var} _{T}}\cdot\mathds{1}\left[N_{T}<2^{l-3}\;\wedge\;\mathrm{Var}_{T}\in[2^{l},2^ {l+1})\right]\right]\] \[\leq O(1)+\sum_{l\in\mathbb{N}}\sqrt{2^{l+1}}\cdot\Pr\left[N_{T}< 2^{l-3}\;\wedge\;\mathrm{Var}_{T}\geq 2^{l}\right].\] (17)

Now we bound \(\Pr\left[N_{T}<k/8\;\wedge\;\mathrm{Var}_{T}\geq k\right]\) for any fixed value of \(k\) (that plays the role of \(2^{l}\)) by constructing a sub-martingale. We start by partitioning the time horizon \([T]\) into blocks based on the realized variance \(\mathrm{Var}_{t}\), such that each block \(B_{j}\coloneqq(b_{j-1},\;b_{j}]\) terminates upon the realized variance \(\mathrm{Var}_{B_{j}}\) first exceeds \(1\). Formally, using notation \(X_{t_{1}:t_{2}}\coloneqq X_{\min\{t_{2},T\}}-X_{t_{1}}\) to denote the increment of any process \((X_{t})\) in \((t_{1},t_{2}]\) (with \(X_{0}=0\) by default), the endpoints \(b_{j}\) are defined recursively as:

\[b_{0}\coloneqq 0,\;b_{j}\coloneqq\min\left\{\infty\right\}\cup\left\{t\in[b_{j-1}+ 1,T]\;|\;\mathrm{Var}_{b_{j-1}:t}\geq 1\right\},\;\forall j\geq 1.\]

We show in the following lemma that for each block \(B_{j}\), the expected increment \(N_{B_{j}}\) within \(B_{j}\) is lower bounded by a constant as long as \(B_{j}\) terminates before \(T\).

**Lemma D.1**.: _For the constant \(c=1-1/e\), \(\mathbb{E}\left[\mathds{1}\left[N_{B_{j}}\geq 1\right]-c\cdot\mathds{1} \left[b_{j}<\infty\right]\;\Big{|}\;\mathbb{F}_{b_{j-1}}\right]\geq 0\)._

We prove Lemma D.1 in Appendix D.2. This lemma justifies that if we define \(A_{j}\) as

\[A_{0}\coloneqq 0,\quad A_{j}-A_{j-1}\coloneqq\mathds{1}\left[N_{B_{j}}\geq 1 \right]-c\cdot\mathds{1}\left[b_{j}<\infty\right]\;(j\geq 1),\]

then \((A_{j})_{j\geq 0}\) forms a sub-martingale of bounded increment \(|A_{j}-A_{j-1}|\leq 1\), making it unlikely for any \(A_{j}\) to deviate significantly below \(0\). However, if \(N_{T}<k/8\) and \(\mathrm{Var}_{T}\geq k\), then \(A_{k/2}\) must witness a large deviation: on the one hand, block \(B_{k/2}\) should terminate properly because the variance in each block cannot exceed \(2\); on the other hand, \(N_{T}<k/8\) implies that at most \(k/8\) of these blocks can have a nonzero increment \(N_{B_{j}}\). As a result,

\[A_{k/2}=\sum\nolimits_{j=1}^{k}\mathds{1}\left[N_{B_{j}}\geq 1\right]-c\cdot \sum\nolimits_{j=1}^{k}\mathds{1}\left[b_{j}<\infty\right]\leq N_{T}-c\cdot(k /2)<-k/8.\]

By applying the Azuma-Hoeffding inequality for submartingales, we can quantitatively bound the probability of such a large deviation by

\[\Pr\left[N_{T}<k/8\;\wedge\;\mathrm{Var}_{T}\geq k\right]\leq\Pr\left[A_{k/2} \leq-k/8\right]\leq e^{-k/64}.\]

Finally, plugging the above bound back into equation (17) gives us

\[M\leq O(1)+\sum\nolimits_{l\in\mathbb{N}}\sqrt{2^{l+1}}\cdot e^{-2^{l-6}}\leq O (1).\]

We have thus established the inequality (16), which in turn proves the lemma. 

### Proof of Lemma d.1

Now we prove Lemma D.1, which we restate below.

**Lemma D.1**.: _For the constant \(c=1-1/e\), \(\mathbb{E}\left[\mathds{1}\left[N_{B_{j}}\geq 1\right]-c\cdot\mathds{1} \left[b_{j}<\infty\right]\;\Big{|}\;\mathbb{F}_{b_{j-1}}\right]\geq 0\)._

Proof.: We first show that for all \(t\in[T]\), we have \(\Pr\left[n_{t}=1\;|\;\mathbb{F}_{t-1}\right]\geq p_{t}^{*}(1-p_{t}^{*})\), where \(\mathbb{F}_{t-1}\) denotes the filtration generated by all the randomness up to time \(t-1\). Note that conditioning on \(\mathbb{F}_{t-1}\), \(x_{t}\) is distributed according to \(\mathsf{Bernoulli}(p_{t}^{*})\). If the forecaster chooses \(p_{t}\geq\frac{1}{2}\), the condition \(|x_{t}-p_{t}|\geq\frac{1}{2}\) holds when \(x_{t}=0\), which happens with probability \(1-p_{t}^{\star}\); otherwise it holds when \(x_{t}=1\), which happens with probability \(p_{t}^{\star}\). Therefore, regardless of the choice of \(p_{t}\), we have

\[\Pr\left[n_{t}=1\mid\mathbb{F}_{t-1}\right]=\Pr_{x_{t}\sim\mathsf{Bernoulli}(p_ {t}^{\star})}\left[|x_{t}-p_{t}|\geq 1/2\right]\geq\min\{p_{t}^{\star},1-p_{t}^{ \star}\}\geq p_{t}^{\star}(1-p_{t}^{\star}).\]

This allows us to invoke Lemma D.5 with \(q_{t}\coloneqq n_{t}\), \(r_{t}\coloneqq p_{t}^{\star}(1-p_{t}^{\star})\), and \(\theta=1\), where we only consider the random process inside block \(B_{j}\). In this context, the stopping time \(\tau_{1}\) corresponds to the end of the block, i.e., \(b_{j}\). Therefore, by applying Lemma D.5 at time step \(b_{j-1}\), we obtain

\[A_{b_{j-1}}=\Pr\left[N_{B_{j}}\geq 1\;\middle|\;\mathbb{F}_{b_{j-1 }}\right]-\left(1-e^{-1}\right)\cdot\Pr\left[b_{j}<\infty\;\middle|\;\mathbb{F }_{b_{j-1}}\right]\geq 0\] \[\iff \;\mathbb{E}\left[1\left[N_{B_{j}}\geq 1\right]-c\cdot 1\left[b_{j}< \infty\right]\;\middle|\;\mathbb{F}_{b_{j-1}}\right]\geq 0,\;\;\text{where $c=1-\frac{1}{e}$}.\]

### A Stronger Lower Bound

In this section, we state and prove the stronger \(\mathsf{SSCE}\) lower bound for all forecasters.

**Theorem D.2**.: _For any \(\mathcal{D}\in\Delta(\{0,1\}^{T})\), \(\mathsf{OPT}_{\mathsf{SSCE}}(\mathcal{D})=\Omega(\mathbb{E}\left[\gamma( \mathrm{Var}_{T})\right])\), where the function \(\gamma\) is defined as \(\gamma(x)\coloneqq x\cdot 1\left[0\leq x<1\right]+\sqrt{x}\cdot 1\left[x\geq 1\right]\)._

Proof of Theorem D.2.: The theorem holds by combining Lemma 6.2, which lower bounds the \(\mathsf{SSCE}\) by \(\Omega(\sqrt{N_{T}})\), and the stronger lower bound on \(\mathbb{E}\left[\sqrt{N_{T}}\right]\) shown in Lemma D.3. 

**Lemma D.3**.: _There exists a universal constant \(C>0\) such that \(\mathbb{E}\left[\sqrt{N_{T}}\right]\geq C\cdot\mathbb{E}\left[\gamma(\mathrm{ Var}_{T})\right]\), where the function \(\gamma\) is defined as \(\gamma(x)\coloneqq x\cdot 1\left[0\leq x<1\right]+\sqrt{x}\cdot 1\left[x\geq 1\right]\)._

Proof of Lemma D.3.: The proof is also based on partitioning the time horizon into blocks \(B_{j}=(b_{j-1},b_{j}]\)--each with approximately unit variance--similar to the approach used in proving Lemma 6.3. However, this proof involves a more careful analysis of the growth of \(\sqrt{N_{t}}\) by further grouping blocks into "epochs" and giving special treatment to the first epoch, where the cumulative variance is very small.

Specifically, consider the blocks \(B_{j}=(b_{j-1},b_{j}]\) defined by

\[b_{0}\coloneqq 0,\;b_{j}\coloneqq\min\left\{\infty\right\}\cup\left\{t\in[b_{j-1}+ 1,T]\;\middle|\;\mathrm{Var}_{b_{j-1}:t}\geq 1\right\},\;\forall j\geq 1.\]

Recall that the increment of \(\mathrm{Var}_{t}\) satisfies \(\mathrm{Var}_{t}-\mathrm{Var}_{t-1}=p_{t}^{\star}(1-p_{t}^{\star})\leq 1/4\). Thus, every block \(j\) satisfies \(\mathrm{Var}_{B_{j}}=\mathrm{Var}_{b_{j}}-\mathrm{Var}_{b_{j-1}}=(\mathrm{Var}_ {b_{j}-1}-\mathrm{Var}_{b_{j-1}})+(\mathrm{Var}_{b_{j}}-\mathrm{Var}_{b_{j}-1}) \leq 1+1/4=5/4\). We further group blocks into epochs such that the \(k\)-th epoch \(\mathcal{T}_{k}\coloneqq(\tau_{k-1},\tau_{k}]\) contains \(\approx 2^{k}\) blocks:

\[\mathcal{T}_{0}\coloneqq B_{1},\quad\mathcal{T}_{k}\coloneqq\bigcup_{j\in(2^{ k-1},2^{k}]}B_{j},\;\forall k\geq 1\quad(\text{or equivalently, $\tau_{k}\coloneqq b_{2^{k}}$}).\]

In addition, we define \(\widetilde{N}_{t}\) as the sum of \(n_{s}\) capped by \(1\) in each block:

\[\widetilde{N}_{t}\coloneqq\sum_{j:b_{j}\leq t}\min\{N_{B_{j}},1\}=\sum_{j:b_{ j}\leq t}1\left[N_{B_{j}}\geq 1\right].\]

Clearly, for all the realized sequences we have \(N_{T}\geq\widetilde{N}_{T}\) and \(\widetilde{N}_{\tau_{k}}\leq 2^{k}\), where the latter is because each block contributes at most \(1\) to \(\widetilde{N}_{t}\). In the following, we will first analyze the growth of \(\sqrt{\widetilde{N}_{t}}\) in epochs \(k\geq 1\), then provide a different analysis for the zeroth epoch.

In each epoch \(\mathcal{T}_{k}\) with \(k\geq 1\).We start by establishing the following lemma, which extends the characterization of Lemma D.1 into epochs.

**Lemma D.4** (Lower bound on \(\widetilde{N}_{\mathcal{T}_{k}}\)).: _For any \(k\geq 1\), we have_

\[\mathbb{E}\left[\widetilde{N}_{\mathcal{T}_{k}}\right]\geq 2^{k-2}\cdot\Pr\left[ \tau_{k}<\infty\right].\]Proof of Lemma D.4.: According to Lemma D.1, we have that in each block \(B_{j}=(b_{j-1},b_{j}]\),

\[\mathbb{E}\left[\mathbbm{1}\left[N_{B_{j}}\geq 1\right]-c\cdot\mathbbm{1} \left[b_{j}<\infty\right]\right]=\mathbb{E}\left[\mathbb{E}\left[\mathbbm{1} \left[N_{B_{j}}\geq 1\right]-c\cdot\mathbbm{1}\left[b_{j}<\infty\right]\,\left|\, \mathbb{F}_{b_{j-1}}\right]\right]\geq 0,\]

where the first step uses the tower property of expectations, and \(c=1-\frac{1}{e}\geq\frac{1}{2}\).

Summing over all the blocks in epoch \(\mathcal{T}_{k}\), we obtain

\[\mathbb{E}\left[\widetilde{N}_{\mathcal{T}_{k}}\right] =\sum_{j=2^{k-1}+1}^{2^{k}}\mathbb{E}\left[\widetilde{N}_{B_{j}} \right]=\sum_{j=2^{k-1}+1}^{2^{k}}\mathbb{E}\left[\mathbbm{1}\left[N_{B_{j}} \geq 1\right]\right]\] (Definition of \[\mathcal{T}_{k}\] and \[\widetilde{N}_{t}\] ) \[\geq c\cdot\mathbb{E}\left[\sum_{j=2^{k-1}+1}^{2^{k}}\mathbbm{1} \left[b_{j}<\infty\right]\right]\] (Lemma D.1 ) \[\geq c\cdot\mathbb{E}\left[\sum_{j=2^{k-1}+1}^{2^{k}}\mathbbm{1} \left[\tau_{k}<\infty\right]\right]\] ( \[b_{j}\leq b_{2^{k}}=\tau_{k}\text{ for all }j\leq 2^{k}\] ) \[\geq 2^{k-2}\cdot\Pr\left[\tau_{k}<\infty\right].\] ( \[c\geq 1/2\] )

We have thus established Lemma D.4. 

With Lemma D.4, we obtain a lower bound by linearizing the increment of \(\sqrt{\widetilde{N}_{t}}\) in each block.

\[\mathbb{E}\left[\sqrt{\widetilde{N}_{\tau_{k}}}-\sqrt{\widetilde{N }_{\tau_{k-1}}}\right]\] \[\geq\mathbb{E}\left[\frac{1}{2}\left(\widetilde{N}_{\tau_{k}} \right)^{-\frac{1}{2}}\cdot\left(\widetilde{N}_{\tau_{k}}-\widetilde{N}_{\tau _{k-1}}\right)\right]\] (Concavity of function \[\sqrt{x}\] ) \[\geq 2^{-\frac{k}{2}-1}\cdot\mathbb{E}\left[\widetilde{N}_{\tau_{ k}}-\widetilde{N}_{\tau_{k-1}}\right]=2^{-\frac{k}{2}-1}\cdot\mathbb{E}\left[ \widetilde{N}_{\mathcal{T}_{k}}\right]\] ( \[\widetilde{N}_{\tau_{k}}\leq 2^{k}\] ) \[\geq 2^{\frac{k}{2}-3}\cdot\Pr\left[\tau_{k}<\infty\right].\] (Lemma D.4 )

The first step above can be alternatively justified by \(\sqrt{a}-\sqrt{b}=\frac{a-b}{\sqrt{a}+\sqrt{b}}\geq\frac{a-b}{2\sqrt{a}}\), which holds for all \(a\geq b\geq 0\).

In epoch \(\mathcal{T}_{0}\).We now analyze \(\sqrt{\widetilde{N}_{\mathcal{T}_{0}}}\) in epoch \(0\). Note that the \(\mathcal{T}_{0}\) contains only the first block \(B_{1}\), so this value is either \(0\) or \(1\), depending on whether there exists a \(t\in B_{1}\) such that \(n_{t}=\mathbbm{1}\left[|x_{t}-p_{t}|\geq\frac{1}{2}\right]=1\).

Recall that in the proof of Lemma D.1, we have shown that regardless of the choice of \(p_{t}\),

\[\Pr\left[n_{t}=1\mid\mathbb{F}_{t-1}\right]=\Pr_{x_{t}\sim\text{Bernoulli}(p_{t}^ {\star})}\left[|x_{t}-p_{t}|\geq 1/2\right]\geq p_{t}^{\star}(1-p_{t}^{\star})\]

Therefore, in the special case of product distributions (i.e., the sequence \((p_{t}^{\star})\) is deterministic and each outcome \(x_{t}\sim p_{t}^{\star}\) is independent of other time steps), we can directly bound the probability that \(\sqrt{\widetilde{N}_{\mathcal{T}_{0}}}=1\) as follows:

\[\Pr\left[\sqrt{\widetilde{N}_{\mathcal{T}_{0}}}=1\right] =1-\prod_{t=1}^{\tau_{1}}\Pr\left[n_{t}=0\right]\geq 1-\prod_{t=1}^{ \tau_{1}}[1-p_{t}^{\star}(1-p_{t}^{\star})]\] \[\geq 1-\exp\left(-\sum_{t=1}^{\tau_{1}}p_{t}^{\star}(1-p_{t}^{ \star})\right)=1-\exp(-\text{Var}_{B_{1}})\geq\frac{1}{2}\text{Var}_{B_{1}},\]

where the last step follows from the inequality \(1-e^{-x}\geq x/2\) when \(0\leq x\leq 5/4\), and the fact that \(\text{Var}_{B_{1}}\leq 5/4\).

However, in the general case where the sequence \((p_{t}^{*})\) is itself random and depends on the history of \(x_{t}\)'s, such a direct argument fails. Instead, we use Lemma D.6 that extends the above analysis to this more general setting. Lemma D.6 is itself a similar but more general statement than Lemma D.5, as it is applicable even when the cumulative variance is smaller than the hard threshold \(\theta\). Invoking Lemma D.6 with \(q_{t}\coloneqq n_{t}\), \(r_{t}\coloneqq p_{t}^{*}(1-p_{t}^{*})\), and the stopping time \(\tau\) as the earlier time step between the end of block \(B_{1}\) and the first time where \(n_{t}=1\), we have

\[\Pr\left[N_{\tau}\geq 1\right] \geq 1-\operatorname{\mathbb{E}}\left[e^{-\operatorname{Var}_{ \tau}}\right]\geq\frac{1}{2}\operatorname{\mathbb{E}}\left[\operatorname{Var} _{\tau}\right],\]

where the last step again uses \(1-e^{-x}\geq x/2\) for \(x\in[0,5/4]\). Moreover, since \(\frac{5}{4}\cdot\mathbbm{1}\left[N_{\tau}\geq 1\right]\geq\operatorname{Var}_{ \tau:b_{1}}\), we also have

\[\Pr\left[N_{\tau}\geq 1\right] \geq\frac{4}{5}\operatorname{\mathbb{E}}\left[\operatorname{Var} _{\tau:b_{1}}\right]\geq\frac{1}{2}\operatorname{\mathbb{E}}\left[ \operatorname{Var}_{\tau:b_{1}}\right].\]

Combining the two inequalities, we obtain

\[\operatorname{\mathbb{E}}\left[\sqrt{\widetilde{N}_{T_{0}}}\right] =\Pr\left[N_{B_{1}}\geq 1\right]\geq\Pr\left[N_{\tau}\geq 1\right]\] \[\geq\frac{1}{4}\operatorname{\mathbb{E}}\left[\operatorname{Var} _{\tau}+\operatorname{Var}_{\tau:b_{1}}\right]=\frac{1}{4}\operatorname{ \mathbb{E}}\left[\operatorname{Var}_{B_{1}}\right]\] \[\geq\frac{1}{4}\operatorname{\mathbb{E}}\left[\operatorname{Var} _{T}\cdot\mathbbm{1}\left[\tau_{1}=\infty\right]\right].\] ( \[\tau_{1}=\infty\implies\operatorname{Var}_{T}=\operatorname{Var}_{B _{1}}\] )

Putting everything together.Combining the lower bounds for epoch \(0\) and epochs \(k\geq 1\), we obtain

\[\operatorname{\mathbb{E}}\left[\sqrt{\widetilde{N}_{T}}\right] =\operatorname{\mathbb{E}}\left[\sqrt{\widetilde{N}_{\tau_{0}}} \right]+\sum_{k\geq 1}\operatorname{\mathbb{E}}\left[\sqrt{\widetilde{N}_{\tau_{k}} }-\sqrt{\widetilde{N}_{\tau_{k-1}}}\right]\] \[\geq\frac{1}{4}\operatorname{\mathbb{E}}\left[\operatorname{Var }_{T}\cdot\mathbbm{1}\left[\tau_{1}=\infty\right]\right]+\sum_{k\geq 1}2^{\frac{k}{ 2}-3}\cdot\Pr\left[\tau_{k}<\infty\right]\] \[=\frac{1}{4}\operatorname{\mathbb{E}}\left[\operatorname{Var} _{T}\cdot\mathbbm{1}\left[\tau_{1}=\infty\right]\right]+\sum_{k\geq 1} \Pr\left[\tau_{k-1}<\infty,\tau_{k}=\infty\right]\sum_{k^{\prime}<k}2^{\frac{k^{ \prime}}{2}-3}\] \[\geq\frac{1}{8\sqrt{2}}\operatorname{\mathbb{E}}\left[ \operatorname{Var}_{T}\cdot\mathbbm{1}\left[\tau_{1}=\infty\right]+\sum_{k\geq 1 }\mathbbm{1}\left[\tau_{k-1}<\infty,\tau_{k}=\infty\right]\cdot 2^{\frac{k}{2}}\right]\] \[\geq\frac{1}{16}\operatorname{\mathbb{E}}\left[\operatorname{Var} _{T}\cdot\mathbbm{1}\left[\tau_{1}=\infty\right]+\sum_{k\geq 1}\mathbbm{1} \left[\tau_{k-1}<\infty,\tau_{k}=\infty\right]\cdot\sqrt{\operatorname{Var}_{T }}\right],\]

where the last step follows from the observation that the cumulative variance in each block cannot exceed \(2\), so \(\tau_{k}=\infty\) implies that \(\operatorname{Var}_{T}<2^{k+1}\), i.e., \(2^{k/2}\geq\sqrt{\operatorname{Var}_{T}}/\sqrt{2}\). Finally, since \(\tau_{1}=\infty\) is equivalent to \(\operatorname{Var}_{T}<1\), we have established that

\[\operatorname{\mathbb{E}}\left[\sqrt{\widetilde{N}_{T}}\right] \geq\frac{1}{16}\operatorname{\mathbb{E}}\left[\operatorname{Var}_{T}\cdot \mathbbm{1}\left[\operatorname{Var}_{T}<1\right]+\mathbbm{1}\left[ \operatorname{Var}_{T}\geq 1\right]\cdot\sqrt{\operatorname{Var}_{T}}\right]=\frac{1}{16} \operatorname{\mathbb{E}}\left[\gamma(\operatorname{Var}_{T})\right].\]

The lemma follows from the fact that \(N_{T}\geq\widetilde{N}_{T}\) always holds, which implies \(\operatorname{\mathbb{E}}\left[\sqrt{N_{T}}\right]\geq\operatorname{\mathbb{E} }\left[\sqrt{\widetilde{N}_{T}}\right]\geq\frac{1}{16}\operatorname{\mathbb{E}} \left[\gamma(\operatorname{Var}_{T})\right]\). 

### Auxiliary Lemmas

**Lemma D.5**.: _Let \(Q_{t}=\sum_{s\leq t}q_{s},R_{t}=\sum_{s\leq t}r_{s}\) be two (coupled) stochastic processes such that \(q_{t}\in\{0,1\},\ r_{t}\in[0,1]\) for all \(t\in[T]\). Let \(\mathbb{F}_{t}\) denote the filtration generated by all the randomness up to time \(t\). Suppose \(r_{t}\) is a deterministic function on \(\mathbb{F}_{t-1}\), and \(s_{t}\coloneqq\Pr\left[q_{t}=1\mid\mathbb{F}_{t-1}\right]\geq r_{t}\).__For any constant \(\theta>0\), define \(\tau_{\theta}\) to be a stopping time chosen as the first time that \(R_{t}\) reaches \(\theta\), i.e.,_

\[\tau_{\theta}\coloneqq\min\{\infty\}\cup\{t\in[T]\mid R_{t}\geq\theta\}.\]

_Let \(Q_{t}^{+}\coloneqq Q_{t:\tau_{\theta}}\) be the sum of \(q_{s}\) in the future until the stopping time \(\tau_{\theta}\). If \(t>\tau_{\theta}\), then we let \(Q_{t}^{+}\coloneqq 0\). Consider random variables \(A_{t}\)'s defined on the filtration \(\mathbb{F}_{t}\) as follows:_

\[A_{t}\coloneqq\Pr\left[Q_{t}^{+}\geq 1\,\Big{|}\,\mathbb{F}_{t}\right]-\left( 1-e^{-(\theta-R_{t})}\right)\cdot\Pr\left[\tau_{\theta}<\infty\mid\mathbb{F}_ {t}\right].\]

_Then we have \(A_{t}\geq 0\) for every \(t\leq T\) and every event in \(\mathbb{F}_{t}\)._

Proof of Lemma D.5.: It suffices to prove the inequality conditioning on events in \(\mathcal{F}_{t}\) that are "atomic" in the sense that they uniquely determine the values of \(q_{1:t}\) and \(r_{1:t}\). The general case would follow from the law of total probability. In particular, in the following proof, we may view the value of \(R_{t}\) as fixed when we analyze the quantity \(A_{t}\).

We perform a backwards induction from \(t=T\) to \(t=0\). Consider the base case of \(t=T\). If \(R_{T}\geq\theta\), we have

\[A_{T}=\underbrace{\Pr\left[Q_{T}^{+}\geq 1\,\Big{|}\,\mathbb{F}_{T}\right]}_{=0 }-\underbrace{\left(1-e^{-(\theta-R_{T})}\right)}_{\leq 0}\cdot\Pr\left[ \tau_{\theta}<\infty\mid\mathbb{F}_{T}\right]\geq 0.\]

Otherwise when \(R_{T}<\theta\), we have \(\Pr\left[\tau_{\theta}<\infty\mid\mathbb{F}_{T}\right]=0\), which also implies \(A_{T}=0\geq 0\).

We then assume \(A_{t}\geq 0\), and show that the same holds for \(A_{t-1}\), where \(t\leq T\). If \(R_{t-1}\geq\theta\), we clearly have \(A_{t-1}\geq 0\), as the factor \(-\left(1-e^{-(\theta-R_{t-1})}\right)\) would be non-negative. Therefore, it suffices to consider the case that \(R_{t-1}<\theta\). In this case, the stopping time \(\tau_{\theta}\) should be \(\geq t\), so we have \(Q_{t-1}^{+}=q_{t}+Q_{t}^{+}\). We bound \(A_{t-1}\) by breaking the event \(Q_{t-1}^{+}\geq 1\) into two cases: either \(q_{t}=1\), or \(q_{t}=0\) but \(Q_{t}^{+}\geq 1\). We have

\[\Pr\left[Q_{t-1}^{+}\geq 1\,\Big{|}\,\mathbb{F}_{t-1}\right] =\Pr\left[q_{t}=1\mid\mathbb{F}_{t-1}\right]+\Pr\left[q_{t}=0 \mid\mathbb{F}_{t-1}\right]\cdot\Pr\left[Q_{t}^{+}\geq 1\mid\mathbb{F}_{t-1},q_{t}=0\right]\] \[=s_{t}+\left(1-s_{t}\right)\mathbb{E}\left[\Pr\left[Q_{t}^{+} \geq 1\mid\mathbb{F}_{t}\right]\,\Big{|}\,\mathbb{F}_{t-1},q_{t}=0\right]\]

For the second term, we apply the induction hypothesis of \(A_{t}\geq 0\) and get

\[\mathbb{E}\left[\Pr\left[Q_{t}^{+}\geq 1\mid\mathbb{F}_{t} \right]\,\Big{|}\,\mathbb{F}_{t-1},q_{t}=0\right] \geq\mathbb{E}\left[\left(1-e^{-(\theta-R_{t})}\right)\cdot\Pr \left[\tau_{\theta}<\infty\mid\mathbb{F}_{t}\right]\,\Big{|}\,\mathbb{F}_{t-1},q_{t}=0\right]\] \[=\left(1-e^{-(\theta-R_{t-1}-r_{t})}\right)\cdot\Pr\left[\tau_{ \theta}<\infty\mid\mathbb{F}_{t-1},q_{t}=0\right],\]

where the second step uses the fact that conditioning on \(\mathcal{F}_{t-1}\), \(R_{t}=R_{t-1}+r_{t}\). As a result, we obtain

\[\Pr\left[Q_{t-1}^{+}\geq 1\,\Big{|}\,\mathbb{F}_{t-1}\right]\geq s_{t}+\left(1-s_{ t}\right)\left(1-e^{-(\theta-R_{t-1}-r_{t})}\right)\cdot\Pr\left[\tau_{\theta}< \infty\mid\mathbb{F}_{t-1},q_{t}=0\right].\] (18)

We also expand the conditional probability \(\Pr\left[\tau_{\theta}<\infty\mid\mathbb{F}_{t-1}\right]\) as follows:

\[\Pr\left[\tau_{\theta}<\infty\mid\mathbb{F}_{t-1}\right] =s_{t}\cdot\Pr\left[\tau_{\theta}<\infty\mid\mathbb{F}_{t-1},q_{ t}=1\right]+\left(1-s_{t}\right)\Pr\left[\tau_{\theta}<\infty\mid \mathbb{F}_{t-1},q_{t}=0\right]\] \[\leq s_{t}+\left(1-s_{t}\right)\Pr\left[\tau_{\theta}<\infty\mid \mathbb{F}_{t-1},q_{t}=0\right]\] (19)

Combining the bounds in (18) and (19), we obtain

\[A_{t-1} \geq s_{t}+\left(1-s_{t}\right)\left(1-e^{-(\theta-R_{t-1}-r_{t}) }\right)\cdot\Pr\left[\tau_{\theta}<\infty\mid\mathbb{F}_{t-1},q_{t}=0\right]\] \[=s_{t}\cdot e^{-(\theta-R_{t-1})}+\left(1-s_{t}\right)\cdot\left(e ^{-(\theta-R_{t-1})}-e^{-(\theta-R_{t-1}-r_{t})}\right)\cdot\Pr\left[\tau_{ \theta}<\infty\mid\mathbb{F}_{t-1},q_{t}=0\right]\] \[\geq e^{-(\theta-R_{t-1})}\cdot\left(s_{t}\cdot e^{r_{t}}+1-e^{r_{t }}\right)\] (bounding the probability by \[1\] ) \[\geq e^{-(\theta-R_{t-1})}\cdot\left(r_{t}\cdot e^{r_{t}}+1-e^{r_{t }}\right)\] ( \[s_{t}\geq r_{t}\] from assumption) \[=e^{-(\theta-R_{t-1})+r_{t}}\cdot\left(r_{t}+e^{-r_{t}}-1\right)\geq 0.\] ( \[\forall x,\,e^{-x}\geq 1-x\] )

We have thus proved that the claim also holds for \(t-1\). This completes the induction.

[MISSING_PAGE_FAIL:45]

[MISSING_PAGE_FAIL:46]

Taking an expectation over \(x_{1},\ldots,x_{T}\sim\mathsf{Bernoulli}(\alpha)\) and \(y\sim\mathsf{Unif}(\{0,1\}^{T})\) gives

\[\operatorname*{\mathbb{E}}_{x_{1},\ldots,x_{T}\sim\mathsf{Bernoulli }(\alpha)}\left[\mathsf{SSC}(x,\beta\cdot\widetilde{1}_{T})\right] =\operatorname*{\mathbb{E}}_{x,y}\left[\sup_{f\in\mathcal{F}} \sum_{t=1}^{T}y_{t}\cdot f(\beta)\cdot(x_{t}-\beta)\right]\] \[=\operatorname*{\mathbb{E}}_{x,y}\left[\left|\sum_{t=1}^{T}y_{t} \cdot(x_{t}-\beta)\right|\right]\] \[\geq\left|\operatorname*{\mathbb{E}}_{x,y}\left[\sum_{t=1}^{T}y_{ t}\cdot(x_{t}-\beta)\right]\right|\] \[=\left|\frac{\alpha-\beta}{2}\cdot T\right|=\Omega_{\alpha,\beta }(T),\]

where the third step follows from Jensen's inequality \(\operatorname*{\mathbb{E}}\left[\left|X\right|\right]\geq\left|\operatorname* {\mathbb{E}}\left[X\right]\right|\). 

## Appendix F Proof of Lemma 7.1

**Lemma 7.1**.: _For any \(x\in\{0,1\}^{T}\) and \(p\in[0,1]^{T}\),_

\[\mathsf{SSC}(x,p)\leq\frac{1}{2}\mathsf{smCE}(x,p)+O(\sqrt{T}),\]

_where the \(O(\cdot)\) notation hides a universal constant that does not depend on \(T\), \(x\) or \(p\)._

We prove Lemma 7.1 via a standard chaining argument.

Proof of Lemma 7.1.: We decompose the SSCE as follows:

\[\mathsf{SSC}(x,p)\] \[=\operatorname*{\mathbb{E}}_{y\sim\mathsf{Unif}(\{0,1\}^{T})} \left[\sup_{f\in\mathcal{F}}\sum_{t=1}^{T}y_{t}\cdot f(p_{t})\cdot(x_{t}-p_{t })\right]\] \[\leq\operatorname*{\mathbb{E}}_{y\sim\mathsf{Unif}(\{0,1\}^{T})} \left[\sup_{f\in\mathcal{F}}\sum_{t=1}^{T}\left(y_{t}-\frac{1}{2}\right)\cdot f (p_{t})\cdot(x_{t}-p_{t})\right]+\frac{1}{2}\sup_{f\in\mathcal{F}}\sum_{t=1}^{ T}f(p_{t})\cdot(x_{t}-p_{t}).\]

Note that the second term is exactly \(\frac{1}{2}\mathsf{smCE}(x,p)\), so it suffices to bound the first term by \(O(\sqrt{T})\).

For notational convenience, let \(M_{T}^{(f)}\coloneqq\sum_{t=1}^{T}\left(y_{t}-\frac{1}{2}\right)\cdot f(p_{t} )\cdot(x_{t}-p_{t})\) for function \(f\in\mathcal{F}\). We will establish the following bound for any \(N\geq 1\) and functions \(f_{1},f_{2},\ldots,f_{N}\) from \([0,1]\) to \([-1,1]\):

\[\operatorname*{\mathbb{E}}_{y\sim\mathsf{Unif}(\{0,1\}^{T})}\left[\sup_{i\in[N ]}M_{T}^{(f_{i})}\right]\leq O(\sqrt{T\log N}).\] (20)

Assuming Inequality (20), applying Dudley's chaining technique [1] to the \(\delta\)-covering \(\mathcal{F}_{\delta}\) defined in Lemma C.2 would give

\[\operatorname*{\mathbb{E}}_{y\sim\mathsf{Unif}(\{0,1\}^{T})} \left[\sup_{f\in\mathcal{F}}M_{T}^{(f)}\right] \lesssim\int_{0}^{1}\sqrt{T\log|\mathcal{F}_{\delta}|}\ \mathrm{d}\delta\] (chaining) \[\lesssim\sqrt{T}\cdot\int_{0}^{1}\delta^{-\frac{1}{2}}\ \mathrm{d}\delta\qquad \text{ ($\log|\mathcal{F}_{\delta}|\leq O(1/\delta)$ from Lemma C.2)}\] \[\leq O(\sqrt{T}),\]

which implies the lemma.

Therefore, it remains to establish Inequality (20). We prove this using Hoeffding's inequality and a union bound. For each \(i\in[N]\) and every \(\varepsilon>0\), we have

\[\Pr\left[\sup_{i\in[N]}M_{T}^{(f_{i})}\geq\varepsilon\right] \leq\sum_{i=1}^{N}\Pr\left[M_{T}^{(f_{i})}\geq\varepsilon\right]\] (union bound) \[\leq\sum_{i=1}^{N}\exp\left(-\frac{2\varepsilon^{2}}{\sum_{t=1}^ {T}(x_{t}-p_{t})^{2}f_{i}(p_{t})^{2}}\right)\] (Hoeffding's inequality) \[\leq N\cdot\exp\left(-\frac{2\varepsilon^{2}}{T}\right).\] ( \[\|f_{i}\|_{\infty}\leq 1,\;\forall i\in[N]\] )

Finally, the bound (20) holds by taking an integral over \(\varepsilon>0\): shorthanding \(X\coloneqq\sup_{i\in[N]}M_{T}^{(f_{i})}\), we have

\[\mathbb{E}\left[X\right]\leq\int_{0}^{+\infty}\Pr\left[X\geq\tau\right]\;\; \mathrm{d}\tau\leq\int_{0}^{+\infty}\min\{N\cdot e^{-2\tau^{2}/T},1\}\;\; \mathrm{d}\tau=O(\sqrt{T\log N}).\]

This completes the proof. 

## Appendix G Supplemental Materials for Section 8

We justify the claim in Section 8 that it is impossible for the SSCE (and most natural calibration measures) to incentivize truthful prediction against all adaptive adversaries.

Suppose that the adversary draws \(x_{1}\) from \(\mathsf{Bernoulli}(1/2)\). If the forecaster predicts \(p_{1}=0\), all the subsequent bits are zeros; otherwise, the adversary keeps producing independent samples from \(\mathsf{Bernoulli}(1/2)\).

Clearly, the truthful forecaster predicts \(p_{t}=1/2\) at every step \(t\in[T]\), and the resulting outcome sequence \(x\) is uniform over \(\{0,1\}^{T}\). The resulting SSCE is then \(\Theta(T^{1/2})\) in expectation. If the forecaster keeps predicting \(p_{t}=0\) instead, the expectation of SSCE\((x,p)\) is only \(O(1)\). Note that this impossibility holds for any calibration measure \(\mathsf{CM}\) that satisfies

\[\operatorname*{\mathbb{E}}_{x_{1},\ldots,x_{T}\sim\mathsf{Bernoulli}(1/2)} \left[\mathsf{CM}_{T}(x,\vec{1}_{T}/2)\right]=\omega(1)\]

and

\[\operatorname*{\mathbb{E}}_{x_{1}\sim\mathsf{Bernoulli}(1/2)}\left[\mathsf{ CM}_{T}(x_{1}\circ\vec{0}_{T-1},\vec{0}_{T})\right]=O(1),\]

where \(\circ\) denotes concatenation.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: The claims match the theoretical results that we prove in the paper. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: This is a theoretical work, so the results hold for the specific problem setups and formulations, which we formally state in Section 2. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes]Justification: All the theorems and claims are formally proved, either in the main paper or in the appendix. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [NA] Justification: The paper does not include experiments. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?Answer: [NA] Justification: The paper does not include experiments requiring code. Guidelines:

* The answer NA means that paper does not include experiments requiring code.
* Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [NA] Justification: The paper does not include experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [NA] Justification: The paper does not include experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors). * It should be clear whether the error bar is the standard deviation or the standard error of the mean.

* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [NA] Justification: The paper does not include experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: The research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: This is a theoretical work, and there is no societal impact of the work performed to the best of our knowledge. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.

* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: The paper poses no such risks. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licensees for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [NA] Justification: The paper does not use existing assets. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.

* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: The paper does not release new assets. Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.