# Score matching through the roof: linear, nonlinear, and latent variables causal discovery

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

Causal discovery from observational data holds great promise, but existing methods rely on strong assumptions about the underlying causal structure, often requiring full observability of all relevant variables. We tackle these challenges by leveraging the score function \(\nabla\log p(X)\) of observed variables for causal discovery and propose the following contributions. First, we generalize the existing results of identifiability with the score to additive noise models with minimal requirements on the causal mechanisms. Second, we establish conditions for inferring causal relations from the score even in the presence of hidden variables; this result is two-faced: we demonstrate the score's potential as an alternative to conditional independence tests to infer the equivalence class of causal graphs with hidden variables, and we provide the necessary conditions for identifying direct causes in latent variable models. Building on these insights, we propose a flexible algorithm for causal discovery across linear, nonlinear, and latent variable models, which we empirically validate.

## 1 Introduction

The inference of causal effects from observations holds the potential for great impact arguably in any domain of science, where it is crucial to be able to answer interventional and counterfactual queries from observational data [1; 2; 3]. Existing causal discovery methods can be categorized based on the information they can extract from the data [4], and the assumptions they rely on. Traditional causal discovery methods (e.g. PC, GES [5; 6]) are general in their applicability but limited to the inference of an equivalence class. Additional assumptions on the structural equations generating effects from the cause are, in fact, imposed to ensure the identifiability of a causal order [7; 8; 9; 10]. As a consequence, existing methods for causal discovery require specialized and often untestable assumptions, preventing their application to real-world scenarios.

Further, the majority of existing approaches are hindered by the assumption that all relevant causes of the measured data are observed, which is necessary to interpret associations in the data as causal relationships. Despite the convenience of this hypothesis, it is often not met in practice, and the solutions relaxing this requirement face substantial limitations. The FCI algorithm [11] can only return an equivalence class from the data. Appealing to additional restrictions ensures the identifiability of some direct causal effects in the presence of latent variables: RCD [12] relies on the linear non-Gaussian additive noise model, whereas CAM-UV [13] requires nonlinear additive mechanisms. Nevertheless, the strict conditions on the structural equations hold back their applicability to more general settings.

Our paper tackles these challenges and can be put in the context of a recent line of work that derives a connection between the score function \(\nabla\log p(X)\) and the causal graph underlying the data-generating process [14; 15; 16; 17; 18; 19]. The use of the score for causal discovery is practically appealing, as it yields advantages in terms of scalability to high dimensional graphs [16]and guarantees of finite sample complexity bounds [20]. Instead of imposing assumptions that ensure strong, though often impractical, theoretical guarantees, we organically demonstrate different levels of identifiability based on the strength of the modeling hypotheses, always relying on the score function to encode all the causal information in the data. Starting from results of Spantini et al. [21] and Lin [22], we show how constraints on the Jacobian of the score \(\nabla^{2}\log p(X)\) can be used as an alternative to conditional independence testing to identify the Markov equivalence class of causal models with hidden variables. Further, we prove that the score function identifies the causal direction of additive noise models, with minimal assumptions on the causal mechanisms. This extends the previous findings of Montagna et al. [17], limited by the assumption of nonlinearity of the causal effects, and Ghoshal and Honorio [14], limited to linear mechanisms. On these results, we build the main contributions of our work, enabling the identification of direct causal effects in hidden variables models.

**Our main contributions** are as follows: _(i)_ We present the necessary conditions for the identifiability of direct causal effects and the presence of hidden variables with the score in the case of latent variables models. _(ii)_ We propose AdaScore (Adaptive Score-based causal discovery), a flexible algorithm for causal discovery based on score matching estimation of \(\nabla\log p(X)\)[23]. Based on the user's belief about the plausibility of several modeling assumptions on the data, AdaScore can output a Markov equivalence class, a directed acyclic graph, or a mixed graph, accounting for the presence of unobserved variables. To the best of our knowledge, the broad class of causal models handled by our method is unmatched by other approaches in the literature.

## 2 Model definition and related works

In this section, we introduce the formalism of structural causal models (SCMs), separately for the the cases with and without hidden variables.

### Causal model with observed variables

Let \(X\) be a set of random variables in \(\mathbb{R}\) defined according to the set of structural equations

\[X_{i}\coloneqq f_{i}(X_{\mathrm{PA}_{i}^{\mathcal{G}}},N_{i}),\ \ \forall i=1,\ldots,k.\] (1)

\(N_{i}\in\mathbb{R}\) are mutually independent random variables with strictly positive density, known as _noise_ or error terms. The function \(f_{i}\) is the _causal mechanism_ mapping the set of _direct causes_\(X_{\mathrm{PA}_{i}^{\mathcal{G}}}\) of \(X_{i}\) and the noise term \(N_{i}\), to \(X_{i}\)'s value. A structural causal model (SCM) is defined as the tuple \((X,N,\mathcal{F},\mathbb{P}_{N})\), where \(\mathcal{F}=(f_{i})_{i=1}^{k}\) is the set of causal mechanisms, and \(\mathbb{P}_{N}\) is the joint distribution relative to the density \(p_{N}\) over the noise terms \(N\in\mathbb{R}^{k}\). We define the _causal graph_\(\mathcal{G}\) as a directed acyclic graph (DAG) with nodes \(X=\{X_{1},\ldots,X_{k}\}\), and the set of edges defined as \(\{X_{j}\to X_{i}:X_{j}\in X_{\mathrm{PA}_{i}^{\mathcal{G}}}\}\), such that \(\mathrm{PA}_{i}^{\mathcal{G}}\) are the indices of the parent nodes of \(X_{i}\) in the graph \(\mathcal{G}\). (In the remainder of the paper, we adopt the following notation: given a set of random variables \(Y=\{Y_{1},\ldots,Y_{n}\}\) and a set of indices \(Z\subset\mathbb{N}\), then \(Y_{Z}=\{Y_{i}|i\in Z,Y_{i}\in Y\}\).)

Under this model, the probability density of \(X\) satisfies the _Markov factorization_ (e.g. Peters et al. [1] Proposition 6.31):

\[p(x)=\prod_{i=1}^{k}p(x_{i}|x_{\mathrm{PA}_{i}^{\mathcal{G}}}),\] (2)

where we adopt the convention of lowercase letters referring to realized random variables, and use \(p\) to denote the density of different random objects, when the distinction is clear from the argument. This factorization is equivalent to the _global Markov condition_ (e.g. Peters et al. [1] Proposition 6.22) that demands that for all \(\{X_{i},X_{j}\}\in X,X_{Z}\subseteq X\setminus\{X_{i},X_{j}\}\), then

\[X_{i}\,\mbox{$\perp\!\!\!\perp$}\,\mbox{$\perp\!\!\!\perp$}\,\mbox{$\circ$}\,X_ {j}|X_{Z}\implies X_{i}\,\mbox{$\perp\!\!\!\perp$}\,X_{j}|X_{Z},\]

where \((\cdot\,\mbox{$\perp\!\!\!\perp$}\,\cdot\,|\cdot)\) denotes probabilistic conditional independence of \(X_{i},X_{j}\) given \(X_{Z}\), and \((\cdot\,\mbox{$\perp\!\!\!\perp$}\,\mbox{$\circ$}\,\cdot\,|\cdot)\) is the notation for _d-separation_, a criterion of conditional independence defined on the graph \(\mathcal{G}\) (Definition 5 of the appendix). As it is commonly done, we assume that the reverse direction \(X_{i}\,\mbox{$\perp\!\!\!\perp$}\,X_{j}|X_{Z}\implies X_{i}\,\mbox{$\perp\!\!\! \perp$}\,\mbox{$\circ$}\,X_{j}|X_{Z}\) hold, and we say that the density \(p\) is _faithful_ to the graph \(\mathcal{G}\)[2; 24] (hence the _faithfulness assumption_). Together with the global Markov condition, faithfulness implies an equivalence between the probabilistic and graphical notions of conditional independence:

\[X_{i}\,\mbox{$\perp\!\!\!\perp$}\,X_{j}|X_{Z}\Longleftrightarrow X_{i}\,\mbox {$\perp\!\!\!\perp$}\,\mbox{$\circ$}\,X_{j}|X_{Z}.\] (3)

[MISSING_PAGE_FAIL:3]

[MISSING_PAGE_EMPTY:4]

Markov equivalence class is the most we can hope to achieve without further hypotheses. As we will see in the next section, the score function can also help leverage additional restrictive assumptions on the causal mechanisms of Equation (4) to identify direct causal effects.

## 4 A theory of identifiability from the score

In this section, we show that, under additional assumptions on the data-generating process, we can identify the direct causal relations that are not influenced by unobserved variables, as well as the presence of unobserved active paths (Definition 5) between nodes in the marginalized graph \(\mathcal{M}_{V}^{\mathcal{G}}\).

As a preliminary step before diving into causal discovery with latent variables, we show how the properties of the score function identify edges in directed acyclic graphs, that is in the absence of latent variables (when \(U=\emptyset\) and \(\mathcal{G}=\mathcal{M}_{V}^{\mathcal{G}}\)). The goal of the next section is two-sided: first, it introduces the fundamental ideas connecting the score function to causal discovery that also apply to hidden variable models, second, it extends the existing theory of causal discovery with score matching to additive noise models with both linear and nonlinear mechanisms.

### Warm up: identifiability without latent confounders

In this section, we summarise and extend the theoretical findings presented in Montagna et al. [17], where the authors show how to derive constraints on the score function that identify the causal order of the DAG \(\mathcal{G}\) where all the variables in the set \(X\) are observed. Define the structural relations of (1) as:

\[X_{i}\coloneqq h_{i}(X_{\mathrm{PA}_{i}^{\mathcal{G}}})+N_{i},i=1,\ldots,k,\] (7)

with three times continuously differentiable mechanisms \(h_{i}\), noise terms centered at zero, and strictly positive density \(p_{X}\). Given the Markov factorization of Equation (2), the components of the score function \(\nabla\log p(x)\) are:

\[\begin{split}\partial_{X_{i}}\log p(x)&=\partial_{ X_{i}}\log p(x_{i}|x_{\mathrm{PA}_{i}^{\mathcal{G}}})+\sum_{j\in\mathrm{CH}_{i}^{ \mathcal{G}}}\partial_{X_{i}}\log p(x_{j}|x_{\mathrm{PA}_{j}^{\mathcal{G}}}) \\ &=\partial_{N_{i}}\log p(n_{i})-\sum_{j\in\mathrm{CH}_{i}^{ \mathcal{G}}}\partial_{X_{i}}h_{j}(x_{\mathrm{PA}_{j}^{\mathcal{G}}}) \partial_{N_{j}}\log p(n_{j}),\end{split}\] (8)

where \(\mathrm{CH}_{i}^{\mathcal{G}}\) denotes the set of children of node \(X_{i}\). We observe that if a node \(X_{s}\) is a _sink_, i.e. a node satisfying \(\mathrm{CH}_{s}^{\mathcal{G}}=\emptyset\), then the summation over the children vanishes, implying that:

\[\partial_{X_{s}}\log p(x)=\partial_{N_{s}}\log p(n_{s}).\] (9)

The key point is that the score component of a sink node is a function of its structural equation noise term, such that one could learn a consistent estimator of \(\partial_{X_{s}}\log p_{X}\) from a set of observations of the noise term \(N_{s}\). Given that, in general, one has access to \(X\) samples rather than observations of the noise random variables, authors in Montagna et al. [17] show that \(N_{s}\) of a sink node can be consistently estimated from i.i.d. realizations of \(X\). For each node \(X_{1},\ldots,X_{k}\), we define the quantity:

\[R_{i}\coloneqq X_{i}-\mathbf{E}[X_{i}|X_{\setminus X_{i}}],\] (10)

where \(X_{\setminus X_{i}}\) are the random variables in the set \(X\setminus\{X_{i}\}\). \(\mathbf{E}[X_{i}|X_{\setminus X_{i}}]\) is the optimal least squares predictor of \(X_{i}\) from all the remaining nodes in the graph, and \(R_{i}\) is the regression residual. For a sink node \(X_{s}\), the residual satisfies:

\[R_{s}=N_{s},\] (11)

which can be seen by rewriting \(\mathbf{E}[X_{s}|X_{\setminus X_{s}}]=h_{s}(X_{\mathrm{PA}_{s}^{\mathcal{G}}} )+\mathbf{E}[N_{s}|X_{\mathrm{DE}_{s}^{\mathcal{G}}},X_{\mathrm{ND}_{s}^{ \mathcal{G}}}]=h_{s}(X_{\mathrm{PA}_{s}^{\mathcal{G}}})+\mathbf{E}[N_{s}]\), where \(X_{\mathrm{DE}_{s}^{\mathcal{G}}}\) and \(X_{\mathrm{ND}_{s}^{\mathcal{G}}}\) denotes the descendants and non-descendants of \(X_{s}\), respectively. Equations (9) and (11) together imply that the score \(\partial_{N_{s}}\log p(N_{s})\) is a function of \(R_{s}\), such that it is possible to find a consistent approximator of the score of a sink from observations of \(R_{s}\).

**Proposition 2** (Generalization of Lemma 1 in Montagna et al. [17]).: _Let \(X\) be a set of random variables, generated by a restricted additive noise model (Definition 9) with structural equations (7), and let \(X_{j}\in X\). Consider \(r_{j}\) in the support of \(R_{j}\). Then:_

\[X_{j}\text{ is a sink}\Longleftrightarrow\mathbf{E}\left[\left(\mathbf{E} \left[\partial_{X_{j}}\log p(X)\mid R_{j}=r_{j}\right]-\partial_{X_{j}}\log p( X)\right)^{2}\right]=0.\] (12)Our result generalizes Lemma 1 in Montagna et al. [17], as they assume \(X\) generated by an identifiable additive noise model with nonlinear mechanisms. Instead, we remove the nonlinearity assumption and make the weaker hypothesis of a _restricted_ additive noise model, which is provably identifiable [9], in the formal sense defined in the appendix (Definition 8). This result doesn't come as a surprise, given the previous findings of Ghoshal and Honorio [14] showing that the score infers linear non-Gaussian additive noise models: Proposition 2 provides a unifying and general theory for the identifiability of models with potentially mixed linear and nonlinear mechanisms.

Based on these insights, Montagna et al. [17] propose the NoGAM algorithm to exploit the condition in (12) for identifying the causal order of the graph: being \(\mathbf{E}\left[\partial_{X_{i}}\log p(X)\mid R_{i}\right]\) the optimal least squares estimator of the score of node \(X_{i}\) from \(R_{i}\), a sink node is characterized as the \(\operatorname*{argmin}_{i}\mathbf{E}\left[\mathbf{E}\left[\partial_{X_{i}} \log p(X)\mid R_{i}\right]-\partial_{X_{i}}\log p(X)\right]^{2}\), where in practice the residuals \(R_{i}\), the score components and the least squares estimators are replaced by their empirical counterparts. After a sink node is identified, it is removed from the graph and assigned a position in the order, and the procedure is iteratively repeated up to the source nodes. Being the score estimated by score matching techniques [23], we usually make reference to _score matching-based_ causal discovery.

In the next section, we show how we can generalize these results to identify direct causal effects between a pair of variables in the marginal MAG \(\mathcal{M}^{\mathcal{G}}_{V}\) when \(U\neq\emptyset\)

### Identifiability in the presence of latent confounders

We now introduce the last of our main theoretical results, that is: given a pair of nodes \(V_{i}\), \(V_{j}\) that are adjacent in the graph \(\mathcal{M}^{\mathcal{G}}_{V}\) with \(U\neq\emptyset\), we can use the score function to identify the presence of a direct causal effect between \(V_{i}\) and \(V_{j}\), or that of an active path that is influenced by unobserved variables. Given that the causal model of Equation (4) ensures identifiability only up to the equivalence class, we need additional restrictive assumptions. In particular, we enforce an additive noise model with respect to both the observed and unobserved noise variables. This corresponds to an additive noise model on the observed variables with the noise terms recentered by the latent causal effects.

**Assumption 1** (SCM assumptions).: _The set of structural equations of the observable variables specified in (4) is now defined as:_

\[V_{i}\coloneqq f_{i}(V_{\mathrm{PA}^{\mathcal{G}}_{i}})+g_{i}(U^{i})+N_{i}, \forall i=1,\dots,d,\] (13)

_assuming the mechanisms \(f_{i}\) to be of class \(\mathcal{C}^{3}(\mathbb{R}^{|V_{\mathrm{PA}^{\mathcal{G}}_{i}}|})\), and mutually independent noise terms with strictly positive density function. The \(N_{i}\)'s are assumed to be non-Gaussian when \(f_{i}\) is linear in some of its arguments._

Crucially, our hypothesis is weaker than those required by two state-of-the-art approaches, CAM-UV [13] and RCD [12]: CAM-UV assumes a Causal Additive Model (CAM) with structural equations with nonlinear mechanisms in the form \(V_{i}\coloneqq\sum_{k\in\mathrm{PA}^{\mathcal{G}}_{i}}f_{ik}(V_{k})+\sum_{U^{i }_{k}}g_{ik}(U^{i}_{k})+N_{i}\), and RCD requires an additive noise model with linear effects of both the latent and observed causes. Thus, our model encompasses and extends the nonlinear and linear settings of CAM-UV and RCD, such that the theory developed in the remainder of the section is valid for a broader class of causal models.

Our first step is rewriting the structural relations in (13) as:

\[\begin{split}& V_{i}\coloneqq f_{i}(V_{\mathrm{PA}^{\mathcal{G}}_{i} })+\tilde{N}_{i},\\ &\tilde{N}_{i}\coloneqq g_{i}(U^{i})+N_{i},\forall i=1,\dots,d, \end{split}\] (14)

which provides an additive noise model in the form of (7). Next, we define the following regression residuals for any node \(V_{k}\) in the graph \(\mathcal{M}^{\mathcal{G}}_{V}\):

\[R_{k}(V_{Z})\coloneqq V_{k}-\mathbf{E}[V_{k}\mid V_{Z\setminus\{k\}}],\] (15)

where \(V_{Z\setminus\{k\}}\) denotes the set of random variables \(V_{Z}\setminus\{V_{k}\}\).

Given these definitions, we are ready to show how directed edges, and the presence of unobserved variables can be identified from the score of linear and nonlinear additive noise models.

[MISSING_PAGE_EMPTY:7]

that are not affected by latents (using hypothesis testing to find vanishing mean squared error in the score predictions from the residuals), in the spirit of the NoGAM algorithm. If there is such a sink, we search all its adjacent nodes via Proposition 1 (plus an optional pruning step for better accuracy, Appendix C.2), and orient the inferred edges towards the sink. Else, if no sink can be found, we pick a node in the graph and find its neighbors by Proposition 1, orienting its edges using the condition in Proposition 3 (score estimation by residuals under latent effects). This way, we get an algorithm that is polynomial in the best case (Appendix C.3). Details on AdaScore are provided in Appendix C, while a pseudo-code summary is provided in the Algorithm 1 box.

``` while nodes remain do if Proposition 3 finds a sink with all parents observed then  add edges from adjacent nodes to sink else  pick some remaining node \(V_{i}\in V\)  prune neighbourhood of \(V_{i}\) using Proposition 1  orient edges adjacent to \(V_{i}\) using Proposition 3 if\(V_{i}\) has outgoing directed edge to some \(V_{j}\in V\)then continue with \(V_{j}\) else  remove \(V_{i}\) form remaining nodes  prune remaining bidirected edges using Proposition 1 ```

**Algorithm 1** Simplified pseudo-code of AdaScore

## 5 Experiments

We use the \(\mathtt{causally}^{2}\) Python library [26] to generate synthetic data with known ground truths, created as Erdos-Renyi sparse and dense graphs, respectively with probability of edge between pair of nodes equals \(0.3\) and \(0.5\). We sample the data according to linear and nonlinear mechanisms with additive noise, where the nonlinear functions are parametrized by a neural network with random weights, a common approach in the literature [18; 26; 27; 28; 29]. Noise terms are sampled from a uniform distribution in the \([-2,2]\) range. Hidden causal effects are obtained by randomly picking two nodes and dropping the corresponding column from the data matrix. See Appendix D.1 for further details on the data generation. As metric, we consider the structural Hamming distance (SHD) [30; 31], a simple count of the number of incorrect edges, where missing and wrongly directed edges count as one error. We fix the level of the hypothesis tests of AdaScore to \(0.05\), which is a common choice in the absence of prior knowledge. We compare AdaScore to NoGAM, CAM-UV, RCD, and DirectLiNGAM, whose assumptions are detailed in Table 1. In the main manuscript, we comment on the results on datasets of \(1000\) observations from _dense_ graphs, with and without latent variables. Additional experiments including those on sparse networks are presented in Appendix E. Our synthetic data are standardized by their empirical variance to remove shortcuts in the data [18; 32].

Discussion.Our experimental results on models without latent variables of Figure 0(a) show that when causal relations are linear, AdaScore can recover the causal graph with accuracy that is comparable with all the other benchmarks, with the exception of DirectLiNGAM. On nonlinear data AdaScore presents better performance than CAM-UV, RCD, and DirectLiNGAM while being comparable to NoGAM in accuracy. This is in line with our expectations: in the absence of finite sample errors and in the fully observable setting, NoGAM and AdaScore are indeed the same algorithms. When inferring under latent causal effects, Figure 0(b), our method performs comparably to CAM-UV and RCD on graphs up to seven nodes while slightly degrading on nine nodes. Additionally, AdaScore outperforms NoGAM in this setting, as we would expect according to our theory. Overall, we observe that our method is robust to a variety of structural assumptions, with accuracy that is often comparable and sometimes better than competitors (as in nonlinear observable settings). We remark that although AdaScore does not clearly outperform the other baselines, its broad theoretical guarantees of identifiability are not matched by any available method in the literature; this makes it an appealing option for inference in realistic scenarios that are hard to investigate with synthetic data, where the structural assumptions of the causal model underlying the observations are unknown.

## 6 Conclusion

The existing literature on causal discovery shows a connection between score matching and structure learning in the context of nonlinear ANMs: in this paper, (i) we formalize and extend these results to linear SCMs, and (ii) we show that the score retains information on the causal structure even in the presence of unobserved variables. Additionally, while previous works posit the accent on finding the causal order through the score, we study its potential to identify the Markov equivalence class with a _constraint-based_ strategy that does not explicitly require tests of conditional independence, as well as to identify direct causal effects. Our theoretical insights result in AdaScore: unlike existing approaches for the estimation of causal directions, our algorithm provides theoretical guarantees for a broad class of identifiable models, namely linear and nonlinear, with additive noise, in the presence of latent variables. Even though AdaScore does not clearly outperform the existing baselines on our synthetic benchmark, its adaptivity to different structural hypotheses is a step towards causal discovery that is less reliant on prior assumptions, which are often untestable and thus hindering reliable inference in real-world problems. While we do not touch on the task of causal representation learning [33], where causal variables are learned from data, we believe this is a promising research direction in relation to our work due to the specific interplay between score-matching estimation and generative models.

\begin{table}
\begin{tabular}{l c c c c} \hline \hline  & CAM-UV & RCD & NoGAM & DirectLiNGAM & AdaScore \\ \hline Linear additive noise model & ✗ & ✓ & ✗ & ✓ \\ Nonlinear additive noise model & ✗ & ✗ & ✓ & ✗ & ✓ \\ Nonlinear CAM & ✓ & ✗ & ✓ & ✗ & ✓ \\ Latent variables effects & ✓ & ✓ & ✗ & ✗ & ✓ \\ \hline Output & Mixed & Mixed & DAG & DAG & Mixed \\ \hline \hline \end{tabular}
\end{table}
Table 1: Experiments causal discovery algorithms. The content of the cells denotes whether the method supports (✓) or not (✗) the condition specified in the corresponding row.

Figure 1: Empirical results on dense graphs with different numbers of nodes, on fully observable (no hidden variables) and latent variable models. We report the SHD accuracy (the lower, the better). We note that DirectLiNGAM is surprisingly robust to different structural assumptions, and AdaScore is generally comparable or better (as in nonlinear observable data) than the other benchmarks.

## References

* Peters et al. [2017] Jonas Peters, Dominik Janzing, and Bernhard Scholkopf. _Elements of causal inference: foundations and learning algorithms_. The MIT Press, 2017.
* Pearl [2009] Judea Pearl. _Causality_. Cambridge university press, 2009.
* Spirtes [2010] Peter Spirtes. Introduction to causal inference. _Journal of Machine Learning Research_, 11(54):1643-1662, 2010. URL http://jmlr.org/papers/v11/spirtes10a.html.
* Glymour et al. [2019] Clark Glymour, Kun Zhang, and Peter Spirtes. Review of causal discovery methods based on graphical models. _Frontiers in Genetics_, 10, 2019. ISSN 1664-8021. doi: 10.3389/fgene.2019.00524. URL https://www.frontiersin.org/articles/10.3389/fgene.2019.00524.
* Spirtes et al. [2000] P. Spirtes, C. Glymour, and R. Scheines. _Causation, Prediction, and Search_. MIT press, 2nd edition, 2000.
* Chickering [2003] David Maxwell Chickering. Optimal structure identification with greedy search. _J. Mach. Learn. Res._, 3(null):507-554, mar 2003. ISSN 1532-4435. doi: 10.1162/153244303321897717. URL https://doi.org/10.1162/153244303321897717.
* Shimizu et al. [2006] Shohei Shimizu, Patrik O. Hoyer, Aapo Hyvarinen, and Antti Kerminen. A linear non-gaussian acyclic model for causal discovery. _J. Mach. Learn. Res._, 7:2003-2030, dec 2006. ISSN 1532-4435.
* Hoyer et al. [2008] Patrik Hoyer, Dominik Janzing, Joris M Mooij, Jonas Peters, and Bernhard Scholkopf. Nonlinear causal discovery with additive noise models. In D. Koller, D. Schuurmans, Y. Bengio, and L. Bottou, editors, _Advances in Neural Information Processing Systems_, volume 21. Curran Associates, Inc., 2008. URL https://proceedings.neurips.cc/paper/2008/file/f7664060cc52bc6f3d620bcedc94a4b6-Paper.pdf.
* Peters et al. [2014] Jonas Peters, Joris M. Mooij, Dominik Janzing, and Bernhard Scholkopf. Causal discovery with continuous additive noise models. _J. Mach. Learn. Res._, 15(1):2009-2053, jan 2014. ISSN 1532-4435.
* Zhang and Hyvarinen [2009] Kun Zhang and Aapo Hyvarinen. On the identifiability of the post-nonlinear causal model. In _Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence_, UAI '09, page 647-655, Arlington, Virginia, USA, 2009. AUAI Press. ISBN 9780974903958.
* Spirtes [2001] Peter Spirtes. An anytime algorithm for causal inference. In Thomas S. Richardson and Tommi S. Jaakkola, editors, _Proceedings of the Eighth International Workshop on Artificial Intelligence and Statistics_, volume R3 of _Proceedings of Machine Learning Research_, pages 278-285. PMLR, 04-07 Jan 2001. URL https://proceedings.mlr.press/r3/spirtes01a.html. Reissued by PMLR on 31 March 2021.
* Maeda and Shimizu [2020] Takashi Nicholas Maeda and Shohei Shimizu. Rcd: Repetitive causal discovery of linear non-gaussian acyclic models with latent confounders. In Silvia Chiappa and Roberto Calandra, editors, _Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics_, volume 108 of _Proceedings of Machine Learning Research_, pages 735-745. PMLR, 26-28 Aug 2020. URL https://proceedings.mlr.press/v108/maeda20a.html.
* Maeda and Shimizu [2021] Takashi Nicholas Maeda and Shohei Shimizu. Causal additive models with unobserved variables. In _Uncertainty in Artificial Intelligence_, pages 97-106. PMLR, 2021.
* Ghoshal and Honorio [2018] Asish Ghoshal and Jean Honorio. Learning linear structural equation models in polynomial time and sample complexity. In Amos Storkey and Fernando Perez-Cruz, editors, _Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics_, volume 84 of _Proceedings of Machine Learning Research_, pages 1466-1475. PMLR, 09-11 Apr 2018. URL https://proceedings.mlr.press/v84/ghoshal18a.html.
* Rolland et al. [2008] Paul Rolland, Volkan Cevher, Matthaus Kleindessner, Chris Russell, Dominik Janzing, Bernhard Scholkopf, and Francesco Locatello. Score matching enables causal discovery of nonlinear additive noise models. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato, editors, _Proceedings of the 39th International Conference onMachine Learning_, volume 162 of _Proceedings of Machine Learning Research_, pages 18741-18753. PMLR, 17-23 Jul 2022.
* Montagna et al. [2023] Francesco Montagna, Nicoletta Nocetti, Lorenzo Rosasco, Kun Zhang, and Francesco Locatello. Scalable causal discovery with score matching. In _2nd Conference on Causal Learning and Reasoning_, 2023. URL https://openreview.net/forum?id=6VvoDjLBPQV.
* Montagna et al. [2023] Francesco Montagna, Nicoletta Nocetti, Lorenzo Rosasco, Kun Zhang, and Francesco Locatello. Causal discovery with score matching on additive models with arbitrary noise. In _2nd Conference on Causal Learning and Reasoning_, 2023. URL https://openreview.net/forum?id=rVO0Bx90deu.
* Montagna et al. [2023] Francesco Montagna, Nicoletta Nocetti, Lorenzo Rosasco, and Francesco Locatello. Shortcuts for causal discovery of nonlinear models by score matching, 2023.
* Sanchez et al. [2023] Pedro Sanchez, Xiao Liu, Alison Q O'Neil, and Sotirios A. Tsaftaris. Diffusion models for causal discovery via topological ordering. In _The Eleventh International Conference on Learning Representations_, 2023. URL https://openreview.net/forum?id=Idusfje4-Wq.
* Zhu et al. [2024] Zhenyu Zhu, Francesco Locatello, and Volkan Cevher. Sample complexity bounds for score-matching: Causal discovery and generative modeling. _Advances in Neural Information Processing Systems_, 36, 2024.
* Spantini et al. [2018] Alessio Spantini, Daniele Bigoni, and Youssef Marzouk. Inference via low-dimensional couplings, 2018.
* Lin [1997] Juan Lin. Factorizing multivariate function classes. In M. Jordan, M. Kearns, and S. Solla, editors, _Advances in Neural Information Processing Systems_, volume 10. MIT Press, 1997. URL https://proceedings.neurips.cc/paper_files/paper/1997/file/8fb21ee7a2207526da55a679f0332de2-Paper.pdf.
* Hyvarinen [2005] Aapo Hyvarinen. Estimation of non-normalized statistical models by score matching. _J. Mach. Learn. Res._, 6:695-709, 2005. URL https://api.semanticscholar.org/CorpusID:1152227.
* Uhler et al. [2012] Caroline Uhler, G. Raskutti, Peter Buhlmann, and B. Yu. Geometry of the faithfulness assumption in causal inference. _The Annals of Statistics_, 41, 07 2012. doi: 10.1214/12-AOS1080.
* Zhang [2008] Jiji Zhang. Causal reasoning with ancestral graphs. _Journal of Machine Learning Research_, 9(7), 2008.
* Montagna et al. [2023] Francesco Montagna, Atalanti Mastakouri, Elias Eulig, Nicoletta Nocetti, Lorenzo Rosasco, Dominik Janzing, Bryon Aragam, and Francesco Locatello. Assumption violations in causal discovery and the robustness of score matching. In A. Oh, T. Neumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, editors, _Advances in Neural Information Processing Systems_, volume 36, pages 47339-47378. Curran Associates, Inc., 2023. URL https://proceedings.neurips.cc/paper_files/paper/2023/file/93ed74938a54a73b5e4c52bbaf42ca8e-Paper-Conference.pdf.
* Lippe et al. [2022] Phillip Lippe, Taco Cohen, and Efstratios Gavves. Efficient neural causal discovery without acyclicity constraints. In _International Conference on Learning Representations_, 2022. URL https://openreview.net/forum?id=eYCiPrLuhG.
* Ke et al. [2023] Nan Rosemary Ke, Silvia Chiappa, Jane X Wang, Jorg Bornschein, Anirudh Goyal, Melanie Rey, Theophane Weber, Matthew Botvinick, Michael Curtis Mozer, and Danilo Jimenez Rezende. Learning to induce causal structure. In _International Conference on Learning Representations_, 2023. URL https://openreview.net/forum?id=hp_RwhKDJ5.
* Brouillard et al. [2020] Philippe Brouillard, Sebastien Lachapelle, Alexandre Lacoste, Simon Lacoste-Julien, and Alexandre Drouin. Differentiable causal discovery from interventional data. In _Proceedings of the 34th International Conference on Neural Information Processing Systems_, NIPS '20, Red Hook, NY, USA, 2020. Curran Associates Inc. ISBN 9781713829546.

* Tsamardinos et al. [2006] Ioannis Tsamardinos, Laura E Brown, and Constantin F Aliferis. The max-min hill-climbing bayesian network structure learning algorithm. _Machine learning_, 65:31-78, 2006.
* Triantafillou and Tsamardinos [2016] Sofia Triantafillou and Ioannis Tsamardinos. Score-based vs constraint-based causal learning in the presence of confounders. In _Cfa@ uai_, pages 59-67, 2016.
* Reisach et al. [2021] Alexander G. Reisach, Christof Seiler, and Sebastian Weichwald. Beware of the simulated dag! causal discovery benchmarks may be easy to game. In _Neural Information Processing Systems_, 2021. URL https://api.semanticscholar.org/CorpusID:239998404.
* Scholkopf et al. [2021] Bernhard Scholkopf, Francesco Locatello, Stefan Bauer, Nan Ke, Nal Kalchbrenner, Anirudh Goyal, and Y. Bengio. Toward causal representation learning. _Proceedings of the IEEE_, PP:1-23, 02 2021. doi: 10.1109/JPROC.2021.3058954.
* Spirtes and Richardson [1996] Peter Spirtes and Thomas Richardson. A polynomial time algorithm for determining dag equivalence in the presence of latent variables and selection bias. In _Proceedings of the 6th International Workshop on Artificial Intelligence and Statistics_, pages 489-500. Citeseer, 1996.
* Li and Turner [2017] Yingzhen Li and Richard E Turner. Gradient estimators for implicit models. _arXiv preprint arXiv:1705.07107_, 2017.
* Buhlmann et al. [2014] Peter Buhlmann, Jonas Peters, and Jan Ernest. CAM: Causal additive models, high-dimensional order search and penalized regression. _The Annals of Statistics_, 42(6), dec 2014. URL https://doi.org/10.1214%2F14-aos1260.

Useful results

In this section, we provide a collection of results and definitions relevant to the theory of this paper.

### Definitions over graphs

Let \(X=X_{1},\ldots,X_{d}\) a set of random variables. A graph \(\mathcal{G}=(X,E)\) consists of finitely many nodes or vertices \(X\) and edges \(E\). We now provide additional definitions, separately for directed acyclic and mixed graphs.

Directed acyclic graph.In a _directed graph_, nodes can be connected by a _directed edge_ (\(\rightarrow\)), and between each pair of nodes there is at most one directed edge. We say that \(X_{1}\) is a _parent_ of \(X_{j}\) if \(X_{i}\to X_{j}\in E\), in which case we also say that \(X_{j}\) is a _child_ of \(X_{i}\). Two nodes are _adjacent_ if they are connected by an edge. Three nodes are called a _v-structure_ if one node is a child of the other two, e.g. as \(X_{i}\to X_{k}\gets X_{j}\) is a collider. A _path_ in \(\mathcal{G}\) is a sequence of at least two distinct vertices \(X_{i_{1}},\ldots,X_{i_{m}}\) such that there is an edge between \(X_{i_{k}}\) and \(X_{i_{k+1}}\). If \(X_{i_{k}}\to X_{i_{k+1}}\) for every node in the path, we speak of a _directed path_, and call \(X_{i_{k}}\) an _ancestor_ of \(X_{i_{k+1}}\), \(X_{i_{k+1}}\) a _descendant_ of \(X_{i_{k}}\). Given the set \(\mathrm{DE}_{i}^{\mathcal{G}}\) of descendants of a node \(X_{i}\), we define the set of _non-descendants_ of \(X_{i}\) as \(\mathrm{ND}_{i}^{\mathcal{G}}=X\setminus(\mathrm{DE}_{i}^{\mathcal{G}}\cup\{X_ {i}\})\). A node without parents is called a _source node_. A node without children is called a _sink node_. A _directed acyclic graph_ is a directed graph with no cycles.

Mixed graph.In a _mixed graph_ nodes can be connected by a _directed edge_ (\(\rightarrow\)) or a _bidirected edge_ (\(\leftrightarrow\)), and between each pair of nodes there is at most one directed edge. Two vertices are said to be _adjacent_ in a graph if there is an edge (of any kind) between them. The definitions of _parent_, _child_, _ancestor_, _descendant_, _path_ provided for directed acyclic graph also apply in the case of mixed graphs. Additionally, \(X_{i}\) is a spouse of \(X_{j}\) (and vice-versa) if \(X_{i}\leftrightarrow X_{j}\in E\). An _almost directed cycle_ occurs when \(X_{i}\leftrightarrow X_{j}\in E\) and \(X_{i}\) is an ancestor of \(X_{j}\) in \(\mathcal{G}\).

For ease of reference from the main text, we separately provide the definition of inducing paths and ancestors in directed acyclic graphs.

**Definition 2** (Ancestor).: Consider a DAG \(\mathcal{G}\) with set of nodes \(X\), and \(X_{i},X_{j}\) elements of \(X\). We say that \(X_{i}\) is an _ancestor_ of \(X_{j}\) if there is a directed path from \(X_{i}\) to \(X_{j}\) in the graph, as in \(X_{i}\rightarrow\ldots\to X_{j}\).

**Definition 3** (Inducing path).: Consider a DAG \(\mathcal{G}\) with set of nodes \(X\), and \(Y,Z\) disjoint subsets such that \(X=Y\dot{\cup}Z\). We say that there is an _inducing path relative to \(Z\)_ between the nodes \(Y_{i},Y_{j}\) if every node on the path that is not in \(Z\cup\{Y_{i},Y_{j}\}\) is a collider on the path (i.e. for each \(Y_{k}\in Y\) on the path the sequence \(Y_{i}\ldots\to Y_{k}\leftarrow\ldots Y_{j}\) appears) and every collider on the path is an ancestor of \(Y_{i}\) or \(Y_{j}\).

One natural way to encode inducing paths and ancestral relationships between variables is represented by maximal ancestral graphs.

**Definition 4** (Mag).: A _maximal ancestral graph_ (MAG) is a mixed graph such that:

1. there are no directed cycles and no almost directed cycles;
2. there are no inducing paths between two non-adjacent nodes.

Next, we define conditional independence in the context of graphs.

**Definition 5** (m-separation).: Let \(\mathcal{M}\) be a mixed graph with nodes \(X\). A path \(\pi\) in \(\mathcal{M}\) between \(X_{i},X_{j}\) elements of \(X\) is _active_ w.r.t. \(Z\subseteq X\setminus\{X_{i},X_{j}\}\) if:

1. every non-collider on \(\pi\) is not in \(Z\)
2. every collider on \(\pi\) is an ancestors of a node in \(Z\).

\(X_{i}\) and \(X_{j}\) are said to be _m-separated_ by \(Z\) if there is no active path between \(X_{i}\) and \(X_{j}\) relative to \(Z\). Two disjoint sets of variables \(W\) and \(Y\) are _m-separated_ by \(Z\) if every variable in \(W\) is m-separated from every variable in \(Y\) by \(Z\).

If m-separation is applied to DAGs, it is called _d-separation_.

The set of directed acyclic graphs that satisfy the same set of conditional independencies form an equivalence class, known as the _Markov equivalence class_.

**Definition 6** (Markov equivalence class of a DAG).: Let \(\mathcal{G}\) be a DAG with nodes \(X\). We denote with \([\mathcal{G}]\) the _Markov equivalence class_ of \(\mathcal{G}\). A DAG \(\tilde{\mathcal{G}}\) with nodes \(X\) is in \([\mathcal{G}]\) if the following conditions are satisfied for each pair \(X_{i},X_{j}\) of distinct nodes in \(X\):

* there is an edge between \(X_{i}\), \(X_{j}\) in \(\mathcal{G}\) if and only if there is an edge between \(X_{i}\), \(X_{j}\) in \(\tilde{\mathcal{G}}\);
* let \(Z\subseteq X\setminus\{X_{i},X_{j}\}\). Then ;
* let \(\pi\) be a path between \(X_{i}\) and \(X_{j}\). \(X_{k}\) is a collider in the path \(\pi\) in \(\mathcal{G}\) if and only if it is a collider in the path \(\pi\) in \(\tilde{\mathcal{G}}\).

In summary, graphs in the same equivalence class share the edges up to direction, the set of d-separations, and the set of colliders.

Just as for DAGs, there may be several MAGs that imply the same conditional independence statements. Denote the _Markov-equivalence class_ of a MAG \(\mathcal{M}\) with \([\mathcal{M}]\): this is represented by a partial mixed graph, the class of graphs that can contain four kinds of edges: \(\rightarrow\), \(\leftrightarrow\), \(\circ\)--\(\circ\) and \(\circ\)\(\rightarrow\), and hence three kinds of end marks for edges: arrowhead (\(>\)), tail (\(-\)) and circle (\(\circ\)).

**Definition 7** (Pag, Definition 3 of Zhang [25]).: Let \([\mathcal{M}]\) be the Markov equivalence class of an arbitrary MAG \(\mathcal{M}\). The partial ancestral graph (PAG) for \([\mathcal{M}]\), \(P_{\mathcal{M}}\), is a partial mixed graph such that:

* \(P_{\mathcal{M}}\) has the same adjacencies as \(\mathcal{M}\) (and any member of \([\mathcal{M}]\)) does;
* A mark of arrowhead is in \(P_{\mathcal{M}}\) if and only if it is shared by all MAGs in \([\mathcal{M}]\); and
* A mark of tail is in \(P_{\mathcal{M}}\) if and only if it is shared by all MAGs in \([\mathcal{M}]\).

Intuitively, a PAG represents an equivalence class of MAGs by displaying all common edge marks shared by all members of the class and displaying circles for those marks that are not in common.

### Equivalence between m-separation and d-separation

In this section, we provide a proof for equation (5), stating the equivalence between m-separation and d-separation in a formal sense.

**Lemma 1** (Adapted from Zhang [25]).: _Let \(\mathcal{G}\) be a DAG with nodes \(X=V\cup U\), with \(V\) and \(U\) disjoint sets, and \(\mathcal{M}^{\mathcal{G}}_{V}\) the marginalization of \(\mathcal{G}\) onto \(V\). For any \(\{V_{i},V_{j}\}\in V\) and \(V_{Z}\subseteq V\setminus\{V_{i},V_{j}\}\), the following equivalence holds:_

Proof.: The implication \(V_{i}\mathop{\hbox{\scalebox{1.2}{$\perp$}}}\limits_{\mathcal{G}}V_{j}|V_{Z}\implies V_{i}\mathop{\hbox{\scalebox{1.2}{$\perp$}}} \limits_{\mathcal{M}^{\mathcal{G}}_{V}}^{m}V_{j}|V_{Z}\) is a direct consequence of Lemma 18 from Spirtes and Richardson [34], where we set \(S=\emptyset\), since we do not consider selection bias. The implication \(V_{i}\mathop{\hbox{\scalebox{1.2}{$\perp$}}}\limits_{\mathcal{G}}V_{j}|V_{Z} \iff V_{i}\mathop{\hbox{\scalebox{1.2}{$\perp$}}}\limits_{\mathcal{M}^{ \mathcal{G}}_{V}}^{m}V_{j}|V_{Z}\) follows from Lemma 17 by Spirtes and Richardson [34], again with \(S=\emptyset\). Note, that in their terminology "d-separation in MAGs" is what we call m-separation. 

### Additive noise model identifiability

We study the identifiability of the additive noise model, reporting results from Peters et al. [9]. We start with a formal definition of identifiability in the context of causal discovery.

**Definition 8** (Identifiable causal model).: Let \((X,N,\mathcal{F},p_{N})\) be an SCM with underlying graph \(\mathcal{G}\) and \(p_{X}\) joint density function of the variables of \(X\). We say that the model is _identifiable_ from observational data if the distribution \(p_{X}\) can not be generated by a structural causal model with graph \(\tilde{\mathcal{G}}\neq\mathcal{G}\).

First, we consider the case of models of two random variables

\[X_{2}\coloneqq f(X_{1})+N,\quad X_{1}\mathop{\hbox{\scalebox{1.2}{$\perp$}}} \limits_{\mathcal{M}}N.\] (17)

**Condition 1** (Condition 19 of Peters et al. [9]).: Consider an additive noise model with structural equations (17). The triple \((f,p_{X_{1}},p_{N})\) does not solve the following differential equation for all pairs \(x_{1},x_{2}\) with \(f^{\prime}(x_{2})\nu^{\prime\prime}(x_{2}-f(x_{1}))\neq 0\):

\[\xi^{\prime\prime\prime}=\xi^{\prime\prime}\left(\frac{f^{\prime\prime}}{f^{ \prime}}-\frac{\nu^{\prime\prime\prime}f^{\prime}}{\nu^{\prime\prime}}\right) +\frac{\nu^{\prime\prime\prime}\nu^{\prime}f^{\prime\prime}f^{\prime}}{\nu^{ \prime\prime}}-\frac{\nu^{\prime}(f^{\prime\prime})^{2}}{f^{\prime}}-2\nu^{ \prime\prime}f^{\prime\prime}f^{\prime}+\nu^{\prime}f^{\prime\prime\prime},\] (18)

Here, \(\xi\coloneqq\log p_{X_{1}}\), \(\nu\coloneqq\log p_{N}\), the logarithms of the strictly positive densities. The arguments \(x_{2}-f(x_{1})\), \(x_{1}\), and \(x_{1}\) of \(\nu\), \(\xi\) and \(f\) respectively, have been removed to improve readability.

Next, we show that a structural causal model satisfying Condition 1 is identifiable, as in Definition 8

**Theorem 1** (Theorem 20 of Peters et al. [9]).: _Let \(p_{X_{1},X_{2}}\) the joint distribution of a pair of random variables generated according to the model of equation (17) that satisfies Condition 1, with graph \(\mathcal{G}\). Then, \(\mathcal{G}\) is identifiable from the joint distribution._

Finally, we show an important fact, holding for identifiable bivariate models, which is that the score \(\frac{\partial}{\partial X_{1}}\log p(x_{1},x_{2})\) is nonlinear in \(x_{1}\).

**Lemma 2** (Sufficient variability of the score).: _Let \(p_{X_{1},X_{2}}\) the joint distribution of a pair of random variables generated according to a structural causal model that satisfies Condition 1, with graph \(\mathcal{G}\). Then:_

\[\frac{\partial}{\partial X_{1}}(\xi^{\prime}(x_{1})-f^{\prime}(x_{1})\nu^{ \prime}(x_{2}-f(x_{1})))\neq 0,\]

_for all pairs \((x_{1},x_{2})\)._

Proof.: By contradiction, assume that there exists \((x_{1},x_{2})\) such that \(\frac{\partial}{\partial X_{1}}(\xi^{\prime}(x_{1})-f^{\prime}(x_{1})\nu^{ \prime}(x_{2}-f(x_{1})))=0\). Then:

\[\frac{\partial}{\partial X_{1}}\left(\frac{\frac{\partial^{2}}{\partial X_{1} ^{2}}\pi(x_{1},x_{2})}{\frac{\partial^{2}}{\partial X_{1}\partial X_{2}}\pi( x_{1},x_{2})}\right)=0,\]

where \(\pi(x_{1},x_{2})=\log p(x_{1},x_{2})\). By explicitly computing all the partial derivatives of the above equation, we obtain that equation 18 is satisfied, which violates Condition 1. 

These results guaranteeing the identifiability of the bivariate additive noise model can be generalized to the multivariable case, with a set of random variables \(X=\{X_{1},\ldots,X_{k}\}\) that satisfy:

\[X_{i}\coloneqq f_{i}(X_{\mathrm{PA}^{\mathcal{G}}_{i}})+N_{i},i=1,\ldots,k,\] (19)

where \(\mathcal{G}\) is the resulting causal graph directed and acyclic. The intuition is that, rather than studying the multivariate model as a whole, we need to ensure that Condition 1 is satisfied for each pair of nodes, adding restrictions on their marginal conditional distribution.

**Definition 9** (Definition 27 of Peters et al. [9]).: Consider an additive noise model with structural equations (19). We call this SCM a _restricted additive noise model_ if for all \(X_{j}\in X\), \(X_{i}\in X_{\mathrm{PA}^{\mathcal{G}}_{j}}\), and all sets \(X_{S}\subseteq X\), \(S\subset\mathbb{N}\), with \(X_{\mathrm{PA}^{\mathcal{G}}_{j}}\setminus\{X_{i}\}\subseteq X_{S}\subseteq X _{\mathrm{ND}_{j}}^{\mathcal{G}}\setminus\{X_{i},X_{j}\}\), there is a value \(x_{S}\) with \(p(x_{S})>0\), such that the triplet

\[(f_{j}(x_{\mathrm{PA}^{\mathcal{G}}_{j}\setminus\{i\}},\cdot),p_{X_{i}|X_{S}=x _{S}},p_{N_{j}})\]

satisfies Condition 1. Here, \(f_{j}(x_{\mathrm{PA}^{\mathcal{G}}_{j}\setminus\{i\}},\cdot)\) denotes the mechanism function \(x_{i}\mapsto f_{j}(x_{\mathrm{PA}^{\mathcal{G}}_{j}})\). Additionally, we require the noise variables to have positive densities and the functions \(f_{j}\) to be continuous and three times continuously differentiable.

Then, for a restricted additive noise model, we can identify the graph from the distribution.

**Theorem 2** (Theorem 28 of Peters et al. [9]).: _Let \(X\) be generated by a restricted additive noise model with graph \(\mathcal{G}\), and assume that the causal mechanisms \(f_{j}\) are not constant in any of the input arguments, i.e. for \(X_{i}\in X_{\mathrm{PA}^{\mathcal{G}}_{j}}\), there exist \(x_{i}\neq x_{i}^{\prime}\) such that \(f_{j}(x_{\mathrm{PA}^{\mathcal{G}}_{j}\setminus\{i\}},x_{i})\neq f_{j}(x_{ \mathrm{PA}^{\mathcal{G}}_{j}\setminus\{i\}},x_{i}^{\prime})\). Then, \(\mathcal{G}\) is identifiable._

### Other auxiliary results

We state several results that hold for a pair of random variables that are not connected by an active path that includes unobserved variables (active paths are introduced in Definition 5). For the remainder of the section, let \(V,U\) be a pair of disjoint sets of random variables, \(X=V\cup U\) generated according to the structural causal model defined by the set of equations (1), \(\mathcal{G}\) the associated causal graph, and \(\mathcal{M}_{V}^{\mathcal{G}}\) the marginalization onto \(V\).

The first statement provides under which condition the unobserved parents of two variables in the marginal MAG are mutually independent random vectors.

**Lemma 3**.: _Let \(V_{j}\in V\), and \(Z\subset\mathbb{N}\) such that \(V_{Z}=V_{\mathrm{PA}_{j}^{\mathcal{G}}}\cup\{V_{j}\}\). Assume \(V_{\mathrm{PA}_{j}^{\mathcal{G}}}\mathop{\hbox{\scalebox{0.8}{$\perp$}}} \limits_{\mathcal{G}}U^{j}\). Then for each index \(Z_{k}\neq j\)._

Proof.: The assumption \(V_{\mathrm{PA}_{j}^{\mathcal{G}}}\mathop{\hbox{\scalebox{0.8}{$\perp$}}} \limits_{\mathcal{G}}U^{j}\) implies that there is no active path in \(\mathcal{G}\) between nodes in \(V_{\mathrm{PA}_{j}^{\mathcal{G}}}\) and nodes in \(U^{j}\). Given that for each \(Z_{k}\in Z\), \(Z_{k}\neq Z\), nodes in \(U^{Z_{k}}\) are direct causes of at least one node in \(V_{\mathrm{PA}_{j}^{\mathcal{G}}}\), any active path between nodes in \(U^{Z_{k}}\) and nodes in \(U^{j}\) would also be an active path between \(V_{\mathrm{PA}_{j}^{\mathcal{G}}}\) and \(U^{j}\), which is a contradiction. Hence \(U^{j}\mathop{\hbox{\scalebox{0.8}{$\perp$}}}\limits_{\mathcal{G}}U^{Z_{k}}\). 

The previous lemmas allow proving the following result, which will be fundamental to demonstrate the theory of Proposition 3.

**Lemma 4**.: _Let \(V_{j}\in V\), and \(Z\subset\mathbb{N}\) such that \(V_{Z}=V_{\mathrm{PA}_{j}^{\mathcal{G}}}\cup\{V_{j}\}\). Assume \(V_{\mathrm{PA}_{j}^{\mathcal{G}}}\mathop{\hbox{\scalebox{0.8}{$\perp$}}} \limits_{\mathcal{G}}U^{j}\). W.l.o.g., let the \(j\)-th element of \(V_{Z}\) be \(V_{Z_{j}}=V_{j}\). Denote as \(U^{Z}\) the set of unobserved parents of nodes in \(V_{Z}\), and \(U^{Z\setminus\{j\}}\) the unobserved parents of nodes in \(V_{Z\setminus\{j\}}\coloneqq V_{Z}\setminus V_{j}\). Then, the following holds for each \(v_{Z},u^{Z}\) values:_

\[\log p(v_{Z})=\log p(v_{j}|v_{\mathrm{PA}_{j}^{\mathcal{G}}})+\log Q(v_{Z}),\]

_where_

\[Q(v_{Z})=\sum_{u^{Z\setminus\{j\}}}p(u^{Z\setminus\{j\}})\prod_{k\neq j}^{|Z| }p(v_{Z_{k}}|v_{Z_{1}},\ldots,v_{Z_{k-1}},u^{Z_{k}}).\]

Proof.: By the law of total probability and the chain rule, we can write \(p(v_{Z})\) as:

\[\begin{split} p(v_{Z})&=\sum_{u}p(v_{Z}|u)p(u)\\ &=\sum_{u}p(u)p(v_{Z_{j}}|u,v_{Z\setminus\{j\}})p(v_{Z\setminus \{j\}}|u).\end{split}\] (20)

By Lemma 3, \(U^{Z_{j}}\mathop{\hbox{\scalebox{0.8}{$\perp$}}}\limits_{\mathcal{G}}U^{Z_{k}}\), \(k\neq j\), where \(U^{Z_{k}}\) denotes unobserved parents of the node \(V_{Z_{k}}\). Then, we can factorize \(p(u)=p\left(u^{Z_{j}}\right)p\left(u^{Z\setminus\{j\}}\right)\). Plugging the factorization in equation (20) we find

\[\begin{split} p(v_{Z})&=\sum_{u}p\left(u^{Z_{j}} \right)p\left(u^{Z\setminus\{j\}}\right)p(v_{Z_{j}}|u,v_{Z\setminus\{j\}})p(v_ {Z\setminus\{j\}}|u)\\ &=\sum_{u}p\left(u^{Z_{j}}\right)p\left(u^{Z\setminus\{j\}}\right) p(v_{Z_{j}}|u^{Z_{j}},v_{\mathrm{PA}_{Z_{j}}^{\mathcal{G}}})p(v_{Z\setminus\{j\}}|u), \end{split}\]

where the latter equation comes from the global Markov property on the graph \(\mathcal{G}\). Further, by assumption of \(V_{\mathrm{PA}_{j}^{\mathcal{G}}}\mathop{\hbox{\scalebox{0.8}{$\perp$}}} \limits_{\mathcal{G}}U^{j}\), we know that \(U^{Z_{j}}\mathop{\hbox{\scalebox{0.8}{$\perp$}}}\limits_{\mathcal{G}}V_{Z_{k}}\), \(k\neq j\), such that \(p(v_{Z\setminus\{j\}}|u)=p(v_{Z\setminus\{j\}}|u^{Z\setminus\{j\}})\). Then:

\[\begin{split} p(v_{Z})&=\sum_{u}p\left(u^{Z_{j}} \right)p\left(u^{Z\setminus\{j\}}\right)p(v_{Z_{j}}|u^{Z_{j}},v_{\mathrm{PA}_{Z_{ j}}^{\mathcal{G}}})p(v_{Z\setminus\{j\}}|u^{Z\setminus\{j\}})\\ &=\sum_{u^{Z_{j}}}p\left(u^{Z_{j}}\right)p(v_{Z_{j}}|u^{Z_{j}},v_{ \mathrm{PA}_{Z_{j}}^{\mathcal{G}}})\sum_{u^{Z\setminus\{j\}}}p\left(u^{Z\setminus \{j\}}\right)p(v_{Z\setminus\{j\}}|u^{Z\setminus\{j\}})\\ &=p(v_{Z_{j}}|v_{\mathrm{PA}_{Z_{j}}^{\mathcal{G}}})\sum_{u^{Z \setminus\{j\}}}p\left(u^{Z\setminus\{j\}}\right)p(v_{Z\setminus\{j\}}|u^{Z \setminus\{j\}}),\end{split}\]

which proves the claim.

Intuitively, Lemma 4 shows that given a node \(V_{j}\) without children and bidirected edges in a marginalized graph \(\mathcal{M}_{V_{Z}}^{\mathcal{G}}\), the _kernel_ of node \(V_{j}\) in the Markov factorization of \(p(v_{Z})\) is equal to the kernel of the same node in the Markov factorization of \(p(x)\) of equation (2), relative to the graph without latent confounders \(\mathcal{G}\).

## Appendix B Proofs of theoretical results

### Proof of Proposition 1

Proof of Proposition 1.: Observe that

\[\frac{\partial^{2}}{\partial V_{i}\partial V_{j}}\log p(v_{Z})=0\iff V_{i} \mathop{\mathchoice{\vbox{\hbox{\scalebox{.5}{$\perp$}}\hbox{ \scalebox{.5}{$\perp$}}\hbox{\scalebox{.5}{$\perp$}} \hbox{\scalebox{.5}{$\perp$}}\hbox{\scalebox{.5}{$\perp$}} \hbox{\scalebox{.5}{$\perp$}}\hbox{\scalebox{.5}{$\perp$}} \hbox{\scalebox{.5}{$\perp$}}\hbox{\scalebox{.5}{$\perp$}} \hbox{\scalebox{.5}{$\perp$}}\hbox{\scalebox{.5}{$\perp$}} \hbox{\scalebox{.5}{$\perp$}}}}_{\mathcal{G}}^{d}V_{j}|V_{Z}\setminus\{V_{i},V_{ j}\}\iff V_{i}\mathop{\mathchoice{\vbox{\hbox{\scalebox{.5}{$\perp$}}\hbox{\scalebox{.5}{$\perp$}}\hbox{\scalebox{.5}{$\perp$}}\hbox{\scalebox{.5}{$ \perp$}}\hbox{\scalebox{.5}{$\perp$}}\hbox{\scalebox{.5}{$ \perp$}}\hbox{\scalebox{.5}{$\perp$}}\hbox{\scalebox{.5}{$ \perp$}}\hbox{\scalebox{.5}{$\perp$}}\hbox{\scalebox{.5}{$ \perp$}}\hbox{\scalebox{.5}{$\perp$}}\hbox{\scalebox{.5}{$ \perp$}}\hbox{\scalebox{.5}{$\perp$}}\hbox{\scalebox{.5}{$ \perp$}}\hbox{\scalebox{.5}{$\perp$}}\hbox{\scalebox{.5}{$ \perp$}}\hbox{\scalebox{.5}{$\perp$}}}}_{\mathcal{M}_{V}^{\mathcal{G}}}^{m}V_{j}|V_ {Z}\setminus\{V_{i},V_{j}\},\]

where the first equivalence holds by a combination of the faithfulness assumption with the global Markov property, as explicit in equation (3), and the second due to Lemma 1. Then, the claim is proven. 

### Proof of Proposition 2

Proof.: The forward direction is immediate from equation (9) and \(R_{j}=N_{j}\), when \(X_{j}\) is a sink (equation (11)). Thus, we focus on the backward direction. Given

\[\mathbf{E}\left[\left(\mathbf{E}\left[\partial_{X_{j}}\log p(X)\mid R_{j}=r_{ j}\right]-\partial_{X_{j}}\log p(X)\right)^{2}\right]=0,\]

we want to show that \(X_{j}\) has no children, which we prove by contradiction.

Let us introduce a function \(q:\mathbb{R}\to\mathbb{R}\) such that:

\[\mathbf{E}\left[\partial_{X_{j}}\log p(X)\mid R_{j}=r_{j}\right]=q(r_{j}),\]

and \(s_{j}:\mathbb{R}^{|X|}\to\mathbb{R}\),

\[s_{j}(x)=\partial_{X_{j}}\log p(x).\]

The mean squared error equal to zero implies that \(s_{j}(X)\) is a constant, once \(R_{j}\) is observed. Formally, under the assumption of \(p(x)>0\) for each \(x\in\mathbb{R}^{\ell}\), this implies that

\[p(s_{j}(x)\neq q(R_{j})|R_{j}=r_{j})=0,\forall x\in\mathbb{R}^{k}.\]

By contradiction, we assume that \(X_{j}\) is not a leaf, and want to show that \(s_{j}(X)\) is not constant in \(X\), given \(R_{j}\) fixed. Let \(X_{i}\) such that \(X_{j}\in X_{\mathrm{PA}_{i}^{\mathcal{G}}}\). Being the structural causal model identifiable, there is no model with distribution \(p_{X}\) whose graph has a backward edge \(X_{i}\to X_{j}\): thus, the Markov factorization of equation (2) is unique and implies:

\[\partial_{X_{j}}\log p(X)=\partial_{N_{j}}\log p(N_{j})-\sum_{k\in\mathrm{CH}_ {j}^{\mathcal{G}}}\partial_{X_{j}}h_{k}(X_{\mathrm{PA}_{k}})\partial N_{k}\log p (N_{k}).\]

We note that, by definition of residual in equation (10), \(R_{j}=r_{j}\) fixes the following distance:

\[R_{j}=N_{j}-\mathbf{E}[N_{j}|X_{\setminus X_{j}}].\]

Hence, conditioning on \(R_{j}\) doesn't restrict the support of \(X\): given \(R_{j}=r_{j}\), for any \(x_{\setminus X_{j}}\) (value of the vector of elements in \(X\setminus\{X_{j}\}\)), \(\exists n_{j}\) with \(p(n_{j}>0)\) (by the hypothesis of strictly positive densities of the noise terms) that satisfies

\[r_{j}=n_{j}-\mathbf{E}[N_{j}|x_{\setminus X_{j}}].\]

Next, we condition on all the parents of \(X_{i}\), except for \(X_{j}\), to reduce our problem to the simpler bivariate case. Let \(S\subset\mathbb{N}\) and \(X_{S}\subseteq X\) such that \(X_{\mathrm{PA}_{i}^{\mathcal{G}}}\setminus\{X_{j}\}\subseteq X_{S}\subseteq X _{\mathrm{ND}_{j}^{\mathcal{G}}}\setminus\{X_{i},X_{j}\}\), and consider \(x_{S}\) such that \(p(x_{S}>0)\). Let \(X_{\mathrm{PA}_{i}^{\mathcal{G}}}=x_{\mathrm{PA}_{i}^{\mathcal{G}}}\) hold under \(X_{S}=x_{S}\). We define \(X_{j_{|x_{s}}}\coloneqq X_{j}|(X_{S}=x_{S})\), and similarly \(X_{|x_{s}}\coloneqq X|(X_{S}=x_{S})\). Being the SCM a restricted 

[MISSING_PAGE_FAIL:18]

Let us introduce \(s_{j}:\mathbb{R}^{|V_{Z}|}\to\mathbb{R}\),

\[s_{j}(v_{Z})=\partial_{V_{j}}\log p(V_{Z}).\]

The mean squared error equal to zero implies that \(s_{j}(V_{Z})\) is constant in \(V_{Z}\), once \(R_{j}\) is observed. By contradiction, we assume that \(V_{\mathrm{PA}_{j}^{\phi}}\not=\underline{d}^{\phi}U^{j}\lor V_{i}\not\in V_{ \mathrm{PA}_{j}^{\phi}}\), and want to show that \(s_{j}(V_{Z})\) is not constant in \(V_{Z}\), given \(R_{j}\) fixed. In this regard, we make the following observation: by definition of residual in equation (15), \(R_{i}(V_{Z})=r_{i}\) fixes the following distance:

\[R_{j}(V_{Z})=\tilde{N}_{j}-\mathbf{E}[\tilde{N}_{j}|V_{Z\setminus\{j\}}].\]

Hence, conditioning on \(R_{j}(V_{Z})\) doesn't restrict the support of \(V_{Z}\): given \(R_{j}(V_{Z})=r_{j}\), \(\exists\tilde{n}_{j}\) with \(p(\tilde{n}_{j})>0\) (by assumption of strictly positive densities \(p_{N_{j}}\) and \(p_{X}\)), that satisfies

\[r_{j}=\tilde{n}_{j}-\mathbf{E}[\tilde{N}_{j}|v_{Z\setminus\{j\}}],\]

for all \(v_{Z\setminus\{j\}}\). Hence, the random variable \(V_{Z}|R_{j}(V_{Z})=r_{j}\) has strictly positive density on all points \(v_{Z}\) where \(p_{V_{Z}}(v_{Z})>0\). Now, consider \(v_{Z}\) and \(v_{Z}^{*}\), taken from the set of uncountable values such that the score \(s_{j}\) function is not a constant, meaning that \(s_{j}(v_{Z})\neq s_{j}(v_{Z}^{*})\), where \(V_{Z}\) is sampled given \(R_{j}(V_{Z})=r_{j}\). Given that different \(v_{Z}\) and \(v_{Z}^{*}\) are selected from an uncountable subset of the support, we conclude that the score \(s_{j}|(R_{j}(V_{Z})=r_{j})=\partial_{V_{j}}\log p(V_{Z}|R_{j}(V_{Z})=r_{j})\) is not a constant for at least an uncountable set of points, which contradicts equation (22). 

Proof of part (ii), forward direction.: Given that \(V_{i}\) is connected to \(V_{j}\) in the marginal MAG and that \(V_{\mathrm{PA}_{j}^{\phi}}\not=\underline{d}^{\phi}U^{j}\lor V_{i}\not\in V_{ \mathrm{PA}_{j}^{\phi}}\), we want to show that for each \(V_{Z}\subseteq V\) with \(\{V_{i},V_{j}\}\subseteq V_{Z}\), the following holds:

\[\mathbf{E}[\partial_{V_{j}}\log p(V_{Z})-\mathbf{E}[\partial_{V_{j}}\log p(V_ {Z})|R_{j}(V_{Z})=r_{j}]]^{2}\neq 0.\] (23)

Let us introduce \(h:\mathbb{R}\to\mathbb{R}\) such that:

\[\mathbf{E}[\partial_{V_{j}}\log p(V_{Z})|R_{j}(V_{Z})=r_{j}]=h(r_{j}),\]

and further define:

\[s_{j}(V_{Z})=\partial_{V_{j}}\log p(V_{Z}).\]

Having the mean squared error in equation (23) equals zero implies that \(s_{j}(V_{Z})\) is a constant, once \(R_{j}(V_{Z})\) is observed. Thus, the goal of the proof is to show that there are values of \(V_{Z}\) such that the score is not a constant once \(R_{j}\) is fixed. By definition of residual in equation (15), \(R_{j}(V_{Z})=r_{j}\) fixes the following distance:

\[R_{j}(V_{Z})=\tilde{N}_{j}-\mathbf{E}[\tilde{N}_{j}|V_{Z\setminus\{j\}}].\]

Hence, conditioning on \(R_{j}(V_{Z})\) doesn't restrict the support of \(V_{Z}\): given \(R_{j}(V_{Z})=r_{j}\), \(\exists\tilde{n}_{j}\) with \(p(\tilde{n}_{j})>0\) (by assumption of positive density of the noise \(N_{j}\) on the support \(\mathbb{R}\)), that satisfies

\[r_{j}=\tilde{n}_{j}-\mathbf{E}[\tilde{N}_{j}|v_{Z\setminus\{j\}}],\]

for all \(v_{Z\setminus\{j\}}\). Hence, the random variable \(V_{Z}|R_{j}(V_{Z})=r_{j}\) has strictly positive density on all points \(v_{Z}\) where \(p_{V_{Z}}(v_{Z})>0\). Now, consider \(v_{Z}\) and \(v_{Z}^{*}\), taken from the set of uncountable values such that the score \(s_{j}\) function is not a constant, meaning that \(s_{j}(v_{Z})\neq s_{j}(v_{Z}^{*})\), where \(V_{Z}\) is sampled given \(R_{j}(V_{Z})=r_{j}\). Given that different \(v_{Z}\) and \(v_{Z}^{*}\) are selected from an uncountable subset of the support, we conclude that the score \(s_{j}|(R_{j}(V_{Z})=r_{j})=\partial_{V_{j}}\log p(V_{Z}|R_{j}(V_{Z})=r_{j})\) is not a constant for at least an uncountable set of points, such that the claim follows. 

Proof of part (ii), backward direction.: Given that \(\mathbf{E}[\partial_{V_{j}}\log p(V_{Z})-\mathbf{E}[\partial_{V_{j}}\log p(V_ {Z})|R_{j}(V_{Z})=r_{j}]]^{2}\neq 0\) for all \(V_{Z}\subseteq V\) such that \(\{V_{i},V_{j}\}\in V_{Z}\), and given \(V_{i}\) and \(V_{j}\) adjacent in the marginal MAG, we want to show that

\[V_{\mathrm{PA}_{j}^{\phi}}\not=\underline{d}^{\phi}U^{j}\lor V_{i}\not\in V_{ \mathrm{PA}_{j}^{\phi}}.\]

The prove comes easily by contradiction: say that \(V_{\mathrm{PA}_{j}^{\phi}}\not=\underline{d}^{\phi}U^{j}\wedge V_{i}\in V_{ \mathrm{PA}_{j}^{\phi}}\). Then, by the forward direction of part _(i)_ of Proposition 3, we know that \(V_{Z}=V_{\mathrm{PA}_{j}^{\phi}}\cup\{V_{j}\}\) satisfies \(\mathbf{E}[\partial_{V_{j}}\log p(V_{Z})-\mathbf{E}[\partial_{V_{j}}\log p(V_ {Z})|R_{j}(V_{Z})=r_{j}]]^{2}=0\), leading to a contradiction.

Algorithm

### Detailed description of our algorithm

In Proposition 1 we have seen that score matching can detect \(m\)-separations and therefore the skeleton of the PAG describing the data. If one is willing to make the assumptions required for Proposition 3 it could be desirable to use this to orient edges, since the interpretation of PAG edges might be cumbersome for people not familiar with ancestral models. Therefore, one could simply find the skeleton of the PAG using the fast adjacency search [5] and then orient the edges by applying Proposition 3 on every subset of the neighbourhood of every node. This would yield a very costly algorithm. But if we make the assumptions required to orient edges with Proposition 3 we can do a bit better. In Algorithm 2 we present an algorithm that still has the same worst case runtime but runs polynomially in the best case. The main intuition is that we iteratively remove irrelevant nodes in the spirit of the original SCORE algorithm [15]. To this end, we first check if the is any unconfounded sink if we consider the set of all remaining variables. If there is one, we can orient its parents and ignore it afterwards. If there is no such set, we need to fall back to the procedure proposed above, i.e. we need to check the condition of Proposition 3 on all subsets of the neighbourhood of a node, until we find no node with a direct outgoing edge. In Proposition 4 we show that this way we do not fail orient edge or fail to remove any adjacency. In the following discussion, we will use the notation

\[\delta_{i}(X_{Z})\coloneqq\mathbf{E}[\partial_{V_{j}}\log p(V_{Z})-\mathbf{E} [\partial_{V_{j}}\log p(V_{Z})|R_{j}(V_{Z})=r_{j}]]^{2},\]

for the second residual from Proposition 3 and also

\[\delta_{i,j}(X_{Z})\coloneqq\frac{\partial^{2}}{\partial V_{i}\partial V_{j}} \log p(v_{Z})\]

for the cross-partial derivative, where \(X_{i},X_{j}\in V\) and \(Z\subseteq V\).

**Proposition 4** (Correctness of algorithm).: _Let \(X=V\dot{\cup}U\) be generated by the SCM in Equation (4) with non-constant scores for uncountably many values. Let \(\mathcal{G}_{X}\) be the causal DAG of \(X\) and \(\mathcal{G}_{V}\) be the marginal MAG of \(\mathcal{G}_{X}\). Then Algorithm 2 outputs a directed edge from \(X_{i}\in V\) to \(X_{j}\in V\) iff there is a direct edge in \(\mathcal{G}_{X}\) between them and no unobserved backdoor path w.r.t. \(U\). Further, the output of Algorithm 2 has the same skeleton as \(\mathcal{G}_{V}\)._

Proof.: We proof the statement by induction over the steps of the algorithm. Let \(S\) be the set of remaining nodes in an arbitrary step of the algorithm. Our induction hypothesis is that for \(X_{i},X_{j}\in S\) and \(X_{k}\in B_{i}\) we have

1. \(X_{i}\) is an unconfounded sink w.r.t. to some set \(S^{\prime}\subseteq S\) iff \(X_{i}\) is an unconfounded sink w.r.t. some \(S^{\prime\prime}\subseteq V\)
2. if there is no \(S^{\prime}\subseteq V\setminus\{X_{i},X_{j}\}\) such that \(X_{i}\mathbin{\hbox to 0.0pt{\vbox{\hrule height 0.4pt width 100 pt\hbox{\vrule width 0.4pt height 6.0pt depth 0.0pt} \hrule height 0.4pt width 100%\hrule height 0.4pt width 100%}}}X_{j}\mid S^{\prime}\) then \(X_{j}\in B_{i}\)

Clearly, this holds in the initial step as \(S=V\).

Suppose we find \(\delta_{i}(X_{S})=0\) for \(X_{i}\in S\). If \(X_{i}\) has at least one adjacent node in \(\mathcal{M}_{V}^{\mathcal{G}}\), by Proposition 3, we know that \(X_{i}\) does not have any children and is also not connected to any other node in \(S\) via a hidden mediator or unobserved confounder. This means, all nodes that are not separable from \(X_{i}\) must be direct parents of \(X_{i}\), which are by our induction hypothesis 2) the nodes in \(B_{i}\). Since \(X_{i}\) does not have children, it also suffices to check \(X_{i}\mathbin{\hbox to 0.0pt{\vbox{\hrule height 0.4pt width 100%\hrule height 0.4pt width 100% }}}X_{j}|S\setminus\{X_{i},X_{j}\}\) for \(X_{j}\in B_{i}\) (instead of conditioning on all subsets of \(B_{i}\)). So we can already add these direct edges to the output. If, on the other hand, \(X_{i}\) has no adjacent nodes in \(\mathcal{M}_{V}^{\mathcal{G}}\), we have \(X_{i}\mathbin{\hbox to 0.0pt{\vbox{\hrule height 0.4pt width 100% \hrule height 0.4pt width 100%\hrule height 0.4pt width 100%\hrule height 0.4pt width 100% }}}X_{j}|S\setminus\{X_{i},X_{j}\}\) for \(X_{j}\in B_{i}\), so in both cases we add the correct set of parents. Since \(X_{i}\) is not an ancestor of any of the nodes in \(S\setminus\{X_{i}\}\), \(X_{i}\) cannot be a hidden mediator or hidden confounder between nodes in \(S\setminus\{X_{i}\}\) and conditioning on \(X_{i}\) cannot block an open path. Thus, the induction hypothesis still holds in the next step.

Suppose now there is no unconfounded sink and we explore \(X_{i}\). By our induction hypothesis 2), \(B_{i}\) contains the parents of \(X_{i}\) and by Proposition 3 it suffices to only look at subsets of \(B_{i}\) to orient direct edges. And also due to the induction hypothesis 2) \(B_{i}\) contains all nodes that are not separable from \(X_{i}\). So by adding bidirected edges to all nodes in \(B_{i}\) can only add too many edges but not miss some.

Now it remains to show that the induction hypothesis holds if we set \(S\) to \(S\setminus\{X_{i}\}\). For 1) we need to show that \(X_{i}\) cannot be a hidden mediator or hidden confounder w.r.t. \(S\setminus\{X_{i}\}\) (since ignoring \(X_{i}\) won't change whether there is a direct edge or not). Suppose \(X_{i}\) is on a unobserved causal path \(X_{k}\rightarrow\cdots\to U^{m}\to X_{l}\) with \(X_{k}\), \(X_{l}\in S\setminus\{X_{i}\}\) and \(U^{m}\in X\setminus(S\setminus\{X_{i}\})\). This path must have been a unobserved causal path before, unless \(X_{i}=U^{m}\). But then there is a direct edge \(X_{i}\to X_{l}\). We would not remove \(X_{i}\) from \(S\) if this edge was unconfounded, so there must a hidden confounder between \(X_{i}\) and \(X_{l}\). But in this case, Proposition 3 wouldn't allow us to direct the edge anyway, since \(V_{\text{PA}_{i}}\mathop{\mathchoice{\vbox{\hbox{$\buildrel \vbox{\hbox{$\buildrel\vbox{\hbox{$\buildrel\vbox{\hbox{$ \buildrel\vbox{\hbox{$\buildrel\vbox{\hbox{$\buildrel\vbox{ \hbox{$\buildrel\vbox{\hbox{$\buildrel\vbox{\hbox{$ \buildrel\vbox{\vbox{$\hbox{$\buildrel\vbox{$ \vbox{$\build{$\build{$ \build{$\build{$ \build{$ $}}}}}}}}}}}}}}{}}}_{d}}^{d}U_{l}\). Suppose there is confounding path \(X_{k}\leftarrow\cdots\to U^{m}\to X_{l}\) with \(X_{k},X_{l}\in S\setminus\{X_{i}\}\) and \(U^{m}\in X\setminus(S\setminus\{X_{i}\})\). If \(X_{i}\neq U^{m}\) the path was already been a confounding path without \(X_{i}\) being unobserved. So again, there must be a confounder between \(X_{i}\) and \(X_{l}\), as otherwise we would not remove \(X_{i}\). And analogously to before, we could not have oriented the edge even with \(X_{i}\in S\) since \(V_{\text{PA}_{i}}\mathop{\mathchoice{\vbox{\hbox{$\buildrel \vbox{\hbox{$\buildrel\vbox{\hbox{$\buildrel\vbox{\hbox{$ \buildrel\vbox{\hbox{$\buildrel\vbox{\hbox{$ \buildrel\vbox{\hbox{$\buildrel\vbox{\hbox{$ \buildrel\vbox{$\build{$\build{$ \build{$\build{$ \build{$ \build{$ \build{$ \build{$ \ $}}}}}}}}}}}}}}_{d}}^{d}U_{l}\). For 2) we only have to see that we just remove nodes from \(B_{i}\) if we found an independence.

For \(|S|<2\), the algorithm enters the final pruning stage. From the discussion above it is clear, that we already have the correct result, up to potentially too many bidirected edges. In the final step we certainly remove all these edges \(X_{i}\leftrightarrow X_{j}\), as we check \(m\)-separation for all subsets of the neighbourhoods \(\operatorname{Adj}(X_{i})\) and \(\operatorname{Adj}(X_{j})\), which are supersets of the true neighbourhoods.

### Finite sample version of AdaScore

All theoretical results in the paper have assumed that we know the density of our data. Obviously, in practise we have to deal with a finite sample instead. Especially, in Proposition 1 and Proposition 3 we derived criteria that compare random variables with zero. Clearly, this condition is never met in practise. Therefore, we need find ways to reasonably set thresholds for these random quantities.

First note, that we use the Stein gradient estimator [35] to estimate the score function. This means especially that for a node \(V_{i}\) we get a vector

\[\left((\frac{\partial}{\partial V_{i}}\log p(v))_{l}\right)_{l=1,\ldots,m},\] (24)

i.e. an estimate of the score for every one of the \(m\) samples. Analogously, we get a \(m\times d\times d\) tensor for the estimates of \(\frac{\partial^{2}}{\partial V_{i}\partial V_{j}}\log p(v)\).

In Proposition 1 we showed that

\[\frac{\partial^{2}}{\partial V_{i}\partial V_{j}}\log p(v_{Z})=0\iff X_{i} \mathop{\mathchoice{\hbox{\hbox to 0.0pt{\kern 2.999968pt\vrule height 6.299904 pt width 1px\hss}\hbox{$\perp$}}}{\hbox{\hbox to 0.0pt{\kern 2.999968pt \vrule height 6.299904pt width 1px\hss}\hbox{$\perp$}}}{\hbox{\hbox to 0.0pt{ \kern 2.099968pt\vrule height 6.299904pt width 1px\hss}\hbox{$\perp$}}}{\hbox{ \hbox to 0.0pt{\kern 1.499977pt\vrule height 6.299904pt width 1px\hss}\hbox{$ \perp$}}}}_{\mathcal{M}_{V}^{0}}^{m}V_{j}|V_{Z}\setminus\{V_{i},V_{j}\}.\]

In the finite sample version, we use a one sample t-test on the vector of estimated cross-partial derivatives with the null-hypothesis that the means is zero. Due to the central limit theorem, the sample mean follows approximately a Gaussian distribution, regardless of the true distribution of the observations.

For Proposition 3 we need to do some additional steps. Recall, that the relevant quantity in Proposition 3 is the mean squared error of a regression, which is always positive. Therefore, a test for mean zero is highly likely to reject in any case. We decided to employ a two-sample test in a similar (but different) manner as Montagna et al. [17]. As test, we used the Mann-Whitney U-test. Note, that Algorithm 2 employs Proposition 3 in two different ways: first, to decide whether there is an unconfounded sink and second, to orient edges in case there is no unconfounded sink. We pick a different sample as second sample of the Mann-Whitney U-test.

Analogously to before, this is a vector with \(m\) entries, one for every sample.

Note, that in the case where we want to check if there is an unconfounded sink, we do not make any mistake by rejecting too few hypotheses, i.e. if we miss some unconfounded sinks (instead, we only lose efficiency, as we do the costly iteration over all possible sets of parents). Therefore, for this test we chose a a second sample that yields a "conservative" test result.

As candidate sink for set \(S\subseteq V\), we pick the node \(X_{i}=\min_{i}\operatorname{mean}(\delta_{i}(X_{S}))\). In fact, we want to know whether the mean of \(\delta_{i}\) is significantly lower than _all_ other means. But we empirically observed that choosing the concatenated \(\delta\)s of all nodes as second sample makes the test reject with very high probability, which would lead our algorithm to falsely assume the existence of an unconfounded sink. Instead, we then pick as second "reference node" \(X_{j}=\min_{j\neq i}\operatorname{mean}(\delta_{j}(X_{Z}))\). We then do the two sample test between \(\delta_{i}(X_{Z})\) and \(\delta_{j}(X_{Z})\). The intuition is that the test will reject the hypothesis of identical means, if \(X_{i}\) is an unconfounded sink but \(X_{j}\) is not.

In the case where we use Proposition 3 to orient edges, we only need to decide whether an not previsouly directed edge \(X_{i}-X_{j}\) needs to be oriented one way, the other way, or not at all. Instead, here the issue lies in the fact that we need to iterate over possible sets of parents of the nodes. Let \(B_{i}\) be the set of nodes that have not been \(m\)-separated from \(X_{i}\) by any test so far. We pick the subset \(Z_{i}=\min_{Z^{\prime}\subseteq B_{i}}\operatorname{mean}(\delta_{i}^{Z^{ \prime}})\), i.e. the set with the lowest mean error. We then conduct the test with \(\delta_{i}(X_{Z_{i}})\) and \(\delta_{j}(X_{Z_{j}})\). If there is a directed edge between them, one of the residuals will be significantly lower than the other.

Just like Montagna et al. [17] we use a cross-validation scheme to generate the residuals, in order to prevent overfitting. We split the dataset into several equally sized, disjoint subsamples. For every residual we fit the regression on all subsamples that don't contain the respective target.

Also, just like in the NoGAM algorithm Montagna et al. [17] we add a pruning step for the directed edges to the end. The idea is to use a feature selection method to remove insignificant edges. Just like Montagna et al. [17], we use the CAM-based pruning step proposed by Buhlmann et al. [36], which fits a generalised additive regression model from the parents to a child and test whether one of theadditive components is significantly non-zero. All parents for which the test rejects this hypothesis are removed.

### Complexity

**Proposition 5**.: _Complexity Let \(n\) be the number of samples and \(d\) the number of observable nodes. Algorithm 2 runs in_

\[\Omega\left((d^{2}-d)\cdot(r(n,d)+s(n,d))\right)\quad\text{ and }\quad\mathcal{O} \left(d^{2}\cdot 2^{d}(r(n,d)+s(n,d))\right),\]

_where \(r(n,d)\) is the time required to solve a regression problem and \(s(n,d)\) is the time for calculating the score. With e.g. kernel-ridge regression and the Stein-estimator, both run in \(\mathcal{O}(n^{3})\)._

Proof.: Algorithm 2 runs its main loop \(d\) times. It first checks for the existence of an unconfounded sink, which involves solving \(2d\) regression problems (including cross-validation prediction) and calculating the score, adding up to \((2d^{2}-d)\) regressions and \(d\) score evaluations. In the worst case, we detect no unconfounded sink and iterate through all subsets of the neighbourhood of a node (which is in the worst case of size \(d-1\)) and for all other nodes in the neighbourhood we solve \(2d\) regression problems and evaluate the score. For each subset we calculate two regression functions, the score and calculate the entries in the Hessian of the log-density, i.e. \(d\cdot 2^{d}\) regressions, \(d\cdot 2^{d-1}\) scores and additionally \(2^{d-1}\) Hessians. If we are unlucky, this node has a directed outgoing edge and we continue with this node (with the same size of nodes). This can happen \(d-1\) times. So we get \((d^{2}-d)\cdot 2^{d}\) regressions and \((d^{2}-d)\cdot 2^{d-1}\) scores and Hessians. In the final pruning step we calculate for every bidirected edge (of which there can be \((d^{2}-d)/2\)) a Hessian for all subsets of the neighbourhoods, which can again be \(2^{d-1}\) subsets. Using the pruning procedure from CAM for the directed edges we also spend at most \(\mathcal{O}(nd^{3})\) steps.

In the best case, we always find an unconfounded sink. Then our algorithm reduces to NoGAM.

## Appendix D Experimental details

In this section, we present the details of our experiments in terms of synthetic data generation and algorithms hyperparameters.

### Synthetic data generation

In this work, we rely on synthetic data to benchmark AdaScore's finite samples performance. For each dataset, we first sample the ground truth graph and then generate the observations according to the causal graph.

Erdos-Renyi graphs.The ground truth graphs are generated according to the Erdos-Renyi model. It allows specifying the number of nodes and the probability of connecting each pair of nodes). In ER graphs, a pair of nodes has the same probability of being connected.

Nonlinear causal mechanisms.Nonlinear causal mechanisms are parametrized by a neural network with random weights. We create a fully connected neural network with one hidden layer with \(10\) units, Parametric ReLU activation function, followed by one normalizing layer before the final fully connected layer. The weights of the neural network are sampled from a standard Gaussian distribution. This strategy for synthetic data generation is commonly adopted in the literature [26; 18; 28; 29; 27].

Linear causal mechanisms.For the linear mechanisms, we define a simple linear regression model predicting the effects from their causes and noise terms, weighted by randomly sampled coefficients. Coefficients are generated as samples from a Uniform distribution supported in the range \([-3,-0.5]\cup[0.5,3]\). We avoid too small coefficients to avoid _close to unfaithful_ datasets Uhler et al. [24].

Noise terms distribution.The noise terms are sampled from a Uniform distribution supported between \(-2\) and \(2\).

Finally, we remark that we standardize the data by their empirical data. This is known to remove shortcuts that allow finding a correct causal order sorting variables by their marginal variance, as in _varsortability_, described in Reisach et al. [32], or sorting variables by the magnitude of their score \(|\partial_{X_{i}}\log p(X)|\), a phenomenon known as _scoresortability_ analyzed by Montagna et al. [18].

### AdaScore hyperparameters

For AdaScore, we set the \(\alpha\) level for the required hypothesis testing at \(0.05\). For the CAM-pruning step, the level is instead set at \(0.001\), the default value of the Godidscover Python implementation of the method, and commonly found in all papers using CAM-pruning for edge selection [15, 16, 17, 36]. For the remaining parameters. The regression hyperparameters for the estimation of the residuals are found via cross-validation during inference: tuning is done minimizing the generalization error on the estimated residuals, without using the performance on the causal graph ground truth. Finally, for the score matching estimation, the regularization coefficients are set to \(0.001\).

### Computer resources

All experiments have been run on an AWS EC2 instance of type p3.2xlarge. These machines contain Intel Xeon E5-2686-v4 processors with 2.3 GHz and 8 virtual cores as well as 61 GB RAM. All experiments can be run within a day.

## Appendix E Additional Experiments

In this section, we provide additional experimental results. All synthetic data has been generated as described in Appendix D.1.

### Non-additive mechanisms

In Figure 1 we have demonstrated the performance of our proposed method on data generated by linear SCMs and non-linear SCMs with additive noise. But Proposition 1 also holds for _any_ faithful distribution generated by an acyclic model. Thus, we employed as mechanism a neural network-based approach similar to the non-linear mechanism described in Appendix D. Instead of adding the noise term, we feed it as additional input into the neural network. Results in this setting are reported in Figure 2. As neither AdaScore nor any of the baseline algorithms has theoretical guarantees for the orientation of edges in this scenario, we report the \(F_{1}\)-score (popular in classification problems) w.r.t. to the existence of an edge, regardless of orientation. Our experiments show that AdaScore can, in general, correctly recover the graph's skeleton in all the scenarios, with an \(F_{1}\) score median between \(1\) and \(\sim 0.75\), respectively for small and large numbers of nodes.

### Sparse graphs

In this section, we present the experiments on sparse Erdos-Renyi graphs where each pair of nodes is connected by an edge with probability \(0.3\). The results are illustrated in Figure 3. For sparse graphs, recovery results are similar to the dense case, with AdaScore generally providing comparable performance to the other methods.

### Increasing number of samples

In the following series of plots we demonstrate the scaling behaviour of our method w.r.t. to the number of samples. Figure 5 shows results with edge probability 0.5 and Figure 4 with 0.3. All graphs contain seven observable nodes. As before we observe that AdaScore performs comparably to other methods. E.g. in Figures 3(a) and 4(b) we can see that the median error AdaScore improves with additional samples and in all plots we see that no other algorithm seems to gain an advantage over AdaScore with increasing sample size.

Figure 3: Empirical results on sparse graphs with different numbers of nodes, on fully observable (no hidden variables) and latent variable models. We report the SHD accuracy (the lower, the better).

Figure 2: Empirical results for non-additive causal mechanisms on sparse graphs with different numbers of nodes, on fully observable (no hidden variables) and latent variable models. We report the \(F_{1}\) score w.r.t. the existence of edges (the higher, the better).

Figure 4: Empirical results on sparse graphs with different numbers of samples and seven nodes, on fully observable (no hidden variables) and latent variable models. We report the SHD accuracy (the lower, the better).

Figure 5: Empirical results on dense graphs with different numbers of samples and seven nodes, on fully observable (no hidden variables) and latent variable models. We report the SHD accuracy (the lower, the better).

### Limitations

In this section, we remark the limitations of our empirical study. It is well known that causal discovery lacks meaningful, multivariate benchmark datasets with known ground truth. For this reason, it is common to rely on synthetically generated datasets. We believe that results on synthetic graphs should be taken with care, as there is no strong reason to believe that they should mirror the benchmarked algorithms' behaviors in real-world settings, where often there is no prior knowledge about the structural causal model underlying available observations.

### NeurIPS Paper Checklist

The checklist is designed to encourage best practices for responsible machine learning research, addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove the checklist: **The papers not including the checklist will be desk rejected.** The checklist should follow the references and precede the (optional) supplemental material. The checklist does NOT count towards the page limit.

Please read the checklist guidelines carefully for information on how to answer these questions. For each question in the checklist:

* You should answer [Yes], [No], or [NA].
* [NA] means either that the question is Not Applicable for that particular paper or the relevant information is Not Available.
* Please provide a short (1-2 sentence) justification right after your answer (even for NA).

**The checklist answers are an integral part of your paper submission.** They are visible to the reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it (after eventual revisions) with the final version of your paper, and its final version will be published with the paper.

The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation. While "[Yes] " is generally preferable to "[No] ", it is perfectly acceptable to answer "[No] " provided a proper justification is given (e.g., "error bars are not reported because it would be too computationally expensive" or "we were unable to find the license for the dataset we used"). In general, answering "[No] " or "[NA] " is not grounds for rejection. While the questions are phrased in a binary way, we acknowledge that the true answer is often more nuanced, so please just use your best judgment and write a justification to elaborate. All supporting evidence can appear either in the main paper or the supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification please point to the section(s) where related material for the question can be found.

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: In the abstract, we claim that we connect the properties of the score function to causal structure learning. In the paper, particularly sections 3 and 4, we present the theoretical results supporting our claim. Further, in the abstract we mention that based on our theory we propose an algorithm for causal discovery from score matching estimation, algorithm that we define in Section 4.3 and we empirically validate in Section 5 and Appendix E. Guidelines:

* The answer NA means that the abstract and introduction do not include the claims made in the paper.
* The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.
* The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.
* It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: The main limitation of our work is on the experimental side: our experiments are limited to synthetic data, which are not an ideal probing ground. Additionally, ourmethod does not provide performance that clearly improves on the existing literature. These limitations of our work are discussed in the discussion of the experiments in Section 5, as well as in the "Limitations" appendix section E.4. Concerning the assumptions required by our method, we thoroughly discuss them in the theoretical sections of the paper, where we define the results that are later used for the definition of the AdaScore. Finally, computational complexity is discussed in Appendix C.3.

Guidelines:

* The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.
* The authors are encouraged to create a separate "Limitations" section in their paper.
* The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.
* The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.
* The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.
* The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.
* If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.
* While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: All our theoretical results make explicit the assumptions for which they are valid. Plus, we in section Appendix B we provide the proofs of our theoretical results. Guidelines:

* The answer NA means that the paper does not include theoretical results.
* All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
* All assumptions should be clearly stated or referenced in the statement of any theorems.
* The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.
* Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.
* Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)?Answer: [Yes] Justification: In Appendix D, we provide all the details to reproduce the data generation of our experiments and the hyperparameters used in AdaScore for our experimental runs. Guidelines:

* The answer NA means that the paper does not include experiments.
* If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.
* If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.
* Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.
* While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: We provide the code for the experiments and the data generation in a zip file. Further, we describe all the details for reproducing our experimental results in Appendix D. Guidelines:

* The answer NA means that paper does not include experiments requiring code.
* Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.

* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: In our experiments section 5, we present all the necessary details on the data generation procedure and a description of the empirical results that are necessary for understanding our findings. Additionally, a comprehensive overview of our experimental design is presented in Appendix D. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: We report all our experimental results in the form of boxplots. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors). * It should be clear whether the error bar is the standard deviation or the standard error of the mean. * It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified. * For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). * If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments?Answer: [Yes] Justification: Details on the computer resources required for the experiments can be found in Appendix D.3. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: We do not believe any of the concerns in the Code of Ethics apply to our work. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: In this work, we present a novel causal discovery method from observational data. We believe there are no specific negative societal impacts, while positive impacts are those generally recognized to causal discovery, as discussed in the Introduction section 1. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. * If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).

11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: We release a causal discovery model from observational data which does not poses such risks. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licensees for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: We use our proprietary assets, as well as public assets available under MIT license, which we correctly cite in our work. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. * If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [Yes] Justification: We release the code for AdaScore, submitted in the form of a zip file containing the necessary documentation for usage. Moreover, an extensive description of the data generation is provided in the paper, as well as a description of the method itself. Guidelines: * The answer NA means that the paper does not release new assets.

* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects**

Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)?

Answer: [NA]

Justification: We do not work with human subjects or crowdsourcing.

Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects**

Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained?

Answer: [NA]

Justification: We do not work with human subjects or crowdsourcing.

Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.