# Visual Pinwheel Centers Act as Geometric Saliency Detectors

 Haixin Zhong\({}^{1,2}\)

hxzhong@fudan.edu.cn

&Mingyi Huang\({}^{1,3}\)

myhuang20@fudan.edu.cn

&Wei P. Dai\({}^{1,5}\)

weidai@fudan.edu.cn

&Haoyu Wang\({}^{3}\)

haoyuwang18@fudan.edu.cn

&Anna Wang Roe\({}^{4}\)

annawang@zju.edu.cn

&Yuguo Yu\({}^{1,2,3,5,*}\)

yuyuguo@fudan.edu.cn

1. Research Institute of Intelligent Complex Systems, Fudan University.

2. State Key Laboratory of Medical Neurobiology and MOE Frontiers Center for Brain Science, Institutes of Brain Science, Fudan University.

3. Institute of Science and Technology for Brain-Inspired Intelligence, Fudan University.

4. MOE Frontier Science Center for Brain Science and Brain-machine Integration, School of Brain Science and Brain Medicine, Key Laboratory of Biomedical Engineering of Ministry of Education, College of Biomedical Engineering and Instrument Science, Zhejiang University.

5. Shanghai Artificial Intelligence Laboratory.

* Corresponding author.

###### Abstract

During natural evolution, the primary visual cortex (V1) of lower mammals typically forms salt-and-pepper organizations, while higher mammals and primates develop pinwheel structures with distinct topological properties. Despite the general belief that V1 neurons primarily serve as edge detectors, the functional advantages of pinwheel structures over salt-and-peppers are not well recognized. To this end, we propose a two-dimensional self-evolving spiking neural network that integrates Hebbian-like plasticity and empirical morphological data. Through extensive exposure to image data, our network evolves from salt-and-peppers to pinwheel structures, with neurons becoming localized bandpass filters responsive to various orientations. This transformation is accompanied by an increase in visual field overlap. Our findings indicate that neurons in pinwheel centers (PCs) respond more effectively to complex spatial textures in natural images, exhibiting quicker responses than those in salt-and-pepper organizations. PCs act as first-order stage processors with heightened sensitivity and reduced latency to intricate contours, while adjacent iso-orientation domains serve as second-order stage processors that refine edge representations for clearer perception. This study presents the first theoretical evidence that pinwheel structures function as crucial detectors of spatial contour saliency in the visual cortex.

## 1 Introduction

The seminal work of Hubel and Wiesel revealed orientation-selective columns in the visual cortex of higher mammals [1, 2]. In higher mammals' primary visual cortex (V1), neurons cluster into "pinwheel" structures around singularities [3], unlike in some mammals like rodents, which display "salt-and-pepper" organizations [4] or mini-columns [5]. While there are established theories and experiments for studying the formation of topological organization maps in the visual cortex [6, 7, 8, 9, 10, 11], the functional significance of pinwheel-like columnar organization remains an unresolved question and is even debated [12, 13].

Sophisticated visual analyses, such as image pattern extraction [14], pattern symmetry [15], material properties [16], and textures [17], are crucial for understanding complex visual inputs. Imaging and electrophysiological studies have shown that iso-orientation domains (IODs) undergo cross-orientation suppression [18], reducing a neuron's response to its preferred orientation when another orientation is also present in the stimulus [13; 19; 20]. This indicates IODs encoding the linear oriented stimuli, which is crucial for detecting edges and contours [21; 22]. Cross-orientation suppression is believed to facilitate the detection of local discontinuities, such as orientation discontinuities [23; 24; 25], leading to perceptual "pop-out" effects and the perception of illusory contours [24; 26; 27]. In contrast, neurons at pinwheel centers (PCs) exhibit greater selectivity for cross-orientation stimuli [12; 13]. This indicates that PCs respond more effectively to multi-orientation patterns, such as pattern symmetry than IODs [12]. This indicates PCs may contribute to encode more complex contour features. However, PCs are less selective but have longer response latency than IODs for stimulus orientation in the hierarchy process within OPMs when it comes to a single stimulus orientation [13; 19; 28]. Some studies indicate that colors [29], textures [30], darks and lights [31], luminance [32], and mirror symmetry [15] play a role in salient to visual processing. Despite these insights, the functional implications of how neurons within IODs and PCs of pinwheels process complex contour stimuli--potentially affecting stimulus salience for both IODs and PCs--from bottom-up visual inputs remain poorly understood, particularly from a temporal-spatial neural dynamics standpoint.

In response to these challenges, our research contributes the following:

* We propose a novel 2D self-evolving spiking neural network (SESNN) model that investigates the spiking mechanisms behind orientation preference maps (OPMs), spanning from salt-and-pepper organizations in mice to pinwheel structures in cats and macaques. The SESNN uniquely produces sparse codes through local synaptic plasticity during natural image learning, establishing a new benchmark for neural coding strategies.
* PCs act as first-stage processors, detecting natural images and initiating spiking waves to neighboring IODs, which then process as second-stage neurons. This indicates that early processing involves complex contours, not just edge detection.
* PCs react faster to a variety of orientation features than IODs, indicating their function in detecting complex orientations and serving as geometric saliency detectors. This suggests PCs have an evolutionary advantage due to self-organized pinwheel structures, which improves their ability to process complex contours.

## 2 Results

### Visual overlap underlying pinwheels emergence

Our SESNN model generates diverse OPMs, from salt-and-peppers to pinwheel structures, by adjusting the visual overlap metric \(\varepsilon\). This metric, crucial for the variety of visual topologies across species, is shown in Fig. 0(a) to produce pinwheel structures at high overlap, akin to those in cats and macaques, while low overlap results in salt-and-pepper organizations, typical of mice or rats. High overlap also enables cortical neurons to sample natural scenes more frequently, aiding in generating high-resolution images during decoding [7; 33].

Fig. 0(a) shows how visual input overlap levels from 9 to 15 pixels affect V1 orientation selectivity maps in the model. The top panel illustrates a higher overlap (15 pixels), and the middle, a lower overlap (12 pixels). This comparison reveals the impact of stimulus overlap on pinwheel density and layout in the visual cortex. Below the threshold (10 pixels in our case), salt-and-pepper patterns form, as the bottom panel indicates. Thus, 9 pixels of overlap are excluded from pinwheel analysis, as shown in Fig. 0(b)-0.

We quantitatively analyze the OPMs shown in Fig. 0(a) with several metrics [7; 34]:

**Pinwheel counts**, defined as the number of PCs, can be measured by 2D fast Fourier transform [35], which are located at the intersection of the real and imaginary components that equal 0 [34]. It exhibits a decreasing trend as the visual input overlap increases (illustrated in Fig. 0(b)), suggesting that a greater overlap in the visual field may lead to a reduction in the number of discrete pinwheel structures.

**The nearest-neighbor pinwheel distance (NNPD)** in millimeter (mm) unit is defined as the distance between the two nearest PCs. The increasing trend of visual input overlap expands the distance between neighboring pinwheels (Fig. 1c).

**The size of hypercolumns** (mm) is defined with periodicity measured by 2D fast Fourier transform and also increases with the visual input overlap (shown in Fig. 1d). This paper does not account for left- and right-eye dominance columns, so the hypercolumn size is defined as the full 180\({}^{\circ}\) cycle of repeating column spacing (\(\Lambda\)) (mm).

It's noteworthy that pinwheel density is not included as a metric in our analysis. This omission is because the observed pinwheel density, irrespective of the hypercolumn size, approaches \(\pi\) pinwheels/\(\Lambda^{2}\), conforming to topological constraints [34; 35].

Our findings emphasize the importance of overlap degrees (Fig. 1a). Greater overlap (e.g., \(\varepsilon_{1}=15\) pixels) fosters stronger local clustering, leading to larger hypercolumn sizes, fewer pinwheels, and longer NNPDs, versus lower overlap (e.g., \(\varepsilon_{2}=12\) pixels). Minimal overlap (e.g., \(\varepsilon_{3}=9\) pixels), yields weak clustering, resembling salt-and-pepper organizations. This suggests that shared input among V1 neurons significantly influences OPM and salt-and-pepper formation. We obtain the anatomical data overlap using Eq. 3 and observe a strong positive correlation (\(R^{2}=0.97\)) between the SESNN model and species' visual RF overlaps (mouse, cat, macaque) (Fig. 1e). This relationship highlights the overlap index's key role in spatial organization within orientation maps. The model's predictions on IOD sizes and visual field extent (Fig. 1f) align with empirical data [7], confirming the SESNN model's robustness in simulating neuroanatomical organization and the biological development of orientation maps.

### Spatial-temporal distributed spiking waves propagate within pinwheels

V1 neurons stimulated by natural images primarily fire within pinwheel structures, particularly within and around PCs (Fig. 2a-b). This pattern is especially pronounced in higher mammals with large IODs, such as macaques and cats.

Figure 1: Receptive field (RF) visual overlaps underlying the emergence of OPM and the salt-and-peppers are revealed via our SESNN model. **a**. Modifying the overlap parameter (\(\varepsilon\)) among neighboring neurons receiving (\(16\times 16\) pixels) visual inputs from natural images influences the dimensions (e.g., **b**. Pinwheel counts, **c**. Nearest-neighbor pinwheel distance, **d**. Hypercolumn size) of pinwheel structures and salt-and-pepper organizations. (Lines: mean. Shaded area: SD.) **e**. Comparing the SESNN model overlap percentage (\(\frac{\varepsilon}{s_{\text{RF}}}\times 100\%\)) with actual anatomical data overlap percentages (\(\varepsilon^{\prime}_{\text{percentage}}\)) in various species (mice, cats, and macaques). **f**. Relationship between the IOD size and the extent of the visual field in anatomical data (mice, cats, and macaques).

We define the response onset latency as 1 ms for the initial discharge from pinwheel structures, with subsequent firings occurring at 2 ms, based on a 1 ms time unit. Stimulated by natural images, the discharges start at the PCs and exhibit pronounced diffusion within the IODs sequentially, depending on their distance from the center, as suggested in Fig. 2c.

### Visual bottom-up saliency detection: functional role of pinwheel in geometric encoding

In this section, we investigate whether pinwheel structures respond distinctly to salient features in input images. The ground truth boundary from the BSDS 500 dataset [36] used as binary input represents geometric complexity (edges and curves) (Fig. 3a). The complexity is measured by calculating the local pixel entropy using sliding windows, with a 15x15 pixel neighborhood to assess pixel value dispersion in the binary images. The computation adheres to the following equation:

\[H(i,j)=-\sum_{k=0}^{L-1}p(m_{k})\log_{2}p(m_{k}),\] (1)

where \(H(i,j)\) denotes the entropy at pixel position \((i,j)\) in the entropy map, \(L\) the count of distinct gray levels within the local neighborhood around pixel \((i,j)\), and \(m_{k}\) the \(k\)th gray level within this specified neighborhood. A large entropy value reflects great unpredictability or complexity in the pixel values, signifying a highly variable pixel value distribution. Conversely, a low entropy value indicates a high degree of predictability, less variation, and reduced complexity in the contours of pixel values. In addition, the saliency map of images is generated based on the classical methodology [37].

Furthermore, we propose a bimodal ratio analysis to compute the orientation bimodal ratio (OBR) to indicate a neuron's orientation tuning curve as either unimodal (single peak) or perfectly bimodal (two peaks of equal strength). This analysis focuses on identifying the peaks in the orientation tuning curve and quantifying their relative strengths.

\[OBR=\frac{2\cdot\min(R_{1},R_{2})}{R_{1}+R_{2}},\] (2)

Figure 2: Spatial-temporal response pattern within pinwheels. **a**. This figure displays the neuronal responses on OPM with a large IOD in a pinwheel structure. The neurons that fire at time \(t_{0}\) are shown as large black dots at PC, and they expand towards the periphery at time \(t_{0}\)+1, also denoted as large black dots. The other small dots represent resting neurons. **b**. Distance between firing neurons and the PC at time \(t_{0}\) and \(t_{0}\)+1. **c**. This panel shows the response onset latency of neurons and the mean distance (\(\pm\) SD) between these neurons within a pinwheel. The distance is measured as the Euclidean distance within a 2D grid, simulating the structure of a 2D V1 area. (Significance: ***p<0.001, Mann-Whitney U test.)

where \(R_{1}\) and \(R_{2}\) represent the normalized firing rates corresponding to the strengths of the two most pronounced peaks in the orientation tuning curve. The OBR ranges from 0, denoting unimodality, to 1, indicating perfect bimodality in the neuron's orientation tuning.

A positive correlation is observed between the saliency map and the geometrical complexity of the BSDS500 dataset (Fig. 3b), demonstrating that higher geometrical complexity correlates with increased saliency. Significantly, in response to the stimulus shown in the BSDS500 image (Fig. 3a), pinwheel structures primarily activate in areas of high contour complexity (regions with the highest saliency in this binary image), which is a response pattern have not been observed in salt-and-peppers (Fig. 3c).

To confirm the disparity in contour complexity responses between pinwheel and salt-and-pepper organizations, we design a star-like binary input (depicted in Fig. 4a), including four identical entities to negate the impact of neuronal positioning within the SESNN model. This approach reaffirms the saliency-complexity correlation (Fig. 4b) and the priority of pinwheel activation over salt-and-peppers in response to heightened complexity (Fig. 4c).

Findings show that PCs exhibit enhanced saliency detection and significantly faster response times than IODs, indicating that PCs respond more quickly and sensitively to geometrically complex stimuli, while IODs are slower and react to simpler geometrical stimuli (see Fig. 4d). Both saliency and latency measurements are normalized to a 0-1 scale for comparison.

The enhanced saliency detection of PCs is due to the complex orientation preference in RFs. As addressed in Fig. 4e, the ordinate represents the OBR, reflecting that neurons near PC generally exhibit bimodal orientation tuning curves with near-equal peak strengths while there is a primary peak and a secondary peak at a relatively far position from PC (\(x=2\)). And the secondary peak is nearly absent at the IODs level (\(x=3\)), leading to an OBR close to 0. Salt-and-peppers, however, show less variation, maintaining a consistent OBR.

In conclusion, PCs demonstrate selectivity for more intricate orientations. This is experimentally supported by [13, 38], who suggest that PCs are particularly sensitive to specific geometric configurations, such as T junctions. Characterized by multiple orientations and an OBR nearing 1 (Fig. 4e), these neurons tend to initiate action potentials in response to complex orientations. Consequently,

Figure 3: Pinwheel structures in V1 exhibit geometric properties. **a**. A BSDS 500 grayscale image displays boundaries, saliency, and entropy maps. **b**. Natural images show a positive correlation between saliency and entropy. **c**. Neuronal response onset latency from pinwheels and salt-and-peppers relates to structural complexity, measured by local pixel entropy. (Data: mean \(\pm\) SD, significance: ****p<0.001, Welch’s t-test.)

this leads to pinwheels being the first to respond. In contrast, neurons in salt-and-peppers do not exhibit a similar responsiveness to complex orientations as observed in pinwheels.

## 3 Methods

### The architecture of SESNN model

Our SESNN model is a two-dimensional network of excitatory (E-) and inhibitory (I-) leaky integrate-and-fire neurons (LIF) (5), stimulated by whitened natural images to mimic the LGN's functions of contrast normalization and edge enhancement without complex modeling [43, 44, 45]. We use 160 whitened natural images as the training dataset, normalized to zero mean and uniform variance, derived from 20 base images (512x512 pixels) [45, 46]. To capture orientation details, each of the base images undergoes a 90-degree clockwise rotation and flip, creating 8 variations per original.

The configuration features E- and I- neurons in recurrent networks with periodic boundary conditions (PBCs) (Fig. 5b), simulating a continuous 2D cortical surface. The neural connectivity at initialization is depicted in Fig. 5c (see Eq. 11). Moreover, the connection strengths in the well-trained model align closely with the experimental finding ([47]). Under natural image stimuli, the SESNN forms single neuron RFs and population-level pinwheel structures in the OPM (Fig. 5e-f). To validate the model, we compare its evolution from randomness to organized states against biological data from macaque pinwheel structures and a baseline model [42], using metrics such as pinwheel density (pinwheels/ \(\Lambda^{2}\)), NNPD (mm), and hypercolumn size (mm) [7, 34, 35] (Fig. 5f and Table 1).

\begin{table}
\begin{tabular}{l l l l} \hline \hline Metric & E-I baseline & SESNN model & Macaque \\ \hline Pinwheel density (pinwheels/\(\Lambda^{2}\)) & \(\sim 2.941\) & \(3.175\pm 0.397\) & \(\sim 3.327\) \\ NNPD (mm) & N/A & \(0.277\pm 0.043\) & \(\sim 0.242\) \\ Hypercolumn size (mm) & N/A & \(0.839\pm 0.054\) & \(\sim 0.760\) \\ \hline \hline \end{tabular}
\end{table}
Table 1: SESNN pinwheels (mean \(\pm\) SD) vs. macaque pinwheels.

Figure 4: Geometric properties emergence in PCs of V1 on star-like patterns. **a**. We introduce artificial star-like patterns to assess neural response to complexity. **b**. Star-like images show a link between saliency and entropy. **c**. Neuron response times in PCs and salt-and-peppers reduce with lower entropy. **d**. The analysis compares PCs and IODs for saliency and response to star-like patterns; the inset details saliency and latency. **e**. OBR varies across cortical distance; the red line marks pinwheels, and the black line, salt-and-peppers (an arbitrary point for salt-and-peppers). (Data: mean \(\pm\) SD, significance: **p\(<\)0.01, ***p\(<\)0.001, ***p\(<\)0.0001, Welch’s t-test.)

### Experiment-data-justified overlapping visual fields among nearby neurons

In each trial, E-neuron processes 100 different 16\(\times\)16 patches for 100 milliseconds each, randomly selected from the training dataset to serve as RFs (see Fig. 5a middle and right panels). It is assumed that these visual inputs overlap on the retina (Fig. 5a, middle panel and its inset). To reflect biological conditions, we perform a statistical analysis based on data from cats, macaques, and mice (Table 2), calculating average overlaps of 99.90% for cats, 99.98% for macaques, and 97.23% for mice using (Eq. 3). These results closely align with our SESNN model's configurations (refer to Fig. 1e). RF size in V1 is more related to resolution than orientation map formation. In macaque V1, RF size increases more than tenfold from fovea to periphery, while orientation map properties show little variation [48; 49]. Our study does not focus on RF size variations across the retina, as we expect minimal effects from these shifts across species, provided the overlap remains constant. Since the fovea is key for detailed visual information, we use V1 RFs in the area centralis to modeling.

We propose the visual input overlap metric \(\varepsilon^{\prime}_{\text{percentage}}\), which is defined as follows:

\[\varepsilon^{\prime}_{\text{percentage}}=\frac{\sqrt{\rho_{\text{V1}}S_{\text{ unit}}}-\frac{L_{\text{win}}M^{-1}}{s_{\text{RF}}^{\prime}}}{\sqrt{\rho_{ \text{V1}}S_{\text{unit}}}-1}\times 100\%\] (3)

where \(S_{\text{unit}}\) represents the unit cortical area mm\({}^{2}\), \(s_{\text{RF}}^{\prime}\) denotes the size of the RF in V1 with unit in degrees, \(\rho_{\text{V1}}\) represents the density of neurons in V1, \(L_{\text{unit}}\) represents the unit of cortical spacing length in unit of mm, and \(M\) refers to the cortical magnification factor (CMF) (mm/degree). We consider only an effective cortical layer composed of output neurons. This is because the apparent overlap within a vertical cortical column primarily contributes to intermediary processing stages for the same input. Therefore, such overlaps should not be conflated with overlaps in the input space.

### Neural dynamics

E-neurons receive stimuli from natural images as well as noise \(\mathcal{N}(0,0.04)\) from other brain areas (noise term). I-neurons indirectly receive natural image stimuli by adjusting E-neurons. The neural spiking dynamics are modeled using biologically inspired LIF neurons, incorporating refractory

Figure 5: Architecture of proposed SESNN model. **a**. The SESNN model comprises 4,900 E- and 1,225 I- neurons [39; 40; 41]. It processes 160 natural images (100 patches each), presenting each 512\(\times\)512 pixel patch to E-neurons for 100 ms with input overlap. The Feed-forward and E-E connections adhere to the Hebbian-Oja (HO) rule; others follow the Correlation Measuring (CM) rule. **b**. E- and I-neurons are spatially arranged with periodic boundaries, sharing coordinates with connected boundaries as per diagram arrows. Identical connections are marked by same-color arrows. **c**. Initial weights are Gaussian distributed. **d**. Post-training connection strengths are depicted, with medians in red. **e**. RF emerges after training. **f**. Post-training spatial organization is compared among the SESNN model’s OPM, macaque V1, and an SNN-based model [42], with color bars for orientation and a 1 mm scale bar on the cortical surface.

periods and adaptive firing thresholds [55]. The neural dynamics are iteratively formulated as follows:

\[u_{i}^{\rm(K)}(t+1)=u_{i}^{\rm(K)}(t)e^{-\frac{n}{\tau(k)}}+h_{\rm K}(i)\sum_{j} \text{FF}_{ij}^{\rm(image\to E)}X_{j}\] (4)

\[+\sum_{\rm K^{*}}\sum_{j}\beta_{ij}^{\rm(K^{*}\to K)}\cdot W_{ij}^{\rm(K^{*}\to K )}\cdot z_{j}^{\rm(K^{*})}(t)+\rm noise,\]

\[h_{\rm K}(i)=\begin{cases}1,&\text{if $i$ is an E-neuron ID},\\ 0,&\text{if $i$ is an I-neuron ID},\end{cases}\] (5)

\[\Delta\theta_{i}^{\rm(K)}\propto p_{i}(z_{i}^{\rm(K^{*})}=1)-p_{i}^{\rm(K)},\] (6)

where \(i=1,2,\ldots,N\rm th\) (the neuron IDs of E-neurons and I-neurons).

In neural dynamics equation, \(u_{i}^{\rm(K)}\left(t\right)\) denotes the membrane potential of neuron \(i\) at time \(t\), applicable to neurons of class \(\rm K\), which includes E- and I- neuron groups. The membrane time constant, symbolized by \(\tau\) in the resistor-capacitor circuit, governs the decay rate of the membrane potential in individual neurons. Notably, inhibitory neurons are configured to fire more rapidly than excitatory neurons [44; 56]. This setup reduces reconstruction error and hastens system convergence, leading to a more efficient and accurate representation of input stimuli. See the section A.2 for detailed neural dynamics.

### Hebbian Learning in SESNN

The learning rules consist of the HO rule [43] for input weight adjustments and the CM rule [44; 45] for intra-network weight changes (Fig. 5a-c). These facilitate adaptive synaptic weight adjustment based on firing pattern correlations, emulating a key learning mechanism in biological neural networks.

The formula for these adjustments is given by:

\[\text{HO}:\ \Delta W_{ij}^{\rm(K^{*}\to K)}\propto y_{i}x_{j}-y_{i}^{2 }W_{ij}^{\rm(K^{*}\to K)},\] (7)

\[\text{CM}:\ \Delta W_{ij}^{\rm(K^{*}\to K)}\propto y_{i}x_{j}-\left\langle y_{i} \right\rangle\left\langle x_{j}\right\rangle\left(1+W_{ij}^{\rm(K^{*}\to K)} \right),\] (8)

where \(x\), \(y\) denote the spike rates of presynaptic and postsynaptic neurons, respectively, with \(\left\langle\cdot\right\rangle\) denotes the lifetime average. After each stimulus presentation of 100 ms, we calculate the network's neuronal instantaneous spike rates using exponential moving averages (EMAs), which aggregate spikes over time to reflect recent activity (see section A.1). Lifetime averages, also computed as EMAs, are crucial for homeostatic stability, helping to modulate neuronal properties or synaptic strengths for consistent activity. See the section A.2 for the hyperparameters.

Our SESNN model reflects experimental findings [57; 47] by representing V1 pyramidal neurons with weaker synaptic strengths, essential for preventing over-excitation and maintaining neural balance. We apply the HO rule [43] to E-E connections with a normalization factor to keep synaptic weights between 0 and 1, while stronger lateral E-I connections under the CM rule lack this normalization [45; 44]. Post-training synaptic strengths are depicted in Fig. 5d. Stabilizing neural network training requires careful learning rate adjustment. A slower rate for E-E connections compared to others is crucial to prevent E-neuron over-excitation, aligning with empirical data [57; 47; 58].

The HO and CM rules facilitate LTP and LTD mechanisms, common in rate learning rules that do not require precise spike timing. We selected these rules for their ease of tuning and ability to stabilize recurrent excitation.

\begin{table}
\begin{tabular}{l c c c} \hline \hline (a)Species & (b)V1 neuron density & (c)V1 RF size & (d)Peak CMF \\ \hline Cat & \(\sim 99,200\)[33] & \(\sim 1.0\)[50] & \(\sim 1.90\)[51] \\ Macaque & \(\sim 243,000\)[33] & \(\sim 0.2\)[52] & \(\sim 18.18\)[52] \\ Mouse & \(\sim 86,600\)[33] & \(\sim 4.0\)[53] & \(\sim 0.03\)[54] \\ \hline \hline \end{tabular}
\end{table}
Table 2: Comparative anatomical data of the retina and V1 across three species. **a**. This table includes three diverse species, encompassing both primates (e.g., macaques) and non-primates (e.g., mice and cats). **b**. V1 neuron density (neurons/mm\({}^{2}\)) within 2D surface. **c**. Size of V1 RF in area centralis (deg). **d**. Peak CMF (mm/deg) of V1 in area centralis.

Related works

**Functional roles of pinwheel structure can be revealed by SESNN model** The classical self-organizing map model [8] and other computational approaches like on-off models [6; 7; 9; 59] and related ANNs [10; 60; 61] lack the dynamic and temporal fidelity needed to realistically simulate the emergence of pinwheel structures in the visual cortex. To address these shortcomings, we propose the novel SESNN model, integrating retinotopy data [33; 50; 52; 53], detailed morphological data [62; 63; 64], and CMF [51; 52; 54] to enhance biological fidelity. The SESNN model effectively simulates macaque cortical organization and pinwheel development within OPMs (Fig. 5f). Furthermore, our investigations reveal that the degree of overlap--reflecting similar feed-forward inputs from identical RGCs to neighboring neurons--positively correlates with the retino-cortical mapping ratio [6], aiding in distinguishing between different V1 organizational patterns.

**PCs and IODs in neural processing hierarchies** Our findings show that PCs and IODs exhibit distinct neural activity waves, leading to varied responses to contour complexity from spatial-temporal dynamics: PCs react first to complex contours, having more multi-orientation selective neurons (Fig. 4e, \(x=1\)) before activity spreads to IODs, which process simpler edges (Fig. 4d and e, \(x=3\)). PCs display a stronger correlation with contour saliency, indicating a heightened role in processing visual stimuli over IODs. In rodents with salt-and-pepper organizations, contour saliency is less pronounced (Figs. 3c and 4c). While PCs are thought to indicate higher-order processing due to delayed response [13; 28], this is likely due to the nature of the stimuli. Studies reveal IODs show cross-orientation suppression under complex stimuli [12], unlike PCs with broader tuning. The SESNN model illustrates a preference for complex stimuli in PCs and simple stimuli in IODs, with activity propagating from PCs to IODs upon encountering complex contours (Fig. 4d and e).

**PCs as geometric saliency detectors** The SESNN model reveals PCs have broader orientation tuning and less selectivity for complex contours, unlike IODs, which show sharper tuning and cross-orientation suppression, preferring simpler edges (\(x=3\) in Fig. 4e) [12; 13; 19; 58; 65; 66; 67]. PCs' excitation leads to reduced cross-orientation suppression. With binary input, PCs correlate more positively with contour complexity than IODs (Figs. 3b and 4b), making them more salient in processing visual stimuli. This differs from rodents with salt-and-pepper organizations that lack distinct contour complexity saliency (Figs. 3c and 4c). Prior studies [12; 13; 28] suggest PCs have delayed response latency, indicative of higher-order processing. This arises from using drifting grating stimuli that activate IODs more readily. Koch et al. [12] note that IODs show cross-orientation suppression under complex stimuli, narrowing their tuning, unlike PCs. However, these studies omit temporal neural data within pinwheel structures. The SESNN model supports physiological findings that IODs and PCs favor single and complex orientation stimuli, respectively.

## 5 Conclusion and limitations

The advantages of pinwheel structures in visual representation and encoding are not fully understood. To address this, we develop a two-dimensional SESNN model that incorporates Hebbian-like plasticity and empirical morphological data. This model evolves to function as localized, bandpass filters, enhancing its responsiveness to a range of orientations and complex spatial textures in natural images. Our findings reveal that neurons within pinwheel structures respond more effectively to these textures, with stronger and quicker reactions than those in salt-and-pepper configurations. Specifically, PCs act as first-order stage processors with heightened sensitivity and reduced response latency to intricate contours, while IODs function as second-stage processors, refining edge representation for greater clarity. This advanced processing capability of pinwheel structures, particularly in detecting spatial contour saliency, not only deepens our understanding of visual processing in higher mammals but may also inform new strategies for visual saliency algorithms in computational models.

Using sliding windows, local entropy assesses variation and complexity in spatial distributions by capturing local intensity changes, indirectly reflecting geometric complexity through edges, corners, and patterns. Since this method cannot directly measure geometric shapes, we verify the use of the Ramer-Douglas-Peucker algorithm to approximate and directly measure geometric structures (refer to section A.5) [68]. This algorithm simplifies shape contours by reducing vertices while preserving the overall form. The resulting polygon will allow us to calculate the distribution of edge lengths and angles, with geometric entropy defined as the sum of these entropy values. In future studies, we will utilize the Ramer-Douglas-Peucker algorithm to enhance our geometric analysis by identifyingand measuring the complexity of specific structural features, such as junctions, sharp corners, and textures, which are essential in complex visual scenes.

## Acknowledgments

We gratefully acknowledge the support from the Science and Technology Innovation 2030 - Brain Science and Brain-Inspired Intelligence Project (2021ZD0201301), the National Natural Science Foundation of China (U20A20221, 12201125, 12072113), the Shanghai Municipal Science and Technology Committee of Shanghai outstanding academic leaders plan (21XD1400400), the Yang Fan plan (22YF1403300), and the China Postdoctoral Science Foundation (2023M740724).

## References

* Hubel and Wiesel [1962] D. H. Hubel and T. N. Wiesel. Receptive fields, binocular interaction and functional architecture in the cat's visual cortex. _The Journal of Physiology_, 160(1):106-154, 1962. ISSN 1469-7793. doi: 10.1113/physiol.1962.sp006837. URL https://onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.1962.sp006837.
* Hubel and Wiesel [1974] David H. Hubel and Torsten N. Wiesel. Sequence regularity and geometry of orientation columns in the monkey striate cortex. _Journal of Comparative Neurology_, 158(3):267-293, 1974. ISSN 1096-9861. doi: 10.1002/cne.901580304. URL https://onlinelibrary.wiley.com/doi/abs/10.1002/cne.901580304.
* Bonhoeffer and Grinvald [1991] Tobias Bonhoeffer and Amiram Grinvald. Iso-orientation domains in cat visual cortex are arranged in pinwheel-like patterns. _Nature_, 353(6343):429-431, October 1991. ISSN 1476-4687. doi: 10.1038/353429a0. URL https://www.nature.com/articles/353429a0.
* Girman et al. [1999] Sergej V. Girman, Yves Sauve, and Raymond D. Lund. Receptive Field Properties of Single Neurons in Rat Primary Visual Cortex. _Journal of Neurophysiology_, 82(1):301-311, July 1999. ISSN 0022-3077. doi: 10.1152/jn.1999.82.1.301. URL https://journals.physiology.org/doi/full/10.1152/jn.1999.82.1.301.
* Ringach et al. [2016] Dario L. Ringach, Patrick J. Mineault, Elaine Tring, Nicholas D. Olivas, Pablo Garcia-Junco-Clemente, and Joshua T. Trachtenberg. Spatial clustering of tuning in mouse primary visual cortex. _Nature Communications_, 7(1):12270, August 2016. ISSN 2041-1723. doi: 10.1038/ncomms12270. URL https://www.nature.com/articles/ncomms12270.
* Jang et al. [2020] Jaeson Jang, Min Song, and Se-Bum Paik. Retino-Cortical Mapping Ratio Predicts Columnar and Salt-and-Pepper Organization in Mammalian Visual Cortex. _Cell Reports_, 30(10):3270-3279.e3, March 2020. ISSN 2211-1247. doi: 10.1016/j.crep.2020.02.038. URL https://www.cell.com/cell-reports/abstract/S2211-1247(20)30199-6.
* Najafian et al. [2022] Sohrab Najafian, Erin Koch, Kai Lun Teh, Jianzhong Jin, Hamed Rahimi-Nasrabadi, Qasim Zaidi, Jens Kremkow, and Jose-Manuel Alonso. A theory of cortical map formation in the visual brain. _Nature Communications_, 13(1):2303, April 2022. ISSN 2041-1723. doi: 10.1038/s41467-022-29433-y. URL https://www.nature.com/articles/s41467-022-29433-y.
* Kohonen [1982] Teuvo Kohonen. Self-organized formation of topologically correct feature maps. _Biological Cybernetics_, 43(1):59-69, January 1982. ISSN 1432-0770. doi: 10.1007/BF00337288. URL https://doi.org/10.1007/BF00337288.
* Miller [1994] K. D. Miller. A model for the development of simple cell receptive fields and the ordered arrangement of orientation columns through activity-dependent competition between ON- and OFF-center inputs. _Journal of Neuroscience_, 14(1):409-441, January 1994. ISSN 0270-6474, 1529-2401. doi: 10.1523/JNEUROSCI.14-01-00409.1994. URL https://www.jneurosci.org/content/14/1/409.
* Chizhov and Graham [2021] Anton V. Chizhov and Lyle J. Graham. A strategy for mapping biophysical to abstract neuronal network models applied to primary visual cortex. _PLOS Computational Biology_, 17(8):e1009007, August 2021. ISSN 1553-7358. doi: 10.1371/journal.pcbi.1009007. URL https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009007.
* Margalit et al. [2024] Eshed Margalit, Hyodong Lee, Dawn Finzi, James J. DiCarlo, Kalanit Grill-Spector, and Daniel L. K. Yamins. A unifying framework for functional organization in early and higher ventral visual cortex. _Neuron_, 112(14):2435-2451.e7, July 2024. ISSN 0896-6273. doi: 10.1016/j.neuron.2024.04.018. URL https://www.cell.com/neuron/abstract/S0896-6273(24)00279-4.
* Koch et al. [2016] Erin Koch, Jianzhong Jin, Jose M. Alonso, and Qasim Zaidi. Functional implications of orientation maps in primary visual cortex. _Nature Communications_, 7(1):13529, November 2016. ISSN 2041-1723. doi: 10.1038/ncomms13529. URL https://www.nature.com/articles/ncomms13529.

* Li et al. [2019] Ming Li, Xue Mei Song, Tao Xu, Dewen Hu, Anna Wang Roe, and Chao-Yi Li. Subdomains within orientation columns of primary visual cortex. _Science Advances_, 5(6):eaaw0807, June 2019. doi: 10.1126/sciadv.aaw0807. URL https://www.science.org/doi/full/10.1126/sciadv.aaw0807.
* Freeman et al. [2013] Jeremy Freeman, Corey M. Ziemba, David J. Heeger, Eero P. Simoncelli, and J. Anthony Movshon. A functional and perceptual signature of the second visual area in primates. _Nature Neuroscience_, 16(7):974-981, July 2013. ISSN 1546-1726. doi: 10.1038/nn.3402. URL https://www.nature.com/articles/nn.3402.
* Cohen and Zaidi [2013] Elias H. Cohen and Qasim Zaidi. Symmetry in context: Salience of mirror symmetry in natural patterns. _Journal of Vision_, 13(6):22, May 2013. ISSN 1534-7362. doi: 10.1167/13.6.22. URL https://doi.org/10.1167/13.6.22.
* Okazawa et al. [2015] Gouki Okazawa, Sutohiro Tajima, and Hidehiko Komatsu. Image statistics underlying natural texture selectivity of neurons in macaque V4. _Proceedings of the National Academy of Sciences_, 112(4):E351-E360, January 2015. doi: 10.1073/pnas.1415146112. URL https://www.pnas.org/doi/full/10.1073/pnas.1415146112.
* Li and Zaidi [2004] Andrea Li and Qasim Zaidi. Three-dimensional shape from non-homogeneous textures: Carved and stretched surfaces. _Journal of Vision_, 4(10):3, October 2004. ISSN 1534-7362. doi: 10.1167/4.10.3. URL https://doi.org/10.1167/4.10.3.
* Tao et al. [2015] Xu Tao, Yan Hong-Mei, Song Xue-Mei, Ming Li, and Yong-Jie Li. Silent suppressive surrounds and optimal spatial frequencies of single neurons in cat V1. _Neuroscience Letters_, 597:104-110, June 2015. ISSN 0304-3940. doi: 10.1016/j.neulet.2015.04.039. URL https://www.sciencedirect.com/science/article/pii/S0304394015003389.
* Nauhaus et al. [2008] Ian Nauhaus, Andrea Benucci, Matteo Carandini, and Dario L. Ringach. Neuronal Selectivity and Local Map Structure in Visual Cortex. _Neuron_, 57(5):673-679, March 2008. ISSN 0896-6273. doi: 10.1016/j.neuron.2008.01.020. URL https://www.cell.com/neuron/abstract/S0896-6273(08)00105-0.
* Priebe and Ferster [2006] Nicholas J. Priebe and David Ferster. Mechanisms underlying cross-orientation suppression in cat visual cortex. _Nature Neuroscience_, 9(4):552-561, April 2006. ISSN 1546-1726. doi: 10.1038/nn1660. URL https://www.nature.com/articles/nn1660. Publisher: Nature Publishing Group.
* Field et al. [1993] David J. Field, Anthony Hayes, and Robert F. Hess. Contour integration by the human visual system: Evidence for a local "association field". _Vision Research_, 33(2):173-193, January 1993. ISSN 0042-6989. doi: 10.1016/0042-6989(93)90156-Q. URL https://www.sciencedirect.com/science/article/pii/0042698993901560.
* Goris et al. [2015] Robbe L. T. Goris, Eero P. Simoncelli, and J. Anthony Movshon. Origin and Function of Tuning Diversity in Macaque Visual Cortex. _Neuron_, 88(4):819-831, November 2015. ISSN 1097-4199. doi: 10.1016/j.neuron.2015.10.009.
* Shen et al. [2007] Zhi-Ming Shen, Wei-Feng Xu, and Chao-Yi Li. Cue-invariant detection of centre-surround discontinuity by V1 neurons in awake macaque monkey. _The Journal of Physiology_, 583(Pt 2):581-592, September 2007. ISSN 0022-3751. doi: 10.1113/jphysiol.2007.130294. URL https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2277020/.
* Sllito et al. [1995] Adam M. Sllito, Kenneth L. Grieve, Helen E. Jones, Javier Cudeiro, and Justin Davls. Visual cortical mechanisms detecting focal orientation discontinuities. _Nature_, 378(6556):492-496, November 1995. ISSN 1476-4687. doi: 10.1038/378492a0. URL https://www.nature.com/articles/378492a0.
* Xu et al. [2013] Tao Xu, Ling Wang, Xue-Mei Song, and Chao-Yi Li. The Detection of Orientation Continuity and Discontinuity by Cat V1 Neurons. _PLoS ONE_, 8(11):e79723, November 2013. ISSN 1932-6203. doi: 10.1371/journal.pone.0079723. URL https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3836789/.
* Nothdurft et al. [1999] H. C. Nothdurft, J. L. Gallant, and D. C. Van Essen. Response modulation by texture surround in primate area V1: correlates of "popout" under anesthesia. _Visual Neuroscience_, 16(1):15-34, 1999. ISSN 0952-5238. doi: 10.1017/s0952523899156189.
* von der Heydt and Peterhans [1989] R. von der Heydt and E. Peterhans. Mechanisms of contour perception in monkey visual cortex. I. Lines of pattern discontinuity. _The Journal of Neuroscience: The Official Journal of the Society for Neuroscience_, 9(5):1731-1748, May 1989. ISSN 0270-6474. doi: 10.1523/JNEUROSCI.09-05-01731.1989.
* Song et al. [2020] Xue Mei Song, Ming Li, Tao Xu, Dewen Hu, and Anna Wang Roe. Precise Targeting of Single Microelectrodes to Orientation Pinwheel Centers. _Bio-protocol_, 10(11):e3643, June 2020. ISSN 2331-8325. doi: 10.21769/BioProtocol.3643. URL https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7842334/.
* Wool et al. [2015] Lauren E. Wool, Stanley J. Komban, Jens Kremkow, Michael Jansen, Xiaobing Li, Jose-Manuel Alonso, and Qasim Zaidi. Salience of unique hues and implications for color theory. _Journal of Vision_, 15(2):10, February 2015. ISSN 1534-7362. doi: 10.1167/15.2.10.

* Knierim and van Essen [1992] J. J. Knierim and D. C. van Essen. Neuronal responses to static texture patterns in area V1 of the alert macaque monkey. _Journal of Neurophysiology_, 67(4):961-980, April 1992. ISSN 0022-3077. doi: 10.1152/jn.1992.67.4.961.
* Komban et al. [2011] Stanley Jose Komban, Jose-Manuel Alonso, and Qasim Zaidi. Darks Are Processed Faster Than Lights. _Journal of Neuroscience_, 31(23):8654-8658, June 2011. ISSN 0270-6474, 1529-2401. doi: 10.1523/JNEUROSCI.0504-11.2011. URL https://www.jneurosci.org/content/31/23/8654.
* Rahimi-Nasrabadi et al. [2021] Hamed Rahimi-Nasrabadi, Jianzhong Jin, Reece Mazade, Carmen Pons, Sohrab Najafian, and Jose-Manuel Alonso. Image luminance changes contrast sensitivity in visual cortex. _Cell Reports_, 34(5), February 2021. ISSN 2211-1247. doi: 10.1016/j.celrep.2021.108692. URL https://www.cell.com/cell-reports/abstract/S2211-1247(21)00005-X.
* Srinivasan et al. [2015] Shyam Srinivasan, C. Nikoosh Carlo, and Charles F. Stevens. Predicting visual acuity from the structure of visual cortex. _Proceedings of the National Academy of Sciences_, 112(25):7815-7820, June 2015. doi: 10.1073/pnas.1509282112. URL https://www.pnas.org/doi/10.1073/pnas.1509282112.
* Stevens et al. [2013] Jean-Luc R. Stevens, Judith S. Law, Jan Antolik, and James A. Bednar. Mechanisms for Stable, Robust, and Adaptive Development of Orientation Maps in the Primary Visual Cortex. _Journal of Neuroscience_, 33(40):15747-15766, October 2013. ISSN 0270-6474, 1529-2401. doi: 10.1523/JNEUROSCI.1037-13.2013. URL https://www.jneurosci.org/content/33/40/15747.
* Kaschube et al. [2010] Matthias Kaschube, Michael Schnabel, Siegrid Lowel, David M. Coppola, Leonard E. White, and Fred Wolf. Universality in the Evolution of Orientation Columns in the Visual Cortex. _Science_, 330(6007):1113-1116, November 2010. doi: 10.1126/science.1194869. URL https://www.science.org/doi/10.1126/science.1194869.
* Martin et al. [2001] D. Martin, C. Fowlkes, D. Tal, and J. Malik. A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics. In _Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001_, volume 2, pages 416-423 vol.2, July 2001. doi: 10.1109/ICCV.2001.937655. URL https://ieeexplore.ieee.org/document/937655.
* Kanan and Cottrell [2010] Christopher Kanan and Garrison Cottrell. Robust classification of objects, faces, and flowers using natural image statistics. In _2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition_, pages 2472-2479, June 2010. doi: 10.1109/CVPR.2010.5539947. URL https://ieeexplore.ieee.org/document/5539947.
* Tang et al. [2018] Shiming Tang, Tai Sing Lee, Ming Li, Yimeng Zhang, Yue Xu, Fang Liu, Benjamin Teo, and Hongfei Jiang. Complex Pattern Selectivity in Macaque Primary Visual Cortex Revealed by Large-Scale Two-Photon Imaging. _Current Biology_, 28(1):38-48.e3, January 2018. ISSN 0960-9822. doi: 10.1016/j.cub.2017.11.039. URL https://www.cell.com/current-biology/abstract/S0960-9822(17)31521-X.
* Alreja et al. [2022] Arish Alreja, Ilya Nemenman, and Christopher J. Rozell. Constrained brain volume in an efficient coding model explains the fraction of excitatory and inhibitory neurons in sensory cortices. _PLOS Computational Biology_, 18(1):e1009642, January 2022. ISSN 1553-7358. doi: 10.1371/journal.pcbi.1009642. URL https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009642.
* Markram et al. [2004] Henry Markram, Maria Toledo-Rodriguez, Yun Wang, Anirudh Gupta, Gial Silberberg, and Ciazhi Wu. Interneurons of the neocortical inhibitory system. _Nature Reviews Neuroscience_, 5(10):793-807, October 2004. ISSN 1471-0048. doi: 10.1038/nrn1519. URL https://www.nature.com/articles/nrn1519.
* Pfeffer et al. [2013] Carsten K. Pfeffer, Mingshan Xue, Miao He, Z. Josh Huang, and Massimo Scanziani. Inhibition of inhibition in visual cortex: the logic of connections between molecularly distinct interneurons. _Nature Neuroscience_, 16(8):1068-1076, August 2013. ISSN 1546-1726. doi: 10.1038/nn.3446. URL https://www.nature.com/articles/nn.3446.
* Srinivasa and Jiang [2013] Narayan Srinivasa and Qin Jiang. Stable learning of functional maps in self-organizing spiking neural networks with continuous synaptic plasticity. _Frontiers in Computational Neuroscience_, 7, 2013. ISSN 1662-5188. URL https://www.frontiersin.org/articles/10.3389/fncom.2013.00010.
* Oja [1982] Erkki Oja. Simplified neuron model as a principal component analyzer. _Journal of Mathematical Biology_, 15(3):267-273, November 1982. ISSN 1432-1416. doi: 10.1007/BF00275687. URL https://doi.org/10.1007/BF00275687.
* King et al. [2013] Paul D. King, Joel Zylberberg, and Michael R. DeWeese. Inhibitory Interneurons Decorrelate Excitatory Cells to Drive Sparse Code Formation in a Spiking Model of V1. _The Journal of Neuroscience_, 33(13):5475, March 2013. doi: 10.1523/NEUROSCI.4188-12.2013. URL http://www.jneurosci.org/content/33/13/5475.abstract.
* Zylberberg et al. [2011] Joel Zylberberg, Jason Timothy Murphy, and Michael Robert DeWeese. A Sparse Coding Model with Synaptically Local Plasticity and Spiking Neurons Can Account for the Diverse Shapes of V1 Simple Cell Receptive Fields. _PLOS Computational Biology_, 7(10):1-12, October 2011. doi: 10.1371/journal.pcbi.1002250. URL https://doi.org/10.1371/journal.pcbi.1002250.

* Olshausen and Field [1996] Bruno A. Olshausen and David J. Field. Emergence of simple-cell receptive field properties by learning a sparse code for natural images. _Nature_, 381(6583):607-609, June 1996. ISSN 1476-4687. doi: 10.1038/381607a0. URL https://www.nature.com/articles/381607a0.
* Hofer et al. [2011] Sonia B. Hofer, Ho Ko, Bruno Pichler, Joshua Vogelstein, Hana Ros, Hongkui Zeng, Ed Lein, Nicholas A. Lesica, and Thomas D. Mrsic-Flogel. Differential connectivity and response dynamics of excitatory and inhibitory neurons in visual cortex. _Nature Neuroscience_, 14(8):1045-1052, August 2011. ISSN 1546-1726. doi: 10.1038/nn.2876. URL https://www.nature.com/articles/nn.2876.
* Bosking et al. [1997] William H. Bosking, Ying Zhang, Brett Schofield, and David Fitzpatrick. Orientation Selectivity and the Arrangement of Horizontal Connections in Tree Shrew Striate Cortex. _Journal of Neuroscience_, 17(6):2112-2127, March 1997. ISSN 0270-6474, 1529-2401. doi: 10.1523/JNEUROSCI.17-06-02112.1997. URL https://www.jneurosci.org/content/17/6/2112.
* Horton and Hocking [1996] Jonathan C. Horton and Davina R. Hocking, Intrinsic Variability of Ocular Dominance Column Periodicity in Normal Macaque Morkes. _Journal of Neuroscience_, 16(22):7228-7339, November 1996. ISSN 0270-6474, 1529-2401. doi: 10.1523/JNEUROSCI.16-22-07228.1996. URL https://www.jneurosci.org/content/16/22/7228. Publisher: Society for Neuroscience Section: Articles.
* Scholl et al. [2013] Benjamin Scholl, Johannes Burge, and Nicholas J. Priebe. Binocular integration and disparity selectivity in mouse primary visual cortex. _Journal of Neurophysiology_, 109(12):3013-3024, June 2013. ISSN 0022-3077. doi: 10.1152/jn.01021.2012. URL https://journals.physiology.org/doi/full/10.1152/jn.01021.2012.
* Tusa et al. [1978] R. J. Tusa, L. A. Palmer, and A. C. Rosenquist. The retinotopic organization of area 17 (striate cortex) in the cat. _Journal of Comparative Neurology_, 177(2):213-235, 1978. ISSN 1096-9861. doi: 10.1002/cne.901770204. URL https://onlinelibrary.wiley.com/doi/abs/10.1002/cne.901770204. _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cne.901770204.
* Scholl et al. [2007] Edward J. Schrounik and Warren M. Slocum. Phosphine induction by microstimulation of macaque V1. _Brain Research Reviews_, 53(2):337-343, February 2007. ISSN 0165-0173. doi: 10.1016/j.brainresrev.2006.11.001. URL https://www.sciencedirect.com/science/article/pii/S0165017306001160.
* Niell and Stryker [2008] Cristopher M. Niell and Michael P. Stryker. Highly Selective Receptive Fields in Mouse Visual Cortex. _Journal of Neuroscience_, 28(30):7520-7536, July 2008. ISSN 0270-6474, 1529-2401. doi: 10.1523/JNEUROSCI.0623-08.2008. URL https://www.jneurosci.org/content/28/30/7520.
* van Beest et al. [2021] Enny H. van Beest, Sreedeep Mukherjee, Lisa Kirchberger, Ulf H. Schnabel, Chris van der Togt, Rob R. M. Teeuwen, Areg Barsegyan, Arne F. Meyer, Jasper Poort, Pieter R. Roelfsema, and Matthew W. Self. Mouse visual cortex contains a region of enhanced spatial resolution. _Nature Communications_, 12(1):4029, June 2021. ISSN 2041-1723. doi: 10.1038/s41467-021-24311-5. URL https://www.nature.com/articles/s41467-021-24311-5.
* Foldiak [1990] P. Foldiak. Forming sparse representations by local anti-Hebbian learning. _Biological Cybernetics_, 64(2):165-170, December 1990. ISSN 1432-0770. doi: 10.1007/BF02331346. URL https://link.springer.com/article/10.1007/BF02331346.
* Thomson and Lamy [2007] Alex Thomson and Christophe Lamy. Functional maps of neocortical local circuitry. _Frontiers in Neuroscience_, 1, 2007. ISSN 1662-453X. URL https://www.frontiersin.org/articles/10.3389/neuro.01.1.1.002.2007.
* Holmgren et al. [2003] Carl Holmgren, Tibor Harkany, Bjorn Svennenfors, and Yuri Zilberter. Pyramidal cell communication within local networks in layer 2/3 of rat neocortex. _The Journal of Physiology_, 551(Pt 1):139-153, August 2003. ISSN 0022-3751. doi: 10.1113/physiol.2003.044784. URL https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2343144/.
* Sato et al. [2016] Tatsuo K. Sato, Bilal Haider, Michael Hausser, and Matteo Carandini. An excitatory basis for divisive normalization in visual cortex. _Nature Neuroscience_, 19(4):568-570, April 2016. ISSN 1546-1726. doi: 10.1038/nn.4249. URL https://www.nature.com/articles/nn.4249.
* Song et al. [2021] Min Song, Jaeson Jang, Gwangsu Kim, and Se-Bum Paik. Projection of Orthogonal Tiling from the Retina to the Visual Cortex. _Cell Reports_, 34(1), January 2021. ISSN 2211-1247. doi: 10.1016/j.celrep.2020.108581. URL https://www.cell.com/cell-reports/abstract/S2211-1247(20)31570-9.
* Margalit et al. [2023] Eshed Margalit, Hyodong Lee, Dawn Finzi, James J. DiCarlo, Kalanti Grill-Spector, and Daniel L. K. Yamins. A Unifying Principle for the Functional Organization of Visual Cortex, May 2023. URL https://www.biorxiv.org/content/10.1101/2023.05.18.541361v1.
* Lufkin et al. [2022] Leon Lufkin, Ashish Puri, Ganilin Song, Xinyi Zhong, and John Lafferty. _Emergent organization of receptive fields in networks of excitatory and inhibitory neurons_. May 2022. doi: 10.48550/arXiv.2205.13614.
* Tao et al. [2004] Louis Tao, Michael Shelley, David McLaughlin, and Robert Shapley. An egalitarian network model for the emergence of simple and complex cells in visual cortex. _Proceedings of the National Academy of Sciences_, 101(1):366-371, January 2004. doi: 10.1073/pnas.2036460100. URL https://www.pnas.org/doi/full/10.1073/pnas.2036460100.

* Stepanyants et al. [2009] Armen Stepanyants, Luis M. Martinez, Alex S. Ferecsko, and Zoltan F. Kisvarday. The fractions of short- and long-range connections in the visual cortex. _Proceedings of the National Academy of Sciences_, 106(9):3555-3560, March 2009, doi: 10.1073/pnas.0810390106. URL https://www.pnas.org/doi/abs/10.1073/pnas.0810390106.
* Amatrudo et al. [2012] Joseph M. Amatrudo, Christina M. Weaver, Johanna L. Crimins, Patrick R. Hof, Douglas L. Rosene, and Jennifer I. Luebke. Influence of Highly Distinctive Structural Properties on the Excitability of Pyramidal Neurons in Monkey Visual and Prefrontal Cortices. _Journal of Neuroscience_, 32(40):13644-13660, October 2012. ISSN 0270-6474, 1529-2401. doi: 10.1523/JNEUROSCI.2581-12.2012. URL https://www.jneurosci.org/content/32/40/13644.
* Ferster et al. [1996] David Ferster, Sooyoung Chung, and Heidi Wheat. Orientation selectivity of thalamic input to simple cells of cat visual cortex. _Nature_, 380(6571):249-252, March 1996. ISSN 1476-4687. doi: 10.1038/380249a0. URL https://www.nature.com/articles/380249a0.
* Blakemore and Tobin [1972] Colin Blakemore and Elisabeth A. Tobin. Lateral inhibition between orientation detectors in the cat's visual cortex. _Experimental Brain Research_, 15(4):439-440, September 1972. ISSN 1432-1106. doi: 10.1007/BF00234129. URL https://doi.org/10.1007/BF00234129.
* Bonds [1989] A. B. Bonds. Role of Inhibition in the Specification of Orientation Selectivity of Cells in the Cat Striate Cortex. _Visual Neuroscience_, 2(1):41-55, January 1989. ISSN 1469-8714, 0952-5238. doi: 10.1017/S0952523800004314.
* Douglas and Peucker [1973] David H. Douglas and Thomas K. Peucker. Algorithms for the reduction of the number of points required to represent a digitized line or its caricature. _Cartographica: The International Journal for Geographic Information and Geovisualization_, 10(2):112-122, 1973. Publisher: University of Toronto Press.
* Tehovnik and Lee [1993] Edward J. Tehovnik and Kyoungmin Lee. The dorsomedial frontal cortex of the rhesus monkey: topographic representation of saccades evoked by electrical stimulation. _Experimental Brain Research_, 96(3):430-442, November 1993. ISSN 1432-1106. doi: 10.1007/BF00234111. URL https://doi.org/10.1007/BF00234111.
* Veit et al. [2014] Julia Veit, Anwesha Bhattacharyya, Robert Kretz, and Gregor Rainer. On the Relation Between Receptive Field Structure and Stimulus Selectivity in the Tree Shrew Primary Visual Cortex. _Cerebral Cortex_, 24(10):2761-2771, October 2014. ISSN 1047-3211. doi: 10.1093/cercor/bht133. URL https://doi.org/10.1093/cercor/bht133.
* Huberman et al. [2006] Andrew D. Huberman, Colenso M. Speer, and Barbara Chapman. Spontaneous Retinal Activity Mediates Development of Ocular Dominance Columns and Binocular Receptive Fields in V1. _Neuron_, 52(2):247-254, October 2006. ISSN 0896-6273. doi: 10.106/j.neuron.2006.07.028. URL https://www.cell.com/neuron/abstract/50896-6273(06)00625-8.
* Foik et al. [2020] Andrzej T. Foik, Leo R. Scholl, Georgina A. Lean, and David C. Lyon. Visual Response Characteristics in Lateral and Medial Subdivisions of the Rat Pulivarin. _Neuroscience_, 441:117-130, August 2020. ISSN 0306-4522. doi: 10.1016/j.neuroscience.2020.06.030. URL https://www.sciencedirect.com/science/article/pii/S0306452220304073.
* Hall et al. [1971] W C Hall, J H Kaas, H Killackey, and I T Diamond. Cortical visual areas in the grey squirrel (Sciurus carolinesis): a correlation between cortical evoked potential maps and architectonic subdivisions. _Journal of Neurophysiology_, 34(3):437-452, May 1971. ISSN 0022-3077. doi: 10.1152/jn.1971.34.3.437. URL https://journals.physiology.org/doi/abs/10.1152/jn.1971.34.3.437.
* Weigand et al. [2017] Marvin Weigand, Fabio Sartori, and Hermann Cuntz. Universal transition from unstructured to structured neural maps. _Proceedings of the National Academy of Sciences_, 114(20):E4057-E4064, May 2017. doi: 10.1073/pnas.1616163114. URL https://www.pnas.org/doi/full/10.1073/pnas.1616163114.
* Law et al. [1988] Margaret I. Law, Kathleen R. Zahs, and Michael P. Stryker. Organization of primary visual cortex (area 17) in the ferret. _Journal of Comparative Neurology_, 278(2):157-180, 1988. ISSN 1096-9861. doi: 10.1002/cne.902780202. URL https://onlinelibrary.wiley.com/doi/abs/10.1002/cne.902780202.
* Keller et al. [2000] Jason Keller, Hans Strasburger, Daniel T Cerutti, and Bernhard A Sabel. Assessing spatial vision -- automated measurement of the contrast-sensitivity function in the hooded rat. _Journal of Neuroscience Methods_, 97(2):103-110, April 2000. ISSN 0165-0270. doi: 10.1016/S00165-0270(00)00173-4. URL https://www.sciencedirect.com/science/article/pii/S016502700001734.
* Engelmann and Peichl [1996] Ralf Engelmann and Leo Peichl. Unique Distribution of Somatostatin-immunoreactive Cells in the Retina of the Tree Shrew (Tupaia belangeryi). _European Journal of Neuroscience_, 8(1):220-228, 1996. ISSN 1460-9568. doi: 10.1111/j.1460-9568.1996.tb01183.x. URL https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1460-9568.1996.tb01183.x.
* Hughes [1979] A. Hughes. A schematic eye for the rat. _Vision Research_, 19(5):569-588, January 1979. ISSN 0042-6989. doi: 10.1016/0042-6989(79)90143-3. URL https://www.sciencedirect.com/science/article/pii/0042698979901433.

* [79] Haoyu Wang, Haixin Zhong, Wei P. Dai, and Yuguo Yu. The Functional Role of Pinwheel Topology in the Primary Visual Cortex of High-Order Animals for Complex Natural Image Representation, March 2024. URL https://www.bioxriv.org/content/10.1101/2024.03.07.583885v1. Pages: 2024.03.07.583885 Section: New Results.
* [80] Anna W. Roe, Leonardo Chelazzi, Charles E. Connor, Bevil R. Conway, Ichiro Fujita, Jack L. Gallant, Haidong Lu, and Wim Vanduffel. Toward a Unified Theory of Visual Area V4. _Neuron_, 74(1):12-29, April 2012. ISSN 0896-6273. doi: 10.1016/j.neuron.2012.03.011. URL https://www.cell.com/neuron/abstract/S0896-6273(12)00274-7.

Appendices

### Exponential moving average

We compute the network's neuronal instantaneous spike rates as exponential moving averages (EMAs), which accumulate spikes over time (see Eq. 9). EMAs are utilized to track recent neuronal activity levels. Concurrently, lifetime average values are also calculated using EMAs, which are crucial for maintaining homeostatic stability. This method helps stabilize the neural network by adjusting neuronal properties or synaptic strengths to sustain consistent activity levels over time.

\[x_{j}(t)=(1-\zeta)x_{j}(t-1)+\zeta\cdot z_{j}(t),\] (9)

where \(\zeta=1-e^{-\frac{1}{16}}\), indicating that the 10 ms is a temporal window of the moving average weighted with exponential decay. The initialization of \(x_{j}\) is 0. The exponential moving average is calculated dynamically and updated along with synaptic weights.

\[\langle x_{j}\rangle:=(1-\xi)\cdot\langle x_{j}\rangle+\xi\cdot\overline{x}_{j},\] (10)

where \(\xi=1-e^{-1}\). It is dynamically updated to ensure the sum of the weights remains constant over time.

### Detailed parameters and connectivity settings for the model

Detailed neural dynamics:The feed-forward connection, labeled \(\text{FF}^{(\text{image}\rightarrow\text{E})}_{ij}\), links pixel \(X_{j}\) of the whitened image patch to excitatory (E-) neuron \(i\). \(W^{(\text{K}^{*}\rightarrow\text{K})}_{ij}\) signifies the synaptic weight from neuron \(j\) of neuron class \(\text{K}^{*}\) to neuron \(i\) of neuron class \(\text{K}\), with its sign determined by the connection type, described as \(\beta^{(\text{K}^{*}\rightarrow\text{K})}_{ij}\)(the neuron receives E-connections, set as +1; conversely, the neuron receives inhibitory (I-) connections, the sign is set as -1). \(z^{(\text{K}^{*})}_{j}\left(t\right)\) indicates the spike output of neuron \(j\) at time \(t\). Upon reaching the spike threshold \(\theta\) (initialized as 2), a spike is emitted, \(z^{(\text{K}^{*})}_{j}\left(t\right)\) is set to 1, then the membrane potential is reset to 0 mV, remaining so until the refractory period (3 ms) concludes. Within primary visual cortex (V1), homeostatic plasticity [34; 55] ensures neural activity stability by dynamically adjusting the firing threshold \(\theta\). This adjustment is based on the deviation of the current firing rate \(p_{i}\left(t\right)\) from the target rates \(p^{(\text{K})}_{i}\) (\(p^{(\text{E})}=2,\ p^{(\text{I})}=4\)), as outlined in Eq. 6[55]. We assign \(\tau^{(\text{E})}=10\) ms for E-neurons and \(\tau^{(\text{I})}=5\) ms for I-neurons. To enhance computational efficiency, we set the time step to 1 ms.

Hyperparameters:For the synaptic plasticity, learning rates are \(\eta_{\text{FF}}=0.2\) (image to E-neurons), \(\eta_{\text{EE}}=0.01\) (E- to E-neurons), \(\eta_{\text{EI}}=0.7\) (I- to E-neurons), \(\eta_{\text{II}}=1.5\) (I- to I-neurons), and \(\eta_{\text{IE}}=0.7\) (E- to I-neurons), while the neural connectivity parameters are \(\alpha_{\text{max,E}}=1.0\) (E- max weight), \(\alpha_{\text{max,I}}=0.5\) (I- max weight), \(\sigma_{\text{EE}}=3.5\) (E-E coupling range), \(\sigma_{\text{EI}}=2.9\) (E-I coupling range), \(\sigma_{\text{IE}}=2.6\) (I-E coupling range), and \(\sigma_{\text{II}}=2.1\) (I-I coupling range).

Neural connectivity within 2D cortical area:E- and I- neurons are arranged symmetrically on a two-dimensional lattice, as illustrated in Fig. 5b. Periodic boundary conditions are employed to mimic the large number of neurons in the actual V1 cortical surface. Specifically, neurons at the boundary are connected to neurons at corresponding symmetric positions on the opposite boundary. The initial connection weights between neurons are modeled by a Gaussian function of their distance (see Fig. 5c), which can be expressed as:

\[W^{\text{K}^{*}\rightarrow\text{K}}_{0}\left(i,j\right)=\alpha_{\text{K}^{*}} \times\exp\left(\frac{-d\left(i,j\right)^{2}}{2\sigma_{\text{K}^{*}}}\right).\] (11)

In this equation, \(d(i,j)\) represents the Euclidean distance from neuron \(i\) to neuron \(j\) in a grid, \(\alpha\) determines the maximum connection weight, which is set to \(\alpha_{\text{EE}}=1,\alpha_{\text{EI}}=1,\alpha_{\text{IE}}=0.5,\alpha_{ \text{II}}=0.5\), and \(\sigma\) governs the rate at which the weight decays with distance. The synaptic types predominantly determine the parameters for this connection weight distribution function. To accurately replicate the neuronal architecture of V1 in macaques. The connectivity radiuses, denoted by \(\sigma\), are set to \(\sigma_{\text{EE}}=3.5\), \(\sigma_{\text{EI}}=2.9\), \(\sigma_{\text{IE}}=2.6\), \(\sigma_{\text{II}}=2.1\). These values are based on anatomical data indicating that the axon length scales of E- and I-neurons are approximately 200 \(\mu\)m and 100 \(\mu\)m, respectively, while the dendrite length scales are around 150 \(\mu\)m for E-neurons and 75 \(\mu\)m for I-neurons in the V1 [62; 63; 64]. We prune any connection strengths below a threshold of 0.01 to maintain computational efficiency and biological plausibility.

### Anatomical data integration

#### Neural connection data

The experimental subjects include six adult cats with unknown genders, with data sourced from research by Armen Stepanyants et al.[63]; and eight macaques, aged 5-11 years, including six males and two females, with data sourced from research by Joseph Amatrudo et al.[64].

#### Neuronal synaptic plasticity

The subjects are rats aged 14-16 days, with unknown gender and quantity, with data sourced from research by Holmgren et al.[57]; transgenic mice, with unknown quantity and gender, with data sourced from research by Hofer et al. [47].

#### Retinal-V1 topological projection data

Receptive field (RF) data: V1 neuron counts for macaques, cats, tree shrews, ferrets, mice, rats, and gray squirrels respectively come from Tehovnik et al. [69] (subjects: 3 macaques, unknown gender and age), Scholl et al. [50] (subjects: cats, unknown gender and age), Veit et al.[70] (subjects: 9 male and 7 female tree shrews, aged 3-8 years), Huberman et al.[71] (subjects: 8 ferrets, unknown gender and age), Niell et al.[53] (subjects: mice, aged 2-6 months, unknown gender), Foik et al.[72](subjects: 21 rats, unknown gender and age), and Hall et al.[73] (subjects: 17 gray squirrels, unknown gender and age). V1 neuron density: Neuron density data for macaques, cats, mice, rats, and gray squirrels come from Srinivasana et al.[52] (subjects: unknown gender and age); tree shrew, ferret, and gray squirrel density data respectively come from Weigand et al.[74].

#### Cortical magnification factor

Cortical magnification factor (CMF) data for macaques, cats, tree shrews, ferrets, mice, rats, and gray squirrels are sourced from Tehovnik et al.[69] (subjects: 3 macaques, unknown gender and age), Veit et al.[70](subjects: cats, unknown gender and age), Bosking et al.[48] (subjects: tree shrews, unknown gender and age), Rockland et al. [75] (subjects: 9 ferrets, female, unknown age), Beest et al.[54] (subjects: 28 mice, 11 males and 17 females, ages 2-14 months), Keller et al.[76] (subjects: male rats, age 3 months), and Hall et al.[73] (subjects: 17 gray squirrels, unknown gender and age).

Additionally, the anatomical data concerning inter-ocular distances are obtained from Najafian et al. [7].

### Unveiling species-specific factors distinguishing pinwheels and salt-and-peppers

#### a.4.1 Anatomical data suggests RFs density underlying V1 organizations

We analyzed anatomical data from seven species, including primates (e.g., macaques) and non-primates (e.g., mice, rats, cats, tree shrews, gray squirrels, and ferrets), as detailed in Table 3. We first find that V1 RFs density (RFD) (\(\rho_{\text{RF}}\)) acts as a linear classifier (\(y=4.42\times 10^{4}x\)), effectively distinguishing species with pinwheel structures from those with salt-and-pepper organizations. In this classifier, species like macaques, cats, tree shrews, and ferrets, which have higher RFD, are

\begin{table}
\begin{tabular}{l c c c c c} \hline \hline \multirow{2}{*}{**a.** Species (mean)} & **b.** Retina & **c.** V1 size & **d.** V1 neurons & **e.** V1 RF & **f.** RFD \\  & (mm\({}^{2}\)) & (mm\({}^{2}\)) & density & size in area & (\((c)\times(d)/(b)\)) \\  & (mm\({}^{2}\)) & (mm\({}^{2}\)) & (neurons/mm\({}^{2}\)) & centralis (deg) & (RFs/mm\({}^{2}\)) \\ \hline Macaque & 636[6] & 1,090[33] & 243,000[33] & 0.2[52] & 416,462.26 \\ Cat & 510[6] & 380[6, 33] & 99,200[33] & 1.0[50] & 73,913.73 \\ Tree shrew & 122[6, 77] & 73[6, 33] & 192,800[74] & 2.0[70] & 115,363.93 \\ Ferret & 83[6, 75] & 78[33] & 95,813[74] & 3.0[71] & 90,041.13 \\ Mouse & 15[6] & 2.5[33] & 86,600[33] & 4.0[53] & 14,433.33 \\ Rat & 52[6, 78] & 7.1[33] & 90,800[33] & 3.0[72] & 12,397.69 \\ Gray squirrel & 205[6] & 32[6] & 84,213[74] & 2.0[73] & 13,145.44 \\ \hline \hline \end{tabular}
\end{table}
Table 3: Comparative anatomical data of the retina and V1 across species.

associated with pinwheel structures (light red area in Fig. 6) and exceed the classification threshold. In contrast, species with lower RFD, such as mice, rats, and gray squirrels, are linked to salt-and-pepper organizations (light blue area in Fig. 6). Thus, V1 RFD serves as a predictive metric for V1 organizational patterns across species. The \(\rho_{\text{RF}}\) is calculated as follows:

\[\rho_{\text{RF}}=\frac{n^{\prime}}{s_{\text{r}}^{\prime}}\propto\frac{n}{\left[ \left(s_{\text{RF}}-\varepsilon\right)\left(\sqrt{n}-1\right)+s_{\text{RF}} \right]^{2}},\] (12)

where \(n^{\prime}\) denotes the total number of neurons in V1, \(s_{\text{r}}^{\prime}\) indicates the retinal surface area. We have \(n^{\prime}=s_{\text{V1}}\times\rho_{\text{V1}}\), where \(s_{\text{V1}}\) corresponds to the V1 2D surface area, and \(\rho_{\text{V1}}\) signifies the neuronal density within V1. The variable \(\varepsilon\) quantifies the degree of visual input overlap among adjacent neurons, \(n\) denotes the total number of neurons, and \(s_{\text{RF}}\) represents the RF size in the self-evolving spiking neural network (SESNN). Referring to Eq. 12 and anatomical data (Table 3), the overlap \(\varepsilon\) positively correlates to V1 RFD \(\rho_{\text{RF}}\) and is a main factor influencing V1 RFD. We discuss the overlap as the variable of V1 organizations in the main text.

#### a.4.2 SESNN reveals neuronal connection range influencing V1 clusters

The anatomical data in Table 3d for seven species show variability in V1 neuronal density (\(\rho_{\text{V1}}\)), which influences inter-neuronal spacing and connection strength. We explore how V1 cortical orientation patterns form by adjusting the lateral connection range, impacting axon reach among E- and I-neurons, as depicted in Fig. 7. We modulate axonal arborization through parameter \(\sigma\) to adjust the connection range, allowing us to simulate neuronal connections in areas with varying densities. This setup enables the SESNN model to predict changes in cortical patterns (Fig. 7). Our observations indicate that increasing axon lengths, thereby extending the connection range, enlarges hypercolumn sizes within pinwheel structures (Fig. 7d), reduces the overall number of pinwheels (Fig. 7b), and increases the nearest-neighbor pinwheel distance (NNPD) (Fig. 7c). These findings underscore the critical role of neural synaptic connection range in organizing orientation maps.

Relationship between maximum values of local pixel entropy and local geometrical entropy for various shapes

To address the limitations of using local pixel entropy (LPE) with sliding windows alone to capture complex geometric properties, we conduct a new analysis comparing the maximum values of LPE with local geometrical entropy (LGE) across various shapes. These shapes include lines, angles, and junctions (L-, T-, X-junctions), as well as jagged edges. Both LPE and LGE values were normalized to the range [0,1] for consistency.

Let \(P=\{v_{1},v_{2},\ldots,v_{n}\}\) be a polygon with vertices \(v_{i}=(x_{i},y_{i})\), where \(i=1,2,\ldots,n\). The edges of the polygon are the line segments between consecutive vertices, denoted as \(e_{i}=\|v_{i+1}-v_{i}\|\)

Figure 6: A linear classifier based on RFD (\(y=4.42\times 10^{4}x\)) effectively differentiates species with salt-and-pepper organizations (rats, mice, gray squirrels) from those with pinwheel structures (macaques, ferrets, cats, tree shrews). **a**. This classifier reflects variations in V1 organizations across species. **b**. A plot categorizing species by the ratio of V1 neuron number to retina size acts as a divider, implying a critical ratio for the formation of pinwheel structures.

where \(\|\cdot\|\) represents the Euclidean distance. The angle \(\theta_{i}\) between two consecutive edges \(e_{i}\) and \(e_{i+1}\) can be computed using the dot product:

\[\theta_{i}=\cos^{-1}\left(\frac{e_{i}\cdot e_{i+1}}{\|e_{i}\|\|e_{i+1}\|}\right).\] (13)

With the set of edge lengths \(\{e_{1},e_{2},\ldots,e_{n}\}\) and angles \(\{\theta_{1},\theta_{2},\ldots,\theta_{n}\}\), we calculate the entropy for both distributions. The entropy \(H\) of a discrete distribution \(X\) with probability mass function \(p(x)\) is given by:

\[H(X)=-\sum_{x\in X}p(x)\log p(x).\] (14)

For the edge lengths and angles, the probability mass function is estimated by normalizing the frequency of occurrence of each unique edge length and angle in the polygon:

\[H(\text{Lengths})=-\sum_{i=1}^{n}p(e_{i})\log p(e_{i}),\] (15)

\[H(\text{Angles})=-\sum_{i=1}^{n}p(\theta_{i})\log p(\theta_{i}).\] (16)

To enhance the sensitivity of geometrical entropy to structural complexity, particularly in differentiating shapes that have similar edge lengths and angles but different structural arrangements, we introduce a scaling factor based on the logarithm of the number of vertices \(n\). The defined geometrical entropy (GE) with the scaling factor is thus defined as:

\[GE=(H(\text{Lengths})+H(\text{Angles}))\times\log(n).\] (17)

Figure 7: Neuronal connection range within V1 contributes to the formation of pinwheel structures. **a**. Modifying the synaptic connection range reshapes the dimensions of pinwheel structures. **b-d**. The relationship between the synaptic connection range (\(\sigma\)) and the number of pinwheels, NNPD (mm), and hypercolumn size (mm). The scale bar: 1 mm in V1 cortical surface. Color scheme: orientation preference. Lines: mean. Shaded area: SD.

This modification allows GE to capture additional complexity arising from intersections and the global arrangement of vertices, providing a more comprehensive assessment of the shape's structural intricacies.

Our results, summarized in Table 4, show that while LPE can reflect the complexity of certain patterns, it does not fully capture the geometric variations seen in more intricate shapes. For instance, the LPE values for line structures remain relatively low compared to those for jagged edges, which have the highest LPE and LGE values due to their high structural complexity. This comparison highlights the added value of incorporating LGE to better characterize local geometric structures, providing a more nuanced measure of complexity that includes both intensity distribution and spatial organization.

### Pinwheel centers response to different orientation bandwidths

Understanding the tuning of pinwheel centers (PCs) in V1 to edges, corners, and junctions is essential. In Fig. 4e, we show that PCs exhibit broader orientation tuning curves than IODs when using star-like patterns as stimuli, potentially enabling the detection of T-junctions and corners, as demonstrated by Li et al. [13] and Koch et al. [12]. We further examine the distribution of PCs' tuning curves using gratings as inputs, specifically analyzing acute angles formed by the primary and secondary peaks (Fig. 8a). This analysis reveals that PCs are more frequently associated with larger acute angles, closer to orthogonal (90deg), suggesting a preference for orthogonal junctions. However, this result does not differentiate between L- and T- junctions based solely on angle. We propose that such high-order feature extraction be deferred to higher visual cortices, like V2 and V4, which are involved in texture detection, as noted by Wang et al. [79] and Roe et al. [80].

### Ablation study

We present a mechanism of multiple orientation tuning that is essential for processing complexity. Our analysis of PCs' preferred acute angles (Fig. 8a) suggests that their broad tuning enables the detection

\begin{table}
\begin{tabular}{|l|c|c|} \hline
**Various shapes** & **Max local pixel entropy** & **Max local geometrical entropy** \\ \hline Line 1 & 0.56 & 0.43 \\ \hline Line 2 & 0.56 & 0.43 \\ \hline Angle 1 & 0.81 & 0.87 \\ \hline Angle 2 & 0.79 & 0.86 \\ \hline Angle 3 & 0.77 & 0.87 \\ \hline L-junction & 0.78 & 0.74 \\ \hline T-junction & 0.78 & 0.64 \\ \hline X-junction & 0.78 & 0.84 \\ \hline Jagged edges & 1.00 & 1.00 \\ \hline \end{tabular}
\end{table}
Table 4: Relationship between maximum values of LPE and LGE for various shapes. Both metrics are normalized to the range [0,1].

Figure 8: PCs in V1 prefer orientations and ablation study. **a**. Probability distribution of preferred acute angles in PCs. **b**. Ablation study on normalized complexity across response onset latencies. Data: mean \(\pm\) SD.

of complex junctions, such as T- and L-junctions, likely due to variations in local connectivity within and between iso-orientation domains.

To test this, we conduct an ablation study by disrupting local connectivity and shuffling the spatial arrangement of orientation-tuned RFs in the pinwheel orientation map, while keeping other properties constant (Fig. 8b). The control group (red) maintains higher complexity over time, whereas shuffling connections--especially both feed-forward and lateral--resulted in a decline in complexity. This highlights the importance of structured connectivity in preserving complex neural responses in V1 and supports the conclusion that structured connectivity underlies enhanced saliency detection by pinwheels.

### Computing infrastructure

The simulations and analyses in this study are performed on a high-performance computing infrastructure to ensure efficient processing of large datasets and complex models. The system is powered by an Intel(r) Xeon(r) Gold 6348 CPU running at 2.60 GHz and an NVIDIA A100 GPU, providing robust computational power for intensive tasks. The system includes 512 GB of memory, which supports handling memory-intensive applications and large-scale simulations. The operating system used is Ubuntu 20.04.6 LTS, known for its stability and compatibility with scientific software. The simulations are conducted using MATLAB R2023a and Python 3.9, both of which are widely used in scientific computing and neural modeling, enabling effective implementation and analysis of the models presented in this study.

\begin{table}
\begin{tabular}{|c|c|} \hline CPU & Intel® Xeon® Gold 6348 CPU @ 2.60GHz \\ \hline GPU & A100 \\ \hline Memory & 512 GB \\ \hline Operating system & Ubuntu 20.04.6 LTS \\ \hline Simulation platform & MATLAB R2023a and Python 3.9 \\ \hline \end{tabular}
\end{table}
Table 5: Computing infrastructure 

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: The abstract and introduction section state the claims made. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: We discussed over the potential limitations in the last paragraph of the discussion. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [NA]Justification: The paper does not include theoretical results. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: The information for reproducing the experiments are provided in the methods section and the appendix. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?Answer: [Yes] Justification: The data and codes are available on request from the authors. Guidelines:

* The answer NA means that paper does not include experiments requiring code.
* Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: The training and test details are provided in Methods section 2.1. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: he errorbars and statistical significance are provided for each data analysis. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors). * It should be clear whether the error bar is the standard deviation or the standard error of the mean.

* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: The computer resources used are described in the appendix. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: The research conform with the NeurIPS Code of Ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: Our work mainly focus on explaning the biological mechanisms underline pinwheel structure in the visual system, thus has no societal impact. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.

* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: The paper poses no such risks. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: The used open-access data and code are explained and cited in Methods section and Appendix accordingly. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.

* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [Yes] Justification: The details of the code and model are part of the submissions including details about training in Methods section and limitations in discussion. Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.