# Computing Optimal Nash Equilibria in Multiplayer Games

Youzhi Zhang

Centre for Artificial Intelligence and Robotics

Hong Kong Institute of Science & Innovation

Chinese Academy of Sciences

youzhi.zhang@cair-cas.org.hk

&Bo An

School of Computer Science and Engineering

Nanyang Technological University

Singapore

boan@ntu.edu.sg

&V. S. Subrahmanian

Department of Computer Science

Northwestern University

Evanston, USA

vss@northwestern.edu

###### Abstract

Designing efficient algorithms to compute a Nash Equilibrium (NE) in multiplayer games is still an open challenge. In this paper, we focus on computing an NE that optimizes a given objective function. For example, when there is a team of players independently playing against an adversary in a game (e.g., several groups in a forest trying to interdict illegal loggers in green security games), these team members may need to find an NE minimizing the adversary's utility. Finding an optimal NE in multiplayer games can be formulated as a mixed-integer bilinear program by introducing auxiliary variables to represent bilinear terms, leading to a huge number of bilinear terms, making it hard to solve. To overcome this challenge, we first propose a general framework for this formulation based on a set of correlation plans. We then develop a novel algorithm called **CRM** based on this framework, which uses **C**orrelation plans with their **R**elations to restrict the feasible solution space after the convex relaxation of bilinear terms while **M**inimizing the number of correlation plans to reduce the number of bilinear terms. We show that our techniques can significantly reduce the time complexity, and CRM can be several orders of magnitude faster than the state-of-the-art baseline.

## 1 Introduction

One of the important problems in artificial intelligence is the design of algorithms for agents to make decisions in interactive environments [33]. To this day, many results have been achieved in two-player non-cooperative environments, for example, security games [39], the game of Go [38], and poker games [6]. One of the most important solution concepts behind these results is the well-known Nash Equilibrium (NE) [30]. Indeed, there are many efficient algorithms, e.g., algorithms based on linear programs [42, 43, 37, 47, 48] or counterfactual regret minimization [56, 5], to compute Nash equilibria (NEs) in two-player zero-sum games. However, there are fewer results on efficient algorithms for NEs with theoretical guarantees in multiplayer games (see the discussion in [4]), and most of these results are for games with particular structures (e.g., polymatrix games [7, 10]). The main reason is that finding NEs in multiplayer games is hard -- it is PPAD-complete even for zero-sum three-player games [8]. Designing efficient algorithms to compute NEs in multiplayer games is thus still an open challenge.

In this paper, we focus on computing an optimal NE that optimizes a specific objective over the space of NEs. In the real world, we may need to optimize our objective over the space of NEs [34]. Possible objectives [9] could be maximizing social welfare (the sum of the players' expected utilities), maximizing the expected utilities of one player or several players, maximizing the minimum utility among players, minimizing the support sizes of the NE strategies, and so on. In addition, when there is a team of players in a game, team members need to consider finding an equilibrium that optimizes some objective [45; 12]. For example, in green security games where several heterogeneous groups (e.g., local police, the Madagascar National Parks, NGOs, and community volunteers) try to protect forests from illegal logging [26], the groups involved may need to find an NE that minimizes the adversary's utility1.

Footnote 1: Here, if all team members play strategies according to an NE minimizing the adversaryâ€™s utility, the adversary cannot deviate from the equilibrium strategy to obtain a higher utility.

Unfortunately, the problems mentioned above are NP-hard [14; 9]. In two-player games, finding an optimal NE can be formulated as a mixed-integer linear program [34]. In this formulation, finding an optimal solution means optimizing an objective over the space of NEs, and this space is modeled as the feasible solution space of the mixed-integer linear program. We can directly extend this two-player formulation to find an optimal NE in multiplayer games by representing the space of NEs as the feasible solution space of a mixed-integer bilinear program transformed from a multilinear program by using auxiliary variables to represent bilinear terms. Then finding an optimal NE requires solving a non-convex program. Unfortunately, such a formulation is not efficient because there are exponentially many bilinear terms in the program. There are other approaches (e.g., [4]) that guarantee finding an NE in multiplayer games. However, these approaches need to enumerate all NEs to find an optimal NE, which is very inefficient [34] (see our experimental results) because there can be exponentially many NEs [44].

To tackle this challenge, we first propose a general framework for transforming a multilinear program for computing optimal NEs into a bilinear program based on a set of correlation plans, where each correlation plan (i.e., a probability distribution over joint actions) corresponds to a set of auxiliary variables representing a set of bilinear terms. We then develop a novel algorithm called **CRM** based on this framework, which uses **C**orrelation plans with their **R**elations to strictly reduce the feasible solution space after the convex relaxation of bilinear terms while **M**inimizing the number of correlation plans to reduce the number of bilinear terms. We show that our techniques can significantly reduce the time complexity, and CRM can be several orders of magnitude faster than the state-of-the-art baseline. To our best knowledge, CRM is the first algorithm to use a minimum set of correlation plans to reformulate the program for computing optimal NEs in multiplayer games.

## 2 Preliminaries

Consider a normal-form game2\(G=(N,A,u)\)[37]. We denote the set of players as \(N=\{1,\ldots,n\}\); the set of all players' joint actions is \(A=\times_{i\in N}A_{i}\), where \(A_{i}\) is the finite set of player \(i\)'s pure strategies (actions) with \(a_{i}\in A_{i}\); and the set of all players' payoff functions is \(u=(u_{1},\ldots,u_{n})\), where \(u_{i}:A\rightarrow\mathbb{R}\) is player \(i\)'s payoff function. Let \(U_{max}=\max_{i\in N}\max_{a\in A}u_{i}(a)\), and \(U_{min}=\min_{i\in N}\min_{a\in A}u_{i}(a)\). In addition, the set of (joint) mixed strategy profiles \(X=\times_{i\in N}X_{i}\), where \(X_{i}=\Delta(A_{i})\) (i.e., the set of probability distributions over \(A_{i}\)) is the set of mixed strategies of player \(i\), and \(x_{i}(a_{i})\) is the probability that any action \(a_{i}\in A_{i}\) is played. Let \(-i\) be the set of all players excluding player \(i\), i.e., \(-i=N\setminus\{i\}\), and \(A_{-i}\) be \(\times_{j\in N\setminus\{i\}}A_{j}\). Generally, given \(N^{\prime}\subseteq N\), \(a_{N^{\prime}}\in A_{N^{\prime}}=\times_{i\in N^{\prime}}A_{i}\), \(a_{N^{\prime}}(i)\) is the action of player \(i\in N^{\prime}\) in the joint action \(a_{N^{\prime}}\). For example, if \(a_{N^{\prime}}=(a_{1},a_{3},a_{5})\) with \(N^{\prime}=\{1,3,5\}\), \(a_{N^{\prime}}(3)=a_{3}\). If \(N^{\prime}=N\), we ignore the subscript, i.e., \(a=a_{N}\) and \(A=A_{N}\). For each \(x\in X\), player \(i\)'s expected payoff is:

Footnote 2: Our methods mostly apply to normal-form games including green security games mentioned in Section 1. Extensive-form games can be first converted to normal-form games to be solved, and exploiting their game structure is the future work.

\[u_{i}(x)=\sum_{a\in A}u_{i}(a)\prod_{j\in N}x_{j}(a(j)),\]

and, if player \(i\) plays \(a_{i}\):

\[u_{i}(a_{i},x_{-i})=\sum_{a_{-i}\in A_{-i}}u_{i}(a_{i},a_{-i})\prod_{j\in-i}x _{j}(a_{-i}(j)).\]In this paper, we consider multiplayer games, i.e., \(n>2\).

A Nash Equilibrium (NE, and NEs for Nash Equilibria) [30] is a stable strategy profile in which no player has an incentive to change her strategy given other players' strategies and always exists. Formally, a strategy profile \(x^{*}\) is an NE if, for each player \(i\), \(x^{*}_{i}\) is a best response to \(x^{*}_{-i}\), i.e., \(u_{i}(x^{*}_{i},x^{*}_{-i})\geq u_{i}(x_{i},x^{*}_{-i}),\forall x_{i}\in X_{i}\), which is equivalent to \(u_{i}(x^{*}_{i},x^{*}_{-i})\geq u_{i}(a_{i},x^{*}_{-i}),\forall a_{i}\in A_{i}\).

With the above condition of NEs, we could use a multilinear program to represent the space of NEs, but it will involve the product of strategies in \(u_{i}(x)\), whose degree is \(n\) and is higher than the product of strategies in \(u_{i}(a_{i},x_{-i})\). To reduce the degree of the program representing the space of NEs from \(n\) to \(n-1\) (i.e., only the product of strategies in \(u_{i}(a_{i},x_{-i})\) is required), in two-player games, the previous work [34] exploited the following NE's property, which can be used in multiplayer games as well. For each strategy profile \(x\in X\), the regret of an action \(a_{i}\) is the difference in player \(i\)'s expected utility between playing \(x_{i}\) in \(x\) and playing \(a_{i}\), i.e., \(u_{i}(x)-u_{i}(a_{i},x_{-i})\). Obviously, a strategy profile \(x\in X\) is an NE if and only if every action either has the regret 0, or is played with the probability 0 in \(x\). Then the space of NEs of a game can be formulated as the feasible solution space of a mixed-integer program by using a binary variable \(b_{a_{i}}\) to represent that any action \(a_{i}\) either has the regret 0, or is played with the probability 0:

\[u_{i}(a_{i},x_{-i})=\sum_{a_{-i}\in A_{-i}}u_{i}(a_{i},a_{-i}) \prod_{j\in-i}x_{j}(a_{-i}(j))\quad\forall i,a_{i}\in A_{i}\] (1a) \[\sum_{a_{i}\in A_{i}}x_{i}(a_{i})=1\quad\forall i\in N\] (1b) \[1-b_{a_{i}}\geq x_{i}(a_{i})\quad\forall i\in N,a_{i}\in A_{i}\] (1c) \[u_{i}(x)\geq u_{i}(a_{i},x_{-i})\quad\forall i\in N,a_{i}\in A_{i}\] (1d) \[u_{i}(x)-u_{i}(a_{i},x_{-i})\leq b_{a_{i}}(U_{max}-U_{min})\quad \forall i\in N,a_{i}\in A_{i},\] (1e) \[u_{i}(a_{i},x_{-i})\in[U_{min},U_{max}],u_{i}(x)\in[U_{min},U_{max }]\quad\forall i\in N,a_{i}\in A_{i},\] (1f) \[x_{i}(a_{i})\in[0,1],b_{a_{i}}\in\{0,1\},\quad\forall i\in N,a_ {i}\in A_{i},\] (1g)

where we use the notations of utility functions \(u_{i}(x)\) and \(u_{i}(a_{i},x_{-i})\) to represent the corresponding variables in the program. Eq.(1c) ensures that binary variable \(b_{a_{i}}\) is set to 0 when \(x_{i}(a_{i})>0\) and can be set to 1 only when \(x_{i}(a_{i})=0\); and Eq.(1e) ensures that the regret of action \(a_{i}\) equals 0 (i.e., \(u_{i}(x)=u_{i}(a_{i},x_{-i})\)), unless \(b_{a_{i}}=1\) where the constraint \(u_{i}(x)-u_{i}(a_{i},x_{-i})\leq(U_{max}-U_{min})\) always holds.

An optimal NE is an NE optimizing an objective function \(g(x)\) over the space of NEs, where \(g(x)\) is a linear objective function3 and could be maximizing social welfare, maximizing the expected utilities of one player or several players, maximizing the minimum utility among players, minimizing the support sizes of the NE strategies, and so on. Unfortunately, finding an optimal NE optimizing the above objectives is NP-hard [9].

Footnote 3: If \(g(x)\) is nonlinear, we can use a variable (i.e., a linear function) \(v\) as the new objective with the constraint such that \(v=g(x)\).

## 3 Computing Optimal Nash Equilibria

The problem of finding an optimal NE in multiplayer games requires optimizing an objective over the space of NEs. This space is represented by Eq.(1), which involves nonlinear terms in Eq.(1a) to represent the strategies of players in \(-i\), which is bilinear when \(n=3\) and is multilinear when \(n\geq 4\). The multilinear program is usually transformed into a bilinear program to make the program solvable using global optimization solvers, e.g., Gurobi [19]. Here, we propose a general framework for this transformation based on a set of correlation plans for any binary collection of subsets of players, where each set in this collection is divided into two disjoint sets, and each correlation plan corresponds to a set of auxiliary variables representing a set of bilinear terms. However, there are two challenges for solving this bilinear program: 1) this bilinear program usually involves a large number of bilinear terms, and 2) an important step used by state-of-the-art algorithms to solve such bilinear programs is to use convex relaxation to replace each bilinear term in the program [15; 18], which significantly enlarges the feasible solution space. To overcome these challenges, we develop a novel algorithm called **CRM** that uses **C**orrelation plans with their **R**elations to strictly reduce the feasible solution space after the convex relaxation while **M**inimizing the number of correlation plans to reduce the number of bilinear terms. Section 3.4 shows that our techniques can significantly reduce the time complexity. The procedure of CRM is shown in Algorithm 2, which is illustrated in Appendix A.

### A General Transformation Framework

A correlation plan is a probability distribution over the joint action space of a subset of players, and we focus on correlation plans for certain special collections of subsets of players, which can be used to transform a multilinear program for computing optimal NEs into a bilinear program.

**Definition 1**.: _A collection \(\mathcal{N}\) of subsets of players is a **binary collection** if:_

1. \(\{-i\mid i\in N\}\subseteq\mathcal{N}\)_;_
2. _for each_ \(N^{\prime}\in\mathcal{N}\)_,_ \(N^{\prime}\subset N\) _with_ \(|N^{\prime}|\geq 2\)_; and_
3. _for each_ \(N^{\prime}\in\mathcal{N}\)_, there are two disjoint children_ \(N^{\prime}_{l}\) _and_ \(N^{\prime}_{r}\) _in_ \(\{\{i\}\mid i\in N\}\cup\mathcal{N}\) _such that_ \(N^{\prime}_{l}\cap N^{\prime}_{r}=\emptyset\) _and_ \(N^{\prime}=N^{\prime}_{l}\cup N^{\prime}_{r^{\prime}}\)_, i.e.,_ \(N^{\prime}\) _is divided into two disjoint sets._

_Let \(N^{\prime}_{l}\) and \(N^{\prime}_{r}\) be the left child and the right child of \(N^{\prime}\in\mathcal{N}\), respectively. For each \(N^{\prime}\) in any binary collection \(\mathcal{N}\), a **correlation plan** of \(N^{\prime}\) is a probability distribution \(x_{N^{\prime}}\) over \(A_{N^{\prime}}\): given \(x_{N^{\prime}}(a_{N^{\prime}})\in[0,1]\) (\(\forall a_{N^{\prime}}\in A_{N^{\prime}},N^{\prime}\in\mathcal{N}\)),_

\[\sum_{a_{N^{\prime}}\in A_{N^{\prime}}}x_{N^{\prime}}(a_{N^{\prime}})=1\quad \forall N^{\prime}\in\mathcal{N}.\] (2)

For simplification, let \(i\) be equivalent to \(\{i\}\) for each \(i\in N\). That is, \(x_{i}\) is a special correlation plan \(x_{\{i\}}\) (i.e., \(x_{i}=x_{\{i\}}\)), \(a_{i}\in A_{i}\) is a special joint action \(a_{\{i_{j}\}}\in A_{\{i\}}\) (i.e., \(a_{i}=a_{\{i_{1}\}}\)). Each element \(N^{\prime}\) in a binary collection \(\mathcal{N}\) has the binary division, i.e., it is divided into two disjoint sets \(N^{\prime}_{l}\) and \(N^{\prime}_{r^{\prime}}\). Based on this binary division, any joint action \(a_{N^{\prime}}\in A_{N^{\prime}}\) can be divided into two sub-joint actions \(a_{N^{\prime}_{l}}\in A_{N^{\prime}_{l}}\) and \(a_{N^{\prime}_{r}}\in A_{N^{\prime}_{r}}\) such that \(a_{N^{\prime}_{l}}=(a_{N^{\prime}_{l}},a_{N^{\prime}_{r}})\). Then we can use this binary division to ensure that \(\prod_{j\in N^{\prime}}x_{j}(a_{N^{\prime}}(j))=x_{N^{\prime}}(a_{N^{\prime}})\) for the correlation plan \(x_{N^{\prime}}\), as shown in Example 1.

**Example 1**.: \(\{\{1,2,3\},\{1,2,4\},\{1,3,4\},\{2,3,4\},\{1,2\},\{1,3\},\{2,3\},\{1,4\},\{3,4 \},\{2,4\}\}\) _is a binary collection for a four-player game. For \(N^{\prime}=\{1,2,3\}\) in this collection with \(N^{\prime}_{l}=\{1,2\}\) (having two children \(\{1\}\) and \(\{2\}\)) and \(N^{\prime}_{r}=\{3\}\), we have \(a_{N^{\prime}}=(a_{1},a_{2},a_{3})=(a_{\{1,2\}},a_{3})\in A_{N^{\prime}}\) and \(a_{\{1,2\}}=(a_{1},a_{2})\in A_{\{1,2\}}\). Then we can have a chain of bilinear constraints (equalities): \(x_{N^{\prime}}(a_{N^{\prime}})=x_{\{1,2\}}(a_{\{1,2\}})x_{3}(a_{3})\) and \(x_{\{1,2\}}(a_{\{1,2\}})=x_{1}(a_{1})x_{2}(a_{2})\), which guarantees that \(x_{N^{\prime}}(a_{N^{\prime}})=x_{1}(a_{1})x_{2}(a_{2})x_{3}(a_{3})\). In other words, we use \(x_{\{1,2\}}(a_{\{1,2\}})\) and \(x_{N^{\prime}}(a_{N^{\prime}})\) as the auxiliary variables to represent bilinear terms \(x_{1}(a_{1})x_{2}(a_{2})\) and \(x_{\{1,2\}}(a_{\{1,2\}})x_{3}(a_{3})\), respectively._

This property of correlation plans of a binary collection \(\mathcal{N}\) can be used to transform the multilinear Program (1) into a bilinear program. First, we use the binary division of each element \(N^{\prime}\) in \(\mathcal{N}\) to connect correlation plans, i.e., for any \(N^{\prime}\in\mathcal{N}\) with its children \(N^{\prime}_{l}\) and \(N^{\prime}_{r}\):

\[x_{N^{\prime}}(a_{N^{\prime}})\!=\!x_{N^{\prime}_{l}}(a_{N^{ \prime}_{l}})x_{N^{\prime}_{r}}(a_{N^{\prime}_{r}})\quad\forall a_{N^{\prime}}\! =\!(a_{N^{\prime}_{l}},a_{N^{\prime}_{r}})\!\in\!A_{N^{\prime}}\] (3a) \[x_{N^{\prime}}(a_{N^{\prime}})\in[0,1]\quad\forall a_{N^{\prime}} \in A_{N^{\prime}}.\] (3b)

Second, we replace \(\prod_{j\in-i}x_{j}(a_{-i}(j))\) in Eq.(1a) with \(x_{-i}(a_{-i})\):

\[u_{i}(a_{i},x_{-i})\!=\!\sum_{a_{-i}\in A_{-i}}\!\!u_{i}(a_{i},a_{-i})x_{-i}(a_{ -i})\quad\forall i\in N,a_{i}\in A_{i}.\] (4)

In the above transformation, each correlation plan corresponds to a set of auxiliary variables (e.g., \(x_{N^{\prime}}(a_{N^{\prime}})\)) representing a set of bilinear terms (e.g., \(x_{N^{\prime}_{l}}(a_{N^{\prime}_{l}})x_{N^{\prime}_{r}}(a_{N^{\prime}_{r}})\)). Eq.(3) guarantees that \(\prod_{j\in N^{\prime}}x_{j}(a_{N^{\prime}}(j))=x_{N^{\prime}}(a_{N^{\prime}})\), and then the feasible solution space of Eqs.(1b)-(1g), (3), and (4) represents the space of NEs.

**Theorem 1**.: _The feasible solution space of mixed strategies (i.e., \(x_{i}(a_{i})\) for each \(i\in N\), \(a_{i}\in A_{i}\)) in Eqs.(1b)-(1g), (3), and (4) is the space of NEs. (Proofs are in Appendix B.)_We can then compute an optimal NE by solving the following mixed-integer bilinear program according to any binary collection \(\mathcal{N}\):

\[\max_{x}g(x)\] (5a) \[\text{s.t. Eqs.}(1b)-(1g),(3),(4).\] (5b)

It is straightforward to solve Program (5) by using the **vanilla binary collection**\(\overline{\mathcal{N}}\) that includes all non-singleton proper subsets of \(N\), i.e., \(\overline{\mathcal{N}}=\{N^{\prime}\mid N^{\prime}\subset N,|N^{\prime}|\geq 2\}\), where, for each \(N^{\prime}\in\overline{\mathcal{N}}\), \(N^{\prime}_{l}\) is \(N^{\prime}\setminus\{j\}\) and \(N^{\prime}_{r}\) is \(\{j=\max_{i\in N^{\prime}}i\}\). Example 1 provides an example of \(\overline{\mathcal{N}}\).

### Exploit Correlation Plans with Their Relations

In this section, we use correlation plans with their relations to restrict the feasible solution space after the convex relaxation. The common convex relaxation technique [27; 35; 18] before searching for the optimal solution is: each bilinear term \(x_{N^{\prime}}(a_{N^{\prime}})=y_{1}y_{2}\) with \(y_{1},y_{2}\in[0,1]\) is represented by the following constraints including four linear constraints:

\[\max\{0,y_{1}+y_{2}-1\}\leq x_{N^{\prime}}(a_{N^{\prime}})\leq \min\{y_{1},y_{2}\},\] (6)

which significantly enlarges the feasible solution space. We now show the motivation to use correlation plans with their relations to reduce this feasible solution space.

**Example 2**.: _Given \(N^{\prime}=\{2,4\}\subset N\) with two actions for each player (i.e., \(A_{i}=\{a_{i},a^{\prime}_{i}\}\)) in a game \(G\), by Eq.(6), bilinear terms (e.g., \(x_{N^{\prime}}(a_{2},a_{4})=x_{2}(a_{2})x_{4}(a_{4})\)) are relaxed according to Eq.(6), e.g., \(\max\{0,x_{2}(a_{2})+x_{4}(a_{4})-1\}\leq x_{N^{\prime}}(a_{2},a_{4})\leq\min \{x_{2}(a_{2}),x_{4}(a_{4})\}\). With additional constraints by Eq.(1b) (e.g., \(x_{4}(a_{4})+x_{4}(a^{\prime}_{4})=1\)), the following assignment could be a feasible solution:_

\[x_{N^{\prime}}(a_{2},a_{4})=x_{N^{\prime}}(a^{\prime}_{2},a_{4}) =x_{N^{\prime}}(a_{2},a^{\prime}_{4})=x_{N^{\prime}}(a^{\prime}_{2},a^{\prime }_{4})\] (7) \[= x_{2}(a_{2})=x_{2}(a^{\prime}_{2})=x_{4}(a_{4})=x_{4}(a^{\prime }_{4})=0.5.\]

_Obviously, in Eq.(7), \(x_{N^{\prime}}(a_{2},a_{4})\) is not equal to \(x_{2}(a_{2})x_{4}(a_{4})\). In fact, based on Eq.(2), we have:_

\[x_{N^{\prime}}(a_{2},a_{4})+x_{N^{\prime}}(a^{\prime}_{2},a_{4}) +x_{N^{\prime}}(a_{2},a^{\prime}_{4})+x_{N^{\prime}}(a^{\prime}_{2},a^{\prime }_{4})=1,\] (8)

_which will make the solution in Eq.(7) infeasible. Moreover, the following assignment is a feasible solution after the relaxation and satisfies Eq.(8):_

\[x_{N^{\prime}}(a_{2},a_{4})=x_{N^{\prime}}(a^{\prime}_{2},a_{4}) =x_{N^{\prime}}(a_{2},a^{\prime}_{4})=0.2,\] (9) \[x_{N^{\prime}}(a^{\prime}_{2},a^{\prime}_{4}) =0.4,x_{2}(a_{2})=x_{4}(a_{4})=0.5.\]

_However, in Eq.(9), \(x_{N^{\prime}}(a_{2},a_{4})\) is still not equal to \(x_{2}(a_{2})x_{4}(a_{4})\). Actually, we have:_

\[x_{N^{\prime}}(a_{2},a_{4})+x_{N^{\prime}}(a^{\prime}_{2},a_{4}) =x_{4}(a_{4}),\] (10) \[x_{N^{\prime}}(a_{2},a^{\prime}_{4})+x_{N^{\prime}}(a^{\prime}_{ 2},a^{\prime}_{4}) =x_{4}(a^{\prime}_{4}),\]

_which will make the solution in Eq.(9) infeasible._

This above example shows that we can use the definition of a correlation plan (i.e., Eq.(2)) and the relation of correlation plans to reduce the feasible solution space after the relaxation.

Each element \(N^{\prime}\) in any binary collection \(\mathcal{N}\) is defined by \(N^{\prime}_{l}\) and \(N^{\prime}_{r}\), which actually defines relations between correlation plans for elements in \(\{\{i\}\mid i\in N\}\cup\mathcal{N}\). In Example 2, Eq.(10) actually represents a relation between the correlation plan \(x_{N^{\prime}}\) and the mixed strategy \(x_{4}\) (i.e., the special correlation plan \(x_{\{4\}}\)). Formally, for any \(N^{\prime}\in\mathcal{N}\) and \(i\in N^{\prime}\):

\[\sum_{a_{N^{\prime}}\in A_{N^{\prime}},a_{N^{\prime}}(i)=a_{i}}x_{N^{\prime}}(a _{N^{\prime}})\!=x_{i}(a_{i})\quad\forall a_{i}\in A_{i},\] (11)

where \(a_{N^{\prime}}(i)\) is the action of player \(i\in N^{\prime}\) in the joint action \(a_{N^{\prime}}\). Similarly, let \(a_{N^{\prime}}(N^{\prime\prime})\) be the sub-joint action of player \(N^{\prime\prime}\subset N^{\prime}\) in the joint action \(a_{N^{\prime}}\). Then, for any \(N^{\prime}\in\mathcal{N}\) with its children \(N^{\prime}_{l}\) and \(N^{\prime}_{r}\), and \(N^{\prime\prime}\in\{N^{\prime}_{l},N^{\prime}_{r}\}\):

\[\sum_{a_{N^{\prime}}\in A_{N^{\prime}},a_{N^{\prime\prime}}(N^{\prime\prime})=a_{ N^{\prime\prime}}}x_{N^{\prime}}(a_{N^{\prime}})\!=x_{N^{\prime\prime}}(a_{N^{ \prime\prime}})\quad\forall a_{N^{\prime\prime}}\!\in\!A_{N^{\prime\prime}}\] (12)

[MISSING_PAGE_EMPTY:6]

To overcome this challenge, we propose building a minimum-height binary tree for each element in \(\{-i\mid i\in N\}\) and ensuring that the number of internal nodes in these binary trees is the minimum. The binary division for each element in a binary collection \(\mathcal{N}\) creates a binary tree for each element in \(\{-i\mid i\in N\}\). For example, Figure 1(a) is a binary tree for \(-5=\{1,2,3,4\}\), and Figure 1(b) is a binary tree for \(-3=\{1,2,5,4\}\) in five-player games. Each binary tree for \(-i\) is a full binary tree, i.e., each internal node has two children, with \(n-2\) internal nodes and \(n-1\) leaf nodes, where the height is the number of internal nodes on the longest path from the root to a leaf (e.g., the height in Figure 1(a) is 2). Details for these binary trees are shown in Appendix D. We can then build a full binary tree \(T_{-n}\) with the minimum height \(\lceil\log_{2}(n-1)\rceil\) for \(-n\) and then replace \(i\) with \(n\) in the nodes of \(T_{-n}\) to obtain \(T_{-i}\) for each \(i\in-n=\{1,\ldots,n-1\}\). That creates \(n\) full binary trees for \(\{-i\mid i\in N\}\). This procedure is shown in Algorithm 1 (details are shown in Appendix D), generating our **minimum binary collection**\(\mathcal{N}\) including all internal nodes in these trees. For example, Figure 1(a) builds a binary tree \(T_{-5}\), and Figure 1(b) obtains \(T_{-3}\) by replacing \(3\) with \(5\) in \(T_{-5}\). Generally, we only need to create at most \(\lceil\log_{2}(n-1)\rceil\) new internal nodes to build a minimum-height binary tree for each \(-i\) with \(i\in-n\). Then \(|\underline{\mathcal{N}}|\) is at most \(n-2+(n-1)\lceil\log_{2}(n-1)\rceil\), i.e., \(O(n\log n)\).

**Theorem 4**.: \(\mathcal{N}\) _generated by Algorithm 1 is a binary collection, and \(O(n\log n)\) for the size of \(\underline{\mathcal{N}}\) is the minimum size of all binary collections of a game \(G\). (Proofs are in Appendix B.)_

\(|\underline{\mathcal{N}}|\) only grows sub-quadratically with \(n\) and is much smaller than \(|\overline{\mathcal{N}}|=2^{n}-(n+2)\) for \(\overline{\mathcal{N}}\). Then \(\underline{\mathcal{N}}\) requires fewer bilinear terms than \(\overline{\mathcal{N}}\) when \(n>3\). For example, in a seven-player game with two actions for each player, by using \(\underline{\mathcal{N}}\) with \(|\underline{\mathcal{N}}|=21\) correlation plans, the number of bilinear terms is 564, which is much smaller than 2044 by using \(\overline{\mathcal{N}}\) with \(|\overline{\mathcal{N}}|=119\) correlation plans. Table 3 of Appendix G shows more examples. Note that Algorithm 1 cannot reduce the number of internal nodes when \(n=3\) because each element in \(\{-i\mid i\in N\}\) includes only two players in three-player games. Our algorithm, CRM, is solving Program (13) based on \(\underline{\mathcal{N}}\), which is shown in Algorithm 2 and is illustrated in Appendix A.

### Complexity

The problem of finding an optimal NE is NP-hard [9], and our algorithm, CRM, i.e., Program (13) based on \(\underline{\mathcal{N}}\) generated by Algorithm 1, is a mixed-integer bilinear program, whose scalability is mainly affected by the number of bilinear terms and integer variables. Generally, the problem of solving a linear integer program is NP-hard, and the time complexity is \(O(I^{2}(EC^{2})^{2E+3})\)[32], where \(I\) is the number of integer variables, \(E\) is the number of constraints containing integer variables, and \(C\) is the maximum value among constants and the range of integer variables in these constraints. Theoretically, each bilinear term can be represented by a mixed-integer linear program by introducing a new set of constraints and binary integer variables [21]. Suppose each bilinear term introduces \(I^{\prime}\) integer variables and \(E^{\prime}\) constraints, and each player has \(m\) actions. Program (5) based on \(\overline{\mathcal{N}}\) has \(mn\) binary integer variables with \(mn\) constraints and the following number of bilinear terms:

\[\sum_{N^{\prime}\in\overline{N}}\prod_{i\in N^{\prime}}|A_{i}|\leq(2^{n}-n-2)m ^{n-1}\leq 2^{n}m^{n-1}.\]

Then the time complexity for solving the Program (5) based on \(\overline{\mathcal{N}}\) is \(O(I_{1}^{2}(E_{1}C^{2})^{2E_{1}+3})\) where \(I_{1}=2^{n}m^{n-1}I^{\prime}+mn\) and \(E_{1}=2^{n}m^{n-1}E^{\prime}+mn\). Program (13) based on \(\underline{\mathcal{N}}\) has \(mn\) binary

Figure 1: Binary trees for \(-5\) and \(-3\)

integer variables with \(mn\) constraints and the following number of bilinear terms:

\[\sum_{N^{\prime}\in\not\in\not\Lambda}\prod_{i\in N^{\prime}}|A_{i}|\leq|\not \Lambda|m^{n-1},\]

i.e., \(O((n\log n)m^{n-1})\) bilinear terms (this size is the minimum because \(O(n\log n)\) is the minimum size of binary collections by Theorem 4) and. Then the time complexity for solving Program (13) based on \(\not\)\(\mathcal{N}\) is \(O(I_{2}^{2}(E_{2}C^{2})^{2E_{2}+3})\) where \(I_{2}=(n\log n)m^{n-1}I^{\prime}+mn\) and \(E_{2}=(n\log n)m^{n-1}E^{\prime}+mn\), and thus \(O(n\log n)\) of Algorithm 1 can be ignored. Therefore, CRM dramatically reduces the time complexity (i.e., the term \(2^{n}\) in \(I_{1}\) and \(E_{1}\) is changed to the term \(n\log n\) in \(I_{2}\) and \(E_{2}\)).

## 4 Experiments

Following prior work for NEs [34; 4; 13], we evaluate our approach on two sets of games: randomly generated games (i.e., \((n,m)\) with \(n\) players and \(m\) actions for each player) and six-player three-action games that are generated by GAMUT [31]. Payoffs are generated from the interval between 0 and 100 (other ranges (e.g., \([0,1]\)) do not affect the result). Details are shown in Appendix F. We show the game size in terms of the number of bilinear terms and integer variables in Appendix G, e.g., the number of bilinear terms in the game \((9,2)\) is 19152 based on \(\not\)\(\mathcal{N}\) but is 2512 based on \(\not\)\(\mathcal{N}\).

**Baselines:** We compare our CRM4 shown in Algorithm 2, i.e., solving Program (13) based on \(\not\)\(\mathcal{N}\), to the state-of-the-art algorithms: i) **MIBP**[34; 13]: the equivalent of solving Program (5) based on \(\not\)\(\mathcal{N}\); ii) **EXCLUSION**[4]: the first implemented algorithm guarantees to converge to an NE by using a tree-search based method by splitting the continuous probability space of the solution; and iii) **ENUMPOLY**[28]: an algorithm in the well-known game-solving package Gambit which

\begin{table}
\begin{tabular}{c c|c c c c c} \hline \multicolumn{2}{c|}{Random Game} & \multicolumn{3}{c}{Runtime \(\pm\) 95\% Confidence Interval (Percentage of Games not Solved) (Utility Gap)} \\ \hline Vary & \((n,m)\) & CRM & MIBP & ENUMPOLY & EXCLUSION \\ \hline \multirow{3}{*}{\(n\)} & (3, 2) & **0.01**\(\pm\)**0 & 0.02 \(\pm\) 0 & 0.03 \(\pm\) 0.01 & 31 \(\pm\) 4 (gap:15\%) \\  & (5, 2) & **0.2**\(\pm\)**0.1 & 0.5 \(\pm\) 0.4 & 11 \(\pm\) 4 & 753 \(\pm\) 148 (73\%) (gap:64\%) \\  & (7, 2) & **25**\(\pm\)**17 & 429 \(\pm\) 131 (20\%) & 1000 \(\pm\) 0 (97\%) & 835 \(\pm\) 119 (80\%) (gap:53\%) \\ \hline \multirow{3}{*}{\(m\)} & (3, 5) & **0.2**\(\pm\)**0.03 & 0.3 \(\pm\)0.1 & 1000 \(\pm\) 0 (100\%) & 1000 \(\pm\) 0 (100\%) (gap:67\%) \\  & (3, 8) & **4**\(\pm\)**3 & 247 \(\pm\) 140 (17\%) & 1000 \(\pm\) 0 (100\%) & 1000 \(\pm\) 0 (100\%) (gap:oc) \\ \cline{1-1}  & (3, 10) & **9**\(\pm\)**9 & 334 \(\pm\) 167 (30\%) & 1000 \(\pm\) 0 (100\%) & 1000 \(\pm\) 0 (100\%) (gap:oc) \\ \cline{1-1}  & (3, 13) & **38**\(\pm\)**21 & 342 \(\pm\) 151 (27\%) & 1000 \(\pm\) 0 (100\%) & 1000 \(\pm\) 0 (100\%) (gap:oc) \\ \hline GAMUT Game & CRM & MIBP & ENUMPOLY & EXCLUSION \\ \hline Random LEG & **2**\(\pm\)**1 & 1000 \(\pm\) 0 (100\%) & 1000 \(\pm\) 0 (100\%) & 986 \(\pm\) 27 (97\%) (gap:11\%) \\ Random graphical & **0.1**\(\pm\)**0.1 & 803 \(\pm\) 140 (83\%) & 50 \(\pm\) 30 & 971 \(\pm\) 55 (97\%) (gap:32\%) \\ Uniform LEG & **2.2**\(\pm\)**1 & 1000 \(\pm\) 0 (100\%) & 1000 \(\pm\) 0 (100\%) & 986 \(\pm\) 26 (97\%) (gap:11\%) \\ \hline \end{tabular}
\end{table}
Table 1: Part of experimental results (more results are in Tables 4 and 5 of Appendix H). The format is: Average Runtime \(\pm\) 95% Confidence Interval (Percentage of Games not Solved within the Time Limit) (Utility Gap). Note that the unit of the runtime is second, the case that all games have been solved with the time limit should be (\(0\%\)) and is omitted, we only need to care about the utility gap (a larger gap means losing more) for EXCLUSION, and the utility gap \(\infty\) represents EXCLUSION cannot return a solution within the time limit.

\begin{table}
\begin{tabular}{l|l l l l l l} \hline Game & \multicolumn{3}{c}{Runtime \(\pm\) 95\% Confidence Interval (Percentage of Games not Solved)} \\ \hline (8, 2) & **156\(\pm\) 83 (3\%)** & 612\(\pm\) 129 (33\%) & 190 \(\pm\) 102 (7\%) & 763 \(\pm\) 120 (60\%) & 1000 \(\pm\) 0 (100\%) \\ (7, 2) & **25**\(\pm\)**17 & 89 \(\pm\) 51 & 36 \(\pm\) 28 & 408 \(\pm\) 157 (30\%) & 488 \(\pm\) 111 (10\%) \\ (3, 15) & **167\(\pm\) 86 (3\%)** & 167 \(\pm\) 86 (3\%) & 317 \(\pm\) 137 (17\%) & 317 \(\pm\) 137 (17\%) & 558 \(\pm\) 150 (40\%) \\ (3, 17) & **231\(\pm\)122 (10\%)** & 231 \(\pm\)122 (10\%) & 326 \(\pm\) 134 (20\%) & 326 \(\pm\) 134 (20\%) & 784 \(\pm\) 102 (53\%) \\ Random graphical & **0.1**\(\pm\)**0.1 & 0.4 \(\pm\) 0.1 & 0.2 \(\pm\) 0.1 & 0.6 \(\pm\) 0.4 & 814 \(\pm\) 134 (80\%) \\ Uniform LEG & **2.2**\(\pm\)**1 & 5 \(\pm\) 4 & 2.5 \(\pm\) 2 & 5 \(\pm\) 5 & 999 \(\pm\) 2 (97\%) \\ \hline \end{tabular}
\end{table}
Table 2: Ablation study (more results are in Table 6 of Appendix H). Note that \(\not\)\(\mathcal{N}\) (in CR and C) and \(\not\)\(\mathcal{N}\) (in CRM, CM, and M) result in the same bilinear terms in three-player games because each element in \(\{-i\mid i\in\{1,2,3\}\}\) includes only two players such that Algorithm 1 cannot reduce the number of internal nodes to reduce the number of bilinear terms, and then CR and CRM (or C and CM) have the same performance. The unit of the runtime is second.

tries to find all NEs by enumerating all the supports which could be the support of an NE and then searching for an equilibrium on that support. They represent approaches to solving a nonlinear program, finding an NE, and enumerating all Nash equilibria, respectively. There are some other algorithms in Gambit [28] for finding an NE in a multiplayer game, including: i) **GNM**[16]: a global Newton method approach; ii) **IPA**[17]: an iterated polymatrix approximation approach; iii) **LIAP**: a function minimization approach; iv) **SIMPDIV**[41]: a simplicial subdivision approach; and v) **LOGIT**[29; 40]: a quantal response method. However, they cannot guarantee finding an NE [4]. Therefore, they are not suitable for finding an optimal NE. In fact, we show in Appendix I that all of them fail to solve many games and even run significantly slower than CRM in many games. Note that these Gambit algorithms only achieve some NE if the game is solved, which may not be optimal.

**Algorithm Setting and Metric:** We set a time limit of 1000 seconds for each case unless stated otherwise. Our optimality gap for EXCLUSION is significantly smaller than 0.001 in [4] (we verified that, with the same optimality gap, our result for EXCLUSION is almost the same as the one in [4]). We mainly use the runtime and the percentage of games that are not solved within the time limit to measure the performance of our approach. Details are shown in Appendix F (also caption of Table 1).

**Result:** Part of results are shown in Table 1, and more results are in Tables 4 and 5 of Appendix H. They show that the runtime of our CRM steadily increases with the game size. Note that the runtime of CRM includes the runtime for our Algorithm 1, which is extremely small (see Appendix E). Moreover, CRM is significantly faster than the baselines and is two or three orders of magnitude faster than the state-of-art baselines MIBP, ENUMPOLY, and EXCLUSION in most games. The reasons are that: 1) MIBP with too many bilinear terms and large feasible solution space after the relaxation cannot perform well without CRM's novel techniques in Section 3, where each of these techniques significantly boosts the performance (see the ablation study); and 2) the exponentially many NEs and the large search space caused by splitting the continuous probability space make ENUMPOLY and EXCLUSION, respectively, hard to scale up. EXCLUSION always has large utility gaps, which means that we will lose large utilities if we use EXCLUSION for our problem. The result that CRM runs significantly faster than EXCLUSION means that CRM is a faster algorithm not only for computing an optimal NE but also for just computing an NE. Furthermore, the gap between CRM and any of the baselines increases with the number of players or actions. In games with a large gap between CRM and baselines, the real gap should be larger because these baselines have not solved all of them within the time limit, while CRM solved all of them. Overall, CRM significantly overcomes the limitation of baselines.

**Ablation Study**: We evaluate each component of CRM by using the following variants: i) **CR**: solving Program (13) based on \(\overline{\mathcal{N}}\); ii) **CM**: solving Program (13) based on \(\underline{\mathcal{N}}\) without the relation constraints Eqs.(11) and (12); iii) **C**: solving Program (13) based on \(\overline{\mathcal{N}}\) without the relation constraints Eqs.(11) and (12); and iv) **M**: solving Program (5) based on \(\underline{\mathcal{N}}\). Part of results are in Table 2, and more results are in Table 6 of Appendix H. We can see that each component of our approach significantly boosts its performance.

## 5 Related Work

Existing works define a correlation plan as a probability distribution over the joint action space of all players, and use it to formulate constraints for a correlated equilibrium [37; 1]. However, the constraints for the space of correlated equilibria cannot be used in our program due to the following two reasons. First, there are no correlation plans for coordinating all players in our program after the convex relaxation because our formulation based on [34] has reduced the degree of the multilinear program for the space of NEs in order to significantly reduce the number of bilinear terms. Second, our correlation plans are different from the correlation plan for correlated equilibria because our correlation plans are only for subsets of the players. Recently, the correlation plan [49] based on a decomposition of the extensive-form game into public states has been used to compute correlated equilibria. However, their approach is not suitable for our problem because our game is not extensive-form and then does not have the property of their problem. Then our approach exploiting the relations of correlation plans and minimizing the number of correlation plans is novel.

Several recent efforts have developed relatively efficient algorithms to find an NE that maximizes the utility of a team of players in zero-sum games [45; 50; 51; 52; 11; 24; 53]. However, these algorithms cannot be used in games where team members have different utility functions. Existingworks transforming multilinear terms into bilinear terms only focus on special cases. For example, the transformation in [13] is equivalent to our transformation based on \(\overline{\mathcal{N}}\), which is only a special case of our transformation framework. They [13] then directly solves the bilinear program based on this special transformation for finding an NE, which is equivalent to our baseline MIBP. Experiments show that our approach with novel techniques in Section 3 significantly outperforms [13]. Similar to the formulation in [34], there are other formulations [2; 3] for finding an optimal NE for two players under the problem of computing a leader-follower (Stackelberg) equilibrium for a single leader and two followers after a mixed strategy is committed by the leader. These formulations are different from ours because of the difference between the NE and the Stackelberg equilibrium. For example, the leader will commit a strategy to the followers in a Stackelberg equilibrium, i.e., the followers know the leader's strategy, but this cannot happen in an NE as all players move simultaneously. Moreover, after dropping the dependences of the followers to the leader's strategies in these bilinear programming formulations, the problem boils down to computing an optimal NE in two-player games because they only consider two followers in their formulations, which results in the same two-player formulation of [34].

For the existing general optimization techniques, e.g., Reformulation-Linearization Technique (RLT) [35; 25; 36], they add linear constraints by multiplying linear constraints with a single variable to reduce the feasible solution space of the convex relaxation and the number of bilinear terms if they can be represented by linear constraints (i.e., variants of original linear constraints). However, these operations are not very effective for our problem because the bilinear terms cannot be represented by those linear constraints (i.e., variants of original linear constraints), and simply multiplying linear constraints with a single variable cannot effectively represent the relation between auxiliary variables and nonlinear terms. Indeed, RLT is implemented in Gurobi [18; 19], but its performance (see MIBP in Table 1) is not good enough for large games in experiments. Moreover, our approach significantly outperforms the state-of-the-art optimization solver Gurobi (see results for CRM versus MIBP in Table 1) in experiments.

## 6 Limitations

Similarly to the previous literature [34; 4; 13], to efficiently evaluate the algorithms, we set a time limit of 1000 seconds for each case unless stated otherwise. It means that we may need 30,000 seconds (almost 8 hours) to run an algorithm for each game setting (e.g., the game \((6,3)\)) with 30 cases. We totally run 13 algorithms for 21 different game settings, whose total runtime is more than 2,000 hours if each algorithm needs 30,000 seconds for each game setting. A higher time limit means more runtime. For example, if the time limit is 10,000s, we may need 20, 000 hours (more than 800 days), which is not reasonable for a personal computer. Increasing the game size will cause a similar problem as well. Our goal is only to show that our proposed algorithm runs faster than baselines. Therefore, as a proof of concept, our time limit and game size are reasonable and practical.

Our algorithm CRM is significantly faster than the state-of-the-art baseline, and it can solve many real-world games: e.g., (1) multiplayer hand games using only the hands of the players (https://en.m.wikipedia.org/wiki/Hand_game), including the rock-paper-scissors games, Morra games, and their variants; and (2) the matching pennies game with several players and only two actions for each player. However, we cannot handle extremely large games now because we are handling a very hard problem, and then it is unrealistic to expect that our exact algorithm CRM could run very fast in large games. Our algorithm is an attempt to make this computation of optimal NEs feasible, and our algorithm framework can be built on by further innovative heuristics to improve the computation of optimal NEs. That is, for games with more players or actions, we can exploit the auxiliary speed-up techniques: the multiagent learning framework--Policy-Spaced Response Oracles (PSRO) [22; 54; 55; 51; 46; 23], the abstraction techniques [47], or only considering approximate NEs. Specifically, our algorithm CRM could be used as the meta-solver in PSRO.

## 7 Conclusion

This paper proposes a novel algorithm (CRM) for computing optimal NEs based on our transformation framework. CRM uses correlation plans with their relations to strictly reduce the feasible solution space after the convex relaxation while minimizing the number of correlation plans to significantly reduce the number of bilinear terms. Experiments show that CRM significantly outperforms baselines.

## Acknowledgments and Disclosure of Funding

This research is supported by the InnoHK Fund, ONR grants N00014-18-1-2670, and N00014-20-1-2407. Bo An is supported by the National Research Foundation, Singapore under its Industry Alignment Fund - Pre-positioning (IAF-PP) Funding Initiative. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not reflect the views of National Research Foundation, Singapore.

## References

* [1] Robert J Aumann. Subjectivity and correlation in randomized strategies. _Journal of mathematical Economics_, 1(1):67-96, 1974.
* [2] Nicola Basilico, Stefano Coniglio, Nicola Gatti, and Alberto Marchesi. Bilevel programming approaches to the computation of optimistic and pessimistic single-leader-multi-follower equilibria. In _SEA_, volume 75, pages 1-14, 2017.
* [3] Nicola Basilico, Stefano Coniglio, Nicola Gatti, and Alberto Marchesi. Bilevel programming methods for computing single-leader-multi-follower equilibria in normal-form and polymatrix games. _EURO Journal on Computational Optimization_, 8(1):3-31, 2020.
* [4] Kimmo Berg and Tuomas Sandholm. Exclusion method for finding Nash equilibrium in multiplayer games. In _AAAI_, pages 383-389, 2017.
* [5] Noam Brown and Tuomas Sandholm. Safe and nested subgame solving for imperfect-information games. In _NeurIPS_, 2017.
* [6] Noam Brown and Tuomas Sandholm. Superhuman AI for heads-up no-limit poker: Libratus beats top professionals. _Science_, 359(6374):418-424, 2018.
* [7] Yang Cai and Constantinos Daskalakis. On minmax theorems for multiplayer games. In _SODA_, pages 217-234, 2011.
* [8] Xi Chen and Xiaotie Deng. 3-Nash is PPAD-complete. In _Electronic Colloquium on Computational Complexity_, volume 134, pages 2-29, 2005.
* [9] Vincent Conitzer and Tuomas Sandholm. Complexity results about Nash equilibria. In _IJCAI_, pages 765-771, 2003.
* [10] Helene Fargier, Paul Jourdan, and Regis Sabbadin. A path-following polynomial equations systems approach for computing Nash equilibria. In _AAMAS_, pages 418-426, 2022.
* [11] Gabriele Farina, Andrea Celli, Nicola Gatti, and Tuomas Sandholm. Connecting optimal ex-ante collusion in teams to extensive-form correlation: Faster algorithms and positive complexity results. In _ICML_, pages 3164-3173. PMLR, 2021.
* [12] Jiarui Gan, Edith Elkind, Sarit Kraus, and Michael Wooldridge. Mechanism design for defense coordination in security games. In _AAMAS_, pages 402-410, 2020.
* [13] Sam Ganzfried. Fast complete algorithm for multiplayer Nash equilibrium. _arXiv preprint arXiv:2002.04734_, 2021.
* [14] Itzhak Gilboa and Eitan Zemel. Nash and correlated equilibria: Some complexity considerations. _Games and Economic Behavior_, 1(1):80-93, 1989.
* [15] Ambros M Gleixner, Timo Berthold, Benjamin Muller, and Stefan Weltge. Three enhancements for optimization-based bound tightening. _Journal of Global Optimization_, 67(4):731-757, 2017.
* [16] Srihari Govindan and Robert Wilson. A global Newton method to compute Nash equilibria. _Journal of Economic Theory_, 110(1):65-86, 2003.
* [17] Srihari Govindan and Robert Wilson. Computing Nash equilibria by iterated polymatrix approximation. _Journal of Economic Dynamics and Control_, 28(7):1229-1241, 2004.

* [18] Gurobi. Non-convex quadratic optimization. https://pages.gurobi.com/rs/181-ZYS-005/images/2020-01-14_Non%20Convex%20Quadratic%20Optimization%20in%20Gurobi%209.0%20Webinar.pdf, 2020. Accessed: 2021-09-20.
* [19] Gurobi. Gurobi optimizer reference manual. https://www.gurobi.com/documentation/9.1/refman/index.html, 2021. Accessed: 2021-09-20.
* [20] Donald E Knuth. The Art of Computer Programming. Fundamental Algorithms, 3rd edition, volume 1, 1997.
* [21] Scott Kolodziej, Pedro M Castro, and Ignacio E Grossmann. Global optimization of bilinear programs with a multiparametric disaggregation technique. _Journal of Global Optimization_, 57(4):1039-1063, 2013.
* [22] Marc Lanctot, Vinicius Zambaldi, Audrunas Gruslys, Angeliki Lazaridou, Karl Tuyls, Julien Perolat, David Silver, and Thore Graepel. A unified game-theoretic approach to multiagent reinforcement learning. In _NeurIPS_, pages 4190-4203, 2017.
* [23] Shuxin Li, Xinrun Wang, Youzhi Zhang, Wanqi Xue, Jakub Cerny, and Bo An. Solving large-scale pursuit-evasion games using pre-trained strategies. In _AAAI_, volume 37, pages 11586-11594, 2023.
* [24] Shuxin Li, Youzhi Zhang, Xinrun Wang, Wanqi Xue, and Bo An. CFR-MIX: Solving imperfect information extensive-form games with combinatorial action space. In _IJCAI_, pages 3663-3669, 2021.
* [25] Leo Liberti. Linearity embedded in nonconvex programs. _Journal of Global Optimization_, 33(2):157-196, 2005.
* [26] Sara Marie McCarthy, Milind Tambe, Christopher Kiekintveld, Meredith L Gore, and Alex Killion. Preventing illegal logging: Simultaneous optimization of resource teams and tactics for security. In _AAAI_, pages 3880-3886, 2016.
* [27] Garth P McCormick. Computability of global solutions to factorable nonconvex programs: Part I-Convex underestimating problems. _Mathematical Programming_, 10(1):147-175, 1976.
* [28] Richard D. McKelvey, Andrew M. McLennan, and Theodore L. Turocy. Gambit: Software tools for game theory, version 16.0.1. _http://www.gambit-project.org_, 2014.
* [29] Richard D McKelvey and Thomas R Palfrey. Quantal response equilibria for normal form games. _Games and Economic Behavior_, 10(1):6-38, 1995.
* [30] John Nash. Non-cooperative games. _Annals of Mathematics_, pages 286-295, 1951.
* [31] Eugene Nudelman, Jennifer Wortman, Yoav Shoham, and Kevin Leyton-Brown. Run the GAMUT: A comprehensive approach to evaluating game-theoretic algorithms. In _AAMAS_, volume 4, pages 880-887, 2004.
* [32] Christos H Papadimitriou. On the complexity of integer programming. _Journal of the ACM (JACM)_, 28(4):765-768, 1981.
* [33] Stuart J Russell and Peter Norvig. _Artificial Intelligence: A Modern Approach_. Malaysia; Pearson Education Limited, 2016.
* [34] Tuomas Sandholm, Andrew Gilpin, and Vincent Conitzer. Mixed-integer programming methods for finding Nash equilibria. In _AAAI_, pages 495-501, 2005.
* [35] Hanif D Sherali and Amine Alameddine. A new reformulation-linearization technique for bilinear programming problems. _Journal of Global Optimization_, 2(4):379-410, 1992.
* [36] Hanif D Sherali, Evrim Dalkiran, and Leo Liberti. Reduced RLT representations for nonconvex polynomial programming problems. _Journal of Global Optimization_, 52(3):447-469, 2012.
* [37] Yoav Shoham and Kevin Leyton-Brown. _Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations_. Cambridge University Press, 2008.

* [38] David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton, et al. Mastering the game of Go without human knowledge. _Nature_, 550(7676):354-359, 2017.
* [39] Arunesh Sinha, Fei Fang, Bo An, Christopher Kiekintveld, and Milind Tambe. Stackelberg security games: Looking beyond a decade of success. In _IJCAI_, pages 5494-5501, 2018.
* [40] Theodore L Turocy. A dynamic homotopy interpretation of the logistic quantal response equilibrium correspondence. _Games and Economic Behavior_, 51(2):243-263, 2005.
* [41] Gerard van der Laan, AJJ Talman, and L Van der Heyden. Simplicial variable dimension algorithms for solving the nonlinear complementarity problem on a product of unit simplices using a general labelling. _Mathematics of Operations Research_, 12(3):377-397, 1987.
* [42] John Von Neumann and Oskar Morgenstern. _Theory of Games and Economic Behavior_. Princeton University Press, 1953.
* [43] Bernhard von Stengel. Efficient computation of behavior strategies. _Games and Economic Behavior_, 14(2):220-246, 1996.
* [44] Bernhard Von Stengel. Rank-1 games with exponentially many Nash equilibria. _arXiv preprint arXiv:1211.2405_, 2012.
* [45] Bernhard von Stengel and Daphne Koller. Team-maxmin equilibria. _Games and Economic Behavior_, 21(1-2):309-321, 1997.
* [46] Wanqi Xue, bf Youzhi Zhang, Shuxin Li, Xinrun Wang, Bo An, and Chai Kiat Yeo. Solving large-scale extensive-form network security games via neural fictitious self-play. In _IJCAI_, pages 3713-3720, 2021.
* [47] Brian Zhang and Tuomas Sandholm. Small Nash equilibrium certificates in very large games. In _NeurIPS_, 2020.
* [48] Brian Zhang and Tuomas Sandholm. Sparsified linear programming for zero-sum equilibrium finding. In _ICML_, pages 11256-11267, 2020.
* [49] Brian Hu Zhang, Gabriele Farina, Andrea Celli, and Tuomas Sandholm. Optimal correlated equilibria in general-sum extensive-form games: Fixed-parameter algorithms, hardness, and two-sided column-generation. In _EC_, pages 1119-1120, 2022.
* [50] Youzhi Zhang and Bo An. Computing team-maxmin equilibria in zero-sum multiplayer extensive-form games. In _AAAI_, pages 2318-2325, 2020.
* [51] Youzhi Zhang and Bo An. Converging to team-maxmin equilibria in zero-sum multiplayer games. In _ICML_, pages 11033-11043, 2020.
* [52] Youzhi Zhang, Bo An, and Jakub Cerny. Computing ex ante coordinated team-maxmin equilibria in zero-sum multiplayer extensive-form games. In _AAAI_, volume 35, pages 5813-5821, 2021.
* [53] Youzhi Zhang, Bo An, and V.S. Subrahmanian. Correlation-based algorithm for team-maxmin equilibrium in multiplayer extensive-form games. In _IJCAI_, pages 606-612, 2022.
* [54] Youzhi Zhang, Bo An, Long Tran-Thanh, Zhen Wang, Jiarui Gan, and Nicholas R Jennings. Optimal escape interdiction on transportation networks. In _IJCAI_, pages 3936-3944, 2017.
* [55] Youzhi Zhang, Qingyu Guo, Bo An, Long Tran-Thanh, and Nicholas R Jennings. Optimal interdiction of urban criminals with the aid of real-time information. In _AAAI_, volume 33, pages 1262-1269, 2019.
* [56] Martin Zinkevich, Michael Johanson, Michael Bowling, and Carmelo Piccione. Regret minimization in games with incomplete information. In _NeurIPS_, pages 1729-1736, 2008.

## Appendix A Illustration of CRM

In four-player games,

\[\overline{\mathcal{N}}=\{\{1,2,3\},\{1,2,4\},\{1,3,4\},\{2,3,4\},\{1,2\},\{1,3\}, \{2,3\},\{1,4\},\{3,4\},\{2,4\}\}.\]

By Algorithm 1 in CRM, we have:

\[\underline{\mathcal{N}}=\{\{1,2,3\},\{4,2,3\},\{1,4,3\},\{1,2,4\},\{1,2\},\{4, 2\},\{1,4\}\},\]

i.e., \(\underline{\mathcal{N}}=\{-4,\)\(-1,-2,-3,\{1,2\},\{2,4\},\{1,4\}\}\). To obtain this set, we first have a full binary tree \(T_{-4}\) with the set of internal nodes \(\mathcal{N}_{T_{-4}}=\{\{1,2,3\},\{1,2\}\}\). Then, for each element in \(\mathcal{N}_{T_{-4}}\), we replace \(1\) with \(4\) to obtain \(\mathcal{N}_{T_{-1}}=\{\{4,2,3\},\{4,2\}\}\); replace \(2\) with \(4\) to obtain \(\mathcal{N}_{T_{-2}}=\{\{1,4,3\},\{1,4\}\}\); and replace \(3\) with \(4\) to obtain \(\mathcal{N}_{T_{-3}}=\{\{1,2,4\},\{1,2\}\}\). Then \(\underline{\mathcal{N}}=\mathcal{N}_{T_{-1}}\cup\mathcal{N}_{T_{-2}}\cup \mathcal{N}_{T_{-3}}\cup\mathcal{N}_{T_{-4}}\).

In three-player games, Algorithm 1 cannot reduce the number of internal nodes because each element in \(\{-i\mid i\in\{1,2,3\}\}\) includes only two players. Then \(\overline{\mathcal{N}}=\underline{\mathcal{N}}=\{\{1,2\},\{1,3\},\{2,3\}\}\), which means that \(\overline{\mathcal{N}}\) and \(\underline{\mathcal{N}}\) will result in the same set of bilinear terms in three-player games.

To be simplified, we show how to formulate the program according to Algorithm 2 (i.e., CRM) in a three-player game \(G=(N,A,u)\) with \(N=\{1,2,3\}\), \(A_{i}=\{a_{i},a_{i}^{\prime}\}\) first. In three-player games, \(-1=\{2,3\}\), and \(\underline{\mathcal{N}}=\{-1,-2,-3\}=\{\{2,3\},\{1,3\},\{1,2\}\}\).

Note that \(A_{-1}=A_{2,3}=A_{2}\times A_{3}=\{(a_{2},a_{3}),(a_{2},a_{3}^{\prime}),(a_{2 }^{\prime},a_{3}),(a_{2}^{\prime},a_{3}^{\prime})\}\) with \(N^{\prime}=-1=\{2,3\},N_{l}^{\prime}=\{2\},N_{r}^{\prime}=\{3\}\). We show the constraints related to player 1 here: We first show player 1's constraints in the Nash equilibria space based on Eqs.(1b)-(1e):

\[x_{1}(a_{1})+x_{1}(a_{1}^{\prime})=1\textbf{ (based on Eqs.(1b))}\] \[1-b_{a_{1}}\geq x_{1}(a_{1}),1-b_{a_{1}^{\prime}}\geq x_{1}(a_{ 1}^{\prime})\textbf{ (based on Eq.(1c))}\] \[u_{1}(x)\!\geq\!u_{1}(a_{1},x_{-1}),u_{1}(x)\!-\!u_{1}(a_{1},x_{ -1})\!\leq\!b_{a_{1}^{\prime}}(U_{max}-U_{min})\textbf{ (based on Eqs.(1d)) and (1e))}\] \[u_{1}(x)\!\geq\!u_{1}(a_{1}^{\prime},x_{-1}),u_{1}(x)\!-\!u_{1}(a _{1}^{\prime},x_{-1})\!\leq\!b_{a_{1}^{\prime}}(U_{max}-U_{min})\textbf{ (based on Eqs.(1d) and (1e))}\]

The above constraints include player 1's expected utility variables \(u_{1}(a_{1},x_{-1})\) and \(u_{1}(a_{1}^{\prime},x_{-1})\), which are represented by the following constraints based on Eq.(4):

\[u_{1}(a_{1},x_{-1}) =u_{1}(a_{1},a_{2},a_{3})x_{-1}(a_{2},a_{3})+u_{1}(a_{1},a_{2},a_{ 3}^{\prime})x_{-1}(a_{2},a_{3}^{\prime})\] \[+u_{1}(a_{1},a_{2}^{\prime},a_{3})x_{-1}(a_{2}^{\prime},a_{3})+u_ {1}(a_{1},a_{2}^{\prime},a_{3}^{\prime})x_{-1}(a_{2}^{\prime},a_{3}^{\prime})\] \[u_{1}(a_{1}^{\prime},x_{-1}) =u_{1}(a_{1}^{\prime},a_{2},a_{3})x_{-1}(a_{2},a_{3})+u_{1}(a_{1} ^{\prime},a_{2},a_{3}^{\prime})x_{-1}(a_{2},a_{3}^{\prime})\] \[+u_{1}(a_{1}^{\prime},a_{2}^{\prime},a_{3})x_{-1}(a_{2}^{\prime},a _{3})+u_{1}(a_{1}^{\prime},a_{2}^{\prime},a_{3}^{\prime})x_{-1}(a_{2}^{\prime},a _{3}^{\prime})\textbf{ (based on Eq.(4)) }\,,\]

where the correlation plan \(x_{-1}\) of \(-1\) over \(A_{-1}\), based on Eq.(2), is defined by:

\[x_{-1}(a_{2},a_{3})+x_{-1}(a_{2},a_{3}^{\prime})+x_{-1}(a_{2}^{\prime},a_{3})+x_ {-1}(a_{2},a_{3}^{\prime})=1\textbf{ (the plan of $-1$ based on Eq.(2))}.\]

In the above correlation plan \(x_{-1}\), \(x_{-1}(a_{2},a_{3})\), \(x_{-1}(a_{2},a_{3}^{\prime})\), \(x_{-1}(a_{2}^{\prime},a_{3})\), \(x_{-1}(a_{2}^{\prime},a_{3}^{\prime})\) represent the following four bilinear terms (constraints):

\[x_{-1}(a_{2},a_{3}) =x_{2}(a_{2})x_{3}(a_{3})\textbf{ (the bilinear constraint based on Eq.(3a)) with}\] \[a_{-1}=(a_{2},a_{3})=(a_{N_{l}^{\prime}},a_{N_{r}^{\prime}}),a_ {N_{l}^{\prime}}=(a_{2}),a_{N_{r}^{\prime}}=(a_{3})\] \[x_{-1}(a_{2},a_{3}^{\prime}) =x_{2}(a_{2})x_{3}(a_{3}^{\prime})\textbf{ (the bilinear constraint based on Eq.(3a)) with}\] \[a_{-1}=(a_{2},a_{3}^{\prime})=(a_{N_{l}^{\prime}},a_{N_{r}^{ \prime}}),a_{N_{l}^{\prime}}=(a_{2}),a_{N_{r}^{\prime}}=(a_{3}^{\prime})\] \[x_{-1}(a_{2}^{\prime},a_{3}) =x_{2}(a_{2}^{\prime})x_{3}(a_{3})\textbf{ (the bilinear constraint based on Eq.(3a)) with}\] \[a_{-1}=(a_{2}^{\prime},a_{3}^{\prime})=(a_{N_{l}^{\prime}},a_ {N_{r}^{\prime}}),a_{N_{l}^{\prime}}=(a_{2}^{\prime}),a_{N_{r}^{\prime}}=(a_{3}^{ \prime}),\]where, based on the binary division in \(\underline{\cal N}\), any joint action \(a_{N^{\prime}}\in A_{N^{\prime}}\) can be divided into two sub-joint actions \(a_{N^{\prime}_{l}}\in A_{N^{\prime}_{l}}\) and \(a_{N^{\prime}_{r}}\in A_{N^{\prime}_{r}}\) such that \(a_{N^{\prime}}=(a_{N^{\prime}_{l}},a_{N^{\prime}_{r}})\). Note that \(x_{2}\) and \(x_{3}\) are special correlation plans with that 2 is set to be equivalent to \(\{2\}\) and 3 is set to be equivalent to \(\{3\}\) for simplification. Correlation plans \(x_{-1}\) and \(x_{2}\) (or \(x_{3}\)) have the following relation:

\(x_{-1}(a_{2},a_{3})+x_{-1}(a_{2},a^{\prime}_{3})=x_{2}(a_{2})\) **(the relation of correlation plans \(x_{-1}\) and \(x_{2}\) based on Eq.(11)),**

\(\forall a_{N^{\prime}}\in\{(a_{2},a_{3}),(a_{2},a^{\prime}_{3})\}\subseteq A_ {-1},a_{N^{\prime}}(2)=a_{2},\) **i.e., \(a_{2}\) is player 2's action in \(a_{N^{\prime}}\)**

\(x_{-1}(a^{\prime}_{2},a_{3})+x_{-1}(a^{\prime}_{2},a^{\prime}_{3})=x_{2}(a^{ \prime}_{2})\) **(the relation of correlation plans \(x_{-1}\) and \(x_{2}\) based on Eq.(11)),**

\(\forall a_{N^{\prime}}\in\{(a^{\prime}_{2},a_{3}),(a^{\prime}_{2},a^{\prime}_{3 })\}\subseteq A_{-1},a_{N^{\prime}}(2)=a^{\prime}_{2},\) **i.e., \(a^{\prime}_{2}\) is player 2's action in \(a_{N^{\prime}}\)**

\(x_{-1}(a_{2},a_{3})+x_{-1}(a^{\prime}_{2},a_{3})=x_{3}(a_{3})\) **(the relation of correlation plans \(x_{-1}\) and \(x_{3}\) based on Eq.(11)),**

\(\forall a_{N^{\prime}}\in\{(a_{2},a_{3}),(a^{\prime}_{2},a^{\prime}_{3})\} \subseteq A_{-1},a_{N^{\prime}}(3)=a^{\prime}_{3},\) **i.e., \(a^{\prime}_{3}\) is player 3's action in \(a_{N^{\prime}}\)**

Constraints related to other players are created similarly. As shown in Algorithm 2 (i.e., CRM), after creating all of these constraints in the bilinear program for the Nash equilibria space, we can solve the program to optimize an objective function by using a global optimization solver, e.g., Gurobi.

In three-player games, \(x_{-1}(a_{-1})\) just represents a bilinear term, and then a chain of bilinear constraints (equalities) to transform a multilinear term into bilinear terms is not explicit. In four-player games, a chain of bilinear constraints (equalities) to transform a multilinear term into bilinear terms is more explicit. For example, in a game \(G=(N,A,u)\) with \(N=\{1,2,3,4\}\), \(A_{i}=\{a_{i},a^{\prime}_{i}\}\), and \(\underline{\cal N}=\{-4,-1,-2,-3,\{1,2\},\{2,4\},\{1,4\}\}\), based on Eq.(3a), we have:

\(x_{-1}(a_{2},a_{3},a_{4})=x_{2,4}(a_{2},a_{4})x_{3}(a_{3}),x_{2,4}(a_{2},a_{4} )=x_{2}(a_{2})x_{4}(a_{4})\) **(a chain of bilinear constraints)**,

where \(N^{\prime}=-1=\{2,3,4\}\), \(N^{\prime}_{l}=\{2,4\}\) and \(N^{\prime}_{r}=\{3\}\) based on \(\underline{\cal N}\). That is, \(a_{-1}=(a_{2},a_{3},a_{4})=(a_{N^{\prime}_{l}},a_{N^{\prime}_{r}})\) with \(a_{N^{\prime}_{l}}=(a_{2},a_{4}),a_{N^{\prime}_{r}}=(a_{3})\) (i.e., joint action \(a_{-1}\) is divided into two sub-joint actions \(a_{N^{\prime}_{l}}\) and \(a_{N^{\prime}_{r}}\) such that \(a_{-1}=(a_{N^{\prime}_{l}},a_{N^{\prime}_{r}})\)) based on \(\underline{\cal N}\), and then we can have the above chain of bilinear constraints for it. Each joint action in \(A_{-1}=A_{2}\times A_{3}\times A_{4}=A_{N^{\prime}_{l}}\times A_{N^{\prime}_{r }}=\{(a_{2},a_{3},a_{4}),(a_{2},a_{3},a^{\prime}_{4}),(a_{2},a_{3}^{\prime},a_ {4}),(a^{\prime}_{2},a_{3},a_{4}),(a^{\prime}_{2},a_{3},a^{\prime}_{4}),(a^{ \prime}_{2},a_{3},a^{\prime}_{4}),(a^{\prime}_{2},a_{3}^{\prime},a_{4})\}\) is divided into two disjoint sets similarly, and then we can have a chain of bilinear constraints for it.

In three-player games, each element in \(\{-i\mid i\in\{1,2,3\}\}\) includes only two players, and then the resulting program does not include the constraints for the relation of correlation plans based on Eq.(12). To show the constraints based on Eq.(12), we consider four-player games. The following constraints are player 1's constraints based on Eq.(12) for solving a game \(G=(N,A,u)\) with \(N=\{1,2,3,4\}\), \(A_{i}=\{a_{i},a^{\prime}_{i}\}\):

\(x_{-1}(a_{2},a_{3},a_{4})\!+\!x_{-1}(a_{2},a_{3}^{\prime},a_{4})\!=\!x_{2,4}(a_{ 2},a_{4})\) **(based on Eq.(12)) with \(a_{N^{\prime}_{l}}=(a_{2},a_{4})\),**

\(\forall a_{N^{\prime}}\in\{(a_{2},a_{3},a_{4}),(a_{2},a^{\prime}_{3},a_{4})\} \subseteq A_{-1},a_{N^{\prime}}(N^{\prime}_{l})=(a_{2},a_{4}),\)

**i.e., \((a_{2},a_{4})\) is \(N^{\prime}_{l}\)'s sub-joint action in \(a_{N^{\prime}_{l}}\)**

\(x_{-1}(a_{2},a_{3},a^{\prime}_{4})\!+\!x_{-1}(a_{2},a^{\prime}_{3},a^{\prime}_{4 })\!=\!x_{2,4}(a_{2},a^{\prime}_{4})\) **(based on Eq.(12)) with \(a_{N^{\prime}_{l}}=(a_{2},a^{\prime}_{4})\),**

\(\forall a_{N^{\prime}}\in\{(a_{2},a_{3},a^{\prime}_{4}),(a_{2},a^{\prime}_{3},a^{ \prime}_{4})\}\subseteq A_{-1},a_{N^{\prime}}(N^{\prime}_{l})=(a_{2},a^{\prime}_{4 }),\)

**i.e., \((a_{2},a_{4})\) is \(N^{\prime}_{l}\)'s sub-joint action in \(a_{N^{\prime}_{l}}\)**

\(x_{-1}(a^{\prime}_{2},a_{3},a^{\prime}_{4})\!+\!x_{-1}(a^{\prime}_{2},a^{\prime}_{3 },a^{\prime}_{4})\!=\!x_{2,4}(a^{\prime}_{2},a^{\prime}_{4})\) **(based on Eq.(12)) with \(a_{N^{\prime}_{l}}=(a^{\prime}_{2},a^{\prime}_{4})\),**

**i.e., \((a_{2},a_{4})\) is \(N^{\prime}_{l}\)'s sub-joint action in \(a_{N^{\prime}_{l}}\)**

where \(N^{\prime}=-1=\{2,3,4\}\), \(N^{\prime}_{l}=\{2,4\}\) and \(N^{\prime}_{r}=\{3\}\) based on \(\underline{\cal N}\). The we can divide the joint actions in \(A_{-1}\), e.g., \(a_{-1}=(a_{2},a_{3},a_{4})=(a_{N^{\prime}_{l}},a_{N^{\prime}_{r}})\) with \(a_{N^{\prime}_and \(|N^{\prime}_{r}|=1\). We could use Eq.(11) to generate constraints for \(N^{\prime}_{r}=\{3\}\) for the relation between \(x_{-1}\) and \(x_{3}\), e.g., for \(a_{3}\in A_{3}\),

\[x_{-1}(a_{2},a_{3},a_{4})+x_{-1}(a^{\prime}_{2},a_{3},a_{4})+x_{-1}(a_{2},a_{3}, a^{\prime}_{4})+x_{-1}(a^{\prime}_{2},a_{3},a^{\prime}_{4})=x_{3}(a_{3}),\]

where, for each \(a_{N^{\prime}}\in\{(a_{2},a_{3},a_{4}),(a^{\prime}_{2},a_{3},a_{4}),(a_{2},a_{3 },a^{\prime}_{4}),(a^{\prime}_{2},a_{3},a^{\prime}_{4})\}\subseteq A_{-1},a_{ N^{\prime}}(3)=a_{3}\), i.e., \(a_{3}\) is player 3's action in \(a_{N^{\prime}}\).

Other constraints for four-player games are created similarly to the above creation of constraints for three-player games.

## Appendix B Proofs

**Theorem 1**.: _The feasible solution space of mixed strategies (i.e., \(x_{i}(a_{i})\) for each \(i\in N\), \(a_{i}\in A_{i}\)) in Eqs.(1b)-(1g), (3), and (4) is the space of NEs._

Proof.: Eq.(1) describing the space of NEs and Eqs.(1b)-(1g), (3), and (4) both include Eqs.(1b)-(1g), which describe the condition of NEs. Then we only need to show that Eq.(4) is equivalent to Eq.(1a). That is, we need to show \(\prod_{j\in-i}x_{j}(a_{-i}(j))=x_{-i}(a_{-i})\) for each \(i\in N\) and \(a_{-i}\in A_{-i}\). To achieve this result, we show \(\prod_{j\in N^{\prime}}x_{j}(a_{N^{\prime}}(j))=x_{N^{\prime}}(a_{N^{\prime}})\) for each \(N^{\prime}\in\mathcal{N}\) and \(a_{N^{\prime}}\in A_{N^{\prime}}\). We show that this statement holds by induction. For any \(N^{\prime}\in\mathcal{N}\) with \(|N^{\prime}|=2\), we obviously have \(\prod_{j\in N^{\prime}}x_{j}(a_{N^{\prime}}(j))=x_{N^{\prime}}(a_{N^{\prime}})\) for each \(a_{N^{\prime}}\in A_{N^{\prime}}\) by Eq.(3). Suppose, for any \(N^{\prime}\in\mathcal{N}\) with \(|N^{\prime}|=k\geq 2\), the statement holds. Now for any \(N^{\prime}\in\mathcal{N}\) with \(|N^{\prime}|=k+1\) and its two children \(N^{\prime}_{l}\) and \(N^{\prime}_{r}\), we have: for any \(a_{N^{\prime}}\in A_{N^{\prime}}\),

\[x_{N^{\prime}}(a_{N^{\prime}}) =x_{N^{\prime}_{l}}(a_{N^{\prime}_{l}})x_{N^{\prime}_{r}}(a_{N^{ \prime}_{r}})\] \[=\prod_{i\in N^{\prime}_{l}}x_{i}(a_{N^{\prime}_{l}}(i))\prod_{j \in N^{\prime}_{r}}x_{j}(a_{N^{\prime}_{r}}(j))\] \[=\prod_{j\in N^{\prime}}x_{j}(a_{N^{\prime}}(j)),\]

where the second "=" is based on the assumption that, for any \(N^{\prime}\in\mathcal{N}\) with \(|N^{\prime}|=k\geq 2\), the statement holds. Then \(\prod_{j\in N^{\prime}}x_{j}(a_{N^{\prime}}(j))=x_{N^{\prime}}(a_{N^{\prime}})\) for each \(N^{\prime}\in\mathcal{N}\) and \(a_{N^{\prime}}\in A_{N^{\prime}}\). Therefore, the theorem holds. 

**Theorem 2**.: \(\mathcal{M}\subset\mathcal{T}\subset\mathcal{R}\)_, i.e., \(\mathcal{T}\) is strictly smaller than \(\mathcal{R}\) but still includes \(\mathcal{M}\)._

Proof.: (i) We first show that \(\mathcal{T}\subset\mathcal{R}\). Given any \(x_{\{i,j\}}(a_{i},a_{j})=x_{i}(a_{i})x_{j}(a_{j})\), in \(\mathcal{T}\), we have \(x_{\{i,j\}}(a_{i},a_{j})\leq\min\{x_{i}(a_{i}),x_{j}(a_{j})\}\) according to Eq.(11). Suppose \(x_{i}(a_{i})+x_{j}(a_{j})-1>x_{\{i,j\}}(a_{i},a_{j})\). According to Eqs.(11) and (1b), we have the following contradiction:

\[x_{i}(a_{i})\] \[=\sum_{a^{\prime}_{j}\in A_{j}}x_{\{i,j\}}(a_{i},a^{\prime}_{j})\] \[<x_{i}(a_{i})+x_{j}(a_{j})-1+\sum_{a^{\prime}_{j}\in A_{j},a^{ \prime}_{j}\neq a_{j}}x_{\{i,j\}}(a_{i},a^{\prime}_{j})\] \[\leq x_{i}(a_{i})-1+\sum_{a_{j}\in A_{j}}x_{j}(a_{j})\] \[=x_{i}(a_{i}),\]

where the first "=" is according to Eq.(11), "\(<\)" is according to the assumption, "\(\leq\)" is according to Eq.(11), and the last "=" is according to Eq.(1b). This contradiction implies that \(x_{i}(a_{i})+x_{j}(a_{j})-1\leq x_{\{i,j\}}(a_{i},a_{j})\), i.e., \(\max\{0,x_{i}(a_{i})+x_{j}(a_{j})-1\}\leq x_{\{i,j\}}(a_{i},a_{j})\). Similarly, for any \(x_{N^{\prime}}(a_{N^{\prime}})=x_{N^{\prime}_{l}}(a_{N^{\prime}_{l}})x_{N^{ \prime}_{r}}(a_{N^{\prime}_{r}})\) with two children \(N^{\prime}_{l}\) and \(N^{\prime}_{r}\) of \(N^{\prime}\), in \(\mathcal{T}\), we have:

\[\max\{x_{N^{\prime}_{l}}(a_{N^{\prime}_{l}})+x_{N^{\prime}_{r}}(a_ {N^{\prime}_{r}})-1,0\}\] \[\leq x_{N^{\prime}}(a_{N^{\prime}})\] \[\leq \min\{x_{N^{\prime}_{l}}(a_{N^{\prime}_{l}}),x_{N^{\prime}_{r}}(a_ {N^{\prime}_{r}})\}.\]Therefore, \(\mathcal{T}\subseteq\mathcal{R}\).

Given any \(x_{\{i,j\}}(a_{1},a_{2})=x_{1}(a_{1})x_{2}(a_{2})\) and \(x_{\{i,j\}}(a^{\prime}_{1},a_{2})=x_{1}(a^{\prime}_{1})x_{2}(a_{2})\), by Eq.(6), we can have a feasible solution such that:

\[x_{\{i,j\}}(a_{1},a_{2})=\min\{x_{1}(a_{1}),x_{2}(a_{2})\}\] \[x_{\{i,j\}}(a^{\prime}_{1},a_{2})=\min\{x_{1}(a^{\prime}_{1}),x_{ 2}(a_{2})\}.\]

Then \(x_{\{i,j\}}(a_{1},a_{2})+x_{\{i,j\}}(a^{\prime}_{1},a_{2})>x_{2}(a_{2})\) when \(0<x_{2}(a_{2})<\min\{x_{1}(a_{1}),x_{1}(a^{\prime}_{1})\}<1\). However, in \(\mathcal{T}\),

\[x_{\{i,j\}}(a_{1},a_{2})+x_{\{i,j\}}(a^{\prime}_{1},a_{2})\leq x_{2}(a_{2}).\]

Then \(\mathcal{R}\nsubseteq\mathcal{T}\). Therefore, \(\mathcal{T}\subset\mathcal{R}\), i.e., \(\mathcal{T}\) is strictly smaller than \(\mathcal{R}\).

(ii) Now we show that \(\mathcal{M}\subset\mathcal{T}\). In \(\mathcal{M}\), for each \(a_{N^{\prime}}\in A_{N^{\prime}},N^{\prime}\in\mathcal{N}\) with two children \(N^{\prime}_{l}\) and \(N^{\prime}_{r}\) of \(N^{\prime}\), there is a bilinear constraint \(x_{N^{\prime}}(a_{N^{\prime}})=x_{N^{\prime}_{l}}(a_{N^{\prime}_{l}})x_{N^{ \prime}_{r}}(a_{N^{\prime}_{r}})\) based on \(a_{N^{\prime}}=(a_{N^{\prime}_{l}},a_{N^{\prime}_{r}})\), where \(x_{N^{\prime}}(a_{N^{\prime}})=x_{i}(a_{i})\) for \(N^{\prime}=\{i\}\). We first show \(\mathcal{M}\subseteq\mathcal{T}\) for Eq.(2) by induction. For any \(N^{\prime}=(i,j)\in\mathcal{N}\), by \(\mathcal{M}\), we have:

\[\sum_{(a_{i},a_{j})\in A_{\{i,j\}}}x_{\{i,j\}}(a_{i},a_{j})=\sum_{a_{i}\in A_{ i}}x_{i}(a_{i})\sum_{a_{j}\in A_{j}}x_{j}(a_{j})=1.\]

Suppose, for any \(N^{\prime}\in\mathcal{N}\) with \(|N^{\prime}|=k\) and \(k\geq 2\),

\[\sum_{a_{N^{\prime}}\in A_{N^{\prime}}}x_{N^{\prime}}(a_{N^{\prime}})=1.\]

Now for any \(N^{\prime}\in\mathcal{N}\) with \(|N^{\prime}|=k+1\), with two children \(N^{\prime}_{l}\) and \(N^{\prime}_{r}\) of \(N^{\prime}\), by \(\mathcal{M}\) and the assumption of \(N_{k}\), we have:

\[\sum_{a_{N^{\prime}}\in A_{N^{\prime}}}x_{N^{\prime}}(a_{N^{\prime }}) =\sum_{a_{N^{\prime}_{l}}\in A_{N^{\prime}_{l}}}x_{N^{\prime}_{l}}(a_{N^{ \prime}_{l}})\sum_{a_{N^{\prime}_{r}}\in A_{N^{\prime}_{r}}}x_{N^{\prime}_{r}} (a_{N^{\prime}_{r}})\] \[=1.\]

Therefore, Eq.(2) is implied by \(\mathcal{M}\). Similarly, for each \(N^{\prime}\subset N\), we have \(\sum_{a_{N^{\prime}}\in A_{N^{\prime}}}x_{N^{\prime}}(a_{N^{\prime}})=1\). For any \(N^{\prime}=(i,j)\in\mathcal{N}\), by \(\mathcal{M}\), we have: for any \(a_{i}\in A_{i}\),

\[\sum_{a_{j}\in A_{j}}x_{\{i,j\}}(a_{i},a_{j})=x_{i}(a_{i})\sum_{a_{j}\in A_{j} }x_{j}(a_{j})=x_{i}(a_{i});\]

and for any \(a_{j}\in A_{j}\), \(\sum_{a_{i}\in A_{i}}x_{\{i,j\}}(a_{i},a_{j})=x_{j}(a_{j})\sum_{a_{i}\in A_{i} }x_{i}(a_{i})=x_{j}(a_{j}).\) For any \(N^{\prime}\in\mathcal{N}\) with \(|N^{\prime}|>2\), by \(\mathcal{M}\), we have: for any \(i\in N^{\prime}\), and \(a_{i}\in A_{i}\), with \(N_{k}=N^{\prime}\setminus\{i\}\),

\[\sum_{a_{N^{\prime}}\in A_{N^{\prime}},a_{N^{\prime}}(i)=a_{i}}x_ {N^{\prime}}(a_{N^{\prime}}) =x_{i}(a_{i})\sum_{a_{N_{k}}\in A_{N_{k}}}x_{N_{k}}(a_{N_{k}})\] \[=x_{i}(a_{i}).\]

Therefore, Eq.(11) is implied by \(\mathcal{M}\).

Now for any \(N^{\prime}\in\mathcal{N}\), with two children \(N^{\prime}_{l}\) and \(N^{\prime}_{r}\) of \(N^{\prime}\), by \(\mathcal{M}\), for each \(a_{N^{\prime}_{l}}\in A_{N^{\prime}_{l}}\), we have:

\[\sum_{a_{N^{\prime}}=(a_{N^{\prime}_{l}},a_{N^{\prime}_{r}})\in A_{N^{ \prime}}}x_{N^{\prime}}(a_{N^{\prime}})\] \[=x_{N^{\prime}_{l}}(a_{N^{\prime}_{l}})\sum_{a_{N^{\prime}_{r}}\in A _{N^{\prime}_{r}}}x_{N^{\prime}_{r}}(a_{N^{\prime}_{r}})\] \[=x_{N^{\prime}_{l}}(a_{N^{\prime}_{l}}),\]where the condition \(a_{N^{\prime}}=(a_{N^{\prime}_{l}},a_{N^{\prime}_{r}})\in A_{N^{\prime}}\) represents that \(a_{N^{\prime}}\in A_{N^{\prime}},a_{N^{\prime}}(N^{\prime}_{l})=a_{N^{\prime}_{l }}\). For each \(a_{N^{\prime}_{r}}\in A_{N^{\prime}_{r}}\), we have:

\[\sum_{a_{N^{\prime}}=(a_{N^{\prime}_{l}},a_{N^{\prime}_{l}})\in A _{N^{\prime}}}x_{N^{\prime}}(a_{N^{\prime}})\] \[=x_{N^{\prime}_{r}}(a_{N^{\prime}_{r}})\sum_{a_{N^{\prime}_{l}} \in A_{N^{\prime}_{l}}}x_{N^{\prime}_{l}}(a_{N^{\prime}_{l}})\] \[=x_{N^{\prime}_{r}}(a_{N^{\prime}_{r}}).\]

Therefore, Eq.(12) is implied by \(\mathcal{M}\). Then \(\mathcal{M}\subseteq\mathcal{T}\).

Given any four bilinear terms:

\[x_{\{1,2\}}(a_{1},a_{2}) =x_{1}(a_{1})x_{2}(a_{2})\] \[x_{\{1,2\}}(a^{\prime}_{1},a_{2}) =x_{1}(a^{\prime}_{1})x_{2}(a_{2})\] \[x_{\{1,2\}}(a_{1},a^{\prime}_{2}) =x_{1}(a_{1})x_{2}(a^{\prime}_{2})\] \[x_{\{1,2\}}(a^{\prime}_{1},a^{\prime}_{2}) =x_{1}(a^{\prime}_{1})x_{2}(a^{\prime}_{2}).\]

The following solution is in \(\mathcal{T}\):

\[x_{\{1,2\}}(a_{1},a_{2}) =0\] \[x_{\{1,2\}}(a^{\prime}_{1},a_{2}) =2/3\] \[x_{\{1,2\}}(a_{1},a^{\prime}_{2}) =1/3\] \[x_{\{1,2\}}(a^{\prime}_{1},a^{\prime}_{2}) =0\] \[x_{1}(a_{1})=1/3,x_{1}(a^{\prime}_{1})=2/3\] \[x_{2}(a_{2})=2/3,x_{2}(a^{\prime}_{2})\!=\!1/3.\]

However, the above solution is not in \(\mathcal{M}\) because: \(x_{1}(a_{1})=1/3\) and \(x_{2}(a_{2})=2/3\) imply that \(x_{\{1,2\}}(a_{1},a_{2})=2/9\), which contradicts \(x_{\{1,2\}}(a_{1},a_{2})=0\) in the above solution. Therefore, \(\mathcal{T}\not\subseteq\mathcal{M}\). That is, \(\mathcal{M}\subset\mathcal{T}\). 

**Theorem 3**.: _The optimal solution of Program (13) maximizes \(g(x)\) over the space of NEs._

Proof.: By Theorem 2, \(\mathcal{T}\) includes \(\mathcal{M}\), i.e., \(\mathcal{T}\) does not reduce the space of NEs. Program (13) is obtained after we explicitly restrict the feasible solution space to \(\mathcal{T}\) by adding Eqs.(2), (11), and (12) to Program (5). The optimization solver will search this feasible solution space after the relaxation to find the optimal solution for the original bilinear program. Therefore, by solving Program (13), we obtain an optimal NE. 

**Theorem 4**.: \(\mathcal{\underline{N}}\) _generated by Algorithm 1 is a binary collection, and \(O(n\log n)\) for the size of \(\mathcal{\underline{N}}\) is the minimum size of all binary collections of a game \(G\)._

Proof.: First, it is clear that \(\mathcal{\underline{N}}\) generated by Algorithm 1 is a binary collection of \(G\). Then \(\{-i\mid i\in N\}\subseteq\mathcal{\underline{N}}\).

The number of internal nodes in each binary tree with \(n-1\) leaves of \(-i\) for each \(i\in N\) is \(n-2\)[20]. To obtain the minimum number of internal nodes in these binary trees for \(\{-i\mid i\in N\}\), we can minimize the difference between binary trees. Given a binary tree \(T_{-n}\) for \(-n\) and a binary tree \(T_{-i}\) for \(-i\) with \(i\in-n\), the difference between \(T_{-n}\) and \(T_{-i}\) at least includes the path from the root to the node \(\{i\}\) in \(T_{-n}\) and the path from the root to the node \(\{n\}\) in \(T_{-i}\). Then the number of different internal nodes (i.e., nodes that are not in \(T_{-n}\)) in these binary trees for \(\{-i\mid i\in N\}\) is at least equal to the total path length in \(T_{-n}\). Algorithm 1 ensures that the number of different internal nodes in these binary trees for \(\{-i\mid i\in N\}\) is equal to the total path length in \(T_{-n}\), and the total path length in \(T_{-n}\) by Algorithm 1 is at most \((n-1)\lceil\log_{2}(n-1)\rceil\). Given a binary tree with \(k-1\) internal nodes, the minimum total path length is \(O(k\log k)\)[20]. Therefore, \(O(n\log n)\) for the size of \(\mathcal{\underline{N}}\) is the minimum size of all binary collections of \(G\).

## Appendix C The Necessity of Eq.(3a) in Program (13)

Now we show the necessity of Eq.(3a) in Program (13). We denote Program \(\mathbf{T}\) as the resulting program after removing Eq.(3a) in Program (13). We use the optimization gap between the optimal objective value \(g^{*}\) in Program (13) and the objective value \(g\) obtained from the players' strategies after solving Program \(\mathbf{T}\) (i.e., \(g\) is the real objective value after playing the strategies obtained from solving Program \(\mathbf{T}\)) to measure the inefficiency of Program \(\mathbf{T}\), i.e., \(g^{*}-\underline{g}\). Note that, by Theorem 2, the optimal objective value of Program \(\mathbf{T}\) is just an upper bound of the optimal objective value of Program (13), which may not be achieved by playing the strategies obtained from solving Program \(\mathbf{T}\). The following theorem shows that \(g^{*}-\underline{g}\) can be arbitrarily large, i.e., Program \(\mathbf{T}\) is not suitable to be used for computing optimal NEs. In addition, the resulting strategy profile by solving Program \(\mathbf{T}\) may not be an NE.5

Footnote 5: To find an optimal NE, this paper only considers programs guaranteeing exact NEs, and designing programs with approximate NEs is the future work.

**Theorem 5**.: \(g^{*}-\underline{g}\) _can be arbitrarily large, and the resulting strategy profile \(x^{\prime}\) by solving Program \(\mathbf{T}\) may not be an NE._

Proof.: Consider a game with three players, \(A_{1}=\{a_{1},a^{\prime}_{1}\},A_{2}=\{a_{2},a^{\prime}_{2}\}\) and \(A_{3}=\{a_{3},a^{\prime}_{3},a^{\prime\prime}_{3}\}\), and the following utility function for three players, respectively, with \(k\geq 1\):

\[u=(u_{1},u_{2},u_{3}):(a_{1},a_{2},a_{3})\rightarrow(0.5k,0.5k,-k);\] \[u=(u_{1},u_{2},u_{3}):(a^{\prime}_{1},a^{\prime}_{2},a^{\prime}_{ 3})\rightarrow(0.5k,0.5k,-k);\] \[u=(u_{1},u_{2},u_{3}):(a_{1},a^{\prime}_{2},a^{\prime}_{3}) \rightarrow(0.125k,0.125k,-0.25k);\] \[u=(u_{1},u_{2},u_{3}):(a_{1},a^{\prime}_{2},a^{\prime}_{3}) \rightarrow(0.125k,0.125k,-0.25k);\] \[u=(u_{1},u_{2},u_{3}):(a_{1},a^{\prime}_{2},a^{\prime\prime}_{3}) \rightarrow(0.1k,0.15k,-0.25k);\] \[u=(u_{1},u_{2},u_{3}):\text{other joint actions}\rightarrow(0,0,0).\]

The objective function is \(g=u_{1}(x_{1},x_{2},x_{3})+u_{2}(x_{1},x_{2},x_{3})\). By solving Program \(\mathbf{T}\), we obtain \(x^{\prime}_{1}\) with \(x^{\prime}_{1}(a_{1})=2/3\) and \(x^{\prime}_{1}(a^{\prime}_{1})=1/3\), \(x^{\prime}_{2}(a_{2})=1/3\) and \(x^{\prime}_{2}(a^{\prime}_{2})=2/3\), and \(x^{\prime}_{3}(a^{\prime\prime}_{3})=0\). If players 1 and 2 play \(x^{\prime}_{1}\) and \(x^{\prime}_{2}\), respectively, \(u_{3}(x^{\prime}_{1},x^{\prime}_{2},a_{3})=-k/3=u_{3}(x^{\prime}_{1},x^{\prime }_{2},a^{\prime}_{3})\), and \(u_{3}(x^{\prime}_{1},x^{\prime}_{2},a^{\prime\prime}_{3})=-k/9\). That is, player 3 will play the pure strategy \(a^{\prime\prime}_{3}\) to respond to \(x^{\prime}_{1}\) and \(x^{\prime}_{2}\), which will result in \(\underline{g}=k/9\). Then the resulting strategy profile \(x^{\prime}\) is not an NE.

It is clear that \((x_{1}^{*},x_{2}^{*},x_{3}^{*})\) with \(x_{1}^{*}(a_{1})=1\), \(x_{2}^{*}(a_{2}^{\prime})=1\), and \(x_{3}^{*}(a_{3}^{\prime\prime})=1\) is an NE, which also is an output of solving Program (13) with the objective value \(g^{*}=k/4\).

Therefore, \(g^{*}-\underline{g}=5k/36\), which is arbitrarily large when \(k\) is arbitrarily large. 

```
1:\(h\leftarrow\lceil\log(|N^{\prime}|)\rceil\)
2:if\(2^{h}=|N^{\prime}|\)then
3: Lower set \(\mathcal{N^{\prime}}_{1}\leftarrow\{\{i\}\ |\ i\in N^{\prime}\}\)
4:for\(k\in\{1,\ldots,\lceil\log(|\mathcal{N^{\prime}}|)\rceil\}\)do
5: Upper set \(\mathcal{N^{\prime}}_{2}\leftarrow\emptyset\)
6:for\(j\in\{1,\ldots,|\mathcal{N^{\prime}}_{1}|/2\}\)do
7:\(N_{1}\leftarrow\mathcal{N^{\prime}}_{1}[j\times 2-1]\cup\mathcal{N^{\prime}}_{1}[j \times 2]\): the union of the \((j\times 2-1)\)-th element and the \((j\times 2)\)-th element in \(\mathcal{N^{\prime}}_{1}\).
8:\(\mathcal{N^{\prime}}_{2}\leftarrow\mathcal{N^{\prime}}_{2}\cup\{N_{1}\}\)
9:\(\textit{Ch}(N_{1})\leftarrow\{\mathcal{N^{\prime}}_{1}[j\times 2-1],\mathcal{N^{ \prime}}_{1}[j\times 2]\}\)
10:endfor
11: Lower set \(\mathcal{N^{\prime}}_{1}\leftarrow\mathcal{N^{\prime}}_{2}\)
12:\(\underline{\mathcal{N}}\leftarrow\underline{\mathcal{N}}\cup\mathcal{N^{\prime }}_{2}\)
13:endfor
14:else
15:\(N^{\prime}_{1}\leftarrow\{N^{\prime}[1],\ldots,N^{\prime}[2^{h-1}]\}\)
16:\(N^{\prime}_{2}\gets N^{\prime}\setminus N^{\prime}_{1}\)
17:if\(3\times 2^{h-2}<=|N^{\prime}|\)then
18: Lower set \(\mathcal{N^{\prime}}_{1}\leftarrow\{\{i\}\ |\ i\in N^{\prime}_{1}\}\)
19:for\(k\in\{1,\ldots,\lceil\log(|N^{\prime}_{1}|)\rceil\}\)do
20: Repeat Lines 5-12.
21:endfor
22:\(Build(N^{\prime}_{2})\)
23:\(\underline{\mathcal{N}}\leftarrow\underline{\mathcal{N}}\cup\{N^{\prime}\}\)
24:\(\textit{Ch}(N^{\prime})\leftarrow\{N^{\prime}_{1},N^{\prime}_{2}\}\)
25:else
26: Lower set \(\mathcal{N^{\prime}}_{1}\leftarrow\{\{i\}\ |\ i\in N^{\prime}_{1}\}\)
27:for\(k\in\{1,\ldots,\lceil\log(|N^{\prime}_{1}|)\rceil-1\}\)do
28: Repeat Lines 5-12.
29:endfor
30:\(Build(N^{\prime}_{2})\)
31:\(N_{1}\leftarrow\mathcal{N^{\prime}}_{1}[2]\cup N^{\prime}_{2}\)
32:\(\underline{\mathcal{N}}\leftarrow\underline{\mathcal{N}}\cup\{N_{1}\}\)
33:\(\textit{Ch}(N_{1})\leftarrow\{\mathcal{N^{\prime}}_{1}[2],N^{\prime}_{2}\}\)
34:\(\textit{Ch}(N^{\prime}_{2})\leftarrow\{\mathcal{N^{\prime}}_{1}[1],N_{1}\}\)
35:endif
36:endif ```

**Algorithm 4**\(Build(N^{\prime})\): Build a minimum-height binary tree for \(N^{\prime}\)

## Appendix D Binary Trees and Details of Algorithm 1

We consider a special binary tree (full binary tree), which includes two kinds of nodes: nodes with two children (internal nodes) and nodes without children (leaf nodes). A binary tree \(T_{N^{\prime}}\) of \(N^{\prime}\subseteq N\) with \(|N^{\prime}|\geq 2\) is that: 1) its root is \(N^{\prime}\); 2) its nodes are \(\{N^{\prime\prime}\ |\ N^{\prime\prime}\subseteq N^{\prime}\}\); 3) each of its leaf nodes is a singleton; and 4) each of its internal nodes \(N^{\prime\prime}\) has two children \(N^{\prime\prime}_{l}\) and \(N^{\prime\prime}_{r}\) with \(N^{\prime\prime}_{l}\cap N^{\prime\prime}_{r}=\emptyset\) and \(N^{\prime\prime}=N^{\prime\prime}_{l}\cup N^{\prime\prime}_{r}\), i.e., \(N^{\prime\prime}\) is divided into two disjoint sets. Let \(\textit{Ch}(N^{\prime\prime})=\{N^{\prime\prime}_{l},N^{\prime\prime}_{r}\}\) be the set of \(N^{\prime\prime\prime}\)'s children in \(T_{N^{\prime}}\), and \(\textit{Ch}(N^{\prime\prime})=\emptyset\) if \(N^{\prime\prime}\) is a singleton. Let \(\mathcal{N}_{T_{N^{\prime}}}\) be the set of internal nodes in \(T_{N^{\prime}}\).

Our binary tree for \(-i\) is a full binary tree, i.e., each internal node has two children, which has \(k-1\) internal nodes if there are \(k\) leaf nodes [20]. For example, Figure 1(a) has 3 internal nodes and 4 leaf nodes. The length of the path from the root to a leaf is the number of internal nodes on this path in a binary tree. The height of a binary tree is the maximum path length, and the total path length is the sum of the lengths of the paths from the root to each leaf node in a binary tree. For example, the path length from the root to each leaf node in Figure 1(a) is 2, the height is 2, and the total path length is \(2\times 4=8\).

To obtain the minimum number of internal nodes in these binary trees for \(\{-i\mid i\in N\}\), we can minimize the difference between binary trees. Given the binary tree \(T_{-n}\) for \(-n\) and the binary tree \(T_{-i}\) for \(-i\) with \(i\in-n\), the difference between \(T_{-n}\) and \(T_{-i}\) at least includes the path from the root to the leaf node \(\{i\}\) in \(T_{-n}\) and the path from the root to the leaf node \(\{n\}\) in \(T_{-i}\). Then the number of different internal nodes (i.e., internal nodes that are not in \(T_{-n}\)) in these binary trees for \(\{-i\mid i\in N\}\) is at least equal to the total path length in \(T_{-n}\). Now we propose an algorithm ensuring that the number of different internal nodes in these binary trees for \(\{-i\mid i\in N\}\) is equal to the total path length in \(T_{-n}\), which is the minimum total path length. To do that, we first build a binary tree for \(-n\) with the minimum height (a full binary tree with the minimum height may not be balanced). Note that there are at most \(2^{h}\) leaf nodes in a binary tree with the height \(h\), and there are \(n-1\) leaf nodes and \(n-2\) internal nodes in a binary tree for \(-n\). Then we can build a full binary tree \(T_{-n}\) with the height \(\lceil\log_{2}(n-1)\rceil\) for \(-n\) and then replace \(i\) with \(n\) in the nodes of \(T_{-n}\) to obtain \(T_{-i}\) for each \(i\in-n=\{1,\ldots,n-1\}\). That creates \(n\) full binary trees for \(\{-i\mid i\in N\}\). This procedure is shown in Algorithm 1, generating our minimum binary collection \(\mathcal{N}\). Figure 1(a) builds a binary tree \(T_{-5}\), and Figure 1(a) obtains \(T_{-3}\) by replacing \(3\) with \(5\) in \(T_{-5}\).

The full details of Algorithm 1 are shown in Algorithm 3. Line 1 builds a binary tree with the height \(\lceil\log_{2}(n-1)\rceil\) for \(-n=\{1,\ldots,n-1\}\), whose details are shown in Algorithm 4. At Lines 2-16, for each \(i\) in \(\{1,\ldots,n-1\}\), we search the binary tree for \(-n\) from the root and replace \(i\) with \(n\) in each node including \(i\) to form a new tree for \(-i\). And we only need to add new internal nodes to \(\mathcal{N}\).

Algorithm 4 builds a binary tree with the height \(\lceil\log_{2}(|N^{\prime}|)\rceil\) for \(N^{\prime}\). If the size of \(N^{\prime}\) is \(2^{\lceil\log_{2}(|N^{\prime}|)\rceil}\) (note that each element in \(N^{\prime}\) corresponds to a leaf node, and there are at most \(2^{h}\) leaf nodes in a binary tree with the height \(h\)), then we can build a complete binary tree, where all leaf nodes are at the lowest level. That is, we combine two nodes at the lower level to form a node at the upper level, as shown at Lines 3-12. If the size of \(N^{\prime}\) is not \(2^{\lceil\log_{2}(|N^{\prime}|)\rceil}\), and it is larger than \(3\times 2^{\lceil\log_{2}(|N^{\prime}|)\rceil-2}\), then we build a complete binary tree for the subset \(N^{\prime}_{1}\) (Line 15) with the height \(\lceil\log_{2}(|N^{\prime}_{1}|)\rceil=\lceil\log_{2}(|N^{\prime}|)\rceil-1\) (Lines 18-20) and then build a binary tree for the remaining subset (Line 22). Finally, we combine both binary trees together to form a binary tree for \(N^{\prime}\) (Line 24). If the size of \(N^{\prime}\) is not \(2^{\lceil\log_{2}(|N^{\prime}|)\rceil}\), and it is less than \(3\times 2^{\lceil\log_{2}(|N^{\prime}|)\rceil-2}\), we build a complete binary tree for the subset \(N^{\prime}_{1}\) (Line 28) with the height \(\lceil\log_{2}(|N^{\prime}_{1}|)\rceil=\lceil\log_{2}(|N^{\prime}|)\rceil-1\). However, at the last step of building the binary tree for \(N^{\prime}_{1}\), we do not combine two nodes to form a root. We keep both two nodes within \(\mathcal{N}^{\prime}_{1}\) by setting \(k\leq\lceil\log(|N^{\prime}_{1}|)\rceil-1=\lceil\log(|N^{\prime}|)\rceil-2\) at Line 26. Then we build a binary tree for the remaining subset \(N^{\prime}_{2}\) (Line 30). After that, we combine the root of the binary tree for \(N^{\prime}_{2}\) and two nodes in \(\mathcal{N}^{\prime}_{1}\) to form a binary tree for \(N^{\prime}\) (Line 31-35). This step is to try to reduce the total path length because the number of nodes in the binary tree for \(N^{\prime}_{2}\) is less than the number of nodes of the binary tree for any node in \(\mathcal{N}^{\prime}_{1}\), and we can reduce the total path length by combining the root of the binary tree for \(N^{\prime}_{2}\) and any node in \(\mathcal{N}^{\prime}_{1}\) to form a node first.

## Appendix E Runtime for Algorithm 1

Table 3 shows the runtime of Algorithm 1, which is extremely small and then can be ignored, compared to the runtime of CRM shown in Tables 4 and 5.

## Appendix F Experiment Setting

**Games:** we evaluate our approach on two sets of games: randomly generated games and games that are generated by GAMUT [31]. Payoffs are generated from the interval between 0 and 100 (other ranges (e.g., \([0,1]\)) do not affect the result). We vary the number of players (i.e., \(n\)) and the number of actions (i.e., \(m\)) for each player for random games (i.e., \((n,m)\)). For GAMUT games, we use the variants with six players and three actions (i.e., the game \((6,3)\)), which are much larger than the three-player three-action games (i.e., the game \((3,3)\)) used in prior work [4, 13]. We show the game size in terms of the number of bilinear terms and integer variables in Appendix G, e.g., the number of 

[MISSING_PAGE_FAIL:22]

[MISSING_PAGE_FAIL:23]

3-player games, so CR and CRM have the same performance in 3-player games shown in Table 6. When the number of players increases, the size of \(\overline{\mathcal{N}}\) is larger and larger than \(\mathcal{N}\), and then CRM's advantage over CR is more significant. This statement is verified by our result: game (7, 2): CRM with 25 \(\pm\) 17 and CR with 89 \(\pm\) 51; and game (8, 2): CRM with 156 \(\pm\) 83 (3%) and CR with 612 \(\pm\) 129 (33%) (see Table 2). However, from the game (7, 2) to the game (8, 2), the trend that CRM's advantage over CR is more significant is not very clear based on the above data due to the time limit in the game (8, 2). To show this trend clearly, we remove the time limit for CRM and CR in the game (8, 2) and obtain: CRM with 166 \(\pm\) 97 and CR with 2334\(\pm\) 1742, which is shown in Table 6. Then from the game (7, 2), where CRM is about 3 times faster than CR, to the game (8, 2), where CRM is about 13 times faster than CR, we can clearly see the trend that CRM's advantage over CR is more significant when the number of players increases. The difference between \(\overline{\mathcal{N}}\) and \(\underline{\mathcal{N}}\) also explains that CR is slower than CM in the game (8, 2).

## Appendix I Results on More Gambit Algorithms

Results in Tables 7 and 8 show that Gambit algorithms, i.e., GNM, IPA, LIAP, SIMPDIV, and LOGIT, cannot guarantee finding an NE, i.e., fail to solve many games, and even run significantly slower than our CRM (see Tables 4 and 5) in many games:

* GNM fails to solve many large games: GNM stops without output in some of these cases, and cannot stop within the time limit in other cases. GNM runs significantly slower than our CRM in many games, e.g., random games \((7,2),(4,4),(3,5),(3,10)\), and GAMUT games Bidirectional LEG, Collaboration, Covariant.
* IPA fails to solve many large games: IPA cannot stop within the time limit in most of these games. IPA runs significantly slower than our CRM in most random games, and the GAMUT game Random graphical.

\begin{table}
\begin{tabular}{l|l l l l l l} \cline{2-7}  & \multicolumn{4}{c}{Runtime \(\pm\) 95\% Confidence Interval (Percentage of Games not Solved)} \\ \hline \((n,m)\) & GNM & IPA & LIAP & SIMPDIV & LOGIT \\ \hline \((3,2)\) & 0.03 \(\pm\) 0.02 & 567 \(\pm\) 177 (57\%) & 0.06 \(\pm\) 0.02 (77\%) & 0.07 \(\pm\) 0.06 & 0.04 \(\pm\) 0.02 (100\%) \\ \((5,2)\) & 0.04 \(\pm\) 0.01 (3\%) & 867 \(\pm\) 122 (87\%) & 0.45 \(\pm\) 0.04 (100\%) & 1000 \(\pm\) 0(100\%) & 0.02 \(\pm\) 0 (100\%) \\ \((7,2)\) & 333 \(\pm\) 169 (53\%) & 400 \(\pm\) 175 (37\%) & 6 \(\pm\) 0.4 (100\%) & 79 \(\pm\) 78.6 & 0.05 \(\pm\) 0.05 (100\%) \\ \((3,3)\) & 0.03 \(\pm\) 0.3(3\%) & 933 \(\pm\) 89 (93\%) & 0.16 \(\pm\) 0.22 (100\%) & 300 \(\pm\) 163 (30\%) & 0.04 \(\pm\) 0.02 (100\%) \\ \((4,3)\) & 0.17 \(\pm\) 0.11 (3\%) & 500 \(\pm\) 179 (50\%) & 0.76 \(\pm\) 0.08 (100\%) & 500 \(\pm\) 179 (50\%) & 0.02 \(\pm\) 0 (100\%) \\ \((5,3)\) & 0.15 \(\pm\) 0.03 (30\%) & 773 \(\pm\) 158 (73\%) & 6.3 \(\pm\) 0.3 (100\%) & 900 \(\pm\) 177 (90\%) & 0.02 \(\pm\) 0.01 (100\%) \\ \hline \((4,2)\) & 0.03 \(\pm\) 0.01 (3\%) & 667 \(\pm\) 169 (63\%) & 0.13 \(\pm\) 0.02 (97\%) & 733 \(\pm\) 158 (73\%) & 0.02 \(\pm\) 0 (100\%) \\ \((4,3)\) & 0.17 \(\pm\) 0.11 (3\%) & 500 \(\pm\) 179 (50\%) & 0.76 \(\pm\) 0.08 (100\%) & 500 \(\pm\) 179 (50\%) & 0.02 \(\pm\) 0 (100\%) \\ \((4,4)\) & 800 \(\pm\) 143 (80\%) & 367 \(\pm\) 172 (33\%) & 4.9 \(\pm\) 0.4 (100\%) & 867 \(\pm\) 121 (87\%) & 0.07 \(\pm\) 0.07 (100\%) \\ \((4,5)\) & 0.33 \(\pm\) 0.07 (37\%) & 833 \(\pm\) 133 (83\%) & 16 \(\pm\) 1 (100\%) & 900 \(\pm\) 170 (90\%) & 0.04 \(\pm\) 0.03 (100\%) \\ \((3,5)\) & 600 \(\pm\) 175 (63\%) & 767 \(\pm\) 151 (77\%) & 1.5 \(\pm\) 0.1 (100\%) & 933 \(\pm\) 89 (93\%) & 0.06 \(\pm\) 0.09 (100\%) \\ \((3,8)\) & 0.76 \(\pm\) 0.26 (17\%) & 506 \(\pm\) 177 (50\%) & 11 \(\pm\) 0.7 (100\%) & 867 \(\pm\) 122 (87\%) & 0.02 \(\pm\) 0 (100\%) \\ \((3,10)\) & 334 \(\pm\) 168 (53\%) & 767 \(\pm\) 153 (77\%) & 37 \(\pm\) 3 (100\%) & 867 \(\pm\) 121 (87\%) & 0.02 \(\pm\) 0 (100\%) \\ \((3,13)\) & 3.8 \(\pm\) 1.1 (47\%) & 1000 \(\pm\) 0 (100\%) & 132 \(\pm\) 11 (100\%) & 805 \(\pm\) 140 (80\%) & 0.03 \(\pm\) 0 (100\%) \\ \hline \end{tabular}
\end{table}
Table 7: Results on more Gambit algorithms for random games. The format for each result is: Average Runtime \(\pm\) 95% Confidence Interval (Percentage of Games not Solved)

\begin{table}
\begin{tabular}{l|l l l l l l l} \cline{2-7}  & \multicolumn{4}{c}{Runtime \(\pm\) 95\% Confidence Interval (Percentage of Games not Solved)} \\ \hline Game & GNM & IPA & LIAP & SIMPDIV & LOGIT \\ \hline Bidirectional LEG & 167 \(\pm\) 133 (63\%) & 10 \(\pm\) 17 & 8 \(\pm\) 0.6 (100\%) & 667 \(\pm\) 169 (67\%) & 0.03 \(\pm\) 0 (100\%) \\ Collaboration & 34 \(\pm\) 64 (3\%) & 0.03 \(\pm\) 0 & 24 \(\pm\) 2 (100\%) & 0.03 \(\pm\) 0 & 0.03 \(\pm\) 0 (100\%) \\ Covariant \(r=0.5\) & 100 \(\pm\) 107 (17\%) & 0.04 \(\pm\) 0 & 21 \(\pm\) 2 (100\%) & 367 \(\pm\) 172 (37\%) & 0.04 \(\pm\) 0.03 (100\%) \\ PolyMatrix & 0.13 \(\pm\) 0.03 (7\%) & 8.3 \(\pm\) 8 & 9 \(\pm\) 0.8 (100\%) & 24 \(\pm\) 27 & 0.05 \(\pm\) 0.05 (100\%) \\ Random LEG & 0.19 \(\pm\) 0.04 (74\%) & 0.04 \(\pm\) 0 & 7.5 \(\pm\) 0.6 (100\%) & 777 \(\pm\) 146 (77\%) & 0.03 \(\pm\) 0 (1000\%) \\ Random graphical & 0.05 \(\pm\) 0 (3\%) & 1000 \(\pm\) 0 (100\%) & 9 \(\pm\) 1 (100\%) & 0.05 \(\pm\) 0.03 & 0.04 \(\pm\) 0.02 (100\%) \\ Uniform LEG & 0.16 \(\pm\) 0.04 (47\%) & 0.04 \(\pm\) 0 & 7.3 \(\pm\)* [leftmargin=*]
* LIAP can only solve several games in small random games \((3,2)\) and \((4,2)\), and fails to solve all of the other games: LIAP stops without output in these games. Even so, LIAP runs significantly slower than our CRM in most games.
* SIMPDIV fails to solve many large games: SIMPDIV cannot stop within the time limit in almost all of these games. SIMPDIV runs significantly slower than our CRM in most games.
* LOGIT fails to solve all of these games: LOGIT stops without output in all of these games. LOGIT may not work properly in this latest GAMBIT version. Even so, LOGIT runs significantly slower than our CRM in the random game \((3,2)\).