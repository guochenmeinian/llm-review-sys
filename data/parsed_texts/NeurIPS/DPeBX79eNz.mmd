# Transfer Learning with Affine Model Transformation

Shunya Minami

The Institute of Statistical Mathematics

mshunya@ism.ac.jp

&Kenji Fukumizu

The Institute of Statistical Mathematics

fukumizu@ism.ac.jp

&Yoshihiro Hayashi

The Institute of Statistical Mathematics

yhayashi@ism.ac.jp

&Ryo Yoshida

The Institute of Statistical Mathematics

yoshidar@ism.ac.jp

###### Abstract

Supervised transfer learning has received considerable attention due to its potential to boost the predictive power of machine learning in scenarios where data are scarce. Generally, a given set of source models and a dataset from a target domain are used to adapt the pre-trained models to a target domain by statistically learning domain shift and domain-specific factors. While such procedurally and intuitively plausible methods have achieved great success in a wide range of real-world applications, the lack of a theoretical basis hinders further methodological development. This paper presents a general class of transfer learning regression called affine model transfer, following the principle of expected-square loss minimization. It is shown that the affine model transfer broadly encompasses various existing methods, including the most common procedure based on neural feature extractors. Furthermore, the current paper clarifies theoretical properties of the affine model transfer such as generalization error and excess risk. Through several case studies, we demonstrate the practical benefits of modeling and estimating inter-domain commonality and domain-specific factors separately with the affine-type transfer models.

## 1 Introduction

Transfer learning (TL) is a methodology to improve the predictive performance of machine learning in a target domain with limited data by reusing knowledge gained from training in related source domains. Its great potential has been demonstrated in various real-world problems, including computer vision [1, 2], natural language processing [3, 4], biology [5], and materials science [6, 7, 8]. Notably, most of the outstanding successes of TL to date have relied on the feature extraction ability of deep neural networks. For example, a conventional method reuses feature representations encoded in an intermediate layer of a pre-trained model as an input for the target task or uses samples from the target domain to fine-tune the parameters of the pre-trained source model [9]. While such methods are operationally plausible and intuitive, they lack methodological principles and remain theoretically unexplored in terms of their learning capability for limited data. This study develops a principled methodology generally applicable to various kinds of TL.

In this study, we focus on supervised TL settings. In particular, we deal with settings where, given feature representations obtained from training in the source domain, we use samples from the target domain to model and estimate the domain shift to the target. This procedure is called hypothesis transfer learning (HTL); several methods have been proposed, such as using a linear transformation function [10, 11] and considering a general class of continuous transformation functions [12]. If the transformation function appropriately captures the functional relationship between the source and target domains, only the domain-specific factors need to be additionally learned, which can be done efficiently even with a limited sample size. In other words, the performance of HTL depends stronglyon whether the transformation function appropriately represents the cross-domain shift. However, the general methodology for modeling and estimating such domain shifts has been less studied.

This study derives a theoretically optimal class of supervised TL that minimizes the expected \(\ell_{2}\) loss function of the HTL. The resulting function class takes the form of an affine coupling \(g_{1}(\bm{f_{s}})+g_{2}(\bm{f_{s}})\cdot g_{3}(\bm{x})\) of three functions \(g_{1},g_{2}\) and \(g_{3}\), where the shift from a given source feature \(f_{s}\) to the target domain is represented by the functions \(g_{1}\) and \(g_{2}\), and the domain-specific factors are represented by \(g_{3}(\bm{x})\) for any given input \(\bm{x}\). These functions can be estimated simultaneously using conventional supervised learning algorithms such as kernel methods or deep neural networks. Hereafter, we refer to this framework as the _affine model transfer_. As described later, we can formulate a wide variety of TL algorithms within the affine model transfer, including the widely used neural feature extractors, offset and scale HTLs [10; 11; 12], and Bayesian TL [13]. We clarify theoretical properties of the affine model transfer such as generalization error and excess risk.

To summarize, the contributions of our study are as follows:

* The affine model transfer is proposed to adapt source features to the target domain by separately estimating cross-domain shift and domain-specific factors.
* The affine form is derived theoretically as an optimal class based on the squared loss for the target task.
* The affine model transfer encompasses several existing TL methods, including neural feature extraction. It can work with any type of source model, including non-machine learning models such as physical models as well as multiple source models.
* For each of the three functions \(g_{1}\), \(g_{2}\), and \(g_{3}\), we provide an efficient and stable estimation algorithm when modeled using the kernel method.
* Two theoretical properties of the affine transfer model are shown: the generalization and the excess risk bound.

With several applications, we compare the affine model transfer with other TL algorithms, discuss its strengths, and demonstrate the advantage of being able to estimate cross-domain shifts and domain-specific factors separately.

## 2 Transfer Learning via Transformation Function

### Affine Model Transfer

This study considers regression problems with squared loss. We assume that the output of the target domain \(y\in\mathcal{Y}\subset\mathbb{R}\) follows \(y=f_{t}(\bm{x})+\epsilon\), where \(f_{t}:\mathcal{X}\rightarrow\mathbb{R}\) is the true model on the target domain, and the observation noise \(\epsilon\) has mean zero and variance \(\sigma^{2}\). We are given \(n\) samples \(\{(\bm{x}_{i},y_{i})\}_{i=1}^{n}\in(\mathcal{X}\times\mathcal{Y})^{n}\) from the target domain and the feature representation \(\bm{f_{s}}(\bm{x})\in\mathcal{F}_{s}\) from one or more source domains. Typically, \(\bm{f_{s}}\) is given as a vector, including the output of the source models, observed data in the source domains, or learned features in a pre-trained model, but it can also be a non-vector feature such as a tensor, graph, or text. Hereafter, \(\bm{f_{s}}\) is referred to as the source features.

In this paper, we focus on transfer learning with variable transformations as proposed in [12]. For an illustration of the concept, consider the case where there exists a relationship between the true functions \(f_{s}^{*}(\bm{x})\in\mathbb{R}\) and \(f_{t}^{*}(\bm{x})\in\mathbb{R}\) such that \(f_{t}^{*}(\bm{x})=f_{s}^{*}(\bm{x})+\bm{x}^{\top}\bm{\theta}^{*},\bm{x}\in \mathbb{R}^{d}\) with an unknown parameter \(\bm{\theta}^{*}\in\mathbb{R}^{d}\). If \(f_{s}^{*}\) is non-smooth, a large number of training samples is needed to learn \(f_{t}^{*}\) directly. However, since the difference \(f_{t}^{*}-f_{s}^{*}\) is a linear function with respect to the unknown \(\bm{\theta}^{*}\), it can be learned with fewer samples if prior information about \(f_{s}^{*}\) is available. For example, a target model can be obtained by adding \(f_{s}\) to the model \(g\) trained for the intermediate variable \(z=y-f_{s}(\bm{x})\).

The following is a slight generalization of TL procedure provided in [12]:

1. With the source features, perform a variable transformation of the observed outputs as \(z_{i}=\phi(y_{i},\bm{f_{s}}(\bm{x}_{i}))\), using the data transformation function \(\phi:\mathcal{Y}\times\mathcal{F}_{s}\rightarrow\mathbb{R}\).
2. Train an intermediate model \(\hat{g}(\bm{x})\) using the transformed sample set \(\{(\bm{x}_{i},z_{i})\}_{i=1}^{n}\) to predict the transformed output \(z\) for any given \(\bm{x}\).
3. Obtain a target model \(\hat{f_{t}}(\bm{x})=\psi(\hat{g}(\bm{x}),\bm{f_{s}}(\bm{x}))\) using the model transformation function \(\psi:\mathbb{R}\times\mathcal{F}_{s}\rightarrow\mathcal{Y}\) that combines \(\hat{g}\) and \(\bm{f_{s}}\) to define a predictor.

In particular, [12] considers the case where the model transformation function is equal to the inverse of the data transformation function. We consider a more general case that eliminates this constraint.

The objective of step 1 is to identify a transformation \(\phi\) that maps the output variable \(y\) to the intermediate variable \(z\), making the variable suitable for learning. In step 2, a predictive model for \(z\) is constructed. Since the data is limited in many TL setups, a simple model, such as a linear model, should be used as \(g\). Step 3 is to transform the intermediate model \(g\) into a predictive model \(f_{t}\) for the original output \(y\).

This class of TL includes several approaches proposed in previous studies. For example, [10, 11] proposed a learning algorithm consisting of linear data transformation and linear model transformation: \(\phi\!=\!y\!-\!\langle\boldsymbol{\theta},\boldsymbol{f_{s}}\rangle\) and \(\psi\!=\!g(\boldsymbol{x})\!+\!\langle\boldsymbol{\theta},\boldsymbol{f_{s}}\rangle\) with pre-defined weights \(\boldsymbol{\theta}\). In this case, factors unexplained by the linear combination of source features are learned with \(g\), and the target output is predicted additively with the common factor \(\langle\boldsymbol{\theta},\boldsymbol{f_{s}}\rangle\) and the additionally learned \(g\). In [13], it is shown that a type of Bayesian TL is equivalent to using the following transformation functions; for \(\mathcal{F}_{s}\subset\mathbb{R}\), \(\phi\!=\!(y\!-\!\tau f_{s})/(1\!-\!\tau)\) and \(\psi\!=\!\rho g(\boldsymbol{x})\!+\!(1\!-\!\rho)f_{s}\) with two varying hyperparameters \(\tau\!<\!1\) and \(0\!\leq\!\rho\!\leq\!1\). This includes TL using density ratio estimation [14] and neural network-based fine-tuning as special cases when the two hyperparameters belong to specific regions.

The performance of this TL strongly depends on the design of the two transformation functions \(\phi\) and \(\psi\). In the sequel, we theoretically derive the optimal form of transformation functions under the squared loss scenario. For simplicity, we denote the transformation functions as \(\phi_{f,}(\cdot)\!=\!\phi(\cdot,\boldsymbol{f_{s}})\) on \(\mathcal{Y}\) and \(\psi_{f_{s}}(\cdot)\!=\!\psi(\cdot,\boldsymbol{f_{s}})\) on \(\mathbb{R}\). To derive the optimal class of \(\phi\) and \(\psi\), note first that the TL procedure described above can be formulated in population as solving two successive least square problems;

\[(i)\;g^{*}:=\arg\min_{g}\mathbb{E}_{p_{t}}\|\phi_{f_{s}}(Y)-g( \boldsymbol{X})\|^{2},\qquad\quad(ii)\;\min_{\psi}\mathbb{E}_{p_{t}}\|Y-\psi_{ f_{s}}(g^{*}(\boldsymbol{X}))\|^{2}.\]

Since the regression function that minimizes the mean squared error is the conditional mean, the first problem is solved by \(g^{*}_{\phi}(\boldsymbol{x})=\mathbb{E}[\phi_{f_{s}}(Y)|\boldsymbol{X}= \boldsymbol{x}]\), which depends on \(\phi\). We can thus consider the optimal transformation functions \(\phi\) and \(\psi\) by the following minimization:

\[\min_{\psi,\phi}\mathbb{E}_{p_{t}}\|Y-\psi_{f_{s}}(g^{*}_{\phi} (\boldsymbol{X}))\|^{2}.\] (1)

It is easy to see that Eq. (1) is equivalent to the following consistency condition:

\[\psi_{f_{s}}\big{(}g^{*}_{\phi}(\boldsymbol{x})\big{)}=\mathbb{E}_{p_{t}}[Y| \boldsymbol{X}=\boldsymbol{x}].\]

From the above observation, we make three assumptions to derive the optimal form of \(\psi\) and \(\phi\):

**Assumption 2.1** (Differentiability).: The data transformation function \(\phi\) is differentiable with respect to the first argument.

**Assumption 2.2** (Invertibility).: The model transformation function \(\psi\) is invertible with respect to the first argument, i.e., its inverse \(\psi_{f_{s}}^{-1}\) exists.

**Assumption 2.3** (Consistency).: For any distribution on the target domain \(p_{t}(\boldsymbol{x},y)\), and for all \(\boldsymbol{x}\in\mathcal{X}\),

\[\psi_{f_{s}}(g^{*}(\boldsymbol{x}))=\mathbb{E}_{p_{t}}[Y|\boldsymbol{X}= \boldsymbol{x}],\]

where \(g^{*}(\boldsymbol{x})=\mathbb{E}_{p_{t}}[\phi_{f_{s}}(Y)|\boldsymbol{X}= \boldsymbol{x}]\).

Assumption 2.2 is commonly used in most existing HTL settings, such as [10] and [12]. It assumes a one-to-one correspondence between the predictive value \(\hat{f}_{t}(\boldsymbol{x})\) and the output of the intermediate model \(\hat{g}(\boldsymbol{x})\). If this assumption does not hold, then multiple values of \(\hat{g}\) correspond to the same predicted value \(\hat{f}_{t}\), which is unnatural. Note that Assumption 2.3 corresponds to the unbiased condition of [12].

We now derive the properties that the optimal transformation functions must satisfy.

**Theorem 2.4**.: _Under Assumptions 2.1-2.3, the transformation functions \(\phi\) and \(\psi\) satisfy the following two properties:_

\[(i)\;\;\;\psi_{f_{s}}^{-1}=\phi_{f_{s}}.\qquad\qquad(ii)\;\;\; \psi_{f_{s}}(g)=g_{1}(\boldsymbol{f_{s}})+g_{2}(\boldsymbol{f_{s}})\cdot g,\]

_where \(g_{1}\) and \(g_{2}\) are some functions._The proof is given in Section D.1 in Supplementary Material. Despite not initially assuming that the two transformation functions are inverses, Theorem 2.4 implies they must indeed be inverses. Furthermore, the mean squared error is minimized when the data and model transformation functions are given by an affine transformation and its inverse, respectively. In summary, under the expected squared loss minimization with the HTL procedure, the optimal class for HTL model is expressed as follows:

\[\mathcal{H}=\big{\{}\bm{x}\mapsto g_{1}(\bm{f_{s}})+g_{2}(\bm{f_{s}})g_{3}(\bm {x})\mid g_{j}\in\mathcal{G}_{j},j=1,2,3\big{\}},\]

where \(\mathcal{G}_{1},\mathcal{G}_{2}\) and \(\mathcal{G}_{3}\) are the arbitrarily function classes. Here, each of \(g_{1}\) and \(g_{2}\) is modeled as a function of \(\bm{f_{s}}\) that represents common factors across the source and target domains. \(g_{3}\) is modeled as a function of \(\bm{x}\), in order to capture the domain-specific factors unexplainable by the source features.

We have derived the optimal form of the transformation functions when the squared loss is employed. Even for general convex loss functions, (i) of Theorem 2.4 still holds. However, (ii) of Theorem 2.4 does not generally hold because the optimal transformation function depends on the loss function. Extensions to other losses are briefly discussed in Section A.1, but the establishment of a complete theory is a future work.

Here, the affine transformation is found to be optimal in terms of minimizing the mean squared error. We can also derive the same optimal function by minimizing the upper bound of the estimation error in the HTL procedure, as discussed in Section A.2.

One of key principles for the design of \(g_{1}\), \(g_{2}\), and \(g_{3}\) is interpretability. In our model, \(g_{1}\) and \(g_{2}\) primarily facilitate knowledge transfer, while the estimated \(g_{3}\) is used to gain insight on domain-specific factors. For instance, in order to infer cross-domain differences, we could design \(g_{1}\) and \(g_{2}\) by the conventional neural feature extraction, and a simple, highly interpretable model such as a linear model could be used for \(g_{3}\). Thus, observing the estimated regression coefficients in \(g_{3}\), one can statistically infer which features of \(\bm{x}\) are related to inter-domain differences. This advantage of the proposed method is demonstrated in Section 5.2 and Section B.3.

### Relation to Existing Methods

The affine model transfer encompasses some existing TL procedures. For example, by setting \(g_{1}(\bm{f_{s}})=0\) and \(g_{2}(\bm{f_{s}})=1\), the prediction model is estimated without using the source features, which corresponds to an ordinary direct learning, i.e., a learning scheme without transfer. Furthermore, various kinds of HTLs can be formulated by imposing constraints on \(g_{1}\) and \(g_{2}\). In prior work, [10] employs a two-step procedure where the source features are combined with pre-defined weights, and then the auxiliary model is additionally learned for the residuals unexplainable by the source features. The affine model transfer can represent this HTL as a special case by setting \(g_{2}=1\). [12] uses the transformed output \(z_{i}=y_{i}/f_{s}\) with the output value \(f_{s}\in\mathbb{R}\) of a source model, and this cross-domain shift is then regressed onto \(\bm{x}\) using a target dataset. This HTL corresponds to \(g_{1}=0\) and \(g_{2}=f_{s}\).

When a pre-trained source model is provided as a neural network, TL is usually performed with the intermediate layer as input to the model in the target domain. This is called a feature extractor or frozen featurizer and has been experimentally and theoretically proven to have strong transfer capability as the de facto standard for TL [9; 15]. The affine model transfer encompasses the neural feature extraction as a special subclass, which is equivalent to setting \(g_{2}(\bm{f_{s}})g_{3}(\bm{x})=0\). A performance comparison of the affine model transfer with the neural feature extraction is presented in Section 5 and Section B.2. The relationships between these existing methods and the affine model transfer are illustrated in Figure 1 and Figure S.1

The affine model transfer can also be interpreted as generalizing the feature extraction by adding a product term \(g_{2}(\bm{f_{s}})g_{3}(\bm{x})\). This additional term allows for the inclusion of unknown factors in the transferred model that are unexplainable by source features alone. Furthermore, this encourages the avoidance of a negative transfer, a phenomenon where prior learning experiences interfere with training in a new task. The usual TL based only on \(\bm{f_{s}}\) attempts to explain and predict the data generation process in the target domain using only the source features. However, in the presence of domain-specific factors, a negative transfer can occur owing to a lack of descriptive power. The additional term compensates for this shortcoming. The comparison of behavior for the case with the non-relative source features is described in Section 5.1.

he affine model transfer can be naturally expressed as an architecture of network networks. This architecture, called affine coupling layers, is widely used for invertible neural networks in flow-based generative modeling [16; 17]. Neural networks based on affine coupling layers have been proven to have universal approximation ability [18]. This implies that the affine transfer model has the potential to represent a wide range of function classes, despite its simple architecture based on the affine coupling of three functions.

## 3 Modeling and Estimation

In this section, we focus on using kernel methods for the affine transfer model and provide the estimation algorithm. Let \(\mathcal{H}_{1},\mathcal{H}_{2}\) and \(\mathcal{H}_{3}\) be reproducing kernel Hilbert spaces (RKHSs) with positive-definite kernels \(k_{1},k_{2}\) and \(k_{3}\), which define the feature mappings \(\Phi_{1}\!:\!\mathcal{F}_{s}\!\rightarrow\!\mathcal{H}_{1}\), \(\Phi_{2}\!:\!\mathcal{F}_{s}\!\rightarrow\!\mathcal{H}_{2}\) and \(\Phi_{3}\!:\!\mathcal{X}\!\rightarrow\!\mathcal{H}_{3}\), respectively. Denote \(\Phi_{1,i}\!=\!\Phi_{1}(\bm{f_{s}}(\bm{x}_{i})),\Phi_{2,i}\!=\!\Phi_{2}(\bm{f_{ s}}(\bm{x}_{i})),\Phi_{3,i}\!=\!\Phi_{3}(\bm{x}_{i})\). For the proposed model class, the \(\ell_{2}\)-regularized empirical risk with the squared loss is given as follows:

\[F_{\alpha,\beta,\gamma}=\frac{1}{n}\sum_{i=1}^{n}\big{\{}y_{i}\!-\!\langle \alpha,\Phi_{1,i}\rangle\!-\!\langle\beta,\Phi_{2,i}\rangle\langle\gamma,\Phi_ {3,i}\rangle\big{\}}^{2}+\lambda_{1}\|\alpha\|^{2}_{\mathcal{H}_{1}}+\lambda_ {2}\|\beta\|^{2}_{\mathcal{H}_{2}}+\lambda_{3}\|\gamma\|^{2}_{\mathcal{H}_{3}},\] (2)

where \(\lambda_{1}\),\(\lambda_{2}\),\(\lambda_{3}\!\geq\!0\) are hyperparameters for the regularization. According to the representer theorem, the minimizer of \(F_{\alpha,\beta,\gamma}\) with respect to the parameters \(\alpha\in\mathcal{H}_{1}\), \(\beta\in\mathcal{H}_{2}\), and \(\gamma\in\mathcal{H}_{3}\) reduces to \(\alpha=\sum_{i=1}^{n}a_{i}\Phi_{1,i},\beta=\sum_{i=1}^{n}b_{i}\Phi_{2,i},\gamma =\sum_{i=1}^{n}c_{i}\Phi_{3,i},\) with the \(n\)-dimensional unknown parameter vectors \(\bm{a},\bm{b},\bm{c}\in\mathbb{R}^{n}\). Substituting this expression into Eq. (2), we obtain the objective function as

\[F_{\alpha,\beta,\gamma}=\frac{1}{n}\|y\!-\!K_{1}\bm{a}\!-\!(K_{2}\bm{b})\circ (K_{3}\bm{c})\|^{2}_{2}\!+\!\lambda_{1}\bm{a}^{\top}K_{1}\bm{a}\!+\!\lambda_{2 }\bm{b}^{\top}K_{2}\bm{b}\!+\!\lambda_{3}\bm{c}^{\top}K_{3}\bm{c}\!=:\!F(\bm{a}, \bm{b},\bm{c}).\] (3)

Here, the symbol \(\circ\) denotes the Hadamard product. \(K_{I}\) is the Gram matrix associated with the kernel \(k_{I}\) for \(I\in\{1,2,3\}\). \(k_{I}^{(i)}=[k_{I}(\bm{x}_{i},\bm{x}_{1})\cdots k_{I}(\bm{x}_{i},\bm{x}_{n})]^ {\top}\) denotes the \(i\)-th column of the Gram matrix. The \(n\times n\) matrix \(M^{(i)}\) is given by the tensor product \(M^{(i)}=k_{2}^{(i)}\otimes k_{3}^{(i)}\) of \(k_{2}^{(i)}\) and \(k_{3}^{(i)}\).

Because the model is linear with respect to parameter \(a\) and bilinear for \(b\) and \(c\), the optimization of Eq. (3) can be solved using well-established techniques for the low-rank tensor regression. In this study, we use the block relaxation algorithm [19] as described in Algorithm 1. It updates \(a,b\), and \(c\) by repeatedly fixing two of the three parameters and minimizing the objective function for the remaining one. Fixing two parameters, the resulting subproblem can be solved analytically because the objective function is expressed in a quadratic form for the remaining parameter.

``` Initialize:\(\bm{a}_{0}\), \(\bm{b}_{0}\neq\bm{0}\), \(\bm{c}_{0}\neq\bm{0}\) repeat \(\bm{a}_{t+1}=\text{arg min}_{\bm{a}}\,F(\bm{a},\ \bm{b}_{t},\,\bm{c}_{t})\)\(\bm{b}_{t+1}=\text{arg min}_{\bm{b}}\,F(\bm{a}_{t+1},\,\bm{b},\ \bm{c}_{t})\)\(\bm{c}_{t+1}=\text{arg min}_{\bm{c}}\,F(\bm{a}_{t+1},\,\bm{b}_{t+1},\,\bm{c})\) until convergence ```

**Algorithm 1** Block relaxation algorithm [19].

Algorithm 1 can be regarded as repeating the HTL procedure introduced in Section 2.1; alternately estimates the parameters \((\bm{a},\bm{b})\) of the transformation function and the parameters \(\bm{c}\) of the model for the given transformed data \(\{(\bm{x}_{i},z_{i})\}_{i=1}^{n}\). The function \(F\) in Algorithm 1 is not jointly convex in general. However, when employing methods like kernel methods or generalized linear models, and fixing two parameters, \(F\) exhibits convexity with respect to the remaining parameter. According to [19], when each sub-minimization problem is convex, Algorithm 1 is guaranteed to converge to a stationary point. Furthermore, [19] showed that consistency and asymptotic normality hold for the alternating minimization algorithm.

## 4 Theoretical Results

In this section, we present two theoretical properties, the generalization bound and excess risk bound.

Figure 1: Architectures of (a) feature extraction, (b) HTL in [10], and (c) affine model transfer.

Let \((\mathcal{Z},P)\) be an arbitrary probability space, and \(\{z_{i}\}_{i=1}^{n}\) be independent random variables with distribution \(P\). For a function \(f\colon\mathcal{Z}\!\to\!\mathbb{R}\), let the expectation of \(f\) with respect to \(P\) and its empirical counterpart denote respectively by \(Pf=\mathbb{E}_{P}f(z),P_{n}f=\frac{1}{n}\sum_{i=1}^{n}f(z_{i})\). We use a non-negative loss \(\ell(y,y^{\prime})\) such that it is bounded from above by \(L>0\) and for any fixed \(y^{\prime}\in\mathcal{Y}\), \(y\!\mapsto\!\ell(y,y^{\prime})\) is \(\mu_{\ell}\)-Lipschitz for some \(\mu_{\ell}>0\).

Recall that the function class proposed in this work is

\[\mathcal{H}=\big{\{}x\mapsto g_{1}(\bm{f_{s}})+g_{2}(\bm{f_{s}})g_{3}(\bm{x}) \mid g_{j}\in\mathcal{G},j=1,2,3\big{\}}.\]

In particular, the following discussion in this section assumes that \(g_{1},g_{2}\), and \(g_{3}\) are represented by linear functions on the RKHSs.

### Generalization Bound

The optimization problem is expressed as follows:

\[\min_{\alpha,\beta,\gamma}P_{n}\ell\big{(}y,\,\langle\alpha,\Phi_{1}\rangle_{ \mathcal{H}_{1}}+\langle\beta,\Phi_{2}\rangle_{\mathcal{H}_{2}}\langle\gamma, \Phi_{3}\rangle_{\mathcal{H}_{3}}\big{)}+\lambda_{\alpha}\|\alpha\|_{ \mathcal{H}_{1}}^{2}+\lambda_{\beta}\|\beta\|_{\mathcal{H}_{2}}^{2}+\lambda_{ \gamma}\|\gamma\|_{\mathcal{H}_{3}}^{2},\] (4)

where \(\Phi_{1}=\Phi_{1}(\bm{f_{s}}(\bm{x})),\Phi_{2}=\Phi_{2}(\bm{f_{s}}(\bm{x}))\) and \(\Phi_{3}=\Phi_{3}(\bm{x})\) denote the feature maps. Without loss of generality, it is assumed that \(\|\Phi_{i}\|_{\mathcal{H}_{i}}^{2}\leq 1\) (\(i=1,2,3\)) and \(\lambda_{\alpha},\lambda_{\beta},\lambda_{\gamma}>0\). Hereafter, we will omit the suffixes \(\mathcal{H}_{i}\) in the norms if there is no confusion.

Let \((\hat{\alpha},\hat{\beta},\hat{\gamma})\) be a solution of Eq. (4), and denote the corresponding function in \(\mathcal{H}\) as \(\hat{h}\). For any \(\alpha\), we have

\[\lambda_{\alpha}\|\hat{\alpha}\|^{2}\!\leq\!P_{n}\ell(y,\langle\hat{\alpha},\!\Phi_{1}\rangle\!+\!\langle\hat{\beta},\!\Phi_{2}\rangle\!\langle\hat{ \gamma},\!\Phi_{3}\rangle)\!+\!\lambda_{\alpha}\|\hat{\alpha}\|^{2}\!+\! \lambda_{\beta}\|\hat{\beta}\|^{2}\!+\!\lambda_{\gamma}\|\hat{\gamma}\|^{2}\! \leq\!P_{n}\ell(y,\langle\alpha,\!\Phi_{1}\rangle\!)\!+\!\lambda_{\alpha}\| \alpha\|^{2},\]

where we use the fact that \(\ell(\cdot,\cdot)\) and \(\|\cdot\|\) are non-negative, and \((\hat{\alpha},\hat{\beta},\hat{\gamma})\) is the minimizer of Eq. (4). Denoting \(\hat{R}_{s}=\inf_{\alpha}\{P_{n}\ell(y,\langle\alpha,\Phi_{1}\rangle)+\lambda_ {\alpha}\|\alpha\|^{2}\}\), we obtain \(\|\hat{\alpha}\|^{2}\leq\lambda_{\alpha}^{-1}\hat{R}_{s}\). Because the same inequality holds for \(\lambda_{\beta}\|\hat{\beta}\|^{2},\lambda_{\gamma}\|\hat{\gamma}\|^{2}\) and \(P_{n}\ell(y,\hat{h})\), we have \(\|\hat{\beta}\|^{2}\leq\lambda_{\beta}^{-1}\hat{R}_{s},\|\hat{\gamma}\|^{2} \leq\lambda_{\gamma}^{-1}\hat{R}_{s}\) and \(P_{n}\ell(y,\hat{h})\leq\hat{R}_{s}\). Moreover, we have \(P\ell(y,\hat{h})=\mathbb{E}P_{n}\ell(y,\hat{h})\leq\mathbb{E}\hat{R}_{s}\). Therefore, it is sufficient to consider the following hypothesis class \(\tilde{\mathcal{H}}\) and loss class \(\mathcal{L}\):

\[\tilde{\mathcal{H}}= \big{\{}x\!\mapsto\!\langle\alpha,\!\Phi_{1}\rangle\!+\!\langle \beta,\!\Phi_{2}\!\langle\gamma,\!\Phi_{3}\rangle\big{\}}\big{\|}\alpha\|^{2}\! \leq\!\lambda_{\alpha}^{-1}\hat{R}_{s},\,\|\beta\|^{2}\!\leq\!\lambda_{\beta}^{- 1}\hat{R}_{s},\,\|\gamma\|^{2}\!\leq\!\lambda_{\gamma}^{-1}\hat{R}_{s},P\ell(y, h)\!\leq\!\mathbb{E}\hat{R}_{s}\big{\}},\] \[\mathcal{L}= \big{\{}(x,y)\mapsto\ell(y,h)\ \mid\ h\in\tilde{\mathcal{H}}\big{\}}.\]

Here, we show the generalization bound of the proposed model class. The following theorem is based on [11], showing that the difference between the generalization error and empirical error can be bounded using the magnitude of the relevance of the domains.

**Theorem 4.1**.: _There exists a constant \(C\) depending only on \(\lambda_{\alpha},\lambda_{\beta},\lambda_{\gamma}\) and \(L\) such that, for any \(\eta>0\) and \(h\in\tilde{\mathcal{H}}\), with probability at least \(1-e^{-\eta}\),_

\[P\ell(y,\,h)-P_{n}\ell(y,\,h)=\ \tilde{O}\bigg{(}\bigg{(}\sqrt{\frac{R_{s}}{n}}+ \frac{\mu_{\ell}^{2}C^{2}+\sqrt{\eta}}{n}\bigg{)}\big{(}C+\sqrt{\eta}\big{)}+ \frac{C^{2}+\eta}{n}\bigg{)},\]

_where \(R_{s}=\inf_{\alpha}\{P\ell(y,\langle\alpha,\Phi_{1}\rangle)+\lambda_{\alpha}\| \alpha\|^{2}\}\)._

Because \(\Phi_{1}\) is the feature map from the source feature space \(\mathcal{F}_{s}\) into the RKHS \(\mathcal{H}_{1}\), \(R_{s}\) corresponds to the true risk of training in the target domain using only the source features \(f_{s}\). If this is sufficiently small, e.g., \(R_{s}=\tilde{O}(n^{-1/2})\), the convergence rate indicated by Theorem 4.1 becomes \(n^{-1}\), which is an improvement over the naive convergence rate \(n^{-1/2}\). This means that if the source task yields feature representations strongly related to the target domain, training in the target domain is accelerated. Theorem 4.1 measures this cross-domain relation using the metric \(R_{s}\).

Theorem 4.1 is based on Theorem 11 of [11] in which the function class \(g_{1}\!+\!g_{3}\) is considered. Our work differs in the following two points: the source features are modeled not only additively but also multiplicatively, i.e., we consider the function class \(g_{1}\!+\!g_{2}\!\cdot\!g_{3}\), and we also consider the estimation of the parameters for the source feature combination, i.e., the parameters of the functions \(g_{1}\) and \(g_{2}\). In particular, the latter affects the resulting rate. With fixed the source combination parameters, the resulting rate improves only up to \(n^{-3/4}\). The details are discussed in Section D.2.

### Excess Risk Bound

Here, we analyze the excess risk, which is the difference between the risk of the estimated function and the smallest possible risk within the function class.

Recall that we consider the functions \(g_{1},g_{2}\) and \(g_{3}\) to be elements of the RKHSs \(\mathcal{H}_{1},\mathcal{H}_{2}\) and \(\mathcal{H}_{3}\) with kernels \(k_{1},k_{2}\) and \(k_{3}\), respectively. Define the kernel \(k^{(1)}\!=\!k_{1}\), \(k^{(2)}\!=\!k_{2}\!\cdot\!k_{3}\) and \(k\!=\!k^{(1)}+k^{(2)}\). Let \(\mathcal{H}^{(1)},\mathcal{H}^{(2)}\) and \(\mathcal{H}\) be the RKHS with \(k^{(1)},k^{(2)}\) and \(k\) respectively. For \(m\!=\!1,2\), consider the normalized Gram matrix \(K^{(m)}\!=\!\frac{1}{n}(k^{(m)}(\bm{x}_{i},\bm{x}_{j}))_{i,j=1,\ldots,n}\) and its eigenvalues \((\hat{\lambda}_{i}^{(m)})_{i=1}^{n}\), arranged in a nonincreasing order.

We make the following additional assumptions:

**Assumption 4.2**.: There exists \(h^{*}\in\mathcal{H}\) and \(h^{(m)*}\in\mathcal{H}^{(m)}\) (\(m=1,2\)) such that \(P(y-h^{*}(\bm{x}))^{2}=\inf_{h\in\mathcal{H}}P(y-h(\bm{x}))^{2}\) and \(P(y-h^{(m)*}(\bm{x}))^{2}=\inf_{h\in\mathcal{H}^{(m)}}P(y-h(\bm{x}))^{2}\).

**Assumption 4.3**.: For \(m=1,2\), there exist \(a_{m}>0\) and \(s_{m}\in(0,1)\) such that \(\hat{\lambda}_{j}^{(m)}\leq a_{m}j^{-1/s_{m}}\).

Assumption 4.2 is used in [20] and is not overly restrictive as it holds for many regularization algorithms and convex, uniformly bounded function classes. In the analysis of kernel methods, Assumption 4.3 is standard [21], and is known to be equivalent to the classical covering or entropy number assumption [22]. The inverse decay rate \(s_{m}\) measures the complexity of the RKHS, with larger values corresponding to more complex function spaces.

**Theorem 4.4**.: _Let \(\hat{h}\) be any element of \(\mathcal{H}\) satisfying \(P_{n}(y-\hat{h}(\bm{x}))^{2}=\inf_{h\in\mathcal{H}}P_{n}(y-h(\bm{x}))^{2}\). Under Assumptions 4.2 and 4.3, for any \(\eta>0\), with probability at least \(1-5e^{-\eta}\),_

\[P(y-\hat{h}(\bm{x}))^{2}-P(y-h^{*}(\bm{x}))^{2}=O\Big{(}n^{-\frac{1}{1+\max{( s_{1},s_{2})}}}\Big{)}.\]

Theorem 4.4 suggests that the convergence rate of the excess risk depends on the decay rates of the eigenvalues of two Gram matrices \(K^{(1)}\) and \(K^{(2)}\). The inverse decay rate \(s_{1}\) of the eigenvalues of \(K^{(1)}\!=\!\frac{1}{n}(k_{1}(\bm{f_{s}}(\bm{x}_{i}),\bm{f_{s}}(\bm{x}_{j})))_{ i,j=1,\ldots,n}\) represents the learning efficiency using only the source features, while \(s_{2}\) is the inverse decay rate of the eigenvalues of the Hadamard product of \(K_{2}=\frac{1}{n}(k_{2}(\bm{f_{s}}(\bm{x}_{i}),\bm{f_{s}}(\bm{x}_{j}))_{i,j=1, \ldots,n}\) and \(K_{3}=\frac{1}{n}(k_{3}(\bm{x}_{i},\bm{x}_{j}))_{i,j=1,\ldots,n}\), which addresses the effect of combining the source features and original input. While rigorous discussion on the relationship between the spectra of two Gram matrices \(K_{2},K_{3}\) and their Hadamard product \(K_{2}\!\circ\!K_{3}\) seems difficult, intuitively, the smaller the overlap between the space spanned by the source features and by the original input, the smaller the overlap between \(\mathcal{H}_{2}\) and \(\mathcal{H}_{3}\). In other words, as the source features and original input have different information, the tensor product \(\mathcal{H}_{2}\!\otimes\!\mathcal{H}_{3}\) will be more complex, and the decay rate \(1/s_{2}\) is expected to be larger. In Section B.1, we experimentally confirm this speculation.

## 5 Experimental Results

We demonstrate the potential of the affine model transfer through two case studies: (i) the prediction of feed-forward torque at seven joints of the robot arm [23], and (ii) the prediction of review scores and decisions of scientific papers [24]. The experimental details are presented in Section C. Additionally, two case studies in materials science are presented in Section B. The Python code is available at https://github.com/mshunya/AffineTL.

### Kinematics of the Robot Arm

We experimentally investigated the learning performance of the affine model transfer, compared to several existing methods. The objective of the task is to predict the feed-forward torques, required to follow the desired trajectory, at seven different joints of the SARCOS robot arm [23]. Twenty-one features representing the joint position, velocity, and acceleration were used as the input \(\bm{x}\). The target task is to predict the torque value at one joint. The representations encoded in the intermediate layer of the source neural network for predicting the other six joints were used as the source features \(\bm{f_{s}}\in\mathbb{R}^{16}\). The experiments were conducted with seven different tasks (denoted as Torque 1-7) corresponding to the seven joints. For each target task, a training set of size \(n\in\{5,10,15,20,30,40,50\}\) was randomly constructed 20 times, and the performances were evaluated using the test data.

The following seven methods were compared, including two existing HTL procedures:

* **Direct** Train a model using the target input \(\bm{x}\) with no transfer.
* **Only source** Train a model \(g(\bm{f_{s}})\) using only the source feature \(\bm{f_{s}}\).
* **Augmented** Perform a regression with the augmented input vector concatenating \(\bm{x}\) and \(\bm{f_{s}}\).
* **HTL-offset** Calculate the transformed output \(z_{i}=y_{i}-g_{\text{only}}(\bm{f_{s}})\) where \(g_{\text{only}}(\bm{f_{s}})\) is the model pre-trained using **Only source**, and train an additional model with input \(\bm{x}_{i}\) to predict \(z_{i}\).
* **HTL-scale** Calculate the transformed output \(z_{i}=y_{i}/g_{\text{only}}(\bm{f_{s}})\), and train an additional model with input \(\bm{x}_{i}\) to predict \(z_{i}\).
* **AffineTL-full** Train the model \(g_{1}+g_{2}\cdot g_{3}\).
* **AffineTL-const** Train the model \(g_{1}+g_{3}\).

Kernel ridge regression with the Gaussian kernel \(\exp(-\|\bm{x}-\bm{x}^{\prime}\|^{2}/2\ell^{2})\) was used for each procedure. The scale parameter \(\ell\) was fixed to the square root of the dimension of the input. The regularization parameter in the kernel ridge regression and \(\lambda_{\alpha},\lambda_{\beta}\), and \(\lambda_{\gamma}\) in the affine model transfer were selected through 5-fold cross-validation. In addition to the seven feature-based methods, four weight-based TL methods were evaluated: fine-tuning, MAML [25], \(L^{2}\)-SP [26], and PAC-Net [27].

Table 1 summarizes the prediction performance of the seven different procedures for varying numbers of training samples in two representative tasks: Torque 1 and Torque 7. The joint of Torque 1 is located closest to the root of the arm. Therefore, the learning task for Torque 1 is less relevant to those for the other joints, and the transfer from Torque 2-6 to Torque 1 would not work. In fact, as shown in Table 1, no method showed a statistically significant improvement to **Direct**. In particular, **Only source** failed to acquire predictive ability, and **HTL-offset** and **HTL-scale** likewise showed poor prediction performance owing to the negative effect of the failure in the variable transformation. In contrast, the two affine transfer models showed almost the same predictive performance as **Direct**, which is expressed as its submodel, and successfully suppressed the occurrence of negative transfer.

Because Torque 7 was measured at the joint closest to the end of the arm, its value strongly depends on those at the other six joints, and the procedures with the source features were more effective than in the other tasks. In particular, **AffineTL** achieved the best performance among the other feature-based methods. This is consistent with the theoretical result that the transfer capability of the affine model transfer can be further improved when the risk of learning using only the source features is sufficiently small.

\begin{table}
\begin{tabular}{l l c c c c c c} \hline \hline \multirow{2}{*}{Target} & \multirow{2}{*}{Model} & \multicolumn{4}{c}{Number of training samples} & \multicolumn{2}{c}{\(n>d\)} \\ \cline{3-8}  & & 5 & 10 & 15 & 20 & 30 & 40 & 50 \\ \hline \multirow{8}{*}{Torque 1} & Direct & \(21.3\pm 2.04\) & \(18.9\pm 2.11\) & \(\bm{17.4\pm 1.79}\) & \(15.8\pm 1.70\) & \(13.7\pm 1.26\) & \(12.2\pm 1.61\) & \(10.8\pm 1.23\) \\  & Only source & \(24.0\pm 6.37\) & \(22.3\pm 3.10\) & \(21.0\pm 2.49\) & \(19.7\pm 1.34\) & \(18.5\pm 1.92\) & \(17.6\pm 1.59\) & \(17.3\pm 1.31\) \\  & Augmented & \(21.8\pm 2.88\) & \(19.2\pm 1.37\) & \(17.8\pm 2.30\) & \(\bm{15.7\pm 1.53}\) & \(\bm{13.3\pm 1.19}\) & \(\bm{11.9\pm 1.37}\) & \(\bm{13.7\pm 0.954}\) \\  & HTL-offset & \(23.7\pm 6.50\) & \(21.2\pm 3.85\) & \(19.8\pm 2.33\) & \(17.8\pm 2.85\) & \(12.6\pm 2.31\) & \(15.0\pm 3.16\) & \(15.1\pm 2.76\) \\  & HTL-scale & \(23.3\pm 4.47\) & \(21.2\pm 5.31\) & \(20.4\pm 3.84\) & \(18.5\pm 2.72\) & \(17.6\pm 2.41\) & \(16.9\pm 2.10\) & \(16.7\pm 1.74\) \\  & Affine-full & **21.2\(\pm 2.21\)** & **18.8\(\pm 1.34\)** & \(18.6\pm 2.83\) & \(15.9\pm 1.65\) & \(17.3\pm 1.53\) & \(12.3\pm 1.45\) & \(11.1\pm 1.22\) \\  & AffineTL-const & \(21.2\pm 2.21\) & **18.8\(\pm 1.44\)** & \(17.7\pm 2.44\) & \(15.9\pm 1.58\) & \(13.4\pm 1.15\) & \(12.2\pm 1.54\) & \(10.9\pm 1.02\) \\  & Fine-tune & \(25.0\pm 7.11\) & \(20.5\pm 3.33\) & \(18.6\pm 2.10\) & \(17.6\pm 2.55\) & \(14.1\pm 1.39\) & \(12.6\pm 1.13\) & \(11.1\pm 1.03\) \\  & MAML & \(28.9\pm 1.23\) & \(22.8\pm 3.21\) & \(20.8\pm 2.12\) & \(20.3\pm 3.14\) & \(16.7\pm 2.00\) & \(14.4\pm 1.85\) & \(13.4\pm 1.19\) \\  & \(L^{2}\)-SP & \(24.9\pm 7.03\) & \(20.5\pm 3.30\) & \(18.8\pm 2.04\) & \(18.0\pm 2.45\) & \(14.5\pm 1.36\) & \(13.0\pm 1.13\) & \(11.6\pm 0.933\) \\  & PAC-Net & \(25.2\pm 8.68\) & \(22.5\pm 5.60\) & \(20.7\pm 2.65\) & \(20.1\pm 2.16\) & \(18.5\pm 2.77\) & \(17.6\pm 1.85\) & \(17.1\pm 1.38\) \\ \hline \multirow{8}{*}{Torque 2} & Direct & \(2.66\pm 0.30\) & \(21.3\pm 0.42\) & \(1.85\pm 0.418\) & \(15.4\pm 0.33\) & \(13.2\pm 0.20\) & \(11.8\pm 0.13\) & \(10.8\pm 0.111\) \\  & Only source & \(23.1\pm 0.618\) & \(17.3\pm 0.50\) & \(14.9\pm 0.513\) & \(12.2\pm 0.269\) & \(1.09\pm 0.232\) & \(0.96\pm 0.144\) & \(0.92\pm 0.170\) \\  & Augmented & \(2.47\pm 0.46\) & \(10.9\pm 0.515\) & \(1.67\pm 0.522\) & \(1.31\pm 0.244\) & \(11.16\pm 0.225\) & \(0.98\pm 0.149\) & \(0.87\pm 0.138\) \\  & HTL-offset & \(2.29\pm 0.621\) & \(\bm{15.69\pm 0.507}\) & \(1.49\pm 0.513\) & \(1.22\pm 0.269\) & \(1.09\pm 0.233\) & \(0.96\pm 0.144\) & \(0.92\pm 0.171\) \\  & HTL-scale & \(2.32\pm 0.599\) & \(1.71\pm 0.515\) & \(1.51\pm 0.513\) & \(1.24\pm 0.217\) & \(1.11\pm 0.234\) & \(0.99\pm 0.175\) & \(0.94\pm 0.172\) \\  & AffineTL-full & \(\bm{23.63\pm 0.586}\) & \(\bm{17In Table S.3 in Section C.1, we present the results for all tasks. In most cases, **AffineTL** achieved the best performance among the feature-based methods. In several other cases, **Direct** produced the best results; in almost all cases, **Only source** and the two HTLs showed no advantage over **AffineTL**. Comparing the weight-based and feature-based methods, we noticed that the weight-based methods showed higher performance with large sample sizes. Nevertheless, in scenarios with extremely small sample sizes (e.g., \(n\!=\!5\) or \(10\)), **AffineTL** exhibited comparable or even superior performance.

The strength of our method compared to weight-based TLs including fine-tuning is that it does not degrade its performance in cases where cross-domain relationships are weak. While fine-tuning outperformed our method in cases of Torque 7, the performance of fine-tuning was significantly degraded as the source-target relationship became weaker, as seen in Torque 1 case. In contrast, our method was able to avoid negative transfer even for such cases. This characteristic is particularly beneficial because, in many cases, the degree of relatedness between the domains is not known in advance. Furthermore, weight-based methods can sometimes be unsuitable, especially when transferring knowledge from large models, such as LLMs. In these scenarios, fine-tuning all parameters is unfeasible, and feature-based TL is preferred. Our approach often outperforms other feature-based methods.

### Evaluation of Scientific Documents

Through a case study in natural language processing, we compare the performance of the affine model transfer with that of ordinary feature extraction-based TL and show the advantage of being able to estimate domain shift and domain-specific factors separately.

We used SciRepEval [24], a benchmark dataset of scientific documents. The dataset consists of abstracts, review scores, and decision statuses of papers submitted to various machine learning conferences. We focused on two primary tasks: a regression task to predict the average review score, and a binary classification task to determine the acceptance or rejection status of each paper. The original input \(\bm{x}\) was represented by a two-gram bag-of-words vector of the abstract. For the source features \(\bm{f_{s}}\), we utilized text embeddings of the abstract generated by the pre-trained language models; BERT [28], SciBERT [29], T5 [30], and GPT-3 [31]. In the affine model transfer, we employed neural networks with two hidden layers to model \(g_{1}\) and \(g_{2}\), and a linear model for \(g_{3}\). For comparison, we also evaluated the performance of the ordinary feature extraction-based TL using a two-layer neural network with \(\bm{f_{s}}\) as inputs. We used 8,166 training samples and evaluated the performance of the model on 2,043 test samples.

Table 2 shows the root mean square error (RMSE) for the regression task and accuracy for the classification task. In the regression tasks, the RMSEs of the affine model transfer were significantly improved over the ordinary feature extraction for the four types of text feature embedding. We also observed the improvements in accuracy for the classification task even though the affine model transfer was derived on the basis of regression settings. While the pre-trained language models have the remarkable ability to represent text quality and structure, their representation ability to perform prediction tasks for machine learning documents is not sufficient. The affine model transfer effectively bridged this gap by learning the additional target-specific factor via the target task, resulting in improved prediction performance in both regression and classification tasks.

Table 3 provides a list of phrases that were estimated to have a positive or negative effect on the review scores. Because we restricted a network to output positive values for \(g_{2}\), the influence of each phrase could be inferred from the estimated coefficients of the linear model \(g_{3}\). Specifically, phrases such as _"tasks including"_ and _"new state"_ were estimated to have positive influences on the predicted score. These phrases often appear in contexts such as _"demonstrated on a wide range of tasks including"_ or _"establishing a new state-of-the-art result,"_, suggesting that superior experimental results tend to yield higher peer review scores. In addition, the phrase _"theoretical analysis"_ was also identified to have a positive effect on the review score, reflecting the significance of theoretical validation in machine learning research. On the contrary, general phrases with broader meanings such as _"recent advances"_ and _"machine learning,"_ contributed to lower scores. This observation suggests the importance of explicitly stating the novelty and uniqueness of research findings and refraining from using generic terminologies.

As illustrated in this example, integrating modern deep learning techniques and highly interpretable transfer models through the mechanism of the affine model transfer not only enhances prediction performance, but also provides valuable insights into domain-specific factors.

### Case Studies in Materials Science

We conducted two additional case studies, both of which pertain to scientific tasks in the field of materials science. One experiment aims to examine the relationship between qualitative differences in source features and learning behavior of the affine model transfer. In the other experiment, we demonstrate the potential utility of the affine model transfer as a calibration tool bridging computational models and real-world systems. In particular, we highlight the benefits of separately modeling and estimating domain-specific factors through a case study in polymer chemistry. The objective is to predict the specific heat capacity at constant pressure of any given organic polymer with its chemical structure in the polymer's repeating unit. Specifically, we conduct TL to bridge the gap between experimental values and physical properties calculated from molecular dynamics simulations. The details are shown in Section B in Supplementary Material,

## 6 Conclusions

In this study, we introduced a general class of TL based on affine model transformations, and clarified their learning capability and applicability. The proposed affine model transformation was shown to be an optimal class that minimizes the expected squared loss in the HTL procedure. The model is contrasted with widely applied TL methods, such as re-using features from pre-trained models, which lack theoretical foundation. The affine model transfer is model-agnostic; it is easily combined with any machine learning models, features, and physical models. Furthermore, in the model, domain-specific factors are involved in incorporating the source features. From this property, the affine transfer has the ability to handle domain common and unique factors simultaneously and separately.

The advantages of the model were verified theoretically and experimentally in this study. We showed theoretical results on the generalization bound and excess risk bound when the regression tasks are solved by kernel methods. It is shown that if the source feature is strongly related to the target domain, the convergence rate of the generalization bound is improved from naive learning. The excess risk of the proposed TL is evaluated using the eigen-decay of the product kernel, which also illustrates the effect of the overlap between the source and target tasks. In our numerical studies, the affine model transfer generally outperforms in test errors when the target and source tasks have a similarity. We have also seen in the example of NLP that the proposed affine model transfer can identify the (non-)valuable phrases for high-quality papers. This can be done by the affine representation of cross-domain shift and domain-specific factors in our model.

\begin{table}
\begin{tabular}{c c c c} \hline \hline  & \multicolumn{2}{c}{Regression} & Classification \\ \hline \multirow{2}{*}{BERT} & FE & 1.3086 \(\pm\) 0.0035 & 0.6250 \(\pm\) 0.0217 \\  & AffineTL & **1.3069 \(\pm\) 0.0042** & **0.6252 \(\pm\) 0.0163** \\ \hline \multirow{2}{*}{SciBERT} & FE & 1.2856 \(\pm\) 0.0144 & **0.6520 \(\pm\) 0.0106** \\  & AffineTL & **1.2797 \(\pm\) 0.0122** & 0.6507 \(\pm\) 0.0124 \\ \hline \multirow{2}{*}{T5} & FE & 1.3486 \(\pm\) 0.0175 & 0.6344 \(\pm\) 0.0079 \\  & AffineTL & **1.3442 \(\pm\) 0.0030** & **0.6366 \(\pm\) 0.0065** \\ \hline \multirow{2}{*}{GPT-3} & FE & 1.3284 \(\pm\) 0.0138 & 0.6279 \(\pm\) 0.0181 \\  & AffineTL & **1.3234 \(\pm\) 0.0140** & **0.6386 \(\pm\) 0.0095** \\ \hline \hline \end{tabular}
\end{table}
Table 2: Prediction performance of peer review scores and acceptance/rejection for submitted papers. The mean and standard deviation of the RMSE and accuracy are reported for the affine model transfer (AffineTL) and feature extraction (FE). Definitions of asterisks and boldface letters are the same as in Table 1.

\begin{table}
\begin{tabular}{c c c} \hline \hline  & Positive & Negative \\ \hline
1 & tasks including & recent advances \\
2 & new state & novel approach \\
3 & high quality & latent space \\
4 & recently proposed & learning approach \\
5 & latent variable & neural architecture \\
6 & number parameters & machine learning \\
7 & theoretical analysis & attention mechanism \\
8 & policy gradient & reinforcement learning \\
9 & inductive bias & proposed framework \\
10 & image generation & descent sgd \\ \hline \hline \end{tabular}
\end{table}
Table 3: Phrases with the top and bottom ten regression coefficients for \(g_{3}\) in the affine transfer model for the regression task with SciBERT.

## Acknowledgments and Disclosure of Funding

This work was supported by JST SPRING Grant No. JPMJSP2104, JST CREST Grants No. JPMJCR22O3 and No. JPMJCR1913, MEXT KAKENHI Grant-in-Aid for Scientific Research on Innovative Areas (Grant No. 19H50820), the Grant-in-Aid for Scientific Research (A) (Grant No. 19H01132) and Grant-in-Aid for Research Activity Start-up (Grant No. 23K19980) from the Japan Society for the Promotion of Science (JSPS), and the MEXT Program for Promoting Researches on the Supercomputer Fugaku (No. hp210264).

## References

* [1]A. Krizhevsky, I. Sutskever, and G. E. Hinton (2012) ImageNet classification with deep convolutional neural networks. Communications of the ACM60, pp. 84-90. Cited by: SS1.
* [2]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [3]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [4]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [5]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [6]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [7]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [8]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [9]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [10]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [11]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [12]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [13]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [14]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [15]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [16]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [17]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [18]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [19]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [20]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [21]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [22]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [23]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [24]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [25]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [26]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [27]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [28]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [29]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [30]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [31]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [32]S. Ruder, M. E. Peters, Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [33]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [34]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [35]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [36]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [37]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [38]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [39]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [40]S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf (2019) Transfer learning in natural language processing. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18. Cited by: SS1.
* [41]S. Ruder, M. E. Peters,* [16] L. Dinh, D. Krueger, and Y. Bengio, "Nice: Non-linear independent components estimation," _arXiv_, vol. abs/1410.8516, 2014.
* [17] L. Dinh, J. N. Sohl-Dickstein, and S. Bengio, "Density estimation using real nvp," _International Conference on Learning Representations_, 2017.
* [18] T. Teshima, I. Ishikawa, K. Tojo, K. Oono, M. Ikeda, and M. Sugiyama, "Coupling-based invertible neural networks are universal diffeomorphism approximators," _Advances in Neural Information Processing Systems_, vol. 33, pp. 3362-3373, 2020.
* [19] H. Zhou, L. Li, and H. Zhu, "Tensor regression with applications in neuroimaging data analysis," _Journal of the American Statistical Association_, vol. 108, no. 502, pp. 540-552, 2013.
* [20] P. L. Bartlett, O. Bousquet, and S. Mendelson, "Local Rademacher complexities," _Annals of Statistics_, vol. 33, pp. 1497-1537, 2005.
* [21] I. Steinwart and A. Christmann, _Support vector machines_. Springer science & business media, 2008.
* [22] I. Steinwart, D. R. Hush, and C. Scovel, "Optimal rates for regularized least squares regression," _Proceedings of the 22nd Annual Conference on Learning Theory_, pp. 79-93, 2009.
* [23] C. K. Williams and C. E. Rasmussen, _Gaussian processes for machine learning_, vol. 2. MIT press Cambridge, MA, 2006.
* [24] A. Singh, M. D'Arcy, A. Cohan, D. Downey, and S. Feldman, "SciRepEval: A multi-format benchmark for scientific document representations," _ArXiv_, vol. abs/2211.13308, 2022.
* [25] C. Finn, P. Abbeel, and S. Levine, "Model-agnostic meta-learning for fast adaptation of deep networks," _International Conference on Machine Learning_, 2017.
* [26] L. Xuhong, Y. Grandvalet, and F. Davoine, "Explicit inductive bias for transfer learning with convolutional networks," _International Conference on Machine Learning_, pp. 2825-2834, 2018.
* [27] S. Myung, I. Huh, W. Jang, J. M. Choe, J. Ryu, D. Kim, K.-E. Kim, and C. Jeong, "PAC-Net: A model pruning approach to inductive transfer learning," _International Conference on Machine Learning_, pp. 16240-16252, 2022.
* [28] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, "BERT: Pre-training of deep bidirectional transformers for language understanding," _arXiv preprint arXiv:1810.04805_, 2018.
* [29] I. Beltagy, K. Lo, and A. Cohan, "SciBERT: A pretrained language model for scientific text," in _Conference on Empirical Methods in Natural Language Processing_, 2019.
* [30] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, and P. J. Liu, "Exploring the limits of transfer learning with a unified text-to-text transformer," _Journal of Machine Learning Research_, vol. 21, no. 140, pp. 1-67, 2020.
* [31] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, _et al._, "Language models are few-shot learners," _Advances in neural information processing systems_, vol. 33, pp. 1877-1901, 2020.
* [32] R. Vershynin, _High-dimensional probability: An introduction with applications in data science_, vol. 47. Cambridge university press, 2018.
* [33] S. Wu, G. Lambard, C. Liu, H. Yamada, and R. Yoshida, "iQSPR in XenonPy: A Bayesian molecular design algorithm," _Molecular Informatics_, vol. 39, no. 1-2, p. 1900107, 2020.
* [34] C. Liu, K. Kitahara, A. Ishikawa, T. Hiroto, A. Singh, E. Fujita, Y. Katsura, Y. Inada, R. Tamura, K. Kimura, and R. Yoshida, "Quasicrystals predicted and discovered by machine learning," _Phys. Rev. Mater._, vol. 7, p. 093805, 2023.
* [35] C. Liu, E. Fujita, Y. Katsura, Y. Inada, A. Ishikawa, R. Tamura, K. Kimura, and R. Yoshida, "Machine learning to predict quasicrystals from chemical compositions," _Advanced Materials_, vol. 33, no. 36, p. 2102507, 2021.

* [36] D. P. Kingma and J. Ba, "Adam: A method for stochastic optimization," _International Conference for Learning Representations_, 2015.
* [37] J. Wang, R. M. Wolf, J. W. Caldwell, P. A. Kollman, and D. A. Case, "Development and testing of a general amber force field," _Journal of Computational Chemistry_, vol. 25, no. 9, pp. 1157-1174, 2004.
* [38] Y. Hayashi, J. Shiomi, J. Morikawa, and R. Yoshida, "Radonpy: automated physical property calculation using all-atom classical molecular dynamics simulations for polymer informatics," _npj Computational Materials_, vol. 8, no. 222, 2022.
* [39] S. Otsuka, I. Kuwajima, J. Hosoya, Y. Xu, and M. Yamazaki, "PoLyInfo: Polymer database for polymeric materials design," _2011 International Conference on Emerging Intelligent Data and Web Technologies_, pp. 22-29, 2011.
* [40] M. Kusaba, Y. Hayashi, C. Liu, A. Wakiuchi, and R. Yoshida, "Representation of materials by kernel mean embedding," _Physical Review B_, vol. 108, p. 134107, 2023.
* [41] J. Duchi, E. Hazan, and Y. Singer, "Adaptive subgradient methods for online learning and stochastic optimization.," _Journal of machine learning research_, vol. 12, no. 7, 2011.
* [42] D. P. Kingma and J. Ba, "Adam: A method for stochastic optimization," _International Conference for Learning Representations_, 2015.
* [43] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay, "Scikit-learn: Machine learning in Python," _Journal of Machine Learning Research_, vol. 12, pp. 2825-2830, 2011.
* [44] M. Mohri, A. Rostamizadeh, and A. S. Talwalkar, _Foundations of Machine Learning_. MIT press, 2018.
* [45] N. Srebro, K. Sridharan, and A. Tewari, "Smoothness, low noise and fast rates," _Advances in Neural Information Processing Systems_, vol. 23, 2010.
* [46] M. Kloft and G. Blanchard, "The local Rademacher complexity of \(\ell_{p}\)-norm multiple kernel learning," _Advances in Neural Information Processing Systems_, vol. 24, 2011.

Supplementary Material

Transfer Learning with Affine Model Transformation

## Appendix A Other Perspectives on Affine Model Transfer

### Transformation Functions for General Loss Functions

Here we discuss the optimal transformation function for general loss functions.

Let \(\ell(y,y^{\prime})\geq 0\) be a convex loss function that returns zero if and only if \(y=y^{\prime}\), and let \(g^{*}(\bm{x})\) be the optimal predictor that minimizes the expectation of \(\ell\) with respect to the distribution \(p_{t}\) followed by \(\bm{x}\) and \(y\) transformed by \(\phi\):

\[g^{*}(\bm{x})=\arg\min_{g}\mathbb{E}_{p_{t}}\big{[}\ell(g(\bm{x}),\phi_{f_{s}}(y ))\big{]}.\]

The function \(g\) that minimizes the expected loss

\[\mathbb{E}_{p_{t}}\big{[}\ell(g(\bm{x}),\phi_{f_{s}}(y))\big{]}=\iint\ell(g( \bm{x}),\phi_{f_{s}}(y))p_{t}(\bm{x},y)\mathrm{d}\bm{x}\mathrm{d}y\]

should be a solution to the Euler-Lagrange equation

\[\frac{\partial}{\partial g(\bm{x})}\int\ell(g(\bm{x}),\phi_{f_{s}}(y))p_{t}( \bm{x},y)\mathrm{d}y=\int\frac{\partial}{\partial g(\bm{x})}\ell(g(\bm{x}), \phi_{f_{s}}(y))p_{t}(y|\bm{x})\mathrm{d}y\,p_{t}(\bm{x})=0.\] (S.1)

Denote the solution of Eq. (S.1) by \(G(\bm{x};\phi_{f_{s}})\). While \(G\) depends on the loss \(\ell\) and distribution \(p_{t}\), we omit those from the argument for notational simplicity. Using this function, the minimizer of the expected loss \(\mathbb{E}_{\bm{x},y}[\ell(g(\bm{x}),y)]\) can be expressed as \(G(\bm{x};\mathrm{id})\), where \(\mathrm{id}\) represents the identity function.

Here, we consider the following assumption to hold, which generalizes Assumption 2.3 in the main text:

**Assumption 2.3(b)**.: _For any distribution on the target domain \(p_{t}(\bm{x},y)\) and all \(\bm{x}\in\mathcal{X}\), the following relationship holds:_

\[\psi_{f_{s}}(g^{*}(\bm{x}))=\arg\min_{g}\mathbb{E}_{\bm{x},y}[\ell(g(\bm{x}),y )].\]

_Equivalently, the transformation functions \(\phi_{f_{s}}\) and \(\psi_{f_{s}}\) satisfy_

\[\psi_{f_{s}}\big{(}G(\bm{x};\phi_{f_{s}})\big{)}=G(\bm{x};\mathrm{id}).\] (S.2)

Assumption 2.3(b) states that if the optimal predictor \(G(\bm{x};\phi_{f_{s}})\) for the data transformed by \(\phi\) is given to the model transformation function \(\psi\), it is consistent with the overall optimal predictor \(G(\bm{x};\mathrm{id})\) in the target region in terms of the loss function \(\ell\). We consider all pairs of \(\psi\) and \(\phi\) that satisfy this consistency condition.

Here, let us consider the following proposition:

**Proposition A.1**.: _Under Assumption 2.1, 2.2 and 2.3(b), \(\psi_{f_{s}}^{-1}=\phi_{f_{s}}\)._

Proof.: The proof is analogous to that of Theorem 2.4 in Section D.1. For any \(y_{0}\in\mathcal{Y}\), let \(p_{t}(y|\bm{x})=\delta_{y_{0}}\). Combining this with Eq. (S.1) leads to

\[\frac{\partial}{\partial g(\bm{x})}\ell(g(\bm{x}),\phi_{f_{s}}(y_{0}))=0\;( \forall y_{0}\in\mathcal{Y}).\]

Because \(\ell(y,y^{\prime})\) returns the minimum value zero if and only if \(y=y^{\prime}\), we obtain \(G(\bm{x};\phi_{f_{s}})=\phi_{f_{s}}(y_{0})\). Similarly, we have \(G(\bm{x};\mathrm{id})=y_{0}\). From these two facts and Assumption 2.3(b), we have \(\psi_{f_{s}}(\phi_{f_{s}}(y_{0}))=y_{0}\), proving that the proposition is true.

Proposition A.1 indicates that the first statement of Theorem 2.4 holds for general loss functions. However, the second claim of Theorem 2.4 generally depends on the type of loss function. Through the following examples, we describe the optimal class of transformation functions for several loss functions.

**Example 1** (Squared loss).: Let \(\ell(y,y^{\prime})=|y-y^{\prime}|^{2}\). As a solution of Eq. (S.1), we can see that the optimal predictor is the conditional expectation \(\mathbb{E}_{p_{t}}[\phi_{f_{s}}(Y)|\bm{X}=\bm{x}]\). As discussed in Section 2.1, the transformation functions \(\phi_{f_{s}}\) and \(\psi_{f_{s}}\) should be affine transformations.

**Example 2** (Absolute loss).: Let \(\ell(y,y^{\prime})=|y-y^{\prime}|\). Substituting this into Eq. (S.1), we have

\[0 =\int\frac{\partial}{\partial g(\bm{x})}\big{|}g(\bm{x})-\phi_{f_ {s}}(y)\big{|}p_{t}(y|\bm{x})\mathrm{d}y\] \[=\int\mathrm{sign}\big{(}g(\bm{x})-\phi_{f_{s}}(y)\big{)}p_{t}(y| \bm{x})\mathrm{d}y\] \[=\int_{\phi_{f_{s}}(y)\geq g(\bm{x})}p_{t}(y|\bm{x})\mathrm{d}y- \int_{\phi_{f_{s}}(y)<g(\bm{x})}p_{t}(y|\bm{x})\mathrm{d}y.\]

Assuming that \(\phi_{f_{s}}\) is monotonically increasing, we have

\[0=\int_{y\geq\phi_{f_{s}}^{-1}(g(\bm{x}))}p_{t}(y|\bm{x})\mathrm{d}y-\int_{y< \phi_{f_{s}}^{-1}(g(\bm{x}))}p_{t}(y|\bm{x})\mathrm{d}y.\]

This yields

\[\int_{\phi_{f_{s}}^{-1}(g(\bm{x}))}^{\infty}p_{t}(y|\bm{x})\mathrm{d}y=\int_{- \infty}^{\phi_{f_{s}}^{-1}(g(\bm{x}))}p_{t}(y|\bm{x})\mathrm{d}y.\]

The same result is obtained even if \(\phi_{f_{s}}\) is monotonically decreasing. Consequently,

\[\phi_{f_{s}}^{-1}(g(\bm{x}))=\mathrm{Median}[Y|\bm{X}=\bm{x}],\]

which results in

\[G(\bm{x};\phi_{f_{s}})=\phi_{f_{s}}\big{(}\mathrm{Median}[Y|\bm{X}=\bm{x}] \big{)}.\]

This implies that Eq. (S.2) holds for any \(\phi_{f_{s}}\) including an affine transformation, and the function form cannot be identified. from this analysis.

**Example 3** (Exponential-squared loss).: As an example where the affine transformation is not optimal, consider the loss function \(\ell(y,y^{\prime})=|e^{y}-e^{y^{\prime}}|^{2}\). Substituting this into Eq. (S.1), we have

\[0 =\int\frac{\partial}{\partial g(\bm{x})}\big{|}\mathrm{exp}(g(\bm {x}))-\mathrm{exp}(\phi_{f_{s}}(y))\big{|}^{2}p_{t}(y|\bm{x})\mathrm{d}y\] \[=2\exp(g(\bm{x}))\int\big{(}\mathrm{exp}(g(\bm{x}))-\mathrm{exp}( \phi_{f_{s}}(y))\big{)}p_{t}(y|\bm{x})\mathrm{d}y.\]

Therefore,

\[G(\bm{x};\phi_{f_{s}})=\log\mathbb{E}\big{[}\mathrm{exp}(\phi_{f_{s}}(Y))|\bm {X}=\bm{x}\big{]}.\]

Consequently, Eq. (S.2) becomes

\[\log\mathbb{E}\big{[}\mathrm{exp}(\phi_{f_{s}}(Y))\big{]}=\phi_{f_{s}}\big{(} \mathrm{log}\,\mathbb{E}\big{[}\mathrm{exp}(Y)\big{]}\big{)}.\]

Even if \(\phi_{f_{s}}\) is an affine transformation, this equation does not generally hold.

### Analysis of the Optimal Function Class Based on the Upper Bound of the Estimation Error

Here, we discuss the optimal class for the transformation function based on the upper bound of the estimation error.

In addition to Assumptions 2.1 and 2.2, we assume the following in place of Assumption 2.3:

**Assumption A.2**.: The transformation functions \(\phi\) and \(\psi\) are Lipschitz continuous with respect to the first argument, i.e., there exist constants \(\mu_{\phi}\) and \(\mu_{\psi}\) such that,

\[\phi(a,c)-\phi(a^{\prime},c)\leq\mu_{\phi}\|a-a^{\prime}\|_{2},\quad\psi(b,c)- \psi(b^{\prime},c)\leq\mu_{\psi}\|b-b^{\prime}\|_{2},\]

for any \(a,a^{\prime}\in\mathcal{Y}\) and \(b,b^{\prime}\in\mathbb{R}\) with any given \(c\in\mathcal{F}_{s}\).

Note that each Lipschitz constant is a function of the second argument \(\bm{f_{s}}\), i.e., \(\mu_{\phi}=\mu_{\phi}(\bm{f_{s}})\) and \(\mu_{\psi}=\mu_{\psi}(\bm{f_{s}})\).

Under Assumptions 2.1, 2.2 and A.2, the estimation error is upper bounded as follows:

\[\mathop{\mathbb{E}}_{\bm{x},y}\Bigl{[}\bigl{|}f_{t}(\bm{x})-\hat{ f}_{t}(\bm{x})\bigr{|}^{2}\Bigr{]} =\mathop{\mathbb{E}}_{\bm{x},y}\Bigl{[}\bigl{|}\psi(g(\bm{x}),\bm{ f_{s}}(\bm{x}))-\psi(\hat{g}(\bm{x}),\bm{f_{s}}(\bm{x}))\bigr{|}^{2}\Bigr{]}\] \[\leq\mathop{\mathbb{E}}_{\bm{x},y}\Bigl{[}\mu_{\psi}(\bm{f_{s}}( \bm{x}))^{2}\bigl{|}g(\bm{x})-\hat{g}(\bm{x})\bigr{|}^{2}\Bigr{]}\] \[\leq 3\mathop{\mathbb{E}}_{\bm{x},y}\Bigl{[}\mu_{\psi}(\bm{f_{s}}( \bm{x}))^{2}\bigl{(}\bigl{|}g(\bm{x})-\phi(f_{t}(\bm{x}),f_{s}(\bm{x}))\bigr{|} ^{2}\Bigr{.}\] \[\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad+\bigl{|}\phi(f_ {t}(\bm{x}),\bm{f_{s}}(\bm{x}))-\phi(y,\bm{f_{s}}(\bm{x}))\bigr{|}^{2}\] \[\leq 3\mathop{\mathbb{E}}_{\bm{x},y}\Bigl{[}\mu_{\psi}(\bm{f_{s}}( \bm{x}))^{2}\bigl{|}\psi^{-1}(f_{t}(\bm{x}),\bm{f_{s}}(\bm{x}))-\phi(f_{t}(x), \bm{f_{s}}(\bm{x}))\bigr{|}^{2}\Bigr{]}\] \[\qquad\qquad\qquad\qquad\qquad\qquad\qquad+3\mathop{\mathbb{E}}_ {\bm{x},y}\Bigl{[}\mu_{\psi}(\bm{f_{s}}(\bm{x}))^{2}\mu_{\phi}(\bm{f_{s}}(\bm{ x}))^{2}\bigl{|}f_{t}(\bm{x})-y\bigr{|}^{2}\Bigr{]}\] \[=3\mathop{\mathbb{E}}_{\bm{x},y}\Bigl{[}\mu_{\psi}(\bm{f_{s}}( \bm{x}))^{2}\bigl{|}\psi^{-1}(f_{t}(\bm{x}),\bm{f_{s}}(\bm{x}))-\phi(f_{t}(\bm {x}),\bm{f_{s}}(\bm{x}))\bigr{|}^{2}\Bigr{]}\] \[\qquad\qquad\qquad\qquad\qquad\qquad\qquad+3\sigma^{2}\mathop{ \mathbb{E}}_{\bm{x},y}\Bigl{[}\mu_{\psi}(\bm{f_{s}}(\bm{x}))^{2}\mu_{\phi}(\bm{ f_{s}}(\bm{x}))^{2}\Bigr{]}\] \[\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad+3\mathop{ \mathbb{E}}_{\bm{x},y}\Bigl{[}\mu_{\psi}(\bm{f_{s}}(\bm{x}))^{2}\bigl{|}z-\hat{ g}(\bm{x})\bigr{|}^{2}\Bigr{]}.\]

The derivation of this inequality is based on [12]. We use the Lipschitz property of \(\psi\) and \(\phi\) for the first and third inequalities, and the second inequality comes from the inequality \((a-d)^{2}\leq 3(a-b)^{2}+3(b-c)^{2}+3(c-d)^{2}\) for \(a,b,c,d\in\mathbb{R}\).

According to this inequality, the upper bound of the estimation error is decomposed into three terms: the discrepancy between the two transformation functions, the variance of the noise, and the estimation error for the transformed data. Although it is intractable to find the optimal solution of \(\phi,\psi\), \(\hat{g}\) that minimizes all these terms together, it is possible to find a solution that minimizes the first and second terms expressed as the functions of \(\phi\) and \(\psi\) only. Obviously, the first term, which represents the discrepancy between the two transformation functions, reaches its minimum (zero) when \(\phi_{f_{s}}=\psi_{f_{s}}^{-1}\). The second term, which is related to the variance of the noise, is minimized when the differential coefficient \(\frac{\partial}{\partial u}\psi_{f_{s}}(u)\) is a constant, i.e., when \(\psi_{f_{s}}\) is a linear function. This is verified as follows. From \(\phi_{f_{s}}=\psi_{f_{s}}^{-1}\) and the continuity of \(\psi_{f_{s}}\), it follows that

\[\mu_{\psi}=\max\Big{|}\frac{\partial}{\partial u}\psi_{f_{s}}(u)\Big{|},\quad \mu_{\phi}=\max\Big{|}\frac{\partial}{\partial u}\psi_{f_{s}}^{-1}(u)\Big{|}= \frac{1}{\min|\frac{\partial}{\partial u}\psi_{f_{s}}(u)|},\]

and thus the product \(\mu_{\phi}\mu_{\psi}\) takes the minimum value (one) when the maximum and minimum of the differential coefficient are the same. Therefore, we can write

\[\phi(y,\bm{f_{s}})=\frac{y-g_{1}(\bm{f_{s}})}{g_{2}(\bm{f_{s}})},\quad\psi(g(x),\bm{f_{s}})=g_{1}(\bm{f_{s}})+g_{2}(\bm{f_{s}})g(\bm{x}),\]

where \(g_{1},g_{2}:\mathcal{F}_{s}\to\mathbb{R}\) are arbitrarily functions. Thus, the minimization of the third term in the upper bound of the estimation error can be expressed as

\[\min_{g_{1},g_{2},g}\mathop{\mathbb{E}}_{\bm{x},y}|y-g_{1}(\bm{f_{s}})-g_{2}( \bm{f_{s}})g(\bm{x})|^{2}.\]

As a result, the suboptimal function class for the upper bound of the estimated function is given as

\[\mathcal{H}=\bigl{\{}x\mapsto g_{1}(\bm{f_{s}})+g_{2}(\bm{f_{s}})\cdot g_{3}( \bm{x})\mid g_{1}\in\mathcal{G}_{1},g_{2}\in\mathcal{G}_{2},g_{3}\in\mathcal{G} _{3}\bigr{\}}.\]

This is the same function class derived in Section 2.1.

## Appendix B Additional Experiments

### Eigenvalue Decay of the Hadamard Product of Two Gram Matrices

We experimentally investigated how the decay rate \(s_{2}\) in Theorem 4.4 is related to the overlap degree in the spaces spanned by the original input \(\bm{x}\) and source features \(\bm{f_{s}}\).

For the original input \(\bm{x}\in\mathbb{R}^{100}\), we randomly constructed a set of 10 orthonormal bases, and then generated 100 samples from their spanning space. For the source features \(\bm{f_{s}}\in\mathbb{R}^{100}\), we selected \(d\) bases randomly from the 10 orthonormal bases selected for \(\bm{x}\) and the remaining \(10-d\) bases from their orthogonal complement space. We then generated 100 samples of \(\bm{f_{s}}\) from the space spanned by these 10 bases. The overlap number \(d\) can be regarded as the degree of overlap of two spaces spanned by the samples of \(\bm{x}\) and \(\bm{f_{s}}\). We generated the 100 different sample sets of \(\bm{x}\) and \(\bm{f_{s}}\).

We calculated the Hadamard product of the Gram matrices \(K_{2}\) and \(K_{3}\) using the samples of \(\bm{x}\) and \(\bm{f_{s}}\), respectively. For the computation of \(K_{2}\) and \(K_{3}\), all combinations of the following five kernels were tested:

\[\text{\bf Linear kernel}\,\,\,k(\bm{x},\bm{x}^{\prime}) =\frac{\bm{x}^{\top}\bm{x}}{2\gamma^{2}}+1,\] \[\text{\bf Matern kernel}\,\,\,k(\bm{x},\bm{x}^{\prime}) =\!\frac{2^{1-\nu}}{\Gamma(\nu)}\!\left(\!\frac{\sqrt{2\nu}\|\bm{ x}\!-\!\bm{x}^{\prime}\|_{2}}{\gamma}\!\right)^{\nu}\!\!\!K_{\nu}\!\left(\!\frac{ \sqrt{2\nu}\|\bm{x}\!-\!\bm{x}^{\prime}\|_{2}}{\gamma}\!\right)\,\text{for }\nu\!=\!\frac{1}{2},\frac{3}{2},\frac{5}{2},\infty,\]

where \(K_{\nu}(\cdot)\) is a modified Bessel function and \(\Gamma(\cdot)\) is the gamma function. Note that for \(\nu=\infty\), the Matern kernel is equivalent to the Gaussian RBF kernel. The scale parameter \(\gamma\) of both kernels was set to \(\gamma=\sqrt{\dim(\bm{x})}=\sqrt{10}\). For a given matrix \(K\), the decay rate of the eigenvalues was estimated as the smallest value of \(s\) that satisfies \(\lambda_{i}\leq\|K\|_{F}^{2}\cdot i^{-\frac{1}{s}}\) where \(\|\cdot\|_{F}\) denotes the Frobenius norm. Note that this inequality holds for any matrices \(K\) with \(s=1\)[32].

Figure S.2 shows the change of the decay rates with respect to varying \(d\) for various combinations of the kernels. In all cases, the decay rate of \(K_{2}\circ K_{3}\) showed a clear trend of monotonically decreasing as the degree of overlap \(d\) increases. In other words, the greater the overlap between the spaces spanned by \(\bm{x}\) and \(\bm{f_{s}}\), the smaller the decay rate, and the smaller the complexity of the RKHS \(\mathcal{H}_{2}\otimes\mathcal{H}_{3}\).

### Lattice Thermal Conductivity of Inorganic Crystals

Here, we describe the relationship between the qualitative differences in source features and the learning behavior of the affine model transfer, in contrast to ordinary feature extraction using neural networks.

The target task is to predict the lattice thermal conductivity (LTC) of inorganic crystalline materials, where the LTC is the amount of vibrational energy propagated by phonons in a crystal. In general, LTC can be calculated ab initio by performing many-body electronic structure calculations based on quantum mechanics. However, it is quite time-consuming to perform the first-principles calculations for thousands of crystals, which will be used as a training sample set to create a surrogate statistical model. Therefore, we perform TL with the source task of predicting an alternative, computationally tractable physical property called scattering phase space (SPS), which is known to be physically related to LTC.

#### b.2.1 Data

We used the dataset from [8] that records SPS and LTC for \(320\) and \(45\) inorganic compounds, respectively. The input compounds were translated to \(290\)-dimensional compositional descriptors using XenonPy [6, 33, 34, 35]1.

Footnote 1: https://github.com/yoshida-lab/XenonPy

#### b.2.2 Model Definition and Hyperparameter Search

Fully connected neural networks were used for both the source and target models, with a LeakyReLU activation function with \(\alpha=0.01\). The model training was conducted using the Adam optimizer [36]. Hyperparameters such as the width of the hidden layer, learning rate, number of epochs, and regularization parameters were adjusted with 5-fold cross-validation. For more details on the experimental conditions and procedure, refer to the provided Python code.

Source ModelFor the preliminary step, neural networks with three hidden layers that predict SPS were trained using 80% of the 320 samples. 100 models with different numbers of neurons were randomly generated and the top 10 source models that showed the highest generalization performance in the source domain were selected. The hidden layer width \(L\) was randomly chosen from the range \([50,100]\), and we trained a neural network with a structure of (input)-\(L\)-\(L\)-\(L\)-1. Each of the three hidden layers of the source model was used as an input to the transfer models, and we examined the difference in prediction performance for the three layers.

Target ModelIn the target task, an intermediate layer of a source model was used as the feature extractor. A model was trained using 40 randomly chosen samples of LTC, and its performance was evaluated with the remaining 5 samples. For each of the 10 source models, we performed the training and testing 10 times with different sample partitions and compared the mean values of RMSE among four different methods: (i) the affine model transfer using neural networks to model the three functions \(g_{1},g_{2}\) and \(g_{3}\), (ii) a neural network using the XenonPy compositional descriptors as input without transfer, (iii) a neural network using the source features as input, and (iv) fine-tuning of the pre-trained neural networks. The width of the layers of each neural network, the number of training epochs, and the dropout rate were optimized during 5-fold cross-validation looped within each training set. For the affine model transfer, the functions \(g_{1}\), \(g_{2}\), and \(g_{3}\) were modeled by neural networks. We used neural networks with one hidden layer for \(g_{1}\), \(g_{2}\) and \(g_{3}\).

#### b.2.3 Results

Figure S.3 shows the change in prediction performance of TL models using source features obtained from different intermediate layers from the first to the third layers. The affine transfer model and the ordinary feature extractor showed opposite patterns. The performance of the feature extractor improved when the first intermediate layer closest to the input layer was used as the source features and gradually degraded when layers closer to the output were used. When the third intermediate layer was used, a negative transfer occurred in the feature extractor as its performance became worse than that of the direct learning. In contrast, the affine transfer model performs better as the second and third intermediate layers closer to the output were used. The affine transfer model using the third intermediate layer reached a level of accuracy slightly better than fine-tuning, which intuitively uses more information to transfer than the extracted features.

In general, the features encoded in an intermediate layer of a neural network are more task-independent as the layer is closer to the input, and the features are more task-specific as the layer is closer to the output [9]. Because the first layer does not differ much from the original input, using both \(\bm{x}\) and \(\bm{f_{s}}\) in the affine model transfer does not contribute much to performance improvement. However, when using the second and third layers as the feature extractors, the use of both \(\bm{x}\) and \(\bm{f_{s}}\) contributes to improving the expressive power of the model, because the feature extractors have acquired different representational capabilities from the original input. In contrast, a model based only on \(\bm{f_{s}}\) from a source task-specific feature extractor could not account for data in the target domain, so its performance would become worse than direct learning without transfer, i.e., a negative transfer would occur.

### Heat Capacity of Organic Polymers

We highlight the benefits of separately modeling and estimating domain-specific factors through a case study in polymer chemistry. The objective is to predict the specific heat capacity at constant pressure \(C_{\mathrm{P}}\) of any given organic polymer with its chemical structure in the polymer's repeating unit. Specifically, we conduct TL to bridge the gap between experimental values and physical properties calculated from molecular dynamics (MD) simulations.

As shown in Figure S.4, there was a large systematic bias between experimental and calculated values; the MD-calculated properties \(C_{\mathrm{P}}^{\mathrm{MD}}\) exhibited an evident overestimation with respect to their experimental values. As discussed in [38], this bias is inevitable because classical MD calculations do not reflect the presence of quantum effects in the real system. According to Einstein's theory for the specific heat in physical chemistry, the logarithmic ratio between \(C_{\mathrm{P}}^{\mathrm{exp}}\) and \(C_{\mathrm{P}}^{\mathrm{MD}}\) can be calibrated by the following equation:

\[\log C_{\mathrm{P}}^{\mathrm{exp}}=\log C_{\mathrm{P}}^{\mathrm{MD}}+2\log \biggl{(}\frac{\hbar\omega}{k_{B}T}\biggr{)}+\log\frac{\exp\bigl{(}\frac{\hbar \omega}{k_{B}T}\bigr{)}}{\bigl{[}\exp\bigl{(}\frac{\hbar\omega}{k_{B}T}\bigr{)} -1\bigr{]}^{2}},\] (S.3)

where \(k_{B}\) is the Boltzmann constant, \(\hbar\) is the Planck constant, \(\omega\) is the frequency of molecular vibrations, and \(T\) is the temperature. The bias is a monotonically decreasing function of frequency \(\omega\), which is described as a black-box function of polymers with their molecular features. Hereafter, we consider the calibration of this systematic bias using the affine transfer model.

#### b.3.1 Data

Experimental values of the specific heat capacity of the 70 polymers were collected from PoLyInfo [39]. The MD simulation was also applied to calculate their heat capacities. For models to predict the log-transformed heat capacity, a given polymer with its chemical structure was translated into the 190-dimensional force field descriptors, using RadonPy [38]2.

Footnote 2: https://github.com/RadonPy/RadonPy

The force field descriptor represents the distribution of the ten different force field parameters ( \(t\in\mathcal{T}=\{\text{mass},\sigma,\epsilon,\text{charge},r_{0},K_{\text{ bond}},\text{polar},\theta_{0},K_{\text{angle}},K_{\text{dih}}\}\) that make up the empirical potential (i.e., the General AMBER force field [37] version 2 (GAFF2)) of the classical MD simulation. The

Figure S.4: MD-calculated (vertical axis) and experimental values (horizontal axis) of the specific heat capacity at constant pressure for various amorphous polymers.

\begin{table}
\begin{tabular}{l l} \hline Parameter & Description \\ \hline mass & Atomic mass \\ \(\sigma\) & Equilibrium radius of van der Waals (vdW) interactions \\ \(\epsilon\) & Depth of the potential well of vdW interactions \\ charge & Atomic charge of Gasteiger model \\ \(r_{0}\) & Equilibrium length of chemical bonds \\ \(K_{\text{bond}}\) & Force constant of bond stretching \\ polar & Bond polarization defined by the absolute value of charge difference between atoms in a bond \\ \(\theta_{0}\) & Equilibrium angle of bond angles \\ \(K_{\text{angle}}\) & Force constant of bond bending \\ \(K_{\text{dih}}\) & Rotation barrier height of dihedral angles \\ \hline \end{tabular}
\end{table}
Table S.1: Force field parameters that form the General AMBER force field [37] version 2 (GAFF2), and their detailed descriptions.

detailed descriptions for each parameter are listed in Table S.1. For each \(t\), pre-defined values are assigned to their constituent elements in a polymer, such as individual atoms (mass, charge, \(\sigma\), and \(\epsilon\)), bonds (\(r_{0}\), \(K_{\mathrm{bond}}\), and polar), angles (\(\theta_{0}\) and \(K_{\mathrm{angle}}\)), or dihedral angles (\(K_{\mathrm{dih}}\)), respectively. The probability density function of the assigned values of \(t\) is then estimated and discretized into 10 points corresponding to 10 different element species such as hydrogen and carbon for mass, and 20 equally spaced grid points for the other parameters. The details of the descriptor calculations are described in [40].

The source feature \(f_{s}\) was given as the log-transformed value of \(C_{\mathrm{P}}^{\mathrm{MD}}\). Therefore, \(f_{s}\) is no longer a function of \(\bm{x}\); this modeling was intended for calibrating the MD-calculated properties.

We randomly sampled 60 training polymers and tested the prediction performance of a trained model on the remaining 10 polymers 20 times. The PoLyInfo sample identifiers for the selected polymers are listed in the code.

#### b.3.2 Model Definition and Hyperparameter Search

As described above, the 190-dimensional force field descriptor consists of ten blocks corresponding to different types of features. The \(J_{t}\) features that make up block \(t\) represent discretized values of the density function of the force field parameters assigned to the atoms, bonds, or dihedral angles that constitute the given polymer. Therefore, the regression coefficients of the features within a block should be estimated smoothly. To this end, we imposed fused regularization on the parameters as

\[\lambda_{1}\|\bm{\gamma}\|_{2}^{2}+\lambda_{2}\sum_{t\in\mathcal{T}}\sum_{j=2 }^{J_{t}}\big{(}\gamma_{t,j}-\gamma_{t,j-1}\big{)}^{2},\]

where \(\mathcal{T}=\{\text{mass},\text{charge},\epsilon,\sigma,K_{\text{bond}},r_{0},K _{\text{angle}},\theta,K_{\text{dih}}\}\), and \(J_{t}=10\) for \(t=\text{mass}\) and \(J_{t}=20\) otherwise. The regression coefficient \(\gamma_{t,j}\) corresponds to the \(j\)-th feature of block \(t\).

Ordinary Linear RegressionThe experimental heat capacity \(y=\log C_{\mathrm{P}}^{\text{exp}}\) was regressed on the MD-calculated property, without regularization, as \(\hat{y}=\alpha_{0}+\alpha_{1}f_{s}\) where \(\hat{y}\) denotes the conditional expectation and \(f_{s}=\log C_{\mathrm{P}}^{\mathrm{MD}}\).

Learning the Log-DifferenceWe calculated the log-difference \(\log C_{\mathrm{P}}^{\mathrm{exp}}-\log C_{\mathrm{P}}^{\mathrm{MD}}\) and trained the linear model with the ridge penalty. The hyperparameters \(\lambda_{1}\) and \(\lambda_{2}\) for the scale- and smoothness-regularizers were determined based on 5-fold cross validation across 25 equally space grids in the interval \([10^{-2},10^{2}]\) for \(\lambda_{1}\) and across the set \(\{50,100,150\}\) for \(\lambda_{2}\).

Affine TransferThe log-transformed value of \(C_{\mathrm{P}}^{\text{exp}}\) is modeled as

\[y:=\log C_{\mathrm{P}}^{\text{exp}}=\underbrace{\alpha_{0}+\alpha_{1}f_{s}}_{ g_{1}}-(\underbrace{\beta f_{s}+1}_{g_{2}})\cdot\underbrace{\bm{x}^{\top} \bm{\gamma}}_{g_{3}}+\epsilon_{\sigma},\] (S.4)

where \(\epsilon_{\sigma}\) represents observation noise, and \(\alpha_{0},\alpha_{1},\beta\) and \(\bm{\gamma}\) are unknown parameters to be estimated. When \(\alpha_{1}=1\) and \(\beta=0\), Eq. (S.4) is consistent with the theoretical equation in Eq. (S.3) in which the quantum effect is linearly modeled as \(\alpha_{0}+\bm{x}^{\top}\bm{\gamma}\).

In the model training, the objective function was given as follows:

\[F_{\bm{\alpha},\beta,\bm{\gamma}}=\frac{1}{n}\sum_{i=1}^{n}\big{\{} y_{i}-(\alpha_{0}+\alpha_{1}f_{s,i}-(\beta f_{s,i}+1)\bm{x}^{\top}\bm{\gamma}) \big{\}}^{2}\] \[+\lambda_{\beta}\beta^{2}+\lambda_{\bm{\gamma},1}\|\bm{\gamma}\|_{ 2}^{2}+\lambda_{\bm{\gamma},2}\sum_{t\in T}\sum_{j=2}^{J_{t}}\big{(}\gamma_{t,j}-\gamma_{t,j-1}\big{)}^{2},\]

where \(\bm{\alpha}=[\alpha_{0}\ \alpha_{1}]^{\top}\). With a fixed \(\lambda_{\beta}=1\), the remaining hyperparameters \(\lambda_{\gamma,1}\) and \(\lambda_{\gamma,2}\) were optimized through 5-fold cross validation over 25 equally space grids in the interval \([10^{-2},10^{2}]\) for \(\lambda_{\gamma,1}\) and across the set \(\{50,100,150\}\) for \(\lambda_{\gamma,2}\).

The algorithm to estimate the parameters \(\bm{\alpha},\beta\) and \(\bm{\gamma}\) is described in Algorithm S.1, where \(\alpha_{0,\text{alt}}\) and \(\alpha_{1,\text{alt}}\) are the estimated parameters of the ordinary linear regression model, and \(\hat{\bm{\gamma}}_{\text{diff}}\) is the estimated parameter of the log-difference model. For each step, the full conditional minimization of \(F_{\bm{\alpha},\beta,\bm{\gamma}}\) with respect to each parameter can be made analytically as

\[\arg\min_{\bm{\alpha}}F_{\bm{\alpha},\beta,\bm{\gamma}} =(F_{s}^{\top}F_{s})^{-1}F_{s}^{\top}(\bm{y}+(\beta\bm{f_{s,1:n}}+ 1)\circ(X\bm{\gamma})),\] \[\arg\min_{\beta}F_{\bm{\alpha},\beta,\bm{\gamma}} =-(\bm{f_{s,1:n}^{\top}\mathrm{diag}(X\bm{\gamma})^{2}\bm{f_{s,1: n}}+n\lambda_{2})^{-1}\bm{f_{s,1:n}^{\top}\mathrm{diag}(X\bm{\gamma})(\bm{y}-F_{s} \bm{\alpha}+X\bm{\gamma})},\] \[\arg\min_{\bm{\gamma}}F_{\bm{\alpha},\beta,\bm{\gamma}} =-(X^{\top}\mathrm{diag}(\beta\bm{f_{s,1:n}}+1)^{2}X+\Lambda)^{-1} X^{\top}\mathrm{diag}(\beta\bm{f_{s,1:n}}+1)(\bm{y}-F_{s}\bm{\alpha}),\]

where \(X\) denote the matrix in which the \(i\)-th row is \(x_{i}\), \(\bm{y}=[y_{1}\cdots y_{n}]^{\top}\), \(\bm{f_{s,1:n}}=[f_{s,1}\cdots f_{s,n}]^{\top}\), \(F_{s}=[\bm{f_{s,1:n}}\ \ \bm{1}]\), and \(d=190\). \(\Lambda\) is a matrix including the two regularization parameters \(\lambda_{\bm{\gamma},1}\) and \(\lambda_{\bm{\gamma},2}\) as

\[\Lambda=D^{\top}D,\ \text{where}\ D=\left[\begin{array}{c}\lambda_{\bm{ \gamma},1}I_{d}\\ \lambda_{\bm{\gamma},2}M\end{array}\right],\ M=\left[\begin{array}{ccccc}-1& 1&0&\cdots&0&0\\ 0&-1&1&\cdots&0&0\\ \vdots&\vdots&\vdots&\ddots&\vdots&\vdots\\ 0&0&0&\cdots&0&0\\ \vdots&\vdots&\vdots&\ddots&\vdots&\vdots\\ 0&0&0&\cdots&-1&1\end{array}\right]\ \gets m\text{-th rows}\,\]

where \(m\in\{10,30,50,70,90,110,130,150,170\}\). Note that the matrix \(M\) is the same as the matrix \([\bm{0}\ I_{189}]-[I_{189}\ \ \bm{0}]\) except that the \(m\)-th row is all zeros. Note also that \(M\in\mathbb{R}^{189\times 190}\), and therefore \(D\in\mathbb{R}^{279\times 190}\) and \(\Lambda\in\mathbb{R}^{190\times 190}\).

The stopping criterion of the algorithm was set as

\[\max_{\theta\in\{\bm{\alpha},\beta,\bm{\gamma}\}}\frac{\max_{i}\big{|}\theta_{ i}^{\mathrm{(new)}}-\theta_{i}^{\mathrm{(old)}}\big{|}}{\max_{i}\big{|} \theta_{i}^{\mathrm{(old)}}\big{|}}<10^{-4},\] (S.5)

where \(\theta_{i}\) denotes the \(i\)-th element of the parameter \(\theta\). This convergence criterion is employed in several existing machine learning libraries, e.g., scikit-learn 3.

Footnote 3: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html

#### b.3.3 Results

Table S.2 summarizes the prediction performance (RMSE) of the three models. The ordinary linear model \(y=\alpha_{0}+\alpha_{1}f_{s}+\epsilon_{\sigma}\), which ignores the force field descriptors, exhibited the lowest prediction

\begin{table}
\begin{tabular}{l c} \hline Model & RMSE (log J/kg\cdot K) \\ \hline \(y=\alpha_{0}+\alpha_{1}f_{s}+\epsilon_{\sigma}\) & 0.1403 \(\pm\) 0.0461 \\ \(y=f_{s}+\bm{x}^{\top}\bm{\gamma}+\epsilon_{\sigma}\) & 0.1368 \(\pm\) 0.04265 \\ \(y=\alpha_{0}+\alpha_{1}f_{s}-(\beta f_{s}+1)\bm{x}^{\top}\bm{\gamma}+\epsilon_{ \sigma}\) & **0.1357 \(\pm\) 0.04173** \\ \hline \end{tabular}
\end{table}
Table S.2: Mean and standard deviation of RMSE of three prediction models.

performance. The other two calibration models \(y=f_{s}+\bm{x}^{\top}\bm{\gamma}+\epsilon_{\sigma}\) and the full model in Eq. (S.4) reached almost the same accuracy, but the latter had achieved slightly better prediction accuracy. The estimated parameters of the full model were \(\alpha_{1}\approx 0.889\) and \(\beta\approx-0.004\). The model form is highly consistent with the theoretical equation in Eq. (S.3) as well as the restricted model (\(\alpha_{1}=1,\beta=0\)). This supports the validity of the theoretical model in [38].

It is expected that physicochemical insights can be obtained by examining the estimated coefficient \(\bm{\gamma}\), which would capture the contribution of the force field parameters to the quantum effects. The magnitude of the quantum effect is a monotonically increasing function of the frequency \(\omega\), and is known to be highly related to the descriptors \(\epsilon\), \(K_{\text{dh}}\), \(K_{\text{bond}}\), \(K_{\text{angle}}\) and mass. According to physicochemical intuition, it is considered that as \(\epsilon\), \(K_{\text{bond}}\), \(K_{\text{angle}}\), and \(K_{\text{dh}}\) decrease, their potential energy surface becomes shallow, which leads to the decrease of \(\omega\), and in turn the decrease of quantum effects. Furthermore, because the molecular vibration of light-weight atoms is faster than that of heavy atoms, \(\omega\) and quantum effects should theoretically increase with decreasing mass.

Figure S.5 shows the mean values of the estimated parameter \(\bm{\gamma}\) for the full calibration model. The physical relationships described above can be captured consistently with the estimated coefficients. The coefficients in lower regions of \(\epsilon\), \(K_{\text{bond}}\), \(K_{\text{angle}}\) and \(K_{\text{dh}}\) showed large negative values, indicating that polymers containing more atoms, bonds, angles, and dihedral angles with lower values will have smaller quantum effects. Conversely, the coefficients in lower regions of mass showed positive large values, meaning that polymers containing more atoms with smaller masses will have larger quantum effects. As illustrated in this example, separate inclusion of the domain-common and domain-specific factors in the affine transfer model enables us to infer the features relevant to the cross-domain differences.

## Appendix C Experimental Details

Instructions for obtaining the datasets used in the experiments are described in the code.

### Kinematics of the Robot Arm

#### c.1.1 Data

We used the SARCOS dataset in [23]. The task is to predict the feed-forward torque required to follow the desired trajectory in the seven joints of the SARCOS anthropomorphic robot arm. The twenty one features representing the joints' position, velocity, and acceleration were used as \(\bm{x}\). The observed values of six torques other than the torque at the joint in the target domain were given to the source features \(\bm{f_{s}}\). The dataset includes 44,484 training samples and 4,449 test samples. We selected \(\{5,10,15,20,30,40,50\}\) samples randomly from the training set. The prediction performances of the trained models were evaluated using the 4,449 test samples. Repeated experiments were conducted 20 times with different independently sampled datasets.

#### c.1.2 Model Definition and Hyperparameter Search

Source modelFor each target task, a multi-task neural network was trained to predict the torque values of the remaining six source tasks. The source model shares four layers (256-128-64-32) up to the final layer, and only the output layer is task-specific. We used all training data and Adagrad [41] with learning rate of \(0.01\).

**Algorithm S.2** Block relaxation algorithm for **AffineTL-full**.

``` Initialize:\(\bm{a}_{0}\leftarrow(K_{1}+\lambda_{1}I_{n})^{-1}\bm{y}\), \(\bm{b}_{0}\sim\mathcal{N}(\bm{0},I_{n})\), \(\bm{c}_{0}\sim\mathcal{N}(\bm{0},I_{n})\), \(d_{0}\gets 0.5\) repeat \(\bm{a}\leftarrow(K_{1}+\lambda_{1}I_{n})^{-1}(\bm{y}-(K_{2}\bm{b}+\bm{1}) \circ(K_{3}\bm{c})-d\bm{1})\) \(\bm{b}\leftarrow(\mathrm{Diag}(K_{3}\bm{c})^{2}K_{2}+\lambda_{2}I_{n})^{-1}((K_ {3}\bm{c})\circ(\bm{y}-K_{1}\bm{a}-K_{3}\bm{c}-d\bm{1}))\) \(\bm{c}\leftarrow(\mathrm{Diag}(K_{2}\bm{b}+\bm{1})^{2}K_{3}+\lambda_{3}I_{n})^ {-1}((K_{2}\bm{b}+\bm{1})\circ(\bm{y}-K_{1}\bm{a}-d\bm{1}))\) \(d\leftarrow\langle\bm{y}-K_{1}\bm{a}-(K_{2}\bm{b}+\bm{1})\circ(K_{3}\bm{c}), \bm{1}\rangle/n\) until convergence ```

**Algorithm S.2** Block relaxation algorithm for **AffineTL-full**.

Direct, **Only source, Augmented, HTL-offset, HTL-scale** For each procedure, we used kernel ridge regression with the RBF kernel \(k(\bm{x},\bm{x}^{\prime})=\exp(-\frac{1}{2\ell^{2}}\|\bm{x}-\bm{x}^{\prime}\|_ {2}^{2})\). The scale parameter \(\ell\) was set to the square root of the input dimension as \(\ell=\sqrt{21}\) for **Direct**, **HTL-offset** and **HTL-scale**, \(\ell=\sqrt{6}\) for **Only source** and \(\ell=\sqrt{27}\) for **Augmented**. The regularization parameter \(\lambda\) was selected in 5-fold cross-validation in which the grid search was performed over 50 grid points in the interval \([10^{-4},10^{2}]\).

AffineTL-full, AffineTL-constWe considered the following kernels:

\[k_{1}(\bm{f_{s}}(\bm{x}),\bm{f_{s}}(\bm{x}^{\prime})) =\exp\Bigl{(}-\frac{1}{2\ell^{2}}\|\bm{f_{s}}(\bm{x})-\bm{f_{s}}( \bm{x}^{\prime})\|_{2}^{2}\Bigr{)}\ (\ell=\sqrt{6}),\] \[k_{2}(\bm{f_{s}}(\bm{x}),\bm{f_{s}}(\bm{x}^{\prime})) =\exp\Bigl{(}-\frac{1}{2\ell^{2}}\|\bm{f_{s}}(\bm{x})-\bm{f_{s}}( \bm{x}^{\prime})\|_{2}^{2}\Bigr{)}\ (\ell=\sqrt{6}),\] \[k_{3}(\bm{x},\bm{x}^{\prime}) =\exp\Bigl{(}-\frac{1}{2\ell^{2}}\|\bm{x}-\bm{x}^{\prime}\|_{2}^{ 2}\Bigr{)}\ (\ell=\sqrt{27}),\]

for \(g_{1},g_{2}\) and \(g_{3}\) in the affine transfer model, respectively.

Hyperparameters to be optimized are the three regularization parameters \(\lambda_{1},\lambda_{2}\) and \(\lambda_{3}\). We performed 5-fold cross-validation to identify the best hyperparameter set from the candidate points; \(\{10^{-3},10^{-2},10^{-1},1\}\) for \(\lambda_{1}\) and \(\{10^{-2},10^{-1},1,10\}\) for each of \(\lambda_{2}\) and \(\lambda_{3}\).

To learn the **AffineTL-full** and **AffineTL-const**, we used the following objective functions:

\[\textbf{AffineTL-full}\ \ \|\bm{y}-(K_{1}\bm{a}+(K_{2}\bm{b}+\bm{1}) \circ(K_{3}\bm{c})+d\bm{1})\|_{2}^{2}+\lambda_{1}\bm{a}^{\top}K_{1}\bm{a}+ \lambda_{2}\bm{b}^{\top}K_{2}\bm{b}+\lambda_{3}\bm{c}^{\top}K_{3}\bm{c},\] \[\textbf{AffineTL-const}\ \ \frac{1}{n}\|\bm{y}-(K_{1}\bm{a}+K_{3}\bm{c}+d\bm{1})\|_{2}^ {2}+\lambda_{1}\bm{a}^{\top}K_{1}\bm{a}+\lambda_{3}\bm{c}^{\top}K_{3}\bm{c}.\]

Algorithm S.2 summarizes the block relaxation algorithm for **AffineTL-full**. For **AffineTL-const**, we found the optimal parameters as follows:

\[\left[\begin{array}{c}\hat{\bm{a}}\\ \hat{\bm{c}}\\ \hat{d}\end{array}\right]=\left(\left[\begin{array}{c}K_{1}\\ K_{3}\\ \bm{1}^{\top}\end{array}\right][\begin{array}{cc}K_{1}&K_{3}&\bm{1}\end{array} \right]+\left[\begin{array}{cc}\lambda_{1}K_{1}\\ &\lambda_{3}K_{3}\\ &0\end{array}\right]\right)^{-1}\left[\begin{array}{c}K_{1}\\ K_{3}\\ \bm{1}^{\top}\end{array}\right]\bm{y}\]

The stopping criterion for the algorithm was the same as Eq. (S.5).

Fine-tuningThe target network was constructed by adding a one-dimensional output layer to the shared layers of the source network. As initial values for the training, we used the weights of the source neural network for the shared layer and the average of the multidimensional output layer of the source network for the output layer. Adagrad [41] was used for the optimization. The learning rate was fixed at \(0.01\) and the number of training epochs was selected from \(\{1,2,3,4,5,6,7,8,9,10,20,50,100\}\) through 5-fold cross-validation.

MamlA fully connected neural network with 256-64-32-16-1 layer width was used, and the initial values were searched through MAML [25] using the six source tasks. The obtained base model was fine-tuned with the target samples. Adam [42] with a fixed learning rate of \(0.01\) was used for the optimization. The number of training epochs was selected from \(\{1,2,3,4,5,6,7,8,9,10,20,50,100\}\) through 5-fold cross-validation.

\(L^{2}\)-Sp\(L^{2}\)-SP is a regularization method proposed by [26] in which the following regularization term is added so that the weights of the target network are estimated in the neighborhood of the weights of the source network:

\[\Omega(\bm{w})=\frac{\lambda}{2}\|\bm{w}-\bm{w_{s}}\|_{2}^{2},\] (S.6)

where \(\bm{w}\) and \(\bm{w_{s}}\) are the weights of the target and source model, respectively, and \(\lambda>0\) is a hyperparameter. We used the weights of the source network as the initial point for the training of the target model, and added a regularization parameter as in Eq. (S.6). Adagrad [41] were used for the optimizer, and the regularization parameters and learning rate were fixed at \(0.01\) and \(0.001\), respectively. The number of training epochs was selected from \(\{1,2,3,4,5,6,7,8,9,10,20,50,100\}\) through 5-fold cross-validation.

PAC-NetPAC-Net, proposed in [27], is a TL method that leverages pruning of the weights of the source network. Its training strategy consists of three steps: identifying the important weights in the source model, fine-tuning them using the source samples, and updating the remaining weights using the target samples.

Firstly, we pruned the bottom \(10\%\) of weights, based on absolute value, from the pre-trained source network. Following this, the remaining weights were retrained using the stochastic gradient descent (SGD). Finally, the pruned weights were retrained using target samples. For the final training phase, SGD with learning rate \(0.01\), was employed, and the number of training epochs was selected from \(\{1,2,3,4,5,6,7,8,9,10,20,50,100\}\) through 5-fold cross-validation.

[MISSING_PAGE_EMPTY:26]

### Evaluation of Scientific Papers

#### c.2.1 Data

We used SciRepEval benchmark dataset for scientific documents, proposed in [23]. This dataset comprises abstracts, review scores, and decision statuses of papers submitted to various machine learning conferences. We conducted two primary tasks: predicting the average review score (a regression task) and determining the acceptance or rejection status of each paper (a binary classification task). The original input \(\bm{x}\), was represented as a two-gram bag-of-words vector derived from the abstract. As for source features \(\bm{f_{s}}\), we employed text embeddings from the abstracts, which were generated by various pre-trained language models, including BERT [28], SciBERT [29], T5 [30], and GPT-3 [31]. When building the vocabulary for the bag-of-words, we ignore phrases with document frequencies strictly higher than 0.9 or strictly lower than 0.01. Additionally, we eliminated certain stop-words using the default settings in scikit-learn [43]. The sentences containing URLs were removed from the abstracts because accepted papers tend to include GitHub links in their abstracts after acceptance, which may cause leakage of information to the prediction. The models were trained on a dataset comprising 8,166 instances, and their performance were subsequently evaluated on a test dataset of 2,043 instances.

#### c.2.2 Model Definition and Hyperparamter Search

For both the affine model transfer and feature extraction, we employed neural networks with ReLU activation and dropout layer with 0.1 dropout rate. The parameters were optimized using Adagrad [41] with 0.01 learning rate.

Affine Model TransferFor functions \(g_{1}\) and \(g_{2}\) in the affine model transfer, we used a neural network composed of layers with widths 128, 64, 32, and 16, wherein the source features \(\bm{f_{s}}\) were used as inputs. The number of layers of each width was determined based on Bayesian optimization. Sigmoid activation was employed to the output of \(g_{2}\) in order to facilitate the interpretation of \(g_{3}\). For \(g_{3}\), we employed a linear model with the input \(\bm{x}\). To prevent overfitting and promote model simplicity, we applied \(\ell_{1}\) regularization to the parameters of \(g_{3}\) with a regularization parameter of 0.01. The final output of the model was computed as \(g_{1}+g_{2}\cdot g_{3}\). In the case of the binary classification task, we applied sigmoid activation function to this final output.

Feature ExtractionAs in the affine model transfer, we used a neural network composed of layers with widths 128, 64, 32, and 16, wherein the source features \(\bm{f_{s}}\) were used as inputs. The number of layers of each width was determined based on Bayesian optimization. In the case of the binary classification task, we applied sigmoid activation function to the final output.

## Appendix D Proofs

### Proof of Theorem 2.4

Proof.: According to Assumption 2.3, it holds that for any \(p_{t}(y|\bm{x})\),

\[\psi_{f_{s}}\bigg{(}\int\phi_{f_{s}}(y)p_{t}(y|\bm{x})\mathrm{d}y\bigg{)}=\int y p _{t}(y|\bm{x})\mathrm{d}y.\] (S.7)

(i) Let \(\delta_{y_{0}}\) be the Dirac delta function supported on \(y_{0}\). Substituting \(p_{t}(y|\bm{x})=\delta_{y_{0}}\) into Eq. (S.7), we have

\[\psi_{f_{s}}(\phi_{f_{s}}(y_{0}))=y_{0}\ (\forall y_{0}\in\mathcal{Y}).\]

Under Assumption 2.3, this implies the property (i).

(ii) For simplicity, we assume the inputs \(\bm{x}\) are fixed and \(p_{t}(y|\bm{x})>0\). Applying the property (i) to Eq. (S.7) yields

\[\int\phi_{f_{s}}(y)p_{t}(y|\bm{x})\mathrm{d}y=\phi_{f_{s}}\bigg{(}\intyp_{t}(y |\bm{x})\mathrm{d}y\bigg{)}.\]We consider a two-component mixture \(p_{t}(y|\bm{x})=(1-\epsilon)q(y|\bm{x})+\epsilon h(y|\bm{x})\) with a mixing rate \(\epsilon\in[0,1]\), where \(q\) and \(h\) denote arbitrary probability density functions. Then, we have

\[\int\phi_{f_{s}}(y)\big{\{}(1-\epsilon)q(y|\bm{x})+\epsilon h(y|\bm{x})\big{\}} \mathrm{d}y=\phi_{f_{s}}\bigg{(}\int y\big{\{}(1-\epsilon)q(y|\bm{x})+\epsilon h (y|\bm{x})\big{\}}\mathrm{d}y\bigg{)}.\]

Taking the derivative at \(\epsilon=0\), we have

\[\int\phi_{f_{s}}(y)\big{\{}h(y|\bm{x})-q(y|\bm{x})\big{\}}\mathrm{d}y=\phi_{f_ {s}}^{\prime}\bigg{(}\int yq(y|\bm{x})\mathrm{d}y\bigg{)}\bigg{(}\int y\big{\{} h(y|\bm{x})-q(y|\bm{x})\big{\}}\mathrm{d}y\bigg{)},\]

which yields

\[\int\big{\{}h(y|\bm{x})-q(y|\bm{x})\big{\}}\big{\{}\phi_{f_{s}}(y)-\phi_{f_{s }}^{\prime}\big{(}\mathbb{E}_{q}[Y|\bm{X}=\bm{x}]\big{)}y\big{\}}\mathrm{d}y=0.\] (S.8)

For Eq. (S.8) to hold for any \(q\) and \(h\), \(\phi_{f_{s}}(y)-\phi_{f_{s}}^{\prime}\big{(}\mathbb{E}_{q}[Y|\bm{X}=\bm{x}] \big{)}y\) must be independent of \(y\). Thus, the function \(\phi_{f_{s}}\) and its inverse \(\psi_{f_{s}}=\phi_{f_{s}}^{-1}\) are limited to affine transformations with respect to \(y\). Since \(\phi\) depends on \(y\) and \(\bm{f_{s}}(\bm{x})\), it takes the form \(\phi(y,\bm{f_{s}}(\bm{x}))=g_{1}(\bm{f_{s}}(\bm{x}))+g_{2}(\bm{f_{s}}(\bm{x}))y\). 

### Proof of Theorem 4.1

To bound the generalization error, we use the empirical and population Rademacher complexity \(\hat{\mathfrak{R}}_{S}(\mathcal{F})\) and \(\mathfrak{R}(\mathcal{F})\) of hypothesis class \(\mathcal{F}\), defined as:

\[\hat{\mathfrak{R}}_{S}(\mathcal{F})=\mathbb{E}_{\sigma}\sup_{f\in\mathcal{F}} \frac{1}{n}\sum_{i=1}^{n}\sigma_{i}f(\bm{x}_{i}), \mathfrak{R}(\mathcal{F})=\mathbb{E}_{S}\hat{\mathfrak{R}}_{S}( \mathcal{F}),\]

where \(\{\sigma_{i}\}_{i=1}^{n}\) is a set of Rademacher variables that are independently distributed and each take one of the values in \(\{-1,+1\}\) with equal probability, and \(S\) denotes a set of samples. The following proof is based on the one of Theorem 11 shown in [11].

Proof of Theorem 4.1.: For any hypothesis class \(\mathcal{F}\) with feature map \(\Phi\) where \(\|\Phi\|^{2}\leq 1\), the following inequality holds:

\[\mathbb{E}_{\sigma}\sup_{\|\bm{\theta}\|^{2}\leq\Lambda}\frac{1}{n}\sum_{i=1} ^{n}\sigma_{i}\langle\bm{\theta},\Phi(\bm{x}_{i})\rangle\leq\sqrt{\frac{ \Lambda}{n}}.\]The proof is given, for example, in Theorem 6.12 of [44]. Thus, the empirical Rademacher complexity of \(\tilde{\mathcal{H}}\) is bounded as

\[\tilde{\mathfrak{R}}_{S}(\tilde{\mathcal{H}}) =\mathbb{E}_{\sigma}\sup_{\begin{subarray}{c}\|\bm{\alpha}\|_{ \mathcal{H}_{1}}^{2}\leq\lambda_{\bm{\alpha}}^{-1}\hat{R}_{s},\\ \|\bm{\beta}\|_{\mathcal{H}_{2}}^{2}\leq\lambda_{\bm{\alpha}}^{-1}\hat{R}_{s}, \\ \|\bm{\gamma}\|_{\mathcal{H}_{3}}^{2}\leq\lambda_{\bm{\gamma}}^{-1}\hat{R}_{s} \end{subarray}}\frac{1}{n}\sum_{i=1}^{n}\sigma_{i}\bigg{\{}\langle\bm{\alpha}, \Phi_{1}(\bm{f_{s}}(\bm{x}_{i}))\rangle_{\mathcal{H}_{1}}+\langle\bm{\beta}, \Phi_{2}(\bm{f_{s}}(\bm{x}_{i}))\rangle_{\mathcal{H}_{2}}\langle\bm{\gamma}, \Phi(\bm{x}_{i})\rangle_{\mathcal{H}_{3}}\bigg{\}}\] \[\leq\mathbb{E}_{\sigma}\sup_{\begin{subarray}{c}\|\bm{\alpha}\|_ {\mathcal{H}_{1}}^{2}\leq\lambda_{\bm{\alpha}}^{-1}\hat{R}_{s}\end{subarray}} \frac{1}{n}\sum_{i=1}^{n}\sigma_{i}\langle\bm{\alpha},\Phi_{1}(\bm{f_{s}}(\bm{ x}_{i}))\rangle_{\mathcal{H}_{1}}\] \[\qquad\qquad\qquad\qquad+\sup_{\begin{subarray}{c}\|\bm{\beta} \|_{\mathcal{H}_{2}}^{2}\leq\lambda_{\bm{\alpha}}^{-1}\hat{R}_{s},\\ \|\bm{\gamma}\|_{\mathcal{H}_{3}}^{2}\leq\lambda_{\bm{\gamma}}^{-1}\hat{R}_{s} \end{subarray}}\frac{1}{n}\sum_{i=1}^{n}\sigma_{i}\langle\bm{\beta}\otimes \bm{\gamma},\Phi_{2}(\bm{f_{s}}(\bm{x}_{i}))\otimes\Phi(\bm{x}_{i})\rangle_{ \mathcal{H}_{2}\otimes\mathcal{H}_{3}}\] \[\leq\sqrt{\frac{\hat{R}_{s}}{\lambda_{\bm{\alpha}}n}}+\sqrt{\frac {\hat{R}_{s}^{2}}{\lambda_{\bm{\beta}}\lambda_{\bm{\gamma}}n}}\] (S.9) \[\leq\sqrt{\frac{\hat{R}_{s}}{n}}\bigg{\{}\sqrt{\frac{1}{\lambda_{ \bm{\alpha}}}}+\sqrt{\frac{L}{\lambda_{\bm{\beta}}\lambda_{\bm{\gamma}}}} \bigg{\}}.\]

The first inequality follows from the subadditivity of supremum. The last inequality follows from the fact that \(\hat{R}_{s}\leq P_{n}\ell(y,\langle 0,\Phi_{1}\rangle)+\lambda_{\bm{\alpha}}\|0\|^{2}\leq L\).

Let \(C=\sqrt{\frac{1}{\lambda_{\bm{\alpha}}}}+\sqrt{\frac{L}{\lambda_{\bm{\beta}} \lambda_{\bm{\gamma}}}}\), and applying Talagrand's lemma [44] and Jensen's inequality, we obtain

\[\mathfrak{R}(\mathcal{L})=\mathbb{E}\hat{\mathfrak{R}}_{S}(\mathcal{L})\leq \mu_{\ell}\mathbb{E}\hat{\mathfrak{R}}_{S}(\tilde{\mathcal{H}})\leq C\mu_{ \ell}\mathbb{E}\sqrt{\frac{\hat{R}_{s}}{n}}\leq C\mu_{\ell}\sqrt{\frac{ \mathbb{E}\hat{R}_{s}}{n}}.\]

To apply Corollary 3.5 of [20], we should solve the equation

\[r=C\mu_{\ell}\sqrt{\frac{r}{n}},\] (S.10)

and obtain \(r^{*}=\frac{\mu_{\ell}^{2}C^{2}}{n}\). Thus, for any \(\eta>0\), with probability at least \(1-e^{-\eta}\), there exists a constant \(C^{\prime}>0\) that satisfies

\[P_{n}\ell(y,\,h)\leq C^{\prime}\bigg{(}\mathbb{E}\hat{R}_{s}+\frac{\mu_{\ell} ^{2}C^{2}}{n}+\frac{\eta}{n}\bigg{)}\leq C^{\prime}\bigg{(}R_{s}+\frac{\mu_{ \ell}^{2}C^{2}}{n}+\frac{\eta}{n}\bigg{)}.\] (S.11)

Note that, for the last inequality, because \(\hat{R}_{s}\leq P_{n}\ell(y,\langle\bm{\alpha},\Phi_{1}\rangle)+\lambda_{\bm{ \alpha}}\|\bm{\alpha}\|^{2}\) for any \(\bm{\alpha}\), taking the expectation of both sides yields \(\mathbb{E}\hat{R}_{s}\leq P\ell(y,\langle\bm{\alpha},\Phi_{1}\rangle)+\lambda _{\bm{\alpha}}\|\bm{\alpha}\|^{2}\), and this gives \(\mathbb{E}\hat{R}_{s}\leq\inf_{\bm{\alpha}}\{P\ell(y,\langle\bm{\alpha},\Phi_{1} \rangle)+\lambda_{\bm{\alpha}}\|\bm{\alpha}\|^{2}\}=R_{s}\). Consequently, applying Theorem 1 of [45], we have

\[P\ell(y,\,h(\bm{x}))\leq P_{n}\ell(y,\,h(\bm{x}))+\,\tilde{O}\bigg{(}\bigg{(} \sqrt{\frac{R_{s}}{n}}+\frac{\mu_{\ell}C+\sqrt{\eta}}{n}\bigg{)}\bigg{(}\sqrt{ L}C+\sqrt{L\eta}\bigg{)}+\frac{C^{2}L+L\eta}{n}\bigg{)}.\] (S.12)

Here, we use \(\hat{\mathfrak{R}}_{S}(\tilde{\mathcal{H}})\leq C\sqrt{\frac{\hat{R}_{s}}{n}} \leq C\sqrt{\frac{L}{n}}\). 

_Remark D.1_.: As in [11], without the estimation of the parameters \(\bm{\alpha}\) and \(\bm{\beta}\), the right-hand side of Eq. (S.9) becomes \(\frac{1}{\sqrt{n}}\Big{(}c_{1}+c_{2}\sqrt{\hat{R}_{s}}\Big{)}\) with some constant \(c_{1}>0\) and \(c_{2}>0\), and Eq. (S.10) becomes

\[r=\frac{1}{\sqrt{n}}(c_{1}+c_{2}\sqrt{r}).\]This yields the solution

\[r^{*}=\left(\frac{c_{2}}{2\sqrt{n}}+\sqrt{\left(\frac{c_{2}}{2\sqrt{n}}\right)^{2} +\frac{c_{1}}{\sqrt{n}}}\right)^{2}\leq\frac{c_{2}^{2}}{n}+\frac{c_{1}}{\sqrt{n}},\]

where we use the inequality \(\sqrt{x}+\sqrt{x+y}\leq\sqrt{4x+2y}\). Thus, Eq. (S.11) becomes

\[P_{n}\ell(y,\,h)\leq C^{\prime}\bigg{(}R_{s}+\frac{c_{2}^{2}}{n}+\frac{c_{1}}{ \sqrt{n}}+\frac{\eta}{n}\bigg{)}.\]

Consequently, we have the following result:

\[P\ell(y,\,h(\bm{x}))\leq P_{n}\ell(y,\,h(\bm{x}))\] \[\quad+\ \tilde{O}\bigg{(}\bigg{(}\sqrt{\frac{R_{s}}{n}}+\frac{ \sqrt{c_{1}}}{n^{3/4}}+\frac{c_{2}+\sqrt{\eta}}{n}\bigg{)}\bigg{(}c_{1}+c_{2} \sqrt{L}+\sqrt{L\eta}\bigg{)}+\frac{(c_{1}+c_{2}\sqrt{L})^{2}+L\eta}{n}\bigg{)}.\]

This means that even if \(R_{s}=\tilde{O}(n^{-1})\), the resulting rate only improves to \(\tilde{O}(n^{-3/4})\).

### Proof of Theorem 4.4

Recall that loss function \(\ell(\cdot,\cdot)\) is assumed to be \(\mu_{\ell}\)-Lipschitz for the first argument. In addition, we impose the following assumption.

**Assumption D.2**.: There exists a constant \(B\geq 1\) such that for every \(h\in\mathcal{H}\), \(P(h-h^{*})\leq BP(\ell(y,h)-\ell(y,h^{*}))\).

Because we consider \(\ell(y,y^{\prime})=(y-y^{\prime})^{2}\) in Theorem 4.4, Assumption D.2 holds as stated in [20].

First, we show the following corollary, which is a slight modification of Theorem 5.4 of [20].

**Corollary D.3**.: _Let \(\hat{h}\) be any element of \(\mathcal{H}\) satisfying \(P_{n}\ell(y,\hat{h})=\inf_{h\in\mathcal{H}}P_{n}\ell(y,h)\), and let \(\hat{h}^{(m)}\) be any element of \(\mathcal{H}^{(m)}\) satisfying \(P_{n}\ell(y,\hat{h}^{(m)})=\inf_{h\in\mathcal{H}^{(m)}}P_{n}\ell(y,h)\). Define_

\[\hat{\psi}(r)=c_{1}\mathfrak{R}_{S}\{h\in\mathcal{H}:\max_{m\in\{1,2\}}P_{n}( h^{(m)}-\hat{h}^{(m)})^{2}\leq c_{3}r\}+\frac{c_{2}\eta}{n},\]

_where \(c_{1},c_{2}\) and \(c_{3}\) are constants depending only on \(B\) and \(\mu_{\ell}\). Then, for any \(\eta>0\), with probability at least \(1-5e^{-\eta}\),_

\[P\ell(y,\hat{h})-P\ell(y,h^{*})\leq\frac{705}{B}\hat{r}^{*}+\frac{(11\mu_{ \ell}+27B)\eta}{n},\]

_where \(\hat{r}^{*}\) is the fixed point of \(\hat{\psi}\)._

Proof.: Define the function \(\psi\) as

\[\psi(r)=\frac{c_{1}}{2}\mathfrak{R}\{h\in\mathcal{H}:\mu_{\ell}^{2}\max P(h^{( m)}-h^{(m)*})^{2}\leq r\}+\frac{(c_{2}-c_{1})\eta}{n}.\]

Because \(\mathcal{H},\mathcal{H}^{(1)}\) and \(\mathcal{H}^{(2)}\) are all convex and thus star-shaped around each of its points, Lemma 3.4 of [20] implies that \(\psi\) is a sub-root. Also, define the sub-root function \(\psi_{m}\) as

\[\psi_{m}(r)=\frac{c_{1}^{(m)}}{2}\mathfrak{R}\{h^{(m)}\in\mathcal{H}^{(m)}:\mu _{\ell}^{2}P(h^{(m)}-h^{(m)*})^{2}\leq r\}+\frac{(c_{2}-c_{1})\eta}{n}.\]

Let \(r_{m}^{*}\) be the fixed point of \(\psi_{m}(r_{m})\). Now, for \(r_{m}\geq\psi_{m}(r_{m})\), Corollary 5.3 of [20] and the condition on the loss function imply that, with probability at least \(1-e^{-\eta}\),

\[\mu_{\ell}^{2}P(\hat{h}^{(m)}-h^{(m)*})^{2}\leq B\mu_{\ell}^{2}P(\ell(y,\hat{h} ^{(m)})-\ell(y,\hat{h}^{(m)*}))\leq 705\mu_{\ell}^{2}r_{m}+\frac{(11\mu_{ \ell}+27B)B\mu_{\ell}^{2}\eta}{n}.\]

Denote the right-hand side by \(s_{m}\), and define \(r=\max r_{m}\) and \(s=\max s_{m}\). Because \(s\geq s_{m}\geq r_{m}\geq r_{m}^{*}\), we obtain \(s\geq\psi_{m}(s)\) according to Lemma 3.2 of [20], and thus,

\[s\geq 10\mu_{\ell}^{2}\mathfrak{R}\{h^{(m)}\in\mathcal{H}^{(m)}:\mu_{\ell}^{2}P( h^{(m)}-h^{(m)*})^{2}\leq s\}+\frac{11\mu_{\ell}^{2}\eta}{n}.\]Therefore, applying Corollary 2.2 of [20] to the class \(\mu_{\ell}\mathcal{H}^{(m)}\), it follows that with probability at least \(1-e^{-\eta}\),

\[\{h^{(m)}\in\mathcal{H}^{(m)}:\mu_{\ell}^{2}P(h^{(m)}-h^{(m)*})^{2}\leq s\}\subseteq \{h^{(m)}\in\mathcal{H}^{(m)}:\mu_{\ell}^{2}P_{n}(h^{(m)}-h^{(m)*})^{2}\leq 2s\}.\]

This implies that with probability at least \(1-2e^{-\eta}\),

\[P_{n}(\hat{h}^{(m)}-h^{(m)*})^{2} \leq 2\left(705r+\frac{(11\mu_{\ell}+27B)B\eta}{n}\right)\] \[\leq 2\left(705+\frac{(11\mu_{\ell}+27B)B}{n}\right)r,\]

where the second inequality follows from \(r\geq\psi(r)\geq\frac{c_{2}\eta}{n}\). Define \(2\left(705+\frac{(11\mu_{\ell}+27B)B}{n}\right)=c^{\prime}\). According to the triangle inequality in \(L_{2}(P_{n})\), it holds that

\[P_{n}(h^{(m)}-\hat{h}^{(m)})^{2} \leq\left(\sqrt{P_{n}(h^{(m)}-h^{(m)*})^{2}}+\sqrt{P_{n}(h^{(m)* }-\hat{h}^{(m)})^{2}}\right)^{2}\] \[\leq\left(\sqrt{P_{n}(h^{(m)}-h^{(m)*})^{2}}+\sqrt{c^{\prime}r} \right)^{2}.\]

Again, applying Corollary 2.2 of [20] to \(\mu_{\ell}\mathcal{H}^{(m)}\) as before, but now for \(r\geq\psi_{m}(r)\), it follows that with probability at least \(1-4e^{-\eta}\),

\[\{h\in\mathcal{H}:\mu_{\ell}^{2} \max P(h^{(m)}-h^{(m)*})^{2}\leq r\}\] \[=\bigcap_{m=1}^{2}\{h^{(m)}\in\mathcal{H}^{(m)}:\mu_{\ell}^{2}P(h ^{(m)}-h^{(m)*})^{2}\leq r\}\] \[\subseteq\bigcap_{m=1}^{2}\{h^{(m)}\in\mathcal{H}^{(m)}:\mu_{ \ell}^{2}P_{n}(h^{(m)}-h^{(m)*})^{2}\leq 2r\}\] \[\subseteq\bigcap_{m=1}^{2}\{h^{(m)}\in\mathcal{H}^{(m)}:\mu_{ \ell}^{2}P_{n}(h^{(m)}-\hat{h}^{(m)})^{2}\leq(\sqrt{2r}+\sqrt{c^{\prime}r})^{ 2}\}\] \[=\{h\in\mathcal{H}:\mu_{\ell}^{2}\max P_{n}(h^{(m)}-\hat{h}^{(m)} )^{2}\leq c_{3}r\},\]

where \(c_{3}=(\sqrt{2}+\sqrt{c^{\prime}})^{2}\). Combining this with Lemma A.4 of [20] leads to the following inequality: with probability at least \(1-5e^{-x}\)

\[\psi(r) =\frac{c_{1}}{2}\mathfrak{R}\{h\in\mathcal{H}:\mu_{\ell}^{2}\max P (h^{(m)}-h^{(m)*})^{2}\leq r\}+\frac{(c_{2}-c_{1})\eta}{n}\] \[\leq c_{1}\hat{\mathfrak{R}}_{S}\{h\in\mathcal{H}:\mu_{\ell}^{2} \max P(h^{(m)}-h^{(m)*})^{2}\leq r\}+\frac{c_{2}\eta}{n}\] \[\leq c_{1}\hat{\mathfrak{R}}_{S}\{h\in\mathcal{H}:\mu_{\ell}^{2} \max P_{n}(h^{(m)}-\hat{h}^{(m)})^{2}\leq c_{3}r\}+\frac{c_{2}\eta}{n}\] \[=\hat{\psi}(r).\]

Letting \(r=r^{*}\) and using Lemma 4.3 of [20], we obtain \(r^{*}\leq\hat{r}^{*}\), thus proving the statement. 

Under Assumption 4.2, we obtain the following excess risk bound for the proposed model class using Corollary D.3. The proof is based on [20].

**Theorem D.4**.: _Let \(\hat{h}\) be any element of \(\mathcal{H}\) satisfying \(P_{n}\ell(y,\hat{h}(\boldsymbol{x}))=\inf_{h\in\mathcal{H}}P_{n}\ell(y,h( \boldsymbol{x}))\). Suppose that Assumption 4.2 is satisfied, then there exists a constant \(c\) depending only on \(\mu_{\ell}\) such that for any \(\eta>0\), with probability at least \(1-5e^{-\eta}\),_

\[P(y-\hat{h}(\boldsymbol{x}))^{2}-P(y-h^{*}(\boldsymbol{x}))^{2}\] \[\qquad\qquad\leq c\left(\min_{0\leq\kappa_{1},\kappa_{2}\leq n} \left\{\frac{\kappa_{1}+\kappa_{2}}{n}+\left(\frac{1}{n}\sum_{j=\kappa_{1}+1}^{ n}\hat{\lambda}_{j}^{(1)}+\sum_{j=\kappa_{2}+1}^{n}\hat{\lambda}_{j}^{(2)} \right)^{\frac{1}{2}}\right\}+\frac{\eta}{n}\right).\]Theorem D.4 is a multiple-kernel version of Corollary 6.7 of [20], and a data-dependent version of Theorem 2 of [46] which considers the eigenvalues of the Hilbert-Schmidt operators on \(\mathcal{H}\) and \(\mathcal{H}^{(m)}\). Theorem D.4 concerns the eigenvalues of the Gram matrices \(K^{(m)}\) computed from the data.

Proof of Theorem D.4.: Define \(R=\max_{m}\sup_{h\in\mathcal{H}^{(m)}}P_{n}(y-h(\bm{x}))^{2}\). For any \(h\in\mathcal{H}^{(m)}\), we obtain

\[P_{n}(h^{(m)}(\bm{x})-\hat{h}^{(m)}(\bm{x}))^{2}\leq 2P_{n}(y-h^{(m)}(\bm{x}))^{2}+ 2P_{n}(y-\hat{h}^{(m)}(\bm{x}))^{2}\leq 4\sup_{h\in\mathcal{H}^{(m)}}P_{n}(y-h( \bm{x}))^{2}\leq 4R.\]

From the symmetry of the \(\sigma_{i}\) and the fact that \(\mathcal{H}^{(m)}\) is convex and symmetric, we obtain the following:

\[\hat{\mathfrak{R}}_{S}\{h\in\mathcal{H}:\max P_{n}(h^{(m)}-\hat{h }^{(m)})^{2}\leq 4R\}\] \[=\mathbb{E}_{\sigma}\sup_{\begin{subarray}{c}h^{(m)}\in \mathcal{H}^{(m)}\\ P_{n}(h^{(m)}-\hat{h}^{(m)})^{2}\leq 4R\end{subarray}}\frac{1}{n}\sum_{i=1}^{n} \sigma_{i}\sum_{m=1}^{2}h^{(m)}(\bm{x}_{i})\] \[=\mathbb{E}_{\sigma}\sup_{\begin{subarray}{c}h^{(m)}\in \mathcal{H}^{(m)}\\ P_{n}(h^{(m)}-\hat{h}^{(m)})^{2}\leq 4R\end{subarray}}\frac{1}{n}\sum_{i=1}^{n} \sigma_{i}\sum_{m=1}^{2}(h^{(m)}(\bm{x}_{i})-\hat{h}^{(m)}(\bm{x}_{i}))\] \[\leq\mathbb{E}_{\sigma}\sup_{\begin{subarray}{c}h^{(m)},g^{(m)} \in\mathcal{H}^{(m)}\\ P_{n}(h^{(m)}-g^{(m)})^{2}\leq 4R\end{subarray}}\frac{1}{n}\sum_{i=1}^{n} \sigma_{i}\sum_{m=1}^{2}(h^{(m)}(\bm{x}_{i})-g^{(m)}(\bm{x}_{i}))\] \[=2\mathbb{E}_{\sigma}\sup_{\begin{subarray}{c}h^{(m)}\in \mathcal{H}^{(m)}\\ P_{n}h^{(m)}\leq R\end{subarray}}\frac{1}{n}\sum_{i=1}^{n}\sigma_{i}\sum_{m=1} ^{2}h^{(m)}(\bm{x}_{i})\] \[\leq 2\sum_{m=1}^{2}\mathbb{E}_{\sigma}\sup_{\begin{subarray}{c}h^ {(m)}\in\mathcal{H}^{(m)}\\ P_{n}h^{(m)}\leq R\end{subarray}}\frac{1}{n}\sum_{i=1}^{n}\sigma_{i}h^{(m)}( \bm{x}_{i})\] \[\leq 2\sum_{m=1}^{2}\left\{\frac{2}{n}\sum_{j=1}^{n}\min\{R,\hat{ \lambda}_{j}^{(m)}\}\right\}^{\frac{1}{2}}\] \[\leq\left\{\frac{16}{n}\sum_{m=1}^{2}\sum_{j=1}^{n}\min\{R,\hat{ \lambda}_{j}^{(m)}\}\right\}^{\frac{1}{2}}.\]

The second inequality comes from the subadditivity of supremum and the third inequality follows from Theorem 6.6 of [20]. To obtain the last inequality, we use \(\sqrt{x}+\sqrt{y}\leq\sqrt{2(x+y)}\). Thus, we have

\[2c_{1}\hat{\mathfrak{R}}_{S}\{h\in\mathcal{H}:\max P_{n}(h^{(m)}- \hat{h}^{(m)})^{2}\leq 4R\}+\frac{(c_{2}+2)\eta}{n}\] \[\leq 4c_{1}\left\{\frac{16}{n}\sum_{m=1}^{2}\sum_{j=1}^{n}\min\left\{ R,\hat{\lambda}_{j}^{(m)}\right\}\right\}^{\frac{1}{2}}+\frac{(c_{2}+2)\eta}{n},\]

for some constants \(c_{1}\) and \(c_{2}\). To apply Corollary D.3, we should solve the following inequality for \(r\)

\[r\leq 4c_{1}\left\{\frac{16}{n}\sum_{m=1}^{2}\sum_{j=1}^{n}\min\left\{r,\hat{ \lambda}_{j}^{(m)}\right\}\right\}^{\frac{1}{2}}.\]For any integers \(\kappa_{m}\in[0,n]\), the right-hand side is bounded as

\[4c_{1}\left\{\frac{16}{n}\sum_{m=1}^{2}\sum_{j=1}^{n}\min\left\{r, \hat{\lambda}_{j}^{(m)}\right\}\right\}^{\frac{1}{2}} \leq 4c_{1}\left\{\frac{16}{n}\sum_{m=1}^{2}\left(\sum_{j=1}^{ \kappa_{m}}r+\sum_{j=\kappa_{m}+1}^{n}\hat{\lambda}_{j}^{(m)}\right)\right\}^{ \frac{1}{2}}\] \[=\left\{\left(\frac{256c_{1}^{2}}{n}\sum_{m=1}^{2}\kappa_{m} \right)r+\frac{256c_{1}^{2}}{n}\sum_{m=1}^{2}\sum_{j=\kappa_{m}+1}^{n}\hat{ \lambda}_{j}^{(m)}\right\}^{\frac{1}{2}},\]

and we obtain the solution \(r^{*}\) as

\[r^{*} \leq\frac{128c_{1}^{2}}{n}\sum_{m=1}^{2}\kappa_{m}+\left(\left\{ \frac{128c_{1}^{2}}{n}\sum_{m=1}^{2}\kappa_{m}\right\}^{2}+\frac{256c_{1}^{2} }{n}\sum_{m=1}^{2}\sum_{j=\kappa_{m}+1}^{n}\hat{\lambda}_{j}^{(m)}\right)^{ \frac{1}{2}}\] \[\leq\frac{256c_{1}^{2}}{n}\sum_{m=1}^{2}\kappa_{m}+\left(\frac{25 6c_{1}^{2}}{n}\sum_{m=1}^{2}\sum_{j=\kappa_{m}+1}^{n}\hat{\lambda}_{j}^{(m)} \right)^{\frac{1}{2}}.\]

Optimizing the right-hand side with respect to \(\kappa_{1}\) and \(\kappa_{2}\), we obtain the solution as

\[r^{*}\leq\min_{0\leq\kappa_{1},\kappa_{2}\leq n}\left\{\frac{256c_{1}^{2}}{n} \sum_{m=1}^{2}\kappa_{m}+\left(\frac{256c_{1}^{2}}{n}\sum_{m=1}^{2}\sum_{j= \kappa_{m}+1}^{n}\hat{\lambda}_{j}^{(m)}\right)^{\frac{1}{2}}\right\}.\]

Furthermore, according to Corollary D.3, there exists a constant \(c\) such that with probability at least \(1-5e^{-\eta}\),

\[P(y-\hat{h}(x))^{2} -P(y-h^{*}(x))^{2}\] \[\leq c\left(\min_{0\leq\kappa_{1},\kappa_{2}\leq n}\left\{\frac{ 1}{n}\sum_{m=1}^{2}\kappa_{m}+\left(\frac{1}{n}\sum_{m=1}^{2}\sum_{j=\kappa_{ m}+1}^{n}\hat{\lambda}_{j}^{(m)}\right)^{\frac{1}{2}}\right\}+\frac{\eta}{n} \right).\]

With Theorem D.4 and Assumption 4.3, we prove Theorem D.4 as follows.

Proof of Theorem 4.4.: Using the inequality \(\sqrt{x+y}\leq\sqrt{x}+\sqrt{y}\) for \(x\geq 0,y\geq 0\), we have

\[P(y-\hat{h}(\bm{x}))^{2}-P(y-h^{*}(\bm{x}))^{2}\] \[\leq O\left(\min_{0\leq\kappa_{1},\kappa_{2}\leq n}\left\{\frac{ \kappa_{1}+\kappa_{2}}{n}+\left(\frac{1}{n}\sum_{j=\kappa_{1}+1}^{n}j^{-\frac{ 1}{\delta_{1}}}+\frac{1}{n}\sum_{j=\kappa_{2}+1}^{n}j^{-\frac{1}{\delta_{2}}} \right)^{\frac{1}{2}}\right\}+\frac{\eta}{n}\right)\] \[\leq O\left(\min_{0\leq\kappa_{1},\kappa_{2}\leq n}\left\{\frac{ \kappa_{1}+\kappa_{2}}{n}+\left(\frac{1}{n}\sum_{j=\kappa_{1}+1}^{n}j^{-\frac {1}{\delta_{1}}}\right)^{\frac{1}{2}}+\left(\frac{1}{n}\sum_{j=\kappa_{2}+1}^ {n}j^{-\frac{1}{\delta_{2}}}\right)^{\frac{1}{2}}\right\}+\frac{\eta}{n}\right).\]

Because it holds that

\[\sum_{j=\kappa_{m}+1}^{n}j^{-\frac{1}{\delta_{m}}}<\int_{\kappa_{m}}^{\infty}x ^{-\frac{1}{\delta_{m}}}\mathrm{d}x<\left[\frac{1}{1-\frac{1}{s_{m}}}x^{1- \frac{1}{s_{m}}}\right]_{\kappa_{m}}^{\infty}=\frac{s_{m}}{1-s_{m}}\kappa_{m}^ {1-\frac{1}{s_{m}}},\]for \(m=1,2\), we should solve the following minimization problem:

\[\min_{0\leq\kappa_{1},\kappa_{2}\leq n}\left\{\frac{\kappa_{1}+\kappa_{2}}{n}+ \left(\frac{1}{n}\frac{s_{1}}{1-s_{1}}\kappa_{1}^{1-\frac{1}{s_{1}}}\right)^{ \frac{1}{2}}+\left(\frac{1}{n}\frac{s_{1}}{1-s_{1}}\kappa_{2}^{1-\frac{1}{s_{1 }}}\right)^{\frac{1}{2}}\right\}\equiv g(\kappa).\]

Taking the derivative, we have

\[\frac{\partial g(\kappa)}{\partial\kappa_{1}}=\frac{1}{n}+\frac{1}{2}\left( \frac{1}{n}\frac{s_{1}}{1-s_{1}}\kappa_{1}^{1-\frac{1}{s_{1}}}\right)^{-\frac {1}{2}}\bigg{(}-\frac{\kappa_{1}^{-\frac{1}{s_{1}}}}{n}\bigg{)}.\]

Setting this to zero, we find the optimal \(\kappa_{1}\) as

\[\kappa_{1}=\left(\frac{s_{1}}{1-s_{1}}\frac{4}{n}\right)^{\frac{s_{1}}{1+s_{1 }}}.\]

Similarly, we have

\[\kappa_{2}=\left(\frac{s_{2}}{1-s_{2}}\frac{4}{n}\right)^{\frac{s_{2}}{1+s_{2 }}},\]

and

\[P(y-\hat{h}(\bm{x}))^{2}-P(y-h^{*}(\bm{x}))^{2}\] \[\quad\leq O\bigg{(}\frac{1}{n}\left(\frac{s_{1}}{1-s_{1}}\frac{4} {n}\right)^{\frac{s_{1}}{1+s_{1}}}+\frac{1}{n}\left(\frac{s_{2}}{1-s_{2}} \frac{4}{n}\right)^{\frac{s_{2}}{1+s_{2}}}\] \[\qquad\qquad\qquad\qquad+2^{\frac{1-s_{1}}{1+s_{1}}}\bigg{(}\frac {s_{1}}{1-s_{1}}\frac{1}{n}\bigg{)}^{\frac{1}{1+s_{1}}}+2^{\frac{1-s_{2}}{1+s _{2}}}\bigg{(}\frac{s_{2}}{1-s_{2}}\frac{1}{n}\bigg{)}^{\frac{1}{1+s_{2}}}+ \frac{\eta}{n}\bigg{)}\] \[=O\Big{(}n^{-\frac{1}{1+s_{1}}}+n^{-\frac{1}{1+s_{2}}}\Big{)}\] \[=O\Big{(}n^{-\frac{1}{1+\max\{s_{1,s_{2}}\}}}\Big{)}\,.\]