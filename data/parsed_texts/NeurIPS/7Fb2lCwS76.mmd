# Change point detection and inference in multivariate non-parametric models under mixing conditions

 Carlos Misael Madrid Padilla

Department of Mathematics

University of Notre Dame

cmadridp@nd.edu

 Haotian Xu

Department of Statistics

University of Warwick

haotian.xu.1@warwick.ac.uk

&Daren Wang

Department of Statistics

University of Notre Dame

dwang24@nd.edu

&Oscar Hernan Madrid Padilla

Department of Statistics

University of California, Los Angeles

oscar.madrid@stat.ucla.edu

&Yi Yu

Department of Statistics

University of Warwick

yi.yu.2@warwick.ac.uk

###### Abstract

This paper addresses the problem of localizing and inferring multiple change points, in non-parametric multivariate time series settings. Specifically, we consider a multivariate time series with potentially short-range dependence, whose underlying distributions have Holder smooth densities and can change over time in a piecewise-constant manner. The change points, which correspond to the times when the distribution changes, are unknown. We present the limiting distributions of the change point estimators under the scenarios where the minimal jump size vanishes or remains constant. Such results have not been revealed in the literature in non-parametric change point settings. As byproducts, we develop a sharp estimator that can accurately localize the change points in multivariate non-parametric time series, and a consistent block-type long-run variance estimator. Numerical studies are provided to complement our theoretical findings.

## 1 Introduction

Given a time series \(\{X_{t}\}_{t=1}^{T}\subset\mathbb{R}^{p}\), which is assumed to be an \(\alpha\)-mixing sequence of random vectors with unknown marginal distributions \(\{P_{t}\}_{t=1}^{T}\). To incorporate the nonstationarity of \(\{X_{t}\}_{t=1}^{T}\), we assume that there exists \(K\in\mathbb{N}\) change points, namely \(\{\eta_{k}\}_{k=1}^{K}\subset\{2,...,T\}\) with \(1=\eta_{0}<\eta_{1}<\ldots<\eta_{k}\leq T<\eta_{K+1}=T+1\), such that

\[P_{t}\neq P_{t-1}\text{ if and only if }t\in\{\eta_{1},\ldots,\eta_{K}\}.\] (1)

Our primary interest is to develop accurate estimators of \(\{\eta_{k}\}_{k=1}^{K}\) and study their limiting properties. We refer to Assumption 1 for detailed technical conditions of our non-parametric change point model.

Nonstationary multivariate data are frequently encountered in real-world applications, including biology (e.g. Molenaar et al. 2009, Wolkovich & Donahue 2021), epidemiology (e.g. Azhar et al. 2021, Nguyen et al. 2021), social science (e.g. Kunitomo & Sato 2021, Cai et al. 2022), climatology (e.g. Corbella & Stretch 2012, Heo & Manuel 2022), finance (e.g. Herzel et al. 2002, Schmitt et al. 2013), neuroscience (e.g. Gorrostieta et al. 2019, Frolov et al. 2020), among others.

Due to the importance of modeling nonstationary data in various scientific fields, we have witnessed a soaring growth of statistical change point literature, (e.g. Aue et al. 2009, Fryzlewicz 2014, Cho & Fryzlewicz 2015, Cho 2016, Wang et al. 2020, Padilla et al. 2022). However, there are a few limitations in the existing works on multivariate non-parametric settings. Firstly, to the best of our knowledge, temporal dependence, which commonly appears in time series, has not been considered. Secondly, there is no localization consistency result for data with the underlying densities being Holder smooth with arbitrary degree of smoothness. Lastly and most importantly, the limiting distributions of change point estimators and the asymptotic inference for change points have not been well studied.

Taking into account the aforestated limitations, this paper examines change point problems in a fully non-parametric time series framework, wherein the underlying distributions are only assumed to have Holder smooth continuous densities and can change over time in a piecewise constant manner. The rest of the paper is organized as follows. In Section 2, we explain the model assumptions for multivariate time series with change points in a non-parametric setting. Section 3 details the two-step change point estimation procedure, as well as the estimators at each step. Theoretical results, including the consistency of the preliminary estimator and the limiting distribution of the final estimator, are presented in Section 4. Section 5 evaluates the practical performance of the proposed procedure via various simulations and a real data analysis. Finally, Section 6 concludes with a discussion.

**Notation.** For any function \(f:\;\mathbb{R}^{p}\to\mathbb{R}\) and for \(1\leq q<\infty\), define \(\|f\|_{L_{q}}=(\int_{\mathbb{R}^{p}}|f(x)|^{q}dx)^{1/q}\) and for \(q=\infty\), define \(\|f\|_{L_{\infty}}=\sup_{x\in\mathbb{R}^{p}}|f(x)|\). Define \(L_{q}=\{f:\;\mathbb{R}^{p}\to\mathbb{R},\;\|f\|_{q}<\infty\}\). Moreover, for \(q=2\), define \(\langle f,g\rangle_{L_{2}}=\int_{\mathbb{R}^{p}}f(x)g(x)dx\) where \(f,g:\;\mathbb{R}^{p}\to\mathbb{R}\). For any vector \(s=(s_{1},\ldots,s_{p})^{\top}\in\mathbb{N}^{p}\), define \(|s|=\sum_{i=1}^{p}s_{i}\), \(s!=s_{1}!\cdots s_{p}!\) and the associated partial differential operator \(D^{s}=\frac{\partial|s|}{\partial x_{1}^{\top}\cdots\partial x_{p}^{\top}}\). For \(\alpha>0\), denote \(\lfloor\alpha\rfloor\) to be the largest integer smaller than \(\alpha\). For any function \(f:\;\mathbb{R}^{p}\to\mathbb{R}\) that is \(|\alpha|\)-times continuously differentiable at point \(x_{0}\), denote by \(f_{x_{0}}^{\alpha}\) its Taylor polynomial of degree \(|\alpha|\) at \(x_{0}\), which is defined as \(f_{x_{0}}^{\alpha}(x)=\sum_{|s|\leq\lfloor\alpha\rfloor}(x-x_{0})^{s}/s!D^{s} f(x_{0})\). For a constant \(L>0\), let \(\mathcal{H}^{\alpha}(L,\mathbb{R}^{p})\) be the set of functions \(f:\;\mathbb{R}^{p}\to\mathbb{R}\) such that \(f\) is \(\lfloor\alpha\rfloor\)-times differentiable for all \(x\in\mathbb{R}^{p}\) and satisfy \(|f(x)-f_{x_{0}}^{\alpha}(x)|\leq L|x-x_{0}|^{\alpha}\), for all \(x,x_{0}\in\mathbb{R}^{p}\). Here \(|x-x_{0}|\) is the Euclidean distance between \(x,x_{0}\in\mathbb{R}^{p}\). In non-parametric statistics literature, \(\mathcal{H}^{\alpha}(L,\mathbb{R}^{p})\) is often referred to as the class of Holder functions. For two positive sequences \(\{a_{n}\}_{n\in\mathbb{N}^{+}}\) and \(\{b_{n}\}_{n\in\mathbb{N}^{+}}\), we write \(a_{n}=O(b_{n})\) or \(a_{n}\lesssim b_{n}\), if \(a_{n}\leq Cb_{n}\) with some constant \(C>0\) that does not depend on \(n\), and \(a_{n}=\Theta(b_{n})\) or \(a_{n}\asymp b_{n}\), if \(a_{n}=O(b_{n})\) and \(b_{n}=O(a_{n})\). For a deterministic or random \(\mathbb{R}\)-valued sequence \(a_{n}\), write that a sequence of random variable \(X_{n}=O_{p}(a_{n})\), if \(\lim_{M\to\infty}\limsup_{n\to\infty}\mathbb{P}(|X_{n}|\geq Ma_{n})=0\). Write \(X_{n}=o_{p}(a_{n})\) if \(\limsup_{n\to\infty}\mathbb{P}(|X_{n}|\geq Ma_{n})=0\) for all \(M>0\). The convergences in distribution and probability are respectively denoted by \(\stackrel{{\mathcal{D}}}{{\to}}\) and \(\stackrel{{ P}}{{\to}}\).

## 2 Model setup

Detailed assumptions imposed on the model (1) are collected in Assumption 1.

**Assumption 1**.: _The data \(\{X_{t}\}_{t=1}^{T}\subset\mathbb{R}^{p}\) are generated based on model (1) and satisfy the following._ **a.** _For each \(t=\{1,\ldots,T\}\), the distribution \(P_{t}\) has a Lebesgue density function \(f_{t}:\mathbb{R}^{p}\to\mathbb{R}\), such that \(f_{t}\in\mathcal{H}^{r}(L,\mathcal{X})\) with \(r,L>0\), where \(\mathcal{X}\) is the union of the supports of all \(f_{t}\), and \(\mathcal{X}\) has bounded Lebesgue measure._

**b.** _Let \(g_{t}\) be the joint density of \(X_{1}\) and \(X_{t+1}\). It satisfies that \(\|g_{t}\|_{L_{\infty}}<\infty\)._

**c.** _The minimal spacing between two consecutive change points \(\Delta=\min_{k=1}^{K+1}(\eta_{k}-\eta_{k-1})>0\)._

**d.** _The minimal jump size between two consecutive change points \(\kappa=\min_{k=1,\ldots,K}\kappa_{k}>0\), where \(\kappa_{k}=\|f_{\eta_{k}}-f_{\eta_{k+1}}\|_{L_{2}}\) denotes the jump size at the \(k\)th change point._

**e.** _The process \(\{X_{t}\}_{t\in\mathbb{Z}}\) is \(\alpha\)-mixing with mixing coefficients_

\[\alpha_{k}=\sup_{t\in\mathbb{Z}}\alpha(\sigma(X_{s},s\leq t),\sigma(X_{s},s\geq t +k))\leq e^{-2ck}\quad\text{for all $k\in\mathbb{Z}$.}\] (2)

The minimal spacing \(\Delta\) and the minimal jump size \(\kappa\) are two key parameters characterizing the change point phenomenon. Assumption 1**d.** characterizes the changes in density functions through the function's \(L_{2}\)-norm, enabling us to detect local and global changes in non-parametric settings.

The decay rate of \(\alpha_{k}\) in Assumption 1**e.** imposes an upper bound on the temporal dependence. This is a standard requirement in the literature (e.g Abadi 2004, Merlevede et al. 2009).

Revolving the change point estimators, we are to conduct the estimation and inference tasks. For a sequence of estimators \(\widehat{\eta}_{1}<\ldots<\widehat{\eta}_{\widehat{K}}\subset\{1,\ldots,T\}\), our first task is to show the localization consistency, i.e. with probability tending to one as the sample size \(T\) grows unbounded, it holds that

\[\widehat{K}=K\text{ and }\max_{k=1,\ldots,\widehat{K}}\lvert\widehat{\eta}_{k}- \eta_{k}\rvert\leq\epsilon,\text{ with }\lim_{T\to\infty}\frac{\epsilon}{\Delta}=0.\] (3)

We refer to \(\epsilon\) as the localization error in the rest of this paper.

With a consistent estimation result, we further refine \(\{\widehat{\eta}_{k}\}_{k=1}^{\widehat{K}}\) and obtain \(\{\widetilde{\eta}_{k}\}_{k=1}^{\widehat{K}}\) with error bounds \(\lvert\widetilde{\eta}_{k}-\eta_{k}\rvert=O_{p}(1)\) and derive the limiting distribution of \((\widetilde{\eta}_{k}-\eta_{k})\kappa_{k}^{\frac{p}{2}+2}\).

We briefly summarize the contributions of our paper as follows.

* We develop a multivariate non-parametric seeded change point detection algorithm detailed Algorithm 1, which is based on the seeded binary segmentation method (SBS), proposed in Kovacs et al. (2020) in the univariate setting. To the best of our knowledge, we are the first to innovatively adapt SBS to a multivariate non-parametric change point model.
* Under the signal-to-noise ratio condition in Assumption 3 that \(\kappa^{2}\Delta\gtrsim\log(T)T^{p/(2r+p)}\), we demonstrate that the output of Algorithm 1 is consistent, with localization errors \(\epsilon\asymp\kappa_{k}^{-2}T^{p/(2r+p)}\log(T)\), for \(k\in\{1,\ldots,K\}\). This localization error is first obtained for \(\alpha\)-mixing time series with a generic smoothness assumption, while the state-of-the-art method from Padilla et al. (2021) only focuses on Lipschitz smooth densities and under temporal independence.
* Based on the consistent estimators \(\{\widehat{\eta}\}_{k=1}^{\widehat{K}}\), we construct the refined estimators \(\{\widetilde{\eta}_{k}\}_{k=1}^{\widehat{K}}\) and derive their limiting distributions in different regimes, as detailed in Theorem 2. These results are novel in the literature of change point and time series analysis.
* Extensive numerical results are presented in Section 5 to corroborate the theoretical findings. The code used for numerical experiments is available upon request prior to publication.

## 3 A two-step multivariate non-parametric change point estimators

In this section, we present the initial and refined change point estimators, both of which share the same building block, namely the non-parametric CUSUM statistic.

**Definition 1** (Non-parametric CUSUM statistic).: _For any integer triplet \(0\leq s<t<e\leq T,\) let the CUSUM statistic be_

\[\widetilde{F}_{t,h}^{(s,e]}(x)=\sqrt{\frac{e-t}{(e-s)(t-s)}}\sum_{i=s+1}^{t}F_ {i,h}(x)-\sqrt{\frac{t-s}{(e-s)(e-t)}}\sum_{i=t+1}^{e}F_{i,h}(x),\ x\in\mathbb{ R}^{p},\]

_where \(F_{t,h}\) is a kernel estimator of \(f_{t}\), i.e. \(F_{t,h}(x)=\mathcal{K}_{h}(x-X_{t})\) with the kernel function_

\[\mathcal{K}_{h}(x)=\frac{1}{h^{p}}\mathcal{K}\bigg{(}\frac{x}{h}\bigg{)}, \quad x\in\mathbb{R}^{p},\]

_accompanied with the bandwidth \(h>0\)._

The CUSUM statistic is a key ingredient of our algorithm and is based on the kernel estimator \(F_{t,h}(\cdot)\). We highlight that kernel-based change-point estimation techniques have been employed in detecting change points in non-parametric models in existing literature, as demonstrated in, for instance, Arlot et al. (2019), Li et al. (2019), Padilla et al. (2021).

Our preliminary estimator is obtained by combining the CUSUM statistic in Definition 1 with a modified version of SBS based on a collection of deterministic seeded intervals defined in Definition 2.

**Definition 2** (Seeded intervals).: _Let \(\mathfrak{K}=\left\lceil C_{\mathfrak{K}}\log_{2}\left(\frac{T}{\Delta} \right)\right\rceil\), with some sufficiently large absolute constant \(C_{\mathfrak{K}}>0\). For \(k\in\{1,\ldots,\mathfrak{K}\}\), let \(\mathcal{J}_{k}\) be the collection of \(2^{k}-1\) intervals of length \(l_{k}=T2^{-k+1}\) that are evenly shifted by \(l_{k}/2=T2^{-k}\), i.e._

\[\mathcal{J}_{k}=\{(\lfloor(i-1)T2^{-k}\rfloor,\,\lceil(i-1)T2^{-k}+T2^{-k+1} \rceil],\quad i=1,\ldots,2^{k}-1\}.\]

_The overall collection of seeded intervals is denoted as \(\mathcal{J}=\cup_{k=1}^{\mathfrak{K}}\mathcal{J}_{k}\)._With the CUSUM statistics and the seeded intervals as building blocks, we are now ready to present our multivariate non-parametric seeded change point detection algorithm.

```
1:Sample \(\{X_{t}\}_{t=s}^{c}\subset\mathbb{R}^{p}\), collection of seeded intervals \(\mathcal{J}\), tuning parameter \(\tau>0\) and bandwidth \(h>0\). initialization: If \((s,e]=(0,n]\), set \(\mathbf{S}\rightarrow\varnothing\) and set \(\rho\rightarrow\log(T)h^{-p}\). for\(\mathcal{I}=(\alpha,\beta]\in\mathcal{J}\)do if\(\mathcal{I}=(\alpha,\beta]\subseteq(s,e]\) and \(\beta-\alpha>2\rho\)then \(b_{\mathcal{I}}\leftarrow\operatorname*{arg\,max}_{\alpha+\rho\leq t\leq \beta-\rho}\|\widetilde{F}_{t,h}^{(\alpha,\beta]}\|_{L_{2}}\) \(a_{\mathcal{I}}\leftarrow\|\widetilde{F}_{b_{\mathcal{I}},h}^{(\alpha,\beta]}\|_{L_{2}}\) else \(a_{\mathcal{I}}\leftarrow-1\) endif endfor \(\mathcal{M}^{s,e}=\{\mathcal{I}:a_{\mathcal{I}}>\tau\}\) if\(\mathcal{M}^{s,e}\neq\emptyset\)then \(\mathcal{I}^{*}\leftarrow\operatorname*{arg\,min}_{\mathcal{I}\in\mathcal{M}^{ s,e}}|\mathcal{I}|\) \(\mathbf{S}\leftarrow\mathbf{S}\cup\{b_{\mathcal{I}^{*}}\}\) \(\text{MNBS}((s,b_{\mathcal{I}^{*}}),\mathcal{J},\tau,h)\) \(\text{MNBS}((b_{\mathcal{I}^{*}}+1,e),\mathcal{J},\tau,h)\) endif ```

**OUTPUT:** The set of estimated change points \(\mathbf{S}\). ```

**Algorithm 1** Multivariate non-parametric Seeded Binary Segmentation. MNSBS \(((s,e),\mathcal{J},\tau,h)\)

Algorithm 1 presents a methodological approach to addressing the problem of estimating multiple change points in multivariate time series data. At its core, the algorithm leverages the strength of seeded intervals, forming a multi-scale search mechanism. To identify potential change points, the method recursively employs the CUSUM statistics. For the functionality of the algorithm, specific inputs are required. These include the observed data set, represented as \(X_{t}^{\top}=1\), the seeded intervals denoted by \(\mathcal{J}\), the bandwidth \(h\) that is crucial for constructing the CUSUM statistics, and a threshold, \(\tau\), which is instrumental in change point detection. We provide theoretical and numerical guidance for tuning parameters in Sections 4 and 5, respectively.

Delving deeper into the architecture of Algorithm 1, it becomes evident that the SBS functions as its foundational framework, while the nonparametric version of the CUSUM statistics acts as its functional units. The design of this algorithm is particularly tailored given its inclination toward nonparametric detection and its ability to identify multiple change points. The SBS is, in essence, an advanced version of the moving-window scanning technique. Its distinctive characteristic is its adaptability in handling the challenges posed by multiple change points that exhibit unpredictable spacing. Instead of being confined to a fixed window width, the SBS introduces versatility by incorporating a range of window width options. Each of these widths is methodically applied during a moving-window scan.

Based on the preliminary estimators \(\{\widehat{\eta}_{k}\}_{k=1}^{\widehat{K}}\) provided by Algorithm 1, we further develop a refinement procedure to enhance the localization accuracy. To be more specific, let

\[s_{k}=\frac{9}{10}\widehat{\eta}_{k-1}+\frac{1}{10}\widehat{\eta}_{k}\quad \text{and}\quad e_{k}=\frac{9}{10}\widehat{\eta}_{k+1}+\frac{1}{10}\widehat{ \eta}_{k}.\] (4)

Then, the preliminary estimators \(\{\widehat{\eta}_{k}\}_{k=1}^{\widehat{K}}\) and \(\widetilde{h}\asymp h\) produce an estimator of \(\kappa_{k}\) as:

\[\widehat{\kappa}_{k}= \left\|\sqrt{\frac{\widehat{\eta}_{k+1}-\widehat{\eta}_{k}}{( \widehat{\eta}_{k+1}-\widehat{\eta}_{k-1})(\widehat{\eta}_{k}-\widehat{\eta}_{ k-1})}}\sum_{i=\widehat{\eta}_{k-1}+1}^{\widehat{\eta}_{k}}F_{i,\widetilde{h}}- \sqrt{\frac{(\widehat{\eta}_{k}-\widehat{\eta}_{k-1})}{(\widehat{\eta}_{k+1}- \widehat{\eta}_{k-1})(\widehat{\eta}_{k+1}-\widehat{\eta}_{k})}}\sum_{i= \widehat{\eta}_{k}+1}^{\widehat{\eta}_{k+1}}F_{i,\widetilde{h}}\right\|_{L_{2}}\] \[\times\sqrt{\frac{\widehat{\eta}_{k+1}-\widehat{\eta}_{k-1}}{( \widehat{\eta}_{k}-\widehat{\eta}_{k-1})(\widehat{\eta}_{k+1}-\widehat{\eta}_ {k})}}.\] (5)We then propose the final change points estimators as

\[\widetilde{\eta}_{k}=\operatorname*{arg\,min}_{s_{k}<\eta<e_{k}}\widehat{Q}_{k}( \eta),\] (6)

where

\[\widehat{Q}_{k}(\eta)=\Big{\{}\sum_{t=s_{k}+1}^{\eta}\|F_{t,h_{1}}-F_{(s_{k}, \widetilde{\eta}_{k}),h_{1}}\|_{L_{2}}^{2}+\sum_{t=\eta+1}^{e_{k}}\|F_{t,h_{1} }-F_{(\widehat{\eta}_{k},e_{k}),h_{1}}\|_{L_{2}}^{2}\Big{\}},\]

with \(h_{1}=c_{\widetilde{\kappa}_{k}}\widehat{\kappa}_{k}^{1/r}\) and \(F_{(s,e],h_{1}}=\frac{1}{e-s}\sum_{i=s+1}^{e}F_{i,h_{1}}\) for integers \(e>s\).

If the initial change point estimators are consistent, i.e. (3) holds with probability tending to \(1\), then the interval \((\widehat{\eta}_{k-1},\widehat{\eta}_{k+1})\) is anticipated to contain merely one undetected change point. By conservatively trimming this interval to \((s_{k},e_{k})\), we can safely any change points previously detected within \((\widehat{\eta}_{k-1},\widehat{\eta}_{k+1})\). Consequently, the trimmed interval \((s_{k},e_{k})\) contains only true change point \(\eta_{k}\) with high probability. Due to the same reason, our choice of weight in Equation 4,1/10, is a convenient choice. In general, any constant weight between \(0\) and \(1/2\) would suffice. Inspired by Padilla et al. (2021), who proposed to use \(O\left(\kappa_{k}\right)\) as an optimal bandwidth in the context of Lipschitz densities, we adopt \(h_{1}=O\left(\hat{\kappa}_{k}^{1/r}\right)\) as the bandwidth for our kernel density estimator. This choice incorporates the broader scope of our work, which studies a more general degree of smoothness. Notably, if the underlying density functions strictly adhere to the Lipschitz criterion and \(r=1\), our bandwidth selection aligns with that recommended by Padilla et al. (2021). We would like to emphasize that while the procedure proposed by Padilla et al. (2021) required knowledge of the population quantities \(\kappa_{k}\), our approach is adaptive as we provide data-driven methods to estimate \(\kappa_{k}\) accurately.

With our newly proposed estimators, in Theorem 2, we derive an improved error bound for the refined estimators \(\{\widetilde{\eta}_{k}\}_{k=1}^{\widehat{K}}\) over the preliminary estimators \(\{\widehat{\eta}_{k}\}_{k=1}^{\widehat{K}}\). We also study the limiting distributions of the refined estimators. Section 4.4 and Section 5 will discuss the theoretically justified rates and practical choices of tuning parameters, respectively.

The computational complexity of Algorithm 1 is \(O(T^{2}\log(T)\Delta^{-1}\cdot\operatorname{Kernel})\), where \(O(T^{2}\log(T)\Delta^{-1})\) is due to the computational cost of the SBS, and "Kernel" stands for the computational cost of numerical computation of the \(L_{2}\)-norm of the CUSUM statistics based on the kernel function evaluated at each time point. The dependence on the dimension \(p\) is only through the evaluation of the kernel function. The computational complexity of the final estimators (including estimating \(\widehat{\kappa}_{k}\)'s) is \(O(T\cdot\operatorname{Kernel})\). Therefore, the overall cost for deriving \(\{\widetilde{\eta}_{k}\}_{k=1}^{\widehat{K}}\) is \(O(T^{2}\log T\Delta^{-1}\cdot\operatorname{Kernel})\).

## 4 Consistent estimation and limiting distributions

To establish the theoretical guarantees of our estimators, we first state conditions needed for the kernel function \(\mathcal{K}(\cdot)\).

**Assumption 2** (The kernel function).: _Assume that the kernel function \(\mathcal{K}(\cdot)\) has compact support and satisfies the following additional conditions._

**a.** _For the Holder smooth parameter \(r\) in Assumption 1_**a**_, assume that \(\mathcal{K}(\cdot)\) is adaptive to \(\mathcal{H}^{r}(L,\mathbb{R}^{p})\), i.e. for any \(f\in\mathcal{H}^{r}(L,\mathbb{R}^{p})\), it holds that_

\[\sup_{x\in\mathbb{R}^{p}}\Big{|}\int_{\mathbb{R}^{p}}h^{-p}\mathcal{K}\Big{(} \frac{x-z}{h}\Big{)}f(z)\,\mathrm{d}z-f(x)\Big{|}\leq\widetilde{C}h^{r},\]

_for some absolute constant \(\widetilde{C}>0\) and tuning parameter \(h>0\)._

**b.** _The class of functions \(\mathcal{F}_{\mathcal{K}}=\{\mathcal{K}(x-\cdot)/h:\,\mathbb{R}^{p}\to \mathbb{R}^{+},h>0\}\) is separable in \(L_{\infty}(\mathbb{R}^{p})\) and is a uniformly bounded VC-class; i.e. there exist constants \(A,\nu>0\) such that for any probability measure \(Q\) on \(\mathbb{R}^{p}\) and any \(u\in(0,\|\mathcal{K}\|_{L_{\infty}})\), it holds that \(\mathcal{N}(\mathcal{F}_{\mathcal{K}},L_{2}(Q),u)\leq(A\|\mathcal{K}\|_{L_{ \infty}}/u)^{\nu}\), where \(\mathcal{N}(\mathcal{F}_{\mathcal{K}},L_{2}(Q),u)\) denotes the \(u\)-covering number of the metric space \((\mathcal{F}_{\mathcal{K}},L_{2}(Q))\)._

**c.** _Let \(m=\lfloor r\rfloor\) and it holds that \(\int_{0}^{\infty}t^{m-1}\sup_{\|x\|\geq t}|\mathcal{K}(x)|^{m}\,\mathrm{d}t< \infty,\ \int_{\mathbb{R}^{p}}\mathcal{K}(z)\|z\|\,\mathrm{d}z\leq C_{K}\), where \(C_{K}>0\) is an absolute constant._Assumption 2 is a standard condition in the non-parametric literature (e.g. Gine and Guillou, 1999, 2001, Sriperumbudur and Steinwart, 2012, Kim et al., 2019, Padilla et al., 2021) and holds for various kernels, such as the Triweight, Epanechnikov and Gaussian kernels, which are considered in Section 5.

### Consistency of preliminary estimators

To establish the consistency of the preliminary estimators outputted by Algorithm 1, we impose the following signal-to-noise ratio condition.

**Assumption 3** (Signal-to-noise ratio).: _Assume there exists an arbitrarily slow diverging sequence \(\gamma_{T}>0\) such that_

\[\kappa^{2}\Delta>\gamma_{T}\log(T)T^{\frac{p}{2r+p}}.\]

We note that Assumption 3 is a mild condition, as it allows both the jump size \(\kappa\) to vanish asymptotically and/or the spacing \(\Delta\) between change points to be much smaller than \(T\). The consistency of Algorithm 1 is established in the following theorem.

**Theorem 1**.: _Suppose Assumptions 1, 2 and 3 hold. Let \(\{\widehat{\eta}_{k}\}_{k=1}^{\widehat{K}}\) be the estimated change points returned by Algorithm 1 with tuning parameters \(\tau=c_{\tau}T^{p/(4r+2p)}\log^{1/2}(T)\) and \(h=c_{h}T^{-1/(2r+p)}\) for sufficiently large constants \(c_{h},c_{\tau}>0\). Then_

\[\mathbb{P}\Big{\{}\widehat{K}=K,\;|\widehat{\eta}_{k}-\eta_{k}|\leq C_{\epsilon }\kappa_{k}^{-2}T^{\frac{p}{2r+p}}\log(T),\forall k=1,\ldots,K\Big{\}}\geq 1-3C _{p,\mathcal{K}}T^{-1},\]

_where \(C_{\epsilon}\) and \(C_{p,\mathcal{K}}\) are positive constants only depending on the kernel and the dimension \(p\)._

### Refined estimators and their limiting distributions

To develop refined estimators based on the preliminary estimators and study their limiting distributions, we would need to require a slightly stronger signal-to-noise ratio condition below.

**Assumption 4** (Signal-to-noise ratio for inference).: _Assume that there exists an arbitrarily slow diverging sequence \(\gamma_{T}>0\) such that_

\[\kappa^{\frac{2p}{r}+3}\Delta>\gamma_{T}\log(T)T^{\frac{p}{2r+p}}.\]

Assumption 4 is slightly stronger than Assumption 3. This is because our refined estimators are based on a sequence of random endpoints, i.e. the preliminary estimators. This brings theoretical challenges in deriving limiting distributions and estimating the long-run variances. It is worth noting that a similar phenomenon has been observed in the study on conducted by Xu, Wang, Zhao and Yu (2022).

**Theorem 2**.: _Suppose that Assumptions 1, 2 and 3 hold. Let \(\{\widetilde{\eta}_{k}\}_{k=1}^{\widehat{K}}\) be the refined change point estimators defined in Section 3, with the preliminary estimators \(\{\widehat{\eta}_{k}\}_{k=1}^{\widehat{K}}\) returned by Algorithm 1, the intervals \(\{(s_{k},c_{\epsilon})\}_{k=1}^{\widehat{K}}\) defined in (4), and \(\widehat{\kappa}_{k}\) defined as in (5). The following holds:_

**a.** _(Non-vanishing regime) Suppose the jump size at the change point_ \(\eta_{k}\) _satisfies_ \(\lim_{T\to\infty}\kappa_{k}\to\varrho_{k}\) _for some absolute constant_ \(\varrho_{k}>0\)_. Then, as_ \(T\to\infty\)_, it holds that_ \(|\widetilde{\eta}_{k}-\eta_{k}|=O_{p}(1)\) _and that_

\[(\widetilde{\eta}_{k}-\eta_{k})\kappa_{k}^{\frac{p}{r}+2}\ \stackrel{{ \mathcal{D}}}{{\longrightarrow}}\ \operatorname*{arg\,min}_{\widetilde{r}\in\mathbb{Z}}\,P_{k}( \widetilde{r})\]

_where_

\[P_{k}(\widetilde{r})\] \[= \begin{cases}\sum_{t=\widetilde{r}+1}^{0}2\big{\langle}F_{\eta_{ k}+t,h_{2}}-f_{\eta_{k}+t}*\mathcal{K}_{h_{2}},(f_{\eta_{k}}-f_{\eta_{k}+1})* \mathcal{K}_{h_{2}}\big{\rangle}_{L_{2}}+\widetilde{r}\|(f_{\eta_{k+1}}-f_{ \eta_{k}})*\mathcal{K}_{h_{2}}\|_{L_{2}}^{2},&\widetilde{r}<0;\\ 0,&\widetilde{r}=0;\\ \sum_{t=1}^{\widetilde{r}}2\big{\langle}F_{\eta_{k}+t,h_{2}}-f_{\eta_{k}+t}* \mathcal{K}_{h_{2}},(f_{\eta_{k+1}}-f_{\eta_{k}})*\mathcal{K}_{h_{2}}\big{\rangle} _{L_{2}}+\widetilde{r}\|(f_{\eta_{k+1}}-f_{\eta_{k}})*\mathcal{K}_{h_{2}}\|_{L _{2}}^{2},&\widetilde{r}>0.\end{cases}\]

_Here_ \(*\) _denotes convolution and_ \(h_{2}=c_{\kappa_{k}}\kappa_{k}^{1/r}\) _for some absolute constant_ \(c_{\kappa_{k}}>0\)_._

**b.** _(Vanishing regime) Suppose the jump size at the change point_ \(\eta_{k}\) _satisfies_ \(\lim_{T\to\infty}\kappa_{k}=0\)_. Then, as_ \(T\to\infty\)_, it holds that_ \(|\widetilde{\eta}_{k}-\eta_{k}|=O_{p}(\kappa_{k}^{-2-p/r})\) _and that_

\[(\widetilde{\eta}_{k}-\eta_{k})\kappa_{k}^{\frac{p}{r}+2}\ \stackrel{{ \mathcal{D}}}{{\rightarrow}}\ \operatorname*{arg\,min}_{\widetilde{r}\in\mathbb{Z}}\,\{ \widetilde{\sigma}_{\infty}(k)B(\widetilde{r})+|\widetilde{r}|\},\] (7)_where \(h_{2}=c_{\kappa_{k}}\kappa_{k}^{1/r}\) for some absolute constant \(c_{\kappa_{k}}>0\). Here_

\[B(\widetilde{r})=\begin{cases}B_{1}(-\widetilde{r}),&\widetilde{r}<0,\\ 0,&\widetilde{r}=0,\\ B_{2}(\widetilde{r}),&\widetilde{r}>0,\end{cases}\]

_with \(B_{1}(r)\) and \(B_{2}(r)\) being two independent standard Brownian motions, and_

\[\widetilde{\sigma}_{\infty}^{2}(k)=\lim_{T\to\infty}\frac{\kappa_{k}^{\frac{p} {k}-2}}{T}\mathrm{Var}\big{(}\sum_{t=1}^{T}\big{\langle}F_{t,h_{2}}-f_{t}* \mathcal{K}_{h_{2}},(f_{\eta_{k}}-f_{\eta_{k+1}})*\mathcal{K}_{h_{2}}\big{\rangle} _{L_{2}}\big{)}.\] (8)

Theorem 2 considers vanishing and non-vanishing regimes of the jump sizes. The upper bounds on the localization error in both regimes can be written as

\[\max_{1\leq k\leq K}|\widetilde{\eta}_{k}-\eta_{k}|\kappa_{k}^{\frac{p}{k}+2}= O_{p}(1).\]

Therefore, when the Holder smoothness parameter \(r=1\), our final estimator \(\{\widetilde{\eta}_{k}\}\) attains the minimax optimal convergence rate developed in Lemma 3 by Padilla et al. (2021). Furthermore, when \(r=1\), our resulting rate is sharper than that in Theorem 1 in Padilla et al. (2021), as we are able to remove the logarithmic factors from the upper bound. Additionally, our method can achieve optimal rates with choices of tuning parameters that do not depend on the unknown jump sizes \(\kappa_{k}\).

Theorem 2 summarizes the limiting distributions of the refined estimators \(\{\widetilde{\eta}_{k}\}_{k=1}^{\widehat{K}}\). In the non-vanishing case, the resulting limiting distribution can be approximated by a two-sided random walk and the change points can be accurately estimated within a constant error rate. In contrast, in the vanishing regime, a central limit theorem under mixing conditions leads to a two-sided Brownian motion distribution in the limit, which quantifies the asymptotic uncertainty of \(\{\widetilde{\eta}_{k}\}_{k=1}^{\widehat{K}}\), enabling inference on change point locations, and allowing for the construction of confidence intervals.

### Consistent long-run variance estimation

To obtain valid confidence intervals for change points using the limiting distributions in Theorem 2**b.**, it is crucial to access robust estimators for the long-run (asymptotic) variances \(\{\widetilde{\sigma}_{\infty}^{2}(k)\}_{k=1}^{\widehat{K}}\) defined in (8). We propose a block-type long-run variance estimator in Algorithm 2 to fulfill this task and demonstrate its consistency in the following theorem.

**Theorem 3**.: _Suppose Assumptions 1, 2 and 3 hold. Let \(\left\{\widetilde{\sigma}_{\infty}^{2}(k)\right\}_{k=1}^{\widehat{K}}\) be the population long-run variance defined in (8) and \(\widetilde{\sigma}_{\infty}^{2}(k)\) the output of Algorithm 2 with \(R=O(T^{(p+r)/(2r+p)}/\kappa_{k}^{p/(2r)+3/2})\). Then it holds that_

\[\max_{k=1}^{K}\left|\widehat{\sigma}_{\infty}^{2}(k)-\widetilde{\sigma}_{ \infty}^{2}(k)\right|\stackrel{{ P}}{{\longrightarrow}}0\quad \text{as}\quad T\to\infty.\]

### Discussions on MNSBS

**Tuning parameters.** Our procedure comprises three steps: (1) preliminary estimation, (2) local refinement, and (3) confidence interval construction with three key tuning parameters. For step (1), we use a kernel density estimator with bandwidth \(h\asymp T^{-1/(2r+p)}\), which follows from the classical non-parametric literature (e.g. Yu 1993, Tsybakov 2009). The threshold tuning parameter \(\tau\) is set to a high-probability upper bound on the CUSUM statistics when there is no change point, which reflects the requirement on the signal-to-noise ratio detailed in Assumption 3. For refined estimation in step (2) and long-run variance estimation in step (3), we set the bandwidth parameter \(h_{1}\asymp\widetilde{\kappa}_{k}^{1/r}\). This choice of bandwidth is inspired by the minimax rate-optimal bandwidth used in Padilla et al. (2021).

**Comparison with Padilla et al. (2021).** Our main contribution is deriving the limiting distribution of multivariate non-parametric change point estimators. This problem has not been formally studied in the existing literature. Additionally, our Holder assumption is more general than the Lipschitz assumption used in Padilla et al. (2021). Our Assumption 1**d** specifies changes through the \(L_{2}\)-norm of probability density functions, which is a weaker assumption than the \(L_{\infty}\)-norm used in Padillaet al. (2021). Furthermore, our assumptions allow for temporal dependence captured by \(\alpha\)-mixing coefficients, whereas Padilla et al. (2021) assumed independent observations.

**Comparison with existing literature in nonparametric, online, and inference change point.**

In the nonparametric change point literature, different kernel-based methods are adopted for change point localisation and testing. In the offline setting, the penalized kernel least squares estimator, originally introduced by Harchaoui & Cappe (2007), was explored by Arlot et al. (2012) for multivariate change point problems, and an oracle inequality was derived. An upper bound on the localization rate provided by this method was established by Garreau & Arlot (2018) and was computationally enhanced further in Celisse et al. (2018). With a focus on a so-called running maximum partition strategy, Harchaoui et al. (2008) formulated a kernel-based test statistic to ascertain the existence of a change-point. In a similar vein, Zou et al. (2014) investigated a problem where \(s\) out of \(n\) sequences are anomalous and devised a test statistic using the kernel maximum mean discrepancy.

In the online setting, Kifer et al. (2004) introduces a meta-algorithm comparing data from a "reference window" to current data using empirical measures. Desobry et al. (2005) detects shifts by comparing two descriptor sets from the signal's immediate past and future, using a dissimilarity metric resembling the Fisher ratio in Gaussian cases via a soft margin single-class SVM. Meanwhile, Liu et al. (2013) adopts density ratio estimation with a non-parametric Gaussian kernel model for change-point detection, updating its parameters online through stochastic gradient descent.

The core methodology is largely shared but with different goals and performance measurements regarding online and offline change point literature comparisons. How to conduct inference in the online change point context is also unclear.

Compared to the existing work, in this paper, we follow the suit of using kernel-based CUSUM statistics but incorporate temporal dependence, which is rarely seen in the literature. Most importantly, we are unaware of existing work on nonparametric change point inference, which is the main selling point of our paper.

Most change point inference work focuses on fixed-dimensional parameters as well as lacks tracking of many model parameters. Xu, Wang, Zhao & Yu (2022), in terms of style, is indeed the most closely related. But tackles high-dimensional linear regression, fundamentally distinct from our nonparametric density estimation.

## 5 Numerical Experiments

We refer to MNSBS as our final estimator, which is used for both localization and inference tasks. To evaluate its localization performance, we compare our proposed method against four competitors - MNP (Padilla et al. 2021), EMNCP (Matteson & James 2014), SBS (Cho & Fryzlewicz 2015) and DCBS (Cho 2016) - across a wide range of simulation settings, using corresponding R functions in changepoints (Xu, Padilla, Wang & Li 2022), ecp (James et al. 2019) and hdbinseg (Cho& Fryzlewicz 2018) packages. However, to the best of our knowledge, no competitor is currently available for the inference task.

**Tuning parameters.** For MNBS implementation, we use the Gaussian kernel and the false discovery rate control-based procedure of Padilla et al. (2021) for \(\tau\) selection. Preliminary estimators are set as \(h=2\times(1/T)^{1/(2r+p)}\), while the second stage estimator has bandwidths respectively set as \(\widetilde{h}=0.05\) and \(h_{1}=2\times\widehat{\kappa}_{k}^{1/r}\). Selection of \(R=\big{\lfloor}\big{(}\max_{k=1}^{\widehat{K}}\{e_{k}-s_{k}\}\big{)}^{3/5} \big{\rfloor}\) with \(\{(s_{k},e_{k})\}_{k=1}^{\widehat{K}}\) is guided by Theorem 3 using \(\{(s_{k},e_{k})\}_{k=1}^{\widehat{K}}\) from (4). For the confidence interval construction, we use \(\{\widehat{\kappa}_{k}\}_{k=1}^{\widehat{K}}\) and \(\{\widehat{\sigma}_{\infty}^{2}(k)\}_{k=1}^{\widehat{K}}\) to estimate the required unknown quantities. We evaluate \(L_{2}\) based statistics in Change point estimation and Long-run variance estimation using the Subregion-Adaptive Vegas Algorithm1 with a maximum of \(10^{5}\) function evaluations.

Footnote 1: The Subregion-Adaptive Vegas Algorithm is available in R package cubature(Narasimhan et al. 2022)

**Evaluation measurements** For a given set of true change points \(\mathcal{C}=\{\eta_{k}\}_{k=0}^{K+1}\), to assess the accuracy of the estimator \(\widehat{\mathcal{C}}=\{\widehat{\eta}_{k}\}_{k=0}^{\widehat{K}+1}\) with \(\widehat{\eta}_{0}=1\) and \(\widehat{\eta}_{T+1}=T+1f\), we report (1) Misestimate: the proportion of mismatating \(K\) and (2) Scaled Hausdorff distance: \(d_{\mathrm{H}}(\widehat{\mathcal{C}},\mathcal{C})\), defined by \(d_{\mathrm{H}}(\widehat{\mathcal{C}},\mathcal{C})=\frac{1}{T}\max\{\max_{x_{ E}\in\widehat{\mathcal{C}}}\min_{y\in\mathcal{C}}\{|x-y|\},\max_{y\in \widehat{\mathcal{C}}}\min_{x\in\mathcal{C}}\{|x-y|\}\}\).

The performance of our change point inference is measured by the coverage of \(\eta_{k}\), defined as \(cover_{k}(1-\alpha)\) for significance level \(\alpha\in(0,1)\). For, \(k=1,\ldots,K\),

\[cover_{k}(1-\alpha)=1\bigg{\{}\eta_{k}\in\bigg{[}\widetilde{\eta}_{k}+\frac{ \widehat{\eta}_{u}(\alpha/2)}{\widehat{\kappa}_{k}^{p/r+2}},\,\widetilde{\eta} _{k}+\frac{\widehat{\eta}_{u}(1-\alpha/2)}{\widehat{\kappa}_{k}^{p/r+2}}\bigg{]} \bigg{\}},\]

with \(\widehat{\eta}_{u}(\alpha/2)\) and \(\widehat{\eta}_{u}(1-\alpha/2)\) are the \(\alpha/2\) and \(1-\alpha/2\) empirical quantiles of the simulated limiting distribution given in (7), \(\widehat{\kappa}_{k}\) is defined in (5), and \(k=1,\ldots,K\).

### Localization

We consider three different scenarios with two equally spaced change points. For each scenario, we set \(r=2\), and vary \(T\in\{150,300\}\) and \(p\in\{3,5\}\). Moreover, we consider \(\{Y_{t}=1\{\lfloor T/3\rfloor<t\leq\lfloor 2T/3\rfloor\}Z_{t}+X_{t}\}_{t=1}^{T} \subset\mathbb{R}^{p}\) with \(X_{t}=0.3X_{t-1}+\epsilon_{t}\).

\(\bullet\)**Scenario 1 (S1)** Let \(Z_{t}=\mu\in\mathbb{R}^{p}\), where \(\mu_{j}=0\) for \(j\in\{1,\ldots,\lceil p/2\rceil\}\) and \(\mu_{j}=2\) otherwise. Let \(\{\epsilon_{t}\}\) be i.i.d. \(\mathcal{N}(0_{p},I_{p})\).

\(\bullet\)**Scenario 2 (S2)** Let \(Z_{t}|\{u_{t}=1\}=1.5\times 1_{p}\), \(Z_{t}|\{u_{t}=0\}=-1.5\times 1_{p}\), where \(\{u_{t}\}\) are i.i.d. Bernoulli\((0.5)\) random variables. Let \(\{\epsilon_{t}\}\) be i.i.d. \(\mathcal{N}(0_{p},I_{p})\).

\(\bullet\)**Scenario 3 (S3)** Let \(Z_{t}=0.3Z_{t-1}+0.5\times 1_{p}+\epsilon_{t}^{*}\), where \(\{\epsilon_{t}^{*}\}\subset\mathbb{R}^{p}\) and \(\{\epsilon_{t}\}\subset\mathbb{R}^{p}\) are mutually independent. They are i.i.d. with entries independently follow \(\text{Unif}(-\sqrt{3},\sqrt{3})\) and the standardized Pareto\((3,1)\), respectively.

**S1-S3** encompass a variety of simulation settings, including the same type of distributions, changed mean and constant covariance in **S1**; a mixture of distributions in **S2**; and change between light-tailed and heavy-tailed distributions in **S3**. We conduct \(200\) repetitions of each experiment and present the results for localization in Figure 1. Our proposed method, MNBS, generally outperforms all other methods in all scenarios, except for **S2**, where ECP performs better. However, we observe that MNSBS achieves comparable performance to ECP for large \(T\) in **S2**.

### Inference

In this section, we focus solely on analyzing the limiting distribution obtained in Theorem 2.**b.**, which pertains to the vanishing regime. We explain this from two different perspectives. Firstly, in the non-vanishing regime (Theorem 2.**a.**), the localization error is at the order of \(O(1)\). As a result, the construction of confidence intervals, which is a direct application of the limiting distribution, is of little demand with such estimation results. Secondly, since the localization error is only at the order of \(O(1)\), the universality cannot come into play to produce a useful limiting distribution.

We consider the process \(\{Y_{t}=1\{\lfloor T/2\rfloor<t\leq T\}\mu+X_{t}\}_{t=1}^{T}\), with \(X_{t}=0.3X_{t-1}+\epsilon_{t}\), Here, \(\mu=1_{p}\) and \(\{\epsilon_{t}\}\) are i.i.d. \(\mathcal{N}(0_{p},I_{p})\). We vary \(T\in\{100,200,300\}\) and \(p\in\{2,3\}\), and observe that our localization results are robust to the bandwidth parameters, yet sensitive to the smoothness parameter \(r\). We thus set \(r=1000\) in our simulations, as the density function of a multivariate normal distribution belongs to the Holder function class with \(r=\infty\). Table 1 shows that our proposed inference procedure produces good coverage in the considered setting.

## 6 Conclusion

We tackle the problem of change point detection for short range dependent multivariate non-parametric data, which has not been studied in the literature. Our two-stage algorithm MNSBS can consistently estimate the change points in stage one, a novelty in the literature. Then, we derived limiting distributions of change point estimators for inference in stage two, a first in the literature.

Our theoretical analysis reveals multiple challenging and interesting directions for future exploration. Relaxing the assumption \(\Delta\asymp T\) may be of interest. In addition, in Theorem 2.**a**, we can see the limiting distribution is a function of the data-generating mechanisms, lacking universality, therefore deriving a practical method to derive the limiting distributions in the non-vanishing regime may be interesting.

\begin{table}
\begin{tabular}{l c c c c} \hline \hline  & \multicolumn{2}{c}{\(\alpha=0.01\)} & \multicolumn{2}{c}{\(\alpha=0.05\)} \\ \(n\) & \(\mathrm{cover}(1-\alpha)\) & \(\mathrm{width}(1-\alpha)\) & \(\mathrm{cover}(1-\alpha)\) & \(\mathrm{width}(1-\alpha)\) \\ \hline  & \multicolumn{2}{c}{\(p=2\)} & \\
100 & 0.864 & 17.613 (6.712) & 0.812 & 14.005 (5.639) \\
200 & 0.904 & 22.940 (7.740) & 0.838 & 18.407 (6.541) \\
300 & 0.993 & 26.144 (9.027) & 0.961 & 20.902 (5.936) \\  & \multicolumn{2}{c}{\(p=3\)} & \\
100 & 0.903 & 15.439 (5.792) & 0.847 & 11.153 (4.361) \\
200 & 0.966 & 20.108 (7.009) & 0.949 & 13.920 (5.293) \\
300 & 0.981 & 22.395 (6.904) & 0.955 & 15.376 (4.763) \\ \hline \hline \end{tabular}
\end{table}
Table 1: Results for change point inference.

Figure 1: From top to bottom: Misestimation rate of the number of change point \(K\); Scaled Hausdorff distances. From left to right: Scenarios **S1-S3**. Different colors represent different methods, ordered as MNSBS, NMP, ECP, SBS, DCBS.

## Acknowledgments and Disclosure of Funding

HX was supported by Swiss National Science Foundation Postdoc Mobility fellowship. OHMM is partially funded by NSF DMS-2015489. YY's research is partially funded by EPSRC EP/V013432/1.

## References

* Abadi (2004) Abadi, M. (2004), 'Sharp error terms and neccessary conditions for exponential hitting times in mixing processes', _The Annals of Probability_**32**(1A), 243-264.
* Arlot et al. (2012) Arlot, S., Celisse, A. & Harchaoui, Z. (2012), 'A kernel multiple change-point algorithm via model selection', _arXiv preprint arXiv:1202.3878_.
* Arlot et al. (2019) Arlot, S., Celisse, A. & Harchaoui, Z. (2019), 'A kernel multiple change-point algorithm via model selection', _Journal of machine learning research_**20**(162).
* Aue et al. (2009) Aue, A., Hormann, S., Horvath, L. & Reimherr, M. (2009), 'Break detection in the covariance structure of multivariate time series models', _The Annals of Statistics_**37**(6B), 4046-4087.
* Azhar et al. (2021) Azhar, M. A. R., Nugroho, H. A. & Wibirama, S. (2021), The study of multivariable autoregression methods to forecast infectious diseases, _in_ '2021 IEEE 5th International Conference on Information Technology, Information Systems and Electrical Engineering (ICITISEE)', IEEE, pp. 83-88.
* Boussama et al. (2011) Boussama, F., Fuchs, F. & Stelzer, R. (2011), 'Stationarity and geometric ergodicity of bekk multivariate garch models', _Stochastic Processes and their Applications_**121**(10), 2331-2360.
* Cai et al. (2022) Cai, X., Wang, X., Eichi, H. R., Ongur, D., Dixon, L., Baker, J. T., Onnela, J.-P. & Valeri, L. (2022), 'State space model multiple imputation for missing data in non-stationary multivariate time series with application in digital psychiatry', _arXiv preprint arXiv:2206.14343_.
* Celisse et al. (2018) Celisse, A., Marot, G., Pierre-Jean, M. & Rigaill, G. (2018), 'New efficient algorithms for multiple change-point detection with reproducing kernels', _Computational Statistics & Data Analysis_**128**, 200-220.
* Chan & Tong (2001) Chan, K.-S. & Tong, H. (2001), _Chaos: a statistical perspective_, Springer Science & Business Media.
* Cho (2016) Cho, H. (2016), 'Change-point detection in panel data via double cusum statistic', _Electronic Journal of Statistics_**10**(2), 2000-2038.
* Cho & Fryzlewicz (2015) Cho, H. & Fryzlewicz, P. (2015), 'Multiple-change-point detection for high dimensional time series via sparsified binary segmentation', _Journal of the Royal Statistical Society: Series B (Statistical Methodology)_**77**(2), 475-507.
* Cho & Fryzlewicz (2018) Cho, H. & Fryzlewicz, P. (2018), _hdbinseg: Change-Point Analysis of High-Dimensional Time Series via Binary Segmentation_. R package version 1.0.1.
* https://CRAN.R-project.org/package=hdbinseg
* Corbella & Stretch (2012) Corbella, S. & Stretch, D. D. (2012), 'Predicting coastal erosion trends using non-stationary statistics and process-based models', _Coastal engineering_**70**, 40-49.
* Desobry et al. (2005) Desobry, F., Davy, M. & Doncarli, C. (2005), 'An online kernel change detection algorithm', _IEEE Transactions on Signal Processing_**53**(8), 2961-2974.
* Doukhan (1994) Doukhan, P. (1994), 'Mixing: properties and examples. lect', _Notes in Statisit_**85**.
* Fan & Yao (2003) Fan, J. & Yao, Q. (2003), _Nonlinear time series: nonparametric and parametric methods_, Vol. 20, Springer.
* Fan & Yao (2008) Fan, J. & Yao, Q. (2008), _Nonlinear time series: nonparametric and parametric methods_, Springer Science & Business Media.
* Frolov et al. (2020) Frolov, N., Maksimenko, V. & Hramov, A. (2020), 'Revealing a multiplex brain network through the analysis of recurrences', _Chaos: An Interdisciplinary Journal of Nonlinear Science_**30**(12), 121108.
* Frolov et al. (2019)Fryzlewicz, P. (2014), 'Wild binary segmentation for multiple change-point detection', _The Annals of Statistics_**42**(6), 2243-2281.
* Garreau and Arlot (2018) Garreau, D. & Arlot, S. (2018), 'Consistent change-point detection with kernels'.
* Gine and Guillou (1999) Gine, E. & Guillou, A. (1999), 'Laws of the iterated logarithm for censored data', _The Annals of Probability_**27**(4), 2042-2067.
* Gine and Guillou (2001) Gine, E. & Guillou, A. (2001), 'On consistency of kernel density estimators for randomly censored data: rates holding uniformly over adaptive intervals', _Annales de l'IHP Probabilites et statistiques_**37**(4), 503-522.
* Gorrostieta et al. (2019) Gorrostieta, C., Ombao, H. & Von Sachs, R. (2019), 'Time-dependent dual-frequency coherence in multivariate non-stationary time series', _Journal of Time Series Analysis_**40**(1), 3-22.
* Han and Wu (2023) Han, F. & Wu, W. B. (2023), Probability inequalities for high-dimensional time series under a triangular array framework, _in_ 'Springer Handbook of Engineering Statistics', Springer, pp. 849-863.
* Harchaoui and Cappe (2007) Harchaoui, Z. & Cappe, O. (2007), Retrospective mutiple change-point estimation with kernels, _in_ '2007 IEEE/SP 14th Workshop on Statistical Signal Processing', IEEE, pp. 768-772.
* Harchaoui et al. (2008) Harchaoui, Z., Moulines, E. & Bach, F. (2008), 'Kernel change-point analysis', _Advances in neural information processing systems_**21**.
* Heo and Manuel (2022) Heo, T. & Manuel, L. (2022), 'Greedy copula segmentation of multivariate non-stationary time series for climate change adaptation', _Progress in Disaster Science_**14**, 100221.
* Herzel et al. (2002) Herzel, S., Starica, C. & Tutuncu, R. (2002), _A non-stationary multivariate model for financial returns_, Chalmers University of Technology.
* James et al. (2019) James, N. A., Zhang, W. & Matteson, D. S. (2019), _ecp: An R Package for Nonparametric Multiple Change Point Analysis of Multivariate Data_. R package version 3.1.2.
* URL:https://cran.r-project.org/package=ecp
* Kifer et al. (2004) Kifer, D., Ben-David, S. & Gehrke, J. (2004), Detecting change in data streams, _in_ 'VLDB', Vol. 4, Toronto, Canada, pp. 180-191.
* Kim et al. (2019) Kim, J., Shin, J., Rinaldo, A. & Wasserman, L. (2019), Uniform convergence rate of the kernel density estimator adaptive to intrinsic volume dimension, _in_ 'International Conference on Machine Learning', PMLR, pp. 3398-3407.
* Kirch (2006) Kirch, C. (2006), Resampling methods for the change analysis of dependent data, PhD thesis, Universitat zu Koln.
* Kovacs et al. (2020) Kovacs, S., Li, H., Buhlmann, P. & Munk, A. (2020), 'Seeded binary segmentation: A general methodology for fast and optimal change point detection', _arXiv preprint arXiv:2002.06633_.
* Kunitomo and Sato (2021) Kunitomo, N. & Sato, S. (2021), 'A robust-filtering method for noisy non-stationary multivariate time series with econometric applications', _Japanese Journal of Statistics and Data Science_**4**(1), 373-410.
* Li et al. (2019) Li, S., Xie, Y., Dai, H. & Song, L. (2019), 'Scan b-statistic for kernel change-point detection', _Sequential Analysis_**38**(4), 503-544.
* Liebscher (2005) Liebscher, E. (2005), 'Towards a unified approach for proving geometric ergodicity and mixing properties of nonlinear autoregressive processes', _Journal of Time Series Analysis_**26**(5), 669-689.
* Liu et al. (2013) Liu, S., Yamada, M., Collier, N. & Sugiyama, M. (2013), 'Change-point detection in time-series data by relative density-ratio estimation', _Neural Networks_**43**, 72-83.
* Matteson and James (2014) Matteson, D. S. & James, N. A. (2014), 'A nonparametric approach for multiple change point analysis of multivariate data', _Journal of the American Statistical Association_**109**(505), 334-345.
* Matteson and James (2015)Merlevede, F., Peligrad, M. & Rio, E. (2012), 'Bernstein inequality and moderate deviations under strong mixing conditions', _arXiv preprint arXiv:1202.4777_.
* Merlevede et al. (2009) Merlevede, F., Peligrad, M., Rio, E. et al. (2009), 'Bernstein inequality and moderate deviations under strong mixing conditions', _High dimensional probability V: the Luminy volume_**5**, 273-292.
* Molenaar et al. (2009) Molenaar, P., Sinclair, K. O., Rovine, M. J., Ram, N. & Corneal, S. E. (2009), 'Analyzing developmental processes on an individual level using nonstationary time series modeling.', _Developmental psychology_**45**(1), 260.
* Narasimhan et al. (2022) Narasimhan, B., Johnson, S. G., Hahn, T., Bouvier, A. & Kieu, K. (2022), _cubature: Adaptive Multivariate Integration over Hypercubes_. R package version 2.0.4.5.
* **URL:**_https://CRAN.R-project.org/package=cubature_
* Nguyen et al. (2021) Nguyen, H. M., Turk, P. J. & McWilliams, A. D. (2021), 'Forecasting covid-19 hospital census: A multivariate time-series model based on local infection incidence', _JMIR Public Health and Surveillance_**7**(8), e28195.
* Padilla et al. (2022) Padilla, C. M. M., Wang, D., Zhao, Z. & Yu, Y. (2022), 'Change-point detection for sparse and dense functional data in general dimensions', _arXiv preprint arXiv:2205.09252_.
* Padilla et al. (2021) Padilla, O. H. M., Yu, Y., Wang, D. & Rinaldo, A. (2021), 'Optimal nonparametric multivariate change point detection and localization', _IEEE Transactions on Information Theory_.
* Schmitt et al. (2013) Schmitt, T. A., Chetalova, D., Schafer, R. & Guhr, T. (2013), 'Non-stationarity in financial time series: Generic features and tail behavior', _EPL (Europhysics Letters)_**103**(5), 58003.
* Sriperumbudur & Steinwart (2012) Sriperumbudur, B. & Steinwart, I. (2012), Consistency and rates for clustering with dbscan, _in_ 'Artificial Intelligence and Statistics', PMLR, pp. 1090-1098.
* Tsybakov (2009) Tsybakov, A. B. (2009), _Introduction to Nonparametric Estimation_, Springer series in statistics, Springer, Dordrecht.
* van der Vaart & Wellner (1996) van der Vaart, A. W. & Wellner, J. A. (1996), _Weak Convergence and Empirical Processes: With Applications to Statistics_, Springer New York, New York, NY.
* **URL:**_https://doi.org/10.1007/978-1-4757-2545-23_
* Venkatraman (1992) Venkatraman, E. S. (1992), _Consistency results in multiple change-point problems_, Stanford University.
* Wang et al. (2020) Wang, D., Yu, Y. & Rinaldo, A. (2020), 'Univariate mean change point detection: Penalization, cusum and optimality', _Electronic Journal of Statistics_**14**(1), 1917-1961.
* Wolkovich & Donahue (2021) Wolkovich, E. & Donahue, M. J. (2021), 'How phenological tracking shapes species and communities in non-stationary environments', _Biological Reviews_**96**(6), 2810-2827.
* Xu et al. (2022) Xu, H., Padilla, O., Wang, D. & Li, M. (2022), _changepoints: A Collection of Change-Point Detection Methods_. R package version 1.1.0.
* **URL:**_https://github.com/HaotianXu/changepoints_
* Xu et al. (2022) Xu, H., Wang, D., Zhao, Z. & Yu, Y. (2022), 'Change point inference in high-dimensional regression models under temporal dependence', _arXiv preprint arXiv:2207.12453_.
* Yu (1993) Yu, B. (1993), 'Density estimation in the \(l_{\infty}\) norm for dependent data with applications to the gibbs sampler', _The Annals of Statistics_ pp. 711-735.
* Zou et al. (2014) Zou, S., Liang, Y., Poor, H. V. & Shi, X. (2014), 'Nonparametric detection of anomalous data via kernel mean embedding', _arXiv preprint arXiv:1405.2294_.

Additional simulation results

### Robustness to Kernel Selection and Bandwidth Parameters

In this subsection, we provide additional simulation results in Table 2 to show that our proposed localization method, i.e. MNSBS, is robust against both the choice of Kernel functions and the choice of bandwidth parameters.

We consider the setting with \(T=150\) and \(p=3\) of **Scenario 1**. In addition to the Gaussian kernel used in the previous numeric experiments, we consider the Epanechnikov kernel and the Triweight kernel. We also let the bandwidth \(h=c_{h}\times(1/T)^{1/(2r+p)}\) with \(r=2\) and \(c_{h}\in\{1,2,5,10,20\}\). Out of the \(500\) iterations for each case, the table below reports the proportion of the number of change points \(K\) and the averaged localization errors.

### Runtime and localization for Independent Data

**Examination of Scenario 1 with independent data.**

We examined **Scenario 1** where \(p=3\), \(n\) is in the set \(\{150,300\}\), and \(X_{t}\) is i.i.d. distributed as \(N\left(0_{p},I_{p}\right)\). Our results indicate that MNSBS excels in change point localization. The refinement process further enhances its performance. Refer to Table 3 for specifics.

**Runtime Comparison.**

We benchmarked the runtime of our method against others. The tests were conducted on a machine powered by an Apple M2 chip with an 8-core CPU. The parameters were set at \(p=3\) and \(n\) in the set \(\{150,300\}\) for the independent setting. Our method performs comparably at \(n=150\). However, it is slower at \(n=300\), attributed to the computational demands of CUSUM. Detailed findings are presented in Table 3.

\begin{table}
\begin{tabular}{c c c c c} \hline  & \multicolumn{4}{c}{\(T=150\), \(p=3\) and \(r=2\)} \\ Kernel & \(c_{h}=1\) & \(c_{h}=2\) & \(c_{h}=5\) & \(c_{h}=10\) & \(c_{h}=20\) \\ \hline \multirow{3}{*}{Gaussian} & \multicolumn{4}{c}{Propotion of times \(K\neq K\)} \\  & 0.138 & 0.070 & 0.066 & 0.070 & 0.068 \\ Epanechnikov & 0.748 & 0.184 & 0.070 & 0.070 & 0.064 \\ Triweight & 0.280 & 0.082 & 0.068 & 0.066 & 0.060 \\ \multicolumn{4}{c}{Average (standard deviation) of \(d_{\mathrm{H}}\)} \\ Gaussian & 0.038(0.050) & 0.029(0.043) & 0.025(0.039) & 0.026(0.040) & 0.026(0.038) \\ Epanechnikov & 0.118(0.045) & 0.037(0.049) & 0.012(0.035) & 0.011(0.035) & 0.010(0.035) \\ Triweight & 0.053(0.057) & 0.017(0.038) & 0.010(0.034) & 0.010(0.035) & 0.010(0.034) \\ \hline \end{tabular}
\end{table}
Table 2: Additional localization results of **Scenario 1**.

\begin{table}
\begin{tabular}{c c c} \hline  & \multicolumn{2}{c}{\(T=150\)} & \multicolumn{2}{c}{\(T=300\)} \\ Method & \(p=3\) & \(p=3\) \\ \hline \multicolumn{3}{c}{average (standard deviation) of running (in seconds)} \\ MNSBS(initial \& reformed) & 1.130 (0.171) & 1.134 (0.065) \\ NMP & 0.812(0.142) & 10.899 (1.142) \\ ECP & **0.117** (0.053) & 0.646 (0.140) \\ SBS & **0.69** (0.033) & 0.656 (0.040) \\ DCDS & 0.566 (0.092) & 1.254 (0.134) \\ MNSBS(initial) & **0.00** & **0.005** \\ MNSBS(experimental) & **0.00** & **0.005** \\ MNSBS(experimental) & **0.00** & **0.000** \\ NMP & **0.00** & **0.000** \\ ECP & **0.00** & 0.040 \\ SBS & 0.445 & 0.015 \\ DCDS & 0.075 & 0.065 \\ AVEAEA(standard deviation) of \(d_{\mathrm{H}}\) \\ MNSBS(initial) & 0.010 (0.013) & 0.009 (0.012) \\ MNSBS(experimental) & **0.006** (0.011) & **0.005** (0.011) \\ NMP & 0.166 (0.019) & **0.008** (0.010) \\ ECP & **0.07** (0.011) & 0.009 (0.028) \\ SBS & 0.158 (0.157) & 0.012 (0.041) \\ DCDS & 0.021 (0.037) & 0.011 (0.022) \\ \hline \end{tabular}
\end{table}
Table 3: Runtime and localization results of **Scenario 1** with independent data.

Real data application

We applied our proposed change point inference procedure to analyze stock price data2, which consisted of daily adjusted close price of the 3 major stock market indices (S&P 500, Dow Jones and NASDAQ) from Jan-01-2021 to Jan-19-2023. After removing missing values and standardizing the raw data, the sample size was \(n=515\) and the dimension \(p=3\).

Footnote 2: The stock price data are downloaded from https://fred.stlouisfed.org/series.

We localized \(6\) estimated change points and performed inference based on them; results are summarized in Table 4. We also implemented the NMP and ECP methods on the same dataset, the estimated change points being presented below. Except for the time point Aug-24-2022 estimated by ECP, all other estimated change points were located in the constructed \(99\%\) confidence intervals by our proposed method.

The transformed real data is illustrated in the figure below. These data correspond to the daily adjusted close price, from Jan-01-2021 to Jan-19-2023, of the 3 major stock market indices, S&P 500, Dow Jones and NASDAQ. Moreover, in Table 4, we present the estimated change point by our proposed method MNSBS on the data before mentioned, together with their respective inference.

The result of the implementation of NMP and ECP methods on the same dataset are {April-01-2021, July-01-2021, Oct-19-2021, Jan-14-2022, April-21-2022, Oct-26-2022} and {April-08-2021, June-25-2021, Oct-18-2021, Jan-18-2022, April-28-2022, Aug-24-2022, Oct-27-2022} respectively.

\begin{table}
\begin{tabular}{l c c c} \hline \hline  & \multicolumn{2}{c}{\(\alpha=0.01\)} & \multicolumn{2}{c}{\(\alpha=0.05\)} \\ \(\widehat{\eta}\) & Lower bound & Upper bound & Lower bound & Upper bound \\ \hline April-07-2021 & April-01-2021 & April-12-2021 & April-05-2021 & April-09-2021 \\ June-30-2021 & June-23-2021 & July-09-2021 & June-25-2021 & July-07-2021 \\ Oct-19-2021 & Oct-12-2021 & Oct-26-2021 & Oct-14-2021 & Oct-22-2021 \\ Jan-18-2022 & Jan-12-2022 & Jan-21-2022 & Jan-13-2022 & Jan-20-2022 \\ April-25-2022 & April-20-2022 & April-28-2022 & April-21-2022 & April-27-2022 \\ Oct-27-2022 & Oct-24-2022 & Nov-01-2022 & Oct-25-2022 & Oct-31-2022 \\ \hline \hline \end{tabular}
\end{table}
Table 4: Confidence intervals constructed for change point locations in the Real data example.

Figure 2: Plot of the standardized daily close price, from Jan-01-2021 to Jan-19-2023, of the 3 major stock market indices.

\(\alpha\)-mixing coefficients

This paper focuses on multivariate time series that exhibit \(\alpha\)-mixing behavior with exponential decay coefficients. This condition is denoted as Assumption 1**e**. While the constant \(2c\) is present in the exponent of the exponential function, it plays a non-essential role in our theoretical framework. We include it solely for the sake of convenience during verification.

The \(\alpha\)-mixing condition with exponential decay as specified in Assumption 1**e** is a commonly held assumption in time series analysis. A broad spectrum of multivariate time series satisfies this condition, including linear/nonlinear VAR models [e.g. Liebscher (2005)], a comprehensive class of GARCH models [e.g. Boussama et al. (2011)], and various Markov processes [e.g. Chan & Tong (2001)]. To further elaborate, consider the \(p\) dimensional stationary VAR(1) model:

\[X_{t}=AX_{t-1}+\epsilon_{t}\]

where \(A\) is the \(p\times p\) transition matrix whose spectral norm satisfying \(\|A\|\in(0,1)\) and the innovations \(\epsilon_{t}\) are i.i.d. Gaussian vectors. Denote \(\Sigma=\operatorname{cov}\left(X_{1}\right)\), and let \(\lambda_{\text{max}}\) and \(\lambda_{\text{min}}\) be the largest and smallest eigenvalues of \(\Sigma\). Then by Theorem 3.1 in Han & Wu (2023), we have that for any \(k\geq 0\), the \(\alpha\)-mixing coefficient of the time series \(X_{t}\) satisfying

\[\alpha_{k}\leq\sqrt{\frac{\lambda_{\text{max}}}{\lambda_{\text{min}}}}|A|^{k} \leq e^{-C\log(1/|A|)k}\]

where \(C>0\) is some constant depending only on \(\sqrt{\lambda_{\text{max}}/\lambda_{\text{min}}}\). In this example, the constant \(C\log(1/|A|)\) corresponds to the constant \(2c\) in Assumption 1**e**. Essentially, Assumption 1**e** is useful to unlock several technical tools under temporal dependence, which include a Bernstein's inequality Merlevede et al. (2012), a moment inequality [see Proposition 2.5 in Fan & Yao (2003)], maximal inequalities (see Section G.1) and a central limit theorem (see Section G.2). For instance, we utilize the moment inequality to bound the autocovariances of a dependence process with all lags by \(\alpha\)-mixing coefficients, thereby demonstrating the existence of the long-run variance, which is the sum of all the autocovariances.

Proof of Theorem 1

In this section, we present the proof of theorem Theorem 1.

Proof of Theorem 1.: For any \((s,e]\subseteq(0,T]\), let

\[\widetilde{f}_{t}^{(s,e]}(x)=\sqrt{\frac{e-t}{(e-s)(t-s)}}\sum_{l=s+1}^{t}f_{l} (x)-\sqrt{\frac{t-s}{(e-s)(e-t)}}\sum_{l=t+1}^{e}f_{l}(x),\,x\in\mathcal{X}.\]

For any \(\widetilde{r}\in(\rho,T-\rho]\), we consider

\[\mathcal{A}((s,e],\rho,\lambda)=\bigg{\{}\max_{t=s+\rho+1}^{e- \rho}\sup_{x\in\mathbb{R}^{p}}|\widetilde{F}_{t,h}^{s,e}(x)-\widetilde{f}_{t}^ {s,e}(x)|\leq\lambda\bigg{\}};\] \[\mathcal{B}(\widetilde{r},\rho,\lambda)=\bigg{\{}\frac{T- \widetilde{r}}{\max_{N=\rho}}\sup_{x\in\mathbb{R}^{p}}\bigg{|}\frac{1}{\sqrt{ N}}\sum_{t=\widetilde{r}+1}^{\widetilde{r}+N}F_{t,h}(x)-\frac{1}{\sqrt{N}} \sum_{t=\widetilde{r}+1}^{\widetilde{r}+N}f_{t}(x)\bigg{|}\leq\lambda\bigg{\}}\bigcup\] \[\bigg{\{}\frac{\widetilde{r}}{\max_{N=\rho}}\sup_{x\in\mathbb{R}^ {p}}\bigg{|}\frac{1}{\sqrt{N}}\sum_{t=\widetilde{r}-N+1}^{\widetilde{r}}F_{t,h }(x)-\frac{1}{\sqrt{N}}\sum_{t=\widetilde{r}-N+1}^{\widetilde{r}}f_{t}(x) \bigg{|}\leq\lambda\bigg{\}}.\]

From Algorithm 1, we have that

\[\rho=\frac{\log(T)}{h^{p}}.\]

Therefore, Proposition 2 imply that with

\[\lambda=C_{\lambda}\bigg{(}2C\sqrt{\frac{\log T}{h^{p}}}+\frac{2C_{1}\sqrt{p} }{\sqrt{h^{p}}}+2C_{2}\sqrt{T}h^{r}.\bigg{)},\] (9)

for some diverging sequence \(C_{\lambda}\), it holds that

\[P\bigg{\{}\mathcal{A}^{c}((s,e],\rho,\lambda)\bigg{\}}\lesssim\frac{1}{T^{2}},\]

and,

\[P\bigg{\{}\mathcal{B}^{c}(\widetilde{r},\rho,\frac{\lambda}{2})\bigg{\}} \lesssim\frac{1}{T^{2}}.\]

Now, we notice that,

\[\sum_{k=1}^{\mathcal{R}}\widetilde{n}_{k}=\sum_{k=1}^{\mathcal{R}}(2^{k}-1) \leq\sum_{k=1}^{\mathcal{R}}2^{k}\leq 2(2^{\bigg{[}C_{\mathcal{R}}\left( \frac{\log\left(\frac{T}{\lambda}\right)}{\log(2)}\right)\bigg{]}}-1)\leq 2(2^{ \bigg{[}C_{\mathcal{R}}\left(\frac{\log(T)}{\log(2)}\right)\bigg{]}}-1)=O(T).\]

since \(2^{-x}<1\) for any \(x>0\). In addition, there are \(K=O(1)\) number of change points. In consequence, it follows that

\[P\bigg{\{}\mathcal{A}(\mathcal{I},\rho,\lambda)\text{ for all } \mathcal{I}\in\mathcal{J}\bigg{\}}\geq 1-\frac{1}{T},\] (10) \[P\bigg{\{}\mathcal{B}(s,\rho,\lambda)\cup\mathcal{B}(e,\rho, \lambda)\text{ for all }(s,e]=\mathcal{I}\in\mathcal{J}\bigg{\}}\geq 1-\frac{1}{T},\] (11) \[P\bigg{\{}\mathcal{B}(\eta_{k},\rho,\lambda)\text{ for all }1\leq k \leq K\bigg{\}}\geq 1-\frac{1}{T}.\] (12)

The rest of the argument is made by assuming the events in equations (10), (11) and (12) hold. By Remark 1, we have that on these events, it is satisfied that

\[\max_{t=s+\rho+1}^{e-\rho}||\widetilde{F}_{t,h}^{s,e}(x)-\widetilde{f}_{t}^{s,e}(x)||_{L_{2}}\leq\lambda.\]Denote

\[\Upsilon_{k}=C\log(T)\bigg{(}T^{\frac{p}{2r+p}}\bigg{)}\kappa_{k}^{-2}\quad\text{ and}\quad\Upsilon_{\max}=C\log(T)\bigg{(}T^{\frac{p}{2r+p}}\bigg{)}\kappa^{-2},\]

where \(\kappa=\min\{\kappa_{1},\ldots,\kappa_{K}\}\). Since \(\Upsilon_{k}\) is the desired localisation rate, by induction, it suffices to consider any generic interval \((s,e]\subseteq(0,T]\) that satisfies the following three conditions:

\[\eta_{m-1}\leq s\leq\eta_{m}\leq\ldots\leq\eta_{m+q}\leq e\leq\eta _{m+q+1},\quad q\geq-1;\] \[\text{either }\eta_{m}-s\leq\Upsilon_{m}\quad\text{or}\quad s- \eta_{m-1}\leq\Upsilon_{m-1};\] \[\text{either }\eta_{m+q+1}-e\leq\Upsilon_{m+q+1}\quad\text{or} \quad e-\eta_{m+q}\leq\Upsilon_{m+q}.\]

Here \(q=-1\) indicates that there is no change point contained in \((s,e]\).

Denote

\[\Delta_{k}=\eta_{k-1}-\eta_{k}\text{ for }k=1,\ldots,K+1\quad\text{and}\quad \Delta=\min\{\Delta_{1},\ldots,\Delta_{K+1}\}.\]

Observe that by assumption 3,

\[\Upsilon_{\max}=C\log(T)\Big{(}T^{\frac{p}{2r+p}}\Big{)}\kappa^{-2}\leq\frac{ \Delta}{4}\]

Therefore, it has to be the case that for any true change point \(\eta_{m}\in(0,T]\), either \(|\eta_{m}-s|\leq\Upsilon_{m}\) or \(|\eta_{m}-s|\geq\Delta-\Upsilon_{\max}\geq\frac{3}{4}\Delta\). This means that \(\min\{|\eta_{m}-e|,|\eta_{m}-s|\}\leq\Upsilon_{m}\) indicates that \(\eta_{m}\) is a detected change point in the previous induction step, even if \(\eta_{m}\in(s,e]\). We refer to \(\eta_{m}\in(s,e]\) as an undetected change point if \(\min\{\eta_{m}-s,\eta_{m}-e\}\geq\frac{3}{4}\Delta\). To complete the induction step, it suffices to show that \(\text{MNSBS}((s,e],h,\tau)\)

**(i)** will not detect any new change point in \((s,e]\) if all the change points in that interval have been previously detected, and

**(ii)** will find a point \(D^{\mathcal{I}^{*}}\) in \((s,e]\) such that \(|\eta_{m}-D^{\mathcal{I}^{*}}|\leq\Upsilon_{m}\) if there exists at least one undetected change point in \((s,e]\).

In order to accomplish this, we need the following series of steps.

**Step 1.** We first observe that if \(\eta_{k}\in\{\eta_{k}\}_{k=1}^{K}\) is any change point in the functional time series, by Lemma 5, there exists a seeded interval \(\mathcal{I}_{k}=(s_{k},e_{k}]\) containing exactly one change point \(\eta_{k}\) such that

\[\min\{\eta_{k}-s_{k},e_{k}-\eta_{k}\}\geq\frac{1}{16}\Delta,\quad\text{and} \quad\max\{\eta_{k}-s_{k},e_{k}-\eta_{k}\}\leq\frac{9}{10}\Delta\]

Even more, we notice that if \(\eta_{k}\in(s,e]\) is any undetected change point in \((s,e]\). Then it must hold that

\[s-\eta_{k-1}\leq\Upsilon_{\max}.\]

Since \(\Upsilon_{\max}=O(\log(T)T^{\frac{p}{2r+p}})\) and by assumption 3, we have that \(\Upsilon_{\max}<\frac{1}{10}\Delta\). Moreover, \(\eta_{k}-s_{k}\leq\frac{9}{10}(\eta_{k}-\eta_{k-1})\), so that it holds that

\[s_{k}-\eta_{k-1}\geq\frac{1}{10}(\eta_{k}-\eta_{k-1})>\Upsilon_{\max}\geq s- \eta_{k-1}\]

and in consequence \(s_{k}\geq s\). Similarly \(e_{k}\leq e\). Therefore

\[\mathcal{I}_{k}=(s_{k},e_{k}]\subseteq(s,e].\]

**Step 2.** Consider the collection of intervals \(\{\mathcal{I}_{k}=(s_{k},e_{k}]\}_{k=1}^{K}\) in **Step 1.** In this step, it is shown that for each \(k\in\{1,\ldots,K\}\), it holds that

\[\frac{t=e_{k}-\eta}{\max\limits_{t=s_{k}+\rho}^{t=e_{k}-\rho}||\vec{F}_{t,h}^{ (s_{k},e_{k})}||_{L_{2}}\geq c_{1}\sqrt{\Delta}\kappa_{k},\] (13)

for some sufficient small constant \(c_{1}\).

Let \(k\in\{1,\ldots,K\}\). By **Step 1**, \(\mathcal{I}_{k}\) contains exactly one change point \(\eta_{k}\). Since \(f_{t}\) is a one-dimensional population time series and there is only one change point in \(\mathcal{I}_{k}=(s_{k},e_{k}]\), it holds that

\[f_{s_{k}+1}=...=f_{\eta_{k}}\neq f_{\eta_{k}+1}=...=f_{e_{k}}\]which implies, for \(s_{k}<t<\eta_{k}\)

\[\begin{split}\widetilde{f}_{t}^{(s_{k},e_{k}]}=& \sqrt{\frac{e_{k}-t}{(e_{k}-s_{k})(t-s_{k})}}\sum_{l=s_{k}+1}^{t}f_{ \eta_{k}}-\sqrt{\frac{t-s_{k}}{(e_{k}-s_{k})(e_{k}-t)}}\sum_{l=t+1}^{\eta_{k}}f _{\eta_{k}}\\ -&\sqrt{\frac{t-s_{k}}{(e_{k}-s_{k})(e_{k}-t)}}\sum_ {l=\eta_{k}+1}^{e_{k}}f_{\eta_{k}+1}\\ =&(t-s_{k})\sqrt{\frac{e_{k}-t}{(e_{k}-s_{k})(t-s_{k })}}f_{\eta_{k}}-(\eta_{k}-t)\sqrt{\frac{t-s_{k}}{(e_{k}-s_{k})(e_{k}-t)}}f_{ \eta_{k}}\\ -&(e_{k}-\eta_{k})\sqrt{\frac{t-s_{k}}{(e_{k}-s_{k}) (e_{k}-t)}}f_{\eta_{k}+1}\\ =&(e_{k}-t)\sqrt{\frac{t-s_{k}}{(e_{k}-t)(e_{k}-s_{k })}}f_{\eta_{k}}-(\eta_{k}-t)\sqrt{\frac{t-s_{k}}{(e_{k}-s_{k})(e_{k}-t)}}f_{ \eta_{k}}\\ -&(e_{k}-\eta_{k})\sqrt{\frac{t-s_{k}}{(e_{k}-s_{k}) (e_{k}-t)}}f_{\eta_{k}+1}\\ =&(e_{k}-\eta_{k})\sqrt{\frac{t-s_{k}}{(e_{k}-t)(e_ {k}-s_{k})}}f_{\eta_{k}}-(e_{k}-\eta_{k})\sqrt{\frac{t-s_{k}}{(e_{k}-s_{k})(e_ {k}-t)}}f_{\eta_{k}+1}\\ =&(e_{k}-\eta_{k})\sqrt{\frac{t-s_{k}}{(e_{k}-t)(e_ {k}-s_{k})}}(f_{\eta_{k}}-f_{\eta_{k}+1}).\end{split}\]

Similarly, for \(\eta_{k}\leq t\leq e_{k}\)

\[f_{t}^{(s_{k},e_{k})}=\sqrt{\frac{e_{k}-t}{(e_{k}-s_{k})(t-s_{k })}}(\eta_{k}-s_{k})(f_{\eta_{k}}-f_{\eta_{k}+1}).\]

Therefore,

\[\begin{split}\widetilde{f}_{t}^{(s_{k},e_{k})}=\begin{cases} \sqrt{\frac{t-s_{k}}{(e_{k}-s_{k})(e_{k}-t)}}(e_{k}-\eta_{k})(f_{\eta_{k}}-f_ {\eta_{k}+1}),&s_{k}<t<\eta_{k};\\ \sqrt{\frac{e_{k}-t}{(e_{k}-s_{k})(t-s_{k})}}(\eta_{k}-s_{k})(f_{\eta_{k}}-f_ {\eta_{k}+1}),&\eta_{k}\leq t\leq e_{k}.\end{cases}\end{split}\] (14)

Since \(\rho=O(\log(T)T^{\frac{p}{2+p+p}})\), by Assumption 3, we have that

\[\min\{\eta_{k}-s_{k},e_{k}-\eta_{k}\}\geq\frac{1}{16}\Delta>\rho,\] (15)

so that \(\eta_{k}\in[s_{k}+\rho,e_{k}-\rho]\). Then, from (14), (15) and the fact that \(|e_{k}-s_{k}|<\Delta\) and \(|\eta_{k}-s_{k}|<\Delta\),

\[||\widetilde{f}_{\eta_{k}}^{(s_{k},e_{k})}||_{L_{2}}=\sqrt{\frac{e_{k}-\eta_{k }}{(e_{k}-s_{k})(\eta_{k}-s_{k})}}(\eta_{k}-s_{k})||f_{\eta_{k}}-f_{\eta_{k}+1 }||_{L_{2}}\geq c_{2}\sqrt{\Delta}\frac{3}{4}\kappa_{k}.\] (16)

Therefore, it holds that

\[\begin{split}\max_{t=s_{k}+\rho}^{t=e_{k}-\rho}||\widetilde{F}_{t,h}^{(s_{k},e_{k})}||_{L_{2}}\geq&||\widetilde{F}_{\eta_{k},h}^{(s _{k},e_{k})}||_{L_{2}}\\ \geq&||\widetilde{F}_{\eta_{k}}^{(s_{k},e_{k})}||_{L_{ 2}}-\lambda\\ \geq& c_{2}\frac{3}{4}\sqrt{\Delta}\kappa_{k}-\lambda, \end{split}\]where the first inequality follows from the fact that \(\eta_{k}\in[s_{k}+\rho,e_{k}-\rho]\), the second inequality follows from the good event in (10) and Remark 2, and the last inequality follows from (16).

Next, we observe that by Assumption 3

\[\log^{\frac{1}{2}}(T)\sqrt{\frac{1}{h^{p}}}=\sqrt{T^{\frac{p}{2r+p}}}\sqrt{\log (T)}\leq\frac{c_{2}}{4}\sqrt{\Delta}\kappa_{k},\]

and,

\[\sqrt{Th}^{r}=T^{\frac{1}{2}-\frac{r}{2r+p}}=T^{\frac{p}{4r+2p}}.\]

In consequence, since \(\kappa_{k}\) is a positive constant, by the upper bound of \(\lambda\) on Equation (9), for sufficiently large \(T\), it holds that

\[\frac{c_{2}}{4}\sqrt{\Delta}\kappa_{k}\geq\lambda.\]

Therefore,

\[\max_{t=s_{k}+\rho}^{t=e_{k}-\rho}||\widetilde{F}_{t,h}^{(s_{k},e_{k})}||_{L_ {2}}\geq\frac{c_{2}}{2}\sqrt{\Delta}\kappa_{k}.\]

Therefore Equation (13) holds with \(c_{1}=\frac{c_{2}}{2}\).

**Step 3.** In this step, it is shown that SBS\(((s,e],h,\tau)\) can consistently detect or reject the existence of undetected change points within \((s,e]\).

Suppose \(\eta_{k}\in(s,e]\) is any undetected change point. Then by the second half of **Step 1**, \(\mathcal{I}_{k}\subseteq(s,e]\), and moreover

\[a_{\mathcal{I}^{*}}\geq\max_{t=s_{k}+\rho}^{t=e_{k}-\rho}||\widetilde{F}_{t,h }^{(s_{k},e_{k})}||_{L_{2}}\geq c_{1}\sqrt{\Delta}\kappa_{k}>\tau,\]

where the second inequality follows from Equation (13), and the last inequality follows from Assumption 3 and the choice of \(\tau=C_{\tau}\bigg{(}\log^{\frac{1}{2}}(T)\sqrt{\frac{1}{h^{p}}}\bigg{)}\). Therefore, \(\mathcal{M}^{s,e}\neq\emptyset\), since \(\mathcal{I}_{k}\in\mathcal{M}^{s,e}\).

Suppose there does not exist any undetected change point in \((s,e]\). Then for any \(\mathcal{I}=(\alpha,\beta]\subseteq(s,e]\), one of the following situations must hold,

* There is no change point within \((\alpha,\beta]\);
* there exists only one change point \(\eta_{k}\) within \((\alpha,\beta]\) and \(\min\{\eta_{k}-\alpha,\beta-\eta_{k}\}\leq\Upsilon_{k}\);
* there exist two change points \(\eta_{k},\eta_{k+1}\) within \((\alpha,\beta]\) and \[\eta_{k}-\alpha\leq\Upsilon_{k}\quad\text{and}\quad\beta-\eta_{k+1}\leq \Upsilon_{k+1}.\]

Observe that if (a) holds, then we have

\[\max_{\alpha+\rho<t<\beta-\rho}||\widetilde{F}_{t,h}^{(\alpha,\beta)}||_{L_{2 }}\leq\max_{\alpha+\rho<t<\beta-\rho}||\widetilde{f}_{t}^{(\alpha,\beta)}||_{ L_{2}}+\lambda=\lambda.\]

Cases (b) and (c) can be dealt with using similar arguments. We will only work on (c) here. It follows that, in the good event in Equation (10),

\[\max_{\alpha+\rho<t<\beta-\rho}||\widetilde{F}_{t,h}^{(\alpha,\beta )}||_{L_{2}} \leq\max_{\alpha<t<\beta}||\widetilde{f}_{t}^{(\alpha,\beta)}||_{ L_{2}}+\lambda\] (17) \[\leq\sqrt{e-\eta_{k}}\kappa_{k+1}+\sqrt{\eta_{k}-s}\kappa_{k}+\lambda\] (18) \[\leq 2\sqrt{C}\log^{\frac{1}{2}}(T)\sqrt{T^{\frac{p}{2r+p}}}+\lambda\] (19)

where the second inequality is followed by Lemma 7. Therefore in the good event in Equation (10), for any \(\mathcal{I}=(\alpha,\beta]\subseteq(s,e]\), it holds that

\[a_{\mathcal{I}}=\frac{\max_{\alpha+\rho}^{\beta-\rho}||\widetilde{F}_{t,h}^{( \alpha,\beta]}||_{L_{2}}}\leq 2\sqrt{C}\log^{\frac{1}{2}}(T)\sqrt{T^{\frac{p}{2r+p}}}+\lambda,\]

Then,

\[2\sqrt{C}\log^{\frac{1}{2}}(T)\sqrt{1+T^{\frac{p}{2r+p}}}+\lambda\] \[= 2\sqrt{C}\log^{\frac{1}{2}}(T)\sqrt{\frac{1}{h^{p}}}+1+2C\sqrt{ \frac{\log T}{h^{p}}}+\frac{2C_{1}\sqrt{p}}{\sqrt{h^{p}}}+2C_{2}\sqrt{T}h^{r}.\]We observe that \(\sqrt{\frac{\log(T)}{h^{p}}}=O\Big{(}\log(T)^{1/2}\sqrt{\frac{1}{h^{p}}}\Big{)}\). Moreover,

\[\sqrt{T}h^{r}=\sqrt{T}\Big{(}\frac{1}{T}\Big{)}^{\frac{r}{2r+p}}\leq\Big{(}T^{ \frac{1}{2}-\frac{r}{2r+p}}\Big{)},\]

and given that,

\[\frac{1}{2}-\frac{r}{2r+p}=\frac{p}{2(2r+p)}\]

we get,

\[\sqrt{T}h^{r}=o\Big{(}\log^{\frac{1}{2}}(T)\sqrt{\frac{1}{h^{p}}}\Big{)}.\]

Therefore, by the choice of \(\tau\), we will always correctly reject the existence of undetected change points, since

\[2\sqrt{C}\log^{\frac{1}{2}}(T)\sqrt{T^{\frac{p}{2r+p}}}+\lambda\leq\tau.\]

Thus, by the choice of \(\tau\), it holds that with sufficiently large constant \(C_{\tau}\),

\[a_{\mathcal{I}}\leq\tau\quad\text{for all}\quad\mathcal{I}\subseteq(s,e].\] (20)

As a result, \(\text{MNSBS}((s,e],h,\tau)\) will correctly reject if \((s,e]\) contains no undetected change points.

**Step 4.** Assume that there exists an undetected change point \(\eta_{\widetilde{k}}\in(s,e]\) such that

\[\min\{\eta_{\widetilde{k}}-s,\eta_{\widetilde{k}}-e\}=\frac{3}{4}\Delta.\]

Then, \(\mathcal{M}^{s,e}\neq\emptyset\). Let \(\mathcal{I}^{*}\) be defined as in MNSBS \(((s,e],h,\tau)\) with

\[\mathcal{I}^{*}=(\alpha^{*},\beta^{*}].\]

To complete the induction, it suffices to show that, there exists a change point \(\eta_{k}\in(s,e]\) such that \(\min\{\eta_{k}-s,\eta_{k}-e\}\geq\frac{3}{4}\Delta\) and \(|b_{\mathcal{I}^{*}}-\eta_{k}|\leq\Upsilon_{k}\). To this end, we consider the collection of change points of \(\{f_{t}\}_{t\in(\alpha^{*},\beta^{*}]}\) We are to ensure that the assumptions of Lemma 12 are satisfied. In the following, \(\lambda\) is used in Lemma 12. Then Equation (68) and Equation (69) are directly consequence of Equation (10), Equation (11), Equation (12). By the narrowest of \(\mathcal{I}^{*}\),

\[|\mathcal{I}^{*}|\leq|\mathcal{I}_{k}|\leq\Delta,\]

and by **Step 1** with \(\mathcal{I}_{k}=(s_{k},e_{k}]\), it holds that

\[\min\{\eta_{k}-s_{k},e_{k}-\eta_{k}\}\geq\frac{1}{16}\zeta_{k}\geq c_{2}\Delta,\]

Therefore for all \(k\in\{\widetilde{k}:\min\{\eta_{\widetilde{k}}-s,e-\eta_{\widetilde{k}}\}\geq c _{2}\Delta\}\),

\[\begin{subarray}{c}t_{\max}^{=\beta^{*}\alpha}|\widetilde{F}_{t,h}^{(\alpha^{* },\beta^{*})}||_{L_{2}}\geq\frac{t_{\max}^{=e_{k}-\alpha}}{\max\limits_{t=s_{k }+\rho}^{2}}||\widetilde{F}_{t,h}^{(s_{k},e_{k})}||_{L_{2}}\geq c_{1}\sqrt{ \Delta}\kappa_{k},\end{subarray}\]

where the last inequality follows from Equation (13). Therefore (70) holds in Lemma 12. Finally, Equation (71) is a direct consequence of the choices that

\[h=C_{h}(T)^{\frac{-1}{2r+d}}\quad\text{and}\quad\rho=\frac{\log(T)}{nh^{d}}.\]

Thus, all the conditions in Lemma 12 are met. So that, there exists a change point \(\eta_{k}\) of \(\{f_{t}\}_{t\in\mathcal{I}^{*}}\), satisfying

\[\min\{\beta^{*}-\eta_{k},\eta_{k}-\alpha^{*}\}>c\Delta,\] (21)

and

\[|b_{\mathcal{I}^{*}}-\eta_{k}|\leq\max\{C_{3}\lambda^{2}\kappa_{k }^{-2},\rho\}\leq C_{4}\log(T)\bigg{(}\frac{1}{h^{p}}+Th^{2r}\bigg{)}\kappa_{k}^{-2}\] \[\leq C\log(T)\bigg{(}T^{\frac{p}{2r+p}}\bigg{)}\kappa_{k}^{-2}\]for sufficiently large constant \(C\), where we have followed the same line of arguments as for the conclusion of (20). Observe that

**i)** The change points of \(\{f_{t}\}_{t\in\mathcal{I}^{*}}\) belong to \((s,e]\cap\{\eta_{k}\}_{k=1}^{K}\); and

**ii)** Equation (21) and \((\alpha^{*},\beta^{*}]\subseteq(s,e]\) imply that

\[\min\{e-\eta_{k},\eta_{k}-s\}>c\Delta\geq\Upsilon_{\max}.\]

As discussed in the argument before **Step 1**, this implies that \(\eta_{k}\) must be an undetected change point of \(\{f_{t}\}_{t\in\mathcal{I}^{*}}\).

Proof of Theorem 2

In this section, we present the proof of theorem Theorem 2.

Proof of Theorem 2.: **Uniform tightness** of \(\kappa_{k}^{2+\frac{p}{r}}\Big{|}\widetilde{\eta}_{k}-\eta_{k}\Big{|}\). Here we show **a.1** and **b.1**. For this purpose, we will follow a series of steps. On **step 1**, we rewrite (6) in order to derive a uniform bound. **Step 2** analyses the lower bound while **Step 3** the upper bound. **Step 1:** Denote \(\widetilde{r}=\widetilde{\eta}_{k}-\eta_{k}\). Without loss of generality, suppose \(\widetilde{r}\geq 0\). Since \(\widetilde{\eta}_{k}=\eta_{k}+\widetilde{r}\), defined in (6), is the minimizer of \(\widehat{Q}_{k}(\eta)\), it follows that

\[\widehat{Q}_{k}(\eta_{k}+\widetilde{r})-\widehat{Q}_{k}(\eta_{k})\leq 0.\]

Let

\[Q^{*}(\eta)=\sum_{t=s_{k}+1}^{\eta}\|F_{t,h_{2}}-f_{(s_{k},\eta_{k})}*\mathcal{ K}_{h_{2}}\|_{L_{2}}^{2}+\sum_{t=q+1}^{e_{k}}\|F_{t,h_{2}}-f_{(\eta_{k},e_{k})}* \mathcal{K}_{h_{2}}\|_{L_{2}}^{2},\] (22)

where,

\[f_{(s_{k},\eta_{k})}=\frac{1}{\eta_{k}-s_{k}}\sum_{i=s_{k}+1}^{\eta_{k}}f_{i},\;f_{(\eta_{k},e_{k})}=\frac{1}{e_{k}-\eta_{k}}\sum_{i=\eta_{k}+1}^{e_{k}}f_ {i}.\] (23)

Observe that,

\[Q^{*}(\eta_{k}+\widetilde{r})-Q^{*}(\eta_{k})\leq \widehat{Q}_{k}(\eta_{k})-\widehat{Q}_{k}(\eta_{k}+\widetilde{r} )-Q^{*}(\eta_{k})+Q^{*}(\eta_{k}+\widetilde{r}).\] (24)

If \(\widetilde{r}\leq 1/\kappa_{k}^{2+\frac{p}{r}}\), then there is nothing to show. So for the rest of the argument, for contradiction, assume that

\[\widetilde{r}\geq\frac{1}{\kappa_{k}^{2+\frac{p}{r}}}.\] (25)

**Step 2: Finding a lower bound.** In this step, we will find a lower bound of the inequality (24). To this end, we observe that,

\[Q^{*}(\eta_{k}+\widetilde{r})-Q^{*}(\eta_{k}) =\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}||F_{t,h_{2}}-f_{(s _{k},\eta_{k})}*\mathcal{K}_{h_{2}}||_{L_{2}}^{2}-\sum_{t=\eta_{k}+1}^{\eta_{ k}+\widetilde{r}}||F_{t,h_{2}}-f_{(\eta_{k},e_{k})}*\mathcal{K}_{h_{2}}||_{L_{2}}^{2}\] \[=\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}||f_{(s_{k},\eta_{k} )}*\mathcal{K}_{h_{2}}-f_{(\eta_{k},e_{k})}*\mathcal{K}_{h_{2}}||_{L_{2}}^{2}\] \[\quad-2\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}\langle f_{(s _{k},\eta_{k})}*\mathcal{K}_{h_{2}}-f_{(\eta_{k},e_{k})}*\mathcal{K}_{h_{2}},F _{t,h_{2}}-f_{(\eta_{k},e_{k})}*\mathcal{K}_{h_{2}}\rangle_{L_{2}}\] \[=\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}\frac{1}{2}||f_{(s _{k},\eta_{k})}-f_{(\eta_{k},e_{k})}||_{L_{2}}^{2}-2||f_{(s_{k},\eta_{k})}* \mathcal{K}_{h_{2}}-f_{(s_{k},\eta_{k})}+f_{(\eta_{k},e_{k})}*\mathcal{K}_{h_{2 }}-f_{(\eta_{k},e_{k})}||_{L_{2}}^{2}\] \[\quad-2\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}\langle f_{(s _{k},\eta_{k})}*\mathcal{K}_{h_{2}}-f_{(\eta_{k},e_{k})}*\mathcal{K}_{h_{2}},F _{t,h_{2}}-f_{(\eta_{k},e_{k})}*\mathcal{K}_{h_{2}}\rangle_{L_{2}}\] \[\geq \frac{1}{2}\widetilde{r}\kappa_{k}^{2}-2\sum_{t=\eta_{k}+1}^{ \eta_{k}+\widetilde{r}}||f_{(s_{k},\eta_{k})}*\mathcal{K}_{h_{2}}-f_{(s_{k}, \eta_{k})}+f_{(\eta_{k},e_{k})}*\mathcal{K}_{h_{2}}-f_{(\eta_{k},e_{k})}||_{L_{ 2}}^{2}\] \[\quad-2\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}\langle f_{(s _{k},\eta_{k})}*\mathcal{K}_{h_{2}}-f_{(\eta_{k},e_{k})}*\mathcal{K}_{h_{2}},F _{t,h_{2}}-f_{(\eta_{k},e_{k})}*\mathcal{K}_{h_{2}}\rangle_{L_{2}}\]We consider,

\[I_{1}:=2\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}||f_{(s_{k}, \eta_{k}]}*\mathcal{K}_{h_{2}}-f_{(s_{k},\eta_{k}]}+f_{(\eta_{k},e_{k}]}* \mathcal{K}_{h_{2}}-f_{(\eta_{k},e_{k}]}||_{L_{2}}^{2},\text{ and,}\] \[I_{2}:=2\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}\langle f_{( s_{k},\eta_{k}]}*\mathcal{K}_{h_{2}}-f_{(\eta_{k},e_{k}]}*\mathcal{K}_{h_{2}},F_{t,h_{2}}-f_{( \eta_{k},e_{k}]}*\mathcal{K}_{h_{2}}\rangle_{L_{2}}.\]

From above, we have that,

\[Q^{*}(\eta_{k}+\widetilde{r})-Q^{*}(\eta_{k})\geq \frac{1}{2}\widetilde{r}\kappa_{k}^{2}-I_{1}-I_{2}.\]

We now analyze the order of magnitude of term \(I_{1}\). Then, we get a lower bound for the term \(-I_{1}\). In fact \(I_{1}\), has an upper bound of the form \(o_{p}(\widetilde{r}\kappa_{k}^{\frac{p}{2}+2})\), where we use that \(||f_{\eta_{k}}*\mathcal{K}_{h_{2}}-f_{\eta_{k}}||_{L_{2}}=o(1)\) and \(||f_{\eta_{k+1}}*\mathcal{K}_{h_{2}}-f_{\eta_{k+1}}||_{L_{2}}=o(1)\). For the term \(I_{2}\), we consider the random variable,

\[Y_{i}=\frac{\langle f_{[s_{k}+1,\eta_{k}]}*\mathcal{K}_{h_{2}}-f_{[\eta_{k}+1, e_{k}]}*\mathcal{K}_{h_{2}},F_{t,h_{2}}-f_{[\eta_{k}+1,e_{k}]}*\mathcal{K}_{h_{2}} \rangle_{L_{2}}}{\kappa_{k}\mathbb{E}(||F_{t,h_{2}}-f_{\eta_{k+1}}*\mathcal{K} _{h_{2}}||_{L^{2}}^{3})^{1/3}}.\]

In order to use Lemma 3, we need to bound \(\mathbb{E}(|Y_{i}|^{3})\). For this, first we use Cauchy Schwartz inequality,

\[\mathbb{E}(|Y_{i}|^{3})\leq \frac{(||(f_{\eta_{k}+1}-f_{\eta_{k}})*\mathcal{K}_{h_{2}}||_{L^ {2}})^{3}\mathbb{E}(||F_{t,h_{2}}-f_{\eta_{k+1}}*\mathcal{K}_{h_{2}}||_{L^{2} }^{3})}{\kappa_{k}^{3}\mathbb{E}(||F_{t,h_{2}}-f_{\eta_{k+1}}*\mathcal{K}_{h_ {2}}||_{L^{2}}^{3})}\]

then, by Minkowski's inequality,

\[||(f_{\eta_{k}+1}-f_{\eta_{k}})*\mathcal{K}_{h_{2}}||_{L^{2}}= \Big{|}\Big{|}\int_{\mathbb{R}^{p}}(f_{\eta_{k}+1}-f_{\eta_{k}}) (\cdot-y)\mathcal{K}_{h_{2}}(y)dy\Big{|}\Big{|}_{L_{2}}\] \[\leq \int_{\mathbb{R}^{p}}\Big{|}\Big{|}(f_{\eta_{k}+1}-f_{\eta_{k}}) (\cdot-y)\mathcal{K}_{h_{2}}(y)\Big{|}\Big{|}_{L_{2}}dy\] \[= \Big{(}\int_{\mathbb{R}^{p}}|\mathcal{K}_{h_{2}}(y)|dy\Big{)} \Big{|}\Big{|}(f_{\eta_{k}+1}-f_{\eta_{k}})(\cdot-y)\Big{|}\Big{|}_{L_{2}}\] \[= ||f_{\eta_{k}+1}-f_{\eta_{k}}||_{L^{2}}||\mathcal{K}_{h_{2}}||_{L^ {1}}.\]

Therefore, by Assumption 2, we have

\[\frac{(||(f_{\eta_{k}+1}-f_{\eta_{k}})*\mathcal{K}_{h_{2}}||_{L^{ 2}})^{3}\mathbb{E}(||F_{t,h_{2}}-f_{\eta_{k+1}}*\mathcal{K}_{h_{2}}||_{L^{2}}^ {3})}{\kappa_{k}^{3}\mathbb{E}(||F_{t,h_{2}}-f_{\eta_{k+1}}*\mathcal{K}_{h_{2}} ||_{L^{2}}^{3})}\] \[\leq \frac{(||f_{\eta_{k}+1}-f_{\eta_{k}}||_{L^{2}}||\mathcal{K}_{h_{2 }}||_{L^{1}})^{3}\mathbb{E}(||F_{t,h_{2}}-f_{\eta_{k+1}}*\mathcal{K}_{h_{2}}||_{L ^{2}}^{3})}{\kappa_{k}^{3}\mathbb{E}(||F_{t,h_{2}}-f_{\eta_{k+1}}*\mathcal{K}_{h _{2}}||_{L^{2}}^{3})}\] \[\leq C_{K}.\]

for any \(t\in(\eta_{k},e_{k}]\). Moreover, we have that

\[\mathbb{E}(||F_{t,h_{2}}-f_{\eta_{k+1}}*\mathcal{K}_{h_{2}}||_{L^{ 2}}^{3})^{\frac{1}{3}} = \Big{(}\int\Big{(}\int(\mathcal{K}_{h_{2}}(x-z)-\mathbb{E}( \mathcal{K}_{h_{2}}(x-X_{t})))^{2}dx\Big{)}^{\frac{3}{2}}f_{t}(z)dz\Big{)}^{1/3}\] (26) \[\leq \Big{(}\int\Big{(}\int(\mathcal{K}_{h_{2}}(x-z))^{2}dx\Big{)}^{ \frac{3}{2}}f_{t}(z)dz\Big{)}^{\frac{1}{3}}\] \[= \frac{1}{\kappa^{\kappa^{p/2\varepsilon}}}.\]

Therefore, by Lemma 3, we have that \(I_{2}=o_{p}\Big{(}\sqrt{\widetilde{r}}\kappa_{k}\kappa_{k}^{-\frac{p}{2 \varepsilon}}(\log(\widetilde{r}\kappa_{k}^{\frac{p}{2}+2})+1)\Big{)}\). Thus,

\[Q^{*}(\eta_{k}+\widetilde{r})-Q^{*}(\eta_{k})\geq \frac{1}{2}\widetilde{r}\kappa_{k}^{2}-O_{p}\Big{(}\sqrt{\widetilde{r }}\kappa_{k}\kappa_{k}^{-\frac{p}{2\varepsilon}}(\log(\widetilde{r}\kappa_{k}^{ \frac{p}{2}+2})+1)\Big{)}-o_{p}(\widetilde{r}\kappa_{k}^{\frac{p}{2}+2}).\] (27)

**Step 3: Finding an upper bound.** Now, we proceeded to get an upper bound of (24). This is, an upper bound of the following expression,

\[\widehat{Q}_{k}(\eta_{k})-\widehat{Q}_{k}(\eta_{k}+\widetilde{r})-Q^{*}(\eta_{k} )+Q^{*}(\eta_{k}+\widetilde{r}).\] (28)Observe that, this expression can be written as,

\[\widehat{Q}_{k}(\eta_{k})-\widehat{Q}_{k}(\eta_{k}+\widetilde{r})-Q^ {*}(\eta_{k})+Q^{*}(\eta_{k}+\widetilde{r})\] \[= -\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}||F_{t,h_{1}}-F_{(s_{ k},\eta_{k}],h_{1}}||_{L_{2}}^{2}+\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}||F_{t,h_{1} }-F_{(\widehat{\eta}_{k},e_{k}],h_{1}}||_{L_{2}}^{2}\] \[+\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}||F_{t,h_{2}}-f_{(s_ {k},\eta_{k}]}*\mathcal{K}_{h_{2}}||_{L_{2}}^{2}-\sum_{t=\eta_{k}+1}^{\eta_{k}+ \widetilde{r}}||F_{t,h_{2}}-f_{(\widehat{\eta}_{k},e_{k}]}*\mathcal{K}_{h_{2} }||_{L_{2}}^{2}\]

So that,

\[\widehat{Q}_{k}(\eta_{k})-\widehat{Q}_{k}(\eta_{k}+\widetilde{r})-Q^{*}(\eta_ {k})+Q^{*}(\eta_{k}+\widetilde{r})=U_{1}+U_{2},\]

where,

\[U_{1} =\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}||F_{t,h_{2}}-f_{(s _{k},\eta_{k}]}*\mathcal{K}_{h_{2}}||_{L_{2}}^{2}-\sum_{t=\eta_{k}+1}^{\eta_{k }+\widetilde{r}}||F_{t,h_{1}}-F_{(s_{k},\widehat{\eta}_{k}],h_{1}}||_{L_{2}}^ {2},\text{ and,}\] \[U_{2} =\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}||F_{t,h_{1}}-F_{( \widehat{\eta}_{k},e_{k}],h_{1}}||_{L_{2}}^{2}-\sum_{t=\eta_{k}+1}^{\eta_{k}+ \widetilde{r}}||F_{t,h_{2}}-f_{(\eta_{k},e_{k}]}*\mathcal{K}_{h_{2}}||_{L_{2}} ^{2}.\]

Now, we analyze each of the terms above. For \(U_{1}\), observe that

\[\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}||F_{t,h_{2}}-f_{(s_ {k},\eta_{k}]}*\mathcal{K}_{h_{2}}||_{L_{2}}^{2}-\sum_{t=\eta_{k}+1}^{\eta_{k }+\widetilde{r}}||F_{t,h_{1}}-F_{(s_{k},\widehat{\eta}_{k}],h_{1}}||_{L_{2}}^ {2}\] \[= \sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}||F_{t,h_{2}}-f_{(s_ {k},\eta_{k}]}*\mathcal{K}_{h_{2}}||_{L_{2}}^{2}-\sum_{t=\eta_{k}+1}^{\eta_{k}+ \widetilde{r}}||F_{t,h_{2}}-F_{(s_{k},\eta_{k}],h_{2}}||_{L_{2}}^{2}\] \[+ \sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}||F_{t,h_{2}}-F_{(s_ {k},\eta_{k}],h_{2}}||_{L_{2}}^{2}-\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}} ||F_{t,h_{1}}-F_{(s_{k},\eta_{k}],h_{1}}||_{L_{2}}^{2}\] \[= I_{3}+I_{4},\]

where,

\[I_{3} =\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}||F_{t,h_{2}}-f_{(s _{k},\eta_{k}]}*\mathcal{K}_{h_{2}}||_{L_{2}}^{2}-\sum_{t=\eta_{k}+1}^{\eta_{k }+\widetilde{r}}||F_{t,h_{2}}-F_{(s_{k},\eta_{k}],h_{2}}||_{L_{2}}^{2},\text{ and,}\] \[I_{4} =\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}||F_{t,h_{2}}-F_{(s _{k},\eta_{k}],h_{2}}||_{L_{2}}^{2}-\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r }}||F_{t,h_{1}}-F_{(s_{k},\widehat{\eta}_{k}],h_{1}}||_{L_{2}}^{2}.\]

To analyze \(I_{3},\) we rewrite it as follow,

\[I_{3}= \sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}||f_{(s_{k},\eta_{k} ]}*\mathcal{K}_{h_{2}}-F_{(s_{k},\eta_{k}],h_{2}}||_{L_{2}}^{2}-2\sum_{t=\eta_{k}+ 1}^{\eta_{k}+\widetilde{r}}\langle f_{(s_{k},\eta_{k}]}*\mathcal{K}_{h_{2}}-F_{(s _{k},\eta_{k}],h_{2}},F_{t,h_{2}}-f_{(s_{k},\eta_{k}]}*\mathcal{K}_{h_{2}} \rangle_{L_{2}}\] \[= I_{3,1}+I_{3,2},\]

where,

\[I_{3,1} =\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}||f_{(s_{k},\eta_{k} ]}*\mathcal{K}_{h_{2}}-F_{(s_{k},\eta_{k}],h_{2}}||_{L_{2}}^{2},\text{ and,}\] \[I_{3,2} =-2\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}\langle f_{(s_{k}, \eta_{k}]}*\mathcal{K}_{h_{2}}-F_{(s_{k},\eta_{k}],h_{2}},F_{t,h_{2}}-f_{(s_{k}, \eta_{k}]}*\mathcal{K}_{h_{2}}\rangle_{L_{2}}.\]Now, we will get an upper bound for each of the terms above. The term \(I_{3,1}=O_{p}\Big{(}\widetilde{r}_{\frac{1}{T}}\frac{\log(T)}{\kappa_{k}^{\frac{p} {p}}}\Big{)}\), which is followed by the use of Remark 1. Even more, by Assumption 4, we get

\[I_{3,1}=o_{p}(\widetilde{r}\kappa_{k}^{\frac{p}{p}+2}).\] (29)

For the term \(I_{3,2}\), by Cauchy Schwartz inequality and triangle inequality,

\[\langle f_{(s_{k},\eta_{k}]}*\mathcal{K}_{\kappa}-F_{(s_{k},\eta_ {k}],\kappa},F_{t,h_{2}}-f_{(s_{k},\eta_{k}]}*\mathcal{K}_{h_{2}})_{L_{2}}\] \[\leq||f_{(s_{k},\eta_{k}]}*\mathcal{K}_{h_{2}}-F_{(s_{k},\eta_{k} ],h_{2}}||_{L_{2}}||F_{t,h_{2}}-f_{(s_{k},\eta_{k}]}*\mathcal{K}_{h_{2}}||_{L _{2}}\] \[\leq||f_{(s_{k},\eta_{k}]}*\mathcal{K}_{h_{2}}-F_{(s_{k},\eta_{k} ],h_{2}}||_{L_{2}}\Big{(}||F_{t,h_{2}}-f_{[\eta_{k}+1,\varepsilon_{k}]}* \mathcal{K}_{h_{2}}||_{L_{2}}+||f_{[\eta_{k}+1,\varepsilon_{k}]}*\mathcal{K}_ {h_{2}}-f_{[s_{k}+1,\eta_{k}]}*\mathcal{K}_{h_{2}}||_{L_{2}}\Big{)}\]

for any \(t\in(\eta_{k},\eta_{k}+\widetilde{r}]\). By the Remark 1, we have that

\[||f_{(s_{k},\eta_{k}]}*\mathcal{K}_{h_{2}}-F_{(s_{k},\eta_{k}],h_{2}}||_{L_{2} }=O_{p}\Big{(}\frac{1}{\sqrt{T}}\sqrt{\frac{\log(T)}{\kappa_{k}^{\frac{p}{p}} }}\Big{)}\]

and using basic properties of integrals \(||f_{[\eta_{k}+1,\varepsilon_{k}]}*\mathcal{K}_{h_{2}}-f_{[s_{k}+1,\eta_{k}]}* \mathcal{K}_{h_{2}}||_{L_{2}}=O(\kappa_{k}).\) Therefore,

\[I_{3,2}\leq O_{p}\Big{(}\frac{1}{\sqrt{T}}\sqrt{\frac{\log(T)}{\kappa_{k}^{ \frac{p}{p}}}}\Big{)}\Big{(}O(\widetilde{r}\kappa_{k})+\sum_{t=\eta_{k}+1}^{ \eta_{k}+\widetilde{r}}||F_{t,h_{2}}-f_{[\eta_{k}+1,\varepsilon_{k}]}* \mathcal{K}_{h_{2}}||_{L_{2}}\Big{)}\]

Now, we need to get a bound of the magnitude of

\[\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}||F_{t,h_{2}}-f_{[\eta_{k}+1, \varepsilon_{k}]}*\mathcal{K}_{h_{2}}||_{L_{2}},\]

in order to get an upper for \(I_{3,2}\). This is done similarly to \(I_{2}\). We consider the random variable

\[\widetilde{Y}_{i}=\frac{\langle F_{t,h_{2}}-f_{(\eta_{k}, \varepsilon_{k}]}*\mathcal{K}_{h_{2}},F_{t,h_{2}}-f_{(\eta_{k},\varepsilon_{k} ]}*\mathcal{K}_{h_{2}}\rangle_{L_{2}}^{\frac{3}{2}}-\mathbb{E}(||F_{t,h_{2}}- f_{\eta_{k+1}}*\mathcal{K}_{h_{2}}||_{L^{2}})}{\mathbb{E}(||F_{t,h_{2}}-f_{ \eta_{k+1}}*\mathcal{K}_{h_{2}}||_{L^{2}})^{\frac{3}{2}}}.\]

In order to use Lemma 3, we observe that since \(||F_{t,h_{2}}-f_{\eta_{k+1}}*\mathcal{K}_{h_{2}}||_{L^{2}}\geq 0,\)

\[\mathbb{E}(|\widetilde{Y}_{i}|^{3})\leq\frac{\mathbb{E}(||F_{t,h_{2}}-f_{\eta_ {k+1}}*\mathcal{K}_{h_{2}}||_{L^{2}}^{3})}{\mathbb{E}(||F_{t,h_{2}}-f_{\eta_{k +1}}*\mathcal{K}_{h_{2}}||_{L^{2}}^{3})}=1.\]

Therefore, using Lemma 3 and that \(\mathbb{E}(||F_{t,h_{2}}-f_{\eta_{k+1}}*\mathcal{K}_{h_{2}}||_{L^{2}})=O(\kappa _{k}^{\frac{-p}{p}})\) by (26), we get that

\[\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}||F_{t,h_{2}}-f_{[\eta_{k}+1, \varepsilon_{k}]}*\mathcal{K}_{h_{2}}||_{L_{2}}^{2}=O_{p}(\sqrt{\widetilde{r} \kappa_{k}^{-\frac{p}{p}}}(\log(\widetilde{r}\kappa_{k}^{\frac{p}{p}+2})+1))+O _{p}(\widetilde{r}\kappa_{k}^{\frac{-p}{p}}).\]

Thus, by Assumption 4 and above,

\[I_{3,2}\leq O_{p}\Big{(}\frac{1}{\sqrt{T}}\sqrt{\frac{\log(T)}{\kappa_{k}^{ \frac{p}{p}}}}\Big{)}\Big{(}O(\widetilde{r}\kappa_{k})+O_{p}(\sqrt{\widetilde{r} \kappa_{k}^{-\frac{p}{p}}}(\log(\widetilde{r}\kappa_{k}^{\frac{p}{p}+2})+1))+O _{p}(\widetilde{r}\kappa_{k}^{\frac{-p}{p}})\Big{)}=o_{p}(\widetilde{r}\kappa_{ k}^{\frac{p}{p}}+2).\] (30)

Consequently, \(I_{3}\) has been bounded, and we only need to go over the term \(I_{4}\), to finalize the analysis for \(U_{1}\). To analyze \(I_{4}\), we observe that

\[I_{4} =\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}||F_{t,h_{2}}-F_{(s_{ k},\eta_{k}],h_{2}}||_{L_{2}}^{2}-\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}||F_{t,h_{1}}-F_{(s_ {k},\widehat{\eta}_{k}],h_{1}}||_{L_{2}}^{2}\] \[=\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}\Big{[}\langle F_{t,h_ {2}},F_{t,h_{2}}\rangle_{L_{2}}-2\langle F_{t,h_{2}},F_{(s_{k},\eta_{k}],h_{2}} \rangle_{L_{2}}+\langle F_{(s_{k},\eta_{k}],h_{2}},F_{(s_{k},\eta_{k}],h_{2}} \rangle_{L_{2}}\Big{]}\] \[\quad+\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}\Big{[}- \langle F_{t,h_{1}},F_{t,h_{1}}\rangle_{L_{2}}+2\langle F_{t,h_{1}},F_{(s_{k}, \widehat{\eta}_{k}],h_{1}}\rangle_{L_{2}}-\langle F_{(s_{k},\widehat{\eta}_{k}],h _{1}},F_{(s_{k},\widehat{\eta}_{k}],h_{1}}\rangle_{L_{2}}\Big{]}\] \[= I_{4,1}+I_{4,2}+I_{4,3},\]where,

\[I_{4,1} =\sum_{t=\eta_{k}+1}^{\eta_{k}+\vec{\tau}}\langle F_{t,h_{2}},F_{t,h_ {2}}\rangle_{L_{2}}-\langle F_{t,h_{1}},F_{t,h_{1}}\rangle_{L_{2}}\] \[I_{4,2} =\sum_{t=\eta_{k}+1}^{\eta_{k}+\vec{\tau}}2\langle F_{t,h_{1}},F_{ (s_{k},\widehat{\eta}_{k}],h_{1}}\rangle_{L_{2}}-2\langle F_{t,h_{2}},F_{(s_{k},\eta_{k}],h_{2}}\rangle_{L_{2}},\;\text{and},\] \[I_{4,3} =\sum_{t=\eta_{k}+1}^{\eta_{k}+\vec{\tau}}\langle F_{(s_{k}, \eta_{k}],h_{2}},F_{(s_{k},\eta_{k}],h_{2}}\rangle_{L_{2}}-\langle F_{(s_{k},\widehat{\eta}_{k}],h_{1}},F_{(s_{k},\widehat{\eta}_{k}],h_{1}}\rangle_{L_{ 2}}.\]

Now, we explore each of the terms \(I_{4,1},I_{4,2},\) and \(I_{4,3}.\) First, \(I_{4,1}\) can be bounded as follows, we add and subtract \(\langle F_{t,h_{1}},F_{t,h_{2}}\rangle_{L_{2}},\) to get

\[\sum_{t=\eta_{k}+1}^{\eta_{k}+\vec{\tau}}\langle F_{t,h_{2}},F_{t,h_{2}}\rangle_{L_{2}}-\langle F_{t,h_{1}},F_{t,h_{1}}\rangle_{L_{2}}\] \[=\sum_{t=\eta_{k}+1}^{\eta_{k}+\vec{\tau}}\langle F_{t,h_{2}},F_{ t,h_{2}}\rangle_{L_{2}}-\langle F_{t,h_{1}},F_{t,h_{1}}\rangle_{L_{2}}+ \langle F_{t,h_{1}},F_{t,h_{2}}\rangle_{L_{2}}-\langle F_{t,h_{1}},F_{t,h_{2} }\rangle_{L_{2}}\] \[=\sum_{t=\eta_{k}+1}^{\eta_{k}+\vec{\tau}}\langle F_{t,h_{2}}-F_{ t,h_{1}},F_{t,h_{2}}\rangle_{L_{2}}+\langle F_{t,h_{1}},F_{t,h_{2}}-F_{t,h_{1}} \rangle_{L_{2}}\]

which, by Holder's inequality, is bounded by

\[\sum_{t=\eta_{k}+1}^{\eta_{k}+\vec{\tau}}||F_{t,h_{2}}||_{L_{2}}||F_{t,h_{2}}- F_{t,h_{1}}||_{L_{2}}+||F_{t,h_{1}}||_{L_{2}}||F_{t,h_{2}}-F_{t,h_{1}}||_{L_{2}}= \widetilde{r}O_{p}(\frac{T^{-\frac{r}{2r+p}}}{\kappa_{k}^{\frac{p}{p}+\frac{1 }{2}+\frac{p}{2r+p}}}\log^{\frac{r}{2r+p}}(T)))\]

since \(||F_{t,h_{1}}-F_{t,h_{2}}||_{L_{2}}=O(\frac{|x-\widehat{x}|^{\frac{1}{2}}}{ \kappa_{k}^{\frac{p}{p}+\frac{1}{2}}})=O_{p}\Big{(}\frac{1}{\frac{p}{\kappa_{ k}^{\frac{p}{p}+\frac{1}{2}}}}\Big{(}\Big{(}\frac{\log(T)}{\Delta} \Big{)}^{\frac{2r}{2r+p}}+\frac{T^{\frac{p}{2r+p}}\log(T)}{\kappa\Delta} \Big{)}^{\frac{1}{2}}\Big{)}\), for any \(t\), see Remark 2 for more detail. Similarly, for \(I_{4,2},\) we have that adding and subtracting \(2\langle F_{t,h_{1}},F_{(s_{k},\eta_{k}],h_{2}}\rangle_{L_{2}},\)

\[\sum_{t=\eta_{k}+1}^{\eta_{k}+\vec{\tau}}2\langle F_{t,h_{1}},F_{ (s_{k},\widehat{\eta}_{k}],h_{1}}\rangle_{L_{2}}-2\langle F_{t,h_{2}},F_{(s_{k },\eta_{k}],h_{2}}\rangle_{L_{2}}\] \[=\sum_{t=\eta_{k}+1}^{\eta_{k}+\vec{\tau}}2\langle F_{t,h_{1}},F_{ (s_{k},\widehat{\eta}_{k}],h_{1}}\rangle_{L_{2}}-2\langle F_{t,h_{2}},F_{(s_{k },\eta_{k}],h_{2}}\rangle_{L_{2}}+2\langle F_{t,h_{1}},F_{(s_{k},\eta_{k}],h_{2} }\rangle_{L_{2}}-2\langle F_{t,h_{1}},F_{(s_{k},\eta_{k}],h_{2}}\rangle_{L_{2}}\] \[=\sum_{t=\eta_{k}+1}^{\eta_{k}+\vec{\tau}}2\langle F_{t,h_{1}}-F_{ t,h_{2}},F_{(s_{k},\eta_{k}],h_{2}}\rangle_{L_{2}}+2\langle F_{t,h_{1}},F_{(s_{k}, \widehat{\eta}_{k}],h_{1}}-F_{(s_{k},\eta_{k}],h_{2}}\rangle_{L_{2}},\]

and by Holder's inequality and Remark 2, it is bounded by

\[\sum_{t=\eta_{k}+1}^{\eta_{k}+\vec{\tau}}||F_{t,h_{1}}-F_{t,h_{2}} ||_{L_{2}}||F_{(s_{k},\eta_{k}],h_{2}}||_{L_{2}}+||F_{t,h_{1}}||_{L_{2}}||F_{(s_{k },\eta_{k}],h_{2}}-F_{(s_{k},\widehat{\eta}_{k}],h_{1}}||_{L_{2}}\] \[= \widetilde{r}O_{p}\Big{(}\frac{1}{\kappa_{k}^{\frac{p}{p}+\frac{1 }{2}+\frac{p}{2r}}}\Big{(}\Big{(}\frac{\log(T)}{\Delta}\Big{)}^{\frac{2r}{2r+p }}+\frac{T^{\frac{p}{2r+p}}\log(T)}{\kappa\Delta}\Big{)}^{\frac{1}{2}}+\frac{T^ {\frac{p}{2r+p}}\log(T)}{\kappa^{2}}\Big{)}\Big{)}.\]Finally, for \(I_{4,3}\), we notice that, adding and subtracting \(\langle F_{(s_{k},\widehat{\eta}_{k}],h_{1}},F_{(s_{k},\eta_{k}],h_{2}}\rangle_{L_{2}}\), it is written as,

\[\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{\tau}}\langle F_{(s_{k}, \eta_{k}],h_{2}},F_{(s_{k},\eta_{k}],h_{2}}\rangle_{L_{2}}-\langle F_{(s_{k}, \eta_{k}],h_{1}},F_{(s_{k},\eta_{k}],h_{1}}\rangle_{L_{2}}\] \[= \sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{\tau}}\langle F_{(s_{k}, \eta_{k}],h_{2}},F_{(s_{k},\eta_{k}],h_{2}}\rangle_{L_{2}}-\langle F_{(s_{k}, \widehat{\eta}_{k}],h_{1}},F_{(s_{k},\widehat{\eta}_{k}],h_{1}}\rangle_{L_{2}}\] \[+ \langle F_{(s_{k},\widehat{\eta}_{k}],h_{1}},F_{(s_{k},\eta_{k}], h_{2}}\rangle_{L_{2}}-\langle F_{(s_{k},\widehat{\eta}_{k}],h_{1}},F_{(s_{k},\eta_{k}],h_{2}} \rangle_{L_{2}}\] \[= \sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{\tau}}\langle F_{(s_{k},\eta_{k}],h_{2}}-F_{(s_{k},\widehat{\eta}_{k}],h_{1}},F_{(s_{k},\eta_{k}],h_{ 2}}\rangle_{L_{2}}+\langle F_{(s_{k},\widehat{\eta}_{k}],h_{1}},F_{(s_{k},\eta_{ k}],h_{2}}-F_{(s_{k},\widehat{\eta}_{k}],h_{1}}\rangle_{L_{2}}\]

which, by Holder's inequality and Remark 2, is bounded by

\[\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{\tau}}||F_{(s_{k},\eta_{ k}],h_{2}}||_{L_{2}}||F_{(s_{k},\widehat{\eta}_{k}],h_{1}}-F_{(s_{k},\eta_{k}],h_{ 2}}||_{L_{2}}+||F_{(s_{k},\widehat{\eta}_{k}],h_{1}}||_{L_{2}}||F_{(s_{k}, \eta_{k}],h_{2}}-F_{(s_{k},\widehat{\eta}_{k}],h_{1}}||_{L_{2}}\] \[= \widetilde{\tau}O_{p}\Big{(}\frac{1}{\kappa_{k}^{\frac{p}{2}+ \frac{1}{2}+\frac{p}{2}}}\Big{(}\Big{(}\frac{\log(T)}{\Delta}\Big{)}^{\frac{2p }{2+p}}+\frac{T^{\frac{p}{2+p}}\log(T)}{\kappa\Delta}\Big{)}^{\frac{1}{2}} \Big{)}\]

Then, by above and Assumption 4, we conclude

\[I_{4}=o_{p}(\widetilde{\tau}\kappa_{k}^{\frac{p}{2}+2}).\] (31)

From (29), (30) and (31), we find that \(U_{1}\) has the following upper bound,

\[\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{\tau}}||F_{t,h_{2}}-f_{(s_{k},\eta_{ k}]}*\mathcal{K}_{h_{2}}||_{L_{2}}^{2}-\sum_{t=\eta_{k}+1}^{\eta_{k}+ \widetilde{\tau}}||F_{t,h_{1}}-F_{(s_{k},\widehat{\eta}_{k}],h_{1}}||_{L_{2}}^{ 2}=o_{p}(\widetilde{\tau}\kappa_{k}^{\frac{p}{2}+2}).\] (32)

Now, making an analogous analysis, we have that \(U_{2}\) is upper bounded by,

\[\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{\tau}}||F_{t,h_{1}}-F_{(\widehat{\eta }_{k},e_{k}],h_{1}}||_{L_{2}}^{2}-\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{ \tau}}||F_{t,h_{2}}-f_{(\eta_{k},e_{k}]}*\mathcal{K}_{h_{2}}||_{L_{2}}^{2}=o_{p}( \widetilde{\tau}\kappa_{k}^{\frac{p}{2}+2}).\] (33)

In fact, we observe that

\[\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{\tau}}||F_{t,h_{1}}-F_{( \widehat{\eta}_{k},e_{k}],h_{1}}||_{L_{2}}^{2}-\sum_{t=\eta_{k}+1}^{\eta_{k}+ \widetilde{\tau}}||F_{t,h_{2}}-f_{(\eta_{k},e_{k}]}*\mathcal{K}_{h_{2}}||_{L_{2}}^ {2}\] \[= \sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{\tau}}||F_{t,h_{2}}-F_{( \eta_{k},e_{k}],h_{2}}||_{L_{2}}^{2}-\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{ \tau}}||F_{t,h_{2}}-f_{(\eta_{k},e_{k}]}*\mathcal{K}_{h_{2}}||_{L_{2}}^{2}\] \[+ \sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{\tau}}||F_{t,h_{1}}-F_{( \widehat{\eta}_{k},e_{k}],h_{1}}||_{L_{2}}^{2}-\sum_{t=\eta_{k}+1}^{\eta_{k}+ \widetilde{\tau}}||F_{t,h_{2}}-F_{(\eta_{k},e_{k}],h_{2}}||_{L_{2}}^{2}\] \[= I_{5}+I_{6},\]

where,

\[I_{5} = \sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{\tau}}||F_{t,h_{2}}-F_{( \eta_{k},e_{k}],h_{2}}||_{L_{2}}^{2}-\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{ \tau}}||F_{t,h_{2}}-f_{(\eta_{k},e_{k}]}*\mathcal{K}_{h_{2}}||_{L_{2}}^{2},\ \text{and},\] \[I_{6} = \sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{\tau}}||F_{t,h_{1}}-F_{( \widehat{\eta}_{k},e_{k}],h_{1}}||_{L_{2}}^{2}-\sum_{t=\eta_{k}+1}^{\eta_{k}+ \widetilde{\tau}}||F_{t,h_{2}}-F_{(\eta_{k},e_{k}],h_{2}}||_{L_{2}}^{2}.\]

Then, \(I_{5}\) is bounded as follows

\[I_{5}=\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{\tau}}||f_{(\eta_{k},e_{k}]}* \mathcal{K}_{h_{2}}-F_{(\eta_{k},e_{k}],h_{2}}||_{L_{2}}^{2}+2\sum_{t=\eta_{k}+1}^{ \eta_{k}+\widetilde{\tau}}\langle f_{(\eta_{k},e_{k}]}*\mathcal{K}_{h_{2}}-F_{( \eta_{k},e_{k}],h_{2}},F_{t,h_{2}}-f_{(\eta_{k},e_{k}]}*\mathcal{K}_{h_{2}})_{L_{2}}\]where,

\[I_{5,1} =\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}||f_{(\eta_{k},e_{k})}* \mathcal{K}_{h_{2}}-F_{(\eta_{k},e_{k}),h_{2}}||_{L_{2}}^{2},\;\text{and},\] \[I_{5,2} =2\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}\langle f_{(\eta_{k },e_{k})}*\mathcal{K}_{h_{2}}-F_{(\eta_{k},e_{k}),h_{2}},F_{t,h_{2}}-f_{(\eta_{ k},e_{k})}*\mathcal{K}_{h_{2}}\rangle_{L_{2}}.\]

The term \(I_{5,1}=O_{p}\Big{(}\widetilde{r}\frac{1}{T}\frac{\log(T)}{\kappa^{\frac{p}{p} }}\Big{)}\), using Remark 1. Even more, by Assumption 4, we get

\[I_{5,1}=o_{p}(\widetilde{r}\kappa_{k}^{\frac{p}{p}+2}).\] (34)

For the term \(I_{5,2}\), by Cauchy Schwartz inequality,

\[\langle f_{(\eta_{k},e_{k})}*\mathcal{K}_{h_{2}}-F_{(\eta_{k},e _{k}),h_{2}},F_{t,h_{2}}-f_{(\eta_{k},e_{k})}*\mathcal{K}_{h_{2}}\rangle_{L_{2}}\] \[\leq||f_{(\eta_{k},e_{k})}*\mathcal{K}_{h_{2}}-F_{(\eta_{k},e_{k }),h_{2}}||_{L_{2}}||F_{t,h_{2}}-f_{(\eta_{k},e_{k})}*\mathcal{K}_{h_{2}}||_{L _{2}}\]

for any \(t\in(\eta_{k},\eta_{k}+\widetilde{r}]\). By Remark 1, we have that \(||f_{(\eta_{k},e_{k})}*\mathcal{K}_{h_{2}}-F_{(\eta_{k},e_{k}),h_{2}}||_{L_{2 }}=O_{p}\Big{(}\frac{1}{\sqrt{T}}\sqrt{\frac{\log(T)}{\kappa_{k}^{\frac{p}{p} }}}\Big{)}\). Therefore,

\[I_{5,2}\leq O_{p}\Big{(}\frac{1}{\sqrt{T}}\sqrt{\frac{\log(T)}{\kappa_{k}^{ \frac{p}{p}}}}\Big{)}\Big{(}\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}||F_{ t,h_{2}}-f_{[\eta_{k}+1,e_{k}]}*\mathcal{K}_{h_{2}}||_{L_{2}}\Big{)}\]

Now, similarly to the bound for \(I_{2},\) we consider the random variable

\[\bar{Y}_{i}=\frac{\langle F_{t,h_{2}}-f_{(\eta_{k},e_{k})}*\mathcal{K}_{\kappa },F_{t,h_{2}}-f_{(\eta_{k},e_{k})}*\mathcal{K}_{h_{2}}\rangle_{L_{2}}^{\frac{1 }{2}}-\mathbb{E}(||F_{t,h_{2}}-f_{[\eta_{k}+1,e_{k})}*\mathcal{K}_{h_{2}}||_{L _{2}})}{\mathbb{E}(||F_{t,h_{2}}-f_{\eta_{k+1}}*\mathcal{K}_{h_{2}}||_{L^{2}} )^{\frac{1}{3}}}.\]

In order to use Lemma 3, we observe

\[\mathbb{E}(|\bar{Y}_{i}|^{3})=\frac{\mathbb{E}(||F_{t,h_{2}}-f_{\eta_{k+1}}* \mathcal{K}_{h_{2}}||_{L^{2}}^{3})}{\mathbb{E}(||F_{t,h_{2}}-f_{\eta_{k+1}}* \mathcal{K}_{h_{2}}||_{L^{2}}^{3})}=1.\]

so that, by Lemma 3,

\[I_{5,2}\leq O_{p}\Big{(}\frac{1}{\sqrt{T}}\sqrt{\frac{\log(T)}{\kappa^{\frac{p }{p}}}}\Big{)}\Big{(}O_{p}(\sqrt{\widetilde{r}\kappa_{k}^{-\frac{p}{p}}}(\log (\widetilde{r}\kappa_{k}^{\frac{p}{p}+2})+1))+O_{p}(\kappa_{k}^{\frac{p}{p}}) \Big{)}=o_{p}(\widetilde{r}\kappa_{k}^{\frac{p}{p}+2}).\] (35)

To analyze \(I_{6},\) we observe that

\[I_{6} =\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}||F_{t,h_{2}}-F_{( \eta_{k},e_{k}),h_{2}}||_{L_{2}}^{2}-\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r }}||F_{t,h_{1}}-F_{(\widehat{\eta}_{k},e_{k}),h_{1}}||_{L_{2}}^{2}\] \[=\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}\Big{[}\langle F_{t,h_{2}},F_{t,h_{2}}\rangle_{L_{2}}-2\langle F_{t,h_{2}},F_{(\eta_{k},e_{k}),h_{ 2}}\rangle_{L_{2}}+\langle F_{(\eta_{k},e_{k}),h_{2}},F_{(\eta_{k},e_{k}],h_{2} }\rangle_{L_{2}}\Big{]}\] \[\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}\Big{[}-\langle F_{t,h_{1}},F_{t,h_{1}}\rangle_{L_{2}}+2\langle F_{t,h_{1}},F_{(\widehat{\eta}_{k},e _{k}),h_{1}}\rangle_{L_{2}}-\langle F_{(\widehat{\eta}_{k},e_{k}),h_{1}},F_{( \widehat{\eta}_{k},e_{k}),h_{1}}\rangle_{L_{2}}\Big{]}\] \[= I_{6,1}+I_{6,2}+I_{6,3},\]

where,

\[I_{6,1} =\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}\langle F_{t,h_{2}},F_{t,h_{2}}\rangle_{L_{2}}-\langle F_{t,h_{1}},F_{t,h_{1}}\rangle_{L_{2}},\] \[I_{6,2} =\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}2\langle F_{t,h_{1}},F_{(\widehat{\eta}_{k},e_{k}],h_{1}}\rangle_{L_{2}}-2\langle F_{t,h_{2}},F_{( \eta_{k},e_{k}],h_{2}}\rangle_{L_{2}}\] \[I_{6,3} =\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}\langle F_{(\eta_{k}, e_{k}],h_{2}},F_{(\eta_{k},e_{k}],h_{2}}\rangle_{L_{2}}-\langle F_{(\widehat{\eta}_{k},e_{k} ),h_{1}},F_{(\widehat{\eta}_{k},e_{k}],h_{1}}\rangle_{L_{2}}.\]Then we bound each of these terms. First, we rewrite \(I_{6,1}\), as

\[\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{\tau}}\langle F_{t,h_{2}},F _{t,h_{2}}\rangle_{L_{2}}-\langle F_{t,h_{1}},F_{t,h_{1}}\rangle_{L_{2}}\] \[= \sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{\tau}}\langle F_{t,h_{2} },F_{t,h_{2}}\rangle_{L_{2}}-\langle F_{t,h_{1}},F_{t,h_{1}}\rangle_{L_{2}}+ \langle F_{t,h_{1}},F_{t,h_{2}}\rangle_{L_{2}}-\langle F_{t,h_{1}},F_{t,h_{2}} \rangle_{L_{2}}\] \[= \sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{\tau}}\langle F_{t,h_{2 }}-F_{t,h_{1}},F_{t,h_{2}}\rangle_{L_{2}}+\langle F_{t,h_{1}},F_{t,h_{2}}-F_{t,h_{1}}\rangle_{L_{2}}\]

which, by Holder's inequality, is bounded by

\[\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{\tau}}||F_{t,h_{2}}||_ {L_{2}}||F_{t,h_{2}}-F_{t,h_{1}}||_{L_{2}}+||F_{t,h_{1}}||_{L_{2}}||F_{t,h_{2} }-F_{t,h_{1}}||_{L_{2}}\] \[= \widetilde{r}O_{p}\Big{(}\frac{1}{\kappa_{k}^{\frac{p}{2r}}+ \frac{1}{2}+\frac{p}{2r}}\Big{)}\Big{(}\frac{\log(T)}{\Delta}\Big{)}^{\frac{2r }{2r+p}}+\frac{T^{\frac{p}{2r+p}}\log(T)}{\kappa\Delta}\Big{)}^{\frac{1}{2}} \Big{)}\]

since \(||F_{t,\kappa}-F_{t,\widetilde{\tau}}||_{L_{2}}^{2}=O(\frac{|\kappa-\widetilde {\tau}|^{\frac{1}{2}}}{\kappa_{k}^{\frac{p}{2r}}+\frac{1}{2}}\Big{)}=O_{p}(- \frac{1}{\kappa_{k}^{\frac{p}{2r}}+\frac{1}{2}}\Big{(}\frac{\log(T)}{\Delta} \Big{)}^{\frac{2r}{2r+p}}+\frac{T^{\frac{p}{2r+p}}\log(T)}{\kappa\Delta} \Big{)}^{\frac{1}{2}}))\), for any \(t\), see

Remark 2 for more detail. Similarly, for \(I_{6,2}\) we have,

\[\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{\tau}}2\langle F_{t,h_{1 }},F_{(\widetilde{\eta}_{k},e_{k}],h_{1}}\rangle_{L_{2}}-2\langle F_{t,h_{2}}, F_{(\eta_{k},e_{k}],h_{2}}\rangle_{L_{2}}\] \[= \sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{\tau}}2\langle F_{t,h_{1 }},F_{(\widetilde{\eta}_{k},e_{k}],h_{1}}\rangle_{L_{2}}-2\langle F_{t,h_{2}}, F_{(\eta_{k},e_{k}],h_{2}}\rangle_{L_{2}}+2\langle F_{t,h_{1}},F_{(\eta_{k},e_{k}],h_{2}} \rangle_{L_{2}}-2\langle F_{t,h_{1}},F_{(\eta_{k},e_{k}],h_{2}}\rangle_{L_{2}}\] \[= \sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{\tau}}2\langle F_{t,h_{ 1}}-F_{t,h_{2}},F_{(\eta_{k},e_{k}],h_{2}}\rangle_{L_{2}}+2\langle F_{t,h_{1}},F_{(\eta_{k},e_{k}],h_{2}}-F_{(\widetilde{\eta}_{k},e_{k}],h_{1}}\rangle_{L_{2}}\]

and by Holder's inequality and Remark 2, it is bounded by

\[\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{\tau}}||F_{t,h_{1}}-F_{t,h_{2}}||_{L_{2}}||F_{(\eta_{k},e_{k}],h_{2}}||_{L_{2}}+||F_{t,h_{1}}||_{L_{2}} ||F_{(\eta_{k},e_{k}],h_{2}}-F_{(\widetilde{\eta}_{k},e_{k}],h_{1}}||_{L_{2}}\] \[= \widetilde{r}O_{p}\Big{(}\frac{1}{\kappa_{k}^{\frac{p}{2r}}+ \frac{1}{2}+\frac{p}{2r}}\Big{(}\Big{(}\frac{\log(T)}{\Delta}\Big{)}^{\frac{2r }{2r+p}}+\frac{T^{\frac{p}{2r+p}}\log(T)}{\kappa\Delta}\Big{)}^{\frac{1}{2}} \Big{)}\Big{)}.\]

Now for \(I_{6,3}\), we write it as

\[\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{\tau}}\langle F_{(\eta_{k},e_{k}],h_{2}},F_{(\eta_{k},e_{k}],h_{2}}\rangle_{L_{2}}-\langle F_{(\widetilde{\eta}_{k},e_{k}],h_{1}},F_{(\widetilde{\eta}_{k},e_{k}],h_{1}}\rangle_{L_{2}}\] \[= \sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{\tau}}\langle F_{(\eta_{k},e_{k}],h_{2}},F_{(\eta_{k},e_{k}],h_{2}}\rangle_{L_{2}}-\langle F_{(\widetilde{ \eta}_{k},e_{k}],h_{1}},F_{(\widetilde{\eta}_{k},e_{k}],h_{1}}\rangle_{L_{2}}+ \langle F_{(\widetilde{\eta}_{k},e_{k}],h_{1}},F_{(\eta_{k},e_{k}],h_{2}}\rangle_{L_{2}}- \langle F_{(\widetilde{\eta}_{k},e_{k}],h_{1}},F_{(\eta_{k},e_{k}],h_{2}}\rangle_{L_{2}}\] \[= \sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{\tau}}\langle F_{(\eta_{k},e_{k}],h_{2}}-F_{(\widetilde{\eta}_{k},e_{k}],h_{1}},F_{(s_{k},\eta_{k}],h_{2}} \rangle_{L_{2}}+\langle F_{(\widetilde{\eta}_{k},e_{k}],h_{1}},F_{(\eta_{k},e_{k} ],h_{2}}-F_{(\widetilde{\eta}_{k},e_{k}],h_{1}})_{L_{2}}\]

which, by Holder's inequality and Remark 2, is bounded by

\[\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{\tau}}||F_{(\eta_{k},e_{k}],h_{2}}||_{L_{2}}||F_{(\eta_{k},e_{k}],h_{2}}-F_{(\widetilde{\eta}_{k},e_{k}],h_{1}}|| _{L_{2}}+||F_{(\widetilde{\eta}_{k},e_{k}],h_{1}}||_{L_{2}}||F_{(\eta_{k},e_{k}],h_{2}}-F_{(\widetilde{\eta}_{k},e_{k}],h_{1}}||_{L_{2}}\] \[= \widetilde{r}O_{p}\Big{(}\frac{1}{\kappa_{k}^{\frac{p}{2r}}+ \frac{1}{2}+\frac{p}{2r}}\Big{(}\Big{(}\frac{\log(T)}{\Delta}\Big{)}^{\frac{2r }{2r+p}}+\frac{T^{\frac{p}{2r+p}}\log(T)}{\kappa\Delta}\Big{)}^{\frac{1}{2}} \Big{)}\Big{)}\]By above and Assumption 4, we conclude

\[I_{6}=o_{p}(\widetilde{r}\kappa_{k}^{\frac{p}{p}+2}).\] (36)

From, (34), (35) and (36), we get that \(U_{2}\) is bounded by

\[\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}||F_{t,\widehat{\kappa}}-F_{( \widehat{\eta}_{k},e_{k}),\widehat{k}}||_{L_{2}}^{2}-\sum_{t=\eta_{k}+1}^{\eta _{k}+\widetilde{r}}||F_{t,\kappa}-f_{(\eta_{k},e_{k}]}*\mathcal{K}_{\kappa}|| _{L_{2}}^{2}=o_{p}(\widetilde{r}\kappa_{k}^{\frac{p}{p}+2})\]

Therefore, from (32) and (33)

\[\widehat{Q}_{k}(\eta_{k})-\widehat{Q}_{k}(\eta_{k}+\widetilde{r})-Q^{*}(\eta _{k})+Q^{*}(\eta_{k}+\widetilde{r})=o_{p}(\widetilde{r}\kappa_{k}^{\frac{p}{ p}+2})\] (37)

**Step 4: Combination of all the steps above.** Finally, combining (24), (27) and (37), uniformly for any \(\widetilde{r}\geq\frac{1}{\kappa_{k}^{\frac{p}{p}+2}}\) we have that

\[\frac{1}{2}\widetilde{r}\kappa_{k}^{2}-O_{p}\Big{(}\sqrt{\widetilde{r}}\kappa _{k}\kappa_{k}^{-\frac{p}{2r}}(\log(\widetilde{r}\kappa_{k}^{\frac{p}{p}+2})+ 1)\Big{)}-o_{p}(\widetilde{r}\kappa_{k}^{\frac{p}{p}+2})\leq o_{p}(\widetilde{r} \kappa_{k}^{\frac{p}{p}+2})\]

which implies,

\[\widetilde{r}\kappa_{k}^{\frac{p}{p}+2}=O_{p}(1)\] (38)

and complete the proofs of \(\mathbf{a.1}\) and \(\mathbf{b.1}\).

**Limiting distributions.** For any \(k\in\{1,\ldots,K\}\), due to the uniform tightness of \(\widetilde{r}\kappa_{k}^{\frac{p}{p}+2}\), (24) and (37), as \(T\to\infty\)

\[Q^{*}(\eta)=\sum_{t=s_{k}+1}^{\eta}||F_{t,h_{2}}-f_{(s_{k},\eta_{k}]}*\mathcal{ K}_{h_{2}}||_{L_{2}}^{2}+\sum_{t=\eta+1}^{e_{k}}||F_{t,h_{2}}-f_{(\eta_{k},e_{k}] }*\mathcal{K}_{h_{2}}||_{L_{2}}^{2},\]

satisfies

\[\Big{|}\widehat{Q}\Big{(}\eta_{k}+\widetilde{r}\Big{)}-\widehat{Q}\Big{(} \eta_{k}\Big{)}-\Big{(}Q^{*}\Big{(}\eta_{k}+\widetilde{r}\Big{)}-Q^{*}\Big{(} \eta_{k}\Big{)}\Big{)}\Big{|}\overset{p}{\to}0.\]

Therefore, it is sufficient to find the limiting distributions of \(Q^{*}\Big{(}\eta_{k}+\widetilde{r}\Big{)}-Q^{*}\Big{(}\eta_{k}\Big{)}\) when \(T\to\infty\).

**Non-vanishing regime.** Observe that for \(\widetilde{r}>0\), we have that when \(T\to\infty\),

\[Q^{*}(\eta_{k}+\widetilde{r})-Q^{*}(\eta_{k}) =\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}||F_{t,h_{2}}-f_{(s_ {k},\eta_{k}]}*\mathcal{K}_{h_{2}}||_{L_{2}}^{2}-\sum_{t=\eta_{k}+1}^{\eta_{k}+ \widetilde{r}}||F_{t,h_{2}}-f_{(\eta_{k},e_{k}]}*\mathcal{K}_{h_{2}}||_{L_{2}}^ {2}\] \[=\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}||f_{(s_{k},\eta_{k} ]}*\mathcal{K}_{h_{2}}-f_{(\eta_{k},e_{k}]}*\mathcal{K}_{h_{2}}||_{L_{2}}^{2}\] \[\quad-2\sum_{t=\eta_{k}+1}^{\eta_{k}+\widetilde{r}}\langle f_{(s_ {k},\eta_{k}]}*\mathcal{K}_{h_{2}}-f_{(\eta_{k},e_{k}]}*\mathcal{K}_{h_{2}},F_{t, h_{2}}-f_{(\eta_{k},e_{k}]}*\mathcal{K}_{h_{2}})_{L_{2}}\] \[\quad\underline{\mathcal{D}}\,\,\sum_{t=1}^{\widetilde{r}}2\Big{\langle} F_{h_{2},\eta_{k}+t}-f_{\eta_{k}+t}*\mathcal{K}_{h_{2}},(f_{\eta_{k}+1}-f_{\eta_{k}})* \mathcal{K}_{h_{2}}\Big{\rangle}_{L_{2}}+\widetilde{r}||(f_{\eta_{k+1}}-f_{ \eta_{k}})*\mathcal{K}_{h_{2}}||_{L_{2}}^{2}.\]

When \(\widetilde{r}<0\) and \(T\to\infty\), we have that

\[Q^{*}(\eta_{k}+\widetilde{r})-Q^{*}(\eta_{k}) =\sum_{t=\eta_{k}+\widetilde{r}}^{\eta_{k}-1}||F_{t,h_{2}}-f_{(s_ {k},\eta_{k}]}*\mathcal{K}_{h_{2}}||_{L_{2}}^{2}-\sum_{t=\eta_{k}+\widetilde{r}}^ {\eta_{k}-1}||F_{t,h_{2}}-f_{(\eta_{k},e_{k}]}*\mathcal{K}_{h_{2}}||_{L_{2}}^{2}\] \[=\sum_{t=\eta_{k}+\widetilde{r}}^{\eta_{k}-1}||f_{(s_{k},\eta_{k} ]}*\mathcal{K}_{h_{2}}-f_{(\eta_{k},e_{k}]}*\mathcal{K}_{h_{2}}||_{L_{2}}^{2}\] \[\quad-2\sum_{t=\eta_{k}+\widetilde{r}}^{\eta_{k}-1}\langle f_{(s_ {k},\eta_{k}]}*\mathcal{K}_{h_{2}}-f_{(\eta_{k},e_{k}]}*\mathcal{K}_{h_{2}},F_{t, h_{2}}-f_{(\eta_{k},e_{k}]}*\mathcal{K}_{h_{2}})_{L_{2}}\] \[\quad\underline{\mathcal{D}}\,\,\sum_{t=\widetilde{r}+1}^{0}2 \Big{\langle}F_{h_{2},\eta_{k}+t}-f_{\eta_{k}+t}*\mathcal{K}_{h_{2}},(f_{\eta_{k }}-f_{\eta_{k+1}})*\mathcal{K}_{h_{2}}\Big{\rangle}_{L_{2}}+\widetilde{r}||(f_{ \eta_{k+1}}-f_{\eta_{k}})*\mathcal{K}_{h_{2}}||_{L_{2}}^{2}.\]Therefore, using Slutsky's theorem and the Argmax (or Argmin) continuous mapping theorem (see 3.2.2 Theorem van der Vaart and Wellner, 1996) we conclude

\[(\widetilde{\eta}_{k}-\eta_{k})\kappa_{k}^{\frac{p}{r}+2}\stackrel{{ \mathcal{D}}}{{\rightarrow}}\operatorname*{arg\,min}_{\widetilde{r}\in \mathbb{Z}}P_{k}(\widetilde{r})\] (39)

**Vanishing regime.** Vanishing regime. Let \(m=\kappa_{k}^{-2-\frac{p}{r}}\), and we have that \(m\rightarrow\infty\) as \(T\rightarrow\infty\). Observe that for \(\widetilde{r}>0\), we have that

\[Q_{k}^{*}\Big{(}\eta_{k}+\widetilde{r}m\Big{)}-Q_{k}^{*}\Big{(} \eta_{k}\Big{)} =\sum_{t=\eta_{k}}^{\eta_{k}+\widetilde{r}m-1}||f_{(s_{k},\eta_{ k}]}*\mathcal{K}_{h_{2}}-f_{(\eta_{k},e_{k}]}*\mathcal{K}_{h_{2}}||_{L_{2}}^{2}\] \[-2\sum_{t=\eta_{k}}^{\eta_{k}+\widetilde{r}m-1}\langle f_{(s_{k},\eta_{k}]}*\mathcal{K}_{h_{2}}-f_{(\eta_{k},e_{k}]}*\mathcal{K}_{h_{2}},F_{t,h_{2}}-f_{(\eta_{k},e_{k}]}*\mathcal{K}_{h_{2}}\rangle_{L_{2}}\]

Following the Central Limit Theorem for \(\alpha-\)mixing, see Lemma 4, we get

\[\frac{1}{\sqrt{m}}\sum_{t=\eta_{k}}^{\eta_{k}+rm-1}\frac{\langle f_{(s_{k}, \eta_{k}]}*\mathcal{K}_{h_{2}}-f_{(\eta_{k},e_{k}]}*\mathcal{K}_{h_{2}},F_{t,h_ {2}}-f_{(\eta_{k},e_{k}]}*\mathcal{K}_{h_{2}})_{L_{2}}}{\kappa_{k}^{\frac{p}{r }+1}}\stackrel{{\mathcal{D}}}{{\rightarrow}}\kappa_{k}^{-\frac{p }{r}}\widetilde{\sigma}_{\infty}(k)\mathbb{B}(\widetilde{r}),\]

where \(\mathbb{B}(\widetilde{r})\) is a standard Brownian motion and \(\widetilde{\sigma}(k)\) is the long-run variance given in (8). Therefore, it holds that when \(T\rightarrow\infty\)

\[Q_{k}^{*}\Big{(}\eta_{k}+\widetilde{r}m\Big{)}-Q_{k}^{*}\Big{(}\eta_{k} \Big{)}\stackrel{{\mathcal{D}}}{{\rightarrow}}\kappa_{k}^{- \frac{p}{r}}\widetilde{\sigma}_{\infty}(k)\mathbb{B}_{1}(r)+\widetilde{r} \kappa_{k}^{-\frac{p}{r}-2}||f_{(s_{k},\eta_{k}]}*\mathcal{K}_{h_{2}}-f_{(\eta _{k},e_{k}]}*\mathcal{K}_{h_{2}}||_{L_{2}}^{2}.\]

Similarly, for \(\widetilde{r}<0\), we have that when \(n\rightarrow\infty\)

\[Q_{k}^{*}\Big{(}\eta_{k}+rm\Big{)}-Q_{k}^{*}\Big{(}\eta_{k}\Big{)}\stackrel{{ \mathcal{D}}}{{\rightarrow}}\kappa_{k}^{-\frac{p}{r}}\widetilde{\sigma}_{ \infty}(k)\mathbb{B}_{1}(-\widetilde{r})-\widetilde{r}\kappa_{k}^{-\frac{p}{r }-2}||f_{(s_{k},\eta_{k}]}*\mathcal{K}_{h_{2}}-f_{(\eta_{k},e_{k}]}*\mathcal{K} _{h_{2}}||_{L_{2}}^{2}.\]

Then, using Slutsky's theorem and the Argmax (or Argmin) continuous mapping theorem (see 3.2.2 Theorem in van der Vaart & Wellner (1996)), and the fact that, \(\mathbb{E}(||f_{(s_{k},\eta_{k}]}*\mathcal{K}_{h_{2}}-f_{(\eta_{k},e_{k}]}* \mathcal{K}_{h_{2}}||_{L_{2}}^{2})=O(\kappa_{k}^{2})\), we conclude that

\[\kappa_{k}^{2+\frac{p}{r}}\Big{(}\widetilde{\eta}_{k}-\eta_{k}\Big{)} \stackrel{{\mathcal{D}}}{{\longrightarrow}}\operatorname*{arg\, min}_{r\in\mathbb{Z}}\widetilde{\sigma}_{\infty}(k)B(\widetilde{r})+| \widetilde{r}|,\]

which completes the proof of \(\mathbf{b.2}\).

Proof of Theorem 3

In this section, we present the proof of theorem Theorem 3.

Proof of Theorem 3.: First, letting \(h_{2}=c_{\kappa}\kappa_{k}^{\frac{1}{k}}\) and \(R=O(\frac{T^{\frac{2r}{2r+p}}}{\kappa_{k}^{\frac{2r}{p}+\frac{1}{2}}})\), we consider

\[\hat{\sigma}_{\infty}^{2}(k)=\frac{1}{R}\sum_{r=1}^{R}\Big{(}\frac{1}{\sqrt{S}} \sum_{i\in\mathcal{S}_{r}}\breve{Y}_{i}\Big{)}^{2},\;\text{where},\;\breve{Y} _{i}=\kappa_{k}^{\frac{p}{2r}-1}\Big{\langle}F_{h_{2},i}-f_{i}*\mathcal{K}_{h_ {2}},(f_{\eta_{k}}-f_{\eta_{k+1}})*\mathcal{K}_{h_{2}}\Big{\rangle}_{L_{2}}.\] (40)

We will show that

1. \(\Big{|}\tilde{\sigma}_{\infty}^{2}(k)-\tilde{\sigma}_{\infty}^{2}(k)\Big{|} \stackrel{{ P}}{{\longrightarrow}}0,\quad T\rightarrow\infty\), and
2. \(\Big{|}\tilde{\sigma}_{\infty}^{2}(k)-\tilde{\sigma}_{\infty}^{2}(k)\Big{|} \stackrel{{ P}}{{\longrightarrow}}0,\quad T\rightarrow\infty\)

in order to conclude the result. For (i), we use \(a^{2}-b^{2}=(a+b)(a-b)\), to write,

\[\Big{|}\tilde{\sigma}_{\infty}^{2}(k)-\tilde{\sigma}_{\infty}^{2} (k)\Big{|}= \Big{|}\frac{1}{R}\sum_{r=1}^{R}\Big{(}\frac{1}{\sqrt{S}}\sum_{i \in\mathcal{S}_{r}}\breve{Y}_{i}\Big{)}^{2}-\frac{1}{R}\sum_{r=1}^{R}\Big{(} \frac{1}{\sqrt{S}}\sum_{i\in\mathcal{S}_{r}}Y_{i}\Big{)}^{2}\Big{|}\] \[= \Big{|}\frac{1}{R}\sum_{r=1}^{R}\Big{(}\frac{1}{\sqrt{S}}\sum_{i \in\mathcal{S}_{r}}\breve{Y}_{i}-Y_{i}\Big{)}\Big{(}\frac{1}{\sqrt{S}}\sum_{i \in\mathcal{S}_{r}}\breve{Y}_{i}+Y_{i}\Big{)}\Big{|}\] \[= \Big{|}\frac{1}{R}\sum_{r=1}^{R}I_{1}I_{2}\Big{|}\]

Then, we bound each of the terms \(I_{1}\) and \(I_{2}\). For \(I_{1}\), we observe that,

\[I_{1}=\Big{|}\frac{1}{\sqrt{S}}\sum_{i\in\mathcal{S}_{r}}\breve{Y}_{i}-Y_{i} \Big{|}\leq\frac{1}{\sqrt{S}}\sum_{i\in\mathcal{S}_{r}}\Big{|}\breve{Y}_{i}-Y_ {i}\Big{|}.\]

Then, adding and subtracting, and

\[\tilde{\kappa}_{k}^{\frac{p}{2r}-1}\Big{\langle}F_{h_{2},i}-f_{i}*\mathcal{K}_{ h_{2}}-F_{h_{1},i}+f_{i}*\mathcal{K}_{h_{1}},(f_{\tilde{\eta}_{k}}-f_{\tilde{\eta}_{k +1}})*\mathcal{K}_{h_{1}}\Big{\rangle}_{L_{2}},\]

we get that,

\[\Big{|}\breve{Y}_{i}-Y_{i}\Big{|}\] \[= \Big{|}\tilde{\kappa}_{k}^{\frac{p}{2r}-1}\Big{\langle}F_{h_{2},i} -f_{i}*\mathcal{K}_{h_{2}},(f_{\eta_{k}}-f_{\eta_{k+1}})*\mathcal{K}_{h_{2}} \Big{\rangle}_{L_{2}}-\tilde{\kappa}_{k}^{\frac{p}{2r}-1}\Big{\langle}F_{h_{1}, i}-f_{i}*\mathcal{K}_{h_{1}},(f_{\tilde{\eta}_{k}}-f_{\tilde{\eta}_{k+1}})* \mathcal{K}_{h_{1}}\Big{\rangle}_{L_{2}}\Big{|}\] \[= \Big{|}\tilde{\kappa}_{k}^{\frac{p}{2r}-1}\Big{\langle}F_{h_{2},i} -f_{i}*\mathcal{K}_{h_{2}},(f_{\eta_{k}}-f_{\eta_{k+1}})*\mathcal{K}_{h_{2}} \Big{\rangle}_{L_{2}}-\tilde{\kappa}_{k}^{\frac{p}{2r}-1}\Big{\langle}F_{h_{1}, i}-f_{i}*\mathcal{K}_{h_{1}},(f_{\eta_{k}}-f_{\eta_{k+1}})*\mathcal{K}_{h_{2}} \Big{\rangle}_{L_{2}}\] \[+ \tilde{\kappa}_{k}^{\frac{p}{2r}-1}\Big{\langle}F_{h_{2},i}-f_{i}* \mathcal{K}_{h_{2}}-F_{h_{1},i}+f_{i}*\mathcal{K}_{h_{1}},(f_{\tilde{\eta}_{k}}- f_{\tilde{\eta}_{k+1}})*\mathcal{K}_{h_{1}}\Big{\rangle}_{L_{2}}\]which can be written as,

\[\Big{|}\Big{\langle}\kappa_{k}^{\frac{p}{2r}-1}(F_{h_{2,i}}-f_{i}* \mathcal{K}_{h_{2}})-\widehat{\kappa}_{k}^{\frac{p}{2r}-1}(F_{h_{1,i}}-f_{i}* \mathcal{K}_{h_{1}}),(f_{\eta_{k}}-f_{\eta_{k+1}})*\mathcal{K}_{h_{2}}-(f_{ \widehat{\eta}_{k}}-f_{\widehat{\eta}_{k+1}})*\mathcal{K}_{h_{1}}\Big{\rangle} _{L_{2}}\] \[+\Big{\langle}\widehat{\kappa}_{k}^{\frac{p}{2r}-1}(F_{h_{1,i}}-f_ {i}*\mathcal{K}_{h_{1}})-\kappa_{k}^{\frac{p}{2r}-1}(F_{h_{2,i}}-f_{i}*\mathcal{ K}_{h_{2}}),(f_{\widehat{\eta}_{k}}-f_{\widehat{\eta}_{k+1}})*\mathcal{K}_{h_{1}}-( f_{\eta_{k}}-f_{\eta_{k+1}})*\mathcal{K}_{h_{2}}\Big{\rangle}_{L_{2}}\] \[+\Big{\langle}\kappa_{k}^{\frac{p}{2r}-1}(F_{h_{2,i}}-f_{i}* \mathcal{K}_{h_{2}}),(f_{\eta_{k}}-f_{\eta_{k+1}})*\mathcal{K}_{h_{2}}-(f_{ \widehat{\eta}_{k}}-f_{\widehat{\eta}_{k+1}})*\mathcal{K}_{h_{1}}\Big{\rangle} _{L_{2}}\] \[+\Big{\langle}\widehat{\kappa}_{k}^{\frac{p}{2r}-1}(F_{h_{1,i}}-f_ {i}*\mathcal{K}_{h_{1}})-\kappa_{k}^{\frac{p}{2r}-1}(F_{h_{2,i}}-f_{i}* \mathcal{K}_{h_{2}}),(f_{\widehat{\eta}_{k}}-f_{\widehat{\eta}_{k+1}})* \mathcal{K}_{h_{1}}\Big{\rangle}_{L_{2}}\Big{|}.\]

Now, we bound the expression above. For this purpose, by triangle inequality, it is enough to bound each of the terms above. Then, we use Holder's inequality. First,

\[\Big{|}\Big{\langle}\kappa_{k}^{\frac{p}{2r}-1}(F_{h_{2,i}}-f_{i}* \mathcal{K}_{h_{2}})-\widehat{\kappa}_{k}^{\frac{p}{2r}-1}(F_{h_{1,i}}-f_{i}* \mathcal{K}_{h_{1}}),(f_{\eta_{k}}-f_{\eta_{k+1}})*\mathcal{K}_{h_{2}}-(f_{ \widehat{\eta}_{k}}-f_{\widehat{\eta}_{k+1}})*\mathcal{K}_{h_{1}}\Big{\rangle} _{L_{2}}\Big{|}\] \[\leq|\kappa_{k}^{\frac{p}{2r}-1}-\widehat{\kappa}_{k}^{\frac{p}{ 2r}-1}|||F_{h_{2,i}}-f_{i}*\mathcal{K}_{h_{2}}-F_{h_{1,i}}+f_{i}*\mathcal{K}_{ h_{1}}||_{L_{2}}||(f_{\eta_{k}}-f_{\eta_{k+1}})*\mathcal{K}_{h_{2}}-(f_{ \widehat{\eta}_{k}}-f_{\widehat{\eta}_{k+1}})*\mathcal{K}_{h_{1}}||_{L_{2}}.\]

Then, using (54), we have that \(|\kappa_{k}^{\frac{p}{2r}-1}-\widehat{\kappa}_{k}^{\frac{p}{2r}-1}|=O_{p} \Big{(}\frac{1}{\kappa_{k}^{\frac{p}{2r}-\frac{p}{2r}}}\Big{(}\Big{(}\frac{ \log(T)}{\Delta}\Big{)}^{\frac{2r}{2r+p}}+\frac{T^{\frac{p}{2r+p}}\log(T)}{ \kappa\Delta}\Big{)}^{\frac{1}{2}}\Big{)}\), and using Remark 2, it follows that

\[\|F_{h_{2,i}}-f_{i}*\mathcal{K}_{h_{2}}-F_{h_{1,i}}+f_{i}*\mathcal{ K}_{h_{1}}||_{L_{2}}\leq \|F_{h_{2,i}}-F_{h_{1,i}}||_{L_{2}}+||f_{i}*\mathcal{K}_{h_{1}}-f_{ i}*\mathcal{K}_{h_{2}}||_{L_{2}}\] \[= O_{p}\Big{(}\frac{1}{\kappa_{k}^{\frac{p}{2r}+\frac{1}{2}}}\Big{(} \Big{(}\frac{\log(T)}{\Delta}\Big{)}^{\frac{2r}{2r+p}}+\frac{T^{\frac{p}{2r+p}} \log(T)}{\kappa\Delta}\Big{)}^{\frac{1}{2}}\Big{)}\]

and,

\[||(f_{\eta_{k}}-f_{\eta_{k+1}})*\mathcal{K}_{h_{2}}-(f_{\widehat {\eta}_{k}}-f_{\widehat{\eta}_{k+1}})*\mathcal{K}_{h_{1}}||_{L_{2}}\] \[\leq ||f_{\eta_{k}}*\mathcal{K}_{h_{2}}-f_{\widehat{\eta}_{k}}*\mathcal{ K}_{h_{1}}||_{L_{2}}+||f_{\widehat{\eta}_{k+1}}*\mathcal{K}_{h_{1}}-f_{\eta_{k+1}}* \mathcal{K}_{h_{2}}||_{L_{2}}\] \[= O_{p}\Big{(}\frac{1}{\kappa_{k}^{\frac{p}{2r}+\frac{1}{2}}}\Big{(} \Big{(}\frac{\log(T)}{\Delta}\Big{)}^{\frac{2r}{2r+p}}+\frac{T^{\frac{p}{2r+p}} \log(T)}{\kappa\Delta}\Big{)}^{\frac{1}{2}}\Big{)}.\]

So that,

\[\Big{|}\Big{\langle}\kappa_{k}^{\frac{p}{2r}-1}(F_{h_{2,i}}-f_{i}* \mathcal{K}_{h_{2}})-\widehat{\kappa}_{k}^{\frac{p}{2r}-1}(F_{h_{1,i}}-f_{i}* \mathcal{K}_{h_{1}}),(f_{\eta_{k}}-f_{\eta_{k+1}})*\mathcal{K}_{h_{2}}-(f_{ \widehat{\eta}_{k}}-f_{\widehat{\eta}_{k+1}})*\mathcal{K}_{h_{1}}\Big{\rangle}_{L_{2}} \Big{|}\] \[= O_{p}\Big{(}\frac{1}{\kappa_{k}^{\frac{p}{2r}+\frac{1}{2}}}\Big{(} \Big{(}\frac{\log(T)}{\Delta}\Big{)}^{\frac{2r}{2r+p}}+\frac{T^{\frac{p}{2r+p}} \log(T)}{\kappa\Delta}\Big{)}^{\frac{1}{2}}\Big{)}O_{p}\Big{(}\frac{1}{\kappa_{ k}^{\frac{p}{2r}+\frac{1}{2}}}\Big{(}\Big{(}\frac{\log(T)}{\Delta} \Big{)}^{\frac{2r}{2r+p}}+\frac{T^{\frac{p}{2r+p}}\log(T)}{\kappa\Delta}\Big{)}^{ \frac{1}{2}}\Big{)}\] \[\cdot O_{p}\Big{(}\frac{1}{\kappa_{k}^{\frac{p}{2r}+\frac{1}{2}}} \Big{(}\Big{(}\frac{\log(T)}{\Delta}\Big{)}^{\frac{2r}{2r+p}}+\frac{T^{\frac{p}{2r+ p}}\log(T)}{\kappa\Delta}\Big{)}^{\frac{1}{2}}\Big{)}.\]

Now, in a similar way, we observe that

\[\Big{\langle}\kappa_{k}^{\frac{p}{2r}-1}(F_{h_{2,i}}-f_{i}*\mathcal{K }_{h_{2}}),(f_{\eta_{k}}-f_{\eta_{k+1}})*\mathcal{K}_{h_{2}}-(f_{\widehat{\eta}_ {k}}-f_{\widehat{\eta}_{k+1}})*\mathcal{K}_{h_{1}}\Big{\rangle}_{L_{2}}\] \[\leq ||\kappa_{k}^{\frac{p}{2r}-1}(F_{h_{2,i}}-f_{i}*\mathcal{K}_{h_{2}} )||_{L_{2}}||(f_{\eta_{k}}-f_{\eta_{k+1}})*\mathcal{K}_{h_{2}}-(f_{\widehat{\eta}_ {k}}-f_{\widehat{\eta}_{k+1}})*\mathcal{K}_{h_{1}}||_{L_{2}}\] \[= O_{p}(\kappa_{k}^{\frac{p}{2r}-1}\kappa_{k}^{-\frac{p}{2r}})O_{p} \Big{(}\frac{1}{\kappa_{k}^{\frac{p}{2r}+\frac{1}{2}}}\Big{(}\Big{(}\frac{ \log(T)}{\Delta}\Big{)}^{\frac{2r}{2r+p}}+\frac{T^{\frac{p}{2r+p}}\log(T)}{ \kappa\Delta}\Big{)}^{\frac{1}{2}}\Big{)}\]

where equality is followed by noticing that

\[||F_{h_{2,i}}-f_{i}*\mathcal{K}_{h_{2}}||_{L_{2}}\leq ||F_{h_{2,i}}||_{L_{2}}+||f_{i}*\mathcal{K}

[MISSING_PAGE_FAIL:35]

was previously bounded by,

\[O_{p}\Big{(}\frac{1}{\kappa_{k}^{\frac{2}{2r+p}}}\Big{(}\Big{(} \frac{\log(T)}{\Delta}\Big{)}^{\frac{2r}{2r+p}}+\frac{T^{\frac{p}{2r+p}}\log(T)}{ \kappa\Delta}\Big{)}\Big{)}O_{p}\Big{(}\frac{1}{\kappa_{k}^{\frac{2r}{2r+p}}}+ \frac{T^{\frac{p}{2r+p}}\log(T)}{\kappa\Delta}\Big{)}^{\frac{1}{2}}\Big{)} \kappa_{k}.\]

Therefore,

\[I_{2}\leq \frac{1}{\sqrt{S}}\sum_{i\in\mathcal{S}_{r}}\Big{|}\tilde{Y}_{i}+Y _{i}\Big{|}\] \[= \sqrt{S}\Big{(}O_{p}(1)+O_{p}\Big{(}\frac{1}{\kappa_{k}^{2-\frac{ p}{2r}}}\Big{(}\Big{(}\frac{\log(T)}{\Delta}\Big{)}^{\frac{2r}{2r+p}}+\frac{T^{ \frac{p}{2r+p}}\log(T)}{\kappa\Delta}\Big{)}\Big{)}O_{p}\Big{(}\frac{1}{\kappa _{k}^{\frac{2r}{2r+p}}}\Big{(}\Big{(}\frac{\log(T)}{\Delta}\Big{)}^{\frac{2r} {2r+p}}+\frac{T^{\frac{p}{2r+p}}\log(T)}{\kappa\Delta}\Big{)}^{\frac{1}{2}} \Big{)}\kappa_{k}\Big{)}.\]

In consequences,

\[\Big{|}\widehat{\sigma}_{\infty}^{2}(k)-\bar{\sigma}_{\infty}^{2} (k)\Big{|}=\Big{|}\frac{1}{R}\sum_{r=1}^{R}\Big{(}\frac{1}{\sqrt{S}}\sum_{i\in \mathcal{S}_{r}}\tilde{Y}_{i}\Big{)}^{2}-\frac{1}{R}\sum_{r=1}^{R}\Big{(}\frac {1}{\sqrt{S}}\sum_{i\in\mathcal{S}_{r}}Y_{i}\Big{)}^{2}\Big{|}\] \[= \Big{|}\frac{1}{R}\sum_{r=1}^{R}I_{1}I_{2}\Big{|}\] \[= S\Big{(}O_{p}\Big{(}\frac{1}{\kappa_{k}^{4-\frac{p}{r}}}\Big{(} \Big{(}\frac{\log(T)}{\Delta}\Big{)}^{\frac{2r}{2r+p}}+\frac{T^{\frac{p}{2r+p} }\log(T)}{\kappa\Delta}\Big{)}^{2}\Big{)}\] \[\cdot O_{p}\Big{(}\frac{1}{\kappa_{k}^{\frac{p}{2r+1}}}\Big{(} \Big{(}\frac{\log(T)}{\Delta}\Big{)}^{\frac{2r}{2r+p}}+\frac{T^{\frac{p}{2r+p} }\log(T)}{\kappa\Delta}\Big{)}\Big{)}O_{p}\Big{(}\frac{1}{\kappa_{k}^{\frac{2 r}{2r+p}}}\Big{(}\Big{(}\frac{\log(T)}{\Delta}\Big{)}^{\frac{2r}{2r+p}}+ \frac{T^{\frac{p}{2r+p}}\log(T)}{\kappa\Delta}\Big{)}^{\frac{1}{2}}\Big{)}\kappa _{k}\] \[+ O_{p}\Big{(}\frac{1}{\kappa_{k}^{2-\frac{p}{2r}}}\Big{(}\Big{(} \frac{\log(T)}{\Delta}\Big{)}^{\frac{2r}{2r+p}}+\frac{T^{\frac{p}{2r+p}}\log( T)}{\kappa\Delta}\Big{)}\Big{)}\] \[\cdot O_{p}\Big{(}\frac{1}{\kappa_{k}^{\frac{p}{2r+\frac{1}{2}}}} \Big{(}\Big{(}\frac{\log(T)}{\Delta}\Big{)}^{\frac{2r}{2r+p}}+\frac{T^{\frac{p} {2r+p}}\log(T)}{\kappa\Delta}\Big{)}^{\frac{1}{2}}\Big{)}O_{p}\Big{(}\frac{1} {\kappa_{k}^{\frac{2r}{2r+\frac{1}{2}}}}\Big{(}\Big{(}\frac{\log(T)}{\Delta} \Big{)}^{\frac{2r}{2r+p}}+\frac{T^{\frac{p}{2r+p}}\log(T)}{\kappa\Delta}\Big{)} ^{\frac{1}{2}}\Big{)}\] \[+ O_{p}(\kappa_{k}^{-1})O_{p}\Big{(}\frac{1}{\kappa_{k}^{\frac{2r}{2 r+\frac{1}{2}}}}\Big{(}\Big{(}\frac{\log(T)}{\Delta}\Big{)}^{\frac{2r}{2r+p}}+ \frac{T^{\frac{p}{2r+p}}\log(T)}{\kappa\Delta}\Big{)}^{\frac{1}{2}}\Big{)}\] \[\cdot O_{p}\Big{(}\frac{1}{\kappa_{k}^{2-\frac{p}{2r}}}\Big{(} \Big{(}\frac{\log(T)}{\Delta}\Big{)}^{\frac{2r}{2r+p}}+\frac{T^{\frac{p}{2r+p} }\log(T)}{\kappa\Delta}\Big{)}\Big{)}O_{p}\Big{(}\frac{1}{\kappa_{k}^{\frac{2r }{2r+\frac{1}{2}}}}\Big{(}\Big{(}\frac{\log(T)}{\Delta}\Big{)}^{\frac{2r}{2r+ p}}+\frac{T^{\frac{p}{2r+p}}\log(T)}{\kappa\Delta}\Big{)}^{\frac{1}{2}}\Big{)} \kappa_{k}\Big{)}.\]

In order to conclude (i), we notice that by Assumption 4 and that \(S=O(T^{\frac{-p}{2r+p}}\kappa_{k}^{\frac{p}{2r}+\frac{3}{2}})\), which implies,

\[\Big{|}\widehat{\sigma}_{\infty}^{2}(k)-\bar{\sigma}_{\infty}^{2} (k)\Big{|}= o_{p}(1).\]

Now, we are going to see that \(\Big{|}\bar{\sigma}_{\infty}^{2}(k)-\bar{\sigma}_{\infty}^{2}(k)\Big{|} \stackrel{{ P}}{{\longrightarrow}}0,\quad T\to\infty.\) To this end, we will show that the estimator is asymptotically unbiased, and its variance \(\to 0\) as \(T\to\infty\). First, we notice that, by Holder's inequality and Minkowsky's inequality,

\[|\tilde{Y}_{i}|= |\kappa_{k}^{\frac{p}{2r}-1}\Big{\langle}F_{h_{2},i}-f_{i}*\mathcal{ K}_{h_{2}},(f_{\eta_{k}}-f_{\eta_{k+1}})*\mathcal{K}_{h_{2}}\Big{\rangle}_{L_{2}}|\] \[\leq \kappa_{k}^{\frac{p}{2r}-1}||F_{h_{2},i}-f_{i}*\mathcal{K}_{h_{2}} ||_{L_{2}}||(f_{\eta_{k}}-f_{\eta_{k+1}})*\mathcal{K}_{h_{2}}||_{L_{2}}\] \[\leq \kappa_{k}^{\frac{p}{2r}-1}\kappa_{k}^{-\frac{p}{2r}}\kappa_{k}=1.\]Now, we analyze the Bias. We observe that,

\[\mathbb{E}(\tilde{\sigma}_{\infty}^{2}(k))=\frac{1}{R}\sum_{r=1}^{R} \mathbb{E}\Big{(}\Big{(}\frac{1}{\sqrt{S}}\sum_{i\in\mathcal{S}_{r}}\tilde{Y}_{i }\Big{)}^{2}\Big{)}=\frac{1}{S}\mathbb{E}\Big{(}\Big{(}\sum_{i\in\mathcal{S}_{r }}\tilde{Y}_{i}\Big{)}^{2}\Big{)}=\sum_{l=-S+1}^{S+1}\frac{S-l}{S}\mathbb{E}( \tilde{Y}_{i}\tilde{Y}_{i+l})\]

and,

\[\widetilde{\sigma}_{\infty}^{2}(k)=\sum_{l=-\infty}^{\infty} \mathbb{E}(\tilde{Y}_{i}\tilde{Y}_{i+l}).\]

so that, the bias has the following form,

\[\widetilde{\sigma}_{\infty}^{2}(k)-\mathbb{E}(\tilde{\sigma}_{ \infty}^{2}(k))=2\sum_{l=S}^{\infty}\mathbb{E}(\tilde{Y}_{i}\tilde{Y}_{i+l})+ 2\sum_{l=1}^{S}\frac{l}{S}\mathbb{E}(\tilde{Y}_{i}\tilde{Y}_{i+l}).\]

Now, we show that each of the above terms vanishes as \(T\to\infty\). We have that, by condition (2) and covariance inequality

\[2\sum_{l=S}^{\infty}\mathbb{E}(\tilde{Y}_{i}\tilde{Y}_{i+l})\leq 8\sum_{l=S}^{\infty}||\tilde{Y}_{i}||_{L_{\infty}}^{2}\alpha_{l} \leq 8\sum_{l=S}^{\infty}\alpha_{l}\to 0,\text{ as }T\to\infty\]

where \(\alpha_{l}\) is the mixing coefficient. Then,

\[2\sum_{l=1}^{S}\frac{l}{S}\mathbb{E}(\tilde{Y}_{i}\tilde{Y}_{i+l })\leq 8\sum_{l=1}^{S}\frac{l}{S}||\tilde{Y}_{i}||_{L_{\infty}}^{2}\alpha_{l} \leq\frac{C}{S}\to 0,\]

by condition (2), choice of \(S\) and Assumption 4. Therefore, we conclude that the Bias vanishes as \(T\to\infty\). To analyze the Variance, we observe that, if \(Y_{r}=\frac{1}{S}\Big{(}\sum_{i\in\mathcal{S}_{r}}\tilde{Y}_{i}\Big{)}^{2}\)

\[Var(\tilde{\sigma}_{\infty}^{2}(k))=\mathbb{E}((\tilde{\sigma} _{\infty}^{2}(k)-\mathbb{E}(\tilde{\sigma}_{\infty}^{2}(k)))^{2})\] \[= \frac{1}{R^{2}}\mathbb{E}\Big{(}\Big{(}\sum_{r=1}^{R}Y_{r}- \mathbb{E}(Y_{r})\Big{)}^{2}\Big{)}\] \[= \frac{1}{R}\sum_{l=-R+1}^{R-1}\frac{R-l}{R}cov(Y_{r},Y_{l+r})\] \[\leq \frac{8}{R}||Y_{r}||_{L_{\infty}}^{2}\sum_{l=0}^{\infty}\widetilde {\alpha}_{l}\leq\frac{8CS}{R}\to 0,\text{ as},\ T\to\infty.\]

where, \(\widetilde{\alpha}_{l}\) are the mixing coefficients of \(\{Y_{r}\}_{r\in\mathbb{Z}}\), which is bounded by the mixing coefficient \(\alpha_{l}\). From here, we conclude the result (ii).

Large probability events

In this section, we deal with all the large probability events that occurred in the proof of Theorem 1. Recall that, for any \((s,e]\subseteq(0,T]\),

\[\widetilde{f}_{t}^{s,e}(x)=\sqrt{\frac{e-t}{(e-s)(t-s)}}\sum_{l=s+1}^{t}f_{l}(x )-\sqrt{\frac{t-s}{(e-s)(e-t)}}\sum_{l=t+1}^{e}f_{l}(x),\;x\in\mathcal{X}.\]

**Proposition 1**.: _For any \(x\),_

\[\mathbb{P}\Big{(}\max_{\rho\leqslant k\leq T-\widetilde{r}}\Big{|}\frac{1}{ \sqrt{k}}\sum_{t=\widetilde{r}+1}^{\widetilde{r}+k}\Big{(}\mathcal{K}_{h}(x-X _{t})-\int\mathcal{K}_{h}(x-z)dF_{t}(z)\Big{)}\Big{|}\geq C\sqrt{\frac{\log T}{ h^{p}}}\Big{)}\leqslant T^{-p-3}.\]

Proof.: We have that the random variables \(\{Z_{t}=\mathcal{K}_{h}\Big{(}x-X_{t}\Big{)}\}_{t=1}^{T}\) satisfies

\[\sigma\Big{(}\mathcal{K}_{h}\Big{(}x-X_{t}\Big{)}\Big{)}\subset\sigma\Big{(} X_{t}\Big{)}\]

and,

\[\Big{|}\mathcal{K}_{h}\Big{(}x-X_{t}\Big{)}\Big{|}\leqslant\frac{1}{h^{p}}C_ {K}.\]

Moreover, let

\[V^{2}=\sup_{t>0}\Big{(}var(\mathcal{K}_{h}(x-X_{t})+2\sum_{j>t}|cov(Z_{t},Z_{j })|)\Big{)}.\]

We observe that,

\[var(\mathcal{K}_{h}(x-X_{t}))\leq E((\frac{1}{h^{p}}\mathcal{K}(\frac{x-X_{t}}{h}))^{2})\] \[\leq \int\frac{1}{h^{2p}}\mathcal{K}(\frac{x-z}{h})dF_{t}(z)\]

making \(\mu=\frac{x-z}{h}\), the last inequality is equal to

\[\int\frac{1}{h^{p}}\mathcal{K}(\frac{x-z}{h})dF_{t}(z) \leq\frac{1}{h^{p}}\int\mathcal{K}^{2}(u)dF_{t}(z)\] \[\leq\frac{1}{h^{p}}C_{k}C_{f}.\]

Then, by proposition 2.5 on Fan & Yao (2008), \(|cov(Z_{1},Z_{1}+t)|\leq C\alpha(t)\frac{1}{h^{2p}}C_{K}^{2}\). On the other hand,

\[cov(Z_{1},Z_{1}+t)= |E(Z_{1}Z_{t+1})-E(Z_{1})^{2}|\] \[\leq\int\int\mathcal{K}_{h}(x-z_{1})\mathcal{K}_{h}(x-z_{2})g_{t }(z_{1},z_{2})dz_{1}dz_{2}+E(Z_{1})^{2}\] \[\leq ||g_{t}||_{L_{\infty}}+E(Z_{1})^{2}.\]

Since by assumption Assumption 1**b** we have that \(||g_{t}||_{L_{\infty}}<\infty\), and

\[E(Z_{1})=E(\mathcal{K}_{h}(x-X_{1}))=\int\frac{1}{h^{p}}\mathcal{K}(\frac{x-z} {h})dF_{t}(z)=\int\mathcal{K}(u)f_{t}(x-hu)du=O(1),\]

we obtain that \(|cov(Z_{1},Z_{1+t})|\). Therefore, \(\sum_{t=1}^{\frac{1}{2}-1}|cov(Z_{1},Z_{t+1})|\leq C\frac{1}{h}\) and, using the mixing condition bound, inequality (2),

\[\sum_{t=\frac{1}{h^{p}}}^{T-1}|cov(Z_{1},Z_{1}+t)|\leq D\sum_{t=\frac{1}{h}}^{\infty}\frac{e^{-2Ct}}{h^{2p}}\] \[\leq D\frac{e^{-2C\frac{1}{h^{p}}}}{h^{2p}}\] \[\leq \widetilde{D}\frac{1}{h^{2p}}h^{p}=\widetilde{D}h^{p}\]where the last inequity is followed by the fact \(e^{-x}<\frac{1}{x}\) for \(x>-1\). In consequence,

\[V^{2}= \sup_{t>0}\Big{(}var(\mathcal{K}_{h}(x-X_{t})+2\sum_{j>t}|cov(Z_{t},Z_{j})|)\Big{)}\] \[= \widetilde{C}\frac{1}{h^{p}}+\widetilde{D}\frac{1}{h^{p}}= \widetilde{\widetilde{C}}\frac{1}{h^{p}}.\]

Then, by Bernstein inequality for mixing dependence, see Merlevede et al. (2009) for more details, letting

\[\lambda=C_{p}\Big{(}\sqrt{\frac{k\log(T)}{h^{p}}}+\sqrt{\frac{\log(T)}{h^{2p}} }+\sqrt{\frac{\log(T)\log^{2}(k)}{h^{p}}}\Big{)}\]

we get that,

\[\mathbb{P}\Big{(}\Big{|}\sum_{t=\vec{r}+1}^{\vec{r}+k}\Big{(} \mathcal{K}_{h}(x-X_{t})-\int\mathcal{K}_{h}(x-z)dF_{t}(z)\Big{)}\Big{|}> \lambda\Big{)}\leq T^{-p-3}.\]

in consequence,

\[\mathbb{P}\Big{(}\Big{|}\frac{1}{\sqrt{k}}\sum_{t=\vec{r}+1}^{ \vec{r}+k}\Big{(}\mathcal{K}_{h}(x-X_{t})-\int\mathcal{K}_{h}(x-z)dF_{t}(z) \Big{)}\Big{|}>\frac{\lambda}{\sqrt{k}}\Big{)}\leq T^{-p-3}.\]

Since \(kh^{p}\geq log(T)\) if \(k>\rho\), and \(\log^{2}(k)=O(k)\),

\[\frac{\lambda}{\sqrt{k}}=\frac{C_{p}\Big{(}\sqrt{\frac{k\log(T)}{ h^{p}}}+\sqrt{\frac{\log(T)}{h^{2p}}}+\sqrt{\frac{\log(T)\log^{2}(k)}{h^{p}}} \Big{)}}{\sqrt{k}}\] \[= C_{p}\Big{(}\sqrt{\frac{\log(T)}{h^{p}}}+\sqrt{\frac{\log(T)}{ kh^{2p}}}+\sqrt{\frac{\log(T)\log^{2}(k)}{kh^{p}}}\Big{)}\] \[\leq C_{p}\Big{(}\sqrt{\frac{\log(T)}{h^{p}}}+\sqrt{\frac{1}{h^{p}}}+ \sqrt{\frac{\log(T)}{h^{p}}}\Big{)}\] \[\leq C_{1}\sqrt{\frac{\log(T)}{h^{p}}}.\]

It follows that,

\[\mathbb{P}\Big{(}\Big{|}\frac{1}{\sqrt{k}}\sum_{t=\vec{r}+1}^{ \vec{r}+k}\Big{(}\mathcal{K}_{h}(x-X_{t})-\int\mathcal{K}_{h}(x-z)dF_{t}(z) \Big{)}\Big{|}>C_{1}\sqrt{\frac{\log(T)}{h^{p}}}\Big{)}\leq T^{-p-3}.\]

**Proposition 2**.: _Define the events_

\[\mathcal{A}_{1}=\Big{\{}\max_{t=s+\rho+1}^{e-\rho}\sup_{x\in\mathbb{R}^{p}} \bigg{|}\widetilde{F}_{t,h}^{s,e}(x)-\widetilde{f}_{t}^{s,e}(x)\bigg{|}\geq 2C \sqrt{\frac{\log T}{h^{p}}}+\frac{2C_{1}\sqrt{p}}{h^{p}}+2C_{2}\sqrt{T}h^{r} \Big{\}}\]

_and,_

\[\mathcal{A}_{2}=\Big{\{}\max_{\rho\leqslant k\leq T-\vec{r}}\sup_{x\in \mathbb{R}^{p}}\Big{|}\frac{1}{\sqrt{k}}\sum_{t=\vec{r}+1}^{\vec{r}+k}\Big{(} \mathcal{K}_{h}(x-X_{t})-f_{t}(x)\Big{)}\Big{|}\geq C\sqrt{\frac{\log T}{h^{p} }}+\frac{C_{1}\sqrt{p}}{h^{p}}+C_{2}\sqrt{T}h^{r}\Big{\}}.\]

_Then_

\[\mathbb{P}\Big{(}\mathcal{A}_{1}\Big{)} \leqslant 2R^{p}T^{-2}\] (43) \[\mathbb{P}\Big{(}\mathcal{A}_{2}\Big{)} \leqslant R^{p}T^{-2}\] (44)

_where \(R\) is a positive constant._

[MISSING_PAGE_EMPTY:40]

The term \(I_{1,2}\) is bounded as followed.

\[\max_{\rho\leqslant k\leqslant T-\widetilde{r}}\Big{|}\frac{1}{ \sqrt{k}}\sum_{t=\widetilde{r}+1}^{\widetilde{r}+k}\Big{(}\mathcal{K}_{h}(x-X_ {t})-\mathcal{K}_{h}(x_{i}-X_{t})\Big{)}\Big{|}\] \[\leq \max_{\rho\leqslant k\leqslant T-\widetilde{r}}\frac{1}{\sqrt{k}} \sum_{t=\widetilde{r}+1}^{\widetilde{r}+k}\Big{|}\mathcal{K}_{h}(x-X_{t})- \mathcal{K}_{h}(x_{i}-X_{t})\Big{|}\] \[\leq \max_{\rho\leqslant k\leqslant T-\widetilde{r}}\frac{1}{\sqrt{k}} \sum_{t=\widetilde{r}+1}^{\widetilde{r}+k}\frac{|x-x_{i}|}{h^{p+1}}\] \[\leq \max_{\rho\leqslant k\leqslant T-\widetilde{r}}\frac{1}{\sqrt{k}} \sum_{t=\widetilde{r}+1}^{\widetilde{r}+k}\frac{\sqrt{h^{p}}h\sqrt{p}}{\sqrt{ T}h^{p+1}}\leq\frac{\sqrt{p}}{\sqrt{h^{p}}}\]

For the term \(I_{1,3}\), since the random variables \(\{\mathcal{K}_{h}(x-X_{t})\}_{t=1}^{T}\) have bounded expected value for any \(x\in\mathbb{R}^{p}\)

\[\max_{\rho\leqslant k\leq T-\widetilde{r}}\Big{|}\frac{1}{\sqrt{ k}}\sum_{t=\widetilde{r}+1}^{\widetilde{r}+k}\Big{(}\int\mathcal{K}_{h}(x_{i}-z) dF_{t}(z)-\int\mathcal{K}_{h}(x-z)dF_{t}(z)\Big{)}\Big{|}\] \[\leq \max_{\rho\leqslant k\leq T-\widetilde{r}}\Big{|}\frac{1}{\sqrt{ k}}\sum_{t=\widetilde{r}+1}^{\widetilde{r}+k}\Big{(}\frac{\sqrt{h^{p}}h2C \sqrt{p}}{h^{p+1}\sqrt{T}}\Big{)}\Big{|}\leq\frac{2C\sqrt{p}}{\sqrt{h^{p}}}.\]

Thus,

\[\max_{\rho\leqslant k\leq T-\widetilde{r}}\sup_{x\in\mathbb{R}^{ p}}\Big{|}\frac{1}{\sqrt{k}}\sum_{t=\widetilde{r}+1}^{\widetilde{r}+k}\Big{(} \mathcal{K}_{h}(x-X_{t})-\int\mathcal{K}_{h}(x-z)dF_{t}(z)\Big{)}\Big{|}\] \[\leq I_{1,1}+C_{2}\frac{\sqrt{p}}{\sqrt{h^{p}}}\]

From here,

\[\mathbb{P}\Big{(}I_{1}>C_{1}\sqrt{\frac{\log T}{h^{p}}}+\frac{C_{ 2}\sqrt{p}}{\sqrt{h^{p}}}\Big{)}\leq \mathbb{P}\Big{(}I_{1,1}+I_{1,2}+I_{1,3}>C_{1}\sqrt{\frac{\log T}{h ^{p}}}+\frac{C_{2}\sqrt{p}}{\sqrt{h^{p}}}\Big{)}\] (47) \[\leq \mathbb{P}\Big{(}I_{1,1}\Big{)}\leq T^{-p-3}|A|=T^{-p-2}(R\sqrt{T }/\sqrt{h^{p}}h)^{p}\] (48) \[\leq T^{-p-3}(R\sqrt{T}\sqrt{T}T^{\frac{1}{p}})^{p}=R^{p}T^{-2}\] (49)

Finally, we analyze the term \(I_{2}\). By the adaptive assumption, the following is satisfied,

\[\max_{\rho\leqslant k\leqslant T-\widetilde{r}}\sup_{x\in \mathbb{R}^{p}}\Big{|}\frac{1}{\sqrt{k}}\sum_{t=\widetilde{r}+1}^{r+k}\Big{(} \int\mathcal{K}_{h}(x-z)dF_{z}(z)-f_{t}(x)\Big{)}\Big{|}\] \[\leq \max_{\rho\leqslant k\leqslant T-\widetilde{r}}\frac{1}{\sqrt{k}} \sum_{t=\widetilde{r}+1}^{r+k}\sup_{x\in\mathbb{R}^{p}}\Big{|}\int\mathcal{K} _{h}(x-z)dF_{z}(z)-f_{t}(x)\Big{|}\] \[\leq \max_{\rho\leqslant k\leqslant T-\widetilde{r}}\frac{1}{\sqrt{k}} \sum_{t=\widetilde{r}+1}^{r+k}C_{2}h^{r}\] \[\leq C_{2}\sqrt{T}h^{r}\]

We conclude the bound for event \(\mathcal{A}_{2}\). We conclude the bound for event \(\mathcal{A}_{2}\). Next, to derive the bound for event \(\mathcal{A}_{1}\), by definition of \(\widetilde{F}_{t,h}^{s,e}\) and \(\widetilde{f}_{t}^{s,e}\), we have that

\[\Big{|}\widetilde{F}_{t,h}^{s,e}(x)-\widetilde{f}_{t}^{s,e}(x)\Big{|} \leq\Big{|}\sqrt{\frac{e-t}{(e-s)(t-s)}}\sum_{l=s+1}^{t}(F_{l,h}(x )-f_{l,h}(x))\Big{|}\] \[+\Big{|}\sqrt{\frac{t-s}{(e-s)(e-t)}}\sum_{l=t+1}^{e}(F_{l,h}(x)- f_{l,h}(x))\Big{|}.\]Then, we observe that,

\[\sqrt{\frac{e-t}{(e-s)(t-s)}}\leq\sqrt{\frac{1}{t-s}}\text{ if }s\leq t,\text{ and } \sqrt{\frac{t-s}{(e-s)(e-t)}}\leq\sqrt{\frac{1}{e-t}}\text{ if }t\leq e.\]

Therefore,

\[X=\max_{t=s+\rho+1}^{e-\rho}\left|\widetilde{F}_{t,h}^{s,e}(x)- \widetilde{f}_{t}^{s,e}(x)\right|\leq \max_{t=s+\rho+1}^{e-\rho}\left|\sqrt{\frac{1}{t-s}}\sum_{l=s+1}^{t} \left(F_{l,h}(x)-\{f_{l,h}(x)\right)\right|\] \[+\max_{t=s+\rho+1}^{e-\rho}\left|\sqrt{\frac{1}{e-t}}\sum_{l=t+1}^ {e}\left(F_{l,h}(x)-f_{l,h}(x)\right)\right|=X_{1}+X_{2}.\]

Finally, letting \(\lambda=2C_{1}\sqrt{\frac{\log T}{h^{p}}}+\frac{2C_{2}\sqrt{p}}{\sqrt{h^{p}}}+ 2C_{2}\sqrt{T}h^{r},\) we get that

\[\mathbb{P}(X\geq\lambda)\leq \mathbb{P}(X_{1}+X_{2}\geq\frac{\lambda}{2}+\frac{\lambda}{2})\] \[\leq \mathbb{P}(X_{1}\geq\frac{\lambda}{2})+\mathbb{P}(X_{2}\geq\frac {\lambda}{2})\] \[\leq 2R^{p}T^{-2},\]

where the last inequality follows from above. This concludes the bound for \(\mathcal{A}_{1}\). 

**Remark 1**.: _On the events \((\mathcal{A}_{1})^{c}\) and, \((\mathcal{A}_{2})^{c}\), by Assumption 1, we have that_

\[\max_{t=s+\rho+1}^{e-\rho}||\widetilde{F}_{t,h}^{s,e}(x)-\widetilde {f}_{t}^{s,e}(x)||_{L_{2}}\leq \max_{t=s+\rho+1}^{e-\rho}\widetilde{C}_{\mathcal{X}}\sup_{x\in \mathbb{R}^{p}}\left|\widetilde{F}_{t,h}^{s,e}(x)-\widetilde{f}_{t}^{s,e}(x)\right|\] \[\leq 2\widetilde{C}_{\mathcal{X}}C\sqrt{\frac{\log T}{h^{p}}}+\frac{ 2\widetilde{C}_{\mathcal{X}}C_{1}\sqrt{p}}{h^{p}}+2\widetilde{C}_{\mathcal{X} }C_{2}\sqrt{T}h^{r}\]

_where \(\widetilde{C}_{\mathcal{X}}\) is the volume of the set \(\mathcal{X}\). Moreover, using inequality (47), we have that_

\[\max_{\rho\leq k\leq T-\widetilde{r}}\left|\left|\frac{1}{\sqrt{ k}}\sum_{t=\widetilde{r}+1}^{\widetilde{r}+k}\left(\mathcal{K}_{h}(\cdot-X_{t})- \int\mathcal{K}_{h}(\cdot-z)dF_{t}(z)\right)\right|\right|_{L_{2}}\] \[\leq C_{\mathcal{X}}\max_{\rho\leq k\leq T-\widetilde{r}}\sup_{x\in \mathbb{R}^{p}}\left|\frac{1}{\sqrt{k}}\sum_{t=\widetilde{r}+1}^{\widetilde{r}+ k}\left(\mathcal{K}_{h}(x-X_{t})-\int\mathcal{K}_{h}(x-z)dF_{t}(z)\right)\right|\] \[= O_{p}\Big{(}\sqrt{\frac{\log T}{h^{p}}}\Big{)}.\]\(\alpha\)-mixing condition

A process \((X_{t},t\in\mathbb{Z})\) is said to be \(\alpha\)-mixing if

\[\alpha_{k}=\sup_{t\in\mathbb{Z}}\alpha(\sigma(X_{s},s\leq t),\sigma(X_{s},s\geq t +k))\longrightarrow_{k\to\infty}0.\]

The strong mixing, or \(\alpha\)-mixing coefficient between two \(\sigma\)-fields \(\mathcal{A}\) and \(\mathcal{B}\) is defined as

\[\alpha(\mathcal{A},\mathcal{B})=\sup_{A\in\mathcal{A},B\in\mathcal{B}}| \mathbb{P}(A\cap B)-\mathbb{P}(A)\mathbb{P}(B)|.\]

Suppose \(X\) and \(Y\) are two random variables. Then for positive numbers \(p^{-1}+q^{-1}+r^{-1}=1\), it holds that

\[|\operatorname{Cov}(X,Y)|\leq 4\|X\|_{L_{p}}\|Y\|_{L_{q}}\{\alpha(\sigma(X), \sigma(Y))\}^{1/r}.\]

Let \(\left\{Z_{t}\right\}_{t=-\infty}^{\infty}\) be a stationary time series vectors. Denote the alpha mixing coefficients of \(k\) to be

\[\alpha(k)=\alpha\Big{(}\sigma\Big{\{}\ldots,Z_{t-1},Z_{t}\Big{\}},\sigma\Big{ }\Big{\{}Z_{t+k},Z_{t+k+1},\ldots\Big{\}}\Big{)}.\]

Note that the definition is independent of \(t\).

### Maximal Inequality

The unstationary version of the following lemma is in Lemma B.5. of Kirch (2006).

**Lemma 1**.: _Suppose \(\left\{y_{i}\right\}_{i=1}^{\infty}\) is a stationary alpha-mixing time series with mixing coefficient \(\alpha(k)\) and that \(\mathbb{E}\Big{(}y_{i}\Big{)}=0\). Suppose that there exists \(\delta,\Delta>0\) such that_

\[\mathbb{E}\Big{(}\Big{|}y_{i}\Big{|}^{2+\delta+\Delta}\Big{)}\leq D_{1}\]

_and_

\[\sum_{k=0}^{\infty}(k+1)^{\delta/2}\alpha(k)^{\Delta/(2+\delta+\Delta)}\leq D _{2}.\]

_Then_

\[\mathbb{E}\Big{(}\max_{k=1,\ldots,n}\Big{|}\sum_{i=1}^{k}y_{i}\Big{|}^{2+ \delta}\Big{)}\leq Dn^{(2+\delta)/2},\]

_where \(D\) only depends on \(\delta\) and the joint distribution of \(\left\{y_{i}\right\}_{i=1}^{\infty}\)._

Proof.: This is Lemma B.8. of Kirch (2006). 

**Lemma 2**.: _Suppose that there exists \(\delta,\Delta>0\) such that_

\[\mathbb{E}\Big{(}\Big{|}y_{i}\Big{|}^{2+\delta+\Delta}\Big{)}\leq D_{1}\]

_and_

\[\sum_{k=0}^{\infty}(k+1)^{\delta/2}\alpha(k)^{\Delta/(2+\delta+\Delta)}\leq D _{2}.\]

_Then it holds that for any \(d>0,0<\nu<1\) and \(x>0\),_

\[\mathbb{P}\Big{(}\max_{k\in[\nu d,d]}\frac{\Big{|}\sum_{i=1}^{k}y_{i}\Big{|}} {\sqrt{k}}\geq x\Big{)}\leq Cx^{-2-\delta},\]

_where \(C\) is some constant._Proof.: Let

\[S_{d}^{*}=\max_{k=1,\ldots,d}\Big{|}\sum_{i=1}^{k}y_{i}\Big{|}.\]

Then Lemma 1 implies that

\[\Big{\|}S_{d}^{*}\Big{\|}_{L_{2+\delta}}\leq C_{1}d^{1/2}\]

Therefore it holds that

\[\mathbb{P}\Big{(}\Big{|}\frac{S_{d}^{*}}{\sqrt{d}}\Big{|}\geq x\Big{)}= \mathbb{P}\Big{(}\Big{|}\frac{S_{d}^{*}}{\sqrt{d}}\Big{|}^{2+\delta}\geq x^{2+ \delta}\Big{)}\leq C_{1}x^{-2-\delta}.\]

Observe that

\[\frac{\Big{|}S_{d}^{*}\Big{|}}{\sqrt{d}}=\max_{k=1,\ldots,d}\frac{\Big{|}\sum_ {i=1}^{k}y_{i}\Big{|}}{\sqrt{d}}\geq\max_{k\in[\nu d,d]}\frac{\Big{|}\sum_{i=1 }^{k}y_{i}\Big{|}}{\sqrt{d}}\geq\max_{k\in[\nu d,d]}\frac{\Big{|}\sum_{i=1}^{k }y_{i}\Big{|}}{\sqrt{k/\nu}}\]

Therefore

\[\mathbb{P}\Big{(}\max_{k\in[\nu d,d]}\frac{\Big{|}\sum_{i=1}^{k}y_{i}\Big{|}} {\sqrt{k}}\geq x/\sqrt{\nu}\Big{)}\leq\mathbb{P}\Big{(}\Big{|}\frac{S_{d}^{*} }{\sqrt{d}}\Big{|}\geq x\Big{)}\leq C_{1}x^{-2-\delta},\]

which gives

\[\mathbb{P}\Big{(}\max_{k\in[\nu d,d]}\frac{\Big{|}\sum_{i=1}^{k}y_{i}\Big{|}} {\sqrt{k}}\geq x\Big{)}\leq C_{2}x^{-2-\delta}.\]

**Lemma 3**.: _Let \(\nu>0\) be given. Under the same assumptions as in Lemma 1, for any \(0<a<1\) it holds that_

\[\mathbb{P}\Big{(}\Big{|}\sum_{i=1}^{r}y_{i}\Big{|}\leq\frac{C}{a}\sqrt{r}\{ \log(r\nu)+1\}\text{ for all }r\geq 1/\nu\Big{)}\geq 1-a^{2},\]

_where \(C\) is some absolute constant._

Proof.: Let \(s\in\mathbb{Z}^{+}\)and \(\mathcal{T}_{s}=\Big{[}2^{s}/\nu,2^{s+1}/\nu\Big{]}\). By Lemma 3, for all \(x\geq 1\),

\[\mathbb{P}\Big{(}\sup_{r\in\mathcal{T}_{s}}\frac{\Big{|}\sum_{i=1}^{r}y_{i} \Big{|}}{\sqrt{r}}\geq x\Big{)}\leq C_{1}x^{-2-\delta}\leq C_{1}x^{-2}.\]

Therefore by a union bound, for any \(0<a<1\),

\[\mathbb{P}\Big{(}\exists s\in\mathbb{Z}^{+}:\sup_{r\in\mathcal{T}_{s}}\frac{ \Big{|}\sum_{i=1}^{r}y_{i}\Big{|}}{\sqrt{r}}\geq\frac{\sqrt{C_{1}}}{a}(s+1) \Big{)}\leq\sum_{s=0}^{\infty}\frac{a^{2}}{(s+1)^{2}}=a^{2}\pi^{2}/6.\]

For any \(r\in\Big{[}2^{s}/\nu,2^{s+1}/\nu\Big{]},s\leq\log(r\nu)/\log(2)\), and therefore

\[\mathbb{P}\Big{(}\exists s\in\mathbb{Z}^{+}:\sup_{r\in\mathcal{T}_{s}}\frac{ \Big{|}\sum_{i=1}^{r}y_{i}\Big{|}}{\sqrt{r}}\geq\frac{\sqrt{C_{1}}}{a}\Big{\{} \frac{\log(r\nu)}{\log(2)}+1\Big{\}}\Big{)}\leq a^{2}\pi^{2}/6.\]

Equation (2) directly gives

\[\mathbb{P}\Big{(}\sup_{r\in\mathcal{T}_{s}}\frac{\Big{|}\sum_{i=1}^{r}y_{i} \Big{|}}{\sqrt{r}}\geq\frac{C}{a}\{\log(r\nu)+1\}\Big{)}\leq a^{2}.\]

### Central Limit theorem

Below is the central limit theorem for \(\alpha\)-mixing random variable. We refer to Doukhan (1994) for more details.

**Lemma 4**.: _Let \(\left\{Z_{t}\right\}\) be a centred \(\alpha\)-mixing stationary time series. Suppose for the mixing coefficients and moments, for some \(\delta>0\) it holds_

\[\sum_{k=1}^{\infty}\alpha_{k}^{\delta/(2+\delta)}<\infty,\quad\mathbb{E}\Big{[} \Big{|}Z_{1}\Big{|}^{2+\delta}<\infty\Big{]}.\]

_Denote \(S_{n}=\sum_{t=1}^{n}Z_{t}\) and \(\sigma_{n}^{2}=\mathbb{E}\Big{[}\Big{|}S_{n}\Big{|}^{2}\Big{]}\). Then_

\[\frac{S_{\lfloor nt\rfloor}}{\sigma_{n}}\to W(t),\]

_where convergence is in Skorohod topology and \(W(t)\) is the standard Brownian motion on \([0,1]\)._

## Appendix I Additional Technical Results

**Lemma 5**.: _Let \(\mathcal{J}\) be defined as in Definition 2 and suppose Assumption 1_ **e** _holds. Then for each change point \(\eta_{k}\) there exists a seeded interval \(\mathcal{I}_{k}=(s_{k},e_{k}]\) such that_

**a.**\(\mathcal{I}_{k}\) _contains exactly one change point \(\eta_{k}\);_

**b.**\(\min\{\eta_{k}-s_{k},e_{k}-\eta_{k}\}\geq\frac{1}{16}\Delta\)_; and_

**c.**\(\max\{\eta_{k}-s_{k},e_{k}-\eta_{k}\}\leq\frac{9}{10}\Delta\)_;_

Proof.: These are the desired properties of seeded intervals by construction. The proof is the same as theorem 3 of Kovacs et al. (2020) and is provided here for completeness.

Let \(k\in\{1,...,\mathfrak{K}\}\), where \(\mathfrak{K}\) is from definition 2. By construction of seeded intervals, we have that in \(\mathcal{J}_{k}\), we can find an interval \((\lfloor(i-1)T2^{-k}\rfloor,\)\(\lceil(i-1)T2^{-k}+T2^{-k+1}\rceil]\), for some \(i\in 1,...,2^{k}-1,\) such that

\[\min\{\eta_{k}-\lfloor(i-1)T2^{-k}\rfloor,\lceil(i-1)T2^{-k}+T2^{-k+1} \rceil-\eta_{k}\}\geq\frac{l_{k}}{4}\] (50)

and

\[\max\{\eta_{k}-\lfloor(i-1)T2^{-k}\rfloor,\lceil(i-1)T2^{-k}+T2^{-k+1} \rceil-\eta_{k}\}\leq l_{k},\] (51)

where \(l_{k}=T2^{-k+1},\) is the size of each interval in \(\mathcal{J}_{k}\). By the choice of \(\mathfrak{K}\), there exist \(k\), such that \(l_{k}=\frac{9}{10}\Delta\), from where the claim is followed. 

**Lemma 6**.: _Let \(\{X_{i}\}_{i=1}^{T}\) be random grid points sampled from a common density function \(f_{t}:\mathbb{R}^{p}\rightarrow\mathbb{R}\), satisfying Assumption 1-_**a** _and -_**b**_. Under Assumption (2), the density estimator of the sampling distribution \(\mu\),_

\[\widehat{f}_{t}(x)=\frac{1}{T}\sum_{t=1}^{T}\mathcal{K}_{h}(x-X_{ i}),\quad x\in\mathbb{R}^{p},\]

_satisfies,_

\[\|\widehat{f}_{T}-f_{t}||_{L_{\infty}}=O_{p}\Big{(}\Big{(}\frac{ \log(T)}{T}\Big{)}^{\frac{2r}{2r+p}}\Big{)}.\] (52)

The verification of these bounds can be found in many places in the literature. See for example Yu (1993) and Tsybakov (2009).

**Remark 2**.: _Even more, by Assumption 1,_

\[||\widehat{f}_{T}-f_{t}||_{L_{2}}\leq C_{\mathcal{X}}||\widehat{ f}_{T}-f_{t}||_{L_{\infty}}=O\Big{(}\Big{(}\frac{\log(T)}{T}\Big{)}^{\frac{2r}{2r+p} }\Big{)}\] (53)

_with high probability. Therefore, given that_

\[\kappa=\frac{||\sqrt{\frac{\eta_{k+1}-\eta_{k}}{(\eta_{k+1}-\eta_ {k-1})(\eta_{k}-\eta_{k-1})}}\sum_{i=\eta_{k-1}+1}^{\eta_{k}}f_{i}-\sqrt{\frac {(\eta_{k}-\eta_{k-1})(\eta_{k+1}-\eta_{k})}{(\eta_{k+1}-\eta_{k-1})(\eta_{k+ 1}-\eta_{k})}}\sum_{i=\eta_{k}+1}^{\eta_{k+1}}f_{i}||_{L_{2}}}{\sqrt{\frac{( \eta_{k}-\eta_{k-1})(\eta_{k+1}-\eta_{k})}{\eta_{k+1}-\eta_{k}}}}\] (54)

_and (5), by triangle inequality, (53), and Lemma 5, we have that_

\[|\kappa-\widehat{\kappa}|=O_{p}\Big{(}\Big{(}\frac{\log(T)}{ \Delta}\Big{)}^{\frac{2r}{2r+p}}+\frac{T^{\frac{p}{2r+p}}\log(T)}{\kappa\Delta }\Big{)}.\]

_From here, and Assumption 2, if \(h_{1}=O(\kappa^{\frac{1}{r}})\) and \(h_{2}=O(\widehat{\kappa}^{\frac{1}{r}})\), we conclude that_

\[||F_{t,h_{1}}-F_{t,h_{2}}||_{L_{2}}^{2}=O\Big{(}\frac{|\kappa- \widehat{\kappa}|}{\kappa^{\frac{p}{r}+1}}\Big{)}.\]

_In fact,_

\[||F_{t,h_{1}}-F_{t,h_{2}}||_{L_{2}}^{2}\] \[= \int_{\mathbb{R}^{p}}(\frac{1}{h_{1}^{p}}\mathcal{K}(\frac{x-X_{ t}}{h_{1}})-\frac{1}{h_{2}^{p}}\mathcal{K}(\frac{x-X_{t}}{h_{2}}))^{2}dx\] \[= \int_{\mathbb{R}^{p}}\Big{(}\frac{1}{h_{1}^{p}}\mathcal{K}(\frac{ x-X_{t}}{h_{1}})\Big{)}^{2}-2\frac{1}{h_{1}^{p}}\mathcal{K}(\frac{x-X_{t}}{h_{1}}) \frac{1}{h_{2}^{p}}\mathcal{K}(\frac{x-X_{t}}{h_{2}})+\Big{(}\frac{1}{h_{2}^{p}} \mathcal{K}(\frac{x-X_{t}}{h_{2}})\Big{)}^{2}dx.\]_Now, we analyze the two following terms,_

\[I_{1}=\int_{\mathbb{R}^{p}}\Big{(}\frac{1}{h_{1}^{p}}\mathcal{K}(\frac{x-X_{t}}{h_ {1}})\Big{)}^{2}-\frac{1}{h_{1}^{p}}\mathcal{K}(\frac{x-X_{t}}{h_{1}})\frac{1}{h _{2}^{p}}\mathcal{K}(\frac{x-X_{t}}{h_{2}})dx\]

_and_

\[I_{2}=\int_{\mathbb{R}^{p}}\Big{(}\frac{1}{h_{2}^{p}}\mathcal{K}(\frac{x-X_{t}} {h_{2}})\Big{)}^{2}-\frac{1}{h_{1}^{p}}\mathcal{K}(\frac{x-X_{t}}{h_{1}})\frac{ 1}{h_{2}^{p}}\mathcal{K}(\frac{x-X_{t}}{h_{2}})dx.\]

_For \(I_{1}\), letting \(u=\frac{x-X_{t}}{h_{1}}\), we have that_

\[\int_{\mathbb{R}^{p}}\Big{(}\frac{1}{h_{1}^{p}}\mathcal{K}(\frac{x-X_{t}}{h_{1 }})\Big{)}^{2}dx=\int_{\mathbb{R}^{p}}\frac{1}{h_{1}^{p}}\Big{(}\mathcal{K}(u )\Big{)}^{2}du\]

_and, letting \(v=\frac{x-X_{t}}{h_{2}}\), we have that_

\[\int_{\mathbb{R}^{p}}\frac{1}{h_{1}^{p}}\mathcal{K}(\frac{x-X_{t}}{h_{1}}) \frac{1}{h_{2}^{p}}\mathcal{K}(\frac{x-X_{t}}{h_{2}})dx= \int_{\mathbb{R}^{p}}\frac{1}{h_{1}^{p}}\mathcal{K}(v\frac{h_{2}}{h_{1}}) \mathcal{K}(v)dv.\]

_Therefore, by Assumption 2 and the Mean Value Theorem,_

\[I_{1}=\frac{1}{h_{1}^{p}}\int_{\mathbb{R}^{p}}\mathcal{K}(v) \Big{(}\mathcal{K}(v)-\mathcal{K}(v\frac{h_{2}}{h_{1}})\Big{)}dv\leq C\frac{1}{h_{1}^{p}}\Big{|}1-\frac{h_{2}}{h_{1}}\Big{|}\int_{ \mathbb{R}^{p}}\mathcal{K}(v)||v||dv\] \[\leq C_{1}\frac{|h_{1}-h_{2}|}{h_{1}^{p+1}}\] \[= O\Big{(}\frac{|\kappa-\widehat{\kappa}|}{\kappa^{\frac{p+1}{r}}} \kappa^{\frac{1}{r}-1}\Big{)}=O\Big{(}\frac{|\kappa-\widehat{\kappa}|}{\kappa^ {\frac{p}{r}+1}}\Big{)}.\]

_Similarly, we have,_

\[I_{2}= \int_{\mathbb{R}^{p}}\Big{(}\frac{1}{h_{2}^{p}}\mathcal{K}(\frac{ x-X_{t}}{h_{2}})\Big{)}^{2}-\frac{1}{h_{1}^{p}}\mathcal{K}(\frac{x-X_{t}}{h_{1}}) \frac{1}{h_{2}^{p}}\mathcal{K}(\frac{x-X_{t}}{h_{2}})dx\] \[= \frac{1}{h_{2}^{p}}\int_{\mathbb{R}^{p}}\mathcal{K}(v)\Big{(} \mathcal{K}(v)-\mathcal{K}(v\frac{h_{1}}{h_{2}})\Big{)}dv\leq C\frac{1}{h_{2}^ {p}}\Big{|}1-\frac{h_{1}}{h_{2}}\Big{|}\int_{\mathbb{R}^{p}}\mathcal{K}(v)||v|| dv=O\Big{(}\frac{|\kappa-\widehat{\kappa}|}{\kappa^{\frac{p}{r}+1}}\Big{)}.\]

### Multivariate change point detection lemmas

We present some technical results corresponding to the generalization of the univariate CUSUM to the Multivariate case. For more details, we refer the interested readers to Padilla et al. (2021) and Wang et al. (2020).

Let \(\{X_{t}\}_{t=1}^{T}\subset\mathbb{R}^{p}\) a process with unknown densities \(\{f_{t}\}_{t=1}^{T}\).

**Assumption 5**.: _We assume there exist \(\{\eta_{k}\}_{k=1}^{K}\subset\{2,...,T\}\) with \(1=\eta_{0}<\eta_{1}<...<\eta_{k}\leq T<\eta_{K+1}=T+1,\) such that_

\[f_{t}\neq f_{t+1}\text{ if and only if }\ t\in\{\eta_{1},...,\eta_{K}\},\] (55)

_Assume_

\[\min_{k=1,\dots,K+1}(\eta_{k}-\eta_{k-1})\geq\Delta>0,\] \[0<||f_{\eta_{k+1}}-f_{\eta_{k}}||_{L_{\infty}}=\kappa_{k}\text{ for all }k=1,\dots,K.\]

In the rest of this section, we use the notation

\[\widehat{f}_{t}^{(s,e]}(x)=\sqrt{\frac{e-t}{(e-s)(t-s)}}\sum_{j=s+1}^{t}f_{j}( x)-\sqrt{\frac{t-s}{(e-s)(e-t)}}\sum_{j=t+1}^{e}f_{j}(x),\]

for all \(0\leq s<t<e\leq T\) and \(x\in\mathbb{R}^{p}\).

**Lemma 7**.: _If \([s,e]\) contain two and only two change points \(\eta_{r}\) and \(\eta_{r+1}\), then_

\[\sup_{s\leq t\leq e}||\widehat{f}_{t}^{s,e}||_{L_{2}}\leq\sqrt{e-\eta_{r+1}}||f _{r+1}-f_{r}||_{L_{2}}+\sqrt{\eta_{r}-s}||f_{r}-f_{r-1}||_{L_{2}}.\]Proof.: This is Lemma 15 in Wang et al. (2020). Consider the sequence \(\left\{g_{t}\right\}_{t=s+1}^{e}\) be such that

\[g_{t}=\left\{\begin{array}{ll}f_{\eta_{k}},&\text{ if }\ s+1\leq t<\eta_{k},\\ f_{t},&\text{ if }\ \ \ \eta_{k}\leq t\leq e.\end{array}\right.\]

For any \(t\geq\eta_{k}\),

\[\widetilde{f}_{t}^{s,e}-\widetilde{g}_{t}^{s,e}\] \[= \sqrt{\frac{e-t}{(e-s)(t-s)}}\Big{(}\sum_{i=s+1}^{t}f_{i}-\sum_{i =s+1}^{\eta_{k}}f_{\eta_{k}}-\sum_{i=\eta_{k}+1}^{t}f_{i}\Big{)}\] \[- \sqrt{\frac{t-s}{(e-s)(e-t)}}\Big{(}\sum_{i=t+1}^{e}f_{i}-\sum_{i =t+1}^{e}f_{i}\Big{)}\] \[= \sqrt{\frac{e-t}{(e-s)(t-s)}}\Big{(}\eta_{k}-s\Big{)}\Big{(}f_{ \eta_{k}}-f_{\eta_{k-1}}\Big{)}.\]

So for \(t\geq\eta_{k},||\widetilde{f}_{t}^{s,e}-\widetilde{g}_{t}^{s,e}||_{L_{2}}\leq \sqrt{\eta_{k}-s}\kappa_{k}\). Since \(\sup_{s\leq t\leq e}||\widetilde{f}_{t}^{s,e}||_{L_{2}}=\max\left\{|| \widetilde{f}_{\eta_{k}}^{s,e}||_{L_{2}},||\widetilde{f}_{\eta_{k+1}}^{s,e}|| _{L_{2}}\right\}\), and that

\[\max\left\{||\widetilde{f}_{\eta_{k}}^{s,e}||_{L_{2}},||\widetilde {f}_{\eta_{k+1}}^{s,e}||_{L_{2}}\right\} \leq\sup_{s\leq t\leq e}||\widetilde{g}_{t}^{s,e}||_{L_{2}}+\sqrt{ \eta_{k}-s}\kappa_{k}\] \[\leq\sqrt{e-\eta_{k+1}}\kappa_{k+1}+\sqrt{\eta_{r}-s}\kappa_{k}\]

where the last inequality follows form the fact that \(g_{t}\) has only one change point in \([s,e]\). 

**Lemma 8**.: _Suppose \(e-s\leq C_{R}\Delta\), where \(C_{R}>0\) is an absolute constant, and that_

\[\eta_{k-1}\leq s\leq\eta_{k}\leq\ldots\leq\eta_{k+q}\leq e\leq\eta_{k+q+1}, \quad q\geq 0\]

_Denote_

\[\kappa_{\max}^{s,e}=\max\Big{\{}\sup_{x\in\mathbb{R}^{p}}\left|f_{\eta_{p}}(x )-f_{\eta_{p-1}}(x)\right|:k\leq p\leq k+q\Big{\}}.\]

_Then for any \(k-1\leq p\leq k+q\), it holds that_

\[\sup_{x\in\mathbb{R}^{p}}\Big{|}\frac{1}{e-s}\sum_{i=s+1}^{e}f_{i}(x)-f_{\eta_ {p}}(x)\Big{|}\leq C_{R}\kappa_{\max}^{s,e}.\]

Proof.: This is Lemma 18 in Wang et al. (2020). Since \(e-s\leq C_{R}\Delta\), the interval \([s,e]\) contains at most \(C_{R}+1\) change points. Observe that

\[\Big{|}\Big{|}\frac{1}{e-s}\sum_{i=s}^{e}f_{i}-f_{\eta_{p}}\Big{|} \Big{|}_{L_{\infty}}\] \[= \frac{1}{e-s}\Big{|}\Big{|}\sum_{i=s}^{\eta_{k}}\left(f_{\eta_{k- 1}}-f_{\eta_{p}}\right)+\sum_{i=\eta_{k}+1}^{\eta_{k+1}}\left(f_{\eta_{k}}-f_{ \eta_{p}}\right)+\ldots+\sum_{i=\eta_{k+q}+1}^{e}\left(f_{\eta_{k+q}}-f_{\eta_ {p}}\right)\Big{|}\Big{|}_{L_{\infty}}\] \[\leq\frac{1}{e-s}\sum_{i=s}^{\eta_{k}}|p-k|\kappa_{\max}^{s,e}+ \sum_{i=\eta_{k}+1}^{\eta_{k+1}}|p-k-1|\kappa_{\max}^{s,e}+\ldots+\sum_{i=\eta_ {k+q}+1}^{e}|p-k-q-1|\kappa_{\max}^{s,e}\] \[\leq\frac{1}{e-s}\sum_{i=s}^{e}\Big{(}C_{R}+1\Big{)}\kappa_{\max }^{s,e},\]

where \(\left|p_{1}-p_{2}\right|\leq C_{R}+1\) for any \(\eta_{p_{1}},\eta_{p_{2}}\in[s,e]\) is used in the last inequality. 

**Lemma 9**.: _Let \((s,e)\subset(0,n)\) contains two or more change points such that_

\[\eta_{k-1}\leq s\leq\eta_{k}\leq\ldots\leq\eta_{k+q}\leq e\leq\eta_{k+q+1}, \quad q\geq 1\]

_If \(\eta_{k}-s\leq c_{1}\Delta\), for \(c_{1}>0\), then_

\[\Big{|}\Big{|}\widetilde{f}_{\eta_{k}}^{s,e}\Big{|}\Big{|}_{L_{\infty}}\leq \sqrt{c_{1}}\Big{|}\Big{|}\widetilde{f}_{\eta_{k+1}}^{s,e}\Big{|}\Big{|}_{L_{ \infty}}+2\kappa_{k}\sqrt{\eta_{k}-s}\]Proof.: This is Lemma 20 in Wang et al. (2020). Consider the sequence \(\left\{g_{t}\right\}_{t=s+1}^{e}\) be such that

\[g_{t}=\begin{cases}f_{\eta_{r+1}},&s+1\leq t\leq\eta_{k},\\ f_{t},&\eta_{k}+1\leq t\leq e\end{cases}\]

For any \(t\geq\eta_{r}\), it holds that

\[||\widetilde{f}_{\eta_{k}}^{s,e}-\widetilde{g}_{\eta_{k}}^{s,e}||_{L_{\infty}} =\Big{|}\Big{|}\sqrt{\frac{(e-s)-t}{(e-s)(t-s)}}\Big{(}\eta_{k}-s\Big{)}\Big{(} f_{\eta_{k+1}}-f_{\eta_{k}}\Big{)}\Big{|}\Big{|}_{L_{\infty}}\leq\sqrt{\eta_{k}-s} \kappa_{k}.\]

Thus,

\[||\widetilde{f}_{\eta_{k}}^{s,e}||_{L_{\infty}} \leq||\widetilde{g}_{\eta_{k}}^{s,e}||_{L_{\infty}}+\sqrt{\eta_{ k}-s}\kappa_{k}\leq\sqrt{\frac{\Big{(}\eta_{k}-s\Big{)}\Big{(}e-\eta_{k+1} \Big{)}}{\Big{(}\eta_{k+1}-s\Big{)}\Big{(}e-\eta_{k}}\Big{)}}||\widetilde{g}_ {\eta_{k+1}}^{s,e}||_{L_{\infty}}+\sqrt{\eta_{k}-s}\kappa_{k}\] \[\leq\sqrt{\frac{c_{1}\Delta}{\Delta}}||\widetilde{g}_{\eta_{k+1} }^{s,e}||_{L_{\infty}}+\sqrt{\eta_{k}-s}\kappa_{k}\leq\sqrt{c_{1}}|| \widetilde{f}_{\eta_{k+1}}^{s,e}||_{L_{\infty}}+2\sqrt{\eta_{k}-s}\kappa_{k},\]

where the first inequality follows from the observation that the first change point of \(g_{t}\) in \((s,e)\) is at \(\eta_{k+1}\). 

**Lemma 10**.: _Under Assumption 5, for any interval \((s,e)\subset(0,T)\) satisfying_

\[\eta_{k-1}\leq s\leq\eta_{k}\leq\ldots\leq\eta_{k+q}\leq e\leq\eta_{k+q+1}, \quad q\geq 0.\]

_Let_

\[b\in\operatorname*{arg\,max}_{t=s+1,\ldots,e}\sup_{x\in\mathbb{R}^{p}}\Big{|} \widetilde{f}_{t}^{(s,e)}(x)\Big{|}.\]

_Then \(b\in\left\{\eta_{1},\ldots,\eta_{K}\right\}\). For any fixed \(z\in\mathbb{R}^{p}\), if \(\widetilde{f}_{t}^{(s,e]}(z)>0\) for some \(t\in(s,e)\), then \(\widetilde{f}_{t}^{(s,e]}(z)\) is either strictly monotonic or decreases and then increases within each of the interval \(\left(s,\eta_{k}\right)\), \(\left(\eta_{k},\eta_{k+1}\right),\ldots,\left(\eta_{k+q},e\right)\)._

Proof.: We prove this by contradiction. Assume that \(b\notin\left\{\eta_{1},\ldots,\eta_{K}\right\}\). Let \(z_{1}\in\operatorname*{arg\,max}_{x\in\mathbb{R}^{p}}\left|\widetilde{f}_{b}^ {s,e}(x)\right|\). Due to the definition of \(b\), we have

\[b\in\operatorname*{arg\,max}_{t=s+1,\ldots,e}\Big{|}\widetilde{f}_{t}^{(s,e)} \Big{(}z_{1}\Big{)}\Big{|}.\]

It is easy to see that the collection of change points \(\left\{f_{t}(z_{1})\right\}_{t=s+1}^{e}\) is a subset of the change points of \(\left\{f\right\}_{t=s+1}^{e}\). Then, from Lemma \(2.2\) in Venkatraman (1992) that

\[\widetilde{f}_{b}^{(s,e]}\Big{(}z_{1}\Big{)}<\max_{j\in\left\{k,\ldots,k+q \right\}}\widetilde{f}_{\eta_{j}}^{(s,e]}\Big{(}z_{1}\Big{)}\leq\max_{t=s+1, \ldots,e}\sup_{x\in\mathbb{R}^{p}}\left|\widetilde{f}_{t}^{(s,e]}(x)\right|\]

which is a contradiction. 

Recall that in Algorithm 1, when searching for change points in the interval \((s,e)\), we actually restrict to values \(t\in\left(s+\rho,e-\rho\right)\). We now show that for intervals satisfying condition \(SE\) from Lemma 1, taking the maximum of the CUSUM statistic over \(\left(s+\rho,e-\rho\right)\) is equivalent to searching on \((s,e)\), when there are change points in \(\left(s+\rho,e-\rho\right)\).

**Lemma 11**.: _Let \(z_{0}\in\mathbb{R}^{p},(s,e)\subset(0,T)\). Suppose that there exists a true change point \(\eta_{k}\in(s,e)\) such that_

\[\min\left\{\eta_{k}-s,e-\eta_{k}\right\}\geq c_{1}\Delta,\] (56)

_and_

\[\Big{|}\widetilde{f}_{\eta_{k}}^{(s,e]}\Big{(}z_{0}\Big{)}\Big{|}\geq\Big{(}c_{ 1}/2\Big{)}\frac{\kappa\Delta}{\sqrt{e-s}},\] (57)_where \(c_{1}>0\) is a sufficiently small constant. In addition, assume that_

\[\max_{t=s+1,\ldots,e}\Big{|}\widetilde{f}_{t}^{(s,e)}\Big{(}z_{0}\Big{)}\Big{|}- \Big{|}\widetilde{f}_{\eta_{k}}^{(s,e)}\Big{(}z_{0}\Big{)}\Big{|}\leq c_{2} \Delta^{4}(e-s)^{-7/2}\kappa,\] (58)

_where \(c_{2}>0\) is a sufficiently small constant. Then for any \(d\in(s,e)\) satisfying_

\[\Big{|}d-\eta_{k}\Big{|}\leq c_{1}\Delta/32,\] (59)

_it holds that_

\[\Big{|}\widetilde{f}_{\eta_{k}}^{(s,e]}\Big{(}z_{0}\Big{)}\Big{|}-\Big{|} \widetilde{f}_{d}^{(s,e)}\Big{(}z_{0}\Big{)}\Big{|}>c\Big{|}d-\eta_{k}\Big{|} \Delta\Big{|}\widetilde{f}_{\eta_{k}}^{(s,e)}\Big{(}z_{0}\Big{)}\Big{|}(e-s)^ {-2},\] (60)

_where \(c>0\) is a sufficiently small constant, depending on all the other absolute constants._

Proof.: Without loss of generality, we assume that \(d\geq\eta_{k}\) and \(\widetilde{f}_{\eta_{k}}\Big{(}z_{0}\Big{)}\geq 0\). Following the arguments in Lemma 2.6 in Venkatraman (1992), it suffices to consider two cases: (i) \(\eta_{k+1}>e\) and (ii) \(\eta_{k+1}\leq e\)**Case (i)**. Note that

\[\widetilde{f}_{\eta_{k}}^{(s,e]}\Big{(}z_{0}\Big{)}=\sqrt{\frac{\Big{(}e-\eta _{k}\Big{)}\Big{(}\eta_{k}-s\Big{)}}{e-s}}\Big{\{}f_{\eta_{k}}\Big{(}z_{0} \Big{)}-f_{\eta_{k+1}}\Big{(}z_{0}\Big{)}\Big{\}}\]

and

\[\widetilde{f}_{d}^{(s,e]}\Big{(}z_{0}\Big{)}=\Big{(}\eta_{k}-s\Big{)}\sqrt{ \frac{e-d}{(e-s)(d-s)}}\Big{\{}f_{\eta_{k}}\Big{(}z_{0}\Big{)}-f_{\eta_{k+1}} \Big{(}z_{0}\Big{)}\Big{\}}.\]

Therefore, it follows from (56) that

\[\widetilde{f}_{\eta_{k}}^{(s,e]}\Big{(}z_{0}\Big{)}-\widetilde{f}_{d}^{(s,e]} \Big{(}z_{0}\Big{)}=\Big{(}1-\sqrt{\frac{(e-d)\Big{(}\eta_{k}-s\Big{)}}{(d- s)\Big{(}e-\eta_{k}\Big{)}}}\widetilde{f}_{\eta_{k}}^{(s,e]}\Big{(}z_{0} \Big{)}\geq c\Delta\Big{|}d-\eta_{k}\Big{|}(e-s)^{-2}\widetilde{f}_{\eta_{k} }^{(s,e]}\Big{(}z_{0}\Big{)}.\] (61)

The inequality follows from the following arguments. Let \(u=\eta_{k}-s,v=e-\eta_{k}\) and \(w=d-\eta_{k}\). Then

\[1-\sqrt{\frac{(e-d)\Big{(}\eta_{k}-s\Big{)}}{(d-s)\Big{(}e-\eta_ {k}\Big{)}}}-c\Delta\Big{|}d-\eta_{k}\Big{|}(e-s)^{2}\] \[= 1-\sqrt{\frac{(v-w)u}{(u+w)v}-c\frac{\Delta w}{(u+v)^{2}}}\] \[= \frac{w(u+v)}{\sqrt{(u+w)v}(\sqrt{(v-w)u}+\sqrt{(u+w)v})}-c\frac {\Delta w}{(u+v)^{2}}.\]

The numerator of the above equals

\[w(u+v)^{3}-c\Delta w(u+w)v-c\Delta w\sqrt{uv(u+w)(v-w)}\] \[\geq 2c_{1}\Delta w\Big{\{}(u+v)^{2}-\frac{c(u+w)v}{2c_{1}}-\frac{c \sqrt{uv(u+w)(v-w)}}{2c_{1}}\Big{\}}\] \[\geq\]

as long as

\[c<\frac{\sqrt{2}c_{1}}{4+1/\Big{(}\sqrt{2}c_{1}\Big{)}}.\]

**Case (ii)**. Let \(g=c_{1}\Delta/16\). We can write

\[\widetilde{f}_{\eta_{k}}^{(s,e]}\Big{(}z_{0}\Big{)}=a\sqrt{\frac{e-s}{\Big{(} \eta_{k}-s\Big{)}\Big{(}e-\eta_{k}\Big{)}}},\quad\widetilde{f}_{\eta_{k}}^{(s, e]}\Big{(}z_{0}\Big{)}=(a+g\theta)\sqrt{\frac{e-s}{\Big{(}e-\eta_{k}-g\Big{)}\Big{(} \eta_{k}+g-s\Big{)}}},\]where

\[a=\sum_{j=s+1}^{\eta_{k}}\Big{\{}f_{j}\Big{(}z_{0}\Big{)}-\frac{1}{e-s}\sum_{j=s+ 1}^{e}f_{j}\Big{(}z_{0}\Big{)}\Big{\}}\]

and \(b=\widetilde{f}_{\eta_{k}+g-s}^{(s,e]}\Big{(}z_{0}\Big{)}-\widetilde{f}_{\eta_{k }}^{(s,e]}\Big{(}z_{0}\Big{)}\). To ease notation, let \(d-\eta_{k}=l\leq g/2,N_{1}=\eta_{k}-s\) and \(N_{2}=e-\eta_{k}-g\). We have

\[E_{l}=\widetilde{f}_{\eta_{k}}^{(s,e]}\Big{(}z_{0}\Big{)}-\widetilde{f}_{d}^{ (s,e]}\Big{(}z_{0}\Big{)}=E_{1l}\Big{(}1+E_{2l}\Big{)}+E_{3l},\] (62)

where

\[E_{1l}=\frac{al(g-l)\sqrt{e-s}}{\sqrt{N_{1}\Big{(}N_{2}+g\Big{)}\sqrt{\Big{(} N_{1}+l\Big{)}\Big{(}g+N_{2}-l\Big{)}\Big{(}\sqrt{\Big{(}N_{1}+l\Big{)} \Big{(}g+N_{2}-l\Big{)}}+\sqrt{N_{1}\Big{(}g+N_{2}\Big{)}}\Big{)}}}},\]

\[E_{2l}=\frac{\Big{(}N_{2}-N_{1}\Big{)}\Big{(}N_{2}-N_{1}-l\Big{)}}{\Big{(} \sqrt{\Big{(}N_{1}+l\Big{)}\Big{(}g+N_{2}-l\Big{)}}+\sqrt{\Big{(}N_{1}+g\Big{)} N_{2}\Big{)}\Big{(}\sqrt{N_{1}\Big{(}g+N_{2}\Big{)}}+\sqrt{\Big{(}N_{1}+g\Big{)} N_{2}}\Big{)}}}},\]

and

\[E_{3l}=-\frac{bl}{g}\sqrt{\frac{\Big{(}N_{1}+g\Big{)}N_{2}}{\Big{(}N_{1}+l \Big{)}\Big{(}g+N_{2}-l\Big{)}}}.\]

Next, we notice that \(g-l\geq c_{1}\Delta/32\). It holds that

\[E_{1l}\geq c_{1l}\Big{|}d-\eta_{k}\Big{|}\Delta\widetilde{f}_{\eta_{k}}^{(s,e ]}\Big{(}z_{0}\Big{)}(e-s)^{-2},\] (63)

where \(c_{1l}>0\) is a sufficiently small constant depending on \(c_{1}\). As for \(E_{2l}\), due to (59), we have

\[E_{2l}\geq-1/2.\] (64)

As for \(E_{3l}\), we have

\[E_{3l} \geq-c_{3l,1}b\Big{|}d-\eta_{k}\Big{|}(e-s)\Delta^{-2}\geq-c_{3l, 2}b\Big{|}d-\eta_{k}\Big{|}\Delta^{-3}(e-s)^{3/2}\widetilde{f}_{\eta_{k}}^{(s,e ]}\Big{(}z_{0}\Big{)}\kappa^{-1}\] (65) \[\geq-c_{1l}/2\Big{|}d-\eta_{k}\Big{|}\Delta\widetilde{f}_{\eta_{k }}^{(s,e]}\Big{(}z_{0}\Big{)}(e-s)^{-2},\] (66)

where the second inequality follows from (57) and the third inequality follows from (58), \(c_{3l,1},c_{3l,2}>0\) are sufficiently small constants, depending on all the other absolute constants. Combining (62), (63), (64) and (65), we have

\[\widetilde{f}_{\eta_{k}}^{(s,e]}\Big{(}z_{0}\Big{)}-\widetilde{f}_{d}^{(s,e]} \Big{(}z_{0}\Big{)}\geq c\Big{|}d-\eta_{k}\Big{|}\Delta\widetilde{f}_{\eta_{k }}^{(s,e]}\Big{(}z_{0}\Big{)}(e-s)^{-2},\] (67)

where \(c>0\) is a sufficiently small constant. In view of (61) and (67), the proof is complete. 

Consider the following events

\[\mathcal{A}((s,e],\rho,\gamma)=\bigg{\{}\max_{t=s+\rho+1,\ldots,e- \rho}\sup_{z\in\mathbb{R}^{p}}|\widetilde{F}_{t,h}^{s,e}(z)-\widetilde{f}_{t}^ {s,e}(z)|\leq\gamma\bigg{\}};\] \[\mathcal{B}(r,\rho,\gamma)=\bigg{\{}\max_{N=\rho,\ldots,T-r}\sup_{z \in\mathbb{R}^{p}}\bigg{|}\frac{1}{\sqrt{N}}\sum_{t=r+1}^{r+N}(F_{t,h}-f_{t}) \bigg{|}\leq\gamma\bigg{\}}\]

\[\bigcup\bigg{\{}\max_{N=\rho,\ldots,r}\bigg{|}\frac{1}{\sqrt{N}}\sum_{t=r-N+1} ^{r}\sup_{z\in\mathbb{R}^{p}}(F_{t,h}(z)-f_{t}(z))\bigg{|}\leq\gamma\bigg{\}}.\]

**Lemma 12**.: _Suppose Assumption 5 holds. Let \([s,e]\) be an subinterval of \([1,T]\) with \(e-s\leq C_{R}\Delta\), and contain at least one change point \(\eta_{r}\) with \(\min\{\eta_{r}-s,e-\eta_{r}\}\geq cT\) for some constant \(c>0\). Let \(\kappa_{\max}^{s,e}=\max\{\kappa_{p}:\min\{\eta_{p}-s,e-\eta_{p}\}\geq cT\}\). Let_

\[b\in\arg\max_{t=s+\rho,\ldots,e-\rho}||\widetilde{F}_{t,h}^{s,e}||_{L_{2}}.\]

_For some \(c_{1}>0\), \(\lambda>0\) and \(\delta>0\), suppose that the following events hold_

\[\mathcal{A}((s,e],\rho,\gamma),\] (68) \[\mathcal{B}(s,\rho,\gamma)\cup\mathcal{B}(e,\rho,\gamma)\cup \bigcup_{\eta\in\{\eta_{k}\}_{k=1}^{K}}\mathcal{B}(\eta,\rho,\gamma)\] (69)

_and that_

\[\max_{t=s+\rho,\ldots,e-\rho}||\widetilde{F}_{t,h}^{s,e}||_{L_{2}}=|| \widetilde{F}_{b,h}^{s,e}||_{L_{2}}\geq c_{1}\kappa_{\max}^{s,e}\sqrt{T}\] (70)

_If there exists a sufficiently small \(c_{2}>0\) such that_

\[\gamma\leq c_{2}\kappa_{\max}^{s,e}\sqrt{T}\quad\text{and that}\quad\rho\leq c _{2}T,\] (71)

_then there exists a change point \(\eta_{k}\in(s,e)\) such that_

\[\min\{e-\eta_{k},\eta_{k}-s\}>c_{3}T\quad\text{and}\quad|\eta_{k}-b|\leq C_{3} \max\{\gamma^{2}\kappa_{k}^{-2},\rho\},\]

_where \(c_{3}\) is some sufficiently small constant independent of \(T\)._

Proof.: Let \(z_{1}\in\arg\max_{z\in\mathbb{R}^{p}}\left|\widetilde{f}_{b}^{(s,e)}(z)\right|\). Without loss of generality, assume that \(\widetilde{f}_{b}^{(s,e]}\Big{(}z_{1}\Big{)}>0\) and that \(\widetilde{f}_{b}^{(s,e]}\Big{(}z_{1}\Big{)}\) as a function of \(t\) is locally decreasing at \(b\). Observe that there has to be a change point \(\eta_{k}\in(s,b)\), or otherwise \(\widetilde{f}_{b}^{(s,e]}\Big{(}z_{1}\Big{)}>0\) implies that \(\widetilde{f}_{t}^{(s,e]}\Big{(}z_{1}\Big{)}\) is decreasing, as a consequence of Lemma 10. Thus, there exists a change point \(\eta_{k}\in(s,b)\) satisfying that

\[\sup_{z\in\mathbb{R}^{p}}\left|\widetilde{f}_{\eta_{k}}^{(s,e]}(z)\right|\geq \left|\widetilde{f}_{\eta_{k}}^{(s,e]}\Big{(}z_{1}\Big{)}\right|>\left| \widetilde{f}_{b}^{(s,e]}\Big{(}z_{1}\Big{)}\right|\geq\sup_{z\in\mathbb{R}^ {p}}\left|\widetilde{F}_{b}^{(s,e]}(z)\right|-\gamma\geq c\kappa_{k}\sqrt{\Delta}\] (72)

where the second inequality follows from Lemma 10, the third because of the good event \(\mathcal{A}\), and fourth inequalities by (70) and Assumption 1, and \(c>0\) is an absolute constant. Observe that \((s,e)\) has to contain at least one change point or otherwise \(\sup_{z\in\mathbb{R}}\left|\widetilde{f}_{\eta_{k}}^{(s,e]}(z)\right|=0\) which contradicts (72).

**Step 1**. In this step, we are to show that

\[\min\Big{\{}\eta_{k}-s,e-\eta_{k}\Big{\}}\geq\min\Big{\{}1,c_{1}^{2}\Big{\}} \Delta/16\] (73)

Suppose that \(\eta_{k}\) is the only change point in \((s,e)\). Then (73) must hold or otherwise it follows from (14) that

\[\sup_{z\in\mathbb{R}^{p}}\left|\widetilde{f}_{\eta_{k}}^{s,e}(z)\right|\leq \kappa_{k}\frac{c_{1}\sqrt{\Delta}}{4},\]

which contradicts (72).

Suppose \((s,e)\) contains at least two change points. Then arguing by contradiction, if \(\eta_{k}-s<\min\Big{\{}1,c_{1}^{2}\Big{\}}\Delta/16\), it must be the cast that \(\eta_{k}\) is the left most change point in \((s,e)\). Therefore

\[\sup_{z\in\mathbb{R}^{p}}\left|\widetilde{f}_{\eta_{k}}^{s,e}(z)\right| \leq c_{1}/4\sup_{z\in\mathbb{R}^{p}}\left|\widetilde{f}_{\eta_{k+1 }}^{s,e}(z)\right|+2\kappa_{k}\sqrt{\eta_{k}-s}\] (74) \[<c_{1}/4\max_{s+\rho<t<c-\rho}\sup_{z\in\mathbb{R}^{p}}\left| \widetilde{f}_{t}^{s,e}(z)\right|+2\sqrt{\Delta}\kappa_{k}\] (75) \[\leq c_{1}/4\max_{s+\rho<t<c-\rho}\sup_{z\in\mathbb{R}^{p}}\left| \widetilde{F}_{t}^{s,e}(z)\right|+c_{1}/4\gamma+2\sqrt{\Delta}\kappa_{k}\] (76) \[\leq\sup_{z\in\mathbb{R}^{p}}\left|\widetilde{F}_{b}^{s,e}(z) \right|-\gamma\] (77)where the first inequality follows from Lemma 9, the second follows from the assumption of \(\eta_{k}-s\), the third from the definition of the event \(\mathcal{A}\) and the last from (70) and Assumption 1. The last display contradicts (72), thus (73) must hold.

**Step 2.** Let

\[z_{0}\in\operatorname*{arg\,max}_{z\in\mathbb{R}^{p}}\Bigl{|}\widetilde{f}_{ \eta_{k}}^{s,e}(z)\Bigr{|}.\]

It follows from Lemma 11 that there exits \(d\in\Bigl{(}\eta_{k},\eta_{k}+c_{1}\Delta/32\Bigr{)}\) such that

\[\widetilde{f}_{\eta_{k}}^{s,e}\Bigl{(}z_{0}\Bigr{)}-\widetilde{f}_{d}^{s,e} \Bigl{(}z_{0}\Bigr{)}\geq 2\gamma.\] (78)

We claim that \(b\in\Bigl{(}\eta_{k},d\Bigr{)}\subset\Bigl{(}\eta_{k},\eta_{k}+c_{1}\Delta/16 \Bigr{)}\). By contradiction, suppose that \(b\geq d\). Then

\[\widetilde{f}_{b}^{s,e}\Bigl{(}z_{0}\Bigr{)}\leq\widetilde{f}_{d}^{s,e} \Bigl{(}z_{0}\Bigr{)}\leq\max_{s<t<e}\sup_{z\in\mathbb{R}^{p}}\Big{|}\widetilde {f}_{t}^{s,e}(z)\Bigr{|}-2\gamma\leq\sup_{z\in\mathbb{R}^{p}}\Big{|}\widetilde {F}_{b}^{s,e}(z)\Bigr{|}-\gamma,\] (79)

where the first inequality follows from Lemma 10, the second follows from (78) and the third follows from the definition of the event \(\mathcal{A}\). Note that (79) is a contradiction to the bound in (72), therefore we have \(b\in\Bigl{(}\eta_{k},\eta_{k}+c_{1}\Delta/32\Bigr{)}\).

**Step 3**. Let

\[j^{*}\in\operatorname*{arg\,max}_{j=1,\ldots,T}\Bigl{|}\widetilde{F}_{b}^{s, e}(X(j))\Bigr{|},\quad f^{s,e}=\Bigl{(}f_{s+1}\Bigl{(}X\Bigl{(}j^{*}\Bigr{)} \Bigr{)},\ldots,f_{e}\Bigl{(}X\Bigl{(}j^{*}\Bigr{)}\Bigr{)}\Bigr{)}^{\top}\in \mathbb{R}^{(e-s)}\]

and

\[F^{s,e}=\Bigl{(}\frac{1}{h^{p}}k\Bigl{(}\frac{X\Bigl{(}j^{*}\Bigr{)}-X(s)}{h} \Bigr{)},\ldots,\frac{1}{h^{p}}k\Bigl{(}\frac{X\Bigl{(}j^{*}\Bigr{)}-X(e)}{h} \Bigr{)}\Bigr{)}\in\mathbb{R}^{(e-s)}.\]

By the definition of \(b\), it holds that

\[\Bigl{\|}F^{s,e}-\mathcal{P}_{b}^{s,e}\Bigl{(}F^{s,e}\Bigr{)}\Bigr{\|}^{2}\leq \Bigl{\|}F^{s,e}-\mathcal{P}_{\eta_{k}}^{s,e}\Bigl{(}F^{s,e}\Bigr{)}\Bigr{\|}^ {2}\leq\Bigl{\|}F^{s,e}-\mathcal{P}_{\eta_{k}}^{s,e}\Bigl{(}f^{s,e}\Bigr{)} \Bigr{\|}^{2}\]

where the operator \(\mathcal{P}^{s,e}(\cdot)\) is defined in Lemma 21 in Wang et al. (2020). For the sake of contradiction, throughout the rest of this argument suppose that, for some sufficiently large constant \(C_{3}>0\) to be specified,

\[\eta_{k}+C_{3}\lambda_{A}^{2}\kappa_{k}^{-2}<b.\] (80)

We will show that this leads to the bound

\[\Bigl{\|}F^{s,e}-\mathcal{P}_{b}^{s,e}\Bigl{(}F^{s,e}\Bigr{)}\Bigr{\|}^{2}> \Bigl{\|}F^{s,e}-\mathcal{P}_{\eta_{k}}^{s,e}\Bigl{(}f^{s,e}\Bigr{)}\Bigr{\|}^ {2},\] (81)

which is a contradiction. If we can show that

\[2\Bigl{\langle}F^{s,e}-f^{s,e},\mathcal{P}_{b}^{s,e}\Bigl{(}F^{s,e}\Bigr{)}- \mathcal{P}_{\eta_{k}}^{s,e}\Bigl{(}f^{s,e}\Bigr{)}\Bigr{\rangle}<\Bigl{\|}f^{ s,e}-\mathcal{P}_{b}^{s,e}\Bigl{(}f^{s,e}\Bigr{)}\Bigr{\|}^{2}-\Bigl{\|}f^{s,e}- \mathcal{P}_{\eta_{k}}^{s,e}\Bigl{(}f^{s,e}\Bigr{)}\Bigr{\|}^{2},\] (82)

then (81) holds. To derive (82) from (80), we first note that \(\min\Big{\{}e-\eta_{k},\eta_{k}-s\Big{\}}\geq\min\Big{\{}1,c_{1}^{2}\Big{\}} \Delta/16\) and that \(\Bigl{|}b-\eta_{k}\Bigr{|}\leq c_{1}\Delta/32\) implies that

\[\min\{e-b,b-s\}\geq\min\Big{\{}1,c_{1}^{2}\Big{\}}\Delta/16-c_{1}\Delta/32\geq \min\Big{\{}1,c_{1}^{2}\Big{\}}\Delta/32\] (83)

As for the right-hand side of (82), we have

\[\Bigl{\|}f^{s,e}-\mathcal{P}_{b}^{s,e}\Bigl{(}f^{s,e}\Bigr{)}\Bigr{\|}^{2}- \Bigl{\|}f^{s,e}-\mathcal{P}_{\eta_{k}}^{s,e}\Bigl{(}f^{s,e}\Bigr{)}\Bigr{\|}^ {2}=\Bigl{(}\widetilde{f}_{\eta_{k}}^{s,e}\Bigl{(}X\Bigl{(}j^{*}\Bigr{)}\Bigr{)} \Bigr{)}^{2}-\Bigl{(}\widetilde{f}_{b}^{s,e}\Bigl{(}X\Bigl{(}j^{*}\Bigr{)} \Bigr{)}\Bigr{)}^{2}\] (84) \[\geq\Bigl{(}\widetilde{f}_{\eta_{k}}^{s,e}\Bigl{(}X\Bigl{(}j^{*} \Bigr{)}\Bigr{)}-\widetilde{f}_{b}^{s,e}\Bigl{(}X\Bigl{(}j^{*}\Bigr{)}\Bigr{)} \Bigr{)}\Bigl{|}\widetilde{f}_{\eta_{k}}^{s,e}\Bigl{(}X\Bigl{(}j^{*}\Bigr{)} \Bigr{)}\Bigr{|}\] (85)On the event \(\mathcal{A}\cap\bar{\mathcal{B}}\), we are to use Lemma 11. Note that (57) holds due to the fact that here we have

\[\Big{|}\widetilde{f}_{\eta_{k}}^{s,e}\Big{(}X\Big{(}j^{*}\Big{)}\Big{)}\Big{|} \geq\Big{|}\widetilde{f}_{b}^{s,e}\Big{(}X\Big{(}j^{*}\Big{)}\Big{)}\Big{|} \geq\Big{|}\widetilde{F}_{b}^{s,e}\Big{(}X\Big{(}j^{*}\Big{)}\Big{)}\Big{|}- \gamma\geq c_{1}\kappa_{k}\sqrt{\Delta}-\gamma\geq\Big{(}c_{1}\Big{)}/2\kappa_ {k}\sqrt{\Delta},\] (86)

where the first inequality follows from the fact that \(\eta_{k}\) is a true change point, the second inequality holds due to the event \(\mathcal{A}\), the third inequality follows from (70), and the final inequality follows from (71). Towards this end, it follows from Lemma 11 that

\[|\;\widetilde{f}_{\eta_{k}}^{s,e}\Big{(}X\Big{(}j^{*}\Big{)}\Big{)}\Big{|}-| \widetilde{f}_{b}^{s,e}\Big{(}X\Big{(}j^{*}\Big{)}\Big{)}\Big{|}|>c|b-\eta_{k} |\Delta|\widetilde{f}_{\eta_{k}}^{s,e}\Big{(}X\Big{(}j^{*}\Big{)}\Big{)}\;| \;(e-s)^{-2}.\] (87)

Combining (84), (86) and (87), we have

\[\Big{\|}f^{s,e}-\mathcal{P}_{b}^{s,e}\Big{(}f^{s,e}\Big{)}\Big{\|}^{2}-\Big{\|} f^{s,e}-\mathcal{P}_{\eta_{k}}^{s,e}\Big{(}f^{s,e}\Big{)}\Big{\|}^{2}\geq\frac{ cc_{1}^{2}}{4}\Delta^{2}\kappa_{k}\mathcal{A}^{2}(e-s)^{-2}\Big{|}b-\eta_{k} \Big{|}.\] (88)

The left-hand side of (82) can be decomposed as follows.

\[2\Big{\langle}F^{s,e}-f^{s,e},\mathcal{P}_{b}^{s,e}\Big{(}F^{s,e }\Big{)}-\mathcal{P}_{\eta_{k}}^{s,e}\Big{(}f^{s,e}\Big{)}\Big{\rangle}\] (89) \[= 2\Big{\langle}F^{s,e}-f^{s,e},\mathcal{P}_{b}^{s,e}\Big{(}F^{s,e }\Big{)}-\mathcal{P}_{b}^{s,e}\Big{(}f^{s,e}\Big{)}\Big{\rangle}+2\Big{\langle} Y^{s,e}-f^{s,e},\mathcal{P}_{b}^{s,e}\Big{(}f^{s,e}\Big{)}-\mathcal{P}_{\eta_{k}}^{s,e }\Big{(}f^{s,e}\Big{)}\Big{\rangle}\] (90) \[= (I)+2\Big{(}\sum_{i=1}^{\eta_{k}-s}+\sum_{i=\eta_{k}-s+1}^{b-s}+ \sum_{i=b-s+1}^{e-s}\Big{)}\Big{(}F^{s,e}-f^{s,e}\Big{)}_{i}\Big{(}\mathcal{P} _{b}^{s,e}\Big{(}f^{s,e}\Big{)}-\mathcal{P}_{\eta_{k}}^{s,e}\Big{(}f^{s,e} \Big{)}\Big{)}_{i}\] (91) \[= (I)+(II.1)+(II.2)+(II.3).\] (92)

As for the term (I), we have

\[(I)\leq 2\gamma^{2}.\] (93)

As for the term (II.1), we have

\[(II.1)=2\sqrt{\eta_{k}-s}\Big{\{}\frac{1}{\sqrt{\eta_{k}-s}}\sum_{i=1}^{\eta_{k }-s}\Big{(}F^{s,e}-f^{s,e}\Big{)}_{i}\Big{\}}\Big{\{}\frac{1}{b-s}\sum_{i=1}^{ b-s}\Big{(}f^{s,e}\Big{)}_{i}-\frac{1}{\eta_{k}-s}\sum_{i=1}^{\eta_{k}-s}\Big{(}f^{s,e}\Big{)}_{i}\Big{\}}.\]

In addition, it holds that

\[\Big{|}\frac{1}{b-s}\sum_{i=1}^{b-s}\Big{(}f^{s,e}\Big{)}_{i}-\frac {1}{\eta_{k}-s}\sum_{i=1}^{\eta_{k}-s}\Big{(}f^{s,e}\Big{)}_{i}\Big{|}=\frac{b- \eta_{k}}{b-s}\Big{|}-\frac{1}{\eta_{k}-s}\sum_{i=1}^{\eta_{k}-s}f_{i}\Big{(} X\Big{(}j^{*}\Big{)}\Big{)}+f_{\eta_{k+1}}\Big{(}X\Big{(}j^{*}\Big{)}\Big{)}\Big{|}\] \[\leq\frac{b-\eta_{k}}{b-s}\Big{(}C_{R}+1\Big{)}\kappa_{s_{0},e _{0}}^{\max},\]

where the inequality is followed by Lemma 8. Combining with the good events,

\[(II.1) \leq 2\sqrt{\eta_{k}-s}\frac{b-\eta_{k}}{b-s}\Big{(}C_{R}+1\Big{)} \kappa_{s_{0},e_{0}}^{\max}\gamma\] (94) \[\leq 2\frac{4}{\min\Big{\{}1,c_{1}^{2}\Big{\}}}\Delta^{-1/2} \gamma\Big{|}b-\eta_{k}\Big{|}\Big{(}C_{R}+1\Big{)}\kappa_{s_{0},e_{0}}^{\max}\] (95)

As for the term (II.2), it holds that

\[(II.2)\leq 2\sqrt{\Big{|}b-\eta_{k}\Big{|}}\gamma\Big{(}2C_{R}+3\Big{)} \kappa_{s_{0},e_{0}}^{\max}\] (96)

As for the term (II.3), it holds that

\[(II.3)\leq 2\frac{4}{\min\Big{\{}1,c_{1}^{2}\Big{\}}}\Delta^{-1/2} \gamma\Big{|}b-\eta_{k}\Big{|}\Big{(}C_{R}+1\Big{)}\kappa_{s_{0},e_{0}}^{\max}\] (97)

Therefore, combining (94), (96), (97), (88), (89) and (93), we have that (82) holds if

\[\Delta^{2}\kappa_{k}^{2}(e-s)^{-2}\Big{|}b-\eta_{k}\Big{|}\gtrsim\max\Big{\{} \gamma^{2},\Delta^{-1/2}\gamma\Big{|}b-\eta_{k}\Big{|}\kappa_{k},\sqrt{\Big{|}b- \eta_{k}\Big{|}\gamma\kappa_{k}\Big{\}}\] (98)

The second inequality holds due to Assumption 3, the third inequality holds due to (79) and the first inequality is a consequence of the third inequality and Assumption 3.