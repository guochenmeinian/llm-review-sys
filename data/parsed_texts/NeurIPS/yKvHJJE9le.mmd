# Safe Time-Varying Optimization based on Gaussian Processes with Spatio-Temporal Kernel

Jialin Li

ETH Zurich (currently with UIUC)

lijial@ethz.ch &Marta Zagorowska

NTNU (currently with TU Delft)

m.a.zagorowska@tudelft.nl &Giulia De Pasquale

Eindhoven Univeristy of Technology

g.de.pasquale@tue.nl &Alisa Rupenyan

Zurich University of Applied Sciences

alisa.rupenyan@zhaw.ch &John Lygeros

ETH Zurich

jlygeros@ethz.ch

###### Abstract

Ensuring safety is a key aspect in sequential decision making problems, such as robotics or process control. The complexity of the underlying systems often makes finding the optimal decision challenging, especially when the safety-critical system is time-varying. Overcoming the problem of optimizing an unknown time-varying reward subject to unknown time-varying safety constraints, we propose TVSAFEOPT, a new algorithm built on Bayesian optimization with a spatio-temporal kernel. The algorithm is capable of safely tracking a time-varying safe region without the need for explicit change detection. Optimality guarantees are also provided for the algorithm when the optimization problem becomes stationary. We show that TVSAFEOPT compares favorably against SAFEOPT on synthetic data, both regarding safety and optimality. Evaluation on a realistic case study with gas compressors confirms that TVSAFEOPT ensures safety when solving time-varying optimization problems with unknown reward and safety functions.

## 1 Introduction

We seek to interactively optimize an unknown time-varying reward function \(f:\mathcal{X}\times\mathcal{T}\rightarrow\mathbb{R}\), where \(\mathcal{X}\) is a finite set of decisions, and \(\mathcal{T}:=\{0,1,2,\ldots,T\},\;T\in\mathbb{N}_{+}\) denotes the discretized time domain. We assume that the optimization problem is safety-critical, that is, there are constraints that evaluated decisions must satisfy with high probability. Similar to the reward, the constraints are also unknown and potentially time-varying, encoded through \(c_{i}:\mathcal{X}\times\mathcal{T}\rightarrow\mathbb{R},\;i\in\mathcal{I}_{c }:=\{1,2,\ldots,m\},\) where \(\;m\in\mathbb{N}_{+}\) denotes the number of safety constraints. The optimization problem at time \(t\) is

\[\max_{\mathbf{x}\in\mathcal{X}}f(\mathbf{x},t)\] (1) \[\text{subject to }c_{i}(\mathbf{x},t)\geq 0,\;i\in\mathcal{I}_{c}\]

Both the reward function and the safety constraints are assumed to be unknown but can be evaluated. This is a plausible setting, for example, for UAV that need to perform rescue missions in dangerous and poorly lit environments.

### Related Work

Bayesian Optimization (BO) is a well-established approach for interactively optimizing unknown reward functions. Various BO based approaches have been proposed to solve a wide range of problems in robotics [1; 2], combinatorial optimization [3], sensor networks [4], and automatic machine learning [5; 6]. However, Safe Bayesian Optimization in the time-varying setting is still under-explored.

**Safe Bayesian Optimization** To address safety requirements in safety-critical applications, Safe Bayesian Optimization (SBO) [7] has been proposed to avoid unsafe decisions with high probability by interactively optimizing a reward function under safety constraints. SAFEOPT [7], one of the first SBO algorithms, expands an initial safe set iteratively based on new evaluations and an

Figure 1: Comparison of safe sets computed by TVSAFEOPT (top row), ETSAFEOPT (middle row), and SAFEOPT (bottom row) at \(t=30,\ t=100,\text{and}\,t=170\). Because TVSAFEOPT takes the possible changes in time into consideration, the safe sets computed by TVSAFEOPT are contained in the ground truth safe regions while those computed by ETSAFEOPT and SAFEOPT have multiple violations. The reason for the violations in ETSAFEOPT is that the algorithm is unable to detect small changes in the constraints, confirming that the performance of ETSAFEOPT depends on the event detection algorithm.

updated Gaussian Process (GP) model of safety functions. It calculates two subsets, maximizers and expanders, from the current safe set and selects the most uncertain decision within their union to balance maximizing the reward function and expanding the safe set. Subsequent algorithms extend SAFEOPT to handle multiple constraints [8], decouple safe set expansion from optimization [9], and expand the safe set in a goal-oriented manner [10]. These methods also explore disconnected safe regions [11; 12] and enhance information-theoretic efficiency [13; 14]. They have been applied to controller tuning for a ball-screw drive [15] and quadrupeds [16], and adaptive control on a rotational motion system [17]. However, SBO typically does not take into account changes with time.

**Contextual Bayesian Optimization** Contextual Bayesian Optimization (CBO) has been introduced to address the influence of external environmental factors on reward and safety functions. Krause and Ong [18] extend the Gaussian Process Upper Confidence Bound (GP-UCB) algorithm [19] by incorporating contextual variables into unconstrained BO, demonstrating sub-linear regret analogous to GP-UCB. An advancement of this framework is proposed in [20], with the Safe Contextual GP-UCB optimizing the contextual upper confidence bound within a safe set to manage room temperature via a PID controller. Berkenkamp et al. [8] present a contextual adaptation of SAFEOPT, discussing its safety and optimality guarantees by framing contextual SBO as distinct SBO sub-problems. Additionally, Konig et al. [21] extends GOOSE [10] to the contextual domain for model-free adaptive control scenarios. Similarly to SBO, CBO does not explicitly consider time-varying problems.

**Time-Varying Bayesian Optimization** Time-Varying Bayesian Optimization (TVBO) addresses problems where the objective is time-dependent, modeled with a temporal kernel [23]. Methods in this setting include periodical resetting [23], change detection [24; 25], sliding-window approaches using recent data [26], and discounting via exponentially decaying past observations [27]. However, these techniques have been developed for unconstrained BO and are unsuitable for safety-critical applications.

**Time-Varying Safe Bayesian Optimization** In the safety-critical time-varying setting, contextual lower confidence bounds can be optimized within the safe set [20], but it does not guarantee optimality theoretically. An event triggering mechanism is introduced to SBO to restart exploration from a backup policy [22], but it may not trigger reliably during changes, posing a safety risk. Extensions to SBO with contextual variables provide theoretical safety and optimality analyses [8; 16], treating contextual SBO as separate sub-problems for each contextual value, and assuming an initial safe set for each. However, ensuring optimality requires each contextual value to appear frequently, which is impractical in time-varying scenarios.

### Methodology and Contributions

**Methodology** We propose the TVSAFEOPT algorithm to optimize an unknown time-varying reward subject to unknown time-varying safety constraints. The algorithm focuses on Time-Varying Safe Bayesian Optimization (TVSBO). TVSAFEOPT utilizes a spatio-temporal kernel and time Lipschitz constants as prior knowledge about how the problem depends on time. The temporal part of the kernel encodes the continuity of the functions with time while the Lipschitz constants explicitly provide upper bounds on how fast the functions may change. Instead of considering safe sets at previous iteration as safe at the current iteration, which might lead to unsafe decisions, TVSAFEOPT robustly subtracts the safety margin when updating the safe sets (Figure 1). In this way, the algorithm is capable of adapting in real time and guarantees safety even when exploring the safe region of non-stationary problems.

**Contributions** Our contributions are threefold: a) We propose the TVSAFEOPT algorithm based on Gaussian processes with spatio-temporal kernels; b) We provide formal safety guarantees for TVSAFEOPT in the most general time-varying setting and optimality guarantees for TVSAFEOPT for

\begin{table}
\begin{tabular}{l l c c c} \hline  & 
\begin{tabular}{c} Handling Changes \\ in Time \\ \end{tabular} & Safety Guarantee & Optimality Guarantee & Safe Seed \\ \hline A-GOOSE [21; 17] & Spatio-temporal kernel & ✓ & ✗ & For all \(t\) \\ C-SAFEOPT [8] & Spatio-temporal kernel & ✓ & ✗ & For all \(t\) \\ ETSAFEOPT [22] & Event detection & ✗ & ✗ & For all \(t\) \\ TVSAFEOPT (ours) & Spatio-temporal kernel & ✓ & ✓ & For initial \(t\) \\ \hline \end{tabular}
\end{table}
Table 1: Overview of safe learning methods based on BO for time-varying problems.

locally stationary optimization problems; c) We show TVSAFEOPT performs well in the most general time-varying setting both on synthetic data and on a realistic case study on gas compressors. In Table 1, we compare Adaptive GOOSE, Contextual SAFEOPT, ETSAFEOPT, and TVSAFEOPT in terms of how they handle changes in time, safety guarantees, optimality guarantees, and required safe seeds.

#### 1.2.1 Expected societal impact

The TVSAFEOPT algorithm proposed in this paper extends the state of the art in Time-Varying Safe Bayesian Optimization by enabling solving optimization problems with time-varying reward and constraints without pre-defining the time changes that can be compensated.Thus, the algorithm can be used at the design stage of operating strategies for safety-critical systems, such as medical dosage design [28] and controller design in robotics [17], or during online operation of chemical plants [29] or autonomous racing [30].

## 2 TVSAFEOpt Algorithm

The TVSAFEOPT algorithm builds upon SAFEOPT [7], to handle time-varying reward function and safety functions. The key new feature of TVSAFEOPT is its capability of safely transferring the current safe set to the next time step. TVSAFEOPT achieves this with the help of the spatio-temporal kernel as well as the sequence of time Lipschitz constants. The approach is summarized in Algorithm 1.

### Assumptions

Following [8], we incorporate the reward and safety functions into an auxiliary function \(h:\mathcal{X}\times\mathcal{T}\times\mathcal{I}\rightarrow\mathbb{R}\), where \(\mathcal{I}:=\{0\}\cup\mathcal{I}_{c}\),

\[h(\mathbf{x},t,i):=\begin{cases}f(\mathbf{x},t)&\text{, if }i=0\\ c_{i}(\mathbf{x},t)&\text{, if }i\in\mathcal{I}_{c}\end{cases}\] (2)

We model the auxiliary function using a prior Gaussian Process (GP) with zero mean and spatio-temporal kernel \(\kappa:(\mathcal{X}\times\mathcal{T}\times\mathcal{I})\times(\mathcal{X} \times\mathcal{T}\times\mathcal{I})\rightarrow\mathbb{R}\), [31]. We require \(h\) to be Lipschitz continuous with respect to both \(\mathbf{x}\) and \(t\), and to have bounded norm in the Reproducing Kernel Hilbert Space (RKHS) [32] associated with the kernel \(\kappa\) as formalized in the following.

**Assumption 2.1**.: The spatio-temporal kernel is positive definite, and satisfies \(\kappa\left((\mathbf{x},t,i),(\mathbf{x},t,i)\right)\leq 1\), for all \(\mathbf{x}\in\mathcal{X},t\in\mathcal{T},i\in\mathcal{I}\). The function \(h(\mathbf{x},t,i)\) has bounded norm in the RKHS associated with kernel \(\kappa\). The function \(h(\mathbf{x},t,i)\) is \(L_{\mathbf{x}}\)-Lipschitz continuous with respect to \(\mathbf{x}\) in the domain \(\mathcal{X}\) with respect to some metric \(d:\mathcal{X}\times\mathcal{X}\rightarrow\mathbb{R}_{\geq 0}\) for all \(t\in\mathbb{N}\), \(i\in\mathcal{I}\). There exists a sequence \(\{L(t)\}_{t\in\mathbb{N},t<T}\), such that, for all \(\mathbf{x}\in\mathcal{X}\), \(i\in\mathcal{I}\), \(t\in\mathbb{N},t<T\), \(|h(\mathbf{x},t+1,i)-h(\mathbf{x},t,i)|\leq L(t)\).

At each algorithm iteration \(k\), we make a decision \(\mathbf{x}_{k}\), which we then apply to the system and get noisy measurements \(y^{i}_{k}\) of the reward function and safety functions during the iteration. We use the index \(k\) to refer to the algorithm iteration. Even though \(k\) and \(t\) might differ in principle, in practice we run one algorithm iteration \(k\) for each time step \(t\).

**Assumption 2.2**.: Observations \(y^{i}_{k}=h(\mathbf{x}_{k},t,i)+\varepsilon^{i}_{k},\ \forall i\in\mathcal{I},\ t\in\mathbb{N}\) are perturbed by i.i.d. zero mean and \(\sigma\)-sub-Gaussian noise.

Based on the measurements, we compute the posterior GP and make the decision for the next time step. To start the exploration, an initial set of safe decisions is assumed to be available to the algorithm. To ensure that the safe set remains non-empty after the first iteration, it is necessary that the initial safety function values at every decision within the initial safe set are positive.

**Assumption 2.3**.: An initial set \(S_{0}\subseteq\mathcal{X}\) of safe decisions is known and for all decisions \(\mathbf{x}\in S_{0}\), we have \(c_{i}(\mathbf{x},0)>0,\ \forall i\in\mathcal{I}_{c}\).

Similar assumptions have also been made for the standard SAFEOPT algorithm [7] and are necessary to ensure feasibility of the exploration steps and to be able to identify new safe decision.

### Safety Updates

To ensure safety, based on Assumption 2.1 and 2.2, we extend the definition of the confidence intervals from [7] so that, with high probability, they contain \(f\) and \(c_{i}\) using the posterior GP estimate given the data sampled so far. The confidence intervals for \(h(\mathbf{x},t,i)\) given training samples until iteration \(k\geq 1\) are defined for all \(\mathbf{x}\in\mathcal{X}\) and for all \(i\in\mathcal{I}\) as

\[Q_{k}(\mathbf{x},i):=\left[\mu_{k-1}(\mathbf{x},i)\pm\sqrt{\beta_{k}}\sigma_{k -1}(\mathbf{x},i)\right],\] (3)

where \(\beta_{k}\) is a scalar that determines the desired confidence interval, \(\mu_{k-1}(\mathbf{x},i)\) and \(\sigma_{k-1}(\mathbf{x},i)\) are the posterior mean and standard deviation of \(h(\mathbf{x},t,i)\) inferred with \(\mathcal{D}_{k}\), training samples till iteration \(k\)[31]. The probability of the true function value \(h\) lying within this interval depends on the choice of \(\beta_{k}\)[8]. We provide more details for this choice in Section 2.4.

We now construct a tighter confidence interval for \(h(\mathbf{x},t,i)\) by using the sequence \(\{Q_{\tau}(\mathbf{x},i)\}_{\tau\leq k}\) instead of \(Q_{k}(\mathbf{x},i)\) alone. To this end, we recursively define for all \(\mathbf{x}\in\mathcal{X}\) and for all \(i\in\mathcal{I}\) the intersection

\[C_{k}(\mathbf{x},i):=(C_{k-1}(\mathbf{x},i)\oplus[-L(t-1),L(t-1)])\cap Q_{k}( \mathbf{x},i),\] (4)

where \(\oplus\) denotes the Minkowski sum, \(C_{0}(\mathbf{x},i)\) is \([L(0),\infty)\) for all \(\mathbf{x}\in S_{0}\), \(i\in\mathcal{I}_{c}\) and \(\mathbb{R}\) otherwise. We use the lower bound \(l_{k}(\mathbf{x},i):=\min C_{k}(\mathbf{x},i)\) and the upper bound \(u_{k}(\mathbf{x},i):=\max C_{k}(\mathbf{x},i)\), to define the width of \(C_{k}(\mathbf{x},i)\)

\[w_{k}(\mathbf{x},i):=u_{k}(\mathbf{x},i)-l_{k}(\mathbf{x},i)\] (5)

further used to update the safe set as well as pick the next decision to explore.

Based on the updated posterior and Lipschitz constants, we can update the safe set \(S_{k}\) with the lower bounds \(l_{k}\) and the previous safe set \(S_{k-1}\) as

\[S_{k}=\cap_{i\in\mathcal{I}_{c}}\cup_{\mathbf{x}\in S_{k-1}}\left\{\mathbf{x }^{\prime}\in\mathcal{X}\mid l_{k}(\mathbf{x},i)-L_{\mathbf{x}}d(\mathbf{x}, \mathbf{x}^{\prime})-L(t)\geq 0\right\}.\] (6)

The set \(S_{k}\) contains decisions that with high probability fulfill the safety constraints given the GP confidence intervals and the Lipschitz constants. In contrast to SAFEOPT, the safe set of TVSAFEOPT is allowed to shrink to adapt to the potential change of the safe region given the time-varying setting. However, the safe set might even become empty after the update. This is either because the safe region indeed becomes empty or because the updated safe set conservatively excludes all decisions with a lower bound of some safety function below \(L\) to guarantee safety. In all these cases, if the updated safe set is empty, we terminate the algorithm.

### Safe Exploration and Exploitation

With the safe set updated, the next challenge is to trade off between exploitation and expansion of the safe region. As in the standard SAFEOPT, the potential maximizers are those decisions, for which the upper confidence bound of the reward function is higher than the largest lower confidence bound

\[M_{k}=\left\{\mathbf{x}\in S_{k}\mid u_{k}(\mathbf{x},0)\geq\max_{\mathbf{x} ^{\prime}\in S_{k}}l_{k}(\mathbf{x}^{\prime},0)\right\}.\] (7)

To identify the potential expanders, \(G_{k}\), containing all decisions that could potentially expand the safe set, we first quantify the potential enlargement of the current safe set after sampling a new decision \(\mathbf{x}\). To do so, we define the function

\[e_{k}(\mathbf{x}):=|\{\mathbf{x}^{\prime}\in\mathcal{X}\backslash S_{k}\mid \exists i\in\mathcal{I}_{c}:u_{k}(\mathbf{x},i)-L_{\mathbf{x}}d(\mathbf{x}, \mathbf{x}^{\prime})-L(t)\geq 0\}|,\] (8)

where \(|\cdot|\) refers to the cardinality of a set, and then update

\[G_{k}=\left\{\mathbf{x}\in S_{k}\mid e_{k}(\mathbf{x})>0\right\}.\] (9)

At iteration \(k\), TVSAFEOPT selects a decision \(\mathbf{x}_{k}\) within the union of potential maximizers (7) and expanders (9)

\[\mathbf{x}_{k}=\operatorname*{arg\,max}_{\mathbf{x}\in G_{k}\cup M_{k},i\in \mathcal{I}}w_{k}(\mathbf{x},i),\] (10)with \(w_{k}\) from (5). The objective of the greedy selection process in (10) is to take the most uncertain decision among the expanders \(G_{k}\) and the maximizers \(M_{k}\). The decision \(\mathbf{x}_{k}\) is then applied to the system and after making observations of the reward and safety functions, \(\mathbf{y}_{k}:=(y_{k}^{0},y_{k}^{1},\ldots,y_{k}^{m})\), we add \((\mathbf{x}_{k},\mathbf{y}_{k})\) to the training samples.

At any iteration, we can obtain an estimate for the current best decisions from

\[\hat{\mathbf{x}}_{k}=\operatorname*{arg\,max}_{\mathbf{x}\in S_{k}}l_{k}( \mathbf{x},0),\] (11)

which returns the maximizer of the lower bound of the reward function within the current safe set.

### Safety Guarantee

To provide safety guarantees, we need the confidence intervals in (3) to contain the safety functions with high probability for all iterations. Note that the parameter \(\beta_{k}\) in (3) tunes the tightness of the confidence interval. The following lemma guides us to make a proper choice for \(\beta_{k}\): This choice depends on the information capacity \(\gamma_{k}^{h}\) associated with the kernel \(\kappa\), namely is the maximal mutual information [33] we can obtain from the GP model of \(h\) through \(k\) noisy measurements \(\hat{h}_{\mathbf{X}_{k}}\) at data points \(\mathbf{X}_{k}:=\{(\mathbf{x}_{\tau}\in\mathcal{X},\tau,i_{\tau}\in\mathcal{ I})\}_{\tau<k}\)

\[\gamma_{k}^{h}:=\max_{\mathbf{X}_{k}}I(\hat{h}_{\mathbf{X}_{k}};h).\] (12)

**Lemma 2.4**.: _Assume that \(h(\mathbf{x},t,i)\) has RKHS norm associated with \(\kappa\) bounded by \(B>0\) and that measurements are perturbed by \(\sigma\)-sub-Gaussian noise. Let the variable \(\gamma_{k}^{h}\) be defined as in (12). For any \(\delta\in(0,1)\), let \(\sqrt{\beta_{k}}=B+\sigma\sqrt{2\left(\gamma_{k\cdot|\mathcal{I}}^{h}+1+\ln( 1/\delta)\right)}\), then the following holds for all decisions \(\mathbf{x}\in\mathcal{X}\), function indices \(i\in\mathcal{I}\), and iterations \(k\geq 1\) jointly with probability at least \(1-\delta\):_

\[|h(\mathbf{x},t,i)-\mu_{k-1}(\mathbf{x},i)|\leq\sqrt{\beta_{k}}\sigma_{k-1}( \mathbf{x},i).\]

Proof.: This lemma is a straightforward consequence of Lemma 1 of [16], a contextual extension of Lemma 4.1 of [8]. We can prove it by selecting time as the context and picking \(\{t\}_{t\geq 1,t\in\mathbb{N}}\) as the context sequence.

Lemma 2.4 indicates that, by selecting \(\beta_{k}\) properly, the confidence intervals \(Q_{k}\) will w.h.p. contain the reward function and the safety functions. Due to this, they can be leveraged to provide theoretical guarantees for safety and optimality.

The following theorem provides a sufficient condition for safety of TVSAFEOPT.

**Theorem 2.5**.: _Let Assumptions 2.1 - 2.3 hold, and let \(\gamma_{k}^{h}\) be defined as in (12). For any \(\delta\in(0,1)\), let \(\sqrt{\beta_{k}}=B+\sigma\sqrt{2\left(\gamma_{k\cdot|\mathcal{I}}^{h}+1+\ln(1/ \delta)\right)}\), then TVSAFEOPT guarantees that with probability at least \(1-\delta\), for all \(i\in\mathcal{I}_{c}\) and for all \(t\geq 0,\) and \(\mathbf{x}\in S_{k}\) it holds \(c_{i}(\mathbf{x},t)\ \geq\ 0.\)_

The proof builds on Lemma 2.4 to show first that for all \(t\geq 0\), for all \(i\in\mathcal{I}\) and for all \(\mathbf{x}\in\mathcal{X},\) then \(h(\mathbf{x},t,i)\in C_{k}(\mathbf{x},i)\) with high probability. Then using the recursive definition of the safe set from (6), we obtain w.h.p. \(c_{i}(\mathbf{x},t)\ \geq\ l_{k}(\mathbf{x}^{\prime},i)-L_{\mathbf{x}}d( \mathbf{x},\mathbf{x}^{\prime})-L(t)\geq\ 0,\) which concludes the proof. For details we refer the reader to Appendix B.

### Near-Optimality Guarantee

In many safety critical real world applications, such as nuclear power plant operations, medical devices calibration, automated emergency response systems, the reward function is stationary most of the time. The problems are stationary until some changes happen and become stationary again when the systems reach new equilibria [34]. However, ensuring optimality is non-trivial even when the problem becomes stationary. Suppose the auxiliary function (2) becomes stationary in a time interval \([\underline{\phi},\overline{\phi}]\), namely suppose there exist \(\overline{\phi}>\underline{\phi}\geq 1\) such that \(\forall t_{1},t_{2}\in[\underline{\phi},\overline{\phi}],f(\mathbf{x},t_{1})=f (\mathbf{x},t_{2})=:\bar{f}(\mathbf{x})\) and \(c(\mathbf{x},t_{1})=c(\mathbf{x},t_{2})=:\bar{c}(\mathbf{x})\), so that the optimization problem (1) becomes

\[\max_{\mathbf{x}\in\mathcal{X}}\bar{f}(\mathbf{x})\] (13) subject to \[\bar{c}_{i}(\mathbf{x})\geq 0,\ i\in\mathcal{I}_{c}.\]

We first define the largest safe set expanded from a set \(S\) subject to a measurement error \(a\) within

* a single time step: \[R_{a}(S):=S\cup\{\mathbf{x}\in\mathcal{X}\mid\forall i\in\mathcal{I}_{c}, \exists\mathbf{x}_{i}^{\prime}\in S,s.t.\ \bar{c}_{i}\left(\mathbf{x}_{i}^{\prime}\right)-L_{ \mathbf{x}}d(\mathbf{x},\mathbf{x}_{i}^{\prime})-a\geq 0\}\]
* \(n\) time steps: \(R_{a}^{n}(S):=\underbrace{R_{a}\left(R_{a}\ldots R_{a}\left(R_{a}\left(S \right)\right)\right)\ldots}_{n\text{ times}}\)) \(\ldots)\)
* arbitrary time steps: \(\bar{R}_{a}(S):=\lim_{n\rightarrow\infty}R_{a}^{n}(S)\)

We also define \(\bar{L}_{\mathrm{t}}\) as an upper bound of the sum of all time Lipschitz constants, that is, \(\sum\limits_{\tau=0}^{T-1}L(\tau)\leq\bar{L}_{\mathrm{t}}\).

We find it reasonable that a tight upper bound \(\bar{L}_{\mathrm{t}}\) can be provided when the underlying system slowly switches to the new stationarity condition.

Given these definitions, we are now in the position to provide optimality guarantees for TVSAFEOPT. In particular, we aim at comparing the found reward value \(\bar{f}(\mathbf{x}_{k})\) with the optimal reward value within the largest safe set obtained in ideal conditions with no measurement error, \(\bar{R}_{0}(S_{0})\). We also aim at providing TVSAFEOPT with an upper bound on the iterations needed to find a near-optimal solution. The following theorem states the optimality guarantee of TVSAFEOPT.

**Theorem 2.6**.: _Let Assumptions 2.1 - 2.3 hold, let \(\gamma_{k}^{h}\) be defined as in (12) and, for any \(\delta\in(0,1)\), let \(\sqrt{\beta_{k}}=B+\sigma\sqrt{2\left(\gamma_{k\cdot|\mathcal{I}}^{h}+1+\ln(1/ \delta)\right)}\). Define \(\hat{\mathbf{x}}_{k}\) as in (11), and, for any \(\epsilon>0\), let \(k^{*}(\epsilon,\delta)\) be the smallest positive integer satisfying_

\[\frac{k^{*}}{\beta_{k^{*}}\gamma_{k^{*}}^{h}}\geq\frac{b_{1}\left(\left|\bar{ R}_{0}\left(S_{0}\right)\right|+1\right)}{\epsilon^{2}},\]

_where \(b_{1}=8/\log\left(1+\sigma^{-2}\right)\). Then, the TVSAFEOPT algorithm, applied to (13), guarantees that, with probability at least \(1-\delta\), there exists \(k\leq k^{*}\) such that_

\[\bar{f}\left(\hat{\mathbf{x}}_{k}\right)\geq\max_{\mathbf{x}\in R_{\epsilon+ \mathcal{I}_{\mathrm{t}}}\left(S_{0}\right)}\bar{f}(\mathbf{x})-\epsilon.\]The proof consists in showing a decaying upper bound of uncertainty \(w_{k}(\mathbf{x},i)\leq\epsilon\) and exploiting local stationarity of (13) to provide bounds on the expansion of the safe set \(S_{k}\). Details can be found in Appendix C.

## 3 Experiments

### Synthetic Example

We first illustrate TVSAFEOPT on a synthetic two-dimensional time-varying optimization problem

\[\max_{x,y}-e^{x^{2}}-\log(1+y^{2})+0.01t\] \[\text{s.t.}\ \left[x+0.5-0.5\left(1-\cos\frac{2\pi}{50}t\right) \cos\frac{\pi}{6}\right]^{2}+\left[y-0.3-0.5\left(1-\cos\frac{2\pi}{50}t\right) \sin\frac{\pi}{6}\right]^{2}\leq 1.\]

Figure 1 compares the safe sets computed by TVSAFEOPT, ETSAFEOPT, and SAFEOPT at \(t=30\), \(t=100\) and \(t=170\). All algorithms start from the same singleton initial safe set \(S_{0}=\{(-0.5,0.0)\}\). Implementation details are described in Appendix A. Figure 1 illustrates that the safe sets computed by TVSAFEOPT are contained in the ground truth safe regions while those computed by SAFEOPT and ETSAFEOPT have multiple violations. Due to the dependence on time of the example (Figure 3), the initial safe set becomes unsafe at \(t=30,\text{ and }t=170\). Taking the possible changes in time into consideration, TVSAFEOPT correctly identifies the possible unsafety of the initial safe set. In contrast, SAFEOPT always consider the initial safe set to be safe. Meanwhile, ETSAFEOPT correctly identifies the lack of safety of the initial safe set at \(t=30\), but fails at \(t=170\). This is because the event trigger is naturally insensitive to continuous changes. This toy example indicates that, in contrast to SAFEOPT and ETSAFEOPT, TVSAFEOPT safely adapts to the time changes of the optimization problem.

In this example, TVSAFEOPT and ETSAFEOPT overall find better reward function values than SAFEOPT, see Figure 3. The reward function value found by TVSAFEOPT is close to the optimal values when the reward function changes slowly, which supports Theorem 2.6.

Quantitative metrics are listed in Table 2. Taking SAFEOPT as a baseline, TVSAFEOPT and ETSAFEOPT achieves less violations, lower cumulative regret at the cost of covering less part of the safe region. Furthermore, TVSAFEOPT has little violations, and achieves larger coverage ratio than ETSAFEOPT. Meanwhile, its cumulative regret is just slightly higher than that of ETSAFEOPT.

Figure 2: Comparison between TVSAFEOPT, SAFEOPT, and approximate optimization on the gas compressor case study, showing average of 10 repetitions with different initial sets. (a): The cardinality of the safe sets, (b): The ratio between the number of unsafe decisions in the safe sets and the cardinality of the safe sets, (c): The ratio between the number of safe decisions in the safe sets and the cardinality of the ground truth safe regions. TVSAFEOPT robustly shrinks its safe sets based on its observations and thus maintains much less violations in its safe sets than SAFEOPT and approximate optimization, at the cost of covering less of the ground truth safe region.

### Gas Compressor Case Study

#### 3.2.1 Problem Setup

We show the performance of the proposed algorithm in a compressor station with three identical compressors operating in parallel at the time-varying compressor head \(H_{t}\) with time-varying power consumption at time \(t\) (adapted from [35], details in Appendix A.3)

\[\min_{m_{i}} \sum_{i=1}^{N}\frac{1}{1-d_{it}}\left(\alpha_{1}+\alpha_{2}\tilde{ m}_{i}+\alpha_{3}\tilde{H}_{t}+\alpha_{4}\tilde{m}_{i}^{2}+\alpha_{5}\tilde{m}_{i} \tilde{H}_{t}+\alpha_{6}\tilde{H}_{t}^{2}\right)\] (14) s.t. \[\sum_{i=1}^{N}m_{i}\geq M_{t}\] (15) \[m_{i}\geq \beta_{1}\tilde{H}_{t}^{2}+\beta_{2}\tilde{H}_{t}+\beta_{3}\, \forall i=1,\ldots,N\] (16) \[m_{i}\geq \gamma_{1}\tilde{H}_{t}^{2}+\gamma_{2}\tilde{H}_{t}+\gamma_{3}\, \forall i=1,\ldots,N\] \[m_{i}\leq \delta_{1}\tilde{\tilde{H}}_{t}+\delta_{2}\,\forall i=1,\ldots,N\] \[m_{i}\leq \sigma_{1}\tilde{\tilde{H}}_{t}^{2}+\sigma_{2}\tilde{\tilde{H}} _{t}+\sigma_{3}\,\forall i=1,\ldots,N,\] (17)

where the objective (14) corresponds to the power to run the station with \(N\) compressors, here \(N=3\), affected by individual degradation \(d_{it}\), \(i=1,l\ldots,N\). The station must also satisfy time-varying demand \(M_{t}\) in (15). In practice, it is common to linearly approximate (16)-(17) with respect to the compressor head \(H_{t}\) (dashed lines in Figure 4) [36].

#### 3.2.2 Results

We compare the performance of TVSAFEOPT, SAFEOPT, and approximate optimization. ETSAFEOPT is not applicable to this case study because the magnitude of changes in the demand \(M_{t}\), compressor head \(H_{t}\), and degradation \(d_{it}\) keeps triggering the event trigger and thus the maintained safe set becomes empty very quickly. Implementation details are described in Appendix A. Figure 2 compares the number of unsafe decisions in the safe sets calculated by TVSAFEOPT, SAFEOPT, and approximate optimization. We see that, by considering the uncertainty with respect to the decision variables, SAFEOPT maintains fewer unsafe decisions in its safe sets than the approximate optimization. However, SAFEOPT tends to expand its safe sets regardless of external changes. TVSAFEOPT further improves this based on SAFEOPT by taking into consideration the time-varying safety functions. TVSAFEOPT robustly shrinks its safe sets based on its observations and thus maintains much

\begin{table}
\begin{tabular}{l l l} \hline  & ETSAFEOPT & TVSAFEOPT \\ \hline Violations & -84.4\% \(\pm\) 1.7 \% & -99.99\% \(\pm\) 0.01\% \\ Coverage Ratio & -30.9\% \(\pm\) 2.9 \% & -21.0\% \(\pm\) 1.3\% \\ Cumulative Regret & -73.6\% \(\pm\) 14.7\% & -66.9\% \(\pm\) 14.4\% \\ \end{tabular}
\end{table}
Table 2: Synthetic example: comparison of TVSAFEOPT and ETSAFEOPT with respect to SAFEOPT, showing the average and the standard deviation results from five runs with different initial safe sets (chosen randomly from the feasible space).

\begin{table}
\begin{tabular}{l l l} \hline  & SAFEOPT & TVSAFEOPT \\ \hline Violations & -89.2\% \(\pm\) 4.2 \% & -96.8\% \(\pm\) 1.0\% \\ Coverage Ratio & -35.7\% \(\pm\) 2.6 \% & -61.0\% \(\pm\) 1.3\% \\ Cumulative Regret & +95.8\% \(\pm\) 32.3\% & +178.3\% \(\pm\) 29.2\% \\ \end{tabular}
\end{table}
Table 3: Compressors case study: comparison of TVSAFEOPT and SAFEOPT with respect to Approximate Optimization, showing the average and the standard deviation results from 10 runs with different initial safe sets (chosen randomly from \([x_{0}-0.5/\sqrt{3}d,x_{0}+0.5/\sqrt{3}d]\) where \(x_{0}\) is the initial safe seed and \(d\) is the distance to the boundary of the feasible region). ETSAFEOPT is not included due to its high dependency on event detection methods, which are unavailable for compressor degradation.

less violations in its safe sets than SAFEOPT (70.4%) and approximate optimization (96.8%). It achieves this at the cost of covering less of the ground truth safe region than SAFEOPT (39.3%) and Approximate Optimization (61.0%).

The right-hand side of Figure 3 shows that TVSAFEOPT preserves safety at the expense of optimality. In the compressor case study, TVSAFEOPT overall finds lower reward function values than SAFEOPT and approximate optimization, which is consistent with the fact that it covers a lower fraction of the ground truth safe regions and the reward function changes significantly between iterations. Because of its strong focus on safety, TVSAFEOPT deviates more from the ground truth. The cumulative regret of TVSAFEOPT is above the one of SAFEOPT by 42.1%, and the one of approximate optimization by 178.3%. This illustrates the trade-off between safety and optimality in the presence of strong uncertainties due to the varying reward and safety constraints. Quantitative metrics using Approximate Optimization as the baseline are listed in Table 3.

## 4 Limitations and Conclusion

**Limitations** The compressor case study demonstrated that TVSAFEOPT ensures safety at the expense of optimality if the stationarity assumption is not satisfied. The assumption about the local stationarity of the optimization problem (1) is thus the main limitation. Even though TVSAFEOPT demonstrates good empirical performance with respect to safety even when the problem is non-stationary, theoretical guarantee for its near-optimality in the non-stationary case warrant further investigation.

The need for obtaining the Lipschitz constants with respect to both \(\mathbf{x}\) and \(t\) in order to compute the safe set \(S_{k}\) in (6) may prove limiting in real applications. To overcome this limitation, we propose practical modifications in Appendix A.1.

**Conclusions** We propose TVSAFEOPT algorithm, which extends SAFEOPT to handle time-varying optimization problems. In conclusion, TVSAFEOPT outperforms SAFEOPT in terms of adaptation to changes in time and maintains fewer unsafe decisions in its safe sets for time-varying problems. This is at the cost of covering less of the ground truth safe regions and may lead to poorer performance in terms of optimality.

We prove the safety guarantee for TVSAFEOPT in the general time-varying setting and prove its near-optimality guarantee for the case in which the optimization problem becomes stationary. The two theoretical results together guarantee that TVSAFEOPT is capable of safely transferring safety of the decisions into the future and, based on the transferred safe sets, it will find the near-optimal decision when the reward function stops changing. We show that TVSAFEOPT performs well in practice for the most general settings where both the reward function and the safety constraint are time-varying, both on synthetic data and for real case study on a gas compressor.

Figure 3: Comparison of reward functions from different methods with different initial safe sets, averaged over 5 runs for the synthetic example (left) and 10 runs for the compressor case study (right, indicating power in MW obtained from maximization of (14)), with error bars, with respect to the optimal values (black). In the synthetic example, TVSAFEOPT finds better reward function values than SAFEOPT, and similar to these of ETSAFEOPT. In the compressor case study, TVSAFEOPT finds lower reward function values than SAFEOPT, but guarantees fewer violations (Table 2 and 3) than either SAFEOPT or Approximate Optimization.

## Acknowledgments and Disclosure of Funding

Research supported by NCCR Automation, National Centre of Competence in Research, funded by the Swiss National Science Foundation (grant no. 180545). Marta Zagorowska also acknowledges funding from the Marie Curie Horizon Postdoctoral Fellowship project RELIC (grant no 101063948) for writing, revisions, and the compressor case study. Alisa Rupenyan acknowledges also support from the Johann Jakob Rieter foundation.

## References

* [1] Daniel Lizotte, Tang Wao, Michael Bowling, and Dale Schuurmans. Automatic gait optimization with Gaussian process regression. _International Joint Conference on Artificial Intelligence_, pages 944-949, 2007.
* [2] Ruben Martinez-Cantin, Nando de Freitas, Arnaud Douchet, and Jose A. Castellanos. Active policy learning for robot planning and exploration under uncertainty. _In Proceedings Robotics: Science and Systems_, pages 321-328, 2007.
* [3] Ziyu Wang, Masrour Zoghi, Frank Hutter, David Matheson, and Nando de Freitas. Bayesian optimization in high dimension via random embeddings. _International Joint Conference on Artificial Intelligence_, pages 1778-1784, 2013.
* [4] Niranjan Srinivas, Andreas Krause, Sham M. Kakade, and Matthias Seeger. Gaussian process optimization in the bandit setting: No regret and experimental design. _International Joint Conference on Machine Learning_, pages 1015-1022, 2010.
* [5] Matthew Hoffman, Bobak Shahriari, and Nando de Freitas. On correlation and budget constraints in model-based bandit optimization with application to automatic machine learning. _International Conference on Artificial Intelligence and Statistics_, pages 365-374, 2014.
* [6] Jasper Snoek, Hugo Larochelle, and Ryan P. Adams. Practical Bayesian optimization of machine learning algorithms. _In Proceedings of Advances in Neural Information Processing Systems_, pages 2951-2959, 2012.
* [7] Yanan Sui, Alkis Gotovos, Joel Burdick, and Andreas Krause. Safe exploration for optimization with Gaussian processes. In _International conference on machine learning_, pages 997-1005. PMLR, 2015.
* [8] Felix Berkenkamp, Andreas Krause, and Angela P Schoellig. Bayesian optimization with safety constraints: safe and automatic parameter tuning in robotics. _Machine Learning_, pages 1-35, 2021.
* [9] Yanan Sui, Vincent Zhuang, Joel Burdick, and Yisong Yue. Stagewise safe Bayesian optimization with Gaussian processes. In _International conference on machine learning_, pages 4781-4789. PMLR, 2018.
* [10] Matteo Turchetta, Felix Berkenkamp, and Andreas Krause. Safe exploration for interactive machine learning. _Advances in Neural Information Processing Systems_, 32, 2019.
* [11] Dominik Baumann, Alonso Marco, Matteo Turchetta, and Sebastian Trimpe. GoSafe: Globally optimal safe robot learning. In _2021 IEEE International Conference on Robotics and Automation (ICRA)_, pages 4452-4458. IEEE, 2021.
* [12] Bhavya Sukhija, Matteo Turchetta, David Lindner, Andreas Krause, Sebastian Trimpe, and Dominik Baumann. GoSafeOpt: Scalable safe exploration for global optimization of dynamical systems. _Artificial Intelligence_, page 103922, 2023.
* [13] Alessandro G. Bottero, Carlos E. Luis, Julia Vinogradska, Felix Berkenkamp, and Jan Peters. Information-theoretic safe Bayesian optimization, 2024.
* [14] Jonas Hubotter, Bhavya Sukhija, Lenart Treven, Yarden As, and Andreas Krause. Information-based transductive active learning. _arXiv preprint arXiv:2402.15898_, 2024.

* [15] Marta Zagorowska, Efe C. Balta, Varsha Behrunani, Alisa Rupenyan, and John Lygeros. Efficient sample selection for safe learning. _IFAC-PapersOnLine_, 56(2):10107-10112, 2023. 22nd IFAC World Congress.
* [16] Daniel Widmer, Dongho Kang, Bhavya Sukhija, Jonas Hubotter, Andreas Krause, and Stelian Coros. Tuning legged locomotion controllers via safe Bayesian optimization. In _7th Annual Conference on Robot Learning (CoRL), 6-9 November, Atlanta, GA_, 2023. URL https://proceedings.mlr.press/v229/widmer23a.html.
* [17] Christopher Konig, Mikos Ozols, Anastasia Makarova, Efe C. Balta, Andreas Krause, and Alisa Rupenyan. Safe risk-averse Bayesian optimization for controller tuning. _IEEE Robotics and Automation Letters_, 8(12):8208-8215, 2023.
* [18] Andreas Krause and Cheng Ong. Contextual Gaussian process bandit optimization. _Advances in neural information processing systems_, 24, 2011.
* [19] Niranjan Srinivas, Andreas Krause, Sham Kakade, and Matthias Seeger. Gaussian process optimization in the bandit setting: no regret and experimental design. In _Proceedings of the 27th International Conference on International Conference on Machine Learning_, ICML'10, page 1015-1022, Madison, WI, USA, 2010. Omnipress.
* [20] Marcello Fiducioso, Sebastian Curi, Benedikt Schumacher, Markus Gwerder, and Andreas Krause. Safe contextual bayesian optimization for sustainable room temperature PID control tuning. In _Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19_, pages 5850-5856. International Joint Conferences on Artificial Intelligence Organization, 7 2019.
* [21] Christopher Konig, Matteo Turchetta, John Lygeros, Alisa Rupenyan, and Andreas Krause. Safe and efficient model-free adaptive control via Bayesian optimization. In _2021 IEEE International Conference on Robotics and Automation (ICRA)_, pages 9782-9788. IEEE, 2021.
* [22] Antonia Holzapfel, Paul Brunzema, and Sebastian Trimpe. Event-triggered safe Bayesian optimization on quadcopters. In Alessandro Abate, Mark Cannon, Kostas Margellos, and Antonis Papachristodoulou, editors, _Proceedings of the 6th Annual Learning for Dynamics & Control Conference (L4DC), 15-17 July, Oxford, UK_, volume 242 of _Proceedings of Machine Learning Research_, pages 1033-1045. PMLR, 15-17 Jul 2024.
* [23] Ilija Bogunovic, Jonathan Scarlett, and Volkan Cevher. Time-varying Gaussian process bandit optimization. In _Artificial Intelligence and Statistics_, pages 314-323. PMLR, 2016.
* [24] Paul Brunzema, Alexander von Rohr, Friedrich Solowjow, and Sebastian Trimpe. Event-triggered time-varying Bayesian optimization. _arXiv preprint arXiv:2208.10790_, 2022.
* [25] Kihyuk Hong, Yuhang Li, and Ambuj Tewari. An optimization-based algorithm for non-stationary kernel bandits without prior knowledge. In _International Conference on Artificial Intelligence and Statistics_, pages 3048-3085. PMLR, 2023.
* [26] Xingyu Zhou and Ness Shroff. No-regret algorithms for time-varying Bayesian optimization. In _2021 55th Annual Conference on Information Sciences and Systems (CISS)_, pages 1-6. IEEE, 2021.
* [27] Yuntian Deng, Xingyu Zhou, Baekjin Kim, Ambuj Tewari, Abhishek Gupta, and Ness Shroff. Weighted Gaussian process bandits for non-stationary environments. In _International Conference on Artificial Intelligence and Statistics_, pages 6909-6932. PMLR, 2022.
* [28] Dinesh Krishnamoorthy and Francis J Doyle. Safe Bayesian optimization using interior-point methods--applied to personalized insulin dose guidance. _IEEE Control Systems Letters_, 6:2834-2839, 2022.
* [29] Dinesh Krishnamoorthy and Francis J Doyle III. Model-free real-time optimization of process systems using safe Bayesian optimization. _AIChE Journal_, 69(4):e17993, 2023.

* [30] Lukas Hewing, Kim P Wabersich, Marcel Menner, and Melanie N Zeilinger. Learning-based model predictive control: Toward safe learning in control. _Annual Review of Control, Robotics, and Autonomous Systems_, 3:269-296, 2020.
* [31] Carl Edward Rasmussen and Chris Williams. _Gaussian Processes for Machine Learning_. Adaptive Computation and Machine Learning. MIT Press, Cambridge, MA, USA, January 2006.
* [32] Bernhard Scholkopf and Alexander J Smola. _Learning with kernels: support vector machines, regularization, optimization, and beyond_. The MIT Press, 2002.
* [33] Thomas M Cover. _Elements of information theory_. John Wiley & Sons, 1999.
* [34] Michael Vogt and Holger Dette. Detecting gradual changes in locally stationary processes. _The Annals of Statistics_, 43(2):713-740, 2015.
* [35] Marta Zagorowska and Nina F. Thornhill. Influence of compressor degradation on optimal load-sharing. _Computers and Chemical Engineering_, 143(5):107104, 2020.
* [36] Andrea Cortinovis, Joachim Ferreau, Daniel Lewandowski, and Mehmet Mercangoz. Experimental evaluation of MPC-based anti-surge and process control for electric driven centrifugal gas compressors. _Journal of Process Control_, 34:13-25, 2015.
* [37] Felix Berkenkamp, Angela P Schoellig, and Andreas Krause. Safe controller optimization for quadrotors with Gaussian processes. In _2016 IEEE International Conference on Robotics and Automation (ICRA), 16-21 May, Stockholm, Sweden_, pages 491-496. IEEE, 2016.
* [38] Rainer Kurz, Matt Lubomirsky, and Klaus Brun. Gas compressor station economic optimization. _International Journal of Rotating Machinery_, 2012:Article ID 715017, 9 pages, 2012.
* [39] Predrag Milosavljevic, Alejandro G. Marchetti, Andrea Cortinovis, Timm Faulwasser, Mehmet Mercangoz, and Dominique Bonvin. Real-time optimization of load sharing for gas compressors in the presence of uncertainty. _Applied Energy_, 272:114883, 2020.
* [40] Marta Zagorowska. _Degradation modelling in process control applications_. PhD thesis, Imperial College London, 2020. available at https://spiral.imperial.ac.uk/handle/10044/1/105173, online 22 May 2024.
* [41] Do Won Kang and Tong Seop Kim. Model-based performance diagnostics of heavy-duty gas turbines using compressor map adaptation. _Applied Energy_, 212:1345-1359, 2018.
* [42] Andrea Cortinovis, Mehmet Mercangoz, Matteo Zovadelli, Diego Pareschi, Antonio De Marco, and Sergio Bittanti. Online performance tracking and load sharing optimization for parallel operation of gas compressors. _Computers & Chemical Engineering_, 88:145-156, 5 2016.
* [43] Ayman Al Zawaadeh, Khalifa Al Hosani, Igor Boiko, and Mohammad Luai Hammadih. Minimum energy adaptive load sharing of parallel operated compressors. _IEEE Open Journal of Industry Applications_, 3:178-191, 2022.
* [44] Vibeke Sterkebye Norstebo. _Optimum Operation of Gas Export Systems_. PhD thesis, Norwegian University of Science and Technology, 2008.
* [45] Rainer Kurz and Klaus Brun. Degradation of gas turbine performance in natural gas service. _Journal of Natural Gas Science and Engineering_, 1(3):95-102, 2009.
* [46] Yiuguang Li and Pannawat Nikitsaranont. Gas turbine performance prognostic for condition-based maintenance. _Applied Energy_, 86(10):2152-2161, October 2009. ISSN 0306-2619.
* [47] Matteo Cicciotti. _Adaptive Monitoring of Health-state and Performance of Industrial Centrifugal Compressors_. PhD thesis, Imperial College London, 2015.
* [48] Marta Zagorowska, Frederik Schulze Spuntrup, Arne-Marius Ditlefsen, Lars Imsland, Erling Lunde, and Nina F. Thornhill. Adaptive detection and prediction of performance degradation in off-shore turbomachinery. _Applied Energy_, 268:p. 114934, 2020.

* [49] Yu-Zhi Chen, Xu-Dong Zhao, Heng-Chao Xiang, and Elias Tsoutsanis. A sequential model-based approach for gas turbine performance diagnostics. _Energy_, 220:119657, 2021-04. ISSN 0360-5442.
* [50] Wenjie Xu, Yuning Jiang, Bratislav Svetozarevic, and Colin Jones. Constrained efficient global optimization of expensive black-box functions. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors, _Proceedings of the 40th International Conference on Machine Learning_, volume 202 of _Proceedings of Machine Learning Research_, pages 38485-38498. PMLR, 23-29 Jul 2023.
* [51] Wenjie Xu, Yuning Jiang, Bratislav Svetozarevic, and Colin N Jones. Primal-dual contextual bayesian optimization for control system online optimization with time-average constraints. In _2023 62nd IEEE Conference on Decision and Control (CDC)_, pages 4112-4117. IEEE, 2023.

Experiment Details

Experiments are conducted on an Intel i7-11370H CPU using Python 3.8.5. The implementation utilizes the following libraries: GPy 1.12.0, NumPy 1.22.0, and Matplotlib 3.5.0.

### Practical Modifications

In practice, Lipschitz constants are difficult to estimate. Thus, here we provide a Lipschitz-constant-free version of TVSAFEOPT algorithm by modifying (6) and (8).

The safe set is updated as all decisions with non-negative lower confidence bounds for the safety functions at the current iteration \(k\), that is,

\[S_{k}=\left\{\mathbf{x}\in\mathcal{X}\mid\forall i\in\mathcal{I}_{c},l_{k}( \mathbf{x},i)\geq 0\right\}.\] (18)

Furthermore, the expanders are intuitively defined as decisions within the current safe set such that, by evaluating any of the decisions, at least one decision outside the current safe set will be considered as safe, that is, \(G_{k}=\left\{\mathbf{x}\in S_{k}\mid e_{k}(\mathbf{x})>0\right\}\), where \(e_{k}(\mathbf{x})\) denotes the number of decisions outside \(S_{k}\) that will be considered safe when evaluating \(\mathbf{x}\). Instead of using Lipschitz constants, we define \(e_{k}(\mathbf{x})\) using lower bound of auxiliary GP similar to the method by Berkenkamp et al. [37]

\[e_{k}(\mathbf{x})=\left|\left\{\mathbf{x}^{\prime}\in\mathcal{D}\backslash S _{k}\mid\exists i\in\mathcal{I}_{c}:l_{k,(\mathbf{x},u_{k}(\mathbf{x},i))} \left(\mathbf{x}^{\prime},k+1,i\right)\geq 0\right\}\right|,\]

where \(l_{k,(\mathbf{x},u_{k}(\mathbf{x},i))}\left(\mathbf{x}^{\prime},k+1,i\right)\) denotes the lower bound of the function values at \(\mathbf{x}\) and \(t=k+1\) if \(\mathbf{x}\) is evaluated at the \(k\)-th iteration and the upper bound is observed.

### Synthetic Example

The search space is \(\mathcal{X}=[-2,2]^{2}\), uniformly quantized into \(100\times 100\) points. Both algorithms start with the singleton initial safe set \(\left\{(-0.5,0.0)\right\}\). The measurements are perturbed by i.i.d. Gaussian noise \(\mathcal{N}(0,0.01^{2})\).

The reward function is formulated as: \(f(\mathbf{x},t)=-e^{x^{2}}-\log(1+y^{2})+0.01t\);

The safety function is formulated as: \(c_{1}(\mathbf{x},t)=1-\left[x+0.5-0.5\left(1-\cos\frac{2\pi}{50}t\right)\cos \frac{\pi}{6}\right]^{2}-\left[y-0.3-0.5\left(1-\cos\frac{2\pi}{50}t\right) \sin\frac{\pi}{6}\right]^{2}\).

The hyperparameters of GPs in the synthetic case study are modelled as follows,

* TVSAFEOPT: The reward function and the safety function are modeled by independent GPs with zero mean and spatio-temporal kernel \(\kappa((\mathbf{x},t),(\mathbf{x}^{\prime},t^{\prime}))=\exp\left(-\frac{\| \mathbf{x}-\mathbf{x}^{\prime}\|_{2}^{2}}{2\sigma_{1}^{2}}\right)\cdot\exp \left(-\left(\frac{t-t^{\prime}}{2\sigma_{2}^{2}}\right)\right)\), where \(\sigma_{1}\equiv 1.0\), \(\sigma_{2}=25.0\) for \(f\), and \(\sigma_{2}=15.0\) for \(c_{1}\).
* SAFEOPT: The reward function and the safety function are modeled by independent GPs with zero mean and 2d Gaussian kernel \(\kappa(\mathbf{x},\mathbf{x}^{\prime})=\exp\left(-\frac{\|\mathbf{x}-\mathbf{x }^{\prime}\|_{2}^{2}}{2\sigma_{3}^{2}}\right)\), where \(\sigma_{3}\equiv 1.0\).
* ETSAFEOPT: Hyperparameters for GPs are the same as SAFEOPT. Besides, we choose the sentivity of the event trigger \(\delta\) as 0.01.

### Compressor Case Study

Centrifugal compressors are often used in gas transport networks to deliver the required amount of gas by boosting the pressure in the pipelines. Organised as compressor stations with \(N\) units, the compressors are often operated to minimise their power consumption \(P\) while satisfying the demand \(M_{t}\) and operating constraints, capturing how compressor head \(H_{t}\) depends on the mass flow through the compressor [38, 39]:

* \(\tilde{m}_{i}=\frac{m_{i}-157.4}{34.37}\), \(\tilde{H}_{t}=\frac{H_{t}-1.016e5}{3.210e4}\), \(\alpha_{1}=1.979e7\), \(\alpha_{2}=5.274e6\), \(\alpha_{3}=5.375e6\), \(\alpha_{4}=6.055e5\), \(\alpha_{5}=5.718e5\), \(\alpha_{6}=3.319e5\)* \(\bar{H}_{t}=\frac{H_{t-1.235e^{3}}}{3.764e^{4}}\), \(\beta_{1}=-1.953\), \(\beta_{2}=16.86\), \(\beta_{3}=118.1\)
* \(\bar{\bar{H}}_{t}=\frac{H_{t-6.152e^{4}}}{7002}\), \(\gamma_{1}=-1.516\), \(\gamma_{2}=-11.12\), \(\gamma_{3}=116.9\)
* \(\bar{\bar{\bar{H}}}_{t}=\frac{H_{t-8.706e^{4}}}{5.289e^{4}}\), \(\delta_{1}=73.21\), \(\delta_{2}=183.7\)
* \(\bar{\bar{H}}_{t}=\frac{H_{t-1.572e^{5}}}{2.044e^{4}}\), \(\sigma_{1}=-7.260\), \(\sigma_{2}=-29.65\), \(\sigma_{3}=204.4\)

The compressor case study has been adapted from [35]. The data for the demand, compressor head, and degradation for the three compressors were obtained from [40] (Creative Commons Attribution NonCommercial Licence).

Individual characteristics of compressors in (16)-(17) are called _compressor maps_ (Figure 4). The operating area for a compressor is defined by minimal and maximal speed of the compressor and its mechanical properties. The operating area can be obtained from compressors maps delivered by the manufacturer of the compressor, or estimated during the operation [41]. However, estimation would require collecting datapoints close to the boundary of the operating area, which may be unavailable due to safety consideration [42, 43]. Using safe learning has the potential to improve the operation of the station because it enables safe exploration of the unknown operating area of individual compressors.

Furthermore, varying operating conditions and demand often lead to compressor degradation \(d_{it}\) (Figure 5), over time increasing power consumption (14) of the entire compressor station [45]. Capturing the time-varying aspect of compressor degradation is a subject of research (e.g. [46, 47, 48]) but limited availability of measured degradation data presents a challenge [49].

For convenience, the optimization variables are scaled by a factor \(K=200\), that is, \(\mathbf{x}=(m_{1},m_{2},m_{3})/K\). The search space is \(\mathcal{X}=[50.0/K,250.0/K]^{3}\), uniformly quantized into \(60\times 60\times 60\) points. Both algorithms start with the singleton initial safe set \(\{(M_{0},M_{0}.M_{0})/3K\}\). The measurements are perturbed by i.i.d. Gaussian noise \(\mathcal{N}(0,0.01^{2})\).

The reward function is formulated as:

\[f(\mathbf{x},t)=-\sum_{i=1}^{3}\frac{1}{(1-d_{it})\cdot 10^{7}}\left(\alpha_{1 }+\alpha_{2}\tilde{m}_{i}+\alpha_{3}\tilde{H}_{t}+\alpha_{4}\tilde{m}_{i}^{2 }+\alpha_{5}\tilde{m}_{i}\tilde{H}_{t}+\alpha_{6}\tilde{H}_{t}^{2}\right)\]

The safety functions are formulated as \(c_{i}(x,t)\geq 0\), \(i=1,\ldots,7\), with:

* \(c_{1}(\mathbf{x},t)=x_{1}-L_{t}\)

Figure 4: Ground truth (solid) and linear approximation (dashed) of the operating area from compressor maps, adapted from [44, 35]. For a given compressor head at time \(t\) (dotted horizontal line for \(H_{t}=120000\) J kg\({}^{-1}\)), the mass flow \(m_{it}\) through the \(i\)-th compressor is required to be between minimum speed (red) and surge (blue) lines, and maximum speed (violet) and choke (yellow) lines

* \(c_{2}(\mathbf{x},t)=U_{t}-x_{1}\)
* \(c_{3}(\mathbf{x},t)=x_{2}-L_{t}\)
* \(c_{4}(\mathbf{x},t)=U_{t}-x_{2}\)
* \(c_{5}(\mathbf{x},t)=x_{3}-L_{t}\)
* \(c_{6}(\mathbf{x},t)=U_{t}-x_{3}\)
* \(c_{7}(\mathbf{x},t)=x_{1}+x_{2}+x_{3}-0.67M_{t}/K\),

where \(L_{t}=\max\{\beta_{1}\bar{H}_{t}^{2}+\beta_{2}\bar{H}_{t}+\beta_{3},\gamma_{1 }\bar{H}_{t}^{2}+\gamma_{2}\bar{H}_{t}+\gamma_{3}\}/K\), \(U_{t}=\min\{\delta_{1}\tilde{\bar{H}}_{t}+\delta_{2},\sigma_{1}\bar{\bar{H}}_{ t}^{2}+\sigma_{2}\tilde{\bar{H}}_{t}+\sigma_{3}\}/K\).

The hyperparameters of GPs in the compressor case study are modelled as follows,

* \(c_{6}\), and \(\sigma_{2}=70.0\) for \(c_{7}\).
* SAFEOPT: The reward function and the safety functions are modeled by independent GPs with zero mean and 3d Gaussian kernel \(\kappa(\mathbf{x},\mathbf{x}^{\prime})=\exp\left(-\frac{\|\mathbf{x}-\mathbf{ x}^{\prime}\|_{2}^{2}}{2\sigma_{3}^{2}}\right)\), where \(\sigma_{3}\equiv 1.0\).

As for approximate optimization, the r.h.s. of (16) - (17) are linearly approximated as follows:

* Surge line: \(\beta_{1}\bar{H}_{t}^{2}+\beta_{2}\bar{H}_{t}+\beta_{3}\approx 4.481e-4\cdot H _{t}+59.76\)
* Min. speed line: \(\gamma_{1}\bar{H}_{t}^{2}+\gamma_{2}\bar{H}_{t}+\gamma_{3}\approx-1.333e-3 \cdot H_{t}+193.3\)
* Choke line: \(\delta_{1}\tilde{\bar{H}}_{t}+\delta_{2}\approx 1.611e-3\cdot H_{t}+46.77\)
* Max. speed line: \(\sigma_{1}\tilde{\bar{H}}_{t}^{2}+\sigma_{2}\tilde{\bar{H}}_{t}+\sigma_{3} \approx-1.667e-3\cdot H_{t}+461.7\)

Figure 5: Visualization of demand (a), compressor head (b), and degradation for the compressors (c) changing with time.

Proof of Safety Guarantee

Note all following lemmas hold for any \(\delta\in(0,1),\) and \(S_{0}\), such that \(\varnothing\subsetneq S_{0}\subseteq\mathcal{X}\).

First, we want to show that the intersected confidence interval \(C_{k}\) in (4) w.h.p. contains the reward function and safety functions \(h(\mathbf{x},t,i)\) as in (2).

**Lemma B.1**.: _Let \(\sqrt{\beta_{k}}=B+\sigma\sqrt{2\left(\gamma_{k\cdot|\mathcal{I}|}^{h}+1+\ln( 1/\delta)\right)}\), with \(\gamma_{k}^{h}\) defined as in (12) and \(C_{k}(\mathbf{x},i)\) defined as in (4), then the following holds with probability at least \(1-\delta\) :_

\[h(\mathbf{x},t,i)\in C_{k}(\mathbf{x},i)\qquad\forall t\geq 0,\forall i\in \mathcal{I},\forall\mathbf{x}\in\mathcal{X},\]

Proof by induction.: If \(t=0\), by Assumption 2.3 and the definition of \(C_{k}\) in (4), then \(h(\mathbf{x},0,i)\in C_{0}(\mathbf{x},i),\) for all \(i\in\mathcal{I}\) and for all \(\mathbf{x}\in\mathcal{X}\).

Suppose, for any \(t=\tau\geq 0\), that \(h(\mathbf{x},\tau,i)\in C_{\tau}(\mathbf{x},i)\), then for \(t=\tau+1\), from the Lipschitz continuity of \(h\), \(|h(\mathbf{x},\tau+1,i)-h(\mathbf{x},\tau,i)|\leq L(\tau)\), it holds that \(h(\mathbf{x},\tau+1,i)\in C_{\tau}(\mathbf{x},i)\oplus[-L(\tau),L(\tau)]\).

Moreover, by Lemma 2.4 and (3) we have that \(h(\mathbf{x},\tau+1,i)\in Q_{\tau+1}(\mathbf{x},i)\).

Thus, \(h(\mathbf{x},\tau+1,i)\in(C_{\tau}(\mathbf{x},i)\oplus[-L(\tau),L(\tau)])\cap Q _{\tau+1}(\mathbf{x},i)=C_{\tau+1}(\mathbf{x},i),\ \forall i\in\mathcal{I},\ \forall \mathbf{x}\in\mathcal{X}\).

Therefore, for all \(t\geq 0\), for all \(i\in\mathcal{I}\) and for all \(\mathbf{x}\in\mathcal{X}\) we have that \(h(\mathbf{x},t,i)\in C_{k}(\mathbf{x},i)\), and this concludes the proof. 

We are now ready to prove Theorem 2.5 that provides a sufficient condition for TVSAFEOPT to ensure safety embedded in the constraints \(c_{i}(\mathbf{x},t)\geq 0\), for all \(i\in\mathcal{I}_{c}\).

Proof of Theorem 2.5.: If \(t=0\), by definition of \(S_{0}\), one has \(c_{i}(\mathbf{x},t)=c_{i}(\mathbf{x},0)\geq L(0)\geq 0\), \(\forall i\in\mathcal{I}_{c}\), \(\forall\mathbf{x}\in S_{0}\).

For any \(t\geq 1\), \(\forall\mathbf{x}\in S_{t}\), by recursive definition of \(S_{k}\) in (6), \(\forall i\in\mathcal{I}_{c}\), there exists \(\mathbf{x}^{\prime}\in S_{t-1}\), \(s.t.\)\(l_{k}(\mathbf{x}^{\prime},i)-L_{\mathbf{x}}d(\mathbf{x},\mathbf{x}^{\prime})-L(t)\geq 0\). Then, \(\forall i\in\mathcal{I}_{c}\)

\[c_{i}(\mathbf{x},t)\] \[\geq c_{i}(\mathbf{x}^{\prime},t)-L_{\mathbf{x}}d(\mathbf{x},\mathbf{x }^{\prime})\qquad\text{ by Lipschitz continuity with }\mathbf{x}\] \[\geq l_{k}(\mathbf{x}^{\prime},i)-L_{\mathbf{x}}d(\mathbf{x},\mathbf{x }^{\prime})\qquad\text{ by Lemma B.1}\] \[\geq l_{k}(\mathbf{x}^{\prime},i)-L_{\mathbf{x}}d(\mathbf{x},\mathbf{x }^{\prime})-L(t)\] \[\geq 0\]

and this concludes the proof.

Proof of Near-Optimality Guarantee

The proof of near optimality consists in two parts: i) bounding the uncertainty and ii) bounding the expansion of the safe set.

### Bounding the Uncertainty

We first derive a decaying upper bound of uncertainty for TVSAFEOPT. In this way we can ensure the uncertainty of the reward function and safety functions to drop below a desired threshold.

**Lemma C.1**.: _Define \(b_{1}:=8/\log\left(1+\sigma^{-2}\right)\in\mathbb{R}\), and \(\gamma_{k}^{h}\) as in (12). For any \(k>k_{0}\geq 1\), there exists \(k^{\prime}\in(k_{0},k]\), such that the following holds for all \(i\in\mathcal{I}\):_

\[w_{k^{\prime}}(\mathbf{x}_{k^{\prime}},i)\leq\sqrt{\frac{b_{1}\beta_{k}\gamma _{k}^{h}}{k-k_{0}}},\]

Proof.: Let \(i_{\tau}:=\operatorname*{arg\,max}_{i\in\mathcal{I}}w_{\tau}(\mathbf{x}_{\tau },i)\), where \(\mathbf{x}_{\tau}=\operatorname*{arg\,max}_{\mathbf{x}\in G_{\tau}\cup M_{ \tau}}\max_{i\in\mathcal{I}}w_{\tau}(\mathbf{x},i)\). For all \(i\in\mathcal{I}\), \(k_{0}<k\), there exists \(k^{\prime}\in(k_{0},k]\):

\[w_{k^{\prime}}(\mathbf{x}_{k^{\prime}},i)\] \[\leq \frac{1}{k-k_{0}}\sum_{\tau=k_{0}+1}^{k}w_{\tau}(\mathbf{x}_{\tau },i_{\tau})\]

\[\overset{(a)}{\leq} \frac{2}{k-k_{0}}\sum_{\tau=k_{0}+1}^{k}\sqrt{\beta_{\tau}}\sigma _{\tau-1}(\mathbf{x}_{\tau},i_{\tau})\] \[\leq \frac{2\sqrt{\beta_{k}}}{k-k_{0}}\sum_{\tau=k_{0}+1}^{k}\sigma_{ \tau-1}(\mathbf{x}_{\tau},i_{\tau})\] \[\overset{(b)}{\leq} \sqrt{\frac{4\beta_{k}}{k-k_{0}}\sum_{\tau=k_{0}+1}^{k}\sigma_{ \tau-1}^{2}(\mathbf{x}_{\tau},i_{\tau})}\] \[\overset{(c)}{\leq} \sqrt{\frac{b_{1}\beta_{k}}{k-k_{0}}\frac{1}{2}\sum_{\tau=k_{0}+1} ^{k}\log(1+\sigma^{-2}\sigma_{\tau-1}^{2}(\mathbf{x}_{\tau},i_{\tau}))}\] \[\overset{(d)}{\leq} \sqrt{\frac{b_{1}\beta_{k}}{k-k_{0}}\frac{1}{2}\sum_{\tau=k_{0}+1} ^{k}\log(1+\sigma^{-2}\sigma_{\tau-1}^{\prime 2}(\mathbf{x}_{\tau},i_{\tau}))}\] \[\overset{(e)}{=} \sqrt{\frac{b_{1}\beta_{k}I(\hat{h}_{\mathbf{x}_{k}};h)}{k-k_{0}}}\] \[\overset{(f)}{\leq} \sqrt{\frac{b_{1}\beta_{k}\gamma_{k}^{h}}{k-k_{0}}}\]

(a): Definition of \(w_{k}\) in (5),

(b): From the fact that the quadratic mean upper bounds the arithmetic mean,

(c): \(\sigma_{\tau-1}^{2}(\mathbf{x}_{\tau},i_{\tau})\ \leq\ k\left((\mathbf{x}_{\tau},\tau,i_{\tau}),(\mathbf{x}_{\tau},\tau,i_{ \tau})\right)\ \leq\ 1\) by Assumption 2.1, and the fact that \(a\ \leq\ \frac{b_{1}}{8}\log(1+\sigma^{-2}a),\ \forall a\in[0,1]\),

(d): \(\sigma_{\tau-1}^{\prime}(\mathbf{x},i)\) denotes the posterior standard deviation of \(h(\mathbf{x},\tau,i)\) inferred by observations at \(\mathbf{X}_{\tau}:=\{(\mathbf{x}_{j},j,i_{j})\}_{j<\tau}\). Since \(\{(\mathbf{x}_{j},j,i_{j})\}_{j=<\tau}\subsetneq\{(\mathbf{x}_{j},j)\}_{j< \tau}\times\mathcal{I}\), then \(\sigma_{\tau-1}(\mathbf{x}_{\tau},i_{\tau})\leq\sigma_{\tau-1}^{\prime}( \mathbf{x}_{\tau},i_{\tau})\),(e): From [19, Lemma 5.3],

(f): Definition of \(\gamma_{k}^{h}\) (12). \(\Box\)

**Corollary C.2**.: _Given \(b_{1}:=8/\log\left(1+\sigma^{-2}\right)\in\mathbb{R}\), take \(T_{k}\) as the smallest positive integer satisfying \(\frac{T_{k}}{\beta_{k+T_{k}}\gamma_{k+T_{k}}^{b}}\geq\frac{b_{1}}{\epsilon^{2}}\). Then, there exists \(k^{\prime}\in(k,k+T_{k}]\), such that for any \(\mathbf{x}\in G_{k^{\prime}}\cup M_{k^{\prime}}\), and for all \(i\in\mathcal{I}\) it holds that_

\[w_{k^{\prime}}(\mathbf{x},i)\leq\epsilon.\]

### Bounding the Expansion of the Safe Set

All following lemmas hold for any \(\delta\in(0,1),\epsilon>0\) and \(S_{0}\), such that \(\varnothing\subsetneq S_{0}\subseteq\mathcal{X}\).

To facilitate the theoretical analysis, we define \(\forall\mathbf{x}\in\mathcal{X},\forall i\in\mathcal{I}\):

\[\begin{cases}\tilde{l}_{k}(\mathbf{x},i):=\max\{\tilde{l}_{k-1}(\mathbf{x},i),\mu_{k-1}(\mathbf{x},i)-\beta_{k}^{1/2}\sigma_{k-1}(\mathbf{x},i)\},\quad k \geq 1\\ \tilde{l}_{0}(\mathbf{x},i):=l_{0}(\mathbf{x},i)\end{cases}\] (19)

Remember that, from (4), we can derive \(\forall\mathbf{x}\in\mathcal{X},\forall i\in\mathcal{I}\):

\[l_{k}(\mathbf{x},i)=\max\{l_{k-1}(\mathbf{x},i)-L(t-1),\ \mu_{k-1}(\mathbf{x},i)- \beta_{k}^{1/2}\sigma_{k-1}(\mathbf{x},i)\}\] (20)

Therefore, \(\tilde{l}_{k}\) can be viewed as updating \(l_{k}\) with \(L(t)\equiv 0\). With a slight abuse of notation, we omit arguments \(\mathbf{x}\) and \(i\) when not ambiguous.

**Lemma C.3**.: _The following holds for any \(k\geq 1,\forall\mathbf{x}\in\mathcal{X},\forall i\in\mathcal{I}\):_

1. \(l_{k}(\mathbf{x},i)\geq l_{k-1}(\mathbf{x},i)-L(t-1)\)__
2. \(\tilde{l}_{k}(\mathbf{x},i)\geq\tilde{l}_{k-1}(\mathbf{x},i)\)__
3. \(l_{k}(\mathbf{x},i)\leq\tilde{l}_{k}(\mathbf{x},i)\)__
4. \(\tilde{l}_{k}(\mathbf{x},i)-\bar{L}_{\mathrm{t}}\leq l_{k}(\mathbf{x},i)\)__

Proof.:
1. Direct consequence of (20).
2. Direct consequence of (19).
3. We proceed by induction. Suppose \(l_{\tau}\leq\tilde{l}_{\tau}\), then \(l_{\tau}-L(\tau)\leq\tilde{l}_{\tau}\), thus according to (20), \(l_{\tau+1}=\max\{l_{\tau}-L(\tau),\ \mu_{\tau}-\beta_{\tau+1}^{1/2}\sigma_{\tau}\} \leq\max\{\tilde{l}_{\tau},\ \mu_{\tau}-\beta_{\tau+1}^{1/2}\sigma_{\tau}\}= \tilde{l}_{\tau+1}\), from which it follows \(l_{k}(\mathbf{x},i)\leq\tilde{l}_{k}(\mathbf{x},i)\).
4. We proceed by induction. Suppose \(l_{\tau}\geq\tilde{l}_{\tau}-\sum\limits_{k=0}^{\tau-1}L(k)\). If \(\mu_{\tau}-\beta_{\tau+1}^{1/2}\sigma_{\tau}>\tilde{l}_{\tau}\), then \(l_{\tau+1}\stackrel{{\eqref{eq:20}}}{{=}}\mu_{\tau}-\beta_{\tau+1} ^{1/2}\sigma_{\tau}\stackrel{{\eqref{eq:20}}}{{=}}\tilde{l}_{ \tau+1}\geq\tilde{l}_{\tau+1}-\sum\limits_{k=0}^{\tau}L(k)\). If \(\mu_{\tau}-\beta_{\tau+1}^{1/2}\sigma_{\tau}<l_{\tau}-L(\tau)\), then \(l_{\tau+1}\stackrel{{\eqref{eq:20}}}{{=}}l_{\tau}-L(\tau)\geq \tilde{l}_{\tau}-\sum\limits_{k=0}^{\tau-1}L(k)-L(\tau)=\tilde{l}_{\tau+1}- \sum\limits_{k=0}^{\tau}L(k)\). Otherwise, \(l_{\tau+1}\stackrel{{\eqref{eq:20}}}{{=}}\mu_{\tau}-\beta_{\tau+1} ^{1/2}\sigma_{\tau}\geq l_{\tau}-L(\tau)\geq\tilde{l}_{\tau}-\sum\limits_{k=0} ^{\tau-1}L(k)-L(\tau)=\tilde{l}_{\tau+1}-\sum\limits_{k=0}^{\tau}L(k)\).

To summarize, \(l_{k}\geq\tilde{l}_{k}-\sum\limits_{k=0}^{t-1}L(k)\geq\tilde{l}_{k}-\bar{L}_{\rm t}\)

Lemma C.3 allows us to define auxiliary safe sets based on \(\tilde{l}_{k}\) such that they are contained in \(S_{k}\). Furthermore, due to the monotonicity of \(\tilde{l}_{k}\), we can prove the auxiliary safe sets never shrink, which will play a fundamental role in studying their convergence property and provide near-optimality guarantee of TVSAFEGPT.

Based on (19), we further define:

\[\overline{S}_{k} :=\{{\bf x}\in\mathcal{X}\mid\forall i\in\mathcal{I}_{c},\exists{ \bf x}_{i}^{\prime}\in\overline{S}_{t-1},s.t.\ \tilde{l}_{k}({\bf x}_{i}^{\prime},i)-L_{\bf x}d({\bf x},{\bf x}_{i}^{\prime}) \geq 0\}\] \[\underline{S}_{k} :=\{{\bf x}\in\mathcal{X}\mid\forall i\in\mathcal{I}_{c},\exists{ \bf x}_{i}^{\prime}\in\underline{S}_{t-1},s.t.\ \tilde{l}_{k}({\bf x}_{i}^{\prime},i)-L_{\bf x}d({\bf x},{\bf x}_{i}^{\prime}) -\bar{L}_{\rm t}\geq 0\}\] \[\overline{S}_{0} =\underline{S}_{0}=S_{0}\] Remember \(S_{k}=\{{\bf x}\in\mathcal{X}\mid\forall i\in\mathcal{I}_{c},\exists{\bf x }_{i}^{\prime}\in S_{t-1},s.t.\ l_{k}({\bf x}_{i}^{\prime},i)-L_{\bf x}d({\bf x},{\bf x}_{i}^{\prime})-L(t)\geq 0\}\). Thus, \(\overline{S}_{k}=\underline{S}_{k}=S_{k}\) if and only if \(L(t)\equiv 0\).

The following lemma proves that \(\underline{S}_{k}\) never shrinks, and that \(\underline{S}_{k}\) and \(\overline{S}_{k}\) are a subset and a superset for \(S_{k}\), respectively.

**Lemma C.4**.: _The following holds for any \(t\geq 1\):_

1. \(\underline{S}_{t-1}\subseteq\underline{S}_{k}\)__
2. \(\underline{S}_{k}\subseteq S_{k}\subseteq\overline{S}_{k}\)__

Proof.:

1. We refer the reader to [8, Lemma 7.1].
2. We proceed by induction. Suppose \(\underline{S}_{\tau}\subseteq S_{\tau}\subseteq\overline{S}_{\tau}\). For all \({\bf x}\in S_{\tau+1}\), and for all \(i\in\mathcal{I}_{c}\), there exists \({\bf x}_{i}^{\prime}\in S_{\tau}\subseteq\overline{S}_{\tau}\), s.t. \(\tilde{l}_{\tau}({\bf x}_{i}^{\prime},i)-L_{\bf x}d({\bf x},{\bf x}_{i}^{ \prime})\geq l_{\tau}({\bf x}_{i}^{\prime},i)-L_{\bf x}d({\bf x},{\bf x}_{i}^{ \prime})-L(\tau)\geq 0\), hence \({\bf x}\in\overline{S}_{\tau+1}\) as well. Therefore, \(S_{\tau}\subseteq\overline{S}_{\tau}\)\(\forall\tau\). For all \({\bf x}\in\underline{S}_{\tau+1}\), and for all \(i\in\mathcal{I}_{c}\), there exists \({\bf x}_{i}^{\prime}\in\underline{S}_{\tau}\subseteq S_{\tau}\), s.t. \(l_{\tau}({\bf x}_{i}^{\prime},i)-L_{\bf x}d({\bf x},{\bf x}_{i}^{\prime})-L( \tau)\geq\tilde{l}_{\tau}({\bf x}_{i}^{\prime},i)-\sum\limits_{k=0}^{\tau-1}L( k)-L_{\bf x}d({\bf x},{\bf x}_{i}^{\prime})-L(\tau)=\tilde{l}_{\tau}({\bf x}_{i}^{ \prime},i)-L_{\bf x}d({\bf x},{\bf x}_{i}^{\prime})-\sum\limits_{k=0}^{\tau}L( k)\geq\tilde{l}_{\tau}({\bf x}_{i}^{\prime},i)-L_{\bf x}d({\bf x},{\bf x}_{i}^{ \prime})-\bar{L}_{\rm t}\geq 0\), thus \({\bf x}\in S_{\tau+1}\). Therefore, \(\underline{S}_{\tau}\subseteq S_{\tau}\), \(\forall\tau\). From which we conclude \(\underline{S}_{\tau}\subseteq S_{\tau}\subseteq\overline{S}_{\tau}\), \(\forall\tau\).

**Note:** Where needed in the following lemmas, we assume \(b_{1}\) and \(T_{k}\) are defined as in Lemma C.1 and Corollary C.2

**Lemma C.5** (Lemma 7.4 in [8]).: _For any \(k\geq 1\), \(a>0\), if \(\bar{R}_{a}\left(S_{0}\right)\backslash\underline{S}_{k}\neq\varnothing\), then \(R_{a}\left(\underline{S}_{k}\right)\backslash\underline{S}_{k}\neq\varnothing\)._

The following lemma provides a sufficient condition for the expansion of the auxiliary safe set \(\underline{S}_{k}\).

**Lemma C.6**.: _For any \(t\geq 1\), if \(\bar{R}_{\bar{L}_{\rm t}+\epsilon}(S_{0})\backslash\underline{S}_{k}\neq\varnothing\), then, with probability at least \(1-\delta\), it holds that \(\underline{S}_{k+T_{k}}\supsetneq\underline{S}_{k}\)._

Proof.: Similar to the proof of [8, Lemma 7.5].

By Lemma C.5, we get that, \(R_{\bar{L}_{\rm t}+\epsilon}\left(\underline{S}_{k}\right)\backslash\underline{S }_{k}\neq\varnothing\). Equivalently, \(\exists{\bf x}\in R_{\bar{L}_{\rm t}+\epsilon}\left(\underline{S}_{k}\right) \backslash\underline{S}_{k}\) which implies that, for all \(i\in\mathcal{I}_{c}\),

\[\exists{\bf z}_{i}\in\underline{S}_{k}:\bar{c}_{i}({\bf z}_{i})-L_{\bf x}d({ \bf z}_{i},{\bf x})-\bar{L}_{\rm t}-\epsilon\geq 0\]Now assume, to the contrary, that \(\underline{S}_{k+T_{k}}=\underline{S}_{k}\). Thus, \(\forall k^{\prime}\in(k,k+T_{k}]\), \(\mathbf{x}\in\mathcal{D}\backslash\underline{S}_{k^{\prime}}\), and \(\forall i\in\mathcal{I}_{c}\), \(\mathbf{z}_{i}\in\underline{S}_{k^{\prime}}\).

\[u_{k^{\prime}}(\mathbf{z}_{i},i)-L_{\mathbf{x}}d(\mathbf{z}_{i}, \mathbf{x})-L(k^{\prime})\] \[\geq \bar{c}_{i}(\mathbf{z}_{i})-L_{\mathbf{x}}d(\mathbf{z}_{i}, \mathbf{x})-L(k^{\prime})\qquad\text{by Lemma B.1}\] \[\geq \bar{c}_{i}(\mathbf{z}_{i})-L_{\mathbf{x}}d(\mathbf{z}_{i}, \mathbf{x})-\bar{L}_{\mathrm{t}}-\epsilon\] \[\geq 0\]

Therefore, by definition (8), \(e_{k^{\prime}}(\mathbf{z}_{i})>0\), which implies \(\mathbf{z}_{i}\in G_{k^{\prime}},\ \forall k^{\prime}\in(k,k+T_{k}],\ \forall i\in \mathcal{I}_{c}\).

Therefore, we know that there exists \(k^{\prime}\in(k,k+T_{k}]\), for all \(i\in\mathcal{I}_{c},\ w_{k^{\prime}}(\mathbf{z}_{i},i)\leq\epsilon\). (Corollary C.2) Hence, for all \(i\in\mathcal{I}_{c}\),

\[\bar{l}_{k^{\prime}}(\mathbf{z}_{i},i)-L_{\mathbf{x}}d(\mathbf{z }_{i},\mathbf{x})\] \[\geq \bar{c}_{i}(\mathbf{z}_{i})-w_{k^{\prime}}(\mathbf{z}_{i},i)-L_{ \mathbf{x}}d(\mathbf{z}_{i},\mathbf{x})\qquad\text{by Lemma B.1}\] \[\geq \bar{c}_{i}(\mathbf{z}_{i})-\epsilon-L_{\mathbf{x}}d(\mathbf{z}_ {i},\mathbf{x})\] \[\geq \bar{L}_{\mathrm{t}}\]

This means \(\mathbf{x}\in\underline{S}_{k^{\prime}}=\underline{S}_{k}\), which leads to a contradiction.

The following lemma gives a superset for the auxiliary safe set \(\underline{S}_{k}\).

**Lemma C.7**.: \(\underline{S}_{k}\subseteq\bar{R}_{L_{\mathrm{t}}}(S_{0})\) _with probability at least \(1-\delta\)._

_Proof by induction._

\(\underline{S}_{0}=S_{0}\subseteq\bar{R}_{\bar{L}_{\mathrm{t}}}(S_{0})\)

Suppose \(\underline{S}_{\tau}\subseteq\bar{R}_{\bar{L}_{\mathrm{t}}}(S_{0})\).

For all \(\mathbf{x}\in\underline{S}_{\tau+1}\) and for all \(i\in\mathcal{I}_{c}\) there exists \(\mathbf{x}_{i}^{\prime}\in\underline{S}_{\tau},s.t.\ \bar{c}_{i}\left(\mathbf{x}_{i}^{ \prime}\right)-L_{\mathbf{x}}d(\mathbf{x},\mathbf{x}_{i}^{\prime})-\bar{L}_{ \mathrm{t}}\stackrel{{(a)}}{{\geq}}\bar{l}_{k}(\mathbf{x}_{i}^{ \prime},i)-L_{\mathbf{x}}d(\mathbf{x},\mathbf{x}_{i}^{\prime})-\bar{L}_{ \mathrm{t}}\geq 0\).

(a): Lemma B.1.

Thus, \(\underline{S}_{\tau+1}\subseteq R_{\bar{L}_{\mathrm{t}}}(\underline{S}_{\tau}) \subseteq\bar{R}_{\bar{L}_{\mathrm{t}}}(S_{0})\) 

**Lemma C.8** (Lemma 7.8 in [8]).: _Let \(k^{*}\) be the smallest integer, such that \(k^{*}\geq\left|\bar{R}_{L_{\mathrm{t}}}\left(S_{0}\right)\right|T_{k^{*}}\). Then, there exists \(k_{0}\leq k^{*}\), such that \(\underline{S}_{k_{0}+T_{k_{0}}}=\underline{S}_{k_{0}}\)._

Lemma C.8 together with Lemma C.6, and Lemma C.7 entail convergence of \(\underline{S}_{k}\) within \(k^{*}\) time steps, which ultimately leads us to the near-optimality of TVSAFEOPT when the problem becomes stationary.

**Lemma C.9**.: _For any \(k\geq 1\), if \(\underline{S}_{k+T_{k}}=\underline{S}_{k}\), then, with probability at least \(1-\delta\), there exists \(k^{\prime}\in(k,k+T_{k}]\) such that_

\[\bar{f}\left(\hat{\mathbf{x}}_{k^{\prime}}\right)\geq\max_{\mathbf{x}\in R_{L _{\mathrm{t}}+\epsilon}(S_{0})}\bar{f}(\mathbf{x})-\epsilon.\]

Proof.: Let \(\mathbf{x}_{k^{\prime}}^{*}:=\operatorname*{arg\,max}_{\mathbf{x}\in S_{k^{ \prime}}}\bar{f}(\mathbf{x})\). Note that \(\mathbf{x}_{k^{\prime}}^{*}\in M_{k^{\prime}}\), since

\[u_{k^{\prime}}(\mathbf{x}_{k^{\prime}}^{*},0) \stackrel{{(a)}}{{\geq}}\bar{f}(\mathbf{x}_{k^{\prime }}^{*})\] \[\geq\bar{f}(\mathbf{x}_{k^{\prime}})\] \[\stackrel{{(b)}}{{\geq}}l_{k^{\prime}}(\hat{\mathbf{ x}}_{k^{\prime}},0)\] \[\stackrel{{(c)}}{{\geq}}\max_{\mathbf{x}\in S_{k^{ \prime}}}l_{k^{\prime}}(\mathbf{x},0)\](a) and (b): Lemma B.1,

(c): Definition of \(\hat{\mathbf{x}}_{k}\) (11).

We will first show that \(\exists k^{\prime}\in(k,k+T_{k}],s.t.\)\(\bar{f}(\hat{\mathbf{x}}_{k^{\prime}})\geq\bar{f}(\mathbf{x}_{k^{\prime}}^{*})-\epsilon\). Assume, to the contrary, that

\[\forall k^{\prime}\in(k,k+T_{k}],\bar{f}(\hat{\mathbf{x}}_{k^{\prime}})<\bar{f} (\mathbf{x}_{k^{\prime}}^{*})-\epsilon\]

Then, we have, \(\exists k^{\prime}\in(k,k+T_{k}]\)

\[\begin{split} l_{k^{\prime}}(\mathbf{x}_{k^{\prime}}^{*},0)\\ \overset{(d)}{\leq}& l_{k^{\prime}}(\hat{\mathbf{x} }_{k^{\prime}},0)\\ \overset{(e)}{\leq}&\bar{f}(\hat{\mathbf{x}}_{k^{ \prime}})\\ <&\bar{f}(\mathbf{x}_{k^{\prime}}^{*})-\epsilon\\ \overset{(f)}{\leq}& l_{k^{\prime}}(\mathbf{x}_{k^{ \prime}}^{*},0),\end{split}\]

which is a contradiction.

(d): Definition of \(\hat{\mathbf{x}}_{k}\) (11),

(e): Lemma B.1,

(f): Corollary C.2, and \(\mathbf{x}_{k^{\prime}}^{*}\in M_{k^{\prime}}\)

Finally, \(\bar{R}_{L_{t}+\epsilon}\left(S_{0}\right)\subseteq\underline{S}_{k^{\prime}} \subseteq S_{k^{\prime}}\), by Lemma C.6 and Lemma C.4 (ii). Therefore, \(\exists\,k^{\prime}\in(k,k+T_{k}]\) such that

\[\begin{split}\max_{\mathbf{x}\in\bar{R}_{L_{t}+\epsilon}(S_{0})} \bar{f}(\mathbf{x})-\epsilon&\leq\max_{\mathbf{x}\in S_{k^{ \prime}}}\bar{f}(\mathbf{x})-\epsilon\\ &=\bar{f}(\mathbf{x}_{k^{\prime}}^{*})-\epsilon\\ &\leq\bar{f}(\hat{\mathbf{x}}_{k^{\prime}})\end{split}\]

### Near-Optimality Proof

Proof of Theorem 2.6.: Theorem 2.6 is a direct consequence of Corollary C.2, Lemma C.8, and Lemma C.9. 

## Appendix D Practical Considerations

### Trade-off between Safety and Optimality

In this work, we focus on safety critical systems where satisfying the safety constraints has highest priority over finding the optima. Through pessimistically considering change with time in the decision-making process, TVSAFEOPT emphasizes safety in non-stationary conditions at the inevitable expense of optimality. In practice, such sacrifice on optimality can be alleviated by tighter bound of rate of change.

Besides, in the case where safety can be to some extent comprised, which is beyond the focus of this work, constrained BO and its time-varying extension would be a more suitable method to apply. We refer the readers to [50, 51] for further information.

### Scalability

Explicit considering time can be viewed roughly as adding dimension by \(1\), Therefore, TVSAFEOPT achieves time adaptation without adding much computational cost. With the increase in dimensionality of the problem, safety constraints might arise across multiple dimensions, from multiple directions at the price of optimality. As our approach is suitable for safety critical conditions, the focus is put on maintaining safety under change, therefore safety considerations "dictate" the optima. Additionally, in practice, the safety functions are modeled independently with a GP, and thus the computational cost scales linearly with the number of constraints.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: The paper set out to solve the problem of optimizing an unknown time-varying reward subject to unknown time-varying safety constraints, as stated in the **Abstract** and the **Introduction** (Section 1). In a partial fulfilment of this goal, the paper develops a safe learning algorithm and provides safety guarantees for a general time-varying case, and near-optimality guarantees for when the time-varying problem becomes stationary. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: The paper contains a separate section on limitations, see Section 4 Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs**Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: The paper provides the necessary assumptions in Section 2.1, the definitions in Section 2, and proofs in Appendices B and C. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: The paper provides the necessary information in Section 3 and the background details are in Appendix A. In particular, the modifications necessary for practical implementation of the proposed algorithm, for example regarding the Lipschitz constants, are provided in Appendix A.1 and the hyperparameters for the examples are in Appendix A.2 and Appendix A.3. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset).

4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: The paper provides the details necessary to reproduce the simulational results in Appendix A. The code accompanying the paper is currently under review and will appear shortly at https://www.research-collection.ethz.ch/. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: The paper provides the necessary information in Section 3 and the background details are in Appendix A. In particular, the modifications necessary for practical implementation of the proposed algorithm, for example regarding the Lipschitz constants, are provided in Appendix A.1 and the hyperparameters for the examples are in Appendix A.2 and Appendix A.3. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments?Answer: [Yes] Justification: The main contribution of the paper is in theoretical guarantees for the proposed algorithm. The only source of uncertainty in the experiments is in assumed measurement noise, with the standard deviation 0.01, making error bars negligible, as stated in respective experimental sections.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: The paper provides the necessary information in Section 3 and the background details are in Appendix A. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: The paper uses neither external datasets nor human subjects, and no data have been collected for the paper. The algorithm proposed in the paper is an optimization algorithm and thus does not introduce additional biases or privacy and dual-use concerns. The necessary licences for fair use have been provided in Appendix A.3. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: The paper states the need for safe optimization algorithm with potential applications in the Introduction (Section 1, in particular Section 1.2.1). The algorithm proposed in the paper is an optimization algorithm and thus does not introduce additional biases or privacy and dual-use concerns. The algorithm does not use external datasets, and as such does not require privacy or security considerations. Neither does the algorithm generate data that can be used for disinformation or discrimination. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.

* Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.
* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [Yes] Justification: The paper does not contain data of high risk for misuse. The necessary licences for fair use have been provided in Appendix A.3. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licensees for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: All previously existing results used in the paper have been cited in **References**, including the necessary licensing information for the data for the compressor case study in Appendix A.3. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.

* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.

13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: The paper does not introduce additional assets. Guidelines: * The answer NA means that the paper does not release new assets. * Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. * The paper should discuss whether and how consent was obtained from people whose asset is used. * At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.

14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: The paper uses neither crowdsourcing nor human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. * According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.

15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: The paper does not use human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.

* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.