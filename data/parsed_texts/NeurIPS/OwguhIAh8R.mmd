# HGDL: Heterogeneous Graph Label Distribution Learning

 Yufei Jin\({}^{\dagger}\), Heng Lian\({}^{\diamond}\), Yi He\({}^{\diamond}\), Xingquan Zhu\({}^{\dagger}\)

\({}^{\dagger}\)Dept. of Elec. Eng. & Computer Sci., Florida Atlantic University, Boca Raton, FL 33431, USA

\({}^{\diamond}\)Dept. of Data Science, William & Mary, Williamsburg, VA 23185, USA

yjin2021@fau.edu; hlian01@wm.edu; yihe@wm.edu; xzhu3@fau.edu

Corresponding author

###### Abstract

Label Distribution Learning (LDL) has been extensively studied in IID data applications such as computer vision, thanks to its more generic setting over single-label and multi-label classification. This paper advances LDL into graph domains and aims to tackle a novel and fundamental _heterogeneous graph label distribution learning_ (HGDL) problem. We argue that the graph heterogeneity reflected on node types, node attributes, and neighborhood structures can impose significant challenges for generalizing LDL onto graphs. To address the challenges, we propose a new learning framework with two key components: 1) proactive graph topology homogenization, and 2) topology and content consistency-aware graph transformer. Specifically, the former learns optimal information aggregation between meta-paths, so that the node heterogeneity can be proactively addressed prior to the succeeding embedding learning; the latter leverages an attention mechanism to learn consistency between meta-path and node attributes, allowing network topology and nodal attributes to be equally emphasized during the label distribution learning. By using KL-divergence and additional constraints, HGDL delivers an end-to-end solution for learning and predicting label distribution for nodes. Both theoretical and empirical studies substantiate the effectiveness of our HGDL approach. Our code and datasets are available at https://github.com/Listener-Watcher/HGDL.

## 1 Introduction

Definite supervision signals are often postulated in learning settings [3; 4]; yet, data generated from the real world tend to present inherent ambiguity, imposing challenges on assertive classifiers that predict instances into single or multiple classes. Label Distribution Learning (LDL) [5; 6; 7; 8; 9] has emerged to navigate label ambiguity by pursuing a mapping from instances to their class distributions. Each distribution quantifies the _descriptive degrees_ of various classes given a specific instance.

However, the existing LDL studies mainly [10; 6; 7; 11] focus on independent and identically distributed (IID) data, such as images or texts, which do not generalize well on _graphs_. In fact, the topological structure underlying instances may provide invaluable information for label distribution learning. For example, in the task of urban planning, recent learning models have been employed to predict the point of interests (POIs) of local regions [12; 13; 14; 15]. LDL can further extend this task by providing the regional distributions over all POIs, which lends a finer-granular delineation of urban regional functionality instead of single- or multi-class classification. To wit, for a region that mixes four POIs (classes): housing, healthcare, education and worship, unlike other models assertively classify it into one or multiple POI(s), LDL model can provide insights of the functional degrees of all four POIs in this region, as shown in Figure 1. Nevertheless, existing LDL studies overlook theurban topology, which can be rendered from, e.g., the taxi services across regions [2], missing out critical city traffic patterns that are highly correlated with regional functionalities. For instance, the regions with balanced POI distributions (e.g., R\({}_{2}\) and R\({}_{3}\)) are less likely to form connections with other nodes compared to regions heavily skewed towards a single class (e.g., R\({}_{4}\)), as their residents enjoy fewer needs to travel to other regions for services such as education and healthcare.

In this paper, we aim to enable and generalize the label distribution learning paradigm in networked data. Two technical challenges confront our study. First, real-world graphs are mostly heterogeneous, comprising diverse types of nodes for better expressiveness. Graph heterogeneity complicates the message-passing between nodes of a specific type (e.g., residence), as the label distributions of those nodes are influenced by their neighboring nodes that may vary in terms of types, content, and topological features. Simply leveraging node embeddings generated from message-passing for LDL will thus not work well [16; 17]. To aid, although meta-path aggregation [18] is seemingly viable, it necessitates extensive domain knowledge and expertise to craft meta-paths for each node type with respect to their label distributions; given the combinatorial number of possible meta-paths in large heterogeneous graphs, searching for the optimal meta-path for LDL is costly, laborious, and time-demanding.

Second, graph topology and nodal features may suggest inconsistent label distributions, where nodes sharing similar contents are positioned far apart on the graph topology. The inconsistency is furthered in heterogeneous graphs, where nodes of the same type often connect through other intermediary types, resulting in substantial topological distances between them. Unlike traditional LDL that focuses on instance vectors only, an effective LDL model on graphs require harmonizing nodal contents with topological structures for a unified representation. The impact of distantly positioned nodes within a graph is substantially diminished, consequently steering the LDL model to prioritize individual nodal vectors, leading to compromised node representations in which the informative patterns embedded in their neighborhood structures are overlooked. Such patterns, which may significantly enhance label distribution predictions as illustrated in Figure 1, are neglected, undermining the LDL model effectiveness.

To overcome the challenges, we propose a new learning framework, coined _Heterogeneous Graph label Distribution Learning_ (HGDL). Specifically, to tame the graph heterogeneity, HGDL learns the optimal graph topology of the target nodes from multiple homogeneous structures searched with various meta-path schemes through a tailored attention mechanism. The node embeddings are then generated by harmonizing the nodal features and the learned meta-path graph using a transformer architecture. A joint optimization objective is crafted based on the distance between true and predicted label distributions of the target nodes from their resultant embeddings, which unifies the learning of meta-path graph topology and the feature-topology harmonization function in an end-to-end fashion.

A key innovation of HGDL is that it changes existing heterogeneous graph learning paradigm from _reactive_ (meaning that aggregation of different meta-paths are done _after_ embedding learning from individual meta-path), to be _proactive_ (meaning that aggregation are done _before_ embedding learning). Combined with attention and transformer mechanisms to adjust individual meta-paths' interplay, and align with nodal features, HGDL deliver significantly better performance over alternatives. Our theoretical analysis assures that HGDL outperforms that of using an arbitrary meta-path graph, and HGDL's topology and feature consistency learning sparsifies network connectivity, intermediately encouraging tightens the error-bound, resulting in better model generalization.

**Specific contributions of this paper are as follows:**

Figure 1: Motivating example of HGDL study, where each node is a local urban region [1] and edges represent taxi services [2] commuting between regions. Heterogeneous node types indicate disparate land use, including residence (R), service (S), leisure (L), and transit (T), among which R nodes are of our interest. Colored R nodes are with ground truth, which delineate their distributions over multiple point-of-interests (POIs), and each POI is deemed as a class/label. Our HGDL problem is to predict the label distribution of uncolored R nodes, enabling a precise delineation of regional urban functionality.

1. This study pioneers the exploration of LDL problem in heterogeneous graphs. The learning problem enjoys practical implications such as for urban functionality delineation (presented in Sec 6.1) and, to our knowledge, has not yet been explored by any contemporary research.
2. We propose an end-to-end HGDL learning approach to jointly learn an optimal meta-path graph topology and align it with nodal features for consistent message-passing. Our approach is surprisingly simple yet effective, with its performance evidenced by theoretical underpinnings. Our approach and its analysis are presented in Sections 4 and 5, respectively.
3. Empirical study has been carried out over five graph datasets that span domains of bio-medicine, scholarly network, business network, and urban planning. Experimental results substantiate the effectiveness of our approach over rival models, documented in Section 6.

## 2 Related Work

Label Distribution Learning (LDL)strives to learn a mapping from input to a distribution that profiles the descriptive degrees of classes associated with it [5; 10; 6; 7; 11]. Existing LDL methods fall into three categories, namely, problem transformation (PT), algorithm adaption (AA), and specialized algorithm (SA). PT methods transform LDL as multiple single-label learning tasks, using with label probabilities [19], and AA approaches revise mainstream learning algorithm to fit the LDL loss. SA algorithms are most commonly used because LDL learning is driven by new algorithm designs. Label correlation has been found to benefit the label distribution learning, where approaches were proposed to encode label correlation to a distance to measure the similarity of any two labels [6]. Later, low-rank approximation is used to construct label correlation matrix to capture the global label correlations [7] Instead of exploring common features for all labels, label-specific features [10] for each label are used to enhance the LDL model. Exploring feature-label and label-label correlation [9] has recently been studied in generalizable label distribution learning for cross domain learning. A Gaussian label distribution learning method [11] employs a parametric model underpinned by an optimization strategy assessing KL-divergence distance between Gaussian distributions, followed by a regression loss to normalize the KL-divergence distance. Noticing the difficulty to obtain ground-truth label distributions, Label Enhancement [20] is commonly used to recover label distributions from logical labels. Our research further push LDL to be generalized onto heterogeneous graphs, which have been overlooked by existing research. Although a recent study [21] explored using LDL in topological spaces, it focused on homogeneous graphs only and cannot work in the setting of more than one node type. Thus, the studied problem in [21] and its challenges differ from ours.

Heterogeneous Graph Neural Networkshave drawn extensive attention in graph learning [16; 17; 22; 18; 23; 24], because the graph heterogeneity imposes considerable challenge to model the interplay among various node types, features, labels, and network topology. Using meta-path to aggregate information from different types of nodes/edges is a common approach for heterogeneous graph learning. HetGNN [17; 18] designs graph neural networks to encode features for each type of neighbors and then aggregates neighbors' representation with respect to different types. This provides a way for GNN to deal with heterogeneous graph structures and node attributes. HAN [25] introduces attention mechanisms to heterogeneous graph learning, where attentions are applied to embedding features learned from homogeneous networks, each created from a meta-path. By doing so, attentions serve as a weighting mechanism automatically determining the importance of each meta-path for learning. Using transformers for heterogeneous networks has also been investigated recently. For example. HGT [26] designs node- and edge-type dependent parameters to characterize the heterogeneous attention over each edge, allowing this method to learn representations for different types of nodes and edges. SeHGNN [27] proposes a transformer based semantic fusion module, allowing feature fusion from different meta-paths. Our research is fundamentally different from existing work in two aspects: 1) we study LDL learning for heterogeneous networks, and 2) we propose a new way to aggregate and align information for heterogeneous network.

## 3 Preliminaries

Notations.A heterogeneous graph is denoted by \(G=\{V,E,X,Y\}\) associated with a node type mapping \(\phi:\ V\mapsto\mathcal{T}^{v}\) and an edge type mapping \(\varphi:\ E\mapsto\mathcal{T}^{e}\), with \(\mathcal{T}^{v}\) and \(\mathcal{T}^{e}\) the predefined and finite sets of nodes and edges, respectively, and \(|\mathcal{T}^{v}|\geq 2\). Denote \(t_{{}_{t}}\in\mathcal{T}^{v}\) as the node type of our interest, and suppose in total \(n\) nodes are of this type. Without loss of generality, we have \(\phi(v_{1})=\ldots=\phi(v_{n})=t_{{}_{t}}\), and \(V_{{}_{t}}=\{v_{1},\ldots,v_{n}\}\subset V\). We deem these \(n\) nodes as our _target nodes_, using a feature matrix \(X\in\mathbb{R}^{n\times m}\) to describe their nodal contents, where each node containsan \(m\)-dimensional feature vector. A meta-path \(\mathcal{P}\) is defined as a relational sequence in form of \(t_{1}\xrightarrow{r_{1}}t_{2}\ldots\xrightarrow{r_{t}}t_{i}\xrightarrow{r_{i+1}}t_ {i+1}\ldots\to t_{l}\) (abbreviated as \(\mathcal{P}=(t_{1}t_{2}\ldots t_{i}t_{i+1}\ldots t_{l})\), where \((t_{i}t_{i+1})\in\mathcal{T}^{e}\) describes the composite relation between a pair of node types. By defining a meta-path \(\mathcal{P}\) with same first and last node type as the target node type, _i.e._\(t_{1}=t_{l}=t_{\iota}\), we can use \(\mathcal{P}\) to convert a heterogeneous network as a meta-path graph concerning only the target node type, which shall be discussed later in Section 4.1.

Problem Statement.In our HGDL problem, the goal is to learn a predictive mapping \(\hbar:\ (G,X)\mapsto Y\), where \(Y\in[0,1]^{q}\) is a distribution of descriptive labels over \(q\) classes. Let \(y_{i,j}\in[0,1]\) be the probability that the node \(v_{i}\) belongs to the \(j\)-th class, we have \(\sum_{j=1}^{q}y_{i,j}=1\). In this work, we follow a transductive learning regime [28] to allow the ground-truth label distributions known for a subset of target nodes \(V_{tr}\subset V_{t_{i}}\) during training. Our learned mapping \(\hbar\) is expected to generalize well so can make accurate prediction on the remaining target nodes \(V_{t_{\iota}}\setminus V_{tr}\).

## 4 HGDL: The Proposed Approach

Overview.The proposed HGDL approach comprises three key components, as illustrated in Figure 2. First, for the target nodes belonging to the node type \(t_{\iota}\) of interest, HGDL generates multiple homogeneous meta-path graphs based on their original locations on the heterogeneous graph through meta-paths; the optimal graph topology of this node type is then learned from the homogeneous graphs via attention mechanism (_Sec 4.1_). Second, HGDL learns the embeddings of the target nodes by harmonizing the information sourced from their feature space and the learned optimal topology using a transformer-like neural architecture (_Sec 4.2_). Third, HGDL minimizes the distance between the predicted and ground-truth label distributions based on the learned node embeddings. We tailor an objective function to unify the three components into one end-to-end optimization problem, in which the optimal graph topology, the harmonization function of the feature and topological information, and the target node label distribution are jointly learned (_Sec 4.3_).

### Optimal Graph Topology Homogenization

For a heterogenous graph, by leveraging meta-path idea, multiple different meta-path homogeneous adjacency matrix can be obtained and they can be treated as multiple sources. Graph learning is about exchanging and updating information from neighbor nodes. A proper neighbor set is therefore important for a target node to learn correct distribution. Given multiple sources, each node will have

Figure 2: The proposed HGDL framework. Using \(k\) meta-paths, the heterogeneous network in 1 is converted to \(k\) homogeneous meta-path graphs in 2. Topology homogenization in 3 proactively aggregates all \(k\) meta-path graphs, through learnable weight matrix \(W_{0}^{i}\in\mathbb{R}^{n\times f}\) for each graph, and finally obtain attention \(\Theta\in\mathbb{R}^{n\times k}\) across all graphs. Topology and feature consistency-aware graph transformer in 4 harmonizes the local and global consistencies. The objective function in 5 unifies loss and regularization terms to guide nodal label distribution learning.

multiple neighbor sets to choose from for updating. Traditionally, embeddings are learned for all the neighbor sets, and then aggregation over embeddings is learned. Semantics over embeddings are hard to interpret and learn compared with directly learned from different neighbor sets.

To generate a meta-path graph from the original heterogeneous graph, interactions between the meta-path and the heterogeneous graph path are used. Two nodes \(v_{i}\) and \(v_{j}\) are connected in the meta-path graph, if there exists a path connecting them in the heterogeneous graph, and the path follows the meta-path. Given a meta path \(\mathcal{P}=(t_{1}\ldots t_{i}t_{i+1}\ldots t_{i})\), we say that a path \(p=(v_{1},\ldots,v_{i},v_{i+1},\ldots,v_{l})\) in graph \(G\) follows the meta-path \(\mathcal{P}\), if \(\forall i,\phi(v_{i})=t_{i}\). Take graph in Fig. 1 as an example. Given meta-path \(\mathcal{P}=(r\ s\ r)\), which defines node type \(t_{1}=r,t_{2}=s,t_{3}=r\). Path \(p=(r_{2},s_{1},r_{3})\) in the heterogeneous graph follows \(\mathcal{P}\) because all nodes in the path \(p\) satisfy \(\phi(r_{2})=t_{1}=r,\phi(s_{1})=t_{2}=s,\phi(r_{3})=t_{3}=r\). Because path \(p=(r_{2},s_{1},r_{3})\) follows the meta-path \(\mathcal{P}\), an edge is used to connect \(r_{2}\) and \(r_{3}\) in the homogeneous meta-path graph constructed from \(\mathcal{P}\). Indeed, each meta-path defines a specific way of information propagation in a heterogeneous network, with resulted meta-path graph capturing unique relationships between target nodes. While defining a single meta-path is relatively easy, there often exists many meta-paths; aggregating a variety of meta-path graphs to support the downstream learning task is non-trivial.

After searching the meta-paths connecting the nodes of target type \(t_{i}\), we generate a set of graphs \(\mathcal{A}=\{A_{1},\ldots A_{k}\}\), in which each adjacency \(A_{i}\in\{0,1\}^{n\times n}\) captures the topological structure of the \(i\)-th meta-path-based homogeneous graph. Denoted by \(A_{i}[p,q]=1\) means that two target nodes \(v_{p}\) and \(v_{q}\), with \(\phi(v_{p})=\phi(v_{q})=t_{\ast}\), are connected by a meta-path; otherwise, \(A_{i}[p,q]=0\). Unlike existing studies [25] that yield target node embeddings through _reactive_ meta-path aggregation, where they aggregate local neighborhood information for each \(A_{i}\in\mathcal{A}\) to capture \(k\) separate meta-path topologies, our HGDL learns the optimal graph topology from \(\mathcal{A}\) in a _proactive_ fashion. Intuitively, HGDL learns node-level attention scores for various homogeneous graphs \(A_{i}\), to respect the fact that the neighboring nodes may pass messages with varying importance levels in local neighborhoods, while the meta-paths walking across nodes of types other than the target \(t_{\iota}\). Revisit the motivating example demonstrated in Fig 1 where the residence nodes are deemed as the target, the meta-path linking through the service nodes dominates, as the residence nodes are more likely to be linked through service nodes instead of Transit and Leisure nodes. Specifically, the attention scores for the nodes in every \(A_{i}\in\mathcal{A}\) are learned in a GAT regime [29], defined as:

\[\Theta=\text{softmax}\Big{(}\big{\|}_{A_{i}\in\mathcal{A}}\{\text{ LapNorm}(A_{i})W_{0}^{i}\}W_{0}^{{}^{\prime}}\Big{)},\quad\tilde{A}=\sum_{i=1}^{k} \Theta[:,i]\cdot\text{LapNorm}(A_{i}),\] (1)

where LapNorm(\(A_{i}\))= \(D_{i}^{-\frac{1}{2}}(A_{i}+I)D_{i}^{-\frac{1}{2}}\in\mathbb{R}^{n\times n}\) denotes Laplacian normalization of \(A_{i}\), with \(D_{i}\) being \(A_{i}\)'s degree matrix and \(I\) is an identity matrix. This term mitigates the imbalanced degree distribution of the meta-path graphs. Denoted by \(W_{0}^{i}\) and \(W_{0}^{{}^{\prime}}\) are the learnable GAT parameters, where \(W_{0}^{i}\in\mathbb{R}^{n\times f}\) maps the meta-path topology of \(A_{i}\) onto an \(f\)-dimensional semantic space. The operator \(\|_{A_{i}\in\mathcal{A}}\{\cdot\}\) concatenates all \(k\) resultant node embedding matrices from meta-path graphs \(\mathcal{A}\), thereby producing an \(\mathbb{R}^{n\times k\cdot f}\) lookup matrix, where each node is associated with a \(k\cdot f\)-dimensional embedding representation, and each latent \(f\)-dimension captures the local neighborhood structure of this node. Then, \(W_{0}^{{}^{\prime}}\in\mathbb{R}^{k\cdot f\times k}\) summarize the \(f\)-dimensional latent space into one coefficient through convex combination, resulting in attention logits, which are fed into \(\text{softmax}(\cdot)=\exp(\cdot)/\sum_{i}\exp(\cdot)\) to yield the attention matrix \(\Theta=[0,1]^{n\times k}\). Take the \(i\)-th column vector of \(\Theta\), denoted by \(\Theta[:,i]\in[0,1]^{n}\), we have the attention scores of \(n\) target nodes for message-passing in the \(i\)-th meta-path graph \(A_{i}\). We thus can deem \(\tilde{A}\) in Eq. (1) as the learned optimal graph topology, which is an element-wise linear combination of \(k\) meta-path topologies with the attention scores broadcast onto all \(n\) nodes. Note, \(\tilde{A}\) is asymmetric, namely \(\tilde{A}[p,q]\neq\tilde{A}[q,p],\ \forall p\neq q\). This is because that the attention score of information aggregation from node \(v_{p}\) to \(v_{q}\) may be different from that from \(v_{q}\) to \(v_{p}\), as their respective local neighborhood topologies naturally differ.

### Local Topology and Global Feature Consistency-Aware Graph Transformer

After obtaining the optimal topology \(\tilde{A}\) from all meta-path graphs \(A_{i}\), the next question is how to harmonize it with the feature information to better the target node embeddings. The benefit of such harmonization is evident. Revisiting the urban network in Fig 1, we can envision that a pair of residence nodes tend to be associated with similar embedding vectors because they enjoy two typesof consistencies: i) _local neighborhood topology_: their residents tend to travel to similar functional regions for leisure or service purposes, and ii) _global feature space_: they share similar contents such as house types and number of residing families. These local and global consistencies complement with each other, as the residence nodes having similar contents can be topologically faraway from each other on the urban network, and vice versa.

To harmonize the local and global consistencies, we are inspired by the recent graph transformers [30] and observe that the feature attention suggests a global adjacency matrix, which can be incorporated into the message-passing process. We define the graph transformer block as follows.

\[Z=\text{ReLU}(\tilde{A}XW_{1}),\quad\tilde{A}_{2}=\text{ LapNorm}\Big{(}\text{softmax}\big{(}(ZQ)(ZK)^{\top}\odot\tilde{A} \big{)}\Big{)},\] (2)

where \(Z\in\mathbb{R}^{n\times h}\) is the node embeddings learned from the optimal graph topology \(\tilde{A}\) through local information aggregation, parameterized by \(W_{1}\in\mathbb{R}^{m\times h}\). Denoted by \(\tilde{A}_{2}\in[0,1]^{n\times n}\) is the normalized feature attention adjacency, where \(Q\) and \(K\in\mathbb{R}^{h\times h}\) map the embedding matrix \(Z\) onto the latent query and key spaces, respectively, such that \((ZQ)(ZK)^{\top}\) calculates an \(n\times n\) node-level attention matrix with respect to the feature space information. Instead of normalizing the attention score by the hidden dimension \(h\), we penalize the feature attention adjacency through an element-wise production \(\odot\) with the optimal meta-path topology \(\tilde{A}\). The intuition behind Eq. (2) is that, for each target node, it aggregates information from those neighboring nodes only if their meta-path topology and feature space are both with high attention scores. In addition, Eq. (2) functions similarly to the edge dropout [31]; in lieu of randomly removing edges, we enforce a neighbor-set intersection, where the information is only propagated from the neighbors on which the feature space and meta-path topology both agree. Such an intersection sparsity thus lowers the degree of the resultant attention adjacency, thereby uplifting the learning efficacy, which will be substantiated later in Sec 5. Finally, denoted by \(H=\text{LeakyReLU}(\tilde{A}_{2}ZW_{2})\in\mathbb{R}^{n\times h}\) are the resultant node embeddings, capturing both local topology and global feature consistencies, which is parameterized by weight \(W_{2}\in\mathbb{R}^{h\times h}\).

### An End-to-End Hgdl Objective Function

Based on the resultant target node embeddings \(H\), we can predict their label distributions as \(\hat{Y}=\text{softmax}(\tilde{A}_{2}HW_{3})\in[0,1]^{n\times q}\), where \(\hat{Y}_{i}=\{\hat{y}_{i,j}\}_{j=1}^{q}\) is the predicted label distribution of node \(v_{i}\), among which \(\hat{y}_{i,j}\) denotes its predicted probability of belonging to the class \(j\). The unified objective of our HGDL framework is defined as follows.

\[\min_{\{W_{i}^{j}\}_{i=1}^{k},W_{o}^{\prime},W_{1},W_{2},W_{3},K, Q}\ell_{\text{HGDL}}=D_{\text{KL}}(Y\|\hat{Y})-\gamma\cdot\Omega,\] \[D_{\text{KL}}(Y\|\hat{Y})=\sum_{i=1}^{n}\sum_{j=1}^{q}y_{i,j} \cdot\log\frac{y_{i,j}}{\hat{y}_{i,j}},\quad\Omega=\sum_{i=1}^{n}D_{\text{KL} }(\Theta[i,:]\parallel U[1,k]),\] (3)

where the KL-divergence \(D_{\text{KL}}(Y\|\hat{Y})\) gauges the discrepancy between the predicted and groundtruth label distributions of the target nodes [32]. The regularization term \(\Omega\) gauges the distance between the attention scores of the \(i\)-th node across \(k\) meta-path typologies (denoted by \(\Theta[i,:]\)) and a uniform distribution \(U[1,k]\). We note the minus sign before \(\Omega\), thus minimizing this term encourages a larger KL-distance, thereby avoiding the trivial uniform attention distribution (meaning that for each node, the learned attention weights from different meta-paths are encouraged to be as different as possible). \(\gamma\) is a tuned parameter to balance the two terms.

## 5 Analysis

We follow the PAC-Bayes regime to analyze the theoretical performance of our HGDL algorithm by deriving its generalization error bound. We proceed analysis based on the meta-path graph adjacency matrices \(\mathcal{A}=\{A_{1},\dots A_{k}\}\), which are searched from the heterogeneous graph \(G\). Throughout the analysis, we assume the nodal feature representations to be residing in an \(\ell_{2}\)-ball of radius \(B\). We argue this a mild assumption, because in implementation we can leverage the batch-norm layers to normalize the resultant node embeddings, such that \(\|\mathbf{h}_{i}^{j}\|_{2}\leq B\), where \(\mathbf{h}_{i}^{j}\) denotes the \(i\)-th node's embedding resulted from the \(j\)-th hidden layer.

Let \(L_{\mathcal{G}}(\hbar)\) and \(L_{(X,\tilde{A})}(\hbar)\) denote the _generalization risk_ over a graph distribution \(\mathcal{G}\) and the _empirical risk_ on the target node samples and the learned meta-path topology \((X,\tilde{A})\), respectively, where \((X,\tilde{A})\in G\stackrel{{\text{iid}}}{{\sim}}\mathcal{G}\). We can define:

\[L_{\mathcal{G}}(\hbar)=\mathbb{E}_{(X,\tilde{A})\sim\mathcal{G}} \mathbb{E}_{y_{i}\sim Y}\big{[}\ell\big{(}\hbar(X,\tilde{A})[i],y_{i}\big{)} \big{]},\] \[L_{(X,\tilde{A})}(\hbar)=\frac{1}{n}\sum_{i=1}^{n}\big{[}\ell \big{(}\hbar(X,\tilde{A})[i],y_{i}\big{)}\big{]},\]

where \(\ell(\cdot,\cdot)\) is a convex distance metric between two distributions that follows \(|\ell(u,p)-\ell(u,q)|\leq(\sqrt{p}+1)\|p-q\|_{2},\ \forall u,p,q\in\mathbb{R}^{m}\). Denoted by \(\hbar(X,\tilde{A})[i]\in\mathbb{R}^{q}\) and \(y_{i}\in[0,1]^{q}\) the predicted and ground-truth label distribution of the \(i\)-th target node, respectively. Implementing KL-divergence, we have \(\ell\big{(}\hbar(X,\tilde{A})[i],y_{i}\big{)}=\sum_{j=1}^{q}\hbar(X,\tilde{A })[i,j]\ln(\hbar(X,\tilde{A})[i,j]/y_{i,j})\), where the predicted probability that node \(i\) belongs to the \(j\)-th class is denoted by \(\hbar(X,\tilde{A})[i,j]\). By analyzing the performance of the learned meta-path graph topology \(\tilde{A}\), we find that:

**Theorem 1**.: _Let \(\mathbb{E}[L_{(X,A_{i})}(\hbar)]\) be the empirical risk of using the \(i\)-th meta-path graph \(A_{i}\in\mathcal{A}\) for label distribution prediction. With the SGD step-size \(\eta\), we have_

\[L_{(X,\tilde{A})}(\hbar)\leq\min_{A_{i}\in\mathcal{A}}\mathbb{E}[L_{(X,A_{i})} (\hbar)]+\frac{\ln k}{\eta n}+\frac{\eta}{8}.\]

**Remark 1**.: Theorem 1 indicates that the empirical risk of HGDL is no larger than the minimum empirical risk incurred by training label distribution learner on the optimal meta-path graph, as the error bound on the RHS reduces to \(\mathcal{O}(1/n)\) with constant \(k\) and \(\eta\). With Stochastic Gradient Descent (SGD) optimizer, larger number of target nodes \(n\) will lead to more training updates over them, diminishing the \(\mathcal{O}(1/n)\) bound faster. This finding substantiates the tightness of our meta-path learning strategy for the optimal graph topology \(\tilde{A}\).

Due to page limits, we defer the proof of Theorem 1 and the rest analysis to the Supplement. We then analyze the generalization error bound of HGDL and find that:

**Theorem 2**.: _Let \(\hbar\in\mathcal{H}:\mathcal{X}\times\mathcal{G}\rightarrow\mathbb{R}^{q}\) be an \(l\)-layer message-passing neural network with maximum hidden dimension \(k\), of which the \(i\)-th layer is parameterized by \(W_{i}\). Then for any \(\delta,\gamma,B>0\) and \(l>1\), with probability at least \(1-\delta\) we have_

\[L_{\mathcal{G}}\left(\hbar\right)-L_{(X,\tilde{A})}\left(\hbar \right)\leq\frac{2(\sqrt{2q}+\sqrt{2})q}{\sqrt{n}}\max_{i\in[n],j\in[l]}\left\| \mathbf{h}_{i}^{l}\right\|_{2}\] \[+3b\sqrt{\frac{\log 2/\delta}{2n}}+\mathcal{O}\bigg{(}\sqrt{ \frac{B^{2}d^{l-1}l^{2}k\log(lk)\mathcal{D}(W_{i})+\log\frac{nl}{\delta}}{ \gamma^{2}n}}\bigg{)},\]

_where \(\mathcal{D}(W_{i})=\prod_{i=1}^{l}\|W_{i}\|_{2}^{2}\cdot\sum_{i=1}^{l}\big{(} \left\|W_{i}\right\|_{F}^{2}/\left\|W_{i}\right\|_{2}^{2}\big{)}\) bounds the hypothesis space and \(b\) is a constant._

Remark 2**.: We remark several key observations from Theorems 1 and 2. First, the generalization capability of the algorithm is negatively impacted by a higher dimensional label space \(q\). Second, the robustness of HGDL decreases with larger \(B\) values, which gauges the magnitude of perturbations thus the inherent high data variance. Third, as the graph neural network architecture becomes deeper (larger \(l\)) or wider (larger \(k\)), the generalization risk increases, suggesting the potential risk of model overfitting. Forth, with larger \(n\), the generalization error bound diminishes, which indicates that the meta-path topology can be better delineated with an increased number of target nodes on the graph.

Remark 3**.: By combining Theorems 1 and 2, we observe that the generalization error bound of HGDL using \(\tilde{A}\) outperforms that of using an arbitrary meta-path graph \(A_{i}\). Further, it is easy to verify that the maximum degree of \(\tilde{A}\), denoted by \(d\), is smaller than that of \(A_{i}\), denoted by \(d_{i}\), _i.e.,_\(d\leq d_{i}\). \(\forall i\in[k]\). This rationalizes our graph transformer design in Sec 4.2, where the enforced topology and feature consistency in Eq. (2) sparsifies network connectivity, thereby intermediately encourages better model generalization.

## 6 Experiments

### Experiment Setup

Benchmark DatasetsTo our best knowledge, no heterogeneous graph dataset with _ground-true label distributions_ currently exists. To level the comparison study, we prepare five datasets with ground-truth node label distributions using existing heterogeneous graphs, including DBLP [33], ACM [33], YELP, DRUG [34], and URBAN [1]. Table 1 summarizes the data statistics. A detailed description on the dataset creation and preprocessing, as well as their domain and label semantic meanings, has been deferred to the Supplement B due to space limitation.

Compared ModelsIn total six competitors are identified for comparative study. As no model directly resolving the HGDL problem exists, we employ the state-of-the-art heterogeneous graph neural networks and integrate them KL-divergence loss to learn label distributions of nodes. They include: 1) GCN\({}_{\text{KL}}\): A baseline that uses graph constructed from each meta-path to train a vanilla GCN [35], using KL-divergence as loss function, and reports the best meta-path result; 2) HAN\({}_{\text{KL}}\): This baseline uses HAN [25] to integrate embedding from different meta-paths; and 3) SeHGNN\({}_{\text{KL}}\): This baseline uses SeHGNN [27], a transformer based approach, to aggregate meta-paths embedding with KL-divergence loss function. For ablation study, we further include three variants reduced from our proposed HGDL method, which include: 4) HGDL\({}_{-\text{TH}}\): it removes HGDL's topology homogenization (Sec 4.1), which learns embedding from each meta-path graph and reports the best meta-path result; 5) HGDL\({}_{-\text{transformer}}\): it uses GCN instead of the transformer (Sec 4.2) to learn embedding to validate HGDL's transformer for embedding learning; and 6) HGDL\({}_{\text{ED}}\): it replaces HGDL's topology and feature consistence-aware graph transformer (Sec. 4.2) by using a random edge dropout method [31].

Evaluation MetricsTo measure the discrepancy between two distributions, i.e., the predicted and true label distributions of target nodes, we identify six metrics: Cosine Distance (COD), Canberra Distance (CAD), Chebyshev Distance (CHD), Clark Distance (CLD); Intersection Score (IND), and Kullback-Leibler Divergence (KL). Their definitions and calculations are deferred to Supplement B.

\begin{table}
\begin{tabular}{l|c c c c c} \hline \hline Dataset & \# node type & \# nodes & \# edges & \# features & \# labels \\ \hline DRUG & 4 & 40,786 & 1,737,890 & 191 & 28 \\ ACM & 5 & 20,200 & 104,976 & 1,903 & 14 \\ DBLP & 4 & 27,325 & 148,246 & 8,920 & 4 \\ YELP & 4 & 8,052,542 & 7,905,197 & 19 & 9 \\ URBAN & 4 & 1,434 & 42,857 & 155 & 10 \\ \hline \hline \end{tabular}
\end{table}
Table 1: Summary of dataset statistics.

\begin{table}
\begin{tabular}{l l c c c c c} \hline \hline Dataset & Model & COID & CADL & CHD1 & CHD1 & SDDT & KL1 & WinfEnd-core \\ \hline \multirow{6}{*}{DRUG} & GCN\({}_{\text{KL}}\) & 0.210\({}_{-0.05}\) & 0.209\({}_{-1.00}\) & 0.245\({}_{-0.11}\) & 1.361\({}_{-0.10}\) & 0.057\({}_{-0.02}\) & 0.084\({}_{-0.15}\) & 42/0 \\  & GCN\({}_{\text{KL}}\) & 0.220\({}_{-0.05}\) & 0.209\({}_{-1.00}\) & 0.264\({}_{-0.11}\) & 1.263\({}_{-0.10}\) & 0.051\({}_{-0.02}\) & 0.059\({}_{-0.05}\) & 64/00 \\  & GCN\({}_{\text{KL}}\) & 0.299\({}_{-0.05}\) & 0.107\({}_{-0.10}\) & 0.264\({}_{-0.11}\) & 2.166\({}_{-0.10}\) & 0.051\({}_{-0.02}\) & 0.059\({}_{-0.05}\) & 64/00 \\  & HGDL\({}_{\text{KL}}\) & 0.299\({}_{-0.05}\) & 0.107\({}_{-0.10}\) & 0.264\({}_{-0.10}\) & 2.166\({}_{-0.10}\) & 0.051\({}_{-0.02}\) & 0.059\({}_{-0.05}\) & 64/00 \\  & HGDL\({}_{\text{KL}}\) & **0.199** & **0.175** & **0.217** & **0.165** & **0.164** & **0.165** & **0.164** \\  & HGDL\({}_{\text{KL}}\) & 0.199\({}_{-0.10}\) & 0.571\({}_{-0.10}\) & 0.259\({}_{-0.10}\) & 2.204\({}_{-0.10}\) & 0.057\({}_{-0.02}\) & 0.052\({}_{-0.10}\) & 44/20 \\  & HGDL\({}_{\text{KL}}\) & 0.212\({}_{-0.10}\) & 0.510\({}_{-0.02}\) & 0.264\({}_{-0.10}\) & 2.029\({}_{-0.10}\) & 0.051\({}_{-0.02}\) & 0.054\({}_{-0.10}\) & 44/20 \\  & HGDL\({}_{\text{KL}}\) & 0.204\({}_{-0.05}\) & 0.962\({}_{-0.10}\) & 0.229\({}_{-0.10}\) & 2.069\({}_{-0.10}\) & 0.051\({}_{-0.10}\) & 0.057\({}_{-0.10}\) & 44/20 \\ \hline \multirow{6}{*}{ACAL} & GCN\({}_{\text{KL}}\) & 0.217\({}_{-0.05}\) & 1310

### Results

Table 2 summarizes results of all methods. Overall, our HGDL wins in 99 out of 180 settings, among which on average 20 out of 30 settings excel in COD, CHD, IND, and KL metrics, 11 out of 30 in CAD, and 8 out of 30 in CLD. On DURG, ACM, DBLP, and URBAN datasets, HGDL outperforms its competitors in 83% settings in COD, CHD, IND, and KL metrics 46% in CAD, and 20% in CLD. Beyond its overall better comparative performance, we make the following observation on HGDL. First, \(\text{HAN}_{\text{KL}}\) and \(\text{SeHGNN}_{\text{KL}}\) achieve better performance on YELP and DBLP dataset for CAD and CLD metrics, but not on the other datasets and metrics. This shows that existing meta-path based methods cannot learn distribution prediction well. In general, these models show similar performance on YELP dataset. We hypothesize that this is due to the lack of rich feature information on YELP, of which the dimension of nodal features is 19 which is minimum across all datasets. Second, HGDL achieves the best results in KL-divergence by a large margin across all settings. On average, HGDL have a 15% improvement compared with the second best result across all datasets in KL-divergence. Given that KL-divergence is the loss objective in our framework, we extrapolate that HGDL converges well in terms of minimizing the distribution distance. Same observation can

Figure 4: KL and CLD tradeoff function example. The estimated probability distribution is [\(x_{1}\), \(x_{2}\), 0.9] and true probability distribution is [0.05,0.05,0.9], with \(x_{1}+x_{2}=0.1\). Horizontal axis is the \(x_{1}\) value and vertical axis is the loss for both CLD and KL divergence. Green dashed lines cover the tradeoff region where the CLD loss monotonically increases and KL-divergence decreases.

Figure 3: Comparisons between HGDL _vs._ results from a single meta-path (CAD and CLD are calculated in natural log for better visualization) for five datasets.

be drawn from the validation loss curve as shown in Supplement C Figures 5, 6, and 7. In addition, on metrics being strongly related to KL divergence including COD, CHD, and IND, our HGDL also enjoys significant performance improvement over other models. Among the metrics, CLD metrics shows a different patterns in terms of KL divergence, we show in Figure 4 that CLD and KL has a tradeoff region in small probability distribution and therefore caused such difference.

Third, the **ablation study** between HGDL and its variants, i.e., HGDL-transformer, HGDL-TH and HGDLED, demonstrate clear benefits of topology homogenization and consistency-aware graph transformer in aggregating meta-paths and nodal features for LDL learning for heterogeneous graphs (more results are deferred to the Section E.1 in Supplement C; there, we observe that HGDLed has no improvement in KL-divergence with different edge drop rates compared to HGDL-transformer, which is the model with 0 edge drop rate). We observe in Table 2 that HGDL-transformer shows comparable performance on ACM and YELP by tying HGDL in five and six metrics, respectively; however, HGDL outperforms it in all settings in other three datasets. Likewise, HGDL-TH ties HGDL across all metrics in YELP but is inferior to HGDL in all settings in other four datasets. HGDLED ties HGDL in six and five settings on YELP and URBAN, respectively, but is outperformed by HGDL for all other three datasets in all settings. The robust performance of HGDL can be attributed to two aspects. On the one hand, the improved results over those ablation variants suggest that our devised model components for proactive meta-path learning and attention modeling are indispensable. On other other hand, it substantiates the usefulness of our design that lets HGDL learn semantic fusion before the embedding learning. This end-to-end learning design provides a larger search space for embedding learning to find optimal solutions, whereas other methods that learn embedding and perform fusion in two independent stages may result in suboptimal node embeddings thus inferior LDL performance.

Fourth, even though the optimal meta-path choice may vary across different metrics and datasets, our HGDL that proactively learns to aggregate multiple meta-path graphs leads to the best performance in most cases. Figure 3 illustrates the performance from single meta-path graph and we can observe that our method outperforms the single best path results in all five datasets, with a larger improvement when the meta-path results are close (indicating each meta-path has similar information, _e.g._, ACM dataset in Figure 3 (b)) and a smaller improvement when one meta-path is significantly inferior to others (_e.g._, DBLP dataset Figure 3 (c) where \(p_{1}\) outperforms \(p_{2}\) with a large margin). These results validate the tightness of Theorem 1 by demonstrating the optimality of the learned meta-path graph in our HGDL method.

### Scalability Analysis

Denote the total number of nodes, hidden dimension size, and number of meta-path by \(n\), \(f\), and \(k\), respectively. The number of learnable parameters is \(\mathcal{O}(n)\) for graph topology homogenization, because HGDL requires learning an adjacency matrix from all meta-path, which involves \(knf+k^{2}f\) training parameters (_i.e._\(\mathcal{O}(n)\) complexity). Inducing adjacency matrix from features, _i.e._ the 2nd stage, only requires \(\mathcal{O}(1)\) number of learnable parameters, same as vanilla GCN. As a result, HGDL has \(\mathcal{O}(n)\) complexity. The runtime performance is detailed in Appendix H.3.

## 7 Conclusion

This paper explored a novel graph learning setting, namely, heterogeneous graph label distribution learning. Our goal is to predict label distributions of target nodes in a heterogeneous graph, which enables a finer-granular delineation of node properties compared to traditional single- or multi-class node classification. We demonstrated that the topological heterogeneity and inconsistency impose unique challenge for generalizing LDL into networked data, and proposed HGDL to overcome them. Specifically, HGDL proactively aggregates meta-paths to achieve optimal graph topology homogenization through attention mechanism, followed by a transformer-based approach to ensure topology and feature consistency for learning node label distributions. We analyzed the PAC-Bayes error bound of HGDL, and the result suggests the superiority of our design over those models learned from a single meta-path graph. Empirical results on five benchmark datasets validated the tightness of our analysis and substantiate that HGDL significantly outperformed its competitors.

## Acknowledgment

This work has been supported in part by the National Science Foundation (NSF) under Grant Nos. IIS-2236578, IIS-2236579, IIS-2302786, IIS-2441449, IOS-2430224, and IOS-2446522.

## References

* [1] N. L. Houssou, J. Guillaume, and A. Prigent, "A graph based approach for functional urban areas delineation," in _Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing_, pp. 652-658, 2019.
* [2] A. Rossi, G. Barlacchi, M. Bianchini, and B. Lepri, "Modelling taxi drivers' behaviour for the next destination prediction," _IEEE Transactions on Intelligent Transportation Systems_, vol. 21, no. 7, pp. 2980-2989, 2019.
* [3] P. Kar and P. Jain, "Supervised learning with similarity functions," _NeurIPS_, vol. 25, 2012.
* [4] A. Hefny, C. Downey, and G. J. Gordon, "Supervised learning for dynamical system learning," _NeurIPS_, vol. 28, 2015.
* [5] X. Geng, "Label distribution learning," _IEEE Trans. Knowl. Data Eng._, vol. 28, no. 7, pp. 1734-1748, 2016.
* [6] X. Jia, W. Li, J. Liu, _et al._, "Label distribution learning by exploiting label correlations," in _AAAI_, 2018.
* [7] T. Ren, X. Jia, W. Li, and S. Zhao, "Label distribution learning with label correlations via low-rank approximation," in _IJCAI_, p. 3325-3331, 2019.
* [8] J. Wang and X. Geng, "Theoretical analysis of label distribution learning," in _AAAI_, vol. 33, pp. 5256-5263, 2019.
* [9] X. Zhao, L. Qi, Y. An, and X. Geng, "Generalizable label distribution learning," in _Proceedings of the 31st ACM International Conference on Multimedia (MM-23)_, p. 8932-8941, 2023.
* [10] T. Ren, X. Jia, W. Li, L. Chen, and Z. Li, "Label distribution learning with label-specific features," in _Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence (IJCAI-19)_, pp. 3318-3324, International Joint Conferences on Artificial Intelligence Organization, 2019.
* [11] H. Xu, X. Liu, Q. Zhao, Y. Ma, C. Yan, and F. Dai, "Gaussian label distribution learning for spherical image object detection," in _CVPR_, 2023.
* [12] Z. Yao, Y. Fu, B. Liu, W. Hu, and H. Xiong, "Representing urban functions through zone embedding with human mobility patterns," in _IJCAI_, 2018.
* [13] Y. Luo, F.-l. Chung, and K. Chen, "Urban region profiling via multi-graph representation learning," in _CIKM_, pp. 4294-4298, 2022.
* [14] Y. Zheng, Y. Lin, L. Zhao, T. Wu, D. Jin, and Y. Li, "Spatial planning of urban communities via deep reinforcement learning," _Nature Computational Science_, vol. 3, no. 9, pp. 748-762, 2023.
* [15] Y. Liu, J. Ding, Y. Fu, and Y. Li, "Urbankg: An urban knowledge graph system," _ACM Transactions on Intelligent Systems and Technology_, vol. 14, no. 4, pp. 1-25, 2023.
* [16] Q. Lv, M. Ding, Q. Liu, Y. Chen, W. Feng, S. He, C. Zhou, J. Jiang, Y. Dong, and J. Tang, "Are we really making much progress? revisiting, benchmarking and refining heterogeneous graph neural networks," in _SIGKDD_, pp. 1150-1160, 2021.
* [17] C. Zhang, D. Song, C. Huang, A. Swami, and N. Chawla, "Heterogeneous graph neural network," in _Proc. of KDD_, pp. 793-803, 2019.
* [18] X. Fu, J. Zhang, Z. Meng, and I. King, "Magnn: Metapath aggregated graph neural network for heterogeneous graph embedding," in _WWW_, pp. 2331-2341, 2020.
* [19] H. Borchani, G. Varando, C. Bielza, and P. Larranaga, "A survey on multi-output regression," _Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery_, vol. 5, 07 2015.
* [20] Y. Wang, Y. Zhou, J. Zhu, X. Liu, W. Yan, and Z. Tian, "Contrastive label enhancement," in _Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence (IJCAI-23)_, pp. 4353-4361, 2023.

* [21] Y. Jin, R. Gao, Y. He, and X. Zhu, "Gldl: Graph label distribution learning," in _Proceedings of the 38th Annual AAAI Conference on Artificial Intelligence_, 2024.
* [22] Y. Dong, Z. Hu, K. Wang, Y. Sun, and J. Tang, "Heterogeneous network representation learning," in _Proc. of the 29th International Joint Conf. on Artificial Intelligence (IJCAI-20)_, pp. 4861-4867, 7 2020.
* [23] Y. Jing, Y. Yang, X. Wang, M. Song, and D. Tao, "Amalgamating knowledge from heterogeneous graph neural networks," in _CVPR_, pp. 15709-15718, 2021.
* [24] X. Wang, N. Liu, H. Han, and C. Shi, "Self-supervised heterogeneous graph neural network with co-contrastive learning," in _SIGKDD_, pp. 1726-1736, 2021.
* [25] W. Xiao, J. Houye, S. Chuan, W. Bai, C. Peng, Y. P., and Y. Yanfang, "Heterogeneous graph attention network," _WWW_, 2019.
* [26] Z. Hu, Y. Dong, K. Wang, and Y. Sun, "Heterogeneous graph transformer," in _Proceedings of The Web Conference_, p. 2704-2710, 2020.
* [27] X. Yang, M. Yan, S. Pan, X. Ye, and D. Fan, "Simple and efficient heterogeneous graph neural network," _Proceedings of the AAAI Conference on Artificial Intelligence_, pp. 10816-10824, 2023.
* [28] M. Wan, Y. Ouyang, L. Kaplan, and J. Han, "Graph regularized meta-path based transductive regression in heterogeneous information network," in _SDM_, pp. 918-926, 2015.
* [29] P. Velickovic, G. Cucurull, A. Casanova, A. Romero, P. Lio, and Y. Bengio, "Graph attention networks," in _ICLR_, 2018.
* [30] V. P. Dwivedi and X. Bresson, "A generalization of transformer networks to graphs," 2021.
* [31] Y. Rong, W. Huang, T. Xu, and J. Huang, "Dropedge: Towards deep graph convolutional networks on node classification," in _International Conference on Learning Representations (ICLR)_, 2020.
* [32] S. Kullback and R. A. Leibler, "On information and sufficiency," _The annals of mathematical statistics_, vol. 22, no. 1, pp. 79-86, 1951.
* [33] J. Tang, J. Zhang, L. Yao, J. Li, L. Zhang, and Z. Su, "Arnetminer: Extraction and mining of academic social networks," in _KDD_, pp. 990-998, 2008.
* [34] Y. Gu, S. Zheng, Q. Yin, R. Jiang, and J. Li, "REDDA: Integrating multiple biological relations to heterogeneous graph neural network for drug-disease association prediction," _Computers in Biology and Medicine_, 11 2022.
* [35] T. N. Kipf and M. Welling, "Semi-supervised classification with graph convolutional networks," in _ICLR_, 2017.
* [36] G. Landrum, P. Tosco, B. Kelley, Ric, D. Cosgrove, sriniker, gedeck, R. Vianello, NadineSchneider, E. Kawashima, G. Jones, D. N, A. Dalke, B. Cole, M. Swain, S. Turk, AlexanderSaveleyev, A. Vaucher, M. Wojcikowski, I. Take, V. F. Scalfani, D. Probst, K. Ujihara, guillaume godin, A. Pahl, R. Walker, J. Lehtivarjo, F. Berenger, jasondbiggs, and streets123, "rdkit/rdkit: 2023_09_4 (q3 2023) release," Jan. 2024.
* [37] D. S. Himmelstein, "User-friendly extensions to mesh v1.0," Feb. 2016.
* [38] V. D. Blondel, J.-L. Guillaume, R. Lambiotte, and E. Lefebvre, "Fast unfolding of communities in large networks," _Journal of statistical mechanics: theory and experiment_, vol. 2008, no. 10, p. P10008, 2008.
* [39] Q. Mao, Z. Liu, C. Liu, and J. Sun, "Hinormer: Representation learning on heterogeneous information networks with graph transformer," 2023.
* [40] N. Cesa-Bianchi and G. Lugosi, _Prediction, learning, and games_. Cambridge university press, 2006.
* [41] P. L. Bartlett, D. J. Foster, and M. J. Telgarsky, "Spectrally-normalized margin bounds for neural networks," _NeurIPS_, vol. 30, 2017.
* [42] B. Neyshabur, S. Bhojanapalli, and N. Srebro, "A pac-bayesian approach to spectrally-normalized margin bounds for neural networks," in _ICLR_, 2018.
* [43] R. Liao, R. Urtasun, and R. Zemel, "A pac-bayesian approach to generalization bounds for graph neural networks," in _ICLR_, 2020.

* [44] J. A. Tropp, "User-friendly tail bounds for sums of random matrices," _Foundations of computational mathematics_, vol. 12, pp. 389-434, 2012.
* [45] P. L. Bartlett and S. Mendelson, "Rademacher and gaussian complexities: Risk bounds and structural results," _Journal of Machine Learning Research_, vol. 3, no. Nov, pp. 463-482, 2002.
* [46] R. E. Schapire and Y. Freund, _Foundations of machine learning_, pp. 23-52. Mit Press, 2012.
* [47] A. Maurer, "A vector-contraction inequality for rademacher complexities," in _ALT_, pp. 3-17, Springer, 2016.
* [48] S. M. Kakade, K. Sridharan, and A. Tewari, "On the complexity of linear prediction: Risk bounds, margin bounds, and regularization," _NeurIPS_, vol. 21, 2008.
* [49] S.-H. Cha, "Comprehensive survey on distance/similarity measures between probability density functions," _City_, vol. 1, no. 2, p. 1, 2007.

## Appendix A Appendix / supplemental material

## Appendix B Roadmap

A structured guide to navigate the supplement content is organized as follows.

* **Supplement A:** Supplement A presents the pseudo-code of our proposed HGDL algorithm.
* **Supplement B:** Supplement B reports datasets and baseline methods used for the experimental study.
* **Supplement C:** Supplement C reports experimental settings and additional results.
* **Supplement D:** Supplement D elaborates the proof of Theorem 1 as introduced in Section 5 of the main manuscript.
* **Supplement E:** Supplement E elaborates the proof of Theorem 2 as introduced in Section 5 of the main manuscript.
* **Supplement F:** Supplement F carries out additional theoretical analysis explaining the rationality of HGDL for label distribution learning.

## Appendix C Supplement A: Pseudo-code and Implementation Details

Algorithm 1 lists the main steps of the HGDL framework where Lines 1 to 6 generate meta-path graphs and their adjacency matrices. Lines 7 to 10 denote the optimal graph topology homogenization (Sec 4.1 of the main manuscript), and Lines 11 to 15 are local topology and global feature consistency-aware graph transformer (Sec 4.2 of the main manuscript). Lines 16 to 20 denote the loss terms and the model training process.

## Appendix D Supplement B: Experiments and Datasets

### Dataset Description

Because no benchmark heterogeneous graph datasets with label distributions currently exist, we create four datasets using existing heterogeneous graphs including DBLP [33], ACM [33], YELP, and DRUG dataset [34]. Table 3 reports number of nodes/edges, number of each node/edge types, and number of labels for each dataset. Table 4 reports meta-paths and label semantic for each datasets. Number of features are refer to the content attribute/features of the target node types. In our experiments, we did not use any content information of non-target nodes (so only target nodes have features).

* **DBLP** is a citation network [33] with four types of nodes (author, paper, conference, and term nodes). Author nodes are our target nodes. To construct a label distribution, we labeled each author with a distribution of conference areas, using the history of each author's published papers at different conference areas. The author's node features are a bag of words of all papers published by the author.
* **ACM** is a citation network from [33] with five types of nodes (author, paper, conference, affiliation, and subject nodes). Author nodes are our target nodes. We first extract one third of the authors and then labeled them based on the subjects of their published papers. Similar to the DBLP dataset, each author's features are also a bag-of-word representation of the author's papers.
* **YELP** is an open-access review network with four types of nodes (business, user, tip, and review nodes). User nodes are our target nodes. We label each user by counting the ratings of the business each user made reviews on and normalize the countings of each rate to a distribution. User's features are the bag of words of their reviews.

\begin{table}
\begin{tabular}{l l l} \hline \hline Datasets & Meta-Paths & Label semantics \\ \hline DRUG & dpd, dsd, dpgpd & See Table 6 \\ ACM & apa, afa, apspa & \{KDD, SIGMOD, WWW, SIGIR, CIKM, SODA, STOC, SOSP, SPAA, SIGCOMM, MobiCOMM, ICML, COLT, VLDB\} \\ DBLP & apcpa, aptpa & \{Database, Data Mining, AI, Information Retrieval\} \\ YELP & urbru, utbtu & \{1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5\} \\ URBAN & rsr, rlr, rtr & \{Accommodation and Residence, Workplace and Public Service, Sustenance and Leisure Places, Farmland, Transportation, Business and Industry, Education, Healthcare, Greenfield, Worship\} \\ \hline \hline \end{tabular}
\end{table}
Table 4: Meta-paths and label semantics of the benchmark datasets

\begin{table}
\begin{tabular}{l l l l l} \hline \hline Dataset & Node Types & \# features & Edge Types & \# Labels \\ \hline DRUG & D:Drug(894)/S:Disease(454) & 191 & DP(4397)/DS(2704) & 28 \\  & P:Protein(18877)/G:gene(20561) & & PG(18545)/PP(201382) & \\  & & & GG(712546)/DD(798316) & \\ ACM & A:Author(5810)/P:Paper(12499) & 1903 & AP(37055)/PC(12499) & 14 \\  & S:Subject(73)/C:conference(14) & & PS(12499)/PF(12499) & \\  & F:Affiliation(1804) & & AF(30424) & \\ DBLP & A:Author(4057)/P:Paper(14328) & 8920 & AP(19645)/PT(114273) & 4 \\  & T:Term(8920)/C:conference(20) & & PC(14328) & \\ YELP & U:User(3001)/B:Business(150346) & 19 & UR(3001)/RB(6990280) & 9 \\  & R:Review(6990280)/T:Tip(908915) & & UT(3001)/BT(908915) & \\ URBAN & NR:Nature Residence(622) & 155 & NR-CS (14818) & 10 \\  & CS:Comprehensive Service(449) & & NR-GL (8328) & \\  & GL:Green Leisure(202) & & NR-TI (11736) & \\  & TJ:Transit Junction(161) & & \\ \hline \hline \end{tabular}
\end{table}
Table 3: Benchmark dataset data statistics* **DRUG** is a drug-disease-protein-gene network from [34], with four types of nodes (drug, disease, protein, and gene nodes). Drug nodes are our target nodes. The label distribution of each drug node is obtained by using associated disease etiology (using top-level categories from Medical Subject Headings, MeSH, disease database). The node features is

\begin{table}
\begin{tabular}{l l l} \hline \hline
**Class 1** & **Class 2** & **Class 3** & **Class 4** \\ \hline
0.8774 \(\pm\) 0.1755 & 0.0415 \(\pm\) 0.1086 & 0.0131 \(\pm\) 0.0619 & 0.0680 \(\pm\) 0.1226 \\
0.0628 \(\pm\) 0.1188 & 0.7733 \(\pm\) 0.2157 & 0.0767 \(\pm\) 0.1463 & 0.0873 \(\pm\) 0.1536 \\
0.0161 \(\pm\) 0.0576 & 0.0438 \(\pm\) 0.1023 & 0.8667 \(\pm\) 0.1881 & 0.0734 \(\pm\) 0.1472 \\
0.0309 \(\pm\) 0.0879 & 0.0364 \(\pm\) 0.0907 & 0.0266 \(\pm\) 0.0757 & 0.9061 \(\pm\) 0.1652 \\ \hline \hline \end{tabular}
\end{table}
Table 6: DRUG label semantics

\begin{table}
\begin{tabular}{l l} \hline \hline DRUG prefix MeSH code & Name \\ \hline C01 & bacterial infections and mycoses \\ C02 & virus diseases \\ C03 & parasitic diseases \\ C04 & neoplasms \\ C05 & musculoskeletal diseases \\ C06 & digestive system diseases \\ C07 & stomatognathic diseases \\ C08 & respiratory tract diseases \\ C09 & otorhinolaryngologic diseases \\ C10 & nervous system diseases \\ C11 & eye diseases \\ C12 & urologic and male genital diseases \\ C13 & female genital diseases and pregnancy complications \\ C14 & cardiovascular diseases \\ C15 & hemic and lymphatic diseases \\ C16 & congenital, hereditary, and neonatal diseases and abnormalities \\ C17 & skin and connective tissue diseases \\ C18 & nutritional and metabolic diseases \\ C19 & endocrine system diseases \\ C20 & immune system diseases \\ C22 & animal diseases \\ C23 & pathological conditions, signs and symptoms \\ C25 & Chemically-Induced Disorders \\ C26 & Wounds and Injuries \\ E01 & Diagnosis \\ F01 & Behavior and Behavior Mechanisms \\ F03 & Mental Disorders \\ G07 & Physiological Phenomena \\ \hline \hline \end{tabular}
\end{table}
Table 7: DBLP dataset average label distributions (mean\(\pm\)Std) for all nodes _w.r.t._ different classes. To generate this average, label distributions are grouped by their dominant class. Average label distributions are then calculated within their respective groups. Standard deviations are calculated between each class within each individual group. The table is \(q\times q\), where \(q\) denotes the number of classes. The diagonal values denote the dominant class’s probability value. The lower the diagonal values, the more spread out the class probability is.

\begin{table}
\begin{tabular}{l l l} \hline \hline Drug name & Drug ID & Drug SMILES \\ \hline Clobazam & DB00734 & Cc Inc2n(c(=0)c1CCN1CCC(c3noc4cc(F)ccc34)CC1)CCCC2 \\ Vinorelbine & DB00987 & NcIccn([CH]2O[CH](CO)[CH](O)[CH]2O)c(=0)n1 \\ Carvedilol & DB00812 & CCCCC1C(=O)N(c2cccc2)N(c2cccc2)C1=O \\ \hline \hline \end{tabular}
\end{table}
Table 5: Examples of drug name, ID, and drug in SMILES notation (SMILES: Simplified Molecular Input Line Entry System)

[MISSING_PAGE_EMPTY:17]

[MISSING_PAGE_FAIL:18]

node (e.g. Class 7 of the ACM dataset in Table 8, or Classes 21, 25, and 28 in the DRUG dataset in Table 10). In this case, the average label distributions of the class are reported as 0 in the tables.

### Baselines

We extend existing heterogeneous graph learning methods to integrate KL-divergence loss, and implement three baselines for comparisons. In addition, three variants of the proposed HGDL method are compared for ablation study purposes:

* GCN\({}_{\text{KL}}\): A baseline uses graph constructed from each meta-path to train a vanilla GCN, using KL-divergence as loss function, and reports the best meta-path result. This baseline is used to demonstrate whether the proposed HGDL can outperform the best single meta-path result.
* HAN\({}_{\text{KL}}\): This baseline is to compare HGDL's semantic fusion component with HAN [25], a classical heterogeneous network learning semantic fusion method. HAN\({}_{\text{KL}}\) uses HAN to integrate embedding from meta-path graphs created from different meta-paths, and uses KL-divergence as the loss function for training.
* SeHGNN\({}_{\text{KL}}\) This baseline is to compare HGDL's semantic fusion with SeHGNN [27], a state of the art transformer based heterogeneous semantic fusion learning method. SeHGNN\({}_{\text{KL}}\) uses neighbor aggregation proposed by SeHGNN to aggregate meta-paths embedding, with KL-divergence being used as the loss function for training.
* HGDL: The proposed HGDL method.
* HGDL\({}_{\text{-TH}}\): This is a variant of the HGDL for ablation study. HGDL\({}_{\text{-TH}}\) removes the graph topology homogenization module (Sec 4.1). The embedding is trained from each meta-path with topology and feature consistence-aware graph transformer (Sec 4.2) being applied to each meta-path. The result of the best meta-path is reported, and the purpose is to demonstrate HGDL's topology homogenization effectiveness.
* HGDL\({}_{\text{-transformer}}\): This is a variant of the HGDL for ablation study. HGDL\({}_{\text{-transformer}}\) uses GCN, instead of the transformer (Sec 4.2), to learn embeddings. This serves as an ablation study to show the advantage of HGDL's transformer component for embedding learning.
* HGDL\({}_{\text{ED}}\) This is a variant of the HGDL for ablation study. HGDL\({}_{\text{ED}}\) replaces HGDL's topology and feature consistence-aware graph transformer (Sec. 4.2) using random edge dropout method [31]. The purposes to demonstrate the advantage of consistent-aware graph transfer, which resembles to learnable edge dropping, compared to random edge dropout.

### Experiment Setup

All results reported in the paper are based on 5 times average for each method. Hyperparameters of all the baselines include the hidden dimension for the embedding learning and the hidden dimension for the semantic fusion learning (if the semantic fusion part exists), and the learning rate. In practice, a 0.005 learning rate is fixed for all the baselines unless it is observed that specific method cannot converge under such learning rate or can converge much faster with a large learning rate. An early stop patience signal is set and a maximum number of epochs is fixed. In practice, we observed convergence before reaching maximum number of epochs in general. For the methods that cannot learn well with all the hyperparameter search, we report the best results we got. For the HDGL\({}_{\text{ED}}\) method, the originally learned feature topology for HGDL is replaced by a 0-1 matrix generated by a Bernoulli distribution with a drop rate provided to convert to a 0-1 matrix. The drop rate for the HDGL\({}_{\text{ED}}\) baseline in Table 2 in the main manuscript is 0.1. Fig 5 provides the results of different drop rate cases. For HGDL we have additional hyperparameters negative slope of Leaky Relu activation and \(\gamma\) for regularization loss.

The train:validation:test splits for DRUG, ACM, DBLP, YELP, and URBAN dataset are 8:1:1, 7:1:2, 4:1:5, 8:1:1, 5:3:2, respectively. We used a smaller training set (40%) for DBLP because because this dataset has comprehensive nodal features (8,920 features) which are the-bag-of-words of papers published by authors. DBLP also has much less number of labels (4 classes), compared to other datasets. The rich nodal features, combined with less number of classes, provide rather rich information to derive research fields. So we reduce the training set size, compared to the test set, to provide less label information for learning.

### Evaluation metric

Given one predicted label distribution \(\hat{y}\) and its corresponding ground truth distribution \(y\), the six metrics used in the Table 2 can be defined as the following:

* Cosine Distance(COD): \[\text{COD}(y,\hat{y})=1-\frac{y\cdot v}{\|y\|\|\hat{y}\|}\] (4)
* Canberra Distance(CAD): \[\text{CAD}(y,\hat{y})=\sum_{i}\frac{|y_{i}-\hat{y}_{i}|}{|y_{i}|+|\hat{y}_{i}|}\] (5)
* Chebyshev Distance(CHD): \[\text{CHD}(y,\hat{y})=\max_{i}|y_{i}-\hat{y}_{i}|\] (6)
* Clark Distance (CLD): \[\text{CLD}(y,\hat{y})=\sqrt{\sum_{i}\frac{(y_{i}-\hat{y}_{i})^{2}}{(y_{i}+ \hat{y}_{i})^{2}}}\] (7)
* Intersection Score(IND): \[\text{IND}(y,\hat{y})=\sum_{i}\min(y_{i},\hat{y}_{i})\] (8)
* Kullback-Leibler Divergence(KL): \[\text{KL}(y,\hat{y})=\sum_{i}y_{i}\cdot\log\frac{y_{i}}{\hat{y}_{i}},\] (9)

## Appendix E Supplement C: Additional Results and Analysis

### Edge Dropping Comparisons

HGDL treats the learnt feature attention as another adjacency matrix, and incorporates it into the graph adjacency matrix by a \(\odot\) operator, which provides an intersection of neighbor sets for a node, _i.e._, the resulting convolution layer is propagated to a neighbor set that both feature and graph topology agrees on. This operation is similar to the recently proposed drop message idea that randomly masks edges for the nodes. Instead of random masking, HGDL selects the neighbors that both feature and graph topology agree on. In other words, Eq. (2) in the main manuscript functions similarly to the edge dropout [31]; in lieu of randomly removing edges, we enforce a neighbor-set intersection, where the information is only propagated from the neighbors on which the feature space and meta-path topology both agree.

To compare the performance between our approach _vs._ the edge dropout [31], the variant \(\text{HGDL}_{\text{ED}}\) is used to replace our transformer based approach by using random edge dropout. In this case, for \(\text{HDGL}_{\text{ED}}\), the originally learned feature topology for \(\text{HGDL}\) is replaced by a 0-1 matrix generated by a Bernoulli distribution with a drop rate provided to convert to a 0-1 matrix. For comparisions, we vary the edge drop rates and report \(\text{HGDL}_{\text{ED}}\)'s performance in Figure 5. The results show that that \(\text{HGDL}_{\text{ED}}\) with random edge dropping doesn't necessarily help improve the distribution learning, implying that our method works not just by relying on the decreasing of the edge number, but also relying on choosing the proper edges to drop.

### Validation Loss Comparisons

Figures 6, 7, and 8 report the training process validation loss (_w.r.t._ KL-divergence loss) between \(\text{HAN}_{\text{KL}}\), \(\text{seHGNN}_{\text{KL}}\), and \(\text{HGDL}\). Because early stop is applied to all methods, they terminate at respective number of epochs. In our experiments, a patience score is used to determine the minimum loss. A method will continue if a smaller validation loss is found within patience number of epochs after the current smallest loss, and terminates otherwise.

\begin{table}
\begin{tabular}{l l l l l l l} \hline \hline  & \multicolumn{6}{c}{DRUG} \\ \hline Model & COD\(\downarrow\) & CAD\(\downarrow\) & CHD\(\downarrow\) & CLD\(\downarrow\) & IND\(\uparrow\) & KL\(\downarrow\) \\ \hline GCN\({}_{\text{KL}}\) & 0.220\({}_{\pm.025}\) & 9.209\({}_{\pm.740}\) & 0.245\({}_{\pm.031}\) & 1.963\({}_{\pm.134}\) & 0.676\({}_{\pm.029}\) & 0.484\({}_{\pm.075}\) \\ \hline HAN\({}_{\text{KL}}\) & 0.279\({}_{\pm.023}\) & 10.084\({}_{\pm.823}\) & 0.268\({}_{\pm.027}\) & 2.155\({}_{\pm.148}\) & 0.632\({}_{\pm.025}\) & 0.579\({}_{\pm.055}\) \\ \hline SeHGNN\({}_{\text{KL}}\) & 0.286\({}_{\pm.018}\) & 10.178\({}_{\pm.781}\) & 0.267\({}_{\pm.020}\) & 2.166\({}_{\pm.143}\) & 0.640\({}_{\pm.016}\) & 0.600\({}_{\pm.059}\) \\ \hline GLDL & 0.199\({}_{\pm.064}\) & **8.887\({}_{\pm.838}\)** & 0.232\({}_{\pm.044}\) & **1.89\({}_{\pm.17}\)** & 0.699\({}_{\pm.049}\) & 0.409\({}_{\pm.105}\) \\ \hline HINormer & 0.365\({}_{\pm.028}\) & 10.563\({}_{\pm.571}\) & 0.308\({}_{\pm.029}\) & 2.227\({}_{\pm.099}\) & 0.575\({}_{\pm.023}\) & 0.742\({}_{\pm.102}\) \\ \hline HGDL & **0.168\({}_{\pm.019}\)** & 9.179\({}_{\pm.574}\) & **0.217\({}_{\pm.017}\)** & 1.957\({}_{\pm.114}\) & **0.710\({}_{\pm.020}\)** & **0.392\({}_{\pm.044}\)** \\ \hline HGDL\({}_{-\text{transformer}}\) & 0.199\({}_{\pm.014}\) & 9.371\({}_{\pm.679}\) & 0.235\({}_{\pm.017}\) & 2.004\({}_{\pm.137}\) & 0.687\({}_{\pm.021}\) & 0.492\({}_{\pm.059}\) \\ \hline HGDL\({}_{-t}\) & 0.212\({}_{\pm.023}\) & 9.510\({}_{\pm.602}\) & 0.240\({}_{\pm.018}\) & 2.029\({}_{\pm.110}\) & 0.671\({}_{\pm.020}\) & 0.462\({}_{\pm.050}\) \\ \hline HGDL\({}_{ed}\) & 0.204\({}_{\pm.026}\) & 9.602\({}_{\pm.882}\) & 0.239\({}_{\pm.028}\) & 2.040\({}_{\pm.162}\) & 0.681\({}_{\pm.030}\) & 0.574\({}_{\pm.085}\) \\ \hline \multicolumn{6}{c}{DBLP} \\ \hline Model & COD\(\downarrow\) & CAD\(\downarrow\) & CHD\(\downarrow\) & CLD\(\downarrow\) & IND\(\uparrow\) & KL\(\downarrow\) \\ \hline GCN\({}_{\text{KL}}\) & 0.031\({}_{\pm.004}\) & 2.852\({}_{\pm.009}\) & 0.091\({}_{\pm.006}\) & 1.647\({}_{\pm.002}\) & 0.908\({}_{\pm.006}\) & 0.114\({}_{\pm.011}\) \\ \hline HAN\({}_{\text{KL}}\) & 0.025\({}_{\pm.002}\) & 2.819\({}_{\pm.012}\) & 0.071\({}_{\pm.004}\) & 1.633\({}_{\pm.007}\) & 0.929\({}_{\pm.004}\) & 0.082\({}_{\pm.008}\) \\ \hline SeHGNN\({}_{\text{KL}}\) & 0.086\({}_{\pm.140}\) & 2.887\({}_{\pm.170}\) & 0.155\({}_{\pm.208}\) & **1.624\({}_{\pm.049}\)** & 0.842\({}_{\pm.214}\) & 0.252\({}_{\pm.397}\) \\ \hline GLDL & 0.019\({}_{\pm.001}\) & 2.8\({}_{\pm.009}\) & **0.056\({}_{\pm.002}\)** & 1.633\({}_{\pm.004}\) & 0.943\({}_{\pm.003}\) & 0.06\({}_{\pm.003}\) \\ \hline HINormer & 0.053\({}_{\pm.008}\) & 2.936\({}_{\pm.013}\) & 0.146\({}_{\pm.019}\) & 1.669\({}_{\pm.008}\) & 0.853\({}_{\pm.019}\) & 0.22\({}_{\pm.025}\) \\ \hline HGDL & **0.019\({}_{\pm.002}\)** & **2.796\({}_{\pm.014}\)** & 0.057\({}_{\pm.005}\) & 1.633\({}_{\pm.005}\) & **0.943\({}_{\pm.005}\)** & **0.057\({}_{\pm.011}\)** \\ \hline HGDL\({}_{-\text{transformer}}\) & 0.025\({}_{\pm.002}\) & 2.828\({}_{\pm.004}\) & 0.074\({}_{\pm.005}\) & 1.642\({}_{\pm.001}\) & 0.925\({}_{\pm.005}\) & 0.090\({}_{\pm.008}\) \\ \hline HGDL\({}_{-t}\) & 0.020\({}_{\pm.002}\) & 2.808\({}_{\pm.013}\) & 0.062\({}_{\pm.005}\) & 1.637\({}_{\pm.005}\) & 0.937\({}_{\pm.005}\) & 0.070\({}_{\pm.011}\) \\ HGDL\({}_{ed}\) & 0.023\({}_{\pm.001}\) & 2.819\({}_{\pm.005}\) & 0.070\({}_{\pm.003}\) & 1.639\({}_{\pm.003}\) & 0.929\({}_{\pm.003}\) & 0.082\({}_{\pm.006}\) \\ \hline \hline \end{tabular}
\end{table}
Table 13: Experimental results of HINormer and GLDL on the Drug and DBLP datasets, where HINormer is a recent heterogeneous graph learning baseline and GLDL is for LDL in homogeneous graphs.

Figure 5: HGDL\({}_{\text{ED}}\) baseline with different edge drop rates on DRUG and ACM dataset.

Figure 8: Training process KL-divergence validation loss comparisons on the ACM dataset. The \(x\)-axis denotes epochs, and the \(y\)-axis denotes training validation loss. Early stop is applied to all three methods, so methods terminate at different epochs. A method terminates at the minimum loss, if no smaller loss is found after continuing a patience number of epochs.

Figure 6: Training process KL-divergence validation loss comparisons on the DRUG dataset. The \(x\)-axis denotes epochs, and the \(y\)-axis denotes training validation loss. Early stop is applied to all three methods, so methods terminate at different epochs. A method terminates at the minimum loss, if no smaller loss is found after continuing a patience number of epochs.

Figure 7: Training process KL-divergence validation loss comparisons on the DBLP dataset. The \(x\)-axis denotes epochs, and the \(y\)-axis denotes training validation loss. Early stop is applied to all three methods, so methods terminate at different epochs. A method terminates at the minimum loss, if no smaller loss is found after continuing a patience number of epochs.

The comparisons show that HGDL achieves the smallest KL-divergence loss across all datasets. For the DRUG dataset (Figure 6), HGDL converges at much better optimal point than the other two baselines. This is also evident by the results shown in the Table 2 of the main manuscript (which are validated on the test set nodes).

### Sensitive Analysis of hyperparameter

To study the effect of hyperparameter \(\gamma\) on the model performance, we explore the \(\gamma\) value ranging from [0,1e-5,1e-4,1e-3,1e-2,0.1] and see how the KL divergence metric is affected by different \(\gamma\) values for our five datasets shown in Figure 9. We can observe that optimal \(\gamma\) values vary for different datasets and therefore it is important to search for a proper \(\gamma\) value for each datasets.

### Comparison against HINormer and GLDL

HINormer [39] is a recent heterogenous graph learning baseline and GLDL method is a recent LDL learning method in homogeneous graphs. To make a more comprehensive comparisons, Table 13 provides the results applied to DBLP and Drug dataset with these two additional baselines. We observe that our method is still competitive in most metrics in terms of GLDL and is more superior to HINormer method in general. This further validates the superiority of our design on heterogenous settings.

## Appendix F Supplement D: Proof of Theorem 1

**Theorem 3**.: _Let \(\mathbb{E}[L_{(X,A_{i})}(\hbar)]\) be the empirical risk of using the \(i\)-th meta-path graph \(A_{i}\in\mathcal{A}\) for label distribution prediction. With the SGD step-size \(\eta\), we have_

\[L_{(X,\hat{A})}(\hbar)\leq\min_{A_{i}\in\mathcal{A}}\mathbb{E}[L_{(X,A_{i})}( \hbar)]+\frac{\ln k}{\eta n}+\frac{\eta}{8}.\]

Proof.: We define the cumulative risk \(L_{(X,A_{i})}(\hbar)=\sum_{i=1}^{n}\left[\ell\big{(}\hbar(X,A_{i})[i],y_{i} \big{)}\right]\) over \(n\) training iterations, and a quantitative variable \(Q_{n}\) as follows:

\[Q_{n}=\exp(-\eta L_{(X,A_{1})}(\hbar))+\ldots\exp(-\eta L_{(X,A_{k})}(\hbar)),\] (10)

where it is trivial to derive \(Q_{1}=k\), as no risk will be suffered if no target node attends training. By performing stochastic gradient descent (SGD) over \(n\) iterations, we have

\[\ln\frac{Q_{n}}{Q_{1}}=\ln\sum_{A_{i}\in\mathcal{A}}\exp(-\eta L_ {(X,A_{i})}(\hbar))-\ln k\] \[\geq \ln\max_{A_{i}\in\mathcal{A}}\big{\{}\exp(-\eta L_{(X,A_{i})}( \hbar))\big{\}}-\ln k\] \[= -\eta\min_{A_{i}\in\mathcal{A}}\big{\{}L_{(X,A_{i})}(\hbar)\big{\}} -\ln k,\] (11)

Figure 9: Sensitive analysis of \(\gamma\), ranging from 0, 1e-5, 1e-4, 1e-3, 1e-2, and 0.1, converted to the values of \(log(\gamma)\) as -6, -5, -4, -3, -2, and -1 along the X-axis.

\[\ln\frac{Q_{n}}{Q_{n-1}} =\ln\frac{\sum_{A_{i}\in\mathcal{A}}\big{[}\exp(-\eta(L_{(X,A_{i})}^ {(n-1)}(\hbar)+\ell_{i}(\hat{y}_{n},y_{n}))\big{]}}{\sum_{A_{i}\in\mathcal{A}} \exp(-\eta L_{(X,A_{i})}^{(n-1)}(\hbar))}\] \[=\ln\sum_{A_{i}\in\mathcal{A}}\text{softmax}(-\eta L_{(X,A_{i})}^ {(n-1)}((\hbar))\cdot\exp(-\eta\ell_{i}(\hat{y}_{n},y_{n}))\] \[\leq\ln\sum_{A_{i}\in\mathcal{A}}\Theta[:,i]\exp(-\eta\ell_{i}( \hat{y}_{n},y_{n})),\] (12)

where \(\ell_{i}(\hat{y}_{n},y_{n})=\ell(\hbar(X,A_{i})[n],y_{n})\) denotes the immediate loss evaluated at the \(n\)-th training iteration based on the \(i\)-th meta-path graph topology. The attention matrix \(\Theta\) are with all entries non-negative by its definition. To proceed, we introduce the lemma by [40].

**Lemma 4** (Hoeffding Inequality).: _Let \(X\) be a random variable with \(a\leq X\leq b\). Then for any \(s\in\mathbb{R}\),_

\[\ln\mathbb{E}\big{(}e^{sX}\big{)}\leq s\mathbb{E}X+\frac{s^{2}(b-a)^{2}}{8}.\]

With normalized immediate loss \(\ell_{i}(\hat{y}_{n},y_{n})\in[0,1],\;\forall i\), we can relax Eq. (12) based on the convexity of \(\ell\) and \(\hbar\):

\[\ln\frac{Q_{n}}{Q_{n-1}} \leq-\eta\big{[}\sum_{A_{i}\in\mathcal{A}}\Theta[:,i]\ell_{i}( \hat{y}_{n},y_{n})\big{]}+\frac{\eta^{2}}{8}\] \[\leq-\eta\big{[}\ell(\hbar(X,\sum_{i=1}^{k}\Theta[:,i]A_{i})[n],y _{n})\big{]}+\frac{\eta^{2}}{8}\] \[\leq-\eta\big{[}\ell(\hbar(X,\tilde{A})[n],y_{n})\big{]}+\frac{ \eta^{2}}{8}.\] (13)

We can observe that over \(n\) training iterations:

\[\ln\frac{Q_{n}}{Q_{n-1}}+\ln\frac{Q_{n-1}}{Q_{n-2}}+\ldots+\ln \frac{Q_{2}}{Q_{1}}\] \[= \ln\left(\frac{Q_{n}}{Q_{n-1}}\cdot\frac{Q_{n-1}}{Q_{n-2}}\cdots \frac{Q_{2}}{Q_{1}}\right)=\ln\frac{Q_{n}}{Q_{1}}\] \[\leq-\eta\sum_{i=1}^{n}\ell(\hbar(X,\tilde{A})[i],y_{i})+\frac{n \cdot\eta^{2}}{8}.\] (14)

Chaining Eq. (11) and Eq. (14) we arrive at:

\[\sum_{i=1}^{n}\ell(\hbar(X,\tilde{A})[i],y_{i})\leq\min_{A_{i}\in\mathcal{A}} \big{\{}L_{(X,A_{i})}(\hbar)\big{\}}+\frac{\ln k}{\eta}+\frac{n\cdot\eta}{8},\]

and dividing the both sides by \(n\), we have

\[L_{(X,\tilde{A})}(\hbar)\leq\min_{A_{i}\in\mathcal{A}}\mathbb{E}[L_{(X,A_{i}) }(\hbar)]+\frac{\ln k}{\eta n}+\frac{\eta}{8}.\]

Note that \(\mathbb{E}[L_{(X,A_{i})}(\hbar)]=\frac{1}{n}L_{(X,A_{i})}(\hbar)\) concludes the proof.

## Appendix G Supplement E: Proof of Theorem 2

**Theorem 5**.: _Let \(\hbar\in\mathcal{H}:\mathcal{X}\times\mathcal{G}\rightarrow\mathbb{R}^{q}\) be an \(l\)-layer message-passing neural network with maximum hidden dimension \(k\), of which the \(i\)-th layer is parameterized by \(W_{i}\). Then for any \(\delta,\gamma,B>0\) and \(l>1\), with probability at least \(1-\delta\) we have_

\[L_{\mathcal{G}}\left(\hbar\right)-L_{\left(X,\tilde{A}\right)} \left(\hbar\right)\leq\frac{2(\sqrt{2q}+\sqrt{2})q}{\sqrt{n}}\max_{i\in\left[n \right],j\in\left[l\right]}\left\|\mathbf{h}_{i}^{j}\right\|_{2}\] \[+3b\sqrt{\frac{\log 2/\delta}{2n}}+\mathcal{O}\Bigg{(}\sqrt{ \frac{B^{2}d^{l-1}l^{2}k\log(lk)\mathcal{D}(W_{i})+\log\frac{nI}{\delta}}{ \gamma^{2}n}}\Bigg{)},\]

_where \(\mathcal{D}(W_{i})=\prod_{i=1}^{l}\left\|W_{i}\right\|_{2}^{2}\cdot\sum_{i=1}^ {l}\left(\left\|W_{i}\right\|_{F}^{2}/\left\|W_{i}\right\|_{2}^{2}\right)\) bounds the hypothesis space and \(b\) is a constant._

ProofWe first try to explore the boundary of a GCN without label distribution, and use the multi-class \(\gamma\)-margin loss following [41, 42]. The generalization error and the empirical error are defined as,

\[L_{\mathcal{G}}\left(f_{w}\right)=\underset{z\sim\mathcal{D}}{ \mathbb{P}}\left(f_{w}(X,A)[y]\leq\gamma+\max_{j\neq y}f_{w}(X,A)[j]\right),\] (15) \[L_{\left(X,A\right)}\left(f_{w}\right)=\frac{1}{n}\sum_{z_{i}\in S }\mathbf{1}\left(f_{w}(X,A)[y]\leq\gamma+\max_{j\neq y}f_{w}(X,A)[j]\right),\]

where \(\gamma>0\) and \(f_{w}(X,A)\) is the \(l\)-th layer representations, i.e., \(H_{l}=f_{w}(X,A)\). \(\mathbf{1}\) is a all-one vector. Two necessary lemmas are derived from this. First, a margin-based generalization bound is given to guarantee that, as long as the change of the output brought by the perturbations is small with a large probability, the corresponding generalization bound [42] is defined as:

**Lemma 6**.: _Let \(f_{w}(x):\mathcal{X}\rightarrow\mathbb{R}^{K}\) be any model with parameters \(w\), and let \(P\) be any distribution on the parameters that is independent of the training data. For any \(w\), we construct a posterior \(Q(w+u)\) by adding any random perturbation \(u\) to \(w\), s.t., \(\mathbb{P}\left(\max_{x\in\mathcal{X}}\left|f_{w+u}(x)-f_{w}(x)\right|_{\infty }<\frac{1}{4}\right)>\frac{1}{2}\). Then, for any \(\gamma,\delta>0\), with probability at least \(1-\delta\) we have:_

\[L_{\mathcal{G}}\left(f_{w}\right)\leq L_{\left(X,A\right)}\left(f_{w}\right)+ \sqrt{\frac{2D_{\mathrm{KL}}(Q(w+u)\left\|P\right\rangle+\log\frac{8n}{\delta }}{2(n-1)}},\] (16)

where \(n\) is the number of instances of training set. Hence, in order to apply Lemma 6, we must ensure that the change of the output brought by the weight perturbations is small with a large probability. In the following lemma, we bound this change using the product of the spectral norms of learned weights at each layer and a term depending on some statistics of the graph [43].

**Lemma 7**.: _For any \(B>0,l>1\), let \(f_{w}\in\mathcal{H}:\mathcal{X}\times\mathcal{G}\rightarrow\mathbb{R}^{K}\) be a \(l\)-layer GCN. Then for any \(w\), and \(x\in\mathcal{X}_{B,h_{0}}\), and any perturbation \(u=\mathrm{vec}\left(\left\{U_{i}\right\}_{i=1}^{l}\right)\) such that \(\forall i\in\mathbb{N}_{i}^{+},\left\|U_{i}\right\|_{2}\leq\frac{1}{l}\left\|W_ {i}\right\|_{2}\), the change in the output of \(GCN\) is bounded as,_

\[\left|L_{\left(X,A\right)}\left(f_{w+u}\right)\right)-L_{\left(X,A\right)}\left(f_{w}\right)\right|_{2}\] (17) \[\qquad\leq eBd^{\frac{l-1}{2}}\left(\prod_{i=1}^{l}\left\|W_{i} \right\|_{2}\right)\sum_{k=1}^{l}\frac{\left\|U_{k}\right\|_{2}}{\left\|W_{k} \right\|_{2}}.\]

Then, we can deduce the bound for a GCN without label distribution. First, let \(\beta=\left(\prod_{i=1}^{l}\left\|W_{i}\right\|_{2}\right)^{1/t}\). Weights are normalized as \(\tilde{W}_{i}=\frac{\beta}{\left\|W_{i}\right\|_{2}}W_{i}\). Due to the homogeneity of ReLU, i.e., \(a\phi(x)=\phi(ax),\forall a\geq 0\). \(\prod_{i=1}^{l}\left\|W_{i}\right\|_{2}=\prod_{i=1}^{l}\left\|\tilde{W}_{i} \right\|_{2}\) and \(\left\|W_{i}\right\|_{F}/\left\|W_{i}\right\|_{2}=\left\|\tilde{W}_{i} \right\|_{F}/\left\|\tilde{W}_{i}\right\|_{2}\), i.e., the terms present in the bound remain unchanged after normalization. Therefore, w.l.o.g., we conduct the assumption that the norm is equal across all layers, i.e., \(\forall i,\left\|W_{i}\right\|_{2}=\beta\). Consider the prior \(P=\mathcal{N}\left(0,\sigma^{2}I\right)\) and the random perturbation \(u\sim\mathcal{N}\left(0,\sigma^{2}I\right)\). Note that the \(\sigma\) of the prior and the perturbation keep the same and will be set according to \(\beta\). Specifically, the value of \(\sigma\) is set based on some approximation \(\tilde{\beta}\) of \(\beta\) since the prior \(P\) can not be directly deduced by any learned weights. We select the approximation \(\tilde{\beta}\) as the cover set that encompasses the possible significant range of \(\beta\). For the moment, assuming we have a constant \(\tilde{\beta}\), we can examine \(\beta\) that fulfills the condition \(\left|\beta-\tilde{\beta}\right|\leq\frac{1}{l}\beta\). Note that this also implies

\[\begin{split}\left|\beta-\tilde{\beta}\right|\leq\frac{1}{l}\beta, &\Rightarrow\left(1-\frac{1}{l}\right)\beta\leq\tilde{\beta}\leq \left(1+\frac{1}{l}\right)\beta,\\ &\Rightarrow\left(1-\frac{1}{l}\right)^{l-1}\beta^{l-1}\leq\tilde {\beta}^{l-1}\leq\left(1+\frac{1}{l}\right)^{l-1}\beta^{l-1},\\ &\Rightarrow\left(1-\frac{1}{l}\right)^{l}\beta^{l-1}\leq\tilde {\beta}^{l-1}\leq\left(1+\frac{1}{l}\right)^{l}\beta^{l-1},\\ &\Rightarrow\frac{1}{e}\beta^{l-1}\leq\tilde{\beta}^{l-1}\leq e \beta^{l-1}.\end{split}\] (18)

According to [44], for random perturbations \(U_{i}\in\mathbb{R}^{h\times h}\) which is object to the distribution \(U_{i}\sim\mathcal{N}\left(\mathbf{0},\sigma^{2}I\right)\),

\[\mathbb{P}\left(\left\|U_{i}\right\|_{2}\geq t\right)\leq 2ke^{-t^{2}/2k \sigma^{2}}.\] (19)

We consider the perturbations of all layers, thus:

\[\begin{split}\mathbb{P}\left(\left\|U_{1}\right\|_{2}<t\& \&\cdots\&\left\|U_{l}\right\|_{2}<t\right)=1- \mathbb{P}\left(\exists i,\left\|U_{i}\right\|_{2}\geq t\right),\\ &\geq 1-\sum_{i=1}^{l}\mathbb{P}\left(\left\|U_{i}\right\|_{2}\geq t \right),\\ &\geq 1-2lke^{-t^{2}/2k\sigma^{2}}.\end{split}\] (20)

Setting \(2lke^{-t^{2}/2k\sigma^{2}}=\frac{1}{2},\) we can have \(t=\sigma\sqrt{2k\log(4lk)}\).

The likelihood that the spectral norm perturbation of any layer not exceeds \(\sigma\sqrt{2h\log(4lk)}\) is at least \(\frac{1}{2}\). Plugging this bound into Lemma 7, we have with probability at least \(\frac{1}{2}\),

\[\begin{split}\left|f_{w+u}(X,A)-f_{w}(X,A)\right|_{2}& \leq eBd^{\frac{l-1}{2}}\left(\prod_{i=1}^{l}\left\|W_{i} \right\|_{2}\right)\sum_{i=1}^{l}\frac{\left\|U_{i}\right\|_{2}}{\left\|W_{i} \right\|_{2}},\\ &=eBd^{\frac{l-1}{2}}\beta^{l}\sum_{i=1}^{l}\frac{\left\|U_{i} \right\|_{2}}{\beta},\\ &\leq eBd^{\frac{l-1}{2}}\beta^{l-1}l\sigma\sqrt{2k\log(4lk)},\\ &\leq e^{2}Bd^{\frac{l-1}{2}}\tilde{\beta}^{l-1}l\sigma\sqrt{2k \log(4lk)},\\ &\leq\frac{\gamma}{4},\end{split}\] (21)

where we can set \(\sigma=\frac{\gamma}{4e^{2}Bd^{\frac{l-1}{2}}\tilde{\beta}^{l-1}l\sqrt{k\log(4 lk)}}\) to get a new inequality. Note that Lemma 7 also requires \(\forall i\in\mathbb{N}_{l}^{+},\left\|U_{i}\right\|_{2}\leq\frac{1}{l}\left\|W_{i} \right\|_{2}\). The requirement is satisfied if \(\sigma\leq\frac{\beta}{l\sqrt{2k\log(4lk)}}\) which in turn can be satisfied if

\[\frac{\gamma}{4eBd^{\frac{l-1}{2}}\beta^{l-1}l\sqrt{2k\log(4lk)}}\leq\frac{ \beta}{l\sqrt{2k\log(4lk)}},\] (22)

since the chosen value of \(\sigma\) satisfies \(\sigma\leq\frac{\gamma}{4eBd^{\frac{l-1}{2}}\beta^{l-1}l\sqrt{2k\log(4lk)}}\).

Note that Eq. (22) can be rewritten as \(\frac{\gamma}{4eB}d^{\frac{1-1}{2}}\leq\beta^{l}\). KL term in the PAC-Bayes bound in Lemma 6 is deduced as:

\[\begin{split}\mathrm{KL}(Q\|P)&=\frac{|w|_{2}^{2}}{2 \sigma^{2}}=\frac{4\epsilon^{2}B^{2}d^{l-1}\beta^{2l-2}l^{2}k\log(4lk)}{2\gamma ^{2}}\sum_{i=1}^{l}\left\|W_{i}\right\|_{F}^{2},\\ &\leq\mathcal{O}\left(\frac{B^{2}d^{l-1}\beta^{2l}l^{2}k\log(lk) }{\gamma^{2}}\sum_{i=1}^{l}\frac{\left\|W_{i}\right\|_{F}^{2}}{\beta^{2}} \right),\\ &\leq\mathcal{O}\left(B^{2}d^{l-1}l^{2}k\log(lk)\frac{\prod_{i=1 }^{l}\left\|W_{i}\right\|_{2}^{2}}{\gamma^{2}}\sum_{i=1}^{l}\frac{\left\|W_{i }\right\|_{F}^{2}}{\left\|W_{i}\right\|_{2}^{2}}\right).\end{split}\] (23)

From Lemma 6, fixing any \(\tilde{\beta}\), with probability \(1-\delta\) and for all \(w\) such that \(\left|\beta-\tilde{\beta}\right|\leq\frac{1}{l}\beta\). Let \(\mathcal{D}(W_{i})=\prod_{i=1}^{l}\left\|W_{i}\right\|_{2}^{2}\cdot\sum_{i=1} ^{l}\left(\left\|W_{i}\right\|_{F}^{2}/\left\|W_{i}\right\|_{2}^{2}\right)\) we can get,

\[\begin{split} L_{\mathcal{G}}\left(f_{w}\right)& \leq L_{(X,A)}\left(f_{w}\right)\\ &+\mathcal{O}\left(\sqrt{\frac{B^{2}d^{l-1}l^{2}k\log(lk) \mathcal{D}(W_{i})+\log\frac{n}{\delta}}{\gamma^{2}n}}\right).\end{split}\] (24)

The choice of \(\tilde{\beta}\) is important, such that for any \(\beta\), we can bound the generalization error like Eq. (24). First, the value range of \(\beta\) is decided as the following,

\[\frac{1}{\sqrt{d}}\left(\frac{\gamma\sqrt{d}}{2B}\right)^{1/l}\leq\beta\leq \frac{1}{\sqrt{d}}\left(\frac{\gamma\sqrt{nd}}{2B}\right)^{1/l},\] (25)

since otherwise the bound holds trivially as \(L_{(X,A)}\left(f_{w}\right)\leq 1\) by definition. Note that the lower bound in Eq. (25) ensures that Eq. (22) holds which in turn justifies the applicability of Lemma 7. If \(\beta<\frac{1}{\sqrt{d}}\left(\frac{\gamma\sqrt{d}}{2B}\right)^{1/l}\), then for any \((X,A)\) and any \(j\in\mathbb{N}_{K}^{+},|f(X,A)[j]|\leq\frac{\gamma}{2}\). To prove this, we have,

\[\begin{split}|f_{w}(X,A)[j]|&\leq\left|f_{w}(X,A) \right|_{2}=\left|\frac{1}{n}\mathbf{1}_{n}\mathbf{x}^{l-1}W_{l}\right|_{2}, \\ &\leq\frac{1}{n}\left|\mathbf{1}_{n}\mathbf{x}^{l-1}\right|_{2} \left\|W_{l}\right\|_{2},\\ &\leq\left\|W_{l}\right\|_{2}\max_{i}\left|\mathbf{x}^{l-1}[i,i] \right|_{2},\\ &\leq Bd^{\frac{l-1}{2}}\prod_{i=1}^{l}\left\|W_{i}\right\|_{2}= d^{\frac{l-1}{2}}\beta^{l}B,\\ &=d^{\frac{l-1}{2}}B\frac{\gamma}{2Bd^{\frac{l-1}{2}}}\leq\frac{ \gamma}{2}.\end{split}\] (26)

Therefore, we always have \(L_{(X,A)}\left(f_{w}\right)=1\) when \(\beta<\frac{1}{\sqrt{d}}\left(\frac{\gamma\sqrt{d}}{2B}\right)^{1/l}\). Alternatively, if \(\beta>\frac{1}{\sqrt{d}}\left(\frac{2\sqrt{nd}}{2B}\right)^{1/l}\), the term inside the big-O notation in Eq. (24) would be,

\[\begin{split}\sqrt{\frac{B^{2}d^{l-1}l^{2}k\log(lk)\mathcal{D}(W_ {i})+\log\frac{n}{\delta}}{\gamma^{2}n}}&\geq\sqrt{\frac{l^{2}k \log(lk)}{4}\sum_{i=1}^{l}\frac{\left\|W_{i}\right\|_{F}^{2}}{\left\|W_{i} \right\|_{2}^{2}}},\\ &\geq\sqrt{\frac{l^{2}k\log(lk)}{4}}\geq 1,\end{split}\] (27)

where we set \(k\geq 2\) in practice and \(l\geq 2\), while considering the fact \(\left\|W_{i}\right\|_{F}\geq\left\|W_{i}\right\|_{2}\). To account for \(\beta\) within the range defined by Eq. (25), a condition ensuring that \(\left|\beta-\tilde{\beta}\right|\leq\frac{1}{l}\beta\) would be \(|\beta-\tilde{\beta}|\leq\frac{1}{l\sqrt{d}}\left(\frac{\gamma\sqrt{d}}{2B}\right) ^{1/l}\). So, if we can identify an overlap of the span in Eq. (25) with a radius of \(\frac{1}{l\sqrt{d}}\left(\frac{\beta\sqrt{d}}{2B}\right)^{1/l}\) and ascertain that bounds akin to Eq. (24) are met when \(\tilde{\beta}\) assumes any value within that overlap, then a bound that is valid for every \(\beta\) can be established. Clearly, it is only essential to ponder a coverage \(C\) of magnitude \(|C|=\frac{l}{2}\left(n^{\frac{1}{2}}-1\right)\). Thus, representing the event of Eq. (24) when \(\tilde{\beta}\) adopts the \(i\)-th value from the coverage as \(E_{i}\), we deduce:

\[\begin{split}\mathbb{P}\left(E_{1}\&\&\cdots \& E_{|C|}\right)=1-\mathbb{P}\left(\exists i,\bar{E}_{i}\right),\\ &\geq 1-\sum_{i=1}^{|C|}\mathbb{P}\left(\bar{E}_{i}\right)\geq 1-|C| \delta.\end{split}\] (28)

Note \(\bar{E}_{i}\) denotes the complement of \(E_{i}\). Hence, we now present the PAC-Bayes generalization bound [43] of GCNs as Theorem 8.

**Theorem 8**.: _For any \(B>0,l>1\), let \(f_{w}\in\mathcal{H}:\mathcal{X}\times\mathcal{G}\rightarrow\mathbb{R}^{K}\) be a l layer GCN. Then for any \(\delta,\gamma>0\), with probability at least \(1-\delta\) over the choice of an i.i.d. size-n training set \(S\) according to \(\mathcal{D}\), for any \(w\), we have,_

\[\begin{split} L_{\mathcal{G}}\left(f_{w}\right)& \leq L_{(X,A)}\left(f_{w}\right)\\ &+\mathcal{O}\left(\sqrt{\frac{B^{2}d^{l-1}l^{2}k\log(lk) \mathcal{D}(W_{i})+\log\frac{n|C|}{\delta}}{\gamma^{2}n}}\right),\\ &=L_{(X,A)}\left(f_{w}\right)\\ &+\mathcal{O}\left(\sqrt{\frac{B^{2}d^{l-1}l^{2}k\log(lk) \mathcal{D}(W_{i})+\log\frac{nl}{\delta}}{\gamma^{2}n}}\right),\end{split}\] (29)

Then we consider a GCN with label distribution learning, and explore the bound in term of Rademacher complexity. Specifically, let \(\eta(\cdot)\) be a label distribution function, thus \(\eta\left(\mathbf{x}_{i}\right)=\left\{\eta_{\mathbf{x}_{i}}^{y_{1}},\ldots, \eta_{\mathbf{x}_{n}}^{y_{p}}\right\}\). Given a function class \(\mathcal{H}\) and a loss function \(\ell(\cdot)\), for function \(\hbar\in\mathcal{H}\), its corresponding risk and empirical risk are defined as \(L_{\mathcal{G}}\left(f_{w}\right)=\mathbb{E}_{\mathbf{x}\sim\mathcal{D}}[\ell (\hbar(\mathbf{x}),\eta(\mathbf{x}))]\) and \(L_{(X,A)}\left(f_{w}\right)=\frac{1}{\hbar}\sum_{i=1}^{n}\ell\left(\hbar\left( \mathbf{x}_{i}\right),\eta\left(\mathbf{x}_{i}\right)\right)\), respectively. Recall the definition of rademacher complexity w.r.t. \(S\) and

\[\hat{\mathcal{R}}_{n}(\ell\circ\mathcal{H}\circ S)=\mathbb{E}_{\epsilon_{1}, \ldots,\epsilon_{n}}\left[\sup_{\hbar\in\mathcal{H}}\frac{1}{n}\sum_{i=1}^{n} \ell\left(\hbar\left(\mathbf{x}_{i}\right),\eta\left(\mathbf{x}_{i}\right) \right)\epsilon_{i}\right],\]

where \(\epsilon_{1},\ldots,\epsilon_{n}\) are \(n\) independent rademacher random variables with \(\mathbb{P}\left(\epsilon_{i}=1\right)=\mathbb{P}\left(\epsilon_{i}=-1\right)= 1/2\).

Then we can derive the following necessary lemma [45][46],

**Lemma 9**.: _Let \(\mathcal{H}\) be a family of functions. For a loss function \(\ell\) bounded by \(\mu\), then for any \(\delta>0\), with probability at least \(1-\delta\), for all \(\hbar\in\mathcal{H}\) such that_

\[L_{\mathcal{D}}(\hbar)\leq L_{S}(\hbar)+2\hat{\mathcal{R}}_{n}(\ell\circ \mathcal{H}\circ S)+3\mu\sqrt{\frac{\log 2/\delta}{2n}}.\] (30)

and the theorem of Rademacher complexity of the method for loss function KL-divergence [8]:

**Theorem 10**.: _Let \(\mathcal{H}\) be a family of functions for multi-output linear regression, and \(\mathcal{H}_{j}\) be a family of functions for the \(j\)-th output. Rademacher complexity of ME(Maximum-Entropy) with KL loss satisfies_

\[\hat{\mathcal{R}}_{n}(\mathrm{KL}\circ\mathrm{SF}\circ\mathcal{H}\circ S)\leq \left(\sqrt{2q}+\sqrt{2}\right)\sum_{j=1}^{q}\hat{\mathcal{R}}_{n}\left( \mathcal{H}_{j}\circ S\right).\] (31)

Note that \(\mathrm{KL}(\mathbf{u},\cdot)\) is not \(\rho\)-Lipschitz over \(\mathbb{R}^{m}\) for any \(\rho\in\mathbb{R}\) and \(\mathbf{u}\in\mathbb{R}^{m}\). Define function \(\phi(\cdot,\cdot)\) as \(\mathrm{KL}(\cdot,\mathrm{SF}(\cdot))\). Next we show that \(\phi(\mathbf{u},\cdot)\) satisfy Lipschitzness. For \(\mathbf{p},\mathbf{q}\in\mathbb{R}^{m}\),

\[|\phi(\mathbf{u},\mathbf{p})-\phi(\mathbf{u},\mathbf{q})|=|\mathrm{KL}(\mathbf{u },\mathrm{SF}(\mathbf{p}))-\mathrm{KL}(\mathbf{u},\mathrm{SF}(\mathbf{q}))|,\]which equals

\[\left|\sum_{i=1}^{p}u_{i}\left(\ln\frac{\exp\left(p_{i}\right)}{ \sum_{j=1}^{n}\exp\left(p_{j}\right)}-\ln\frac{\exp\left(q_{i}\right)}{\sum_{j=1 }^{n}\exp\left(q_{j}\right)}\right)\right|,\] \[\leq\sum_{i=1}^{p}\left|\ln\left(1+\sum_{j\neq i}\mathrm{e}^{p_{ j}-p_{i}}\right)-\ln\left(1+\sum_{j\neq i}\mathrm{e}^{q_{j}-q_{i}}\right) \right|u_{i}.\]

Observing that \(\ln\left(1+\sum_{j}\exp v_{i}\right)\) is 1-Lipschitz for \(\mathbf{v}\in\mathbb{R}^{m}\), thus right-hand side of preceding equation is bounded by

\[\sum_{i=1}^{p}u_{i}\left\|\mathbf{p}-\mathbf{1}\cdot p_{i}- \mathbf{q}+\mathbf{1}\cdot q_{i}\right\|_{2},\] \[\leq||\mathbf{p}-\mathbf{q}||_{2}+\sqrt{c}\sum_{i=1}^{p}u_{i} \left|p_{i}-q_{i}\right|,\] \[\leq(\sqrt{p}+1)\|\mathbf{p}-\mathbf{q}\|_{2},\]

namely, \(\phi\) is \((\sqrt{p}+1)\)-Lipschitz. According to [47], we have:

\[\hat{\mathcal{R}}_{n}(\mathrm{KL}\circ\mathrm{SF}\circ\mathcal{H }\circ S) \leq\sqrt{2}(\sqrt{q}+1)\sum_{j=1}^{q}\hat{\mathcal{R}}_{n}\left( \mathcal{H}_{j}\circ S\right),\] \[=(\sqrt{2q}+\sqrt{2})\sum_{j=1}^{q}\hat{\mathcal{R}}_{n}\left( \mathcal{H}_{j}\circ S\right),\]

Although only implementing KL-divergence does not satisfy Lipschitzness, the combination of KL and Softmax(SF) is \((\sqrt{p}+1)\)-Lipschitz. Define class of functions of \(j\)-th output with weight constraints as \(\mathcal{H}_{j}=\left\{x\rightarrow\mathbf{w}_{j}\cdot x:\left\|\mathbf{w}_{ j}\right\|_{2}\leq 1\right\}\). According to [48], rademacher complexity of \(\mathcal{H}_{j}\) satisfies

\[\hat{\mathcal{R}}_{n}\left(\mathcal{H}_{j}\circ S\right)\leq\frac{\max_{i\in[ n]}\left\|\left\|x_{i}\right\|_{2}}{\sqrt{n}}.\]

Then right-hand side of Eq. (31) is bounded as

\[\hat{\mathcal{R}}_{n}(\mathrm{KL}\circ\mathrm{SF}\circ\mathcal{H }\circ S)\leq\frac{(\sqrt{2q}+\sqrt{2})q}{\sqrt{n}}\max_{i\in[n]}\left\|x_{i} \right\|_{2}.\] (32)

According to Lemma 9, while we have the rademacher complexity of LDL with KL-divergence loss defined in Eq. (32), the bound can be defined as:

\[L_{\mathcal{G}}\left(f_{w}\right)-L_{(X,A)}\left(f_{w}\right) \leq 2\frac{(\sqrt{2q}+\sqrt{2})q}{\sqrt{n}}\max_{i\in[n]}\left\|x _{i}\right\|_{2}\] (33) \[+3\mu\sqrt{\frac{\log 2/\delta}{2n}}.\]

Considering the node representations vary in different layers, Without loss of generality, we replace \(\max_{i\in[n]}\left\|x_{i}\right\|_{2}\) with \(\max_{i\in[n],j\in[l]}\left\|\mathbf{x}_{i}^{j}\right\|_{2}\) to find the maximum node representation, instead of node feature. Then recall the PAC risk bound defined in Eq. (29),

\[L_{\mathcal{G}}\left(f_{w}\right) -L_{(X,A)}\left(f_{w}\right)\] \[\leq\mathcal{O}\left(\sqrt{\frac{B^{2}d^{l-1}l^{2}k\log(lk) \mathcal{D}(W_{i})+\log\frac{nl}{\delta}}{\gamma^{2}n}}\right),\]

We use the sum of both above bounds as the final risk bound for a GCN with KL-divergence loss for the label distribution learning problem.

\[L_{\mathcal{G}}\left(f_{w}\right)-L_{(X,A)}\left(f_{w}\right)\leq \frac{2(\sqrt{2q+\sqrt{2}})q}{\sqrt{n}}\max_{i\in[n],j\in[\bar{\mathsf{v}}]}\left\| \mathbf{x}_{i}^{j}\right\|_{2}\] \[+3b\sqrt{\frac{\log 2/\delta}{2n}}+\mathcal{O}\Bigg{(}\sqrt{\frac{B^{2 }d^{l-1}l^{2}k\log(lk)\mathcal{D}(W_{i})+\log\frac{nl}{\delta}}{\gamma^{2}n}} \Bigg{)},\] (34)

As [49] suggests that 0 is replaced by a very small value, say \(\gamma>0\), for division by 0 when implementing KL divergence, then for probability distribution \(\mathbf{p},\mathbf{q}\in\mathbb{R}^{m}\) with \(p_{i}\geq\gamma,q_{i}\geq\gamma\)

\[\mathrm{KL}(\mathbf{p},\mathbf{q})=\sum_{i=1}^{n}p_{i}\ln\frac{p_{i}}{q_{i}} \leq\sum_{i=1}^{n}p_{i}\ln\frac{1}{\gamma}\leq-\ln\gamma,\]

thus there exists a constant \(b\geq-\ln\gamma\) such that \(\mathrm{KL}(\cdot,\cdot)\leq b\) (e.g., \(b=35\) for \(\gamma=1\times 10^{-15}\) ).

Hence, all of the above concludes the proof.

## Appendix H Supplement F: Additional Theoretical Analysis

### Uniform Distribution Phenomenon

It is observed in the experiment that given a fixed large hidden dimension \(f\), normalized adjacency matrices are more easily to initialize approximate uniform attention than unnormalized adjacency matrices. In the following, we provide a theoretical analysis of the reason behind this phenomenon.

#### h.1.1 Normalized adjacency matrix are more likely to initialize uniform attention

For simplicity of analysis, we use one node's attentions from a single meta path graph in the study. Same analysis can be applied to all nodes and all meta-path graphs, without loss of generalizability.

Denote \(A\in\mathbf{R}^{n\times n}\) the adjacency matrix of the meta-path graph from a meta-path \(\mathcal{P}\), and \(W\in\mathbb{R}^{n\times f}\) the learnable weight of the meta-path graph (\(W\) is indeed \(W_{0}^{i}\) in Eq. (1) shown in the main manuscript. We drop \(W_{0}^{i}\)'s subscript 0 and superscript \(i\) here for simplicity, as our analysis is based on a single meta-path graph). \(W[:,i]\in\mathbb{R}^{n\times 1}\) denotes the column vector of \(W\), and \(A[i,:]\in\mathbb{R}^{1\times n}\) is a row vector recording node \(i\)'s connections (\(n\) is the number of nodes in the meta-path graph).

A uniform weight initialization is with bounds \([-\frac{1}{\sqrt{f}},\frac{1}{\sqrt{f}}]\) for all the learnable matrices. \(d\) denotes the average degree of the graph adjacency matrix.

**Theorem 11**.: _Denote \(A\) and \(\tilde{A}\) the adjacency matrix and normalized adjacency matrix of a graph, respectively. For node \(i\) in the graph, its attention is proportional to \(A[i,:]\cdot W[:,i]\sim\mathcal{O}(\frac{d}{\sqrt{f}})\) for the adjacency matrix, but proportional to \(\tilde{A}[i,:]\cdot W[:,i]\sim\mathcal{O}(\frac{1}{\sqrt{f}})\) for normalized adjacency matrix._

Proof.: Normalization of \(A\) (ignoring the self-loop for simplicity) gives:

\[\tilde{A}=D^{\frac{-1}{2}}AD^{\frac{-1}{2}}\] (35) \[\tilde{A}[i,j]=\frac{1}{\sqrt{d_{i}}\sqrt{d_{j}}}*A[i,j]\] (36)

Denote \(e_{j}\in\mathbb{R}^{1\times n}\) a one-hot encoded vector with only \(j^{th}\) position has value 1 (_e.g._\(e_{2}=(0,1,0,0,0)\). Because \(\|e_{i}\|=1\), it's easy to know that \(e_{j},\forall j\) can be used to construct an orthonormal eigenbasis. Denote \(E_{i}\) as the index set of edges for node \(i\). For example, if \(A[i,:]=(0,1,1,0,0)\), then \(E_{i}=\{2,3\}\), because index position 2 and 3 has 1 (_i.e._ edge connections) to node \(i\). Then we can decompose \(A[i,:]\) and \(W[:,i]\) as follows,\[A[i,:]=\sum_{j\in E_{i}}e_{j}\] (37) \[\tilde{A}[i,:]=\sum_{j\in E_{i}}\frac{1}{\sqrt{d_{i}}\sqrt{d_{j}}}e_ {j}\] (38) \[W[:,i]=\sum_{k}c_{k}e_{k}\] (39)

where \(c_{k}\) is a scalar for basis \(e_{k}\) and \(c_{k}\) is bounded by \([-\frac{1}{\sqrt{f}},\frac{1}{\sqrt{f}}]\). Assume that \(c_{k}\neq 0\) for \(k\in E_{i}\) (meaning that the scalar is nonzero when nodes \(i\) and \(k\) are connected), then we have

\[A[i,:]\cdot W[:,i] =\sum_{j\in E_{i}}e_{j}*\sum_{k}c_{k}e_{k}=\sum_{l=1}^{d_{i}}c_{l }\sim O(d/\sqrt{f})\] (40) \[\tilde{A}[i,:]\cdot W[:,i] =\sum_{j\in E_{i}}\frac{1}{\sqrt{d_{i}}\sqrt{d_{j}}}e_{j}*\sum_{k }c_{k}e_{k}\] (41) \[\sim\sum_{l=1}^{d_{i}}\frac{c_{l}}{\sqrt{d\times d}}\sim\ O(1/ \sqrt{f})\] (42)

where \(d_{i}\) denotes the degree of node \(i\) (_i.e._\(d_{i}=\sum A[i,:]\)). Compared to Eq. (42) vs. Eq. (40), it is easy to conclude that \(f\) plays more significant role in Eq. (42). Meaning that an unnormalized adjacency matrix affects the final attention with the average degree of the matrix while normalized adjacency matrix is dominated by the square root of hidden dimension \(f\). With a relatively large hidden dimension, it is easy to see that normalized adjacency matrices are more likely to be dominated by the hidden dimension size \(f\) and produce uniform distribution of learned attention in the beginning stage. 

### Benefits of proposed attention structure in terms of label distribution learning

Similar structure of our proposed attention structure is applied when combining GNN and transformer structure, we provide an analysis on why such proposed attention structure is beneficial to graph label distribution learning. To show this, we first leverage the conclusion from Eq. (34) to obtain a bound of graph label distribution learning on normal l GCN layer.

There are three parts for the bounds, the part \(\mathcal{O}\Bigg{(}\sqrt{\frac{B^{2}d^{l-1}l^{2}k\log(lk)\mathcal{D}(W_{i})+ \log\frac{nl}{k}}{\gamma^{2}n}}\Bigg{)}\) is our focus as it is directly related to maximum degree \(d\) of graph adjacency matrix and is related to our change in the GNN structure. It is easy to observe that our proposed attention structure follows the same GCN update except the adjacency matrix is now learnable from features and combined with topology space. So we assume that our model is a dynamic graph version and we focus on how the changes in the learnable graph could affect the bound. We show in the following that our method reduces the maximum degree of graph adjacency matrix and therefore tightens the bound for graph label distribution learning.

Our attention layer learns a feature space topology and intersects its feature neighbor with its topology neighbor to get a consistent neighbor set agreed by both feature and topology.

**Theorem 12** (Equal priority of feature and topology space).: _Denote original graph structure as A, propagation graph for attention structure as \(\tilde{A}\), denote \(\delta(A[i,:])\) as the \(i^{th}\) node's degree. \(\Delta\)(A) as maximum degree of adjacency matrix A and \(\operatorname*{arg\,max}_{i}\delta(A[i,:])\) as the node index that has the maximum degree:_

\[\Delta(\tilde{A})\leq\Delta(A)\] (43)

Proof.: \[\tilde{A}_{f}=ZQ(ZK)^{T}\] (44) \[\tilde{A}=Softmax(\tilde{A}_{f}\odot A)\] (45)With \(\odot\) operator, for any node i, it is easy to observe that

\[\delta(\tilde{A}[i,:])\leq\delta(A[i,:])\] (46)

Assume without loss of generality that \(A\) has \(\Delta\)(A) at node \(j\), \(i.e.\)\(\operatorname*{arg\,max}_{i}\delta(A[i,:])=j.\) and \(\tilde{A}\) has \(\Delta\)(A) at node k,i.e, \(\operatorname*{arg\,max}_{i}\delta(\tilde{A}[i,:])=k\). For arbitrary node \(i\) in \(\tilde{A}\),

\[\delta(\tilde{A}[i,:])\leq\delta(A[i,:])\leq\delta(A[j,:])\] (47) \[\Delta(\tilde{A})=\delta(\tilde{A}[k,:])\leq\delta(A[k,:])\leq \delta(A[j,:])=\Delta(A)\] (48)

We note that the equality sign only appears iff \(k=j\) and \(\delta(\tilde{A}[k,:])=\delta(A[k,:])\) which relies on \(\tilde{A}_{f}\) at row \(k\) to be exactly the same as \(A\) at row \(k\). The probability is related to the consistency of feature similarity and topology structure.

For a graph with relatively low homophily score \(p_{i}\) for a specific node \(i\) with \(p_{i}\) defined as

\[p_{i}=\frac{\sum_{i\in Neighbor}(Label(Neighbor(i))==Label(i))}{|Neighbor|}\] (49)

where \(Label(i)\) for a node i is the dominate class of its distribution and \(Neighbor(i)\) is defined as topology neighbor set of node \(i\). \(|Neighbor(i)|\) indicates the size of the set.

Assume that feature similarity strongly relates to label connection among nodes,i.e, features are similar between samples if their label distribution are close. The learnt \(\tilde{A}_{f}\) at row k satisfies the equality condition iff \(p_{k}=1\). For practical graphs in general, such homophily score rarely exist and therefore our methods should reduce the maximum degree of the propagation graph in most cases. 

Remark 1.With Theorem 6, we have shown that our proposed design (_i.e_ using \(\odot\) between learnt feature topology and graph topology) can reduce maximum degree of the propagation graph with high probability. Leveraging derived bound term from Eq. (29) related to maximum degree, we can observe that lower maximum degree allows the model to have a tighter bound for HGDL problem in general. Therefore, our proposed design is naturally beneficial to the heterogeneous graph label distribution learning.

### Runtime Discussion

To verify the efficiency of our method, Table 14 shows the runtime for 100 training epochs for our baseline methods, Each method has been trained with 100 epochs. We can observe that our proposed HGDL algorithm enjoys good scalability by attaining runtime results that are comparable to the baseline GCNs. Compared to other baseline such as SeHGNN, HGDL is in general much faster. This indicates that our method is more efficient for learning heterogeneous networks. This can be mainly attributed to the automated learning of weights to control individual meta-paths and then integrates them to yield optimal graph topology homogenization for label distribution learning.

\begin{table}
\begin{tabular}{l r r r r r} \hline \hline
100 epochs (s) & DRUG (894) & URBAN (604) & ACM (5810) & YELP (3001) & DBLP (4057) \\ \hline GCN\({}_{\text{KL}}\) & 2.51 & 2.77 & 10.97 & **1.8569** & **23** \\ \hline HAN\({}_{\text{KL}}\) & 1.73 & 0.979 & 75 & 12.53 & 23.63 \\ \hline SeHGNN\({}_{\text{KL}}\) & 2.0592 & 1.16 & 75.25 & 12.45 & 23.45 \\ \hline HGDL\({}_{\text{KL}}\) & **1.19** & **1.05** & **8.81** & 8.75 & 26.57 \\ \hline \hline \end{tabular}
\end{table}
Table 14: Runtime results for 100 training epochs. The numbers of target nodes are labeled beside their corresponding dataset names.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: Our study aims to generalize Label Distribution Learning from IID data to the non-IID, networked data, and we have made this claim clear in the Abstract and Introduction. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: We discussed the limited performance gain on CAD and CLD metrics in Section 6.3 and provided Runtime analysis in Supplement F Section H.3. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof?Answer: [Yes] Justification: We have analyzed the generalization error bound of the proposed algorihtm in a PAC-Bayes regime and provided the complete proof in Supplement D and E. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? [Yes] Justification: We have provided tuned parameter settings in provided Github link and reported their impact on empirical results in Supplement C. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code**Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: We have uploaded the code and benchmark datasets as the supplementary submission in provided Github link. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: We have presented the creation and preprocessing steps of the benchmark datasets and the implementation details of our algorithms in Supplementary B and C, respectively. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: We generated experimental results from repeated experiments (including different train/test split) and leveraged t-test to validate the statistical significance in settings where our algorithm outperform its competitors. We reported its win/tie/loss in Section 6.2 where "win" indicates that our algorithm outperforms the compared models with confidence level at a level of 90%. Guidelines: * The answer NA means that the paper does not include experiments.

* The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.
* The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).
* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: We disclosed our computing node setup. Note, our algorithm is not computational demanding and could be generalized onto various single-GPU machines. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: We revised the COE and all agreed on it. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes]Justification: We demonstrated multiple potential application of our algorithm with the benchmark dataset, including the use case of Urban Functionality Delineation, which has been leveraged as the motivating example of our proposal in Introduction. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. * If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: NA Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [NA] Justification: NA Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset.

* The authors should state which version of the asset is used and, if possible, include a URL.
* The name of the license (e.g., CC-BY 4.0) should be included for each asset.
* For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.
* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [Yes] Justification: The artifacts generated from this paper will be published under CC-BY 4.0 license for public access and non-commercial use. Guidelines: * The answer NA means that the paper does not release new assets. * Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. * The paper should discuss whether and how consent was obtained from people whose asset is used. * At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: NA Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. * According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: NA Guidelines:* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.