# Linear Causal Bandits: Unknown Graph and Soft Interventions

Zirui Yan

Rensselaer Polytechnic Institute

yanz11@rpi.edu &Ali Tajer

Rensselaer Polytechnic Institute

tajer@ecse.rpi.edu

###### Abstract

Designing causal bandit algorithms depends on two central categories of assumptions: (i) the extent of information about the underlying causal graphs and (ii) the extent of information about interventional statistical models. There have been extensive recent advances in dispensing with assumptions on either category. These include assuming known graphs but unknown interventional distributions, and the converse setting of assuming unknown graphs but access to restrictive hard/\(\mathrm{do}\) interventions, which removes the stochasticity and ancestral dependencies. Nevertheless, the problem in its general form, i.e., _unknown_ graph and _unknown_ stochastic intervention models, remains open. This paper addresses this problem and establishes that in a graph with \(N\) nodes, maximum in-degree \(d\) and maximum causal path length \(L\), after \(T\) interaction rounds the regret upper bound scales as \(\tilde{\mathcal{O}}((cd)^{L-\frac{1}{2}}\sqrt{T}+d+RN)\) where \(c>1\) is a constant and \(R\) is a measure of intervention power. A universal minimax lower bound is also established, which scales as \(\Omega(d^{L-\frac{3}{2}}\sqrt{T})\). Importantly, the graph size \(N\) has a diminishing effect on the regret as \(T\) grows. These bounds have matching behavior in \(T\), exponential dependence on \(L\), and polynomial dependence on \(d\) (with the gap \(d\) ). On the algorithmic aspect, the paper presents a novel way of designing a computationally efficient CB algorithm, addressing a challenge that the existing CB algorithms using soft interventions face.

## 1 Motivation & Overview

Causal bandits (CBs) provide a formal framework for the sequential design of experiments over a network of agents with _causal_ interactions. The objective of CBs is to identify an experiment that maximizes a notion of utility over the causal network. CB settings are specified by three elements: (i) a causal graphical model that defines the topological ordering of the causal variables and their probabilistic relationships; (ii) a set of structural equation models (SEMs) that specify their cause-effect dependencies among the variables; and (iii) _intervention_ models that specify the extent of exogenous variations imposed on the causal interactions by an external force. By interpreting the set of interventions as the set of _arms_ and the decision quality (utility) as the rewards, CBs' objective is to maximize the cumulative reward by strategically selecting the sequence of interventions that optimize a notion of cumulative utility [1; 2]. CBs have a broad range of applications [3; 4; 5].

The recent advances in CBs can be grouped based on three assumption dimensions: (i) the assumptions on the extent of information available about the causal graph structure, (ii) the assumptions about pre- and post-intervention statistical models, and (iii) the nature of the SEMs. There have been significant advances in understanding CBs when the _causal graphs are known_. The most relevant studies include those that started with analyzing \(do\) interventions as the simplest form of interventions [1; 2; 6; 7] and have progressed toward the more complex stochastic interventions (hard and soft). These studies have investigated various linear and non-linear SEMs. Specifically, the studies in [8; 9; 10; 11; 12; 13] assume that the pre- and post-interventional statistical distributions are known. The study in [14] further advances the results by assuming that these distributions are known only partially, and finally, the studies in [15; 16; 17; 18] entirely dispense with all the assumptions about the interventions' statistical models.

In sharp contrast, when the causal graph is _unknown_, the problem is far less investigated and open in its general form. The lack of topology knowledge makes the problem substantially more complex, since the graph's topology captures all the conditional independence information about the random variables in the system. Hence, when the graph is known, it is unnecessary to learn the conditional independencies; however, when it is unknown, all the conditional independencies should be learned.

The notable results under unknown graphs include [19], which assumes that all interventional distributions are _fully known_. Dispensing with the assumption of interventional distributions with a focus on \(do\) is investigated in [19, 20, 21, 22, 23, 24, 25]. \(do\) interventions are generally more amenable to tractable analysis because of the analytical simplifications they enable. A \(do\) intervention at a node sets the random value of that node to a pre-specified fixed value. This results in (i) removing all the causal dependence of that node on its ancestors and (ii) removing the randomness of the data generated by that node. In sharp contrast, _stochastic soft interventions_ are the more general and realistic forms of interventions that retain all the ancestral dependencies and the probabilistic nature of the model. A soft intervention, specifically, changes the pre-intervention statistical models to other distinct models.

Contributions.We establish upper and lower regret bounds for the CB problem under _unknown_ graphs, _unknown_ pre- and post-intervention statistical models, and _soft_ stochastic interventions. Furthermore, we also provide a novel approach to algorithm design and regret analysis. The main assumptions and contributions of the paper are as follows.

* **Topology:** We assume to know only the number of the nodes on the graph and the in-degree of the causal graph.1 Footnote 1: We note that assuming only an upper bound on the in-degree is sufficient to achieve the same regret bound.
* **Statistical model:** We assume that all pre- and post-intervention statistical models are unknown.
* **Regret bounds:** We characterize almost matching upper and lower bounds on the regret as a function of the time horizon and graph topology parameters. Specifically, we show the achievable regret of \(\tilde{\mathcal{O}}\big{(}(\kappa d)^{L-\frac{1}{2}}\sqrt{T}+d+N\big{)}\) where \(\kappa>1\) is a constant, \(N\) is the number of graph nodes, \(d\) is the maximum in-degree of the graph, \(L\) is the maximum causal depth, and \(T\) is the time horizon. We also establish the minimax regret lower bound of \(\Omega(d^{L-\frac{3}{2}}\sqrt{T})\).
* **Tightness of the bounds:** The dependence of the achievable regret on \(N\) is diminishing as \(T\) grows. Therefore, the mismatch of the achievable and the minimax regrets is on the order of \(d\) and a constant \(\kappa^{L-\frac{1}{2}}\).
* **Special cases:** Our general regret bounds provide improvements for the known special cases. In particular, we show that when the graph becomes known, our achievable regret becomes \(\tilde{\mathcal{O}}(d^{L-\frac{1}{2}}\sqrt{T})\), which is tighter than the best known results \(\tilde{\mathcal{O}}(d^{2L-1}\sqrt{T})\)[18].
* **Scalabe algorithm:** We introduce a novel CB algorithm under soft interventions. We note that the existing algorithms for soft algorithms are based on the upper confidence bound (UCB) principle, and they are generally not scalable due to the intractable optimization problem pertinent to maximizing the UCBs. In our algorithm, we circumvent his issue, resulting in a scalable algorithm as the graph size grows.

\begin{table}
\begin{tabular}{|c|c|c|c|c|} \hline Algorithm & Regret bound & Intervention & Scalable & Lower bound \\ \hline \hline \multicolumn{5}{|c|}{Unknown Graph} \\ \hline CN-UCB[20] & \(\tilde{\mathcal{O}}\big{(}\sqrt{KT}+Kd\big{)}\) & \(\mathrm{do}\) & ✓ & \(\Omega(\sqrt{NKT})\)1  \\ \hline GA-LCB (This paper) & \(\tilde{\mathcal{O}}\big{(}(\kappa d)^{L-\frac{1}{2}}\sqrt{T}+d+RN\big{)}\) & soft & ✓ & - \\ \hline \hline \multicolumn{5}{|c|}{Known Graph} \\ \hline C-UCB[6] & \(\tilde{\mathcal{O}}\left(\sqrt{K^{d}T}\right)\) & \(\mathrm{do}\) & ✓ & - \\ \hline LinSEM-UCB[15] & \(\tilde{\mathcal{O}}\left(d^{2L-\frac{3}{2}}\sqrt{NT}\right)\) & soft & ✗ & \multirow{2}{*}{\(\Omega\left(d^{L-\frac{3}{2}}\sqrt{T}\right)\)} \\ \hline GCB-UCB[18] & \(\tilde{\mathcal{O}}\left(d^{2L-1}\sqrt{T}\right)\) & soft & ✗ & \\ GA-LCB (this paper) & \(\tilde{\mathcal{O}}\left(d^{L-\frac{1}{2}}\sqrt{T}\right)\) & soft & ✓ & \\ \hline \end{tabular}
\end{table}
Table 1: Cumulative instance-independent regrets for linear CBs.

Notations.For a positive integer \(N\in\mathbb{N}\), we define \([N]\triangleq\{1,\cdots,N\}\). Random variables and their realizations are represented by upper- and lower-case letters, respectively. Matrices and vectors are represented by bold upper- and lower-case letters. The \(i\)-th element of vector \(\mathbf{x}\) is denoted by \(x_{i}\). The \(i\)-th column vector of matrix \(\mathbf{A}\) is denoted by \([\mathbf{A}]_{i}\) and \([\mathbf{A}]_{i,j}\) denotes the \((i,j)\) element of \(\mathbf{A}\). \(\mathbf{A}^{n}\) denotes the \(n\)-th power of matrix \(\mathbf{A}\) for \(n\in\mathbb{N}\). \(\mathds{1}\) denotes the indicator function. Sets and events are denoted by calligraphic letters. The cardinality of set \(\mathcal{A}\) is denoted by \(|\mathcal{A}|\). For any set \(\mathcal{S}\subseteq[N]\), \(\mathbf{1}\{\mathcal{S}\}\in\{0,1\}^{N}\) is specified such that its elements at the coordinates included in \(\mathcal{S}\) are set to \(1\), and the rest are \(0\). For a vector \(\mathbf{x}\) and positive semidefinite matrix \(\mathbf{A}\), we define \(\left\|\mathbf{x}\right\|_{\mathbf{A}}=\sqrt{\mathbf{x}^{\top}\mathbf{A} \mathbf{x}}\) as the weighted \(\ell_{2}\) norm. The \(\ell_{1}\)-norm and \(\ell_{2}\)-norm of vector \(\mathbf{x}\in\mathbb{R}^{d}\) are denoted by \(\left\|\mathbf{x}\right\|_{1}\) and \(\left\|\mathbf{x}\right\|_{2}\), respectively. The notation \(\tilde{\mathcal{O}}\) is an order notation that ignores constant and poly-logarithmic factors.

## 2 Causal Bandit Problem Setup

Causal graph.Consider an _unknown_ directed acyclic graph (DAG) \(\mathcal{G}=\{\mathcal{V},\mathcal{E}\}\) in which \(\mathcal{V}=[N]\) is the set of nodes and \(\mathcal{E}\) is the set of directed edges. A directed edge from node \(i\) to node \(j\) is denoted by the ordered tuple \((i,j)\). The set of parents of node \(i\in\mathcal{V}\) is denoted by \(\mathsf{pa}(i)\). Similarly, the sets of ancestors and descendants of node \(i\) are denoted by \(\mathsf{an}(i)\) and \(\mathsf{de}(i)\), respectively. We define the _causal depth_ of node \(i\), denoted by \(L_{i}\), as the length of the longest directed causal path that ends at node \(i\in[N]\). According, we denote the maximum causal depth of the graph by \(L\triangleq\max_{i\in[N]}L_{i}\) and denote the _maximum in-degree_ of the graph by \(d\triangleq\{\max_{i\in[N]}|\mathsf{pa}(i)|\}\).

Data model.DAG \(\mathcal{G}\) represents a Bayesian network, in which we denote the causal random variable associated with node \(i\in\mathcal{V}\) by \(X_{i}\). Accordingly, we define the random vector \(X\triangleq(X_{1},\ldots,X_{N})^{\top}\). For any \(A\subseteq\mathcal{V}\), \(X_{A}\) denotes the vector formed by \(\{X_{i}:i\in A\}\). The extents of the cause-effect relationships among the causal variables \(X\) are specified by the following linear SEMs:

\[X\ =\ \mathbf{B}^{\top}X+\epsilon\;,\] (1)

where \(\mathbf{B}\in\mathbb{R}^{N\times N}\) is the edge weights matrix and \(\epsilon\triangleq(\epsilon_{1},\ldots,\epsilon_{N})^{\top}\) denotes the model noises. It is noteworthy that the element \([\mathbf{B}]_{j,i}\) is non-zero if and only if \(j\in\mathsf{pa}(i)\). We denote the conditional distribution of \(X_{i}\) given its parents by \(\mathbb{P}(X_{i}\mid X_{\mathsf{pa}(i)})\).

Soft stochastic interventions.We use _soft_ interventions as the most general form of intervention. A _soft_ intervention on node \(i\) retains the ancestral dependence of \(X_{i}\) on \(X_{\mathsf{pa}(i)}\) and its probabilistic nature. Specifically, a soft intervention on node \(i\) changes the conditional probability \(\mathbb{P}(X_{i}\mid X_{\mathsf{pa}(i)})\) to a distinct one denoted by \(\mathbb{Q}(X_{i}\mid X_{\mathsf{pa}(i)})\). In a linear SEM, the impact of a soft intervention on node \(i\) can be abstracted by a change in the vector \([\mathbf{B}]_{i}\). We denote the post-intervention vector by \([\mathbf{B}^{*}]_{i}\). We refer to \(\mathbf{B}\) and \(\mathbf{B}^{*}\) as the observational and interventional weights matrices, respectively. We allow multiple nodes to be intervened simultaneously and denote the space of possible interventions by \(\mathcal{A}\triangleq 2^{[N]}\). For a specific intervention \(\mathbf{a}\in\mathcal{A}\), we define \(\mathbf{B}_{\mathbf{a}}\) as the post-intervention weight matrix specified by

\[[\mathbf{B}_{\mathbf{a}}]_{i}\ \triangleq\ \mathds{1}\{i\in\mathbf{a}\}[ \mathbf{B}^{*}]_{i}+\mathds{1}\{i\notin\mathbf{a}\}[\mathbf{B}]_{i}\;.\] (2)

Causal bandit - problem statement.In causal bandit, a learner performs a sequence of interventions to optimize a reward measure. Each unique set of interventions \(\mathbf{a}\in\mathcal{A}\) is represented by an arm. Following the CB's convention, we designate node \(N\) as the reward node and its associated value \(X_{N}\) as the reward variable. We denote the post-intervention probability measure of \(X\) induced by intervention \(\mathbf{a}\) by \(\mathbb{P}_{\mathbf{a}}\), and the associated expectation by \(\mathbb{E}_{\mathbf{a}}\). Subsequently, we denote the expected value of variable \(X_{i}\) under intervention \(\mathbf{a}\in\mathcal{A}\) by

\[\mu_{i,\mathbf{a}}\ \triangleq\ \mathbb{E}_{\mathbf{a}}[X_{i}]\;,\] (3)

Accordingly, we denote the optimal intervention by \(\mathbf{a}^{*}\), which is specified by

\[\mathbf{a}^{*}\ \triangleq\ \operatorname*{arg\,max}_{\mathbf{a}\in\mathcal{A}} \mu_{N,\mathbf{a}}\;.\] (4)

The sequence of interventions over time is denoted by \(\{\mathbf{a}(t)\in\mathcal{A}:t\in\mathbb{N}\}\). Upon intervention \(\mathbf{a}(t)\) in round \(t\), the learner observes \(X(t)\triangleq(X_{1}(t),\ldots,X_{N}(t))^{\top}\) and collects the reward \(X_{N}(t)\). The learner's objective is to minimize the regret that it incurs with respect to an omniscient oracle that hasaccess to the best intervention \(\mathbf{a}^{*}\). Hence, the average regret incurred at time \(t\) is \(r(t)=\mu_{\mathbf{a}^{*}}-\mu_{\mathbf{a}}\). Accordingly, the average cumulative regret over horizon \(T\) is given by

\[\mathbb{E}[\mathcal{R}(T)]\ \triangleq\ T\mu_{\mathbf{a}^{*}}-\sum_{t=1}^{T}\mu_{ \mathbf{a}(t)}\.\] (5)

We list the set of assumptions that we make about the SEMs.

**Assumption 1** (Unknown graph).: _We assume that the skeleton and orientation of the edges in graph \(\mathcal{G}\) are unknown. We assume the number of nodes \(N\) and degree \(d\) are known._

This assumption is in contrast to all the existing studies on soft intervention [15; 16; 17; 18].

**Assumption 2** (Unknown conditional distributions).: _We assume that all observational and interventional conditional distributions \(\{\mathbb{P}(X_{i}\mid X_{\mathsf{pa}(i)}):i\in[N]\}\) and \(\{\mathbb{Q}(X_{i}\mid X_{\mathsf{pa}(i)}):i\in[N]\}\) are unknown._

**Assumption 3** (Weight matrices).: _The interventional and observational matrices \(\mathbf{B}\) and \(\mathbf{B}^{*}\) are unknown. We assume that the range of weight matrix elements is known, i.e., there exists a known \(m_{\mathbf{B}}\in\mathbb{R}_{+}\) such that \(|[\mathbf{B}]_{j,i}|\ \leq\ m_{\mathbf{B}}\) and \(|[\mathbf{B}^{*}]_{j,i}|\ \leq\ m_{\mathbf{B}}\) for all \(i,j\in[N]\)._

**Assumption 4** (Noise model).: _We assume that the noise statistical model is unknown. The expected noise value \(\bm{\nu}\triangleq\mathbb{E}[\epsilon]\) is known. We assume the noise terms are independent and bounded, i.e., there exists \(m_{\epsilon}\in\mathbb{R}_{+}\) such that \(|\epsilon_{i}(t)|\leq m_{\epsilon}\) for all \(i\in[N]\) and \(t\in[T]\)._

We note the assumption that knowing \(d\) can be replaced by knowing an upper bound, and the requirement of expected noise value \(\bm{\nu}\) can be removed by the re-arrange method in [15]. To ensure the bounded stability of the system, the bounded noise and weights assumptions are widely used in the linear causal bandits literature [15; 26; 27]. These assumptions imply boundedness of the variables, i.e., there exists constant \(m\) such that \(\|X\|\leq m\). The recent study in [28] shows that in linear bandits, the regret will scale linearly with this constant. Without loss of generality, we assume \(m_{\epsilon}=m_{\mathbf{B}}=1\). Finally, we provide the following standard regularity condition on interventions to ensure sufficient distinction between the observational and interventional statistical models [20; 23].

**Assumption 5** (Intervention regularity).: _A soft intervention on node \(i\) with causal depth \(L_{i}\geq 1\) shifts the expected values of the descendants of \(i\) at least \(\eta\), i.e., \(\big{|}\mu_{j,\emptyset}-\mu_{j,(i)}\big{|}\ >\ \eta\) for all \(i\in[N]\) and \(j\in\mathsf{de}(i)\)._

## 3 Graph-Agnostic Linear Causal Bandit (GA-LCB) Algorithm

In this section, we introduce our proposed algorithm **G**raph-**A**gnostic **L**inear **C**ausal **B**andit (GA-LCB). We also provide detailed comparisons to the existing algorithms designed for soft interventions. We will provide the regret analysis in Section 4, and defer all the proofs to the appendices.

Algorithm overview.Identifying the best intervention \(\mathbf{a}^{*}\) defined in (4) hinges on learning all the possible probability distributions \(\mathbb{P}_{\mathbf{a}}\), the number of which grows exponentially with graph size \(N\). Learning such an excessive number of distributions can be circumvented by properly leveraging the SEM parameters. Specifically, all the distributions \(\{\mathbb{P}_{\mathbf{a}}:\mathbf{a}\in\mathcal{A}\}\) are functions of the observational and interventional weight matrices \(\mathbf{B}\) and \(\mathbf{B}^{*}\). Furthermore, we note that each of these matrices consists of at most \(Nd\) non-zero entries. Hence, learning the entire set of distributions is equivalent to estimating at most \(2Nd\) non-zero parameters of \(\mathbf{B}\) and \(\mathbf{B}^{*}\). This problem, however, faces the hard constraint that the estimated matrices \(\mathbf{B}\) and \(\mathbf{B}^{*}\) must conform to a valid DAG structure. Not enforcing this constraint gives rise to issues such as the possibility of support structures that include cycles or inconsistent supports for the estimates of \(\mathbf{B}\) and \(\mathbf{B}^{*}\).

For this DAG-constrained problem of estimating matrices \(\mathbf{B}\) and \(\mathbf{B}^{*}\), we take a two-step approach. The first step aims to resolve the skeleton uncertainty to the extent needed to identify the best intervention, and the second step leverages the skeleton estimates to identify the best intervention design. More specifically, the first step (GA-LCB-SL in Algorithm 1) focuses on estimating the skeleton, which is equivalent to estimating the parent sets \(\{\mathsf{pa}(i):i\in[N]\}\). Forming such estimates based on _soft_ interventions is fundamentally different from doing so based on \(do\) intervention setting [20; 23] since under \(do\) interventions, identifying \(\mathsf{pa}(N)\) suffices to determine the best intervention when there are no confounders. This is because \(do\) interventions remove all ancestral dependence of \(X_{N}\), and its statistical model can be specified only by the value assigned to its parents under a \(do\) intervention. Under soft interventions, however, all the causal paths from the youngest nodes to the reward node remain intact. This means that all nodes along the causal paths that end at the reward node contribute to the reward. Therefore, inevitably, we need to estimate the parent sets \(\{\mathsf{pa}(i):i\in[N]\}\). Motivated by these, Algorithm 1 provides estimates \(\{\widehat{\mathsf{pa}}(i):i\in[N]\}\) such that with a high probability: (1) \(\mathsf{pa}(i)\subseteq\widehat{\mathsf{pa}}(i)\); and (2) \(|\widehat{\mathsf{pa}}(i)|\leq c|\mathsf{pa}(i)|\) for a small constant \(c>1\). We note that our approach is distinct from the conventional approaches to learning causal skeletons, which typically identify only the Markov equivalence class and assume the existence of an oracle rather than focusing on sample complexity and computational efficiency. For linear non-Gaussian data, a DAG can be learned using observational data with a sample complexity of \(O(d^{4}\log n)\)[29]. In comparison, our CB-based structure learning saves on sample complexity and computation.

```
1:Inputs: identifiability parameter \(\eta\), sufficient exploration conditions \(T_{1}\) and \(T_{2}\)
2:\(t=0\)
3:while\(\widehat{\mathcal{G}}\) is not a DAG or \(t\leq(N+1)T_{1}\)do
4: Pull the arm \(\mathbf{a}(Nt+1)=\emptyset\) and observe \(X(t)\) and set \(t=t+1\)
5:for\(i\in[N-1]\)do
6: Pull the arm \(\mathbf{a}(Nt+i+1)=\{i\}\) and observe \(X(t)\)
7: Identify the ancestors set \(\widehat{\mathsf{an}}(i)\) according to (9) and construct \(\widehat{\mathcal{G}}\)
8:\(t=t+1\)
9:if\(N_{\emptyset}<T_{2}\)then Pull the arm \(\mathbf{a}(t)=\emptyset\) and observe \(X(t)\) until \(N_{\emptyset}=T_{2}\)
10: Calculate the Lasso estimator \([\widehat{\mathbf{B}}]_{i}^{\text{Lasso}}\) as in (10)
11: Identify the parents: \(\widehat{\mathsf{pa}}(i)=\operatorname{supp}\left([\widehat{\mathbf{B}}]_{i}^ {\text{Lasso}}\right)\)
12: Return: \(\{\widehat{\mathsf{pa}}(i)\mid i\in[N]\}\) and topological ordering \(\widehat{\pi}\) based on ancestors sets ```

**Algorithm 1** Graph-Agnostic Linear Causal Bandit: Structure Learning (GA-LCB-SL)

The second step is focused on narrowing the search space for the set of candidate interventions among which the optimal one is identified. This will provide significant computational savings as we will discuss. In this step, specifically, based on the estimates \(\{\widehat{\mathsf{pa}}(i):i\in[N]\}\), the GA-LCB-ID algorithm performs a successive refinement of the set \(\mathcal{A}\) to identify the intervention set of interest. This process consists of \(S=\left\lceil\log\sqrt{T}\right\rceil\) refinement stages, where the refined set in stage \(s\in[S]\) is denoted by \(\hat{\mathcal{A}}_{s}\subset\mathcal{A}_{s-1}\) with \(\hat{\mathcal{A}}_{1}\triangleq\mathcal{A}\). To identify the interventions to be eliminated at stage \(s\), the GA-LCB-ID algorithm identifies the interventions whose UCB values fall below the maximum in \(\hat{\mathcal{A}}_{s}\) minus a bandwidth \(m2^{1-s}\). Such successive refinement allows us to calculate UCBs only for promising interventions, leading to a higher computational efficiency. Furthermore, the refinement rules do not need to calculate the exact UCB values. Instead, they calculate an upper bound for the UCBs, referred to as the UCB _widths_. This circumvents the computational challenge of calculating the exact UCBs.

### Step 1: CB-based Structure Learning

Our approach to using a sequence of interventions to learn the unknown graph \(\mathcal{G}\) consists of two procedures. It starts by identifying the correct ancestors \(\mathsf{an}(i)\) for \(i\in[N]\). After \(T_{1}\) rounds of exploration, for all \(i,j\in[N]\) we compute the mean estimates as

\[\hat{\mu}_{i,\emptyset}(t)\ =\ \frac{1}{N_{\emptyset}(t)}\sum_{\tau\in[t], \mathsf{an}(\tau)=\emptyset}X_{i}(\tau)\,\quad\text{and}\quad\hat{\mu}_{i,\{j\}}(t)\ =\ \frac{1}{N_{\{j\}}(t)}\sum_{\tau\in[t],\mathsf{an}(\tau)=\{j\}}X_{i}(\tau)\,\] (6)

where \(N_{\mathsf{a}}(t)\) denote the number of times the \(\mathbf{a}\in\mathcal{A}\) is selected up to time \(t\)

\[N_{\mathbf{a}}(t)\ \triangleq\ \sum_{\tau\in[t]}\mathds{1}\left\{\mathbf{a}( \tau)=\mathbf{a}\right\}\,.\] (7)

Subsequently, the algorithm identifies descendants sets \(\widehat{\mathsf{de}}(i)\) for \(i\in[N]\) according to:

\[\widehat{\mathsf{de}}(i)\ =\ \left\{j\in[N]\ :\ |\hat{\mu}_{j,\emptyset}-\hat{\mu}_{j, \{i\}}|>\frac{\eta}{2}\right\}\,\] (8)according to which clearly \(i\in\widehat{\mathsf{de}}(i)\). Note that \(|\mathsf{de}(i)|=0\) indicates that node \(i\) is a root node (intervention on a root node does not change the conditional distributions). Furthermore, we also estimate the ancestors sets \(\{\widehat{\mathsf{an}}(i):i\in[N]\}\) according to:

\[\widehat{\mathsf{an}}(i)=\big{\{}j\in[N]\;:\;i\neq j\text{ and }\{|\widehat{ \mathsf{de}}(j)|=0\text{ or }i\in\widehat{\mathsf{de}}(j)\}\big{\}}\;.\] (9)

The algorithm will check whether the ancestor sets will form a DAG. This is confirmed by verifying that there does not exist \(i,j\in[N]\) such that \(j\in\widehat{\mathsf{de}}(i)\) and \(i\in\widehat{\mathsf{de}}(j)\). To further refine the estimate of the parent set, the algorithm initiates \(T_{2}\) rounds of additional explorations. This ensures the algorithm has gathered sufficient observational data to accurately identify the parent set \(\mathsf{pa}(i)\). Subsequently, it uses the Lasso estimator on the ancestors set with \(\lambda=m\sqrt{\frac{2\log(4N|\widehat{\mathsf{an}}(i)|/\delta)}{N_{\mathsf{ b}}(t)}}\) for \(i\in[N]\) as

\[[\widehat{\mathbf{B}}^{\text{Lasso}}]_{i}\;=\;\underset{\theta\in\mathbb{R}^{| \mathsf{da}(i)|}}{\text{argmin}}\bigg{(}\frac{1}{N_{\mathsf{b}}(t)}\sum_{\tau \in[t],\mathsf{a}(\tau)=\emptyset}\big{(}X_{i}(\tau)-\theta^{\top}X_{\widehat {\mathsf{an}}(i)}(\tau)\big{)}^{2}+\lambda\|\theta\|_{1}\bigg{)}.\] (10)

Based on these steps, Algorithm 1 identifies the parent set of node \(i\in[N]\) as

\[\widehat{\mathsf{pa}}(i)\;=\;\operatorname{supp}\left([\widehat{\mathbf{B}}^{ \text{Lasso}}]_{i}\right)\;.\] (11)

Specifically, Algorithm 1 returns the estimates \(\{\widehat{\mathsf{pa}}(i):i\in[N]\}\) and a valid topological order \(\hat{\pi}\) based on ancestor information. Given a causal graph \(\mathcal{G}\), an ordered permutation of \([N]\), denoted by \(\pi\) is said to be a valid topological order if for each edge \((i\to j)\in\mathcal{E}\), we have \(\pi_{i}<\pi_{j}\). This can be achieved by iteratively adding nodes to \(\pi\) such that the parents of that node are already included in \(\pi\). Finally, we note that we set the exploration constants \(T_{1}\) and \(T_{2}\) as follows.

\[T_{1}=\frac{32m^{2}}{\eta^{2}}\log\left(\frac{2N^{2}}{\delta}\right)\;,\quad \text{and}\quad T_{2}=cd\log(N)\;,\] (12)

where \(c>1\) is a constant.

```
1:Inputs: Time Horizon \(T\), \(S=\big{\lceil}\log\sqrt{T}\big{\rceil}\), exploration parameter \(\alpha\in\mathbb{R}^{+}\), {identifiability parameter \(\eta\), sufficient exploration conditions \(T_{1}\) and \(T_{2}\)} or {edge set \(\mathcal{E}\)},
2:if\(\mathcal{E}\) not given then
3:\(\{\widehat{\mathsf{pa}}(i)\;|\;i\in[N]\},\widehat{\pi}=\)GraphLearning(\(\eta,T_{1},T_{2}\))
4:set \(s=1\) and \(\hat{\mathcal{A}}_{1}=\mathcal{A}\)
5:while\(t\leq T\)do
6:for\(i\in[N]\)do
7: Calculate the ridge regression estimators \([\mathbf{B}(t-1)]_{i}\) and \([\mathbf{B}^{*}(t-1)]_{i}\) as in (13) and (14)
8:for\(\mathbf{a}\in\hat{\mathcal{A}}_{s}\)do
9:for\(i\in\widehat{\pi}\)do
10: Calculate estimated mean \(\hat{\mu}_{i,\mathbf{a}}(t)\) as in (17)
11: Calculate the width \(w_{i,\mathbf{a}}(t-1)\) according to (19)
12: Calculate \(\operatorname{UCB}_{\mathbf{a}}(t-1)=\hat{\mu}_{N,\mathbf{a}}(t-1)+w_{N, \mathbf{a}}(t-1)\)
13:if\(w_{N,\mathbf{a}}(t-1)\leq m\frac{1}{\sqrt{T}}\) for all \(\mathbf{a}\in\hat{\mathcal{A}}_{s}\)then
14: Choose \(\mathbf{a}(t)\) according to (23) until \(t=T\)
15: Break
16:while\(w_{N,\mathbf{a}}(t-1)\leq m2^{-s}\) for all \(\mathbf{a}\in\hat{\mathcal{A}}_{s}\)do
17: Update \(\hat{\mathcal{A}}_{s+1}\) as in (22) and set \(s=s+1\)
18: Choose \(\mathbf{a}(t)\in\hat{\mathcal{A}}_{s}\) such that \(w_{\mathbf{a}(t)}^{*}>m2^{-s}\) ```

**Algorithm 2** Graph-Agnostic Linear Causal Bandit: Intervention Design (GA-LCB-ID)

### Step 2: Sequential Design of Interventions

Assume at the stage \(s\in S\triangleq\big{\lceil}\log\sqrt{T}\big{\rceil}\), the algorithm maintains a refined set \(\hat{\mathcal{A}}_{s}\subset\mathcal{A}\). It starts with the set of candidates \(\hat{\mathcal{A}}_{1}=\mathcal{A}\) and successively refines this set by performing elimination on the previous refined set using the \(\operatorname{UCB}\)_width_. Based on the outputs of Algorithm 1, we first estimate 

[MISSING_PAGE_EMPTY:7]

### Computational Efficiency

We compare the computational efficiency of our algorithm with those of the existing algorithms for linear SEMs with soft interventions in [15; 18]. The algorithms in these studies adopt similar procedures: they find estimators for observational and interventional weights, form the confidence ellipsoids for the weights, and solve a joint optimization problem to calculate UCBs as

\[\mathrm{UCB}_{\mathbf{a}}\ =\max_{\widetilde{\mathbf{B}}_{\mathbf{a}}\in\mathcal{C}_{ \mathbf{a}}}\left\langle f_{N}\big{(}\widetilde{\mathbf{B}}_{\mathbf{a}}\big{)},\boldsymbol{\nu}\right\rangle\,,\] (24)

where \(\mathcal{C}_{\mathbf{a}}=\prod_{i\in[N]}\mathcal{C}_{i,\mathbf{a}}\) and \(\mathcal{C}_{i,\mathbf{a}}=\mathds{1}\{i\in\mathbf{a}\}\mathcal{C}_{i}^{*}+ \mathds{1}\{i\notin\mathbf{a}\}\mathcal{C}_{i}\) are confidence regions, \(f_{N}\) is compounding function (see [15, Lemma 1] or Appendix C). Subsequently, the interventions are chosen as those that maximize \(\mathrm{UCB}_{\mathbf{a}}\)

\[\mathbf{a}(t+1)=\operatorname*{arg\,max}_{\mathbf{a}\in\mathcal{A}}\mathrm{UCB }_{\mathbf{a}}\enspace.\] (25)

All the algorithms estimate the observational and interventional weights by solving \(2N\) ridge regressions, which is not the computation bottleneck. The two bottlenecks in this standard UCB-type approach lie in solving (24) and (25).

First, different from the case in linear bandits [30], the optimization problem in (24) for CBs is neither convex nor concave. This is due to the highly non-linear reward function. The nonlinearity arises from the compounding effects of the causal influences along different paths leading to the reward node. The contribution of any given node \(X_{i}\) to the reward value will be multiplied by all the coefficients along the path connecting \(X_{i}\) to the reward node (see Appendix C for more details). When there are multiple such paths, the aggregate weight products of all paths carry the contribution of \(X_{i}\) to the reward node. Therefore, the reward becomes a function of the product of causal weights (i.e., elements of \(\mathbf{B}\) and \(\mathbf{B}^{*}\)). This non-linearity in weights makes the optimization problem in (24) becomes computationally impossible for larger graphs. In contrast, GA-LCB addresses this issue by computing the upper confidence bounds iteratively through causal depth, which can be done in polynomial time.

Secondly, solving (25) involves an optimization problem over a discrete set of size \(2^{N}\), the computational complexity of which grows exponentially with \(N\). To circumvent this, GA-LCB randomly chooses the under-explored intervention (line 18). UCB optimization specified in (23) is performed only when the refinement process is completed, indicating that (23) will be solved over a small subset of sufficiently good interventions.

## 4 Regret Analysis

We show that the GA-LCB is almost minimax optimal by characterizing the achievable regret of the GA-LCB algorithm in the graph-independent setting and establishing that it matches a minimax regret lower bound. We provide additional discussions to interpret the dependence of the regret terms on various graph parameters and the relationship of these results vis-a-vis the existing results in the literature. We also present an improved graph-dependent bound, when additional information about the graph is available.

### Graph-independent bounds

We first show the graph-independent bounds that hold for a class of bandits with a maximum in-degree \(d\) and maximum causal length \(L\). The key steps in these analyses involve determining the exploration time that ensures the identification of the parent sets with high probability and bounding the time instances that the refinement process is conducted. To delineate a regret upper bound, we start by establishing the performance guarantee for the GA-LCB-SL algorithm. In the following theorem, we demonstrate that with high probability, this algorithm correctly identifies the topological ordering and the parent sets. For this purpose, we define \(\kappa_{\max}\) and \(\kappa_{\min}\) as the maximum and minimum eigenvalue of the following second moment with null intervention:

\[\kappa_{\max}\ \triangleq\ \lambda_{\max}\left(\mathbb{E}_{\emptyset}\left[XX^{ \top}\right]\right)\,,\quad\kappa_{\min}\ \triangleq\ \lambda_{\min}\left(\mathbb{E}_{\emptyset}\left[XX^{\top}\right]\right)\enspace.\] (26)

**Theorem 1** (Achievable Graph Skeleton Learning).: _Under Assumptions 1-4, the GA-LCB-SL algorithm ensures that_1. _with probability_ \(1-\delta\) _we have a valid topological ordering_ \(\widehat{\pi}\)_; and_
2. _with probability at least_ \(1-2\delta\)_, for all_ \(i\in[N]\) _we have_ \(\mathsf{pa}(i)\subseteq\widehat{\mathsf{pA}}(i)\) _and_ \(|\widehat{\mathsf{pA}}(i)|\leq\kappa|\mathsf{pa}(i)|\)_,_

_where \(\kappa\) is defined as_

\[\kappa=\frac{9\min\left\{m^{2},\kappa_{\max}+m^{2}\sqrt{\frac{16}{3T_{2}}\log \left(\frac{2dN}{\delta}\right)}\right\}}{\kappa_{\min}}\;.\] (27)

Leveraging the result of Theorem 1, we characterize the achievable regret of GA-LCB.

**Theorem 2** (Achievable Regret).: _Under Assumptions 1-5, the GA-LCB-ID algorithm ensures that with probability \(1-3\delta\)_

\[\mathbb{E}[\mathcal{R}(T)]\;\leq\;\tilde{\mathcal{O}}\big{(}(\kappa d)^{L- \frac{1}{2}}\sqrt{T}+d+RN\big{)}\;,\] (28)

_where we have defined \(R\triangleq\frac{m^{2}}{\eta^{2}}\)._

We note that \(R\) represents the guaranteed maximum signal-to-intervention-power ratio. This ratio measures the difficulty in distinguishing between observational and interventional distributions (the higher \(R\), the harder to distinguish).

To emphasize the cost of learning the skeleton, in the next corollary, we provide the achievable regret of the GA-LCB algorithm when the graph skeleton is known.

**Corollary 1** (Achievable Regret - Known Skeleton).: _When the graph skeleton is known, under the same setting as in Theorem 2, with probability \(1-\delta\), GA-LCB-ID ensures that_

\[\mathbb{E}[\mathcal{R}(T)]\;\leq\;\tilde{\mathcal{O}}\big{(}d^{L-\frac{1}{2}} \sqrt{T}\big{)}\;.\] (29)

Comparing Corollary 1 with Theorem 1, we observe that the term \(\tilde{\mathcal{O}}(d+RN)\) represents the cost to do structure learning, while \(\kappa^{L-\frac{1}{2}}\) reflects the cost resulting from imperfect graph learning.

Next, we establish a lower bound on the regret. Any lower bound on the regret of the setting in which the graph's skeleton is _known_ will immediately serve as a lower bound for our setting with an _unknown_ graph. We will present one such lower bound and show that even though it is expectedly looser than a lower bound for our setting, it still almost matches the achievable regret characterized in Theorem 2. We also emphasize that our result improves the known minimax lower bound when the graph skeleton is known (c.f. [15, 18]).

**Theorem 3** (Regret Lower Bound).: _For any given skeleton with parameters \(d\) and \(L\), there exists a causal bandit instance such that the expected regret of any algorithm is at least_

\[\mathbb{E}[\mathcal{R}(T)]\;\geq\;\Omega\big{(}d^{L-\frac{3}{2}}\sqrt{T} \big{)}\;.\] (30)

When comparing the upper bound in Theorem 2 and the lower bound in Theorem 3, we observe that the regret upper bound and lower bound show similar behavior with respect to graph parameter \(d\), \(L\), and the time horizon \(T\). Given these results, we provide some observations.

* **Dependence on \(N\).** We first note that the achievable regret has a diminishing dependence on the graph size \(N\) as \(T\) grows. This is especially important since the number of interventions grows exponentially with \(N\). This result indicates that the achievable regret has a diminishing effect not only on the graph size but also on the cardinality of the intervention space.
* **Unknown Skeleton.** Comparing Theorem 2 and Corollary 1 indicates that the impact of an unknown graph has two parts. First, sufficient exploration is required to determine the correct topological ordering and parent sets, which adds a \(\tilde{\mathcal{O}}(d+RN)\) term to the regret bound. Secondly, the imperfect identification of the parent set by the Lasso estimator leads to an estimated graph with a maximum in-degree of \(cd\) instead of \(d\), which is propagated through the network layers.
* **Graph topology.** The regret bounds depend on the graph through its connectivity parameters \(d\) and \(L\). Unlike the observations in [15, 18], we have almost-matching upper and lower bounds up to a \(d\) factor. This significantly improves from the previously-known gap of \(d^{L}\).

* **Dependence on \(T\).** Regret upper and lower bound both scale with \(T\) at the rate \(\tilde{\mathcal{O}}(\sqrt{T})\).
* **Linear bandits.** Finally, we note that despite some similarities, our problem is significantly different from linear bandits since, as shown in Appendix C, in linear causal bandits, the reward is non-linear with respect to the parameters or the interventions. This is the case for even \(L=1\). We note that our regret's dependence on \(d\) differs from that in the linear bandit setting. In linear bandits, the regret scales linearly with \(d\) as shown in [31; 32]. When \(L=1\), the regret upper bound in our case scales as \(\tilde{\mathcal{O}}(\sqrt{dT})\), and the regret lower bound scales as \(\Omega(\sqrt{T})\). We conjecture that the regret upper bound is tighter because it more accurately captures the uncertainty of parameter estimation.
* **Regret bounds comparisons.** GA-LCB provides significantly improved regret bounds compared to LinSEM-UCB [15] and GCB-UCB [18]. Specifically, under the known graph skeleton setting, GA-LCB achieves a \(d^{L}\sqrt{N}\) factor improvement in the regret bounds compared to LinSEM-UCB. While GCB-UCB removes the \(\sqrt{N}\) factor, it underperforms compared to LinSEM-UCB. Furthermore, our regret upper bound has only a \(d\) factor more than the lower bound.

### Graph-dependent Regret Bound

The graph-independent bounds can be further refined to recover graph-dependent regret bounds that use the instance-level information. To account for the actual influence of the graph parameters on the reward node, we define the _effective maximum in-degree_ as \(d_{e}=\max_{i\in\mathsf{an}(N)}d_{i}\) and the _effective maximum causal depth_ as \(L_{e}=\max_{i\in\mathsf{an}(N)}L_{i}\). We have the natural inequalities \(d_{e}\leq d\) and \(L_{e}\leq L\). To characterize the graph-dependent bound, we need to slightly modify the GA-LCB-ID algorithm. Specifically, we only need to identify the optimal intervention within \(\mathcal{A}^{\prime}=2^{[\widehat{\mathsf{an}}(N)]}\) and estimate the column vectors \(\{[\mathbf{B}]_{i},[\mathbf{B}^{*}]_{i}:i\in\widehat{\mathsf{an}}(N)\}\). By incorporating instance-specific information about the graph structure, the regret upper bound can be further refined as follows.

**Corollary 2** (Achievable Regret - Graph-Dependent).: _When \(L_{e}\) and \(d_{e}\) are known, the modified GA-LCB-ID algorithm ensures that with probability \(1-3\delta\)_

\[\mathbb{E}[\mathcal{R}(T)]\ \leq\ \tilde{\mathcal{O}}\big{(}(\kappa d_{e})^{L_{e }-\frac{1}{2}}\sqrt{T}+d+RN\big{)}\.\] (31)

By comparing the upper bound in Theorem 2 and Corollary 2, we observe that the cost of learning the graph remains intact. The reason is that we must explore interventions on every node \(i\in[N]\) to identify the ancestor relationships, even when graph-dependent information is known. Hence, all the regret improvements are due to the part of learning the best intervention, particularly in relation to the graph topology. The term \((\kappa d)^{L-\frac{1}{2}}\) in Theorem 2 is replaced with \((\kappa d_{e})^{L_{e}-\frac{1}{2}}\). The change is due to the fact we do not need to learn optimal intervention in the whole graph \(\mathcal{G}\) as the interventions on non-ancestor nodes will not affect the reward. Instead, it suffices to learn only the optimal intervention on the subgraph \(\tilde{\mathcal{G}}\) formed by \(\widehat{\mathsf{an}}(N)\) and the parameters of \(\tilde{\mathcal{G}}\).

## 5 Conclusions

In this paper, we have solved the causal bandit problem with unknown graph skeletons under general stochastic interventions. We have proposed an implementable algorithm and provided regret analysis for both unknown and known graph skeletons. The unknown skeleton affects the achievable regret bounds in two ways: a term that is linear in \(d+N\) but is independent of \(T\) and a \(cd\) factor due to the imperfect identification of the parents. When the graph skeleton is unknown, the achievable regret bounds and the minimax regret lower bound are shown to match up to a \(d\) factor. Compared to the existing algorithms, the proposed algorithm is more amenable to scalable implementation.

## Acknowledgments

This work was supported in part by the U.S. National Science Foundation under Grant DMS-2319996, and in part by the Rensselaer-IBM Future of Computing Research Collaboration (FCRC).

## References

* Lattimore et al. [2016] Finnian Lattimore, Tor Lattimore, and Mark D Reid. Causal bandits: Learning good interventions via causal inference. In _Proc. Advances in Neural Information Processing Systems_, Barcelona, Spain, December 2016.
* Bareinboim et al. [2015] Elias Bareinboim, Andrew Forney, and Judea Pearl. Bandits with unobserved confounders: A causal approach. In _Proc. Advances in Neural Information Processing Systems_, Montreal, Canada, December 2015.
* Ahmed et al. [2021] Ossama Ahmed, Frederik Trauble, Anirudh Goyal, Alexander Neitz, Manuel Wuthrich, Yoshua Bengio, Bernhard Scholkopf, and Stefan Bauer. Causalworld: A robotic manipulation benchmark for causal structure and transfer learning. In _Proc. International Conference on Learning Representations_, virtual, May 2021.
* Liu et al. [2020] Siqi Liu, Kay Choong See, Kee Yuan Ngiam, Leo Anthony Celi, Xingzhi Sun, and Mengling Feng. Reinforcement learning for clinical decision support in critical care: Comprehensive review. _Journal of Medical Internet Research_, 22(7), July 2020.
* Zhao et al. [2022] Yan Zhao, Mitchell Goodman, Sameer Kanase, Shenghe Xu, Yannick Kimmel, Brent Payne, Saad Khan, and Patricia Grao. Mitigating targeting bias in content recommendation with causal bandits. In _Proc. ACM Conference on Recommender Systems Workshop on Multi-Objective Recommender Systems_, Seattle, WA, September 2022.
* Lu et al. [2020] Yangyi Lu, Amirhossein Meisami, Ambuj Tewari, and William Yan. Regret analysis of bandit problems with causal background knowledge. In _Proc. Conference on Uncertainty in Artificial Intelligence_, virtual, August 2020.
* Nair et al. [2021] Vineet Nair, Vishakha Patil, and Gaurav Sinha. Budgeted and non-budgeted causal bandits. In _Proc. International Conference on Artificial Intelligence and Statistics_, virtual, April 2021.
* Yabe et al. [2018] Akihiro Yabe, Daisuke Hatano, Hanna Sumita, Shinji Ito, Naonori Kakimura, Takuro Fukunaga, and Ken-ichi Kawarabayashi. Causal bandits with propagating inference. In _Proc. International Conference on Machine Learning_, Stockholm, Sweden, July 2018.
* Maiti et al. [2022] Aurhya Maiti, Vineet Nair, and Gaurav Sinha. A causal bandit approach to learning good atomic interventions in presence of unobserved confounders. In _Proc. Conference on Uncertainty in Artificial Intelligence_, Eindhoven, Netherlands, August 2022.
* Xiong and Chen [2023] Nuoya Xiong and Wei Chen. Pure exploration of causal bandits. In _Proc. International Conference on Learning Representations_, Kigali, Rwanda, May 2023.
* Feng and Chen [2023] Shi Feng and Wei Chen. Combinatorial causal bandits. In _Proc. AAAI Conference on Artificial Intelligence_, Washington, D.C., February 2023.
* Sawarni et al. [2023] Ayush Sawarni, Rahul Madhavan, Gaurav Sinha, and Siddharth Barman. Learning good interventions in causal graphs via covering. In _Proc. Conference on Uncertainty in Artificial Intelligence_, Pittsburgh, PA, 2023.
* Wei et al. [2023] Lai Wei, Muhammad Qasim Elahi, Mahsa Ghasemi, and Murat Kocaoglu. Approximate allocation matching for structural causal bandits with unobserved confounders. In _Proc. Advances in Neural Information Processing Systems_, New Orleans, LA, December 2023.
* Sen et al. [2017] Rajat Sen, Karthikeyan Shanmugam, Alexandros G. Dimakis, and Sanjay Shakkottai. Identifying best interventions through online importance sampling. In _Proc. International Conference on Machine Learning_, Sydney, Australia, August 2017.
* Varici et al. [2023] Burak Varici, Karthikeyan Shanmugam, Prasanna Sattigeri, and Ali Tajer. Causal bandits for linear structural equation models. _Journal of Machine Learning Research_, 24(297):1-59, 2023.
* Sussex et al. [2023] Scott Sussex, Anastasiia Makarova, and Andreas Krause. Model-based causal bayesian optimization. In _Proc. International Conference on Learning Representations_, Kigali, Rwanda, May 2023.

* [17] Scott Sussex, Pier Giuseppe Sessa, Anastasia Makarova, and Andreas Krause. Adversarial causal bayesian optimization. In _Proc. International Conference on Learning Representations_, Kigali, Rwanda, May 2023.
* [18] Zirui Yan, Dennis Wei, Dmitriy Katz-Rogozhnikov, Prasanna Sattigeri, and Ali Tajer. Causal bandits with general causal models and interventions. In _Proc. International Conference on Artificial Intelligence and Statistics_, Valencia, Spain, May 2024.
* [19] Blair Bilodeau, Linbo Wang, and Daniel M Roy. Adaptively exploiting \(d\)-separators with causal bandits. In _Proc. Advances in Neural Information Processing Systems_, New Orleans, LA, December 2022.
* [20] Yangyi Lu, Amirhossein Meisami, and Ambuj Tewari. Causal bandits with unknown graph structure. In _Proc. Advances in Neural Information Processing Systems_, virtual, December 2021.
* [21] Arnoud De Kroon, Joris Mooij, and Danielle Belgrave. Causal bandits without prior knowledge using separating sets. In _Proc. Conference on Causal Learning and Reasoning_, Eureka, CA, April 2022.
* [22] Shi Feng, Nuoya Xiong, and Wei Chen. Combinatorial causal bandits without graph skeleton. In _Asian Conference on Machine Learning_, Hanoi, Vietnam, December 2023.
* [23] Mikhail Konobeev, Jalal Etesami, and Negar Kiyavash. Causal bandits without graph learning. _arXiv:2301.11401_.
* [24] Alan Malek, Virginia Aglietti, and Silvia Chiappa. Additive causal bandits with unknown graph. In _Proc. International Conference on Machine Learning_, Honolulu, Hawaii, July 2023.
* [25] Muhammad Qasim Elahi, Mahsa Ghasemi, and Murat Kocaoglu. Partial structure discovery is sufficient for no-regret learning in causal bandits. In _Proc. International Conference on Machine Learning Workshop on Foundations of Reinforcement Learning and Control-Connections and Perspectives_, Vienna, Austria, July 2024.
* [26] Zirui Yan, Arpan Mukherjee, Burak Varici, and Ali Tajer. Robust causal bandits for linear models. _IEEE Journal on Selected Areas in Information Theory_, 5:78-93, March 2024.
* [27] Zirui Yan, Arpan Mukherjee, Burak Varici, and Ali Tajer. Improved bound for robust causal bandits with linear models. In _Proc. IEEE International Symposium on Information Theory_, Athens, Greece, July 2024.
* [28] Hamish Flynn, David Reeb, Melih Kandemir, and Jan R Peters. Improved algorithms for stochastic linear bandits using tail bounds for martingale mixtures. In _Proc. Advances in Neural Information Processing Systems_, New Orleans, LA, December 2023.
* [29] Asish Ghoshal and Jean Honorio. Learning linear structural equation models in polynomial time and sample complexity. In _Proc. International Conference on Artificial Intelligence and Statistics_, Playa Blanca, Spain, April 2018.
* [30] Tor Lattimore and Csaba Szepesvari. _Bandit Algorithms_. Cambridge University Press, Cambridge, UK, 2020.
* [31] Varsha Dani, Thomas P Hayes, and Sham M Kakade. Stochastic linear optimization under bandit feedback. In _Proc. Conference on Learning Theory_, Helsinki, Finland, July 2008.
* [32] Yingkai Li, Yining Wang, and Yuan Zhou. Nearly minimax-optimal regret for linearly parameterized bandits. _IEEE Transactions on Information Theory_, 70(1):372-388, 2023.
* [33] Peter J Bickel, Ya'acov Ritov, and Alexandre B Tsybakov. Simultaneous analysis of lasso and dantzig selector. _Annals of Statistics_, 37(4):1705-1732, 2009.
* [34] Botao Hao, Tor Lattimore, and Mengdi Wang. High-dimensional sparse linear bandits. In _Proc. Advances in Neural Information Processing Systems_, Virtual, December 2020.

* [35] Martin J Wainwright. _High-dimensional statistics: A non-asymptotic viewpoint_, volume 48. Cambridge University Press, Cambridge, UK, 2019.
* [36] Adel Javanmard and Andrea Montanari. Confidence intervals and hypothesis testing for high-dimensional regression. _Journal of Machine Learning Research_, 15(1):2869-2909, 2014.
* [37] Peter Auer. Using confidence bounds for exploitation-exploration trade-offs. _Journal of Machine Learning Research_, 3(Nov):397-422, 2002.
* [38] Wei Chu, Lihong Li, Lev Reyzin, and Robert Schapire. Contextual bandits with linear payoff functions. In _Proc. International Conference on Artificial Intelligence and Statistics_, Ft. Lauderdale, FL, April 2011.

## Appendix A Empirical Evaluations

In this section, we assess the regret performance of GA-LCB. As the most relevant existing approaches, we compare the regret of our algorithm to those of LinSEM-UCB [15] and GCB-UCB [18], which are designed for causal bandits with soft interventions.

Causal graph.We consider the hierarchical graph illustrated in Figure 1. This graph consists of \((L+1)\) layers, with the first \(L\) layers having \(d\) nodes. The nodes between two adjacent layers are fully connected. The last layer consists of one node (reward node) that is fully connected to nodes in layer \(L\). The number of nodes in this graph is \(N=dL+1\).

Parameter setting.The noise terms \(\{\epsilon_{i}:i\in[N]\}\) are set to be drawn from the uniform distribution \(\mathsf{Unif}(0,1)\). We set the non-zero elements in the observational and interventional weights matrix to \(1\) and \(0.5\), respectively. We evaluate \(L\in\{2,4,6\}\). The experiment was conducted using 2 CPUs from Mac Mini 2023. We set \(T_{1}=T_{2}=500\) for experiments with \(L=2\), \(T_{1}=T_{2}=1000\) for experiments with \(L=4\) and \(L=6\).

Algorithm settings.The theoretical guarantees relied on specific technical conditions on parameters. We observe that the algorithms designed can provide better-than-foreseen empirical performance by tuning the parameters involved. Specifically, we adjusted the parameters \(\lambda\), \(\alpha\), and the sufficient exploration times \(T_{1}\) and \(T_{2}\). We observe that setting \(\lambda=\alpha=0.1\) yields reasonable performance. The experiments are repeated \(100\) times, and the average cumulative regret is reported.

Regret performance.In Figure 2, we present the cumulative regret of GA-LCB algorithm and other algorithms with the hierarchical graph with \(d=3\) and \(L=2\). LinSEM-UCB and GCB-UCB exhibit lower regret within the shown time horizon, while our algorithm (GA-LCB with known graph) shows a slightly higher regret. This difference is due to balancing a more precise confidence radius with enhanced scalability. Besides, we observe that GA-LCB incurs higher regret due to the structure learning phase. Since both LinSEM-UCB and GCB-UCB face computational challenges for scaling up to larger graphs, we evaluate the cumulative regret of GA-LCB under known and unknown graph

Figure 1: Example of hierarchical graph.

settings when the maximum causal depth is \(L=4\) in Figure 3 and \(L=6\) in Figure 4. We show the scalability of the GA-LCB algorithm. Besides, comparing the regret of known and unknown settings, we see the additional cost of structured learning is diminishing, which is desirable. The fluctuation of GA-LCB under the known graph setting is due to imperfect phased eliminations which remove the interventions with larger expected values first.

Scaling with \(L\):Scaling of the regret with respect to the causal depth \(L\) is depicted in Figure 6 for the setting of a hierarchical graph with \(d=2\) and \(L\) varying in the range \(\{1,\cdots,9\}\). The theoretical results (regret upper and lower bounds) predict that the regret grows at the rate \((2\kappa)^{L}\) (i.e., exponential in \(L\)). The empirical results in Figure 6 corroborate that the cumulative regret scales exponentially with length \(L\), and the actual regret closely tracks the upper bound's trend.

Scaling with \(d\):Scaling of the regret with respect to the maximum in-degree \(d\) is depicted in Figure 6 for a hierarchical graph with \(L=2\). We increase the number of sufficient exploration parameters \(T_{1}\) and \(T_{2}\) to ensure we accommodate all settings with different degrees. The theoretical predictions suggest that our algorithm's regret scales as \(d^{3/2}\) (i.e., polynomial \(d\)). Figure 6 demonstrates that our regret is super-linear and tracks the polynomial trend of the regret upper bound (i.e., the achievable regret).

Computational time.In Figure 7, we compare the running times of different algorithms under the two settings mentioned above. The figure indicates that our proposed algorithm significantly reduces computational time in the hierarchical graph with \(L=2\) when compared with LinSEM-UCB and GCB-UCB. In the hierarchical graph with \(L=4\), which is considered sufficiently large in the related studies, the GA-LCB still demonstrates a notable stronger running time.

Figure 5: Cumulative regret with different length \(L\) under hierarchical graph with \(d=2\). Figure 6: Cumulative regret with different degree \(d\) under hierarchical graph with \(L=2\).

Additional Notations

In this section, we present the notations that will be useful in our analyses. We denote the singular values of a matrix \(\mathbf{A}\in\mathbb{R}^{M\times N}\) with \(M\geq N\) in the descending order by

\[\sigma_{1}(\mathbf{A})\geq\sigma_{2}(\mathbf{A})\geq\cdots\geq\sigma_{N}( \mathbf{A})\;.\] (32)

In the proofs, the analyses often involve with zero-padded vectors and their corresponding matrices (e.g., \(X_{\mathbf{pa}(i)}\) and \(\mathbf{V}_{i,a_{i}(t)}\)). Consequently, these matrices have non-trivial _null spaces_, resulting in zero singular values. In such instances, we are interested in the _effective_ smallest singular values that are non-zero. We denote the _effective_ largest and smallest eigenvalues, which correspond to the effective dimensions of a positive semidefinite matrix \(\mathbf{A}\) with rank \(k\), by

\[\sigma_{\max}\left(\mathbf{A}\right)\triangleq\sigma_{1}(\mathbf{A})\;,\quad \text{and}\quad\sigma_{\min}\left(\mathbf{A}\right)\triangleq\sigma_{k}( \mathbf{A})\;.\] (33)

For a square matrix \(\mathbf{U}=\mathbf{A}\mathbf{A}^{\top}\in\mathbb{R}^{N\times N}\), we denote the _effective_ largest and smallest eigenvalues by2

Footnote 2: For matrix \(\mathbf{V}=\mathbf{U}+\mathbf{I}\), we denote the _effective_ smallest eigenvalues by \(\lambda_{\min}\left(\mathbf{V}\right)\triangleq\sigma_{\min}^{2}(\mathbf{A})+1\).

\[\lambda_{\max}\left(\mathbf{U}\right)\triangleq\sigma_{\max}^{2}(\mathbf{A}) \;,\quad\text{and}\quad\lambda_{\min}\left(\mathbf{U}\right)\triangleq\sigma_ {\min}^{2}(\mathbf{A})\;.\] (34)

Then we construct data matrices that are related to gram matrices. At time \(t\in\mathbb{N}\) and for any node \(i\in[N]\), the data matrices \(\mathbf{U}_{i}(t)\in\mathbb{R}^{t\times N}\) and \(\mathbf{U}_{i}^{*}(t)\in\mathbb{R}^{t\times N}\) consist of the weighted observational and interventional data, respectively. Specifically, for any \(\tau\in[t]\) and \(i\in[N]\), we define

\[\left[\mathbf{U}_{i}^{\top}(t)\right]_{\tau} \triangleq\ \mathds{1}\{a_{i}(\tau)=0\}X_{\hat{\mathbf{pa}}(i)}^{\top}(\tau)\;,\] (35) \[\text{and}\quad\left[\mathbf{U}_{i}^{*\top}(t)\right]_{\tau} \triangleq\ \mathds{1}\{a_{i}(\tau)=1\}X_{\hat{\mathbf{pa}}(i)}^{\top}(\tau)\;.\] (36)

We also define the observation matrix that is used for Lasso estimator \(\mathbf{U}_{i,\hat{\mathbf{an}}(i)}(t)\in\mathbb{R}^{t\times N}\) that stores the observational data on the ancestor's set.

\[[\mathbf{U}_{i,\hat{\mathbf{an}}(i)}^{\top}(t)]_{\tau}=\mathds{1}\{\mathbf{a }(\tau)=\emptyset\}X_{\hat{\mathbf{an}}(i)}^{\top}(\tau)\;.\] (37)

We also define the data vector \(\mathbf{D}_{i}(t)\in\mathbb{R}^{t}\) and \(\mathbf{D}_{i}^{*}(t)\in\mathbb{R}^{t}\) as

\[\left[\mathbf{D}_{i}(t)\right]_{\tau} \triangleq\ \mathds{1}\{a_{i}(\tau)=0\}(X_{i}(\tau)-\nu_{i})\;,\] (38) \[\text{and}\quad\left[\mathbf{D}_{i}^{*}(t)\right]_{\tau} \triangleq\ \mathds{1}\{a_{i}(\tau)=1\}(X_{i}(\tau)-\nu_{i})\;.\] (39)

Similarly to (2), we denote the relevant data matrices for node \(i\in[N]\) under intervention \(\mathbf{a}\in\mathcal{A}\) by

\[\mathbf{U}_{i,a_{i}}(t) \triangleq\ \mathds{1}\{a_{i}(t)=1\}\mathbf{U}_{i}^{*}(t)+\mathds{1} \{a_{i}(t)=0\}\mathbf{U}_{i}(t)\;,\] (40) \[\mathbf{V}_{i,a_{i}}(t) \triangleq\ \mathds{1}\{a_{i}(t)=1\}\mathbf{V}_{i}^{*}(t)+\mathds{1} \{a_{i}(t)=0\}\mathbf{V}_{i}(t)\;.\] (41) \[\mathbf{D}_{i,a_{i}}(t) \triangleq\ \mathds{1}\{a_{i}(t)=1\}\mathbf{D}_{i}^{*}(t)+\mathds{1} \{a_{i}(t)=0\}\mathbf{D}_{i}(t)\;.\] (42)

Define \(N_{i}^{*}(t)\) as the number of times that node \(i\in[N]\) is intervened, and \(N_{i}(t)\) as its complement

\[N_{i}^{*}(t) \triangleq\ \sum_{\tau=1}^{t}\mathds{1}\{a_{i}(\tau)=1\}\;,\] (43) \[\text{and}\quad N_{i}(t) \triangleq\ t-N_{i}^{*}(t)\;.\] (44)

Accordingly, for any \(i\in[N]\) and \(t\in\mathbb{N}\), define

\[N_{i,a_{i}}(t)\triangleq\mathds{1}\{a_{i}(t)=1\}N_{i}^{*}(t)+\mathds{1}\{a_{ i}(t)=0\}N_{i}(t)\;,\] (45)

For \(\mathbf{a}\in\mathcal{A}\), we define the pseudo estimated variables \(\widehat{X}_{\mathbf{a}}(t)\) and pseudo underground variables \(X_{\mathbf{a}}(t)\) is the random variable at time \(t\) generated according to the following linear SEMs

\[\widehat{X}_{\mathbf{a}}(t) =\mathbf{B}_{\mathbf{a}}^{\top}(t)\widehat{X}_{\mathbf{a}}(t)+ \epsilon(t)\;,\] (46) \[\text{and}\quad X_{\mathbf{a}}(t) =\mathbf{B}_{\mathbf{a}}^{\top}X_{\mathbf{a}}(t)+\epsilon(t)\;,\] (47)which share the same \(\epsilon(t)\) accorss the different interventions.

Finally, let us denote the second moment of the parents of a node \(i\) under intervention \(\mathbf{a}\in\mathcal{A}\) with unknown weight matrices \(\mathbf{B}\) and \(\mathbf{B}^{*}\) by

\[\widetilde{\Sigma}_{i,\mathbf{a}}\ \triangleq\ \mathbb{E}_{\mathbf{a}}\left[X_{ \widehat{\mathsf{a}}\widehat{\mathsf{n}}(i)}X_{\widehat{\mathsf{a}}\widehat{ \mathsf{n}}(i)}^{\top}\right].\] (48)

Accordingly, we denote the lower and upper bounds on the minimum and maximum singular values of these moments by

\[\tilde{\kappa}_{i,\mathbf{a},\min}\triangleq\sigma_{\min}\left( \widetilde{\Sigma}_{i,\mathbf{a}}\right),\quad\tilde{\kappa}_{\min} \triangleq\min_{i\in[N]}\tilde{\kappa}_{i,\emptyset,\min},\] (49) \[\tilde{\kappa}_{i,\mathbf{a},\max}\triangleq\sigma_{\max}\left( \widetilde{\Sigma}_{i,\mathbf{a}}\right),\quad\tilde{\kappa}_{\max} \triangleq\min_{i\in[N]}\tilde{\kappa}_{i,\emptyset,\max}.\] (50)

We note due to the Cauchy interlacing theorem, we have

\[\kappa_{\min}\leq\tilde{\kappa}_{\min}\leq\tilde{\kappa}_{\max}\leq\kappa_{ \max}\.\] (51)

Finally, we use \(\Delta(\mathbf{x})\) to represent the diagonal matrix with elements in \(\mathbf{x}\).

## Appendix C Decomposition of Node-level Rewards

Similar to [15, Lemma 1], we present the following decomposition for the expected value of the variable \(X_{i}\) for \(i\in[N]\). We note our design of the mean value estimator in (17) based on this lemma.

**Lemma 1**.: _Given intervention \(\mathbf{a}\in\mathcal{A}\), the value of node \(X_{i}\) is related to the noise vector \(\epsilon\) via \(X_{i}=\left\langle f_{i}(\mathbf{B}_{\mathbf{a}}),\ \epsilon\right\rangle\), where \(f_{i}(\mathbf{B}_{\mathbf{a}})\triangleq\sum_{\ell=0}^{L_{i}}\left[\mathbf{B }_{\mathbf{a}}^{\ell}\right]_{i}\). Consequently, the expected value of \(X_{i}\) under intervention \(\mathbf{a}\) is_

\[\mu_{i,\mathbf{a}}\ =\ \left\langle f_{i}(\mathbf{B}_{\mathbf{a}}),\ \boldsymbol{\nu}\right\rangle\.\] (52)

Proof.: To capture the contribution of \(\epsilon_{j}\) on node \(i\), we use the fact that the entry at row \(j\) and column \(i\) of \(\mathbf{B}_{\mathbf{a}}^{\ell}\) is the sum aggregate of the weight products along all paths from node \(j\) to node \(i\) that have the exact length \(\ell\). Since the longest length will be \(L_{i}\), the term \(\sum_{\ell=1}^{L_{i}}[\mathbf{B}_{\mathbf{a}}]_{j,i}\) becomes the aggregated sum of weight products along all paths from node \(j\) to node \(i\) regardless of path length. We denote this sum by

\[f_{i}\left(\mathbf{B}_{\mathbf{a}}\right)\triangleq\sum_{\ell=0}^{L_{i}} \left[\mathbf{B}_{\mathbf{a}}^{\ell}\right]_{i}\.\] (53)

We note that the noise \(\epsilon\) at any time \(t\) is independent of the process that decides \(\mathbf{B}_{\mathbf{a}}\). Therefore, the expected value of \(X_{i}\) under intervention \(\mathbf{a}\) is

\[\mu_{i,\mathbf{a}}=\mathbb{E}_{\mathbf{a}}\left[X_{i}\right]=\mathbb{E}\left[ \sum_{\ell=0}^{L_{i}}\left\langle\left[\mathbf{B}_{\mathbf{a}}^{\ell}\right]_{ i},\epsilon\right\rangle\right]=\left\langle f_{i}\left(\mathbf{B}_{ \mathbf{a}}\right),\boldsymbol{\nu}\right\rangle\.\] (54)

## Appendix D Proof of Theorem 1 (Structure Learning)

The proof is divided into two parts. First, we show that \(T_{1}=\frac{32m^{2}}{\eta^{2}}\log(\frac{2N^{2}}{\delta})\) is sufficient to identify the ancestors sets and a valid topological ordering with probability at least \(1-\delta\). Subsequently, we show that with a probability of at least \(1-\delta\), Lasso regression yields the desired estimates for the parent sets.

**Part 1: topological ordering.** In this part, we show that \(\mathsf{de}(i)\subseteq\widehat{\mathsf{de}}(i)\). Based on this, we will see an efficient topological ordering would be natural. Recall the definition of \(\widehat{\mathsf{de}}(i)\) and \(\widehat{\mathsf{an}}(i)\) in (8) and (9), respectively, it is equivalent to show that for \(i\in[N]\) with \(L_{i}\geq 1\) all \(j\in\mathsf{de}(i)\), we have \(|\hat{\mu}_{j,\emptyset}-\hat{\mu}_{j,\{i\}}|>\frac{\eta}{2}\) and for all \(j\in\mathsf{an}(i)\), we have \(|\hat{\mu}_{j,\emptyset}-\hat{\mu}_{j,\{i\}}|\leq\frac{\eta}{2}\).

We note that the bounded noises that satisfy Assumption 4 are \(1\)-sub-Gaussian. After sufficient exploration, the mean estimators \(\hat{\mu}_{j,\emptyset}\) and \(\hat{\mu}_{j,\emptyset}\) defined in (6) will be close enough to the true means\(\mu_{j,\emptyset}\) and \(\mu_{j,\emptyset}\) with high probability, respectively. When the mean estimates are accurate enough, based on Assumption 5, we show that \(\frac{\eta}{2}\) can be used to separate descendants from non-descendants based on the value of \(|\hat{\mu}_{j,\emptyset}-\hat{\mu}_{j,[i]}|\). Based on the definition of \(\hat{\mu}_{j,\emptyset}\) and \(\hat{\mu}_{j,\emptyset}\) in (6), we have

\[\mathbb{P}\Big{(}|\hat{\mu}_{j,\emptyset}-\mu_{j,\emptyset}|\geq \frac{\eta}{4}\Big{)} =\mathbb{P}\Big{(}|\hat{\mu}_{j,\emptyset}-\mu_{j,\emptyset}|\geq \frac{\eta}{4}\Big{)}\] (55) \[\leq 2\exp\bigg{(}-\frac{2T_{1}\frac{\eta^{2}}{16}}{4m^{2}}\bigg{)}\] (56) \[=\frac{\delta}{N^{2}}\,\] (57)

where (55) holds because Hoeffding's inequality and (57) holds since the definition of \(T_{1}\) in (12).

Similarly, we have

\[\mathbb{P}\Big{(}|\hat{\mu}_{j,\{i\}}-\mu_{j,\{i\}}|\geq\frac{\eta}{4}\Big{)} \leq\frac{\delta}{2N^{2}}\.\] (58)

We define error events in which the mean estimates have a large error as follows.

\[\mathcal{E}_{\text{TO}}\triangleq\Big{\{}|\hat{\mu}_{j,\emptyset}-\mu_{j, \emptyset}|\leq\frac{\eta}{4}\ \text{ and }\ |\hat{\mu}_{j,\{i\}}-\mu_{j,\{i\}}|\leq\frac{\eta}{4},\quad\forall j \in[N],i\in[N-1]\Big{\}}\.\] (59)

By taking a union bound and leveraging (57)-(58), we obtain

\[\mathbb{P}(\mathcal{E}_{\text{TO}})\leq N^{2}\times\frac{\delta}{N^{2}}= \delta\.\] (60)

Next, we prove that under event \(\mathcal{E}_{\text{TO}}^{\text{c}}\), we can correctly identify \(\mathsf{de}(i)\) for all node \(i\in[N]\). If \(j\in\mathsf{de}(i)\), to evaluate the gap \(|\hat{\mu}_{j,\emptyset}-\hat{\mu}_{j,\{i\}}|\), we leverage the following relationship:

\[|\mu_{j,\emptyset}-\mu_{j,\{i\}}| =|(\hat{\mu}_{j,\emptyset}-\hat{\mu}_{j,\{i\}})+(\mu_{j,\emptyset }-\hat{\mu}_{j,\emptyset})+(\mu_{j,\{i\}}-\hat{\mu}_{j,\{i\}})|\] (61) \[\leq|\hat{\mu}_{j,\emptyset}-\hat{\mu}_{j,\{i\}}|+|\mu_{j, \emptyset}-\hat{\mu}_{j,\emptyset}|+|\mu_{j,\{i\}}-\hat{\mu}_{j,\{i\}}|\,\] (62)

where (62) is due to the triangle inequality. Thus, for all \(i\in[N-1]\) and \(j\in\mathsf{de}(i)\) we have

\[|\hat{\mu}_{j,\emptyset}-\hat{\mu}_{j,\{i\}}| \geq|\mu_{j,\emptyset}-\mu_{j,\{i\}}|-|\hat{\mu}_{j,\emptyset}- \mu_{j,\emptyset}|-|\hat{\mu}_{j,\{i\}}-\mu_{j,\{i\}}|\] (63) \[\stackrel{{\eqref{eq:2}}}{{>}}\eta-\frac{\eta}{4}- \frac{\eta}{4}\] (64) \[=\frac{\eta}{2}\.\] (65)

On the other hand, when \(j\not\in\mathsf{de}(i)\), we have \(\mu_{j,\emptyset}=\mu_{j,\{i\}}\), based on which we obtain

\[|\hat{\mu}_{j,\emptyset}-\hat{\mu}_{j,\{i\}}| =|\hat{\mu}_{j,\emptyset}-\mu_{j,\emptyset}+\hat{\mu}_{j,\{i\}}- \mu_{j,\{i\}}|\] (66) \[\leq|\hat{\mu}_{j,\emptyset}-\mu_{j,\emptyset}|+|\hat{\mu}_{j,\{ i\}}-\mu_{j,\{i\}}|\] (67) \[\stackrel{{\eqref{eq:3}}}{{\leq}}\eta/2\.\] (68)

In conclusion, with probability \(1-\delta\), the estimates of descendants sets \(\widehat{\mathsf{de}}(i)=\mathsf{de}(i)\) for node \(i\in[N]\) with \(L_{i}>0\) with probability at least \(1-\delta\). Hence, with probability at least \(1-\delta\) the \(\widehat{\mathsf{an}}(i)\) defined in (9) will be the best set we can find, that is \(\widehat{\mathsf{an}}(i)\subseteq\mathsf{an}(i)\) for \(i\in[N]\) and for \(i\in\widehat{\mathsf{an}}(i)\setminus\mathsf{an}(i)\), we can infer that \(i\) is a root node. Besides, the topological ordering \(\hat{\pi}\) is valid.

**Part 2: Lasso regression.** In this part, we establish a sparsity property of the Lasso estimator in linear causal bandit, which is inspired by [33] and [34]. We consider the case when \(T_{2}\geq T_{1}\). The case for \(T_{2}<T_{1}\) can be analyzed similarly. We prove for fixed \(i\in[N]\) as it is the same for all \(i\in[N]\). When the ancestors sets and topological ordering are correct with probability at least \(1-\delta\) from Part 1. We define the time instance \(T_{3}=NT_{1}+T_{2}-T_{1}\) be the time that the Lasso estimators are calculated.

We show that when \(T_{2}\gtrsim d\log(N)\) and when ancestors sets and topological ordering are correct, with probability at least \(1-\delta\), the Lasso estimates satisfy the desired property. The proof consists of three steps. In the first step, we show that the Lasso estimates provide a bounded cardinality,that is for \(i\in[N]\) we have \(|\widehat{\mathsf{a}}(i)|\leq\kappa|\mathsf{pa}(i)|\). his step involves first bounding the support of the Lasso estimator by the empirical error, followed by bounding the empirical error itself. In the second step, we prove by contradiction that for \(i\in[N]\) we prove \(|\mathsf{pa}(i)\subseteq|\widehat{\mathsf{pA}}(i)|\). Finally, we take a union bounds on all nodes \(i\in[N]\) to get the desired result.

_Step 1: Bounded cardinality._ In this step we show \(|\widehat{\mathsf{pA}}(i)|\leq\kappa|\mathsf{pa}(i)|\). Recall that the Lasso estimator in the feature selection stage is defined as

\[[\widehat{\mathbf{B}}^{\text{Lasso}}]_{i}\ \triangleq\ \underset{\theta\in\mathbb{R}^{| \widehat{\mathsf{a}}(i)|}}{\mathrm{argmin}}\bigg{(}\frac{1}{N_{\emptyset}(t)} \sum_{\tau\in[t],\mathbf{a}(\tau)=\emptyset}\big{(}X_{i}(\tau)-\theta^{\top}X_{ \widehat{\mathsf{a}}\mathsf{n}(i)}(\tau)\big{)}^{2}+\lambda_{i}\|\theta\|_{1 }\bigg{)}.\] (69)

We state some preliminary properties of the Lasso estimator and later show that our estimator satisfies the conditions for these properties.

**Property 1** (Restricted eigenvalues).: _Let \(\mathcal{S}\triangleq\mathrm{supp}([\mathbf{B}]_{i})\), define the cone_

\[\mathcal{C}(S)\ \triangleq\ \big{\{}\theta\in\mathbb{R}^{N}\mid\mathrm{ supp}(\theta)=\widehat{\mathsf{a}}(i),\left\|\theta_{\mathcal{S}^{c}}\right\|_{1} \leq 3\left\|\theta_{\mathcal{S}}\right\|_{1}\big{\}}\.\] (70)

_Then for all \(\theta\in\mathbb{C}(S)\), there exists some positive constant \(\kappa^{\prime}\) such that the observation matrix \(\mathbf{U}_{i,\widehat{\mathsf{a}}\mathsf{n}(i)}(t)\in\mathbb{R}^{t\times| \widehat{\mathsf{a}}\mathsf{n}(i)|}\) satisfies the condition_

\[\frac{\|\mathbf{U}_{i,\widehat{\mathsf{a}}\mathsf{n}(i)}(t)\theta\|_{2}^{2}}{ t}\geq\kappa^{\prime}\|\theta\|_{2}^{2}\.\] (71)

**Property 2** (Column normalized).: _We say that \(\mathbf{U}_{i,\widehat{\mathsf{a}}\mathsf{n}(i)}(t)\) is column-normalized if_

\[\frac{\left\|[\mathbf{U}_{i,\widehat{\mathsf{a}}\mathsf{n}(i)}(t)]_{j}\right\| _{2}}{\sqrt{t}}\leq m\,\quad\forall j\in\widehat{\mathsf{pA}}(i)\.\] (72)

**Lemma 2**.: _Consider a \(d\)-sparse linear regression and assume that design matrix \(\mathbf{U}_{i,0}(t)\in\mathbb{R}^{t\times|\widehat{\mathsf{a}}\mathsf{n}(i)|}\) satisfies Properties 1-2. Given the Lasso estimator with regularization parameter \(\lambda=4m\sqrt{\log(|\widehat{\mathsf{a}}\mathsf{n}(i)|)/t}\), then the following properties hold with probability at least \(1-\delta\)._

* _The estimation error under_ \(\ell_{1}\)_-norm of any optimal solution_ \([\widehat{\mathbf{B}}^{\text{Lasso}}]_{i}\) _satisfies_ _[_35_, Theorem_ 7.13_]__:_ \[\left\|[\widehat{\mathbf{B}}^{\text{Lasso}}]_{i}-[\mathbf{B}]_{i}\right\|_{1} \leq\frac{d}{\kappa^{\prime}}\sqrt{\frac{2\log(2|\widehat{\mathsf{a}} \mathsf{n}(i)|/\delta)}{t}}\.\] (73)
* _The mean square prediction error of any optimal solution_ \([\widehat{\mathbf{B}}^{\text{Lasso}}]_{i}\) _satisfies_ _[_35_, Theorem_ 7.20_]__:_ \[\frac{1}{t}\sum_{s=1}^{t}\left(X_{\widehat{\mathsf{a}}\mathsf{n}(i)}^{\top}(s )\left([\widehat{\mathbf{B}}^{\text{Lasso}}]_{i}-[\mathbf{B}]_{i}\right) \right)^{2}\leq\frac{9}{\kappa^{\prime}}\cdot\frac{d\log(|\widehat{\mathsf{a} }\mathsf{n}(i)|/\delta)}{t}\.\] (74)

For \(j\in\widehat{\mathsf{n}}(i)\) define the random variables

\[b_{i,j}\triangleq\frac{1}{N_{\emptyset}(t)}\sum_{\tau\in[T_{3}],\mathbf{a}( \tau)=\emptyset}X_{j}(t)\left(\epsilon_{i}(t)-\nu_{i}\right)\.\] (75)

Since \(\left\|X_{\widehat{\mathsf{a}}\mathsf{n}(i)}(t)\right\|_{\infty}\leq m\), the Hoeffding's inequality for sub-Gaussian random variables implies

\[\mathbb{P}\bigg{(}\Big{|}\sum_{\tau\in[T_{3}],\mathbf{a}(\tau)=\emptyset}X_{j }(t)\left(\epsilon_{i}(t)-\nu_{i}\right)\Big{|}\geq\zeta\bigg{)}\leq 2\exp \left(-\frac{\zeta^{2}}{2N_{\emptyset}(t)m^{2}}\right).\] (76)

We note that content we have \(N_{\emptyset}(t)=T_{2}\). For \(j\in[N]\), define \(\mathcal{E}_{g_{j}}\) as the event that \(g_{j}\) is contained in the interval close to mean value, i.e.,

\[\mathcal{E}_{b_{i,j}}=\left\{|b_{i,j}|\leq\sqrt{\frac{2m^{2}\log\left(\frac{4N |\widehat{\mathsf{a}}\mathsf{n}(i)|}{\delta}\right)}{T_{2}}}\right\}\.\] (77)Based on the probability bounds in (76), we have

\[\mathbb{P}(\mathcal{E}_{b_{i,j}})\leq\frac{\delta}{2N|\hat{\mathfrak{a}}\hat{n}(i) |}\;.\] (78)

Accordingly, define

\[\mathcal{E}_{b_{i}}=\bigcup_{j\in\mathfrak{a}\hat{n}(i)}\mathcal{E}_{b_{i,j}}\;.\] (79)

By taking a union bound and leveraging (78), we obtain

\[\mathbb{P}\left(\mathcal{E}_{b_{i}}^{\mathrm{c}}\right)\leq\sum_{j\in\hat{ \mathfrak{a}}\hat{n}(i)}\mathbb{P}\left(\mathcal{E}_{b_{i,j}}^{\mathrm{c}} \right)\leq|\hat{\mathfrak{a}}\hat{n}(i)|\times\frac{\delta}{2N|\hat{ \mathfrak{a}}\hat{n}(i)|}\leq\frac{\delta}{2N}\;.\] (80)

From the Karush-Kuhn-Tucker (KKT) condition of Lasso regression, the solution \([\hat{\mathbf{B}}^{\mathrm{Lasso}}]_{i}\) satisfies

\[\frac{1}{T_{2}}\sum_{\tau\in[T_{3}],\mathfrak{a}(\tau)=\emptyset }X_{j}(t)\left(X_{i}(t)-[\widehat{\mathbf{B}}^{\mathrm{Lasso}}]_{i}^{\top}X_{ \hat{\mathfrak{a}}(i)}(t)\right)=\lambda\,\mathrm{sign}\left([\widehat{ \mathbf{B}}^{\mathrm{Lasso}}]_{i}\right),\] (81) \[\left|\frac{1}{T_{2}}\sum_{\tau\in[t],\mathfrak{a}(\tau)=\emptyset }X_{j}(t)\left(X_{i}(t)-[\widehat{\mathbf{B}}^{\mathrm{Lasso}}]_{i}^{\top}X_{ \hat{\mathfrak{a}}(i)}(t)\right)\right|\leq\lambda,\] if \[[\widehat{\mathbf{B}}^{\mathrm{Lasso}}]_{i,j}=0\;.\] (82)

Therefore, we have

\[\frac{1}{T_{2}}\sum_{\tau\in[t],\mathfrak{a}(\tau)=\emptyset}X_{j} (t)\left([\mathbf{B}]_{i}^{\top}X_{\mathfrak{pa}(i)}(t)-[\widehat{\mathbf{B} }^{\mathrm{Lasso}}]_{i}^{\top}X_{\mathfrak{pa}(i)}(t)\right)\] \[=\frac{1}{T_{2}}\sum_{\tau\in[t],\mathfrak{a}(\tau)=\emptyset}X_{j }(t)\left(X_{i}(t)-[\widehat{\mathbf{B}}^{\mathrm{Lasso}}]_{i}^{\top}X_{ \mathfrak{pa}(i)}(t)\right)-\frac{1}{T_{2}}\sum_{\tau\in[t],\mathfrak{a}(\tau) =\emptyset}X_{j}(t)\epsilon_{i}(t)\;.\] (83)

Since \(\lambda=m\sqrt{\frac{2\log\left(\frac{4N|\hat{\mathfrak{a}}(i)|}{\delta} \right)}{T_{2}}}\), under event \(\mathcal{E}_{g_{i}}\), we have

\[\left|\frac{1}{T_{2}}\sum_{\tau\in[T_{3}],\mathfrak{a}(\tau)=\emptyset}X_{j}(t )\left([\mathbf{B}]_{i}^{\top}X_{\mathfrak{pa}(i)}(t)-[\widehat{\mathbf{B}}^{ \mathrm{Lasso}}]_{i}^{\top}X_{\mathfrak{pa}(i)}(t)\right)\right|\geq\lambda/2, \;\mathrm{if}\;[\widehat{\mathbf{B}}^{\mathrm{Lasso}}]_{j,i}\neq 0\;.\] (84)

Based on (84), we can have the following lower bound

\[\frac{1}{T_{2}^{2}}\sum_{j\in\hat{\mathfrak{a}}\hat{n}(i)}\left( \sum_{\tau\in[T_{3}],\mathfrak{a}(\tau)=\emptyset}X_{j}(t)\left([\mathbf{B}]_ {i}^{\top}X_{\mathfrak{pa}(i)}(t)-[\widehat{\mathbf{B}}^{\mathrm{Lasso}}]_{i }^{\top}X_{\mathfrak{pa}(i)}(t)\right)\right)^{2}\] \[\geq\sum_{j\in\mathrm{supp}([\mathbf{B}^{\mathrm{Lasso}}]_{i})} \left(\frac{1}{T_{2}}\sum_{\tau\in[T_{3}],\mathfrak{a}(\tau)=\emptyset}X_{j}(t )\left([\mathbf{B}]_{i}^{\top}X_{\mathfrak{pa}(i)}(t)-[\widehat{\mathbf{B}}^ {\mathrm{Lasso}}]_{i}^{\top}X_{\mathfrak{pa}(i)}(t)\right)\right)^{2}\] (85) \[\geq\frac{\lambda^{2}}{4}\left|\mathrm{supp}\left([\widehat{ \mathbf{B}}^{\mathrm{Lasso}}]_{i}\right)\right|\;,\] (86)

where (85) holds since \(\hat{\mathfrak{a}}\hat{n}(i)\subseteq\mathrm{supp}([\mathbf{B}^{\mathrm{ Lasso}}]_{i})\) and (86) holds due to (84). On the other hand, define the uncentered empirical covariance matrix as

\[\widehat{\Sigma}_{i}=\frac{1}{T_{2}}\mathbf{U}_{i,\hat{\mathfrak{a}}\hat{n}(i )}^{\top}(T_{3})\mathbf{U}_{i,\hat{\mathfrak{a}}\hat{n}(i)}(T_{3})\;.\] (87)

Let \(\hat{\kappa}_{i,\max}=\sigma_{\max}\left(\widehat{\Sigma}_{i}\right)\). Then we have

\[\hat{\kappa}_{i,\max}=\sigma_{\max}\left(\mathbf{U}_{i,\hat{\mathfrak{a}}\hat{ n}(i)}^{\top}(T_{3})\mathbf{U}_{i,\hat{\mathfrak{a}}\hat{n}(i)}(T_{3})/T_{2} \right)=\frac{1}{T_{2}}\sigma_{\max}\left(\mathbf{U}_{i,\hat{\mathfrak{a}}\hat{ n}(i)}^{\top}(T_{3})\mathbf{U}_{i,\hat{\mathfrak{a}}\hat{n}(i)}(T_{3})\right)\;.\] (88)

Now we need a high probability bound for \(\phi_{\max}\). In order to proceed, we need upper and lower bounds for the maximum and minimum singular values of \(\mathbf{U}_{i,\hat{\mathfrak{a}}\hat{n}(i)}(t)\). However, these bounds depend on the number of non-zero rows of \(\mathbf{U}_{i,\widehat{\mathfrak{m}}(i)}(t)\) matrices, which equals to value of the random variable \(N_{i,a(t)}(t)\). Let us define the weighted constant

\[\gamma_{n}\triangleq\max\left\{\eta m^{2}\sqrt{T_{2}},\eta^{2}m^{2}\right\}\;.\] (89)

We define the error events corresponding to the maximum and minimum singular values of \(\mathbf{U}_{i,\widehat{\mathfrak{m}}(i)}(t)(T_{3})\) as follows.

\[\mathcal{E}_{i}\triangleq \bigg{\{}\sigma_{\min}\left(\mathbf{U}_{i,\widehat{\mathfrak{m}}( i)}(T_{3})\right)\leq\sqrt{\max\big{\{}0,T_{2}\bar{\kappa}_{i,\emptyset,\min}- \gamma_{n}\big{\}}}.\] \[\text{or}\;\sigma_{\max}\left(\mathbf{U}_{i,\widehat{\mathfrak{ m}}(i)}(t)\right)\geq\sqrt{T_{2}\bar{\kappa}_{i,\emptyset,\max}+\gamma_{n}} \bigg{\}}\;,\] (90)

**Lemma 3**.: _[_15_, Lemma 8]_ _The probability of the error events \(\mathcal{E}_{i}(t)\) are upper bounded as_

\[\mathbb{P}(\mathcal{E}_{i}(t))\leq d\exp\left(-\frac{3\eta^{2}}{16}\right)\;.\] (91)

Thus, by setting \(\eta=\sqrt{\frac{16}{3}\log\big{(}\frac{2dN}{\delta}\big{)}}\), we have with probability \(1-\frac{\delta}{2N}\) we have

\[\sigma_{\max}\left(\mathbf{U}_{i,\widehat{\mathfrak{m}}(i)}(t)\right)<\sqrt{ T_{2}\bar{\kappa}_{i,\emptyset,\max}+\gamma_{n}}\;.\] (92)

Hence, with probability \(1-\delta\) we have

\[\hat{\kappa}_{i,\max} =\sigma_{\max}\left(\mathbf{U}_{i,\widehat{\mathfrak{m}}(i)}^{ \top}\mathbf{U}_{i,\widehat{\mathfrak{m}}(i)}/T_{2}\right)\] (93) \[=\frac{1}{T_{2}}\sigma_{\max}\left(\mathbf{U}_{i,\widehat{ \mathfrak{m}}(i)}^{\top}\mathbf{U}_{i,\widehat{\mathfrak{m}}(i)}\right)\] (94) \[<\bar{\kappa}_{i,\emptyset,\max}+\frac{\gamma_{n}}{T_{2}}\] (95) \[<\kappa_{\max}+\frac{\max\big{\{}\alpha m^{2}\sqrt{T_{2}},\alpha^ {2}m^{2}\big{\}}}{T_{2}}\] (96) \[=\kappa_{\max}+m^{2}\max\left\{\sqrt{\frac{16}{3T_{2}}\log\Big{(} \frac{2dN}{\delta}\Big{)}},\frac{16}{3T_{2}}\log\Big{(}\frac{2dN}{\delta} \Big{)}\right\}\] (97) \[=\kappa_{\max}+m^{2}\sqrt{\frac{16}{3T_{2}}\log\Big{(}\frac{2dN}{ \delta}\Big{)}}\;,\] (98)

where we use (92) in (95) and the last inequality is due to \(T_{2}\gtrsim d\log(N)\). Since \(\kappa_{i,\max}\) has the natural upper bound \(m^{2}\), we define

\[\kappa_{0}\triangleq\min\left\{m^{2},\kappa_{\max}+m^{2}\sqrt{\frac{16}{3T_{2 }}\log\Big{(}\frac{2dN}{\delta}\Big{)}}\right\}.\] (99)

Combined with (98) we know that

\[\bar{\kappa}_{i,\max}\leq\kappa_{0}\;,\] (100)

based on which we have

\[\frac{1}{T_{2}^{2}}\sum_{j\in\widehat{\mathfrak{m}}(i)}\left(\sum _{\tau\in[T_{3}],\mathfrak{a}(\tau)=\emptyset}X_{j}(t)\left([\mathbf{B}]_{i}^ {\top}X_{\mathfrak{p}\mathfrak{a}(i)}(t)-[\widehat{\mathbf{B}}^{\text{Lass}}]_ {i}^{\top}X_{\mathfrak{p}\mathfrak{a}(i)}(t)\right)\right)^{2}\] (101) \[= \frac{1}{T_{2}^{2}}\big{(}\mathbf{U}_{i,\widehat{\mathfrak{m}}(i) }(T_{3})[\mathbf{B}]_{i}-\mathbf{U}_{i,\widehat{\mathfrak{m}}(i)}(T_{3})[ \widehat{\mathbf{B}}^{\text{Lass}}]_{i}\big{)}^{\top}\mathbf{U}_{i,\widehat{ \mathfrak{m}}(i)}(T_{3})\mathbf{U}_{i,\widehat{\mathfrak{m}}(i)}^{\top}(T_{3})\] \[\quad\times\big{(}\mathbf{U}_{i,\widehat{\mathfrak{m}}(i)}(T_{3})[ \mathbf{B}]_{i}-\mathbf{U}_{i,\widehat{\mathfrak{m}}(i)}(T_{3})[\widehat{ \mathbf{B}}^{\text{Lass}}]_{i}\big{)}\] (102) \[\leq \kappa_{0}\frac{1}{T_{2}}\|\mathbf{U}_{i,\widehat{\mathfrak{m}}(i) }(T_{3})[\widehat{\mathbf{B}}^{\text{Lass}}]_{i}-\mathbf{U}_{i,\widehat{ \mathfrak{m}}(i)}(T_{3})[\mathbf{B}]_{i}\|_{2}^{2}\;,\] (103)

where (102) holds due to the matrix formulation of the equation and the definition of \(\mathbf{U}_{i,\widehat{\mathfrak{m}}(i)}(T_{3})\) in (37), and (103) holds due to (100).

Combining all the results in (86) and (103), we find that with probability at least \(1-\frac{1}{N\delta}\),

\[\big{|}\mathrm{supp}\left([\mathbf{B}^{\mathrm{Lasso}}]_{i}\right)\big{|}\leq \frac{4\kappa_{0}}{\lambda^{2}T_{2}}\|\mathbf{U}_{i,\widehat{\mathbf{m}}(i)}[ \mathbf{B}^{\mathrm{Lasso}}]_{i}-\mathbf{U}_{i,\widehat{\mathbf{m}}(i)}[ \mathbf{B}]_{i}\|_{2}^{2}\.\] (104)

The speed of convergence of Lasso estimators depends on how rapidly the term \(\|\mathbf{U}_{i,\widehat{\mathbf{m}}(i)}[\mathbf{B}^{\mathrm{Lasso}}]_{i}- \mathbf{U}_{i,\widehat{\mathbf{m}}(i)}[\mathbf{B}]_{i}\|_{2}^{2}\) decreases. We now ensure \(\mathbf{D}\) satisfies Property 1 with \(\kappa=\kappa_{\min,\emptyset}/2\) when \(T_{2}\gtrsim d\log(|\widehat{\mathbf{m}}(i)|)\). The uncentered empirical covariance matrix defined in (87) satisfies

\[\mathbb{E}(\widehat{\Sigma}_{i})=\mathrm{Cov}(X_{\widehat{\mathbf{m}}(i)})= \Sigma_{i,\emptyset}\.\] (105)

We need the notion of restricted eigenvalue defined as follows.

**Definition 1**.: _Given a symmetric matrix \(\mathbf{H}\in\mathbb{R}^{d\times d}\), positive integer \(k\), and \(L>0\), the restricted eigenvalue of \(H\) is defined as_

\[\phi^{2}(H,k,L)\triangleq\min_{\mathcal{S}\subset[d],|\mathcal{S}|\leq k}\min _{\theta\in\mathbb{R}^{d}}\left\{\frac{\langle\theta,\mathbf{H}\theta\rangle} {\|\theta_{\mathcal{S}}\|_{1}^{2}}:\theta\in\mathbb{R}^{d},\|\theta_{ \mathcal{S}^{c}}\|_{1}\leq L\,\|\theta_{\mathcal{S}}\|_{1}\right\}.\] (106)

It is easy to see \(\mathbf{U}_{i,\widehat{\mathbf{m}}(i)}(T_{3})\Sigma_{i,\emptyset}^{-1/2}\) has independent sub-Gaussian rows with sub-Gaussian norm \(\left\|\Sigma_{i,\emptyset}^{-1/2}X_{\widehat{\mathbf{m}}(i)}\right\|_{\psi_{ 2}}=\tilde{\kappa}_{i,\emptyset,\min}^{-1/2}\). If the population covariance matrix meets the restricted eigenvalue condition, then the empirical covariance matrix also satisfies this condition with high probability [36, Theorem 10]. Specifically, suppose the number of rounds in the exploration phase satisfies

\[T_{2}\geq 4c_{*}c^{\prime}\tilde{\kappa}_{i,\emptyset,\min}^{-2}\log(e| \widehat{\mathbf{m}}(i)|/c^{\prime})\,\] (107)

for some \(c_{*}\leq 2000\) and \(c^{\prime}=10^{4}d\tilde{\kappa}_{i,\emptyset,\max}^{2}/\phi^{2}(\Sigma,k,9)\). Then the following condition holds

\[\mathbb{P}\left(\phi(\widehat{\Sigma},k,3)\geq\frac{1}{2}\phi(\Sigma,k,9) \right)\geq 1-2\exp\left(-\frac{T_{2}}{4c_{*}\tilde{\kappa}_{i,\emptyset, \min}^{-1/2}}\right).\] (108)

Noting \(\phi(\Sigma,k,9)\geq\tilde{\kappa}_{i,\emptyset,\min}^{1/2}\), we subsequently get

\[\mathbb{P}\left(\phi^{2}(\widehat{\Sigma},k,3)\geq\frac{\tilde{\kappa}_{i, \emptyset,\min}}{2}\right)\geq 1-2\exp\left(-c_{1}T_{2}\right),\] (109)

where \(c_{1}=\frac{1}{4c^{*}\tilde{\kappa}_{i,\min}^{-1/2}}\). This guarantees \(\widehat{\Sigma}\) satisfies Property 1 in the appendix with \(\kappa_{0}=\frac{\tilde{\kappa}_{i,\widehat{\mathbf{m}}}}{2}\). It can be readily verified that Property 2 holds. Applying the in-sample prediction error bound in Lemma 2, we have with probability at least \(1-\frac{\delta}{N}\),

\[\frac{1}{T_{3}}\|\mathbf{U}_{i,\widehat{\mathbf{m}}(i)}(t)[\widehat{\mathbf{ B}}^{\mathrm{Lasso}}]_{i}-\mathbf{U}_{i,\widehat{\mathbf{m}}(i)}(t)[ \mathbf{B}]_{i}\|_{2}^{2}\leq\frac{18}{\tilde{\kappa}_{\min}}\cdot\frac{d\log (\frac{N\|\widehat{\mathbf{m}}(i)\|}{\delta})}{T_{2}}\leq\frac{18}{\kappa_{ \min}}\cdot\frac{d\log(\frac{N\|\widehat{\mathbf{m}}(i)\|}{\delta})}{T_{2}}\.\] (110)

Putting (104) and (110) together, with probability at least \(1-\frac{2\delta}{N}\), we have

\[|\widehat{\mathbf{p}}(i)|\leq|\mathrm{supp}([\widehat{\mathbf{B}}^{\mathrm{ Lasso}}]_{i})|\leq\frac{9\hat{\kappa}|\mathsf{pa}(i)|}{\kappa_{\min}}=\kappa| \mathsf{pa}(i)|\.\] (111)

_Step 2: Containing \(\mathsf{pa}(i)\) set._ This step is to verify the variable screening property of the Lasso estimator, that is \(\mathrm{supp}([\widehat{\mathbf{B}}^{\mathrm{Lasso}}]_{i})\supseteq\mathrm{ supp}([\mathbf{B}]_{i})\). Since we set

\[T_{2}>\frac{4d\log(N)}{\kappa_{\min}^{2}\min_{j\in\mathrm{supp}([\mathbf{B}]_{i})} |[\mathbf{B}]_{j,i}|^{2}}\,\] (112)

by using Lemma 2, it holds that with probability at least \(1-\frac{\delta}{2N}\),

\[\min_{j\in\mathrm{supp}([\mathbf{B}]_{i})}|[\mathbf{B}]_{j,i}|>\|[\widehat{ \mathbf{B}}^{\mathrm{Lasso}}]_{i}-[\mathbf{B}]_{i}\|_{2}\geq\|[\widehat{ \mathbf{B}}^{\mathrm{Lasso}}]_{i}-[\mathbf{B}]_{i}\|_{\infty}\,\] (113)where in the last inequality we use the fact that \(\|\cdot\|_{2}\geq\|\cdot\|_{\infty}\).

Now we prove the variable screening property by contradiction. If there exists a \(j\) such that \(j\in\mathrm{supp}([\mathbf{B}]_{i})\) but \(j\notin\mathrm{supp}([\widehat{\mathbf{B}}^{\mathrm{Lasso}}]_{i})\), we have

\[\left|[\widehat{\mathbf{B}}^{\mathrm{Lasso}}]_{j,i}-[\mathbf{B}]_{j,i}\right|= \left|[\mathbf{B}]_{j,i}\right|>\|[\widehat{\mathbf{B}}^{\mathrm{Lasso}}]_{i}-[ \mathbf{B}]_{i}\|_{\infty}\;.\] (114)

On the other hand,

\[\left|[\widehat{\mathbf{B}}^{\mathrm{Lasso}}]_{j,i}-\mathbf{B}_{j,i}\right| \leq\|[\widehat{\mathbf{B}}^{\mathrm{Lasso}}]_{i}-[\mathbf{B}]_{i}\|_{\infty}\;,\] (115)

which leads to a contradiction. Hence, we conclude that \(\mathrm{supp}([\widehat{\mathbf{B}}^{\mathrm{Lasso}}]_{i})\supseteq\mathrm{ supp}([\mathbf{B}]_{i})\).

_Step 3: Union bounds._ By taking a Union bounds on \(N\) nodes with probability at least \(1-2\delta\), for all \(i\in[N]\), we have

\[\mathsf{pa}(i)\subseteq\widehat{\mathsf{p}}\widehat{\mathsf{a}}(i)\;,\quad \text{and}\quad|\widehat{\mathsf{p}}\widehat{\mathsf{a}}(i)|\leq\kappa| \mathsf{pa}(i)|\;.\] (116)

\(\blacksquare\)

## Appendix E Proof of Theorem 2 (Intervention Design)

This proof leverages a technique initially introduced by [37] and further developed by [38] and [32] for contextual linear bandit setting. However, unlike their settings, we face stochastic environments and compound effects due to the causal structures. In the proof, we address the added uncertainty introduced by noise from the parent variables, which requires careful handling. In the proof of Theorem 2, we work with the estimate of the maximum in-degree, denoted by \(\widehat{d}\triangleq\max_{i\in[N]}|\widehat{\mathsf{pA}}(i)|\) which, with probability at least \(1-2\delta\), satisfies \(\widehat{d}\leq\kappa d\), as proved in Theorem 1. However, to cover the proof for Corollary 1 and Corollary 2 where the proof needs to deal with \(d\) and \(d_{e}\), respectively, we use the notation \(d\) to represent \(\widehat{d}\), and \(\widehat{\mathsf{pA}}(i)\) to represent \(\mathsf{pa}(i)\) throughout. Besides, we work on the time instances from \(T_{3}\) to \(T\) for GA-LCB, to accommodate the known graph setting, we extend the proof across the entire time horizon, and prove the theorem for the entire time horizon \(T\). The proof consists of four main parts: first, we demonstrate that the UCB width holds in Section E.1, second, we bound the cumulative width in Section E.2, then bound the time required for elimination in Section E.3, and finally, we bound the regret in Section E.4.

### Bounding UCB width

In this section, we begin by proving the following estimation error lemma, that is for node \(i\in\widehat{\pi}\), if we can observe the contextual observation \(X_{\mathsf{pa}(i),\mathbf{a}}\), a tighter contextual UCB width can be achieved, as shown in the following lemma.

**Lemma 4**.: _For \(i\in\hat{\pi}\) and \(\mathbf{a}\in\mathcal{A}\), define the true UCB width as_

\[\widehat{w}_{i,\mathbf{a}}(t)\triangleq\sum_{j\in\widehat{\mathsf{pA}}(i)}w_{ j,\mathbf{a}}+\alpha\max_{\mathbf{a}\in\mathcal{A}}\|X_{\mathsf{pa}(i), \mathbf{a}}(t)\|_{[\mathbf{V}_{i,a_{i}}(t)]^{-1}}\;,\] (117)

_where \(\alpha=\sqrt{1/2\log(2NT)}+\sqrt{d}\). With probability at least \(1-\frac{\delta}{T}\) for all \(\mathbf{a}\in\mathcal{A}\) and \(j\in\mathsf{an}(i)\) we have_

\[\left|\widehat{X}_{j,\mathbf{a}}(t)-X_{j,\mathbf{a}}(t)\right|\leq\widehat{w} _{j,\mathbf{a}}(t)\;.\] (118)

_Proof:_ We first provide a high probability bound on the exploration bonus \(\|X_{\mathsf{pa}(i),\mathbf{a}}(t)\|_{[\mathbf{V}_{i,a_{i}}(t)]^{-1}}^{2}\) via Azuma's inequality and then prove this lemma via induction on the causal depth \(L_{i}\).

**High probability bound.** Due to the statistical independence of the observation samples \(\mathbf{U}_{i,a_{i}}(t)\) and \(X_{\mathsf{pa}(i),\mathbf{a}}(t)\) for all \(\mathbf{a}\in\mathcal{A}\), we have \(\mathbb{E}[\boldsymbol{\epsilon}_{i}(t)]=\mathbf{0}\), where \(\boldsymbol{\epsilon}_{i}(t)\triangleq(\epsilon_{i}(1),\cdots,\epsilon_{i}(t) )^{\top}\). Hence, for all \(\mathbf{a}\in\mathcal{A}\) we have

\[\mathbb{P}\left(\left|\epsilon_{i}^{\top}\mathbf{U}_{i,a_{i}}(t)[ \mathbf{V}_{i,a_{i}}(t)]^{-1}X_{\mathsf{pa}(i),\mathbf{a}}(t)\right|>\beta\max_ {\mathbf{a}\in\mathcal{A}}\|X_{\mathsf{pa}(i),\mathbf{a}}(t)\|_{[\mathbf{V}_{i,a_{i}}(t)]^{-1}}\right)\] (119) \[\leq 2\exp\left(-\frac{2\beta^{2}\max_{\mathbf{a}\in\mathcal{A}} \|X_{\mathsf{pa}(i),\mathbf{a}}(t)\|_{[\mathbf{V}_{i,a_{i}}(t)]^{-1}}^{2}}{ \left\|\mathbf{U}_{i,a_{i}}(t)[\mathbf{V}_{i,a_{i}}(t)]^{-1}X_{\mathsf{pa}(i), \mathbf{a}}(t)\right\|^{2}}\right)\] (120) \[\leq 2\exp\left(-2\beta^{2}\right)\] (121) \[=\frac{\delta}{TN}\;,\] (122)

where (120) holds since Azuma's inequality implies, and (121) is due to the following fact

\[\max_{\mathbf{a}\in\mathcal{A}}\|X_{\mathsf{pa}(i),\mathbf{a}}^{ \top}(t)\|_{[\mathbf{V}_{i,a_{i}}(t)]^{-1}}^{2}\] (123) \[\geq\|X_{\mathsf{pa}(i),\mathbf{a}}^{\top}(t)\|_{[\mathbf{V}_{i,a_{i}}(t)]^{-1}}^{2}\] (124) \[=X_{\mathsf{pa}(i),\mathbf{a}}^{\top}(t)[\mathbf{V}_{i,a_{i}}(t)] ^{-1}\left(\mathbf{I}_{N}+\mathbf{U}_{i,a_{i}}(t)^{\top}\mathbf{U}_{i,a_{i}}(t )\right)[\mathbf{V}_{i,a_{i}}(t)]^{-1}X_{\mathsf{pa}(i),\mathbf{a}}(t)\] (125) \[\geq X_{\mathsf{pa}(i),\mathbf{a}}^{\top}(t)[\mathbf{V}_{i,a_{i}} (t)]^{-1}\mathbf{U}_{i,a_{i}}(t)^{\top}\mathbf{U}_{i,a_{i}}(t)[\mathbf{V}_{i,a _{i}}(t)]^{-1}X_{\mathsf{pa}(i),\mathbf{a}}(t)\] (126) \[=\left\|\mathbf{U}_{i,a_{i}}(t)[\mathbf{V}_{i,a_{i}}(t)]^{-1}X_{ \mathsf{pa}(i),\mathbf{a}}(t)\right\|^{2}.\] (127)

and we use \(\beta=\sqrt{\frac{1}{2}\log\frac{NT}{\delta}}\) in (122), which corresponding to the first term in \(\alpha\) we used for the UCB _width_ in Theorem 2.

Next, we prove the Lemma 4 by induction.

**Base step:**\(L_{i}=1\). For node \(i\in[N]\) with causal depth \(L_{i}=1\), we show that for all \(\mathbf{a}\in\mathcal{A}\) with probability \(1-\frac{\delta}{TN}\) we have

\[\left|\widehat{X}_{i,\mathbf{a}}(t)-X_{i,\mathbf{a}}(t)\right| \leq\alpha\max_{\mathbf{a}\in\mathcal{A}}\|X_{\mathsf{pa}(i)}\|_{[\mathbf{V}_{ i,a_{i}}(t)]^{-1}}\;.\] (128)

We start by decomposing the left-hand side in (128) as follows.

\[\widehat{X}_{i,\mathbf{a}}(t)-X_{i,\mathbf{a}}(t) =[\mathbf{B}_{\mathbf{a}}(t)]_{i}^{\top}\widehat{X}_{\mathsf{pa}( i),\mathbf{a}}(t)-[\mathbf{B}_{\mathbf{a}}]_{i}^{\top}X_{\mathsf{pa}(i),\mathbf{a}}(t)\] (129) \[=[\mathbf{B}_{\mathbf{a}}(t)]_{i}^{\top}\left(\widehat{X}_{ \mathsf{pa}(i),\mathbf{a}}(t)-X_{\mathsf{pa}(i),\mathbf{a}}(t)\right)\] \[\quad+\mathbf{D}_{i,a_{i}}^{\top}(t)\mathbf{U}_{i,a_{i}}(t)[ \mathbf{V}_{i,a_{i}}(t)]^{-1}X_{\mathsf{pa}(i),\mathbf{a}}(t)\] \[\quad-[\mathbf{B}_{\mathbf{a}}]_{i}^{\top}\left(\mathbf{I}_{N}+ \mathbf{U}_{i,a_{i}}(t)^{\top}\mathbf{U}_{i,a_{i}}(t)\right)[\mathbf{V}_{i,a_ {i}}(t)]^{-1}X_{\mathsf{pa}(i),\mathbf{a}}(t)\] (130) \[=\mathbf{D}_{i,a_{i}}^{\top}(t)\mathbf{U}_{i,a_{i}}(t)[\mathbf{V} _{i,a_{i}}(t)]^{-1}X_{\mathsf{pa}(i),\mathbf{a}}(t)\] \[\quad-[\mathbf{B}_{\mathbf{a}}]_{i}^{\top}\left(\mathbf{I}_{N}+ \mathbf{U}_{i,a_{i}}(t)^{\top}\mathbf{U}_{i,a_{i}}(t)\right)[\mathbf{V}_{i,a_ {i}}(t)]^{-1}X_{\mathsf{pa}(i),\mathbf{a}}(t)\] (131) \[=\mathbf{D}_{i,a_{i}}^{\top}(t)\mathbf{U}_{i,a_{i}}(t)[\mathbf{V} _{i,a_{i}}(t)]^{-1}X_{\mathsf{pa}(i),\mathbf{a}}(t)\] \[\quad-[\mathbf{B}_{\mathbf{a}}]_{i}^{\top}[\mathbf{V}_{i,\mathbf{ a}}(t)]^{-1}X_{\mathsf{pa}(i),\mathbf{a}}(t)\] (133) \[=\epsilon_{i}^{\top}(t)\mathbf{U}_{i,a_{i}}(t)[\mathbf{V}_{i,a_{i }}(t)]^{-1}X_{\mathsf{pa}(i),\mathbf{a}}(t)\] \[\quad-[\mathbf{B}_{\mathbf{a}}]_{i}^{\top}[\mathbf{V}_{i,\mathbf{ a}}(t)]^{-1}X_{\mathsf{pa}(i),\mathbf{a}}(t)\] \[\quad-[\mathbf{B}_{\mathbf{a}}]_{i}^{\top}[\mathbf{V}_{i,\mathbf{ a}}(t)]^{-1}X_{\mathsf{pa}(i),\mathbf{a}}(t)\] (134)

where (131) is due to when \(L_{i}=1\) we have \(\widehat{X}_{\mathsf{pa}(i),\mathbf{a}}(t)=X_{\mathsf{pa}(i),\mathbf{a}}(t)= \epsilon_{\mathsf{pa}(i)}\). Since \(\|[\mathbf{B}_{\mathbf{a}}]_{i}\|\leq\sqrt{d}\), we obtain

\[\left|\widehat{X}_{i,\mathbf{a}}(t)-X_{i,\mathbf{a}}(t)\right| \leq \left|\epsilon_{i}^{\top}(t)\mathbf{U}_{i,a_{i}}(t)[\mathbf{V}_{i,a_{i}}(t)]^{-1}X_{\mathsf{pa}(i),\mathbf{a}}\right|\] \[+\sqrt{d}\left\|[\mathbf{V}_{i,a_{i}}(t)]^{-1}X_{\mathsf{pa}(i), \mathbf{a}}(t)\right\|\;.\] (135)The right-hand side above decomposes the prediction error into a variance term (first term) and a bias term (second term). Next, we bound the second term in (135) as follows

\[\big{\|}[\mathbf{V}_{i,a_{i}}(t)]^{-1}X_{\mathbf{pa}(i),\mathbf{a}}( t)\big{\|}\] (136) \[=\sqrt{X_{\mathbf{pa}(i),\mathbf{a}}^{\top}(t)[\mathbf{V}_{i,a_{i }}(t)]^{-1}\mathbf{I}_{N}[\mathbf{V}_{i,a_{i}}(t)]^{-1}X_{\mathbf{pa}(i), \mathbf{a}}(t)}\] (137) \[\leq\sqrt{X_{\mathbf{pa}(i),\mathbf{a}}^{\top}(t)[\mathbf{V}_{i,a _{i}}(t)]^{-1}\left(\mathbf{I}_{N}+\mathbf{U}_{i,a_{i}}(t)^{\top}\mathbf{U}_{i,a_{i}}(t)\right)[\mathbf{V}_{i,a_{i}}(t)]^{-1}X_{\mathbf{pa}(i),\mathbf{a}}(t)}\] (138) \[=\|X_{\mathbf{pa}(i),\mathbf{a}}(t)\|_{[\mathbf{V}_{i,a_{i}}(t)]^ {-1}}\;,\] (139)

where (138) holds since the matrix \(\mathbf{U}_{i,a_{i}}(t)^{\top}\mathbf{U}_{i,a_{i}}(t)\) is positive semidefinite.

Combining the bounds in (135), (122) and (139) completes proof for \(L_{i}=1\).

**Induction Step:** Assume that the property holds true for causal depths up to \(L_{i}=k\). We show that it will also hold for \(L_{i}=k+1\). For this purpose, we start with the following expansion and apply the triangular inequality to find an upper bound for it. Similar to (135), we have

\[\widehat{X}_{i,\mathbf{a}}(t)-X_{i,\mathbf{a}}(t)\] (140) \[=[\mathbf{B}_{\mathbf{a}}(t)]_{i}^{\top}\left(\widehat{X}_{ \mathbf{pa}(i),\mathbf{a}}(t)-X_{\mathbf{pa}(i),\mathbf{a}}(t)\right)\] \[\quad+\epsilon_{i}^{\top}(t)\mathbf{U}_{i,a_{i}}(t)[\mathbf{V}_{i,a_{i}}(t)]^{-1}X_{\mathbf{pa}(i),\mathbf{a}}(t)\] \[\quad-[\mathbf{B}_{\mathbf{a}}]_{i}^{\top}[\mathbf{V}_{i,\mathbf{ a}}(t)]^{-1}X_{\mathbf{pa}(i),\mathbf{a}}(t)\;.\] (141)

Using \(\|[\mathbf{B}_{\mathbf{a}}]_{i}\|\leq\sqrt{d}\) and triangle inequality, we obtain

\[\left|\widehat{X}_{i,\mathbf{a}}(t)-X_{i,\mathbf{a}}(t)\right| \leq\left|[\mathbf{B}_{\mathbf{a}}(t)]_{i}^{\top}\left(\widehat{X }_{\mathbf{pa}(i),\mathbf{a}}(t)-X_{\mathbf{pa}(i),\mathbf{a}}(t)\right)\right|\] \[\quad+\left|\left(\mathbf{D}_{i,a_{i}}(t)^{\top}-[\mathbf{B}_{ \mathbf{a}}]_{i}^{\top}\mathbf{U}_{i,a_{i}}(t)^{\top}\right)\mathbf{U}_{i,a_{ i}}(t)[\mathbf{V}_{i,a_{i}}(t)]^{-1}X_{\mathbf{pa}(i),\mathbf{a}}(t)\right|\] \[\quad+\sqrt{d}\left\|[\mathbf{V}_{i,a_{i}}(t)]^{-1}X_{\mathbf{pa}( i),\mathbf{a}}(t)\right\|\;,\] (142)

where the last two terms can be bounded similarly as in the Base Step. It remains to bound the term

\[\left|[\mathbf{B}_{\mathbf{a}}(t)]_{i}^{\top}\left(\widehat{X}_{\mathbf{pa}(i),\mathbf{a}}(t)-X_{\mathbf{pa}(i),\mathbf{a}}(t)\right)\right|\leq\sum_{j\in \mathsf{pa}(i)}\left|[\mathbf{B}_{\mathbf{a}}(t)]_{j,i}\right|\left|\widehat{X }_{j,\mathbf{a}}(t)-X_{j,\mathbf{a}}(t)\right|\;.\] (143)

From induction, we know that for all \(j\in\mathsf{pa}(i)\), with probability \(1-\delta\) we have

\[\left|\widehat{X}_{j,\mathbf{a}}(t)-X_{j,\mathbf{a}}(t)\right|\leq\widehat{w }_{j,\mathbf{a}}(t)\;.\] (144)

Thus, we obtain

\[\left|\widehat{X}_{i,\mathbf{a}}(t)-X_{i,\mathbf{a}}(t)\right| \leq\sum_{j\in\mathsf{pa}(i)}\left|[\mathbf{B}(t)]_{i}^{\top} \right|w_{j,\mathbf{a}}+\alpha\|X_{\mathbf{pa}(i)}\|_{[\mathbf{V}_{i,a_{i}}(t) ]^{-1}}\] (145) \[\leq\sum_{j\in\mathsf{pa}(i)}\widehat{w}_{j,\mathbf{a}}+\alpha\| X_{\mathbf{pa}(i)}\|_{[\mathbf{V}_{i,a_{i}}(t)]^{-1}}\;.\] (146)

Hence, we conclude the proof. 

### Bound sum of width of UCB

To bound the sum of UCB width, we first need to bound the sum of the exploration bonuses, as presented in the following lemma.

**Lemma 5**.: _For all \(i\in[N]\) with \(L_{i}=\ell\),with probability at least \(1-\delta\) we have_

\[\sum_{t=1}^{T}\big{\|}X_{\mathbf{pa}(i)}(t)\big{\|}_{[\mathbf{V}_{i,a_{i}(t)}( t)]^{-1}}\leq 2\sqrt{5\frac{m_{\mathbf{pa},\ell}^{2}}{\log(m_{\mathbf{pa},\ell}^{2}/d+1)}} \psi\log\left(\frac{m_{\mathbf{pa},\ell}^{2}}{2d}\psi+1\right)\,,\] (147)

_where \(m_{\mathbf{pa},\ell}\triangleq\max_{i\in[N],L_{i}=\ell}\big{\|}X_{\mathbf{pa} (i)}\big{\|}\).__Proof:_ This proof will use some intermediate steps from proof of Lemma 4. To proceed, we need the following lemma to bound the exploration bonus \(\left\|X_{\mathsf{pa}(i)}(t)\right\|_{\left[\mathbf{V}_{i,a_{i}(t)}(t)\right]^{-1}}\) in terms of eigenvalues.

**Lemma 6**.: _Let \(\{\lambda_{a_{i}(t),j}(t),j\in[N]\}\) denote the ordered eigenvalues of \(\mathbf{V}_{i,a_{i}(t)}(t)\) such that \(\lambda_{a_{i}(t),j}(t)\leq\lambda_{a_{i}(t),j+1}(t)\) for \(j\in[N-1]\). Then we have_

\[\left\|X_{\mathsf{pa}(i)}(t)\right\|_{\left[\mathbf{V}_{i,a_{i}(t)}(t)\right]^ {-1}}^{2}\leq 10\sum_{j=1}^{d}\frac{\lambda_{a_{i}(t),j}(t+1)-\lambda_{a_{i}(t),j} (t)}{\lambda_{a_{i}(t),j}(t)}\;.\] (148)

_Proof:_ The proof is similar to [37, Lemma 11] and [38, Lemma 2] with minor modifications to reflect bounded assumptions (the effect of \(m\)) and causal mechanisms (post-intervention distributions). We provide the proof for fixing \(i\in[N]\) and \(a_{i}=0\) as it can be readily generalized to all cases \(\mathbf{a}\in\mathcal{A}\). To proceed, we need the following lemmas.

**Lemma 7**.: _[_37_, Lemma 17]_ _For any \(\lambda_{1}\geq\lambda_{2}\), \(a\in\mathbb{R}\), we have_

\[\left(\begin{array}{cc}\lambda_{1}&a\\ a&\lambda_{2}\end{array}\right)=\mathbf{U}^{\top}\left(\begin{array}{cc} \lambda_{1}+y&0\\ 0&\lambda_{2}-y\end{array}\right)\mathbf{U}\] (149)

_for some \(0\leq y\leq\frac{a^{2}}{\lambda_{1}-\lambda_{2}}\) and some orthogonal matrix \(\mathbf{U}\)._

**Lemma 8**.: _Let \(\lambda_{1}\geq\cdots\geq\lambda_{d}\geq 1\). And let \(\nu_{1},\geq\cdots\geq\nu_{d}\) denote the effective eigenvalues of matrix \(\Delta\left(\lambda_{1},\ldots,\lambda_{d},1\cdots 1\right)+\mathbf{z}\cdot \mathbf{z}^{\top}\), where \(\mathbf{z}\in\mathbb{R}^{N}\), \(\left\|\mathbf{z}\right\|\leq m_{\mathsf{pa},L_{i}}\), and \(\operatorname{supp}(\mathbf{z})=[d]\). There exists \(y_{h,j}\geq 0,1\leq h<j\leq d\), and the following holds:_

\[\nu_{j} \geq\lambda_{j}\;,\] (150) \[\nu_{j} =\lambda_{j}+z_{j}^{2}-\sum_{h=1}^{j-1}y_{h,j}+\sum_{h=j+1}^{d}y_{ j,h}\;,\] (151) \[\sum_{h=1}^{j-1}y_{h,j}\leq z_{j}^{2}\;,\] (152) \[\sum_{h=j+1}^{d}y_{j,h}\leq\nu_{j}-\lambda_{j}\;,\] (153) \[\sum_{j=1}^{d}\nu_{j}=\sum_{j=1}^{d}\lambda_{j}+\left\|\mathbf{z }\right\|^{2}\;.\] (154)

_If \(\lambda_{h}>\lambda_{j}+m_{\mathsf{pa},L_{i}}^{2}\) then_

\[y_{h,j}\leq\frac{z_{j}^{2}z_{h}^{2}}{\lambda_{h}-\lambda_{j}-m_{\mathsf{pa},L_ {i}}^{2}}\;.\] (155)

_Proof:_ Clearly (151) implies (154) and (151); (152) imply (153). We prove the lemma by a recursive methods similar to induction on the dimension \(d\).

**Base step:** We apply Lemma 7 to obtain the following transformation:

\[\Delta\left(\lambda_{1},\ldots,\lambda_{d},1,\cdots,1\right)+ \mathbf{z}\cdot\mathbf{z}^{\top}\] (156) \[=\left(\begin{array}{cccc}\lambda_{1}+z_{1}^{2}&\cdots&z_{1}z_ {d-1}&z_{1}z_{d}\\ \vdots&\ddots&\vdots&\vdots\\ z_{1}z_{d-1}&\cdots&\lambda_{d-1}+z_{d-1}^{2}&z_{d-1}z_{d}\\ z_{1}z_{d}&\cdots&z_{d-1}z_{d}&\lambda_{d}+z_{d}^{2}\\ &&\mathbf{I}_{N-d}\end{array}\right)\] (157) \[=\mathbf{U}_{d}^{\top}\left(\begin{array}{cccc}\tilde{\lambda} _{1}+z_{1}^{2}&\cdots&z_{1}z_{d-1}&0\\ \vdots&\ddots&\vdots&\vdots\\ z_{1}z_{d-1}&\cdots&\tilde{\lambda}_{d-1}+z_{d-1}^{2}&0\\ 0&\cdots&0&\tilde{\lambda}_{d}\\ &&\mathbf{I}_{N-d}\end{array}\right)\mathbf{U}_{d}\;,\] (158)where \(\tilde{\lambda}_{h}=\lambda_{h}+y_{h,d}\), and \(y_{h,d}\geq 0\), for \(h=1,\ldots,d-1\), and \(\tilde{\lambda}_{d}=\lambda_{d}+z_{d}^{2}-\sum_{h=1}^{d-1}y_{h,d}\). And we have the fact that \(\sum_{h=1}^{d-1}y_{h}\leq z_{d}^{2}\). Thus \(\tilde{\lambda}_{j}\geq\lambda_{j}\) for \(j=1,\ldots,d\).

**Induction Hypothesis:** Assume that we can apply the base step to dimension \(\{d^{\prime},\cdots,d\}\) and get \(\{\mathbf{U}_{d^{\prime}},\cdots\mathbf{U}_{d}\}\).

**Induction Step:** We proceed by applying Lemma 7 with the upper left sub-matrix

\[\Delta\big{(}\tilde{\lambda}_{1}, \ldots,\tilde{\lambda}_{d^{\prime}}\big{)}+[z_{1},\cdots z_{d^{ \prime}}]\cdot[z_{1},\cdots z_{d^{\prime}}]^{\top}\] (159) \[=\left(\begin{array}{ccc}\tilde{\lambda}_{1}+z_{1}^{2}&\cdots& z_{1}z_{d^{\prime}}\\ \vdots&\ddots&\vdots\\ z_{1}z_{d^{\prime}}&\cdots&\tilde{\lambda}_{d^{\prime}}+z_{d^{\prime}}^{2} \end{array}\right)\] (160) \[=\mathbf{U}_{d^{\prime}}\left(\begin{array}{ccc}\tilde{\lambda }_{1}+z_{1}^{2}&\cdots&z_{1}z_{d^{\prime}-1}&0\\ \vdots&\ddots&\vdots&\vdots\\ z_{1}z_{d^{\prime}-1}&\cdots&\tilde{\lambda}_{d^{\prime}-1}+z_{d^{\prime}-1}^{2 }&0\\ 0&\cdots&0&\tilde{\lambda}_{d}^{\prime}\end{array}\right)\mathbf{U}_{d^{\prime }}\;.\] (161)

to tackle the \(d^{\prime}\) row and column. Then (155) follows from Lemma 7 since all elements in the diagonal are increasing with the induct step but no element grows by more than \(m_{\mathsf{pa},\ell}^{2}\) since \(\|\mathbf{z}\|\leq m_{\mathsf{pa},\ell}^{2}\). 

Now, we are ready to prove the Lemma 5. From the definition of \(\mathbf{V}_{i,a_{i}(t)}(t+1)\) we get

\[\mathbf{V}_{i,a_{i}(t)}(t+1) =\mathbf{V}_{i,a_{i}(t)}(t)+X_{\mathsf{pa}(i)}(t)X_{\mathsf{pa}(i )}^{\top}(t)\] (162) \[=\mathbf{U}(t)^{\top}\Delta\left(\lambda_{1}(t),\ldots,\lambda_{ d}(t),1,\cdots,1\right)\mathbf{U}(t)\] \[\quad+\mathbf{U}(t)^{\top}\widetilde{X}_{\mathsf{pa}(i)}(t) \widetilde{X}_{\mathsf{pa}(i)}^{\top}(t)\mathbf{U}(t)\;,\] (163)

where in (163) we apply Lemma 8 on \(\mathbf{V}_{i,a_{i}(t)}(t)\) and we define \(\widetilde{X}_{\mathsf{pa}(i)}(t)=\mathbf{U}(t)X_{\mathsf{pa}(i)}(t)\). Thus, the effective eigenvalues of \(\mathbf{V}_{i,a_{i}(t)}(t+1)\) are the effective eigenvalues of the matrix

\[\Delta\left(\lambda_{1}(t),\ldots,\lambda_{d}(t),1\cdots,1\right)+\widetilde{ X}_{\mathsf{pa}(i)}(t)\cdot\widetilde{X}_{\mathsf{pa}(i)}^{\top}(t)\;.\] (164)

Using the notation of Lemma 8, let \(\lambda_{1}\geq\cdots\geq\lambda_{d}\geq 1\) be the eigenvalues of \(\mathbf{V}_{i,a_{i}(t)}(t)\), \(\{\nu_{1},\ldots,\nu_{d}\}\) be the eigenvalues of \(\mathbf{V}_{i,a_{i}(t)}(t+1)\), and \(\mathbf{z}=\widetilde{X}_{\mathsf{pa}(i)}(t)\). For these choices we have the following property

\[X_{\mathsf{pa}(i)}^{\top}(t)[\mathbf{V}_{i,a_{i}(t)}(t)]^{-1}X_{\mathsf{pa}(i) }(t)=\sum_{j}\frac{z_{j}^{2}}{\lambda_{j}}\;.\] (165)

To bound \(z_{j}^{2}\), we use (151) in Lemma 8 and obtain

\[z_{j}^{2}\leq\nu_{j}-\lambda_{j}+\sum_{h=1}^{j-1}y_{h,j}\;.\] (166)

For \(\lambda_{h}>\lambda_{j}+3m_{\mathsf{pa},L_{i}}^{2}\) from (155) we obtain

\[y_{h,j}\leq\frac{z_{j}^{2}z_{h}^{2}}{\lambda_{h}-\lambda_{j}-m_{\mathsf{pa},L_{ i}}^{2}}\leq\frac{z_{j}^{2}z_{h}^{2}}{2m_{\mathsf{pa},L_{i}}^{2}}\;,\] (167)

and

\[\sum_{h:\lambda_{h}>\lambda_{j}+3m_{\mathsf{pa}(i),L_{i}}^{2}}y_{h,j}\leq\frac{ z_{j}^{2}}{2m_{\mathsf{pa},L_{i}}^{2}}\sum_{h:\lambda_{h}>\lambda_{j}+3m_{\mathsf{ pa},L_{i}}^{2}}z_{h}^{2}\leq\frac{z_{j}^{2}}{2}\;,\] (168)

since \(\|\mathbf{z}\|\leq m_{\mathsf{pa},L_{i}}^{2}\). Hence, by combining (166) and (168) we get

\[z_{j}^{2}\leq\nu_{j}-\lambda_{j}+\sum_{h=1}^{j-1}y_{h,j}\leq\nu_{j}-\lambda_{j} +z_{j}^{2}/2+\sum_{h<j:\lambda_{h}\leq\lambda_{j}+3m_{\mathsf{pa},L_{i}}^{2}}y_ {h,j}\;,\] (169)and, subsequently

\[z_{j}^{2}\leq 2\Big{[}\nu_{j}-\lambda_{j}+\sum_{h<j:\lambda_{h}\leq\lambda_{j}+3 m_{\mathsf{pa},L_{i}}^{2}}y_{h,j}\Big{]}\,.\] (170)

If \(\lambda_{j}\geq m_{\mathsf{pa},L_{i}}^{2}\) and \(\lambda_{h}\leq\lambda_{j}+3m_{\mathsf{pa},L_{i}}^{2}\) when \(\lambda_{j}\geq\lambda_{h}/4\) and we have

\[\sum_{j}\sum_{h<j:\lambda_{h}\leq\lambda_{j}+3m_{\mathsf{pa},L_{i}} ^{2}}\frac{y_{h,j}}{\lambda_{j}} \leq 4\sum_{j}\sum_{h<j:\lambda_{h}\leq\lambda_{j}+3m_{\mathsf{pa}, L_{i}}^{2}}\frac{y_{h,j}}{\lambda_{h}}\] (171) \[\leq 4\sum_{h}\sum_{j=h+1}^{d}\frac{y_{h,j}}{\lambda_{h}}\] (172) \[\leq 4\sum_{h:\lambda_{h}\geq 1}\frac{\nu_{h}-\lambda_{h}}{ \lambda_{h}}\;,\] (173)

where (171) holds as we relax the sum to include more terms and (173) holds due to (153). Thus, by applying (170) and (173) to (165), we obtain

\[\big{\|}X_{\mathsf{pa}(i)}(t)\big{\|}_{[\mathbf{V}_{i,a_{i}(t)}(t )]^{-1}}^{2} =\sum_{j}\frac{z_{j}^{2}}{\lambda_{j}}\] (174) \[\leq 2\sum_{j}\frac{\nu_{j}-\lambda_{j}}{\lambda_{j}}+2\sum_{j} \sum_{h<j:\lambda_{h}\leq\lambda_{j}+3m_{\mathsf{pa},L_{i}}^{2}}\frac{y_{h,j}} {\lambda_{j}}\] (175) \[\leq 2\sum_{j}\frac{\nu_{j}-\lambda_{j}}{\lambda_{j}}+8\sum_{h} \frac{\nu_{h}-\lambda_{h}}{\lambda_{h}}\] (176) \[\leq 10\sum_{j}\frac{\nu_{j}-\lambda_{j}}{\lambda_{j}}\;.\] (177)

So far, we have characterized a bound for confidence width. Next in terms of eigenvalues, we proceed to bound the sum in term of time instances the following lemma.

**Lemma 9**.: _For all \(i\in[N]\) with \(L_{i}=\ell\) we have_

\[\sum_{t=1}^{T}\big{\|}X_{\mathsf{pa}(i)}(t)\big{\|}_{[\mathbf{V}_{i,a_{i}(t)}( t)]^{-1}}^{2}\leq 2\sqrt{5\frac{m_{\mathsf{pa},\ell}^{2}}{\log(m_{\mathsf{pa}, \ell}^{2}/d+1)}T\log\left(\frac{m_{\mathsf{pa},\ell}^{2}}{2d}T+1\right)}\;.\] (178)

_Proof:_ The proof is similar to the proof of [37, Lemma 13], but modified to handle the difference between our algorithms and the difference of the weights. Lemma 6 implies

\[\sum_{t=1}^{T}\big{\|}X_{\mathsf{pa}(i)}(t)\big{\|}_{[\mathbf{V}_{i,a_{i}(t)}( t)]^{-1}}^{2}=\sum_{t=1}^{T}\sqrt{10\sum_{j=1}^{d}\left(\frac{\lambda_{a_{i}(t),j}(t+1)}{\lambda_{a_{i}(t),j}(t)}-1\right)}\;.\] (179)

Since \(a_{i}(t)\in\{0,1\}\) we have

\[\sum_{t=1}^{T}\big{\|}X_{\mathsf{pa}(i)}(t)\big{\|}_{[\mathbf{V}_ {i,a_{i}(t)}(t)]^{-1}}^{2}= \sum_{t=1}^{T}\mathds{1}\{a_{i}(t)=0\}\sqrt{10\sum_{j=1}^{d}\left( \frac{\lambda_{0,j}(t+1)}{\lambda_{0,j}(t)}-1\right)}\] \[+\sum_{t=1}^{T}\mathds{1}\{a_{i}(t)=1\}\sqrt{10\sum_{j=1}^{d} \left(\frac{\lambda_{1,j}(t+1)}{\lambda_{1,j}(t)}-1\right)}\;.\] (180)

To bound the width sum, we leverage the closed-form solution of the following optimization problem. We define the instances at which node \(i\) is intervened and not intervened as follows.

\[T_{i}(t)=\{\tau\in[t]\mid a_{i}(\tau)=0\}\;,\quad T_{i}^{*}(t)=\{\tau\in[t] \mid a_{i}(\tau)=1\}\;.\] (181)

**Lemma 10**.: _[_38_, Lemma 8]_ _The solution to the following optimization problem with a set of time instances \(\Psi\subset[T]\) and \(C>d\)_

\[\left\{\begin{aligned} \max_{\{c_{tj}\in\mathbb{R}_{+}\}}& \sum_{t\in\Psi}\sqrt{\sum_{j=1}^{d}c_{tj}}\\ \mathrm{s.t.}&\sum_{j=1}^{d}\prod_{t\in\Psi}\left(c_ {tj}+1\right)\leq C\end{aligned}\right.\;,\] (182)

_is_

\[c_{tj}=\left(\frac{C}{d}\right)^{1/|\Psi|}-1,\quad\forall\;t\in\Psi,j\in[d]\;.\] (183)

We have the following property for the constraints.

\[\sum_{j=1}^{d}\prod_{t\in T_{i}(t)}\frac{\lambda_{0,j}(t+1)}{ \lambda_{0,j}(t)} =\sum_{j=1}^{d}\lambda_{0,j}(T+1)\] (184) \[=\sum_{t\in T_{i}(t)}\left\|X_{\mathsf{pa}(i)}(t)\right\|^{2}+d\] (185) \[\leq m_{\mathsf{pa},\ell}^{2}|T_{i}(t)|+d\;,\] (186) \[\text{and}\quad\sum_{j=1}^{d}\prod_{t\in T_{i}(t)}\frac{\lambda_ {0,j}(t+1)}{\lambda_{0,j}(t)} \leq m_{\mathsf{pa},\ell}^{2}|T_{i}^{*}(t)|+d\;,\] (187)

where (186) is due to the definition of \(m_{\mathsf{pa},\ell}\). Hence, by applying Lemma 10 in (180) we obtain

\[\sum_{t\in T_{i}(t)}\left\|X_{\mathsf{pa}(i)}(t)\right\|_{[\mathbf{ V}_{i,a_{i}(t)}(t)]^{-1}}^{2} \leq|T_{i}(t)|\sqrt{10d}\sqrt{\left(\frac{m_{\mathsf{pa},\ell}^{2 }}{d}|T_{i}(t)|+1\right)^{\frac{1}{|T_{i}^{*}(t)|}}}-1\] \[\quad+|T_{i}^{*}(t)|\sqrt{10d}\sqrt{\left(\frac{m_{\mathsf{pa}, \ell}^{2}}{d}|T_{i}^{*}(t)|+1\right)^{\frac{1}{|T_{i}^{*}(t)|}}}-1\;.\] (188)

Next, we use the following lemma to bound (188).

**Lemma 11**.: _If \(\psi\geq 1\), the following inequality holds_

\[\left(\frac{m_{\mathsf{pa},\ell}^{2}}{d}\psi+1\right)^{1/\psi}-1\leq\frac{m_{ \mathsf{pa},\ell}^{2}/\hat{d}}{log(m_{\mathsf{pa},\ell}^{2}/\hat{d}+1)}\frac{ 1}{\psi}log\left(\frac{m_{\mathsf{pa},\ell}^{2}}{\hat{d}}\psi+1\right)\;.\] (189)

_Proof:_ Let \(a\triangleq\frac{m_{\mathsf{pa},\ell}^{2}/\hat{d}}{log(m_{\mathsf{pa},\ell}^{ 2}/\hat{d}+1)}\), showing (189) is equivalent to showing

\[\frac{1}{\psi}log\left(\frac{m_{\mathsf{pa},\ell}^{2}}{d}\psi+1\right)\leq log \left(1+a\;\frac{1}{\psi}log\left(\frac{m_{\mathsf{pa},\ell}^{2}}{d}\psi+1 \right)\right)\;.\] (190)

Define

\[g(\psi)\triangleq\frac{1}{\psi}log\left(\frac{m_{\mathsf{pa},\ell}^{2}}{d} \psi+1\right)\;,\] (191)

and

\[h(\psi)\triangleq\log(1+ag(\psi))\;.\] (192)

Since \(h(\psi)>0\). Showing (189) is equivalent to showing that for all \(\psi\geq 1\) we have

\[\frac{g(\psi)}{h(\psi)}\leq 1\;.\] (193)We show it in two steps. First, we show when \(\psi=1\), \(\frac{g(\psi)}{h(\psi)}\) is less than 1. Second, we show the derivative of the function \(\frac{g(\psi)}{h(\psi)}\) is negative for \(\psi\geq 1\). To proceed, we use the following properties of \(g(\psi)\) and \(h(\psi)\).

\[\lim_{\psi\to\infty}g(\psi) =\lim_{\psi\to\infty}\frac{1}{\psi}\log\left(\frac{m_{\mathsf{pa},\ell}^{2}}{d}\psi+1\right)\] (194) \[=\lim_{\psi\to\infty}\frac{\frac{m_{\mathsf{pa}(\lambda),\ell}^{ 2}}{d}}{\frac{m_{\mathsf{pa},\ell}^{2}}{d}\psi+1}\] (195) \[=0\;,\] (196)

where (195) is due to L'Hopital's rule. Similarly, we have

\[\lim_{\psi\to\infty}h(\psi)=0\;.\] (197)

Besides, the derivative of \(g(\psi)\) is

\[g^{\prime}(\psi)=\frac{\frac{m_{\mathsf{pa},\ell}^{2}}{d}\psi-\log\left(\frac{ m_{\mathsf{pa},\ell}^{2}}{d}\psi+1\right)\left(\frac{m_{\mathsf{pa},\ell}^{2}}{d} \psi+1\right)}{\psi^{2}(\frac{m_{\mathsf{pa},\ell}^{2}}{d}\psi+1)}\;.\] (198)

Now, let

\[k(\psi)\triangleq\frac{m_{\mathsf{pa},\ell}^{2}}{d}\psi-\log\left(\frac{m_{ \mathsf{pa},\ell}^{2}}{d}\psi+1\right)\left(\frac{m_{\mathsf{pa},\ell}^{2}}{d} \psi+1\right)\;.\] (199)

The sign of \(g^{\prime}(\psi)\) is the same as \(k(\psi)\) when \(\psi>0\). Furthermore, \(k(1)\leq 0\) and

\[k^{\prime}(\psi)=-\frac{m_{\mathsf{pa},\ell}^{2}}{d}\log\left(\frac{m_{ \mathsf{pa},\ell}^{2}}{d}\psi+1\right)<0\;.\] (200)

Thus, we can conclude that \(k(\psi)<0\) for all \(\psi\geq 1\). Therefore, using (198) we find

\[g^{\prime}(\psi)<0\;.\] (201)

_Step 1_: When \(\psi=1\), we have

\[\frac{g(1)}{h(1)}=\frac{\log(m_{\mathsf{pa},\ell}^{2}/d+1)}{\log(1+a\log(m_{ \mathsf{pa},\ell}^{2}/d+1))}\;.\] (202)

To show \(\frac{g(1)}{h(1)}\leq 1\), we equivalently show

\[m_{\mathsf{pa},\ell}^{2}/d+1\leq 1+a\log(m_{\mathsf{pa},\ell}^{2}/d+1)\;,\] (203)

which is obvious since \(a=\frac{m_{\mathsf{pa},\ell}^{2}/d}{\log(m_{\mathsf{pa},\ell}^{2}/d+1)}\). Thus, we have

\[\frac{g(1)}{h(1)}\leq 1\;.\] (204)

_Step 2_: The gradient of \(\frac{g(\psi)}{h(\psi)}\) can be calculated as

\[\left(\frac{g(\psi)}{h(\psi)}\right)^{\prime} =\frac{g^{\prime}(\psi)h(\psi)-h^{\prime}(\psi)g(\psi)}{h^{2}( \psi)}\] (205) \[=\frac{g^{\prime}(\psi)\log(1+ag(\psi))-\frac{ag^{\prime}(\psi)}{ 1+ag(\psi)}g(\psi)}{h^{2}(\psi)}\] (206) \[=\frac{g^{\prime}(\psi)}{h^{2}(\psi)\left(1+ag(\psi)\right)}\left( \left(1+ag(\psi)\right)\log(1+ag(\psi))-ag(\psi)\right)\;.\] (207)We have \(g^{\prime}(\psi)<0\), \(1+ag(\psi)>0\), and \(h(\psi)>0\). Thus, we only need to show that \(m(\psi)=\big{(}1+ag(\psi)\big{)}\log(1+ag(\psi))-ag(\psi)>0\). We show this by noting that

\[\lim_{\psi\to\infty}m(\psi)=0\;,\] (208)

and

\[m^{\prime}(\psi)=ag^{\prime}(\psi)\log(1+ag(\psi))+ag^{\prime}(\psi)-ag^{ \prime}(\psi)=ag^{\prime}(\psi)\log(1+ag(\psi))<0\;.\] (209)

Thus, we conclude that \(m(\psi)>0\) for \(\psi\geq 1\) and

\[\left(\frac{g(\psi)}{h(\psi)}\right)^{\prime}<0\;.\] (210)

Combine the results in (201), (204) and (210) we show the inequality in (189). 

Now, by applying lemma 11 to (188), we obtain

\[\sum_{t=1}^{T}\big{\|}X_{\mathsf{pa}(i)}(t)\big{\|}_{[\mathbf{V}_ {i,a_{i}(t)}(t)]^{-1}}\leq\sqrt{10\frac{m_{\mathsf{pa},\ell}^{2}}{\log(m_{ \mathsf{pa},\ell}^{2}/d+1)}|T_{i}(t)|\log\left(\frac{m_{\mathsf{pa},\ell}^{2} }{d}|T_{i}(t)|+1\right)}\\ +\sqrt{10\frac{m_{\mathsf{pa},\ell}^{2}}{\log(m_{\mathsf{pa}, \ell}^{2}/d+1)}|T_{i}^{*}(t)|\log\left(\frac{m_{\mathsf{pa},\ell}^{2}}{d}|T_{ i}^{*}(t)|+1\right)}\;.\] (211)

Since the function \(g(t)=\sqrt{10\frac{m_{\mathsf{pa},\ell}^{2}}{\log(m_{\mathsf{pa},\ell}^{2}/d+1 )}t\log\left(\frac{m_{\mathsf{pa},\ell}^{2}}{d}t+1\right)}\) is concave function in \(t\) and \(|T_{i}(t)|+|T_{i}^{*}(t)|=T\), we have

\[\sum_{t=1}^{T}\big{\|}X_{\mathsf{pa}(i)}(t)\big{\|}_{[\mathbf{V}_ {i,a_{i}(t)}(t)]^{-1}}\leq 2\sqrt{5\frac{m_{\mathsf{pa},\ell}^{2}}{\log(m_{ \mathsf{pa},\ell}^{2}/d+1)}T\log\left(\frac{m_{\mathsf{pa},\ell}^{2}}{2d}T+1 \right)}\;.\] (212)

### Bounding the time periods for elimination

Based on Lemma 9, we are able to bound the following lemma, which provide three important properties.

**Lemma 12**.: _With probability at least \(1-2\delta\), the following properties hold:_

1. \(\forall\mathbf{a}\in\mathcal{A},t\in[T]\)_:_ \(|\hat{\mu}_{N,\mathbf{a}}(t)-\mu_{N,\mathbf{a}}|\leq w_{N,\mathbf{a}}(t)\)_._
2. \(\forall s\in[S]\)_:_ \(\mathbf{a}^{*}\in\hat{\mathcal{A}}_{s}\)_._
3. \(\forall\mathbf{a}\in\hat{\mathcal{A}}_{s}\)_:_ \(\mu_{N,\mathbf{a}^{*}}-\mu_{N,\mathbf{a}}\leq m2^{3-s}\)_._

_Proof:_ We prove the properties when the properties in Theorem 1 hold. We prove the first property using the triangle inequality. Specifically,

\[\big{\|}X_{\mathsf{pa}(i)}(t)\big{\|}_{[\mathbf{V}_{i,a_{i}(t)}( t)]^{-1}} \leq\|\hat{\boldsymbol{\mu}}_{\mathsf{pa}(i)}(t)\|_{[\mathbf{V}_{i,a_{i}(t)}(t)] ^{-1}}+\|X_{\mathsf{pa}(i)}(t)-\hat{\boldsymbol{\mu}}_{\mathsf{pa}(i)}(t)\|_{[ \mathbf{V}_{i,a_{i}(t)}(t)]^{-1}}\] (213) \[\leq\|\hat{\boldsymbol{\mu}}_{\mathsf{pa}(i)}(t)\|_{[\mathbf{V}_{ i,a_{i}(t)}(t)]^{-1}}+\sqrt{2}m_{\mathsf{pa},L_{i}}\lambda_{\min}^{-1/2}\big{(} \mathbf{V}_{i,a_{i}(t)}(t)\big{)}\;.\] (214)

Therefore, using the definition in (19) and (117), we obtain

\[\widehat{w}_{N,\mathbf{a}}(t)\leq w_{N,\mathbf{a}}(t)\;.\] (215)

Thus, by using Lemma 4 and summing over \(t\in[T]\), with probability at least \(1-\delta\) we have

\[|\hat{\mu}_{N,\mathbf{a}}(t)-\mu_{N,\mathbf{a}}|=\Big{|}\widehat{X}_{N, \mathbf{a}}(t)-X_{N,\mathbf{a}}(t)\Big{|}\leq\widehat{w}_{N,\mathbf{a}}(t)\leq w _{N,\mathbf{a}}(t)\;.\] (216)The second property holds since when the first property holds, \({\bf a}^{*}\) always satisfies the condition in the line 16-17 in GA-LCB, i.e.

\[{\rm UCB}_{{\bf a}^{*}}(t)\geq\max_{{\bf a}\in\hat{\mathcal{A}}_{s}}{ \rm UCB}_{{\bf a}}(t)-m2^{1-s}.\] (217)

Next, we prove the third one by induction.

**Base Step:** When \(s=1\) it is obvious since we have \(|\mu_{N,{\bf a}^{*}}|\leq m\) and \(|\mu_{N,{\bf a}}|\leq m\).

**Induction Hypothesis:** Assume it holds for \(s\leq s^{\prime}\).

**Induction:** This indicates that for \(s=s^{\prime}+1\) we have \(\hat{\mathcal{A}}_{s}\subset\hat{\mathcal{A}}_{s-1}\). Additionally the condition in line 16 implies that \(w_{\bf a}^{s-1}\leq m2^{-(s-1)}\) for \({\bf a}\in\hat{\mathcal{A}}_{s}\) and \(w_{{\bf a}^{*}}^{s-1}\leq m2^{-(s-1)}\). Furthermore, the description of \(\mathcal{A}_{s}\) in (22) implies

\[{\rm UCB}_{\bf a}^{(s-1)}(t)\geq{\rm UCB}_{{\bf a}^{*}}^{(s-1)}(t)-m2^{1-(s-1)}\;.\] (218)

Thus, for any \({\bf a}\in\hat{\mathcal{A}}_{s-1}\) we have

\[\mu_{N,{\bf a}} \geq{\rm UCB}_{\bf a}^{(s-1)}(t)-m2\cdot 2^{-(s-1)}\] (219) \[\geq{\rm UCB}_{{\bf a}^{*}(t)}^{(s-1)}(t)-m4\cdot 2^{-(s-1)}\] (220) \[\geq\mu_{N,{\bf a}^{*}}-m4\cdot 2^{-(s-1)}\;.\] (221)

where (219) holds due to \({\bf a}\in\hat{\mathcal{A}}_{s-1}\), (220) holds due to (218) and (221) holds due to the definition of UCB. 

The next lemma provides an upper bound on the number of trials for which an alternative is chosen at the time \(T_{s}\) for \(s\in[S]\).

**Lemma 13**.: _If we define \(T_{s}\) as the time when \(\hat{A}_{s}\) is ended and \(\hat{\mathcal{A}}_{s+1}\) starts, for all \(s\in[S]\) we have_

\[T_{s} \leq\frac{2^{s}}{m}\times\left((\alpha+\sqrt{d})\sum_{\ell=1}^{L} d^{\ell-1}2\sqrt{5\frac{m_{{\bf pa},\ell}^{2}}{\log(m_{{\bf pa},\ell}^{2}/d+1)}T_{s} \log\left(\frac{m_{{\bf pa},\ell}^{2}}{2d}T_{s}+1\right)}\right.\] \[\left.+(\alpha+\sqrt{d})2\sqrt{2}\sum_{\ell=1}^{L}d^{\ell-1}m_{{ \bf pa},\ell}\left(\sqrt{\frac{2}{\kappa_{\min}}}\sqrt{T_{s}}+8\tau+1\right) \,\right)\,.\] (222)

_Proof:_ Note that similar to (213), we apply triangle inequality to get

\[\|\hat{\bm{\mu}}_{{\bf pa}(i)}(t)\|_{[{\bf V}_{i,a_{i}(t)}(t)]^{ -1}} \leq\|X_{{\bf pa}(i)}(t)\|_{[{\bf V}_{i,a_{i}(t)}(t)]^{-1}}+\|\hat {\bm{\mu}}_{{\bf pa}(i)}(t)-X_{{\bf pa}(i)}(t)\|_{[{\bf V}_{i,a_{i}(t)}(t)]^{ -1}}\] (223) \[\leq\|X_{{\bf pa}(i)}(t)\|_{[{\bf V}_{i,a_{i}(t)}(t)]^{-1}}+\sqrt {2}m_{{\bf pa},L_{i}}\lambda_{\min}^{-1/2}\big{(}{\bf V}_{i,a_{i}(t)}(t)\big{)}\;.\] (224)

_Step 1:_ To proceed, we first bound the second term in (224): summation regarding the eigenvalues, in the following lemma.

**Lemma 14**.: _We have the following upper bound for the eigenvalues_

\[\mathbb{E}\left[\sum_{t=1}^{T}\lambda_{\min}^{-1/2}\big{(}{\bf V} _{i,a_{i}(t)}(t)\big{)}\right]\leq\sqrt{\frac{2}{\kappa_{\min}}}\sqrt{T}+8 \tau+1\;,\] (225)

_where \(\tau\triangleq\frac{\iota^{2}m^{4}}{\kappa_{\min}^{2}}\) and \(\iota\triangleq\sqrt{\frac{16}{3}\log(2dNT^{2}(T+1))}\)._

_Proof:_ In order to proceed, we need upper and lower bounds on the maximum and minimum singular values of \({\bf U}_{i,a(t)}(t)\). However, these bounds depend on the number of non-zero rows of \({\bf U}_{i,a(t)}(t)\) matrices, which equals the values of the random variable \(N_{i,a(t)}(t)\). Let us define the weighted constant

\[\gamma_{n}\triangleq\max\left\{\iota m^{2}\sqrt{n},\iota^{2}m^{2} \right\}\;,\] (226)

[MISSING_PAGE_FAIL:34]

It is noteworthy that the term in the sum in (238) has a critical point, and we bound the two regions separately. To this end, we define the function

\[n(x)\triangleq\frac{1}{\sqrt{\max\left\{0,x\kappa_{\min}-\gamma_{n}\right\}+1}}\;, \quad x>0\;.\] (239)

In order to analyze the behavior of the function \(n\), we introduce \(\tau\triangleq\frac{\iota^{2}m^{4}}{\kappa_{\min}^{2}}\) as the critical point. Note that when \(x\leq\tau\), we have \(x\kappa_{\min}<\gamma_{n}\). In this case,

\[n(x)=1\;,\] (240)

which is an increasing function over the region. Now, we are ready to bound the last term

\[\mathbb{E}\left[\mathds{1}\{\mathcal{E}_{i,\cup}^{\mathrm{c}}\}\sum_{t=1}^{T} \lambda_{i}(t)\right]\leq\mathbb{E}\left[\sum_{t=1}^{T}h(N_{i,a(t)}(t))\right]\;.\] (241)

We define the set of time indices at which the chosen interventions are under-explored as

\[\mathcal{H}_{i}\triangleq\left\{t\in[T]\;|\;N_{i,\mathbf{a}(t)}(t)\leq 4\tau \right\}\;.\] (242)

It can be readily verified that \(|\mathcal{H}_{i}|\leq 8\tau\) since for node \(i\) we have \(a_{i}\in\{0,1\}\). Furthermore, when \(x\in\mathcal{H}_{i}\), we have

\[h(x)=1,\;x\leq\tau\;.\] (243)

Then we can bound the sum in (241) when \(\mathcal{H}_{i}\) occurs as follows.

\[\mathbb{E}\sum_{t=1}^{T}\mathds{1}\{t\in\mathcal{H}_{i}\}h(N_{i,a(t)}(t))\leq 8 \tau\;.\] (244)

Next, we only need to bound the remaining part when \(t\not\in\mathcal{H}_{i}\)

\[\mathbb{E}\sum_{t=1}^{T}\mathds{1}\{t\in\mathcal{H}_{i}^{\mathrm{c}}\}h(N_{i, a(t)}(t))\;.\] (245)

Note that when \(t\in\mathcal{H}_{i}^{\mathrm{c}}\), we have \(N_{i,a(t)}(t)>\tau\) and \(n\) is a decreasing function. Hence,

\[\sum_{t=1}^{T}\mathds{1}\{t\in\mathcal{H}_{i}^{\mathrm{c}}\}h(N_{i,a(t)}(t)) \leq\sum_{s=4\tau+1}^{N_{i}(T)+4\tau}n(s)+\sum_{s=4\tau+1}^{N_{i}^{*}(T)+4 \tau}n(s)\;.\] (246)

We bound the discrete sums through integrals and define

\[H_{\tau}(y)=\int_{x=4\tau}^{y}n(x)dx\;,\quad y\geq 4\tau\;.\] (247)

Since \(g(x)\) is a positive, non-increasing function, for any \(k\in\mathbb{N},k\geq 4\tau+1\) we have

\[\sum_{s=4\tau+1}^{k}n(s)\leq\int_{s=4\tau}^{k}n(s)\mathrm{d}s=H_{\tau}(k)\;.\] (248)

Then, the sum in (246) is upper bounded by

\[\sum_{s=4\tau+1}^{N_{i}(T)+4\tau}n(s)+\sum_{s=4\tau+1}^{N_{i}^{*}(T)+4\tau}n (s)\leq H_{\tau}(N_{i}(t)+4\tau)+H_{\tau}(N_{i}^{*}(t)+4\tau)\;.\] (249)

Since \(h(x)\) is positive and decreasing, and \(H(y)\) is defined as an integral of the \(n\) function with a positive first derivative and negative second derivative, it can be deduced that \(H\) is a concave function. Thus, by applying the concavity property we have

\[H_{\tau}(N_{i}(t)+4\tau)+H_{\tau}(N_{i}^{*}(t)+4\tau)\leq 2H_{\tau}\left( \frac{T}{2}+4\tau\right)\;.\] (250)Next, we proceed to establish an upper bound on the function \(H\) as follows.

\[H_{\tau}\left(\frac{T}{2}+4\tau\right)=\int_{x=4\tau}^{\frac{T}{2}+ 4\tau}h(x)\mathrm{d}x\] (251) \[=\int_{x=4\tau}^{\frac{T}{2}+4\tau}\frac{1}{\sqrt{x\kappa_{\min}- \gamma_{n}+1}}\mathrm{d}x\;.\] (252) \[=\int_{x=4\tau}^{\frac{T}{2}+4\tau}\frac{1}{\sqrt{x\kappa_{\min}- \gamma_{n}+1}}\mathrm{d}x\] (253) \[=\frac{2\sqrt{\kappa_{\min}(\frac{T}{2}+4\tau)-\gamma_{n}+1}-2 \sqrt{4\kappa_{\min}\tau-\gamma_{n}+1}}{\kappa_{\min}}\] (254) \[\leq\sqrt{\frac{2}{\kappa_{\min}}}\sqrt{T}\;,\] (255)

where we have used \(\int\frac{1}{\sqrt{ax-b}}dx=\frac{2\sqrt{ax-b}}{a}+\text{ constant }\). Combining the results in (235), (244) and (255), the final result for the bound is

\[\mathbb{E}\left[\sum_{t=1}^{T}\lambda_{i}(t)\right]\leq\sqrt{\frac{2}{\kappa_ {\min}}}\sqrt{T}+8\tau+1\;.\] (256)

_Step 2:_ Now we bound the first term in second term in (224). We proceed by proving the following inequalities by induction. For \(i\in\hat{\pi}\) with causal depth \(L_{i}\), we prove

\[\sum_{t=1}^{T_{s}}w^{(s)}_{i,\mathbf{a}(\tau)} \leq(\alpha+\sqrt{d})\sum_{\ell=1}^{L_{i}}d^{\ell-1}2\sqrt{5\frac{ m_{\mathbf{pa},\ell}^{2}}{\log(m_{\mathbf{pa},\ell}^{2}/d+1)}T_{s}\log\left( \frac{m_{\mathbf{pa},\ell}^{2}}{2d}T_{s}+1\right)}\] \[\quad+(\alpha+\sqrt{d})2\sqrt{2}\sum_{\ell=1}^{L_{i}}d^{\ell-1}m_ {\mathbf{pa},\ell}\left(\sqrt{\frac{2}{\kappa_{\min}}}\sqrt{T_{s}}+8\tau+1 \right)\;.\] (257)

**Base step:** when \(i\in[N]\) and \(L_{i}=1\), we have

\[w^{(s)}_{i,\mathbf{a}(\tau)}\leq\|X_{\mathbf{pa}(i)}(t)\|_{[\mathbf{V}_{i,a_{ i}}(t)]^{-1}}+2\sqrt{2}m_{\mathbf{pa},L_{i}}\lambda_{\min}^{-1/2}\big{(} \mathbf{V}_{i,\mathbf{a}(\tau)}(t)\big{)}\;.\] (258)

Hence, applying Lemma 9 and Lemma 14, we have

\[\sum_{t=1}^{T_{s}}w^{(s)}_{i,\mathbf{a}(\tau)} \leq 2\sqrt{5\frac{m_{\mathbf{pa},L_{i}}^{2}}{\log(m_{\mathbf{pa},L _{i}}^{2}/d+1)}T_{s}\log\left(\frac{m_{\mathbf{pa},L_{i}}^{2}}{2d}T_{s}+1\right)}\] \[\quad+2\sqrt{2}m_{\mathbf{pa},L_{i}}\left(\sqrt{\frac{2}{\kappa_ {\min}}}\sqrt{T_{s}}+8\tau+1\right)\;.\] (259)

**Induction Step**: Assume (257) holds for nodes \(i\in[N]\) with \(L_{i}=k-1\). Then for \(i\in[N]\) and \(L_{i}=k\), we have

\[\sum_{t=1}^{T_{s}}w^{(s)}_{i,\mathbf{a}(\tau)} =\sum_{t=1}^{T_{s}}\sum_{j\in\mathbf{pa}(i)}w^{(s)}_{j,\mathbf{a}( \tau)}\] \[\quad+\sum_{t=1}^{T_{s}}(\alpha+\sqrt{d})(\|X_{\mathbf{pa}(i)}(t) \|_{[\mathbf{V}_{i,\mathbf{a}_{i}}(t)]^{-1}}+2\sqrt{2}m_{\mathbf{pa},L_{i}} \lambda_{\min}^{-1/2}\big{(}\mathbf{V}_{i,\mathbf{a}(\tau)}(t)\big{)})\] (260) \[\leq d\times(\alpha+\sqrt{d})\sum_{\ell=1}^{k-1}d^{\ell-1}\sqrt{10 \frac{m_{\mathbf{pa},\ell}^{2}}{\log(m_{\mathbf{pa},\ell}^{2}/d+1)}T_{s}\log \left(\frac{m_{\mathbf{pa},\ell}^{2}}{d}T_{s}+1\right)}\] \[\quad+d\times(\alpha+\sqrt{d})2\sqrt{2}\sum_{\ell=1}^{k-1}d^{ \ell-1}m_{\mathbf{pa},\ell}\left(\sqrt{\frac{2}{\kappa_{\min}}}\sqrt{T_{s}}+8 \tau+1\right)\] \[\quad+(\alpha+\sqrt{d})\sqrt{10\frac{m_{k}^{2}}{\log(m_{k}^{2}/d+ 1)}T_{s}\log\left(\frac{m_{\mathbf{pa},\ell}^{2}}{d}T_{s}+1\right)}\] \[\quad+(\alpha+\sqrt{d})2\sqrt{2}m_{k}\left(\sqrt{\frac{2}{\kappa _{\min}}}\sqrt{T_{s}}+8\tau+1\right)\] (261) \[=(\alpha+\sqrt{d})\sum_{\ell=1}^{L_{i}}d^{\ell-1}\sqrt{10\frac{m_ {\mathbf{pa},\ell}^{2}}{\log(m_{\mathbf{pa},\ell}^{2}/d+1)}T_{s}\log\left( \frac{m_{\mathbf{pa},\ell}^{2}}{d}T_{s}+1\right)}\] \[\quad+(\alpha+\sqrt{d})2\sqrt{2}\sum_{\ell=1}^{L_{i}}d^{\ell-1}m_ {\mathbf{pa},\ell}\left(\sqrt{\frac{2}{\kappa_{\min}}}\sqrt{T_{s}}+8\tau+1 \right)\;,\] (262)

where in (260) we use the definition of width, (261) holds due to induction and Lemma 14. Hence, we have proved the following inequality for the reward node.

\[\sum_{t=1}^{T_{s}}w^{(s)}_{N,\mathbf{a}(\tau)} \leq(\alpha+\sqrt{d})\sum_{\ell=1}^{L}d^{\ell-1}2\sqrt{5\frac{m_ {\mathbf{pa},\ell}^{2}}{\log(m_{\mathbf{pa},\ell}^{2}/d+1)}T_{s}\log\left( \frac{m_{\mathbf{pa},\ell}^{2}}{2d}T_{s}+1\right)}\] \[\quad+(\alpha+\sqrt{d})2\sqrt{2}\sum_{\ell=1}^{L}d^{\ell-1}m_{ \mathbf{pa},\ell}\left(\sqrt{\frac{2}{\kappa_{\min}}}\sqrt{T_{s}}+8\tau+1 \right)\;.\] (263)

By the condition of line 18 of GA-LCB, we have

\[\sum_{t=1}^{T_{s}}w^{(s)}_{N,\mathbf{a}(\tau)}(\tau)\geq m2^{-s}T_{s}\;.\] (264)

Combining (263) and (264) we obtain

\[T_{s}\leq \frac{2^{s}}{m}\bigg{(}(\alpha+\sqrt{d})\sum_{\ell=1}^{L}d^{\ell- 1}2\sqrt{5\frac{m_{\mathbf{pa},\ell}^{2}}{\log(m_{\mathbf{pa},\ell}^{2}/d+1)}T_ {s}\log\left(\frac{m_{\mathbf{pa},\ell}^{2}}{2d}T_{s}+1\right)}\] \[\quad+(\alpha+\sqrt{d})2\sqrt{2}\sum_{\ell=1}^{L}d^{\ell-1}m_{ \mathbf{pa},\ell}\Big{(}\sqrt{\frac{2}{\kappa_{\min}}}\sqrt{T_{s}}+8\tau+1 \Big{)}\bigg{)}\;.\] (265)

### Bounding the regret

Lastly, we define \(\Psi_{0}\) as the time instance that GA-LCB performs \(\mathrm{UCB}\) to select interventions. Now, we are ready to prove the final theorem. We start from the decomposition of the regret as follows

\[\mathbb{E}[\mathcal{R}(T)] =T\mu_{\mathbf{a}^{*}}-\sum_{t=1}^{T}\mu_{\mathbf{a}(t)}\] (266) \[=\sum_{t\in\Psi_{0}}\left(\mu_{\mathbf{a}^{*}}-\mu_{\mathbf{a}(t) }\right)+\sum_{s=1}^{S}\sum_{t=T_{s}-1+1}^{T_{s}}\left(\mu_{\mathbf{a}^{*}}-\mu _{\mathbf{a}(t)}\right)\] (267) \[\leq\frac{2m}{\sqrt{T}}|\Psi_{0}|+\sum_{s=1}^{S}8m2^{-s}T_{s}\] (268) \[\leq\frac{2m}{\sqrt{T}}|\Psi_{0}|+\sum_{s=1}^{S}8\bigg{(}(\alpha+ \sqrt{d})\sum_{\ell=1}^{L}d^{\ell-1}2\sqrt{5\frac{m_{\mathbf{p}\mathbf{a}, \ell}^{2}}{\log(m_{\mathbf{p}\mathbf{a},\ell}^{2}/d+1)}T_{s}\log\left(\frac{m _{\mathbf{p}\mathbf{a},\ell}^{2}}{2d}T_{s}+1\right)}\] \[\quad+(\alpha+\sqrt{d})2\sqrt{2}\sum_{\ell=1}^{L}d^{\ell-1}m_{ \mathbf{p}\mathbf{a},\ell}\Big{(}\sqrt{\frac{2}{\kappa_{\min}}}\sqrt{T_{s}}+ 8\tau+1\Big{)}\Big{)}\] (269) \[\leq 2m\sqrt{T}+8(\alpha+\sqrt{d})S\sum_{\ell=1}^{L}d^{\ell-1}m_{ \mathbf{p}\mathbf{a},\ell}\Bigg{(}2\sqrt{\frac{5}{\log(m_{\mathbf{p}\mathbf{ a},\ell}^{2}/d+1)}T\log\left(\frac{m_{\mathbf{p}\mathbf{a},\ell}^{2}}{2d}T+1 \right)}\] \[\quad+2\sqrt{2}\left(\sqrt{\frac{2}{\kappa_{\min}}}\sqrt{T}+8 \tau+1\right)\Bigg{)}\;,\] (270)

where (267) is due to \(2^{-S}\leq\frac{1}{\sqrt{T}}\) and Lemma 13. Then we use the fact that for \(d\geq 2\) we have

\[\sum_{\ell=1}^{L}d^{\ell-1}=\frac{d^{L}-1}{d-1}\leq 2d^{L-1}=\mathcal{O}(d^{L- 1})\;.\] (271)

Since \(S=\mathcal{O}(\log T)\) and \(m_{\mathbf{p}\mathbf{a},\ell}\leq m\), we have

\[\mathbb{E}[\mathcal{R}(T)]\leq\tilde{\mathcal{O}}\Big{(}d^{L-\frac{1}{2}} \sqrt{T}\Big{)}\;.\] (272)

Finally, to get the regret bound in Theorem 2, we combine the results in Theorem 1 and (272), we conclude that with probability at least \(1-3\delta\), we have

\[\mathbb{E}[\mathcal{R}(T)]\leq\tilde{\mathcal{O}}\Big{(}d^{L-\frac{1}{2}} \sqrt{T}+RN+d\Big{)}\;.\] (273)

## Appendix F Notes on proof of Corollary 1 and Corollary 2

In the setting of Corollary 1, the causal graph \(\mathcal{G}\) is known. We do not need to use GA-LCB-SL algorithm to do structure learning. Instead, we can directly employ the GA-LCB-ID algorithm with the true parent sets \(\{\mathsf{pa}(i)\mid i\in[N]\}\). Hence, we can follow the proof of Theorem 2 to prove Corollary 1. The difference is that we will use the exact maximum in-degree \(d\) instead of \(\kappa d\) as we do not have that error due to the imperfect graph structure learning. Consequently, the regret bound simplifies, and we obtain the result stated in Corollary 1.

For Corollary 2, we have additional knowledge of the _effective_ maximum in-degree \(d_{e}\) and the causal depth \(L_{e}\). If we define \(\widehat{d_{e}}=\max i\in\mathsf{an}(N)|\widehat{\mathsf{pa}}(i)|\), from Theorem 1 we have \(\widehat{d_{e}}\leq\kappa d_{e}\). At the same time, we can obtain a valid topological ordering \(\widehat{\pi}_{e}\) that only contains \(\widehat{\mathsf{an}}(N)\). Hence, we can follow the proof of Theorem 2 with maximum in-degree \(d_{e}\) and causal depth \(L_{e}\) and induction on \(\pi_{e}\) to prove Corollary 2.

## Appendix G Proof of Theorem 3 (Lower Bound)

Let \(\Pi\) be the set of all policies on the set of stochastic bandit environments \(\mathcal{I}\). The minimax regret is defined as

\[\inf_{\pi\in\Pi}\sup_{\mathcal{I}_{0}\in\mathcal{I}}\mathbb{E}_{\pi,\mathcal{I}_ {0}}[\mathcal{R}(T)]\,\] (274)

where \(\mathbb{E}_{\pi,\mathcal{I}_{0}}[\mathcal{R}(T)]\) denotes the expected regret of policy \(\pi\) on the bandit instance \(\mathcal{I}_{0}\). We will consider a set \(\tilde{\mathcal{I}}\), instead of \(\mathcal{I}\), that contains two bandit instances. By definition of minimax regret, a lower bound for the regret of any policy on \(\tilde{\mathcal{I}}\) also is a lower bound for the minimax regret since

\[\inf_{\pi\in\Pi}\sup_{\mathcal{I}_{0}\in\mathcal{I}}\mathbb{E}_{\pi,\mathcal{I }_{0}}[\mathcal{R}(T)]\geq\inf_{\pi\in\Pi}\sup_{\mathcal{I}_{0}\in\tilde{ \mathcal{I}}}\mathbb{E}_{\pi,\mathcal{I}_{0}}[\mathcal{R}(T)]\.\] (275)

Following this property, the central idea of the proof is as follows. Consider two linear SEM causal bandit instances that differ by a small fraction and are hard to distinguish. At the same time, we can construct them to have different optimal interventions, indicating that a selection policy cannot incur small regret for both at the same time under the same data realization. Note that, the difference of the rewards, or equivalently the regrets, observed by these two bandit instances under the same intervention can be computed by tracing the effect of the differing edge parameter over all the paths that end at the reward node. We carefully build graphs to maximize the number of such paths for given \(d\) and \(L\). In this section, we provide details of these steps.

We consider the hierarchical graph as depicted in Figure 8, which consists of \(L\) layers each with \(d\) nodes. Adjacent layers are fully connected. There exists a final layer with one node fully connected to layer \(L\). We label the \(j\)-th node on layer \(\ell\) by \(X_{(\ell-1)d+j}\) and the reward node by \(X_{N}\).

We consider two linear SEM causal bandit instances \(I\) and \(\bar{I}\) that share the same graph \(\mathcal{G}\). \(I\) is parameterized by \(I\triangleq\{\mathbf{B},\mathbf{B}^{*},\epsilon\}\) and \(\bar{I}\) is parameterized by \(I\triangleq\{\bar{\mathbf{B}},\bar{\mathbf{B}}^{*},\epsilon\}\). For each instance \(I\in\tilde{\mathcal{I}}\) and for edges \((i\to j)\in\mathcal{E}\) with causal depth \(L_{i}=0\) or \(L_{i}>1\), let the weights of all observational edges be \(m_{\mathbf{B}}\), and all interventional edges be \(m_{\mathbf{B}}-\delta\) where \(\delta\in(0,m_{\mathbf{B}})\) will be determined later. In other words, for \(i,j\in[N]\), if \(L_{i}=0\) or \(L_{i}>1\) and \((i\to j)\in\mathcal{E}\), then

\[[\mathbf{B}]_{i,j}=[\bar{\mathbf{B}}]_{i,j}=m_{\mathbf{B}}\,\qquad\text{and} \qquad[\mathbf{B}^{*}]_{i,j}=[\bar{\mathbf{B}}^{*}]_{i,j}=m_{\mathbf{B}}-\delta\.\] (276)

Let noise terms follow the standard Gaussian distribution for nodes except the first layer, i.e., \(\epsilon_{i}\sim\mathcal{N}(0,1)\) for all \(i\in[N],i>d\). Furthermore, we let the noise in the first layer follow a Gaussian distribution \(\mathcal{N}(1,1)\) for all \(i\in[d]\).

The only difference between instances in \(I\) and \(\bar{I}\) is in the weights for the nodes with causal depth \(L_{i}=1\). Note that nodes are labeled from \(d+1\) to \(2d\). We have for \(i\in[d+1,2d]\) and \(j\in[d]\)

\[[\mathbf{B}]_{i,d+j}=[\bar{\mathbf{B}}^{*}]_{i,d+j}=m_{\mathbf{B}},\qquad\text {and}\qquad[\mathbf{B}^{*}]_{i,d+j}=[\bar{\mathbf{B}}]_{i,d+j}=m_{\mathbf{B}}-\delta\.\] (277)

Figure 8: Sample hierarchical graph used in the proof of Theorem 3.

Next, consider a fixed bandit policy \(\pi\) that generates the following filtration over time

\[\mathcal{F}_{t}\triangleq\{\mathbf{a}(1),X(1),\ldots,\mathbf{a}(t),X(t)\}\;.\] (278)

The decision of \(\pi\) at time \(t\) is \(\mathcal{F}_{t-1}\)-measurable. Accordingly, define \(\mathbb{P}_{t}\) and \(\bar{\mathbb{P}}_{t}\) as the probability measures induced by \(\mathcal{F}_{t}\) by \(t\) rounds of interaction between \(\pi\) and the two bandit instances \(I\) and \(\bar{I}\). When it is clear from context, we use the shorthand terms \(\mathbb{P}\) and \(\bar{\mathbb{P}}\) for \(\mathbb{P}_{T}\) and \(\bar{\mathbb{P}}_{T}\), respectively. We will show that \(\pi\) cannot suffer small regret in both instances at the same time and under the same filtration \(\mathcal{F}_{T}\).

By Lemma 1, since all the elements of observational and interventional weights are non-negative, the optimal intervention is the one that maximizes the value of each entry of \(\mathbf{B}_{\mathbf{a}}\) and \(\bar{\mathbf{B}}_{\mathbf{a}}\). The optimal action between two bandit instances only differs in nodes with \(L_{j}=2\). This means optimal intervention should include node \(j\) if elements of \([\mathbf{B}]_{j}\) are \(m_{\mathbf{B}}\) and not include \(j\) otherwise, for \(j\in[d+1,2d]\). As a result, we have \(\mathbf{a}_{I}^{*}=\emptyset\) and \(\mathbf{a}_{I}^{*}=[d+1,2d]\). Define \(\mathcal{E}_{\mathrm{lb}}^{j}\) as the event in which the decision on node \(d\) is sup-optimal at least \(\frac{T}{2}\) times after \(T\) rounds on bandit instance \(I\), i.e.,

\[\mathcal{E}_{\mathrm{lb}}^{j}\triangleq\left\{N_{d+j}^{*}(T)\geq\frac{T}{2} \right\}\;,\quad\text{for }j\in[d]\;.\] (279)

We note that the event \(\mathcal{E}_{\mathrm{lb}}^{j}\) is defined on the \(\sigma\)-algebra defined by the filtration \(\mathcal{F}_{t}\), that induces both \(\mathbb{P}_{t}\) and \(\bar{\mathbb{P}}_{t}\). We compute the expected instantaneous regret when node \(i\in[d+1,2d]\) is chosen sub-optimal in the first bandit instance and the total regret is the summation over these nodes. Note that each path passes node that node \(i\) contributes to the expected regret. Furthermore, since every weight is positive, in \(\mathcal{I}\), we have when the intervention on node \(\{d+1,\cdots,2d\}\) is chosen to be suboptimal, the impact on the average regret is \(\delta m_{\mathbf{B}}^{L-1}d^{L-1}\) since there are \(d^{L-2}\) paths of length \(L-1\) from node \(j\) to \(N\) and the difference between weights as \(\delta\) is multiplied with a \(m_{\mathbf{B}}\) factor for every edge along a path. Then, by the definition of \(\mathcal{E}_{\mathrm{lb}}\), we have

\[\mathbb{E}_{\mathbb{P}}[\mathcal{R}(t)] =\mathbb{E}_{\mathbb{P}}\left[\sum_{t=1}^{T}r(t)\right]\] (280) \[=\mathbb{E}_{\mathbb{P}}\left[\sum_{t=1}^{T}\sum_{j\in[d,2d]} \mathds{1}\{j\not\in\mathbf{a}(t)\}\delta m_{\mathbf{B}}^{L-1}d^{L-1}\right]\] (281) \[\geq\sum_{j=1}^{d}\mathbb{P}(\mathcal{E}_{\mathrm{lb}}^{j})\frac {T}{2}\delta m_{\mathbf{B}}^{L-1}d^{L-1}\;,\] (282)

where (281) holds as we break down the regret and (282) holds due to the definition of \(\mathcal{E}_{\mathrm{lb}}^{j}\) in (279).

Similarly, for \(\bar{I}\), each node \(\{d+1,\cdots,2d\}\) that is not intervened, it will occur at least \(\delta m_{\mathbf{B}}^{L-1}d^{L-1}\) regret. Applying the same steps as in (280),-(282), we obtain

\[\mathbb{E}_{\bar{\mathbb{P}}}[\mathcal{R}(t)] =\mathbb{E}_{\bar{\mathbb{P}}}\left[\sum_{t=1}^{T}r(t)\right]\] (283) \[\geq\mathbb{E}_{\bar{\mathbb{P}}}\left[\sum_{t\in[T]}\sum_{j\in[ d,2d]}\mathds{1}\{j\in\mathbf{a}(t)\}\delta m_{\mathbf{B}}^{L-1}d^{L-1}\right]\] (284) \[\geq\sum_{j=1}^{d}\bar{\mathbb{P}}(\mathcal{E}_{\mathrm{lb}}^{j,c })\frac{T}{2}\delta m_{\mathbf{B}}^{L-1}d^{L-1}\;.\] (285)

By combining (282) and (285) we have

\[\mathbb{E}_{\mathbb{P}}[\mathcal{R}(t)]+\mathbb{E}_{\bar{\mathbb{P}}}[ \mathcal{R}(t)]\geq\frac{T}{2}\;\delta m_{\mathbf{B}}^{L-1}d^{L-1}\sum_{j=1}^{ d}[\mathbb{P}(\mathcal{E}_{\mathrm{lb}}^{j})+\bar{\mathbb{P}}(\mathcal{E}_{ \mathrm{lb}}^{j,c})]\;.\] (286)

Next, we characterize a lower bound on \(\mathbb{P}(\mathcal{E}_{\mathrm{lb}})+\bar{\mathbb{P}}(\mathcal{E}_{\mathrm{lb}} ^{\varsigma})\), which involves the Kullback-Leibler (KL) divergence between \(\mathbb{P}\) and \(\bar{\mathbb{P}}\), denoted by \(\mathrm{D}_{\mathrm{KL}}(\mathbb{P}\parallel\bar{\mathbb{P}})\). For this purpose, we leverage the following theorem.

**Theorem 4** (Bretagnolle-Huber inequality).: _Let \(\mathbb{P}\) and \(\bar{\mathbb{P}}\) be probability measures on the same measurable space \((\Omega,\mathcal{F})\) and let \(A\in\mathcal{F}\) be an arbitrary event. Then,_

\[\mathbb{P}(A)+\bar{\mathbb{P}}(A^{c})\geq\frac{1}{2}\exp(-\mathrm{D }_{\mathrm{KL}}(\mathbb{P}\parallel\bar{\mathbb{P}}))\;.\] (287)

By invoking Theorem 4, from (286) we obtain

\[\mathbb{E}_{\mathbb{P}}[\mathcal{R}(t)]+\mathbb{E}_{\mathbb{P}}[ \mathcal{R}(t)] \geq\frac{T}{2}\ \delta m_{\mathbf{B}}^{L-1}d^{L-1}\sum_{j=1}^{d}[ \mathbb{P}(\mathcal{E}_{\mathrm{lb}}^{j})+\bar{\mathbb{P}}(\mathcal{E}_{ \mathrm{lb}}^{j,c})]\] (288) \[\geq\frac{T}{4}\ \delta m_{\mathbf{B}}^{L-1}d^{L-1}\ d\exp(- \mathrm{D}_{\mathrm{KL}}(\mathbb{P}\parallel\bar{\mathbb{P}}))\;.\] (289)

It remains to compute \(\exp(-\mathrm{D}_{\mathrm{KL}}(\mathbb{P}\parallel\bar{\mathbb{P}}))\) to conclude our proof, for which we leverage the following result.

**Lemma 16**.: _The KL divergence between \(\mathbb{P}\) and \(\bar{\mathbb{P}}\), the probability measures induced by \(\mathcal{F}_{t}\) on \(I\) and \(\bar{I}\), is equal to_

\[\mathrm{D}_{\mathrm{KL}}(\mathbb{P}\parallel\bar{\mathbb{P}})=Td ^{2}(1+d)\delta^{2}\;.\] (290)

_Proof:_ Note that a Bayesian network factorizes as

\[\mathbb{P}(X_{1},\ldots,X_{N})=\prod_{i=1}^{N}\mathbb{P}(X_{i} \mid X_{\mathsf{pa}(i)})\;.\] (291)

Additionally, the two bandit instances differ only in the mechanism of the first layer. Then, \(\mathrm{D}_{\mathrm{KL}}(\mathbb{P}\parallel\bar{\mathbb{P}})\) can be decomposed as

\[\mathrm{D}_{\mathrm{KL}}(\mathbb{P}\parallel\bar{\mathbb{P}}) =\sum_{i=1}^{N}\mathrm{D}_{\mathrm{KL}}\big{(}\mathbb{P}(X_{i} \mid X_{\mathsf{pa}(i)})\parallel\bar{\mathbb{P}}(X_{i}\mid X_{\mathsf{pa}(i) }))\] (292) \[=\sum_{j=1}^{d}\mathrm{D}_{\mathrm{KL}}\big{(}\mathbb{P}(X_{d+j} )\parallel\bar{\mathbb{P}}(X_{d+j})\mid X_{\mathsf{pa}(d+j)}\big{)}\;.\] (293)

Hence, we only need to analyze \(\mathrm{D}_{\mathrm{KL}}(\mathbb{P}(X_{d+j})\parallel\bar{\mathbb{P}}(X_{d+j} )\mid X_{\mathsf{pa}(d+j)})\) under two cases: (i) when node \((d+j)\) is observed, and (ii) node \((d+j)\) is intervened. We have that

\[X_{j+d}\sim\begin{cases}\mathcal{N}\big{(}m_{\mathbf{B}}\sum_{i=1}^{d}X_{i},1 \big{)}\;,&\text{under $\mathbb{P}$ when $j+d\notin a$}\\ \mathcal{N}\big{(}(m_{\mathbf{B}}-\delta)\sum_{i=1}^{d}X_{i},1\big{)}\;,&\text {under $\mathbb{P}$ when $j+d\in a$}\\ \mathcal{N}\big{(}(m_{\mathbf{B}}-\delta)\sum_{i=1}^{d}X_{i},1\big{)}\;,&\text {under $\bar{\mathbb{P}}$ when $j+d\notin a$}\\ \mathcal{N}\big{(}m_{\mathbf{B}}\sum_{i=1}^{d}X_{i},1\big{)}\;,&\text{under $\bar{\mathbb{P}}$ when $j+d\in a$}\\ \end{cases}\;.\] (294)

By noting that

\[\mathrm{D}_{\mathrm{KL}}\Big{(}\mathcal{N} \big{(}m_{\mathbf{B}}\sum_{i=1}^{d}X_{i},1\big{)}\parallel \mathcal{N}\big{(}(m_{\mathbf{B}}-\delta)\sum_{i=1}^{d}X_{i},1\big{)}\Big{)}\] (295) \[=\mathrm{D}_{\mathrm{KL}}\Big{(}\mathcal{N}\big{(}(m_{\mathbf{B}} -\delta)\sum_{i=1}^{d}X_{i},1\big{)}\parallel\mathcal{N}\big{(}m_{\mathbf{B} }\sum_{i=1}^{d}X_{i},1\big{)}\Big{)}\] (296) \[=\frac{\delta^{2}(\sum_{i=1}^{d}X_{i})^{2}}{2}\;,\] (297)from (294) we obtain that for \(j\in[d]\)

\[\mathrm{D}_{\mathrm{KL}}(\mathbb{P}(X_{j+d})\parallel\bar{\mathbb{P} }(X_{d+j})|X_{\mathbf{pa}(j+d)})\] \[=\sum_{t\in[T]:j+d\notin\mathbf{a}(t)}\mathrm{D}_{\mathrm{KL}}( \mathcal{N}(m_{\mathbf{B}}\sum_{i=1}^{d}X_{i},1),\mathcal{N}((m_{\mathbf{B}}- \delta)\sum_{i=1}^{d}X_{i},1))\] (298) \[\quad+\sum_{t\in[T]:j+d\in\mathbf{a}(t)}\mathrm{D}_{\mathrm{KL}}( \mathcal{N}((m_{\mathbf{B}}-\delta)\sum_{i=1}^{d}X_{i},1),\mathcal{N}(m_{ \mathbf{B}}\sum_{i=1}^{d}X_{i},1))\] (299) \[=N_{1}^{*}(T)\;\mathbb{E}\frac{\delta^{2}(\sum_{i=1}^{d}X_{i})^{2 }}{2}+(T-N_{1}^{*}(T))\;\mathbb{E}\frac{\delta^{2}(\sum_{i=1}^{d}X_{i})^{2}}{2}\] (300) \[=T(d+d^{2})\delta^{2}\;.\] (301)

\(\blacksquare\)

By applying Lemma 16 on (289) and setting \(\delta=\frac{1}{\sqrt{d^{2}(1+d)T}}\), we obtain

\[\max\{\mathbb{E}_{\mathbb{P}}[\mathcal{R}(t)],\mathbb{E}_{\mathbb{ P}}[\mathcal{R}(t)]\} \geq\frac{1}{2}(\mathbb{E}_{\mathbb{P}}[\mathcal{R}(t)]+\mathbb{E }_{\mathbb{P}}[\mathcal{R}(t)])\] (302) \[\geq\frac{T}{8}\;\delta m_{\mathbf{B}}^{L-1}d^{L-1}\;d\exp(-2T(d +d^{2})\delta^{2})\] (303) \[=\frac{\exp(-2)}{8}\;m_{\mathbf{B}}^{L-1}\frac{d^{L-1}}{\sqrt{d+ 1}}\;\sqrt{T}\;.\] (304)

Hence, the policy \(\pi\) incurs a regret \(\Omega(d^{L-\frac{3}{2}}\sqrt{T})\) in at least one of the two bandit instances.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: See Section 4 for details. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: Our primary limitation, discussed under assumption 4 in Section 2, is the assumption that the bound\(m\) is known. However, whether this assumption can be relaxed is an open question even in linear bandit settings. Another limitation is that to enhance the performance in empirical applications, we need to tune the exploration times and \(\alpha\) as hyperparameters. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when the image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs**Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: We provide a full set of assumptions at the end of Section 2. All proofs are included in the Appendix. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in the appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: See the details in Appendix A and the codes in https://github.com/ZiruiYan/Linear-Causal-Bandit-Unknown-Graph. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.

5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: See the details in Appendix A and the codes. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: See the details in Appendix A and the codes in https://github.com/ZiruiYan/Linear-Causal-Bandit-Unknown-Graph. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [No] Justification: The theoretical results are based on average regret. We do not include the variance of regret as a metric in this paper; therefore, it is not defined and applicable. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.

* The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).
* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: The experiments only needs single CPU. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: The research only include the synthetic dataset and hence, do not have potential potential harmfulness. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: This is a theoretical paper. Guidelines: * The answer NA means that there is no societal impact of the work performed.

* If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.
* Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.
* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: We did not use such data and models. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [NA] Justification: We did not use existing assets. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.

* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: We did not release new assets. Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: We did not involve crowdsourcing nor research with human subjects Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: We did not involve crowdsourcing nor research with Human subjects
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.