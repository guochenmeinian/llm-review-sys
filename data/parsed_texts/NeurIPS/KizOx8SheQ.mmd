# Diff-BBO: Diffusion-Based Inverse Modeling for Black-Box Optimization

 Dongxia Wu

University of California San Diego

La Jolla, CA

dowu@ucsd.edu

&Nikki Lijing Kuang

University of California San Diego

La Jolla, CA

llkuang@ucsd.edu

&Ruijia Niu

University of California San Diego

La Jolla, CA

rniu@ucsd.edu

&Yi-An Ma

University of California San Diego

La Jolla, CA

yianma@ucsd.edu

&Rose Yu

University of California San Diego

La Jolla, CA

roseyu@ucsd.edu

###### Abstract

Black-box optimization (BBO) aims to optimize an objective function by iteratively querying a black-box oracle in a sample-efficient way. While prior studies focus on forward approaches to learn surrogates for the unknown objective function, they struggle with steering clear of out-of-distribution and invalid inputs. Recently, inverse modeling approaches that map objective space to the design space with conditional diffusion models have demonstrated impressive capability in learning the data manifold. They have shown promising performance in offline BBO tasks. However, these approaches require a pre-collected dataset. How to design the acquisition function for inverse modeling to _actively_ query new data remains an open question. In this work, we propose _diffusion-based inverse modeling for black-box optimization_ (Diff-BBO), an _inverse_ approach leveraging diffusion models for online BBO problem. Instead of proposing candidates in the design space, Diff-BBO employs a novel acquisition function _Uncertainty-aware Exploration_ (UaE) to propose objective function values. Subsequently, we employ a conditional diffusion model to generate samples based on these proposed values within the design space. We demonstrate that using UaE results in optimal optimization outcomes, supported by both theoretical and empirical evidence.

## 1 Introduction

Practical problems in science and engineering often involve optimizing a black-box objective function that is expensive to evaluate, such as robotics (Tesch et al., 2013) and molecular design (Sanchez-Lengeling and Aspuru-Guzik, 2018). How to achieve a near-optimal solution while minimizing function evaluations is thus a major challenge in black-box optimization (BBO). Prior works in BBO have largely focused on the online setting where a model can iteratively query the function during training (Turner et al., 2021; Zhang et al., 2021; Hebbal et al., 2019; Mockus, 1974). Most existing algorithms belong to forward methods, including Bayesian optimization (BO) (Kushner, 1964; Mockus, 1974; Wu et al., 2023; Frazier, 2018), bandit algorithms (Agrawal and Goyal, 2012;Karbasi et al., 2023), and conditional sampling approaches (Brookes et al., 2019; Gruver et al., 2024; Stanton et al., 2022). They build a surrogate model to approximate the black-box function and optimize sequentially.

However, these approaches may face difficulties in scenarios where valid inputs represent a small subspace, such as valid protein sequences or molecular structures. Such optimization problems become exceptionally challenging, as the optimizer must navigate and avoid out-of-distribution and invalid inputs (Kumar and Levine, 2020). Recently, a novel set of methods, termed _inverse approaches_, have been proposed to address this issue. These methods (Kumar and Levine, 2020; Krishnamoorthy et al., 2023; Kim et al., 2023; Fu and Levine, 2021) break the traditional paradigm by learning an inverse mapping from objective space back to the input (design) space. Leveraging the state-of-the-art generative models, such as diffusion models (Sohl-Dickstein et al., 2015; Song et al., 2020), these approaches effectively capture data distributions in high-dimensional input space and facilitate optimization within the data manifold (Kong et al., 2024; Li et al., 2024; Kong et al., 2024). They achieve high performance in offline optimization settings (Kumar and Levine, 2020; Lu et al., 2023; Wang et al., 2018), assuming access to a fixed pre-collected dataset.

Despite these advancements, the online setting of inverse modeling, particularly how to capture the uncertainty of the inverse model and design an acquisition function for data-efficient querying, remains an open question. In this paper, we propose Diff-BBO, an inverse approach for online black-box optimization. Our approach consists of a novel acquisition function design through the _uncertainty quantification_ (UQ) of conditional diffusion model, which proposes the desired objective function values to strategically sample the design space and query the oracle function efficiently. We summarize our main contributions as follows:

* We present Diff-BBO, an inverse modeling approach for efficient online black-box optimization (BBO) leveraging uncertainty of conditional diffusion models.
* We design a novel acquisition function for BBO based on the uncertainty of conditional diffusion models. Theoretically, we prove that the balance between targeting higher objective values and minimizing epistemic uncertainty lead to optimal optimization outcomes.
* We demonstrate that Diff-BBO achieves state-of-the-art performance with superior sample efficiency on Design-Bench and molecular discovery task in the online BBO setting.

## 2 Methodology

Let \(f:\mathcal{X}\rightarrow\mathbb{R}\) denote the unknown ground-truth black-box function that evaluates the quality of any data point \(\bm{x}\), with \(\mathcal{X}\subseteq\mathbb{R}^{d}\). Our goal is to find the optimal point \(\bm{x}^{*}\) that maximizes \(f\), \(\bm{x}^{*}\in\operatorname*{argmax}_{\bm{x}\in\mathcal{X}}f(\bm{x})\). In the batch online BBO setting, we iteratively query \(f\) with batch size \(N\) and a fixed query iteration \(K\) and update the model based on observed outputs. At each iteration, the acquisition function guides the data selection of new query points by balancing exploration and exploitation. In Diff-BBO, we model the conditional distribution of \(p(\bm{x}|y,\mathcal{D})\) with training data \(\mathcal{D}\). The function value \(y\) to condition on is proposed by an acquisition function, which quantifies the

Figure 1: Forward modeling vs inverse modeling for black-box optimization. (_Top_) Forward modeling approach using certain surrogate models (e.g., GPs) for forward modeling and acquisition functions (e.g., UCB, PI, and EI) to select \(\mathbf{x}\). (_Bottom_) Our inverse modeling approach using generative model (e.g., diffusion model) for inverse modeling and acquisition function (e.g., UAE) to select \(y\).

quality of the generated \(\bm{x}\). The objective of the above optimization becomes:

\[\max_{y_{k}\in\mathbb{R}}\sum\nolimits_{k=1}^{K}f(\bm{x}_{k}),\ \ \bm{x}_{k}\sim p_{\theta}(\cdot\mid y_{k},\mathcal{D}),\ \ \theta\in\Theta.\] (1)

To solve this optimization problem, we introduce Diff-BBO algorithm in Algorithm 1. At each iteration \(k\), we train a conditional diffusion model and compute the optimal \(y_{k}^{*}\) with the designed acquisition function. In practice, \(y\) is selected from a constructed candidate set \(\mathcal{Y}\) based on the acquisition function scores \(\alpha(y)\). The range of \(\mathcal{Y}\) is determined by \(w\cdot\phi_{k}\), where \(w\) is a positive scalar and \(\phi_{k}\) is the maximum function values being queried in the current training dataset \(\mathcal{D}\). Conditioning on \(y_{k}^{*}\), we generate \(N\) samples \(\{\mathbf{x}_{j}\}_{j=1}^{N}\), where \(\bm{x}_{j}\sim p_{\theta}(\mathbf{x}|y_{k}^{*},\mathcal{D})\). By querying the oracle to evaluate \(\bm{x}_{j}\), we obtain the best possible reconstructed value \(\phi_{k}\) for the current iteration, and append all queried data pairs \(\{\mathbf{x}_{j},f(\mathbf{x}_{j})\}_{j=1}^{N}\) to the training dataset \(\mathcal{D}\). Figure 1 summarizes the difference between the prior forward BBO methods and our proposed inverse modeling approach.

### Acquisition Function Design

In this section, we analyze the uncertainty of Diff-BBO, decomposing its uncertainty into aleatoric and epistemic uncertainty. Then we propose an acquisition function called Uncertainty-aware Exploration (UaE) based on it. We prove that by achieving a balance between high objective values and low epistemic uncertainty, UaE provides a near-optimal solution to the online BBO problem.

Uncertainty Decomposition.We resort to the tools of Bayesian inference to solve the optimization problem defined in Equation (1). Given an observed value \(y\) of a sample \(\bm{x}\), the objective of Bayesian inference is to estimate the predictive distribution:

\[p(\bm{x}\mid y,\mathcal{D})=\mathbb{E}_{\theta}[p_{\theta}(\bm{x}\mid y)]= \int_{\theta}p_{\theta}(\bm{x}\mid y)p(\theta\mid\mathcal{D})d\theta.\] (2)

By Equation (2), we recognize that the uncertainty arises from two sources: uncertainty in deciding parameter \(\theta\) from its posterior \(p(\theta|\mathcal{D})\) and uncertainty in generating sample \(\bm{x}\) from a fixed diffusion model \(p_{\theta}(\bm{x}\mid y)\) after \(\theta\) is chosen. We further provide a decomposition in terms of the aleatoric uncertainty and its epistemic counterpart.

To estimate the aleatoric uncertainty, we can Monte Carlo (MC) sample \(\bm{x}\) for \(N\) times from a learned likelihood function \(p_{\theta}(\bm{x}\mid y)\) for fixed \(y,\theta\). To estimate the epistemic uncertainty, we use ensemble techniques. During the inference time, by initializing the trained ensemble models with different random seeds, we first sample \(M\) model parameters \(\{\theta_{i}\}_{i=1}^{M}\) to simulate \(M\) conditional diffusion models. Then we generate \(N\) samples \(\{\bm{x}_{j}\}_{j=1}^{N}\) for each diffusion model with corresponding parameter \(\theta_{i},\ \forall i\in[M]\). Combining the above gives a practical way to decompose and estimate the two types of uncertainty, which is formally described in Proposition 1.

**Proposition 1** (Uncertainty Decomposition).: _At each iteration \(k\in[K]\), the overall uncertainty in inverse modeling can be split into aleatoric and epistemic components, measured empirically as:_

\[\Delta_{\text{aleatoric}}\left(y,\mathcal{D}\right) =\mathbb{E}_{\theta_{i}\sim p(\cdot\mid\mathcal{D})}\left[\operatorname {Var}_{\bm{x}_{i,j}\sim p_{\theta_{i}}(\cdot\mid y)}\left(\|\bm{x}_{i,j}\| \right)\right],\ \ \forall i\in[M],j\in[N];\] (3) \[\Delta_{\text{epistemic}}\left(y,\mathcal{D}\right) =\operatorname{Var}_{\theta_{i}\sim p(\cdot\mid\mathcal{D})} \left(\mathbb{E}_{\bm{x}_{i,j}\sim p_{\theta_{i}}(\cdot\mid y)}\left[\|\bm{x} _{i,j}\|\right)\right],\ \ \forall i\in[M],j\in[N].\]

Uncertainty-aware Exploration.At each iteration \(k\in[K]\) of Dif-BBO algorithm, the acquisition function proposes an optimal scalar value \(y_{k}^{*}\) as follows: \(y_{k}^{*}=\operatorname{argmax}_{y}\alpha(y,\mathcal{D})\), which is used to generate \(\bm{x}\) in the design space using conditional difussion model.

Note that to design an effective acquisition function for inverse modeling, we need to achieve a balance between high objective values \(y\) and low epistemic uncertainty. On the one hand, it is advantageous to focus on the regions in \(\mathcal{X}\) whose corresponding \(y\) is of high values. As function evaluations are expensive to perform, we prefer to generate samples \(\bm{x}\) conditioned on higher \(y\), and only query the oracle for such promising samples to solve the black-box optimization task. On the other hand, we employ the epistemic uncertainty to gauge the error in the trained diffusion model. Specifically, it helps reduce the approximation error between \(y_{k}^{*}\) and the reconstructed function value \(\max_{j\in[N]}f(\bm{x}_{j})\), where \(f(\cdot)\) is the black-box oracle, and \(\bm{x}_{j}\sim p_{\theta}(\cdot|y_{k}^{*},\mathcal{D}),\forall j\in[N]\).

We introduce the _Uncertainty-aware Exploration_ (UaE) as our designed acquisition function:

\[\alpha(y,\mathcal{D})=y-\Delta_{\text{epistemic}}(y,\mathcal{D}),\] (4)

which utilizes the uncertainty estimation on conditional diffusion model as in Proposition1. By balancing the exploration-exploitation trade-off, UaE effectively solve the online BBO problem.

Performance Analyses of UaE.We prove in Theorem1 that by adopting UaE for inverse modeling to guide the selection of generated samples for solving BBO problems, we can obtain a near-optimal solution for the optimization problem defined in Equation1. Detailed discussions and proofs can be found in AppendixC, AppendixD, and AppendixE.

**Theorem 1**.: _Let \(\mathcal{Y}\) be the constructed candidate set at each iteration \(k\in[K]\) in Algorithm1. By adopting UaE as the acquisition function to guide the sample generation process in conditional diffusion model, Diff-BBO (Algorithm1) achieves a near-optimal solution for the online BBO problem defined in Equation1:_

\[\max_{y_{k}\in\mathbb{R}}\sum_{k=1}^{K}f(\bm{x}_{k}),\ \ \bm{x}_{k}\sim p_{ \theta}(\cdot\mid y_{k},\mathcal{D}),\ \ \theta\in\Theta\ \ \Rightarrow\max_{y_{k}\in\mathcal{Y}}\sum_{k=1}^{K}\alpha(y_{k}, \mathcal{D}).\]

As a result, equipped with the novel design of UaE, Diff-BBO is a theoretically sound approach utilizing inverse modeling to effectievely solve the online BBO problem.

## 3 Experiments

To validate the efficacy of Diff-BBO, we conduct experiments on six real-world online black-box optimization tasks for both continuous and discrete optimization tasks.

Dataset.We restructured \(5\) real-world tasks from Design-Bench including \(3\) continuous and \(2\) discrete tasks. In **D'Kitty** and **Ant** Morphology, the goal is to optimize for the morphology of robots. In **Superconductor**, the aim is to optimize superconducting material with a high critical temperature. **TFBind8** and **TFBind10** are discrete tasks to find a DNA sequence with maximum affinity to bind with a specified transcription factor. We also include a **Molecular Discovery** task to optimize compound's activity against a biological target with therapeutic value. For each task, we arrange the offline dataset from Krishnamoorthy et al. (2023) in ascending order based on objective values and select data from the 25th to the 50th percentile as the initial training dataset. We prioritize data with lower objective scores to better observe performance differences across each baseline. Each optimization iteration is allocated \(100\) queries to the oracle function (batch size \(N=100\)), with a total of \(16\) iterations conducted. More details of the dataset are provided in AppendixF.1.

Baselines.We compare Diff-BBO with 10 baselines, including Bayesian optimization (BO), trust region BO (TuRBO) (Eriksson et al., 2019), local latent space Bayesian optimization (LOL-BO) (Maus et al., 2022), likelihood-free BO (LFBO) (Song et al., 2022), evolutionary algorithms (Brandle, 1980; Real et al., 2019), conditioning by adaptive sampling (CbAS) (Brookes et al., 2019), and random sampling. For BO approaches, we include Gaussian Processes (GP) with Monte Carlo (MC)-based batch expected improvement (EI), MC-based batch upper confidence bound (UCB) (Wilson et al., 2017), and joint entropy search (JES (Hvarfner et al., 2022) as the acquisition functions. For LFBO, we use EI and probability of improvement (PI) as the acquisition functions.

Results.Figure2 illustrates the performance across six datasets for all baselines and our proposed algorithm. Notably, Diff-BBO consistently outperforms other baselines in both discrete and continuous settings. Specifically, in the Ant and Dkitty tasks, Diff-BBO demonstrates a significant lead over all baseline methods, starting from the very first iteration of the online optimization process. This remarkable performance can be attributed to Diff-BBO's diffusion model-based inverse modeling approach, which effectively learns the data manifold in the design space from the initial dataset, even when the initial dataset lacks data with high objective function values.

## 4 Conclusion

In this paper, we introduced Diff-BBO, an inverse modeling approach for online black-box optimization that leverages the uncertainty of conditional diffusion models. By utilizing the novel acquisition function UaE, Diff-BBO strategically proposes objective function values to improve sample efficiency. We did extensive empirical evaluations to show the superior performance of Diff-BBO. Theoretically, we prove that using UaE leads to optimal optimization solutions.

## References

* Agrawal and Goyal (2012) Agrawal, S. and Goyal, N. (2012). Analysis of thompson sampling for the multi-armed bandit problem. In _Conference on learning theory_, pages 39-1. JMLR Workshop and Conference Proceedings.
* Brindle (1980) Brindle, A. (1980). Genetic algorithms for function optimization.
* Brookes et al. (2019) Brookes, D., Park, H., and Listgarten, J. (2019). Conditioning by adaptive sampling for robust design. In _International conference on machine learning_, pages 773-782. PMLR.
* Eckmann et al. (2022) Eckmann, P., Sun, K., Zhao, B., Feng, M., Gilson, M. K., and Yu, R. (2022). Limo: Latent inceptionism for targeted molecule generation. _arXiv preprint arXiv:2206.09010_.
* Eriksson et al. (2019) Eriksson, D., Pearce, M., Gardner, J., Turner, R. D., and Poloczek, M. (2019). Scalable global optimization via local bayesian optimization. _Advances in neural information processing systems_, 32.
* Frazier (2018) Frazier, P. I. (2018). A tutorial on bayesian optimization. _arXiv preprint arXiv:1807.02811_.
* Fu and Levine (2021) Fu, J. and Levine, S. (2021). Offline model-based optimization via normalized maximum likelihood estimation. _arXiv preprint arXiv:2102.07970_.
* Gruver et al. (2024) Gruver, N., Stanton, S., Frey, N., Rudner, T. G., Hotzel, I., Lafrance-Vanasse, J., Rajpal, A., Cho, K., and Wilson, A. G. (2024). Protein design with guided discrete diffusion. _Advances in neural information processing systems_, 36.
* Hebbal et al. (2019) Hebbal, A., Brevault, L., Balesdent, M., Talbi, E.-G., and Melab, N. (2019). Bayesian optimization using deep gaussian processes. _arXiv preprint arXiv:1905.03350_.
* Ho et al. (2020) Ho, J., Jain, A., and Abbeel, P. (2020). Denoising diffusion probabilistic models. _Advances in neural information processing systems_, 33:6840-6851.
* Ho and Salimans (2022) Ho, J. and Salimans, T. (2022). Classifier-free diffusion guidance. _arXiv preprint arXiv:2207.12598_.
* Hvarfner et al. (2022) Hvarfner, C., Hutter, F., and Nardi, L. (2022). Joint entropy search for maximally-informed bayesian optimization. _Advances in Neural Information Processing Systems_, 35:11494-11506.
* Jeon and Kim (2020) Jeon, W. and Kim, D. (2020). Autonomous molecule generation using reinforcement learning and docking to develop potential novel inhibitors. _Scientific reports_, 10(1):22104.
* Karbasi et al. (2023) Karbasi, A., Kuang, N. L., Ma, Y., and Mitra, S. (2023). Langevin thompson sampling with logarithmic communication: bandits and reinforcement learning. In _International Conference on Machine Learning_, pages 15828-15860. PMLR.
* Kim et al. (2023) Kim, M., Berto, F., Ahn, S., and Park, J. (2023). Bootstrapped training of score-conditioned generator for offline design of biological sequences. _Advances in Neural Information Processing Systems_, 37.

Figure 2: Comparison of Diff-BBO with baselines for online black-box optimization. We plot the mean and standard deviation across three random seeds.

Kong, L., Du, Y., Mu, W., Neklyudov, K., De Bordol, V., Wang, H., Wu, D., Ferber, A., Ma, Y.-A., Gomes, C. P., et al. (2024). Diffusion models as constrained samplers for optimization with unknown constraints. _arXiv preprint arXiv:2402.18012_.
* Krishnamoorthy et al. (2023) Krishnamoorthy, S., Mashkaria, S. M., and Grover, A. (2023). Diffusion models for black-box optimization. In _International Conference on Machine Learning_, pages 17842-17857. PMLR.
* Kumar and Levine (2020) Kumar, A. and Levine, S. (2020). Model inversion networks for model-based optimization. _Advances in neural information processing systems_, 33:5126-5137.
* Kushner (1964) Kushner, H. J. (1964). A new method of locating the maximum point of an arbitrary multipeak curve in the presence of noise.
* Lee et al. (2023) Lee, S., Jo, J., and Hwang, S. J. (2023). Exploring chemical space with score-based out-of-distribution generation. In _International Conference on Machine Learning_, pages 18872-18892. PMLR.
* Li et al. (2024) Li, Z., Yuan, H., Huang, K., Ni, C., Ye, Y., Chen, M., and Wang, M. (2024). Diffusion model for data-driven black-box optimization. _arXiv preprint arXiv:2403.13219_.
* Lu et al. (2023) Lu, H., Qian, H., Wu, Y., Liu, Z., Zhang, Y.-L., Zhou, A., and Yu, Y. (2023). Degradation-resistant offline optimization via accumulative risk control. In _ECAI 2023_, pages 1609-1616. IOS Press.
* Maus et al. (2022) Maus, N., Jones, H., Moore, J., Kusner, M. J., Bradshaw, J., and Gardner, J. (2022). Local latent space bayesian optimization over structured inputs. _Advances in neural information processing systems_, 35:34505-34518.
* Mockus (1974) Mockus, J. (1974). On bayesian methods for seeking the extremum. In _Proceedings of the IFIP Technical Conference_, pages 400-404.
* Morris et al. (2009) Morris, G. M., Huey, R., Lindstrom, W., Sanner, M. F., Belew, R. K., Goodsell, D. S., and Olson, A. J. (2009). Autodock4 and autodocktools4: Automated docking with selective receptor flexibility. _Journal of computational chemistry_, 30(16):2785-2791.
* Noh et al. (2022) Noh, J., Jeong, D.-W., Kim, K., Han, S., Lee, M., Lee, H., and Jung, Y. (2022). Path-aware and structure-preserving generation of synthetically accessible molecules. In _International Conference on Machine Learning_, pages 16952-16968. PMLR.
* Real et al. (2019) Real, E., Aggarwal, A., Huang, Y., and Le, Q. V. (2019). Regularized evolution for image classifier architecture search. In _Proceedings of the aaai conference on artificial intelligence_, volume 33, pages 4780-4789.
* Sanchez-Lengeling and Aspuru-Guzik (2018) Sanchez-Lengeling, B. and Aspuru-Guzik, A. (2018). Inverse molecular design using machine learning: Generative models for matter engineering. _Science_, 361(6400):360-365.
* Sohl-Dickstein et al. (2015) Sohl-Dickstein, J., Weiss, E., Maheswaranathan, N., and Ganguli, S. (2015). Deep unsupervised learning using nonequilibrium thermodynamics. In _International conference on machine learning_, pages 2256-2265. PMLR.
* Song et al. (2022) Song, J., Yu, L., Neiswanger, W., and Ermon, S. (2022). A general recipe for likelihood-free bayesian optimization. In _International Conference on Machine Learning_, pages 20384-20404. PMLR.
* Song et al. (2020) Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., and Poole, B. (2020). Score-based generative modeling through stochastic differential equations. _arXiv preprint arXiv:2011.13456_.
* Stanton et al. (2022) Stanton, S., Maddox, W., Gruver, N., Maffettone, P., Delaney, E., Greenside, P., and Wilson, A. G. (2022). Accelerating bayesian optimization for biological sequence design with denoising autoencoders. In _International Conference on Machine Learning_, pages 20459-20478. PMLR.
* Tesch et al. (2013) Tesch, M., Schneider, J., and Choset, H. (2013). Expensive multiobjective optimization for robotics. In _2013 ieee international conference on robotics and automation_, pages 973-980. IEEE.
* Todorov et al. (2012) Todorov, E., Erez, T., and Tassa, Y. (2012). Mujoco: A physics engine for model-based control. In _2012 IEEE/RSJ international conference on intelligent robots and systems_, pages 5026-5033. IEEE.
* Trabucco et al. (2022) Trabucco, B., Geng, X., Kumar, A., and Levine, S. (2022). Design-bench: Benchmarks for data-driven offline model-based optimization. In _International Conference on Machine Learning_, pages 21658-21676. PMLR.
* Trabucco et al. (2015)Turner, R., Eriksson, D., McCourt, M., Kili, J., Laaksonen, E., Xu, Z., and Guyon, I. (2021). Bayesian optimization is superior to random search for machine learning hyperparameter tuning: Analysis of the black-box optimization challenge 2020. In _NeurIPS 2020 Competition and Demonstration Track_, pages 3-26. PMLR.
* Wang et al. (2018) Wang, H., Jin, Y., Sun, C., and Doherty, J. (2018). Offline data-driven evolutionary optimization using selective surrogate ensembles. _IEEE Transactions on Evolutionary Computation_, 23(2):203-216.
* Wilson et al. (2017) Wilson, J. T., Moriconi, R., Hutter, F., and Deisenroth, M. P. (2017). The reparameterization trick for acquisition functions. _arXiv preprint arXiv:1712.00424_.
* Wu et al. (2023) Wu, D., Niu, R., Chinazzi, M., Ma, Y., and Yu, R. (2023). Disentangled multi-fidelity deep bayesian active learning. In _International Conference on Machine Learning_, pages 37624-37634. PMLR.
* Zhang et al. (2021) Zhang, D., Fu, J., Bengio, Y., and Courville, A. (2021). Unifying likelihood-free inference with black-box optimization and beyond. _arXiv preprint arXiv:2110.03372_.

## Appendix A Diff-BBO algorithm

``` Input: Initial dataset \(\mathcal{D}=\{\mathbf{x},y\}\), total number of iterations \(K\), candidate feasible range \(C\), oracle function \(f(\cdot)\), batch size \(N\)
1Initialization: Conditional diffusion model \(p_{\theta}(\mathbf{x}|y)\)
2for\(k=1,2,\cdots K\)do
3 Train the conditional diffusion model with \(\mathcal{D}\)
4 Construct a candidate set \(\mathcal{Y}=\{y:0\leq y\leq C\}\)
5\(y_{k}^{*}=\operatorname*{argmax}_{y\in\mathcal{Y}}\alpha(y,\mathcal{D})\)
6 Generate \(\{\mathbf{x}_{j}\}_{j=1}^{N}\) where \(\mathbf{x}_{j}\sim p_{\theta}(\mathbf{x}\mid y_{k}^{*},\mathcal{D})\)
7 Query the oracle function \(f(\cdot)\) with generated samples \(\{\mathbf{x}_{j}\}_{j=1}^{N}\)
8\(\mathcal{D}\leftarrow\mathcal{D}\cup\{\mathbf{x}_{j},f(\mathbf{x}_{j})\}_{j=1 }^{N}\)
9\(\phi_{k}\leftarrow\max\left(f(x)\right)\ s.t.\ x\in\mathcal{D}\)
10
11
12 ```

**Algorithm 1**Diff-BBO

## Appendix B Conditional Diffusion Model Training

Diffusion Models (Sohl-Dickstein et al., 2015; Song et al., 2020) are probabilistic generative models that learn distributions through an iterative denoising process. These models consist of three components: a forward diffusion process that produces a series of noisy samples by adding Gaussian noise, a reverse process to reconstruct the original data samples from the noise, and a sampling procedure to generate new data samples from the learned distribution. Let the original sample be \(\mathbf{x}_{0}\) and \(t\) be the diffusion step. For conditional diffusion models, a conditional variable \(y\) is added to both the forward process as \(q\left(\bm{x}_{t}|\bm{x}_{t-1},y\right)\) and reverse process as \(p_{\theta}\left(\bm{x}_{t-1}\mid\bm{x}_{t},y\right),\ \forall t\in[T]\).

The reverse process begins with the standard Gaussian distribution \(p(\bm{x}_{T})=\mathcal{N}(\mathbf{0},\bm{I})\), and denoises \(\bm{x}_{t}\) to recover \(\bm{x}_{0}\) through the following Markov chain with reverse transitions:

\[p_{\theta}\left(\bm{x}_{0:T}|y\right)=p(\bm{x}_{T})\prod_{t=1}^{T }p_{\theta}\left(\bm{x}_{t-1}\mid\bm{x}_{t},y\right),\ \ \bm{x}_{T}\sim\mathcal{N}(\mathbf{0},\bm{I}),\] \[p_{\theta}\left(\bm{x}_{t-1}\mid\bm{x}_{t},y\right)=\mathcal{N} \left(\bm{x}_{t-1};\mu_{\theta}(\bm{x}_{t},t,y),\Sigma_{\theta}(\bm{x}_{t},t,y )\right).\]

During training, \(\Sigma_{\theta}\) is empirically fixed, and \(\mu_{\theta}\) is reparametrized by a trainable denoise function \(\bm{\epsilon}_{\theta}\left(\bm{x}_{t},t,y\right)\), which is used to estimate the noise vector \(\epsilon\) that was added to input \(\bm{x}_{t}\), and is trained by minimizing a reweighted version of the evidence lower bound (ELBO):

\[\mathcal{L}_{\mathrm{dif}}=\mathbb{E}_{\bm{x}_{0}\sim q\left(\bm{x} \right),y,\bm{\epsilon}\sim\mathcal{N}(0,\bm{I}),t\sim\mathcal{U}(0,T),\bm{x} _{t}\sim q\left(\bm{x}_{t}|\bm{x}_{0},y\right)}\left[w\left(t\right)\left\|\bm {\epsilon}-\bm{\epsilon}_{\theta}\left(\bm{x}_{t},t,y\right)\right\|_{2}^{2} \right].\] (5)

Note that the loss in Equation (5) (Ho et al., 2020) for \(\bm{\epsilon}_{\theta}\) is denoising score matching for all time step \(t\), which estimates the gradient of the log probability density of the noisy data (a.k.a. score function): \(\bm{\epsilon}_{\theta}\left(\bm{x}_{t},t,y\right)\approx-\sigma_{t}\nabla_{ \bm{x}}\log p(\bm{x}\mid y)\). We further denote the score function as \(s_{\theta}(\bm{x}_{t},y,t):=-\bm{\epsilon}_{\theta}\left(\bm{x}_{t},t,y\right) /\sigma_{t}\).

Instead of learning a fixed deterministic \(\theta\) from a deterministic neural network, we are interested in learning its Bayesian posterior to further understand and improve the model's performance as well as its reliability with uncertainty quantification. In Bayesian settings, we consider the model parameters \(\theta\in\Theta\), where \(\Theta\) is the parameter space, and maintain its posterior distribution \(p(\theta|\mathcal{D})\), which is learned from training data \(\mathcal{D}\). By choosing \(\theta\) from its posterior, essentially we sample a score function \(\widetilde{s}_{\theta}(\bm{x}_{t},y,t)\) from the probability distribution \(p(s_{\theta}\mid\bm{x}_{t},y,t,\mathcal{D})=\mathcal{N}(s_{\theta}(\bm{x}_{t},y,t),\Sigma_{s_{\theta}}(\bm{x}_{t},y,t))\), whose expected value is \(s_{\theta}(\bm{x}_{t},y,t)\), and variance is a diagonal covariance matrix \(\Sigma_{s_{\theta}}(\bm{x}_{t},y,t)\).

Specifically, we adopt classifier-free guidance as in (Ho and Salimans, 2022) to eliminate the requirement of training a separate classifier model. We jointly train an unconditional diffusion model \(p_{\theta}(\bm{x})\) parameterized by \(\epsilon_{\theta}(\mathbf{x},t,\emptyset)\) and a conditional diffusion model \(p_{\theta}(\bm{x}|y)\) parameterized by \(\epsilon_{\theta}(\mathbf{x},t,y)\) by minimizing the following loss function:

\[\mathcal{L}_{\mathrm{cdiff}}=\mathbb{E}_{\bm{x}_{0},y,\bm{\epsilon},t,\bm{x}_{t },\lambda}\left[w\left(t\right)\left\|\bm{\epsilon}-\bm{\epsilon}_{\theta} \left(\bm{x}_{t},t,(1-\lambda)y+\lambda\emptyset\right)\right\|_{2}^{2} \right],\] (6)where \(\bm{x}_{0}\sim q(\bm{x}),\bm{\epsilon}\sim\mathcal{N}(0,\bm{I}),t\sim\mathcal{U}(0, T),\bm{x}_{t}\sim q(\bm{x}_{t}\mid\bm{x}_{0}),\lambda\sim\mathrm{Bernoulli}(p_{ \mathrm{uncond}})\), and \(p_{\mathrm{uncond}}\) is the probability of setting \(y\) to the unconditional information \(\emptyset\). The overall Diff-BBO framework with the conditional diffusion model included in shown in Figure 3.

## Appendix C Uncertainty Quantification on Conditional Diffusion Model

Here, let us first consider the problem of how to capture the uncertainty for a fixed diffusion model. In fact, the uncertainty in generating \(\bm{x}\) can be explicitly traced through the denoising process. More specifically, Theorem 2 provides analytical solutions to compute the uncertainty on a single denoising process of general score-based conditional diffusional models. It provides theoretical insights of how uncertainty is being propagated through the reverse denoising process both in discrete time and continuous time, which is characterized through the lens of stochastic differential equations (SDEs) of the Ornstein-Uhlenbeck (OU) process.

**Theorem 2**.: _(Uncertainty propagation) Let \(t\in[T]\) be the diffusion step, \(s_{\theta}(\bm{x},y,t)\) be the score function of the corresponding diffusion model \(p_{\theta}(\bm{x}\mid y)\). For a single conditional diffusional model \(p_{\theta}(\bm{x}\mid y)\), the uncertainty in generating a sample \(\bm{x}\) can be analytically traced through the discrete-time reverse denoising process as follows:_

\[\mathrm{Var}(\bm{x}_{t-1})=\tfrac{1}{4}\mathrm{Var}(\bm{x}_{t})+\mathrm{Var}(s _{\theta}(\bm{x},y,t))+\tfrac{1}{2}\left(\mathbb{E}\left[\bm{x}_{t}\circ s_{ \theta}(\bm{x}_{t},y,t)\right]-\mathbb{E}[\bm{x}_{t}]\circ\mathbb{E}[s_{\theta }(\bm{x}_{t},y,t)]\right)+I,\]

\[\mathbb{E}(\bm{x}_{t-1})=\frac{1}{2}\mathbb{E}(\bm{x}_{t})+\mathbb{E}(s_{ \theta}(\bm{x},y,t)),\]

_where \(\circ\) is the Hadamard product, and \(I\) is the identity matrix. Similarly, in continuous-time process, the uncertainty can be captured as follows:_

\[\mathrm{Var}(\bm{x}_{0})=(T+1)I+\mathrm{Var}\left(\int_{t=0}^{T}\left(\frac{1} {2}\bm{x}_{t}+s_{\theta}(\bm{x},y,t)\right)\mathrm{d}t\right).\] (7)

Nevertheless, performing exact Bayesian inference for uncertainty quantification when training diffusion models requires non-trivial efforts and can be computationally demanding. Hence, we introduce a practically-efficient uncertainty decomposition based on Equation (2).

### Conditional Diffusion SDE

It can be shown that the conditional diffusion model can be represented by the Ornstein-Uhlenbeck (OU) process, which is a time-homogeneous continuous-time Markov process:

\[\mathrm{d}\bm{x}_{t}=-\gamma\bm{x}_{t}\,\mathrm{d}t+\sigma\,\mathrm{d}\bm{w}_ {t},\] (8)

Figure 3: Black-box optimization framework using the conditional diffusion model as the inverse model. The overall framework includes \(4\) stages. 1. Train the conditional diffusion model given the current training dataset. 2. Compute the acquisition function and select the optimal \(y^{*}\) to condition on. 3. Generate samples \(\{\bm{\mathrm{x}}_{0}\}\) conditioned on \(y^{*}\). 4. Query the oracle given generated samples \(\{\bm{\mathrm{x}}_{0}\}\) and update the training dataset.

where \(\gamma\) is the relaxation rate, \(\sigma\) is the strength of fluctuation, and \(\bm{w}_{t}\) is the standard Wiener process (a.k.a., Brownian motion). Both \(\gamma\) and \(\sigma\) are time-invariant. In particular, setting \(\gamma=1\) and \(\sigma=\sqrt{2}\), we are able to establish that Denoising Diffusion Probabilistic Model (DDPM) is equivalent to OU process observed at discrete times. In the remaining text, we consider SDEs for general score-based diffusion models. The SDE of the forward process in conditional diffusion model can then be written as:

\[\mathrm{d}\bm{x}_{t}=-\frac{1}{2}g(t)\bm{x}_{t}\,\mathrm{d}t+\sqrt{g(t)}\, \mathrm{d}\bm{w}_{t},\ \ \bm{x}_{0}\sim q(\bm{x}|y)\] (9)

where \(g(t)\) is a nondecreasing weighting function that controls the speed of diffusion in the forward process and \(g(t)>0\). For simplicity of analysis, we fix \(g(t)=1\) for all \(t\in[T]\).

The generation process of a conditional score-based diffusion model can be viewed as a particular discretization of the following reverse-time SDE:

\[\mathrm{d}\bm{x}_{t}=\left(\frac{1}{2}\bm{x}_{t}-\nabla_{\bm{x}_{t}}\log p( \bm{x}_{t}|y)\right)\mathrm{d}t+\mathrm{d}\bm{w}_{t},\ \ \bm{x}_{0}\sim p(\bm{x}_{T}|y).\] (10)

In practice, the unknown ground truth conditional score \(\nabla_{\bm{x}_{t}}\log p(\bm{x}_{t}|y)\) needs to be estimated with score networks. Let such estimator denoted by \(s_{\theta}(\bm{x},y,t)\), then the conditional sample generation is to simulate the following backward SDE:

\[\mathrm{d}\bm{x}_{t}=\left(\frac{1}{2}\bm{x}_{t}-s_{\theta}(\bm{x},y,t)\right) \mathrm{d}t+\mathrm{d}\bm{w}_{t},\ \ \bm{x}_{0}\sim\mathcal{N}(\bm{0},\bm{I}).\] (11)

In Bayesian settings, we sample a score function \(\widetilde{s}_{\theta}(\bm{x}_{t},y,t)\) from the probability distribution \(p(s_{\theta}|\bm{x}_{t},y,t,\mathcal{D})=\mathcal{N}(s_{\theta}(\bm{x}_{t},y,t ),\Sigma_{\theta}(\bm{x}_{t},y,t))\) with expected value \(s_{\theta}(\bm{x}_{t},y,t)\), and diagonal covariance \(\Sigma_{\theta}(\bm{x}_{t},y,t)\).

### Estimation of Uncertainty

In this section, we quantify the uncertainty of a single conditional diffusion model in both discrete-time and continuous-time reverse process for Theorem2.

#### c.2.1 Uncertainty in Discrete-time Reverse Process

We first proof the first statement of Theorem2. We consider the Euler discretization of Equation11, which leads to:

\[\bm{x}_{t-1}=\frac{1}{2}\bm{x}_{t}+s_{\theta}(\bm{x},y,t)+\bm{\epsilon},\ \ \epsilon\sim\mathcal{N}(\bm{0},\bm{I}).\] (12)

We thus have,

\[\mathrm{Var}(\bm{x}_{t-1}) =\frac{1}{4}\mathrm{Var}(\bm{x}_{t})+\mathrm{Var}(s_{\theta}(\bm{ x},y,t))+\frac{1}{2}\mathrm{Cov}\left(\bm{x}_{t},s_{\theta}(\bm{x},y,t)\right)+I.\] (13) \[\mathbb{E}(\bm{x}_{t-1}) =\frac{1}{2}\mathbb{E}(\bm{x}_{t})+\mathbb{E}(s_{\theta}(\bm{x}, y,t)).\] (14)

Here \(\mathrm{Cov}\left(\bm{x}_{t},s_{\theta}(\bm{x},y,t)\right)\) is the element-wise covariance between \(\bm{x}_{t}\) and \(s_{\theta}(\bm{x},y,t)\). Note that we only need to consider the correlation between \(\bm{x}_{t}\) and \(s_{\theta}(\bm{x},y,t)\) at the same time step. As a result, to estimate \(\mathrm{Cov}\left(\bm{x}_{t},s_{\theta}(\bm{x},y,t)\right)\), we have,

\[\mathrm{Cov}\left(\bm{x}_{t},s_{\theta}(\bm{x},y,t)\right) =\mathbb{E}\left[\left(\bm{x}_{t}-\mathbb{E}[\bm{x}_{t}]\right) \left(s_{\theta}(\bm{x},y,t)-\mathbb{E}[s_{\theta}(\bm{x},y,t)]\right)^{ \mathrm{T}}\right]\] \[=\mathbb{E}\left[\bm{x}_{t}\circ s_{\theta}(\bm{x},y,t)\right]- \mathbb{E}[\bm{x}_{t}]\circ\mathbb{E}[s_{\theta}(\bm{x},y,t)]\] \[=\mathbb{E}_{\bm{x}_{t}}\left[\bm{x}_{t}\circ s_{\theta}(\bm{x},y,t)\right]-\mathbb{E}[\bm{x}_{t}]\circ\mathbb{E}_{\bm{x}_{t}}[s_{\theta}(\bm {x}_{t},y,t)]\] (15)

where \(\circ\) is the Hadamard product and the third equality is by tower's rule. Substituting Equation15 back to Equation13 completes the proof of the first part of Theorem2.

#### c.2.2 Uncertainty in Continuous-time Reverse Process

We now proof the second statement of Theorem2. To perform the uncertainty quantification for the continuous-time reverse process, we posit the following assumption.

**Assumption 1**.: _For valid \(t\in[0,T]\), the generating process \(\bm{x}_{t}\) in Equation10 is integrable and has finite second-order moments._With Assumption 1, integrating Equation (10) with respect to \(t\) yields:

\[\bm{x}_{0}=\bm{x}_{T}-\int_{t=0}^{T}\left(\frac{1}{2}\bm{x}_{t}+\nabla_{\bm{x}_{ t}}\log p(\bm{x}_{t}|y)\right)\mathrm{d}t+\int_{t=0}^{T}\mathrm{d}\bm{w}_{t}.\] (16)

Applying the variance operator to both sides of

\[\mathrm{Var}(\bm{x}_{0}) =\mathrm{Var}(\bm{x}_{T})+\mathrm{Var}\left(\int_{t=0}^{T}\left( \frac{1}{2}\bm{x}_{t}+\nabla_{\bm{x}_{t}}\log p(\bm{x}_{t}|y)\right)\mathrm{d}t \right)+\mathrm{Var}\left(\int_{t=0}^{T}\mathrm{d}\bm{w}_{t}\right)\] \[=I+\mathrm{Var}\left(\int_{t=0}^{T}\left(\frac{1}{2}\bm{x}_{t}+ \nabla_{\bm{x}_{t}}\log p(\bm{x}_{t}|y)\right)\mathrm{d}t\right)+\mathbb{E} \left[\left(\int_{t=0}^{T}\mathrm{d}\bm{w}_{t}\right)^{2}\right]-\left(\mathbb{ E}\left[\int_{t=0}^{T}\mathrm{d}\bm{w}_{t}\right]\right)^{2}\] \[=(T+1)I+\underbrace{\mathrm{Var}\left(\int_{t=0}^{T}\left(\frac{ 1}{2}\bm{x}_{t}+\nabla_{\bm{x}_{t}}\log p(\bm{x}_{t}|y)\right)\mathrm{d}t \right)}_{\text{$Y_{1}$}},\] (17)

where the last equality follows the properties of Ito Integral and rules of stochastic calculus such that \((\mathrm{d}\bm{w})^{2}=\mathrm{d}t\), \(\mathbb{E}[\int_{t=0}^{T}\mathrm{d}\bm{w}_{t}]=0\). Hence, to provide an uncertainty estimate for \(\bm{x}_{0}\), it remains to estimate the term \(V_{1}\). Recall that the true score function \(\nabla_{\bm{x}_{t}}\log p(\bm{x}_{t}|y)\) is approximated by \(s_{\theta}((\bm{x}_{t},y,t)=-\bm{\epsilon}_{\theta}(\bm{x}_{t},t,y)/\sigma_{t}\). For ease of notation, let \(s_{\theta,t}=s_{\theta}(\bm{x}_{t},y,t)\) and \(\widetilde{s}_{\theta,t}=\widetilde{s}_{\theta}(\bm{x}_{t},y,t)\), which gives

\[V_{1}=\int_{t=0}^{T}\int_{s=0}^{T}\left(\frac{1}{4}\mathrm{Cov}(\bm{x}_{s}, \bm{x}_{t})-\frac{1}{2}\mathrm{Cov}(\bm{x}_{s},s_{\theta,t})-\frac{1}{2} \mathrm{Cov}(\bm{x}_{t},s_{\theta,s})+\mathrm{Cov}(s_{\theta,t},s_{\theta,s}) \right)\mathrm{d}s\,\mathrm{d}t.\]

When \(s\neq t\), score functions \(s_{\theta,t}\) and \(s_{\theta,s}\) are independent, and similarly, \(\bm{x}_{t}\) and \(s_{\theta,s}\) are also independent. As a result, the above equation can be further simplified as

\[V_{1}=\int_{t=0}^{T}\int_{s=0}^{T}\left(\frac{1}{4}\mathrm{Cov}(\bm{x}_{s},\bm {x}_{t})-\frac{1}{2}\mathrm{Cov}(\bm{x}_{s},s_{\theta,t})\right)\mathrm{d}s\, \mathrm{d}t-\int_{t=0}^{T}\left(\mathrm{Cov}(\bm{x}_{t},s_{\theta,t})+\mathrm{ Cov}(s_{\theta,t},s_{\theta,t})\right)\mathrm{d}t.\]

Combining all the above results together completes the proof of the second statement of Theorem 2.

## Appendix D Performance Analysis of UaE

To quantify the quality of generated samples, we theoretically analyze the sub-optimality performance gap between \(y_{k}^{*}\) and reconstructed value at each iteration. In particular, Theorem 3 and Theorem 4 demonstrate that such sub-optimality gap can be effectively handled in inverse modeling, with proofs deferred to Appendix D.1. We first show that by using conditional diffusion model, the expected error of the sub-optimality performance gap is zero.

**Theorem 3**.: _At each iteration \(k\in[K]\), define the sub-optimality performance gap as_

\[\Delta(p_{\theta},y_{k}^{*})=\left|y_{k}^{*}-\max_{j\in[N]}f(\bm{x}_{j}) \right|,\ \ \mathrm{where}\ \bm{x}_{j}\sim p_{\theta}(\cdot|y_{k}^{*},\mathcal{D}),\ \ \forall j\in[N].\] (18)

_Assume that there exists some \(\theta^{*}\sim p(\theta|\mathcal{D})\) that produces a predictive distribution \(p_{\theta^{*}}\left(\cdot\mid\mathcal{D}\right)\) such that it is able to generate a sample \(\bm{x}^{*}\) that perfectly reconstructs \(y_{k}^{*}\). Suppose function \(f\) is \(L\)-Lipschitz and each sample is \(\sigma\)-subGaussian, it can be shown that_

\[\mathbb{E}\left[\Delta(p_{\theta},y_{k}^{*})\right]\leq c_{1}L\sqrt{d}\sigma,\]

_where \(c_{1}\) is some universal constant and the empirical estimator \(\widehat{\mathbb{E}}\left[\Delta(p_{\theta},y_{k}^{*})\right]\) is unbiased._

Theorem 3 suggests that in expectation, the reconstructed function value \(\max_{j\in[N]}f(\bm{x}_{j})\) is able to accurately recover the provided conditional information \(y_{k}^{*}\). Hence, in order to obtain a reasonable estimator for the optimization problem, the remaining concern goes to the variance of the gap defined in Equation (18), which is further evaluated in Theorem 4.

**Theorem 4**.: _(Sub-optimality bound) At each iteration \(k\in[K]\), suppose \(M\) model parameters \(\{\theta_{i}\}_{i=1}^{M}\) are generated from the ensemble model for some fixed dataset \(\mathcal{D}\). Suppose function \(f\) is \(L\)-Lipschitz, it can be shown that the variance of the sub-optimality performance gap of each model is bounded by the epidemic uncertainty:_

\[\mathrm{Var}\left(\Delta(p_{\theta_{i}},y_{k}^{*})\right)\leq c_{2}L^{2}d \sigma^{2}+c_{2}L^{2}\Delta_{\mathrm{epistemic}}(y_{k}^{*},\mathcal{D}),\ \ \forall i\in M,\] (19)

_where \(c_{2}\) is some universal positive constant._

Theorem 4 shows that the variance of the sub-optimality performance gap can be upper bounded by the epistemic uncertainty of diffusion model. Therefore, our proposed acquisition function achieves the balance between high objective value and low epistemic uncertainty.

### Analysis of Sub-optimality

In this section, we study the behavior of the sub-optimality gap of our algorithm by proving Theorem 3 and Theorem 4. We first introduce the notation that is used throughout this section and the next section. Then we present the main lemmas along with their proofs. Finally, we combine the lemmas to prove our main results.

At each iteration \(k\in[K]\), let \(y_{k}^{*}\) be the target function value on which the diffusion model conditions, and \(p_{\theta}\) be the model learned by the conditional diffusion model. We define the performance metric for online BBO problem, which measures the sub-optimal performance gap between the function value achieved by sample \(\bm{x}\sim p_{\theta}(\cdot|y_{k}^{*},\mathcal{D})\) and the target function value \(y_{k}^{*}\). Its formal definition is described as follows:

\[\Delta(p_{\theta},y_{k}^{*})=\left|y_{k}^{*}-\max_{j\in[N]}f(\bm{x}_{j}) \right|,\ \ \text{where}\ \ \bm{x}_{j}\sim p_{\theta}(\cdot|y_{k}^{*},\mathcal{D}),\ \ \forall j\in[N].\] (20)

For simplicity of analysis, we consider \(N=1\), and let the generated sample at the \(k\)-th iteration be \(\bm{x}_{k}\) in the remaining text. We remark that all proofs go through smoothly for general \(N\) with more nuanced notations, and do not affect the conclusions being drawn. To proceed with the proofs in this section, we first state the formal assumptions for the black-box function \(f(\cdot)\) and sample \(\bm{x}\).

**Assumption 2**.: _The scalar black-box function \(f\) is L-Lipschitz in \(\bm{x}\):_

\[|f(\bm{x}^{\prime})-f(\bm{x})|\leq L\|\bm{x}^{\prime}-\bm{x}\|,\ \ \forall\bm{x}^{\prime},\bm{x}\in\mathbb{R}^{d}.\]

**Assumption 3**.: _Each generated sample \(\bm{x}\in\mathbb{R}^{d}\) is \(\sigma\)-subGaussian. That is, there exists \(\sigma\in\mathbb{R}\) such that for any \(\bm{v}\in\mathbb{R}^{d}\) with \(\|\bm{v}\|=1\), \(\bm{v}^{\mathrm{T}}(\bm{x}-\mathbb{E}[\bm{x}])\) is \(\sigma\)-subGaussian, and its moment generating function is bounded by:_

\[\mathbb{E}[\exp\big{(}\lambda\bm{v}^{\mathrm{T}}(\bm{x}-\mathbb{E}[\bm{x}]) \big{)}]\leq\exp\bigg{(}\frac{\sigma^{2}\lambda^{2}}{2}\bigg{)},\quad\forall \lambda\in\mathbb{R},\ \bm{v}\in\mathbb{S}^{d-1},\]

_where \(\mathbb{S}:=\{\bm{v}\in\mathbb{R}^{d}:\|\bm{v}\|=1\}\) is the \((d-1)\) unit sphere._

Before proceeding with the proofs of main theorems, we present our main lemmas.

**Lemma D.1**.: _At each iteration \(k\in[K]\), under fixed parameters \(\theta\) and \(\theta^{*}\), for \(\bm{x}_{k}\sim p_{\theta}(\cdot|y_{k}^{*},\mathcal{D})\), \(\bm{x}^{*}\sim p_{\theta^{*}}(\cdot|y_{k}^{*},\mathcal{D})\), be have_

\[\mathbb{E}_{\bm{x}_{k}\sim p_{\theta}(\cdot|y_{k}^{*},\mathcal{D} ),\bm{x}^{*}\sim p_{\theta^{*}}(\cdot|y_{k}^{*},\mathcal{D})}\left[\|\bm{x}^{ *}-\bm{x}_{k}\|\right] \leq 8\sqrt{d}\sigma+\left\|\mathbb{E}_{\bm{x}^{*}}[\bm{x}^{*}]- \mathbb{E}_{\bm{x}_{k}}[\bm{x}_{k}]\right\|,\] (21) \[\mathbb{E}_{\bm{x}_{k}\sim p_{\theta}(\cdot|y_{k}^{*},\mathcal{D} ),\bm{x}^{*}\sim p_{\theta}(\cdot|y_{k}^{*},\mathcal{D})}\left[\|\bm{x}^{*}- \bm{x}_{k}\|\right] \geq\left\|\mathbb{E}_{\bm{x}^{*}}[\bm{x}^{*}]-\mathbb{E}_{\bm{x}_{k}}[ \bm{x}_{k}]\right\|.\] (22)

Proof of Lemma D.1.: To bound \(\mathbb{E}\left[\|\bm{x}^{*}-\bm{x}_{k}\|\right]\), by triangle inequality,

\[\mathbb{E}_{\bm{x}_{k},\bm{x}^{*}}\left[\|\bm{x}^{*}-\bm{x}_{k}\| \right] =\mathbb{E}\left[\|\bm{x}^{*}-\mathbb{E}[\bm{x}^{*}]+\mathbb{E}[ \bm{x}_{k}]-\bm{x}_{k}+\mathbb{E}[\bm{x}^{*}]-\mathbb{E}[\bm{x}_{k}]\|\right]\] \[\leq\mathbb{E}\left[\|\bm{x}^{*}-\mathbb{E}[\bm{x}^{*}]\|\right]+ \mathbb{E}\left[\|\bm{x}_{k}-\mathbb{E}[\bm{x}_{k}]\|\right]+\mathbb{E} \left[\|\mathbb{E}[\bm{x}^{*}]-\mathbb{E}[\bm{x}_{k}]\|\right].\]

Under assumption 3, by Lemma D.3, we have,

\[\mathbb{E}_{\bm{x}_{k},\bm{x}^{*}}\left[\|\bm{x}^{*}-\bm{x}_{k}\|\right]\leq 8\sqrt{d}\sigma+\left\|\mathbb{E}[\bm{x}^{*}]- \mathbb{E}[\bm{x}_{k}]\right\|.\]

Applying triangle inequality completes the step. In addition, it can be easily seen that

\[\mathbb{E}_{\bm{x}_{k},\bm{x}^{*}}\left[\|\bm{x}^{*}-\bm{x}_{k}\|\right]\geq\left\| \mathbb{E}[\bm{x}^{*}]-\mathbb{E}[\bm{x}_{k}]\right\|.\]

**Lemma D.2**.: _At each iteration \(k\in[K]\), under fixed parameters \(\theta\) and \(\theta^{*}\), for \(\bm{x}_{k}\sim p_{\theta}(\cdot|y_{k}^{*},\mathcal{D})\), \(\bm{x}^{*}\sim p_{\theta^{*}}(\cdot|y_{k}^{*},\mathcal{D})\), we have_

\[\operatorname{Var}_{\bm{x}_{k}\sim p_{\theta}(\cdot|y_{k}^{*},\mathcal{D}),\bm {x}^{*}\sim p_{\theta^{*}}(\cdot|y_{k}^{*},\mathcal{D})}(\|\bm{x}^{*}-\bm{x}_{ k}\|)\leq c_{3}d\sigma^{2}.\] (23)

Proof of Lemma d.2.: By definition of variance,

\[\operatorname{Var}_{\bm{x}_{k},\bm{x}^{*}}(\|\bm{x}^{*}-\bm{x}_{k}\|)=\mathbb{ E}[\|\bm{x}^{*}-\bm{x}_{k}\|^{2}]-(\mathbb{E}[\|\bm{x}^{*}-\bm{x}_{k}\|])^{2}.\] (24)

Expanding the first term leads to

\[\mathbb{E}[\left\|\bm{x}^{*}-\bm{x}_{k}\right\|^{2}] =\mathbb{E}[(\bm{x}^{*}-\bm{x}_{k})^{\mathrm{T}}(\bm{x}^{*}-\bm{x }_{k})]\] \[=\mathbb{E}[\left\|\bm{x}^{*}\right\|^{2}]+\mathbb{E}[\|\bm{x}_{k }\|^{2}]-2\mathbb{E}[(\bm{x}_{k})^{\mathrm{T}}\bm{x}^{*}]\] \[=\mathbb{E}[\left\|\bm{x}^{*}\right\|^{2}]+\mathbb{E}[\left\|\bm{ x}_{k}\right\|^{2}]-2\mathbb{E}[(\bm{x}_{k})]^{\mathrm{T}}\mathbb{E}[\bm{x}^{*}],\] (25)

where the last equality is due to the independece between \(\bm{x}^{*}\) and \(\bm{x}_{k}\).

Under Assumption 3 and by Lemma D.4, we have

\[\mathbb{E}[\left\|\bm{x}^{*}\right\|^{2}] =\mathbb{E}[\left\|\bm{x}^{*}-\mathbb{E}[\bm{x}^{*}]+\mathbb{E}[ \bm{x}^{*}]\right\|^{2}]\] \[=\mathbb{E}[(\bm{x}^{*}-\mathbb{E}[\bm{x}^{*}])^{\mathrm{T}}(\bm {x}^{*}-\mathbb{E}[\bm{x}^{*}])]+\left\|\mathbb{E}[\bm{x}^{*}]\right\|^{2}\] \[=\operatorname{tr}(\mathbb{E}[(\bm{x}^{*}-\mathbb{E}[\bm{x}^{*}]) (\bm{x}^{*}-\mathbb{E}[\bm{x}^{*}])]^{\mathrm{T}})+\left\|\mathbb{E}[\bm{x}^{* }]\right\|^{2}\] \[\leq Cd\sigma^{2}+\left\|\mathbb{E}[\bm{x}^{*}]\right\|^{2}.\]

Here, the second equality holds as the cross terms vanish due to the fact that \(\mathbb{E}[\bm{x}^{*}-\mathbb{E}[\bm{x}^{*}]]=0\). Similarly,

\[\mathbb{E}[\left\|\bm{x}_{k}\right\|^{2}]\leq Cd\sigma^{2}+\left\|\mathbb{E}[ \bm{x}_{k}]\right\|^{2}.\]

Substituting the above two results back to Equation (25),

\[\mathbb{E}[\left\|\bm{x}^{*}-\bm{x}_{k}\right\|^{2}] \leq 2Cd\sigma^{2}+\left\|\mathbb{E}[\bm{x}_{k}]\right\|^{2}+ \left\|\mathbb{E}[\bm{x}^{*}]\right\|^{2}-2\mathbb{E}[(\bm{x}_{k})^{\mathrm{T }}\bm{x}^{*}]\] \[\leq 2Cd\sigma^{2}+\left\|\mathbb{E}[\bm{x}_{k}]-\mathbb{E}[\bm{x} ^{*}]\right\|^{2}.\] (26)

Substituting Equation (26) back to Equation (24) and applying Lemma D.1 leads to

\[\operatorname{Var}_{\bm{x}_{k},\bm{x}^{*}}(\|\bm{x}^{*}-\bm{x}_{k}\|)\leq 2 Cd\sigma^{2}+\left\|\mathbb{E}[\bm{x}_{k}]-\mathbb{E}[\bm{x}^{*}]\right\|^{2}- (8\sqrt{d}\sigma+\left\|\mathbb{E}[\bm{x}^{*}]-\mathbb{E}[\bm{x}_{k}]\right\|) ^{2}\leq c_{3}d\sigma^{2}.\]

With the above results, we are ready to prove Theorem 3 and Theorem 4.

**Theorem 3**.: _At each iteration \(k\in[K]\), define the sub-optimality performance gap as_

\[\Delta(p_{\theta},y_{k}^{*})=\left|y_{k}^{*}-\max_{j\in[N]}f(\bm{x}_{j}) \right|,\ \ \mathrm{where}\ \ \bm{x}_{j}\sim p_{\theta}(\cdot|y_{k}^{*},\mathcal{D}),\ \ \forall j\in[N].\] (18)

_Assume that there exists some \(\theta^{*}\sim p(\theta|\mathcal{D})\) that produces a predictive distribution \(p_{\theta^{*}}(\cdot\mid\mathcal{D})\) such that it is able to generate a sample \(\bm{x}^{*}\) that perfectly reconstructs \(y_{k}^{*}\). Suppose function \(f\) is \(L\)-Lipschitz and each sample is \(\sigma\)-subGaussian, it can be shown that_

\[\mathbb{E}\left[\Delta(p_{\theta},y_{k}^{*})\right]\leq c_{1}L\sqrt{d}\sigma,\]

_where \(c_{1}\) is some universal constant and the empirical estimator \(\widehat{\mathbb{E}}\left[\Delta(p_{\theta},y_{k}^{*})\right]\) is unbiased._

Proof of Theorem 3.: Recall that we consider the case where \(N=1\), and denote \(\bm{x}_{k}\) the generated sample in the \(k\)-th iteration, i.e. \(\bm{x}_{k}\sim p_{\theta}(\cdot|y_{k}^{*},\mathcal{D})\), where \(\theta\sim p(\theta\mid\mathcal{D})\). In each iteration \(k\), with the existence of \(\theta^{*}\sim p(\theta\mid\mathcal{D})\), we have \(y_{k}^{*}=f(\bm{x}^{*})\), where \(\bm{x}^{*}\sim p_{\theta^{*}}(\cdot|y_{k}^{*},\mathcal{D})\). Hence, under Assumption 2,

\[\mathbb{E}\left[\Delta(p_{\theta},y_{k}^{*})\right]=\mathbb{E}\left[\left|f( \bm{x}^{*})-f(\bm{x}_{k})\right|\right]\leq L\mathbb{E}\left[\left\|\bm{x}^{*}- \bm{x}_{k}\right\|\right].\]

By Lemma D.1, we have

\[\mathbb{E}\left[\Delta(p_{\theta},y_{k}^{*})\right]\leq 8L\sqrt{d}\sigma+ \mathbb{E}_{\theta,\theta^{*}}\left[\left\|\mathbb{E}[\bm{x}^{*}]-\mathbb{E}[ \bm{x}_{k}]\right\|\right].\]

**Theorem 4**.: _(Sub-optimality bound) At each iteration \(k\in[K]\), suppose \(M\) model parameters \(\{\theta_{i}\}_{i=1}^{M}\) are generated from the ensemble model for some fixed dataset \(\mathcal{D}\). Suppose function \(f\) is \(L\)-Lipschitz, it can be shown that the variance of the sub-optimality performance gap of each model is bounded by the epidemic uncertainty:_

\[\mathrm{Var}\left(\Delta(p_{\theta_{i}},y_{k}^{*})\right)\leq c_{2}L^{2}d \sigma^{2}+c_{2}L^{2}\Delta_{\mathrm{epistemic}}(y_{k}^{*},\mathcal{D}),\ \ \forall i\in M,\] (19)

_where \(c_{2}\) is some universal positive constant._

Proof of Theorem 4.: At every iteration \(k\in[K]\), let the target function value on which the conditional diffusion model conditions be \(y_{k}^{*}\). The statement needs to hold for each conditional diffusion model in the ensemble, and thus for simplicity of notation, the subscript \(i\) of \(\theta_{i}\) is dropped in the remaining proof. With the existence of \(\theta^{*}\sim p(\theta\mid\mathcal{D})\), we have \(y_{k}^{*}=f(\bm{x}^{*})\), where \(\bm{x}^{*}\sim p_{\theta^{*}}(\cdot|y_{k}^{*},\mathcal{D})\). Recall that \(f(\bm{x}_{k})\) is achieved by \(\bm{x}_{k}\sim p_{\theta}(\cdot|y_{k}^{*},\mathcal{D})\), where \(\theta\sim p(\theta\mid\mathcal{D})\), and \(N=1\).

Thus, by Eve's law, the overall variance of \(\Delta(p_{\theta},y_{k}^{*})\) can be decomposed as:

\[\mathrm{Var}\left(\Delta(p_{\theta},y_{k}^{*})\right) =\mathrm{Var}\left(|y_{k}^{*}-f(\bm{x}_{k})|\right)\] \[=\mathrm{Var}\left(|f(\bm{x}^{*})-f(\bm{x}_{k})|\right)\] \[=\underbrace{\mathbb{E}_{\theta,\theta^{*}}\left[\mathrm{Var}_{ \bm{x}_{k},\bm{x}^{*}}(|f(\bm{x}^{*})-f(\bm{x}_{k})|\mid\theta,\theta^{*}) \right]}_{T_{1}}+\underbrace{\mathrm{Var}_{\theta,\theta^{*}}(\mathbb{E}_{\bm {x}_{k},\bm{x}^{*}}[|f(\bm{x}^{*})-f(\bm{x}_{k})|\mid\theta,\theta^{*}])}_{T_ {2}}.\]

In particular, the first term \(T_{1}\) corresponds to the aleatoric component and the second term \(T_{2}\) corresponds to the episemic component. We then proceed to bound the above two terms separately.

**Step 1: bound \(T_{1}\).** Under Assumption 2,

\[\mathrm{Var}_{\bm{x}_{k},\bm{x}^{*}}(|f(\bm{x}^{*})-f(\bm{x}_{k})|\mid\theta, \theta^{*})\leq L^{2}\mathrm{Var}_{\bm{x}_{k},\bm{x}^{*}}(\|\bm{x}^{*}-\bm{x} _{k}\|\mid|\theta,\theta^{*}).\]

Under Assumption 3 and by Lemma D.2,

\[T_{1}\leq L^{2}\mathbb{E}_{\theta,\theta^{*}}[\mathrm{Var}_{\bm{x}_{k},\bm{x} ^{*}}(\|\bm{x}^{*}-\bm{x}_{k}\|\mid|\theta,\theta^{*})]\leq c_{3}L^{2}d\sigma ^{2}.\] (27)

**Step 2: bound \(T_{2}\).** Under Assumption 2,

\[T_{2}\leq L^{2}\mathrm{Var}_{\theta,\theta^{*}}(\mathbb{E}_{\bm{x}_{k},\bm{x} ^{*}}[\|\bm{x}^{*}-\bm{x}_{k}\|\mid|\theta,\theta^{*}]))\]

By Lemma D.1,

\[\mathrm{Var}_{\theta,\theta^{*}}(\mathbb{E}_{\bm{x}_{k},\bm{x}^{* }}[|f(\bm{x}^{*})-f(\bm{x}_{k})|\mid\theta,\theta^{*}]) \leq\mathrm{Var}_{\theta,\theta^{*}}\left(\mathbb{E}_{\theta, \theta^{*}}\left[8\sqrt{d}\sigma+\|\mathbb{E}_{\bm{x}^{*}}[\bm{x}^{*}]- \mathbb{E}_{\bm{x}_{k}}[\bm{x}_{k}]\|\right]\right)\] \[\leq\mathrm{Var}_{\theta,\theta^{*}}\left(\|\mathbb{E}_{\bm{x}^{* }}[\bm{x}^{*}]-\mathbb{E}_{\bm{x}_{k}}[\bm{x}_{k}]\|\right).\]

Then by property of variance, we have

\[\mathrm{Var}_{\theta,\theta^{*}}\left(\|\mathbb{E}_{\bm{x}^{*}}[\bm{x}^{*}]- \mathbb{E}_{\bm{x}_{k}}[\bm{x}_{k}]\|\right)=\mathbb{E}_{\theta,\theta^{*}} \left[\|\mathbb{E}_{\bm{x}^{*}}[\bm{x}^{*}]-\mathbb{E}_{\bm{x}_{k}}[\bm{x}_{k }]\|^{2}\right]-\left(\mathbb{E}_{\theta,\theta^{*}}\Big{[}\left\|\mathbb{E}_ {\bm{x}^{*}}[\bm{x}^{*}]-\mathbb{E}_{\bm{x}_{k}}[\bm{x}_{k}]\right\|\Big{]} \right)^{2}.\]

From the proof of Lemma D.2, we have

\[\mathbb{E}_{\theta,\theta^{*}}\Big{[}\|\mathbb{E}_{\bm{x}^{*}}[ \bm{x}^{*}|\theta^{*}]-\mathbb{E}_{\bm{x}_{k}}[\bm{x}_{k}|\theta]\|^{2}\, \Big{]}\] \[=\mathbb{E}_{\theta^{*}}[\mathbb{E}_{\bm{x}^{*}}[\|\bm{x}^{*}\|^{ 2}\,|\theta^{*}]]+\mathbb{E}_{\theta}[\mathbb{E}_{\bm{x}_{k}}[\|\bm{x}_{k}\|^{ 2}\,|\theta]]-2\mathbb{E}_{\theta,\theta^{*}}[\mathbb{E}_{\bm{x}_{k}}[(\bm{x }_{k}|\theta)]^{\top}\mathbb{E}_{\bm{x}^{*}}[\bm{x}^{*}|\theta^{*}]]\] \[=2(\mathbb{E}_{\theta}[\mathbb{E}_{\bm{x}_{k}}[\|\bm{x}_{k}\|^{2} \,|\theta])-\mathbb{E}_{\theta,\theta^{*}}[\mathbb{E}_{\bm{x}_{k}}[(\bm{x}_{k}| \theta)]^{\top}\mathbb{E}_{\bm{x}^{*}}[\bm{x}^{*}|\theta^{*}]])\]

Combining the above results, we have

\[T_{2}\leq L^{2}\mathrm{Var}_{\theta,\theta^{*}}\left(\|\mathbb{E}_{\bm{x}^{*}}[ \bm{x}^{*}]-\mathbb{E}_{\bm{x}_{k}}[\bm{x}_{k}]\|\right)\leq 2L^{2}\mathrm{Var}_{\theta}( \mathbb{E}_{\bm{x}_{k}}[\bm{x}_{k}]).\] (28)

Combining Equation (27) and Equation (28) completes the proof:

\[\mathrm{Var}\left(\Delta(p_{\theta},y_{k}^{*})\right)\leq c_{3}L^{2}d\sigma^{2}+ 2L^{2}\mathrm{Var}_{\theta}(\mathbb{E}_{\bm{x}}[\|\bm{x}_{k}\|]).\]

### Supporting Lemmas

**Lemma D.3**.: _Let \(\bm{x}\in\mathbb{R}^{d}\) be a \(\sigma\)-subGaussian random vector, then_

\[\mathbb{E}[\left\|\bm{x}-\mathbb{E}[\bm{x}]\right\|]\leq 4\sigma\sqrt{d}.\] (29)

**Lemma D.4**.: _Let \(\bm{x}\in\mathbb{R}^{d}\) be a \(\sigma\)-subGaussian random vector, then its variance satisfies:_

\[\text{Var}[\bm{x}]\leq Cd\sigma^{2},\] (30)

_where \(C\) is some positive constant._

Proof of lemma d.4.: By definition of sub-Gaussian vector, for any direction \(\bm{u}\in\mathbb{R}^{d}\) with \(\left\|\bm{u}\right\|=1\),

\[\mathbb{E}\left[\exp(\lambda\bm{u}^{\mathrm{T}}(\bm{x}-\mathbb{E}[\bm{x}])) \right]\leq\exp\left(\frac{\lambda^{2}\sigma^{2}}{2}\right),\ \ \forall\lambda\in \mathbb{R}.\]

This implies that the second moment in any direction \(\bm{u}\) satisfies:

\[\mathbb{E}\left[\bm{u}^{\mathrm{T}}((\bm{x}-\mathbb{E}[\bm{x}])(\bm{x}- \mathbb{E}[\bm{x}])^{\mathrm{T}})\right]\leq\sigma^{2}.\]

Therefore, the maximum eigenvalue of the covariance matrix is upper-bounded by \(C\sigma^{2}\), where \(C\) is some positive constant.

\[\text{Var}[\bm{x}]=\text{tr}\left(\mathbb{E}\left[(\bm{x}-\mathbb{E}[\bm{x}]) (\bm{x}-\mathbb{E}[\bm{x}])^{\mathrm{T}}\right]\right)\leq Cd\sigma^{2}.\]

**Lemma D.5**.: _In each iteration \(k\in[K]\), let \(\mathcal{D}\) be the collected dataset, \(\theta\) and \(\theta^{*}\) are parameters independently drawn from posterior \(p(\theta|\mathcal{D})\), \(\bm{x}_{k}\sim p_{\theta}(\cdot|y_{k}^{*},\mathcal{D})\) and \(\bm{x}^{*}\sim p_{\theta^{*}}(\cdot|y_{k}^{*},\mathcal{D})\). For any measurable function \(f\), and \(\sigma(\mathcal{D})\)-measurable random variable \(\bm{x}_{k}\),_

\[\mathbb{E}\left[f(\bm{x}_{k})\right]=\mathbb{E}\left[f(\bm{x}^{*})\right].\]

Proof of Lemma d.5.: Since the black-box function \(f\) is measurable, and by the nature of Algorithm 1, in each iteration \(k\), the generated sample \(\bm{x}_{k}\), the target function value \(y_{k}^{*}\), the predictive distribution \(p_{\theta}(\cdot|y_{k}^{*},\mathcal{D})\), the posterior distribution \(p(\theta\mid\mathcal{D})\) are \(\sigma(\mathcal{D})\)-measurable at iteration \(k\), the only randomness in \(f(\bm{x})\) comes from the random sampling in the algorithm. Thus, condition on the training data \(\mathcal{D}\) and target value \(y_{k}^{*}\), by tower rule,

\[\mathbb{E}\left[f(\bm{x}_{k})\right]=\mathbb{E}\left[\mathbb{E} \left[f(\bm{x}_{k})|\theta\right]\right] =\int_{\theta}\int_{\bm{x}_{k}}f(\bm{x}_{k})p_{\theta}(\bm{x}_{k} |y_{k}^{*},\mathcal{D})p(\theta|\mathcal{D})\,\mathrm{d}\bm{x}_{k}\,\mathrm{d}\theta\] \[=\int_{\theta}\int_{\bm{x}_{k}}f(\bm{x}_{k})p_{\theta}(\bm{x}_{k} |y_{k}^{*},\mathcal{D})\,\mathrm{d}\bm{x}_{k}\,p(\theta|\mathcal{D})\,\mathrm{ d}\theta.\]

Note that both the true parameter \(\theta^{*}\) and the chosen parameter \(\theta\) are drawn from the same posterior distribution \(p(\theta\mid\mathcal{D})\), we have

\[\int_{\theta}\int_{\bm{x}}f(\bm{x})p_{\theta}(\bm{x}|y_{k}^{*},\mathcal{D})\, \mathrm{d}\bm{x}\,p(\theta|\mathcal{D})\,\mathrm{d}\theta=\int_{\theta^{*}} \int_{\bm{x}}f(\bm{x})p_{\theta^{*}}(\bm{x}|y_{k}^{*},\mathcal{D})\,\mathrm{d} \bm{x}\,\,p(\theta^{*}|\mathcal{D})\,\mathrm{d}\theta^{*}.\]

As a result, we have

\[\mathbb{E}\left[f(\bm{x}_{k})\right]=\int_{\theta^{*}}\int_{\bm{x}^{*}}f(\bm{x }^{*})p_{\theta^{*}}(\bm{x}^{*}|y_{k}^{*},\mathcal{D})\,\mathrm{d}\bm{x}^{*}p( \theta^{*}|\mathcal{D})\,\mathrm{d}\theta^{*}=\mathbb{E}\left[\mathbb{E}\left[ f(\bm{x}^{*})|\theta^{*}\right]\right]=\mathbb{E}\left[f(\bm{x}^{*})\right].\]

**Corollary 1**.: _In each iteration \(k\in[K]\), let \(\mathcal{D}\) be the collected dataset, \(\theta\) and \(\theta^{*}\) are parameters independently drawn from posterior \(p(\theta|\mathcal{D})\), \(\bm{x}_{k}\sim p_{\theta}(\cdot|y_{k}^{*},\mathcal{D})\) and \(\bm{x}^{*}\sim p_{\theta^{*}}(\cdot|y_{k}^{*},\mathcal{D})\). For any measurable function \(f\), and \(\sigma(\mathcal{D})\)-measurable random variable \(\bm{x}_{k}\),_

\[\mathbb{E}\left[\left\|\bm{x}_{k}\right\|\right]=\mathbb{E}\left[\left\|\bm{x} ^{*}\right\|\right].\]

Proof of Corollary 1.: Since the norm function is deterministic and \(\sigma(\mathcal{D})\)-measurable, the proof directly follows that of Lemma D.5.

Optimality of Proposed Acquisition Function

**Theorem 1**.: _Let \(\mathcal{Y}\) be the constructed candidate set at each iteration \(k\in[K]\) in Algorithm 1. By adopting UAE as the acquisition function to guide the sample generation process in conditional diffusion model, Diff-BBO (Algorithm 1) achieves a near-optimal solution for the online BBO problem defined in Equation (1):_

\[\max_{y_{k}\in\mathbb{R}}\sum_{k=1}^{K}f(\bm{x}_{k}),\ \ \bm{x}_{k}\sim p_{ \theta}(\cdot\mid y_{k},\mathcal{D}),\ \ \theta\in\Theta\ \Rightarrow\max_{y_{k}\in\mathcal{Y}}\sum_{k=1}^{K} \alpha(y_{k},\mathcal{D}).\]

Proof of Theorem 1.: Following Theorem 4, we can express the function evaluation as follows,

\[f(\bm{x}_{k})=y_{k}-(y_{k}-f(\bm{x}_{k})),\forall k\in[K].\]

The overall objective of the optimization problem defined in Equation (1) can then be further decomposed as

\[\max_{y_{k}\in\mathbb{R}}\sum_{k=1}^{K}f(\bm{x}_{k}),\ \ \bm{x}_{k}\sim p_{ \theta}(\cdot\mid y_{k}),\ \ \theta\in\Theta\] \[\Leftrightarrow\max_{y_{k}\in\mathbb{R}}\sum_{k=1}^{K}y_{k}-(y_{ k}-f(\bm{x}_{k})),\ \ \bm{x}_{k}\sim p_{\theta}(\cdot\mid y_{k}),\ \ \theta\in\Theta\] \[\Rightarrow\max_{y_{k}\in\mathbb{R}}\sum_{k=1}^{K}y_{k}-\Delta(p _{\theta},y_{k}).\]

By Theorem 4, which shows \(\Delta(p_{\theta},y_{k}^{*})\) can be effectively upper bounded the epidemic uncertainty, we therefore have

\[\max_{y_{k}\in\mathbb{R}}\sum_{k=1}^{K}f(\bm{x}_{k}),\ \ \bm{x}_{k}\sim p_{ \theta}(\cdot\mid y_{k}),\ \ \theta\in\Theta\Rightarrow\max_{y_{k}\in\mathcal{Y}}\sum_{k=1}^{K}y_{k}-\Delta _{\mathrm{episdecim}}(y_{k},\mathcal{D})\]

Essentially, our chosen acquisition function allows Diff-BBO to maximize the lower bound of the original optimization problem. 

## Appendix F Experiment Details

### Dataset Details.

DesignBench (Trabucco et al., 2022)is a benchmark for real-world black-box optimization tasks. For continuous tasks, we use Superconductor, D'Kitty Morphology and Ant Morphology benchmarks. For discrete tasks, we utilize TFBind8 and TFBind10 benchmarks. We exclude Hopper due to the domain is known to be buggy, as explained in Appendix C in (Krishnamoorthy et al., 2023). We also exclude NAS due to the significant computational resource requirement. Additionally, we exclude the ChEMBL task because the oracle model exhibits non-trivial discrepancies when queried with the same design.

* **Superconductor (materials optimization).** This task involves searching for materials with high critical temperatures. The dataset comprises 17,014 vectors, each with 86 components that represent the number of atoms of each chemical element in the formula. The provided oracle function is a pre-trained random forest regression model.
* **D'Kitty Morphology (robot morphology optimization).** This task focuses on optimizing the parameters of a D'Kitty robot, including the size, orientation, and location of the limbs, to make it suitable for a specific navigation task. The dataset consists of 10,004 entries with a parameter dimension of 56. It utilizes MuJoCO (Todorov et al., 2012), a robot simulator, as the oracle function.
* **Ant Morphology (robot morphology optimization).** Similar to D'Kitty, this task aims to optimize the parameters of a quadruped robot to maximize its speed. It includes 10,004 data points with a parameter dimension of 60. It also uses MuJoCO as the oracle function.

* **TFBind8 (DNA sequence optimization).** This task seeks to identify the DNA sequence of length eight with the highest binding affinity to the transcription factor SIX6 REF R1. The design space comprises sequences of nucleotides represented as categorical variables. The dataset size is 32,898, with a dimension of 8. The ground truth is used as a direct oracle since the affinity for the entire design space is available.
* **TFBind10 (DNA sequence optimization).** Similar to TFBind8, this task aims to find the DNA sequence of length ten that exhibits the highest binding affinity with transcription factor SIX6 REF R1. The design space consists of all possible nucleotide sequences. The dataset size is 10,000, with a dimension of 10. The ground truth is used as a direct oracle since the affinity for the entire design space is available.

Molecular Discovery.A key problem in drug discovery is the optimization of a compound's activity against a biological target with therapeutic value. Similar to other papers (Eckmann et al., 2022; Jeon and Kim, 2020; Lee et al., 2023; Noh et al., 2022), we attempt to optimize the score from AutoDock4 (Morris et al., 2009), which is a physics-based estimator of binding affinity. The oracle is a feed-forward model as a surrogate to AutoDock4. The surrogate model is trained until convergence on 10,000 compounds randomly sampled from the latent space (using \(\mathcal{N}(0,1)\)) and their computed objective values with AutoDock4. We construct our continuous design space by fixing a random protein embedding and randomly sampling 10,000 molecular embedding of dimension \(32\).

For each task, we arrange the offline dataset from Krishnamoorthy et al. (2023) in ascending order based on objective values and select data from the 25th to the 50th percentile as the initial training dataset. We prioritize data with lower objective scores to better observe performance differences across each baseline. The overview of all the task statistics is provided in Table 1.

### Implementation Details.

We train our model on NVIDIA A100 GPU and report the average performance over 3 random runs along with standard deviation for each task. For discrete tasks, we follow the procedure in Krishnamoorthy et al. (2023) where we convert the \(d\)-dimensional vector to a \(d\times c\) one hot vector regarding \(c\) classes. We then approximate logits by interpolating between a uniform distribution and the one hot distribution using a mixing factor of \(0.6\). We jointly train a conditional and unconditional model with the same model by randomly set the conditioning value to \(0\) with dropout probability of \(0.15\).

For each task, we fix the learning rate at \(0.001\) with batch size of \(256\). We use \(5\) ensemble models to estimate the uncertainty for our acquisition function. We set hidden dimensions to \(1024\) and gamma to \(2\). We use \(10\%\) of the available data at each iteration as validation set during training.

### Ablation study

In this section, we conduct ablation studies to investigate the impact of our designed acquisition function, UaE. We compare Diff-BBO with the fixed condition approach. Instead of using UaE to dynamically determine which \(y\) to condition on, the fixed condition approach always generates new samples conditioned on \(w\cdot\phi_{k}\) (Line 9 of Algorithm 1) with a fixed weight \(w\). As shown in Figure 4, Diff-BBO consistently outperforms the fixed condition approach. This demonstrates that our acquisition function is effective in identifying the optimal \(y\) for conditioning.

Furthermore, we evaluate the effect of batch size, aka the number of queries per iteration on Diff-BBO on the Superconductor task. As shown in Figure 5, we compare the objective function score over number of function evaluations. We can see the performance of our approach remains similar when the batch size becomes small, suggesting remarkable robustness across different batch sizes. Hence,

\begin{table}
\begin{tabular}{l r r r} \hline \hline
**Task** & **Size** & **Dimensions** & **Task Max** \\ \hline TFBind8 & 32,898 & 8 & 1.0 \\ TFBind10 & 10,000 & 10 & 2.128 \\ D’Kitty & 10,004 & 56 & 340.0 \\ Ant & 10,004 & 60 & 590.0 \\ Superconductor & 17,014 & 86 & 185.0 \\ Molecular Discovery & 10,000 & 32 & 1.0 \\ \hline \hline \end{tabular}
\end{table}
Table 1: Data StatisticsDiff-BBO is a highly-scalable inverse modeling approach that can efficiently leverage parallelism to handle larger computational loads without compromising performance.

## Appendix G Impact Statement

Optimization techniques can address various real-world problems, including drug and material design. Our method enhances sample-efficient online black-box optimization, potentially accelerating solutions in these areas. However, caution is needed to prevent misuse, such as optimizing drugs to enhance harmful side effects.

Figure 4: Impact of acquisition function design for black-box optimization on the TFBIND10 task. Comparison of Diff-BBO with five fixed-condition approaches, each with different conditioning weights. Results averaged across three random runs.

Figure 5: Ablation study to evaluate the effect of batch size on the superconductor task. The mean and standard deviation across three random seeds are plotted. Diff-BBO shows robust performances across different batch size given the same total number of evaluations.