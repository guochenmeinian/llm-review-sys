# Relational Verification Leaps Forward with RABBit

 Tarun Suresh\({}^{1}\)1 Debangshu Banerjee\({}^{1}\)1 Gagandeep Singh\({}^{1,2}\)

\({}^{1}\)University of Illinois Urbana-Champaign, \({}^{2}\)VMware Research

{tsuresh3, db21, ggnds}@illinois.edu

Equal contribution. Primary Correspondence: tsuresh3@illinois.edu

Footnote 1: footnotemark:

###### Abstract

We propose RABBit, a Branch-and-Bound-based verifier for verifying relational properties defined over Deep Neural Networks, such as robustness against universal adversarial perturbations (UAP). Existing SOTA complete \(L_{\infty}\)-robustness verifiers can not reason about dependencies between multiple executions and, as a result, are imprecise for relational verification. In contrast, existing SOTA relational verifiers only apply a single bounding step and do not utilize any branching strategies to refine the obtained bounds, thus producing imprecise results. We develop the first scalable Branch-and-Bound-based relational verifier, RABBit, which efficiently combines branching over multiple executions with cross-executional bound refinement to utilize relational constraints, gaining substantial precision over SOTA baselines on a wide range of datasets and networks. Code is at this URL.

## 1 Introduction

Deep neural networks (DNNs) are now widely used in safety-critical fields like autonomous driving and medical diagnosis [1], where their decisions can have serious consequences. However, understanding and ensuring their reliability is difficult due to their complex and opaque nature. Despite efforts to find and address vulnerabilities, such as adversarial attacks [1, 2, 3] and adversarial training techniques [1], ensuring safety remains a challenge. As a result, extensive research is focused on formally verifying the safety of DNNs. However, most of the existing \(L_{\infty}\) robustness verification techniques can not handle relational properties common in practical situations. While significant efforts have been invested in verifying the absence of input-specific adversarial examples within the local neighborhood of test inputs, recent studies [11] emphasize that input-specific attacks are impractical regardless. Conversely, practical attack scenarios [12, 13] involve the creation of universal adversarial perturbations (UAPs) [14], which are crafted to impact a substantial portion of inputs from the training distribution. RaVeN [1] and subsequently RACoon [1] showed that since the same adversarial perturbation is applied to multiple inputs, the executions on different perturbed inputs are related, exploiting the relationship between different executions significantly improves the precision of the verifier. Despite RaVeN and RACoon's ability to leverage cross-executional dependencies, both of them remain imprecise as they only apply a single bounding step and lack refinement using branching strategies used in SOTA complete non-relational verifiers.

**Key challenges:** For precise relational verification, we need efficient algorithms that can effectively combine branching strategies over multiple executions with bounding techniques that can leverage cross-executional dependencies. Theoretically, MILP (Mixed Integer Linear Programming) can exactly encode DNN executions with piecewise linear activation functions like ReLU over any input regions specified by linear inequalities. However, the associated MILP optimization problem is computationally expensive. For instance, encoding \(k\) executions of a DNN with \(n_{r}\) ReLU activationsintroduces \(O(n_{r}\times k)\) integer variables in the worst case. As the cost of MILP optimization grows exponentially with the number of integer variables, even SOTA off-the-shelf solvers like Gurobi (Gurobi Optimization, LLC, 2018) struggle to verify small DNNs for a relational property over \(k\) executions within a reasonable time limit. For scalability, SOTA non-relational verifiers like \(\alpha,\beta\)-CROWN (Wang et al., 2021) design custom "Branch and Bound" (BaB) solvers using more scalable differentiable optimization techniques such as gradient descent. However, these verifiers ignore dependencies between multiple executions, resulting in imprecise relational verification. Conversely, the SOTA relational verifier RACoon uses parametric linear relaxation for each activation to avoid integer variables and employs gradient descent to learn parameters that leverage cross-executional dependencies for verification. This method, however, introduces imprecision due to the replacement of non-linear activations with parametric linear approximations. Therefore, precise relational verification requires scalable algorithms that can: a) scale to the large DNNs used in this paper, b) effectively reduce imprecision from parametric linear relaxations, and c) utilize cross-executional dependencies.

**Our contributions:** We advance the state-of-the-art in relational DNN verification by:

* Efficiently combining branching strategies over multiple DNN executions with a cross-executional bounding method that utilizes dependencies between DNN's outputs from different executions while reducing imprecision resulting from parametric linear relaxations.
* **a) strong bounding:** applies cross-execution bounding at each step, branching over all executions. This method provides tighter bounds than RACoon (cross-executional bound refinement without branching) and \(\alpha,\beta\)-CROWN (branching without cross-executional bound refinement), **b) strong branching:** applies cross-execution bounding only at the start to derive fixed linear approximations for each execution. These approximations are then used to branch independently over each execution, exploring more branches per execution.
* Combining strong bounding and branching results into an efficiently optimizable MILP instance that leverages the benefits of both techniques, outperforming each individually.
* Performing extensive experiments on popular datasets and various DNNs (standard and robustly trained) to showcase the precision improvement over the current SOTA baselines.

## 2 Related Works

**Non-relational DNN verifiers:** Given a logical input specification \(\phi\) and an output specification \(\psi\), DNN verifiers formally prove that for all inputs \(\mathbf{x}\) satisfying \(\phi\), the output \(N(\mathbf{x})\) of the DNN satisfies \(\psi\). If the verification process fails, the verifier generates a counter-example where the output specification \(\psi\) does not hold. DNN verifiers are broadly divided into three main types based on their ability to prove properties: - (i) sound but incomplete verifiers which may not always prove property even if it holds (Gehr et al., 2018; Singh et al., 2018, 2019, 2019, 2020, 2021), (ii) complete verifiers that can always prove the property if it holds (Wang et al., 2018; Gehr et al., 2018; Bunel et al., 2020, 2020, 2020, 2021, 2022, 2021, 2022, 2021, 2022, 2021, 2022, 2022] and (iii) verifiers with probabilistic guarantees (Cohen et al., 2019; Li et al., 2022). Beyond the commonly studied \(L_{\infty}\) robustness verification problem, several works adapt DNN verification techniques for specific applications, such as robustness against image rotation (Singh et al., 2019, 2019), incremental verification (Ugare et al., 2023, 2024), interpretability (Banerjee et al., 2024), and certifiable training (Mueller et al., 2023; Palma et al., 2024; Jiang and Singh, 2024).

**Relational DNN verifier:** Existing relational verifiers fall into two main categories based on the type of relational properties they can handle: (i) verifiers for properties such as UAP and fairness, which are defined across multiple executions of the same DNN (Zeng et al., 2023; Khedr and Shoukry, 2023; Meyer et al., 2024; Banerjee et al., 2024, 2024), and (ii) verifiers for properties like local DNN equivalence, defined over multiple executions of different DNNs on the same input (Paulsen et al., 2020, 2021). For relational properties defined across multiple executions of the same DNN, existing verifiers (Khedr and Shoukry, 2023) reduce the verification problem to an \(L_{\infty}\) robustness problem by constructing a "product DNN" that includes multiple copies of the same DNN. However, the relational verifier in (Khedr and Shoukry, 2023) treats all \(k\) executions of the DNN as independent, which results in a loss of precision. On the other hand, (Zeng et al., 2023) (referred to as the I/O formulation) tracks the relationships between inputs used in multiple executions at the input layer, but it does not maintain the relationships between the outputs fed into the subsequent hidden layers. As a result, it achieves only limited improvement over baseline verifiers that treat all executions independently. RaVeN (Banerjee et al., 2024) uses DiffPoly a abstract intepretation based framework to track linear relationships between the outputs at all layers resulting from multiple executions of the same DNN. While RaVeN is significantly more precise than the I/O formulation, tracking linear constraints at each layer across all DNN executions can be computationally expensive. The SOTA relational verifier RACon (Banerjee and Singh, 2024) improves the scalability of RaVeN while maintaining RaVeN's precision by introducing a new gradient-descent based bounding strategy called cross-executional bound refinement, as detailed in Section 3. There exist, probabilistic verifiers, (Xie et al., 2021; Zhang et al., 2022) based on randomized smoothing (Cohen et al., 2019) for verifying relational properties. However, these works can only give probabilistic guarantees on smoothed models which have high inference costs. Similar to (Banerjee et al., 2024; Banerjee and Singh, 2024), in this work, we focus on deterministic relational verifiers for DNNs with ReLU activation. However, RABBit can be extended to activations like Sigmoid with branching methods (Shi et al., 2024) and parametric bounds (Wu et al., 2023).

## 3 Preliminaries

We provide background on "branch and bound" (BaB) based non-relational DNN verification, as well as DNN safety properties that can be encoded as relational properties.

**Non-relational DNN verification:** For a single execution, non-relational DNN verification focuses on proving that, for all perturbations \(\mathbf{x}+\boldsymbol{\delta}\) of a given input \(\mathbf{x}\) specified by \(\phi\), the network's output \(\mathbf{y}=N(\mathbf{x}+\boldsymbol{\delta})\) meets a specified logical condition \(\psi\). Commonly, safety properties such as \(L_{\infty}\) robustness encode the output condition (\(\psi\)) as a linear inequality or a conjunction of linear inequalities over the DNN output \(\mathbf{y}\in\mathbb{R}^{n_{l}}\). For instance, an output property could be expressed as \(\psi(\mathbf{y})=(\mathbf{c}^{T}\mathbf{y}\geq 0)\), where \(\mathbf{c}\in\mathbb{R}^{n_{l}}\). Generally, even for DNNs with piecewise-linear activation functions and input constraints defined by linear inequalities, complete verification--i.e., always proving the property or finding a counterexample--is an NP-complete problem. Given a DNN \(N:\mathbb{R}^{n_{0}}\rightarrow\mathbb{R}^{n_{l}}\) and a property defined by \((\phi,\psi)\), scalable yet sound (but incomplete) verifiers approximate the network's behavior by computing a linear approximation specified by \(\mathbf{L}\in\mathbb{R}^{n_{0}}\) and \(b\in\mathbb{R}\). For any input \(\mathbf{x}\) satisfying \(\phi\), this linear approximation ensures that \(\mathbf{L}^{T}\mathbf{x}+b\leq\mathbf{c}^{T}N(\mathbf{x})\). The verifier then aims to show that \(\mathbf{L}^{T}\mathbf{x}+b\geq 0\) for all \(\mathbf{x}\) that satisfy \(\phi\), which implies \(\mathbf{c}^{T}N(\mathbf{x})\geq 0\). While \(\mathbf{L}^{T}\mathbf{x}+b\) provides a valid lower bound for \(\mathbf{c}^{T}N(\mathbf{x})\), it may lack precision. To enhance this precision for piecewise-linear activations, state-of-the-art non-relational verifiers use a branch-and-bound (BaB) method. In each branching step, the problem is divided into smaller subproblems, while the bounding method computes a valid lower bound for each subproblem.

**Branching for piecewise linear activation:** The non-relational verifier computes \(\mathbf{L}\) by replacing non-linear activations with linear relaxations, which introduces imprecision. However, for piecewise linear activations like ReLU, it is possible to consider each linear piece separately as different subproblems, avoiding the need for imprecise linear relaxations. For instance, for \(y=ReLU(x)\), branching on \(x\) and considering the cases \(x\leq 0\) and \(x\geq 0\) allows decomposing \(ReLU(x)\) into two distinct linear pieces. Still in the worst case decomposing all ReLU nodes in a DNN results in exponential blowup making it practically infeasible. Therefore, SOTA non-relation verifiers like \(\alpha,\beta\)-CROWN (Wang et al., 2021) greedily pick a small subset of ReLU nodes for branching while using linear relaxations for the rest. We explain the bounding step used for each subproblem below.

**Bounding with parameter refinement:** Obtaining sound linear relaxations of activations \(\sigma\) like ReLU, which are not used for branching, involves computing linear lower bounds \(\sigma_{l}(x)\) and upper bounds \(\sigma_{u}(x)\) that contain all possible outputs of \(\sigma\) w.r.t all inputs \(\mathbf{x}\) satisfying \(\phi\). That is, for all possible input values \(x\) of \(\sigma\), \(\sigma_{l}(x)\leq\sigma(x)\leq\sigma_{u}(x)\) holds. SOTA non-relational verifiers, such as \(\alpha,\beta\)-CROWN, improve precision by using parametric linear relaxations instead of static linear bounds and refine the parameters to facilitate verification of the property \((\phi,\psi)\). For example, for \(ReLU(x)\), the parametric lower bound is \(ReLU(x)\geq\alpha\times x\) with \(\alpha\in[0,1]\). Since \(\alpha\times x\) remains a valid lower for any \(\alpha\in[0,1]\), this allows optimizing \(\alpha\) while ensuring the bound remains mathematically correct. Each branched ReLU say \(y=ReLU(x)\), introduces two subproblems each with one additional constraint \(x\leq 0\) (or, \(x\geq 0\)) where ReLU behaves as a linear function i.e. \(y=0\) (or, \(y=x\)) respectively. To obtain the lower bound of \(\mathbf{L}^{T}\mathbf{x}+b\) over inputs satisfying \(\phi\) with the additional branching constraints \(\alpha,\beta\)-CROWN convert the constrained optimization problem into an unconstrained one by looking at the Lagrangian dual. The dual replaces each branching constraint by augmenting the minimization objective \(\mathbf{L}^{T}\mathbf{x}+b\) with additional terms i.e. \(\mathbf{L}^{T}\mathbf{x}+b+\beta^{+}x\) for \(x\leq 0\)or \(\mathbf{L}^{T}\mathbf{x}+b+\beta^{-}x\) for \(x\geq 0\) where \(\beta^{+}\geq 0\) and \(\beta^{-}\leq 0\). Overall, at high level, \(\alpha,\beta\)-CROWN computes parametric linear approximations \(\mathbf{L}(\boldsymbol{\alpha},\boldsymbol{\beta})^{T}\mathbf{x}+b(\boldsymbol{ \alpha},\boldsymbol{\beta})\) and refine the parameters \(\alpha,\beta\) to facilitate verification of \((\phi,\psi)\).

**DNN relational properties:** Relational properties defined for a DNN \(N:\mathbb{R}^{n_{0}}\rightarrow\mathbb{R}^{n_{i}}\) defined over \(k\) executions of \(N\) are specified by the tuple \((\Phi,\Psi)\). Here, \(\Phi:\mathbb{R}^{n_{0}\times k}\rightarrow\{true,false\}\) (the input specification) encodes the input region \(\Phi_{t}\subseteq\mathbb{R}^{n_{0}\times k}\) encompassing all potential inputs corresponding to each of the \(k\) executions of \(N\). Furthermore, the safety property we expect the outputs of all \(k\) executions of \(N\) to satisfy is specified by \(\Psi:\mathbb{R}^{n_{1}\times k}\rightarrow\{true,false\}\) (the output specification). Given \(N\), an input specification \(\Phi\) and an output specification \(\Psi\), DNN relational verification seeks to formally prove whether \(\forall\mathbf{x}_{1}^{*},\ldots,\mathbf{x}_{\mathbf{k}}^{*}\in\mathbb{R}^{n _{0}}\Phi(\mathbf{x}_{1}^{*},\ldots,\mathbf{x}_{\mathbf{k}}^{*})\implies\Psi(N (\mathbf{x}_{1}^{*}),\ldots N(\mathbf{x}_{\mathbf{k}}^{*}))\) or otherwise provide a counterexample. The inputs to the \(k\) executions of \(N\) are denoted by \(\mathbf{x}_{1}^{*},\ldots,\mathbf{x}_{\mathbf{k}}^{*}\) and the corresponding outputs are denoted by \(N(\mathbf{x}_{1}^{*}),\ldots,N(\mathbf{x}_{\mathbf{k}}^{*})\). For the \(i\)-th execution, commonly, the input region \(\phi_{t}^{i}\) is a \(L_{\infty}\) region around a fixed point \(\mathbf{x}_{\mathbf{i}}\in\mathbb{R}^{n_{0}}\) defined as \(\phi_{t}^{i}=\{\mathbf{x}_{i}^{*}\in\mathbb{R}^{n_{0}}\mid\|\mathbf{x}_{\mathbf{ i}}^{*}-\mathbf{x}_{\mathbf{i}}\|_{\infty}\leq\epsilon\}\) and the corresponding output specification \(\psi^{i}(N(\mathbf{x}_{1}^{*}))=\bigwedge_{j=1}^{m}(\mathbf{c_{i_{j}}}^{T}N( \mathbf{x}_{1}^{*})\geq 0)\). Consequently, \(\Phi(\mathbf{x}_{1}^{*},\ldots,\mathbf{x}_{\mathbf{k}}^{*})=\bigwedge_{i=1}^{ k}(\mathbf{x}_{1}^{*}\in\phi_{t}^{i})\bigwedge\Phi^{\delta}(\mathbf{x}_{1}^{*}, \ldots,\mathbf{x}_{\mathbf{k}}^{*})\) where \(\Phi^{\delta}(\mathbf{x}_{1}^{*},\ldots,\mathbf{x}_{\mathbf{k}}^{*})\) encodes the relationship between the inputs used in different execution and \(\Psi(N(\mathbf{x}_{1}^{*}),\ldots,N(\mathbf{x}_{\mathbf{k}}^{*}))=\bigwedge_{i= 1}^{k}\psi^{i}(N(\mathbf{x}_{1}^{*}))\). Following this, we describe relational properties encoding important DNN safety configurations.

**UAP verification:** In a UAP attack, given a DNN \(N\), the adversary aims to find an adversarial perturbation with a bounded \(L_{\infty}\) norm that maximizes the rate at which \(N\) misclassifies when the same adversarial perturbation is applied to all inputs from the distribution. The UAP verification problem aims to find the worst-case accuracy of \(N\) against the UAP adversary. We refer to this worst-case accuracy as UAP accuracy in the rest of the paper. As shown by Theorem 2 in (Zeng et al., 2023), it is possible to statistically estimate the UAP accuracy of \(N\) with respect to the input distribution if one can determine the UAP accuracy of \(N\) on \(k\) randomly selected images. We focus on the \(k\)-UAP verification problem for the rest of the paper as improving the precision of \(k\)-UAP verification directly improves the UAP accuracy on the input distribution (Banerjee and Singh, 2024). The \(k\)-UAP verification problem is fundamentally different from local \(L_{\infty}\) robustness verification since the same adversarial perturbation is applied across the set of inputs. Thus, improving precision for the UAP verification problem requires a relational verifier that can exploit dependencies between the perturbed inputs. We provide the \(\Phi\) and \(\Psi\) of the UAP verification problem in Appendix A.1.

## 4 Cross-executional BaB

The key distinction between relational and non-relational DNN verification is the dependency between different DNN executions, which necessitates that any precise relational verifier utilizes these cross-execution dependencies. For instance, for \(k\)-UAP problem with two images \(\mathbf{x_{1}}\), \(\mathbf{x_{2}}\) consider the scenario where both \(\mathbf{x_{1}}\) and \(\mathbf{x_{2}}\) have valid adversarial perturbations \(\boldsymbol{\delta_{1}}\) and \(\boldsymbol{\delta_{2}}\) but no common perturbation say \(\boldsymbol{\delta}\) that works for both \(\mathbf{x_{1}}\) and \(\mathbf{x_{2}}\). In this case, any non-relational verification that does not account for cross-execution dependencies can never prove the absence of a common perturbation given that both \(\mathbf{x_{1}}\), \(\mathbf{x_{2}}\) have valid adversarial perturbations. This highlights the importance of utilizing cross-executional dependencies. The SOTA relational verifier RACon (Banerjee and Singh, 2024) leverages cross-execution dependencies to **jointly** optimize the \(\boldsymbol{\alpha}\) parameters from different executions, significantly improving the precision of relational verification. However, RACoon only uses parametric linear relaxations for non-linear activations and lacks a branching step, resulting in reduced precision, as confirmed by our experimental results in Section 6. To address this, we propose two separate BaB algorithms, each with its benefits, described in Sections 4.1 and 4.2. Finally, we combine the results to formulate an efficiently optimizable MILP instance in Section 5

### Strong Bounding

Before going into the details, we briefly review the cross-executional bound refinement proposed in RACoon. For \(k\)-UAP, given any subset \(S\) of the \(k\) executions, RACoon can verify the absence of any common perturbation that works for **all** executions in \(S\) with cross-executional bound refinement. For all \(i\in S\), let \((\mathbf{L}_{i}(\boldsymbol{\alpha}_{i}),\mathbf{b}_{i}(\boldsymbol{\alpha}_{i}))\) denote the parametric linear approximations corresponding to the \(i\)-th execution. Then the optimal value \(t^{*}=\max_{\boldsymbol{\alpha}_{i},\lambda_{i}}-\epsilon\times\|\sum_{i\in S} \lambda_{i}\times\mathbf{L}_{i}(\boldsymbol{\alpha}_{i})\|_{1}+\sum_{i\in S} \lambda_{i}\times a_{i}(\boldsymbol{\alpha}_{i})\geq 0\) proves the absence of a common perturbation \(\boldsymbol{\delta}\) for \(S\). Here, \(\epsilon\) is the perturbation bound i.e. \(\|\boldsymbol{\delta}\|_{\infty}\leq\epsilon\), \(a_{i}(\boldsymbol{\alpha}_{i})=\mathbf{b}_{i}(\boldsymbol{\alpha}_{i})+\mathbf{L} _{i}(\boldsymbol{\alpha}_{i})^{T}\mathbf{x_{i}}\) and \(\lambda_{i}\in[0,1]\) with \(\sum_{i\in S}\lambda_{i}=1\) are the cross-executional parameters that relate linear approximations from different execution enabling joint optimization over \(\boldsymbol{\alpha}_{i}\)s. Next,we detail the first BaB method - strong bounding that combines cross-executional bounding with branching methods to verify the absence of common perturbation for any subset of \(n=|S|\) executions.

**Branching and bounding:** For \(n\leq k\) executions, we construct a "product DNN" by duplicating the DNN \(n\) times, one for each execution. Formally, a product DNN is a function \(N^{n}:\mathbb{R}^{n_{0}\times n}\rightarrow\mathbb{R}^{n_{1}\times n}\) with \(N^{n}(\mathbf{x}_{1},\ldots,\mathbf{x}_{\mathbf{n}})=[N(\mathbf{x}_{1}), \ldots,N(\mathbf{x}_{\mathbf{n}})]^{T}\). At each branching step, we greedily select a subset of unbranched ReLU activations from the product DNN and branch on them, while using parametric linear relaxations for the rest. We adapt existing greedy branching heuristics, such as BaBSR [14], for selecting the candidate ReLU activations. The heuristic computes a score for each unbranched ReLU activation in the product DNN, and we branch on the activations with the highest scores. Next, we detail the bounding method applied to each subproblem resulting from branching. Since the number of subproblems can be large, the bounding method needs to be fast yet capable of leveraging both branching constraints and cross-executional dependencies. However, the cross-executional bound refinement from RACoon can not handle branching constraints, while the bounding step from \(\alpha,\beta\)-CROWN does not utilize dependencies across executions. Hence, we develop a three-step algorithm for obtaining the optimal value \(t^{*}\) with fast gradient descent-based methods. First, we replace these branching constraints by introducing dual variables \(\boldsymbol{\beta}\), resulting in new parametric linear approximations \((\mathbf{L}_{i}(\boldsymbol{\alpha}_{i},\boldsymbol{\beta}_{i}),b_{i}( \boldsymbol{\alpha}_{i},\boldsymbol{\beta}_{i}))\) for each subproblem for all \(i\in S\). Then for each subproblem, we introduce additional variables \(\lambda_{i}\) for each execution with constraints \(\lambda_{i}\in[0,1]\) and \(\sum_{i\in S}\lambda_{i}=1\). These \(\lambda_{i}\)s relate linear approximations from different executions capturing cross-executional dependencies. This reduces finding \(t^{*}\) for each subproblem to the following optimization problem \(t^{*}=\max_{\boldsymbol{\alpha}_{i},\boldsymbol{\beta}_{i},\lambda_{i}}- \epsilon\times\|\sum_{i\in S}\lambda_{i}\times\mathbf{L}_{i}(\boldsymbol{ \alpha}_{i},\boldsymbol{\beta}_{i})\|_{1}+\sum_{i\in S}\lambda_{i}\times a_{i} (\boldsymbol{\alpha}_{i},\boldsymbol{\beta}_{i})\). Here, \(a_{i}(\boldsymbol{\alpha}_{i},\boldsymbol{\beta}_{i})=b_{i}(\boldsymbol{ \alpha}_{i},\boldsymbol{\beta}_{i})+\mathbf{L}_{i}(\boldsymbol{\alpha}_{i}, \boldsymbol{\beta}_{i})^{T}\mathbf{x}_{i}\). Finally, we apply projected gradient ascent to refine parameters \((\boldsymbol{\alpha}_{i},\boldsymbol{\beta}_{i},\lambda_{i})\). The detailed derivation of the bounding step and the proof of correctness is in Appendix B. Precision gains of strong bounding over the baselines are in Section 6.2. Suppose, \(\mathcal{F}(S)\) denotes the set of subproblems then Theorem 4.1 proves the absence of common perturbation for the subset of executions \(S\).

**Theorem 4.1**.: _If \(\min_{\mathcal{F}(S)}\max_{\boldsymbol{\alpha}_{i},\boldsymbol{\beta}_{i}, \lambda_{i}}-\epsilon\times\|\sum_{i\in S}\lambda_{i}\times\mathbf{L}_{i}( \boldsymbol{\alpha}_{i},\boldsymbol{\beta}_{i})\|_{1}+\sum_{i\in S}\lambda_{i} \times a_{i}(\boldsymbol{\alpha}_{i},\boldsymbol{\beta}_{i})\geq 0\) then executions in \(S\) do not have a common perturbation \(\boldsymbol{\delta}\in\mathbb{R}^{n_{0}}\) with \(\|\boldsymbol{\delta}\|_{\infty}\leq\epsilon\)._

Proof.: The detailed proof is in the Appendix B.

While strong bounding effectively combines cross-executional refinement with branching, it has the following drawbacks that led to the development of the 2nd BaB method. First, strong bounding branches over all executions simultaneously, which limits the number of branches explored per execution within a fixed timeout compared to branching on individual executions. For instance, if strong bounding solves \(m\) subproblems for \(n\) executions, then assuming each execution branched uniformly, each execution gets only \(m^{\frac{1}{n}}\) subproblems. In contrast, given the same timeout, branching individually allows exploring \(\frac{m}{n}\) subproblems per execution. Second, strong bounding only proves the absence of common perturbation, a relaxation of the \(k\)-UAP problem. To mitigate this, RACoon uses parameter refinement to obtain linear approximations and formulate a MILP, providing a more precise bound on \(k\)-UAP accuracy. However, for strong bounding, as the number of subproblems increases and each subproblem has a different linear approximation, formulating a MILP with each linear approximation is practically infeasible. Restricting the number of linear approximations can help accommodate MILP formulation by compromising on the strong cross-executional bounding.

### Strong Branching

Unlike strong bounding, strong branching explores more branches by branching on each execution independently. Additionally, for each execution, we aim to keep the number of linear approximations small post-branching, ensuring the MILP instance using these approximations remains easy to optimize. To limit the number of linear approximations for each execution \(i\), we fix a set of linear coefficients \(\{\mathbf{L}_{1},\ldots,\mathbf{L}_{m}\}\) called "target coefficients" and for each \(j\in[m]\), \(\mathbf{L}_{j}\in\mathbb{R}^{n_{0}}\) compute valid lower bound \(b_{j}^{*}\) of the following optimization problem \(\min_{\boldsymbol{\delta}}\mathbf{c}^{T}N(\mathbf{x}_{i}+\boldsymbol{\delta}) -\mathbf{L}_{j}^{T}(\mathbf{x}_{i}+\boldsymbol{\delta})\) with \(\|\boldsymbol{\delta}\|_{\infty}\leq\epsilon\) using BaB. In this case, for all \(\boldsymbol{\delta}\in\mathbb{R}^{n_{0}}\) with \(\|\boldsymbol{\delta}\|_{\infty}\leq\epsilon\) the refined bias \(b_{j}^{*}\) and \(\mathbf{L}_{j}\) remain a valid lower bound of \(\mathbf{c}^{T}N(\mathbf{x}_{i}+\boldsymbol{\delta})\) i.e. \(\mathbf{L}_{j}^{T}(\mathbf{x}_{i}+\boldsymbol{\delta})+b_{j}^{*}\leq\mathbf{c }^{T}N(\mathbf{x}_{i}+\boldsymbol{\delta})\). Moreover, since we only refine the bias, the number of linear approximations remains the same as at the start of BaB, even after branching. Next, we describe how we utilize cross-execution dependencies while branching on each execution independently.

**Selecting targets:** To select target coefficients, we greedily pick subsets of executions and run cross-executional refinement from RACoon without branching on each subset of executions. We describe the greedy selection strategy in Section 5. For each set of executions, we add the linear approximations obtained by cross-executional refinement to the corresponding executions' target sets. Cross-executional refinement ensures for each execution set the parameters corresponding to the linear approximations are tailored for the relational verification.

**Bounding and branching:** Given a target coefficient \(\mathbf{L}_{t}\in\mathbb{R}^{n_{0}}\), since finding the exact solution of \(\min_{\boldsymbol{\delta}}\mathbf{c}^{T}N(\mathbf{x}_{\mathbf{i}}+\boldsymbol {\delta})-\mathbf{L}_{t}^{T}(\mathbf{x}_{\mathbf{i}}+\boldsymbol{\delta})\) is computationally expensive, strong branching aims to obtain a tight mathematically correct lower bound on the difference \(\mathbf{c}^{T}N(\mathbf{x}_{\mathbf{i}}+\boldsymbol{\delta})-\mathbf{L}_{t}^{ T}(\mathbf{x}_{\mathbf{i}}+\boldsymbol{\delta})\). For any subproblem, let \((\mathbf{L}(\boldsymbol{\alpha},\boldsymbol{\beta}),b(\boldsymbol{\alpha}, \boldsymbol{\beta}))\) denote the parametric linear approximation. Then for this particular subproblem, for all \(\boldsymbol{\alpha},\boldsymbol{\beta}\), \(\mathbf{L}(\boldsymbol{\alpha},\boldsymbol{\beta})^{T}(x_{i}+\boldsymbol{ \delta})+b(\boldsymbol{\alpha},\boldsymbol{\beta})\leq\mathbf{c}^{T}N( \mathbf{x}_{\mathbf{i}}+\boldsymbol{\delta})\) and subsequently:

\[\max_{\boldsymbol{\alpha},\boldsymbol{\beta}}\min_{\|\boldsymbol{\delta}\|_{ \infty}\leq\epsilon}(\mathbf{L}(\boldsymbol{\alpha},\boldsymbol{\beta})- \mathbf{L}_{t})^{T}(\mathbf{x}_{\mathbf{i}}+\boldsymbol{\delta})+b(\boldsymbol {\alpha},\boldsymbol{\beta})\leq\min_{\|\boldsymbol{\delta}\|_{\infty}\leq \epsilon}\mathbf{c}^{T}N(\mathbf{x}_{\mathbf{i}}+\boldsymbol{\delta})-\mathbf{L }_{t}^{T}(\mathbf{x}_{\mathbf{i}}+\boldsymbol{\delta})\] (1)

The optimal solution of the max-min problem in Eq. 1 provides a mathematically correct lower bound of \(\min_{\boldsymbol{\delta}}\mathbf{c}^{T}N(\mathbf{x}_{\mathbf{i}}+\boldsymbol {\delta})-\mathbf{L}_{t}^{T}(\mathbf{x}_{\mathbf{i}}+\boldsymbol{\delta})\) for each subproblem. However, it is hard to solve a max-min problem with scalable differentiable optimization techniques like gradient descent typically used for large DNNs considered in this paper. Instead, we compute a closed form of the inner minimization problem reducing the optimization instance to a more tractable maximization problem (Theorem 4.2).

**Theorem 4.2**.: _For any \(\boldsymbol{\alpha},\boldsymbol{\beta}\), if \(\mathbf{L}(\boldsymbol{\alpha},\boldsymbol{\beta})\in\mathbb{R}^{n_{0}}\) and \(b(\boldsymbol{\alpha},\boldsymbol{\beta})\in\mathbb{R}\) then \(\min_{\|\boldsymbol{\delta}\|_{\infty}\leq\epsilon}(\mathbf{L}(\boldsymbol{ \alpha},\boldsymbol{\beta})-\mathbf{L}_{t})^{T}(\mathbf{x}+\boldsymbol{\delta} )+b(\boldsymbol{\alpha},\boldsymbol{\beta})=-\epsilon\times\|\mathbf{L}( \boldsymbol{\alpha},\boldsymbol{\beta})-\mathbf{L}_{t}\|_{1}+(\mathbf{L}( \boldsymbol{\alpha},\boldsymbol{\beta})-\mathbf{L}_{t})^{T}\mathbf{x}+b( \boldsymbol{\alpha},\boldsymbol{\beta})\)._

**Proof:** The proof is in Appendix C.

We apply a projected gradient ascent to optimize the maximization with the closed form obtained above (Appendix C.1). The proof of the correctness of the bounding method is in Appendix C. Note the proof of correctness does not necessitate the optimizer to find the global optimum. This is important since gradient ascent may not always converge to the global optimum. Since strong branching branch on each execution independently we reuse the branching strategy of \(\alpha,\beta\)-CROWN.

## 5 RABBit

In this section, we detail the algorithm (Algo. 1) that combines the results from strong bounding and strong branching to formulate the MILP. Running strong bounding on all \(2^{k}-1\) non-empty subsets of \(k\) executions is impractical. Therefore, we use a greedy approach to select subsets of executions for strong bounding. Similarly, for strong branching, we greedily select the target linear coefficients. First, we describe both greedy strategies before moving on to the MILP formulation.

**Elimination of individually verified executions:** RABBit maintains a list of unverified indices and eliminates any executions that can be verified individually and does not consider them for subsequent steps (lines 3, 8, and 13 in Algo. 1). For instance, for \(k\)-UAP verification, we do not need to consider those executions that are proved to have no adversarial perturbation \(\boldsymbol{\delta}\) such that \(\|\boldsymbol{\delta}\|_{\infty}\leq\epsilon\). Pruning individually verified executions improves the runtime without any compromise on the precision of the relational verifier (see Theorem B.1 [1]).

**Greedy target coefficient selection:** RABBit first runs RACoon which in turn executes an incomplete non-relational verifier \(\alpha\)-CROWN [20] eliminating the verified executions (line 8 in Algo. 1). Subsequently, for target selection, RABBit greedily picks the first \(k_{t}\) (hyperparameter) executions based on \(s_{i}\) the lower bound on \(\psi^{i}(N(\mathbf{x}_{\mathbf{i}}+\boldsymbol{\delta}))\) as computed by \(\alpha\)-CROWN, prioritizing executions with higher \(s_{i}\) (line 9). Intuitively, for unverified executions, \(s_{i}\) measures the maximum violation of the output specification \(\psi^{i}(N(\mathbf{x}_{\mathbf{i}}+\boldsymbol{\delta}))\) and thus leads to the natural choice of picking executions with smaller violations. For each selected execution \(i\), we choose up to \(m\) target coefficients by iterating over all subsets \(i\in S\) considered by RACoon, and selecting linear approximations corresponding to the top \(m\) subsets.The cross-executional lower bound \(t^{*}\) from RACoon decides the priority of each subset \(S\). Subsets \(S\) with higher \(t^{*}\) indicate smaller violations and are more likely to be verified for the absence of a common perturbation, making them suitable for target selection.

**Selection of subsets of executions for strong bounding:** Thereafter, until timeout \(\zeta\), we run strong bounding on subsets of executions from individually unverified executions \(I\). For each subset \(S\subseteq I\)the cross-executional bound obtained by RACoon on \(S\) decides its priority. However, considering all non-empty subsets of \(I\) can be expensive. Instead, similar to strong branching, we first pick top-\(k_{t}\) executions (\(I_{2}\)) from \(I\) (Algo 1 line 19). We sort all non-empty subsets \(S\subseteq I_{2}\) based on their priority and, in each iteration, run strong bounding on the highest-priority subset that has not been scheduled yet (Algo 1 line 22). Given a large timeout, RABBit would eventually select all subsets from \(I_{2}\).

**MILP Formulation:** The MILP formulation uses both the refined biases from strong branching (line 11) and the subsets \(S\) of executions verified for the absence of common perturbation from strong bounding (line 22) to compute final verified UAP accuracy. RABBit MILP formulation involves three steps. First, we deduce linear constraints between the input and output of \(N\) for each unverified execution using linear approximations of \(N\) with refined bias obtained by strong branching. Secondly, we add constraints for each subset \(S\) verified for the absence of common perturbation with strong bounding. Then, similar to the current SOTA baseline [24], we encode the output specification \(\Psi\) as a MILP objective, introducing only \(O(k)\) integer variables. Finally, we use an off-the-shelf MILP solver [Gurobi Optimization, LLC, 2018] to optimize the MILP.

\(\Psi\) **encoding:** First, we show the MILP objective \(\mathbf{M}\) that encodes \(\Psi\). We introduce binary variables \(z_{i}\in\{0,1\}\) for each individually unverified execution in \(I\) where for any perturbation \(\boldsymbol{\delta}\in\mathbb{R}^{n_{0}}\) and \(\|\boldsymbol{\delta}\|_{\infty}\leq\epsilon\), \(z_{i}=1\) implies \(\psi^{i}(N(x_{i}+\boldsymbol{\delta}))=True\). Then the finding the worst case UAP accuracy is equivalent to the following \(\mathbf{M}=\frac{1}{k}\times\big{(}(k-|I|)+min_{\|\delta\|_{\infty}\leq\epsilon }\sum_{i\in I}z_{i}\big{)}\).

Constraints encoding:We add constraints from strong bounding, strong branching, and from the linear approximation obtained from the call to RACoon (Algo. 1 line 8). Suppose for any subset \(S\subseteq I\), strong bounding verifies the absence of common perturbation. Then for all \(\boldsymbol{\delta}\in\mathbb{R}^{n_{0}}\) and \(\|\boldsymbol{\delta}\|_{\infty}\leq\epsilon\) at least one of the executions from \(S\) will always satisfy the corresponding output specification. Hence, for every such \(S\) we add the constraint: \(\sum_{i\in S}z_{i}\geq 1\). Now, let for any \(i\in I\), \(\{(\mathbf{L}_{i}^{1},b_{i}^{1}),\ldots,(\mathbf{L}_{i}^{m},b_{i}^{m})\}\) denote set of linear approximation with \(b_{i}^{m}\) either coming from RACoon or from strong branching. Then we add the following constraints \(z_{i}\geq z_{i}^{\prime}\), \(z_{i}^{\prime}=(o_{i}\geq 0)\), \(o_{i}\geq\mathbf{L}_{i}^{jT}(\mathbf{x_{i}}+\boldsymbol{\delta})+b_{i}^{j}\) where \(j\in[m]\), and \(o_{i}\in\mathbb{R}\), \(z_{i}^{\prime}\) are new real and integer variables respectively.

Limitations:Although RABBit outperforms SOTA verifiers in relational verification, like all deterministic verifiers, whether relational or non-relational (including ours), do not scale to deep neural networks (DNNs) trained on very large datasets such as ImageNet. RABBit is sound but incomplete, meaning it may not be able to prove certain relational properties even if they are true. Note that all complete non-relational verifiers are also incomplete for relational properties since they do not track any dependencies between executions.

## 6 Experimental Evaluation

We evaluate the effectiveness of RABBit on multiple relational properties such UAP accuracy ( Table 1) and top-k accuracy (Appendix Table 5), DNNs, and datasets. In our evaluation, we compare RABBit against SOTA baselines, including non-relational verifiers CROWN (Zhang et al., 2018), \(\alpha\)-CROWN (Xu et al., 2021), \(\alpha,\beta\)-CROWN (Wang et al., 2021), MN-BaB (Ferrari et al., 2022), GCP-CROWN (Zhang et al., 2022a), as well as relational verifiers I/O Formulation (Zeng et al., 2023) and RACoon. As previously noted, RaVeN adds linear constraints for each layer, which restricts its scalability as the number of executions \(k\) increases. Therefore, we compare RABBit with RaVeN for a smaller execution count of \(k=5\), as shown in Appendix Table 4. Additionally, we show that: a) given the same time, RABBit always outperforms the SOTA BaB-based non-relational verifier \(\alpha,\beta\)-CROWN; b) strong bounding computes a tighter bound on \(t^{*}\) than \(\alpha,\beta\)-CROWN; and c) we provide an ablation study on \(\epsilon\) and \(k\) used by RABBit.

### Experiment Setup

**Networks**. We use standard convolutional architectures, such as ConvSmall and ConvBig, which are used to evaluate both SOTA relational (Banerjee and Singh, 2024) and non-relational verifiers (Wang et al., 2021) (see Table 1). We provide the details of the DNN architectures in the Appendix D.1. We use networks trained using both standard training methods and robust training strategies, such as DiffAI (Mirman et al., 2018), SABR (Mueller et al., 2023), and CITRUS (Xu and Singh, 2024). Our experiments utilize publicly available pre-trained DNNs sourced from the CROWN repository (Zhang et al., 2020), \(\alpha,\beta\)-CROWN repository (Wang et al., 2021), and ERAN repository (Singh et al., 2019). The clean accuracies of these networks are reported in Appendix D.2.

**Implementation details and hyperparameters**. We implemented our method in Python with Pytorch V1.11 on top of SOTA complete non-relational verifier \(\alpha,\beta\)-CROWN (Wang et al., 2021). We used Gurobi V11.0 as the off-the-shelf MILP solver. For both strong bounding and strong branching, we use Adam (Kingma and Ba, 2014) for parameter learning and run it for 20 iterations on each subproblem. We set the value of \(k_{t}=10\) for CIFAR-10 and \(k_{t}=24\) for MNIST networks respectively. We use a single NVIDIA A100-PCI GPU with 40 GB RAM for bound refinement and an Intel(R) Xeon(R) Silver 4214R CPU @ 2.40GHz with 64 GB RAM for MILP optimization. For any relational property with \(k\) executions, we give an overall timeout of \(k\) minutes (averaging 1 minute/execution) to RABBit and all baselines. Each MILP instance gets a timeout of \(10\) minutes. We issue the MILP optimization call on line 25 of Algo. 1 in a separate thread for runtime optimization, ensuring that the MILP optimization process does not unnecessarily block the subsequent iterations of the while loop (line 20 of Algo. 1).

### Experimental Results

**Effectiveness of RABBit:** Table 1 compares the results of RABBit to all baselines across different datasets (column 1) and DNN architectures (column 2) trained with various methods (column 3), with \(\epsilon\) values defining the \(L_{\infty}\) bound of \(\boldsymbol{\delta}\) in column 4. For each DNN and \(\epsilon\), we run RABBit and all the baselines on 10 relational properties each defined with \(k=50\) randomly selected inputs, and report the worst-case UAP accuracy averaged over the 10 properties. Note that for each DNN, we exclude inputs misclassified by the DNN. We compare the performance of RABBit against SOTA relational and complete non-relational verifiers as well as against strong bounding and strong branching.

The results in Table 1 demonstrate that strong bounding, strong branching, and RABBit all outperform the existing SOTA verifiers on all DNNs and \(\epsilon\). Notably, RABBit gains up to \(+4.8\%\) and up to \(+3.2\%\) improvement in the worst-case UAP accuracy (averaged over 10 runs) for CIFAR10 and MNIST DNNs, respectively. RABBit also efficiently scales to the largest verifiable DNN architectures such as ConvBig, conferring up to +1.6% improvement in worst-case UAP accuracy. In some cases, strong bounding outperforms strong branching, while in others, strong branching outperforms strong

\begin{table}
\begin{tabular}{c c c c c c c c c c c c c c c} \hline \hline Dataset & Network & Training & Perturbation & CROWN & \(\alpha\)-CROWN & \(\alpha,\beta\)-CROWN & MN-BaB & GCP-CROWN & 10 & RACon & Strong & Strong & RABBit \\  & Structure & Method & Bound(\(\epsilon\)) & & & & & & & & & & & & \\  & Cronwall & Standard & 1.025 & 44.8 & 45.4 & 62.2 & 55.0 & 64.8 & 45.4 & 45.4 & 63.5 (+1.6) & 63.2 (+1.0) & 65.4 (+1.2) \\  & Cronwall & Standard & 1.025 & 44.4 & 49.6 & 53.8 & 55.0 & 53.8 & 50.4 & 51.6 & 59.0 (+1.0) & 59.0 (+1.0) & 59.0 (+1.3) \\ CIFAR10 & Crosswall & SABR & 2.255 & 72.5 & 75.8 & 79.4 & 80.0 & 58.0 & 75.8 & 78.2 & 50.1 (+1.0) & 53.5 (+1.3) & 53.5 (+1.0) \\  & Cronwall & GTRUS & 2.255 & 74.8 & 76.0 & 79.2 & 79.6 & 79.6 & 77.0 & 78.2 & 81.8 (+1.0) & 32.1 (+1.0) & 33.0 (+1.0) \\  & Cron-Eng & Default & 2.255 & 46.6 & 51.8 & 61.2 & 61.6 & 64.2 & 51.2 & 53.2 & 54.6 (+1.2) & 62.5 (+1.0) & 63.0 (+1.6) \\ \hline \multirow{4}{*}{MNIST} & Crosswall & Standard & 0.07 & 53.0 & 59.4 & 83.6 & 77.4 & 84.2 & 60.0 & 66.6 & 51.2 (+1.2) & 66.1 (+1.0) & 64.8 (+1.0) \\  & Cronwall & Pyramid & 0.13 & 51.8 & 57.0 & 76.6 & 77.0 & 77.0 & 77.2 & 57.2 & 89.0 (+1.0) & 68.1 (+1.0) \\ \cline{1-1}  & Crosswall & SABR & 0.15 & 27.0 & 36.0 & 50.4 & 51.2 & 60.2 & 42.2 & 45.8 & 62.6 (+1.2) & 62.1 (+1.0) & 63.4 (+1.2) \\ \cline{1-1}  & Crosswall & CTPRUS & 0.15 & 28.8 & 41.6 & 73.0 & 69.2 & 73.0 & 41.6 & 44.6 & 74.0 (+1.0) & 73.4 (+0.4) & 74.6 (+1.0) \\ \hline \hline \end{tabular}
\end{table}
Table 1: RABBit Efficacy Analysis for Worst-Case UAP Accuracybounding, highlighting the importance of both methods. RABBit combines the strengths of both strong branching and strong bounding, producing the best results overall.

**Time vs UAP Accuracy Analysis:** Fig. 1 shows timewise the worst-case UAP accuracy (averaged over 10 runs) for different ConvSmall CIFAR10 networks with \(k=50\) on \(\epsilon\) values from Table 1. Note that RABBit invokes RACoon, which in turn calls \(\alpha\)-CROWN and eliminates verified executions (Line 7 in Algorithm 1). Hence, for a fair comparison, we also run \(\alpha\)-CROWN first for \(\alpha,\beta\)-CROWN and then run \(\alpha,\beta\)-CROWN only on the unverified indices. For all DNNs, RABBit consistently outperforms the SOTA BaB-based non-relational verifier \(\alpha,\beta\)-CROWN at all timestamps. This confirms that the improved precision shown in Table 1 is not dependent on the specific timeout value.

**Evaluating Bound Improvement:** In Figs 2 and 3, we present a timewise analysis of the improvement in \(t^{*}\) with strong bounding over \(\alpha,\beta\)-CROWN and RACoon. For this experiment, we use DiffAI and CITRUS ConvSmall networks with epsilon values from Table 1. For each network and \(\epsilon\), we select 30 executions at random and compute the percentage improvement in \(t^{*}\) with strong bounding over RACoon and \(\alpha,\beta\)-CROWN.We also report the average improvement and 95% confidence intervals for all cases in Table 6 in Appendix G. The results demonstrate that the \(t^{*}\) with strong bounding is significantly tighter compared to the bounds from the SOTA verifiers \(\alpha,\beta\)-CROWN and

Figure 1: Average Worst Case \(k\)-UAP accuracy vs Time for ConvSmall CIFAR10 DNNs.

Figure 3: Timewise Analysis of Average % Improvement in \(t^{*}\) with Strong Bounding (MNIST)

Figure 2: Timewise Analysis of Average % Improvement in \(t^{*}\) with Strong Bounding (CIFAR10)

RACoon at all timestamps. Furthermore, strong bounding improves \(t^{*}\) on average by up to 108.7% for CIFAR10 networks and 57.7% for MNIST networks. These results highlight the importance of leveraging dependencies across executions during both branching and bounding to improve precision.

**Different \(\epsilon\) and \(k\) values:** Fig. 4 shows the results of RACoon, \(\alpha,\beta\)-CROWN, and RABBit for \(k\)-UAP verification of CIFAR10 ConvSmall DNNs for 5 different \(\epsilon\) values and \(k=50\). RABBit outperforms RACoon and \(\alpha,\beta\)-CROWN for all evaluated \(\epsilon\) values, notably improving the worst case \(k\)-UAP accuracy by up to 4.8%. Similarly, we analyze the performance of RACoon, \(\alpha,\beta\)-CROWN, and RABBit for \(k\)-UAP verification of CIFAR10 ConvSmall DNNs with different \(k\) values. As presented in Fig. 5, for all \(k\) values, RABBit is more precise than both baselines. Expectedly, the worst-case \(k\)-UAP accuracy for relational verifiers is higher with larger \(k\) values as it is easier to prove the absence of a common perturbation with larger \(k\).

## 7 Conclusion

We present RABBit, a general framework for improving the precision of relational verification of DNNs through BaB methods specifically designed to utilize dependencies across executions. Our experiments, on various DNN architectures, and training methods demonstrate that RABBit significantly outperforms both SOTA relational and non-relational verifiers for relational properties. Although we focus on the worst-case UAP accuracy and top-k accuracy RABBit can be extended to properties involving different DNNs, such as local equivalence of DNN pairs Paulsen et al. (2020) or properties defined over an ensemble of DNNs.

## Acknowledgement

We thank the anonymous reviewers for their insightful comments. This work was supported in part by NSF Grants No. CCF-2238079, CCF-2316233, CNS-2148583.

Figure 4: Average Worst Case \(k\)-UAP accuracy vs \(\epsilon\) for CIFAR10 DNNs.

Figure 5: Average Worst Case \(k\)-UAP accuracy for different \(k\) values for CIFAR10 ConvSmall DNNs.

## References

* Amato et al. (2013) Filippo Amato, Alberto Lopez, Eladia Maria Pena-Mendez, Petr Vanhara, Ales Hampl, and Josef Havel. Artificial neural networks in medical diagnosis. _Journal of Applied Biomedicine_, 11(2), 2013.
* Anderson et al. (2020) Ross Anderson, Joey Huchette, Will Ma, Christian Tjandraatmadja, and Juan Pablo Vielma. Strong mixed-integer programming formulations for trained neural networks. _Mathematical Programming_, 2020.
* 32nd International Conference, CAV 2020, Los Angeles, CA, USA, July 21-24, 2020, Proceedings, Part I_, volume 12224 of _Lecture Notes in Computer Science_, pages 66-96. Springer, 2020. doi: 10.1007/978-3-030-53288-8_4. URL https://doi.org/10.1007/978-3-030-53288-8_4.
* Balunovic et al. (2019) Mislav Balunovic, Maximilian Baader, Gagandeep Singh, Timon Gehr, and Martin Vechev. Certifying geometric robustness of neural networks. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alche-Buc, E. Fox, and R. Garnett, editors, _Advances in Neural Information Processing Systems_, volume 32. Curran Associates, Inc., 2019. URL https://proceedings.neurips.cc/paper_files/paper/2019/file/f7fa6aca028e7ff4ef62d75ed025fe76-Paper.pdf.
* Banerjee and Singh (2024) Debangshu Banerjee and Gagandeep Singh. Relational DNN verification with cross executional bound refinement. In _Forty-first International Conference on Machine Learning_, 2024. URL https://openreview.net/forum?id=HOG80Yk4Gw.
* Banerjee et al. (2024a) Debangshu Banerjee, Avaljot Singh, and Gagandeep Singh. Interpreting robustness proofs of deep neural networks. In _The Twelfth International Conference on Learning Representations_, 2024a. URL https://openreview.net/forum?id=Ev10F9TWML.
* Banerjee et al. (2024b) Debangshu Banerjee, Changming Xu, and Gagandeep Singh. Input-relational verification of deep neural networks. _Proc. ACM Program. Lang._, 8(PLDI), June 2024b. doi: 10.1145/3656377. URL https://doi.org/10.1145/3656377.
* Banerjee et al. (2020a) Debangshu Banerjee, Changming Xu, and Gagandeep Singh. Scalable relational verification and training for deep neural networks. 2024c.
* Bunel et al. (2020a) Rudy Bunel, Jingyue Lu, Ilker Turkaslan, Pushmeet Kohli, P Torr, and P Mudigonda. Branch and bound for piecewise linear neural network verification. _Journal of Machine Learning Research_, 21 (2020a), 2020a.
* Bunel et al. (2020b) Rudy Bunel, Ilker Turkaslan, Philip H. S. Torr, M. Pawan Kumar, Jingyue Lu, and Pushmeet Kohli. Branch and bound for piecewise linear neural network verification. _J. Mach. Learn. Res._, 21(1), jan 2020b. ISSN 1532-4435.
* Bunel et al. (2020c) Rudy R Bunel, Oliver Hinder, Srinadh Bhojanapalli, and Krishnamurthy Dvijotham. An efficient non-convex reformulation of stagewise convex optimization problems. _Advances in Neural Information Processing Systems_, 33, 2020c.
* Cohen et al. (2019) Jeremy Cohen, Elan Rosenfeld, and Zico Kolter. Certified adversarial robustness via randomized smoothing. In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, _Proceedings of the 36th International Conference on Machine Learning_, volume 97 of _Proceedings of Machine Learning Research_, pages 1310-1320. PMLR, 09-15 Jun 2019. URL https://proceedings.mlr.press/v97/cohen19c.html.
* Ehlers (2017) Ruediger Ehlers. Formal verification of piece-wise linear feed-forward neural networks. In _International Symposium on Automated Technology for Verification and Analysis_, 2017.
* Ferrari et al. (2022) Claudio Ferrari, Mark Niklas Mueller, Nikola Jovanovic, and Martin Vechev. Complete verification via multi-neuron relaxation guided branch-and-bound. In _International Conference on Learning Representations_, 2022. URL https://openreview.net/forum?id=l_amHf10aK.
* Furnst et al. (2019)

[MISSING_PAGE_FAIL:12]

* De Palma et al. (2021) Alessandro De Palma, Harkirat S. Behl, Rudy R. Bunel, Philip H. S. Torr, and M. Pawan Kumar. Scaling the convex barrier with active sets. In _9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021_, 2021.
* De Palma et al. (2024) Alessandro De Palma, Rudy R Bunel, Krishnamurthy Dj Dvijotham, M. Pawan Kumar, Robert Stanforth, and Alessio Lomuscio. Expressive losses for verified robustness via convex combinations. In _The Twelfth International Conference on Learning Representations_, 2024. URL https://openreview.net/forum?id=mzyZ4wzK1M.
* Paulsen et al. (2020) Brandon Paulsen, Jingbo Wang, and Chao Wang. Reludiff: Differential verification of deep neural networks. In _Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering_, ICSE '20, page 714-726, New York, NY, USA, 2020. Association for Computing Machinery. ISBN 9781450371216. doi: 10.1145/3377811.3380337. URL https://doi.org/10.1145/3377811.3380337.
* Paulsen et al. (2021) Brandon Paulsen, Jingbo Wang, Jiawei Wang, and Chao Wang. Neurodiff: Scalable differential verification of neural networks using fine-grained approximation. In _Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering_, ASE '20, page 784-796, New York, NY, USA, 2021. Association for Computing Machinery. ISBN 9781450367684. doi: 10.1145/3324884.3416560. URL https://doi.org/10.1145/3324884.3416560.
* Shi et al. (2024) Zhouxing Shi, Qirui Jin, J Zico Kolter, Suman Jana, Cho-Jui Hsieh, and Huan Zhang. Formal verification for neural networks with general nonlinearities via branch-and-bound, 2024. URL https://openreview.net/forum?id=ivokwVKY4o.
* Singh et al. (2018) Gagandeep Singh, Timon Gehr, Matthew Mirman, Markus Puschel, and Martin Vechev. Fast and effective robustness certification. _Advances in Neural Information Processing Systems_, 31, 2018.
* Singh et al. (2019a) Gagandeep Singh, Rupanshu Ganvir, Markus Puschel, and Martin Vechev. Beyond the single neuron convex barrier for neural network certification. In _Advances in Neural Information Processing Systems_, 2019a.
* Singh et al. (2019b) Gagandeep Singh, Timon Gehr, Markus Puschel, and Martin Vechev. An abstract domain for certifying neural networks. _Proceedings of the ACM on Programming Languages_, 3(POPL), 2019b.
* Ugare et al. (2023) Shubham Ugare, Debangshu Banerjee, Sasa Misailovic, and Gagandeep Singh. Incremental verification of neural networks. _Proc. ACM Program. Lang._, 7(PLDI), June 2023. doi: 10.1145/3591299. URL https://doi.org/10.1145/3591299.
* Ugare et al. (2024) Shubham Ugare, Tarun Suresh, Debangshu Banerjee, Gagandeep Singh, and Sasa Misailovic. Incremental randomized smoothing certification. In _The Twelfth International Conference on Learning Representations_, 2024. URL https://openreview.net/forum?id=SdeAPV1irk.
* Wang et al. (2018) Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, and Suman Jana. Efficient formal safety analysis of neural networks. In _Advances in Neural Information Processing Systems_, 2018.
* Wang et al. (2021) Shiqi Wang, Huan Zhang, Kaidi Xu, Xue Lin, Suman Jana, Cho-Jui Hsieh, and J Zico Kolter. Beta-CROWN: Efficient bound propagation with per-neuron split constraints for neural network robustness verification. In A. Beygelzimer, Y. Dauphin, P. Liang, and J. Wortman Vaughan, editors, _Advances in Neural Information Processing Systems_, 2021. URL https://openreview.net/forum?id=ahY11RBeCFw.
* Wu et al. (2023) Haoze Wu, Teruhiro Tagomori, Alexander Robey, Fengjun Yang, Nikolai Matni, George Pappas, Hamed Hassani, Corina Pasareanu, and Clark Barrett. Toward certified robustness against real-world distribution shifts. In _2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML)_, pages 537-553. IEEE, 2023.
* Xie et al. (2021) Chulin Xie, Minghao Chen, Pin-Yu Chen, and Bo Li. Crfl: Certifiably robust federated learning against backdoor attacks. In _International Conference on Machine Learning_, pages 11372-11382. PMLR, 2021.
* Xu and Singh (2024) Changming Xu and Gagandeep Singh. Cross-input certified training for universal perturbations, 2024.
* Xu et al. (2020)Kaidi Xu, Zhoxing Shi, Huan Zhang, Yihan Wang, Kai-Wei Chang, Minlie Huang, Bhavya Kailkhura, Xue Lin, and Cho-Jui Hsieh. Automatic perturbation analysis for scalable certified robustness and beyond. In _Proceedings of the 34th International Conference on Neural Information Processing Systems_, NIPS '20, Red Hook, NY, USA, 2020. Curran Associates Inc. ISBN 9781713829546.
* Xu et al. (2021) Kaidi Xu, Huan Zhang, Shiqi Wang, Yihan Wang, Suman Jana, Xue Lin, and Cho-Jui Hsieh. Fast and complete: Enabling complete neural network verification with rapid and massively parallel incomplete verifiers. In _International Conference on Learning Representations_, 2021. URL https://openreview.net/forum?id=nVZtXB16LNn.
* Zeng et al. (2023) Yi Zeng, Zhoxing Shi, Ming Jin, Feiyang Kang, Lingjuan Lyu, Cho-Jui Hsieh, and Ruoxi Jia. Towards robustness certification against universal perturbations. In _The Eleventh International Conference on Learning Representations_, 2023. URL https://openreview.net/forum?id=7GEvPKxjtt.
* Zhang et al. (2018) Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, and Luca Daniel. Efficient neural network robustness certification with general activation functions. _Advances in neural information processing systems_, 31, 2018.
* Zhang et al. (2020) Huan Zhang, Hongge Chen, Chaowei Xiao, Sven Gowal, Robert Stanforth, Bo Li, Duane Boning, and Cho-Jui Hsieh. Towards stable and efficient training of verifiably robust neural networks. In _Proc. International Conference on Learning Representations (ICLR)_, 2020.
* Zhang et al. (2022a) Huan Zhang, Shiqi Wang, Kaidi Xu, Linyi Li, Bo Li, Suman Jana, Cho-Jui Hsieh, and J Zico Kolter. General cutting planes for bound-propagation-based neural network verification. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, _Advances in Neural Information Processing Systems_, 2022a. URL https://openreview.net/forum?id=5haAJAcofjc.
* Zhang et al. (2022b) Yuhao Zhang, Aws Albarghouthi, and Loris D'Antoni. Bagflip: A certified defense against data poisoning. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, _Advances in Neural Information Processing Systems_, 2022b. URL https://openreview.net/forum?id=ZidkM5b92G.

## Appendix A Formal encoding of relational properties

### k-UAP verification

Given a set of \(k\) points \(\mathbf{X}=\{\mathbf{x}_{1},...,\mathbf{x}_{\mathbf{k}}\}\) where for all \(i\in[k],\mathbf{x_{i}}\in\mathbb{R}^{n_{0}}\) and \(\epsilon\in\mathbb{R}\) we can first define individual input constraints used to define \(L_{\infty}\) input region for each execution \(\forall i\in[k].\phi_{in}^{i}(\mathbf{x_{i}^{*}})=\|\mathbf{x_{i}^{*}}- \mathbf{x_{i}}\|_{\infty}\leq\epsilon\). We define \(\Phi^{\delta}(\mathbf{x_{1}^{*}},\dots,\mathbf{x_{k}^{*}})\) as follows:

\[\Phi^{\delta}(\mathbf{x_{1}^{*}},\dots,\mathbf{x_{k}^{*}})=\bigwedge_{(i,j\in[ k])\wedge(i<j)}(\mathbf{x_{i}^{*}}-\mathbf{x_{j}^{*}}=\mathbf{x_{i}}-\mathbf{x_{ j}})\] (2)

Then, we have the input specification as \(\Phi(\mathbf{x_{1}^{*}},\dots,\mathbf{x_{k}^{*}})=\bigwedge_{i=1}^{k}\phi_{in} ^{i}(\mathbf{x_{i}^{*}})\wedge\Phi^{\delta}(\mathbf{x_{1}^{*}},\dots,\mathbf{ x_{k}^{*}})\).

Next, we define \(\Psi(\mathbf{x_{1}^{*}},\dots,\mathbf{x_{k}^{*}})\) as conjunction of \(k\) clauses each defined by \(\psi^{i}(\mathbf{y_{i}})\) where \(\mathbf{y_{i}}=N(\mathbf{x_{i}^{*}})\). Now we define \(\psi^{i}(\mathbf{y_{i}})=\bigwedge_{j=1}^{n_{l}}(\mathbf{c_{i,j}}^{T}\mathbf{ y_{i}}\geq 0)\) where \(\mathbf{c_{i,j}}\in\mathbb{R}^{n_{i}}\) is defined as follows

\[\forall a\in[n_{l}].c_{i,j,a}=\begin{cases}1&\text{if $a\neq j$ and $a$ is the correct label for $\mathbf{y_{i}}$}\\ -1&\text{if $a=j$ and $a$ is not the correct label for $\mathbf{y_{i}}$}\\ 0&\text{otherwise}\end{cases}\] (3)

In this case, the tuple of inputs \((\mathbf{x_{1}^{*}},\dots,\mathbf{x_{k}^{*}})\) satisfies the input specification \(\Phi(\mathbf{x_{1}^{*}},\dots,\mathbf{x_{k}^{*}})\) iff for all \(i\in[k]\), \(\mathbf{x_{i}^{*}}=\mathbf{x_{i}}+\boldsymbol{\delta}\) where \(\boldsymbol{\delta}\in\mathbb{R}^{n_{0}}\) and \(\|\boldsymbol{\delta}\|_{\infty}\leq\epsilon\). Hence, the relational property \((\Phi,\Psi)\) defined above verifies whether there is an adversarial perturbation \(\boldsymbol{\delta}\in\mathbb{R}^{n_{0}}\) with \(\|\boldsymbol{\delta}\|_{\infty}\leq\epsilon\) that can misclassify **all**\(k\) inputs. Next, we show the formulation for the worst-case UAP accuracy of the k-UAP verification problem as described in section 3. Let, for any \(\boldsymbol{\delta}\in\mathbb{R}^{n_{0}}\) and \(\|\boldsymbol{\delta}\|_{\infty}\leq\epsilon\), \(\mu(\delta)\) denotes the number of clauses (\(\psi^{i}\)) in \(\Psi\) that are satisfied. Then \(\mu(\delta)\) is defined as follows

\[z_{i}(\boldsymbol{\delta}) =\begin{cases}1&\psi^{i}(N(\mathbf{x_{i}}+\boldsymbol{\delta})) \text{ is }True\\ 0&\text{otherwise}\end{cases}\] (4) \[\mu(\boldsymbol{\delta}) =\sum_{i=1}^{k}z_{i}(\boldsymbol{\delta})\] (5)

Since \(\psi^{i}(N(\mathbf{x_{i}}+\boldsymbol{\delta}))\) is \(True\) iff the perturbed input \(\mathbf{x_{i}}+\boldsymbol{\delta}\) is correctly classified by \(N\), for any \(\boldsymbol{\delta}\in\mathbb{R}^{n_{0}}\) and \(\|\boldsymbol{\delta}\|_{\infty}\leq\epsilon\), \(\mu(\boldsymbol{\delta})\) captures the number of correct classifications over the set of perturbed inputs \(\{\mathbf{x_{1}}+\boldsymbol{\delta},\dots,\mathbf{x_{k}}+\boldsymbol{\delta}\}\). The worst-case k-UAP accuracy \(\mathbf{M}_{0}(\Phi,\Psi)\) for \((\Phi,\Psi)\) is as follows

\[\mathbf{M}_{0}(\Phi,\Psi)=\min_{\boldsymbol{\delta}\in\mathbb{R}^{n_{0}},\; \|\boldsymbol{\delta}\|_{\infty}\leq\epsilon}\mu(\boldsymbol{\delta})\] (6)

## Appendix B Details of strong bounding

For fixed linear approximations \(\{(\mathbf{L}_{1},b_{1}),\dots(\mathbf{L}_{n},b_{n})\}\) corresponding to \(n\) executions of \(N\) if the optimal value \(t^{*}\) of the following linear program \(\geq 0\) then the \(n\) executions do not have a common peturbation (from Theorem B.3. Banerjee and Singh [2024]).

\[min\;\;t\;\;\;\text{s.t.}\;\|\boldsymbol{\delta}\|_{\infty}\leq\epsilon\] \[\mathbf{L_{i}}^{T}(\mathbf{x_{i}}+\boldsymbol{\delta})+b_{i}\leq t \;\;\;\;\;\forall i\in[n]\] (7)

Now in the first step, we compute the Lagrangian dual of the linear program from Eq. 7. The Lagrangian Dual is as follows where for all \(i\in[n]\), \(\lambda_{i}\geq 0\) are Lagrange multipliers.

\[\max_{0\leq\lambda_{i}}\min_{t\in\mathbb{R},\|\boldsymbol{\delta}\|_{\infty} \leq\epsilon}(1-\sum_{i=1}^{n}\lambda_{i})\times t+\sum_{i=1}^{n}\lambda_{i} \times\left(\mathbf{L}_{i}^{T}(\mathbf{x_{i}}+\boldsymbol{\delta})+b_{i}\right)\]

We set the coefficient of the unbounded variable \(t\) to \(0\) to avoid cases where \(\min_{t\in\mathbb{R},\|\boldsymbol{\delta}\|_{\infty}\leq\epsilon}(1-\sum_{i=1} ^{n}\lambda_{i})\times t+\sum_{i=1}^{n}\lambda_{i}\times\left(\mathbf{L}_{i}^{T}( \mathbf{x_{i}}+\boldsymbol{\delta})+b_{i}\right)=-\infty\). This leads to the following Lagrangian Dual form

\[\max_{0\leq\lambda_{i}}\min_{\|\boldsymbol{\delta}\|_{\infty}\leq\epsilon}\sum_ {i=1}^{n}\lambda_{i}\times\left(\mathbf{L}_{i}^{T}(\mathbf{x_{i}}+\boldsymbol{ \delta})+b_{i}\right)\quad\text{where }\sum_{i=1}^{n}\lambda_{i}=1\]Now for every subproblem, replacing the branching constraints by introducing dual variables \(\bm{\beta}\) results in the parametric linear approximations of \(N\) specified by \((\mathbf{L}_{i}(\bm{\alpha}_{i},\bm{\beta}_{i}),b_{i}(\bm{\alpha}_{i},\bm{\beta}_ {i}))\) for each execution \(i\in[n]\). Then the Lagrangian Dual with the parametric linear approximations \(\{(\mathbf{L}_{1}(\bm{\alpha}_{1},\bm{\beta}_{1}),b_{1}(\bm{\alpha}_{1},\bm{ \beta}_{1})),\ldots,(\mathbf{L}_{n}(\bm{\alpha}_{n},\bm{\beta}_{n}),b_{n}(\bm{ \alpha}_{n},\bm{\beta}_{n}))\}\) is as follows

\[\max_{0\leq\lambda_{i}}\min_{\|\bm{\delta}\|_{\infty}\leq\epsilon} \sum_{i=1}^{n}\lambda_{i}\times\big{(}\mathbf{L}_{i}(\bm{\alpha}_{i},\bm{\beta} _{i})^{T}(\mathbf{x_{i}}+\bm{\delta})+b_{i}(\bm{\alpha}_{i},\bm{\beta}_{i}) \big{)}\quad\text{where }\sum_{i=1}^{n}\lambda_{i}=1\]

**Theorem 4.1**.: _If \(\min_{\mathcal{F}(S)}\max_{\bm{\alpha}_{i},\bm{\beta}_{i},\lambda_{i}}- \epsilon\times\|\sum_{i\in S}\lambda_{i}\times\mathbf{L}_{i}(\bm{\alpha}_{i}, \bm{\beta}_{i})\|_{1}+\sum_{i\in S}\lambda_{i}\times a_{i}(\bm{\alpha}_{i},\bm {\beta}_{i})\geq 0\) then executions in \(S\) do not have a common perturbation \(\bm{\delta}\in\mathbb{R}^{n_{0}}\) with \(\|\bm{\delta}\|_{\infty}\leq\epsilon\)._

Proof.: First, we show that \(\min_{\|\bm{\delta}\|_{\infty}\leq\epsilon}\sum_{i=1}^{n}\lambda_{i}\times \big{(}\mathbf{L}_{i}(\bm{\alpha}_{i},\bm{\beta}_{i})^{T}(\mathbf{x_{i}}+\bm {\delta})+b_{i}(\bm{\alpha}_{i},\bm{\beta}_{i})\big{)}=-\epsilon\times\|\sum_{ i=1}^{n}\lambda_{i}\times\mathbf{L}_{i}(\bm{\alpha}_{i},\bm{\beta}_{i})\|_{1}+ \sum_{i=1}^{n}\lambda_{i}\times a_{i}(\bm{\alpha}_{i},\bm{\beta}_{i})\).

\[\min_{\|\bm{\delta}\|_{\infty}\leq\epsilon}\sum_{i=1}^{n}\lambda_ {i}\times\big{(}\mathbf{L}_{i}(\bm{\alpha}_{i},\bm{\beta}_{i})^{T}(\mathbf{x_ {i}}+\bm{\delta})+b_{i}(\bm{\alpha}_{i},\bm{\beta}_{i})\big{)}\] \[=\min_{\|\bm{\delta}\|_{\infty}\leq\epsilon}\sum_{i=1}^{n}\lambda_ {i}\times\mathbf{L}_{i}(\bm{\alpha}_{i},\bm{\beta}_{i})^{T}(\bm{\delta})+\sum _{i=1}^{n}\lambda_{i}\times\big{(}b_{i}(\bm{\alpha}_{i},\bm{\beta}_{i})+ \mathbf{L}_{i}(\bm{\alpha}_{i},\bm{\beta}_{i})^{T}\mathbf{x_{i}}\big{)}\] \[=\sum_{i=1}^{n}\lambda_{i}\times a_{i}(\bm{\alpha}_{i},\bm{\beta} _{i})+\min_{\|\bm{\delta}\|_{\infty}\leq\epsilon}\sum_{i=1}^{n}\lambda_{i} \times\mathbf{L}_{i}(\bm{\alpha}_{i},\bm{\beta}_{i})^{T}(\bm{\delta})\] \[=\sum_{i=1}^{n}\lambda_{i}\times a_{i}(\bm{\alpha}_{i},\bm{\beta} _{i})-\epsilon\times\|\sum_{i=1}^{n}\lambda_{i}\times\mathbf{L}_{i}(\bm{\alpha }_{i},\bm{\beta}_{i})\|_{1}\quad\text{Using H\"{o}lder's Inequality}\] (8)

For fixed \(\bm{\alpha}_{i},\bm{\beta}_{i}\), the optimal solution of the LP in Eq. 7 and subsequently of the Lagrangian gives us

\[\max_{0\leq\lambda_{i}}\min_{\|\bm{\delta}\|_{\infty}\leq\epsilon} \sum_{i=1}^{n}\lambda_{i}\times\big{(}\mathbf{L}_{i}(\bm{\alpha}_{i},\bm{\beta }_{i})^{T}(\mathbf{x_{i}}+\bm{\delta})+b_{i}(\bm{\alpha}_{i},\bm{\beta}_{i}) \big{)}\] \[=\min_{\|\bm{\delta}\|_{\infty}\leq\epsilon}\max_{1\leq i\leq n} \big{(}\mathbf{L}_{i}(\bm{\alpha}_{i},\bm{\beta}_{i})^{T}(\mathbf{x_{i}}+\bm{ \delta})+b_{i}(\bm{\alpha}_{i},\bm{\beta}_{i})\big{)}\quad\text{provided }\sum_{i=1}^{n}\lambda_{i}=1\] (9)

For each subproblem, for all \(\bm{\alpha}_{i},\bm{\beta}_{i}\)

\[\min_{\|\bm{\delta}\|_{\infty}\leq\epsilon}\max_{1\leq i\leq n} \mathbf{c_{i}}^{T}N(\mathbf{x_{i}}+\bm{\delta})\geq\min_{\|\bm{\delta}\|_{ \infty}\leq\epsilon}\max_{1\leq i\leq n}\big{(}\mathbf{L}_{i}(\bm{\alpha}_{i}, \bm{\beta}_{i})^{T}(\mathbf{x_{i}}+\bm{\delta})+b_{i}(\bm{\alpha}_{i},\bm{\beta }_{i})\big{)}\]

Hence,

\[\min_{\|\bm{\delta}\|_{\infty}\leq\epsilon}\max_{1\leq i\leq n} \mathbf{c_{i}}^{T}N(\mathbf{x_{i}}+\bm{\delta})\] \[\geq\max_{\bm{\alpha}_{i},\bm{\beta}_{i}}\min_{\|\bm{\delta}\|_{ \infty}\leq\epsilon}\max_{1\leq i\leq n}\big{(}\mathbf{L}_{i}(\bm{\alpha}_{i}, \bm{\beta}_{i})^{T}(\mathbf{x_{i}}+\bm{\delta})+b_{i}(\bm{\alpha}_{i},\bm{\beta}_ {i})\big{)}\] \[\geq\max_{\bm{\alpha}_{i},\bm{\beta}_{i}}\max_{0\leq\lambda_{i}} \min_{\|\bm{\delta}\|_{\infty}\leq\epsilon}\sum_{i=1}^{n}\lambda_{i}\times \big{(}\mathbf{L}_{i}(\bm{\alpha}_{i},\bm{\beta}_{i})^{T}(\mathbf{x_{i}}+\bm{ \delta})+b_{i}(\bm{\alpha}_{i},\bm{\beta}_{i})\big{)}\quad\text{where }\sum_{i=1}^{n}\lambda_{i}=1\text{ from Eq.~{}\ref{eq:eq

## Appendix C Details of strong branching

**Theorem 4.2**.: _For any \(\bm{\alpha},\bm{\beta}\), if \(\mathbf{L}(\bm{\alpha},\bm{\beta})\in\mathbb{R}^{n_{0}}\) and \(b(\bm{\alpha},\bm{\beta})\in\mathbb{R}\) then \(\min_{\|\bm{\delta}\|_{\infty}\leq\epsilon}(\mathbf{L}(\bm{\alpha},\bm{\beta}) -\mathbf{L}_{t})^{T}(\mathbf{x}+\bm{\delta})+b(\bm{\alpha},\bm{\beta})=- \epsilon\times\|\mathbf{L}(\bm{\alpha},\bm{\beta})-\mathbf{L}_{t}\|_{1}+( \mathbf{L}(\bm{\alpha},\bm{\beta})-\mathbf{L}_{t})^{T}\mathbf{x}+b(\bm{\alpha },\bm{\beta})\)._

Proof.: \[\min_{\|\bm{\delta}\|_{\infty}\leq\epsilon}(\mathbf{L}(\bm{\alpha },\bm{\beta})-\mathbf{L}_{t})^{T}(\mathbf{x}+\bm{\delta})+b(\bm{\alpha},\bm{ \beta})\] \[=\min_{\|\bm{\delta}\|_{\infty}\leq\epsilon}(\mathbf{L}(\bm{ \alpha},\bm{\beta})-\mathbf{L}_{t})^{T}\bm{\delta}+b(\bm{\alpha},\bm{\beta})+ (\mathbf{L}(\bm{\alpha},\bm{\beta})-\mathbf{L}_{t})^{T}\mathbf{x}\] \[=b(\bm{\alpha},\bm{\beta})+(\mathbf{L}(\bm{\alpha},\bm{\beta})- \mathbf{L}_{t})^{T}\mathbf{x}+\min_{\|\bm{\delta}\|_{\infty}\leq\epsilon}( \mathbf{L}(\bm{\alpha},\bm{\beta})-\mathbf{L}_{t})^{T}\bm{\delta}\] \[=b(\bm{\alpha},\bm{\beta})+(\mathbf{L}(\bm{\alpha},\bm{\beta})- \mathbf{L}_{t})^{T}\mathbf{x}-\epsilon\times\|(\mathbf{L}(\bm{\alpha},\bm{ \beta})-\mathbf{L}_{t})\|_{1}\quad\text{Using H\"{o}lder's Inequality}\]

### Projected gradient ascent

For each \(\bm{\alpha_{i}},\bm{\beta}_{i}\), after each step of gradient ascent (for maximization problem), we clip \(\bm{\alpha_{i}},\bm{\beta}_{i}\) values to the corresponding ranges \([\bm{l_{i}}^{\bm{\alpha}},\bm{u_{i}}^{\bm{\alpha}}]\)\([\bm{l_{i}}^{\bm{\beta}},\bm{u_{i}}^{\bm{\beta}}]\) respectively. This is similar to the approach used in the SOTA non-relational bound refinement \(\alpha,\beta\)-CROWN Wang et al. (2021). Since \(\lambda_{i}\in[0,1]\) and \(\sum_{i=1}^{k}\lambda_{i}=1\) we replace \(\lambda_{i}=\frac{sigmoid(x_{i})}{\sum_{i=1}^{k}sigmoid(x_{i})}\) where \(x_{i}\in\mathbb{R}\). For any values of \((x_{1},\dots,x_{k})\in\mathbb{R}^{k}\) the corresponding \((\lambda_{1},\dots,\lambda_{k})\) satisfy \(\lambda_{i}\in[0,1]\) and \(\sum_{i=1}^{k}\lambda_{i}=1\). We then apply gradient ascent (for maximization problem) on \((x_{1},\dots,x_{k})\) without any constraints.

[MISSING_PAGE_EMPTY:18]

[MISSING_PAGE_EMPTY:19]

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: See Section 1 for main claims and contributions. The main claims made in this section and the abstract reflect the paper's scope and contributions. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: See end of Section 5 for the limitations. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes]Justification:

Guidelines:

* The answer NA means that the paper does not include theoretical results.
* All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
* All assumptions should be clearly stated or referenced in the statement of any theorems.
* The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.
* Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.
* Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: See experimental setup in Section 6. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?Answer: [Yes] Justification: We provide the code to replicate the main results of this paper. Guidelines:

* The answer NA means that paper does not include experiments requiring code.
* Please See Section the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See Section the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: See experimental setup in Section 6. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: RABBit is a deterministic verifier. The experiment "Evaluating Bound Improvement" (Section 6) is the only randomized experiment in the paper. We report the mean and 95% confidence intervals of the experiment in Appendix G. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors).

* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: See experimental setup in Section 6. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: Submission meets all ethical guidelines after authors reviewed the NeurIPS Code of Ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: See Section 1 and Section 7 for societal impacts of the work. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.

* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: No data or models with high risk for misuse were used. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: We have only utilized publically available code, models, and datasets and properly cited all relevant works. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.

* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [Yes] Justification: We provide the code to replicate the main results of this paper. Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: No crowdsourcing nor human research with subject participants. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: No crowdsourcing nor human research with subject participants. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.