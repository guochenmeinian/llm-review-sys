# A Unified Framework for Rank-based Loss Minimization

 Rufeng Xiao\({}^{*}\)   Yuze Ge\({}^{*}\)   Rujun Jiang\({}^{\dagger}\)   Yifan Yan

School of Data Science, Fudan University

{rfxiao21,yze23}@m.fudan.edu.cn

rjjiang@fudan.edu.cn

yanyf21@m.fudan.edu.cn

Equal contribution

###### Abstract

The empirical loss, commonly referred to as the average loss, is extensively utilized for training machine learning models. However, in order to address the diverse performance requirements of machine learning models, the use of the rank-based loss is prevalent, replacing the empirical loss in many cases. The rank-based loss comprises a weighted sum of sorted individual losses, encompassing both convex losses like the spectral risk, which includes the empirical risk and conditional value-at-risk, and nonconvex losses such as the human-aligned risk and the sum of the ranked range loss. In this paper, we introduce a unified framework for the optimization of the rank-based loss through the utilization of a proximal alternating direction method of multipliers. We demonstrate the convergence and convergence rate of the proposed algorithm under mild conditions. Experiments conducted on synthetic and real datasets illustrate the effectiveness and efficiency of the proposed algorithm.

## 1 Introduction

The empirical risk function is the cornerstone of machine learning. By minimizing this function, machine learning models typically achieve commendable average performance. However, as these models find applications across a diverse spectrum of real-world scenarios, the evaluation standards for machine learning performance have evolved to include factors such as risk aversion and fairness [49, 9]. This has led to the empirical loss function often being supplanted by other loss functions, many of which fall under the category of the rank-based loss, which consists of a weighted sum of sorted individual losses. We consider the following optimization problem in this paper, which minimizes the rank-based loss plus a regularizer:

\[\min_{\bm{w}\in\mathbb{R}^{d}}\quad\sum_{i=1}^{n}\sigma_{i}\bm{l}_{[i]}\left(- \bm{y}\odot(X\bm{w})\right)+g(\bm{w}).\] (1)

Here, \(\bm{l}(\bm{u})\triangleq\left[l(u_{1}),\ldots,l(u_{n})\right]^{\top}:\mathbb{ R}^{n}\rightarrow\mathbb{R}^{n}\) represents a vector-valued mapping where \(l:\mathbb{R}\rightarrow\mathbb{R}\) denotes an individual loss function and \(u_{i}\) is the \(i\)-th element of \(\bm{u}\), \(\bm{l}_{[1]}(\cdot)\leqslant\cdots\leqslant\bm{l}_{[n]}(\cdot)\) denotes the order statistics of the empirical loss distribution, \(g:\mathbb{R}^{d}\rightarrow\mathbb{R}\) is a regularizer that induces desired structures, \(\bm{w}\in\mathbb{R}^{d}\) represents the parameters of the linear model, \(X\in\mathbb{R}^{n\times d}\) is the data matrix, and \(\bm{y}\in\{\pm 1\}^{n}\) is the label vector. The subscript \([i]\) denotes the \(i\)-th smallest element, \(\sigma_{i}\in[0,1]\) is the weight corresponding to the \(i\)-th smallest element, and "\(\odot\)" represents the Hadamard product. Depending on the values of \(\sigma_{i}\), the rank-based loss can encompass a significant range of losses oftenused in machine learning and other fields: the L-risk or the spectral risk [1; 2; 35], the trimmed risk or the sum of the ranked-range loss [27], the human-aligned risk based on the cumulative prospect theory [31].

**Related work.** When the values of \(\sigma_{i}\) are constant and monotonically increase, i.e., \(\sigma_{1}\leq\dots\leq\sigma_{n}\), the rank-based loss is referred to as the spectral risk [1]. Several methods have been proposed in the literature, including: a derivative-free method proposed by [25] that utilizes a stochastic smoothing technique; an adaptive sampling algorithm proposed by [14] for the minimization of conditional value at risk (CVaR), which is a special case of the spectral risk; and a stochastic algorithm developed by [36] for minimizing the general spectral risk by characterizing the subdifferential of the rank-based loss. In the case of nonconvex rank-based losses, [27] utilizes the difference of convex algorithm for minimizing the average of ranked-range (AoRR) loss. The nonconvex human-aligned risk was minimized by [31] by directly computing the gradient of the function, even though the rank-based loss is nondifferentiable, without any convergence guarantee. Despite the increasing applications of the rank-based loss, a unified framework for addressing the rank-based loss minimization remains elusive. Moreover, stochastic methods may encounter bias issues [36], existing methods for the spectral risk cannot deal with nonconvex rank-based losses, and existing methods for human-aligned risk lack convergence guarantee [31].

**Our Contributions.** We present a unified framework for the minimization of the rank-based loss to overcome the challenges of existing methods. Specifically, we focus on monotone increasing loss functions, such as the hinge loss and the logistic loss, and use weakly convex regularizers. We leverage the alternating direction multiplier method (ADMM), which is widely used in solving nonsmooth nonconvex composite problems [8; 32; 48]. To utilize the ADMM framework, we introduce an auxiliary variable to represent the product of the data matrix and parameter vector. The two subproblems are either strongly convex (with a proximal term), which can be solved by various existing methods, or can be efficiently solved by the pool adjacent violators algorithm (PAVA) [6]. We demonstrate that our algorithm can find an \(\epsilon\)-KKT point in at most \(O(1/\epsilon^{2})\) iterations under mild conditions. To relax the assumptions further, we propose a variant of the ADMM with a smoothing technique when the regularizer is nonsmooth. Notably, when the Moreau envelope is applied to smooth the nonsmooth regularizer, we show that our algorithm can find an \(\epsilon\)-KKT point within \(O(1/\epsilon^{4})\) iterations.

Our contributions can be summarized as follows:

1. We propose a unified framework for the rank-based loss minimization for monotonically increasing loss functions. This approach is versatile, effectively dealing with both convex and nonconvex loss functions by allowing different settings of weights \(\sigma_{i}\).
2. Furthermore, the regularizer in our problem can be weakly convex functions, extending existing works that only consider convex or smooth regularizers, such as the \(l_{1}\) and \(l_{2}\) penalty.
3. We theoretically demonstrate that our ADMM algorithm converges to an \(\epsilon\)-approximate KKT point under different assumptions.
4. The experiments in three different aggregate loss function frameworks demonstrate the advantages of the proposed algorithm.

## 2 Preliminaries

In this section, we explore the wide variety of rank-based losses and introduce the Moreau envelope as a smooth approximation of weakly convex functions.

### Rank-Based Loss

Let \(\{(X_{1},y_{1}),\dots,(X_{n},y_{n})\}\) be an i.i.d. sample set from a distribution \(\mathbb{P}\) over a sample space \((\mathcal{X},\mathcal{Y})\), and \(\mathcal{L}\) be the individual loss function. Then \(Y=\mathcal{L}(\bm{w},X,y)\) is also a random variable, and \(Y_{i}=\mathcal{L}(\bm{w},X_{i},y_{i})\) represents the \(i\)-th training loss with respect to the sample \((X_{i},y_{i})\), \(i\in\{1,\dots,n\}\). Let \(Y_{[1]}\leq\dots\leq Y_{[n]}\) be the order statistics. The rank-based loss function in problem (1) equals

\[\sum_{i=1}^{n}\sigma_{i}Y_{[i]}.\] (2)Spectral RiskThe spectral risk, as defined in [1], is given by:

\[\mathrm{R}_{\sigma}(\bm{w})=\int_{0}^{1}\mathrm{VaR}_{t}(\bm{w})\sigma(t)\,dt,\] (3)

where \(\mathrm{VaR}_{t}(\bm{w})=\inf\left\{u:\mathrm{F}_{\bm{w}}(u)\geq t\right\}\) denotes the quantile function, and \(F_{\bm{w}}\) represents the cumulative distribution function of \(Y\). The function \(\sigma:[0,1]\rightarrow\mathbb{R}_{+}\) is a nonnegative, nondecreasing function that integrates to 1, known as the spectrum of the rank-based loss. The discrete form of (3) is consistent with (2), with \(\sigma_{i}=\int_{(i-1)/n}^{i/n}\sigma(t)\,dt\)[36]. The spectral risk builds upon previous aggregate losses that have been widely used to formulate learning objectives, such as the average risk [46], the maximum risk [43], the average top-\(k\) risk [21] and conditional value-at-risk [39]. By choosing a different spectral \(\sigma(t)\), such as the superquantile [30], the extremile [15], and the exponential spectral risk measure [11], can be constructed for various spectral risks.

Human-Aligned RiskWith the growing societal deployment of machine learning models for aiding human decision-making, these models must possess qualities such as fairness, in addition to strong average performance. Given the significance of these additional requirements, amendments to risk measures and extra constraints have been introduced [28, 23, 19]. Inspired by the cumulative prospect theory (CPT) [45], which boasts substantial evidence for its proficiency in modeling human decisions, investigations have been carried out in bandit [24] and reinforcement learning [41]. Recently, [31] also utilized the concept of CPT to present a novel notion of the empirical human risk minimization (EHRM) in supervised learning. The weight assigned in (3) is defined as \(\sigma_{i}=w_{a,b}(\frac{i}{n})\), where

\[w_{a,b}(t)=\frac{3-3b}{a^{2}-a+1}\left(3t^{2}-2(a+1)t+a\right)+1.\]

These weights assign greater significance to extreme individual losses, yielding an S-shaped CPT-weighted cumulative distribution. Moreover, we consider another CPT-weight commonly employed in decision making [45, 41]. Let \(\bm{z}=-\bm{y}\odot(X\bm{w})\) and \(B\) be a reference point. Unlike previous weight settings, \(\sigma_{i}\) is related to the value of \(z_{[i]}\) and is defined as

\[\sigma_{i}(z_{[i]})=\begin{cases}\omega_{-}(\frac{i}{n})-\omega_{-}(\frac{i-1 }{n}),&z_{[i]}\leq B,\\ \omega_{+}(\frac{n-i+1}{n})-\omega_{+}(\frac{n-i}{n}),&z_{[i]}>B,\end{cases}\] (4)

where

\[\omega_{+}(p)=\frac{p^{\gamma}}{\left(p^{\gamma}+(1-p)^{\gamma}\right)^{1/ \gamma}},\quad\omega_{-}(p)=\frac{p^{\delta}}{\left(p^{\delta}+(1-p)^{\delta} \right)^{1/\delta}},\] (5)

with \(\gamma\) and \(\delta\) as hyperparameters.

Ranked-Range LossThe average of ranked-range aggregate (AoRR) loss follows the same structure as (2), where

\[\sigma_{i}=\begin{cases}\frac{1}{k-m},&i\in\{m+1,\dots,k\},\\ 0,&\text{otherwise},\end{cases}\] (6)

with \(1\leq m<k\leq n\). The ranked-range loss effectively handles outliers, ensuring the robustness of the model against anomalous observations in the dataset [27]. It is clear that AoRR includes the average loss, the maximum loss, the average top-\(k\) loss, value-at-risk [39] and the median loss [34]. [27] utilized the difference-of-convex algorithm (DCA) [40] to solve the AoRR aggregate loss minimization problem, which can be expressed as the difference of two convex problems.

### Weakly Convex Function and Moreau Envelope

A function \(g:\mathbb{R}^{d}\rightarrow\mathbb{R}\) is said to be \(c\)-weakly convex for some \(c>0\) if the function \(g+\frac{c}{2}\|\cdot\|^{2}\) is convex. The class of weakly convex functions is extensive, encompassing all convex functions as well as smooth functions with Lipschitz-continuous gradients [37]. In our framework, we consider weakly convex functions as regularizers. It is worth noting that weakly convex functions constitute a rich class of regularizers. Convex \(L^{p}\) norms with \(p\geq 1\) and nonconvex penalties such as the Minimax Concave Penalty (MCP) [52] and the Smoothly Clipped Absolute Deviation (SCAD) [20] are examples of weakly convex functions [7].

Next, we define the Moreau envelope of \(c\)-weakly convex function \(g(\bm{w})\), with proximal parameter \(0<\gamma<\frac{1}{c}\):

\[M_{g,\gamma}(\bm{w})=\min_{\bm{x}}\left\{g(\bm{x})+\frac{1}{2\gamma}\|\bm{x}-\bm {w}\|^{2}\right\}.\] (7)

The proximal operator of \(g\) with parameter \(\gamma\) is given by

\[\mathrm{prox}_{g,\gamma}(\bm{w})=\arg\min_{\bm{x}}\left\{g(\bm{x})+\frac{1}{2 \gamma}\|\bm{x}-\bm{w}\|^{2}\right\}.\]

We emphasize that \(\mathrm{prox}_{g,\gamma}(\cdot)\) is a single-valued mapping, and \(M_{g,\gamma}(\bm{w})\) is well-defined since the objective function in (7) is strongly convex for \(\gamma\in\left(0,c^{-1}\right)\)[7].

The Moreau envelope is commonly employed to smooth weakly convex functions. From [7, Lemma 3.1-3.2] we have

\[\nabla M_{g,\gamma}(\bm{w})=\gamma^{-1}\left(\bm{w}-\mathrm{prox}_{g,\gamma}( \bm{w})\right)\in\partial g\left(\mathrm{prox}_{g,\gamma}\left(\bm{w}\right) \right).\] (8)

Here \(\partial\) represents Clarke generalized gradient [10]. For locally Lipschitz continuous function \(f:\mathbb{R}^{d}\rightarrow\mathbb{R}\), its Clarke generalized gradient is denoted by \(\partial f(\bm{x})\). We say \(\bm{x}\) is stationary for \(f\) if \(\bm{0}\in\partial f(\bm{x})\). For convex functions, Clarke generalized gradient coincides with subgradient in the sense of convex analysis. Under assumptions in Section 3.3, both \(\Omega(\bm{z}):=\sum_{i=1}^{n}\sigma_{i}l_{[i]}\left(\bm{z}\right)\) and \(g(\bm{w})\) are locally Lipschitz continuous [12, 47]. Thus, the Clarke generalized gradients of \(\Omega(\bm{z})\) and \(g(\bm{w})\) are well defined, and so is that of \(L_{\rho}(\bm{w},\bm{z};\bm{\lambda})\) defined in Section 3.1.

## 3 Optimization Algorithm

Firstly, we make the basic assumption about the loss function \(l\) and the regularizer \(g\):

**Assumption 1**: _The individual loss function \(l(\cdot):\mathcal{D}\rightarrow\mathbb{R}\) is convex and monotonically increasing, where \(\mathcal{D}\subset\mathbb{R}\) is the domain of \(l\). The regularizer \(g(\cdot):\mathbb{R}^{d}\rightarrow\mathbb{R}\cup\{\infty\}\) is proper, lower semicontinuous, and \(c\)-weakly convex. Furthermore, \(l(\cdot)\) and \(g(\cdot)\) are lower bounded by 0._

Many interesting and widely used individual loss functions satisfy this assumption, such as logistic loss, hinge loss, and exponential loss. Our algorithm described below can also handle monotonically decreasing loss functions, by simply replacing \(\sigma_{i}\) with \(\sigma_{n-i+1}\) in (1). We assume \(l\) and \(g\) are lower bounded, and take the infimum to be 0 for convenience. The lower bounded property of \(l\) implies that the \(\Omega\) is also lower bounded by 0 since \(\sigma_{i}\geq 0\) for all \(i\).

### The ADMM Framework

By Assumption 1, the original problem is equivalent to

\[\min_{\bm{w}}\sum_{i=1}^{n}\sigma_{i}l\left(\left(D\bm{w}\right)_{[i]}\right)+ g(\bm{w}),\]

where \(l\) is the individual loss function, \(D=-\operatorname{diag}(\bm{y})X\) and \(\operatorname{diag}(\bm{y})\) denotes the diagonal matrix whose diagonal entries are the vector \(\bm{y}\).

To make use of the philosophy of ADMM, by introducing an auxiliary variable \(\bm{z}=D\bm{w}\), we reformulate the problem as

\[\min_{\bm{w},\bm{z}}\quad\Omega(\bm{z})+g(\bm{w})\qquad\text{ s.t. }\quad\bm{z}=D\bm{w},\] (9)

where \(\Omega(\bm{z})=\sum_{i=1}^{n}\sigma_{i}l\left(z_{[i]}\right).\)

Note that for human-aligned risk, \(\sigma_{i}\) should be written as \(\sigma_{i}(z_{[i]})\) since it is a piecewise function with two different values in (4), but for simplicity, we still write it as \(\sigma_{i}\).

The augmented Lagrangian function can then be expressed as

\[L_{\rho}(\bm{w},\bm{z};\bm{\lambda})=\sum_{i=1}^{n}\Omega(\bm{z})+\frac{\rho}{ 2}||\bm{z}-D\bm{w}+\frac{\bm{\lambda}}{\rho}||^{2}+g(\bm{w})-\frac{||\bm{ \lambda}||^{2}}{2\rho}.\]The ADMM, summarised in Algorithm 1, cyclically updates \(\bm{w},\bm{z}\) and \(\bm{\lambda}\), by solving the \(\bm{w}\)- and \(\bm{z}\)-subproblems and adopting a dual ascent step for \(\bm{\lambda}\). In Algorithm 1, we assume the \(\bm{w}\)- subproblem can be solved exactly (for simplicity). When \(g(\bm{w})\) is a smooth function, the \(\bm{w}\)-subproblem is a smooth problem and can be solved by various gradient-based algorithms. Particularly, the \(\bm{w}\)-subproblem is the least squares and admits a closed-form solution if \(g(\bm{w})\equiv 0\) or \(g(\bm{w})=\frac{\mu}{2}||\bm{w}||_{2}^{2}\), where \(\mu>0\) is a regularization parameter. When \(g(\bm{w})\) is nonsmooth, if \(\mathrm{prox}_{g,\gamma}(\bm{w})\) is easy to compute, we can adopt the proximal gradient method or its accelerated version [4]. Particularly, if \(g(\bm{w})=\frac{\mu}{2}||\bm{w}||_{1}\), then the subproblem of \(\bm{w}\) becomes a LASSO problem, solvable by numerous effective methods such as the Coordinate Gradient Descent Algorithm (CGDA) [22], the Smooth L1 Algorithm (SLA) [42], and the Fast Iterative Shrinkage-Thresholding Algorithms (FISTA) [4].

```
0:\(X\), \(\bm{y}\), \(\bm{w}^{0}\), \(\bm{z}^{0}\), \(\bm{\lambda}^{0}\), \(\rho\), \(r\), and \(\sigma_{i},i=1,...,n\).
1:for all\(k=0,1,...\)do
2:\(\bm{z}^{k+1}=\arg\min_{\bm{z}}\Omega(\bm{z})+\frac{\rho}{2}||\bm{z}-D\bm{w}^{ k}+\frac{\bm{\lambda}^{k}}{\rho}||^{2}\).
3:\(\bm{w}^{k+1}=\arg\min_{\bm{w}}\frac{\rho}{2}||\bm{z}^{k+1}-D\bm{w}+\frac{\bm{ \lambda}^{k}}{\rho}||^{2}+g(\bm{w})+\frac{r}{2}\|\bm{w}-\bm{w}^{k}\|^{2}\).
4:\(\bm{\lambda}^{k+1}=\bm{\lambda}^{k}+\rho(\bm{z}^{k+1}-D\bm{w}^{k+1})\).
5:endfor ```

**Algorithm 1** ADMM framework

At first glance, the \(\bm{z}\)-subproblem is nonconvex and difficult to solve. However, we can solve an equivalent convex chain-constrained program that relies on sorting and utilize the pool adjacent violators algorithm (PAVA). More specifically, we follow the approach presented in [13, Lemma 3] and introduce the auxiliary variable \(\bm{m}=D\bm{w}^{k}-\frac{\bm{\lambda}^{k}}{\rho}\) (we remove the superscript for \(\bm{m}\) for simplicity). This enables us to express the \(\bm{z}\)-subproblem in the equivalent form below

\[\min_{\bm{z}}\quad\sum_{i=1}^{n}\sigma_{i}l(z_{p_{i}})+\frac{\rho}{2}(z_{p_{i} }-m_{p_{i}})^{2}\qquad\text{s.t. }z_{p_{1}}\leq z_{p_{2}}\leq\cdots\leq z_{p_{n}},\]

where \(\{p_{1},p_{2},\ldots,p_{n}\}\) is a permutation of \(\{1,\ldots,n\}\) such that \(m_{p_{1}}\leqslant m_{p_{2}}\leqslant\cdots\leqslant m_{p_{n}}\).

### The Pool Adjacent Violators Algorithm (PAVA)

To introduce our PAVA, for ease of notation and without loss of generality, we consider \(m_{1}\leqslant m_{2}\leqslant\cdots\leqslant m_{n}\), i.e., the following problem

\[\min_{\bm{z}}\quad\sum_{i=1}^{n}\sigma_{i}l(z_{i})+\frac{\rho}{2}(z_{i}-m_{i} )^{2}\qquad\text{s.t. }z_{1}\leq z_{2}\leq\cdots\leq z_{n}.\] (10)

The above problem constitutes a convex chain-constrained program. Although it can be solved by existing convex solvers, the PAVA [6] is often more efficient.

The PAVA is designed to solve the following problem

\[\min_{\bm{z}}\quad\sum_{i=1}^{n}\theta_{i}(z_{i})\qquad\text{s.t. }z_{1}\leq z_{2}\leq\cdots\leq z_{n},\]

where each \(\theta_{i}\) represents a univariate _convex_ function. In our problem, \(\theta_{i}(z_{i})=\sigma_{i}l(z_{i})+\frac{\rho}{2}(z_{i}-m_{i})^{2}\). The PAVA maintains a set \(J\) that partitions the indices \(\{1,2,\ldots,n\}\) into consecutive blocks \(\{[s_{1}+1,s_{2}],[s_{2}+1,s_{3}],\cdots,[s_{k}+1,s_{k+1}]\}\) with \(s_{1}=0\) and \(s_{k+1}=N\). Here, \([a,b]\) represents the index set \(\{a,a+1,\ldots,b\}\) for positive integers \(a<b\), and by convention, we define \([a,a]=a\). A block \([p,q]\) is termed a _single-valued block_ if every \(z_{i}\) in the optimal solution of the following problem has the same value,

\[\min_{z_{p},\ldots,z_{q}}\quad\sum_{i=p}^{q}\theta_{i}(z_{i})\qquad\text{s.t. }z_{p}\leq z_{p+1}\leq\cdots\leq z_{q},\]

i.e., \(z_{p}^{*}=z_{p+1}^{*}=\cdots=z_{q}^{*}\). In line with existing literature, we use \(v_{[p,q]}\) to denote this value. For two consecutive blocks \([p,q]\) and \([q+1,r]\), if \(v_{[p,q]}\leq v_{[q+1,r]}\), the two blocks are _in-order_; otherwise, they are _out-of-order_. Similarly, the consecutive blocks \(\{[s_{k},s_{k+1}]\,,[s_{k+1}+1,s_{k+2}]\,,\cdots,[s_{k+t}+1,s_{k+t+1}]\}\) are said to be _in-order_ if \(v_{[s_{k}s_{k+1}]}\leq v_{[s_{k+1}+1,s_{k+2}]}\leq\cdots\leq v_{[s_{k+t}+1,s_{k +t+1}]}\); otherwise they are _out-of-order_. Particularly, if \(v_{[s_{k}s_{k+1}]}>v_{[s_{k+1}+1,s_{k+2}]}>\cdots>v_{[s_{k+t}+1,s_{k+t+1}]}\), the consecutive blocks are said to be _consecutive out-of-order_. The PAVA initially partitions each integer from 1 to \(n\) into single-valued blocks \([i,i]\) for \(i=1,\ldots,n\). When there are consecutive _out-of-order_ single-valued blocks \([p,q]\) and \([q+1,r]\), the PAVA merges these two blocks by replacing them with the larger block \([p,r]\). The PAVA terminates once all the single-valued blocks are in-order.

```
0:\(J=\{[1,1],[2,2],\ldots,[n,n]\}\), \(\theta_{i},i=1,2,\ldots,n\).
0:\(\{y_{1}^{*},y_{2}^{*},\ldots,y_{N}^{*}\}\)
1:for each \([i,i]\in J\)do
2: Compute the minimizer \(v_{[i,i]}\) of \(\theta_{i}(\bm{y})\)
3:endfor
4:while exists out-of-order blocks in \(J\)do
5: Find consecutive out-of-order blocks \(C=\{[s_{k},s_{k+1}],[s_{k+1}+1,s_{k+2}],\cdots,[s_{k+t}+1,s_{k+t+1}]\}\).
6:\(J\gets J\backslash C\cup\{[s_{k},s_{k+t+1}]\}\), compute the minimizer \(v_{[s_{k},s_{k+t+1}]}\) of \(\sum_{i=s_{k}}^{s_{k+t+1}}\theta_{i}(\bm{z})\).
7:endwhile
8:for each \([m,n]\in J\)do
9:\(y_{i}^{*}=v_{[m,n]},\;\forall i=m,m+1,\ldots,n\).
10:endfor ```

**Algorithm 2** A refined pool-adjacent-violators algorithm for solving problem (10)

Traditional PAVA processes the merging of _out-of-order_ blocks one by one, identifying two consecutive _out-of-order_ blocks and then solving a single unconstrained convex minimization problem to merge them. For constant \(\sigma_{i}\), our proposed Algorithm 2, however, leverages the unique structure of our problem to improve the PAVA's efficiency. Specifically, we can identify and merge multiple consecutive _out-of-order_ blocks, thereby accelerating computation. This acceleration is facilitated by the inherent properties of our problem. Notably, in case the spectral risk and the rank-ranged loss, the function \(\theta_{i}(z_{i})\) demonstrates strong convexity due to the presence of the quadratic term \(\frac{\rho}{2}(z_{i}-m_{i})^{2}\) and the convex nature of \(l(z_{i})\). This key observation leads us to the following proposition.

**Proposition 1**: _For constant \(\sigma_{i}\), suppose \(v_{[m,n]}>v_{[n+1,p]}\), the blocks \([m,n]\) and \([n+1,p]\) are consecutive out-of-order blocks. We merge these two blocks into \([m,p]\). Then the block optimal value, denoted by \(v_{[m,p]}\), satisfies \(v_{[n+1,p]}\leq v_{[m,p]}\leq v_{[m,n]}\)._

Proposition 1 provides a crucial insight: when we encounter consecutive _out-of-order_ blocks with a length greater than 2, we can merge them simultaneously, rather than performing individual block merges. This approach significantly improves the efficiency of the algorithm. To illustrate this concept, consider a scenario where we have a sequence of values arranged as \(v_{[1,2]}>v_{[3,4]}>v_{[5,6]}\). Initially, we merge the blocks \([1,2]\) and \([3,4]\), resulting in \(v_{[1,4]}\geq v_{[3,4]}>v_{[5,6]}\). However, since \(v_{[1,4]}\) is still greater than \(v_{[5,6]}\), we need to merge the blocks \([1,4]\) and \([5,6]\) as well. Rather than calculating \(v_{[1,4]}\) separately, we can streamline the process by directly merging the entire sequence into a single block, namely \([1,6]\), in a single operation. By leveraging this approach, we eliminate the need for intermediate calculations and reduce the computational burden associated with merging individual blocks. This results in a more efficient version of the PAVA. Further details can be found in Appendix B.3.

It is worth noting that when \(\theta_{i}(z_{i})\) is convex with respect to \(z_{i}\), the PAVA guarantees to find a global minimizer [6]. However, when considering the empirical human risk minimization with CPT-weight in (4), the function \(\theta_{i}(z_{i})\) is nonconvex, which is because \(\sigma_{i}\) is a piecewise function with two different values. In such cases, we can still find a point that satisfies the first-order condition [12, Theorem 3]. In summary, we always have

\[\bm{0}\in\partial_{\bm{z}}L_{\rho}(\bm{w}^{k+1},\bm{z};\bm{\lambda}^{k}).\] (11)

### Convergence Analysis of Algorithm 1

We now demonstrate that Algorithm 1 is guaranteed to converge to an \(\epsilon\)-KKT point of problem (9). To this end, we shall make the following assumptions.

**Assumption 2**: _The sequence \(\{\bm{\lambda}^{k}\}\) is bounded and satisfies \(\sum_{k=1}^{\infty}\|\bm{\lambda}^{k}-\bm{\lambda}^{k+1}\|^{2}<\infty.\)_

It is worth noting that Assumption 2 is commonly employed in ADMM approaches [51, 44, 3].

Next, we present our convergence result based on the aforementioned assumptions. As mentioned in Section 3.2, the PAVA can always find a solution for the \(\bm{z}\)-subproblem that satisfies the first-order condition (11). When \(\sigma_{i}\) is constant, which is the case of the spectral risk and the AoRR risk, the subproblems of PAVA are strongly convex, and we can observe the descent property of the \(\bm{z}\)-subproblem:

\[L_{\rho}(\bm{z}^{k},\bm{w}^{k},\bm{\lambda}^{k})-L_{\rho}(\bm{z}^{k+1},\bm{w}^ {k},\bm{\lambda}^{k})\geq 0.\] (12)

However, if \(\sigma_{i}\) has different values for \(\bm{z}\) less than and larger than the reference point \(B\) as in (4), the subproblems of PAVA may lose convexity, and the descent property may not hold. Thus, we assume that (12) holds for simplicity. By noting that the \(w\)-subproblem can be solved exactly as it is strongly convex, we make the following assumption.

**Assumption 3**: _The \(\bm{w}\)-subproblem is solved exactly, and the \(\bm{z}\)-subproblem is solved such that (11) and (12) hold._

**Theorem 1**: _Assume that Assumptions 1, 2 and 3 hold. Then Algorithm 1 can find an \(\epsilon\)-KKT point \((\bm{z}^{k+1},\bm{w}^{k+1},\bm{\lambda}^{k+1})\) of problem (9) within \(O(1/\epsilon^{2})\) iterations, i.e.,_

\[\mathrm{dist}\left(-\bm{\lambda}^{k+1},\partial\Omega\left(\bm{z}^{k+1} \right)\right)\leq\epsilon,\quad\mathrm{dist}\left(D^{\top}\bm{\lambda}^{k+1}, \partial g\left(\bm{w}^{k+1}\right)\right)\leq\epsilon,\quad\|\bm{z}^{k+1}-D \bm{w}^{k+1}\|\leq\epsilon,\]

_where \(\mathrm{dist}(\bm{a},A)=\min\{\|\bm{a}-\bm{x}\|:\;\bm{x}\in A\}\) defines the distance of a point \(\bm{a}\) to a set \(A\)._

In the absence of Assumption 2, a common assumption for nonconvex ADMM is that \(g(\bm{w})\) possesses a Lipschitz continuous gradient [48, 32], e.g., \(g(\bm{w})=\frac{\mu}{2}\|\bm{w}\|^{2}\). Under this assumption, Algorithm 1 guarantees to find an \(\epsilon\)-KKT point within \(O(1/\epsilon^{2})\) iterations [48, 32].

## 4 ADMM for a Smoothed Version of Problem (1)

In Section 3.3, our convergence result is established under Assumption 2 when a nonsmooth regularizer \(g(\bm{w})\) is present. In this section, to remove this assumption, we design a variant of the proximal ADMM by smoothing the regularizer \(g(\bm{w})\). We employ the Moreau envelope to smooth \(g(\bm{w})\) and replace \(g(\bm{w})\) in Algorithm 1 with \(M_{g,\gamma}(\bm{w})\). We point out that \(M_{g,\gamma}(\bm{w})\) is a \(\gamma^{-1}\) weakly convex function if \(0<c\gamma\leq\frac{1}{3}\). Thus the \(w\)-subproblem is still strongly convex and can be solved exactly. See Appendix A.1 for proof. We assume that the sequence \(\{\bm{\lambda}^{k}\}\) is bounded, which is much weaker than Assumption 2. We will show that within \(O(1/\epsilon^{4})\) iterations, \((\bm{z}^{k},\tilde{\bm{w}}^{k},\bm{\lambda}^{k})\) is an \(\epsilon\)-KKT point, where \(\tilde{\bm{w}}^{k}=\mathrm{prox}_{g,\gamma}(\bm{w}^{k})\).

To compensate for the absence of Assumption 2, we introduce the following more practical assumptions.

**Assumption 4**: _We assume \(\bm{z}^{k}\in Im(D)\;\forall k\), where \(Im(D)=\{D\bm{x}:\bm{x}\in\mathbb{R}^{d}\}.\)_

A stronger version of Assumption 4 is that \(DD^{\top}=(\mathrm{diag}(\bm{y})X)(\mathrm{diag}(\bm{y})X)^{\top}=\mathrm{ diag}(\bm{y})XX^{\top}\mathrm{diag}(\bm{y})\succ 0\)[32]. It is worth noting that the full row rank property of the data matrix is often assumed in the high dimensional setting classification (\(m<d\) and each entry of \(\bm{y}\) belongs to \(\{-1,1\}\)). Here we do not impose any assumptions on the rank of data matrix \(X\).

**Assumption 5**: \(\nabla M_{g,\gamma}(\bm{w})\) _is bounded by \(M>0\), i.e., \(\|\nabla M_{g,\gamma}(\bm{w})\|\leq M,\;\forall\bm{w}\in\mathbb{R}^{n}.\)_

Regarding nonsmooth regularizers, Assumption 5 is satisfied by weakly convex functions that are Lipschitz continuous [7], due to the fact that Lipschitz continuity implies bounded subgradients and (8). Common regularizers such as \(l_{1}\)-norm, MCP and SCAD are all Lipschitz continuous.

The following proposition establishes the relationship between \(\{(\bm{z}^{k},\bm{w}^{k},\bm{\lambda}^{k})\}\) and \(\{(\bm{z}^{k},\tilde{\bm{w}}^{k},\bm{\lambda}^{k})\}\).

**Proposition 2**: _Suppose \(g\) is \(c\)-weakly convex and Assumption 3 holds. Suppose the sequence \(\{(\bm{z}^{k},\bm{w}^{k},\bm{\lambda}^{k})\}\) is produced during the iterations of Algorithm 1 with replacing \(g(\bm{w})\) by \(M_{g,\gamma}(\bm{w})\) and \(\tilde{\bm{w}}^{k}=\mathrm{prox}_{g,\gamma}(\bm{w}^{k})\). Then we have_

\[\bm{0}\in\partial\Omega(\bm{z}^{k+1})+\bm{\lambda}^{k+1}+\rho D( \bm{w}^{k+1}-\bm{w}^{k}),\qquad D^{T}\bm{\lambda}^{k+1}+r(\bm{w}^{k}-\bm{w}^{k +1})\in\partial g(\tilde{\bm{w}}^{k+1}).\] (13)

Before presenting our main results, we introduce a Lyapunov function that plays a significant role in our analysis:

\[\Phi^{k}=L_{\rho}(\bm{w}^{k},\bm{z}^{k},\bm{\lambda}^{k})+\frac{2 r^{2}}{\sigma\rho}\|\bm{w}^{k}-\bm{w}^{k-1}\|^{2}.\]

The following lemma demonstrates the sufficient decrease property for \(\Phi^{k}\).

**Lemma 1**: _Let \(r>\gamma^{-1}\). Under Assumptions 1, 3, 4 and 5, if \(0<c\gamma\leq\frac{1}{3}\), then we have_

\[\Phi^{k}-\Phi^{k+1}\geq(\frac{2r-\gamma^{-1}}{2}-\frac{4r^{2}}{ \sigma\rho}-\frac{2}{\sigma\rho\gamma^{2}})\|\bm{w}^{k+1}-\bm{w}^{k}\|^{2}+ \frac{1}{\rho}\|\bm{\lambda}^{k+1}-\bm{\lambda}^{k}\|^{2}.\] (14)

The sufficient decrease property for the Lyapunov function is crucial in the proof of nonconvex ADMM. Using Lemma 1, we can control \(\|\bm{w}^{k+1}-\bm{w}^{k}\|\) and \(\|\bm{\lambda}^{k+1}-\bm{\lambda}^{k}\|\) through the decrease of the Lyapunov function. We are now ready to present the main result of this section.

**Theorem 2**: _Suppose \(\{\bm{\lambda}^{k}\}\) is bounded. Set \(\gamma=\epsilon\leq\frac{1}{3c},\ \rho=\frac{C_{1}}{\epsilon},\ r=\frac{C_{2}}{\epsilon}\), where \(C_{1}\) and \(C_{2}\) are constants such that \(C_{2}>1\) and \(C_{1}>\frac{8C_{2}^{2}+\frac{1}{3c}+4}{\sigma(2C_{2}-1)}\). Under the same assumptions in Lemma 1, Algorithm 1 with replacing \(g(\bm{w})\) by \(M_{g,\gamma}(\bm{w})\) finds an \(\epsilon\)-KKT point \((\bm{z}^{k+1},\tilde{\bm{w}}^{k+1},\bm{\lambda}^{k+1})\) within \(O(1/\epsilon^{4})\) iterations, i.e.,_

\[\mathrm{dist}\left(-\bm{\lambda}^{k+1},\partial\Omega\left(\bm{ z}^{k+1}\right)\right)\leq\epsilon,\quad\mathrm{dist}\left(D^{T}\bm{\lambda}^{k+1}, \partial g\left(\tilde{\bm{w}}^{k+1}\right)\right)\leq\epsilon,\quad\|\bm{z} ^{k+1}-D\tilde{\bm{w}}^{k+1}\|\leq\epsilon.\]

## 5 Numerical Experiment

In this section, we perform binary classification experiments to illustrate both the robustness and the extensive applicability of our proposed algorithm.

When using the logistic loss or hinge loss as individual loss, the objective function of problem (1) can be rewritten as \(\sum_{i=1}^{n}\sigma_{i}\log\left(1+\exp\left(z_{[i]}\right)\right)+g(\bm{w})\) or \(\sum_{i=1}^{n}\sigma_{i}\left[1+z_{[i]}\right]_{+}+g(\bm{w}),\) where \(\bm{z}=-\bm{y}\odot(X\bm{w})\), and \(g(\bm{w})=\frac{\mu}{2}\|\bm{w}\|_{2}^{2}\) or \(g(\bm{w})=\frac{\mu}{2}\|\bm{w}\|_{1}\).

We point out some key settings:

1. For the spectral risk measures, we use the logistic loss and hinge loss as individual loss, and use \(\ell_{1}\) and \(\ell_{2}\) regularization with \(\mu\) taken as \(10^{-2}\).
2. For the average of ranked range aggregate loss, we use the logistic loss and hinge loss as individual loss and use \(\ell_{2}\) regularization with \(\mu=10^{-4}\).
3. For the empirical human risk minimization, we use the logistic loss as individual loss, and use \(\ell_{2}\) regularization with \(\mu=10^{-2}\).

As shown in Section 2.1, we can apply our proposed algorithm to a variety of frameworks such as the spectral risk measure (SRM), the average of ranked-range (AoRR) aggregate loss, and the empirical human risk minimization (EHRM). We compare our algorithm with LSVRG, SGD, and DCA: LSVRG(NU) denotes LSVRG without uniformity, and LSVRG(U) denotes LSVRG with uniformity, as detailed in [36]; SGD denotes the stochastic subgradient method in [36]; DCA denotes the difference-of-convex algorithm in [40]; sADMM refers to the smoothed version of ADMM.

The details of our algorithm setting, more experiment settings and detailed information for each dataset are provided in Appendix B. Additional experiments with synthetic datasets are presented in Appendix C.

[MISSING_PAGE_FAIL:9]

Nevertheless, as evidenced in Table 4, our proposed algorithm achieves better objective value in a shorter time for all the instances.

## 6 Conclusion

This paper considers rank-based loss optimization with monotonically increasing loss functions and weakly convex regularizers. We propose a unified ADMM framework for rank-based loss minimization. Notably, one subproblem of the ADMM is solved efficiently by the PAVA. Numerical experiments illustrate the outperformance of our proposed algorithm, with all three practical frameworks delivering satisfactory results. We also point out some limitations of our algorithm. To effectively utilize our algorithm, individual losses must exhibit monotonicity, as this allows us to use the PAVA to solve subproblems. If the sample size is large, the PAVA's computational efficiency may be hindered, potentially limiting its overall effectiveness. Future work may explore a variant using mini-batch samples, potentially improving early-stage optimization performance and overall computational efficiency.

**Acknowledgement**  Rujun Jiang is partly supported by NSFC 12171100 and Natural Science Foundation of Shanghai 22ZR1405100.

\begin{table}
\begin{tabular}{c c c c c c c c c c} \hline \hline  & \multicolumn{2}{c}{Datasets} & \multicolumn{2}{c}{**Russia**} & \multicolumn{2}{c}{**Saturlesia**} & \multicolumn{2}{c}{**Frontiers**} & \multicolumn{2}{c}{**Tissue**} & \multicolumn{2}{c}{**Tissue**} \\ \hline \multirow{6}{*}{
\begin{tabular}{c} Lepaireur \\ time (s) \\ \end{tabular} } & \multicolumn{2}{c}{ADMM} & DCA & ADMM & DCA & ADMM & DCA & ADMM & DCA & ADMM & DCA \\  & \multicolumn{2}{c}{**d3014**} & **d41535 (0.0661)** & 0.557(11.255) & **d4011 (0.0601)** & 0.693(0.0605) & **d4018 (0.0901)** & 0.685(0.0903) & **d4027 (0.0941)** & 0.691(1.0920) & **d4018 (0.0903)** \\  & \multicolumn{2}{c}{**d3014**} & **d41535 (0.0641)** & 0.673(0.297) & 3.564(0.30) & 5.58(0.96) & **d53.56(0.30)** & 1162-42(1.16) & **d403.06(0.30)** & 51.68(0.21) & **d75.88(0.37)** & 63.53(1.54) \\  & \multicolumn{2}{c}{**d3014**} & **d43036 (0.0617)** & 0.655(0.1701) & **d4017 (0.0600)** & 0.939(0.0612) & **d4000 (0.0908)** & 0.942(0.1657) & **d4017 (0.0621)** & 0.932(0.0613) & **d4033 (0.0606)** & 0.991(1.0013) \\  & \multicolumn{2}{c}{**d3014**} & **d41535 (0.063)** & 2.816(0.11) & **1.46(0.06)** & 24.15(0.067) & **23.03(0.33)** & 39.09(1.054) & **7.21(1.28)** & 14.53(1.55) & **5.31(1.42)** & 114.53(0.584) \\ \hline \hline \end{tabular}
\end{table}
Table 4: Comparison with AoRR framework. ‘objval’ denotes the objective value of problem (1).

Figure 1: Time vs. Sub-optimality gap in synthetic datasets with ERM framework. (a-d) for \(\ell_{2}\) regularization, and (e-f) for \(\ell_{1}\) regularization. Sub-optimality is defined as \(F^{k}-F^{*}\), where \(F^{k}\) represents the objective function value at the \(k\)-th iteration or epoch and \(F^{*}\) denotes the minimum value obtained by all algorithms. Plots are truncated when \(F^{k}-F^{*}<10^{-8}\).

\begin{table}
\begin{tabular}{c|c c c c|c c c} \hline \hline  & ADMM & LSVR(ON) & LSVR(U) & SGD & ADMM & LSVR(ON) & LSVR(U) & SGD \\ \hline \multirow{2}{*}{
\begin{tabular}{c} objval \\ Accuracy \\ \end{tabular} } & **0.4958 (0.0405)** & 0.5583 (0.0022) & 0.5384 (0.0023) & 0.6093 (0.0013) & BOD & -0.0521 (0.0160) & -0.0238 (0.0114) & -0.0231 (0.0110) & **-0.01600.0103** \\  & **0.7759 (0.0076)** & 0.7445 (0.0050) & 0.7488 (0.0054) & 0.6334 (0.0205) & AOD & **0.01330 (0.0609)** & 0.0449 (0.0199) & 0.0450 (0.0196) & 0.0426 (0.0078) \\  & **0.3306 (0.0071)** & 0.6585 (0.0161) & 0.6957 (0.0158) & 0.0459 (0.0060) & TI & **0.6858 (0.0018)** & 0.0933 (0.0186) & 0.0934 (0.0018) & 0.1062 (0.0062) \\  & DI & **1.0533 (0.0126)** & 1.1034 (0.0300) & 1.104 (0.0297) & 1.0586 (0.0066) & FIND & 0.0521 (0.0160) & 0.0238 (0.0114) & 0.0231 (0.0110) & **0.0160 (0.0193)** \\ \hline \hline \end{tabular}
\end{table}
Table 3: Comparison with EHRM framework. ‘objval’ denotes the objective value of problem (1).

## References

* Acerbi (2002) Acerbi, C. (2002). Spectral measures of risk: A coherent representation of subjective risk aversion. _Journal of Banking & Finance_, 26(7):1505-1518.
* Acerbi and Simonetti (2002) Acerbi, C. and Simonetti, P. (2002). Portfolio optimization with spectral measures of risk. _arXiv preprint cond-mat/0203607_.
* Bai et al. (2021) Bai, X., Sun, J., and Zheng, X. (2021). An augmented lagrangian decomposition method for chance-constrained optimization problems. _INFORMS Journal on Computing_, 33(3):1056-1069.
* Beck and Teboulle (2009) Beck, A. and Teboulle, M. (2009). A fast iterative shrinkage-thresholding algorithm for linear inverse problems. _SIAM journal on imaging sciences_, 2(1):183-202.
* Bellamy et al. (2018) Bellamy, R. K., Dey, K., Hind, M., Hoffman, S. C., Houde, S., Kannan, K., Lohia, P., Martino, J., Mehta, S., Mojsilovic, A., et al. (2018). Ai fairness 360: An extensible toolkit for detecting, understanding, and mitigating unwanted algorithmic bias. _arXiv preprint arXiv:1810.01943_.
* Best et al. (2000) Best, M. J., Chakravarti, N., and Ubhaya, V. A. (2000). Minimizing separable convex functions subject to simple chain constraints. _SIAM Journal on Optimization_, 10(3):658-672.
* Bohm and Wright (2021) Bohm, A. and Wright, S. J. (2021). Variable smoothing for weakly convex composite functions. _Journal of optimization theory and applications_, 188:628-649.
* Boyd et al. (2011) Boyd, S., Parikh, N., Chu, E., Peleato, B., Eckstein, J., et al. (2011). Distributed optimization and statistical learning via the alternating direction method of multipliers. _Foundations and Trends(r) in Machine learning_, 3(1):1-122.
* Chow et al. (2015) Chow, Y., Tamar, A., Mannor, S., and Pavone, M. (2015). Risk-sensitive and robust decision-making: a CVAR optimization approach. _Advances in neural information processing systems_, 28.
* Clarke (1990) Clarke, F. H. (1990). _Optimization and nonsmooth analysis_. SIAM.
* Cotter and Dowd (2006) Cotter, J. and Dowd, K. (2006). Extreme spectral risk measures: An application to futures clearinghouse margin requirements. _Journal of Banking & Finance_, 30(12):3469-3485.
* Cui et al. (2023) Cui, X., Jiang, R., Shi, Y., and Yan, Y. (2023). Decision making under cumulative prospect theory: An alternating direction method of multipliers. _arXiv preprint arXiv:2210.02626_.
* Cui et al. (2018) Cui, X., Sun, X., Zhu, S., Jiang, R., and Li, D. (2018). Portfolio optimization with nonparametric value at risk: A block coordinate descent method. _INFORMS Journal on Computing_, 30(3):454-471.
* Curi et al. (2020) Curi, S., Levy, K. Y., Jegelka, S., and Krause, A. (2020). Adaptive sampling for stochastic risk-averse learning. _Advances in Neural Information Processing Systems_, 33:1036-1047.
* Daouia et al. (2019) Daouia, A., Gijbels, I., and Stupfler, G. (2019). Extremiles: A new perspective on asymmetric least squares. _Journal of the American Statistical Association_, 114(527):1366-1381.
* Davis and Drusvyatskiy (2019) Davis, D. and Drusvyatskiy, D. (2019). Stochastic model-based minimization of weakly convex functions. _SIAM Journal on Optimization_, 29(1):207-239.
* Derrac et al. (2015) Derrac, J., Garcia, S., Sanchez, L., and Herrera, F. (2015). Keel data-mining software tool: Data set repository, integration of algorithms and experimental analysis framework. _J. Mult. Valued Logic Soft Comput_, 17.
* Dua et al. (2017) Dua, D., Graff, C., et al. (2017). Uci machine learning repository, 2017. _URL http://archive.ics.uci.edu/ml_, 7(1).
* Duchi et al. (2019) Duchi, J. C., Hashimoto, T., and Namkoong, H. (2019). Distributionally robust losses against mixture covariate shifts. _Under review_, 2:1.
* Fan and Li (2001) Fan, J. and Li, R. (2001). Variable selection via nonconcave penalized likelihood and its oracle properties. _Journal of the American statistical Association_, 96(456):1348-1360.

* Fan et al. [2017] Fan, Y., Lyu, S., Ying, Y., and Hu, B. (2017). Learning with average top-k loss. _Advances in neural information processing systems_, 30.
* Friedman et al. [2010] Friedman, J., Hastie, T., and Tibshirani, R. (2010). Regularization paths for generalized linear models via coordinate descent. _Journal of statistical software_, 33(1):1.
* Garcia and Fernandez [2015] Garcia, J. and Fernandez, F. (2015). A comprehensive survey on safe reinforcement learning. _Journal of Machine Learning Research_, 16(1):1437-1480.
* Gopalan et al. [2017] Gopalan, A., Prashanth, L., Fu, M., and Marcus, S. (2017). Weighted bandits or: How bandits learn distorted values that are not expected. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 31.
* Holland and Haress [2022] Holland, M. J. and Haress, E. M. (2022). Spectral risk-based learning using unbounded losses. In _International Conference on Artificial Intelligence and Statistics_, pages 1871-1886. PMLR.
* HSU [2010] HSU, C.-W. (2010). A practical guide to support vector classification. _http://www. csie. ntu. edu. tw/~ cjilin/papers/guide/guide. pdf_.
* Hu et al. [2020] Hu, S., Ying, Y., Lyu, S., et al. (2020). Learning by minimizing the sum of ranked range. _Advances in Neural Information Processing Systems_, 33:21013-21023.
* Kamishima et al. [2011] Kamishima, T., Akaho, S., and Sakuma, J. (2011). Fairness-aware learning through regularization approach. In _2011 IEEE 11th International Conference on Data Mining Workshops_, pages 643-650. IEEE.
* Kushmerick [1999] Kushmerick, N. (1999). Learning to remove internet advertisements. In _Proceedings of the third annual conference on Autonomous Agents_, pages 175-181.
* Laguel et al. [2021] Laguel, Y., Pillutla, K., Malick, J., and Harchaoui, Z. (2021). Superquantiles at work: Machine learning applications and efficient subgradient computation. _Set-Valued and Variational Analysis_, 29(4):967-996.
* Leqi et al. [2019] Leqi, L., Prasad, A., and Ravikumar, P. K. (2019). On human-aligned risk minimization. _Advances in Neural Information Processing Systems_, 32.
* Li and Pong [2015] Li, G. and Pong, T. K. (2015). Global convergence of splitting methods for nonconvex composite optimization. _SIAM Journal on Optimization_, 25(4):2434-2460.
* Lin et al. [2022] Lin, Z., Li, H., and Fang, C. (2022). _Alternating Direction Method of Multipliers for Machine Learning_. Springer.
* Ma et al. [2011] Ma, Y., Li, L., Huang, X., and Wang, S. (2011). Robust support vector machine using least median loss penalty. _IFAC Proceedings Volumes_, 44(1):11208-11213.
* Maurer et al. [2021] Maurer, A., Parletta, D. A., Paudice, A., and Pontil, M. (2021). Robust unsupervised learning via l-statistic minimization. In _International Conference on Machine Learning_, pages 7524-7533. PMLR.
* Mehta et al. [2023] Mehta, R., Roulet, V., Pillutla, K., Liu, L., and Harchaoui, Z. (2023). Stochastic optimization for spectral risk measures. In _International Conference on Artificial Intelligence and Statistics_, pages 10112-10159. PMLR.
* Nurrinskii [1973] Nurrinskii, E. A. (1973). The quasigradient method for the solving of the nonlinear programming problems. _Cybernetics_, 9(1):145-150.
* Pedregosa et al. [2011] Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., and Duchesnay, E. (2011). Scikit-learn: Machine learning in Python. _Journal of Machine Learning Research_, 12:2825-2830.
* Pflug [2000] Pflug, G. C. (2000). Some remarks on the value-at-risk and the conditional value-at-risk. _Probabilistic constrained optimization: Methodology and applications_, pages 272-281.

* Phan (2016) Phan, D. N. (2016). _DCA based algorithms for learning with sparsity in high dimensional setting and stochastical learning_. PhD thesis, Universite de Lorraine.
* Prashanth et al. (2016) Prashanth, L., Jie, C., Fu, M., Marcus, S., and Szepesvari, C. (2016). Cumulative prospect theory meets reinforcement learning: Prediction and control. In _International Conference on Machine Learning_, pages 1406-1415. PMLR.
* Schmidt et al. (2007) Schmidt, M., Fung, G., and Rosales, R. (2007). Fast optimization methods for l1 regularization: A comparative study and two new approaches. In _Machine Learning: ECML 2007: 18th European Conference on Machine Learning, Warsaw, Poland, September 17-21, 2007. Proceedings 18_, pages 286-297. Springer.
* Shalev-Shwartz and Wexler (2016) Shalev-Shwartz, S. and Wexler, Y. (2016). Minimizing the maximal loss: How and why. In _International Conference on Machine Learning_, pages 793-801. PMLR.
* Shen et al. (2014) Shen, Y., Wen, Z., and Zhang, Y. (2014). Augmented lagrangian alternating direction method for matrix separation based on low-rank factorization. _Optimization Methods and Software_, 29(2):239-263.
* Tversky and Kahneman (1992) Tversky, A. and Kahneman, D. (1992). Advances in prospect theory: Cumulative representation of uncertainty. _Journal of Risk and uncertainty_, 5:297-323.
* Vapnik (2013) Vapnik, V. (2013). _The Nature of Statistical Learning Theory_. Springer Science & Business Media.
* Vial (1983) Vial, J.-P. (1983). Strong and weak convexity of sets and functions. _Mathematics of Operations Research_, 8(2):231-259.
* Wang et al. (2019) Wang, Y., Yin, W., and Zeng, J. (2019). Global convergence of admm in nonconvex nonsmooth optimization. _Journal of Scientific Computing_, 78:29-63.
* Williamson and Menon (2019) Williamson, R. and Menon, A. (2019). Fairness risk measures. In _International Conference on Machine Learning_, pages 6786-6797. PMLR.
* Wnek (1992) Wnek, J. (1992). MONK's Problems. UCI Machine Learning Repository. DOI: 10.24432/CBR30R.
* Xu et al. (2012) Xu, Y., Yin, W., Wen, Z., and Zhang, Y. (2012). An alternating direction algorithm for matrix completion with nonnegative factors. _Frontiers of Mathematics in China_, 7:365-384.
* Zhang (2010) Zhang, C.-H. (2010). Nearly unbiased variable selection under minimax concave penalty. _The Annals of Statistics_, pages 894-942.
* Zhang et al. (2017) Zhang, Z., Song, Y., and Qi, H. (2017). Age progression/regression by conditional adversarial autoencoder. In _Proceedings of the IEEE conference on computer vision and pattern recognition_, pages 5810-5818.

## Appendix A Proofs

### Proofs for properties of Moreau envelope

**Lemma 2**: _Let \(g:\mathbb{R}^{n}\to\mathbb{R}\cup\{\infty\}\) be a \(c\)-weakly convex function. For \(0<c\gamma\leq\frac{1}{3}\), the Moreau envelope \(M_{g,\gamma}\) of \(g\) is \(\gamma^{-1}\)-weakly convex._

#### a.1.1 Proof of Lemma 2

**Lemma 3**: _Let \(g:\mathbb{R}^{n}\to\mathbb{R}\cup\{\infty\}\). Then \(g\) is \(c\)-weakly convex if and only if the following holds_

\[\langle\bm{v}-\bm{w},\bm{x}-\bm{y}\rangle\geq-c\|\bm{x}-\bm{y}\|^{2},\]

_for \(\bm{x},\bm{y}\in\mathbb{R}^{n}\), \(\bm{v}\in\partial g(\bm{x}),\bm{w}\in\partial g(\bm{y})\)._

_Proof:_ See [16, Lemma 2.1]. \(\blacksquare\)

**Lemma 4**: _Suppose \(g(\bm{w})\) is \(c\)-weakly convex. If \(0<c\gamma\leq\frac{1}{3}\), then we have_

\[\|\operatorname{prox}_{g,\gamma}(\bm{x})-\operatorname{prox}_{g,\gamma}(\bm{y })\|^{2}\leq 3\|\bm{y}-\bm{x}\|^{2}.\]

_Proof:_ Suppose \(\bm{x},\bm{y}\in\mathbb{R}^{n}\). By (8) and Lemma 3 we have

\[-c\|\operatorname{prox}_{g,\gamma}(\bm{x})-\operatorname{prox}_{g, \gamma}(\bm{y})\|^{2}\] \[=\frac{1}{2\gamma}[-\|\bm{y}-\operatorname{prox}_{g,\gamma}(\bm{ y})-\bm{x}+\operatorname{prox}_{g,\gamma}(\bm{x})\|^{2}-\|\operatorname{prox}_{g, \gamma}(\bm{y})-\operatorname{prox}_{g,\gamma}(\bm{x})\|^{2}\] \[+\|\bm{x}-\bm{y}\|^{2}].\]

Thus we have

\[(1-2c\gamma)\|\operatorname{prox}_{g,\gamma}(\bm{y})-\operatorname{ prox}_{g,\gamma}(\bm{x})\|^{2} \leq-\|\bm{y}-\operatorname{prox}_{g,\gamma}(\bm{y})-\bm{x}+ \operatorname{prox}_{g,\gamma}(\bm{x})\|^{2}+\|\bm{x}-\bm{y}\|^{2}\] \[\leq\|\bm{x}-\bm{y}\|^{2}.\]

Note that \((1-2c\gamma)^{-1}\leq 3\) when \(0<c\gamma\leq\frac{1}{3}\). Thus we have

\[\|\operatorname{prox}_{g,\gamma}(\bm{y})-\operatorname{prox}_{g,\gamma}(\bm{x} )\|^{2} \leq(1-2c\gamma)^{-1}\|\bm{x}-\bm{y}\|^{2}\leq 3\|\bm{x}-\bm{y}\|^{2}.\]

\(\blacksquare\)

**Proof of Lemma 2**

_Proof:_ For any \(\bm{x},\bm{y}\in\mathbb{R}^{n}\), we have

\[\langle\nabla M_{g,\gamma}(\bm{x})-\nabla M_{g,\gamma}(\bm{y}), \bm{x}-\bm{y}\rangle\] \[= \gamma^{-1}\langle\bm{x}-\operatorname{prox}_{g,\gamma}(\bm{x})- \bm{y}+\operatorname{prox}_{g,\gamma}(\bm{y}),\bm{x}-\bm{y}\rangle\] \[= \gamma^{-1}\|\bm{x}-\bm{y}\|^{2}+\gamma^{-1}\langle\operatorname{ prox}_{g,\gamma}(\bm{y})-\operatorname{prox}_{g,\gamma}(\bm{x}),\bm{x}-\bm{y}\rangle\] \[\geq \gamma^{-1}\|\bm{x}-\bm{y}\|^{2}-\frac{1}{2\gamma}\|\bm{x}-\bm{y }\|^{2}-\frac{1}{2\gamma}\|\operatorname{prox}_{g,\gamma}(\bm{x})- \operatorname{prox}_{g,\gamma}(\bm{y})\|^{2}\] \[\geq \frac{1}{2\gamma}\|\bm{x}-\bm{y}\|^{2}-\frac{3}{2\gamma}\|\bm{x} -\bm{y}\|^{2}\] \[= -\frac{1}{\gamma}\|\bm{x}-\bm{y}\|^{2},\]

where the first equality follows from (8) and the last inequality follows from Lemma 4. Thus \(g\) is \(\gamma^{-1}\)-weakly convex by Lemma 3.

### Proofs for ADMM in Section 3

#### a.2.1 Proof of Proposition 1

_Proof:_ First we define \(h_{[a,b]}(z)=\sum_{i=a}^{b}\theta_{i}(z)\). Due to convexity, we have

\[0\in\partial h_{[m,n]}(v_{[m,n]})\quad\text{and}\quad 0\in\partial h_{[n+1,p]}(v_{ [n+1,p]}).\]

Noting that \(v_{[m,n]}>v_{[n+1,p]}\), due to the strong convexity of \(h\), we further have

\[\partial h_{[m,n]}(v_{[n+1,p]})<0,\quad\text{and}\quad\partial h_{[n+1,p]}(v_ {[m,n]})>0,\]

where we use the convention that a set \(A>0\) (or \(<0\)) denotes that all elements \(g\in A\) satisfies \(g>0\) (or \(<0\)). Therefore we obtain that there exist \(s_{[m,n]},s_{[n+1,p]}\in\mathbb{R}\) such that

\[\partial h_{[m,p]}(v_{[m,n]}) =\partial h_{[m,n]}(v_{[m,n]})+\partial h_{[n+1,p]}(v_{[m,n]}) \ni s_{[m,n]}>0,\] \[\partial h_{[m,p]}(v_{[n+1,p]}) =\partial h_{[m,n]}(v_{[n+1,p]})+\partial h_{[n+1,p]}(v_{[n+1,p]}) \ni s_{[n+1,p]}<0.\]

As \(h_{[m,p]}\) is strongly convex in \([v_{[n+1,p]},v_{[m,n]}]\), the subgradient \(\partial h_{[m,p]}\) is strictly increasing in \([v_{[n+1,p]},v_{[m,n]}]\). That is, \(\forall x,y\in[v_{[n+1,p]},v_{[m,n]}],\forall s_{x}\in\partial h_{[m,p]}(x),s_ {y}\in\partial h_{[m,p]}(y),\)\((s_{x}-s_{y})(x-y)\geq 0\). The above facts, together with the strong convexity of \(h_{[m,p]}\), the unique minimizer \(v_{[m,p]}\) of \(h_{[m,p]}\) must lie in the interval \([v_{[n+1,p]},v_{[m,n]}]\). \(\blacksquare\)

#### a.2.2 Proof of Theorem 1

_Proof:_ We use the extended formula for Clark generalized gradient of a sum of two functions in our proofs: \(\partial(f_{1}+f_{2})(\bm{x})\subset\partial f_{1}(\bm{x})+\partial f_{2}(\bm {x})\) if \(f_{1}\) and \(f_{2}\) are finite at \(\bm{x}\) and \(f_{2}\) is differentiable at \(\bm{x}\). The equality holds if \(f_{1}\) is regular at \(\bm{x}\). [10, Theorem 2.9.8].

By Assumption 3, we have

\[\bm{0} \in\partial_{\bm{z}}\left(\Omega(\bm{z}^{k+1})+\frac{\rho}{2}|| \bm{z}^{k+1}-D\bm{w}^{k}+\frac{\bm{\lambda}^{k}}{\rho}||^{2}\right)\] (15) \[\subset\partial\Omega(\bm{z}^{k+1})+\bm{\lambda}^{k}+\rho(\bm{z}^ {k+1}-D\bm{w}^{k})\] \[=\partial\Omega(\bm{z}^{k+1})+\bm{\lambda}^{k}+\rho(\bm{z}^{k+1}- D\bm{w}^{k+1})+\rho D(\bm{w}^{k+1}-\bm{w}^{k})\] \[=\partial\Omega(\bm{z}^{k+1})+\bm{\lambda}^{k+1}+\rho D(\bm{w}^{k +1}-\bm{w}^{k}),\]

and

\[L_{\rho}(\bm{z}^{k},\bm{w}^{k},\bm{\lambda}^{k})-L_{\rho}(\bm{z}^{k+1},\bm{w} ^{k},\bm{\lambda}^{k})\geq 0.\] (16)

Here the last equality of (15) follows from \(\bm{\lambda}^{k+1}=\bm{\lambda}^{k}+\rho(\bm{z}^{k+1}-D\bm{w}^{k+1})\).

By Assumption 3 and \((r-c)\)-strong convexity of the \(\bm{w}\)-subproblem, we have

\[\bm{0} \in\partial_{\bm{w}}\left(\frac{\rho}{2}||\bm{z}^{k+1}-D\bm{w}^{k +1}+\frac{\bm{\lambda}^{k}}{\rho}||^{2}+g(\bm{w}^{k+1})+\frac{r}{2}||\bm{w}^{k +1}-\bm{w}^{k}||^{2}\right)\] (17) \[=\partial g(\bm{w}^{k+1})-D^{\top}\bm{\lambda}^{k}-\rho D^{\top} (\bm{z}^{k+1}-D\bm{w}^{k+1})+r(\bm{w}^{k+1}-\bm{w}^{k})\] \[=\partial g(\bm{w}^{k+1})-D^{\top}\bm{\lambda}^{k+1}+r(\bm{w}^{k+1 }-\bm{w}^{k}),\]

and

\[L_{\rho}(\bm{z}^{k+1},\bm{w}^{k},\bm{\lambda}^{k})-L_{\rho}(\bm{z}^{k+1},\bm{w} ^{k+1},\bm{\lambda}^{k})\geq\frac{2r-c}{2}\|\bm{w}^{k+1}-\bm{w}^{k}\|^{2}.\] (18)

The second equality of (17) is due to the fact that weakly convex functions are regular [47, Proposition 4.5]. By the dual update we have

\[L_{\rho}(\bm{z}^{k+1},\bm{w}^{k+1},\bm{\lambda}^{k})-L_{\rho}(\bm {z}^{k+1},\bm{w}^{k+1},\bm{\lambda}^{k+1})\] (19) \[= \left(\bm{\lambda}^{k}-\bm{\lambda}^{k+1}\right)^{\top}\left(\bm{ z}^{k+1}-D\bm{w}^{k+1}\right)\] \[= -\frac{1}{\rho}\|\bm{\lambda}^{k+1}-\bm{\lambda}^{k}\|^{2}.\]Summing (16), (18) and (19) we obtain that

\[L_{\rho}(\bm{z}^{k},\bm{w}^{k},\bm{\lambda}^{k})-L_{\rho}(\bm{z}^{k+1},\bm{w}^{k+ 1},\bm{\lambda}^{k+1})\geq\frac{2r-c}{2}\|\bm{w}^{k+1}-\bm{w}^{k}\|^{2}-\frac{1 }{\rho}\|\bm{\lambda}^{k}-\bm{\lambda}^{k+1}\|^{2}.\] (20)

By Assumptions 1 and 2 we have that

\[\begin{split} L_{\rho}(\bm{z}^{k},\bm{w}^{k},\bm{\lambda}^{k})& =\Omega(\bm{z}^{k})+g(\bm{w}^{k})+(\bm{\lambda}^{k})^{\top}(\bm{z} ^{k}-D\bm{w}^{k})+\frac{\rho}{2}\|\bm{z}^{k}-D\bm{w}^{k}\|^{2}\\ &=\Omega(\bm{z}^{k})+g(\bm{w}^{k})+\frac{\rho}{2}\|\bm{z}^{k}-D \bm{w}^{k}+\frac{\bm{\lambda}^{k}}{\rho}\|^{2}-\frac{\|\bm{\lambda}^{k}\|^{2} }{2\rho}\\ &\geq-\frac{\|\bm{\lambda}^{k}\|^{2}}{2\rho}>-\infty.\end{split}\] (21)

So \(L_{\rho}(\bm{z}^{k},\bm{w}^{k},\bm{\lambda}^{k})\) is bounded below by some \(L^{*}\). Moreover, \(\sum_{k=1}^{K}\|\bm{\lambda}^{k+1}-\bm{\lambda}^{k}\|^{2}\leq\sum_{k=1}^{ \infty}\|\bm{\lambda}^{k+1}-\bm{\lambda}^{k}\|^{2}<\infty\) for \(\forall K\geq 1\).

Let \(\hat{L}:=L_{\rho}(\bm{z}^{1},\bm{w}^{1},\bm{\lambda}^{1})-L^{*}+\sum_{k=1}^{ \infty}\frac{2}{\rho}\|\bm{\lambda}^{k+1}-\bm{\lambda}^{k}\|^{2}<\infty\). Then telescoping (20) from \(k=1\) to \(K\), we obtain that

\[\begin{split}\hat{L}&\geq L_{\rho}(\bm{z}^{1},\bm{w} ^{1},\bm{\lambda}^{1})-L_{\rho}(\bm{z}^{K},\bm{w}^{K},\bm{\lambda}^{K})+\sum_{ k=1}^{K}\frac{2}{\rho}\|\bm{\lambda}^{k+1}-\bm{\lambda}^{k}\|^{2}\\ &\geq\sum_{k=1}^{K}\frac{2r-c}{2}\|\bm{w}^{k+1}-\bm{w}^{k}\|^{2}+ \sum_{k=1}^{K}\frac{1}{\rho}\|\bm{\lambda}^{k+1}-\bm{\lambda}^{k}\|^{2}.\end{split}\] (22)

This implies that

\[\min_{k\leq K}\frac{2r-c}{2}\|\bm{w}^{k+1}-\bm{w}^{k}\|^{2}+\frac{1}{\rho}\| \bm{\lambda}^{k+1}-\bm{\lambda}^{k}\|^{2}\leq\frac{\hat{L}}{K}.\]

Letting \(k=\arg\min_{i\leq K}\frac{2r-c}{2}\|\bm{w}^{i+1}-\bm{w}^{i}\|^{2}+\frac{1}{ \rho}\|\bm{\lambda}^{i+1}-\bm{\lambda}^{i}\|^{2}\), we have

\[\begin{split}\|\bm{w}^{k+1}-\bm{w}^{k}\|&\leq\sqrt{ \frac{2\hat{L}}{K(2r-c)}},\\ \|\bm{\lambda}^{k+1}-\bm{\lambda}^{k}\|&\leq\sqrt{ \frac{\rho\hat{L}}{K}}.\end{split}\]

Letting \(K=\frac{1}{c^{2}}\), by (15) and (17) we further have

\[\begin{split}\text{dist}\left(-\bm{\lambda}^{k+1},\partial\Omega \left(\bm{z}^{k+1}\right)\right)\leq\rho\|D\|\|\bm{w}^{k+1}-\bm{w}^{k}\|\leq \rho\|D\|\sqrt{\frac{2\hat{L}}{K(2r-c)}}=O(\epsilon),\\ \text{dist}\left(D^{T}\bm{\lambda}^{k+1},\partial g\left(\bm{w}^ {k+1}\right)\right)\leq r\|\bm{w}^{k+1}-\bm{w}^{k}\|\leq r\sqrt{\frac{2\hat{L} }{K(2r-c)}}=O(\epsilon),\\ \|\bm{z}^{k+1}-D\bm{w}^{k+1}\|=\frac{1}{\rho}\|\bm{\lambda}^{k+1} -\bm{\lambda}^{k}\|\leq\sqrt{\frac{\hat{L}}{\rho K}}=O(\epsilon).\end{split}\]

The proof of Theorem 1 is adapted from [33, Theorem 4.1].

### Proofs for smoothed ADMM in Section 4

#### a.3.1 Proof of Proposition 2

Proof.: By Assumption 3, similar to (15), we have

\[\mathbf{0} \in \partial\Omega(\bm{z}^{k+1})+\bm{\lambda}^{k}+\rho(\bm{z}^{k+1}-D \bm{w}^{k})\] \[= \partial\Omega(\bm{z}^{k+1})+\bm{\lambda}^{k}+\rho(\bm{z}^{k+1}-D \bm{w}^{k+1})+\rho D(\bm{w}^{k+1}-\bm{w}^{k})\] \[= \partial\Omega(\bm{z}^{k+1})+\bm{\lambda}^{k+1}+\rho D(\bm{w}^{k+ 1}-\bm{w}^{k}),\]

where the last equality follows from \(\bm{\lambda}^{k+1}=\bm{\lambda}^{k}+\rho(\bm{z}^{k+1}-D\bm{w}^{k+1})\).

By the first order condition of the \(\bm{w}\)-subproblem and Assumption 3, we have

\[\mathbf{0} =\nabla M_{g,\gamma}(\bm{w}^{k+1})-D^{\top}\bm{\lambda}^{k}-\rho D ^{\top}(\bm{z}^{k+1}-D\bm{w}^{k+1})+r(\bm{w}^{k+1}-\bm{w}^{k})\] (23) \[= \nabla M_{g,\gamma}(\bm{w}^{k+1})-D^{\top}\bm{\lambda}^{k+1}+r( \bm{w}^{k+1}-\bm{w}^{k}).\]

Note that \(\nabla M_{g,\gamma}(\bm{w}^{k+1})\in\partial g\left(\operatorname{prox}_{g, \gamma}\left(\bm{w}^{k+1}\right)\right)=\partial g(\tilde{\bm{w}}^{k+1})\). This completes the proof. 

#### a.3.2 Proof of Lemma 1

**Lemma 5**: _Under Assumption 4, if \(0<c\gamma\leq\frac{1}{2}\), then for \(\forall k=0,1,\dots\), we have_

\[\|\bm{\lambda}^{k+1}-\bm{\lambda}^{k}\|^{2}\leq\sigma^{-1}(\gamma^{-2}+r^{2}) \|\bm{w}^{k+1}-\bm{w}^{k}\|^{2}+\sigma^{-1}r^{2}\|\bm{w}^{k-1}-\bm{w}^{k}\|^{ 2},\]

_where \(\sigma\) is the smallest positive eigenvalue of \(DD^{\top}\)._

Proof.: By Assumption 4 we have \(\bm{\lambda}^{k+1}-\bm{\lambda}^{k}=\rho(\bm{z}^{k+1}-D\bm{w}^{k+1})\in Im(D)\). Then we obtain that

\[\|\bm{\lambda}^{k}-\bm{\lambda}^{k+1}\|^{2}\leq\sigma^{-1}\|D^{ \top}\left(\bm{\lambda}^{k}-\bm{\lambda}^{k+1}\right)\|^{2}\] \[\leq \sigma^{-1}\|\nabla M_{g,\gamma}(\bm{w}^{k+1})-\nabla M_{g,\gamma }(\bm{w}^{k})\|^{2}+\sigma^{-1}r^{2}\|\bm{w}^{k}-\bm{w}^{k+1}\|^{2}+\ \sigma^{-1}r^{2}\|\bm{w}^{k-1}-\bm{w}^{k}\|^{2}\] \[\leq \sigma^{-1}(\gamma^{-2}+r^{2})\|\bm{w}^{k+1}-\bm{w}^{k}\|^{2}+ \sigma^{-1}r^{2}\|\bm{w}^{k-1}-\bm{w}^{k}\|^{2},\]

where the second inequality follows from (23) and the last inequality follows from the fact that \(M_{g,\gamma}\) has \(\gamma^{-1}\) Lipschitz continuous gradient when \(0<c\gamma\leq\frac{1}{2}\)[7]. 

Proof of Lemma 1

Proof.: By Assumption 3 we have

\[L_{\rho}(\bm{z}^{k},\bm{w}^{k},\bm{\lambda}^{k})-L_{\rho}(\bm{z}^{k+1},\bm{w}^ {k},\bm{\lambda}^{k})\geq 0.\] (24)

Since \(0<c\gamma\leq\frac{1}{3}\), \(M_{g,\gamma}(\bm{w})\) is \(\gamma^{-1}\)-weakly convex by Lemma 2. By the optimality of \(\bm{w}^{k+1}\) and \((r-\gamma^{-1})\)-strong convexity of the \(\bm{w}\)-subproblem we have

\[L_{\rho}(\bm{z}^{k+1},\bm{w}^{k},\bm{\lambda}^{k})-L_{\rho}(\bm{z}^{k+1},\bm{w} ^{k+1},\bm{\lambda}^{k})\geq\frac{2r-\gamma^{-1}}{2}\|\bm{w}^{k+1}-\bm{w}^{k} \|^{2}.\] (25)

By the update of dual variable

\[L_{\rho}(\bm{z}^{k+1},\bm{w}^{k+1},\bm{\lambda}^{k})-L_{\rho}(\bm{z}^{k+1},\bm{ w}^{k+1},\bm{\lambda}^{k+1})=-\frac{1}{\rho}\|\bm{\lambda}^{k+1}-\bm{\lambda}^{k}\|^{2}.\] (26)

Summing (24), (25) and (26) we have

\[L_{\rho}(\bm{z}^{k},\bm{w}^{k},\bm{\lambda}^{k})-L_{\rho}(\bm{z}^{k+1},\bm{w}^{ k+1},\bm{\lambda}^{k+1})\geq\frac{2r-\gamma^{-1}}{2}\|\bm{w}^{k+1}-\bm{w}^{k}\|^{2}- \frac{1}{\rho}\|\bm{\lambda}^{\bm{k+1}}-\bm{\lambda}^{k}\|^{2}.\] (27)

Finally, we obtain that

\[\Phi^{k}-\Phi^{k+1}\] \[= L_{\rho}(\bm{z}^{k},\bm{w}^{k},\bm{\lambda}^{k})-L_{\rho}(\bm{z} ^{k+1},\bm{w}^{k+1},\bm{\lambda}^{k+1})+\frac{2r^{2}}{\rho\sigma}\|\bm{w}^{k-1 }-\bm{w}^{k}\|^{2}-\frac{2r^{2}}{\rho\sigma}\|\bm{w}^{k}-\bm{w}^{k+1}\|^{2}\] \[\geq (\frac{2r-\gamma^{-1}}{2}-\frac{2r^{2}}{\rho\sigma})\|\bm{w}^{k+1} -\bm{w}^{k}\|^{2}+\frac{2r^{2}}{\rho\sigma}\|\bm{w}^{k}-\bm{w}^{k-1}\|^{2}+(- \frac{2}{\rho}+\frac{1}{\rho})\|\bm{\lambda}^{k+1}-\bm{\lambda}^{k}\|^{2}\] \[\geq (\frac{2r-\gamma^{-1}}{2}-\frac{4r^{2}}{\sigma\rho}-\frac{2}{\sigma \rho\gamma^{2}})\|\bm{w}^{k+1}-\bm{w}^{k}\|^{2}+\frac

#### a.3.3 Proof of Theorem 2

_Proof:_ First note that \(0<c\gamma\leq\frac{1}{3}\), so Lemma 1 holds. Let \(\mathcal{E}_{0}:=\frac{1}{3c}\) and \(\mathcal{E}_{1}:=\frac{r-\gamma^{-1}}{2}-\frac{4r^{2}}{\sigma\rho}-\frac{2}{ \sigma\rho\gamma^{2}}\). Using the definitions of \(\gamma\), \(\rho\) and \(r\) we have

\[\mathcal{E}_{1} =\frac{2r-\gamma^{-1}}{2}-\frac{4r^{2}}{\sigma\rho}-\frac{2}{ \sigma\rho\gamma^{2}}\] (28) \[=\frac{1}{2\sigma\rho\gamma^{2}}\left(2\sigma\rho r\gamma^{2}- \sigma\rho\gamma-8r^{2}\gamma^{2}-4\right)\] \[=\frac{2\sigma C_{1}C_{2}-\sigma C_{1}-8C_{2}^{2}-4}{2\sigma C_{ 1}\epsilon}\] \[>\frac{\mathcal{E}_{0}}{2\sigma C_{1}\epsilon}>\frac{1}{2\sigma C _{1}}>0.\]

Since \(\{\bm{\lambda}^{k}\}\) is bounded, we obtain that \(L_{\rho}(\bm{z}^{k},\bm{w}^{k},\bm{\lambda}^{k})\) is bounded below by a similar manner of (21) and Assumption 1. Thus \(\Phi^{k}\) is lower bounded by some \(\Phi^{\star}\) as well, i.e., \(\Phi^{k}\geq\Phi^{\star}\), for \(\forall k\geq 1\). Telescoping (14) from \(k=1\) to \(K\) we have:

\[\Phi^{1}-\Phi^{\star}\geq\sum_{k=1}^{K}\mathcal{E}_{1}\|\bm{w}^{k+1}-\bm{w}^{ k}\|^{2}+\sum_{k=1}^{K}\frac{1}{\rho}\|\bm{\lambda}^{k+1}-\bm{\lambda}^{k}\|^{2}.\]

Thus we have:

\[\min_{k\leq K}\mathcal{E}_{1}\|\bm{w}^{k+1}-\bm{w}^{k}\|^{2}+\frac{1}{\rho}\| \bm{\lambda}^{k+1}-\bm{\lambda}^{k}\|^{2}\leq\frac{\Phi^{1}-\Phi^{\star}}{K}.\]

Let \(k=\arg\min_{i\leq K}\mathcal{E}_{1}\|\bm{w}^{i+1}-\bm{w}^{i}\|^{2}+\frac{1}{ \rho}\|\bm{\lambda}^{i+1}-\bm{\lambda}^{i}\|^{2}\), we have

\[\|\bm{w}^{k+1}-\bm{w}^{k}\|\leq\sqrt{\frac{\Phi^{1}-\Phi^{\star}}{K\mathcal{E }_{1}}},\]

\[\|\bm{\lambda}^{k+1}-\bm{\lambda}^{k}\|\leq\sqrt{\frac{\rho(\Phi^{1}-\Phi^{ \star})}{K}}.\]

Recall \(\tilde{\bm{w}}^{k}=\operatorname{prox}_{g,\gamma}(\bm{w}^{k})\). Note that by (28), \(\mathcal{E}_{1}^{-1}\) is upper bounded by the constant \(2\sigma C_{1}\). Letting \(K=\frac{1}{\epsilon^{4}}\), by Propositon 2, the definitions of \(r\) and \(\rho\) and the above two equations, we have

\[\text{dist}\left(-\bm{\lambda}^{k+1},\partial\Omega\left(\bm{z}^{k+1}\right) \right)\leq\rho\|D\|\|\bm{w}^{k+1}-\bm{w}^{k}\|=O(\epsilon),\]

\[\text{dist}\left(D^{T}\bm{\lambda}^{k+1},\partial g\left(\tilde{\bm{w}}^{k+1} \right)\right)\leq r\|\bm{w}^{k+1}-\bm{w}^{k}\|=O(\epsilon),\]

\[\|\bm{z}^{k+1}-D\tilde{\bm{w}}^{k+1}\|\leq\|\bm{z}^{k+1}-D\bm{w}^{k+1}\|+\|D( \tilde{\bm{w}}^{k+1}-\bm{w}^{k+1})\|\]

\[\leq\frac{1}{\rho}\|\bm{\lambda}^{k+1}-\bm{\lambda}^{k}\|+\gamma\|D\|M=O( \epsilon),\]

where the second inequality follows from (8) and Assumption 5. This completes the proof. 

Our proof of Theorem 2 draws inspiration from [33, Theorem 4.1] and [32]. In our method, we employ the Moreau envelope \(M_{g,\gamma}\) instead of \(g(w)\) to obtain a smoothed version of Problem (1). However, the solution obtained through Algorithm 1 may not satisfy the \(\epsilon\)-KKT conditions of the original problem. Nonetheless, our analysis demonstrates that by setting \(\tilde{\bm{w}}^{k}=\operatorname{prox}_{g,\gamma}(\bm{w}^{k})\), our algorithm guarantees an \(\epsilon\)-KKT point of the original problem in at most \(O(1/\epsilon^{4})\) iterations.

## Appendix B Additional Experimental Details

### Source Code

The source code is available in the https://github.com/RufengXiao/ADMM-for-rank-based-loss.

### Experimental Environment

All algorithms are implemented in Python 3.8 and all the experiments are conducted on a Linux server with 256GB RAM and 96-core AMD EPYC 7402 2.8GHz CPU.

### Details for the PAVA

**Proposition 3**: _Given two consecutive blocks \([m,n]\) and \([n+1,p]\), if they are out-of-order, then we have_

\[\frac{\sum_{i=m}^{n}\sigma_{i}}{n-m+1}<\frac{\sum_{i=n+1}^{p}\sigma_{i}}{p-n}.\]

_Proof:_ Suppose on the contrary that \(v_{[m,n]}>v_{[n+1,p]}\) but

\[\frac{\sum_{i=m}^{n}\sigma_{i}}{n-m+1}\geq\frac{\sum_{i=n+1}^{p}\sigma_{i}}{p-n}.\]

We use the conventions that \(h_{[a,b]}(z)=\sum_{i=a}^{b}\theta_{i}(z)\). For any \(g\in\partial l(v_{[m,n]})\), we must have \(g\geq 0\) because \(l\) is monotonically increasing (see the beginning of Section 3.1). Therefore we have

\[\frac{\sum_{i=m}^{n}\sigma_{i}}{n-m+1}g+\rho\left(v_{[m,n]}-\frac {\sum_{i=m}^{n}m_{i}}{n-m+1}\right)\] \[\geq \frac{\sum_{i=n+1}^{p}\sigma_{i}}{p-n}g+\rho\left(v_{[m,n]}-\frac {\sum_{i=m}^{n}m_{i}}{n-m+1}\right)\] \[\geq \frac{\sum_{i=n+1}^{p}\sigma_{i}}{p-n}g+\rho\left(v_{[m,n]}-\frac {\sum_{i=n+1}^{p}m_{i}}{p-n}\right),\]

where the first inequality is due to the non-negativity of \(g\), and the second inequality is due to the fact that \(m_{i}\leq m_{i+1}\) for \(i=m,m+1,\ldots,p\). Note also that

\[\frac{\sum_{i=m}^{n}\sigma_{i}}{n-m+1}g+\rho\left(v_{[m,n]}-\frac{\sum_{i=m}^{ n}m_{i}}{n-m+1}\right)\in\frac{1}{n-m+1}\partial h_{[m,n]}(v_{[m,n]})\]

and

\[\frac{\sum_{i=n+1}^{p}\sigma_{i}}{p-n}g+\rho\left(v_{[m,n]}-\frac{\sum_{i=n+1 }^{p}m_{i}}{p-n}\right)\in\frac{1}{p-n}\partial h_{[n+1,p]}(v_{[m,n]})\]

We also have \(0\in\partial h_{[m,n]}(v_{[m,n]})\) from the optimality condition. This implies that there exists some \(s\in\partial h_{[n+1,p]}(v_{[m,n]})\) such that \(s\leq 0\).

Now if there exists another \(s^{\prime}\in\partial h_{[n+1,p]}(v_{[m,n]})\) such that \(s^{\prime}>0\), then we have \(0\in\partial h_{[n+1,p]}(v_{[m,n]})\), which contradicts with the uniqueness of the optimal point \(v_{[n+1,p]}\) to \(h_{[n+1,p]}\) (due to its strongly convexity). So we must have \(s\leq 0\) for all \(s\in\partial h_{[n+1,p]}(v_{[m,n]})\). Then we must have \(v_{[m,n]}\leq v_{[n+1,p]}\) from the optimality of \(v_{[n+1,p]}\) to \(h_{[n+1,p]}\) and convexity of \(h_{[n+1,p]}\). However, this contradicts the fact that \([m,n]\) and \([n+1,p]\) are _out-of-order_.

Proposition 3 presents an additional opportunity to accelerate the PAVA, particularly for the top-\(k\) loss and AoRR framework. Consider the case of top-\(k\) loss, where \(\sigma_{i}=1\) if \(i=k\) and \(\sigma_{i}=0\) otherwise. In this scenario, the condition for merging blocks is satisfied only when \(i=k\). Therefore, we only need to examine the block containing \(k\), its preceding block, and its subsequent block. Consequently, the time complexity of searching for _out-of-order_ blocks in line 5 of Algorithm 2 is reduced to \(O(1)\).

By leveraging this insight, we enhance the efficiency of our algorithm, specifically for top-\(k\) loss. An analogous acceleration can also be applied to the AoRR loss. This optimization dramatically reduces computational complexity, thereby facilitating faster execution of the PAVA for both top-\(k\) loss and AoRR loss.

In our implementation of the PAVA, we use either the bisection method or Newton's method to find a minimizer of the convex function \(h_{[m,n]}\). Assuming the maximum number of iterations for these methods as \(T\), the computation of the minimizer \(v_{[m,n]}\) exhibits a time complexity of \(O(T)\). In the PAVA, as we merge _out-of-order_ blocks, the size of the index set \(J\) decreases by at least one.

Initially, \(J\) comprises \(n\) blocks. Hence, the minimizer needs to be computed no more than \(O(n)\) times throughout the algorithm. Furthermore, before each merge, we perform up to \(O(n)\) comparisons. However, this complexity is reduced to \(O(1)\) for top-\(k\) loss and AoRR loss due to the structures of these losses. Overall, the time complexity of our PAVA is \(O(n^{2}+nT)\). Notably, for top-\(k\) loss and AoRR loss, the time complexity is reduced to \(O(n+nT)\).

Moreover, in the empirical human risk minimization with CPT-weight in (4), \(\theta_{i}(z_{i})\) is nonconvex with regard to \(z_{i}\) because \(\sigma_{i}\) is dependent on the value of \(z_{i}\). Specifically, \(\theta_{i}(z_{i})\) takes the form of a two-piece function for \(z_{i}\in(-\infty,B]\) and \((B,\infty)\), where \(B\) represents a certain threshold. However, despite its nonconvexity, \(\theta_{i}(z_{i})\) remains convex within each piece. Exploiting this property, we can determine the minimizer of such a function by comparing the minimizers of the two separate pieces. Considering this observation, the overall time complexity of the PAVA for the empirical human risk minimization is still \(O(n^{2}+nT)\).

### Datasets Description

Datasets for our experiments are generated in two ways.

**Synthetic data.** We construct synthetic datasets where the data matrix \(X\) and label vector \(y\) are generated artificially. We utilize the datasets.make_classification() function from the Python package scikit-learn[38] to generate two-class classification problem datasets of various dimensions.

**Real data.** In the case of real data, the data matrix \(X\) and label vector \(y\) are derived from existing datasets. The 'SVMguide'[26] dataset, frequently used in support vector machines, is included in our experiments. We also employ 'AD'[29], which comprises potential advertisements for Internet pages, and 'Monks'[50], the dataset based on the MONK's problem that served as the first international comparison of learning algorithms. The 'Splice' dataset from the UCI[18] is used for the task of recognizing DNA sequences as exons or introns. We additionally include 'Australian', 'Phoneme', and 'Titanic' dataset from [17]. Lastly, the 'UTKFace' dataset [53] is used to predict gender based on facial images. Detailed statistics for each dataset are presented in Table 5.

### Details of Our Algorithm Setting

In the experiments, we set the maximum iteration limit in our algorithm to 300. We utilize FISTA to solve the \(w\)-subproblem in our algorithm and L-BFGS for the smoothed \(w\)-subproblem. For varying frameworks, we adopt different choices of \(\{\rho_{k}\}\), which varies when the iteration number \(k\) increase, in Algorithm 1. To enable the replication of our experiments, we provide a suggested selection for \(\{\rho_{k}\}\). The specifics regarding these choices for \(\{\rho_{k}\}\) are detailed in Table 6. We set the \(\gamma\) in Section 4 to \(\gamma^{k}=\text{max}\{10^{-5}\times 0.9^{k},10^{-9}\}\).

### Details of Experiments Setting

**Spectral Risk Measures.** Our objective is to demonstrate the versatility of our algorithm and its ability to converge to a globally optimal solution in the convex problem. Consequently, we utilize two real binary classification problem datasets and several synthetic datasets to highlight the advantages of our algorithm. We compare our method with the algorithms in [36]. We adapt their implementation

\begin{table}
\begin{tabular}{c c c c c} \hline \hline Datasets & \# Classes & \# Samples & \# Features & Class Ratio \\ \hline AD & 2 & 2,359 & 1,558 & 0.20 \\ SVMguide & 2 & 3,089 & 4 & 1.84 \\ Monks & 2 & 432 & 6 & 1.12 \\ Australian & 2 & 690 & 14 & 0.80 \\ Phoneme & 2 & 5,404 & 5 & 0.41 \\ Titanic & 2 & 2,201 & 3 & 0.48 \\ Splice & 2 & 3,190 & 60 & 0.93 \\ UTKFace & 2 & 9,778 & 136 & 1.24 \\ \hline \hline \end{tabular}
\end{table}
Table 5: Statistical details of eight real datasets.

by replacing the gradient of the \(\ell_{2}\) norm with the soft threshold operator to incorporate the \(\ell_{1}\) regularization. For simplicity, we set the regularization parameter \(\mu\) as 0.01 and \(q\) as 0.8. The datasets are divided into 60% for training and 40% for testing. Both SGD and LSVRG are run for 2000 epochs and the batch size of SGD is set to 64, and the epoch lengths are set to 100 as recommended in [36]. We give an example of how we choose the learning rate. For comparative purposes, we have chosen the learning rate that yields the lowest objective value in a single randomized experiment among five different learning rates from \(\{10^{-2},10^{-3},10^{-4},1/N_{\text{samples}},1/\left(N_{\text{samples}} \times N_{\text{features}}\right)\}\). We illustrate this approach using the AD dataset under the SRM superquantile framework as an example. The results are compiled in Table 7. The learning rate corresponding to the bold values, indicating the minimal objective value, is subsequently chosen.

**Average of Ranked Range Aggregate Loss.** We employ the same real datasets as those used in [27]. Consistent with their experimental setup, we randomly split each dataset into a 50% training set, a 25% validation set, and a 25% test set. As [27] only considered \(\ell_{2}\) regularization with \(\mu=10^{-4}\), our experiments in this section also utilize the AoRR aggregate loss with \(\ell_{2}\) regularization. The choice of hyper-parameters \(k\) and \(m\) and the selection of inner and outer epochs for each dataset follow [27].Table 8 presents the hyper-parameters for individual logistic loss, while Table 9 displays those for individual hinge loss.

**Empirical Human Risk Minimization.** We set \(\gamma=0.61\) and \(\delta=0.69\) in (5) based on the recommendations in [45]. We set \(B=\text{log}\left(1+\text{exp}\left(-5\right)\right)\) in (4). For simplicity, we only use \(\ell_{2}\) regularization. We employ the 'UTKFace' dataset [53], also used in [31], for gender prediction. The experiments are performed five times with different random seeds. In this experimental segment, we exclusively use the logistic loss as the individual loss since hinge loss has most of the zeros so that it is not easy to determine the corresponding \(B\) in (4) which means that its distribution is not suitable for this framework. The cumulative distribution function of loss \(F\) is derived from synthetic data, and \(F(B)\) is approximately equal to \(0.05\). The datasets are divided into 60% for training and 40% for testing. Other settings are similar to those in [31]. In accordance with [31], we divide the population into two groups based on race (white \(G_{1}\) and other race \(G_{2}\)). However, for simplicity, we only obtain the parameters \(w\) for gender prediction by minimizing the problem (1) without using a neural network. The parameter settings mirror those in Section 5.1. We use the same method to get the learning rate, and the learning rate for all three algorithms is set to \(1/\left(N_{\text{samples}}\times N_{\text{features}}\right)\)

\begin{table}
\begin{tabular}{l|l|l} \hline \hline Framework & \(\rho_{0}\) & \(\rho_{k}\) \\ \hline SRM & \(10^{-5}\) & \(1.2^{k}\rho_{0}\) \\ \hline AoRR & \(2\times 10^{-7}\) & \(5^{\left(\left(k-7\right)/3\right)}\rho_{0}\) \\ \hline EHRM & \(10^{-4}\) & 
\begin{tabular}{l} if \(\|\bm{z}_{k}-D_{k}\bm{w}_{k}\|_{2}>10^{-2}\) then \(\rho_{k}=1.02\rho_{k-1}\) \\ else \(\rho_{k}=1.07\rho_{k-1}\) \\ \end{tabular} \\ \hline \hline \end{tabular}
\end{table}
Table 6: The choices for \(\{\rho_{k}\}\)

\begin{table}
\begin{tabular}{r r r r|r r r} \hline \hline  & \multicolumn{4}{c}{_Logistic Loss_} & \multicolumn{4}{c}{_Hinge Loss_} \\ \hline Learning Rate & LSVRG(NU) & LSVRG(U) & SGD & LSVRG(NU) & LSVRG(U) & SGD \\ \hline \multicolumn{6}{c}{\(g(\bm{w})=\frac{\ell_{2}}{2}\|\bm{w}\|_{2}^{2}\)} \\ \hline
0.01 & 0.49612 & 0.19169 & **0.16200** & 0.18016 & 0.22529 & 0.11009 \\
0.001 & **0.15757** & **0.15753** & 0.16210 & **0.08600** & 0.09591 & **0.08702** \\
0.0001 & 0.17936 & 0.17930 & 0.27038 & 0.09270 & 0.09261 & 0.11568 \\
1/\(N_{\text{samples}}\) & 0.15761 & 0.15758 & 0.16755 & 0.08609 & **0.08940** & 0.08911 \\
1/\(N_{\text{samples}}\times N_{\text{features}}\) & 0.65849 & 0.65849 & 0.68518 & 0.85333 & 0.85333 & 0.96771 \\ \hline \multicolumn{6}{c}{\(g(\bm{w})=\frac{\mu}{2}\|\bm{w}\|_{1}\)} \\ \hline
0.01 & 0.34731 & 0.37191 & **0.27573** & 0.56240 & 0.45764 & 0.17956 \\
0.001 & **0.26991** & **0.26986** & 0.28041 & 0.16954 & 0.16959 & **0.15089** \\
0.0001 & 0.30385 & 0.30385 & 0.38138 & **0.15621** & **0.15471** & 0.18250 \\
1/\(N_{\text{samples}}\) & 0.27084 & 0.27078 & 0.28763 & 0.16805 & 0.15828 & 0.15198 \\
1/\(N_{\text{samples}}\times N_{\text{features}}\) & 0.66741 & 0.66743 & 0.68723 & 0.87358 & 0.87358 & 0.97219 \\ \hline \hline \end{tabular}
\end{table}
Table 7: Objective value in different learning rates for SGD and LSVRG.

Let TPR denote the true positive rate, FPR the false positive rate, and FNR the false negative rate. Additionally, let \(X\in\mathcal{X}\) represent the dataset and \(Y\in\{0,1\}\) the label. We utilize the same fairness metrics suggested by [5], as followed in [31]. Considering the privileged group \(G_{1}\subseteq X\) and the unprivileged group \(G_{2}\subseteq X\), the definitions of the following metrics are from [31]:

* Statistical Parity Difference (SPD): \(P\left(Y=1\mid X\in G_{2}\right)-P\left(Y=1\mid X\in G_{1}\right)\).
* Disparate Impact (DI): \(\frac{P\left(Y=1\mid X\in G_{2}\right)}{P\left(Y=1\mid X\in G_{1}\right)}\).
* Equal Opportunity Difference (EOD): \(\operatorname{TPR}\left(G_{2}\right)-\operatorname{TPR}\left(G_{1}\right)\).
* Average Odds Difference (AOD): \(\frac{1}{2}\left(\operatorname{FPR}\left(G_{2}\right)-\operatorname{FPR} \left(G_{1}\right)+\left(\operatorname{TPR}\left(G_{2}\right)-\operatorname{ TPR}\left(G_{1}\right)\right)\right)\).
* Theil Index (TI): \(\frac{1}{n}\sum_{i=1}^{n}\frac{b_{i}}{\mu}\ln\left(\frac{b_{i}}{\mu}\right)\) where \(b_{i}=\widehat{Y}_{i}-Y_{i}+1\) and \(\mu=\frac{1}{n}\sum_{i=1}^{n}b_{i}\). Here, \(\widehat{Y}_{i}\) is the prediction of \(X_{i}\) and \(n\) represents the number of samples.
* False Negative Rate Difference (FNRD): \(\operatorname{FNR}\left(G_{2}\right)-\operatorname{FNR}\left(G_{1}\right)\).

## Appendix C Additional Experimental Results

In this section, synthetic datasets labeled 1, 2, 3, and 4 are utilized. Detailed descriptions of datasets 1, 2, 3, and 4 can be found in Table 10.

### Experiments of Synthetic Datasets with ERM

The experimental settings implemented in this section are consistent with those discussed in Section 5.1. The datasets are replaced with the synthetic datasets. We use the same method to get the learning rate for other algorithms. Tables 11, 12, and 13 enumerate the mean and standard deviation of the results, primarily focusing on the objective value and test accuracy.'sADMM' stands for the ADMM applied to the smoothed problem. Tables 11, 12, and 13 show that under most scenarios in the ERM framework, our ADMM algorithm exhibits superior performance in terms of objective

\begin{table}
\begin{tabular}{l c c|l c c} \hline \hline Datasets & num\_sample & num\_feature & Datasets & num\_sample & num\_feature \\ \hline
1 & 1000 & 500 & 3 & 5000 & 1000 \\
2 & 2000 & 1000 & 4 & 10000 & 1000 \\ \hline \hline \end{tabular}
\end{table}
Table 10: Details of the synthetic datasets.

\begin{table}
\begin{tabular}{c|c c c c c} \hline \hline Datasets & \(k\) & \(m\) & \# Outer epochs & \# Inner epochs & Learning rate \\ \hline Monk & 70 & 20 & 5 & 2000 & 0.01 \\ Australian & 80 & 3 & 10 & 1000 & 0.01 \\ Phoneme & 1400 & 100 & 10 & 1000 & 0.01 \\ Titanic & 500 & 10 & 10 & 1000 & 0.01 \\ \hline \hline \end{tabular}
\end{table}
Table 8: AoRR hyper-parameters on real datasets for individual logistic loss.

\begin{table}
\begin{tabular}{c|c c c c c} \hline \hline Datasets & \(k\) & \(m\) & \# Outer epochs & \# Inner epochs & Learning rate \\ \hline Monk & 70 & 45 & 5 & 1000 & 0.01 \\ Australian & 80 & 3 & 5 & 1000 & 0.01 \\ Phoneme & 1400 & 410 & 10 & 500 & 0.01 \\ Titanic & 500 & 10 & 5 & 500 & 0.01 \\ Splice & 450 & 50 & 10 & 1000 & 0.01 \\ \hline \hline \end{tabular}
\end{table}
Table 9: AoRR hyper-parameters on real datasets for individual hinge loss.

[MISSING_PAGE_EMPTY:23]

enumerate the mean and standard deviation of results for the objective value, accuracy, and time. A careful examination of Tables 14 and 15 suggests that our algorithm, in most scenarios, achieves lower objective values and comparable accuracy in a shorter time span relative to existing methods.

### Experiments about Figure 1

We increased the sample size to further observe the performance of our algorithm and the experimental results are shown in Figure 3. It can be seen that both ADMM and sADMM exhibit relatively fast convergence compared to other algorithms. An interesting phenomenon is that in the case of a large amount of data, random algorithms are able to achieve decent results in the early stages of optimization. The underlying reason for this phenomenon may be that existing methods use mini-batch samples that are independent of the sample size to update model parameters, thereby reducing the computational cost per iteration. This allows existing methods to update parameters more frequently, leading to faster convergence in the early stages of optimization. In contrast, the proposed algorithm uses the entire batch of samples in each iteration, resulting in slower iteration speeds. This leads to suboptimal solutions in the early stages compared to existing methods. In Appendix B.3, we provide a detailed explanation of the time complexity of the PAVA, which is \(O(n+nT)\) for top-k loss and AoRR loss, where \(T\) represents the maximum number of iterations when solving each PAVA subproblem, and \(n\) represents the sample size. Therefore, with an increase in

\begin{table}
\begin{tabular}{c c c c c c c} \hline \hline Datasets & \multicolumn{2}{c}{ADMM} & DCA & LSVRG(NU) & LSVRG(U) & SGD \\ \hline \multirow{4}{*}{1} & \multirow{4}{*}{Accuracy} & object & 1.75\(\times 10^{-3}\) (\(\text{\text{\text{\text{\text{\text{\textbackslash{\text{\textbackslash{\textbackslash{ \textbackslash{\textbackslash{\textbackslash{\textbackslash{\textbackslash{ \textbackslash{\textbackslash{\textbackslash{ \textbackslash{  \textbackslash{   }}}}}}}}}}}}}}\)) & 1.12\(\times 10^{-3}\) (\(\text{\text{\text{\text{\textbackslash{\textbackslash{\textbackslash{\textbackslash{ \textbackslash{\textbackslash{\textbackslash{\textbackslash{\textbackslash{ \textbackslash{\textbackslash{\textbackslash{\textbackslash{ \textbackslash{\textbackslash{ \textbackslash{ \textbackslash{ \textbackslash{ \textbackslash{   \textbackslash{   \textbackslash{    \textbackslash{   \textbackslash{   \textbackslash{  \textbackslash{  \textbackslash{   \textbackslash{  \textbackslash{  \textbackslash{  \textbackslash{  \textbackslash{  \textbackslash{  \textbackslash{  \textbackslashbackslash{   \textbackslash{ \textbackslashbackslash{   \textbackslash{  \textbackslash{ \textbackslash{  \textbackslash{  \textbackslash{  \textbackslashbackslash{  \textbackslash{  \textbackslash{  \textbackslashbackslash{  \textbackslash{  \textbackslash{  \textbackslash{  \texttextbackslash{  \textbackslash{  \texttextbackslash{  \texttextbackslash{  \texttextbackslash{  \texttextbackslash{  \texttextbackslash{  \texttextbackslash{  \texttextbackslash{  \texttexttextbackslash{  \texttexttextbackslash{  \texttexttexttextbackslash{  \texttexttextbackslash{  \texttexttexttextbackslash{  \texttexttexttextbackslash{  \texttexttexttexttextbackslash{  \texttexttexttexttextbackslash{  \texttexttexttexttextbackslash{ \sample size, the time required for our proposed algorithm will also increase. Nevertheless, compared to existing algorithms, we are still able to achieve higher accuracy within a reasonable time frame.

\begin{table}
\begin{tabular}{c c c c c c c} \hline \hline Datasets & \multicolumn{2}{c}{ADMM} & DCA & LSVRG(NU) & LSVRG(U) & SGD \\ \hline \multirow{4}{*}{1} & objval & 2.97\(\times 10^{-5}\) (1.92\(\times 10^{-6}\)) & 9.99\(\times 10^{-1}\) (2.66\(\times 10^{-2}\)) & 1.71\(\times 10^{-3}\) (1.49\(\times 10^{-1}\)) & 1.72\(\times 10^{-3}\) (1.38\(\times 10^{-4}\)) & 3.68\(\times 10^{-5}\) (2.34\(\times 10^{-6}\)) \\  & \multirow{2}{*}{1} & Accuracy & 0.7700 (0.0371) & 0.7750 (0.0409) & 0.7600 (0.0427) & 0.7620 (0.0415) & 0.7680 (0.0315) \\  & & Time & 4.37 (0.66) & 137.22 (28.90) & 116.39 (3.64) & 114.37 (2.93) & 286.19 (1.35) \\  & & objval & 2.12\(\times 10^{-5}\) (6.51\(\times 10^{-7}\)) & 1.00\(\times 10^{-2}\) (2.66\(\times 10^{-2}\)) & 7.05\(\times 10^{-5}\) (5.90\(\times 10^{-5}\)) & 1.21\(\times 10^{-3}\) (3.85\(\times 10^{-5}\)) & 2.42\(\times 10^{-5}\) (5.20\(\times 10^{-7}\)) \\
2 & Accuracy & 0.8320 (0.0093) & 0.8270 (0.0099) & 0.8420 (0.0113) & 0.6940 (0.0277) & 0.8380 (0.0093) \\  & & Time & 5.54 (0.64) & 172.5 (24.82) & 104.79 (2.87) & 93.35 (3.00) & 352.67 (4.98) \\  & & object & 4.82\(\times 10^{-5}\) (1.49\(\times 10^{-6}\)) & 9.89\(\times 10^{-1}\) (1.90\(\times 10^{-2}\)) & 2.94\(\times 10^{-4}\) (9.49\(\times 10^{-6}\)) & 2.78\(\times 10^{-4}\) (4.43\(\times 10^{-5}\)) & 6.30\(\times 10^{-5}\) (2.01\(\times 10^{-6}\)) \\
3 & Accuracy & 0.8130 (0.0113) & 0.8060 (0.0084) & 0.8100 (0.0101) & 0.8070 (0.0135) & 0.8180 (0.0066) \\  & & Time & 15.36 (0.70) & 290.7 (26.15) & 112.68 (8.08) & 99.52 (4.88) & 540.62 (66.63) \\  & & objval & 8.53\(\times 10^{-4}\) (1.95\(\times 10^{-4}\)) & 9.82\(\times 10^{-2}\) (2.51\(\times 10^{-2}\)) & 1.22\(\times 10^{-3}\) (3.17\(\times 10^{-5}\)) & 1.08\(\times 10^{-4}\) (3.85\(\times 10^{-5}\)) & 8.16\(\times 10^{-5}\) (1.00\(\times 10^{-6}\)) \\
4 & Accuracy & 0.9430 (0.0053) & 0.9360 (0.0046) & 0.9310 (0.0049) & 0.9240 (0.0028) & 0.9350 (0.0048) \\  & & Time & 31.42 (3.34) & 396.03 (31.66) & 129.22 (24.09) & 115.06 (3.46) & 633.69 (82.42) \\ \hline \hline \end{tabular}
\end{table}
Table 15: Comparison with AoRR framework, \(k=\lfloor 0.8\times N_{\text{train}}\rfloor\), \(m=\lceil 0.2\times N_{\text{train}}\rceil\) and hinge loss. ‘objval’ denotes the objective value of problem (1).

Figure 3: Time vs. Sub-optimality gap in synthetic dataset with ERM framework and \(\ell_{1}\) regularization. The datasets with the same number of samples are generated by different random number seeds. Sub-optimality is defined as \(F^{k}-F^{*}\), where \(F^{k}\) represents the objective function value at the \(k\)-th iteration or epoch and \(F^{*}\) denotes the minimum value obtained by all algorithms. Plots are truncated when \(F^{k}-F^{*}<10^{-8}\).