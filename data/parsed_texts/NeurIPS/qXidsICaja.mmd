# Expert-level protocol translation for self-driving labs

 Yu-Zhe Shi\({}^{\star}\)

Fanxu Meng\({}^{\star}\)

Haofei Hou\({}^{\star}\)

Zhangqian Bi

Qiao Xu

Lecheng Ruan\({}^{\boxplus}\)

Qining Wang\({}^{\boxplus}\)

Department of Advanced Manufacturing and Robotics,

College of Engineering, Peking University

\({}^{\star}\)Equal contribution \({}^{\boxplus}\)ruanlecheng@ucla.edu, qiningwang@pku.edu.cn

###### Abstract

Recent development in Artificial Intelligence (AI) models has propelled their application in scientific discovery, but the validation and exploration of these discoveries require subsequent empirical experimentation. The concept of self-driving laboratories promises to automate and thus boost the experimental process following AI-driven discoveries. However, the transition of experimental protocols, originally crafted for human comprehension, into formats interpretable by machines presents significant challenges, which, within the context of specific expert domain, encompass the necessity for structured as opposed to natural language, the imperative for explicit rather than tacit knowledge, and the preservation of causality and consistency throughout protocol steps. Presently, the task of protocol translation predominantly requires the manual and labor-intensive involvement of domain experts and information technology specialists, rendering the process time-intensive. To address these issues, we propose a framework that automates the protocol translation process through a three-stage workflow, which incrementally constructs Protocol Dependence Graphs (PDGs) that approach structured on the syntax level, completed on the semantics level, and linked on the execution level. Quantitative and qualitative evaluations have demonstrated its performance at par with that of human experts, underscoring its potential to significantly expedite and democratize the process of scientific discovery by elevating the automation capabilities within self-driving laboratories.

## 1 Introduction

The evolution of AI techniques has significantly accelerated the processes inherent to scientific discovery, with a notable impact observed within the domain of experimental sciences (Wang et al., 2023b). This influence is manifested through a variety of avenues: the generation of hypothesis spaces informed by extensive literature analysis (Jablonka et al., 2022; Kim et al., 2024), the interpretation of observational data via the identification of high-dimensional correlations (Jumper et al., 2021; Abramson et al., 2024), the engineering of novel structures that meet predefined specifications (Grisoni et al., 2021; Park et al., 2023), and the implementation of comprehensive simulations to ascertain the characteristics of potential products (Hie et al., 2021; Singh et al., 2023).

However, the findings facilitated by AI-driven research require further validation and exploration via empirical experiments, and may even entail a cyclical process where AI-generated hypotheses are refined based on the outcomes of real-world experiments, which demands the assembly of a sizable cohort of experienced experimenters to carry out these investigations in accordance with established _protocols_(McNutt, 2014). Unfortunately, the formation and sustenance of such a dedicated experimental cadre are fraught with considerable financial demands, and the collaborative engagement between people oriented towards AI methodologies and those grounded in experimental sciences is frequently encumbered by the communication gaps between distinct intellectual paradigms (Baker, 2016; Freedman et al., 2015; Munafo et al., 2017; Baker, 2021; Shi et al., 2023a).

To bridge the aforementioned gap, the paradigm of self-driving laboratories has garnered attention, which automates experimental protocols via robotic systems, potentially revolutionizing the way experiments are conducted (Bedard et al., 2018; Steiner et al., 2019; Mehr et al., 2020; Rohrbach et al., 2022; Burger et al., 2020; Szymanski et al., 2023). Despite the promising outlook, designing such labs relies largely on the translation of protocols, primarily designed for human experimenters, into machine-readable instructions. This translation process necessitates extensive collaboration between domain experts, who possess the requisite scientific knowledge; and information technology specialists, who encode this knowledge into software and hardware systems. The inherently labor-intensive nature of such translation significantly prolongs the development of self-driving laboratories. The primary challenges are rooted in the discrepancies across three critical aspects (see Fig. 1):

SyntaxHuman experimenters can effortlessly **comprehend** protocols articulated in Natural Language (NL), whereas automated systems frequently necessitate dedicated syntax parsers to convert these protocols into a sequence of actionable steps. Consider the protocol: _"Split the mixture equally into 2 separate 50 mL round-bottom flasks for the next steps."_ This example highlights the meticulous control over experimental procedures, explicitly directing the _"split"_ of the mixture into precisely measured volumes -- a crucial factor for achieving uniform outcomes in subsequent reactions. It is imperative at this level to uphold a **structured** representation of the mapping of operation conditions and the control flows of operations.

SemanticsHuman experimenters can **infer** implicit knowledge and context relying on the flexibility and adaptability of human understanding. In contrast, machine instructions necessitate a level of precision and rigidity that human communication does not inherently require. For instance, consider the protocol: _"Stir the mixture at room temperature for 5 minutes."_ While a human expert might inherently understand that _"room temperature"_ denotes a temperature range of 20-25 \({}^{\circ}C\) drawing on their prior knowledge, an automation system necessitates explicit information regarding such implicit details, which therefore need to be **completed** before execution.

ExecutionHuman experimenters can **simulate** possible intermediate states and outcomes by considering the cumulative effects of a sequence of actions. For instance, given the two instructions adjacently: _"Add 35 mL water to the flask"_ and _"Add 25 mL water to the flask"_, an experimenter can deduce that the flask's minimal capacity comes over 60 mL to prevent errors. For an automated system to perform a similar function, the actions need to be **linked** along their execution order.

Great efforts have been made on such translation tasks, among which Chemputer is representative (Mehr et al., 2020). This algorithm parses the NL-based protocol into XDL, a Domain-Specific Language (DSL) specially designed to describe chemical synthesis reactions. The completeness and

Figure 1: **Illustration of the protocol translation problem.** An NL-based protocol is translated to a structured protocol, then to a completed protocol, and finally to a linked protocol that is ready for self-driving laboratories along with a corresponding PDG, after being processed through the syntax, semantics, and execution levels. The three colors of arrows and text/ code highlights indicate the three translation steps respectively.

linkages are constructed with a set of manually-written constraints, with which the correctness of protocols can be further checked. This methodology has gained widespread acceptance in automated chemical synthesis, as a testament to the intensive efforts by domain and IT experts in developing XDL and the corresponding constraints. However, the application of a similar framework in other domains of experimental sciences, such as _Genetics_, _Medicine_, _Ecology_, and _Bioengineering_, would necessitate repeating these labor-intensive tasks on a case-by-case basis, thus underscoring the critical need for a more generally applicable, human-free protocol translator.

In this work, we propose a novel framework of human-free translator, designed to potentially facilitate applications across diverse experimental science domains without requiring extensive manual intervention. This framework decomposes the translation challenge into three hierarchical stages: structured on the syntax level, completed on the semantics level, and linked on the execution level, mirroring the cognitive steps undertaken by human experts in similar translation tasks. In the proposed work, the DSL, its constraints, and linkages are generated automatically, based on protocols tailored for human experimenters, thereby eliminating the need for labor-intensive manual processes.

Our contributions are threefold: (i) We conduct a systematic analysis of the existing discrepancies in protocol translation between human experimenters and automated systems in self-driving laboratories. From this analysis, we derive design principles that emulate human cognitive processes involved in protocol translation (Sec. 2). (ii) We devise an autonomous protocol translator through a tripartite framework that incrementally constructs PDGs, encapsulating the spatial-temporal dynamics of protocol execution across syntax, semantics, and execution levels (Sec. 3). (iii) Through both quantitative and qualitative evaluations in various experimental science domains, we demonstrate that our translator, when integrated as an auxiliary module for Large Language Models (LLMs), approaches the efficacy of skilled human experimenters and substantially surpasses the performance of purely LLMs-based alternatives in protocol translation tasks (Sec. 4).

## 2 Protocol translation for self-driving laboratories

In this section, we explore the translation of protocols for human experimenters to those suitable for self-driving laboratories. We analyze the task requirements across syntax (Sec. 2.1), semantics (Sec. 2.2), and execution (Sec. 2.3) levels. We pinpoint challenges at each level for both humans and machines, delving into systematic methods for addressing these issues. Leveraging expert insights, we delineate fundamental design principles for achieving effective protocol translation (Sec. 2.4).

### Syntax level

Operation-condition mappingIn NL-based protocols, operations and their corresponding parameters such as input reagents and conditions, are entangled with each other. For example, _"Dissolve 10 g of sodium chloride in 100 mL of distilled water at 80\({}^{\circ}C\)"_, the entanglements of actions and conditions highlight the complexity machines face in parsing such protocols. Human experimenters can _recognize_ them without information loss thanks to the _internalized language_ for parsing NL (Chomsky, 1956, 2007). In contrast, protocols for machines must be represented precisely, with proper extraction of keys and values, and matching between them with appropriate data structures.

Operation control flowsIn NL-based protocols, both linear and non-linear control flows are implicitly embedded in the text. While linear control flows, _i.e._, workflows in sequential execution order, can be straightforward, non-linear control flows such as iterative loops and parallel operations can be hard to detect because the signal and the operational domain can be separated. Consider the protocol: _"Repeat the titration until the endpoint is reached, then record the volume of titrant used"_. These steps embody a non-linear control flow, challenging machines to correctly interpret the iterative process involved. Even human experts have to read the protocols carefully to understand the local and global structures to match the signals with operational domains, let alone machines.

### Semantics level

Latent semantics of known unknownsSome assigned values of parameters are regarded as common sense knowledge of domain experts by default, thus the values are omitted for simplicity or referred to via a _proxy name_ following the domains' conventions. For example, the protocol instruction _"Dry the purified product at room temperature"_ relies on the experimenter's understanding of what constitutes _"room temperature"_. However, machines substantially suffer from such latent semantics, implying that every value of parameters should be made explicit.

Latent semantics of unknown unknownsSometimes, even required parameters for a specific operation are omitted from the protocols either or not intentionally, causing _unknown unknowns_ that one may even be not aware of the absence of such information. For instance, the protocol instruction _"Centrifuge the sample after adding the enzyme"_ does not specify the key controlling parameter, speed or duration, for the _"centrifuge"_ operation, before describing its specific value. Both human and machines require every parameter of operations to be grounded.

### Execution level

Capacity of resourcesProtocols often omit explicit specifications of resource capacities, leading to potential execution errors like exceeding a device's maximum capacity. This issue, inherent in the execution sequence, is undetectable by analyzing single operations alone. For example, the instruction _"Transfer the mixture to a beaker"_ requires choosing a beaker with adequate capacity, a decision based on the cumulative volume from previous steps. Humans intuitively manage this through a mental simulation of the experimental process (Gallese and Goldman, 1998). Machines, therefore, need a pre-execution verification mechanism to ensure resource capacities are not exceeded, highlighting the need for an integrated understanding of the experimental sequence.

Safety of operationsIn addition to managing resource capacities, another source of runtime errors stems from operations that, while semantically valid, may lead to adverse or dangerous outcomes in certain execution contexts. Such scenarios necessitate a _dual-constraint_ approach, where experiments are mindful not only of the actions required _what I should do_ but also of potential missteps to avoid _what I must not do_. For instance, the instruction _"Heat the reaction mixture to 70\({}^{\circ}C\)"_ can be appropriate or hazardous, depending on the mixture's composition -- safe with a heat-stable catalyst, but risky with a heat-sensitive component due to potential decomposition. To navigate these complexities, human experts effectively run mental simulations, conducting _"What if?"_ queries and counterfactual reasoning (Hoch, 1985) to anticipate the consequences of their actions. Similarly, machines need a system to draw upon domain-specific knowledge and historical context to assess the safety of each operation, ensuring that all actions are contextually appropriate and safe.

Figure 2: **The design principles and the resulting pipeline of our translator. (Syntax level) Operation dependence synthesis on the syntax level, through the joint optimization of DSL program syntax space and the parsing tree of the NL-based protocols. This process is static and context-free. (Semanties level) Reagent flow analysis on the semantics level, through an automaton scheme maintaining the lifecycles of reagents and intermediate products. This process is static and context-free. (Execution level) Spatial-temporal dynamics analysis on the execution level, through the partial execution trace model based on the spatial-temporal dual constraint representation. This process is dynamic and context-aware.**

### Design principles inspired by human experimenters

Human experts' cognitive capabilities on the translation of protocols serve two key roles: understanding protocols for in-hand experiments and manually developing translators for self-driving laboratories. Inspired by these practices, we outlined design principles for our translator and assessed the strengths and weaknesses of current DSLs for NL-based protocols, such as XDL (Steiner et al., 2019), ULSA (Wang et al., 2022), ORD (Kearnes et al., 2021), Biocoder (Ananthanarayanan and Thies, 2010), Autoprotocol (Strateos, 2023), and the family of DSLs (hereinafter called ADSL) which are automatically designed by the AutoDSL tool driven by domain corpora (Shi et al., 2024).

Operation dependence synthesis for the syntax levelTo precisely comprehend the complicated operation-condition mappings and non-linear control flows, machines should equip with an _externalized language_ in parallel with humans' _internalized language_(Chomsky, 2007). A machine-recognizable language commonly possesses a Context-Free Grammar (CFG) which externally defines the key-value structures on different hierarchies: (i) operation as key, reagents and conditions as values; (ii) condition as key, the corresponding parameters as values; and (iii) signal of control flow as key, the corresponding operational domains as values. If a protocol can be parsed into an Abstract Syntax Tree (AST) with the CFG, it is verified on the syntax level (Hopcroft et al., 1996), resulting in the dependency structures of the operation flow (see Fig. 2 Top). All DSLs mentioned before are context-free languages with CFGs (Fowler, 2010), echoing this design principle.

Reagent flow analysis for the semantics levelDespite the merits of DSLs based on CFGs, the context-free nature hinders verification on the semantics level, which is pivotal in protocols essentially describing procedures, where the preconditions and postconditions between temporally adjacent operations can be end-to-end connected. To be specific, although a CFG defines a structural space with hierarchies of operations, conditions, parameters, and control flows, _i.e._, _"There must be several parameters corresponding to a condition"_, it does not constrain the mappings under the context of domain-specific knowledge, _i.e._, _"There are parameters controlling the Temperature, Duration, and Acidity of the condition"_. If the exact mapping between keys and values cannot be specified, the self-driving laboratories can hardly be aware of the loss of completeness, _i.e._, being aware of the omitted conditions given an operation or the missing value given a parameter, due to the extremely large search space over all symbols given by the corresponding DSLs (Gulwani et al., 2017). The design choices of DSLs diverge on this level, where Autoprotocol only supports verification on the syntax level and does not possess any domain knowledge, ORD and ULSA offer the relations between operations and conditions without more fine-grained parameters, while XDL, Biocoder, and ADSL offer the find-grained key-value relation below the hierarchy of operations without more constraints about the values, _e.g._, suggested values of specific parameters. Hence, we require a mechanism for completing the structures of reagent flow (see Fig. 2 Middle), while the completeness of the fine-grained parameters is guaranteed by the DSLs.

Spatial-temporal dynamics analysis for the execution levelCompletion on the semantics level is conducted statically because the semantics of operations are viewed individually rather than contextualized in the execution sequence. Regrettably, such effort cannot guarantee that the protocols can be executed successfully without any errors in the run time, which is unacceptable by self-driving laboratories (Christensen et al., 2021; Seifrid et al., 2022). One way is to have domain experts write down all of the potential bad cases as constraints and use them for verification. However, run-time errors raised in the dynamic context of operations are heavily long-tail distributed. This makes it extremely hard to predict such errors from statistical _hindsight_(Pearl, 2019), _i.e._, the set of collected post-hoc bad cases. Thus, we leverage the powerful _foresight_ based on simulation, which spans the full probabilistic worlds of each operation by its semantic constraints, both on the _spatial_ dimension, _e.g._, capacity of resources captured by the reagent dependency, and the _temporal_ dimension, _e.g._, safety of operations captured by the operation dependency. The simulation is conducted along the topological order of the corresponding execution flow graph. At each operation unit, both historical operations in the same protocols and similar operations in other protocols are recalled dynamically, checking and refining the dual-constraint spaces accordingly (see Fig. 2 Bottom). Interestingly, none of the DSLs in our discussion take this feature as part of language design and only XDL employs an external compiler with hand-crafted rules for error detection. Such consideration is reasonable because in mainstream DSL design, verification on the execution level is not guaranteed by the DSLs themselves for design simplicity and user convenience (Mernik et al., 2005). Consequently, we require an environment to dynamically check the correctness of execution both spatially and temporally, through synthesizing operation and reagent dependencies.

The framework of protocol translation

In this section, we introduce the three-stage framework for human-free protocol translation, which gradually constructs a structural representation of protocols, called the _Protocol Dependence Graph_ (PDG). The PDG makes explicit both the operation and reagent dependencies for a protocol. Operation dependence echoes the concept of program control flow, which derives the condition of sequential, branch, or loop execution of protocol operations (Sec. 3.1). Reagent flow provides an explicit representation of the reagent instantiate-exploit relationships implicitly in the protocol (Sec. 3.2). Additionally, we simulate the protocol execution process using the PDG, checking and refining operation sequences under the spatial and temporal dynamics of execution (Sec. 3.3).

### Operation dependence synthesis for the syntax level

The operation dependence models the topological order for executing operations in a protocol. The procedure is executed sequentially from the first operation in the protocol to the last, unless the experimenter encounters structures that change the execution flow, such as branches and loops. In practice, we extract the operation dependence by compiling the protocol to DSL programs.

InputThe compilation process is conducted based on the corresponding DSL \(\mathcal{L}=\{\mathcal{S},\Lambda\}\). The CFG-based syntax \(\mathcal{S}=(S,V,\Sigma,R)\) includes (i) the start symbol \(S\); (ii) the variable set \(V=\{V_{\texttt{ctrl}},V_{\texttt{op}},V_{\texttt{cond}},V_{\texttt{par}}\}\) with placeholders for control flow signals \(V_{\texttt{ctrl}}\), operations \(V_{\texttt{op}}\), conditions \(V_{\texttt{cond}}\), and parameters \(V_{\texttt{par}}\); (iii) the set of terminals \(\Sigma\), which are the grounded values of parameters; (iv) the set of production rules \(R\) defining the structural space between the four variable sets. The semantics \(\Lambda=(T_{\texttt{ctrl}},T_{\texttt{op}},T_{\texttt{cond}},T_{\texttt{par}}, T_{R})\) constrains the variables and production rules, assigning the placeholders with substantial meanings. To note, according to the design choice discussed in Sec. 2.4, the DSL used here should be one of XDL, Biocoder, and ADSL, _i.e._ the DSLs with the most fine-grained structural representation compared with their counterparts.

Pre-processingGiven an input protocol \(\mathbf{c}\) for translation, we first parse the NL sentences by an off-the-shelf tool and extract the actions accordingly. Then, the extracted actions are matched with the operations \(o\in T_{\texttt{op}}\) of the DSL, according to both exact match score and semantic similarity. Afterwards, we extract the arrays of entities related to the extracted action \(\mathbf{e}_{t}\in\mathcal{E}\) by an off-the-shelf tool, where we regard the output labels to the entities and relations as _pseudo-labels_ because they can possibly be noisy. Please refer to Appx. C.1 for implementation details.

DSL program synthesisSynthesizing structural representation given unstructured signal is challenging (Billard, 2000, 2006). Specifically, the one-to-many mappings of many DSL operations bring uncertainty into the matching. For example, the operation add possesses distinct patterns: two or three input slots. This further distorts the matching of reagents, conditions, and parameters because off-the-shelf tools can hardly detect the exact categories of these entities deeply rooted in domain-specific knowledge. Since the observation and hypothesis spaces are both noisy, we propose to jointly optimize the patterns of operations and the pseudo-labels. We denote the set of all possible program patterns generated by operation \(o\) as \(o^{\ast}=\{\texttt{p}|o\Rightarrow^{\ast}\ \texttt{p},T_{R}\Rightarrow^{\ast} \texttt{p},\texttt{p}\in T_{\texttt{ctrl}}\cup T_{\texttt{op}}^{\ast}\cup T_{ \texttt{cond}}^{\ast}\cup T_{\texttt{par}}^{\ast}\}\). A synthesized DSL program is defined as \(\texttt{p}(\mathbf{c})=\langle\texttt{p}(o_{1}),\texttt{p}(o_{2}),\ldots, \texttt{p}(o_{\texttt{p}(\mathbf{c})}|)\rangle\), where \(\texttt{p}(o_{t})\) is the program of an operation assembled with its corresponding conditions and parameters under the selected pattern in \(o^{\ast}\). Let \(s(\mathbf{c})=\langle\mathbf{e}_{1},\mathbf{e}_{2},\ldots,\mathbf{e}_{|s( \mathbf{c})|}\rangle\) represent the sequence of operation-related entities, the objective of optimization can be

\[\arg\min_{\texttt{p}(o_{t}),\mathbf{e}_{t}}\sum_{t}\sum_{\begin{subarray}{c}o _{t}^{\ast}\end{subarray}}D\big{(}\texttt{p}(\mathbf{c})\big{\|}s(\mathbf{c} )\big{)},\] (1)

where \(D(\cdot\|\cdot)\) is a divergence function with three indicators: (i) the selected pattern examples should be as close as possible to the text span; (ii) the selected pattern should be as similar as possible with the extracted subject-verb-object structure; and (iii) as many labeled entities as possible should be mapped to the parameter space (see Fig. 3B). Though \(|o^{\ast}|\) is not a large value, the whole sequence of operations can yield an exponential complexity. Hence, to make the joint optimization tractable, we separate the search of solution into two steps in the spirit of Expectation Maximization (EM): (i) Expectation: sampling programs from the legal space defined by the corresponding DSL, with a program-size-sensitive prior \(|\texttt{p}(o_{t})|^{-1}\); (ii) Maximization: randomly alternating symbols in \(s(\mathbf{c})\) by matching them with those in \(\texttt{p}(\mathbf{c})\) and greedily select the edits that decrease the objective function.

### Reagent flow analysis for the semantic level

The DSL programs are further contextualized by associating operations with reagent flow. Reagent flow indicates the transfer of reagents among operations, reflecting how one operation impacts the subsequent ones. We define the reagent flow following the _reaching definitions_ schema (Alfred et al., 2007), which is commonly used to capture the life cycle of a variable in compiler design. This schema determines a set of reagents reachable at each point in a protocol, and subsequently tracks the _kills_ and _defines_ of an operation, _i.e._, whether a reachable reagent is consumed, or a new reagent is yielded, in an operation.

InputWe denote the reagents consumed and the intermediate products yielded by each operation \(o\) as \(\textsc{In}(o)\) and \(\textsc{Out}(o)\) respectively. The objective is to find a set of operation pairs \(\{\langle o_{i},o_{j}\rangle\,|\,\textsc{Out}(o_{i})\cap\textsc{In}(o_{j})\neq\phi\}\) such that \(\textsc{Out}(o_{i})\) is required as input by \(\textsc{In}(o_{i})\).

The reaching definitions schemaWe determine the availability of a reagent at each step by locating where it is defined in a protocol when execution reaches each operation. A reagent \(r\) reaches an operation \(o\), if there is a path from the point following \(r\) to \(o\), such that \(r\) is not _killed_, _i.e._, consumed, along that path. Any reagent \(r\) that reaches an operation \(o\) might be killed at that point, and \(o\) may yield new intermediate products \(r^{\prime}\) that reach future operations. Notably, according to statistics on corpora of protocols (Vaucher et al., 2020), for about 90% operations of a target DSL, if \(o_{i}<o_{j}\) are two adjacent operations, \(\textsc{Out}(o_{i})\cap\textsc{In}(o_{j})\neq\phi\) holds. This implies that the reagent generated by preceding operation is likely to be used and then be killed instantly by the following operation.

Reagent flow analysis via operation flow traversalWe traverse the DSL program in execution order to leverage the reagent locality revealed from statistical results, determining the reachability and life cycle of reagents. A Pushdown Automaton (PDA) with a random access memory is adopted to record reachable reagents as operation context, defining and killing reagents at each operation point along the computation1. A PDA is formally defined as a 7-tuple \(M=(Q,\Sigma,\Gamma,\delta,q_{0},Z,F)\), where \(Q\subseteq T_{\textsc{op}}\) indicates the set of states, \(\Sigma=T_{\textsc{op}}\) represents the domain of inputs, \(\Gamma\subseteq T_{\textsc{par}}\) denotes possible memory elements, \(\delta\subseteq Q\times\Sigma\times\Gamma\to Q\times\Gamma^{*}\) is the transition procedure (Transition in Alg. 1), \(q_{0}=o_{1}\) defines the initial state, \(Z=\epsilon\) is the initial memory element, and \(F\) denotes the set of accepting states. The reagent dependence construction process (Flow in Alg. 1) traverses the DSL program in execution order by leveraging the NextOps utility, which evaluates to subsequent operations. In every transition step with input, the killed reagents are removed from the memory, and the defined reagents are added to the memory. After a reagent is killed, the pair of the operations that defined it and killed it will be added to the set of reagent flow constraints. The accepting state is reached if the memory is empty at the end of execution, _i.e._, all reagents defined in operations are killed by other operations. We employ state-of-the-art LLMs to extract reagent entities from NL-based protocol descriptions for the two utilities Kills and Defines through instruction-following in-context learning (Wei et al., 2021; Brown et al., 2020) (refer to Appx. C.2 for details).

Footnote 1: It is worth noting that this extended PDA with random access can be shown to be in the same computation class as Turing machines (Aho and Ullman, 1972), and we employ this extended PDA due to its simplicity.

``` procedureTransition(\(M\), \(o\)) \(\vartriangle\)Context Transition \(\textsc{Erase}(M(\Gamma),\textsc{Kills}(M(\Gamma),o))\) \(\textsc{Appx}(M(\Gamma),\textsc{Defines}(o))\) \(\vartriangle\)State Transition \(M(q)\leftarrow(M(q)\setminus o)\cup\textsc{NextOps}(o)\) procedureFlow(\(p(\mathbf{c})\), \(M\)) \(R=\{\ \}\)\(\triangleright\)Set of reagent dependence \(M(q)\leftarrow\{o_{1}\}\)\(\triangleright\)Initial State \(M(\Gamma)\leftarrow\big{\langle}\big{\rangle}\)\(\triangleright\)Initial Memory while\(M(q)\neq\phi\)do  Transition(\(M\), \(M(q)\)) ```

**Algorithm 1** Reagent flow analysis

### Spatial-temporal dynamics for the execution level

While the pre-specified PDG analysis indicates the things _should_ be done to follow operation and reagent flow, we still need to care about the things _must not_ be done by describing the activities that may be performed and the constraints prohibiting undesired execution behavior. Therefore, we introduce a constrained-based execution model to support dynamic protocol simulation, getting grounded in the theories of process modeling and execution (Dourish et al., 1996; Pesic et al., 2007).

A constraint-based protocol execution modelWe extend the DSL program \(\vartriangleright(\mathbf{c})\) by a constraint set \(C=C_{op}\cup C_{reg}\cup C_{s}\cup C_{t}\) to construct a constraint-based execution model \(S=(\vartriangleright(\mathbf{c}),C)\). The execution of a program is represented by a trace \(\sigma=\langle(o_{1},c_{1}),(o_{2},c_{2}),\ldots,(o_{|\vartriangleright( \mathbf{c})|},c_{|\vartriangleright(\mathbf{c})|})\rangle\)where the order of \(o_{i}\) reflects the temporal sequence. The execution context \(c_{i}\) defines the spatial environment in which each operation is performed. Each constraint \(c\in S(C)\) is a predicate that maps the execution trace \(\sigma\) to a binary condition denoting satisfy or not. An execution trace \(\sigma\) is said to satisfy the program constraint if and only if \(|\sigma|=|\wp(\mathbf{c})|\) and \(c(\sigma)\) holds for all \(c\in C\).

Leveraging partial execution trace for spatial and temporal constraintsExplicit constraints, namely operation and reagent flow, are easy to satisfy. Unfortunately, deriving implicit constraints, _e.g._, the capacity of resources and safety of operations, is case-by-case for each protocol, requiring expert efforts. We propose profiling the context through execution to derive implicit spatial and temporal constraints that meet domain-specific requirements. An execution trace is defined as _partially_ satisfying the constraints \(C\) if it follows the operation and reagent flow; that is, for any \(\langle o_{i},o_{j>i}\rangle\) in trace \(\sigma\), there exists at least a pair of valid operation flow path and reagent flow path from \(o_{i}\) to \(o_{j}\).

## 4 Results

In this section, we compete our framework with human experts on the overall translation task, and assess the utility of each component of the framework by comparing with alternative approaches.

### Experimental setting

MaterialsWe select 75 complicated experiments with 1,166 steps in total as the testing set, from the domains of _Chemical Synthesis_ (235 steps in 10 experiments; 235 in 10 for simplicity; "Synthesis" for abbreviation), _Genetics_ (396 in 34), _Medical and Clinical Research_ (307 in 23, "Medical"), _Bioengineering_ (218 in 17), and _Ecology_ (10 in 1). Please refer to Appx. D for details.

Expert-created protocol translationWe recruited five groups of experienced experimenters, each specializing in a different domain, with seven participants in each group. Every participating experimenter holds at least a Master's degree related to the corresponding domain, has obtained at least six years' experience in manually conducting pre-designed experiments of the domain, has acquired elementary programming skills, and has at least heard of self-driving laboratories. These human experts are asked to translate the original NL-based protocols for their domains into those suitable for self-driving laboratories. Their outputs are subjected to DSL-based representations and complete PDGs to evaluate machines' behaviors, which are clearly demonstrated by a running example and the examples in the DSL documentation. Outputs from experts are carefully cross-validated and the individual divergence between them is minimized through an expert-panel-driven workshop discussion following the established workflow (Reilly et al., 2023). Translation results of human experts and machines are serialized and are compared through ROUGE and BLEU metrics (Lin, 2004; Papineni et al., 2002). Please refer to Appx. B for ethics considerations.

Alternative methodsWe compare our translator with alternative methods on the first two levels, to investigate the effects of early stages on the overall translation result. On the syntax level, we compare the syntactic synthesis method (referred to as Ours-SY) with ConDec-SY (Wang et al., 2023a), which synthesizes DSL programs by LLMs with external DSL grammars as constraint, and a baseline DSL-LLM-SY leveraging the minimal realization used in Shi et al. (2024). On the semantics level, we compare the deductive verification method (referred to as Ours-SE) with NL-RAG-LLM-SE, which retrieves on the embedded vector database of original NL-based protocols, and a baseline NL-LLM-SE implemented by pure prompt-engineering on LLMs. Since the I/Oes of all stages are unified in the pipeline, we implement an overall baseline Best-Baseline that combines the strongest alternative methods within the evaluation of the first two stages.

### Overall assessment on expert-created protocol translation

ResultComparing the overall output of our translator and ideal human experimenters, we find that our translator approaches the level of experts with average performance higher than \(85\%\) across all indicators. Our translator significantly outperforms the alternative pipeline Best-Baseline on the (\(t(148)=-17.71,\mu_{d}<0,p<.0005\); see Fig. 3C).

DiscussionWe find that our translator demonstrates similar performance to human experts in translating protocols with complete parameters and clear descriptions (see Fig. 4A). However, in cases where the linear description of the experimental protocol is lacking, our translator and human experts diverge. Specifically, our translator tends to translate based on the information within the sentence or between adjacent sentences, while human experts tend to consider the overall experimental process comprehensively. Though there are minor gaps, these observations suggest that our translator is approaching the level of performance of experienced human experimenters. Please refer to Appx. E.3 for case studies on the distinctions between the behaviors of experts and machines.

### Comparison between alternative models

ResultOn the syntax level, our Ours-SY significantly outperforms alternative approaches (\(t(148)=-17.07,\mu_{d}<0,p<.0005\) for ConDec-SY; \(t(148)=-15.47,\mu_{d}<0,p<.0005\) for DSL-LLM-SY; see Fig. 3D). On the semantics level, our Ours-SE significantly outperforms alternative approaches (\(t(148)=-2.52,\mu_{d}<0,p<.05\) for NL-RAG-LLM-SE; \(t(148)=-3.07,\mu_{d}<0,p<.005\) for NL-LLM-SE; see Fig. 3E).

DiscussionCompared with alternative methods on the syntax level, our translator excels in ensuring the accuracy of translations across different protocols thanks to the PDG representation, as shown in Fig. 4B. On the semantics level, our translator performs better in translating incomplete protocols with missing information than other baselines, as shown in Fig. 4C. We explain these merits with the properties of structural representation, which defines a representation space with

Figure 3: **Results of experiment.****(A)** Distinctions between various domains regarding domain-specific corpora and the corresponding DSLs. **(B)** Convergence of the three indicators in the objective function for program synthesis. **(C)** Our translator significantly outperforms the best baseline and approaches human-level performance. **(D)** Our translator significantly outperforms alternative methods on the syntax level. **(E)** Our translator significantly outperforms alternative methods on the semantics level.

[MISSING_PAGE_FAIL:10]

## Acknowledgements

This work was partially supported by the National Natural Science Foundation of China under Grants 91948302 and 52475001. Part of the authors are visiting students at Peking University during this work. In particular, Z. Bi is visiting from Huazhong University of Science and Technology and Q. Xu is visiting from University of Science and Technology of China. The authors would also like to thank Jiawen Liu for her assistance in figure drawings.

## References

* J. Abramson, J. Adler, J. Dunger, R. Evans, T. Green, A. Pritzel, O. Ronneberger, L. Willmore, A. J. Ballard, J. Bambrick, et al. (2024)Accurate structure prediction of biomolecular interactions with alphafold 3. Nature, pp. 1-3. Cited by: SS1.
* A. V. Aho and J. D. Ullman (1972)The theory of parsing, translation, and compiling. Vol. 1, Prentice-Hall Englewood Cliffs, NJ. Cited by: SS1.
* V. A. Alfred, S. L. Monica, and D. U. Jeffrey (2007)Compilers principles, techniques & tools. Pearson Education. Cited by: SS1.
* V. Ananthanarayanan and W. Thies (2010)Biocoder: a programming language for standardizing and automating biology protocols. Journal of Biological Engineering4, pp. 1-13. Cited by: SS1.
* M. Baker (2016)1,500 scientists lift the lid on reproducibility. Nature, pp. 533-(7604). Cited by: SS1.
* M. Baker (2021)Five keys to writing a reproducible lab protocol. Nature, pp. 597-(7875):293-294. Cited by: SS1.
* A. Bedard, A. Adamo, K. C. Aroh, M. G. Russell, A. A. Bodermann, J. Torosian, B. Yue, K. F. Jensen, and T. F. Jamison (2018)Reconfigurable system for automated optimization of diverse chemical reactions. Science361 (6408), pp. 1220-1225. Cited by: SS1.
* L. Billard (2000)Regression analysis for interval-valued data. Data Analysis, Classification, and Related Methods. Cited by: SS1.
* L. Billard (2006)Symbolic data analysis: what is it?. In Proceedings in Computational Statistics: 17th Symposium Held in Rome, Italy, Cited by: SS1.
* D. A. Boiko, R. MacKnight, B. Kline, and G. Gomes (2023)Autonomous chemical research with large language models. Nature, pp. 570-578. Cited by: SS1.
* A. M. Bran, S. Cox, O. Schilter, C. Baldassari, A. White, and P. Schwaller (2023)Augmenting large language models with chemistry tools. In NeurIPS 2023 AI for Science Workshop, Cited by: SS1.
* T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al. (2020)Language models are few-shot learners. In Advances in Neural Information Processing Systems, Cited by: SS1.
* B. Burger, P. M. Maffettone, V. V. V. Gusev, C. M. Aitchison, Y. Bai, X. Wang, X. Li, B. M. Alston, B. Closes, et al. (2020)A mobile robotic chemist. Nature, pp. 583-(7815):237-241. Cited by: SS1.
* N. Chomsky (1956)Three models for the description of language. IRE Transactions on Information Theory2 (3), pp. 113-124. Cited by: SS1.
* N. Chomsky (2007)Approaching ug from below. Interfaces + recursion = language89, pp. 1-30. Cited by: SS1.
* M. Christensen, L. P. Yunker, P. Shiri, T. Zepel, P. L. Prieto, S. Grunert, F. Bork, and J. E. Hein (2021)Automation isn't automatic. Chemical Science12 (47), pp. 15473-15490. Cited by: SS1.
* P. Dourish, J. Holmes, A. MacLean, P. Marqvardsen, and A. Zbyslaw (1996)Freeflow: mediating between representation and action in workflow systems. In Proceedings of the 1996 ACM conference on Computer supported cooperative work, Cited by: SS1.
* M. Felleisen (1991)On the expressive power of programming languages. Science of computer programming17 (1-3), pp. 35-75. Cited by: SS1.
* M. Felleisen (1991)On the expressive power of programming languages. Science of computer programming, pp. 17(1-3):35-75. Cited by: SS1.

Fowler, M. (2010). _Domain-specific languages_. Pearson Education.
* Freedman et al. (2015) Freedman, L. P., Cockburn, I. M., and Simcoe, T. S. (2015). The economics of reproducibility in preclinical research. _PLoS Biology_, 13(6):e1002165.
* Gallese and Goldman (1998) Gallese, V. and Goldman, A. (1998). Mirror neurons and the simulation theory of mind-reading. _Trends in Cognitive Sciences_, 2(12):493-501.
* Grisoni et al. (2021) Grisoni, F., Huisman, B. J., Button, A. L., Moret, M., Atz, K., Merk, D., and Schneider, G. (2021). Combining generative artificial intelligence and on-chip synthesis for de novo drug design. _Science Advances_, 7(24):eabg3338.
* Gulwani et al. (2017) Gulwani, S., Polozov, O., Singh, R., et al. (2017). Program synthesis. _Foundations and Trends(r) in Programming Languages_, 4(1-2):1-119.
* Hie et al. (2021) Hie, B., Zhong, E. D., Berger, B., and Bryson, B. (2021). Learning the language of viral evolution and escape. _Science_, 371(6526):284-288.
* Hoch (1985) Hoch, S. J. (1985). Counterfactual reasoning and accuracy in predicting personal events. _Journal of Experimental Psychology: Learning, Memory, and Cognition_, 11(4):719.
* Honnibal and Johnson (2015) Honnibal, M. and Johnson, M. (2015). An improved non-monotonic transition system for dependency parsing. In _Annual Conference on Empirical Methods in Natural Language Processing_.
* Hopcroft et al. (1996) Hopcroft, J. E., Motwani, R., and Ullman, J. D. (1996). _Introduction to Automata Theory, Languages, and Computation_. Addison-Wesley Longman Publishing Co., Inc.
* Jablonka et al. (2022) Jablonka, K. M., Patiny, L., and Smit, B. (2022). Making the collective knowledge of chemistry open and machine actionable. _Nature Chemistry_, 14(4):365-376.
* Jumper et al. (2021) Jumper, J., Evans, R., Pritzel, A., Green, T., Figurnov, M., Ronneberger, O., Tunyasuvunakool, K., Bates, R., Zidek, A., Potapenko, A., et al. (2021). Highly accurate protein structure prediction with alphafold. _Nature_, 596(7873):583-589.
* Kearnes et al. (2021) Kearnes, S. M., Maser, M. R., Wleklinski, M., Kast, A., Doyle, A. G., Dreher, S. D., Hawkins, J. M., Jensen, K. F., and Coley, C. W. (2021). The open reaction database. _Journal of the American Chemical Society_, 143(45):18820-18826.
* Kim et al. (2024) Kim, C., Gadgil, S. U., DeGrave, A. J., Omiye, J. A., Cai, Z. R., Daneshjou, R., and Lee, S.-I. (2024). Transparent medical image ai via an image-text foundation model grounded in medical literature. _Nature Medicine_, pages 1-12.
* Lin (2004) Lin, C.-Y. (2004). Rouge: A package for automatic evaluation of summaries. In _Text summarization branches out_.
* Lloyd (2012) Lloyd, J. W. (2012). _Foundations of logic programming_. Springer Science & Business Media.
* McNutt (2014) McNutt, M. (2014). Reproducibility. _Science_, 343(6168):229-229.
* Mehr et al. (2020) Mehr, S. H. M., Craven, M., Leonov, A. I., Keenan, G., and Cronin, L. (2020). A universal system for digitization and automatic execution of the chemical synthesis literature. _Science_, 370(6512):101-108.
* Mernik et al. (2005) Mernik, M., Heering, J., and Sloane, A. M. (2005). When and how to develop domain-specific languages. _ACM Computing Surveys (CSUR)_, 37(4):316-344.
* Munafo et al. (2017) Munafo, M. R., Nosek, B. A., Bishop, D. V., Button, K. S., Chambers, C. D., Percie du Sert, N., Simonsohn, U., Wagenmakers, E.-J., Ware, J. J., and Ioannidis, J. (2017). A manifesto for reproducible science. _Nature Human Behaviour_, 1(1):1-9.
* Papineni et al. (2002) Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J. (2002). Bleu: a method for automatic evaluation of machine translation. In _Proceedings of the 40th annual meeting of the Association for Computational Linguistics_.
* Papineni et al. (2017)Park, N. H., Manica, M., Born, J., Hedrick, J. L., Erdmann, T., Zubarev, D. Y., Adell-Mill, N., and Arrechea, P. L. (2023). Artificial intelligence driven design of catalysts and materials for ring opening polymerization using a domain-specific language. _Nature Communications_, 14(1):3686.
* Pearl (2019) Pearl, J. (2019). The seven tools of causal inference, with reflections on machine learning. _Communications of the ACM_, 62(3):54-60.
* Pesic et al. (2007) Pesic, M., Schonenberg, M., Sidorova, N., and van der Aalst, W. M. (2007). Constraint-based workflow models: Change made easy. In _OTM Confederated International Conferences" On the Move to Meaningful Internet Systems"_.
* Reilly et al. (2023) Reilly, J., Shain, C., Borghesani, V., Kuhnke, P., Vigliocco, G., Peelle, J., Mahon, B., Buxbaum, L., Majid, A., Brysbaert, M., et al. (2023). What we mean when we say semantic: A consensus statement on the nomenclature of semantic memory. _OSF preprint_.
* Rohrbach et al. (2022) Rohrbach, S., Siauciulis, M., Chisholm, G., Pirvan, P.-A., Saleeb, M., Mehr, S. H. M., Trushina, E., Leonov, A. I., Keenan, G., Khan, A., et al. (2022). Digitization and validation of a chemical synthesis literature database in the chempu. _Science_, 377(6602):172-180.
* Seifrid et al. (2022) Seifrid, M., Pollice, R., Aguilar-Granda, A., Morgan Chan, Z., Hotta, K., Ser, C. T., Vestfrid, J., Wu, T. C., and Aspuru-Guzik, A. (2022). Autonomous chemical experiments: Challenges and perspectives on establishing a self-driving lab. _Accounts of Chemical Research_, 55(17):2454-2466.
* Shi et al. (2024a) Shi, Y.-Z., Hou, H., Bi, Z., Meng, F., Wei, X., Ruan, L., and Wang, Q. (2024a). AutoDSL: Automated domain-specific language design for structural representation of procedures with constraints. In _Annual Meeting of the Association for Computational Linguistics_.
* Shi et al. (2024b) Shi, Y.-Z., Li, H., Ruan, L., and Qu, H. (2024b). Constraint representation towards precise data-driven storytelling. In _IEEE Visualization and Visual Analytics Gen4DS_.
* Shi et al. (2023a) Shi, Y.-Z., Li, S., Niu, X., Xu, Q., Liu, J., Xu, Y., Gu, S., He, B., Li, X., Zhao, X., et al. (2023a). PersLEARN: Research training through the lens of perspective cultivation. In _Annual Meeting of the Association for Computational Linguistics_.
* Shi et al. (2023b) Shi, Y.-Z., Xu, M., Hopcroft, J. E., He, K., Tenenbaum, J. B., Zhu, S.-C., Wu, Y. N., Han, W., and Zhu, Y. (2023b). On the complexity of Bayesian generalization. In _International Conference on Machine Learning_.
* Shi et al. (2024c) Shi, Y.-Z., Xu, Q., Meng, F., Ruan, L., and Wang, Q. (2024c). Abstract Hardware Grounding towards the Automated Design of Automation Systems. In _International Conference on Intelligent Robotics and Applications_.
* Singh et al. (2023) Singh, S. H., van Breugel, F., Rao, R. P., and Brunton, B. W. (2023). Emergent behaviour and neural dynamics in artificial agents tracking odour plumes. _Nature Machine Intelligence_, 5(1):58-70.
* Steiner et al. (2019) Steiner, S., Wolf, J., Glatzel, S., Andreou, A., Granda, J. M., Keenan, G., Hinkley, T., Aragon-Camarasa, G., Kitson, P. J., Angelone, D., et al. (2019). Organic synthesis in a modular robotic system driven by a chemical programming language. _Science_, 363(6423):eaav2211.
* Strateos (2023) Strateos (2023). Autoprotocol specification. https://autoprotocol.org/specification/.
* Szymanski et al. (2023) Szymanski, N. J., Rendy, B., Fei, Y., Kumar, R. E., He, T., Milsted, D., McDermott, M. J., Gallant, M., Cubuk, E. D., Merchant, A., et al. (2023). An autonomous laboratory for the accelerated synthesis of novel materials. _Nature_, 624(7990):86-91.
* Vaucher et al. (2020) Vaucher, A. C., Zipoli, F., Geluykens, J., Nair, V. H., Schwaller, P., and Laino, T. (2020). Automated extraction of chemical synthesis actions from experimental procedures. _Nature Communications_, 11(1):3601.
* Wang et al. (2023a) Wang, B., Wang, Z., Wang, X., Cao, Y., A Saurous, R., and Kim, Y. (2023a). Grammar prompting for domain-specific language generation with large language models. In _Advances in Neural Information Processing Systems_.

Wang, H., Fu, T., Du, Y., Gao, W., Huang, K., Liu, Z., Chandak, P., Liu, S., Van Katwyk, P., Deac, A., et al. (2023b). Scientific discovery in the age of artificial intelligence. _Nature_, 620(7972):47-60.
* Wang et al. (2022) Wang, Z., Cruse, K., Fei, Y., Chia, A., Zeng, Y., Huo, H., He, T., Deng, B., Kononova, O., and Ceder, G. (2022). ULSA: Unified language of synthesis actions for the representation of inorganic synthesis protocols. _Digital Discovery_, 1(3):313-324.
* Wei et al. (2021) Wei, J., Bosma, M., Zhao, V. Y., Guu, K., Yu, A. W., Lester, B., Du, N., Dai, A. M., and Le, Q. V. (2021). Finetuned language models are zero-shot learners. _arXiv preprint arXiv:2109.01652_.
* Xie et al. (2024) Xie, T., Li, Q., Zhang, Y., Liu, Z., and Wang, H. (2024). Self-improving for zero-shot named entity recognition with large language models. _arXiv preprint arXiv:2311.08921_.
* Zhang et al. (2021) Zhang, J., Chen, B., Zhang, L., Ke, X., and Ding, H. (2021). Neural, symbolic and neural-symbolic reasoning on knowledge graphs. _AI Open_, 2:14-35.

Additional remarks

### Rationale for the evaluation metrics

Direct comparisons across entire sentences under BLEU and ROUGE scores would indeed pose a problem -- it may be problematic considering instructions that look similar could have very different semantics. Therefore, to circumvent this issue, we convert all results into a standardized JSON-style format for data representation, and comparisons are made between key-value pairs rather than entire sentences, effectively resolving the metric concern.

Let us consider comparing similarity between the following two instructions _"... pour hot water..."_ and _"... pour cold water..."_. We transform them into the following JSON-style format:

```
1{...
2...
3function_name: "pour",
4reagent: "water",
5temperature: "hot",
6...
7}
8...
9{
10...
11function_name: "pour",
12reagent: "water",
13temperature: "cold",
14...
15} ```

The comparison between the two sentences is then transformed into a comparison between two JSON code blocks. We calculate the similarity score cumulatively based on the similarity between the values of matched pairs of keys. For instance, for the key "temperature", the values "hot" and "cold" yield a low similarity score under the ROUGE, BLEU, and even the Exact Match metrics. As "temperature" is one of the major keys within configuration parameters, a high penalty in this dimension significantly affects the cumulative similarity score. With this fine-grained comparison metric, we can comprehensively track the distinctions and commonalities between results without losing expressivity regarding the quantities.

We also acknowledge that there are advanced evaluation metrics, especially in the recent works where LLMs are leveraged as external judges and achieve considerable performance in general testing cases. Our choice of _less advanced_ metrics is driven by the intention to focus specifically on domain-specific knowledge, which constitutes the primary scope of this paper and may be relatively sparse in general LLMs. Nonetheless, the exploration of more sophisticated evaluation metrics represents a promising avenue for future research.

### Insight behind the design of PDG

We have constructed the operation dependence graph on the syntax level and the reagent flow graph on the semantics level. Indeed, the two analytical results come with a _duality_. In the operation dependence graph, vertices represent operations and edges represent reagents passed between them. In contrast, the reagent flow graph uses vertices for reagent states and edges for operations causing state transitions. Interestingly, the vertices of one of the two graphs can be one-to-one mapped to the edges of another, echoing the duality. On a higher level, we say that the former provides an _experimenter-centered view_ while the latter offers a _reagent-centered view_. These two perspectives are complementary on encoding both the information of the interventions to the environment and the status of the environment itself. Consequently, by leveraging such duality, we are able to track spatial dynamics, _e.g._, the variance of required resources, and temporal dynamics, _e.g._, the context of sequential operations, simultaneously on the PDG.

### Computational complexity of the framework

Let us consider a new coming protocol with \(k\) steps, with each step configured by a constant number of parameters, denoted as \(c\). On the syntax level, the primary computation bottleneck arises during DSL program synthesis, where the EM Algorithm exhibits a worst-case complexity of \(O(c^{k})\). This is a highly conservative estimate, as mainstream optimization approaches can solve the EM much more efficiently. On the semantics level, the bottleneck occurs during reagent flow analysis, which consumes \(O(k^{2})\) complexity. Notably, only approximately 10% of the steps are included in the nested loop for reagent flow construction, as about 90% of the steps are linearly connected. On the execution level, the protocol execution model also exhibits \(O(k^{2})\) complexity, encompassing both forward and backward tracing. This can be optimized by replacing the full tracing strategy with a sliding window built upon the topological dependencies between steps. Although the complexities of the algorithms at these three levels are tractable, there is substantial room for improving the efficiency of the framework. Investigating methods to speed up the translation process for protocols with extremely high complexity would be a valuable area of research.

### Generality of the framework

The general applicability of our proposed framework beyond experimental sciences can indeed be a common concern. The core value of translating NL-based protocols into formats suitable for machine execution substantially lies in facilitating experiments in self-driving laboratories, thereby accelerating scientific discovery. Experimental protocols come with unique properties and challenges, such as the fine-grained incorporation of domain-specific knowledge, the non-trivial dependency topologies between operations, the long-horizon lifecycles of intermediate productions, and the necessity for precise execution without run-time errors. These factors shape the scope of our research problem, emphasizing the need to handle protocols with stringent terminology and formatting.

Despite the specific scope of this paper, we are open to exploring the potential for generalizing our framework to other domains with similar properties and challenges as those found in scientific experiments -- such as cooking. Imagine a self-driving kitchen that automatically prepares all ingredients and executes all procedures for cooking a meal according to NL-based recipes. Such self-driving kitchens would also benefit significantly from translating human-oriented recipes into formats suitable for machine execution. In the following, we present a running example of such a translation, adapted from a use case of the Corel1 DSL.

Footnote 1: Visit https://fse.studenttheses.ub.rug.nl/25731/ for documentation.

The protocol after pre-processing is as follows.

```
1PastaBolognese
2
3Yield:2plates
4
5Ingredients:
6
7-8[ounces]whitefresh{pasta}
8
9-1[floor]olive{oil}
10
11-1/4[ounc]{garlic};minced
12
13-4[ounces]{onions};chopped
14
15-4[ounces]shallowfried{beef};minced
16
17-1-11/2[ounc]leanprepared{bacon}
18
19-1/3[oup]red{wine} ```
20
21-150[gram]raw(carrots);thinlysliced
22
23-2/3[ounce]concentrated{tomatopuree}
24
25-4[ounces]red(sweetepper);cutjulienne
26
27-1[ounce]{parmesan}cheese
28
29Instructions:
30
31Addthe@oil@toalargesaucepan,heatto<300F>,andsautethe
#onions@.
32
33After|2minutes|,addthe@garlic@.Keeponmediumtobighheat,anddon'tstir.
34
35After|2minutes|more,addthe@beef@.
36
37Frythe@bacon@inasparatepan,onhighheat.Removeliquidefatwhendone.
38
39Boil@pasta@inamediumpan,untiladente{-|8minutes|}.Drainwhendone.
40
41Oncethe@beef@isdone,addthe@carrots@,@sweetepper@and@tomatopuree@.
42
43Slowlyaddthe@wine@aswell,tonotlowerthetemperature.Letitsimmer(butnotboil)for|5-10minutes|.

Given the protocol as the input of our framework, the resulting DSL program is as follows.

```
1add(slot="oil",target="largesaucepan",container=plate_1,emit=mixture_1);
2
3heat(target=mixture_1,temperature=300F,container=plate_1,postcon=stop());
4
5saute(target="onions",container=plate_2,duration=2mins);
6
7add(slot="garlic",target=mixture_1,container=plate_1,emit=mixture_2);
8
9heat(target=mixture_2,temperature=325F,container=plate_1,duration=2mins);
10
11add(slot="beef",target=mixture_2,container=plate_1,emit=mixture_3);
12
13heat(target=mixture_2,temperature=325F,container=plate_1,postcond=check_done(target="beef"));* 15fry(target = "bacon", temperature = 350F, container = pan_1, postcond = remove(target = "liquidized fat"));
* 16
* 17boil(target = "pasta", temperature = 212F, container = pan_2, duration = 8mins, postcond = drain());
* 18
* 19add(precond = check_done(target = "beef"), slot = ["carrots", "sweet pepper", "tomato puree"], target = mixture_3, container = plate_1, emit = mixture_4);
* 20
* 21add(slot = "wine", target = mixture_4, container = plate_1, pace = 1mL/s) ;
* 22
* 23immer(target = mixture_4, temperature = 211F, duration = 7.5mins);

In this example, we observe that the NL-based recipe possesses ambiguities and omissions. Our translation framework addresses these challenges by structuring the recipe on the syntax level, completing the latent information on the semantics level, and linking the programs with necessary resources, such as the usage of plates, on the execution level. Due to the modularity of DSLs, although Corel's distribution of syntactic and semantic features differs significantly from those of DSLs used for representing experimental protocols, our translator can generalize to this new target domain through the structure of rules, namely _rule-based generalization_[23].

### The motivations behind this work

In this work, we study the problem of translating experimental protocols designed for human experimenters into formats suitable for machine execution. Our primary motivation is to bridge the existing gap between machine learning algorithms in the field of AI for science, such as molecular design, and the grounded experimental verification facilitated by self-driving laboratories. Conventional workflows for setting up self-driving laboratories and conducting physical experiments necessitate deep integration with domain experts, significantly impeding the progress of machine learning researchers in verifying and iterating their findings. Consequently, our framework aims to provide an infrastructure that enables these researchers to advance their machine learning algorithms and seamlessly validate their findings, thereby closing the loop of automatic scientific discovery.

To meet the requirements of such infrastructure, we conduct a systematic study to identify existing gaps in protocol translation between human experimenters and automatic translators in self-driving laboratories. From the study, we derive design principles that emulate human cognitive processes involved in protocol translation. Under the guidance of these design principles, we develop the three-stage framework that integrates cognitive insights from human experts with approaches from program synthesis, automaton construction, and counterfactual analysis. On the syntax level, we synthesize the operation dependence graph to transform NL-based protocols into structured representations, thereby making explicit the operation-condition mappings and the control flows. On the semantics level, we analyze the reagent flow graph to reconstruct the complete lifecycles of intermediate products, addressing the latent, missing, or omitted properties and values. On the execution level, we contextualize both the operation dependence graph and the reagent flow graph within spatial and temporal dynamics, resulting in the protocol dependence graph. This graph conducts counterfactual reasoning to detect potential conflicts or shortages of execution resources and to identify inappropriate combinations of operations in execution sequences.

## Appendix B Ethics statement

### Human participants

The meta-evaluation included in this work has been approved by the Institutional Review Board (IRB) of Peking University. We have been committed to upholding the highest ethical standards in conducting this study and ensuring the protection of the rights and welfare of all participants. We paid the domain experts a wage of $22.5/h, which is significantly higher than the standard wage.

We have obtained informed consent from all participants, including clear and comprehensive information about the purpose of the study, the procedures involved, the risks and benefits, and the right to withdraw at any time without penalty. Participants were also assured of the confidentiality of their information. Any personal data collected (including name, age, and gender) was handled in accordance with applicable laws and regulations.

### Corpora collection

We carefully ensure that all experimental protocols incorporated into our corpora strictly adhere to open access policies, governed by the Creative Commons license. This approach guarantees full compliance with copyright and intellectual property laws, eliminating any potential infringement or unauthorized use of protected materials. By exclusively utilizing resources that are freely available and legally distributable, we uphold the highest standards of ethical conduct in research, fostering an environment of transparency and respect for the intellectual property rights of others. This commitment ensures that our work not only advances the frontiers of knowledge but does so in a manner that is both legally sound and ethically responsible.

## Appendix C Implementation details

### Details of pre-processing

We employ the SpaCy Dependency Parser to analyze the syntactic structure of protocol \(\mathbf{c}\), which allows for the extraction of verbs and the identification of associated objects and modifiers (Honnibal and Johnson, 2015). After parsing, these verbs are aligned with corresponding operational actions \(o\in T_{\mathrm{cp}}\) in the DSLs by maximizing the cosine similarity between their word2vec representations and those of the DSL operations. Furthermore, we utilize an advanced few-shot Named Entity Recognition (NER) algorithm, based on large language models, to accurately identify and classify entities \(\mathbf{e}_{t}\in\mathcal{E}\) within the text (Xie et al., 2024). The rationale of integrating LLMs with classical parsing techniques lies in leveraging the advanced natural language processing capabilities of LLMs while mitigating their inherent uncertainties.

The prompt for NER is as follows.

```
1Givenentitylabelset:{label_set}.
2Pleasenamethementitiesinthegiventext.Basedonthegivenentitylabelset,provideanswerinthefollowingJSONformat:{"EntityName":"EntityLabel"}].Ifthereisnoentityinthetext,returnthefollowingemptylist:{].
3Pleasenotethatentitieshavealreadybeenannotatedwith[],noneedtoextractandanalyzeotherentities.
4{cases}
5Text:{query}
6Answer: ```

### Details of reagent flow analysis

We extract reagents from the natural language descriptions of protocols using two utility functions, Kills and Defines. Kills identifies the reagent consumed in an operation, while Defines identifies the reagent introduced in an operation. Due to the potential for a single chemical substance to have multiple names among other factors, it is impractical to rely solely on string matching to determine if a reagent is killed in a given operation. Instead, we employ a method based on prompt engineering with LLMs for this analysis.

The following prompt is used to analyze whether the input of the current operation is the output of a previous operation:1This instruction describes a step in an experimental process, which includes one action, multiple parameters, and one output.
2Please help analyze the output of this instruction. I will provide a list of potential outputs. You need to assist in determining which of these outputs is most suitable for this instruction.
3Note that you must choose one output from the list. Please output only a string without any explanation.
4
5[Examples]
6Instruction: ("action": "add", "reagent": ["glycolue"], "output": "")
7Potential output list: "RNA", "mRNA"
8Output: "RNA"
9
10Instruction: ("action": "add", "concentration": ["1:10 volume 5 M NaCl"], "output": "")
11Potential output list: "a \(\mu\)MACS column", "solution"
12Output: "solution"
13
14Instruction: ("action": "heat", "reagent": ["limestone"], "output": "")
15Potential output list: "water", "NaCl"
16Output:
17
18[Question]
19Instruction: (Instruction)
20Potential output list: (Input)
21Output: ```

Additionally, this prompt is used to determine if reagents in the current memory \(M(\Gamma)\) are killed by the current operation:

```
1This instruction describes a step in an experimental process, which includes one action, multiple parameters-including various reagents- and one output.
2Please help analyze the missing reagents of this instruction. I will provide a list of potential reagents. You need to help me analyze which of these reagents might be the ones omitted from the current instruction.
3Please note how many reagent parameters are missing from the current instruction. It is possible that some reagent parameters cannot be completed with the list provided. Please output only a comma- separated list of strings without any explanation.
4
5[Examples]
6Instruction: ("action": "add", "reagent": [""], "output": "")
7Potential reagent list: "RNA", "glycolue"
8Reagents: "glycobline"
9
10Instruction: ("action": "add", "concentration": ["1:10 volume"], "reagent": ["", ""], "output": "")
11Potential reagent list: "HMACS", "solution", "NaCl"
12Reagents: "NaCl", "HMACS"* [14]Instruction: ("action": "use", "reagent": ["BamHI", "XhoI", ""], "device ": ("PCR amplification"), "output": "")
* [15]Potential reagent list: "agar", "food"
* [16]Reagents:
* [17]
* [18][Question]
* [19]Instruction: (Instruction)
* [20]Potential reagent list: (Memory)
* [21]Reagents: ```

In the process of synthesizing operation dependencies on the syntax level, we implement the Defines function. This involves pattern matching after pre-processing to accurately define reagents in each operation.

### Cost of the implementation

The computational cost of our algorithm primarily arises from the expenses associated with API calls to LLMs. We selected OpenAI's gpt-3.5-turbo-0125 model for our experiments. Across 75 test protocols, we executed 1816 queries to achieve syntax-level translation, resulting in structured protocols. At the semantic level, we conducted 4062 queries for completion tasks (including translating protocols retrieved from training dataset). During these experiments, the cost model charged US$0.50 per million tokens for inputs and US$1.50 per million tokens for outputs. Consequently, our expenditures were approximately US$10. Additionally, we utilized OpenAI's text-embedding-ada-002 model to embed the training dataset and build a vector database, which incurred a cost of about US$7.

## Appendix D The testing set

### Collection

The real experiments for the testing set are retrieved from open-sourced websites run by top-tier publishers, including Nature's Protocolexchange2, Cell's Star-protocols3, Bio-protocol4, Wiley's Current Protocols5, and Jove6.

Footnote 2: https://protocolexchange.researchsquare.com/

Footnote 3: https://star-protocols.cell.com/

Footnote 4: https://bio-protocol.org/en

Footnote 5: https://currentprotocols.onlinelibrary.wiley.com/

Footnote 6: https://www.jove.com/

### Showcases

```
1[Protocol1-Biochemistry]
2Preparationoflysates
31.Harvestapproximately1x10^?cellsbycentrifugationat2000RPMfor5min.Aspiratmediaandresuspendcellpelletwith1mLofice-coldPBSandtransfertoa1mLcentrifugetube.Microcentrifugeat2000RPMfor5minat4^oC.
42.AspiratPBS,andthenaddHypotonicBuffer(supplementedwith1%T TritonX-100,tob disruptmembraneandcytoskeleton-boundMEKK1fractions).
53.Celllysatesarehomogenizedbypassingthrough22-gaugeneedles,andtubesareputonicefor15mintocompletethelysis.Crudeextractsarethencentrifugedat2500RPMfor5min.Supernatantsaretransfertofreshcentrifugetubes,andcold5MNaClisaddedtoeach sample to make a salt concentration of between 0.7-1.0 M to disrupt protein-protein interactions.
* 64. Spin the crude extracts by ultracentrifugation at 55000 RPM to properly pellet residual insoluble proteins from the extract. Transfer supernatants into fresh centrifuge tubes.
* 7Immunoprecipitation
* 85. Rinse Protein A beads in Hypotonic Buffer and place on ice until ready for use.
* 96. Take a volume of cell lysates (prepared as described above), and dilute with Hypotonic Buffer to 250-500 mM salt to enable protein-protein interactions.
* 107. Add 2 \(\mu\)g of preclearing antibody to the diluted lysate (e.g., anti-Myc or anti-p65), vortex, add 50 \(\mu\)L of Protein A beads, and rock for 45 min.
* 118. Touchspins samples, and transfer supernatant to a fresh tube.
* 129. Add 2 \(\mu\)g of polyclonal anti-MEKK1 to the lysates, and rock for 1 h. After this period, add 50 \(\mu\)L of Protein A beads and rock tubes at 4 \({}^{\circ}\) C for 1 h.
* 1310. Touchspins beads, wash beads with hypotonic buffer (supplemented with NaCl to a concentration of 300 mM), vortex, and rock for 10 min. In total, 3-5 washes of the beads are performed.
* 1411. Finally, wash once with Hypotonic Buffer, and resuspend in Kinase Assay Buffer. Purified MEKK1 may be stored by snap-freezing in liquid nitrogen and long-term storage at -80 \({}^{\circ}\)C. Kinase assay Following preparation of MEKK1 immunoprecipitates (as above), incubate with 7 \(\mu\) g of JNKK1(K131M) along with 5 \(\mu\)Ci of ATP in Kinase Assay Buffer for 30 min at 30 \({}^{\circ}\)C."
* 15

* 171. Note that everything is in DEPC water. Inoculate W303a cells expressing different TOR1-RR variants in 2 mL SC medium overnight.
* 182. Subculture the cells starting from OD600=0.1 in 10 mL SC media, shake vigorously at 30 \({}^{\circ}\)C, 300 RPM for around 4-6 h until OD600=0.4-0.5.
* 193. Collect the cells by spinning down without freezing on ice. Discard supernatant.
* 204. Re-suspended cells with 1 mL water and transfer to a 1.5 eppendorf tube, quickly spin down at 3,000 x g for 15 sec.
* 215. Re-suspended cell pellet in 400 \(\mu\)L of AE buffer at room temperature.
* 226. Add 40 \(\mu\)L 10% SDS (final around 1%) and vortex briefly at room temperature (RT).
* 237. Immediately add 500 \(\mu\)L hot phenol/AE (put in 65 \({}^{\circ}\)C for 10 min before use), vortex vigorously for 1 min. Incubate at 65 \({}^{\circ}\)C for 5 min. Briefly vortex every 30 sec.
* 248. Immediately freeze by dumping into liquid nitrogen. Wait to thaw at RT (put in 30 \({}^{\circ}\)C to thaw may crack the tube).
* 259. Centrifuge for 10 min on a standard laboratory microfuge at 20,000 x g at RT.
* 2610. Transfer around 400 \(\mu\)L supernatant to a new eppendorf tube. Recycle the lower phenol fraction carefully following the chemical safety protocol in your laboratory.

2711. Add equal volume (400 \(\mu\)L) phenol: CHC13/AE-Na. Vortex vigorously for 1 min at RT.
* 2812. Spin down at 20,000 x g for 5 min in a standard laboratory microfuge.
* 2913. Transfer supernatant (around 350 \(\mu\)L) to a fresh 1.5 mL eppendorf tube. Add CHC13: isoamyl alcohol (24:1). Vortex vigorously for 1 min at RT.
* 3014. Transfer aqueous supernatant to a fresh 1.5 mL microfuge tube. If white cloudy precipitate is observed between the aqueous phase and organic phase, repeat steps 17-18.
* 3115. Add 1/10 volume of 3 M NaOAc (pH 5) and vortex vigorously. Add 2.5 volumes of ethanol. Vortex again.
* 3216. Place at -20 \({}^{\circ}\)C for at least 30 min.
* 3317. Spin down in the microfuge at 20,000 x g, 15 min at 4 \({}^{\circ}\)C. RNA pellet is usually visible.
* 3418. Add ice-cold 75% EtOH, place at 4 \({}^{\circ}\)C for around 10 min. Vortex and spin down on microfuge 20,000 x g, 15 min at 4 \({}^{\circ}\)C. Discard supernatant. Suck out the liquid droplets in the tube. The white RNA pellet will turn clear when it dries out. Add 30-50 \(\mu\)L ddH2O (DEPC) immediately after it becomes clear. Do not let the RNA over-dry, which will make it difficult to dissolve. If RNA pellet is over-dry, dissolve RNA at 37 \({}^{\circ}\)C for 30 min. Store RNAs at -80 \({}^{\circ}\)C for more than 2 months."
* 35

* 371. Passage through a 45 \(\mu\)m filter. Add 100 \(\mu\)L/well of 100 \(\mu\)g/mL salmon sperm DNA to a 96-well Microtest assay plate.
* 382. Wrap the plate with plastic wrap and incubate at 4 \({}^{\circ}\)C overnight.
* 393. Discard the coating antibody solution and wash the plate with 1x PBS-Tween 6 times.
* 404. Dry the plate and add 100 \(\mu\)L of blocking solution per well to the plate.
* 415. Incubate the plate at room temperature (RT) for 1.5 h.
* 426. Discard the blocking solution and wash the plate with 1x PBS-Tween 5 times.
* 437. Dry the plate and keep it at 4 \({}^{\circ}\)C for later use.
* 448. Harvest the spleen and create a single-cell suspension by gently smashing spleen pieces with the frosted surface of a pair of microscope slides in 5 mL of DMEM.
* 459. Transfer the cells into 50 mL conical tubes and spin down the cells at 300 RCF for 5 min at 4 \({}^{\circ}\)C.
* 4610. Discard the supernatant with aspiration without disturbing the pellet.
* 4711. Re-suspend the cells with 5 mL of 0.17 M ammonium chloride and keep the cells on ice for 5 min.
* 4812. Add 15 mL DMEM to the cells and spin at 300 RCF for 5 min at 4 \({}^{\circ}\)C.
* 4913. Discard the supernatant and re-suspend the cells with 20 mL of DMEM and count the cells.
* 5014. Re-suspend 2 x 10\({}^{\circ}\)7 cells in 2 mL of 10% DMEM and make a three-fold serial dilution (at total of 8 dilutions) with 10% DMEM.
* 5115. Add 50 \(\mu\)L/well of the serial dilutions on the DNA-coated plate and centrifuge at 300 RCF for 5 min at 4 \({}^{\circ}\)C.

5216. Incubate the cells at 30 \({}^{\circ}\)C for 2 h in a cell-culture incubator with 6% C02.
5317. Add 50 \(\mu\)L/well of biotin-conjugated anti-IgM or anti-IgG (1:350 in 10% DMEM) to the cells.
5418. Centrifuge the cells at 300 RCF for 5 min at 4 \({}^{\circ}\)C and incubate the cells overnight in a cell-culture incubator with 6% C02.
5519. Discard the cells and wash the plates 10 times with 10x PBS-Tween 20.
5620. Dry the plates and add 50 \(\mu\)L of streptavidin alkaline phosphatase (1:1,000 in 1% BSA/PBS) to the plate.
5721. Incubate the plate at RT for 1 h and wash the plate 10 times with 10x PBS-Tween 20.
5822. Dry the plate and add 50 \(\mu\)L/well of 1 mg/mL BCIP in AMP buffer to develop the plate.
5923. When the spots are clearly visible under a dissecting microscope, stop the development by discarding the BCIP solution and rinsing the plate with tap water thoroughly.
6024. Spots can be counted using a dissecting microscope or using an ELISpot reader."

### Instruction for human experts

1 Instruction for Human Study on Protocol Translation and Parameter Completion
2 [Objective]
3 The purpose of this study is toevaluate the accuracy and completeness of translating natural language laboratory protocols into a structured JSON representation and to assess the manual completion of missing parameters within these protocols.
4 [Experimental Tasks]
5 Participants in this study will perform two main tasks:
61. Translation of Natural Language Protocols to JSON-Structured Representation
72. Manual Parameter Completion in JSON-Structured Protocols
8 [Task 1: Translation of Natural Language Protocols to JSON-Structured Representation]
9 [Description]
10 Participants will be provided with a set of laboratory protocols written in natural language. The task is to translate each protocol into a JSON-structured format. This involves accurately mapping the operations, input reagents, and conditions specified in the natural language description to a precise JSON schema.
11 [Procedure]
121. Read the provided natural language protocol carefully.
132. Identify and extract the key elements of the protocol, including: Operations (e.g., dissolve, mix, heat)/Input reagents (e.g., sodium chloride, distilled water)/Conditions (e.g., temperature, time, concentration)
143. Construct a JSON representation that clearly reflects the structure and content of the protocol. Ensure that each element is correctly mapped to its corresponding key and value pairs.
15 [Example]16Extract total RNA from at least 2 x 10^6 cells using TRIZOL reagent.
17("action": "extract", "output": "total RNA", "reagent": ["TRIZOL reagent "], "volume": ["at least 2 x 10^6 cells"], "container": [""]]
18[Manual Parameter Completion in JSON-Structured Protocols]
19[Description]
20Participants will receive a set of JSON-structured protocols with certain parameters intentionally left incomplete. The task is to manually complete these parameters based on domain knowledge and logical inference.
21[Procedure]
221. Review the provided JSON-structured protocol.
232. Identify any missing or incomplete parameters.
243. Use your expertise to infer the missing information. This may include: Estimating reasonable values for missing quantities or conditions;
25Ensuring consistency and coherence within the protocol.
264. Complete the JSON structure with the inferred parameters, maintaining accuracy and logical consistency.
27[Example]
28["action": "apply", "output": "known DHB cluster signals", "device": ["<<MASK>>"]]
29["action": "apply", "output": "known DHB cluster signals", "device": ["<<<<a pneumatic sprayer system>>>>"]]

[MISSING_PAGE_EMPTY:26]

[MISSING_PAGE_FAIL:27]

\begin{table}
\begin{tabular}{p{113.8pt}|p{113.8pt}|p{113.8pt}} \hline \hline
**Original Text** & **Semantic Level** & **Known Unknows** \\ \hline Transfer the sample (plasma, cell suspension) into a glass centrifuge vial. & TRANSFER; [[Reagent: the sample (plasma, cell suspension)], [Container: a glass centrifuge vial]] -\textgreater{} & **Known Unknows** \\ \hline Adjust the volume to 1 ml with PBS. & MODIFI; [[Output: heparinized Blood:1 ml medium], [Volume: asl mlss]] -\textgreater{} & **1 ml** \\ \hline
50-200 ul plasma was taken from heparinized blood.1 ml medium. & TAKE; [[Resagent: heparinized blood.1 ml medium]] -\textgreater{} & TAKE; [[Output: a plasma sample]] -\textgreater{} & **Known Unknows** \\ \hline Add 10 ul of the internal standard (10 ul of X17.5 ml in MeOH). Add 300 ul of 18.5 hCL. & LABO; [[Reagent: 18.5 hCL], [Volume: <<300 ul] -\textgreater{} & ***300 ul** \\ \hline As an example, S1P extraction from a plasma sample is shown in step A7. & SMOU; [[Output: step A7], [Reagent: a plasma sample]] -\textgreater{} & **Shlow:** [[Output: step A7], [Reagent: a plasma sample]] -\textgreater{} \\ The CHC13-phase is extracted by directly pipeting through the upper aqueous phase. & TAKE; [[Output: step A7], [Reagent: a plasma sample]] -\textgreater{} & **Known Unknows** \\ \hline Add this CHC13-phase of step A7. & TAKE; [[Return: step A7], [Reagent: a plasma sample]] -\textgreater{} & **Known Unknows** \\ \hline Add this CHC13-phase of step A7. & TAKE; [[Return: step A7], [Reagent: a plasma sample]] -\textgreater{} & **Known Unknows** \\ \hline Vacuum-dry the CHC13 in the vacuum rotator at 00 °C for 45 min. & TAKE; [[Return: step A7], [Reagent: a plasma sample]] -\textgreater{} & **Known Unknows** \\ \hline Alternatively, the samples can be dried under nitrogen gas flow. & TAKE; [[Output: step A7], [Reagent: a plasma sample]] -\textgreater{} & **Known Unknows** \\ \hline Re-equilibrate with 90 solution A. & EQUILIBRATE; [[Output: step A7], [Concentration: 90 solution]] -\textgreater{} & **Known Unknows** \\ \hline S1P is analyzed with the mass transition 380 m/z \textgreater{} 264 ml/z. For quantitative analysis, a standard curve with S1P amounts of 1 pmol to 100 pmol as the internal standard is generated. & TAKE; [[Return: step A7], [Concentration: 90 solution]] -\textgreater{} & **Known Unknows** \\ \hline \hline \end{tabular}
\end{table}
Table A4: **Running cases on the semantics level regarding known unknowns**

\begin{table}
\begin{tabular}{p{142.3pt}|p{142.3pt}|p{142.3pt}} \hline \hline
**Original Text** & **Semantic Level** & **Unknown Unknown Unknown known knowns** \\ \hline \hline Harvest approximately 1x107 cells by centrifugation for 5 min. & HARVEST: [[Device: centrifugation], [Time: 5 min], [Force: \#<22000 RPMw>]] & *<2000 RPMw>* \\ \hline Cell lysates are homogenized by passing through 22:gauge needles. & HOMOGENTZE: [[Reagent: cell lysates]] \\ \hline Tubes are put on ice for 15 min to complete the lysis. & INCUBATE: [[Container: tubes], [Time: 15 min], [Temperature: on ice]] -> \\ \hline Crude extracts are then centrifuged. & CINRIFUGE: [[Force: \#<2500 RPMw>], [Time: \#<5 min>]] -> \\ \hline Supernatants are transferred to fresh centrifuge tubes. & TRANSFER: [[Container: fresh centrifuge tubes]] -> \\ \hline Cold5 M NaClis added to each sample to make a salt concentration of between 0.7 - 1.0 M to disrupt protein-protein interactions. & ADD: [[Container: each sample], [Reagent: 5 M NaCl, [Concentration: 0.7 - 1.0 M]] -> sample with NaCl \\ \hline Spin the crude extracts by ultracentrifugation to properly pellet residual insoluble proteins from the extract. & SPIN: [[Device: ultracentrifugation], [Force: \#<55000 RPMw>], [Reagent: residual insoluble proteins]] -> \\ \hline Transfer supernatants into fresh centrifuge tubes. & TRANSFER: [[Reagent: supernatants], [Container: fresh centrifuge tubes]] -> \\ \hline Rinse Protein A beads in Hypotonic Buffer until ready for use. & RINSE: [[Reagent: Hypotonic Buffer]] -> use \\ \hline Take a volume of cell lysates (prepared as described above). & TAKE: [[Volume: cell lysates]] -> \\ \hline Dilute with Hypotonic Buffer to 250 – 500 mM salt to enable protein-protein interactions. & DIMUTE: [[Reagent: Hypotonic Buffer]] -> antibody \\ \hline Add 2 ug of preclearing antibody to the diluted lysate (e.g., anti), vortex, add 50 uL of Protein A beads. & ADD: [[Reagent: antibody, Protein A beads]] -> polyclonal anti-MEKK1 \\ \hline Add 2 ug of polyclonal anti-MEKK1 to the lysates, add 50 uL of Protein A beads at 4 °C for 1 h. & ADD: [[Reagent: polyclonal anti-MEKK1], [Container: the lysates], [Temperature: 4 °C], [Time: 1 h]] -> \\ \hline Touchspin beads, wash beads with hypotonic buffer (supplemented with NaCl). & WASH: [[Reagent: hypotonic buffer], [Concentration: \#<300 mM*>]] -> \\ \hline In total, 3 – 5 washes of the beads are performed. & WASH: [[Reagent: hypotonic buffer], [Frequency: 3 – 5]] -> \\ \hline Finally, wash once with Hypotonic Buffer. & WASH: [[Reagent: Hypotonic Buffer]] -> \\ \hline Purified MEKK1 may be stored by snap-freezing in liquid nitrogen. & STORE: [[Method: snap-freezing], [Reagent: liquid nitrogen]] -> M \\ \hline Following preparation of MEKK1 immunoprec precipitates (as above), incubate with 7 ug of JNK1(K131M) along with 5 uCi of [y- \({}^{32}\)P]ATP for 30 min. & INCUBATE: [[Reagent: JNKKT(K131M), [y-\({}^{32}\)P]ATP], [Container: \#<Kinase Assay Buffer>>], [Temperature: \#<30 ^C>>], [Time: 30 min]] -> \\ \hline \end{tabular}
\end{table}
Table A5: **Running cases on the semantics level regarding unknown unknowns**

\begin{table}
\begin{tabular}{p{142.3pt}|p{142.3pt}|p{142.3pt}} \hline \hline
**Original Text** & **Execution Level** & **Reagent Flow Graph** \\ \hline \hline \multirow{3}{*}{Replace medium after 12 hours (Day 2).} & REPLACE; [[Output: medium replaced], [Container: medium] -> & in: old medium; out: new medium \\ \cline{1-1} \cline{2-2} Digest mESCs with 0.05 trypsin, prepare for FACS into 96-well plates (Day 10). & DIEGST; [[Output: mESCs], [Reagent] 0.05 trypsin], [Container: 96-well plates]] -> & in: mESCs, 0.05 trypsin; out: digested mESCs (ensure trypsin is neutralized to avoid over-digestion) \\ \cline{1-1} \cline{2-2} Remove single colonies from 96-well plates to 24-well plates. & REMOVE; [[Output: single colonies], [Container: 96-well plates]] -> & in: single colonies; out: single colonies in 24-well plates \\ \cline{1-1} \cline{2-2} Confirm positive colonies by transient transfection of sgRNAs analysis (SPH primers) (Day 14-15). & CONFIRIM; [[Output: positive colonies], [ Reagent: SPR primers]] -> & in: single colonies; SPH primers; out: positive colonies \\ \cline{1-1} \cline{2-2} Sort single cells into 96-well plates by FACS. & SORT; [[Output: single cells], [Device: FACS], [Container: 96-well plates]] -> & in: single cells; out: sorted single cells in 96-well plates (ensure proper calibration of FACS to avoid sorting errors) \\ \cline{1-1} \cline{2-2} Confirm insertion by PCR (Day 18). & CONFIRIM; [[Output: insertion confirmed]] -> & in: single cells; out: confirmed insertion \\ \cline{1-1} Confirm positive colonies by PCR (Day 22). & CONFIRIM; [[Output: positive colonies]] -> & in: single colonies; out: positive colonies \\ \cline{1-1} \cline{2-2} Measure fluorescent intensity of colonies by FACS, take fluorescence images under confocal microscope (Day 27). & TAKE; [[Output: fluorescence images], [Device: confocal microscope], [Container: colonies]] -> & in: colonies; out: fluorescence images (handle samples to avoid photobleaching) \\ \hline \hline \end{tabular}
\end{table}
Table 6: **Running cases on the execution level regarding capacity of resources**

\begin{table}
\begin{tabular}{p{142.3pt}|p{142.3pt}|p{142.3pt}} \hline \hline
**Original Text** & **Execution Level** & **Reagent Flow Graph** \\ \hline \hline \multirow{3}{*}{Preparae annealing solution} & PREPARE; [[Output: annealing solution], [Concentration: 50 uM RNA/DNA oligos, NaCl in DNase/RNase-free water], [Volume: 50 u1], [Container: PCR tube] -> & in: DNase/RNase-free water (50 u1), RNA/DNA oligos (50 uM), NaCl (50 mM); out: annealing solution (50 u1) \\ \cline{1-1} \cline{2-2} Dissolve inhibitor compound in DMSO to 10 mM, if needed, prepare serial dilutions in Milli-Q water. & DISSOLEV; [[Output: inhibitor compound, DMSO; solution], [Reagent: inhibitor compound, DMSO]] -> & in: inhibitor compound, DMSO; out: inhibitor compound solution (volume depends on dilution) \\ \cline{1-1} \cline{2-2} Add water (20 u1 in blanks, 10 u1 [Reagent: water], [Container: 96-well plate]] -> & ADD: [[Output: water in wells], [Reagent: water], [Container: 96-well plate]] -> & in: water (20 u1 for blanks, 10 u1 for controls); out: water in 96-well plate (20 u1 in blanks, 10 u1 controls) \\ \cline{1-1} \cline{2-2} Add 80 u1 RT reaction mix (1.25x). & ADD: [[Output: RT reaction mix in wells], [Volume: 80 u1]] -> & in: RT reaction mix (80 u); out: RT reaction mix in 96-well plate (80 u) \\ \cline{1-1} \cline{2-2} Add 10 ul inhibitor dlution to samples, to each well. & ADD: [[Output: samples with inhibitor], [Volume: 10 u1], [Reagent: inhibitor dilution] -> & in: inhibitor dilution (10 u1); out: samples with inhibitor (10 u1) \\ \cline{1-1} \cline{2-2} Stop reaction with 50 u1 EDTA (0.5 M, pH 8.0). & STOP: [[Output: stopped reaction], [Reagent: EDTA], [Volume: 50 u1]] -> & in: EDTA (50 u1); out: stopped reaction with EDTA (50 u1) \\ \cline{1-1} \cline{2-2} Quantity reaction with Victor 3 at 409/528 nm, report inhibitor values as percentage of control. & QUANTIFY: [[Output: quantified reaction], [Device: Victor 3]] -> & in: reaction; out: quantified reaction at 490/528 nm \\ \cline{1-1} \cline{2-2} Subtract blank value from samples. & SUBRTACT; [[Output: corrected samples], [Reagent: blank value]] -> & in: blank value, samples; out: corrected sample values \\ \cline{1-1} \cline{2-2} Calculate IC50 value as the concentration reporting 50 reduction of signal compared to control. & CALCULATE; [[Output: IC50 value], [Reagent: signal]] -> & in: signal; out: IC50 value \\ \hline \hline \end{tabular}
\end{table}
Table 7: **Running cases on the execution level regarding safety of operations**

### Types of errors made by our translator

We present a detailed analysis of the errors made by our proposed automatic translator compared to human experts. We discuss the potential improvements of the translator accordingly.

Distinctions on the syntax levelDifference between the translation results of our system and those of experts is subtle, with the biggest difference being in the analysis of long sentences in natural language. For human experts, it is natural and easy to analyze the parameters of events/actions or multiple actions in long sentences, while for our approach, there are sometimes problems with the correspondence between action and parameter, which need to be improved in future work.

This series of examples in Tab. A8 demonstrates the superior performance of our system at the syntax level when processing relatively short sentences.

This series of examples in Tab. A9 illustrates the challenges faced with longer sentences due to the diversity of actions and the multiple parameters.

\begin{table}
\begin{tabular}{l|l|l} \hline \hline
**Original Text** & **Syntax Level** & **Remarks** \\ \hline Transfer 200 ul of serum into a 1.5 & TRANSFER: [[Output: buffer], [Reagent: serum], [Container: a 1.5 m1 microfuge tube], [Volume: 200 ul]] -\textgreater{} \\ \hline Add 200 ul of buffer XBP & ADD: [[Output: the sample/XBP mixture], [Reagent: buffer], [Volume: 200 ul]] -\textgreater{} \\ \hline Add the sample/XBP mixture onto the exoEasy spin column. & ADD: [[Output: 1], [Reagent: the sample/XBP mixture] -\textgreater{} \\ \hline Add 10 ml of buffer XWP to the exoEasy spin column. & ADD: [[Output: 1], [Reagent: Buffer [Volume: 10 ml]]] -\textgreater{} \\ Transfer the spin column to a fresh collection tube. & TRANSFER: [[Output: Qiazol], [Container: a fresh collection tube]] -\textgreater{} \\ \hline Add 700 ul Qiazol to the membrane of the spin column. & ADD: [[Output: 1], [Reagent: Qiazoll], [Volume: 700 ul]] -\textgreater{} \\ Transfer the flow-through, which is the lysate, to a PLG tube. & TRANSFER: [[Output: flow-through], [Container: PLG tube]] -\textgreater{} \\ Inchuate at room temperature for 5 minutes. & INCUBATE: [[Output: 1], [Temperature: room temperature], [Time: 5 minutes]] -\textgreater{} \\ \hline Add 90 ul chloroform. & ADD: [[Output: 1], [Volume: 90 ul]] -\textgreater{} \\ \hline \hline \end{tabular}
\end{table}
Table A8: **Distinctions on the syntax level when processing relatively short sentences**

\begin{table}
\begin{tabular}{l|l||l} \hline \hline
**Original Text** & **Syntax Level** & **Remarks** \\ \hline \multirow{4}{*}{\begin{tabular}{l} Rine MSC with 2 ml PBS. \\ Typsinine with 0.5 ml trypsin. \\ \end{tabular} } & RINSER: [[Output: MSC with 2 ml PBS], [Reagent: PBS], [Volume: 2 ml]] -\textgreater{} \\  & RINSER: [[Output: 1], [Reagent: \\  & trypsin: [Volume: 0.5 ml]] -\textgreater{} \\ Transfer to 15 ml tube. & TRANSFER: [[Output: 1], [Container: 15 \\  & ml tube]] -\textgreater{} \\ Add 10 ml DMEM with 10 FBS. & ADD: [[Output: 1], [Reagent: DMEM, [FPS], [Volume: 10 ml]]] -\textgreater{} \\ Inchuate overnight at 37 °C, 5 CO2. & INDATTER: [[Output: 1], [Temperature: ] & Lack of parameter \\ Wash cells twice with 2 ml PBS, add osteogenic differentiation medium. & KASH: [[Output: 1], [Volume: 2 ml PBS], [Reagent: osteogenic differentiation [reaction]]] -\textgreater{} \\ Change medium every 2 days for 10 days. & CNANOER: [[Output: Alizarind red], [Time: every 2 days for 10 days]] -\textgreater{} \\ \hline \hline \end{tabular} 
\begin{tabular}{l} A day 10, stain with Alizarind red \\ S for 5 min. \\ \end{tabular} } & STMIN: [[Output: 1], [Reagent: XAlizarin [Time: 5 min]] -\textgreater{} \\ \hline \hline \end{tabular}
\end{table}
Table A9: **Distinctions on the syntax level when processing longer sentences**Distinctions on the semantics levelWhen supplementing known unknowns, human experts tend to rely on contextual reasoning. Since experts are not familiar with protocols from all fields, they often infer parameters based on context for protocols outside their expertise. The primary source of their errors is a lack of understanding of protocols in specific domains, which is fundamentally consistent with the approach of our system. When supplementing unknown unknowns, human experts tend to transfer their knowledge from familiar domains, such as instruments used or common parameters, to protocols in various fields, using this as a basis for parameter supplementation. Our system, however, completes parameters based on all collected protocols, which is essentially the opposite of the transfer process used by human experts.

The example presents as follows -- the completion of two types of parameters at the semantic level is included: for instance, determining the configuration parameter for an operation, where human experts rely on personal experimental experience; and inferring the required reagents for one step, where human experts use contextual reasoning. When the context is not sufficiently clear, human experts cannot infer the known unknowns within a single sentence.

\begin{table}
\begin{tabular}{l|l|l} \hline \hline
**Original Text** & **Machine Result** & **Remarks** \\ \hline Add 700 ul of buffer RWT to the RNeasy MiniElute spin column. & ADD: [[Output: ], [Reagent: *buffer & known unknown \\ Discard the flow-through. & RDT3P: [Volume: 700 ul]] -> & DISCARD: [[Output: the flow-through], [Volume: ]] -> \\ Discard the collection tube with the flow-through. & DISCARD: [[Output: the flow-through], [Container: the collection tube], [Volume: ], [Reagent: the flow-through]] -> & DISCARD: [[Output: ], [Device: RNeasy & known unknown \\ Transrier the RNeasy spin column into a new 2 ml collection tube (supplied). & MRAN: [[Output: ], [Container: *cspin & known unknown \\ Open the lid of the spin column. & OCPAN: [[Output: ], [Container: *cspin & known unknown \\ Centrifuge at full speed (14,000 c))] -> & CENTRIFIC: [[Output: ], [Speed: & unknown unknown \\ xg) to dry the membrane. & FOIN: [[At: *cspin]] -> & membrane1, [Time: *cspin]] -> & LDSCARD: [[Output: the flow-through], [Container: the collection tube], [Volume: ], [Reagent: the flow-through]] -> & \\ Transfer the RNeasy MinElute spin column into a new 1.5 ml collection tube. & TRANSFER: [[Output: RNase-free & \\ Add 14 ul RNase-free water directly to the center of the spin column membrane. & & \\ \hline \hline \end{tabular}
\end{table}
Table A10: **Machine results on the semantics level**
\begin{table}
\begin{tabular}{p{142.3pt}|p{142.3pt}|p{142.3pt}|p{142.3pt}} \hline \hline
**Original Text** & **Human Study Result** & **Remarks** \\ \hline Add 700 ul of buffer RWT to the RNeasy MinElute spin column. & ADD: [[Output: ], [Reagent: *<NONE>>], [Volume: 700 ul]] -> & known unknown \\ Discard the flow-through. & DISCARD: [[Output: the flow-through], [Volume: ]] -> & [Volume: ]] -> \\ Discard the collection tube with the flow-through. & DISCARD: [[Output: the flow-through], [Container: the collection tube], [Volume: ], [Reagent: the flow-through]] -> & DISCARD: [[Output: the flow-through], [Container: the collection tube], [Volume: ], [Reagent: the flow-through]] -> & DISCARD: [[Output: ], [Reagent: the flow-through]] -> & known unknown \\ \hline Transfer the RNeasy MinElute spin column into a new 2 ml collection tube (supplied). & TRANSFER: [[Output: ], [Device: RNeasy MinElute], [Container: a new 2 ml collection tube (supplied)), [Volume: ]] -> & TRANSFER: [[Output: ], [Container: *<spin columns>]] -> & **unknown unknown** \\ \hline  & & & \\ \end{tabular}
\end{table}
Table 11: **Human results on the semantics level**Distinctions on the execution levelHuman experts track capacity primarily based on prior knowledge, subsequently using context to judge the appropriateness of the equipment used. In contrast, the machine extracts the entire flow process, enabling it to calculate each step and ensure that the capacity tracking is scientifically sound and reasonable.

This series of examples in Tab. A12 demonstrates how our system tracks the required capacities at each step of the protocol by contextualizing the step into the spatial dimension.

This series of examples in Tab. A13 illustrates how our system tracks the preconditions and postconditions at each step of the protocol by contextualizing the step into the temporal dimension.

### Properties of the pre-processing pipeline

Significant differences exist between various stages of the pre-processing pipeline. We present several real-world examples to illustrate these distinctions in Tab. A14.

\begin{table}
\begin{tabular}{p{56.9pt}|p{56.9pt}|p{56.9pt}|p{56.9pt}|p{56.9pt}|p{56.9pt}} \hline \hline
**Original Text** & **Action Extraction** & **Entity Extraction** & **Classification with LLM** & **Preprocess Result** & **LLM-Pure** \\ \hline Stain with DAPI nucleic acid stain for 30 seconds. & stain & [Reagent: DAPI nucleic acid & [Reagent: DAPI nucleic acid & [Output: & [Iparation: \\  & & nucleic & stain], [Time: & ], [Reagent: & 30 seconds], \\  & & acid & 30 seconds] & DAPI nucleic acid & [Reagent: DAPI \\  & & [Time: 30 seconds] & [Time: 30 seconds] & [Time: 30 seconds] & \\  & & seconds] & & & \\ \hline
**Parify CD4+ by magnetic isolation using the Auto MACS sorter (Miltevi Biotec) using POSSEID2 program.** & [Reagent: CD4+], [Device: the Auto MACS sorter (Miltevi Biotec), & [Iparative: \\  & & & the Auto MACS sorter (Miltevi Biotec), & [Iparative: \\  & & & & the Auto MACS sorter (Miltevi Biotec), \\  & & sorter & [Device: & [Micro], \\  & & & & \\  & & (Miltevi), & [ProgsSEID2 program] & [Micro], \\  & & & & \\  & & & & & \\  & & & & \\  & & & & & \\  & & & & & \\  & & & & & \\  & & & & & \\ \hline Measure baseline oxidative status and early 20 s for at least 5 min, then add stimulating absignignign). & [Output: baseline & [Output: oxidative & MEASU: \\  & & & baseline & [Output: \\  & & & oxidative & baseline & baseline \\  & & & status], & [Time: \\  & & & every 20 s], & status], & status], \\  & & & every 20 s], & [Time: s min], & [Time: every \\  & & & [Reagent: \\  & & & stimulating & 20 s, 5 min]], & \\  & & & substances] & [Iparative: \\  & & & stimulating & \\  & & & substances] & \\ \hline Spin the crude extracts by ultracententification at 55000 RPM to properly pellet residual insoluble proteins from the extract. & [Device: ultracententification [Force: & [Force: 55000 RPM], [Reagent: & centrifugation], \\  & & & residual & [Force: 55000 RPM], & [Output: \\  & & & residual & [Force: 55000 RPM], & [Purpose: \\  & & & insoluble & RPM], [Output: \\  & & residual & & ], [Reagent: \\  & & insoluble & [Contaneir: \\  & & & & residual \\  & & & & \\  & & & & \\  & & & & \\  & & & & \\  & & & & \\ \hline Confirm positive cloning by transient soft RNAs analysis (SPH primers). & confirm & [Output: positive colonies], & [Output: \\  & & & colonies], & positive & primarys], \\  & & & [Reagent: \\  & & & sgRNAs analysis & [Reagent: \\  & & & analysis & (SPH primers)] & \\  & & & analysis & \\  & & & & \\ \hline \hline \end{tabular}
\end{table}
Table A14: **Showcases of action extraction, entity extraction, and classification in protocol steps**Reproducibility

The project page with supplementary files for reproducing the results of this paper will be available at https://autodsl.org/procedure/papers/neurips24shi.html.

## Appendix G Limitations

As a systematic study with a proof-of-concept framework, the design and evaluation of the pipeline come with limitations, leading to further investigations:

* We majorly exploit the approaches of empirical study to observe the behavior of DSLs and human experts for extracting design principles. Can we draw theories from information theory to rigorously prove the expression capacity of DSLs and other structural knowledge representations, to advance our design choice?
* We majorly consider the imperative programming DSLs as the vehicle of PDGs in this work. This raises the question of whether incorporating alternative programming paradigms, such as functional and object-oriented models, could enhance the representation of complex entities within protocols, particularly the properties of reagents.
* Can we extend the protocol translator to a larger set of experiments, especially those with heterogeneous hardware devices such as mobile robots?
* Can we find similar mechanism in other critical domains with the requirements on protocol execution, such as advanced manufacturing, and generalize our translator for such applications?

With many questions unanswered, we hope to explore more on automated protocol translation for self-driving laboratories and beyond.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: In this paper, we systematically study the problem of translating protocols for human experimenters into those suitable for self-driving laboratories, in order to standardize and automate the translation process. Further, we propose the initial proof-of-concept framework that fully frees domain experts from hand-crafting protocol translators. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: We have discussed the potential limitations at Appx. G. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof?Answer: [NA] Justification: No theoretical result is included in this paper. Guidelines:

* The answer NA means that the paper does not include theoretical results.
* All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
* All assumptions should be clearly stated or referenced in the statement of any theorems.
* The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.
* Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.
* Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: We have provided them with the implementation details at Appx. C. We will also release our codes upon acceptance. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code**Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [No] Justification: We have provided them with the implementation details Appx. C. We will also release our codes upon acceptance. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: All of them are carefully illustrated in implementation details Appx. C. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: Yes. Please refer to Fig. 3. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).

* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: Please refer to Appx. C.3. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: Yes. Please refer to the main text. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: Please refer to the general discussions at Sec. 5. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.

* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: The paper poses no such risks. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licensees for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: Yes. Their licenses are checked and their published works are properly cited. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.

* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? [NA] Justification: The paper does not release new assets. Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [Yes] Justification: Please refer to Appx. B and Appx. D. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [Yes] Justification: We have obtained an approved IRB in advance. Please refer to Appx. B. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.