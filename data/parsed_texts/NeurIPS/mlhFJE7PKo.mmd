# HEST-1k: A Dataset for Spatial Transcriptomics and Histology Image Analysis

 Guillaume Jaume\({}^{1,2,}\)1  Paul Doucet\({}^{1,3,}\)1  Andrew H. Song\({}^{1,2}\)  Ming Y. Lu\({}^{1,2,4}\)

Cristina Almagro-Perez\({}^{1,2}\)  Sophia J. Wagner\({}^{1,6,7}\)  Anurag J. Vaidya\({}^{1,2,5}\)

Richard J. Chen\({}^{1,2}\)  Drew F.K. Williamson\({}^{8}\)  Ahrong Kim\({}^{1,9}\)  Faisal Mahmood\({}^{1,2}\)

\({}^{1}\)Mass General Brigham, Boston, USA \({}^{2}\)Harvard Medical School, Boston, USA \({}^{3}\)ETH Zurich, Switzerland \({}^{4}\)EECS MIT, Cambridge, USA \({}^{5}\)HST MIT, Cambridge, USA \({}^{6}\)TUM, Munich, Germany \({}^{7}\)Helmholtz Munich, Munich, Germany \({}^{8}\)Emory School of Medicine, Atlanta, USA \({}^{9}\)Pusan National University, South Korea gjaume@bwh.harvard.edu  faisalmahmood@bwh.harvard.edu

Equal contribution

Footnote 1: footnotemark:

###### Abstract

Spatial transcriptomics enables interrogating the molecular composition of tissue with ever-increasing resolution and sensitivity. However, costs, rapidly evolving technology, and lack of standards have constrained computational methods in ST to narrow tasks and small cohorts. In addition, the underlying tissue morphology, as reflected by H&E-stained whole slide images (WSIs), encodes rich information often overlooked in ST studies. Here, we introduce HEST-1k, a collection of 1,229 spatial transcriptomic profiles, each linked to a WSI and extensive metadata. HEST-1k was assembled from 153 public and internal cohorts encompassing 26 organs, two species (_Homo Sapiens_ and _Mus Musculus_), and 367 cancer samples from 25 cancer types. HEST-1k processing enabled the identification of 2.1 million expression-morphology pairs and over 76 million nuclei. To support its development, we additionally introduce the HEST-Library, a Python package designed to perform a range of actions with HEST samples. We test HEST-1k and Library on three use cases: (1) benchmarking foundation models for pathology (HEST-Benchmark), (2) biomarker exploration, and (3) multimodal representation learning. HEST-1k, HEST-Library, and HEST-Benchmark can be freely accessed at https://github.com/mahmoodlab/hest.

## 1 Introduction

Advances in molecular profiling enable spatially-resolved gene expression analysis with increasingly large gene panels, enhanced spatial resolution, and greater sensitivity [9, 122]. From the early days of bulk RNA sequencing constrained by its coarse resolution and limited gene panels, spatially-resolved technologies have progressed to achieve whole-transcriptome sequencing at sub-cellular resolution [81]. In cancer research, spatial transcriptomics (ST) holds particular promise for characterizing the tumor microenvironment, a key element in understanding disease progression and treatment response [133, 97, 140, 151]. With the large amount of transcriptomics data generated by a single ST sample (e.g., \(>\)10 million transcripts are detected in a typical 10x Genomics Xenium assay), computational methods are often used to uncover promising biomarkers, such as employing clustering methods for cell phenotyping [122].

However, high costs and rapidly evolving technology have constrained computational methods to narrow tasks and data cohorts of only a few patients [103, 63, 135]. Consequently, we observe a lackof standardized resources and unified formats for handling ST, which limits the development of deep learning models on a large scale [109]. In addition, the underlying tissue morphology, traditionally visualized in hematoxylin and eosin (H&E)-stained tissue sections (whole-slide images, WSIs), is often overlooked in ST studies, despite encoding valuable information. In particular, pairs of ST and WSI enable analyzing expression changes in their morphological context, which may facilitate the identification of morphological biomarkers (e.g., changes in nuclear shape) that correspond to gene regulation patterns. Alternatively, pairs of ST and WSI can enable multimodal tissue representation learning for joint modeling of the morphomolecular signature of tissue at a scale and resolution beyond bulk RNA sequencing [28]. Finally, the development of "foundation models" for encoding histopathology images [147; 42; 29; 59; 88] has increased the need for new, diverse, and challenging benchmarks beyond diagnostic tasks. Using ST, new tasks can be defined to predict gene expression changes from histology.

Here, we introduce HEST-1k, a collection of paired ST and H&E-stained WSIs curated from public and internal cohorts (Figure 1.a). HEST-1k comprises 1,229 samples from 153 cohorts encompassing 26 organs, two species (_Homo Sapiens_ and _Mus Musculus_), and 367 cancer samples from 25 different subtypes. Processing all samples in HEST-1k resulted in 2.1 million expression-morphology pairs and 76 million detected nuclei. With new cohorts frequently made public, we also introduce the HEST-Library, a Python package for interacting with HEST-1k data and assembling new samples as they become available (Figure 1.b). We highlight the potential of HEST-1k through three use cases: (i) benchmarking foundation models for histology using the HEST-Benchmark, a set of nine tasks (eight human cancer types and nine organs) for gene expression prediction from histology and evaluated on eleven state-of-the-art models (Figure 1.c), (ii) a proof-of-concept demonstrating the use of HEST-1k for biomarker characterization (Figure 1.d), and (iii) a proof-of-concept for expression-guided fine-tuning of foundation models for histology (Figure 1.e).

Figure 1: **The HEST environment.****a.** Overview of HEST-1k, a dataset of \(n\)=1,229 paired spatial transcriptomics, H&E-stained whole-slide images and metadata. “Pathological” cases refer to non-tumor/non-cancer samples; “Tumor” refers to non-cancer samples. **b.** Overview of HEST-Library functionalities. **c., d., e.** Applications of HEST-1k include benchmarking foundation models for histology (**c.**), biomarker exploration (**d.**) and multimodal representation learning (**e.**).

Related work

**Libraries for ST analysis.** Libraries to process, visualize, and analyze ST have been built around two core pipelines: _Scanpy_[149] (and the Anndata format) in Python and _Seurat_[24] in R. _Scanpy_ has served as the foundation for several subsequent developments such as _Squidpy_[115] for spatial data exploration at cellular-, gene-, and morphological-level, _SpatialData_[95] for multi-technology integration and deep learning interfacing, _STlearn_[119] for cell-cell interactions and spatiotemporal trajectory analyses, and SOPA [21] for designing multistep pipelines. In R, _Seurat_[24] has been consolidated with packages such as _BayeSpace_[159] for clustering and spot super-resolution, and _Giotto suites_[26] for preprocessing, data integration and visualization of multiple ST technologies. 10x Genomics also includes proprietary software analytics through the Xenium and Visium Explorer pipelines for multimodal visualization, nuclear segmentation, and cell deconvolution. However, none of these pipelines were designed to handle the diversity of legacy data, where datasets can suffer from missing or incorrect data, such as alignment mismatches, incorrect pixel resolution, inconsistent image file formats, etc.

**Molecular profile prediction from H&E.** Molecular profiling from histology images has been explored both at (1) _slide-level_ to predict bulk molecular status/changes from a WSI and at (2) _patch-level_ to predict local molecular status/changes from regions-of-interest. (1) Slide-level profiling has been explored to predict the gene mutations [125, 143, 72, 38, 45, 145, 86], microsatellite instability [143, 71], and gene expression changes [127, 39, 55, 3], among others. The motivation is two-fold: First, patient screening to substitute or complement costly clinical molecular assays, and second, to identify morphological correlates of molecular alterations for discovering novel biomarkers. Such studies can be conducted on large patient cohorts as they mainly rely on data generated by the routine clinical workflow (e.g., using TCGA cohorts with >11,000 cases from 33 cancer types). (2) With ST, several works have explored predicting expression changes from regions-of-interest [55, 152, 116, 160, 121, 108, 107, 32, 144]. Due to limited cohort sizes (typically one to ten patients), transfer learning has become the norm using pretrained models based on ConvNets [55] or Vision Transformers [152, 116]. Due to the inherent noise found in transcriptomic measurements, several methods have been developed for integrating context that can account for global and local information from surrounding ST spots [58, 32, 160, 144]. While recent technologies offer near-single-cell resolution (such as Visium HD and Xenium), legacy assays operate at a more coarse resolution, which can be upsampled using super-resolution techniques [159, 20, 157]. The potential clinical and research implications of such methods are still being explored, with HEST-1k potentially catalyzing their large-scale development.

**Foundation models in pathology.** A fundamental task in computational pathology is to extract _general-purpose_ embeddings of image patches (typically 256\(\times\)256 to 512\(\times\)512-pixel regions) that can then be used for downstream tasks, such as diagnosis or prognosis prediction. To achieve this, self-supervised learning (SSL) has been extensively applied [75, 42, 142, 147, 68, 33, 146, 11, 29, 88, 65, 64], such as based on the DINOv2 framework [112]. General-purpose patch encoders are trained on increasingly large and diverse patient cohorts (e.g., UNI [29] uses a ViT-Large trained on 100k WSIs, Virchow [142] uses a ViT-Huge trained on more than 1.5M WSIs). Recently, vision-language encoders designed for pathology have also been proposed [46, 92, 59, 88, 87] and rely on large-scale paired data scraped from social media, textbooks, or publications. As the number of such models rapidly increases, new, diverse, and challenging benchmarks are needed to replace or complement well-established tasks where performance has saturated. HEST-Benchmark aims to address this by offering a set of nine patch-level tasks for gene expression prediction from histology.

**Patch-level benchmarks in histopathology.** Early task and dataset contributions in computational pathology revolved around classifying small regions of interest. Over the years, a variety of benchmarks have been established: In prostate cancer, Gleason grading at pixel- and patch-level has been widely explored, with public resources such as AGGC [60], DiagSet [77], and SICAPv2 [129]. In colorectal cancer, datasets have been proposed for tissue classification, such as HunCRC [118], UniToPatho [15], MHIST [148], and CRC-100k [73]. In breast cancer, morphological subtyping has been vastly explored (e.g., for atypical ductal hyperplasia detection), such as BACH [8], BRACS [22], and BreakHis [131], and for lymph node metastasis detection with Patch CAMELYON (pCAM) [137], respectively. However, the performance on many of these datasets has saturated; for instance, Gleason scoring reaches similar or better performance than pathologists [23], which limits objective comparisons of new methods and hinders well-informed model selection for developing better features.

Instead, HEST-Benchmark provides a collection of diverse and challenging tasks that enable assessing the predictive capabilities of foundation models for histology.

## 3 HEST-1k Dataset

We present HEST-1k, a dataset of paired ST, H&E-stained WSIs, and metadata (Figure 1.a). To this end, we extracted all publicly available cohorts that provide ST with H&E-stained whole-slide images. Specifically, we harvested data from 10x Genomics public datasets (TENX)1, Mendeley (MEND)2, Spatial-Research (SPA)3, Zenodo (ZEN)4, the National Center for Biotechnology Information (NCBI)5, GitHub6, the Human Cell Atlas7, BioStudies8, HTAN9, and internal data cohorts. A summary of all sources is provided in Appendix Table A1 with specifics in Appendix Table A2, A4, A6,A7,A8,A9, and A10.

Footnote 1: https://www.10xgenomics.com/datasets 2 https://data.mendeley.com/ 3 https://www.spatialresearch.org/ 4 https://zenodo.org/ 5 https://www.ncbi.nlm.nih.gov/gds/ 6 https://github.com/ 6.47,A8,A9, and A10.

Footnote 3: https://data.humancellatlas.org/ 8 https://www.ebi.ac.uk/biostudies/ 9 https://humantumortalas.org/ 10 https://oncotree.mskcc.org

### Metadata

As spatial transcriptomics experiments were not intended for large-scale computational research, they are provided in various formats (e.g., images can be in JPG or TIFF format, with or without cross-modal alignment files) and resolutions. We unified all data with comprehensive metadata with _generic-_, _histology-_, and _expression-_related descriptors for all samples. **Generic:** We provide the reference to the original publication, download link, year of publication, license, and sample species. Each sample is then categorized as either healthy, cancer, tumor (non-cancer), treated (which refers to a post-compound administration), genetically modified (mostly knock-out mouse samples), or pathological (i.e., non-tumorous with extra specification). All cancer samples were unified using the OncoTree code, a taxonomy of cancer types provided by the Memorial Sloan Kettering Cancer Center10. Finally, we provide the organ using the highest level of the OncoTree taxonomy as a reference. **Expression:** We report the number of genes and spots per sample, the spot resolution and spacing, the total number of reads, and the mean number of reads per spot. We additionally provide the transcriptomic technology (ST, Visum, Visium HD, or Xenium). **Histology:** We provide the image resolution (in \(\mu\)m/pixel) and magnification as 10\(\times\) (1.15 to 0.8 \(\mu\)m/px), 20\(\times\) (0.8 to 0.4 \(\mu\)m/px) and 40\(\times\) (0.4 to 0.1 \(\mu\)m/px). All images with a pixel size higher than 1.15 \(\mu\)m/px were discarded to ensure an acceptable image quality. In addition, we provide the image size at the highest resolution and the tissue preparation protocol (frozen or formalin-fixed paraffin-embedded, FFPE).

Footnote 1: https://www.10xgenomics.com/datasets 2 https://data.mendeley.com/ 3 https://www.spatialresearch.org/ 4. https://zenodo.org/ 5 https://www.ncbi.nlm.nih.gov/gds/ 6 https://github.com/ 7. https://data.humancellatlas.org/ 8 https://www.ebi.ac.uk/biostudies/ 9. https://humantumortalas.org/ 10. https://oncotree.mskcc.org

### Histology

All tissue sections were normalized and transformed into a generic TIFF object, a pyramidal image that can easily be integrated into computational frameworks using Openslide or viewers such as QuPath[14]. In addition, we provide a contour object that delineates all the tissue regions identified in the image. We developed a robust tissue _vs._ background detection method where we fine-tuned a DeepLabV3 [27] model with an ImageNet-pretrained ResNet50 backbone on a set of annotated segmentation regions (including pen marks, fiducials, multiple stains, artifacts, etc.). From the tissue segmentation, we extracted 224\(\times\)224-pixel patches at 20\(\times\) magnification around each spot. For Xenium samples, we generated "pseudo-Visium" spots by pooling transcripts on 55 \(\times\) 55-\(\mu\)m patches without spacing. This yielded 2.1 million valid patches for which a corresponding expression profile was derived. Such patching can readily be used for various downstream tasks, such as employed in the **HEST-Benchmark** or multimodal fine-tuning of foundation models for histology (Section 5 and 7).

### Nuclear segmentation and classification

In addition to patching, we include nuclear segmentation that delineates each nucleus identified in all slides from HEST-1k. We used CellViT [61], a state-of-the-art nuclear segmentation model that was trained on the PanNuke dataset [47, 48]. CellViT enables joint instance segmentation and classification of each nucleus into five classes: neoplastic epithelial, non-neoplastic epithelial, inflammatory, stromal, and necrotic. On average, we identified 62.1k nuclei per slide, for a total of 76.4 million nuclei identified across all samples. Among those, 17.6 million are classified as neoplastic, 21.5 million as stromal, 4.9 million as normal epithelial, 15.4 million as inflammatory, and 76 thousand as necrotic. The resulting nuclear segmentation and classification can easily be visualized using QuPath (using geoyion) or loaded as Python/R objects (using JSON). For all Xenium samples, we additionally provide the nuclear and cell segmentation derived from the DAPI staining finely aligned with the H&E slide.

### Gene expression

All expression data were unified in a Anndata object that can be loaded with _scampy_. Anndata encodes the gene names (as _var_) and number of spots (as _obs_). Each entry represents the raw transcript counts of a gene in a given spot. No additional normalization was conducted, and we let users explore various normalization strategies based on needs, e.g., using total count normalization, log-normalization, etc. In addition, we include metadata to specify the number of genes, the gene panel, and the tissue site. For all Xenium samples, we also provide the list of all measured transcripts with their exact 2D position in the tissue (aligned with the H&E slide).

To use the expression in tandem with the WSI, an alignment file describing the mapping between the image and the spots is needed. However, relying on publicly available alignment information brings three challenges: (1) most datasets report alignment with respect to a low-resolution version of the image, (2) they are not standardized, and (3) alignment quality can be low. To address these limitations, we re-aligned all samples under the same unified format between the WSI and the corresponding expression profile. For all Visium samples, we developed an automatic alignment pipeline based on fiducial detection (see Section 4) and embedded the alignment in the _scampy_ object. For all Xenium samples, we used the publicly available VALIS [50] pipeline for fine-grained image registration to align the DAPI image (aligned with the transcripts by design) and the H&E slide.

## 4 HEST-Library

The HEST-Library is built around _scampy_ and Anndata. At its core, the HEST-Library enables (1) assembling and querying HEST-1k, (2) visualizing and mitigating batch effects, and (3) running the HEST-Benchmark (Section 5). We describe its core functionalities, particularly for unifying legacy data.

**Conversion to generic TIFF.** We integrate functions to convert a WSI from common formats found in public ST datasets (e.g., OME.TIF, JPG, BigTIFF, etc.) to a pyramidal generic TIFF format. Pyramidal formats offer seamless integration with OpenSlide (commonly used in computational pathology pipelines) and QuPath (open-access software for WSI visualization and annotation).

**Automatic alignment in Visium.** Spot alignment is crucial to ensure an accurate match between the ST spots and the WSI. While software such as LoupeBrowser enables manual alignment using fiducials (i.e., reference markers placed at the corners of the capture area), the process remains time-consuming when processing large batches of samples. Instead, we implemented an automatic fiducial detection algorithm based on YOLOv8 [123] for processing Visium samples (Appendix Figure 5). Specifically, we manually annotated 119 fiducial regions that we further augmented using tissue and fiducial mixing. We then fine-tuned YOLOv8 pretrained on the COCO dataset. In early versions that do not provide corner fiducials (e.g., STv1), we realigned using the provided spot position files. In Xenium, we use VALIS [50] to register the DAPI staining (aligned with the transcripts) with the H&E image.

**Automatic detection of image resolution.** From the alignment and the spot resolution, we can infer the exact pixel size. To this end, we compute the distance in pixel between two neighboring spots and leverage the known inter-spot distance in \(\mu\)m to estimate the pixel width in \(\mu\)m/px. For Xenium samples, we use the H&E alignment file provided as part of the assay, which provides an affine transformation from the DAPI-stained image (with known pixel size) to the H&E image. We then compared the self-reported image resolution and our re-estimations to manually inspect and correct discrepancies.

**Conversion to Anndata.** ST data is provided in multiple formats, such as CSV, MEX, TXT, h5, etc. We provide functions to unify a large set of existing formats into a Anndata object that stores the raw transcript counts as a matrix of genes by the number of spots, in addition to metadata about the samples (e.g., the (x,y) coordinates of each spot, the pixel resolution, etc.).

**Tissue segmentation and patching.** We provide a tissue segmentation pipeline optimized for Visium/Xenium images. The segmentation can then automatically tessellate the tissue into fixed-size image patches at a predefined resolution (expressed in \(\mu\)m/px) around each spot.

**Automatic HEST-1k download.** To facilitate downloading part or all of the HEST-1k dataset (over \(>\)1TB), we implemented an easy download option where the user can specify entries of the metadata, for instance, to query all human invasive breast cancer cases.

**Batch effect visualization and mitigation.** We provide functions to help visualize batch effects using dimensionality reduction techniques with user-prompted stratification (e.g., tissue site, institution, disease, etc.). In addition, we provide a wrapper of well-established batch effect mitigation strategies (namely ComBat [158], Harmony [76] and matching mutual nearest neighbors [54]), which can be applied to a list of HEST samples.

## 5 HEST-Benchmark

From HEST-1k, we curated the HEST-Benchmark, a set of nine tasks for gene expression prediction from histology in human cancer samples. The goal is two-fold: (i) benchmarking foundation models for histology under a diverse and challenging benchmark and (ii) understanding the predictive capabilities of state-of-the-art models in predicting expression from morphology. Compared to existing tasks (e.g., Camelyon16 [18]), the HEST-Benchmark brings increased morphological diversity and more complex challenges, particularly with the inherent difficulty of expression prediction.

### Task definition

We define nine tasks with data from eight human cancers and nine organs (eight primary and one metastatic dataset), which include **invasive ductal carcinoma** (breast cancer, IDC, Task 1), **prostate adenocarcinoma** (prostate cancer, PRAD, Task 2), ** pancreatic adenocarcinoma** (pancreatic cancer, PAAD, Task 3), **skin cutaneous melanoma** (skin cancer, SKCM, Task 4), **colonic adenocarcinoma** (colon cancer, COAD, Task 5), **rectal adenocarcinoma** (rectum cancer, READ, Task 6), **clear cell renal cell carcinoma** (kidney cancer, ccRCC, Task 7), **lung adenocarcinoma** (lung cancer, LUAD, Task 8), and **axillary lymph nodes in IDC** (metastatic, LYMPH-IDC, Task 9). Additional information is provided in Appendix Table A11.

For each task, we predict the expression of the top 50 genes with the highest normalized variance across all samples from 112\(\times\)112 \(\mu\)m H&E regions (equivalent to 224\(\times\)224-pixel patches at 20\(\times\)). To avoid train/test patient-level data leakage, we use patient-stratified splits, resulting in a \(k\)-fold cross-validation, where \(k\) is the number of patients. In ccRCC, we use \(k/2\)-fold cross-validation due to the large number of patients.

### Evaluating foundation model for pathology

We use the HEST-Benchmark to evaluate 11 foundation models for pathology. Namely, **ResNet50 (IN) [90]** (ImageNet pretrained), **CTransPath [146]** (adapted MoCov3 pretrained on TCGA and PAIP), **Remedis [11]** (SimCLR [30] pretrained on TCGA), **Phikon [42]** (iBOT pretrained on TCGA), **UNI [29]** (DINov2 ViT-Large pretrained on internal hospital data and GTEx), **CONCH [88]** (visual-language model using CoCa pretrained on captions from publications and educational resources), **GigaPath**[154] (DINov2 ViT-giant pretrained on proprietary data), **Virchow**[142] (DINov2 ViT-Huge pretrained on proprietary data), **H-Optimus-0** (DINov2 ViT-giant pretrained on proprietary data), and **UNIV1.5** (DINov2 ViT-giant pretrained on public and proprietary data). Additional information is provided in Table A12 and Appendix C.3.

We learn a regression model to map model-specific patch embeddings (512 to 2,048 dimensions) to the log1p-normalized expression of the top 50 highly variable genes. All tasks are evaluated using the Pearson correlation between the predicted and measured gene expression. We report mean and standard deviation across all folds (or patients). All experiments were run on a single NVIDIA 3090 GPU. We report performance using three downstream regression models: (i) PCA-reducedembeddings (with n=256 factors) followed by Ridge regression trained with adaptive regularization as shown in Table 1, (ii) Ridge regression model as shown in Appendix Table A13, and (iii) an XGBoost regression model with 100 estimators and a maximum depth of 3 as shown in Appendix Table A14. Our main results are reported using PCA+Ridge (i) and XGBoost (iii). Directly applying Ridge regression may unfairly penalize models with larger embedding dimensions. To guarantee a fairer and more objective comparison, we chose to utilize PCA reduction.

### Scaling laws in HEST-Benchmark

Overall, H-Optimus-0 brings the best average Pearson correlation in both PCA+Ridge and XGBoost evaluation, outperforming the second-best model, UNIV1.5, by 0.56% and 0.69%, respectively. ResNet50 (IN), the only model that was not pretrained on histology images, leads to the lowest performance in both PCA+Ridge and XGBoost. Legacy domain-specific models, such as CTransPath, are outperformed by all recent models, including UNIV1.5, UNI, GigaPath, Virchow, and H-Optimus-0. The disparity between the top and bottom domain-specific models is notable, showing an absolute improvement of 7.0% for PCA+Ridge and 4.8% for XGBoost. When inspecting individual performance, we observe large differences across tasks from 0.6432 Pearson correlation in SKCM to 0.2292 in READ for H-Optimus-0 evaluated using PCA+Ridge.

**Model scaling law.** By inspecting the number of trainable parameters within the vision encoder for each model, we can describe how model size influences performance (measured with average Pearson correlation across all tasks, Figure 2.a). Performance increases with model size following a logarithmic scaling law (Pearson correlation of R=0.81, P-value\(<\)0.01). Models considered "parameter-efficient" are represented on top of the log-transformed linear regression line (e.g., CONCH, UNIV1.5, and H-Optimus-0). This observation suggests a trade-off between downstream performance and model size. Despite the observation of a model scaling law, significant variations in performance among models of identical size persist, such as between H-Optimus-0 and GigaPath, both of which are ViT-giant models with over one billion parameters.

**Data scaling law.** We further explored how the number of training samples used for pretraining each model (i.e., the number of image patches) affects performance. We observe that increasing the number of patches moderately correlates with the average performance (Pearson correlation of R=0.48, P-value=0.13). This correlation is weaker than model size, which we hypothesize is due to this analysis overlooking both the absolute number of WSIs used for pretraining (image patches are not independently and identically distributed per WSI) and disparities of morphological variety among WSIs (e.g., staining variation, disease diversity, artifacts, etc.).

\begin{table}
\begin{tabular}{l l l l l l l l l l l} \hline \hline  & **IDC** & **PRAD** & **PAAD** & **SKCM** & **COAD** & **READ** & **ceRCC** & **LUAD** & **LYMPH IDC** & **Average** \\ \hline
**ResNet50 (IN)** & 0.4741 & 0.3075 & 0.3889 & 0.4822 & 0.2528 & 0.0812 & 0.2231 & 0.4917 & 0.2322 & 0.326 \\
**CTransPath** & 0.5011 & 0.3427 & 0.4378 & 0.5106 & 0.2285 & 0.11 & 0.2279 & 0.4985 & 0.2353 & 0.3447 \\  & \(\pm\)0.0531 & \(\pm\)0.0458 & \(\pm\)0.0664 & \(\pm\)0.0827 & \(\pm\)0.0577 & \(\pm\)0.0064 & \(\pm\)0.0475 & \(\pm\)0.0414 & \(\pm\)0.0477 \\
**Phixon** & 0.5327 & 0.342 & 0.4432 & 0.5355 & 0.2585 & 0.1517 & 0.2423 & 0.5468 & 0.2373 & 0.3656 \\  & \(\pm\)0.0914 & \(\pm\)0.0877 & \(\pm\)0.00884 & \(\pm\)0.0589 & \(\pm\)0.0056 & \(\pm\)0.0022 & \(\pm\)0.063 & \(\pm\)0.0048 & \(\pm\)0.0587 & \\
**CONCH** & 0.5363 & 0.3548 & 0.4475 & 0.5791 & 0.2533 & 0.1674 & 0.2179 & 0.5312 & 0.2507 & 0.3709 \\  & \(\pm\)0.0842 & \(\pm\)0.0099 & \(\pm\)0.0729 & \(\pm\)0.0524 & \(\pm\)0.0057 & \(\pm\)0.0076 & \(\pm\)0.0353 & \(\pm\)0.0017 & \(\pm\)0.002 & \\
**REMDSIs** & 0.529 & 0.3471 & 0.4644 & 0.5818 & 0.2856 & 0.1145 & 0.2647 & 0.5336 & 0.2473 & 0.3742 \\  & \(\pm\)0.069 & \(\pm\)0.0074 & \(\pm\)0.0722 & \(\pm\)0.0421 & \(\pm\)0.02 & \(\pm\)0.0987 & \(\pm\)0.0539 & \(\pm\)0.0326 & \(\pm\)0.0858 & \\
**GigaPath** & 0.5508 & 0.3708 & 0.4768 & 0.5533 & 0.001 & 0.186 & 0.2391 & 0.5399 & 0.2493 & 0.3853 \\  & \(\pm\)0.0726 & \(\pm\)0.041 & \(\pm\)0.0898 & \(\pm\)0.0386 & \(\pm\)0.1453 & \(\pm\)0.0094 & \(\pm\)0.01964 & \(\pm\)0.01969 & \(\pm\)0.0523 & 0.3862 \\
**UNI** & 0.5702 & 0.314 & 0.4764 & 0.6254 & 0.263 & 0.1762 & 0.2427 & 0.5511 & 0.2565 & 0.3862 \\  & \(\pm\)0.0833 & \(\pm\)0.0173 & \(\pm\)0.0887 & \(\pm\)0.0338 & \(\pm\)0.0311 & \(\pm\)0.0685 & \(\pm\)0.0085 & \(\pm\)0.0198 & \(\pm\)0.0048 & \\
**Virchow** & 0.5702 & 0.3309 & 0.4875 & 0.6088 & 0.0831 & 0.2019 & 0.2637 & 0.5459 & 0.2594 & 0.3977 \\  & \(\pm\)0.0939 & \(\pm\)0.0081 & \(\pm\)0.0412 & \(\pm\)0.0733 & \(\pm\)0.0083 & \(\pm\)0.0367 & \(\pm\)0.039 & \(\pm\)0.08262 & \(\pm\)0.043 & \\
**Virchow2** & 0.5922 & 0.3465 & 0.4661 & 0.6174 & 0.2578 & 0.2084 & **0.2788** & **0.5605** & 0.2582 & 0.3984 \\  & \(\pm\)0.0814 & \(\pm\)0.0305 & \(\pm\)0.0766 & \(\pm\)0.0174 & \(\pm\)0.0199 & \(\pm\)0.0502 & \(\pm\)0.0516 & \(\pm\)0.0172 & \(\pmOverall, HEST-Benchmark brings new insights into the performance of foundation models for pathology. We observe that (1) Scaling the model size strongly correlates with average performance, but the gains grow logarithmically with the number of trainable parameters. (2) Scaling the number of training patches weakly correlates with a higher performance (also on a logarithmic scale). (3) Performance remains low for some tasks (e.g., READ and ccRCC), which suggests that (i) the morphology might not be as reflective of gene expression for some cancer types or (ii) some cohorts have more noise than others (e.g., due to batch effects, low sensitivity, dropout events, or spillover between adjacent spots).

## 6 HEST for biomarker exploration

HEST-1k also enables the analysis of interactions and correlations between tissue morphology (as seen in H&E) and local gene expression (as provided in ST). Here, we showcase the capabilities of HEST-1k (1) by studying morphological correlates of expression changes in invasive breast cancer and (2) by visualizing tumor heterogeneity both on the morphological and molecular sides. Specifically, we focus on invasive ductal carcinoma (IDC) samples imaged with Xenium. Using CellViT nuclear segmentation and classification, we identified neoplastic nuclei (exemplified in two samples: Figure 3.a with n=168,033 nuclei and Appendix Figure 6.a with n=342,018 nuclei). We then overlay the WSI with the expression of specific genes, such as _GATA3_, a known prognostic gene in breast cancer [102](Figure 3.b). This qualitatively shows that high _GATA3_ expression is associated with cancerous regions and reveals heterogeneity within invasive regions (e.g., the right-most region shows higher expression of _GATA3_ than the rest of the tumor, Figure 3.b). Using the nuclear segmentation, we can compute human-interpretable features related to nuclear size (area, perimeter, major axis length, minor axis length, and equivalent diameter), topology and shape (roundness, ellipticity, eccentricity, extent, and roughness), and cell distribution (cell density and crowdedness). A heatmap of the nuclear area of neoplastic cells also indicates morphological heterogeneity among neoplastic regions (Figure 3.c,d). Regions with a high nuclear area and elevated GATA3 expression notably overlap, suggesting that this tumor exhibits molecular heterogeneity, which to some degree is morphologically expressed.

To investigate this hypothesis, we measured the Pearson correlation between the expression of _GATA3_ and nuclear area in neoplastic cells (Figure 3.e). We observe a moderate correlation (R=0.47, P-value\(<10^{-4}\)), which is also observed in other genes and morphological features (Figure 3.f). Overall, out of the 12 human-interpretable features we analyzed, we found the highest association with gene expression for size-related features, while features involving topology, shape, and cell distribution had a lower correlation (R<0.2). A similar analysis in another IDC sample (Appendix Figure 6.b,c) further asserted these observations. In particular, we found the highest associations between nuclear size and expression for the genes _FLNB_ (R=0.45, P-value\(<10^{-4}\)) and _TPD52_ (R=0.47, P-value\(<10^{-4}\)), both

Figure 2: **Scaling laws in HEST-Benchmark.****a.** Model scaling law comparing the number of training parameters in the vision encoder (log-scale) and the average performance on the HEST-Benchmark. Pearson correlation between parameters and performance of R=0.81 (P-value < 0.01). **b.** Data scaling law comparing the number of image patches used for pretraining (log-scale) and the average performance on the HEST-Benchmark. Pearson correlation between number of patches and performance of R=0.48 (P-value=0.13).

involved in breast tumor growth and proliferation [13; 124], and _FOXA1_ (R=0.47, P-value\(<10^{-4}\)), a known prognostic factor associated with better survival [12; 150].

Such analysis highlights how HEST-1k can be used to identify fine-grained morphological correlates of expression. Similar approaches can be used to characterize morphological and molecular tumor heterogeneity at a larger scale.

## 7 HEST for multimodal representation learning

Access to spatially-resolved expression-morphology pairs unlocks new directions for multimodal representation learning. Several problem statements can be explored, such as cross-modal alignment and retrieval, multimodal fusion, etc. Here, we fine-tune CONCH [88] (ViT-Base model) on five Xenium invasive breast cancer cases (four ductal and one lobular case) using multimodal contrastive alignment. We hypothesize that the resulting breast cancer-specific patch encoder, termed CONCH-FT, can better encode the underlying molecular landscape associated with disease-specific morphologies. To validate the hypothesis, CONCH-FT is benchmarked on an independent breast cancer cohort for molecular subtyping against its non-finetuned version.

Specifically, for each Xenium sample, we extract 112\(\times\)112-\(\mu\)m image patches centered around each spot at 20\(\times\) magnification (0.5\(\mu\)m/px). This yields 47,051 pairs of 224\(\times\)224-pixel patches and corresponding expression profile (n=238 common genes in the panel, log1p normalized). We then embed the data using modality-specific encoders: the image patches using a pretrained CONCH model and the expression data using a 3-layer MLP (normalized expression data are encoded as tabular data). The modality-specific embeddings are then aligned using a contrastive objective, i.e., InfoNCE loss [111] by fine-tuning the image encoder and training the expression encoder from scratch. To mitigate over-fitting, we use the following training recipe: (1) Finetune only the last 3 layers of CONCH, (2) employ a layer-wise learning decay factor of 0.7, and (3) employ patch-level image augmentation. Additional details are provided in Appendix.

We evaluate the resulting CONCH-FT model to predict ER, PR, and HER2 expression status (binary) from WSIs in the BCNB dataset [153] (n=1,058 WSIs). To generate a slide representation for a

Figure 3: **HEST for biomarker exploration: Analysis of an invasive ductal carcinoma sample imaged with Xenium.****a**. IDC Xenium sample with neoplastic nuclei overlaid in red (\(n_{c}=168,033\) detected nuclei). Gray scale bar represents 2 mm. **b**. Heatmap of Xenium expression of gene _GATA3_. Blue and red values indicate above and below the mean (in white), respectively. **c**. Heatmap of neoplastic nuclear area. **d**. Four randomly selected regions with CellViT segmentation of the neoplastic nuclei. Black scale bar represents 30 \(\mu\)m. **e., f**. Correlation between nuclear area and _GATA3_, and minor axis length and _MYBPC1_.

WSI, we take the average of the patch embedding in the WSI (mean pooling), which is subsequently mapped to the expression status using logistic regression (Table 2). The simple mean pooling approach to embedding the slide without additional fine-tuning on the downstream tasks highlights the expressivity of the learned latent space. We observe that CONCH-FT outperforms CONCH on most metrics, demonstrating that pan-tissue histology patch encoders can be further fine-tuned to obtain better tissue-specific patch encoders. This is further validated by the larger rank induced by the patch embedding space [49] for CONCH-FT, suggesting better expressivity of the patch embeddings. While these results are based on only five paired WSIs, we anticipate additional benefits when training with larger disease-specific cohorts.

## 8 Discussion

**Summary.** We assembled HEST-1k, a dataset comprising paired spatial transcriptomics, H&E-stained whole-slide images, and comprehensive metadata built from public and internal cohorts. HEST-1k includes 1,229 samples, encompassing 2.1 million spots and over 76 million cells. The scale and comprehensiveness of HEST-1k, supported by the HEST-Library, enable exploring directions such as biomarker exploration and multimodal representation learning. Additionally, motivated by the need for new, diverse, and challenging patch-level benchmarks, we curated the HEST-Benchmark, a set of nine tasks covering eight cancer types and nine organs for gene expression prediction from histology. The HEST-Benchmark revealed data and model scaling laws across 11 foundation models of different dimensions and pretraining scale [88].

**Limitations.** Our study includes a few limitations. First, research data, such as those generated in spatial transcriptomic, are inherently noisy. While we tried to minimize "label" noise (e.g., by re-estimating image magnification and alignment, and unifying cancer samples using oncotree code taxonomy), staining and compression artifacts, varying acquisition protocols, among others, can negatively impact the quality of HEST-1k. Second, batch effects (on both the imaging and transcriptomic sides) can be significant across samples, datasets, and technologies. While this study does not explore batch effects quantification or mitigation, we provide a set of helpers in HEST-Library to let users explore this direction. Lastly, although the HEST-Library was designed for versatility, it cannot cover all existing formats and should rather be viewed as a blueprint for processing ST data in a consistent and unified manner.

**Future work.** Spatial transcriptomics is rapidly evolving, with new datasets frequently published. As they become available, we will keep updating HEST-1k with new resources. This study merely starts to uncover the potential of HEST-1k for advancing translational research and biomarker exploration, and we plan to explore these capabilities further. Additionally, the prospects for multimodal representation learning with HEST-1k are promising and are expected to grow with the addition of more data.

\begin{table}
\begin{tabular}{l c c c c c c c} \hline \hline  & **Rank** & \multicolumn{2}{c}{**ER**} & \multicolumn{2}{c}{**PR**} & \multicolumn{2}{c}{**HER2**} \\  & AUC & Bal.acc. & AUC & Bal.acc. & AUC & Bal.acc. \\ \hline
**CONCH** & 144.66 & 0.881 & 0.745 & 0.810 & 0.698 & 0.715 & **0.624** \\
**CONCH-FT** & **146.47** & **0.884** & **0.752** & **0.818** & **0.714** & **0.724** & 0.615 \\ \hline \hline \end{tabular}
\end{table}
Table 2: **CONCH fine-tuning on invasive breast cancer. Logistic regression evaluation for ER/PR/HER2 status on BCNB (binary task, n=1,058 WSIs). A WSI is represented by the average of the patch embeddings within each WSI. We report the mean \(\pm\) standard deviation computed over all folds (or patients) for ROC-AUC (AUC) and balanced accuracy (Bal.acc.). Best is bold.**

## Acknowledgements

We thank Dr. Maxime Meylan for his insights and guidance on accessing data published in [103]. We thank Rushin Gindra for his support in inspecting HEST-1k data, reporting issues, and providing references. HEST is supported by the Brigham and Women's Hospital (BWH) President's Fund, Mass General Hospital (MGH) Pathology, and the National Institute of Health (NIH) National Institute of General Medical Sciences (NIGMS) through R35GM138216. S.J.W. is supported by the Helmholtz Association under the joint research school "Munich School for Data Science - MUDS" and the Add-on Fellowship of the Joachim Herz Foundation.

## Checklist

1. Do the main claims made in the abstract, and introduction accurately reflect the paper's contributions and scope? [Yes] Each claim: HEST-1k, HEST-Library, HEST-Benchmark, HEST for biomarker exploration, and multimodal fine-tuning are supported by dedicated sections in the main text, in addition to supplementary information provided in the appendix. In addition, all the code to reproduce results is made available.
2. Did you describe the limitations of your work? [Yes] We discuss limitations in the **Discussion**.
3. Did you discuss any potential negative societal impacts of your work? [Yes] We discuss potential negative societal impacts in the section **Ethical considerations, intended usage, and license**.
4. Have you read the ethics review guidelines and ensured that your paper conforms to them? [Yes]
5. Did you include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)? [Yes] In the abstract, we provide a link to access the HEST page on GitHub. HEST-Library includes a link to download all data and to run the HEST-Benchmark. Finally, we provide all metadata associated with HEST-1k in a CSV as part of the supplementary material.
6. Did you specify all the training details (e.g., data splits, hyperparameters, how they were chosen)? [Yes] When relevant, we provide training details, such as in the **HEST-Benchmark**.
7. Did you report error bars? [Yes] HEST-Benchmark results include standard deviation computed from cross-validation across all patients.
8. Did you include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)? [Yes]
9. If your work uses existing assets, did you cite the creators? [Yes] All public resources used in this study are cited in Appendix Table A2, A4, A6, A7, A8, A9 and A10.
10. Did you mention the license of the assets? [Yes] Metadata associated with HEST-1k includes the license under which data were originally published. We ensured that the reported license allowed the distribution and creation of derivatives of the data.
11. Did you include any new assets either in the supplemental material or as a URL? [Yes] As part of HEST-1k, we include internal datasets (see Appendix Table A9).
12. Did you discuss whether and how consent was obtained from people whose data you're using/curating? [No] We used public resources for which the license was allowing redistributing the work. Users are welcome to inspect the individual IRBs of each publicly available resource.
13. Did you discuss whether the data you are using/curating contains personally identifiable information or offensive content? [Yes] We manually ensured that none of the published and distributed data includes personally identifiable information or offensive content, such as personal health information.

## Appendix

* A Ethical considerations, intended usage and license
* B Background
* B.1 Computational pathology
* B.2 Spatial transcriptomics (ST)
* C HEST
* C.1 HEST-1k
* C.2 HEST-Library
* C.3 HEST-Benchmark
* D HEST for multimodal representation learning
* E HEST for discovery
* F Datasheet for HEST-1k
* F.1 Motivation for dataset creation
* F.2 Dataset composition
* F.3 Data collection process
* F.4 Data preprocessing
* F.5 Dataset distribution
* F.6 Legal and ethical considerations
* G Author statement

## Appendix A Ethical considerations, intended usage and license

All resources provided as part of this study are strictly for research purposes and must not be utilized to support any diagnostic procedures. Users are hereby notified that the nuclear segmentation and classification components are derived from a publicly available model. Consequently, this model should not be regarded as the definitive standard, and users should exercise particular caution when utilizing this part of the dataset. Despite our efforts to exclude sensitive information, such as patient names, addresses, and social security numbers, users are expressly prohibited from attempting to reverse engineer the data to extract confidential patient information. In the presumption that users will adhere to the aforementioned restrictions, we have not identified any potential adverse social impacts that could arise from the use of HEST-1k.

The dataset is hosted on the HuggingFace Dataset webpage. All instructions are provided in the main README of HEST-Library. From there, users can choose to download HEST-1k in its entirety or a subset (e.g., only breast cancer samples). The HEST-1k, HEST-Benchmark, and HEST library are released under the Attribution-NonCommercial-ShareAlike 4.0 International license (CC BY-NC-SA 4.0 Deed)11.

Footnote 11: https://creativecommons.org/licenses/by-nc-sa/4.0/

## Appendix B Background

This study connects two fields: (1) computational pathology, which primarily uses routinely acquired clinical data to determine outcomes such as disease diagnosis from H&E-stained digitized tissuesections, and (2) spatial transcriptomics, which so far has been confined to biological research and aims to identify new biomarkers predictive of disease progression or response to treatment, among others.

### Computational pathology

Research in computational pathology [130] has primarily focused on classifying digitized WSIs into clinical outcomes. Unlike natural image classification tasks such as ImageNet, a WSI may reach sizes of up to 150,000 \(\times\) 150,000 pixels at 20\(\times\) magnification (0.5\(\mu\)m/pixel). The challenge of managing the large size of WSIs has been one the central themes of the field, primarily through the adoption of multiple instance learning (MIL) for weakly-supervised classification [62]. MIL employs a two-step process: (1) Initially, the tissue is segmented from the background and then tessellated into patches, usually 256 \(\times\) 256 pixels, akin to an ImageNet sample, and each patch is compressed into a patch embedding using a pretrained patch encoder. (2) Subsequently, these patch embeddings are aggregated using a learnable neural network, such as an attention-based network, a graph neural network, or a Transformer, to produce a slide embedding [62, 128]. This slide embedding is then used to classify specific targets of interest, such as cancer histological subtyping, morphological subtyping, mutation prediction, or survival analysis.

Such frameworks have been shown to achieve better or similar performance than humans for Gleason grading in prostate cancer[23], metastasis detection in lymph nodes[18], determining the origin of a cancer of unknown primary[89], predicting heart transplant rejection[83], among others.

### Spatial transcriptomics (ST)

ST enables the measurement of gene activity and the mapping of its corresponding location in the tissue. In this study, we collected samples from two ST paradigms: sequencing-based (ST, Visium, Visium HD) and imaging-based (Xenium).

**Visium (HD) / Spatial transcriptomics:** Visium-HD and its predecessors Visium and Spatial Transcriptomics (STv1) refer to a family of sequencing-based products for spatially resolving large transcript panels, whose main difference lies in the resolution and spacing between the expression measurement, called a spot. These spots capture mRNA from tissue sections placed on the chip, and the location-specific barcodes contained in each of the spots bind to the RNA to retain spatial information. The RNA molecules are then washed off the slides and processed by a sequencing instrument. Using a sequencing-based method allows the reuse of existing sequencing instruments developed in the fields of single-cell and bulk transcriptomics, hence benefiting from existing technological advancements and allowing whole transcriptome analysis. A fundamental drawback of current sequencing-based methods is the inherent RNA resolution limitation imposed by the size of the spots (e.g., 55\(\mu\)m in Visium).

**Xenium:** Xenium is an imaging-based spatial profiling technology that offers in situ RNA capturing on tissue sections by imaging fluorescent RNA markers derived from padlock probes and rolling circle amplification chemistry. This approach provides the exact 2D location of each measured transcript. As of 2024, Xenium cannot perform whole transcriptome measurements and is limited to gene panels of up to 5,000 genes.

## Appendix C Heat

### Heat-1k

We provide a comprehensive description of all publicly available and internal cohorts integrated into HEST-1k.

### HEST-Library

The HEST-Library helps transform unstructured spatial transcriptomics and histology data into a unified format. An overview of the HEST-Library is provided in Figure 4. An example of fiducial detection is presented in Figure 5.

### HEST-Benchmark

**Gene selection, XGBoost Forest, and Ridge regression models:** We learn a regression model that maps the patch embeddings of each encoder to its corresponding gene expression profile. The XGboost model uses 100 estimators, a 0.1 learning rate, a max depth of 3, 0.8 subsampling, gamma of 0.0, regression alpha of 0.0, and regression lambda of 1.0. Additional information can be found in the XGBoost API12. The Ridge regression uses a fixed \(L2\) regularization coefficient \(\lambda\) set to \(100/MC\), where \(M\) is the embedding dimension and \(C=50\) is the number of targets trained with the Regularized Least-Squares Routine solver (sklearn implementation). Both regression models are trained to predict a panel constituted of the 50 most variable genes of each task. Specifically, for each

Figure 4: **Overview of HEST-Library functionalities.** HEST was designed to transform legacy data scrapped in multiple public repositories, such as NCBI, into unified HEST objects that can easily be integrated into computational pipelines.

\begin{table}
\begin{tabular}{l c c c} \hline \hline
**Resource** & **Number of datasets** & **Number of samples** & **Size (GB, raw)** \\ \hline
10x Genomics & 87 & 112 & 275 \\ Mendeley & 9 & 118 & 181 \\ Spatial-Research & 4 & 139 & 18 \\ Zenodo & 4 & 21 & 18 \\ NCBI & 43 & 696 & 298 \\ Internal & 3 & 28 & 60 \\ Miscellaneous & 4 & 114 & 147 \\ \hline \hline \end{tabular}
\end{table}
Table A1: **HEST-1k data overview.** All samples include a license that allows sharing and redistributing. National Center for Biotechnology Information: NCBI.

task, we select the 50 most variable genes across all spots and samples after excluding the genes that have non-zero counts in less than 10% of the spots.

**Benchmark task description:** We provide complementary information on each task introduced as part of the HEST-Benchmark.

**Task 1: Prediction of expression in invasive ductal carcinoma (breast cancer, IDC).** We used all publicly available Xenium samples available on 10x Genomics ("FFPE Human Breast using the Entire Sample Area", 2 patients) and two samples published in [63] (TENX95, TENX99, NCBI783, NCBI785). All samples are FFPE sections imaged with the Xenium pipeline v1.

**Task 2: Prediction of expression in prostate adenocarcinoma (prostate cancer, PRAD).** We used all 23 Visium samples (fresh frozen sections) from 2 patients published in [40] (MEND139 to MEND162). Both patients were diagnosed with prostatic acinar adenocarcinoma with a (4+3) Gleason score (ISUP group 4).

**Task 3: Prediction of expression in pancreatic adenocarcinoma (pancreatic cancer, PAAD).** We used 3 samples from 3 different patients from 10x Genomics ("FFPE Human Pancreas with Xenium Multimodal Cell Segmentation" and "Pancreatic Cancer with Xenium Human Multi-Tissue and Cancer Panel"). All samples are FFPE sections processed with Xenium pipeline v1 (TENX116, TENX126, TENX140).

**Task 4: Expression prediction in skin cutaneous melanoma (skin cancer, SKCM).** We used 2 samples from 2 different patients from 10x Genomics website ("Human Skin Data with Xenium Human Multi-Tissue and Cancer Panel"). All samples are FFPE sections processed with Xenium pipeline v1 (TENX115, TENX117).

**Task 5: Prediction of expression in colon adenocarcinoma (colon cancer, COAD).** We used 4 COAD samples from 2 different patients available on 10x Genomics (TENX111, TENX147, TENX148, TENX149). All samples are fresh frozen sections processed with Visium.

**Task 6: Prediction of expression in rectal adenocarcinoma (rectum cancer, READ).** We used 4 READ samples from 2 different patients published in [135]. All samples are fresh frozen sections processed with Visium (ZEN36, ZEN40, ZEN48, ZEN49).

**Task 7: Prediction of expression in clear cell renal cell carcinoma (kidney cancer, ccRCC).** We used the 24 ccRCC samples of 24 different patients published in [103]. All samples are fresh frozen sections processed with Visium (INT1 to INT24).

Figure 5: **Fiducial detection and automatic alignment in Visium.** Corner fiducials on 6.5\(\times\)6.5mm and 11mm\(\times\)11mm Visium slides are automatically detected with a finetuned Yolov8 model. The spot coordinates are then derived if at least 3 of the 4 corner fiducials are detected. This process enables automatically estimating the pixel resolution.

**Task 8: Prediction of expression in lung adenocarcinoma (lung cancer, LUAD).** We used 2 LUAD samples from 2 different patients from 10x genomics ("Preview Data: FFPE Human Lung Cancer with Xenium Multimodal Cell Segmentation"). All samples are fresh frozen sections processed with Xenium pipeline v1 (TENX118, TENX141).

**Task 9: Prediction of expression in axillary lymph nodes in IDC patients.** We used 4 axillary lymph node samples from 2 IDC patients published in [84]. All samples are fresh frozen sections processed with Visium (NCBI681, NCBI682, NCBI683, NCBI684).

We provide a brief description of each patch encoder assessed with the HEST-Benchmark.

**ResNet50 (IN) [90]:** This model uses a ResNet50 backbone [56] trained on ImageNet [35] (1.2 million natural images). Following prior work [90], the patch embeddings are extracted by taking the representation at the penultimate layer before final classification.

**CTransPath [146]:** This model uses a "Tiny" Swin Transformer backbone [85] with a window size of 14 (Swin-T/14, 28 million parameters) pretrained on TCGA and PAIP datasets (17 million images) using MoCoV3 [31].

**Remedis [11]:** This model uses a ResNet-152\(\times\)2 (232 million parameters) initialized with the "Big Transfer"-medium protocol [74] on ImageNet-22K and pretrained with SimCLR [30] on TCGA.

**Phikhon [42]:** This model uses a Vision Transformer-Base (ViT-B, 86 million parameters) [37] trained on TCGA data using iBOT [161].

**UNI [29]:** This model uses a ViT-Large (ViT-L, 307 million parameters) [37] trained on 100 million histology images (over 100,000 slides) from proprietary and public data using DINOv2 [112].

**CONCH [88]:** This model uses a ViT-B (86 million parameters) trained on a smaller version of UNI using iBOT, and then fine-tuned on 1.17 million histology image-caption pairs extracted from online educational and research resources using CoCa [156].

**GigaPath [154]:** This model uses a ViT-giant (1.13 billion parameters) trained on 1.3 billion image patches from 171,189 WSIs at 20\(\times\) magnification using DINOv2.

**Virchow [142]:** This model uses a ViT-Huge (632M parameters) trained on 2 billion image patches and 1.5M WSIs at 20\(\times\) magnification using DINOv2.

**Virchow 2 [162]:** This model uses a ViT-Huge (632M parameters) trained on 1.9B patches and 3.1M WSIs using DINOv2

**H-Optimus-0:** This model uses a ViT-giant (1.13B parameters) trained 273 million image patches from 500,000 WSIs at 20\(\times\) magnification using DINOv2.

**UNIV1.5:** This model uses a ViT-giant (1.13B parameters) trained on 432 million image patches from 350,000 WSIs using DINOv2.

## Appendix D HEST for multimodal representation learning

We provide additional information regarding CONCH fine-tuning using multimodal alignment. CONCH-FT model, a ViT-Base model initialized with CONCH weights, was fine-tuned for 50 epochs using a cosine learning rate scheduler, with a base learning rate of \(10^{-4}\) for the image encoder and \(10^{-5}\) for the expression encoder. Only the last 3 layers of the model were fine-tuned, with a layer-wise learning decay rate of 0.7. For training with the infoNCE loss, a contrastive temperature of \(10^{-2}\) and batch size of 1,024 pairs of patch and transcriptomics were used. A combination of random horizontal/vertical flip and color jittering was employed for image patch augmentation.

The rank of the embedding space (also referred to as smooth rank measure [49]) measures the quality of the embeddings produced from encoders trained in unsupervised or self-supervised manners. Given the patch embedding matrix \(H\in\mathcal{R}^{N\times d}\) and \(d<N\), where \(N\) is the number of patches and \(d\) is the feature dimension, we compute the rank as the entropy of the \(d\) L1-normalized singular values of \(H\).

HEST for discovery

Cells were segmented and classified using CellViT [61]. To find the gene expression profile of each neoplastic cell, we matched each cell to its corresponding cell index in Xenium by assigning the index for which the distance between the cell centroids was the smallest. After matching all neoplastic cells, only those cells for which the assignment was unique were kept. After this filtering step, an average of 91% of the cells per sample were kept while 9% of the cells were discarded.

## Appendix F Datasheet for HEST-1k

We provide a DataSheet for HEST-1k that summarizes the contributions, analyses, and intended usages presented in the study.

### Motivation for dataset creation

* **Why was the dataset created?** HEST-1k was designed with three key applications: (1) multimodal representation learning of histology and transcriptomics, (2) biomarker exploration and characterization, and (3) benchmarking foundation models for pathology. Despite many publicly available resources, no existing unified and user-friendly formatting was available to bring ST into the world of deep learning.
* **What (other) tasks could the dataset be used for? Are there obvious tasks for which it should not be used?** Users are welcome to introduce new, creative ways to use the dataset. However, users are not allowed to try to retrieve patient information from the existing data. A dedicated section is provided to discuss ethical considerations and intended usage.
* **Has the dataset been used for any tasks already? If so, where are the results so others can compare (e.g., links to published papers)?** The metadata attached to HEST-1k reports all samples that were made public as part of a publication (peer-reviewed or not).

Figure 6: **HEST for biomarker discovery: Analysis of an invasive ductal carcinoma Xenium sample.****a.** IDC Xenium sample with neoplastic nuclei overlaid in red (\(n_{c}\)=342,018 detected nuclei). Six randomly selected regions with CellViT segmentation of the neoplastic nuclei. Black scale bar represents 30 \(\mu\)m. **b.** Pearson correlation between the major axis length of neoplastic nuclei and the log1p-normalized expression of _TPD52_. **c.** Analogous analysis between nuclear area and _FLNB_ expression.

* **Who funded the creation of the dataset?** HEST is supported by the Brigham and Women's Hospital (BWH) President's Fund, Mass General Hospital (MGH) Pathology, and the National Institute of Health (NIH) National Institute of General Medical Sciences (NIGMS) through R35GM138216.

### Dataset composition

* **What are the instances?** The modalities used in this study are histopathology whole-slide images, gene expression data, and derivatives of these two modalities, such as nuclear segmentation and classification maps.
* **Are relationships between instances made explicit in the data** Each whole-slide image maps to a unique gene expression profile in an unequivocal way.
* **What data does each instance consist of?** Imaging data consists of Generic TIFF objects stored in a pyramidal format, and gene expression data consists of _scanpy_ objects. Derivatives are stored in JSON files, parquet files, and Hierarchical Data Format (HDF) files.
* **Is there a label/target associated with instances? If the instances are related to people, are subpopulations identified (e.g., by age, gender, etc.), and what is their distribution?** Each sample pair (slide and expression profile) is associated with comprehensive metadata. All metadata information is thoroughly described in the main paper. Age and gender are only reported in a subset of cases.
* **Is everything included or does the data rely on external resources? (e.g., websites, tweets, datasets) If external resources, a) are there guarantees that they will exist, and remain constant, over time; b) is there an official archival version. Are there licenses, fees or rights associated with any of the data?** We provide all data as part of the HEST-1k release. In addition, a link to the original data is provided in the metadata. Each sample is associated with a license as provided by the original publication, where we ensured that the reported license allowed for distributing and creating derivatives of the data.
* **Are there recommended data splits or evaluation measures?** HEST-1k comes with the HEST-Benchmark, a series of tasks for gene expression prediction from histology images. All patient-stratified splits are specified in the attached comma-separated values (CSV) files.
* **What experiments were initially run on this dataset? Have a summary of those results and, if available, provide the link to a paper with more information here.** All experiments run with HEST-1k are described in this study. The reader can refer to the main text for a thorough description of all experiments (see **HEST-Benchmark**, **HEST for biomarker exploration**, **HEST for multimodal representation learning**).

### Data collection process

* **How was the data collected?** The data were manually inspected and curated by the authors of the present study.
* **Who was involved in the data collection process?** All authors of the present study were involved in the data collection, inspection, and curation. The reader can refer to the original publication to understand how the data were originally acquired.
* **Over what time frame was the data collected? Does the collection time frame match the creation time frame?** The original data comprise publications from 2016 to 2024. As the dataset grows, more recent publications might be included in HEST-1k.
* **Does the dataset contain all possible instances? Or is it, for instance, a sample (not necessarily random) from a larger set of instances?** All pairs of gene expression data and whole-slide images of the underlying studies were included and are unique.
* **Is there information missing from the dataset and why? (this does not include intentionally dropped instances; it might include, e.g., redacted text, and withheld documents) Is this data missing because it was unavailable?** Original publications may include some missing information, such as the alignment file between the slide and the expression profile. We developed computational tools to minimize missing information and reach near-complete metadata.

* **Are there any known errors, sources of noise, or redundancies in the data?** All whole-slide images have been manually inspected. The quality from one sample to another varies significantly, for instance, due to poor staining, compression artifact, lower resolution, etc. Gene expression data are inherently noisy. Users can decide to apply post-hoc normalization methods to reduce noise, e.g., stain normalization on the imaging side or batch effect mitigation on the transcriptomics side.

### Data preprocessing

* **What preprocessing/cleaning was done?** All whole-slide images were converted into pyramidal TIFF objects with re-estimated pixel resolution. All alignment files have been manually inspected and included if missing. All gene expression data have been transformed into _scampy_ objects following the same process.
* **Was the "raw" data saved in addition to the preprocessed/cleaned data? (e.g., to support unanticipated future uses)** Raw data are downloaded but not publicly shared. In the case of public samples, users can re-download them using the metadata provided as part of the dataset release.
* **Is the preprocessing software available?** Yes, the source code to preprocess HEST-1k is made publicly available as part of the HEST library.

### Dataset distribution

* **How is the dataset distributed?** HEST-1k is distributed using HuggingFace Datasets.
* **When will the dataset be released/first distributed?** The dataset is public and can be accessed through the HuggingFace Datasets interface.
* **What license (if any) is it distributed under? Are there any copyrights on the data?** The dataset is distributed under the Attribution-NonCommercial-ShareAlike 4.0 International license (CC BY-NC-SA 4.0 Deed).
* **Are there any fees or access/export restrictions?** No access/export restrictions unless they violate the terms of the above-mentioned license (CC BY-NC-SA 4.0 Deed).
* **Who is supporting/hosting/maintaining the dataset? How does one contact the owner/curator/manager of the dataset?** The dataset is maintained by the authors of the publication.
* **Will the dataset be updated? How often and by whom? How will updates/revisions be documented and communicated (e.g., mailing list, GitHub)? Is there an erratum?** The dataset might evolve as additional samples become publicly available. Dataset versioning will be put in place.
* **If the dataset becomes obsolete how will this be communicated?** The GitHub README will be updated.
* **Is there a repository to link to any/all papers/systems that use this dataset?** There is no repository to link papers that use HEST-1k. Users are required to cite HEST-1k if they use it in their own research.
* **If others want to extend/augment/build on this dataset, is there a mechanism for them to do so? If so, is there a process for tracking/assessing the quality of those contributions. What is the process for communicating/distributing these contributions to users?** Users are welcome to contact us if they would like to provide additional data that meets our standards. We do not have a dedicated system to communicate these contributions. Newly added data will be tracked in the versioning.

### Legal and ethical considerations

* **If the dataset relates to people (e.g., their attributes) or was generated by people, were they informed about the data collection? (e.g., datasets that collect writing, photos, interactions, transactions, etc.)** HEST-1k does not include patient information (such as name, address, etc.).

* **If it relates to other ethically protected subjects, have appropriate obligations been met? (e.g., medical data might include information collected from animals)** For animal samples (_Mus musculus_ tissue), we refer to the original publication for an in-depth analysis.
* **If it relates to people, were there any ethical review applications/reviews/approvals? (e.g. Institutional Review Board applications)** For human tissue, we refer to the original publication for an in-depth analysis. Internal cohorts were ethically reviewed and collected as part of dedicated IRBs.
* **If it relates to people, could this dataset expose people to harm or legal action? (e.g., financial, social or otherwise) What was done to mitigate or reduce the potential for harm?** No, patients cannot be linked to the corresponding histology and gene expression profile.
* **If it relates to people, does it unfairly advantage or disadvantage a particular social group? In what ways? How was this mitigated?** Most datasets do not include specific demographics. When reported, we include this information in the metadata associated with each sample. To our knowledge, the representation of HEST-1k does not unfairly advantage or disadvantage a particular social group.
* **Does the dataset contain information that might be considered sensitive or confidential? (e.g., personally identifying information)** No.
* **Does the dataset contain information that might be considered inappropriate or offensive?** No.

## Appendix G Author statement

The authors of this paper bear all responsibility in case of violation of rights associated with HEST-1k, HEST-Library, and HEST-Benchmark.

\begin{table}
\begin{tabular}{l l l c c} \hline \hline
**Collection name** & **Organ** & **Technology** & \(n\) & 
\begin{tabular}{c} **Num.** \\ **genes** \\ \end{tabular} \\ \hline Adult Mouse Brain (FFPE) & Brain & Visium & 1 & 19,465 \\ Adult Mouse Brain Coronal Section (Fresh Frozen) 1 & Brain & Visium & 1 & 32,285 \\ Adult Mouse Brain Coronal Section (Fresh Frozen) 2 & Brain & Visium & 1 & 32,285 \\ Adult Mouse Kidney (FFPE) & Kidney & Visium & 1 & 19,465 \\ Adult Mouse Olfactory Bulb & Brain & Visium & 1 & 32,285 \\ Characterization of immune cell populations in the tumor microenvironment of colorectal cancer using high definition spatial profiling [110] & Bowel & Mixed & 8 & 18,085 \\ FFPE Human Breast using the Entire Sample Area FFPE Human Breast with Custom Add-on Panel FFPE Human Breast with Pre-designed Panel FFPE Human Pancreas with Xenium Multimodal Cell Segmentation & Breast & Xenium & 2 & 541 \\ FFPE Human Prostate Adenocarcinoma with 5K Human Pan Tissue and Pathways Panel FFPE Human Skin Primary Dermal Melanoma with 5K Human Pan Tissue and Pathways Panel Fresh Frozen Mouse Colon with Xenium Multimodal Cell Segmentation & Breast & Xenium & 1 & 541 \\ Fresh Frozen Mouse Brain Hemisphere with 5K Mouse Pan Tissue and Pathways Panel Fresh Frozen Visium on CytAssist: Human Breast Cancer, Probe-Based Whole Transcriptome Profiling & Breast & & 10,006 \\ Fresh Frozen Visium on CytAssist: Mouse Brain, Probe-Based Whole Transcriptome Profiling & Skin & & 10,017 \\ Human Bone and Bone Marrow Data with Custom Add-on Panel & Bone & Xenium & 1 & 541 \\ Human Brain Cancer, 11 mm Capture Area (FFPE) Human Breast Cancer (Block A Section 1) Human Breast Cancer (Block A Section 2) Human Breast Cancer (Block A Section 2) Human Breast Cancer: Ductal Carcinoma In Situ, Invasive Carcinoma (FFPE) Human Breast Cancer: Targeted, Immunology Panel Human Breast Cancer: Visium Fresh Frozen, Whole Transcriptome Human Cerebellum: Targeted, Neuroscience Panel Human Cerebellum: Whole Transcriptome Analysis Human Cervical Cancer (FFPE) Human Colon Preview Data (Xenium Human Colon Gene Expression Panel) Human Colorectal Cancer: Targeted, Gene Signature Panel Human Colorectal Cancer: Whole Transcriptome Human Glioblastoma: Targeted, Pan-Cancer Panel Human Glioblastoma: Whole Transcriptome Analysis Human Heart Human Heart Data with Xenium Human Multi-Tissue and Cancer Panel Human Intestine Cancer (FPPE) Human Kidney Preview Data (Xenium Human Multi-Tissue and Cancer Panel) Human Kidney 11 mm Capture Area (FFPE) Human Liver Data with Xenium Human Multi-Tissue and Cancer Panel Human Lung Cancer (FFPE) Human Lung Cancer, 11 mm Capture Area (FFPE) Human Lymph Node & \(n\): number of samples in the cohort. \\ \hline \hline \end{tabular}
\end{table}
Table 2: **Datasets gathered from 10x Genomics portal. \(n\)**: number of samples in the cohort.

\begin{table}
\begin{tabular}{l l l c c} \hline \hline
**Collection name** & **Organ** & **Technology** & \(n\) & 
\begin{tabular}{c} **Num.** \\ **genes** \\ \end{tabular} \\ \hline Human Ovarian Cancer (FFPE) & Ovary & Visium & 1 & 17,943 \\ Human Ovarian Cancer, 11 mm Capture Area (FFPE) & Ovary & Visium & 1 & 18,085 \\ Human Prostate Cancer, Acinar Cell Carcinoma (FFPE) & Prostate & Visium & 1 & 17,943 \\ Human Prostate & Prostate & Visium & 1 & 17,943 \\ Human Skin Data with Xenium Human Multi-Tissue and Cancer Panel & Skin & Xenium & 2 & 541 \\ Human Skin Preview Data (Xenium Human Skin Gene Expression Panel with Custom Add-On) & Skin & Xenium & 1 & 541 \\ Human Skin Preview Data (Xenium Human Skin Gene Expression Panel) & Skin & Xenium & 1 & 541 \\ Human Tonsil Data with Xenium Human Multi-Tissue and Cancer Panel & Lymph node & Xenium & 2 & 541 \\ Mouse Bone Data with Custom Add-on Panel & Bone & Xenium & 3 & 541 \\ Mouse Brain Coronal Section 1 (FFPE) & Brain & Visium & 1 & 19,465 \\ Mouse Brain Section 1 (Sagittal-Anterior) & Brain & Visium & 1 & 31,053 \\ Mouse Brain Serial Section 1 (Sagittal-Posterior) & Brain & Visium & 1 & 31,053 \\ Mouse Brain Serial Section 2 (Sagittal-Anterior) & Brain & Visium & 1 & 31,053 \\ Mouse Brain Serial Section 2 (Sagittal-Posterior) & Brain & Visium & 1 & 31,053 \\ Mouse Embryo, 11 mm Capture Area (FFPE) & Embryo & Visium & 1 & 19,465 \\ Mouse Kidney Section (Coronal) & Visium & 1 & 31,053 \\ Mouse Tissue Microarray in 3x3 Layout with 1 mm Edge to Edge Spacing (FFPE) & Lung/Brain & Visium & 1 & 19,465 \\ Mouse Tissue Microarray in 3x5 Layout with 1 mm Edge to Edge Spacing (FFPE) & Kidney/Brain Visium & 1 & 19,465 \\ Normal Human Prostate (FFPE) & Prostate & Visium & 1 & 17,943 \\ Pancreatic Cancer with Xenium Human Multi-Tissue and Cancer Panel & Princess & Xenium & 1 & 538 \\ Preservation Method Comparison on CytAssist: FFPE Mouse Brain (Sagittal), 11 mm Capture Area & Brain & Visium & 1 & 19,465 \\ Preservation Method Comparison on CytAssist: Fixed Frozen Mouse Brain (Sagittal), 11 mm Capture Area & Brain & Visium & 1 & 19,465 \\ Preservation Method Comparison on Visium CytAssist: Freß Frozen Mouse Brain (Sagittal), 11 mm Capture Area & Brain & Visium & 1 & 19,465 \\ Frozen Mouse Brain (Sagittal), 11 mm Capture Area & Brain & Visium & 1 & 19,465 \\ Preservation Method Comparison on Visium CytAssist: Fixed Frozen Mouse Brain (Sagittal), 11 mm Capture Area & Brain & Visium & 1 & 19,465 \\ Preview Data: FFPE Human Lung Cancer with Xenium Multimodal Cell Segmentation & Brain & Visium & 1 & 19,465 \\ Preview Data: FFPE Human Lymph Node with 5K Pan Tissue and Pathways Panel & Brain & Visium & 1 & 19,465 \\ Visium CytAssist Gene Expression Libraries of Post-Xenium Human Colon Cancer (FFPE) & Brain & Visium & 1 & 19,465 \\ Visium CytAssist Gene Expression Libraries of Post-Xenium Mouse Brain (FF) & Visium & 1 & 541 \\ Visium CDAssist, Mouse Embryo, 11 mm Capture Area (FFPE) & Visium HD Spatial Gene Expression Library, Mouse Kidney (FFPE) & Visium HD Spatial Gene Expression Library, Human Panel (FFPE) & Visium HD Spatial Gene Expression Library, Human Panel (FFPE) & & \\ Whole Mouse Pup Preview Data (Xenium Mouse Tissue Atlassing Panel) & Whole Mouse Patient & 1 & 541 \\ \hline \hline \end{tabular}
\end{table}
Table 3: **Datasets gathered from 10x Genomics portal. Continuation.**

## Appendix A

\begin{table}
\begin{tabular}{p{113.8pt} p{113.8pt} p{113.8pt} p{113.8pt}} \hline \hline
**Publication** & **Organ** & **Technology** & \(n\) & **Num. genes** \\ \hline A spatiotemporal organ-wide gene expression and cell atlas of the developing human heart [10] & Heart & \begin{tabular}{} \end{tabular} & 19 & 39,739 \\ Integrating spatial gene expression and breast tumour morphology via deep learning [55] & Breast & \begin{tabular}{} \end{tabular} & 68 & 16,744 \\ Spatial deconvolution of HER2-positive breast cancer delineates tumor-associated cell type interactions [4] & Breast & \begin{tabular}{} \end{tabular} & 36 & 15,045 \\ Visualization and analysis of gene expression in tissue sections by spatial transcriptomics [134] & Brain & 
\begin{tabular}{} \end{tabular} & 16 & 16,573 \\ \hline \hline \end{tabular}
\end{table}
Table A5: **Datasets gathered from NCBI. Continuation.**

\begin{table}
\begin{tabular}{l l l l l} \hline \hline
**Publication** & **Organ** & **Technology** & \(n\) & \begin{tabular}{l} **Num.** \\ **genes** \\ \end{tabular} \\ \hline \begin{tabular}{l} Prostate ST Internal \\ Tertiary lymphoid structures generate and propagate \\ anti-tumor antibody-producing plasma cells in renal \\ cell cancer [103] \\ \end{tabular} & \begin{tabular}{l} Prostate \\ Lymph \\ node \\ \end{tabular} & 
\begin{tabular}{l} Visium \\ \end{tabular} & 4 & 17,943 \\ \hline \hline \end{tabular}
\end{table}
Table A9: **Internal datasets.**

\begin{table}
\begin{tabular}{l c c c c c c c c c} \hline \hline  & **IDC** & **PRAD** & **PAAD** & **SKCM** & **COAD** & **READ** & **ccRCC** & **LUAD** & **LYMPH IDC** & **Average** \\ \hline
**REMEDIS** & 0.4936 & 0.2632 & 0.2881 & 0.4117 & 0.151 & 0.0776 & 0.2201 & 0.3114 & 0.1694 & 0.2651 \\  & \(\pm\) 0.0725 & \(\pm\) 0.0821 & \(\pm\) 0.0544 & \(\pm\)0.0384 & \(\pm\) 0.0147 & \(\pm\) 0.0684 & \(\pm\) 0.0418 & \(\pm\) 0.0432 & \(\pm\) 0.0855 \\
**GigaPath** & 0.532 & 0.3035 & 0.3172 & 0.2231 & 0.163 & 0.1236 & 0.2172 & 0.3144 & 0.1925 & 0.2652 \\  & \(\pm\) 0.0812 & \(\pm\) 0.0279 & \(\pm\) 0.0165 & \(\pm\) 0.0871 & \(\pm\) 0.0417 & \(\pm\) 0.0379 & \(\pm\) 0.0479 & \(\pm\) 0.0871 & \(\pm\) 0.0301 & \\
**UNlv1.5** & 0.5657 & 0.3065 & 0.3004 & 0.258 & 0.1982 & 0.1077 & 0.2023 & 0.3084 & 0.1998 & 0.2719 \\  & \(\pm\) 0.0866 & \(\pm\) 0.02 & 0.0199 & \(\pm\) 0.0514 & \(\pm\) 0.0026 & \(\pm\) 0.0222 & \(\pm\) 0.0695 & \(\pm\) 0.0174 & \(\pm\) 0.0129 & \\
**H-Optimus-0** & **0.5789** & 0.2561 & 0.3367 & 0.2778 & 0.1605 & 0.1228 & 0.2342 & 0.3143 & 0.1976 & 0.2754 \\  & \(\pm\) 0.0898 & \(\pm\) 0.0063 & \(\pm\) 0.0428 & \(\pm\) 0.0948 & \(\pm\) 0.0822 & \(\pm\) 0.0399 & \(\pm\) 0.0737 & \(\pm\) 0.083 & \(\pm\) 0.0253 & \\
**Virchow2** & 0.5666 & 0.2972 & 0.2718 & 0.3038 & 0.1814 & 0.1208 & 0.2257 & 0.3017 & 0.2172 & 0.2762 \\  & \(\pm\) 0.0848 & \(\pm\) 0.037 & \(\pm\) 0.0387 & \(\pm\) 0.0184 & \(\pm\) 0.0326 & \(\pm\) 0.0526 & \(\pm\) 0.0433 & \(\pm\) 0.1199 & \(\pm\) 0.019 & \\
**Virchow** & 0.5583 & 0.2744 & 0.3361 & 0.3389 & 0.1825 & 0.0955 & 0.2375 & 0.2897 & 0.2081 & 0.2801 \\  & \(\pm\) 0.0876 & \(\pm\) 0.0019 & \(\pm\) 0.0377 & \(\pm\) 0.0058 & \(\pm\) 0.0087 & \(\pm\) 0.0872 & \(\pm\) 0.0731 & 0.4708 & \(\pm\) 0.0234 & \\
**ResNet50** & 0.4453 & 0.2753 & 0.3432 & 0.413 & 0.2009 & 0.0669 & 0.2103 & 0.4001 & 0.203 & 0.2842 \\  & \(\pm\) 0.0377 & \(\pm\) 0.0682 & \(\pm\) 0.0654 & \(\pm\) 0.0814 & \(\pm\) 0.0616 & \(\pm\) 0.0646 & \(\pm\) 0.0548 & \(\pm\) 0.0637 & \(\pm\) 0.0536 & \\
**CTransPath** & 0.4996 & 0.2895 & 0.3826 & 0.4038 & 0.1751 & 0.0909 & 0.2139 & 0.4026 & 0.2089 & 0.2963 \\  & \(\pm\) 0.0594 & \(\pm\) 0.0734 & \(\pm\) 0.066 & \(\pm\) 0.0043 & \(\pm\) 0.0808 & \(\pm\) 0.0438 & \(\pm\) 0.0749 & \(\pm\) 0.0867 & \(\pm\) 0.0867 & \(\pm\) 0.0867 \\
**Phikon** & 0.5259 & 0.2493 & 0.3594 & 0.3684 & 0.1697 & 0.1136 & **0.253** & 0.4224 & 0.2151 & 0.2974 \\  & \(\pm\) 0.0791 & \(\pm\) 0.1264 & \(\pm\) 0.0707 & \(\pm\) 0.1061 & \(\pm\) 0.0562 & \(\pm\) 0.0749 & \(\pm\) 0.0483 & \(\pm\) 0.0579 & \(\pm\) 0.0416 & \\
**UNI** & 0.563 & 0.257 & 0.3768 & 0.3433 & 0.1839 & 0.1239 & 0.2395 & 0.3714 & 0.2236 & 0.2981 \\  & \(\pm\) 0.0771 & \(\pm\) 0.0819 & \(\pm\) 0.0355 & \(\pm\) 0.0556 & \(\pm\) 0.0509 & \(\pm\) 0.0534 & \(\pm\) 0.0587 & \(\pm\) 0.1098 & \(\pm\) 0.0289 & \\
**CONCH** & 0.528 & **0.3604** & **0.4224** & **0.5079** & **0.2467** & **0.1443** & 0.2356 & **0.4957** & **0.2462** & **0.3541** \\  & \(\pm\) 0.0794 & \(\pm\) 0.0135 & \(\pm\) 0.0773 & \(\pm\) 0.0281 & \(\pm\) 0.0045 & \(\pm\) 0.0455 & \(\pm\) 0.0837 & \(\pm\) 0.0203 & \(\pm\) 0.0349 & \\ \hline \hline \end{tabular}
\end{table}
Table A11: **Overview of the HEST-Benchmark. Each task involves predicting the expression levels of the 50 most variable genes from 112\(\times\)112 \(\mu\)m H&E-stained image patches centered on each spatial transcriptomics spot. The tasks are formulated as multivariate regression problems. The Oncotree code describes the cancer type diagnosed in samples, e.g., PAAD denotes pancreatic adenocarcinoma. Additional information is provided in the Appendix.**

\begin{table}
\begin{tabular}{l c c c c c c c c c|c} \hline \hline  & **IDC** & **PRAD** & **PAAD** & **SKCM** & **COAD** & **READ** & **ccRCC** & **LUAD** & **LYMPH IDC** & **Average** \\ \hline
**ResNet50 (IN)** & 0.4646 & 0.3433 & 0.4017 & 0.4707 & 0.2892 & 0.0586 & 0.181 & 0.4967 & 0.2284 & 0.326 \\  & \(\pm\) 0.0353 & \(\pm\) 0.0168 & \(\pm\) 0.0648 & \(\pm\) 0.0834 & \(\pm\) 0.0115 & \(\pm\) 0.069 & \(\pm\) 0.0502 & \(\pm\) 0.01 & \(\pm\) 0.0511 & \\
**CTransPath** & 0.4738 & 0.3514 & 0.4257 & 0.5304 & 0.2921 & 0.0996 & 0.2026 & 0.5225 & 0.234 & 0.348 \\  & \(\pm\) 0.0394 & \(\pm\) 0.0032 & \(\pm\) 0.0701 & \(\pm\) 0.073 & \(\pm\) 0.0018 & \(\pm\) 0.0766 & \(\pm\) 0.0387 & \(\pm\) 0.0063 & \(\pm\) 0.0613 & \\
**Phikon** & 0.4704 & **0.3943** & 0.3988 & 0.5323 & 0.277 & 0.1451 & 0.213 & 0.542 & 0.2443 & 0.3575 \\  & \(\pm\) 0.0672 & \(\pm\) 0.0123 & \(\pm\) 0.0598 & \(\pm\) 0.0607 & \(\pm\) 0.0098 & \(\pm\) 0.0851 & \(\pm\) 0.0062 & \(\pm\) 0.0177 & \(\pm\) 0.0632 & \\
**GigaPath** & 0.5222 & 0.3749 & 0.4415 & 0.5297 & 0.2876 & 0.1609 & 0.2207 & 0.5506 & 0.2464 & 0.3705 \\  & \(\pm\) 0.0641 & \(\pm\) 0.0103 & \(\pm\) 0.058 & \(\pm\) 0.0376 & \(\pm\) 0.0099 & \(\pm\) 0.0777 & \(\pm\) 0.0402 & \(\pm\) 0.0108 & \(\pm\) 0.0526 & \\
**CONCH** & 0.5175 & 0.3784 & 0.4428 & 0.5766 & 0.3215 & 0.1431 & 0.1738 & 0.5581 & 0.2554 & 0.3742 \\  & \(\pm\) 0.0602 & \(\pm\) 0.0124 & \(\pm\) 0.0657 & \(\pm\) 0.0519 & \(\pm\) 0.0062 & \(\pm\) 0.0665 & \(\pm\) 0.0544 & 0.0081 & \(\pm\) 0.0605 & \\
**REMEDIS** & 0.5116 & 0.3526 & **0.4621** & 0.5885 & 0.319 & 0.1129 & 0.2303 & 0.562 & 0.2521 & 0.3768 \\  & \(\pm\) 0.0594 & \(\pm\) 0.0073 & \(\pm\) 0.0555 & \(\pm\) 0.0253 & \(\pm\) 0.0101 & \(\pm\) 0.0846 & \(\pm\) 0.0393 & \(\pm\) 0.0057 & \(\pm\) 0.0601 & \\
**Virchow2** & 0.5378 & 0.3772 & 0.4237 & 0.5565 & 0.281 & **0.1779** & **0.2428** & 0.5641 & 0.2582 & 0.3799 \\  & \(\pm\) 0.0685 & \(\pm\) 0.007 & \(\pm\) 0.0525 & \(\pm\) 0.0152 & \(\pm\) 0.0162 & \(\pm\) 0.077 & \(\pm\) 0.0361 & \(\pm\) 0.0069 & \(\pm\) 0.0504 & \\
**UNI** & 0.538 & 0.3513 & 0.451 & 0.6089 & 0.2921 & 0.1679 & 0.235 & 0.5357 & 0.2456 & 0.3806 \\  & \(\pm\) 0.0603 & \(\pm\) 0.0162 & \(\pm\) 0.0387 & \(\pm\) 0.0294 & \(\pm\) 0.0191 & \(\pm\) 0.0641 & \(\pm\) 0.0381 & \(\pm\) 0.0057 & \(\pm\) 0.058 & \\
**Virchow** & 0.5309 & 0.3447 & 0.4448 & 0.6089 & 0.3275 & 0.1419 & 0.2307 & 0.5643 & **0.2617** & 0.3839 \\  & \(\pm\) 0.0764 & \(\pm\) 0.0117 & \(\pm\) 0.0501 & \(\pm\) 0.0165 & \(\pm\) 0.00254 & \(\pm\) 0.0669 & \(\pm\) 0.0036 & \(\pm\) 0.0091 & \(\pm\) 0.0537 & \\
**UNIV1.5** & 0.555 & 0.3654 & 0.434 & 0.6025 & **0.336** & 0.1742 & 0.2166 & 0.5634 & 0.2515 & 0.3887 \\  & \(\pm\) 0.0763 & \(\pm\) 0.0098 & \(\pm\) 0.0568 & \(\pm\) 0.0385 & \(\pm\) 0.0179 & \(\pm\) 0.0568 & \(\pm\) 0.0337 & \(\pm\) 0.0054 & \(\pm\) 0.0434 & \\
**H-Optimus-0** & **0.5564** & 0.3829 & 0.4445 & **0.6502** & 0.2922 & 0.1731 & 0.2402 & **0.5654** & 0.2555 & **0.3956** \\  & \(\pm\) 0.0777 & \(\pm\) 0.0049 & \(\pm\) 0.0563 & \(\pm\) 0.0326 & \(\pm\) 0.0063 & \(\pm\) 0.0777 & \(\pm\) 0.0348 & \(\pm\) 0.0084 & \(\pm\) 0.0522 & \\ \hline \hline \end{tabular}
\end{table}
Table A14: **HEST-Benchmark evaluated using XGBoost regression.** Model performance measured with Pearson correlation. Best is **bold**, second best is underlined.

## References

* [1] Xesus Abalo et al. _Human squamous cell carcinoma_, _Visium_. Version V1. 2021. doi: 10.17632/2bh5fchcv6.1. url: https://data.mendeley.com/datasets/2bh5fchcv6/1.
* [2] H. A. Abdel-Hafiz et al. "Y chromosome loss in cancer drives growth by evasion of adaptive immunity". In: _Nature_ 619.7970 (2023), pp. 624-631. doi: 10.1038/s41586-023-06083-w.
* [3] Areej Alsaafin et al. "Learning to predict RNA sequence expressions from whole slide images with applications for search and classification". In: _Communications Biology_ 6.1 (2023), p. 304.
* [4] Alma Andersson et al. "Spatial deconvolution of HER2-positive breast cancer delineates tumor-associated cell type interactions". In: _Nat. Commun._ 12.6012 (Oct. 2021), pp. 1-14. issn: 2041-1723. doi: 10.1038/s41467-021-26271-2.
* [5] Tallulah S. Andrews et al. "Single-cell, single-nucleus, and spatial transcriptomics characterization of the immunological landscape in the healthy and PSC human liver". In: _J. Hepatol._ 80.5 (May 2024), pp. 730-743. issn: 1600-0641. doi: 10.1016/j.jhep.2023.12.023. eprint: 38199298.
* [6] Zaneta Andrusivova and Yuhang Fan. _Ex-ST_. Version V1. 2023. doi: 10.17632 / nrbsxrk@mp.1. url: https://data.mendeley.com/datasets/nrbsxrk8@mp/1.
* [7] Paige E. Anton et al. "Binge ethanol exposure in advanced age elevates neuroinflammation and early indicators of neurodegeneration and cognitive impairment in female mice". In: _Brain Behav. Immun._ 116 (Feb. 2024), pp. 303-316. issn: 0889-1591. doi: 10.1016/j.bbi.2023.12.034.
* [8] Guilherme Aresta et al. "Bach: Grand challenge on breast cancer histology images". In: _Medical image analysis_ 56 (2019), pp. 122-139.
* [9] Michaela Asp, Joseph Bergenstrahle, and Joakim Lundeberg. "Spatially Resolved Transcriptomes--Next Generation Tools for Tissue Exploration". In: _BioEssays_ 42.10 (Oct. 2020), p. 1900221. issn: 0265-9247. doi: 10.1002/bies.201900221.
* [10] Michaela Asp et al. "A Spatiotemporal Organ-Wide Gene Expression and Cell Atlas of the Developing Human Heart". In: _Cell_ 179.7 (Dec. 2019), pp. 1647-166019. issn: 1097-4172. doi: 10.1016/j.cell.2019.11.025. eprint: 31835037.
* [11] Shekoofeh Azizi et al. "Robust and data-efficient generalization of self-supervised machine learning for diagnostic imaging". In: _Nature Biomedical Engineering_ (2023), pp. 1-24.
* [12] Sunil Badve et al. "FOXA1 expression in breast cancer--correlation with luminal subtype A and survival". In: _Clinical cancer research_ 13.15 (2007), pp. 4415-4421.
* [13] S Bandaru et al. "Targeting filamin B induces tumor growth and metastasis via enhanced activity of matrix metalloproteinase-9 and secretion of VEGF-A". In: _Oncogenesis_ 3.9 (2014), e119-e119.
* [14] Peter Bankhead et al. "QuPath: Open source software for digital pathology image analysis". In: _Scientific Reports_ 7 (Dec. 2017). doi: 10.1038/s41598-017-17204-5.
* [15] Carlo Alberto Barbano et al. "UniToPatho, a labeled histopathological dataset for colorectal polyps classification and adenoma dysplasia grading". In: _arXiv_ (Jan. 2021). doi: 10.1109/ICIP42928.2021.9506198. eprint: 2101.09991.
* [16] Enrico R. Barrozo et al. "SARS-CoV-2 niches in human placenta revealed by spatial transcriptomics". In: _Med_ 4.9 (Sept. 2023), 612-634.e4. issn: 2666-6340. doi: 10.1016/j.medj.2023.06.003.
* [17] Enrico R. Barrozo et al. "Zika virus co-opts microRNA networks to persist in placental niches detected by spatial transcriptomics". In: _Am. J. Obstet. Gynecol._ 230.2 (Feb. 2024), pp. 2511-25117. ISSN: 1097-6868. doi: 10.1016/j.ajog.2023.08.012. eprint: 37598997.
* [18] Babak Ehteshami Bejnordi et al. "Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer". In: _JAMA_ 318.22 (2017), pp. 2199-2210.
* [19] Andrew K. Beppu et al. "Epithelial plasticity and innate immune activation promote lung tissue remodeling following respiratory viral infection". In: _Nat. Commun._ 14.5814 (Sept. 2023), pp. 1-16. issn: 2041-1723. doi: 10.1038/s41467-023-41387-3.

* [20] Ludvig Bergenstrahle et al. "Super-resolved spatial transcriptomics by deep data fusion". In: _Nat. Biotechnol._ 40 (Apr. 2022), pp. 476-479. issn: 1546-1696. doi: 10.1038/s41587-021-01075-3.
* [21] Quentin Blampey et al. "Sopa: a technology-invariant pipeline for analyses of image-based spatial omics". In: _Nature Communications_ 15 (2024). Publisher: Nature Publishing Group, p. 4981. doi: 10.1038/s41467-024-48981-z. url: https://www.nature.com/articles/s41467-024-48981-z.
* [22] Nadia Brancati et al. "BRACS: A Dataset for BReAst Carcinoma Subtyping in H&E Histology Images". In: _arXiv preprint arXiv:2111.04740_ (2021).
* [23] Wouter Bulten et al. "Artificial intelligence for diagnosis and Gleason grading of prostate cancer: the PANDA challenge". In: _Nature Medicine_ 28.1 (2022), pp. 154-163.
* [24] Andrew Butler et al. "Integrating single-cell transcriptomic data across different conditions, technologies, and species". In: _Nat. Biotechnol._ 36 (May 2018), pp. 411-420. issn: 1546-1696. doi: 10.1038/nbt.4096.
* [25] V. H. Canela et al. "A spatially anchored transcriptomic atlas of the human kidney papilla identifies significant immune injury in patients with stone disease". In: _Nature Communications_ 14.1 (2023), p. 4140. doi: 10.1038/s41467-023-41340-8.
* [26] Jiaji George Chen et al. "Giotto Suite: a multi-scale and technology-agnostic spatial multi-omics analysis ecosystem". In: _bioRxiv_ (Nov. 2023), p. 2023.11.26.568752. eprint: 2023.11.26.568752. url: https://doi.org/10.1101/2023.11.26.568752.
* [27] Liang-Chieh Chen et al. "Rethinking Atrous Convolution for Semantic Image Segmentation". In: _arXiv_ (June 2017). doi: 10.48550/arXiv.1706.05587. eprint: 1706.05587.
* [28] Richard J Chen et al. "Pan-cancer integrative histology-genomic analysis via multimodal deep learning". In: _Cancer Cell_ 40.8 (2022), pp. 865-878.
* [29] Richard J. Chen et al. "Towards a General-Purpose Foundation Model for Computational Pathology". In: _Nature Medicine_ (2024).
* [30] Ting Chen et al. "A simple framework for contrastive learning of visual representations". In: _International conference on machine learning_. PMLR. 2020, pp. 1597-1607.
* [31] Xinlei Chen, Saining Xie, and Kaiming He. "An Empirical Study of Training Self-Supervised Vision Transformers". In: _arXiv_ (Apr. 2021). doi: 10.48550/arXiv.2104.02057. eprint: 2104.02057.
* [32] Youngmin Chung et al. "Accurate Spatial Gene Expression Prediction by integrating Multi-resolution features". In: _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_. 2024, pp. 11591-11600.
* [33] Ozan Ciga, Tony Xu, and Anne Louise Martel. "Self supervised contrastive learning for digital histopathology". In: _Machine Learning with Applications_ 7 (2022).
* [34]_Demo 10x Vision dataset for STQ_. [Online; accessed 16. May 2024]. Feb. 2024. doi: 10.5281/zenodo.10654467.
* [35] Jia Deng et al. "Imagenet: A large-scale hierarchical image database". In: _2009 IEEE conference on computer vision and pattern recognition_. Ieee. 2009, pp. 248-255.
* [36] Sergii Domanskiy et al. "Nextflow Pipeline for Visium and H&E Data from Patient-Derived Xenogratt Samples". In: _bioRxiv_ (2023). doi: 10.1101/2023.07.27.550727. eprint: https://www.biorxiv.org/content/early/2023/07/30/2023.07.27.550727.full.pdf. https://www.biorxiv.org/content/early/2023/07/30/2023.07.27.550727.
* [37] Alexey Dosovitskiy et al. "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale". In: _International Conference on Learning Representations_. 2021. url: https://openreview.net/forum?id=YicbFdNTTy.
* [38] Amelie Echle et al. "Deep learning in cancer pathology: a new generation of clinical biomarkers". In: _British journal of cancer_ 124.4 (2021), pp. 686-696.
* [39] Omar SM El Nahhas et al. "Regression-based Deep-Learning predicts molecular biomarkers from pathology slides". In: _Nature communications_ 15.1 (2024), p. 1253.
* [40] Andrew Erickson et al. "Spatially resolved clonal copy number alterations in benign and malignant tissue". In: _Nature_ 608 (Aug. 2022), pp. 360-367. issn: 1476-4687. doi: 10.1038/s41586-022-05023-2.

* [41] Ricardo Melo Ferreira et al. "Integration of spatial and single-cell transcriptomics localizes epithelial cell-immune cross-talk in kidney injury". In: _JCI Insight_ 6.12 (June 2021). issn: 0021-9738. doi: 10.1172/jci.insight.147703.
* [42] Alexandre Filiot et al. "Scaling Self-Supervised Learning for Histopathology with Masked Image Modeling". In: _medRxiv_ (July 2023). doi: 10.1101/2023.07.21.23292757.
* [43] Marcos A. S. Fonseca et al. "Single-cell transcriptomic analysis of endometriosis". In: _Nat. Genet._ 55 (Feb. 2023), pp. 255-267. issn: 1546-1718. doi: 10.1038/s41588-022-01254-1.
* [44] R. Fu et al. "Spatial transcriptomic analysis delineates epithelial and mesenchymal subpopulations and transition stages in childhood ependymoma". In: _Neuro-Oncology_ 25.4 (2023), pp. 786-798. doi: 10.1093/neuonc/noad070.
* [45] Yu Fu et al. "Pan-cancer computational histopathology reveals mutations, tumor composition and prognosis". In: _Nature Cancer_ 1.8 (2020), pp. 800-810.
* [46] Jevgenij Gamper and Nasir Rajpoot. "Multiple Instance Captioning: Learning Representations from Histopathology Textbooks and Articles". In: _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_. 2021.
* [47] Jevgenij Gamper et al. "PanNuke: an open pan-cancer histology dataset for nuclei instance segmentation and classification". In: _European Congress on Digital Pathology_. Springer. 2019, pp. 11-19.
* [48] Jevgenij Gamper et al. "PanNuke Dataset Extension, Insights and Baselines". In: _arXiv preprint arXiv:2003.10778_ (2020).
* [49] Quentin Garrido et al. "Rankme: Assessing the downstream performance of pretrained self-supervised representations by their rank". In: _International Conference on Machine Learning_. PMLR. 2023, pp. 10929-10974.
* [50] Chandler D. Gatenbee et al. "Virtual alignment of pathology image series for multi-gigapixel whole slide images". In: _Nat. Commun._ 14.4502 (July 2023), pp. 1-14. issn: 2041-1723. doi: 10.1038/s41467-023-40218-9.
* [51] Julie Giraud et al. "TREM1+CD163+ regulatory myeloid cells expand in steatohepatitis-HCC and associate with poor prognosis and therapeutic resistance to immune checkpoint blockade". In: _bioRxiv_ (Nov. 2022), p. 2022.11.09.515839. eprint: 2022.11.09.515839. url: https://doi.org/10.1101/2022.11.09.515839.
* [52] K. H. 3rd Gouin et al. "An N-Cadherin 2 expressing epithelial cell subpopulation predicts response to surgery, chemotherapy and immunotherapy in bladder cancer". In: _Nature Communications_ 12.1 (2021), p. 4906. doi: 10.1038/s41467-021-25205-2.
* [53] Eva Gracia Villacampa et al. "Genome-wide spatial expression profiling in formalin-fixed tissues". In: _Cell Genomics_ 1.3 (Dec. 2021), p. 100065. issn: 2666-979X. doi: 10.1016/j.xgen.2021.100065.
* [54] Lalieh Haghverdi et al. "Batch effects in single-cell RNA-sequencing data are corrected by matching mutual nearest neighbors". In: _Nat. Biotechnol._ 36 (May 2018), pp. 421-427. issn: 1546-1696. doi: 10.1038/nbt.4091.
* [55] Bryan He et al. "Integrating spatial gene expression and breast tumour morphology via deep learning". In: _Nature biomedical engineering_ 4.8 (2020), pp. 827-834.
* [56] Kaiming He et al. "Deep residual learning for image recognition". In: _Proceedings of the IEEE conference on computer vision and pattern recognition_. 2016, pp. 770-778.
* [57] Cody N. Heiser et al. "Molecular cartography uncovers evolutionary and microenvironmental dynamics in sporadic colorectal tumors". In: _Cell_ 186.25 (Dec. 2023). Publisher: Elsevier, 5620-5637.e16. issn: 0092-8674. doi: 10.1016/j.cell.2023.11.006. url: https://doi.org/10.1016/j.cell.2023.11.006 (visited on 10/25/2024).
* [58] Jian Hu et al. "SpaGCN: Integrating gene expression, spatial location and histology to identify spatial domains and spatially variable genes by graph convolutional network". In: _Nature methods_ 18.11 (2021), pp. 1342-1351.
* [59] Zhi Huang et al. "A visual-language foundation model for pathology image analysis using medical Twitter". In: _Nature Medicine_ 29 (Aug. 2023), pp. 1-10. doi: 10.1038/s41591-023-02504-3.

* [60] Xinmi Huo et al. _Comprehensive AI Model Development for Gleason Grading: From Scanning, Cloud-Based Annotation to Pathologist-AI Interaction_. [Online; accessed 7. May 2024]. July 2022. doi: 10.2139/ssrn.4172090.
* [61] Fabian Horst et al. "CellViT: Vision Transformers for precise cell segmentation and classification". In: _Medical Image Analysis_ 94 (2024), p. 103143. issn: 1361-8415. doi: https://doi.org/10.1016/j.media.2024.103143. url: https://www.sciencedirect.com/science/article/pii/S1361841524000689.
* [62] Maximilian Iles, Jakub Tomczak, and Max Welling. "Attention-based Deep Multiple Instance Learning". In: _Proceedings of the 35th International Conference on Machine Learning_. 2018, pp. 2132-2141.
* [63] Amanda Janesick et al. "High resolution mapping of the tumor microenvironment using integrated single-cell, spatial and in situ analysis". In: _Nat. Commun._ 14.8353 (Dec. 2023), pp. 1-15. issn: 2041-1723. doi: 10.1038/s41467-023-43458-x.
* [64] Guillaume Jaume et al. "Multistrain Pretraining for Slide Representation Learning in Pathology". In: _Proceedings of the European Conference on Computer Vision (ECCV)_. Springer. 2024.
* [65] Guillaume Jaume et al. "Transcriptomics-guided Slide Representation Learning in Computational Pathology". In: _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)_. 2024.
* [66] Andrew L. Ji et al. "Multimodal Analysis of Composition and Spatial Architecture in Human Squamous Cell Carcinoma". In: _Cell_ 182.2 (July 2020), pp. 497-51422. issn: 1097-4172. doi: 10.1016/j.cell.2020.05.039. eprint: 32579974.
* [67] Kazumasa Kanemaru et al. "Spatially resolved multiomics of human cardiac niches". In: _Nature_ 619.7971 (July 2023), pp. 801-810. issn: 1476-4687. doi: 10.1038/s41586-023-06311-1. url: https://doi.org/10.1038/s41586-023-06311-1.
* [68] Mingu Kang et al. "Benchmarking Self-Supervised Learning on Diverse Pathology Datasets". In: _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_. 2023, pp. 3344-3354.
* [69] Panagiotis Karras et al. "A cellular hierarchy in melanoma uncouples growth and metastasis". In: _Nature_ 610 (Oct. 2022), pp. 190-198. issn: 1476-4687. doi: 10.1038/s41586-022-05242-7.
* [70] Claudia Kathe et al. "The neurons that restore walking after paralysis". In: _Nature_ 611 (Nov. 2022), pp. 540-547. issn: 1476-4687. doi: 10.1038/s41586-022-05385-7.
* [71] Jakob Nikolas Kather et al. "Deep learning can predict microsatellite instability directly from histology in gastrointestinal cancer". In: _Nature medicine_ 25.7 (2019), pp. 1054-1056.
* [72] Jakob Nikolas Kather et al. "Pan-cancer image-based detection of clinically actionable genetic alterations". In: _Nature Cancer_ 1.8 (2020), pp. 789-799.
* [73] Jakob Nikolas Kather et al. "Predicting survival from colorectal cancer histology slides using deep learning: A retrospective multicenter study". In: _PLoS Med._ 16.1 (Jan. 2019). doi: 10.1371/journal.pmed.1002730.
* ECCV 2020: 16th European Conference, Glasgow, UK, August 23-28, 2020, Proceedings, Part V_. Heidelberg, Germany: Springer-Verlag, 2020, pp. 491-507. issn: 978-3-030-58557-0. doi: 10.1007/978-3-030-58558-7_29.
* [75] Navid Alemi Koohbanani et al. "Self-Path: Self-supervision for Classification of Pathology Images with Limited Annotations". In: _IEEE Transactions on Medical Imaging_ (2021).
* [76] Ilya Korsunsky et al. "Fast, sensitive and accurate integration of single-cell data with Harmony". In: _Nat. Methods_ 16 (Dec. 2019), pp. 1289-1296. issn: 1548-7105. doi: 10.1038/s41592-019-0619-0.
* [77] Michal Koziarski et al. "DiagSet: a dataset for prostate cancer histopathological image classification". In: _Sci. Rep._ 14.6780 (Mar. 2024), pp. 1-14. issn: 2045-2322. doi: 10.1038/s41598-024-52183-4.
* [78] Thomas Krausgruber et al. "Single-cell and spatial transcriptomics reveal aberrant lymphoid developmental programs driving granuloma formation". In: _Immunity_ 56.2 (Feb. 2023), 289-306.e7. issn: 1074-7613. doi: 10.1016/j.immuni.2023.01.014.

* [79] Blue B. Lake et al. "An atlas of healthy and injured cell states and niches in the human kidney". In: _Nature_ 619 (July 2023), pp. 585-594. issn: 1476-4687. doi: 10.1038/s41586-023-05769-3.
* [80] Rich Gang Li et al. "YAP induces a neonatal-like pro-renewal niche in the adult heart". In: _Nature cardiovascular research_ 3.3 (Mar. 2024), p. 283. doi: 10.1038/s44161-024-00428-w.
* [81] Xinmin Li and Cun-Yu Wang. "From bulk, single-cell to spatial RNA sequencing". In: _Int. J. Oral Sci._ 13.36 (Nov. 2021), pp. 1-6. issn: 2049-3169. doi: 10.1038/s41368-021-00146-0.
* [82] Wenyong Lin et al. "Single-nucleus ribonucleic acid-sequencing and spatial transcriptomics reveal the cardioprotection of Shexiang Baoxin Pill (SBP) in mice with myocardial ischemia-reperfusion injury". In: _Front. Pharmacol._ 14 (May 2023), p. 1173649. issn: 1663-9812. doi: 10.3389/fphar.2023.1173649.
* [83] Jana Lipkova et al. "Deep learning-enabled assessment of cardiac allograft rejection from endomyocardial biopsies". In: _Nature medicine_ 28.3 (2022), pp. 575-582.
* [84] Tong Liu et al. "Single cell profiling of primary and paired metastatic lymph node tumors in breast cancer patients". In: _Nat. Commun._ 13.6823 (Nov. 2022), pp. 1-17. issn: 2041-1723. doi: 10.1038/s41467-022-34581-2.
* [85] Ze Liu et al. "Swin transformer: Hierarchical vision transformer using shifted windows". In: _Proceedings of the IEEE/CVF International Conference on Computer Vision_. 2021, pp. 10012-10022.
* [86] Chiara Maria Lavinia Loeffler et al. "Artificial Intelligence-based Detection of FGFR3 Mutational Status Directly from Routine Histology in Bladder Cancer: A Possible Preselection for Molecular Testing?" In: _European Urology Focus_ 8.2 (2022), pp. 472-479.
* [87] Ming Y. Lu et al. "A Multimodal Generative AI Copilot for Human Pathology". In: _Nature_ (June 2024), pp. 1-3. issn: 1476-4687. doi: 10.1038/s41586-024-07618-3.
* [88] Ming Y Lu et al. "A visual-language foundation model for computational pathology". In: _Nature Medicine_ 30.3 (2024), pp. 863-874.
* [89] Ming Y Lu et al. "AI-based pathology predicts origins for cancers of unknown primary". In: _Nature_ 594.7861 (2021), pp. 106-110.
* [90] Ming Y Lu et al. "Data Efficient and Weakly Supervised Computational Pathology on Whole Slide Images". In: _Nature Biomedical Engineering_ (2020).
* [91] Ming Y Lu et al. "Data-efficient and weakly supervised computational pathology on whole-slide images". In: _Nature biomedical engineering_ 5.6 (2021), pp. 555-570.
* [92] Ming Y. Lu et al. "Visual Language Pretrained Multiple Instance Zero-Shot Transfer for Histopathology Images". In: _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)_. 2023, pp. 19764-19775.
* [93] Elo Madissoon et al. "A spatially resolved atlas of the human lung characterizes a gland-associated immune niche". In: _Nature Genetics_ 55.1 (2023), pp. 66-77.
* [94] Silas Maniatis et al. "Spatiotemporal dynamics of molecular pathology in amyotrophic lateral sclerosis". In: _Science_ 364.6435 (2019), pp. 89-93.
* [95] Luca Marconato et al. "SpatialData: an open and universal data framework for spatial omics". In: _Nat. Methods_ (Mar. 2024), pp. 1-5. issn: 1548-7105. doi: 10.1038/s41592-024-02212-x.
* [96] Maja Marklund. _Prostate needle biopsies pre- and post-ADT: Count matrices, histological-, and Androgen receptor immunohistochemistry images_. Version V1. 2022. doi: 10.17632/mdt8n2xgf4.1. url: https://data.mendeley.com/datasets/mdt8n2xgf4/1.
* [97] Vivien Marx. "Method of the Year: spatially resolved transcriptomics". In: _Nature methods_ 18.1 (2021), pp. 9-14.
* [98] Olivier Mauduit et al. "Spatial transcriptomics of the lacrimal gland features macrophage activity and epithelium metabolism as key alterations during chronic inflammation". In: _Front. Immunol._ 13 (Oct. 2022), p. 1011125. issn: 1664-3224. doi: 10.3389/fimmu.2022.1011125.
* [99] Kristen R Maynard et al. "Transcriptome-scale spatial gene expression in the human dorsolateral prefrontal cortex". In: _Nature neuroscience_ 24.3 (2021), pp. 425-436.

* [100] D. W. McKellar et al. "Large-scale integration of single-cell transcriptomic data captures transitional progenitor states in mouse skeletal muscle regeneration". In: _Communications Biology_ 4.1 (2021), p. 1280. doi: 10.1038/s42003-021-02756-8.
* [101] David W. McKellar et al. "Spatial mapping of the total transcriptome by in situ polyadenylation". In: _Nat. Biotechnol._ 41 (Apr. 2023), pp. 513-520. issn: 1546-1696. doi: 10.1038/s41587-022-01517-6.
* [102] Rohit Mehra et al. "Identification of GATA3 as a Breast Cancer Prognostic Marker by Global Gene Expression Meta-analysis". In: _Cancer Res._ 65.24 (Dec. 2005), pp. 11259-11264. issn: 0008-5472. doi: 10.1158/0008-5472.CAN-05-2495.
* [103] Maxime Meylan et al. "Tertiary lymphoid structures generate and propagate anti-tumor antibody-producing plasma cells in renal cell cancer". In: _Immunity_ 55.3 (Mar. 2022), 527-541.e5. issn: 1074-7613. doi: 10.1016/j.immuni.2022.02.001.
* [104] Reza Mirzazadeh et al. _Human ileum, Visium_. Version V1. 2021. doi: 10.17632 / v8s9nz948s.1. url: https://data.mendeley.com/datasets/v8s9nz948s/1.
* [105] Reza Mirzazadeh et al. "Spatially resolved transcriptomic profiling of degraded and challenging fresh frozen samples". In: _Nat. Commun._ 14.509 (Jan. 2023), pp. 1-16. issn: 2041-1723. doi: 10.1038/s41467-023-36071-5.
* [106] Acadia H. M. Moeyersoms et al. "Spatial Transcriptomics Identifies Expression Signatures Specific to Lacrimal Gland Adenoid Cystc Carcinoma Cells". In: _Cancers_ 15.12 (June 2023), p. 3211. issn: 2072-6694. doi: 10.3390/cancers15123211. eprint: 37370820.
* [107] Raktim Kumar Mondol et al. "hist2RNA: An Efficient Deep Learning Architecture to Predict Gene Expression from Breast Cancer Histopathology Images". In: _Cancers_ 15.9 (Apr. 2023), p. 2569. issn: 2072-6694. doi: 10.3390/cancers15092569.
* [108] Taku Monjo et al. "Efficient prediction of a spatial transcriptomics profile better characterizes breast cancer tissue sections without costly experimentation". In: _Sci. Rep._ 12.4133 (Mar. 2022), pp. 1-12. issn: 2045-2322. doi: 10.1038/s41598-022-07685-4.
* [109] Lambda Moses and Lior Pachter. "Museum of spatial transcriptomics". In: _Nat. Methods_ 19 (May 2022), pp. 534-546. issn: 1548-7105. doi: 10.1038/s41592-022-01409-2.
* [110] Michelli F. Oliveira et al. "Characterization of immune cell populations in the tumor microenvironment of colorectal cancer using high definition spatial profiling". In: _bioRxiv_ (2024). doi: 10.1101/2024.06.04.597233. eprint: https://www.biorxiv.org/content/early/2024/06/05/2024.06.04.597233.full.pdf. url: https://www.biorxiv.org/content/early/2024/06/05/2024.06.04.597233.
* [111] Aaron van den Oord, Yazhe Li, and Oriol Vinyals. "Representation learning with contrastive predictive coding". In: _arXiv preprint arXiv:1807.03748_ (2018).
* [112] Maxime Oquab et al. "Dinov2: Learning robust visual features without supervision". In: _arXiv preprint arXiv:2304.07193_ (2023).
* [113] Cantin Ortiz et al. "Molecular atlas of the adult mouse brain". In: _Sci. Adv._ 6.26 (June 2020). issn: 2375-2548. doi: 10.1126/sciadv.abb3446.
* [114] Hubert Pakula et al. "Distinct mesenchymal cell states mediate prostate cancer progression". In: _Nat. Commun._ 15.363 (Jan. 2024), pp. 1-21. issn: 2041-1723. doi: 10.1038/s41467-023-44210-1.
* [115] Giovanni Palla et al. "Squidpy: a scalable framework for spatial omics analysis". In: _Nat. Methods_ 19 (Feb. 2022), pp. 171-178. issn: 1548-7105. doi: 10.1038/s41592-021-01358-2.
* [116] Minxing Pang, Kenong Su, and Mingyao Li. "Leveraging information in spatial transcriptomics to predict super-resolution gene expression from histology images in tumors". In: _bioRxiv_ (Nov. 2021), p. 2021.11.28.470212. eprint: 2021.11.28.470212. url: https://doi.org/10.1101/2021.11.28.470212.
* [117] S. M. Parigi et al. "The spatial transcriptomic landscape of the healing mouse intestine following damage". In: _Nature Communications_ 13.1 (2022), p. 828. doi: 10.1038/s41467-022-28423-2.
* [118] Balint Armin Pataki et al. "HunCRC: annotated pathological slides to enhance deep learning applications in colorectal cancer screening". In: _Sci. Data_ 9.370 (June 2022), pp. 1-7. issn: 2052-4463. doi: 10.1038/s41597-022-01450-y.

* [119] Duy Pham et al. "Robust mapping of spatiotemporal trajectories and cell-cell interactions in healthy and diseased tissues". In: _Nat. Commun._ 14.7739 (Nov. 2023), pp. 1-25. issn: 2041-1723. doi: 10.1038/s41467-023-43120-6.
* [120] Jill Pilet et al. "Preneoplastic liver colonization by 11p15.5 altered mosaic cells in young children with hepatoblastoma". In: _Nat. Commun._ 14 (2023). doi: 10.1038/s41467-023-42418-9.
* [121] Md Mamunur Rahaman, Ewan K. A. Millar, and Erik Meijering. "Breast cancer histopathology image-based gene expression prediction using spatial transcriptomics data and deep learning". In: _Sci. Rep._ 13.13604 (Aug. 2023), pp. 1-11. issn: 2045-2322. doi: 10.1038/s41598-023-40219-0.
* [122] Anjali Rao et al. "Exploring tissue architecture using spatial transcriptomics". In: _Nature_ 596 (Aug. 2021), pp. 211-220. issn: 1476-4687. doi: 10.1038/s41586-021-03634-9.
* [123] Joseph Redmon et al. "You Only Look Once: Unified, Real-Time Object Detection". In: _2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)_. IEEE, 2016, pp. 27-30. doi: 10.1109/CVPR.2016.91.
* [124] Jing Ren et al. "Tumor protein D52 promotes breast cancer proliferation and migration via the long non-coding RNA NEAT1/microRNA-218-5p axis". In: _Annals of Translational Medicine_ 9.12 (2021).
* [125] Oliver Lester Saldanha et al. "Self-supervised attention-based deep learning for pan-cancer mutation prediction from histopathology". In: _NPJ Precision Oncology_ 7.1 (2023), p. 35.
* [126] A. Schabitz et al. "Spatial transcriptomics landscape of lesions from non-communicable inflammatory skin diseases". In: _Nat. Commun._ 13.7729 (Dec. 2022), pp. 1-13. issn: 2041-1723. doi: 10.1038/s41467-022-35319-w.
* [127] Benoit Schmauch et al. "A deep learning model to predict RNA-Seq expression of tumours from whole slide images". In: _Nature Communications_ 11.1 (2020).
* [128] Zhuchen Shao et al. "Transmil: Transformer based correlated multiple instance learning for whole slide image classification". In: _Advances in Neural Information Processing Systems_ 34 (2021).
* [129] Julio Silva-Rodriguez et al. "Going deeper through the Gleason scoring scale: An automatic end-to-end system for histology prostate grading and cribribrim pattern detection". In: _Comput. Methods Programs Biomed._ 195 (Oct. 2020), p. 105637. issn: 0169-2607. doi: 10.1016/j.cmpb.2020.105637.
* [130] Andrew H. Song et al. "Artificial intelligence for digital and computational pathology". In: _Nature Reviews Bioengineering_ (2023). issn: 2731-6092. doi: 10.1038/s44222-023-00096-8. URL: https://doi.org/10.1038/s44222-023-00096-8.
* [131] Fabio A. Spanhol et al. "A Dataset for Breast Cancer Histopathological Image Classification". In: _IEEE Trans. Biomed. Eng._ 63.7 (Oct. 2015), pp. 1455-1462. doi: 10.1109/TBME.2015.2496264.
* [132]_Spotiphy: generative modeling in single-cell spatial whole transcriptomics_. [Online; accessed 16. May 2024]. Jan. 2024. doi: 10.5281/zenodo.10520022.
* [133] Patrik L Stahl et al. "Visualization and analysis of gene expression in tissue sections by spatial transcriptomics". In: _Science_ 353.6294 (2016), pp. 78-82.
* [134] Patrik L. Stahl et al. "Visualization and analysis of gene expression in tissue sections by spatial transcriptomics". In: _Science_ 353.6294 (July 2016), pp. 78-82. issn: 0036-8075. doi: 10.1126/science.aaf2403.
* [135] Alberto Valdeolivas et al. "Charting the Heterogeneity of Colorectal Cancer Consensus Molecular Subtypes using Spatial Transcriptomics". In: _bioRxiv_ (Jan. 2023), p. 2023.01.23.525135. eprint: 2023.01.23.525135. URL: https://doi.org/10.1101/2023.01.23.525135.
* [136] Annika Vannan et al. "Image-based spatial transcriptomics identifies molecular niche dysregulation associated with distal lung remodeling in pulmonary fibrosis". In: _bioRxiv_ (2023). doi: 10.1101/2023.12.15.571954. eprint: https://www.biorxiv.org/content/early/2023/12/17/2023.12.15.571954.full.pdf. url: https://www.biorxiv.org/content/early/2023/12/17/2023.12.15.571954.
* [137] Bastiaan S Veeling et al. "Rotation Equivariant CNNs for Digital Pathology". In: (June 2018). arXiv: 1806.03962 [cs.CV].

* [138] Marco Vicari et al. "Spatial multimodal analysis of transcriptomes and metabolomics in tissues". In: _Nat. Biotechnol._ (Sept. 2023), pp. 1-5. issn: 1546-1696. doi: 10.1038/s41587-023-01937-y.
* [139] Eva Gracia Villacampa et al. "Genome-wide spatial expression profiling in formalin-fixed tissues". In: _Cell Genom._ 1.3 (Dec. 2021), p. 100065. issn: 2666-979X. doi: 10.1016/j.xgen.2021.100065. eprint: 36776149.
* [140] Karin E. de Visser and Johanna A. Joyce. "The evolving tumor microenvironment: From cancer initiation to metastatic outgrowth". In: _Cancer Cell_ 41.3 (Mar. 2023), pp. 374-403. issn: 1535-6108. doi: 10.1016/j.cell.2023.02.016.
* [141] Andrew P. Voigt et al. "Gene Expression Within a Human Choroidal Neovascular Membrane Using Spatial Transcriptomics". In: _Invest. Ophthalmol. Visual Sci._ 64.13 (Oct. 2023), p. 40. issn: 1552-5783. doi: 10.1167/iovs.64.13.40.
* [142] Eugene Vorontsov et al. "A foundation model for clinical-grade computational pathology and rare cancers detection". In: _Nature medicine_ (2024), pp. 1-12.
* [143] Sophia J. Wagner et al. "Transformer-based biomarker prediction from colorectal cancer histology: A large-scale multicentric study". In: _Cancer Cell_ 41.9 (Sept. 2023). issn: 1535-6108.
* [144] Hongyi Wang et al. "M2ORT: Many-To-One Regression Transformer for Spatial Transcriptomics Prediction from Histopathology Images". In: _arXiv_ (Jan. 2024). doi: 10.48550/arXiv.2401.10608. eprint: 2401.10608.
* [145] Shuo Wang et al. "Predicting EGFR mutation status in lung adenocarcinoma on computed tomography image using deep learning". In: _European Respiratory Journal_ 53.3 (2019).
* [146] Xiyue Wang et al. "Transformer-based unsupervised contrastive learning for histopathological image classification". In: _Medical Image Analysis_ 81 (2022), p. 102559.
* [147] Xiyue Wang et al. "TransPath: Transformer-Based Self-supervised Learning for Histopathological Image Classification". In: _International Conference on Medical Image Computing and Computer-Assisted Intervention_. Springer. 2021, pp. 186-195.
* [148] Jerry Wei et al. "A Petri Dish for Histopathology Image Analysis". In: _International Conference on Artificial Intelligence in Medicine_. Springer. 2021, pp. 11-24.
* [149] F. Alexander Wolf, Philipp Angerer, and Fabian J. Theis. "SCANPY: large-scale single-cell gene expression data analysis". In: _Genome Biol._ 19.1 (Dec. 2018), pp. 1-5. issn: 1474-760X. doi: 10.1186/s13059-017-1382-0.
* [150] Ido Wolf et al. "FOXA1: Growth inhibitor and a favorable prognostic factor in human breast cancer". In: _International journal of cancer_ 120.5 (2007), pp. 1013-1022.
* [151] Yi Xiao and Dihua Yu. "Tumor microenvironment as a therapeutic target in cancer". In: _Pharmacol. Ther._ 221 (May 2021), p. 107753. issn: 0163-7258. doi: 10.1016/j.pharmthera.2020.107753.
* [152] Ronald Xie et al. "Spatially Resolved Gene Expression Prediction from Histology Images via Bi-modal Contrastive Learning". In: _Advances in Neural Information Processing Systems_. Ed. by A. Oh et al. Vol. 36. Curran Associates, Inc., 2023, pp. 70626-70637. URL: https: //proceedings.neurips.cc/paper_files/paper/2023/file/df656d6ed77b565e8dcdfbf568aead0a-Paper-Conference.pdf.
* [153] Feng Xu et al. "Predicting axillary lymph node metastasis in early breast cancer using deep learning on primary tumor biopsy slides". In: _Frontiers in oncology_ 11 (2021), p. 759007.
* [154] Hanwen Xu et al. "A whole-slide foundation model for digital pathology from real-world data". In: _Nature_ 630 (June 2024), pp. 181-188. issn: 1476-4687. doi: 10.1038/s41586-024-07441-w.
* [155] Meilin Xue et al. "Schwann cells regulate tumor cells and cancer-associated fibroblasts in the pancreatic ductal adenocarcinoma microenvironment". In: _Nat. Commun._ 14.4600 (July 2023), pp. 1-18. issn: 2041-1723. doi: 10.1038/s41467-023-40314-w.
* [156] Jiahui Yu et al. "CoCa: Contrastive Captioners are Image-Text Foundation Models". In: 2022.
* [157] Daiwei Zhang et al. "Inferring super-resolution tissue architecture by integrating spatial transcriptomics with histology". In: _Nat. Biotechnol._ (Jan. 2024), pp. 1-6. issn: 1546-1696. doi: 10.1038/s41587-023-02019-9.

* [158] Yuqing Zhang, Giovanni Parmigiani, and W. Evan Johnson. "ComBat-seq: batch effect adjustment for RNA-seq count data". In: _NAR Genomics Bioinf. 2.3_ (Sept. 2020), lqaa078. issn: 2631-9268.
* [159] Edward Zhao et al. "Spatial transcriptomics at subspot resolution with BayesSpace". In: _Nat. Biotechnol._ 39 (Nov. 2021), pp. 1375-1384. issn: 1546-1696.
* [160] Weiqin Zhao et al. "Hist2Cell: Deciphering Fine-grained Cellular Architectures from Histology Images". In: _bioRxiv_ (Feb. 2024), p. 2024.02.17.580852.
* [161] Jinghao Zhou et al. "iBOT: Image BERT Pre-Training with Online Tokenizer". In: _International Conference on Learning Representations (ICLR)_ (2022).
* [162] Eric Zimmermann et al. "Virchow2: Scaling Self-Supervised Mixed Magnification Models in Pathology". In: 2024.