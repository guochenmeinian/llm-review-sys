# Statistically Valid Variable Importance Assessment through Conditional Permutations

 Ahmad Chamma

Inria, Universite Paris Saclay, CEA

ahmad.chamma@inria.fr

&Denis A. Engemann

Roche Pharma Research and Early Development,

Neuroscience and Rare Diseases,

Roche Innovation Center Basel,

F. Hoffmann-La Roche Ltd., Basel, Switzerland

denis.engemann@roche.com

Bertrand Thirion

Inria, Universite Paris Saclay, CEA

bertrand.thirion@inria.fr

###### Abstract

Variable importance assessment has become a crucial step in machine-learning applications when using complex learners, such as deep neural networks, on large-scale data. Removal-based importance assessment is currently the reference approach, particularly when statistical guarantees are sought to justify variable inclusion. It is often implemented with variable permutation schemes. On the flip side, these approaches risk misidentifying unimportant variables as important in the presence of correlations among covariates. Here we develop a systematic approach for studying Conditional Permutation Importance (CPI) that is model agnostic and computationally lean, as well as reusable benchmarks of state-of-the-art variable importance estimators. We show theoretically and empirically that _CPI_ overcomes the limitations of standard permutation importance by providing accurate type-I error control. When used with a deep neural network, _CPI_ consistently showed top accuracy across benchmarks. An experiment on real-world data analysis in a large-scale medical dataset showed that _CPI_ provides a more parsimonious selection of statistically significant variables. Our results suggest that _CPI_ can be readily used as drop-in replacement for permutation-based methods.

## 1 Introduction

Machine learning is an area of growing interest for biomedical research (Iniesta et al., 2016; Taylor and Tibshirani, 2015; Malley et al., 2011) for predicting biomedical outcomes from heterogeneous inputs (Hung et al., 2020; Zheng and Agresti, 2000; Giorgio et al., 2022; Sechidis et al., 2021). Biomarker development is increasingly focusing on multimodal data including brain images, genetics, biological specimens and behavioral data (Coravos et al., 2019; Siebert, 2011; Ye et al., 2008; Castillo-Barnes et al., 2018; Yang et al., 2022). Such high-dimensional settings with correlated inputs put strong pressure on model identification. With complex, often nonlinear models, it becomes harder to assess the role of features in the prediction, aka _variable importance_(Casalicchio et al., 2019; Altmann et al., 2010). In epidemiological and clinical studies, one is interested in _population-level_ feature importance, as opposed to instance-level feature importance.

In that context, variable importance is understood as _conditional_ importance, meaning that it measures the information carried by one variable on the outcome _given_ the others, as opposed to the easily accessible marginal importance of the variables. Conditional importance is necessary e.g. to assesswhether a given measurement is worth acquiring, on top of others, for a diagnostic or prognostic task. As the identification of relevant variables is model-dependent and potentially unstable, point estimates of variable importance are misleading. One needs confidence intervals of importance estimates or statistical guarantees, such as type-I error control, i.e. the percentage of non-relevant variables detected as relevant (false positives). This control depends on the accuracy of the p-values on variable importance being non-zero (Cribbie, 2000).

Within the family of removal-based importance assessment methods (Covert et al., 2022), a popular model-agnostic approach is _permutation_ variable importance, that measures the impact of shuffling a given variable on the prediction (Janitza et al., 2018). By repeating the _permutation_ importance analysis on permuted replicas of the variable of interest, importance values can be tested against the null hypothesis of being zero, yielding p-values that are valid under general distribution assumptions. Yet, statistical guarantees for permutation importance assessment do not hold in the presence of correlated variables, leading to selection of unimportant variables (Molnar et al., 2021; Hooker et al., 2021; Nicodemus et al., 2010; Stigler, 2005). For instance, the method proposed in (Mi et al., 2021) is a powerful variable importance evaluation scheme, but it does not control the rate of type-I error.

In this work, we propose a general methodology for studying the properties of Conditional Permutation Importance in biomedical applications alongside tools for benchmarking variable importance estimators:

* Building on the previous literature on CPI, we develop theoretical results for the limitations regarding Permutation Importance (PI) and advantages of conditional Permutation Importance (CPI) given correlated inputs (section 3).
* We propose a novel implementation for CPI allowing us to combine the potential advantages of highly expressive base learners for prediction (a deep neural network) and a comparably lean Random Forest model as a conditional probability learner (section 4).
* We conduct extensive benchmarks on synthetic and heterogeneous multimodal real-world biomedical data tapping into different correlation levels and data-generating scenarios for both classification and regression (section 5).
* We propose a reusable library for simulation experiments and real-world applications of our method on a public GitHub repo https://github.com/achamma723/Variable_Importance.

## 2 Related work

A popular approach to interpret black-box predictive models is based on _locally interpretable_, i.e. _instance-based_, models. _LIME_(Ribeiro et al., 2016) provides local interpretable model-agnostic explanations by locally approximating a given complex model with a linear model around the instance of interest. _SHAP_(Burzykowski, 2020) is a popular package that measures _local_ feature effects using the Shapley values from coalitional game theory.

However, global, i.e. population-level, explanations are better suited than instance-level explanations for epidemiological studies and scientific discovery in general. Many methods can be subsumed under the general category of removal-based approaches (Covert et al., 2022). _Permutation_ importance is defined as the decrease in a model score when the values of a single feature are randomly shuffled (Breiman, 2001). This procedure breaks the relationship between the feature and the outcome, thus the drop in model performance expresses the relevance of the feature. Janitza et al. (2018) use an ensemble of Random Forests with the sample space equally partitioned. They approximate the null distribution based on the observed importance scores to provide p-values. Yet, this coarse estimate of the null distribution can give unstable results. Recently, a generic approach has been proposed in (Williamson et al., 2021) that measures the loss difference between models that include or exclude a given variable, also applied with LOCO (Leave One Covariate Out) in the work by Lei et al. (2018). They show the asymptotic consistency of the model. However, their approach is intractable, given that it requires refitting the model for each variable. A simplified version has been proposed by Gao et al. (2022). However, relying on linear approximations, some statistical guarantees from (Williamson et al., 2021) are potentially lost.

Another recent paper by Mi et al. (2021) has introduced model-agnostic explanation for black-box models based on the _permutation_ approach. _Permutation_ importance (Breiman, 2001) can work with any learner. Moreover, it relies on a single model fit, hence it is an efficient procedure. Strobl et al. (2008) pointed out limitations with the _permutation_ approach in the face of correlated variables. As an alternative, they propose a _conditional permutation_ importance by shuffling the variable of interest conditionally on the other variables. However, the solution was specific to Random Forests, as it is based on bisecting the space with the cutpoints extracted during the building process of the forest.

With the _Conditional Randomization Test_ proposed by Candes et al. (2017), the association between the outcome \(y\) and the variable of interest \(x^{j}\) conditioned on \(\mathbf{x}^{-\mathbf{j}}\) is estimated. The variable of interest is sampled conditionally on the other covariates multiple times to compute a test statistic and p-values. However, this solution is limited to generalized linear models and is computationally expensive. Finally, a recent paper by Watson and Wright (2021) showed the necessity of conditional schemes and introduced a knockoff sampling scheme, whereby the variable of interest is replaced by its knockoff to monitor any drop in performance of the leaner used without refitting. This method is computationally inexpensive, and enjoys statistical guarantees from from (Lei et al., 2018). However, it depends on the quality of the knockoff sampling where even a relatively small distribution shift in knockoff generation can lead to large errors at inference time.

Other work has presented comparisons of select models within distinct communities (Liu et al., 2021; Chipman et al., 2010; Janitza et al., 2018; Mi et al., 2021; Altenmuller et al., 2021), however, lacking conceptualization from a unified perspective. In summary, previous work has established potential advantages of conditional permutation schemes for inference of variable importance. Yet, the lack of computationally scalable approaches has hampered systematic investigations of different permutation schemes and their comparison with alternative techniques across a broader range of predictive modeling settings.

## 3 Permutation importance and its limitations

### Preliminaries

NotationsWe will use the following system of notations. We denote matrices, vectors, scalar variables and sets by bold uppercase letters, bold lowercase letters, script lowercase letters, and calligraphic letters, respectively (e.g. \(\mathbf{X}\), \(\mathbf{x}\), \(x\), \(\mathcal{X}\)). We call \(\mu\) the function that maps the sample space \(\mathcal{X}\subset\mathbb{R}^{p}\) to the sample space \(\mathcal{Y}\subset\mathbb{R}\) and \(\hat{\mu}\) is an estimate of \(\mu\). Permutation procedures will be represented by (_perm_). We denote by \([\![n]\!]\) the set \(\{1,\ldots,n\}\).

Let \(\mathbf{X}\in\mathbb{R}^{n\times p}\) be a design matrix where the i-th row and the j-th column are denoted \(\mathbf{x_{i}}\) and \(\mathbf{x^{j}}\) respectively. Let \(\mathbf{X^{-j}}=(\mathbf{x^{1}},\ldots,\mathbf{x^{j-1}},\mathbf{x^{j+1}}, \ldots,\mathbf{x^{p}})\) be the design matrix, where the \(j^{th}\) column is removed, and \(\mathbf{X^{(j)}}=(\mathbf{x^{1}},\ldots,\mathbf{x^{j-1}},\{\mathbf{x^{j}}\}^{ perm},\mathbf{x^{j+1}},\ldots,\mathbf{x^{p}})\) the design matrix with the \(j^{th}\) column shuffled. The rows of \(\mathbf{X^{-j}}\) and \(\mathbf{X^{(j)}}\) are denoted \(\mathbf{x^{-j}_{i}}\) and \(\mathbf{x^{(j)}_{i}}\) respectively, for i \(\in[\![n]\!]\).

Problem settingMachine learning inputs are a design matrix \(\mathbf{X}\) and a target \(\mathbf{y}\in\mathbb{R}^{n}\) or \(\in\{0,1\}^{n}\) depending on whether it is a regression or a classification problem. Throughout the paper, we rely on an i.i.d. sampling train / test partition scheme where the \(n\) samples are divided into \(n_{train}\) training and \(n_{test}\) test samples and consider that \(\mathbf{X}\) and \(\mathbf{y}\) are restricted to the test samples - the training samples were used to obtain \(\hat{\mu}\).

### The _permutation_ approach leads to false detections in the presence of correlations

A known problem with _permutation_ variable importance is that if features are correlated, their importance is typically over-estimated (Strobl et al., 2008), leading to a loss of type-I error control. However, this loss has not been precisely characterized yet, which we will work through for the linear case. We use the setting of (Mi et al., 2021), where the estimator \(\hat{\mu}\), computed with empirical risk minimization under the training set, is used to assess variable importance on a new set of data (test set). We consider a regression model with a least-square loss function for simplicity. The importance of variable \(\mathbf{x^{j}}\) is computed as follows:

\[\hat{m}^{j}=\frac{1}{n_{test}}\sum_{i=1}^{n_{test}}\left((y_{i}-\hat{\mu}( \mathbf{x^{(j)}_{i}}))^{2}-(y_{i}-\hat{\mu}(\mathbf{x_{i}}))^{2}\right).\] (1)Let \(\varepsilon_{i}=y_{i}-\mu(\mathbf{x_{i}})\) for \(i\in[n_{test}]\). Re-arranging terms yields

\[\hat{m}^{j}= \frac{1}{n_{test}}\sum_{i=1}^{n_{test}}(\hat{\mu}(\mathbf{x_{i}})- \hat{\mu}(\mathbf{x_{i}^{(j)}}))(2\mu(\mathbf{x_{i}})-\hat{\mu}(\mathbf{x_{i}}) -\hat{\mu}(\mathbf{x_{i}^{(j)}})+2\varepsilon_{i}).\] (2)

Mi et al. (2021) argued that these terms vanish when \(n_{test}\rightarrow\infty\). But it is not the case as long as the training set is fixed. In order to get tractable computation, we assume that \(\mu\) and \(\hat{\mu}\) are linear functions: \(\mu(\mathbf{x})=\mathbf{x}\mathbf{w}\) and \(\hat{\mu}(\mathbf{x})=\mathbf{x}\hat{\mathbf{w}}\). Let us further consider that \(\mathbf{x^{j}}\) is a null feature, i.e. \(w^{j}=0\). This yields \(\mathbf{x}\mathbf{w}=x^{j}w^{j}+\mathbf{x^{-j}}\mathbf{w^{-j}}=\mathbf{x^{-j} }\mathbf{w^{-j}}\). Denoting the standard dot product by \(\langle.,.\rangle\), this leads to (Detailed proof of getting from Eq. 2 to Eq. 3 can be found in supplement section A)

\[\hat{m}^{j}=\frac{2\hat{w}^{j}}{n_{test}}\left<\mathbf{x^{j}}-\{\mathbf{x^{j} }\}^{perm},\mathbf{X^{-j}}(\mathbf{w^{-j}}-\hat{\mathbf{w}}^{-j})+\varepsilon\right>\] (3)

as \((\|\mathbf{x^{j}}\|^{2}-\|\{\mathbf{x^{j}}\}^{perm}\|^{2})=0\). Next, \(\frac{1}{n_{test}}(\{\mathbf{x^{j}}\}^{perm},\mathbf{X^{-j}}(\mathbf{w^{-j}}- \hat{\mathbf{w}}^{-j}))\to 0\) and \(\frac{1}{n_{test}}\langle\mathbf{x^{j}}-\{\mathbf{x^{j}}\}^{perm},\varepsilon\rangle\to 0\) when \(n_{test}\rightarrow\infty\) with speed \(\frac{1}{\sqrt{n_{test}}}\) from the Berry-Essen theorem, assuming that the first three moments of these quantities are bounded and that the test samples are i.i.d. Let us assume that the correlation within \(\mathbf{X}\) takes the following form: \(\mathbf{x^{j}}=\mathbf{X^{-j}}\mathbf{u}+\boldsymbol{\delta}\), where \(\mathbf{u}\in\mathbb{R}^{p-1}\) and \(\boldsymbol{\delta}\) is a random vector independent of \(\mathbf{X^{-j}}\). By contrast, \(\frac{2\hat{w}^{j}}{n_{test}}(\mathbf{x^{j}},\mathbf{X^{-j}}(\mathbf{w^{-j}}- \hat{\mathbf{w}}^{-j}))\) has a non-zero limit \(2\hat{w}^{j}\mathbf{u}^{T}Cov(\mathbf{X^{-j}})(\mathbf{w^{-j}}-\hat{\mathbf{w }}^{-j})\), where \(Cov(\mathbf{X^{-j}})=\lim_{n_{test}\rightarrow\infty}\frac{\mathbf{X^{-j}}^{T} \mathbf{X^{-j}}}{n_{test}}\) (remember that both \(\mathbf{w^{-j}}\) and \(\hat{\mathbf{w}}^{-j}\) are fixed, because the training set is fixed). Thus, the permutation importance of a null but correlated variable does not vanish when \(n_{test}\rightarrow\infty\), implying that this inference scheme will lead to false positives.

## 4 _Conditional sampling_-based feature importance

### Main result

We define the permutation of variable \(x^{j}\) conditional to \(\mathbf{x^{-j}}\), as a variable \(\tilde{x}^{j}\) that retains the dependency of \(x^{j}\) with respect to the other variables in \(\mathbf{x^{-j}}\), but where the independent part is shuffled, \(\mathbf{\tilde{x}^{(j)}}\) is the vector \(\mathbf{x}\) where \(x^{j}\) is replaced by \(\tilde{x}^{j}\). We propose two constructions below (see Fig. E1). In the case of regression, this leads to the following importance estimator:

\[\hat{m}^{j}_{CPI}=\frac{1}{n_{test}}\sum_{i=1}^{n_{test}}\left((y_{i}-\hat{\mu} (\mathbf{\tilde{x}_{i}^{(j)}}))^{2}-(y_{i}-\hat{\mu}(\mathbf{x_{i}}))^{2} \right).\] (4)

As noted by Watson and Wright (2021), this inference is correct, as in traditional permutation tests, as long as one wishes to perform inference conditional to \(\hat{\mu}\). However, the following proposition states that this inference has much wider validity in the asymptotic regime.

**Proposition**.: _Assuming that the estimator \(\hat{\mu}\) is obtained from a class of functions \(\mathcal{F}\) with sufficient regularity, i.e. that it meets conditions (A1, A2, A3, A4, B1 and B2) defined in supplementary material, the importance score \(\hat{m}^{j}_{CPI}\) defined in (4) cancels when \(n_{train}\rightarrow\infty\) and \(n_{test}\rightarrow\infty\) under the null hypothesis, i.e. the \(j\)-th variable is not significant for the prediction. Moreover, the Wald statistic \(z^{j}=\frac{mean(\hat{m}^{j}_{CPI})}{std(\hat{m}^{j}_{CPI})}\) obtained by dividing the mean of the importance score by its standard deviation asymptotically follows a standard normal distribution._

This implies that in the large sample limit, the p-value associated with \(z^{j}\) controls the type-I error rate for all optimal estimators in \(\mathcal{F}\).

The proof of the proposition is given in the supplement (section C). It consists in observing that the importance score defined in (4) is \(0\) for the class of learners discussed in (Williamson et al., 2021), namely those that meet a certain set of convergence guarantees and are invariant to arbitrary change of their \(j^{th}\) argument, conditional on the others. In the supplement, we also restate the precise technical conditions under which the importance score \(\hat{m}^{j}_{CPI}\) used is (asymptotically) valid, i.e. leads to a Wald-type statistic that behaves as a standard normal under the null hypothesis.

It is easy to see that for the setting in Sec. 3.2, all terms in Eq. 4 vanish with speed \(\frac{1}{\sqrt{n_{test}}}\).

### Practical estimation

Next, we present algorithms for computing conditional permutation importance. We propose two constructions for \(\tilde{x}^{j}\), the conditionally permuted counterpart of \(x^{j}\). The first one is additive: on test samples, \(x^{j}\) is divided into the predictable and random parts \(\tilde{x}^{j}=\mathbb{E}(x^{j}|\mathbf{x}^{-\mathbf{j}})+\left(x^{j}-\mathbb{E} (x^{j}|\mathbf{x}^{-\mathbf{j}})\right)^{perm}\), where the residuals of the regression of \(x^{j}\) on \(\mathbf{x}^{-\mathbf{j}}\) are shuffled to obtain \(\tilde{x}^{j}\). In practice, the expectation is obtained by a universal but efficient estimator, such as a random forest trained on the test set.

The other possibility consists in using a random forest (RF) model to fit \(x^{j}\) from \(\mathbf{x}^{-\mathbf{j}}\) and then sample the prediction within leaves of the RF.

Random shuffling is applied B times. For instance, using the additive construction, a shuffling of the residuals \(\tilde{\mathbf{c}}^{\mathbf{j},\mathbf{b}}\) for a given \(b\in\llbracket B\rrbracket\) allows to reconstruct the variable of interest as the sum of the predicted version and the shuffled residuals, that is

\[\mathbf{\tilde{x}}^{\mathbf{j},\mathbf{b}}=\mathbf{\hat{x}}^{\mathbf{j}}+ \tilde{\mathbf{c}}^{\mathbf{j},\mathbf{b}}.\] (5)

Let \(\mathbf{\tilde{X}}^{\mathbf{j},\mathbf{b}}=(\mathbf{x}^{\mathbf{1}},\ldots, \mathbf{x}^{\mathbf{j}-\mathbf{1}},\mathbf{\tilde{x}}^{\mathbf{j},\mathbf{b}},\mathbf{x}^{\mathbf{j}+\mathbf{1}},\ldots,\mathbf{x}^{\mathbf{p}})\in\mathbb{ R}^{n_{test}\times p}\) be the new design matrix including the reconstructed version of the variable of interest \(\mathbf{x}^{\mathbf{j}}\). Both \(\mathbf{\tilde{X}}^{\mathbf{j},\mathbf{b}}\) and the target vector \(\mathbf{y}\) are fed to the loss function in order to compute a loss score \(l_{i}^{j,b}\in\mathbb{R}\) defined by

\[l_{i}^{j,b}=\left\{\begin{array}{l}y_{i}\log\left(\frac{S(\hat{y}_{i})}{S( \hat{y}_{i}^{b})}\right)+(1-y_{i})\log\left(\frac{1-S(\hat{y}_{i})}{1-S(\hat{y} _{i}^{b})}\right)\\ (y_{i}-\hat{y}_{i}^{b})^{2}-(y_{i}-\hat{y}_{i})^{2}\end{array}\right.\] (6)

for binary and regression cases respectively where \(i\in\llbracket n_{test}\rrbracket\), \(j\in\llbracket p\rrbracket\), \(b\in\llbracket B\rrbracket\), \(i\) indexes a test sample of the dataset, \(\hat{y}_{i}=\hat{\mu}(\mathbf{x}_{\mathbf{i}})\) and \(\tilde{y}_{i}^{b}=\hat{\mu}(\mathbf{\hat{x}}_{\mathbf{i}}^{\mathbf{j},\mathbf{ b}})\) is the new fitted value following the reconstruction of the variable of interest with the \(b^{th}\) residual shuffled and \(\text{S}(x)=\frac{1}{1+e^{-x}}\).

The variable importance scores are computed as the double average over the number of permutations \(B\) and the number of test samples \(n_{test}\) (line 15 of Alg. 1), while their standard deviations are computed as the square root of the average over the test samples of the quadratic deviation over the number of permutations (line 17). Note that, unlike Williamson et al. (2021), the variance estimator is non-vanishing, and thus can be used as a plugin. A \(z_{CPI}^{j}\) statistic is then computed by dividing the mean of the corresponding importance scores with the corresponding standard deviation (line 18). P-values are computed using the cumulative distribution function of the standard normal distribution (line 19). The conditional sampling and inference steps are summarized in Algorithm 1. This leads to the _CPI-DNN_ method when \(\hat{\mu}\) is a deep neural network, or _CPI-RF_ when \(\hat{\mu}\) is a random forest. Supplementary analysis reporting the computational advantage of _CPI-DNN_ over a remove-and-relearn alternative a.k.a. _LOCO-DNN_, can be found in supplement (section D), which justifies its _computational leanness_.

## 5 Experiments & Results

In all experiments, we refer to the original implementation of the different methods in order to maintain a fair comparison. Regarding _Permfit-DNN, CPI-DNN_ and _CPI-RF_ models specifically, our implementation involves a 2-fold internal validation (the training set of further split to get validation set for hyperparameter tuning). The scores from different splits are thus concatenated to compute the final variable importance. We focus on the _Permfit-DNN_ and _CPI-DNN_ importance estimators that use a deep neural network as learner \(\hat{\mu}\), using standard permutation and algorithm 1, respectively. All experiments are performed with \(100\) runs. The evaluation metrics are detailed in the supplement (section E).

### Experiment 1: Type-I error control and accuracy when increasing variable correlation

We compare the performance of _CPI-DNN_ with that of _Permfit-DNN_ by applying both methods across different correlation scenarios. The data \(\{\mathbf{x}_{i}\}_{i=1}^{n}\) follow a Gaussian distribution with a prescribed covariance structure \(\mathbf{\Sigma}\) i.e. \(\mathbf{x}_{i}\sim\mathcal{N}(0,\mathbf{\Sigma})\forall i\in\llbracket n\rrbracket\). We consider a block-designed covariance matrix \(\mathbf{\Sigma}\) of 10 blocks with an equal correlation coefficient \(\rho\in\{0,0.2,0.5,0.8\}\) among the variables ofeach block. In this experiment, \(p=100\) and \(n=300\). The first variable of each of the first 5 blocks is chosen to predict the target \(y\) with the following model, where \(\epsilon\sim\mathcal{N}(0,\mathbf{I})\):

\[y_{i}=x_{i}^{1}+2\text{ log}(1+2(x_{i}^{11})^{2}+(x_{i}^{21}+1)^{2})+x_{i}^{31} x_{i}^{41}+\epsilon_{i},\ \forall i\in[\![n]\!]\]

The AUC score and type-I error are presented in Fig. 1. Power and computation time are reported in the supplement Fig. 1 - S1. Based on the AUC scores, _Permfit-DNN_ and _CPI-DNN_ showed virtually identical performance. However, _Permfit-DNN_ lost type-I error control when correlation in \(\mathbf{X}\) is increased, while _CPI-DNN_ always controlled the type-I error at the targeted rate.

### Experiment 2: Performance across different settings

In the second setup, we check if _CPI-DNN_ and _Permfit-DNN_ control the type-I error with an increasing total number of samples \(n\). The data are generated as previously, with a correlation \(\rho=0.8\). We fix the number of variables \(p\) to \(50\) while the number of samples \(n\) increases from \(100\) to \(1000\) with a step size of \(100\). We use 5 different models to generate the outcome \(\mathbf{y}\) from \(\mathbf{X}\): _classification_, _Plain linear_, _Regression with ReLu_, _Interactions only_ and _Main effects with interactions_. Further details regarding each data-generating scenario can be found in supplement (section G).

Figure 1: **CPI-DNN vs Permfit-DNN: Performance at detecting important variables on simulated data with \(n=300\) and \(p=100\). (A): The type-I error quantifies to which extent the rate of low p-values (\(p<0.05\)) exceeds the nominal false positive rate. (B): The AUC score measures to which extent variables are ranked consistently with the ground truth. Dashed line: targeted type-I error rate. Solid line: chance level.**

The AUC score and type-I error of _Permfit-DNN_ and _CPI-DNN_ are shown as a function of sample size in Fig. 2. The accuracy of the two methods was similar across data-generating scenarios, with a slight reduction in the AUC scores of _Permfit-DNN_ as compared to _CPI-DNN_. Only _CPI-DNN_ controlled the rate of type-I error in the different scenarios at the specified level of \(0.05\). Thus, _CPI-DNN_ provided an accurate ranking of the variables according to their importance score while, at the same time, controlling for the type-I error in all scenarios.

### Experiment 3: Performance benchmark across methods

In the third setup, we include _Permfit-DNN_ and _CPI-DNN_ in a benchmark with other state-of-the-art methods for variable importance using the same setting as in Experiment 2, while fixing the total number of samples \(n\) to \(1000\). We consider the following methods:

* Marginal Effects: A univariate linear model is fit to explain the response from each of the variables separately. The importance scores are then obtained from the ensuing p-values.
* Conditional-RF (Strobl et al., 2008): A conditional variable importance approach based on a Random Forest model. This method provides p-values.
* d\({}_{0}\)CRT (Liu et al., 2021; Nguyen et al., 2022): The Conditional Randomization Test with distillation, using a sparse linear or logistic learner.
* Lazy VI (Gao et al., 2022).
* Permfit-DNN (Mi et al., 2021).
* LOCO (Lei et al., 2018): This method applies the remove-and-retrain approach.
* cpi-knockoff (Watson and Wright, 2021): Similar to CPI-RF, but permutation steps are replaced by a sampling step with a knockoff sampler.
* CPI-RF: This corresponds to the method in Alg. 1, where \(\hat{\mu}\) is a Random Forest.
* CPI-DNN: This corresponds to the method in Alg. 1, where \(\hat{\mu}\) is a DNN.

The extensive benchmarks on baselines and competing methods that provide p-values are presented in Fig. 3. For type-I error, \(d_{0}\)_CRT, CPI-RF, CPI-DNN, LOCO_ and _cpi-knockoff_ provided reliable control, whereas Marginal effects, _Permfit-DNN_, _Conditional-RF_ and _Lazy VI_ showed less consistent results across scenarios. For AUC, we observed that marginal effects performed poorly, as they do not use a proper predictive model. _LOCO_ and _cpi-knockoff_ behave similarly. \(d_{0}\)_CRT_ performed well when the data-generating model was linear and did not include interaction effects. _Conditional-RF_ and _CPI-RF_ showed reasonable performance across scenarios. Finally, _Permfit-DNN_ and _CPI-DNN_ outperformed all the other methods, closely followed by _Lazy VI_.

Additional benchmarks on popular methods that do not provide p-values, e.g. BART (Chipman et al., 2010) or local and instance-based methods such as Shapley values (Kumar et al., 2020), are reported in the supplement (section H). The performance of these methods in terms of power and computation

Figure 2: **Model comparisons across data-generating scenarios**: The **(A)** type-I error and **(B)** AUC scores of _Permfit-DNN_ and _CPI-DNN_ are plotted as function of sample size for five different settings. The number \(n\) of samples increased from \(100\) to \(1000\) with a step size of \(100\). The number of variables \(p\) was set to 50. Dashed line: targeted type-I error rate. Solid line: chance level.

time are reported in the supplement Figs. 3 - S2 & 3 - S3 respectively. Additional inspection of power showed that across data generating scenarios, _CPI-DNN_, _Permfit-DNN_ and _conditional-RF_ showed strong results. _Marginal_ and _d0CRT_ performed only well in scenarios without interaction effects. _CPI-RF_, _epi-knockoff_, _LOCO_ and _Lazy VI_ performed poorly. Finally, to put estimated variable importance in perspective with model capacity, we benchmarked prediction performance of the underlying learning algorithms in the supplement Fig. 3 - S4.

### Experiment 4: _Permfit-DNN_ vs _Cpi-Dnn_ on Real Dataset UKBB

Large-scale simulations comparing the performance of _CPI-DNN_ and _Permfit-DNN_ are conducted in supplement (section L). We conducted an empirical study of variable importance in a biomedical application using the non-conditional permutation approach Permfit-DNN (no statistical guarantees for correlated inputs) and the safer CPI-DNN approach. A recent real-world data analysis of the UK Biobank dataset reported successful machine learning analysis of individual characteristics. The UK Biobank project (UKBB) curates phenotypic and imaging data from a prospective cohort of volunteers drawn from the general population of the UK [Constantinescu et al., 2022]. The data is provided by the UKBB operating within the terms of an Ethics and Governance Framework. The work focused on age, cognitive function and mood from brain images and social variables and put the ensuing models in relation to individual life-style choices regarding sleep, exercise, alcohol and tobacco [Dadi et al., 2021].

A coarse analysis of variable importance was presented, in which entire blocks of features were removed. It suggested that variables measuring brain structure or brain activity were less important for explaining the predictions of cognitive or mood outcomes than socio-demographic characteristics. On the other hand, brain imaging phenotypes were highly predictive of the age of a person, in line with the brain-age literature [Cole and Franke, 2017]. In this benchmark, we explored variable-level importance rankings provided by the _CPI-DNN_ and _Permfit-DNN_ methods.

The real-world empirical benchmarks on predicting personal characteristics and life-style are summarized in Fig. 4. Results in panel **(A)** suggest that highest agreement for rankings between _CPI-DNN_ and _Permfit-DNN_ was achieved for social variables (bottom left, orange squares). At the same time, _CPI-DNN_ flagged more brain-related variables as relevant (bottom right, circles). We next computed counts and percentage and broke down results by variable domain (Fig. 4, **B**). Naturally, the total relevance for brain versus social variables varied by outcome. However, as a tendency, _CPI-DNN_ seemed more selective as it flagged fewer variables as important (blue) beyond those flagged as important by both methods (light blue). This was more pronounced for social variables where _CPI-DNN_

Figure 3: **Extended model comparisons**: _CPI-DNN_ and _Permfit-DNN_ were compared to baseline models (outer columns) and competing approaches across data-generating scenarios (inner columns). Prediction tasks were simulated with \(n\) = 1000 and \(p\) = 50. **(A)**: Type-I error. **(B)**: AUC scores. Dashed line: targeted type-I error rate. Solid line: chance level.

sometimes added no further variables. As expected by the impact of aging on brain structure and function, brain data was most important for age-prediction compared to other outcomes. Interestingly, most disagreements between the methods occurred in this setting as _CPI_ rejected 16 out of 66 brain inputs that were found as important by _Permfit_. This outlines the importance of correlations between brain variables, that lead to spurious importance findings with _Permfit_. We further explored the utility of our approach for age-prediction from neuromagnetic recordings (Engemann et al., 2020) and observed that _CPI-DNN_ readily selected relevant frequency bands without fine-tuning the approach (section M in the supplement).

## 6 Discussion

In this work, we have developed a framework for studying the behavior of marginal and conditional permutation methods and proposed the _CPI-DNN_ method, that was inspired by the limitations of the _Permfit-DNN_ approach. Both methods build on top of an expressive DNN learner, and both methods turned out superior to competing methods at detecting relevant variables, leading to high AUC scores across various simulated scenarios. However, our theoretical results predicted that _Permfit-DNN_ would not control type-I error with correlated data, which was precisely what our simulation-based analyzes confirmed for different data-generating scenarios (Fig. 1 - 2). Other popular methods (Fig. 3) showed similar failures of type-I error control across scenarios or only worked well in a subset of tasks. Instead, _CPI-DNN_ achieved control of type-I errors by upgrading the _permutation_ to _conditional permutation_. The consequences were pronounced for correlated predictive features arising from generative models with product terms, which was visible even with a small fraction of data points for model training. Among alternatives, the _Lazy VI_ approach (Gao et al., 2022) obtained an accuracy almost as good as _Permfit-DNN_ and _CPI-DNN_ but with an unreliable type-I error control.

Taken together, our results suggest that _CPI-DNN_ may be a practical default choice for variable importance estimation in predictive modeling. A practical validation of the standard normal distribution assumption for the non important variables can be found in supplement (section N). The _CPI_ approach is generic and can be implemented for any combination of learning algorithms as a base learner or conditional means estimator. _CPI-DNN_ has a linear and quadratic complexity in the number of samples and variables, respectively. This is of concern when modeling the conditional distribution of the variable of interest which lends itself to high computational complexity. In our work, Random Forests proceed to be useful default estimators as they are computationally lean and their model complexity, given reasonable default choices implemented in standard software, can be well controlled by tuning the tree depth. In fact, our supplementary analyses (section O) suggest that proper hyperparameter tuning was sufficient to obtain good calibration of p-values. As a potential limitation, it is noteworthy the current configuration of our approach uses a deep neural network as

Figure 4: **Real-world empirical benchmark**: Prediction of personal characteristics (age, cognition, mood) and life-style habits (alcohol consumption, sleep, exercise & smoking) from various sociodemographic and brain-imaging derived phenotypes in a sample of \(n=8357\) volunteers from the UK Biobank. **(A)** plots variable rankings for _Permfit-DNN_ (x axis) versus _CPI-DNN_ (y axis) across all outcomes. Color: variable domain (brain versus social). Shape: variables classified by both methods as important (squares), unimportant (crosses) or by only one of the methods, _i.e._, _CPI-DNN_ (circles) or _Permfit-DNN_ (triangles). **(B)** presents a detailed breakdown of percentage and counts of variable classification split by variable domain.

the base learner. Therefore, in general, more samples might be needed for good model performance, hence, improved model interpretation.

Our real-world data analysis demonstrated that _CPI-DNN_ is readily applicable, providing similar variable rankings as _Permfit-DNN_. The differences observed are hard to judge as the ground truth is not known in this setting. Moreover, accurate variable selection is important to obtain unbiased interpretations which are relevant for data-rich domains like econometrics, epidemiology, medicine, genetics or neuroscience. In that context, it is interesting that recent work raised doubts about the signal complexity in the UK biobank dataset (Schulz et al., 2020), which could mean that underlying predictive patterns are spread out over correlated variables. In the subset of the UK biobank that we analysed, most variables actually had low correlation values (Fig. E4), which would explain why _CPI-DNN_ and _Permfit-DNN_ showed similar results. Nevertheless, our empirical results seem compatible with our theoretical results as _CPI-DNN_ flagged fewer variables as important, pointing at stricter control of type-I errors, which is a welcome property for biomarker discovery.

When considering two highly correlated variables \(\mathbf{x_{1}}\) and \(\mathbf{x_{2}}\), the corresponding conditional importance of both variables is 0. This problem is linked to the very definition of conditional importance, and not to the _CPI_ procedure itself. The only workaround is to eliminate, prior to importance analysis, degenerate cases where conditional importance cannot be defined. Therefore, possible future directions include inference on groups of variables, e.g, gene pathways, brain regions, while preserving statistical control offered by _CPI-DNN_.

AcknowledgementThis work has been supported by Bertrand Thirion and is supported by the KARAIB AI chair (ANR-20-CHIA-0025-01), and the H2020 Research Infrastructures Grant EBRAIN-Health 101058516. D.E. is a full-time employee of F. Hoffmann-La Roche Ltd.

## References

* Altenmuller et al. (2021) Marlene Sophie Altenmuller, Leonie Lucia Lange, and Mario Gollwitzer. When research is me-search: How researchers' motivation to pursue a topic affects laypeople's trust in science. _PLoS One_, 16(7):e0253911, July 2021. ISSN 1932-6203. doi: 10.1371/journal.pone.0253911.
* Altmann et al. (2010) Andre Altmann, Laura Tolosi, Oliver Sander, and Thomas Lengauer. Permutation importance: A corrected feature importance measure. _Bioinformatics_, 26(10):1340-1347, May 2010. ISSN 1367-4803. doi: 10.1093/bioinformatics/btq134.
* Bradley (1997) Andrew P. Bradley. The use of the area under the ROC curve in the evaluation of machine learning algorithms. _Pattern Recognition_, 30(7):1145-1159, July 1997. ISSN 0031-3203. doi: 10.1016/S0031-3203(96)00142-2.
* Breiman (2001) Leo Breiman. Random Forests. _Machine Learning_, 45(1):5-32, October 2001. ISSN 1573-0565. doi: 10.1023/A:1010933404324.
* Biecek and Burzykowski (2020) Przemyslaw Biecek and Tomasz Burzykowski. _Explanatory Model Analysis_. December 2020.
* Candes et al. (2017) Emmanuel Candes, Yingying Fan, Lucas Janson, and Jinchi Lv. Panning for Gold: Model-X Knockoffs for High-dimensional Controlled Variable Selection. _arXiv:1610.02351 [math, stat]_, December 2017.
* Casalicchio et al. (2019) Giuseppe Casalicchio, Christoph Molnar, and Bernd Bischl. Visualizing the Feature Importance for Black Box Models. In Michele Berlingerio, Francesco Bonchi, Thomas Gartner, Neil Hurley, and Georgiana Ifrim, editors, _Machine Learning and Knowledge Discovery in Databases_, Lecture Notes in Computer Science, pages 655-670, Cham, 2019. Springer International Publishing. ISBN 978-3-030-10925-7. doi: 10.1007/978-3-030-10925-7_40.
* Castillo-Barnes et al. (2018) Diego Castillo-Barnes, Javier Ramirez, Fermin Segovia, Francisco J. Martinez-Murcia, Diego Salas-Gonzalez, and Juan M. Gorriz. Robust Ensemble Classification Methodology for I123-Ioflupane SPECT Images and Multiple Heterogeneous Biomarkers in the Diagnosis of Parkinson's Disease. _Frontiers in Neuroinformatics_, 12:53, 2018. ISSN 1662-5196. doi: 10.3389/fninf.2018.00053.
* Chipman et al. (2010) Hugh A. Chipman, Edward I. George, and Robert E. McCulloch. BART: Bayesian additive regression trees. _Ann. Appl. Stat._, 4(1), March 2010. ISSN 1932-6157. doi: 10.1214/09-AOAS285.
* Casalicchio et al. (2019)James H. Cole and Katja Franke. Predicting Age Using Neuroimaging: Innovative Brain Ageing Biomarkers. _Trends Neurosci_, 40(12):681-690, December 2017. ISSN 1878-108X. doi: 10.1016/j.tins.2017.10.001.
* Constantinescu et al. (2022) Andrei-Emil Constantinescu, Ruth E. Mitchell, Jie Zheng, Caroline J. Bull, Nicholas J. Timpson, Borko Amulic, Emma E. Vincent, and David A. Hughes. A framework for research into continental ancestry groups of the UK Biobank. _Human Genomics_, 16(1):3, January 2022. ISSN 1479-7364. doi: 10.1186/s40246-022-00380-5.
* Coravos et al. (2019) Andrea Coravos, Sean Khozin, and Kenneth D. Mandl. Developing and adopting safe and effective digital biomarkers to improve patient outcomes. _npj Digit. Med._, 2(1):1-5, March 2019. ISSN 2398-6352. doi: 10.1038/s41746-019-0090-4.
* Covert et al. (2020) Ian Covert, Scott Lundberg, and Su-In Lee. Understanding Global Feature Contributions With Additive Importance Measures, October 2020.
* Covert et al. (2022) Ian Covert, Scott Lundberg, and Su-In Lee. Explaining by Removing: A Unified Framework for Model Explanation, May 2022.
* Cribbie (2000) Robert A. Cribbie. Evaluating the importance of individual parameters in structural equation modeling: The need for type I error control. _Personality and Individual Differences_, 29(3):567-577, September 2000. ISSN 0191-8869. doi: 10.1016/S0191-8869(99)00219-6.
* Dadi et al. (2021) Kamalaker Dadi, Gael Varoquaux, Josselin Houenou, Danilo Bzdok, Bertrand Thirion, and Denis Engemann. Population modeling with machine learning can enhance measures of mental health. _GigaScience_, 10(10):giab071, October 2021. ISSN 2047-217X. doi: 10.1093/gigascience/giab071.
* Engemann et al. (2020) Denis A Engemann, Oleh Kozynets, David Sabbagh, Guillaume Lemaitre, Gael Varoquaux, Franziskus Liem, and Alexandre Gramfort. Combining magnetoencephalography with magnetic resonance imaging enhances learning of surrogate-biomarkers. _eLife_, 9:e54055, May 2020. ISSN 2050-084X. doi: 10.7554/eLife.54055.
* Gao et al. (2022) Yue Gao, Abby Stevens, Rebecca Willet, and Garvesh Raskutti. Lazy Estimation of Variable Importance for Large Neural Networks, July 2022.
* Giorgio et al. (2022) Joseph Giorgio, William J. Jagust, Suzanne Baker, Susan M. Landau, Peter Tino, Zoe Kourtzi, and Alzheimer's Disease Neuroimaging Initiative. A robust and interpretable machine learning approach using multimodal biological data to predict future pathological tau accumulation. _Nat Commun_, 13(1):1887, April 2022. ISSN 2041-1723. doi: 10.1038/s41467-022-28795-7.
* Hooker et al. (2021) Giles Hooker, Lucas Mentch, and Siyu Zhou. Unrestricted Permutation forces Extrapolation: Variable Importance Requires at least One More Model, or There Is No Free Variable Importance, October 2021.
* Hung et al. (2020) Jui-Long Hung, Kerry Rice, Jennifer Kepka, and Juan Yang. Improving predictive power through deep learning analysis of K-12 online student behaviors and discussion board content. _Information Discovery and Delivery_, 48(4):199-212, January 2020. ISSN 2398-6247. doi: 10.1108/IDD-02-2020-0019.
* Iniesta et al. (2016) R. Iniesta, D. Stahl, and P. McGuffin. Machine learning, statistical learning and the future of biological research in psychiatry. _Psych Med_, 46(12):2455-2465, September 2016. ISSN 1469-8978. doi: 10.1017/S0033291716001367.
* Janitza et al. (2018) Silke Janitza, Ender Celik, and Anne-Laure Boulesteix. A computationally fast variable importance test for random forests for high-dimensional data. _Adv Data Anal Classif_, 12(4):885-915, December 2018. ISSN 1862-5355. doi: 10.1007/s11634-016-0276-4.
* Kumar et al. (2020) I. Elizabeth Kumar, Suresh Venkatasubramanian, Carlos Scheidegger, and Sorelle Friedler. Problems with Shapley-value-based explanations as feature importance measures, June 2020.
* Lei et al. (2018) Jing Lei, Max G'Sell, Alessandro Rinaldo, Ryan J. Tibshirani, and Larry Wasserman. Distribution-Free Predictive Inference for Regression. _Journal of the American Statistical Association_, 113(523):1094-1111, July 2018. ISSN 0162-1459. doi: 10.1080/01621459.2017.1307116.

Molei Liu, Eugene Katsevich, Lucas Janson, and Aaditya Ramdas. Fast and Powerful Conditional Randomization Testing via Distillation. _arXiv:2006.03980 [stat]_, June 2021.
* Louppe et al. [2013] Gilles Louppe, Louis Wehenkel, Antonio Sutera, and Pierre Geurts. Understanding variable importances in forests of randomized trees. In _Advances in Neural Information Processing Systems_, volume 26. Curran Associates, Inc., 2013.
* Malley et al. [2011] James D. Malley, Karen G. Malley, and Sinisa Pajevic. _Statistical Learning for Biomedical Data_. Cambridge University Press, February 2011. ISBN 978-1-139-49685-8.
* Mi et al. [2021] Xinlei Mi, Baiming Zou, Fei Zou, and Jianhua Hu. Permutation-based identification of important biomarkers for complex diseases via machine learning models. _Nat Commun_, 12(1):3008, May 2021. ISSN 2041-1723. doi: 10.1038/s41467-021-22756-2.
* Molnar et al. [2021] Christoph Molnar, Gunnar Konig, Julia Herbinger, Timo Freiesleben, Susanne Dandl, Christian A. Scholbeck, Giuseppe Casalicchio, Moritz Grosse-Wentrup, and Bernd Bischl. General Pitfalls of Model-Agnostic Interpretation Methods for Machine Learning Models, August 2021.
* Nguyen et al. [2022] Binh T. Nguyen, Bertrand Thirion, and Sylvain Arlot. A Conditional Randomization Test for Sparse Logistic Regression in High-Dimension, May 2022.
* Nguyen et al. [2020] Tuan-Binh Nguyen, Jerome-Alexis Chevalier, Bertrand Thirion, and Sylvain Arlot. Aggregation of Multiple Knockoffs. _arXiv:2002.09269 [math, stat]_, June 2020.
* Nicodemus et al. [2010] Kristin K. Nicodemus, James D. Malley, Carolin Strobl, and Andreas Ziegler. The behaviour of random forest permutation-based variable importance measures under predictor correlation. _BMC Bioinformatics_, 11(1):110, February 2010. ISSN 1471-2105. doi: 10.1186/1471-2105-11-110.
* Ribeiro et al. [2016] Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. "Why Should I Trust You?": Explaining the Predictions of Any Classifier, August 2016.
* Schulz et al. [2020] Marc-Andre Schulz, B. T. Thomas Yeo, Joshua T. Vogelstein, Janaina Mourao-Miranada, Jakob N. Kather, Konrad Kording, Blake Richards, and Danilo Bzdok. Different scaling of linear models and deep learning in UKBiobank brain images versus machine-learning datasets. _Nat Commun_, 11(1):4238, August 2020. ISSN 2041-1723. doi: 10.1038/s41467-020-18037-z.
* Sechidis et al. [2021] Konstantinos Sechidis, Matthias Kormaksson, and David Ohlssen. Using knockoffs for controlled predictive biomarker identification. _Statistics in Medicine_, 40(25):5453-5473, 2021.
* Siebert [2011] Janet Siebert. Integrated biomarker discovery: Combining heterogeneous data. _Bioanalysis_, 3(21):2369-2372, November 2011. ISSN 1757-6180. doi: 10.4155/bio.11.229.
* Stigler [2005] Stephen Stigler. Correlation and causation: A comment. _Perspect Biol Med_, 48(1 Suppl):S588-94, 2005. ISSN 0031-5982.
* Strobl et al. [2008] Carolin Strobl, Anne-Laure Boulesteix, Thomas Kneib, Thomas Augustin, and Achim Zeileis. Conditional variable importance for random forests. _BMC Bioinformatics_, 9(1):307, July 2008. ISSN 1471-2105. doi: 10.1186/1471-2105-9-307.
* Taylor and Tibshirani [2015] Jonathan Taylor and Robert J. Tibshirani. Statistical learning and selective inference. _Proceedings of the National Academy of Sciences_, 112(25):7629-7634, June 2015. doi: 10.1073/pnas.1507583112.
* Watson and Wright [2021] David S. Watson and Marvin N. Wright. Testing conditional independence in supervised learning algorithms. _Mach Learn_, 110(8):2107-2129, August 2021. ISSN 1573-0565. doi: 10.1007/s10994-021-06030-6.
* Williamson et al. [2021] Brian D. Williamson, Peter B. Gilbert, Noah R. Simon, and Marco Carone. A General Framework for Inference on Algorithm-Agnostic Variable Importance. _Journal of the American Statistical Association_, 0(0):1-14, November 2021. ISSN 0162-1459. doi: 10.1080/01621459.2021.2003200.
* Yang et al. [2022] Yuzhe Yang, Yuan Yuan, Guo Zhang, Hao Wang, Ying-Cong Chen, Yingcheng Liu, Christopher G. Tarolli, Daniel Crepeau, Jan Bukartyk, Mithri R. Junna, Aleksandar Videnovic, Terry D. Ellis, Melissa C. Lipford, Ray Dorsey, and Dina Katabi. Artificial intelligence-enabled detection and assessment of Parkinson's disease using nocturnal breathing signals. _Nat Med_, 28(10):2207-2215, October 2022. ISSN 1546-170X. doi: 10.1038/s41591-022-01932-x.
* Zhang et al. [2018]Jieping Ye, Kewei Chen, Teresa Wu, Jing Li, Zheng Zhao, Rinkal Patel, Min Bae, Ravi Janardan, Huan Liu, Gene Alexander, and Eric Reiman. Heterogeneous data fusion for alzheimer's disease study. In _Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining_, KDD '08, pages 1025-1033, New York, NY, USA, August 2008. Association for Computing Machinery. ISBN 978-1-60558-193-4. doi: 10.1145/1401890.1402012.
* Zheng and Agresti (2000) B. Zheng and A. Agresti. Summarizing the predictive power of a generalized linear model. _Stat Med_, 19(13):1771-1781, July 2000. ISSN 0277-6715. doi: 10.1002/1097-0258(20000715)19:13<1771::aid-sim485>3.0.co;2-p.

## Appendix A Supplement proof - getting from Eq. 2 to Eq. 3

\[\hat{m}^{j}= \frac{1}{n_{test}}\sum_{i=1}^{n_{test}}(\hat{\mu}(\mathbf{x}_{ \mathbf{i}})-\hat{\mu}(\mathbf{x}_{\mathbf{i}}^{\mathbf{j}}))(2\mu(\mathbf{x}_{ \mathbf{i}})-\hat{\mu}(\mathbf{x}_{\mathbf{i}})-\hat{\mu}(\mathbf{x}_{\mathbf{ i}}^{\mathbf{j}})+2\varepsilon_{i})\;2\] \[= \frac{1}{n_{test}}\sum_{i=1}^{n_{test}}(\mathbf{x}_{\mathbf{i}}^ {-\mathbf{j}}\hat{\mathbf{w}}^{-\mathbf{j}}+x_{i}^{j}\hat{w}^{-\mathbf{j}}- \mathbf{x}_{\mathbf{i}}^{-\mathbf{j}}\hat{\mathbf{w}}^{-\mathbf{j}}-\{x_{i}^ {j}\}^{perm}\hat{w}^{j})(2\mathbf{x}_{\mathbf{i}}^{-\mathbf{j}}\mathbf{w}^{- \mathbf{j}}-2\mathbf{x}_{\mathbf{i}}^{-\mathbf{j}}\hat{\mathbf{w}}^{-\mathbf{j }}-(x_{i}^{j}\hat{w}^{j}+\{x_{i}^{j}\}^{perm}\hat{w}^{j})+2\varepsilon_{i})\] \[= \frac{2\hat{w}^{j}}{n_{test}}\sum_{i=1}^{n_{test}}(x_{i}^{j}-\{x_{ i}^{j}\}^{perm})(\mathbf{x}_{\mathbf{i}}^{-\mathbf{j}}(\mathbf{w}^{-\mathbf{j}}- \hat{\mathbf{w}}^{-\mathbf{j}})+\varepsilon_{i})-\frac{\hat{w}^{j}((x_{i}^{j}) ^{2}-(\{x_{i}^{j}\}^{perm})^{2})}{\widetilde{n_{test}}\sum_{i=1}^{n_{test}}(x_{ i}^{j}-\{x_{i}^{j}\}^{perm})(\mathbf{x}_{\mathbf{i}}^{-\mathbf{j}}(\mathbf{w}^{- \mathbf{j}}-\hat{\mathbf{w}}^{-\mathbf{j}})+\varepsilon_{i})\;3}\]

## Appendix B Diagram of CPI constructions

Appendix C Conditional Permutation Importance (CPI) Wald statistic asymptotically controls type-I errors: hypotheses, theorem and proof

OutlineThe proof relies on the observation that the importance score defined in (4) is \(0\) in the asymptotic regime, where the permutation procedure becomes a sampling step, under the assumption that variable \(j\) is not conditionally associated with \(y\). Then all the proof focuses on the convergence of the finite-sample estimator to the population one. To study this, we use the framework developed in [20]. Note that the major difference with respect to other contributions [21] is that the ensuing inference is no longer conditioned on the estimated learner \(\hat{\mu}\). Next, we first restate the precise technical conditions under which the different importance scores considered are asymptotically valid, i.e. lead to a Wald-type statistic that behaves as a standard normal under the null hypothesis.

NotationsLet \(\mathcal{F}\) represent the class of functions from which a learner \(\mu:\mathbf{x}\mapsto y\) is sought.

Let \(P_{0}\) be the data-generating distribution and \(P_{n}\) is the empirical data distribution observed after drawing \(n\) samples (noted \(n_{train}\) in the main text; in this section, we denote it \(n\) to simplify notations). The separation between train and test samples is actually only relevant to alleviatesome technical conditions on the class of learners used. \(\mathcal{M}\) is the general class of distributions from which \(P_{1},\ldots,P_{n},P_{0}\) are drawn. \(\mathcal{R}:=\{c(P_{1}-P_{2}):c\in[0,\infty),P_{1},P_{2}\in\mathcal{M}\}\) is the space of finite signed measures generated by \(\mathcal{M}\). Let \(l\) be the loss function used to obtain \(\mu\). Given \(f\in\mathcal{F}\), \(l(f;P_{0})=\int l(f(\mathbf{x}),y)P_{0}(\mathbf{z})d\mathbf{z}\), where \(\mathbf{z}=(\mathbf{x},y)\). Let \(\mu_{0}\) denote a population solution to the estimation problem \(\mu_{0}\in\text{argmin}_{f\in\mathcal{F}}l(f;P_{0})\) and \(\hat{\mu}_{n}\) a finite sample estimate \(\hat{\mu}_{n}\in\text{argmin}_{f\in\mathcal{F}}l(f;P_{n})=\frac{1}{n}\sum_{( \mathbf{x},y)\in P_{n}}l(f(\mathbf{x}),y)\).

Let us denote by \(\dot{l}(\mu,P_{0};h)\) the Gateaux derivative of \(P\mapsto l(\mu,P)\) at \(P_{0}\) in the direction \(h\in\mathcal{R}\), and define the random function \(g_{n}:\mathbf{z}\mapsto\dot{l}(\hat{\mu}_{n},P_{0};\delta_{\mathbf{z}}-P_{0})- \dot{l}(\mu_{0},P_{0};\delta_{\mathbf{z}}-P_{0})\), where \(\delta_{\mathbf{z}}\) is the degenerate distribution on \(\mathbf{z}=(\mathbf{x},y)\).

**Hypotheses**

1. (Optimality) there exists some constant \(C>0\), such that for each sequence \(\mu_{1},\mu_{2},\cdots\in\mathcal{F}\) given that \(\|\mu_{n}-\mu_{0}\|\to 0,|l(\mu_{n},P_{0})-l(\mu_{0},P_{0})|<C\|\mu_{n}-\mu_{0}\|_{ \mathcal{F}}^{2}\) for each \(n\) large enough.
2. (Differentiability) there exists some constant \(\kappa>0\) such that for each sequence \(\epsilon_{1},\epsilon_{2},\cdots\in\mathbb{R}\) and \(h_{1},h_{2},\cdots\in\mathcal{R}\) satisfying \(\epsilon_{n}\to 0\) and \(\|h_{n}-h_{\infty}\|\to 0\), it holds that \[\sup_{\mu\in\mathcal{F}:\|\mu-\mu_{0}\|_{\mathcal{F}}<\kappa}\left|\frac{l(\mu,P_{0}+\epsilon_{n}h_{n})-l(\mu,P_{0})}{\epsilon_{n}}-\dot{l}(\mu,P_{0};h_{n} )\right|\to 0.\]
3. (Continuity of optimization) \(\|\mu_{P_{0}+\epsilon h}-\mu_{0}\|_{\mathcal{F}}=O(\epsilon)\) for each \(h\in\mathcal{R}\).
4. (Continuity of derivative) \(\mu\mapsto\dot{l}(\mu,P_{0};h)\) is continuous at \(\mu_{0}\) relative to \(\|.\|_{\mathcal{F}}\) for each \(h\in\mathcal{R}\).
5. (Minimum rate of convergence) \(\|\hat{\mu}_{n}-\mu_{0}\|_{\mathcal{F}}=o_{P}(n^{-1/4})\).
6. (Weak consistency) \(\int g_{n}(\mathbf{z})^{2}dP_{0}(\mathbf{z})=o_{P}(1)\).
7. (Limited complexity) there exists some \(P_{0}\)-Donsker class \(\mathcal{G}_{0}\) such that \(P_{0}(g_{n}\in\mathcal{G}_{0})\to 1\).

**Proposition** (Theorem 1 in [20]) If the above conditions hold, \(l(\hat{\mu}_{n},P_{n})\) is an asymptotically linear estimator of \(l(\mu_{0},P_{0})\) and \(l(\hat{\mu}_{n},P_{n})\) is non-parametric efficient.

Let \(P_{0}^{\star}\) be the distribution obtained by sampling the j-th coordinate of \(\mathbf{x}\) from the conditional distribution of \(q_{0}(x^{j}|\mathbf{x}^{-\underline{\mathsf{j}}})\), obtained after marginalizing over \(y\):

\[q_{0}(x^{j}|\mathbf{x}^{-\underline{\mathsf{j}}})=\frac{\int P_{0}(\mathbf{x}, y)dy}{\int P_{0}(\mathbf{x},y)dx^{j}dy}\]

\(P_{0}^{\star}(\mathbf{x},y)=q_{0}(x^{j}|\mathbf{x}^{-\underline{\mathsf{j}}}) \int P_{0}(\mathbf{x},y)dx^{j}\). Similarly, let \(P_{n}^{\star}\) denote its finite-sample counterpart. It turns out from the definition of \(\hat{m}_{CPI}^{j}\) in Eq. 4 that \(\hat{m}_{CPI}^{j}=l(\hat{\mu}_{n},P_{n}^{\star})-l(\hat{\mu}_{n},P_{n})\). It is thus the final-sample estimator of the population quantity \(m_{CPI}^{j}=l(\hat{\mu}_{0},P_{0}^{\star})-l(\hat{\mu}_{n},P_{0})\).

Given that \(\hat{m}_{CPI}^{j}=l(\hat{\mu}_{n},P_{n}^{\star})-l(\hat{\mu}_{0},P_{0}^{\star})- (l(\hat{\mu}_{n},P_{n})-l(\hat{\mu}_{0},P_{0}))+l(\hat{\mu}_{0},P_{0}^{\star})- l(\hat{\mu}_{0},P_{0})\), the estimator \(\hat{m}_{CPI}^{j}\) is asymptotically linear and non-parametric efficient.

The crucial observation is that under the j-null hypothesis, \(y\) is independent of \(x^{j}\) given \(\mathbf{x}^{-\underline{\mathsf{j}}}\). Indeed, in that case \(P_{0}(\mathbf{x},y)=q_{0}(x^{j}|\mathbf{x}^{-\underline{\mathsf{j}}})P_{0}(y| \mathbf{x}^{-\underline{\mathsf{j}}})P_{0}(\mathbf{x}^{-\underline{\mathsf{j}}})\) and \(P_{0}(x^{j}|\mathbf{x}^{-\underline{\mathsf{j}}},y)=P_{0}(x^{j}|\mathbf{x}^{- \underline{\mathsf{j}}})\), so that \(P_{0}^{\star}=P_{0}\). Hence, mean/variance of \(\hat{m}_{CPI}^{j}\)'s distribution provide valid confidence intervals for \(m_{CPI}^{j}\) and \(mean(\hat{m}_{CPI}^{j})\underset{n\to\infty}{\longrightarrow}0\). Thus, the Wald statistic \(\hat{z}_{CPJ}^{j}\) defined in section (4.2) converges to a standard normal distribution, implying that the ensuing test is valid.

In practice, hypothesis (B3), which is likely violated, is avoided by the use of cross-fitting as discussed in [20]: as stated in the main text, variable importance is evaluated on a set of samples not used for training. An interesting impact of the cross-fitting approach is that it reduces the hypotheses to (A1) and (A2), plus the following two:

1. (Minimum rate of convergence) \(\|\hat{\mu}_{n}-\mu_{0}\|_{\mathcal{F}}=o_{P}(n^{-1/4})\) on each fold of the sample splitting scheme.
2. (Weak consistency) \(\int g_{n}(\mathbf{z})^{2}dP_{0}(\mathbf{z})=o_{P}(1)\) on each fold of the sample splitting scheme.

## Appendix D Computational scaling of _Cpi-Dnn_ and leanness

_Computationally lean_ refers to two facts: (1) there is no need to refit the costly MLP learner to predict y unlike _LOCO-DNN_ (A removal-based method provided with our learner) as seen in Fig. E2. Both _CPI-DNN_ and _LOCO-DNN_ achieved a high AUC score and controlled the Type-I error in a highly correlated setting (\(\rho\)=\(0.8\)). However, in terms of computation time, _CPI-DNN_ is far ahead of _LOCO-DNN_, which validates our use of the permutation scheme. (2) The conditional estimation step involved for the conditional permutation procedure is done with an efficient RF estimator, leading to small time difference wrt _Permfit-DNN_; Overall we obtain the accuracy of LOCO-type procedures for the cost of a basic permutation scheme.

## Appendix E Evaluation Metrics

AUC score[1]: The variables are ordered by increasing p-values, yielding a family of \(p\) splits into relevant and non-relevant at various thresholds. AUC score measures the consistency of this ranking with the ground truth (\(p_{signals}\) predictive features versus \(p-p_{signals}\)).

Type-I error: Some methods output p-values for each of the variables, that measure the evidence against each variable being a null variable. This score checks whether the rate of low p-values of null variables exceeds the nominal false positive rate (set to \(0.05\)).

Power: This score reports the average proportion of informative variables detected (when considering variables with p-value \(<0.05\)).

Computation time: The average computation time per core on 100 cores.

Prediction Scores: As some methods share the same core to perform inference and with the data divided into a train/test scheme, we evaluate the predictive power for the different cores on the test set.

## Appendix F Supplement Figure 1 - Power & Computation time

Based on Fig. 1 - S1, both methods _Permfit-DNN_ and _CPI-DNN_ have almost similar power. In high correlation regime, Permfit-DNN yields more detections, but it does not control type-I errors (Fig. 1). Regarding computation time, _CPI-DNN_ is slightly more computationally expensive than _Permfit-DNN_.

## Appendix G Supplement Experiment 5.2 - Models

ClassificationThe signal \(\mathbf{X}\boldsymbol{\beta^{main}}\) is turned to binomial variables using the probit function \(\Phi\). \(\boldsymbol{\beta}^{main}\) and \(\boldsymbol{\beta^{quad}}\) are the two vectors with different lengths of regression coefficients having only \(n_{\text{signal}}=20\) non-zero coefficients, the true model. \(\boldsymbol{\beta^{main}}\) is used with the main effects while \(\boldsymbol{\beta^{quad}}\) is involved with the interaction effects. Following (Janitza et al., 2018), the \(\boldsymbol{\beta}\) values \(\in\{\boldsymbol{\beta^{main}},\boldsymbol{\beta^{quad}}\}\) are drawn i.i.d. from the set \(\mathcal{B}=\{\pm 3,\pm 2,\pm 1,\pm 0.5\}\).

\[y_{i}\sim Binomial(\Phi(\boldsymbol{x_{i}\boldsymbol{\beta^{main}}})),\;\forall i \in\llbracket n\rrbracket\]

Plain linear modelWe rely on a linear model, where \(\boldsymbol{\beta^{main}}\) is drawn as previously and \(\epsilon\) is the Gaussian additive noise \(\sim\mathcal{N}(0,\mathbf{I})\) with magnitude \(\sigma=\frac{\|\mathbf{X}\boldsymbol{\beta^{main}}\|_{2}}{SNR\sqrt{n}}\): \(y_{i}=\mathbf{x_{i}}\boldsymbol{\beta^{main}}+\sigma\epsilon_{i},\;\forall i \in\llbracket n\rrbracket\).

Regression with ReLuAn extra ReLu function is applied to the output of the Plain linear model: \(y_{i}=Relu(\mathbf{x_{i}\boldsymbol{\beta^{main}}}+\sigma\epsilon_{i}),\; \forall i\in\llbracket n\rrbracket\).

Interactions only modelWe compute the product of each pair of variables. The corresponding values are used as inputs to a linear model: \(y_{i}=\text{quad}(\mathbf{x_{i}},\boldsymbol{\beta^{quad}})+\sigma\epsilon_{i},\;\forall i\in\llbracket n\rrbracket\), where \(\text{quad}(\mathbf{x_{i}},\boldsymbol{\beta^{quad}})=\sum_{ \begin{subarray}{c}k,j=1\\ k<j\end{subarray}}^{P_{signals}}\boldsymbol{\beta^{quad}}_{k,j}x_{i}^{k}x_{i}^ {j}\). The magnitude \(\sigma\) of the noise is set to \(\frac{\|\text{quad}(\mathbf{X},\boldsymbol{\beta^{quad}})\|_{2}}{SNR\sqrt{n}}\). The non-zero \(\boldsymbol{\beta^{quad}}\) coefficients are drawn uniformly from \(\mathcal{B}\).

Figure 1: **Permfit-DNN vs CPI-DNN**: Performance at detecting important variables on simulated data under the setting of experiment 1, with \(n\) = 300 and \(p\) = 100. **(A)**: The power reports the average proportion of informative variables detected (p-value \(<0.05\)). **(B)**: The computation time is in seconds with (log10 scale) per core on 100 cores.

Main effects with InteractionsWe combine both Main and Interaction effects. The magnitude \(\sigma\) of the noise is set to \(\frac{||\mathbf{X}\boldsymbol{\beta}^{\text{main}}+\text{quad}(\boldsymbol{X}, \boldsymbol{\beta}^{\text{quad}})||_{2}}{SNR\sqrt{n}}\): \(y_{i}=\mathbf{x_{i}}\boldsymbol{\beta}^{\text{main}}+\text{quad}(\mathbf{x_{i} },\beta^{\text{quad}})+\sigma\epsilon_{i},\ \forall i\in[\![n]\!]\).

## Appendix H Supplement Figure 3 - Extended model comparisons

We also benchmarked the following methods deprived of statistical guarantees:

* Knockoffs (Candes et al., 2017; Nguyen et al., 2020): The knockoff filter is a variable selection method for multivariate models that controls the False Discovery Rate. The first step of this procedure involves sampling extra null variables that have a correlation structure similar to that of the original variables. A statistic is then calculated to measure the strength of the original variables versus their knockoff counterpart. We call this the knockoff statistic \(\mathbf{w}=\{w_{j}\}_{j=1}^{p}\) that is the difference between the importance of a given feature and the importance of its knockoff.
* Approximate Shapley values (Burzykowski, 2020): SHAP being an instance method, we relied on an aggregation (averaging) of the per-sample Shapley values.
* Shapley Additive Global importance (SAGE) (Covert et al., 2020): Whereas SHAP focuses on the _local interpretation_ by aiming to explain a model's individual predictions, SAGE is an extension to SHAP assessing the role of each feature in a _global interpretability_ manner. The SAGE values are derived by applying the Shapley value to a function that represents the predictive power contained in subsets of features.
* Mean Decrease of Impurity (Louppe et al., 2013): The importance scores are related to the impact that each feature has on the impurity function in each of the nodes.
* BART (Chipman et al., 2010): BART is an ensemble of additive regression trees. The trees are built iteratively using a back-fitting algorithm such as MCMC (Markov Chain Monte Carlo). By keeping track of covariate inclusion frequencies, BART can identify which components are more important for explaining \(\mathbf{y}\).

Based on AUC, we observe SHAP, SAGE and Mean Decrease of Impurity (MDI) perform poorly. These approaches are vulnerable to correlation. Next, Knockoff-Deep and Knockoff-Lasso perform well when the model does not include interaction effects. BART and Knockoff-Bart show fair performance overall.

Figure 3: S1: **Extended model comparisons**: State-of-the-art methods for variable importance not providing statistical guarantees in terms of p-values are compared (outer columns) and to competing approaches across data-generating scenarios (inner columns) using the settings of experiments 2 and 3. Prediction tasks were simulated with \(n\) = 1000 and \(p\) = 50. Solid line: chance level.

## Appendix I Supplement Figure 3 - Power

Based on the power computation, _Permfit-DNN_ and _CPI-DNN_ outperform the alternative methods. Thus, the use of the right learner leads to better interpretations.

## Appendix J Supplement Figure 3 - Computation time

The computation time of the different methods mentioned in this work (with and without statistical guarantees) is presented in Fig. 3 - S3 in seconds with (log10 scale). First, we compare _CPI-RF_, _cpi-knockoff_ and _LOCO_ based on a Random Forest learner with \(p\)=50. We see that _cpi-knockoff_ and _LOCO_ are faster than _CPI-DNN_. A possible reason is that _CPI-DNN_ uses an inner 2-fold internal validation for hyperparameter tuning (learning rate, L1 and L2 regularization) unlike the alternatives. Next, The DNN-based methods (_CPI-DNN_ and _Permfit-DNN_) are competitive with the alternatives that control type-I error (\(d_{0}CRT\), _cpi-knockoff_ and _LOCO_) despite the use of computationally le

Figure 3 - S3: **Extended model comparisons**: The computation times for the different methods (with and without statistical guarantees in terms of p-values) are reported in seconds with (log10 scale) per core on 100 cores. Prediction tasks were simulated with \(n\) = 1000 and \(p\) = 50.

Figure 3 - S2: **Extended model comparisons**: _CPI-DNN_ and _Permfit-DNN_ were compared to baseline models (outer columns) and to competing approaches across data-generating scenarios (inner columns). Convention about power as in Fig. 1 - S1. Prediction tasks were simulated with \(n\) = 1000 and \(p\) = 50.

## Appendix K Supplement Figure 3 - Prediction scores on simulated data

The results for computing the prediction accuracy using the underlying learners of the different methods are reported in Fig. 3 - S4. Marginal inference, performs poorly, as it is not a predictive approach. Linear models based on Lasso show a good performance in the no-interaction effect scenario. Non-linear models based on Random Forest and BART improve on the lasso-based models. Nevertheless, they fail to achieve a good performance in scenarios with interaction effects. The models equipped with a deep learner outperform the other methods.

Figure 3: S4: **Evaluating predictive power**: Performance of the different base learners used in the variable importance methods (**Marginal** = {Marginal effects}, **Lasso** = {Knockoff-Lasso}, **Random Forest** = {MDI, d0CRT, CPI-RF, Conditional-RF, cpi-knockoff, LOCO }, **BART** = {Knockoff-BART, BART} and **DNN** = {Knockoff-Deep, Permfit-DNN, CPI-DNN, Lazy VI}) on simulated data with \(n\) = 1000 and \(p\) = 50 in terms of **ROC-AUC** score for the classification and **R2** score for the regression.

## Appendix L Large scale simulations

In Figs. E3 and E4, we provide a comparison of the performance of both _Permfit-DNN_ and _CPI-DNN_ on the semi-simulated data from UK Biobank, with the design matrix consisting of the variables in the UK BioBank and the outcome is generated following a random selection of the true support, where \(n\)=\(8357\) and \(p\)=\(671\), and a large scale simulation with \(n\)=\(10000\), \(p\) = \(50\) and block-based correlation of coefficient \(\rho\) = \(0.8\). For the UKBB-based simulation, we see that _CPI-DNN_ achieves a higher AUC score and Power. However, both methods control the type-I error at the targeted level. To better understand the reason, we plotted (Fig. E3 Bottom panel) the histogram of the correlation values within the UKBB data: in this case, we consider a low-correlation setting which explains the good control for _Permfit-DNN_. In the large scale simulation where the correlation coefficient is set to 0.8, the difference is clear and only _CPI-DNN_ controls the type-I error.

## Appendix M Age prediction from brain activity (MEG) in Cam-CAN dataset

Following the work of Engemann et al. (2020), we have applied _CPI-DNN_ to the problem of age prediction from brain activity in different frequencies recorded with magnetoencephalography (MEG) in the Cam-CAN dataset. Without tweaking, the DNN learner reached a prediction performance on par with the published results as seen in Fig. E5. The p-values formally confirm aspects of the exploratory analysis in the original publication (importance of beta band).

Practical validation of the normal distribution assumption

In Fig. E7, we compared the distribution of the importance scores of a random picked non-significant variable using _CPI-DNN_ and _Permfit-DNN_ through histogram plots, and we can emphasize that the normal distribution assumption holds in practice.

Also, in Fig. E6, we plot the distribution of the p-values provided by _CPI-DNN_ and _Permfit-DNN_ vs the uniform distribution through QQ-plot. We can see that the p-values for _CPI-DNN_ are well calibrated and slightly deviated towards higher values. However, with _Permfit-DNN_ the p-values are not calibrated.

Random Forest for modeling the conditional distribution and resulting calibration

The use of the Random Forest model was to maintain a good non-linear model with time benefits for the prediction of the conditional distribution of the variable of interest. In Fig. E8, We can see that reducing the depth to 1 or 2, thus making the model overly simple, breaks the control of the type-I errors at the targeted level. With larger depths, the model becomes more conservative. Therefore, the max depth of the Random Forest is chosen based on the performance with 2-fold cross validation.