# A Unified Model and Dimension

for Interactive Estimation

Nataly Brukhim

Princeton University

nbrukhim@princeton.edu

&Miro Dudik

Microsoft Research

mudik@microsoft.com

Aldo Pacchiano

Broad Institute of MIT and Harvard & Boston University

apacchia@broadinstitute.org

&Robert Schapire

Microsoft Research

schapire@microsoft.com

###### Abstract

We study an abstract framework for interactive learning called _interactive estimation_ in which the goal is to estimate a target from its "similarity" to points queried by the learner. We introduce a combinatorial measure called _dissimilarity dimension_ which is used to derive learnability bounds in our model. We present a simple, general, and broadly-applicable algorithm, for which we obtain both regret and PAC generalization bounds that are polynomial in the new dimension. We show that our framework subsumes and thereby unifies two classic learning models: statistical-query learning and structured bandits. We also delineate how the dissimilarity dimension is related to well-known parameters for both frameworks, in some cases yielding significantly improved analyses.

## 1 Introduction

We study a general interactive learning protocol called _interactive estimation_. In this model, the learner repeatedly queries the environment with an element from a set of _alternatives_, and observes a stochastic reward whose expectation is given by an arbitrary measure of the "similarity" between the queried alternative and the unknown ground truth. Thus, in rough terms, the goal is to estimate a target from its similarity to queried alternatives. By studying such a general abstraction of interactive learning, we are able to reason about the properties of a very broad family of learning settings, and to make connections across a variety of contexts.

Our results are based on a combinatorial complexity measure we introduce called the _dissimilarity dimension_, which is used to derive learnability bounds in our model. Intuitively, this measure corresponds to the length of the longest sequence of alternatives in which each one has a similar suboptimal value of similarity to all its predecessors. We then use the measure to analyze the performance of a simple, broadly-applicable class of algorithms which repeatedly make new queries that best fit the preceding observations. We prove both regret bounds and PAC generalization bounds that are all polynomial in the dissimilarity dimension.

We show that our learning framework subsumes two classic learning models that were seemingly unrelated prior to this work:

First, our model subsumes the statistical query (SQ) model, introduced by Kearns [19] for designing noise-tolerant learning algorithms. In the SQ model, the learner can sequentially ask certain queries of an oracle, who responds with answers that are only approximately correct, with the goal of correctly estimating a target. Despite its simplicity, it has been proven to be a powerful model. Indeed, a wide range of algorithmic techniques in machine learning are implementable using SQ learning. Thus, it has been proven useful, not only for designing noise-tolerant algorithms, but also for its connectionsto other noise models, and as an explanatory tool to prove hardness of many problems (see the survey of Reyzin [23]). We show that our framework subsumes the SQ model, and furthermore that the dissimilarity dimension generalizes well-known parameters that characterize SQ learnability.

Second, our model captures structured bandits, in which the learner repeatedly chooses actions which yield stochastic rewards, with the goal of minimizing regret relative to the best action in hindsight. Over more than a decade, the eluder dimension [24] has been a central technique for analyzing regret for contextual bandits and reinforcement learning (RL) with function approximation [30; 22; 29; 10]. We will see that the dissimilarity dimension is upper-bounded by the eluder dimension, and that there can in fact be a large gap between the two. This sometimes leads to an improved analysis when relying on the proposed dissimilarity measure rather than the eluder dimension.

Because SQ and bandits are both subsumed by our framework, all the results mentioned above directly apply to those settings as well, including the applicability of our general-purpose algorithms.

To summarize, our main contributions are as follows:

* **Unified framework.** We derive a general framework which captures various interactive learning settings, including specifically SQ and bandits.
* **Novel dimension, performance bounds.** We introduce the dissimilarity dimension that is used to derive learnability bounds in our model. We study a general, simple algorithm, and give a novel analysis that results in both regret and PAC generalization bounds that are polynomial in the new dimension. We also give lower bounds in the SQ and bandit settings.
* **Improved analysis.** We show instances in which the standard analysis of a certain class of algorithms using the eluder dimension yields bounds that are arbitrarily large, but in which an analysis using our dimension yields low regret bounds.

Related work.The interactive estimation model we consider in this work is defined with respect to an evaluation function that can be thought of as an arbitrary measure of the "similarity" between the queried alternative and the target. Previously, Balcan and Blum [3] developed a theory of similarity-based learning that generalizes kernel methods, providing sufficient conditions for a similarity function to be useful for learning. Chen et al. [8] review several approaches to classification based on similarity between examples, including, for instance, kernels and nearest neighbors. Ben-David et al. [5] studied a learning-by-distances model that resembles ours using a metric as a measure of similarity. In comparison to these works, our model admits an arbitrary similarity measure for which we derive a general dimension, algorithm, and bounds.

In the context of bandit and reinforcement learning, a parameter called the decision-estimation coefficient (DEC) has recently been proposed by Foster et al. [15] to characterize learnability in interactive decision making. Unlike DEC, our dimension is combinatorial in nature, and applies to settings like SQ, which are not captured by DEC.

As discussed above, our model subsumes SQ and bandits, both of which have been extensively studied (see the references above as well as various surveys [20; 23]).

## 2 Setting

In this paper, we study an interactive learning protocol called _interactive estimation_. In this protocol, the learner is provided with a set \(\mathcal{Z}\) of _alternatives_, and an _evaluation function_\(\rho:\mathcal{Z}\times\mathcal{Z}\rightarrow[-1,1]\). Intuitively, \(\rho\) can be viewed as a measure of "similarity," though it need not be symmetric. There is also a distinguished alternative \(z^{*}\in\mathcal{Z}\) called the _target_, fixed throughout the interaction, and unknown to the learner. In each of a sequence of steps \(t=1,\ldots,T\), the learner selects one alternative \(z_{t}\in\mathcal{Z}\) and receives a stochastic _reward_\(r_{t}\in[-1,1]\) drawn independently, conditioned on \(z_{t}\), with expectation satisfying \(\mathbb{E}[r_{t}\,|\,z_{t}]=\rho(z_{t}\,|\,z^{*})\). Informally, by choosing alternatives and observing their similarity to \(z^{*}\), the learner aims to get close to the target. The special case when \(r_{t}=\rho(z_{t}\,|\,z^{*})\), that is, when rewards are deterministic functions of the queried alternatives, is referred to as the _deterministic setting_.

We generally assume \(\rho(z^{*}\,|\,z^{*})\geq\rho(z\,|\,z^{*})\) for all \(z\in\mathcal{Z}\) and denote this optimal value as \(\alpha^{*}\coloneqq\rho(z^{*}\,|\,z^{*})\). We will assume that the value of \(\alpha^{*}\) is known to the learner or that we are provided with an alternate _optimality level_\(\alpha\leq\alpha^{*}\) such that the task is to identify \(z\) with \(\rho(z\,|\,z^{*})\geq\alpha\). At the end of Section 3 we discuss how this assumption can be relaxed.

We consider two alternative goals for a learner in this model: _sublinear regret_ and _PAC generalization_. A learner achieves _sublinear regret_ relative to an optimality level \(\alpha\leq\alpha^{*}\) if \(\text{Regret}(T,\alpha)=o(T)\), where

\[\text{Regret}(T,\alpha)=\sum_{t=1}^{T}\Bigl{(}\alpha-\rho(z_{t}\mid z^{*}) \Bigr{)}.\]

We say that a learner achieves _PAC generalization_ if for any \(\epsilon,\delta>0\) and \(\alpha\leq\alpha^{*}\), with probability at least \(1-\delta\) (over the randomness of the query responses and the learner's own randomization), after \(m(\epsilon,\delta,\alpha)\) interactions in the protocol above, the learner outputs \(\hat{z}\) such that \(\rho(\hat{z}\mid z^{*})\geq\alpha-\epsilon\). The function \(m(\epsilon,\delta,\alpha)\) is referred to as sample complexity. We recover standard notions of regret and PAC generalization by setting \(\alpha=\alpha^{*}\).

**Example 1** (Point on a sphere).: _Let \(\left\lVert\cdot\right\rVert\) denote the standard Euclidean norm in \(\mathbb{R}^{n}\) and let \(\mathcal{Z}=\mathcal{S}_{n-1}=\{\mathbf{z}\in\mathbb{R}^{n}:\;\left\lVert \mathbf{z}\right\rVert=1\}\) be the unit sphere in \(\mathbb{R}^{n}\). The goal is to estimate an unknown point \(\mathbf{z}^{*}\in\mathcal{S}_{n-1}\) based on rewards equal to the inner product between the queries and the target, that is, \(r_{t}=\rho_{\text{sphere}}(\mathbf{z}_{t}\mid\mathbf{z}^{*})\coloneqq\langle \mathbf{z}_{t},\mathbf{z}^{*}\rangle\)._

We now introduce the two main examples corresponding to classic learning models that are subsumed by the interactive estimation model.

**Example 2** (Structured bandits).: _Let \(\mathcal{A}\) be an action set, \(\mathcal{F}\) a space of reward functions \(f:\mathcal{A}\to[-1,1]\), and \(f^{*}\in\mathcal{F}\) the target reward function. In step \(t\), the learner chooses an action \(a_{t}\in\mathcal{A}\) and receives reward \(r_{t}\in[-1,1]\) with \(\mathbb{E}[r_{t}\mid a_{t}]=f^{*}(a_{t})\). The goal is to maximize the sum of rewards. Let \(a^{*}=\operatorname*{argmax}_{a\in\mathcal{A}}f^{*}(a)\) be an optimal action. To represent bandits in our formalism, we let \(\mathcal{Z}=\mathcal{F}\times\mathcal{A}\), \(z^{*}=(f^{*},a^{*})\), and \(\rho_{\text{bandits}}\bigl{(}(f,a)\mid(f^{*},a^{*})\bigr{)}=f^{*}(a)\)._

The structured bandit problem has been extensively studied, and Example 2 captures its expressiveness within our framework. For example, it recovers the possibly simplest case of \(K\)-armed bandits, by considering \(\mathcal{A}=\{1,...,K\}\) and \(\mathcal{F}=[0,1]^{K}\). At each round, the learner chooses arm \(a_{t}\in\mathcal{A}\) and observes a reward \(r_{t}\) which is drawn from a distribution with mean \(f^{*}(a_{t})\). See Appendix D for a more concrete example of \(K\)-armed bandits instantiated within our framework. In Section 5 we also give concrete bounds for other example classes including linear bandits and GLM bandits.

We remark that although the protocol in which the learner submits pairs \((f,a)\) in each round rather than an action \(a\), may seem more complicated than the standard bandits protocol, it is in fact equivalent as the function \(f\) is ignored in the evaluation. Moreover, this formulation naturally captures any algorithms for realizable bandits. Such algorithms often keep track of a version space (set of functions \(f\) consistent with the data), and so at each point of interaction, there is an implicit \(f_{t}\) that is associated with \(a_{t}\) produced at that time. The above protocol simply makes the choice of \(f_{t}\) explicit.

**Example 3** (SQ learning).: _Given a domain \(\mathcal{X}\), the goal is to learn a binary classifier \(h^{*}:\mathcal{X}\to\{\pm 1\}\) from some hypothesis class \(\mathcal{H}\subseteq\{\pm 1\}^{\mathcal{X}}\), based on training examples \((x,y)\) drawn from some distribution \(D\) such that \(y=h^{*}(x)\). In step \(t\), the learner produces a hypothesis \(h_{t}\) and observes the accuracy of \(h_{t}\) on a fresh finite sample. In this case, \(\mathcal{Z}=\mathcal{H}\), the evaluation function is equal to the expected accuracy \(\rho_{\text{SQ}}(h\mid h^{*})=\mathbb{E}_{x\sim D}[h(x)h^{*}(x)]\), and the reward is the empirical accuracy on a fresh sample._

The SQ learning model considered in this work (Example 3) differs from the original model of Kearns [19] because it is restricted, as in previous works [7, 13, 31], to so-called _correlational_ queries (called CSQs) and assumes stochastic responses, as opposed to allowing arbitrary queries and adversarial responses. We discuss relationships between various SQ variants in Appendix B.

We finish this section by introducing a central concept of this paper, a new combinatorial complexity measure called the _dissimilarity dimension_ which, as we will see, allows us to derive learnability bounds for the interactive estimation protocol.

**Definition 1** (Dissimilarity dimension).: _For a set \(\mathcal{Z}\), scalars \(\alpha\in\mathbb{R}\), \(\epsilon>0\), and evaluation function \(\rho:\mathcal{Z}\times\mathcal{Z}\to[-1,1]\), the dissimilarity dimension \(\mathsf{d}_{\rho}(\mathcal{Z},\alpha,\epsilon)\) is the largest integer \(d\) for which there exist \(z_{1},\ldots,z_{d}\in\mathcal{Z}\) with \(\rho(z_{i}\mid z_{i})\geq\alpha\), and a scalar \(c\leq\alpha-\epsilon\), such that for all \(i<j\),_

\[\Bigl{|}\rho(z_{i}\mid z_{j})-c\Bigr{|}\leq\frac{\epsilon}{\sqrt{d}}.\]_Furthermore, denote the monotonic dissimilarity dimension as \(\overline{\mathsf{d}}_{\rho}(\mathcal{Z},\alpha,\epsilon)\coloneqq\max_{\epsilon ^{\prime}\geq\epsilon}\mathsf{d}_{\rho}(\mathcal{Z},\alpha,\epsilon^{\prime})\). 1_

Note that \(\mathsf{d}_{\rho}(\mathcal{Z},\alpha,\epsilon)=0\) if there is no \(z\) such that \(\rho(z\,|\,z)\geq\alpha\), and otherwise \(\mathsf{d}_{\rho}(\mathcal{Z},\alpha,\epsilon)\geq 1\). In particular, if \(\alpha\leq\alpha^{*}\) then \(\mathsf{d}_{\rho}(\mathcal{Z},\alpha,\epsilon)\geq 1\).

Footnote 1: We remark that the term \(\sqrt{d}\) in Definition 1 can be generalized to any function \(g(d)\) and state our main results in terms of \(g\). However, for ease of presentation we pick \(g(d)=\sqrt{d}\) as it simplifies the comparison between the dissimilarity dimension and eluder dimension (e.g. Thm. 11 and Prop. 12).

In rough terms, this dimension corresponds to the longest sequence of points with \(\alpha\)-large self-evaluation, such that the evaluation \(\rho(z_{i}\,|\,z_{j})\) of each point \(z_{i}\) relative to every successive point \(z_{j}\) is "small" (significantly less than \(\alpha\)), and also tightly clustered around some value \(c\). Thus, each point is similar to itself, but dissimilar from all successive points to about the same degree. The idea is illustrated in Figure 1. The monotonic dissimilarity dimension is the tightest upper bound on the dissimilarity dimension that is non-increasing in \(\epsilon\).

Various concrete examples where the dissimilarity dimension can be bounded are provided in Section 5. For instance, using a general bound for linear bandits from Section 5, we can show that for the task of finding a point on a sphere based on inner products (Example 1), the dimension \(\overline{\mathsf{d}}_{\rho_{\text{\tiny{sphere}}}}(\mathcal{Z},\alpha, \epsilon)\leq 4n+3\), a bound that is independent of both \(\alpha\) and \(\epsilon\).

## 3 Algorithms and upper bounds

In this section we analyze algorithms for the interactive estimation protocol, which we call _interactive estimation algorithms_. We show that when an interactive estimation algorithm satisfies two properties, _large self-evaluations_ and _decaying estimation error_, then its regret can be bounded using the dissimilarity dimension. We introduce a simple algorithm (Algorithm 1), which satisfies these properties for many standard classes of alternatives. The first property requires that the algorithm only select alternatives that would achieve the expected reward of at least \(\alpha\) if they were the target:

**Definition 2** (\(\alpha\)-large self-evaluations).: _An interactive estimation algorithm has \(\alpha\)-large self-evaluations if at every time step \(t=1,\ldots,T\), it selects a query \(z_{t}\) such that \(z_{t}\in\mathcal{Z}_{\alpha}\), where_

\[\mathcal{Z}_{\alpha}=\{z\in\mathcal{Z}:\rho(z\,|\,z)\geq\alpha\}.\] (1)

Algorithm 1 satisfies this property, with the optimality level \(\alpha\) provided as input. At the end of the section, we discuss the case when \(\alpha\) is not provided and \(\alpha^{*}\) is unknown. We derive an optimistic version of Algorithm 1 that achieves \(\alpha^{*}\)-large self-evaluations with high probability.

The second property states that the queries produced by the algorithm provide increasingly good estimates of the expected rewards in the previous rounds (that is they are good estimators _with the benefit of hindsight_), as quantified by the square loss.

**Definition 3** (Decaying estimation error).: _An interactive estimation algorithm has decaying estimation error if there exists \(C_{T,\delta}\geq 0\) growing sublinearly in \(T\), that is, \(C_{T,\delta}=o(T)\), such that with probability at least \(1-\delta\) the sequence of queries \(z_{1},\ldots,z_{T}\) produced by the algorithm satisfies_

\[\sum_{i=1}^{t-1}\Bigl{(}\rho(z_{i}\mid z_{t})-\rho(z_{i}\mid z^{*})\Bigr{)}^{2} \leq C_{T,\delta}\] (2)

_for all \(t\in\{1,\ldots,T\}\) simultaneously._

Algorithm 1 optimizes an empirical version of Eq. (2), with the observed rewards \(r_{i}\) in place of the expectations \(\rho(z_{i}\mid z^{*})\). Thus, in the deterministic setting, with \(r_{i}=\rho(z_{i}\mid z^{*})\), Algorithm 1 satisfies this property with \(C_{T,\delta}=0\). It can also be shown that it satisfies this property when the set of alternatives is finite:

**Theorem 4**.: _Assume that \(|\mathcal{Z}|<\infty\). Then Algorithm 1 satisfies the decaying estimation error property with \(C_{T,\delta}=O\bigl{(}\ln(T|\mathcal{Z}|/\delta)\bigr{)}\)._

In the general case, when \(\mathcal{Z}\) is infinite, we show that Algorithm 1 satisfies the decaying estimation error property with \(C_{T,\delta}=O\bigl{(}\log(TN/\delta)\bigr{)}\) where \(N\) is a suitable covering number of \(\mathcal{Z}\) (see Corollary 18 in Appendix A.1). For example, for _linear bandits_, which is an instance of Example 2 in which the action set and function class correspond to a subset of the unit ball in \(\mathbb{R}^{n}\), we obtain \(C_{T,\delta}=O\bigl{(}n\log(1/\epsilon)+\log(T/\delta)\bigr{)}\).

In Appendix A.3, we discuss an approach in which we have access to an online regression oracle for the least squares problem in step 3. We show that a suitably modified version of Algorithm 1 has a decaying estimation error as long as the online regression oracle achieves a sublinear regret (but without further dependence on a covering number).

To develop some intuition how Algorithm 1 works, we can again consider the \(K\)-armed bandit problem (a special case of Example 2), and suppose that \(\alpha=0.75\). In each step, the algorithm picks a pair \((f_{t},a_{t})\), where \(f_{t}\in[0,1]^{K}\) is the vector of mean reward estimates and \(a_{t}\) is the arm with the largest mean estimate. The estimates \(f_{t}(a)\), \(a=1,\ldots,K\), are formed by optimizing the least squares error of the observed rewards, under the constraint that at least one of the mean estimates must be above \(0.75\). As a result, the algorithm pulls the arm with the largest average reward as long as that average is above \(0.75\) (arms that have not been pulled are assumed to have averages above \(0.75\)). If all the averages are below \(0.75\) then the algorithm selects the arm \(a\) with the smallest value \(n_{a}(0.75-\hat{\mu}_{a})^{2}\), where \(n_{a}\) is how many times the arm has been pulled so far and \(\hat{\mu}_{a}\) is its average reward; it can be verified that this solves the least squares problem subject to the constraint that at least one of the mean estimates is above \(0.75\).

We next state our main results: a regret bound and a PAC generalization guarantee. They are both based on bounding how many "bad" queries any algorithm with large self-evaluations and decaying estimation error can make. Concretely, we say that a query \(z\in\mathcal{Z}\) is \(\epsilon\)_-bad_ if its suboptimalty gap is greater than \(\epsilon\), that is, if

\[\rho(z\mid z^{*})<\alpha-\epsilon.\]

The next lemma shows that the number of \(\epsilon\)-bad queries is upper bounded polynomially in the dissimilarity dimension.

**Lemma 5** (Few bad queries).: _Let \(\epsilon,\delta>0\), and let \(d=\overline{\mathrm{d}}_{\rho}(\mathcal{Z},\alpha,\epsilon)<\infty\) for some set \(\mathcal{Z}\), evaluation function \(\rho\) and \(\alpha\leq\alpha^{*}\). Let \(\mathsf{Alg}\) be an interactive estimation algorithm with \(\alpha\)-large self-evaluations and a decaying estimation error with some \(C_{T,\delta}\). Then, with probability at least \(1-\delta\), the number of \(\epsilon\)-bad queries that \(\mathsf{Alg}\) makes in \(T\) steps is at most \(2d^{1.5}\ln(4/\epsilon)+12d^{2.5}C_{T,\delta}/\epsilon^{2}\). Consequently, if \(C_{T,\delta}\geq\ln(2T)\), then with probability at least \(1-\delta\), the number of \(\epsilon\)-bad queries is at most \(36d^{2.5}C_{T,\delta}/\epsilon^{2}\), and if \(C_{T,\delta}=0\) then it is at most \(2d^{1.5}\ln(4/\epsilon)\)._The above result is the core component of our main theorems. The proof is given in Appendix A.4; here we sketch the main ideas. The goal is to show that the "bad" interval \([-1,\alpha-\epsilon]\) cannot contain too many queries made by Alg. The proof starts by partitioning this interval into disjoint subintervals and then bounds the number of queries in each subinterval. It does so by constructing a graph with nodes corresponding to queries, which are connected by an edge if they satisfy the dimension conditions. The decaying errors that imply a certain minimum number of edges (as a function of number of queries). On the other hand, the dissimilarity dimension bounds the size of the largest clique, which implies an upper bound on the number of edges (using Turan's Theorem [26], a standard result from extremal graph theory). Combining the bounds yields an upper bound on the number of queries in the subinterval. Summing across subintervals proves the lemma.

The following theorems use Lemma 5 to bound both the regret and PAC sample complexity. The proofs are deferred to Appendices A.6 and A.7.

**Theorem 6** (Regret).: _Let \(\delta,T>0\), and let \(d=\overline{\mathrm{d}}_{\rho}(\mathcal{Z},\alpha,1/T)\) for some set \(\mathcal{Z}\), evaluation function \(\rho\) and \(\alpha\leq\alpha^{*}\). Let \(\mathsf{Alg}\) be an interactive estimation algorithm with \(\alpha\)-large self-evaluations and a decaying estimation error with some \(C_{T,\delta}\). If \(C_{T,\delta}\geq\ln(2T)\) then with probability at least \(1-\delta\), the regret of \(\mathsf{Alg}\) satisfies_

\[\mathrm{Regret}(T,\alpha)\leq 1+12d^{1.25}\sqrt{C_{T,\delta}T}.\]

_In the deterministic setting, \(\mathrm{Regret}(T,\alpha)\leq 1+12d^{1.5}\)._

For an algorithm with a decaying estimation error, the term \(C_{T,\delta}\) is sublinear in \(T\), implying a sublinear regret in Theorem 6. For example, Algorithm 1 has a decaying estimation error with \(C_{T,\delta}\) that scales logarithmically with \(T/\delta\) for many standard function classes, and so the overall regret scales as \(O(\sqrt{T\log T})\) (see Corollary 18 in Appendix A.1).

To derive PAC generalization guarantees, we apply a variant of online-to-batch reduction to any algorithm with large self-evaluations and a decaying estimation error. The resulting approach, shown in Algorithm 2, satisfies the following guarantee (proved in Appendix A.7):

**Theorem 7** (PAC generalization).: _Let \(\epsilon,\delta>0\), and let \(d=\overline{\mathrm{d}}_{\rho}(\mathcal{Z},\alpha,\epsilon)\) for some set \(\mathcal{Z}\), evaluation function \(\rho\) and \(\alpha\leq\alpha^{*}\). Let \(\mathsf{Alg}\) be an interactive estimation algorithm with \(\alpha\)-large self-evaluations and a decaying estimation error with \(C_{T,\delta}\geq\ln(2T)\), and suppose that we run Algorithm 2 with \(\mathsf{Alg}\) as the base algorithm, \(T\geq 64d^{2.5}(C_{T,\delta/2})/\epsilon^{2}\), \(n_{1}=\lceil\log_{2}(4/\delta)\rceil\), and \(n_{2}=\lceil 128\ln(8n_{1}/\delta)/\epsilon^{2}\rceil\). Then, with probability at least \(1-\delta\), the output \(\hat{z}\in\mathcal{Z}\) satisfies_

\[\rho(\hat{z}\mid z^{*})\geq\alpha-\epsilon,\]

_and the overall number of issued queries is \(O\big{(}\frac{d^{2.5}(C_{T,\delta/2})+\ln^{2}(1/\delta)}{\epsilon^{2}}\big{)}\)._

_In the deterministic setting, it suffices to run \(\mathsf{Alg}\) with \(T>2d^{1.5}\ln(4/\epsilon)\) and return \(\hat{z}=z_{\hat{t}}\) where \(\hat{t}=\operatorname*{argmax}_{t\in\{1,\ldots,T\}}r_{t}\) is the index of the largest observed reward. Then, with probability 1, we obtain \(\rho(\hat{z}\mid z^{*})\geq\alpha-\epsilon\) and issue at most \(O(d^{1.5}\ln(4/\epsilon))\) queries._

Unknown \(\alpha^{*}\) and optimism.Algorithms 1 and 2 achieve performance guarantees with respect to a provided optimality level \(\alpha\leq\alpha^{*}\). When it is not easy to provide a non-trivial \(\alpha\) (for example, when \(\alpha^{*}\) is unknown and cannot be non-trivially bounded), Algorithm 3 uses the optimistic least squares algorithmic template (see, e.g., [24]) to ensure \(\alpha^{*}\)-large self-evaluations with high probability and to achieve a sublinear \(\mathrm{Regret}(T,\alpha^{*})\). Algorithm 3 takes as input a confidence radius parameter \(R\) of the same order as the decaying estimation error parameter \(C_{T,\delta}\) for Algorithm 1. We can then show that \(z^{*}\in\mathcal{Z}_{t}\) with high probability for all \(t\in\{1,\ldots,T\}\). Therefore, \(z_{t}\) must satisfy \(\rho(z_{t}|\,z_{t})\geq\rho(z^{*}|\,z^{*})=\alpha^{*}\). In Appendix A.1 we show this modified version of the algorithm satisfies the decaying estimation error property. This technique allows us to achieve a sublinear \(\text{Regret}(T,\alpha^{*})\) without knowing \(\alpha^{*}\) beforehand. Similar to the case of fixed \(\alpha\), it is possible to derive a version of Algorithm 3 that leverages an online regression oracle. (See Appendix A.3 for details.)

```
1:Input: set of alternatives \(\mathcal{Z}\), evaluation function \(\rho\), number of steps \(T\), confidence-set radius \(R\).
2:for\(t=1,\ldots,T\)do
3: Compute confidence set \[\hat{z}_{t} =\operatorname*{argmin}_{z\in\mathcal{Z}}\sum_{i=1}^{t-1}\Bigl{(} \rho(z_{i}\,|\,z)-r_{i}\Bigr{)}^{2},\] \[\mathcal{Z}_{t} =\biggl{\{}z\in\mathcal{Z}:\;\sum_{i=1}^{t-1}\Bigl{(}\rho(z_{i} \,|\,z)-\rho(z_{i}\,|\,\hat{z}_{t})\Bigr{)}^{2}\leq R\biggr{\}}.\]
4: Submit the query \(z_{t}=\operatorname*{argmax}_{z\in\mathcal{Z}_{t}}\rho(z\,|\,z)\).
5: Observe reward \(r_{t}\).
6:endfor ```

**Algorithm 3** Optimistic Interactive Estimation via Least Squares

## 4 Statistical queries

In this section we consider the statistical query (SQ) model, as defined in Example 3. In particular, we study the connection between our generalized framework and SQ learning, showing specifically that the dissimilarity dimension can be used to recover generalization bounds based on a known combinatorial parameter that characterizes SQ learning, called the _strong SQ dimension_. There are several notions of such a dimension [12; 25]. Here we focus on the one due to Szorenyi [25]:

**Definition 4** (Strong SQ dimension, [25]).: _For a fixed distribution \(D\) over \(\mathcal{X}\), the strong SQ dimension of a hypothesis class \(\mathcal{H}\subseteq\{\pm 1\}^{\mathcal{X}}\) with respect to some \(\epsilon>0\), denoted \(\mathtt{dim}_{\text{SQ}}(\mathcal{H},\epsilon)\), is the largest number \(d\) for which there exist \(h_{1},\ldots,h_{d}\in\mathcal{H}\) such that:_

* \(|\langle h_{i},h_{j}\rangle|\leq 1-\epsilon\) _for all_ \(1\leq i<j\leq d\)_, and_
* \(|\langle h_{i},h_{j}\rangle-\langle h_{i^{\prime}},h_{j^{\prime}}\rangle|\leq \frac{1}{d}\) _for all_ \(1\leq i<j\leq d\)_,_ \(1\leq i^{\prime}<j^{\prime}\leq d\)_,_

_where \(\langle h,h^{\prime}\rangle:=\mathbb{E}_{x\sim D}[h(x)h^{\prime}(x)]\)._

The dissimilarity and strong SQ dimensions are closely related to one another in the sense of each providing a kind of polynomial bound on the other, as stated in the next proposition (see Appendix B.1 for the proof).

**Proposition 8**.: _Let \(D\) be a fixed distribution over \(\mathcal{X}\), and let \(\mathcal{H}\subseteq\{\pm 1\}^{\mathcal{X}}\) be a hypotheses class. For \(\epsilon>0\), let \(d_{\text{SQ}}(\epsilon)=\mathtt{dim}_{\text{SQ}}(\mathcal{H},\epsilon)\), and let \(d_{\rho}(\epsilon)=\mathtt{d}_{\rho_{\text{SQ}}}(\mathcal{H},1,\epsilon)\)._

_If \(d_{\rho}(\epsilon)\geq 2\) then_

\[\min\Bigl{\{}d_{\text{SQ}}(\epsilon),\;\bigl{\lfloor}4\epsilon^{2}\,(d_{\text {SQ}}(\epsilon))^{2}\bigr{\rfloor}\Bigr{\}}\leq d_{\rho}(\epsilon)\leq\max \Bigl{\{}d_{\text{SQ}}(\epsilon/4),\,4\epsilon^{2}\,(d_{\text{SQ}}(\epsilon/ 4)+1)^{2}\Bigr{\}}.\] (3)

_Similarly, if \(d_{\rho}(4\epsilon)\geq 2\) then_

\[\min\left\{d_{\rho}(4\epsilon),\;\biggl{\lfloor}\frac{\sqrt{d_{\rho}(4\epsilon) }}{8\epsilon}\biggr{\rfloor}\right\}\leq d_{\text{SQ}}(\epsilon)\leq\max \left\{d_{\rho}(\epsilon),\;\frac{\sqrt{d_{\rho}(\epsilon)+1}}{2\epsilon} \right\}.\] (4)

We next give a lower bound based on the strong SQ dimension, which together with Proposition 8 will allow us to lower bound sample complexity of any interactive estimation algorithm in the SQ setting in terms of the dissimilarity dimension.

**Theorem 9** (SQ lower bound).: _Let \(\epsilon>0\), and let \(\mathcal{H}\subseteq\{\pm 1\}^{\mathcal{X}}\) be a hypothesis class with strong SQ dimension \(d_{\text{SQ}}=\mathtt{dim}_{\text{SQ}}(\mathcal{H},2\epsilon)\geq 11\). Let \(\mathsf{Alg}\) be any interactive estimation algorithm with the property that for any target \(h^{*}\in\mathcal{H}\), \(\mathsf{Alg}\) outputs an \(\epsilon\)-approximation to \(h^{*}\) with probability at least \(2/3\) using at most \(m\) queries. Then \(m>\sqrt[3]{d_{\text{SQ}}}/12\)._The proof relies on a reduction to a lower bound of Szorenyi [25]. However, the lower bound of Szorenyi [25] holds within an SQ model that differs from ours, in that it allows adversarial query responses. Therefore, we first need to show how to obtain a learning algorithm \(\mathsf{Alg}^{\prime}\) that can be used with an adversarial oracle from an interactive estimation algorithm \(\mathsf{Alg}\) that uses an unbiased stochastic query oracle (as we assume in this work). To do this, we apply the reduction technique developed by Feldman et al. [13]. (See Appendix B.2 for the full proof and additional details.)

Combining Theorem 9 and Proposition 8 yields a lower bound on the sample complexity of interactive estimation in the SQ setting, for a sufficiently small \(\epsilon\), in terms of the dissimilarity dimension:

**Corollary 10**.: _Let \(\epsilon>0\), and let \(\mathcal{H}\subseteq\{\pm 1\}^{\mathcal{X}}\) be a hypothesis class with strong SQ dimension \(\mathtt{dim}_{\mathsf{SQ}}(\mathcal{H},2\epsilon)\geq 11\). Let \(d_{\rho}(\epsilon)=\mathtt{d}_{\mathsf{pos}}(\mathcal{H},1,\epsilon)\). Assume \(\epsilon\leq 1/\big{(}2\sqrt{d_{\rho}(\epsilon)}\big{)}\). Let \(\mathsf{Alg}\) be any interactive estimation algorithm with the property that for any target \(h^{*}\in\mathcal{H}\), \(\mathsf{Alg}\) outputs an \(\epsilon\)-approximation to \(h^{*}\) with probability at least \(2/3\) using at most \(m\) queries. Then \(m>\sqrt[3]{d_{\rho}(\epsilon)}/12\)._

## 5 Bandits

In this section we focus on the bandits setting described in Example 2. We study the relationship between the dissimilarity dimension and the _eluder dimension_[24], a common combinatorial dimension for bounding regret of bandit algorithms. We show that eluder dimension can be used to upper bound the dissimilarity dimension, and we also highlight the cases when dissimilarity dimension leads to a tighter analysis.

Throughout this section we follow the setup introduced in Example 2. We consider an action set \(\mathcal{A}\), a class \(\mathcal{F}\) of reward functions \(f:\mathcal{A}\to[-1,1]\), and a target reward function \(f^{*}\in\mathcal{F}\). We map this to our setting by considering the set of alternatives \(\mathcal{Z}=\mathcal{F}\times\mathcal{A}\), evaluation function \(\rho_{\text{bandits}}\big{(}(f,a)\mid(f^{\prime},a^{\prime})\big{)}=f^{\prime}(a)\) and the target \((f^{*},a^{*})\), where \(a^{*}=\operatorname*{argmax}_{a\in\mathcal{A}}f^{*}(a)\).

### Comparison with eluder dimension

We start by describing the relationship between our dimension and the eluder dimension. Following Russo and Van Roy [24], we define \(\epsilon\)-dependence and \(\epsilon\)-eluder dimension as follows:

**Definition 5** (\(\epsilon\)-dependence).: _An action \(a\in\mathcal{A}\) is \(\epsilon\)-dependent on actions \(\{a_{1},\dots,a_{n}\}\subseteq\mathcal{A}\) with respect to \(\mathcal{F}\) if any pair of functions \(f,f^{\prime}\in\mathcal{F}\) satisfying \(\sqrt{\sum_{i=1}^{n}(f(a_{i})-f^{\prime}(a_{i}))^{2}}\leq\epsilon\) also satisfies \(|f(a)-f^{\prime}(a)|\leq\epsilon\). Furthermore, an action \(a\) is \(\epsilon\)-independent of \(\{a_{1},\dots,a_{n}\}\) with respect to \(\mathcal{F}\) if it is not \(\epsilon\)-dependent on \(\{a_{1},\dots,a_{n}\}\)._

**Definition 6** (\(\epsilon\)-eluder dimension).: _The \(\epsilon\)-eluder dimension \(\mathtt{dim}_{\mathsf{E}}(\mathcal{F},\epsilon)\) is the length \(d\) of the longest sequence of elements in \(\mathcal{A}\) such that every element is \(\epsilon\)-independent of its predecessors. Moreover, the monotone eluder dimension is defined as \(\overline{\mathtt{dim}_{\mathsf{E}}}(\mathcal{F},\epsilon)\coloneqq\max_{ \epsilon^{\prime}\geq\epsilon}\mathtt{dim}_{\mathsf{E}}(\mathcal{F},\epsilon^{ \prime})\)._

The next theorem shows that the dissimilarity dimension is upper bounded by the eluder dimension (see Appendix C.1 for a proof):

**Theorem 11**.: _Let \(\mathcal{Z}=\mathcal{F}\times\mathcal{A}\), \(\rho=\rho_{\text{bandits}}\), \(\epsilon>0\), \(\alpha\leq\alpha^{*}\). Then \(\overline{\mathtt{d}}_{\rho}(\mathcal{Z},\alpha,3\epsilon/2)\leq 9\, \overline{\mathtt{dim}}_{\mathsf{E}}(\mathcal{F},\epsilon)\)._

Nevertheless, as the next example shows, the eluder dimension can be arbitrarily large, while the dissimilarity dimension remains constant. In this example, the action set is a circle in \(\mathbb{R}^{2}\), that is, \(\mathcal{A}=\mathcal{C}\coloneqq\{\mathbf{v}\in\mathbb{R}^{2}:\,\|\mathbf{v}\|=1\}\). We fix two open semicircles \(U_{0},U_{1}\subseteq\mathcal{C}\) with positive \(x\) and \(y\) coordinates, respectively, and for any \(N\in\mathbb{N}\) and \(\epsilon>0\), construct a function class \(\mathcal{F}_{N,\epsilon}\) with all the functions \(f:\mathcal{A}\to[-1,1]\) obtained by the following process. First, pick one of the semicircles \(U_{j}\) and any \(N\) points from \(U_{j}\). On each of these points, \(f\) can equal either \(+\epsilon\) or \(-\epsilon\). Everywhere else in \(U_{j}\), \(f\) equals zero, and everywhere outside \(U_{j}\), it equals the linear function \(\langle\mathbf{v},\mathbf{a}\rangle\) parameterized by some \(\mathbf{v}\in\mathcal{C}\setminus U_{j}\). Thus, the functions are constructed to be "simple" (namely, linear) near the optimal action \(\mathbf{v}\), but complex far from it. The eluder dimension is large to capture overall complexity, whereas the dissimilarity dimension is small to capture the simplicity near the optimum. (See Appendix C.5 for the formal construction of \(\mathcal{F}_{N,\epsilon}\) and the proof of Proposition 12.)

**Proposition 12**.: _Let \(\epsilon\in(0,1/2)\), \(N\in\mathbb{N}\) and consider the action set \(\mathcal{A}=\mathcal{C}\). Then, there is a function class \(\mathcal{F}_{N,\epsilon}\subseteq[-1,1]^{\mathcal{A}}\), such that for \(\mathcal{Z}_{N,\epsilon}\coloneqq\mathcal{F}_{N,\epsilon}\times\mathcal{A}\), \(\rho=\rho_{\text{bandits}}\), it holds that \(\mathtt{d}_{\rho}(\mathcal{Z}_{N,\epsilon},1,\epsilon)\leq 16\), but the eluder dimension is lower bounded as \(\mathtt{dim}_{\mathsf{E}}(\mathcal{F}_{N,\epsilon},\epsilon)\geq N\)._

Thus, our regret bound based on the dissimilarity dimension implies that (optimistic) least squares algorithms have a regret independent of \(N\). The same analysis with the eluder dimension [24] yieldsa regret bound scaling polynomially with \(N\). This shows that in the cases when the function classes are simple near the optimum, but complex far from it, the dissimilarity dimension can better capture the statistical complexity of bandit optimization than the eluder dimension.

### Dissimilarity dimension bounds

We next derive dissimilarity dimension bounds for several standard bandit classes. Existing bounds on eluder dimension can be used to immediately bound the dissimilarity dimension, but in several cases we are able to obtain tighter bounds.

We first consider _linear bandits_. Let \(\mathcal{B}_{n}=\{\mathbf{v}\in\mathbb{R}^{n}:\;\|\mathbf{v}\|\leq 1\}\) be the unit ball in \(\mathbb{R}^{n}\). Actions are chosen from a set \(\mathcal{A}\subseteq\mathcal{B}_{n}\); the reward function class is \(\mathcal{F}^{lb}=\{f_{\bm{\theta}}:\bm{\theta}\in\Theta\}\), where \(\Theta\subseteq\mathcal{B}_{n}\) and \(f_{\bm{\theta}}(\mathbf{a})=\langle\bm{\theta},\mathbf{a}\rangle\). The corresponding set of alternatives is denoted \(\mathcal{Z}^{lb}=\mathcal{F}^{lb}\times\mathcal{A}\). In this case we obtain the following bound (see Appendix C.2 for a proof):

**Theorem 13** (Linear bandits).: _Let \(\mathcal{Z}^{lb}\) be as defined above, let \(\rho=\rho_{\text{bandits}}\), and let \(\epsilon>0\), \(\alpha\leq\alpha^{\star}\). Then \(\mathsf{d}_{\rho}(\mathcal{Z}^{lb},\alpha,\epsilon)\leq 4n+3\). Moreover, when \(\alpha=1\), then \(\mathsf{d}_{\rho}(\mathcal{Z}^{lb},\alpha,\epsilon)\leq 2n+1\)._

The proof proceeds by deriving an upper bound as well as a lower bound on the rank of the matrix \(\mathbf{M}\) with entries \(M_{ij}=\rho(z_{i}\mid z_{j})-c\) obtained from elements \(z_{1},\ldots,z_{d}\) that satisfy the dimension condition for \(d=\mathsf{d}_{\rho}(\mathcal{Z},\alpha,\epsilon)\) with a scalar \(c\). The upper bound on the rank is \(n+1\), and the lower bound is \(d/4\) (which can be tightened to \(d/2\) when \(\mathbf{M}\) is symmetric). The upper bound is obtained by basic linear algebra and the lower bound from a standard result on ranks of perturbed identity matrices (2, Lemma 2.2). Combining these bounds then yields the claim of Theorem 13. Similar to existing bounds on eluder dimension (24, Proposition 6), our bound in Theorem 13 is linear in \(n\). However, the eluder dimension bound has an additional dependence on \(1/\epsilon\), while our bound does not.

Next, we consider _generalized linear model_ (GLM) bandits. Similar to linear bandits, the action set is \(\mathcal{A}\subseteq\mathcal{B}_{n}\), but the function class includes a nonlinearity. Specifically, we are provided with a function \(g:\mathbb{R}\to\mathbb{R}\) that is differentiable and strictly increasing, and consider the function class \(\mathcal{F}^{glm}=\{f_{\bm{\theta}}:\bm{\theta}\in\Theta\}\) where \(\Theta\subseteq\mathcal{B}_{n}\) and \(f_{\bm{\theta}}(\mathbf{a})=g(\langle\bm{\theta},\mathbf{a}\rangle)\). Furthermore, we assume that there are \(\underline{h},\overline{h}>0\) such that for all \(\mathbf{a}\in\mathcal{A}\), \(\bm{\theta}\in\Theta\), we have \(\underline{h}\leq g^{\prime}(\langle\bm{\theta},\mathbf{a}\rangle)\leq\overline {h}\). Define \(r=\overline{h}/\underline{h}\). We again denote \(\mathcal{Z}^{glm}=\mathcal{F}^{glm}\times\mathcal{A}\). Using an existing bound on the eluder dimension for GLM bandits ((24), Proposition 7) and the fact that our dimension is bounded by the eluder dimension (Theorem 11), we obtain the following bound (see Appendix C.3 for a proof):

**Theorem 14** (GLM bandits).: _Let \(\mathcal{Z}^{glm}\) be as defined above, let \(\rho=\rho_{\text{bandits}}\), and let \(\epsilon>0\), \(\alpha\leq\alpha^{\star}\). Then \(\mathsf{d}_{\rho}(\mathcal{Z}^{glm},\alpha,\epsilon)\leq O(nr^{2}\log(\overline {h}/\epsilon))\)._

By considering a different proof technique, along the lines of Theorem 13, it might be possible to tighten this bound. We leave this extension for future work.

Next, we consider a bandit setting that is similar to GLMs, but in this case the non-linearity is provided by the non-differentiable rectified linear unit (ReLU) activation function \(\text{relu}(x)=\max\{x,0\}\). We consider the action set \(\mathcal{A}=\mathcal{B}_{n}\), and the set of reward functions \(\mathcal{F}^{\text{relu}}\) consisting of all functions of the form \(f_{\bm{\theta},b}(\mathbf{a})=\text{relu}(\langle\bm{\theta},\mathbf{a} \rangle-b)\) for some \(\bm{\theta}\in\mathcal{B}_{n}\) and \(b\in[0,1)\). The subset of \(\mathcal{F}^{\text{relu}}\) with a fixed value of \(b\) is denoted \(\mathcal{F}^{\text{relu}}_{b}\), and we consider the set of alternatives \(\mathcal{Z}^{\text{relu}}_{b}=\mathcal{F}^{\text{relu}}_{b}\times\mathcal{B}_ {n}\).

Unlike the classes considered above, this setting can be shown to be challenging to learn in the general case. Indeed, it turns out that eluder dimension (as well as a related measure called star dimension) is growing at least exponentially with \(n\)(21; 10). The same lower bound can be shown for the dissimilarity dimension by a similar proof technique. The following theorem also provides an exponential upper bound, showing that in certain regimes the exponential dependence is tight (see Appendix C.4 for a proof):

**Theorem 15** (ReLU bandits).: _Let \(\mathcal{Z}^{\text{relu}}\) be as defined above, let \(\rho=\rho_{\text{bandits}}\), and let \(\epsilon,b>0\) such that \(b\leq 1-\epsilon\). Then \(\mathsf{d}_{\rho}(\mathcal{Z}^{\text{relu}}_{b},1-b,\epsilon)=O\big{(} \epsilon^{-n/2}\big{)}\), and \(\mathsf{d}_{\rho}(\mathcal{Z}^{\text{relu}}_{1-\epsilon},\epsilon,\epsilon)= \Omega\big{(}\epsilon^{-n/2}\big{)}\)._

We note that previous work ((10), Theorem 5.1) has shown that for a function class of one-layer neural networks with ReLU activations, obtaining sublinear regret requires \(T=\Omega(\epsilon^{-(n-2)})\).

## 6 Conclusion

In this paper, we have introduced a new model for interactive estimation and proposed a new combinatorial dimension, called dissimilarity dimension, to study the hardness of learning in this model. In (stochastic, correlational) statistical query learning, our dimension is polynomially related to the strong SQ dimension. In bandits, our dimension is upper bounded by the eluder dimension, and there are examples where the dissimilarity dimension leads to much tighter regret bounds.

While this work provides an initial investigation of the dissimilarity dimension, many open questions remain. For example, our regret bound for the general setting scales as \(d^{1.25}\). Is it possible to tighten this to linear dependence, as is the case, for example, for eluder dimension? On the algorithmic side, we currently require solving a least squares problem of size \(t\) in iteration \(t\). Although we also introduce an algorithm that leverages an online regression oracle (see Appendix A.3), the oracle-based approach still requires solving a least squares problem (on the data smoothed by the oracle). Is it possible to derive dissimilarity-dimension-based regret bounds directly for the predictions produced by the oracle? Ultimately, we hope investigations of relationships between dissimilarity dimension and related notions may help us understand the hardness of learning in interactive settings.

## Acknowledgments and Disclosure of Funding

Aldo Pacchiano would like to thank the support of the Eric and Wendy Schmidt Center at the Broad Institute of MIT and Harvard. This work was supported in part by funding from the Eric and Wendy Schmidt Center at the Broad Institute of MIT and Harvard.

## References

* [1] Alekh Agarwal, Daniel Hsu, Satyen Kale, John Langford, Lihong Li, and Robert Schapire. Taming the monster: A fast and simple algorithm for contextual bandits. In _International Conference on Machine Learning_, pages 1638-1646. PMLR, 2014.
* [2] Noga Alon. Perturbed identity matrices have high rank: Proof and applications. _Combinatorics, Probability and Computing_, 18(1-2):3-15, 2009.
* [3] Maria-Florina Balcan and Avrim Blum. On a theory of learning with similarity functions. In _Proceedings of the 23rd international conference on Machine learning_, pages 73-80, 2006.
* [4] Shai Ben-David and Eli Dichterman. Learning with restricted focus of attention. _Journal of Computer and System Sciences_, 56(3):277-298, 1998.
* [5] Shai Ben-David, Alon Itai, and Eyal Kushilevitz. Learning by distances. _Information and Computation_, 117(2):240-250, March 1995.
* [6] Alina Beygelzimer, John Langford, Lihong Li, Lev Reyzin, and Robert Schapire. Contextual bandit algorithms with supervised learning guarantees. In _Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics_, pages 19-26. JMLR Workshop and Conference Proceedings, 2011.
* [7] Nader H Bshouty and Vitaly Feldman. On using extended statistical queries to avoid membership queries. _Journal of Machine Learning Research_, 2(Feb):359-395, 2002.
* [8] Yihua Chen, Eric K Garcia, Maya R Gupta, Ali Rahimi, and Luca Cazzanti. Similarity-based classification: Concepts and algorithms. _Journal of Machine Learning Research_, 10(3), 2009.
* [9] Thomas M Cover. Universal portfolios. _Mathematical finance_, 1(1):1-29, 1991.
* [10] Kefan Dong, Jiaqi Yang, and Tengyu Ma. Provable model-based nonlinear bandit and reinforcement learning: Shelve optimism, embrace virtual curvature. _Advances in Neural Information Processing Systems_, 34:26168-26182, 2021.
* [11] Simon Du, Sham Kakade, Jason Lee, Shachar Lovett, Gaurav Mahajan, Wen Sun, and Ruosong Wang. Bilinear classes: A structural framework for provable generalization in rl. In _International Conference on Machine Learning_, pages 2826-2836. PMLR, 2021.
* [12] Vitaly Feldman. A complete characterization of statistical query learning with applications to evolvability. _Journal of Computer and System Sciences_, 78(5):1444-1459, 2012.
* [13] Vitaly Feldman, Elena Grigorescu, Lev Reyzin, Santosh S Vempala, and Ying Xiao. Statistical algorithms and a lower bound for detecting planted cliques. _Journal of the ACM (JACM)_, 64(2):1-37, 2017.

* Foster and Rakhlin [2020] Dylan Foster and Alexander Rakhlin. Beyond ucb: Optimal and efficient contextual bandits with regression oracles. In _International Conference on Machine Learning_, pages 3199-3210. PMLR, 2020.
* Foster et al. [2021] Dylan J Foster, Sham M Kakade, Jian Qian, and Alexander Rakhlin. The statistical complexity of interactive decision making. _arXiv preprint arXiv:2112.13487_, 2021.
* Freedman [1975] David A Freedman. On tail probabilities for martingales. _the Annals of Probability_, pages 100-118, 1975.
* Horn and Johnson [2012] Roger A Horn and Charles R Johnson. _Matrix analysis_. Cambridge university press, 2012.
* Kalai and Vempala [2002] Adam Tauman Kalai and Santosh Vempala. Efficient algorithms for universal portfolios. _Journal of Machine Learning Research_, pages 423-440, 2002.
* Kearns [1998] Michael Kearns. Efficient noise-tolerant learning from statistical queries. _Journal of the ACM (JACM)_, 45(6):983-1006, 1998.
* Lattimore and Szepesvari [2020] Tor Lattimore and Csaba Szepesvari. _Bandit algorithms_. Cambridge University Press, 2020.
* Li et al. [2021] Gene Li, Pritish Kamath, Dylan J Foster, and Nathan Srebro. Eluder dimension and generalized rank. _arXiv preprint arXiv:2104.06970_, 2021.
* Osband and Van Roy [2014] Ian Osband and Benjamin Van Roy. Model-based reinforcement learning and the eluder dimension. _Advances in Neural Information Processing Systems_, 27, 2014.
* Reyzin [2020] Lev Reyzin. Statistical queries and statistical algorithms: Foundations and applications. _arXiv preprint arXiv:2004.00557_, 2020.
* Russo and Van Roy [2013] Daniel Russo and Benjamin Van Roy. Eluder dimension and the sample complexity of optimistic exploration. _Advances in Neural Information Processing Systems_, 26, 2013.
* Szorenyi [2009] Balazs Szorenyi. Characterizing statistical query learning: simplified notions and proofs. In _International Conference on Algorithmic Learning Theory_, pages 186-200. Springer, 2009.
* Turan [1941] P Turan. On an extremal problem in graph theory (in Hungarian). _Mat. Fiz. Lapok_, 48:436-452, 1941.
* Vershynin [2018] Roman Vershynin. _High-dimensional probability: An introduction with applications in data science_, volume 47. Cambridge university press, 2018.
* Vovk [1998] Vladimir Vovk. A game of prediction with expert advice. _Journal of Computer and System Sciences_, 56(2):153-173, 1998.
* Wang et al. [2020] Ruosong Wang, Russ R Salakhutdinov, and Lin Yang. Reinforcement learning with general value function approximation: Provably efficient approach via bounded eluder dimension. _Advances in Neural Information Processing Systems_, 33:6123-6135, 2020.
* Wen and Van Roy [2013] Zheng Wen and Benjamin Van Roy. Efficient exploration and value function generalization in deterministic systems. _Advances in Neural Information Processing Systems_, 26, 2013.
* Yang [2005] Ke Yang. New lower bounds for statistical query learning. _Journal of Computer and System Sciences_, 70(4):485-509, 2005.

Missing proofs of Section 3

### Analysis of Least Squares Algorithms (Algorithms 1 and 3)

Our analysis relies on the following variant of Freedman's inequality [16] (see Agarwal et al. [1, Lemma 9] and Beygelzimer et al. [6, Theorem 1]).

**Lemma 16** (Simplified Freedman's inequality).: _Let \(R>0\) and let \(X_{1},\ldots,X_{n}\) be a sequence of real-valued random variables, such that for all \(i\in[n]\) it holds that \(X_{i}\leq R\) and \(\mathbb{E}[X_{i}|X_{1},\ldots,X_{i-1}]=0\). For any \(\delta\in(0,1)\), and \(\eta\in(0,1/R)\), with probability at least \(1-\delta\),_

\[\sum_{i=1}^{n}X_{i}\leq\eta\sum_{i=1}^{n}\mathbb{E}[X_{i}^{2}\mid X_{1},\ldots,X_{i-1}]+\frac{\ln(1/\delta)}{\eta}.\] (5)

Next we define an \(\epsilon\)-cover of a set \(\mathcal{Z}\), that will be used in the bound of Theorem 17.

**Definition 7** (\(\epsilon\)-cover).: _Let \(\psi\) be the pseudometric over the set \(\mathcal{Z}\) defined, for any \(z_{1},z_{2}\in\mathcal{Z}\), as_

\[\psi(z_{1},z_{2})=\sup_{z\in\mathcal{Z}}\Big{|}\rho(z\mid z_{1})-\rho(z\mid z_ {2})\Big{|}.\] (6)

_We say a set \(N\subseteq\mathcal{Z}\) is an \(\epsilon\)-cover of \(\mathcal{Z}\) with respect to \(\psi\) if for every \(z\in\mathcal{Z}\) there exists some \(z^{\prime}\in N\) such that \(\psi(z,z^{\prime})\leq\epsilon\). We denote by \(\mathcal{N}(\mathcal{Z},\epsilon)\) the minimum cardinality of any \(\epsilon\)-cover of \(\mathcal{Z}\)._

For example, in the case of linear bandits (see Section 5.2) when \(\mathcal{Z}=\mathcal{Z}^{lb}\) and \(\rho=\rho_{\text{bandits}}\), it can be shown that \(\mathcal{N}(\mathcal{Z}^{lb},\epsilon)\) is upper bounded by the \(\ell_{2}\)-covering number of the \(n\)-dimensional unit ball. This is because for any \(z,z_{1},z_{2}\in\Theta\times\mathcal{A}\),

\[\big{|}\rho(z\mid z_{1})-\rho(z\mid z_{2})\big{|}=\big{|}\langle\boldsymbol{ \theta}_{1},\mathbf{a}\rangle-\langle\boldsymbol{\theta}_{2},\mathbf{a} \rangle\big{|}\leq\|\boldsymbol{\theta}_{1}-\boldsymbol{\theta}_{2}\|\| \mathbf{a}\|\leq\|\boldsymbol{\theta}_{1}-\boldsymbol{\theta}_{2}\|.\]

The bound on \(\mathcal{N}(\mathcal{Z}^{lb},\epsilon)\) now follows because the \(\ell_{2}\)-covering number of the unit ball with radius \(\epsilon\) is \(O\big{(}(3/\epsilon)^{n}\big{)}\) (see, for example, Lemma D.1 of Du et al. [11]).

We next show that Algorithm 1 satisfies the decaying estimation error property with \(C_{T,\delta}\) that scales logarithmically with the covering number with respect to \(\psi\).

**Theorem 17** (LS guarantee).: _Consider the setting from Section 2, where the learner sequentially issues the queries \(z_{1},\ldots,z_{T}\) and receives responses \(r_{1},\ldots,r_{T}\). Assume there is \(\beta\geq 0\) such that \(\big{|}r_{t}-\mathbb{E}[r_{t}\mid z_{t}]\big{|}\leq\beta\) for all \(t\), and \(\beta^{\prime}\geq 2\beta\) such that for all \(z,z^{\prime}\), \(\big{|}\rho(z\mid z^{\prime})-\rho(z\mid z^{*})\big{|}\leq\beta^{\prime}\). Let \(\tilde{\mathcal{Z}}\) be a set of alternatives such that \(z^{*}\in\tilde{\mathcal{Z}}\) and let \(\hat{z}_{t}\) be defined as the least squares optimizer,_

\[\hat{z}_{t}=\operatorname*{argmin}_{z\in\tilde{\mathcal{Z}}}\sum_{i=1}^{t-1} \Bigl{(}\rho(z_{i}\mid z)-r_{i}\Bigr{)}^{2}.\]

_Then, for any sequence of queries \(z_{1},\ldots,z_{T}\in\tilde{\mathcal{Z}}\) (possibly equal to \(\hat{z}_{1},\ldots,\hat{z}_{T}\)), we have with probability \(1-\delta\), for all \(t\in[T]\) simultaneously,_

\[\sum_{i=1}^{t-1}\Bigl{(}\rho(z_{i}\mid\hat{z}_{t})-\rho(z_{i}\mid z^{*}) \Bigr{)}^{2}\leq C_{T,\delta},\text{ and }\]

_where \(C_{T,\delta}=16\beta\beta^{\prime}\ln\bigl{(}2T\mathcal{N}(\tilde{\mathcal{Z }},\beta^{\prime}/T)\ \big{/}\ \delta\bigr{)}\)._

Proof.: For \(i=1,\ldots,T\), let \(h_{i}=(z_{1},r_{1},\ldots,z_{i-1},r_{i-1},z_{i})\) denote the history of interaction up to the query \(z_{i}\), but excluding the response \(r_{i}\), and let \(\xi_{i}=r_{i}-\rho(z_{i}\mid z^{*})\). In the interactive estimation setting, we then have \(\mathbb{E}[\xi_{i}\mid h_{i}]=0\), and by the lemma assumption, \(\mathbb{E}[\xi_{i}^{2}\mid h_{i}]\leq\beta^{2}\).

Since \(\hat{z}_{t}\) is the minimizer of the least squares loss up to time \(t\), we have

\[\sum_{i=1}^{t-1}\Bigl{(}\rho(z_{i}\mid\hat{z}_{t})-r_{i}\Bigr{)}^{2}\leq\sum_{i= 1}^{t-1}\Bigl{(}\rho(z_{i}\mid z^{*})-r_{i}\Bigr{)}^{2},\]which can be rewritten, substituting \(r_{i}=\rho(z_{i}\mid z^{*})+\xi_{i}\), as

\[\sum_{i=1}^{t-1}\Bigl{(}\rho(z_{i}\mid\hat{z}_{t})-\rho(z_{i}\mid z^{*})-\xi_{i} \Bigr{)}^{2}\leq\sum_{i=1}^{t-1}\xi_{i}^{2}.\]

Therefore, by re-arranging terms, we get

\[\sum_{i=1}^{t-1}\Bigl{(}\rho(z_{i}\mid\hat{z}_{t})-\rho(z_{i}\mid z^{*})\Bigr{)} ^{2}\leq 2\sum_{i=1}^{t-1}\xi_{i}\Bigl{(}\rho(z_{i}\mid\hat{z}_{t})-\rho(z_{ i}\mid z^{*})\Bigr{)}.\] (7)

Set \(\epsilon_{1}=\beta^{\prime}\!/T\), and let \(N\) be a minimal \(\epsilon_{1}\)-cover of \(\tilde{\mathcal{Z}}\) with respect to the pseudometric \(\psi\) (see Eq. 6). Furthermore, let \(\hat{z}_{t}^{\epsilon}\in N\) be an element of this cover that is \(\epsilon_{1}\)-close to \(\hat{z}_{t}\) (with respect to \(\psi\)). Then,

\[\sum_{i=1}^{t-1}\Bigl{(}\rho(z_{i}\mid\hat{z}_{t})-\rho(z_{i} \mid z^{*})\Bigr{)}^{2} \leq 2\sum_{i=1}^{t-1}\xi_{i}\Bigl{(}\rho(z_{i}\mid\hat{z}_{t})- \rho(z_{i}\mid z^{*})\Bigr{)}\] \[=2\sum_{i=1}^{t-1}\xi_{i}\Bigl{(}\rho(z_{i}\mid\hat{z}_{t})-\rho( z_{i}\mid\hat{z}_{t}^{\epsilon})\] \[\qquad\qquad\qquad\qquad+\rho(z_{i}\mid\hat{z}_{t}^{\epsilon})- \rho(z_{i}\mid z^{*})\Bigr{)}\] \[\leq 2t\beta\epsilon_{1}+2\sum_{i=1}^{t-1}\xi_{i}\Bigl{(}\rho(z_{ i}\mid\hat{z}_{t}^{\epsilon})-\rho(z_{i}\mid z^{*})\Bigr{)},\] (8)

where the first inequality follows from Eq. (7), and the last inequality follows because \(|\xi_{i}|\leq\beta\) and \(\hat{z}_{t}^{\epsilon}\) is \(\epsilon_{1}\)-close to \(\hat{z}_{t}\).

Now, for any \(z\in N\) and \(i\in[T]\), define

\[K_{i}^{z}=\xi_{i}\Bigl{(}\rho(z_{i}\mid z)-\rho(z_{i}\mid z^{*})\Bigr{)}.\]

Since \(\mathbb{E}[\xi_{i}\mid h_{i}]=0\), we have, for any _fixed_\(z\in N\), \(\mathbb{E}[K_{i}^{z}\mid h_{i}]=0\). This means that for any fixed \(z\in N\), \(K_{1}^{z},\ldots,K_{T}^{z}\) is a martingale difference sequence. By the lemma assumptions, \(|K_{i}^{z}|\leq\beta\beta^{\prime}\). Also,

\[\mathbb{E}\bigl{[}(K_{i}^{z})^{2}\mid h_{i}\bigr{]}\leq\beta^{2}\mathbb{E} \Bigl{[}\bigl{(}\rho(z_{i}\mid z)-\rho(z_{i}\mid z^{*})\bigr{)}^{2}\,\Big{|}\, h_{i}\Bigr{]}=\beta^{2}\bigl{(}\rho(z_{i}\mid z)-\rho(z_{i}\mid z^{*})\bigr{)}^{2}.\] (9)

Thus, by Freedman's inequality (Lemma 16) with \(\eta=1/(4\beta\beta^{\prime})\) and \(\delta^{\prime}=\frac{\delta}{T|N|}\), we obtain that for any fixed \(z\in N\) and \(t\in[T]\), with probability at least \(1-\delta^{\prime}\),

\[\sum_{i=1}^{t-1}\xi_{i}\Bigl{(}\rho(z_{i}\mid z)-\rho(z_{i}\mid z ^{*})\Bigr{)} \leq\frac{1}{4\beta\beta^{\prime}}\sum_{i=1}^{t-1}\beta^{2}\Bigl{(} \rho(z_{i}\mid z)-\rho(z_{i}\mid z^{*})\Bigr{)}+4\beta\beta^{\prime}\ln\! \left(\frac{T|N|}{\delta}\right)\] \[=\frac{\beta}{4\beta^{\prime}}\sum_{i=1}^{t-1}\Bigl{(}\rho(z_{i} \mid z)-\rho(z_{i}\mid z^{*})\Bigr{)}^{2}\!+4\beta\beta^{\prime}\ln\!\left( \frac{T|N|}{\delta}\right)\!.\] (10)

Taking a union bound over all \(z\in N\) and \(t\in[T]\), we obtain that Eq. (10) holds with probability at least \(1-\delta\) simultaneously for all \(z\in N\) and \(t\in[T]\). Henceforth, we assume that we are in the event when Eq. (10) holds for all \(z\in N\) and \(t\in[T]\).

Applying the bound of Eq. (10) with \(z=\hat{z}_{t}^{\epsilon}\) to the sum on the right-hand side of Eq. (8) then yields

\[\sum_{i=1}^{t-1}\Bigl{(}\rho(z_{i}\mid\hat{z}_{t})-\rho(z_{i}\mid z ^{*})\Bigr{)}^{2}\leq 2t\beta\epsilon_{1}+\frac{\beta}{2\beta^{\prime}}\sum_{i=1}^{t-1} \Bigl{(}\rho(z_{i}\mid\hat{z}_{t}^{\epsilon})-\rho(z_{i}\mid z^{*})\Bigr{)}^{2}\] (11) \[\qquad\qquad\qquad\qquad\qquad\qquad+8\beta\beta^{\prime}\ln\! \left(\frac{T|N|}{\delta}\right)\!.\]

Using the inequality \((a+b)^{2}\leq 2a^{2}+2b^{2}\), which holds for any \(a,b\in\mathbb{R}\), and the fact that \(\hat{z}_{t}^{\epsilon}\) and \(\hat{z}_{t}\) are \(\epsilon_{1}\)-close, we obtain, for every \(i=1,\ldots,t-1\),

\[\Bigl{(}\rho(z_{i}\mid\hat{z}_{t}^{\epsilon})-\rho(z_{i}\mid z^{*})\Bigr{)}^{2} =\Bigl{(}\bigl{[}\rho(z_{i}\mid\hat{z}_{t}^{\epsilon})-\rho(z_{i}\mid\hat{z}_{t}) \bigr{]}+\bigl{[}\rho(z_{i}\mid\hat{z}_{t})-\rho(z_{i}\mid z^{*})\bigr{]} \Bigr{)}^{2}\]\[\leq 2\epsilon_{1}^{2}+2\big{(}\rho(z_{i}\mid z^{*})-\rho(z_{i}\mid\hat{z }_{t})\big{)}^{2}.\]

Plugging this into the right-hand side of Eq. (11) yields

\[\sum_{i=1}^{t-1}\Bigl{(}\rho(z_{i}\mid\hat{z}_{t})-\rho(z_{i}\mid z ^{*})\Bigr{)}^{2} \leq 2t\beta\epsilon_{1}+\frac{\beta}{\beta^{\prime}}t\epsilon_{1}^ {2}+\frac{\beta}{\beta^{\prime}}\sum_{i=1}^{t-1}\Bigl{(}\rho(z_{i}\mid\hat{z}_ {t})-\rho(z_{i}\mid z^{*})\Bigr{)}^{2}\] \[\qquad\qquad\qquad\qquad\qquad+8\beta\beta^{\prime}\ln\biggl{(} \frac{T|N|}{\delta}\biggr{)}\] \[\leq 2t\beta\epsilon_{1}+\frac{t\beta\epsilon_{1}^{2}}{\beta^{ \prime}}+\frac{1}{2}\sum_{i=1}^{t-1}\Bigl{(}\rho(z_{i}\mid\hat{z}_{t})-\rho( z_{i}\mid z^{*})\Bigr{)}^{2}\] \[\qquad\qquad\qquad\qquad\qquad+8\beta\beta^{\prime}\ln\biggl{(} \frac{T|N|}{\delta}\biggr{)},\]

where the last inequality follows by the assumption that \(\beta^{\prime}\geq 2\beta\). Then, by re-arranging terms and multiplying by \(2\), we get

\[\sum_{i=1}^{t-1}\Bigl{(}\rho(z_{i}\mid\hat{z}_{t})-\rho(z_{i}\mid z^{*}) \Bigr{)}^{2} \leq 4t\beta\epsilon_{1}+\frac{2t\beta\epsilon_{1}^{2}}{\beta^{ \prime}}+16\beta\beta^{\prime}\ln\biggl{(}\frac{T|N|}{\delta}\biggr{)}.\]

Recall that we set \(\epsilon_{1}=\beta^{\prime}/T\), and \(N\) is a minimal \(\epsilon_{1}\)-cover of \(\tilde{\mathcal{Z}}\), so \(|N|=\mathcal{N}(\tilde{\mathcal{Z}},\beta^{\prime}/T)\). Plugging these values in the previous equation, we thus obtain that with probability at least \(1-\delta\), for all \(t\in[T]\),

\[\sum_{i=1}^{t-1}\Bigl{(}\rho(z_{i}\mid\hat{z}_{t})-\rho(z_{i}\mid z ^{*})\Bigr{)}^{2} \leq 4\beta\beta^{\prime}+\frac{2\beta\beta^{\prime}}{T}+16\beta \beta^{\prime}\ln\biggl{(}\frac{T\mathcal{N}(\tilde{\mathcal{Z}},\beta^{ \prime}/T)}{\delta}\biggr{)}\] \[\leq 16\beta\beta^{\prime}\ln\biggl{(}\frac{2T\mathcal{N}(\tilde{ \mathcal{Z}},\beta^{\prime}/T)}{\delta}\biggr{)},\] (12)

where the last inequality follows because \(4+2/T\leq 16\ln 2\) for \(T\geq 1\). Finally, when Eq. (12) holds, we also have

\[z^{*}\in\biggl{\{}z\in\tilde{\mathcal{Z}}:\;\sum_{i=1}^{t-1}\Bigl{(}\rho(z_{ i}\mid z)-\rho(z_{i}\mid\hat{z}_{t})\Bigr{)}^{2}\leq 16\beta\beta^{\prime}\ln \biggl{(}\frac{2T\mathcal{N}(\tilde{\mathcal{Z}},\beta^{\prime}/T)}{\delta} \biggr{)}\biggr{\}}.\qed\]

Considering Algorithm 1 and using Theorem 17 with \(\tilde{\mathcal{Z}}=\mathcal{Z}_{\alpha}\), \(z_{t}=\hat{z}_{t}\), \(\beta=2\) and \(\beta^{\prime}=4\) then immediately yields the following corollary (\(\alpha\)-large self-evaluations follow because \(\hat{z}_{t}\in\mathcal{Z}_{\alpha}\)):

**Corollary 18**.: _Consider the setting from Section 2 with a set of alternatives \(\mathcal{Z}\) and an evaluation function \(\rho\). Let \(\alpha\) be an optimality level such that \(\mathcal{N}(\mathcal{Z}_{\alpha},4/T)=e^{o(T)}\). Then Algorithm 1 has \(\alpha\)-large self-evaluations and satisfies the decaying error property with \(C_{T,\delta}=128\ln\bigl{(}2T\mathcal{N}(\mathcal{Z}_{\alpha},4/T)/\delta \bigr{)}\)._

Similarly, Theorem 17 also implies that Algorithm 3 satisfies the decaying error property as well as \(\alpha^{*}\)-large self-evaluations, although \(\alpha^{*}\) is not known:

**Corollary 19**.: _Consider the setting from Section 2 with a set of alternatives \(\mathcal{Z}\) and an evaluation function \(\rho\), and assume that \(\mathcal{N}(\mathcal{Z},4/T)=e^{o(T)}\). Then Algorithm 3 with \(R=128\ln\bigl{(}2T\mathcal{N}(\mathcal{Z},4/T)\bigr{/}\delta\bigr{)}\) has \(\alpha^{*}\)-large self-evaluations and satisfies the decaying error property with \(C_{T,\delta}=4R=512\ln\bigl{(}2T\mathcal{N}(\mathcal{Z},4/T)/\delta\bigr{)}\)._

Proof.: We apply Theorem 17 with \(\tilde{\mathcal{Z}}=\mathcal{Z}\), \(\beta=2\) and \(\beta^{\prime}=4\). Our choice of \(R\) in Algorithm 3 coincides with the value of \(C_{T,\delta}\) appearing in Theorem 17, and therefore the theorem implies that \(z^{*}\in\mathcal{Z}_{t}\) with probability at least \(1-\delta\) for all \(t\in[T]\). In that case the queries \(z_{t}\) issued by the algorithm satisfy \(\rho(z_{t}\mid z_{t})\geq\rho(z^{*}\mid z^{*})=\alpha^{*}\) and thus the algorithm has \(\alpha^{*}\)-large self-evaluations.

For the second part, the triangle inequality implies that with probability at least \(1-\delta\) for all \(t\in[T]\),

\[\sqrt{\sum_{i=1}^{t-1}\Bigl{(}\rho(z_{i}\mid z)-\rho(z_{i}\mid z _{t})\Bigr{)}^{2}} \leq\sqrt{\sum_{i=1}^{t-1}\Bigl{(}\rho(z_{i}\mid z)-\rho(z_{i} \mid\hat{z}_{t})\Bigr{)}^{2}}+\sqrt{\sum_{i=1}^{t-1}\Bigl{(}\rho(z_{i}\mid \hat{z}_{t})-\rho(z_{i}\mid z_{t})\Bigr{)}^{2}}\] \[\leq\sqrt{R}+\sqrt{R},\]

where the bound on the first term on the right-hand side follows by Theorem 17 and the bound on the second term by the fact that \(z_{t}\in\mathcal{Z}_{t}\)

### Proof of Theorem 4

The theorem follows immediately from Corollary 18, because \(\mathcal{N}(\mathcal{Z}_{\alpha},\epsilon)\leq|\mathcal{Z}_{\alpha}|\leq| \mathcal{Z}|<\infty\) for any \(\alpha\) and \(\epsilon\).

### Online Regression Oracles

We assume access to an _online regression oracle_\(\mathcal{R}\)_eg_, which solves a regression problem over a function class \(\Phi=\{\phi_{z}:z\in\mathcal{Z}\}\) indexed by \(z\in\mathcal{Z}\), where \(\phi_{z}:\mathcal{Z}\rightarrow\mathbb{R}\) is defined as \(\phi_{z}(z^{\prime})=\rho(z^{\prime}\mid z)\) for all \(z^{\prime}\in\mathcal{Z}\); that is, functions \(\phi_{z}\) evaluate \(\rho\) in its first argument.

The oracle operates in the following protocol: In each time step, the oracle receives an observation \(z_{t}\), produces a prediction \(\widehat{\rho}_{t}\in\mathbb{R}\), and finally receives a response \(r_{t}\) and incurs square loss \((\widehat{\rho}_{t}-r_{t})^{2}\). We assume that for any \(T\) and sequence of observations and responses (even if generated adaptively), the oracle satisfies the following regret bound:

\[\sum_{t=1}^{T}(\widehat{\rho}_{t}-r_{t})^{2}-\inf_{z\in\mathcal{Z}}\sum_{t=1} ^{T}(\rho(z_{t}\mid z)-r_{t})^{2}\leq\mathrm{Regret}_{\mathcal{R}\text{eg}}(T),\] (13)

where \(\mathrm{Regret}_{\mathcal{R}\text{eg}}(\cdot)\) is a non-decreasing sublinear function (that typically also depends on various properties of \(\rho\), \(\mathcal{Z}\), and the range of responses \(r_{t}\)). For many function classes, there are well-known constructions of online regression oracles that satisfy Eq. (13) [9, 28, 18]. For example, if \(\Phi\) is finite, there are oracles with \(\mathrm{Regret}_{\mathcal{R}\text{eg}}(T)=O(\ln|\Phi|)\) and for parametric classes, such as linear functions, there are oracles with \(\mathrm{Regret}_{\mathcal{R}\text{eg}}(T)=O(d\log(T/d))\). More examples can be found in Section 2.2 of Foster and Rakhlin [14].

```
1:Input: online regression oracle \(\mathcal{R}\)eg, optimality level \(\alpha\).
2: Initialize \(z_{1}\) to an arbitrary element of \(\mathcal{Z}_{\alpha}\).
3:for\(t=1\ldots T\)do
4: Use \(\mathcal{R}\)eg to predict \(\widehat{\rho}_{t}\) given the observation \(z_{t}\).
5: Observe reward \(r_{t+1}\) and pass it to \(\mathcal{R}\)eg.
6: Set \(z_{t+1}=\operatorname*{argmin}_{z\in\mathcal{Z}_{\alpha}}\sum_{i=1}^{t}\Big{(} \rho(z_{i}\mid z)-\widehat{\rho}_{i}\Big{)}^{2}\).
7:endfor ```

**Algorithm 4** Interactive Estimation via Least Squares

We now analyze Algorithm 4 under the assumption of access to an online regression oracle. This algorithm takes as input an online regression oracle \(\mathcal{R}\)_eg_. Algorithm 4 can also be modified using the optimistic least squares template of Russo and Van Roy [24] to handle the case when \(\alpha^{*}\) is unknown. This is done by replacing step 6 of Algorithm 4 with the following two steps:

\[\mathcal{Z}_{t+1} =\Big{\{}z\in\mathcal{Z}:\;\sum_{i=1}^{t}(\rho(z_{i}\mid z)- \widehat{\rho}_{i})^{2}\leq R\Big{\}},\] \[z_{t+1} =\operatorname*{argmax}_{z\in\mathcal{Z}_{t+1}}\rho(z\mid z),\]

where \(R=8\mathrm{Regret}_{\mathcal{R}\text{eg}}(T)+64\beta\max\{\beta,\beta^{ \prime}\}\ln\bigl{(}\frac{T}{\delta}\bigr{)}\) and \(\beta,\beta^{\prime}\) are defined as in Lemma 20. The results of Lemma 20 justify the validity of these choices (using a similar reasoning as in Corollary 19) and imply that Algorithm 4 satisfies the decaying estimation error property (Definition 3), provided that the regression oracle \(\mathcal{R}\)_eg_ satisfies the regret bound of Eq. (13).

**Lemma 20**.: _Consider the setting defined in Section 2 with \(\alpha\leq\alpha^{*}\), and assume there are \(\beta,\beta^{\prime}\geq 0\) such that \(|r_{t}-\mathbb{E}[r_{t}\mid z_{t}]|\leq\beta\) for all \(t\) and there is \(\beta^{\prime}\geq 2\beta\) s.t. for all \(z\in\mathcal{Z}\) and \(\widehat{\rho}\in\Gamma_{z}\), \(\bigl{|}\widehat{\rho}-\rho(z\mid z^{*})\bigr{|}\leq\beta^{\prime}\) where \(\Gamma_{z}\subset\mathbb{R}\) is the space of plausible responses of \(\mathcal{R}\)eg for input \(z\). The sequence of queries \(z_{1},\ldots,z_{T}\) as defined in Algorithm 4 satisfies with probability at least \(1-\delta\) for all \(t\in[T]\) simultaneously,_

\[\sum_{i=1}^{t}\left(\rho(z_{i}\mid z_{t+1})-\rho(z_{i}\mid z^{*})\right)^{2}\leq C _{T,\delta}\quad\text{ and }\quad z^{*}\in\Big{\{}z\in\mathcal{Z}_{\alpha}:\;\sum_{i=1}^{t}( \rho(z_{i}\mid z)-\widehat{\rho}_{i})^{2}\leq C_{T,\delta}\Big{\}}\]

_where \(C_{T,\delta}=8\mathrm{Regret}_{\mathcal{R}\text{eg}}(T)+64\beta\max\{\beta, \beta^{\prime}\}\ln\bigl{(}\frac{T}{\delta}\bigr{)}\)._Proof.: Let \(\xi_{i}=r_{i}-\rho(z_{i}\mid z^{*})\). Recall that \(\mathbb{E}[r_{i}\mid z_{i}]=\rho(z_{i}\mid z^{*})\) and therefore, by assumption, \(|\xi_{i}|\leq\beta\) for all \(i\). By definition, the online regression oracle satisfies

\[\sum_{i=1}^{t}(\widehat{\rho}_{i}-r_{i})^{2} \leq\inf_{z\in\mathcal{Z}}\sum_{i=1}^{t}(\rho(z_{i}\mid z)-r_{i}) ^{2}+\mathrm{Regret}_{\mathcal{R}\epsilon g}(t)\] \[\overset{(i)}{\leq}\sum_{i=1}^{t}(\rho(z_{i}\mid z^{*})-r_{i})^{2 }+\mathrm{Regret}_{\mathcal{R}\epsilon g}(t)\] \[=\sum_{i=1}^{t}\xi_{i}^{2}+\mathrm{Regret}_{\mathcal{R}\epsilon g }(t).\] (14)

Inequality \((i)\) holds because \(z^{*}\in\mathcal{Z}\). Expanding the LHS,

\[\sum_{i=1}^{t}(\widehat{\rho}_{i}-r_{i})^{2}=\sum_{i=1}^{t}\Bigl{[}(\widehat {\rho}_{i}-\rho(z_{i}\mid z^{*}))^{2}-2\xi_{i}(\widehat{\rho}_{i}-\rho(z_{i} \mid z^{*}))+\xi_{i}^{2}\Bigr{]}.\]

Plugging this back into Eq. (14) and rearranging, we obtain

\[\sum_{i=1}^{t}(\widehat{\rho}_{i}-\rho(z_{i}\mid z^{*}))^{2}\leq\sum_{i=1}^{t }2\xi_{i}(\widehat{\rho}_{i}-\rho(z_{i}\mid z^{*}))+\mathrm{Regret}_{\mathcal{ R}\epsilon g}(t).\] (15)

For any \(i\in[T]\) we define:

\[K_{i}=\xi_{i}(\widehat{\rho}_{i}-\rho(z_{i}\mid z^{*}))\]

Observe that

\[\mathbb{E}\left[K_{i}\mid\{z_{\ell},\widehat{\rho}_{\ell}\}_{\ell=1}^{i} \right]=0.\]

Thus \(K_{1},\ldots,K_{T}\) is a martingale difference sequence. Notice that \(|K_{i}|\leq\beta\beta^{\prime}\) and that

\[\mathbb{E}\bigl{[}K_{i}^{2}\mid\{z_{\ell},\widehat{\rho}_{\ell}\}_{\ell=1}^{i }\bigr{]}\leq\beta^{2}\mathbb{E}\Bigl{[}\bigl{(}\widehat{\rho}_{i}-\rho(z_{i} \mid z^{*})\bigr{)}^{2}\,\big{|}\,\{z_{\ell},\widehat{\rho}_{\ell}\}_{\ell=1}^ {i}\Bigr{]}=\beta^{2}\bigl{(}\widehat{\rho}_{i}-\rho(z_{i}\mid z^{*})\bigr{)} ^{2}.\]

Then, by plugging this into Freedman's inequality (Lemma 16) with \(\eta:=\frac{1}{4}\min(1/\beta^{2},1/\beta\beta^{\prime})\) and \(\delta^{\prime}:=\delta/T\), we get that for any fixed \(t\in[T]\), with probability at least \(1-\delta\),

\[\sum_{i=1}^{t}\xi_{i}\bigl{(}\widehat{\rho}_{i}-\rho(z_{i}\mid z^{*})\bigr{)} \leq\frac{1}{4}\sum_{i=1}^{t}\bigl{(}\widehat{\rho}_{i}-\rho(z_{i}\mid z^{*}) \bigr{)}^{2}+4\beta\max\{\beta,\beta^{\prime}\}\ln\left(\frac{T}{\delta}\right).\] (16)

Plugging Eq. (16) back into Eq. (15) and rearranging terms yields

\[\sum_{i=1}^{t}(\widehat{\rho}_{i}-\rho(z_{i}\mid z^{*}))^{2}\leq 2\mathrm{ Regret}_{\mathcal{R}\epsilon g}(t)+16\beta\max\{\beta,\beta^{\prime}\}\ln \left(\frac{T}{\delta}\right)\] (17)

with probability at least \(1-\delta\) for all \(t\in[T]\). Thus we conclude that with probability at least \(1-\delta\), for all \(t\in[T]\),

\[z^{*}\in\Bigl{\{}z\in\mathcal{Z}_{\alpha}:\,\sum_{i=1}^{t}(\rho(z_{i}\mid z)- \widehat{\rho}_{i})^{2}\leq C_{T,\delta}\Bigr{\}}.\]

By the triangle inequality,

\[\sqrt{\sum_{i=1}^{t}(\rho(z_{i}\mid z^{*})-\rho(z_{i}\mid z_{t+1}))^{2}}\leq \sqrt{\sum_{i=1}^{t}(\rho(z_{i}\mid z^{*})-\widehat{\rho}_{i})^{2}}+\sqrt{ \sum_{i=1}^{t}(\widehat{\rho}_{i}-\rho(z_{i}\mid z_{t+1}))^{2}}.\]

Since by definition \(z_{t+1}=\operatorname*{argmin}_{z\in\mathcal{Z}_{\alpha}}\sum_{i=1}^{t}\left( \rho(z_{i}\mid z)-\widehat{\rho}_{i}\right)^{2}\), we have

\[\sum_{i=1}^{t}\left(\rho(z_{i}\mid z_{t+1})-\widehat{\rho}_{i}\right)^{2}\leq \sum_{i=1}^{t}\left(\rho(z_{i}\mid z^{*})-\widehat{\rho}_{i}\right)^{2}.\]Substituting back into the triangle inequality above,

\[\sqrt{\sum_{i=1}^{t}(\rho(z_{i}\mid z^{*})-\rho(z_{i}\mid z_{t+1}))^{2}}\leq 2 \sqrt{\sum_{i=1}^{t}(\rho(z_{i}\mid z^{*})-\widehat{\rho}_{i})^{2}},\]

implying

\[\sum_{i=1}^{t}(\rho(z_{i}\mid z^{*})-\rho(z_{i}\mid z_{t+1}))^{2}\leq 4\sum_{i=1} ^{t}(\rho(z_{i}\mid z^{*})-\widehat{\rho}_{i})^{2}.\]

Plugging Eq. (17) on the right-hand side yields

\[\sum_{i=1}^{t}(\rho(z_{i}\mid z^{*})-\rho(z_{i}\mid z_{t+1}))^{2}\leq 8\mathrm{ Regret}_{\mathcal{R}\mathfrak{eg}}(t)+64\beta\max\{\beta,\beta^{\prime}\}\ln \left(\frac{T}{\delta}\right).\]

The result follows by using the monotonicity of \(\mathrm{Regret}_{\mathcal{R}\mathfrak{eg}}(t)\). 

### Proof of Lemma 5

The proof uses Turan's Theorem [26], a standard result from extremal graph theory that bounds the number of edges of a graph that does not contain a clique of a given size:

**Theorem 21** (Turan's Theorem).: _Let \(G=(V,E)\) be an undirected graph without self-loops and whose largest clique is of size at most \(d\). Then_

\[|E|\leq\left(1-\frac{1}{d}\right)\frac{|V|^{2}}{2}.\]

We now turn to the proof of Lemma 5. First note that if \(\epsilon\geq 1+\alpha\) then no query is \(\epsilon\)-bad, because \(\alpha-\epsilon\leq-1\leq\rho(z\mid z^{*})\) for every \(z\in\mathcal{Z}\), and therefore the lemma holds. In the remainder of the proof, we assume that \(0<\epsilon<1+\alpha\).

Consider the queries \(z_{1},\ldots,z_{T}\) and their corresponding values relative to \(z^{*}\), denoted as \(v_{t}=\rho(z_{t}|z^{*})\) for \(t\in[T]\). A query \(z_{t}\) is \(\epsilon\)-bad if its corresponding value \(v_{t}\) is in the interval \(I=[-1,\alpha-\epsilon)\). The proof proceeds by partitioning the interval \(I\) into subintervals and separately bounding the number of values \(v_{t}\) in each subinterval.

To define these subintervals, let \(q=1+\frac{1}{\sqrt{d}}\), and consider the sequence of suboptimality gaps \(\epsilon_{i}=q^{i-1}\epsilon\) for \(i=1,\ldots,n+1\), where

\[n=\left\lceil\log_{q}\left(\frac{1+\alpha}{\epsilon}\right)\right\rceil.\]

The gaps \(\epsilon_{i}\) form an increasing sequence \(\epsilon,q\epsilon,q^{2}\epsilon,\ldots\) such that the last element satisfies

\[\epsilon_{n+1}=q^{n}\epsilon\geq\left(\frac{1+\alpha}{\epsilon}\right)\epsilon =1+\alpha.\]

Using these gaps we define intervals \(I_{i}=[\alpha-\epsilon_{i+1},\alpha-\epsilon_{i})\) for \(i=1,\ldots,n\). Since \(\epsilon_{n+1}\geq 1+\alpha\), the union \(I_{1}\cup\cdots\cup I_{n}=[\alpha-\epsilon_{n+1},\alpha-\epsilon)\) covers the interval \(I\). We bound the number of values \(v_{t}\) in each interval \(I_{i}\).

Let \(S_{i}\) be the set of query indices with values in \(I_{i}\), that is \(S_{i}=\left\{t\in[T]:\,\rho(z_{t}\mid z^{*})\in I_{i}\right\}\), let \(m_{i}=|S_{i}|\), and assume that \(m_{i}\geq 2\) (the case \(m_{i}\leq 1\) will be dealt with later). Furthermore, let \(c_{i}=\alpha-(\epsilon_{i+1}+\epsilon_{i})/2\) be the midpoint of the interval \(I_{i}\). Since the width of the interval \(I_{i}\) is \(\epsilon_{i+1}-\epsilon_{i}=(q-1)\epsilon_{i}=\epsilon_{i}/\sqrt{d}\), we obtain

\[\left|\rho(z_{t}\mid z^{*})-c_{i}\right|\leq\frac{\epsilon_{i}}{2\sqrt{d}}\] (18)

for all \(t\in S_{i}\).

Let \(d_{i}=\mathfrak{d}_{\rho}(\mathcal{Z},\alpha,\epsilon_{i})\) be the (non-monotonic) dissimilarity dimension with respect to the suboptimality gap \(\epsilon_{i}\). Since \(\alpha\leq\alpha^{*}\) and \(\epsilon_{i}\geq\epsilon\), we have \(1\leq d_{i}\leq d\). We construct an upper bound on \(m_{i}\), exploiting the fact that \(d_{i}\) is the dissimilarity dimension with respect to \(\epsilon_{i}\).

In the rest of the proof we refer to a pair of queries with indices \(s,t\in S_{i}\) such that \(s<t\) as _dissimilar_ if

\[\left|\rho(z_{s}\mid z_{t})-c_{i}\right|\leq\frac{\epsilon_{i}}{\sqrt{d_{i}}}.\]

This is exactly the property appearing in the definition of the dissimilarity dimension with respect to \(\epsilon_{i}\), and so there cannot be more than \(d_{i}\) queries such that every pair is dissimilar (note that all the queries \(z_{t}\) satisfy \(\rho(z_{t}\mid z_{t})\geq\alpha\) thanks to \(\alpha\)-large self-evaluations).

The derivation of the bound on \(m_{i}\) proceeds in several steps. First, we identify pairs of dissimilar queries and construct a graph where each edge corresponds to a dissimilar pair. Second, we use Turan's Theorem (Theorem 21) to upper bound the number of such pairs, using the fact that the graph cannot contain a clique of size greater than \(d_{i}\). Finally, using the bound on the number of dissimilar pairs, we bound \(m_{i}\).

To start, let \(t_{1}<t_{2}<\ldots<t_{m_{i}}\) be the query indices included in \(S_{i}\), and let \(k\in\{2,\ldots,m_{i}\}\). Consider a uniform distribution over \(\ell\in[k-1]\). Then by Markov's inequality and the decaying estimation error property, we obtain

\[\frac{1}{k-1}\sum_{\ell=1}^{k-1}\mathbf{1}\Bigg{[}\Big{(}\rho(z_{ t_{\ell}}\mid z_{t_{k}})-\rho(z_{t_{\ell}}\mid z^{*})\Big{)}^{2}\geq\frac{ \epsilon_{i}^{2}}{4d}\Bigg{]} \leq\Bigg{[}\frac{1}{k-1}\sum_{\ell=1}^{k-1}\Bigl{(}\rho(z_{t_{ \ell}}\mid z_{t_{k}})-\rho(z_{t_{\ell}}\mid z^{*})\Bigr{)}^{2}\Bigg{]}\cdot \frac{4d}{\epsilon_{i}^{2}}\] \[\leq\Bigg{[}\frac{1}{k-1}\sum_{s=1}^{t_{k}-1}\Bigl{(}\rho(z_{s} \mid z_{t_{k}})-\rho(z_{s}\mid z^{*})\Bigr{)}^{2}\Bigg{]}\cdot\frac{4d}{ \epsilon_{i}^{2}}\] \[\leq\frac{C_{T,\delta}}{k-1}\cdot\frac{4d}{\epsilon_{i}^{2}}.\]

Multiplying by \(k-1\), we therefore obtain

\[\left|\left\{s\in S_{i}:\,s<t_{k}\text{ and }\left|\rho(z_{s}\mid z_{t_{k}})- \rho(z_{s}\mid z^{*})\right|\geq\frac{\epsilon_{i}}{2\sqrt{d}}\right\}\right| \leq\frac{4dC_{T,\delta}}{\epsilon_{i}^{2}},\]

and summing across all \(k\in\{2,\ldots,m_{i}\}\) then yields

\[\left|\left\{s,t\in S_{i}:\,s<t\text{ and }\left|\rho(z_{s}\mid z_{t})- \rho(z_{s}\mid z^{*})\right|\geq\frac{\epsilon_{i}}{2\sqrt{d}}\right\}\right| \leq m_{i}\frac{4dC_{T,\delta}}{\epsilon_{i}^{2}}.\] (19)

We next construct an undirected graph without self-loops, \(G_{i}=(V_{i},E_{i})\). The vertex set of the graph is \(V_{i}=S_{i}\). The edge set is defined to be

\[E_{i}=\left\{\left\{t,s\right\}\subseteq S_{i}:\,s<t\text{ and }\left|\rho(z_{s}\mid z_{t})- \rho(z_{s}\mid z^{*})\right|<\frac{\epsilon_{i}}{2\sqrt{d}}\right\}.\]

By comparing with Eq. (19), we obtain

\[\left|E_{i}\right|\geq\frac{m_{i}(m_{i}-1)}{2}-m_{i}\frac{4dC_{T,\delta}}{ \epsilon_{i}^{2}}.\] (20)

Note that any pair of vertices \(s<t\) connected by an edge corresponds to a dissimilar pair of queries:

\[\left|\rho(z_{s}\mid z_{t})-c_{i}\right| \leq\left|\rho(z_{s}\mid z_{t})-\rho(z_{s}\mid z^{*})\right|+ \left|\rho(z_{s}\mid z^{*})-c_{i}\right|\] \[<\frac{\epsilon_{i}}{2\sqrt{d}}+\frac{\epsilon_{i}}{2\sqrt{d}}\] \[\leq\frac{\epsilon_{i}}{\sqrt{d_{i}}},\]

where the first inequality is the triangular inequality, the second inequality follows by combining the definition of \(E_{i}\) and Eq. (18), and the final one is from the fact that \(d_{i}\leq d\). From the definition of the dissimilarity coefficient, the largest clique in \(G_{i}\) is of size at most \(d_{i}\). Using Turan's Theorem, we thus must have

\[\left|E_{i}\right|\leq\left(1-\frac{1}{d_{i}}\right)\cdot\frac{m_{i}^{2}}{2} \leq\left(1-\frac{1}{d}\right)\cdot\frac{m_{i}^{2}}{2}.\]Combining with the lower bound on \(|E_{i}|\) from Eq. (20), we obtain

\[\frac{m_{i}(m_{i}-1)}{2}-m_{i}\frac{4dC_{T,\delta}}{\epsilon_{i}^{2}}\leq\left(1- \frac{1}{d}\right)\cdot\frac{m_{i}^{2}}{2}.\]

Dividing by \(m_{i}\), multiplying by \(2d\), and rearranging then yields

\[m_{i}\leq 2d\left(\frac{1}{2}+\frac{4dC_{T,\delta}}{\epsilon_{i}^{2}}\right)=d+ \frac{8d^{2}C_{T,\delta}}{\epsilon_{i}^{2}}.\]

We have originally assumed that \(m_{i}\geq 2\), but the bound that we have just derived also holds when \(m_{i}\leq 1\) (because \(d\geq 1\)).

To complete the proof it suffices to sum up the upper bounds on \(m_{i}\) across \(i=1,\ldots,n\):

\[\sum_{i=1}^{n}m_{i} =\sum_{i=1}^{n}\Biggl{[}d+\frac{8d^{2}C_{T,\delta}}{\epsilon^{2} }\cdot\left(1/q^{2}\right)^{i-1}\Biggr{]}\] \[\leq nd+\frac{8d^{2}C_{T,\delta}}{\epsilon^{2}}\cdot\frac{1}{1- (1/q^{2})}.\] (21)

To bound \(n\), we use the fact that \(\alpha\leq 1\), the inequality \(\ln(1+x)\geq\frac{x}{1+x}\) (which holds for \(x\geq 0\)), and the fact that \(d\geq 1\):

\[n \leq 1+\log_{q}(2/\epsilon)\] \[=1+\frac{\ln(2/\epsilon)}{\ln(1+\frac{1}{\sqrt{d}})}\leq 1+[\ln(2/ \epsilon)]\cdot\frac{1+\frac{1}{\sqrt{d}}}{\frac{1}{\sqrt{d}}}=1+(\sqrt{d}+1) \ln(2/\epsilon)\] \[\leq 2\ln 2+2\sqrt{d}\ln(2/\epsilon)\leq 2\sqrt{d}\ln(4/ \epsilon).\]

Also,

\[1-\frac{1}{q^{2}}=1-\frac{1}{1+\frac{2}{\sqrt{d}}+\frac{1}{d}}\geq 1-\frac{1}{1 +\frac{2}{\sqrt{d}}}=\frac{\frac{2}{\sqrt{d}}}{1+\frac{2}{\sqrt{d}}}=\frac{2 }{\sqrt{d}+2}\geq\frac{2}{3\sqrt{d}}.\]

Plugging these back in Eq. (21) yields

\[\sum_{i=1}^{n}m_{i}\leq 2d^{1.5}\ln(4/\epsilon)+\frac{12d^{2.5}C_{T,\delta}}{ \epsilon^{2}},\]

completing the proof of the main claim of the lemma.

The second claim holds vacuously when \(T=0\), so assume that \(T\geq 1\). If \(C_{T,\delta}\geq\ln(2T)\), and using the fact that \((\ln x)\leq x\) and \(2\leq 3\ln 2\), we can write

\[2d^{1.5}\ln(4/\epsilon)=d^{1.5}\ln(16/\epsilon^{2})\leq\frac{16d^{1.5}}{ \epsilon^{2}}\leq\frac{24(\ln 2)d^{1.5}}{\epsilon^{2}}\leq\frac{24d^{2.5}}{ \epsilon^{2}}\cdot\ln(2T)\leq\frac{24d^{2.5}C_{T,\delta}}{\epsilon^{2}},\]

which yields the first part of the second claim. The second part is immediate by plugging in \(C_{T,\delta}=0\) in the main claim.

### Useful lemmas

In this subsection we prove two lemmas that will be needed for the proofs of the main results (Theorems 6 and 7) in Appendices A.6 and A.7. They both rely on a standard technique of bounding a sum by a definite integral:

**Proposition 22**.: _Let \(f:\mathbb{R}\rightarrow\mathbb{R}\) be a non-increasing function and \(T\geq 1\). Then_

\[\sum_{t=1}^{T}f(t)\leq f(1)+\int_{1}^{T}f(t)\mathrm{d}t.\]

Proof.: The proof is immediate by noting that \(f(t)\leq\int_{t-1}^{t}f(t)\mathrm{d}t\). 

In the lemmas below we write \(\mathbb{R}_{+}\) to denote \([0,+\infty)\).

**Lemma 23**.: _Let \(q_{1},\ldots,q_{T}\) be a sequence in \(\mathbb{R}_{+}\), and let \(\kappa:\mathbb{R}_{+}\rightarrow\mathbb{R}_{+}\) be a non-increasing function such that for all \(\epsilon>0\),_

\[\sum_{t=1}^{T}\mathbf{1}(q_{t}\geq\epsilon)\leq\frac{\kappa(\epsilon)}{ \epsilon^{2}}.\]

_Then, for any \(\tau\geq 0\),_

\[\sum_{t=1}^{T}q_{t}\leq T\tau+2\sqrt{\kappa(\tau)T}.\]

Proof.: First, since we are only concerned with bounding the sum \(\sum_{t}q_{t}\), we assume without loss of generality that the sequence is in descending order, i.e., \(q_{1}\geq\cdots\geq q_{T}\). Then, for any \(\tau\geq 0\),

\[\sum_{t=1}^{T}q_{t}=\sum_{t=1}^{T}q_{t}\mathbf{1}(q_{t}\leq\tau)+\sum_{t=1}^{T }q_{t}\mathbf{1}(q_{t}>\tau)\leq T\tau+\sum_{t=1}^{T}q_{t}\mathbf{1}(q_{t}> \tau).\] (22)

Consider any \(k\) such that \(q_{k}>\tau\). Since the sequence \(q_{1},\ldots,q_{T}\) is non-increasing, we have

\[k\leq\sum_{t=1}^{T}\mathbf{1}(q_{t}\geq q_{k})\leq\frac{\kappa(q_{k})}{q_{k}^ {2}}\leq\frac{\kappa(\tau)}{q_{k}^{2}},\]

where the last inequality follows by the monotonicity of \(\kappa\). This in turn implies that \(q_{k}\leq\sqrt{\frac{\kappa(\tau)}{k}}\). Therefore,

\[\sum_{t=1}^{T}q_{t}\mathbf{1}(q_{t}>\tau)\leq\sum_{t=1}^{T}\sqrt{\frac{\kappa( \tau)}{t}}.\] (23)

By Proposition 22,

\[\sum_{t=1}^{T}\frac{1}{\sqrt{t}}\leq 1+2\sqrt{T}-2\sqrt{1}<2\sqrt{T}.\] (24)

Combining Eqs. (22), (23) and (24), we get

\[\sum_{t=1}^{T}q_{t}\leq T\tau+2\sqrt{\kappa(\tau)T}.\]

which concludes the proof. 

**Lemma 24**.: _Let \(a>0\), let \(q_{1},\ldots,q_{T}\) be a sequence of reals in \([0,a]\), and let \(\kappa:\mathbb{R}_{+}\rightarrow\mathbb{R}_{+}\) be a non-increasing function such that for all \(\epsilon\in(0,a]\),_

\[\sum_{t=1}^{T}\mathbf{1}(q_{t}\geq\epsilon)\leq\kappa(\epsilon)\ln\left( \frac{a}{\epsilon}\right).\]

_Then, for any \(\tau\geq 0\),_

\[\sum_{t=1}^{T}q_{t}\leq T\tau+a[1+\kappa(\tau)]\exp\left(-\frac{1}{\kappa( \tau)}\right).\]

Proof.: We follow a similar proof strategy as in Lemma 23 and start by bounding the sum \(\sum_{t}q_{t}\). We assume without loss of generality that the sequence is in descending order, i.e., \(q_{1}\geq\cdots\geq q_{T}\). Then, for any \(\tau\geq 0\),

\[\sum_{t=1}^{T}q_{t}=\sum_{t=1}^{T}q_{t}\mathbf{1}(q_{t}\leq\tau)+\sum_{t=1}^{T }q_{t}\mathbf{1}(q_{t}>\tau)\leq T\tau+\sum_{t=1}^{T}q_{t}\mathbf{1}(q_{t}> \tau).\] (25)Consider any \(k\) such that \(q_{k}>\tau\). Then

\[k\leq\sum_{t=1}^{T}\mathbf{1}(q_{t}\geq q_{k})\leq\kappa(q_{k})\ln\left(\frac{a}{q _{k}}\right)\leq\kappa(\tau)\ln\left(\frac{a}{q_{k}}\right),\]

where the last inequality follows by the monotonicity of \(\kappa\) and the fact that \(\ln(a/q_{k})\geq 0\). This in turn implies that \(q_{k}\leq a\exp\bigl{(}-\frac{k}{\kappa(\tau)}\bigr{)}\). Therefore,

\[\sum_{t=1}^{T}q_{t}\mathbf{1}(q_{t}>\tau)\leq\sum_{t=1}^{T}a\exp\left(-\frac{t }{\kappa(\tau)}\right).\] (26)

By Proposition 22,

\[\sum_{t=1}^{T}\exp\left(-\frac{t}{\kappa(\tau)}\right) \leq\exp\left(-\frac{1}{\kappa(\tau)}\right)-\kappa(\tau)\left( \exp\left(-\frac{T}{\kappa(\tau)}\right)-\exp\left(-\frac{1}{\kappa(\tau)} \right)\right)\] \[\leq[1+\kappa(\tau)]\exp\left(-\frac{1}{\kappa(\tau)}\right).\] (27)

Combining Eqs. (25), (26) and (27), we get

\[\sum_{t=1}^{T}q_{t}\leq T\tau+a[1+\kappa(\tau)]\exp\left(-\frac{1}{\kappa(\tau )}\right),\]

which concludes the proof. 

### Proof of Theorem 6

Throughout the proof we use the shorthand \(d_{\epsilon}=\overline{\mathfrak{d}}_{\rho}(\mathcal{Z},\alpha,\epsilon)\), so \(d=d_{1/T}\). The proof proceeds by applying Lemmas 23 and 24 to the bounds on the number of bad queries from Lemma 5. Specifically, let \(q_{t}=[\alpha-\rho(z_{t}\mid z^{*})]_{+}\) denote the suboptimality of each query \(z_{t}\) made by the algorithm. Then, for any \(\epsilon>0\), the number of \(\epsilon\)-bad queries can be written as \(\sum_{t=1}^{T}\mathbf{1}(q_{t}\geq\epsilon)\).

First consider the case \(C_{T,\delta}\geq\ln(2T)\). By Lemma 5, with probability at least \(1-\delta\), the number of \(\epsilon\)-bad queries is at most \(36d_{\epsilon}^{2.5}C_{T,\delta}/\epsilon^{2}\). Setting \(\kappa(\epsilon)=36d_{\epsilon}^{2.5}C_{T,\delta}\), we apply Lemma 23, with \(\tau=1/T\), to obtain that with probability at least \(1-\delta\),

\[\mathrm{Regret}(T,\alpha)\leq\sum_{t=1}^{T}q_{t}\leq 1+12d^{1.25}\sqrt{C_{T, \delta}T}.\]

If \(C_{T,\delta}=0\), then by Lemma 5, the number of \(\epsilon\)-bad queries is at most \(2d_{\epsilon}^{1.5}\ln(4/\epsilon)\). Setting \(a=4\) and \(\kappa(\epsilon)=2d_{\epsilon}^{1.5}\), we apply Lemma 24, with \(\tau=1/T\), to obtain

\[\mathrm{Regret}(T,\alpha)\leq\sum_{t=1}^{T}q_{t}\leq 1+4(1+2d^{1.5})\exp\left(- \frac{1}{2d^{1.5}}\right)\leq 1+12d^{1.5},\]

completing the proof.

### Proof of Theorem 7

First, we consider the deterministic setting. By Lemma 5, at most \(2d^{1.5}\ln(4/\epsilon)\) of queries issued by Alg are \(\epsilon\)-bad. Setting \(T>2d^{1.5}\ln(4/\epsilon)\) implies that at least one query is not \(\epsilon\)-bad. Thus, returning \(\hat{z}\) for which the observed reward is the largest guarantees that \(\rho(\hat{z}\mid z^{*})\geq\alpha-\epsilon\), as needed.

Next, we prove the result for the case \(C_{T,\delta}\geq\ln(2T)\). By Lemma 5, with probability at least \(1-\delta/2\), there are at most \(\frac{16}{9\epsilon^{2}}\cdot 36d^{2.5}(C_{T,\delta/2})\) queries that are \(3\epsilon/4\)-bad. Setting \(T\geq 64d^{2.5}(C_{T,\delta/2})/\epsilon^{2}\), implies that at least half of the queries are not \(3\epsilon/4\)-bad. In the remainder of the proof, we only consider the high-probability event in which this is the case.

For \(n_{1}=\lceil\log_{2}(4/\delta)\rceil\) the probability that all \(n_{1}\) samples are \(3\epsilon/4\)-bad is at most \((1/2)^{n_{1}}\leq\delta/4\).

For \(n_{2}=\lceil 128\ln(8n_{1}/\delta)/\epsilon^{2}\rceil\), by applying Hoeffding's inequality and union bound over each of the \(n_{1}\) rounds we get that with probability at most \(\delta/4\) there is some index \(\ell\leq n_{1}\) for which \(|\bar{r}_{t_{\ell}}-\rho(z_{t_{\ell}}\,|\,z^{*})|>\epsilon/8\).

Overall, with probability at least \(1-\delta\) we get that there is at least one index \(j\) of the \(n_{1}\) sampled indices that is not \(3\epsilon/4\)-bad, and that \(|\bar{r}_{t_{\ell}}-\rho(z_{t_{\ell}}\,|\,z^{*})|\leq\epsilon/8\) for all \(\ell=1,\ldots,n_{1}\). Therefore,

\[\bar{r}_{t_{j}}\geq\rho(z_{t_{j}}\,\,|\,z^{*})-\epsilon/8\geq\alpha-3\epsilon/ 4-\epsilon/8=\alpha-7\epsilon/8.\]

For all indices \(k\) that are \(\epsilon\)-bad we have

\[\bar{r}_{t_{k}}\leq\rho(z_{t_{k}}\,\,|\,z^{*})+\epsilon/8<\alpha-\epsilon+ \epsilon/8=\alpha-7\epsilon/8.\]

Thus, for all of the \(\epsilon\)-bad queries we have \(\bar{r}_{t_{k}}<\bar{r}_{t_{j}}\), and so Algorithm 2 will not return any of the \(\epsilon\)-bad queries, because it is choosing the index with maximum value of \(\bar{r}_{t_{\ell}}\). In other words, the returned query \(z_{t_{\ell}}\) satisfies

\[\rho(z_{t_{\ell}}\,|\,z^{*})\geq\alpha-\epsilon.\]

## Appendix B Missing proofs of Section 4

First we discuss the connection between our SQ setting and the SQ model of Kearns [19]. We focus on two aspects in which they appear to differ and explain why these models are equivalent.

Correlational _vs_ general statistical queries.The restriction of the SQ model in which the oracle may only output the approximate correlation between a query and the target function, termed _correlational statistical query_ (CSQ), was studied by Bshouty and Feldman [7]. The CSQ oracle can be viewed as providing something akin to a negative distance between the query and the target. This is equivalent to the _learning by distances_ framework of Ben-David et al. [5], who defined their model independently of Kearns [19]. Bshouty and Feldman [7] showed that an arbitrary statistical query can be answered by asking two SQs that are independent of the target and two CSQs. That is, in the distribution-dependent learning model (i.e., when the learner has access to the distribution over \(\mathcal{X}\)), correlational queries can simulate general queries.

Adversarial _vs_ statistical noise.The setting we consider in this work assumes stochastic query responses, similar to several previous works [13, 31, 4]. On the other hand, the original SQ model [19] assumed that the query oracle can respond with an adversarial (rather than statistical) noise, up to a pre-specified tolerance parameter \(\tau>0\). The previous works have shown that the two noise models are equivalent [13, 31, 4]

### Proof of Proposition 8

We first prove the first inequality of Eq. (3). Let \(\epsilon>0\) and let \(d=d_{\text{SQ}}(\epsilon)\). Then there exists a sequence \(h_{1},\ldots,h_{d}\in\mathcal{H}\) satisfying both conditions of Definition 4. Let \(d^{\prime}\) be equal to the leftmost expression of Eq. (3). We aim to show \(d_{\rho}(\epsilon)\geq d^{\prime}\). Note that \(d^{\prime}\leq d\).

Let \(c\) be the midpoint between \(c_{min}=\min_{i<j}\langle h_{i},h_{j}\rangle\) and \(c_{max}=\max_{i<j}\langle h_{i},h_{j}\rangle\). Then \(c\leq 1-\epsilon\). Moreover, for all \(i\neq j\),

\[|\langle h_{i},h_{j}\rangle-c|\leq\frac{1}{2}|c_{max}-c_{min}|\leq\frac{1}{2d }\leq\frac{\epsilon}{\sqrt{d^{\prime}}}\]

where the last inequality follows from our choice of \(d^{\prime}\) (which ensures \(d^{\prime}\leq 4(d\epsilon)^{2}\)). Thus, \(h_{1},\ldots,h_{d^{\prime}}\), the first \(d^{\prime}\) elements of the original sequence of hypotheses, satisfy Definition 1, proving the claim.

We prove the first inequality of Eq. (4) in a similar way. Let us re-define \(d=d_{\rho}(4\epsilon)\) and let \(d^{\prime}\) be equal to the leftmost expression of Eq. (4). As before, \(d^{\prime}\leq d\). Then there exists a sequence \(h_{1},\ldots,h_{d}\in\mathcal{H}\) satisfying the conditions of Definition 1 for some \(c\leq 1-4\epsilon\). Then for all \(i\neq j\), \(\langle h_{i},h_{j}\rangle\leq c+\frac{4\epsilon}{\sqrt{d}}\leq 1-\epsilon\), since \(d\geq 2\). Moreover, for all \(i\neq j\) and \(i^{\prime}\neq j^{\prime}\),

\[|\langle h_{i},h_{j}\rangle-\langle h_{i^{\prime}},h_{j^{\prime}}\rangle|=| \langle h_{i},h_{j}\rangle-c+c-\langle h_{i^{\prime}},h_{j^{\prime}}\rangle| \leq\frac{8\epsilon}{\sqrt{d}}\leq\frac{1}{d^{\prime}},\]

with the last inequality following from our choice of \(d^{\prime}\). Thus, \(h_{1},\ldots,h_{d^{\prime}}\), the first \(d^{\prime}\) hypotheses in the original sequence, satisfy Definition 4.

The second inequality of Eq. (4), now follows from the first inequality of Eq. (3), since if the second inequality of Eq. (4) does not hold then the leftmost expression of Eq. (3) must be at least \(d_{\rho}(\epsilon)\), a contradiction. Likewise, the second inequality of Eq. (3), now follows from the first inequality of Eq. (4).

### Lower bound setting

**Definition 8** (SQ oracle (adversarial)).: _Let \(D\) be the input distribution over the domain \(X\). For a tolerance parameter \(\tau>0\), \(\mathcal{O}^{adv}(\tau):=\mathcal{O}^{adv}_{D,h^{*}}(\tau)\) oracle is the oracle that for any query function \(h\in\mathcal{H}\), returns a value \(v\in[\mu-\tau,\mu+\tau]\), where \(\mu=\mathbb{E}_{x\sim D}[h(x)h^{*}(x)]\)._

**Definition 9** (Sample oracle (statistical)).: _Let \(D\) be the input distribution over the domain \(X\). The Sample oracle \(\mathcal{O}:=\mathcal{O}_{D,h^{*}}\) oracle is the oracle that given any function \(h\in\mathcal{H}\), takes an independent random sample \(x\) from \(D\) and returns the value \(v=h(x)h^{*}(x)\)._

We will need the following results for our proof. The first is a reduction from an adversarial noise oracle to a statistical one. Specifically, consider the learning setting defined in Section 2, for a sample oracle \(\mathcal{O}\). Let \(\mathsf{Alg}\) be a (possibly randomized) algorithm for that setting. The following theorem shows a simulation of \(\mathcal{O}\) via \(\mathcal{O}^{adv}\) the SQ oracle.

**Theorem 25** ([13], Theorem 3.13).: _Assume that \(\mathsf{Alg}\) outputs a \(\epsilon\)-approximation to \(h^{*}\) with probability at least \(\delta\), using \(m\) samples from \(\mathcal{O}\). Then, for any \(\delta^{\prime}\in(0,1/4]\), there exists a SQ algorithm \(\mathsf{Alg}^{\prime}\) that uses at most \(m\) queries to \(\mathcal{O}^{adv}({\delta^{\prime}}^{2}/m)\) and outputs an \(\epsilon\)-approximation to \(h^{*}\) with probability at least \(\delta-\delta^{\prime}\)._

Their result is obtained by simulating \(\mathsf{Alg}\) using \(\mathcal{O}^{adv}\) as follows: for any query of \(\mathsf{Alg}\) to \(\mathcal{O}\), the response of \(\mathcal{O}^{adv}\) to that query is used as bias for a coin flip, which is then given to the learner as the simulated outcome of \(\mathcal{O}\). They then prove that the true \(m\) samples of \(\mathcal{O}\) and the simulated coin flips are statistically close by bounding their distributional distance. This implies that the success probability of \(\mathsf{Alg}^{\prime}\), the simulated algorithm, is not much worse than that of \(\mathsf{Alg}\), the original algorithm.

We note that the result originally stated in [13] differs from Theorem 25 above in two ways. First, it reduces to a _variant_ of \(\mathcal{O}^{adv}(\tau)\) with a tolerance \(\tau^{\prime}\in[\tau,\sqrt{\tau}]\). Thus, it holds for \(\mathcal{O}^{adv}(\tau)\) as well. Second, it is phrased in a more general setting of search problems over distributions, which captures the SQ model, as detailed in [13], Section 6.

The second result that is needed for our proof is the following lower bound due to [25].

**Theorem 26** ([25], Theorem 8).: _Let \(\epsilon>0\), and let \(\mathcal{H}\subseteq\{\pm 1\}^{\mathcal{X}}\) be a hypothesis space with strong SQ dimension \(d_{\mathsf{SQ}}\coloneqq\mathsf{dim}_{\mathsf{SQ}}(\mathcal{H},2\epsilon)\geq 3\) (see Definition 4). Then for any SQ algorithm \(\mathsf{Alg}\) using \(m\) queries to \(\mathcal{O}^{adv}(\tau)\) with tolerance \(\tau\geq 2/\sqrt{d_{\mathsf{SQ}}}\), there exist \(h^{*}\in\mathcal{H}\) such that if \(\mathsf{Alg}\) outputs an \(\epsilon\)-approximation to \(h^{*}\), then \(m>d_{\mathsf{SQ}}\tau^{2}/3\)._

#### b.2.1 Proof of Theorem 9

Set \(\delta=2/3\). Let \(D\) be a distribution over \(\mathcal{X}\). Assume towards contradiction that there exists a learning algorithm \(\mathsf{Alg}\) such that for any \(h^{*}\in\mathcal{H}\), given oracle access to \(\mathcal{O}:=\mathcal{O}_{D,h^{*}}\) and using \(m\leq\sqrt[3]{d_{\mathsf{SQ}}}/12\) samples from \(\mathcal{O}\), the algorithm \(\mathsf{Alg}\) outputs an \(\epsilon\)-approximation to \(h^{*}\) with probability at least \(\delta\).

We then apply Theorem 25 for \(\delta^{\prime}=\delta/2\) to simulate the algorithm using \(\mathcal{O}^{adv}:=\mathcal{O}^{adv}_{D,h^{*}}\). The resulting algorithm uses \(m\leq\sqrt[3]{d_{\mathsf{SQ}}}/12\) queries to \(\mathcal{O}^{adv}(\tau)\) for \(\tau={\delta^{\prime}}^{2}/m>4/(3\sqrt[3]{d_{\mathsf{SQ}}})\geq 2/\sqrt{d_{ \mathsf{SQ}}}\) and has success probability of at least \(\delta-\delta^{\prime}=\delta/2>1/3\). By Theorem 26 we obtain a contradiction, as \(m>d_{\mathsf{SQ}}\tau^{2}/3>\sqrt[3]{d_{\mathsf{SQ}}}/2\).

## Appendix C Missing proofs of Section 5

### Proof of Theorem 11

Let \(d=\overline{\mathsf{d}}_{\rho}(\mathcal{Z},\alpha,3\epsilon/2)\). Note that the eluder dimension is always at least \(1\), so the theorem trivially holds if \(d\leq 9\). In the remainder of the proof assume that \(d\geq 10\).

From the definition of the monotonic dissimilarity dimension, there exists \(\tau\geq 3\epsilon/2\) such that \(d=\mathsf{d}(\mathcal{Z},\alpha,\tau)\). Let \((f_{1},a_{1}),\ldots,(f_{d},a_{d})\) be a sequence satisfying the dimension conditions for \(\tau\)We will show that the first \(\lceil d/9\rceil\) elements of this sequence also satisfy the conditions of the eluder dimension for some \(\epsilon^{\prime}\geq\epsilon\). Specifically, we will show that there is some \(\epsilon^{\prime}\geq\epsilon\) such that every element \(a_{j}\) with \(j\leq\lceil d/9\rceil\) in the sequence above is \(\epsilon^{\prime}\)-independent of its predecessors. That is, we will show that for every such element \(a_{j}\), there exists a pair of functions \(f,f^{\prime}\in\mathcal{F}\) that satisfy

\[\sqrt{\sum_{i=1}^{j-1}\bigl{(}f(a_{i})-f^{\prime}(a_{i})\bigr{)}^{2}}\leq \epsilon^{\prime},\]

yet it also holds that \(f(a_{j})-f^{\prime}(a_{j})>\epsilon^{\prime}\).

By definition of the dissimilarity dimension, there exists \(c\leq\alpha-\tau\) such that for all \(i<j\),

\[\left|f_{j}(a_{i})-c\right|=\left|\rho\bigl{(}(f_{i},a_{i})\left|\left.(f_{j}, a_{j})\right.\right)-c\right|\leq\frac{\tau}{\sqrt{d}}.\] (28)

Then, by the triangle inequality,

\[\left|f_{j}(a_{i})-f_{j+1}(a_{i})\right|=\left|f_{j}(a_{i})-c+c-f_{j+1}(a_{i} )\right|\leq\left|f_{j}(a_{i})-c\right|+\left|f_{j+1}(a_{i})-c\right|\leq \frac{2\tau}{\sqrt{d}}.\] (29)

Therefore,

\[\bigl{(}f_{j}(a_{i})-f_{j+1}(a_{i})\bigr{)}^{2}\leq\frac{4\tau^{2}}{d},\] (30)

and so for all \(j\leq\lceil d/9\rceil\) it holds that,

\[\sum_{i=1}^{j-1}(f_{j}(a_{i})-f_{j+1}(a_{i}))^{2}<\frac{4\tau^{2}}{9}.\] (31)

Next, recall that for all \(j\leq d\) we have \(f_{j}(a_{j})\geq\alpha\geq c+\tau\) and \(f_{j+1}(a_{j})\leq c+\frac{\tau}{\sqrt{d}}\). Thus,

\[f_{j}(a_{j})-f_{j+1}(a_{j})\geq c+\tau-c-\frac{\tau}{\sqrt{d}}>\frac{2\tau}{3},\] (32)

where the last inequality holds for \(d\geq 10\). Overall, Eqs. (31) and (32) then demonstrate that for \(\epsilon^{\prime}=2\tau/3\geq\epsilon\), the element \(a_{j}\) is \(\epsilon^{\prime}\)-independent of its predecessors, finishing the proof.

### Proof of Theorem 13

Our proof uses the following result on ranks of perturbed identity matrices (see [2, Lemma 2.2]):

**Lemma 27**.: _Let \(\mathbf{A}\in\mathbb{R}^{d\times d}\) be a symmetric matrix such that \(A_{ii}=1\) for all \(i\) and \(|A_{ij}|\leq 1/\sqrt{d}\) for all \(i\neq j\). Then \(\operatorname{rank}(\mathbf{A})>d/2\)._

The proof begins by constructing a matrix \(\mathbf{M}\) whose entries are derived from the evaluation values of elements that satisfy the dimension condition. Then we bound the rank of \(\mathbf{M}\) from above as well as from below. The lower bound is expressed in terms of the dimension \(d=\mathsf{d}_{\rho}(\mathcal{Z},\alpha,\epsilon)\) while the upper bound is expressed in terms of \(n\). Combining the bounds then yields the result of the theorem.

**Construction of \(\mathbf{M}\).** Let \((f_{\boldsymbol{\theta}_{1}},\mathbf{a}_{1}),\ldots,(f_{\boldsymbol{\theta}_ {d}},\mathbf{a}_{d})\) denote the alternatives that satisfy the dimension conditions, with respect to some value \(c\) such that \(c\leq\alpha-\epsilon\) (see Definition 1). Define \(\mathbf{M}\) to be the \(d\times d\) matrix with entries \(M_{ij}=\langle\boldsymbol{\theta}_{i},\mathbf{a}_{j}\rangle-c\) for \(i,j\leq d\). Note that all diagonal entries of \(\mathbf{M}\) are at least \(\alpha-c\geq\epsilon\), and all other entries are in \(\left[-\frac{\epsilon}{\sqrt{d}},\frac{\epsilon}{\sqrt{d}}\right]\).

**Upper bound on \(\operatorname{rank}(\mathbf{M})\).** Let \(\mathbf{K}\in\mathbb{R}^{d\times d}\) be the matrix of inner products, \(K_{ij}=\langle\boldsymbol{\theta}_{i},\mathbf{a}_{j}\rangle\), and let \(\mathbf{U}\) be the Gram matrix for the set of vectors \(\boldsymbol{\theta}_{1},\ldots,\boldsymbol{\theta}_{d},\mathbf{a}_{1},\ldots,\mathbf{a}_{d}\). Then \(\mathbf{U}\) is a \(2d\times 2d\) matrix of the rank at most \(n\), because the vectors are of the dimension \(n\) (see, e.g., [17, Theorem 7.2.10]), and \(\mathbf{K}\) is a submatrix of \(\mathbf{U}\), so \(\operatorname{rank}(\mathbf{K})\leq\operatorname{rank}(\mathbf{U})\leq n\). Moreover, \(\mathbf{M}=\mathbf{K}-c\mathbf{1}\mathbf{1}^{\top}\), where \(\mathbf{1}\) is the all-ones vector in \(\mathbb{R}^{d}\). Therefore, by subadditivity of rank,

\[\operatorname{rank}(\mathbf{M})=\operatorname{rank}(\mathbf{K}-c\mathbf{1} \mathbf{1}^{\top})\leq\operatorname{rank}(\mathbf{K})+\operatorname{rank}(-c \mathbf{1}\mathbf{1}^{\top})\leq n+1.\] (33)

**Lower bound on \(\operatorname{rank}(\mathbf{M})\).** Let \(\mathbf{D}\in\mathbb{R}^{d\times d}\) be the diagonal matrix with entries \(D_{ii}=1/\sqrt{M_{ii}}\). Since \(M_{ii}\geq\epsilon>0\), we have \(0<D_{ii}\leq 1/\sqrt{\epsilon}\). Consider the matrix \(\mathbf{M}^{\prime}=\mathbf{DMD}\). Then

\[\operatorname{rank}(\mathbf{M}^{\prime})=\operatorname{rank}(\mathbf{DMD})= \operatorname{rank}(\mathbf{M}),\] (34)

because the matrix \(\mathbf{D}\) is non-singular (see (17, Section 0.4.6(b))). Furthermore, matrix \(\mathbf{M}^{\prime}\) satisfies \(M^{\prime}_{ii}=1\) for all \(i\) and

\[|M^{\prime}_{ij}|=|D_{ii}M_{ij}D_{jj}|\leq\frac{1}{\sqrt{\epsilon}}\cdot\frac{ \epsilon}{\sqrt{d}}\cdot\frac{1}{\sqrt{\epsilon}}=\frac{1}{\sqrt{d}}\]

for all \(i\neq j\). Consider the symmetric matrix \(\mathbf{S}=(\mathbf{M}^{\prime}+(\mathbf{M}^{\prime})^{\top})/2\). Then, we also have \(S_{ii}=1\) for all \(i\), and \(|S_{ij}|\leq 1/\sqrt{d}\) for all \(i\neq j\). Thus, by Lemma 27, \(\operatorname{rank}(\mathbf{S})>d/2\). Moreover, by the subadditivity of the rank

\[d/2<\operatorname{rank}(\mathbf{S})\leq\operatorname{rank}(\mathbf{M}^{\prime }/2)+\operatorname{rank}\bigl{(}(\mathbf{M}^{\prime})^{\top}\!/2\bigr{)}=2 \operatorname{rank}(\mathbf{M}^{\prime}).\] (35)

Combining Eqs. (35), (34) and (33), we therefore obtain

\[d/2<2\operatorname{rank}(\mathbf{M}^{\prime})=2\operatorname{rank}(\mathbf{M} )\leq 2n+2,\]

and so \(d<4n+4\). Since \(d\) is an integer, we must have \(d\leq 4n+3\).

In the special case that \(\alpha=1\), we have \(\langle\boldsymbol{\theta}_{i},\mathbf{a}_{i}\rangle\geq 1\) for all \(i\leq d\), which is only possible when \(\boldsymbol{\theta}_{i}=\mathbf{a}_{i}\) for all \(i\leq d\). As a result, the matrices \(\mathbf{M}\) and \(\mathbf{M}^{\prime}\) are both symmetric, and thus \(\mathbf{S}=\mathbf{M}^{\prime}\) and

\[d/2<\operatorname{rank}(\mathbf{S})=\operatorname{rank}(\mathbf{M}^{\prime})= \operatorname{rank}(\mathbf{M})\leq n+1,\]

implying that \(d\leq 2n+1\).

### Proof of Theorem 14

Using an existing bound on the eluder dimension for GLM bandits ([24], Proposition 7), and the fact that our dimension is bounded by the eluder dimension (Theorem 11) the result follows.

### Proof of Theorem 15

Denote \(d=\mathsf{d}_{\rho}(\mathcal{Z}_{b}^{\text{relu}},1-b,\epsilon)\). Notice that since \(b<1\), for any \(\boldsymbol{\theta},\mathbf{a}\in\mathcal{B}_{n}\) such that \(\boldsymbol{\theta}\neq\mathbf{a}\) it holds that \(f_{\boldsymbol{\theta},b}(\mathbf{a})<f_{\boldsymbol{\theta},b}(\boldsymbol{ \theta})=1-b\). Let \((f_{\boldsymbol{\theta}_{1},b},\boldsymbol{\theta}_{1}),\ldots,(f_{\boldsymbol{ \theta}_{d},b},\boldsymbol{\theta}_{d})\) be a sequence of elements satisfying the dimension definition, with respect to a corresponding scalar \(c\leq 1-b-\epsilon\). Since the evaluation is symmetric for ReLU functions, we can view this sequence as a set, and denote \(U=\{\boldsymbol{\theta}_{1},\ldots\boldsymbol{\theta}_{d}\}\). In addition, note that by the dimension definition, for all \(\boldsymbol{\theta}\in U\), \(\|\boldsymbol{\theta}\|=1\).

We start by proving an upper bound on \(d\). Assume \(d\geq 9\). First, consider the case \(c\leq\epsilon/3\). Let \(U_{0}\) be any subset of the unit sphere such that for all \(\boldsymbol{\theta}\neq\boldsymbol{\theta}^{\prime}\) in \(U_{0}\) it holds that \(\langle\boldsymbol{\theta},\boldsymbol{\theta}^{\prime}\rangle\leq b+2\epsilon/3\). Observe that for all such \(\boldsymbol{\theta}\neq\boldsymbol{\theta}^{\prime}\) we have \(f_{\boldsymbol{\theta},b}(\mathbf{u}^{\prime})=f_{\boldsymbol{\theta}^{\prime },b}(\boldsymbol{\theta})\in[0,2\epsilon/3]\). Thus, we get that \(d\leq|U_{0}|\).

A standard sphere covering argument shows that the size of such a set is upper bounded as follows. The \(\delta\)-covering number of the unit sphere is at most \((3/\delta)^{n}\) ([27], Cor. 4.2.13). Thus, there are at most \((3/\delta)^{n}\) points such that each pair \(\boldsymbol{\theta}\neq\boldsymbol{\theta}^{\prime}\) satisfies \(\|\boldsymbol{\theta}-\boldsymbol{\theta}^{\prime}\|\geq\delta\), or equivalently \(\langle\boldsymbol{\theta},\boldsymbol{\theta}^{\prime}\rangle\leq 1-\delta^{2}/2\). By setting \(\delta=\sqrt{2(1-b-2\epsilon/3)}\) we get that \(|U_{0}|\leq(\frac{3}{\delta})^{n}\leq(\frac{3}{2\sqrt{2(\epsilon-2\epsilon/3)}})^ {n}\leq(4/\sqrt{\epsilon})^{n}\), which yields the desired bound.

Now, consider the case \(c>\epsilon/3\). In this case, for all \(i\neq j\), we have that \(f_{\boldsymbol{\theta}_{j},b}(\boldsymbol{\theta}_{i})\geq c-\frac{\epsilon}{ \sqrt{d}}\geq c-\epsilon/3>0\), and so \(\langle\boldsymbol{\theta}_{i},\boldsymbol{\theta}_{j}\rangle>b\). Let \(c^{\prime}=c+b\). Thus, it must also hold that, \(|\langle\boldsymbol{\theta}_{i},\boldsymbol{\theta}_{j}\rangle-c^{\prime}| \leq\frac{\epsilon}{\sqrt{d}}\) for all \(i\neq j\). Note that \(c^{\prime}<1-\epsilon\). Then, by applying Lemma 13 we get that \(d\) is upper bounded by \(2n+4\). Overall, the bound in the claim holds.

Next, we show a lower bound on \(d=\mathsf{d}_{\rho}(\mathcal{Z}_{1-\epsilon}^{\text{relu}},\epsilon,\epsilon)\), by lower bounding the size of the set \(U\) defined above. We now apply a sphere _packing_ argument, which shows that there exists such a set \(U\) with size \(|U|\geq(1/2\epsilon)^{n/2}\). We follow a similar argument as above. Specifically, the \(\delta\)-packing number of the unit sphere is at most \((1/\delta)^{n}\) ([27], Cor. 4.2.13). By plugging in \(\delta=\sqrt{2\epsilon}\), yields the desired bound.

### Proof of Proposition 12

We start with an auxiliary lemma:

**Lemma 28** (dissimilarity subadditivity).: _Let \(\mathcal{Z}_{1}\) and \(\mathcal{Z}_{2}\) be two sets, and let \(\alpha\in\mathbb{R}\) and \(\epsilon>0\). Denote \(\mathcal{Z}=\mathcal{Z}_{1}\cup\mathcal{Z}_{2}\) and let \(\rho:\mathcal{Z}\times\mathcal{Z}\to\mathbb{R}\) be an evaluation function. Then,_

\[\mathsf{d}_{\rho}(\mathcal{Z},\alpha,\epsilon)\leq\mathsf{d}_{\rho}(\mathcal{ Z}_{1},\alpha,\epsilon)+\mathsf{d}_{\rho}(\mathcal{Z}_{2},\alpha,\epsilon)\]

_and_

\[\overline{\mathsf{d}}_{\rho}(\mathcal{Z},\alpha,\epsilon)\leq\overline{ \mathsf{d}}_{\rho}(\mathcal{Z}_{1},\alpha,\epsilon)+\overline{\mathsf{d}}_{ \rho}(\mathcal{Z}_{2},\alpha,\epsilon).\]

Proof.: Let \(z_{1},\ldots,z_{d}\subseteq\mathcal{Z}\) such that there exists \(c\leq\alpha-\epsilon\) with \(|\rho(z_{i}|z_{j})-c|\leq\frac{\epsilon}{\sqrt{d}}\) for all \(i<j\), and \(\rho(z_{i}|z_{i})\geq\alpha\). Let \(I_{1},I_{2}\subseteq[d]\) be disjoint sets of indices with \(\{z_{i}\}_{i\in I_{1}}\subseteq\mathcal{Z}_{1}\) and \(I_{2}=[d]\setminus I_{1}\). Consider the sub-sequence \(z_{\ell_{1}},\ldots,z_{\ell_{|I_{1}|}}\) ordered by appearance in \(z_{1},\ldots,z_{d}\) of elements in \(I_{1}\). By definition for all \(i<j\),

\[|\rho(z_{\ell_{i}}|z_{\ell_{j}})-c|\leq\frac{\epsilon}{\sqrt{d}}\]

Therefore the sequence \(z_{\ell_{1}},\ldots,z_{\ell_{|I_{1}|}}\) satisfies \(|\rho(z_{\ell_{i}}|z_{\ell_{j}})-c|\leq\frac{\epsilon}{\sqrt{|I_{1}|}}\) for all \(i<j\) and therefore \(|I_{1}|\leq\mathsf{d}_{\rho}(\mathcal{Z}_{1},\alpha,\epsilon)\). The same logic implies \(|I_{2}|\leq\mathsf{d}_{\rho}(\mathcal{Z}_{2},\alpha,\epsilon)\).

To get the monotonic version, note that if \(\epsilon^{*}=\arg\max_{\epsilon^{\prime}\geq\epsilon}\mathsf{d}_{\rho}( \mathcal{Z},\alpha,\epsilon^{\prime})\),

\[\overline{\mathsf{d}}_{\rho}(\mathcal{Z},\alpha,\epsilon) =\mathsf{d}_{\rho}(\mathcal{Z},\alpha,\epsilon^{*})\] \[\leq\mathsf{d}_{\rho}(\mathcal{Z}_{1},\alpha,\epsilon^{*})+ \mathsf{d}_{\rho}(\mathcal{Z}_{2},\alpha,\epsilon^{*})\] \[\leq\overline{\mathsf{d}}_{\rho}(\mathcal{Z}_{1},\alpha,\epsilon) +\overline{\mathsf{d}}_{\rho}(\mathcal{Z}_{2},\alpha,\epsilon)\]

where the first inequality is by the first statement of the lemma which was proved above, the next inequality is by definition of the monotonic dimension, and the last inequality follows by \(\epsilon\leq\epsilon^{*}\). 

We can now construct the classes that demonstrate the separation of the eluder and dissimilarity dimension.

We consider two overlapping semicircles, indexed by \(j\in\{0,1\}\), and defined as

\[U_{0}=\Big{\{}(\cos x,\sin x):\;x\in\Big{(}-\frac{\pi}{2},\frac{\pi}{2}\Big{)} \Big{\}},\text{ and }U_{1}=\Big{\{}(\cos x,\sin x):\;x\in\big{(}0,\pi\big{)}\Big{\}}.\]

For each \(j\in\{0,1\}\), and any \(N\in\mathbb{N}\) and \(\epsilon>0\), we define the function class

\[\mathcal{F}_{j,N,\epsilon}\coloneqq\Big{\{}f_{\mathbf{v},S,\sigma}:\;\mathbf{ v}\in\mathcal{C}\setminus U_{j},\,S\subseteq U_{j},\,|S|=N,\sigma\in\{\pm\epsilon\}^{S} \Big{\}},\]

containing functions

\[f_{\mathbf{v},S,\sigma}(\mathbf{a})=\begin{cases}0&\text{if }\mathbf{a}\in U_{j} \setminus S,\\ \sigma(\mathbf{a})&\text{if }\mathbf{a}\in S,\\ \langle\mathbf{v},\mathbf{a}\rangle&\text{if }\mathbf{a}\in\mathcal{C}\setminus U_{j}. \end{cases}\] (36)

In words, the functions in the class \(\mathcal{F}_{j,N,\epsilon}\) are linear outside of the semicircle \(U_{j}\), and zero in the semicircle \(U_{j}\), except for a set of size \(N\), where they can take any combination of values \(+\epsilon\) and \(-\epsilon\). For any \(N\in\mathbb{N}\) and \(\epsilon>0\), we define the class \(\mathcal{F}_{N,\epsilon}\coloneqq\bigcup_{j\in\{0,1\}}\mathcal{F}_{j,N,\epsilon}\) and show that this class has a constant dissimilarity dimension but its eluder dimension is at least \(N\).

Finally, consider the action set \(\mathcal{A}=\mathcal{C}\) and the function class \(\mathcal{F}_{N,\epsilon}\) as defined above. Let \(\mathcal{Z}_{N,\epsilon}=\mathcal{F}_{N,\epsilon}\times\mathcal{A}\), \(\rho=\rho_{\text{bandits}}\) and \(\epsilon\in(0,1/2)\). We how show that \(\mathtt{dim}_{\mathbb{E}}(\mathcal{F}_{N,\epsilon},\epsilon)\geq N\), but \(\mathsf{d}_{\rho}(\mathcal{Z}_{N,\epsilon},1,\epsilon)\leq 16\). First we prove the following lower bound on the eluder dimension of \(\mathcal{F}_{j,N,\epsilon}\).

**Lemma 29**.: _The eluder dimension of \(\mathcal{F}_{j,N,\epsilon}\) satisfies \(\mathtt{dim}_{\mathbb{E}}(\mathcal{F}_{j,N,\epsilon},\epsilon)\geq N\) for all \(j\in\{0,1\}\)._

Proof.: Let \(\mathbf{a}_{1},\ldots,\mathbf{a}_{N}\) be an arbitrary set of points in \(U_{j}\) and consider the functions \(\{f_{i}\}_{i=1}^{N+1}\subseteq\mathcal{F}_{j,N,\epsilon,S,\mathbf{v}}\) that for all \(i,i^{\prime}\leq N\) satisfy:

\[f_{i}(\mathbf{a}_{i^{\prime}})=\begin{cases}\epsilon&\text{if }i^{\prime}\neq i\\ -\epsilon&\text{if }i^{\prime}=i,\end{cases}\]and \(f_{N+1}(\mathbf{a}_{i})=\epsilon\) for all \(i\leq N\). We now show that for all \(i\leq N\), the action \(\mathbf{a}_{i}\) is \(\epsilon\)-independent of \(\mathbf{a}_{1},\ldots,\mathbf{a}_{i-1}\) with respect to \(\mathcal{F}_{j,N,\epsilon,S,\mathbf{v}}\). This holds since \(\sqrt{\sum_{j=1}^{i-1}(f_{i}(\mathbf{a}_{j})-f_{N+1}(\mathbf{a}_{j}))^{2}}=0\) while \(|f_{i}(\mathbf{a}_{i})-f_{N+1}(\mathbf{a}_{i})|=2\epsilon>\epsilon\). This finalizes the proof. 

**Lemma 30**.: _Denote \(\mathcal{Z}_{N,\epsilon}=\mathcal{F}_{N,\epsilon}\times\mathcal{A}\) and let \(\epsilon\in(0,1/2)\). Then, \(\mathsf{d}_{\rho}(\mathcal{Z}_{N,\epsilon},1,\epsilon)\leq 16\)._

Proof.: Denote by \(\mathcal{Z}_{j,N,\epsilon}=\mathcal{F}_{j,N,\epsilon}\times\mathcal{A}\) for all \(j\in\{0,1\}\). We start by showing that for all \(j\in\{0,1\}\), \(\mathsf{d}_{\rho}(\mathcal{Z}_{j,N,\epsilon},1,\epsilon)\leq 8\). Let \(z_{1},\ldots,z_{d}\) be a maximal sequence certifying the dissimilarity dimension \(\mathsf{d}_{\rho}(\mathcal{Z}_{N,\epsilon},1,\epsilon)\geq d\), i.e., it holds that,

\[|\rho(z_{i}|z_{i^{\prime}})-c|\leq\frac{\epsilon}{\sqrt{d}}\text{ for all }i<i^{\prime},\qquad\text{while }\rho(z_{i}|z_{i})\geq 1.\]

Since \(\rho(z_{i}|z_{i})\geq 1\), it must be the case that \(z_{i}=(f_{\mathbf{v}_{i},S_{i},\sigma_{i}},\mathbf{v}_{i})\) with \(\mathbf{v}_{i}\not\in U_{j}\) (since otherwise the self evaluations would be strictly less than \(1\)). This implies that \(\rho(z_{i}|z_{j})=\langle\mathbf{v}_{i},\mathbf{v}_{j}\rangle\) for all \(i<j\). Consequently, the score evaluations of all \(z_{1},\ldots,z_{d}\) are equivalent to the score evaluations of the linear problem defined by \(\mathbf{v}_{1},\ldots,\mathbf{v}_{d}\). Thus Theorem 13 implies the maximum length of such a sequence can be of size at most \(2\times 2+4=8\). Finally the sub-additivity of the dissimilarity dimension (see Lemma 28) implies,

\[\mathsf{d}_{\rho}(\mathcal{Z}_{N,\epsilon},1,\epsilon)\leq\sum_{j=0}^{1} \mathsf{d}_{\rho}(\mathcal{Z}_{j,N,\epsilon},1,\epsilon)\leq 16.\qed\]

Combining the results of Lemmas 29 and 30 finalizes the proof of Proposition 12.

## Appendix D Multi-Armed Bandits

In this section we explore the dissimilarity dimension of the \(K\)-armed bandit problem. In this setting the learner interacts with a set of \(K\) arms and at every step of a sequential interaction pulls an arm \(a_{t}\in[K]\) and receives a reward \(r_{t}\) such that \(\mathbb{E}[r_{t}]=\mu_{i_{i}}\) where \(\mu_{a_{t}}\) is the mean reward of arm \(a_{t}\). For simplicity we will assume \(\mu_{a}\in[0,1]\) for all \(a\in[K]\) and that \(|r_{t}|\leq 1\).

The \(K\)-armed bandit problem is an instance of structured bandits where \(\mathcal{A}=[K]\) and \(\mathcal{F}=[0,1]^{K}\). The dissimilarity dimension of the \(K\)-armed bandit problem satisfies,

**Proposition 31**.: _Consider the action set \(\mathcal{A}=[K]\) and the function class \(\mathcal{F}=[0,1]^{K}\) as defined above. Let \(\alpha\in[0,1]\) and \(\mathcal{Z}=\mathcal{F}\times\mathcal{A}\), \(\rho=\rho_{\text{bandits}}\) and \(\epsilon\in(0,1/2)\). Then \(\mathsf{d}_{\rho}(\mathcal{Z},\alpha,\epsilon)\leq K\)._

Proof.: Let \(c\leq\alpha-\epsilon\) and \(z_{1},\ldots,z_{d}\in\mathcal{Z}\) with \(z_{i}=(f_{i},a_{i})\) be a maximal sequence such that, \(\rho(z_{i}|z_{i})\geq\alpha\) while

\[|\rho(z_{i}|z_{j})-c|\leq\frac{\epsilon}{\sqrt{d}}.\]

For \(i<j\). Substituting the definition of \(\rho\), this implies \(f_{i}(a_{i})\geq\alpha\) for all \(i\in[K]\) while \(|f_{j}(a_{i})-c|\leq\frac{\epsilon}{\sqrt{d}}\) for all \(i<j\). By definition of \(c\), if \(d\geq 2\)

\[f_{j}(a_{i})\leq\alpha-\epsilon+\frac{\epsilon}{\sqrt{d}}\leq\alpha-\left(1- \frac{1}{\sqrt{2}}\right)\epsilon<\alpha-\frac{\epsilon}{4},\quad\text{ for all }i<j.\] (37)

Let \(I_{i}=\{a_{\ell}\}_{\ell=1}^{i}\) be the set of actions up to index \(i\) in the tuple sequence \(z_{1},\ldots,z_{i}\). Equation 37 implies that \(f_{j}(a)\leq\alpha-\frac{\epsilon}{4}\) for all \(j>i\). Since \(a_{j}\) satisfies \(f_{j}(a_{j})\geq\alpha>\alpha-\frac{\epsilon}{4}\) this implies \(a_{j}\not\in I_{i}\). We conclude that \(a_{i}\neq a_{j}\) for all \(i<j\). Since there are at most \(K\) different arm values, this implies \(d\leq K\). 

### Structured Bandits

We will now explain in detail how what Algorithm 1 reduces to in the structured bandits setting from Example 2. We write \(z_{i}=(f_{i},a_{i})\) for all \(i\in[T]\). The large evaluation set \(\mathcal{Z}_{\alpha}\) can be reduced to the following set of functions,

\[\mathcal{F}_{\alpha}=\{f\in\mathcal{F}\,\text{t.}\max_{a\in\mathcal{A}}f(a) \geq\alpha\}.\]Since the \(\rho_{\text{bandits}}\) function \(\rho_{\text{bandits}}(z_{i}|z)\) is independent on \(a\) for \(z=(f,a)\), the least squares equation \(\operatorname*{argmin}_{z\in\mathcal{Z}_{\alpha}}\sum_{i=1}^{t-1}\Bigl{(}\rho(z _{i}\,|\,z)-r_{i}\Bigr{)}^{2}\) reduces to,

\[f_{t}=\operatorname*{argmin}_{f\in\mathcal{F}_{\alpha}}\sum_{i=1}^{t-1}\left(f( a_{i})-r_{i}\right)^{2}.\]

finally, to ensure the action query has a self evaluation of at least \(\alpha\), we output \(a_{t}=\operatorname*{argmax}_{a\in\mathcal{A}}f_{t}(a)\).

We will now explain in detail what the Optimistic Interactive Estimation Algorithm 3 reduces to in the structured bandits setting from Example 2. We write \(z_{i}=(f_{i},a_{i})\) for all \(i\in[T]\).

The least squares objective (\(z_{t}=\operatorname*{argmin}_{z\in\mathcal{Z}_{\alpha}}\sum_{i=1}^{t-1}\Bigl{(} \rho(z_{i}\,|\,z)-r_{i}\Bigr{)}^{2}\)) can be written as,

\[\hat{f}_{t}=\operatorname*{argmin}_{f\in\mathcal{F}}\sum_{i=1}^{t-1}\left(f(a _{i})-r_{i}\right)^{2}.\]

The action component of the \(z\) element in this objective can be ignored since the \(\rho_{\text{bandits}}\) evaluation function does not depend on it. The confidence ball \(\mathcal{Z}_{t}=\biggl{\{}z\in\mathcal{Z}:\sum_{i=1}^{t-1}\Bigl{(}\rho(z_{i}\, |\,z)-\rho(z_{i}\,|\,\hat{z}_{t})\Bigr{)}^{2}\leq R\biggr{\}}\) reduces to,

\[\mathcal{F}_{t}=\biggl{\{}f\in\mathcal{F}:\,\sum_{i=1}^{t-1}\Bigl{(}f(a_{i})- \hat{f}_{t}(a_{i})\Bigr{)}^{2}\leq R\biggr{\}}.\]

The query can be reduced to the action component of \(z_{t}\),

\[a_{t}=\operatorname*{argmax}_{f,a\in\mathcal{F}_{t}\times\mathcal{A}}f(a).\]

Algorithm 6 summarizes this reduction and corresponds to the standard optimistic least squares for sturctured bandit problems from [24].

```
1:Input: action set \(\mathcal{A}\), function class \(\mathcal{F}\), confidence-set radius \(R\), number of steps \(T\).
2:for\(t=1,\ldots,T\)do
3: Compute confidence set \[\hat{f}_{t} =\operatorname*{argmin}_{f\in\mathcal{F}}\sum_{i=1}^{t-1}\left(f(a _{i})-r_{i}\right)^{2}.\] \[\mathcal{F}_{t} =\bigg{\{}f\in\mathcal{F}:\,\sum_{i=1}^{t-1}\Bigl{(}f(a_{i})-\hat {f}_{t}(a_{i})\Bigr{)}^{2}\leq R\bigg{\}}.\]
4: Submit the query \(a_{t}=\operatorname*{argmax}_{f,a\in\mathcal{F}_{t}\times\mathcal{A}}f(a)\).
5: Observe reward \(r_{t}\).
6:endfor ```

**Algorithm 6** Optimistic Interactive Estimation for Structured Bandits