# Bayesian Active Causal Discovery with

Multi-Fidelity Experiments

 Zeyu Zhang

Gaoling School of Artificial Intelligence

Renmin University of China

zeyuzhang@ruc.edu.cn

&Chaozhuo Li

Microsoft Research Asia

cli@microsoft.com

&Xu Chen

Gaoling School of Artificial Intelligence

Renmin University of China

xu.chen@ruc.edu.cn

Co-first authors.

Xing Xie

Microsoft Research Asia

xingx@microsoft.com

Co-first authors.

Corresponding author.

###### Abstract

This paper studies the problem of active causal discovery when the experiments can be done based on multi-fidelity oracles, where higher fidelity experiments are more precise and expensive, while the lower ones are cheaper but less accurate. In this paper, we formally define the task of multi-fidelity active causal discovery, and design a probabilistic model for solving this problem. In specific, we first introduce a mutual-information based acquisition function to determine which variable should be intervened at which fidelity, and then a cascading model is proposed to capture the correlations between different fidelity oracles. Beyond the above basic framework, we also extend it to the batch intervention scenario. We find that the theoretical foundations behind the widely used and efficient greedy method do not hold in our problem. To solve this problem, we introduce a new concept called \(\epsilon\)-submodular, and design a constraint based fidelity model to theoretically validate the greedy method. We conduct extensive experiments to demonstrate the effectiveness of our model.

## 1 Introduction

Causal discovery aims to learn the causal structure of a set of variables, which is fundamental for many real-world applications, including health caring [1], education [2] drug discovery [3] and protein synthesis [4]. In general, causal structure learning is an NP-hard problem [5], and purely based on the observational datasets, one cannot identify the unique causal structure, where the best result is discovering its Markov equivalence class [6].

To more accurately identify the unique causal structure, a promising direction is active causal discovery (ACD), where the model is allowed to actively intervene the causal structure to query key information for orienting the causal relations between different variables. For example, to study the causal relations between the drugs and diseases, one can conduct clinical tests via selectively administering the medicines to the patients. The key of active causal discovery is how to design effective experiments when the total cost (_e.g._, the number of experiments) is limited. To achieve this goal, recent years have witnessed many promising models. For example, Agrawal et al. [7] proposes to intervene on the variables which can orient as many as possible undirected edges. Tigas et al. [8]designs a mutual information based method to determine the variables and values to be intervened, and study both single and batch intervention scenarios.

While the above models have achieved remarkable successes, they only allow to query a single oracle (_e.g._, the real causal structure) for the experiments3. However, in many real-world applications, the experiments can be done via different methods. For example, to investigate the drug-disease causal relations, in addition to the clinical tests, one can also build simulators to obtain the medicine effects on the patients [9]. Usually, each experimental method corresponds to a unique oracle, and different oracles have various fidelites. Higher-fidelity experiments are more accurate but expensive, for example, administering drugs to the real patients. Lower-fidelity experiments are cheaper but inaccurate, for example, using patient simulators. These different fidelity oracles may offer better cost-benefit trade-offs, which, however, cannot be handled by existing active causal discovery models.

Footnote 3: In the following, we may interchangeably use “oracle”, “causal structure” and “structure causal model” to represent the underlying model for generating the results of the experiments.

To bridge the above gap, in this paper, we formally define the task of active causal discovery with multi-fidelity oracles, where the model has to actively select which variables and values to intervene at which fidelities. This task is non-trivial due to the following reasons: to begin with, because of the introduction of multi-fidelity oracles, the model has to strategically choose the lower-cost and informative enough experiments to uncover the real causal structure, which needs our special designs. Then, given the experiment results with different fidelities, how to infer the real causal structure is also not easy, since the experiment results can be not produced from the oracle corresponding to the real causal structure. In addition, in practice, an efficient experiment should allow simultaneously intervening multiple variables [10]. However, how to extend our model to the batch intervention scenario is still not clear.

To overcome the above challenges, we design a Bayesian active causal discovery model, which is composed of two components. The first one is a mutual information (MI) based acquisition function. It aims to select the interventional variables, values and fidelities which are more informative for the real causal structure. The second one is a cascading fidelity model. In specific, we first regard the highest fidelity oracle as the real causal structure, and then a cascading model is built to correlate different fidelity oracles, so that the experiment results at one fidelity can be leveraged to infer the oracle at another fidelity. To achieve more efficient experiments, we also extend our model to the batch intervention scenario. Previously, the greedy method is demonstrated to be an efficient and effective strategy for batch intervention [8]. However, we found that, by allowing multi-fidelity oracles, the theoretical foundations behind the greedy method do not hold. For alleviating this problem, we introduce a new concept called \(\epsilon\)-submodular, and design a constraint-based fidelity model to theoretically validate the greedy method.

The main contributions of this paper are summarized as follows: (1) we formally define the task of active causal discovery with multi-fidelity oracles, which, to our knowledge, is the first time in the field of causal discovery. (2) To solve the above task, we propose a Bayesian framework, which is composed of a mutual information based acquisition function and a cascading fidelity model. (3) To extend our framework to the batch intervention scenario, we introduce a constraint-based fidelity model, which provides theoretical guarantees for the efficient greedy method. (4) We conduct extensive experiments to demonstrate the effectiveness of our model.

## 2 Preliminaries

### Structure Causal Model

Structure causal model (SCM) is an effective language for describing and learning the causal relations between different random variables [11]. Usually, SCM is composed of a causal graph and a set of structure equation models (SEM).

For the causal graph, we denote it by \(G=\langle V,\mathbf{E}\rangle\), where \(V\) is the node set, and \(\mathbf{E}\) is the adjacency matrix. Each node in \(V\) corresponds to a variable. Suppose there are \(d\) variables in our studied problem, then we use \(X_{V}=[X_{1},X_{2},\ldots,X_{d}]\) to denote the variable set. The adjacency matrix \(\mathbf{E}\in\{0,1\}^{d\times d}\) describes the causal relations between different variables. \(\mathbf{E}_{ij}=1\) means that \(X_{i}\) is a parent of \(X_{j}\), and there exists an edge from \(X_{i}\) to \(X_{j}\), while \(\mathbf{E}_{ij}=0\) indicates that there is no edge between \(X_{i}\) and \(X_{j}\).

For the structure equation models, we denote them by \(\bm{g}=\{g_{1},g_{2},...,g_{d}\}\), where each \(g_{i}\) quantitatively describes the relation between \(X_{i}\) and its parents. Formally, we implement \(F\) with the commonly used additive noise models (ANM) [12], that is:

\[X_{i}=g_{i}(pa(i);\gamma_{i})+\epsilon_{i},\quad\epsilon_{i}\sim\mathcal{N}(0, \sigma_{i}^{2}),\] (1)

where \(\gamma_{i}\) is the parameter set of \(g_{i}\), and the noise term \(\epsilon_{i}\) follows the Gaussian distribution with \(\sigma_{i}^{2}\) as the variance. We denote the complete parameter set of \(\bm{g}\) as \(\bm{\theta}=\{\bm{\gamma},\bm{\sigma}\}\), where \(\bm{\gamma}=\{\gamma_{1},\gamma_{2},\ldots,\gamma_{d}\}\) and \(\bm{\sigma}=\{\sigma_{1},\sigma_{2},\ldots,\sigma_{d}\}\). Note that, given the above equation, we can easily derive the distribution of \(X_{V}\), that is, \(p(X_{V})=\prod_{i=1}^{d}\mathcal{N}(g_{i}(pa(i);\gamma_{i}),\sigma_{i}^{2})\).

Based on the above formulation, given an observational dataset \(D=\{\bm{x}_{k}\}_{k=1}^{N}\sim p(X_{V})\), causal discovery aims to learn the adjacency matrix \(\mathbf{E}\), or more generally, simultaneously identify \(\mathbf{E}\) and the SEM parameter \(\bm{\theta}\). In this paper, we focus on the general case, and denote \(\bm{\phi}=(\bm{\theta},\mathbf{E})\).

### Active Causal Discovery

Previous work has demonstrated that, purely based on the observational dataset, the real causal graph can only be identifiable to its Markov equivalence class. Active causal discovery holds the promise of identifying more accurate causal graph via designing interventional experiments.

Formally, an interventional experiment is represented by \(\bm{e}=\{(j,v)\}\), which means cutting all the causal relations pointing to \(X_{j}\), and fixing the value of \(X_{j}\) as \(v\). In causal learning, the experiment \(\bm{e}\) can also be represented by \(\text{do}(X_{j}=v)\). Obviously, the distribution of \(X_{V}\) is changed after the experiment \(\bm{e}\), and we denote the experiment-induced distribution by \(p(X_{V}|\text{do}(X_{j}=v))\). In practice, we cannot access the implementation of \(p\), but can only observe the experiment result sampled from \(p(X_{V}|\text{do}(X_{j}=v))\). The key of active causal discovery is to design a series of experiments within limited budgets, such that the results can be better leveraged to identify \(\bm{\phi}\).

### Multi-Fidelity Active Causal Discovery

Existing ACD models mostly obtain the experiment results via interacting with the real SCM. However, in practice, the experiments can be done in different ways (_e.g._, real clinical tests or patient simulators). Each type of experiment corresponds to an underlying oracle, which produces the results of the experiments. Different oracles may provide better cost-benefit trade-offs for the experiment designs, which are failed to be considered by the previous work.

Formally, suppose we have \(M\) oracles, and the parameters of the \(i\)th oracle is denoted by \(\bm{\phi}_{i}\). Let the experiment cost of the \(i\)th oracle be \(\lambda_{i}\), and without loss of generality, we assume \(\lambda_{1}\leq\lambda_{2}\leq\cdots\leq\lambda_{M}\). Intuitively, if an oracle is more accurate (_i.e._, has higher fidelity), then it should be more expensive4. We regard the real SCM as the most accurate oracle, thus we set \(\bm{\phi}_{M}=\bm{\phi}\). We denote all the oracle parameters and costs as \(\bm{\Phi}=\{\bm{\phi}_{1},\bm{\phi}_{2},...,\bm{\phi}_{M}\}\) and \(\bm{\Lambda}=\{\lambda_{1},\lambda_{2},...,\lambda_{M}\}\), respectively.

Footnote 4: Note that if some oracle costs more than another one with higher fidelity, then this oracle is useless, since one may always choose to query the higher fidelity oracle.

Due to the introduction of multi-fidelity oracles, the experiment in traditional active causal discovery is extended to be a triplet \(\bm{e}=\{(j,v),m\}\), where in addition to the intervention pair \((j,v)\), the fidelity \(m\) should also be considered in the experiment design. We define the dataset for model training as \(D=\{\bm{e}_{t},\bm{x}_{t}\}_{t=1}^{T}\), where \(\bm{e}_{t}=\{(j,v),m\}\) indicates the distribution for generating \(\bm{x}_{t}\). In general, \(\{(j,v),m\}\) means that \(\bm{x}_{t}\) is generated from \(p_{m}(X_{V}|\text{do}(X_{j}=v))\), which is induced by \(\bm{\phi}_{m}\) and the intervention \((j,v)\). If \((j,v)=\emptyset\), then \(\bm{x}_{t}\) is an observational data, which is sampled from \(\bm{\phi}_{m}\) without any intervention. Finally, we define the task of multi-fidelity active causal discovery as follows:

**Definition 1** (Multi-Fidelity Active Causal Discovery (MFACD)).: Given \(M\) oracles with different costs \(\bm{\Lambda}\), we need to design a model \(f\), which can strategically determine the intervention pair \((j,v)\) and fidelity \(m\) to achieve better cost-benefit trade-off in terms of identifying the real SCM \(\bm{\phi}_{M}\).

The Licence Model

For solving the task of MFACD, we design a Bayesian framework called Licence (Multi-fidelity active learning for causal discovery), which is composed of two components. The first one is an acquisition function based on mutual information, which is responsible for designing the experiments. The second one is a cascaded fidelity model, which is designed to capture the correlation between different \(\bm{\phi}_{i}\)'s. The experiment results obtained from the first component are leveraged to update the fidelity model, and \(\bm{\phi}_{M}\) in the fidelity model is the finally predicted result. At last, we introduce how to extend our model to the batch intervention scenario.

### MI-based Acquisition Function

Intuitively, a better experiment should leverage little cost to reveal as much as possible information about the real SCM \(\bm{\phi}_{M}\). Thus, we design the following acquisition function:

\[f(j,v,m)=\frac{I(\bm{x};\bm{\phi}_{M}|\bm{e},D)}{\lambda_{m}},\]

where \(\bm{e}=\{(j,v),m\}\) is the experiment to be designed. \(D\) is the dataset already collected, which will be enlarged after each experiment. \(I(\bm{x};\bm{\phi}_{M}|\bm{e},D)\) is the mutual information, which indicates that if we conduct experiment \(\bm{e}\), then how much information the experiment result may share with the target parameter \(\bm{\phi}_{M}\). Obviously, we should select \(\bm{e}\) which can lead to larger \(I(\bm{x};\bm{\phi}_{M}|\bm{e},D)\). \(\lambda_{m}\) is the cost of \(\bm{e}\). By dividing \(I(\bm{x};\bm{\phi}_{M}|\bm{e},D)\) with \(\lambda_{m}\), we trade-off the experiment informativeness and cost. To determine \((j,v,m)\), we derive an estimator for \(f(j,v,m)\) following the idea of Bayesian Active Learning by Disagreement (BALD) [13], that is:

\[\begin{split}& f(j,v,m)=\frac{H(\bm{x}|\bm{e},D)-H(\bm{x}|\bm{ \phi}_{M},\bm{e},D)}{\lambda_{m}}\\ =&\frac{-\mathbb{E}_{p(\bm{x}|\bm{e},D)}\left[\log \mathbb{E}_{p(\bm{\phi}_{m}|\bm{e},D)}[p(\bm{x}|\bm{e},\bm{\phi}_{m})]\right] +\mathbb{E}_{p(\bm{\phi}_{M}|D)}\left[\mathbb{E}_{p(\bm{x}|\bm{e},\bm{\phi}_{ M})}[\log p(\bm{x}|\bm{e},\bm{\phi}_{M})]\right]}{\lambda_{m}},\end{split}\] (2)

where \(p(\bm{x}|\bm{e},D)\) and \(p(\bm{\phi}_{m}|\bm{e},D)\) correspond to the distributions of \(\bm{x}\) and \(\bm{\phi}_{m}\) after observing \(D\) under the intervention \((j,v)\). \(p(\bm{\phi}_{M}|D)\) is the posterior of \(\bm{\phi}_{M}\) after observing \(D\). \(p(\bm{x}|\bm{e},\bm{\phi}_{m})\) is the probability of \(\bm{x}\) based on \(\bm{\phi}_{m}\) intervened by \((j,v)\). We approximate the expectation operator based Monte Carlo sampling. The detailed derivation process can be seen in the appendix.

Obviously, determining the best \((j,v,m)\) equals to solving the following problem:

\[\{j^{*},v^{*},m^{*}\}=\arg\max_{\{j,v,m\}}f(j,v,m).\] (3)

In our task, the intervention value \(v\) is continuous. Following the previous work, we firstly learn the optimal \(v\) for each \((j,m)\) pair based on Bayesian optimization (BO). Then, we compare all the results, and select the solution which can lead to the largest \(f(j,v,m)\). We present the detailed Bayesian optimization process in the appendix. It should be noted that one can also leverage more advanced BO methods for jointly learning \((j,v,m)\)[14]. However, we do not find significant performance improvements by these models.

### Cascaded Fidelity Model

Intuitively, the experiment results from different oracles may share common information. The samples at one fidelity may help to infer the oracles at other fidelities. To capture the correlations between different oracles, we build a cascaded probabilistic model (see Figure 1), where the oracles with different fidelities are successively connected, and the observed samples are only determined by their corresponding oracles.

Formally, to achieve more robust optimization, we first regard the discrete adjacency matrix \(\mathbf{E}\) as the samples from Bernoulli distribution. In specific, we let \(\mathbf{E}_{ij}\sim\text{Bernoulli}(\sigma(\mathbf{S}_{i}^{T}\mathbf{T}_{\cdot j }))\), where \(\mathbf{S},\mathbf{T}\in\mathbb{R}^{K\times d}\) (\(K\ll d\)) are two continuous matrices. \(\mathbf{S}_{\cdot i}\) and \(\mathbf{T}_{\cdot j}\) are the \(i\)th and \(j\)th columns of \(\mathbf{S}\) and \(\mathbf{T}\), respectively. By replacing \(\mathbf{E}\) with \(\mathbf{S}\) and \(\mathbf{T}\), we revise the parameter set \(\bm{\phi}\) as \((\bm{\theta},\mathbf{S},\mathbf{T})\).

For each fidelity \(m\), we assign a prior distribution of \(\bm{\phi}_{m}\) given \(\bm{\phi}_{m-1}\) as follows:

\[\begin{split} p(\bm{\phi}_{1})&\propto e^{-\beta \cdot f(\mathbf{S}_{1},\mathbf{T}_{1})}\cdot\mathcal{N}(\mathbf{0},\bm{I}),\\ p(\bm{\phi}_{m}|\bm{\phi}_{m-1})&\propto e^{-\beta \cdot f(\mathbf{S}_{m},\mathbf{T}_{m})}\cdot\mathcal{N}(\bm{a}\bm{\phi}_{m-1 }+\bm{b},\bm{\sigma}^{2}\bm{I}),\quad m\geq 2,\end{split}\] (4)where we add subscript \(m\) to indicate different fidelities. \(f(\mathbf{S}_{m},\mathbf{T}_{m})=\mathbb{E}_{p(\mathbf{E}|\mathbf{S}_{m},\mathbf{T }_{m})}[\lambda_{1}\cdot\{\text{trace}\left(e^{\mathbf{E}}\right)-d\}+\lambda_{2 }\cdot||\mathbf{E}||_{1}]\) is a regularizer to encourage \(\mathbf{E}\) to be a sparse and directed acyclic graph [15]. \(\lambda_{1}\), \(\lambda_{2}\), \(\bm{a}\), \(\bm{b}\) and \(\bm{\sigma}^{2}\) are hyper-parameters.

Since the real SCM is \(\bm{\phi}_{M}\), we need to infer the posterior \(p(\bm{\phi}_{M}|D)\), where \(D\) is the initially observational dataset or experiment results. Directly computing \(p(\bm{\phi}_{M}|D)\) is not easy, since the dataset \(D\) may contain samples from different fidelity oracles. To solve this problem, we first obtain the joint distribution \(p(\bm{\Phi}|D)\), where \(\bm{\Phi}=\{\bm{\phi}_{1},\bm{\phi}_{2},...,\bm{\phi}_{M}\}\) is the collection of all the oracle parameters. Then we derive \(p(\bm{\phi}_{M}|D)\) by marginalizing out \(\{\bm{\phi}_{1},\bm{\phi}_{2},...,\bm{\phi}_{M-1}\}\).

To efficiently compute and sample from \(p(\bm{\Phi}|D)\), we introduce a variational approximator \(q(\bm{\Phi})\), which is specified as follows:

\[\begin{split} q(\bm{\phi}_{1})&\sim\mathcal{N}( \bm{0},\bm{I}),\\ q_{\psi_{m}}(\bm{\phi}_{m}|\bm{\phi}_{m-1})&\sim \mathcal{N}(\bm{c}_{m}\bm{\phi}_{m-1}+\bm{d}_{m},\bm{\sigma}_{m}^{2}\bm{I}), \quad m\geq 2,\\ q(\bm{\Phi})&=q(\bm{\phi}_{1})\prod_{m=2}^{M}q( \bm{\phi}_{m}|\bm{\phi}_{m-1}),\end{split}\] (5)

where \(\psi_{m}=\{\bm{c}_{m},\bm{d}_{m},\bm{\sigma}_{m}\}\) is the set of learnable parameters, and we denote \(\bm{\Psi}=\{\psi_{m}\}_{m=2}^{M}\). According to the theory of variational inference [16], we maximize the following evidence lower bound (ELBO) [16] to learn \(\bm{\Psi}\):

\[\begin{split}\text{ELBO}=&\mathbb{E}_{\bm{\Phi} \sim q(\bm{\Phi})}\left[\log p(D|\bm{\Phi})-\text{KL}(q(\bm{\Phi})||p(\bm{ \Phi}))\right],\\ =&\mathbb{E}_{\bm{\Phi}\sim q(\bm{\Phi})}\left[\log p (D|\bm{\Phi})-\log q(\bm{\Phi})+\log p(\bm{\Phi})\right],\end{split}\] (6)

where the likelihood \(p(D|\bm{\Phi})\) can be easily obtained based on equation (1). More detailed derivation on the ELBO can be seen in the appendix. Once we have learned \(\bm{\Psi}\), the posterior \(p(\bm{\Phi}|D)\) is approximated by \(q(\bm{\Phi})\), and further, we have the following theory:

**Theorem 1**.: _If \(p(\bm{\Phi}|D)\approx q(\bm{\Phi})\), then for any variable sets \(A,B\subseteq\bm{\Phi}\), \(p(A|B,D)\approx q(A|B)\). As a special case \(p(\bm{\phi}_{M}|D)\approx q(\bm{\phi}_{M})\)._

The proof of this theory is immediate, since

\[\begin{split} p(A|B,D)&=\frac{p(A,B|D)}{p(B|D)}= \frac{\int_{\bm{\Phi}_{-A-B}}p(\bm{\Phi}|D)\text{d}\bm{\Phi}_{-A-B}}{\int_{ \bm{\Phi}_{-B}}p(\bm{\Phi}|D)\text{d}\bm{\Phi}_{-B}}\approx\frac{\int_{\bm{ \Phi}_{-A-B}}q(\bm{\Phi})\text{d}\bm{\Phi}_{-A-B}}{\int_{\bm{\Phi}_{-B}}q(\bm {\Phi})\text{d}\bm{\Phi}_{-B}}\\ &=\frac{q(A,B)}{q(B)}=q(A|B)\end{split}\]

Let \(A=\bm{\phi}_{M}\) and \(B=\emptyset\), we have \(p(\bm{\phi}_{M}|D)\approx q(\bm{\phi}_{M})\). Based on this theory, we leverage \(q\) to replace \(p\) in (2) for easy sampling.

_Remark_.: According to the specification of \(q_{\psi_{m}}(\bm{\phi}_{m}|\bm{\phi}_{m-1})\), we can easily demonstrate that \(q(\bm{\Phi})\) follows Gaussian distribution. Such property enables us to use the reparameterization trick [17] to relate \(\bm{\Phi}\) with \(\bm{\Psi}\). Different from traditional variational models, in our objective, the adjacency matrix

Figure 1: The cascaded probabilistic model is shown above. Different fidelity oracles are successively connected, and the observed samples are only determined by their corresponding oracles.

\(\bm{E}\) in \(f(\mathbf{S}_{m},\mathbf{T}_{m})\) is sampled from a discrete distribution, which cuts down the back-propagation signal. To solve this problem, we leverage gumbel-softmax to further associate \(\bm{E}\) with \((\mathbf{S}_{m},\mathbf{T}_{m})\in\bm{\Phi}\). Since \(\bm{\Phi}\) can be further represented by \(\bm{\Psi}\), all the variables in (6) can be reparameterized by \(\bm{\Psi}\), which enables us to optimize it in an end to end manner. We present the detailed derivation process and the complete learning algorithm in the appendix.

### Extension to Batch Intervention

In practice, simultaneously intervening multiple variables can be more efficient due to the lower frequency on interacting with the oracles. However, under the setting of batch intervention, the candidate intervention space exponentially increases with respect to the number of targets. Suppose we need to select \(c\) out of \(d\) variables for intervention, then the size of the candidate space is \(d^{c}\). Previous work found that the greedy strategy is a both efficient and effective method for the batch intervention scenario [8]. From the efficiency perspective, the greedy method only need to search in a \(cd\)-sized candidate space. From the effectiveness perspective, people demonstrate that the mutual information obtained by the greedy strategy is not worse than that of the optimal solution multiplied by \((1-\frac{1}{e})\)[18]. In the following, we introduce how to extend our model to the batch intervention scenario, and leverage the greedy strategy to solve our task.

**Objective for batch intervention in MFACD**. We use the following objective for batch intervention scenario:

\[\begin{split}\operatorname*{arg\,max}_{\{\bm{e}_{i}\}_{i=1}^{n}}I (\{\bm{x}_{i}\}_{i=1}^{n};\bm{\phi}_{M}|\{\bm{e}_{i}\}_{i=1}^{n},D),\\ \text{s.t.}&\sum_{i=1}^{n}\lambda_{i}\leq C,\end{split}\] (7)

where \(\bm{e}_{i}=\{(j_{i},v_{i}),m_{i}\}\) is an experiment, \(\bm{x}_{i}\) is the observed sample from the experiment \(\bm{e}_{i}\), that is, \(\bm{x}_{i}\sim p_{m_{i}}(X_{V}|do(X_{j_{i}}=v_{i}))\). \(\lambda_{i}\) is the cost of experiment \(\bm{e}_{i}\). This objective aims to design a series of experiments with budget C, which can reveal the information about \(\bm{\phi}_{M}\) as much as possible. The number of intervention targets \(n\) is not a fixed value, which is constrained by the total budget.

**The greedy method for MFACD**. The greedy method designs each experiment independently, and at each step, it selects the experiment which can maximize the average information gain. Following [19], the \(k\)th experiment is determined based on the following objective:

\[\begin{split}\operatorname*{arg\,max}_{\bm{e}_{k}}& \frac{I(\{\bm{x}_{i}\}_{i=1}^{k-1}\cup\bm{x}_{k};\bm{\phi}_{M}|\{\bm{e}_{i} \}_{i=1}^{k-1}\cup\bm{e}_{k},D)-I(\{\bm{x}_{i}\}_{i=1}^{k-1};\bm{\phi}_{M}|\{ \bm{e}_{i}\}_{i=1}^{k-1},D))}{\lambda_{m}}\\ & s.t.\sum_{m=1}^{k-1}\lambda_{m}+\lambda_{k}\leq C,\end{split}\] (8)

where \(\{\bm{e}_{i}\}_{i=1}^{k-1}\) is the previously designed experiments, and is fixed when learning \(\bm{e}_{k}\).

**What's wrong with the greedy method.** The theoretical foundations of the greedy method is demonstrated by the previous work [19] as follows:

**Theorem 2**.: _If \(I(\bm{x};\bm{\phi}_{M}|\bm{e},D)\) is (1) submodular and (2) non-decreasing, then_

\[I(\{\bm{x}_{i}^{g}\}_{i=1}^{n};\bm{\phi}_{M}|\{\bm{e}_{i}^{g}\}_{i=1}^{n},D) \geq(1-\frac{1}{e})I(\{\bm{x}_{i}^{*}\}_{i=1}^{n};\bm{\phi}_{M}|\{\bm{e}_{i}^{* }\}_{i=1}^{n},D),\] (9)

_where \(\{\bm{e}_{i}^{g}\}_{i=1}^{n}\) is the solution obtained from the greedy method, and \(\{\bm{e}_{i}^{*}\}_{i=1}^{n}\) is the optimal solution._

However, due to the introduction of multi-fidelity, in our model, \(I(\bm{x};\bm{\phi}_{M}|\bm{e},D)\) is actually not submodular. More specifically, in the proof of submodular, two samples \(\bm{x}_{s}\) and \(\bm{x}_{t}\) has to be independent given \(\bm{\phi}_{M}\) (_e.g._, see B.4 in [8]). In the single-fidelity setting, this requirement naturally holds, since \(\bm{\phi}_{M}\) is exactly the parameter used to sample \(\bm{x}_{s}\) and \(\bm{x}_{t}\). However, when we introduce multi-fidelity, \(\bm{x}_{s}\) and \(\bm{x}_{t}\) may not independent given \(\bm{\phi}_{M}\), since they are only directly influenced by their own oracles (see Figure 1).

**An improved greedy method tailored to MFACD**. To alleviate the above problem, in this section we design an improved greedy method tailored to our task. In specific, we first define several new concepts, and then build theories based on these concepts to inspire our model designs.

**Definition 2** (\(\epsilon\)-independent).: For random variables \(A,B\) and \(C\), if their mutual information satisfy \(I(A;B|C)\leq\epsilon\), then we say \(A\) and \(B\) are \(\epsilon\)-independent given \(C\).

**Definition 3** (\(\epsilon\)-submodular).: Suppose \(f(\cdot)\) is a set function on \(\Omega\). If for any \(A,B\subseteq\Omega\), \(A\subseteq B\) and \(x\in\Omega\backslash B\), \(f(A\cup\{x\})-f(A)\geq f(B\cup\{x\})-f(B)-\epsilon\), then we say \(f\) is \(\epsilon\)-submodular on \(\Omega\).

Based on the above two definitions, we have:

**Theorem 3**.: _For any two experiments \(\bm{e}_{s}\) and \(\bm{e}_{t}\), if the corresponding samples \(\bm{x}_{s}\) and \(\bm{x}_{t}\) are \(\epsilon\)-independent given \(\bm{\phi}_{M},\{\bm{e}_{s},\bm{e}_{t}\}\) and \(D\), then \(I(\cdot;\phi_{M}|\cdot,D)\) is \(\epsilon\)-submodular._

**Theorem 4**.: _If \(I(\cdot;\bm{\phi}_{M}|\cdot,D)\) is \(\epsilon\)-submodular on \(X\) and non-decrease, for any \(i,j\), \(\frac{\lambda_{i}}{\lambda_{j}}\leq B_{\lambda}\), then_

\[I(\{\bm{x}_{i}^{g}\}_{i=1}^{n};\bm{\phi}_{M}|\{\bm{e}_{t}^{g}\}_{i=1}^{n},D) \geq(1-e^{-\frac{1}{B_{\lambda}}})I(\{\bm{x}_{i}^{*}\}_{i=1}^{n};\bm{\phi}_{M} |\{\bm{e}_{i}^{*}\}_{i=1}^{n},D)-B,\]

_where \(B=\frac{\epsilon}{B_{\lambda}}\cdot\sum_{i=1}^{n}(1-\frac{1}{B_{\lambda}n})^{ i-1}\)._

Following this theory, we improve objective (6) to a consitant-based ELBO as follows to capture the degree of independence between different experiment results:

\[\max \ \mathbb{E}_{\bm{\Phi}\sim q(\bm{\Phi})}\left[\log p(D|\bm{\Phi}) -\log q(\bm{\Phi})+\log p(\bm{\Phi})\right],\] (10) s.t. \[\sum_{\{\bm{e}_{s},\bm{e}_{t}\}}I(\bm{x}_{s};\bm{x}_{t}|\bm{\phi }_{M},\{\bm{e}_{s},\bm{e}_{t}\},D)\leq\epsilon.\]

The proofs of the above theories are presented in the appendix, and similar to objective (2), we use Monte Carlo method to approximate the mutual information in objective (10).

## 4 Related Works

**Bayesian Active Causal Discovery.** Causal discovery [20; 21; 22] refers to recovering causality in a set of variables, especially trying to find a directed acyclic graph (DAG) that can represent the relationship between variables in a system. Active causal discovery was first proposed in [23; 24] with the assumption that the data is discrete-valued. In active causal discovery, the experimenter attempts to intervene on the variables in the system at each step, utilizes the interventional data to recover causal relation, and finally identifies the entire causal structure with minimal cost [25]. Many methods have been discussed in different settings over the past decades, including continuous linear Bayesian networks [26; 27], non-linear causal models [28], and large-scale causal models [8].

**Multi-fidelity Settings.** The fidelity commonly refers to how accurate the model or environment can be when providing information. Higher-fidelity models are more accuracy but cost much, while lower ones are less accurate but cheaper. In order to combine the strength of each model, multi-fidelity models are proposed to achieve an accurate model with lower costs. Multi-fidelity models can be divided into two main categories [29]: Multi-fidelity Surrogate Models (MFSM) [30; 31; 32] and Multi-fidelity Hierarchical Models (MFHM) [33; 34; 35]. In addition to optimization, multi-fidelity models can also be used for uncertainty propagation [36] and statistical inference [37]. Recent works also start to study the multi-fidelity settings when conducting Bayesian experiments [38; 39; 40], and adopt deep learning frameworks to solve corresponding problems.

Our paper makes a first step towards multi-fidelity active causal discovery, and solve the non-trivial challenges when combining the above two fields, which, to the best of our knowledge, is the first time in the causal inference domain.

## 5 Experiments

In this section, we conduct experiments to demonstrate the effectiveness of our model, where we focus on the following problems: (1) whether our model can achieve better performance than the previous ACD methods? (2) Whether the constraint in objective (10) in necessary? (3) How the DAG regularization coefficient influence the model performance? In the following, we first introduce the experiment setup, and then present and analyze the results.

### Experimental Setup

We experiment with three commonly used causal discovery datasets, including Erdos-Renyi graph (**ER**) [41], Scale-Free graph (**SF**) [42] and DREAM [43]. To demonstrate the effectiveness of our model, we compare it with AIT [44] and CBED [8], which are the recent state-of-the-art models in this field. Since they cannot select different fidelities, we design two variants for each of the baseline, that is, **X-REAL** and **X-RANDOM**, which means that the model always interacts with the ground truth oracle \(\phi_{M}\) or randomly select the oracles. Here "X" is AIT or CBED. For the evaluation metrics, we use SHD [45], AUPRC [46] and RMSE to evaluate different models. The first two metrics aim to evaluate the accuracy of the learned topological structure, and the last one measures the performance of functional relations. For single intervention, we first generate several observational samples to initialize the model. Then, we indicate a total intervention budget, and let the model interact with the causal graph with different fidelities until the budget runs out. For each interaction, the model will provide an intervention, and correspondingly obtain a sample from the oracles, which is used to update the model. Finally, the model outputs the estimated causal graph, which is leveraged to evaluate the performance. For batch intervention, we indicate the total budget for each intervention step, and the model determines \(n\) interventions simultaneously, which are delivered to the oracles to obtain the samples. We present more detailed settings in the appendix.

### Overall Performance

In this experiment, we evaluate the models under different total budgets, and we present the results on ER and SF datasets with 10 graph nodes. The experiments on DREAM and more nodes are presented in the appendix. From the results shown in Figure 2, we can see: as the total budget becomes larger, the performances of all the models tend to increase on both datasets. This is not surprising, since more experiment budgets enable us to conduct more interventions or query more accurate oracles, which can reveal more information about the ground truth and facilitate more accurate causal discovery. In most cases, our model can perform better than the baselines across different datasets, evaluation metrics and intervention budgets. These results demonstrate the effectiveness of our model. In specific, on the metrics of SHD, AUPRC and RMSE, our model can on average improve performance of the best baseline by about 27.74%, 82.35% and 22.74% on ER, and 17.69%, 60.27% and 21.62%

Figure 2: Results of the overall performance on different datasets and budgets. Lower SHD, RMSE or larger AUPRC indicate better performances. We conduct each experiment for ten times, and report the average performances and error bars.

on SF, respectively. If we look more carefully, we find that, for both AIT and CBED, randomly querying the oracles can sometimes perform better than always interacting with the ground truth oracles. This result suggests that lower fidelity oracles can be helpful to trade-off the performance and cost. However, the random method is still suboptimal, and designing more principled and tailored strategies to select the fidelities is necessary, which is evidenced by the lowered performance of "X-RANDOM" than our model.

### Necessity of the Mutual Information Constraint in Objective (10)

In our model, the mutual information constraint in objective (10) aims to make the greedy method validate. In this section, we study whether it is necessary by experiments. To achieve this goal, we introduce a variant of our model **Licence (w/o reg)**, where we remove the mutual information constraint. We evaluate the models based on the dataset of ER with 10 graph nodes, and the total budget is set as 30. The results are presented in Figure 3(a). We can see, in some cases, "X-RANDOM" performs better than "X-REAL", which is consistent with the above experiments, and demonstrates that always querying the ground truth oracle may not lead to better performance under limited budget. By comparing our model with the variant Licence (w/o reg), we find that our model can consistently achieve better performances on all the evaluation metrics. In specific, Licence can improve the performance of Licence (w/o reg) by about 2.05%, 16.57% and 14.92% on SHD, AUPRC and RMSE respectively. These results demonstrate that the mutual information constraint is necessary in our model, which empirically verifies the theories proposed in section 3.3.

### Influence of the DAG regularization coefficient

In this section, we analysis the influence of the DAG regulation coefficient \(\beta\) in equation (4). The results are reported based on AUPRC. The coefficient \(\beta\) reflects the importance of DAG regulation when updating the model. As \(\beta\) increases, the DAGness is more emphasized for the causal graph. In this subsection, we conduct experiments for various \(\beta\), ranging from \(0.0\) to \(1.0\), and the results are shown in Figure 3(b). We can see as \(\beta\) increases, the performance of AUPRC improves as well, and peaks at \(\beta=0.8\). That is probably because lower \(\beta\) will decrease the acyclic property of causal graphs, which is incompatible with the prior knowledge of true causal graphs. However, higher coefficient may also impact the optimization process, which leads to sub-optimal results. We think a trade-off between mild constraint for easy optimization and solid constraint for DAG property is supposed to take into consider for different tasks and settings.

## 6 Conclusion

This paper formally defines the task of active causal discovery with multi-fidelity oracles, which, to our knowledge, is the first time in the causal discovery domain. To solve this task, we propose a Bayesian framework, which is composed of a mutual information based acquisition function and a cascading fidelity model. We also extend our framework to the batch intervention scenario, and propose a constraint-based fidelity model to validate the efficient greedy method.

Figure 3: (a) The results of experiments on ER graph with 10 graph nodes under the batch intervention scenario. The average performance and error bars are provided. (b) The results of Licence model with different DAG regulation coefficient \(\beta\)’s. The experiment is conducted based on ER graph with 10 graph nodes.

This paper actually makes an initial step toward considering different oracles in active causal discovery. There is much room left for improvement. To begin with, one can design more advanced batch intervention strategies, which can bypass the greedy method and does not need to introduce the mutual information constraint in the fidelity model. In addition, since the experiments in active causal discovery are conducted sequentially, and the former experiment results may influence the latter ones, it is interesting to consider the experiment designs as a Markov decision process, and leverage reinforcement learning to optimize the total information gains of all the experiments in a more principled manner.

## Acknowledgments

This work is supported in part by National Key R&D Program of China (2022ZD0120103), National Natural Science Foundation of China (No. 62102420), Beijing Outstanding Young Scientist Program NO. BJJWZYJH012019100020098, Intelligent Social Governance Platform, Major Innovation & Planning Interdisciplinary Platform for the "Double-First Class" Initiative, Renmin University of China, Public Computing Cloud, Renmin University of China, fund for building world-class universities (disciplines) of Renmin University of China, Intelligent Social Governance Platform.

## References

* [1] Jeffrey S Levin. Religion and health: Is there an association, is it valid, and is it causal? _Social Science & Medicine_, 38(11):1475-1482, 1994.
* [2] Eric R Eide and Mark H Showalter. Methods matter: Improving causal inference in educational and social science research: A review article. _Economics of Education Review_, 31(5):744-748, 2012.
* [3] Bengt Muthen and Hendricks C Brown. Estimating drug effects in the presence of placebo response: causal inference using growth mixture modeling. _Statistics in medicine_, 28(27):3363-3385, 2009.
* [4] Karen Sachs, Omar Perez, Dana Pe'er, Douglas A Lauffenburger, and Garry P Nolan. Causal protein-signaling networks derived from multiparameter single-cell data. _Science_, 308(5721):523-529, 2005.
* [5] David Maxwell Chickering. Learning bayesian networks is np-complete. _Learning from data: Artificial intelligence and statistics V_, pages 121-130, 1996.
* [6] Thomas S Verma and Judea Pearl. Equivalence and synthesis of causal models. In _Probabilistic and Causal Inference: The Works of Judea Pearl_, pages 221-236. 2022.
* [7] Raj Agrawal, Chandler Squires, Karren Yang, Karthikeyan Shanmugam, and Caroline Uhler. Abcd-strategy: Budgeted experimental design for targeted causal structure discovery. In _The 22nd International Conference on Artificial Intelligence and Statistics_, pages 3400-3409. PMLR, 2019.
* [8] Panagiotis Tigas, Yashas Annadani, Andrew Jesson, Bernhard Scholkopf, Yarin Gal, and Stefan Bauer. Interventions, where and how? experimental design for causal models at scale. In _Advances in Neural Information Processing Systems_.
* [9] Azam Peyvandipour, Nafiseh Saberian, Adib Shafi, Michele Donato, and Sorin Draghici. A novel computational approach for drug repurposing using systems biology. _Bioinformatics_, 34(16):2817-2825, 2018.
* [10] Yashas Annadani, Panagiotis Tigas, Desi R Ivanova, Andrew Jesson, Yarin Gal, Adam Foster, and Stefan Bauer. Differentiable multi-target causal bayesian experimental design. _arXiv preprint arXiv:2302.10607_, 2023.
* [11] Judea Pearl and Dana Mackenzie. _The book of why: the new science of cause and effect_. Basic books, 2018.

* [12] Patrik Hoyer, Dominik Janzing, Joris M Mooij, Jonas Peters, and Bernhard Scholkopf. Nonlinear causal discovery with additive noise models. _Advances in neural information processing systems_, 21, 2008.
* [13] Neil Houlsby, Ferenc Huszar, Zoubin Ghahramani, and Mate Lengyel. Bayesian active learning for classification and preference learning. _arXiv preprint arXiv:1112.5745_, 2011.
* [14] Samuel Daulton, Xingchen Wan, David Eriksson, Maximilian Balandat, Michael A Osborne, and Eytan Bakshy. Bayesian optimization over discrete and mixed spaces via probabilistic reparameterization. _arXiv preprint arXiv:2210.10199_, 2022.
* [15] Xun Zheng, Bryon Aragam, Pradeep K Ravikumar, and Eric P Xing. Dags with no tears: Continuous optimization for structure learning. _Advances in neural information processing systems_, 31, 2018.
* [16] David M Blei, Alp Kucukelbir, and Jon D McAuliffe. Variational inference: A review for statisticians. _Journal of the American statistical Association_, 112(518):859-877, 2017.
* [17] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. _arXiv preprint arXiv:1312.6114_, 2013.
* [18] Andreas Krause and Carlos E Guestrin. Near-optimal nonmyopic value of information in graphical models. _arXiv preprint arXiv:1207.1394_, 2012.
* [19] Shibo Li, Jeff M Phillips, Xin Yu, Robert Kirby, and Shandian Zhe. Batch multi-fidelity active learning with budget constraints. _Advances in Neural Information Processing Systems_, 35:995-1007, 2022.
* [20] Christina Heinze-Deml, Marloes H Maathuis, and Nicolai Meinshausen. Causal structure learning. _Annual Review of Statistics and Its Application_, 5:371-391, 2018.
* [21] Clark Glymour, Kun Zhang, and Peter Spirtes. Review of causal discovery methods based on graphical models. _Frontiers in genetics_, 10:524, 2019.
* [22] Matthew J Vowels, Necati Cihan Camgoz, and Richard Bowden. D'ya like dags? a survey on structure learning and causal discovery. _ACM Computing Surveys_, 55(4):1-36, 2022.
* [23] Kevin P Murphy. Active learning of causal bayes net structure. Technical report, technical report, UC Berkeley, 2001.
* [24] Simon Tong and Daphne Koller. Active learning for structure in bayesian networks. In _International joint conference on artificial intelligence_, volume 17, pages 863-869. Citeseer, 2001.
* [25] Yang-Bo He and Zhi Geng. Active learning of causal networks with intervention experiments and optimal designs. _Journal of Machine Learning Research_, 9(Nov):2523-2547, 2008.
* [26] Hyunghoon Cho, Bonnie Berger, and Jian Peng. Reconstructing causal biological networks through active learning. _PloS one_, 11(3):e0150611, 2016.
* [27] Robert Osazuwa Ness, Karen Sachs, Parag Mallick, and Olga Vitek. A bayesian active learning experimental design for inferring signaling networks. In _Research in Computational Molecular Biology: 21st Annual International Conference, RECOMB 2017, Hong Kong, China, May 3-7, 2017, Proceedings 21_, pages 134-156. Springer, 2017.
* [28] Julius von Kugelgen, Paul K Rubenstein, Bernhard Scholkopf, and Adrian Weller. Optimal experimental design via bayesian optimization: active causal structure learning for gaussian process networks. _arXiv preprint arXiv:1910.03962_, 2019.
* [29] M Giselle Fernandez-Godino, Chanyoung Park, Nam-Ho Kim, and Raphael T Haftka. Review of multi-fidelity models. _arXiv preprint arXiv:1609.07196_, 2016.

* [30] Alexander IJ Forrester, Neil W Bressloff, and Andy J Keane. Optimization using surrogate models and partially converged computational fluid dynamics simulations. _Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences_, 462(2071):2177-2204, 2006.
* [31] TD Robinson, Michael S Eldred, Karen E Willcox, and Robert Haimes. Surrogate-based optimization using multifidelity models with variable parameterization and corrected space mapping. _AIAA journal_, 46(11):2814-2822, 2008.
* [32] Christopher C Fischer, Ramana V Grandhi, and Philip S Beran. Bayesian low-fidelity correction approach to multi-fidelity aerospace design. In _58th AIAA/ASCE/AHS/ASC Structures, Structural Dynamics, and Materials Conference_, page 0133, 2017.
* [33] SA Burton and P Hajela. A variable-complexity approach to second-order reliability-based optimization. _Structural and Multidisciplinary Optimization_, 25(4):237-250, 2003.
* [34] Akil Narayan, Claude Gittelson, and Dongbin Xiu. A stochastic collocation algorithm with multifidelity models. _SIAM Journal on Scientific Computing_, 36(2):A495-A521, 2014.
* [35] Benjamin Peherstorfer, Tiangang Cui, Youssef Marzouk, and Karen Willcox. Multifidelity importance sampling. _Computer Methods in Applied Mechanics and Engineering_, 300:490-509, 2016.
* [36] Leo Wai-Tsun Ng and Michael Eldred. Multifidelity uncertainty quantification using non-intrusive polynomial chaos and stochastic collocation. In _53rd aiaa/asme/asce/ahs/asc structures, structural dynamics and materials conference 20th aiaa/asme/ahs adaptive structures conference 14th aiaa_, page 1852, 2012.
* [37] Tiangang Cui, Youssef M Marzouk, and Karen E Willcox. Data-driven model reduction for the bayesian solution of inverse problems. _International Journal for Numerical Methods in Engineering_, 102(5):966-990, 2015.
* [38] Shibo Li, Wei Xing, Robert Kirby, and Shandian Zhe. Multi-fidelity bayesian optimization via deep neural networks. _Advances in Neural Information Processing Systems_, 33:8521-8531, 2020.
* [39] Shibo Li, Robert Kirby, and Shandian Zhe. Batch multi-fidelity bayesian optimization with deep auto-regressive networks. _Advances in Neural Information Processing Systems_, 34:25463-25475, 2021.
* [40] Shibo Li, Jeff M Phillips, Xin Yu, Robert Kirby, and Shandian Zhe. Batch multi-fidelity active learning with budget constraints. _Advances in Neural Information Processing Systems_, 35:995-1007, 2022.
* [41] Paul Erdos, Alfred Renyi, et al. On the evolution of random graphs. _Publ. Math. Inst. Hung. Acad. Sci_, 5(1):17-60, 1960.
* [42] Lun Li, David Alderson, John C Doyle, and Walter Willinger. Towards a theory of scale-free graphs: Definition, properties, and implications. _Internet Mathematics_, 2(4):431-523, 2005.
* [43] Thomas Schaffter, Daniel Marbach, and Dario Floreano. Genenetweaver: in silico benchmark generation and performance profiling of network inference methods. _Bioinformatics_, 27(16):2263-2270, 2011.
* [44] Yashas Annadani, Jonas Rothfuss, Alexandre Lacoste, Nino Scherrer, Anirudh Goyal, Yoshua Bengio, and Stefan Bauer. Variational causal networks: Approximate bayesian inference over causal structures. _arXiv preprint arXiv:2106.07635_, 2021.
* [45] Ioannis Tsamardinos, Laura E Brown, and Constantin F Aliferis. The max-min hill-climbing bayesian network structure learning algorithm. _Machine learning_, 65:31-78, 2006.
* [46] Jesse Davis and Mark Goadrich. The relationship between precision-recall and roc curves. In _Proceedings of the 23rd international conference on Machine learning_, pages 233-240, 2006.

* [47] Harold J Kushner. A new method of locating the maximum point of an arbitrary multipeak curve in the presence of noise. 1964.
* [48] Carl Edward Rasmussen. Gaussian processes in machine learning. In _Advanced Lectures on Machine Learning: ML Summer Schools 2003, Canberra, Australia, February 2-14, 2003, Tubingen, Germany, August 4-16, 2003, Revised Lectures_, pages 63-71. Springer, 2004.
* [49] Niranjan Srinivas, Andreas Krause, Sham M Kakade, and Matthias Seeger. Gaussian process optimization in the bandit setting: No regret and experimental design. _arXiv preprint arXiv:0912.3995_, 2009.
* [50] Reuven Y Rubinstein and Dirk P Kroese. _Simulation and the Monte Carlo method_. John Wiley & Sons, 2016.
* [51] Chris J Maddison, Andriy Mnih, and Yee Whye Teh. The concrete distribution: A continuous relaxation of discrete random variables. _arXiv preprint arXiv:1611.00712_, 2016.
* [52] Dimitri P Bertsekas. _Constrained optimization and Lagrange multiplier methods_. Academic press, 2014.
* [53] Lars Lorch, Jonas Rothfuss, Bernhard Scholkopf, and Andreas Krause. Dibs: Differentiable bayesian structure learning. _Advances in Neural Information Processing Systems_, 34:24111-24123, 2021.

## Appendix

* [1]
* Monte Carlo Approximation for \(f(j,v,m)\)
* 1 Derivation Process for \(f(j,v,m)\)
* 2 Sampling from \(p(\bm{\phi}_{m}|D)\)
* 3 Sampling from \(p(\bm{\phi}_{m}|\bm{\phi}_{M},D)\)
* 4 Calculation of \(p(\bm{x}|\bm{e},\bm{\phi}_{m})\)
* Bayesian Optimization for Determining \((j^{*},v^{*},m^{*})\)
* Detailed Training Process of ELBO
* 1 Derivation Process of ELBO
* 2 Estimation of ELBO
* 3 Gaussian Reparameterization Trick
* 4 Gumbel-softmax Reparameterization Trick
* 5 Optimization of ELBO
* Training Process of Constraint based ELBO
* Proof of Theory 3
* Proof of Theory 4
* Algorithm
* More Experiments
* 1 Experimental Settings
	* 1.1 Datasets
		* 1.1.2 Baselines
		* 1.1.3 Metrics
* 2 Simulation of Oracles with Different Fidelities
* 3 Details of Configurations and Computation
* 4 Experiments on DREAM Dataset
* 5 Experiments on More Nodes
* 6 Supplementary Experiments on MAE Metric
* 7 Supplementary Experiments on Different Oracle Settings
* 8 Supplementary Experiments on Regularization Coefficient \(\lambda\)
* 9 Supplementary Experiments on Ablation Studies
* Potentially Negative Social Impact
* Limitations
Monte Carlo Approximation for \(f(j,v,m)\)

### Derivation Process for \(f(j,v,m)\)

Considering that the mutual information is not directly tractable, we approximate \(f(j,v,m)\) by:

\[f(j,v,m)= -\frac{1}{\lambda_{m}\cdot K_{1}\cdot L_{1}}\sum_{k_{1}=1}^{K_{1}} \sum_{l_{1}=1}^{L_{1}}\log\left[\frac{1}{C}\sum_{c_{1}=1}^{C_{1}}p(\bm{x}_{m}^{ (k_{1},l_{1})}|\bm{\phi}_{m}^{(c_{1})},\bm{e})\right]\] \[+\frac{1}{\lambda_{m}\cdot K_{2}\cdot L_{2}\cdot C_{2}}\sum_{k_{2 }=1}^{K_{2}}\sum_{l_{2}=1}^{L_{2}}\sum_{c_{2}=1}^{C_{2}}\log\left[p(\bm{x}_{m}^ {(k_{2},l_{2},c_{2})}|\bm{\phi}_{M}^{(k_{2})},\bm{e})\right],\]

where \(\bm{e}=\{(j,v),m\}\) is the experiment to be designed, \(\bm{\phi}_{m}^{(c_{1})},\bm{\phi}_{m}^{(k_{1})}\sim p(\bm{\phi}_{m}|D)\), \(\bm{x}_{m}^{(k_{1},l_{1})}\sim p(\bm{x}|\bm{\phi}_{m}^{(k_{1})},\bm{e})\), \(\bm{\phi}_{M}^{(k_{2})}\sim p(\bm{\phi}_{M}|D)\), \(\bm{\phi}_{m}^{(k_{2},l_{2})}\sim p(\bm{\phi}_{m}|\bm{\phi}_{M}^{(k_{2})},D)\) and \(\bm{x}_{m}^{(k_{2},l_{2},c_{2})}\sim p(\bm{x}|\bm{\phi}_{m}^{(k_{2},l_{2})}, \bm{e})\).

We present the detailed approximation process as follows:

\[f(j,v,m) =\frac{1}{\lambda_{m}}I(\bm{x};\bm{\phi}_{M}|\bm{e},D)\] \[=\frac{1}{\lambda_{m}}\left[H(\bm{x}|\bm{e},D)-H(\bm{x}|\bm{\phi}_ {M},\bm{e},D)\right]\] \[=\frac{1}{\lambda_{m}}\left[-\mathbb{E}_{p(\bm{x}|\bm{e},D)}\left[ \log p(\bm{x}|\bm{e},D)+\mathbb{E}_{p(\bm{\phi}_{M}|D)}\left[\mathbb{E}_{p(\bm {x}|\bm{\phi}_{M},\bm{e})}\left[\log p(\bm{x}|\bm{e},\bm{\phi}_{M})\right]\right] \right]\right]\] \[=\frac{1}{\lambda_{m}}\left[-\mathbb{E}_{p(\bm{x}|\bm{e},D)} \left[\log\mathbb{E}_{p(\bm{\phi}_{m}|\bm{e},D)}\left[p(\bm{x}|\bm{e},\bm{\phi }_{m})\right]\right]\right]\right]\] \[+\underbrace{\frac{1}{\lambda_{m}}\left[\mathbb{E}_{p(\bm{\phi}_{ M}|D)}\left[\mathbb{E}_{p(\bm{x}|\bm{e},\bm{\phi}_{M})}\left[\log p(\bm{x}| \bm{e},\bm{\phi}_{M})\right]\right]\right]}_{F}\]

For part \(E\), we can estimate it by

\[E=-\frac{1}{\lambda_{m}\cdot K_{1}\cdot L_{1}}\sum_{k_{1}=1}^{K_{1}}\sum_{l_{1 }=1}^{L_{1}}\log\left[\frac{1}{C}\sum_{c_{1}=1}^{C_{1}}p(\bm{x}_{m}^{(k_{1},l_ {1})}|\bm{\phi}_{m}^{(c_{1})},\bm{e})\right],\]

where for the first expectation on \(p(\bm{\phi}_{m}|\bm{e},D)\), we first sample \(\bm{\phi}_{m}^{(k_{1})}\) from \(\bm{\phi}_{m}^{(k_{1})}\sim p(\bm{\phi}_{m}|\bm{e},D)\) for \(K_{1}\) times, and then for each \(\bm{\phi}_{m}^{(k_{1})}\), we sample \(\bm{x}_{m}^{(k_{1},l_{1})}\) from \(\bm{x}_{m}^{(k_{1},l_{1})}\sim p(\bm{x}|\bm{\phi}_{m}^{(k_{1})},\bm{e})\) for \(L_{1}\) times. For the second expectation on \(p(\bm{\phi}_{m}|\bm{e},D)\), we sample \(\bm{\phi}_{m}^{(c_{1})}\sim p(\bm{\phi}_{m}|\bm{e},D)\) for \(C_{1}\) times.

For part \(F\), we have

\[F =\frac{1}{\lambda_{m}}\cdot\left[\mathbb{E}_{p(\bm{\phi}_{M}|D)} \left[\mathbb{E}_{p(\bm{x}|\bm{\phi}_{M},\bm{e})}\left[\log p(\bm{x}|\bm{\phi }_{M},\bm{e})\right]\right]\right]\] \[=\frac{1}{\lambda_{m}}\cdot\left[\mathbb{E}_{p(\bm{\phi}_{M}|D)} \left[\int p(\bm{x}|\bm{\phi}_{M},\bm{e})\log p(\bm{x}|\bm{\phi}_{M},\bm{e}) \;d\bm{x}\right]\right]\] \[=\frac{1}{\lambda_{m}}\cdot\left[\mathbb{E}_{p(\bm{\phi}_{M}|D, \bm{e})}\left[\int\int p(\bm{x}|\bm{\phi}_{m},\bm{e})p(\bm{\phi}_{m}|\bm{\phi }_{M})\;d\bm{\phi}_{m}\log p(\bm{x}|\bm{\phi}_{M},\bm{e})\;d\bm{x}\right]\right]\] \[=\frac{1}{\lambda_{m}}\cdot\left[\mathbb{E}_{p(\bm{\phi}_{M}|D, \bm{e})}\left[\int\int p(\bm{x}|\bm{\phi}_{m},\bm{e})p(\bm{\phi}_{m}|\bm{\phi }_{M})\log p(\bm{x}|\bm{\phi}_{M},\bm{e})\;d\bm{x}\;d\bm{\phi}_{m}\right]\right]\] \[=\frac{1}{\lambda_{m}}\cdot\left[\mathbb{E}_{p(\bm{\phi}_{M}|D, \bm{e})}\left[\int\mathbb{E}_{p(\bm{x}|\bm{\phi}_{m},\bm{e})}\left[p(\bm{\phi}_ {m}|\bm{\phi}_{M})\log p(\bm{x}|\bm{\phi}_{M},\bm{e})\right]\;d\bm{\phi}_{m} \right]\right]\] \[=\frac{1}{\lambda_{m}}\cdot\left[\mathbb{E}_{p(\bm{\phi}_{M}|D, \bm{e})}\left[\mathbb{E}_{p(\bm{\phi}_{m}|\bm{\phi}_{M})}\left[\mathbb{E}_{p(\bm {x}|\bm{\phi}_{m},\bm{e})}\left[\log p(\bm{x}|\bm{\phi}_{M},\bm{e})\right] \right]\right]\right].\]

It can be estimated by

\[\frac{1}{\lambda_{m}\cdot K_{2}\cdot L_{2}\cdot C_{2}}\sum_{k_{2}=1}^{K_{2}}\sum_{l _{2}=1}^{L_{2}}\sum_{c_{2}=1}^{C_{2}}\log\left[p(\bm{x}_{m}^{(k_{2},l_{2},c_{2})}| \bm{\phi}_{M}^{(k_{2})},\bm{e})\right],\]

[MISSING_PAGE_FAIL:16]

Then, we integrate \(\phi_{2,j},\phi_{3,j},\ldots,\phi_{m-1,j}\) sequentially to obtain \(q(\phi_{m,j}|\phi_{1,j})\).

First of all, we integrate \(\phi_{2,j}\) for the joint distribution, where we have:

\[q(\phi_{m,j},\phi_{m-1,j},\ldots,\phi_{3,j}|\phi_{1,j})\] \[= \int q(\phi_{m,j},\phi_{m-1,j},\ldots,\phi_{3,j},\phi_{2,j}|\phi_ {1,j})\;d\phi_{2,j}\] \[= \int\prod_{i=2}^{m}\frac{1}{\sqrt{2\pi}\sigma_{i,j}}\cdot e^{ \frac{-1}{2\sigma_{i,j}^{2}}(\phi_{i,j}-\mu_{i,j})^{2}}d\phi_{2,j}\] \[= \prod_{i=4}^{m}\frac{1}{\sqrt{2\pi}\sigma_{i,j}}\cdot e^{\frac{- 1}{2\sigma_{i,j}^{2}}(\phi_{i,j}-\mu_{i,j})^{2}}\cdot\frac{1}{\sqrt{2\pi} \sigma_{3,j}}\cdot\frac{1}{\sqrt{2\pi}\sigma_{2,j}}\cdot\int e^{\frac{-1}{2 \sigma_{3,j}^{2}}[\phi_{3,j}-(c_{3,j}\phi_{2,j}+d_{3,j})]^{2}}.\] \[e^{\frac{-1}{2\sigma_{2,j}^{2}}[\phi_{2,j}-(w_{2}\phi_{1,j}+d_{3,j})]^{2}}d\phi_{2,j}.\]

Denote \(\bar{c}_{2,j}=c_{2,j}\) and \(\bar{d}_{2,j}=d_{2,j}\), and because of \(\sigma_{3,j}=\sigma_{2,j}\), we have

\[q(\phi_{m,j},\phi_{m-1,j},\ldots,\phi_{3,j}|\phi_{1,j})\] \[= \frac{1}{\sqrt{2\pi}\sigma_{2,j}}\cdot\prod_{i=4}^{m}\frac{1}{ \sqrt{2\pi}\sigma_{i,j}}\cdot e^{\frac{-1}{2\sigma_{i,j}^{2}}(\phi_{i,j}-\mu_{ i,j})^{2}}\cdot\frac{1}{\sqrt{2\pi}\sigma_{3,j}}\int e^{\frac{-1}{2\sigma_{3,j} ^{2}}[\phi_{3,j}-(c_{3,j}\phi_{2,j}+d_{3,j})]^{2}}.\] \[e^{\frac{-1}{2\sigma_{3,j}^{2}}[\phi_{2,j}-(\bar{c}_{2,j}\phi_{1,j}+\bar{d}_{2,j})]^{2}}d\phi_{2,j}\] \[= \frac{1}{\sqrt{2\pi}\sigma_{2,j}}\cdot\prod_{i=4}^{m}\frac{1}{ \sqrt{2\pi}\sigma_{i,j}}\cdot e^{\frac{-1}{2\sigma_{i,j}^{2}}(\phi_{i,j}-\mu_{ i,j})^{2}}\cdot\frac{1}{\sqrt{2\pi}\sigma_{3,j}}\int.\] \[e^{\frac{-1}{2\sigma_{3,j}^{2}}\left\{\left[\phi_{3,j}-(c_{3,j} \phi_{2,j}+d_{3,j})\right]^{2}+\left[\phi_{2,j}-(\bar{c}_{2,j}\phi_{1,j}+\bar{ d}_{2,j})\right]^{2}\right\}}\] \[e^{\frac{-1}{2\sigma_{3,j}^{2}}\left\{\left[\phi_{3,j}-(c_{3,j} \phi_{2,j}+d_{3,j})\right]^{2}+\left[\phi_{2,j}-(\bar{c}_{2,j}\phi_{1,j}+\bar {d}_{2,j})\right]^{2}\right\}}d\phi_{2,j}.\]

For \(S_{1}\), we have

\[S_{1}= \left[\phi_{3,j}-(c_{3,j}\phi_{2,j}+d_{3,j})\right]^{2}+\left[ \phi_{2,j}-(\bar{c}_{2,j}\phi_{1,j}+\bar{d}_{2,j})\right]^{2}\] \[= \phi_{3,j}^{2}+c_{3,j}^{2}\phi_{2,j}^{2}+d_{3,j}^{2}+2d_{3,j}c_{3,j}\phi_{2,j}-2c_{3,j}\phi_{3,j}\phi_{2,j}-2d_{3,j}\phi_{3,j}+\phi_{2,j}^{2}\] \[+\bar{c}_{2,j}^{2}\phi_{1,j}^{2}+\bar{d}_{2,j}^{2}+2\bar{d}_{2,j} \bar{c}_{2,j}\phi_{1,j}-2\bar{c}_{2,j}\phi_{1,j}-2d_{3,j}\phi_{3,j}\] \[= (c_{3,j}^{2}+1)\cdot\left(\phi_{2,j}-\frac{c_{3,j}\phi_{3,j}+\bar {c}_{2,j}\phi_{1,j}+\bar{d}_{2,j}-d_{3,j}c_{3,j}}{c_{3,j}^{2}+1}\right)^{2}\] \[+\frac{c_{3,j}^{2}\phi_{3,j}^{2}+\bar{c}_{2,j}^{2}c_{3,j}^{2}\phi _{1,j}^{2}+\bar{d}_{2,j}^{2}c_{3,j}^{2}+2d_{3,j}\bar{c}_{2,j}c_{3,j}\phi_{1,j}- \bar{c}_{2,j}^{2}\phi_{1,j}^{2}-\bar{d}_{2,j}\bar{c}_{2,j}\phi_{1,j}}{c_{3,j} ^{2}+1}\] \[+\frac{\phi_{3,j}^{2}+\bar{c}_{2,j}^{2}\phi_{1,j}^{2}+\bar{d}_{2, j}^{2}+2\bar{d}_{2,j}\bar{c}_{2,j}\phi_{1,j}-2d_{3,j}\phi_{3,j}-c_{3,j}^{2}d_{3,j}^{2}-c_{3,j}^{2} \phi_{3,j}^{2}+2c_{3,j}^{2}d_{3,j}\phi_{3,j}}{c_{3,j}^{2}+1}\] \[+\frac{2c_{3,j}\bar{d}_{2,j}d_{3,j}-2c_{3,j}\phi_{3,j}\bar{c}_{2, j}\phi_{1,j}-2c_{3,j}\phi_{3,j}\bar{d}_{2,j}+2\bar{d}_{2,j}\bar{c}_{2,j}c_{3,j}^{2} \phi_{1,j}-2d_{3,j}c_{3,j}^{2}\phi_{3,j}}{c_{3,j}^{2}+1}.\]Then we have

\[S_{1}= (c_{3,j}^{2}+1)\cdot\left(\phi_{2,j}-\frac{c_{3,j}\phi_{3,j}+\bar{c} _{2,j}\phi_{1,j}+\bar{d}_{2,j}-d_{3,j}c_{3,j}}{c_{3,j}^{2}+1}\right)^{2}\] \[+\frac{\phi_{3,j}^{2}-2(\bar{c}_{2,j}c_{3,j}\phi_{1,j}+\bar{d}_{2, j}c_{3,j}+d_{3,j})\phi_{3,j}}{c_{3,j}^{2}+1}\] \[+\frac{\big{(}\bar{c}_{2,j}c_{3,j}\phi_{1,j}+\bar{d}_{2,j}c_{3,j}+ d_{3,j}\big{)}^{2}-d_{3,j}^{2}\cdot(c_{3,j}^{2}+1)}{c_{3,j}^{2}+1}\] \[= (c_{3,j}^{2}+1)\cdot\left(\phi_{2,j}-\frac{c_{3,j}\phi_{3,j}+\bar {c}_{2,j}\phi_{1,j}+\bar{d}_{2,j}-d_{3,j}c_{3,j}}{c_{3,j}^{2}+1}\right)^{2}\] \[+\frac{1}{c_{3,j}^{2}+1}\cdot\big{[}\phi_{3,j}-(c_{3,j}\bar{c}_{2,j}\phi_{1,j}+\bar{d}_{2,j}c_{3,j}+d_{3,j})\big{]}^{2}-d_{3,j}^{2}.\]

Therefore we have

\[q(\phi_{m,j},\phi_{m-1,j},\ldots,\phi_{3,j}|\phi_{1,j})\] \[= \frac{1}{\sqrt{2\pi}\sigma_{2,j}}\cdot\prod_{i=4}^{m}\frac{1}{ \sqrt{2\pi}\sigma_{i,j}}\cdot e^{\frac{-1}{2\sigma_{i,j}^{2}}(\phi_{i,j}-\mu_{i,j})^{2}}.\] \[\underbrace{\left[\int\frac{\sqrt{c_{3,j}^{2}+1}}{\sqrt{2\pi} \sigma_{3,j}}e^{\frac{-(c_{3,j}^{2}+1)}{2\sigma_{3,j}^{2}}\big{(}\phi_{2,j}- \frac{c_{3,j}\phi_{3,j}+c_{2,j}\phi_{1,j}+\bar{d}_{2,j}-d_{3,j}c_{3,j}}{c_{3,j }^{2}+1}\big{)}^{2}}\ d\phi_{2,j}\right]}_{S_{2}}\cdot\] \[e^{\frac{-1}{2\sigma_{3,j}^{2}(c_{3,j}^{2}+1)}\big{[}\phi_{3,j}- (c_{3,j}\bar{c}_{2,j}\phi_{1,j}+\bar{d}_{2,j}c_{3,j}+d_{3,j})\big{]}^{2}} \cdot e^{\frac{d_{3,j}^{2}}{2\sigma_{3,j}^{2}}}\cdot\frac{1}{\sqrt{c_{3,j}^{2 }+1}}\]

The \(S_{2}\) part is the integration form of \(\phi_{2,j}\sim\mathcal{N}(\frac{c_{3,j}\phi_{3,j}+\bar{c}_{2,j}\phi_{1,j}+\bar {d}_{2,j}-d_{3,j}c_{3,j}}{c_{3,j}^{2}+1})\), which is equal to \(1\), so we have

\[q(\phi_{m,j},\phi_{m-1,j},\ldots,\phi_{3,j}|\phi_{1,j})\] \[= \frac{1}{\sqrt{2\pi}\sigma_{2,j}}\cdot\prod_{i=4}^{m}\frac{1}{ \sqrt{2\pi}\sigma_{i,j}}\cdot e^{\frac{-1}{2\sigma_{i,j}^{2}}(\phi_{i,j}-\mu_{ i,j})^{2}}\cdot e^{\frac{-1}{2\sigma_{3,j}^{2}(c_{3,j}^{2}+1)}\big{[}\phi_{3,j}-(c_{3,j} \bar{c}_{2,j}\phi_{1,j}+\bar{d}_{2,j}c_{3,j}+d_{3,j})\big{]}^{2}}.\] \[e^{\frac{d_{3,j}^{2}}{2\sigma_{3,j}^{2}}}\cdot\frac{1}{\sqrt{c_{3,j}^{2}+1}}.\]

We denote \(\bar{c}_{3,j}=c_{3,j}\bar{c}_{2,j}\) and \(\bar{d}_{3,j}=\bar{d}_{2,j}c_{3,j}+d_{3,j}\), and denote \(r_{2,j}=e^{\frac{d_{3,j}^{2}}{2\sigma_{3,j}^{2}}}\cdot\frac{1}{\sqrt{c_{3,j}^{ 2}+1}}\), so we have

\[q(\phi_{m,j},\phi_{m-1,j},\ldots,\phi_{3,j}|\phi_{1,j})\] \[= \frac{1}{\sqrt{2\pi}\sigma_{2,j}}\cdot\prod_{i=4}^{m}\frac{1}{ \sqrt{2\pi}\sigma_{i,j}}\cdot e^{\frac{-1}{2\sigma_{i,j}^{2}}(\phi_{i,j}-\mu_{ i,j})^{2}}\cdot e^{\frac{-1}{2\sigma_{3,j}^{2}(c_{3,j}^{2}+1)}\big{[}\phi_{3,j}-( \bar{c}_{3,j}\phi_{1,j}+\bar{d}_{3,j})\big{]}^{2}}\cdot r_{2,j}\] \[= \frac{1}{\sqrt{2\pi}\sigma_{2,j}}\cdot\prod_{i=5}^{m}\frac{1}{ \sqrt{2\pi}\sigma_{i,j}}\cdot e^{\frac{-1}{2\sigma_{i,j}^{2}}(\phi_{i,j}-\mu_{ i,j})^{2}}\cdot\frac{1}{\sqrt{2\pi}\sigma_{4}}\cdot e^{\frac{-1}{2\sigma_{4}^{2}} \big{[}\phi_{4}-(c_{4}\phi_{3,j}+d_{4})\big{]}^{2}}.\] \[e^{\frac{-1}{2\sigma_{3,j}^{2}(c_{3,j}^{2}+1)}\big{[}\phi_{3,j}-( \bar{c}_{3,j}\phi_{1,j}+\bar{d}_{3,j})\big{]}^{2}}\cdot r_{2,j}\] \[= \frac{1}{\sqrt{2\pi}\sigma_{2,j}}\cdot\prod_{i=5}^{m}\frac{1}{ \sqrt{2\pi}\sigma_{i,j}}\cdot e^{\frac{-1}{2\sigma_{i,j}^{2}}(\phi_{i,j}-\mu_{ i,j})^{2}}\cdot\frac{1}{\sqrt{2\pi}\sigma_{4}}\cdot e^{\frac{-1}{2\sigma_{4}^{2}} \big{[}\phi_{4}-(c_{4}\phi_{3,j}+d_{4})\big{]}^{2}}.\] \[e^{\frac{-1}{2\sigma_{4}^{2}}\big{[}\phi_{3,j}-(\bar{c}_{3,j}\phi_ {1,j}+\bar{d}_{3,j})\big{]}^{2}}\cdot r_{2,j}\]Similarly, then we integrate \(\phi_{3,j}\)

\[q(\phi_{m,j},\phi_{m-1,j},\ldots,\phi_{4}|\phi_{1,j})\] \[= \int q(\phi_{m,j},\phi_{m-1,j},\ldots,\phi_{3,j}|\phi_{1,j})\,d \phi_{3,j}\] \[= \frac{r_{2,j}}{\sqrt{2\pi}\sigma_{2,j}}\cdot\prod_{i=5}^{m}\frac{ 1}{\sqrt{2\pi}\sigma_{i,j}}\cdot e^{\frac{-1}{2\sigma_{i,j}^{2}}(\phi_{i,j}- \mu_{i,j})^{2}}\cdot\int\frac{1}{\sqrt{2\pi}\sigma_{4}}\cdot e^{\frac{-1}{2 \sigma_{4}^{2}}[\phi_{4}-(c_{4}\phi_{3,j}+d_{4})]^{2}}.\] \[e^{\frac{-1}{2\sigma_{4}^{2}}[\phi_{3,j}-(\bar{c}_{3,j}\phi_{1,j} +\bar{d}_{3,j})]^{2}}\,d\phi_{2,j}.\]

The formulation is similar to the previous one, so we can utilize the process above to integrate succesively, and we finally obtain

\[q(\phi_{m,j}|\phi_{1,j})=\frac{\prod_{i=2}^{m-1}r_{i,j}}{\sqrt{2\pi}\sigma_{2,j}}\cdot e^{\frac{-1}{2\sigma_{m,j}^{2}(c_{m,j}^{2}+1)}[\phi_{m,j}-(\bar{c}_{ m,j}\phi_{1,j}+\bar{d}_{m,j})]^{2}},\]

which indicates

\[p(\phi_{m,j}|\phi_{1,j},D)\approx\frac{\prod_{i=2}^{m-1}r_{i,j}}{\sqrt{2\pi} \sigma_{2,j}}\cdot e^{\frac{-1}{2\sigma_{m,j}^{2}(c_{m,j}^{2}+1)}[\phi_{m,j}- (\bar{c}_{m}\phi_{1,j}+\bar{d}_{m,j})]^{2}},\]

where we have the iterative calculation by

\[r_{i,j}=e^{\frac{d_{i+1,j}^{2}}{2\sigma_{i+1,j}^{2}}}\cdot\frac{1}{\sqrt{c_{i+ 1,j}^{2}+1}},\]

\[\bar{c}_{i,j}=c_{i,j}\bar{c}_{i-1,j},\ (i\geq 3),\]

\[\bar{d}_{i,j}=\bar{d}_{i-1,j}c_{i,j}+d_{i,j},\ (i\geq 3).\]

### Sampling from \(p(\boldsymbol{\phi}_{m}|\boldsymbol{\phi}_{M},D)\)

To sample from the distribution \(p(\boldsymbol{\phi}_{m}|\boldsymbol{\phi}_{M},D)\), we first obtain a sample \(\boldsymbol{\phi}_{1}\) from the prior distribution (_i.e.,_\(\boldsymbol{\phi}_{1}\sim\mathcal{N}(\boldsymbol{0},\boldsymbol{I})\)), then get \(\boldsymbol{\phi}_{m}\) from a consecutive sampling process:

\[\boldsymbol{\phi}_{M-1}\sim p(\boldsymbol{\phi}_{M-1}|\boldsymbol{\phi}_{M}, \boldsymbol{\phi}_{1},D),\]

\[\boldsymbol{\phi}_{M-2}\sim p(\boldsymbol{\phi}_{M-2}|\boldsymbol{\phi}_{M-1},\boldsymbol{\phi}_{1},D),\]

\[\vdots\]

\[\boldsymbol{\phi}_{m}\sim p(\boldsymbol{\phi}_{m}|\boldsymbol{\phi}_{m+1}, \boldsymbol{\phi}_{1},D),\]

because of the Markov property in our cascaded model. So our target is obtaining the distributions \(p(\boldsymbol{\phi}_{i-1}|\boldsymbol{\phi}_{i},\boldsymbol{\phi}_{1},D)\). For a certain \(p(\boldsymbol{\phi}_{i-1}|\boldsymbol{\phi}_{i},\boldsymbol{\phi}_{1},D)\), according to the Bayes rule, we have

\[p(\boldsymbol{\phi}_{i-1}|\boldsymbol{\phi}_{i},\boldsymbol{\phi}_{1},D)= \frac{p(\boldsymbol{\phi}_{i}|\boldsymbol{\phi}_{i-1},\boldsymbol{ \phi}_{1},D)\cdot p(\boldsymbol{\phi}_{i-1}|\boldsymbol{\phi}_{1},D)}{p( \boldsymbol{\phi}_{i}|\boldsymbol{\phi}_{1},D)}.\]

Similarly with the last section, we use non-bold symbols to represent one dimension of the multi-dimension parameters, where they are able to transfer independently, and finally construct the eventual parameters by concatenating, that is,

\[p(\boldsymbol{\phi}_{i-1}|\boldsymbol{\phi}_{i},\boldsymbol{\phi}_{1},D)=\prod _{j=1}^{d}p(\phi_{i,j}|\phi_{i-1,j},\phi_{1,j},D).\]

So our target can be converted to calculate the probability \(p(\phi_{i,j}|\phi_{i-1,j},\phi_{1,j},D)\) for all dimensions \(\forall 1\leq j\leq d\). According to the Markov property and the transportation probability, we have

\[p(\phi_{i,j}|\phi_{i-1,j},\phi_{1,j},D) \approx q(\phi_{i,j}|\phi_{i-1,j},\phi_{1,j})\] \[=\frac{1}{\sqrt{2\pi}\sigma_{i,j}}\cdot e^{\frac{-1}{2\sigma_{i,j }^{2}}[\phi_{i,j}-(c_{i}\phi_{i-1,j}+d_{i,j})]^{2}}.\]According to the previous section, we have

\[p(\phi_{i,j}|\phi_{1,j},D) \approx q(\phi_{i,j}|\phi_{1,j})=\frac{\prod_{i=2}^{i-1}r_{i,j}}{ \sqrt{2\pi}\sigma_{2,j}}\cdot e^{\frac{-1}{2\sigma_{i,j}^{2}(c_{i,j}^{2}+1)} \left[\phi_{i,j}-(\bar{c}_{i}\phi_{1,j}+\bar{d}_{i,1})\right]^{2}},\] \[p(\phi_{i-1,j}|\phi_{1,j},D) \approx q(\phi_{i-1,j}|\phi_{1,j})=\frac{\prod_{i=2}^{i-2}r_{i,j}}{ \sqrt{2\pi}\sigma_{2,j}}\cdot e^{\frac{-1}{2\sigma_{i-1,j}^{2}(c_{i-1,j}^{2}+1) }\left[\phi_{i-1,j}-(\bar{c}_{i-1,j}\phi_{1,j}+\bar{d}_{i-1,j})\right]^{2}}.\]

Then we have

\[p(\phi_{i-1,j}|\phi_{i,j},\phi_{1,j},D)\approx\frac{q(\phi_{i,j}| \phi_{i-1,j},\phi_{1,j})\cdot q(\phi_{i-1,j}|\phi_{1,j})}{q(\phi_{i,j}|\phi_{1,j})}\] \[= \frac{1}{\sqrt{2\pi}\sigma_{i,j}\cdot r_{i-1}}\cdot e^{\frac{-1} {2\sigma_{i,j}^{2}}\cdot[\phi_{i,j}-(c_{i,j}\phi_{i-1,j}+d_{i,j})]^{2}}\cdot \frac{e^{\frac{[\phi_{i-1,j}-(c_{i-1,j}\phi_{1,j}+d_{i-1,j})]^{2}}{-2\sigma_{ i-1,j}^{2}(c_{i-1,j}^{2}+1)}}}{\frac{[\phi_{i,j}-(c_{i,j}\phi_{i-1,j}+d_{i,j})]^{2}} {-2\sigma_{i,j}^{2}(c_{i,j}^{2}+1)}}\] \[= \sqrt{\frac{c_{i,j}+1}{2\pi\sigma_{i,j}^{2}}}\cdot e^{\frac{2 \sigma_{i,j}^{2}}{d_{i,j}^{2}}\cdot e^{\frac{[\phi_{i,j}-(c_{i,j}\phi_{i-1,j}+d _{i,j})]^{2}}{2\sigma_{i+1,j}^{2}}}}\cdot e^{\frac{[\phi_{i,j}-(c_{i,j}\phi_{i- 1,j}+d_{i,j})]^{2}}{-2\sigma_{i,j}^{2}}}\cdot e^{\frac{[\phi_{i-1,j}-(c_{i-1,j }\phi_{1,j}+d_{i-1,j})]^{2}}{-2\sigma_{i,j}^{2}}}\] \[= \sqrt{\frac{c_{i,j}+1}{2\pi\sigma_{i,j}^{2}}}\cdot e^{\frac{2 \sigma_{i,j}^{2}}{d_{i,j}^{2}}\cdot\frac{[\phi_{i,j}-(c_{i,j}\phi_{i-1,j}+d_{i,j})]^{2}}{2\sigma_{i+1,j}^{2}}}.\] \[\frac{-1}{-2\sigma_{i,j}^{2}}\underbrace{\left\{\phi_{i,j}-(c_{i, j}\phi_{i-1,j}+d_{i,j})\right\}^{2}+\left[\phi_{i-1,j}-(\bar{c}_{i-1,j}\phi_{1,j}+ \bar{d}_{i-1,j})\right]^{2}\right\}_{C}\] \[e^{\frac{1}{2\sigma_{i,j}^{2}}\cdot\left\{\phi_{i,j}-(c_{i,j} \phi_{i-1,j}+d_{i,j})\right\}^{2}+\left[\phi_{i-1,j}-(\bar{c}_{i-1,j}\phi_{1,j }+\bar{d}_{i-1,j})\right]^{2}\right\}}\]

Then we calculate the part \(C\) as

\[C =\left[\phi_{i,j}-(c_{i,j}\phi_{i-1,j}+d_{i,j})\right]^{2}+\left[ \phi_{i-1,j}-(\bar{c}_{i-1,j}\phi_{1,j}+\bar{d}_{i-1,j})\right]^{2}\] \[=\phi_{i,j}^{2}+(c_{i,j}\phi_{i-1,j}+d_{i,j})^{2}-2(c_{i,j}\phi_{ i-1,j}+d_{i,j})\phi_{i,j}\] \[+\phi_{i-1,j}^{2}+(\bar{w}_{i-1}\phi_{1,j}+\bar{d}_{i-1,j})^{2}-2 \phi_{i-1,j}(\bar{c}_{i-1,j}\phi+\bar{d}_{i-1,j})\] \[=\phi_{i,j}^{2}+c_{i,j}^{2}\phi_{i-1,j}^{2}+d_{i,j}^{2}+2d_{i,j}c _{i,j}\phi_{i-1,j}-2c_{i,j}\phi_{i-1,j}\phi_{i,j}-2d_{i,j}\phi_{i,j}+\phi_{i-1, j}^{2}\] \[+\bar{c}_{i-1,j}^{2}\phi_{1,j}^{2}+\bar{d}_{i-1,j}^{2}+2\bar{c}_{ i-1,j}\bar{d}_{i-1,j}\phi_{1,j}-2\bar{c}_{i-1,j}\phi_{1,j}\phi_{i-1,j}-2\bar{d}_{i-1,j} \phi_{i-1,j}\] \[=(\bar{w}_{i-1}^{2}+1)\cdot\left[\phi_{i-1,j}-\frac{c_{i,j}\phi_{ i,j}+\bar{c}_{i-1,j}\phi_{1,j}+\bar{d}_{i-1,j}-d_{i,j}c_{i,j}}{c_{i,j}^{2}+1} \right]^{2}+B,\]

where \(B\) does not include \(\phi_{i}\), which indicates

\[p(\phi_{i-1,j}|\phi_{i,j},\phi_{1,j},D)\sim\mathcal{N}(\frac{c_{i,j}\phi_{i,j}+ \bar{c}_{i-1,j}\phi_{1,j}+\bar{d}_{i-1,j}-d_{i,j}w_{i-2}}{c_{i,j}^{2}+1},\frac{ \sigma_{i,j}^{2}}{c_{i,j}^{2}+1}).\]

### Calculation of \(p(\bm{x}|\bm{e},\bm{\phi}_{m})\)

In this section, we will show how to calculate the graph probability \(p(\bm{x}|\bm{e},\bm{\phi}_{m})\). Remember the graph parameters \(\bm{\phi}_{m}=[\bm{\theta}_{m};\mathbf{S}_{m};\mathbf{T}_{m}]\), so we have

\[p(\bm{x}|\bm{e},\bm{\phi}_{m}) =\int_{\mathbf{E}}p(\bm{x}|\bm{e},\bm{\theta}_{m},\mathbf{E}) \cdot p(\mathbf{E}|\bm{e},\bm{S}_{m},\bm{T}_{m})\;d\mathbf{E}\] \[=\mathbb{E}_{\mathbf{E}\sim p(\mathbf{E}|\bm{S}_{m},\bm{T}_{m})} \left[p(\bm{x}|\bm{e},\bm{\theta}_{m},\mathbf{E})\right].\]

According to Monte Carlo sampling, we have

\[p(\bm{x}|\bm{e},\bm{\phi}_{m})=\frac{1}{K}\cdot\sum_{l=1}^{K}p(\bm{x}|\bm{e},\bm{ \theta}_{m},\mathbf{E}_{l}),\]

where \(\mathbf{E}_{l}[i,j]\sim\text{Bernoulli}(\sigma(\mathbf{S}_{m}^{T}[i]\cdot \mathbf{T}_{m}[j]))\). In order to conduct intervention process, we change the \(j\)th column of \(\mathbf{E}_{l}\) to zeros, and represent it with \(\tilde{\mathbf{E}}_{l}\). Moreover, we replace the \(j\)th element of with \(v\), and get the result \(\tilde{\bm{x}}\). We change the \(j\)th element of \(\bm{\epsilon}_{m}\) with zero, and get the result \(\tilde{\bm{\epsilon}}_{m}\). Then according the definition of causal graphs, we have

\[p(\bm{x}|\bm{e},\bm{\phi}_{m})=\frac{1}{K}\sum_{l=1}^{K}\mathcal{N}(\bm{x};\bm{ f}(\tilde{\bm{x}};\tilde{\mathbf{E}}_{l},\bm{\gamma}_{m}),\tilde{\bm{\epsilon}}_{ m}),\]

where \(\bm{f}\) is the causal function that depends on the parameter \(\bm{\gamma}_{m}\).

## Appendix B Bayesian Optimization for Determining \((j^{*},v^{*},m^{*})\)

We intend to find the best tuple for acquisition, that is,

\[(j^{*},v^{*},m^{*})=\operatorname*{arg\,max}_{(j,v,m)}f(j,v,m).\]

We define the best interventional value \(v\) under interventional node \(j\) and fidelity \(m\) as

\[v^{*}(j,m) =\operatorname*{arg\,max}_{v}f(j,v,m)\] \[=\operatorname*{arg\,max}_{v}f_{j,m}(v).\]

where \(f_{j,m}(v)\) is rewritten from \(f(j,v,m)\) under given \(j,m\). Therefore, our task is calculating \(v^{*}(j,m)\) for \(\forall j\in[d],m\in[M]\) with Bayesian optimization [47]. We utilize a Gaussian Process (GP) [48] to model surrogate function distributions for each \(v^{*}(j,m)\). We denote \(f\sim\mathcal{GP}(\bm{0},\mathcal{K}(v_{i},v_{j}))\), and \(\mathcal{K}(v_{i},v_{j})\) is the kernel of GP. We sequentially find \(v_{t}\) and calculate \(f_{j,m}(v_{t})\) to direct the process. According to GP, the previous \(t\) functions and the \(t+1\) function are multivariate Gaussian distribution,

\[\begin{bmatrix}\bm{F}_{1:t}\\ f_{t+1}\end{bmatrix}\sim\mathcal{N}\left(\bm{0},\begin{bmatrix}\bm{K}_{t}&\bm {k}_{t+1}\\ \bm{k}_{t+1}^{T}&\mathcal{K}(v_{t+1},v_{t+1})\end{bmatrix}\right),\]

where we define

\[\bm{F}_{1:t}=\left[f_{1},f_{2},\dots,f_{t}\right],\] \[\bm{k}_{t+1}=\left[\mathcal{K}(v_{t+1},v_{1}),\mathcal{K}(v_{t+1 },v_{2}),\dots,\mathcal{K}(v_{t+1},v_{t+1})\right]^{T},\] \[\bm{K}_{t}=\begin{bmatrix}\mathcal{K}(v_{1},v_{1})&\cdots& \mathcal{K}(v_{t},v_{1})\\ \vdots&\ddots&\vdots\\ \mathcal{K}(v_{t},v_{1})&\cdots&\mathcal{K}(v_{t},v_{t})\end{bmatrix}.\] (11)

Given previous \(t\) steps, we have the posterior probability is

\[p(f_{t+1}|\{(v_{i},f_{j,m}(v_{i}))\}_{i=1}^{t},v_{t+1})=\mathcal{N}(\mu_{t}(v_ {t+1}),\sigma_{t}^{2}(v_{t+1})),\]

with the non-parametric means and variances

\[\mu_{t}(v_{t+1})=\bm{k}_{t+1}^{T}(\bm{K}+\bm{I})^{-1}\bm{F}_{1:t},\] (12) \[\sigma_{t}^{2}(v_{t+1})=\mathcal{K}(v_{v+1},v_{t+1})-\bm{k}_{t+1} ^{T}(\bm{K}+\bm{I})^{-1}\bm{k}_{t+1}.\] (13)

We acquire the next \(v_{t+1}\) with GP-UCB [49] function

\[a_{t+1}(v)=\mu_{t}(v)+\beta_{ac}\cdot\sqrt{\sigma_{t}^{2}(v)},\] \[v_{t+1}=\operatorname*{arg\,max}_{v}a_{t+1}(v).\]

where \(\beta_{ac}\) is a hyper-parameter. Suppose the maximum of steps is \(T\), the final output of function \(v^{*}(j,m)\) is

\[v^{*}(j,m)=\operatorname*{arg\,max}_{v}\mu_{T}(v).\]

Then we choose the best interventional node \(j\) and fidelity \(m\) by their best values under \(\mathcal{O}(d\cdot M)\)

\[j^{*},m^{*}=\operatorname*{arg\,max}_{j,m}v^{*}(j,m),\] \[v^{*}=v^{*}(j^{*},m^{*}).\]Detailed Training Process of ELBO

### Derivation Process of ELBO

Because we use the distribution \(q(\bm{\phi}_{m})\) to approximate the distribution \(p(\bm{\phi}_{m})\), then we intend to minimize the distance between these two distributions optimize the parameters of \(q(\bm{\phi}_{m})\), where we utilize KL divergence to measure the distance, that is,

\[\Psi^{*}=\operatorname*{arg\,min}_{\Psi}\text{KL}[q(\bm{\Phi}||p(\bm{\Phi}|D)].\]

According to the variational inference, we have

\[\text{KL}\left[q(\bm{\Phi})||p(\bm{\Phi}|D)\right]\] \[=\int q(\bm{\Phi})\log\frac{q(\bm{\Phi})}{p(\bm{\Phi}|D)}\ d\bm{\Phi}\] \[=\int q(\bm{\Phi})\log q(\bm{\Phi})\ d\bm{\Phi}-\int q(\bm{\Phi}) \log p(\bm{\Phi}|D)\ d\bm{\Phi}\] \[=\mathbb{E}_{\bm{\Phi}\sim q(\bm{\Phi})}\left[\log q(\bm{\Phi}) \right]-\int q(\bm{\Phi})\log\frac{p(\bm{\Phi},D)}{p(D)}\ d\bm{\Phi}\] \[=\mathbb{E}_{\bm{\Phi}\sim q(\bm{\Phi})}\left[\log q(\bm{\Phi}) \right]-\int q(\bm{\Phi})\log p(\bm{\Phi},D)\ d\bm{\Phi}+\int q(\bm{\Phi})\log p (D)\ d\bm{\Phi}\] \[=\underbrace{\mathbb{E}_{\bm{\Phi}\sim q(\bm{\Phi})}\left[\log q (\bm{\Phi})\right]-\mathbb{E}_{\bm{\Phi}\sim q(\bm{\Phi})}\left[\log p(\bm{ \Phi},D)\right]}_{\text{-ELBO}}+\log p(D).\]

Because \(\log p(D)\) is not related to \(\Psi\), minimizing \(\text{KL}\left[q(\bm{\Phi})||p(\bm{\Phi}|D)\right]\) is equivalent to maximizing the ELBO part, and we have

\[\text{ELBO} =\mathbb{E}_{\bm{\Phi}\sim q(\bm{\Phi})}\left[\log p(\bm{\Phi},D )\right]-\mathbb{E}_{\bm{\Phi}\sim q(\bm{\Phi})}\left[\log q(\bm{\Phi})\right]\] \[=\mathbb{E}_{\bm{\Phi}\sim q(\bm{\Phi})}\left[\log p(D|\bm{\Phi} )\right]+\mathbb{E}_{\bm{\Phi}\sim q(\bm{\Phi})}\left[\log p(\bm{\Phi})\right] -\mathbb{E}_{\bm{\Phi}\sim q(\bm{\Phi})}\left[\log q(\bm{\Phi})\right]\] \[=\mathbb{E}_{\bm{\Phi}\sim q(\bm{\Phi})}\left[\log p(D|\bm{\Phi} )-\log q(\bm{\Phi})+\log p(\bm{\Phi})\right]\]

Above all, we can conclude that

\[\Psi^{*}=\operatorname*{arg\,min}_{\Psi}\text{KL}[q(\bm{\Phi}||p(\bm{\Phi}|D)]\]

is equivalent to maximize evidence lower bound

\[\Psi^{*} =\operatorname*{arg\,max}_{\Psi}\text{ELBO}\] \[=\operatorname*{arg\,max}_{\Psi}\mathbb{E}_{\bm{\Phi}\sim q(\bm{ \Phi})}\left[\log p(D|\bm{\Phi})-\log q(\bm{\Phi})+\log p(\bm{\Phi})\right].\]

### Estimation of ELBO

We represent the equation of ELBO as

\[\text{ELBO} =\underbrace{\mathbb{E}_{\bm{\Phi}\sim q(\bm{\Phi})}\left[\log p (D|\bm{\Phi})\right]}_{A}-\underbrace{\mathbb{E}_{\bm{\Phi}\sim q(\bm{\Phi})} \left[\log q(\bm{\Phi})-\log p(\bm{\Phi})\right]}_{B}.\]

For the part \(A\), we have

\[A=\mathbb{E}_{\bm{\Phi}\sim q(\bm{\Phi})}\left[\log\prod_{i=1}^{N}p(\bm{x}^{( i)}|j^{(i)},v^{(i)},m^{(i)},\bm{\Phi})\right],\]where \(N\) is the current number of samples in buffer. Then we have

\[A= \mathbb{E}_{\bm{\Phi}\sim q(\bm{\Phi})}\left[\log\prod_{i=1}^{N}p(\bm {x}^{(i)}|j^{(i)},v^{(i)},m^{(i)},\bm{\Phi})\right]\] \[= \mathbb{E}_{\bm{\Phi}\sim q(\bm{\Phi})}\left[\sum_{i=1}^{N}\log p( \bm{x}^{(i)}|j^{(i)},v^{(i)},m^{(i)},\bm{\Phi})\right]\] \[= \sum_{i=1}^{N}\mathbb{E}_{\bm{\Phi}\sim q(\bm{\Phi})}\left[\log p( \bm{x}^{(i)}|j^{(i)},v^{(i)},m^{(i)},\bm{\Phi})\right]\] \[= \sum_{i=1}^{N}\mathbb{E}_{\bm{\phi}_{m^{(i)}}\sim q(\bm{\phi}_{m^ {(i)}})}\left[\log p(\bm{x}^{(i)}|j^{(i)},v^{(i)},m^{(i)},\bm{\phi}_{m^{(i)}}) \right].\]

Using Monte Carlo sampling [50], we can calculate the expectation by \(N_{S}\) samples for each point.

\[A= \sum_{i=1}^{N}\sum_{j=1}^{N_{S}}\log p(\bm{x}^{(i)}|j^{(i)},v^{(i)},m^{(i)},\bm{\phi}_{m^{(i)}}^{(j)}),\]

where we sample \(\bm{\phi}_{m^{(i)}}^{(j)}\sim q(\bm{\phi}_{m^{(i)}})\) with size \(N_{S}\).

Then we denote the distribution \(q(\bm{\Phi})=\mathcal{N}(\tilde{\bm{\mu}}_{all},\tilde{\bm{\Sigma}}_{all})\), and similarly, we have \(p(\bm{\Phi})=\prod_{m=1}^{M}e^{-\beta\cdot f(\mathbf{S}_{m},\mathbf{T}_{m})} \cdot\mathcal{N}(\bm{\mu}_{all},\bm{\Sigma}_{all})\). Both the parameter \(\tilde{\bm{\mu}}_{all},\tilde{\bm{\Sigma}}_{all}\) can be represented by the parameters in \(\Psi\), while \(\bm{\mu}_{all}\) and \(\bm{\Sigma}_{all}\) are constant. Then we calculate part \(B\)

\[B= \mathbb{E}_{\bm{\Phi}\sim q(\bm{\Phi})}\left[\log q(\bm{\Phi})- \log p(\bm{\Phi})\right]\] \[= \int_{\bm{\Phi}}\mathcal{N}(\tilde{\bm{\mu}}_{all},\tilde{\bm{ \Sigma}}_{all})\log\frac{\mathcal{N}(\tilde{\bm{\mu}}_{all},\tilde{\bm{\Sigma}} _{all})}{\prod_{m=1}^{M}e^{-\beta\cdot f(\mathbf{S}_{m},\mathbf{T}_{m})}\cdot \mathcal{N}(\bm{\mu}_{all},\bm{\Sigma}_{all})}\ d\bm{\Phi}\] \[= \int_{\bm{\Phi}}\mathcal{N}(\tilde{\bm{\mu}}_{all},\tilde{\bm{ \Sigma}}_{all})\log\frac{\mathcal{N}(\tilde{\bm{\mu}}_{all},\tilde{\bm{\Sigma}} _{all})}{\mathcal{N}(\bm{\mu}_{all},\bm{\Sigma}_{all})}\ d\bm{\Phi}+\int_{\bm {\Phi}}\mathcal{N}(\tilde{\bm{\mu}}_{all},\tilde{\bm{\Sigma}}_{all})\log\frac{ 1}{\prod_{m=1}^{M}e^{-\beta\cdot f(\mathbf{S}_{m},\mathbf{T}_{m})}}\ d\bm{\Phi}\] \[= \underbrace{\text{KL}[\mathcal{N}(\tilde{\bm{\mu}}_{all},\tilde{ \bm{\Sigma}}_{all})||\mathcal{N}(\bm{\mu}_{all},\bm{\Sigma}_{all})]}_{C}+ \underbrace{\int_{\bm{\Phi}}\mathcal{N}(\tilde{\bm{\mu}}_{all},\tilde{\bm{ \Sigma}}_{all})\log\prod_{m=1}^{M}e^{\beta\cdot f(\mathbf{S}_{m},\mathbf{T}_{ m})}\ d\bm{\Phi}}_{D}.\]

According to KL divergence of Gaussian distribution, we can calculate \(C\) in a close-form.

\[C= \text{KL}[\mathcal{N}(\tilde{\bm{\mu}}_{all},\tilde{\bm{\Sigma}} _{all})||\mathcal{N}(\bm{\mu}_{all},\bm{\Sigma}_{all})]\] \[= \frac{1}{2}\left[\log\frac{||\bm{\Sigma}_{all}||}{||\tilde{\bm{ \Sigma}}_{all}||}-d+\text{tr}(\bm{\Sigma}_{all}^{-1}\tilde{\bm{\Sigma}}_{all})+( \tilde{\bm{\mu}}_{all}-\bm{\mu}_{all})^{T}\bm{\Sigma}_{all}^{-1}(\tilde{\bm{ \mu}}_{all}-\bm{\mu}_{all})\right].\]

Then we calculate \(D\) by the following steps:

\[D =\int_{\bm{\Phi}}\mathcal{N}(\bm{\mu}_{all},\bm{\Sigma}_{all})\log \prod_{m=1}^{M}e^{\beta\cdot f(\mathbf{S}_{m},\mathbf{T}_{m})}\ d\bm{\Phi}\] \[=\int_{\bm{\Phi}}\mathcal{N}(\bm{\mu}_{all},\bm{\Sigma}_{all})\sum _{m=1}^{M}\log e^{\beta\cdot f(\mathbf{S}_{m},\mathbf{T}_{m})}\ d\bm{\Phi}\] \[=\cdot\int_{\bm{\Phi}}\mathcal{N}(\bm{\mu}_{all},\bm{\Sigma}_{all}) \sum_{m=1}^{M}\beta\cdot f(\mathbf{S}_{m},\mathbf{T}_{m})\ d\bm{\Phi}\] \[=\beta\cdot\mathbb{E}_{\bm{\Phi}\sim\mathcal{N}(\bm{\mu}_{all}, \bm{\Sigma}_{all})}\left[\sum_{m=1}^{M}f(\mathbf{S}_{m},\mathbf{T}_{m}) \right].\]Using Monte Carlo sampling, we can calculate the expectation by \(N_{D}\) samples for each point.

\[D =\beta\cdot\sum_{i=1}^{N_{D}}\sum_{m=1}^{M}f(\mathbf{S}_{m}^{(i)}, \mathbf{T}_{m}^{(i)}).\] \[=\beta\cdot\sum_{i=1}^{N_{D}}\sum_{m=1}^{M}\mathbb{E}_{p(\mathbf{ E}|\mathbf{S}_{m}^{(i)},\mathbf{T}_{m}^{(i)})}\left[\lambda_{1}\cdot\left[ \text{tr}\left(e^{\mathbf{E}}\right)-d\right]+\lambda_{2}\cdot||\mathbf{E}|| \right],\]

where we samples \(\mathbf{\Phi}^{(i)}\sim\mathcal{N}(\boldsymbol{\mu}_{all},\boldsymbol{\Sigma} _{all})\) with size \(N_{D}\). Using Monte Carlo sampling again, we can calculate the expectation by \(N_{E}\) samples.

\[D =\beta\cdot\sum_{i=1}^{N_{D}}\sum_{m=1}^{M}\sum_{j=1}^{N_{E}} \left[\lambda_{1}\cdot\left[\text{tr}\left(e^{\mathbf{E}}\right)-d\right]+ \lambda_{2}\cdot||\mathbf{E}||\right],\]

where we samples \(\mathbf{E}^{(j)}\sim p(\mathbf{E}|\mathbf{S}_{m}^{(i)},\mathbf{T}_{m}^{(i)})\) with size \(N_{E}\).

Finally, we obtain the estimation

\[\text{ELBO}= \sum_{i=1}^{N}\sum_{j=1}^{N_{E}}\log p(x^{(i)}|j^{(i)},v^{(i)},m^{ (i)},\boldsymbol{\phi}_{m^{(i)}}^{(j)})\] \[-\frac{1}{2}\left[\log\frac{||\boldsymbol{\Sigma}_{all}||}{|| \tilde{\boldsymbol{\Sigma}}_{all}||}-d+\text{tr}(\boldsymbol{\Sigma}_{all}^{-1 }\tilde{\boldsymbol{\Sigma}}_{all})+(\tilde{\boldsymbol{\mu}}_{all}-\boldsymbol {\mu}_{all})^{T}\boldsymbol{\Sigma}_{all}^{-1}(\tilde{\boldsymbol{\mu}}_{all}- \boldsymbol{\mu}_{all})\right]\] \[-\beta\cdot\sum_{i=1}^{N_{D}}\sum_{m=1}^{M}\sum_{j=1}^{N_{E}} \left[\lambda_{1}\cdot\left[\text{tr}\left(e^{\mathbf{E}}\right)-d\right]+ \lambda_{2}\cdot||\mathbf{E}||\right].\]

### Gaussian Reparameterization Trick

In the last section, we derive the objection function for optimizing the model parameters, where we can use methods of the gradient decent to solve it. However, a significant problem rises due to the sampling process, because the gradient of model parameters can not pass backward from the naive sampling process(_i.e.,_ untraceable). Therefore, we use Gaussian reparameterization trick to make the Gaussian sampling process traceable.

In specific, we will demonstrate the traceable calculation of \(\boldsymbol{\phi}\) by Gaussian reparameterization trick. In order to sample \(\boldsymbol{\phi}\sim\mathcal{N}(\boldsymbol{\mu},\boldsymbol{\Sigma})\), we first sample \(\boldsymbol{\delta}\sim\mathcal{N}(\boldsymbol{0},\mathbf{I})\) instead, and then obtain \(\boldsymbol{\phi}=\boldsymbol{\mu}+\boldsymbol{\delta}\odot\boldsymbol{\Sigma}\). Therefore, the gradient can be traced from \(\boldsymbol{\phi}\) to \(\boldsymbol{\mu}\) and \(\boldsymbol{\Sigma}\). In specific, both \(\boldsymbol{\mu}\) and \(\boldsymbol{\Sigma}\) can be represented with the function of learnable parameter \(\Psi\).

### Gumbel-softmax Reparameterization Trick

Besides of the Gaussian sampling process, the Bernoulli sampling in our equation is not traceable either, so we utilize Gumbel-softmax reparameterization trick to make it traceable.

We demonstrate the traceable calculation of \(\mathbf{E}\sim p(\mathbf{E}|\mathbf{S},\mathbf{T})\) by Gumbel-max reparameterization trick. According to Gumbel-max [51], we have

\[\text{Bernoulli}(p)\iff\mathbf{1}\left[G_{1}+\log p>G_{0}+\log(1-p)\right], \quad G_{0},G_{1}\sim\text{Gumbel}(0,1).\]

Instead of using unit step function, we utilize sigmoid function

\[\sigma(G_{1}+\log p>G_{0}+\log(1-p)).\]

Therefore, we have

\[\mathbf{E}_{i,j}=\sigma(\mathbf{L}_{i,j}+\mathbf{S}_{i}^{T}\cdot \mathbf{T}_{j}),\]

where \(\mathbf{L}_{i,j}\sim L(0,1)\). Therefore, we sample \(\mathbf{L}_{i,j}\sim L(0,1)\) instead, where \(L(0,1)\) is logistic distribution, and calculate \(\mathbf{E}_{i,j}=\sigma(\mathbf{L}_{i,j}+\mathbf{S}_{i}^{T}\cdot\mathbf{T}_{j})\) to trace gradients. Specifically, both \(\boldsymbol{S}_{i}\) and \(\boldsymbol{T}_{i}\) can be represented with the function of learnable parameter \(\Psi\).

### Optimization of ELBO

With the estimation and reparameterization trick, we are able to conduct gradient descent methods to optimize our parameters with the objection function

\[\Psi^{*}=\operatorname*{arg\,max}_{\Psi}\text{ELBO}.\]

The format of stochastic gradient descent (SGD) is

\[\Psi\leftarrow\Psi+\gamma\cdot\frac{\partial\text{ELBO}}{\partial\Psi},\]

where \(\gamma\) is the learning rate.

## Appendix D Training Process of Constraint based ELBO

We intend to optimize our parameter with

\[\Psi^{*}= \operatorname*{arg\,max}_{\Psi}\mathbb{E}_{\bm{\Phi}\sim q(\bm{ \Phi})}\left[\log p(D|\bm{\Phi})-\log q(\bm{\Phi})+\log p(\bm{\Phi})\right],\] \[\text{s.t.}\sum_{\{\bm{e}_{s},\bm{e}_{t}\}}I(\bm{x}_{s};\bm{x}_{t} |\bm{\phi}_{M},\{\bm{e}_{s},\bm{e}_{t}\},D)\leq\epsilon.\]

However, the objection has a constraint, which is hard to optimize with gradient descent methods. So we utilize Lagrange multiplier [52] to convert it to a constraint-free method:

\[\Psi^{*}= \operatorname*{arg\,max}_{\Psi}\mathbb{E}_{\bm{\Phi}\sim q(\bm{ \Phi})}\left[\log p(D|\bm{\Phi})-\log q(\bm{\Phi})+\log p(\bm{\Phi})\right]+ \lambda\cdot\sum_{\{\bm{e}_{s},\bm{e}_{t}\}}I(\bm{x}_{s};\bm{x}_{t}|\bm{\phi} _{M},\{\bm{e}_{s},\bm{e}_{t}\},D),\]

where \(\lambda\) is the Lagrange multiplier. Then, we intend to calculate the constraint part.

First of all, we have

\[I(\bm{x}_{s};\bm{x}_{t}|\bm{\phi}_{M},\{\bm{e}_{s},\bm{e}_{t}\},D)\] \[= H(\bm{x}_{s}|\bm{\phi}_{M},\{\bm{e}_{s},\bm{e}_{t}\},D)+H(\bm{x} _{t}|\bm{\phi}_{M},\{\bm{e}_{s},\bm{e}_{t}\},D)-H(\bm{x}_{s},\bm{x}_{t}|\bm{ \phi}_{M},\{\bm{e}_{s},\bm{e}_{t}\},D)\] \[= H(\bm{x}_{s}|\bm{\phi}_{M},\bm{e}_{s},D)+H(\bm{x}_{t}|\bm{\phi}_{ M},\bm{e}_{t},D)-H(\bm{x}_{s},\bm{x}_{t}|\bm{\phi}_{M},\{\bm{e}_{s},\bm{e}_{t}\},D),\]

For the term \(H(\bm{x}_{s}|\bm{\phi}_{M},\bm{e}_{s},D)\), we have

\[H(\bm{x}_{s}|\bm{\phi}_{M},\bm{e}_{s},D) =-\int p(\bm{x}_{s}|\bm{\phi}_{M},\bm{e}_{s},D)\log p(\bm{x}_{s}| \bm{\phi}_{M},\bm{e}_{s},D)\;d\bm{x}_{s}\] \[=-\mathbb{E}_{p(\bm{x}_{s}|\bm{\phi}_{M},\bm{e}_{s},D)}\left[\log p (\bm{x}_{s}|\bm{\phi}_{M},\bm{e}_{s},D)\right].\]

We use Monte Carlo sampling to estimate \(H(\bm{x}_{s}|\bm{\phi}_{M},\bm{e}_{s},D)\), and we have

\[H(\bm{x}_{s}|\bm{\phi}_{M},\bm{e}_{s},D)\approx\frac{1}{K_{1}\cdot K_{2}}\sum _{k_{1}=1}^{K_{1}}\sum_{k_{2}=1}^{K_{2}}\log p(\bm{x}^{(k_{1},k_{2})}|\bm{e}^{ s},\bm{\phi}_{M}),\]

where we sample graphs \(\bm{\phi}_{m}^{k_{1}}\sim q(\bm{\phi}_{m}|\bm{e}^{s},\bm{\phi}_{M})\), and obtain samples \(\bm{x}^{(k_{1},k_{2})}\sim p(\bm{x}|\bm{e}^{s},\bm{\phi}_{m}^{k_{1}})\). Similarly, we can calculate

\[H(\bm{x}_{t}|\bm{\phi}_{M},\bm{e}_{t},D)\approx\frac{1}{K_{1}\cdot K_{2}}\sum _{k_{1}=1}^{K_{1}}\sum_{k_{2}=1}^{K_{2}}\log p(\bm{x}^{(k_{1},k_{2})}|\bm{e}^{ t},\bm{\phi}_{M}),\]

where we sample graphs \(\bm{\phi}_{m}^{k_{1}}\sim q(\bm{\phi}_{m}|\bm{e}^{t},\bm{\phi}_{M})\), and obtain samples \(\bm{x}^{(k_{1},k_{2})}\sim p(\bm{x}|\bm{e}^{t},\bm{\phi}_{m}^{k_{1}})\).

And we have

\[H(\bm{x}_{s},\bm{x}_{t}|\bm{\phi}_{M},\{\bm{e}_{s},\bm{e}_{t}\},D)\approx\frac {1}{K_{1}\cdot K_{2}\cdot K_{3}}\sum_{k_{1}=1}^{K_{1}}\sum_{k_{2}=1}^{K_{2}} \sum_{k_{2}=1}^{K_{2}}\log p(\bm{x}^{(k_{1},k_{2}^{1})},\bm{x}^{(k_{1},k_{2}^ {2})}|\{\bm{e}_{s},\bm{e}_{t}\},\bm{\phi}_{M}),\]where we sample graphs \(\bm{\phi}_{m}^{k_{1}}\sim q(\bm{\phi}_{m}|\{\bm{e}_{s},\bm{e}_{t}\},\bm{\phi}_{M})\), obtain samples \(\bm{x}^{(k_{1},k_{2}^{1})}\sim p(\bm{x}|\bm{e}^{s},\bm{\phi}_{m}^{k_{1}})\), and obtain samples \(\bm{x}^{(k_{1},k_{2}^{2})}\sim p(\bm{x}|\bm{e}^{t},\bm{\phi}_{m}^{k_{1}})\).

Therefore, we add constraint on the original loss function to obtained the estimation of constraint based ELBO, that is,

\[\text{ELBO}= \sum_{i=1}^{N}\sum_{j=1}^{N_{S}}\log p(x^{(i)}|j^{(i)},v^{(i)},m^{ (i)},\bm{\phi}_{m^{(i)}}^{(j)})\] \[-\frac{1}{2}\left[\log\frac{||\bm{\Sigma}_{all}||}{||\tilde{\bm{ \Sigma}}_{all}||}-d+\text{tr}(\bm{\Sigma}_{all}^{-1}\tilde{\bm{\Sigma}}_{all})+( \tilde{\bm{\mu}}_{all}-\bm{\mu}_{all})^{T}\bm{\Sigma}_{all}^{-1}(\tilde{\bm{ \mu}}_{all}-\bm{\mu}_{all})\right]\] \[-\beta\cdot\sum_{i=1}^{N_{D}}\sum_{m=1}^{M}\sum_{j=1}^{N_{S}} \left[\lambda_{1}\cdot\left[\text{tr}\left(e^{\bm{E}}\right)-d\right]+\lambda _{2}\cdot||\mathbf{E}||\right]+\lambda\cdot\left[I(\bm{x}_{s};\bm{x}_{t}|\bm{ \phi}_{M},\{\bm{e}_{s},\bm{e}_{t}\},D)\right].\]

## Appendix E Proof of Theory 3

Proof.: To begin with, we introduce two anchor variables \(\bm{x},\bm{e}\), indicating existing samples and experiments in the system, which are independent with the following experiments. Since \(\bm{x}_{s},\bm{x}_{t}\) are \(\epsilon\)-independent given \(\bm{\phi}_{M},\{\bm{e}_{s},\bm{e}_{t}\}\) and \(D\), we have:

\[I(\bm{x}_{s};\bm{x}_{t}|\bm{\phi}_{M},\{\bm{e}_{s},\bm{e}_{t}\}, D)=I(\bm{x}_{s};\bm{x}_{t}|\bm{\phi}_{M},\bm{x},\bm{e}\cup\{\bm{e}_{s},\bm{e}_{t}\}, D)\leq\epsilon\] \[\Leftrightarrow H(\bm{x}_{s}|\bm{\phi}_{M},\bm{x},\bm{e}\cup\{\bm{e}_{s},\bm{e}_{t}\}, D)+H(\bm{x}_{t}|\bm{\phi}_{M},\bm{x},\bm{e}\cup\{\bm{e}_{s},\bm{e}_{t}\},D)\] \[-H(\bm{x}_{s},\bm{x}_{t}|\bm{\phi}_{M},\bm{x},\bm{e}\cup\{\bm{e}_{ s},\bm{e}_{t}\},D)\leq\epsilon,\]

Since

\[I(\bm{x}_{s};\bm{\phi}_{M}|\bm{x},\bm{e}\cup\{\bm{e}_{s},\bm{e}_ {t}\},D)= H(\bm{x}_{s}|\bm{x},\bm{e}\cup\{\bm{e}_{s},\bm{e}_{t}\},D)-H(\bm{x}_{ s}|\bm{\phi}_{M},\bm{x},\bm{e}\cup\{\bm{e}_{s},\bm{e}_{t}\},D)\] \[I(\bm{x}_{t};\bm{\phi}_{M}|\bm{x},\bm{e}\cup\{\bm{e}_{s},\bm{e}_ {t}\},D)= H(\bm{x}_{t}|\bm{x},\bm{e}\cup\{\bm{e}_{t},\bm{e}_{t}\},D)-H(\bm{x}_{ t}|\bm{\phi}_{M},\bm{x},\bm{e}\cup\{\bm{e}_{s},\bm{e}_{t}\},D)\]

We have:

\[I(\bm{x}_{s};\bm{\phi}_{M}|\bm{x},\bm{e}\cup\{\bm{e}_{s},\bm{e} _{t}\},D)+I(\bm{x}_{t};\bm{\phi}_{M}|\bm{x},\bm{e}\cup\{\bm{e}_{s},\bm{e}_{t} \},D)\] \[= H(\bm{x}_{s}|\bm{x},\bm{e}\cup\{\bm{e}_{s},\bm{e}_{t}\},D)+H(\bm {x}_{t}|\bm{x},\bm{e}\cup\{\bm{e}_{t},\bm{e}_{t}\},D)\] \[- H(\bm{x}_{s}|\bm{\phi}_{M},\bm{x},\bm{e}\cup\{\bm{e}_{s},\bm{e}_ {t}\},D)-H(\bm{x}_{t}|\bm{\phi}_{M},\bm{x},\bm{e}\cup\{\bm{e}_{s},\bm{e}_{t}\},D)\] \[\geq H(\bm{x}_{s},\bm{x}_{t}|\bm{x},\bm{e}\cup\{\bm{e}_{s},\bm{e}_{t} \},D)-H(\bm{x}_{s},\bm{x}_{t}|\bm{\phi}_{M},\bm{x},\bm{e}\cup\{\bm{e}_{s},\bm{e }_{t}\},D)-\epsilon\] \[= I(\bm{x}_{s},\bm{x}_{t};\bm{\phi}_{M}|\bm{x},\bm{e}\cup\{\bm{e}_{ s},\bm{e}_{t}\},D)-\epsilon.\]

According to the basic mutual information property \(I(A,B;C)-I(B;C)=I(A;C|B)\), we have:

\[I(\bm{x}\cup\bm{x}_{s};\bm{\phi}_{M}|\bm{e}\cup\{\bm{e}_{s},\bm{e }_{t}\},D)-I(\bm{x};\bm{\phi}_{M}|\bm{e}\cup\{\bm{e}_{s},\bm{e}_{t}\},D)\] \[+I(\bm{x}\cup\bm{x}_{t};\bm{\phi}_{M}|\bm{e}\cup\{\bm{e}_{s},\bm{e }_{t}\},D)-I(\bm{x};\bm{\phi}_{M}|\bm{e}\cup\{\bm{e}_{s},\bm{e}_{t}\},D)\] \[\geq I(\bm{x}\cup\{\bm{x}_{t},\bm{x}_{s}\};\bm{\phi}_{M}|\bm{e}\cup\{ \bm{e}_{s},\bm{e}_{t}\},D)-I(\bm{x};\bm{\phi}_{M}|\bm{e}\cup\{\bm{e}_{s},\bm{e }_{t}\},D)-\epsilon.\]

Thus, we have:

\[I(\bm{x}\cup\bm{x}_{s};\bm{\phi}_{M}|\bm{e}\cup\{\bm{e}_{s},\bm{e }_{t}\},D)+I(\bm{x}\cup\bm{x}_{t};\bm{\phi}_{M}|\bm{e}\cup\{\bm{e}_{s},\bm{e}_{t} \},D)\] \[\geq I(\bm{x}\cup\{\bm{x}_{t},\bm{x}_{s}\};\bm{\phi}_{M}|\bm{e}\cup\{\bm{e }_{s},\bm{e}_{t}\},D)+I(\bm{x};\bm{\phi}_{M}|\bm{e}\cup\{\bm{e}_{s},\bm{e}_{t}\},D)-\epsilon.\]

Since different experiments are independent, we have:

\[I(\bm{x}\cup\bm{x}_{s};\bm{\phi}_{M}|\bm{e}\cup\{\bm{e}_{s}\},D)+I(\bm{x}\cup\bm{x}_ {t};\bm{\phi}_{M}|\bm{e}\cup\{\bm{e}_{t}\},D)\] \[\geq I(\bm{x}\cup\{\bm{x}_{t},\bm{x}_{s}\};\bm{\phi}_{M}|\bm{e}\cup\{\bm{e }_{s},\bm{e}_{t}\},D)+I(\bm{x};\bm{\phi}_{M}|\bm{e},D)-\epsilon.\]

Thus, \(I(\cdot;\bm{\phi}_{M}|\cdot,D)\) is \(\epsilon\)-submodular. 

## Appendix F Proof of Theory 4

For clear presentation, we denote \(g(\{\bm{e}_{i}\}_{i=1}^{n})=I(\{\bm{x}_{i}\}_{i=1}^{n};\bm{\phi}_{M}|\{\bm{e}_{i} \}_{i=1}^{n},D)\), then we need to solve the following problem:

\[\operatorname*{arg\,max}_{\{\bm{e}_{i}\}_{i=1}^{n}}g(\{\bm{e}_{i}\}_{i=1}^{n}),\] (14)Suppose \(S^{*}=\{\bm{e}_{i}^{*}\}_{i=1}^{n}\) is the optimal solution for objective (14), and the results of the greedy method is \(S=\{\bm{e}_{i}\}_{i=1}^{n}\), where the experiments are sequentially determined from \(\bm{e}_{1}\) to \(\bm{e}_{n}\). We denote \(S_{1:j}=\{\bm{e}_{i}\}_{i=1}^{j}\), and \(\Delta(\bm{e}|S_{1:j})=g(S_{1:j}\cup\bm{e})-g(S_{1:j})\), according to the greedy method, we have:

\[\bm{e}_{j+1}=\arg\max_{\bm{e}}\frac{\Delta(\bm{e}|S_{1:j})}{\lambda_{\bm{e}}},\]

where \(\lambda_{\bm{e}}\) is the cost of experiment \(\bm{e}\).

Based on all the above notations, we have:

\[g(S^{*}) \leq g(S^{*}\cup S_{1:j})\] \[=g(S_{1:j})+g(S_{1:j}\cup\bm{e}_{1}^{*})-g(S_{1:j})\] \[+g(S_{1:j}\cup\bm{e}_{1}^{*}\cup\bm{e}_{2}^{*})-g(S_{1:j}\cup\bm{ e}_{1}^{*})\] \[+\ldots\] \[+g(S_{1:j}\cup\{\bm{e}_{1}^{*},...,\bm{e}_{n}^{*}\})-g(X_{1:i} \cup\{\bm{e}_{1}^{*},...,\bm{e}_{n-1}^{*}\})\] \[=g(S_{1:j})+\sum_{k=1}^{n}\left[g(S_{1:j}\cup\{\bm{e}_{1}^{*},...,\bm{e}_{k}^{*}\})-g(X_{1:i}\cup\{\bm{e}_{1}^{*},...,\bm{e}_{k-1}^{*}\})\right]\] \[\leq g(S_{1:j})+\sum_{k=1}^{n}\left[g(S_{1:j}\cup\{\bm{e}_{k}^{*} \})-g(S_{1:j})+\epsilon\right]\] \[=g(S_{1:j})+\sum_{k=1}^{n}\left[\Delta(\{\bm{e}_{k}^{*}\}|S_{1:j} )+\epsilon\right],\]

where the first inequality holds because of the non-decreasing property, and the second inequality holds because of the \(\epsilon\)-submodular property.

Since \(\bm{e}_{j+1}=\arg\max_{\bm{e}}\frac{\Delta(\bm{e}|S_{1:j})}{\lambda_{\bm{e}}}\), we have \(\frac{\Delta(\bm{e}|S_{1:j})}{\lambda_{\bm{e}}}\leq\frac{\Delta(\bm{e}_{j+1}| S_{1:j})}{\lambda_{\bm{e}_{j+1}}}\) for any \(\bm{e}\), thus \(\Delta(\bm{e}|S_{1:j})\leq\frac{\lambda_{\bm{e}}}{\lambda_{\bm{e}_{j+1}}} \Delta(\bm{e}_{j+1}|S_{1:j})\leq B_{\lambda}\Delta(\bm{e}_{j+1}|S_{1:j})\). By bringing this result into the above equation, we have:

\[g(S^{*}) \leq g(S_{1:j})+\sum_{k=1}^{n}\left[\Delta(\{\bm{e}_{k}^{*}\}|S_ {1:j})+\epsilon\right]\] \[\leq g(S_{1:j})+\sum_{k=1}^{n}\left[B_{\lambda}\Delta(\bm{e}_{j+1} |S_{1:j})+\epsilon\right]\] \[=g(S_{1:j})+nB_{\lambda}\Delta(\bm{e}_{j+1}|S_{1:j})+n\epsilon\]

Let \(T_{j}=g(S^{*})-g(S_{1:j})\), we have:

\[T_{j}-T_{j+1}=g(S_{1:j+1})-g(S_{1:j})=\Delta(\bm{e}_{j+1}|S_{1:j})\geq\frac{T _{j}-n\epsilon}{nB_{\lambda}}\]

Then

\[T_{n} \leq(1-\frac{1}{nB_{\lambda}})T_{n-1}+\frac{\epsilon}{B_{\lambda }}\leq[(1-\frac{1}{nB_{\lambda}})]^{2}T_{n-2}+(1-\frac{1}{nB_{\lambda}})\frac {\epsilon}{B_{\lambda}}+\frac{\epsilon}{B_{\lambda}}\] \[\leq...\leq[(1-\frac{1}{nB_{\lambda}})]^{n}T_{0}+[(1-\frac{1}{nB_ {\lambda}})]^{n-1}\frac{\epsilon}{B_{\lambda}}+...+\frac{\epsilon}{B_{\lambda}}\]

Let \(B=[(1-\frac{1}{nB_{\lambda}})]^{n-1}\frac{\epsilon}{B_{\lambda}}+...+\frac{ \epsilon}{B_{\lambda}}=\frac{\epsilon}{B_{\lambda}}\sum_{i=1}^{n}[(1-\frac{1}{ nB_{\lambda}})]^{i-1}\), and considering that \([(1-\frac{1}{nB_{\lambda}})]^{n}=e^{-\frac{1}{B_{\lambda}}}\), we have:

\[g(S^{*})-g(S_{1:n})\leq e^{-\frac{1}{B_{\lambda}}}g(S^{*})+B\]

Thus, we have \(g(S_{1:n})\geq(1-e^{-\frac{1}{B_{\lambda}}})g(S^{*})-B\).

## Appendix G Algorithm

The algorithm for Licence method for single intervention scenario is shown in Algorithm 1. Moreover, the algorithm for Licence method for batch interventiion scenario is shown in Algorithm 2.

```
0: Variable set \(X_{V}\), number of oracles \(M\), cost of oracles \(\mathbf{\Lambda}\), observational data \(D^{O}\), total budget \(C\), and learning rate \(\eta\).
0: Causal graph \(\boldsymbol{\phi}_{M}\).
1 Initialize the model parameter \(\Psi\).
2 Optimize \(\Psi\) with the training process of ELBO under \(D^{O}\).
3 Initialize \(D^{I}=\emptyset\).
4while Budget \(C\) does not run outdo
5 Initialize \(j^{*},m^{*},v^{*}\) and let \(\zeta^{*}=-\infty\).
6for\((j,m)\) in \(\{1,2,\ldots,d\}\times\{1,2,\ldots,M\}\)do
7 Calculate \(v^{*}(j,m)\) with BO.
8if\(f(j,v^{*}(j,m),m)>\zeta^{*}\)then
9 Update \(j^{*}\gets j,m^{*}\gets m\) and \(v^{*}\gets v^{*}(j,m)\).
10 Update \(\zeta^{*}\gets f(j,v^{*}(j,m),m)\).
11 end if
12
13 end for
14
15 subtract the budget with \(C\gets C-\lambda_{m^{*}}\).
16Acquire \((j^{*},v^{*},m^{*})\) towards the true causal graph to obtain \(\boldsymbol{x}^{*}\sim p_{m}(X_{V}|do(X_{j}=v))\).
17 Update \(D^{I}\gets D^{I}\cup\{\boldsymbol{x}^{*}\}\).
18 Optimize \(\Psi\) with training process of ELBO under \(D^{O}\cup D^{I}\).
19
20 end for
21 Sample \(\boldsymbol{\phi}_{M}\) from \(p(\boldsymbol{\phi}_{M}|D)\) return Causal graph \(\boldsymbol{\phi}_{M}\). ```

**Algorithm 1**Algorithm of Licence for Single Intervention Scenario

## Appendix H More Experiments

### Experimental Settings

#### h.1.1 Datasets

The details of our experimental datasets are presented as follows:

\(\bullet\)**Erdos-Renyi (ER)**[41] graph is a random graph introduced by Paul Erdos and Alfred Renyi. For ER graph, a graph with \(n\) vertices is generated by connecting each pair of vertices with a probability \(p\).

\(\bullet\)**Scale-Free (SF)**[42] graph is a type of random graph that has a degree distribution following power law. A small number of vertices in SF graph own a large number of edges, while the vast majority of vertices have relatively few edges.

\(\bullet\)**DREAM**[43] is the abbreviation for Dialogue for Reverse Engineering Assessments and Methods, which can estimate the reverse quality that causal discovery methods perform. Specifically, we use a biological graph generator GeneNetWeaver for our experiments, which is a real-word public dataset.

#### h.1.2 Baselines

The details of experimental baselines are demonstrated as follows. We utilize DiBS [53] as our basic graph representation component. For acquisition methods, we use AIT and CBED and obtain the query tuples of node and value.

\(\bullet\)**AIT**[44] is an active learning method that utilize f-score to select intervention queries.

\(\bullet\)**CBED**[8] is based on the calculation of mutual information (MI), which intend to select intervention queries with maximal MI scores after obtaining new samples under current queries.

For the batch intervention scenario, we extend above methods with greedy strategy, which can promise an lower bound for approximation with submodular property. For choosing the fidelities to query, we use two circumstances, _i.e.,_ REAL and RANDOM.

\(\bullet\)**REAL** fidelity means the model always choose the highest fidelity to conduct experiments. This strategy is aligned with classic causal discovery under active learning paradigm without multi-fidelity settings, which can just choose the most accurate samples to conduct discovery process.

\(\bullet\)**RANDOM** fidelity means the model choose different fidelities randomly with uniform probability.

#### h.1.3 Metrics

The details of experimental metrics are demonstrated as follows. We utilize SHD and AUPRC to reflect the topological structure discovering performance, and design RMSE to reflex the predicting performance of functional relations.

\(\bullet\)**SHD**[45] is the abbreviation for Structural Hamming Distance, and it estimate the topological structure by counting the number of different edges on adjacency matrix. We calculate the expectation of SHD under multiple graph samplings.

\(\bullet\)**AUPRC**[46] is the area under precision-recall curve, where we consider entities on the adjacency matrix as binary classification problem. The AUPRC is also under the expectation for multiple graph sampling.

\(\bullet\)**RMSE** is designed for estimating the performance of grasping functional relations. We obtain several samples from the true causal graph, and let our model and the true causal function to conduct forward process respectively, then calculate the RMSE between the two results. We calculate RMSE by sampling graphs for multiple times.

### Simulation of Oracles with Different Fidelities

For a given intervention \((j,v)\), suppose we have \(M\) oracles \(\{\phi_{1},\phi_{2},...,\phi_{M}\}\), then the experiment results \(\{x_{j,v,1},x_{j,v,2},...,x_{j,v,M}\}\) are specified as follows:

\[x_{j,v,m} =x_{j,v,M}+\delta_{m},\] \[\delta_{m} \sim N(0,\sigma_{m}),\]

where \(x_{j,v,M}\) is the ground truth, which can be directly obtained from the datasets. Since \(x_{j,v,m}\) is correlated with \(x_{j,v,M}\) by the first line, their underlying oracles \(\phi_{m}\) and \(\phi_{M}\) are correlated in our simulation. In our experiment, we set \(\delta_{1}>\delta_{2}>...>\delta_{M}=0\). Suppose the cost of \(\phi_{m}\) as \(\lambda_{m}\), then we set \(\lambda_{1}<\lambda_{2}<...<\lambda_{M}\).

### Details of Configurations and Computation

The details of the configurations of device and platform are demonstrate in Table 1(left). We will show the details of the time cost on computation. We measure the time cost on the generation of each intervention per fidelity for all models, and the results are shown in Figure 1(right). We find that our method cost a little more than the baselines, which is probably due to the more complex sampling process in our model.

We also show the details of experimental settings for our overall experiments in Table 2. We carefully tune the hyper-parameters for baselines and our model, and the final values can be obtained in the configuration file in our codes.

### Experiments on DREAM Dataset

We conduct experiments on a real-world biological dataset, called DREAM. Note that, DREAM does not support the calculation of RMSE, because of the lack of interface in this real-world dataset. We use two sub-datasets _Ecoli_ and _Yeast_ as our true causal graphs. The results are shown in Figure 4. We find that our model outperforms that other baselines on both _Ecoli_ and _Yeast_, and both single and batch intervention scenario.

### Experiments on More Nodes

In this section, we conduct further experiments on datasets with more nodes. We extend the number of nodes from 10 to 20, and experiment on the ER graph. The results are shown in Figure 3. We find that our model is still effective on the scenario of more nodes, and is better than baselines.

\begin{table}
\begin{tabular}{c c} \hline \hline
**Name** & **Details** \\ \hline CPU & Intel Xeon Platinum 8350C 2.60GHz \\ GPU & RTX A5000 (24GB) \\ Memory & 42GB RAM \\ Python & Version 3.8 \\ Java & Version 1.8.0 (Necessary for DREAM) \\ \hline \hline \end{tabular} 
\begin{tabular}{c c} \hline \hline
**Model** & **Time (secs)** \\ \hline AIT-REAL & 7.686 \\ AIT-RANDOM & 7.451 \\ CBED-REAL & 7.998 \\ CBED-RANDOM & 7.989 \\ Licence & 8.320 \\ \hline \hline \end{tabular}
\end{table}
Table 1: The left table demonstrate the details of the configuration of device and platform. The right table shows the details of time cost on computation.

\begin{table}
\begin{tabular}{c c c} \hline \hline
**Name** & **Explanation** & **Value** \\ \hline budget & The total budget for interventional experiments, (_i.e.,_ C). & 10/20/30/40/50 \\ oracle number & The number of oracles, (_i.e.,_\(M\)) & 3 \\ oracle cost & The cost for each oracle, (_i.e.,_\(\mathbf{\Lambda}\)) & 2, 8, 32 \\ oracle noise & The extra additive noise for each oracle. & 0.04, 0.02, 0.00 \\ observation number & The number of observational samples. & 1000 \\ expect edge number & The number of expect edges. & 2 \\ additive noise & The value of additive noise during data generations. & 0.01 \\ \hline \hline \end{tabular}
\end{table}
Table 2: The details of experimental settings.

### Supplementary Experiments on MAE Metric

We further compare our model with the baselines based on the Mean Absolute Error (MAE) metric. The experiments are conducted based on ER with different total budgets. The results are presented in Table 4.

The results indicate that our model surpasses the baselines in terms of MAE. This further provides evidence that the superior performance of our model is a general conclusion.

### Supplementary Experiments on Different Oracle Settings

To demonstrate that our model is generally effective for different cost- and noisy-levels. We conduct experiments based on different sets of oracles. In specific, the experiments are conducted based on the following settings in Table 5. The results are presented in Figure 5.

From the results, we can see that our model can always perform better than the baselines on different sets of oracles.

\begin{table}
\begin{tabular}{c c c c c c} \hline \hline
**Model** & **Budget(10)** & **Budget(20)** & **Budget(30)** & **Budget(40)** & **Budget(50)** \\ \hline AIT-REAL & 3.46\(\pm\)0.01 & 2.43\(\pm\)0.01 & 2.63\(\pm\)0.01 & 3.46\(\pm\)0.01 & 2.42\(\pm\)0.01 \\ AIT-RANDOM & 3.71\(\pm\)0.02 & 2.42\(\pm\)0.01 & 2.82\(\pm\)0.01 & 2.68\(\pm\)0.00 & 2.54\(\pm\)0.01 \\ CBED-REAL & 3.73\(\pm\)0.01 & 2.56\(\pm\)0.00 & 2.54\(\pm\)0.00 & 3.69\(\pm\)0.01 & 2.52\(\pm\)0.00 \\ CBED-RANDOM & 4.00\(\pm\)0.02 & 2.53\(\pm\)0.00 & 2.88\(\pm\)0.00 & 3.14\(\pm\)0.01 & 2.70\(\pm\)0.01 \\ Licence & **2.06\(\pm\)0.00** & **2.20\(\pm\)0.01** & **1.70\(\pm\)0.00** & **1.77\(\pm\)0.00** & **2.07\(\pm\)0.00** \\ \hline \hline \end{tabular}
\end{table}
Table 4: Results of the metric MAE (%).

Figure 4: The performance among models on DREAM datasets with different datasets and budgets. Lower SHD, RMSE indicate better performances. We conduct each experiment for ten times, and report the average performances and error bars.

\begin{table}
\begin{tabular}{c c c c c c} \hline \hline
**Model** & **Budget(10)** & **Budget(20)** & **Budget(30)** & **Budget(40)** & **Budget(50)** \\ \hline AIT-REAL & 63.36\(\pm\)4.89 & 64.36\(\pm\)5.18 & 64.53\(\pm\)6.83 & 63.28\(\pm\)4.86 & 64.35\(\pm\)5.19 \\ AIT-RANDOM & 63.62\(\pm\)4.61 & 62.16\(\pm\)5.75 & 64.60\(\pm\)5.23 & 66.87\(\pm\)6.47 & 63.53\(\pm\)5.27 \\ DiBS-REAL & 63.58\(\pm\)6.35 & 61.50\(\pm\)7.69 & 63.50\(\pm\)6.86 & 63.56\(\pm\)6.34 & 61.45\(\pm\)7.69 \\ DiBS-RANDOM & 63.68\(\pm\)6.77 & 65.07\(\pm\)6.41 & 63.91\(\pm\)7.14 & 63.99\(\pm\)4.46 & 63.86\(\pm\)3.00 \\ Licence & 49.67\(\pm\)11.64 & 49.61\(\pm\)8.08 & 55.68\(\pm\)8.63 & 51.34\(\pm\)11.24 & 51.36\(\pm\)9.11 \\ \hline \hline \end{tabular}
\end{table}
Table 3: SHD results of 20 nodes graphs on different budgets. Lower SHD indicates better performances. We conduct each experiment for ten times, and report average performances and error bars.

### Supplementary Experiments on Regularization Coefficient \(\lambda\)

In our model, the \(\epsilon\)-independent constraint in Equation 10 is an important contribution. In the optimization process, we convert it to the objective. We study the influence of the coefficient \(\lambda\) by tuning it in the range of [\(10^{-5}\),\(10^{-6}\),\(10^{-7}\),\(10^{-8}\),\(10^{-9}\)]. The results are presented in Figure 6.

From the results, we can see the performances of our model varies as we set different \(\lambda\)'s. In most cases, the best performance is achieved when \(\lambda\) is moderated (not too large or too small).

### Supplementary Experiments on Ablation Studies

To study whether the correlation modeling between different oracles are necessary, we first build a variant of our model by regarding different oracles as independent components, that is, removing the links between different \(\phi\)'s in Figure 1, and then compare our model with such variant. The results are presented in Table 6.

We can see, in most cases, our model can achieve better performance than its variant without modeling the correlations between different oracles.

## Appendix I Potentially Negative Social Impact

Causal discovery focuses on understanding causal relationships between variables. While causal discovery has the potential to bring about positive social impacts, it is important to consider both the positive and negative implications of its applications. In this response, I will focus on the negative impact of causal discovery.

\(\bullet\)**Reductionism and Oversimplification.** Causal discovery techniques often aim to identify simple cause-and-effect relationships. However, complex social phenomena often involve a multitude of interconnected factors, making it difficult to capture the full complexity of the system. Relying solely on causal discovery may lead to oversimplification and reductionism, neglecting the nuanced interactions between variables.

\begin{table}
\begin{tabular}{c c c c c c c} \hline \hline
**Metrics** & **Model** & **Budget(10)** & **Budget(20)** & **Budget(30)** & **Budget(40)** & **Budget(50)** \\ \hline \multirow{3}{*}{SHD \(\downarrow\)} & Licence (w/o rel) & **14.61\(\pm\)2.30** & 15.25\(\pm\)2.74 & 15.47\(\pm\)3.74 & 15.17\(\pm\)4.30 & 18.52\(\pm\)4.65 \\  & Licence & 14.67\(\pm\)2.98 & **14.73\(\pm\)2.04** & **14.29\(\pm\)3.20** & **14.83\(\pm\)3.24** & **15.02\(\pm\)3.01** \\ \hline \multirow{3}{*}{AUPRC (\%) \(\uparrow\)} & Licence (w/o rel) & 28.96\(\pm\)1.28 & **35.05\(\pm\)3.35** & 31.74\(\pm\)1.50 & 37.85\(\pm\)2.03 & 33.70\(\pm\)4.36 \\  & Licence & **35.75\(\pm\)2.13** & 25.12\(\pm\)2.01 & **41.79\(\pm\)1.71** & **40.89\(\pm\)2.92** & **41.76\(\pm\)3.19** \\ \hline \multirow{3}{*}{RMSE (\%) \(\downarrow\)} & Licence (w/o rel) & 3.34\(\pm\)0.04 & 3.10\(\pm\)0.02 & 2.46\(\pm\)0.00 & **2.61\(\pm\)0.00** & 2.83\(\pm\)0.00 \\  & Licence & **2.82\(\pm\)0.01** & **2.75\(\pm\)0.00** & **2.40\(\pm\)0.00** & 2.68\(\pm\)0.01 & **2.69\(\pm\)0.01** \\ \hline \hline \end{tabular}
\end{table}
Table 6: Results of the Licence and Licence without the cascaded relation.

\begin{table}
\begin{tabular}{c c c c c c} \hline \hline  & Setting 1 & \multicolumn{4}{c}{Setting 2} \\ \hline Oracle (\(m\)) & cost (\(\lambda_{m}\)) & noise (\(\sigma_{m}\)) & Oracle (\(m\)) & cost (\(\lambda_{m}\)) & noise (\(\sigma_{m}\)) \\
1 & 2 & 0.04 & 1 & 2 & 0.04 \\
2 & 8 & 0.02 & 2 & 8 & 0.02 \\
3 & 32 & 0 & 3 & 16 & 0 \\ \hline \hline \multicolumn{4}{c}{Setting 3} & \multicolumn{4}{c}{Setting 4} \\ \hline Oracle (\(m\)) & cost (\(\lambda_{m}\)) & noise (\(\sigma_{m}\)) & Oracle (\(m\)) & cost (\(\lambda_{m}\)) & noise (\(\sigma_{m}\)) \\
1 & 2 & 0.04 & 1 & 2 & 0.04 \\
2 & 4 & 0.02 & 2 & 8 & 0.02 \\
3 & 32 & 0 & 3 & 32 & 0 \\ \hline \hline \multicolumn{4}{c}{Setting 5} & \multicolumn{4}{c}{Setting 6} \\ \hline Oracle (\(m\)) & cost (\(\lambda_{m}\)) & noise (\(\sigma_{m}\)) & Oracle (\(m\)) & cost (\(\lambda_{m}\)) & noise (\(\sigma_{m}\)) \\
1 & 2 & 0.08 & 1 & 2 & 0.04 \\
2 & 8 & 0.02 & 2 & 8 & 0.03 \\
3 & 32 & 0 & 3 & 32 & 0 \\ \hline \hline \end{tabular}
\end{table}
Table 5: Settings for different cost and noise levels.

Figure 5: Results of different settings of oracles in terms of cost and noise.

Figure 6: Results of extensive experiments on regularization \(\lambda\).

\(\bullet\)**Ethical Concerns.** Causal discovery can involve analyzing sensitive data, such as personal information or medical records. If not handled carefully, the use of this data can raise significant ethical concerns related to privacy, consent, and potential discrimination. Improper handling of data could lead to violations of privacy and unfair treatment of individuals or groups.

\(\bullet\)**Overreliance on Correlation.** Causal discovery often relies on identifying statistical correlations between variables. However, correlation does not imply causation, and there is a risk of mistakenly inferring causal relationships based solely on correlation. Overreliance on such methods can lead to erroneous conclusions, leading to misguided decision-making and ineffective interventions.

\(\bullet\)**Social Bias and Inequality.** Causal discovery relies on the data used for analysis, which can reflect existing biases and inequalities present in society. If the data used is biased, the causal relationships discovered may perpetuate or exacerbate existing social inequalities. Causal discovery methods need to be sensitive to potential biases and strive for fairness and inclusivity in both data collection and analysis.

In conclusion, while causal discovery holds promise in understanding complex systems, it is crucial to consider its potential negative impacts. Oversimplification, ethical concerns, overreliance on correlation, and social bias are all factors that need to be addressed to ensure responsible and beneficial applications of causal discovery. It is essential to approach this field with caution and incorporate broader societal considerations to mitigate the negative impacts and harness its potential for positive social change.

## Appendix J Limitations

In this section, we analyze the limitations of our work, including sub-optimum of greedy method, estimation of mutual information, and scale of causal graph.

\(\bullet\)**Sub-optimum of greedy method.** For the whole process of active causal discovery, the interventional data will be acquired successively in the greedy manner. Therefore, even if the strategy for acquisition is the optimal for each current step, the entire trajectory of causal discovery is sub-optimal. A possible solution is finding the best acquisition trajectory by reinforcement learning.

\(\bullet\)**Estimation of mutual information.** For different circumstances, the costs, accuracy and data scale can be various. Therefore, the scale of mutual information can be affected as well. So it is important to adjust hyper-parameters accordingly.

\(\bullet\)**Scale of causal graph.** It is a classic problem for causal discovery that most existing methods suffer from the difficulty in extending to large-scale graphs. The efficiency and effectiveness are supposed to be further improved, and we will optimize our model as well.

## References

* [1] Jeffrey S Levin. Religion and health: Is there an association, is it valid, and is it causal? _Social Science & Medicine_, 38(11):1475-1482, 1994.
* [2] Eric R Eide and Mark H Showalter. Methods matter: Improving causal inference in educational and social science research: A review article. _Economics of Education Review_, 31(5):744-748, 2012.
* [3] Bengt Muthen and Hendricks C Brown. Estimating drug effects in the presence of placebo response: causal inference using growth mixture modeling. _Statistics in medicine_, 28(27):3363-3385, 2009.
* [4] Karen Sachs, Omar Perez, Dana Pe'er, Douglas A Lauffenburger, and Garry P Nolan. Causal protein-signaling networks derived from multiparameter single-cell data. _Science_, 308(5721):523-529, 2005.
* [5] David Maxwell Chickering. Learning bayesian networks is np-complete. _Learning from data: Artificial intelligence and statistics V_, pages 121-130, 1996.
* [6] Thomas S Verma and Judea Pearl. Equivalence and synthesis of causal models. In _Probabilistic and Causal Inference: The Works of Judea Pearl_, pages 221-236. 2022.

* [7] Raj Agrawal, Chandler Squires, Karren Yang, Karthikeyan Shanmugam, and Caroline Uhler. Abcd-strategy: Budgeted experimental design for targeted causal structure discovery. In _The 22nd International Conference on Artificial Intelligence and Statistics_, pages 3400-3409. PMLR, 2019.
* [8] Panagiotis Tigas, Yashas Annadani, Andrew Jesson, Bernhard Scholkopf, Yarin Gal, and Stefan Bauer. Interventions, where and how? experimental design for causal models at scale. In _Advances in Neural Information Processing Systems_.
* [9] Azam Peyvandipour, Nafiseh Saberian, Adib Shafi, Michele Donato, and Sorin Draghici. A novel computational approach for drug repurposing using systems biology. _Bioinformatics_, 34(16):2817-2825, 2018.
* [10] Yashas Annadani, Panagiotis Tigas, Desi R Ivanova, Andrew Jesson, Yarin Gal, Adam Foster, and Stefan Bauer. Differentiable multi-target causal bayesian experimental design. _arXiv preprint arXiv:2302.10607_, 2023.
* [11] Judea Pearl and Dana Mackenzie. _The book of why: the new science of cause and effect_. Basic books, 2018.
* [12] Patrik Hoyer, Dominik Janzing, Joris M Mooij, Jonas Peters, and Bernhard Scholkopf. Nonlinear causal discovery with additive noise models. _Advances in neural information processing systems_, 21, 2008.
* [13] Neil Houlsby, Ferenc Huszar, Zoubin Ghahramani, and Mate Lengyel. Bayesian active learning for classification and preference learning. _arXiv preprint arXiv:1112.5745_, 2011.
* [14] Samuel Daulton, Xingchen Wan, David Eriksson, Maximilian Balandat, Michael A Osborne, and Eytan Bakshy. Bayesian optimization over discrete and mixed spaces via probabilistic reparameterization. _arXiv preprint arXiv:2210.10199_, 2022.
* [15] Xun Zheng, Bryon Aragam, Pradeep K Ravikumar, and Eric P Xing. Dags with no tears: Continuous optimization for structure learning. _Advances in neural information processing systems_, 31, 2018.
* [16] David M Blei, Alp Kucukelbir, and Jon D McAuliffe. Variational inference: A review for statisticians. _Journal of the American statistical Association_, 112(518):859-877, 2017.
* [17] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. _arXiv preprint arXiv:1312.6114_, 2013.
* [18] Andreas Krause and Carlos E Guestrin. Near-optimal nonmyopic value of information in graphical models. _arXiv preprint arXiv:1207.1394_, 2012.
* [19] Shibo Li, Jeff M Phillips, Xin Yu, Robert Kirby, and Shandian Zhe. Batch multi-fidelity active learning with budget constraints. _Advances in Neural Information Processing Systems_, 35:995-1007, 2022.
* [20] Christina Heinze-Deml, Marloes H Maathuis, and Nicolai Meinshausen. Causal structure learning. _Annual Review of Statistics and Its Application_, 5:371-391, 2018.
* [21] Clark Glymour, Kun Zhang, and Peter Spirtes. Review of causal discovery methods based on graphical models. _Frontiers in genetics_, 10:524, 2019.
* [22] Matthew J Vowels, Necati Cihan Camgoz, and Richard Bowden. D'ya like dags? a survey on structure learning and causal discovery. _ACM Computing Surveys_, 55(4):1-36, 2022.
* [23] Kevin P Murphy. Active learning of causal bayes net structure. Technical report, technical report, UC Berkeley, 2001.
* [24] Simon Tong and Daphne Koller. Active learning for structure in bayesian networks. In _International joint conference on artificial intelligence_, volume 17, pages 863-869. Citeseer, 2001.

* [25] Yang-Bo He and Zhi Geng. Active learning of causal networks with intervention experiments and optimal designs. _Journal of Machine Learning Research_, 9(Nov):2523-2547, 2008.
* [26] Hyunghoon Cho, Bonnie Berger, and Jian Peng. Reconstructing causal biological networks through active learning. _PloS one_, 11(3):e0150611, 2016.
* [27] Robert Osazuwa Ness, Karen Sachs, Parag Mallick, and Olga Vitek. A bayesian active learning experimental design for inferring signaling networks. In _Research in Computational Molecular Biology: 21st Annual International Conference, RECOMB 2017, Hong Kong, China, May 3-7, 2017, Proceedings 21_, pages 134-156. Springer, 2017.
* [28] Julius von Kugelgen, Paul K Rubenstein, Bernhard Scholkopf, and Adrian Weller. Optimal experimental design via bayesian optimization: active causal structure learning for gaussian process networks. _arXiv preprint arXiv:1910.03962_, 2019.
* [29] M Giselle Fernandez-Godino, Chanyoung Park, Nam-Ho Kim, and Raphael T Haftka. Review of multi-fidelity models. _arXiv preprint arXiv:1609.07196_, 2016.
* [30] Alexander IJ Forrester, Neil W Bressloff, and Andy J Keane. Optimization using surrogate models and partially converged computational fluid dynamics simulations. _Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences_, 462(2071):2177-2204, 2006.
* [31] TD Robinson, Michael S Eldred, Karen E Willcox, and Robert Haimes. Surrogate-based optimization using multifidelity models with variable parameterization and corrected space mapping. _AIAA journal_, 46(11):2814-2822, 2008.
* [32] Christopher C Fischer, Ramana V Grandhi, and Philip S Beran. Bayesian low-fidelity correction approach to multi-fidelity aerospace design. In _58th AIAA/ASCE/AHS/ASC Structures, Structural Dynamics, and Materials Conference_, page 0133, 2017.
* [33] SA Burton and P Hajela. A variable-complexity approach to second-order reliability-based optimization. _Structural and Multidisciplinary Optimization_, 25(4):237-250, 2003.
* [34] Akil Narayan, Claude Gittelson, and Dongbin Xiu. A stochastic collocation algorithm with multifidelity models. _SIAM Journal on Scientific Computing_, 36(2):A495-A521, 2014.
* [35] Benjamin Peherstorfer, Tiangang Cui, Youssef Marzouk, and Karen Willcox. Multifidelity importance sampling. _Computer Methods in Applied Mechanics and Engineering_, 300:490-509, 2016.
* [36] Leo Wai-Tsun Ng and Michael Eldred. Multifidelity uncertainty quantification using non-intrusive polynomial chaos and stochastic collocation. In _53rd aiaa/asme/asme/asme structures, structural dynamics and materials conference 20th aiaa/asme/ahs adaptive structures conference 14th aiaa_, page 1852, 2012.
* [37] Tiangang Cui, Youssef M Marzouk, and Karen E Willcox. Data-driven model reduction for the bayesian solution of inverse problems. _International Journal for Numerical Methods in Engineering_, 102(5):966-990, 2015.
* [38] Shibo Li, Wei Xing, Robert Kirby, and Shandian Zhe. Multi-fidelity bayesian optimization via deep neural networks. _Advances in Neural Information Processing Systems_, 33:8521-8531, 2020.
* [39] Shibo Li, Robert Kirby, and Shandian Zhe. Batch multi-fidelity bayesian optimization with deep auto-regressive networks. _Advances in Neural Information Processing Systems_, 34:25463-25475, 2021.
* [40] Shibo Li, Jeff M Phillips, Xin Yu, Robert Kirby, and Shandian Zhe. Batch multi-fidelity active learning with budget constraints. _Advances in Neural Information Processing Systems_, 35:995-1007, 2022.
* [41] Paul Erdos, Alfred Renyi, et al. On the evolution of random graphs. _Publ. Math. Inst. Hung. Acad. Sci_, 5(1):17-60, 1960.

* [42] Lun Li, David Alderson, John C Doyle, and Walter Willinger. Towards a theory of scale-free graphs: Definition, properties, and implications. _Internet Mathematics_, 2(4):431-523, 2005.
* [43] Thomas Schaffter, Daniel Marbach, and Dario Floreano. Genenetweaver: in silico benchmark generation and performance profiling of network inference methods. _Bioinformatics_, 27(16):2263-2270, 2011.
* [44] Yashas Annadani, Jonas Rothfuss, Alexandre Lacoste, Nino Scherrer, Anirudh Goyal, Yoshua Bengio, and Stefan Bauer. Variational causal networks: Approximate bayesian inference over causal structures. _arXiv preprint arXiv:2106.07635_, 2021.
* [45] Ioannis Tsamardinos, Laura E Brown, and Constantin F Aliferis. The max-min hill-climbing bayesian network structure learning algorithm. _Machine learning_, 65:31-78, 2006.
* [46] Jesse Davis and Mark Goadrich. The relationship between precision-recall and roc curves. In _Proceedings of the 23rd international conference on Machine learning_, pages 233-240, 2006.
* [47] Harold J Kushner. A new method of locating the maximum point of an arbitrary multipeak curve in the presence of noise. 1964.
* [48] Carl Edward Rasmussen. Gaussian processes in machine learning. In _Advanced Lectures on Machine Learning: ML Summer Schools 2003, Canberra, Australia, February 2-14, 2003, Tubingen, Germany, August 4-16, 2003, Revised Lectures_, pages 63-71. Springer, 2004.
* [49] Niranjan Srinivas, Andreas Krause, Sham M Kakade, and Matthias Seeger. Gaussian process optimization in the bandit setting: No regret and experimental design. _arXiv preprint arXiv:0912.3995_, 2009.
* [50] Reuven Y Rubinstein and Dirk P Kroese. _Simulation and the Monte Carlo method_. John Wiley & Sons, 2016.
* [51] Chris J Maddison, Andriy Mnih, and Yee Whye Teh. The concrete distribution: A continuous relaxation of discrete random variables. _arXiv preprint arXiv:1611.00712_, 2016.
* [52] Dimitri P Bertsekas. _Constrained optimization and Lagrange multiplier methods_. Academic press, 2014.
* [53] Lars Lorch, Jonas Rothfuss, Bernhard Scholkopf, and Andreas Krause. Dibs: Differentiable bayesian structure learning. _Advances in Neural Information Processing Systems_, 34:24111-24123, 2021.