# Interventional Causal Discovery in a Mixture of DAGs

Burak Varric

Carnegie Mellon University

&Dmitriy A. Katz

IBM Research

&Dennis Wei

IBM Research

&Prasanna Sattigeri

IBM Research

&Ali Tajer

Rensselaer Polytechnic Institute

Work was done when BV was a Ph.D. student at Rensselaer Polytechnic Institute.

###### Abstract

Causal interactions among a group of variables are often modeled by a single causal graph. In some domains, however, these interactions are best described by multiple co-existing causal graphs, e.g., in dynamical systems or genomics. This paper addresses the hitherto unknown role of interventions in learning causal interactions among variables governed by a mixture of causal systems, each modeled by one directed acyclic graph (DAG). Causal discovery from mixtures is fundamentally more challenging than single-DAG causal discovery. Two major difficulties stem from (i) an inherent uncertainty about the skeletons of the component DAGs that constitute the mixture and (ii) possibly cyclic relationships across these component DAGs. This paper addresses these challenges and aims to identify edges that exist in at least one component DAG of the mixture, referred to as the _true_ edges. First, it establishes matching necessary and sufficient conditions on the size of interventions required to identify the true edges. Next, guided by the necessity results, an adaptive algorithm is designed that learns all true edges using \(\mathcal{O}(n^{2})\) interventions, where \(n\) is the number of nodes. Remarkably, the size of the interventions is optimal if the underlying mixture model does not contain cycles across its components. More generally, the gap between the intervention size used by the algorithm and the optimal size is quantified. It is shown to be bounded by the _cyclic complexity number_ of the mixture model, defined as the size of the minimal intervention that can break the cycles in the mixture, which is upper bounded by the number of cycles among the ancestors of a node.

## 1 Introduction

The causal interactions in a system of causally related variables are often abstracted by a directed acyclic graph (DAG). This is the common practice in various disciplines, including biology [1], social sciences [2], and economics [3]. In a wide range of applications, however, the complexities of the observed data cannot be reduced to conform to a single DAG, and they are best described by a mixture of multiple co-existing DAGs over the same set of variables. For instance, gene expression of certain cancer types comprises multiple subtypes with different causal relationships [4]. In another example, mixture models are often more accurate than unimodal distributions in representing dynamical systems [5], including time-series trajectories in psychology [6] and data from complex robotics environments [7].

Despite the widespread applications, causal discovery for a mixture of DAGs remains an under-investigated domain. Furthermore, the existing studies on the subject are also limited to using only observational data [8, 9, 10, 11]. Observational data alone is highly insufficient in uncovering causal relationships. It is well-established that even for learning a single DAG, observational data can learn a DAG only up to its Markov equivalence class (MEC) [12]. Hence, _interventions_, which refer toaltering the causal mechanisms of a set of target nodes, have a potentially significant role in improving identifiability guarantees in mixture DAG models. Specifically, interventional data can be used to learn specific cause-effect relationships and refine the equivalence classes.

Using interventions for learning a single DAG is well-investigated for various causal models and interventions [13, 14, 15, 16, 17]. In this paper, we investigate using interventions for causal discovery in a mixture of DAGs, a fundamentally more challenging problem. The major difficulties stem from (i) an inherent uncertainty about the skeletons of the DAGs that constitute the mixture and (ii) possibly cyclic relationships across these DAGs. For a single DAG, the skeleton can be learned from observational data via conditional independence (CI) tests and the role of interventions is limited to orienting the edges. On the contrary, in a mixture of DAGs, the skeleton cannot be learned from observational data alone, making interventions essential for both learning the skeleton and orienting the edges. Uncertainty in the skeleton arises because, in addition to _true edges_ present in at least one individual DAG, there are _inseparable_ random variable pairs that cannot be made conditionally independent via CI tests, even though they are nonadjacent in every DAG of the mixture. These types of inseparable node pairs, referred to as _emergent edges_[11], cannot be distinguished from true edges using observational data alone.

In this paper, we aim to characterize the fundamental limits of interventions needed for learning the true edges in a mixture of DAGs. The two main aspects of these limits are the minimum _size_ and _number_ of the interventions. To this end, we first investigate the necessary and sufficient size of interventions for identifying a true edge. Subsequently, we design an adaptive algorithm that learns the true edges using interventions guided by the necessary and sufficient intervention sizes. We quantify the optimality gap of the maximum intervention size used by the algorithm as a function of the structure of the cyclic relationships across the mixture model. We note that the component DAGs of the mixture cannot be identified without further assumptions even when using interventions (see examples in Appendix D.1). Hence, our focus is on learning the set of true edges in the mixture as specified above. Our contributions are summarized as follows.

* **Intervention size:** We establish matching necessary and sufficient intervention size to identify each node's _mixture parents_ (i.e., the union of its parents across all DAGs). Specifically, we show that this size is one more than the number of mixture parents of the said node.
* **Tree DAGs:** For the special case of a mixture of directed trees, we show that the necessary and sufficient intervention size is one more than the number of DAGs in the mixture.
* **Algorithm:** We design an adaptive algorithm that identifies all directed edges of the individual DAGs in the mixture by using \(\mathcal{O}(n^{2})\) interventions, where \(n\) is the number of variables. Remarkably, the maximum size of the interventions used in our algorithm is optimal if the mixture ancestors of a node (i.e., the union of its ancestors across all DAGs) do not form a cycle.
* **Optimality gap:** We show that the gap between the maximum intervention size used by the proposed algorithm for a given node and the optimal size is bounded by the _cyclic complexity number_ of the node, which is defined as the number of nodes needing intervention to break cycles among the ancestors of the node, and is upper bounded by the number of such cycles.

We provide an overview of the closely related literature, the majority of which is focused on the causal discovery of single DAGs.

**Causal discovery of a mixture of DAGs.** The relevant literature on the causal discovery of a mixture of DAGs focuses on developing graphical models to represent CI relationships in the observed mixture distribution [8, 9, 10, 11]. Among them, [8] proposes a _fused graph_ and shows that the mixture distribution is Markov with respect to it. The study in [9] proposes a similar mixture graph but relies on longitudinal data to orient any edges. The study in [10] constructs a _mixture DAG_ that represents the mixture distribution and designed an algorithm for learning a maximal ancestral graph. The algorithm of [10] requires the component DAGs of the mixture to be poset compatible, which rules out any cyclic relationships across the DAGs. The study in [11] introduces the notion of _emergent edges_ to investigate the inseparability conditions arising in the mixture of DAGs. The study in [18] proposes a variational inference-based approach for causal discovery from a mixture of time-series data. Despite their differences, all these studies are limited to using observational data.

**Intervention design for causal discovery of a single DAG.** We note that the structure of a single DAG without latent variables can be learned using single-node interventions. Hence, the majority of the literature focuses on minimizing the number of interventions. Worst-case bounds on the number of interventions with unconstrained size are established in [13], and heuristic adaptive algorithms are proposed in [14]. Intervention design on causal graphs with latent variables is studied in [19; 20; 21]. The study in [20] also shows that single-node interventions are not sufficient for exact graph recovery in the presence of latent variables. In another direction, [16] studies interventions under size constraints, establishes a lower bound for the number of interventions, and shows that \(\mathcal{O}(\frac{n}{k}\log\log k)\) randomized interventions with size \(k\) suffice for identifying the DAG with high probability. In the case of single-node interventions, adaptive and non-adaptive algorithms are proposed in [22], active learning of directed trees is studied in [23], and a universal lower bound for the number of interventions is established in [17]. [24] also studies the universal lower bound problem and [25] provides an exact characterization for the number of interventions required to recover the DAG from the observational essential graph. A linear cost model, where the cost of an intervention is proportional to its size, is proposed in [26]. It is shown that learning the DAG with optimal cost under the linear cost model is NP-hard [27]. The size of the minimal intervention sets is studied for cyclic directed models in [28]. Specifically, it is shown that the required intervention size is at least \(\zeta-1\) where \(\zeta\) denotes the size of the largest strongly connected component in the cyclic model. A related problem to intervention design is causal discovery from a combination of observational and interventional data. In this setting, the characterization of the equivalence classes and designing algorithms for learning them is well-explored for a single DAG [29; 30; 31; 32].

**Causal discovery from multiple clusters/contexts.** Another approach to causal discovery from a mixture of DAGs is clustering the observed samples and performing structure learning on each cluster separately [33; 34; 35; 36; 37]. Learning from multiple contexts is also studied in the interventional causal discovery literature [38; 39; 40; 41]. However, these studies assume that domain indexes are known. In a similar problem, [42] aims to learn the domain indexes and perform causal discovery simultaneously.

## 2 Preliminaries and definitions

### Observational mixture model

DAG models.We consider \(K\geq 2\) distinct DAGs \(\mathcal{G}_{\ell}\triangleq(\mathbf{V},\mathbf{E}_{\ell})\) for \(\ell\in\{1,\ldots,K\}\) defined over the same set of nodes \(\mathbf{V}\triangleq\{1,\ldots,n\}\). \(\mathbf{E}_{\ell}\) denotes the set of _directed_ edges in graph \(\mathcal{G}_{\ell}\). Throughout the paper, we refer to these as the mixture _component_ DAGs. We use \(\mathrm{pa}_{\ell}(i)\), \(\mathrm{ch}_{\ell}(i)\), \(\mathrm{an}_{\ell}(i)\), and \(\mathrm{de}_{\ell}(i)\) to refer to the parents, children, ancestors, and descendants of node \(i\) in DAG \(\mathcal{G}_{\ell}\), respectively. We also use \(i\stackrel{{\ell}}{{\rightsquigarrow}}j\) to denote \(i\in\mathrm{an}_{\mathrm{m}}(j)\). For each node \(i\in\mathbf{V}\), we define \(\mathrm{pa}_{\mathrm{m}}(i)\) as the union of the nodes that are parents of \(i\) in at least one component DAG and refer to \(\mathrm{pa}_{\mathrm{m}}(i)\) as the _mixture parents_ of node \(i\). Similarly, for each node \(i\in\mathbf{V}\) we define \(\mathrm{ch}_{\mathrm{m}}(i)\), \(\mathrm{an}_{\mathrm{m}}(i)\), and \(\mathrm{de}_{\mathrm{m}}(i)\).

Mixture model.Each of the component DAGs represents a Bayesian network. We denote the random variable generated by node \(i\in\mathbf{V}\) by \(X_{i}\) and define the random vector \(X\triangleq(X_{1},\ldots,X_{n})^{\top}\). For any subset of nodes \(A\subseteq\mathbf{V}\), we use \(X_{A}\) to denote the vector formed by \(X_{i}\) for \(i\in A\). We denote the probability density function (pdf) of \(X\) under \(\mathcal{G}_{\ell}\) by \(p_{\ell}\), which factorizes according to \(\mathcal{G}_{\ell}\) as

\[p_{\ell}(x)=\prod_{i\in[n]}p_{\ell}(x_{i}\mid x_{\mathrm{pa}_{\ell}(i)})\;, \quad\forall\ell\in[K]\;.\] (1)

For distinct \(\ell,\ell^{\prime}\in[K]\), \(p_{\ell}\) and \(p_{\ell^{\prime}}\) can be distinct even when \(\mathbf{E}_{\ell}=\mathbf{E}_{\ell^{\prime}}\). The differences between any two DAGs are captured by the nodes with distinct causal mechanisms (i.e., conditional distributions) in the DAGs. To formalize such distinctions, we define the following test, which contains all the nodes with at least two different conditional distributions across component distributions.

\[\Delta\triangleq\left\{i\in\mathbf{V}:\exists\ell,\ell^{\prime}\in[K]\;:\;p_{ \ell}(X_{i}\mid X_{\mathrm{pa}_{\ell}(i)})\neq p_{\ell^{\prime}}(X_{i}\mid X _{\mathrm{pa}_{\ell^{\prime}}(i)})\right\}\,.\] (2)

We adopt the same mixture model as the prior work on causal discovery of mixture of DAGs [8; 9; 10; 11]. Specifically, observed data is generated by a mixture of distributions \(\{p_{\ell}:\ell\in[K]\}\). It is unknown to the learner which model is generating the observations \(X\). To formalize this, we define \(L\in\{1,\ldots,K\}\) as a latent random variable where \(L=\ell\) specifies that the true model is \(p_{\ell}\). We denote the probability mass function (pmf) of \(L\) by \(r\). Hence, we have the following mixture distribution for the observed samples \(X\).

\[p_{\mathrm{m}}(x)\triangleq\sum_{\ell\in[K]}r(\ell)\cdot p_{\ell}(x)\;.\] (3)Next, we provide several definitions that are instrumental to formalizing causal discovery objectives.

**Definition 1** (True edge).: _We say that \(j\to i\) is a true edge if \(j\in\mathrm{pa}_{\mathrm{m}}(i)\). The set of all true edges is denoted by_

\[\mathbf{E}_{\mathrm{t}}\triangleq\{(j\to i):i,j\in\mathbf{V},\;\;\exists\; \mathcal{G}_{\ell}:j\in\mathrm{pa}_{\ell}(i)\}\;.\] (4)

A common approach to causal discovery is the class of constraint-based approaches, which perform conditional independence (CI) tests on the observed data to infer (partial) knowledge about the DAGs' structure [43; 44; 45]. In this paper, we adopt a constraint-based CI testing approach. Following this approach, the following definition formally specifies the set of node pairs that cannot be made conditionally independent in the mixture distribution.

**Definition 2** (Inseparable pair).: _The node pair \((i,j)\) is called inseparable if \(X_{i}\) and \(X_{j}\) are always statistically dependent in the mixture distribution \(p_{\mathrm{m}}\) under any conditioning set. The set of inseparable node pairs is specified by_

\[\mathbf{E}_{i}\triangleq\{(i-j):i,j\in\mathbf{V},\;\;\nexists A\subseteq \mathbf{V}\setminus\{i,j\}:\;\;X_{i}\perp\!\!\!\perp X_{j}\mid X_{A}\;\;\text{ in }\;p_{\mathrm{m}}\}\;.\] (5)

Note that when \((j\to i)\) is a true edge, the pair \((i,j)\) will be inseparable. A significant difference between independence tests for mixture models and single-DAG models is that not all inseparable pairs have an associated true edge in the former. More specifically, due to the mixing of multiple distributions, a pair of nodes can be nonadjacent in all component DAGs but still be inseparable in mixture distribution \(p_{\mathrm{m}}\). We refer to such inseparable node pairs as _emergent pairs_, formalized next.

**Definition 3** (Emergent pair).: _An inseparable pair \((i,j)\in\mathbf{E}_{\mathrm{i}}\) is called an emergent pair if there is no true edge associated with the pair. The set of emergent pairs is denoted by_

\[\mathbf{E}_{\mathrm{e}}\triangleq\{(i,j)\in\mathbf{E}_{i}:\;i\notin\mathrm{pa}_ {\mathrm{m}}(j)\;\;\wedge\;\;j\notin\mathrm{pa}_{\mathrm{m}}(i)\}\;.\] (6)

The conditions under which emergent edges arise in mixture models are recently investigated in [11], where it is shown that the causal paths that pass through a node in the set \(\Delta\) defined in (2) are instrumental for their analysis. These paths are specified next.

**Definition 4** (\(\Delta\)-through path).: _We say that a causal path in \(\mathcal{G}_{\ell}\) between \(i\) and \(j\) is a \(\Delta\)-through path if it passes through at least one node in \(\Delta\), i.e., there exists \(u\in\Delta\) such that \(i\stackrel{{\ell}}{{\rightsquigarrow}}u\stackrel{{ \ell}}{{\rightsquigarrow}}j\). If \(u\in\mathrm{ch}_{\ell}(i)\), the path is also called a \(\Delta\)-child-through path._

### Intervention model

In this section, we describe the intervention model we use for causal discovery on a mixture of DAGs. We consider stochastic _hard_ interventions on component DAGs of the mixture model. A hard intervention on a set of nodes \(\mathcal{I}\subseteq\mathbf{V}\) cuts off the edges incident on nodes \(i\in\mathcal{I}\) in all component DAGs \(\mathcal{G}_{\ell}\) for \(\ell\in[K]\). We denote the post-intervention component DAGs upon an intervention \(\mathcal{I}\) by \(\{\mathcal{G}_{\ell,\mathcal{I}}:\ell\in[K]\}\). We note that hard interventions are less restrictive than _do_ interventions, which not only remove ancestral dependencies but also remove randomness by assigning constant values to the intervened nodes. Specifically, in \(\mathcal{G}_{\ell,\mathcal{I}}\), the causal mechanism of an intervened node \(i\in\mathcal{I}\) changes from \(p_{\ell}(x_{i}\mid x_{\mathrm{pa}_{i}(i)})\) to \(q_{i}(x_{i})\). Therefore, upon an intervention \(\mathcal{I}\subseteq\mathbf{V}\), the interventional component DAG distributions are given by

\[p_{\ell,\mathcal{I}}(x)\triangleq\prod_{i\in\mathcal{I}}q_{i}(x_{i})\prod_{i \in\mathbf{V}\setminus\mathcal{I}}p_{\ell}(x_{i}\mid x_{\mathrm{pa}_{\ell}(i) })\;,\qquad\forall\ell\in[K]\;.\] (7)

Subsequently, the interventional mixture distribution \(p_{\mathrm{m},\mathcal{I}}(x)\) is given by

\[p_{\mathrm{m},\mathcal{I}}(x)\triangleq\sum_{\ell\in[K]}r(\ell)\cdot p_{\ell, \mathcal{I}}(x)\;.\] (8)

We note that an intervened node \(i\in\mathcal{I}\) has the same causal mechanism \(q_{i}(x_{i})\) for all interventions \(\mathcal{I}\subseteq\mathbf{V}\) that contain \(i\). This is because an intervention procedure targets a set of nodes in all mixture components at the same time. Hence, resulting \(q_{i}(X_{i})\) is shared for all component models, owing to the same intervention mechanism, e.g., gene knockout experiments [46]. Hence, the set of nodes with distinct causal mechanisms across the components of the interventional mixture model becomes \(\Delta_{\mathcal{I}}\triangleq\Delta\setminus\mathcal{I}\). Next, we specify the \(\mathcal{I}\)-mixture DAG, which extends the mixture DAG defined for observational data in [10; 11] and will facilitate our analysis.

**Definition 5** (\(\mathcal{I}\)-mixture DAG).: _Given an intervention \(\mathcal{I}\) on a mixture of DAGs, \(\mathcal{I}\)-mixture DAG \(\mathcal{G}_{\mathrm{m,\mathcal{I}}}\) is a graph with \(nK+1\) nodes constructed by first concatenating the \(K\) component DAGs and then adding a single node \(y\) to the concatenation. Furthermore, there will be a directed edge from \(y\) to every node in \(\Delta_{\mathcal{I}}\) in every DAG \(\{\mathcal{G}_{\ell,\mathcal{I}}:\ell\in[K]\}\). In the \(\mathcal{I}\)-mixture DAG \(\mathcal{G}_{\mathrm{m,\mathcal{I}}}\), we use \(i_{\ell}\) to denote the copy of node \(i\) in \(\mathcal{G}_{\ell,\mathcal{I}}\). Accordingly, for any \(A\subseteq\mathbf{V}\) we define \(\bar{A}\triangleq\{i_{\ell}:i\in A,\ \ell\in[K]\}\)._

Figure 1 illustrates an example of a mixture of \(K=2\) component DAGs, different edge types, an intervention \(\mathcal{I}\) on the mixture, and the construction of the \(\mathcal{I}\)-mixture DAG from post-intervention component DAGs \(\mathcal{G}_{1,\mathcal{I}}\) and \(\mathcal{G}_{2,\mathcal{I}}\). We define the _observational mixture DAG_ as the \(\mathcal{I}\)-mixture DAG when the intervention set is \(\mathcal{I}=\emptyset\) and denote it by \(\mathcal{G}_{\mathrm{m}}\). It is known that \(p_{\mathrm{m}}\) specified in (3) satisfies the global Markov property with respect to observational mixture DAG [10, Theorem 3.2]. It can be readily verified that this result extends to the interventional setting for \(p_{\mathrm{m,\mathcal{I}}}\) and \(\mathcal{G}_{\mathrm{m,\mathcal{I}}}\). We make the following faithfulness assumption to facilitate causal discovery via statistical independence tests.

**Assumption 1** (\(\mathcal{I}\)-mixture faithfulness).: _For any intervention \(\mathcal{I}\subseteq\mathbf{V}\), the interventional mixture distribution \(p_{\mathrm{m,\mathcal{I}}}(x)\) is faithful to \(\mathcal{G}_{\mathrm{m,\mathcal{I}}}\), that is if \(X_{A}\perp\!\!\!\perp X_{B}\mid X_{C}\) in \(p_{\mathrm{m,\mathcal{I}}}(x)\), then \(\bar{A}\) and \(\bar{B}\) are \(d\)-separated given \(\bar{C}\) in \(\mathcal{G}_{\mathrm{m,\mathcal{I}}}\)._

Finally, we note that the observational counterpart of Assumption 1, i.e., when \(\mathcal{I}=\emptyset\), is standard in the literature for analyzing a mixture of DAGs [9, 10, 11]. In working with interventions, we naturally extend it to interventional mixture distributions. Also note that Assumption 1 does not compare observational and interventional distributions. Hence, it is not comparable to various faithfulness assumptions in the literature on the interventional causal discovery of a single DAG, e.g., [29, 31].

### Causal discovery objectives

We aim to address the following question: _how can we use interventions to perform causal discovery in a mixture of DAGs_, with the objectives specified next.

The counterpart of this question is well-studied for the causal discovery of a single DAG. Since the unoriented skeleton of the single DAG can already be identified by CI tests on observational data, interventions are leveraged to orient the edges. Interventions are generally bounded by a pre-specified budget, measured by the number of interventions. The extent of causal relationships that observational data can uncover in a mixture of DAGs is significantly narrower than those in single DAGs. The striking difference is the existence of emergent pairs specified in (6). Therefore, the objective of intervention design extends to distinguishing _true_ cause-effect relationships from the emergent pairs as well as determining the direction of causality. Specifically, we focus on identifying the true edges specified in (4) as the edges exist in at least one component DAG of the mixture. For this purpose, two central objectives of our investigation are:

1. Determining the necessary and sufficient size of the interventions for identifying true edges \(\mathbf{E}_{\mathrm{t}}\).
2. Designing efficient algorithms with near-optimal intervention sizes.

## 3 Interventions for causal discovery of a mixture of DAGs

In this section, we investigate the first key question of interventional causal discovery on a mixture of DAGs and investigate the size of the necessary and sufficient interventions for identifying mixture parents of a node. First, we consider a mixture of general DAGs without imposing structural constraints and establish matching necessary and sufficient intervention size for distinguishing a true edge from an emergent pair. Then, we strengthen the results for a mixture of directed trees. The results established in this section are pivotal for understanding the fundamental limits of causal discovery of a mixture of DAGs. These results guide the intervention design in Section 4.

Our analysis uncovers the connections between the mixture distribution under an intervention \(\mathcal{I}\) and the structure of post-intervention component DAGs \(\{\mathcal{G}_{\ell,\mathcal{I}}:\ell\in[K]\}\). We know that the interventional mixture distribution \(p_{\mathrm{m},\mathcal{I}}\) satisfies the Markov property with respect to \(\mathcal{I}\)-mixture DAG \(\mathcal{G}_{\mathrm{m},\mathcal{I}}\) specified in Definition 5. Therefore, in conjunction with the \(\mathcal{I}\)-mixture faithfulness assumption, the separation statements in \(\mathcal{G}_{\mathrm{m},\mathcal{I}}\) can be inferred exactly by testing the conditional independencies in \(p_{\mathrm{m},\mathcal{I}}\). To establish the necessary and sufficient intervention sizes, we recall that set \(\Delta\) plays an important role in the separability conditions in \(\mathcal{I}\)-mixture DAG \(\mathcal{G}_{\mathrm{m},\mathcal{I}}\) since \(\Delta\) allows paths across different component DAGs. The following result serves as an intermediate step in obtaining our main result.

**Lemma 1**.: _Consider an inseparable pair \((i,j)\in\mathbf{E}_{i}\) and an intervention \(\mathcal{I}\subseteq\mathbf{V}\). We have the following identifiability guarantees using the interventional mixture distribution \(p_{\mathrm{m},\mathcal{I}}(x)\)._

1. **Identifiability:** _It is possible to determine whether_ \(j\in\mathrm{pa}_{\mathrm{m}}(i)\) _if_ \(j\in\mathcal{I}\) _and there do not exist_ \(\Delta\)_-through paths from_ \(j\) _to_ \(i\) _in_ \(\mathcal{G}_{\ell,\mathcal{I}}\) _for any_ \(\ell\in[K]\)_._
2. **Non-identifiability:** _It is impossible to determine whether_ \(j\in\mathrm{pa}_{\mathrm{m}}(i)\) _if_ \(j\in\Delta_{\mathcal{I}}\) _or there exists a_ \(\Delta\)_-child-through path from_ \(j\) _to_ \(i\) _in at least one_ \(\mathcal{G}_{\ell,\mathcal{I}}\) _where_ \(\ell\in[K]\)_._

Lemma 1 provides intuition for characterizing sufficient and necessary conditions for identifying a true edge. The identifiability result implies that it suffices to choose an intervention \(\mathcal{I}\) that reduces the viable \(\Delta\)-through paths in \(\mathcal{G}_{\mathrm{m},\mathcal{I}}\) to true edges from \(j\) to \(i\). Similarly, the non-identifiability result implies the necessity of intervening on \(\Delta\)-child nodes. Building on these properties, our main result in this section establishes matching necessary and sufficient intervention sizes for identifying true edges.

**Theorem 1** (Intervention sizes).: _Consider nodes \(i,j\in\mathbf{V}\) in a mixture of DAGs._

1. **Sufficiency:** _For any mixture of DAGs, there exists an intervention_ \(\mathcal{I}\) _with_ \(|\mathcal{I}|\leq|\mathrm{pa}_{\mathrm{m}}(i)|+1\) _that ensures the determination of whether_ \(j\in\mathrm{pa}_{\mathrm{m}}(i)\) _using CI tests on_ \(p_{\mathrm{m},\mathcal{I}}\)_._
2. **Necessity:** _There exist DAG mixtures for which it is impossible to determine whether_ \(j\in\mathrm{pa}_{\mathrm{m}}(i)\) _using CI tests on_ \(p_{\mathrm{m},\mathcal{I}}(x)\) _for any intervention_ \(\mathcal{I}\) _with_ \(|\mathcal{I}|\leq|\mathrm{pa}_{\mathrm{m}}(i)|\)_._

Theorem 1 represents a fundamental step for understanding the intricacies of mixture causal discovery and serves as a guide for evaluating the optimality and efficiency of any learning algorithm. We also note that the necessity statement reflects a worst-case scenario. As such, we present the following refined sufficiency results that can guide efficient algorithm designs.

**Lemma 2**.: _Consider nodes \(i,j\in\mathbf{V}\) in a mixture of DAGs. It is possible to determine whether \(j\in\mathrm{pa}_{\mathrm{m}}(i)\) using CI tests on \(p_{\mathrm{m},\mathcal{I}}\) and any of the following interventions:_

1. \(\mathcal{I}=\{j\}\cup\bigcup_{\ell\in[K]}\left\{\mathrm{pa}_{\ell}(i)\cap \mathrm{de}_{\ell}(j)\right\}\) _; or_
2. \(\mathcal{I}=\{j\}\cup\bigcup_{\ell\in[K]}\left\{\mathrm{an}_{\ell}(i)\cap \mathrm{ch}_{\ell}(j)\right\}\) _; or_
3. \(\mathcal{I}=\{j\}\cup\bigcup_{\ell\in[K]}\left\{\mathrm{an}_{\ell}(i)\cap \mathrm{de}_{\ell}(j)\cap\Delta\right\}\)__._

Note that the three interventions in Lemma 2 can coincide when parents of \(i\) in a component DAG are also children of \(j\) and are in \(\Delta\). This case yields the set \(\mathcal{I}=\mathrm{pa}_{\mathrm{m}}(i)\cup\{j\}\) with size \((|\mathrm{pa}_{\mathrm{m}}(i)|+1)\). Since this can be a rare occurrence for realistic mixture models, partial knowledge about the underlying component DAGs, e.g., ancestral relations or the knowledge of \(\Delta\), can prove to be useful for identifying \(\mathrm{pa}_{\mathrm{m}}(i)\) using interventions with smaller sizes. Finally, we note that our results in Theorem 1 and Lemma 2 are given for a mixture of general DAGs, and they can be improved for special classes of DAGs. In the next result, we focus on mixtures of directed trees.

**Theorem 2** (Intervention sizes - trees).: _Consider nodes \(i,j\in\mathbf{V}\) in a mixture of \(K\) directed trees._

1. **Sufficiency:** _For any mixture of directed trees, there exists an intervention_ \(\mathcal{I}\) _with_ \(|\mathcal{I}|\leq K+1\) _such that it is possible to determine whether_ \(j\in\mathrm{pa}_{\mathrm{m}}(i)\) _using CI tests on_ \(p_{\mathrm{m},\mathcal{I}}\)_._
* **Necessity:** _There exist mixtures of directed trees such that it is impossible to determine whether_ \(j\in\operatorname{pa}_{\mathrm{m}}(i)\) _using CI tests on_ \(p_{\mathrm{m},\mathcal{I}}\) _for any intervention_ \(\mathcal{I}\) _with_ \(|\mathcal{I}|\leq K\)_._

Theorem 2 shows that, unlike the general result in Theorem 1, the number of mixture components plays a key role when considering a mixture of directed trees. Hence, prior knowledge of the number of mixture components can be useful for the causal discovery of a mixture of directed trees.

## 4 Learning algorithm and its analysis

In this section, we design an adaptive algorithm that identifies and orients all true edges, referred to as **C**ausal **D**iscovery from **I**nterventions on **Mixture** Models (CADIM). The algorithm is summarized in Algorithm 1, and its steps are described in Section 4.1. We also analyze the performance guarantees of the algorithm and the optimality of the interventions used in the algorithm in Section 4.2.

### Causal discovery from interventions on mixture models

The proposed CADIM algorithm designs interventions for performing causal discovery on a mixture of DAGs. The algorithm is designed to be general and demonstrate feasible time complexity for any mixture of DAGs without imposing structural constraints. Therefore, we forego the computationally expensive task of learning the inseparable pairs from observational data, which requires \(\mathcal{O}(n^{2}\cdot 2^{n})\) CI tests [11], and entirely focus on leveraging interventions for discovering the true causal relationships. The key idea of the algorithm is to use interventions to decompose the ancestors of a node into topological layers and identify the mixture parents by sequentially processing the topological layers using carefully selected interventions. The algorithm consists of four main steps, which are described next.

**Step 1: Identifying mixture ancestors.** We start by identifying the set of mixture ancestors \(\operatorname{an}_{\mathrm{m}}(i)\) for each node \(i\in\mathbf{V}\), i.e., the union of ancestors of \(i\) in the component DAGs. For this purpose, we use single-node interventions. Specifically, for each node \(i\in\mathbf{V}\), we intervene on \(\mathcal{I}=\{i\}\) and construct the set of nodes that are marginally dependent on \(X_{i}\) in \(p_{\mathrm{m},\mathcal{I}}\), i.e.,

\[\hat{\mathrm{de}}(i)=\{j:X_{j}\not\perp\!\!\!\perp X_{i}\;\;\text{ in }\;p_{ \mathrm{m},\{i\}}\}\;,\quad\forall i\in\mathbf{V}\;.\] (9)

Then, we construct the sets \(\hat{\mathrm{an}}(i)=\{j:i\in\hat{\mathrm{de}}(j)\}\) for all \(i\in\mathbf{V}\). Under \(\mathcal{I}\)-mixture faithfulness, this procedure ensures that \(\hat{\mathrm{de}}(i)=\mathrm{de}_{\mathrm{m}}(i)\), and \(\hat{\mathrm{an}}(i)=\operatorname{an}_{\mathrm{m}}(i)\) (see Lemma 3). The rest of the algorithm steps aim to identify mixture parents of a single node \(i\), \(\operatorname{pa}_{\mathrm{m}}(i)\), within the set \(\hat{\mathrm{an}}(i)\). Hence, the following steps can be repeated for all \(i\in\mathbf{V}\) to identify all true edges.

**Step 2: Obtaining cycle-free descendants.** In this step, we consider a given node \(i\in\mathbf{V}\) and aim to break the _cycles_ across the nodes in \(\hat{\mathrm{an}}(i)\) by careful interventions. Once this is achieved, for all \(j\in\hat{\mathrm{an}}(i)\), we will refine \(j\)'s descendant set \(\hat{\mathrm{de}}(j)\) to _cycle-free_ descendant set \(\mathrm{de}_{i}(j)\). The motivation is that these refined descendant sets can be used to topologically order the nodes in \(\hat{\mathrm{an}}(i)\). The details of this step work as follows. First, we construct the set of cycles

\[\mathcal{C}(i)\triangleq\{\pi=(\pi_{1},\ldots,\pi_{\ell})\;:\;\pi_{1}=\pi_{ \ell}\;,\forall u\in[\ell-1]\;\;\pi_{u}\in\hat{\mathrm{an}}(i)\;\wedge\;\pi_{ u}\in\hat{\mathrm{an}}(\pi_{u+1})\}\;.\] (10)

Subsequently, if \(\mathcal{C}(i)\) is not empty, we define a minimal set that shares at least one node with each cycle in \(\mathcal{C}(i)\),

\[\mathcal{B}(i)\triangleq\;\text{ a minimal set such that }\;\forall\pi\in \mathcal{C}(i)\;\;|\mathcal{B}(i)\cap\pi|\geq 1\;.\] (11)

We refer to \(\mathcal{B}(i)\) as the _breaking set_ of node \(i\) since intervening on any set \(\mathcal{I}\) that contains \(\mathcal{B}(i)\) breaks all the cyclic relationships in \(\mathcal{C}(i)\). Then, if \(\mathcal{C}(i)\) is not empty, we sequentially intervene on \(\mathcal{I}=\mathcal{B}(i)\cup\{j\}\) for all \(j\in\hat{\mathrm{an}}(i)\), and construct the cycle-free descendant sets defined as

\[\mathrm{de}_{i}(j)\leftarrow\{k\in\hat{\mathrm{an}}(i)\cup\{i\}:X_{j}\not \perp\!\!\!\perp X_{k}\;\;\text{ in }\;p_{\mathrm{m},\mathcal{I}}\}\;,\quad\text{ where }\;\mathcal{I}=\mathcal{B}(i)\cup\{j\}\;.\] (12)

Note that \(\mathrm{de}_{i}(j)\) is a subset of \(\mathrm{de}_{\mathrm{m}}(j)\) since intervening on \(j\) makes it independent of all its non-descendants. Finally, we construct the set \(\mathcal{A}=\{j\in\hat{\mathrm{an}}(i):i\in\mathrm{de}_{i}(j)\}\).

**Step 3: Topological layering.** In this step, we decompose \(\hat{\mathrm{an}}(i)\) into topological layers by using the cycle-free descendant sets constructed in Step 2. We start by constructing the first layer as

\[S_{1}(i)=\{j\in\mathcal{A}:\mathrm{de}_{i}(j)\cap\mathcal{A}=\emptyset\}\;.\] (13)```
1:Step 1: Identify mixture ancestors
2:for\(i\in\mathbf{V}\)do
3: Intervene on \(\mathcal{I}=\{i\}\), observe samples from \(p_{\mathrm{m},\mathcal{I}}\)
4:\(\mathrm{\hat{de}}(i)\leftarrow\{j:X_{j}\not\perp X_{i}\ \ \mathrm{in}\ \ p_{\mathrm{m},\mathcal{I}}\}\)\(\triangleright\) mixture descendants of node \(i\)
5:for\(i\in\mathbf{V}\)do
6:\(\mathrm{\hat{an}}(i)\leftarrow\{j:i\in\mathrm{\hat{de}}(j)\}\)\(\triangleright\) mixture ancestors of node \(i\)
7:Repeat Steps 2, 3, 4 for all \(i\in\mathbf{V}\)
8:Step 2: Obtain cycle-free descendants
9: Find cycles among \(\mathrm{\hat{an}}(i)\)
10:\(\mathcal{C}(i)\leftarrow\{\pi=(\pi_{1},\ldots,\pi_{t+1})\ :\ \pi_{1}=\pi_{t+1}\, \forall u\in[t]\ \ \pi_{u}\in\mathrm{\hat{an}}(i)\ \land\ \pi_{u}\in\mathrm{\hat{an}}(\pi_{u+1})\}\)
11:if\(\mathcal{C}(i)\) is empty then
12:\(\mathcal{B}(i)\leftarrow\emptyset\)
13:for\(j\in\mathrm{\hat{an}}(i)\)do
14:\(\mathrm{de}_{i}(j)\leftarrow\left\{\mathrm{\hat{de}}(j)\cap\mathrm{\hat{an}}(i )\right\}\cup\{i\}\)
15:else
16:\(\mathcal{B}(i)\leftarrow\) a minimal set such that \(\forall\pi\in\mathcal{C}(i)\ \left|\mathcal{B}(i)\cap\pi\right|\geq 1\)
17:for\(j\in\mathrm{\hat{an}}(i)\)do
18: Intervene on \(\mathcal{I}=\mathcal{B}(i)\cup\{j\}\)\(\triangleright\) break cycles among \(\mathrm{\hat{an}}(i)\)
19:\(\mathrm{de}_{i}(j)\leftarrow\{k\in\mathrm{\hat{an}}(i)\cup\{i\}:X_{j}\not \perp X_{k}\ \ \mathrm{in}\ \ p_{\mathrm{m},\mathcal{I}}\}\)\(\triangleright\) cycle-free descendants of node \(j\)
20:\(\mathcal{A}\leftarrow\{j\in\mathrm{\hat{an}}(i)\ :\ i\in\mathrm{de}_{i}(j)\}\)\(\triangleright\) refined ancestors
21:Step 3: Topological layering
22:\(t\gets 0\)
23:while\(\left|\mathcal{A}\right|\geq 1\)do
24:\(t\gets t+1\)
25:\(S_{t}(i)\leftarrow\{j\in\mathcal{A}:\mathrm{de}_{i}(j)\cap\mathcal{A}=\emptyset\}\)
26:\(\mathcal{A}\leftarrow\mathcal{A}\setminus S_{t}(i)\)
27:Step 4: Identify mixture parents
28:\(\mathrm{\hat{pa}}(i)\leftarrow\emptyset\)
29:for\(u\in(1,\ldots,t)\)do
30:for\(j\in S_{u}(i)\)do
31: Intervene on \(\mathcal{I}=\mathrm{\hat{pa}}(i)\cup\mathcal{B}(i)\cup\{j\}\)
32:if\(X_{j}\not\perp X_{i}\) in \(p_{\mathrm{m},\mathcal{I}}\)then
33:\(\mathrm{\hat{pa}}(i)\leftarrow\mathrm{\hat{pa}}(i)\cup\{j\}\)
34:Return\(\mathrm{\hat{pa}}(i)\) ```

**Algorithm 1** Causal Discovery from Interventions on Mixture Models (CADIM)

The construction of cycle-free descendant sets ensures that \(S_{1}(i)\) is not empty. Next, we update \(\mathcal{A}\leftarrow\mathcal{A}\setminus S_{1}(i)\) by removing layer \(S_{1}(i)\) to conclude the first step. Then, we iteratively construct the layers \(S_{u}(i)=\{j\in\mathcal{A}:\mathrm{\hat{de}}(j)\cap\mathcal{A}=\emptyset\}\) and update \(\mathcal{A}\leftarrow\mathcal{A}\setminus S_{u}(i)\) as in Line 26 of the algorithm. We continue until the set \(\mathcal{A}\) is exhausted, and denote these topological layers by \(\{S_{1}(i),\ldots,S_{t}(i)\}\).

Step 4: Identifying the mixture parents.Finally, we process the topological layers sequentially to identify the mixture parents in each layer. For a node \(j\in S_{1}(i)\), whether \(j\in\mathrm{pa}_{\mathrm{m}}(i)\) can be determined from a marginal independence test on \(p_{\mathrm{m},\mathcal{I}}\) where \(\mathcal{I}=\mathcal{B}(i)\cup\{j\}\). Leveraging this result, when processing each \(S_{u}(i)\), we consider the nodes \(j\in S_{u}(i)\) sequentially and intervene on \(\mathcal{I}=\mathrm{\hat{pa}}(i)\cup\mathcal{B}(i)\cup\{j\}\), where \(\mathrm{\hat{pa}}(i)\) denotes the estimated mixture parents. Under this intervention, a statistical dependence implies a true edge from \(j\) to \(i\). Hence, we update the set \(\mathrm{\hat{pa}}(i)\) as follows.

\[\mathrm{\hat{pa}}(i)\leftarrow\mathrm{\hat{pa}}(i)\cup\{j\}\quad\text{if}\ \ X_{j}\not\perp X_{i}\ \ \mathrm{in}\ p_{\mathrm{m},\mathcal{I}}\ \ \mathrm{where}\ \ \mathcal{I}=\mathrm{\hat{pa}}(i)\cup\mathcal{B}(i)\cup\{j\}\.\] (14)

After the last layer \(S_{t}(i)\) is processed, the algorithm returns the estimated mixture parents \(\mathrm{\hat{pa}}(i)\). By repeating Steps 2, 3, and 4 for all \(i\in\mathbf{V}\), we determine the true edges with their orientations.

### Guarantees of the CADIM algorithm

In this section, we establish the guarantees of the CADIM algorithm and interpret them vis-a-vis the results in Section 3. We start by providing the following result to show the correctness of identifying mixture ancestors.

**Lemma 3**.: _Given \(\mathcal{I}\)-mixture faithfulness, Step 1 of Algorithm 1 identifies \(\{\mathrm{an}_{\mathrm{m}}(i):i\in[n]\}\) using \(n\) single-node interventions._

Note that the mixture ancestor sets \(\{\mathrm{an}_{\mathrm{m}}(i)\}\) do not imply a topological order over the nodes \(\mathbf{V}\), e.g., there may exist nodes \(u,v\) such that \(u\in\mathrm{an}_{\mathrm{m}}(v)\) and \(v\in\mathrm{an}_{\mathrm{m}}(u)\). As such, a major difficulty in learning a mixture of DAGs compared to learning a single DAG is the possible cyclic relationships formed by the combination of components of the mixture. Recall that the breaking set is specified in (11) to treat such possible cycles carefully. We refer to the size of \(\mathcal{B}(i)\) as the _cyclic complexity number_ of node \(i\), denoted by \(\tau_{i}\), and the size of the largest breaking set by \(\tau_{\mathrm{m}}\) as

\[\tau_{i}\triangleq\left|\mathcal{B}(i)\right|,\quad\forall i\in\mathbf{V}\;, \qquad\text{and}\quad\tau_{\mathrm{m}}\triangleq\max_{i\in\mathbf{V}}\tau_{i}\;.\] (15)

Note that \(\tau_{i}\) is readily bounded by the number of cycles in \(\mathcal{C}(i)\). Next, we analyze the guarantees of the algorithm for a node \(i\) in two cases: \(\tau_{i}=0\) (cycle-free case) and \(\tau_{i}\geq 1\) (nonzero cyclic complexity).

Cycle-free case.Our next result shows that if \(\tau_{i}=0\), i.e., there are no cycles among the nodes in \(\mathrm{an}_{\mathrm{m}}(i)\), then we identify the mixture parents \(\mathrm{pa}_{\mathrm{m}}(i)\), i.e., the union of the nodes that are parents of \(i\) in at least one component DAG, using interventions with the optimal size.

**Theorem 3** (Guarantees for cycle-free ancestors).: _If the cyclic complexity of node \(i\) is zero, then Algorithm 1 ensures that \(\mathrm{\tilde{pa}}(i)=\mathrm{pa}_{\mathrm{m}}(i)\) by using \(|\mathrm{an}_{\mathrm{m}}(i)|\) interventions where the size of each intervention is at most \(|\mathrm{pa}_{\mathrm{m}}(i)|+1\)._

Theorem 3 shows that by repeating the algorithm steps for each node \(i\in\mathbf{V}\), we can identify all true edges with their orientations using \(n+\sum_{i\in\mathbf{V}}|\mathrm{an}_{\mathrm{m}}(i)|\leq n+n(n-1)=n^{2}\) interventions, where the size of each intervention is bounded by the worst-case necessary size established in Theorem 1.

Nonzero cyclic complexity.Finally, we address the most general case, in which the mixture ancestors of node \(i\) might contain cycles. In this case, our algorithm performs additional interventions to break the cycles among \(\mathrm{an}_{\mathrm{m}}(i)\). Hence, the number and size of the interventions will be greater than the cycle-free case, which is established in the following result.

**Theorem 4** (Guarantees for general mixtures).: _Algorithm 1 ensures that \(\mathrm{\tilde{pa}}(i)=\mathrm{pa}_{\mathrm{m}}(i)\) by using \(|\mathrm{an}_{\mathrm{m}}(i)|\) interventions with size \(\tau_{i}+1\), and \(|\mathrm{an}_{\mathrm{m}}(i)|\) interventions with size at most \(|\mathrm{pa}_{\mathrm{m}}(i)|+\tau_{i}+1\)._

Theorem 4 shows that, Algorithm 1 achieves the causal discovery objectives by using a total of \(n+2\sum_{i\in\mathbf{V}}|\mathrm{an}_{\mathrm{m}}(i)|\leq n+2n(n-1)=\mathcal{ O}(n^{2})\) interventions, where the maximum intervention size for learning each \(\mathrm{pa}_{\mathrm{m}}(i)\) is at most \(\tau_{i}\) larger than the necessary and sufficient size \(|\mathrm{pa}_{\mathrm{m}}(i)|+1\). This optimality gap reflects the challenges of accommodating cyclic relationships in intervention design for learning in mixtures while also maintaining a quadratic number of interventions \(\mathcal{O}(n^{2})\).

## 5 Experiments

We evaluate the performance of Algorithm 1 for estimating the true edges in a mixture of DAGs using synthetic data and investigate the need for interventions, the effect of the graph size, and the cyclic complexity. Additional results for varying the number of components, parameterization, and number of samples are provided in Appendix E1.

Footnote 1: The codebase for the experiments can be found at https://github.com/bvariici/intervention-mixture-DAG.

**Experimental setup.** We use an Erdos-Renyi model \(G(n,p)\) with density \(p=2/n\) to generate the component DAGs \(\{\mathcal{G}_{\ell}:\ell\in[K]\}\) for different values of nodes \(n\) and mixture components \(K\). We adopt linear structural equation models (SEMs) with Gaussian noise for the causal models, in which the noise for node \(i\) is sampled from \(\mathcal{N}(\mu_{i},\sigma_{i}^{2})\) where \(\mu_{i}\) is sampled uniformly in \([-1,1]\) and \(\sigma_{i}^{2}\) is sampled uniformly in \([0.5,1.5]\). The edge weights are sampled uniformly in \(\pm[0.25,2]\). Weconsider the case where a change in the conditional distribution of node \(i\) is only caused by changes in the parents of \(i\) across different DAGs. We use a partial correlation test to check (conditional) independence in the algorithm steps, similar to the related work [10; 11]. We repeat this procedure for \(100\) randomly generated DAG mixtures for each of the following settings.

**Need for interventions.** We demonstrate the need for interventions for learning the skeleton in the mixture of DAGs, unlike the case of single DAGs. To this end, we consider a mixture of \(K=2\) DAGs and learn the inseparable node pairs via exhaustive CI tests (see Algorithm 2 in Appendix E). Figure 1(a) empirically verifies the claim that true edges (even their undirected versions) cannot be learned using observational data only.

**Recovery of true edges.** We evaluate the performance of Algorithm 1 on the central task of learning the true edges in the mixture. For this purpose, we report average precision and recall rates for recovering [the true edges. We look into the performance of Algorithm 1 under a varying number of nodes \(n\in[5,30]\) for a mixture of \(K=3\) DAGs and using \(5000\) samples from each DAG. Figure 1(b) demonstrates that Algorithm 1 maintains a strong performance even under \(n=30\) nodes. We provide additional results for the number of DAGs in the range \(K\in[2,10]\) and varying number of samples in Appendix E.

**Quantification of cyclic complexity.** We recall that for finding the mixture parents of a node \(i\), the maximum size of the intervention used in Algorithm 1 is at most \(\tau_{i}\), i.e., cyclic complexity, larger than the necessary size. In Figure 1(c), we plot the empirical values of average cyclic complexity - both the ground truth and estimated by the algorithm. Figure 1(c) shows that even though average \(\tau_{i}\) increases with \(K\), it still remains very small, e.g., approximately \(1.5\) for a mixture of \(K=3\) DAGs with \(n=10\) nodes. Furthermore, on average, the estimated \(\tau_{i}\) values used in the algorithm are almost identical to the ground truth \(\tau_{i}\). Therefore, Algorithm 1 maintains its close to optimal intervention size guarantees in the finite-sample regime.

## 6 Conclusion

In this paper, we have conducted the first analysis of using interventions to learn causal relationships in a mixture of DAGs. First, we have established the matching necessary and sufficient size of interventions needed for learning the true edges in a mixture. Subsequently, guided by this result, we have designed an algorithm that learns the true edges using interventions with close to optimal sizes. We have also analyzed the optimality gap of our algorithm in terms of the cyclic relationships within the mixture model. The proposed algorithm uses a total of \(\mathcal{O}(n^{2})\) interventions. Establishing lower bounds for the number of interventions with constrained sizes remains an important direction for future work, which can draw connections to intervention design for single-DAG and further characterize the differences of causal discovery in mixtures. Finally, generalizing the mixture model to accommodate partial knowledge of the underlying domains can be useful in disciplines where such knowledge can be acquired a priori.

## Acknowledgments and disclosure of funding

This work was supported by IBM through the IBM-Rensselaer Future of Computing Research Collaboration.

Figure 2: Mean true edge recovery rates and quantification of mean cyclic complexity of a node.

## References

* Friedman et al. [2000] Nir Friedman, Michal Linial, Iftach Nachman, and Dana Pe'er. Using Bayesian networks to analyze expression data. In _Proc. International Conference on Computational Molecular Biology_, Tokyo, Japan, April 2000.
* Meinshausen et al. [2016] Nicolai Meinshausen, Alain Hauser, Joris M Mooij, Jonas Peters, Philip Versteeg, and Peter Buhlmann. Methods for causal inference from gene perturbation experiments and validation. _Proceedings of the National Academy of Sciences_, 113(27):7361-7368, 2016.
* Imbens [2020] Guido W Imbens. Potential outcome and directed acyclic graph approaches to causality: Relevance for empirical practice in economics. _Journal of Economic Literature_, 58(4):1129-1179, 2020.
* Reid et al. [2017] Brett M Reid, Jennifer B Permuth, and Thomas A Sellers. Epidemiology of ovarian cancer: A review. _Cancer Biology & Medicine_, 14(1):9, 2017.
* Chen and Poor [2022] Yanxi Chen and H. Vincent Poor. Learning mixtures of linear dynamical systems. In _Proc. International Conference on Machine Learning_, Baltimore, Maryland, July 2022.
* Bulteel et al. [2016] Kirsten Bulteel, Francis Tuerlinckx, Annette Brose, and Eva Ceulemans. Clustering vector autoregressive models: Capturing qualitative differences in within-person dynamics. _Frontiers in Psychology_, 7:1540, 2016.
* Brunskill et al. [2009] Emma Brunskill, Bethany R. Leffler, Lihong Li, Michael L. Littman, and Nicholas Roy. Provably efficient learning with typed parametric models. _Journal of Machine Learning Research_, 10(68):1955-1988, 2009.
* Spirtes [1995] Peter Spirtes. Directed cyclic graphical representations of feedback models. In _Proc. Conference on Uncertainty in Artificial Intelligence_, Montreal, Canada, August 1995.
* Strobl [2023] Eric V. Strobl. Causal discovery with a mixture of dags. _Machine Learning_, 112(11):4201-4225, 2023.
* Saeed et al. [2020] Basil Saeed, Snigdha Panigrahi, and Caroline Uhler. Causal structure discovery from distributions arising from mixtures of dags. In _Proc. International Conference on Machine Learning_, virtual, July 2020.
* Varci et al. [2024] Burak Varci, Dmitriy Katz, Dennis Wei, Prasanna Sattigeri, and Ali Tajer. Separability analysis for causal discovery in mixture of DAGs. _Transactions on Machine Learning Research_, 2024. ISSN 2835-8856. URL https://openreview.net/forum?id=ALRWXT1RLZ.
* Verma and Pearl [1992] Thomas Verma and Judea Pearl. An algorithm for deciding if a set of observed independencies has a causal explanation. In _Proc. Conference on Uncertainty in Artificial Intelligence_, Stanford, CA, July 1992.
* Eberhardt and Scheines [2007] Frederick Eberhardt and Richard Scheines. Interventions and causal inference. _Philosopy of Science_, 74(5):981-995, December 2007.
* Hauser and Buhlmann [2014] Alain Hauser and Peter Buhlmann. Two optimal strategies for active learning of causal models from interventional data. _International Journal of Approximate Reasoning_, 55(4):926-939, June 2014.
* Hyttinen et al. [2013] Antti Hyttinen, Frederick Eberhardt, and Patrik O Hoyer. Experiment selection for causal discovery. _Journal of Machine Learning Research_, 14(1):3041-3071, 2013.
* Shanmugam et al. [2015] Karthikeyan Shanmugam, Murat Kocaoglu, Alexandros G Dimakis, and Sriram Vishwanath. Learning causal graphs with small interventions. In _Proc. Advances in Neural Information Processing Systems_, Montreal, Canada, December 2015.
* Squires et al. [2020] Chandler Squires, Sara Magliacane, Kristjan Greenewald, Dmitriy Katz, Murat Kocaoglu, and Karthikeyan Shanmugam. Active structure learning of causal DAGs via directed clique trees. In _Proc. Advances in Neural Information Processing Systems_, December 2020.

* [18] Sumanth Varambally, Yi-An Ma, and Rose Yu. Discovering mixtures of structural causal models from time series data. _arXiv:2310.06312_, 2023.
* [19] Murat Kocaoglu, Karthikeyan Shanmugam, and Elias Bareinboim. Experimental design for learning causal graphs with latent variables. _Proc. Advances in Neural Information Processing Systems_, December 2017.
* [20] Raghavendra Addanki, Shiva Kasiviswanathan, Andrew McGregor, and Cameron Musco. Efficient intervention design for causal discovery with latents. In _Proc. International Conference on Machine Learning_, July 2020.
* [21] Raghavendra Addanki, Andrew McGregor, and Cameron Musco. Intervention efficient algorithms for approximate learning of causal graphs. In _Algorithmic Learning Theory_, March 2021.
* [22] Yang-Bo He and Zhi Geng. Active learning of causal networks with intervention experiments and optimal designs. _Journal of Machine Learning Research_, 9(November):2523-2547, 2008.
* [23] Kristjan Greenewald, Dmitriy Katz, Karthikeyan Shanmugam, Sara Magliacane, Murat Kocaoglu, Enric Boix Adsera, and Guy Bresler. Sample efficient active learning of causal trees. In _Proc. Advances in Neural Information Processing Systems_, Vancouver, Canada, December 2019.
* [24] Vibhor Porwal, Piyush Srivastava, and Gaurav Sinha. Almost optimal universal lower bound for learning causal dags with atomic interventions. In _Proc. International Conference on Artificial Intelligence and Statistics_, virtual, March 2022.
* [25] Davin Choo, Kirankumar Shiragur, and Arnab Bhattacharyya. Verification and search algorithms for causal dags. In _Proc. Advances in Neural Information Processing Systems_, New Orleans, LA, December 2022.
* [26] Murat Kocaoglu, Alex Dimakis, and Sriram Vishwanath. Cost-optimal learning of causal graphs. In _Proc. International Conference on Machine Learning_, Sydney, Australia, August 2017.
* [27] Erik Lindgren, Murat Kocaoglu, Alexandros G Dimakis, and Sriram Vishwanath. Experimental design for cost-aware learning of causal graphs. In _Proc. Advances in Neural Information Processing Systems_, Montreal, Canada, December 2018.
* [28] Ehsan Mokhtarian, Saber Salehkaleybar, AmirEmad Ghassami, and Negar Kiyavash. A unified experiment design approach for cyclic and acyclic causal models. _Journal of Machine Learning Research_, 24(354):1-31, 2023.
* [29] Karren Yang, Abigail Katcoff, and Caroline Uhler. Characterizing and learning equivalence classes of causal DAGs under interventions. In _Proc. International Conference on Machine Learning_, Stockholm, Sweden, July 2018.
* [30] Amin Jaber, Murat Kocaoglu, Karthikeyan Shanmugam, and Elias Bareinboim. Causal discovery from soft interventions with unknown targets: Characterization and learning. In _Proc. Advances in Neural Information Processing Systems_, December 2020.
* [31] Chandler Squires, Yuhao Wang, and Caroline Uhler. Permutation-based causal structure learning with unknown intervention targets. In _Proc. Conference in Uncertainty in Artificial Intelligence_, August 2020.
* [32] Philippe Brouillard, Sebastien Lachapelle, Alexandre Lacoste, Simon Lacoste-Julien, and Alexandre Drouin. Differentiable causal discovery from interventional data. In _Proc. Advances in Neural Information Processing Systems_, December 2020.
* [33] Bo Thiesson, Christopher Meek, David Maxwell Chickering, and David Heckerman. Learning mixtures of DAG models. In _Proc. Conference on Uncertainty in Artificial Intelligence_, Madison, WI, July 1998.
* [34] Biwei Huang, Kun Zhang, Pengtao Xie, Mingming Gong, Eric P Xing, and Clark Glymour. Specific and shared causal relation modeling and mechanism-based clustering. In _Proc. Advances in Neural Information Processing Systems_, Vancouver, Canada, December 2019.

* [35] Kun Zhang and Madelyn RK Glymour. Unmixing for causal inference: Thoughts on Mccaffrey and Danks. _The British Journal for the Philosophy of Science_, 2020.
* [36] Wei Chen, Yunjin Wu, Ruichu Cai, Yueguo Chen, and Zhifeng Hao. CCSL: A causal structure learning method from multiple unknown environments. _arXiv:2111.09666_, 2021.
* [37] Alex Markham, Richeek Das, and Moritz Grosse-Wentrup. A distance covariance-based kernel for nonlinear causal clustering in heterogeneous populations. In _Proc. Conference on Causal Learning and Reasoning_, Eureka, CA, April 2022.
* [38] Biwei Huang, Kun Zhang, Jiji Zhang, Joseph D Ramsey, Ruben Sanchez-Romero, Clark Glymour, and Bernhard Scholkopf. Causal discovery from heterogeneous/nonstationary data. _Journal of Machine Learning Research_, 21(89):1-53, 2020.
* [39] Kun Zhang, Biwei Huang, Jiji Zhang, Clark Glymour, and Bernhard Scholkopf. Causal discovery from nonstationary/heterogeneous data: Skeleton estimation and orientation determination. In _Proc. International Joint Conference on Artificial Intelligence_, Melbourne, Australia, August 2017.
* [40] Joris M. Mooij, Sara Magliacane, and Tom Claassen. Joint causal inference from multiple contexts. _Journal of Machine Learning Research_, 21(99):1-108, 2020.
* [41] Amin Jaber, Murat Kocaoglu, Karthikeyan Shanmugam, and Elias Bareinboim. Causal discovery from soft interventions with unknown targets: Characterization and learning. In _Proc. Advances in Neural Information Processing Systems_, virtual, December 2020.
* [42] Chenxi Liu and Kun Kuang. Causal structure learning for latent intervened non-stationary data. In _Proc. International Conference on Machine Learning_, Honolulu, Hawaii, July 2023.
* [43] Peter Spirtes, Clark N Glymour, Richard Scheines, and David Heckerman. _Causation, Prediction, and Search_. MIT Press, Cambridge, MA, 2000.
* [44] Judea Pearl. _Causality_. Cambridge University Press, Cambridge, UK, 2009.
* [45] Joris M Mooij and Tom Claassen. Constraint-based causal discovery using partial ancestral graphs in the presence of cycles. In _Proc. Conference on Uncertainty in Artificial Intelligence_, virtual, August 2020.
* [46] F Ann Ran, Patrick D Hsu, Jason Wright, Vineeta Agarwala, David A Scott, and Feng Zhang. Genome engineering using the crispr-cas9 system. _Nature Protocols_, 8(11):2281-2308, 2013.
* [47] Geoffrey J McLachlan, Sharon X Lee, and Suren I Rathnayake. Finite mixture models. _Annual Review of Statistics and Its Application_, 6(1):355-378, 2019.
* [48] Abhinav Kumar and Gaurav Sinha. Disentangling mixtures of unknown causal interventions. In _Proc. Uncertainty in Artificial Intelligence_, July 2021.

## Appendix A Auxiliary results

**Lemma 4** (Markov property, [10, Theorem 3.2]).: _Let \(A,B,C\subseteq\mathbf{V}\) be disjoint. If \(\bar{A}\) and \(\bar{B}\) are \(d\)-separated given \(\bar{C}\) in the mixture DAG, then \(X_{A}\) and \(X_{B}\) are conditionally independent given \(X_{C}\) in mixture distribution._

**Lemma 5** ([11, Theorem 5]).: _Consider nodes \(i,j\in\mathbf{V}\) such that \(i\) and \(j\) are not adjacent in any of the component DAGs, i.e., \(i\notin\mathrm{pa}_{\mathrm{m}}(j)\) and \(j\notin\mathrm{pa}_{\mathrm{m}}(i)\)._

1. _If_ \(i\in\Delta\) _and_ \(j\in\Delta\)_:_ \(i\) _and_ \(j\) _are always inseparable, i.e.,_ \((i-j)\) _is an emergent edge._
2. _If_ \(i\notin\Delta\) _and_ \(j\notin\Delta\)_: If_ \(i\) _and_ \(j\) _are inseparable, then there exist two component DAGs_ \(\mathcal{G}_{\ell}\)_,_ \(\mathcal{G}_{\ell^{\prime}}\) _such that_ \(\mathcal{G}_{\ell}\) _contains a_ \(\Delta\)_-through path from_ \(i\) _to_ \(j\) _and_ \(\mathcal{G}_{\ell^{\prime}}\) _contains a_ \(\Delta\)_-through path from_ \(j\) _to_ \(i\)_._
3. _If_ \(i\notin\Delta\) _and_ \(j\in\Delta\)_: If_ \(i\) _and_ \(j\) _are inseparable, then at least one component DAG contains a_ \(\Delta\)_-through path from_ \(i\) _to_ \(j\)_._

**Lemma 6** ([11, Theorem 6]).: _Suppose that \(\mathcal{G}_{1},\ldots,\mathcal{G}_{K}\) are directed trees. Consider nodes \(i,j\in\mathbf{V}\) such that \(i\) and \(j\) are not adjacent in any component DAG, i.e., \(i\notin\mathrm{pa}_{\mathrm{m}}(j)\) and \(j\notin\mathrm{pa}_{\mathrm{m}}(i)\)._

1. _If_ \(i\in\Delta\) _and_ \(j\in\Delta\)_:_ \(i\) _and_ \(j\) _are always inseparable._
2. _If_ \(i\notin\Delta\) _and_ \(j\notin\Delta\)_:_ \(i\) _and_ \(j\) _are separable if and only if there does not exist_ \(\mathcal{G}_{\ell}\)_,_ \(\mathcal{G}_{\ell^{\prime}}\) _such that the two DAGs contain_ \(\Delta\)_-child-through paths between_ \(i\) _and_ \(j\) _in opposite directions._
3. _If_ \(i\notin\Delta\) _and_ \(j\in\Delta\)_:_ \(i\) _and_ \(j\) _are separable if and only if none of the component DAGs contains a_ \(\Delta\)_-child-through path from_ \(i\) _to_ \(j\)Proofs for Section 3

### Proof of Lemma 1

**Proof of identifiability:** Since \(j\in\mathcal{I}\), we have \(j\notin\Delta_{\mathcal{I}}\). Then, Lemma 5 (iii) implies that if \((j\to i)\) is not a true edge and there does not exist a \(\Delta\)-through path from \(j\) to \(i\) in any \(\mathcal{G}_{\ell,\mathcal{I}}\), then \(i\) and \(j\) are separable in \(p_{\mathrm{m},\mathcal{I}}\). Consequently, whether \(j\in\mathrm{pa}_{\mathrm{m}}(i)\) can be determined from \(p_{\mathrm{m},\mathcal{I}}\).

**Proof of non-identifiability:** First, note that using Lemma 4, for any intervention \(\mathcal{I}\), \(p_{\mathrm{m},\mathcal{I}}\) is Markov with respect to the \(\mathcal{I}\)-mixture DAG \(\mathcal{G}_{\mathrm{m},\mathcal{I}}\). Then, for \(j\in\Delta_{\mathcal{I}}\), if also \(i\in\Delta_{\mathcal{I}}\), \(i\) and \(j\) are inseparable in \(p_{\mathrm{m},\mathcal{I}}\) regardless of whether there is a true edge between \(i\) and \(j\). Hence, whether \(j\in\mathrm{pa}_{\mathrm{m}}(i)\) cannot be determined using CI tests on \(p_{\mathrm{m},\mathcal{I}}\). For the second statement, recall that intervention \(\mathcal{I}\) cuts off all incoming edges to nodes of \(\mathcal{I}\) in all component DAGs. Then, if \(i\in\mathcal{I}\), we cannot determine whether \(j\in\mathrm{pa}_{\mathrm{m}}(i)\) since the possible influence of \(j\) on \(i\) is cut off by the intervention. Suppose that \(i\in\Delta_{\mathcal{I}}\), and let \(\pi\) be a \(\Delta\)-child-through path from \(j\) to \(i\) in some component DAG \(\mathcal{G}_{\ell,\mathcal{I}}\), i.e., \(\pi\) is given by \(j\stackrel{{\ell}}{{\rightarrow}}k\stackrel{{\ell}}{{ \leftrightarrow}}i\) for some \(k\in\Delta_{\mathcal{I}}\). Since \(i\in\Delta_{\mathcal{I}}\), the \(\mathcal{I}\)-mixture DAG \(\mathcal{G}_{\mathrm{m},\mathcal{I}}\) also contains the path \(j\stackrel{{\ell}}{{\rightarrow}}k\stackrel{{\ell}}{{ \leftarrow}}y\stackrel{{\ell}}{{\rightarrow}}i\). Since these two paths cannot be blocked simultaneously by conditioning on a set of nodes, \(i\) and \(j\) are inseparable regardless of whether \(j\in\mathrm{pa}_{\mathrm{m}}(i)\). Therefore, whether \(j\in\mathrm{pa}_{\mathrm{m}}(i)\) cannot be determined using CI tests on \(p_{\mathrm{m},\mathcal{I}}\).

### Proof of Lemma 2

We start by providing a general statement that will be used for the proof of the three subcases. Let \(\mathcal{I}\) be an intervention such that \(j\in\mathcal{I}\) and there does not exist a \(\Delta\)-through path from \(j\) to \(i\) in any component DAG \(\mathcal{G}_{\ell,\mathcal{I}}\). In this case, using Lemma 5, if \((j\to i)\) is not a true edge, then \(i\) and \(j\) are separable in \(p_{\mathrm{m},\mathcal{I}}\). Subsequently, if \(i\) and \(j\) are inseparable in \(p_{\mathrm{m},\mathcal{I}}\), then \((j\to i)\) is a true edge.

Let \(\pi\) be a \(\Delta\)-through path from \(j\) to \(i\) in some \(\mathcal{G}_{\ell,\mathcal{I}}\). Note that, for any of the following three intervention sets,

1. \(\mathcal{I}=\{j\}\cup\bigcup\limits_{\ell\in[K]}\left\{\mathrm{pa}_{\ell}(i) \cap\mathrm{de}_{\ell}(j)\right\}\enspace,\)
2. \(\mathcal{I}=\{j\}\cup\bigcup\limits_{\ell\in[K]}\left\{\mathrm{a}_{\ell}(i) \cap\mathrm{ch}_{\ell}(j)\right\}\enspace,\)
3. \(\mathcal{I}=\{j\}\cup\bigcup\limits_{\ell\in[K]}\left\{\mathrm{a}_{\ell}(i) \cap\mathrm{de}_{\ell}(j)\cap\Delta\right\}\enspace,\)

\(\pi\) cannot contain a node between \(j\) and \(i\). Therefore, if \(j\notin\mathrm{pa}_{\mathrm{m}}(i)\), there does not exist a \(\Delta\)-through path from \(j\) to \(i\). Subsequently, if \(i\) and \(j\) are not separable in \(p_{\mathrm{m},\mathcal{I}}\) for any of these three interventions, it means there exists \(j\stackrel{{\ell}}{{\rightarrow}}i\) for some component DAG \(\mathcal{G}_{\ell}\). Therefore, whether \(j\in\mathrm{pa}_{\mathrm{m}}(i)\) can be determined by checking whether \(i\) and \(j\) are separable in \(p_{\mathrm{m},\mathcal{I}}\) for any of these three interventions.

### Proof of Theorem 1

The sufficiency result immediately follows from Lemma 2 since each of the three interventions in stated in Lemma 2 is a subset of \(\mathrm{pa}_{\mathrm{m}}(i)\cup\{j\}\). To show the worst-case necessity of an intervention with size at least \(|\mathrm{pa}_{\mathrm{m}}(i)|+1\), we construct the following example. Consider component DAGs \(\{\mathcal{G}_{\ell}:\ell\in[K]\}\) such that \(\mathcal{G}_{1}\) contains a single edge \(i\stackrel{{ 1}}{{\rightarrow}}j\). In the rest of the component DAGs, for any \(k\stackrel{{\ell}}{{\rightarrow}}i\) edge, let us also draw \(j\stackrel{{\ell}}{{\rightarrow}}k\). We do not put any constraints on the other possible connections in \(\{\mathcal{G}_{\ell}:\ell\in\{2,\dots,K\}\}\). Note that this construction yields that \(\mathrm{pa}_{\mathrm{m}}(i)\cup\{i,j\}\subseteq\Delta\). Consider the paths

\[j\stackrel{{ 1}}{{\leftarrow}}y\stackrel{{ 1}}{{\rightarrow}}i\enspace,\quad\text{and}\quad\{j\stackrel{{ \ell}}{{\rightarrow}}k\stackrel{{\ell}}{{\rightarrow}}i:k\in \mathrm{pa}_{\mathrm{m}}(i)\}\enspace.\] (16)

For any intervention \(\mathcal{I}\subseteq\mathbf{V}\setminus\{i\}\) that does not contain all nodes in \(\mathrm{pa}_{\mathrm{m}}(i)\cup\{j\}\), at least one of these paths will be active in the \(\mathcal{I}\)-mixture DAG \(\mathcal{G}_{\mathrm{m},\mathcal{I}}\), regardless of whether there exists a \(j\stackrel{{\ell}}{{\rightarrow}}i\), \(\ell\in\{2,\dots,K\}\) edge. Therefore, at the worst-case, whether \(j\in\mathrm{pa}_{\mathrm{m}}(i)\) cannot be determined from \(p_{\mathrm{m},\mathcal{I}}\) for any intervention \(\mathcal{I}\) with size \(|\mathcal{I}|\leq|\mathrm{pa}_{\mathrm{m}}(i)|\).

[MISSING_PAGE_FAIL:16]

[MISSING_PAGE_FAIL:17]

Finally, note that while processing each layer \(S_{u}(i)\), the algorithm uses \(|S_{u}(i)|\) interventions, one for each \(j\in S_{u}(i)\), with size \(|\mathcal{I}|=\left|\mathrm{pa}_{\mathrm{m}}(i)\cap\bigcup\limits_{k=1}^{u-1}S_{ k}(i)\right|+1\). This is upper bounded by \(|\mathrm{pa}_{\mathrm{m}}(i)|+1\), which is shown to be the worst-case necessary intervention size in Theorem 1. Then, including \(n\) single-node interventions performed in Step 1, for identifying \(\mathrm{pa}_{\mathrm{m}}(i)\) for all \(i\in\mathbf{V}\), Algorithm 1 uses a total of

\[n+\sum_{i=1}^{n}\sum_{u=1}^{t}|S_{u}(i)|=n+\sum_{i=1}^{n}|\mathrm{ an}_{\mathrm{m}}(i)|=\mathcal{O}(n^{2})\] (30)

interventions, which completes the proof of the theorem.

### Proof of Theorem 4

We start by giving a synopsis of the proof. Lemma 3 ensures that Step 1 of Algorithm 1 identifies \(\mathrm{an}_{\mathrm{m}}(i)\) and \(\mathrm{de}_{\mathrm{m}}(i)\) correctly for all \(i\in\mathbf{V}\). Hence, in this proof we use \(\mathrm{an}_{\mathrm{m}}(i)\) and \(\mathrm{de}_{\mathrm{m}}(i)\) for \(\mathrm{an}(i)\) and \(\mathrm{de}_{\mathrm{m}}(i)\), respectively. In this theorem, we consider the most general case in which the nodes in mixture ancestors \(\mathrm{an}_{\mathrm{m}}(i)\) can form cycles via their mixture ancestral relationships. These cycles will be accommodated by the procedure in Step 2. Intuitively, by intervening on a small number of nodes, we can break all the cycles in \(\mathcal{C}(i)\) in the new interventional mixture graphs. Then, we would be able to follow Steps 3 and 4 similarly to the proof of Theorem 3, albeit using interventions with larger sizes.

Step 2.First, we recall the definition of cycles among mixture ancestors of \(i\),

\[\mathcal{C}(i)\leftarrow\{\pi=(\pi_{1},\ldots,\pi_{\ell})\ :\ \pi_{1}=\pi_{\ell}\, \forall u\in[\ell-1]\ \ \pi_{u}\in\mathrm{\hat{an}}(i)\ \land\ \pi_{u}\in\mathrm{\hat{an}}(\pi_{u+1})\}\,\] (31)

and the associated breaking set,

\[\mathcal{B}(i)\triangleq\text{a minimal set s.t.}\ \ \forall\pi\in \mathcal{C}(i),\ \ |\mathcal{B}(i)\cap\pi|\geq 1\.\] (32)

We denote the size of the breaking set by \(\tau_{i}\triangleq|\mathcal{B}(i)|\) and refer to it as the _cyclic complexity_ of node \(i\). The intervention \(\mathcal{I}=\mathcal{B}(i)\) breaks all cycles in \(\mathcal{C}(i)\). To see this consider a cycle \(\pi=(\pi_{1},\ldots,\pi_{\ell})\) in \(\mathcal{C}(i)\) and suppose that \(pi_{u}\in\mathcal{B}(i)\). Then, intervening on \(\pi_{u}\) breaks all causal paths from \(\pi_{u-1}\) to \(\pi_{u}\), which breaks the cycle. In Step 2, we leverage this property to obtain _cycle-free_ descendants of each node \(j\in\mathrm{an}_{\mathrm{m}}(i)\). Specifically, for each each \(j\in\mathrm{an}_{\mathrm{m}}(i)\), we intervene on \(\mathcal{I}=\mathcal{B}(i)\cup\{j\}\) and set

\[\mathrm{de}_{i}(j)=\{k\in\mathrm{an}_{\mathrm{m}}(i)\cup\{i\}:X_{j}\not \perp\!\!\!\perp X_{k}\ \ \text{in}\ \ p_{\mathrm{m},\mathcal{I}}\}\.\] (33)

Note that if \(j\in\mathrm{pa}_{\mathrm{m}}(i)\), then \(i\in\mathrm{de}_{i}(j)\). Hence, after constructing these cycle-free descendant sets, we refine the ancestor set

\[\mathcal{A}=\{j\in\mathrm{an}_{\mathrm{m}}(i):i\in\mathrm{de}_{i}( j)\}\,\] (34)

which contains all \(\mathrm{pa}_{\mathrm{m}}(i)\). We will use induction to prove that topological layering in Step 3 and the sequential interventions on Step 4 ensure to identify \(\mathrm{pa}_{\mathrm{m}}(i)\) from \(\mathcal{A}\).

Base case.Consider \(S_{1}(i)\) defined as

\[S_{1}(i)=\{j\in\mathcal{A}:\mathrm{de}_{i}(j)\cap\mathcal{A}= \emptyset\}\.\] (35)

First, we show that \(S_{1}(i)\) is not empty. Otherwise, starting from a node \(\pi_{1}\in\mathcal{A}\), we would have

\[\mathrm{de}_{i}(\pi_{1})\cap\mathcal{A}\neq\emptyset \implies \exists\ \pi_{2}\in\mathrm{de}_{i}(\pi_{1})\cap\mathcal{A}\] (36) \[\mathrm{de}_{i}(\pi_{2})\cap\mathcal{A}\neq\emptyset \implies \exists\ \pi_{3}\in\mathrm{de}_{i}(\pi_{2})\cap\mathcal{A}\] (37) \[\vdots\] (38) \[\mathrm{de}_{i}(\pi_{\ell})\cap\mathcal{A}\neq\emptyset \implies \exists\ \pi_{1}\in\mathrm{de}_{i}(\pi_{\ell})\cap\mathcal{A}\] (39)

since \(\mathcal{A}\) has finite elements. However, this implies that none of the \(\{\pi_{1},\ldots,\pi_{\ell}\}\) are contained in \(\mathcal{B}(i)\) due to the construction of \(\mathrm{de}_{i}(j)\) sets with interventions \(\mathcal{I}=\mathcal{B}(i)\cup\{j\}\). This contradicts with the definition of the breaking set \(\mathcal{B}(i)\) as it does not contain any node from the cycle \(\{\pi_{1},\ldots,\pi_{\ell}\}\).

Next, consider a node \(j\in S_{1}(i)\) and intervene on \(\mathcal{I}=\mathcal{B}(i)\cup\{j\}\). We will show that

\[j\in\mathrm{pa}_{\mathrm{m}}(i)\quad\iff\quad X_{j}\not\perp\!\!\!\!\perp X_{i} \ \ \mathrm{in}\ \ p_{\mathrm{m},\mathcal{I}}\.\] (40)

If \(j\in\mathrm{pa}_{\mathrm{m}}(i)\), then by \(\mathcal{I}\)-mixture faithfulness, \(X_{j}\not\perp\!\!\!\!\perp X_{i}\) in \(p_{\mathrm{m},\mathcal{I}}\). We prove the other direction, that is \(X_{j}\not\perp\!\!\!\!\perp X_{i}\) in \(p_{\mathrm{m},\mathcal{I}}\) implies that \(j\in\mathrm{pa}_{\mathrm{m}}(i)\) as follows. First, note that \(X_{j}\not\perp\!\!\!\!\perp X_{i}\) in \(p_{\mathrm{m},\mathcal{I}}\) does not have a conditioning set. Then, it implies that there exists an active path \(j\stackrel{{\ell}}{{\rightsquigarrow}}i\) in \(\mathcal{G}_{\ell,\mathcal{I}}\) for some \(\ell\in[K]\). Suppose that \(j\notin\mathrm{pa}_{\mathrm{m}}(i)\), which implies that \(j\stackrel{{\ell}}{{\rightsquigarrow}}k\stackrel{{ \ell}}{{\rightsquigarrow}}i\) in \(\mathcal{G}_{\ell,\mathcal{I}}\), and \(k\notin\mathcal{B}(i)\) for path being active. However, in this case we have \(k\in\mathrm{de}_{i}(j)\cap\mathcal{A}\), which contradicts with \(j\in S_{1}(i)\) due to definition of \(S_{1}(i)\). Hence, for \(j\in S_{1}(i)\), \(X_{j}\not\perp\!\!\!\!\perp X_{i}\) in \(p_{\mathrm{m},\mathcal{I}}\) implies that \(j\in\mathrm{pa}_{\mathrm{m}}(i)\), which concludes the proof of the base case.

Induction step.Assume that we have identified the set \(S_{u}(i)\cap\mathrm{pa}_{\mathrm{m}}(i)\) correctly for \(u\in\{1,\ldots,v-1\}\). Let \(\mathcal{A}=\mathrm{an}_{\mathrm{m}}(i)\setminus\bigcup\limits_{k=1}^{v-1}S_{ k}(i)\) and consider \(S_{v}(i)\) defined as

\[S_{v}(i)=\{j\in\mathcal{A}:\mathrm{de}_{i}(j)\cap\mathcal{A}=\emptyset\}\.\] (41)

Note that, after processing \(\{S_{1},\ldots,S_{v-1}\}\) correctly, we have

\[\dot{\mathrm{pa}}(i)=\mathrm{pa}_{\mathrm{m}}(i)\cap\bigcup\limits_{k=1}^{v-1 }S_{k}(i)\.\] (42)

Consider a node \(j\in S_{v}(i)\) and intervene on

\[\mathcal{I}=\{j\}\cup\dot{\mathrm{pa}}(i)\cup\mathcal{B}(i)=\{j\}\cup \bigcup\limits_{k=1}^{v-1}S_{k}(i)\cap\mathrm{pa}_{\mathrm{m}}(i)\.\] (43)

We will show that

\[j\in\mathrm{pa}_{\mathrm{m}}(i)\quad\iff\quad X_{j}\not\perp\!\!\!\!\perp X_{i} \ \mathrm{in}\ \ p_{\mathrm{m},\mathcal{I}}\.\] (44)

If \(j\in\mathrm{pa}_{\mathrm{m}}(i)\), then by \(\mathcal{I}\)-mixture faithfulness, \(X_{j}\not\perp\!\!\!\perp X_{i}\) in \(p_{\mathrm{m},\mathcal{I}}\). We will prove the other direction, that is \(X_{j}\not\perp\!\!\!\perp X_{i}\) in \(p_{\mathrm{m},\mathcal{I}}\) implies \(j\in\mathrm{pa}_{\mathrm{m}}(i)\), similarly to the base case. First, note that \(X_{j}\not\perp\!\!\!\perp X_{i}\) in \(p_{\mathrm{m},\mathcal{I}}\) does not have a conditioning set. Then, it implies that there exists an active path \(j\stackrel{{\ell}}{{\rightsquigarrow}}i\) in \(\mathcal{G}_{\ell,\mathcal{I}}\) for some \(\ell\in[K]\). Now, suppose that \(j\notin\mathrm{pa}_{\mathrm{m}}(i)\), which implies that the active path has the form \(j\stackrel{{\ell}}{{\rightsquigarrow}}k\stackrel{{ \ell}}{{\rightsquigarrow}}i\) in \(\mathcal{G}_{\ell,\mathcal{I}}\) for some \(\ell\in[K]\) and \(k\notin\mathcal{I}\). Since \(k\in\mathrm{pa}_{\mathrm{m}}(i)\), \(k\notin\mathcal{I}\) implies that \(k\notin\bigcup\limits_{u=1}^{v-1}S_{u}(i)\). Then, we have \(k\in\mathrm{de}_{i}(j)\cap\mathcal{A}\), which contradicts with \(k\in S_{v}(i)\) due to definition of \(S_{v}(i)\). Therefore, for \(j\in S_{v}(i)\) and \(\mathcal{I}=\mathcal{B}(i)\cup\dot{\mathrm{pa}}(i)\cup\{j\}\), \(X_{j}\not\perp\!\!\!\perp X_{i}\) in \(p_{\mathrm{m},\mathcal{I}}\) implies that \(j\in\mathrm{pa}_{\mathrm{m}}(i)\), which concludes the proof of the induction step. Therefore, by induction, the algorithm identifies \(S_{u}\cap\mathrm{pa}_{\mathrm{m}}(i)\) correctly for all \(u\in\{1,\ldots,t\}\).

Finally, note that while processing each layer \(S_{u}(i)\), the algorithm uses \(|S_{u}(i)|\) interventions, one for each \(j\in S_{u}(i)\), with size \(|\mathcal{I}|=\left|\mathrm{pa}_{\mathrm{m}}(i)\cap\bigcup\limits_{k=1}^{u-1}S_ {k}(i)\right|+\mathcal{B}(i)+1\), where \(\tau_{i}=|\mathcal{B}(i)|\) is referred to as the cyclic complexity of node \(i\). Therefore, the size of the largest intervention set is

\[|\mathrm{pa}_{\mathrm{m}}(i)|+\tau_{i}+1\.\] (45)

We note that this upper bound on the intervention size is \(\tau_{i}\) larger than the necessary size \(|\mathrm{pa}_{\mathrm{m}}(i)|+1\) shown in Theorem 1. This optimality gap reflects the effect of the cyclic complexity of the problem. Finally, adding \(n\) single-node interventions performed in Step 1, for identifying \(\mathrm{pa}_{\mathrm{m}}(i)\) for all \(i\in\mathbf{V}\), Algorithm 1 uses a total of

\[n+\sum_{i=1}^{n}|\mathrm{an}_{\mathrm{m}}(i)|+\sum_{i=1}^{n}\sum_{u=1}^{t}|S_{u} (i)|=n+2\sum_{i=1}^{n}|\mathrm{an}_{\mathrm{m}}(i)|\leq 2n^{2}-n=\mathcal{O}(n^{2})\] (46)

interventions, which completes the proof of the theorem.

Additional examples

### Partitioning true edges into component DAGs

We have emphasized in Section 1 that the component DAGs of the mixture cannot be identified without further assumptions even under our interventional setting. We discuss a few examples of this matter.

1. Consider the following two mixtures of \(K=2\) DAGs * Mixture 1: Edge sets \(\mathbf{E}_{1}=\{1\to 2,1\to 3\}\) and \(\mathbf{E}_{2}=\emptyset\) * Mixture 2: Edge sets \(\mathbf{E}_{1}=\{1\to 2\}\) and \(\mathbf{E}_{2}=\{1\to 3\}\) In this case, distributions of the two mixtures can still be the same under all intervention sets \(\mathcal{I}\subseteq\{1,2,3\}\). Hence, without additional assumptions (e.g., model parameterization), we cannot distinguish the two mixtures via only conditional independence tests. Instead, we can only learn the set of true edges, \(\mathbf{E}_{\mathrm{t}}=\{1\to 2,1\to 3\}\) for both mixtures.
2. Consider a mixture of two DAGs with edge sets \(\mathbf{E}_{1}=\{1\to 2,2\to 3\}\) and \(\mathbf{E}_{2}=\{3\to 1\}\). Recall that in Stage 1 of Algorithm 1, we learn the mixture ancestors of the nodes as an intermediate step. Hence, after learning the set of true edges in the mixture via the rest of the algorithm, we have the following information: \[1\in\mathrm{an}_{\mathrm{m}}(3)\;,\;\;1\notin\mathrm{pa}_{ \mathrm{m}}(3),\;\;1\in\mathrm{pa}_{\mathrm{m}}(2)\;,\] (47) \[2\in\mathrm{pa}_{\mathrm{m}}(3)\;,\;\;2\notin\mathrm{an}_{ \mathrm{m}}(1)\;,\] (48) \[3\in\mathrm{pa}_{\mathrm{m}}(1)\;,\;\;3\notin\mathrm{an}_{ \mathrm{m}}(2)\] (49) Suppose that we know \(K=2\). Then, we can see that the only possible component DAGs that result in this mixture are \(\mathbf{E}_{1}=\{1\to 2,2\to 3\}\) and \(\mathbf{E}_{2}=\{3\to 1\}\). This is because \(3\to 1\) cannot be in the same DAG as the other two edges due to the known ancestral relationships. Hence, we learn the component DAGs in this case. However, without learning the true edges, we would not be able to know that we can learn the component DAGs of the mixture model.

These examples show that our work is a necessary first step into the interventional causal discovery of mixtures. Furthermore, we hope that it can inspire future work for the use of interventions in a mixture of models, e.g., establishing graphical conditions for (partial) recovery of individual DAGs, leveraging the side information.

Finally, we note two things regarding the possible side information that can enable stronger results. First, mixture distributions (the underlying component distributions \(p_{\ell}(x)\)s) can be identified under some assumptions, e.g., Gaussian mixture models [47]. Second, in a related line of work, disentangling mixtures of unknown interventional datasets is studied under specific conditions on the intervention sets and given the distribution of the observational DAG [48]. Establishing the necessary and sufficient conditions for achieving similar disentangling objectives tasks in our mixture model is an open problem for future work.

### An example of cyclic complexity

We have empirically quantified the average cyclic complexity in Section 5. In addition, we give a visual example here. Consider the mixture of two DAGs in Figure 3. By definition of mixture ancestors, we have

\[\mathrm{an}_{\mathrm{m}}(1) =\{2,5\}\;,\] (50) \[\mathrm{an}_{\mathrm{m}}(2) =\{3,5\}\;,\] (51) \[\mathrm{an}_{\mathrm{m}}(3) =\emptyset\;,\] (52) \[\mathrm{an}_{\mathrm{m}}(4) =\{1,2,3,5\},\] (53) \[\mathrm{an}_{\mathrm{m}}(5) =\{1,2\}\;.\] (54)Then, by definition of \(\mathcal{C}(i)\) in (10), we have

\[\mathcal{C}(1) =\{(2,5,2)\}\;,\] (55) \[\mathcal{C}(2) =\emptyset\;,\] (56) \[\mathcal{C}(3) =\emptyset\;,\] (57) \[\mathcal{C}(4) =\{(2,5,2),(2,1,5,2),(1,5,1)\},\] (58) \[\mathcal{C}(5) =\emptyset\;.\] (59)

Subsequently, an example of minimal breaking sets and cycle complexities are given by

\[\mathcal{B}(1) =\{2\} \implies\quad\tau_{1}=1\;,\] (60) \[\mathcal{B}(2) =\emptyset \implies\quad\tau_{2}=0\;,\] (61) \[\mathcal{B}(3) =\emptyset \implies\quad\tau_{3}=0\;,\] (62) \[\mathcal{B}(4) =\{5\} \implies\quad\tau_{4}=1\;,\] (63) \[\mathcal{B}(5) =\emptyset \implies\quad\tau_{5}=0\;.\] (64)

This example illustrates that even though the mixture model can contain many cycles, the cyclic complexity of the nodes can be small.

## Appendix E Additional experiments

Effect of the number of samples.For the same experimental setting in Section 5, we investigate the effect of the number of samples on the performance of Algorithm 1. Figure 3(a) demonstrates that the algorithm achieves almost perfect precision even with as few as \(s=1000\) samples under the parameterization described in Section 5. The recall rates are lower than the precision; however, when the number of samples is increased to \(s=10000\), the gap is closed, and the recall rates also become closer to perfect.

Varying the true edge weights.Recall that in Section 5, we have considered the case where the weight of a true edge is constant across the component DAGs it belongs to. However, our theory and algorithm can handle the general case, in which conditional distributions \(p_{\ell}(X_{i}\mid X_{\mathrm{pa}_{\ell}(i)})\) and \(p_{\ell^{\prime}}(X_{i}\mid X_{\mathrm{pa}_{\ell^{\prime}}(i)})\) can be different even if the parent sets \(\mathrm{pa}_{\ell}(i)=\mathrm{pa}_{\ell^{\prime}}(i)\) for two component DAGs \(\mathcal{G}_{\ell}\) and \(\mathcal{G}_{\ell^{\prime}}\). For instance, when considering a mixture of DAGs where \((1\to 2)\in\mathbf{E}_{1}\), \((1\to 2)\notin\mathbf{E}_{1}\), and \((1\to 2)\in\mathbf{E}_{3}\) relations, the edge weight from node \(1\) to node \(2\) can be different in \(\mathcal{G}_{1}\) and \(\mathcal{G}_{3}\). To investigate the performance of our algorithm in this general setting, we consider the following parameterization. When randomly generating the weight of a true edge \((i\to j)\in\mathbf{E}_{\text{t}}\), it has two options: (i) With probability \(0.5\), it is constant across the component DAGs it belongs to, (ii) with probability \(0.5\), it is different (randomly sampled) for every component DAG it belongs to. Figure 3(b) shows that the performance of the algorithm is virtually the same for this setting compared to the main setting considered in Section 5.

Skeleton (true edges) versus inseparable pairs.In Section 5, we demonstrate the need for interventions by learning inseparable pairs from observational mixture data and comparing them to the skeleton of the true edges. To learn the inseparable pairs specified in (5), we perform exhaustive conditional independent tests as in [11], summarized in Algorithm 2. Note that as mentioned in Section 4.1, this exhaustive search requires \(\mathcal{O}(n^{2}\cdot 2^{n})\) CI tests, which we perform only for this experiment setting and omit in our proposed Algorithm 1.

Figure 3: Sample DAGs for a mixture of two DAGs

```
1:Input: Samples from mixture distribution \(p_{\mathrm{m}}\)
2:Return: Inseparable pairs of the mixture \(\mathbf{E}_{\mathrm{i}}\)
3: Form complete undirected graph: \(\mathbf{E}_{\mathrm{i}}\leftarrow\{(i-j):i,j\in\mathbf{V}\}\)
4:for all \(i,j\in\mathbf{V}\)do
5:for all \(S\in\mathbf{V}\setminus\{i,j\}\)do
6:if\(X_{i}\perp\!\!\!\perp X_{j}\;\!\!\!\!\perp X_{S}\)then
7: Remove \((i-j)\) edge: \(\mathbf{E}_{\mathrm{M}}\leftarrow\mathbf{E}_{\mathrm{M}}\setminus(i-j)\), and \(\mathrm{SepSet}(i,j)\gets S\).
8:break
9:endif
10:endfor
11:endfor ```

**Algorithm 2** Mixture skeleton learning via observational data [11, Algorithm 1 - Stage 1]

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: Sections 3 and 4 establish the results claimed in the abstract and introduction. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: The limitations of the work are clarified throughout the paper and discussed in Section 6. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.

Figure 4: Additional experiment results for true edge recovery

* The authors are encouraged to create a separate "Limitations" section in their paper.
* The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.
* The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.
* The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.
* The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.
* If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.
* While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: The assumptions for the theoretical results are clearly stated in the theorem statements, and the proofs of the results are provided in Appendix B and C. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: The algorithm details are summarized in Algorithm 1, and described in Section 4. The experimental procedure is described in Section 5, and detailed parameterization is given in Appendix E. The code for reproducing the main experimental results can be found at https://github.com/bvarici/intervention-mixture-DAG. Guidelines: * The answer NA means that the paper does not include experiments.

* If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.
* If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.
* Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.
* While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: The code for reproducing the main experimental results can be found at https://github.com/bvarici/intervention-mixture-DAG. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).

* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: The experimental procedure is described in Section 5, and detailed parameterization is provided in Appendix E. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: The plots in all figures are given for an average of 100 experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors). * It should be clear whether the error bar is the standard deviation or the standard error of the mean. * It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified. * For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). * If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: Experiments are run on a single commercial CPU. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.

* The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.
* The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: The authors have reviewed the NeurIPS Code of Ethics and confirm that the research in this paper conforms with the code of ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: This paper is mostly theoretical and does not pose potential negative societal impacts. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. * If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: This paper is mostly theoretical and does not pose such risks.

Guidelines:

* The answer NA means that the paper poses no such risks.
* Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.
* Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.
* We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
* **Licenses for existing assets*
* Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: Portions of the publicly available code of [11] is adopted in the code of our experiments. Guidelines:
* The answer NA means that the paper does not use existing assets.
* The authors should cite the original paper that produced the code package or dataset.
* The authors should state which version of the asset is used and, if possible, include a URL.
* The name of the license (e.g., CC-BY 4.0) should be included for each asset.
* For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.
* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [Yes] Justification: The codebase for the experiments can be found at https://github.com/bvarici/intervention-mixture-DAG, and is released under Apache 2.0 license. Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)?Answer: [NA] Justification: [NA] Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: [NA] Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.