# An efficient search-and-score algorithm for ancestral graphs using multivariate information scores

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

We propose a greedy search-and-score algorithm for ancestral graphs, which include directed as well as bidirected edges, originating from unobserved latent variables. The normalized likelihood score of ancestral graphs is estimated in terms of multivariate information over relevant subsets of vertices, \(\bm{C}\), that are connected through collider paths confined to the ancestor set of \(\bm{C}\). For computational efficiency, the proposed two-step algorithm relies on local information scores limited to the close surrounding vertices of each node (step 1) and edge (step 2). This computational strategy is shown to outperform state-of-the-art causal discovery methods on challenging benchmark datasets.

## 1 Introduction

The likelihood function plays a central role in the selection of a graphical model \(\mathcal{G}\) based on observational data \(\mathcal{D}\). Given \(N\) independent samples from \(\mathcal{D}\), the likelihood \(\mathcal{L}_{\mathcal{D}|\mathcal{G}}\) that they might have been generated by the graphical model \(\mathcal{G}\) is given by [1],

\[\mathcal{L}_{\mathcal{D}|\mathcal{G}}=\frac{1}{Z_{\mathcal{D},\mathcal{G}}}\, \exp\left(-NH(p,q)\right)\] (1)

where \(H(p,q)=-\sum_{\bm{x}}p(\bm{x})\log q(\bm{x})\) is the cross-entropy between the empirical probability distribution \(p(\bm{x})\) of the observed data \(\mathcal{D}\) and the theoretical probability distribution \(q(\bm{x})\) of the model \(\mathcal{G}\) and \(Z_{\mathcal{D},\mathcal{G}}\) a data- and model-dependent factor ensuring proper normalization condition for finite dataset. In short, Eq.1 results from the asymptotic probability that the \(N\) independent samples, \(\bm{x}^{(1)},\cdots,\bm{x}^{(N)}\), are drawn from the model distribution, \(q(\bm{x})\), _i.e._\(\mathcal{L}_{\mathcal{D}|\mathcal{G}}\equiv q(\bm{x}^{(1)},\cdots,\bm{x}^{(N)})= \prod_{i}q(\bm{x}^{(i)})\), rather than the empirical distribution, \(p(\bm{x})\). This leads to, \(\log\mathcal{L}_{\mathcal{D}|\mathcal{G}}=\sum_{i}\log q(\bm{x}^{(i)})\), which converges towards \(N\sum_{\bm{x}}p(\bm{x})\log q(\bm{x})=-N\,H(p,q)\) in the large sample size limit, \(N\to\infty\), with \(\log Z_{\mathcal{D},\mathcal{G}}=\mathcal{O}(\log N)\).

The structural constraints of the model \(\mathcal{G}\) translate into the factorization form of the theoretical probability distribution, \(q(\bm{x})\)[2; 3; 4; 5; 6]. In particular, the probability distribution of Bayesian networks (BN) factorizes in terms of conditional probabilities of each variable given its parents, as \(q_{{}_{\mathrm{BN}}}(\bm{x})=\prod_{i}q(x_{i}|\mathbf{p}\mathbf{a}_{X_{i}})\), where \(\mathbf{p}\mathbf{a}_{X_{i}}\) denote the values of the parents of node \(X_{i}\) in \(\mathcal{G}\), \(\mathbf{P}\mathbf{a}_{X_{i}}\). For Bayesian networks, the factors of the model distribution, \(q(x_{i}|\mathbf{p}\mathbf{a}_{X_{i}})\), can be directly estimated with the empirical conditional probabilities of each node given its parents as, \(q(x_{i}|\mathbf{p}\mathbf{a}_{X_{i}})\equiv p(x_{i}|\mathbf{p}\mathbf{a}_{X_{ i}})\), leading to the well known estimation of the likelihood function in terms of conditional entropies \(H(X_{i}|\mathbf{P}\mathbf{a}_{X_{i}})=-\sum_{\bm{x}}p(x_{i},\mathbf{p}\mathbf{a}_ {X_{i}})\log p(x_{i}|\mathbf{p}\mathbf{a}_{X_{i}})\),

\[\mathcal{L}_{\mathcal{D}|\mathcal{G}_{\mathrm{BN}}}=\frac{1}{Z_{\mathcal{D}, \mathcal{G}_{\mathrm{BN}}}}\,\exp\left(-N\overset{\mathrm{vertices}}{\sum} \overset{\mathrm{vertices}}{H(X_{i}|\mathbf{P}\mathbf{a}_{X_{i}})}\right)\] (2)This paper concerns the experimental setting for which some variables of the underlying Bayesian model are not observed. This frequently occurs in practice for many applications. We derive an explicit likelihood function for the class of ancestral graphs, which include directed as well as bidirected edges, arising from the presence of unobserved latent variables. Tian and Pearl 2002 [7] showed that the probability distribution of such graphs factorizes into c-components including subsets of variables connected through bidirected paths (_i.e._ containing only bidirected edges). Richardson 2009 [6] later proposed a refined factorization of the model distribution of the broader class of acyclic directed mixed graphs in terms of conditional probabilities over "head" and "tail" subsets of variables within each ancestrally closed subsets of vertices. However, unlike with Bayesian networks, the contributions of c-components or head-and-tail factors to the likelihood function cannot simply be estimated in terms of empirical distribution \(p(\bm{x})\), as shown below. This leaves the likelihood function of ancestral graphs difficult to estimate from empirical data, in general, although iterative methods have been developped when the data is normally distributed [8; 9; 10; 11; 12; 13].

The present paper provides an explicit decomposition of the likelihood function of ancestral graphs in terms of multivariate cross-information over relevant '\(ac\)-connected' subsets of variables, Figs. 1, which do not rely on the head-and-tail factorization but coincide with the parametrizing sets [14] derived from the head-and-tail factorization. It suggests a natural estimation of these revelant contributions to the likelihood function in terms of empirical distribution \(p(\bm{x})\). This result extends the likelihood expression of Bayesian Networks (Eq. 2) to include the effect of unobserved latent variables and enables the implementation of a greedy search-and-score algorithm for ancestral graphs. For computational efficiency, the proposed two-step algorithm relies on local information scores limited to the close surrounding vertices of each node (step 1) and edge (step 2). This computational strategy is shown to outperform state-of-the-art causal discovery methods on challenging benchmark datasets.

## 2 Theoretical results

### Multivariate cross-entropy and cross-information

The theoretical result of the paper (Theorem 1) is expressed in terms of multivariate cross-information derived from multivariate cross-entropies through the Inclusion-Exclusion Principle. The same expressions can be written between multivariate information and multivariate entropies by simply substituting \(q(\{x_{i}\})\) with \(p(\{x_{i}\})\) in the equations below and will be used to estimate the likelihood function of ancestral graphs (Proposition 3).

As recalled above, the cross-entropy between \(m\) variables, \(\bm{V}=\{X_{1},\cdots,X_{m}\}\), is defined as,

\[H(\bm{V})\;=\;-\!\!\sum_{\{x_{i}\}}p(x_{1},\cdots,x_{m})\log q(x_{1},\cdots,x _{m})\] (3)

where \(p(\{x_{i}\})\) is the empirical joint probability distribution of the variables \(\{X_{i}\}\) and \(q(\{x_{i}\})\) the joint probability distribution of the model. Bayes formula, \(q(\{x_{i}\},\{y_{j}\})=q(\{x_{i}\}|\{y_{j}\})\)\(q(\{y_{j}\})\), directly translates into the definition of conditional cross-entropy through the decomposition,

\[H(\{X_{i}\},\{Y_{j}\})=H(\{X_{i}\}|\{Y_{j}\})+H(\{Y_{j}\})\] (4)

Multivariate (cross) information, \(I(\bm{V})\equiv I(X_{1};\cdots;X_{m})\), are defined from multivariate (cross) entropies through Inclusion-Exclusion formulas over all subsets of variables [15; 16; 17; 18] as,

\[I(X) = H(X)\] \[I(X;Y) = H(X)+H(Y)-H(X,Y)\] \[I(X;Y;Z) = H(X)+H(Y)+H(Z)-H(X,Y)-H(X,Z)-H(Y,Z)+H(X,Y,Z)\] \[I(\bm{V}) = -\sum_{\bm{S}\subseteq\bm{V}}(-1)^{|\bm{S}|}H(\bm{S})\] (5)

where the semicolon separators are needed to distinguish multipoint (cross) information from joint variables as \(\{X,Z\}\) in \(I(\{X,Z\};Y)=I(X;Y)+I(Z;Y)-I(X;Y;Z)\). Below, implicit separators between non-conditioning variables in multivariate (cross) information will always correspond to semicolons, _e.g._ as in \(I(\bm{V})\) in Eq. 5. Unlike multivariate (cross) entropies, which are always positive,

[MISSING_PAGE_FAIL:3]

#### 2.2.2 _ac_-connecting paths and _ac_-connected subsets

Let us now define **ancestor collider connecting paths** or _ac_-connecting paths**, which entail simpler path connecting criterion than the traditional **m-connecting criterion**, discussed in the Appendix A. Yet, _ac_-connecting paths** and _ac_-connected subsets** will turn out to be directly relevant to characterize the likelihood decomposition and Markov equivalent classes of ancestral graphs.

**Definition 2**. [_ac_-connecting path] An \(ac\)-connecting path between \(X\) and \(Y\) given a subset of variables \(\bm{C}\) (possibly including \(X\) and \(Y\)) is a collider path, \(X\!\ast\!\to Z_{1}\longleftrightarrow\cdots\longleftrightarrow Z_{K} \leftarrow\!\ast\!Y\), with all \(Z_{i}\in\mathbf{An}_{\mathcal{G}}(\{X,Y\}\cup\bm{C})\), that is, with \(Z_{i}\) in \(\bm{C}\) or connected to \(\{X,Y\}\cup\bm{C}\) by an ancestor path, _i.e._\(Z_{i}\to\cdots\to T\) with \(T\in\{X,Y\}\cup\bm{C}\).

**Definition 3**. [_ac_-connected subset] A subset \(\bm{C}\) is said to be \(ac\)-connected if \(\forall X,Y\in\bm{C}\), \(X\) and \(Y\) are connected (through any type of edge) or there is an \(ac\)-connecting path between \(X\) and \(Y\) given \(\bm{C}\).

### Likelihood decomposition of ancestral graphs

**Theorem 1**.: **[likelihood of ancestral graphs]** _The cross-entropy \(H(p,q)\) and likelihood \(\mathcal{L}_{\mathcal{D}|\mathcal{G}}\) of an ancestral graph \(\mathcal{G}\) is decomposable in terms of multivariate cross-information, \(I(\bm{C})\), summed over all \(ac\)-connected subsets of variables, \(\bm{C}\) (Definition 3),_

\[H(p,q) = -\sum_{\bm{C}\subseteq\bm{V}}^{\mathrm{ac}-\mathrm{connected}} (-1)^{|\bm{C}|}I(\bm{C})\] \[\mathcal{L}_{\mathcal{D}|\mathcal{G}} = \frac{1}{Z_{\mathcal{D},\mathcal{G}}}\exp\left(N\sum_{\bm{C} \subseteq\bm{V}}^{\mathrm{ac}-\mathrm{connected}}(-1)^{|\bm{C}|}I(\bm{C})\right)\] (12)

_where \(N\) is the number of iid samples in the dataset \(\mathcal{D}\) and \(Z_{\mathcal{D},\mathcal{G}}\) a data- and model-dependent normalization constant._

The proof of Theorem 1 is left to the Appendix B. It is based on a partition of the cross-entropy (Eq. 6) into cross-information contributions from \(ac\)-connected and non-\(ac\)-connected subsets of variables, which do not rely on head-and-tail factorizations. Hu and Evans [14] proposed an equivalent result (Proposition 3.3 in [14]) with a proof using head-and-tail decomposition to define parametrizing sets, which happen to coincide with the \(ac\)-connected sets defined here (Definition 3). Theorem 1 characterizes in particular the Markov equivalence class of ancestral graphs [8, 19, 20, 21, 22, 23, 24] as,

**Corollary 2**.: _Two ancestral graphs are Markov equivalent if and only if they have the same \(ac\)-connected subsets of vertices._

Note, in particular, that Eq. 12 holds for _maximal ancestral graphs_ (MAG), for which all pairs of \(ac\)-connected variables are connected by an edge, and their Markov equivalent representatives, the _partial ancestral graphs_ (PAG) [8, 25, 26, 27].

**Proposition 3**.: The likelihood decomposition of ancestral graphs (Eq. 12, Theorem 1) can be estimated by replacing the model distribution \(q\) by the empirical distribution \(p\) in the retained multivariate cross-information terms \(I(\bm{C})\) corresponding to all _ac_-connected subsets of variables, \(\bm{C}\).

Hence, Proposition 3 amounts to estimating all relevant cross-information terms in the likelihood function with the corresponding multivariate information terms computed from the available data, while assuming by construction that the model distribution obeys all local and global conditional independences entailed by the ancestral graph. The corresponding factorization of the model distribution can be expressed in terms of empirical distribution, assuming positive distributions, see Appendix C.

Fig. 1 illustrates the cross-entropy decomposition for a few graphical models in terms of cross-information contributions from their \(ac\)-connected subsets of vertices. In particular, an unshielded non-collider (_e.g._\(X\to Z\to W\), Fig. 1A), is less likely (_i.e._ higher cross-entropy) than an unshielded collider or 'v-structure' (_e.g._\(X\to Z\gets W\), Fig. 1B), if the corresponding three-point information term is negative, \(I(X;Z;W)<0\), in agreement with earlier results [28, 29]. However, this early approach, exploiting the sign and magnitude of three-point information to orient v-structures, does not include higher order terms involving multiple v-structures, which can lead to orientation conflicts between unshielded triples, in practice. Resolving such orientation conflicts requires to include

[MISSING_PAGE_EMPTY:5]

collider path, Fig. 1D. By contrast, the cross-entropy based on the head-and-tail factorization of the same two-collider path, _i.e._\(q(x,z,y,w)=q(z,y|x,w)q(x)q(w)\)[6], is found to be equivalent to the cross-entropy of a Bayesian graph without bidirected edge, Fig. 1E, when estimated with the empirical distribution \(p(.)\), see Appendix C. This observation illustrates the difficulty to estimate the likelihood functions of ancestral graphs using head-and-tail factorization.

Further examples of graphical models, Figs. 1F-I, show the relative simplicity of the decomposition with only few (non-trivial) \(ac\)-connected contributing subsets \(\bm{C}\) with \(|\bm{C}|\geqslant 3\), as compared to the much larger number of non-\(ac\)-connected non-contributing subsets, that cancel each other by construction due to conditional independence constraints of the underlying model. Note, in particular, that most contributing multivariate information \(I(\bm{C})\) only concern direct connections or collider paths within a single component subgraph induced by \(\bm{C}\) (solid line edges in Fig. 1). However, occasionally, collider paths extending beyond \(\bm{C}\) into \(\mathbf{An}_{\mathcal{G}}(\bm{C})\setminus\bm{C}\) (marked with wiggly edges) with corresponding ancestor path(s) (marked with dashed edges) do occur, as shown in Fig. 1G.

In addition, the present information-theoretic decomposition of the likelihood of ancestral graphs can readily distinguish their Markov equivalence classes according to Corollary 2. For instance, the ancestral graphs of Fig. 1F and Fig. 1G, despite sharing the same edges and the same unshielded collider (\(X\to Z\gets T\)), turn out not to be Markov equivalent, as discussed in [24]. Indeed, their cross-entropy decompositions differ by two \(ac\)-connected contributing terms: a three-point cross information \(I(X;Y;T)\) with a collider path not confined in \(\bm{C}\) (_i.e._\(X\rightsquigarrow Z\rightsquigarrow T\longleftrightarrow Y\) and corresponding ancestor path \(Z\dashrightarrow Y\)) and a four-point information term \(I(X;Y;Z;T)\) due to the two-collider path (\(X\to Z\longleftrightarrow T\longleftrightarrow Y\)). More quantitatively, it shows that the graph of Fig. 1G with a two-collider path is more likely than the graph of Fig. 1F whenever \(I(X;Y;T)-I(X;Y;Z;T)=I(X;Y;T|Z)=I(X;Y|Z)-I(X;Y|Z,T)\!<\!0\). Finally, the Markov equivalent graphs of Fig. 1H and Fig. 2, also due to [24], illustrate the fact that the actual ancestor collider path between unconnected pairs does not need to be unique nor conserved between Markov equivalent graphs (as long as their cross-entropies share the same multivariate cross-information decomposition).

## 3 Efficient search-and-score causal discovery using local information scores

The likelihood estimation of ancestral graphs (Theorem 1 and Proposition 3) enables the implementation of a search-and-score algorithm for this broad class of graphs, which has attracted a number of contributions recently [11; 12; 13; 30; 31; 32]. Our specific objective is not to develop an exact method limited to simple graphical models with a few nodes and small datasets but to implement an efficient and reliable heuristic method applicable to more challenging graphical models and large datasets.

Indeed, search-and-score structure learning methods need to rely on heuristic rather than exhaustive search, in general, given that the number of ancestral graphs grows super-exponentially as the number of vertices increases. This can be implemented for instance with a Monte Carlo algorithmic scheme with random restarts, which efficiently probes relevant graphical models. Here, we opt, instead, to use the prediction of an efficient hybrid causal discovery method, MMIC [29; 33; 34], as starting point for a subsequent search-and-score approach based on the proposed likelihood estimation of ancestral graphs (Eq. 12 and Proposition 3).

Moreover, while the likelihood decomposition of ancestral graphs may involve extended \(ac\)-connected subsets of variables, as illustrated in Fig. 1, we aim to implement a computationally efficient search-and-score causal discovery method based on approximate local scores limited to the close surrounding vertices of each node and edge. Yet, while MMIC only relies on unshielded triple scores, the novel search-and-score extension, MMIC_search&score, uses also higher-order local information scores to compare alternative subgraphs, as detailed below.

The proposed method is shown to outperform MMIC and other state-of-the-art causal discovery methods on challenging datasets including latent variables.

### MMIC, an hybrid causal discovery method based on unshielded triple scores

MIIC is an hybrid causal discovery method combining constraint-based and information-theoretic frameworks [29; 35]. Unlike traditional constraint-based methods [4; 5], MMIC does not directly attempt to uncover conditional independences but, instead, iteratively substracts the most significant three-point (conditional) information contributions of successive contributors, \(A_{1}\), \(A_{2}\),..., \(A_{n}\), from the mutual information between each pair of variables, \(I(X;Y)\), as,

\[I(X;Y)-I(X;Y;A_{1})-I(X;Y;A_{2}|A_{1})-\cdots-I(X;Y;A_{n}|\{A_{i}\}_{n-1})=I(X;Y| \{A_{i}\}_{n})\] (13)

where \(I(X;Y;A_{k}|\{A_{i}\}_{k-1})>0\) is the _positive_ information contribution from \(A_{k}\) to \(I(X;Y)\)[28; 36]. Conditional independence is eventually established when the residual conditional mutual information on the right hand side of Eq. 13, \(I(X;Y|\{A_{i}\}_{n})\), becomes smaller than a complexity term, _i.e._\(k_{X;Y|\{A_{i}\}}(\hat{N})\geqslant I(X;Y|\{A_{i}\}_{n})\geqslant 0\), which dependents on the considered variables and sample size \(N\).

This leads to an undirected skeleton, which MMIC then (partially) orients based on the sign and amplitude of the regularized conditional 3-point information terms [28; 29]. In particular, negative conditional 3-point information terms, \(I(X;Y;Z|\{A_{\}})\!<\!0\), correspond to the signature of causality in observational data [28] and lead to the prediction of a v-structure, \(X\to Z\gets Y\), if \(X\) and \(Y\) are not connected in the skeleton. By contrast, a positive conditional 3-point information term, \(I(X;Y;Z|\{A_{\}})\!>\!0\), implies the absence of a v-structure and suggests to propagate the orientation of a previously directed edge \(X\to Z-Y\) as \(X\to Z\to Y\).

In practice, MMIC's strategy to circumvent spurious conditional independences significantly improves recall, that is, the fraction of correctly recovered edges, compared to traditional constraint-based methods [28; 29]. Yet, MMIC only relies on unshielded triple scores to reliably uncover significant contributors and orient v-structures, as outlined above. MMIC has been recently improved to ensure the consistency of the separating set in terms of indirect paths in the final skeleton or (partially) oriented graphs [37; 34] and to improve the reliably of predicted orientations [33; 34].

The predictions of this recent version of MMIC, which include three type of edges (directed, bidirected and undirected), have been used as starting point for the subsequent local search-and-score method implemented in the present paper.

### New search-and-score method based on higher-order local information scores

Starting from the structure predicted by MMIC, as detailed above, MMIC_search&score method proceeds in two steps.

#### 3.2.1 Step 1: Node scores for edge orientation priming and edge removal

The first step consists in minimizing a node score corresponding to the local normalized log likelihood of each node w.r.t. its possible parents or spouses amongst the connected nodes predicted by MMIC. To this end, the node score assesses the conditional entropy of each node w.r.t. a selection of parents, spouses or neighbors, \(\mathbf{Pa}^{\prime}_{x_{i}}\subseteq\mathbf{Pa}_{x_{i}}\!\cup\mathbf{Sp}_{x_{ i}}\!\cup\mathbf{Ne}_{x_{i}}\!\), and a factorized Normalized Maximum Likelihood (fNML) regularization [28], see Appendix D for details,

\[\mathrm{Score}_{\mathrm{n}}(X_{i})=H(X_{i}|\mathbf{Pa}^{\prime}_{x_{i}})+ \frac{1}{N}\sum_{j}^{q_{x_{i}}}\log\mathcal{C}^{r_{x_{i}}}_{n_{j}}\] (14)

where \(q_{x_{i}}\) corresponds to the combination of levels of \(\mathbf{Pa}^{\prime}_{x_{i}}\), while \(r_{x_{i}}\) is the number of levels of \(X_{i}\), and \(n_{j}\) the number of samples corresponding to a particular combination of levels \(j\) in each summand, with \(\sum_{j}n_{j}=N\), the total number of samples. \(\log\mathcal{C}^{r_{x_{i}}}_{n_{j}}\) is the fNML regulatization cost summed over all combinations of levels, \(q_{x_{i}}\), [38; 39], see Appendix D.

This first algorithm is looped over each node, priming the orientations of their surrounding edges (as directed, bidirected or undirected), until convergence. Edges without orientation priming at either extremity are removed at the end of Step 1.

#### 3.2.2 Step 2: Edge orientation scores

The second step consists in minimizing an edge orientation score corresponding to the local normalized log likelihood of each edge w.r.t. its nodes' parents and spouses inferred in Step 1. To this end, the edge score assesses the conditional information and a fNML complexity cost with respect to the type of orientation, given three sets of parents and spouses of \(X\) and \(Y\), _i.e._\(\mathbf{Pa}^{\prime}_{x_{i}\!\vee\!Y}=\mathbf{Pa}_{x_{i}}\!\cup\mathbf{Sp}_{x _{i}}\!\setminus\!Y\), \(\mathbf{Pa}^{\prime}_{\!\vee\!X}=\mathbf{Pa}_{x_{i}}\!\cup\mathbf{Sp}_{x_{i} }\!\setminus\!X\) and \(\mathbf{Pa}^{\prime}_{x_{i}\!\vee\!Y}=\mathbf{Pa}^{\prime}_{x_{i}\!\vee\!Y} \cup\mathbf{Pa}^{\prime}_{\!\vee\!X}\) with their corresponding combinations of levels, \(q_{\psi_{x}}\), \(q_{\psi_{y}}\) and \(q_{\psi_{x}}\). These orientation scores, listed in Table 1, include symmetrized fNML complexity terms to enforce Markov equivalence, if \(X\) and \(Y\) share the same parents or spouses (excluding \(X\) and \(Y\)), see Appendix D. Indeed, all three scores become equals if \(\mathbf{Pa}^{\prime}_{\chi_{Y}\chi}=\mathbf{Pa}^{\prime}_{\chi_{Y}}=\mathbf{Pa }^{\prime}_{\chi_{Y}}\) implying also the same combinations of parent and spouse levels, \(q_{\psi_{x}}=q_{\psi_{y}}=q_{xy}\).

This second algorithm is looped over each edge to compute an orientation score decrement, given the orientations of its surrounding edges. The orientation change corresponding to the largest orientation score decrement is then chosen at each iteration until convergence or until a limit cycle is reached and stopped at the lowest sum of local orientation scores.

## 4 Experimental results

We first tested whether MIL_search&score orientation scores (Table 1) effectively predicts bidirected orientations on three simple ancestral models, Fig. 3, when the end nodes do not share the same parents (Fig. 3, Model 1), share some parents (Fig. 3, Model 2) or when the bidirected edge is part of a longer than two-collider paths (Fig. 3, Model 3). The prediction of the edge orientation scores are summarized in Table 3, Appendix E, and show good predictions for large enough datasets.

Beyond these simple examples, focussing on the discovery of bidirected edges in small toy models of ancestral graphs, we also analyzed more challenging benchmarks from the bnlearn repository [40], Fig. 2. They concern ancestral graphs obtained by hiding up to 20% of variables in Bayesian Networks of increasing complexity (number of nodes and parameters), such as Alarm (37 nodes, 46 links, 509 parameters), Insurance (27 nodes, 52 links, 984 parameters), and Barley (48 nodes, 84 links, 114,005 parameters). We then assessed causal discovery performance in terms of _Precision_, \(TP/(TP+FP)\), and _Recall_, \(TP/(TP+FN)\), relative to the theoretical PAGs, while counting as false positive (\(FP\)), all correctly predicted edges but without or with a different orientation as the directed or bidirected edges of the PAG.

Fig. 2 compares MIL_search&score performance to MILC results used as starting point for MILC_search&score and to FCI [41]. MILC and MILC_search&score settings were set as described in section 3 above. The open-source MILC R package (v1.5.2, GPL-3.0 license) was obtained at https://github.com/miicTeam/miic_R_package. FCI from the python causal-learn package (v0.1.3.8, MIT license) [41] was obtained at https://github.com/py-why/causal-learn and run with G\({}^{2}\)-conditional independence test and default parameter \(\alpha=0.05\).

Overall, MILC_search&score is found to outperform MILC in terms of edge precision with little to no decrease in edge recall, Fig. 2, demonstrating the benefit of MILC_search&score's rationale to improve MILC predictions by extending MILC information scores from unshielded triples to higher-order information contributions. These originate from \(ac\)-connected subsets including nodes with more than two parents or spouses, or \(ac\)-connected subsets including two-collider paths. MILC_search&score is also found to outperform FCI on complex ancestral benchmark networks with many parameters, such as Barley (114,005 parameters), Fig. 2. However, FCI is found to reach similar or better precision scores on easier benchmarks with fewer parameters (_i.e._ Alarm and Insurance), although its recall remains usually lower than MILC_search&score, especially at small sample size, as expected for a purely constraint-based causal discovery approach.

Importantly, the benchmark PAGs used to score the causal discovery results with increasing proportions of latent variables, Fig. 2, include not only bidirected edges originating from hidden common causes but also additional directed or undirected edges arising, in particular, from indirect effects of

\begin{table}
\begin{tabular}{l l l} \hline Edge & Information & Symmetrized fNML complexity (Markov equivalent) \\ \(X\to Y\) & \(-I(X;Y|\mathbf{Pa}^{\prime}_{\chi_{Y}\chi})\) & \(\frac{1}{2N}\Big{(}\sum_{j}^{q_{\psi_{y}}q_{\psi_{y}}}\log\mathcal{C}^{r_{x}}_ {n_{j}}-\sum_{j}^{q_{\psi_{y}}}\log\mathcal{C}^{r_{x}}_{n_{j}}+\sum_{j}^{q_{ \psi_{x}}r_{x}}\log\mathcal{C}^{r_{y}}_{n_{j}}-\sum_{j}^{q_{\psi_{x}}}\log \mathcal{C}^{r_{y}}_{n_{j}}\Big{)}\) \\ \(X\gets Y\) & \(-I(X;Y|\mathbf{Pa}^{\prime}_{\chi_{Y}\chi})\) & \(\frac{1}{2N}\Big{(}\sum_{j}^{q_{\psi_{y}}q_{\psi_{y}}}\log\mathcal{C}^{r_{x}}_ {n_{j}}-\sum_{j}^{q_{\psi_{y}}}\log\mathcal{C}^{r_{x}}_{n_{j}}+\sum_{j}^{q_{ \psi_{x}}r_{x}}\log\mathcal{C}^{r_{y}}_{n_{j}}-\sum_{j}^{q_{\psi_{y}}}\log \mathcal{C}^{r_{y}}_{n_{j}}\Big{)}\) \\ \(X\leftrightarrow Y\) & \(-I(X;Y|\mathbf{Pa}^{\prime}_{\chi_{Y}\chi})\) & \(\frac{1}{2N}\Big{(}\sum_{j}^{q_{\psi_{y}}r_{y}}\log\mathcal{C}^{r_{x}}_{n_{j}}- \sum_{j}^{q_{\psi_{x}}r_{y}}\log\mathcal{C}^{r_{x}}_{n_{j}}+\sum_{j}^{q_{\psi_ {x}}r_{x}}\log\mathcal{C}^{r_{y}}_{n_{j}}-\sum_{j}^{q_{\psi_{x}}}\log\mathcal{C }^{r_{y}}_{n_{j}}\Big{)}\) \\ \hline \end{tabular}
\end{table}
Table 1: Local scores for the orientation of a single directed or bidirected edge.

hidden variables with observed parents. Irrespective of their orientations, all these additional edges originating from indirect effects of hidden variables generally correspond to weaker effects (_i.e._ lower mutual information of indirect effects due to the Data Processing Inequality) and are more difficult to uncover than the edges of the original graphical model without hidden variables.

## 5 Limitations

The main limitation of the paper concerns the local scores used in the search-and-score algorithm, which are limited to \(ac\)-connected subsets of vertices with a maximum of two-collider paths.

While this approach could be extended to higher-order information contributions including three- or more collider paths, it allows for a simple two-step search-and-score scheme at the level of individual nodes (step 1) and edges (step 2), as detailed in section 3. This already shows a significant improvement in causal discovery performance (_i.e._ combing good precision and good recall on challenging benchmarks) as compared to existing state-of-the-art methods.

Figure 2: **Benchmark results on ancestral graphs of increasing complexity. Benchmark results on ancestral graphs obtained by hiding 0%, 5%, 10% or 20% of variables in Bayesian Networks of increasing complexity (see main text): Alarm (lhs), Insurance (middle), and Barley (rhs). MIL_search&score results are compared to MILC results used as starting point for MILC_search&score and FCI [41]. Causal discovery performance is assessed in terms of _Precision_ and _Recall_ relative to the theoretical PAGs, while counting as false positive all correctly predicted edges but without or with a different orientation as the directed or bidirected edges of the PAG. Error bars (\(\pm\sigma\)): standard deviations.**

## References

* [1] D. Koller, N. Friedman, _Probabilistic Graphical Models: Principles and Techniques_ (MIT Press, 2009).
* [2] J. Pearl, A. Paz, Graphoids: A graph-based logic for reasoning about relevance relations, or when would x tell you more about y if you already know z, _Tech. rep._, UCLA Computer Science Department (1985).
* [3] J. Pearl, _Probabilistic reasoning in intelligent systems_ (Morgan Kaufmann, San Mateo, CA, 1988).
* [4] J. Pearl, _Causality: models, reasoning and inference_ (Cambridge University Press, 2009), second edn.
* [5] P. Spirtes, C. Glymour, R. Scheines, _Causation, Prediction, and Search_ (MIT press,, 2000), second edn.
* [6] T. S. Richardson, A factorization criterion for acyclic directed mixed graphs, _Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence_, UAI '09 (AUAI Press, Arlington, VA, USA, 2009), p. 462-470.
* [7] J. Tian, J. Pearl, A general identification condition for causal effects, _Proceedings of the National Conference on Artificial Intelligence_ (Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999, 2002), pp. 567-573.
* [8] T. Richardson, P. Spirtes, Ancestral graph markov models. _Ann. Statist._**30**, 962-1030 (2002).
* [9] M. Drton, M. Eichler, T. S. Richardson, Computing maximum likelihood estimates in recursive linear models with correlated errors. _Journal of Machine Learning Research_**10**, 2329-2348 (2009).
* [10] R. J. Evans, T. S. Richardson, Maximum likelihood fitting of acyclic directed mixed graphs to binary data, _Proceedings of the 26th Conference on Uncertainty in Artificial Intelligence_, UAI'10 (AUAI Press, Corvallis, OR, USA, 2010).
* [11] S. Triantafillou, I. Tsamardinos, Score-based vs constraint-based causal learning in the presence of confounders, _CFA@UAI_ (2016).
* [12] K. Rantanen, A. Hyttinen, M. Jarvisalo, Maximal ancestral graph structure learning via exact search, _Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial Intelligence_, C. de Campos, M. H. Maathuis, eds. (PMLR, 2021), vol. 161 of _Proceedings of Machine Learning Research_, pp. 1237-1247.
* [13] T. Claassen, I. G. Bucur, Greedy equivalence search in the presence of latent confounders, _Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence_, J. Cussens, K. Zhang, eds. (PMLR, 2022), vol. 180 of _Proceedings of Machine Learning Research_, pp. 443-452.
* [14] Z. Hu, R. Evans, Faster algorithms for markov equivalence, _Proceedings of the 36th Conference on Uncertainty in Artificial Intelligence (UAI)_, J. Peters, D. Sontag, eds. (PMLR, 2020), vol. 124 of _Proceedings of Machine Learning Research_, pp. 739-748.
* [15] W. J. McGill, Multivariate information transmission. _Trans. of the IRE Professional Group on Information Theory (TIT)_**4**, 93-111 (1954).
* [16] H. K. Ting, On the amount of information. _Theory Probab. Appl._**7**, 439-447 (1962).
* [17] T. S. Han, Multiple mutual informations and multiple interactions in frequency data. _Information and Control_**46**, 26-45 (1980).
* [18] R. W. Yeung, A new outlook on shannon's information measures. _IEEE transactions on information theory_**37**, 466-474 (1991).
* [19] P. Spirtes, T. Richardson, A polynomial time algorithm for determinant dag equivalence in the presence of latent variables and selection bias, _Proceedings of the 6th International Workshop on Artificial Intelligence and Statistics_ (1996).
* [20] T. Richardson, Markov properties for acyclic directed mixed graphs. _Scandinavian Journal of Statistics_**30**, 145-157 (2003).
* [21] R. A. Ali, T. S. Richardson, Markov equivalence classes for maximal ancestral graphs, _Proceedings of the Eighteenth Conference on Uncertainty in Artificial Intelligence_, UAI'02 (Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 2002), pp. 1-9.
* [22] R. A. Ali, T. S. Richardson, P. Spirtes, J. Zhang, Towards characterizing markov equivalence classes for directed acyclic graphs with latent variables, _Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence_, UAI'05 (Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 2005).

* [23] J. Tian, Generating markov equivalent maximal ancestral graphs by single edge replacement, _Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence_, UAI'05 (Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 2005).
* [24] R. A. Ali, T. S. Richardson, P. Spirtes, Markov equivalence for ancestral graphs. _Ann. Statist._**37**, 2808-2837 (2009).
* [25] T. Richardson, P. Spirtes, Scoring ancestral graph models, _Tech. rep._ (1999). Available as Technical Report CMU-PHIL 98.
* [26] J. Zhang, A characterization of markov equivalence classes for directed acyclic graphs with latent variables, _Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence_, UAI'07 (Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 2007).
* [27] J. Zhang, On the completeness of orientation rules for causal discovery in the presence of latent confounders and selection bias. _Artif. Intell._**172**, 1873-1896 (2008).
* [28] S. Affeldt, H. Isambert, Robust reconstruction of causal graphical models based on conditional 2-point and 3-point information, _Proceedings of the Thirty-First Conference on Uncertainty in Artificial Intelligence, UAI 2015, July 12-16, 2015, Amsterdam, The Netherlands_ (2015), pp. 42-51.
* [29] L. Verny, N. Sella, S. Affeldt, P. P. Singh, H. Isambert, Learning causal networks with latent variables from multivariate information in genomic data. _PLoS Comput. Biol._**13**, e1005662 (2017).
* [30] B. Andrews, G. F. Cooper, T. S. Richardson, P. Spirtes, The m-connecting imset and factorization for admg models, Preprint (2022). Arxiv 2207.08963.
* [31] Z. Hu, R. J. Evans, Towards standard imsets for maximal ancestral graphs. _Bernoulli_**30** (2024).
* [32] Z. Hu, R. Evans, A fast score-based search algorithm for maximal ancestral graphs using entropy, Preprint (2024). Arxiv 2402.04777.
* [33] V. Cabeli, H. Li, M. da Camara Ribeiro-Dantas, F. Simon, H. Isambert, Reliable causal discovery based on mutual information supremum principle for finite datasets, _WIY21, 35rd Conference on Neural Information Processing Systems_ (NeurIPS, 2021).
* [34] M. d. C. Ribeiro-Dantas, H. Li, V. Cabeli, L. Dupuis, F. Simon, L. Hettal, A.-S. Hamy, H. Isambert, Learning interpretable causal networks from very large datasets, application to 400, 000 medical records of breast cancer patients. _iscience_**27**, 109736 (2024).
* [35] V. Cabeli, L. Verny, N. Sella, G. Uguzzoni, M. Verny, H. Isambert, Learning clinical networks from medical records based on information estimates in mixed-type data. _PLoS Comput. Biol._**16**, e1007866 (2020).
* [36] S. Affeldt, L. Verny, H. Isambert, 3off2: A network reconstruction algorithm based on 2-point and 3-point information statistics. _BMC Bioinformatics_**17** (2016).
* [37] H. Li, V. Cabeli, N. Sella, H. Isambert, Constraint-based causal structure learning with consistent separating sets. _Advances in Neural Information Processing Systems (NeurIPS)_**32** (2019).
* [38] P. Kontkanen, P. Myllymaki, A linear-time algorithm for computing the multinomial stochastic complexity. _Inf. Process. Lett._**103**, 227-233 (2007).
* [39] T. Roos, T. Silander, P. Kontkanen, P. Myllymaki, Bayesian network structure learning using factorized nml universal models, _Proc. 2008 Information Theory and Applications Workshop (ITA-2008)_ (IEEE Press, 2008).
* [40] M. Scutari, Learning Bayesian Networks with the bnlearn R Package. _J. Stat. Softw._**35**, 1-22 (2010).
* [41] Y. Zheng, B. Huang, W. Chen, J. Ramsey, M. Gong, R. Cai, S. Shimizu, P. Spirtes, K. Zhang, Causal-learn: Causal discovery in python. _Journal of Machine Learning Research_**25**, 1-8 (2024).
* [42] Y. M. Shtarkov, Universal sequential coding of single messages. _Problems of Information Transmission_**23**, 3-17 (1987).
* [43] J. Rissanen, I. Tabus, _Adv. Min. Descrip. Length Theory Appl._ (MIT Press, 2005), pp. 245-264.
* [44] W. Szpankowski, _Average case analysis of algorithms on sequences_ (John Wiley & Sons,, 2001).

* [45] P. Kontkanen, W. Buntine, P. Myllymaki, J. Rissanen, H. Tirri, Efficient computation of stochastic complexity. _in: C. Bishop, B. Frey (Eds.) Proceedings of the Ninth International Conference on Artificial Intelligence and Statistics, Society for Artificial Intelligence and Statistics_**103**, 233-238 (2003).
* [46] P. Kontkanen, Computationally efficient methods for mdl-optimal density estimation and data clustering, Ph.D. thesis (2009).
* [47] D. M. Chickering, A Transformational Characterization of Equivalent Bayesian Network Structures, _UAI '95: Proceedings of the Eleventh Annual Conference on Uncertainty in Artificial Intelligence_ (Morgan Kaufmann, 1995), pp. 87-98.
* [48] M. Kalisch, M. Machler, D. Colombo, M. H. Maathuis, P. Buhlmann, Causal inference using graphical models with the r package pcalg. _J. Stat. Softw._**47**, 1-26 (2012).

## Appendix A Preliminaries: connection and separation criteria

### \(m\)-connection _vs \(m\)_'-connection criteria

An ancestral graph can be interpreted as encoding a set of conditional independence relations by a graphical criterion, called \(m\)-separation, based on the concept of \(m\)-connecting paths, which generalizes the separation criteria of Markov and Bayesian networks to ancestral graphs.

**Definition 4**.: [\(m\)-connecting path] A path \(\pi\) between \(X\) and \(Y\) is \(m\)-connecting given a (possibly empty) subset \(\bm{C}\subseteq\bm{V}\) (with \(X,Y\notin\bm{C}\)) if:

* its non-collider(s) are not in \(\bm{C}\), and
* its collider(s) are in \(\mathbf{An}_{\mathcal{G}}(\bm{C})\).

**Definition 5**.: [\(m\)-separation criterion] The subsets \(\bm{A}\) and \(\bm{B}\) are said to be \(m\)-separated by \(\bm{C}\), noted \(\bm{A}\perp_{m}\bm{B}|\bm{C}\), if there is no \(m\)-connecting path between any vertex in \(\bm{A}\) and any vertex in \(\bm{B}\) given \(\bm{C}\).

The probabilistic interpretation of ancestral graph is given by its global and pairwise Markov properties (which are equivalent [8]): if \(\bm{A}\) and \(\bm{B}\) are \(m\)-separated by \(\bm{C}\), then \(\bm{A}\) and \(\bm{B}\) are conditionally independent given \(\bm{C}\) and \(\forall X\in\bm{A}\) and \(\forall Y\in\bm{B}\), there is a probability distribution \(P\) faithful to \(\mathcal{G}\) such that their conditional mutual information vanishes, _i.e._\(I_{P}(X;Y|\bm{C})=0\), also noted \(X\perp_{P}Y|\bm{C}\).

However, as discussed above, the proof of Theorem 1 will require to introduce a weaker \(m^{\prime}\)-connection criterion defined below.

**Definition 6**.: [\(m^{\prime}\)-connecting path] A path \(\pi\) between \(X\) and \(Y\) is \(m^{\prime}\)-connecting given a subset \(\bm{C}\subseteq\bm{V}\) (with \(X,Y\) possibly in \(\bm{C}\)) if:

* its non-collider(s) are not in \(\bm{C}\), and
* its collider(s) are in \(\mathbf{An}_{\mathcal{G}}(\{X,Y\}\cup\bm{C})\).

Note, in particular, that an \(m\)-connecting path is necessary an \(m^{\prime}\)-connecting path but that the converse is not always true. For example, the path \(X\to Z\longleftrightarrow T\longleftrightarrow Y\) in Fig. 1G (with \(Z\to Y\)) is an \(m^{\prime}\)-connecting path given \(T\) (as \(Z\in\mathbf{An}_{\mathcal{G}}(\{X,Y\}\cup T)\)) but not an \(m\)-connecting path given \(T\) (as \(Z\notin\mathbf{An}_{\mathcal{G}}(T)\)).

However, Richardson and Spirtes 2002 [8] have shown the following lemma,

**Lemma 4**.: [Corollary 3.15 in [8]] _In an ancestral graph \(\mathcal{G}\), there is a \(m^{\prime}\)-connecting path \(\bm{\mu}\) between \(X\) and \(Y\) given \(\bm{C}\) if and only if there is a (possibly different) \(m\)-connecting path \(\pi\) between \(X\) and \(Y\) given \(\bm{C}\)._

Hence, Lemma 4 implies that \(m^{\prime}\)-separation and \(m\)-separation criteria are in fact equivalent, as an absence of \(m^{\prime}\)-connecting paths implies an absence of \(m\)-connecting paths and vice versa. This enables to reformulate the \(m\)-separation criterion above as,

**Definition 7**.: [\(m^{\prime}\)-separation (and \(m\)-separation) criteria] The subsets \(\bm{A}\) and \(\bm{B}\) are said to be \(m^{\prime}\)-separated (or \(m\)-separated) by \(\bm{C}\), if all paths from any \(X\in\bm{A}\) to any \(Y\in\bm{B}\) have either

* a non-collider in \(\bm{C}\), or
* a collider _not_ in \(\mathbf{An}_{\mathcal{G}}(\{X,Y\}\cup\bm{C})\).

The probabilistic interpretation of an ancestral graph is given by its (global) Markov property: if \(\bm{A}\) and \(\bm{B}\) are \(m\)-separated (or \(m^{\prime}\)-separated) by \(\bm{C}\), then \(\bm{A}\) and \(\bm{B}\) are conditionally independent given \(\bm{C}\), noted as, \(\bm{A}\perp_{m}\bm{B}|\bm{C}\).

### _ac_-connecting paths and _ac_-connected subsets

Let us now recall the definition of **ancestor collider connecting paths** or _ac_-**connecting paths**, which is directly relevant to characterize the likelihood decomposition and Markov equivalent classes of ancestral graphs (Theorem 1). We give here a different yet equivalent definition of _ac_-connecting paths as defined in the main text (Definition 2) in order to underline the similarities and differencies with the notion of \(m^{\prime}\)-connecting path (Definition 6).

[MISSING_PAGE_FAIL:14]

confined to \(\mathbf{An}_{\mathcal{G}}(\bm{S}^{\prime})\) and thus to \(\mathbf{An}_{\mathcal{G}}(\bm{S})\geq\mathbf{An}_{\mathcal{G}}(\bm{S}^{\prime})\), which is an \(m^{\prime}\)-connecting path between \(X\) and \(Y\) given \(\bm{A}\), contradicting the above hypothesis of \(m^{\prime}\)-separation given \(\bm{A}\), _i.e._\(I(X;Y|\bm{A})=0\). The use of \(m^{\prime}\)-separation, _i.e._ the absence of \(m^{\prime}\)-connecting paths with colliders in \(\mathbf{An}_{\mathcal{G}}(\bm{S})\) rather than \(m\)-connecting paths with colliders in \(\mathbf{An}_{\mathcal{G}}(\bm{A})\), is necessary here, see Definitions 4 and 6. Hence, no \(ac\)-connected subset \(\bm{S}^{\prime}\) is included in cancelling combinations of multivariate information terms associated to pairwise conditional independence, \(I(X;Y|\bm{A})=\sum_{\bm{S}^{\prime}\subseteq\bm{S}}^{X,Y\in\bm{S}^{\prime}}(-1 )^{|\bm{S}^{\prime}|}I(\bm{S}^{\prime})=0\).

_iii)_ Finally, we will show that the information terms which appear in multiple cancelling combinations from different pairwise independence constraints do not modify the multivariate information decomposition of the likelihood function of ancestral graphs, Eq. 12, as these shared/overlapping terms in fact all cancel through more global Markov independence relationships involving higher order (three or more points) vanishing multivariate information terms, such as \(I(X;Y;Z|\bm{A})=0\).

This result requires to use an ordering of the nodes, \(X_{k}\succ X_{j}\succ X_{i}\), that is compatible with the directed edges of the ancestral graph assumed to have no undirected edges, _i.e._\(X_{j}\notin\mathbf{An}(X_{i})\) if \(X_{j}\succ X_{i}\). Under this ordering, higher order nodes \(X_{k}\succ X_{i}\succ X_{j}\) can be a priori excluded from all separating sets \(\bm{A}_{ij}\) of pairs of lower order nodes, _i.e._ if \(I(X_{i};X_{j}|\bm{A}_{ij})=0\) then \(X_{k}\notin\bm{A}_{ij}\).

In particular, the two pairwise conditional independence relations \(I(X_{k};X_{\ell}|\bm{A}_{k\ell})=0\), with \(X_{\ell}\succ X_{k}\), and \(I(X_{i};X_{j}|\bm{A}_{ij})=0\), with \(X_{j}\succ X_{i}\), do not share any multivariate information terms, if \(X_{\ell}\neq X_{j}\). Indeed, as \(I(X_{k};X_{\ell}|\bm{A}_{k\ell})\) contains all information terms including both \(X_{k}\) and \(X_{\ell}\) as well as every subset (possibly empty) of \(\bm{A}_{k\ell}\), none of them includes \(X_{j}\) if \(X_{\ell}\succ X_{j}\). Therefore \(I(X_{k};X_{\ell}|\bm{A}_{k\ell})\) does not contain any information term of \(I(X_{i};X_{j}|\bm{A}_{ij})\) which contains both \(X_{i}\) and \(X_{j}\) as well as every subset (possibly empty) of \(\bm{A}_{ij}\). This property eliminates all multiple counting of multivariate informations terms shared if \(X_{\ell}\neq X_{j}\). Note that this result does not hold in general for ancestral graphs including undirected edges.

Hence, the issue of redundant multivariate information terms in the likelihood decomposition, Eq. 12, is related to the conditional independences of two or more pairs, \(\{X_{i},X_{r}\}\), \(\{X_{j},X_{r}\}\),..., \(\{X_{\ell},X_{r}\}\), sharing the same higher order node, \(X_{r}\). However, this situation also entails a more global Markov independence constraint between \(X_{r}\) and \(\{X_{i},X_{j},\cdots,X_{\ell}\}\), given a separating set \(\bm{A}\), which can be decomposed into more local independence constraints using the chain rule and the decomposition rules of multivariate information (Eq. 9),

\[0 = I(\{X_{i},X_{j},\cdots,X_{\ell}\};X_{r}|\bm{A})\] \[= \big{(}I(X_{i};X_{r}|\bm{A})+I(X_{j};X_{r}|\bm{A},X_{i})\big{)}+ \big{[}I(X_{k};X_{r}|\bm{A},X_{i},X_{j})\big{]}+\cdots+I(X_{\ell};X_{r}|\bm{A},\cdots)\] \[= \big{(}I(X_{i};X_{r}|\bm{A})+I(X_{j};X_{r}|\bm{A})-I(X_{i};X_{j} ;X_{r}|\bm{A})\big{)}\] \[+\big{[}I(X_{k};X_{r}|\bm{A},X_{i})-I(X_{j};X_{k};X_{r}|\bm{A},X_ {i})\big{]}+\cdots+I(X_{\ell};X_{r}|\bm{A},\cdots)\] \[= \big{(}I(X_{i};X_{r}|\bm{A})+I(X_{j};X_{r}|\bm{A})-I(X_{i};X_{j} ;X_{r}|\bm{A})\big{)}\] \[+\big{[}I(X_{k};X_{r}|\bm{A})-I(X_{j};X_{k};X_{r}|\bm{A})-I(X_{i };X_{k};X_{r}|\bm{A})+I(X_{i};X_{j};X_{k};X_{r}|\bm{A})\big{]}+\cdots\]

where all the conditional multivariate information terms vanish by induction due to the non-negativity of (conditional) mutual information. In particular, the conditional multivariate information terms in the last expression, _i.e._ between \(X_{r}\) and each subset of \(\{X_{i},X_{j},\cdots,X_{\ell}\}\) given the separating set \(\bm{A}\), all vanish. This result can be readily extended to any subsets \(\{X_{r},X_{s},\cdots,X_{z}\}\) (conditionally) independent of \(\{X_{i},X_{j},\cdots,X_{\ell}\}\) given a separating set \(\bm{A}\), _i.e._\(I(\{X_{i},X_{j},\cdots,X_{\ell}\};\{X_{r},X_{s},\cdots,X_{z}\}|\bm{A})=0\). Hence, as the final conditional multivariate cross information terms of the decomposition all vanish while not sharing any subsets of variables, it proves the absence of redundancy and a global cancellation of non-\(ac\)-connected subsets (from pairwise and higher order conditional independence relations) in the likelihood function of ancestral graphs without undirected edges, Eq. 12.

Hence, only \(ac\)-connected subsets effectively contribute to the cross-entropy of an ancestral graph with only directed and bidirected edges, Eq. 12.

Factorization of the probability distribution of ancestral graphs

### Factorization resulting from Theorem 1 and Proposition 3

Before presenting the factorization of the model distribution of ancestral graphs resulting from Theorem 1 and Proposition 3, it is instructive to obtain an equivalent factorization for Bayesian graphs, assuming a positive empirical distributions, \(p(x_{1},\cdots,x_{m})=\prod_{i=1}^{m}p(x_{i}|x_{i-1},\cdots,x_{1})>0\),

\[q(x_{1},\cdots,x_{m}) = \prod_{i=1}^{m}q(x_{i}|\mathbf{pa}_{x_{i}})=\prod_{i=1}^{m}p(x_{i} |\mathbf{pa}_{x_{i}})\] (15) \[= p(x_{1},\cdots,x_{m})\prod_{i=1}^{m}\frac{p(x_{i}|\mathbf{pa}_{x_ {i}})}{p(x_{i}|x_{i-1},\cdots,x_{1})}\] \[= p(x_{1},\cdots,x_{m})\prod_{i=1}^{m}\frac{p(x_{i}|\mathbf{pa}_{x_ {i}})p(\boldsymbol{x}_{i-1}\backslash\mathbf{pa}_{x_{i}}|\mathbf{pa}_{x_{i}})}{ p(x_{i},\boldsymbol{x}_{i-1}\backslash\mathbf{pa}_{x_{i}}|\mathbf{pa}_{x_{i}})}\]

This leads to the following alternative expressions for the cross-entropy \(H(p,q)=-\sum_{\boldsymbol{x}}p(\boldsymbol{x})\log q(\boldsymbol{x})\) in terms of multivariate entropy and information, which only depend on the empirical joint distribution \(p(\boldsymbol{x})\),

\[H(p,q) = \sum_{i=1}^{m}H(x_{i}|\mathbf{Pa}_{X_{i}})\] (16) \[= H(X_{1},\cdots,X_{m})+\sum_{i=1}^{m}I(X_{i};\boldsymbol{X}_{i-1 }\backslash\mathbf{Pa}_{X_{i}}|\mathbf{Pa}_{X_{i}})\]

where \(\sum_{i=1}^{m}I(X_{i};\boldsymbol{X}_{i-1}\backslash\mathbf{Pa}_{X_{i}}| \mathbf{Pa}_{X_{i}})\) can be decomposed, using the chain rule and Eq. 11, into unconditional multivariate information terms, which exactly cancel all the multivariate information of the non-\(ac\)-connected subsets of variables in the multivariate entropy decomposition, Eq. 6.

Note, however, that this result obtained for Bayesian networks requires an explicit factorization of the global model distribution, \(q(\boldsymbol{x})\), in terms of the empirical distribution, \(p(\boldsymbol{x})\), which is not known and presumably does not exist, in general, for ancestral graphs.

Alternatively, assuming that the empirical and model distributions are positive (\(\forall\boldsymbol{x},p(\boldsymbol{x})>0\), \(q(\boldsymbol{x})>0\)), it is always possible to factorize them into factors associated to each (cross) information term in the (cross) entropy decomposition, Eq. 6, as,

\[q(\boldsymbol{x}) = \prod_{i=1}^{m}q(x_{i})\times\prod_{i<j}^{m}\frac{q(x_{i},x_{j}) }{q(x_{i})q(x_{j})}\times\prod_{i<j<k}^{m}\frac{q(x_{i},x_{j},x_{k})q(x_{i})q( x_{j})q(x_{k})}{q(x_{i},x_{j})q(x_{i},x_{k})q(x_{j},x_{k})}\times\cdots\] (17)

where all the marginal distributions over a subset of variables, _e.g._\(q(x_{i},x_{j},x_{k})=\sum_{\ell\neq i,j,k}q(\boldsymbol{x})\) or \(p(x_{i},x_{j},x_{k})=\sum_{\ell\neq i,j,k}p(\boldsymbol{x})\), cancel two-by-two by construction.

This can be illustrated on a simple example of a two-collider path including one bidirected edge, \(X\to Z\longleftrightarrow Y\gets W\) (Fig. 1D), valid for \(q(.)\) and \(p(.)\) alike,

\[q(x,z,y,w) = q(x)\;q(z)\;q(y)\;q(w)\] (18) \[\times\;\frac{q(x,z)\;q(z)\;q(y)\;q(x,z,w)}{q(x,z)\;q(x,w)\;q(z,w) }\;\frac{q(y,w)}{q(x)\;q(y)\;q(w)}\;\frac{q(x,w)}{q(x)\;q(w)}\;\frac{q(z,w)}{q( z)\;q(w)}\] \[\times\;\frac{q(x)\;q(z)\;q(y)\;q(x,z,y)}{q(x,z)\;q(x,y)\;q(z,w)} \;\frac{q(z)\;q(y)\;q(w)\;q(z,y)}{q(z,y)\;q(z,w)\;q(y,w)}\] \[\times\;\frac{q(x)\;q(z)\;q(w)\;q(x,z,w)}{q(x,z)\;q(x,w)\;q(z,w) }\;\frac{q(x)\;q(y)\;q(w)\;q(z,y)\;q(x,w)\;q(y,w)}{q(x,z)\;q(x,w)\;q(z,w)}\] \[\times\;\frac{q(x,z)\;q(z,y)\;q(y,w)\;q(x,y)\;q(x,w)\;q(z,w)\;q(x, z,y,w)}{q(x,z,y)\;q(x,z,w)\;q(x,y,w)\;q(z,y,w)\;q(x)\;q(y)\;q(z)\;q(w)}\]

where all individual distribution marginals on subsets of variables, _e.g._\(q(x)\), \(q(x,z)\), \(q(x,z,y)\) (or \(p(x)\), \(p(x,z)\), \(p(x,z,y)\)), cancel two-by-two by construction, except \(q(x,z,y,w)\) (or \(p(x,z,y,w)\)).

In addition and _only for the model distribution_\(q(.)\), all ratios in gray in Eq. 18 also cancel due to Markov independence relations across non-\(ac\)-connected subsets (see proof of Theorem 1). This leaves a truncated factorization retaining all and only the \(ac\)-connected subsets of variables in the graph, which we propose to estimate on empirical data by substituting the remaining \(q(.)\) terms by their empirical counterparts \(p(.)\), see Proposition 3.

This leads to the following global factorization for \(q(.)\) in terms of \(p(.)\),

\[q(x,z,y,w) \equiv p(x)\;p(z)\;p(y)\;p(w)\;\frac{p(x,z)}{p(x)\,p(z)}\;\frac{p(z,y) }{p(z)\,p(y)}\;\frac{p(y,w)}{p(y)\,p(w)}\] (19) \[\times\;\frac{p(x)\,p(z)\,p(y)\,p(x,z,y)}{p(x,z)\,p(x,y)\,p(z,y)} \;\frac{p(z)\,p(y)\,p(w)\,p(z,y,w)}{p(z,y)\,p(z,w)\,p(y,w)}\] \[\times\;\frac{p(x,z)\,p(z,y)\,p(y,w)\,p(x,y)\,p(x,w)\,p(z,w)\,p(x, z,y,w)}{p(x,z,y)\,p(x,z,w)\,p(x,y,w)\,p(z,y,w)\,p(x)\,p(y)\,p(z)\,p(w)}\] \[= p(x,z,y,w)\;\frac{p(x)\,p(y)}{p(x,y)}\;\frac{p(x)\,p(w)}{p(x,w)} \;\frac{p(z)\,p(w)}{p(z,w)}\] \[\times\;\frac{p(x,z)\,p(x,w)\,p(z,w)}{p(x)\,p(z)\,p(w)\,p(x,z,w)} \;\frac{p(x,y)\,p(x,w)\,p(y,w)}{p(x)\,p(y)\,p(w)\,p(x,y,w)}\]

where the terms in gray have been passed to the lhs of Eq. 18 applied to \(p(.)\). This ultimately leads to the analog of the Bayesian Network factorization in Eq. 15 but for the two-collider path, \(X\to Z\longleftrightarrow Y\gets W\) (Fig. 1D),

\[q(x,z,y,w) \equiv p(x,z,y,w)\;\frac{p(x)\,p(w)}{p(x,w)}\;\frac{p(z|x)\,p(w|x)}{p(z,w |x)}\;\frac{p(x|w)\,p(y|w)}{p(x,y|w)}\] (20)

where the last three factors "correct" the expression of \(p(x,z,y,w)\) for the three (conditional) independences entailed by the underlying graph, that is, \(X\perp W\), \(Z\perp W|X\), and \(X\perp Y|W\).

### Relation to the head-and-tail factorizations

The head-and-tail factorizations of the model distribution of an acyclic directed mixed graph, introduced by Richardson 2009 [6], enable the parametrization of the joint probability distribution with independent parameters for ancestrally closed subsets of vertices.

For instance, the head-and-tail factorizations of the simple two-collider path including one bidirected edge, \(X\to Z\longleftrightarrow Y\gets W\), introduced above, Fig. 1D, are [6],

\[q(x,w) = q(x)\,q(w)\] \[q(x,z) = q(z|x)\;q(x)\] \[q(y,w) = q(y|w)\;q(w)\] \[q(x,z,w) = q(z|x)\;q(x)\,q(w)\] \[q(x,y,w) = q(y|w)\;q(w)\,q(x)\] \[q(x,z,y,w) = q(z,y|x,w)\;q(x)\,q(w)\] (21)

Importantly, these head-and-tail factorizations imply additional relations such as \(q(y|w)=q(y|x,w)\) (_i.e._\(X\perp Y|W\)) obtained by comparing the last two relations in Eq. 21 after marginalizing \(q(x,z,y,w)\) over \(z\). However, such implicit conditional independence relations are _not verified by the empirical distribution_\(p(.)\)_in general_ and prevent the estimation of the head-and-tail factorizations by substituting the rhs \(q(.)\) terms in Eq. 21 with their empirical counterparts \(p(.)\), as in the case of Bayesian networks, Eq. 15.

Indeed, while the head-and-tail factorization relations, Eq. 21, obey the local and global Markov independence relations entailed by the graphical model, Fig. 1D, leading to the cancellation of all factors associated to non-\(ac\)-connected subsets in gray in Eq. 18, the remaining head-and-tail factors cannot be readily estimated with the empirical distribution \(p(.)\).

In particular, the cross-entropy of the two-collider path of interest, Fig. 1D, obtained with the head-and-tail factorizations corresponds to1\(H(p,q)\!=\!-\sum p(x,z,y,w)\log q(z,y|x,w)\,q(x)\,q(w)\). Then, estimating the \(q(.)\) terms with their \(p(.)\) counterparts leads to the cross-entropy of a Bayesian graph, Fig. 1E, with a different Markov equivalent class than the ancestral graph of interest, Fig. 1D. A similar discrepancy is obtained with a c-component factorization which leads to the cross-entropy of the Bayesian graph of Fig. 1E without edge \(X\to Y\), corresponding to a different Markov equivalence class than the previous two graphs, Figs. 1D & E.

Footnote 1: Indeed, all terms in Eq. 18 actually cancel two-by-two by construction, _whatever their factorization expression_, except for the remaining joint-distribution over all variables, \(q(x,z,y,w)\!=\!q(z,y|x,w)\,q(x)\,q(w)\).

These examples illustrate the difficulty to exploit the c-component or head-and-tail factorizations to estimate the likelihood of ancestral graphs including bidirected edge(s).

## Appendix D Node and edge scores based on Normalized Maximum Likelihood criteria

Search-and-score methods based on likelihood estimates need to properly account for finite sample size, as cross-entropy minimization leads to ever more complex models, resulting in model overfitting for finite datasets. While BIC regularization is valid in the asymptotic limit of very large datasets, it tends to overestimate finite size corrections, leading to lower recall, in general. In order to better take into account finite sample size, we used instead the (universal) Normalized Maximum Likelihood (NML) criteria [42, 43, 38, 39], which amounts to normalizing the likelihood function over all possible datasets with the same number \(N\) of samples.

**Node score**. We first used the factorized Normalized Maximum Likelihood (fNML) complexity [38, 39] to define a local score for each node \(X_{i}\), which extends the decomposable likelihood of Bayesian graphs given each node's parents, Eq. 2, to all non-descendant neighbors, \(\mathbf{Pa}^{\prime}_{X_{i}}\),

\[\mathcal{L}_{\mathcal{D}|\mathcal{G}_{X_{i}}}=\ e^{-N.\,\mathrm{ Score}_{n}(X_{i})} = \frac{e^{-NH(X_{i}|\mathbf{Pa}^{\prime}_{X_{i}})}}{\sum_{| \mathcal{D}^{\prime}|=N}e^{-NH(X_{i}|\mathbf{Pa}^{\prime}_{X_{i}})}}\] (22) \[= e^{-NH(X_{i}|\mathbf{Pa}^{\prime}_{X_{i}})-\sum_{j}^{q_{i}}\log \mathcal{C}_{n_{j}}^{r_{i}}}\] (23) \[= e^{N\sum_{j}^{q_{i}}\sum_{k}^{r_{i}}\frac{n_{jk}}{N}\log\left( \frac{n_{jk}}{n_{j}}\right)-\sum_{j}^{q_{i}}\log\mathcal{C}_{n_{j}}^{r_{i}}}\] (24) \[= \prod_{j}^{q_{i}}\frac{\prod_{k}^{r_{i}}\left(\frac{n_{jk}}{n_{j }}\right)^{n_{jk}}}{\mathcal{C}_{n_{j}}^{r_{i}}}\] (25)

where \(n_{jk}\) corresponds to the number of data points for which \(X_{i}\) is in its \(k\)th state and its non-descendant neighbors in their \(j\)th state, with \(n_{j}=\sum_{k}^{r_{i}}n_{jk}\). The universal normalization constant \(\mathcal{C}_{n}^{r}\) is then computed by summing the numerator over all possible partitions of the \(n\) data points into a maximum of \(r\) subsets, \(\ell_{1}+\ell_{2}+\cdots+\ell_{r}=n\) with \(\ell_{k}\geqslant 0\),

\[\mathcal{C}_{n}^{r}=\sum_{\ell_{1}+\ell_{2}+\cdots+\ell_{r}=n}\frac{n!}{\ell_{ 1}!\ell_{2}!\cdots\ell_{r}!}\prod_{k=1}^{r}\left(\frac{\ell_{k}}{n}\right)^{ \ell_{k}}\] (26)

which can in fact be computed in linear-time using the following recursion [38],

\[\mathcal{C}_{n}^{r}=\mathcal{C}_{n}^{r-1}+\frac{n}{r-2}\mathcal{C}_{n}^{r-2}\] (27)

with \(\mathcal{C}_{n}^{1}=1\) for all \(n\) and applying Eq. 30 below for \(r=2\). However, for large \(n\) and \(r\), \(\mathcal{C}_{n}^{r}\) computation tends to be numerically unstable, which can be circumvented by implementing the recursion on parametric complexity ratios \(\mathcal{D}_{n}^{r}=\mathcal{C}_{n}^{r}/\mathcal{C}_{n}^{r-1}\) rather than parametric complexities themselves [35] as,

\[\mathcal{D}_{n}^{r} = 1+\frac{n}{(r-2)\mathcal{D}_{n}^{r-1}}\] (28) \[\log\mathcal{C}_{n}^{r} = \sum_{k=2}^{r}\log\mathcal{D}_{n}^{k}\] (29)for \(r\geqslant 3\), with \(\mathcal{C}_{n}^{1}=1\) and \(\mathcal{C}_{n}^{2}=\mathcal{D}_{n}^{2}\), which can be computed directly with the general formula, Eq. 26, for \(r=2\),

\[\mathcal{C}_{n}^{2}=\sum_{h=0}^{n}\binom{n}{h}\left(\frac{h}{n}\right)^{h} \left(\frac{n-h}{n}\right)^{n-h}\] (30)

or its Szpankowski approximation for large \(n\) (needed for \(n>1000\) in practice) [44, 45, 46],

\[\mathcal{C}_{n}^{2} =\sqrt{\frac{n\pi}{2}}\left(1+\frac{2}{3}\sqrt{\frac{2}{n\pi}}+ \frac{1}{12n}+\mathcal{O}\left(\frac{1}{n^{3/2}}\right)\right)\] (31) \[\simeq\sqrt{\frac{n\pi}{2}}\exp\left(\sqrt{\frac{8}{9n\pi}}+ \frac{3\pi-16}{36n\pi}\right)\] (32)

This leads to the following local score for each node \(X_{i}\), which is minimized over alternative combinations of non-descendant neighbors, \(\mathbf{Pa}^{\prime}_{{}_{X_{i}}}\subseteq\mathbf{Pa}_{{}_{X_{i}}}\cup \mathbf{Sp}_{{}_{X_{i}}}\cup\mathbf{Ne}_{{}_{X_{i}}}\), in the first step of the local search-and-score algorithm (step 1) detailed in the main text,

\[\mathrm{Score}_{\mathrm{n}}(X_{i})=H(X_{i}|\mathbf{Pa}^{\prime}_{{}_{X_{i}}})+ \frac{1}{N}\sum_{j}^{q_{x_{i}}}\log\mathcal{C}_{n_{j}}^{r_{x_{i}}}\] (33)

**Edge scores**. We then defined several edge scores to optimize the orientation of each edge, \(X-Y\), given its close surrounding vertices.

To this end, we first introduced a local score for node pairs which simply sums the node scores, Eq. 33, for each node. The resulting pair scores are listed in Table 2 for unconnected node pairs and for pairs of nodes connected by a directed edge, where \(\mathbf{Pa}^{\prime}_{{}_{X\!\!,\!Y}}=\mathbf{Pa}_{{}_{X}}\cup\mathbf{Sp}_{{}_{ X}}\backslash Y\) and \(\mathbf{Pa}^{\prime}_{{}_{Y\!\!,\!X}}=\mathbf{Pa}_{{}_{Y}}\cup\mathbf{Sp}_{{}_{ Y}}\backslash X\) with their corresponding combinations of levels, \(q_{y_{\!y}}\) and \(q_{x_{\!y}}\).

Then, edge scores for directed edges, \(X\to Y\) and \(Y\to X\), are defined w.r.t. to the edge removal score, \(X\not\sim Y\), by substracting the pair scores of unconnected pairs to the pair scores of directed edges, leading to the following edge orientation scores,

\[\mathrm{Score}(X\to Y) = -I(X;Y|\mathbf{Pa}^{\prime}_{{}_{Y\!\!,\!X}})+\frac{1}{N}\Big{(} \sum_{j}^{q_{y_{\!y}}r_{x}}\log\mathcal{C}_{n_{j}}^{r_{y}}-\sum_{j}^{q_{y_{ \!y}}}\log\mathcal{C}_{n_{j}}^{r_{y}}\Big{)}\] (34) \[\mathrm{Score}(Y\to X) = -I(X;Y|\mathbf{Pa}^{\prime}_{{}_{X\!\!,\!Y}})+\frac{1}{N}\Big{(} \sum_{j}^{q_{x_{\!y}}r_{y}}\log\mathcal{C}_{n_{j}}^{r_{x}}-\sum_{j}^{q_{y_{ \!y}}}\log\mathcal{C}_{n_{j}}^{r_{x}}\Big{)}\] (35)

However, if \(r_{x}\neq r_{y}\), the fNML complexities of these orientation scores are not identical for Markov equivalent edge orientations between nodes sharing the same parents (or spouses) [47], \(\mathbf{Pa}^{\prime}_{{}_{Y\!\!,\!X}}=\mathbf{Pa}^{\prime}_{{}_{X\!\!,\!Y}}= \mathbf{Pa}^{\prime}\) and \(q_{y_{\!y}}=q_{{}_{x_{\!y}}}\), despite sharing the same conditional mutual information,

\[I(X;Y|\mathbf{Pa}^{\prime}) = \frac{1}{2}\Big{(}H(X|\mathbf{Pa}^{\prime})+H(Y|\mathbf{Pa}^{ \prime},X)\Big{)}+\frac{1}{2}\Big{(}H(X|\mathbf{Pa}^{\prime},Y)+H(Y|\mathbf{Pa} ^{\prime})\Big{)}\] (36)

This suggests to symmetrize the fNML complexities for edge orientation scores by averaging them over each directed orientation, as for the conditional information in Eq. 36, leading to the proposed fNML complexity for directed edges given in Table 1 in the main text.

\begin{table}
\begin{tabular}{l l l} \hline Pair score & Information & fNML Complexity \\ \(X\not\sim Y\) & \(H(X|\mathbf{Pa}^{\prime}_{{}_{X\!\!,\!Y}})+H(Y|\mathbf{Pa}^{\prime}_{{}_{Y\! \!,\!X}})\) & \(\frac{1}{N}\Big{(}\sum_{j}^{q_{x_{\!y}}}\log\mathcal{C}_{n_{j}}^{r_{x}}+\sum_{j }^{q_{y_{\!x}}}\log\mathcal{C}_{n_{j}}^{r_{y}}\Big{)}\) \\ \(X\to Y\) & \(H(X|\mathbf{Pa}^{\prime}_{{}_{X\!\!,\!Y}})+H(Y|\mathbf{Pa}^{\prime}_{{}_{Y\! \!,\!X}})\) & \(\frac{1}{N}\Big{(}\sum_{j}^{q_{x_{\!y}}}\log\mathcal{C}_{n_{j}}^{r_{x}}+\sum_{j }^{q_{y_{\!y}}}\log\mathcal{C}_{n_{j}}^{r_{y}}\Big{)}\) \\ \(X\gets Y\) & \(H(X|\mathbf{Pa}^{\prime}_{{}_{X\!\!,\!Y}},Y)+H(Y|\mathbf{Pa}^{\prime}_{{}_{Y\! \!,\!X}})\) & \(\frac{1}{N}\Big{(}\sum_{j}^{q_{x_{\!y}}r_{y}}\log\mathcal{C}_{n_{j}}^{r_{x}}+ \sum_{j}^{q_{y_{\!y}}}\log\mathcal{C}_{n_{j}}^{r_{y}}\Big{)}\) \\ \hline \end{tabular}
\end{table}
Table 2: Local scores for node pairsFor bidirected edges, the proposed local orientation score accounts for all \(ac\)-connected subsets in close vicinity of the bidirected edge, which concerns all subsets including either \(X\) and any combination (possibly void) of parents or spouses different from \(Y\) (_i.e._ corresponding to the information contributions \(H(X|\mathbf{Pa}^{\prime}_{{}_{XY}})\)) or \(Y\) and any combination of parents or spouses different from \(X\) (_i.e._ corresponding to the information contributions \(H(Y|\mathbf{Pa}^{\prime}_{{}_{Y\setminus X}})\)) or, else, including both nodes \(X\) and \(Y\) plus any combination of their parents or spouses, corresponding to the following information contribution, \(-I(X;Y|\mathbf{Pa}^{\prime}_{{}_{XY}})\), where \(\mathbf{Pa}^{\prime}_{{}_{XY}}=\mathbf{Pa}^{\prime}_{{}_{XY}}\cup\mathbf{Pa}^{ \prime}_{{}_{Y\setminus X}}\). This last term, \(-I(X;Y|\mathbf{Pa}^{\prime}_{{}_{XY}})\), contains all the remaining information contributions once the bidirected orientation score is given relative to the edge removal score (Table 2) as for the two directed orientation scores, above. Finally, the symmetrized fNML complexity associated with a bidirected edge should be computed with the whole set of conditioning parents or spouses, \(\mathbf{Pa}^{\prime}_{{}_{XY}}\), as indicated in Table 1. Note that this bidirected orientation score becomes also Markov equivalent to the two directed orientation scores, as required, when the nodes share the same parents and spouses, _i.e._\(\mathbf{Pa}^{\prime}_{{}_{XY}}=\mathbf{Pa}^{\prime}_{{}_{Y\setminus X}}= \mathbf{Pa}^{\prime}_{{}_{X\setminus Y}}\) and \(q_{{}_{xy}}=q_{{}_{\psi x}}=q_{{}_{\psi y}}\) in Table 1.

## Appendix E Toy models

Fig. 3 shows three simple ancestral models used to test MILC_search&score orientation scores (Table 1) to effectively predict bidirected orientations when the end nodes do not share the same parents (Model 1), share some parents (Model 2) or when the bidirected edge is part of a longer than two-collider paths (Model 3).

The data is generated from the theoretical DAG using the rmvDAG function in the pcalg package [48]. Each node follows a normal distribution, and the data is discretized using bnlearn's discretize function using Hartemink's pairwise mutual information method [40]. For these toy models, the edge orientation scores are computed assuming the correct parents of each node.

The prediction of the edge orientation scores are summarized in Table 3 in % of replicates displaying directed edges (wrong) or bidirected edge (correct) as a function of increasing dataset size \(N\).

Figure 3: **Simple ancestral graphs.**

NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: The main claims of the paper are supported by the theoretical and experimental results shown in Figs. 1 & 2, respectively. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: We have added a Discussion & Limitation section at the end of the paper. The main limitation of the experimental results is the fact that we did not have sufficient time to perform many dataset replicates of the benchmark ancestral graphs. While the obtained statistics already support our main experimental results, we intend to perform more dataset replicates for the final version of the paper. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.

3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: For the theoretical results (notably Theorem 1) we provide the full set of assumptions (section 2 and Appendix A)and a complete proof (Appendix B). Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: We provided the full description of the experiments run in the paper (sections 2 & 3 and Appendix D). The open-source code reproducing the experimental results presented in the paper will be provided with the camera-ready version of the paper. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset).

* We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
* **Open access to data and code*
* Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [No] Justification: We do not include a new code with the initial submission, as it is not yet properly packaged at submission time, but we definitely intend to release this open-source code including proper annotation and userguide with the final camera-ready version of the paper. MILC and FCI open-source packages used for benchmark comparison are already published and available on public servers. Guidelines:
* The answer NA means that paper does not include experiments requiring code.
* Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
* **Experimental Setting/Details*
* Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: We provided the full description of the experiments run in the paper (sections 2.3 and Appendix D). Guidelines:
* The answer NA means that the paper does not include experiments.
* The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them.
* The full details can be provided either with the code, in appendix, or as supplemental material.
* **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes]Justification: The 1-sigma error bars are plotted in Fig. 2. While these statistics already support our experimental results, we intend to perform more dataset replicates for the final version of the paper, which we did not have sufficient time to perform by the time of submission. This should reduce some error bars, in particular, those for the results displaying large error bars. Guidelines:

* The answer NA means that the paper does not include experiments.
* The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.
* The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).
* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.

8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: The computer resource used for all experiments is a simple laptop with intel i7 processors, 12 cores and 16 threads. Guidelines:

* The answer NA means that the paper does not include experiments.
* The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.
* The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.
* The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).

9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: The paper does not use or produce sensitive data nor concern potentially harmful applications. Guidelines:

* The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
* If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.

* The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: The paper does not use or produce sensitive data nor concern potentially harmful applications. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. * If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: The paper does not use or produce sensitive data nor concern potentially harmful applications. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected?Answer: [Yes] Justification: We have credited all previously published resources (including license details) used in the paper.

Guidelines:

* The answer NA means that the paper does not use existing assets.
* The authors should cite the original paper that produced the code package or dataset.
* The authors should state which version of the asset is used and, if possible, include a URL.
* The name of the license (e.g., CC-BY 4.0) should be included for each asset.
* For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.
* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.

13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets?

Answer: [NA] Justification: We do not include a new code with the initial submission, as it is not yet properly packaged at submission time, but we definitely intend to release this open-source code including proper annotation and userguide with the final camera-ready version of the paper.

Guidelines:

* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.

14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)?

Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.

15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper. * We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution. * For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.