# Protein-Nucleic Acid Complex Modeling with Frame Averaging Transformer

Tinglin Huang\({}^{1}\)

Correspondence to tinglin.huang@yale.edu

Zhenqiao Song\({}^{2}\)

Rex Ying\({}^{1}\)

Wengong Jin\({}^{3,4}\)

\({}^{1}\)Yale University, \({}^{2}\)Carnegie Mellon University,

\({}^{3}\)Northeastern University, Khoury College of Computer Sciences

\({}^{4}\)Broad Institute of MIT and Harvard

###### Abstract

Nucleic acid-based drugs like aptamers have recently demonstrated great therapeutic potential. However, experimental platforms for aptamer screening are costly, and the scarcity of labeled data presents a challenge for supervised methods to learn protein-aptamer binding. To this end, we develop an unsupervised learning approach based on the predicted pairwise contact map between a protein and a nucleic acid and demonstrate its effectiveness in protein-aptamer binding prediction. Our model is based on FAFormer2, a novel equivariant transformer architecture that seamlessly integrates frame averaging (FA) within each transformer block. This integration allows our model to infuse geometric information into node features while preserving the spatial semantics of coordinates, leading to greater expressive power than standard FA models. Our results show that FAFormer outperforms existing equivariant models in contact map prediction across three protein complex datasets, with over 10% relative improvement. Moreover, we curate five real-world protein-aptamer interaction datasets and show that the contact map predicted by FAFormer serves as a strong binding indicator for aptamer screening.

Footnote 2: https://github.com/Graph-and-Geometric-Learning/Frame-Averaging-Transformer

## 1 Introduction

Nucleic acids have recently shown significant potential in drug discovery, as shown by the success of mRNA vaccines [26, 61, 60] and aptamers [15, 32, 14, 41]. Aptamers are single-stranded nucleic acids capable of binding to a wide range of molecules, including previously undruggable targets [20, 11]. Currently, aptamer discovery is driven by high-throughput screening, which is time-consuming and labor-intensive. While machine learning can potentially accelerate this process, the limited availability of labeled data presents a significant challenge in ML-guided aptamer discovery [57, 44, 16]. Given this challenge, our goal is to build an unsupervised protein-nucleic acid interaction predictor for large-scale aptamer screening.

Motivated by previous work on unsupervised protein-protein interaction prediction [34], we focus on predicting the contact map between proteins and nucleic acids at the residue/nucleotide level. The main idea is that a predicted contact map offers insights into the likelihood of a protein forming a complex with an aptamer, thereby encoding the binding affinity between them. Concretely, as shown in Figure 1(a), our model is trained to identify specific contact pairs between residues and nucleotides when forming a complex. The maximum contact probability across all pairs is then interpreted as the binding affinity, which is subsequently used for aptamer screening.

[MISSING_PAGE_FAIL:2]

Protein complex modelingThe prediction and understanding of interactions between proteins and molecules play a crucial role in biomedicine. For example, some prior studies focus on developing a geometric learning method to predict the conformation of a small molecule when it binds to a protein target [71; 19; 53; 50]. As for the protein-protein complex, [25; 29] explore the application of machine learning in predicting the structure of protein multimer. Some studies [77; 56] investigate the protein-protein interface prediction in the physical space. Jin et al. [38] studies the protein-protein affinity prediction in an unsupervised manner. For protein-nucleic acid, some prior works explore the identification of the nucleic-acid-binding residues on protein [65; 86; 89; 37; 85] or predict the binding probability of RNA on proteins [79; 82; 87; 54]. Some previous studies focus on modeling protein-nucleic acid complex by computational method [81; 80; 28]. AlphaFold3 [1] and RoseTTAFoldNA [5] are the recent progresses in this field, which both are pretrained language models for complex structure prediction.

Geometric deep learningRecently, geometric deep learning achieved great success in chemistry, biology, and physics domains [13; 90; 40; 55; 52; 64; 10; 70]. The previous methods roughly fall into four categories: 1) Invariant methods extract invariant geometric features from the molecules, such as pairwise distance and torsion angles, to exhibit invariant transformations [67; 31; 30]; 2) Spherical harmonics-based models leverage the functions derived from spherical harmonics and irreducible representations to transform data equivariantly [27; 47; 75]; 3) Some methods encode the coordinates and node features in separate branches, interacting these features through the norm of coordinates [66; 39]; 4) Frame averaging (FA) [63; 21] framework proposes to model the coordinates in eight different frames extracted by PCA, achieving equivariance by averaging the encoded representations.

The proposed FAFormer combines the strengths of FA and the third category of methods by encoding and interacting coordinates with node features using FA-based components. Besides, FAFormer can also be viewed as a combination of GNN and Transformer architectures, as the edge representation calculation functions similarly to message passing in GNN. This integration is made possible by the flexibility provided by FA as an integrated component.

## 3 Frame Averaging Transformer

In this section, we present our proposed FAFormer, a frame averaging (FA)-based transformer architecture. We first introduce the FA framework in Section 3.1 and elaborate on the proposed FAFormer in Section 3.2. Discussion on the equivariance is provided in Section 3.3, and the computational complexity analysis can be found in Appendix B.

### Background: Frame Averaging

Frame averaging (FA) [63] is an encoder-agnostic framework that can make a given encoder equivariant to the Euclidean symmetry group. FA applies the principle components derived via Principal Component Analysis (PCA) to construct the frame capable of achieving \(E(3)\) equivariance. Specifically, the frame function \(\mathcal{F}(\cdot)\) maps a given set of coordinates \(\bm{X}\) to eight transformations:

\[\mathcal{F}(\bm{X})=\{(\bm{U},\bm{c})|\bm{U}=[\alpha_{1}\bm{u}_{1},\alpha_{2} \bm{u}_{2},\alpha_{3}\bm{u}_{3}],\alpha_{i}\in\{-1,1\}\}\] (1)

where \(\bm{u}_{1},\bm{u}_{2},\bm{u}_{3}\) are the three principal components of \(\bm{X}\), \(\bm{U}\in\mathbb{R}^{3\times 3}\) denotes the rotation matrix based on the principal components, and \(\bm{c}\in\mathbb{R}^{3}\) is the centroid of \(\bm{X}\). The main idea of FA is to encode the coordinates as projected by the transformations, followed by averaging these representations. We introduce \(f_{\mathcal{F}}(\cdot)\) to represent the projections of given coordinates via \(\mathcal{F}(\cdot)\):

\[\begin{split} f_{\mathcal{F}}(\bm{X})&:=\{(\bm{X}- \bm{c})\bm{U}\mid(\bm{U},\bm{c})\in\mathcal{F}(\bm{X})\}\\ &:=\{\bm{X}^{(g)}\}_{\mathcal{F}}\end{split}\] (2)

where \(\bm{X}^{(g)}\) denotes the coordinates transformed by \(g\)-th transformations. We can apply any encoder \(\Phi(\cdot)\) to the projected coordinates and achieve equivariance by averaging, which can be formulated as an inverse mapping \(f_{\mathcal{F}^{-1}}(\cdot)\):

\[f_{\mathcal{F}^{-1}}\left(\{\Phi(\bm{X}^{(g)})\}_{\mathcal{F}}\right):=\frac{1 }{|\mathcal{F}(\bm{X})|}\sum_{g}\Phi(\bm{X}^{(g)})\bm{U}_{g}^{-1}+\bm{c}\] (3)where \(\bm{U}_{g}^{-1}\) is the inverse matrix of \(g\)-th transformations and the result exhibit \(E(3)\) equivariance. The outcome is invariant when simply averaging the representations without inverse matrix.

### Model Architecture

Instead of serving FA as an external encoder wrapper, we propose instantiating FA as an integral geometric component within Transformer. This integration preserves equivariance and enables the model to encode coordinates effectively in the latent space, ensuring compatibility with Transformer architecture. The overall architecture is illustrated in Figure 2.

Graph ConstructionEach molecule can be naturally represented as a graph [47; 35; 43] where the residues/nucleic acids are the nodes and the interactions between them represent the edges. To efficiently model the macro-molecules (i.e., protein and nucleic acid), we restrict the attention for each node \(i\) to its \(K\)-nearest neighbors \(\mathcal{N}_{\text{top-}K}(i)\), within a predetermined distance cutoff \(c\):

\[\mathcal{N}(i)=\{j|d_{ij}\leq c\text{ and }j\in\mathcal{N}_{\text{top-}K}(i)\}\] (4)

where we use \(\mathcal{N}(i)\) to denote the valid neighbors of node \(i\), and \(d_{ij}\) denotes the distance between node \(i\) and \(j\). The long-range context information can be captured by iterative attention within the local neighbors for each node \(i\).

Overall ArchitectureAs shown in Figure 2(a), the input of FAFormer comprises the node features \(\bm{Z}\in\mathbb{R}^{N\times D}\), coordinates \(\bm{X}\in\mathbb{R}^{N\times 3}\), and edge representations \(\bm{E}\in\mathbb{R}^{N\times K\times D}\) derived by our proposed edge module, where \(N\) is the number nodes and \(D\) is the hidden size. FAFormer processes and updates the input features at each layer:

\[\bm{Z}^{(l+1)},\bm{X}^{(l+1)},\bm{E}^{(l+1)}=f^{(l)}(\bm{Z}^{(l)},\bm{X}^{(l)},\bm{E}^{(l)})\] (5)

where \(f^{(l)}(\cdot)\) represents \(l\)-th layer of FAFormer. In each model layer, we first update coordinates and node features using the Biased MLP Attention Module. Then, these features are fed into Local Frame Edge Module to refine the edge representations. Finally, the node representations undergo further updates through Global Frame FFN.

Figure 2: Overview of FAFormer architecture. The input consists of the node features, coordinates, and edge representations, which are processed by a stack of **(b)** Biased MLP Attention Module, **(c)** Local Frame Edge Module, **(d)** Global Frame FFN, and **(e)** Gate Function. \(\sum\) denotes aggregation, \(\cdot\) is multiplication, \(+\) is addition, and \(||\) indicates concatenation. Purple cells indicate the operation related to FA. **(f)** illustrates the difference between the local and global frames, where the local frame captures local interactions among the immediate neighbors for each node, while the global frame captures long-range correlations among all nodes.

FA Linear ModuleBased on FA, we generalize the vanilla linear module to encode coordinates in the latent space invariantly:

\[\text{Linear}_{\mathcal{F}}(\bm{X}):=\frac{1}{|\mathcal{F}(\bm{X})|}\sum_{g} \text{Norm}(\bm{X}^{(g)})\bm{W}_{g}\] (6)

where \(\{\bm{X}^{(g)}\}_{\mathcal{F}}\) is obtained using Equ.(2), \(\bm{W}_{g}\in\mathbb{R}^{3\times D}\) is a learnable matrix for \(g\)-th transformations, and \(\text{Norm}(\bm{X}):=\bm{X}/\sqrt{\frac{1}{v}||\bm{X}||_{2}^{2}}\) is the normalization which scales the coordinates such that their root-mean-square norm is one [39]. \(\text{Linear}_{\mathcal{F}}(\cdot)\) is an invariant transformation and will serve as a building block within each layer of the model.

Local Frame Edge ModuleWe explicitly embed the interactions between each node and its neighbors as the edge representation \(\bm{E}\in\mathbb{R}^{N\times K\times D}\), where \(K\) is the number of the neighbors. It encodes the relational information and represents the bond interaction between nodes, which is critical in understanding the conformation of molecules [40, 4, 35].

As shown in Figure 2(f), unlike the vanilla FA which _globally_ encodes the geometric context of the entire molecule, the edge module builds frame _locally_ around each node's neighbors. Specifically, given a node \(i\) and its neighbor \(j\in\mathcal{N}(i)\), the geometric context is encoded within the local neighborhood:

\[\{\bm{X}_{i\to j}^{\prime}\}_{\mathcal{N}(i)}=\text{Linear}_{ \mathcal{F}}\left(\{\bm{X}_{i}-\bm{X}_{j}\}_{\mathcal{N}(i)}\right)\] (7)

where \(\{\bm{X}_{i}-\bm{X}_{j}\}_{\mathcal{N}(i)}\) denotes the direction vectors from center node \(i\) to its neighbors, and \(\bm{X}_{i\to j}^{\prime}\in\mathbb{R}^{d}\) is the encoded representation. With the local frame, the spatial information sent from one source node depends on the target node, which is compatible with the attention mechanism. Then the node features are engaged with geometric features, and the edge representation is finalized through the residual connection with the gate mechanism:

\[\bm{m}_{ij}=\text{Linear}(\bm{Z}_{i}||\bm{Z}_{j}||\bm{X}_{i\to j}^{ \prime})\quad\text{and}\quad\bm{E}_{ij}^{\prime}=\bm{g}_{ij}\cdot\bm{m}_{ij}+ \bm{E}_{ij}\] (8)

where \((\cdot||\cdot)\) is the concatenation operation, and the calculated gate \(\bm{g}_{ij}=\sigma(\text{Linear}(\bm{m}_{ij}))\) provides flexibility in regulating the impact of updated edge representation.

The encoded edge representation in FAFormer plays a crucial role in modeling the pairwise relationships between nodes, especially for nucleic acid due to their specific base pairing rules [58, 45]. The incorporation of FA facilitates the encoding of the pairwise relationships in a geometric context, resulting in an expressive representation.

Biased MLP Attention ModuleAs shown in Figure 2(b), the attention module of FAFormer first transforms the node features \(\bm{Z}\) into query, key, and value representations:

\[\bm{Z}_{Q}=\bm{Z}\bm{W}_{Q},\ \bm{Z}_{K}=\bm{Z}\bm{W}_{K},\ \bm{Z}_{V}=\bm{Z}\bm{W}_{V}\] (9)

where \(\bm{W}_{Q},\bm{W}_{K},\bm{W}_{V}\in\mathbb{R}^{D\times D}\) are the learnable projections. We adopt MLP attention [12] to derive the attention weight between node pairs, which can effectively capture any attention pattern. The relational information from the edge representation is integrated as an additional bias term:

\[a_{ij}=\text{Softmax}_{i}\left(\text{Linear}(\bm{Z}_{Q,i}||\bm{Z}_{K,j})+b_{ ij}\right),\] (10)

where \(b_{ij}=\text{Linear}(\text{LN}(\bm{E}_{ij}))\) represents the scalar bias term based on the edge representation, \(a_{ij}\) denotes the attention score between \(i\)-th and \(j\)-th nodes, \(\bm{Z}_{*,i}\) is \(i\)-th representation of the matrix \(\bm{Z}_{*}\), \(\text{Softmax}_{i}(\cdot)\) is the softmax function operated on the attention scores of node \(i\)'s neighbors, and \(\text{LN}(\cdot)\) is layernorm function [3].

Besides the value embeddings, the edge representation will also be aggregated to serve as the context for the update of node feature in FAFormer:

\[\bm{Z}_{i}^{*} =\sum_{j\in\mathcal{N}(i)}a_{ij}\bm{Z}_{j},\bm{E}_{i}^{*}=\sum_{j \in\mathcal{N}(i)}a_{ij}\bm{E}_{ij},\] (11) \[\bm{Z}_{i}^{\prime} =\text{LN}\left(\text{Linear}(\bm{Z}_{i}^{*}||\bm{E}_{i}^{*}) \right)+\bm{Z}_{i}\] (12)where \(\bm{Z}^{\prime}_{i}\) is the update representation of node \(i\). The above attention can be extended to a multi-head fashion by performing multiple parallel attention functions. For the coordinates, we employ an equivariant aggregation function that supports multi-head attention:

\[\bm{X}^{*}=f_{\mathcal{F}^{-1}}\left(\{[\bm{A}^{(0)}\bm{X}^{(g)},\cdots,\bm{A}^{ (H)}\bm{X}^{(g)}]\bm{W}\}_{\mathcal{F}}\right)\] (13)

where \(\{\bm{X}^{(g)}\}_{\mathcal{F}}=f_{\mathcal{F}}(\bm{X})\), \(H\) is the number of attention heads, \([\cdot]\) is the tensor stack operation and \(\bm{W}\in\mathbb{R}^{H\times 1}\) is a linear transformation for aggregating coordinates in different heads. An additional gate function that uses node representations as input to modulate the aggregation is applied:

\[\bm{X}^{\prime}=\bm{g}_{\text{attn}}\cdot\bm{X}^{*}+(1-\bm{g}_{\text{attn}}) \cdot\bm{X}\] (14)

where \(\bm{g}_{\text{attn}}=\sigma(\text{Linear}(\bm{Z}))\) is the vector-wise gate designed to modulate the integration between the aggregated and the original coordinates. This introduced gate mechanism further encourages the communication between node features and geometric features.

Global Frame FFNTo further exploit the interaction between node features and coordinates, we extend the conventional FFN to _Global Frame_ FFN which integrates spatial locations with node features through FA, which is illustrated in Figure 2(d):

\[\bm{X}_{v}=\text{Linear}_{\mathcal{F}}(\bm{X})\quad\text{and}\quad\bm{Z}^{ \prime}=\text{FFN}(\bm{Z}||\bm{X}_{v})+\bm{Z}\] (15)

where \(\text{FFN}(\cdot)\) denotes a two-layer fully connected feed-forward network. This integration of spatial information \(\bm{X}_{v}\) into the feature vectors enables the self-attention mechanism to operate in a geometric-aware manner. Unlike the edge module that focuses on each node's local neighbors, global frame FFN encodes the coordinates of all nodes, thereby capturing the long-range correlation among nodes.

### Equivariance

The function \(\text{Linear}_{\mathcal{F}}(\cdot)\) exhibits invariance since results are simply averaged across different transformations. In light of this, the node representation generated by the edge module and FFN are also invariant. The biased attention is based on the scalar features so the output is always invariant.

The update of coordinates within FAFormer leverages a multi-head attention aggregation with a gate function. Both functions are \(E(3)\)-equivariant: attention aggregation is based on frame averaging, while gate function is linear and also exhibits \(E(3)\)-equivariance, with a formal proof in Appendix C.

In conclusion, FAFormer is symmetry-aware which exhibits invariance for node representations and \(E(3)\)-equivariance for coordinates.

## 4 Experiments

In this section, we present three protein complex datasets and five aptamer datasets to explore protein complex interactions and evaluate the effectiveness of FAFormer. More details regarding the experiments and datasets can be found in Appendix A and D. Additional experiments, including the ablation studies, and the comparison with AlphaFold3, can be found in Appendix E. All the datasets used in this study are included in our anonymous repository.

### Dataset

Protein ComplexesWe cleaned up and constructed three 3D structure datasets of protein complexes from multiple sources [8; 7; 2; 77]. A residue-nucleotide pair is determined to be in contact if any of their atoms are within 6A from each other [77; 78]. We conduct dataset splitting based on the protein sequence identity, using a threshold of 50% for protein-RNA/DNA complexes3 and 30% for protein-protein complexes. The details of all datasets are shown in Table 1.

Footnote 3: Note that we don’t use 30% as the threshold since it results in a very limited validation and test set.

The protein's and nucleic acid's structures in the validation/test sets are generated by ESMFold [48] (proteins) or RoseTTAFoldNA (nucleic acids). This offers a more realistic scenario, given that the crystal structures are often unavailable.

[MISSING_PAGE_EMPTY:7]

[MISSING_PAGE_FAIL:8]

### Comparison with RoseTTAFoldNA

In this section, we investigate the performance of RoseTTAFoldNA [5] which is a pretrained protein complex structure prediction model and compare it with FAFormer. The performance of FAFormer is evaluated on the individual predicted protein and nucleic acid structures by ESMFold and RoseTTAFoldNA. We additionally test the performance of AlphaFold3 [1] on a subset of the screening tasks due to AlphaFold3 server submission limits (Appendix E).

DatasetFor the contact map prediction task, we select the test cases used in RoseTTAFoldNA to create the test set, yielding 86 protein-DNA and 16 protein-RNA cases. Furthermore, the complexes from our collected dataset that have more than 30% protein sequence identity to these test examples are removed. This leads to 1,962 training cases for protein-DNA and 1,094 for protein-RNA, which are used for training FAFormer. The MSAs of proteins and RNAs are retrieved for RoseTTAFoldNA.

For the aptamer screening task, we construct a smaller candidate set for each protein target by randomly sampling 10% candidates, given that the inference of RoseTTAFoldNA with MSA searching is time-consuming. The datasets will be equally split into validation and test sets. More details of these datasets can be found in Appendix D.

ResultsThe comparison results of contact map prediction are presented in Figure 3, where FAFormer can achieve comparable performance to RoseTTAFoldNA using unbounded structures.

\begin{table}
\begin{tabular}{l|c|c c c c c} \hline \hline  & Metric & GFP & HNRPC & NELF & CHK2 & UBLCP1 \\ \hline \multirow{3}{*}{RoseTTAFoldNA} & Top10 Prec. & \(0.4000\) & \(0.1000\) & \(0.0\) & \(0.0\) & \(0.0\) \\  & Top50 Prec. & \(0.3600\) & \(0.0599\) & \(0.0\) & \(0.1000\) & \(0.0199\) \\  & & PRAUC & \(0.3926\) & \(0.1452\) & \(0.0481\) & \(0.1176\) & \(0.0722\) \\ \hline \hline \multirow{3}{*}{FAFormer} & Top10 Prec. & \(0.4000\)\({}_{0.0}\) & \(0.1666\)\({}_{124}\) & \(0.1666\)\({}_{0.081}\) & \(0.1333\)\({}_{1.24}\) & \(0.1000\)\({}_{0.094}\) \\  & Top50 Prec. & \(0.3800\)\({}_{0.18}\) & \(0.0800\)\({}_{0.024}\) & \(0.0866\)\({}_{0.018}\) & \(0.1266\)\({}_{0.039}\) & \(0.0866\)\({}_{0.009}\) \\ \cline{1-1}  & PRAUC & \(0.4027\)\({}_{0.022}\) & \(0.1781\)\({}_{0.089}\) & \(0.1044\)\({}_{0.18}\) & \(0.1374\)\({}_{0.13}\) & \(0.0762\)\({}_{0.16}\) \\ \hline \hline \end{tabular}
\end{table}
Table 6: Comparison results with RoseTTAFoldNA using the sampled datasets, which accounts for the performance differences of FAFormer as shown in Table 5.

Figure 4: Case study based on two complex examples (PDB id: 7DVV and 7KX9), where each heatmap entry represents the contact probability between the nucleotide and residue. In each row, the figure on the left displays the ground truth contact maps, while the figure on the right displays the results predicted by FAFormer.

Figure 3: Contact map prediction on RoseTTAFoldNA test set.

Specifically, our method has higher F1 scores for protein-DNA complexes (0.103 vs. 0.087) and performs comparably for protein-RNA complexes (0.108 vs. 0.12). Besides, Table 6 shows that RoseTTAFoldNA fails to receive positive aptamers for some targets, e.g., NELF and UBLCP1, while FAFormer consistently outperforms RoseTTAFoldNA for all the targets.

Aligning Figure 3 with Table 6, we observe that while FAFormer does not surpass RoseTTAFoldNA in contact map prediction, it significantly excels in aptamer screening. We attribute this to two reasons: 1) Similar to AlphaFold3 (Table 10), RoseTTAFoldNA as a foundational structure prediction model is optimized for general complex structures, which might bias its performance on some specific protein targets. For example, it can achieve good performance on proteins GFP and HNRNPC but fails for NELF. 2) The protein-RNA test set used by RoseTTAFoldNA for contact map prediction is limited, which may not comprehensively evaluate FAFormer.

Case StudyTwo examples of protein-DNA (PDB id: 7DVV) and protein-RNA (PDB id: 7KX9) complexes are provided in Figure 4, which shows a visual comparison between the actual (left) and the predicted (right) contact maps. Note that only the residues involved in the actual contact map are presented for a clear demonstration4. The complete contact map can be found in Appendix E.1. We can find that despite the sparsity of contact pairs, the predicted contact maps show a high degree of accuracy when compared to the ground truth.

Footnote 4: We sort the residue IDs alongside the row ID so that the contact map appears diagnostic.

Time ComparisonTable 7 shows the average and total inference time of FAFormer and RoseTTAFoldNA on the test cases for the contact map prediction task, including the time for predicting the unbound structures for FAFormer. The predicted structures used for the evaluation of FAFormer are generated without protein and RNA MSAs, demonstrating a significantly faster inference speed by orders of magnitude. For the unsupervised aptamer screening task, while RoseTTAFoldNA requires only a single MSA search for each protein target, it needs to search MSAs for each RNA candidate sequence separately. Besides, the inclusion of MSAs results in a large input sequence matrix, leading to a time-consuming folding process of RoseTTAFoldNA.

## 5 Conclusion

This research focuses on predicting contact maps for protein complexes in the physical space and reformulates the task of large-scale unsupervised aptamer screening as a contact map prediction task. To this end, we propose FAFormer, a frame averaging-based Transformer, with the main idea of incorporating frame averaging within each layer of Transformer. Our empirical results demonstrate the superior performance of FAFormer on contact map prediction and unsupervised aptamer screening tasks, which outperforms eight baseline methods on all the tasks.

Broader ImpactsThe proposed paradigm for aptamer screening can be extended to other modalities, such as protein-small molecules and antibody-antigen. Moreover, the strong correlation between contact prediction and affinity estimation demonstrated in our paper can guide future model development. Besides, FAFormer introduces a novel approach to equivariant model design by leveraging the flexibility of FA. This idea opens up numerous possibilities for future research, including exploring different ways to integrate FA with various neural network architectures.

LimitationIn this study, the geometric features utilized in the encoders are limited to the coordinates of the \(C_{\alpha}\) and \(C_{3}\) atoms. Features extracted from the backbone or sidechains have not been used, which may limit the performance of the geometric encoders.

\begin{table}
\begin{tabular}{c|c c|c c} \hline \hline  & \multicolumn{2}{c|}{Protein-DNA} & \multicolumn{2}{c}{Protein-RNA} \\  & Avg. & Total & Avg. & Total \\ \hline \hline RoseTTAFoldNA & \(0.175\)h & \(15.12\)h & \(0.440\)h & \(7.04\)h \\ FAFormer & \(32.65\)s & \(0.78\)h & \(51.75\)s & \(0.23\)h \\ \hline \hline \end{tabular}
\end{table}
Table 7: Inference time on contact map prediction, denoted in seconds (”s”) and hours (“h”).

Acknowledgements

We thank Yangtian Zhang, Junchi Yu, Weikang Qiu, and anonymous reviewers for their valuable feedback on the manuscript. This work was supported by the BroadIgnite Award, the Eric and Wendy Schmidt Center at the Broad Institute of MIT and Harvard, NSF IIS Div Of Information & Intelligent Systems 2403317, and Amazon research.

## References

* [1] Josh Abramson, Jonas Adler, Jack Dunger, Richard Evans, Tim Green, Alexander Pritzel, Olaf Ronneberger, Lindsay Willmore, Andrew J Ballard, Joshua Bambrick, et al. Accurate structure prediction of biomolecular interactions with alphafold 3. _Nature_, pages 1-3, 2024.
* [2] Bartosz Adamczyk, Maciej Antczak, and Marta Szachniuk. Rnasolo: a repository of cleaned pdb-derived rna 3d structures. _Bioinformatics_, 38(14):3668-3670, 2022.
* [3] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. _arXiv preprint arXiv:1607.06450_, 2016.
* [4] Minkyung Baek, Ivan Anishchenko, Ian Humphreys, Qian Cong, David Baker, and Frank DiMaio. Efficient and accurate prediction of protein structure using rosettafold2. _bioRxiv_, pages 2023-05, 2023.
* [5] Minkyung Baek, Ryan McHugh, Ivan Anishchenko, David Baker, and Frank DiMaio. Accurate prediction of nucleic acid and protein-nucleic acid complexes using rosettafoldna. _bioRxiv_, pages 2022-09, 2022.
* [6] Ali Bashir, Qin Yang, Jinpeng Wang, Stephan Hoyer, Wenchuan Chou, Cory McLean, Geoff Davis, Qiang Gong, Zan Armstrong, Junghoon Jang, et al. Machine learning guided aptamer refinement and discovery. _Nature Communications_, 12(1):2366, 2021.
* [7] Helen M Berman, Catherine L Lawson, and Bohdan Schneider. Developing community resources for nucleic acid structures. _Life_, 12(4):540, 2022.
* [8] Helen M Berman, John Westbrook, Zukang Feng, Gary Gilliland, Talapady N Bhat, Helge Weissig, Ilya N Shindyalov, and Philip E Bourne. The protein data bank. _Nucleic acids research_, 28(1):235-242, 2000.
* [9] Nicholas Boyd, Brandon M Anderson, Brent Townshend, Ryan Chow, Connor J Stephens, Ramya Rangan, Matias Kaplan, Meredith Corley, Akshay Tambe, Yuzu Ido, et al. Atom-1: A foundation model for rna structure and function built on chemical mapping data. _bioRxiv_, pages 2023-12, 2023.
* [10] Johann Brehmer, Pim De Haan, Sonke Behrends, and Taco S Cohen. Geometric algebra transformer. _Advances in Neural Information Processing Systems_, 36, 2024.
* [11] Edward N Brody and Larry Gold. Aptamers as therapeutic and diagnostic agents. _Reviews in Molecular Biotechnology_, 74(1):5-13, 2000.
* [12] Shaked Brody, Uri Alon, and Eran Yahav. How attentive are graph attention networks? _arXiv preprint arXiv:2105.14491_, 2021.
* [13] Michael M Bronstein, Joan Bruna, Taco Cohen, and Petar Velickovic. Geometric deep learning: Grids, groups, graphs, geodesics, and gauges. _arXiv preprint arXiv:2104.13478_, 2021.
* [14] Andrey A Buglak, Alexey V Samokhvalov, Anatoly V Zherdev, and Boris B Dzantiev. Methods and applications of in silico aptamer design and modeling. _International Journal of Molecular Sciences_, 21(22):8420, 2020.
* [15] Jonghoe Byun. Recent progress and opportunities for nucleic acid aptamers. _Life_, 11(3):193, 2021.
* [16] Chetan Chandola and Muniasamy Neerathilingam. Aptamers for targeted delivery: current challenges and future opportunities. _Role of novel drug delivery vehicles in nanobiodedicine_, pages 1-22, 2019.
* [17] Jiayang Chen, Zhihang Hu, Siqi Sun, Qingxiong Tan, Yixuan Wang, Qinze Yu, Licheng Zong, Liang Hong, Jin Xiao, Tao Shen, et al. Interpretable rna foundation model from unannotated data for highly accurate rna structure and function predictions. _bioRxiv_, pages 2022-08, 2022.
* [18] Zihao Chen, Long Hu, Bao-Ting Zhang, Aiping Lu, Yaofeng Wang, Yuanyuan Yu, and Ge Zhang. Artificial intelligence in aptamer-target binding prediction. _International journal of molecular sciences_, 22(7):3605, 2021.

* Corso et al. [2022] Gabriele Corso, Hannes Stark, Bowen Jing, Regina Barzilay, and Tommi Jaakkola. Difffock: Diffusion steps, twists, and turns for molecular docking. _arXiv preprint arXiv:2210.01776_, 2022.
* Coutinho et al. [2019] Maria Francisca Coutinho, Liliana Matos, Juliana Ines Santos, and Sandra Alves. Rna therapeutics: how far have we gone? _The mRNA Metabolism in Human Disease_, pages 133-177, 2019.
* Duval et al. [2023] Alexandre Agm Duval, Victor Schmidt, Alex Hernandez-Garc'a, Santiago Miret, Fragkiskos D Malliaros, Yoshua Bengio, and David Rolnick. Faenet: Frame averaging equivariant gnn for materials modeling. In _International Conference on Machine Learning_, pages 9013-9033. PMLR, 2023.
* Elfwing et al. [2018] Stefan Elfwing, Eiji Uchibe, and Kenji Doya. Sigmoid-weighted linear units for neural network function approximation in reinforcement learning. _Neural networks_, 107:3-11, 2018.
* Ellington and Szostak [1990] Andrew D Ellington and Jack W Szostak. In vitro selection of rna molecules that bind specific ligands. _nature_, 346(6287):818-822, 1990.
* Emami and Ferdousi [2021] Neda Emami and Reza Ferdousi. Aptanet as a deep learning approach for aptamer-protein interaction prediction. _Scientific reports_, 11(1):6074, 2021.
* Evans et al. [2021] Richard Evans, Michael O'Neill, Alexander Pritzel, Natasha Antropova, Andrew Senior, Tim Green, Augustin Zidek, Russ Bates, Sam Blackwell, Jason Yim, et al. Protein complex prediction with alphafold-multimer. _biocriv_, pages 2021-10, 2021.
* Fang et al. [2022] Enyue Fang, Xiaohui Liu, Miao Li, Zelun Zhang, Lifang Song, Baiyu Zhu, Xiaohong Wu, Jingjing Liu, Danhua Zhao, and Yuhua Li. Advances in covid-19 mrna vaccine development. _Signal transduction and targeted therapy_, 7(1):94, 2022.
* Fuchs et al. [2020] Fabian Fuchs, Daniel Worrall, Volker Fischer, and Max Welling. Se (3)-transformers: 3d roto-translation equivariant attention networks. _Advances in neural information processing systems_, 33:1970-1981, 2020.
* Gajda et al. [2010] Michal J Gajda, Irina Tuszynska, Marta Kaczor, Anastasia Yu Bakulina, and Janusz M Bujnicki. Filtrest3d: discrimination of structural models using restraints from experimental data. _Bioinformatics_, 26(23):2986-2987, 2010.
* Ganea et al. [2021] Octavian-Eugen Ganea, Xinyuan Huang, Charlotte Bunne, Yatao Bian, Regina Barzilay, Tommi Jaakkola, and Andreas Krause. Independent se (3)-equivariant models for end-to-end rigid protein docking. _arXiv preprint arXiv:2111.07786_, 2021.
* Gasteiger et al. [2021] Johannes Gasteiger, Florian Becker, and Stephan Gunnemann. Gemnet: Universal directional graph neural networks for molecules. _Advances in Neural Information Processing Systems_, 34:6790-6802, 2021.
* Gasteiger et al. [2020] Johannes Gasteiger, Shankar Giri, Johannes T Margraf, and Stephan Gunnemann. Fast and uncertainty-aware directional message passing for non-equilibrium molecules. _arXiv preprint arXiv:2011.14115_, 2020.
* Gold et al. [2012] Larry Gold, Neboja Janjic, Thale Jarvis, Dan Schneider, Jeffrey J Walker, Sheri K Wilcox, and Dom Zichi. Aptamers and the rna world, past and present. _Cold Spring Harbor perspectives in biology_, 4(3):a003582, 2012.
* Hughes et al. [2011] James P Hughes, Stephen Rees, S Barrett Kalindjian, and Karen L Philpott. Principles of early drug discovery. _British journal of pharmacology_, 162(6):1239-1249, 2011.
* Humphreys et al. [2021] IR Humphreys, J Pei, M Baek, A Krishnakumar, I Anishchenko, S Ovchinnikov, J Zhang, TJ Ness, S Banjade, S Bagde, et al. Structures of core eukaryotic protein complexes. biorxiv 2021: 2021.09. 30.462231.
* Ingraham et al. [2019] John Ingraham, Vikas Garg, Regina Barzilay, and Tommi Jaakkola. Generative models for graph-based protein design. _Advances in neural information processing systems_, 32, 2019.
* Iwano et al. [2022] Natsuki Iwano, Tatsuo Adachi, Kazuteru Aoki, Yoshikazu Nakamura, and Michiaki Hamada. Generative aptamer discovery using raptgen. _Nature Computational Science_, 2(6):378-386, 2022.
* Jiang et al. [2023] Zheng Jiang, Yue-Yue Shen, and Rong Liu. Structure-based prediction of nucleic acid binding residues by merging deep learning-and template-based approaches. _PLOS Computational Biology_, 19(9):e1011428, 2023.
* Jin et al. [2023] Wengong Jin, Siranush Sarkizova, Xun Chen, Nir Hacohen, and Caroline Uhler. Unsupervised protein-ligand binding energy prediction via neural euler's rotation equation. _arXiv preprint arXiv:2301.10814_, 2023.

* [39] Bowen Jing, Stephan Eismann, Patricia Suriana, Raphael JL Townshend, and Ron Dror. Learning from protein structure with geometric vector perceptrons. _arXiv preprint arXiv:2009.01411_, 2020.
* [40] John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin Zidek, Anna Potapenko, et al. Highly accurate protein structure prediction with alphafold. _Nature_, 596(7873):583-589, 2021.
* [41] Anthony D Keefe, Supriya Pai, and Andrew Ellington. Aptamers as therapeutics. _Nature reviews Drug discovery_, 9(7):537-550, 2010.
* [42] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. _arXiv preprint arXiv:1412.6980_, 2014.
* [43] Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. _arXiv preprint arXiv:1609.02907_, 2016.
* [44] AV Lakhin, Vyacheslav Zalmanovich Tarantul, and LV3890987 Gening. Aptamers: problems, solutions and prospects. _Acta Naturae_, 5(4 (19)):34-43, 2013.
* [45] Neocles B Leontis and Eric Westhof. Geometric nomenclature and classification of rna base pairs. _Rna_, 7(4):499-512, 2001.
* [46] Shuya Li, Fanghong Dong, Yuexin Wu, Sai Zhang, Chen Zhang, Xiao Liu, Tao Jiang, and Jianyang Zeng. A deep boosting based approach for capturing the sequence binding preferences of rna-binding proteins from high-throughput clip-seq data. _Nucleic acids research_, 45(14):e129-e129, 2017.
* [47] Yi-Lun Liao and Tess Smidt. Equiformer: Equivariant graph attention transformer for 3d atomistic graphs. _arXiv preprint arXiv:2206.11990_, 2022.
* [48] Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan dos Santos Costa, Maryam Fazel-Zarandi, Tom Sercu, Sal Candido, et al. Language models of protein sequences at the scale of evolution enable accurate structure prediction. _BioRxiv_, 2022:500902, 2022.
* [49] Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Nikita Smetanin, Robert Verkuil, Ori Kabeli, Yaniv Shmueli, et al. Evolutionary-scale prediction of atomic-level protein structure with a language model. _Science_, 379(6637):1123-1130, 2023.
* [50] Meng Liu, Youzhi Luo, Kanji Uchino, Koji Maruhashi, and Shuiwang Ji. Generating 3d molecules for target protein binding. _arXiv preprint arXiv:2204.09410_, 2022.
* [51] Qingxiu Liu, Wei Zhang, Siying Chen, Zhenjing Zhuang, Yi Zhang, Lingli Jiang, and Jun Sheng Lin. Selex tool: a novel and convenient gel-based diffusion method for monitoring of aptamer-target binding. _Journal of biological engineering_, 14:1-13, 2020.
* [52] Shengchao Liu, Weitao Du, Yanjing Li, Zhuoxinran Li, Zhiling Zheng, Chenru Duan, Zhiming Ma, Omar Yaghi, Anima Anandkumar, Christian Borgs, et al. Symmetry-informed geometric representation for molecules, proteins, and crystalline materials. _arXiv preprint arXiv:2306.09375_, 2023.
* [53] Shitong Luo, Jiaqi Guan, Jianzhu Ma, and Jian Peng. A 3d generative model for structure-based drug design. _Advances in Neural Information Processing Systems_, 34:6229-6239, 2021.
* [54] Daniel Maticzka, Sita J Lange, Fabrizio Costa, and Rolf Backofen. Graphprot: modeling binding preferences of rna-binding proteins. _Genome biology_, 15(1):1-18, 2014.
* [55] Amil Merchant, Simon Batzner, Samuel S. Schoenholz, Muratahan Aykol, Gowoon Cheon, and Ekin Dogus Cubuk. Scaling deep learning for materials discovery. _Nature_, 2023.
* [56] Alex Morehead, Chen Chen, Ada Sedova, and Jianlin Cheng. Dips-plus: The enhanced database of interacting protein structures for interface prediction. _Scientific Data_, 10(1):509, 2023.
* [57] Flemming Morsch, Iswarya Lalitha Umasankar, Lys Sanz Moreta, Paridhi Latawa, Danny B Lange, Jesper Wengel, Huram Konjen, and Christian Code. Aptabert: Predicting aptamer binding interactions. _bioRxiv_, pages 2023-11, 2023.
* [58] Wilma K Olson, Manju Bansal, Stephen K Burley, Richard E Dickerson, Mark Gerstein, Stephen C Harvey, Udo Heinemann, Xiang-Jun Lu, Stephen Neidle, Zippora Shakked, et al. A standard reference frame for the description of nucleic acid base-pair geometry. _Journal of molecular biology_, 313(1):229-237, 2001.

* [59] John M Pagano, Hojoong Kwak, Colin T Waters, Rebekka O Sprouse, Brian S White, Abdullah Ozer, Kylan Szeto, David Shalloway, Harold G Craighead, and John T Lis. Defining self-e rna binding in hiv-1 and promoter-proximal pause regions. _PLoS genetics_, 10(1):e1004090, 2014.
* [60] Norbert Pardi, Michael J Hogan, Frederick W Porter, and Drew Weissman. mrna vaccines--a new era in vaccinology. _Nature reviews Drug discovery_, 17(4):261-279, 2018.
* [61] Jung Woo Park, Philip NP Lagniton, Yu Liu, and Ren-He Xu. mrna vaccines for covid-19: what, why and how. _International journal of biological sciences_, 17(6):1446, 2021.
* [62] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. _Advances in neural information processing systems_, 32, 2019.
* [63] Omri Puny, Matan Atzmon, Heli Ben-Hamu, Ishan Misra, Aditya Grover, Edward J Smith, and Yaron Lipman. Frame averaging for invariant and equivariant network design. _arXiv preprint arXiv:2110.03336_, 2021.
* [64] Weikang Qiu, Huangriu Chu, Selena Wang, Haolan Zuo, Xiaoxiao Li, Yize Zhao, and Rex Ying. Learning high-order relationships of brain regions. In _Forty-first International Conference on Machine Learning_, 2023.
* [65] Rahmatullah Roche, Bernard Moussad, Md Hossain Shuvo, Sumit Tarafder, and Debswapna Bhattacharya. Equipnas: improved protein-nucleic acid binding site prediction using protein-language-model-informed equivariant deep graph neural networks. _bioRxiv_, pages 2023-09, 2023.
* [66] Victor Garcia Satorras, Emiel Hoogeboom, and Max Welling. E (n) equivariant graph neural networks. In _International conference on machine learning_, pages 9323-9332. PMLR, 2021.
* [67] Kristof T Schutt, Huziel E Sauceda, P-J Kindermans, Alexandre Tkatchenko, and K-R Muller. Schnet-a deep learning architecture for molecules and materials. _The Journal of Chemical Physics_, 148(24), 2018.
* [68] Incheol Shin, Keumseok Kang, Juseong Kim, Sanghun Sel, Jeonghoon Choi, Jae-Wook Lee, Ho Young Kang, and Giltae Song. Aptatrans: a deep neural network for predicting aptamer-protein interaction using pretrained encoders. _BMC bioinformatics_, 24(1):447, 2023.
* [69] Bo Shui, Abdullah Ozer, Warren Zipfel, Nevedita Sahu, Avtar Singh, John T Lis, Hua Shi, and Michael I Koflikoff. Rna aptamers that functionally interact with green fluorescent protein and its derivatives. _Nucleic acids research_, 40(5):e39-e39, 2012.
* [70] Zhenqiao Song, Tinglin Huang, Lei Li, and Wengong Jin. Surfpro: Functional protein design based on continuous surface. _arXiv preprint arXiv:2405.06693_, 2024.
* [71] Hannes Stark, Octavian Ganea, Lagnajit Pattanaik, Regina Barzilay, and Tommi Jaakkola. Equibind: Geometric deep learning for drug binding structure prediction. In _International conference on machine learning_, pages 20503-20521. PMLR, 2022.
* [72] Regina Stoltenburg, Christine Reinemann, and Beate Strehlitz. Selex--a (r) evolutionary method to generate high-affinity nucleic acid ligands. _Biomolecular engineering_, 24(4):381-403, 2007.
* [73] Kylan Szeto, David R Latulippe, Abdullah Ozer, John M Pagano, Brian S White, David Shalloway, John T Lis, and Harold G Craighead. Rapid-sex for rna aptamers. _PloS one_, 8(12):e82667, 2013.
* [74] Philipp Tholke and Gianni De Fabritiis. Torchmd-net: equivariant transformers for neural network based molecular potentials. _arXiv preprint arXiv:2202.02541_, 2022.
* [75] Nathaniel Thomas, Tess Smidt, Steven Kearnes, Lusann Yang, Li Li, Kai Kohlhoff, and Patrick Riley. Tensor field networks: Rotation-and translation-equivariant neural networks for 3d point clouds. _arXiv preprint arXiv:1802.08219_, 2018.
* [76] Jacob M Tome, Abdullah Ozer, John M Pagano, Dan Gheba, Gary P Schroth, and John T Lis. Comprehensive analysis of rna-protein interactions by high-throughput sequencing-rna affinity profiling. _Nature methods_, 11(6):683-688, 2014.
* [77] Raphael Townshend, Rishi Bedi, Patricia Suriana, and Ron Dror. End-to-end learning on 3d protein structure for interface prediction. _Advances in Neural Information Processing Systems_, 32, 2019.
* [78] Raphael JL Townshend, Martin Vogele, Patricia Suriana, Alexander Derry, Alexander Powers, Yianni Laloudakis, Sidhika Balachandar, Bowen Jing, Brandon Anderson, Stephan Eismann, et al. Atom3d: Tasks on molecules in three dimensions. _arXiv preprint arXiv:2012.04035_, 2020.

* [79] Ameni Trabelsi, Mohamed Chaabane, and Asa Ben-Hur. Comprehensive evaluation of deep learning architectures for prediction of dna/ma sequence binding specificities. _Bioinformatics_, 35(14):i269-i277, 2019.
* [80] Irina Tuszynska, Marcin Magnus, Katarzyna Jonak, Wayne Dawson, and Janusz M Bujnicki. Npdcok: a web server for protein-nucleic acid docking. _Nucleic acids research_, 43(W1):W425-W430, 2015.
* [81] Irina Tuszynska, Dorota Matelska, Marcin Magnus, Grzegorz Chojnowski, Joanna M Kasprzak, Lukasz P Kozlowski, Stanislaw Dunin-Horkawicz, and Janusz M Bujnicki. Computational modeling of protein-ma complex structures. _Methods_, 65(3):310-319, 2014.
* [82] Michael Uhl, Van Dinh Tran, Florian Heyl, and Rolf Backofen. Rnaprot: an efficient and feature-rich rna binding protein binding site predictor. _GigaScience_, 10(8):giab054, 2021.
* [83] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. _Advances in neural information processing systems_, 30, 2017.
* [84] Pauli Virtanen, Ralf Gommers, Travis E Oliphant, Matt Haberland, Tyler Reddy, David Cournapeau, Evgeni Burovski, Pearu Peterson, Warren Weckesser, Jonathan Bright, et al. Scipy 1.0: fundamental algorithms for scientific computing in python. _Nature methods_, 17(3):261-272, 2020.
* [85] Junkang Wei, Siyuan Chen, Licheng Zong, Xin Gao, and Yu Li. Protein-rna interaction prediction with deep learning: structure matters. _Briefings in bioinformatics_, 23(1):bbab540, 2022.
* [86] Ying Xia, Chun-Qiu Xia, Xiaoyong Pan, and Hong-Bin Shen. Graphbind: protein structural context embedded rules learned by hierarchical graph neural networks for recognizing nucleic-acid-binding residues. _Nucleic acids research_, 49(9):e51-e51, 2021.
* [87] Yiran Xu, Jianghui Zhu, Wenze Huang, Kui Xu, Rui Yang, Qiangfeng Cliff Zhang, and Lei Sun. Prismnet: predicting protein-rna interaction using in vivo rna structural information. _Nucleic Acids Research_, page gkad353, 2023.
* [88] Zichao Yan, William L Hamilton, and Mathieu Blanchette. Neural representation and generation for rna secondary structures. _arXiv preprint arXiv:2102.00925_, 2021.
* [89] Qianmu Yuan, Sheng Chen, Jiahua Rao, Shuangjia Zheng, Huiying Zhao, and Yuedong Yang. Alphafold2-aware protein-dna binding site prediction using graph transformer. _Briefings in Bioinformatics_, 23(2):bbab564, 2022.
* [90] Xuan Zhang, Limei Wang, Jacob Helwig, Youzhi Luo, Cong Fu, Yaochen Xie, Meng Liu, Yuchao Lin, Zhao Xu, Keqiang Yan, et al. Artificial intelligence for science in quantum, atomistic, and continuum systems. _arXiv preprint arXiv:2307.08423_, 2023.

Experimental Details

Running environment.The experiments are conducted on a single Linux server with The AMD EPYC 7513-32 Core Processor, 1024G RAM, and 4 Tesla A40-48GB. Our method is implemented on PyTorch 1.13.1 and Python 3.9.6.

Training details.For all the baseline models and FAFormer, we fix the batch size as 8, the number of layers as 3, the dimension of node representation as 64, and the optimizer as Adam [42]. Binary cross-entropy loss is used for contact map identification tasks with a positive weight of 4. The gradient norm is clipped to 1.0 in each training step to ensure learning stability. We report the model's performance on the test set using the best-performing model selected based on its performance on the validation set. All the results are reported based on three different random seeds.

The learning rate is tuned within {1e-3, 5e-4, 1e-4} and is set to 1e-3 by default, as it generally yields the best performance. For each model, we search the hyperparameters in the following ranges: dropout rate in [0, 0.5], the number of nearest neighbors for the GNN-based methods in {10, 20, 30}, and the number of attention heads in {1, 2, 4, 8}. The hyperparameters used in each method are shown below:

* FAFormer: The number of attention heads, dropout rate, and attention dropout rate are 4, 0.2, and 0.2 respectively. We initialize the weight of the gate function with zero weights, and bias with a constant value of 1, ensuring a mostly-opened gate. SiLU [22] is used as the activation function. The distance threshold \(c\) is set as 1e5A and the number of neighbors is 30.
* GVP-GNN5: The dimensions of node/edge scalar features and node/edge vector features are set as 64 and 16 respectively. The dropout rate is fixed at 0.2. For a fair comparison, we only extract the geometric feature based on \(C_{\alpha}\), i.e., the forward and reverse unit vectors oriented in the direction of \(C_{\alpha}\) between neighbor residues. Footnote 5: https://github.com/drorlab/gvp-pytorch
* EGNN6: The number of neighbors is set as 30. Besides, we apply gate attention to each edge update module and residue connection to the node update module. SiLU [22] is used as the activation function. Footnote 6: https://github.com/vgsatorras/egnn
* Equiformer7 and SE(3)Transformer8: The number of attention heads, and the hidden size of each attention head are set as 4 and 16. We exclude the neighbor nodes with a distance greater than 100A and set the number of neighbors as 30. Based on our experiments, we set the degree of spherical harmonics to 1, as higher degrees tend to lead to performance collapse according to our experiments. Footnote 8: https://github.com/atomicarchitects/Equ.ioformer
* Transformer and FA9: The Transformer is applied as FA's backbone encoder. The dropout and attention dropout rates are 0.2 and 0.2. The number of attention heads is set as 4. Footnote 9: https://github.com/FabianFuchsML/se3-transformer-public
* GraphBind10: The dropout ratio and the number of neighbors are 0.5 and 30. We apply addition aggregation to the node and edge update module, following the suggested setting presented in the paper. Footnote 10: http://github.com/omri1348/Frame-Averaging Footnote 10: http://www.csbio.sjtu.edu.cn/bioinf/GraphBind/sourcecode.html
* GraphSite11: The number of neighbors and dropout ratio are 30 and 0.2. The number of attention layers and attention heads are 2 and 4 respectively. Besides, we additionally use the DSSP features as the node features, as suggested in the paper. Footnote 11: https://github.com/biomed-AI/GraphSite
* RoseTTAFoldNA12: We employ the released pretrained weight of RoseTTAFoldNA, and set up all the required databases, including UniRef, BFD, structure templates, Rfam, and RNAcentral following the instructions. Footnote 12: https://github.com/uw-ipd/RoseTTAFold2NAEfficiency Analysis

### Computational Complexity

As a core component in the model, frame averaging's time complexity mainly comes from the calculation of PCA among the input coordinates. This operation is practically efficient due to the low dimensionality of the input (only 3 for coordinates). Besides, the calculation of eigenvalue decomposition can be significantly accelerated by some libraries, such as PyTorch [62] and SciPy [84]. We ignore the complexity used for calculating projected coordinates in the following analysis.

As for the local frame edge module in FAFormer, linear transformations are employed to compute the pairwise representation (Equ. (7) and Equ. (8)), and an additional gate is applied to regulate these messages (Equ. (8)), resulting in a computational complexity of \(O(NKD+NKD^{2})\). Considering the residue connection, the overall complexity of the local frame edge module is \(O(NKD+NKD^{2}+ND)\).

As for the self-attention module, linear transformations are performed on token embeddings and edge representations (Equ. (9)), and the multi-head MLP attention computation is limited to nearest neighbors (Equ. (10)), leading to the complexity of \(O(NHD^{2}+NKHD)\) where \(H\) is the number of attention heads. Further operations, including aggregation, linear projection, and residual connections (Equ. (11) and Equ. (12)), add \(O(NKHD+NKHD^{2}+ND)\). Moreover, applying a gate function to the combination of aggregated coordinates and original coordinates (Equ. (13) and Equ. (14)) adds \(O(NKH+ND+ND^{2})\). As a result, the total complexity for the self-attention module is \(O(NKHD+NKHD^{2}+NKH+ND+ND^{2})\).

Regarding the FFN, most operations are linear transformations that have the complexity of \(O(ND^{2})\). The gate function and linear combination of coordinates contribute \(O(ND^{2}+ND)\). So the total computational complexity of FFN is \(O(ND^{2}+ND)\).

### Wall-Clock Time Performance Comparison

We conduct a comparison of wall-clock time performance between FAFormer and other geometric baseline models under the same computational environment. Specifically, we measure the average training time for one epoch of each model, with the results illustrated in Figure 5. It can be observed that FAFormer demonstrates greater efficiency compared to spherical harmonics-based models and achieves performance comparable to the GNN-based method GVP-GNN. Such efficiency is attributed to the utilization of top-\(K\) neighbor graphs and FA-based modules in FAFormer, which enable efficient modeling of coordinates through linear transformations.

## Appendix C Equivariance Proof

In this section, we investigate the equivariance of the gate function (Figure 2(e)), which can be formulated as:

\[\text{Gate}(\bm{X}_{i},f_{\Delta}(\bm{X}_{i}),\bm{Z}_{i}) :=\bm{g}_{i}\Delta\bm{X}_{i}+(1-\bm{g}_{i})\bm{X}_{i}\] (18) \[:=\bm{X}_{i}^{\prime}\] (19)

where \(\bm{X}_{i}\) represents the coordinates of \(i\)-th node, \(\bm{g}_{i}=\sigma(\text{Linear}(\bm{Z}_{i}))\) is the gate score based on \(i\)-th node's feature, and \(\Delta\bm{X}_{i}=f_{\Delta}(\bm{X}_{i})\) denotes the coordinate update function, i.e., the multi-head

Figure 5: Training time comparison between FAFormer and the other baseline models.

aggregation function Equ.(13) which is based on the frame averaging and thus is \(E(3)\) equivariant:

\[\bm{Q}\Delta\bm{X}_{i}+\bm{t}=f_{\Delta}(\bm{Q}\bm{X}_{i}+\bm{t})\] (20)

where \(\bm{t}\in\mathbb{R}^{3}\) is a translation vector and \(\bm{Q}\in\mathbb{R}^{3\times 3}\) is an orthogonal matrix.

We aim to prove that the gate function is \(E(3)\) equivariant, meaning it is translation equivariant for any translation vector \(\bm{t}\in\mathbb{R}^{3}\) and rotation/reflection equivariant for any orthogonal matrix \(\bm{Q}\in\mathbb{R}^{3\times 3}\). Specifically, we want to show:

\[\bm{Q}\bm{X}_{i}^{\prime}+\bm{t}=\text{Gate}(\bm{Q}\bm{X}_{i}+\bm{t},f_{\Delta }(\bm{Q}\bm{X}_{i}+\bm{t}),\bm{Z}_{i})\] (21)

_Derivation._

\[\text{Gate}(\bm{Q}\bm{X}_{i}+\bm{t},f_{\Delta}(\bm{Q}\bm{X}_{i}+ \bm{t}),\bm{Z}_{i}) =\bm{g}_{i}(\bm{Q}\Delta\bm{X}_{i}+\bm{t})+(1-\bm{g}_{i})(\bm{Q} \bm{X}_{i}+\bm{t})\] (22) \[=\bm{g}_{i}\bm{Q}\Delta\bm{X}_{i}+(1-\bm{g}_{i})\bm{Q}\bm{X}_{i}+ \bm{g}_{i}\bm{t}+(1-\bm{g}_{i})\bm{t}\] (23) \[=\bm{Q}\left(\bm{g}_{i}\Delta\bm{X}_{i}+(1-\bm{g}_{i})\bm{X}_{i} \right)+\bm{t}\] (24) \[=\bm{Q}\bm{X}_{i}^{\prime}+\bm{t}\] (25)

Therefore, we have proven that applying rotation and translation to \(\bm{X}_{i}\) results in the identical rotation and translation being applied to \(\bm{X}_{i}^{\prime}\).

## Appendix D Dataset Descriptions

Protein Complex DatasetsWe collect the complexes from PDB [8], NDB [7], RNASolo [2] and DIPS [77] databases. Complexes are excluded if they have protein sequences shorter than 5 or longer than 800 residues, or nucleic acid sequences shorter than 5 or longer than 500 nucleotides. The redundant proteins with over 90% sequence similarity to other sequences within the datasets are removed. The protein and the binder structures will be separated and decentered.

#### 0.d.0.1 **Pdamer Datasets**

Detailed information on each protein target and the aptamer candidates is presented below. The threshold for categorizing sequences as positive or negative aptamers is determined by referencing previous studies or identifying natural cutoffs in the affinity score distributions.

* GFP13: Green fluorescent protein. The aptamer candidates are mutants of GFPapt [69], with \(K_{d}\) values ranging from 0nM to 125nM as affinity measures. Candidates with \(K_{d}\) values lower than 10nM are considered positive cases. Footnote 13: https://www.uniprot.org/uniprotkb/P42212/entry
* NELF14: Negative elongation factor E. The aptamer candidates are mutants of NELFapt [59], with \(K_{d}\) values ranging from 0nM to 183nM as affinity measures. Candidates with \(K_{d}\) values lower than 5nM are considered positive cases. Footnote 14: https://www.uniprot.org/uniprotkb/P92204/entry
* HNRNPC15: Heterogeneous nuclear ribonucleoproteins C1/C2. The aptamer candidates are the randomly generated RNA 7mers and we apply the affinity values provided by the previous studies [46]. Candidates with affinity scores lower than -0.5 are positive. Footnote 15: https://www.uniprot.org/uniprotkb/O96017/entry
* CHK216: Serine/threonine-protein kinase Chk2. Szeto et al [73] applied SELEX (Systematic Evolution of Ligands by EXponential Enrichment) [23] to screen aptamers from a large library of random nucleic acid sequences through multiple rounds. During each round, the bound sequences were amplified and isolated. We use the final round of sequences as the candidates, with sequences having multiplicities over 100 considered positive aptamers. Footnote 16: https://www.uniprot.org/uniprotkb/O96017/entry
* UBLCP17: Ubiquitin-like domain-containing CTD phosphatase 1. Similar to CHK2, the final round of sequences are considered candidates, with sequences having multiplicities over 200 considered positive aptamers.

[MISSING_PAGE_FAIL:19]

[MISSING_PAGE_FAIL:20]

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: As presented in the abstract and introduction, we focus on learning the interactions of protein complexes and extending it to the zero-shot aptamer screening application. Besides, we propose FAFormer, which is an equivariant Transformer architecture based on frame averaging, achieves the best performance on all the tasks. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: We've included a section in the paper specifically focusing on modeling the interactions of protein complexes and zero-shot aptamer screening without evaluating FAFormer on other tasks. We will continue to work on this and aim to benchmark the method more comprehensively. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.

3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: We provide proof verifying the equivariance of the gate function, including a detailed derivation demonstrating how the gate function maintains equivariance with orthogonal matrices and translation vectors. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: We've included a code link in the paper for review, which contains the pipelines for all tasks and datasets. Additionally, we present the data sources and processing methods for all datasets. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset).

4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: A code link is included in the paper, containing the training pipelines for all tasks. Additionally, we have detailed the dataset preprocessing methods and provided the corresponding scripts in the code link. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: As shown in Appendix A and Appendix D, we have introduced the dataset splitting strategies based on protein sequence identity, the search range of each hyperparameter, and the optimal hyperparameters for each model. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes]Justification: We report the variance for all results by repeating the experiments with three different random seeds. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors). * It should be clear whether the error bar is the standard deviation or the standard error of the mean. * It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified. * For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). * If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: As mentioned in the Appendix A, the experiments are conducted on a single Linux server with The AMD EPYC 7513-32 Core Processor, 1024G RAM, and 4 Tesla A40-48GB. Our method is implemented on PyTorch 1.13.1 and Python 3.9.6. The computational complexity and running time comparison are shown in Appendix B. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: We've followed the instructions in the NeurIPS Code of Ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).

10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: This paper presents work whose goal is to advance the field of geometric deep learning on protein complex modeling. There are some potential societal consequences of our work, none of which we feel must be specifically highlighted here. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. * If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: The datasets and models used in this study don't have such risks. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes]Justification: All the involved models and datasets, including pretrained protein/RNA sequence models, pretrained structure prediction models (RoseTTAFoldNA and AlphaFold3), complex datasets, and aptamer datasets, are properly credited and cited. Guidelines:

* The answer NA means that the paper does not use existing assets.
* The authors should cite the original paper that produced the code package or dataset.
* The authors should state which version of the asset is used and, if possible, include a URL.
* The name of the license (e.g., CC-BY 4.0) should be included for each asset.
* For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.
* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.

13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets?

Answer: [NA]

Justification: The paper does not introduce new assets; it only uses existing models and datasets that are properly credited and cited. Guidelines:

* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.

14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)?

Answer: [NA]

Justification: The paper does not involve crowdsourcing experiments or research with human subjects.

Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.

15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects**Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained?

Answer: [NA]

Justification: The paper does not involve crowdsourcing experiments or research with human subjects.

Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.