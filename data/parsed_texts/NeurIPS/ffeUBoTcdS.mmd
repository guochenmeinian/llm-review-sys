# Persistent Test-time Adaptation in

Recurring Testing Scenarios

 Trung-Hieu Hoang\({}^{1}\)  Duc Minh Vo\({}^{2}\)  Minh N. Do\({}^{1,3}\)

\({}^{1}\)Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign

\({}^{2}\)The University of Tokyo

\({}^{3}\)VinUni-Illinois Smart Health Center, VinUniversity

{ththieu, minhdo}@illinois.edu  vmduc@nlab.ci.i.u-tokyo.ac.jp

###### Abstract

Current test-time adaptation (TTA) approaches aim to adapt a machine learning model to environments that change continuously. Yet, it is unclear whether TTA methods can maintain their adaptability over prolonged periods. To answer this question, we introduce a diagnostic setting - **recurring TTA** where environments not only change but also recur over time, creating an extensive data stream. This setting allows us to examine the error accumulation of TTA models, in the most basic scenario, when they are regularly exposed to previous testing environments. Furthermore, we simulate a TTA process on a simple yet representative \(\epsilon\)**-perturbed Gaussian Mixture Model Classifier**, deriving theoretical insights into the dataset- and algorithm-dependent factors contributing to gradual performance degradation. Our investigation leads us to propose **persistent TTA** (**PeTTA**), which senses when the model is diverging towards collapse and adjusts the adaptation strategy, striking a balance between the dual objectives of adaptation and model collapse prevention. The supreme stability of PeTTA over existing approaches, in the face of lifelong TTA scenarios, has been demonstrated over comprehensive experiments on various benchmarks. Our project page is available at https://ththieu166.github.io/petta.

## 1 Introduction

Machine learning (ML) models have demonstrated significant achievements in various areas [18; 38; 47; 23]. Still, they are inherently susceptible to distribution-shift [46; 13; 48; 21; 6] (also known as the divergence between the training and testing environments), leading to a significant degradation in model performance. The ability to deviate from the conventional testing setting appears as a crucial aspect in boosting ML models' adaptability when confronted with a new testing environment that has been investigated [30; 53; 14]. Among common domain generalization methods [58; 24; 1], _test-time adaptation (TTA)_ takes the most challenging yet rewarding path that leverages unlabeled data available at test time for self-supervised adaptation prior to the final inference [57; 39; 8; 41; 59].

Early TTA studies have concentrated on a simply ideal adaptation scenario where the test samples come from a fixed single domain [57; 39; 41]. As a result, such an assumption is far from the ever-changing and complex testing environments. To confront continually changing environments [59; 12], Yuan _et al._[61] proposed a _practical TTA_ scenario where distribution changing and correlative sampling occur [15] simultaneously. Though practical TTA is more realistic than what the previous assumptions have made, it still assumes that any environment only appears once in the data stream, a condition which does not hold true. Taking a surveillance camera as an example, it might accommodate varying lighting conditions recurringly day after day (Fig. 1-left). Based on this reality, we hypothesize that the recurring of those conditions may reveal the error accumulation phenomenon in TTA, resulting in performance degradation over a long period. To verify our hypothesis, we simulate arecurring testing environment and observe the increasing error rate by recurringly adapting to the test set of CIFAR-10-C [19] multiple times. We showcase the testing error of RoTTA [61] after 20 cycles of adaptation in Fig. 1-right. As expected, RoTTA can successfully adapt and deliver encouraging outcomes within the first few passes. However, this advantage is short-lived as our study uncovers a significant issue: _TTA approaches in this setting may experience severe and persistent degradation in performance_. Consequently, the testing error of RoTTA gradually escalates over time and quickly surpasses the model without adaptation. This result confirms the risk of TTA deployment in our illustrative scenario, as an algorithm might work well in the first place and gradually degenerate. Therefore, ensuring sustainable quality is crucial for real-world applications, especially given the recurring nature of testing environments.

This study examines whether the adaptability of a TTA algorithm persists over an extended testing stream. Specifically, in the most basic scenario, where the model returns to a previously encountered testing environment after undergoing various adjustments. We thus propose a more general testing scenario than the practical TTA [61], namely _recurring TTA_, where the environments not only change gradually but also recur in a correlated manner over time. We first analyze a simulation using the \(\epsilon-\)_perturbed Gaussian Mixture Model Classifier_ (\(\epsilon-\)_GMMC_) on a synthesized dataset and derive a theoretical analysis to confirm our findings, offering insights to tackle similar issues in deep neural networks. The analysis provides hints for reasoning the success of many recent robust continual TTA approaches [61; 12; 59; 15] and leading us to propose a simple yet effective baseline to avoid performance degradation, namely _Persistent TTA_ (_PeTTA_). PeTTA continuously monitors the chance of collapsing and adjusts the adaptation strategy on the fly, striking a balance between the two objectives: _adaptation_ and _collapse prevention_. Our contributions can be summarized as follows:

* recurring TTA_, a simple yet sufficient setup for diagnosing the overlooked _gradual performance degradation_ phenomenon of TTA.
* Second, we formally _define the phenomenon of TTA collapsing and undertake a theoretical analysis_ on an \(\epsilon\)-GMMC, shedding light on dataset-dependent and algorithm-dependent factors that contribute to the error accumulation during TTA processes.
* a simple yet effective adaptation scheme that surpasses all baseline models and demonstrates a persisting performance.

For more context on related work, readers are directed to visit our discussions in Appdx. A.

## 2 Background

**Test-time Adaptation (TTA).** A TTA algorithm operates on an ML classifier \(f_{t}:\mathcal{X}\rightarrow\mathcal{Y}\) with parameter \(\theta_{t}\in\Theta\) (parameter space) gradually changing over time (\(t\in\mathcal{T}\)) that maps an input image \(\bm{x}\in\mathcal{X}\) to a category (label) \(y\in\mathcal{Y}\). Let the capital letters \((X_{t},Y_{t})\in\mathcal{X}\times\mathcal{Y}\) denote a pair of _random variables_ with the joint distribution \(P_{t}(\bm{x},y)\in\mathcal{P}_{d},t\in\mathcal{T}\). Here, \(\mathcal{P}_{d}\) belongs to collection of \(D\) sets of testing scenarios (domains) \(\{\mathcal{P}_{d}\}_{d=1}^{D}\). The covariate shift [46] is assumed: \(P_{t}(\bm{x})\) and \(P_{t^{\prime}}(\bm{x})\)

Figure 1: _Recurring Test-time Adaption (TTA)._ (left) Testing environments may change recurringly and preserving adaptability when visiting _the same_ testing condition is not guaranteed. (right) The testing error of RoTTA [61] progressively raises (performance degradation) and exceeds the error of the source model (no TTA) while our PeTTA demonstrates its stability when adapting to the test set of CIFAR-10-C [19] 20 times. The **bold** lines denote the running mean and the shaded lines in the background represent the testing error on each domain (excluding the source model, for clarity).

could be different but \(P_{t}(y|\bm{x})=P_{t^{\prime}}(y|\bm{x})\) holds \(\forall t\neq t^{\prime}\). At \(t=0\), \(\theta_{0}\) is initialized by a supervised model trained on \(P_{0}\in\mathcal{P}_{0}\) (source dataset). The model then explores an online stream of testing data. For each \(t>0\), it receives \(X_{t}\) (typically in form of a batch of \(N_{t}\) testing samples) for adapting itself \(f_{t-1}\to f_{t}\) before making the final prediction \(f_{t}\left(X_{t}\right)\).

**TTA with Mean Teacher Update.** To achieve a stable optimization process, the main (_teacher_) model \(f_{t}\) are updated indirectly through a _student_ model with parameters \(\theta_{t}^{\prime}\)[57; 61; 12; 15; 55]. At first, the teacher model in the previous step introduces a _pseudo label_[28]\(Y_{t}\) for each \(X_{t}\):

\[\hat{Y}_{t}=f_{t-1}(X_{t}).\] (1)

With a classification loss \(\mathcal{L}_{\mathrm{CLS}}\) (e.g., cross-entropy [16]), and a model parameters regularizer \(\mathcal{R}\), the student model is first updated with a generic optimization operator Optim, followed by an exponential moving average (EMA) update of the teacher model parameter \(\theta_{t-1}\):

\[\theta_{t}^{\prime} =\mathop{\texttt{Optim}}_{\theta^{\prime}\in\Theta}\mathbb{E}_{P_ {t}}\left[\mathcal{L}_{\mathrm{CLS}}\left(\hat{Y}_{t},X_{t};\theta^{\prime} \right)\right]+\lambda\mathcal{R}(\theta^{\prime}),\] (2) \[\theta_{t} =(1-\alpha)\theta_{t-1}+\alpha\theta_{t}^{\prime},\] (3)

with \(\alpha\in(0,1)\) - the update rate of EMA, and \(\lambda\in\mathbb{R}^{+}\) - the weighting coefficient of the regularization term, are the two hyper-parameters.

**Practical TTA.** In practical TTA [61], two characteristics of the aforementioned distribution of data stream are noticeable. Firstly, \(P_{t}\)'s can be partitioned by \(t_{d}\)'s in which \(\{P_{t}\}_{t=t_{d-1}}^{t_{d}}\subset\mathcal{P}_{d}\). Here, each partition of consecutive steps follows the same underlying distribution which will _change continually through \(D\) domains_[59] (\(\mathcal{P}_{1}\rightarrow\mathcal{P}_{2}\cdots\rightarrow\mathcal{P}_{D}\)). Secondly, the category distribution in each testing batch is _temporally correlated_[15]. This means within a batch, a small subset of categories is dominant over others, making the marginal distribution \(P_{t}(y)=0,\forall y\not\in\mathcal{Y}_{t}\subset\mathcal{Y}\) even though the category distribution over all batches are balanced. Optimizing under this low intra-batch diversity (\(|\mathcal{Y}_{t}|\ll|\mathcal{Y}|\)) situation can slowly degenerate the model [7].

## 3 Recurring TTA and Theoretical Analysis

This section conducts a theoretical analysis on a concrete failure case of a simple TTA model. The results presented at the end of Sec. 3.2 will elucidate the factors contributing to the collapse (Sec. 3.1), explaining existing good practices (Sec. 3.3) and give insights into potential solutions (Sec. 4).

### Recurring TTA and Model Collapse

**Recurring TTA.** To study the gradual performance degradation (or model collapse), we propose a _new testing scenario based on practical TTA_[61]. Conducting a single pass through \(D\) distributions, as done in earlier studies [61; 59], may not effectively identify the degradation. To promote consistency, our recurring TTA performs _revisiting the previous distributions \(K\) times_ to compare the incremental error versus the previous visits. For example, a sequence with \(K=2\) could be \(\mathcal{P}_{1}\rightarrow\mathcal{P}_{2}\rightarrow\cdots\rightarrow\mathcal{ P}_{D}\rightarrow\mathcal{P}_{1}\rightarrow\mathcal{P}_{2}\rightarrow\cdots \rightarrow\mathcal{P}_{D}\). Appdx. D extends our justifications on constructing recurring TTA.

**Definition 1** (**Model Collapse)**.: _A model is said to be collapsed from step \(\tau\in\mathcal{T},\tau<\infty\) if there exists a non-empty subset of categories \(\tilde{\mathcal{Y}}\subset\mathcal{Y}\) such that \(\Pr\{Y_{t}\in\tilde{\mathcal{Y}}\}>0\) but the marginal \(\Pr\{\hat{Y}_{t}\in\tilde{\mathcal{Y}}\}\) converges to zero in probability:_

\[\lim_{t\rightarrow\tau}\Pr\{\hat{Y}_{t}\in\tilde{\mathcal{Y}}\}=0.\]

Here, upon collapsing, a model tends to _ignore_ almost categories in \(\tilde{\mathcal{Y}}\). As it is irrecoverable once collapsed, the only remedy would be resetting all parameters back to \(\theta_{0}\).

### Simulation of Failure and Theoretical Analysis

Collapsing behavior varies across datasets and the adaptation processes. Formally studying this phenomenon on a particular real dataset and a TTA algorithm is challenging. Therefore, we propose a theoretical analysis on \(\epsilon\)-perturbed binary Gaussian Mixture Model Classifier (\(\epsilon\)-GMMC) that shares the typical characteristics _by construction_ and demonstrates the _same collapsing pattern_ in action (Sec. 5.1) as observed on real continual TTA processes (Sec. 5.3).

**Simulated Testing Stream.** Observing a testing stream with \((X_{t},Y_{t})\in\mathcal{X}\times\mathcal{Y}=\mathbb{R}\times\{0,1\}\) and the underlying joint distribution \(P_{t}(x,y)=p_{y,t}\cdot\mathcal{N}(x;\mu_{y},\sigma_{y}^{2})\). The main task is predicting \(X_{t}\) was sampled from cluster 0 or 1 (negative or positive). Conveniently, let \(p_{y,t}\stackrel{{\Delta}}{{=}}P_{t}(y)=\Pr(Y_{t}=y)\) and \(\hat{p}_{y,t}\stackrel{{\Delta}}{{=}}\Pr(\hat{Y}_{t}=y)\) be the marginal distribution of the true label \(Y_{t}\) and pseudo label \(\hat{Y}_{t}\).

**GMMC and TTA.** GMMC first implies an _equal prior_ distribution by construction which is desirable for the actual TTA algorithms (e.g., category-balanced sampling strategies in [61, 15]). Thus, it simplifies \(f_{t}\) into a maximum likelihood estimation \(f_{t}(x)=\operatorname*{argmax}_{y\in\mathcal{Y}}\Pr(x|y;\theta_{t})\) with \(\Pr(x|y;\theta_{t})=\mathcal{N}(x;\hat{\mu}_{y,t},\hat{\sigma}_{y,t}^{2})\). The goal is estimating a set of parameters \(\theta_{t}=\{\hat{\mu}_{y,t},\hat{\sigma}_{y,t}^{2}\}_{y\in\mathcal{Y}}\). A perfect classifier \(\theta_{0}=\{\mu_{y},\sigma_{y}^{2}\}_{y\in\mathcal{Y}}\) is initialized at \(t=0\). For the consecutive steps, the simplicity of GMMC allows solving the Optim (for finding \(\theta_{t}^{\prime}\), Eq. 2) perfectly by computing the empirical mean and variance of new samples, approximating \(\mathbb{E}_{P_{t}}\). The mean teacher update (Eq. 3) for GMMC is:

\[\hat{\mu}_{y,t}=\begin{cases}(1-\alpha)\hat{\mu}_{y,t-1}+\alpha\mathbb{E}_{P_{ t}}\left[X_{t}|\hat{Y}_{t}\right]&\text{if }\hat{Y}_{t}=y\\ \hat{\mu}_{y,t-1}&\text{otherwise}\end{cases}.\] (4)

The update of \(\hat{\sigma}_{y,t}^{2}\) is similar. \(\hat{Y}_{t}=f_{t-1}(X_{t})\) can be interpreted as a _pseudo label_ (Eq. 1).

\(\epsilon\)**-Gmmc.** Severe distribution shifts or low intra-batch category diversity of recurring TTA/practical TTA _both result in an increase in the error rate of the predictor_. Instead of directly modeling the dynamic changes of \(p_{y,t}\) (which can be complicated depending on the dataset), we study an \(\epsilon-\)pertubed GMMC (\(\epsilon-\)GMMC), where \(p_{y,t}\) is _assumed to be static_ (defined below) and the pseudo-label predictor of this model is _perturbed_ to _simulate undesirable effects of the testing stream_ on the predictor. Two kinds of errors appear in a binary classifier [4]. Let

\[\epsilon_{t}=\Pr\{Y_{t}=1|\hat{Y}_{t}=0\}\] (5)

be the false negative rate (FNR) of the model at step \(t\). Without loss of generality, we study the _increasing type II collapse of \(\epsilon\)-Gmmc_. By intentionally flipping the true positive pseudo labels in simulation, an FNR of \(\epsilon_{t}\) is maintained (Fig. 2).

**Assumption 1** (**Static Data Stream**).: _The marginal distribution of the true label follows the same Bernoulli distribution \(\mathrm{Ber}(p_{0})\): \(p_{0,t}=p_{0}\), (\(p_{1,t}=p_{1}=1-p_{0}),\forall t\in\mathcal{T}\)._

**Lemma 1** (**Increasing FNR**).: _Under Assumption 1, a binary \(\epsilon\)-Gmmc would collapsed (Def. 1) with \(\lim_{t\to\tau}\hat{p}_{1,t}=0\) (or \(\lim_{t\to\tau}\hat{p}_{0,t}=1\), equivalently) if and only if \(\lim_{t\to\tau}\epsilon_{t}=p_{1}\)._

Lemma 1 states the negative correlation between \(\hat{p}_{1,t}\) and \(\epsilon_{t}\). Unsurprisingly, towards the collapsing point where all predictions are zeros, the FNR also increases at every step and eventually reaches the highest possible FNR of \(p_{1}\).

**Lemma 2** (\(\epsilon\)**-Gmmc After Collapsing**).: _For a binary \(\epsilon\)-Gmmc model, with Assumption 1, if \(\lim_{t\to\tau}\hat{p}_{1,t}=0\) (collapsing), the cluster 0 in GMMC converges in distribution to a single-cluster GMMC with parameters:_

\[\mathcal{N}(\hat{\mu}_{0,t},\hat{\sigma}_{0,t}^{2})\stackrel{{ d}}{{\to}}\mathcal{N}(p_{0}\mu_{0}+p_{1}\mu_{1},p_{0}\sigma_{0}^{2}+p_{1} \sigma_{1}^{2}+p_{0}p_{1}(\mu_{0}-\mu_{1})^{2}).\]

Lemma 2 states the resulting \(\epsilon-\)Gmmc after collapsing. Cluster 0 now _covers the whole data distribution_ (and assigning label 0 for all samples). Furthermore, _collapsing happens when \(\hat{\mu}_{0,t}\) moves toward \(\mu_{1}\)_. We next investigate the factors and conditions for this undesirable convergence.

Figure 2: \(\epsilon\)-perturbed binary Gaussian Mixture Model Classifier, imitating a continual TTA algorithm for theoretical analysis. Two main components include a pseudo-label predictor (Eq. 1), and a mean teacher update (Eqs. 2, 3). The _predictor is perturbed_ for retaining a false negative rate of \(\epsilon_{t}\) to simulate an undesirable TTA testing stream.

**Theorem 1** (**Convergence of \(\epsilon-\)Gmmc**).: _For a binary \(\epsilon\)-GMMC model, with Assumption 1, let the distance from \(\hat{\mu}_{0,t}\) toward \(\mu_{1}\) is \(d_{t}^{0\to 1}=|\mathbb{E}_{P_{t}}\left[\hat{\mu}_{0,t}\right]-\mu_{1}|\), then:_

\[d_{t}^{0\to 1}-d_{t-1}^{0\to 1}\leq\alpha\cdot p_{0}\cdot\left(|\mu_{0}-\mu_{1}|- \frac{d_{t-1}^{0\to 1}}{1-\epsilon_{t}}\right).\]

From Thm. 1, we observe that the distance \(d_{t}^{0\to 1}\)'s converges (also indicating the convergence to the distribution in Lemma 2) if \(d_{t}^{0\to 1}<d_{t-1}^{0\to 1}\). The model collapse happens when this condition holds for a sufficiently long period.

**Corollary 1** (**A Condition for \(\epsilon-\)Gmmc Collapse**).: _With fixed \(p_{0}\), \(\alpha,\mu_{0},\mu_{1}\), \(\epsilon-\)GMMC is collapsed if there exists a sequence of \(\{\epsilon_{t}\}_{\tau-\Delta_{\tau}}^{\tau}\) (\(\tau\geq\Delta_{\tau}>0\)) such that:_

\[p_{1}\geq\epsilon_{t}>1-\frac{d_{t-1}^{0\to 1}}{|\mu_{0}-\mu_{1}|},\quad t\in[ \tau-\Delta_{\tau},\tau].\]

Corollary 1 introduces a condition \(\epsilon\)-GMMC collapse. Here, \(\epsilon_{t}\)'s are non-decreasing, \(\lim\limits_{t\to\tau}\epsilon_{t}=p_{1}\).

**Remarks.** Thm. 1 concludes two sets of factors contributing to collapse: (i) _data-dependent factors_: the prior data distribution (\(p_{0}\)), the nature difference between two categories (\(|\mu_{0}-\mu_{1}|\)); and (ii) _algorithm-dependent factors_: the update rate (\(\alpha\)), the FNR at each step (\(\epsilon_{t}\)). \(\epsilon\)-GMMC analysis sheds light on explaining model collapse on real datasets (Sec. 5.3), reasons the existing approaches (Sec. 3.3) and motivates the development of our baseline (Sec. 4).

### Connection to Existing Solutions

Prior TTA algorithms have already incorporated implicit mechanisms to mitigate model collapse. The theoretical results in the previous section explain the rationale behind these effective strategies.

**Regularization Term for \(\theta_{t}\).** Knowing that \(f_{0}\) is always well-behaved, an attempt is restricting the divergence of \(\theta_{t}\) from \(\theta_{0}\), e.g. using \(\mathcal{R}(\theta_{t})\stackrel{{\Delta}}{{=}}\|\theta_{0}- \theta_{t}\|_{2}^{2}\) regularization [40]. The key idea is introducing a penalty term to avoid an extreme divergence as happening in Thm. 1.

**Memory Bank for Harmonizing \(P_{t}(x)\).** Upon receiving \(X_{t}\), samples in this batch are selectively updated to a memory bank \(\mathcal{M}\) (which already contains a subset of some instances of \(X_{t^{\prime}},t^{\prime}<t\) in the previous steps). By keeping a balanced number of samples from each category, distribution \(P_{t}^{\mathcal{M}}(y)\) of samples in \(\mathcal{M}\) is expected to have less zero entries than \(P_{t}(y)\), making the optimization step over \(P_{t}^{\mathcal{M}}\) more desirable. From Thm. 1, \(\mathcal{M}\) moderates the extreme value of the category distribution (\(p_{0}\) term) which typically appears on batches with low intra-batch category diversity.

## 4 Persistent Test-time Adaptation (PeTTA)

Now we introduce our _Persistent TTA (PeTTA)_ approach. Further inspecting Thm. 1, while \(\epsilon_{t}\) (Eq. 5) is not computable without knowing the true labels, the measure of divergence from the initial distribution (analogously to \(d_{t-1}^{0\to 1}\) term) can provide hints to fine-tune the adaptation process.

**Key Idea.** A proper adjustment toward the TTA algorithm can _break the chain of monotonically increasing \(\epsilon_{t}\)'s in Corollary 1 to prevent the model collapse. In the mean teacher update, the larger value of \(\lambda\) (Eq. 2) prioritizes the task of preventing collapse on one hand but also limits its adaptability to the new testing environment. Meanwhile, \(\alpha\) (Eq. 3) controls the weight on preserving versus changing the model from the previous step. Drawing inspiration from the exploration-exploitation tradeoff [49; 25] encountered in reinforcement learning [54], we introduce a mechanism for _adjusting \(\lambda\) and \(\alpha\) on the fly, balancing between the two primary objectives: adaptation and preventing model collapse_. Our strategy is prioritizing collapse prevention (increasing \(\lambda\)) and preserving the model from previous steps (decreasing \(\alpha\)) when there is a significant deviation from \(\theta_{0}\).

In [40; 61; 59], \(\lambda\) and \(\alpha\) were fixed through hyper-parameter tuning. This is suboptimal due to varying TTA environments and the lack of validation set [62]. Furthermore, Thm. 1 suggests the convergence rate quickly escalates when \(\epsilon_{t}\) increases, making constant \(\lambda,\alpha\) insufficient to prevent collapse.

**Sensing the Divergence of \(\theta_{t}\).** We first equip PeTTA with a mechanism for _measuring its divergence from \(\theta_{0}\)_. Since \(f_{t}(\bm{x})=\text{argmax}\,_{y\in\mathcal{Y}}\Pr(y|\bm{x};\theta_{t})\), we can decompose \(\Pr(y|\bm{x};\theta_{t})=[h\left(\phi_{\theta_{t}}(\bm{x})\right)]_{y}\), with \(\phi_{\theta_{t}}(\cdot)\) is a \(\theta_{t}\)-parameterized deep feature extractor followed by a _fixed_ classification head (a linear and softmax layer) \(h(\cdot)\). The operator \([\cdot]_{y}\) extracts the \(y^{\text{th}}\) component of a vector.

Since \(h(\cdot)\) remains unchanged, instead of comparing the divergence in the parameter space (\(\Theta\)) or between the output probability \(\Pr(y|\bm{x};\theta_{t})\) and \(\Pr(y|\bm{x};\theta_{0})\), we suggest an _inspection over the feature embedding space_ that preserves a _maximum amount of information_ in our case (data processing inequality [9]). Inspired by [31] and under Gaussian assumption, the Mahalanobis distance of the first moment of the feature embedding vectors is compared. Let \(\bm{z}=\phi_{\theta_{t}}(\bm{x})\), we keep track of a collection of the running mean of feature vector \(\bm{z}\): \(\{\bm{\hat{\mu}}_{t}^{y}\}_{y\in\mathcal{Y}}\) in which \(\bm{\hat{\mu}}_{t}^{y}\) is EMA updated with vector \(\bm{z}\) if \(f_{t}(\bm{x})=y\). The divergence of \(\theta_{t}\) at step \(t\), evaluated on class \(y\) is defined as:

\[\gamma_{t}^{y}=1-\exp\left(-(\bm{\hat{\mu}}_{t}^{y}-\bm{\mu}_{0}^{y})^{T}\left( \bm{\Sigma}_{0}^{y}\right)^{-1}(\bm{\hat{\mu}}_{t}^{y}-\bm{\mu}_{0}^{y}) \right),\] (6)

where \(\bm{\mu}_{0}^{y}\) and \(\bm{\Sigma}_{0}^{y}\) are the pre-computed empirical mean and covariant matrix of feature vectors in the source dataset (\(F_{0}\)). The covariant matrix here is diagonal for simplicity. In practice, without directly accessing the training set, we assume a small set of unlabeled samples can be drawn from the source distribution for empirically computing these values (visit Appdx. E.4 for further details).

Here, we implicitly expect the independence of each entry in \(\bm{z}\) and TTA approaches _learn to align feature vectors of new domains back to the source domain_ (\(P_{0}\)). Therefore, the accumulated statistics of these feature vectors at each step should be concentrated near the vectors of the initial model. The value of \(\gamma_{t}^{y}\in[0,1]\) is close to 0 when \(\theta_{t}=\theta_{0}\) and increases exponentially as \(\bm{\hat{\mu}}_{t}^{y}\) diverging from \(\bm{\mu}_{0}^{y}\).

**Adaptive Regularization and Model Update.** With \(\alpha_{0}\), \(\lambda_{0}\) are initial values, utilizing \(\gamma_{t}^{y}\) derived in Eq. 6, a pair of \((\lambda_{t}\), \(\alpha_{t}\)) is _adaptively_ chosen at each step:

\[\bar{\gamma}_{t} =\frac{1}{|\hat{\mathcal{Y}}_{t}|}\sum_{y\in\hat{\mathcal{Y}}_{t} }\gamma_{t}^{y},\quad\hat{\mathcal{Y}}_{t}=\left\{\hat{Y}_{t}^{(i)}|i=1, \cdots,N_{t}\right\};\] \[\lambda_{t} =\bar{\gamma}_{t}\cdot\lambda_{0},\qquad\alpha_{t}=(1-\bar{ \gamma}_{t})\cdot\alpha_{0},\] (7)

\(\hat{\mathcal{Y}}_{t}\) is a set of unique pseudo labels in a testing batch (\(\hat{Y}_{t}^{(i)}\) is the \(i^{\text{th}}\) realization of \(\hat{Y}_{t}\)).

**Anchor Loss.** Penalizing the divergence with regular vector norms in high-dimensional space (\(\Theta\)) is insufficient (curse of dimensionality [5, 51]), especially with a large model and limited samples. _Anchor loss_\(\mathcal{L}_{\mathrm{AL}}\) can nail down the similarity between \(f_{t}\) and \(f_{0}\) in the probability space [32, 12]:

\[\mathcal{L}_{\mathrm{AL}}(X_{t};\theta)=-\sum_{y\in\mathcal{Y}}\Pr(y|X_{t}; \theta_{0})\log\Pr(y|X_{t};\theta),\] (8)

which is equivalent to minimizing the KL divergence \(D_{KL}\left(\Pr(y|X_{t};\theta_{0})\|\Pr(y|X_{t};\theta)\right)\).

**Persistent TTA.** Having all the ingredients, we design our approach, PeTTA, following the convention setup of the mean teacher update, with the category-balanced memory bank and the robust batch normalization layer from [61]. Appdx. E.1 introduces the _pseudo code_ of PeTTA. For \(\mathcal{L}_{\mathrm{CLS}}\), either the self-training scheme [12] or the regular cross-entropy [16] is adopted. With \(\mathcal{R}(\theta)\), cosine similarity or L2 distance are both valid metrics for measuring the distance between \(\theta\) and \(\theta_{0}\) in the parameter space. Fisher regularizer coefficient [40, 27] can also be used, optionally. To sum up, the teacher model update of PeTTA is an _elaborated version_ of EMA with \(\lambda_{t},\alpha_{t}\) (Eq. 7) and \(\mathcal{L}_{\mathrm{AL}}\) (Eq. 8):

\[\theta_{t}^{\prime} =\mathop{\texttt{Optim}}_{\theta^{\prime}\in\Theta}\mathbb{E}_{P_ {t}}\left[\mathcal{L}_{\mathrm{CLS}}\left(\hat{Y}_{t},X_{t};\theta^{\prime} \right)+\mathcal{L}_{\mathrm{AL}}\left(X_{t};\theta^{\prime}\right)\right]+ \lambda_{t}\mathcal{R}(\theta^{\prime}),\] \[\theta_{t} =(1-\alpha_{t})\theta_{t-1}+\alpha_{t}\theta_{t}^{\prime}.\]

## 5 Experimental Results

### \(\epsilon-\)Mmc Simulation Result

**Simulation Setup.** A total of 6000 samples from two Gaussian distributions: \(\mathcal{N}(\mu_{0}=0,\sigma_{0}^{2}=1)\) and \(\mathcal{N}(\mu_{1}=2,\sigma_{1}^{2}=1)\) with \(p_{0}=p_{1}=\frac{1}{2}\) are synthesized and gradually released in a batch of \(B=10\) samples. For evaluation, an independent set of 2000 samples following the same distribution is used for computing the prediction frequency, and the false negative rate (FNR). \(\epsilon-\)GMMC update follows Eq. 4 with \(\alpha=5e^{-2}\). To simulate model collapse, the predictor is intercepted and 10% of the true-postive pseudo labels at each testing step are randomly flipped (Corollary 1).

**Simulation Result.** In action, both the likelihood of predicting class 0 (Fig. 2(a)-left) and the \(\epsilon_{t}\) (Eq. 5) (Fig. 2(c)-right, solid line) gradually increases over time as expected (Lemma 1). After collapsing,\(\epsilon\)-GMMC merges the two initial clusters, resulting in a single one (Fig. 2(b)-left) with parameters that match Lemma 2. The distance from \(\hat{\mu}_{0,t}\) (initialized at \(\mu_{0}\)) towards \(\mu_{1}\) converges (Fig. 2(c)-left, solid line), coincided with the analysis in Thm. 1 when \(\epsilon_{t}\) is chosen following Corollary 1 (Fig. 2(c), dashed line). GMMC (perturbed-free) stably produces accurate predictions (Fig. 2(a)-right) and approximates the true data distribution (Fig. 2(b)-right). The simulation empirically validates our analysis (Sec. 3.2), confirming the vulnerability of TTA models when the pseudo labels are inaccurately estimated.

### Setup - Benchmark Datasets

**Datasets.** We benchmark the performance on _four_ TTA classification tasks. Specifically, CIFAR10 \(\rightarrow\) CIFAR10-C, CIFAR100 \(\rightarrow\) CIFAR100-C, and ImageNet \(\rightarrow\) ImageNet-C [19] are three corrupted images classification tasks (corruption level 5, the most severe). Additionally, we incorporate DomainNet [44] with 126 categories from four domains for the task _real_\(\rightarrow\)_clipart, painting, sketch_.

**Compared Methods.** Besides PeTTA, the following algorithms are investigated: CoTTA [59], EATA [40], RMT [12], MECTA [22], RoTTA [61], ROID [37] and TRIBE [52]. Noteworthy, only RoTTA is specifically designed for the practical TTA setting while others fit the continual TTA setting in general. A parameter-free approach: LAME [7] and a reset-based approach (i.e., reverting the model to the source model after adapting to every \(1,000\) images): RDumb [45] are also included.

**Recurring TTA.** Following the practical TTA setup, multiple testing scenarios from each testing set will gradually change from one to another while the Dirichlet distribution (\(\mathrm{Dir}(0.1)\) for CIFAR10-C, DomainNet, and ImageNet-C, and \(\mathrm{Dir}(0.01)\) for CIFAR100-C) generates category temporally correlated batches of data. For all experiments, we set the number of revisits \(K=20\) (times) as this number is sufficient to fully observe the gradual degradation on existing TTA baselines.

**Implementation Details.** We use PyTorch[43] for implementation. RobustBench[10] and torchvision[35] provide pre-trained source models. Hyper-parameter choices are kept as close as possible to the original selections of authors. Visit Sec. G for more implementation details. Unless otherwise noted, for all PeTTA experiments, the EMA update rate for robust batch normalization [61] and feature embedding statistics is set to \(5e^{-2}\); \(\alpha_{0}=1e^{-3}\) and cosine similarity regularizer is used. On CIFAR10/100-C and ImageNet-C we use the self-training loss in [12] for \(\mathcal{L}_{\mathrm{CLS}}\) and \(\lambda_{0}=10\) while the regular cross-entropy loss [13] and \(\lambda_{0}=1\) (severe domain shift requires prioritizing

Figure 3: Simulation result on \(\epsilon\)-perturbed Gaussian Mixture Model Classifier (\(\epsilon\)-GMMC) and GMMC (perturbed-free). (a) Histogram of model predictions through time. A similar prediction frequency pattern is observed on CIFAR-10-C (Fig. 2(a)-left). (b) The probability density function of the two clusters after convergence versus the true data distribution. The initial two clusters of \(\epsilon\)-GMMC collapsed into a single cluster with parameters stated in Lemma 2. In the perturbed-free, GMMC converges to the true data distribution. (c) Distance toward \(\mu_{1}\) (\(|\mathbb{E}_{P_{i}}\left[\hat{\mu}_{0,t}\right]-\mu_{1}|\)) and false-negative rate (\(\epsilon_{t}\)) in simulation coincides with the result in Thm. 1 (with \(\epsilon_{t}\) following Corollary 1).

[MISSING_PAGE_FAIL:8]

**Collapsing Pattern.** The rise in classification error (Fig. 1-right) can be reasoned by the prediction frequency of RoTTA [61] in an recurring TTA setting (Fig. 5a-left). Similar to \(\epsilon\)-GMMC, the likelihood of receiving predictions on certain categories gradually increases and dominates the others. Further inspecting the confusion matrix of a collapsed model (Fig. 5b-top) reveals two major groups of categories are formed and a single category within each group represents all members, thereby becoming dominant. To see this, Fig. 5c-left simplifies the confusion matrix by only visualizing the

top prone-to-misclassified pair of categories. Here, label _deeer_ is used for almost every living animal while _airplane_ represents transport vehicles. The similarity between categories in the feature space of the source model (Fig. 5c-right) is correlated with the likelihood of being merged upon collapsing. As distance in feature space is analogous to \(|\mu_{0}-\mu_{1}|\) (Thm. 1), closer clusters are at a higher risk of collapsing. This explains and showcases that the collapsing behavior is predictable up to some extent.

### Ablation Study

**Effect of Each Component.** Tab. 4 gives an ablation study on PeTTA, highlighting the use of a regularization term (\(\mathcal{R}(\theta)\)) with a fixed choice of \(\lambda,\alpha\) not only fails to mitigate model collapse but may also introduce a negative effect (rows 2-3). Trivially applying the anchor loss (\(\mathcal{L}_{\mathrm{AL}}\)) alone is also incapable of eliminating the lifelong performance degradation in continual TTA (row 4). Within PeTTA, adopting the adaptive \(\lambda_{t}\) scheme alone (row 5) or in conjunction with either \(\alpha_{t}\) or anchor loss \(\mathcal{L}_{\mathrm{AL}}\) (rows 6-7) partially stabilizes the performance. Under the drastic domain shifts with a larger size of categories or model parameters (e.g., on CIFAR-100-C, DomainNet, ImageNet-C), restricting \(\alpha_{t}\) adjustment limits the ability of PeTTA to stop undesirable updates while a common regularization term without \(\mathcal{L}_{\mathrm{AL}}\) is insufficient to guide the adaptation. Thus, leveraging all elements secures the persistence of PeTTA (row 8).

**Various Choices of Regularizers.** The design of PeTTA is not coupled with any specific regularization term. Demonstrated in Tab. 5, PeTTA works well for the two common choices: L2 and cosine similarity. The conjunction use of Fisher coefficent [27; 40] for weighting the model parameter importance is also studied. While the benefit (in terms of improving accuracy) varies across datasets, PeTTA accommodates all choices, as the model collapse is not observed in any of the options.

## 6 Discussions and Conclusion

**On a Potential Risk of TTA in Practice.** We provide empirical and theoretical evidence on the risk of deploying continual TTA algorithms. Existing studies fail to detect this issue with _a single pass per test set_. The recurring TTA could be conveniently adopted as a _straightforward evaluation_, where its challenging test stream magnifies the error accumulation that a model might encounter in practice.

**Limitations.** PeTTA takes one step toward mitigating the gradual performance degradation of TTA. Nevertheless, a complete elimination of error accumulation cannot be guaranteed rigorously through regularization. Future research could delve deeper into expanding our efforts to develop an algorithm that achieves error accumulation-free by construction. Furthermore, as tackling the challenge of the temporally correlated testing stream is not the focus of PeTTA, using a small memory bank as in [61; 15] is necessary. It also assumes the features statistics from the source distribution are available (Appdx. E.3, E.4). These constraints potentially limit its scalability in real-world scenarios.

**Conclusion**. Towards trustworthy and reliable TTA applications, we rigorously study the _performance degradation problem of TTA_. The proposed _recurring TTA_ setting highlights the limitations of modern TTA methods, which struggle to prevent the error accumulation when continuously adapting to demanding test streams. Theoretically inspecting a failure case of \(\epsilon-\)_GMMC_ paves the road for designing PeTTA- a simple yet efficient solution that continuously assesses the model divergence for harmonizing the TTA process, balancing adaptation, and collapse prevention.

\begin{table}
\begin{tabular}{l|c|c|c|c} \hline \multicolumn{2}{l|}{**Method**} & \multicolumn{1}{c|}{**CF-10-C**} & \multicolumn{1}{c|}{**CF-100-C**} & \multicolumn{1}{c|}{**DN**} & \multicolumn{1}{c}{**IN-C**} \\ \hline Baseline w/o \(\mathcal{R}(\theta)\), \(\mathcal{L}_{\mathrm{AL}}\) & 42.6 & 63.0 & 77.9 & 93.4 \\ \hline \(\mathcal{R}(\theta)\) fixed \(\lambda=0.1\lambda_{0}\) & 43.3 & 65.0 & 80.0 & 92.5 \\ \(\mathcal{R}(\theta)\) fixed \(\lambda=\lambda_{0}\) & 42.0 & 64.6 & 66.6 & 92.9 \\ \hline \(\mathcal{L}_{\mathrm{AL}}\) only & 25.4 & 56.5 & 47.5 & 68.1 \\ \hline \hline PeTTA - \(\lambda_{t}\) & 27.1 & 55.0 & 59.7 & 92.7 \\ PeTTA - \(\lambda_{t}+\alpha_{t}\) & 23.9 & 41.4 & 44.5 & 75.7 \\ PeTTA - \(\lambda_{t}+\mathcal{L}_{\mathrm{AL}}\) & 26.2 & 36.3 & 43.2 & 62.0 \\ \hline PeTTA - \(\lambda_{t}+\alpha_{t}+\mathcal{L}_{\mathrm{AL}}\) & **22.8** & **35.1** & **42.9** & **60.5** \\ \hline \end{tabular}
\end{table}
Table 4: Average (across 20 visits) error of multiple variations of PeTTA: without (w/o) \(\mathcal{R}(\theta)\), \(\mathcal{L}_{\mathrm{AL}}\); \(\mathcal{L}_{\mathrm{AL}}\) only; fixed regularization coefficient \(\lambda\); adaptive coefficient \(\lambda_{t}\), update rate \(\alpha_{t}\); using anchor loss \(\mathcal{L}_{\mathrm{AL}}\).

\begin{table}
\begin{tabular}{c|c|c|c|c} \hline \multicolumn{2}{c|}{**Method**} & \multicolumn{1}{c|}{**CF-10-C**} & \multicolumn{1}{c|}{**CF-100-C**} & \multicolumn{1}{c|}{**DN**} & \multicolumn{1}{c}{**IN-C**} \\ \hline \(\mathcal{R}(\theta)\) & Fisher & 23.0 & 35.6 & 43.1 & 70.8 \\ \cline{2-5} L2 & ✗ & 22.7 & 36.0 & 43.9 & 70.0 \\ \hline \multirow{2}{*}{Cosine} & ✗ & 22.8 & **35.1** & **42.9** & **60.5** \\  & ✓ & **22.6** & 35.9 & 43.3 & 63.8 \\ \hline \multicolumn{2}{c}{CF: CIFAR, DN: DomainNet, IN: ImageNet} \\ \hline \end{tabular}
\end{table}
Table 5: Average (across 20 visits) error of PeTTA. PeTTA favors various choices of regularizers \(\mathcal{R}(\theta)\): L2 and cosine similarity in conjunction with Fisher [27; 40] coefficient.

## Acknowledgements

This work was supported by the Jump ARCHES Endowment through the Health Care Engineering Systems Center, JSPS/MEXT KAKENHI JP24K20830, ROIS NII Open Collaborative Research 2024-24S1201, in part by the National Institute of Health (NIH) under Grant R01 AI139401, and in part by the Vingroup Innovation Foundation under Grant VINIF.2021.DA00128.

## References

* Ahuja et al. [2021] Kartik Ahuja, Ethan Caballero, Dinghuai Zhang, Jean-Christophe Gagnon-Audet, Yoshua Bengio, Ioannis Mitliagkas, and Irina Rish. Invariance principle meets information bottleneck for out-of-distribution generalization. In A. Beygelzimer, Y. Dauphin, P. Liang, and J. Wortman Vaughan, editors, _Advances in Neural Information Processing Systems_, 2021. URL https://openreview.net/forum?id=jlcR0LfeF.
* Aljundi et al. [2019] Rahaf Aljundi, Eugene Belilovsky, Tinne Tuytelaars, Laurent Charlin, Massimo Caccia, Min Lin, and Lucas Page-Caccia. Online continual learning with maximal interfered retrieval. In H. Wallach, H. Larochelle, A. Beygelzimer, F. dAlche-Buc, E. Fox, and R. Garnett, editors, _Advances in Neural Information Processing Systems_, volume 32, 2019. URL https://proceedings.neurips.cc/paper_files/paper/2019/file/15825ae15eb335cc13f9b559f166ee8-Paper.pdf.
* Aljundi et al. [2019] Rahaf Aljundi, Min Lin, Baptiste Goujaud, and Yoshua Bengio. Gradient based sample selection for online continual learning. In _Advances in Neural Information Processing Systems_, volume 32, 2019. URL https://proceedings.neurips.cc/paper_files/paper/2019/file/e562cd9c0768d5464b64cf61da7fc6bb-Paper.pdf.
* Banerjee et al. [2009] Amitav Banerjee, U. B. Chitnis, S. L. Jadhav, J. S. Bhawalkar, and S. Chaudhury. Hypothesis testing, type I and type II errors. _Industrial Psychiatry Journal_, 18(2):127-131, 2009. ISSN 0972-6748. doi: 10.4103/0972-6748.62274. URL https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2996198/.
* Bellman [1957] Richard Bellman. _Dynamic Programming_. Princeton University Press, Princeton, NJ, USA, 1957.
* Blaas et al. [2023] Arno Blaas, Andrew Miller, Luca Zappella, Joern-Henrik Jacobsen, and Christina Heinze-Deml. Considerations for distribution shift robustness in health. In _ICLR 2023 Workshop on Trustworthy Machine Learning for Healthcare_, 2023. URL https://openreview.net/forum?id=y7XveyWYZIB.
* Boudiar et al. [2022] Malik Boudiar, Romain Mueller, Ismail Ben Ayed, and Luca Bertinetto. Parameter-free online test-time adaptation. In _2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)_, pages 8334-8343, 2022. doi: 10.1109/CVPR52688.2022.00816.
* Chen et al. [2022] Dian Chen, Dequan Wang, Trevor Darrell, and Sayna Ebrahimi. Contrastive test-time adaptation. In _Proceedings of the IEEE International Conference on Computer Vision_, 2022.
* Cover and Thomas [2006] Thomas M. Cover and Joy A. Thomas. _Elements of Information Theory (Wiley Series in Telecommunications and Signal Processing)_. Wiley-Interscience, USA, 2006. ISBN 0471241954.
* Croce et al. [2021] Francesco Croce, Maksym Andriushchenko, Vikash Sehwag, Edoardo Debenedetti, Nicolas Flammarion, Mung Chiang, Prateek Mittal, and Matthias Hein. Robustbench: a standardized adversarial robustness benchmark. In _Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track_, 2021. URL https://openreview.net/forum?id=SSKZPJCt7B.
* De Lange et al. [2022] Matthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Ales Leonardis, Gregory Slabaugh, and Tinne Tuytelaars. A continual learning survey: Defying forgetting in classification tasks. _IEEE Transactions on Pattern Analysis and Machine Intelligence_, 44(7):3366-3385, 2022. doi: 10.1109/TPAMI.2021.3057446.
* Dobler et al. [2022] Mario Dobler, Robert A. Marsden, and Bin Yang. Robust mean teacher for continual and gradual test-time adaptation. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)_, pages 7704-7714, June 2022.
* Ganin and Lempitsky [2015] Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In _Proceedings of the 32nd International Conference on Machine Learning_, volume 37 of _Proceedings of Machine Learning Research_, pages 1180-1189, Lille, France, 07-09 Jul 2015. PMLR. URL https://proceedings.mlr.press/v37/ganin15.html.
* Ganin et al. [2017] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Francois Laviolette, Mario Marchand, and Victor Lempitsky. _Domain-Adversarial Training of Neural Networks_, pages 189-209. Springer International Publishing, 2017. doi: 10.1007/978-3-319-58347-1_10. URL https://doi.org/10.1007/978-3-319-58347-1_10.
* Gong et al. [2022] Taesik Gong, Jongheon Jeong, Taewon Kim, Yewon Kim, Jinwoo Shin, and Sung-Ju Lee. NOTE: Robust continual test-time adaptation against temporal correlation. In _Advances in Neural Information Processing Systems_, 2022.

* Grandvalet and Bengio [2004] Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. In L. Saul, Y. Weiss, and L. Bottou, editors, _Advances in Neural Information Processing Systems_, volume 17, 2004. URL https://proceedings.neurips.cc/paper_files/paper/2004/file/96f2b50b5d3613adf9c27049b2a888c7-Paper.pdf.
* He et al. [2015] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. _arXiv preprint arXiv:1512.03385_, 2015.
* He et al. [2015] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification. In _Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)_, pages 1026-1034, 2015.
* Hendrycks and Dietterich [2019] Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. _Proceedings of the International Conference on Learning Representations_, 2019.
* Hendrycks et al. [2020] Dan Hendrycks, Norman Mu, Ekin D. Cubuk, Barret Zoph, Justin Gilmer, and Balaji Lakshminarayanan. AugMix: A simple data processing method to improve robustness and uncertainty. _Proceedings of the International Conference on Learning Representations (ICLR)_, 2020.
* Hendrycks et al. [2021] Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, Dawn Song, Jacob Steinhardt, and Justin Gilmer. The many faces of robustness: A critical analysis of out-of-distribution generalization. In _2021 IEEE/CVF International Conference on Computer Vision (ICCV)_, pages 8320-8329, 2021. doi: 10.1109/ICCV48922.2021.00823.
* Hong et al. [2023] Junyuan Hong, Lingjuan Lyu, Jiayu Zhou, and Michael Spranger. MECTA: Memory-economic continual test-time model adaptation. In _The Eleventh International Conference on Learning Representations_, 2023. URL https://openreview.net/forum?id=N92hjSf5NWh.
* Isensee et al. [2021] Fabian Isensee, Paul F. Jaeger, Simon A. A. Kohl, Jens Petersen, and Klaus H. Maier-Hein. nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. _Nature Methods_, 18(2):203-211, February 2021. ISSN 1548-7105. doi: 10.1038/s41592-020-01008-z. URL https://www.nature.com/articles/s41592-020-01008-z.
* Iwasawa and Matsuo [2021] Yusuke Iwasawa and Yutaka Matsuo. Test-time classifier adjustment module for model-agnostic domain generalization. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang, and J. Wortman Vaughan, editors, _Advances in Neural Information Processing Systems_, volume 34, pages 2427-2440, 2021. URL https://proceedings.neurips.cc/paper_files/paper/2021/file/1415fe9feao7fa1e45dddcf5682239a0-Paper.pdf.
* Katehakis and Veinott [1987] Michael N. Katehakis and Arthur F. Veinott. The multi-armed bandit problem: Decomposition and computation. _Mathematics Operations Research_, 12:262-268, 1987. URL https://api.semanticscholar.org/CorpusID:656323.
* Kingma and Ba [2015] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In Yoshua Bengio and Yann LeCun, editors, _3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings_, 2015. URL http://arxiv.org/abs/1412.6980.
* Kirkpatrick et al. [2017] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A. Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Kumaran, and Raia Hadsell. Overcoming catastrophic forgetting in neural networks. _Proceedings of the National Academy of Sciences_, 114(13):3521-3526, 2017. doi: 10.1073/pnas.1611835114. URL https://www.pnas.org/doi/abs/10.1073/pnas.1611835114.
* Lee [2013] Dong-Hyun Lee. Pseudo-label : The simple and efficient semi-supervised learning method for deep neural networks. _ICML 2013 Workshop : Challenges in Representation Learning (WREPL)_, 07 2013.
* Lee et al. [2024] T. Lee, S. Chottananurak, T. Gong, and S. Lee. Aetta: Label-free accuracy estimation for test-time adaptation. In _2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)_, pages 28643-28652, Los Alamitos, CA, USA, jun 2024. IEEE Computer Society. doi: 10.1109/CVPR52733.2024.02706. URL https://doi.ieeecomputersociety.org/10.1109/CVPR52733.2024.02706.
* Li et al. [2018] Haoliang Li, Sinno Jialin Pan, Shiqi Wang, and Alex C. Kot. Domain generalization with adversarial feature learning. In _Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)_, June 2018.
* Li et al. [2017] Yanghao Li, Naiyan Wang, Jianping Shi, Jiaying Liu, and Xiaodi Hou. Revisiting batch normalization for practical domain adaptation. In _International Conference on Learning Representations Workshop_, 2017. URL https://openreview.net/forum?id=BJuysoFeg.
* Li and Hoiem [2018] Zhizhong Li and Derek Hoiem. Learning without forgetting. _IEEE Transactions on Pattern Analysis and Machine Intelligence_, 40(12):2935-2947, 2018. doi: 10.1109/TPAMI.2017.2773081.
* Liang et al. [2020] Jian Liang, Dapeng Hu, and Jiashi Feng. Do we really need to access the source data? Source hypothesis transfer for unsupervised domain adaptation. In _International Conference on Machine Learning (ICML)_, pages 6028-6039, 2020.

* Lin et al. [2023] Sen Lin, Peizhong Ju, Yingbin Liang, and Ness Shroff. Theory on forgetting and generalization of continual learning. In _Proceedings of the 40th International Conference on Machine Learning_, ICML'23, 2023.
* maintainers and contributors [2016] TorchVision maintainers and contributors. Torchvision: Pytorch's computer vision library. https://github.com/pytorch/vision, 2016.
* Marsden et al. [2022] Robert A Marsden, Mario Dobler, and Bin Yang. Gradual test-time adaptation by self-training and style transfer. _arXiv preprint arXiv:2208.07736_, 2022.
* Marsden et al. [2024] Robert A Marsden, Mario Dobler, and Bin Yang. Universal test-time adaptation through weight ensembling, diversity weighting, and prior correction. In _Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision_, pages 2555-2565, 2024.
* Mildenhall et al. [2020] Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik, Jonathan T. Barron, Ravi Ramamoorthi, and Ren Ng. NeRF: Representing scenes as neural radiance fields for view synthesis. In _Proceedings of the European Conference on Computer Vision (ECCV)_, 2020.
* Nguyen et al. [2023] A. Tuan Nguyen, Thanh Nguyen-Tang, Ser-Nam Lim, and Philip Torr. TIPI: Test time adaptation with transformation invariance. In _Conference on Computer Vision and Pattern Recognition 2023_, 2023. URL https://openreview.net/forum?id=NWhicy376e.
* Niu et al. [2022] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan. Efficient test-time model adaptation without forgetting. In _The International Conference on Machine Learning_, 2022.
* Niu et al. [2023] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Zhiquan Wen, Yaofo Chen, Peilin Zhao, and Mingkui Tan. Towards stable test-time adaptation in dynamic wild world. In _The Eleventh International Conference on Learning Representations_, 2023. URL https://openreview.net/forum?id=g2YraF75Tj.
* Parthasarathy [2005] K. R. Parthasarathy. _Introduction to Probability and Measure_, volume 33 of _Texts and Readings in Mathematics_. Hindustan Book Agency, Gurgaon, 2005. ISBN 978-81-85931-55-5 978-93-86279-27-9. doi: 10.1007/978-93-86279-27-9. URL http://link.springer.com/10.1007/978-93-86279-27-9.
* Paszke et al. [2019] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zach DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high-performance deep learning library, 2019.
* Peng et al. [2019] Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, and Bo Wang. Moment matching for multi-source domain adaptation. In _Proceedings of the IEEE International Conference on Computer Vision_, pages 1406-1415, 2019.
* Press et al. [2023] Ori Press, Steffen Schneider, Matthias Kuemmerer, and Matthias Bethge. RDumb: A simple approach that questions our progress in continual test-time adaptation. In _Thirty-seventh Conference on Neural Information Processing Systems_, 2023. URL https://openreview.net/forum?id=VfP6PVTVshC.
* Quionero-Candela et al. [2009] Joaquin Quionero-Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil D. Lawrence. _Dataset Shift in Machine Learning_. The MIT Press, 2009. ISBN 0262170051.
* Radford et al. [2021] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Greethen Krueger, and Ilya Sutskever. Learning transferable visual models from natural language supervision. In Marina Meila and Tong Zhang, editors, _Proceedings of the 38th International Conference on Machine Learning_, volume 139 of _Proceedings of Machine Learning Research_, pages 8748-8763. PMLR, 18-24 Jul 2021. URL https://proceedings.mlr.press/v139/radford21a.html.
* Recht et al. [2019] Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar. Do ImageNet classifiers generalize to ImageNet? In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, _Proceedings of the 36th International Conference on Machine Learning_, volume 97 of _Proceedings of Machine Learning Research_, pages 5389-5400. PMLR, 09-15 Jun 2019. URL https://proceedings.mlr.press/v97/recht19a.html.
* Rhee and Kim [2018] Mooweon Rhee and Tohyun Kim. _Exploration and Exploitation_, pages 543-546. Palgrave Macmillan UK, London, 2018. ISBN 978-1-137-00772-8. doi: 10.1057/978-1-137-00772-8.388. URL https://doi.org/10.1057/978-1-137-00772-8_388.
* Riemer et al. [2019] Matthew Riemer, Ignacio Cases, Robert Ajemian, Miao Liu, Irina Rish, Yuhai Tu,, and Gerald Tesauro. Learning to learn without forgetting by maximizing transfer and minimizing interference. In _International Conference on Learning Representations_, 2019. URL https://openreview.net/forum?id=B1gTShActC7.
* Sirimongkolskasem and Drikvandi [2019] Tanin Sirimongkolskasem and Reza Drikvandi. On Regularisation Methods for Analysis of High Dimensional Data. _Annals of Data Science_, 6(4):737-763, December 2019. ISSN 2198-5812. doi: 10.1007/s40745-019-00209-4. URL https://doi.org/10.1007/s40745-019-00209-4.

* Su et al. [2024] Yongyi Su, Xun Xu, and Kui Jia. Towards real-world test-time adaptation: Tri-net self-training with balanced normalization. _Proceedings of the AAAI Conference on Artificial Intelligence_, 38(13):15126-15135, 2024.
* Sun et al. [2020] Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt. Test-time training with self-supervision for generalization under distribution shifts. In Hal Daume III and Aarti Singh, editors, _Proceedings of the 37th International Conference on Machine Learning_, volume 119 of _Proceedings of Machine Learning Research_, pages 9229-9248. PMLR, 13-18 Jul 2020. URL https://proceedings.mlr.press/v119/sun20b.html.
* Sutton and Barto [2018] Richard S. Sutton and Andrew G. Barto. _Reinforcement Learning: An Introduction_. MIT Press, Cambridge, MA, 2018.
* Tarvainen and Valpola [2017] Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. In _Proceedings of the 31st International Conference on Neural Information Processing Systems_, NIPS'17, page 1195-1204, 2017. ISBN 9781510860964.
* Vela et al. [2022] Daniel Vela, Andrew Sharp, Richard Zhang, Trang Nguyen, An Hoang, and Oleg S. Pianykh. Temporal quality degradation in AI models. _Scientific Reports_, 12(1):11654, July 2022. ISSN 2045-2322. doi: 10.1038/s41598-022-15245-z. URL https://www.nature.com/articles/s41598-022-15245-z.
* Wang et al. [2021] Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, and Trevor Darrell. Tent: Fully test-time adaptation by entropy minimization. In _International Conference on Learning Representations_, 2021. URL https://openreview.net/forum?id=uX13b2Lkrx3c.
* Wang et al. [2021] Jindong Wang, Cuiling Lan, Chang Liu, Yidong Ouyang, and Tao Qin. Generalizing to unseen domains: A survey on domain generalization. In Zhi-Hua Zhou, editor, _Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21_, pages 4627-4635. International Joint Conferences on Artificial Intelligence Organization, 8 2021. doi: 10.24963/ijcai.2021/628. URL https://doi.org/10.24963/ijcai.2021/628. Survey Track.
* Wang et al. [2022] Qin Wang, Olga Fink, Luc Van Gool, and Dengxin Dai. Continual test-time domain adaptation. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)_, pages 7201-7211, June 2022.
* a case study in healthcare information systems. _International Journal of Information Management Data Insights_, 2(1):100070, 2022. ISSN 2667-0968. doi: https://doi.org/10.1016/j.ijimei.2022.100070. URL https://www.sciencedirect.com/science/article/pii/S2667096822000143.
* Yuan et al. [2023] Longhui Yuan, Binhui Xie, and Shuang Li. Robust test-time adaptation in dynamic scenarios. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pages 15922-15932, 2023.
* Zhao et al. [2023] Hao Zhao, Yuejiang Liu, Alexandre Alahi, and Tao Lin. On pitfalls of test-time adaptation. In _ICLR 2023 Workshop on Pitfalls of limited data and computation for Trustworthy ML_, 2023. URL https://openreview.net/forum?id=0Go_RsG_dYn.

**Persistent Test-time Adaptation in Recurring Testing Scenarios**

**Technical Appendices**

**Table of Contents**

* A Related Work
* B Proof of Lemmas and Theorems
* B.1 Proof of Lemma 1
* B.2 Proof of Lemma 2.
* B.3 Proof of Theorem 1 and Corollary 1.
* C Further Justifications on Gaussian Mixture Model Classifier
* D Further Justifications on the Recurring Testing Scenario
* D.1 Recurring TTA Follows the Design of a Practical TTA Stream
* D.2 Recurring TTA as a Diagnostic Tool
* D.3 Recurring TTA with Random Orders
* E Further Justifications on Persistent TTA (PeTTA)
* E.1 Pseudo Code
* E.2 Anchor Loss
* E.3 The Use of the Memory Bank
* E.4 Empirical Mean and Covariant Matrix of Feature Vectors on the Source Dataset
* E.5 Novelty of PeTTA
* F Additional Experimental Results of PeTTA
* F.1 Performance of PeTTA Versus Compared Methods
* F.2 An Inspection of PeTTA
* F.3 Does Model Reset Help?
* F.4 PeTTA with 40 Recurring Visits
* F.5 The Sensitivity of Hyper-parameter Choices in PeTTA
* F.6 More Details on the Ablation Study
* F.7 More Confusion Matrices in Recurring TTA Setting
* G Experimental Details
* G.1 Computing Resources
* G.2 Experiments on CCC Testing Stream
* G.3 Test-time Adaptation Methods
* G.4 The Use of Existing Assets
Related Work

**Towards Robust and Practical TTA.** While forming the basis, early single-target TTA approaches [53, 57, 39, 41, 33] is far from practice. Observing the dynamic of many testing environments, a continual TTA setting is proposed where an ML model continuously adapts to a sequence of multiple shifts [36, 59]. Meanwhile, recent studies [15, 7] point out that the category distribution realistic streams is highly temporally correlated. Towards real-world TTA setting, Yuan _et al._[61] launch the _practical TTA_ which considers the simultaneous occurrence of the two aforementioned challenges.

For a robust and gradual adaptation, an update via the mean teacher [55] mechanism is exploited in many continual TTA algorithms [59, 61, 12, 22]. To moderate the temporally correlated test stream, common approaches utilize a small memory bank for saving a category-balanced subset of testing samples [15, 61], inspired by the replay methods [50, 2] to avoid forgetting in the task of continual learning [34, 3, 11]. Our study emphasizes another perspective: beyond a supreme performance, a desirable TTA should also _sustain it for an extended duration_.

**Temporal Performance Degradation.** By studying the quality of various ML models across multiple industry applications [56, 60] the issue of AI "aging" with the temporal model degradation progress, even with data coming from a stable process has been confirmed. In TTA, the continuous changes of model parameters through gradient descent aggravate the situation, as also recently noticed in [45]. Apart from observation, we attempt to investigate and provide _theoretical_ insights towards the mechanism of this phenomenon.

**Accumulated Errors in TTA.** In TTA, the issue of accumulated error has been briefly acknowledged. Previous works strive to avoid drastic changes to model parameters as a good practice. Up to some degree, it helps to avoid performance degradation. Nevertheless, it is still _unclear whether their effectiveness truly eliminates the risk_. To preserve in-distribution performance, regularization [27, 40] or replaying of training samples at test-time [12] have been used. Other studies explore reset (recovering the initial model parameters) strategies [59, 45], periodically or upon the running entropy loss approaches a threshold [41]. Unfortunately, knowledge accumulated in the preceding steps will vanish, and a bad heuristic choice of threshold or period leads to highly frequent model resets. Noteworthy, tuning those hyper-parameters is exceedingly difficult due to the unavailability of the validation set [62]. LAME [7] suggests a post-processing step for adaptation (without updating the parameters). This approach, however, still limits the knowledge accumulation. Our PeTTA is _reset-free_ by achieving an adaptable continual test-time training.

## Appendix B Proof of Lemmas and Theorems

In this section, we prove the theoretical results regarding the \(\epsilon-\)perturbed Gaussian Mixture Model Classifier (\(\epsilon-\)GMMC) introduced in Sec. 3.2. We first briefly summarize the definition of model collapse and the static data stream assumption:

**Definition 1** (**Model Collapse)**.: _A model is said to be collapsed from step \(\tau\in\mathcal{T},\tau<\infty\) if there exists a non-empty subset of categories \(\tilde{\mathcal{Y}}\subset\mathcal{Y}\) such that \(\Pr\{Y_{t}\in\tilde{\mathcal{Y}}\}>0\) but the marginal \(\Pr\{\hat{Y}_{t}\in\tilde{\mathcal{Y}}\}\) converges to zero in probability:_

\[\lim_{t\rightarrow\tau}\Pr\{\hat{Y}_{t}\in\tilde{\mathcal{Y}}\}=0.\]

**Assumption 1** (**Static Data Stream)**.: _The marginal distribution of the true label follows the same Bernoulli distribution \(\mathrm{Ber}(p_{0})\): \(p_{0,t}=p_{0}\), (\(p_{1,t}=p_{1}=1-p_{0}),\forall t\in\mathcal{T}\)._

**Preliminary.** Following the same set of notations introduced in the main text, recall that we denoted \(p_{y,t}\triangleq\Pr\{Y_{t}=y\}\), \(\hat{p}_{y,t}\triangleq\Pr\{\hat{Y}_{t}=y\}\) (marginal distribution of the true label \(Y_{t}\) and pseudo label \(\hat{Y}_{t}\) receiving label \(y\), respectively) and \(\epsilon_{t}\) = \(\Pr\{Y_{t}=1|\hat{Y}_{t}=0\}\) (the false negative rate (FNR) of \(\epsilon-\)GMMC). At testing step \(t\), we obtain the following relations:

\[\mathbb{E}_{P_{t}}\left[X_{t}|\hat{Y}_{t}=0\right] =(1-\epsilon_{t})\mu_{0}+\epsilon_{t}\mu_{1},\] (9) \[\mathbb{E}_{P_{t}}\left[X_{t}|\hat{Y}_{t}=1\right] =\mu_{1},\] (10) \[\mathrm{Var}_{P_{t}}\left(X_{t}|\hat{Y}_{t}=0\right) =(1-\epsilon_{t})\sigma_{0}^{2}+\epsilon_{t}\sigma_{1}^{2}+ \epsilon_{t}(1-\epsilon_{t})(\mu_{0}-\mu_{1})^{2},\] (11) \[\mathrm{Var}_{P_{t}}\left(X_{t}|\hat{Y}_{t}=1\right) =\sigma_{1}^{2}.\] (12)

In addition, under Assumption 1, the marginal distribution \(P_{t}(x)\) (also referred as _data distribution_ in our setup) is:

\[P_{t}(x)=\mathcal{N}(x;p_{0}\mu_{0}+p_{1}\mu_{1},p_{0}\sigma_{0}^{2}+p_{1} \sigma_{1}^{2}+p_{0}p_{1}(\mu_{0}-\mu_{1})^{2})\qquad\forall t\in\mathcal{T}.\] (13)

### Proof of Lemma 1

**Lemma 1** (Increasing FNR).: _Under Assumption 1, a binary \(\epsilon\)-GMMC would collapsed (Def. 1) with \(\underset{t\rightarrow\tau}{\lim}\hat{p}_{1,t}=0\) (or \(\underset{t\rightarrow\tau}{\lim}\hat{p}_{0,t}=1\), equivalently) if and only if \(\underset{t\rightarrow\tau}{\lim}\epsilon_{t}=p_{1}\)._

Proof.: Under Assumption 1, we have \(\mathbb{E}_{P_{t}}\left[X_{t}\right]=p_{0}\mu_{0}+(1-p_{0})\mu_{1}\). Also note that:

\[\mathbb{E}_{P_{t}}\left[X_{t}\right] =\mathbb{E}_{P_{t}}\left[\mathbb{E}_{P_{t}}\left[X_{t}|\hat{Y}_{t }\right]\right]\] (14) \[=\mathbb{E}_{P_{t}}\left[X_{t}|\hat{Y}_{t}=0\right]\hat{p}_{0,t}+ \mathbb{E}_{P_{t}}\left[X_{t}|\hat{Y}_{t}=1\right]\hat{p}_{1,t}\] \[=[(1-\epsilon_{t})\mu_{0}+\epsilon_{t}\mu_{1}]\,\hat{p}_{0,t}+ \mu_{1}(1-\hat{p}_{0,t})\] \[=[(1-\epsilon_{t})\hat{p}_{0,t}]\,\mu_{0}+[1-\hat{p}_{0,t}(1- \epsilon_{t})]\,\mu_{1}\] \[=p_{0}\mu_{0}+(1-p_{0})\mu_{1},\]

where the second equality follows Eqs. 9-10. Therefore:

\[\hat{p}_{0,t}=\frac{p_{0}}{1-\epsilon_{t}}.\] (15)

Eq. 15 shows positive correlation between \(\hat{p}_{0,t}\) and \(\epsilon_{t}\). Given \(\underset{t\rightarrow\tau}{\lim}\epsilon_{t}=p_{1}\), taking the limit introduces:

\[\underset{t\rightarrow\tau}{\lim}\hat{p}_{0,t}=\underset{t \rightarrow\tau}{\lim}\frac{p_{0}}{1-\epsilon_{t}}=\frac{p_{0}}{1-p_{1}}=1.\]

Similarly, having \(\underset{t\rightarrow\tau}{\lim}\hat{p}_{0,t}=1\), the false negative rate \(\epsilon_{t}\) when \(t\rightarrow\tau\) is:

\[\underset{t\rightarrow\tau}{\lim}\epsilon_{t}=1-p_{0}=p_{1}.\]

Since \(\hat{p}_{0,t}+\hat{p}_{1,t}=1\), \(\underset{t\rightarrow\tau}{\lim}\hat{p}_{1,t}=0\), equivalently. Towards the collapsing point, the model tends to predict a single label (class 0 in the current setup). In addition, the FNR of the model \(\epsilon_{t}\) also raises correspondingly. 

### Proof of Lemma 2.

**Lemma 2** (\(\epsilon\)**-GMMC After Collapsing**).: _For a binary \(\epsilon\)-GMMC model, with Assumption 1, if \(\underset{t\rightarrow\tau}{\lim}\hat{p}_{1,t}=0\) (collapsing), the cluster 0 in GMMC converges in distribution to a single-cluster GMMC with parameters:_

\[\mathcal{N}(\hat{\mu}_{0,t},\hat{\sigma}_{0,t}^{2})\overset{d}{\rightarrow} \mathcal{N}(p_{0}\mu_{0}+p_{1}\mu_{1},p_{0}\sigma_{0}^{2}+p_{1}\sigma_{1}^{2 }+p_{0}p_{1}(\mu_{0}-\mu_{1})^{2}).\]

Proof.: From Eqs. 9-10, under the increasing type II collapse of \(\epsilon-\)GMMC setting, the perturbation does not affect the approximation of \(\mu_{1}\). Meanwhile, when \(\epsilon_{t}\) increases, one can expect that moves further away from \(\mu_{0}\) toward \(\mu_{1}\). First, the mean teacher model of GMMC (Eq. 4, main text) gives:

\[\mathbb{E}_{P_{t}}\left[\hat{\mu}_{0,t}|\hat{Y}_{t}=1\right] =\mathbb{E}_{P_{t-1}}\left[\hat{\mu}_{0,t-1}\right],\] \[\mathbb{E}_{P_{t}}\left[\hat{\mu}_{0,t}|\hat{Y}_{t}=0\right] =(1-\alpha)\mathbb{E}_{P_{t-1}}\left[\hat{\mu}_{0,t-1}|\hat{Y}_{t }=0\right]+\alpha\mathbb{E}_{P_{t}}\left[X_{t}|\hat{Y}_{t}=0\right]\] \[=(1-\alpha)\mathbb{E}_{P_{t-1}}\left[\hat{\mu}_{0,t-1}\right]+ \alpha\left(\mathbb{E}_{P_{t}}\left[X_{t}|\hat{Y}_{t}=0\right]\right),\] \[\mathbb{E}_{P_{t}}\left[\hat{\mu}_{1,t}|\hat{Y}_{t}=1\right] =(1-\alpha)\mathbb{E}_{P_{t-1}}\left[\hat{\mu}_{1,t-1}|\hat{Y}_{t }=1\right]+\alpha\mathbb{E}_{P_{t}}\left[X_{t}|\hat{Y}_{t}=1\right]\] \[=(1-\alpha)\mathbb{E}_{P_{t-1}}\left[\hat{\mu}_{1,t-1}\right]+ \alpha\left(\mathbb{E}_{P_{t}}\left[X_{i}|\hat{Y}_{t}=1\right]\right),\] \[\mathbb{E}_{P_{t}}\left[\hat{\mu}_{1,t}|\hat{Y}_{t}=0\right] =\mathbb{E}_{P_{t-1}}\left[\hat{\mu}_{1,t-1}\right].\]

By defining \(u_{y,t}=\mathbb{E}_{P_{t}}\left[\hat{\mu}_{y,t}\right]\), we obtain the following recurrence relation between \(u_{0,t}\) and \(u_{0,t-1}\):

\[u_{0,t} =\mathbb{E}_{P_{t}}\left[\hat{\mu}_{0,t}|\hat{Y}_{t}=0\right]\hat {p}_{0,t}+\mathbb{E}_{P_{t}}\left[\hat{\mu}_{0,t}|\hat{Y}_{t}=1\right]\hat{p}_{ 1,t}\] \[=\left((1-\alpha)u_{0,t-1}+\alpha\mathbb{E}_{P_{t}}\left[X_{t}| \hat{Y}_{t}=0\right]\right)\hat{p}_{0,t}+u_{0,t-1}\hat{p}_{1,t}\] \[=\left[(1-\alpha)\hat{p}_{0,t}+\hat{p}_{1,t}\right]u_{0,t-1}+ \alpha\hat{p}_{0,t}\mathbb{E}_{P_{t}}\left[X_{t}|\hat{Y}_{t}=0\right]\] \[=(1-\alpha\hat{p}_{0,t})u_{0,t-1}+\alpha\hat{p}_{0,t}\left[(1- \epsilon_{t})\mu_{0}+\epsilon_{t}\mu_{1}\right].\] (16)

Given \(\underset{t\rightarrow\tau}{\lim}\hat{p}_{0,t}=1\), it follows that \(\underset{t\rightarrow\tau}{\lim}\epsilon_{0,t}=p_{1}\) by Lemma 1. From this point:

\[u_{0,t}=(1-\alpha)u_{0,t-1}+\alpha\left(p_{0}\mu_{0}+p_{1}\mu_{1}\right)\qquad \forall t>\tau.\]

Taking the limit \(t\rightarrow\infty\):

\[\underset{t\rightarrow\infty}{\lim}u_{0,t} =\underset{t\rightarrow\infty}{\lim}(1-\alpha)u_{0,t-1}+\alpha \left(p_{0}\mu_{0}+p_{1}\mu_{1}\right)\] \[=\underset{t\rightarrow\infty}{\lim}(1-\alpha)^{t}\hat{\mu}_{0,0} +\alpha\sum_{i=1}^{t}(1-\alpha)^{i-1}\left(p_{0}\mu_{0}+p_{1}\mu_{1}\right)\] \[=\underset{t\rightarrow\infty}{\lim}(1-\alpha)^{t}\hat{\mu}_{0,0} +(1-(1-\alpha)^{t})(p_{0}\mu_{0}+p_{1}\mu_{1})\] \[=p_{0}\mu_{0}+p_{1}\mu_{1}.\]

The second equation is obtained by solving the recurrence relation. When \(\underset{t\rightarrow\tau}{\lim}\hat{p}_{0,t}=1\), \(\{\hat{\mu}_{y,t}\}_{y\in\{0,1\}}\) becomes a deterministic values. Hence, giving \(u_{y,t}=\mathbb{E}_{P_{t}}\left[\hat{\mu}_{y,t}\right]=\hat{\mu}_{0,t}(\forall t >\tau)\) and

\[\underset{t\rightarrow\infty}{\lim}\hat{\mu}_{0,t}=\underset{t \rightarrow\infty}{\lim}u_{0,t}=p_{0}\mu_{0}+p_{1}\mu_{1}.\] (17)

Repeating the steps above with Eqs. 11-12 in place of Eqs. 9-10, we obtain a similar result for \(\sigma_{0,t}^{2}\):

\[\underset{t\rightarrow\infty}{\lim}\hat{\sigma}_{0,t}^{2}=p_{0}\sigma_{0}^{2} +p_{1}\sigma_{1}^{2}+p_{0}p_{1}(\mu_{0}-\mu_{1})^{2}.\] (18)

By _Levy's continuity theorem_ (p. 302, [42]), from Eqs. 17-18, when \(t\rightarrow\infty\), the estimated distribution of the first cluster \(\mathcal{N}(x;\hat{\mu}_{0,t}\hat{\sigma}_{0,t}^{2})\) converges to the whole data distribution \(P_{t}(x)\) (Eq. 13) when collapsing.

### Proof of Theorem 1 and Corollary 1.

**Theorem 1** (**Convergence of \(\epsilon-\)Gmdc**).: _For a binary \(\epsilon\)-GMMC model, with Assumption 1, let the distance from \(\hat{\mu}_{0,t}\) toward \(\mu_{1}\) is \(d_{t}^{0\to 1}=|\mathbb{E}_{P_{t}}\left[\hat{\mu}_{0,t}\right]-\mu_{1}|\), then:_

\[d_{t}^{0\to 1}-d_{t-1}^{0\to 1}\leq\alpha\cdot p_{0}\cdot\left(|\mu_{0}-\mu_{1}|- \frac{d_{t-1}^{0\to 1}}{1-\epsilon_{t}}\right).\]Proof.: Substituting Eq. 15 into \(\hat{p}_{0,t}\) of Eq. 16 gives:

\[u_{0,t}=\left(1-\frac{\alpha p_{0}}{1-\epsilon_{t}}\right)u_{0,t-1}+\frac{\alpha p _{0}}{1-\epsilon_{t}}\left[(1-\epsilon_{t})\mu_{0}+\epsilon_{t}\mu_{1}\right].\]

Hence, we have the distance from \(u_{0,t}\) toward \(\mu_{1}\):

\[|u_{0,t}-\mu_{1}|= \left|\left(1-\frac{\alpha p_{0}}{1-\epsilon_{t}}\right)u_{0,t-1} +\alpha p_{0}\mu_{0}+\frac{\alpha p_{0}\epsilon_{t}\mu_{1}}{1-\epsilon_{t}}- \mu_{1}\right|\] \[= \left|\left(1-\frac{\alpha p_{0}}{1-\epsilon_{t}}\right)(u_{0,t- 1}-\mu_{1})+\alpha p_{0}\mu_{0}+\frac{\alpha p_{0}\epsilon_{t}\mu_{1}}{1- \epsilon_{t}}-\frac{\alpha p_{0}\mu_{1}}{1-\epsilon_{t}}\right|\] \[= \left|\left(1-\frac{\alpha p_{0}}{1-\epsilon_{t}}\right)(u_{0,t- 1}-\mu_{1})+\alpha p_{0}\mu_{0}-\frac{\alpha p_{0}\mu_{1}(1-\epsilon_{t})}{1- \epsilon_{t}}\right|\] \[= \left|\left(1-\frac{\alpha p_{0}}{1-\epsilon_{t}}\right)(u_{0,t- 1}-\mu_{1})+\alpha p_{0}(\mu_{0}-\mu_{1})\right|\] \[\leq \left(1-\frac{\alpha p_{0}}{1-\epsilon_{t}}\right)|u_{0,t-1}-\mu_ {1}|+\alpha p_{0}|\mu_{0}-\mu_{1}|.\]

The last inequality holds due to the triangle inequality. Equivalently,

\[|u_{0,t}-\mu_{1}|-|u_{0,t-1}-\mu_{1}|\leq\alpha\cdot p_{0}\cdot\left(|\mu_{0}- \mu_{1}|-\frac{|u_{0,t-1}-\mu_{1}|}{1-\epsilon_{t}}\right).\]

Let \(d_{t}^{0\to 1}=|\mathbb{E}_{P_{t}}\left[\hat{\mu}_{0,t}\right]-\mu_{1}|\), we conclude that:

\[d_{t}^{0\to 1}-d_{t-1}^{0\to 1}\leq\alpha\cdot p_{0}\cdot\left(|\mu_{0}-\mu_{1}|- \frac{d_{t-1}^{0\to 1}}{1-\epsilon_{t}}\right).\]

**Corollary 1** (A Condition for \(\epsilon-\)GMMC Collapse).: _With fixed \(p_{0}\), \(\alpha,\mu_{0},\mu_{1}\), \(\epsilon-\)GMMC is collapsed if there exists a sequence of \(\{\epsilon_{t}\}_{\tau-\Delta_{\tau}}^{\tau}\) (\(\tau\geq\Delta_{\tau}>0\)) such that:_

\[p_{1}\geq\epsilon_{t}>1-\frac{d_{t-1}^{0\to 1}}{|\mu_{0}-\mu_{1}|},\quad t\in[ \tau-\Delta_{\tau},\tau].\]

Proof.: Initialized at \(\mu_{0}\), \(\epsilon\)-GMMC is collapsing when \(\hat{\mu}_{0,t}\) converges to the mid-point \(p_{0}\mu_{0}+p_{1}\mu_{1}\) (Lemma 2), i.e., moving closer to \(\mu_{1}\). From Thm. 1, the distance towards \(\mu_{1}\)\(d_{t}^{0\to 1}<d_{t-1}^{0\to 1}\) if

\[|\mu_{0}-\mu_{1}|-\frac{|u_{0,t-1}-\mu_{1}|}{1-\epsilon_{t}}<0\Leftrightarrow| \mu_{0}-\mu_{1}|<\frac{|u_{0,t-1}-\mu_{1}|}{1-\epsilon_{t}}\Leftrightarrow \epsilon_{t}>1-\frac{|u_{0,t-1}-\mu_{1}|}{|\mu_{0}-\mu_{1}|}.\]

When there exists this sequence \(\{\epsilon_{t}\}_{\tau-\Delta_{\tau}}^{\tau}\) (\(\tau\geq\Delta_{\tau}>0\)) it follows that \(d_{t}^{0\to 1}<d_{t-1}^{0\to 1}\) and \(\epsilon_{t}>\epsilon_{t-1}\) is guaranteed \(\forall t\in[\tau-\Delta_{\tau},\tau]\). Hence, \(\lim\limits_{t\to\tau}\epsilon_{t}=p_{1}\) (model collapsed, by Lemma 1). 

## Appendix C Further Justifications on Gaussian Mixture Model Classifier

One may notice that in \(\epsilon\)-GMMC (Sec. 4.2), the classifier is defined \(f_{t}(x)=\text{argmax}_{y\in\mathcal{Y}}\Pr(x|y;\theta_{t})\) (maximum likelihood estimation) while in general, \(f_{t}(x)=\text{argmax}_{y\in\mathcal{Y}}\Pr(y|x;\theta_{t})\) (maximum a posterior estimation), parameterized by a neural network. In this case, since the _equal prior_ (i.e., \(\Pr(y;\theta_{t})=\Pr(y^{\prime};\theta_{t}),\forall y,y^{\prime}\in\mathcal{C}\)) is enforced in \(\epsilon\)-GMMC, the two definitions are _equivalent_.

Proof.: Having:

\[\text{argmax}_{y\in\mathcal{Y}}\Pr(y|x;\theta_{t}) =\text{argmax}_{y\in\mathcal{Y}}\frac{\Pr(x|y;\theta_{t})\Pr(y; \theta_{t})}{\sum_{y^{\prime}\in\mathcal{Y}}\Pr(x|y^{\prime};\theta_{t})\Pr(y^ {\prime};\theta_{t})}\] \[=\text{argmax}_{y\in\mathcal{Y}}\Pr(x|y;\theta_{t}).\]

We conclude that the two definitions are equivalent. In fact, it is well-known that maximum likelihood estimation is a special case of maximum a posterior estimation when the prior is uniform.

Further Justifications on the Recurring Testing Scenario

### Recurring TTA Follows the Design of a Practical TTA Stream

Note that in recurring TTA, besides the recurrence of environments (or corruptions) as in [59, 40], the distribution of class labels is also temporally correlated (non-i.i.d.) as suggested by [15, 61] to reflect the practical testing stream better. In short, recurring TTA is formed by recurring the environments of _practical TTA_ scenario introduced in [61] multiple times (readers are encouraged to visit the original paper for additional motivations on this scenario).

### Recurring TTA as a Diagnostic Tool

Noticeably, CoTTA [59] also performed 10-round repetition across multiple domain shifts to simulate a lifelong TTA testing stream just like our recurring TTA. However, the key difference is CoTTA assumes the distribution of class labels is i.i.d., which does not hold in many real-life testing scenarios as argued in [15, 61]. Our recurring TTA lifts this assumption and allows temporally correlated (non-i.i.d.) label distribution (more challenging, more practical). This extension allows _recurring TTA_ to spot the risk of model collapse on CoTTA [59] and other methods. The _over-simplicity_ of the repeating scheme in CoTTA for spotting performance degradation is also suggested in [45]. Clearly, it seems not to be a problem at first glance in Tab. 5 of [59] (CoTTA's 10-round repetition), but in fact, the risk in CoTTA remains, as explored in our scenario and also on CCC [45].

The construction of our recurring TTA is notably simple - a technical effort to extend the testing stream. However, this simplicity is on purpose, _serving as a diagnostic tool for lifelong continual TTA_. Counterintuitively, our experiments on four different tasks with the latest methods verify that even if the model is exposed to the same environment _(the most basic case)_, their adaptability and performance are still consistently reduced (demonstrated visually in Fig. 1, quantitatively in Sec. 5.3).

We believe that the extensive testing stream by recurrence in our setup is a _simple yet sufficient scenario_ to demonstrate the vulnerability of existing continual TTA methods when facing the issue of model collapse (compared to CCC [45], a notably _more complicated scenario_ than our recurring TTA). Indeed, recurring shifts are sufficient to show this failure mode and any lifelong TTA method should necessarily be able to handle recurring conditions.

### Recurring TTA with Random Orders

Recall that in Sec. 3.1, _recurring TTA_ is constructed by repeating _the same_ sequence of \(D\) distributions \(K\) times. For example, a sequence with \(K=2\) could be \(\mathcal{P}_{1}\rightarrow\mathcal{P}_{2}\rightarrow\cdots\rightarrow \mathcal{P}_{D}\rightarrow\mathcal{P}_{1}\rightarrow\mathcal{P}_{2}\rightarrow \cdots\rightarrow\mathcal{P}_{D}\). For simplicity and consistency that promote reproducibility, the _same order of image corruptions_ (following [61]) is used for all recurrences. This section presents supplementary experimental findings indicating that _the order of image corruptions_ within each recurrence, indeed, _does not affect_ the demonstration of TTA model collapse and the performance of our PeTTA.

**Experiment Setup.** We refer to the setting _same-order_ as using one order of image corruptions in [61] for all recurrences (specifically, on CIFAR-10/100-C and ImageNet-C: _motion \(\rightarrow\) snow \(\rightarrow\) fog \(\rightarrow\) shot \(\rightarrow\) defocus \(\rightarrow\) contrast \(\to\) zoom \(\rightarrow\) brightness \(\rightarrow\) frost \(\rightarrow\) elastic \(\rightarrow\) glass \(\rightarrow\) gaussian \(\rightarrow\) pixelated \(\rightarrow\) jpeg \(\rightarrow\) impulse_). Conversely, in _random-order_, the order of image corruptions is randomly shuffled at the beginning of each recurrence. Hence, the corruption orders across \(K\) recurrences are now entirely different. We redo the experiment of the second setting three times (with different random seeds = \(0,1,2\)). Nevertheless, different TTA methods are ensured to be evaluated on the same testing stream, since it is fixed after generation. Without updating its parameters, the performance of the _source model_ is trivially independent of the order of corruptions.

**Experimental Result.** The experimental results are visualized in Fig. 6. The first column plots the experiments under the _same-order_, while the remaining three columns plot the experiments in the _random-order_ setting, with varying random seeds. Note that the message conveyed by each sub-figure entirely matches that of Fig. 1-right.

**Discussions.** Clearly, a similar collapsing pattern is observed in all three TTA tasks, with three combinations of 20 image corruption orders. This pattern also matches the easiest setting using the _same order_ of image corruptions we promoted in _recurring TTA_.

## Appendix E Further Justifications on Persistent TTA (PeTTA)

### Pseudo Code

We summarize the key steps of our proposed PeTTA in Alg. 1, with the key part (lines 4-13) highlighted in blue. Our approach fits well in the general workflow of a TTA algorithm, _enhancing the regular mean-teacher update step_. Appldx. E.5 elaborates more on our contributions in PeTTA, distinguishing them from other components proposed in previous work. The notations and definitions of all components follow the main text (described in detail in Sec. 4). On line 8 of Alg. 1, as a

Figure 6: Recurring TTA with different order of corruptions. This figure plots the testing error of two TTA approaches: RoTTA\(\blacklozenge\)[61], and, PeTTA\(\blacklozenge\)_(ours)_, and source model-\(\times\)- as a reference performance under our recurring TTA (with 20 visits) across three TTA tasks. On the _same-order_ experiments (column 1), the same order of image corruptions is applied for all 20 visits. Meanwhile, in _random-order_, this order is reshuffled at the beginning of each visit (columns 2-4). Random-order experiments are redone three times with different random seeds. Here, we empirically validate that using the same order of domain shifts (image corruptions) in our recurring TTA is sufficient to showcase the model collapse and evaluate the persistence of our PeTTA. Best viewed in color.

shorthand notation, \(\phi_{\theta_{t-1}}(X_{t}|\hat{Y}_{t}=y)\) denotes the empirical mean of all feature vectors of \(X_{t}^{(i)}\) (extracted by \(\phi_{\theta_{t-1}}\left(X_{t}^{(i)}\right)\)) if \(\hat{Y}_{t}^{(i)}=y,i=1,\cdots,N_{t}\) in the current testing batch.

### Anchor Loss

**KL Divergence Minimization-based Interpretation of Anchor Loss**. In Sec. 4, we claimed that minimizing the anchor loss \(\mathcal{L}_{\mathrm{AL}}\) is equivalent to minimizing the relative entropy (or KL divergence) between the output probability of two models parameterized by \(\theta_{0}\) and \(\theta\).

Proof.: Having:

\[D_{KL}\left(\Pr(y|X_{t};\theta_{0})||\Pr(y|X_{t};\theta)\right) =\sum_{y\in\mathcal{Y}}\Pr(y|X_{t};\theta_{0})\log\frac{\Pr(y|X_{t };\theta_{0})}{\Pr(y|X_{t};\theta)}\] \[=\underbrace{-\sum_{y\in\mathcal{Y}}\Pr(y|X_{t};\theta_{0})\log \Pr(y|X_{t};\theta)}_{\mathcal{L}_{\mathrm{AL}}(X_{t},\theta)}-\underbrace{H (\Pr(y|X_{t};\theta_{0}))}_{\text{constant}}.\]

Hence,

\[\underset{\theta\in\Theta}{\text{argmin}}\;\mathcal{L}_{\mathrm{AL}}(X_{t}; \theta)=\underset{\theta\in\Theta}{\text{argmin}}\;D_{KL}\left(\Pr(y|X_{t}; \theta_{0})||\Pr(y|X_{t};\theta)\right).\]Intuitively, a desirable TTA solution should be able to adapt to novel testing distributions on the one hand, but it should _not_ significantly diverge from the initial model. \(\mathcal{L}_{\mathrm{AL}}\) fits this purpose, constraining the KL divergence between two models at each step.

**Connections between Anchor Loss and Regularizer Term.** While supporting the same objective (collapse prevention by avoiding the model significantly diverging from the source model), the major difference between Anchor loss (\(\mathcal{L}_{\mathrm{AL}}\)) and the Regularizer term (\(\mathcal{R}(\theta)\)) is that the anchor loss operates on the probability space of model prediction while the regularizer term works on the model parameter spaces. Tab. 4 (lines 1 and 5) summarizes the ablation study when each of them is eliminated. We see the role of the regularization term is crucial for avoiding model collapse, while the anchor loss guides the adaptation under the drastic domain shift. Nevertheless, fully utilizing all components is suggested for maintaining TTA persistence.

### The Use of the Memory Bank

**The size of Memory Bank.** The size of the memory bank in PeTTA is _relatively small, equal to the size of one mini-batch for update_ (64 images, specifically).

**The Use of the Memory Bank in PeTTA is Fair with Respect To the Compared Methods.** Our directly comparable method - RoTTA [61] also takes this advantage (referred to as category-balanced sampling, Sec. 3.2 of [61]). Hence, the comparison between PeTTA and RoTTA _is fair_ in terms of additional memory usage. Noteworthy, the use of a memory bank is a _common practice_ in TTA literature (e.g., [15; 8; 61]), especially in situations where the class labels are temporally correlated or non-i.i.d. distributed (as we briefly summarized in Appdx. A - Related Work section). CoTTA [59], EATA [40] and MECTA [22] (compared method) assume labels are i.i.d. distributed. Hence, a memory bank is unnecessary, but their performance under temporally correlated label distribution has dropped significantly as a trade-off. The RMT [12] (compared method) does not require a memory bank but it needs to cache a portion of the source training set for replaying (Sec. 3.3 in [12]) which even requires _more_ resources than the memory bank.

**Eliminating the Need for a Memory Bank.** As addressing the challenge of temporally correlated label distribution on the testing stream is not the focus of PeTTA, we have conveniently adopted the use of the memory bank proposed in [61]. Since this small additional memory requirement is not universally applied in every real-world scenario, we believe that this is a reasonable assumption, and commonly adopted in TTA practices. Nevertheless, exploring alternative ways for reducing the memory size (e.g., storing the embedded features instead of the original image) would be an interesting future direction.

### Empirical Mean and Covariant Matrix of Feature Vectors on the Source Dataset

**Two Ways of Computing \(\mu_{0}^{y}\) and \(\Sigma_{0}^{y}\) in Practice.** One may notice that in PeTTA, computing \(\gamma_{t}^{y}\) requires the _pre-computed empirical mean_ (\(\mu_{0}^{y}\)) _and covariance (\(\Sigma_{0}^{y}\)) of the source dataset_. This requirement may not be met in real-world situations where the source data is unavailable. In practice, the empirical mean and covariance matrix computed on the source distribution can be provided in the following two ways:

1. Most ideally, these values are computed directly by inference on the entire training set once the model is fully trained. They will be provided alongside the source-distribution pre-trained model as a pair for running TTA.
2. With only the source pre-trained model available, assume we can sample a set of unlabeled data from the source distribution. The (pseudo) labels for them are obtained by inferring from the source model. Since the source model is well-performed in this case, using pseudo is approximately as good as the true label.

**Accessing the Source Distribution Assumption in TTA.** In fact, the second way is typically assumed to be possible in previous TTA methods such as EATA [40], and MECTA [22] (a compared method) to estimate a Fisher matrix (for anti-forgetting regularization purposes). Our work - PeTTA _follows the same second setup_ as the previous approaches mentioned above. A variation of RMT [12] (a compared method) approach even requires having the fully labeled source data available at test-time for source replaying (Sec. 3.3 of [12]). This variation is used for comparison in our experiments.

We believe that having the empirical mean and covariant matrix pre-computed on a portion of the source distribution in PeTTA _is a reasonable assumption_. Even in the ideal way, revealing the statistics might not severely violate the risk of data privacy leakage or require notable additional computing resources.

**Number of Samples Needed for Computation.** To elaborate more on the feasibility of setting (2) mentioned above, we perform a small additional experiment on the performance of PeTTA while varying the number of samples used for computing the empirical mean and covariant matrix on the source distribution. In this setting, we use the test set of CIFAR-10, CIFAR-100, DomainNet validation set of ImageNet (original images, without corruption, or the _real_ domain test set of DomainNet), representing samples from the source distribution. The total number of images is \(10,000\) in CIFAR-10/A00, \(50,000\) in ImageNet, and \(69,622\) in DomainNet. We randomly sample \(25\%,50\%,75\%\), and \(100\%\) of the images in this set to run PeTTA for 20 rounds of recurring. The result is provided in Tab. 6 below.

The default choice of PeTTA is using \(100\%\) samples of the validation set of the source dataset. However, we showcase that it is possible to reduce the number of unlabeled samples from the source distribution to compute the empirical mean and covariant matrix for PeTTA, without significantly impacting its performance.

### Novelty of PeTTA

PeTTA is composed of multiple components. Among them, the anchor loss is an existing idea (examples of previous work utilizing this idea are [32, 12]). Similarly, the mean-teacher update; and regularization are well-established techniques and very useful for the continual or gradual TTA scenario. Hence, we do not aim to improve or alternate these components.

Nevertheless, the novelty of our contribution is the _sensing of the divergence and adaptive model update_, in which the importance of minimizing the loss (adaptation) and regularization (collapse prevention) is changed adaptively. In short, we propose a harmonic way of combining those elements adaptively to achieve a persistent TTA process.

The design of PeTTA draws inspiration from a theoretical analysis (Sec. 3.2), empirically surpassing both the conventional reset-based approach [45] (Apdx. F.3) and other continual TTA approaches [61, 12, 59, 22, 7] on our proposed recurring TTA (Sec. 3.1, Appdx. F.1), as well as the previously established CCC [45] benchmark.

## Appendix F Additional Experimental Results of PeTTA

### Performance of PeTTA Versus Compared Methods

**Performance on CIFAR-100-C and Domainnet Datasets.** Due to the length constraint, the classification errors on the tasks CIFAR-100\(\rightarrow\)CIFAR-100-C, and _real_\(\rightarrow\)_cipart, painting, sketch_ of DomainNet are provided in Tab. 7 and Tab. 8. To prevent model collapse, the adaptability of PeTTA is more constrained. As a result, it requires more time for adaptation initially (e.g., in the first visit) but remains stable thereafter. Generally, consistent trends and observations are identified across all four TTA tasks.

**Standard Deviation of PeTTA Performance Across Multiple Runs.** For PeTTA experiments marked with (*) in Tab. 1, Tab. 2, Tab. 7, and Tab. 8, the average performance across five independent runs with different random seeds is reported. Due to the space constraint, the corresponding standard deviation values are now reported in Tab. 9. Generally, the average standard deviation across runs

\begin{table}
\begin{tabular}{c|c c c|c} \hline
**TTA Task** & **25\%** & **50\%** & **75\%** & **100\%** \\ \hline CIFAR-10 \(\rightarrow\) CIFAR-10-C & 22.96 & 22.99 & 23.03 & 22.75 \\ CIFAR-100 \(\rightarrow\) CIFAR-100-C & 35.01 & 35.11 & 35.09 & 35.15 \\ DomainNet: _real_\(\rightarrow\)_clip_\(\rightarrow\)_paint_\(\rightarrow\)_sketch_ & 43.18 & 43.12 & 43.15 & 42.89 \\ ImageNet \(\rightarrow\) ImageNet-C & 61.37 & 59.68 & 61.05 & 60.46 \\ \hline \end{tabular}
\end{table}
Table 6: Average classification error of PeTTA (across 20 visits) with varying sizes of source samples used for computing feature empirical mean (\(\mu_{0}^{y}\)) and covariant matrix (\(\Sigma_{0}^{y}\)).

stays within \(\pm 0.1\%\) for small datasets (CIFAR-10-C, CIFAR-100-C) and \(\pm 0.5\%\) for larger datasets (ImageNet-C, DomainNet).

### An Inspection of PeTTA

In Fig. 7, we showcase an inspection of our PeTTA on the task CIFAR-10 \(\rightarrow\) CIFAR-10-C [19] in a typical recurring TTA with 20 visits. Specifically, the visualizations of PeTTA parameters (\(\bar{\gamma}_{t}\), \(\lambda_{t}\), and \(\alpha_{t}\)), adaptation losses (\(\mathcal{L}_{\mathrm{CLS}}\), \(\mathcal{L}_{\mathrm{AL}}\)) and regularization term (\(\mathcal{R}(\theta)\)) are provided. Here, we observe the values of adaptive parameters \(\lambda_{t}\) and \(\alpha_{t}\) continuously changing through time, as the testing scenarios evolve during recurring TTA. This proposed mechanism _stabilizes_ the value of the loss functions, and regularization term, balancing between the two primary objectives: adaptation and preventing model collapse. Thus, _the error rate persists_ as a result. A similar pattern is observed on other datasets (CIFAR-100-C [19] and DomainNet [44]).

### Does Model Reset Help?

**Experiment Setup.** We use the term _"model reset"_ to represent the action of _"reverting the current TTA model to the source model"_. This straightforward approach is named RDumb [45]. We thoroughly conducted experiments to compare the performance of RDumb with PeTTA. The implementation of RDumb in this setting is as follows. We employ RoTTA [61] as the base test-time adaptor due to the characteristics of the practical TTA [61] stream. The model _(including model

\begin{table}
\begin{tabular}{c|c c c c c c c c c c c c c c c c c c c c c} \hline \hline \multicolumn{11}{c}{_Recurring TTA visit_} \\ \cline{2-11} \multicolumn{11}{c}{**Method**} & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 & 16 & 17 & 18 & 19 & 20 & **Avg** \\ \hline \multicolumn{11}{c}{_Source_} \\ \hline \multicolumn{11}{c}{_Source_} \\ \hline \multicolumn{11}{c}{_LAME_} \\ \hline \multicolumn{11}{c}{_} & 40.5 & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \\ \hline CIFAR [59] & 53.4 & 58.4 & 63.4 & 67.6 & 71.4 & 74.9 & 78.2 & 81.1 & 84.0 & 66.7 & 88.8 & 99.7 & 92.3 & 93.5 & 94.7 & 95.6 & 96.3 & 97.0 & 97.3 & 97.6 & 83.1 \\ \multicolumn{11}{c}{_READ_} & 28.5 & 95.0 & 66.8 & 97.3 & 97.4 & 97.2 & 97.2 & 97.3 & 97.4 & 97.5 & 97.5 & 97.6 & 97.6 & 97.7 & 97.7 & 97.7 & 97.8 & 97.7 & 97.7 & 96.0 \\ \multicolumn{11}{c}{_BLOT_} & 29.5 & 95.3 & 46.8 & 47.9 & 47.3 & 47.1 & 46.3 & 46.9 & 46.8 & 46.5 & 46.5 & 46.6 & 46.5 & 46.5 & 46.5 & 46.5 & 46.5 & 47.5 & 47.2 \\ \multicolumn{11}{c}{_MER_} & 31.8 & 44.8 & 44.9 & 47.1 & 44.3 & 44.3 & 44.3 & 44.3 & 44.8 & 48.0 & 48.8 & 43.8 & 44.6 & 44.9 & 44.9 & 44.9 & 44.3 & 44.9 & 44.9 & 44.2 \\ \multicolumn{11}{c}{_ROTTA_} & 28.5 & 35.2 & 38.5 & 41.9 & 48.3 & 49.2 & 84.5 & 35.2 & 38.1 & 83.3 & 64.6 & 47.3 & 70.7 & 78.2 & 78.5 & 78.1 & 79.2 & 84.5 & 82.8 & 84.5 & 81.4 \\ \multicolumn{11}{c}{_RODN_} & 36.7 & 36.7 & 36.6 & 36.7 & 36.8 & 36.3 & 36.5 & 36.6 & 36.6 & 36.5 & 36.7 & 36.6 & 36.7 & 36.6 & 36.6 & 36.7 & 36.6 & 36.6 & 36.7 & 36.6 & 36.7 & 36.6 \\ \multicolumn{11}{c}{_ROTTB_} & 27.8 & 36.3 & 36.2 & 36.9 & 36.1 & 75.1 & 10.7 & 29.1 & 10.7 & 10.7 & 26.3 & 10.8 & 36.7 & 36.6 & 36.7 & 36.6 & 36.6 & 36.6 & 36.7 & 36.6 & 36.7 & 36.9 & 36.9 & 36.9 \\ \multicolumn{11}{c}{_TRDB_} & 27.8 & **36.3** & 35.3 & **34.9** & 35.3 & **35.1** & 37.1 & 37.2 & 37.1 & 39.1 & 42.1 & 41.0 & 43.1 & 45.1 & 45.1 & 45.0 & 44.9 & 44.9 & 44.9 & 44.9 & 44.9 & 39.6 \\ \multicolumn{11}{c}{_PETTA (Longo)_} & **35.8** & **34.4** & **34.7** & **36.0** & **38.1** & **35.1** & **36.2** & **35.3** & **35.3** & **35.2** & **35.3** & **36.2** & **36.3** & **36.1** & **38.2** & **36.1** & **38.2** & **36.2** & **36.2** & **36.2** & **36.2** & **36.1** \\ \hline \hline \end{tabular}
\end{table}
Table 7: Average classification error of the task CIFAR-100 \(\rightarrow\) CIFAR-100-C in _recurring TTA_ scenario. The lowest error is highlighted in **bold**, (\({}^{*}\))average value across 5 runs (different random seeds) is reported for PeTTA.

\begin{table}
\begin{tabular}{c|c c c c c c c c c c c c c c c c c c c c c c c} \hline \hline \multicolumn{11}{c}{_Method_} & \multicolumn{1}{c}{_Epistrict TTA visit_} \\ \cline{2-11} \multicolumn{11}{c}{**Method**} & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 & 16 & 17 & 18 & 19 & 20 & **Avg** \\ \hline \multicolumn{11}{c}{_Source_} \\ \hline \multicolumn{11}{c}{_LAME_} \\ \hline \multicolumn{11}{c}{_CoPTA_} \\ \hline \multicolumn{11}{c}{_CAI_} \\ \hline \multicolumn{parameters, the optimizer state, and the memory bank)_ is reset after adapting itself to \(T\) images.1 For each dataset, three values of this hyper-parameter \(T\) are selected:

Footnote 1: A slight abuse of notation. \(T\) here is the number of images between two consecutive resets, following the notation on Sec. 3 of [45], _not_ the sample indices in our notations.

* \(T=1,000\): This is the value selected by the RDumb's authors [45]. Unless specifically stated, we use this value when reporting the performance of RDumb [45] in all other tables.
* \(T=10,000\) (CIFAR-10/100-C), \(T=5,000\) (ImageNet-C) and \(T=24,237\) (DomainNet).2 This value is equal to the number of samples in the test set of a _single corruption type_, i.e., the model is reset exactly after visiting each \(\mathcal{P}_{i}\)'s (see Sec. 3.1 for notations). For DomainNet [44], since the number of images within each domain is unequal, the average number of images is used instead. Footnote 2: A subset of \(5,000\) samples from ImageNet-C are selected following RobustBench [10] for a consistent evaluation with other benchmarks.
* types of corruptions [19] for CIFAR-10/100-C and ImageNet-C and \(D=3\) for DomainNet (_clipart, painting, sketch_). For example, the model is reset 20 times within a _recurring TTA_ setting with 20 recurrences under this choice of \(T\).

The second and the last reset scheme could be interpreted as assuming the model has access to _an oracle model_ with a capability of signaling the transitions between domains, or recurrences. Typically, this is _an unrealistic capability in real-world scenarios_, and a desirable continual TTA algorithm should be able to operate independently without knowing when the domain shift happening.

**Experimental Results.** An empirical comparison between RDumb [45] and our PeTTA are reported in Tab. 10, Tab. 11, Tab. 12 and Tab. 13 for all four tasks.

**Discussions.** Across datasets and reset frequencies, our PeTTA approach is always _better_ than RDumb [45]. The supreme performance holds even when RDumb has access to the oracle information that can reset the model exactly at the transition between each domain shift or recurrence. Importantly, this oracle information is typically unavailable in practice.

\begin{table}
\begin{tabular}{c|c c c c c c c c c c c c c c c c c c c c c c c} \hline \hline  & \multicolumn{4}{c}{_Recurring TTA unit_} & \multicolumn{11}{c}{} \\
**Reset Every** & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 & 16 & 17 & 18 & 19 & 20 & **Avg** \\ \hline \(T=1000\) & 36.7 & 36.7 & 36.6 & 36.6 & 36.7 & 36.8 & 36.7 & 36.5 & 36.6 & 36.5 & 36.7 & 36.6 & 36.5 & 36.6 & 36.6 & 36.7 & 36.6 & 36.5 & 36.6 \\ \(T=1000\) & 43.5 & 46.6 & 43.7 & 43.4 & 45.5 & 43.6 & 43.4 & 43.5 & 43.6 & 43.8 & 43.5 & 43.5 & 43.6 & 43.4 & 43.6 & 43.5 & 43.8 & 43.7 & 43.6 & 43.6 \\ \(T=1000\) & **36.4** & 35.4 & 35.4 & 35.3 & 35.4 & 35.5 & 35.6 & 35.4 & 35.5 & 35.3 & **35.2** & 35.4 & **35.1** & 35.8 & **35.1** & 35.6 & 35.3 & 35.8 & 35.4 \\ \hline
**PUTA**(_four_)1 & 35.8 & **34.4** & **34.7** & **35.0** & **35.1** & **35.1** & **35.2** & **35.3** & **35.3** & **35.3** & **35.2** & **35.3** & **35.2** & **35.1** & **35.2** & **35.2** & **35.2** & **35.2** & **35.2** & **35.2** & **35.1** \\ \hline \hline \end{tabular}
\end{table}
Table 11: Average classification error comparison between RDumb [45] (a reset-based approach) with different reset frequencies and our PeTTA on CIFAR-100-C dataset.

\begin{table}
\begin{tabular}{c|c c c c c c c c c c c c c c c c c c c c c} \hline \hline  & \multicolumn{4}{c}{_Recurring TTA unit_} & \multicolumn{11}{c}{} \\
**Reset Every** & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 & 16 & 17 & 18 & 19 & 20 & **Avg** \\ \hline \(T=1000\) & 36.7 & 36.7 & 36.6 & 36.6 & 36.7 & 36.8 & 36.7 & 36.5 & 36.6 & 36.6 & 36.7 & 36.6 & 36.5 & 36.7 & 36.5 & 36.6 & 36.6 & 36.7 & 36.6 & 36.5 & 36.6 \\ \(T=1000\) & 43.5 & 46.6 & 43.7 & 43.7 & 43.4 & 43.5 & 43.6 & 43.4 & 43.5 & 43.6 & 43.8 & 43.5 & 43.5 & 43.6 & 43.4 & 43.6 & 43.5 & 43.8 & 43.7 & 43.6 & 43.6 \\ \(T=10000\) & **36.4** & 35.4 & 35.4 & 35.4 & 35.3 & 35.4 & 35.5 & 35.6 & 35.4 & 35.5 & **35.3** & **35.2** & **35.4** & **35.1** & **35.8** & **35.1** & 35.6 & 35.3 & 35.8 & 35.4 \\ \hline
**PUTA**(_four_)2 & 35.8 & **34.4** & **34.7** & **35.0** & **35.1** & **35.1** & **35.2** & **35.3** & **35.3** & **35.3** & **35.2** & **35.3** & **35.2** & **35.1** & **35.2** & **35.1** & **35.2** & **35.2** & **35.2** & **35.2** & **35.2** & **35.2** & **35.1** \\ \hline \hline \end{tabular}
\end{table}
Table 12: Average classification error comparison between RDumb [45] (a reset-based approach) with different reset frequencies and our PeTTA on DomainNet dataset.

\begin{table}
\begin{tabular}{c|c c c c c c c c c c c c c c c c c c c c c} \hline \hline  & \multicolumn{4}{c}{_Recurring TTA unit_} & \multicolumn{11}{c}{} \\
**Reset Every** & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 & 16 & 17 & 18 & 19 & 20 & **Avg** \\ \hline \(T=1000\) & 44.3 & 44.4 & 44.3 & 44.5 & 44.2 & 44.2 & 44.3 & 44.5 & 44.4 & 44.2 & 44.3 & 44.3 & 44.3 & 44.3 & 44.5 & 44.3 & 44.5 & 44.3 & 44.2 & 44.3 & 44.4 & 44.3 \\ \(T=21272\) & 44.1 & 44.3 & 45.9 & 44.2 & 44.1 & 44.3 & 44.2 & 44.4 & 44.1 & 44.1 & 44.0 & 44.3 & 44.1 & 44.0 & 44.2 & 44.1 & 44.1 & 44.1 & 44.1 & 44.1 & 44.1 \\ \(T=271272\) & 44.3 & 44.3 & 44.0 & 44.3 & 44.1 & 44.2 & 44.4 & 44.2 & 44.1 & 44.0 & 44.1 & 44.2 & 44.1 & 44.1 & 44.1 & 44.1 & 44.0 & 44.3 & 44.2 \\ \hline
**PUTA**(_four_)2 & **43.8** & **42.6** & **42.3** & **42.6** & **42.8** & **42.8** & **42.8** & **42.8** & **42.9** & **42.9** & **43.1** & **43.0** & **42.9** & **43.0** & **43.1** & **43.0** & **42.8** & **42.9** & **42.9** & **42.9** \\ \hline \hline \end{tabular}
\end{table}
Table

[MISSING_PAGE_FAIL:27]

[MISSING_PAGE_FAIL:28]

[MISSING_PAGE_FAIL:29]

### The Use of Existing Assets

Many components of PeTTA is utilized from the official repository of RoTTA [61]5 and RMT [12]. 6 These two assets are released under MIT license. All the datasets, including CIFAR-10-C, CIFAR-100-C and ImageNet-C [19] are publicly available online, released under Apache-2.0 license.7 DomainNet dataset [44] (cleaned version) is also released for research purposes.8

Footnote 5: https://github.com/BIT-DA/RoTTA

Footnote 6: https://github.com/mariodebler/test-time-adaptation

Footnote 7: https://github.com/hendrycks/robustness

Footnote 8: https://ai.bu.edu/M3SDA/Figure 7: An inspection of PeTTA on the task CIFAR-10 \(\rightarrow\) CIFAR-10-C [19] in a recurring with 20 visits (visits are separated by the _vertical dashed lines_). Here, we visualize (rows 1-3) the dynamic of PeTTA adaptive parameters \((\bar{\gamma}_{t},\lambda_{t},\alpha_{t})\), (rows 4-5) the value of the \(\mathrm{loss\ functions}\) (\(\mathcal{L}_{\mathrm{CLS}},\mathcal{L}_{\mathrm{AL}}\)) and (row 6) the value of the \(\mathrm{regularization\ term}\) (\(\mathcal{R}(\theta)\)) and (row 7) the classification error rate at each step. The **solid line** in the foreground of each plot denotes the running mean. The plots show an adaptive change of \(\lambda_{t},\alpha_{t}\) through time in PeTTA, which stabilizes TTA performance, making PeTTA achieve a persisting adaptation process in all observed values across 20 visits.

\begin{table}
\begin{tabular}{c|c|c|c} \hline \hline
**Total Visits** & **CF-10-C** & **CF-100-C** & **IN-C** \\ \hline
20 visits & 22.8 & 35.1 & 60.5 \\
40 visits & 22.9 & 35.1 & 61.0 \\ \hline \hline \end{tabular}
\end{table}
Table 14: Average testing error of PeTTA in recurring TTA with 20 and 40 visits. PeTTA demonstrates its persistence over an extended testing time horizon beyond the 20\({}^{th}\) visit milestone (Fig. 8’s horizontal dashed line).

Figure 8: Testing error of PeTTA with 40 recurring TTA visits.

Figure 9: An inspection on the ablation study of multiple variations of PeTTA on the task CIFAR-100 \(\rightarrow\) CIFAR-100-C [19] in an episodic TTA with 20 visits (visits are separated by the vertical dashed lines). **(top)**: testing error of multiple variations of PeTTA. The performance of PeTTA without (w/o) \(\mathcal{R}(\theta)\), or fixed regularization coefficient (\(\lambda=\lambda_{0}/0.1\lambda_{0}\)) degrades through time (the top 3 lines). The degradation of PeTTA \(\rightarrow\)\(\lambda_{t}\) is still happening but at a slower rate (justification below). The performance of the other three variations persists through time with PeTTA -\(\lambda_{t}+\alpha_{t}+\mathcal{L}_{\text{AL}}\) achieves the best performance. **(bottom)**: changes of \(\gamma_{t}\) in multiple variations of PeTTA. When limiting the degree of freedom in adjusting \(\alpha_{t}\) or lacking of supervision from \(\mathcal{L}_{\text{AL}}\) (e.g., PeTTA -\(\lambda_{t}+\alpha_{t}\), PeTTA -\(\lambda_{t}+\mathcal{L}_{\text{AL}}\), and especially PeTTA -\(\lambda_{t}\)), the value of \(\gamma_{t}\), unfortunately, escalates and eventually saturated. After this point, PeTTA has the same effect as using a fixed regularization coefficient. Therefore, fully utilizing all components is necessary to preserve the persistence of PeTTA. Best viewed in color.

Figure 10: The dynamic of the confusion matrix of RoTTA [61] in episodic TTA with 20 visits.

Figure 11: The dynamic of the confusion matrix of PeTTA (_ours_) in episodic TTA with 20 visits.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: We have highlighted the three main claims and contributions of our work in both the abstract (highlighted in bold font) and the introduction section (listed as bullet points). Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: We have discussed the limitations and potential future work of our study in Sec. 6. Specifically, three main limitations are included: (1) Collapse prevention can not be guaranteed through regularization, PeTTA requires (2) the use of a relatively small memory bank is available and (3) the empirical mean and covariant matrix of feature vectors on the source dataset is computable. We also include discussions in Appdx. E.3 and Appdx. E.4 to further elaborate (2), and (3) respectively. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.

3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: We have provided the full proof of all lemmas and theorem in Appdx. B. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: This study propose a new TTA approach - PeTTA. A full description of this approach is given in Sec. 4 with its pseudo-code provided in Appdx. E.1. The implementation of PeTTA in Python is also attached as supplemental material. Additionally, Sec. 5.2 and Appdx. G are dedicated to providing further implementation details for reproducing the main experimental results. Lastly, the construction of recurring TTA is notably simple, and can be easily extended to other TTA streams. Its configuration on each tasks is described in the Recurring TTA paragraph of Sec. 5.2. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset).

* We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
* **Open access to data and code*
* Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: This study does not involve any private datasets. All datasets used in our experiments are publicly available online from previous works (more information in Appdx. G.4). The source code of PeTTA is also attached as supplemental material. Guidelines:
* The answer NA means that paper does not include experiments requiring code.
* Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
* Benchmark Datasets). In the supplementary material, any _additional_ experimental results beyond the main paper, such as those in Appdx. D.3, and Appdx. F.3, are consistently preceded by a subsection titled _Experiment Setup_ summarizing the experimental details before presenting the results. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
* **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments?Answer: [Yes] Justification: Due to the limited computing resources, we only extensively evaluate the performance of our proposed method _(PeTTA)_ across 5 independent runs, with different random seeds. Specifically, the mean values in 5 runs are reported in Tab. 1, Tab. 2, Tab. 7, and Tab. 8. The corresponding standard deviation values are provided in Appdx. F.1. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors). * It should be clear whether the error bar is the standard deviation or the standard error of the mean. * It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified. * For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). * If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: We have provided the information on the computing resources used in our experiments in Appdx. G.1. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: The authors have reviewed and to the best of our judgment, this study has performed to the NeurIPS Code of Ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.

* The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [No] Justification: This study advances the research in test-time adaptation area in general, and not tied to particular applications. Hence, there are no significant potential societal consequences of our work which we feel must be specifically highlighted here. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. * If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: To the best of our judgment, this study poses no risks for misuse. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected?Answer: [Yes] Justification: The original papers that produced the code package or dataset have been properly cited throughout the paper. Further information on the licenses of used assets are provided in Appdx. G.4. Guidelines:

* The answer NA means that the paper does not use existing assets.
* The authors should cite the original paper that produced the code package or dataset.
* The authors should state which version of the asset is used and, if possible, include a URL.
* The name of the license (e.g., CC-BY 4.0) should be included for each asset.
* For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.
* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.

13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: This study does not release new assets. Guidelines:

* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.

14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: This study does not involve crowdsourcing nor research with human subjects. Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.

15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects**Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained?

Answer: [NA]

Justification: This study does not involve crowdsourcing nor research with human subjects. Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.