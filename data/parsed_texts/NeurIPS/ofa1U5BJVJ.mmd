# Online (Multinomial) Logistic Bandit:

Improved Regret and Constant Computation Cost

 Yu-Jie Zhang\({}^{1}\) Masashi Sugiyama\({}^{2,1}\)

\({}^{1}\) The University of Tokyo, Chiba, Japan

\({}^{2}\) RIKEN AIP, Tokyo, Japan

###### Abstract

This paper investigates the logistic bandit problem, a variant of the generalized linear bandit model that utilizes a logistic model to depict the feedback from an action. While most existing research focuses on the binary logistic bandit problem, the multinomial case, which considers more than two possible feedback values, offers increased practical relevance and adaptability for use in complex decision-making problems such as reinforcement learning. In this paper, we provide an algorithm that enjoys both statistical and computational efficiency for the logistic bandit problem. In the binary case, our method improves the state-of-the-art binary logistic bandit method by reducing the per-round computation cost from \(\mathcal{O}(\log T)\) to \(\mathcal{O}(1)\) with respect to the time horizon \(T\), while still preserving the minimax optimal guarantee up to logarithmic factors. In the multinomial case, with \(K+1\) potential feedback values, our algorithm achieves an \(\widetilde{\mathcal{O}}(K\sqrt{T})\) regret bound with \(\mathcal{O}(1)\) computational cost per round. The result not only improves the \(\widetilde{\mathcal{O}}(K\sqrt{\kappa T})\) bound for the best-known tractable algorithm--where the large constant \(\kappa\) increases exponentially with the diameter of the parameter domain--but also reduces the \(\mathcal{O}(T)\) computational complexity demanded by the previous method.

## 1 Introduction

The stochastic linear bandit (SLB) [1; 2; 3] problem is a natural generalization of the classic stochastic multi-armed bandit problem [4] by incorporating side information into the decision-making process. In the SLB problem, a linear model is used to characterize the relationship between the reward \(r_{t}\in\mathbb{R}\) and the learner's action \(\mathbf{x}_{t}\in\mathcal{X}\subseteq\mathbb{R}^{d}\), whereas such an assumption is not always satisfied in real-world applications. Consequently, various models have been developed to account for the non-linear reward, including the generalized linear bandit (GLB) model [5] and kernelized bandit model [6]. The logistic bandit is a specific kind of GLB model by connecting the learner's \(d\)-dimensional action and the reward with a logistic model. Most existing work focuses on the binary case [7; 8; 9; 10]. The reward \(r_{t}\in\{0,1\}\) exhibits a binary value and the probability is modeled by \(\text{Pr}[r_{t}=1\mid\mathbf{x}_{t}]=\sigma(\mathbf{w}_{*}^{\top}\mathbf{x}_ {t})\), where \(\sigma(z)=1/(1+\exp(-z))\) is a non-linear link function and \(\mathbf{w}_{*}\in\mathcal{W}\subseteq\mathbb{R}^{d}\) is an unknown parameter. Compared to the SLB model, the logistic bandit model provides a more precise representation for a wide range of real-world application problems, where feedback exhibits discrete behavior. Moreover, from a theoretical perspective, it also serves as a basic setting for understanding the impact of non-linearity of the reward on the decision-making process. In this paper, we investigate a more general _multinomial logistic bandit_ (MLogB) problem [11], in which the learner's action \(\mathbf{x}_{t}\) results in feedback \(y_{t}\) that could have \(K+1\) possible outcome values. The probability of each outcome is characterized with a logistic model (the formal definition is provided in Section 2.1). The MLogB model is of more practical interest compared to the binary case. For example, in the real-world application such as online advertising, there could be multiple possible feedback from customers, including "buy now", "add to cart", "view related item", andjust leave without any click. Beyond addressing practical demands, studying the MLogB problem can shed light on other decision-making problems. For instance, in the theoretical reinforcement learning research [12; 13], the transition matrix is approximated using a linear model, which enables the application of the SLB method for balancing the exploration-exploitation trade-off. Since the transition matrix is inherently a probability matrix, the multinomial logistic model may be a more suitable structure for modeling transition probabilities between states.

As shown in Table 1, the logistic bandit problem has received much attention in the binary case. There are two main focuses arising from the non-linearity of the reward function: _statistical efficiency_ and _resource overhead_. Regarding the statistical efficiency, a main focus is the algorithms' dependence on \(\kappa=\max_{\mathbf{x}\in\mathcal{X},\mathbf{w}\in\mathcal{W}}1/\sigma^{ \prime}(\mathbf{w}^{\top}\mathbf{x})\), a crucial parameter capturing the non-linearity of the reward function. Since the binary logistic bandit is a special case of the generalized linear model, the result from [5] implies an \(\widetilde{\mathcal{O}}(\kappa\sqrt{T})\) bound. However, the parameter \(\kappa\) grows exponentially in terms of the diameter of the decision domain \(\mathcal{W}\) and action space \(\mathcal{X}\), making the linear dependence unfavorable. A pivotal advancement is made by [9], where the paper presents an algorithm that achieves the nearly minimax optimal bound \(\widetilde{\mathcal{O}}(\sqrt{T/\kappa_{*}})\). Here, \(\kappa_{*}=1/\sigma^{\prime}(\mathbf{w}^{\top}_{*}\mathbf{x}_{*})\) is the non-linear parameter associated with the best action \(\mathbf{x}_{*}=\arg\max_{\mathbf{x}\in\mathcal{X}}\sigma(\mathbf{w}^{\top}_{ *}\mathbf{x})\), suggesting that non-linearity might be advantageous for statistical efficiency, rather than a hindrance. Alongside statistical efficiency considerations, the non-linearity of the feedback raises concerns about the algorithms' computation and storage efficiency. The methods [8; 9] with improved dependence on \(\kappa\) usually require storing and optimizing over all historical data to estimate the unknown parameter, leading to an \(\mathcal{O}(t)\) computation and storage cost at round \(t\in[T]\). The pioneering work [7] provided the first efficient solution for binary logistic bandit with constant computation and storage costs and [14] further proposed an efficient algorithm for generalized linear bandit, but their regret bounds still exhibit a linear dependence on \(\kappa\). Recently, a jointly efficient algorithm was proposed by [10], which achieves the optimal dependence on \(\kappa\) with a \(\mathcal{O}(\log t)\) computation cost and constant storage cost per round. However, it remains open whether the minimax optimal bound is achievable with constant computation cost independent of the time \(t\).

Regrading the multinomial logistic bandit, the best-known feasible algorithm was proposed by [11]. This method achieves an \(\widetilde{\mathcal{O}}(K\sqrt{\kappa T})\) regret bound, bearing an \(\mathcal{O}(\sqrt{\kappa})\) dependence on the exponentially large constant. Moreover, it still demands \(\mathcal{O}(t)\) computation and storage costs to optimize over all past data. The same study also introduced an \(\widetilde{\mathcal{O}}(K^{3/2}\sqrt{T})\) bound with improved dependence on \(\kappa\). Yet, this solution leans heavily towards theoretical insights and is intractable in implementation [11; Section 2.6]. Designing a practical or more efficient algorithm with improved dependence on \(\kappa\) is still an unsolved challenge. More discussions on the related work and topics can be found in Section 4.

**Our Results**. In this paper, we provide an algorithm with both statistical and computational efficiency.

* For the multinomial logistic bandit, we propose OFUL-MLogB, a jointly efficient method attaining an \(\widetilde{\mathcal{O}}(K\sqrt{T})\) regret bound with \(\mathcal{O}(1)\) in \(T\) computation and storage cost per round. The result improves the previous work on the dependence of the large constant \(\kappa\).
* For the binary case, our proposed OFUL-MLogB can achieve the \(\widetilde{\mathcal{O}}(\sqrt{T/\kappa_{*}})\) optimal bound up to logarithmic factors. Besides, our method reduces the computation cost of the state-of-the-art binary method [10] from \(\mathcal{O}(\log t)\) to \(\mathcal{O}(1)\) per round.

\begin{table}
\begin{tabular}{c c c c c c c} \hline \hline
**Setting** & **Algorithm** & **Regret** & **Comput. per Round** & **Storage Cost** & **Improved \(\kappa\)** & **Constant Cost** \\ \hline \multirow{5}{*}{binary} & Logistic-UCB-1 [8] & \(\widetilde{\mathcal{O}}(\sqrt{\kappa T})\) & \(\mathcal{O}(t)\) & \(\mathcal{O}(t)\) & \(\times\) & \(\times\) \\  & OFULog-t [9] & \(\widetilde{\mathcal{O}}(\sqrt{T/\kappa_{*}})\) & \(\mathcal{O}(t)\) & \(\mathcal{O}(t)\) & \(\checkmark\) & \(\times\) \\  & (ada)-OFU-ECOLog [10] & \(\widetilde{\mathcal{O}}(\sqrt{T/\kappa_{*}})\) & \(\mathcal{O}(\log t)\) & \(\mathcal{O}(1)\) & \(\checkmark\) & \(\times\) \\  & OL2M [7],GLOC [14] & \(\widetilde{\mathcal{O}}(\kappa\sqrt{T})\) & \(\mathcal{O}(1)\) & \(\mathcal{O}(1)\) & \(\times\) & \(\checkmark\) \\  & OFUL-MLogB (Corollary 1) & \(\widetilde{\mathcal{O}}(\sqrt{T/\kappa_{*}})\) & \(\mathcal{O}(1)\) & \(\mathcal{O}(1)\) & \(\checkmark\) & \(\checkmark\) \\ \hline \multirow{5}{*}{multinomial} & MNL-UCB [11] & \(\widetilde{\mathcal{O}}(K\sqrt{\kappa T})\) & \(\mathcal{O}(t)\) & \(\mathcal{O}(t)\) & \(\times\) & \(\times\) \\  & Improved MNL-UCB [11] & \(\widetilde{\mathcal{O}}(K^{3/2}\sqrt{T})\) & \(\--\) & \(\mathcal{O}(t)\) & \(\checkmark\) & \(-\) \\ \cline{1-1}  & OFUL-MLogB (Theorem 4) & \(\widetilde{\mathcal{O}}(K\sqrt{T})\) & \(\mathcal{O}(1)\) & \(\mathcal{O}(1)\) & \(\checkmark\) & \(\checkmark\) \\ \hline \hline \end{tabular}
\end{table}
Table 1: Comparison in terms of the regret bound, computation cost and storage cost. For the regret bound, the logarithmic dependence on the time horizon \(T\) is hidden by the \(\widetilde{\mathcal{O}}(\cdot)\)-notation. As for the computational cost (abbreviated as “Comput.”) and storage cost, we only keep the dependence on the time step \(t\). Notation “\(\cdot\)” denotes that the algorithm is intractable for implementation.

## 2 Multinomial Logistic Bandit with Improved Regret

This section provides preliminaries on the multinomial logistic bandit problem and optimistic algorithms, beginning with the problem formulation and notations. Then, we revisit the optimistic algorithms for the MLogB problem. Specifically, we investigate the previously best-known feasible algorithm, MNL-UCB algorithm [11], and propose an improved version with better dependence on the exponentially large constant \(\kappa\) and the number of outcome values \(K\).

### Problem Formulation

The multinomial logistic bandit (MLogB) problem studies a \(T\) round decision-making process between the learner and the environment. At the beginning of the iteration \(t\), the learner will first select an action \(\mathbf{x}_{t}\in\mathcal{X}\) from the feasible action set \(\mathcal{X}\subseteq\mathbb{R}^{d}\) and then submit it to the environment. After that, a response \(y_{t}\in\{0\}\cup[K]\) with \(K+1\) possible outcomes (like "buy now", "add to chart", or "do nothing") is returned based on the learner's choice, where \(K\in\mathbb{N}\). Specifically, the MLogB problem assumes that each outcome \(k\in[K]\) is associated with a ground-truth parameter \(\mathbf{w}_{*}^{(k)}\in\mathbb{R}^{d}\) and the probability of the outcome \(\text{Pr}[y_{t}=k\mid\mathbf{x}_{t}]\) follows the logistic model,

\[\Pr[y_{t}=k\mid\mathbf{x}_{t}]=\frac{\exp\left((\mathbf{w}_{*}^{(k)})^{ \top}\mathbf{x}_{t}\right)}{1+\sum_{j=1}^{K}\exp\left((\mathbf{w}_{*}^{(j)})^ {\top}\mathbf{x}_{t}\right)}\ \ \text{ and }\ \Pr[y_{t}=0\mid\mathbf{x}_{t}]=1-\sum_{k=1}^{K}\text{Pr}[y_{t}=k\mid \mathbf{x}_{t}].\]

For notational simplicity, we denote by \(W_{*}=[\mathbf{w}_{*}^{(1)},\dots,\mathbf{w}_{*}^{(K)}]^{\top}\in\mathbb{R}^{K \times d}\) the matrix for the unknown parameter and define the softmax function \(\boldsymbol{\sigma}:\mathbb{R}^{K}\mapsto[0,1]^{K}\) by

\[[\boldsymbol{\sigma}(\mathbf{z})]_{k}=\frac{\exp([\mathbf{z}]_{k})}{1+\sum_{ j=1}^{K}\exp([\mathbf{z}]_{j})}\ \text{for all }k\in[K]\ \ \text{ and }\ [\boldsymbol{\sigma}(\mathbf{z})]_{0}=\frac{1}{1+\sum_{j=1}^{K}\exp([ \mathbf{z}]_{j})},\] (1)

where \([\cdot]_{k}\) denotes the \(k\)-th entry of the input vector. Then, the probability of the outcome can also be written in a concise way as \(\text{Pr}[y_{t}=k\mid\mathbf{x}_{t}]=[\boldsymbol{\sigma}(W_{*}\mathbf{x}_{t })]_{k}\). Besides, each outcome is associated with a fixed and known reward. We denote by \(\rho_{k}\in\mathbb{R}_{+}\) the reward for the outcome \(k\in[K]\), and let \(\rho_{0}=0\) for the outcome \(y_{t}=0\). Therefore, the expected reward of the learner's action \(\mathbf{x}_{t}\) is defined as \(r(\mathbf{x}_{t})=\sum_{k=0}^{K}\text{Pr}[y_{t}=k\mid\mathbf{x}_{t}]\cdot\rho _{k}=\boldsymbol{\rho}^{\top}\boldsymbol{\sigma}(W_{*}\mathbf{x}_{t})\). Let \(\mathbf{x}_{*}=\arg\max_{\mathbf{x}\in\mathcal{X}}\boldsymbol{\rho}^{\top} \boldsymbol{\sigma}(W_{*}\mathbf{x})\). The goal of the learner is to maximize the cumulative reward, which is equivalent to minimizing the regret

\[\mathrm{Reg}_{T}=\sum_{t=1}^{T}\boldsymbol{\rho}^{\top}\bigg{(}\boldsymbol{ \sigma}(W_{*}\mathbf{x}_{*})-\boldsymbol{\sigma}(W_{*}\mathbf{x}_{t})\bigg{)},\] (2)

When \(K=1\) and \(\rho_{1}=1\), MLogB recovers the binary logistic bandit by \(r(\mathbf{x})=\sigma(\mathbf{w}_{*}^{\top}\mathbf{x})=1/(1+\exp(-\mathbf{w}_{*} ^{\top}\mathbf{x}))\), where \(\mathbf{w}_{*}\in\mathbb{R}^{d}\) is a unknown parameter.

**Exponentially Large Constant \(\kappa\).** In the logistic bandit problem, the non-linearity of the reward function is captured by the gradient of the link function \(\nabla\boldsymbol{\sigma}:\mathbf{z}\in\mathbb{R}^{d}\mapsto\mathrm{diag}( \boldsymbol{\sigma}(\mathbf{z}))-\boldsymbol{\sigma}(\mathbf{z})\boldsymbol{ \sigma}(\mathbf{z})^{\top}\). The analysis typically that requires that the gradient term is bounded from below and thus one would define the constant \(\kappa\triangleq 1/\min_{W\in\mathcal{W},\mathbf{x}\in\mathcal{X}}\lambda_{\min}( \nabla\boldsymbol{\sigma}(W\mathbf{x}))\) such that \(\frac{1}{\kappa}I_{d}\preccurlyeq\nabla\boldsymbol{\sigma}(W\mathbf{x})\) for any \(W\in\mathcal{W}\) and \(\mathbf{x}\in\mathcal{X}\), where \(\lambda_{\min}:\mathbb{R}^{K\times K}\rightarrow\mathbb{R}^{K}\) is the minimum eigenvalue of the input matrix. In the binary case (\(K=1\)), one can show that \(\kappa=\max_{\mathbf{w}\in\mathcal{W},\mathbf{x}\in\mathcal{X}}\{1+\exp(\mathbf{ w}^{\top}\mathbf{x})+\exp(-\mathbf{w}^{\top}\mathbf{x})\}=\mathcal{O}(e^{SX})\), where \(S\) and \(X\) are the diameters of the parameter space \(\mathcal{W}\) and action space \(\mathcal{X}\). In the multinomial case, the paper [11, Section 3] also shows that \(\kappa\) is an exponentially large constant with respect to \(S\) and \(X\). Thus, an algorithm with improved dependence on \(\kappa\) is demanded.

### Assumptions and Notations

Same as the previous work for multinomial logistic bandit [11], we use the following assumptions.

**Assumption 1**.: The norm of the action is bounded by 1, i.e., \(\|\mathbf{x}\|_{2}\leq 1\) for any \(\mathbf{x}\in\mathcal{X}\).

**Assumption 2**.: The reward vector \(\boldsymbol{\rho}\in\mathbb{R}_{+}^{K}\) and its norm is bounded by \(R\), i.e., \(\|\boldsymbol{\rho}\|_{2}\leq R\).

**Assumption 3**.: The norm of the parameter \(W_{*}\in\mathbb{R}^{K\times d}\) is bounded by \(S\), i.e., \(\|W_{*}\|_{\mathrm{F}}\leq S\), where \(\|\cdot\|_{\mathrm{F}}\) denotes the Frobenius norm of a matrix.

**Assumption 4**.: Let \(\nabla\sigma(\mathbf{z}):\mathbf{z}\in\mathbb{R}^{d}\mapsto\mathrm{diag}(\bm{ \sigma}(\mathbf{z}))-\bm{\sigma}(\mathbf{z})\bm{\sigma}(\mathbf{z})^{\top}\). For all \(\mathbf{x}\in\mathcal{X}\) and \(W\in\mathcal{W}\), we have \(\lambda_{\min}(\nabla\sigma(W\mathbf{x}))\geq 1/\kappa\) and \(\lambda_{\max}(\nabla\sigma(W\mathbf{x}))\leq L\), where \(\lambda_{\max}:\mathbb{R}^{K\times K}\rightarrow\mathbb{R}^{K}\) and \(\lambda_{\min}:\mathbb{R}^{K\times K}\rightarrow\mathbb{R}^{K}\) take the maximum and minimum eigenvalues of the input, respectively.

**Other Notations.** The following notations are used in the paper. Given a \(K\)-by-\(d\) matrix \(W\), we denote by \(\overrightarrow{W}\) its \(Kd\)-dimensional vectorization. For any positive semi-definite \(H\in\mathbb{R}^{Kd\times Kd}\), we define the norm \(\|\overrightarrow{W}\|_{H}=\sqrt{\left\langle\overrightarrow{W},H \overrightarrow{W}\right\rangle}\). The notation \(\otimes\) is used for the standard Kronecker product. When the input is a vector \(\overrightarrow{W}\in\mathbb{R}^{Kd}\), we treat it as a \(Kd\times 1\) matrix. Moreover, for any symmetric matrix \(A,B\in\mathbb{R}^{Kd\times Kd}\), we denote by \(A\succcurlyeq B\) that \(A-B\) is a semi-positive definite matrix. We use \(\mathcal{F}_{t}=\sigma(\mathbf{x}_{1},y_{1},\ldots,\mathbf{y}_{t-1},\mathbf{x }_{t})\) to denote the filtration, which encodes the information collected so far before receiving \(y_{t}\). Finally, \(\mathcal{O}(\cdot)\) is used to highlight the dependence on \(d\), \(K\), \(\kappa\), and \(T\). With \(\widetilde{\mathcal{O}}(\cdot)\)-notation, we further hide the dependence on the dimension \(d\) and logarithmic factors.

### Optimistic Algorithm with Improved Bound

This part revisit the principle of optimism in the face of uncertainty (OFU) [15] and introduces an improved version of the MNL-UCB algorithm [11] with better dependence on \(\kappa\) and \(K\).

**Optimism in the Face of Uncertainty.** The OFU principle is a fundamental paradigm for addressing the exploration-exploitation dilemma in bandits. At each iteration \(t\), the algorithm selects the arm by the rule \(\mathbf{x}_{t}=\arg\max_{\mathbf{x}\in\mathcal{X}}\widetilde{r}_{t}(\mathbf{x})\), where \(\widetilde{r}_{t}(\mathbf{x})\) is an optimistic estimate of the true reward \(r(\mathbf{x})\) satisfying \(\widetilde{r}_{t}(\mathbf{x})\geq r(\mathbf{x})\) for all \(\mathbf{x}\in\mathcal{X}\). Based on the OFU rule, one can show that \(\mathrm{Re}_{T}\leq\sum_{t=1}^{T}(\widetilde{r}(\mathbf{x}_{t})-r(\mathbf{x }_{t}))\), indicating that a tighter optimistic estimate \(\widetilde{r}_{t}\) will lead to a tighter regret bound. Therefore, designing a tight optimistic estimate \(\widetilde{r}_{t}\) is essential for the OFU algorithm.

In the context of the logistic bandit, a common practice is to construct a confidence set \(\mathcal{C}_{t}\subset\mathbb{R}^{K\times d}\), which is supposed to contain the true parameter \(W_{*}\) with high probability. As such, the learner can obtain the optimistic reward for each arm \(\mathbf{x}\in\mathcal{X}\) by \(\widetilde{r}_{t}(\mathbf{x})=\arg\max_{W\in\mathcal{C}_{t}}\bm{\rho}^{\top} \bm{\sigma}(W\mathbf{x})\). A tighter confidence set will lead to a tighter optimistic reward, and thus resulting in a better regret bound.

**Improved Concentration Set.** Given the reward is generated by the multinomial logistic model, we can employ the maximum likelihood estimation (MLE) method to learn the unknown parameter \(W_{*}\). Specifically, after observing the action-feedback pairs \(\{(\mathbf{x}_{s},y_{s})\}_{s=1}^{t-1}\), one can train the model by

\[W_{t}^{\texttt{MLE}}=\operatorname*{arg\,min}_{W\in\mathbb{R}^{K\times d}} \mathcal{L}_{t}(W)\triangleq\sum_{s=1}^{t-1}\ell_{s}(W)+\frac{\lambda}{2}\|W \|_{\mathrm{F}}^{2},\] (3)

where \(\ell_{t}(W)=\sum_{k=0}^{K}\mathds{1}\{y_{t}=k\}\cdot\log\left(1/[\bm{\sigma}( W\mathbf{x}_{t})]_{k}\right)\) is the multiclass logistic loss established over \((\mathbf{x}_{t},y_{t})\) and \(\lambda>0\) is the regularization parameter. Let \(\overrightarrow{W}\in\mathbb{R}^{Kd}\) be the vectorized parameter. We also define the gradient \(\mathbf{g}_{t}(\overrightarrow{W})\) and the Fisher information matrix \(H_{t}(W)\) of the logistic loss by

\[\mathbf{g}_{t}(\overrightarrow{W})\triangleq\nabla\mathcal{L}_{t}( \overrightarrow{W})\quad\text{ and }\quad H_{t}(W)\triangleq\lambda I+\sum_{s=1}^{t-1}\nabla\bm{\sigma}(W \mathbf{x}_{s})\otimes\mathbf{x}_{s}\mathbf{x}_{s}^{\top},\]

where \(\overrightarrow{W}\in\mathbb{R}^{Kd}\) is the vectorized parameter and \(\nabla\bm{\sigma}:\mathbf{z}\mapsto\mathrm{diag}(\bm{\sigma}(\mathbf{z}))- \bm{\sigma}(\mathbf{z})\bm{\sigma}(\mathbf{z})^{\top}\) is the first order derivative of the reward vector \(\bm{\sigma}(\mathbf{z})\). Then, we are ready to present our confidence set for the maximum likelihood estimator, which exhibits \(\mathcal{O}(\sqrt{K})\) improvement over that in [11].

**Theorem 1**.: _Set the parameter \(\lambda=\mathcal{O}(dK\log(t/\delta))\) with a certain \(\delta\in(0,1]\). For each iteration \(t\in[T]\), we define the confidence set as_

\[\mathcal{C}_{t}(\delta)\triangleq\left\{W\in\mathcal{W}\;\middle|\;\left\| \mathbf{g}_{t}(\overrightarrow{W})-\mathbf{g}_{t}(\overrightarrow{W}_{t}^{ \texttt{MLE}})\right\|_{H_{t}^{-1}(W)}\leq\beta_{t}(\delta)\right\},\] (4)

_where \(\beta_{t}(\delta)=4\sqrt{Kd(1+S)\log\left(2\left(1+t/d\right)/\delta\right)}= \mathcal{O}(\sqrt{dK\log t})\) is the radius of the set and \(\mathcal{W}=\{W\in\mathbb{R}^{K\times d}\;|\;\|W\|_{\mathrm{F}}\leq S\}\). Then, we have \(\Pr\bigl{[}\forall t\geq 1,W_{*}\in\mathcal{C}_{t}(\delta)\bigr{]}\geq 1-\delta\)._

One advantage of the confidence set (4) is that its radius \(\beta_{t}(\delta)\) is independent of the exponentially large constant \(\kappa\) and thus is much tighter than the confident set constructed for the generalizedlinear bandit [5], whose radius exhibits a linear dependence on \(\kappa\). The \(\kappa\)-independent set are first established by [8] for the binary logistic bandit problem and then adapted to multinomial setting by [11] with refined analysis on the self-normalized martingale tail-inequality for multinomial noise. Our confidence set is tighter than that in [11] by improving the radius from \(\beta_{t}(\delta)=\mathcal{O}(K\sqrt{d\log t})\) to \(\beta_{t}(\delta)=\mathcal{O}(\sqrt{dK\log t})\). The improvement is based on a slightly refined self-normalized tail-inequality for the multinomial case, whose formal description is provided in Appendix C.1.

**Construction of Optimistic Reward.** Based on the confidence set (4), we can construct the optimistic reward and select the arm for each iteration by

\[\widetilde{r}_{t}(\mathbf{x})=\arg\max_{W\in\mathcal{C}_{t}(\delta)}\boldsymbol {\rho}^{\top}\boldsymbol{\sigma}(W\mathbf{x})\quad\text{ and }\quad\mathbf{x}_{t}=\arg\max_{\mathbf{x}\in\mathcal{W}} \widetilde{r}_{t}(\mathbf{x}).\] (5)

We have following guarantee for the algorithm based on the MLE (3) and the selection rule specified in (4) and (5). We summarize the algorithmic procedure in Algorithm 1.

**Theorem 2**.: _Under the same conditions as Theorem 1. Let \(\delta\in(0,1]\). Algorithm 1 ensures_

\[\operatorname{Reg}_{T}\leq\mathcal{O}\left(\min\{d\log T\sqrt{\kappa KT},dK \log T\sqrt{T}+\kappa d^{2}K\log^{2}T\}\right)\]

_with probability at least \(1-\delta\) when we set the parameter \(\lambda=\mathcal{O}(dK\log(T/\delta))\)._

**Remark 1** (Improved dependence on \(K\) and \(\kappa\)).: Our method achieves the \(\widetilde{\mathcal{O}}(\sqrt{\kappa KT})\) and \(\widetilde{\mathcal{O}}(K\sqrt{T})\) regret bounds for \(\text{MLogB}\) problem simultaneously. The first bound slightly improves the \(\widetilde{\mathcal{O}}(K\sqrt{\kappa T})\) guarantee of the MNL-UCB algorithm [11] by an \(\mathcal{O}(\sqrt{K})\) factor while the second one is independent of the exponentially large constant \(\kappa\) in its leading term. An \(\widetilde{\mathcal{O}}(K^{\frac{3}{2}}\sqrt{T})\) bound is also attained by [11]. However, their proposed method is intractable as its confidence set is established on all minimal elements of partially Loewner-ordered set \(C_{t}(\delta)\cap\mathcal{W}\)[11, Appendix D]. The computation cost of identifying all minimal elements and projecting onto the proposed confidence set is prohibitive. Our solution is free from such demands by using a different rule to construct the optimistic reward.

```
0: regularization coefficient \(\lambda\), probability \(\delta\).
1: Initialize \(H_{1}=\lambda I_{Kd}\) and \(\widetilde{W}_{1}^{\text{\sf MLE}}\) as any point in \(\mathcal{W}\)
2:for\(t=1,\dots,T\)do
3: Construct \(\widetilde{r}_{t}\) and select the arm by (5). Then, the learner receives \(y_{t}\).
4: Train the estimator \(W_{t+1}^{\text{\sf MLE}}\) by (3) and construct the confidence set \(\widetilde{\mathcal{C}}_{t+1}(\delta)\) as (4).
5:endfor ```

**Algorithm 1** MNL-UCB+

## 3 Jointly Efficient Algorithm

In this section, we introduce OFUL-MLogB, an algorithm with jointly computational and statistical efficiency for the \(\text{MLogB}\) problem. We will first discuss the efficiency concern of the existing methods in the literature and then introduce our algorithm, followed by a technical highlight.

### Efficiency Concerns

The algorithms for logistic bandit crucially rely on two components to ensure the statistical efficiency: the MLE (3) and the optimistic rule (5) for constructing \(\widetilde{r}_{t}\). However, the implementation of both components could be inefficient by requiring \(\mathcal{O}(t)\) computation cost per online iteration.

**Computation and Storage Cost of Maximum Likelihood Estimation.** For logistic bandit or even the generalized linear bandit problem [3; 8; 9; 11], MLE is a widely used tool to learn the unknown parameter. To solve the optimization problem, the gradient-based method, e.g. the projected gradient descent [16], are usually applied. However, as discussed in [10], the optimization of the MLE problem typically requires \(\mathcal{O}(t\log(1/\epsilon))\) gradient step to achieve \(\epsilon\)-accuracy. Besides, the loss function \(\mathcal{L}_{t}\) is established on all historical data \(\{(\mathbf{x}_{s},y_{s})\}_{s=1}^{t-1}\), resulting in an \(\mathcal{O}(t)\) gradient query complexity for each gradient step and \(\mathcal{O}(t)\) storage cost, and thus is inefficient.

**Computation and Storage Cost of Optimistic Reward Construction.** The construction of the optimistic reward \(\widetilde{r}_{t}(\mathbf{x})\) requires to solve the optimization problem (5). However, the objective function \(\bm{\rho}^{\top}\bm{\sigma}(W\mathbf{x})\) is non-concave and the decision domain \(\mathcal{C}_{t}(\delta)\) is non-convex, making the maximization problem \(\widetilde{r}_{t}(\mathbf{x})=\arg\max_{W\in\mathcal{C}_{t}(\delta)}\bm{\rho}^ {\top}\bm{\sigma}(W\mathbf{x})\) computationally challenging. In the binary case, the paper [9] proposed a convex relaxation of the confidence set \(\mathcal{C}_{t}(\delta)\), whereas the relaxed confidence set is still established on all historical data, resulting in \(\mathcal{O}(t)\) time complexity and \(\mathcal{O}(t)\) storage cost at iteration \(t\). The optimistic estimate construction in the previous work for multinomial logisticti bandits [11] is computationally efficient without involving any optimization problem solving. However, it will lead to an inferior regret bound of \(\widetilde{\mathcal{O}}(\sqrt{\kappa T})\).

In the binary case, the work [10] proposed a jointly efficient algorithm, which achieved a nearly minimax optimal bound with \(\mathcal{O}(\log t)\) computation cost per iteration and \(\mathcal{O}(1)\) storage cost. However, as we will discuss in Section 3.3, it is hard to apply their analysis to the multinomial case.

### Efficient Algorithm

In this section, we proposed a novel algorithm which only requires \(\mathcal{O}(1)\) computation cost per iteration and \(\mathcal{O}(1)\) storage cost. The algorithm can achieve the best known results both for binary and multinomial logistic bandits. We have introduced new ingredients both on the algorithm design and regret analysis to achieve the jointly efficient algorithm.

**Efficient Online Estimation.** Instead of performing MLE, we run an online mirror descent algorithm to estimate parameter:

\[\overrightarrow{W}_{t+1}^{\text{\tiny{ML}}}=\operatorname*{arg\,min}_{W\in \mathcal{W}}\langle\nabla\ell_{t}(\overrightarrow{W}_{t}^{\text{\tiny{ML}}}), \overrightarrow{W}\rangle+\frac{1}{2\eta}\|\overrightarrow{W}-\overrightarrow {W}_{t}^{\text{\tiny{ML}}}\|_{\widetilde{H}_{t}}^{2},\ \forall t\geq 1\] (6)

where \(\eta>0\) is the step size to be specified later and the first iteration model \(\overrightarrow{W}_{1}^{\text{\tiny{ML}}}\) can be initialized as any point in the domain \(\mathcal{W}=\{\overrightarrow{W}\in\mathbb{R}^{Kd}\mid\|\overrightarrow{W} \|_{2}\leq S\}\). We set the matrix as \(\widetilde{H}_{t}=H_{t}+\eta\nabla\bm{\sigma}(W_{t}^{\text{\tiny{ML}}} \mathbf{x}_{t})\otimes\mathbf{x}_{t}\mathbf{x}_{t}^{\top}\), where \(H_{t}=\lambda I+\sum_{s=1}^{t-1}\nabla\bm{\sigma}(W_{s+1}^{\text{\tiny{ML}}} \mathbf{x}_{s})\otimes\mathbf{x}_{s}\mathbf{x}_{s}^{\top}\). Both \(\widetilde{H}_{t}\) and \(H_{t}\) can be updated incrementally.

We show the online estimator (6) enjoys computational, storage, and statistical efficiency. Since (6) exhibits a standard online mirror descent formulation [17], it can be solved with a single projected gradient step with the following equivalent formulation by

\[\overrightarrow{Z}_{t+1}=\overrightarrow{W}_{t}^{\text{\tiny{DL}}}-\eta \widetilde{H}_{t}^{-1}\nabla\ell_{t}(\overrightarrow{W}_{t}^{\text{\tiny{DL}}} )\quad\text{ and }\quad\overrightarrow{W}_{t+1}^{\text{\tiny{DL}}}=\arg\min_{ \overrightarrow{W}\in\mathcal{W}}\|\overrightarrow{W}-\overrightarrow{Z}_{t+1} \|_{\widetilde{H}_{t}}.\]

For the gradient descent step above, the most time-consuming operation is maintaining the inverse of the matrix \(\widetilde{H}_{t}\). Since \(\nabla\bm{\sigma}(W_{t}^{\text{\tiny{DL}}}\mathbf{x}_{t})\otimes\mathbf{x}_ {t}\mathbf{x}_{t}^{\top}\) is a rank-\(K\) matrix, it can be calculated by the Sherman-Morrison-Woodbury formula with \(\mathcal{O}(d^{2}K^{3})\) cost per round. As for the projection step, since \(\widetilde{H}_{t}\) is positive semi-definite matrix, it can be solved in \(\mathcal{O}(K^{3}d^{3})\)[18, Section 4].* As a consequence, our algorithm achieves a light update with \(\mathcal{O}(1)\) cost per round. Regarding storage cost, our proposed estimator eliminates the need to store all historical data and updates in a one-pass fashion, requiring only \(\mathcal{O}(1)\) storage cost throughout the learning process. Moreover, the estimator is also statistically efficient. We can construct the following \(\kappa\)-independent confidence set similar to that in Theorem 1.

**Theorem 3**.: _Let \(\delta\in(0,1]\) and \(\alpha=2(1+S)+\ln(K+1)\). Set the parameter \(\eta=\alpha/2\) and \(\lambda=\max\{28Kd\alpha,7\sqrt{6}\alpha S\}\). For each iteration \(t\in[T]\), we define the confidence set as_

\[\mathcal{C}_{t}^{\mathsf{OL}}(\delta)\triangleq\left\{W\in\mathcal{W}\; \middle|\;\middle|\|\overline{W}_{t}^{\mathsf{OL}}-\overline{W}\right\|_{H_{t} }\leq\beta_{t}^{\mathsf{OL}}(\delta)\right\},\] (7)

_where \(\beta_{t}^{\mathsf{OL}}(\delta)=\mathcal{O}\big{(}\log K\log t\sqrt{Kd}\big{)}\). Then, we have \(\Pr\big{[}\forall t\geq 1,W_{*}\in\mathcal{C}_{t}(\delta)\big{]}\geq 1-\delta\). Moreover, the computation cost of solving (6) is \(\mathcal{O}(1)\) per round._

**Remark 2** (Comparison with the online estimator [10]).: Our algorithm design is inspired by the online estimator [10] developed for the binary case, while achieving even lighter cost by novel algorithm ingredients and analysis. As discussed in Section 3.3, the analysis for the binary setting is hard to be applied to the multinomial case. Specifically, the paper [10] has proposed an intermediary decision \(\overline{W}_{t}\) in the analysis to prove the statistical efficiency of the proposed estimator. However, the favorable property of the intermediate decision only holds in the binary case. To this end, we have proposed a new intermediary decisions, which not only help to prove the statistically efficient of our estimator but also eliminate the requirement of the exploration step. Besides, we have also introduced a novel algorithm ingredient to further speed-up the algorithm. Instead of learning with original loss function as in [10], by a more refined exploitation of the negative term in the analysis, we show it is sufficient to learn with the first order approximate \(\langle\nabla\ell_{t}(\overline{W}_{t}^{\mathsf{OL}}),\overline{W}\rangle\) of \(\ell_{t}(W)\) with the adjusted local norm \(\left\|\cdot\right\|_{\bar{H}_{t}}\). Our new algorithm not only enjoys a computation efficiency improvement from \(\mathcal{O}(\log t)\) in [10] to \(\mathcal{O}(1)\), but also is free from any exploration step required by the previous work. We provide a technical highlight in Section 3.3.

**Efficient Optimistic Reward Construction.** Although the confidence set \(\mathcal{C}_{t}^{\mathsf{OL}}(\delta)\) is convex, the optimistic rule (5) by \(\widetilde{r}_{t}(\mathbf{x})=\arg\min_{W\in\mathcal{C}_{t}^{\mathsf{OL}}( \delta)}\boldsymbol{\rho}^{\top}\boldsymbol{\sigma}(W\mathbf{x})\) still involves inefficient non-concave optimization problem solving. In this part, we propose a novel optimistic reward that can be solved in a constant time per round.

**Proposition 1**.: _For any \(\mathbf{x}\in\mathcal{X}\) and iteration \(t\in[T]\), the optimistic reward is constructed by_

\[\widetilde{r}_{t}^{\mathsf{OL}}(\mathbf{x})=\boldsymbol{\rho}^{\top} \boldsymbol{\sigma}(W_{t}^{\mathsf{OL}}\mathbf{x})+\epsilon_{t}^{\mathsf{ fast}}(\mathbf{x})+\epsilon_{t}^{\mathsf{end}}(\mathbf{x}).\] (8)

_In above, \(\epsilon_{t}^{\mathsf{fast}}(\mathbf{x})=\beta_{t}^{\mathsf{OL}}(\delta)\cdot \|H_{t}^{-\frac{1}{2}}(I_{K}\otimes\mathbf{x})\nabla\boldsymbol{\sigma}(W_{t} ^{\mathsf{OL}}\mathbf{x})\boldsymbol{\rho}\|_{2}\) and \(\epsilon_{t}^{\mathsf{end}}(\mathbf{x})=3R\left(\beta_{t}^{\mathsf{OL}}\right) ^{2}\cdot\|(I_{K}\otimes\mathbf{x}^{\top})H_{t}^{-1/2}\|_{2}^{2}\) are the bonus. Then, we have \(\widetilde{r}_{t}^{\mathsf{OL}}(\mathbf{x})\geq\boldsymbol{\rho}^{\top} \boldsymbol{\sigma}(W_{*}\mathbf{x})\) for all \(t\geq 1\) and \(\mathbf{x}\in\mathcal{X}\) with probability at least \(1-\delta\)._

Proposition 1 constructs the optimistic reward by adding the "bonus" to the reward empirically estimated by \(W_{t}^{\mathsf{OL}}\). Different from the term used in [11], our bonus terms are independent of the exponentially large constant and thus can lead to an improved \(\widetilde{\mathcal{O}}(K\sqrt{T})\) bound. The optimistic rule (8) does not involve any optimization problem solving and can be calculated in an \(\mathcal{O}(1)\) cost.

Overall Algorithm and Guarantees.We overall procedures in Algorithm 2. For the general multinomial setting, it ensures an \(\widetilde{\mathcal{O}}(K\sqrt{T})\) regret guarantee and an \(\mathcal{O}(1)\) computation cost.

**Theorem 4**.: _Under the same condition as Theorem 3, Algorithm 2 ensures_

\[\mathrm{Reg}_{T}=\mathcal{O}\left(Kd\log K(\log T)^{\frac{3}{2}} \sqrt{T}+\kappa K^{\frac{3}{2}}d^{2}(\log K)^{2}(\log T)^{3}\right)=\widetilde {\mathcal{O}}(K\sqrt{T}).\]

_The computation cost of Algorithm 2 is bounded by \(\mathcal{O}(1)\) for each round \(t\in[T]\)._

**Remark 3** (On the \(\widetilde{\mathcal{O}}(\sqrt{T/\kappa_{*}})\) bound).: In the binary setting, [9, 10] show that an \(\widetilde{\mathcal{O}}(\sqrt{T/\kappa_{*}})\) minimax optimal is achievable with \(\kappa_{*}=1/\sigma^{\prime}(\mathbf{w}_{*}^{\top}\mathbf{x}_{*})\). However, due to the multinomial behavior of the feedback, it is unclear how to achieve such a rate in MLogB case (see the discussion in Appendix C.5). Besides, it also raises concerns about efficiency when applying the method developed for binary case to multinomial setting. In particular, the \(\widetilde{\mathcal{O}}(\sqrt{T/\kappa_{*}})\) is achieved by the rule \(\arg\max_{\mathbf{x}\in\mathcal{X},\mathbf{w}\in\mathcal{C}_{t}(\delta)} \sigma(\mathbf{w}^{\top}\mathbf{x})\) in [9, 10]. The optimization can be efficiently solved in the binary case since one can simply eliminate the non-linearity of the reward function by the relationship \(\sigma(z_{1})>\sigma(z_{2})\) for any \(z_{1}\in\mathbb{R}>z_{2}\in\mathbb{R}\). Such a condition does not hold in MLogB problem.

When reduced to the binary case \(K=1\), our algorithm can also achieves the minimax regret bound.

**Corollary 1**.: _When \(K=1\), the multinomial logistic bandit reduces to the binary logistic bandit problem. Then, under the same conditions as Theorem 4, Algorithm 2 with the optimistic rule \(\widetilde{r}_{t}(\mathbf{x})=\arg\max_{\mathbf{w}\in\mathcal{C}_{t}^{\mathsf{ OR}}(\delta)}\mathbf{w}^{\top}\mathbf{x}\) ensures \(\mathrm{Reg}_{T}\leq\widetilde{\mathcal{O}}(\sqrt{T/\kappa_{*}})\) with probability at least \(1-\delta\)._

### Analysis

This section presents the proof sketch for Theorem 3, which plays an key role in the analysis for Algorithm 2. For notational simplicity, we will drop the superscript \(\mathtt{OL}\) in this section.

**Leveraging Negative Terms for Efficient Update.** If we update the model with the original loss function by \(\overrightarrow{W}_{t+1}=\arg\min_{W\in\mathcal{W}}\ell_{t}(W)+\frac{1}{2\eta} \|\overrightarrow{W}-\overrightarrow{W}_{t}\|_{H_{t}}^{2}\), the arguments in [10] shows that the estimation error between \(\overrightarrow{W}_{t+1}\) and \(\overrightarrow{W}_{*}\) can be bounded by their gap on the loss function

\[\|\overrightarrow{W}_{t+1}-\overrightarrow{W}_{*}\|_{H_{t+1}}^{2}\lesssim\sum _{s=1}^{t}\ell_{s}(W_{*})-\sum_{s=1}^{t}\ell_{s}(W_{s+1}).\] (9)

However, the update rule with original loss will lead to an \(\mathcal{O}(\log t)\) computation cost per iteration. To facilitate a more efficient algorithm, we introduce the update rule with the linearized loss \(\langle\nabla\ell_{t}(\overrightarrow{W}_{t}),\overrightarrow{W}\rangle\) and the adjusted norm \(\widetilde{H}_{t}\) as (6). As we have shown in the proof of Lemma 12 in Appendix C.1. Denote by \(\widetilde{\ell}_{t}(W)=\langle\nabla\ell_{t}(\overrightarrow{W}_{t}), \overrightarrow{W}\rangle+\frac{1}{2}\|\overrightarrow{W}-\overrightarrow{W }_{t}\|_{\nabla^{2}\ell_{t}(\overrightarrow{W}_{t})}^{2}\) the second-order surrogate of \(\ell_{t}(W)\). The efficient update rule will introduce an additional term

\[\sum_{s=1}^{t}\langle\nabla\ell_{s}(\overrightarrow{W}_{s+1})-\nabla \widetilde{\ell}_{s}(\overrightarrow{W}_{s+1}),\overrightarrow{W}_{s+1}- \overrightarrow{W}_{*}\rangle.\]

We handle the additional term by the self-concordant property of the logistic loss and exploiting a negative term ignored in the previous analysis. Since the logistic loss is a \(\sqrt{6}\)-self-concordant-like function [19, Lemma 4], then Theorem 3 of [19] indicates that the additional term can be bounded by

\[\sum_{s=1}^{t}\langle\nabla\ell_{t}(\overrightarrow{W}_{s+1})-\nabla \widetilde{\ell}_{s}(\overrightarrow{W}_{s+1}),\overrightarrow{W}_{s+1}- \overrightarrow{W}_{*}\rangle\leq\sum_{s=1}^{t}\sqrt{6K}S\|\overrightarrow{W }_{s+1}-\overrightarrow{W}_{s}\|_{\nabla^{2}\ell_{s}(\xi_{s})}^{2},\]

where \(\xi_{s}\in\mathbb{R}^{Kd}\) is on the line connecting \(\overrightarrow{W}_{s+1}\) and \(\overrightarrow{W}_{s}\). Besides, by a refined analysis of the online mirror descent (OMD) update (6), we identify an additional _negative term_\(-\sum_{s=1}^{t}\|\overrightarrow{W}_{s+1}-\overrightarrow{W}_{s}\|_{H_{s}}^{2}\) on the right hand side of (9). By properly choosing the coefficient \(\lambda\), one can cancel the additional term by the negative term and achieves (9) with the efficient update. We note that the negative term in the OMD analysis is also found crucial in the gradient-variation regret of non-stationary online learning [20, 21] as well as its applications to game theory [22] and the SEA model [23].

**Novel construction of the intermediary prediction.** Then, we can further bound the right hand side of (9) by inserting an intermediary loss \(\ell_{s}(\widetilde{W}_{s})\) as

\[\sum_{s=1}^{t}\ell_{s}(W_{*})-\sum_{s=1}^{t}\ell_{s}(W_{s+1})=\underbrace{ \sum_{s=1}^{t}\ell_{s}(W_{*})-\sum_{s=1}^{t}\ell_{s}(\widetilde{W}_{s})}_{ \mathtt{term}\ (k)}+\underbrace{\sum_{s=1}^{t}\ell_{s}(\widetilde{W}_{s})-\sum_{s=1}^{t} \ell_{s}(W_{s+1})}_{\mathtt{term}\ (k)}.\]

In the binary case, inspired by the study [24] for the binary online logistic regression, [10] propose to construct \(\widetilde{\mathbf{w}}_{s}=\arg\min_{\mathbf{w}\in\mathcal{W}_{s}}\ell_{\text{ b}}(\mathbf{w}^{\top}\mathbf{x}_{s},+1)+\ell_{\text{b}}(\mathbf{w}^{\top} \mathbf{x}_{s},0)+\frac{1}{2\eta}\|\mathbf{w}-\mathbf{w}_{s}\|_{H_{s}}^{2}\), where \(\ell_{\text{b}}\) is the binary logistic loss and \(\mathcal{W}_{s}\) is a branch decision domain. Then, both term (A) and term (B) can be bounded without the dependence on \(\kappa\). However, the analysis for term (B) crucially relies on the condition \(|\sigma(\widetilde{\mathbf{w}}_{s}^{\top}\mathbf{x}_{s})-y_{s}|\cdot|\sigma( \widetilde{\mathbf{w}}_{s}^{\top}\mathbf{x}_{s})-1+y_{s}|=\sigma^{\prime}( \widetilde{\mathbf{w}}_{s}^{\top}\mathbf{x}_{s})\) to eliminate the dependence on \(\kappa\), where \(y_{s}\in\{0,1\}\) is the one-dimensional feedback. It is hard to show such an relationship in the multinomial case since the feedback \(y_{s}\) has multiple value. A similar challenge is also observed in the recent study on online multiclass logistic regression [25, Appendix F]. One might consider whether it is possible to construct \(\widetilde{W}_{t}\) with the update rule developed in [25]. However, since the online update rule of [25] requires to perform over \(\mathbb{R}^{K\times d}\), the learned parameter would become unbounded, which makes it is hard to provide an upper bound for term (A).

To this end, we design a new intermediary term by \(\ell_{\text{n}}(\widetilde{\mathbf{z}}_{s},y_{s})\), where \(\ell_{\text{n}}\) is the multiclass logistic loss. The prediction is constructed by \(\widetilde{\mathbf{z}}_{s}=\boldsymbol{\sigma}^{+}(\mathbb{E}_{W\sim P_{s}}[ \boldsymbol{\sigma}(W\mathbf{x}_{s})])\) with the Gaussian distribution \(P_{s}=\mathcal{N}(\overrightarrow{W}_{s},\alpha H_{s}^{-1})\), where \(\boldsymbol{\sigma}^{+}\) is a pseudo inverse function of the sigmoid function \(\boldsymbol{\sigma}\). Suchan integral construction \(\widetilde{\mathbf{z}}_{s}=\boldsymbol{\sigma}^{+}(\mathbb{E}_{W\sim P_{s}}[ \boldsymbol{\sigma}(W\mathbf{x}_{s})])\) is previously used in the online logistic regression literature [26; 27] but we tailored the tool to our analysis with a different construction of the distribution \(P_{s}\). Lemma 13 and Lemma 14 in Appendix C.1 shows that

\[\texttt{term}\left(\texttt{A}\right)\lesssim(\log K+\log t)\log t\ \ \ \texttt{and}\ \ \texttt{term}\left(\texttt{B}\right)\lesssim\sum_{s=1}^{t}\lVert \overrightarrow{W}_{s}-\overrightarrow{W}_{s+1}\rVert_{H_{s}}^{2}+Kd\log K \log t,\]

Then, combining the upper bound of term (A) and term (B) and eliminating the additional term \(\sum_{s=1}^{t}\lVert\overrightarrow{W}_{s}-\overrightarrow{W}_{s+1}\rVert_{H_ {s}}^{2}\) with the negative term obtained by a refined analysis of online mirror descent, we complete the proof of Theorem 3.

## 4 More Discussions and Related Work

This section begins with a discussion on the tightness of the proposed bounds.

**On the Tightness of Our Bounds.** In this paper, we introduced OFUL-MLogB, a jointly efficient algorithm that simultaneously achieves regret bounds of \(\widetilde{\mathcal{O}}(\sqrt{\kappa KT})\) and \(\widetilde{\mathcal{O}}(K\sqrt{T})\).+ The tightness of these bounds, with respect to \(\kappa\) and \(T\), was detailed in Remark 3. Regarding the number of feedback values \(K\), [11] claimed the optimality of a linear dependence on \(K\). However, our findings revealed a nuanced interplay between \(\kappa\) and \(K\). The \(\widetilde{\mathcal{O}}(\sqrt{\kappa KT})\) bound does not conflict with the lower bound argument by [11], given that the non-linear constant \(\kappa\) is also associated with \(K\). Beyond \(\kappa\), the norm of the unknown parameter \(S\) and maximum norm \(R\) of the reward vector \(\boldsymbol{\rho}\) can also depend on \(K\) based on the problem's specifics. It is an interesting direction to understand the interrelation of these constants by establishing a lower bound. Additionally, our method has a linear dependence on \(d\). In the finite-arm case, an \(\mathcal{O}(\sqrt{d})\) dependence might be attainable with a SupLin-type algorithm [28].

Footnote †: Theorem 5 in Appendix C.3.2 shows that OFUL-MLogB also attains the \(\widetilde{\mathcal{O}}(\sqrt{\kappa KT})\) regret bound.

Below, we introduce more related works on logistic bandit and the related topics.

**Logistic Bandit.** While the logistic bandit is a specific instance of the generalized linear bandit model [5; 29; 30; 31; 32; 33; 34], the algorithms proposed for GLB tend to exhibit a linear dependence on the nonlinear term \(\kappa\), which is exponentially large in the logistic bandit case. Therefore, addressing the non-linearity of the reward function warrants specialized consideration. Besides the UCB-type algorithms [8; 9] mentioned in Section 1, for the \(N\)-arm case, [35] proposed an experimental design-based algorithm providing an \(\widetilde{\mathcal{O}}(\sqrt{d\log NT/\kappa_{*}})\) regret bound with better dependence on \(d\). However, the previous methods were built upon the MLE estimator, whose optimization demands \(\mathcal{O}(t)\) computation and storage complexity for the \(t\)-th iteration. To the best of our knowledge, the only known jointly computational and statistical efficient algorithm was proposed by [10], which achieves a nearly minimax optimal regret bound with computation cost of \(\mathcal{O}(\log t)\) per round. In addition to the frequentist bounds, there are also researches on logistic bandit from the Bayesian view. [36] showed the Bayesian regret of the Thompson sampling method is independent of \(\kappa\) (even in the lower order term) when the feasible domain is identical to the parameter domain, i.e., \(\mathcal{X}=\mathcal{W}\). [37] further proved the \(\kappa\)-independent bound with weaker conditions.

**Multinomial Logit (MNL) Bandit.** Another relevant line of research is the multinomial logit contextual bandit problem [38; 39; 40; 41; 42], which generalizes the binary logistic bandit by allowing the learner to submit a subset of arms \(S_{t}=\{\mathbf{x}_{t,i}\}_{i=1}^{K}\in\mathcal{X}\) to the users. The expected reward function is also modeled by the multinomial logit model: \(\mathbb{E}[r_{t}|S_{t}]=\sum_{\mathbf{x}_{t,i}\in S_{t}}\rho_{t,i}\exp(\mathbf{ w}_{*}^{+}\mathbf{x}_{t,i})/(1+\sum_{\mathbf{x}_{t,i}\in S_{t}}\exp(\mathbf{ w}_{*}^{\top}\mathbf{x}_{t,i}))\), where \(\rho_{t,i}\) is the reward for arm \(\mathbf{x}_{t,i}\) and \(\mathbf{w}_{*}\in\mathbb{R}^{d}\) is an unknown parameter. There are also studies on the MNL bandit problem concerning the exponentially large constant \(\kappa\). [42] proposed an optimistic algorithm with \(\mathcal{O}(d\sqrt{T})\) regret bounds without \(\kappa\) in its leading term, which improves the \(\mathcal{O}(d\kappa\sqrt{T})\) bound with better dependence on \(\kappa\). Considering uniform reward, i.e., \(\rho_{t,i}=1\) for all \(t\in[T]\) and \(i\in[N]\), [43] further showed an \(\widetilde{\mathcal{O}}(d\sqrt{T/\kappa_{*}})\) bound. To the best of our knowledge, all the existing methods with improved \(\kappa\) are established on the MLE estimator. It would be an interesting future direction to develop jointly efficient algorithm for the MNL bandit problem.

## 5 Experiments

This section validates the statistical and computation efficiency of the proposed method by experiments. We conduct a bandit learning for \(T=3000\) iterations. In each experiment, we run experiments on 6 random configurations, in which the arm set and the underlying parameter are randomly sampled. Specially, \(|\mathcal{X}|=20\) actions are randomly sampled from a 2-dimensional sphere of radius 1. In the binary case, the norm of the unknown parameter \(\mathbf{w}_{*}\) is set as \(S=5\). In the multinomial case, we set \(K=4\) with \(S=1\). The reward vector is set as \(\boldsymbol{\rho}=[0.25,0.5,0.75,1]\). For each configuration, we report the averaged results over 10 trials. More details can be found in Appendix D.

**Experimental Results.** Figure 4 provides a comparison of performance and computation costs in the binary case. The algorithm O2LM[7], which has a constant computational cost per iteration, is used as a comparison baseline. Our algorithm demonstrates a time complexity akin to O2LM, affirming its computational efficiency. Compared to the state-of-the-art binary logistic bandit algorithm ada-OFU-ECOLOG[10], our OFU-MLogB method has lighter computational overheads while preserving similar empirical performance. Figure 4 illustrates the comparison in the multinomial setting. Our algorithm is around 50 times faster than MNL-UCB[11] for running \(T=3000\) iterations and achieves better empirical performance. More experimental results on other configurations and the running time curve that increases along the iterations can be found in Appendix D.

## 6 Conclusion

This paper proposed a jointly efficient algorithm OFUL-MLogB for both binary and multinomial logistic bandit problems with constant computation cost per round and improved regret guarantees. For the multinomial setting, our method improves over the best-known feasible algorithm both on the dependence of \(\kappa\) and the computation cost. When reduced to the binary case, OFUL-MLogB also contributes to improve the computation cost of previous method from \(\mathcal{O}(\log t)\) to \(\mathcal{O}(1)\) per round while still preserving the \(\widetilde{\mathcal{O}}(\sqrt{T/\kappa_{*}})\) minimax optimal bound up to logarithmic factors. A promising future direction is to consider the multinomial logit model in reinforcement learning. Besides, it is still open on how to achieve the \(\widetilde{\mathcal{O}}(\sqrt{T/\kappa_{*}})\) bound for the multinomial case.

## Acknowledgments

YJZ and MS were supported by the Institute for AI and Beyond, UTokyo. YJZ was also supported by Todai Fellowship. The authors would thank Peng Zhao for helpful discussions and Jing Wang for the assistance in experiments.

Figure 1: Performance and computation cost comparison for binary logistic bandit.

Figure 2: Performance and computation cost comparison for multinomial logistic bandit.

## References

* [1] Peter Auer. Using confidence bounds for exploitation-exploration trade-offs. _Journal of Machine Learning Research_, 3:397-422, 2002.
* [2] Varsha Dani, Thomas P. Hayes, and Sham M. Kakade. Stochastic linear optimization under bandit feedback. In _Proceedings of the 21st Annual Conference on Learning Theory (COLT)_, pages 355-366, 2008.
* [3] Yasin Abbasi-Yadkori, David Pal, and Csaba Szepesvari. Improved algorithms for linear stochastic bandits. In _Advances in Neural Information Processing Systems 24 (NeurIPS)_, pages 2312-2320, 2011.
* [4] Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multiarmed bandit problem. _Machine Learning_, 47(2-3):235-256, 2002.
* [5] Sarah Filippi, Olivier Cappe, Aurelien Garivier, and Csaba Szepesvari. Parametric bandits: The generalized linear case. In _Advances in Neural Information Processing Systems 23 (NeurIPS)_, pages 586-594, 2010.
* [6] Sayak Ray Chowdhury and Aditya Gopalan. On kernelized multi-armed bandits. In _Proceedings of the 34th International Conference on Machine Learning (ICML)_, pages 844-853, 2017.
* [7] Lijun Zhang, Tianbao Yang, Rong Jin, Yichi Xiao, and Zhi-Hua Zhou. Online stochastic linear optimization under one-bit feedback. In _Proceedings of the 33rd International Conference on Machine Learning (ICML)_, pages 392-401, 2016.
* [8] Louis Faury, Marc Abeille, Clement Calauzenes, and Olivier Fercoq. Improved optimistic algorithms for logistic bandits. In _Proceedings of the 37th International Conference on Machine Learning (ICML)_, pages 3052-3060. PMLR, 2020.
* [9] Marc Abeille, Louis Faury, and Clement Calauzenes. Instance-wise minimax-optimal algorithms for logistic bandits. In _Proceedings of the 24th International Conference on Artificial Intelligence and Statistics (AISTATS)_, pages 3691-3699, 2021.
* [10] Louis Faury, Marc Abeille, Kwang-Sung Jun, and Clement Calauzenes. Jointly efficient and optimal algorithms for logistic bandits. In _Proceedings of the 25th International Conference on Artificial Intelligence and Statistics (AISTATS)_, pages 546-580, 2022.
* [11] Sanae Amani and Christos Thrampoulidis. UCB-based algorithms for multinomial logistic regression bandits. In _Advances in Neural Information Processing Systems 34 (NeurIPS)_, 2021.
* [12] Chi Jin, Zhuoran Yang, Zhaoran Wang, and Michael I. Jordan. Provably efficient reinforcement learning with linear function approximation. In _Proceedings of the 33rd Conference on Learning Theory (COLT)_, pages 2137-2143, 2020.
* [13] Dongruo Zhou, Quanquan Gu, and Csaba Szepesvari. Nearly minimax optimal reinforcement learning for linear mixture markov decision processes. In _Proceedings of the 34th Conference on Learning Theory (COLT)_, pages 4532-4576, 2021.
* [14] Kwang-Sung Jun, Aniruddha Bhargava, Robert D. Nowak, and Rebecca Willett. Scalable generalized linear bandits: Online computation and hashing. In _Advances in Neural Information Processing Systems 30 (NeurIPS)_, pages 99-109, 2017.
* [15] Tor Lattimore and Csaba Szepesvari. _Bandit Algorithms_. Cambridge University Press, 2020.
* [16] Elad Hazan. Introduction to online convex optimization. _Foundations and Trends in Optimization_, 2(3-4):157-325, 2016.
* [17] Francesco Orabona. A modern introduction to online learning. _ArXiv preprint_, arXiv: 1912.13213, 2019.
* [18] Zakaria Mhammedi, Wouter M. Koolen, and Tim van Erven. Lipschitz adaptivity with multiple learning rates in online learning. In _Proceedings of the 32nd Annual Conference on Learning Theory (COLT)_, pages 2490-2511, 2019.
* [19] Quoc Tran-Dinh, Yen-Huan Li, and Volkan Cevher. Composite convex minimization involving self-concordant-like cost functions. In _Proceedings of the 3rd International Conference on Modelling, Computation and Optimization in Information Systems and Management Sciences_, pages 155-168, 2015.

* [20] Peng Zhao, Yu-Jie Zhang, Lijun Zhang, and Zhi-Hua Zhou. Dynamic regret of convex and smooth functions. In _Advances in Neural Information Processing Systems 33 (NeurIPS)_, pages 12510-12520, 2020.
* [21] Peng Zhao, Yu-Jie Zhang, Lijun Zhang, and Zhi-Hua Zhou. Adaptivity and non-stationarity: Problem-dependent dynamic regret for online convex optimization. _ArXiv preprint_, arXiv:2112.14368, 2021.
* [22] Mengxiao Zhang, Peng Zhao, Haipeng Luo, and Zhi-Hua Zhou. No-regret learning in time-varying zero-sum games. In _Proceedings of the 39th International Conference on Machine Learning (ICML)_, pages 26772-26808, 2022.
* [23] Sijia Chen, Wei-Wei Tu, Peng Zhao, and Lijun Zhang. Optimistic online mirror descent for bridging stochastic and adversarial online convex optimization. In _Proceedings of the 40th International Conference on Machine Learning (ICML)_, pages 5002-5035, 2023.
* [24] Remi Jezequel, Pierre Gaillard, and Alessandro Rudi. Efficient improper learning for online logistic regression. In _Proceedings of the 33rd Conference on Learning Theory (COLT)_, pages 2085-2108, 2020.
* [25] Naman Agarwal, Satyen Kale, and Julian Zimmert. Efficient methods for online multiclass logistic regression. In _Proceedings of International Conference on Algorithmic Learning Theory (ALT)_, pages 3-33, 2022.
* [26] Dylan J. Foster, Satyen Kale, Haipeng Luo, Mehryar Mohri, and Karthik Sridharan. Logistic regression: The importance of being improper. In _Proceedings of the 31st Conference On Learning Theory (COLT)_, pages 167-208, 2018.
* [27] Remi Jezequel, Pierre Gaillard, and Alessandro Rudi. Mixability made efficient: Fast online multiclass logistic regression. In _Advances in Neural Information Processing Systems 34 (NeurIPS)_, pages 23692-23702, 2021.
* [28] Wei Chu, Lihong Li, Lev Reyzin, and Robert E. Schapire. Contextual bandits with linear payoff functions. In _Proceedings of the 14th International Conference on Artificial Intelligence and Statistics (AISTATS)_, pages 208-214, 2011.
* [29] Lihong Li, Yu Lu, and Dengyong Zhou. Provably optimal algorithms for generalized linear contextual bandits. In _Proceedings of the 34th International Conference on Machine Learning (ICML)_, pages 2071-2080, 2017.
* [30] Daniel Russo and Benjamin Van Roy. Eluder dimension and the sample complexity of optimistic exploration. In _Advances in Neural Information Processing Systems 26 (NeurIPS)_, pages 2256-2264, 2013.
* [31] Daniel Russo and Benjamin Van Roy. Learning to optimize via information-directed sampling. In _Advances in Neural Information Processing Systems 27 (NeurIPS)_, pages 1583-1591, 2014.
* [32] Marc Abeille and Alessandro Lazaric. Linear Thompson sampling revisited. In _Proceedings of the 20th International Conference on Artificial Intelligence and Statistics (AISTATS)_, pages 176-184, 2017.
* [33] Branislav Kveton, Manzil Zaheer, Csaba Szepesvari, Lihong Li, Mohammad Ghavamzadeh, and Craig Boutilier. Randomized exploration in generalized linear bandits. In _Proceedings of the 23rd International Conference on Artificial Intelligence and Statistics (AISTATS)_, pages 2066-2076, 2020.
* [34] Peng Zhao, Lijun Zhang, Yuan Jiang, and Zhi-Hua Zhou. A simple approach for non-stationary linear bandits. In _Proceedings of the 23rd International Conference on Artificial Intelligence and Statistics (AISTATS)_, pages 746-755, 2020.
* [35] Blake Mason, Kwang-Sung Jun, and Lalit Jain. An experimental design approach for regret minimization in logistic bandits. In _Proceedings of the 36th AAAI Conference on Artificial Intelligence (AAAI)_, pages 7736-7743, 2022.
* [36] Shi Dong, Tengyu Ma, and Benjamin Van Roy. On the performance of thompson sampling on logistic bandits. In _Proceedings of the 32nd Annual Conference on Learning Theory (COLT)_, pages 1158-1160, 2019.
* [37] Gergely Neu, luliia Olkhovskaia, Matteo Papini, and Ludovic Schwartz. Lifting the information ratio: An information-theoretic analysis of thompson sampling for contextual bandits. In _Advances in Neural Information Processing Systems 36 (NeurIPS)_, 2022.

* [38] Shipra Agrawal, Vashist Avadhanula, Vineet Goyal, and Assaf Zeevi. Thompson sampling for the mnl-bandit. In _Proceedings of the 30th Annual Conference on Learning Theory (COLT)_, pages 76-78, 2017.
* [39] Shipra Agrawal, Vashist Avadhanula, Vineet Goyal, and Assaf Zeevi. Mnl-bandit: A dynamic learning approach to assortment selection. _Operations Research_, 67(5):1453-1485, 2019.
* [40] Min-hwan Oh and Garud Iyengar. Thompson sampling for multinomial logit contextual bandits. In _Advances in Neural Information Processing Systems 32 (NeurIPS)_, pages 3145-3155, 2019.
* [41] Wang Chi Cheung and David Simchi-Levi. Thompson sampling for online personalized assortment optimization problems with multinomial logit choice models. _Available at SSRN 3075658_, 2017.
* [42] Priyank Agrawal, Theja Tulabandhula, and Vashist Avadhanula. A tractable online learning algorithm for the multinomial logit contextual bandit. _European Journal of Operational Research_, 2023.
* [43] Noemie Perivier and Vineet Goyal. Dynamic pricing and assortment under a contextual MNL demand. In _Advances in Neural Information Processing Systems 36 (NeurIPS)_, 2022.
* [44] Yurii E. Nesterov and Arkadii Nemirovskii. _Interior-point polynomial algorithms in convex programming_. SIAM, 1994.
* [45] Francis Bach. Self-concordant analysis for logistic regression. _Electronic Journal of Statistics_, 4:384-414, 2010.
* [46] Tianxiao Sun and Quoc Tran-Dinh. Generalized self-concordant functions: a recipe for newton-type methods. _Mathematical Programming_, 178(1):145-213, 2019.
* [47] Yasin Abbasi-Yadkori, David Pal, and Csaba Szepesvari. Online-to-confidence-set conversions and application to sparse stochastic bandits. In _Proceedings of the 15th International Conference on Artificial Intelligence and Statistics (AISTATS)_, pages 1-9, 2012.
* [48] Nicolo Cesa-Bianchi and Gabor Lugosi. _Prediction, Learning, and Games_. Cambridge University Press, 2006.
* [49] Nicolo Campolongo and Francesco Orabona. Temporal variability in implicit online learning. In _Advances in Neural Information Processing Systems 33 (NeurIPS)_, 2020.

Properties of the Logistic Regression

This section collects several key properties of the logistic loss used throughout the paper.

### Multiclass Logistic Loss

We have the following property of the multiclass logistic loss.

**Property 1**.: _Let \(y\in\mathcal{Y}\) with \(\mathcal{Y}=\{0\}\cup[K]\) and \(\ell:\mathbb{R}^{K}\times\mathcal{Y}\mapsto\mathbb{R}\) be the multiclass logistic loss defined by_

\[\ell(\mathbf{z},y)=\sum_{k=0}^{K}\mathds{1}\{y=k\}\cdot\log\left( \frac{1}{[\bm{\sigma}(\mathbf{z})]_{k}}\right),\] (10)

_where \(\bm{\sigma}:\mathbb{R}^{K}\rightarrow[0,1]^{K}\) is the vector valued link function defined by \([\bm{\sigma}(\mathbf{z})]_{k}=\exp(z_{k})/(1+\sum_{j=1}^{K}\exp(z_{j}))\) and \([\bm{\sigma}(\mathbf{z})]_{0}=\exp(z_{k})/(1+\sum_{j=1}^{K}\exp(z_{j}))\). Let \(\mathbf{y}=[\mathds{1}\{y=1\},\ldots,\mathds{1}\{y=K\}]\in\mathbb{R}^{K}\) and \(\sigma_{k}(\mathbf{z})=[\bm{\sigma}(\mathbf{z})]_{k}\) be the \(k\)-th entry of \(\bm{\sigma}(\mathbf{z})\). Then the first, second and third derivations w.r.t. the first argument of the loss function can be written as_

\[\nabla_{z}\ell(\mathbf{z},y)=\bm{\sigma}(\mathbf{z})-\mathbf{y},\] \[\nabla_{z}^{2}\ell(\mathbf{z},y)=\mathrm{diag}(\bm{\sigma}( \mathbf{z}))-\bm{\sigma}(\mathbf{z})\bm{\sigma}(\mathbf{z})^{\top},\] \[\nabla_{z}^{3}\ell(\mathbf{z},y)[\mathbf{u}]=\sum_{k=1}^{K}u_{k} \sigma_{k}(\mathbf{z})\left(2\bm{\sigma}(\mathbf{z})\bm{\sigma}(\mathbf{z})^ {\top}-\mathrm{diag}(\bm{\sigma}(\mathbf{z}))-\mathbf{e}_{k}\bm{\sigma}( \mathbf{z})^{\top}-\bm{\sigma}(\mathbf{z})\mathbf{e}_{k}^{\top}+E_{k}\right),\]

_where \(u_{k}\) is the \(k\)-th entry of the vector \(\mathbf{u}\in\mathbb{R}^{K}\) and \(E_{k}\in\mathbb{R}^{K\times K}\) is a "one-hot" matrix whose \((k,k)\)-th entry equals to 1 while others equaling to 0. Besides, \(\mathbf{e}_{k}\) is the one-hot vector whose \(k\)-th entry equals to 1. In the above, \(\nabla_{z}^{3}\ell(\mathbf{z},y)[\mathbf{u}]=\lim_{t\to 0}t^{-1}\left( \nabla_{z}^{2}\ell(\mathbf{z}+t\mathbf{u},y)-\nabla_{z}^{2}\ell(\mathbf{z},y)\right)\)._

When we train a linear model with the logistic regression loss, we can calculate its gradient and Hessian as follows.

**Property 2**.: _Denote by the logistic loss defined over the data point \((\mathbf{x}_{t},y_{t})\in\mathcal{X}\times\mathcal{Y}\) by_

\[\ell_{t}(W)=\ell(W\mathbf{x},y)=\sum_{k=0}^{K}\mathds{1}\{y_{t}=k \}\cdot\log\left(1/[\bm{\sigma}(W\mathbf{x}_{t})]_{k}\right).\] (11)

_Then, the gradient \(\nabla\ell_{t}(\overrightarrow{W})\in\mathbb{R}^{Kd}\) and the Hessian \(\nabla^{2}\ell_{t}(W)\in\mathbb{R}^{Kd\times Kd}\) of the loss function with respective to the vectorized model \(\overrightarrow{W}\) is given by_

\[\nabla\ell_{t}(\overrightarrow{W})=(\bm{\sigma}(W\mathbf{x}_{t} )-\mathbf{y}_{t})\otimes\mathbf{x}_{t}\ \ \text{and}\ \ \nabla^{2}\ell_{t}(W)=\mathrm{diag}(\bm{\sigma}(W\mathbf{x}_{t}))-\bm{\sigma}(W \mathbf{x}_{t})\bm{\sigma}(W\mathbf{x}_{t})^{\top}\otimes\mathbf{x}_{t} \mathbf{x}_{t}^{\top}.\]

Besides, we can obtain the gradient of the vector-valued link function as follows.

**Property 3**.: _Let the sigmoid function \(\bm{\sigma}:\mathbb{R}^{K}\mapsto[0,1]^{K}\) be defined as (1) and \(\sigma_{k}(\mathbf{z})\) denote the \(k\)-th entry of \(\bm{\sigma}(\mathbf{z})\). We have_

\[\nabla\sigma_{k}(\mathbf{z})=\sigma_{k}(\mathbf{z})\cdot(\mathbf{ e}_{k}-\bm{\sigma}(\mathbf{z}));\] \[\nabla^{2}\sigma_{k}(\mathbf{z})=\sigma_{k}(\mathbf{z})\left(2\bm {\sigma}(\mathbf{z})\bm{\sigma}(\mathbf{z})^{\top}-\mathrm{diag}(\bm{\sigma}( \mathbf{z}))-\mathbf{e}_{k}\bm{\sigma}(\mathbf{z})^{\top}-\bm{\sigma}( \mathbf{z})\mathbf{e}_{k}^{\top}+E_{k}\right),\]

_In above, \(E_{k}\in\mathbb{R}^{K\times K}\) is an all zero matrix except that its \((k,k)\)-th entry is \(1\). For the first order derivation, we can write it into a more concise formulation by the notation \(\nabla\bm{\sigma}(\mathbf{z}):\mathbb{R}^{K}\mapsto\mathbb{R}^{K\times K}\)_

\[\nabla\bm{\sigma}(\mathbf{z})\triangleq\frac{\partial\bm{\sigma}(\mathbf{z} )}{\partial\mathbf{z}^{\top}}=\mathrm{diag}(\bm{\sigma}(\mathbf{z}))-\bm{ \sigma}(\mathbf{z})\bm{\sigma}(\mathbf{z})^{\top}.\]

We have the following lemma for the logistic loss function.

**Lemma 1**.: _Let \(C>0\), \(\mathbf{a}\in[-C,C]^{K}\), \(y\in\{0\}\cup[K]\) and \(\mathbf{b}\in\mathbb{R}^{K}\). Then, we have_

\[\ell(\mathbf{a},y)\geq\ell(\mathbf{b},y)+\nabla\ell(\mathbf{b},y) ^{\top}(\mathbf{a}-\mathbf{b})+\frac{1}{\log(K+1)+2(C+1)}(\mathbf{a}-\mathbf{b })^{\top}\nabla^{2}\ell(\mathbf{b},y)(\mathbf{a}-\mathbf{b}).\]Proof.: Lemma 1 is essentially the Lemma 4 of [27] with a slightly different definition of the logistic loss. The \(K+1\)-class logistic loss used by [27] is defined as \(\widetilde{\ell}(\widetilde{\mathbf{z}},y)=\sum_{k=0}^{K}\mathds{1}\{y=k\}\log \left(\sum_{k=0}^{K}\exp([\widetilde{\mathbf{z}}]_{j})/\exp([\widetilde{ \mathbf{z}}]_{k})\right)\), where \(\widetilde{\mathbf{z}}\in\mathbb{R}^{K+1}\) is a \(K+1\)-dimensional input. One can connect the two logistic losses by \(\widetilde{\ell}([\mathbf{z};0],y)=\ell(\mathbf{z},y)\). Then, we can prove Lemma 1 by directly applying Lemma 4 of [27] with the augmented vectors \(\widetilde{\mathbf{a}}=[\mathbf{a};0]\) and \(\widetilde{\mathbf{b}}=[\mathbf{b};0]\). 

### Self-concordant-like Function

Then, we introduce the notion of self-concordant-like function, which generalizes the standard self-concordant notion. The self-concordant function is first introduced by [44] in the study of inner-point algorithm and the notion is further generalized by the following work [45, 19, 46] for analyzing the Newton-step methods. The self-concordant function enjoys several nice properties, which plays an important role in our local analysis. A comprehensive study for self-concordance function is provided by [46]. Here, we present the definition and necessary lemmas for our analysis.

**Definition 1** (Theorem 3 of [19]).: A convex function \(\ell\in\mathcal{C}^{3}:\mathbb{R}^{d}\to\mathbb{R}\) is \(M\)-self-concordant-like if and only if for any \(\mathbf{x},\mathbf{u}_{1},\mathbf{u}_{2},\mathbf{u}_{3}\in\mathbb{R}^{d}\), we have

\[\left|\langle D^{3}\ell(\mathbf{z})[\mathbf{u}_{1}]\mathbf{u}_{2},\mathbf{u}_ {3}\rangle\right|\leq M\|\mathbf{u}_{1}\|_{2}\|\mathbf{u}_{2}\|_{\mathbf{z}} \|\mathbf{u}_{3}\|_{\mathbf{z}},\]

where \(\|\mathbf{u}\|_{\mathbf{z}}:=\sqrt{\mathbf{u}^{\top}\nabla^{2}f(\mathbf{z}) \mathbf{u}}\) is the local norm over the Hessian \(\nabla^{2}\ell(\mathbf{z})\).

The logistic loss is \(\sqrt{6}\)-self-concordant-like function.

**Lemma 2** (Lemma 4 of [19]).: _The logistic loss defined as (11) is \(\sqrt{6}\|\mathbf{x}_{t}\|_{2}\)-self-concordant-like._

The self-concordant function enjoys favorable properties, which help us to conduct local analysis for the logistic bandit problem. We list useful lemmas as follows.

**Lemma 3** (Bound of Hessian Map, Theorem 4(b) of [19]).: _Let \(\ell:\mathbb{R}^{d}\mapsto\mathbb{R}\) be an \(M\)-self-concordant-like function. Then, for any \(\mathbf{z}_{1},\mathbf{z}_{2}\in\mathrm{dom}(\ell)\), we have_

\[e^{-M\|\mathbf{z}_{1}-\mathbf{z}_{2}\|_{2}}\nabla^{2}\ell(\mathbf{z}_{1}) \preccurlyeq\nabla^{2}\ell(\mathbf{z}_{2})\preccurlyeq e^{M\|\mathbf{z}_{1} -\mathbf{z}_{2}\|_{2}}\nabla^{2}\ell(\mathbf{z}_{1})\] (12)

The following lemma is a consequence of the bound of the Hessian map.

**Lemma 4** (Corollary 2 of [46]).: _Let \(\ell:\mathbb{R}^{d}\mapsto\mathbb{R}\) be an \(M\)-self-concordant-like function. Then, for any \(\mathbf{z}_{1},\mathbf{z}_{2}\in\mathrm{dom}(\ell)\), we have_

\[\frac{1-e^{-M\|\mathbf{z}_{1}-\mathbf{z}_{2}\|_{2}}}{M\|\mathbf{z}_{1}- \mathbf{z}_{2}\|_{2}}\cdot\nabla^{2}\ell(\mathbf{z}_{2})\preccurlyeq\int_{0 }^{1}\nabla^{2}\ell(\mathbf{z}_{1}+\nu(\mathbf{z}_{2}-\mathbf{z}_{1})) \mathrm{d}\nu\preccurlyeq\frac{e^{M\|\mathbf{z}_{1}-\mathbf{z}_{2}\|_{2}}-1} {M\|\mathbf{z}_{1}-\mathbf{z}_{2}\|_{2}}\nabla^{2}\ell(\mathbf{z}_{1}).\]

We can also have the bound on the function value of the self-concordant functions.

**Lemma 5** (Proposition 10 of [46]).: _Let \(\ell:\mathbb{R}^{d}\mapsto\mathbb{R}\) be an \(M\)-self-concordant-like function. Then, for any \(\mathbf{z}_{1},\mathbf{z}_{2}\in\mathrm{dom}(\ell)\), we have_

\[c(-M\|\mathbf{z}_{1}-\mathbf{z}_{2}\|_{2})\cdot\|\mathbf{z}_{2}-\mathbf{z}_{1 }\|_{\mathbf{z}_{1}}^{2}\leq\ell(\mathbf{z}_{2})-\ell(\mathbf{z}_{1})-\nabla \ell(\mathbf{z}_{1})^{\top}(\mathbf{z}_{2}-\mathbf{z}_{1})\leq c(M_{f}\| \mathbf{z}_{1}-\mathbf{z}_{2}\|_{2})\cdot\|\mathbf{z}_{2}-\mathbf{z}_{1}\|_{ \mathbf{z}_{1}}^{2},\]

_where \(c:\mathbb{R}\mapsto\mathbb{R}\) is the coefficient function defined as \(c(x)=(e^{x}-x-1)/x^{2}\)._

## Appendix B Omitted Proofs for Section 2.3

### Proof of Theorem 1

This section we present the proof of Theorem 1.

#### b.1.1 Main Proof

Before introducing the main proof, we introduce a key lemma on an improved self-normalized martingale tail inequality for the multinomial noise, which helps to save an \(\mathcal{O}(\sqrt{K})\) factor compared to the one obtained by [11]. The proof of Lemma 6 is provided in Appendix B.1.2

**Lemma 6**.: _Let \(\{\mathcal{F}_{t}\}_{t=0}^{\infty}\) be a filtration. Let \(\{\mathbf{x}_{t}\}_{t=1}^{\infty}\) be a stochastic process in \(\mathcal{B}_{2}(d)\triangleq\{\mathbf{x}\in\mathbb{R}^{d}\mid\|\mathbf{x}_{t}\|_ {2}\leq 1\}\) such that \(\mathbf{x}_{t}\) is \(\mathcal{F}_{t}\) measurable. Let \(\{\boldsymbol{\varepsilon}_{t}\}_{t=0}^{\infty}\) be a martingale difference sequence such that \(\boldsymbol{\varepsilon}_{t}\in\mathbb{R}^{K}\) is \(\mathcal{F}_{t+1}\) measurable. Furthermore, assume that conditional on \(\mathcal{F}_{t}\), we have \(\|\boldsymbol{\varepsilon}_{t}\|_{1}\leq 2\) almost surely, and denoted by \(\Sigma_{t}\triangleq\mathbb{E}[\boldsymbol{\varepsilon}_{t}\boldsymbol{ \varepsilon}_{t}^{\top}\mid\mathcal{F}_{t}]\). Let \(\lambda>0\) and for any \(t\geq 1\) define_

\[S_{t}=\sum_{s=1}^{t-1}\boldsymbol{\varepsilon}_{s}\otimes\mathbf{x}_{s}\ \text{ and }\ H_{t}=\lambda I_{Kd}+\sum_{s=1}^{t-1}\Sigma_{s}\otimes\mathbf{x}_{s} \mathbf{x}_{s}^{\top}.\]

_Then for any \(\delta\in(0,1]\), we have_

\[\Pr\left[\exists t>1,\left\|S_{t}\right\|_{H_{t}^{-1}}\geq\frac{\sqrt{ \lambda}}{4}+\frac{4}{\sqrt{\lambda}}\log\left(\frac{\left|H_{t}\right|^{1/2} }{\delta\lambda^{Kd/2}}\right)+\frac{4}{\sqrt{\lambda}}Kd\log(2)\right]\leq\delta.\]

Lemma 6 is a counterpart of the variance-aware self-normalized tail inequality [8, Theorem 1] for the multinomial case. In comparison with the previously established result by [11], our inequality more effectively leverages the geometric structure of the noise in the multinomial logistic bandit problem, as indicated by the condition \(\|\boldsymbol{\varepsilon}_{t}\|_{1}\leq 2\). The previous paper's condition, \(\|\boldsymbol{\varepsilon}_{t}\|_{2}\leq\sqrt{K}\), is relatively loose, ultimately resulting in an additional \(O(\sqrt{K})\) term in the concentration inequality. Then, we introduce the main proof of Theorem 1

Proof of Theorem 1.: The optimality of the MLE estimator indicates that \(\mathbf{g}_{t}(\overrightarrow{W}_{t}^{\text{MLE}})=\nabla\mathcal{L}_{t}( \overrightarrow{W}_{t}^{\text{MLE}})=\mathbf{0}\). In such a case, we have

\[\mathbf{g}_{t}(W_{t}^{\text{MLE}})-\mathbf{g}_{t}(W_{*})=-\mathbf{g}_{t}(W_{ *})=\sum_{s=1}^{t-1}(\boldsymbol{\sigma}(W_{*}\mathbf{x}_{s})-\mathbf{y}_{s}) \otimes\mathbf{x}_{s}-\lambda\overrightarrow{W}_{*}=\sum_{s=1}^{t-1} \boldsymbol{\varepsilon}_{s}\otimes\mathbf{x}_{s}-\lambda\overrightarrow{W}_ {*},\]

where \(\boldsymbol{\varepsilon}_{s}=\boldsymbol{\sigma}(W_{*}\mathbf{x}_{s})- \mathbf{y}_{s}\) is the noise with bounded \(L_{\infty}\) norm as we have \(\|\boldsymbol{\varepsilon}_{s}\|_{\infty}\leq\|\boldsymbol{\sigma}(W_{*} \mathbf{x}_{s})\|_{\infty}+\|\mathbf{y}_{s}\|_{\infty}\leq 2\). Then, we can bound the gap between \(\overrightarrow{W}_{t}^{\text{MLE}}\) and \(\overrightarrow{W}_{*}^{*}\) by

\[\|\mathbf{g}_{t}(W_{t}^{\text{MLE}})-\mathbf{g}_{t}(W_{*})\|_{H_ {t}^{-1}(W_{*})} \leq\left\|\sum_{s=1}^{t-1}\boldsymbol{\varepsilon}_{s}\otimes \mathbf{x}_{s}\right\|_{H_{t}^{-1}(W_{*})}+\|\lambda\overrightarrow{W}_{*}\|_{ H_{t}^{-1}(W_{*})}\] \[\leq\left\|\sum_{s=1}^{t-1}\boldsymbol{\varepsilon}_{s}\otimes \mathbf{x}_{s}\right\|_{H_{t}^{-1}(W_{*})}+\sqrt{\lambda}S\] \[\leq\frac{\sqrt{\lambda}}{4}+\frac{4}{\sqrt{\lambda}}\log\left( \frac{\left|H_{t}\right|^{1/2}}{\delta\lambda^{Kd/2}}\right)+\frac{4}{\sqrt{ \lambda}}Kd\log(2)+\sqrt{\lambda}S,\] (13)

with probability at least \(1-\delta\) for all \(t\geq 1\). In above, the matrix \(H_{t}(W_{*})\) is defined as \(H_{t}(W_{*})=\lambda I_{Kd}+\sum_{s=1}^{t-1}\Sigma(W_{*}\mathbf{x}_{s}) \mathbf{x}_{s}\mathbf{x}_{s}^{\top}\). The first inequality is due to the relationship \(H_{t}^{-1}(W_{*})\preccurlyeq 1/\lambda\cdot I_{Kd}\). The last inequality is by Lemma 6 since

\[\Sigma(W_{*}\mathbf{x}_{s})=\operatorname{diag}(\boldsymbol{\sigma}(W_{*} \mathbf{x}_{s}))-\boldsymbol{\sigma}(W_{*}\mathbf{x}_{s})\boldsymbol{\sigma}(W_ {*}\mathbf{x}_{s})^{\top}=\mathbb{E}[\boldsymbol{\varepsilon}_{s}\boldsymbol{ \varepsilon}_{s}^{\top}\mid\mathcal{F}_{s-1}].\]

Then, we can bound the determinate of \(H_{t}(W_{*})\) by

\[\left|H_{t}\right|\leq\left(\frac{\text{Tr}(H_{t})}{Kd}\right)^{Kd}\leq\left( \frac{\lambda Kd+\sum_{s=1}^{t-1}\sum_{k=1}^{K}\Sigma_{k}(W_{*}\mathbf{x}_{s}) \|\mathbf{x}_{s}\|_{2}}{Kd}\right)^{Kd}\leq(\lambda+t/d)^{Kd}.\] (14)

Plugging (14) into (13), we have

\[\left\|\mathbf{g}_{t}(W_{t}^{\text{MLE}})-\mathbf{g}_{t}(W_{*})\right\|_{H_{t}^ {-1}(W_{*})}\leq\left(\frac{1}{4}+S\right)\sqrt{\lambda}+\frac{2Kd}{\sqrt{ \lambda}}\log\left(1+\frac{t}{\lambda d}\right)+\frac{4Kd}{\sqrt{\lambda}}\log \left(\frac{2}{\delta}\right),\] (15)

By setting

\[\lambda=\frac{4Kd\log(2\left(1+t/d\right)/\delta)}{S+1/4}=\mathcal{O}(dK\log(t/ \delta)),\] (16)

we have

\[\left\|\mathbf{g}_{t}(W_{t}^{\text{MLE}})-\mathbf{g}_{t}(W_{*})\right\|_{H_{t}^ {-1}(W_{*})}\leq beta_{t}(\delta)\triangleq 4\sqrt{Kd(1+S)\log\left(2\left(1+t/d \right)/\delta\right)},\]

which completes the proof.

#### b.1.2 Useful Lemmas

**Lemma 6**.: _Let \(\{\mathcal{F}_{t}\}_{t=1}^{\infty}\) be a filtration. Let \(\{\mathbf{x}_{t}\}_{t=1}^{\infty}\) be a stochastic process in \(\mathcal{B}_{2}(d)\triangleq\{\mathbf{x}\in\mathbb{R}^{d}\mid\|\mathbf{x}_{t}\| _{2}\leq 1\}\) such that \(\mathbf{x}_{t}\) is \(\mathcal{F}_{t}\) measurable. Let \(\{\varepsilon_{t}\}_{t=1}^{\infty}\) be a martingale difference sequence such that \(\boldsymbol{\varepsilon}_{t}\in\mathbb{R}^{K}\) is \(\mathcal{F}_{t+1}\) measurable. Furthermore, assume that conditional on \(\mathcal{F}_{t}\), we have \(\|\boldsymbol{\varepsilon}_{t}\|_{1}\leq 2\) almost surely, and denoted by \(\Sigma_{t}\triangleq\mathbb{E}[\boldsymbol{\varepsilon}_{t}\boldsymbol{ \varepsilon}_{t}^{\top}\mid\mathcal{F}_{t}]\). Let \(\lambda>0\) and for any \(t\geq 1\) define_

\[S_{t}=\sum_{s=1}^{t-1}\boldsymbol{\varepsilon}_{s}\otimes\mathbf{x}_{s}\ \ \text{and}\ \ H_{t}=\lambda I_{Kd}+\sum_{s=1}^{t-1}\Sigma_{s}\otimes\mathbf{x}_{s} \mathbf{x}_{s}^{\top}.\]

_Then for any \(\delta\in(0,1]\), we have_

\[\Pr\left[\exists t>1,\|S_{t}\|_{H_{t}^{-1}}\geq\frac{\sqrt{\lambda}}{4}+ \frac{4}{\sqrt{\lambda}}\log\left(\frac{|H_{t}|^{1/2}}{\delta\lambda^{Kd/2}} \right)+\frac{4}{\sqrt{\lambda}}Kd\log(2)\right]\leq\delta.\]

Proof of Lemma 6.: The proof follows the pipeline in the analysis of the self-normalized tail-inequality in the previous studies [3, 8, 11]. Letting \(\bar{H}_{t}=\sum_{s=1}^{t-1}\Sigma_{s}\otimes\mathbf{x}_{s}\mathbf{x}_{s}^{ \top}\), we define the function

\[M_{t}(\boldsymbol{\xi})\triangleq\exp(\boldsymbol{\xi}^{\top}S_{t}-\| \boldsymbol{\xi}\|_{\bar{H}_{t}}^{2}),\]

for any \(t\geq 1\) and \(\boldsymbol{\xi}\in\mathbb{R}^{Kd}\). For \(t=0\), let \(M_{0}(\boldsymbol{\xi})=0\).

By Lemma 7 in Appendix B.1.2, we can show that \(\{M_{t}(\boldsymbol{\xi})\}_{t=1}^{\infty}\) is a non-negative super-martingale for any \(\boldsymbol{\xi}\in\frac{1}{2}\mathcal{B}_{2}(Kd)\). We note that our Lemma 7 is an improved version of Lemma 7 in [11], which relaxs restriction on the feasible domain of \(\boldsymbol{\xi}\) from \(\boldsymbol{\xi}\in\frac{1}{\sqrt{K}}\mathcal{B}_{2}(Kd)\) to \(\boldsymbol{\xi}\in\frac{1}{2}\mathcal{B}_{2}(Kd)\), resulting in saving an \(\mathcal{O}(\sqrt{K})\) factor in the bound.

Then, let \(h(\boldsymbol{\xi})\) be a probability density with support on \(\frac{1}{2}\mathcal{B}_{2}(Kd)\) and define

\[\bar{M}_{t}\triangleq\int_{\boldsymbol{\xi}}M_{t}(\boldsymbol{\xi})\mathrm{d} h(\boldsymbol{\xi})=\int_{\boldsymbol{\xi}}\exp(\boldsymbol{\xi}^{\top}S_{t}-\| \boldsymbol{\xi}\|_{\bar{H}_{t}}^{2})\mathrm{d}h(\boldsymbol{\xi})\]

for all \(t\geq 1\). Lemma 20.3 of [15] shows that \(\bar{M}_{t}\) is also a non-negative super-martingale and \(\mathbb{E}[\bar{M}_{0}]=1\). Then, the maximal inequality (Theorem 3.9 of [15]) shows that

\[\text{Pr}\left[\sup_{t\in\mathbb{N}}\log(\bar{M}_{t})\geq\log\left(\frac{1}{ \delta}\right)\right]=\text{Pr}\left[\sup_{t\in\mathbb{N}}\bar{M}_{t}\geq\frac {1}{\delta}\right]\leq\delta.\] (17)

Next, we turn to exam the formulation of \(\bar{M}_{t}\) and subsequently establish a connection with the term we aim to bound, \(\|S_{t}\|_{H_{t}^{-1}}\). Let \(h(\boldsymbol{\xi})\) be the density of an isotropic normal distribution with precision matrix \(2\lambda I_{Kd}\) truncated on \(\frac{1}{2}\mathcal{B}_{2}(Kd)\) and \(N(h)\) be its normalization constant. Furthermore, let \(g(\boldsymbol{\xi})\) be the density of the normal distribution with precision matrix \(2H_{t}\) that is truncated on the ball \(\frac{1}{4}\mathcal{B}_{2}(Kd)\). Following the arguments in the proof of [8, Theorem 1] (more precisely the arguments in deriving Eq.(11) in [8]), for any \(t\geq 1\), one can show that

\[\bar{M}_{t}\geq\exp(\boldsymbol{\xi}^{\top}S_{t}-\|\boldsymbol{\xi}\|_{H_{t}}^ {2})\cdot\frac{N(g)}{N(h)}.\]

for any \(\boldsymbol{\xi}\in\frac{1}{4}\mathcal{B}_{2}(Kd)\). Let \(\boldsymbol{\xi}_{0}\triangleq\frac{H_{t}^{-1}S_{t}}{\|S_{t}\|_{H_{t}^{-1}}} \cdot\frac{\sqrt{\lambda}}{4}\). One can check \(\|\boldsymbol{\xi}_{0}\|_{2}\leq\frac{1}{\sqrt{\lambda}}\cdot\frac{\sqrt{ \lambda}}{4}\leq 1/4\). Then, we can further have

\[\log(\bar{M}_{t})\geq\boldsymbol{\xi}_{0}^{\top}S_{t}-\|\boldsymbol{\xi}_{0}\|_ {H_{t}}^{2}+\log\left(\frac{N(g)}{N(h)}\right)=\frac{\sqrt{\lambda}}{4}\|S_{t} \|_{H_{t}^{-1}}-\frac{\lambda}{16}+\log\left(\frac{N(g)}{N(h)}\right).\] (18)

Combining (17) and (18), for any \(t\geq 1\), we have

\[\text{Pr}\left[\|S_{t}\|_{H_{t}^{-1}}\leq\frac{\sqrt{\lambda}}{4}+\frac{4}{ \sqrt{\lambda}}\log\left(\frac{N(h)}{\delta N(g)}\right)\right]\geq 1-\delta.\]

We complete the proof with Lemma 6 of [8] such that

\[\log\left(\frac{N(h)}{N(g)}\right)\leq\log\left(\frac{|H_{t}|^{1/2}}{\lambda^{Kd /2}}\right)+Kd\log(2).\]

**Lemma 7**.: _For all \(\bm{\xi}\in\frac{1}{2}\mathcal{B}_{2}(Kd)\), the sequence \(\{M_{t}(\bm{\xi})\}_{t=1}^{\infty}\) is a non-negative super-martingale._

Proof of Lemma 7.: To show that \(\{M_{t}(\bm{\xi})\}_{t=1}^{\infty}\) is a non-negative super-martingale, it is sufficient to prove \(\mathbb{E}[M_{t+1}(\bm{\xi})\,|\,\mathcal{F}_{t}]\leq M_{t}(\bm{\xi})\) for any \(t>1\) and \(\bm{\xi}\in\frac{1}{2}\mathcal{B}_{2}(Kd)\). By the definition of \(M_{t+1}(\bm{\xi})\), we have

\[\mathbb{E}[M_{t+1}(\bm{\xi})\,|\,\mathcal{F}_{t}] =\mathbb{E}\left[\exp(\bm{\xi}^{\top}S_{t+1}-\|\bm{\xi}\|_{H_{t+1} ^{\top}}^{2})\,|\,\mathcal{F}_{t}\right]\] \[=\mathbb{E}\left[\exp(\bm{\xi}^{\top}(\bm{\varepsilon}_{t}\otimes \mathbf{x}_{t})-\bm{\xi}^{\top}(\Sigma_{t}\otimes\mathbf{x}_{t}\mathbf{x}_{t}^ {\top})\bm{\xi})\,|\,\mathcal{F}_{t}\right]M_{t}(\bm{\xi})\] \[=\mathbb{E}\left[\exp(\bm{\varepsilon}_{t}^{\top}(I_{K}\otimes \mathbf{x}_{t}^{\top})\bm{\xi}-\bm{\xi}^{\top}(\Sigma_{t}\otimes\mathbf{x}_{t} \mathbf{x}_{t}^{\top})\bm{\xi})\,|\,\mathcal{F}_{t}\right]M_{t}(\bm{\xi}).\] (19)

Let \(\bm{\xi}=[\bm{\xi}_{1};\ldots;\bm{\xi}_{K}]\) and \(\bm{\xi}_{k}\in\mathbb{R}^{d}\) is the vector containing \((k-1)d+1\)-th to \(kd\)-th elements of \(\bm{\xi}\). We can further check that

\[|\bm{\varepsilon}_{t}^{\top}(I_{K}\otimes\mathbf{x}_{t}^{\top})\bm{\xi}|\leq \|\bm{\varepsilon}_{t}\|_{1}\cdot\|(I_{K}\otimes\mathbf{x}_{t}^{\top})\bm{\xi} \|_{\infty}=\|\bm{\varepsilon}_{t}\|_{1}\cdot\max_{k\in K}\bm{\xi}_{k}^{\top} \mathbf{x}_{t}|\leq 1,\]

where the first inequality is due to the Holer's inequality. The last inequality is by the condition \(\|\bm{\varepsilon}_{t}\|_{1}\leq 2\) and \(\|\bm{\xi}_{k}\|_{2}\leq\|\bm{\xi}\|_{2}\leq 1/2\) for any \(k\in[K]\). Then, we can further bound the expectation term in (19) by

\[\mathbb{E}\left[\exp(\bm{\varepsilon}_{t}^{\top}(I_{K}\otimes \mathbf{x}_{t}^{\top})\bm{\xi}-\bm{\xi}^{\top}(\Sigma_{t}\otimes\mathbf{x}_{t} \mathbf{x}_{t}^{\top})\bm{\xi})\,|\,\mathcal{F}_{t}\right]\] \[=\mathbb{E}\left[\exp(\bm{\varepsilon}_{t}^{\top}(I_{K}\otimes \mathbf{x}_{t}^{\top})\bm{\xi})\,|\,\mathcal{F}_{t}\right]\cdot\exp(-\bm{\xi} ^{\top}(\Sigma_{t}\otimes\mathbf{x}_{t}\mathbf{x}_{t}^{\top})\bm{\xi})\] \[\leq\,\exp(\bm{\xi}^{\top}(I_{K}\otimes\mathbf{x}_{t})\Sigma_{t }(I_{K}\otimes\mathbf{x}_{t}^{\top})\bm{\xi})\cdot\exp(-\bm{\xi}^{\top}(\Sigma _{t}\otimes\mathbf{x}_{t}\mathbf{x}_{t}^{\top})\bm{\xi})\] \[=\,\exp(\bm{\xi}^{\top}(\Sigma_{t}\otimes\mathbf{x}_{t}\mathbf{x} _{t}^{\top})\bm{\xi})\cdot\exp(-\bm{\xi}^{\top}(\Sigma_{t}\otimes\mathbf{x}_ {t}\mathbf{x}_{t}^{\top})\bm{\xi})=1,\]

where the first inequality is due to Lemma 8 and the last equality is due to mixed-product property of the Kronecker product. Therefore, we can show \(\mathbb{E}[M_{t+1}(\bm{\xi})\,|\,\mathcal{F}_{t}]\leq M_{t}(\bm{\xi})\) and complete the proof.

**Lemma 8** (Lemma 6 of [11]).: _Let \(\bm{\varepsilon}\in\mathbb{R}^{K}\) be a zero-mean random vector with covariance matrix \(\Sigma\). Then, for any vector \(\mathbf{a}\in\mathbb{R}^{K}\) such that \(|\bm{\varepsilon}^{\top}\mathbf{a}|\leq 1\), we have \(\mathbb{E}[\exp(\bm{\varepsilon}^{\top}\mathbf{a})]\leq\exp(\mathbf{a}^{\top} \Sigma\mathbf{a})\)._

### Proof of Theorem 2

This section provides the proof for Theorem 2.

#### b.2.1 Main Proof

Proof of Theorem 2.: We prove the proposed algorithm can achieve \(\mathcal{O}(d\log T\sqrt{\kappa KT})\) and \(\mathcal{O}(dK\log T\sqrt{T}+\kappa d^{2}K^{2}\log^{2}T)\) bounds simultaneously. Before presenting the proofs, we introduce two matrix that measures the local curvature of the loss function and will be used in the rest part of the proof:

\[A(\mathbf{x},W_{1},W_{2})=\int_{v=0}^{1}\nabla\bm{\sigma}(vW_{1} \mathbf{x}+(1-v)W_{2}\mathbf{x})\mathrm{d}v;\] (20) \[G_{t}(W_{1},W_{2})=\lambda I_{Kd}+\sum_{s=1}^{t-1}A(\mathbf{x}_{ s},W_{1},W_{2})\otimes\mathbf{x}_{s}\mathbf{x}_{s}^{\top}.\] (21)

Analysis for the \(\mathcal{O}(d\log T\sqrt{\kappa KT})\) Bound.The regret can be bounded by

\[\mathrm{Reg}_{T} =\,\sum_{t=1}^{T}\bm{\rho}^{\top}\bm{\sigma}(W_{*}\mathbf{x}_{*} )-\sum_{t=1}^{T}\bm{\rho}^{\top}\bm{\sigma}(W_{*}\mathbf{x}_{t})\] \[\leq\,\sum_{t=1}^{T}\bm{\rho}^{\top}\bm{\sigma}(W_{t}^{\texttt{ OPT}}\mathbf{x}_{t})-\sum_{t=1}^{T}\bm{\rho}^{\top}\bm{\sigma}(W_{*} \mathbf{x}_{t})\] \[=\,\sum_{t=1}^{T}\bm{\rho}^{\top}A(\mathbf{x}_{t},W_{*},W_{t}^{ \texttt{OPT}})(W_{t}^{\texttt{OPT}}-W_{*})\mathbf{x}_{t}\]\[\leq \sum_{t=1}^{T}\lVert(W_{t}^{\texttt{OPT}}-W_{*})\mathbf{x}_{t} \rVert_{A(\mathbf{x}_{t},W_{*},W_{t}^{\texttt{OPT}})}\] \[\leq \sum_{t=1}^{T}\lVert(W_{t}^{\texttt{OPT}}-W_{*})\mathbf{x}_{t} \rVert_{A(\mathbf{x}_{t},W_{*},W_{t}^{\texttt{OPT}})}\] \[\leq R\sum_{t=1}^{T}\lVert(W_{t}^{\texttt{OPT}}-W_{*})\mathbf{x}_ {t}\rVert_{A(\mathbf{x}_{t},W_{*},W_{t}^{\texttt{OPT}})}\]

In the above, the term \(A(\mathbf{x}_{t},W_{*},W_{t}^{\texttt{OPT}})\) is defined as (20) and the first inequality is a consequence of the optimistic rule (5) such that \((\mathbf{x}_{t},W_{t}^{\texttt{OPT}})=\arg\max_{\mathbf{x}_{\in}\mathcal{X},W \in C_{t}(\delta)}\boldsymbol{\rho}^{\top}\boldsymbol{\sigma}(W\mathbf{x})\) and the first equality is due to the mean value theorem for the vector valued function. The second inequality is due to the Cauchy-Schwarz inequality and we can obtain the the last second inequality by the fact \(\nabla\boldsymbol{\sigma}(\mathbf{z})\preccurlyeq I_{K}\) for any \(\mathbf{z}\in\mathbb{R}^{K}\). The last inequality is due to Assumption 2.

Let \(G_{t}^{-\frac{1}{2}}(W_{1},W_{2})\) be defined as (21). We can proceed to handle the gap between \(W_{t}^{\texttt{OPT}}\) and \(W_{*}\) by

\[\sum_{t=1}^{T}\lVert(W_{t}^{\texttt{OPT}}-W_{*})\mathbf{x}_{t} \rVert_{A(\mathbf{x}_{t},W_{*},W_{t}^{\texttt{OPT}})}\] \[\leq \sum_{t=1}^{T}\lVert(W_{t}^{\texttt{OPT}}-W_{*})\mathbf{x}_{t} \rVert_{2}\] \[= \sum_{t=1}^{T}\lVert(I_{K}\otimes\mathbf{x}_{t}^{\top})\cdot( \overrightarrow{W}_{t}^{\texttt{OPT}}-\overrightarrow{W}_{*})\rVert_{2}\] \[= \sum_{t=1}^{T}\lVert(I_{K}\otimes\mathbf{x}_{t}^{\top})G_{t}^{- \frac{1}{2}}(W_{*},W_{t}^{\texttt{OPT}})\cdot G_{t}^{\frac{1}{2}}(W_{*},W_{t} ^{\texttt{OPT}})(\overrightarrow{W}_{t}^{\texttt{OPT}}-\overrightarrow{W}_{* })\rVert_{2}\] \[\leq \sum_{t=1}^{T}\lVert(I_{K}\otimes\mathbf{x}_{t}^{\top})G_{t}^{- \frac{1}{2}}(W_{*},W_{t}^{\texttt{OPT}})\rVert_{2}\cdot\lVert G_{t}^{\frac{1 }{2}}(W_{*},W_{t}^{\texttt{OPT}})(\overrightarrow{W}_{t}^{\texttt{OPT}}- \overrightarrow{W}_{*})\rVert_{2}\] \[\leq \sum_{t=1}^{T}\lVert(I_{K}\otimes\mathbf{x}_{t}^{\top})\bar{V}_{t }^{-\frac{1}{2}}\rVert_{2}\cdot\lVert G_{t}^{\frac{1}{2}}(W_{*},W_{t}^{ \texttt{OPT}})(\overrightarrow{W}_{t}^{\texttt{OPT}}-\overrightarrow{W}_{* })\rVert_{2}\] \[\leq \underbrace{\sqrt{\sum_{t=1}^{T}\lVert(I_{K}\otimes\mathbf{x}_{t} ^{\top})\bar{V}_{t}^{-\frac{1}{2}}\rVert_{2}}}_{\texttt{term}\;(\mathbf{a})} \cdot\underbrace{\sqrt{\sum_{t=1}^{T}\lVert G_{t}^{\frac{1}{2}}(W_{*},W_{t}^{ \texttt{OPT}})(\overrightarrow{W}_{t}^{\texttt{OPT}}-\overrightarrow{W}_{* })\rVert_{2}^{2}}}_{\texttt{term}\;(\mathbf{b})}.\] (22)

where the first inequality is due to the fact \(A(\mathbf{x}_{t},W_{*},W_{t}^{\texttt{OPT}})\preccurlyeq I_{K}\) and the second inequality is due to the Cauchy-Schwarz inequality. Since both \(W_{*},W_{t}^{\texttt{OPT}}\in\mathcal{W}\), the third inequality is by the condition \(G_{t}(W_{*},W_{t}^{\texttt{OPT}})\succcurlyeq\bar{V}_{t}\triangleq\lambda I_{ Kd}+\frac{1}{\kappa}\sum_{s=1}^{t-1}I_{K}\otimes\mathbf{x}_{s}\mathbf{x}_{s}^{\top}\). We can show the last inequality by using Cauchy-Schwarz inequality again.

Then, we proceed to bound term (a) and term (b) respectively.

\[\texttt{term}\;(\mathbf{a}) =\sqrt{\sum_{t=1}^{T}\lVert(I_{K}\otimes\mathbf{x}_{t}^{\top})\bar {V}_{t}^{-\frac{1}{2}}\rVert_{2}^{2}}\] \[=\sqrt{\sum_{t=1}^{T}\lambda_{\max}((I_{K}\otimes\mathbf{x}_{t}^{ \top})\bar{V}_{t}^{-1}(I_{K}\otimes\mathbf{x}_{t}))}\] \[=\sqrt{\sum_{t=1}^{T}\lambda_{\max}((I_{K}\otimes\mathbf{x}_{t}^{ \top})\left(I_{K}\otimes\left(\lambda I_{d}+\frac{1}{\kappa}\sum_{s=1}^{t-1} \mathbf{x}_{s}\mathbf{x}_{s}^{\top}\right)\right)^{-1}(I_{K}\otimes\mathbf{x} _{t}))}\]\[=\sqrt{\sum_{t=1}^{T}\lambda_{\max}\left(I_{K}\otimes\mathbf{x}_{t}^{ \top}\bigg{(}\lambda I_{d}+\frac{1}{\kappa}\sum_{s=1}^{t-1}\mathbf{x}_{s} \mathbf{x}_{s}^{\top}\bigg{)}^{-1}\mathbf{x}_{t}\right)}\] \[=\sqrt{\sum_{t=1}^{T}\mathbf{x}_{t}^{\top}\bigg{(}\lambda I_{d}+ \frac{1}{\kappa}\sum_{s=1}^{t-1}\mathbf{x}_{s}\mathbf{x}_{s}^{\top}\bigg{)}^{- 1}\mathbf{x}_{t}}\] \[\leq\sqrt{\kappa d\log\left(1+\frac{T}{\kappa\lambda d}\right)}\] (23)

In above, we denote by \(\lambda_{\max}\) the maximum eigenvalue of the input matrix. The second inequality is due to the property of the maximum eigenvalue such that \(\lambda_{\max}(ABC)=\lambda_{\max}(BCA)\) for matrix \(A,B\) and \(C\). The last second equality is due to the mixed product property of the the Kronecker product and \((A\otimes B)^{-1}=A^{-1}\otimes B^{-1}\) for matrix \(A\) and \(B\). In the last inequality, we can bound the term with the standard arguments of the elliptical potential lemma [3, Lemma 11].

It remains to bound term (b). Since Theorem 1 shows that \(W_{*}\in\mathcal{C}_{t}(\delta)\) with probability at least \(1-\delta\) for all \(t>1\) and the optimistic rule (5) ensures \(W_{t}^{\texttt{OPT}}\in\mathcal{C}_{t}(\delta)\), Lemma 9 in Appendix B.2.2 indicates that the distance between \(W_{*}\) and \(W_{t}^{\texttt{OPT}}\) can be bounded by

\[\|G_{t}^{\frac{1}{2}}(W_{*},W_{t}^{\texttt{OPT}})(\overrightarrow{W}_{t}^{ \texttt{OPT}}-\overrightarrow{W}_{*})\|_{2}\leq 2\sqrt{1+2S}\beta_{t}(\delta).\]

Then, plugging the above displayed equation into term (b), we can bound this term by

\[\texttt{term}\;(\texttt{b})\leq 2\sqrt{1+2S}\sqrt{\sum_{t=1}^{T}(\beta_{t}( \delta))^{2}}\leq 2\sqrt{(1+2S)T}\beta_{T}(\delta)=\mathcal{O}(\sqrt{dTK \log(T/\delta)}),\]

where the last inequality holds because \(\beta_{t}(\delta)\) is a non-decreasing function with respect to \(t\). A combination of the upper bound for term (a) and term (b) leads to

\[\mathrm{Reg}_{T}\leq 8(1+2S)Rd\sqrt{\kappa KT\cdot\log\Big{(}\frac{2(1+T/d)}{ \delta}\Big{)}\cdot\log\Big{(}1+\frac{T}{\kappa d}\Big{)}}=\mathcal{O}(d\log T \sqrt{\kappa KT}).\]

Analysis for the \(\mathcal{O}(Kd\log T\sqrt{T}+\kappa Kd^{2}\log^{2}T)\) Bound.Inspired by the analysis for binary logistic bandit problem [9, Appendix C], we employ a different decomposition compared to the one used in the first part of the analysis

\[\mathrm{Reg}_{T} = \sum_{t=1}^{T}\sum_{k=1}^{K}\rho_{k}(\sigma_{k}(W_{*}\mathbf{x}_{ *})-\sigma_{k}(W_{*}\mathbf{x}_{t}))\] \[\leq \sum_{t=1}^{T}\sum_{k=1}^{K}\rho_{k}(\sigma_{k}(W_{t}^{\texttt{OPT }}\mathbf{x}_{t})-\sigma_{k}(W_{*}\mathbf{x}_{t}))\] \[= \sum_{t=1}^{T}\sum_{k=1}^{K}\rho_{k}\nabla\sigma_{k}(W_{*} \mathbf{x}_{t})^{\top}(W_{t}^{\texttt{OPT}}-W_{*})\mathbf{x}_{t}+\sum_{k=1}^{ K}\rho_{k}\|(W_{t}^{\texttt{OPT}}-W_{*})\mathbf{x}_{t}\|_{\Xi_{k,t}}^{2}\] \[\leq \underbrace{\sum_{t=1}^{T}\left|\sum_{k=1}^{K}\rho_{k}\nabla \sigma_{k}(W_{*}\mathbf{x}_{t})^{\top}(W_{t}^{\texttt{OPT}}-W_{*})\mathbf{x} _{t}\right|}_{\texttt{term}\;(\texttt{c})}+\underbrace{\sum_{t=1}^{T}\left| \sum_{k=1}^{K}\rho_{k}\|(W_{t}^{\texttt{OPT}}-W_{*})\mathbf{x}_{t}\|_{\Xi_{k,t }}^{2}\right|}_{\texttt{term}\;(\texttt{d})},\]

where \(\sigma_{k}:\mathbf{x}\mapsto[\boldsymbol{\sigma}(\mathbf{x})]_{k}\) is the \(k\)-th output of the vector-valued function \(\boldsymbol{\sigma}(\mathbf{x})\) and \(\Xi_{k,t}=\int_{\nu=0}^{1}(1-\nu)\nabla^{2}\sigma_{k}((W_{*}+\nu(W_{t}^{ \texttt{OPT}}-W_{*}))\mathbf{x}_{t})\mathrm{d}\nu\). In the above, the first inequality is due to the optimistic rule (5) and the last equality is due to the integral formulation of the Taylor series. Then, we proceed to handle term (c) and term (d) respectively.

As for term (c), we have

\[\texttt{term}\;(\texttt{c})=\sum_{t=1}^{T}\left|\boldsymbol{\rho}\nabla \boldsymbol{\sigma}(W_{*}\mathbf{x}_{t})^{\top}(\overrightarrow{W}_{t}^{ \texttt{OPT}}-\overrightarrow{W}_{*})\mathbf{x}_{t}\right|\]\[= \sum_{t=1}^{T}\left|\boldsymbol{\rho}\nabla\boldsymbol{\sigma}(W_{*} \mathbf{x}_{t})^{\top}(I_{K}\otimes\mathbf{x}_{t}^{\top})(\overrightarrow{W}_{t }^{\texttt{OPT}}-\overrightarrow{W}_{*})\right|\] \[= \sum_{t=1}^{T}\left|\boldsymbol{\rho}\nabla\boldsymbol{\sigma}(W_ {*}\mathbf{x}_{t})^{\top}(I_{K}\otimes\mathbf{x}_{t}^{\top})G_{t}^{-\frac{1}{2 }}(W_{*},W_{t}^{\texttt{OPT}})\cdot G_{t}^{\frac{1}{2}}(W_{*},W_{t}^{\texttt{ OPT}})(\overrightarrow{W}_{t}^{\texttt{OPT}}-\overrightarrow{W}_{*})\right|\] \[\leq \sum_{t=1}^{T}\lVert\overrightarrow{W}_{t}^{\texttt{OPT}}- \overrightarrow{W}_{*}\rVert_{G_{t}(W_{*},W_{t}^{\texttt{OPT}})}\cdot\lVert G _{t}^{-\frac{1}{2}}(W_{*},W_{t}^{\texttt{OPT}})(I_{K}\otimes\mathbf{x}_{t}) \nabla\boldsymbol{\sigma}(W_{*}\mathbf{x}_{t})\boldsymbol{\rho}\rVert_{2}\] \[\leq 2\sqrt{1+2S}\beta_{T}(\delta)\sum_{t=1}^{T}\lVert G_{t}^{- \frac{1}{2}}(W_{*},W_{t}^{\texttt{OPT}})(I_{K}\otimes\mathbf{x}_{t})\nabla \boldsymbol{\sigma}(W_{*}\mathbf{x}_{t})\boldsymbol{\rho}\rVert_{2},\] (24)

where the first inequality holds by Cauchy-Schwarz inequality and the last one is due to Lemma 9.

Let \(\lambda_{\max}(\cdot)\) denote the maximum eigenvalue of the matrix. We can further bound (24) by

\[\sum_{t=1}^{T}\lVert G_{t}^{-\frac{1}{2}}(W_{*},W_{t}^{\texttt{ OPT}})(I_{K}\otimes\mathbf{x}_{t})\nabla\boldsymbol{\sigma}(W_{*}\mathbf{x}_{t}) \boldsymbol{\rho}\rVert_{2}\] \[\leq \sum_{t=1}^{T}\lVert\nabla\boldsymbol{\sigma}^{\frac{1}{2}}(W_{* }\mathbf{x}_{t})\boldsymbol{\rho}\rVert_{2}\cdot\lVert G_{t}^{-\frac{1}{2}}(W_ {*},W_{t}^{\texttt{OPT}})(I_{K}\otimes\mathbf{x}_{t})\nabla\boldsymbol{\sigma} ^{\frac{1}{2}}(W_{*}\mathbf{x}_{t})\rVert_{2}\] \[\leq R\sum_{t=1}^{T}\sqrt{\lambda_{\max}\bigg{(}(\nabla \boldsymbol{\sigma}^{\frac{1}{2}}(W_{*}\mathbf{x}_{t})\otimes\mathbf{x}_{t}^{ \top})G_{t}^{-1}(W_{*},W_{t}^{\texttt{OPT}})(\nabla\boldsymbol{\sigma}^{ \frac{1}{2}}(W_{*}\mathbf{x}_{t})\otimes\mathbf{x}_{t})\bigg{)}}\] \[= R\sum_{t=1}^{T}\sqrt{\lambda_{\max}\bigg{(}(\nabla\boldsymbol{ \sigma}(W_{*}\mathbf{x}_{t})\otimes\mathbf{x}_{t}\mathbf{x}_{t}^{\top})G_{t}^ {-1}(W_{*},W_{t}^{\texttt{OPT}})\bigg{)}}\] \[\leq R\sqrt{T}\sqrt{(1+2S)Kd\ln\left(1+\frac{T}{2\lambda}\right)}\] (25)

where the first inequality is due to the fact that \(\lVert A\mathbf{b}\rVert_{2}\leq\lVert A\rVert_{2}\cdot\lVert\mathbf{b}\rVert\) for a matrix \(A\) and vector \(\mathbf{b}\). The second inequality is due to the definition of the induced norm \(\lVert A\rVert_{2}=\sqrt{\lambda_{\max}(A^{T}A)}\) and the mixed-product property of the Kronecker production. The last equality is due to the cycle property of the maximum eigenvalue such that \(\lambda_{\max}(ABC)=\lambda_{\max}(CAB)\) for matrices \(A,B\) and \(C\) and we use the mixed-product property again. The last inequality is due to Lemma 10 in Appendix B.2.2.

Combining (24) and (25), we arrive

\[\texttt{term}\left(\mathtt{c}\right)\leq 8R(1+2S)^{\frac{3}{2}}dK\sqrt{T \cdot\log\Big{(}\frac{2(1+t/d)}{\delta}\Big{)}\cdot\log\Big{(}1+\frac{T}{2d} \Big{)}}=\mathcal{O}(dK\log T\sqrt{T}).\] (26)

Then, we turn to handle term (d). Lemma 11 indicates that

\[\Xi_{k,t}=\int_{\nu=0}^{1}(1-\nu)\nabla^{2}\sigma_{k}((W_{*}+\nu(W_{t}^{ \texttt{OPT}}-W_{*}))\mathbf{x}_{t})\mathrm{d}\nu\preccurlyeq 3I_{K}\int_{\nu=0}^{1}(1- \nu)\mathrm{d}\nu\preccurlyeq 3I_{K}.\] (27)

As a consequence, we can bound term (d) by

\[\texttt{term}\left(\mathtt{d}\right) = \sum_{t=1}^{T}\left|\sum_{k=1}^{K}\rho_{k}\lVert(W_{t}^{\texttt{ OPT}}-W_{*})\mathbf{x}_{t}\rVert_{\Xi_{k,t}}^{2}\right|\] \[\leq 3\sum_{t=1}^{T}\left|\sum_{k=1}^{K}\rho_{k}\lVert(W_{t}^{ \texttt{OPT}}-W_{*})\mathbf{x}_{t}\rVert_{2}^{2}\right|\]\[\leq 3R\sum_{t=1}^{T}\lVert(W_{t}^{\texttt{OPT}}-W_{*})\mathbf{x}_{t} \rVert_{2}^{2}\] \[\leq 3R\beta_{T}^{2}(\delta)\sum_{t=1}^{T}\lVert(I_{K}\otimes \mathbf{x}_{t}^{\top})\bar{V}_{t}^{-\frac{1}{2}}\rVert_{2}^{2}\] \[\leq 3R\beta_{T}^{2}(\delta)\kappa d\log\left(1+\frac{T}{\kappa \lambda d}\right)\]

where the first inequality is due to Assumption 2 and the second inequality is due to (27). The last second inequality can be obtained by a similar argument in obtaining (22). The last inequality can be obtained by the same argument as (23).

Combining (26) and (26), we obtain

\[\operatorname{Reg}_{T} \leq 8R(1+2S)^{\frac{3}{2}}dK\sqrt{T\cdot\log\left(\frac{2(1+T/d)}{ \delta}\right)\cdot\log\left(1+\frac{T}{2d}\right)}\] \[\qquad+48R(1+S)\kappa Kd^{2}\log\left(\frac{2(1+T/d)}{\delta} \right)\cdot\log\left(1+\frac{T}{2d}\right)\] \[=\mathcal{O}(dK\log T\sqrt{T}+\kappa d^{2}K\log^{2}T).\]

We have completed the proof. 

#### b.2.2 Useful Lemma

This section provides the lemmas used in the main proof.

**Lemma 9**.: _If \(W_{*}\in\mathcal{C}_{t}(\delta)\), then for all \(W\in\mathcal{C}_{t}(\delta)\):_

\[\lVert G_{t}^{\frac{1}{2}}(W_{*},W)(\overrightarrow{W}-\overrightarrow{W}_{* })\rVert_{2}\leq 2\sqrt{1+2S}\beta_{t}(\delta),\]

_where \(\beta_{t}(\delta)=4\sqrt{Kd(1+S)\log\left(2\left(1+t/d\right)/\delta\right)}= \mathcal{O}(\sqrt{dK\log t})\) is defined in Theorem 1._

Proof of Lemma 9.: Lemma 3 in [11] shows that

\[\mathbf{g}_{t}(\overrightarrow{W}_{*})-\mathbf{g}_{t}(\overrightarrow{W})=G _{t}(W_{*},W)(\overrightarrow{W}_{*}-\overrightarrow{W}),\]

for any \(\overrightarrow{W}\in\mathcal{C}_{t}(\delta)\). Then, we have

\[\lVert G_{t}^{\frac{1}{2}}(W_{*},W)(\overrightarrow{W}- \overrightarrow{W}_{*})\rVert_{2}\] \[=\lVert\mathbf{g}_{t}(\overrightarrow{W}_{*})-\mathbf{g}_{t}( \overrightarrow{W})\rVert_{G_{t}^{-1}(W_{*},W)}\] \[\leq\lVert\mathbf{g}_{t}(\overrightarrow{W}_{*})-\mathbf{g}_{t}( \overrightarrow{W}_{t}^{\texttt{ME}})\rVert_{G_{t}^{-1}(W_{*},W)}+\lVert \mathbf{g}_{t}(\overrightarrow{W})-\mathbf{g}_{t}(\overrightarrow{W}_{t}^{ \texttt{ME}})\rVert_{G_{t}^{-1}(W_{*},W)}\] \[\leq\sqrt{1+2S}\left(\lVert\mathbf{g}_{t}(\overrightarrow{W}_{*} )-\mathbf{g}_{t}(\overrightarrow{W}_{t}^{\texttt{ME}})\rVert_{H_{t}^{-1}(W_{*} )}+\lVert\mathbf{g}_{t}(\overrightarrow{W})-\mathbf{g}_{t}(\overrightarrow{W }_{t}^{\texttt{ME},\texttt{E}})\rVert_{H_{t}^{-1}(W)}\right)\] \[\leq 2\sqrt{1+2S}\beta_{t}(\delta),\]

where the last second inequality is due to generalized self-concordant properties of the logistic loss as shown by Lemma 13 of [11]. The last inequality is due to Theorem 1 and the condition that \(W\) is contained in the confidence set \(\mathcal{C}_{t}(\delta)\). 

**Lemma 10**.: _When the regularization parameter \(\lambda>2\), we have_

\[\sum_{t=1}^{T}\lambda_{\max}\bigg{(}(\nabla\boldsymbol{\sigma}(W_{*}\mathbf{x} _{t})\otimes\mathbf{x}_{t}\mathbf{x}_{t}^{\top})G_{t}^{-1}(W_{*},W_{t}^{ \texttt{OPT}})\bigg{)}\leq(1+2S)Kd\ln\left(1+\frac{T}{2\lambda}\right).\]

Proof of Lemma 10.: Denoting by \(\operatorname{Tr}(A)\) the trace of matrix \(A\), We have

\[\sum_{t=1}^{T}\lambda_{\max}\bigg{(}(\nabla\boldsymbol{\sigma}(W_{*}\mathbf{x }_{t})\otimes\mathbf{x}_{t}\mathbf{x}_{t}^{\top})G_{t}^{-1}(W_{*},W_{t}^{ \texttt{OPT}})\bigg{)}\]\[\leq \sum_{t=1}^{T}\mathrm{Tr}\Big{(}(\nabla\bm{\sigma}(W_{*}\mathbf{x}_{t })\otimes\mathbf{x}_{t}\mathbf{x}_{t}^{\top})G_{t}^{-1}(W_{*},W_{t}^{\texttt{ OPT}})\Big{)}\] \[\leq (1+2S)\sum_{t=1}^{T}\mathrm{Tr}\Big{(}(\nabla\bm{\sigma}(W_{*} \mathbf{x}_{t})\otimes\mathbf{x}_{t}\mathbf{x}_{t}^{\top})H_{t}^{-1}(W_{*}) \Big{)},\]

where the last inequality is due to Lemma 4 of [11] such that \((1+2S)G_{t}(W_{*},W_{t}^{\texttt{OPT}})\succcurlyeq H_{t}(W_{*})\).

Let \(M_{t}(W_{*})=\frac{\lambda}{2}I_{Kd}+\sum_{s=1}^{t}\nabla\bm{\sigma}(W_{*} \mathbf{x}_{s})\otimes\mathbf{x}_{s}\mathbf{x}_{s}^{\top}\). Then, we can further bound the last line of the above displayed equations by

\[(1+2S)\sum_{t=1}^{T}\mathrm{Tr}\Big{(}(\nabla\bm{\sigma}(W_{*} \mathbf{x}_{t})\otimes\mathbf{x}_{t}\mathbf{x}_{t}^{\top})H_{t}^{-1}(W_{*}) \Big{)}\] \[= (1+2S)\sum_{t=1}^{T}\mathrm{Tr}\left(M_{t}(W_{*})-M_{t-1}(W_{*}) \right)H_{t}^{-1}(W_{*})\big{)}\] \[\leq (1+2S)\sum_{t=1}^{T}\mathrm{Tr}\left(M_{t}(W_{*})-M_{t-1}(W_{*}) \right)M_{t}^{-1}(W_{*})\big{)}\] \[\leq (1+2S)\sum_{t=1}^{T}\log\frac{|M_{t}(W_{*})|}{|M_{t-1}(W_{*})|}\] \[\leq (1+2S)Kd\ln\left(1+\frac{T}{2\lambda}\right)\]

The first inequality is by the fact \(H_{t}(W_{*})\succcurlyeq M_{t}(W_{*})\) under the condition \(\lambda\geq 2\). The last second inequality is due to Lemma 4.5 of [16]. 

**Lemma 11**.: _Let \(\sigma_{k}:\mathbf{z}\mapsto[\bm{\sigma}(\mathbf{x})]_{k}\in\mathbb{R}\) by the \(k\)-th output of the vector-valued function \(\bm{\sigma}(\mathbf{z})\). Then, for any \(\mathbf{z}\in\mathbb{R}^{K}\), we have \(\nabla^{2}\sigma_{k}(\mathbf{z})\leq 3I_{K}\) for any \(k\in[K]\)._

Proof of Lemma 11.: For any \(\mathbf{z}\in\mathbb{R}^{K}\), we have

\[3I_{K}-\nabla^{2}\sigma_{k}(\mathbf{z})\] \[= 3I_{K}+\sigma_{k}(\mathbf{z})\cdot\left(\mathrm{diag}(\bm{\sigma }(\mathbf{z}))+\mathbf{e}_{k}\bm{\sigma}(\mathbf{z})^{\top}+\bm{\sigma}( \mathbf{z})\mathbf{e}_{k}^{\top}\right)-2\sigma_{k}\cdot(\mathbf{z})\bm{ \sigma}(\mathbf{z})\bm{\sigma}(\mathbf{z})^{\top}-\sigma_{k}(\mathbf{z})E_{k}\] \[\succcurlyeq 3I_{K}-2\sigma_{k}(\mathbf{z})\bm{\sigma}(\mathbf{z})\bm{ \sigma}(\mathbf{z})^{\top}+\sigma_{k}(\mathbf{z})(\mathbf{e}_{k}\bm{\sigma}( \mathbf{z})^{\top}+\bm{\sigma}(\mathbf{z})\mathbf{e}_{k}^{\top}-E_{k})\] (28) \[= 3I_{K}-\sigma_{k}(\mathbf{z})\bm{\sigma}(\mathbf{z})\bm{\sigma}( \mathbf{z})^{\top}-\sigma_{k}(\mathbf{z})(\bm{\sigma}(\mathbf{z})-\mathbf{e} _{k})(\bm{\sigma}(\mathbf{z})-\mathbf{e}_{k})^{\top}\succcurlyeq 0\] (29)

where we denote by \(E_{k}\) as the matrix where the entry at the \((k,k)\)-th position is 1, and all other entries are 0. In the above, the first inequality is due to the definition of \(\sigma_{k}\). The second inequality holds since \(\mathrm{diag}(\bm{\sigma}(\mathbf{z}))\) is semi-positive defined matrix. The last inequality is a consequence of the fact that the maximum eigenvalue of \(\sigma_{k}(\mathbf{z})\bm{\sigma}(\mathbf{z})\bm{\sigma}(\mathbf{z})^{\top}\) is bounded by \(\sigma_{k}(\mathbf{z})(\bm{\sigma}(\mathbf{z})-\mathbf{e}_{k})(\bm{\sigma}( \mathbf{z})-\mathbf{e}_{k})^{\top}\) is less than \(1\). The maximum eigenvalue of \(\sigma_{k}(\mathbf{z})(\bm{\sigma}(\mathbf{z})-\mathbf{e}_{k})(\bm{\sigma}( \mathbf{z})-\mathbf{e}_{k})^{\top}\) is bounded by 2. 

## Appendix C Omitted Proofs for Section 3

This section presents the omitted details for Section 3. To simplify the notation, we exclude the superscript OL in all the proofs within this section.

### Proof of Theorem 3

This section provides the proof of Theorem 3. We will first provide the main proof of Theorem 3 and the prove the technical lemma used in the main proof.

#### c.1.1 Main Proof

Proof of Theorem 3.: The proof shares the similarity with the online-to-confidence-set conversion technique [47, 14], where the estimation error of the online estimator \(W_{t}^{\text{OL}}\) is bounded by the regret. However, we have introduced a novel algorithm and analysis ingredient to achieve jointly statistical and computation efficiency.

The following lemma provides the estimation error analysis. Drawing inspiration from the modern analysis of OMD [23], we explicitly extract the negative term \(-\sum_{s=1}^{t}\lVert\overrightarrow{W}_{s+1}-\overrightarrow{W}_{s}\rVert_{ H_{s}}^{2}\) in the upper bound, which is pivotal for our subsequent theoretical analysis and the algorithm design.

**Lemma 12**.: _Under Assumptions 1 and 3, we consider the estimator update rule_

\[\overrightarrow{W}_{t+1}=\operatorname*{arg\,min}_{W\in\mathcal{W}}\ \Big{\{}\widetilde{\ell}_{t}(W)+\frac{1}{2\eta}\lVert \overrightarrow{W}-\overrightarrow{W}_{t}\rVert_{H_{t}}^{2}\Big{\}},\]

_where \(\widetilde{\ell}_{t}(W)=\langle\nabla\ell_{t}(\overrightarrow{W}_{t}), \overrightarrow{W}\rangle+\frac{1}{2}\lVert\overrightarrow{W}-\overrightarrow {W}_{t}\rVert_{\nabla^{2}\ell_{t}(\overrightarrow{W}_{t})}^{2}\) and \(H_{t}=\lambda I_{Kd}+\sum_{s=1}^{t-1}\nabla^{2}\ell_{s}(W_{s+1})\otimes \mathbf{x}_{s}\mathbf{x}_{s}^{\top}\). Then, letting \(\alpha=\ln(K+1)+2(S+1)\) and \(\lambda>0\), we have_

\[\lVert\overrightarrow{W}_{t+1}-\overrightarrow{W}_{s}\rVert_{H_ {t+1}}^{2}\leq\alpha\bigg{(} \sum_{s=1}^{t}\ell_{s}(W_{s})-\sum_{s=1}^{t}\ell_{s}(W_{s+1})\bigg{)}+4 \lambda S^{2}\] \[+\sum_{s=1}^{t}\sqrt{6}\alpha S\lVert\overrightarrow{W}_{s+1}- \overrightarrow{W}_{s}\rVert_{I_{K}\otimes\mathbf{x}_{s}\mathbf{x}_{s}^{\top }}^{2}-\sum_{s=1}^{t}\lVert\overrightarrow{W}_{s+1}-\overrightarrow{W}_{s} \rVert_{H_{s}}^{2},\]

_when the step size is set as \(\eta=\alpha/2\)._

Then, we focus on the first term of the right hand side. Inspired by the previous studies on binary logistic bandit [10], we decompose the regret into two part by inserting an intermediate decision.

\[\sum_{s=1}^{t}\ell_{s}(W_{s})-\sum_{s=1}^{t}\ell_{s}(W_{s+1})\] \[= \underbrace{\sum_{s=1}^{t}\ell_{s}(W_{s})-\sum_{s=1}^{t}\ell( \widetilde{\mathbf{z}}_{s},y_{s})}_{\texttt{term (A)}}+\underbrace{\sum_{s=1}^{t}\ell(\widetilde{\mathbf{z}}_{s},y_{s})-\sum_{ s=1}^{t}\ell_{s}(W_{s+1})}_{\texttt{term (B)}},\]

where the \(\widetilde{\mathbf{z}}_{s}\) is an aggregating forecaster for logistic loss defined by \(\widetilde{\mathbf{z}}_{s}=\boldsymbol{\sigma}^{+}\left(\mathbb{E}_{W\sim P_ {s}}[\boldsymbol{\sigma}(W\mathbf{x}_{s})]\right)\) and \(P_{s}=\mathcal{N}(\overrightarrow{W}_{s},(1+cH_{s}^{-1})\) is the Gaussian distribution with mean \(\overrightarrow{W}_{s}\) and covariance matrix \(cH_{s}^{-1}\), where \(c>0\) is a constant to be specified. In above, \(\boldsymbol{\sigma}^{+}:\Delta\mapsto\mathbb{R}^{K}\) is a pseudo-inverse function of \(\boldsymbol{\sigma}(\cdot)\) whose \(k\)-th output is \([\boldsymbol{\sigma}^{+}(\mathbf{p})]_{k}=\log\left(p_{k}/(1-\lVert\mathbf{p} \rVert_{1})\right)\) for any \(\mathbf{p}\in\{\mathbf{q}\in[0,1]^{K}\lVert\lVert\mathbf{q}\rVert_{1}<1\}\). We bound the above two terms respectively. First, we show that the term (A) is bounded by \(\mathcal{O}\big{(}\log^{2}t\big{)}\) with high probability.

**Lemma 13**.: _Let \(\delta\in(0,1]\). Under Assumptions 1 and 3, we have_

\[\Pr\left[\forall t\geq 1,\sum_{s=1}^{t}\ell_{s}(W_{s})-\sum_{s=1}^{t}\ell( \widetilde{\mathbf{z}}_{s},y_{s})\leq\gamma_{t}^{\boldsymbol{\lambda}}(\delta )\right]\geq 1-\delta,\]

_where the confidence radius is \(\gamma_{t}^{\boldsymbol{\lambda}}=(\log(1+K)+2\log(1+(1+K)t))\left(\frac{5}{4}+4 \log\left(\frac{\sqrt{1+2t}}{\delta}\right)\right)+2=\mathcal{O}\left((\log K+ \log t)\log t\right)\)._

Besides, the term (b) can be bounded by the following lemma,

**Lemma 14**.: _Under Assumptions 1 and 3, for any \(c>0\), we have_

\[\sum_{s=1}^{t}\ell(\widetilde{\mathbf{z}}_{s},y_{s})-\sum_{s=1}^{t}\ell_{s}(W_ {s+1})\leq\frac{1}{c}\sum_{s=1}^{t}\lVert\overrightarrow{W}_{s}-\overrightarrow {W}_{s+1}\rVert_{H_{s}}^{2}+\gamma_{t}^{\mathbf{B}}(\delta),\]_by setting \(\lambda\geq\max\{2,24Kdc\}\). In the above, \(\gamma_{t}^{\mathtt{B}}(\delta)=\sqrt{6}cKd\ln\left(1+\frac{(t+1)L}{2\lambda}\right)\) and \(L:=\max_{W\in\mathbb{R}^{Kd},t\in[T]}\nabla^{2}\ell_{t}(W)\) is the smooth parameter of the logistic loss._

Combining Lemma 12, Lemma 13 and Lemma 14, we arrive at

\[\|\overrightarrow{W}_{t+1}-\overrightarrow{W}_{*}\|_{H_{t+1}}\] \[\leq\sqrt{4\lambda S^{2}+\alpha\gamma_{t}^{\mathtt{A}}+\alpha \gamma_{t}^{\mathtt{B}}+(\frac{\alpha}{c}-1)\sum_{s=1}^{t}\|\overrightarrow{W }_{s+1}-\overrightarrow{W}_{s}\|_{H_{s}}^{2}+\sqrt{6}\alpha S\sum_{s=1}^{t}\| \overrightarrow{W}_{s+1}-\overrightarrow{W}_{s}\|_{I_{K}\otimes\mathbf{x}_{s} \mathbf{x}_{s}^{\top}}^{2}}\] \[\leq\sqrt{4\lambda S^{2}+\alpha\gamma_{t}^{\mathtt{A}}+\alpha \gamma_{t}^{\mathtt{B}}}\] \[=\sqrt{\underbrace{4\lambda S^{2}}_{=\mathcal{O}(Kd\log K)}}+ \underbrace{\alpha(3\log K+2\log t)\left(\frac{5}{4}+4\log\left(\frac{\sqrt{1 +2t}}{\delta}\right)\right)+2}_{=\mathcal{O}((\log K+\log t)\log t)}+\underbrace {7\alpha^{2}Kd\ln\left(1+(t+1)L\right)/\sqrt{6}}_{=\mathcal{O}(Kd\log^{2}K\log t )}\] \[\triangleq\beta_{t}^{\mathtt{OL}}(\delta).\]

For the last second inequality, we eliminate the additional term by the parameter setting \(\eta=\alpha/2\), \(c=7\alpha/6\) and \(\lambda\geq\{7\sqrt{6}\alpha S,28Kd\alpha\}\) and due to the fact that \(I_{K}\otimes\mathbf{x}_{s}\mathbf{x}_{s}^{\top}\ll I_{Kd}\) under the condition \(\|\mathbf{x}_{t}\|_{2}\leq 1\) for any \(t\in[T]\). In the above, we have \(\lambda=\mathcal{O}(Kd\log K)\) and \(\alpha=\mathcal{O}(\log K)\). Then, we can show \(\|\overrightarrow{W}_{t+1}-\overrightarrow{W}_{*}\|_{H_{t+1}}\leq\beta_{t}^{ \mathtt{OL}}(\delta)=\mathcal{O}(\log K\log t\sqrt{Kd})\), which completes the proof. 

#### c.1.2 Proof of Lemma 12

Proof of Lemma 12.: Let \(\widetilde{\ell}_{s}(W)=\ell_{s}(W_{s})+\langle\overrightarrow{W}- \overrightarrow{W}_{s},\nabla\ell_{s}(\overrightarrow{W}_{s})\rangle+\frac{1} {2}\|\overrightarrow{W}-\overrightarrow{W}_{s}\|_{\nabla^{2}\ell_{s}( \overrightarrow{W}_{s})}^{2}\) be a second order approximation of the original function \(\ell_{s}(W)\) at the point \(\overrightarrow{W}_{s}\). The update rule (6) can be equally written as

\[\overrightarrow{W}_{s+1}=\operatorname*{arg\,min}_{W\in\mathcal{W}}\widetilde {\ell}_{s}(W)+\frac{1}{2\eta}\|\overrightarrow{W}-\overrightarrow{W}_{s}\|_{ H_{s}}^{2},\] (30)

which is an implicit online mirror descent update with the loss function \(\widetilde{\ell}_{s}\). Then, according to Lemma 16, the model \(W_{t+1}\) ensures,

\[\langle\nabla\widetilde{\ell}_{s}(\overrightarrow{W}_{s+1}),\overrightarrow{ W}_{s+1}-\overrightarrow{W}_{*}\rangle\leq\frac{1}{2\eta}\left(\| \overrightarrow{W}_{s}-\overrightarrow{W}_{*}\|_{H_{s}}^{2}-\|\overrightarrow{ W}_{s+1}-\overrightarrow{W}_{*}\|_{H_{s}}^{2}-\|\overrightarrow{W}_{s+1}- \overrightarrow{W}_{s}\|_{H_{s}}^{2}\right).\] (31)

One the other hand, let \(\alpha=\log(1+K)+2(1+S)\). Since \(\|W_{*}\mathbf{x}_{t}\|_{\infty}=\max_{k\in[K]}\{\|\mathbf{w}_{*}^{(k)}\|_{2} \cdot\|\mathbf{x}_{t}\|_{2}\}\leq S\) and \(\ell_{s}(W)=\ell(W\mathbf{x}_{s},y_{s})\), Lemma 1 shows

\[\ell_{s}(W_{s+1})-\ell_{s}(W_{*})\leq\langle\nabla\ell_{s}(W_{s+1}), \overrightarrow{W}_{s+1}-\overrightarrow{W}_{*}\rangle-\frac{1}{\alpha}\| \overrightarrow{W}_{s+1}-\overrightarrow{W}_{*}\|_{\nabla^{2}\ell_{s}(W_{s+1})} ^{2}.\] (32)

By setting \(\eta=\alpha/2\), the combination of (31) and (32) shows

\[\ell_{s}(W_{s+1})-\ell_{s}(W_{*})\leq\langle\nabla\ell_{s}(W_{s+ 1})-\nabla\widetilde{\ell}_{s}(W_{s+1}),\overrightarrow{W}_{s+1}-\overrightarrow{W }_{*}\rangle\] (33) \[\qquad\qquad\qquad\qquad+\frac{1}{\alpha}\left(\|\overrightarrow{ W}_{s}-\overrightarrow{W}_{*}\|_{H_{s}}^{2}-\|\overrightarrow{W}_{s+1}- \overrightarrow{W}_{*}\|_{H_{s+1}}^{2}-\|\overrightarrow{W}_{s+1}-\overrightarrow{ W}_{s}\|_{H_{s}}^{2}\right).\]

In above, we can further bound inner product term by

\[\langle\nabla\ell_{s}(W_{s+1})-\nabla\widetilde{\ell}_{s}(W_{s+1 }),\overrightarrow{W}_{s+1}-\overrightarrow{W}_{*}\rangle\] \[=\langle\nabla\ell_{s}(W_{s+1})-\nabla\ell_{s}(W_{s})-\nabla^{2} \ell_{s}(\overrightarrow{W}_{s})(\overrightarrow{W}_{s+1}-\overrightarrow{W}_{s}),\overrightarrow{W}_{s+1}-\overrightarrow{W}_{*}\rangle\] \[=\] \[= \left\langle D^{3}\ell_{s}(\xi_{s+1})[\overrightarrow{W}_{s+1}- \overrightarrow{W}_{s}](\overrightarrow{W}_{s+1}-\overrightarrow{W}_{s}), \overrightarrow{W}_{s+1}-\overrightarrow{W}_{*}\right\rangle\] \[= \left\langle D^{3}\ell_{s}(\xi_{s+1})[\overrightarrow{W}_{s+1}- \overrightarrow{W}_{*}](\overrightarrow{W}_{s+1}-\overrightarrow{W}_{s}), \overrightarrow{W}_{s+1}-\overrightarrow{W}_{s}\right\rangle\]\[\leq\sqrt{6}\|\overrightarrow{W}_{s+1}-\overrightarrow{W}_{s}\|_{I_{K} }^{2}\otimes_{\mathbf{x}_{s}\mathbf{x}_{s}^{\top}}-\|\overrightarrow{W}_{s+1}- \overrightarrow{W}_{s}\|_{H_{s}}^{2}\Big{)}\] \[\leq\sqrt{6}S\|\overrightarrow{W}_{s+1}-\overrightarrow{W}_{s}\|_ {I_{K}\otimes_{\mathbf{x}_{s}\mathbf{x}_{s}^{\top}}}^{2}\] (34)

In above \(\xi_{s+1}\) is a certain point on the line connecting \(\overrightarrow{W}_{t}\) and \(\overrightarrow{W}_{t+1}\). The notation is defined as \(D^{3}\ell_{s}(\overrightarrow{W})[\overrightarrow{U}]=\lim_{\alpha\to 0}\alpha^{-1} \left(\nabla^{2}\ell_{s}(\overrightarrow{W}+\alpha\overrightarrow{U})- \nabla^{2}\ell_{s}(\overrightarrow{W})\right)\). The first inequality is due to the definition of \(\ell_{s}\) and the second inequality is by the Taylor series for the vector-valued function. The third inequality is because the third order derivative of the logistic loss is a symmetric tensor as shown in Property 1. The last second inequality is by Definition 1 since the multiclass logistic loss is a \(\sqrt{6}\) self-concordant-like function. The last inequality is by the boundedness of the decision domain \(\mathcal{W}\) and bounded action such that \(\|\mathbf{x}\|_{2}\leq 1\) for any \(\mathbf{x}\in\mathcal{X}\) under Assumption 1.

Combining (33) and (34), we have

\[\ell_{s}(W_{s+1})-\ell_{s}(W_{*})\] \[\leq\frac{1}{\alpha}\left(\|\overrightarrow{W}_{s}- \overrightarrow{W}_{*}\|_{H_{s}}^{2}-\|\overrightarrow{W}_{s+1}- \overrightarrow{W}_{*}\|_{H_{s+1}}^{2}-\|\overrightarrow{W}_{s+1}- \overrightarrow{W}_{s}\|_{H_{s}}^{2}\right)+\sqrt{6}S\|\overrightarrow{W}_{s+ 1}-\overrightarrow{W}_{s}\|_{I_{K}\otimes_{\mathbf{x}_{s}\mathbf{x}_{s}^{\top }}}^{2},\]

Taking the summation of the above inequality over \(t\) rounds and rearranging the term, we have

\[\|\overrightarrow{W}_{t+1}-\overrightarrow{W}_{*}\|_{H_{t+1}}^{2} \leq\alpha\left(\sum_{s=1}^{t}\ell_{s}(W_{*})-\sum_{s=1}^{t} \ell_{s}(W_{s+1})\right)+\|\overrightarrow{W}_{1}-\overrightarrow{W}_{*}\|_{H _{1}}^{2}\] \[+\sum_{s=1}^{t}\left(\sqrt{6}\alpha S\|\overrightarrow{W}_{s+1}- \overrightarrow{W}_{s}\|_{I_{K}\otimes_{\mathbf{x}_{s}\mathbf{x}_{s}^{\top}}}^ {2}-\|\overrightarrow{W}_{s+1}-\overrightarrow{W}_{s}\|_{H_{s}}^{2}\right)\] \[\leq\alpha\left(\sum_{s=1}^{t}\ell_{s}(W_{*})-\sum_{s=1}^{t} \ell_{s}(W_{s+1})\right)+4\lambda S^{2}\] \[+\sum_{s=1}^{t}\left(\sqrt{6}\alpha S\|\overrightarrow{W}_{s+1}- \overrightarrow{W}_{s}\|_{I_{K}\otimes_{\mathbf{x}_{s}\mathbf{x}_{s}^{\top}}}^ {2}-\|\overrightarrow{W}_{s+1}-\overrightarrow{W}_{s}\|_{H_{s}}^{2}\right),\]

which completes the proof.

#### c.1.3 Proof of Lemma 13

Proof of Lemma 13.: Since the norm of the intermediate decision \(\widetilde{\mathbf{z}}_{s}=\boldsymbol{\sigma}^{+}(\mathbb{E}_{W\sim P_{s}}[ \boldsymbol{\sigma}(W\mathbf{x}_{s})])\) is generally unbounded, as suggested by [26], we use the smoothed version \(\widetilde{\mathbf{z}}_{s}^{\mu}=\boldsymbol{\sigma}^{+}\left(\mathrm{smooth} _{\mu}(\mathbb{E}_{W\sim P_{s}}[\boldsymbol{\sigma}(W\mathbf{x}_{s})])\right)\) as an intermediate term in the analysis. In above, the smooth function \(\mathrm{smooth}_{\mu}:[0,1]^{K}\mapsto[0,1]^{K}\) with parameter \(\mu\in[0,1/2]\) is defined by \(\mathrm{smooth}_{\mu}(\mathbf{p})=(1-\mu)\mathbf{p}+\mu \mathbf{1}/(K+1)\), where \(\mathbf{1}\in\mathbb{R}^{K}\) is an all one vector.

Given the construction of the pseudo inverse function \(\boldsymbol{\sigma}^{+}\) such that \(\boldsymbol{\sigma}(\boldsymbol{\sigma}^{+}(\mathbf{p}))=\mathbf{p}\) for any \(\mathbf{p}\in\{\mathbf{q}\in[0,1]^{K}\mid\|\mathbf{q}\|_{1}<1\}\), one can check that \(\widetilde{\mathbf{z}}_{s}^{\mu}=\boldsymbol{\sigma}^{+}\left(\mathrm{smooth} _{\mu}(\boldsymbol{\sigma}(\widetilde{\mathbf{z}}_{s}))\right)\). Then, Lemma 17 shows that

\[\sum_{s=1}^{t}\ell(\widetilde{\mathbf{z}}_{s}^{\mu},y_{s})-\sum_{s=1}^{t}\ell( \widetilde{\mathbf{z}}_{s},y_{s})\leq 2\mu t.\] (35)

Besides, Lemma 17 also shows that \(\|\widetilde{\mathbf{z}}_{s}^{\mu}\|_{\infty}\leq\log(1+(K+1)/\mu)\). Therefore, to prove the lemma, it is sufficient bound the gap between the loss of \(W_{*}\) and \(\widetilde{\mathbf{z}}_{s}^{\mu}\). By the definition of the loss function \(\ell_{s}\), we have \(\ell_{s}(W_{*})=\ell(\mathbf{z}_{s}^{*},\mathbf{y}_{s})\), where \(\mathbf{z}_{s}^{*}=W_{*}\mathbf{x}_{s}\). Then, we have

\[\sum_{s=1}^{t}\ell_{s}(W_{*})-\sum_{s=1}^{t}\ell(\widetilde{\mathbf{ z}}_{s}^{\mu},y_{s})= \sum_{s=1}^{t}\ell(\widetilde{\mathbf{z}}_{s}^{\mu},y_{s})-\sum_{s=1}^{t}\ell( \widetilde{\mathbf{z}}_{s}^{\mu},y_{s})\] \[\leq \sum_{s=1}^{t}\langle\nabla_{z}\ell(\mathbf{z}_{s}^{*},y_{s}), \mathbf{z}_{s}^{*}-\widetilde{\mathbf{z}}_{s}^{\mu}\rangle-\sum_{s=1}^{t} \frac{1}{S_{\mu}}\|\mathbf{z}_{s}^{*}-\widetilde{\mathbf{z}}_{s}^{\mu}\|_{ \nabla_{z}^{2}\ell(\mathbf{z}_{s}^{*},y_{s})}^{2}\]\[=\sum_{s=1}^{t}\langle\bm{\sigma}(\mathbf{z}_{s}^{*})-\mathbf{y}_{s}, \mathbf{z}_{s}^{*}-\widetilde{\mathbf{z}}_{s}^{\mu}\rangle\] (36) \[=(S_{\mu}+S)\sum_{s=1}^{t}\langle\bm{\sigma}(\mathbf{z}_{s}^{*})- \mathbf{y}_{s},\mathbf{d}_{s}\rangle\] \[\leq(S_{\mu}+S)\sqrt{\lambda+\sum_{s=1}^{t}\lVert\mathbf{d}_{s} \rVert_{\nabla\bm{\sigma}(\mathbf{z}_{s}^{*})}^{2}}\cdot\sqrt{\frac{\sqrt{ \lambda}}{4}+\frac{4}{\sqrt{\lambda}}\log\left(\frac{\sqrt{1+\sum_{s=1}^{t} \lVert\mathbf{d}_{s}\rVert_{\nabla\bm{\sigma}(\mathbf{z}_{s}^{*})}^{2}}}{ \delta}\right)}\] \[\leq(S_{\mu}+S)\sqrt{\lambda+\sum_{s=1}^{t}\lVert\mathbf{d}_{s} \rVert_{\nabla\bm{\sigma}(\mathbf{z}_{s}^{*})}^{2}}\cdot\sqrt{\frac{\sqrt{ \lambda}}{4}+\frac{4}{\sqrt{\lambda}}\log\left(\frac{\sqrt{1+2t}}{\delta} \right)},\] (38)

for any \(t\geq 1\). In above, the second inequality is a consequence of the fact \(\lVert\mathbf{d}_{s}\rVert_{\Sigma(\mathbf{z}_{s}^{*})}^{2}=\mathbf{d}_{s}^{ \top}\nabla\bm{\sigma}(\mathbf{z}_{s}^{*})\mathbf{d}_{s}\leq 2\). Then, combining (36) and (38) and setting \(\lambda=1\), we arrive ++

Footnote ‡: We note that the \(\lambda\) here is irrelevant of the algorithm, we can set it as any value.

\[\sum_{s=1}^{t}\ell_{s}(W_{s})-\sum_{s=1}^{t}\ell(\widetilde{ \mathbf{z}}_{s}^{\mu},\mathbf{y}_{s})\] \[\leq(S_{\mu}+S)\sqrt{1+\sum_{s=1}^{t}\lVert\mathbf{d}_{s} \rVert_{\Sigma(\mathbf{z}_{s}^{*})}^{2}}\cdot\sqrt{\frac{1}{4}+4\log\left( \frac{\sqrt{1+2t}}{\delta}\right)}-(S_{\mu}+S)\sum_{s=1}^{t}\lVert\mathbf{d}_ {s}\rVert_{\Sigma(\mathbf{z}_{s}^{*})}^{2}\] \[\leq(S_{\mu}+S)\left(1+\sum_{s=1}^{t}\lVert\mathbf{d}_{s} \rVert_{\Sigma(\mathbf{z}_{s}^{*})}\right)+(S_{\mu}+S)\left(\frac{1}{4}+4\log \left(\frac{\sqrt{1+2t}}{\delta}\right)\right)-(S_{\mu}+S)\sum_{s=1}^{t} \lVert\mathbf{d}_{s}\rVert_{\Sigma(\mathbf{z}_{s}^{*})}^{2}\] \[\leq\frac{5}{4}(S_{\mu}+S)+4(S_{\mu}+S)\log\bigg{(}\frac{\sqrt{1 +2t}}{\delta}\bigg{)},\] (39)where the second inequality is due to AM-GM inequality. Finally, combining (35) and (39), we have

\[\sum_{s=1}^{t}\ell_{s}(W_{*})-\sum_{s=1}^{t}\ell(\widetilde{\mathbf{ z}}_{s},\mathbf{y}_{s}) \leq\frac{5}{4}(S_{\mu}+S)+4(S_{\mu}+S)\log\bigg{(}\frac{\sqrt{1+2t} }{\delta}\bigg{)}2+\mu t\] \[\leq 3\log(1+(1+K)t)\left(\frac{5}{4}+4\log\bigg{(}\frac{\sqrt{1+ 2t}}{\delta}\bigg{)}\right)+2,\]

where the last inequality is by the parameter setting \(\mu=1/t\) and, as a consequence, \(S_{\mu}=\log(1+K)+2\log(1+(K+1)t)\). We have completed the proof. 

#### c.1.4 Proof of Lemma 14

Proof of Lemma 14.: Our proof starts with the observation made by [26, Proposition 2] that \(\widetilde{\mathbf{z}}_{s}\) is an aggregating forecaster [48, Chapter, 3.5] for the logistic function, which satisfies

\[\ell(\widetilde{\mathbf{z}}_{s},\mathbf{y}_{s})\leq-\ln\left(\mathbb{E}_{W \sim P_{s}}\big{[}e^{-\ell_{s}(W)}\big{]}\right).\]

Then, a direct calculation with the definition of Gaussian distribution \(P_{s}\sim\mathcal{N}(\overrightarrow{W}_{s},cH_{s}^{-1})\) gives

\[\ell(\widetilde{\mathbf{z}}_{s},\mathbf{y}_{s})\leq-\ln\left(\mathbb{E}_{W \sim P_{s}}\left[e^{-\ell_{s}(W)}\right]\right)=-\ln\left(\frac{1}{Z_{s}}\int _{\mathbb{R}^{Kd}}e^{-L_{s}(W)}\mathrm{d}\overrightarrow{W}\right),\] (40)

where we define the loss function \(L_{s}(W)=\ell_{s}(W)+(2c)^{-1}\|\overrightarrow{W}-\overrightarrow{W}_{s}\| _{H_{s}}^{2}\) and \(Z_{s}=\sqrt{(2\pi)^{Kd}c|H_{s}^{-1}|}\) being the normalization factor.

Then, we consider the following quadratic approximation,

\[\widetilde{L}_{s}(W)=L_{s}(W_{s+1})+\langle\nabla L_{s}(W_{s+1}), \overrightarrow{W}-\overrightarrow{W}_{s+1}\rangle+\frac{1}{2c}\| \overrightarrow{W}-\overrightarrow{W}_{s+1}\|_{H_{s}}^{2}.\] (41)

According to Lemma 18, we have

\[L_{s}(W)\leq\widetilde{L}_{s}(W)+e^{6\|\overrightarrow{W}- \overrightarrow{W}_{s+1}\|_{2}^{2}}\|\overrightarrow{W}-\overrightarrow{W}_{ s+1}\|_{\nabla\ell_{s}(W_{s+1})}^{2}.\]

Then, we can low bound the term in the expectation by

\[\mathbb{E}_{W\sim P_{s}}\left[e^{-\ell_{s}(W)}\right]\] \[=\frac{1}{Z_{s}}\int_{\mathbb{R}^{Kd}}e^{-L_{s}(W)}\mathrm{d}W\] \[\geq\frac{1}{Z_{s}}\int_{\mathbb{R}^{Kd}}e^{-\widetilde{L}_{s}(W) -e^{6|\overrightarrow{W}-\overrightarrow{W}_{s+1}\|_{2}^{2}}\|\overrightarrow{ W}-\overrightarrow{W}_{s+1}\|_{\nabla\ell_{s}(W_{s+1})}^{2}}\mathrm{d}W\] \[=\frac{e^{-L_{s}(W_{s+1})}}{Z_{s}}\int_{\mathbb{R}^{Kd}} \widetilde{f}_{s+1}(W)\cdot e^{-\langle\nabla L_{s}(W_{s+1}),\overrightarrow{ W}-\overrightarrow{W}_{s+1}\rangle}\mathrm{d}W,\] (42)

where we define the function \(\widetilde{f}_{s}:\mathcal{W}\mapsto\mathbb{R}\) as

\[\widetilde{f}_{s+1}(W)=\exp\left(-\frac{1}{2c}\|\overrightarrow{W}- \overrightarrow{W}_{s+1}\|_{H_{s}}^{2}-e^{6|\overrightarrow{W}-\overrightarrow {W}_{s+1}\|_{2}^{2}}\|\overrightarrow{W}-\overrightarrow{W}_{s+1}\|_{\nabla^{ 2}\ell_{s}(W_{s+1})}^{2}\right).\]

Denote by \(\widetilde{Z}_{s+1}=\int_{W\in\mathbb{R}^{Kd}}\widetilde{f}_{s+1}(W)\mathrm{d }W\leq+\infty\) the normalization factor and \(\widetilde{P}_{s+1}\) the distribution whose density function is \(\widetilde{f}_{s+1}(W)/\widetilde{Z}_{s+1}\), we can further rewrite the last line of the above displayed equation (42) as

\[\mathbb{E}_{W\sim P_{s}}\left[e^{-\ell_{s}(W)}\right]\geq\frac{e^{-L_{s}(W_{s+1 })}\widetilde{Z}_{s+1}}{Z_{s}}\mathbb{E}_{W\sim\widetilde{P}_{s+1}}\left[e^{- \langle\nabla L_{s}(W_{s+1}),\overrightarrow{W}-\overrightarrow{W}_{s+1} \rangle}\right]\]

[MISSING_PAGE_FAIL:29]

where the last inequality is because the moment-generating function for \(\chi^{2}\)-distribution is bounded by \(\mathbb{E}_{X\sim\chi^{2}}\left[e^{tX}\right]\leq 1/\sqrt{1-2t}\) for all \(t\leq 1/2\).

Then, we consider the second on the upper bound of term (b). A direct calculation gives,

\[\texttt{term}\left(\texttt{a-2}\right)=\mathbb{E}_{W\sim\mathcal{N}\left( \texttt{0},\alpha H_{s}^{-1}\right)}\left[\|(\nabla^{2}\ell_{s}(W_{s+1}))^{ \frac{1}{2}}\overrightarrow{W}\|^{4}\right]=\mathbb{E}_{W\sim\mathcal{N}\left( \texttt{0},\alpha\widetilde{H}_{s}^{-1}\right)}\left[\|\overrightarrow{W}\|_ {2}^{4}\right],\]

where \(\widetilde{H}_{s}=(\nabla^{2}\ell_{s}(W_{s+1}))^{-\frac{1}{2}}H_{s}(\nabla^{2 }\ell_{s}(W_{s+1}))^{-\frac{1}{2}}\). Then, let \(\widetilde{\lambda}_{i}:=\lambda_{i}\bigg{(}c\widetilde{H}_{s}^{-1}\bigg{)}\) be the \(i\)-th largest eigenvalue of the matrix. A similar decomposition as (47) shows that

\[\texttt{term}\left(\texttt{a-2}\right) =\sqrt{\mathbb{E}_{X_{i}\sim\mathcal{N}(0,1)}\left[\left\|\sum_{i =1}^{Kd}\sqrt{\widetilde{\lambda}_{i}X_{i}}\mathbf{e}_{i}\right\|_{2}^{4} \right]}=\sqrt{\mathbb{E}_{X_{i}\sim\mathcal{N}(0,1)}\left[\bigg{(}\sum_{i=1} ^{Kd}\widetilde{\lambda}_{i}X_{i}^{2}\bigg{)}^{2}\right]}\] \[=\sqrt{\sum_{i=1}\sum_{j=1}\widetilde{\lambda}_{i}\widetilde{ \lambda}_{j}\mathbb{E}_{X_{i},X_{j}\sim\mathcal{N}(0,1)}[X_{i}^{2}X_{j}^{2}]} \leq\sqrt{3\sum_{i=1}^{Kd}\sum_{j=1}^{Kd}\widetilde{\lambda}_{i}\widetilde{ \lambda}_{j}}=\sqrt{3}c\text{Tr}\big{(}\widetilde{H}_{s}^{-1}\big{)},\]

where the last inequality is due to \(\mathbb{E}_{X_{i},X_{j}\sim\mathcal{N}(0,1)}[X_{i}^{2}X_{j}^{2}]\leq 3\) for all \(i,j\in[Kd]\) and the last equality comes from the fact that \(\sum_{i=1}^{Kd}\widetilde{\lambda}_{i}=\text{Tr}\big{(}c\widetilde{H}_{s}^{-1 }\big{)}\). The notation \(\text{Tr}(A)\) is used to denote the trace of the matrix \(A\).

Then, we proceed to bound the trace \(\text{Tr}\big{(}\widetilde{H}_{s}^{-1}\big{)}\) with \(\widetilde{H}_{s}=H_{s}\nabla^{2}\ell_{s}(W_{s+1})\). Recall the definition of \(H_{s}=\lambda I_{Kd}+\sum_{\tau=1}^{s-1}\nabla^{2}\ell_{\tau}(W_{\tau+1})\). We define \(M_{s+1}=\lambda I_{Kd}/2+\sum_{\tau=1}^{s}\nabla^{2}\ell_{\tau}(W_{\tau+1})\). Under the condition \(\lambda\geq 2\) for any \(s\in[T]\), we have \(\nabla^{2}\ell_{s}(W)\preccurlyeq I_{Kd}\leq\frac{\lambda}{2}I_{Kd}\) for any \(s\in[T]\) and \(W\in\mathcal{W}\). Then, we have \(H_{s}\succcurlyeq M_{s+1}\). Then, we can bound the trace by

\[\text{Tr}\big{(}\widetilde{H}_{s}^{-1}\big{)} =\text{Tr}\bigg{(}H_{s}^{-1}\nabla^{2}\ell_{s}(W_{s+1})\bigg{)} \leq\text{Tr}\bigg{(}M_{s+1}^{-1}\nabla^{2}\ell_{s}(W_{s+1})\bigg{)}\] \[=\text{Tr}\bigg{(}M_{s+1}^{-1}(M_{s+1}-M_{s})\big{)}\bigg{)}\leq \log\frac{|M_{s+1}|}{|M_{s}|}.\]

where the last inequality is due to Lemma 4.5 of [16]. As a consequence, we have \(\texttt{term}\left(\texttt{a-2}\right)\leq\sqrt{3}c\ln(|M_{s+1}|/|M_{s}|)\), which leads to

\[\Omega_{s}\leq\texttt{term}\left(\texttt{a-1}\right)\cdot\texttt{term}\left( \texttt{a-2}\right)\leq\sqrt{6}c\ln\bigg{(}\frac{|M_{s+1}|}{|M_{s}|}\bigg{)}\] (49)

Combining (46) and (49), we obtain that

\[\sum_{s=1}^{t}\ell(\widetilde{\mathbf{z}}_{s},\mathbf{y}_{s})-\sum_{s=1}^{t} \ell_{s}(W_{s+1})\leq\frac{1}{c}\sum_{s=1}^{t}\|\overrightarrow{W}_{s}- \overrightarrow{W}_{s+1}\|_{H_{s}}^{2}+\sqrt{6}c\sum_{s=1}^{t}\ln\bigg{(}\frac {|M_{s+1}|}{|M_{s}|}\bigg{)}\,.\]

W can further bound the last term of the displayed equality by \(\sum_{s=1}^{t}\ln\left(|M_{s+1}|/|M_{s}|\right)\leq\ln\left(|M_{t+1}|/|\lambda /2\cdot I_{Kd}|\right)\leq Kd\ln\left(1+\frac{(t+1)L}{2\lambda}\right)\), which completes the proof. 

#### c.1.5 Useful Lemmas

Proof of Lemma 15.: The proof of Lemma 15 shares the same spirit as that of Lemma 6. Let \(\bar{H}_{t}=\sum_{s=1}^{t-1}\|\mathbf{z}_{s}\|_{\Sigma_{s}}^{2}\). We can also defined the function

\[M_{t}(\xi)=\exp(\xi S_{t}-\xi^{2}\bar{H}_{t})\]

for any \(t\geq 1\) and \(\xi\in\mathbb{R}\). For \(t=0\), we let \(M_{0}(\xi)=0\). Following the similar arguments in the proof of Lemma 7, one can show that the sequence \(\{M_{t}(\xi)\}_{t=1}^{\infty}\) is a non-negative super-martingale when \(\xi\leq\frac{1}{2}\). Then, let \(h(\xi)\) be the density of the normal distribution with precision \(2\lambda\) truncated on the 1-dimensional ball \(\frac{1}{2}\mathcal{B}(1)\). We can define

\[\bar{M}_{t}=\int_{\xi}\exp(\xi S_{t}-\xi^{2}\bar{H}_{t})\mathrm{d}h(\xi).\]By the similar arguments in deriving (17), we have

\[\text{Pr}\left[\sup_{t\in\mathbb{N}}\log(\bar{M}_{t})\geq\log\left(\frac{1}{\delta }\right)\right]=\text{Pr}\left[\sup_{t\in\mathbb{N}}\bar{M}_{t}\geq\frac{1}{ \delta}\right]\leq\delta.\] (50)

Following the arguments in the proof of [8, Theorem 1], for any \(t\geq 1\), we have

\[\bar{M}_{t}\geq\exp(\xi S_{t}-\xi^{2}H_{t})\cdot\frac{N(g)}{N(h)}\]

for any \(|\xi|\leq 1/4\). In the above, \(g(\xi)\) is the normal distribution with precision \(2H_{t}\) truncated on the interval \([-1/4,1/4]\). Then, let \(\xi_{0}=\frac{1}{4}\sqrt{\frac{\lambda}{H_{t}}}\), we have \(\xi_{0}\leq 1/4\) since \(H_{t}\geq\lambda\). We can obtain that

\[\log(\bar{M}_{t})\geq\xi_{0}S_{t}-\xi_{0}^{2}H_{t}+\log\left(\frac{N(g)}{N(h)} \right)=\frac{\sqrt{\lambda}}{4}\cdot\frac{S_{t}}{\sqrt{H_{t}}}-\frac{\lambda} {16}+\log\left(\frac{N(g)}{N(h)}\right).\] (51)

A combination of (50) and (51) shows that

\[\Pr\left[\forall t\geq 1,\frac{\sqrt{\lambda}}{4}\cdot\frac{S_{t}}{\sqrt{H_{t} }}-\frac{\lambda}{16}+\log\left(\frac{N(g)}{N(h)}\right)\leq\log\left(\frac{1} {\delta}\right)\right]\geq 1-\delta,\]

which indicates

\[\Pr\left[\forall t\geq 1,S_{t}\leq\sqrt{H_{t}}\left(\frac{\sqrt{\lambda}}{4}+ \frac{4}{\sqrt{\lambda}}\log\left(\frac{N(h)}{\delta N(g)}\right)\right)\right] \geq 1-\delta.\]

We complete the proof with Lemma 6 of [8], which shows that \(\log\left(N(h)/N(g)\right)\leq\log\left((2\sqrt{H_{t}})/\lambda\right)\). 

**Lemma 16** (Proposition 4.1 of [49]).: _Let the \(\mathbf{w}_{t+1}\) be the solution of the update rule_

\[\mathbf{w}_{t+1}=\operatorname*{arg\,min}_{\mathbf{w}\in\mathcal{V}}\eta\ell _{t}(\mathbf{w})+\mathcal{D}_{\psi}(\mathbf{w},\mathbf{w}_{t}),\]

_where \(\mathcal{V}\subseteq\mathcal{W}\subseteq\mathbb{R}^{d}\) is a non-empty convex set and \(\mathcal{D}_{\psi}(\mathbf{w}_{1},\mathbf{w}_{2})=\psi(\mathbf{w}_{1})-\psi( \mathbf{w}_{2})-\langle\nabla\psi(\mathbf{w}_{2}),\mathbf{w}_{1}-\mathbf{w}_ {2}\rangle\) is the Bregman Divergence w.r.t. a strictly convex and continuously differentiable function \(\psi:\mathcal{W}\mapsto\mathbb{R}\). Further supposing \(\psi(\mathbf{w})\) is 1-strongly convex w.r.t. a certain norm \(\|\cdot\|\) in \(\mathcal{W}\), then there exists a \(\mathbf{g}_{t}^{\prime}\in\partial\ell_{t}(\mathbf{w}_{t+1})\) such that_

\[\langle\eta_{t}\mathbf{g}_{t}^{\prime},\mathbf{w}_{t+1}-\mathbf{u}\rangle \leq\langle\nabla\psi(\mathbf{w}_{t})-\nabla\psi(\mathbf{w}_{t+1}),\mathbf{w} _{t+1}-\mathbf{u}\rangle\]

_for any \(\mathbf{u}\in\mathcal{W}\)._

**Lemma 17**.: _Let \(\ell(\mathbf{z},y)=\sum_{k=0}^{K}\mathds{1}\{y=k\}\cdot\log\left(\frac{1}{[ \boldsymbol{\sigma}(\mathbf{z})]_{k}}\right)\) and \(\mathbf{z}\in\mathbb{R}^{K}\) be a \(K\)-dimensional vector. Define \(\mathbf{z}^{\mu}\triangleq\boldsymbol{\sigma}^{+}\big{(}\mathrm{smooth}_{\mu}( \boldsymbol{\sigma}(\mathbf{z}))\big{)}\), where \(\mathrm{smooth}_{\mu}(\mathbf{p})=(1-\mu)\mathbf{p}+\mu\mathbf{1}/(K+1)\). Then, for \(\mu\in[0,1/2]\), we have_

\[\ell(\mathbf{z}^{\mu},y)-\ell(\mathbf{z},y)\leq 2\mu\]

_for any \(y\in\{0\}\cup[K]\). We also have \(\|\mathbf{z}^{\mu}\|_{\infty}\leq\log(K/\mu)\)._

Proof of Lemma 17.: The proof of Lemma 17 is extracted from the proof of [26, Lemma 3] with a slight modification to the logistic loss used in this paper. According to the definition of \(\mathbf{z}^{\mu}\) and the fact that \(\boldsymbol{\sigma}(\boldsymbol{\sigma}^{+}(\mathbf{p}))=\mathbf{p}\) for any \(\mathbf{p}\in\{\mathbf{q}\in[0,1]^{K}\|\mathbf{q}\|_{1}<1\}\), we have \(\boldsymbol{\sigma}(\mathbf{z}^{\mu})=(1-\mu)\boldsymbol{\sigma}(\mathbf{z})+ \mu\mathbf{1}/(K+1)\). Then, we have

\[\ell(\mathbf{z}^{\mu},y)-\ell(\mathbf{z},y)=\sum_{k=0}^{K}\mathds{1}\{y=k\} \cdot\log\left(\frac{[\boldsymbol{\sigma}(\mathbf{z})]_{k}}{(1-\mu)[ \boldsymbol{\sigma}(\mathbf{z})]_{k}+\mu\mathbf{1}/(K+1)}\right)\leq\log(1-\mu )\leq 2\mu,\]

where the first inequality is due to \(\sum_{k=0}^{K}\mathds{1}\{y=k\}=1\) and the last inequality is due to \(\log(1/(1-a))\leq a\) for \(a\in[0,1/2]\). Besides, let \(\mathbf{p}=\boldsymbol{\sigma}(\mathbf{z})\). According to the definition of \(\mathbf{z}^{\mu}\), we have

\[\|\mathbf{z}^{\mu}\|_{\infty}=\max_{k\in[K]}\left\{\left|\log\left(\frac{(1- \mu)\widetilde{p}_{k}+\mu/(K+1)}{(1-K\mu/(K+1))-(1-\mu)\|\widetilde{\mathbf{p}} \|_{1}}\right)\right|\right\}.\]Since the term inside the logarithmic function can be bounded by

\[\frac{\mu}{1+K(1-\mu)}\leq\log\left(\frac{(1-\mu)\widetilde{p}_{k}+\mu/(K+1)}{(1- K\mu/(K+1))-(1-\mu)\|\widetilde{\mathbf{p}}\|_{1}}\right)\leq 1+\frac{K+1}{\mu}\]

and \(\mu/(1+K(1-\mu))\leq 1\), we have \(\|\mathbf{z}^{\mu}\|_{\infty}\leq\log(1+(K+1)/\mu)\).

**Lemma 18**.: _Let \(L_{s}(W)=\ell_{s}(W)+\frac{1}{2c}\|\overrightarrow{W}-\overrightarrow{W}_{s} \|_{H_{s}}^{2}\). Then, for any \(W,W_{s+1}\in\mathcal{W}\), the quadratic approximation \(\widetilde{L}_{s}(W)=L_{s}(W_{s+1})+\langle\nabla L_{s}(W_{s+1}),\overrightarrow {W}-\overrightarrow{W}_{s+1}\rangle+\frac{1}{2c}\|\overrightarrow{W}- \overrightarrow{W}_{s+1}\|_{H_{s}}^{2}\) defined as (41) satisfies_

\[L_{s}(W)\leq\widetilde{L}_{s}(W)+e^{6\|\overrightarrow{W}-\overrightarrow{W }_{s+1}\|_{2}^{2}}\|\overrightarrow{W}-\overrightarrow{W}_{s+1}\|_{\nabla \ell_{s}(W_{s+1})}^{2}.\]

Proof of Lemma 18.: According to [19, Lemma 4], \(\ell_{s}\) is a \(\sqrt{6}\)-self-concordant-like function. Then, by Lemma 5 and the fact \(c(x)\leq e^{x^{2}}\) for any \(x\geq 0\), then for any \(W\in\mathcal{W}\), we have

\[\ell_{s}(W)\leq\ell_{s}(W_{s+1})+\langle\nabla\ell_{s}(W_{s+1}), \overrightarrow{W}-\overrightarrow{W}_{s+1}\rangle+e^{6\|\overrightarrow{W}- \overrightarrow{W}_{s+1}\|_{2}^{2}}\|\overrightarrow{W}-\overrightarrow{W}_ {s+1}\|_{\nabla^{2}\ell_{s}(W_{s+1})}^{2}.\] (52)

Besides, since \(g_{s}(W)=\frac{1}{2c}\|\overrightarrow{W}-\overrightarrow{W}_{s}\|_{H_{s}}^{2}\) is a quadratic function, we have

\[g_{s}(W)=g_{s}(W_{s+1})+\langle\nabla g_{s}(W_{s+1}),\overrightarrow{W}- \overrightarrow{W}_{s+1}\rangle+\frac{1}{2c}\|\overrightarrow{W}- \overrightarrow{W}_{s+1}\|_{H_{s}}^{2}.\] (53)

Then combing (52) and (53), we can obtain an upper bound of \(L_{s}(W)=\ell_{s}(W)+g_{s}(W)\) by

\[L_{s}(W) \leq L_{s}(W_{s+1})+\langle\nabla L_{s}(W_{s+1}),\overrightarrow{W }-\overrightarrow{W}_{s+1}\rangle\] \[\qquad+\frac{1}{2c}\|\overrightarrow{W}-\overrightarrow{W}_{s+1} \|_{H_{s}}^{2}+e^{6\|\overrightarrow{W}-\overrightarrow{W}_{s+1}\|_{2}^{2}}\| \overrightarrow{W}-\overrightarrow{W}_{s+1}\|_{\nabla^{2}\ell_{s}(W_{s+1})}^{2}\] \[\leq\widetilde{L}_{s}(W)+e^{6\|\overrightarrow{W}-\overrightarrow{ W}_{s+1}\|_{2}^{2}}\|\overrightarrow{W}-\overrightarrow{W}_{s+1}\|_{\nabla^{2} \ell_{s}(W_{s+1})}^{2},\]

We have complete the proof. 

### Proof of Proposition 1

This section presents the proof of Proposition 1.

#### c.2.1 Main Proof of Proposition 1

Proof of Proposition 1.: Since \(\boldsymbol{\rho}^{\top}\boldsymbol{\sigma}(W_{*}\mathbf{x})\leq\boldsymbol{ \rho}^{\top}\boldsymbol{\sigma}(W_{t}\mathbf{x})+|\boldsymbol{\rho}^{\top} \boldsymbol{\sigma}(W_{\ast}\mathbf{x})-\boldsymbol{\rho}^{\top}\boldsymbol{ \sigma}(W_{t}\mathbf{x})|\), to show \(\widetilde{r}_{t}^{\mathsf{DL}}(\mathbf{x})=\boldsymbol{\rho}^{\top} \boldsymbol{\sigma}(W_{t}\mathbf{x})+\epsilon_{t}^{\mathsf{fast}}(\mathbf{x})+ \epsilon_{t}^{\mathsf{snd}}(\mathbf{x})\) is an optimistic estimate, it is sufficient to prove that \(|\boldsymbol{\rho}^{\top}\boldsymbol{\sigma}(W_{*}\mathbf{x})-\boldsymbol{ \rho}^{\top}\boldsymbol{\sigma}(W_{t}\mathbf{x})|\leq\epsilon_{t}^{\mathsf{ fast}}(\mathbf{x})+\epsilon_{t}^{\mathsf{snd}}(\mathbf{x})\). We have the following decomposition:

\[|\boldsymbol{\rho}^{\top}\boldsymbol{\sigma}(W_{*}\mathbf{x})- \boldsymbol{\rho}^{\top}\boldsymbol{\sigma}(W_{t}\mathbf{x})|\] \[= \left|\sum_{k=1}^{K}\rho_{k}(\sigma_{k}(W_{*}\mathbf{x})-\sigma_{k }(W_{t}\mathbf{x}))\right|\] \[= \left|\sum_{k=1}^{K}\rho_{k}\nabla\sigma_{k}(W_{t}\mathbf{x})^{ \top}(W_{*}-W_{t})\mathbf{x}+\sum_{k=1}^{K}\rho_{k}\|(W_{*}-W_{t})\mathbf{x} \|_{\Xi_{k,t}}^{2}\right|\] \[\leq \underbrace{\left|\sum_{k=1}^{K}\rho_{k}\nabla\sigma_{k}(W_{t} \mathbf{x})^{\top}(W_{*}-W_{t})\mathbf{x}\right|}_{\mathtt{term}\ (\mathbf{a})}+\underbrace{\left|\sum_{k=1}^{K}\rho_{k}\|(W_{*}-W_{t}) \mathbf{x}\|_{\Xi_{k,t}}^{2}\right|}_{\mathtt{term}\ (\mathbf{b})},\]where \(\sigma_{k}:\mathbf{x}\mapsto[\bm{\sigma}(\mathbf{x})]_{k}\) is the \(k\)-th output of the vector-valued function \(\bm{\sigma}(\mathbf{x})\) and \(\Xi_{k,t}=\int_{\nu=0}^{1}(1-\nu)\nabla^{2}\sigma_{k}((W_{t}+\nu(W_{*}-W_{t})) \mathbf{x})\mathrm{d}\nu\). In the above, the last equality is due to the integral formulation of the Taylor series.

Then, we proceed to analyze term (a) and term (b), respectively.

\[\mathtt{term}\left(\mathtt{a}\right) =|\bm{\rho}^{\top}\nabla\bm{\sigma}(W_{t}\mathbf{x})(W_{*}-W_{t} )\mathbf{x}|\] \[=|\bm{\rho}^{\top}\nabla\bm{\sigma}(W_{t}\mathbf{x})(I_{K} \otimes\mathbf{x}^{\top})(\overrightarrow{W_{*}}-\overrightarrow{W_{t}})|\] \[=|\bm{\rho}^{\top}\nabla\bm{\sigma}(W_{t}\mathbf{x})(I_{K} \otimes\mathbf{x}^{\top})H_{t}^{-\frac{1}{2}}H_{t}^{\frac{1}{2}}( \overrightarrow{W_{*}}-\overrightarrow{W_{t}})|\] \[\leq\|\overrightarrow{W_{*}}-\overrightarrow{W_{t}}\|_{H_{t}}\cdot \|H_{t}^{-\frac{1}{2}}(I_{K}\otimes\mathbf{x})\nabla\bm{\sigma}(W_{t}\mathbf{ x})\bm{\rho}\|_{2}\] \[\leq\beta_{t}^{\mathsf{nd}}(\delta)\cdot\|H_{t}^{-\frac{1}{2}}(I_ {K}\otimes\mathbf{x})\nabla\bm{\sigma}(W_{t}\mathbf{x})\bm{\rho}\|_{2}\] \[=\epsilon_{t}^{\mathsf{fast}}(\mathbf{x}),\]

where the last inequality is due to Theorem 3.

Then, we upper bound term (b) by \(\epsilon_{t}^{\mathsf{end}}\) with the following arguments. For notation simplicity, we denote by \(\bm{\xi}_{t,\nu}=W_{t}\mathbf{x}+\nu(W_{*}-W_{t})\mathbf{x}\). Then, Lemma 11 indicates that

\[\Xi_{k,t}=\int_{\nu=0}^{1}(1-\nu)\nabla^{2}\sigma_{k}(\bm{\xi}_{t,\nu})\mathrm{ d}\nu\preccurlyeq 3I_{K}\int_{\nu=0}^{1}(1-\nu)\mathrm{d}\nu\preccurlyeq 3I_{K}.\]

As a consequence, we can bound term (b) by

\[\mathtt{term}\left(\mathtt{b}\right) \leq 3\left|\sum_{k=1}^{K}\rho_{k}\|(W_{*}-W_{t})\mathbf{x}\|_{2}^ {2}\right|\] \[\leq 3R\|(W_{*}-W_{t})\mathbf{x}\|_{2}^{2}\] \[=3R\|(I_{d}\otimes\mathbf{x}^{\top})(\overrightarrow{W_{*}}- \overrightarrow{W_{t}})\|_{2}^{2}\] \[= \leq 3R\|\overrightarrow{W_{*}}-\overrightarrow{W_{t}}\|_{H_{t}} ^{2}\cdot\|(I_{K}\otimes\mathbf{x}^{\top})H_{t}^{-\frac{1}{2}}\|_{2}^{2}\] \[\leq 3R\left(\beta_{t}^{\mathsf{nd}}\right)^{2}\cdot\|(I_{K} \otimes\mathbf{x}^{\top})H_{t}^{-\frac{1}{2}}\|_{2}^{2}\] \[=\epsilon_{t}^{\mathsf{end}}(\mathbf{x}),\]

where the first inequality is due to Assumption 2 and the last inequality is due to Theorem 3. Combining the upper bound for term (a) and term (b), we have

\[|\bm{\rho}^{\top}\bm{\sigma}(W_{*}\mathbf{x})-\bm{\rho}^{\top}\bm{\sigma}(W_{t }\mathbf{x})| \leq\epsilon_{t}^{\mathsf{fast}}(\mathbf{x})+\epsilon_{t}^{\mathsf{ nd}}(\mathbf{x}),\] (54)

for any \(\mathbf{x}\in\mathcal{X}\). We complete the proof by \(\bm{\rho}^{\top}\bm{\sigma}(W_{*}\mathbf{x})\leq\bm{\rho}^{\top}\bm{\sigma}(W _{t}\mathbf{x})+|\bm{\rho}^{\top}\bm{\sigma}(W_{*}\mathbf{x})-\bm{\rho}^{\top} \bm{\sigma}(W_{t}\mathbf{x})|\). 

### Proof of Theorem 4

Proof of Theorem 4.: We first prove the regret bound and then discuss the computation cost.

#### c.3.1 Main Proof

Regret Analysis.We can bound the regret by two times of the bonus term over \(\mathbf{x}_{t}\).

\[\mathrm{Reg}_{T} =\,\sum_{t=1}^{T}\left(\bm{\rho}^{\top}\bm{\sigma}(W_{*}\mathbf{x }_{*})-\bm{\rho}^{\top}\bm{\sigma}(W_{*}\mathbf{x}_{t})\right)\] \[\leq\,\sum_{t=1}^{T}\left(\bm{\rho}^{\top}\bm{\sigma}(W_{t} \mathbf{x}_{*})+\epsilon_{t}^{\mathsf{fast}}(\mathbf{x}_{*})+\epsilon_{t}^{ \mathsf{end}}(\mathbf{x}_{*})-\bm{\rho}^{\top}\bm{\sigma}(W_{*}\mathbf{x}_{t})\right)\] \[\leq\,\sum_{t=1}^{T}\left(\bm{\rho}^{\top}\bm{\sigma}(W_{t} \mathbf{x}_{t})+\epsilon_{t}^{\mathsf{fast}}(\mathbf{x}_{t})+\epsilon_{t}^{ \mathsf{end}}(\mathbf{x}_{t})-\bm{\rho}^{\top}\bm{\sigma}(W_{t}\mathbf{x}_{t})\right)\]\[\leq 2\sum_{t=1}^{T}\epsilon_{t}^{\texttt{fast}}(\mathbf{x}_{t})+2\sum_{t =1}^{T}\epsilon_{t}^{\texttt{end}}(\mathbf{x}_{t}),\] (55)

where the first inequality is due to Proposition 1 and the second inequality is due to the rule of constructing the optimistic reward. The last inequality is due to (54).

Then, we turn to analyze the upper bound for the first term and second term respectively.

\[\sum_{t=1}^{T}\epsilon_{t}^{\texttt{fast}}(\mathbf{x}_{t})\] (56) \[= \sum_{t=1}^{T}\beta_{t}^{\texttt{OL}}(\delta)\cdot\|H_{t}^{- \frac{1}{2}}(I_{K}\otimes\mathbf{x}_{t})\nabla\boldsymbol{\sigma}(W_{t} \mathbf{x}_{t})\boldsymbol{\rho}\|_{2}\] \[\leq \beta_{T}^{\texttt{OL}}(\delta)\sum_{t=1}^{T}\|H_{t}^{-\frac{1}{ 2}}(I_{K}\otimes\mathbf{x}_{t})\nabla\boldsymbol{\sigma}(W_{t}\mathbf{x}_{t}) \boldsymbol{\rho}\|_{2}\] \[\leq \beta_{T}^{\texttt{OL}}(\delta)\underbrace{\sum_{t=1}^{T}\|H_{t }^{-\frac{1}{2}}(I_{K}\otimes\mathbf{x}_{t})\nabla\boldsymbol{\sigma}(W_{t+ 1}\mathbf{x}_{t})\boldsymbol{\rho}\|_{2}}_{\texttt{term (a)}}+\beta_{T}^{\texttt{OL}}(\delta)\underbrace{\sum_{t=1}^{T}\|H_{t}^{- \frac{1}{2}}(I_{K}\otimes\mathbf{x}_{t})\left(\nabla\boldsymbol{\sigma}(W_{t} \mathbf{x}_{t})-\nabla\boldsymbol{\sigma}(W_{t+1}\mathbf{x}_{t})\right) \boldsymbol{\rho}\|_{2}}_{\texttt{term (b)}}.\]

For the first term, we have

\[\texttt{term}\left(\mathbf{a}\right) \leq \sum_{t=1}^{T}\|\boldsymbol{\rho}\|_{\nabla\boldsymbol{\sigma}(W_ {t+1}\mathbf{x}_{t})}\cdot\|H_{t}^{-\frac{1}{2}}(I_{K}\otimes\mathbf{x}_{t}) \nabla\boldsymbol{\sigma}^{\frac{1}{2}}(W_{t+1}\mathbf{x})\|_{2}\] \[\leq R\sum_{t=1}^{T}\sqrt{\lambda_{\max}\bigg{(}(\nabla\boldsymbol {\sigma}^{\frac{1}{2}}(W_{t+1}\mathbf{x})\otimes\mathbf{x}_{t}^{\top})H_{t}^{- 1}(\nabla\boldsymbol{\sigma}^{\frac{1}{2}}(W_{t+1}\mathbf{x})\otimes\mathbf{x }_{t})\bigg{)}}\] \[= R\sum_{t=1}^{T}\sqrt{\lambda_{\max}\bigg{(}(\nabla\boldsymbol{ \sigma}(W_{t+1}\mathbf{x}_{t})\otimes\mathbf{x}_{t}\mathbf{x}_{t}^{\top})H_{t} ^{-1}\bigg{)}}\] \[\leq R\sqrt{T}\sqrt{Kd\ln\left(1+\frac{TL}{2\lambda}\right)}\]

where the first inequality is due to the fact that \(\|A\mathbf{b}\|_{2}\leq\|A\|_{2}\cdot\|\mathbf{b}\|\) for a matrix \(A\) and vector \(\mathbf{b}\). The second inequality is due to the definition of the induced norm for the matrix is defined as \(\|A\|_{2}=\sqrt{\lambda_{\max}(A^{T}A)}\) and the mixed-product property of the Kronecker production. The first equality is due to the cycle property of the maximum eigenvalue such that \(\lambda_{\max}(ABC)=\lambda_{\max}(CAB)\) for matrices \(A,B\) and \(C\). The last second inequality is due to the Cauchy-Schwarz inequality. Finally, we can obtain the last inequality by Lemma 19, which can be seen as a matrix version of the elliptical potential lemma.

Then, we can bound term (b) as follows.

\[\texttt{term}\left(\mathbf{b}\right) \leq \sum_{t=1}^{T}\|H_{t}^{-\frac{1}{2}}(I_{K}\otimes\mathbf{x}_{t}) \|_{2}\cdot\|(\nabla\boldsymbol{\sigma}(W_{t}\mathbf{x}_{t})-\nabla\boldsymbol{ \sigma}(W_{t+1}\mathbf{x}_{t}))\,\boldsymbol{\rho}\|_{2}\] \[= \sum_{t=1}^{T}\|H_{t}^{-\frac{1}{2}}(I_{K}\otimes\mathbf{x}_{t}) \|_{2}\cdot\left\|\sum_{k=1}^{K}\rho_{k}(\nabla\sigma_{k}(W_{t}\mathbf{x}_{t}) -\nabla\sigma_{k}(W_{t+1}\mathbf{x}_{t}))\right\|_{2}\] \[= \sum_{t=1}^{T}\|H_{t}^{-\frac{1}{2}}(I_{K}\otimes\mathbf{x}_{t}) \|_{2}\cdot\left\|\sum_{k=1}^{K}\rho_{k}\nabla^{2}\sigma_{k}(\boldsymbol{\xi}_{ t,k})(W_{t}-W_{t+1})\mathbf{x}_{t}\right\|_{2}\]\[= \sum_{t=1}^{T}\lVert H_{t}^{-\frac{1}{2}}(I_{K}\otimes\mathbf{x}_{t}) \rVert_{2}\cdot\left\lVert\sum_{k=1}^{K}\rho_{k}\nabla^{2}\sigma_{k}(\bm{\xi}_{t,k})(I_{K}\otimes\mathbf{x}_{t})^{\top}(\overrightarrow{W}_{t}-\overrightarrow {W}_{t+1})\right\rVert_{2}\] \[= \sum_{t=1}^{T}\lVert H_{t}^{-\frac{1}{2}}(I_{K}\otimes\mathbf{x}_ {t})\rVert_{2}\cdot\left\lVert\sum_{k=1}^{K}\rho_{k}\nabla^{2}\sigma_{k}(\bm{ \xi}_{t,k})(I_{K}\otimes\mathbf{x}_{t})\right\rVert_{2}\] (57)

In the above, the second equality is due to the mean-value theorem, where denote by \(\bm{\xi}_{t,k}\in\mathbb{R}^{K}\) a certain point on the line connecting \(W_{t}\mathbf{x}_{t}\) and \(W_{t+1}\mathbf{x}_{t}\). We can further bound the second term of the right hand side of the above displayed inequality by

\[\left\lVert\sum_{k=1}^{K}\rho_{k}\nabla^{2}\sigma_{k}(\bm{\xi}_{t,k})(I_{K}\otimes\mathbf{x}_{t}^{\top})(\overrightarrow{W}_{t}-\overrightarrow {W}_{t+1})\right\rVert_{2}\] \[= \left\lVert\sum_{k=1}^{K}\rho_{k}\nabla^{2}\sigma_{k}(\bm{\xi}_{ t,k})(I_{K}\otimes\mathbf{x}_{t}^{\top})H_{t}^{-\frac{1}{2}}H_{t}^{\frac{1}{2}}( \overrightarrow{W}_{t}-\overrightarrow{W}_{t+1})\right\rVert_{2}\] \[\leq \left\lVert\sum_{k=1}^{K}\rho_{k}\nabla^{2}\sigma_{k}(\bm{\xi}_{ t,k})(I_{K}\otimes\mathbf{x}_{t}^{\top})H_{t}^{-\frac{1}{2}}\right\rVert_{2} \cdot\left\lVert\overrightarrow{W}_{t}-\overrightarrow{W}_{t+1}\right\rVert_ {H_{t}}\] \[\leq \frac{\alpha\sqrt{K}}{\lambda}\left\lVert\sum_{k=1}^{K}\rho_{k} \nabla^{2}\sigma_{k}(\bm{\xi}_{t,k})(I_{K}\otimes\mathbf{x}_{t}^{\top})H_{t}^{ -\frac{1}{2}}\right\rVert_{2}\] \[\leq \frac{\alpha\sqrt{K}}{\lambda}\sum_{k=1}^{K}\rho_{k}\lVert\nabla^ {2}\sigma_{k}(\bm{\xi}_{t,k})\rVert_{2}\cdot\left\lVert(I_{K}\otimes\mathbf{ x}_{t}^{\top})H_{t}^{-\frac{1}{2}}\right\rVert_{2}\] \[\leq \frac{3\alpha KR}{\lambda}\left\lVert(I_{K}\otimes\mathbf{x}_{t}^ {\top})H_{t}^{-\frac{1}{2}}\right\rVert_{2}\] (58)

where the first inequality is by the fact \(\lVert A\mathbf{b}\rVert_{2}\leq\lVert A\rVert_{2}\cdot\lVert\mathbf{b}\rVert _{2}\) for any matrix \(A\) and vector \(\mathbf{b}\). The second inequality is due to Lemma 20. The last inequality is due to Lemma 11 such that for any \(\mathbf{z}\in\mathbb{R}^{K}\) and \(\sum_{k=1}^{K}\rho_{k}\leq\sqrt{K}R\).

Then plugging (58) into (57), we can bound term (b) by

\[\texttt{term}\left(\mathbf{b}\right)\leq\frac{3\alpha KR}{\lambda}\sum_{t=1}^ {T}\lVert H_{t}^{-\frac{1}{2}}(I_{K}\otimes\mathbf{x}_{t})\rVert_{2}^{2}\leq \frac{3\kappa KdR\alpha}{\lambda}\ln\left(1+\frac{T}{\lambda\kappa}\right),\]

where the last inequality is due to Lemma 21. Combining the upper bound for term (a) and term (b) and plugging them into (56), we have

\[\sum_{t=1}^{T}\epsilon_{t}^{\texttt{fast}}(\mathbf{x}_{t}) \leq\beta_{T}^{\texttt{0L}}(\delta)\left(R\sqrt{T}\sqrt{Kd\ln \left(1+\frac{TL}{2\lambda}\right)}\right)+\frac{3\kappa KdR\alpha\beta_{T}^{ \texttt{0L}}(\delta)}{\lambda}\ln\left(1+\frac{T}{\lambda\kappa}\right)\] \[=\mathcal{O}\Big{(}Kd\log K(\log T)^{\frac{3}{2}}\sqrt{T}+\kappa K ^{\frac{3}{2}}d^{\frac{3}{2}}(\log K)^{2}(\log T)^{2}\Big{)}.\] (59)

As for the term \(\sum_{t=1}^{T}\epsilon_{t}^{\texttt{snd}}(\mathbf{x}_{t})\), we have

\[\sum_{t=1}^{T}\epsilon_{t}^{\texttt{snd}}(\mathbf{x}_{t}) =3R\left(\beta_{t}^{\texttt{0L}}\right)^{2}\cdot\lVert(I_{K} \otimes\mathbf{x}_{t}^{\top})H_{t}^{-\frac{1}{2}}\rVert_{2}^{2}\] \[\leq 3R\left(\beta_{t}^{\texttt{0L}}\right)^{2}\kappa d\ln\left(1+ \frac{T}{\lambda\kappa}\right)\] \[=\mathcal{O}\left(\kappa Kd^{2}(\log K)^{2}(\log T)^{3}\right).\] (60)

Combining (59) and (60) with (55), we have

\[\mathrm{Reg}_{T} \leq 2\sum_{t=1}^{T}\epsilon_{t}^{\texttt{fast}}(\mathbf{x}_{t})+2 \sum_{t=1}^{T}\epsilon_{t}^{\texttt{snd}}(\mathbf{x}_{t})\] \[\leq 2\beta_{T}^{\texttt{0L}}(\delta)R\sqrt{T}\sqrt{d\ln\left(1+ \frac{TL}{2\lambda}\right)}+\frac{6\kappa KdR\alpha\beta_{T}^{\texttt{0L}}( \delta)}{\lambda}\ln\left(1+\frac{T}{\lambda\kappa}\right)\]\[\sum_{t=1}^{T}\lambda_{\max}\bigg{(}(\nabla\bm{\sigma}(W_{t+1} \mathbf{x}_{t})\otimes\mathbf{x}_{t}\mathbf{x}_{t}^{\top})H_{t}^{-1}\bigg{)}\leq Kd \ln\left(1+\frac{TL}{2\lambda}\right),\]

_where \(L=\max_{\mathbf{x}\in\mathcal{X},W\in\mathcal{W}}\lambda_{\max}(\nabla\bm{ \sigma}(W\mathbf{x}))\)_

Proof of Lemma 19.: Let \(M_{t}=\frac{\lambda}{2}I_{Kd}+\sum_{s=1}^{t}\nabla\bm{\sigma}(W_{s+1}\mathbf{x }_{s})\otimes\mathbf{x}_{s}\mathbf{x}_{s}^{\top}\). Then, we have \(H_{t}-M_{t}=\frac{\lambda}{2}I_{Kd}-\nabla\bm{\sigma}(W_{t+1}\mathbf{x}_{t}) \otimes\mathbf{x}_{t}\mathbf{x}_{t}^{\top}\). Since \(\nabla\bm{\sigma}(W_{t+1}\mathbf{x}_{t})\otimes\mathbf{x}_{t}\mathbf{x}_{t}^{ \top}\preccurlyeq I_{Kd}\), we have \(H_{t}\succcurlyeq M_{t}\) when \(\lambda>2\). Then, we have

\[\sum_{t=1}^{T}\lambda_{\max}\bigg{(}(\nabla\bm{\sigma}(W_{t+1} \mathbf{x}_{t})\otimes\mathbf{x}_{t}\mathbf{x}_{t}^{\top})H_{t}^{-1}\bigg{)}\]\[\leq \sum_{t=1}^{T}\mathrm{Tr}\left((\nabla\bm{\sigma}(W_{t+1}\mathbf{x}_{ t})\otimes\mathbf{x}_{t}\mathbf{x}_{t}^{\top})H_{t}^{-1}\right)\] \[\leq \sum_{t=1}^{T}\mathrm{Tr}\left(M_{t}-M_{t-1}\right)M_{t}^{-1}\right)\] \[\leq \sum_{t=1}^{T}\log\frac{|M_{t}|}{|M_{t-1}|}\] \[\leq Kd\ln\left(1+\frac{TL}{2\lambda}\right)\]

where we denote by \(\mathrm{Tr}(A)\) the trace of matrix A. The second inequality is by the condition \(H_{t}\succcurlyeq M_{t}\). The last second inequality is due to Lemma 4.5 of [16].

**Lemma 20**.: _Let \(\overrightarrow{W}_{t+1}=\arg\min_{W\in\mathcal{W}}\langle\nabla\ell_{t}( \overrightarrow{W}_{t}),\overrightarrow{W}\rangle+\frac{1}{\alpha}\| \overrightarrow{W}-\overrightarrow{W}_{t}\|_{\widetilde{H}_{t}}^{2}\). Then, we have_

\[\|\overrightarrow{W}_{t+1}-\overrightarrow{W}_{t}\|_{H_{t}}\leq\frac{\alpha} {2\lambda}\|\nabla\ell_{t}(\overrightarrow{W}_{t})\|_{2}\leq\frac{\alpha \sqrt{K}}{\lambda}.\]

Proof of Lemma 20.: Let \(F_{t}(\overrightarrow{W})=\langle\nabla\ell_{t}(\overrightarrow{W}_{t}), \overrightarrow{W}\rangle+\frac{1}{\alpha}\|\overrightarrow{W}- \overrightarrow{W}_{t}\|_{\widetilde{H}_{t}}^{2}\). Since \(\overrightarrow{W}_{t+1}=\arg\min_{W\in\mathcal{W}}F_{t}(\overrightarrow{W})\), we have \(F_{t}(\overrightarrow{W}_{t+1})\leq F_{t}(\overrightarrow{W}_{t})\), which implies

\[\frac{1}{\alpha}\|\overrightarrow{W}_{t+1}-\overrightarrow{W}_{t}\|_{ \widetilde{H}_{t}}^{2}\leq\langle\nabla\ell_{t}(\overrightarrow{W}_{t}), \overrightarrow{W}_{t}-\overrightarrow{W}_{t+1}\rangle.\]

Then, by the Holder's inequality, we can further bound the inner product term by

\[\langle\nabla\ell_{t}(\overrightarrow{W}_{t}),\overrightarrow{W}_{t}- \overrightarrow{W}_{t+1}\rangle\leq\|\overrightarrow{W}_{t+1}-\overrightarrow{ W}_{t}\|_{\widetilde{H}_{t}}\cdot\|\nabla\ell_{t}(\overrightarrow{W}_{t})\|_{ \widetilde{H}_{t}^{-1}},\]

which indicates that

\[\|\overrightarrow{W}_{t+1}-\overrightarrow{W}_{t}\|_{\widetilde{H}_{t}}\leq \alpha\|\nabla\ell_{t}(\overrightarrow{W}_{t})\|_{\widetilde{H}_{t}^{-1}}.\]

Since \(\widetilde{H}_{t}\succcurlyeq H_{t}\) and \(\widetilde{H}_{t}^{-1}\preccurlyeq I_{K}d/\lambda\), we can further have,

\[\|\overrightarrow{W}_{t+1}-\overrightarrow{W}_{t}\|_{H_{t}}\leq\| \overrightarrow{W}_{t+1}-\overrightarrow{W}_{t}\|_{\widetilde{H}_{t}}\leq \alpha\|\nabla\ell_{t}(\overrightarrow{W}_{t})\|_{\widetilde{H}_{t}^{-1}}\leq \frac{\alpha}{2\lambda}\|\nabla\ell_{t}(\overrightarrow{W}_{t})\|_{2}\leq \frac{\alpha\sqrt{K}}{\lambda},\]

where the last inequality is due to the definition of \(\nabla\ell_{t}(\overrightarrow{W}_{t})=(\bm{\sigma}_{t}(\overrightarrow{W}_{t} )-\mathbf{y}_{t})\otimes\mathbf{x}_{t}\) such that \(\|\nabla\ell_{t}(\overrightarrow{W}_{t})\|_{2}\leq 2\sqrt{K}\). 

**Lemma 21**.: _Let \(H_{t}=\lambda I_{Kd}+\sum_{s=1}^{t-1}\nabla\bm{\sigma}(W_{s+1}\mathbf{x}_{s}) \otimes\mathbf{x}_{s}\mathbf{x}_{s}^{\top}\). Then, we have_

\[\sum_{t=1}^{T}\|H_{t}^{-\frac{1}{2}}(I_{K}\otimes\mathbf{x}_{t})\|_{2}^{2}\leq \kappa d\ln\left(1+\frac{T}{\lambda\kappa}\right),\]

_where \(\lambda>2\)._

Proof of Lemma 21.: The proof of Lemma 21 shares the same spirits with that of Lemma 19. Let \(\bar{V}_{t}=\frac{\lambda}{2}I_{Kd}+\frac{1}{\kappa}\sum_{s=1}^{t}I_{K}\otimes \mathbf{x}_{s}\mathbf{x}_{s}^{\top}\). We have \(H_{t}\succcurlyeq\bar{V}_{t}\) when \(\lambda>2\). We can prove the lemma by

\[\sum_{t=1}^{T}\|H_{t}^{-\frac{1}{2}}(I_{K}\otimes\mathbf{x}_{t}) \|_{2}^{2}\] \[= \sum_{t=1}^{T}\lambda_{\max}\left((I_{K}\otimes\mathbf{x}_{t}^{ \top})H_{t}^{-1}(I_{K}\otimes\mathbf{x}_{t})\right)\]\[\leq \sum_{t=1}^{T}\lambda_{\max}\left((I_{K}\otimes\mathbf{x}_{t}^{\top}) \bar{V}_{t}^{-1}(I_{K}\otimes\mathbf{x}_{t})\right)\] \[= \sum_{t=1}^{T}\lambda_{\max}\left((I_{K}\otimes\mathbf{x}_{t}^{ \top})\left(I_{K}\otimes\left(\lambda I_{d}+\frac{1}{\kappa}\sum_{s=1}^{t} \mathbf{x}_{s}\mathbf{x}_{s}^{\top}\right)^{-1}\right)(I_{K}\otimes\mathbf{x}_ {t})\right)\] \[= \sum_{t=1}^{T}\lambda_{\max}\left(I_{K}\otimes\left(\mathbf{x}_{t }^{\top}\left(\lambda I_{d}+\frac{1}{\kappa}\sum_{s=1}^{t}\mathbf{x}_{s} \mathbf{x}_{s}^{\top}\right)^{-1}\mathbf{x}_{t}\right)\right)\] \[= \mathbf{x}_{t}^{\top}\Big{(}\lambda I_{d}+\frac{1}{\kappa}\sum_{ s=1}^{t}\mathbf{x}_{s}\mathbf{x}_{s}^{\top}\Big{)}^{-1}\mathbf{x}_{t}\leq \kappa d\ln\left(1+\frac{T}{\lambda\kappa}\right),\]

where the first inequality is due to \(H_{t}\succcurlyeq\bar{V}_{t}\). The second equality is due to the definition of \(\bar{V}_{t}\) and the third equality is due to the mixed-product property of the Kronecker product. The last inequality can be obtain by the standard elliptical potential lemma [3, Lemma 11]. 

#### c.3.4 Computation Cost of Algorithm 2

```
0: regularization coefficient \(\lambda\), probability \(\delta\), step size \(\eta\).
1: Initialize \(H_{1}=\lambda I_{Kd}\) and \(\overrightarrow{W}_{1}\) as any point in \(\mathcal{W}\)
2:for\(t=1,\ldots,T\)do
3: Select the arm by \(\mathbf{x}_{t}=\operatorname*{arg\,max}_{\mathbf{x}\in\mathcal{X}}\widetilde{r }_{t}(\mathbf{x})\) and receive \(y_{t}\).
4: Update \(\widetilde{H}_{t}=H_{t}+\eta\nabla\boldsymbol{\sigma}(W_{t}\mathbf{x}_{t}) \otimes\mathbf{x}_{t}\mathbf{x}_{t}^{\top}\)
5: Update the estimator \(\overrightarrow{W}_{t+1}\) for the next iteration by (6)
6: Update \(H_{t+1}=H_{t}+\nabla\boldsymbol{\sigma}(W_{t+1}\mathbf{x}_{t})\otimes \mathbf{x}_{t}\mathbf{x}_{t}^{\top}\) and
7: Construct the optimistic reward by \(\widetilde{r}_{t+1}(\mathbf{x})=\boldsymbol{\rho}^{\top}\boldsymbol{\sigma}(W _{t+1}\mathbf{x})+\epsilon_{t+1}^{\texttt{fast}}(\mathbf{x})+\epsilon_{t+1}^ {\texttt{snd}}(\mathbf{x})\) as (8).
8:endfor ```

**Algorithm 2** OFUL-MLogB

Here, we discuss about the computation cost of the Algorithm 2. For each iteration, our algorithm requires to maintain the inverse of matrix \(H_{t+1}=H_{t}+\nabla\boldsymbol{\sigma}(W_{t+1}\mathbf{x}_{t})\otimes\mathbf{x }_{t}\mathbf{x}_{t}^{\top}\) and \(\widetilde{H}_{t}=H_{t}+\eta\nabla\boldsymbol{\sigma}(W_{t}\mathbf{x}_{t}) \otimes\mathbf{x}_{t}\mathbf{x}_{t}^{\top}\). Since \(\nabla\boldsymbol{\sigma}(W_{t+1}\mathbf{x}_{t})\otimes\mathbf{x}_{t} \mathbf{x}_{t}^{\top}\) and \(\nabla\boldsymbol{\sigma}(W_{t}\mathbf{x}_{t})\otimes\mathbf{x}_{t}\mathbf{x }_{t}^{\top}\) are both rank-\(K\) matrix, then one can main \(H_{t}\) and \(\widetilde{H}_{t}\) with \(\mathcal{O}(K^{3}d^{2})\) computation cost per iteration by the Sherman-Morrison-Woodbury formula. Given the \(H_{t}^{-1}\) and \(\widetilde{H}_{t}^{-1}\), we discuss the computation cost of the construction of the optimistic reward 8 and the update rule for the estimator (6).

Computation Cost of the Estimator (6).As shown by the discussion in Section 3.2, the update rule (6) is identical to

\[\overrightarrow{Z}_{t+1}=\overrightarrow{W}_{t}-\eta\widetilde{H}_{t}^{-1} \nabla\ell_{t}(\overrightarrow{W}_{t})\quad\text{ and }\quad\overrightarrow{W}_{t+1}=\operatorname*{arg\,min}_{ \overrightarrow{W}\in\mathcal{W}}\lVert\overrightarrow{W}-\overrightarrow{Z}_ {t+1}\rVert_{\widetilde{H}_{t}}.\]

Given the \(\widetilde{H}_{t}^{-1}\), we can perform the gradient step with \(\mathcal{O}(K^{2}d^{2})\) time complexity. As for the projection step, the optimization problem can be solved in \(\mathcal{O}(K^{3}d^{3})\) time [18, Section 4]. As a consequence, the overall time complexity for obtaining the estimator (6) is \(\mathcal{O}(K^{3}d^{3})\).

Computation Cost of Building Optimistic Reward.As shown by (8), we construct the optimistic reward by \(\widehat{r}_{t}^{\texttt{ML}}(\mathbf{x})=\boldsymbol{\rho}^{\top}\boldsymbol{ \sigma}(W_{t}^{\texttt{ML}}\mathbf{x})+\epsilon_{t}^{\texttt{fast}}(\mathbf{x})+ \epsilon_{t}^{\texttt{snd}}(\mathbf{x})\). We can compute \(\epsilon_{t}^{\texttt{fast}}(\mathbf{x})\) with the following equivalent formulation

\[\epsilon_{t}^{\texttt{fast}}(\mathbf{x}) =\beta_{t}^{\texttt{ML}}(\delta)\cdot\lVert H_{t}^{-\frac{1}{2}}( I_{K}\otimes\mathbf{x})\nabla\boldsymbol{\sigma}(W_{t})\boldsymbol{\rho}\rVert_{2}\] \[=\beta_{t}^{\texttt{ML}}(\delta)\sqrt{\boldsymbol{\rho}^{\top}( \nabla\boldsymbol{\sigma}(W_{t}\mathbf{x})\otimes\mathbf{x}^{\top})H_{t}^{-1} \boldsymbol{\rho}^{\top}(\nabla\boldsymbol{\sigma}(W_{t}\mathbf{x})\otimes \mathbf{x})\boldsymbol{\rho}}.\]

Given \(H_{t}^{-1}\), it will take \(\mathcal{O}(K^{2}d^{2})\) to calculate \(\epsilon_{t}^{\texttt{fast}}(\mathbf{x})\). As for the term \(\epsilon_{t}^{\texttt{fast}}(\mathbf{x})\), it can also be rewritten as

\[\epsilon_{t}^{\texttt{snd}}(\mathbf{x})=3R\left(\beta_{t}^{\texttt{ML}}\right)^ {2}\cdot\lVert(I_{K}\otimes\mathbf{x}^{\top})H_{t}^{-1/2}\rVert_{2}^{2}\]\[=3R\left(\beta_{t}^{\text{GL}}\right)^{2}\sqrt{\lambda_{\max}\left((I_{K} \otimes\mathbf{x}\mathbf{x}^{\top})H_{t}^{-1}\right)},\]

It would take \(\mathcal{O}(K^{3}d^{3})\) time to perform the eigenvalue decomposition. Given there are \(|\mathcal{X}|\) arm, the time complexity for identify the arm \(\mathbf{x}_{t}=\arg\max_{\mathbf{x}\in\mathcal{X}}\widetilde{r}_{t}(\mathbf{x})\) is in total \(\mathcal{O}(|\mathcal{X}|K^{3}d^{3})\).

Overall, Algorithm 2 can be implemented in \(\mathcal{O}(|\mathcal{X}|K^{3}d^{3})\) time, which is independent of \(T\).

### Proof of Corollary 1

#### c.4.1 Main Proof

In the binary case, we select the arm by \((\mathbf{x}_{t},\widetilde{\mathbf{w}}_{t})=\arg\max_{\mathbf{x}\in\mathcal{ X},W\in\mathcal{C}_{t}(\delta)}\mathbf{w}^{\top}\mathbf{x}\). In such a case, we show Algorithm 2 achieves an \(\widetilde{O}(T/\kappa_{*})\) bound with a constant computation cost. The proof is almost the same as that of [10, Theorem 2]. The main difference is that we complete the proof with the confidence set of the efficient online estimator (Theorem 3). We present the proof here for self-containedness.

Proof of Corollary 1.: When \(K=1\) and \(\rho_{1}=1\), the MLogB problem recovers the binary logistic bandit problem with the feedback \(y_{t}=\{0,1\}\) and the reward model \(\text{Pr}[y=1|\mathbf{x}]=\sigma(\mathbf{w}_{*}^{\top}\mathbf{x})\). In such a case, we can decompose the regret by

\[\mathrm{Reg}_{T} =\sum_{t=1}^{T}\sigma(\mathbf{w}_{*}^{\top}\mathbf{x}_{*})-\sum _{t=1}^{T}\sigma(\mathbf{w}_{*}^{\top}\mathbf{x}_{t})\] \[\leq\sum_{t=1}^{T}\sigma(\widetilde{\mathbf{w}}_{t}^{\top}\mathbf{ x}_{t})-\sum_{t=1}^{T}\sigma(\mathbf{w}_{*}^{\top}\mathbf{x}_{t})\] \[=\sum_{t=1}^{T}\sigma^{\prime}(\mathbf{w}_{*}^{\top}\mathbf{x}_{t })(\widetilde{\mathbf{w}}_{t}^{\top}-\mathbf{w}_{*})^{\top}\mathbf{x}_{t}+ \sum_{t=1}^{T}\sigma^{\prime\prime}(\boldsymbol{\xi}_{t}\mathbf{x}_{t})(( \widetilde{\mathbf{w}}_{t}-\mathbf{w}_{*})^{\top}\mathbf{x}_{t})^{2}\] \[=\underbrace{\sum_{t\in I_{1}}\sigma^{\prime}(\mathbf{w}_{*}^{ \top}\mathbf{x}_{t})(\widetilde{\mathbf{w}}_{t}^{\top}-\mathbf{w}_{*})^{\top} \mathbf{x}_{t}}_{\text{term }(\text{a})}+\underbrace{\sum_{t\in I_{2}}\sigma^{ \prime}(\mathbf{w}_{*}^{\top}\mathbf{x}_{t})(\widetilde{\mathbf{w}}_{t}^{\top }-\mathbf{w}_{*})^{\top}\mathbf{x}_{t}}_{\text{term }(\text{b})}+\underbrace{\sum_{t=1}^{T} \sigma^{\prime\prime}(\boldsymbol{\xi}_{t}\mathbf{x}_{t})((\widetilde{ \mathbf{w}}_{t}-\mathbf{w}_{*})^{\top}\mathbf{x}_{t})^{2}}_{\text{term }(\text{c})},\]

where the first inequality is due to the arm selection rule. The first equality is due to the Taylor series and \(\boldsymbol{\xi}_{t}\in\mathbb{R}^{d}\) is a certain point on the line connecting \(\widetilde{\mathbf{w}}_{t}\) and \(\mathbf{w}_{*}\). For the last equality, we divide the time horizon into two parts \(I_{1}=\{t\in[T]\mid\sigma^{\prime}(\mathbf{w}_{*}^{\top}\mathbf{x}_{t})\geq \sigma^{\prime}(\mathbf{w}_{t+1}^{\top}\mathbf{x}_{t})\}\) and \(I_{2}=[T]/I_{1}\).

For term (a), we have

\[\text{term }(\text{a})\] \[=\sum_{t\in I_{1}}\sigma^{\prime}(\mathbf{w}_{*}^{\top}\mathbf{x }_{t})(\widetilde{\mathbf{w}}_{t}^{\top}-\mathbf{w}_{*})^{\top}\mathbf{x}_{t}\] \[\leq\sum_{t\in I_{1}}\sigma^{\prime}(\mathbf{w}_{t+1}^{\top} \mathbf{x}_{t})(\widetilde{\mathbf{w}}_{t}-\mathbf{w}_{*})^{\top}\mathbf{x}_{t }+\sum_{t\in I_{1}}|(\mathbf{w}_{t+1}-\mathbf{w}_{*})^{\top}\mathbf{x}_{t}|( \widetilde{\mathbf{w}}_{t}-\mathbf{w}_{*})^{\top}\mathbf{x}_{t}\] \[\leq\underbrace{\sum_{t\in I_{1}}\sqrt{\sigma^{\prime}(\mathbf{w} _{t+1}^{\top}\mathbf{x}_{t})}\cdot\|\widetilde{\mathbf{w}}_{t}-\mathbf{w}_{*} \|_{H_{t}}\cdot\|\sqrt{\sigma^{\prime}(\mathbf{w}_{t+1}^{\top}\mathbf{x}_{t})} \mathbf{x}_{t}\|_{H_{t}^{-1}}}_{\text{term }(\text{a-1})}\] \[\qquad+\underbrace{\sum_{t\in I_{1}}\|\mathbf{x}_{t}\|_{H_{t}^{-1}} ^{2}\|\widetilde{\mathbf{w}}_{t}-\mathbf{w}_{*}\|_{H_{t}}\cdot\|\mathbf{w}_{t+1 }-\mathbf{w}_{*}\|_{H_{t+1}}}_{\text{term }(\text{a-2})},\]

where the first inequality is due to the mean value theorem and the condition that \(|\sigma^{\prime\prime}(z)|\leq 1\) for any \(z\in\mathbb{R}\). The second inequality is due to the Cauchy-Schwarz inequality and \(H_{t}\preccurlyeq H_{t+1}\). We can further bound term (a-1) by

\[\text{term }(\text{a-1})=\sum_{t\in I_{1}}\sqrt{\sigma^{\prime}(\mathbf{w}_{t+1}^{ \top}\mathbf{x}_{t})}\cdot\|\widetilde{\mathbf{w}}_{t}-\mathbf{w}_{*}\|_{H_{t} }\cdot\|\sqrt{\sigma^{\prime}(\mathbf{w}_{t+1}^{\top}\mathbf{x}_{t})}\mathbf{x}_{t }\|_{H_{t}^{-1}}\]\[\leq 2\beta_{T}(\delta)\sqrt{\sum_{t\in I_{1}}\sigma^{\prime}(\mathbf{w} _{t+1}^{\top}\mathbf{x}_{t})}\sqrt{\sum_{t\in I_{1}}\lVert\sqrt{\sigma^{\prime}( \mathbf{w}_{t+1}^{\top}\mathbf{x}_{t})}\mathbf{x}_{t}\rVert_{H_{t}^{-1}}^{2}}\] \[\leq 2\beta_{T}(\delta)\sqrt{\sum_{t\in I_{1}}\sigma^{\prime}( \mathbf{w}_{*}^{\top}\mathbf{x}_{t})}\sqrt{\sum_{t\in I_{1}}\lVert\sqrt{ \sigma^{\prime}(\mathbf{w}_{t+1}^{\top}\mathbf{x}_{t})}\mathbf{x}_{t}\rVert_{H _{t}^{-1}}^{2}}\] \[\leq 4\beta_{T}(\delta)\cdot\sqrt{\operatorname{Reg}_{T}+T\sigma^{ \prime}(\mathbf{w}_{*}^{\top}\mathbf{x}_{*})}\cdot\sqrt{d\log(1+\frac{T}{ \lambda})},\] (62)

where the first inequality is due to \(\widetilde{\mathbf{w}}_{t}\) and \(\mathbf{w}_{*}\) are both contained in \(\mathcal{C}_{t}(\delta)\) and \(\beta_{t}(\delta)=\mathcal{O}(\log t)\) is the radius of \(\mathcal{C}_{t}(\delta)\) as shown in Theorem 3. The last second inequality is by the condition such that \(\sigma^{\prime}(\mathbf{w}_{*}^{\top}\mathbf{x}_{t})\geq\sigma^{\prime}( \mathbf{w}_{t+1}^{\top}\mathbf{x}_{t})\) for all \(t\in I_{1}\). Then, following the same argument in the proof of [10, Theorem 2], one can show

\[\sqrt{\sum_{t\in I_{1}}\sigma^{\prime}(\mathbf{w}_{*}^{\top}\mathbf{x}_{t})} \leq\sqrt{\sum_{t\in T}\sigma^{\prime}(\mathbf{w}_{*}^{\top}\mathbf{x}_{t})} \leq\sqrt{\operatorname{Reg}_{T}+T\sigma^{\prime}(\mathbf{w}_{*}^{\top} \mathbf{x}_{*})},\] (63)

which leads to the last inequality. We also use the elliptical potential lemma [10, Lemma 9] in the last inequality.

As for term (a-2), we have

\[\texttt{term}\left(\texttt{a-2}\right)\leq(\beta_{T}(\delta))^{2}\sum_{t\in[ T]}\lVert\mathbf{x}_{t}\rVert_{H_{t}^{-1}}^{2}\leq\kappa d(\beta_{T}(\delta))^{2} \ln(1+\frac{T}{\lambda\kappa}),\] (64)

where the first inequality holds because \(\mathbf{w}_{*}\) and \(\widetilde{\mathbf{w}}_{t}\) are contained in \(\mathcal{C}_{t}(\delta)\). The second inequality can be obtained following the similar argument in obtaining (60). Combining the upper bound for term (a-1) and term (a-2), we have

\[\texttt{term}\left(\texttt{a}\right)\leq 4\beta_{T}(\delta)\sqrt{d\log(1+ \frac{T}{\lambda})}\cdot\sqrt{\operatorname{Reg}_{T}+T\sigma^{\prime}( \mathbf{w}_{*}^{\top}\mathbf{x}_{*})}+\kappa d(\beta_{T}(\delta))^{2}\ln(1+ \frac{T}{\lambda\kappa}).\]

As for term (b), we have \(\sigma^{\prime}(\mathbf{w}_{*}^{\top}\mathbf{x}_{t})<\sigma^{\prime}(\mathbf{ w}_{t+1}^{\top}\mathbf{x}_{t})\) for all \(t\in I_{2}\). Then, we have

\[\texttt{term}\left(\texttt{b}\right) \leq\] \[\leq 4\beta_{T}(\delta)\sqrt{d\log(1+\frac{T}{\lambda})}\cdot\sqrt{ \operatorname{Reg}_{T}+T\sigma^{\prime}(\mathbf{w}_{*}^{\top}\mathbf{x}_{*})},\]

where the second inequality is due to the condition \(\sigma^{\prime}(\mathbf{w}_{*}^{\top}\mathbf{x}_{t})<\sigma^{\prime}(\mathbf{ w}_{t+1}^{\top}\mathbf{x}_{t})\) and the last inequality can be obtained using similar arguments as those used to derive (62).

Regarding term (c), the application of similar arguments used to derive equation (62) demonstrates.

\[\texttt{term}\left(\texttt{c}\right)\leq\kappa d(\beta_{T}(\delta))^{2}\ln(1+ \frac{T}{\lambda\kappa}).\]

Then, combining the upper bounds for term (a), term (b) and term (c), we have

\[\operatorname{Reg}_{T}\leq 8\beta_{T}(\delta)\sqrt{d\log(1+\frac{T}{\lambda})} \cdot\sqrt{\operatorname{Reg}_{T}+T\sigma^{\prime}(\mathbf{w}_{*}^{\top} \mathbf{x}_{*})}+2\kappa d(\beta_{T}(\delta))^{2}\ln(1+\frac{T}{\lambda \kappa}).\]

Resolving the above displayed inequality leads to

\[\operatorname{Reg}_{T}\leq 32\beta_{T}(\delta)\sqrt{d\log(1+\frac{T}{\lambda})} \sqrt{T\sigma^{\prime}(\mathbf{w}_{t}^{\top}\mathbf{x}_{*})}+(8\kappa+64)d( \beta_{T}(\delta))^{2}\ln(1+\frac{T}{\lambda}).\]

In the binary case, \(\beta_{T}(\delta)=\mathcal{O}(\sqrt{d}\log T)\). Then we have \(\operatorname{Reg}_{T}=\mathcal{O}(d\log^{\frac{3}{2}}T\sqrt{T/\kappa_{*}}+ \kappa d^{2}\log^{3}T)\), which completes the proof.

#### c.4.2 Computation Cost for Binary Case

Since the binary logistic bandit is a special case of the MLogB problem, the time complexity analysis in Appendix C.3.4 is also applicable in the binary case. The only difference is that we select the arm as \((\mathbf{x}_{t},\widetilde{\mathbf{w}}t)=\arg\max\mathbf{x}\in\mathcal{X},W\in \mathcal{C}_{t}(\delta)\mathbf{w}^{\top}\mathbf{x}\) in the binary case. As \(\mathcal{C}_{t}(\delta)\triangleq\{\mathbf{w}\in\mathcal{W}\mid\|\mathbf{w}- \mathbf{w}_{*}\|_{H_{t}}\leq\beta_{t}(\delta)\}\) is an ellipsoid, the optimization can be rewritten as:

\[\mathbf{x}_{t} =\operatorname*{arg\,max}_{\mathbf{x}\in\mathcal{X}}\left(\max_ {\|\mathbf{w}-\mathbf{w}_{t}\|_{H_{t}}\leq\beta_{t}(\delta)}\mathbf{w}^{\top} \mathbf{x}\right)\] \[=\operatorname*{arg\,max}_{\mathbf{x}\in\mathcal{X}}\left(\max_ {\|\mathbf{u}\|_{H_{t}}\leq\beta_{t}(\delta)}\mathbf{w}_{t}^{\top}\mathbf{x}+ \mathbf{u}^{\top}\mathbf{x}\right)\] \[=\operatorname*{arg\,max}_{\mathbf{x}\in\mathcal{X}}\mathbf{w}_{ t}^{\top}\mathbf{x}+\beta_{t}(\delta)\|\mathbf{x}\|_{H_{t}^{-1}}.\]

Given \(H_{t}^{-1}\), the above optimization problem can be solved in \(\mathcal{O}(d^{2})\) time.

### On the Minimax Optimal Bound for the MLogB

In the binary case, we have achieved the minimax dynamic regret bound \(\widetilde{\mathcal{O}}(\sqrt{T/\kappa_{*}})\) up to a logarithmic factor in terms of \(T\). In the MLogB problem, the best-known result is \(\widetilde{\mathcal{O}}(K\sqrt{T})\). A natural question arises: can we obtain a similar minimax optimal result in the MLogB problem? However, we find that it remains challenging both in terms of regret analysis and the design of efficient algorithms.

Challenge in Regret Analysis.To establish the minimax optimal bound for the binary case, as demonstrated in [9; 10] and we restate in (63), a critical step involves showing

\[\sqrt{\sum_{t\in T}\sigma^{\prime}(\mathbf{w}_{*}^{\top}\mathbf{x}_{t})}\leq \sqrt{\operatorname{Reg}_{T}+T\sigma^{\prime}(\mathbf{w}_{*}^{\top}\mathbf{x}_ {*})}.\]

In the MLogB problem, in order to obtain a similar result to the minimax optimal bound achieved in the binary case, it is sufficient to demonstrate

\[\sqrt{\sum_{t=1}^{T}\boldsymbol{\rho}^{\top}\nabla\boldsymbol{\sigma}(W_{*} \mathbf{x}_{t})\boldsymbol{\rho}}\leq\sqrt{2R\cdot\operatorname{Reg}_{T}+\sum _{t=1}^{T}\boldsymbol{\rho}^{\top}\Sigma(W_{*}\mathbf{x}_{*})\boldsymbol{\rho}}.\] (65)

However, it is unclear how to prove such a relationship as the binary case. Indeed, denoting by \(\mathbf{r}_{t}=\boldsymbol{\sigma}(W_{*}\mathbf{x}_{*})-\boldsymbol{\sigma}(W_ {*}\mathbf{x}_{t})\) the reward vector and \(r_{t,k}\) by its \(k\)-th entry, we can further rewrite the \(k\)-th entry of the vector \(\boldsymbol{\rho}^{\top}\Sigma(W_{*}\mathbf{x}_{t})\) can be further written as

\[[\boldsymbol{\rho}^{\top}\Sigma(W_{*}\mathbf{x}_{t})]_{k} =\sigma_{k}(W_{*}\mathbf{x}_{t})\boldsymbol{\rho}^{\top}(\mathbf{ e}_{k}-\boldsymbol{\sigma}(W_{*}\mathbf{x}_{t}))\] \[=(\sigma_{k}(W_{*}\mathbf{x}_{*})-r_{t,k})\rho_{k}-(\sigma_{k}(W_ {*}\mathbf{x}_{*})-r_{t,k})\boldsymbol{\rho}^{\top}(\boldsymbol{\sigma}(W_{*} \mathbf{x}_{*})-\mathbf{r}_{t})\] \[=\sigma_{k}(W_{*}\mathbf{x}_{*})\rho_{k}-\sigma_{k}(W_{*} \mathbf{x}_{*})\boldsymbol{\rho}^{\top}\boldsymbol{\sigma}(W_{*}\mathbf{x}_{*} )+(\sigma_{k}(W_{*}\mathbf{x}_{*}))\boldsymbol{\rho}^{\top}\mathbf{r}_{t}+r_{ t,k}\boldsymbol{\rho}^{\top}(\boldsymbol{\sigma}(W_{*}\mathbf{x}_{t})- \mathbf{e}_{k})\] \[=[\boldsymbol{\rho}^{\top}\Sigma(W_{*}\mathbf{x}_{*})]_{k}+\sigma _{k}(W_{*}\mathbf{x}_{*})\boldsymbol{\rho}^{\top}\mathbf{r}_{t}+r_{t,k} \boldsymbol{\rho}^{\top}(\boldsymbol{\sigma}(W_{*}\mathbf{x}_{t})-\mathbf{e}_ {k}).\]

In such a case, we can bound the left hand side of (65) by

\[\sqrt{\sum_{t=1}^{T}\boldsymbol{\rho}^{\top}\Sigma(W_{*}\mathbf{x }_{t})\boldsymbol{\rho}} =\sqrt{\left(\boldsymbol{\rho}^{\top}\Sigma(W_{*}\mathbf{x}_{*}) \boldsymbol{\rho}+\boldsymbol{\rho}^{\top}\mathbf{r}_{t}\cdot\boldsymbol{\rho}^ {\top}\left(\boldsymbol{\sigma}(W_{*}\mathbf{x}_{t})+\boldsymbol{\sigma}(W_{*} \mathbf{x}_{*})\right)-\sum_{k=1}^{K}\rho_{k}^{2}r_{t,k}\right)}\] \[\leq\sqrt{\sum_{t=1}^{T}\boldsymbol{\rho}^{\top}\Sigma(W_{*} \mathbf{x}_{*})\boldsymbol{\rho}+2R\cdot\operatorname{Reg}_{T}-\sum_{t=1}^{T} \sum_{k=1}^{K}\rho_{k}^{2}r_{t,k}}.\] (66)

In the binary case, In the binary case, the additional term becomes \(-\sum_{t=1}^{T}r_{t}=-\operatorname{Reg}_{T}<0\), thereby resulting in the derivation of (63). Nevertheless, in the context of the MLogB problem, this particular term has the potential to assume positive values, posing challenges in determining an upper bound for it.

Challenge in Efficient Algorithm Design.When extending algorithms that achieve minimax optimal bounds from the binary case to the multinomial case, there are computational concerns to address. In the binary case, the minimax optimal regret bound relies on constructing an optimistic reward through \(\widetilde{r}_{t}(\mathbf{x})=\arg\max_{\mathbf{w}\in\mathcal{C}_{t}(\delta)} \sigma(\mathbf{w}^{\top}\mathbf{x})\). Since \(\sigma(\mathbf{z})\) is an increasing function, the optimization problem can be simplified to

\[\widetilde{r}_{t}(\mathbf{x})=\operatorname*{arg\,max}_{\mathbf{w}\in \mathcal{C}_{t}(\delta)}\mathbf{w}^{\top}\mathbf{x},\]

which becomes a convex optimization problem when \(\mathcal{C}_{t}(\delta)\) is a convex set. However, when applying this analysis to the multinomial case, solving the problem requires optimizing

\[\widetilde{r}_{t}(\mathbf{x})=\operatorname*{arg\,max}_{W\in\mathcal{C}_{t}( \delta)}\boldsymbol{\rho}^{\top}\boldsymbol{\sigma}(W\mathbf{x}).\]

Here, the loss function is non-concave, rendering the maximization problem challenging to efficiently solve. Consequently, new approaches for constructing the optimistic reward function may be necessary.

## Appendix D Omitted Details for Experiments

In this section, we presents more empirical results for other configurations and introduced the parameter configurations for the contenders.

Experimental Details.For each configuration, both the arm set \(\mathcal{X}\) and the underlying unknown parameter \(W_{*}\) are randomly selected. In the binary case, the norm of the unknown parameter is set as \(\|\mathbf{w}_{*}\|_{2}=S\) with \(S=5\). As for the multinomial case, each row of \(\mathcal{W}_{*}\) are randomly sampled with \(\|\mathbf{w}_{*}^{(k)}\|_{2}=\widetilde{S}\) for all \(k\in[K]\) with \(\widetilde{S}=1\). The parameter of all contenders are set according to their order as suggested in the corresponding paper. We use \(\lambda=d\log(T)\) for Log-UCB1, \(\lambda=d\) for OL2M, \(\lambda=1\) for ada-OFU-ECOLog and \(\lambda=\sqrt{K}\alpha S\) for OFU-MLogB. The step size for OFU-MLogB is set as \(\eta=S/2+\ln(K+1)/4\). The experiments are run on Xeon E-2288G processors (8 cores, 3.7GHz base, 5.0GHz boost).

More Results.Figure 3 provides additional empirical results for the binary logistic bandit problem. These results align with the trends observed in the main paper, wherein our OFU-MLogB algorithm shows performance comparable to ada-OFU-ECOLog but with reduced computational overhead. Meanwhile, more results for the multinomial case are provided by Figure 4. The cumulative running time for MNL-UCB increase at a rate of \(\mathcal{O}(t^{2})\). In contrast, the running time for our OFU-MLogB exhibits a linear dependence with \(t\), attributable to the constant computation cost per round.

Figure 4: More results for multinomial logistic bandit.

Figure 3: More results for binary logistic bandit.