# Gliding over the Pareto Front with Uniform Designs

 Xiaoyuan Zhang\({}^{a}\), Genghui Li \({}^{b}\), Xi Lin \({}^{a}\), Yichi Zhang\({}^{c}\), Yifan Chen\({}^{d}\), Qingfu Zhang\({}^{a}\)

\({}^{a}\) Department of Computer Science, City University of Hong Kong;

\({}^{b}\) College of Computer Science and Software Engineering, Shenzhen University

\({}^{c}\) Department of Statistics, Indiana University Bloomingtom

\({}^{d}\) Departments of Mathematics and Computer Science, Hong Kong Baptist University

Corresponding to Qingfu Zhang. Contact: {xzhang2523-c@my.qingfu.zhang@}cityu.edu.hk. The source code is integrated into the LibMOON library, available at https://github.com/xzhang2523/libmoon.

###### Abstract

Multiobjective optimization (MOO) plays a critical role in various real-world domains. A major challenge therein is generating \(K\) uniform Pareto-optimal solutions to approximate the entire Pareto front. To address this issue, this paper firstly introduces _fill distance_ to evaluate the \(K\) design points, which provides a quantitative metric for the representativeness of the design. However, directly specifying the optimal design that minimizes the fill distance is nearly intractable due to the involved nested \(\min-\max-\min\) problem structure. To address this, we propose a surrogate "max-packing" design for the fill distance design, which is easier to optimize and leads to a rate-optimal design with a fill distance at most \(4\times\) the minimum value. Extensive experiments on synthetic and real-world benchmarks demonstrate that our proposed paradigm efficiently produces high-quality, representative solutions and outperforms baseline MOO methods.

## 1 Introduction

Multiobjective optimization (MOO) is widely used to inform real-world decision-making across various fields, including materials science [20, 46, 5, 30], recommendation systems [29, 61, 31], and industrial design [44, 52, 50, 57]. An MOO problem (MOP) involves optimizing multiple conflicting objectives, which can be (informally) formulated as:

\[\min_{\bm{x}\in\mathcal{X}}\bm{f}(\bm{x})=(f_{1}(\bm{x}),\ldots,f_{m}(\bm{x})),\] (1)

where \(m\) is the number of objectives. Equation (1) is a vector optimization problem and it does not admit a total ordering, therefore, to compare solutions, the concept of _Pareto optimality_ is introduced. A solution is called _Pareto optimal_ if no other solution \(\bm{x}^{\prime}\in\mathcal{X}\)_dominates_ it. Domination occurs when \(f_{i}(\bm{x}^{\prime})\leq f_{i}(\bm{x})\) for all \(i=1,\ldots,m\), with at least one strict inequality [37, 19]. In this paper, \(\bm{f}(\bm{x})\) denotes _the Pareto objective_ of a Pareto optimal solution. The set of all Pareto optimal solutions is the Pareto set (PS), and their objectives form the Pareto front (PF).

Under mild conditions, a PS or PF forms a continuous (\(m\)-1)-dim manifold containing infinitely many solutions [25]. For a general MOP, it is intractable to precisely depict the entire PS or PF with a closed-form expression. Researchers thus turns to use a small number \(K\) of diverse Pareto optimal objectives to "represent" the entire PF. Several prior works have been focused on generating diverse

Figure 1: **Covering of a Pareto Front (PF). Eight diverse Pareto objectives are used to cover the entire PF with a small covering radius.**solutions (see Section 2), but they lack formal definitions of representability and uniformity. In this paper, we define representability as the covering radius of a size-\(K\) solution set that covers the entire PF. An illustrative example is provided in Figure 1, where eight uniformly distributed solutions cover the entire PF with a small radius.

In this paper, we first introduce the fill distance (FD) as the minimal covering radius of the Pareto objectives, which measures how well a set of discrete solutions represents the true PF. A design with a smaller covering radius is considered a better representation of the PF. Next, we demonstrate that optimizing FD is challenging due to its nested \(\min-\max-\min\) structure (Equation (4)). To overcome this, we maximize the minimal (\(\max-\min\)) pairwise distances between Pareto objectives, which bounds the minimal covering radius up to a constant. Finally, we propose a bi-level optimization framework with a neural network to efficiently solve this \(\max-\min\) problem.

Our method, _UMOD_ (Uniform Multi-Objective optimization based on Decomposition) is within the decomposition-based MOO paradigm [58]. To show its effectiveness, we conduct comparative evaluations against methods on complex multiobjective problems with numerous local optimas and on fairness classification problems with thousands of decision variables. The contribution of this paper can be summarized as:

1. We introduce the fill distance as a metric for a set of Pareto solutions in MOO. We prove that the optimal fill distance design serves as an upper bound for the optimal Inverted Generational Distance (IGD) design, and that the max-packing design is rate-optimal with respect to the fill distance. Therefore, the max-packing design provides an effective surrogate for the optimal fill distance design.
2. We present a practical algorithm for identifying the maximum-packing design of Pareto objectives, and formulate it as a bi-level optimization problem. To expedite the optimization process, we introduce a neural network to avoid the frequent solving of the inner-loop optimization problem. Additionally, we analyze the optimization bounds of the neural network-based approach in comparison to solving the original optimization problem directly.
3. Finally, we evaluate our approach against leading MOO methods, including evolutionary algorithms and gradient-based algorithms, on both synthetic and real-world problems. UMOD outperforms these methods in terms of both uniformity and efficiency, based on commonly used metrics in MOO.

**Notations.** In this paper, \(\rho(\bm{y}^{(a)},\bm{y}^{(b)})\) represents the Euclidean distance between vectors \(\bm{y}^{(a)}\) and \(\bm{y}^{(b)}\), with bold letters for vectors. Superscripts denote vectors, and subscripts (e.g., \(y_{i}\)) indicate elements of a vector. A PF is denoted by \(\mathcal{T}\). The objective space is \(\mathcal{Y}=\{\bm{y}\mid\bm{f}(\bm{x}),\bm{x}\in\mathcal{X}\}\). \(\Delta_{m}\) is the \(m\)-D preference simplex; \(\Delta_{m}=\{\bm{y}\mid\sum_{i=1}^{m}y_{i}=1,y_{i}\geq 0,i\in[m]\}\), where \([m]=\{1,\ldots,m\}\). \(\mathbb{Y}\) denotes a set.

## 2 Related works

In this section, we review three lines of works to generate uniform or diverse Pareto objectives. We focus our discussions on uniform/diverse _Pareto objectives_ rather than _Pareto solutions_ because our goal is to produce uniform Pareto solutions in the objective space (\(\mathcal{Y}\)), not the decision space (\(\mathcal{X}\)).

### Methods to generate diverse Pareto objectives

Various MOO methods can effectively generate diverse Pareto objectives, for both _gradient-based_ and _evolution-computation (EC)-based_ frameworks. In the line of gradient-based methods, Pareto MultiTask Learning (PMTL) [32] generates Pareto objectives which are constrained in specific regions (sectors); MOO with Stein Variational Gradient Descent (MOO-SVGD) models objective vectors as particles, updating them through repulsive forces with a kernel function to maximize their separation; Exact Pareto Optimization (EPO) [36] aligns solutions with user-specific preference vectors, fostering a diverse distribution of Pareto objectives by specifying diverse preferences. For multiobjective evolutionary algorithms (MOEAs), NSGA2 [14] introduces the crowding distance and Pareto rank to achieve a diverse distribution of Pareto objectives; MOEA/D [58] and its variants generate diverse Pareto objectives by leveraging the positional relationship between preference vectors and Pareto objectives; Hypervolume-based methods (e.g., SMS-MOEA [6]) maximize the set of solutions with the largest hypervolume both to enhance convergence and diversity. A distinction of the proposedUMOD method with the previously mentioned methods is that, for general MOPs, the distribution of the achieved Pareto objectives remains unknown, whereas the objective distribution of the proposed method has desirable properties.

### Subset selection for multiobjective optimization

Another approach to generating a size-\(K\) diverse Pareto set is subset selection. This method first generates a large number of Pareto solutions, then selects \(K\) solutions to maximize hypervolume or minimize the IGD indicator [23; 53; 9; 45]. Solving the subset selection problem, a discrete optimization problem, is generally inefficient compared with continuous optimization problems. Recently, some approaches employ greedy algorithms [9; 33; 28] to obtain approximate solutions, with _naive greedy methods_ typically providing a \((1-1/e)\) guarantee. In contrast, our method addresses a continuous optimization problem on the PF, using gradient-based techniques to solve the established optimization problem to improve both accuracy and efficiency.

### Preference adjustment methods in the decomposition-based MOO paradigm

Since the proposed method can also be classified under the preference adjustment category, we discuss the relationship between the proposed UMOD and preference/weight2 adjustment methods. The study of preference adjustment methods start from MOEA/D-AWA [40], where its strategy is to remove the preference corresponding to the most crowded objective and add a preference corresponding to the most sparse one. Subsequently, several preference adjustment methods have been introduced [35], including DEA-GNG [34] and MOEA/D-SOM [22], which utilize neural gas networks to guide the selection of preference vectors. W-MOEA/D [21], tw-MOEA/D [38], pa\(\lambda\)-MOEA/D [48], and MOEA/D-AWG [55] use mathematical models to shape the non-dominated solutions and adjust preference vectors. The proposed method differs from other preference adjustment methods in two ways: (1) it models the PF with a neural network for better accuracy and efficiency, and (2) it offers a rigorous theoretical analysis for selecting preference vectors yielding uniformity and representativeness.

Footnote 2: In this paper, “preference vector” and “weight vector” are used interchangeably.

## 3 Pareto solutions with uniform designs

### FD as an upper bound of IGD

We first define _fill distance_ (FD) [11] of a set \(\mathbb{Y}\) (\(\mathbb{Y}=[\bm{y}^{(1)},\ldots,\bm{y}^{(K)}]\)) and establish its relationship with the inverted generational distance (IGD) indicator [49] of a set \(\mathbb{Y}\), a famous metric in MOO. Formally, FD and IGD are defined as follows:

**Definition 1** (FD & IGD).: \[\mathrm{FD}(\mathbb{Y})=\max_{\bm{y}\in\mathcal{T}}\min_{\bm{y}^{\prime}\in \mathbb{Y}}\rho(\bm{y},\bm{y}^{\prime})=\max_{\bm{y}\in\mathcal{T}}\mathrm{ dist}(\bm{y},\mathbb{Y}),\qquad\mathrm{IGD}(\mathbb{Y})=\int_{\mathcal{T}}\min_{ \bm{y}^{\prime}\in\mathbb{Y}}\rho(\bm{y},\bm{y}^{\prime})d\bm{y},\] (2)

where \(\rho(\cdot,\cdot)\) represents the Euclidean distance. The term \(\min_{\bm{y}^{\prime}\in\mathbb{Y}}\rho(\bm{y},\bm{y}^{\prime})\) represents the nearest distance from a point \(\bm{y}\) on the PF to the reference set \(\mathbb{Y}\). Therefore, \(\mathrm{FD}(\mathbb{Y})=\max_{\bm{y}\in\mathcal{T}}\min_{\bm{y}^{\prime}\in \mathbb{Y}}\rho(\bm{y},\bm{y}^{\prime})\) denotes the _covering radius_ of \(\mathbb{Y}\), i.e., the largest radius within which at least one solution in \(\mathbb{Y}\) covers the entire PF. However, \(\mathrm{IGD}(\mathbb{Y})\), which represents the average distance from a point on the PF to the set \(\mathbb{Y}\), lacks the clear geometric interpretation that fill distance offers. For MOO, the goal is to minimize a set of Pareto objectives, i.e., \(\mathbb{Y}\subset\mathcal{T}\), by optimizing either the FD or IGD indicator: \(\min_{\mathbb{Y}\subset\mathcal{T}}\mathrm{FD}(\mathbb{Y})\) or \(\min_{\mathbb{Y}\subset\mathcal{T}}\mathrm{IGD}(\mathbb{Y})\) to reach a diverse distribution. Let the optimal sets be \(\mathbb{Y}^{\mathrm{FD}}\) and \(\mathbb{Y}^{\mathrm{IGD}}\) respectively. The following theorem compares FD and IGD.

**Theorem 2** (FD as an upper bound of IGD).: \[\mathrm{IGD}(\mathbb{Y}^{\mathrm{IGD}})\leq\mathrm{IGD}(\mathbb{Y}^{\mathrm{FD }})\leq\mathrm{FD}(\mathbb{Y}^{\mathrm{FD}})\] (3)

The first inequality follows because \(\mathbb{Y}^{\mathrm{IGD}}\) minimizes IGD, and the second holds because the average distance (\(\mathrm{IGD}(\mathbb{Y}^{\mathrm{FD}})\)) is no greater than the maximum distance (\(\mathrm{FD}(\mathbb{Y}^{\mathrm{FD}})\)). Theorem 2 shows that \(\mathbb{Y}^{\mathrm{FD}}\), the optimal FD configuration, sets an upper bound for the IGD value. Since the optimal IGD configuration does not similarly bound FD, we focus on FD in this paper.

### Max-packing design as a surrogate of FD design

The minimization of FD involves solving the following nested \(\min-\max-\min\) problem:

\[d^{\mathrm{FD}}=\min_{\mathbb{Y}\subset\mathcal{T}}\max_{\bm{y}\in\mathcal{T}} \min_{\bm{y}^{\prime}\in\mathbb{Y}}\rho(\bm{y},\bm{y}^{\prime}).\] (4)

A small \(d^{\mathrm{FD}}\) suggests that the optimal configuration \(\mathbb{Y}^{\mathrm{FD}}\) effectively covers the PF with a low covering radius. However, this triply nested structure is challenging to optimize [54, 39], so we propose using a max-packing design as a surrogate for solving Equation (4).

\[d^{\mathrm{Pack}}=\max_{\mathbb{Y}\subset\mathcal{T}}\delta=\max_{\mathbb{Y} \subset\mathcal{T}}\left(\min_{1\leq i<j\leq K}\rho(\bm{y}^{(i)},\bm{y}^{(j)}) \right),\] (5)

where \(\delta\) represents the _separation distance_ between two vectors. The optimal design \(\mathbb{Y}^{\mathrm{Pack}}\), which solves the optimization problem (Equation (5)), is known as the max-packing design [8]. In this paper, we show that \(\mathbb{Y}^{\mathrm{Pack}}\) effectively optimizes FD _when the decision space is a PF_, as \(d^{\mathrm{FD}}\) is bounded by \(\mathbb{Y}^{\mathrm{Pack}}\) up to a constant factor, independent of size \(K\) in Theorem 3.

**Theorem 3** (Surrogate for minimal FD).: _Consider a connected, compact 3 PF \(\mathcal{T}\). The minimal fill distance \(d^{\mathrm{FD}}\) between \(\mathcal{T}\) and a size-\(K\) design \(\mathbb{Y}^{\mathrm{Pack}}\)/\(\mathbb{Y}^{\mathrm{FD}}\) will then be bounded as:_

Footnote 3: A connected, compact set is also called a _rectifiable_ set.

\[\frac{1}{4}d^{\mathrm{Pack}}\leq d^{\mathrm{FD}}\leq\mathrm{FD}(\mathbb{Y}^{ \mathrm{Pack}})\leq d^{\mathrm{Pack}},\] (6)

_Furthermore, the fill distance between \(\mathcal{T}\) and the optimal design \(d^{\mathrm{Pack}}\) induced by \(\mathbb{Y}^{\mathrm{Pack}}\) is upper bounded by \(d^{\mathrm{Pack}}\), which is guaranteed to be upper bounded by \(4d^{\mathrm{FD}}\). \(\mathbb{Y}^{\mathrm{Pack}}\) is thus considered a quality, rate-optimal representative for the whole PF \(\mathcal{T}\)._

The second inequality \(d^{\mathrm{FD}}\leq d^{\mathrm{Pack}}\) is proved by Auffray et al. [3], Pronzato [39], and we provide a tighter lower bound \(d^{\mathrm{Pack}}/4\), utilizing the topological property of a PF. The complete proof of Theorem 3 is left in Appendix A.1. Furthermore, under an additional strict inequality condition \(d^{\mathrm{Pack}}_{K}<d^{\mathrm{Pack}}_{K+1}\) on the PF, the max-packing design \(\mathbb{Y}^{\mathrm{Pack}}_{K}\) serves as a \(d^{\mathrm{Pack}}_{K}\)-covering of \(\mathcal{T}\), which is established by Theorem 4. The subscript "\(K\)" specifically denotes the max-packing distance \(d^{\mathrm{Pack}}_{K}\) for a size-\(K\) design, similarly used for \(\mathbb{Y}^{\mathrm{Pack}}_{K}\) to represent a size-\(K\) design.

**Theorem 4**.: _Consider a connected, compact PF (\(\mathcal{T}\)), with the property \(d^{\mathrm{Pack}}_{K}<d^{\mathrm{Pack}}_{K+1}\), the max-packing design \(\mathbb{Y}^{\mathrm{Pack}}_{K}\) covers \(\mathcal{T}\) with radius of at most \(d^{\mathrm{Pack}}_{K}\)._

This theorem suggests that \(\mathbb{Y}^{\mathrm{Pack}}_{K}\) can represent \(\mathcal{T}\) well since the maximal distance between any vector \(\bm{y}\in\mathcal{T}\) and \(\mathbb{Y}^{\mathrm{Pack}}_{K}\) is bounded by \(d^{\mathrm{Pack}}_{K}\).

### Characterizations of a max-packing design

This section discusses key properties of the max-packing design on a PF. For bi-objective problems, \(\mathbb{Y}^{\mathrm{Pack}}\) shows favorable properties when \(\mathbb{Y}^{\mathrm{Pack}}\subset\mathcal{T}\), as formalized in Theorem 5, with the proof in Appendix A.2.

**Theorem 5** (Characterization of \(\mathbb{Y}^{\mathrm{Pack}}\) for biobjective problems).: _Let \(\mathbb{Y}^{\mathrm{Pack}}=[\bm{y}^{(1)},\ldots,\bm{y}^{(K)}]\) be sorted by the first component, such that \(y^{(1)}_{1}\leq\ldots\leq y^{(K)}_{1}\). For a compact, connected \(\mathcal{T}\), \(\mathbb{Y}^{\mathrm{Pack}}\) is characterized as follows:_

1. _Equal spacing:_ \(\rho(\bm{y}^{(1)},\bm{y}^{(2)})=\ldots=\rho(\bm{y}^{(K-1)},\bm{y}^{(K)})\)_, for_ \(K\geq 3\)_._
2. _Endpoint alignment:_ \(\bm{y}^{(1)}\) _and_ \(\bm{y}^{(K)}\) _are two endpoints (_\(\bm{p}^{(1)},\bm{p}^{(2)}\)_) of_ \(\mathcal{T}\)_, i.e.,_ \(\bm{y}^{(1)}=\bm{p}^{(1)}=[\inf_{\bm{y}\in\mathcal{T}}y_{1},\sup_{\bm{y}\in \mathcal{T}}y_{2}]\) _and_ \(\bm{y}^{(K)}=\bm{p}^{(2)}=[\sup_{\bm{y}\in\mathcal{T}}y_{1},\inf_{\bm{y}\in \mathcal{T}}y_{2}]\)_, for_ \(K\geq 2\)_._

**Remark**.: Firstly, \(\mathbb{Y}^{\mathrm{Pack}}\), including both the starting and ending points, spans the maximum range among all designs, which is a desirable property. Secondly, equal pairwise distances between Pareto objectives yields an intuitive interpretation of uniformity. Maximizing hypervolume ensures the "equal spacing" property only for bi-objective _linear_ PFs [4][Theorem 4], while the max-packing design only requires the PF to be _compact and connected_.

Besides this non-asymptotical bi-objective results, we examine the asymptotic properties of \(\mathbb{Y}^{\mathrm{Pack}}\) with Theorem 6.

**Theorem 6** (Asymptotic uniformity [8](Theorem. 2.1)).: _As the number of set size \(K\rightarrow\infty\), the set sequence \(\{\mathbb{Y}^{\mathrm{Pack}}_{K}\}\) weakly converge to a uniform distribution over a compact, connected \(\mathcal{T}\). Specifically, for any subset \(\mathcal{B}\subset\mathcal{T}\) with measure-zero boundary, the proportion of points in \(\mathbb{Y}^{\mathrm{Pack}}_{K}\) lying within \(\mathcal{B}\) converges to the proportion of \(\mathcal{T}\) occupied by \(\mathcal{B}\):_

\[\lim_{K\rightarrow\infty}\frac{\#(\mathbb{Y}^{\mathrm{Pack}}_{K}\cap\mathcal{ B})}{\#(\mathbb{Y}^{\mathrm{Pack}}_{K})}=\frac{\mathrm{Vol}(\mathcal{B})}{ \mathrm{Vol}(\mathcal{T})}=\mathbb{P}(\bm{y}\in\mathcal{B}\mid\bm{y}\in \mathcal{T}),\] (7)

_where \(\#\) denotes the number of points in a set, and "\(\mathrm{Vol}\)" denotes the volume of a set._

Theorem 6 shows that as the solution set size \(K\) grows, \(\mathbb{Y}^{\mathrm{Pack}}_{K}\) approaches a uniform distribution. Specifically, random variable \(\bm{Y}^{\mathrm{Pack}}_{K}\xrightarrow{d}\mathrm{Unif}(\mathcal{T})\), meaning \(\bm{Y}^{\mathrm{Pack}}_{K}\), the categorical distribution where each \(\bm{y}\in\mathbb{Y}^{\mathrm{Pack}}_{K}\) has probability \(1/K\), converges in distribution to \(\mathrm{Unif}(\mathcal{T})\).

## 4 Efficient optimization of a size-\(K\) uniform set

The original max-packing problem (Equation (5)) maximizes the minimal pairwise distance among Pareto objectives and can be reformulated as the following constrained optimization problem on the PF:

\[\max\left(\min_{1\leq i<j\leq K}\rho(\bm{y}^{(i)},\bm{y}^{(j)})\right)\qquad \qquad\text{s.t. }\bm{y}^{(i)},\bm{y}^{(j)}\in\mathcal{T}.\] (8)

To constrain \(\bm{y}^{(i)},\bm{y}^{(j)}\) pairs as Pareto objectives, we solve decision variables of \(\bm{y}^{(i)}\)'s as the optimal solution of the following modified Tchebycheff (mTche) aggregation function (Equation (9)),

\[\bm{y}=\tilde{\bm{h}}(\bm{\lambda})=\arg\min_{\bm{y}^{{}^{\prime}}\in\mathcal{ Y}}\left\{\frac{y_{i}-z_{i}}{\lambda_{i}}\right\}:\qquad\qquad\left[0, \frac{\pi}{2}\right]^{m-1}\mapsto\mathbb{R}^{m},\] (9)

where \(\bm{z}\) is a reference point (\(z_{i}\leq y_{i},\forall\bm{y}\in\mathcal{Y},\forall i\in[m]\)). This substitution is equivalent _when the optimal solution of Equation (9) is unique_, as for any Pareto objective \(\bm{y}\), there exists a preference \(\bm{\lambda}\in\Delta_{m}\) such that the optimal value of Equation (9) matches \(\bm{y}\) (explained in Appendix A.4). Substituting Equation (9) into Equation (8) yields the following bi-level optimization problems:

\[\left\{\begin{aligned} d^{\mathrm{Pack}}&=\max_{\bm{ \vartheta}^{(1)},\ldots,\bm{\vartheta}^{(K)}}\min_{1\leq i<j\leq K}\rho(\bm{y }^{(i)},\bm{y}^{(j)})\\ \bm{y}^{(k)}&=\arg\min_{\bm{y}^{(k)}\in\mathcal{Y}} \left\{\frac{y_{i}^{(k)}-z_{i}}{\lambda_{i}(\bm{\vartheta}^{(k)})}\right\}, \,i\in[m].\end{aligned}\right.\Rightarrow\begin{aligned} d^{ \mathrm{Pack}}&=\max_{\bm{\vartheta}^{(1)},\ldots,\bm{\vartheta}^{(K )}\leq 1\leq i<j\leq K}\rho(\bm{h}(\bm{\vartheta}^{(i)}),\bm{h}(\bm{\vartheta}^{(j)})) \\ \text{s.t. }&\bm{\vartheta}^{(k)}\in\left[0,\frac{\pi}{2} \right]^{m-1}.\end{aligned}\right.\] (10)

Exact Pareto optimal solutions can also be obtained using PMGDA [59], which achieves faster convergence with a suitable control parameter \(\sigma\). The function \(\bm{\lambda}(\bm{\vartheta})\) converts a "preference angle" from an angle space \(\left[0,\frac{\pi}{2}\right]^{m-1}\) into a preference vector. The conversion relationship is detailed in Appendix C.3. We use \(\bm{\lambda}(\bm{\vartheta})\) as decision variables for easier optimization since \(\bm{\lambda}(\bm{\vartheta})\) is constrained in a box. In the right equation, the Pareto objective is denoted as \(\bm{y}=\bm{h}(\bm{\vartheta})=\tilde{\bm{h}}(\bm{\lambda}(\bm{\vartheta}))\). Various bi-level optimization methods [60, 47] can be used to solve the problem (Equation (10)). For efficiency consideration, we use a gradient-based approach. Define \(\delta=\min_{(i,j)}\rho(\bm{y}^{(i)},\bm{y}^{(j)})\), where \((i^{*},j^{*})\) is the optimal pair from \(\arg\min_{(i,j)}\rho(\bm{y}^{(i)},\bm{y}^{(j)})\). After some basic algebraic calculations, \(\frac{\partial\delta}{\partial\bm{\vartheta}}\) can be calculated by the following two equations:

\[\frac{\partial\delta}{\partial\bm{\vartheta}^{(i^{*})}}=\underbrace{\frac{ \partial\bm{h}(\bm{\vartheta}^{(i^{*})})}{\partial\bm{\vartheta}^{(i^{*})}}}_{ \bm{B}(n\times m)}\underbrace{\frac{\bm{h}(\bm{\vartheta}^{(i^{*})})-\bm{h}( \bm{\vartheta}^{(j^{*})})}{\rho(\bm{h}(\bm{\vartheta}^{(i^{*})}),\bm{h}(\bm{ \vartheta}^{(j^{*})}))}}_{\bm{A}(m\times 1)}\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\, \,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\, \,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\, \,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\, \,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\, \,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\, \,\,\,\,\,\,\,\,\,\,\,\,\,\,\,Instead, we use a neural model \(\bm{h}_{\phi}\) trained on historical data \((\bm{\vartheta},\bm{h}(\bm{\vartheta}))\) to approximate \(\bm{h}\), enabling efficient estimation via \(\frac{\partial\bm{h}_{\phi}}{\partial\bm{\vartheta}}\). We analyze the neural model's error in Theorem 7, with full details in Appendix A.3.

**Theorem 7** (Optimization error \(\epsilon_{\mathrm{nn}}\) introduced by using a network).: _Let \(\bm{h}_{\phi}(\bm{\vartheta})\) be an approximator of \(\bm{h}(\bm{\vartheta})\) such that \(||\bm{h}_{\phi}(\bm{\vartheta})-\bm{h}(\bm{\vartheta})||\leq\epsilon\), for every \(\bm{\vartheta}\in[0,\frac{\pi}{2}]^{m-1}\), as commonly assumed in bi-level optimization, e.g., [18], Eq. (10). \(\epsilon_{\mathrm{nn}}\) is the difference between the maximum of the minimal distances calculated using the approximate function \(\bm{h}_{\phi}\) and the true function \(\bm{h}\). Then, \(\epsilon_{\mathrm{nn}}\) is bounded by \(2\epsilon\):_

\[\epsilon_{\mathrm{nn}}=\left|\max_{\bm{\vartheta}:(1),\dots,\bm{\vartheta}^{ (K)}}\min_{1\leq i<j\leq K}\rho(\bm{h}_{\phi}(\bm{\vartheta}^{(i)}),\bm{h}_{ \phi}(\bm{\vartheta}^{(j)}))-d^{\mathrm{Pack}}\right|\leq 2\epsilon.\]

**Remark.** The error \(\epsilon\), defined as \(||\bm{h}_{\phi}(\bm{\vartheta})-\bm{h}(\bm{\vartheta})||\leq\epsilon\), is both influenced by the covering radius \(R\) of the estimated solutions \(\bm{h}_{\phi}(\bm{\vartheta}^{(1)}),\dots,\bm{h}_{\phi}(\bm{\vartheta}^{(K)})\) and the fitting error \(\epsilon_{\mathrm{fit}}\), where \(\epsilon_{\mathrm{fit}}=\max_{k\in[K]}||\bm{h}_{\phi}(\bm{\vartheta}^{(k)})- \bm{h}(\bm{\vartheta}^{(k)})||\). For any \(\bm{\vartheta}\), the error satisfies \(||\bm{h}_{\phi}(\bm{\vartheta})-\bm{h}(\bm{\vartheta})||\leq L||\bm{\vartheta} -\bm{\vartheta}^{(i^{\prime})}||+\epsilon_{\mathrm{fit}}\leq L\cdot R+\epsilon_ {\mathrm{fit}}\), where \(L\) is the Lipschitz constant of function \((\bm{h}_{\phi}(\bm{\vartheta})-\bm{h}(\bm{\vartheta}))\), \(\bm{\vartheta}^{(i^{\prime})}\) is the nearest solution to \(\bm{\vartheta}\) among the estimated solutions, and \(R\) is the covering radius, which can be further reduced by adding more training pairs. For overparameterized networks, \(\epsilon_{\mathrm{fit}}\) can be considered as very small.

**Practical algorithms.** Due to the space limit, the pseudo-codes of UMOD are provided in Algorithm 1 and Algorithm 2 in Appendix C.1. Initially, \(K\) diverse preferences are generated by the Das-Dennis algorithm [12]. Then either a decomposition-based multiobjective evolutionary algorithm or a gradient-based MOO with mTche aggregation function is employed for producing preference angle and Pareto objective pairs \((\bm{\vartheta},\bm{y})\). Evolutionary algorithms are preferred for problems with multiple local optimas, while gradient-based MOO methods are preferred for multiobjective machine learning (MOML) problems. Given \((\bm{\vartheta},\bm{y})\) pairs, a PF model \(\bm{h}_{\phi}(\bm{\vartheta})\) is fitted by optimizing the mean square estimation error. Finally, preference angles are updated to maximize the minimal pairwise distances of Pareto objectives. These two steps are repeated alternatively until convergence.

## 5 Experiments

The experiments compare UMOD with other methods on two types of MOPs: (1) those with multiple local optimas which can be solved by MOEAs efficiently, and (2) multiobjective fairness classification neural networks as decision variables. MOEAs and multiobjective fairness problems are executed with 31/5 random seeds, separately. We employ seven indicators to assess performance of different algorithms: **(1) Hypervolume** (\(\uparrow\)) [24], **(2) IGD** (\(\downarrow\)) [26], **(3) Sparsity** (\(\downarrow\)) [56], **(4) Spacing** (\(\downarrow\)) [43], (5) Uniformity (\(\uparrow\)), (6) Smooth Uniformity (\(\uparrow\)), and (7) Fill distance** (\(\downarrow\)). Indicators 1-2 focus on convergence and diversity for multi-objective optimization (MOO), while indicators 3-7 evaluate solution uniformity. See Appendix B.1 for more detailed expression for these indicators.

### Comparison with MOEAs

We demonstrate the effectiveness of our proposed method across a diverse set of MOEA benchmark problems, including the ZDT4[16], DTLZ [15]5, and real-world testing problems [50]. Real-world testing problems include: four-bar truss design (RE21), reinforced concrete beam design (RE22), disc brake design (RE33), rocket injector design (RE37), car side impact design (RE41), and conceptual marine design (RE42). Notably, RE41 and RE42 are complex four-objective problem having a large objective spaces. The prefix "RE" denotes this problem is a real-world one.

Footnote 4: ZDT5 is a discrete optimization problem and is commonly excluded in MOEA studies.

Baseline MOEAs include: _MOEA/D_[58], a decomposition-based approach; (2) _MOEA/D-AWA_[40],

Figure 2: (a): UMOD solutions are more uniform. (b): A PF model can be trained with a small number of solutions.

\begin{table}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|} \hline \hline \multicolumn{2}{|c|}{Indicate} & \multicolumn{2}{c|}{DEA-GNG [34]} & \multicolumn{2}{c|}{LMPPE [51]} & \multicolumn{2}{c|}{Subnet [9, 45]} & NSGA3 [13, 27] & SMS-EMOA [6] & MOEAAD [58] & MOEAAD-AWA [46] & UMOD \\ \hline HV & 1.03 (0.00)(6) & 1.03 (0.00)(2) & 1.02 (0.00)(7) & 1.03 (0.00)(5) & 1.04 (0.00)(1) & 1.03 (0.00)(4) & 1.03 (0.00)(3) & **1.24 (0.00) (9)** \\ IGD & 5.68 (0.29)(7) & 5.42 (0.21)(6) & 5.21 (0.40)(1) & 5.28 (0.00)(3) & 5.22 (0.07)(2) & 5.30 (0.00)(4) & 5.42 (0.02) (5) & **5.19 (0.00) (9)** \\ Spacing & 6.35 (1.74)(7) & 4.44 (1.82)(3) & 2.51 (0.47)(3) & 5.90 (0.00)(5) & 1.04 (0.06)(1) & 5.92 (0.01)(6) & 3.69 (0.00) (4) & **0.12 (0.06)** \\ ZDTI & Sparsity & 4.80 (0.19)(7) & 4.55 (0.12)(4) & 2.59 (1.08)(9) & 4.00 (0.00)(5) & 4.48 (0.01)(2) & 4.61 (0.00)(6) & 4.54 (0.01)(5) & 4.39 (0.00)(1) \\ Uniform & 1.33 (0.11)(6) & 1.67 (0.32)(2) & 0.89 (0.10)(7) & 1.53 (0.00)(3) & 1.85 (0.03)(1) & 1.51 (0.00)(4) & 1.51 (0.00)(5) & **2.07 (0.01) (9)** \\ Uniform & 0.47 (0.12)(6) & 6.68 (0.13)(2) & 0.09 (0.10)(7) & 0.49 (0.00)(4) & 0.74 (0.01)(4) & 0.48 (0.00)(5) & 0.53 (0.00)(3) & **0.7 (0.00) (9)** \\ Fill Distance & 1.60 (0.23)(6) & 1.23 (0.09)(7) & 2.00 (0.10)(7) & 1.55 (0.00)(5) & 1.16 (0.00)(4) & 1.43 (0.00)(3) & **1.04 (0.01) (9)** \\ \hline HV & 1.24 (0.00)(5) & 1.23 (0.01)(7) & 1.24 (0.00)(4) & 1.24 (0.00)(2) & 1.24 (0.00)(1) & 1.24 (0.00)(6) & 1.24 (0.00)(3) & **1.24 (0.00) (6)** \\ IGD & 4.63 (0.28)(5) & 4.61 (0.13)(4) & 5.15 (0.11)(6) & 4.44 (0.00)(3) & 4.23 (0.02)(5) & 5.40 (0.02)(4) & 4.33 (0.00)(4) & **4.12 (0.00) (6)** \\ Spacing & 6.63 (1.05)(6) & 3.62 (0.53)(9) & 1.68 (0.00)(5) & 5.71 (0.00)(5) & 1.91 (0.72)(5) & 1.09 (0.72)(5) & 1.09 (0.74)(3) & **0.12 (0.05) (9)** \\ RE2I & Sparsity & 3.10 (0.21)(6) & 2.90 (0.00)(6) & **1.74 (0.00)(9)** & 3.02 (0.00)(5) & 2.82 (0.02)(2) & 3.87 (0.02)(7) & 2.84 (0.01)(3) & 2.70 (0.00)(1) \\ Uniform & 0.81 (0.12)(7) & 0.95 (0.16)(9) & 0.05 (0.05)(4) & 1.16 (0.00)(2) & 1.26 (0.05)(1) & 0.93 (0.00)(6) & 1.11 (0.00)(3) & **1.02 (0.01) (9)** \\ Slufantom & -0.03 (0.07)(5) & 1.20 (0.03)(5) & -0.17 (0.00)(7) & 0.08 (0.00)(4) & 0.20 (0.01)(1) & -0.17 (0.00)(6) & 1.03 (0.01)(2) & **0.01 (0.00) (6)** \\ Fill Distance & 1.45 (0.20)(4) & 1.21 (0.12)(5) & 2.62 (0.01)(7) & 1.47 (0.00)(5) & 1.09 (0.04)(1) & 2.11 (0.01)(6) & 1.15 (0.02) (2) & **0.33 (0.00) (6)** \\ \hline HV & 5.14 & 4.14 & 5.57 & 3.86 & **0.57** & 3.86 & 3.57 & 1.29 \\ IGD & 5 & 4.86 & 4 & 2.43 & 2.29 & 4.43 & 4 & **1** \\ Spacing & 5.71 & 2.71 & 3.86 & 3.86 & 3.9 & 5.14 & 3.57 & **0.14** \\ Rank & Sparsity & 5.29 & 5.71 & 1.43 & 3.71 & 2.71 & 4.86 & 3.43 & **0.86** \\ Uniform & 5 & 3.86 & 6.43 & 3 & 1.71 & 4.29 & 3.57 & **0.14** \\ Uniform & 5.14 & 3.57 & 6.86 & 3.14 & 2 & 4 & 3.14 & **0.14** \\ Fill Distance & 5.43 & 3.57 & 5.57 & 3.43 & 2.29 & 3.57 & 3.29 & **0.86** \\ \hline \hline \end{tabular}
\end{table}
Table 1: Partial results for biobjective problems (full results are in Table 7).

Figure 4: Results on RE21 and DTLZ2.

Figure 3: Result comparison by different methods on ZDT1.

integrating adaptive weight adjustment; (3) _NSGA3_[13, 27], generating diverse Pareto objectives through crowding distance; (4) _SMS-EMOA_[6], maximizing hypervolume for diverse solutions; (5) _LMPFE_[51], estimating the PF using multiple local models; (6) _Subset selection_[9, 45], choosing a solution set by hypervolume maximization6; and (7) _DEA-GNG_[34], a preference adjustment method based on growing neural gas network. Methods (1)-(4) are classical MOEA methods implemented by Pymoo [7], while methods (5)-(7) are more recent methods. Full name of these methods are provided in Table 4.

Footnote 6: Code: https://github.com/HisaoLabSUSTC/GAHSS.

We present the results for _biobjective_ problems in Figure 3 and Table 17. By directly minimizing maximal pairwise distances, the uniform indicator (which corresponds to maximal pairwise distances, see Appendix B.1, metric 5) is optimized effectively and ranks best among all methods. The fill distance, a surrogate for maximal pairwise distance up to constant, also performs best among all methods. This indicates that solutions found by UMOD cover the true PF with the minimal covering radius among all methods. Figure 3 further confirms that the covering radius of UMOD is significantly smaller than other methods. We also observe that the IGD indicator (Appendix B.1, metric 2), representing the mean Euclidean distance between the true PF and the found size-\(K\) solution set, is significantly improved. The significant improvement over IGD, a well-established indicator of uniformity and convergence of Pareto solutions, suggests that our method finds high

\begin{table}
\begin{tabular}{c|l|l|l|l|l|l|l|l|l|l|l} \hline \hline  & Indicator & DEA-GNG [34] & LMPFE [51] & Subset [45] & NSGA3 [13] & SMS-EMOA [6] & MOEAD [58] & MOEAD-AWA [40] & UMOD \\ \hline \multirow{7}{*}{Rank} & HV & 1.01 (0.01) (7) & 1.05 (0.00) (6) & 1.08 (0.00) (1) & 1.06 (0.00) (5) & **1.08 (0.00) (6)** & 1.06 (0.00) (3) & 1.06 (0.00) (4) & 1.07 (0.00) (2) \\  & IGD & 1.25 (0.04) (2) & 1.26 (0.09) (1) & 1.54 (0.00) (1) & 1.25 (0.00) (3) & 1.54 (0.025) (1) & 1.55 (0.00) (5) & 1.25 (0.00) (4) & **1.09 (0.00) (1)** \\  & Spacing & 25.7 (1.73) & 2.64 (0.39) (1) & 8.97 (0.00) (7) & 5.45 (0.00) (7) & 7.15 (0.51) (6) & 8.54 (0.01) (4) & 5.45 (0.01) (1) & **6.52 (0.21) (6)** \\ \cline{2-11}  & Sparsity & **1.06 (0.13)** & 2.18 (0.13) (2) & 2.42 (0.00) (2) & 2.43 (0.00) (2) & 2.75 (0.014) & 2.43 (0.00) (6) & 2.43 (0.00) (5) & 1.61 (0.13) (1) \\ \cline{2-11}  & Uniform & **1.58 (0.19)** & 2.54 (0.17) & 1.09 (0.00) (7) & 2.43 (0.00) (4) & 1.51 (0.16) (2) & 2.43 (0.00) (2) & 2.34 (0.00) (2) & **1.37 (0.09) (6)** \\ \cline{2-11}  & StUniform & 0.36 (0.23) (5) & 0.97 (0.06) (1) & -0.04 (0.00) (7) & 9.05 (0.00) (4) & 0.18 (0.07) (16) & 9.95 (0.00) (2) & 9.05 (0.00) (3) & **1.15 (0.02) (1)** \\ \cline{2-11}  & Full Distance & 3.20 (0.60) (5) & 2.69 (0.10) (4) & 3.54 (0.00) (7) & 2.59 (0.00) (1) & 3.42 (0.16) (6) & 2.59 (0.00) (3) & 2.59 (0.00) (2) & **2.37 (0.08) (9)** \\ \hline \multirow{7}{*}{Rank} & HV & 6.8 & 4.6 & 1.8 & 4.4 & **0.2** & 3.6 & 4.2 & 2.4 \\  & IGD & 6 & 3 & 4.6 & 1.8 & 4.6 & 3.4 & 4 & **0.6** \\ \cline{1-1}  & Spacing & 4.4 & 2.8 & 5.6 & 3.6 & 4 & 3.4 & 3.6 & **0.6** \\ \cline{1-1}  & Sparsity & **1.4** & 3.6 & 1.6 & 4.6 & 4.8 & 5.6 & 4.6 & 1.8 \\ \cline{1-1}  & Uniform & 5.8 & 2 & 5.8 & 2.8 & 4 & 3.4 & 3.4 & **0.8** \\ \cline{1-1}  & StUniform & 6 & 2 & 5.8 & 3.4 & 4.4 & 3 & 3.2 & **0.2** \\ \cline{1-1}  & Full Distance & 6.6 & 4.2 & 5.2 & 1 & 4.2 & 3.2 & 3.2 & **0.4** \\ \hline \hline \end{tabular}
\end{table}
Table 2: Partial results on three-objective problems (full results are in Table 8).

Figure 5: Results on RE41 by different methods (full results are in Figure 8).

Figure 6: Results on RE42 by different methods (full results are in Figure 9).

[MISSING_PAGE_FAIL:9]

Results with five solutions are illustrated in Figure 7 compared with PMGDA [59], Hypervolume-gradient method (HVGrad), EPO [36], modified Tchebycheff aggregation function method (AggmTche) [58]. For the Adult dataset, all methods run for 30 epochs, and for the Compass dataset, 20 epochs. A detailed description of these methods is in Appendix C.4. In real-world problems, the true PF range is often unknown, making it difficult for preference-based methods to select uniform preference vectors. If these vectors exclude PF endpoints, parts of the PF can not be recovered. In contrast, HV-Grad and the proposed UMOD method do not rely on preferences and can automatically identify a large PF. Figure 7 validates Theorem 5, showing that UMOD identifies both endpoints of the true PF, while HVGrad's endpoints cannot be determined.

Numerical results are presented in Table 3. In real-world problems, objectives often vary in scale, making uniform preference vectors non-equivalent to uniform objective vectors. UMOD, however, is designed to generate uniform objective vectors independent of scale, as evidenced by its superior performance in uniformity and soft uniformity indicators. Additionally, UMOD's spacing indicator, measuring neighborhood distance deviation, is significantly lower than other methods (except Agg-LS, which produces duplicate solutions in the Adult dataset, resulting in the lowest spacing). UMOD's Span indicators outperform other methods a lot, demonstrating its ability to recover a more complete PF, a desirable feature. Many methods show similar HV indicators, but their solution configurations vary, suggesting HV optimization is a coarse measure of uniformity. UMOD's significantly better uniformity performance indicates that directly optimizing uniformity, as in UMOD, is a promising approach for generating diverse Pareto solutions.

## 6 Conclusions and further works

**Conclusions.** In this paper, we have proposed a new understanding of a longstanding problem in MOO, generating \(K\) uniform and representative Pareto objectives, through searching for a max-packing design on the PF. We provide rigorous analysis of the resulting objective design, and in particular, we show this design will asymptotically converge to the uniform measure over Pareto front. With this new paradigm, we also empirically demonstrate how the space-filling design we obtain can benefit downstream performance with both synthetic and real-world MOO tasks. Overall, we believe that we pave a new way for (rate-)optimally configuring the Pareto objectives.

**Future works** include applying UMOD to large-scale real-world multiobjective problems, such as material design, vaccine design, and recommendation systems. The broader impacts of this work is discussed in Appendix D.1.

## Acknowledge

GH Li offers guidance on evolutionary computation, while YF Chen proves Theorem 3. The work described in this paper was supported by the Research Grants Council of the Hong Kong Special Administrative Region, China [GRF Project No. CityU 11215622].

Figure 7: Result on fairness classification.

## References

* [1] Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner. Machine bias. In _Ethics of data and analytics_, pages 254-264. Auerbach Publications, 2022.
* [2] Arthur Asuncion and David Newman. Uci machine learning repository, 2007.
* [3] Yves Auffray, Pierre Barbillon, and Jean-Michel Marin. Maximin design on non hypercube domains and kernel interpolation. _Statistics and Computing_, 22:703-712, 2012.
* [4] Anne Auger, Johannes Bader, Dimo Brockhoff, and Eckart Zitzler. Theory of the hypervolume indicator: optimal \(\mu\)-distributions and the choice of the reference point. In _Proceedings of the tenth ACM SIGEVO workshop on Foundations of genetic algorithms_, pages 87-102, 2009.
* [5] Sterling G Baird, Ramsey Issa, and Taylor D Sparks. Materials science optimization benchmark dataset for multi-objective, multi-fidelity optimization of hard-sphere packing simulations. _Data in Brief_, 50:109487, 2023.
* [6] Nicola Beume, Boris Naujoks, and Michael Emmerich. Sms-emoa: Multiobjective selection based on dominated hypervolume. _European Journal of Operational Research_, 181(3):1653-1669, 2007.
* [7] J. Blank and K. Deb. pymoo: Multi-objective optimization in python. _IEEE Access_, 8:89497-89509, 2020.
* [8] S Borodachov, D Hardin, and E Saff. Asymptotics of best-packing on rectifiable sets. _Proceedings of the American Mathematical Society_, 135(8):2369-2380, 2007.
* [9] Weiyu Chen, Hisao Ishibuchi, and Ke Shang. Fast greedy subset selection from large candidate solution sets in evolutionary multiobjective optimization. _IEEE Transactions on Evolutionary Computation_, 26(4):750-764, 2021.
* [10] Eng Uno Choo and Derek R Atkins. Proper efficiency in nonconvex multicriteria programming. _Mathematics of Operations Research_, 8(3):467-470, 1983.
* [11] Paolo Climaco and Jochen Garcke. On minimizing the training set fill distance in machine learning regression, 2024. URL https://arxiv.org/abs/2307.10988.
* [12] Indraneel Das and John E Dennis. Normal-boundary intersection: A new method for generating the pareto surface in nonlinear multicriteria optimization problems. _SIAM journal on optimization_, 8(3):631-657, 1998.
* [13] Kalyanmoy Deb and Himanshu Jain. An evolutionary many-objective optimization algorithm using reference-point-based nondominated sorting approach, part i: Solving problems with box constraints. _IEEE Transactions on Evolutionary Computation_, 18(4):577-601, 2014. doi: 10.1109/TEVC.2013.2281535.
* [14] Kalyanmoy Deb, Amrit Pratap, Sameer Agarwal, and TAMT Meyarivan. A fast and elitist multiobjective genetic algorithm: Nsga-ii. _IEEE transactions on evolutionary computation_, 6(2):182-197, 2002.
* [15] Kalyanmoy Deb, Lothar Thiele, Marco Laumanns, and Eckart Zitzler. Scalable multi-objective optimization test problems. In _Proceedings of the 2002 Congress on Evolutionary Computation. CEC'02 (Cat. No. 02TH8600)_, volume 1, pages 825-830. IEEE, 2002.
* [16] Kalyanmoy Deb, Ankur Sinha, and Saku Kukkonen. Multi-objective test problems, linkages, and evolutionary methodologies. In _Proceedings of the 8th annual conference on Genetic and evolutionary computation_, pages 1141-1148, 2006.
* [17] Timo M Deist, Monika Grewal, Frank JWM Dankers, Tanja Alderliesten, and Peter AN Bosman. Multi-objective learning to predict pareto fronts using hypervolume maximization. _arXiv preprint arXiv:2102.04523_, 2021.
* [18] Justin Dumouchelle, Esther Julien, Jannis Kurtz, and Elias B Khalil. Neur2bilo: Neural bilevel optimization. _arXiv preprint arXiv:2402.02552_, 2024.

* [19] Matthias Ehrgott. _Multicriteria optimization_, volume 491. Springer Science & Business Media, 2005.
* [20] Abhijith M Gopakumar, Prasanna V Balachandran, Dezhen Xue, James E Gubernatis, and Turab Lookman. Multi-objective optimization for materials discovery via adaptive design. _Scientific reports_, 8(1):3738, 2018.
* [21] Fang-Qing Gu and Hai-Lin Liu. A novel weight design in multi-objective evolutionary algorithm. In _2010 International Conference on Computational Intelligence and Security_, pages 137-141. IEEE, 2010.
* [22] Fangqing Gu and Yiu-Ming Cheung. Self-organizing map-based weight design for decomposition-based many-objective evolutionary algorithm. _IEEE Transactions on Evolutionary Computation_, 22(2):211-225, 2017.
* [23] Yu-Ran Gu, Chao Bian, Miqing Li, and Chao Qian. Subset selection for evolutionary multi-objective optimization. _IEEE Transactions on Evolutionary Computation_, 2023.
* [24] Andreia P Guerreiro, Carlos M Fonseca, and Luis Paquete. The hypervolume indicator: Problems and algorithms. _arXiv preprint arXiv:2005.00515_, 2020.
* [25] Claus Hillermeier. Generalized homotopy approach to multiobjective optimization. _Journal of Optimization Theory and Applications_, 110(3):557-583, 2001.
* [26] Hisao Ishibuchi, Hiroyuki Masuda, Yuki Tanigaki, and Yusuke Nojima. Modified distance calculation in generational distance and inverted generational distance. In _Evolutionary Multi-Criterion Optimization: 8th International Conference, EMO 2015, Guimaraes, Portugal, March 29-April 1, 2015. Proceedings, Part II 8_, pages 110-125. Springer, 2015.
* [27] Himanshu Jain and Kalyanmoy Deb. An evolutionary many-objective optimization algorithm using reference-point based nondominated sorting approach, part ii: Handling constraints and extending to an adaptive approach. _IEEE Transactions on Evolutionary Computation_, 18(4):602-622, 2014. doi: 10.1109/TEVC.2013.2281534.
* [28] Vishal Kaushal, Ganesh Ramakrishnan, and Rishabh Iyer. Submodlib: A submodular optimization library. _arXiv preprint arXiv:2202.10680_, 2022.
* [29] Naime Ranjbar Kermany. _Towards Fairness-aware Multi-Objective Recommendation Systems_. PhD thesis, Macquarie University, 2024.
* [30] Beichen Li, Bolei Deng, Wan Shou, Tae-Hyun Oh, Yuanming Hu, Yiyue Luo, Liang Shi, and Wojciech Matusik. Computational discovery of microstructured composites with optimal stiffness-toughness trade-offs, 2024.
* [31] Quzhen Lin, Xiaozhou Wang, Bishan Hu, Lijia Ma, Fei Chen, Jianqiang Li, and Carlos A Coello Coello. Multiobjective personalized recommendation algorithm using extreme point guided evolutionary computation. _Complexity_, 2018:1-18, 2018.
* [32] Xi Lin, Hui-Ling Zhen, Zhenhua Li, Qing-Fu Zhang, and Sam Kwong. Pareto multi-task learning. _Advances in neural information processing systems_, 32, 2019.
* [33] Yajing Liu, Edwin KP Chong, Ali Pezeshki, and Zhenliang Zhang. Submodular optimization problems and greedy strategies: A survey. _Discrete Event Dynamic Systems_, 30(3):381-412, 2020.
* [34] Yiping Liu, Hisao Ishibuchi, Naoki Masuyama, and Yusuke Nojima. Adapting reference vectors and scalarizing functions by growing neural gas to handle irregular pareto fronts. _IEEE Transactions on Evolutionary Computation_, 24(3):439-453, 2019.
* [35] Xiaoliang Ma, Yanan Yu, Xiaodong Li, Yutao Qi, and Zexuan Zhu. A survey of weight vector adjustment methods for decomposition-based multiobjective evolutionary algorithms. _IEEE Transactions on Evolutionary Computation_, 24(4):634-649, 2020.

* Mahapatra and Rajan [2020] Debabrata Mahapatra and Vaibhav Rajan. Multi-task learning with user preferences: Gradient descent with controlled ascent in pareto optimization. In _International Conference on Machine Learning_, pages 6597-6607. PMLR, 2020.
* Miettinen [1999] Kaisa Miettinen. _Nonlinear multiobjective optimization_, volume 12. Springer Science & Business Media, 1999.
* Pilat and Neruda [2016] Martin Pilat and Roman Neruda. General tuning of weights in moea/d. In _2016 IEEE Congress on Evolutionary Computation (CEC)_, pages 965-972. IEEE, 2016.
* Pronzato [2017] Luc Pronzato. Minimax and maximin space-filling designs: some properties and methods for construction. _Journal de la Societe Francaise de Statistique_, 158(1):7-36, 2017.
* Qi et al. [2014] Yutao Qi, Xiaoliang Ma, Fang Liu, Licheng Jiao, Jianyong Sun, and Jianshe Wu. Moea/d with adaptive weight adjustment. _Evolutionary computation_, 22(2):231-264, 2014.
* Ruchte and Grabocka [2021] Michael Ruchte and Josif Grabocka. Scalable pareto front approximation for deep multi-objective learning. In _2021 IEEE international conference on data mining (ICDM)_, pages 1306-1311. IEEE, 2021.
* Sayin [2000] Sergil Sayin. Measuring the quality of discrete representations of efficient sets in multiple objective mathematical programming. _Mathematical Programming_, 87:543-560, 2000.
* Schott [1995] Jason R Schott. Fault tolerant design using single and multicriteria genetic algorithm optimization. 1995.
* Schulz et al. [2017] Adriana Schulz, Jie Xu, Bo Zhu, Changxi Zheng, Eitan Grinspun, and Wojciech Matusik. Interactive design space exploration and optimization for cad models. _ACM Transactions on Graphics (TOG)_, 36(4):1-14, 2017.
* Shang et al. [2023] Ke Shang, Tianye Shu, Hisao Ishibuchi, Yang Nan, and Lie Meng Pang. Benchmarking large-scale subset selection in evolutionary multi-objective optimization. _Information Sciences_, 622:755-770, 2023.
* Shi et al. [2023] Bofeng Shi, Turab Lookman, and Dezhen Xue. Multi-objective optimization and its application in materials science. _Materials Genome Engineering Advances_, 1(2):e14, 2023.
* Sinha et al. [2017] Ankur Sinha, Pekka Malo, and Kalyanmoy Deb. A review on bilevel optimization: From classical to evolutionary approaches and applications. _IEEE transactions on evolutionary computation_, 22(2):276-295, 2017.
* Siwei et al. [2011] Jiang Siwei, Cai Zhihua, Zhang Jie, and Ong Yew-Soon. Multiobjective optimization by decomposition with pareto-adaptive weight vectors. In _2011 Seventh international conference on natural computation_, volume 3, pages 1260-1264. IEEE, 2011.
* Sun et al. [2018] Yanan Sun, Gary G Yen, and Zhang Yi. Igd indicator-based evolutionary algorithm for many-objective optimization problems. _IEEE Transactions on Evolutionary Computation_, 23(2):173-187, 2018.
* Tanabe and Ishibuchi [2020] Ryoji Tanabe and Hisao Ishibuchi. An easy-to-use real-world multi-objective optimization problem suite. _Applied Soft Computing_, 89:106078, 2020.
* Tian et al. [2022] Ye Tian, Langchun Si, Xingyi Zhang, Kay Chen Tan, and Yaochu Jin. Local model-based pareto front estimation for multiobjective optimization. _IEEE Transactions on Systems, Man, and Cybernetics: Systems_, 53(1):623-634, 2022.
* Wang et al. [2011] Lihui Wang, Amos HC Ng, and Kalyanmoy Deb. _Multi-objective evolutionary optimisation for product design and manufacturing_. Springer, 2011.
* Wang et al. [2022] Zihan Wang, Bochao Mao, Hao Hao, Wenjing Hong, Chunyun Xiao, and Aimin Zhou. Enhancing diversity by local subset selection in evolutionary multiobjective optimization. _IEEE Transactions on Evolutionary Computation_, 2022.
* Wu [2016] Jeff Wu. Space-filling designs, 2016. URL https://www2.isye.gatech.edu/~jeffwu/isye8813/spacefilling_designs.pdf.

* [55] Mengyuan Wu, Sam Kwong, Yuheng Jia, Ke Li, and Qingfu Zhang. Adaptive weights generation for decomposition-based multi-objective optimization using gaussian process regression. In _Proceedings of the Genetic and Evolutionary Computation Conference_, pages 641-648, 2017.
* [56] Jie Xu, Yunsheng Tian, Pingchuan Ma, Daniela Rus, Shinjiro Sueda, and Wojciech Matusik. Prediction-guided multi-objective reinforcement learning for continuous robot control. In _International conference on machine learning_, pages 10607-10616. PMLR, 2020.
* [57] Jie Xu, Andrew Spielberg, Allan Zhao, Daniela Rus, and Wojciech Matusik. Multi-objective graph heuristic search for terrestrial robot design. In _2021 IEEE international conference on robotics and automation (ICRA)_, pages 9863-9869. IEEE, 2021.
* [58] Qingfu Zhang and Hui Li. Moea/d: A multiobjective evolutionary algorithm based on decomposition. _IEEE Transactions on evolutionary computation_, 11(6):712-731, 2007.
* [59] Xiaoyuan Zhang, Xi Lin, and Qingfu Zhang. Pmgda: A preference-based multiple gradient descent algorithm. _IEEE Transactions on Emerging Topics in Computational Intelligence_, 2024.
* [60] Yihua Zhang, Prashant Khanduri, Ioannis Tsaknakis, Yuguang Yao, Mingyi Hong, and Sijia Liu. An introduction to bi-level optimization: Foundations and applications in signal processing and machine learning. _arXiv preprint arXiv:2308.00788_, 2023.
* [61] Yong Zheng and David Xuejun Wang. A survey of recommender systems with multi-objective optimization. _Neurocomputing_, 474:141-153, 2022.

## Supplementary Material

### Table of Contents

* A Complete proofs of theoretical results
* A.1 Upper and lower bounds for space filling design
* A.2 Configuration of \(d^{\text{Pack}}\) for bi-objective problems
* A.3 Theoretical results for optimization bounds
* A.4 Proof of the "equivalent conversion" argument
* B Experiment details
* B.1 Metrics
* B.2 Full name of multiobjective methods
* B.3 Detailed hyperparameters and licences
* B.4 Visualization for four objective problems
* B.5 Full numerical results
* B.6 Results on DTLZ5 and DTLZ6
* C Method details
* C.1 Practical algorithms
* C.2 Problem formulations
* C.3 Conversion between a preference and a preference angle
* C.4 Baseline methods used in fairness classification problem
* C.5 Duplicated solutions issues caused by the mTche aggregation function
* D Miscellaneous
* D.1 Broader impacts
* D.2 Limitations

The appendix comprises four sections:

1. Appendix A: Detailed proofs for the main paper's conclusions.

2. Appendix B: Additional experimental details.

3. Appendix C: Method details omitted from the main paper.

4. Appendix D: Discussion on the broader impact of our method.

Complete proofs of theoretical results

This section provides complete proofs for the theoretical results. We first provide the properties for max-packing and space-filling designs in Appendices A.1 and A.2. Lastly, in Appendix A.3, we prove for the bi-level optimization bound by using neural network as an approximation for the inner loop optimization problem.

### Upper and lower bounds for space filling design

In the following content, we proves for Theorem 3 in the main paper, i.e.,

\[\frac{1}{4}d^{\mathrm{Pack}}\leq d^{\mathrm{FD}}\leq\mathrm{FD}(\mathbb{Y}^{ \mathrm{Pack}})\leq d^{\mathrm{Pack}},\]

Proof.: Following the derivation to attain Equation (3) in Pronzato [39], we can prove \(d^{\mathrm{FD}}\leq d^{\mathrm{Pack}}\) as well as the claim that the fill distance between \(\mathcal{T}\) and the optimal design \(\mathbb{Y}^{\mathrm{Pack}}\) induced by \(d^{\mathrm{Pack}}\) is upper bounded by \(d^{\mathrm{Pack}}\).

Next, we prove \(d^{\mathrm{FD}}\geq\frac{1}{4}d^{\mathrm{Pack}}\) by contradiction. Consider \(\mathbb{Y}^{\mathrm{FD}}\) is the design that induces \(d^{\mathrm{FD}}\), we have that each point in \(\mathbb{Y}^{\mathrm{Pack}}\) must be within a \(d^{\mathrm{FD}}\)-ball centered at a point in \(\mathbb{Y}^{\mathrm{FD}}\), and the condition \(d^{\mathrm{FD}}<\frac{1}{4}d^{\mathrm{Pack}}\) requires that a specific ball will only contain a single \(\bm{y}^{(k)}\in\mathbb{Y}^{\mathrm{Pack}}\) otherwise \(\mathbb{Y}^{\mathrm{Pack}}\) will not be a \(d^{\mathrm{Pack}}\)-packing.

Since \(d^{\mathrm{FD}}<\frac{1}{4}d^{\mathrm{Pack}}\), for all \(k\in[K]\) the corresponding \(d^{\mathrm{FD}}\)-ball is completely contained in the larger \((d^{\mathrm{Pack}}/2)\)-ball centered at \(\bm{y}^{(k)}\). However, we note \(\mathcal{T}\) is connected, and thus there exists a certain \(y\in\mathcal{T}\) outside all the \(K\)\((d^{\mathrm{Pack}}/2)\)-balls; this certain point will not be covered by all the \(d^{\mathrm{FD}}\)-ball centered at points in \(\mathbb{Y}^{\mathrm{FD}}\) as well. Finally, the existence of the certain point contradicts the claim that \(\mathbb{Y}^{\mathrm{FD}}\) is a \(d^{\mathrm{FD}}\)-covering. 

Lastly, we prove for Theorem 4 in the main paper by a contradiction.

Proof.: Since \(d^{\mathrm{Pack}}_{K+1}>d^{\mathrm{Pack}}_{K}\), \(K\) is the maximal packing number under distance \(d^{\mathrm{Pack}}_{K}\).

Assume \(\mathbb{Y}^{\mathrm{Pack}}_{K}\) is not a \(d^{\mathrm{Pack}}_{K}\)-covering. Then there exists \(\bm{y}^{(K+1)}\) such that \(\rho(\bm{y}^{(K+1)},\bm{y}^{(i)})<d^{\mathrm{Pack}}_{K}\) for all \(i\in[K]\). This contradicts the assumption, as \(\mathbb{Y}^{\mathrm{Pack}}_{K}\cup\{\bm{y}^{(K+1)}\}\) forms a \(d^{\mathrm{Pack}}_{K}\)-covering, implying a packing number of \(K+1\) when \(K\) was maximal. Thus, \(\mathbb{Y}^{\mathrm{Pack}}_{K}\) is a \(d^{\mathrm{Pack}}_{K}\)-covering. 

### Configuration of \(d^{\mathrm{Pack}}\) for bi-objective problems

In the following, we prove Theorem 5 in the main paper. Before that, we prove for Lemma 8 to describe a property of \(\rho(\bm{y}^{(1)},\bm{y}^{(2)})\), the distance between \(\bm{y}^{(1)}\) and \(\bm{y}^{(2)}\) when \(\bm{y}^{(1)},\bm{y}^{(2)}\in\mathcal{T}\).

**Lemma 8**.: _For biobjective problem function \(g\) is strictly decreasing with respect to the first element (\(y^{(1)}_{1}\)) of \(\bm{y}^{(1)}\) and strictly increasing with the first element (\(y^{(2)}_{1}\)) of \(\bm{y}^{(2)}\)._

Proof.: We consider a new vector \(\tilde{\bm{y}}^{(1)}\in\mathcal{T}\) such that \(\tilde{y}^{(1)}_{1}<y^{(1)}_{1}\). Since \(\tilde{\bm{y}}^{(1)}\in\mathcal{T}\), \(\bm{y}^{(1)}\) and \(\tilde{\bm{y}}^{(1)}\) cannot dominate each other, implying \(\tilde{y}^{(1)}_{2}>y^{(1)}_{2}\). The distance between this new solution \(\tilde{\bm{y}}^{(1)}\) and \(\bm{y}^{(2)}\) is:\[\rho(\tilde{\bm{y}}^{(1)},\bm{y}^{(2)}) =\sqrt{(\tilde{y}_{1}^{(1)}-y_{1}^{(2)})^{2}+(\tilde{y}_{2}^{(1)}-y_ {2}^{(2)})^{2}}\] \[=\sqrt{(y_{1}^{(1)}-\delta_{1}-y_{1}^{(2)})^{2}+(y_{2}^{(1)}+\delta _{2}-y_{2}^{(2)})^{2}}\qquad\qquad(\delta_{1},\delta_{2}>0)\] \[=\sqrt{(y_{1}^{(1)}-y_{1}^{(2)})^{2}+\delta_{1}^{2}-2\delta_{1}(y _{1}^{(1)}-y_{1}^{(2)})+(y_{2}^{(1)}-y_{2}^{(2)})^{2}+\delta_{2}^{2}+2\delta_{ 2}(y_{2}^{(1)}-y_{2}^{(2)})}\] \[\geq\sqrt{(y_{1}^{(1)}-y_{1}^{(2)})^{2}+(y_{2}^{(1)}-y_{2}^{(2)})^ {2}+C}\qquad\qquad(C>0)\] \[>\rho(\bm{y}^{(1)},\bm{y}^{(2)}).\] (11)

The previous equations show that \(\rho(\bm{y}^{(1)},\bm{y}^{(2)})\) is strictly decreasing with respect to the first element of \(\bm{y}^{(1)}\). Similarly, considering a new vector \(\tilde{\bm{y}}^{(2)}\in\mathcal{T}\), \(\tilde{y}_{1}^{(2)}>y_{1}^{(2)}(\tilde{y}_{2}^{(2)}<y_{2}^{(2)})\), using the same calculation method used in Equation (11), it is proved that \(\rho(\bm{y}^{(1)},\tilde{\bm{y}}^{(2)})>\rho(\bm{y}^{(1)},\bm{y}^{(2)})\). This indicates that \(\rho(\bm{y}^{(1)},\bm{y}^{(2)})\) is strictly increasing with respect to the first element of \(\bm{y}^{(2)}\). 

With this established Lemma, we are now geared up for the complete proof.

Proof.: The proof consists of two parts.

**Part 1** proves that the neighboring distances \(\rho(\bm{y}^{(i)},\bm{y}^{(i+1)})\) are equal for all \(i\in[K-1]\).

**Part 2** proves that \(\bm{y}^{(1)}=\bm{p}^{(1)}\) and \(\bm{y}^{(K)}=\bm{p}^{(2)}\). \(\bm{p}^{(1)}\) and \(\bm{p}^{(2)}\) are the two endpoints of a PF.

Part 1.We prove \(\rho(\bm{y}^{(1)},\bm{y}^{(2)})=\ldots=\rho(\bm{y}^{(K-1)},\bm{y}^{(K)})\) by contradiction. We denote \(d^{(i)}\) the distance between \(\bm{y}^{(i)}\) and \(\bm{y}^{(i+1)}\) and \(i^{\prime}\) and \(j^{\prime}\) are two indices such that

\[\begin{cases}d^{(i^{\prime})}>d^{(i^{\prime}+1)},\ldots,d^{(j^{\prime})},\\ d^{(i^{\prime}+1)},\ldots,d^{(j^{\prime}-1)}>d^{(j^{\prime})}.\end{cases}\] (12)

Without loss of generality, assume \(i^{\prime}<j^{\prime}\). We now aim to derive a contradiction under the condition given by Equation (12). The approach is to iteratively decrease the first element of \(\bm{y}^{(i^{\prime}+1)}\) by a small margin \(\varepsilon>0\), yielding \(\tilde{\bm{y}}^{(i^{\prime}+1)}\). By Lemma 8, this adjustment ensures that \(\rho(\bm{y}^{(i^{\prime})},\tilde{\bm{y}}^{(i^{\prime}+1)})<\rho(\bm{y}^{(i^{ \prime})},\bm{y}^{(i^{\prime}+1)})\) while \(\rho(\tilde{\bm{y}}^{(i+1)},\bm{y}^{(i+2)})>\rho(\bm{y}^{(i+1)},\bm{y}^{(i+2)})\). Specifically, for each \(k\) such that \(i^{\prime}+1\leq k\leq j^{\prime}-2\), \(\bm{y}^{(k)}\) is updated to \(\tilde{\bm{y}}^{(k)}\) according to the following rules:

\[\begin{cases}\rho(\bm{y}^{(i^{\prime})},\bm{y}^{(i^{\prime}+1)})-\varepsilon= \rho(\tilde{\bm{y}}^{(i^{\prime})},\tilde{\bm{y}}^{(i^{\prime}+1)}),\\ \rho(\bm{y}^{(k)},\bm{y}^{(k+1)})=\rho(\tilde{\bm{y}}^{(k)},\tilde{\bm{y}}^{(k +1)}),\\ \rho(\bm{y}^{(j^{\prime}-1)},\bm{y}^{(j^{\prime})})+\epsilon=\rho(\tilde{\bm{y} }^{(j^{\prime}-1)},\tilde{\bm{y}}^{(j^{\prime})}).\end{cases}\] (13)

When \(\varepsilon\) is sufficiently small, \(\tilde{j}^{\prime}=\arg\min\{\rho(\tilde{\bm{y}}^{(i^{\prime})},\tilde{\bm{y} }^{(i^{\prime}+1)}),\ldots,\rho(\tilde{\bm{y}}^{(j^{\prime}-1)},\tilde{\bm{y} }^{(j^{\prime})})\}=j^{\prime}\), meaning the minimal index before and after adjustment remains unchanged. However, the value of the adjusted distance \(\rho(\tilde{\bm{y}}^{(j^{\prime})},\tilde{\bm{y}}^{(j^{\prime}+1)})\) is increased from \(\rho(\bm{y}^{(j^{\prime})},\bm{y}^{(j^{\prime}+1)})\) by \(\varepsilon\), showing the original design is not a max-packing design, leading to a contradiction. If conditions

\[\begin{cases}d^{(i^{\prime})}<d^{(i^{\prime}+1)},\ldots,d^{(j^{\prime})},\\ d^{(i^{\prime}+1)},\ldots,d^{(j^{\prime}-1)}<d^{(j^{\prime})},\end{cases}\] (14)

hold, a similar argument as above can be used to derive a contradiction. Since the selection of \(i^{\prime}\) and \(j^{\prime}\) is arbitrary, this implies that for any interval between \(i^{\prime}\) and \(j^{\prime}\), both Equation (12) and Equation (14) cannot hold simultaneously. This leads

**Part 2.** We prove \(\bm{y}^{(1)}=\bm{p}^{(1)}\) by contradiction. The proof for \(\bm{y}^{(K)}=\bm{p}^{(2)}\) follows similarly. Assuming \(\bm{y}^{(1)}\neq\bm{p}^{(1)}\), we replace \(\bm{y}^{(1)}\) with \(\bm{p}^{(1)}\), forming a new configuration \([\tilde{\bm{y}}^{(1)}(\bm{p}^{(1)}),\bm{y}^{(2)},\ldots,\bm{y}^{(K)}]\). Based on Part 1, where we showed equal neighboring distances between vectors, the condition

\[\rho(\tilde{\bm{y}}^{(1)},\bm{y}^{(2)})>\rho(\bm{y}^{(2)},\bm{y}^{(3)})=\ldots= \rho(\bm{y}^{(K-1)},\bm{y}^{(K)})\]

holds.

Next, we replace \(\bm{y}^{(2)},\ldots,\bm{y}^{(K-1)}\) with \(\tilde{\bm{y}}^{(2)},\ldots,\tilde{\bm{y}}^{(K-1)}\) on the PF, such that \(\tilde{y}^{(i)}_{1}=y^{(i)}_{1}-\epsilon^{(i)}\), for \(2\leq i\leq K-1\), ensuring

\[\rho(\tilde{\bm{y}}^{(i)},\tilde{\bm{y}}^{(i+1)})>\rho(\bm{y}^{(i)},\bm{y}^{ (i+1)}),\quad i\in[K-1].\]

By Lemma 8, moving \(\bm{y}^{(1)}\) to \(\tilde{\bm{y}}^{(1)}\) results in \(\rho(\tilde{\bm{y}}^{(1)},\bm{y}^{(2)})>\rho(\bm{y}^{(1)},\bm{y}^{(2)})\). Iteratively shifting \(\bm{y}^{(2)},\ldots,\bm{y}^{(K-1)}\) ensures \(\tilde{y}^{(2)}_{1}<y^{(2)}_{1}\) and so on, until \(\tilde{y}^{(K-1)}_{1}<y^{(K-1)}_{1}\), completing the process.

This leads to a contradiction, proving that \(\bm{y}^{(1)}=\bm{p}^{(1)}\) and \(\bm{y}^{(K)}=\bm{p}^{(2)}\).

### Theoretical results for optimization bounds

In this part, we prove for Theorem 7, which bounds the optimization error caused by neural network in the bi-level optimization problem (Equation (10)).

Proof.: Consider the function \(\rho(\cdot,\cdot)\), which measures the distance between two vectors. Given our assumption, we derive the error between distances computed under \(\bm{h}\) and \(\bm{h}_{\phi}\). For any two points \(\bm{y}^{(i)}\), \(\bm{y}^{(j)}\) in the image of \(\bm{h}\), the error in their distances compared to \(\bm{h}_{\phi}\) can be bounded as follows:

\[\begin{split}|\rho(\bm{y}^{(i)},\bm{y}^{(j)})-\rho(\bm{h}_{\phi} (\bm{\vartheta}^{(i)}),\bm{h}_{\phi}(\bm{\vartheta}^{(j)}))|&=| \|\bm{y}^{(i)}-\bm{y}^{(j)}\|-\|\bm{h}_{\phi}(\bm{\vartheta}^{(i)})-\bm{h}_{ \phi}(\bm{\vartheta}^{(j)})\|\|\\ &\leq\|\bm{y}^{(i)}-\bm{h}_{\phi}(\bm{\vartheta}^{(i)})+\bm{h}_{ \phi}(\bm{\vartheta}^{(j)})-\bm{y}^{(j)}\|\\ &\leq\|\bm{y}^{(i)}-\bm{h}_{\phi}(\bm{\vartheta}^{(i)})\|+\|\bm{ h}_{\phi}(\bm{\vartheta}^{(j)})-\bm{y}^{(j)}\|\\ &\leq\epsilon+\epsilon=2\epsilon.\end{split}\] (16)

This follows from the triangle inequality and the assumption \(|\bm{h}_{\phi}(\bm{\vartheta})-h(\bm{\vartheta})|\leq\epsilon\).

Given this pairwise bound, the overall configuration of points is such that the minimization of distances among points under \(\bm{h}_{\phi}\) will either match or exceed the minimization under \(\bm{h}\) within the bounds of \(2\epsilon\):

\[\min_{1\leq i<j\leq K}\rho(\bm{h}_{\phi}(\bm{\vartheta}^{(i)}),\bm{h}_{\phi}( \bm{\vartheta}^{(j)}))\leq\min_{1\leq i<j\leq K}\rho(\bm{y}^{(i)},\bm{y}^{(j )})+2\epsilon.\] (17)

Considering the maximization of these minimum distances across all configurations \(\bm{\vartheta}^{(1)},\ldots,\bm{\vartheta}^{(K)}\), we have:

\[\begin{split}\left|\max_{\bm{\vartheta}^{(1)},\ldots,\bm{ \vartheta}^{(K)}}\min_{1\leq i<j\leq K}\rho(\bm{h}_{\phi}(\bm{\vartheta}^{(i) }),\bm{h}_{\phi}(\bm{\vartheta}^{(j)}))-\max_{\bm{\vartheta}^{(1)},\ldots,\bm{ \vartheta}^{(K)}}\min_{1\leq i\leq j\leq K}\rho(\bm{y}^{(i)},\bm{y}^{(j)}) \right|\\ \leq\max_{\bm{\vartheta}^{(1)},\ldots,\bm{\vartheta}^{(K)}}2 \epsilon=2\epsilon.\end{split}\] (18)

Thus, the error in the optimal maximal minimal distance under the model transformation can be bounded by \(2\epsilon\), completing the proof. 

### Proof of the "equivalent conversion" argument

This argument is actually a direct corollary the following two lemmas.

**Lemma 9** (Adapted from [10], Theorem 3.1).: _A solution \(\bm{x}\) is weakly Pareto optimal iff there exists a weight vector \(\bm{\lambda}\) such that \(\bm{x}\) is (one of) an optimal solution of the modified Tchebycheff function._

**Lemma 10** (Modified from [37], Theorem 2.6.2).: _If an aggregation function is decreasing w.r.t. vector \(\bm{f}(\bm{x})\) (i.e., \(g_{\bm{\lambda}}(\bm{f}(\bm{x}))\leq g_{\bm{\lambda}}(\bm{f}(\bm{x}^{\prime}))\) when \(f_{i}(\bm{x})\leq f_{i}(\bm{x}^{\prime}),\forall i\in[m]\) and at least one index \(j\)\(f_{j}(\bm{x})<f_{j}(\bm{x}^{\prime})\), then one of the optimal solution \(\bm{x}^{*}\) of \(g_{\bm{\lambda}}(\bm{f}(\bm{x}))\) is a weakly Pareto optimal solution for the original MOP. In addition, if the optimality is unique, \(\bm{x}^{*}\) is Pareto optimal._

Based on the first Lemma, we know that for any weakly Pareto objective, there is a corresponding preference vector that solving the modified Tchebycheff function can recover this vector. Furthermore, since we assume the uniqueness of the optimality of the modified Tchebycheff function, thus according to the second lemma, solving the modified Tchebycheff function only yields Pareto optimal solutions. Combining these two arguments, we achieve that for any Pareto optimal objective, there exists a preference vector such that solving the corresponding modified Tchebycheff function yield this Pareto optimal vector.

## Appendix B Experiment details

This section has four parts. In Appendix B.1, we explain the metrics used in the experiments in details. In Appendix B.3, we list the necessary hyperparameters and license. In Appendix B.4, we visualize the results on four-objective problems by projection. Lastly, Appendix B.5 list for all numerical results for all experiments.

### Metrics

To evaluate the uniformity and quality of these solutions, we use various performance indicators, detailed and mathematically expressed below.

**1. Hypervolume (HV)** (\(\uparrow\)) [24] both assesses convergence to a PF and solution diversity. Low HV values suggest poor convergence to the PF, while comparisons are significant when HVs are substantially high. The hypervolume indicator measures the dominated volume by at least one

Figure 8: Results on RE41.

objective belongs to the set \(\mathbb{Y}\) with a reference point \(\bm{r}\).

\[\mathrm{HV}_{\bm{r}}=\mathrm{Vol}(\{\bm{y}|\exists\bm{y}^{\prime}\in\mathbb{Y}, \bm{y}^{\prime}\preceq\bm{y}\preceq\bm{r}\}).\]

**2. IGD**[26] indicator of a set \(\mathbb{A}\) with a reference set \(\mathbb{Z}\) is defined as:

\[\mathrm{IGD}(\mathbb{A})=\frac{1}{|\mathbb{Z}|}\sum_{i=1}^{|\mathbb{Z}|}d_{i},\]

where \(d_{i}\) represents the Euclidean distance from \(z_{i}\) to the nearest distance in the set of \(\mathbb{A}\).

**3. Sparsity** (\(\downarrow\)) [56] is a measure calculated from the squared distances among solution vectors that are sorted according to their non-dominance levels [14]. The mathematical definition is given by:

\[\text{Sparsity}=\frac{1}{N-1}\sum_{j=1}^{m}\sum_{i=1}^{N-1}\left(\tilde{y}_{j}^ {(i)}-\tilde{y}_{j}^{(i+1)}\right)^{2},\]

where \(\tilde{\bm{y}}^{(i)}\) are the objective vectors arranged in a non-dominated sorting order from the set \(\{\bm{y}^{(1)},\ldots,\bm{y}^{(N)}\}\). Here, \(m\) represents the number of objectives, and \(N\) is the number of solutions. A lower Sparsity value indicates a more uniformly distributed set of solutions along the Pareto front. Specifically, for a Pareto front with a two-dimensional linear shape, the sparsity indicator reaches its minimum when the objectives are spaced equidistantly.

**4. Spacing** (\(\downarrow\)) [43]: This metric assesses solution distribution uniformity by calculating the standard deviation of \(\tilde{d}^{(i)}\), the minimal distance between a solution \(\bm{y}^{(i)}\) and its nearest neighbor, where \(d^{(i)}=\min_{j\in[m],j\neq i}\rho(\bm{y}^{(i)},\bm{y}^{(j)})\). A lower spacing indicator implies evenly spaced solutions, reflecting uniform distribution. A spacing indicator of zero indicates that all Pareto objectives have equally minimal neighborhood distances.

Figure 9: Results on RE42.

Uniformity (\(\uparrow\)) and **Smooth Uniformity** (\(\uparrow\)) indicators, as introduced by [42], evaluate the distribution of solutions. The Uniformity indicator, \(\delta_{\mathrm{Unif}}\), is defined as the minimum distance between any two solutions:

\[\delta_{\mathrm{Unif}}=\min_{1\leq i<j\leq K}\rho(\bm{y}^{(i)},\bm{y}^{(j)}).\]

On the other hand, the Smooth Uniformity indicator, \(\tilde{\delta}_{\mathrm{Unif}}\), incorporates a logarithmic sum exponential function to average distances among solutions. It introduces a sensitivity parameter \(\eta\) (set to 20 in this study) to highlight the overall distribution of distances:

\[\tilde{\delta}_{\mathrm{Unif}}=-\frac{2}{\eta K(K-1)}\log\sum_{1\leq i<j\leq K }\exp(\eta\cdot\rho(\bm{y}^{(i)},\bm{y}^{(j)})).\]

### Full name of multiobjective methods

To avoid confusion, we provide the full names of the baseline MOO methods in Table 4. For SMS-MOEA (MOEA using S-Metric Selection), the term "S-metric" refers to the "hypervolume" metric.

### Detailed hyperparameters and licences

Table 5 lists the hyperparameters for implementing MOPs solved by evolutionary algorithms. The system used features an Intel Core i7-10700 CPU and a NVIDIA RTX 3080 GPU.

Our method is implemented in the MOEA/D framework using Pymoo [7], without modifying the MOEA/D hyperparameters. The main difference is the use of a PF model (a fully-connected neural network) to map preference angles to Pareto objectives and update preference vectors. The hyperparameters for the PF model are listed in Table 5.

For fairness classification problems, we use an additional fully connected network to classify input features into corresponding classes. The parameters of this network serve as the decision variables (\(x\)) for a multiobjective problem. Details of the fairness classification problems are shown in Table 6.

\begin{table}
\begin{tabular}{l|l} \hline \hline Short Name & Full name \\ \hline DEA-GNG & **D**ecomposition based **E**volutionary **A**lgorithm guided by **G**rowing **N**eural **G**as \\ LMPFE & Evolutionary algorithm with **L**ocal **M**odel based **P**areto **F**ront **E**stimation \\ NSGA3 & **N**ondominated **S**orting **G**e**etic **A**lgorithm 3 \\ SMS-EMOA & **S** **M**etric **S**election based **E**volutionary **M**ultiobjective **O**ptimization **A**lgorithm \\ MOEA/D & **M**ulti**Objective **E**volutionary **A**lgorithm based on **D**ecomposition \\ MOEA/D-AWA & **MOEA/D** with **A**daptive **W**eight **A**djustment \\ UMOD & **Uniform **M**ultiobjective **O**ptimization based on **D**ecomposition \\ \hline MOO-SVGD & **M**ulti**Objective **O**ptimization **S**tein **V**ariational **G**radient **D**escent \\ EPO & **Exact **P**areto **O**ptimization \\ PMGDA & **P**reference based **M**ultiple **G**radient **D**escent **A**lgorithm \\ Agg-LS & **Aggregation function based on **L**inear **S**calarization \\ Agg-PBI & **Aggregation function based on **P**enalty **B**ased **I**ntersection \\ Agg-Tche & **Aggregation function based **T**chebycheff Scalarization \\ \hline IGD & **Invetted **G**eneral **D**istance \\ HV & **Hyper**Volume** \\ \hline MOO & **M**ulti**Objective **O**ptimization \\ MOP & **M**ultiobjective **O**ptimization **P**roblem \\ \hline \hline \end{tabular}
\end{table}
Table 4: Full name table, which has three parts. The first part is related with evolutionary algorithms, the second part is related with gradient-based methods, the third part is related to indicators, while the last part is related to multiobjective optimization concepts.

[MISSING_PAGE_FAIL:22]

[MISSING_PAGE_EMPTY:23]

[MISSING_PAGE_EMPTY:24]

### Results on DTLZ5 and DTLZ6

The PFs of DTLZ5 and DTLZ6 are identical, which are a degenerate 1-dimensional hyper-curve within the three-objective space. The visualization results are shown in Figures 10 and 11 and numerical results are shown in Table 10.

Table 10 highlights that UMOD significantly outperforms other methods in ensuring evenly distributed solutions. In the decomposition-based framework, for such degenerated problems, different preferences may correspond to the same Pareto objective. The reason behind generating duplicate solutions is explained in Appendix C.5. And therefore, MOEA/D and MOEA/D-AWA tend to produce duplicate solutions. NSGA3 is also found to produce duplicate solutions easily. SMS-MOEA avoids duplicate solutions by maximizing the hypervolume. SMS-MOEA surpasses UMOD in hypervolume, but UMOD considerably outperforms SMS-MOEA in IGD and FD, which are of interests in this paper.

\begin{table}
\begin{tabular}{l c c c c c c c} \hline \hline  & Spacing & Sparsity & HV & Uniform & Smooth Uniform & IGD & FD \\ \hline UMOD & **0.0073** & **0.0131** & 0.6995 & **0.0867** & **-0.0634** & **0.0294** & **0.085** \\ MOEAD & 0.0871 & 0.0645 & 0.6352 & 0 & -0.1978 & 0.143 & 0.3002 \\ AWA & 0.0909 & 0.0312 & 0.6697 & 0 & -0.1802 & 0.0712 & 0.1697 \\ SMS-MOEA & 0.0454 & 0.0147 & **0.7035** & 0.0783 & -0.0753 & 0.0307 & 0.1099 \\ NSGA3 & 0.0599 & 0.0289 & 0.6623 & 0.0005 & -0.1417 & 0.0683 & 0.1802 \\ \hline UMOD & **0.0125** & **0.0128** & 0.7011 & **0.0738** & **-0.0618** & **0.0285** & **0.0731** \\ MOEAD & 0.0843 & 0.0599 & 0.6352 & 0 & -0.2032 & 0.143 & 0.3002 \\ AWA & 0.0908 & 0.0312 & 0.6697 & 0 & -0.1694 & 0.0712 & 0.1697 \\ SMS-MOEA & 0.0426 & 0.0143 & **0.7036** & 0.072 & -0.0752 & 0.0305 & 0.1099 \\ NSGA3 & 0.0524 & 0.0415 & 0.6623 & 0 & -0.1357 & 0.0931 & 0.2972 \\ \hline \hline \end{tabular}
\end{table}
Table 10: Numerical results on DTLZ5 and DTLZ6 problems.

Figure 11: Comparison of using different methods on DTLZ6.

Figure 10: Comparison of using different methods on DTLZ5.

Method details

### Practical algorithms

In this section, we present practical algorithms to solve the maximal packing problem in the Pareto front (Equation (10)). We start by generating an initial uniform distribution of preference vectors. Then, we use either multiobjective evolutionary algorithms (MOEAs) or gradient-based MOO to solve for the preference angle and Pareto objective pairs. MOEAs are suitable for problems with local optimas, while gradient-based MOO is efficient for neural network problems with millions of decision variables. Next, we fit a Pareto front model to learn the expression of \(\bm{h}_{\phi}\) and re-determine the preference angles by maximizing the pairwise distances. These two steps are repeated alternately.

```
1:Input: Initial \(K\) uniform preferences \(\{\bm{\lambda}^{(1)},\ldots,\bm{\lambda}^{(K)}\}\) by Das-Dennis method [12]. Initial solutions \(\{\bm{x}^{(1)},\ldots,\bm{x}^{(K)}\}\).
2:for\(n=1\)to\(N\)do
3: Run MOEA/D with mTche aggregation function or gradient-based MOO using \(\{\bm{x}^{(1)},\ldots,\bm{x}^{(K)}\}\) as initial solutions under preferences \(\{\bm{\lambda}^{(1)},\ldots,\bm{\lambda}^{(K)}\}\).
4: Train a model \(\bm{h}_{\phi}\) to predict Pareto objectives by the preference angles using mean square estimation with angle-objective pairs \((\bm{\vartheta}^{(i)},\bm{y}^{(i)})\).
5: Update \((\bm{\vartheta}^{(1)},\ldots,\bm{\vartheta}^{(K)})\) by Algorithm 2.
6: Recalculate preference vectors, \(\bm{\lambda}^{(1)},\ldots,\bm{\lambda}^{(K)}\).
7: Update the initial solutions \(\{\bm{x}^{(1)},\ldots,\bm{x}^{(K)}\}\) by MOEA/D or gradient-based mTche using the last generation of solutions as a warm start.
8:endfor ```

**Algorithm 1****Uniform Multiobjective Optimization** (UMOD)

```
1:Input: The initial configuration \(\{\bm{\vartheta}^{(1)},\ldots,\bm{\vartheta}^{(K)}\}\) and \(\bm{h}_{\phi}\).
2:for\(i=1\)to\(N_{\text{opt}}\)do
3: Calculate the indexes for the minimal pairwise objectives: \[(i^{*},j^{*})=\arg\min_{1\leq i<j\leq K}\bm{h}_{\phi}(\bm{\vartheta}^{(i)}, \bm{\vartheta}^{(j)}).\]
4: Update the positions of \((\bm{\vartheta}^{(i^{*})},\bm{\vartheta}^{(j^{*})})\): \[\begin{cases}\bm{\vartheta}^{(i^{*})}\leftarrow\text{clip}\left(\bm{\vartheta} ^{(i^{*})}+\eta\frac{\partial\bm{h}_{\phi}(\bm{\vartheta}^{(i^{*})})}{ \partial\bm{\vartheta}^{(i^{*})}})A_{\phi},0,\frac{\pi}{2}\right)\\ \bm{\vartheta}^{(j^{*})}\leftarrow\text{clip}\left(\bm{\vartheta}^{(j^{*})}- \eta\frac{\partial\bm{h}_{\phi}(\bm{\vartheta}^{(j^{*})})}{\partial\bm{ \vartheta}^{(j^{*})}}A_{\phi},0,\frac{\pi}{2}\right).\end{cases}\]

 where \(A_{\phi}=\frac{\bm{h}_{\phi}(\bm{\vartheta}^{(i^{*})})-\bm{h}_{\phi}(\bm{ \vartheta}^{(j^{*})})}{\rho(\bm{h}_{\phi}(\bm{\vartheta}^{(i^{*})}),\bm{h}_{ \phi}(\bm{\vartheta}^{(j^{*})}))}\top\).
5:endfor
6:Output: The updated preference angles \(\{\bm{\vartheta}^{(1)},\ldots,\bm{\vartheta}^{(K)}\}\). ```

**Algorithm 2****Recalculate Preference Angles** (ALG_Update)

### Problem formulations

For completeness, ZDT1, ZDT2, and DTLZ1 problems are described as follows.

Zdt1.**

\[\begin{cases}f_{1}(\bm{x})=x_{1},\\ f_{2}(\bm{x})=g(\bm{x})\cdot h(f_{1}(\bm{x}),g(\bm{x})),\\ g(\bm{x})=1+\frac{9}{n-1}\sum_{i=2}^{n}x_{i},\\ h(f_{1}(\bm{x}),g(\bm{x}))=1-\sqrt{f_{1}(\bm{x})/g(\bm{x})},\\ 0\leq x_{i}\leq 1,\qquad i\in[n].\end{cases}\] (19)

The PF of ZDT1 is \(f_{2}=1-\sqrt{f_{1}},0\leq f_{1}\leq 1\).

Zdt2.**

\[\begin{cases}f_{1}(\bm{x})=x_{1},\\ f_{2}(\bm{x})=g(\bm{x})\cdot h(f_{1}(\bm{x}),g(\bm{x})),\\ g(\bm{x})=1+\frac{9}{n-1}\sum_{i=2}^{n}x_{i},\\ h(f_{1}(\bm{x}),g(\bm{x}))=1-f_{1}(\bm{x})/g(\bm{x})^{2},\\ 0\leq x_{i}\leq 1,\qquad i\in[n].\end{cases}\] (20)

The PF of ZDT2 is \(f_{2}=1-f_{1}^{2},0\leq f_{1}\leq 1\).

Dtlz1.**

\[\begin{cases}f_{1}(\bm{x})=\frac{1}{2}x_{1}x_{2}(1+g(\bm{x})),\\ f_{2}(\bm{x})=\frac{1}{2}x_{1}(1-x_{2})(1+g(\bm{x})),\\ f_{3}(\bm{x})=\frac{1}{2}(1-x_{1})(1+g(\bm{x})),\\ g(\bm{x})=100((n-2)+\sum_{i=3}^{n}(x_{i}-0.5)^{2}+\sum_{i=3}^{n}\cos(20\pi(x_{i} -0.5))),\\ 0\leq x_{i}\leq 1,\qquad i\in[n].\end{cases}\] (21)

The PF of DTLZ1 is \(0.5\Delta_{3}\) (3-dim simplex).

### Conversion between a preference and a preference angle

The preference vector \(\bm{\lambda}\) and preference angles \(\bm{\vartheta}\) are easily inter-convertible via the following equations. This one-to-one, differentiable mapping allows conversion between \(\bm{\vartheta}\) and \(\bm{\lambda}\). While \(\bm{\lambda}\) belongs to the \(m\)-D simplex, \(\bm{\vartheta}\) lies within the box constraint \([0,\frac{\pi}{2}]^{m-1}\). For optimization purposes, \(\bm{\vartheta}\) is more manageable because it can be easily projected onto \([0,\frac{\pi}{2}]^{m-1}\), whereas projecting \(\bm{\lambda}\) onto the \(m\)-D simplex is more complex.

\[\begin{cases}&\vartheta_{1}=\arg\cos(\sqrt{\lambda_{1}}),\\ &\vartheta_{2}=\arg\cos\left(\frac{\sqrt{\lambda_{2}}}{\sin\vartheta_{1}} \right),\\ &\vartheta_{3}=\arg\cos\left(\frac{\sqrt{\lambda_{3}}}{\sin\vartheta_{1}\sin \vartheta_{2}}\right),\\ &\vdots\\ &\vartheta_{m-1}=\arg\cos\left(\frac{\sqrt{\lambda_{m-1}}}{\prod_{i=1}^{m-2} \sin\vartheta_{i}}\right),\end{cases}\qquad\begin{cases}\lambda_{2}=\sin^{2}( \vartheta_{1})\cos^{2}(\vartheta_{2}),\\ \lambda_{3}=\sin^{2}(\vartheta_{1})\sin^{2}(\vartheta_{2})\cos^{2}(\vartheta_{3 }),\\ \vdots\\ &\lambda_{m}=\prod_{i=1}^{m-1}\sin^{2}(\vartheta_{i}).\end{cases}\] (22)

### Baseline methods used in fairness classification problem

This subsection describes baseline gradient methods for fairness classification problems (Section 5.2). We introduce three aggregation functions:

1. **Agg-LS** (Linear Scalarization):

\[g_{\bm{\lambda}}^{\mathrm{LS}}(\bm{x})=\sum_{i=1}^{m}\lambda_{i}f_{i}(\bm{x}).\]
2. **Agg-Tche** (Tchebycheff):

\[g_{\bm{\lambda}}^{\mathrm{Tche}}(\bm{x})=\max_{i\in[m]}\{\lambda_{i}(f_{i}( \bm{x})-z_{i})\},\]

where \(\bm{z}\) is a reference point (e.g., ideal point) which dominates the entire PF, i.e., \(\bm{z}\preceq\bm{y}\), for all \(\bm{y}\in\mathcal{T}\). For the modified Tchebycheff (**Agg-mTche**) function, the modification involves replacing \(\lambda_{i}\) with \(\frac{1}{\lambda_{i}}\) in the equation above.

3. **Agg-PBI** (Penalty-Based Intersection):

\[g_{\bm{\lambda}}^{\mathrm{PBI}}(\bm{x})=d_{1}+\mu d_{2}=\frac{\left\|(\bm{z}- \bm{f}(\bm{x}))^{\top}\bm{\lambda}\right\|}{\left\|\bm{\lambda}\right\|}+\mu \left\|\bm{f}(\bm{x})-(\bm{z}-d_{1}\bm{\lambda})\right\|,\]

where \(\bm{z}\) is the same reference point as introduced. For gradient-based multiobjective optimization methods, solution \(\bm{x}\) is updated as \(\bm{x}\leftarrow\bm{x}-\eta\frac{\partial g_{\bm{\lambda}}(\bm{x})}{\partial \bm{x}}\), where \(\eta\) is a small positive learning rate, and the superscript agg denotes PBI, LS, or Tche. We also would like to briefly introduce the other three gradient based method, PMGDA (Preference-based Multiple Gradient Descent Algorithm) [59], EPO (Exact Pareto optimization) [36], and HVGrad (Gradient-based HV maximization method) [17]. PMGDA and EPO employ gradient-based techniques to precisely identify Pareto solutions at the intersection points where the Pareto objectives converge with the PF. On the other hand, HVGrad leverages gradient ascent on the hypervolume to maximize the hypervolume metric, thereby optimizing the overall dominance of the solution set.

### Duplicated solutions issues caused by the mTche aggregation function

In this section, we discuss when Tchebycheff aggregation methods yield duplicated Pareto objectives. Appendix C.5 illustrates this, showing a preference vector \(\bm{\lambda}^{(1)}\) intersecting the PF at the optimal solution \(\bm{y}^{*}\), where

\[\frac{y_{i}^{*}}{\lambda_{i}}=\ldots=\frac{y_{m}^{*}}{\lambda_{m}}.\] (23)

If the preference vector does not intersect the Pareto front (\(\bm{\lambda}^{(2)}\)), \(\bm{y}^{*}\) is the Pareto front endpoint with the highest Tchebycheff value. In Appendix C.5, \(\bm{y}^{*}\) is the optimal value, so preferences \(\bm{\lambda}^{(1)}\) and \(\bm{\lambda}^{(2)}\) correspond to the duplicated Pareto objective \(\bm{y}^{*}\).

Figure 12: Duplicated solutions generated by Agg-mTche. Different preference vectors \(\bm{\lambda}^{(1)}\) and \(\bm{\lambda}^{(2)}\) correspond to the same optimal objective vector \(\bm{y}^{*}\).

## Appendix D Miscellaneous

### Broader impacts

By optimizing multiple conflicting objectives, these algorithms enhance decision-making in fields such as healthcare, product design, and trustworthy machine learning. In product design, multiobjective optimization balances trade-offs between capacity and cost, facilitating the effective release of products that represent the entire Pareto front. In trustworthy machine learning, the UMOD method designs a series of classifiers that balance fairness and accuracy, improving our understanding of different Pareto-optimal classifiers.

UMOD is a foundational algorithm, and its broader impact depends on its downstream applications. We believe UMOD itself does not have a direct negative social impact.

### Limitations

While we have illustrated UMOD's success, we acknowledge some limitations. First, UMOD does not address disconnected Pareto fronts such as DTLZ7, as Theorems 3 and 4 assume a connected Pareto front to ensure uniform distribution. Second, we have not considered problems with discrete, binary decision variables, or constrained MOPs, as our approach requires a continuous Pareto front. Adapting UMOD to these complex MOO problems is our next goal. Finally, UMOD requires a neural model to estimate the Pareto front shape. Although training and preference updating with neural networks are efficient, this adds extra operations compared to traditional multiobjective algorithms, which brings inconvenience.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes]. Justification: We explicitly enumerate our contributions in the end of the introduction part.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: We list the limitations in the last section (Section 6).
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: The assumptions are included in theorems and the full proofs are provided in Appendices A.1 to A.3 respectively.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: We provide experiment details in Appendix B.3.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes]. Justification: The model implementation and the code are attached as supplementary materials. Source codes have been open to the public.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes]. Justification: The details experiment settings are provided in Appendix B.3.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes]. Justification: All numerical results are averaged on 31 random seeds.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes]. Justification: Details are provided in Section 5 (Experiment settings).
9. **Code Of Ethics**Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes].
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes]. Social impact is discussed in Appendix D.1.
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: This paper is not related to LLMs and image generators.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes]. Justification: Licenses are provided in Appendix B.3.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [Yes]. Justification: The paper proposes a new model, and we choose the CC BY 4.0 license.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA]. Justification: This paper is not related with human subjects.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA]. Justification: The proposed method is a fundamental algorithm and is not directly related to human subjects.