# Online Inventory Problems: Beyond the i.i.d. Setting with Online Convex Optimization

 Massil Hihat\({}^{1,2}\), Stephane Gaiffas\({}^{1,2}\), Guillaume Garrigos\({}^{1,2}\), Simon Bussy\({}^{1}\)

\({}^{1}\)LOPF, Califrais' Machine Learning Lab, Paris, France

\({}^{2}\)Universite Paris Cite and Sorbonne Universite, CNRS,

Laboratoire de Probabilites, Statistique et Modelisation, Paris, France

{hihat, stephane.gaiffas, garrigos}@lpsm.paris, simon.bussy@califrais.fr

###### Abstract

We study multi-product inventory control problems where a manager makes sequential replenishment decisions based on partial historical information in order to minimize its cumulative losses. Our motivation is to consider general demands, losses and dynamics to go beyond standard models which usually rely on newsvendor-type losses, fixed dynamics, and unrealistic i.i.d. demand assumptions. We propose MaxCOSD, an online algorithm that has provable guarantees even for problems with non-i.i.d. demands and stateful dynamics, including for instance perishability. We consider what we call non-degeneracy assumptions on the demand process, and argue that they are necessary to allow learning.

## 1 Introduction

An inventory control problem is a problem faced by an inventory manager that must decide how much goods to order at each time period to meet demand for its products. The manager's decision is driven by the will to minimize a certain _regret_, which often penalizes missed sales and storage costs. It is a standard problem in operations research and operations management, and the reader unfamiliar with the topic can find a precise description of this problem in Section 2.

The classical literature of inventory management focuses on optimizing an inventory system with complete knowledge of its parameters: we know in advance the demands, or the distribution they will be drawn from. Many efforts have been put into characterizing the optimal ordering policies, and providing efficient algorithms to find them. See e.g. the Economic Order Quantity model [7], the Dynamic Lot-Size model [30] or the newsvendor model [1]. Nevertheless, in many applications, the parameters of the inventory system are unknown. In this case, the manager faces a joint learning and optimization problem that is typically framed as a _sequential decision making_ problem: the manager bases its replenishment decisions on data that are collected over time, such as past demands (observable demand case) or past sales (censored demand case). The early attempts to solve these _online_ inventory problems employed various techniques and provided only weak guarantees or no guarantees at all [23, 4, 6, 12].

With the recent advances in online learning frameworks such as online convex optimization (OCO), bandits, or learning with expert advice, the literature of learning algorithms for inventory problems took a great leap forward. There is currently a growing body of research aiming at solving various online inventory problems while providing strong theoretical guarantees in the form of _regret bounds_[9, 13, 24, 3, 34, 25, 35, 15, 32, 33, 31].

However, these works rely on mathematically convenient but unrealistic assumptions. The most common one being that the demands are assumed to be independent and identically distributed (_i.i.d._) across time, which rules out correlations and nonstationarities that are common in real-world scenarios.

Furthermore, these works focus on specific cost structures (typically the _newsvendor_ cost) and inventory dynamics (like lost sales models with nonperishable products), which we detail in Section 2.2. The main goal of this paper is to go beyond these restrictions and consider general demand processes, losses and dynamics, in order to provide numerical methods backed with theoretical guarantees compatible with real-world problems.

To do so, we recast the online inventory problem into a new framework called Online Inventory Optimization (OIO), which extends OCO. Our main contribution is a new algorithm called MaxCOSD, which can be seen as a generalization of the Online Subgradient Descent method. It solves OIO problems with provable theoretical guarantees under minimal assumptions (see Section 4). Here is an informal version of our main statement:

**Theorem 1** (Informal version of Theorem 12).: _Consider an OIO problem that satisfies convexity and boundedness assumptions. Assume further that demands are not degenerate (see Assumption 10). Then, running MaxCOSD (see Algorithm 2) with adequate adaptive learning rates gives an optimal \(O(\sqrt{T})\) regret, both in expectation and in high probability._

Our main assumption is a _non-degeneracy_ hypothesis on the demand process, which we present and discuss in Section 5. This assumption generalizes typical hypotheses made in the inventory literature, while not requiring the demand to be _i.i.d._. We also show that this assumption is sharp, in the sense that the OIO cannot be solved without such assumption. Finally, in Section 6 we present numerical experiments on both synthetic and real-world data that validate empirically the versatility and performances of MaxCOSD. The appendices gather the proofs of all our statements.

This paper helps to bridge the gap between OCO and inventory optimization problems, and we hope that it will raise awareness of OCO researchers to this family of under-studied problems, while being of importance to the industry.

## 2 A general model for online inventory problems

In this section, we present a new but simple model allowing to study a large class of online inventory problems. Then, in a series of remarks we discuss particular instances of these problems and the limitations of our model.

### Description of the model and main assumptions

In the following, \(n\in\mathbb{N}=\{1,2,\dots\}\) refers to the number of products and \(\mathcal{Y}\subset\mathbb{R}_{+}^{n}\) denotes the _feasible set_. An _online inventory optimization_ (OIO) problem is a sequential decision problem where an _inventory manager_ interacts with an _environment_ according to the following protocol.

First, the environment sets the initial inventory state to zero (\(x_{1}=\mathbf{0}\in\mathbb{R}^{n}\)), and chooses (possibly random) _demands_\(d_{t}\in\mathbb{R}_{+}^{n}\) and _losses_\(\ell_{t}:\mathbb{R}^{n}\to\mathbb{R}\) for every time period \(t\in\mathbb{N}\). Then, the interactions begin and unfold as follows, for every time period \(t\in\mathbb{N}\):

1. The manager observes the _inventory state_\(x_{t}\in\mathbb{R}^{n}\), where \(x_{t,i}\) encodes the quantity of the \(i^{\text{th}}\) product available in the inventory.
2. The manager raises this level by choosing an _order-up-to level_\(y_{t}\in\mathcal{Y}\) which satisfies the _feasibility_ constraint: \[y_{t}\succeq x_{t}.\] (1) Then, the manager receives instantaneously \(y_{t,i}-x_{t,i}\geq 0\) units of the \(i^{\text{th}}\) product.
3. The manager suffers a loss \(\ell_{t}(y_{t})\) and observes a subgradient \(g_{t}\in\partial\ell_{t}(y_{t})\).
4. The environment updates the inventory state by choosing \(x_{t+1}\in\mathbb{R}^{n}\) satisfying the following _inventory dynamical constraint_: \[x_{t+1}\preceq[y_{t}-d_{t}]^{+}\,.\] (2)

The goal of the manager is to design an online _algorithm_ that produces feasible order-up-to levels \(y_{t}\) which minimizes the cumulative loss suffered using past observations (past inventory states and subgradients). Let us emphasize here the fact that demands and losses are not directly observable. Throughout the paper, we make the following assumptions on the feasible set and the losses.

**Assumption 2** (Convex and bounded problem).:
1. _(Convex and bounded constraint)_ The feasible set \(\mathcal{Y}\) is closed, convex, nonnegative (\(\mathcal{Y}\subset\mathbb{R}_{+}^{n}\)) and bounded: \(\operatorname{diam}\mathcal{Y}\leq D\) for some \(D\geq 0\).
2. _(Convex losses)_ For every \(t\in\mathbb{N}\), the loss function \(\ell_{t}\) is convex.
3. _(Uniformly bounded subgradients)_ There exists \(G>0\) such that, for all \(t\in\mathbb{N}\), \(y\in\mathcal{Y}\) and \(g\in\partial\ell_{t}(y)\) we have \(\|g\|_{2}\leq G\).

Apart from the non-negativity assumption \(\mathcal{Y}\subset\mathbb{R}_{+}^{n}\) which is specific to inventory problems, Assumption 2 is very common in online convex optimization [36].

**Definition 3** (Regret).: Given an horizon \(T\in\mathbb{N}\), we measure the performance of an algorithm with the usual notion of _regret_ which is defined as:

\[R_{T}=\sum_{t=1}^{T}\ell_{t}(y_{t})-\inf_{y\in\mathcal{Y}}\sum_{t=1}^{T}\ell_ {t}(y).\] (3)

Observe that \(R_{T}\) is possibly random, so we call its expectation the _expected regret_\(\mathbb{E}\left[R_{T}\right]\).

Notice that in our model any constant strategy is feasible (see Lemma 26 in the appendix). Thus, the regret (3) is well-defined and can be interpreted as the difference between the cumulative loss incurred by the algorithm and that incurred by the best feasible constant strategy1. It is an easy exercise to see that under Assumption 2 we always have \(R_{T}\leq DGT\) (see Lemma 27 in the appendix). Thus, our goal is to design algorithms with _sublinear_ regret with respect to \(T\), achieving \(\mathbb{E}[R_{T}]\leq o(T)\). Note that some authors consider the equivalent notion of averaged regret \((1/T)R_{T}\). In this context, we would talk about _no-regret_ algorithms.

Footnote 1: In the context of inventory problems, these constant strategies are known under the name of (stationary) base-stock policies, \(S-\)policies, or order-up-to policies. See e.g. [26, Chapter 4].

### Description of standard inventory models and limitations of our model

**Remark 4** (On the demands).: Demands are modeled by a stochastic process \((d_{t})_{t\in\mathbb{N}}\subset\mathbb{R}_{+}^{n}\) with fixed in advance distribution. In other words, we consider a general oblivious model for demands where we make _no_ assumptions of regularity, stationarity or independence. Thus, our model accommodates both _i.i.d._[9, 3, 25, 32, 33, 31] and _deterministic_ demands [13, 24, 34, 35, 15], while also allowing for correlations and nonstationarities that appear for instance in autoregressive models. However, we rule out strategic behaviors: this is not a game-theoretic model.

**Remark 5** (On the dynamic).: Inventory states \(x_{t}\) are constrained by the inventory dynamical constraint (2) which links states, demands, and order-up-to levels. This constraint resembles the notion of _partial perishability_ introduced in [9, Section 3.3] which imposes further that inventory states are non-negative. In the following, we present some standard dynamics that conform to our model. We warn the reader that we try here to simplify the vocabulary used in the scattered inventory literature, and that some authors [9, 3] may refer to these dynamics using different terms2. Footnote 2: For instance the stateless dynamic is usually referred to as the “perishable” setting, and lost sales and backlogging dynamics may both be referred to as “nonperishable” settings.

* **Stateless dynamic.** In stateless inventory problems, we assume that no product is carried over from one period to the other, _i.e._\(x_{t}=\mathbf{0}\). Observe that due to the non-negativity assumption \(\mathcal{Y}\subset\mathbb{R}_{+}^{n}\), the feasibility constraint (1) is satisfied by any choice of \(y_{t}\in\mathcal{Y}\) in stateless problems. This means that stateless inventory problems coincide with the usual online convex optimization (OCO) framework [36]. See Appendix D.1 for a discussion on the relationship between OCO and OIO. Any dynamic which is not stateless is called **stateful**, see below.
* **Backlogging dynamic.** In backlogging inventory problems, excess demand stays on the books until it is satisfied and inventory leftovers are carried over to the next period. It corresponds to set \(x_{t+1}=y_{t}-d_{t}\). Notice that in this case the inventory state may be negative to represent backorders. This kind of dynamic has been widely studied in the context of classical inventory theory due to its linear nature, see e.g. [26, Chapter 4].

* **Lost sales dynamic.** Assume that products are nonperishable, excess demand is lost and inventory leftovers are carried over to the next period. We refer to this case as the lost sales dynamic which corresponds to set \(x_{t+1}=\left[y_{t}-d_{t}\right]^{+}\). See e.g. [9, 25].
* **Perishable dynamic.** In perishable inventory systems [19], newly ordered products are fresh units that have a fixed usable lifetime. To model such a dynamic, it is necessary to track the entire age distribution of the on hand inventory and to specify the stockout type (lost sales or backlogging) and the issuing policy (i.e. how items are issued to meet demand). For instance, [32] describes a perishable setting modeling a single product with first-in-first-out issuing policy, which satisfies our inventory dynamical constraint (2).

All those dynamics are what we call _deterministic_ dynamics, in the sense that they take the form:

\[(\forall t\in\mathbb{N})\quad x_{t+1}=X_{t}(y_{1},d_{1},\dots,y_{t},d_{t}),\] (4)

where \(X_{t}:(\mathcal{Y}\times\mathbb{R}_{+}^{n})^{t}\to\mathbb{R}^{n}\) is a fixed in advance function satisfying \(X_{t}(y_{1}^{\prime},d_{1}^{\prime},\dots,y_{t}^{\prime},d_{t}^{\prime})\preceq \left[y_{t}^{\prime}-d_{t}^{\prime}\right]^{+}\) for all realizations \((\ell_{t}^{\prime})_{t\in\mathbb{N}}\), \((d_{t}^{\prime})_{t\in\mathbb{N}}\) and \((y_{t}^{\prime})_{t\in\mathbb{N}}\).

**Remark 6** (On the feasible set).: The feasible set \(\mathcal{Y}\) models fixed constraints on the order-up-to levels. Since it should satisfy Assumption 2.i), our framework does not allow for discrete sets as they appear in [15] for instance. This is one of the main limitations of our work. Typical choices include box constraints: \(\mathcal{Y}=\prod_{i=1}^{n}[\underline{y}_{i},\overline{y}_{i}]\), or capacity constraints [25]: \(\mathcal{Y}=\{y\in\mathbb{R}_{+}^{n}\mid\sum_{i=1}^{n}y_{i}\leq M\}\). Note that in some instances, the parameters of the box constraint is dictated by some assumptions on the problem. For instance, it is assumed in [9, 32] that \(\mathcal{Y}=[0,D]\) where \(D\) is a known upper bound for an optimal constant policy.

**Remark 7** (On the losses).: Losses \((\ell_{t})_{t\in\mathbb{N}}\) are random functions drawn before the interactions start. As for demands, we consider an oblivious model for the losses which allows to handle both the _i.i.d._ case and the _deterministic_ case. Most interestingly, losses can depend on the demands. This allows to consider the _newsvendor_ loss, which writes \(\ell_{t}(y)=c(y,d_{t})\) with:

\[c(y,d)=\sum_{i=1}^{n}\left(h_{i}\left[y_{i}-d_{i}\right]^{+}+p_{i}\left[d_{i}- y_{i}\right]^{+}\right).\] (5)

Here \(h_{i}\in\mathbb{R}_{+}\) and \(p_{i}\in\mathbb{R}_{+}\) are respectively the unit holding cost (a.k.a. overage cost) and unit lost sales penalty cost (a.k.a. underage cost) of product \(i\in[n]\). The newsvendor loss satisfy assumptions 2.ii) and 2.iii) with \(G=\sqrt{n}\max_{i\in[n]}\max\{h_{i},p_{i}\}\). Our model also accommodates the newsvendor loss with time-varying unit cost parameters, as long as these remain bounded.

Because the losses are drawn before-hand, our model usually does not allow to incorporate costs that depend explicitly on the inventory states such as purchase costs, outdating costs, or fixed costs. However, there are exceptions: when the dynamic is lost sales, purchase costs can be included into our model, by considering the newsvendor loss onto which a cost transformation is applied (a.k.a. _explicit formulation_[26, Paragraph 4.3.2.4]). See also [9, 25] and the references therein.

**Remark 8** (On the observability structure and subgradients).: To handle arbitrary losses, we required in our model that in addition to inventory states \(x_{t}\), at least one subgradient \(g_{t}\in\partial\ell_{t}(y_{t})\) is revealed at each period. In the case of the newsvendor loss, this is less demanding than both the _observable demand_ setting and the _censored demand_ setting [3]. In the former, the demand \(d_{t}\) is revealed instead of a subgradient \(g_{t}\), meaning that the manager has complete information on the newsvendor loss \(\ell_{t}=c(\cdot,d_{t})\). In the latter, the sale \(s_{t}:=\min\{y_{t},d_{t}\}\) is revealed, allowing the manager to compute a subgradient through the following formula (see Lemma 28 in Appendix B):

\[\left(h_{i}\mathds{1}_{\{y_{t},i>s_{t,i}\}}-p_{i}\mathds{1}_{\{y_{t,i}=s_{t,i }\}}\right)_{i\in[n]}\in\partial\ell_{t}(y_{t}).\]

In this case, we see that no randomization is involved in the choice of the subgradient. This means that the subgradient selection is _deterministic_, in the sense that:

\[(\forall t\in\mathbb{N})\quad g_{t}=\Gamma_{t}(\ell_{t},y_{t}),\] (6)

where \(\Gamma_{t}:\mathbb{R}^{\mathbb{R}^{n}}\times\mathcal{Y}\to\mathbb{R}^{n}\) is a fixed in advance function such that \(\Gamma_{t}(\ell_{t}^{\prime},y_{t}^{\prime})\in\partial\ell_{t}^{\prime}(y_{t} ^{\prime})\) for all realizations \((\ell_{t}^{\prime})_{t\in\mathbb{N}}\) and \((y_{t}^{\prime})_{t\in\mathbb{N}}\).

**Remark 9** (OIO vs OCO).: In this final remark, we would like to point out that OIO is a novel and strict extension of OCO, that is, OIO cannot be casted into OCO or one of its known extensions. More details on this are provided in Appendix D.1.

## 3 Partial results for simple inventory problems

Previous works on online inventory problems mainly focused on two settings: stateless inventory problems and stateful inventory problems with _i.i.d._ demands. Both settings are discussed here.

### Stateless inventory problems

In the literature of stateless inventory problems, arbitrary deterministic demands have already been considered. This has been done for instance in [13; 34; 35], which assume demand is observable and rely on the "learning with expert advice" framework. On the other hand [24] is the first work that considered the stateless setting with censored demand. See also [15] which tackled these problems in the discrete case, by reducing them to partial monitoring (an online learning framework that generalizes bandits). All these works achieve a \(O(\sqrt{T})\) regret (up to logarithmic terms), but are restricted to the newsvendor cost structure.

In our work, we aim at solving inventory problems with arbitrary demands and losses. Recall that under Assumption 2, stateless inventory problems coincide with the standard OCO framework [36] since feasibility (1) is trivially verified (see Remark 5). Thus, a natural choice to solve stateless inventory problems is the Online Subgradient Descent (OSD) method, which we recall in Algorithm 1.

```
1Parameters: learning rates \((\eta_{t})_{t\in\mathbb{N}}\), initial order-up-to level \(y_{1}\in\mathcal{Y}\)
2for\(t=1,2,\ldots\)do
3 Output \(y_{t}\);
4 Observe \(g_{t}\in\partial\ell_{t}(y_{t})\);
5 Set \(y_{t+1}=\operatorname{Proj}_{\mathcal{Y}}(y_{t}-\eta_{t}g_{t})\); ```

**Algorithm 1**OSD

Classical regret analysis of OSD (this is essentially proven in [8; Theorem 3.1], see also Corollary 20 in the appendix) shows that taking _decreasing_ learning rates of the form \(\eta_{t}=\gamma D/(G\sqrt{t})\) where \(\gamma>0\), leads to a regret bound \(R_{T}=O(GD\sqrt{T})\). It must be noted that the \(O(\sqrt{T})\) scaling is _optimal_ under Assumption 2 (see e.g. [22, Theorem 5] or [21, Theorem 5.1]).

### Stateful i.i.d. inventory problems

When non-trivial dynamics are involved, inventory problems are much more complex and have mainly been studied in the _i.i.d._ demands framework. We review here the literature of joint learning and inventory control with censored demand and refer to the recent review of [5; Chapter 11] for further references. We stress that all those papers obtain rates for the _pseudo-regret_, a lower bound of the expected regret which we consider in this paper (see Appendix D.2 for more details).

The seminal work of Huh and Rusmevichientong [9] is the first that derives regret bounds for the single-product _i.i.d._ newsvendor case under censored demand, it is also the sole work that considers general dynamics through their notion of _partial perishability_[9; Section 3.3]. They were able to design an algorithm called Adaptive Inventory Management (AIM) based on a subgradient descent and dynamic projections onto the feasibility constraint (1) which achieves a \(O(\sqrt{T})\) pseudo-regret. Their main assumption is that the demands should not be degenerate in the sense that \(\mathbb{E}\left[d_{1}\right]>0\) and that the manager should know a lower bound \(0<\rho<\mathbb{E}\left[d_{1}\right]\). This lower bound is then used in AIM to tune adequately the learning rate of the subgradient descent. Their analysis is based on results from queuing theory which rely heavily on the _i.i.d._ assumption.

Shi et al. [25] designed the Data-Driven Multi-product (DDM) algorithm which extend the AIM method of [9] to the multi-product case under capacity constraints. They also derived a \(O(\sqrt{T})\) pseudo-regret bound by assuming further that demands are pairwise independent across products and that \(\mathbb{E}\left[d_{1,i}\right]>0\) for all \(i\in[n]\) amongst other regularity conditions.

Zhang et al. [32] tackled the case of single-product _i.i.d._ perishable inventory systems with outdating costs. They designed the Cycle-Update Policy (CUP) algorithm which updates the order-up-to level according to a subgradient descent, but only when the system experiences a stockout, _i.e._ when \(x_{t}=0\), the order-up-to level remains unchanged otherwise. Feasibility is guaranteed using sucha policy. However, in order to derive \(O(\sqrt{T})\) pseudo-regret they need to ensure that the system experiences frequently stockouts. To do so, they consider a stronger form of non-degeneracy, namely, \(\mathbb{P}\left[d_{1}\geq D\right]>0\) where \(\mathcal{Y}=[0,D]\).

Variants of the subgradient descent have also been developed in order to achieve \(O(\sqrt{T})\) pseudo-regret in inventory systems that includes lead times [33] or fixed costs [31] which are both beyond the scope of our model.

To summarize, an optimal \(O(\sqrt{T})\) rate for the pseudo-regret is achievable in many stateful inventory problems, under the _i.i.d._ assumption. To prove so, most of the cited works developed specific variants of the subgradient descent that accommodates the specific dynamic at play. We will show in Section 4 that this optimal \(O(\sqrt{T})\) rate can be achieved by our algorithm MaxCOSD when applied to general inventory problems, with no _i.i.d._ assumption on the demand.

## 4 MaxCOSD: an algorithm for general inventory problems

In this section, we introduce and study our main algorithm: the Maximum Cyclic Online Subgradient Descent (MaxCOSD) algorithm. It is a variant of the subgradient descent where instead of changing the order-up-to levels at every period, updates are done only at certain _update periods_ denoted \((t_{k})_{k\in\mathbb{N}}\). These define _update cycles_\(\mathcal{T}_{k}=\{t_{k},\ldots,t_{k+1}-1\}\) during which the order-up-to level remains unchanged: \(y_{t}=y_{t_{k}}\) for all \(t\in\mathcal{T}_{k}\). Update periods are dynamically triggered by verifying, at the beginning of each time period \(t\in\mathbb{N}\), whether a _candidate order-up-to level_\(\hat{y}_{t}\) is feasible or not. This candidate is computed by making a subgradient step in the direction of the subgradients accumulated during the cycle and using the following _adaptive_ learning rates,3

Footnote 3: It may happen that \(\eta_{t}\) is undefined due to a denominator that is zero in Eq. (7), in such cases set \(\eta_{t}=0\).

\[\eta_{t}=\frac{\gamma D}{\sqrt{\left\|\sum_{s=t_{k}}^{t}g_{s}\right\|_{2}^{2}+ \sum_{m=1}^{k-1}\left\|\sum_{s\in\mathcal{T}_{m}}g_{s}\right\|_{2}^{2}}}\] (7)

The pseudo-code for MaxCOSD is given in Algorithm 2.

```
1Parameters: learning rate parameter \(\gamma>0\), initial order-up-to level \(y_{1}\in\mathcal{Y}\)
2Initialization: Set \(\hat{y}_{1}=y_{1}\), \(t_{1}=1\), \(k=1\);
3for\(t=1,2,\ \ldots\)do
4 Output \(y_{t}\);
5 Observe \(g_{t}\in\partial\ell_{t}(y_{t})\) and \(x_{t+1}\);
6 Compute \(\hat{y}_{t+1}=\mathrm{Proj}_{\mathcal{Y}}\left(\hat{y}_{t_{k}}-\eta_{t}\sum_{s =t_{k}}^{t}g_{s}\right)\) where \(\eta_{t}\) is defined3 in Eq. (7);
7if\(x_{t+1}\leq\hat{y}_{t+1}\)then
8 Set \(y_{t+1}=\hat{y}_{t+1}\), \(t_{k+1}=t+1\), \(k=k+1\);
9else
10 Set \(y_{t+1}=y_{t}\); ```

**Algorithm 2**MaxCOSD

MaxCOSD is inspired by CUP [32], which handles the feasibility constraint through cyclical updates. This approach differs for instance from AIM [9] or DDM [25], where the feasibility is enforced through projections onto the constraint. Among the differences between MaxCOSD and CUP is the fact that their cycle definition differ: in CUP stockouts trigger updates, whereas MaxCOSD relies directly on the feasibility condition, making its updates more frequent. Also, we use adaptive learning rates inspired by AdaGrad-Norm learning rates [27, Theorem 2] which allows us to be adaptive to the constant \(G\) and obtain high probability regret bounds which are not available for CUP. Finally, and most importantly, the assumptions required by CUP are restrictive: _i.i.d._ demands, single-product, perishable dynamic and a strong form of a demand non-degeneracy. On the other hand, MaxCOSD performs well under much milder assumptions, which we introduce next.

**Assumption 10** (Uniformly probably positive demand).: There exists \(\mu\in(0,1]\) and \(\rho>0\) such that, for all \(t\in\mathbb{N}\), almost surely,

\[\mathbb{P}\left[\forall i\in[n],\ d_{t,i}\geq\rho\ \big{|}\ \ell_{1},d_{1}, \ldots,\ell_{t-1},d_{t-1}\right]\geq\mu.\] (8)

In simple settings we recover through Assumption 10 conditions that already appeared in the literature:

* In single-product _i.i.d._ newsvendor inventory problems, our assumption is equivalent to the existence of \(\rho>0\) such that \(\mathbb{P}\left[d_{1}\geq\rho\right]>0\), that is, \(\mathbb{P}\left[d_{1}>0\right]>0\), or equivalently \(\mathbb{E}\left[d_{1}\right]>0\). This is exactly the non-degeneracy assumption required by [9] in AIM.
* In its multi-product extension, [25] assumes also pairwise independence across products. If we rather require mutual independence across products, then, Assumption 10 rewrites \(\mathbb{P}\left[d_{1,1}>0\right]\cdots\mathbb{P}\left[d_{1,n}>0\right]>0\), thus, our assumption reduces to \(\mathbb{E}\left[d_{1,i}\right]>0\) for all \(i\in[n]\) which is also required by [25] in their algorithm DDM.
* We recover an assumption made for CUP [32] by requiring \(\rho=D\) where \(\mathcal{Y}=[0,D]\), and where \(D\) is also assumed to be large enough (see Remark 6).
* If the demand is deterministic, then \(\mu=1\) and Eq. (8) becomes \(d_{t,i}\geq\rho\) for all \(i\in[n]\).
* If the demand is discrete, i.e. \(d_{t,i}\in\{0,1,\dots\}\) for all \(t\in\mathbb{N},i\in[n]\), then, we can take \(\rho=1\) and rewrite Eq. (8) as follows: \(\mathbb{P}\left[\exists i\in[n],d_{t,i}=0|\ell_{1},d_{1},\ldots,\ell_{t-1},d_{ t-1}\right]\leq 1-\mu\).

In addition to Assumption 10 we also introduce a mild technical condition.

**Assumption 11** (Deterministic dynamic and subgradient selection).: Dynamics and subgradient selections are deterministic, see Eq. (4) and Eq. (6).

We can now state our main result: under this new set of assumptions MaxCOSD achieves an optimal \(O(\sqrt{T})\) regret bound both in expectation and in high probability.

**Theorem 12**.: _Consider an inventory problem, and let assumptions 2, 10 and 11 hold. Then, MaxCOSD (see Algorithm 2) run with \(y_{1}\in\mathcal{Y}\) and \(\gamma>0\) is feasible. Furthermore, when \(\gamma\in(0,\rho/D]\), it enjoys the following regret bounds for all \(T\in\mathbb{N}\),_

\[\mathbb{E}\left[R_{T}\right]\leq\frac{\sqrt{2}GD}{\mu}\left(\frac{1}{2\gamma} +\gamma+1\right)\sqrt{T},\]

_and for any confidence level \(\delta\in(0,1)\) we have with probability at least \(1-\delta\),_

\[R_{T}\leq GD\left(\frac{1}{2\gamma}+\gamma+1\right)\left(1+\frac{1}{\mu}\log \left(\frac{T}{\delta}\right)\right)\sqrt{T}.\]

The obtained regret scales in \(O(\sqrt{T})\), which is similar to other methods in the literature (see Section 3.2). As for the scaling in the constants \(\mu\) and \(\rho\), our rate scales like \(O(\frac{1}{\rho\mu})\) and we do not know whether this can be improved or not. As a matter of comparison, CUP enjoys the same scaling (see [32, Theorem 2 & Remark 3 & Assumption 1]).

## 5 Non-degenerate demands are needed for stateful inventory problems

Throughout this paper, we have seen instances of OIO which can be solved with sublinear regret rates: stateless OIO (equivalent to OCO), and some stateful OIO. It must be noted that, contrary to OCO, solving those stateful OIO problems required a non-degeneracy assumption on the demand (see Assumption 10 and Section 3.2). We argue here that such an assumption is necessary for solving stateful OIO. Note that this idea is not new, and was already observed in the conclusion of [3]: _"To control for the impact of overordering, demands must be bounded away from zero, at least in expectation."_. Our contribution is to make this observation formal.

**Proposition 13**.: _Given any feasible deterministic4 algorithm for the single-product lost sales newsvendor inventory problem with observable demand over \(\mathcal{Y}=[0,D]\), there exists a sequence of demands such that the regret is linear, i.e. \(R_{T}=\Theta(T)\)._Proposition 13 shows that Assumption 2 is not sufficient to reach sublinear regret in general inventory problems. This is totally unusual from an OCO perspective, and is a specificity of _stateful_ OIO. Furthermore, the above result shows that what prevents us from reaching sublinear rates is not the limited feedback (demands and losses are observable in this example) but rather _zero demands_. This is why it is necessary to make an assumption preventing demands to be too small, in some sense. Note that one may think of imposing positive demands to circumvent this difficulty, but this is not sufficient. Indeed, a sequence of demands converging too fast to zero can also be problematic.

**Proposition 14**.: _Given any feasible algorithm for the single-product lost sales problem with observable demand over \(\mathcal{Y}=[0,D]\) such that \(y_{1}\in(0,D]\), there exists a constant sequence of losses and a sequence of positive demands such that the regret is linear, i.e. \(R_{T}=\Theta(T)\)._

Let us now investigate why degenerated demand becomes a problem when going from stateless to stateful OIO. The main difference between the two is that the feasibility constraint is always trivially satisfied for stateless OIO (see Remark 5). Instead, for stateful OIO, we can show that the higher is the demand, the easier it is for the feasibility constraint to be satisfied.

**Lemma 15**.: _Let \(y,y^{\prime},d\in\mathbb{R}_{+}^{n}\). If \(\left\|y^{\prime}-y\right\|_{2}\leq\min_{i\in[n]}d_{i}\), then, \(y^{\prime}\succeq\left[y-d\right]^{+}\). In particular, given an inventory problem and a time period \(t\in\mathbb{N}\), taking \(y_{t+1}\in\mathcal{Y}\subset\mathbb{R}_{+}^{n}\) such that \(\left\|y_{t+1}-y_{t}\right\|_{2}\leq\min_{i\in[n]}d_{i,t}\) ensures that \(y_{t+1}\) is feasible, in the sense that \(x_{t+1}\preceq y_{t+1}\)._

The above lemma shows that if \(y_{t+1}\) is taken close enough from the previous \(y_{t}\), then the algorithm is feasible. The key point here is that "close enough" is controlled by the demand, meaning that when the demand is closer to zero there are less feasible choices for the manager. In such a case, we understand that it may be impossible to achieve sublinear regret, because the set of feasible choices could be too reduced.

The distance between two consecutive decisions can easily be controlled in methods based on subgradient descents, through their learning rates. This is why Lemma 15 is very helpful in the design of efficient feasible algorithms. It has been employed in the proof of our main result regarding MaxCOSD (Theorem 12). In the following, we further illustrate its usefulness by showing that OSD (see Algorithm 1) with adequate learning rates is feasible when the demand is _uniformly positive_.

**Assumption 16** (Uniformly positive demand).: There exists \(\rho>0\) such that for all \(t\in\mathbb{N}\), \(i\in[n]\),

\[d_{t,i}\geq\rho.\] (9)

**Theorem 17**.: _Consider an inventory problem, and let assumptions 2 and 16 hold. Then, OSD (see Algorithm 1) run with \(y_{1}\in\mathcal{Y}\) and \(\eta_{t}=\gamma D/(G\sqrt{t})\) where \(\gamma\in(0,\rho/D]\), is feasible and satisfies for all \(T\in\mathbb{N}\) that \(R_{T}\leq(1+2\gamma)(2\gamma)^{-1}GD\sqrt{T}\)._

## 6 Numerical results

The goal of the following numerical experiments5 is to show the versatility and performances of MaxCOSD in various settings. Let us consider the following problems.

Footnote 5: The code is available at https://github.com/Califrais/newsvendor_tester.

* **Setting 1.** Single-product lost sales inventory problem with _i.i.d._ demands drawn according to \(\text{Poisson}(1)\).
* **Setting 2.** Single-product perishable inventory problem with a lifetime of \(2\) periods and _i.i.d._ demands drawn according to \(\text{Poisson}(1)\).
* **Setting 3.** Multi-product lost sales inventory problem with \(n=100\) and capacity constraints. Demands are _i.i.d._ and drawn independently across products according to \(\text{Poisson}(\lambda_{i})\) where the intensities \(\lambda_{i}\) have been drawn independently according to \(\text{Uniform}[1,2]\).
* **Setting 4.** Multi-product lost sales inventory problem with \(n=3049\) and capacity constraints. Demands are taken from the real-world dataset of the M5 competition [17].
* **Setting 5.** Multi-product lost sales inventory problem with \(n=3049\) and box constraints. As in Setting 4 we considered demands from the M5 competition dataset [17].

We use the newsvendor loss in all the settings. In all the settings the cost parameters satisfy \(p_{i}/h_{i}=200\) since this ratio is known to exceed 200 in many applications [10]. In settings 1, 2 and 3, \(h_{i}=1\) and in settings 4 and 5, \(h_{i}\) and \(p_{i}\) are proportional to the real average selling costs.

In settings 1, 2, 3 and 4 we compare MaxCOSD against the following baselines: AIM [9] for Setting 1, CUP [32] for Setting 2, and DDM [25] for settings 3 and 4. In Setting 5, we ran a parallelized version of MaxCOSD, that is, one instance of MaxCOSD per product, and a parallelized version of AIM. Notice that in Settings 4 and 5 demands are not _i.i.d._ and thus, do not fit the assumptions of the baselines considered. Notice also that Theorem 12 requires MaxCOSD's learning rate to be small enough (\(\gamma\leq\rho/D\)), which we do not try to enforce here. All the algorithms have been initialized with \(y_{1}=\mathbf{0}\). Settings 1, 2 and 3 have been run \(10\) times, with different demand realizations generated through independent samples.

Figure 1 shows, for every setting, the regret obtained after \(T\) periods as a function of the learning rate parameter \(\gamma\in[10^{-5},10^{1}]\). We picked \(T=1969\) for all the settings because it corresponds to the number of periods available in our real-world dataset [17]. We see that MaxCOSD performs well compared to baselines whenever the number of handled products remains low (Settings 1,2,3,5). Instead, we see that MaxCOSD is less efficient when the number of products becomes large, in particular in the Setting 4. The performance of MaxCOSD in the large \(n\) regime can be explained by the fact that the cycles become longer, as it becomes less likely that the feasibility condition is satisfied. Indeed, we have seen in Lemma 15 that the larger the overall demand is, the easier feasibility holds. But when \(n\) grows, \(\min_{i}d_{i,t}\) becomes smaller, making the problem harder.

## 7 Conclusion

In this paper, we address Online Inventory Optimization problems by introducing MaxCOSD, the first algorithm which can be applied to a wide variety of real-world problems. More precisely, MaxCOSD enjoys an optimal \(O(\sqrt{T})\) regret without assuming the demand to be _i.i.d._, and can handle a large class of dynamics, including perishability models. We achieved this result by applying ideas and methods from online learning to OIO problems.

Still, there is a lot of space for improvements and future developments. First, we observed that for problems with a large number of products and capacity constraints, the empirical performance of MaxCOSD could be improved. To do so, one would need to better handle the feasibility constraint, by using for instance projections onto the feasibility constraint, an idea already used by DDM, but with no theoretical guarantees so far in real-world scenarios. Second, we obtained regret bounds under minimal structural assumptions on the problem (convex lipschitz losses), but we could expect to obtain better rates by making stronger assumptions on the problem. One such assumption, which is classical in the Online Convex Optimization literature, is to assume further that the losses are strongly convex or exp-concave, typically leading to a logarithmic \(O(\log(T))\) regret. Another assumption,

Figure 1: Regret in settings 1 to 5 (from left to right) as a function of the learning rate parameter \(\gamma\).

which is more specific to the Online Inventory literature, is to make some regularity assumption directly on the demand, also leading to a logarithmic pseudo-regret in the newsvendor case [3, Subsection 2.3]. Finally, even if our model is quite versatile, it has its limits, and more work is needed to improve it. For instance, we have seen in Section 2.2 that we do not accommodate for outdating costs as they appear in [32]. Also, we do not handle discrete feasible sets for which two promising techniques have been applied in the literature: expert algorithms [15] and probabilistic rounding [9, Subsection 3.4]. We could also hope to further weaken our non-degeneracy Assumption 10, by making an hypothesis which applies independently to each product, without having to assume pairwise independence across products. We believe that an adequate adaptation of online convex optimization techniques to the online inventory framework will prove to be a successful strategy for overcoming those challenges.

## Acknowledgement

We are thankful to Adeline Fermanian and the anonymous reviewers for helpful discussions and suggestions. Our work has been funded by the LOPF LabCom ANR-20-LCV1-0005 grant, provided by the French "Agence Nationale de la Recherche".

## References

* [1] Kenneth J Arrow, Theodore Harris, and Jacob Marschak. Optimal inventory policy. _Econometrica: Journal of the Econometric Society_, pages 250-272, 1951.
* [2] Masoud Badiei, Na Li, and Adam Wierman. Online convex optimization with ramp constraints. In _2015 54th IEEE Conference on Decision and Control (CDC)_, pages 6730-6736. IEEE, 2015.
* [3] Omar Besbes and Alp Muharremoglu. On implications of demand censoring in the newsvendor problem. _Management Science_, 59(6):1407-1424, 2013.
* [4] Apostolos N Burnetas and Craig E Smith. Adaptive ordering and pricing for perishable products. _Operations Research_, 48(3):436-443, 2000.
* [5] Xi Chen, Stefanus Jasin, and Cong Shi. _The Elements of Joint Learning and Optimization in Operations Management_, volume 18. Springer Nature, 2022.
* [6] Gregory A Godfrey and Warren B Powell. An adaptive, distribution-free algorithm for the newsvendor problem with censored demands, with applications to inventory and distribution. _Management Science_, 47(8):1101-1112, 2001.
* [7] Ford W Harris. How many parts to make at once. 1913.
* [8] Elad Hazan et al. Introduction to online convex optimization. _Foundations and Trends(r) in Optimization_, 2(3-4):157-325, 2016.
* [9] Woonghee Tim Huh and Paat Rusmevichientong. A nonparametric asymptotic analysis of inventory planning with censored demand. _Mathematics of Operations Research_, 34(1):103-123, 2009.
* [10] Woonghee Tim Huh, Ganesh Janakiraman, John A Muckstadt, and Paat Rusmevichientong. An adaptive algorithm for finding the optimal base-stock policy in lost sales inventory systems with censored demand. _Mathematics of Operations Research_, 34(2):397-416, 2009.
* [11] Rodolphe Jenatton, Jim Huang, and Cedric Archambeau. Adaptive algorithms for online convex optimization with long-term constraints. In _International Conference on Machine Learning_, pages 402-411. PMLR, 2016.
* [12] Retsef Levi, Robin O Roundy, and David B Shmoys. Provably near-optimal sampling-based policies for stochastic inventory control models. _Mathematics of Operations Research_, 32(4):821-839, 2007.
* [13] Tatsiana Levina, Yuri Levin, Jeff McGill, Mikhail Nediak, and Vladimir Vovk. Weak aggregating algorithm for the distribution-free perishable inventory problem. _Operations Research Letters_, 38(6):516-521, 2010.
* [14] Nikolaos Liakopoulos, Apostolos Destounis, Georgios Paschos, Thrasyvoulos Spyropoulos, and Panayotis Mertikopoulos. Cautious regret minimization: Online optimization with long-term budget constraints. In _International Conference on Machine Learning_, pages 3944-3952. PMLR, 2019.

* [15] Gabor Lugosi, Mihalis G Markakis, and Gergely Neu. On the hardness of inventory management with censored demand data. _arXiv preprint arXiv:1710.05739_, 2017.
* [16] Mehrdad Mahdavi, Rong Jin, and Tianbao Yang. Trading regret for efficiency: online convex optimization with long term constraints. _The Journal of Machine Learning Research_, 13(1):2503-2528, 2012.
* [17] Spyros Makridakis, Evangelos Spiliotis, and Vassilios Assimakopoulos. The m5 competition: Background, organization, and implementation. _International Journal of Forecasting_, 38(4):1325-1336, 2022.
* [18] Shie Mannor, John N Tsitsiklis, and Jia Yuan Yu. Online learning with sample path constraints. _Journal of Machine Learning Research_, 10(3), 2009.
* [19] Steven Nahmias. _Perishable inventory systems_, volume 160. Springer Science & Business Media, 2011.
* [20] Michael J Neely and Hao Yu. Online convex optimization with time-varying constraints. _arXiv preprint arXiv:1702.04783_, 2017.
* [21] Francesco Orabona. A modern introduction to online learning. _arXiv preprint arXiv:1912.13213_, 2019.
* [22] Francesco Orabona and David Pal. Scale-free online learning. _Theoretical Computer Science_, 716:50-69, 2018.
* [23] Herbert Scarf. Bayes solutions of the statistical inventory problem. _The annals of mathematical statistics_, 30(2):490-508, 1959.
* [24] Peter Sempolinski and Amitabh Chaudhary. Online algorithms for the newsvendor problem with and without censored demands. In _Frontiers in Algorithmics: 4th International Workshop, FAW 2010, Wuhan, China, August 11-13, 2010. Proceedings 4_, pages 234-249. Springer, 2010.
* [25] Cong Shi, Weidong Chen, and Izak Duenyas. Nonparametric data-driven algorithms for multiproduct inventory systems with censored demand. _Operations Research_, 64(2):362-370, 2016.
* [26] Lawrence V Snyder and Zuo-Jun Max Shen. _Fundamentals of supply chain theory_. John Wiley & Sons, 2019.
* [27] Matthew Streeter and H Brendan McMahan. Less regret via online conditioning. _arXiv preprint arXiv:1002.4862_, 2010.
* [28] Wen Sun, Debadeepta Dey, and Ashish Kapoor. Safety-aware algorithms for adversarial contextual bandit. In _International Conference on Machine Learning_, pages 3280-3288. PMLR, 2017.
* [29] Roman Vershynin. _High-dimensional probability: An introduction with applications in data science_, volume 47. Cambridge university press, 2018.
* [30] Harvey M Wagner and Thomson M Whitin. Dynamic version of the economic lot size model. _Management science_, 5(1):89-96, 1958.
* [31] Hao Yuan, Qi Luo, and Cong Shi. Marrying stochastic gradient descent with bandits: Learning algorithms for inventory systems with fixed costs. _Management Science_, 67(10):6089-6115, 2021.
* [32] Huanan Zhang, Xiuli Chao, and Cong Shi. Perishable inventory systems: Convexity results for base-stock policies and learning algorithms under censored demand. _Operations Research_, 66(5):1276-1286, 2018.
* [33] Huanan Zhang, Xiuli Chao, and Cong Shi. Closing the gap: A learning algorithm for lost-sales inventory systems with lead times. _Management Science_, 66(5):1962-1980, 2020.
* [34] Yong Zhang, Vladimir Vovk, and Weiguo Zhang. Probability-free solutions to the non-stationary newsvendor problem. _Annals of Operations Research_, 223(1):433-449, 2014.
* [35] Yong Zhang, Xingyu Yang, and Baixun Li. Distribution-free solutions to the extended multi-period newsboy problem. _Journal of Industrial & Management Optimization_, 13(2):633, 2017.
* [36] Martin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In _Proceedings of the 20th international conference on machine learning (icml-03)_, pages 928-936, 2003.

Analysis of MaxCOSD

The goal of this appendix is to study the MaxCOSD algorithm (see Algorithm 2) and prove Theorem 12. To do so, we start by introducing a generalized version of MaxCOSD named Cyclic Online Subgradient Descent (COSD) which has general update periods and learning rates (see Algorithm 3). In Proposition 19 we provide a general analysis of COSD which shows that it is sufficient to control the cycles' length to derive \(O(\sqrt{T})\) regret bounds. As a byproduct of this proposition we also derive the classical analysis of OSD (see Corollary 20). A way of ensuring that the cycles' lengths are efficiently controlled is through a probabilistic property (see Assumption 21) which is similar to sub-exponential concentration [29, Section 2.7]. Finally, using Lemma 15 and Assumptions 2, 10 and 11 we show that when \(\gamma\in(0,\rho/D]\) the cycles' length of MaxCOSD satisfy Assumption 21 which allows us to conclude with Theorem 12.

### Design of COSD

The Cyclic Online Subgradient Descent (COSD) generalizes MaxCOSD by allowing arbitrary learning rates and update periods. Recall that update periods are allowed to be dynamically defined, for this reason we will refer to a sequence of update periods \((t_{k})_{k\in\mathbb{N}}\) as an _update strategy_ which is formally defined below.

**Definition 18** (Update strategy).: An update strategy \((t_{k})_{k\in\mathbb{N}}\subset\mathbb{N}\) is a sequence of random variables such that, \(t_{1}=1\), \(t_{k}<t_{k+1}\) for every \(k\in\mathbb{N}\), and for every \(t\in\mathbb{N}\), \(k\in\mathbb{N}\), the event \(\{t_{k}=t\}\) is observable by the manager at the beginning of period \(t\), _i.e._ it belongs to \(\sigma(g_{1},x_{2},\dots,g_{t-1},x_{t})\).

The pseudo-code of COSD is given in Algorithm 3.

```
1Parameters: learning rates \((\eta_{t})_{t\in\mathbb{N}}\), update strategy \((t_{k})_{k\in\mathbb{N}}\) and \(y_{1}\in\mathcal{Y}\)
2Initialization
3 Set \(t_{1}=1\), \(k=1\) ;
4for\(t=1,2,\dots\)do
5 Output \(y_{t}\);
6 Observe \(g_{t}\in\partial\ell_{t}(y_{t})\) and \(x_{t+1}\);
7if\(t_{k+1}=t+1\)then
8 Set \(y_{t+1}=\operatorname{Proj}_{\mathcal{Y}}\Big{(}y_{t_{k}}-\eta_{t}\sum_{s=t_{k} }^{t}g_{s}\Big{)}\);
9 Set \(k=k+1\);
10
11else
12 Set \(y_{t+1}=y_{t}\); ```

**Algorithm 3**COSD

By choosing appropriately the update strategy we recover the following algorithms:

* **OSD.** If updates are made at every period, _i.e._\(t_{k}=k\), we recover OSD. Its feasibility is not guaranteed.
* **Minibatch OSD.** Given a fixed minibatch size \(\tau\in\mathbb{N}\), the updates period are defined offline via \(t_{k}=1+(k-1)\tau\).
* **CUP.** For every \(k\in\mathbb{N}\), \(t_{k}\) is defined as the periods where the inventory is empty, that is, \[t_{1}=1,\qquad t_{k+1}=\inf\{t\geq t_{k}+1:x_{t}\preceq\mathbf{0}\}\text{ for }k\in\mathbb{N}.\] (10) This update strategy corresponds to that used by CUP [32]. One easily sees that for such update periods \(t_{k}\), feasibility always holds.
* **MaxCOSD.** To recover MaxCOSD we define dynamically the update strategy as the periods where the candidate order-up-to levels \((\hat{y}_{t})_{t\in\mathbb{N}}\) are feasible. Formally, it writes: \[t_{1}=1,\qquad t_{k+1}=\inf\{t\geq t_{k}+1:x_{t}\preceq\hat{y}_{t}\}\text{ for }k\in\mathbb{N},\] (11)where \((\hat{y}_{t})_{t\in\mathbb{N}}\) is defined by:

\[\hat{y}_{1}=y_{1},\quad\hat{y}_{t+1}=\mathrm{Proj}_{\mathcal{Y}}\left(\hat{y}_{t_ {k}}-\eta_{t}\sum_{s=t_{k}}^{t}g_{s}\right),\] (12)

with \(k=\max\{j\geq 1:t_{j}\leq t\}\) or equivalently \(t\in\mathcal{T}_{k}=\{t_{k},\ldots,t_{k+1}-1\}\). Notice that at update periods the implemented order-up-to levels coincide with the candidate order-up-to level, that is, we have \(y_{t_{k}}=\hat{y}_{t_{k}}\) for all \(k\in\mathbb{N}\).

### Analysis of COSD and OSD

The following proposition summarizes the main properties of COSD. For convenience, we will use the notation \(\bar{t}_{k}:=t_{k+1}-1\) for the last period of the \(k^{th}\) cycle \(\mathcal{T}_{k}\).

**Proposition 19**.: _Let assumptions 2.i) and 2.ii) be satisfied. Given any update strategy and any sequence of learning rates \((\eta_{t})_{t\in\mathbb{N}}\) such that: \(0<\eta_{\bar{t}_{k+1}}\leq\eta_{\bar{t}_{k}}\) for all \(k\in\mathbb{N}\), COSD (see Algorithm 3) has the following properties:_

1. _it is feasible if and only if for all_ \(k\in\{2,3,\ldots\}\)_,_ \(y_{t_{k}}\succeq x_{t_{k}}\)_,_
2. _for all_ \(K\in\mathbb{N}\)_, the regret at the end of the_ \(K^{th}\) _cycle satisfies,_ \[R_{\bar{t}_{K}}\leq\frac{D^{2}}{2\eta_{\bar{t}_{K}}}+\frac{1}{2}\sum_{k=1}^{K }\eta_{\bar{t}_{k}}\left\|\sum_{t\in\mathcal{T}_{k}}g_{t}\right\|_{2}^{2}.\] (13)

Proof.: Let us prove claim i). By definition, the algorithm produces feasible sequence of order-up-to levels if \(y_{t}\succeq x_{t}\) for all \(t\in\mathbb{N}\). But for all \(t\in\{t_{k}+1,\ldots,\bar{t}_{k}\}\) for some \(k\in\mathbb{N}\), we have necessarily \(y_{t}=y_{t-1}\succeq\left[y_{t-1}-d_{t-1}\right]^{+}\succeq x_{t}\) where the last inequality comes from (2). Thus we only need to check feasibility at the update periods, _i.e._ check that \(y_{t_{k}}\succeq x_{t_{k}}\) for all \(k\in\mathbb{N}\). Furthermore, it is clear that the latter is verified for \(k=1\) since \(x_{t_{1}}=x_{1}=\bm{0}\preceq y_{t_{1}}\).

Now to prove the regret bound (claim ii)) we follow the lines of the classical analysis of OSD (see e.g. the proof of [8, Theorem 3.1] or that of [21, Theorem 2.13]) when run against the sequence of losses \((\sum_{t\in\mathcal{T}_{k}}\ell_{t})_{k\in\mathbb{N}}\) instead of \((\ell_{t})_{t\in\mathbb{N}}\). For convenience, we will write \(\tilde{g}_{k}=\sum_{t\in\mathcal{T}_{k}}g_{t}\) for all \(k\in\mathbb{N}\).

Let \(y\in\mathcal{Y},K\in\mathbb{N}\) and \(k\in[K]\), we start by bounding \(\sum_{t\in\mathcal{T}_{k}}\ell_{t}(y_{t})-\ell_{t}(y)\). By definition of the subgradient \(g_{t}\in\partial\ell_{t}(y_{t})\) we have:

\[\sum_{t\in\mathcal{T}_{k}}\ell_{t}(y_{t})-\ell_{t}(y)=\sum_{t\in\mathcal{T}_{k }}\ell_{t}(y_{t_{k}})-\ell_{t}(y)\leq\left\langle\tilde{g}_{k},y_{t_{k}}-y \right\rangle.\] (14)

We rewrite this bound as follows:

\[\left\langle\tilde{g}_{k},y_{t_{k}}-y\right\rangle=\frac{1}{2\eta_{\bar{t}_{k }}}\left(\left\|y_{t_{k}}-y\right\|_{2}^{2}+\eta_{t_{k}}^{2}\left\|\tilde{g}_{ k}\right\|_{2}^{2}-\left\|(y_{t_{k}}-y)-\eta_{\bar{t}_{k}}\tilde{g}_{k} \right\|_{2}^{2}\right).\]

By using the property of non-expansiveness of the Euclidean projection we have:

\[\left\|y_{t_{k+1}}-y\right\|_{2}^{2}=\left\|\mathrm{Proj}_{\mathcal{Y}}\left(y _{t_{k}}-\eta_{\bar{t}_{k}}\tilde{g}_{k}\right)-\mathrm{Proj}_{\mathcal{Y}}(y) \right\|_{2}^{2}\leq\left\|(y_{t_{k}}-\eta_{\bar{t}_{k}}\tilde{g}_{k})-y\right\| _{2}^{2}.\]

Combining the last two results leads to:

\[\left\langle\tilde{g}_{k},y_{t_{k}}-y\right\rangle\leq\frac{1}{2\eta_{\bar{t}_{ k}}}\left(\left\|y_{t_{k}}-y\right\|_{2}^{2}+\eta_{\bar{t}_{k}}^{2}\left\| \tilde{g}_{k}\right\|_{2}^{2}-\left\|y_{t_{k+1}}-y\right\|_{2}^{2}\right).\]Finally, we combine the last inequality with inequality (14) and sum these over \(k=1,\ldots,K\).

\[\sum_{t=1}^{i_{K}}\ell_{t}(y_{t})-\ell_{t}(y) \leq\sum_{k=1}^{K}\left\langle\tilde{g}_{k},y_{t_{k}}-y\right\rangle\] \[\leq\sum_{k=1}^{K}\frac{1}{2\eta_{\tilde{t}_{k}}}\left(\left\|y_{ t_{k}}-y\right\|_{2}^{2}-\left\|y_{t_{k+1}}-y\right\|_{2}^{2}\right)+\sum_{k=1}^{K} \frac{\eta_{\tilde{t}_{k}}}{2}\left\|\tilde{g}_{k}\right\|_{2}^{2}\] \[=\frac{1}{2}\left(\frac{\left\|y_{t_{1}}-y\right\|_{2}^{2}}{\eta _{\tilde{t}_{1}}}-\frac{\left\|y_{t_{K+1}}-y\right\|_{2}^{2}}{\eta_{\tilde{t} _{K}}}+\sum_{k=1}^{K-1}\left(\frac{1}{\eta_{\tilde{t}_{k+1}}}-\frac{1}{\eta_{ \tilde{t}_{k}}}\right)\left\|y_{t_{k+1}}-y\right\|_{2}^{2}\right)\] \[\qquad+\sum_{k=1}^{K}\frac{\eta_{\tilde{t}_{k}}}{2}\left\|\tilde{ g}_{k}\right\|_{2}^{2}\] \[\leq\frac{1}{2}\left(\frac{D^{2}}{\eta_{\tilde{t}_{1}}}+\sum_{k=1 }^{K-1}\left(\frac{1}{\eta_{\tilde{t}_{k+1}}}-\frac{1}{\eta_{\tilde{t}_{k}}} \right)D^{2}\right)+\sum_{k=1}^{K}\frac{\eta_{\tilde{t}_{k}}}{2}\left\|\tilde {g}_{k}\right\|_{2}^{2}\] \[=\frac{D^{2}}{2\eta_{\tilde{t}_{K}}}+\sum_{k=1}^{K}\frac{\eta_{ \tilde{t}_{k}}}{2}\left\|\tilde{g}_{k}\right\|_{2}^{2}.\]

Claim ii is thereby proved by taking the supremum over \(y\in\mathcal{Y}\). 

Proposition 19 gives us guidelines to design optimal update cycles and learning rates. First, this proposition states that it suffices to verify the feasibility constraint at the update periods to ensure that the whole sequence of order-up-to levels produced by COSD is feasible. On the other hand, to guarantee that this algorithm has a sublinear regret we will need to ensure that the cycles \(\mathcal{T}_{k}\) are not too long, _i.e._ that update periods are frequent enough, and then consider adequate learning rates.

Since OSD is an instance of COSD, we can recover classical regret bounds of OSD (see e.g. (8, Theorem 3.1) or (21, Theorem 2.13)) and in particular \(O(\sqrt{T})\) regret bounds, as a corollary of Proposition 19.

**Corollary 20**.: _Let assumptions 2.i) and 2.ii) be satisfied. Given positive non-increasing learning rates \((\eta_{t})_{t\in\mathbb{N}}\), i.e. \(0<\eta_{t+1}\leq\eta_{t}\) for all \(t\in\mathbb{N}\), the regret of OSD (see Algorithm 1) satisfies for all \(T\in\mathbb{N}\),_

\[R_{T}\leq\frac{D^{2}}{2\eta_{T}}+\sum_{t=1}^{T}\frac{\eta_{t}}{2}\left\|g_{t} \right\|_{2}^{2}.\]

_In particular, if \(\eta_{t}=\gamma D/(G\sqrt{t})\) with \(\gamma>0\), we have_

\[R_{T}\leq\left(\frac{1}{2\gamma}+\gamma\right)GD\sqrt{T}.\]

Proof.: The regret bound follows from claim ii) of Proposition 19. Indeed, by taking \(t_{k}=k\) for all \(k\in\mathbb{N}\), COSD coincide with OSD, thus, for \(K=\bar{t}_{K}=T\) we obtain the desired regret bound. 

### Controlling the cycles' length

In this subsection we analyze COSD with eventually unbounded cycles as it is the case for the CUP or the MaxCOSD update strategy. We start by introducing an assumption on the cycles called _geometric cycles_ which yields expected regret bounds and high probability regret bounds.

**Assumption 21** (Geometric cycles).: Let \(\mu\in(0,1]\). An update strategy \((t_{k})_{k\in\mathbb{N}}\) has \(\mu-\)_geometric cycles_ if there exists \(C_{\mu}\geq 1\) such that for any \(m\in\mathbb{N}\) and \(k\in\mathbb{N}\) we have:

\[\mathbb{P}\left[t_{k+1}-t_{k}>m\right]\leq C_{\mu}(1-\mu)^{m}.\] (15)

The name geometric cycles is motivated by the fact that if \(\xi\) is a geometric random variable with parameter \(\mu\), _i.e._\(\xi\in\mathbb{N}\) and \(\mathbb{P}\left[\xi>m\right]=(1-\mu)^{m}\) for all \(m\in\mathbb{N}\), then Assumption 21 rewrites:\(\mathbb{P}\left[t_{k+1}-t_{k}>m\right]\leq C_{\mu}\mathbb{P}\left[\xi>m\right]\) for all \(k,m\in\mathbb{N}\). This property resembles sub-exponential concentration [29, Section 2.7]. This notion was inspired from a proof in [32] where the authors observe, under their assumptions, that CUP's cycles length are geometrically distributed with a parameter lower bounded by \(\mu\). Assumption 21 generalizes this property.

The following proposition summarizes some important properties of geometric cycles.

**Proposition 22**.: _Consider an update strategy \((t_{k})_{k\in\mathbb{N}}\) with \(\mu-\)geometric cycles (see Assumption 21), then,_

* _For all_ \(k\in\mathbb{N}\)_,_ \(\mathbb{E}\left[t_{k+1}-t_{k}\right]\leq C_{\mu}/\mu\) _and_ \(\mathbb{E}\left[(t_{k+1}-t_{k})^{2}\right]\leq C_{\mu}(2-\mu)/\mu^{2}\leq 2C_{ \mu}/\mu^{2}\)_._
* _For all_ \(K\in\mathbb{N}\) _and any confidence level_ \(\delta\in(0,1)\) _we have with probability at least_ \(1-\delta\)_,_ \[\sqrt{\sum_{k=1}^{K}(t_{k+1}-t_{k})^{2}}\leq\left(1+\frac{\log(KC_{\mu}/\delta )}{\mu}\right)\sqrt{K}.\]

Proof.: First, let us observe that if \(\mu=1\) in Assumption 21 then, \(t_{k}=k\) for all \(k\in\mathbb{N}\) and one can easily check that all the claims are indeed verified. In the following we assume \(\mu\in(0,1)\).

Let \(\xi\) be a geometric random variable of parameter \(\mu\), that is, \(\xi\in\mathbb{N}\) and \(\mathbb{P}\left[\xi>m\right]=(1-\mu)^{m}\) for all \(m\in\mathbb{N}\). Then, it is well-known that \(\mathbb{E}\left[\xi\right]=1/\mu\) and \(\mathbb{E}\left[\xi^{2}\right]=(2-\mu)/\mu^{2}\).

We now prove the first claim by means of direct computations. For all \(k\in\mathbb{N}\), we have:

\[\mathbb{E}\left[t_{k+1}-t_{k}\right]=\sum_{m=0}^{+\infty}\mathbb{P}\left[t_{k+ 1}-t_{k}>m\right]\leq\sum_{m=0}^{+\infty}C_{\mu}\mathbb{P}\left[\xi>m\right]= C_{\mu}\mathbb{E}\left[\xi\right]=\frac{C_{\mu}}{\mu}.\]

Also, using the fact that for any integer \(a\) and real number \(b\), we have, \(a>b\) if and only if \(a>\left\lfloor b\right\rfloor\), we can upper bound \(\mathbb{E}\left[(t_{k+1}-t_{k})^{2}\right]\) as follows:

\[\mathbb{E}\left[(t_{k+1}-t_{k})^{2}\right] =\sum_{m=0}^{+\infty}\mathbb{P}\left[(t_{k+1}-t_{k})>\sqrt{m} \right]=\sum_{m=0}^{+\infty}\mathbb{P}\left[(t_{k+1}-t_{k})>\lfloor\sqrt{m} \rfloor\right]\] \[\leq\sum_{m=0}^{+\infty}C_{\mu}\mathbb{P}\left[\xi>\lfloor\sqrt{ m}\rfloor\right]=C_{\mu}\mathbb{E}\left[\xi^{2}\right]=C_{\mu}\frac{2-\mu}{\mu^{2}} \leq\frac{2C_{\mu}}{\mu^{2}}.\]

Finally, let us prove the second claim. Let \(K\in\mathbb{N}\) and \(\varepsilon>0\), it is classical to see that:

\[\mathbb{P}\left[\sqrt{\sum_{k=1}^{K}(t_{k+1}-t_{k})^{2}}>\varepsilon\right] \leq\mathbb{P}\left[\exists k\in[K],\;(t_{k+1}-t_{k})^{2}> \varepsilon^{2}/K\right]\] \[\leq\sum_{k=1}^{K}\mathbb{P}\left[(t_{k+1}-t_{k})>\lfloor \varepsilon/\sqrt{K}\rfloor\right].\]

We use Assumption 21, which yields:

\[\mathbb{P}\left[\sqrt{\sum_{k=1}^{K}(t_{k+1}-t_{k})^{2}}>\varepsilon\right] \leq KC_{\mu}(1-\mu)^{\lfloor\varepsilon/\sqrt{K}\rfloor}\leq KC_{\mu}(1-\mu) ^{(\varepsilon/\sqrt{K})-1}.\]

Now for \(\delta\in(0,1)\) we plug \(\varepsilon=\left(1+\frac{\log(\delta/(KC_{\mu}))}{\log(1-\mu)}\right)\sqrt{K}>0\) in the last result, to obtain:

\[\sqrt{\sum_{k=1}^{K}(t_{k+1}-t_{k})^{2}}\leq\left(1+\frac{\log(\delta/(KC_{\mu }))}{\log(1-\mu)}\right)\sqrt{K},\]

with probability at least \(1-\delta\). We conclude by simply observing that \(-1/\log(1-\mu)\leq 1/\mu\)Using these tools, we are now ready to provide strong regret bounds for COSD under the assumption of geometric cycles. We are going from now on to focus on adaptive learning rates (see Eq. 7) which will allow us to unlock high probability regret bounds.

**Corollary 23**.: _Consider an inventory problem satisfying Assumption 2 and COSD (see Algorithm 3) with adaptive learning rates (see Eq. (7)) and an update strategy with \(\mu-\)geometric cycles (see Assumption 21), then, the following regret bounds hold for all \(T\in\mathbb{N}\),_

\[\mathbb{E}\left[R_{T}\right]\leq\frac{\sqrt{2C_{\mu}}}{\mu}DG\left(\frac{1}{2 \gamma}+\gamma+1\right)\sqrt{T},\]

_and for any confidence level \(\delta\in(0,1)\) we have with probability at least \(1-\delta\),_

\[R_{T}\leq DG\left(\frac{1}{2\gamma}+\gamma+1\right)\left(1+\frac{1}{\mu}\log \left(\frac{TC_{\mu}}{\delta}\right)\right)\sqrt{T}.\]

_Finally, COSD is feasible if and only if for all \(k\in\{2,3,\ldots\}\), \(y_{t_{k}}\succeq x_{t_{k}}\)._

Proof.: Let \(T\in\mathbb{N}\) and \(K=\min\{k\geq 1,t_{k}\leq T\}\). We start by bounding the regret \(R_{T}\) in terms of the regret at the end of \(K-1^{th}\) cycle \(R_{\tilde{t}_{K-1}}=R_{t_{K}-1}\) and a remainder term as follows:

\[R_{T}\leq R_{\tilde{t}_{K-1}}+\sup_{y\in\mathcal{Y}}\sum_{t=t_{K}}^{T}\ell_{t} (y_{t})-\ell_{t}(y)\leq R_{\tilde{t}_{K-1}}+\sup_{y\in\mathcal{Y}}\sum_{t=t_{K }}^{T}\left\langle g_{t},y_{t}-y\right\rangle.\]

where we used \(g_{t}\in\partial\ell_{t}(y_{t})\). Applying Cauchy-Schwartz inequality, Assumption 2 and \(T\leq t_{K+1}-1\) leads us to:

\[R_{T}\leq R_{\tilde{t}_{K-1}}+DG(t_{K+1}-t_{K}).\] (16)

Let us now bound \(R_{\tilde{t}_{K-1}}\). As a consequence of claim ii) of Proposition 19 and after substituting \(\eta_{t}\) by its value and applying Lemma 25 provided in Appendix B to \(f(x)=1/(2\sqrt{x})\), \(a_{0}=0\) and \(a_{k}=\left\|\sum_{t\in\mathcal{T}_{k}}g_{t}\right\|_{2}^{2}\) for \(k\in[K-1]\) we obtain:

\[R_{\tilde{t}_{K-1}}\leq D\left(\frac{1}{2\gamma}+\gamma\right)\sqrt{\sum_{k= 1}^{K-1}\left\|\sum_{t\in\mathcal{T}_{k}}g_{t}\right\|_{2}^{2}}\leq DG\left( \frac{1}{2\gamma}+\gamma\right)\sqrt{\sum_{k=1}^{K-1}(t_{k+1}-t_{k})^{2}}.\]

Combining this with inequality (16) leads us to:

\[R_{T} \leq DG\left(\left(\frac{1}{2\gamma}+\gamma\right)\sqrt{\sum_{k= 1}^{K-1}(t_{k+1}-t_{k})^{2}}+(t_{K+1}-t_{K})\right)\] \[\leq DG\left(\frac{1}{2\gamma}+\gamma+1\right)\sqrt{\sum_{k=1}^{K }(t_{k+1}-t_{k})^{2}}.\]

To obtain the expected regret bound, we start by noticing that \(K\leq T\) then taking the expectation in this last inequality, applying Jensen's inequality, then, Proposition 22 that bounds \(\mathbb{E}\left[(t_{k+1}-t_{k})^{2}\right]\leq 2C_{\mu}/\mu^{2}\) we end up with the desired bound. Finally, to obtain the high probability regret bound, we notice again that \(K\leq T\) and then apply the high probability bound of Proposition 22. 

### Proof of Theorem 12

In the following lemma we claim that under the assumptions of Theorem 12, MaxCOSD with the appropriate learning rates has geometric cycles (see Assumption 21).

**Lemma 24**.: _Consider an inventory problem and let assumptions 2, 10 and 11 hold. Then, MaxCOSD with learning rates defined in Eq. (7) and \(\gamma\in(0,\rho/D]\) has \(\mu-\)geometric cycles with \(C_{\mu}=1\)._

Proof.: First, notice that if \(\min_{i\in[n]}d_{t,i}\geq\rho\) then \(x_{t+1}\preceq\hat{y}_{t+1}\), i.e. \(t+1\) is an update period for MaxCOSD. This is a consequence of Lemma 15, which applies since we have:

\[\left\|\hat{y}_{t+1}-y_{t}\right\|=\left\|\mathrm{Proj}_{\mathcal{Y}}\left( \hat{y}_{t_{k}}-\eta_{t}\sum_{s=t_{k}}^{t}g_{s}\right)-\hat{y}_{t_{k}}\right\| \leq\eta_{t}\left\|\sum_{s=t_{k}}^{t}g_{s}\right\|_{2}\leq\gamma D\leq\rho\leq \min_{i\in[n]}d_{t,i}.\]Now let \(k\in\mathbb{N}\) and \(m\in\mathbb{N}\). Using this initial observation we have:

\[\mathbb{P}\left[t_{k+1}-t_{k}>m\right] =\mathbb{P}\left[x_{t_{k}+1}\ngeq\hat{y}_{t_{k}+1},\ldots,x_{t_{k}+ m}\ngeq\hat{y}_{t_{k}+m}\right]\] \[\leq\mathbb{P}\left[\min_{i\in[n]}d_{t_{k},i}<\rho,\ldots,\min_{i \in[n]}d_{t_{k}+m-1,i}<\rho\right]\] \[=\sum_{s\geq 1}\mathbb{P}\left[t_{k}=s,\;\min_{i\in[n]}d_{s,i}< \rho,\;\ldots,\;\min_{i\in[n]}d_{s+m-1,i}<\rho\right]\]

The last step of this proof is showing that in fact,

\[\mathbb{P}\left[t_{k}=s,\;\min_{i\in[n]}d_{s,i}<\rho,\;\ldots,\;\min_{i\in[n]} d_{s+m-1,i}<\rho\right]\leq\mathbb{P}\left[t_{k}=s\right](1-\mu)^{m}.\] (17)

We prove this by a simple induction over \(m\geq 1\). Noticing that \(\{t_{k}=s\}\in\sigma(g_{1},x_{2},\ldots,g_{s-1},x_{s})\subset\sigma(\ell_{1}, d_{1},\ldots,\ell_{s-1},d_{s-1})\), where the last inclusion comes from Assumption 11, and using the basic properties of conditional expectations we derive the inequality for \(m=1\):

\[\mathbb{P}\left[t_{k}=s,\;\min_{i\in[n]}d_{s,i}<\rho\right] =\mathbb{E}\left[\mathbb{P}\left[t_{k}=s,\;\min_{i\in[n]}d_{s,i}< \rho|\ell_{1},d_{1},\ldots,\ell_{s-1},d_{s-1}\right]\right]\] \[=\mathbb{E}\left[\mathds{1}_{\{t_{k}=s\}}\mathbb{P}\left[\min_{i \in[n]}d_{s,i}<\rho|\ell_{1},d_{1},\ldots,\ell_{s-1},d_{s-1}\right]\right]\] \[\leq\mathbb{P}\left[t_{k}=s\right](1-\mu),\]

where the last inequality comes from Assumption 10. Assume now the relation (17) holds for \(m\), let us prove in a similar way that it holds for \(m+1\).

\[\mathbb{P}\left[t_{k}=s,\;\min_{i\in[n]}d_{s,i}<\rho,\;\ldots,\; \min_{i\in[n]}d_{s+m,i}<\rho\right]\] \[=\mathbb{E}\left[\mathbb{P}\left[t_{k}=s,\;\min_{i\in[n]}d_{s,i}< \rho,\;\ldots,\;\min_{i\in[n]}d_{s+m,i}<\rho|\ell_{1},d_{1},\ldots,\ell_{s+m-1 },d_{s+m-1}\right]\right]\] \[=\mathbb{E}\left[\mathds{1}_{\{t_{k}=s\}}\mathds{1}_{\{i\in[n] \leavevmode\nobreak\ \mathaccent 0{\cdot}i\in[n]\leavevmode\nobreak\ \mathaccent 0{\cdot}i\in[n]\leavevmode\nobreak\ \mathaccent 0{\cdot}i\in[n]\leavevmode\nobreak\ \mathaccent 0{\cdot}i\in[n]\leavevmode\nobreak\ \mathaccent 0{\cdot}d_{s+m-1,i}<\rho\}}\mathbb{P}\left[\min_{i\in[n]}d_{s+m,i}<\rho| \ell_{1},d_{1},\ldots,\ell_{s+m-1},d_{s+m-1}\right]\right]\] \[\leq\mathbb{P}\left[t_{k}=s,\;\min_{i\in[n]}d_{s,i}<\rho,\;\ldots,\;\min_{i\in[n]}d_{s+m-1,i}<\rho\right](1-\mu)\] \[\leq\mathbb{P}\left[t_{k}=s\right](1-\mu)^{m+1}.\]

Summing the relations (17) over \(s\geq 1\) leads to the final bound: \(\mathbb{P}\left[t_{k+1}-t_{k}>m\right]\leq(1-\mu)^{m}\), which is our claim. 

We are now ready to prove Theorem 12.

Proof of Theorem 12.: By definition, MaxCOSD is always feasible (independently of the learning rates chosen). Lemma 24 ensures that when \(\gamma\in(0,\rho/D]\), MaxCOSD with adaptive learning rates as defined in Eq. (7) has \(\mu-\)geometric cycles with \(C_{\mu}=1\). Thus, Corollary 23 applies and leads to the regret bounds we claimed. 

## Appendix B Other lemmas

**Lemma 25** (Lemma 4.13 of [21]).: _Let \(a_{0},a_{1},\ldots,a_{K}\) be non-negative numbers and \(f:\mathbb{R}_{+}\rightarrow\mathbb{R}_{+}\) a measurable non-increasing function, we have:_

\[\sum_{k=1}^{K}a_{k}f\left(a_{0}+\sum_{m=1}^{k}a_{m}\right)\leq\int_{a_{0}}^{ \sum_{k=0}^{K}a_{k}}f(x)dx.\]Proof.: Define \(s_{k}=\sum_{m=0}^{k}a_{m}\). The following holds for all \(k\in[K]\),

\[a_{k}f\left(a_{0}+\sum_{m=1}^{k}a_{m}\right)=a_{k}f(s_{k})=\int_{s_{k-1}}^{s_{k} }f(s_{k})dx\leq\int_{s_{k-1}}^{s_{k}}f(x)dx.\]

Summing over \(k=1,\ldots,K\) leads to the desired bound. 

**Lemma 26**.: _Consider an inventory problem with non-negative feasible set \(\mathcal{Y}\subset\mathbb{R}_{+}^{n}\). Then, any non-decreasing sequence of order-up-to levels \((y_{t})_{t\in\mathbb{N}}\subset\mathcal{Y}\) (i.e. such that \(y_{t}\preceq y_{t+1}\) for all \(t\in\mathbb{N}\)) is feasible. In particular, constant strategies are feasible too._

Proof.: Consider a non-decreasing sequence of order-up-to levels \((y_{t})_{t\in\mathbb{N}}\subset\mathcal{Y}\subset\mathbb{R}_{+}^{n}\). First of all, \(y_{1}\) is feasible since we impose \(x_{1}=\mathbf{0}\) and \(y_{1}\in\mathbb{R}_{+}^{n}\). Then, for every \(t\in\mathbb{N}\), we can write:

\[y_{t+1}\succeq y_{t}\succeq[y_{t}-d_{t}]^{+}\succeq x_{t+1}.\]

The first inequality comes from the assumption that \((y_{t})_{t\in\mathbb{N}}\) is non-decreasing, the second one from the monotonicity of the positive part and the fact that \(y_{t}\in\mathbb{R}_{+}^{n}\), finally, the last inequality is the inventory dynamical constraint. Thus, the whole strategy \((y_{t})_{t\in\mathbb{N}}\) is feasible. 

**Lemma 27**.: _Consider an inventory problem that satisfies Assumption 2, then, the regret of any algorithm is bounded as follows:_

\[R_{T}\leq DGT.\]

Proof.: Let \(y\in\mathcal{Y}\). For all \(t\in\mathbb{N}\), we have:

\[\ell_{t}(y_{t})-\ell_{t}(y)\leq\left\langle g_{t},y_{t}-y\right\rangle\leq \left\|g_{t}\right\|_{2}\left\|y_{t}-y\right\|_{2}\leq GD,\]

where we used the definition of the subgradient \(g_{t}\in\partial\ell_{t}(y_{t})\), then, Cauchy-Schwartz inequality and finally Assumption 2. Summing these inequalities over \(t=1,\ldots,T\) and taking the supremum over \(y\in\mathcal{Y}\) leads to the desired bound. 

**Lemma 28**.: _Consider the newsvendor cost function \(c\) defined in (5). Let \(d\in\mathbb{R}^{n}\). A vector \(g\in\mathbb{R}^{n}\) is a subgradient of the function of \(c(\cdot,d)\) at \(y\in\mathbb{R}^{n}\) if and only if for all \(i\in[n]\) we have:_

\[g_{i}\in\begin{cases}\{h_{i}\},&\text{if }y_{i}>d_{i}\\ [-p_{i},h_{i}],&\text{if }y_{i}=d_{i}\\ \{-p_{i}\},&\text{if }y_{i}<d_{i}.\end{cases}\]

_In particular, denoting \(s=\min\{y,d\}\), the vector \((h_{i}\mathds{1}_{\{y_{i}>s_{i}\}}-p_{i}\mathds{1}_{\{y_{i}=s_{i}\}})_{i\in[n]}\) is a subgradient of \(c(\cdot,d)\) at \(y\)._

## Appendix C Postponed proofs

### Proof of Proposition 13

Proof of Proposition 13.: Formally, in the lost sales single-product newsvendor setting with observable demand over \(\mathcal{Y}=[0,D]\), a feasible deterministic algorithm is defined by a sequence of functions \((Y_{t})_{t\in\mathbb{N}}\) of the form \(Y_{t}:\mathbb{R}_{+}^{t-1}\to[0,D]\) satisfying \(Y_{t+1}(d_{1},\ldots,d_{t})\geq\left[Y_{t}(d_{1},\ldots,d_{t-1})-d_{t}\right] ^{+}\) for all \(d_{1},\ldots,d_{t}\in\mathbb{R}_{+}\).

Let \(\tilde{d}\in(0,D]\), and consider a constant demand sequence defined by \(\tilde{d}_{t}:=\tilde{d}\) at every period \(t\in\mathbb{N}\). Consider now \((\tilde{y}_{t})_{t\in\mathbb{N}}\) the sequence of order-up-to levels generated by this algorithm when facing this constant demand, that is, \(\tilde{y}_{t}:=Y_{t}(\tilde{d},\ldots,\tilde{d})\). We will now distinguish two cases.

1. Consider the case where \(\tilde{y}_{t}=0\) for all \(t\in\mathbb{N}\). Taking \(y=\tilde{d}\) in the regret definition (3) yields: \[R_{T}\geq\sum_{t=1}^{T}c(0,\tilde{d})-\sum_{t=1}^{T}c(\tilde{d},\tilde{d})=Tp \tilde{d}=\Omega(T).\]2. Now, consider the case where there exists \(T_{0}\geq 1\) such that \(\tilde{y}_{1}=\cdots=\tilde{y}_{T_{0}-1}=0\) and \(\tilde{y}_{T_{0}}>0\). Consider a new demand sequence \((d_{t})_{t\in\mathbb{N}}\) defined as follows: \(d_{1}=\cdots=d_{T_{0}-1}=\bar{d}\) and \(d_{t}=0\) for \(t\geq T_{0}\). Denote by \((y_{t})_{t\in\mathbb{N}}\) the sequence of order-up-to levels generated by the algorithm against the demand sequence \((d_{t})_{t\in\mathbb{N}}\), that is, \(y_{t}=Y_{t}(d_{1},\ldots,d_{t-1})\). Since the algorithm is deterministic, we also have: \(y_{t}=0\) for \(t\leq T_{0}-1\). Indeed, we have, \(y_{t}=Y_{t}(d_{1},\ldots,d_{t-1})=Y_{t}(\tilde{d},\ldots,\tilde{d})=\tilde{y} _{t}=0\). On the other hand, we have for all \(t\geq T_{0}+1\), \(y_{t}\geq\left[y_{t-1}-d_{t-1}\right]^{+}=y_{t-1}\), thus, \(y_{t}\geq y_{T_{0}}=\tilde{y}_{T_{0}}>0\) for all \(t\geq T_{0}\). Taking \(y=0\) in the regret definition (3) we obtain for \(T\geq T_{0}\), \[R_{T}\geq\sum_{t=1}^{T}c(y_{t},d_{t})-c(0,d_{t})=\sum_{t=T_{0}}^{T}c(y_{t},0)= \sum_{t=T_{0}}^{T}hy_{t}\geq(T-T_{0}+1)h\tilde{y}_{T_{0}}=\Omega(T).\]

### Proof of Proposition 14

Proof of Proposition 14.: Take \((d_{t})_{t\in\mathbb{N}}\subset\mathbb{R}_{++}\) such that \(\sum_{t=1}^{\infty}d_{t}<y_{1}\) and define \(C=y_{1}-\sum_{t=1}^{\infty}d_{t}>0\). Notice that due to the feasibility constraint (1) and the lost sales dynamic we have for all \(t\in\mathbb{N}\), \(y_{t+1}\geq x_{t+1}=\left[y_{t}-d_{t}\right]^{+}\geq y_{t}-d_{t}\). Thus, we have for every \(t\in\mathbb{N}\), \(y_{t}=y_{1}+\sum_{s=1}^{t-1}(y_{s+1}-y_{s})\geq y_{1}-\sum_{s=1}^{t-1}d_{s}\geq C\). Now take the losses \(\ell_{t}(y)=y\), then, \(R_{T}=\sum_{t=1}^{T}y_{t}\geq CT\) for all \(T\in\mathbb{N}\). 

### Proof of Lemma 15

Proof of Lemma 15.: Since \(\left[y-d\right]^{+}=\max\{y-d,0\}\) and \(y^{\prime}\succeq 0\), it is enough to show that \(y^{\prime}\succeq y-d\). The latter holds since, for any \(i\in[n]\), we have \(y_{i}-y_{i}^{\prime}\leq\left\|y^{\prime}-y\right\|_{2}\leq\min_{i\in[n]}d_{i} \leq d_{i}\). 

### Proof of Theorem 17

Proof of Theorem 17.: The regret bound follows from the classical analysis of OSD, see our Corollary 20 or the proof of [8, Theorem 3.1]. Thus, we only need to show the feasibility. For all \(t\in\mathbb{N}\), we have,

\[\left\|y_{t+1}-y_{t}\right\|_{2}=\left\|\operatorname{Proj}_{\mathcal{Y}}(y_{t }-\eta_{t}g_{t})-y_{t}\right\|_{2}\leq\eta_{t}\left\|g_{t}\right\|_{2}=\frac{ \gamma D}{G\sqrt{t}}\left\|g_{t}\right\|_{2}\leq\frac{\rho}{\sqrt{t}}\leq\rho,\] (18)

the first inequality is provided by the property of non-expansiveness of the Euclidean projection, the second inequality comes from \(\gamma\leq\rho/D\) and \(\left\|g_{t}\right\|_{2}\leq G\), and the last inequality from \(\sqrt{t}\geq 1\). Combining this result with Assumption 16, we obtain \(\left\|y_{t+1}-y_{t}\right\|_{2}\leq\min_{i\in[n]}d_{t,i}\). According to Lemma 15 and the inventory dynamical constraint (2) this guarantees feasibility. 

## Appendix D Discussion

### On the relation between Online Inventory Optimization and Online Convex Optimization

In the usual Online Convex Optimization (OCO) framework introduced by [36] a decision-maker and an environment interact as follows: at every time period \(t\in\mathbb{N}\), first, the decision-maker chooses a decision \(y_{t}\in\mathcal{Y}\) and the environment chooses a loss function \(\ell_{t}\), then, the decision-maker receive some feedback which usually consist of either the loss function itself \(\ell_{t}\) (full-information setting), the loss incurred \(\ell_{t}(y_{t})\) (bandit setting) or a subgradient \(g_{t}\in\partial\ell_{t}(y_{t})\) (first-order feedback setting). The goal of the decision-maker is to minimize its cumulative loss incurred \(\sum_{t=1}^{T}\ell_{t}(y_{t})\).

OIO extend the OCO framework by adding the feasibility constraint (1). A naive solution to accommodate such constraints into the OCO framework is by adding to the losses the convex indicator of the feasibility constraint, that is, by considering the losses \(\tilde{\ell}_{t}(y)=\ell_{t}(y)+\chi_{t}(y)\), where \(\chi_{t}(y)\) takes the value \(0\) if \(y\succeq x_{t}\) holds and \(+\infty\) otherwise. However, this is not satisfactory since by doing so we also alter the regret (3) by imposing on the competitor \(y\in\mathcal{Y}\) the feasibility constraints associated to the algorithm.

Many extensions of the OCO framework have been developed over the years. Of particular interest, those which include constraints of different forms like:

* _OCO with long-term constraints_[16, 11], where \(m\) convex constraints of the form \(f_{i}(\cdot)\leq 0\) for \(i\in[m]\) should be satisfied in the long run, that is, the goal is to minimize the cumulative loss while keeping low constraint violation \(\sum_{t=1}^{T}f_{i}(y_{t})\) for each \(i\in[m]\).
* _OCO with long-term and time-varying constraints_[20, 14] which compared to the previous extension, considers time-varying convex constraints of the form \(f_{t,i}(\cdot)\leq 0\) where \(f_{t,i}\) is revealed at the _end_ of time period \(t\). Even as long-term constraints, this learning task is known to be unsolvable in general (see e.g. [28, Proposition 2.1] or [18, Proposition 4] for more precise statement), thus, restricted notions of regret have been considered in this context.
* _OCO with ramp constraints_[2], where at each time period \(t\in\{2,3,\dots\}\) the decision-maker should choose \(y_{t}\in\mathcal{Y}\) such that \(|y_{t,i}-y_{t-1,i}|\leq\kappa_{i}\) for all \(i\in[n]\).

We argue that OIO problems are different from these extensions. Indeed, our feasibility constraints (1) are neither long-term constraint since we do not allow for violations, nor ramp constraints since the bounds are time-varying. Also, our task is further challenging since we aim at bounding the regret (3) based on a competitor \(y\in\mathcal{Y}\) which does not suffer from the feasibility constraint (1).

### On the notion of pseudo-regret

There exists an alternative notion of regret we call the _pseudo-regret_\(\bar{R}_{T}\) which is in fact more common in the literature of online inventory problems [9, 3, 25, 32]. It is defined as the difference between the expected cumulative loss of the algorithm and that of the best fixed constant strategy, that is, formally

\[\bar{R}_{T}=\mathbb{E}\left[\sum_{t=1}^{T}\ell_{t}(y_{t})\right]-\inf_{y\in \mathcal{Y}}\mathbb{E}\left[\sum_{t=1}^{T}\ell_{t}(y)\right].\]

The difference between the expected regret \(\mathbb{E}\left[R_{T}\right]\) and the pseudo-regret \(\bar{R}_{T}\) is in the competitor \(y\). In the former, the competitor is random and depends on the realization of the losses, whereas, in the latter the competitor is fixed and depends only on the distribution of the losses. Notice that we always have \(\bar{R}_{T}\leq\mathbb{E}\left[R_{T}\right]\), thus, an upper bound obtained on the expected regret applies directly to the pseudo-regret.