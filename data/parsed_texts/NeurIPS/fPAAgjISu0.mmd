# In Defense of Softmax Parametrization for Calibrated and Consistent Learning to Defer

Yuzhou Cao\({}^{1}\)  Hussein Mozannar\({}^{2}\)  Lei Feng\({}^{1}\)

\({}^{1}\)School of Computer Science and Engineering, Nanyang Technological University, Singapore

\({}^{2}\)CSAIL and IDSS, Massachusetts Institute of Technology, Cambridge, MA

\({}^{3}\)Department of Statistics and Data Science, Southern University of Science and Technology, China

yuzhou002@e.ntu.edu.sg, mozannar@mit.edu

lfengqaq@gmail.com, weihx@sustech.edu.cn, boan@ntu.edu.sg

Corresponding author: Lei Feng.

###### Abstract

Enabling machine learning classifiers to defer their decision to a downstream expert when the expert is more accurate will ensure improved safety and performance. This objective can be achieved with the learning-to-defer framework which aims to jointly learn how to classify and how to defer to the expert. In recent studies, it has been theoretically shown that popular estimators for learning to defer parameterized with softmax provide unbounded estimates for the likelihood of deferring which makes them uncalibrated. However, it remains unknown whether this is due to the widely used softmax parameterization and if we can find a softmax-based estimator that is both statistically consistent and possesses a valid probability estimator. In this work, we first show that the cause of the miscalibrated and unbounded estimator in prior literature is due to the symmetric nature of the surrogate losses used and not due to softmax. We then propose a novel statistically consistent asymmetric softmax-based surrogate loss that can produce valid estimates without the issue of unboundedness. We further analyze the non-asymptotic properties of our method and empirically validate its performance and calibration on benchmark datasets.

## 1 Introduction

As machine learning models get deployed in risk-critical tasks such as autonomous driving [18], content moderation [27], and medical diagnosis [20], we have a higher urgency to prevent incorrect predictions. To enable a safer and more accurate system, one solution is to allow the model to defer to a downstream human expert when necessary. The **L**earning to **D**efer (L2D) paradigm achieves this aim [28; 30; 31; 9; 44; 32; 33; 45; 3; 35; 15; 42] and enables models to defer to an expert, i.e., abstain from giving a prediction and request a downstream expert for an answer when needed. L2D aims to train an augmented classifier that can choose to defer to an expert when the expert is more accurate or make a prediction without the expert. L2D can be formulated as a risk-minimization problem that minimizes the 0-1-deferral risk [30], which incurs a cost of one when the classifier is incorrect or when we defer to an expert who errs and incurs a cost of zero otherwise.

Despite being formulated straightforwardly, the risk minimization problem is NP-hard even in simple settings [15; 32] due to the discontinuous and non-convex nature of the 0-1-deferral loss. To make the optimization problem tractable, many efforts have been made to design a continuous surrogate loss for the 0-1-deferral loss while guaranteeing statistical consistency, which means that the minimizer of the surrogate risk is that of the 0-1-deferral risk. In Mozannar and Sontag [30], a cross-entropy-likesurrogate loss is proposed that is statistically consistent. Charusaie et al. [9] further generalized the results in Mozannar and Sontag [30] and showed that all the losses that are consistent for ordinary multi-class classification, i.e., classification-calibrated [38; 43; 6], are consistent for L2D with certain reformulation, which makes L2D a more comprehensive framework. By minimizing the risk _w.r.t._ consistent surrogate losses [30; 9], we can obtain a model that defers to who between the classifier and expert is more accurate on an instance basis. However, we also need assessments of the uncertainty of the classifier when it predicts and the uncertainty of the expert prediction when we defer. This allows us to perform better triaging of samples and provide reliable estimates of uncertainty. Verma and Nalisnick [44] pointed out that the previous estimator in [30] generates highly biased probability estimates for the predictions due to its unboundedness. They then proposed a surrogate based on the One-versus-All (OvA) strategy [52] to alleviate this problem, which allows both statistical consistency and improved calibration compared to the previous softmax-based method [30].

Does the difference in performance between OvA and softmax-based methods indicate that softmax parameterization is a sub-optimal choice in L2D? The cause of the unbounded probability estimation in [30] is in fact still elusive, and we cannot simply attribute it to softmax parameterization. Furthermore, notice that the softmax-based method [30] is only a specific implementation of applying softmax in L2D. Meanwhile, softmax parameterization is also a more straightforward modeling of multiclass posterior distributions: while the OvA strategy works by splitting a \(K\)-class classification problem into \(K\) independent binary classification problems and thus induces \(K\) uncorrelated probability estimators for each class, softmax parameterization works by directly estimating class posterior probabilities as a whole. Given the wide use and practical advantages of softmax parameterization in classification tasks and the resemblance between L2D and multiclass classification, it is also promising that the usage of the softmax function can result in competitive methods for L2D. Then a natural question arises: can we design a softmax-based consistent surrogate loss for L2D without triggering unbounded probability estimation enabling calibrated estimates?

In this paper, we give a positive answer to this question by providing a novel consistent surrogate loss with _asymmetric softmax parameterization_, which can be seen as the combination of ordinary softmax function and an additional probability estimator. This surrogate can also induce a non-trivial bounded probability estimator for prediction probabilities and expert accuracy. To defend the use of softmax parameterization, we show that it is not the cause of the failure but rather it is the symmetric structure of the surrogates that leads to the unboundedness in probability estimation. Unlike the unbounded estimator [30] that mixes up class probabilities and the expert's accuracy and the OvA estimator that treats each class and expert independently, our method models the class probabilities as a whole with softmax and the expert's accuracy independently with a normalized function, which better reflects the structure of L2D with probability estimation. The differences between our work and previous works are illustrated in Figure 1. We further analyze the limitation and broader impact of our work in Appendix G. Our contributions are four-fold and summarized below:

* In Section 3, we prove that a non-trivial bounded probability estimator does not exist as long as we are using _symmetric_ loss functions.
* We propose an asymmetric formulation of softmax parameterization, and show that it can induce both a consistent surrogate loss and a non-trivial bounded probability estimator. We further show that the proposed asymmetric softmax-based method and OvA-based method [44] actually benefit from their asymmetric structure.

Figure 1: Illustration of the proposed and previous estimators. Probability estimation in L2D aims to predict both the class probabilities and the expert’s accuracy \(\boldsymbol{\eta}\times\Pr(M=Y|X=\boldsymbol{x})\in\Delta^{K}\times[0,1]\), while only our proposed estimator takes exactly the same range.

* We further study the regret transfer bounds of our proposed asymmetric surrogate and show that it is compatible with both L2D and multi-class classification.
* Experiments on datasets with both synthetic experts and real-world experts are conducted to demonstrate the usefulness of our method for both prediction and expert accuracy estimation.

## 2 Preliminaries

In this section, we review the problem setting of L2D and briefly introduce previous works.

### Problem Setting

In this paper, we study the problem of learning to defer to an expert in the \(K\)-class classification scenario. Let us denote by \(\mathcal{X}\) and \(\mathcal{Y}=\{1,\cdots,K\}\) the feature and label space respectively. Denote by \(X\!\times\!Y\!\times\!M\in\mathcal{X}\!\times\!\mathcal{Y}\times\mathcal{Y}\) the data-label-expert random variable triplet and \(\bm{x},y,m\) are their realizations, which obeys an underlying distribution with density \(p(\bm{x},y,m)\). We have access to data triplets \(\{(\bm{x}_{i},y_{i},m_{i})\}_{i=1}^{n}\) that are drawn independently and identically from the distribution. The goal of L2D in the classification scenario is to obtain a classifier with deferral option \(f(\cdot):\mathcal{X}\rightarrow\mathcal{Y}^{\perp}\), where \(\perp\) is the option of deferral to the expert and \(\mathcal{Y}^{\perp}\) is the augmented decision space \(\mathcal{Y}\cup\{\perp\}\).

The problem evaluation is the following 0-1-deferral loss \(\ell_{01}^{\perp}\)2, which is a generalized version of the zero-one loss \(\ell_{01}(f(\bm{x}),y)=[\![f(\bm{x})\neq y]\!]\), which takes the value of 1 if we use the output of the classifier when it predicts an incorrect label \(([f(\bm{x})\in\mathcal{Y}\ \mathrm{and}\ f(\bm{x})\neq y]\!])\) or defer to the expert when they are incorrect (\([\![f(\bm{x})=\perp\ \mathrm{and}\ m\neq y]\!]\)), where \([\![\cdot]\!]\) is the Iverson bracket notation suggested by Knuth [22]. Then we aim to minimize the risk _w.r.t._ to this loss:

Footnote 2: Though the formulation introduced here is not its most general version, we only study this one and its induced surrogates (4) since previous works on the design of surrogate losses for L2D [30; 9; 44] also concentrated on it.

\[\min_{f}R_{01}^{\perp}(f)=\mathbb{E}_{p(\bm{x},y,m)}\left[\ell_{01}^{\perp}(f( \bm{x}),y,m)\right].\] (1)

Denote by \(f^{*}\) the minimizer of the risk \(R_{01}^{\perp}(f)\), i.e., the Bayes optimal solution, and \(\bm{\eta}(\bm{x})=\{\Pr(Y=y|X=\bm{x})\}_{y=1}^{K}\). Mozannar and Sontag [30] provide a characterization of the form of the Bayes optimal solution as:

**Definition 1**.: (Bayes optimality of L2D) A classifier with deferral option \(f^{*}\rightarrow\mathcal{Y}^{\perp}\) is the minimizer of \(R_{01}^{c}(f)\) if and only if it meets the following condition almost surely:

\[f^{*}(\bm{x})=\left\{\begin{aligned} \perp,& \max_{y}\eta_{y}(\bm{x})<\Pr(M=Y|X=\bm{x}),\\ \operatorname{argmax}_{y}\eta_{y}(\bm{x}),&\mathrm{ else}.\end{aligned}\right.\]

The form of the optimal solution is intuitive: we should defer to the expert if they have a higher probability of being correct than the optimal classifier which follows the most likely label class given the input \(\bm{x}\). This optimal solution can also be seen as the generalized version of Chow's rule in learning to reject [10], where a fixed cost in \([0,1]\) serves as the known accuracy of an expert.

### Consistent Surrogate Losses for L2D

Although we know the form of the Bayes optimal solution, practically the risk minimization problem above faces computational difficulties: the minimization of the discontinuous and non-convex problem (1) is NP-hard [32]. A widely used strategy for tackling this difficulty is to substitute the original loss function which is discontinuous with a continuous surrogate, which has been applied in many areas including ordinary classification [52; 6; 43; 39; 16; 37], multi-label classification [17; 23; 51; 47], AUC optimization [17; 23; 29], cost-sensitive learning [41; 11], top-\(K\) classification [25; 48], adversarially robust classification [4; 2; 1], and learning to reject [12; 13; 5; 49; 34; 8; 7]. Denote by \(\bm{g}:\mathcal{X}\rightarrow\mathbb{R}^{K+1}\) the learnable scoring function that induces our decision function for L2D \(f:\mathcal{X}\rightarrow\mathcal{Y}^{\perp}\) with the following transformation \(\varphi:\mathbb{R}^{K+1}\rightarrow\mathcal{Y}^{\perp}\):

\[\varphi(\bm{g}(\bm{x}))=\left\{\begin{aligned} \perp,& g_{K+1}(\bm{x})>\max_{y\in \mathcal{Y}}g_{y}(\bm{x})\\ \operatorname{argmax}_{y\in\mathcal{Y}}g_{y}(\bm{x}),& \mathrm{else}.\end{aligned}\right.\]We consider a continuous surrogate function \(\Phi:\mathbb{R}^{K+1}\times\mathcal{Y}\times\mathcal{Y}\rightarrow\mathbb{R}^{+}\) and the surrogate risk below:

\[\min_{\bm{g}}R_{\Phi}^{\perp}(\bm{g})=\mathbb{E}_{p(\bm{x},y,m)}\left[\Phi(\bm {g}(\bm{x}),y,m)\right].\] (2)

Assuming we find a surrogate function that overcomes the computational optimization challenges, we need to verify the consistency of \(\Phi\)_w.r.t._\(\ell_{01}^{\perp}\), i.e., any minimizer of the surrogate risk also minimizes the original risk: (2):

\[\varphi\circ\bm{g}^{*}\in\operatorname*{argmin}_{f}R_{01}^{\perp}(f),\;\;\; \forall\bm{g}^{*}\in\operatorname*{argmin}_{\bm{g}}R_{\Phi}^{\perp}(\bm{g}).\]

The first consistent surrogate [30]_w.r.t._\(\ell_{01}^{\perp}\) is proposed by modifying the softmax cross-entropy loss:

\[L_{\mathrm{CE}}(\bm{g}(\bm{x}),y,m)=-\log\psi_{y}^{\mathrm{sm}}(\bm{g}(\bm{x}) )-\llbracket m=y\rrbracket\log\psi_{K+1}^{\mathrm{sm}}(\bm{g}(\bm{x})),\] (3)

where \(\psi^{\mathrm{sm}}\) is the softmax function \(\psi_{y}^{\mathrm{sm}}(\bm{u})=\exp(u_{y})/\sum_{y^{\prime}=1}^{d}\exp(u_{y^ {\prime}})\), where \(d\) is the dimensionality of the input. Inspired by the risk formulation above, Charusaie et al. [9] further generalized the family of consistent surrogate for \(\ell_{01}^{\perp}\) by considering the following consistent surrogate reformulation:

\[L_{\phi}(\bm{g}(\bm{x}),y,m)=\phi(\bm{g}(\bm{x}),y)+\llbracket m=y\rrbracket \phi(\bm{g}(\bm{x}),K+1).\] (4)

It is known from Proposition 2 in Charusaie et al. [9] that surrogates take the form above are consistent _w.r.t._\(\ell_{01}^{\perp}\) if \(\phi\) is a classification-calibrated multi-class loss [43; 6]. Using this result, we can directly make use of any statistically valid surrogate loss in ordinary classification with a simple modification.

### Problems with Probability Estimation for L2D

While prior literature has established how to construct consistent surrogates for L2D, it is less well-known whether such surrogates can actually provide calibrated estimates of classifier and deferral probabilities. As mentioned before, we are also interested in the true probability of the correctness of our prediction, i.e., the value of \(\bm{\eta}(\bm{x})\) (label being \(Y\)) and \(\Pr(M=Y|X=\bm{x})\) (expert is correct). To achieve this goal of probability estimation, the commonly used method is to combine the obtained scoring function \(\bm{g}^{*}\) with a transformation function \(\psi\) to make the composite function \(\psi\circ\bm{g}^{*}\) a probability estimator \(\hat{\bm{\eta}}^{\psi}(\bm{g}(\bm{x}))\). For example, the softmax function is frequently used as \(\psi\) in ordinary multi-class classification to map the scoring function from \(\mathbb{R}^{K}\) to \(\Delta^{K}\). So far, we have not discussed whether these probability estimates are valid.

In the task of L2D for classification, we aim to estimate both \(\bm{\eta}(\bm{x})\in\Delta^{K}\) and \(\Pr(M=Y|X=\bm{x})\in[0,1]\) with a \(K+1\)-dimensional estimator, where its \(y\)-th dimension is the estimate of \(\eta_{y}(\bm{x})\) for \(y\in\mathcal{Y}\) and \(K+1\)-th dimension is the estimate of \(\Pr(M=Y|X=\bm{x})\). Correspondingly, the transformation \(\psi\) should be from \(\mathbb{R}^{K+1}\) to a range \(\mathcal{P}\) that contains \(\Delta^{K}\times[0,1]\). It was shown in Theorem 1 of Mozannar and Sontag [30] that a probability estimator \(\hat{\bm{\eta}}^{\mathrm{sm}}\) with the softmax output of score function \(\bm{g}\) and an extra fractional transformation guarantees to recover class probabilities and expert accuracy at \(\bm{g}^{*}\in\operatorname*{argmin}_{\bm{g}}R_{L_{CE}}(\bm{g})\), which is formulated as:

\[\hat{\eta}_{y}^{\mathrm{sm}}(\bm{g}(\bm{x}))=\psi_{y}^{\mathrm{sm}}(\bm{g}( \bm{x}))/\left(1-\psi_{K+1}^{\mathrm{sm}}(\bm{g}(\bm{x}))\right),\quad\forall y \in\mathcal{Y}\cup\{K+1\},\] (5)

It is noticeable that the range of this estimator is \(\hat{\bm{\eta}}^{\mathrm{sm}}\in\Delta^{K}\times[0,+\infty]\): the estimate of expert accuracy \(\hat{\eta}_{K+1}^{\mathrm{sm}}\) is **unbounded above** and will approach \(+\infty\) if \(\psi_{K+1}^{\mathrm{sm}}(\bm{u})\to 1\). Verma and Nalisnick [44] pointed out that the unboundedness can hurt the performance of this probability estimator: if \(\psi_{K+1}^{\mathrm{sm}}(\bm{g}(\bm{x}))>1/2\), the estimated expert accuracy will be greater than 1 and thus meaningless. Experimental results also show the frequent occurrence of such meaningless results due to the overconfidence of deep models [19]. We further illustrate such miscalibration in Figure 2.

To mitigate this problem, a new OvA-based surrogate loss that can induce a bounded probability estimator while remaining consistent is proposed in [44], which has the following formulation:

\[L_{\mathrm{OvA}}(\bm{g}(\bm{x}),y,m)\!=\!\xi(g_{y}(\bm{x}))\!+\!\sum\nolimits_ {y^{\prime}\neq y}^{K+1}\!\xi(-g_{y^{\prime}}(\bm{x}))\!+\!\llbracket m=y \rrbracket(\xi(g_{K\!+\!1}(\bm{x}))\!-\!\xi(-g_{K\!+\!1}(\bm{x}))),\] (6)

where \(\xi\) is a binary proper composite [46; 40] loss. Its induced probability estimator \(\hat{\bm{\eta}}^{\mathrm{OvA}}\) is:

\[\hat{\eta}_{y}^{\mathrm{OvA}}(\bm{g}(\bm{x}))=\psi_{\xi}(g_{y}(\bm{x})),\quad \forall y\in\mathcal{Y}\cup\{K+1\},\] (7)

where \(\psi_{\xi}\) is a mapping to \([0,1]\) determined by the binary loss, which makes \(\hat{\bm{\eta}}^{\mathrm{OvA}}\) bounded. It is also experimentally shown that the \(\hat{\bm{\eta}}^{\mathrm{OvA}}\) outperformed \(\hat{\bm{\eta}}^{\mathrm{sm}}\)[30] in the task of probability estimation.

Given the success of the OvA-based loss, can we assert that softmax parameterization is inferior to the OvA strategy in probability estimation for L2D? We argue in this paper that such a conclusion should not be drawn so quickly. We should not discourage the use of softmax parameterization based solely on the specific implementation (3), since there may be other implementations of softmax that can resolve the issues with \(\hat{\bm{\eta}}^{\rm sm}\). Furthermore, the great success of softmax parameterization in deep learning models suggests that this potential implementation could also achieve outstanding performance. In this paper, we focus on finding such an implementation and show its superiority both theoretically and experimentally.

## 3 Problem with Symmetric Losses for L2D with Probability Estimation

Before beginning the search for a suitable implementation of softmax parameterization for L2D, it is important to determine the cause of the unboundedness of \(\hat{\bm{\eta}}^{\rm sm}\). Is it due to the use of softmax parameterization or some other factor? If the reason is the former one, any attempts to create a bounded probability estimator with a softmax function for L2D will be in vain. Therefore, it is crucial to identify the root cause of the unboundedness before proceeding with further efforts.

Surprisingly, we find that such unboundedness is not a particular problem of softmax parameterization and is a common one shared by many loss functions. Recall that the loss (3) with unbounded estimator \(\hat{\bm{\eta}}^{\rm sm}\) is a special case of the consistent surrogate (4) by setting the multi-class loss \(\phi\) to softmax cross-entropy loss. We show that even if we use other losses beyond the softmax function and choose other losses such as the standard OvA losses ((14) in Zhang [52]), the induced probability estimators are still inevitably unbounded (or bounded but induced from an unbounded one) as long as we are using \(\phi\) with symmetric structure:

**Theorem 1**.: (Impossibility of non-trivial bounded probability estimator with symmetric losses)

If a surrogate loss \(L_{\phi}\) defined as (4) has probability estimators and is induced from a symmetric consistent multi-class loss \(\phi\) such that that \(P\phi(\bm{u})=\phi(P\bm{u})\), where \(P\) is any permutation matrix, it must have an unbounded probability estimator \(\hat{\bm{\eta}}\): let \(\bm{g}^{*}\in\operatorname*{argmin}R_{L_{\phi}}(\bm{g})\), we have that \(\forall\hat{\bm{\eta}}(\cdot)\) where \(\hat{\bm{\eta}}(\bm{g}^{*}(\bm{x}))=[\bm{\eta}(\bm{x});\Pr(M=Y|X=\bm{x})]\), \(\hat{\bm{\eta}}\) is not bounded above. Furthermore, any bounded probability estimator \(\hat{\bm{\eta}}^{\prime}\) for \(L_{\phi}\) must be a piecewise modification of the unbounded estimator \(\hat{\bm{\eta}}\): denote by \(\mathcal{U}=\cup_{\bm{\beta}}\operatorname*{argmin}_{\bm{u}}\sum_{y=1}^{K+1} \beta_{y}L_{\phi}(\bm{u},y)\) for all \(\bm{\beta}\in\Delta^{K}\times[0,1]\), we have that \(\hat{\bm{\eta}}^{\prime}\) is equal to \(\hat{\bm{\eta}}\) on \(\mathcal{U}\).

The proof is provided in Appendix A. Intuitively, the existence of such an unbounded estimator is caused by the fact that symmetric loss induced \(L_{\phi}\) neglects the asymmetric structure of the probabilities to be estimated by modeling \(\frac{|\bm{\eta}(\bm{x});\Pr(M=Y|X=\bm{x})|}{1+\Pr(M=Y|X=\bm{x})}\) directly. Furthermore, all potential bounded probability estimators are piecewise modifications of the unbounded estimator sharing the same values on \(\mathcal{U}\) with \(\hat{\bm{\eta}}\), which means that they are generated by substituting the invalid values of the unbounded estimator with a valid one, e.g., we can obtain a bounded estimator based on the unbounded one (5) by clipping it to 1 if its estimated expert accuracy is larger than 1.

Figure 2: Illustration of the miscalibration of estimator (5) on a binary classification with deferral problem. The unbounded estimator (5) first estimates \(\frac{[\bm{\eta}(\bm{x});\Pr(M=Y|X=\bm{x})]}{1+\Pr(M=Y|X=\bm{x})}\) that takes value in the 2-D probability simplex denoted by the left triangle and then obtain the final estimate with the fractional transformation (5). However, when over-confidence occurs in the 2-D simplex, i.e., the softmax output lies in the invalid region that \(\psi_{3}^{\rm sm}>1/2\), (5) will magnify the calibration error of the estimates and clipping it to a valid estimate cannot solve this problem.

However, such modifications to make an unbounded estimator bounded are not very useful. Due to the training process's complexity and the distribution's arbitrariness, it is hard to design an appropriate modification of an unbounded estimator. For example, though we can bound the expert accuracy of (5) by 1 when it generates an invalid value that is larger than 1, it is still an overly confident estimation. Meanwhile, we do not know how to upper bound it by a value lower than 1 without prior knowledge of \(\Pr(M=Y|X=\bm{x})\). Overall, training with \(L_{\phi}\) in Theorem 1 can easily lead to a model that generates invalid probability estimation with an unbounded estimator \(\tilde{\bm{\eta}}\), while most modified bounded estimators cannot efficiently solve this problem. We will experimentally verify this point in Section 5.

This result shows that the consistent surrogate framework [9] does not directly provide us a solution for solving the unboundedness problem since most multi-class losses we use, e.g., CE loss, OvA loss, Focal loss [26], are symmetric. This motivates the design of surrogates with bounded probability estimators for L2D in our work. Based on Theorem 1, we have the following findings: firstly unboundedness of probability estimators is not necessarily caused by the softmax parameterization, as the induced estimator of any symmetric loss, e.g., standard softmax-free symmetric OvA losses [52], exhibits unboundedness too. Secondly, due to the fact that the OvA strategy for L2D (6) successfully gets rid of the unboundedness issue, we can reasonably deduce that a modified softmax function can also present similar outcomes. In the following section, we propose a novel modification of the softmax parameterization that overcomes these issues and reveals that both the previous OvA-based work [44] and our current work benefit from the use of asymmetric losses.

## 4 Consistent Softmax-Based Surrogate with Bounded Probability Estimator

In this section, we find a softmax parameterization that is a feasible solution in L2D for the construction of surrogate loss with a bounded probability estimator. We first propose a cross-entropy-like surrogate loss but with an asymmetric transformation that resembles the ordinary softmax function for its first \(K\) elements but processes the \(K+1\)-th coordinate in a special way. Then we show that such a transformation has useful properties for both classification and probability estimation, and then provide consistency analysis for both the loss function and its induced bounded probability estimator. Finally, we show that our proposed loss and the OvA loss [44] are connected to the consistent surrogate formulation (4) with the use of asymmetric multi-class losses, which indicates the helpfulness of asymmetry and shed light on the future study of consistent surrogates for L2D with bounded estimators.

### Consistent Surrogate Formulation with Asymmetric Bounded Softmax Parameterization

Before searching for a softmax-parameterization that is capable of L2D with probability estimation, we need to better understand the failure of (3) for inducing a bounded probability estimator. By inspecting the proof of consistency in Theorem 1 of Mozumar and Sontag [30], we can learn that the cross-entropy-like surrogate (3) works by fitting a \(K+1\) class posterior distribution: \(\psi^{\mathrm{sm}}(\bm{g}^{\star})=\tilde{\bm{\eta}}(\bm{x})=\left[\frac{\eta _{1}(\bm{x})}{1+\Pr(M=Y|\bm{x})},\cdots,\frac{\eta_{K}(\bm{x})}{1+\Pr(M=Y|\bm{ x})},\frac{\Pr(M=Y|\bm{x})}{1+\Pr(M=Y|\bm{x})}\right]\). Though we can check that the \(\varphi\circ\bm{g}^{\star}\) is exactly a Bayes optimal solution of \(R_{01}^{\perp}(f)\) due to the monotonicity of the softmax function and the form of \(\tilde{\bm{\eta}}\), to get \([\bm{\eta}(\bm{x});\Pr(M=Y|X=\bm{x})]\) we need to perform an extra inverse transformation should be exerted on \(\psi^{\mathrm{sm}}\). This is caused by the following dichotomy: the class probabilities and expert accuracy we aim to estimate are in the range of \(\Delta^{K}\times[0,1]\), while the standard softmax-parameterization of (3) maps the \(K+1\) dimensional scoring function \(\bm{g}\) into \(\Delta^{K+1}\).

To solve this issue, a promising approach is to modify the softmax function to make it a transformation that can directly cast the scoring function \(\bm{g}\) into the target range \(\Delta^{K}\times[0,1]\). Since the target range is not symmetric, the modified softmax should also be asymmetric. This idea is given a concrete form in the following asymmetric softmax parameterization:

**Definition 2**.: (Asymmetric softmax parameterization) \(\tilde{\bm{\psi}}\) is called a _asymmetric softmax function_ that for any \(K>1\) and \(\bm{u}\in\mathbb{R}^{K+1}\):

\[\tilde{\psi}_{y}(\bm{u})=\left\{\begin{array}{ll}\frac{\exp(u_{y})}{\sum_{ y^{\prime}=1}^{K}\exp(u_{y^{\prime}})},&y\neq K+1,\\ \frac{\exp(u_{K+1})}{\sum_{y^{\prime}=1}^{K+1}\exp(u_{y^{\prime}})-\max_{y^{ \prime}\in\{1,\cdots,K\}}\exp(u_{y^{\prime}})},&\mathrm{else}.\end{array}\right.\] (8)At first glance, the proposed asymmetric function appears to be the standard softmax function, which excludes the \(K+1\)-th input of \(\bm{u}\) for \(y\neq K+1\). However, the last coordinate of the function takes on a quite different form. This special asymmetric structure is designed to satisfy the following properties:

**Proposition 1**.: (Properties of \(\tilde{\psi}\)) For any \(\bm{u}\in\mathbb{R}^{K+1}\):

(i). (Boundedness) \(\tilde{\psi}(\bm{u})\in\Delta^{K}\times[0,1]\),

(ii). (Maxima-preserving) \(\operatorname*{argmax}_{y\in\{1,\cdots,K+1\}}\tilde{\psi}_{y}(\bm{u})= \operatorname*{argmax}_{y\in\{1,\cdots,K+1\}}u_{y}\).

It can be seen that the proposed asymmetric softmax \(\tilde{\psi}\) is not only bounded but also successfully maps \(\bm{g}\) into the desired target range, which indicates that \(\tilde{\psi}\) may directly serve as the probability estimator \(\hat{\bm{\eta}}^{\tilde{\psi}}(\bm{g}(\bm{x}))=\tilde{\psi}(\bm{g}(\bm{x}))\). Furthermore, the maxima-preserving property guarantees that the estimator is also capable of discriminative prediction: if a scoring function \(\bm{g}^{\prime}\) can recover the true probability, i.e., \(\hat{\bm{\eta}}^{\tilde{\psi}}(\bm{g}^{\prime}(\bm{x}))=[\bm{\eta}(\bm{x}); \operatorname*{Pr}(M=Y|X=\bm{x})]\), then \(\varphi\circ\bm{g}^{\prime}\) must also be the Bayes optimal solution of \(R^{\perp}_{01}(\bm{g})\). Based on the asymmetric softmax function, we propose the following surrogate loss for L2D:

**Definition 3**.: (Asymmetric Softmax-Parameterized Loss) The proposed surrogate for L2D with asymmetric softmax parameterization \(L_{\tilde{\psi}}(\bm{u},y,m):\mathbb{R}^{K+1}\times\mathcal{Y}\times\mathcal{Y}\) is formulated as:

\[L_{\tilde{\psi}}(\bm{u},y,m)\!=\!-\log(\tilde{\psi}_{y}\left(\bm{u}\right))- \llbracket m\neq y\rrbracket\log(1-\tilde{\psi}_{K+1}(\bm{u}))-\llbracket m =y\rrbracket\log(\tilde{\psi}_{K+1}(\bm{u})).\] (9)

The proposed loss takes an intuitive form, which can be seen as the combination of the cross-entropy loss (the first term) and a modified version of binary logistic loss (the last two terms). This formulation is inspired by the structure of our problem, where the expert accuracy is not directly related to class probabilities while the class probabilities should fulfill that \(\bm{\eta}(\bm{x})\in\Delta^{K}\). In fact, the proposed surrogate is not a simple summation of two independent losses and they are indirectly related by the asymmetric softmax function: according to Definition 2, the two counterparts share the same elements \([g_{1},\cdots,g_{K}]\). This correlation serves as a normalization for \(\tilde{\psi}_{K+1}\) that brings the property of maxima-preserving, which is crucial for the following consistency analysis:

**Theorem 2**.: (Consistency of \(L_{\tilde{\psi}}\) and bounded probability estimator \(\hat{\bm{\eta}}^{\tilde{\psi}}\))

The proposed surrogate \(L_{\tilde{\psi}}\) is a consistent surrogate for L2D, i.e., \(\varphi\circ\bm{g}^{*}\in\operatorname*{argmin}_{f}R^{\perp}_{01}(f),\ \ \forall\bm{g}^{*}\in \operatorname*{argmin}_{g}R^{\perp}_{\Phi}(\bm{g})\). The bounded probability estimator can also recover the desired class probabilities and expert accuracy: \(\hat{\bm{\eta}}^{\tilde{\psi}}(\bm{g}^{*}(\bm{x}))=\left[\bm{\eta}(\bm{x}); \operatorname*{Pr}(M=Y|X=\bm{x})\right],\ \forall\bm{x}\in\mathcal{X}\). Furthermore, if there exists other probability estimators for \(L_{\tilde{\psi}}\), they must also be bounded.

The proof can be found in Appendix C. According to the theorem above, we showed that our proposed asymmetric softmax function induces a consistent surrogate and a bounded probability estimator. We also showed that there does not exist an unbounded probability estimator for \(L_{\tilde{\psi}}\), which guarantees that our proposed bounded estimator is never the modification of an unbounded one. This result enriches the toolbox for L2D with probability estimation and theoretically justifies the use of softmax parameterization in L2D. In fact, we can further substitute the cross-entropy-like counterpart with any strictly proper loss [46] to get the same consistency result. In the following subsection, we will discuss the relationship between our method and the general consistent surrogate framework [9].

### Connection with Consistent Surrogate Framework [9]: Asymmetry Can Help

In the previous section, we showed that there exists an implementation of softmax \(\tilde{\psi}\) that can induce both a consistent loss and a valid probability estimator for L2D. Given the theoretical successes of our proposed softmax-based method and the previous OvA strategy, we may further expect them to provide more insights into the design of surrogates and probability estimators for L2D. Recalling the consistent surrogate formulation (4) proposed in Charusaie et al. [9] that allows the use of all consistent multi-class losses for constructing L2D surrogates, it is an instinctive idea that our proposed consistent surrogates (9) and the previous work [44] can be included in this framework. However, this idea may not be easily confirmed: Theorem 1 implies that the two surrogates are not the trivial combinations of commonly used symmetric losses and formulation (4) since they can both induce bounded probability estimators. The following corollary shows that the two surrogates are included in the family of consistent surrogate formulation (4), but induced from two novel asymmetric multi-class surrogates.

**Corollary 1**.: We can get the consistent surrogates \(L_{\hat{\psi}}\) (9) and \(L_{\mathrm{OvA}}\) (6) by setting \(\phi\) in the consistent loss formulation (4) to specific **consistent and asymmetric** multi-class losses.

Due to page limitations, we present the formulation of the asymmetric multi-class losses and the proof in the Appendix D. Although this conclusion reveals the connection between the two consistent surrogates and the general framework (4), it is important to note that it does not necessarily imply that the results in Verma and Nalisnick [44] and this paper are trivial. Since asymmetric losses are seldom used in ordinary multi-class classification, it is hard to obtain \(L_{\hat{\phi}}\) and \(L_{\mathrm{OvA}}\) by simply selecting \(\phi\) from known consistent multi-class losses. According to this corollary and theorem 1, we can determine that a multi-class loss \(\phi\) with asymmetric structure is a necessity if we aim to design consistent L2D surrogates with bounded probability estimators based on the general formulation (4). Based on this insight, it is promising to discover more surrogates with bounded probability estimators for L2D by focusing on the design of asymmetric multi-class surrogates.

### Regret Transfer Bounds

In this section, we further study the regret transfer bounds of our proposed surrogate (9) to characterize the effect of minimizing surrogate risk \(R_{L_{\hat{\psi}}}(\bm{g})\) on both the target risk \(R_{01}^{\perp}(\bm{g})\) and the misclassification error of the classifier. Denoted by \(\bm{g}_{\mathrm{class}}=\bm{g}_{1:K}\) the classifier counterpart of our model and \(R_{01}(\bm{g})\) is its misclassification error, we can show that:

**Theorem 3**.: \(\max\big{(}R_{01}(\bm{g}_{\mathrm{class}})-R_{01}^{*},\ R_{01}^{\perp}(\bm{g} )-R_{01}^{\perp*}\big{)}\leq\sqrt{2\left(R_{L_{\hat{\psi}}}(\bm{g})-R_{L_{\hat {\psi}}}^{*}\right)}\)_._

The proof can be found in Appendix E. This theorem shows that we can use the excess risk of our proposed surrogate to upper-bound those of our concerned targets, and its proof is conducted by applying Pinsker's inequality and zooming.

This theorem shows that as long as we reach a low risk _w.r.t._ the proposed surrogate (approximately optimal), we can obtain a model with satisfying performances for both L2D and classification. This conclusion is not trivial: according to the characterization of \(R_{01}^{\perp}\)'s Bayes optimality in Definition 1, the classifier counterpart is not guaranteed to classify accurately on the deferred samples. We will further experimentally demonstrate the efficacy of our surrogate for L2D and classification in the next section.

## 5 Experiments

In this section, we compare our proposed asymmetric softmax estimator and its induced surrogate loss with the estimators and losses in previous works. Detailed setup can be found in Appendix F.

**Datasets and Models.** We evaluate the proposed method and baselines on widely used benchmarks with both synthetic and real-world experts. For synthetic experts, we conduct experiments on the CIFAR100 [24]. Following the previous works, the expert has a chance of \(p\) to generate correct labels on the first \(k\in\{20,40,60\}\) classes and at random otherwise. We set \(p=94\%\) as in Mozannar and Sontag [30] and \(75\%\) as in Verma and Nalisnick [44] to simulate experts of high and medium accuracy. For real-world experts, we use CIFAR10H, HateSpeech, and ImageNet-16H [36; 14; 21]

Figure 3: Distributions of the true and estimated accuracy of baselines and proposed method on CIFAR10H.

datasets, where the expert's prediction is generated using the provided auxiliary expert information. More experimental results of real-world experts can be found in Appendix F.

For CIFAR-100, HateSpeech, and ImageNet-16H, we report the misclassification error, coverage, and the ECE of the expert accuracy estimates. We also report the error of our model with the defernt budget as in Figure 4 of Verma and Nalisinck [44] to further evaluate the performance of the obtained classifier. For CIFAR10H, we plot the distribution of the true and estimated expert accuracy in Figure 3 to illustrate the performance of baselines and our method on fitting \(\Pr(M=Y|X=\bm{x})\). The experiments on CIFAR-100 is conducted with 28-layer WideResNet [50] and SGD as in previous works [30; 44], and those on datasets with real-world experts are conducted using pre-trained models/embedding.

**Baselines.** We compare our **A**symmetric Soft**Max** based method (A-SM) with the previously proposed **S**ymmetric **S**oft**Max**-based (S-SM) method [30] and **A**symmetric OvA (A-OvA) based method [44]. We also combined the **S**ymmetric OvA logistic loss (S-OvA) with (4) to further evaluate the effect of symmetric loss and its induced unbounded estimator. For unbounded probability estimators in S-SM and S-OvA, we clip their estimates into \([0,1]\) to make them valid. We directly use the output of baselines and our method without post-hoc techniques [19; 33] to better reflect their own performance.

**Experimental Results.** By observing Figure 3, we can find that the distributions of bounded method A-OvA and our proposed A-SM have markedly more overlap with the true distribution compared with the symmetric and unbounded ones, which directly shows that the bounded estimators can better estimate of expert accuracy. As can be seen from the experimental results reported in Table 1 and 2, our proposed A-SM is always better than or comparable to all the baselines _w.r.t._ classification accuracy. We can also see that the coverage of our method is always significantly higher than the baselines, which shows that our surrogate can induce ideal models for L2D. Though S-SM is comparable to A-SM with a high-accuracy expert, it has a significantly lower coverage and is

\begin{table}
\begin{tabular}{c|c|c c c|c c c} \hline \hline \multirow{2}{*}{Method} & \multirow{2}{*}{Expert} & \multirow{2}{*}{Error} & \multirow{2}{*}{Coverage} & \multicolumn{3}{c}{Budgeted Error} \\ \cline{5-8}  & & & & & 10\% & 20\% & 30\% \\ \hline \multicolumn{8}{c}{Expert Accuracy = 94\%} \\ \hline \multirow{3}{*}{S-SM} & 20 & **24.58(0.13)** & 77.72(0.31 & 4.86(0.11) & 31.68(0.39) & 25.00(0.24) & 24.59(0.13) \\  & 40 & **21.92(0.32)** & 57.89(0.54) & 9.22(0.38) & 46.69(0.63) & 38.50(0.60) & 29.94(0.62) \\  & 60 & **18.69(0.88)** & 40.34(6.28) & 11.10(0.72) & 59.44(4.95) & 51.36(5.08) & 42.77(5.09) \\ \hline \multirow{3}{*}{S-OvA} & 20 & 27.00(1.91) & 85.40(0.91) & 5.15(0.31) & 28.42(2.26) & 27.00(1.91) & 27.00(1.91) \\  & 40 & 27.33(1.50) & 68.47(1.59) & 9.38(0.46) & 39.95(2.35) & 32.93(2.30) & 27.92(2.06) \\  & 60 & **18.44(0.64)** & 58.18(1.55) & 7.70(0.24) & 42.52(1.74) & 33.67(1.72) & 25.74(1.75) \\ \hline \multirow{3}{*}{A-OvA} & 20 & 25.63(0.97) & 90.40(0.89) & **4.35(0.29)** & 25.65(0.99) & 25.63(0.97) & 25.63(0.97) \\  & 40 & 23.23(0.42) & 80.46(0.51) & **6.81(0.33)** & 27.44(0.62) & 23.23(0.42) & 23.23(0.42) \\  & 60 & **19.64(1.10)** & 70.44(2.73) & 7.34(0.38) & 31.90(2.73) & 24.75(2.73) & 20.05(1.62) \\ \hline \multirow{3}{*}{A-SM (Proposed)} & 20 & **24.54(0.06)** & **98.16(0.03)** & **4.63(0.11)** & **24.54(0.06)** & **24.54(0.06)** & **24.54(0.06)** \\  & 40 & **22.17(0.36)** & **92.20(0.32)** & **6.58(0.22)** & **22.17(0.36)** & **22.17(0.36)** & **22.17(0.36)** \\  & 60 & **19.30(0.58)** & **84.72(0.30)** & **5.96(0.44)** & **22.91(0.42)** & **19.30(0.58)** & **19.30(0.58)** \\ \hline \multicolumn{8}{c}{Expert Accuracy = 75\%} \\ \hline \multirow{3}{*}{S-SM} & 20 & 25.49(0.20) & 86.46(0.52) & 5.07(0.21) & 26.09(0.23) & 25.48(0.20) & 25.49(0.20) \\  & 40 & 25.13(0.44) & 74.65(0.48) & 12.82(0.29) & 32.82(0.66) & 26.99(0.59) & 25.13(0.44) \\  & 60 & 24.05(0.43) & 60.25(1.21) & 18.70(0.55) & 42.30(0.98) & 36.18(0.99) & 29.47(1.10) \\ \hline \multirow{3}{*}{S-OvA} & 20 & 26.53(0.86) & 90.06(2.92) & 5.57(0.54) & 26.83(1.20) & 26.53(0.86) & 26.53(0.86) \\  & 40 & 26.89(1.78) & 77.69(5.82) & 7.14(1.41) & 32.30(4.92) & 28.33(3.11) & 26.90(1.78) \\  & 60 & 25.29(0.69) & 69.08(1.35) & 7.47(0.12) & 36.67(1.45) & 30.44(1.33) & 25.70(1.15) \\ \hline \multirow{3}{*}{A-OvA} & 20 & 25.94(0.52) & 93.05(0.43) & **4.78(0.29)** & 25.

outperformed by A-SM with an expert of lower accuracy, which indicates that it is suffering from the problem of deferring more samples than necessary. This problem is also observed in learning with rejection [8]. Though S-OvA can mitigate this problem, its coverage is still consistently lower than A-SM. Notice that when there exist deferral budget requirements, all the unbounded baselines are outperformed by A-OvA, and A-OvA is further outperformed by A-SM, which indicates that our method can also efficiently generate a classifier. Meanwhile, the ECE of our estimated expert accuracy is also comparable to or better than A-OvA, while those of the unbounded ones all have significantly higher ECE, which further shows the efficacy of our method in estimating expert accuracy.

## 6 Conclusion

In this paper, we provide a novel consistent surrogate loss based on an asymmetric softmax function for learning to defer that can also provide calibrated probability estimates for the classifier and for expert correctness. We reveal that the root cause of the previous unbounded and miscalibrated probability estimators for L2D is not softmax but the intrinsic symmetry of the used loss function. We solve this problem by designing an asymmetric softmax function and using it to induce a consistent surrogate loss and a bounded probability estimator. We further give the regret transfer bounds of our method for both L2D and classification tasks. Finally, we evaluate our method and the baseline surrogate losses and probability estimators on benchmark datasets with both synthetic and real-world experts and show that we outperform prior methods. While we provide a consistent multi-expert extension of our proposed surrogate in Appendix H, it is still a promising future direction to generalize the multi-expert surrogates [45] to all the consistent multiclass losses as in Charusaie et al. [9].

## Acknowledgement

This research/project is supported by the National Research Foundation, Singapore and DSO National Laboratories under the AI Singapore Programme (AISG Award No: AISG2-GC-2023-009), and Ministry of Education, Singapore, under its Academic Research Fund Tier 1 (RG13/22). Lei Feng is supported by Chongqing Overseas Chinese Entrepreneurship and Innovation Support Program, CAAI-Huawei MindSpore Open Fund, and OpenI Community (https://openi.pcl.ac.cn). Hussein Mozannar is thankful for the support of the MIT-IBM Watson AI Lab.

\begin{table}
\begin{tabular}{c|c c c|c c c} \hline \hline Method & Error & Coverage & ECE & \multicolumn{3}{c}{Budgeted Error} \\ \cline{3-8}  & & & & 10\% & 20\% & 30\% \\ \hline \multicolumn{8}{c}{HateSpeech} \\ \hline S-SM & 8.65(0.14) & 70.19(1.50) & 3.95(0.48) & 25.48(0.49) & 16.80(0.44) & 8.97(0.33) \\ \hline S-OvA & 8.65(0.14) & 69.90(0.53) & 1.77(0.07) & 24.19(0.25) & 15.89(0.34) & 8.78(0.31) \\ \hline A-OvA & 9.64(0.32) & 77.2(0.42) & **1.73(0.26)** & 16.525(0.28) & 8.80(0.25) & 8.56(0.29) \\ \hline A-SM & **8.06(0.40)** & **81.98(0.58)** & **1.53(0.26)** & **15.07(0.35)** & **8.06(0.40)** & **8.06(0.40)** \\ \hline \multicolumn{8}{c}{ImageNet-16H} \\ \hline S-SM & 15.08(1.19) & 26.41(1.78) & 22.92(2.59) & 68.58(1.30) & 60.33(1.19) & 51.27(1.94) \\ \hline S-OvA & 15.15(1.50) & 23.08(2.39) & 11.68(0.53) & 68.91(2.51) & 60.08(1.82) & 51.50(2.05) \\ \hline A-OvA & 14.17(0.58) & 21.56(2.13) & 11.57(1.50) & 71.14(2.10) & 62.39(2.10) & 53.95(2.27) \\ \hline A-SM & **12.59(0.79)** & **39.48(2.50)** & **8.13(1.33)** & **57.75(1.37)** & **49.66(1.18)** & **40.85(1.51)** \\ \hline \hline \end{tabular}
\end{table}
Table 2: Experimental results on HateSpeech and ImageNet-16H with noise type “095” for 5 trials. We report the mean(%)standard error(%) of related statistics.The best and comparable methods based on t-test at significance level \(5\%\) are highlighted in boldface.

## References

* Awasthi et al. [2021] Pranjal Awasthi, Natalie Frank, Anqi Mao, Mehryar Mohri, and Yutao Zhong. Calibration and consistency of adversarial surrogate losses. _CoRR_, abs/2104.09658, 2021. URL https://arxiv.org/abs/2104.09658.
* Awasthi et al. [2021] Pranjal Awasthi, Anqi Mao, Mehryar Mohri, and Yutao Zhong. A finer calibration analysis for adversarial robustness. _CoRR_, abs/2105.01550, 2021. URL https://arxiv.org/abs/2105.01550.
* Bansal et al. [2021] Gagan Bansal, Besmira Nushi, Ece Kamar, Eric Horvitz, and Daniel S. Weld. Is the most accurate AI the best teammate? optimizing AI for teamwork. In _AAAI_, 2021.
* Bao et al. [2020] Han Bao, Clayton Scott, and Masashi Sugiyama. Calibrated surrogate losses for adversarially robust classification. In _COLT_, volume 125 of _Proceedings of Machine Learning Research_, pages 408-451. PMLR, 2020.
* Bartlett and Wegkamp [2008] Peter L. Bartlett and Marten H. Wegkamp. Classification with a reject option using a hinge loss. _J. Mach. Learn. Res._, 9:1823-1840, 2008.
* Bartlett et al. [2006] Peter L Bartlett, Michael I Jordan, and Jon D McAuliffe. Convexity, classification, and risk bounds. _Journal of the American Statistical Association_, 101(473):138-156, 2006.
* Cao et al. [2022] Yuzhou Cao, Tianchi Cai, Lei Feng, Lihong Gu, Jinjie GU, Bo An, Gang Niu, and Masashi Sugiyama. Generalizing consistent multi-class classification with rejection to be compatible with arbitrary losses. In _NeurIPS_, 2022.
* Charoenphakdee et al. [2021] Nontawat Charoenphakdee, Zhenghang Cui, Yivan Zhang, and Masashi Sugiyama. Classification with rejection based on cost-sensitive classification. In _ICML_, volume 139 of _Proceedings of Machine Learning Research_, pages 1507-1517. PMLR, 2021.
* Charusaie et al. [2022] Mohammad-Amin Charusaie, Hussein Mozannar, David A. Sontag, and Samira Samadi. Sample efficient learning of predictors that complement humans. In _ICML_, 2022.
* Chow [1970] C. Chow. On optimum recognition error and reject tradeoff. _IEEE Transactions on Information Theory_, 16(1):41-46, 1970. doi: 10.1109/TIT.1970.1054406.
* Clayton [2012] Scott Clayton. Calibrated asymmetric surrogate losses. _Electronic Journal of Stats_, 6:238-238, 2012.
* Cortes et al. [2016] Corinna Cortes, Giulia DeSalvo, and Mehryar Mohri. Boosting with abstention. In _NeurIPS_, pages 1660-1668, 2016.
* Cortes et al. [2016] Corinna Cortes, Giulia DeSalvo, and Mehryar Mohri. Learning with rejection. In _ALT_, volume 9925, pages 67-82, 2016.
* Davidson et al. [2017] Thomas Davidson, Dana Warmsley, Michael W. Macy, and Ingmar Weber. Automated hate speech detection and the problem of offensive language. In _ICWSM_, 2017.
* De et al. [2021] Abir De, Nastaran Okati, Ali Zarezade, and Manuel Gomez Rodriguez. Classification under human assistance. In _AAAI_, 2021.
* Finocchiaro et al. [2019] Jessica Finocchiaro, Rafael M. Frongillo, and Bo Waggoner. An embedding framework for consistent polyhedral surrogates. In _NeurIPS_, pages 10780-10790, 2019. URL https://proceedings.neurips.cc/paper/2019/hash/9ec51f6eb240fb631a35864e13737bca-Abstract.html.
* Gao and Zhou [2013] Wei Gao and Zhi-Hua Zhou. On the consistency of multi-label learning. _Artif. Intell._, 199-200:22-44, 2013.
* Grigorescu et al. [2020] Sorin Mihai Grigorescu, Bogdan Trasnea, Tiberiu T. Cocias, and Gigel Macesanu. A survey of deep learning techniques for autonomous driving. _J. Field Robotics_, 37(3):362-386, 2020.
* Guo et al. [2017] Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Weinberger. On calibration of modern neural networks. In _ICML_, 2017.

* Kadampur and Riyaee [2020] Mohammad Ali Kadampur and Sulaiman Al Riyaee. Skin cancer detection: Applying a deep learning based model driven architecture in the cloud for classifying dermal cell images. _Informatics in Medicine Unlocked_, 18:100282, 2020. ISSN 2352-9148.
* Kerrigan et al. [2021] Gavin Kerrigan, Padhraic Smyth, and Mark Steyvers. Combining human predictions with model probabilities via confusion matrices and calibration. In _NeurIPS_, 2021.
* Knuth [1992] Donald E Knuth. Two notes on notation. _The American Mathematical Monthly_, 99(5):403-422, 1992.
* Koyejo et al. [2015] Oluwasanmi Koyejo, Nagarajan Natarajan, Pradeep Ravikumar, and Inderjit S. Dhillon. Consistent multilabel classification. In _NeurIPS_, pages 3321-3329, 2015.
* Krizhevsky et al. [2009] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.
* Lapin et al. [2018] Maksim Lapin, Matthias Hein, and Bernt Schiele. Analysis and optimization of loss functions for multiclass, top-k, and multilabel classification. _IEEE Trans. Pattern Anal. Mach. Intell._, 40(7):1533-1554, 2018.
* Lin et al. [2017] Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Dollar. Focal loss for dense object detection. _IEEE International Conference on Computer Vision (ICCV)_, 2017.
* Link et al. [2016] Daniel Link, Bernd Hellingrath, and Jie Ling. A human-is-the-loop approach for semi-automated content moderation. In _ISCRAM_, 2016.
* Madras et al. [2018] David Madras, Toniann Pitassi, and Richard S. Zemel. Predict responsibly: Improving fairness and accuracy by learning to defer. In _NeurIPS_, 2018.
* Menon and Williamson [2014] Aditya Krishna Menon and Robert C. Williamson. Bayes-optimal scorers for bipartite ranking. In _COLT_, volume 35 of _JMLR Workshop and Conference Proceedings_, pages 68-106. JMLR.org, 2014. URL http://proceedings.mlr.press/v35/menon14.html.
* Mozannar and Sontag [2020] Hussein Mozannar and David A. Sontag. Consistent estimators for learning to defer to an expert. In _ICML_, 2020.
* Mozannar et al. [2022] Hussein Mozannar, Arvind Satyanarayan, and David A. Sontag. Teaching humans when to defer to a classifier via exemplars. In _AAAI_, 2022.
* Mozannar et al. [2023] Hussein Mozannar, Hunter Lang, Dennis Wei, Prasanna Sattigeri, Subhro Das, and David A. Sontag. Who should predict? exact algorithms for learning to defer to humans. _CoRR_, abs/2301.06197, 2023.
* Narasimhan et al. [2022] Harikrishna Narasimhan, Wittawat Jitkrittum, Aditya Krishna Menon, Ankit Singh Rawat, and Sanjiv Kumar. Post-hoc estimators for learning to defer to an expert. In _NeurIPS_, 2022.
* Ni et al. [2019] Chenri Ni, Nontawat Charoenphakdee, Junya Honda, and Masashi Sugiyama. On the calibration of multiclass classification with rejection. In _NeurIPS_, 2019.
* Okati et al. [2021] Nastaran Okati, Abir De, and Manuel Gomez-Rodriguez. Differentiable learning under triage. In _NeurIPS_, 2021.
* Peterson et al. [2019] Joshua C. Peterson, Ruairidh M. Battleday, Thomas L. Griffiths, and Olga Russakovsky. Human uncertainty makes classification more robust. In _ICCV_, pages 9616-9625, 2019.
* Pires and Szepesvari [2016] Bernardo Avila Pires and Csaba Szepesvari. Multiclass classification calibration functions. _CoRR_, abs/1609.06385, 2016. URL http://arxiv.org/abs/1609.06385.
* Ramaswamy and Agarwal [2016] Harish G. Ramaswamy and Shivani Agarwal. Convex calibration dimension for multiclass loss matrices. _J. Mach. Learn. Res._, 17:14:1-14:45, 2016.
* Ramaswamy and Agarwal [2016] Harish G. Ramaswamy and Shivani Agarwal. Convex calibration dimension for multiclass loss matrices. _J. Mach. Learn. Res._, 17:14:1-14:45, 2016. URL http://jmlr.org/papers/v17/14-316.html.

* Reid and Williamson [2010] Mark D. Reid and Robert C. Williamson. Composite binary losses. _J. Mach. Learn. Res._, 11:2387-2422, 2010.
* Scott [2011] Clayton Scott. Surrogate losses and regret bounds for cost-sensitive classification with example-dependent costs. In Lise Getoor and Tobias Scheffer, editors, _ICML_, pages 153-160. Omnipress, 2011. URL https://icml.cc/2011/papers/138_icmlpaper.pdf.
* Straitouri et al. [2022] Eleni Straitouri, Lequn Wang, Nastaran Okati, and Manuel Gomez Rodriguez. Improving expert predictions with prediction sets, 2022.
* Tewari and Bartlett [2007] Ambuj Tewari and Peter L. Bartlett. On the consistency of multiclass classification methods. _J. Mach. Learn. Res._, 8:1007-1025, 2007.
* Verma and Nalisnick [2022] Rajeev Verma and Eric T. Nalisnick. Calibrated learning to defer with one-vs-all classifiers. In _ICML_, 2022.
* Verma et al. [2023] Rajeev Verma, Daniel Barrejon, and Eric T. Nalisnick. Learning to defer to multiple experts: Consistent surrogate losses, confidence calibration, and conformal ensembles. In _AISTATS_, 2023.
* Williamson et al. [2016] Robert C. Williamson, Elodie Vernet, and Mark D. Reid. Composite multiclass losses. _J. Mach. Learn. Res._, 17:223:1-223:52, 2016.
* Wu et al. [2021] Guoqiang Wu, Chongxuan Li, Kun Xu, and Jun Zhu. Rethinking and reweighting the univariate losses for multi-label ranking: Consistency and generalization. _CoRR_, abs/2105.05026, 2021. URL https://arxiv.org/abs/2105.05026.
* Yang and Koyejo [2020] Forest Yang and Sanmi Koyejo. On the consistency of top-k surrogate losses. In _ICML_, volume 119 of _Proceedings of Machine Learning Research_, pages 10727-10735. PMLR, 2020.
* Yuan and Wegkamp [2010] Ming Yuan and Marten H. Wegkamp. Classification methods with reject option based on convex risk minimization. _J. Mach. Learn. Res._, 11:111-130, 2010.
* Zagoruyko and Komodakis [2016] Sergey Zagoruyko and Nikos Komodakis. Wide residual networks. In _BMVC_, 2016.
* Zhang et al. [2020] Mingyuan Zhang, Harish Guruprasad Ramaswamy, and Shivani Agarwal. Convex calibrated surrogates for the multi-label f-measure. In _ICML_, volume 119 of _Proceedings of Machine Learning Research_, pages 11246-11255. PMLR, 2020.
* Zhang [2004] Tong Zhang. Statistical analysis of some multi-category large margin classification methods. _J. Mach. Learn. Res._, 5:1225-1251, 2004.

[MISSING_PAGE_FAIL:14]

Proof of Theorem 2

Proof.: The consistency can be directly obtained by recovering the class probability and expert accuracy according to the maxima-preserving, then we first focus on how our proposed estimator recovers the posterior probabilities.

According to the property of log loss, it is easy to learn that \(\tilde{\psi}_{y}(\bm{g}^{*}(\bm{x}))=p(y|\bm{x})\) for \(y\in\{1,\cdots,K\}\). When \(y=K+1\), we can learn from the range of our estimator and the property of binary log loss that \(\tilde{\psi}_{y}(\bm{g}^{*}(\bm{x}))=\Pr(M=Y|X=\bm{x})\). Then we can conclude that \(\tilde{\psi}(\bm{g}^{*}(\bm{x}))=\bm{\eta}(\bm{x})\times\Pr(M=Y|X=\bm{x})\).

Then we begin to prove that there is no unbounded probability estimator by contradiction. Suppose there exists an unbounded estimator \(\psi\). For any \(\bm{g}\), it must be the solution of a distribution and expert whose posterior probability is \(\tilde{\psi}(\bm{g}(\bm{x}))\) for each point \(\bm{x}\). However, for a \(\bm{g}\) that there exists \(\bm{x}\) that \(\psi(\bm{g}(\bm{x}))\not\in\Delta^{K}\times[0,1]\), we can learn that it cannot be the solution of any distribution and expert according to the definition of probability estimator. We can learn from this contradiction that \(\psi\) is not a probability estimator as long as its range is not \(\Delta^{K}\times[0,1]\). 

## Appendix D Proof of Corollary 1

Proof.: We can set the multi-class loss to \(\phi_{\tilde{\psi}}\) to get our proposed loss:

\[\phi_{\tilde{\psi}}\left(\bm{u},y\right)=\left\{\begin{array}{l}-\log\left( \frac{\exp(u_{y})}{\sum_{y^{\prime}=1}^{K^{\prime}-1}\exp(u_{y^{\prime}})} \right)-\log\left(1-\frac{\exp(u_{K^{\prime}})}{\sum_{y^{\prime}=1}^{K^{\prime }}\exp(u_{y^{\prime}})-\max_{y^{\prime}\in[1,K^{\prime}-1]}\exp_{u_{y^{\prime}} }}\right),\;y\neq K^{\prime},\\ -\log\left(\frac{\exp(u_{K^{\prime}})}{\sum_{y^{\prime}=1}^{K^{\prime}}\exp(u_ {y^{\prime}})-\max_{y^{\prime}\in[1,K^{\prime}-1]}\exp_{u_{y^{\prime}}}} \right)+\log\left(1-\frac{\exp(u_{K^{\prime}})}{\sum_{y^{\prime}=1}^{K^{\prime }}\exp(u_{y^{\prime}})-\max_{y^{\prime}\in[1,K^{\prime}-1]}\exp_{u_{y^{\prime} }}}\right),\;\text{else}.\end{array}\right.\]

A similar result can be deduced for the OvA-based surrogate by considering the following consistent multi-class loss with a strictly proper binary composite loss \(\xi\):

\[\phi_{\mathrm{OvA}}\left(\bm{u},y\right)=\left\{\begin{array}{l}\xi(u_{y})+ \sum_{y^{\prime}\neq y}\xi(-u_{y^{\prime}}),\;y\neq K^{\prime},\\ \xi(u_{K^{\prime}})-\xi(-u_{K^{\prime}}),\;\text{else}.\end{array}\right.\]

We then begin to prove their consistency. It is easy to verify that \(\phi_{\tilde{\psi}}\) is minimized when \(\tilde{\psi}(\bm{g}(\bm{x}))=\frac{p(y|\bm{x})}{1-p(K^{\prime}|\bm{x})}\), and we can conclude its consistency using the maxima-preserving property of \(\tilde{\psi}\).

For \(\phi_{\mathrm{OvA}}\), denote by \(\psi_{\mathrm{OvA}}\) the inverse link of \(\xi\). We can learn that \(\bm{g}^{*}(\bm{x})=\psi_{\mathrm{OvA}}(\frac{p(y|\bm{x})}{1-p(K^{\prime}|\bm{x })})\), and we can learn the consistency since \(\xi\) is strictly proper and thus \(\psi_{\mathrm{OvA}}\) is increasing. 

## Appendix E Proof of Theorem 3

Proof.: We first apply Pinsker's inequality. We can learn that:

\[R_{L_{\tilde{\psi}}}(\bm{g})-R_{L_{\tilde{\psi}}}^{*}\geq\mathbb{E}_{p(\bm{x}) }\left[\frac{1}{2}\|\tilde{\psi}_{1:K}(\bm{g}(\bm{x}))-\bm{\eta}(x)\|_{1}^{2}+ 2(\tilde{\psi}_{K+1}(\bm{g}(\bm{x})-\Pr(M=Y|X=\bm{x}))^{2}\right].\]

We can learn that \(R_{L_{\tilde{\psi}}}(\bm{g})-R_{L_{\tilde{\psi}}}^{*}\geq\mathbb{E}_{p(\bm{x}) }\left[\frac{1}{2}\|\tilde{\psi}_{1:K}(\bm{g}(\bm{x}))-\bm{\eta}(x)\|_{1}^{2}\right]\) immediately and learn that the bound for \(R_{01}\) following the analysis of cross-entropy loss in ordinary classification. Then we move to analyze the 0-1-deferral risk. We can further learn that :

\[R_{L_{\tilde{\psi}}}(\bm{g})-R_{L_{\tilde{\psi}}}^{*}\geq\mathbb{E}_{p(\bm{x} )}\left[\frac{1}{2}\|\tilde{\psi}_{1:K}(\bm{g}(\bm{x}))-\bm{\eta}(x)\|_{1}^{2}+ 2(\tilde{\psi}_{K+1}(\bm{g}(\bm{x}))-\Pr(M=Y|X=\bm{x}))^{2}\right]\] \[\geq\frac{1}{2}\mathbb{E}_{p(\bm{x})}\left[\|\tilde{\psi}_{1:K}( \bm{g}(\bm{x}))-\bm{\eta}(x)\|_{1}^{2}+(\tilde{\psi}_{K+1}(\bm{g}(\bm{x}))- \Pr(M=Y|X=\bm{x}))^{2}\right]\]

For any \(\bm{x}\), when \(\bm{g}(\bm{x})\) can induce the Bayes optimal solution for it, the excess risk is zero and the bound holds naturally. When it is not optimal, denote by \(\eta_{K+1}(\bm{x})=\Pr(M=Y|X=\bm{x})\). \(y^{\prime}\) is the dimension with the largest value of \(\bm{g}(\bm{x})\) and that of \(\bm{\eta}(\bm{x})\) is \(y^{\prime\prime}\). Then we can learn that:

\[\frac{1}{2}\left(\|\tilde{\psi}_{1:K}(\bm{g}(\bm{x}))-\bm{\eta}(x) \|_{1}^{2}+(\tilde{\psi}_{K+1}(\bm{g}(\bm{x}))-\Pr(M=Y|X=\bm{x}))^{2}\right)\] \[\geq\frac{1}{2}\left(\tilde{\psi}_{y^{\prime}}(\bm{g}(\bm{x}))- \eta_{y^{\prime}}(\bm{x})-\tilde{\psi}_{y^{\prime\prime}}(\bm{g}(\bm{x}))+ \eta_{y^{\prime\prime}}(\bm{x})\right)^{2}\] \[\geq\frac{1}{2}\left(\eta_{y^{\prime}}(\bm{x})-\eta_{y^{\prime \prime}}(\bm{x})\right)^{2}\]

The last step is obtained according to the maxima-preserving property. Further generalizing \(y^{\prime}\) and \(y^{\prime\prime}\) to be instance-dependent (\(y^{\prime}(\bm{x})\) and \(y^{\prime\prime}(\bm{x})\)), we can learn the following inequality using Jensen's inequality:

\[R_{L_{\tilde{\psi}}}(\bm{g})-R_{L_{\tilde{\psi}}}^{*}\geq\frac{1}{2}(\mathbb{ E}_{p(\bm{x})}[|\eta_{y^{\prime}}(\bm{x})-\eta_{y^{\prime\prime}}(\bm{x})|])^{2},\]

which concludes the proof since the second expectation term is \(R_{01}^{\perp}(\bm{g})-R_{01}^{\perp*}\) 

## Appendix F Details of Experiments

Details of Model and Optimizer:For methods on CIFAR-10, we use the 28-layer WideResNet that is the same as those used in Mozannar and Sontag [30], Charusaie et al. [9]. The optimizer is SGD with cosine annealing, where the learning rate is 1e-1 and weight decay is 5e-4. We conduct the experiments on 8 NVIDIA GeForce 3090 GPUs and the batch size is 1024 (128 on each GPU). The training epoch on CIFAR100 is set to 200.

For methods on CIFAR-10H, we train the same WideResNet on the fully-label CIFAR-10 dataset and then train the linear layer using the CIFAR-10H dataset. The optimizer is AdamW [] and the learning rate, batch size, epoch number are 1e-4, 128, 200. For methods on HateSpeech, we use a 384-dimension embedding and linear model in the experiment. The optimizer is SGD with cosine annealing and the learning rate, batch size, epoch number is 0.1, 128, 50. For methods on ImageNet-16H, we use the embedding generated by the pretrained DenseNet and linear model. The optimizer is Adam and the learning rate, batch size, epoch number is 1e-3, 1e-1, 100.

\begin{table}
\begin{tabular}{c|c c c|c c c} \hline \multirow{2}{*}{Method} & \multirow{2}{*}{Error} & \multirow{2}{*}{Coverage} & \multirow{2}{*}{ECE} & \multicolumn{3}{c}{Budgeted Error} \\ \cline{5-8}  & & & & 10\% & 20\% & 30\% \\ \hline S-SM & 3.82(0.02) & 41.28(0.14) & 6.64(0.22) & 50.25(0.57) & 41.00(0.81) & 31.47(0.37) \\ \hline S-OvA & 4.30(0.12) & 37.08(1.36) & 2.46(0.48) & 52.75(0.40) & 43.31(0.58) & 33.23(0.72) \\ \hline A-OvA & 4.00(0.11) & 92.75(0.24) & **0.95(0.16)** & 4.00(0.11) & 4.00(0.11) & 4.00(0.11) \\ \hline A-SM & **3.65(0.09)** & **94.20(0.37)** & **0.94(0.17)** & **3.65(0.09)** & **3.65(0.09)** & **3.65(0.09)** \\ \hline \end{tabular}
\end{table}
Table 2: Experimental results on CIFAR10H with for 5 trials. We report the mean(%)standard error(%) of related statistics.The best and comparable methods based on t-test at significance level \(5\%\) are highlighted in boldface.

\begin{table}
\begin{tabular}{c|c c c|c c c} \hline \multirow{2}{*}{Method} & \multirow{2}{*}{Error} & \multirow{2}{*}{Coverage} & \multirow{2}{*}{ECE} & \multicolumn{3}{c}{Budgeted Error} \\ \cline{5-8}  & & & & 10\% & 20\% & 30\% \\ \hline \multicolumn{8}{c}{Image Noise Type = “080”} \\ \hline S-SM & 10.63(1.34) & 22.59(1.59 & 18.31(3.22) & 66.58(3.91) & 60.41(2.98) & 53.33(2.79) \\ \hline S-OvA & 10.48(0.64) & 21.88(2.75) & 12.79(0.33) & 70.50(3.78) & 61.58(4.64) & 51.22(3.37) \\ \hline A-OvA & 10.36(1.09) & 25.86(3.56) & 8.69(0.63) & 70.83(1.25) & 61.32(1.70) & 52.26(0.95) \\ \hline A-SM & **7.94(0.85)** & **37.32(2.72)** & **7.39(0.23)** & **54.24(2.89)** & **45.33(2.91)** & **34.11(1.65)** \\ \hline \end{tabular}
\end{table}
Table 3: Experimental results on ImageNet-16H with for 5 trials. We report the mean(%)standard error(%) of related statistics.The best and comparable methods based on t-test at significance level \(5\%\) are highlighted in boldface.

The extra result on ImageNet with noise type "080" and the exact statistics for CIFAR-10H are shown in the tables in the appendix.

Details of Evaluation Metrics:The reported Error is the sample mean of \(\ell_{01}^{\perp}\), and Coverage is the ratio of undeferred samples. The ECE of expert accuracy is defined below:

\[\mathrm{ECE}=\sum_{i=1}^{N}b_{i}|p_{i}-c_{i}|,\]

where \(b_{i}\) is the ratio of predictions whose confidences fall into the \(i\)th bin. \(p_{i}\) is the average confidence and \(c_{i}\) is the average accuracy in this bin. We set the bin number to 15. The budgeted error is calculated as below: if the coverage is lower than \(1-x\%\), we will use the classifier's prediction instead of the expert's for those samples whose estimated expert accuracy is lower to make the coverage equal to \(1-x\%\).

## Appendix G Limitations and Broader Impact

Limitations:This work is designed for L2D without extra constraints on the number of expert queries. We believe that combining it with selective learning, i.e., adding explicit constraints on the ratio of deferred samples, can be a promising future direction.

Broader Impact:When applied in real-world applications, the frequency of expert queries may be imbalanced due to the performance differences of the expert among samples. This is a common impact shared by all the L2D methods. We believe that introducing fairness targets into L2D can be another promising direction.

## Appendix H Consistent Multi-Expert Extension

We provide a direct extension of our loss for the multi-expert setting and provide consistency analysis: Denote by the expert advice \(\bm{m}=[m_{1},\cdots,m_{M}]\in\mathcal{Y}\times\cdots\times\mathcal{Y}\). We first define an extended ASM:

**Definition 4**.: (Multi-expert asymmetric softmax parameterization) \(\tilde{\bm{\psi}}\) is called a _multi-expert asymmetric softmax function_ that for any \(K>1\) and \(\bm{u}\in\mathbb{R}^{K+M}\):

\[\tilde{\psi}_{y}^{M}(\bm{u})=\left\{\begin{array}{ll}\frac{\exp(u_{y})}{ \sum_{y^{\prime}=1}^{K}\exp(u_{y^{\prime}})},&y\not\in[K+1,K+M],\\ \frac{\exp(u_{y})}{\sum_{y^{\prime}=1}^{K+1}\exp(u_{y^{\prime}})+\exp(y)-\max_{ y^{\prime}\in\{1,\cdots,K\}}\exp(u_{y^{\prime}})},&\mathrm{else}.\end{array}\right.\] (10)

We can directly extend the property of single-expert ASM to this case:

**Proposition 2**.: (Properties of \(\tilde{\psi}^{M}\)) For any \(\bm{u}\in\mathbb{R}^{K+M}\):

(i). (Boundedness) \(\tilde{\psi}^{M}(\bm{u})\in\Delta^{K}\times[0,1]^{M}\),

(ii). (Maxima-preserving) \(\operatorname*{argmax}_{y\in\{1,\cdots,K+M\}}\tilde{\psi}_{y}^{M}(\bm{u})= \operatorname*{argmax}_{y\in\{1,\cdots,K+M\}}u_{y}\).

Then we give the following extension:

**Definition 5**.: (Multi-expert extension)

\[L_{\tilde{\psi}^{M}}(\bm{u},y,m)\!=\!-\log(\tilde{\psi}_{y}^{M} \left(\bm{u}\right))-\sum_{i=1}^{M}\left(\llbracket m_{i}\neq y\rrbracket\log(1 -\tilde{\psi}^{M}{}_{K+i}(\bm{u}))-\llbracket m_{i}=y\rrbracket\log(\tilde{ \psi}_{K+i}^{M}(\bm{u}))\right).\]

According to the position, we can simply give the characterization of \(L_{\tilde{\psi}^{M}}\)'s optimal solution:

\[\tilde{\psi}_{y}^{M*}(\bm{u})=\left\{\begin{array}{ll}p(y|\bm{x}),&y\not\in [K+1,K+M],\\ \text{Pr}(M_{y-K}|\bm{x}),&\mathrm{else}.\end{array}\right.\] (11)

According to the maxima-preserving, we can directly learn the consistency of our multiclass extension.

Estimation Error Bound

In this section, we give a routine analysis of our method's estimation error bound. Our proof of the estimation error bound is based on Rademacher complexity:

**Definition 6**.: (Rademacher complexity) Let \(Z_{1},\ldots,Z_{n}\) be \(n\) i.i.d. random variables drawn from a probability distribution \(\mu,\mathcal{H}=\{h:\mathcal{Z}\rightarrow\mathbb{R}\}\) be a class of measurable functions. Then the expected Rademacher complexity of \(\mathcal{H}\) is defined as

\[\mathfrak{R}_{n}(\mathcal{H})=\mathbb{E}_{Z_{1},\ldots,Z_{n}\sim\mu}\mathbb{ E}_{\bm{\sigma}}\left[\sup_{h\in\mathcal{H}}\frac{1}{n}\sum_{i=1}^{n}\sigma_{i}h \left(Z_{i}\right)\right]\]

where \(\bm{\sigma}=\{\sigma_{1},\ldots,\sigma_{n}\}\) are Rademacher variables taking the value from \(\{-1,+1\}\) with even probabilities.

First, let \(\mathcal{G}\subset\mathcal{X}\rightarrow\mathbb{R}^{K+1}\) be the model class and each of its dimension is constructed by \(\mathcal{G}_{y}\subset\mathcal{X}\rightarrow\mathbb{R}\). Then, we define the following scoring function space for L2D task:

\[\mathcal{L}\circ\mathcal{G}=\{h:(\bm{x},y,m)\mapsto L_{\tilde{\psi}}(\bm{g}( \bm{x}),y,m)|\bm{g}\in\mathcal{G}\}\]

So the Rademacher complexity of \(\mathcal{L}\circ\mathcal{G}\) given \(n\)\(i.i.d.\) samples drawn from distribution with density \(p(\bm{x},y,m)\) can be defined as

\[\mathfrak{R}_{n}(\mathcal{L}\circ\mathcal{G})=\mathbb{E}_{p(\bm{x},y,m)} \mathbb{E}_{\bm{\sigma}}\left[\sup_{g\in\mathcal{G}}\frac{1}{n}\sum_{i=1}^{n} \sigma_{i}h(\bm{x}_{i},y_{i},m_{i})\right].\]

Denote by \(\hat{R}_{L_{\tilde{\psi}}}(\bm{g})=\frac{1}{n}\sum_{i=1}^{n}L_{\tilde{\psi}}( \bm{g}(\bm{x}_{i}),y_{i},m_{i})\) the empirical risk and \(\hat{g}\) the empirical risk minimizer. We have the following theorem:

**Lemma 1**.: \[R_{L_{\tilde{\psi}}}(\hat{\bm{g}})-R_{L_{\tilde{\psi}}}(\bm{g}^{*})\leq 2 \sup_{\bm{g}\in\mathcal{G}}|\hat{R}_{L_{\tilde{\psi}}}(\bm{g})-R_{L_{\tilde{ \psi}}}(\bm{g})|\]

Proof.: \[R_{L_{\tilde{\psi}}}(\hat{\bm{g}})-R_{L_{\tilde{\psi}}}(\bm{g}^{*}) =R_{L_{\tilde{\psi}}}(\hat{\bm{g}})-\hat{R}_{L_{\tilde{\psi}}}( \hat{\bm{g}})+\hat{R}_{L_{\tilde{\psi}}}(\hat{\bm{g}})-R_{L_{\tilde{\psi}}}( \bm{g}^{*})\] \[\leq R_{L_{\tilde{\psi}}}(\hat{\bm{g}})-\hat{R}_{L_{\tilde{\psi}} }(\hat{\bm{g}})+\hat{R}_{L_{\tilde{\psi}}}(\bm{g}^{*})-R_{L_{\tilde{\psi}}}( \bm{g}^{*})\] \[\leq 2\sup_{\bm{g}\in\mathcal{G}}\left|\hat{R}_{L_{\tilde{\psi}}}( \bm{g})-R_{L_{\tilde{\psi}}}(\bm{g})\right|\]

which completes the proof. 

Then it is routing to get the estimation error bound with Rademacher complexity and McDiarmid's inequality:

**Theorem 4**.: Suppose \(L_{\tilde{\psi}}(\bm{g}(\bm{x}),y,m)\leq M\) and \(L_{\tilde{\psi}}\) is \(L-\)Lipschitz _w.r.t._\(\bm{g}(\bm{x})\), then with probability at least \(1-\delta\):

\[R_{L_{\tilde{\psi}}}(\hat{\bm{g}})-R_{L_{\tilde{\psi}}}(\bm{g}^{*})\leq 4 \sqrt{2}L\sum_{y=1}^{K+1}\mathfrak{R}_{n}(\mathcal{G}_{y})+4M\sqrt{\frac{\ln(2/ \delta)}{2n}}\]

Proof.: We will only discuss a one-sided bound on \(\sup_{\bm{g}\in\mathcal{G}}\left(\hat{R}(\bm{g})-R(\bm{g})\right)\) that holds with probability at least \(1-\frac{\delta}{2}\). Altering \((\bm{x}_{[}i],y_{i},m_{i})\) to \((\bm{x}^{\prime}_{[}i],y^{\prime}_{i},m^{\prime}_{i})\) and we can get a perturbed empirical risk \(\hat{R}^{\prime}(\bm{g})\). We can learn that

\[|\sup_{\bm{g}\in\mathcal{G}}\left(\hat{R}^{\prime}(\bm{g})-R(\bm{g})\right)- \sup_{\bm{g}\in\mathcal{G}}\left(\hat{R}(\bm{g})-R(\bm{g})\right)|\leq|\sup_{ \bm{g}\in\mathcal{G}}\left(\hat{R}^{\prime}(\bm{g})-\hat{R}(\bm{g})\right)| \leq\frac{M}{n}.\]

Then we can use Mcdiarmids' inequality and vector-valued Talagrand inequality to learn:

\[\sup_{\bm{g}\in\mathcal{G}}\left|\hat{R}_{L_{\tilde{\psi}}}(\bm{g})-R_{L_{ \tilde{\psi}}}(\bm{g})\right|\leq 2\sqrt{2}L\sum_{y=1}^{K+1}\mathfrak{R}_{n}( \mathcal{G}_{y})+2M\sqrt{\frac{\ln(2/\delta)}{2n}}\]Using the lemma 1 and we can conclude our proof.