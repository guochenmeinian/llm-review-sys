# Online Ad Procurement in Non-stationary Autobidding Worlds

 Jason Cheuk Nam Liang

MIT

jcnliang@mit.edu

&Haihao Lu

University of Chicago

haihao.lu@chicagobooth.edu

&Baoyu Zhou

University of Michigan

zbaoyu@umich.edu

###### Abstract

Today's online advertisers procure digital ad impressions through interacting with autobidding platforms: advertisers convey high level procurement goals via setting levers such as budget, target return-on-investment, max cost per click, etc. Then ads platforms subsequently procure impressions on advertisers' behalf, and report final procurement conversions (e.g. click) to advertisers. In practice, advertisers may receive minimal information on platforms' procurement details, and procurement outcomes are subject to non-stationary factors like seasonal patterns, occasional system corruptions, and market trends which make it difficult for advertisers to optimize lever decisions effectively. Motivated by this, we present an online learning framework that helps advertisers dynamically optimize ad platform lever decisions while subject to general long-term constraints in a realistic bandit feedback environment with non-stationary procurement outcomes. In particular, we introduce a primal-dual algorithm for online decision making with multi-dimensional decision variables, bandit feedback and long-term uncertain constraints. We show that our algorithm achieves low regret in many worlds when procurement outcomes are generated through procedures that are stochastic, adversarial, adversarially corrupted, periodic, and ergodic, respectively, without having to know which procedure is the ground truth. Finally, we emphasize that our proposed algorithm and theoretical results extend beyond the applications of online advertising.

## 1 Introduction

Automated bidding (or autobidding for short) has become the dominant mode for advertisers to procure digital ad inventories and impressions, contributing to more than \(\$120\) billion dollar ad spend in 2022 and more than \(90\%\) of total online ad transaction volumes [2, 1]. In an autobidding platform, advertisers only need to convey their high-level procurement goals for an ad campaign to the platform, which then takes charge of procuring ads on advertisers' behalf. Such procurement goals are communicated to a platform through platform _levers_, which are adjustable parameters that advertisers can control to influence the bidding process and campaign performance. To exemplify, Figure 1 displays certain several levers presented on the Google Ads interface, where an advertiser can set per-campaign budgets, target cost-per-actions, campaign duration, campaign schedules, targeting, etc; similar examples are also shown in related literature [21].

As the primary avenue for advertisers to run ad campaigns on autobidding platforms and influence ad conversion outcomes (e.g., clicks), making efficient lever decisions is vital to advertisers to achieve their procurement objectives. However, advertisers face many challenges in practice when optimizing for lever decisions, namely high-dimensional decision making under long-term constraints, non-stationary autobidding environments, and limited procurement feedback.

High-dimensional decision making and long-term constraint satisfaction.Making multiple lever decisions involves evaluating numerous possible combinations of lever configurations, which is computationally intensive and time-consuming in real-time decision making setups. Also, advertisers need to understand the potential interactions and dependencies between levers, as adjusting one lever may have unintended consequences or interactions with other levers, making it challenging topredict the overall impact of adjustments accurately. Furthermore, advertisers may need to satisfy certain long-term constraints over time, e.g., limiting total spend under a budget, or achieving certain return-on-investment targets. Hence in addition to analyzing the interactions between different levers, advertisers also need to concern long-term consequences of making certain lever decisions.

**Limited feedback on procurement outcome and constraints.** Despite the fact that autobidding via lever decisions greatly simplifies advertisers' ad procurement process as they no longer have to handle the intricacies of procuring individual ad impressions, the procurement procedure becomes a black box for advertisers, as advertisers only have limited visibility into the specific details of how the platform executes ad placement processes. This lack of transparency can make it challenging for advertisers to control the nuances of their campaign execution through lever decisions, and it amplifies the complexity to conduct counterfactual analyses on outcomes for past lever decisions.

**Many non-stationary autobidding worlds.** Autobidding procurement environments are highly non-stationary, as a wide spectrum of latent factors in online ad marketplaces may greatly vary procurement outcomes of the same lever decisions in different time periods. These latent factors include but are not limited to changing user preferences, seasonality effects, shifts in market trends, occasional malfunctions in autobidding platforms, etc. These dynamics may influence how users interact with different types of ads, which necessitates continuous adjustment of lever decision strategies to adapt to current and future market conditions.

To address these challenges, in this work we answer the following questions: _How should an advertiser dynamically set multiple levers to optimize conversion outcomes subject to long-term constraints under limited information? And can she run a unified algorithm that can perform well while being agnostic to many types of non-stationary autobidding procurement environments?_

Motivated by these questions, in this work we study an advertiser's online high-dimensional lever decision problem with long-term constraints under limited bandit feedback in many non-stationary worlds. We summarize our main contributions as followed:

**1. Modelling online lever decisions in many worlds using online constrained optimization with bandit function-valued feedback and uncertain constraints (Section 2)**. We cast the advertiser lever decision problem as an online constrained optimization with bandit function-valued feedback and uncertain constraints, where functions at which (lever) decisions are evaluated correspond to the conversion and constraint functions in our autobidding setup. Further, we model real-world non-stationarity in autobidding environments as possibly time-varying distributions from which conversion and constraint functions are sampled, and then further applied to lever decisions. Under this model, we discuss five different input procedures from which the sequence of functional distributions are sampled to model stochastic, adversarial, corrupted, periodic, and ergodic environments; see Section 2.2 for more details. To the best of our knowledge, from a modelling perspective this is the first work to model a high-dimensional lever decision problem in practical non-stationary autobidding worlds.

**2. Proposing a constrained bandit optimization algorithm universally applicable to many worlds (Section 3).** We develop a unified bandit optimization algorithm with robust performance guarantees across different worlds. Our algorithm incorporates four key designs to handle bandit function-valued feedback and unknown non-stationary environments. 1. we utilize dual descent to update dual variables associated with long-term constraints and decouple decisions over time; 2. we employ a primal-ascent-based bandit online convex optimization (BOCO) approach to make (primal) lever decisions to cope with bandit function valued feedback; 3. we implement an exponential weights

Figure 1: Example levers on the Google Ads interface to create digital advertising campaigns.

expert algorithm on top of primal-ascent BCOO, where each expert corresponds to a different primal ascent step size. This enables our algorithm to adapt to the optimal primal ascent step size for each world without prior knowledge on which world we are in; 4. our algorithm dynamically checks for realized constraint violations and applies "safe lever decisions" to ensure long-term constraint satisfaction. For further details, we refer the readers to Algorithm 1 in Section 3.

**3. Analyzing the performance of proposed algorithms in many worlds (Section 4).** We present theoretical analysis (Theorem 4.2) on the regret bound of the proposed algorithm, and we show that our unified algorithm can achieve reasonable regret bounds with all five input procedures. These regret bounds are summarized in the following Table 1.

The parameters \((\delta,\xi,\text{OPT}(\mathcal{P}_{1:T}),q,\kappa)\) are formally defined in Section 2.2 and Theorem 4.2. Finally, in Section 5 we remark all results are applicable to other problems.

### Related works.

**Autobidding.** In an autobidding framework, there is a considerable body of works that study the price of anarchy, which aims to improve worst case individual or total advertiser welfare guarantees w.r.t. the optimal welfare via mechanism design frameworks; see e.g. [23, 7, 20, 38, 22]. We remark that this line of work does not concern developing online learning algorithms. On the other hand, numerous works have concentrated on developing online bidding algorithms for repeated ad auctions [41, 10, 31, 30], as well as designing repeated selling mechanisms for ad impression allocation; see [12, 27] and references therein. However, as discussed in the introduction, autobidding platforms conduct bidding on behalf of advertisers while keeping bidding and selling mechanism details undisclosed. In this study, we treat the bidding procedure and selling mechanism as a black box and directly model bidding and auction outcomes using conversion functions; see Section 2. To the best of our knowledge, the most pertinent work to this paper is [21], which explores a similar ad procurement problem by optimizing levers within a bandit environment. However, this work solely focuses on the stochastic world and optimizing a single lever (i.e., a 1-dimensional decision space). In contrast, our paper develops a unified algorithm capable of making high-dimensional lever decisions in many worlds.

**Online convex optimization.** In Section 2, we cast the advertiser's online learning problem of interest to a high-dimensional bandit online convex optimization problem with uncertain long-term constraints, and develop an algorithm that yields good performance guarantees under different procedures from which the objective and constraint functions are generated. There has been a rich line of works that study bandit convex optimization with no long-term constraints in stochastic and adversarial worlds [25, 32, 42, 17, 44], as well as works that study (full-information feedback) online convex optimization with long-term constraints [36, 33, 43, 35]. Further, works that study both bandit feedback and long-term constraints either consider single-dimensional (such as multi-arm bandits with constraints) [40, 6, 4, 24], or consider static regret (i.e., benchmarking performance to that of a single optimal action) [13, 16, 14, 37]. This paper distinguishes itself from these two streams of works by considering high-dimensional decisions as well as dynamic regret, i.e., comparing to the best sequence of actions instead of a single action; see Eq. (1). Finally, all aforementioned works only study algorithms in stochastic or adversarial setups, whereas in this work we go beyond these two worlds and address more complex learning environment such as periodic, corrupted, ergodic, and finite switching. To the best of our knowledge, the only related work that develops a universal algorithm under "many world" setups is [10]. However, [10] considers a full-information scenario where the online decisions in period can be made after observing realized objective and constraint functions during that period. In this work, we present an efficient algorithm to handle bandit feedback.

**Notation.** For any vector \(\bm{z}\in\mathbb{R}^{d}\), let \(\|\bm{z}\|\) be its Euclidean norm. Denote \(\mathbb{B}=\{\bm{z}\in\mathbb{R}^{d}:\|\bm{z}\|\leq 1\}\) as the \(d\)-dimensional unit ball centered at \(\bm{0}\), and let \(\mathbb{S}=\{\bm{z}\in\mathbb{R}^{d}:\|\bm{z}\|=1\}\) be the unit sphere. For any set \(\mathcal{S}\), let \(U(\mathcal{S})\) be the uniform distribution over \(\mathcal{S}\). Let \(\bm{e}\) denote the vector whose components

\begin{table}
\begin{tabular}{c c c c c} \hline \hline Stochastic & \(\delta\)-corrupted & Adversarial & Periodic & Ergodic \\ \hline \(\mathcal{O}(T^{\frac{3}{4}})\) & \(\mathcal{O}(T^{\frac{3}{4}}+\delta)\) & \(\begin{pmatrix}1-\frac{1}{\xi}\end{pmatrix}\text{OPT}(\mathcal{P}_{1:T})\\ &+\tilde{\mathcal{O}}\left(A\cdot T^{\frac{3}{4}}\right)\end{pmatrix}\) & \(\mathcal{O}(T^{\frac{3}{4}}+q\sqrt{T})\) & \(\mathcal{O}(T^{\frac{3}{4}}+\kappa\sqrt{T})\) \\ \hline \hline \end{tabular}
\end{table}
Table 1: \(T\)-period regret bounds for Algorithm 1 under different input models. Here \(A>0\) is some algorithm dependent factor which we will later specify in Section 4.

are all 1's, and \(\bm{e}_{j}\) be the unit vector whose \(j\)'th position is 1. We use \(\mathcal{O}\) notation to represent the asymptotic order of a term when the period \(T\to\infty\) and ignore the \(\log T\) terms.

## 2 Autobidding with bandit feedback in many worlds (input models)

### Autobidding as a bandit online optimization with long-term uncertain constraints

Consider an advertiser repeatedly interacting with an ad platform over \(T\in\mathbb{N}\) periods, where each period can be interpreted as a single ad campaign that is run on the platform. During each period \(t\in[T]\), the advertiser makes \(d\geq 1\) lever decisions denoted as \(\bm{x}_{t}\in\mathcal{X}\subseteq\mathbb{R}^{d}\), e.g., setting the per-campaign budget, campaign duration, per-campaign target return-on-investment, and max spend per conversion; see Figure 1 for example lever decisions in practice. Here, \(\mathcal{X}\) is some compact and convex decision set whose diameter is \(D=\sup_{(\bm{x},\bm{x}^{\prime})\subseteq\mathcal{X}}\lVert\bm{x}-\bm{x}^{ \prime}\rVert\). For simplicity, assume \(\bm{0}\in\mathcal{X}\) so \(\lVert\bm{x}\rVert\leq D\) for any \(\bm{x}\in\mathcal{X}\). After the lever decisions \(\bm{x}_{t}\) are made the campaign is fully executed via autobidding, the advertiser observes bandit feedback for her campaign outcomes: she only observes her realized conversion \(f_{t}(\bm{x}_{t})\in\mathbb{R}_{\geq 0}\) (e.g., number of clicks on her ads), as well as some constraint balance \(\bm{g}_{t}(\bm{x}_{t})\in\mathbb{R}^{K}\). The conversion and constraint functions \((f_{t},\bm{g}_{t})\) are sampled from some (possibly infinite) support \(\mathcal{S}\) according to distribution \(\mathcal{P}_{t}\in\Delta(\mathcal{S})\) (we will discuss how \(\mathcal{P}_{t}\)'s are generated by nature in Section 2.2). Using the notation \(\mathcal{P}_{1:T}=\left(\mathcal{P}_{t}\right)_{t\in[T]}\) the advertiser's hindsight optimization problem is

\[\text{OPT}(\mathcal{P}_{1:T})=\max_{\bm{x}\in\mathcal{X}^{T}}~{}\sum_{t\in[T] }\mathbb{E}_{\mathcal{P}_{t}}[f_{t}(\bm{x}_{t})]~{}~{}\text{s.t.}~{}\sum_{t\in[ T]}\mathbb{E}_{\mathcal{P}_{t}}[g_{k,t}(\bm{x}_{t})]\geq 0\quad k=1\ldots K\,.\] (1)

Here, we use a constraint function \(g_{k,t}:\mathcal{X}\to\mathbb{R}\) to characterize general performance metrics of the advertiser for her ad campaigns. In the following, we present several examples for constraint functions that are widely used in practice or studied in literature. For illustrative purposes, we assume \(x_{t,1}=\bm{e}_{1}^{\top}\bm{x}_{t}\) (i.e., the first lever) represents the per-campaign budget for the \(t\)'th campaign.

* _Long-term budget constraint._ The advertiser has a total budget \(BT>0\). Then by letting constraint function \(g_{k,t}(\bm{x})=B-x_{t,1}\), we have \(\sum_{t\in[T]}g_{k,t}(\bm{x}_{t})\geq 0\Longrightarrow\sum_{t\in[T]}x_{t,1} \leq BT\), which means total campaign spent over \(T\) periods (assuming each campaign fully depletes the campaign budget) must be less than the advertiser's total budget \(BT\).
* _Long-term return-on-investment constraint._ The advertiser intends to safeguard a long-term return-on-investment \(\gamma>0\), i.e., she attains a long-term average of at least \(\gamma\) conversions per dollar spent. Then by considering \(g_{k,t}(\bm{x})=f_{t}(\bm{x})-\gamma x_{t,1}\), we have \(\sum_{t\in[T]}g_{k,t}(\bm{x}_{t})\geq 0\Longrightarrow\sum_{t\in[T]}f_{t}(\bm{x}_ {t})\geq\gamma\sum_{t\in[T]}x_{t,1}\), which means total conversion over \(T\) periods is at least \(\gamma\) times total spend.

Finally, we make the following mild assumptions on conversion and constraint functions.1

Footnote 1: These assumptions are justified in many related works in autobidding; see [21; 14] and references therein. For example, [21] shows that the conversion function is concave and piecewise-linear when autobidding platforms procure ad impressions on behalf of advertisers in standard second price or VCG auctions.

**Assumption 2.1** (Mild assumptions on conversion and constraint functions).: _For any \((f,\bm{g})\in\mathcal{S}\), \(f\), \(g_{1}\ldots g_{K}\) are all bounded concave functions, i.e., we assume \(\sup_{\bm{x}\in\mathcal{X}}\lVert\bm{g}(\bm{x})\rVert_{\infty}\leq G\) and \(\sup_{\bm{x}\in\mathcal{X}}\left\lVert f(\bm{x})\right\rVert\leq\bar{F}\) for some \(\bar{G}\), \(\bar{F}<\infty\). Moreover, \(f\) and \(\bm{g}\) are \(L\)-Lipschitz, i.e., for any \(\{\bm{x},\bm{x}^{\prime}\}\subseteq\mathcal{X}\), we have \(\left|f(\bm{x})-f(\bm{x}^{\prime})\right|\leq L\lVert\bm{x}-\bm{x}^{\prime}\rVert\) and \(\lVert\bm{g}(\bm{x})-\bm{g}(\bm{x}^{\prime})\rVert\leq L\lVert\bm{x}-\bm{x}^{ \prime}\rVert\). Furthermore, there exists \((f,\bm{g})\in\mathcal{S}\) such that \(\min_{\bm{x}\in\mathcal{X}}\min_{k\in[K]}g_{k}(\bm{x})<0\)._

### Five input models characterizing many autobidding worlds

In this subsection, we describe structural properties of the input distribution sequence \(\mathcal{P}_{1:T}\), and shed light on how we utilize various properties to model a wide spectrum of autobidding environments (called worlds) such as time-varying user preferences, seasonality, shifts in market trends, etc., that may potentially lead to different procurement outcomes for the same ad campaign lever decisions.

**Stochastic**: There exists some probability distribution \(\mathcal{P}\in\Delta(\mathcal{S})\) such that \(\mathcal{P}_{1}=\ldots=\mathcal{P}_{T}=\mathcal{P}\). This stochastic world represents a stationary autobidding environment where the underlying latent factors influencing user behaviors (and correspondingly conversion results) remain constant over time; see [31; 9; 21].

\(\delta\)**-corrupted.** There exists \(\mathcal{P}\in\Delta(\mathcal{S})\) as well as \(\delta\in\mathbb{N}\) periods \(\mathcal{T}=\{\tau_{1}\dots\tau_{\delta}\}\subset[T]\) such that \(\mathcal{P}_{t}=\mathcal{P}\) for all \(t\notin\mathcal{T}\). This \(\delta\)-corrupted input sequence represents occasional anomalies in the autobidding environment that may be caused by systematic malfunctions in the autobidding platform, or deliberate attempts by malicious competitors to exploit the system for their own benefit; e.g., some competitors may engage in click fraud to inflate the number of clicks on our ads to exhaust our budget or generate false data to manipulate autobidding algorithms (for example, see [29]).

**Adversarial.**\(\mathcal{P}_{1:T}\) is adversarially chosen by nature before the process starts, and the distributions over time can possibly be non-identical and/or dependent. This adversarial world can be viewed a hypothetical extreme case for the \(\delta\)-corrupted world where each period the procurement outcomes can potentially be corrupted by an adversary. Adversarial input sequences have been widely studied in the literature to assess algorithmic performances in worst-case scenarios; see [3, 30].

**Periodic.** There exists period length \(q\in\mathbb{N}\) such that \(T=cq\) for some integer \(c\geq 2\) with \(\mathcal{P}_{1:T}\) satisfying \(\mathcal{P}_{1:q}=\mathcal{P}_{q+1:2q}=\dots=\mathcal{P}_{(c-1)q+1:T}\). This periodic world captures regular cyclic patterns or fluctuations in the user behavior over specific time intervals; e.g., seasonality, day-of-week patterns, and time of a day.

**Ergodic.**\(\mathcal{P}_{1:T}\) is an ergodic process (e.g., an irreducible and aperiodic Markov chain or stationary autoregressive processes), where there exists some \(\kappa>0\) and a stationary distribution such that the distance between \(\kappa\)-step transition probabilities and this stationary distribution decreases exponentially fast in \(\kappa\). Mathematically, given the input distribution sequence \(\mathcal{P}_{1:T}\), denote \(\mathcal{P}_{(t+\kappa)|[t-1]}\) as the conditional distribution of \((f_{t+\kappa},\bm{g}_{t+\kappa})\) conditioned on the realizations \(\{(f_{r},\bm{g}_{r})\}_{\tau\in[t]}\). Then, for the ergodic input model there exists a stationary distribution \(\widetilde{\mathcal{P}}\in\Delta(\mathcal{S})\) and absolute constant \(R>0\) such that

\[\sup_{\{(f_{t},\bm{g}_{t})\}_{t\in[T]}\in\mathcal{S}^{T}}\sup_{t\in[T-\kappa]} \|\mathcal{P}_{(t+\kappa)|[t-1]}-\widetilde{\mathcal{P}}\|_{TV}\leq\delta:=R \exp(-\kappa)\;;\] (2)

We remark that exponentially decaying ergodic models have been studied widely in the context of online optimization; see e.g. [10, Section 5.2] for further discussions. To make the problem of interest tractable, we assume \(\kappa>\log(T)\). Intuitively, an ergodic input sequence signifies that the procurement outcomes in close time proximity are correlated, which is commonly observed in real-world autobidding systems, as they often involve iterative processes that enable procurement algorithms (operated on behalf of advertisers) to converge to a stable state; see details in [9, 28].

### Minimizing regret subject to long-term constraints with a universal algorithm

In this work, we take the perspective of an advertiser making repeated lever decisions as described in Section 2.1. We focus on designing a single online algorithm that determines a lever decision \(\bm{x}_{t}\in\mathcal{X}\) in each period \(t\) with the goal to minimize regret \(\mathcal{R}_{T}\) (defined as follows) under any input sequence \(\mathcal{P}_{1:T}\) while satisfying long-term constraints

\[\mathcal{R}_{T}=\text{OPT}(\mathcal{P}_{1:T})-\sum_{t\in[T]}\mathbb{E}\left[f _{t}(\bm{x}_{t})\right]\ \text{ and }\sum_{t\in[T]}\mathbb{E}\left[\bm{g}_{t}(\bm{x}_{t})\right]\geq\bm{0}.\] (3)

Here, the expectation is taken w.r.t. randomness from the input sequence as well as any randomness in our algorithm. We highlight that our desired policy should be agnostic to the input model as well as the input sequence \(\mathcal{P}_{1:T}\). We remark that our work distinguishes itself from related work that study solely stochastic and/or adversarial input models, as we aim to design a universal algorithm that achieves salient performance over any input model described in Section 2.2.

## 3 A universal constrained BOCO framework for many worlds

In this section, we focus on designing an algorithm that achieves low regret (per Eq. (3)) while maintaining long-term constraint satisfaction in any world described in Section 2.2, without having to know which world we are in. We first highlight three main challenges for our problem of interest.

**Dynamic benchmark lever sequence and unknown input sequence \(\mathcal{P}_{1:T}\).** Recall the hindsight optimal problem in Eq. (1), with which we are comparing our algorithm's performance to the optimal sequence of lever decisions over time given any input sequence \(\mathcal{P}_{1:T}\), instead of comparing to a single optimal lever decision as in many related works; e.g., see [15] and references therein. This dynamic optimal sequence presents a very strong benchmark and makes learning very difficult as we (ideally) need to account for variations in the underlying non-stationary ground truth input sequence \(\mathcal{P}_{1:T}\). Nevertheless, we do not know the input sequence \(\mathcal{P}_{1:T}\) in advance, nor do we know in which world the sequence belongs (Section 2.2).

Bandit function-value (zeroth-order) feedback.Our setup concerns a bandit function-value feedback model, where the realized conversion and constraint functions in each period, namley \(f_{t}:\mathcal{X}\to\mathbb{R}_{\geq 0}\) and \(\bm{g}_{t}:\mathcal{X}\to\mathbb{R}^{K}\) are never revealed to us, and we can only access their function values at our single lever decisions during the period. We also contrast our setup with a "two-point feedback" setup in online convex optimization literature, where in each period one can access function values twice (see [44] and references therein). Using the context of our setup, in a "two-point feedback" after nature samples \(f_{t}:\mathcal{X}\to\mathbb{R}_{\geq 0}\) and \(\bm{g}_{t}:\mathcal{X}\to\mathbb{R}^{K}\) from \(\mathcal{P}_{t}\), we can observe the values for two lever decisions \(\{\bm{x}_{t}^{(1)},\bm{x}_{t}^{(2)}\}\subseteq\mathcal{X}\), namely \((f_{t}(\bm{x}_{t}^{(1)}),\bm{g}_{t}(\bm{x}_{t}^{(1)}))\) and \((f_{t}(\bm{x}_{t}^{(2)}),\bm{g}_{t}(\bm{x}_{t}^{(2)}))\).

Universal algorithm for many worlds.Instead of developing separate algorithms that cope with each individual world described in Section 2.1, we aim to develop a single universal algorithm that performs well in every world without exploiting any knowledge on the realized input sequence \(\mathcal{P}_{1:T}\) or its structural properties.

The key component of our algorithm to handle the aforementioned challenges is the following Lagrangian function: for any \(f_{t}:\mathcal{X}\to\mathbb{R}_{\geq 0}\) and \(\bm{g}_{t}:\mathcal{X}\to\mathbb{R}^{K}\), let's define \(\mathcal{L}_{t}:\mathcal{X}\times\mathbb{R}_{\geq 0}^{K}\to\mathbb{R}\) such that

\[\mathcal{L}_{t}(\bm{x},\bm{\lambda})=f_{t}(\bm{x})+\bm{\lambda}^{\top}\bm{g}_ {t}(\bm{x})\;.\] (4)

Surrounding this Lagrangian function, our proposed algorithm is formally stated in Algorithm 1 with four key components described as follows.

1. Dual descent to decouple decisions across time.As our lever decisions over time should be somewhat intertwined with one another due to the presence of long term constraints, we decouple this cross-period dependency by lagrangifying the hindsight problem in Eq. (1) w.r.t. some benchmark dual variables. In each period \(t\), we maintain an estimate of dual variables \(\bm{\lambda}_{t}\in\mathbb{R}_{\geq 0}^{K}\) corresponding to each of our \(K\) constraints, and adopt a standard dual descent approach to dynamically adjust these estimates; see Eq. (9). In particular, after observing \((f_{t}(\bm{x}_{t}),\bm{g}_{t}(\bm{x}_{t}))\), we update our dual variable by projecting each coordinate of \(\bm{\lambda}_{t}-\eta\nabla_{\bm{\lambda}}\mathcal{L}_{t}(\bm{x}_{t},\bm{ \lambda}_{t})=\bm{\lambda}_{t}-\eta\bm{g}_{t}(\bm{x}_{t})\) onto some interval \([0,\frac{\bar{F}}{\beta}]\) where \(\eta>0\) is the dual descent step size, \(\bar{F}\) is the maximum achievable conversion, and \(\beta>0\) is some "safety buffer" to be defined later.

2. Primal ascent to handle bandit function-valued feedback in many worlds.Given a dual variable \(\bm{\lambda}_{t}\) during period \(t\), standard optimization frameworks suggest optimizing primal decisions (i.e., lever decisions) by setting \(\bm{x}_{t}=\arg\max_{\bm{x}\in\mathcal{X}}\mathbb{E}_{\mathcal{P}_{t}}[ \mathcal{L}_{t}(\bm{x},\bm{\lambda}_{t})]\). However, in our setting this is not possible due to the bandit function-valued feedback structure: we do not know \(f_{t}(\cdot)\), \(\bm{g}_{t}(\cdot)\) nor \(\mathcal{P}_{t}\), and hence cannot optimize for \(\mathbb{E}_{\mathcal{P}_{t}}[\mathcal{L}_{t}(\cdot,\bm{\lambda}_{t})]\). To handle this, we view the primal decision problem as a _bandit online convex optimization problem (BOCO)_ where the adversarial objective functions are \(\mathcal{L}_{t}(\cdot,\bm{\lambda}_{t})\), and run a BOCO algorithm to make primal lever decisions in each period.

Mathematically, we define the BOCO objective function \(h_{t}:\mathcal{X}\to\mathbb{R}\) as

\[h_{t}(\bm{x})=\mathcal{L}_{t}(\bm{x},\bm{\lambda}_{t})=f_{t}(\bm{x})+\bm{ \lambda}_{t}^{\top}\bm{g}_{t}(\bm{x})\;.\] (5)

Then, the BOCO algorithm constructs an estimate \(\bm{\nabla}_{t}\) of \(\bm{\nabla}h_{t}(\bm{x})\) based on a random perturbation approach with perturbation parameter \(\rho>0\) (see Eq. (7) and [25] for more details in random perturbations methods to estimate gradients). Next, the BOCO algorithm computes primal decision \(\bm{x}_{t}\) by an ascent type update, i.e., projecting \(\bm{x}_{t-1}+\gamma\bm{\nabla}_{t}\) back onto \(\mathcal{X}\), where \(\gamma>0\) is the primal ascent step size; see Eq. (9). The loss we incur by running BOCO primal update instead of setting \(\arg\max_{\bm{x}\in\mathcal{X}}\mathbb{E}_{\mathcal{P}_{t}}[h_{t}(\bm{x}_{t})]\) in the full information setting depends on the specific type of world we are in, i.e., the input sequence \(\mathcal{P}_{1:T}\). We later show in Lemma 4.3 that input sequences in each world induce some comparator sequence \(\bm{y}_{1}\ldots\bm{y}_{T}\in\mathcal{X}\), so the conversion loss due to BOCO primal ascent updates can be characterized as some BOCO "dynamic" regret \(\sum_{t\in[T]}h_{t}(\bm{y}_{t})-h_{t}(\bm{x}_{t}^{BOCO})\). Later in Lemma 4.6, we show that our BOCO algorithm achieves low dynamic regret against any comparator sequence \(\bm{y}_{1}\ldots\bm{y}_{T}\in\mathcal{X}\).

3. Choosing primal ascent step sizes from expert advice for different worlds.Different worlds (and correspondingly different BOCO comparator sequences) may require different "optimal" BOCO primal ascent step sizes in order to achieve optimal regret guarantees. Since we are unaware of the world from which the input sequence \(\mathcal{P}_{1:T}\) is generated, on top of our primal ascent procedure we run a meta "expert" algorithm that allows us to adaptively approximate optimal step sizes in each world. In particular, we consider \(N\) experts, each corresponding to a primal ascent step size \(\gamma_{i}>0\)and produce independent lever decision based on primal ascent with her own step size; see Eq. (9). Then, we dynamically maintain exponential weights \(\bm{w}_{t}\in\Delta_{N}\) in the \(N\)-dimensional simplex over \(N\) experts, based on their past performance measured by some surrogate loss function defined in Eq. (8). Finally we set the weighted average primal decision over all experts as our ultimate primal decision; see Eq. (6). We later show in Lemma A.3 that such exponentially weighted average BOCO primal ascent decisions achieve low conversion loss compared to the "optimal" BOCO primal ascent expert (i.e., step size) in every world, without having to know which world we are in.

**4. Constraint violation check to ensure constraint satisfaction.** To ensure long-term constraint satisfaction, we maintain a constraint balance \(B_{k,t}=\sum_{\tau\in[t-1]}g_{k,t}(\bm{x}_{\tau})\) for each constraint \(k\in[K]\) that keeps track of our deviation from satisfying the constraint. To make our problem tractable, we make the assumption that there is always a "safe action" with which we are always guaranteed to attain some small positive constraint balance.2

Footnote 2: The existence of a safe action is not unnatural, and is studied in many literature; see [24, 21, 14]. For instance, letâ€™s recall our examples for constraint functions in Section 2.1 and assume we only have a long-term budget constraint. Then the corresponding safe action for the constraint function \(g_{k,t}(\bm{x}_{t})=B-x_{t,1}\) would be any \(\bm{x}_{t}\) whose first entry \(x_{t,1}=0\) so that we acquire positive constraint value \(B>0\).

**Assumption 3.1** (Safe action).: _Assume there exists some \(\bar{\beta}>0\) and an action \(\widetilde{\bm{x}}_{\beta}\in\mathcal{X}\) such that for any \((f,\bm{g})\in\mathcal{S}\), we have \(g_{k}(\widetilde{\bm{x}}_{\beta})>\bar{\beta}\) for all \(k\in[K]\)._

With the constraint balance, in each period before making a lever decision, we check the following: if by playing the safe action in all future rounds nearly violates constraints (step 2 in Algorithm 1), then we hard stop our algorithm and play the safe action in all subsequent rounds. We remark that we do not necessarily know the constraint function value lower bound \(\bar{\beta}>0\) in Assumption 3.1. However, we show later in Theorem 4.1 that by considering any safety buffer \(\beta<\bar{\beta}\) (e.g., taking \(\beta=1/\log(T)\) for large enough \(T\)), we are hard stopping more conservatively, and thus maintain constraint satisfaction. Note that our final regret scales with \(\frac{1}{\beta^{2}}\); see Lemma 4.6.

```
0: Initial dual variable \(\bm{\lambda}_{1}=\bm{0}\), primal expert solutions \(\widetilde{\bm{x}}_{1}^{i}=\bm{0}\) for any \(i\in[N]\); perturbation parameter \(\rho>0\) and \(\alpha\in(0,1)\); primal ascent step sizes for experts \(\{\gamma_{1},\ldots,\gamma_{N}\}>0\); dual descent step size \(\eta\); learning rate of the meta-algorithm \(\epsilon\); initial expert weights \(w_{i,1}=1\) for all \(i\in[N]\); safety buffer \(\beta>0\).
1: Initialize constraint balance \(B_{k,1}=0\) for all \(k\in[K]\)
2:while {for all \(k\in[K]\), \(B_{k,t}-\bar{G}+\beta(T-t-1)\geq 0\)}do
3: Compute exponentially weighted average forecaster: \[\widetilde{\bm{x}}_{t}=\frac{1}{\sum_{i\in[N]}w_{i}^{i}}\sum_{i\in[N]}w_{i}^{i }\widetilde{\bm{x}}_{t}^{i}\] (6)
4: Sample \(\bm{u}_{t}\sim U(\mathrm{S})\) uniformly at random from the unit sphere.
5: Set \(\bm{x}_{t}=\widetilde{\bm{x}}_{t}+\rho\bm{u}_{t}\) and observe \(f_{t}(\bm{x}_{t})\) and \(\bm{g}_{t}(\bm{x}_{t})\). Update \(B_{k,t+1}=B_{k,t}+g_{k,\ell}(\bm{x}_{t})\).
6: Construct gradient estimate for \(\nabla_{\bm{x}}\mathcal{L}(\bm{x}_{t},\bm{\lambda}_{t})\) \[\bm{\nabla}_{t}=\tfrac{d}{\rho}\left(f_{t}(\bm{x}_{t})+\bm{\lambda}_{t}^{\top} g_{t}(\bm{x}_{t})\right)\cdot\bm{u}_{t}\] (7)
7: Update exponential weights for experts: Let \(\ell_{t}:\mathcal{X}\rightarrow\mathbb{R}\) be a surrogate loss function to measure the performance of each expert. Then we update expert weights by \[w_{i,t+1}=w_{i,t}\exp\left(-\epsilon\ell_{t}(\widetilde{\bm{x}}_{t}^{i})\right) \quad\text{ where }\quad\ell_{t}(\bm{z})=\bm{\nabla}_{t}^{\top}(\widetilde{\bm{x}}_{t}-\bm{z})\] (8)
8: Primal ascent per expert and dual descent: \[\widetilde{\bm{x}}_{t+1}^{i}=\Pi_{(1-\alpha)\mathcal{X}}(\widetilde{\bm{x}}_{t }^{i}+\gamma_{i}\bm{\nabla}_{t})\;\;\text{and}\;\;\bm{\lambda}_{t+1}=\Pi_{[0, \tfrac{\bar{\beta}}{\mathcal{S}}\bm{e}]}(\bm{\lambda}_{t}-\eta\nabla_{\bm{ \lambda}}\bm{\mathcal{L}}_{t}(\bm{x}_{t},\bm{\lambda}_{t}))_{+}\] (9)
9:endwhile
10: Set stopping time \(\tau_{A}=t\). For \(t=\tau_{A}\ldots T\) set safety option \(\bm{x}_{t}=\widetilde{\bm{x}}_{\beta}\). ```

**Algorithm 1**

## 4 Performance analysis of our constrained BOCO algorithm

In this section, we analyze the performance of Algorithm 1 under input sequence \(\mathcal{P}_{1:T}\) which may be generated from any world described in Section 2.2. Our first result Lemma 4.1 shows that our algorithm maintains long-term constraint satisfaction almost surely for any input sequence.

**Lemma 4.1** (Strict constraint satisfaction).: _Suppose Assumption 3.1 hold, and \(T\) is large enough so that the safety buffer \(\beta=\frac{1}{\log(T)}<\bar{\beta}\), where \(\bar{\beta}\) is defined in Assumption 3.1. Then, for any \(k\in[K]\), we have \(\sum_{t\in[T]}g_{k,t}(\bm{x}_{t})>0\)._

The main result of this paper is the following Theorem 4.2, where we bound the regret of our proposed Algorithm 1 in all worlds specified in Section 2.2.

**Theorem 4.2** (Bounding regret in many worlds).: _Let the safety buffer \(\beta=\frac{1}{\log(T)}\), and the number of experts \(N=\max\left(1,\left\lceil-\log_{2}\left(K^{-\frac{1}{6}}(1+DT)^{\frac{1}{2}}T^{- \frac{3}{4}}\right)\right\rceil+1\right)\), where \(K\) is the total number of constraints and \(D\) is diameter of the decision set \(\mathcal{X}\). Choose the corresponding primal ascent step sizes for the \(N\) experts as \(\{\gamma_{1}\ldots\gamma_{N}\}=\{2^{-i}K^{-\frac{1}{6}}(1+DT)^{\frac{1}{2}}T^ {-\frac{3}{4}}:i=0\ldots N-1\}\). Then by taking dual descent step size \(\eta=\frac{1}{\sqrt{KT}}\), random perturbation parameter \(\rho=K^{\frac{1}{3}}T^{-\frac{1}{4}}\) and \(\alpha=\min\left(\frac{1}{2},K^{\frac{1}{3}}T^{-\frac{1}{4}}\right)\), and exponential weighted expert learning rate \(\epsilon=T^{-\frac{1}{2}}\), we obtain the following bounds on \(\mathcal{R}_{T}\) in each input setting of interest: (1) **Stochastic:**\(\mathcal{R}_{T}\leq\mathcal{O}(T^{3/4})\); (2) **Adversarial:**\(\mathcal{R}_{T}\leq\left(1-\frac{1}{\xi}\right)\text{\rm OPT}(\mathcal{P}_{1: T})+\tilde{\mathcal{O}}\left(\sqrt{1+P(\widetilde{\bm{y}}_{1:T})}\cdot T^{\frac{3}{4}}\right)\), where \(\xi=1-\frac{1}{\beta}\min_{(f,\bm{g})\in\mathcal{S}}\min_{k\in[K],\bm{x}\in \mathcal{X}}g_{k}(\bm{x})>1\) under Assumption 2.1, \(\bar{\beta}>0\) is defined in Assumption 3.1, \(\widetilde{\bm{y}}_{t}=\arg\max_{\bm{x}\in\mathcal{X}}f_{t}(\bm{x}_{t})+\bm{ \lambda}_{t}^{\top}\bm{g}_{t}(\bm{x}_{t})\), and \(P(\widetilde{\bm{y}}_{1:T})=\sum_{t\in[T-1]}\|\widetilde{\bm{y}}_{t}- \widetilde{\bm{y}}_{t+1}\|\); (3) \(\delta\)-corrupted: \(\mathcal{R}_{T}\leq\mathcal{O}(T^{3/4}+\delta)\); (4) **Periodic**: \(\mathcal{R}_{T}\leq\mathcal{O}(T^{3/4}+q\sqrt{T})\); (5) **Ergodic**: \(\mathcal{R}_{T}\leq\mathcal{O}(T^{3/4}+\kappa\sqrt{T})\)._

We also summarize our regret bounds in Table 1. Although it is always challenging to identify which input procedure the data currently comes from, Theorem 4.2 shows that the proposed Algorithm 1 achieves reasonable regret bound in five input settings without knowing which setting we are in. We remark that in the adversarial setting, our algorithm is \((1-\frac{1}{\xi})\)-competitive, namely, it can achieve at least a \(\frac{1}{\xi}\)-portion of the reward compared to OPT; later in Section 5 we comment that no sublinear regret is achievable. For the \(\delta\)-corrupted world, we corrupt \(\delta\) instances in the input sequence over time, so if \(\delta=0\), we recover the stochastic world and achieve diminishing \(\mathcal{O}(T^{3/4})\) regret; in the case we corrupt all samples, then we recover the adversarial case, and the regret becomes \(\mathcal{O}(T)\) as expected. In the periodic world, if period length \(q=1\), we recover the stochastic case.

**Remark 4.1**.: _We remark that our regret upper bound in the adversarial case depends on the dual variables \(\{\bm{\lambda}_{t}\}_{t\in[T]}\) generated throughout the algorithm, which contrasts adversarial regret bounds in [44] that only depend on the total variance of the optimal sequence of \(1\). This is due to that fact that [44] handles a non-constrained online optimization problem, whereas we tackle a more difficult problem with long-term adversarial constraints that leads to more severe regret degradation as we ensure satisfaction of long-term adversarial constraints. We acknowledge that this bound should ideally be independent of dual variables, and we leave this for future work._

In the rest of this section, we present a proof scratch of Theorem 4.2, and the formal proof of the results can be found in Appendix A. The high-level idea of the proof is that we decompose total regret into three components as in Lemma 4.3 bellow, namely the conversion losses due to hard stopping, dual descent, and primal ascent, respectively. Then, we bound each component's regret.

**Lemma 4.3** (Regret decomposition).: _Let \(\left(\bm{\lambda}_{t}\in\mathbb{R}_{\geq 0}^{K}\right)_{t\in[T]}\) be the sequence of dual variables generated from Algorithm 1, and define \(h_{t}(\bm{x})=\mathcal{L}_{t}(\bm{x},\bm{\lambda}_{t})\) where there Lagrangian function \(\mathcal{L}_{t}(\bm{x},\bm{\lambda})\) is defined in Eq. (4). Then we have_

\[\text{\rm OPT}(\mathcal{P}_{1:T})-\sum_{t\in[T]}\mathbb{E}\left[f_{t}(\bm{x}_{ t})\right]\leq\bar{F}(T-\tau_{A})+\sum_{t\in[\tau_{A}]}\bm{\lambda}_{t}^{\top}\bm{g}_{t} (\bm{x}_{t})+\mathcal{R}_{\text{\rm BOCO}}(\tau_{A})\] (10)

_where \(\mathcal{R}_{\text{\rm BOCO}}(\tau_{A})\) admits the following bounds in each input setting: (1) **Stochastic:**\(\max_{\bm{x}\in\mathcal{X}}\sum_{t\in[\tau_{A}]}h_{t}(\bm{x})-h_{t}(\bm{x}_{t})\); (2) **Adversarial:**\(\sum_{t\in[\tau_{A}]}h_{t}(\widetilde{\bm{y}}_{t})-h_{t}(\bm{x}_{t})+\left(1- \frac{1}{\xi}\right)\text{\rm OPT}(\mathcal{P}_{1:T})\) where \(\widetilde{\bm{y}}_{t}=\arg\max_{\bm{x}\in\mathcal{X}}\mathbb{E}_{\mathcal{P} _{t}}[f_{t}(\bm{x})+\bm{\lambda}_{t}^{\top}\bm{g}_{t}(\bm{x})]\); (3) \(\delta\)**-corrupted:**\(\max_{\bm{x}\in\mathcal{X}}\sum_{t\in[\tau_{A}]}h_{t}(\bm{x})-h_{t}(\bm{x}_{t})+ \mathcal{O}(\eta qT)\); (5) **Ergodic**: \(\max_{\bm{x}\in\mathcal{X}}\sum_{t\in[\tau_{A}]}h_{t}(\bm{x})-h_{t}(\bm{x}_{t})+ \mathcal{O}(\eta\kappa T)\)._

Here, we remark that the first term \(\bar{F}(T-\tau_{A})\) is the loss due to hard stopping to maintain long-term constraint satisfaction; the second term \(\sum_{t\in[\tau_{A}]}\bm{\lambda}_{t}^{\top}\bm{g}_{t}(\bm{x}_{t})\) is the loss due to dual descent; and thefinal term \(\mathcal{R}_{\text{BOCO}}(\tau_{A})\) is the loss due to primal ascent. The first two components turn out to be identical in different settings, and the input model only affects the last term \(\mathcal{R}_{\text{BOCO}}(\tau_{A})\). We next present our key results with which we use to bound first two components (dual descent and hard stop loss), and the third component (primal ascent loss), respectively.

Bounding dual descent and hard stop loss.Our strategy to bound the loss due to dual descent and hard stopping relies on bounding some cumulative "complementary slackness" induced from dual descent in the following Lemma 4.4. We note that the bound in Lemma 4.4 holds for any \(\bm{\lambda}\in[\bm{0},\frac{\bar{F}}{\beta}\bm{e}]\), and thus by choosing appropriate \(\bm{\lambda}\), we can "internalize" the losses due to dual descent and hard stopping, as demonstrted in Lemma 4.5.

**Lemma 4.4** (Bounding complementary slackness).: _For any \(\bm{\lambda}\in[\bm{0},\frac{\bar{F}}{\beta}\bm{e}]\) and \(t\in[T]\), we have \(\sum_{\tau\in[t]}(\bm{\lambda}_{\tau}-\bm{\lambda})^{\top}\bm{g}_{\tau}(\bm{ x}_{\tau})=\sum_{\tau\in[t]}(\bm{\lambda}_{\tau}-\bm{\lambda})^{\top}\nabla_{ \bm{\lambda}}\mathcal{L}_{\tau}(\bm{x}_{\tau},\bm{\lambda}_{\tau})\;\leq\; \frac{\eta}{2}tK\bar{G}^{2}+\frac{1}{2\eta}\|\bm{\lambda}\|_{2}^{2}\)_

**Lemma 4.5** (Internalizing dual descent and hard stop losses.).: _Given the stopping time \(\tau_{A}\in[T]\), w.p. 1 we have \(\bar{F}(T-\tau_{A})+\sum_{t\in[\tau_{A}]}\bm{\lambda}_{t}^{\top}\bm{g}_{t}(\bm {x}_{t})\;\leq\;\frac{\eta}{2}TK\bar{G}^{2}+\frac{1}{2\eta}\Big{(}\frac{\bar{F }}{\beta}\Big{)}^{2}+\bar{F}+\frac{\bar{F}}{\beta}\bar{G}\)._

Bounding primal ascent loss (dynamic BOCO regret).We present our main result Lemma 4.6, which bounds the loss due to primal ascent for given any comparator sequence \(\bm{y}_{1}\ldots\bm{y}_{T}\in\mathcal{X}\).

**Lemma 4.6** (Bounding primal ascent (dynamic BOCO regret)).: _For any \(i\in[N],\,t\in[T]\) and any sequence \(\bm{y}_{1:t}\in\mathcal{X}^{t}\) we have \(\sum_{\tau\in[t]}h_{\tau}(\bm{y}_{\tau})-h_{\tau}(\bm{x}_{\tau})\;\leq\; \mathcal{O}\Big{(}\frac{(\rho+\alpha)T}{\beta}+\frac{1+P(\bm{y}_{1:\tau})}{ \gamma_{i}}+\frac{\gamma_{i}KT}{\beta^{2}\rho^{2}}+T\epsilon+\frac{1}{\epsilon }\Big{)}\), where \(P(\bm{y}_{1:T})=\sum_{t\in[T-1]}\|\bm{y}_{t}-\bm{y}_{t+1}\|\), and parameters \((\alpha,\gamma_{i},\epsilon,\rho)\) are specified in Algorithm 1._

Proof sketch.: We define the smoothed-versions of BOCO rewards \(h_{t}:\mathcal{X}\rightarrow\mathbb{R}\) as \(\hat{h}_{t}(\bm{x})=\mathbb{E}_{\bm{v}\sim U(\mathbb{R})}[\mathcal{L}_{t}(\bm {x}+\rho\bm{v},\bm{\lambda}_{t})]\). Then, we decompose the primal ascent loss (BOCO dynamic regret) \(\sum_{\tau\in[t]}(h_{\tau}(\bm{y}_{\tau})-h_{\tau}(\bm{x}_{\tau}))\) into 3 terms:

\[\sum_{\tau\in[t]}(h_{\tau}(\bm{y}_{\tau})-\hat{h}_{\tau}((1-\alpha)\bm{y}_{ \tau}))+\sum_{\tau\in[t]}(\hat{h}_{\tau}((1-\alpha)\bm{y}_{\tau})-\hat{h}_{ \tau}(\bm{\widetilde{x}}_{\tau}))+\sum_{\tau\in[t]}(\hat{h}_{\tau}(\bm{ \widetilde{x}}_{\tau})-h_{\tau}(\bm{x}_{\tau})),\]

where we recall the \(\bm{\widetilde{x}}_{\tau}\) is the un-perturbed version of our primal lever decision in Algorithm 1. The first and third summands can be directly be bounded via exploiting Lipschitz continuity properties for \(h_{t}\) (see Lemma A.1). The second summand can further be upper bounded (using Lemma A.2) by the surrogate loss difference between the primal decision weighted over all expert decisions and the comparator decision, namely \(\ell_{\tau}\left(\bm{\widetilde{x}}_{\tau}\right)-\ell_{\tau}\left((1-\alpha) \bm{y}_{\tau}\right)\). Then, we choose any expert \(i\in[N]\) corresponding to primal ascent step size \(\gamma_{i}>0\) as an "intermediary" and decompose cumulative surrogate loss as \(\sum_{t\in[T]}(\ell_{t}\left(\bm{\widetilde{x}}_{t}\right)-\ell_{t}\left((1- \alpha)\bm{y}_{t}\right))=\sum_{t\in[T]}(\ell_{t}\left(\bm{\widetilde{x}}_{t} \right)-\ell_{t}\left(\bm{\widetilde{x}}_{t}^{i}\right))+\sum_{t\in[T]}(\ell_{t }\left(\bm{\widetilde{x}}_{t}^{i}\right)-\ell_{t}\left((1-\alpha)\bm{y}_{t} \right))\). The first summand corresponds to the cumulative loss of our unperturbed primal decisions against any expert, and the second summand represents the cumulative loss of any expert w.r.t. the comparator sequence. Both summands are bounded in Lemma A.3. 

We note that choosing different experts as the intermediary may yield different bounds. But since Lemma A.3 holds for any expert \(i\in[N]\), we can consider the expert with the "optimal" primal ascent step size in each world, respectively.

## 5 Additional discussions

Lower bounds.A natural question to ask is whether regret bounds in Theorem 4.2 are optimal. Here, we look at lower bounds in "relaxed" problem settings, e.g., bandit online convex optimization with no-constraints [11; 44], or online constrained optimization under full-information feedback [8; 10]:

\begin{tabular}{c c c c c} \hline \hline Stochastic & \(\delta\)-corrupted & Adversarial & Periodic & Ergodic \\ \hline \(\Omega(\sqrt{T})\)[19] & \(\Omega(\sqrt{T}+\delta)\)[10] & \(\Omega\Big{(}\Big{(}1-\frac{1}{\xi}\Big{)}T\Big{)}\)[8] & \(\Omega(\sqrt{qT})\)[10] & NA \\ \hline \hline \end{tabular} These relaxed lower bounds are applicable to our setting (though they may not be the tightest bounds), and we can see that it may be possible to employ more complex machinery to attain better regret performances for our bandit convex online optimization setup with uncertain constraints. Yet, to identify an algorithm that can achieve the optimal regret in many worlds is an extremely challengingopen problem. For instance, even in the relaxed setting of bandit convex optimization with no-constraints, to the best of our knowledge there is no universal algorithm that achieves optimal regret in just the stochastic and adversarial worlds.

**Other applications.** Our proposed Algorithm 1 addresses a more general problem of online decision making with multi-dimensional decisions, bandit feedback and long-time uncertain constraints. That being said, our algorithm can also be applicable to other problem settings, for example:

_Personalized recommendation and assortment in online retailing._ Online retail platforms aim to optimize sales or revenue by recommending a limited assortment of products to customers. However, the likelihood of customer purchases given an assortment as well as their preferences are unknown, and different customer types may change over time due to evolving market trends. Platforms only observe bandit binary purchase decisions. Hence in our context, the decision set \(\mathcal{X}\) represents a probability simplex over \(d\) items. The online decisions \(\bm{x}_{t}\in\mathcal{X}\) correspond to recommendation probabilities for each item. The function \(f_{t}(\bm{x}_{t})\) reflects the revenue generated from customer purchases, while \(\bm{g}_{t}(\bm{x}_{t})\) captures assortment capacity constraints, product inventory limits, or fairness considerations to ensure equal visibility for each product [18].

_Real time posted pricing in E-commerce and cloud computing._ In online E-commerce platforms such as Amazon and eBay, sellers set prices to sell various items to sequentially arriving customers [5, 34, 26]; and in cloud computing, operators of cloud services such as Alibaba Cloud (Alicloud) or Amazon Web Services (AWS) set prices for renting out different computing capacities (virtual machines, VMs etc.) upon customer requests [39]. The arrival of customer types as well as their demand may differ significantly over time (think about demand for sanitary products during pandemics outbursts, or computing resource demands during periodic business hours). Further, decision makers only get to observe (bandit) demand at the realized pricing decisions. Thereby, we can view \(\bm{x}_{t}\in\mathcal{X}\) as the vector of prices for various sold products, \(f_{t}(\bm{x}_{t})\) as the generated revenue over a given period, \(\bm{g}_{t}(\bm{x}_{t})\) as real time product/resource capacity constraints, operating cost constraints, etc.

## References

* [1] Programmatic advertising trends, stats, & news. https://roirevolution.com/blog/programmatic-advertising-trends-stats-news/. Accessed: 2023-03-30.
* [2] Programmatic digital display advertising in 2022: Ad spend, formats, and forecast. https://www.insiderintelligence.com/insights/programmatic-digital-display-ad-spending/. Accessed: 2023-03-30.
* [3] Shipra Agrawal, Zizhuo Wang, and Yinyu Ye. A dynamic near-optimal algorithm for online linear programming. _Operations Research_, 62(4):876-890, 2014.
* [4] Sanae Amani, Mahnoosh Alizadeh, and Christos Thrampoulidis. Linear stochastic bandits under safety constraints. _Advances in Neural Information Processing Systems_, 32, 2019.
* [5] Moshe Babaioff, Shaddin Dughmi, Robert Kleinberg, and Aleksandrs Slivkins. Dynamic pricing with limited supply, 2015.
* [6] Ashwinkumar Badanidiyuru, Robert Kleinberg, and Aleksandrs Slivkins. Bandits with knapsacks. _Journal of the ACM (JACM)_, 65(3):1-55, 2018.
* [7] Santiago Balseiro, Yuan Deng, Jieming Mao, Vahab Mirrokni, and Song Zuo. Robust auction design in the auto-bidding world. _Advances in Neural Information Processing Systems_, 34:1777-17788, 2021.
* [8] Santiago Balseiro and Yonatan Gur. Learning in repeated auctions with budgets: Regret minimization and equilibrium. _Management Science_, 65(9):3952-3968, 2019.
* [9] Santiago Balseiro, Anthony Kim, Mohammad Mahdian, and Vahab Mirrokni. Budget-management strategies in repeated auctions. _Operations Research_, 69(3):859-876, 2021.
* [10] Santiago Balseiro, Haihao Lu, and Vahab Mirrokni. The best of many worlds: Dual mirror descent for online allocation problems. _Operations Research_, 71(1):101-119, 2023.
* [11] Omar Besbes, Yonatan Gur, and Assaf Zeevi. Stochastic multi-armed-bandit problem with non-stationary rewards. _Advances in Neural Information Processing Systems_, 27, 2014.
* [12] Mark Braverman, Jieming Mao, Jon Schneider, and Matt Weinberg. Selling to a no-regret buyer. In _Proceedings of the 2018 ACM Conference on Economics and Computation_, pages 523-538, 2018.
* [13] Matteo Castiglioni, Andrea Celli, and Christian Kroer. Online learning with knapsacks: the best of both worlds. In _International Conference on Machine Learning_, pages 2767-2783. PMLR, 2022.
* [14] Matteo Castiglioni, Andrea Celli, and Christian Kroer. Online bidding in repeated non-truthful auctions under budget and roi constraints. _arXiv preprint arXiv:2302.01203_, 2023.

* Castiglioni et al. [2022] Matteo Castiglioni, Andrea Celli, Alberto Marchesi, Giulia Romano, and Nicola Gatti. A unifying framework for online optimization with long-term constraints. _Advances in Neural Information Processing Systems_, 35:33589-33602, 2022.
* Chaudhary and Kalathil [2022] Sapana Chaudhary and Dileep Kalathil. Safe online convex optimization with unknown linear safety constraints. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 36, pages 6175-6182, 2022.
* Chen et al. [2019] Lin Chen, Mingrui Zhang, and Amin Karbasi. Projection-free bandit convex optimization. In _The 22nd International Conference on Artificial Intelligence and Statistics_, pages 2047-2056. PMLR, 2019.
* Chen et al. [2022] Qiyi Chen, Negin Golrezaei, Fransisca Susan, and Edy Baskoro. Fair assortment planning. _arXiv preprint arXiv:2208.07341_, 2022.
* Dani et al. [2007] Varsha Dani, Sham M Kakade, and Thomas Hayes. The price of bandit information for online optimization. _Advances in Neural Information Processing Systems_, 20, 2007.
* Deng et al. [2022] Yuan Deng, Negin Golrezaei, Patrick Jaillet, Jason Cheuk Nam Liang, and Vahab Mirrokni. Fairness in the autobidding world with machine-learned advice. _arXiv preprint arXiv:2209.04748_, 2022.
* Deng et al. [2023] Yuan Deng, Negin Golrezaei, Patrick Jaillet, Jason Cheuk Nam Liang, and Vahab Mirrokni. Multi-channel autobidding with budget and roi constraints. _arXiv preprint arXiv:2302.01523_, 2023.
* Deng et al. [2022] Yuan Deng, Jieming Mao, Vahab Mirrokni, Hanrui Zhang, and Song Zuo. Efficiency of the first-price auction in the autobidding world. _arXiv preprint arXiv:2208.10650_, 2022.
* Deng et al. [2021] Yuan Deng, Jieming Mao, Vahab Mirrokni, and Song Zuo. Towards efficient auctions in an auto-bidding world. In _Proceedings of the Web Conference 2021_, pages 3965-3973, 2021.
* Feng et al. [2023] Zhe Feng, Swati Padmanabhan, and Di Wang. Online bidding algorithms for return-on-spend constrained advertisers. In _Proceedings of the ACM Web Conference 2023_, pages 3550-3560, 2023.
* Flaxman et al. [2005] Abraham D Flaxman, Adam Tauman Kalai, and H Brendan McMahan. Online convex optimization in the bandit setting: gradient descent without a gradient. In _Proceedings of the sixteenth annual ACM-SIAM symposium on Discrete algorithms_, pages 385-394, 2005.
* Golrezaei et al. [2020] Negin Golrezaei, Patrick Jaillet, and Jason Cheuk Nam Liang. No-regret learning in price competitions under consumer reference effects. _Advances in Neural Information Processing Systems_, 33:21416-21427, 2020.
* Golrezaei et al. [2023] Negin Golrezaei, Patrick Jaillet, and Jason Cheuk Nam Liang. Incentive-aware contextual pricing with non-parametric market noise. In _International Conference on Artificial Intelligence and Statistics_, pages 9331-9361. PMLR, 2023.
* Golrezaei et al. [2021] Negin Golrezaei, Patrick Jaillet, Jason Cheuk Nam Liang, and Vahab Mirrokni. Bidding and pricing in budget and ROI constrained markets. _arXiv preprint arXiv:2107.07725_, 2021.
* Golrezaei et al. [2021] Negin Golrezaei, Vahideh Manshadi, Jon Schneider, and Shreyas Sekar. Learning product rankings robust to fake users. In _Proceedings of the 22nd ACM Conference on Economics and Computation_, pages 560-561, 2021.
* Han et al. [2020] Yanjun Han, Zhengyuan Zhou, Aaron Flores, Erik Ordentlich, and Tsachy Weissman. Learning to bid optimally and efficiently in adversarial first-price auctions. _arXiv preprint arXiv:2007.04568_, 2020.
* Han et al. [2020] Yanjun Han, Zhengyuan Zhou, and Tsachy Weissman. Optimal no-regret learning in repeated first-price auctions. _arXiv preprint arXiv:2003.09795_, 2020.
* Hazan and Li [2016] Elad Hazan and Yuanzhi Li. An optimal algorithm for bandit convex optimization. _arXiv preprint arXiv:1603.04350_, 2016.
* Jenatton et al. [2016] Rodolphe Jenatton, Jim Huang, and Cedric Archambeau. Adaptive algorithms for online convex optimization with long-term constraints. In _International Conference on Machine Learning_, pages 402-411. PMLR, 2016.
* Kuo et al. [2011] Chia-Wei Kuo, Hyun-Soo Ahn, and Goker Aydin. Dynamic pricing of limited inventories when customers negotiate. _Operations Research_, 59(4):882-897, 2011.
* Liakopoulos et al. [2019] Nikolaos Liakopoulos, Apostolos Destounis, Georgios Paschos, Thrasyvoulos Spyropoulos, and Panayotis Mertikopoulos. Cautious regret minimization: Online optimization with long-term budget constraints. In _International Conference on Machine Learning_, pages 3944-3952. PMLR, 2019.
* Mahdavi et al. [2012] Mehrdad Mahdavi, Rong Jin, and Tianbao Yang. Trading regret for efficiency: online convex optimization with long term constraints. _The Journal of Machine Learning Research_, 13(1):2503-2528, 2012.
* Mannor et al. [2009] Shie Mannor, John N Tsitsiklis, and Jia Yuan Yu. Online learning with sample path constraints. _Journal of Machine Learning Research_, 10(3), 2009.
* Mehta [2022] Aranyak Mehta. Auction design in an auto-bidding setting: Randomization improves efficiency beyond vcg. In _Proceedings of the ACM Web Conference 2022_, pages 173-181, 2022.
* Peng et al. [2023] Huijie Peng, Yan Cheng, and Xingyuan Li. Real-time pricing method for spot cloud services with non-stationary excess capacity. _Sustainability_, 15(4):3363, 2023.

* [40] Wen Sun, Debadeepta Dey, and Ashish Kapoor. Safety-aware algorithms for adversarial contextual bandit. In _International Conference on Machine Learning_, pages 3280-3288. PMLR, 2017.
* [41] Jonathan Weed, Vianney Perchet, and Philippe Rigollet. Online learning in repeated auctions. In _Conference on Learning Theory_, pages 1562-1583. PMLR, 2016.
* [42] Scott Yang and Mehryar Mohri. Optimistic bandit convex optimization. _Advances in Neural Information Processing Systems_, 29, 2016.
* [43] Jianjun Yuan and Andrew Lamperski. Online convex optimization for cumulative constraints. _Advances in Neural Information Processing Systems_, 31, 2018.
* [44] Peng Zhao, Guanghui Wang, Lijun Zhang, and Zhi-Hua Zhou. Bandit convex optimization in non-stationary environments. _The Journal of Machine Learning Research_, 22(1):5562-5606, 2021.

Appendices for

**Online Ad Procurement in Non-stationary Autobidding Worlds**

## Appendix A Proofs for Section 4

### Additional definitions for Section 4

**Definition A.1** (Total variation between probability distributions).: _Consider two distributions \(\{\mathcal{P},\mathcal{P}^{\prime}\}\subseteq\Delta(\mathcal{S})\). Then we define their total variation as \(\|\mathcal{P}-\mathcal{P}^{\prime}\|_{TV}=\frac{1}{2}\int_{\mathcal{S}}| \mathcal{P}(s)-\mathcal{P}^{\prime}(s)|ds\)._

We also define the smoothed version of \(h_{t}:\mathcal{X}\rightarrow\mathbb{R}\) (see Eq. (5)) for any \(t\) as follows:

\[\hat{h}_{t}(\bm{x})=\mathbb{E}_{\bm{v}\sim\mathcal{U}(\mathbb{B})}[\mathcal{L} _{t}(\bm{x}+\rho\bm{v},\bm{\lambda}_{t})]\] (11)

where we recall the Lagrangian function \(\mathcal{L}_{t}\) is defined in Eq. (4).

### Additional lemmas for Section 4

**Lemma A.1** (Lipschitz continuity).: _Let Assumption 2.1 hold, and we recall the definitions of \(h_{t}(\bm{x})\) and \(\hat{h}_{t}(\bm{x})\) from Eqs. (5) and (11), respectively, and recall \(\bm{\lambda}_{1}\ldots\bm{\lambda}_{T}\) as the dual variables generated from Algorithm 1. Then for any \(\{\bm{x},\bm{x}^{\prime}\}\subseteq\mathcal{X}\), we have \(|h_{t}(\bm{x})-h_{t}(\bm{x}^{\prime})|\leq(1+K\frac{\bar{F}}{\beta})L\cdot\| \bm{x}-\bm{x}^{\prime}\|\) and \(\Big{|}h_{t}(\bm{x})-\hat{h}_{t}(\bm{x})\Big{|}\leq(1+K\frac{\bar{F}}{\beta})L\rho\)._

**Lemma A.2** (Bounding BCOO dynamic regret with surrogate loss).: _Recall the definition \(\hat{h}_{t}(\bm{x})=\mathbb{E}_{\bm{v}\sim U(\mathbb{B})}[\mathcal{L}_{t}(\bm {x}+\rho\bm{v},\bm{\lambda}_{t})]\). Then, \(\hat{h}_{t}(\bm{x})\) is concave. Further, For any \(\bm{y}\in(1-\alpha)\mathcal{X}\), we have \(\hat{h}_{t}(\bm{y})-\hat{h}_{t}(\widetilde{\bm{x}}_{t})\;\leq\;\mathbb{E}_{\bm {u}_{t}\sim U(S)}\left[\ell_{t}(\widetilde{\bm{x}}_{t})-\ell_{t}(\bm{y})\right]\), where \(\widetilde{\bm{x}}_{t}\) is defined in Eq. (6), and the surrogate loss function \(\ell_{t}:\mathcal{X}\rightarrow\mathbb{R}\) is defined in Eq. (8)._

**Lemma A.3** (Bounding surrogate loss for each expert).: _Recall the definition of individual forecasters \(\widetilde{\bm{x}}_{t}^{c}\) defined in Eq. (9), and the surrogate loss function \(\ell_{t}:\mathcal{X}\rightarrow\mathbb{R}\) defined in Eq. (8). Then for any \(i\in[N]\) and any sequence \(\bm{y}_{1:T}\in\mathcal{X}^{T}\), by defining \(P(\bm{y}_{1:T})=\sum_{t\in[T-1]}\|\bm{y}_{t}-\bm{y}_{t+1}\|\) (see Lemma 4.6), we have (i) and (ii) \(\sum_{t\in[T]}(\ell_{t}\left(\widetilde{\bm{x}}_{t}\right)-\ell_{t}\left( \widetilde{\bm{x}}_{t}^{c}\right))\;\leq\;\mathcal{O}(T\epsilon+\frac{1}{ \epsilon})\), where the constant \(\beta\) is specified in Algorithm 1. Here, recall \(D\) is the diameter of the decision set \(\mathcal{X}\)._

The proofs of Lemmas A.1, A.2,A.3 are shown in Appendices A.9, A.10, and A.11, respectively.

### Proof for Lemma 4.1

Proof.: For any \(k\in[K]\) we have

\[\sum_{t\in[T]}g_{k,t}(\bm{x}_{t}) = \sum_{t\in[\tau_{A}-1]}g_{k,t}(\bm{x}_{t})+\sum_{t=\tau_{A}}^{T}g _{k,t}(\bm{x}_{t})\;\overset{(a)}{\geq}\;\sum_{t\in[\tau_{A}-1]}g_{k,t}(\bm{x }_{t})+\bar{\beta}(T-\tau_{A}+1)\] (12) \[\geq \sum_{t\in[\tau_{A}-1]}g_{k,t}(\bm{x}_{t})+\beta(T-\tau_{A})+ \beta\;\overset{(b)}{\geq}\;\bar{G}+\beta>0\;,\]

where in \((a)\) we set \(\bm{x}_{t}=\widetilde{\bm{x}}_{\beta}\) for all \(t=\tau_{A}\ldots T\) and \(g_{k,t}(\widetilde{\bm{x}}_{\beta})\geq\bar{\beta}\) for any \(k\in[K]\); \((b)\) follows from the definition of the stopping time such that for any \(t^{\prime}<\tau_{A}\) and \(k\in[K]\) we have \(\sum_{t\in[t^{\prime}]}g_{k,t}(\bm{x}_{t})-\bar{G}+\beta(T-t^{\prime}-1)\geq 0\). 

### Proof for Lemma 4.4

Proof.: It is easy to see \(\bm{\lambda}_{t+1}=\Pi_{[\bm{0},\frac{\bar{F}}{\beta}\bm{e}]}(\bm{\lambda}_{t} -\eta\nabla_{\bm{\lambda}}\mathcal{L}_{t}(\bm{x}_{t},\bm{\lambda}_{t}))_{+}= \arg\min_{\bm{\lambda}\in[\bm{0},\frac{\bar{F}}{\beta}\bm{e}]}\nabla_{\bm{ \lambda}}\mathcal{L}_{t}(\bm{x}_{t},\bm{\lambda}_{t})^{\top}\bm{\lambda}+\frac {1}{2\eta}\|\bm{\lambda}-\bm{\lambda}_{t}\|^{2}\). By the first-order stationary condition at \(\bm{\lambda}_{t+1}\), we have for any \(\bm{\lambda}\in[\bm{0},\frac{F}{\beta}\bm{e}]\)

\[\left(\nabla_{\bm{\lambda}}\mathcal{L}_{t}(\bm{x}_{t},\bm{\lambda}_{t})+\frac{1} {\eta}(\bm{\lambda}_{t+1}-\bm{\lambda}_{t})\right)^{\top}(\bm{\lambda}-\bm{ \lambda}_{t+1})\geq 0\;.\]

Then for all \(\bm{\lambda}\in\mathbb{R}_{\geq 0}^{K}\), it follows that

\[\nabla_{\bm{\lambda}}\mathcal{L}_{t}(\bm{x}_{t},\bm{\lambda}_{t}) ^{\top}(\bm{\lambda}_{t}-\bm{\lambda})\] \[= \nabla_{\bm{\lambda}}\mathcal{L}_{t}(\bm{x}_{t},\bm{\lambda}_{t} )^{\top}(\bm{\lambda}_{t}-\bm{\lambda}_{t+1})+\nabla_{\bm{\lambda}}\mathcal{L }_{t}(\bm{x}_{t},\bm{\lambda}_{t})^{\top}(\bm{\lambda}_{t+1}-\bm{\lambda})\] \[\leq \nabla_{\bm{\lambda}}\mathcal{L}_{t}(\bm{x}_{t},\bm{\lambda}_{t} )^{\top}(\bm{\lambda}_{t}-\bm{\lambda}_{t+1})+\frac{1}{\eta}(\bm{\lambda}_{t +1}-\bm{\lambda}_{t})^{\top}(\bm{\lambda}-\bm{\lambda}_{t+1})\] \[\leq \nabla_{\bm{\lambda}}\mathcal{L}_{t}(\bm{x}_{t},\bm{\lambda}_{t} )^{\top}(\bm{\lambda}_{t}-\bm{\lambda}_{t+1})+\frac{1}{2\eta}\|\bm{\lambda}- \bm{\lambda}_{t}\|^{2}-\frac{1}{2\eta}\|\bm{\lambda}-\bm{\lambda}_{t+1}\|^{2} -\frac{1}{2\eta}\|\bm{\lambda}_{t+1}-\bm{\lambda}_{t}\|^{2}\] \[\leq \frac{\eta}{2}\|\nabla_{\bm{\lambda}}\mathcal{L}_{t}(\bm{x}_{t}, \bm{\lambda}_{t})\|^{2}+\frac{1}{2\eta}\|\bm{\lambda}-\bm{\lambda}_{t}\|^{2}- \frac{1}{2\eta}\|\bm{\lambda}-\bm{\lambda}_{t+1}\|^{2}\;.\]

By a telescoping argument, we have

\[\sum_{\tau\in[t]}\nabla_{\bm{\lambda}}\mathcal{L}_{\tau}(\bm{x}_ {\tau},\bm{\lambda}_{\tau})^{\top}(\bm{\lambda}_{\tau}-\bm{\lambda}) \leq \frac{\eta}{2}\sum_{\tau\in[t]}\|\nabla_{\bm{\lambda}}\mathcal{L }_{\tau}(\bm{x}_{\tau},\bm{\lambda}_{\tau})\|^{2}+\frac{1}{2\eta}\|\bm{\lambda }-\bm{\lambda}_{1}\|^{2}\] (13) \[= \frac{\eta}{2}\sum_{\tau\in[t]}\|\nabla_{\bm{\lambda}}\mathcal{L }_{\tau}(\bm{x}_{\tau},\bm{\lambda}_{\tau})\|^{2}+\frac{1}{2\eta}\|\bm{\lambda }\|^{2}\;,\]

where in the final equality we used \(\bm{\lambda}_{1}=\bm{0}\). Also,

\[\|\nabla_{\bm{\lambda}}\mathcal{L}_{\tau}(\bm{x}_{\tau},\bm{\lambda}_{\tau}) \|^{2}\ =\ \|\bm{g}_{\tau}(\bm{x}_{\tau})\|^{2}\ \leq\ K\bar{G}^{2}\;.\] (14)

Hence, combining Eqs. (13) and (14), we get the desired bound. 

### Proof of Lemma 4.5

Proof.: If \(\tau_{A}=T\), taking \(\bm{\lambda}=0\) in Lemma 4.4 yields \(\sum_{t\in[T]}\bm{\lambda}_{t}^{\top}\bm{g}_{t}(\bm{x}_{t})\ \leq\ \frac{\eta}{2}TK\bar{G}^{2}\) and thus the desired inequality holds. If \(\tau_{A}<T\), then there exists some \(k\in[K]\) such that \(\sum_{t\in[\tau_{A}]}g_{k,t}(\bm{x}_{t})-\bar{G}+\beta(T-\tau_{A}-1)<0\), so by taking \(\bm{\lambda}=\frac{F}{\beta}\bm{e}_{k}\) (\(\bm{e}_{k}\in\mathbb{R}^{K}\) is the unit vector whose \(k\)th entry is 1) in Lemma 4.4 yields

\[\sum_{t\in[\tau_{A}]}\bm{\lambda}_{t}^{\top}\bm{g}_{t}(\bm{x}_{t}) \leq \sum_{t\in[\tau_{A}]}\bm{\lambda}^{\top}\bm{g}_{t}(\bm{x}_{t})+ \frac{\eta}{2}TK\bar{G}^{2}+\frac{1}{2\eta}\|\bm{\lambda}\|^{2}\] \[= \frac{\bar{F}}{\beta}\sum_{t\in[\tau_{A}]}g_{k,t}(\bm{x}_{t})+ \frac{\eta}{2}TK\bar{G}^{2}+\frac{1}{2\eta}\Big{(}\frac{\bar{F}}{\beta}\Big{)} ^{2}\] \[\leq -\frac{\bar{F}}{\beta}\cdot\beta(T-\tau_{A}-1)+\frac{\bar{F}}{ \beta}\bar{G}+\frac{\eta}{2}TK\bar{G}^{2}+\frac{1}{2\eta}\Big{(}\frac{\bar{F}}{ \beta}\Big{)}^{2}\] \[= -\bar{F}(T-\tau_{A})+\bar{F}+\frac{\bar{F}}{\beta}\bar{G}+\frac{ \eta}{2}TK\bar{G}^{2}+\frac{1}{2\eta}\Big{(}\frac{\bar{F}}{\beta}\Big{)}^{2},\]

which completes the proof. 

### Proof of Lemma 4.6

Proof.: Recall the definition of \(h_{t}(\bm{x})\) in Eq. (5). Then, we have

\[\sum_{\tau\in[t]}h_{\tau}(\bm{y}_{\tau})-\sum_{\tau\in[t]}h_{ \tau}(\bm{x}_{\tau})\] (15) \[= \sum_{\tau\in[t]}\Big{(}\underbrace{h_{\tau}(\bm{y}_{\tau})-\hat{ h}_{\tau}((1-\alpha)\bm{y}_{\tau})}_{A}+\underbrace{\hat{h}_{\tau}((1-\alpha)\bm{y}_{ \tau})-\hat{h}_{\tau}(\widetilde{\bm{x}}_{\tau})}_{B}+\underbrace{\hat{h}_{\tau} (\widetilde{\bm{x}}_{\tau})-h_{\tau}(\bm{x}_{\tau})}_{C}\Big{)}\]Bounding \(A\). \[\begin{split} h_{\tau}(\bm{y}_{\tau})-\hat{h}_{\tau}((1-\alpha)\bm{y }_{\tau})&=\;h_{\tau}(\bm{y}_{\tau})-h_{\tau}((1-\alpha)\bm{y}_{ \tau})+h_{\tau}((1-\alpha)\bm{y}_{\tau})-\hat{h}_{\tau}((1-\alpha)\bm{y}_{\tau}) \\ &\stackrel{{(a)}}{{\leq}}(1+K\frac{\bar{F}}{\beta})L \alpha\|\bm{y}_{\tau}\|+(1+K\frac{\bar{F}}{\beta})L\rho\\ &\stackrel{{(b)}}{{\leq}}(1+K\frac{\bar{F}}{\beta})L \alpha D+(1+K\frac{\bar{F}}{\beta})L\rho\,,\end{split}\] (16)

where (a) follows from Lemma A.1; (b) follows from \(\|\bm{y}_{\tau}\|=\|\bm{y}_{\tau}-\bm{0}\|\leq D\) since we assumed \(\bm{0}\in\mathcal{X}\).

Bounding \(B\). \[\begin{split}&\sum_{\tau\in[t]}\hat{h}_{\tau}((1-\alpha)\bm{y}_{ \tau})-\hat{h}_{\tau}(\widetilde{\bm{x}}_{\tau})\\ &\stackrel{{(a)}}{{\leq}}\sum_{\tau\in[t]}\mathbb{E }_{\bm{u}_{\tau}\sim U(\mathbb{S})}\left[\ell_{\tau}(\widetilde{\bm{x}}_{\tau })-\ell_{\tau}((1-\alpha)\bm{y}_{\tau})\right]\\ &=\;\sum_{\tau\in[t]}\mathbb{E}_{\bm{u}_{\tau}\sim U(\mathbb{S})} \left[\ell_{\tau}(\widetilde{\bm{x}}_{\tau})-\ell_{\tau}(\widetilde{\bm{x}}_{ \tau}^{i})+\ell_{\tau}(\widetilde{\bm{x}}_{\tau}^{i})-\ell_{\tau}((1-\alpha) \bm{y}_{\tau})\right]\\ &\stackrel{{(b)}}{{\leq}}\mathcal{O}\left(\frac{P( \bm{y}_{1:T})}{\gamma_{i}}+\frac{\gamma_{i}K\frac{\bar{F}}{\beta}T}{\rho^{2}}+T \epsilon+\frac{1}{\epsilon}\right)\;,\end{split}\] (17)

where (a) follows from Lemma A.2 and (b) follows from Lemma A.3 (i) and (ii).

Bounding \(C\). \[\begin{split}\hat{h}_{\tau}(\widetilde{\bm{x}}_{\tau})-h_{\tau}( \bm{x}_{\tau})&=\;\hat{h}_{\tau}(\widetilde{\bm{x}}_{\tau})-h_{ \tau}(\widetilde{\bm{x}}_{\tau})+h_{\tau}(\widetilde{\bm{x}}_{\tau})-h_{\tau}( \bm{x}_{\tau})\\ &\stackrel{{(a)}}{{\leq}}(1+K\frac{\bar{F}}{\beta})L \rho+(1+K\frac{\bar{F}}{\beta})L\cdot\|\widetilde{\bm{x}}_{\tau}-\bm{x}_{\tau}\| \\ &\stackrel{{(b)}}{{=}}(1+K\frac{\bar{F}}{\beta})L\rho+ (1+K\frac{\bar{F}}{\beta})L\cdot\|\rho\bm{u}_{\tau}\|\\ &\leq\;2\rho(1+K\frac{\bar{F}}{\beta})L\;,\end{split}\] (18)

where (a) follows Lemma A.1; (b) is from the definition \(\bm{x}_{\tau}=\widetilde{\bm{x}}_{\tau}+\rho\bm{u}_{\tau}\) in Algorithm 1. 

### Proof of Lemma 4.3

In this section, we provide upper bounds of the regret term under five different environments of input procedures: stochastic, adversarial, \(\delta\)-corrupted, periodic, and ergodic. The structure of the following proof might seem similar to [10]; see [10, Sections 3-5]. However, we note that the proof techniques are fundamentally different since our paper considers the bandit feedback environment while [10] makes sequential decisions after observations.

Stochastic.Proof.: In the stochastic regime, we have \(\mathcal{P}=\mathcal{P}_{1}=\cdots=\mathcal{P}_{T}\) for some \(\mathcal{P}\), and therefore we can rewrite \(\text{OPT}(\mathcal{P}_{1:T})\) in Eq. (1) as followed

\[\text{OPT}(\mathcal{P}_{1:T})=\max_{\bm{x}_{1:T}\in\mathcal{X}^{T}}\;\;\;\sum_{ t\in[T]}F(\bm{x}_{t})\quad\text{s.t.}\;\sum_{t\in[T]}\bm{G}(\bm{x}_{t}) \geq\bm{0}\,.\]where we defined \(F(\bm{x})=\mathbb{E}_{(f,\bm{g})\sim\mathcal{P}}[f(\bm{x})]\), and \(\bm{G}(\bm{x})=\mathbb{E}_{(f,\bm{g})\sim\mathcal{P}}[\bm{g}(\bm{x})]\) for any \(\bm{x}\in\mathcal{X}\). Hence, for any \(\bm{\lambda}\geq\bm{0}\) we have

\[\begin{split}\text{OPT}(\mathcal{P}_{1:T})&=\ \frac{T-\tau_{A}}{T}\text{OPT}( \mathcal{P}_{1:T})+\frac{\tau_{A}}{T}\text{OPT}(\mathcal{P}_{1:T})\\ &\leq\ (T-\tau_{A})\bar{F}+\frac{\tau_{A}}{T}\max_{\bm{x}_{1:T}\in \mathcal{X}^{T}}\sum_{t\in[T]}\big{(}F(\bm{x}_{t})+\bm{\lambda}^{\top}\bm{G}( \bm{x}_{t})\big{)}\\ &=\ (T-\tau_{A})\bar{F}+\frac{\tau_{A}}{T}\max_{\bm{x}\in\mathcal{X}} \sum_{t\in[T]}\big{(}F(\bm{x})+\bm{\lambda}^{\top}\bm{G}(\bm{x})\big{)}\\ &=\ (T-\tau_{A})\bar{F}+\tau_{A}\max_{\bm{x}\in\mathcal{X}}\big{(}F( \bm{x})+\bm{\lambda}^{\top}\bm{G}(\bm{x})\big{)}\,\end{split}\] (19)

where in the inequality we applied Assumption 2.1 which states \(\sup_{\bm{x}\in\mathcal{X}}|f(\bm{x})|\leq\bar{F}\) for all \((f,\bm{g})\in\mathcal{S}\). Choosing \(\bm{\lambda}=\bar{\bm{\lambda}}_{\tau_{A}}:=\frac{1}{\tau_{A}}\sum_{t\in[\tau _{A}]}\bm{\lambda}_{t}\) we have

\[\begin{split}\text{OPT}(\mathcal{P}_{1:T})&\leq\ \mathbb{E}\Big{[}(T-\tau_{A})\bar{F}+\tau_{A}\max_{\bm{x}\in\mathcal{X}}\big{(} F(\bm{x})+\bm{\lambda}^{\top}\bm{G}(\bm{x})\big{)}\,\Big{]}\\ &\leq\ \mathbb{E}\Big{[}(T-\tau_{A})\bar{F}+\max_{\bm{x}\in \mathcal{X}}\sum_{t\in[\tau_{A}]}(F(\bm{x})+\bm{\lambda}_{t}^{\top}\bm{G}(\bm {x}))\Big{]}\\ &\stackrel{{(a)}}{{\leq}}\ \mathbb{E}\Big{[}(T-\tau_{A})\bar{F}+ \max_{\bm{x}\in\mathcal{X}}\sum_{t\in[\tau_{A}]}\mathbb{E}\left[f_{t}(\bm{x})+ \bm{\lambda}_{t}^{\top}\bm{g}_{t}(\bm{x})\,\Big{|}\,\sigma(\mathcal{H}_{t-1}) \right]\Big{]}\\ &\stackrel{{(b)}}{{=}}\ \mathbb{E}\Big{[}(T-\tau_{A})\bar{F}+ \max_{\bm{x}\in\mathcal{X}}\sum_{t\in[\tau_{A}]}\mathbb{E}\left[h_{t}(\bm{x}) \,\Big{|}\,\sigma(\mathcal{H}_{t-1})\right]\Big{]}\\ &\leq\ \mathbb{E}\Big{[}(T-\tau_{A})\bar{F}+\max_{\bm{x}\in \mathcal{X}}\sum_{t\in[\tau_{A}]}h_{t}(\bm{x})\Big{]}\,\end{split}\] (20)

where in \((a)\) we used the fact that \(\bm{\lambda}_{t}\) is \(\mathcal{H}_{t-1}\)-measurable; in \((b)\) we used definitions \(h_{t}(\bm{x})=\mathcal{L}_{t}(\bm{x};\bm{\lambda}_{t})\) and \(\mathcal{L}_{t}(\bm{x};\bm{\lambda})=f_{t}(\bm{x})+\bm{\lambda}^{\top}\bm{g}_{ t}(\bm{x})\) in Eqs. (4) and (5) respectively.

On the other hand, we have

\[f_{t}(\bm{x}_{t})=h_{t}(\bm{x}_{t})-\bm{\lambda}_{t}^{\top}\bm{g}_{t}(\bm{x}_{ t}),\] (21)

so combining this with Eq. (20) we have

\[\begin{split}\text{OPT}(\mathcal{P}_{1:T})-\sum_{t\in[T]} \mathbb{E}[f_{t}(\bm{x}_{t})]&\leq\ \mathbb{E}\Big{[}(T-\tau_{A})\bar{F}+\max_{\bm{x}\in\mathcal{X}}\sum_{t\in[\tau _{A}]}\Big{(}h_{t}(\bm{x})-h_{t}(\bm{x}_{t})\Big{)}+\sum_{t\in\tau_{A}}\bm{ \lambda}_{t}^{\top}\bm{g}_{t}(\bm{x}_{t})\Big{]}\end{split}\] (22)

where we also used the fact that \(f_{t}(\bm{x})\geq 0\) for all \(t=\tau_{A}+1\ldots T\) and \(\bm{x}\in\mathcal{X}\). 

### Adversarial.

Proof.: Recall the definition of \(\xi\) is Theorem 4.2:

\[\xi=1-\frac{\min_{(f,\bm{g})\in\mathcal{S}}\min_{k\in[K],\bm{x}\in\mathcal{X}}g _{k}(\bm{x})}{\bar{\beta}}>1\.\] (23)

For any \(t\in[T]\), define \(\widetilde{\bm{y}}_{t}=\arg\max_{\bm{x}}f_{t}(\bm{x})+\bm{\lambda}_{t}^{\top} \bm{g}_{t}(\bm{x})\).

By comparing to the safety action \(\bm{x}_{\beta}\in\mathcal{X}\) which ensures \(g_{k}(\bm{x}_{\beta})\geq\bar{\beta}\) for any \(k\in[K]\) and \((f,\bm{g})\in\mathcal{S}\), as well as the optimal hindsight action \(\bm{x}_{t}^{*}\in\mathcal{X}\) (i.e., \(\bm{x}_{1}^{*}\ldots\bm{x}_{T}^{*}\) is the optimal decision sequence to \(\text{OPT}(\mathcal{P}_{1:T})\)), we have

\[\begin{split} f_{t}(\widetilde{\bm{y}}_{t})+\bm{\lambda}_{t}^{\top} \bm{g}_{t}(\widetilde{\bm{y}}_{t})&\geq\ f_{t}(\bm{x}_{\beta})+\bm{ \lambda}_{t}^{\top}\bm{g}_{t}(\bm{x}_{\beta})\geq\bar{\beta}\bm{\lambda}_{t}^{ \top}\bm{e}\\ \text{and}& f_{t}(\widetilde{\bm{y}}_{t})+\bm{\lambda}_{t}^{\top}\bm{g}_{t}( \widetilde{\bm{y}}_{t})&\geq\ f_{t}(\bm{x}_{t}^{*})+\bm{\lambda}_{t}^{ \top}\bm{g}_{t}(\bm{x}_{t}^{*}).\end{split}\] (24)We further have

\[\begin{split}\xi f_{t}(\widetilde{\bm{y}}_{t})&=\ f_{t}( \widetilde{\bm{y}}_{t})+(\xi-1)f_{t}(\widetilde{\bm{y}}_{t})\\ &\stackrel{{(a)}}{{\geq}}\ f_{t}(\bm{x}_{t}^{*})+ \bm{\lambda}_{t}^{\top}\bm{g}_{t}(\bm{x}_{t}^{*})-\bm{\lambda}_{t}^{\top}\bm{g }_{t}(\widetilde{\bm{y}}_{t})+(\xi-1)\left(-\bm{\lambda}_{t}^{\top}\bm{g}_{t}( \widetilde{\bm{y}}_{t})+\bar{\beta}\bm{\lambda}_{t}^{\top}\bm{e}\right)\\ &=\ f_{t}(\bm{x}_{t}^{*})+\bm{\lambda}_{t}^{\top}\bm{g}_{t}(\bm{x} _{t}^{*})-\xi\bm{\lambda}_{t}^{\top}\bm{g}_{t}(\widetilde{\bm{y}}_{t})+(\xi-1) \bar{\beta}\bm{\lambda}_{t}^{\top}\bm{e}\\ &\stackrel{{(b)}}{{\geq}}\ f_{t}(\bm{x}_{t}^{*})- \xi\bm{\lambda}_{t}^{\top}\bm{g}_{t}(\widetilde{\bm{y}}_{t})\end{split}\] (25)

where (a) follows Eq. (24); in (b) we used the fact that \(g_{k,t}(\bm{x}_{t}^{*})+(\xi-1)\bar{\beta}\geq 0\) since we have \(\min_{(f,\bm{g})\in\mathcal{S}}\min_{k\in[K],\bm{x}\in\mathcal{X}}(g_{k,t}( \bm{x})+(\xi-1)\bar{\beta})\geq 0\) (see Eq. (23)). Hence we have

\[\begin{split}&\text{OPT}(\mathcal{P}_{1:T})-\sum_{t\in[T]}\mathbb{ E}[f_{t}(\bm{x}_{t})]\\ &=\ \Big{(}1-\frac{1}{\xi}\Big{)}\text{OPT}(\mathcal{P}_{1:T})+\sum_{t \in[T]}\mathbb{E}\Big{[}\frac{1}{\xi}f_{t}(\bm{x}_{t}^{*})-f_{t}(\bm{x}_{t}) \Big{]}\\ &\leq\ \Big{(}1-\frac{1}{\xi}\Big{)}\text{OPT}(\mathcal{P}_{1:T})+\sum_{t \in[T]}\mathbb{E}\Big{[}f_{t}(\widetilde{\bm{y}}_{t})-f_{t}(\bm{x}_{t})+\bm{ \lambda}_{t}^{\top}\bm{g}_{t}(\widetilde{\bm{y}}_{t})\Big{]}\\ &\leq\ \Big{(}1-\frac{1}{\xi}\Big{)}\text{OPT}(\mathcal{P}_{1:T})+ \mathbb{E}\Big{[}(T-\tau_{A})\bar{F}+\sum_{t\in\tau_{A}}\Big{(}f_{t}( \widetilde{\bm{y}}_{t})-f_{t}(\bm{x}_{t})+\bm{\lambda}_{t}^{\top}\bm{g}_{t}( \widetilde{\bm{y}}_{t})\Big{)}\Big{]}\;,\end{split}\] (26)

which completes the proof. 

#### \(\delta\)-corrupted.

Here, we will prove a more general \(\delta\)-corrupted model where the input distribution sequence \(\mathcal{P}_{1:T}\) satisfies the following:

\[\sum_{t\in[T]}\|\mathcal{P}_{t}-\frac{1}{T}\sum_{s\in[T]}\mathcal{P}_{s}\|_{TV }\leq\delta\;,\] (27)

where the total variation norm is defined in Definition A.1. In fact, the definition in Section 2.2 for the \(\delta\)-corrupted regime satisfies the above property: recall the definition in Section 2.2, there exists \(\mathcal{P}\in\Delta(\mathcal{S})\) as well as \(\delta\in\mathbb{N}\) periods \(\mathcal{T}=\{\tau_{1}\ldots\tau_{\delta}\}\subset[T]\) such that \(\mathcal{P}_{t}=\mathcal{P}\) for all \(t\notin\mathcal{T}\), so for any \(t\notin\mathcal{T}\), we have

\[\begin{split}\|\mathcal{P}_{t}-\frac{1}{T}\sum_{s\in[T]} \mathcal{P}_{s}\|_{TV}&=\ \|\mathcal{P}-\frac{1}{T}\Big{(}\mathcal{T}\mathcal{P}+\sum_{s\in \mathcal{T}}(\mathcal{P}_{s}-\mathcal{P})\Big{)}\|_{TV}\\ &=\ \|\frac{1}{T}\sum_{s\in\mathcal{T}}(\mathcal{P}-\mathcal{P}_{s})\|_{ TV}\ \leq\ \frac{\delta}{2T}\;.\end{split}\] (28)

On the other hand, we have for any \(t\in\mathcal{T}\), \(\|\mathcal{P}_{t}-\frac{1}{T}\sum_{s\in[T]}\mathcal{P}_{s}\|_{TV}\leq\frac{1}{2}\). After summing it up, we get

\[\begin{split}\sum_{t\in[T]}\|\mathcal{P}_{t}-\frac{1}{T}\sum_{s \in[T]}\mathcal{P}_{s}\|_{TV}&=\ \sum_{t\in\mathcal{T}}\|\mathcal{P}_{t}-\frac{1}{T}\sum_{s\in[T]} \mathcal{P}_{s}\|_{TV}+\sum_{t\notin\mathcal{T}}\|\mathcal{P}_{t}-\frac{1}{T} \sum_{s\in[T]}\mathcal{P}_{s}\|_{TV}\\ &\leq\ \frac{\delta}{2}+(T-\delta)\frac{\delta}{2T}\ \leq\ \delta\;,\end{split}\]

which coincides with our general definition of \(\delta\)-corruption in Eq. (27).

We now prove the \(\delta\)-corruption regime under the general definition in Eq. (27). Define \(\widetilde{\mathcal{P}}=\frac{1}{T}\sum_{s\in[T]}\mathcal{P}_{s}\), \(\widetilde{F}(\bm{x})=\mathbb{E}_{(f,\bm{g})\sim\widetilde{\mathcal{P}}}[f( \bm{x})]\), \(\widetilde{\bm{G}}(\bm{x})=\mathbb{E}_{(f,\bm{g})\sim\widetilde{\mathcal{P}}}[ \bm{g}(\bm{x})]\), \(F_{t}(\bm{x})=\mathbb{E}_{(f,\bm{g})\sim\mathcal{P}_{t}}[f(\bm{x})]\) and \(\bm{G}_{t}(\bm{x})=\mathbb{E}_{(f,\bm{g})\sim\mathcal{P}_{t}}[\bm{g}(\bm{x})]\) for all \(t\in[T]\) and any \(x\in\mathcal{X}\). Then for any \(\bm{\lambda}\in[\bm{0},\frac{\widetilde{F}}{\beta}\bm{e}]\), we have \[\text{OPT}(\mathcal{P}_{1:T}) \leq \max_{\bm{x}_{1:T}\in\mathcal{X}^{T}}\sum_{t\in[T]}\big{(}F_{t}(\bm{ x}_{t})+\bm{\lambda}^{\top}\bm{G}_{t}(\bm{x}_{t})\big{)}\] \[\leq \max_{\bm{x}_{1:T}\in\mathcal{X}^{T}}\sum_{t\in[T]}\big{(}\widetilde {F}(\bm{x}_{t})+\bm{\lambda}^{\top}\widetilde{\bm{G}}(\bm{x}_{t})\big{)}+( \bar{F}+\bar{G}K\frac{\bar{F}}{\beta})\delta\] \[= T\cdot\max_{\bm{x}\in\mathcal{X}}(\widetilde{F}(\bm{x})+\bm{ \lambda}^{\top}\widetilde{\bm{G}}(\bm{x}))+(\bar{F}+\bar{G}K\frac{\bar{F}}{ \beta})\delta,\]

where the last inequality follows the definitions of \((\widetilde{F},\widetilde{\bm{G}})\), Assumption 2.1, and the general definition of \(\delta\)-corruption in Eq. (27). After choosing \(\bm{\tilde{\lambda}}=\frac{1}{\tau_{A}}\sum_{t\in[\tau_{A}]}\bm{\lambda}_{t}\), similar to our proof in Eq. (20) for the stochastic case we have

\[\text{OPT}(\mathcal{P}_{1:T})\] (30) \[= \mathbb{E}\Big{[}\frac{T-\tau_{A}}{T}\text{OPT}(\mathcal{P}_{1:T} )+\frac{\tau_{A}}{T}\text{OPT}(\mathcal{P}_{1:T})\Big{]}\] \[\overset{(a)}{\leq} \mathbb{E}\Big{[}(T-\tau_{A})\bar{F}+\tau_{A}\cdot\max_{\bm{x}\in \mathcal{X}}(\widetilde{F}(\bm{x})+\bm{\lambda}^{\top}\widetilde{\bm{G}}(\bm{ x}))+\frac{\tau_{A}}{T}(\bar{F}+\bar{G}K\frac{\bar{F}}{\beta})\delta\Big{]}\] \[= \mathbb{E}\Big{[}(T-\tau_{A})\bar{F}+\frac{\tau_{A}}{T}(\bar{F}+ \bar{G}K\frac{\bar{F}}{\beta})\delta+\max_{\bm{x}\in\mathcal{X}}(\sum_{t\in[ \tau_{A}]}\widetilde{F}(\bm{x})+\bm{\lambda}_{t}^{\top}\widetilde{\bm{G}}(\bm{ x}))\Big{]}\] \[\overset{(b)}{\leq} \mathbb{E}\Big{[}(T-\tau_{A})\bar{F}+\Big{(}1+\frac{\tau_{A}}{T} \Big{)}\left(\bar{F}+\bar{G}K\frac{\bar{F}}{\beta}\right)\delta+\max_{\bm{x} \in\mathcal{X}}\sum_{t\in[\tau_{A}]}(F_{t}(\bm{x})+\bm{\lambda}_{t}^{\top}\bm{ G}_{t}(\bm{x}))\Big{]}\] \[\leq \mathbb{E}\Big{[}(T-\tau_{A})\bar{F}+\Big{(}1+\frac{\tau_{A}}{T} \Big{)}\left(\bar{F}+\bar{G}K\frac{\bar{F}}{\beta}\right)\delta+\max_{\bm{x} \in\mathcal{X}}\sum_{t\in[\tau_{A}]}\mathbb{E}\left[f_{t}(\bm{x})+\bm{\lambda} _{t}^{\top}\bm{g}_{t}(\bm{x})\;\Big{|}\;\sigma(\mathcal{H}_{t-1})\right]\Big{]}\] \[\leq \mathbb{E}\Big{[}(T-\tau_{A})\bar{F}+2(\bar{F}+\bar{G}K\frac{\bar {F}}{\beta})\delta+\max_{\bm{x}\in\mathcal{X}}\sum_{t\in[\tau_{A}]}h_{t}(\bm{ x})\Big{]},\]

where (a) follows from Eq. (29); (b) follows from the definition of general \(\delta\)-corruption in Eq. (27). Finally, we complete the proof by using the definition \(f_{t}(\bm{x}_{t})=h_{t}(\bm{x}_{t})-\bm{\lambda}_{t}^{\top}\bm{g}_{t}(\bm{x}_{ t})\) and following the same argument as in Eq. (22) for the stochastic regime.

#### Periodic.

Recall in Section 2.2 that in the periodic regime, there exists cycle length \(q\in\mathbb{N}\) such that \(T=cq\) for some integer \(c\geq 2\) with \(\mathcal{P}_{1:T}\) as \(\mathcal{P}_{1:q}=\mathcal{P}_{q+1:2q}=\cdots=\mathcal{P}_{(c-1)q+1:T}\). For any \(t\in[T]\), define \(c_{t}\in[c]\) such that \((c_{t}-1)q+1\leq t\leq c_{t}q\). After denoting \(\widetilde{\mathcal{P}}=\frac{1}{q}\sum_{t\in[q]}\mathcal{P}_{t}\), we define the mean deviation within a single cycle of length \(q\) as

\[MD(\mathcal{P}_{1:q})=\sum_{1\leq t\leq q}\|\mathcal{P}_{t}-\widetilde{\mathcal{ P}}\|_{TV}\quad\text{and}\quad\delta=c\cdot MD(\mathcal{P}_{1:q}).\] (31)

We define \(\widetilde{F}(\bm{x})=\mathbb{E}_{(f,\bm{g})\sim\widetilde{\mathcal{P}}}[f(\bm {x})]\), \(\widetilde{\bm{G}}(\bm{x})=\mathbb{E}_{(f,\bm{g})\sim\widetilde{\mathcal{P}}}[ \bm{g}(\bm{x})]\), \(F_{t}(\bm{x})=\mathbb{E}_{(f,\bm{g})\sim\mathcal{P}_{t}}[f(\bm{x})]\) and \(\bm{G}_{t}(\bm{x})=\mathbb{E}_{(f,\bm{g})\sim\mathcal{P}_{t}}[\bm{g}(\bm{x})]\) for all \(t\in[T]\) and any \(x\in\mathcal{X}\). Then for any \(\bm{\lambda}\in[\bm{0},\frac{\bar{F}}{\beta}\bm{e}]\), we have

\[\text{OPT}(\mathcal{P}_{1:T}) \leq \max_{\bm{x}_{1:T}\in\mathcal{X}^{T}}\sum_{t\in[T]}\big{(}F_{t}( \bm{x}_{t})+\bm{\lambda}^{\top}\bm{G}_{t}(\bm{x}_{t})\big{)}\] \[= c\cdot\max_{\bm{x}_{1:q}\in\mathcal{X}^{q}}\sum_{t\in[q]}\big{(}F_ {t}(\bm{x}_{t})+\bm{\lambda}^{\top}\bm{G}_{t}(\bm{x}_{t})\big{)}\] \[\leq cq\cdot\max_{\bm{x}\in\mathcal{X}}(\widetilde{F}(\bm{x})+\bm{ \lambda}^{\top}\widetilde{\bm{G}}(\bm{x}))+(\bar{F}+\bar{G}K\frac{\bar{F}}{\beta} )c\cdot MD(\mathcal{P}_{1:q})\] \[\leq cq\cdot\max_{\bm{x}\in\mathcal{X}}(\widetilde{F}(\bm{x})+\bm{ \lambda}^{\top}\widetilde{\bm{G}}(\bm{x}))+(\bar{F}+\bar{G}K\frac{\bar{F}}{\beta} )\delta,\]where the equality follows the nature of periodic setting and the last inequality follows the definitions of \((\widetilde{F},\widetilde{\bm{G}})\), Assumption 2.1, and (31). After choosing \(\bm{\lambda}=\sum_{\hat{c}\in[c_{\tau_{A}}-1]}\frac{\overline{\sigma}_{A}}{\tau _{A}}\bm{\lambda}_{(\hat{c}-1)q+1}+\frac{\tau_{A}-(c_{\tau_{A}}-1)q}{\tau_{A}} \bm{\lambda}_{(c_{\tau_{A}}-1)q+1}\), we further have that

\[\text{OPT}(\mathcal{P}_{1:T})\] \[= \frac{T-\tau_{A}}{T}\text{OPT}(\mathcal{P}_{1:T})+\frac{\tau_{A}} {T}\text{OPT}(\mathcal{P}_{1:T})\] \[\leq (T-\tau_{A})\bar{F}+\tau_{A}\cdot\max_{\bm{x}\in\mathcal{X}}( \widetilde{F}(\bm{x})+\bm{\lambda}^{\top}\widetilde{\bm{G}}(\bm{x}))+\frac{ \tau_{A}}{T}(\bar{F}+\bar{G}K\frac{\bar{F}}{\beta})\delta\] \[= (T-\tau_{A})\bar{F}+\max_{\bm{x}\in\mathcal{X}}\left(\tau_{A} \widetilde{F}(\bm{x})+\left(\sum_{\hat{c}\in[c_{\tau_{A}}-1]}q\bm{\lambda}_{( \hat{c}-1)q+1}+(\tau_{A}-(c_{\tau_{A}}-1)q)\bm{\lambda}_{(c_{\tau_{A}}-1)q+1} \right)^{\top}\widetilde{\bm{G}}(\bm{x})\right)\] \[+\frac{\tau_{A}}{T}(\bar{F}+\bar{G}K\frac{\bar{F}}{\beta})\delta\] \[= (T-\tau_{A})\bar{F}+\max_{\bm{x}\in\mathcal{X}}\left(q\cdot\sum_{ \hat{c}\in[c_{\tau_{A}}-1]}\left(\widetilde{F}(\bm{x})+\bm{\lambda}_{(\hat{c} -1)q+1}^{\top}\widetilde{\bm{G}}(\bm{x})\right)\right.\] \[+(\tau_{A}-(c_{\tau_{A}}-1)q)\cdot\left(\widetilde{F}(\bm{x})+ \bm{\lambda}_{(\hat{c}-1)q+1}^{\top}\widetilde{\bm{G}}(\bm{x})\right)\Big{)}+ \frac{\tau_{A}}{T}(\bar{F}+\bar{G}K\frac{\bar{F}}{\beta})\delta\] \[\leq (T-\tau_{A})\bar{F}+\max_{\bm{x}\in\mathcal{X}}\sum_{t\in[\tau_{A }]}\left(\widetilde{F}(\bm{x})+\bm{\lambda}_{t}^{\top}\widetilde{\bm{G}}(\bm{ x})\right)+\bar{G}\cdot\sum_{t\in[\tau_{A}]}\|\bm{\lambda}_{t}-\bm{\lambda}_{(c_{t}-1)q+1} \|_{1}+\frac{\tau_{A}}{T}(\bar{F}+\bar{G}K\frac{\bar{F}}{\beta})\delta.\]

From Eq. (9) in Algorithm 1, we know that \(\|\bm{\lambda}_{t+1}-\bm{\lambda}_{t}\|_{1}\leq\eta\bar{G}K\), which further implies \(\|\bm{\lambda}_{t+i}-\bm{\lambda}_{t}\|_{1}\leq\eta\bar{G}Ki\) for any \(i\in[q-1]\) and thus

\[\sum_{t\in[\tau_{A}]}\|\bm{\lambda}_{t}-\bm{\lambda}_{(c_{t}-1)q+1}\|_{1}\leq c _{\tau_{A}}\eta\bar{G}K\sum_{i\in[q-1]}i\leq\frac{1}{2}\bar{G}K\eta c_{\tau_{A} }q^{2}.\] (32)

After combining the two equations above, it follows that

\[\text{OPT}(\mathcal{P}_{1:T})\] \[\leq \mathbb{E}\Big{[}(T-\tau_{A})\bar{F}+\max_{\bm{x}\in\mathcal{X}} \sum_{t\in[\tau_{A}]}\left(\widetilde{F}(\bm{x})+\bm{\lambda}_{t}^{\top} \widetilde{\bm{G}}(\bm{x})\right)+\frac{1}{2}\bar{G}^{2}K\eta c_{\tau_{A}}q^{2} +\frac{\tau_{A}}{T}(\bar{F}+\bar{G}K\frac{\bar{F}}{\beta})\delta\Big{]}\] \[\leq \mathbb{E}\Big{[}(T-\tau_{A})\bar{F}+2(\bar{F}+\bar{G}K\frac{\bar{ F}}{\beta})\delta+\frac{1}{2}\bar{G}^{2}K\eta qT+\max_{\bm{x}\in\mathcal{X}}\sum_{t\in[ \tau_{A}]}\mathbb{E}\left[h_{t}(\bm{x})\,\Big{|}\,\,\sigma(\mathcal{H}_{t-1}) \right]\Big{]}\] \[\leq \mathbb{E}\Big{[}(T-\tau_{A})\bar{F}+2(\bar{F}+\bar{G}K\frac{\bar{ F}}{\beta})\delta+\frac{1}{2}\bar{G}^{2}K\eta qT+\max_{\bm{x}\in\mathcal{X}}\sum_{t\in[ \tau_{A}]}h_{t}(\bm{x})\Big{]}\;,\]

where the second last inequality follows from \(c_{\tau_{A}}q\leq cq=T\).

Finally, we complete the proof by using the definition \(f_{t}(\bm{x}_{t})=h_{t}(\bm{x}_{t})-\bm{\lambda}_{t}^{\top}\bm{g}_{t}(\bm{x}_{ t})\) and following the same argument as in Eq. (22) for the stochastic regime.

**Ergodic.**

Consider some \(\kappa\geq\log(T)\). Given the input distribution sequence \(\mathcal{P}_{1:T}\), denote \(\mathcal{P}_{(t+\kappa)|[t-1]}\) as the conditional distribution of \((f_{t+\kappa},\bm{g}_{t+\kappa})\) conditioned on the \(\{(f_{\tau},\bm{g}_{\tau})\}_{\tau\in[t]}\). Then, in the ergodic regime, there exists a stationary distribution \(\widetilde{\mathcal{P}}\in\Delta(\mathcal{S})\) and absolute constant \(R>0\) such that

\[\sup_{\{(f_{t},\bm{g}_{t})\}_{t\in[T]}\in S^{T}}\sup_{t\in[T-\kappa]}\|\mathcal{ P}_{(t+\kappa)|[t-1]}-\widetilde{\mathcal{P}}\|_{TV}\leq\delta:=R\exp(-\kappa)\;;\] (33)see [10, Section 5.2] for further discussions. By defining \(\widetilde{F}(\bm{x})=\mathbb{E}_{(f,\bm{g})\sim\widetilde{\mathcal{P}}}[f(\bm{x})]\), \(\widetilde{\bm{G}}(\bm{x})=\mathbb{E}_{(f,\bm{g})\sim\widetilde{\mathcal{P}}}[ \bm{g}(\bm{x})]\), \(\hat{F}_{t+\kappa}(\bm{x})=\mathbb{E}_{(f,\bm{g})\sim\mathcal{P}_{(t+\kappa)| |t-1}}[f(\bm{x})]\), \(\hat{\bm{G}}_{t+\kappa}(\bm{x})=\mathbb{E}_{(f,\bm{g})\sim\mathcal{P}_{(t+\kappa)| |t-1}}[\bm{g}(\bm{x})]\), \(F_{t}(\bm{x})=\mathbb{E}_{(f,\bm{g})\sim\mathcal{P}_{t}}[f(\bm{x})]\) and \(\bm{G}_{t}(\bm{x})=\mathbb{E}_{(f,\bm{g})\sim\mathcal{P}_{t}}[\bm{g}(\bm{x})]\) for all \(t\in[T]\) and any \(x\in\mathcal{X}\), we know that for any \(\bm{\lambda}\in[\bm{0},\frac{\bar{F}}{\beta}\bm{e}]\), it follows that

\[\text{OPT}(\mathcal{P}_{1:T})\] \[\leq \max_{\bm{x}_{1:T}\in\mathcal{X}^{T}}\mathbb{E}\left[\sum_{t\in[ T]}\left(F_{t}(\bm{x}_{t})+\bm{\lambda}^{\top}\bm{G}_{t}(\bm{x}_{t})\right)\right]\] \[= \max_{\bm{x}_{1:\kappa}\in\mathcal{X}^{\kappa}}\mathbb{E}\left[ \sum_{t\in[\kappa]}\left(F_{t}(\bm{x}_{t})+\bm{\lambda}^{\top}\bm{G}_{t}(\bm{x }_{t})\right)\right]+\max_{\bm{x}_{\kappa+1:T}\in\mathcal{X}^{T-\kappa}} \mathbb{E}\left[\sum_{t=1}^{T-\kappa}(\hat{F}_{t+\kappa}(\bm{x}_{t+\kappa})+ \bm{\lambda}^{\top}\hat{\bm{G}}_{t+\kappa}(\bm{x}_{t+\kappa}))\right]\] \[\leq (\bar{F}+\bar{G}K\frac{\bar{F}}{\beta})\kappa+\max_{\bm{x}_{\kappa +1:T}\in\mathcal{X}^{T-\kappa}}\sum_{t=1}^{T-\kappa}(\widetilde{F}(\bm{x}_{t+ \kappa})+\bm{\lambda}^{\top}\widetilde{\bm{G}}(\bm{x}_{t+\kappa}))+(\bar{F}+ \bar{G}K\frac{\bar{F}}{\beta})\cdot(T-\kappa)\delta\] \[\leq T\cdot\max_{\bm{x}\in\mathcal{X}}(\widetilde{F}(\bm{x})+\bm{ \lambda}^{\top}\widetilde{\bm{G}}(\bm{x}))+(\bar{F}+\bar{G}K\frac{\bar{F}}{ \beta})\kappa+(\bar{F}+\bar{G}K\frac{\bar{F}}{\beta})\cdot T\delta\;.\]

By choosing \(\bm{\lambda}=\frac{1}{\tau_{A}}\sum_{t\in[\tau_{A}]}\bm{\lambda}_{t}\), we further have

\[\text{OPT}(\mathcal{P}_{1:T})\] \[= \mathbb{E}\Big{[}\frac{T-\tau_{A}}{T}\text{OPT}(\mathcal{P}_{1:T} )+\frac{\tau_{A}}{T}\text{OPT}(\mathcal{P}_{1:T})\Big{]}\] \[\leq \mathbb{E}\Big{[}(T-\tau_{A})\bar{F}+\tau_{A}\cdot\max_{\bm{x}\in \mathcal{X}}\Big{(}\widetilde{F}(\bm{x})+\bm{\lambda}^{\top}\widetilde{\bm{G} }(\bm{x})\Big{)}\Big{]}+(\bar{F}+\bar{G}K\frac{\bar{F}}{\beta})\kappa+(\bar{F} +\bar{G}K\frac{\bar{F}}{\beta})\cdot T\delta\] \[= \mathbb{E}\Big{[}(T-\tau_{A})\bar{F}+\max_{\bm{x}\in\mathcal{X}} \sum_{t\in[\tau_{A}]}\Big{(}\widetilde{F}(\bm{x})+\bm{\lambda}_{t}^{\top} \widetilde{\bm{G}}(\bm{x})\Big{)}\Big{]}+(\bar{F}+\bar{G}K\frac{\bar{F}}{ \beta})\kappa+(\bar{F}+\bar{G}K\frac{\bar{F}}{\beta})\cdot T\delta\] \[\leq \mathbb{E}\Big{[}(T-\tau_{A})\bar{F}+\max_{\bm{x}\in\mathcal{X}} \sum_{t\in[\tau_{A}]}\Big{(}\hat{F}_{t+\kappa}(\bm{x})+\bm{\lambda}_{t}^{ \top}\hat{\bm{G}}_{t+\kappa}(\bm{x})\Big{)}\Big{]}+(\bar{F}+\bar{G}K\frac{\bar {F}}{\beta})\kappa+2(\bar{F}+\bar{G}K\frac{\bar{F}}{\beta})\cdot T\delta\] \[= \mathbb{E}\Big{[}(T-\tau_{A})\bar{F}+\max_{\bm{x}\in\mathcal{X}} \mathbb{E}\sum_{t\in[\tau_{A}]}(\hat{F}_{t+\kappa}(\bm{x})+\bm{\lambda}_{t+ \kappa}^{\top}\hat{\bm{G}}_{t+\kappa}(\bm{x})+(\bm{\lambda}_{t}-\bm{\lambda}_ {t+\kappa})^{\top}\hat{\bm{G}}_{t+\kappa}(\bm{x}_{t}))\Big{]}\] \[+(\bar{F}+\bar{G}K\frac{\bar{F}}{\beta})\kappa+2(\bar{F}+\bar{G}K \frac{\bar{F}}{\beta})\cdot T\delta\] \[\leq \mathbb{E}\Big{[}(T-\tau_{A})\bar{F}+\max_{\bm{x}\in\mathcal{X}} \sum_{t\in[\tau_{A}-\kappa]}(\hat{F}_{t+\kappa}(\bm{x})+\bm{\lambda}_{t+ \kappa}^{\top}\hat{\bm{G}}_{t+\kappa}(\bm{x}_{t}))\Big{]}+\kappa\eta TK\bar{G}^ {2}\] \[+2(\bar{F}+\bar{G}K\frac{\bar{F}}{\beta})\kappa+2(\bar{F}+\bar{K} \frac{\bar{F}}{\beta})\cdot T\delta\] \[\overset{(b)}{\leq} \mathbb{E}\Big{[}(T-\tau_{A})\bar{F}+\max_{\bm{x}\in\mathcal{X}} \sum_{t=\kappa+1}^{T\bm{x}}h_{t}(\bm{x})\Big{]}+\kappa\eta TK\bar{G}^{2}+2( \bar{F}+\bar{G}K\frac{\bar{F}}{\beta})\kappa+2(\bar{F}+\bar{G}K\frac{\bar{F}}{ \beta})\cdot T\delta\] \[\leq \mathbb{E}\Big{[}(T-\tau_{A})\bar{F}+\max_{\bm{x}\in\mathcal{X}} \sum_{t\in[\tau_{A}]}h_{t}(\bm{x})\Big{]}+\kappa\eta TK\bar{G}^{2}+2(\bar{F}+ \bar{G}K\frac{\bar{F}}{\beta})\kappa+2(\bar{F}+\bar{G}K\frac{\bar{F}}{\beta}) \cdot T\delta\]\[\stackrel{{(c)}}{{\leq}}\ \mathbb{E}\Big{[}(T-\tau_{A})\bar{F}+ \max_{\bm{x}\in\mathcal{X}}\sum_{t\in[\tau_{A}]}h_{t}(\bm{x})\Big{]}+\kappa\eta TK \bar{G}^{2}+2(\bar{F}+\bar{G}K\frac{\bar{F}}{\beta})\kappa+2R(\bar{F}+\bar{G}K \frac{\bar{F}}{\beta}),\]

where in (a), from (9) in Algorithm 1, we know that \(\|\bm{\lambda}_{t+1}-\bm{\lambda}_{t}\|_{1}\leq\eta\bar{G}K\), which further implies \(\|\bm{\lambda}_{t+\kappa}-\bm{\lambda}_{t}\|_{1}\leq\kappa\eta\bar{G}K\) and thus

\[(\bm{\lambda}_{t}-\bm{\lambda}_{t+\kappa})^{\top}\dot{\bm{G}}_{t+ \kappa}(\bm{x}_{t})\leq\kappa\eta K\bar{G}^{2}\.\] (35)

In (b), we used the fact that for any \(t\geq\kappa+1\), we have

\[\mathbb{E}\Big{[}\max_{\bm{x}\in\mathcal{X}}\sum_{t\in[\tau_{A}- \kappa]}(\hat{F}_{t+\kappa}(\bm{x})+\bm{\lambda}_{t+\kappa}^{\top}\dot{\bm{G}} _{t+\kappa}(\bm{x}_{t}))\Big{]}\] (36) \[= \mathbb{E}\Big{[}\max_{\bm{x}\in\mathcal{X}}\sum_{t\in[\tau_{A}- \kappa]}\mathbb{E}\Big{[}h_{t+\kappa}(\bm{x})\mid(f_{\tau},\bm{g}_{\tau})_{\tau \in[t-1]}\Big{]}\Big{]}\] \[\leq \mathbb{E}\Big{[}\max_{\bm{x}\in\mathcal{X}}\sum_{t\in[\tau_{A}- \kappa]}h_{t+\kappa}(\bm{x})\Big{]}\.\]

In (c) we used the fact that \(\kappa\geq\log(T)\), so \(\delta=R\exp(-\kappa)\geq R\).

Finally, we complete the proof by using the definition \(f_{t}(\bm{x}_{t})=h_{t}(\bm{x}_{t})-\bm{\lambda}_{t}^{\top}\bm{g}_{t}(\bm{x}_{ t})\) and following the same argument as in Eq. (22) for the stochastic regime.

### Proof of Theorem 4.2

Proof.: We bound the regret in every world as followed

\[\mathcal{R}_{T} =\ \text{OPT}(\mathcal{P}_{1:T})-\sum_{t\in[T]}\mathbb{E}\left[f_{ t}(\bm{x}_{t})\right]\] \[\stackrel{{(a)}}{{\leq}}\ \mathbb{E}\Big{[}\bar{F}(T-\tau_{A})+ \sum_{t\in[\tau_{A}]}\bm{\lambda}_{t}^{\top}\bm{g}_{t}(\bm{x}_{t})+\mathcal{R }_{\text{BOCO}}(\tau_{A})\Big{]}\] \[\stackrel{{(b)}}{{\leq}}\ \mathbb{E}\Big{[} \mathcal{R}_{\text{BOCO}}(\tau_{A})\Big{]}\]

where (a) follows from Lemma 4.3, and (b) follows from Lemma 4.5. Recall \(\mathcal{R}_{\text{BOCO}}(\tau_{A})\) is specified in Lemma 4.3 for each world.

In the following we bound \(\mathcal{R}_{\text{BOCO}}(\tau_{A})\) for each world.

**Stochastic.**

\[\mathbb{E}\Big{[}\mathcal{R}_{\text{BOCO}}(\tau_{A})\Big{]}= \mathbb{E}\Big{[}\max_{\bm{x}\in\mathcal{X}}\sum_{t\in[\tau_{A}]}h_{t}(\bm{x} )-h_{t}(\bm{x}_{t})\Big{]}\ \stackrel{{(a)}}{{\leq}}\ \mathcal{O}\Big{(}\frac{(\rho+\alpha)T}{ \beta}+\frac{1}{\gamma_{i}}+\frac{\gamma_{i}KT}{\beta^{2}\rho^{2}}+T\epsilon+ \frac{1}{\epsilon}\Big{)}\ \stackrel{{(b)}}{{=}}\ \mathcal{O}\Big{(}T^{\frac{3}{4}}\Big{)}\,\] (37)

where (a) follows from Lemma 4.6 by taking the comparator sequence \(\bm{y}_{t}=\arg\max_{\bm{x}\in\mathcal{X}}\sum_{t\in[\tau_{A}]}h_{t}(\bm{x})\) for all \(t\in[\tau_{A}]\) such that \(P(\bm{y}_{1:T})=1\), as well as any primal ascent expert \(i\in[N]\); (b) follows from taking \(\eta=\frac{1}{\sqrt{KT}}\), \(\rho=K^{\frac{1}{3}}T^{-\frac{1}{4}}\), \(\epsilon=T^{-\frac{1}{2}}\), \(\beta=\frac{1}{\log(T)}\), and finally choosing \(\gamma_{i}=K^{-\frac{1}{6}}(1+DT)^{\frac{1}{2}}T^{-\frac{3}{4}}\). Recall all primal ascent expert stepsizes are \(\{\gamma_{1}\ldots\gamma_{N}\}=\{2^{-i}K^{-\frac{1}{6}}(1+DT)^{\frac{1}{2}}T^{- \frac{3}{4}}:i=0\ldots N-1\}\).

\(\delta\)**-corrupted, Periodic, and Ergodic.** The proof is nearly identical with that of the stochastic world in Eq. (37) given that we still consider the comparator sequence \(\bm{y}_{t}=\arg\max_{\bm{x}\in\mathcal{X}}\sum_{t\in[\tau_{A}]}h_{t}(\bm{x})\) for all \(t\in[\tau_{A}]\) such that \(P(\bm{y}_{1:T})=1\). Hence we will omit the proof.

**Adversarial.** Recall the definition \(\widetilde{\bm{y}}_{t}=\arg\max_{\bm{x}\in\mathcal{X}}f_{t}(\bm{x}_{t})+\bm{ \lambda}_{t}^{\top}\bm{g}(\bm{x}_{t})\). Then we have

\[\begin{split}\mathbb{E}\Big{[}\mathcal{R}_{\text{BOCO}}(\tau_{A}) \Big{]}&=~{}\bigg{(}1-\frac{1}{\xi}\bigg{)}\,\text{OPT}(\mathcal{ P}_{1:T})+\sum_{t\in[\tau_{A}]}\mathbb{E}\Big{[}h_{t}(\widetilde{\bm{y}}_{t})-h_{t}( \bm{x}_{t})\Big{]}\\ &\leq~{}\mathcal{O}\Big{(}\frac{(\rho+\alpha)T}{\beta}+\frac{1+P (\widetilde{\bm{y}}_{1:T})}{\gamma_{i}}+\frac{\gamma_{i}KT}{\beta^{2}\rho^{2}} +T\epsilon+\frac{1}{\epsilon}\Big{)}\\ &\leq~{}\bigg{(}1-\frac{1}{\xi}\bigg{)}\,\text{OPT}(\mathcal{P}_ {1:T})+\tilde{\mathcal{O}}\left(\sqrt{1+P(\widetilde{\bm{y}}_{1:T})}\cdot T^{ \frac{3}{4}}\right),\end{split}\] (38)

where we chose the primal ascent stepsize \(\gamma_{i}\) s.t.

\[\frac{1}{2}K^{-\frac{1}{6}}(1+P(\widetilde{\bm{y}}_{1:T}))^{\frac{1}{2}}T^{- \frac{3}{4}}\leq\gamma_{i}\leq K^{-\frac{1}{6}}(1+P(\widetilde{\bm{y}}_{1:T}) )^{\frac{1}{2}}T^{-\frac{3}{4}}\] (39)

We note that such a \(\gamma_{i}\) must exist because \(P(\widetilde{\bm{y}}_{1:T})\leq DT\) given all \(\widetilde{\bm{y}}_{t}\in\mathcal{X}\), so that the largest element in the primal ascent stepsize set, namely \(K^{-\frac{1}{6}}(1+DT)^{\frac{1}{2}}T^{-\frac{3}{4}}\) is larger than the upper bound above, namely \(K^{-\frac{1}{6}}(1+P(\widetilde{\bm{y}}_{1:T}))^{\frac{1}{2}}T^{-\frac{3}{4}}\).

### Proof for Lemma a.1

Proof.: Recall the definition \(h_{t}(\bm{x})=f_{t}(\bm{x})+\bm{\lambda}_{t}^{\top}\bm{g}_{t}(\bm{x})\) in Eq. (5). Then we have

\[\begin{split}\Big{|}h_{t}(\bm{x})-h_{t}(\bm{x}^{\prime})\Big{|}& \leq~{}\Big{|}f_{t}(\bm{x})-f_{t}(\bm{x}^{\prime})\Big{|}+\|\bm{ \lambda}_{t}\|\cdot\|\bm{g}_{t}(\bm{x})-\bm{g}_{t}(\bm{x}^{\prime})\|\\ &\stackrel{{(a)}}{{\leq}}~{}L\|\bm{x}-\bm{x}^{\prime} \|+K\frac{\bar{F}}{\beta}L\|\bm{x}-\bm{x}^{\prime}\|=(1+K\frac{\bar{F}}{\beta })L\cdot\|\bm{x}-\bm{x}^{\prime}\|\,\end{split}\] (40)

where (a) follows from the fact that any \((f,\bm{g})\in\mathcal{S}\) are \(L\)-lipschitz under Assumption 2.1.

On the other hand, recall the definition \(\hat{h}_{t}(\bm{x})=\mathbb{E}_{\bm{v}\sim U(\mathbb{B})}[\mathcal{L}_{t}(\bm {x}+\rho\bm{v},\bm{\lambda}_{t})]\) in Eq. (11). Then we have

\[\begin{split}\Big{|}h_{t}(\bm{x})-\hat{h}_{t}(\bm{x})\Big{|}= \mathbb{E}_{\bm{v}\sim U(\mathbb{B})}\Big{[}h_{t}(\bm{x})-h_{t}(\bm{x}+\rho \bm{v})\Big{]}~{}\leq~{}(1+K\frac{\bar{F}}{\beta})L\rho\cdot E_{\bm{v}\sim U (\mathbb{B})}\Big{[}\|\bm{v}\|\Big{]}{\leq}(1+K\frac{\bar{F}}{\beta})L\rho\,\end{split}\] (41)

where the inequality follows from the first part of this lemma. 

### Proof of Lemma a.2

Proof.: Recall the definitions \(h_{t}(\bm{x})=f_{t}(\bm{x})+\bm{\lambda}_{t}^{\top}\bm{g}_{t}(\bm{x})\) in Eq. (5), and \(\hat{h}_{t}(\bm{x})=\mathbb{E}_{\bm{v}\sim U(\mathbb{B})}[\mathcal{L}_{t}(\bm{x }+\rho\bm{v},\bm{\lambda}_{t})]\) in Eq. (11). Then, we have

\[\begin{split}\hat{h}_{t}(\bm{y})-\hat{h}_{t}(\widetilde{\bm{x}}_{t })&\stackrel{{(a)}}{{\leq}}~{}\langle\nabla\hat{h}_{t }(\widetilde{\bm{x}}_{t}),\bm{y}-\widetilde{\bm{x}}_{t}\rangle\\ &\stackrel{{(b)}}{{=}}~{}\Big{\langle}\frac{d}{\rho} \cdot\mathbb{E}_{\bm{u}\sim U(\mathbb{S})}\left[h_{t}(\widetilde{\bm{x}}_{t}+ \rho\bm{u})\cdot\bm{u}\right]\,\ \bm{y}-\widetilde{\bm{x}}_{t}\Big{\rangle}\\ &=~{}\mathbb{E}_{\bm{u}_{t}\sim U(\mathbb{S})}\left[\left\langle \frac{d}{\rho}\cdot h_{t}(\widetilde{\bm{x}}_{t}+\rho\bm{u}_{t})\cdot\bm{u}_{t} \,\ \bm{y}-\widetilde{\bm{x}}_{t}\right\rangle\right]\\ &\stackrel{{(c)}}{{=}}~{}\mathbb{E}_{\bm{u}_{t}\sim U( \mathbb{S})}\left[\left\langle\nabla_{t},\bm{y}-\widetilde{\bm{x}}_{t}\right\rangle \right]\\ &\stackrel{{(d)}}{{=}}~{}\mathbb{E}_{\bm{u}_{t}\sim U( \mathbb{S})}\left[\ell_{t}(\widetilde{\bm{x}}_{t})-\ell_{t}(\bm{y})\right]\end{split}\] (42)

where (a) follows from concavity of \(\hat{h}_{t}(\cdot)\); (b) follows from Lemma B.2 by taking \(h=-h_{t}\), so that in the lemma \(-\nabla_{\bm{x}}\mathbb{E}_{\bm{v}\sim U(\mathbb{B})}[h(\bm{x}+\rho\bm{v})]= \nabla\hat{h}_{t}(\bm{x})\) and \(-\mathbb{E}_{\bm{u}\sim U(\mathbb{S})}\left[h(\bm{x}+\rho\bm{u})\cdot\bm{u} \right]=\mathbb{E}_{\bm{u}\sim U(\mathbb{S})}\left[h_{t}(\bm{x}+\rho\bm{u}) \cdot\bm{u}\right]\); (c) follows from the gradient estimate in Eq. (7) where

\[\nabla_{t}=\frac{d}{\rho}\left(f_{t}(\bm{x}_{t})+\bm{\lambda}_{t}^{\top}\bm{g}_{t }(\bm{x}_{t})\right)\cdot\bm{u}_{t}=\frac{d}{\rho}\cdot h_{t}(\bm{x}_{t}) \cdot\bm{u}_{t}=\frac{d}{\rho}\cdot h_{t}(\widetilde{\bm{x}}_{t}+\rho\bm{u}_{t}) \cdot\bm{u}_{t}\]

Finally, (d) follows from the definition of surrogate loss functions in Eq. (8).

### Proof of Lemma a.3

**Proving (i):**

Proof.: Let's denote \(\nabla_{t}=\|\bm{\nabla}_{t}\|\). Since \(\widetilde{\bm{x}}_{t+1}^{i}=\Pi_{(1-\alpha)\mathcal{X}}(\widetilde{\bm{x}}_{t} ^{i}+\gamma_{i}\bm{\nabla}_{t})\) we have \(\|\bm{y}-\widetilde{\bm{x}}_{t+1}^{i}\|\leq\|\bm{y}-(\widetilde{\bm{x}}_{t}^{i }+\gamma_{i}\bm{\nabla}_{t})\|\) for any \(\bm{y}\in(1-\alpha)\mathcal{X}\). Then

\[\|\bm{y}-\widetilde{\bm{x}}_{t+1}^{i}\|^{2}\leq\|\bm{y}-\widetilde {\bm{x}}_{t}^{i}\|^{2}-2\gamma_{i}\bm{\nabla}_{t}^{\top}(\bm{y}-\widetilde{\bm {x}}_{t}^{i})+\gamma_{i}^{2}\nabla_{t}^{2}\] \[\implies \|\widetilde{\bm{x}}_{t+1}^{i}\|^{2}\;\leq\;\|\widetilde{\bm{x}}_ {t}^{i}\|^{2}+2\bm{y}^{\top}(\widetilde{\bm{x}}_{t+1}^{i}-\widetilde{\bm{x}}_{ t}^{i})-2\gamma_{i}\bm{\nabla}_{t}^{\top}(\bm{y}-\widetilde{\bm{x}}_{t}^{i})+ \gamma_{i}^{2}\nabla_{t}^{2}\;.\]

Hence by taking \(\bm{y}=(1-\alpha)\bm{y}_{t}\in(1-\alpha)\mathcal{X}\) and rearranging we get

\[\begin{split}& 2\gamma_{i}\left(\ell_{t}\left(\widetilde{\bm{x}}_{t} ^{i}\right)-\ell_{t}\left((1-\alpha)\bm{y}_{t}\right)\right)\\ &=\;2\gamma_{i}\bm{\nabla}_{t}^{\top}((1-\alpha)\bm{y}_{t}- \widetilde{\bm{x}}_{t}^{i})\\ &\leq\;\|\widetilde{\bm{x}}_{t}^{i}\|^{2}-\|\widetilde{\bm{x}}_{ t+1}^{i}\|^{2}+2(1-\alpha)\bm{y}_{t}^{\top}(\widetilde{\bm{x}}_{t+1}^{i}- \widetilde{\bm{x}}_{t}^{i})+\gamma_{i}^{2}\nabla_{t}^{2}\;.\end{split}\] (43)

Telescoping with \(\tau=1\ldots t\) we get

\[\begin{split}&\sum_{\tau\in[t]}\ell_{\tau}\left(\widetilde{\bm {x}}_{\tau}^{i}\right)-\sum_{\tau\in[t]}\ell_{\tau}\left((1-\alpha)\bm{y}_{ \tau}\right)\\ &\leq\frac{1}{2\gamma_{i}}\|\widetilde{\bm{x}}_{1}^{i}\|^{2}+ \frac{1-\alpha}{\gamma_{i}}\sum_{\tau\in[t]}\bm{y}_{\tau}^{\top}(\widetilde{ \bm{x}}_{\tau+1}^{i}-\widetilde{\bm{x}}_{\tau}^{i})+\frac{\gamma_{i}}{2}\sum_{ \tau\in[t]}\nabla_{\tau}^{2}\\ &=\;\frac{1}{2\gamma_{i}}\|\widetilde{\bm{x}}_{1}^{i}\|^{2}+ \frac{1-\alpha}{\gamma_{i}}\left(\bm{y}_{t}^{\top}\widetilde{\bm{x}}_{t+1}^{i} +\sum_{\tau\in[t-1]}\left(\bm{y}_{\tau}-\bm{y}_{\tau+1}\right)^{\top} \widetilde{\bm{x}}_{\tau+1}^{i}\right)+\frac{\gamma_{i}}{2}\sum_{\tau\in[t]} \nabla_{\tau}^{2}\\ &\leq\;\frac{1}{2\gamma_{i}}\|\widetilde{\bm{x}}_{1}^{i}\|^{2}+ \frac{1-\alpha}{\gamma_{i}}\!\left(\|\bm{y}_{t}\|\cdot\|\widetilde{\bm{x}}_{t+ 1}^{i}\|+\sum_{\tau\in[t-1]}\|\bm{y}_{\tau}-\bm{y}_{\tau+1}\|\cdot\|\widetilde{ \bm{x}}_{\tau+1}^{i}\|\right)+\frac{\gamma_{i}}{2}\sum_{\tau\in[t]}\nabla_{ \tau}^{2}\\ &\leq\;\frac{(1-\alpha)^{2}D^{2}}{2\gamma_{i}}+\frac{(1-\alpha)^{ 2}D}{\gamma_{i}}\left(P(\bm{y}_{1:T})+D\right)+\frac{\gamma_{i}d^{2}}{2\rho^{2 }}\left(\bar{F}+K\frac{\bar{F}}{\beta}\bar{G}\right)^{2}t\;,\end{split}\] (44)

where \(P(\bm{y}_{1:T})\) is defined in the lemma statement. 

**Proving (ii):**

Proof.: First, we have for any \(t\in[T]\), \(i\in[N]\)

\[\begin{split}\left|\ell_{t}(\widetilde{\bm{x}}_{t}^{i})\right|& =\;\left|\bm{\nabla}_{t}^{T}\left(\widetilde{\bm{x}}_{t}-\widetilde{\bm{x}}_ {t}^{i}\right)\right|&\leq\;\|\bm{\nabla}_{t}\|\cdot\|\widetilde{\bm {x}}_{t}^{i}-\widetilde{\bm{x}}_{t}\|\;\leq\;\frac{d}{\rho}\left(\bar{F}+K\frac{ \bar{F}}{\beta}\bar{G}\right)\cdot(1-\alpha)D\;,\end{split}\] (45)

where we recall \(D=\sup_{\{\bm{x},\bm{x}^{\prime}\}\subseteq\mathcal{X}}\|\bm{x}-\bm{x}^{ \prime}\|\) is the diameter of \(\mathcal{X}\), and both \(\{\widetilde{\bm{x}}_{t}^{i},\widetilde{\bm{x}}_{t}\}\subseteq(1-\alpha) \mathcal{X}\).

Define \(W_{t}=\sum_{i\in[N]}w_{i,t}\) for all \(t\in[T]\), then

\[\begin{split}\log\left(\frac{W_{t+1}}{W_{t}}\right)& =\;\log\left(\sum_{i\in[N]}\frac{w_{i,t}\exp\left(-\epsilon\ell_{t}( \widetilde{\bm{x}}_{t}^{i})\right)}{W_{t}}\right)\\ &=\;\log\left(\mathbb{E}_{I_{t}\sim\bm{w}_{t}/W_{t}}\left[\exp \left(-\epsilon\ell_{t}(\widetilde{\bm{x}}_{t}^{I_{t}})\right)\right]\right)\\ &\stackrel{{(a)}}{{\leq}}\;-\epsilon\mathbb{E}_{I_{t} \sim\bm{w}_{t}/W_{t}}\left[\ell_{t}(\widetilde{\bm{x}}_{t}^{I_{t}})\right]+ \frac{\epsilon^{2}}{2}\cdot\left(\frac{d}{\rho}\left(\bar{F}+K\frac{\bar{F}}{ \beta}\bar{G}\right)\cdot(1-\alpha)D\right)^{2}\\ &\stackrel{{(b)}}{{=}}\;-\epsilon\ell_{t}\left(\mathbb{E} _{I_{t}\sim\bm{w}_{t}/W_{t}}\left[\widetilde{\bm{x}}_{t}^{I_{t}}\right]\right)+ \frac{\epsilon^{2}}{2}\cdot\left(\frac{d}{\rho}\left(\bar{F}+K\frac{\bar{F}}{ \beta}\bar{G}\right)\cdot(1-\alpha)D\right)^{2}\\ &\stackrel{{(c)}}{{=}}\;-\epsilon\ell_{t}\left( \widetilde{\bm{x}}_{t}\right)+\frac{\epsilon^{2}}{2}\cdot\left(\frac{d}{\rho} \left(\bar{F}+K\frac{\bar{F}}{\beta}\bar{G}\right)\cdot(1-\alpha)D\right)^{2}.\end{split}\]Here (a) follows from Hoeffding's Lemma as described in Lemma B.1 where we take \(X=\ell_{t}(\widetilde{\bm{x}}_{t}^{I_{t}})\), \(a=-\frac{d}{\rho}\left(\bar{F}+K\frac{\bar{F}}{\beta}\bar{G}\right)\cdot(1- \alpha)D\) and \(b=\frac{d}{\rho}\left(\bar{F}+K\frac{\bar{F}}{\beta}\bar{G}\right)\cdot(1- \alpha)D\); (b) follows from the definition that \(\ell_{t}(\widetilde{\bm{x}})=\bm{\nabla}_{t}^{T}(\widetilde{\bm{x}}- \widetilde{\bm{x}}_{t})\) is a linear function in \(\widetilde{\bm{x}}\); (c) follows from Eq.(6).

Hence, telescoping the above we get

\[\log\left(\frac{W_{t+1}}{W_{1}}\right) \leq -\epsilon\sum_{\tau\in[t]}\ell_{\tau}\left(\widetilde{\bm{x}}_{ \tau}\right)+\frac{t\epsilon^{2}}{2}\cdot\left(\frac{d}{\rho}\left(\bar{F}+K \frac{\bar{F}}{\beta}\bar{G}\right)\cdot(1-\alpha)D\right)^{2}\,.\] (47)

On the other hand, we have

\[\log\left(\frac{W_{t+1}}{W_{1}}\right) = \log(W_{t+1})-\log(W_{1})\] (48) \[\geq \log(\max_{i\in[N]}w_{i,t})-\log(N)\] \[= \max_{i\in[N]}\log(w_{i,t})-\log(N)\] \[\stackrel{{(a)}}{{=}} \max_{i\in[N]}\log\left(w_{i,1}\exp\left(-\epsilon\sum_{\tau\in[ t]}\ell_{\tau}\left(\widetilde{\bm{x}}_{\tau}^{i}\right)\right)\right)-\log(N)\] \[= -\epsilon\min_{i\in[N]}\sum_{\tau\in[t]}\ell_{\tau}\left( \widetilde{\bm{x}}_{\tau}^{i}\right)-\log(N)\;.\]

Hence, after combining Eqs. (47) and (48), and dividing both sides by \(\epsilon>0\), we get

\[-\sum_{\tau\in[t]}\ell_{\tau}\left(\widetilde{\bm{x}}_{\tau} \right)+\frac{t\epsilon}{2}\cdot\left(\frac{d}{\rho}\left(\bar{F}+K\frac{\bar {F}}{\beta}\bar{G}\right)\cdot(1-\alpha)D\right)^{2}\geq-\min_{i\in[N]}\sum_{ \tau\in[t]}\ell_{\tau}\left(\widetilde{\bm{x}}_{\tau}^{i}\right)-\frac{\log(N )}{\epsilon}\] (49) \[\Longrightarrow \sum_{\tau\in[t]}\ell_{\tau}\left(\widetilde{\bm{x}}_{\tau} \right)-\min_{i\in[N]}\sum_{\tau\in[t]}\ell_{\tau}\left(\widetilde{\bm{x}}_{ \tau}^{i}\right)\ \leq\ \frac{t\epsilon}{2}\cdot\left(\frac{d}{\rho}\left(\bar{F}+K\frac{\bar{F}}{ \beta}\bar{G}\right)\cdot(1-\alpha)D\right)^{2}+\frac{\log(N)}{\epsilon}\] \[\Longrightarrow \sum_{\tau\in[t]}\ell_{\tau}\left(\widetilde{\bm{x}}_{\tau} \right)-\sum_{\tau\in[t]}\ell_{\tau}\left(\widetilde{\bm{x}}_{\tau}^{i}\right) \ \leq\ \frac{t\epsilon}{2}\cdot\left(\frac{d}{\rho}\left(\bar{F}+K\frac{\bar{F}}{ \beta}\bar{G}\right)\cdot(1-\alpha)D\right)^{2}+\frac{\log(N)}{\epsilon},\ \ \forall i\in[N]\;,\]

which completes the proof. 

## Appendix B Supplementary lemmas

**Lemma B.1** (Hoeffding's lemma).: _Let \(X\) be some random variable such that \(a\leq X\leq b\) almost surely for some \(a,b\in\mathbb{R}\). Then for any \(\epsilon\in\mathbb{R}\), we have \(\mathbb{E}\left[\exp(-\epsilon X)\right]\leq\exp\left(-\epsilon\mathbb{E} \left[X\right]+\frac{\epsilon^{2}(b-a)^{2}}{8}\right)\)._

**Lemma B.2** ([25] Lemma 2.1).: _Let \(h:\mathcal{X}\rightarrow\mathbb{R}\) be some convex function (not necessarily differentiable). Then for any \(\bm{x}\in\mathcal{X}\subseteq\mathbb{R}^{d}\) and \(\delta>0\) we have_

\[\nabla_{\bm{x}}\mathbb{E}_{\bm{v}\sim U(\mathbb{B})}[h(\bm{x}+\delta\bm{v})]= \frac{d}{\delta}\cdot\mathbb{E}_{\bm{u}\sim U(\mathbb{S})}\left[h(\bm{x}+ \delta\bm{u})\cdot\bm{u}\right].\] (50)