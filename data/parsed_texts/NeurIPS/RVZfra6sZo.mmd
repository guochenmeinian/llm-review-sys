# DDN: Dual-domain Dynamic Normalization for Non-stationary Time Series Forecasting

 Tao Dai\({}^{1}\), Beiliang Wu\({}^{1,}\), Peiyuan Liu\({}^{2,}\), Naiqi Li\({}^{2,}\), Xue Yuerong\({}^{2}\), Shu-Tao Xia\({}^{2}\), Zexuan Zhu\({}^{1}\)

\({}^{1}\)College of Computer Science and Software Engineering, Shenzhen University, China

\({}^{2}\)Tsinghua Shenzhen International Graduate School, Tsinghua University, China

{daitao.edu, peiyuanliu.edu, linaqi.thu}@gmail.com; xiast@sz.tsinghua.edu.cn

Equal contributionCorrespondence to: Peiyuan Liu and Naiqi Li

###### Abstract

Deep neural networks (DNNs) have recently achieved remarkable advancements in time series forecasting (TSF) due to their powerful ability of sequence dependence modeling. To date, existing DNN-based TSF methods still suffer from unreliable predictions for real-world data due to its non-stationarity characteristics, _i.e.,_ data distribution varies quickly over time. To mitigate this issue, several normalization methods (e.g., SAN) have recently been specifically designed by normalization in a fixed period/window in the time domain. However, these methods still struggle to capture distribution variations, due to the complex time patterns of time series in the time domain. Based on the fact that wavelet transform can decompose time series into a linear combination of different frequencies, which exhibits distribution variations with time-varying periods, we propose a novel Dual-domain Dynamic Normalization (DDN) to dynamically capture distribution variations in both time and frequency domains. Specifically, our DDN tries to eliminate the non-stationarity of time series via both frequency and time domain normalization in a sliding window way. Besides, our DDN can serve as a plug-in-play module, and thus can be easily incorporated into other forecasting models. Extensive experiments on public benchmark datasets under different forecasting models demonstrate the superiority of our DDN over other normalization methods. Code is available at https://github.com/Hank0626/DDN.

## 1 Introduction

Deep neural networks (DNNs) with powerful dependency modeling capability have recently been widely used in time series forecasting (TSF) applications, including weather prediction [1], energy consumption estimation [2], and traffic flow forecasting [3]. Despite the great advancements of DNN-based TSF methods [4; 5; 6; 7], they still suffer from unreliable predictions for real-world data due to its non-stationary nature of real-world time series, _i.e.,_ data distribution within the series varies quickly over time (_a.k.a_, distribution drift [8; 9; 10]). Such non-stationary challenge limits the real applications of DNN-based TSF methods.

To mitigate the problem of distribution drift, the classic reversible normalization [11] has recently been proposed with a two-stage pipeline of normalization and de-normalization. The former stage of normalization eliminates non-stationary factors for converting a non-stationary sequence into a stationary sequence, which has to acquire the mean and standard deviation of the sequence before. The latter stage of de-normalization reconstructs non-stationary information from the distribution prediction model or directly reuses the mean and standard deviation acquired in normalization.

Later, several advanced variants of reversible normalization [12; 13; 14] have achieved impressive performance by further alleviating the non-stationary property of real-world time series.

Despite the great success of normalization methods, existing methods are limited in capturing distribution variations by performing normalization with a fixed period/window. As shown in Figure 1, either existing coarse-grained (e.g., RevIN [11]) or fine-grained normalization (e.g., SAN [14]) in single time domain tends to produce sub-optimal performance. On the other hand, it is known that wavelet transform can decompose time series into a time-dependent sum of frequency components, which exhibits distribution variations with time-varying periods (see Figure 1). Thus, making full use of such frequency information is helpful to capture distribution variations with time-varying periods and intensities. These observations motivate us to develop a more powerful normalization strategy to dynamically capture distribution variations.

In this paper, we propose a novel **Dual-domain Dynamic Normalization (DDN)** framework to dynamically capture distribution variations in both times and frequency domains in a sliding window way. Specifically, our DDN decomposes the original time series into different frequency components, including low-frequency and high-frequency components, based on Discrete Wavelet Transform (DWT) [15; 16]. Followed by performing sliding normalization in an individual frequency component with proper window size (see Figure 1), which is helpful to capture distribution variations with time-varying periods and intensities. Besides, time domain normalization is developed to compute local sliding statistics [17], including sliding mean and sliding standard deviation. Unlike the previous works that process a coarse-grained level, our DDN leverages fine-grained a more informative sliding window to calculate distribution characteristics for every time step.

Our main contributions can be summarized as: **(i)** We propose a novel Dual-domain Dynamic Normalization (DDN) to dynamically capture distribution variations in both time and frequency domains with sliding statistics. Compared with previous works, our DDN is capable of dynamically reflecting the rapid variations to time series. **(ii)** Our DDN aims to eliminate non-stationary factors with frequency domain normalization and time domain normalization. Benefiting from the complementary properties of the time and frequency domain information, it allows our DDN to further clarify non-stationary factors and reconstruct non-stationary information. **(iii)** Extensive experiments demonstrate the effectiveness of our DDN, by achieving significant performance improvements across various baseline models on seven real-world datasets.

## 2 Related Works

### Deep Models for Time Series Forecasting

Reviewing the development of time series forecasting based on deep models, early methods [18; 19; 20] often integrated cross-dimension information in embedding module, then modeling cross-time

Figure 1: (a) Existing methods with a fixed period/window normalization struggle to capture distribution variations. (b) Our method dynamically captures distribution variations in both time and frequency domains.

information. In contrast, recent Sota methods indicate that two modeling ways can be better: CI (Channel Independent) and CD (Channel Dependent). The primary distinction between the two approaches lies in the former focusing only on cross-time features but the latter incorporating cross-dimension features. Theoretically, the latter can leverage more information and achieve higher prediction accuracy [21; 22; 23]. In practice, for relatively short input series, CD methods [24; 25] achieve comparable or even better performance than the CI methods. However, for longer input sequences, the situation is often the opposite[26; 4; 27]. In recent research, this difference can be attributed to the CD having higher capacity but often lacking robustness in predicting distributional drift than CI [28; 29], while longer series typically experience more severe distributional drift. The superior performance of CI highlights the importance of handling distribution drift, and it is a valuable direction in the current research on time series forecasting.

### Stationary for Time Series Forecasting

RevIN [11] was the first work to apply reversible normalization for time series forecasting, which assumes that history and future sequences share the same distribution. It counts distribution statistics of historical sequence for both normalization and de-normalization. Due to its simplicity and impressive effectiveness, it has been widely used in recent works [30; 31]. However, RevIN overlooks the distributional differences between historical and future sequences. Building upon RevIN, DishTS [12] proposes different distribution characteristics for historical and future sequences, using a distribution forecasting model to predict mean and standard deviation. Concurrently, NST [13] employs a module to provide more consistent distribution with future distribution, which can refer to appendix B. Furthermore, SAN [14] notes that existing distribution assumptions may not adapt to the scenario that time series points rapidly change over time [32; 33] and proposes a more fine-grained method, which supposes the distribution characteristics of time points is different between slices but same within a slice. Nevertheless, SAN still stops at the slice level, rather than the time series point level. Meanwhile, existing works lack consideration of the discrepancies between low and high frequencies, leading to insufficient consideration of non-stationary information.

## 3 Methodology

In the realm of multivariate time series forecasting, we consider a historical sequence \(\bm{X}\in\mathbb{R}^{M\times L}\) and aim to predict the corresponding future sequence \(\bm{Y}\in\mathbb{R}^{M\times T}\), \(M\) is the number of channels. DDN is a model-agnostic plugin designed to align the distribution characteristics of \(\bm{X}\) and accurately estimate the distribution of \(\bm{Y}\). In this section, we will comprehensively outline the pipeline of the entire framework and elaborate on how to remove and reconstruct non-stationary factors of time series. To enhance clarity and facilitate understanding of subsequent chapters, the key notations used in this paper are summarized in Table 1, and the framework can be referred to in Figure 2.

### Overall Framework

As depicted in Figure 2, we first eliminate non-stationary factors via both the Frequency Domain Normalization (**FDN**) and the Time Domain Normalization (**TDN**). These processes output two stationary sequences and two sets of distribution characteristics. Two stationary sequences weighted to a sequence and input to the time series Forecasting Model (**FM**) for future sequence forecasting, while two sets of non-stationary factors input to Distribution Prediction Model (**DPM**) and predict future non-stationary factors. Finally, these factors are weighted together and incorporated with forecasting

\begin{table}
\begin{tabular}{c c} \hline \hline Notation & Description \\ \hline \(L,T\) & The time steps of the historical/future sequences \\ \(\bm{x}^{i},\bm{y}^{i}\) & The \(i\)-th historical or future series \\ \(\bm{\bar{x}}^{i}_{*},\bm{\bar{y}}^{i}_{*}\) & The \(\bm{x}^{i}\) after normalization and it predicted series \\ \(\bm{\mu}^{i},\bm{\sigma}^{i}\) & The \(i\)-th mean or standard deviation series of \(\bm{x}^{i}\) \\ \(\bm{\mu}^{i}_{y},\bm{\sigma}^{i}_{y}\) & The \(i\)-th mean or standard deviation series of \(\bm{y}^{i}\) \\ \(\bm{\mu}^{i}_{*},\bm{\sigma}^{i}_{*}\) & The distribution forecasting of \(\bm{\mu}^{i}\) or \(\bm{\sigma}^{i}\) \\ \hline \hline \end{tabular}
\end{table}
Table 1: Summary of key mathematical notationsoutput to reconstruct non-stationary factors by de-normalization. Here, \(\theta_{d}\) and \(\theta_{f}\) correspond to the parameters of DPM and FM, and the training strategy can be seen in the section 3.4.

### Non-stationarity Elimination

For each series \(\bm{x}^{i}\), we perform a sliding window along the temporal dimension to acquire distribution characteristics, then replicate padding that will align the length of sliding statistics to the original series. Finally, sliding mean \(\bm{\mu}^{i}\) and sliding standard deviation \(\bm{\sigma}^{i}\) represent to the distribution characteristics of \(\bm{x}^{i}\). This process can be described as follows:

\[\begin{split}\mu^{i}_{j}&=\frac{1}{2k+1}\sum_{-k}^{ k}x^{i}_{j+t},\quad\left(\sigma^{i}_{j}\right)^{2}=\frac{1}{2k+1}\sum_{-k}^{k} \left(x^{i}_{j+t}-\mu^{i}_{j}\right)^{2},\\ \bm{\mu}^{i}&=\mathrm{Pad}(\{\mu^{i}_{k+1},\cdots, \mu^{i}_{L-k}\}),\quad\bm{\sigma}^{i}=\mathrm{Pad}(\{\sigma^{i}_{k+1},\cdots, \sigma^{i}_{L-k}\}).\end{split}\] (1)

Here \(2k+1\) is the size of the sliding window, and stride is \(1\). After that, the size of sliding statistics is \(L-2k\). Where \({\mu_{j}}^{i}\) and \({\sigma_{j}}^{i}\) represent the mean value and standard deviation value of the \(j^{th}\) time point respectively, where \(j\in\{k+1,\cdots,L-k\}\). To make sure each time point possesses corresponding sliding statistics. We copy the sliding statistics closest in time by \(\mathrm{Pad}\left(\cdot\right)\) operation, the obtaining \(\bm{\mu}_{i}\) and \(\bm{\sigma}_{i}\) are used to achieve the transformation from non-stationary sequences to stationary sequences. The process is as follows:

\[\bar{\bm{x}}^{i}=\frac{1}{\bm{\sigma}^{i}+\epsilon}\odot\left(\bm{x}^{i}-\bm{ \mu}^{i}\right),\quad\epsilon>0.\] (2)

Here, \(\bar{\bm{x}}^{i}\) is the stationary series, \(\epsilon\) is a positive number to prevent the denominator from zero, and \(\odot\) denotes the element-wise product. By this sliding normalization, annotated as \(\mathrm{SlidingNorm}\left(\cdot\right)\), we can acquire the non-stationary factors of each time point and convert non-stationary sequences to stationary sequences.

Frequency Domain Normalization.In this branch, to exhaustively unveil non-stationary factors and eliminate them accurately. Discrete Wavelet Transform (DWT) is conducted on \(\bm{x}_{i}\) to separate the low-frequency component \(\bm{x}^{i}_{l}\) and high-frequency component \(\bm{x}^{i}_{h}\). Subsequently, we acquire and eliminate their non-stationary factors. The process is as follows:

\[\begin{split}\bm{x}^{i}_{l},\bm{x}^{i}_{h}=\mathrm{DWT}_{\phi_{l,h}}(\bm{x}^{i}),\\ \bar{\bm{x}}^{i}_{l},\bm{\mu}^{i}_{l},\bm{\sigma}^{i}_{l}=\mathrm{ SlidingNorm}(\bm{x}^{i}_{l}),&\bar{\bm{x}}^{i}_{h},\bm{\mu}^{i}_{h}, \bm{\sigma}^{i}_{h}=\mathrm{SlidingNorm}(\bm{x}^{i}_{h}),\end{split}\] (3)

Here, \(\phi_{l,h}\) is a pair of learnable wavelet bases. \(\bar{\bm{x}}^{i}_{l}\), \(\bm{\mu}^{i}_{l}\), and \(\bm{\sigma}^{i}_{l}\) represent the stationary sequence, sliding mean, and sliding standard deviation of the low-frequency component. While \(\bar{\bm{x}}^{i}_{h}\), \(\bm{\mu}^{i}_{h}\), and \(\bm{\sigma}^{i}_{h}\)

Figure 2: The comprehensive time series forecasting framework comprises a time series forecasting model and an auxiliary module designed for handling non-stationary factors. This auxiliary module consists of two sub-modules: one for eliminating non-stationary factors and another for reconstructing them. The non-stationary factor elimination sub-module includes Time Domain Normalization and Frequency Domain Normalization, while the non-stationary factor reconstruction sub-module incorporates a distribution prediction module.

denote those of the high-frequency component. In practice, different types of DWT have different padding lengths and lead to different output lengths. To ensure a consistent and clear output length, Inverse Discrete Wavelet Transform (IDWT) performs to restore a definite size. The process is as follows:

\[\bm{\hat{x}}^{i}=\mathrm{IDWT}_{\phi_{l,h}}(\bm{\bar{x}}^{i}_{l},\bm{\bar{x}}^{i }_{h}),\quad\bm{\hat{\mu}}^{i}=\mathrm{IDWT}_{\phi_{l,h}}(\bm{\mu}^{i}_{l},\bm{ \mu}^{i}_{h}),\ \bm{\hat{\sigma}}^{i}=\mathrm{IDWT}_{\phi_{l,h}}(\bm{\sigma}^{i}_{l},\bm{ \sigma}^{i}_{h}).\] (4)

Where \(\bm{\hat{x}}^{i}\), \(\bm{\hat{\mu}}^{i}\), and \(\bm{\hat{\sigma}}^{i}\) encompass the stationary sequences, sliding means, and sliding standard deviations of different frequency components. Through these operations, the output stationary sequence and distribution statistics maintain consistency with the dimensions of the input non-stationary sequence.

Time Domain Normalization.We conduct the same manners in the time domain without frequency decomposition. The process can be formulated as follows:

\[\bm{\bar{x}}^{i},\bm{\mu}^{i},\bm{\sigma}^{i}=\mathrm{SlidingNorm}(\bm{x}^{i }),\] (5)

The wavelet transform in FDN typically involves padding, which can potentially distort the statistical distribution information of the decomposed sequences. To address this, we implement sliding normalization directly on the original sequence. Consequently, the resulting distribution information is utilized for predicting future distributions, while the output stationary sequence is weighted with the stationary sequence derived from FDN.

Stationary Sequences Weighting.Two stationary sequences from FDN and TDN will be weighted to a stationary output, which can be expressed as follows:

\[\bm{\bar{x}}^{i}=\bm{\bar{x}}^{i}\cdot\beta+\bm{\hat{x}}^{i}\cdot\alpha.\] (6)

Here, \(\alpha\) is a trainable parameter and \(\beta=1-\alpha\). The weighted \(\bm{\bar{x}}^{i}\) serves as the final stationary sequence, which is then inputted into FM for stable forecasting.

### Non-stationarity Reconstruction

We acquire two sets of sliding statistics reflecting distribution variations after FDN and TDN. Later, we refer to the structure of existing distribution prediction works [34; 12] to predict future distribution. Initially, we calculate the mean value of each sliding statistic to compute the statistical differences. Subsequently, the difference and original series are inputted for future difference prediction. Ultimately, these predicted differences added to the mean value as future sliding statistics.

Frequency Domain Prediction.As shown in Figure 3, for the distribution statistics of FDN, we predict future statistics by distribution prediction model and formulate as:

\[\bm{\hat{\sigma}}^{i}_{\Delta}=\mathrm{SP}\left(\bm{\hat{\sigma}}^ {i}-\sigma^{i}_{f},\bm{x}^{i}\right),\quad\bm{\hat{\sigma}}^{i}_{*}=\bm{\hat {\sigma}}^{i}_{\Delta}+\sigma^{i}_{f},\] (7) \[\bm{\hat{\mu}}^{i}_{\Delta}=\mathrm{MP}\left(\bm{\hat{\mu}}^{i}- \mu^{i}_{f},\bm{x}^{i}-\mu^{i}_{f}\right),\quad\bm{\hat{\mu}}^{i}_{*}=\bm{ \hat{\mu}}^{i}_{\Delta}+\mu^{i}_{f}.\]

Here, \(\mu^{i}_{f}\) and \(\sigma^{i}_{f}\) are the mean values of \(\bm{\hat{\mu}}^{i}\) and \(\bm{\hat{\sigma}}^{i}\). While \(\bm{\hat{\mu}}^{i}_{*}\) and \(\bm{\hat{\sigma}}^{i}_{*}\) denote the prediction of \(\bm{\hat{\mu}}^{i}\) and \(\bm{\hat{\sigma}}^{i}\). The \(\mathrm{MP}\) is a mean prediction branch, and the \(\mathrm{SP}\) is a standard deviation prediction branch. They are affiliated with DPM and adopt the same network structure.

Time Domain PredictionAs the above frequency domain prediction process, for the distribution statistics of TDN, this prediction process can be formulated as follows:

\[\bm{\sigma}^{i}_{\Delta}=\mathrm{SP}\left(\bm{\sigma}^{i}-\sigma^ {i}_{o},\bm{x}^{i}\right),\quad\bm{\sigma}^{i}_{*}=\bm{\sigma}^{i}_{\Delta}+ \sigma^{i}_{o},\] (8) \[\bm{\mu}^{i}_{\Delta}=\mathrm{MP}\left(\bm{\mu}^{i}-\mu^{i}_{o}, \bm{x}^{i}-\mu^{i}_{o}\right),\quad\bm{\mu}^{i}_{*}=\bm{\mu}^{i}_{\Delta}+ \mu^{i}_{o}.\]

Here, \(\mu^{i}_{o}\) and \(\sigma^{i}_{o}\) are the mean values of \(\bm{\mu}^{i}\) and \(\bm{\sigma}^{i}\), respectively. Likewise, \(\bm{\mu}^{i}_{*}\) and \(\bm{\sigma}^{i}_{*}\) denote the prediction of \(\bm{\mu}^{i}\) and \(\bm{\sigma}^{i}\). The \(\mathrm{SP}\) and the \(\mathrm{MP}\) are noted in frequency domain prediction.

De-normalization.After the aforementioned distribution predictions, two sets of estimated distribution statistics will be gained. Which are weighted to reconstruct the non-stationary information of the output of the time series forecasting model. This process can be described as follows:

\[\begin{split}\boldsymbol{\mu}_{*}^{i}=\boldsymbol{\mu}_{*}^{i} \cdot\beta+\hat{\boldsymbol{\mu}}_{*}^{i}\cdot\alpha,\quad\boldsymbol{\sigma} _{*}^{i}=\boldsymbol{\sigma}_{*}^{i}\cdot\beta+\hat{\boldsymbol{\sigma}}_{*}^{i }\cdot\alpha,\quad\bar{\boldsymbol{x}}^{i}=\bar{\boldsymbol{x}}^{i}\cdot\beta +\hat{\boldsymbol{x}}^{i}\cdot\alpha.\\ \boldsymbol{y}_{*}^{i}=\bar{\boldsymbol{y}}_{*}^{i}\odot\left( \boldsymbol{\sigma}_{*}^{i}+\epsilon\right)+\boldsymbol{\mu}_{*}^{i}.\end{split}\] (9)

Where \(\bar{\boldsymbol{y}}_{*}^{i}\) is the output of the time series forecasting model, and \(\boldsymbol{y}_{*}^{i}\) represents the predicted sequence after reconstructing non-stationary information. While \(\alpha\), \(\beta\), and \(\epsilon\) mentioned before.

### Collaborative Training

Distribution prediction and future series forecasting are essentially a bi-level optimization problem [35; 36; 37], where distribution outputs significantly impact the future series output. To enhance the training effects of our models, we pre-train the DPM to yield a relatively well-trained DPM. This procedure can be formulated as follows:

\[\theta_{d}=\arg\min_{\text{MSE}}\left(\left(\boldsymbol{\mu}_{*}^{i}, \boldsymbol{\sigma}_{*}^{i}\right),\left(\boldsymbol{\mu}_{y}^{i},\boldsymbol {\sigma}_{y}^{i}\right),\theta_{d}\right).\] (10)

Where \(\theta_{d}\) represents the parameters of the DPM, it is noteworthy that the wavelet bases \(\phi_{l,h}\) and the weighted factor \(\alpha\) belong to \(\theta_{d}\). We select the mean square error (MSE) as our loss function between the predicted distribution and the ground truth of the distribution, acquired from the future sequence through TDN. Subsequently, assuming a total training duration of \(T\) epochs, the parameters \(\theta_{d}\) of the DPM will be frozen, then we train FM for \(T_{1}\) epochs. Finally, DPM and FM will be subject to collaborative training during the remaining \(T-T_{1}\) epochs. The process is as follows:

\[\begin{split}\theta_{f}&=\arg\min_{\text{MSE}} \left(\boldsymbol{y}_{*}^{i},\boldsymbol{y}_{y}^{i},\theta_{f}\right),\quad \text{if }t\leq T_{1},\\ \left\{\theta_{d},\theta_{f}\right\}&=\arg\min_{ \text{MSE}}\left(\boldsymbol{y}_{*}^{i},\boldsymbol{y}_{y}^{i},\left\{\theta_ {d},\theta_{f}\right\}\right),\quad\text{otherwise}.\end{split}\] (11)

Where \(t\) denotes the \(t^{th}\) epoch during the training process, and \(\phi_{f}\) represents the parameters of the FM. We train DPM and FM concurrently to mitigate potential errors in the pretraining stage, as the ground truth of distribution is drived from future sequences based on distribution assumption. This ground truth is somewhat inconsistent with the actual situation and fails to account for high-frequency distribution changes. Consequently, we pretrain the DPM using assumption-based distribution ground truth, and then collaborative train it jointly based on the loss derived from the future sequences.

## 4 Experiments

In this section, we conduct comprehensive experiments on multiple real-world time series datasets to assess the effectiveness of our proposed reversible normalization method DDN.

Figure 3: The architecture of the distribution prediction model primarily consists of two predictive branches: the Mean Prediction branch and the Standard Deviation (Std) Prediction branch. The specific network structure of these branches is illustrated in the Prediction Branch.

DatasetsWe conduct extensive experiments on these seven popular real-world datasets [18], including **Electricity Transformer Temperature (ETT)** with its four subsets (ETTh1, ETH2, ETTm1, ETTm2), **Weather**, **Electricity**, and **Traffic**. The setting of these datasets following original works [18, 20], and more descriptions about these datasets present in appendix A.1.

Baselines.DDN is a model-agnostic method that can be applied to any mainstream time series forecasting model. To demonstrate its versatility, we integrate DDN into several representative models, including the earlier proposed models **FEDformer**[19] and **Autoformer**[20], the CI model **DLinear**[27], and the CD model **iTransformer**[24].

Implementation details.Our experiments were conducted three times with a consistent random seed and averaged to mean values. The Mean Square Error (MSE) and Mean Absolute Error (MAE) are chosen as evaluation metrics, with MSE serving as the training loss. All models use the same prediction lengths \(T=\{96,192,336,720\}\). For the look-back window \(L\), Autoformer [20] and FEDformer [19] use \(L=96\), while DLinear [27] and iTransformer [24] utilize \(L=336\) and \(L=720\) respectively. The wavelet bases initialize to the "coiflet" bases, the default size of our sliding window is set to 7 for information content and temporal locality balance, and \(\alpha\) starts at zero. More implementation details of our experiments can be referred to appendix A.2.

### Main Results

As illustrated, the DDN method significantly enhances the predictive performance of the four different baselines across nearly all datasets. For the MSE metric, this improvement is particularly evident in the three relatively large datasets: Weather, Electricity, and Traffic. Utilizing DDN, Autoformer achieves a relative error reduction of 19.2%, 24.7%, and 25.6%, respectively, while FEDformer achieves a relative error reduction of 13.1%, 16.2%, and 22.3%. Similarly, incorporating the DDN into the other models also results in substantial performance gains. Additionally, Autoformer, FEDformer, and DLinear do not employ reversible normalization in official implements. While iTransformer utilizes the RevIN [11] normalization technique based on static statistics. However, replacing the RevIN module in iTransformer with the DDN module still yields significant performance improvements. These results strongly demonstrate that DDN makes the baseline model more robust in forecasting.

\begin{table}
\begin{tabular}{c c c c c c c c c c c c c c c c c c} \hline \hline \multirow{2}{*}{Methods} & \multirow{2}{*}{Autoformer} & \multirow{2}{*}{+DDN} & \multicolumn{2}{c}{FEDformer} & \multicolumn{2}{c}{+DDN} & \multicolumn{2}{c}{DLinear} & \multicolumn{2}{c}{+DDN} & iTransformer & \multicolumn{2}{c}{+DDN} \\ \cline{3-14}  & & & & MSE & MAE & MSE & MAE & MSE & MAE & MSE & MAE & MSE & MAE & MSE & MAE & MSE & MAE & MSE & MAE \\ \hline \multirow{8}{*}{**FEDformer**} & 96 & 0.458 & 0.448 & **0.427** & **0.424** & **0.371** & 0.411 & 0.385 & **0.408** & 0.377 & 0.399 & **0.372** & **0.396** & 0.392 & 0.422 & **0.377** & **0.405** \\  & 192 & 0.481 & 0.474 & **0.472** & **0.452** & **0.420** & 0.443 & **0.415** & **0.425** & 0.417 & 0.426 & **0.406** & **0.416** & 0.428 & 0.448 & **0.441** & **0.430** \\  & 336 & 0.508 & 0.485 & **0.498** & **0.466** & **0.446** & 0.459 & 0.458 & **0.452** & 0.464 & 0.461 & **0.432** & **0.434** & 0.467 & 0.475 & **0.453** & **0.456** \\  & 720 & 0.525 & 0.516 & **0.502** & **0.483** & **0.482** & 0.495 & 0.490 & **0.479** & 0.493 & 0.505 & **0.462** & **0.474** & 0.568 & 0.547 & **0.553** & **0.530** \\ \hline \multirow{8}{*}{**FEDformer**} & 96 & 0.493 & 0.470 & **0.354** & **0.390** & 0.362 & 0.408 & **0.313** & **0.364** & 0.301 & 0.344 & **0.288** & **0.342** & 0.322 & 0.371 & **0.301** & **0.355** \\  & 192 & 0.546 & 0.498 & **0.397** & **0.408** & 0.395 & 0.427 & **0.361** & **0.396** & 0.335 & 0.356 & **0.324** & **0.364** & 0.353 & 0.392 & **0.339** & **0.378** \\  & 336 & 0.658 & 0.543 & **0.429** & **0.433** & 0.441 & **0.454** & **0.417** & **0.430** & 0.370 & 0.387 & **0.356** & **0.385** & 0.410 & **0.370** & **0.396** \\  & 270 & 0.626 & 0.532 & **0.488** & **0.464** & 0.488 & 0.481 & **0.470** & **0.472** & 0.425 & 0.421 & **0.415** & **0.419** & 0.441 & **0.432** & **0.426** & **0.426** \\ \hline \multirow{8}{*}{**FEDformer**} & 96 & 0.247 & 0.320 & **0.190** & **0.243** & 0.246 & 0.328 & **0.174** & **0.237** & 0.175 & 0.237 & **0.146** & **0.201** & 0.177 & 0.228 & **0.148** & **0.210** \\  & 192 & 0.302 & 0.366 & **0.231** & **0.282** & 0.281 & 0.341 & **0.233** & **0.294** & 0.217 & 0.275 & **0.190** & **0.247** & 0.223 & 0.266 & **0.191** & **0.252** \\  & 336 & 0.362 & 0.394 & **0.289** & **0.327** & 0.337 & 0.376 & **0.307** & **0.349** & 0.263 & 0.314 & **0.239** & **0.288** & 0.287 & 0.310 & **0.237** & **0.290** \\  & 720 & 0.427 & 0.433 & **0.369** & **0.375** & 0.414 & 0.426 & **0.399** & **0.405** & 0.325 & 0.366 & **0.311** & **0.343** & 0.364 & 0.365 & **0.301** & **0.336** \\ \hline \multirow{8}{*}{**FEDformer**} & 96 & 0.195 & 0.309 & **0.150** & **0.254** & 0.185 & 0.300 & **0.146** & **0.251** & 0.140 & 0.237 & **0.131** & **0.228** & 0.133 & 0.229 & **0.127** & **0.225** \\  & 192 & 0.215 & 0.325 & **0.173** & **0.275** & 0.196 & 0.31

[MISSING_PAGE_FAIL:8]

[MISSING_PAGE_FAIL:9]

Conclusion

In this work, we propose Dual-domain Dynamic Normalization (DDN), a novel method that dynamically captures non-stationary factors in time series forecasting, addressing sudden changes and distribution drifts in both time and frequency domains. Specifically, DDN employs sliding normalization in the time domain to eliminate and reconstruct non-stationary factors at a fine-grained level. In the frequency domain, it decomposes time series into high and low frequencies, effectively capturing rapid variations and sudden changes. As a model-agnostic auxiliary module, DDN significantly enhances the predictive performance of various forecasting models. Extensive experiments on seven real-world datasets validate the superiority of DDN, demonstrating its effectiveness in addressing distribution drift and improving the reliability of time series predictions.

## 6 Acknowledgments

This work is supported in part by the National Natural Science Foundation of China, under Grant (62302309, 62171248), Shenzhen Science and Technology Program (JCYJ20220818101014030, JCYJ20220818101012025), and the PCNL KEY project (PCL2023AS6-1).

## References

* [1] Zahra Karevan and Johan AK Suykens. Transductive lstm for time-series prediction: An application to weather forecasting. _Neural Networks_, 125:1-9, 2020.
* [2] Chirag Deb, Fan Zhang, Junjing Yang, Siew Eang Lee, and Kwok Wei Shah. A review on time series forecasting techniques for building energy consumption. _Renewable and Sustainable Energy Reviews_, 74:902-924, 2017.
* [3] Marco Lippi, Matteo Bertini, and Paolo Frasconi. Short-term traffic flow forecasting: An experimental comparison of time-series analysis and supervised learning. _IEEE Transactions on Intelligent Transportation Systems_, 14(2):871-882, 2013.
* [4] Tao Dai, Beiliang Wu, Peiyuan Liu, Naiqi Li, Jigang Bao, Yong Jiang, and Shu-Tao Xia. Periodicity decoupling framework for long-term series forecasting. In _The Twelfth International Conference on Learning Representations_, 2024.
* [5] Nikita Kitaev, Lukasz Kaiser, and Anselm Levskaya. Reformer: The efficient transformer. _arXiv preprint arXiv:2001.04451_, 2020.
* [6] Shiyang Li, Xiaoyong Jin, Yao Xuan, Xiyou Zhou, Wenhu Chen, Yu-Xiang Wang, and Xifeng Yan. Enhancing the locality and breaking the memory bottleneck of transformer on time series forecasting. _Advances in neural information processing systems_, 32, 2019.
* [7] Ruofeng Wen, Kari Torkkola, Balakrishnan Narayanaswamy, and Dhruv Madeka. A multi-horizon quantile recurrent forecaster. _arXiv preprint arXiv:1711.11053_, 2017.
* [8] Tonya Fields, George Hsieh, and Jules Chenou. Mitigating drift in time series data with noise augmentation. In _2019 International Conference on Computational Science and Computational Intelligence (CSCI)_, pages 227-230. IEEE, 2019.
* [9] Jie Lu, Anjin Liu, Fan Dong, Feng Gu, Joao Gama, and Guangquan Zhang. Learning under concept drift: A review. _IEEE transactions on knowledge and data engineering_, 31(12):2346-2363, 2018.
* [10] Wendi Li, Xiao Yang, Weiqing Liu, Yingce Xia, and Jiang Bian. Ddg-da: Data distribution generation for predictable concept drift adaptation. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 36, pages 4092-4100, 2022.
* [11] Taesung Kim, Jinhee Kim, Yunwon Tae, Cheonbok Park, Jang-Ho Choi, and Jaegul Choo. Reversible instance normalization for accurate time-series forecasting against distribution shift. In _International Conference on Learning Representations_, 2021.

* [12] Wei Fan, Pengyang Wang, Dongkun Wang, Dongjie Wang, Yuanchun Zhou, and Yanjie Fu. Dish-ts: a general paradigm for alleviating distribution shift in time series forecasting. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 37, pages 7522-7529, 2023.
* [13] Yong Liu, Haixu Wu, Jianmin Wang, and Mingsheng Long. Non-stationary transformers: Exploring the stationarity in time series forecasting. _Advances in Neural Information Processing Systems_, 35:9881-9893, 2022.
* [14] Zhiding Liu, Mingyue Cheng, Zhi Li, Zhenya Huang, Qi Liu, Yanhu Xie, and Enhong Chen. Adaptive normalization for non-stationary time series forecasting: A temporal slice perspective. _Advances in Neural Information Processing Systems_, 36, 2024.
* [15] Pimwadee Chaovalit, Aryya Gangopadhyay, George Karabatis, and Zhiyuan Chen. Discrete wavelet transform-based time series analysis and mining. _ACM Computing Surveys (CSUR)_, 43(2):1-37, 2011.
* [16] Shyh-Jier Huang and Cheng-Tao Hsieh. Coiflet wavelet transform applied to inspect power system disturbance-generated signals. _IEEE Transactions on Aerospace and Electronic Systems_, 38(1):204-210, 2002.
* [17] Eric Zivot, Jiahui Wang, Eric Zivot, and Jiahui Wang. Rolling analysis of time series. _Modeling financial time series with S-Plus(r)_, pages 299-346, 2003.
* [18] Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, and Wancai Zhang. Informer: Beyond efficient transformer for long sequence time-series forecasting. In _Proceedings of the AAAI conference on artificial intelligence_, volume 35, pages 11106-11115, 2021.
* [19] Tian Zhou, Ziqing Ma, Qingsong Wen, Xue Wang, Liang Sun, and Rong Jin. Fedformer: Frequency enhanced decomposed transformer for long-term series forecasting. In _International conference on machine learning_, pages 27268-27286. PMLR, 2022.
* [20] Haixu Wu, Jiehui Xu, Jianmin Wang, and Mingsheng Long. Autoformer: Decomposition transformers with auto-correlation for long-term series forecasting. _Advances in neural information processing systems_, 34:22419-22430, 2021.
* [21] Yi Zheng, Qi Liu, Enhong Chen, Yong Ge, and J Leon Zhao. Exploiting multi-channels deep convolutional neural networks for multivariate time series classification. _Frontiers of Computer Science_, 10:96-112, 2016.
* [22] Andreia Dionisio, Rui Menezes, and Diana A Mendes. Mutual information: a measure of dependency for nonlinear time series. _Physica A: Statistical Mechanics and its Applications_, 344(1-2):326-329, 2004.
* [23] Stefan Frenzel and Bernd Pompe. Partial mutual information for coupling analysis of multivariate time series. _Physical review letters_, 99(20):204101, 2007.
* [24] Yong Liu, Tengge Hu, Haoran Zhang, Haixu Wu, Shiyu Wang, Lintao Ma, and Mingsheng Long. itransformer: Inverted transformers are effective for time series forecasting. In _The Twelfth International Conference on Learning Representations_, 2023.
* [25] Yunhao Zhang and Junchi Yan. Crossformer: Transformer utilizing cross-dimension dependency for multivariate time series forecasting. In _The eleventh international conference on learning representations_, 2022.
* [26] Yuqi Nie, Nam H Nguyen, Phanwadee Sinthong, and Jayant Kalagnanam. A time series is worth 64 words: Long-term forecasting with transformers. In _The Eleventh International Conference on Learning Representations_, 2022.
* [27] Ailing Zeng, Muxi Chen, Lei Zhang, and Qiang Xu. Are transformers effective for time series forecasting? In _Proceedings of the AAAI conference on artificial intelligence_, volume 37, pages 11121-11128, 2023.

* [28] Qingsong Wen, Weiqi Chen, Liang Sun, Zhang Zhang, Liang Wang, Rong Jin, Tieniu Tan, et al. Onenet: Enhancing time series forecasting models under concept drift by online ensembling. _Advances in Neural Information Processing Systems_, 36, 2024.
* [29] Lu Han, Han-Jia Ye, and De-Chuan Zhan. The capacity and robustness trade-off: Revisiting the channel independent strategy for multivariate time series forecasting. _arXiv preprint arXiv:2304.05206_, 2023.
* [30] Luo donghao and wang xue. ModernTCN: A modern pure convolution structure for general time series analysis. In _The Twelfth International Conference on Learning Representations_, 2024.
* [31] Xue Wang, Tian Zhou, Qingsong Wen, Jinyang Gao, Bolin Ding, and Rong Jin. Card: Channel aligned robust blend transformer for time series forecasting. In _The Twelfth International Conference on Learning Representations_, 2023.
* [32] Shohreh Deldari, Daniel V Smith, Hao Xue, and Flora D Salim. Time series change point detection with self-supervised contrastive predictive coding. In _Proceedings of the Web Conference 2021_, pages 3124-3135, 2021.
* [33] Kwei-Herng Lai, Daochen Zha, Junjie Xu, Yue Zhao, Guanchu Wang, and Xia Hu. Revisiting time series outlier detection: Definitions and benchmarks. In _Thirty-fifth conference on neural information processing systems datasets and benchmarks track (round 1)_, 2021.
* [34] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In _Proceedings of the IEEE conference on computer vision and pattern recognition_, pages 770-778, 2016.
* [35] Risheng Liu, Jiaxin Gao, Jin Zhang, Deyu Meng, and Zhouchen Lin. Investigating bi-level optimization for learning and vision from a unified perspective: A survey and beyond. _IEEE Transactions on Pattern Analysis and Machine Intelligence_, 44(12):10045-10067, 2021.
* [36] El-Ghazali Talbi. A taxonomy of metaheuristics for bi-level optimization. In _Metaheuristics for bi-level optimization_, pages 1-39. Springer, 2013.
* [37] Stephen Gould, Basura Fernando, Anoop Cherian, Peter Anderson, Rodrigo Santa Cruz, and Edison Guo. On differentiating parameterized argmin and argmax problems with application to bi-level optimization. _arXiv preprint arXiv:1607.05447_, 2016.
* [38] Graham Elliott, Thomas J Rothenberg, and James H Stock. Efficient tests for an autoregressive unit root, 1992.
* [39] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. _arXiv preprint arXiv:1412.6980_, 2014.

### NeurIPS Paper Checklist

The checklist is designed to encourage best practices for responsible machine learning research, addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove the checklist: **The papers not including the checklist will be desk rejected.** The checklist should follow the references and precede the (optional) supplemental material. The checklist does NOT count towards the page limit.

Please read the checklist guidelines carefully for information on how to answer these questions. For each question in the checklist:

* You should answer [Yes], [No], or [NA].
* [NA] means either that the question is Not Applicable for that particular paper or the relevant information is Not Available.
* Please provide a short (1-2 sentence) justification right after your answer (even for NA).

**The checklist answers are an integral part of your paper submission.** They are visible to the reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it (after eventual revisions) with the final version of your paper, and its final version will be published with the paper.

The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation. While "[Yes] " is generally preferable to "[No] ", it is perfectly acceptable to answer "[No] " provided a proper justification is given (e.g., "error bars are not reported because it would be too computationally expensive" or "we were unable to find the license for the dataset we used"). In general, answering "[No] " or "[NA] " is not grounds for rejection. While the questions are phrased in a binary way, we acknowledge that the true answer is often more nuanced, so please just use your best judgment and write a justification to elaborate. All supporting evidence can appear either in the main paper or the supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification please point to the section(s) where related material for the question can be found.

IMPORTANT, please:

* **Delete this instruction block, but keep the section heading "NeurIPS paper checklist"**,
* **Keep the checklist subsection headings, questions/answers and guidelines below.**
* **Do not modify the questions and only use the provided macros for your answers**.

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: We have clearly outlined the main contributions of this paper in the abstract and introduction sections. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes]Justification: We have mentioned it in both the methods and experimental analysis sections. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: We have clearly outlined the assumption and proof of this paper in the Introduction, Method, and Appendix sections. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: We have clearly outlined the experiment details in the Experiments and Appendix sections. Guidelines:* The answer NA means that the paper does not include experiments.
* If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.
* If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.
* Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.
* While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: We provide the code link in the abstract. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). ** Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: We have clearly outlined the experiment details in the Experiments and Appendix sections. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: We have conducted relevant analysis in both the experimental and appendix sections and the experimental results were obtained by averaging three times. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors). * It should be clear whether the error bar is the standard deviation or the standard error of the mean. * It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified. * For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). * If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: We have clearly outlined the GPU version, programming languages and main libraries in the Appendix sections. Guidelines: * The answer NA means that the paper does not include experiments.

* The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.
* The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.
* The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: Our research conducted in the paper conform the ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: There is no societal impact of the work performed. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. * If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: The paper poses no such risks.

Guidelines:

* The answer NA means that the paper poses no such risks.
* Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.
* Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.
* We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.

12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: We have clearly outlined the links of these assets in the Appendix sections. Guidelines:

* The answer NA means that the paper does not use existing assets.
* The authors should cite the original paper that produced the code package or dataset.
* The authors should state which version of the asset is used and, if possible, include a URL.
* The name of the license (e.g., CC-BY 4.0) should be included for each asset.
* For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.
* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.

13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: This paper does not release new assets. Guidelines:

* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.

14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)?Answer: [NA] Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: This paper paper does not involve crowdsourcing nor research with human subjects. Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.

Experiments Setting

### Dataset Details

Our comprehensive experiments are conducted on seven time series datasets. Consistent with the methodologies of [18; 20; 24], we partition all datasets chronologically into training, validation, and testing subsets. Specifically, for the ETT dataset, we adopted a 6:2:2 split ratio, while a 7:1:2 ratio was utilized for the other datasets. Detailed descriptions of these datasets are as follows:

1. **ETT-small3** (Electricity Transformer Temperature) dataset: Comprises data from electricity transformers in two regions of China, collected between July 2016 and July 2018. It offers two different granularities: ETTh (1 hour) and ETTm (15 minutes). Each data point includes the value of oil temperature and six external power load features. Footnote 3: https://github.com/zhouhaoyi/ETDataset
2. **Weather4** dataset: Comprises 21 distinct meteorological measurements in Germany, recorded every 10 minutes throughout 2020. It features key indicators such as air temperature and visibility, providing an in-depth view of weather patterns. Footnote 4: https://www.bgc-jena.mpg.de/wetter/
3. **Electricity5** dataset: Contains hourly electricity consumption data in kilowatt-hours (kWh) for 321 clients from 2012 to 2014, sourced from the UCI Machine Learning Repository. Footnote 5: https://archive.ics.uci.edu/ml/datasets/ElectricityLoadDiagrams20112014
4. **Traffic6** dataset: Features hourly data on road occupancy rates from 862 detectors in the San Francisco Bay area freeways, covering 2015 to 2016. Footnote 6: https://pems.dot.ca.gov/

We provide access to all datasets through https://github.com/thuml/iTransformer. Detailed statistics for these datasets, including time steps, channels, and ADF test [38] results (evaluate the stationarity of a time series; a smaller value indicates greater non-stationarity.), are presented in Table A.1.

### Setting Details

All experiments were conducted using PyTorch on a single NVIDIA 3090 24GB GPU. We utilize the ADAM optimizer [39] with an initial learning rate of \(1e^{-4}\) for the distribution prediction model and employing Mean Squared Error (MSE) loss. The batch size, training epochs, and other baseline settings remain consistent with iTransformer [24]. The network for mean or standard deviation prediction comprises two feedforward Neural Network (FFN) layers, with dimensions of 512 for the first layer and 1024 for the second layer. We initialize the wavelet as Coiflet3, with \(\alpha\) starting from 0. We conduct pre-training for 5 epochs and commence collaborative training from either the first or second epoch based on specific settings and datasets, aiming for improved training and model fitting.

\begin{table}
\begin{tabular}{c|c c c c} \hline \hline Datasets & Timesteps & Variates & Granularity & ADF \\ \hline Electricity & 26304 & 321 & 1 hour & -8.44 \\ Weather & 52696 & 21 & 10 min & -26.68 \\ Traffic & 17544 & 862 & 1 hour & -15.02 \\ ETTh1 & 17420 & 7 & 1 hour & -5.91 \\ ETTh2 & 17420 & 7 & 1 hour & -4.13 \\ ETTm1 & 69680 & 7 & 15 min & -5.91 \\ ETTm2 & 69680 & 7 & 15 min & -5.66 \\ \hline \hline \end{tabular}
\end{table}
Table 6: The statistics of datasets.

### Baseline Methods

Our baseline methods are described as follows:

* Autotorormer [20] is a transformer-based approach that adopts a decomposition strategy to learn complex temporal patterns in long-term prediction scenarios, decomposing time series into trend, cycle, and seasonal components, reflecting the long-term and seasonal aspects of the sequence data, respectively. The source code is available at https://github.com/thuml/Autotormer.
* FEDformer [19] is a hybrid Transformer-based model that integrates seasonal-trend decomposition and frequency enhancements. It can efficiently capture both global variations and intricate patterns. The source code is available at https://github.com/MAZiqing/FEDformer.
* DLinear [27] is a one-layer linear model challenging the efficacy of Transformer-based approaches in long-term time series forecasting, demonstrating superior performance on multiple datasets. The source code is available at https://github.com/cure-lab/LTSF-Linear.
* iTransformer [24] is a transformer-based model. The time series serve as variable tokens, utilizing self-attention mechanisms to capture correlations between multiple variables and using feedforward networks to encode the sequence representation. The source code is available at https://github.com/thuml/iTransformer.

## Appendix B Reversible Normalization

Related reversible normalization methods are described in table 7, and they are described as follows:

* RevIN [11] introduces a data normalization method that addresses the limitations of simply eliminating non-stationary information, which can result in the loss of valuable data that the model needs to learn effectively. Unlike traditional methods that may lead to the model's inability to capture these critical non-stationary factors, this work proposes, for the first time, an explicit restoration of non-stationary information after the model's output. This ensures that while the model can learn without being affected by data drift, it also retains the essential non-stationary information. The source code is available at https://github.com/ts-kim/RevIN.
* NST [13] unlikes traditional time series forecasting methods that reduce non-stationarity by stabilizing the original data, this approach contradicts the importance of predicting sudden events in time series forecasting and overlooks the prevalence of non-stationary data in real-world scenarios, ultimately leading to overly stabilized modeling and prediction. To address this, this paper proposes a novel network architecture composed of sequence stabilization and inverse stabilization attention mechanisms. The source code is available at https://github.com/thuml/Nonstationary_Transformers.
* Dish-TS [12] notes that existing work on distribution shift in time series is often limited by distribution quantization and tends to overlook the potential distribution shift between the look back window and the horizon. To address this, this paper proposes using an MLP-based network to predict mean and standard deviation separately for the look back and horizon windows. The source code is available at https://github.com/weifantt/Dish-TS.
* SAN [14] indicates previous efforts on addressing non-stationarity have attempted to reduce it through normalization techniques. However, these methods typically overlook the distributional differences between input sequences and horizon sequences, assuming that all time points within the same instance share identical statistical properties. This overly idealistic approach can lead to suboptimal improvements. To address this issue, this paper introduces a novel slice-level adaptive normalization method. The source code is available at https://github.com/icantnamemyself/SAN.

Although NST [13] claims that non-stationary information can enhance feature diversity, previous methods have suffered from over-stationarization and inadequate consideration of non-stationary information utilization. However, it is noteworthy that, upon reviewing the current implementationof the non-stationary transformer, the designed non-stationary information extraction module and the corresponding integration of this information into intermediate feature learning can essentially be seen as a mode that employs a distribution prediction network to estimate future non-stationary information and learns through the prediction network. Figure 5 presents a visual comparison of the effects with and without the integration of non-stationary information extraction. It is evident that the non-stationary information extraction and integration module fundamentally enables more accurate reconstruction of non-stationary information, such as mean value.

\begin{table}
\begin{tabular}{c c c} \hline \hline
**Method** & **Granularity** & **Estimation** \\ \hline \hline \begin{tabular}{c} RevIN \\ [11] \\ \end{tabular} & Series Level & Statistics \\ \hline \begin{tabular}{c} NST \\ [13] \\ \end{tabular} & Input/Output Level & Prediction \\ \hline \begin{tabular}{c} Dish-TS \\ [12] \\ \end{tabular} & Input/Output Level & Prediction \\ \hline \begin{tabular}{c} SAN \\ [14] \\ \end{tabular} & Slice Level & Prediction \\ \hline 
\begin{tabular}{c} **DDN** \\ (Ours) \\ \end{tabular} & Point Level & Prediction \\ \hline \end{tabular}
\end{table}
Table 7: Comparative overview of non-stationary processing techniques in time series forecasting. “Granularity” and “Estimation” denote the normalization fineness and the prediction derivation method, respectively.

Figure 5: The comparison of NST [13], “Merge” means using non-stationary factors extraction module and merge to feature, ’No Merge” is the opposite.

### Discrete Wavelet Transform

The Discrete Wavelet Transform (DWT) offers a nuanced approach to signal analysis by decomposing a time series into distinct frequency bands at multiple resolutions. This method is particularly adept at pinpointing both frequency and temporal aspects of a signal, making it invaluable for analyzing non-stationary time series. Initially, the general DWT of a time series \(x(t)\) is expressed through the wavelet coefficients:

\[x_{\phi}(a,b)=\frac{1}{\sqrt{|a|}}\sum_{t}x(t)\cdot\phi\left(\frac{t-b}{a}\right)\] (12)

where \(a\) and \(b\) denote the scaling and translation parameters, respectively, and \(\phi\) is the mother wavelet function. Building upon this foundation, the DWT isolates the approximation coefficients (AC) and detail coefficients (DC), which capture distinct signal characteristics:

\[\begin{split} x_{ac}^{i}&=\mathrm{DWT}_{\phi_{ \text{low}}}(x^{i})=\sum_{t}x(t)\cdot\phi_{\text{low}}(t),\\ x_{dc}^{i}&=\mathrm{DWT}_{\phi_{\text{high}}}(x^{i })=\sum_{t}x(t)\cdot\phi_{\text{high}}(t),\end{split}\] (13)

where \(\phi_{\text{low}}(t)\) represents the low-pass filter and \(\phi_{\text{high}}(t)\) the high-pass filter. Together, these filters facilitate the separation of the input time series into \(x_{ac}^{i}\) and \(x_{dc}^{i}\). The AC coefficients \(x_{ac}^{i}\) embody the low-frequency components that outline the overarching trends within the time series, whereas the DC coefficients \(x_{dc}^{i}\) encompass the high-frequency components, often associated with transient or noise elements in the signal.

The Inverse Discrete Wavelet Transform (IDWT) is then utilized to reconstruct the signal from its wavelet coefficients. The IDWT is the process that combines the AC and DC to form the original signal or an approximation of it. The reconstruction using IDWT can be written as:

\[x^{i}(t)=\mathrm{IDWT}(x_{ac}^{i},x_{dc}^{i})=\sum_{a}x_{ac}^{i}(a)\cdot\phi_{ ac}(a,t)+\sum_{b}x_{dc}^{i}(b)\cdot\phi_{dc}(b,t)\] (14)

where \(\phi_{ac}(a,t)\) and \(\phi_{dc}(b,t)\) are the reconstruction functions from the approximation and detail coefficients, respectively. The wavelet transform, with its ability to localize both frequency and time, provides a powerful framework for signal analysis, particularly for signals like time series that contain non-stationary elements.

[MISSING_PAGE_EMPTY:24]

## Appendix D Quantitative Evaluation Supplement

### Multivariable Forecasting Results of ETT

As illustrated in table 8, we present the comprehensive multivariate forecasting results on the ETT dataset in Table 5, encompassing the hourly datasets ETTh1 and ETTh2, as well as the 15

Figure 11: Our DDN reversible normalization method, samples from DLiner [27] Traffic dataset forecasting.

Figure 10: Comparison with slice level reversible normalization, samples from DLiner [27] weather dataset forecasting.

Figure 9: Comparison with slice level reversible normalization, samples from DLiner [27] weather dataset forecasting.

minute datasets ETTm1 and ETTm2. The data clearly indicate that DDN demonstrates substantial enhancements across these datasets when applied to various backbone models.

### Comparison between DDN and Reversible Normalization Methods

This section comprehensively compares DDN with existing reversible normalization methods. As shown in Table 9, our method consistently achieves state-of-the-art performance across almost all datasets, with a slight under-performance on the ETTm1 dataset compared to SAN. This demonstrates the versatility and effectiveness of our approach.

### Collaborative Training Ablation

Although recent works have shown that the two-stage training strategy effectively enhances the training of distribution prediction models, this training overly relies on the distribution ground truth obtained through distribution assumptions, which often contain inaccuracies. To address this, we introduce a collaborative training strategy that adjusts the distribution prediction model using the MSE loss between the actual sequence and the prediction during training. As illustrated in table 10, collaborative training generally yields superior training outcomes, and its lower bound in performance is comparable to that of the two-stage training strategy. This indicates that collaborative training can better mitigate the errors introduced by distribution assumptions and improve the accuracy of distribution prediction models.

### Univariate Forecasting Results

Following the same settings as our main experiment, we present the univariate forecasting results of Autoformer [20] and FEDformer [19] across three datasets, including Weather, Electricity, and Traffic, in Table 11. Similar to the multivariate forecasting results, DDN consistently enhances the performance of mainstream forecasting models in nearly all cases. It demonstrates that DDN is applicable in both multivariate time series forecasting and univariate forecasting.

\begin{table}
\begin{tabular}{c c c c c c c c c c c c c c c c c} \hline \hline \multirow{2}{*}{Methods} & \multirow{2}{*}{Autoformer} & \multicolumn{2}{c}{+DDN} & \multicolumn{2}{c}{FEDformer} & \multicolumn{2}{c}{+DDN} & \multicolumn{2}{c}{DLinear} & \multicolumn{2}{c}{+DDN} & \multicolumn{2}{c}{+Transformer} & \multicolumn{2}{c}{+DDN} \\ \cline{2-13}  & & & MSE & MAE & MSE & MAE & MSE & MAE & MSE & MAE & MSE & MAE & MSE & MAE & MSE & MAE & MSE & MAE \\ \hline \multirow{8}{*}{\begin{tabular}{c} 192 \\ \end{tabular} } & 96 & 0.458 & **0.448** & **0.427** & **0.424** & **0.371** & 0.411 & 0.385 & **0.408** & 0.377 & 0.399 & **0.372** & **0.396** & 0.392 & 0.422 & 0.377 & **0.405** \\  & 192 & 0.481 & 0.474 & **0.472** & **0.452** & **0.420** & 0.443 & **0.415** & **0.452** & 0.417 & 0.426 & **0.406** & **0.416** & 0.428 & 0.448 & **0.414** & **0.430** \\  & 336 & 0.508 & 0.485 & **0.498** & **0.466** & **0.446** & 0.459 & 0.458 & **0.452** & 0.464 & 0.461 & **0.432** & **0.434** & 0.467 & 0.475 & **0.453** & **0.456** \\  & 720 & 0.525 & 0.516 & **0.502** & **0.483** & **0.482** & 0.495 & 0.490 & **0.479** & 0.493 & 0.505 & **0.462** & **0.474** & 0.568 & 0.547 & **0.553** & **0.530** \\ \hline \multirow{8}{*}{\begin{tabular}{c} 192 \\ \end{tabular} } & 96 & 0.384 & 0.420 & **0.350** & **0.385** & 0.341 & 0.382 & **0.312** & **0.357** & 0.292 & 0.356 & **0.279** & **0.340** & 0.315 & 0.366 & **0.279** & **0.342** \\  & 192 & 0.457 & 0.450 & **0.398** & **0.413** & 0.426 & 0.346 & **0.384** & **0.403** & 0.383 & 0.418 & **0.341** & **0.379** & 0.394 & 0.416 & **0.341** & **0.384** \\  & 336 & 0.468 & 0.473 & **0.428** & **0.444** & 0.481 & 0.479 & **0.421** & **0.437** & 0.473 & 0.477 & **0.364** & **0.402** & 0.430 & 0.445 & **0.369** & **0.410** \\  & 720 & 0.473 & 0.485 & **0.437** & **0.460** & 0.458 & 0.477 & **0.424** & **0.450** & 0.708 & 0.599 & **0.396** & **0.434** & 0.443 & 0.469 & **0.406** & **0.447** \\ \hline \multirow{8}{*}{\begin{tabular}{c} 2016 \\ \end{tabular} } & 96 & 0.493 & 0.470 & **0.354** & **0.390** & 0.362 & 0.408 & **0.313** & **0.364** & 0.301 & 0.344 & **0.288** & **0.342** & 0.322 & 0.371 & **0.301** & **0.355** \\  & 192 & 0.546 & 0.498 & **0.397** & **0.408** & 0.395 & 0.427 & **0.361** & 0.396 & 0.335 & 0.366 & **0.324** & **0.364** & 0.353 & 0.339 & **0.339** & **0.378** \\  & 336 & 0.658 & 0.543 & **0.429** & **0.433** & 0.441 & 0.454 & **0.417** & **0.430** & 0.370 & 0.387 & **0.356** & **0.385** & 0.385 & 0.410 & **0.370** & **0.396** \\  & 720 & 0.626 & 0.532 & **0.488** & **0.464** & 0.488 & 0.481 & **0.470** & **0.472** & 0.425 & 0.421 & **0.415** & **0.419** & 0.441 & 0.443 & **0.426** & **0.426** \\ \hline \multirow{8}{*}{
\begin{tabular}{c} 2016 \\ \end{tabular} } & 96 & 0.261 & 0.329 & **0.177** & **0.262** & 0.191 & 0.283 & **0.171** & **0.255** & 0.169 & 0.263 & **0.167** & **0.257** & 0.187 & 0.279 & **0.162** & **0.253** \\  & 192 & 0.282 & 0.339 & **0.240** & **0.304** & 0.261 & 0.326 & **0.240** & **0.298** & 0.232 & 0.310 & **0.225** & **0.298** & 0.246 & 0.313 & **0.217** & **0.291** \\  & 336 & 0.350 & 0.378 & **0.306** & **0.344** & 0.327 & 0.365 & **0.306** & **0.342** & 0.303 & 0.361 & **0.286** & **0.339** & 0.300 & 0.354 & **0.269** & **0.327** \\ \cline{1-1}  & 720 & 0.438 & 0.428 & **0.409** & **0.421** & 0.428 & 0.423 & **0.413** & **0.410** & 0.403 & 0.424 & **0.371** & **0.391** & 0.378 & 0.403 & **0.350** & **0.380** \\ \hline \hline \end{tabular}
\end{table}
Table 8: Forecasting results comparison under different prediction lengths \(T\in\{96,192,336,720\}\) on ETT dataset. The input sequence length \(L=96\) for Autoformer and FEDformer, \(L=336\) for DLinear, and \(L=720\) for irTransformer. The **bold** values indicate best performance.

[MISSING_PAGE_FAIL:27]

[MISSING_PAGE_FAIL:28]