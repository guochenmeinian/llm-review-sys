# Decentralized Noncooperative Games with Coupled Decision-Dependent Distributions

 Wenjing Yan  Xuanyu Cao

Department of Electronic and Computer Engineering

The Hong Kong University of Science and Technology

wj.yan@connect.ust.hk, eexcao@ust.hk

Corresponding Author.

###### Abstract

Distribution variations in machine learning, driven by the dynamic nature of deployment environments, significantly impact the performance of learning models. This paper explores endogenous distribution shifts in learning systems, where deployed models influence environments, which in turn alters the data distributions that the learning models rely on. This phenomenon is formulated by a decision-dependent distribution mapping within the recently introduced framework of performative prediction (PP) (Perdomo et al., 2020). Our study investigates the performative effect in a decentralized noncooperative game, where players aim to minimize private cost functions while simultaneously managing coupled inequality constraints. In this context, we examine two equilibrium concepts for the studied game: performative stable equilibrium (PSE) and Nash equilibrium (NE), and establish sufficient conditions for their existence and uniqueness. Notably, we provide the first upper bound on the distance between the PSE and NE in the literature, which is challenging to evaluate due to the absence of strong convexity on the joint cost function. Furthermore, we develop a decentralized stochastic primal-dual algorithm for efficiently computing the PSE point. By rigorously bounding the performative effect, we prove that the proposed algorithm achieves sublinear convergence rates for both performative regret and constraint violations and maintains the same order of convergence rate as the case without performativity. Numerical experiments further confirm the effectiveness of our algorithm and theoretical results.

## 1 Introduction

Machine learning aims to generalize models trained on given datasets to make accurate predictions or decisions on new, unseen data (El Naqa and Murphy, 2015). The effectiveness of those models depends on the alignment between the training datasets and deployment environments (Quinonero-Candela et al., 2008). However, real-world environments are seldom static and often exhibit fluctuations that can severely degrade model performance (Zhou, 2022). In particular, shifts in data-generating distributions, driven by the dynamic nature of real-world conditions, present significant challenges for model deployment.

Distribution shifts in machine learning can occur exogenously or endogenously. Exogenous distribution shifts are driven by external factors beyond the control of the learning platforms, such as environmental changes (Chan et al., 2020) or policy amendments (Wu et al., 2021). In contrast, endogenous shifts arise from the system's inherent dynamics and interactions, where the deployed models affect environments, which in turn alters the data distributions that the learning models rely on (Dong et al., 2018). For instance, an increase in commodity prices may decrease user interest, thereby impacting sales. The key distinction lies in the controllability of endogenous shifts, providingan opportunity for designers to either exploit these shifts for improved performance or mitigate unintended consequences (Dean et al., 2023).

While substantial efforts have been made to address exogenous distribution changes, such as covariate shift (Chan et al., 2020), label shift (Wu et al., 2021), and concept drift (Lu et al., 2018), relatively little attention has been paid to the challenges posed by endogenous distribution shifts. Tackling these endogenous shifts is particularly challenging as data distributions are intrinsically linked to the decisions made by the learning model itself (Perdomo et al., 2020). As a result, addressing endogenous shifts may require the explicit modeling of feedback loops, consideration of causal relationships, and the adaptation of models to dynamic environments.

A notable advancement in this area is the recently proposed framework of "performative prediction (PP)" (Perdomo et al., 2020), also referred to as "decision-dependent learning" (Drusvyatskiy and Xiao, 2023). This framework elegantly captures the dynamic interplay between decisions and data distributions through a decision-dependent mapping, denoted by \(\mathcal{D}(\bm{\theta})\) where \(\bm{\theta}\) represents the decision variable. By linking \(\bm{\theta}\) to the data distribution, this formulation bridges the gap between model deployment and parameter optimization. Following the seminal work of (Perdomo et al., 2020), a growing body of research has emerged, focusing on stability and optimality analysis (Piliouras and Yu, 2023; Miller et al., 2021), as well as algorithmic design for various settings, including reinforcement learning (Mandal et al., 2023), online learning (Wood et al., 2021), bandit problems (Jagadeesan et al., 2022), and bilevel optimization (Lu, 2023).

This paper investigates endogenous distribution shifts in a decentralized noncooperative game, where players aim to minimize private cost functions while simultaneously managing coupled inequality constraints. To contextualize this setting, consider scenarios where strategic responses exhibit in learning environments and competitive interactions occur among players. For example, in autonomous vehicular networks, multiple vehicles compete to select their routes under constraints such as road capacities, traffic congestion, and travel costs. The route choices of each vehicle influence traffic patterns and consequently affect the travel times experienced by other vehicles (Mori et al., 2015). Similarly, in finance, traders compete to maximize profits under constraints like market capacities and inventory levels. The trading strategies of these participants impact market volatility and the distribution of asset prices, creating a dynamic pricing landscape (Fattouh and Mahadeva, 2014). These dynamics extend to other domains, such as electricity market competition (Moshari et al., 2010), ride-sharing platforms (Narang et al., 2023), natural resource extraction (Cust and Poelhekke, 2015), and online advertising auctions (Varian, 2009).

Despite its pervasiveness, this performative phenomenon has largely been overlooked in the studies of decentralized noncooperative games. This paper addresses the problem by formulating performativity using coupled decision-dependent distributions, following the PP framework of (Perdomo et al., 2020). However, the intricate interplay between decentralized players and endogenous distribution shifts presents challenging theoretical and algorithmic questions: _How do strategic responses in learning environments influence the game's equilibrium? How can players adapt their strategies effectively when confronted with coupled decision-dependent distributions? How can we design algorithms to exploit these dynamics for optimal decision-making?_ These questions form the core of our investigation, guiding us toward more resilient, adaptive, and efficient learning outcomes in decentralized games, especially in environments characterized by continuously evolving data and decision-making processes. Our main contributions are summarized below:

* We initially formulate the problem of decentralized noncooperative games with data performativity, where selfish players seek to minimize individual costs while managing coupled inequality constraints. Under this setting, we examine two equilibrium concepts: performative stable equilibrium (PSE) and Nash equilibrium (NE), and establish sufficient conditions for their existence and uniqueness. Compared to conventional games, this examination is more complicated due to the interplay between decision-making and distribution changes. Notably, we make a significant contribution by providing the first upper bound on the distance between the PSE and NE in the literature. Computing this distance in PP games is challenging due to the absence of strong convexity on the joint cost function, an essential property for determining the optimality gap of performative stable points in previous work. Instead, we characterize the distance by leveraging relations from strong duality and derive a result comparable to the findings of the prior work (Perdomo et al., 2020; Lu, 2023).

* To compute the PSE point of the PP-game, we propose a decentralized stochastic primal-dual algorithm based on repeated risk minimization (RRM). The development and convergence analysis of this algorithm face two primary challenges. First, there is a complex interaction between decentralized competition and endogenous distribution shifts. Second, players only have partial observation, as they communicate solely with neighbors, despite their private cost functions being influenced by the strategies of all players. We evaluate the performance of our algorithm by two commonly used metrics: performative regret, which measures the suboptimality of the strategy sequence generated by RRM relative to the PSE point, and constraint violation. By rigorously bounding the performative effect, we prove that the proposed algorithm achieves sublinear convergence rates for both metrics. Furthermore, our results show that while the performative effect slows down convergence, it does not degrade the order of performative regret compared to the case without performativity (Lu et al., 2020).

Finally, we conduct numerical experiments on a networked Cournot game and a ride-share market. The simulation results confirm the sublinear convergence of our algorithm. Furthermore, the results demonstrate that while greater performative strength leads to a wider gap between the PSE and NE, the discrepancy between these two equilibria remains marginal. This verifies both the effectiveness of the PSE solutions and the accuracy of our distance analysis between the PSE and NE.

**Related Work:** Among the numerous existing studies, two closely related works (Narang et al., 2023) and (Wang et al., 2023) have considered performative behaviors in games. A key distinction in our work is that our model requires all players' collective strategies to adhere to the constraints of the learning system, whereas both (Narang et al., 2023) and (Wang et al., 2023) address unconstrained settings. This difference results in fundamentally distinct algorithmic designs and convergence analyses. Our approach employs a primal-dual technique and requires consensus, whereas their methods only rely on local stochastic gradient descent. Additionally, we consider a mathematically richer model compared to (Wang et al., 2023), whose framework is structured in a specific form involving local costs dependent solely on individual strategies and a regularizer quantifying similarity among neighboring strategies. Furthermore, our algorithm design accounts for practical constraints where players can only communicate with their immediate neighbors, while (Narang et al., 2023) assumes full accessibility to all players' strategies across the entire network. Importantly, our work makes a significant contribution by providing the first upper bound on the distance between the performative stable equilibrium (PSE) and Nash equilibrium (NE)--a gap not previously addressed. Other related works such as (Li et al., 2022) and (Piliouras and Yu, 2023), have studied performative prediction in decentralized multi-agent optimization. The former focuses on consensus-seeking agents, while the latter is restricted to location-scale families. Finally, (Yan and Cao, 2024) considers the constrained performative prediction problem in a single-agent setting, whereas our paper addresses decentralized noncooperative games. A more comprehensive literature review is provided in Appendix A.

## 2 Problem Formulation

Consider a decentralized noncooperative game with \(n\) players. Each player \(i\) selects a strategy (or, interchangeably, decision, action), denoted as \(\bm{\theta}_{i}\), from its feasible set \(\bm{\Omega}_{i}\subseteq\mathbb{R}^{d}\). Let the collective decisions of all players be denoted as \(\bm{\theta}:=\mathrm{col}\left(\bm{\theta}_{1},\cdots,\bm{\theta}_{n}\right)\), and the collective decisions of all players except player \(i\) be represented as \(\bm{\theta}_{-i}:=\mathrm{col}\left(\bm{\theta}_{1},\cdots,\bm{\theta}_{i-1}, \bm{\theta}_{i+1},\cdots,\bm{\theta}_{n}\right)\), for any \(i\in[n]\), where \([n]\) denotes the set of integers \(\{1,2,\ldots,n\}\). Each player \(i\) has a private cost function \(J_{i}(\bm{\xi}_{i};\bm{\theta}_{i},\bm{\theta}_{-i})\), which depends on the random variable \(\bm{\xi}_{i}\in\bm{\Xi}_{i}\), the player's private decision \(\bm{\theta}_{i}\), and the decisions of all other players \(\bm{\theta}_{-i}\). This paper considers a scenario where the underlying populations strategically respond to the players' decisions, causing shifts in data distributions. This interplay is modeled by a decision-dependent distribution mapping \(\bm{\xi}_{i}\sim\mathcal{D}_{i}\left(\bm{\theta}_{i},\bm{\theta}_{-i}\right)\) for all \(i\in[n]\). The objective of each player \(i\) is to selfishly minimize its _performative risk_\(\mathbb{E}_{\bm{\xi}_{i}\sim\mathcal{D}_{i}\left(\bm{\theta}_{i},\bm{\theta}_{-i }\right)}J_{i}(\bm{\xi}_{i};\bm{\theta}_{i},\bm{\theta}_{-i})\) (abbreviated as \(\mathrm{PR}_{i}(\bm{\theta}_{i},\bm{\theta}_{-i})\)), subject to a coupled constraint \(\sum_{i=1}^{n}\bm{g}_{i}(\bm{\theta}_{i})\preceq\bm{0}\), i.e.,

\[\begin{split}\min_{\bm{\theta}_{i}\in\bm{\Omega}_{i}}& \quad\mathbb{E}_{\bm{\xi}_{i}\sim\mathcal{D}_{i}\left(\bm{\theta}_{i},\bm{ \theta}_{-i}\right)}J_{i}\left(\bm{\xi}_{i};\bm{\theta}_{i},\bm{\theta}_{-i} \right)\\ \text{subject to}&\quad\bm{g}_{i}(\bm{\theta}_{i})+ \sum_{j\neq i}\bm{g}_{j}(\bm{\theta}_{j})\preceq\bm{0}.\end{split}\] (1)

Both \(J_{i}(\cdot)\) and \(\bm{g}_{i}(\cdot)\) are only locally accessible to player \(i\) for all \(i\in[n]\). In the game (1), each player solves its private optimization problem to determine the best strategy, given the current strategiesof all the other players. An equilibrium of the game (1) corresponds to a set of strategies where no player can improve its performance by deviating unilaterally from its strategy.

Denote by \(\boldsymbol{\xi}:=\mathrm{col}\left(\boldsymbol{\xi}_{1},\cdots,\boldsymbol{\xi}_{n}\right)\) the concatenation of the variables \(\boldsymbol{\xi}_{i}\) and by \(J\left(\boldsymbol{\xi};\boldsymbol{\theta}\right):=\mathrm{col}\left(J_{1} \left(\boldsymbol{\xi}_{1};\boldsymbol{\theta}\right),\cdots,J_{n}\left( \boldsymbol{\xi}_{n};\boldsymbol{\theta}\right)\right)\) the concatenation of the cost functions \(J_{i}(\cdot)\) for all \(i\in[n]\). A stochastic pseudogradient mapping of \(J\left(\boldsymbol{\xi};\boldsymbol{\theta}\right)\) is defined as \(\nabla J\left(\boldsymbol{\xi};\boldsymbol{\theta}\right):=\mathrm{col}\left( \nabla_{\boldsymbol{\theta}_{1}}J_{1}\left(\boldsymbol{\xi}_{1};\boldsymbol{ \theta}\right),\cdots,\nabla_{\boldsymbol{\theta}_{n}}J_{n}\left(\boldsymbol {\xi}_{n};\boldsymbol{\theta}\right)\right)\). We have the following assumption on \(\nabla J\left(\boldsymbol{\xi};\boldsymbol{\theta}\right)\).

**Assumption 2.1**.: There exists a constant \(\mu>0\) such that the stochastic gradient mapping \(\nabla J\left(\boldsymbol{\xi};\boldsymbol{\theta}\right)\) is \(\mu\)-strongly monotone, i.e., \(\left\langle\nabla J\left(\boldsymbol{\xi};\boldsymbol{\theta}\right)-\nabla J \left(\boldsymbol{\xi};\boldsymbol{\theta}^{\prime}\right),\boldsymbol{\theta }-\boldsymbol{\theta}^{\prime}\right\rangle\geq\mu\|\boldsymbol{\theta}- \boldsymbol{\theta}^{\prime}\|_{2}^{2},\forall\boldsymbol{\xi}\in\boldsymbol{ \Xi},\boldsymbol{\theta},\boldsymbol{\theta}^{\prime}\in\boldsymbol{\Omega}\), where \(\boldsymbol{\Xi}:=\boldsymbol{\Xi}_{1}\times\cdots\times\boldsymbol{\Xi}_{n}\) and \(\boldsymbol{\Omega}:=\boldsymbol{\Omega}_{1}\times\cdots\times\boldsymbol{\Omega }_{n}\).

Assumption 2.1 is commonly made in the literature of game theory. It suffices to guarantee the existence of Nash equilibrium for a stochastic game with fixed data distributions (Facchinei and Pang, 2003, Theorem 2.3.3(b)). However, in our paper, since the data distributions are decision-dependent, Assumption 2.1 does not imply the monotonicity of the gradient mapping of the joint performative risk, denoted by \(\mathrm{PR}(\cdot):=\mathrm{col}\left(\mathrm{PR}_{1}(\cdot),\cdots,\mathrm{PR} _{n}(\cdot)\right)\). Therefore, the existence and uniqueness (E\(\&\)U) conditions for the Nash equilibrium of the game (1) need further investigation.

We define a graph \(\mathcal{G}(\mathbf{P})\) to represent the impact of players' decisions on the data distributions of different players. In \(\mathcal{G}(\mathbf{P})\), the weight \(p_{ij}>0\) if player \(j\)'s decision affects player \(i\)'s data distribution, and \(p_{ij}=0\) otherwise. Particularly, \(p_{ii}\) represents the weight of self-influence. These weights are normalized as \(\sum_{j=1}^{n}p_{ij}=1\), for all \(i\in[n]\). Clearly, the larger the weight \(p_{ij}\), the stronger the effect of player \(j\)'s decision on the data distribution of player \(i\).

Let \(\mathcal{W}_{1}\left(\mathcal{D},\mathcal{D}^{\prime}\right)\) represent the _Wasserstein_-\(1\) distance between two probability measures \(\mathcal{D}\) and \(\mathcal{D}^{\prime}\). Following (Wang et al., 2023), we impose the following assumption on the distributions \(\{\mathcal{D}_{i}\}_{i\in[n]}\).

**Assumption 2.2**.: For any \(i\in[n]\), there exists a constant \(\varepsilon_{i}\geq 0\) such that, \(\forall\boldsymbol{\theta},\boldsymbol{\theta}^{\prime}\in\boldsymbol{\Omega}\), the distribution mapping \(\mathcal{D}_{i}\) is constrained by \(\mathcal{W}_{1}\left(\mathcal{D}_{i}\left(\boldsymbol{\theta}\right),\mathcal{D }_{i}\left(\boldsymbol{\theta}^{\prime}\right)\right)\leq\varepsilon_{i} \sqrt{\sum_{j=1}^{n}p_{ij}\left\|\boldsymbol{\theta}_{j}-\boldsymbol{\theta}^{ \prime}_{j}\right\|_{2}^{2}}\).

For any \(i\in[n]\), the parameter \(\varepsilon_{i}\) bounds the sensitivity of player \(i\)'s distribution with respect to (w.r.t.) the decision variations of all players. This \(\varepsilon\)-sensitivity property of distributions is conceptually akin to the Lipschitz continuity of functions that quantifies the variation of function values w.r.t argument changes. We also require the following assumptions.

**Assumption 2.3**.: For any \(i\in[n]\), the non-empty feasible set \(\boldsymbol{\Omega}_{i}\) is closed, convex, and bounded, i.e., there exists a constant \(C\geq 0\) such that, \(\forall\boldsymbol{\theta}_{i}\in\boldsymbol{\Omega}_{i}\), \(\|\boldsymbol{\theta}_{i}\|_{2}\leq C\).

**Assumption 2.4**.: For any \(i\in[n]\) and \(\boldsymbol{\theta}_{i}\in\boldsymbol{\Omega}_{i}\), the cost function \(J_{i}(\boldsymbol{\xi}_{i};\boldsymbol{\theta}_{i},\boldsymbol{\theta}_{-i})\) is convex w.r.t. \(\boldsymbol{\theta}_{i}\). Moreover, there exists a constant \(L_{i}\geq 0\) such that \(J_{i}\left(\boldsymbol{\xi}_{i};\boldsymbol{\theta}\right)\) is \(L_{i}\)-smooth, i.e, \(\left\|\nabla J_{i}\left(\boldsymbol{\xi}_{i};\boldsymbol{\theta}\right)- \nabla J_{i}\left(\boldsymbol{\xi}_{i}^{\prime};\boldsymbol{\theta}^{\prime} \right)\right\|_{2}\leq L_{i}\left(\left\|\boldsymbol{\xi}_{i}-\boldsymbol{ \xi}_{i}^{\prime}\right\|_{2}+\left\|\boldsymbol{\theta}-\boldsymbol{\theta}^{ \prime}\right\|_{2}\right),\forall\boldsymbol{\xi}_{i}^{\prime},\boldsymbol{ \xi}_{i}^{\prime}\in\boldsymbol{\Xi}_{i},\boldsymbol{\theta},\boldsymbol{\theta}^ {\prime}\in\boldsymbol{\Omega}\).

**Assumption 2.5**.: For any \(i\in[n]\) and \(\boldsymbol{\theta}_{i}\in\boldsymbol{\Omega}_{i}\), the constraint function \(\boldsymbol{g}_{i}(\theta_{i})\) is convex w.r.t. \(\boldsymbol{\theta}_{i}\). Moreover, there exist a constant \(G_{g}\geq 0\) such that \(\boldsymbol{g}_{i}(\cdot)\) is \(G_{g}\)-Lipschitz, i.e., \(\left\|\boldsymbol{g}_{i}(\boldsymbol{\theta}_{i})-\boldsymbol{g}_{i}( \boldsymbol{\theta}_{i}^{\prime})\right\|_{2}\leq G_{g}\|\boldsymbol{\theta}_{i} -\boldsymbol{\theta}_{i}^{\prime}\|_{2},\forall\boldsymbol{\theta}_{i}, \boldsymbol{\theta}_{i}^{\prime}\in\boldsymbol{\Omega}_{i}\).

Assumptions 2.3 and 2.5 are widely used in constrained optimization (Bertsekas, 2014; Yan and Cao, 2024a), and Assumption 2.4 is standard in the PP literature. From Yan and Cao (2024a, Proposition 1), under Assumptions 2.3 and 2.4, the cost function \(J_{i}(\boldsymbol{\xi}_{i};\boldsymbol{\theta})\), \(\forall i\in[n]\) is Lipschitz continuous, i.e., there exist a constant \(G_{i}\geq 0\) such that \(|J_{i}(\boldsymbol{\xi}_{i};\boldsymbol{\theta})-J_{i}(\boldsymbol{\xi}_{i}^{ \prime};\boldsymbol{\theta}^{\prime})|\leq G_{i}\left(\left\|\boldsymbol{ \xi}_{i}-\boldsymbol{\xi}_{i}^{\prime}\right\|_{2}+\left\|\boldsymbol{\theta}- \boldsymbol{\theta}^{\prime}\right\|_{2}\right),\forall\boldsymbol{\xi}_{i}, \boldsymbol{\xi}_{i}^{\prime}\in\boldsymbol{\Xi}_{i},\boldsymbol{\theta}, \boldsymbol{\theta}^{\prime}\in\boldsymbol{\Omega}\). Moreover, Assumptions 2.3 and 2.5 imply the boundedness of \(\|\boldsymbol{g}_{i}(\boldsymbol{\theta}_{i})\|_{2}\), i.e., there exists a constant \(B\geq 0\) such that \(\|\boldsymbol{g}_{i}(\boldsymbol{\theta}_{i})\|_{2}\leq B,\forall\boldsymbol{ \theta}_{i}\in\boldsymbol{\Omega}_{i},i\in[n]\).

## 3 Equilibrium of the PP-Game

This section examines two fundamental equilibrium concepts of the performative game (1): Nash equilibrium (NE) and performative stable equilibrium (PSE), as defined below.

**Definition 3.1** (Nash Equilibrium).: A vector \(\boldsymbol{\theta}^{\mathrm{ne}}:=\mathrm{col}\left(\boldsymbol{\theta}_{1}^{ \mathrm{ne}},\ldots,\boldsymbol{\theta}_{n}^{\mathrm{ne}}\right)\) achieves an NE of the game (1) if it holds for any \(i\in[n]\) that

\[\boldsymbol{\theta}_{i}^{\mathrm{ne}}\in\operatorname*{arg\,min}_{ \boldsymbol{\theta}_{i}\in\boldsymbol{\Omega}_{i}} \quad\mathbb{E}_{\boldsymbol{\xi}_{i}\sim\mathcal{D}_{i}\left(\boldsymbol{ \theta}_{i},\boldsymbol{\theta}_{-i}^{\mathrm{ne}}\right)}J_{i}\left( \boldsymbol{\xi}_{i};\boldsymbol{\theta}_{i},\boldsymbol{\theta}_{-i}^{ \mathrm{ne}}\right)\] subject to \[\quad\boldsymbol{g}_{i}(\boldsymbol{\theta}_{i})+\sum_{j\neq i} \boldsymbol{g}_{j}(\boldsymbol{\theta}_{j}^{\mathrm{ne}})\preceq\boldsymbol{0}.\]

**Definition 3.2** (Performance Stable Equilibrium).: A vector \(\bm{\theta}^{\text{\rm{pse}}}:=\mathrm{col}\left(\bm{\theta}_{1}^{\text{\rm{pse}}}, \ldots,\bm{\theta}_{n}^{\text{\rm{pse}}}\right)\) achieves a PSE of the game (1) if it holds for any \(i\in[n]\) that

\[\bm{\theta}_{i}^{\text{\rm{pse}}}\in\operatorname*{arg\,min}_{\bm {\theta}_{i}\in\bm{\Omega}_{i}} \quad\operatorname*{E}_{\bm{\xi}_{i}\sim\mathcal{D}_{i}(\bm{ \theta}^{\text{\rm{pse}}})}J_{i}\left(\bm{\xi}_{i};\bm{\theta}_{i},\bm{\theta }_{-i}^{\text{\rm{pse}}}\right)\] \[\text{subject to} \quad\bm{g}_{i}(\bm{\theta}_{i})+\sum_{j\neq i}\bm{g}_{j}(\bm{ \theta}_{j}^{\text{\rm{pse}}})\preceq\bm{0}.\]

NE is a fundamental concept in game theory. At NE, each player's strategy optimally aligns with its own interest, given the strategies of other players. Hence, no player has an incentive to deviate from its strategy unilaterally. In the case of performative games, the computation of NE needs to take into account the data distributions \(\mathcal{D}_{i}(\cdot)\) for all \(i\in[n]\), as they are parameterized by the optimization variable \(\bm{\theta}\). However, this information is often unavailable in practice. Instead, at PSE, the data distribution of each player \(i\in[n]\) is fixed at \(\mathcal{D}_{i}\left(\bm{\theta}^{\text{\rm{pse}}}\right)\) and the PSE point achieves an NE of the game (1) under the fixed data distribution of its own deployment. This formulation draws benign properties akin to problems with fixed data distributions, facilitating the adaptation of existing algorithms. Therefore, PSE is more frequently chosen as a performance metric in the literature of PP.

### Existence and Uniqueness of PSE

We first establish the condition for the E\(\&\)U of the PSE of the game (1). Our approach relies on repeated risk minimization (RRM) for closed-loop retraining. First, we define a mapping \(\mathcal{T}(\bm{\theta}):=\{\mathcal{T}_{i}(\bm{\theta})\}_{i\in[n]}\) that, for any \(i\in[n]\),

\[\bm{\theta}_{i}^{\prime}=\mathcal{T}_{i}(\bm{\theta}):= \operatorname*{arg\,min}_{\bm{u}_{i}\in\bm{\Omega}_{i}} \quad\operatorname*{E}_{\bm{\xi}_{i}\sim\mathcal{D}_{i}(\bm{ \theta}_{i},\bm{\theta}_{-i})}J_{i}\left(\bm{\xi}_{i};\bm{u}_{i},\bm{\theta}_{ -i}^{\prime}\right)\] subject to \[\quad\bm{g}_{i}(\bm{u}_{i})+\sum_{j\neq i}\bm{g}_{j}\left(\bm{ \theta}_{j}^{\prime}\right)\preceq\bm{0}.\]

The mapping \(\mathcal{T}(\bm{\theta})\) outputs the NE of the game (1) under the fixed data distributions \(\mathcal{D}_{i}(\bm{\theta}_{i},\bm{\theta}_{-i})\) for all \(i\in[n]\). With Assumption 2.1, the E\(\&\)U of this NE is guaranteed, thereby ensuring the validity of the mapping \(\mathcal{T}(\bm{\theta})\). Based on \(\mathcal{T}(\bm{\theta})\), the RRM updates \(\bm{\theta}_{i}^{t}\) at each iteration \(t\) by

\[\bm{\theta}_{i}^{t+1}=\mathcal{T}_{i}(\bm{\theta}^{t}),\forall i \in[n].\] (2)

Clearly, \(\bm{\theta}^{t+1}\) is an NE of the game (1) under the deployment of \(\bm{\theta}^{t}\). Additionally, we have that any fixed point of (2) achieves an PSE for the game (1), i.e., \(\bm{\theta}^{\text{\rm{pse}}}=\mathcal{T}(\bm{\theta}^{\text{\rm{pse}}})\). By investigating the convergence the iterative equation (2), we have the following sufficient condition for the E\(\&\)U of the PSE of the game (1).

**Theorem 3.3**.: _Suppose that Assumptions 2.1-2.5 hold. Then, for any \(\bm{\theta},\bm{\delta}\in\bm{\Omega}\), the mapping \(\mathcal{T}(\bm{\theta})\) satisfies_

\[\|\mathcal{T}(\bm{\theta})-\mathcal{T}(\bm{\delta})\|_{2}\leq\tfrac {1}{\mu}\sqrt{\sum_{i=1}^{n}L_{i}^{2}\varepsilon_{i}^{2}\max_{j\in[n]}p_{ij}} \left\|\bm{\theta}-\bm{\delta}\right\|_{2}.\]

_Thus, if it is satisfied that_

\[\tfrac{1}{\mu}\sqrt{\sum_{i=1}^{n}L_{i}^{2}\varepsilon_{i}^{2} \max_{j\in[n]}p_{ij}}<1,\] (3)

_the sequence generated by the RRM (2) converges to a unique PSE point \(\bm{\theta}^{\text{\rm{pse}}}\) at a linear rate that_

\[\|\bm{\theta}^{t+1}-\bm{\theta}^{\text{\rm{pse}}}\|_{2}\leq\left( \tfrac{1}{\mu}\sqrt{\sum_{i=1}^{n}L_{i}^{2}\varepsilon_{i}^{2}\max_{j\in[n]}p_{ ij}}\right)^{t}\left\|\bm{\theta}^{1}-\bm{\theta}^{\text{\rm{pse}}}\right\|_{2}.\]

The proof of Theorem 3.3 is provided in Appendix B. According to Theorem 3.3, under Assumptions 2.1-2.5, when condition (3) holds, we have that: (i) the game (1) admits a unique PSE, and (ii) the RRM method (2) converges linearly to the PSE.

Since the influence weights \(\{p_{ij}\}_{j\in[n]}\) are normalized, with \(\sum_{j=1}^{n}p_{ij}=1\) for all \(i\in[n]\), we generally have that \(p_{ij}=\mathcal{O}(\tfrac{1}{n})\). Therefore, the contraction condition (3) exhibits good scalability w.r.t. the number of players. Moreover, according to the proof in Appendix B, if for any player \(i\in[n]\), its distribution \(\mathcal{D}_{i}(\cdot)\) depends only on its own decision \(\bm{\theta}_{i}\), i.e., \(p_{ij}=0\) for all \(j\neq i\), then we have

\[\|\mathcal{T}(\bm{\theta})-\mathcal{T}(\bm{\delta})\|_{2}\leq\tfrac {1}{\mu}\max_{i\in[n]}L_{i}\varepsilon_{i}\left\|\bm{\delta}-\bm{\theta} \right\|_{2}.\]The contraction of the above iterative equation only requires that \(\frac{1}{\mu}\max_{i\in[n]}L_{i}\varepsilon_{i}<1\). Furthermore, if all players exhibit equivalent model parameters that \(L_{1}=\cdots=L_{n}=L\) and \(\varepsilon_{1}=\cdots=\varepsilon_{n}=\varepsilon\) and \(p_{ij}=\frac{1}{n}\) for all \(i,j\in[n]\), condition (3) reduces to \(\frac{L\varepsilon}{\mu}<1\), recovering the contraction requirement of (Perdomo et al., 2020) for a single-agent PP case.

### Existence and Uniqueness of NE

First, we define a gradient mapping \(G_{\bm{\theta}}^{(i)}(\bm{\delta}_{i},\bm{\delta}_{-i}):=\mathbb{E}_{\bm{ \xi}_{i}\sim\mathcal{D}_{i}(\bm{\theta})}\nabla_{\bm{\delta}_{i}}J_{i}\left( \bm{\xi}_{i};\bm{\delta}_{i},\bm{\delta}_{-i}\right)\) for any \(i\in[n]\), and \(G_{\bm{\theta}}(\bm{\delta}):=\mathrm{col}\left(G_{\bm{\theta}}^{(1)}(\bm{ \delta}),\cdots,G_{\bm{\theta}}^{(n)}(\bm{\delta})\right)\). Moreover, for any \(i\in[n]\), define

\[H_{\bm{\theta}_{i},\bm{\theta}_{-i}}^{(i)}(\bm{\delta}):=\nabla_{\bm{u}_{i}} \mathbb{E}_{\bm{\xi}_{i}\sim\mathcal{D}_{i}(\bm{u}_{i},\bm{\theta}_{-i})} \left[J_{i}\left(\bm{\xi}_{i};\bm{\delta}\right)\right]\rvert_{\bm{u}_{i}=\bm {\theta}_{i}}\]

and \(H_{\bm{\theta}}(\bm{\delta}):=\mathrm{col}\left(H_{\bm{\theta}_{1},\bm{\theta }_{-1}}^{(1)}(\bm{\delta}),\cdots,H_{\bm{\theta}_{n},\bm{\theta}_{-n}}^{(n)}( \bm{\delta})\right)\). Then, for any \(i\in[n]\), the gradient of the performative risk \(\mathrm{PR}_{i}(\bm{\theta}_{i},\bm{\theta}_{-i})\) w.r.t. \(\bm{\theta}_{i}\) is given by

\[\nabla_{\bm{\theta}_{i}}\mathrm{PR}_{i}(\bm{\theta}_{i},\bm{\theta}_{-i})=G_{ \bm{\theta}_{i},\bm{\theta}_{-i}}^{(i)}(\bm{\theta}_{i},\bm{\theta}_{-i})+H_{ \bm{\theta}_{i},\bm{\theta}_{-i}}^{(i)}(\bm{\theta}_{i},\bm{\theta}_{-i}).\]

Define \(\nabla\mathrm{PR}(\bm{\theta}):=\mathrm{col}\left(\nabla_{\bm{\theta}_{i}} \mathrm{PR}_{i}(\bm{\theta}),\cdots,\nabla_{\bm{\theta}_{i}}\mathrm{PR}_{n}( \bm{\theta})\right)\), we further have

\[\nabla\mathrm{PR}(\bm{\theta})=G_{\bm{\theta}}(\bm{\theta})+H_{\bm{\theta}}( \bm{\theta}).\]

From Facchinei and Pang (2003, Theorem 2.3.3(b)), to prove the E&U of the NE of the (1), we require the strongly monotonivity of the gradient mapping \(\nabla\mathrm{PR}(\bm{\theta})\). Therefore, we have the following sufficient condition for the E&U of the NE of the game (1).

**Theorem 3.4**.: _Suppose that Assumptions 2.1-2.5 hold. If it is satisfied that_

\[\mu-\sum_{i=1}^{n}L_{i}\varepsilon_{i}\max_{j\in[n]}\sqrt{p_{ij}}-\sqrt{\sum_{ i=1}^{n}L_{i}^{2}\varepsilon_{i}^{2}p_{ii}}>0,\] (4)

_then, the PP-game (1) is strongly monotone and admits a unique NE._

The proof of Theorem 3.4 is presented in Appendix C. Since \(p_{ij}\) characterizes the influence of player \(j\)'s decision on the data distribution of player \(i\), we typically have \(p_{ij}\leq p_{ii}\) for \(j\neq i\) and thus \(\max_{j\in[n]}p_{ij}=p_{ii}\) for all \(i\in[n]\). Then, the condition (4) reduces to \(\mu-\sum_{i=1}^{n}L_{i}\varepsilon_{i}p_{ii}-\sqrt{\sum_{i=1}^{n}L_{i}^{2} \varepsilon_{i}^{2}p_{ii}}>0\). Similarly, when \(L_{1}=\cdots=L_{n}=L\), \(\varepsilon_{1}=\cdots=\varepsilon_{n}=\varepsilon\), and \(p_{ij}=\frac{1}{n}\) for all \(i,j\in[n]\), we require that \(\mu-2L\varepsilon>0\), i.e., \(\varepsilon\leq\frac{\mu}{2L}\), which recovers the condition to guarantee the convexity of the performative risk \(\mathrm{PR}(\cdot)\), and thereby the E&U of the performative optimal point of (Miller et al., 2021) for single-agent PP.

### Distance Between PSE and NE

**Theorem 3.5**.: _Define \(\widetilde{\mu}:=\mu-\sum_{i=1}^{n}L_{i}\varepsilon_{i}\max_{j\in[n]}\sqrt{p_ {ij}}\) and \(\alpha:=\sum_{i=1}^{n}G_{i}\left(1+\varepsilon_{i}\max_{j\in[n]}\sqrt{p_{ij}}\right)\). Suppose that Assumptions 2.1-2.5 hold and \(\widetilde{\mu}>0\). Then, for every PSE point and NE point, we have the following relations:_

\[\|\bm{\theta}^{\mathrm{pse}}-\bm{\theta}^{\mathrm{ne}}\|_{2}\leq\frac{1}{\widetilde {\mu}}\sqrt{\sum_{i=1}^{n}G_{i}^{2}\varepsilon_{i}^{2}p_{ii}}\quad\text{and} \quad|\mathrm{PR}(\bm{\theta}^{\mathrm{pse}})-\mathrm{PR}(\bm{\theta}^{ \mathrm{ne}})|\leq\frac{\alpha}{\widetilde{\mu}}\sqrt{\sum_{i=1}^{n}G_{i}^{2} \varepsilon_{i}^{2}p_{ii}}.\]

The proof of Theorem 3.5 is presented in Appendix D. According to Theorem 3.5, the distance between the PSE and NE of the game (1) depends on the cost functions' parameters \(\mu\), \(\{G_{i}\}\), \(\{L_{i}\}\), as well as the sensitivity of the data distributions \(\{\varepsilon_{i}\}\). Larger sensitivity parameters widen the gap between the PSE and NE, while a bigger monotonicity parameter \(\mu\) reduces it. Notably, when the sensitivity parameter \(\varepsilon_{i}=0\) for all \(i\in[n]\), the game (1) reduces to a conventional stochastic game with fixed data distributions, and as a result, the PSE and NE converge to the same point.

To the best of our knowledge, this is the first result on the distance between PSE and NE of PP-games. Characterizing this distance is challenging in games due to the lack of strong convexity on the joint cost function \(J(\cdot)\), which is an essential property for determining the optimality gap of performative stable points in previous work (Perdomo et al., 2020; Lu, 2023). In this paper, we characterize this gap by leveraging relations from strong duality (Boyd and Vandenberghe, 2004; Facchinei and Pang, 2010). Our result is comparable to the findings in (Perdomo et al., 2020) for single-agent PP problems wherein this optimality gap is bounded by \(\frac{2L\varepsilon}{\mu}\). In our case, when \(G_{1}=\cdots=G_{n}=G\), \(\varepsilon_{1}=\cdots=\varepsilon_{n}=\varepsilon\) and \(p_{ij}=\frac{1}{n}\) for all \(i,j\in[n]\), we have \(\|\bm{\theta}^{\mathrm{pse}}-\bm{\theta}^{\mathrm{ne}}\|_{2}\leq\frac{G \varepsilon}{\mu-L\varepsilon}\).

## 4 Computation of the PSE

Although RRM theoretically has the capability to find a PSE point, how to perform risk minimization at its each update remains unknown. Moreover, RRM requires the computation of an NE for each deployment, which is computationally intensive. In this section, we present a decentralized stochastic primal-dual algorithm for efficiently computing the PSE of the game (1). Theoretical analysis is also provided on the convergence of the proposed algorithm.

### Algorithm Development

For each player \(i\in[n]\), define a regularized Lagrangian as

\[\mathcal{L}_{\bm{\delta}}^{(i)}(\bm{\theta}_{i},\bm{\theta}_{-i},\bm{\lambda} )=\mathbb{E}_{\bm{\xi}_{i}\sim\mathcal{D}_{i}(\bm{\delta})}J_{i}\left(\bm{\xi} _{i};\bm{\theta}_{i},\bm{\theta}_{-i}\right)+\left\langle\bm{\lambda},\bm{g}_ {i}(\bm{\theta}_{i})+\sum_{j\neq i}\bm{g}_{j}\left(\bm{\theta}_{j}\right) \right\rangle,\]

where \(\bm{\lambda}\in\mathbb{R}_{+}^{m}\) is the dual variable. Denote by \(\nabla\bm{g}_{i}(\cdot)\) the Jacobian matrix of \(\bm{g}_{i}(\cdot)\). From the primal-dual theory (Boyd and Vandenbergheg, 2004; Facchinei and Pang, 2010), for any \(\gamma>0\), there exists a bounded Lagrangian multiplier \(\bm{\lambda}^{\rm{pse}}\) such that the following condition holds:

\[\bm{\theta}_{i}^{\rm{pse}}= P_{\bm{\Omega}_{i}}\left[\bm{\theta}_{i}^{\rm{pse}}-\gamma \left(G_{\bm{\theta}^{\rm{pse}}}^{(i)}\left(\bm{\theta}^{\rm{pse}},\bm{ \lambda}^{\rm{pse}}\right)+\gamma\nabla\bm{g}_{i}(\bm{\theta}_{i}^{\rm{pse}})^ {\top}\bm{\lambda}^{\rm{pse}}\right)\right],\quad\forall i\in[n],\] \[\bm{\lambda}^{\rm{pse}}= \left[\bm{\lambda}^{\rm{pse}}+\gamma\left(\bm{g}_{i}(\bm{\theta} _{i}^{\rm{pse}})+\sum_{j\neq i}\bm{g}_{j}\left(\bm{\theta}_{j}^{\rm{pse}}\right) \right)\right]_{+},\]

where \(\gamma\) is a control parameter. Thus, given \(\bm{\theta}_{-i}^{\rm{pse}}\) and under \(\bm{\xi}_{i}\sim\mathcal{D}_{i}(\bm{\theta}^{\rm{pse}})\), \((\bm{\theta}_{i}^{\rm{pse}},\bm{\lambda}^{\rm{pse}})\) is a saddle point of the Lagrangian \(\mathcal{L}_{\bm{\theta}^{\rm{pse}}}^{(i)}(\bm{\theta}_{i},\bm{\theta}_{-i}^{ \rm{pse}},\bm{\lambda})\) for any \(i\in[n]\). The joint saddle point \((\bm{\theta}^{\rm{pse}},\bm{\lambda}^{\rm{pse}})\) achieve the PSE of the game (1) under strong duality (Boyd and Vandenbergheg, 2004).

In the decentralized noncooperative game (1), each player can only communicate with its neighbors. We use \(\mathcal{G}(\mathbf{A})\) to denote the communication graph of the network, where \(\mathbf{A}=\left(a_{ij}\right)_{n\times n}\) represents a weight matrix. In \(\mathcal{G}(\mathbf{A})\), \(a_{ij}=a_{ji}>0\) if there is a communication link between player \(i\) and play \(j\), and \(a_{ij}=a_{ji}=0\) otherwise. Let \(\mathcal{N}_{i}\) be the set containing player \(i\) and all its neighbors such that \(j\in\mathcal{N}_{i}\) if \(a_{ij}>0\). We assume that the communication graph \(\mathcal{G}(\mathbf{A})\) is connected and the weight matrix \(\mathbf{A}\) is doubly stochastic.

To find the saddle point \((\bm{\theta}^{\rm{pse}},\bm{\lambda}^{\rm{pse}})\), we develop a decentralized stochastic primal-dual algorithm, as presented in Algorithm 1. The basic idea of Algorithm 1 is to perform gradient update on the primal variables \(\bm{\theta}_{i}\) for all \(i\in[n]\) and the dual variable \(\bm{\lambda}\). In the decentralized noncooperative game, each player \(i\in[n]\) only observes information from its neighbors. However, its private cost funtion \(J_{i}(\bm{\xi}_{i};\bm{\theta}_{i},\bm{\theta}_{-i})\) involves all players' strategies. To solve this problem, we let each player \(i\) store an estimate for the strategies of all the other players, denoted by \(\widehat{\bm{\theta}}_{ih}\), for all \(h\neq i\). Define a vector \(\widehat{\bm{\theta}}_{i}\) that concatenates all the estimates \(\widehat{\bm{\theta}}_{ih}\). In each iteration \(t\), neighbors exchange strategy \(\bm{\theta}_{i}^{t}\), estimate \(\widehat{\bm{\theta}}_{i}^{t}\), and dual variable \(\bm{\lambda}_{i}^{t}\) with each other. Then, each player \(i\) updates the estimates \(\widehat{\bm{\theta}}_{ih}\), for all \(h\neq i\) by weighted average in Step 4. The primal variable \(\bm{\theta}_{i}^{t}\) is updated by gradient descent by Step 6, and the dual variable \(\bm{\lambda}_{i}^{t}\) is updated by gradient ascent by Step 7. The coefficient \(\gamma_{t}\) is the stepsize at the \(t\)th iteration for all \(t\in[T]\).

### Performance Analysis

Before analyzing the performance of Algorithm 1, we define the performance metrics adopted in this paper. The first metric is performative regret. For any player \(i\in[n]\), its performative regret over \(T\) iterations is defined as

\[\mathcal{R}_{i}(T)\!:=\!\sum\nolimits_{t=1}^{T}\left(\mathbb{E}_{\boldsymbol{ \xi}_{i}\sim\mathcal{D}_{i}(\boldsymbol{\theta}^{\text{\tiny{pse}}})}J_{i} \left(\boldsymbol{\xi}_{i};\boldsymbol{\theta}_{i}^{\text{\tiny{pse}}}, \boldsymbol{\theta}_{-i}^{\text{\tiny{pse}}}\right)-\mathrm{PR}_{i}\left( \boldsymbol{\theta}^{\text{\tiny{pse}}}\right)\right).\]

The regret \(\mathcal{R}_{i}(T)\) measures the suboptimality of the sequence of decisions \(\{\boldsymbol{\theta}_{i}^{1},\cdots,\boldsymbol{\theta}_{i}^{T}\}\) taken by play \(i\) relative to \(\boldsymbol{\theta}_{i}^{\text{\tiny{pse}}}\). Besides, since the decisions of all players are subject to constraints, another performance metric of constraint violation, denoted by \(\mathcal{R}_{g}(T)\), is required, defined as

\[\mathcal{R}_{g}(T)=\left\|\left[\sum\nolimits_{t=1}^{T}\sum\nolimits_{i=1}^{n }\boldsymbol{g}_{i}\left(\boldsymbol{\theta}_{i}^{t}\right)\right]_{+}\right\| _{2}.\]

Any online or learning algorithm is regarded as "good" if both the time-average regret and the time-average constraint violation are sublinear, i.e., \(\lim_{T\rightarrow\infty}\mathcal{R}_{i}(T)/T\leq o(1)\) for any \(i\in[n]\) and \(\lim_{T\rightarrow\infty}\mathcal{R}_{g}(T)/T\leq o(1)\).

For analysis, we make the following assumption on the variance of the stochastic gradient \(\nabla_{\boldsymbol{\theta}_{i}}J_{i}\left(\boldsymbol{\xi}_{i};\boldsymbol{ \delta}_{i},\boldsymbol{\delta}_{-i}\right)\), \(\forall i\in[n]\).

**Assumption 4.1**.: The stochastic gradient \(\nabla_{\boldsymbol{\delta}_{i}}J_{i}\left(\boldsymbol{\xi}_{i};\boldsymbol{ \delta}_{i},\boldsymbol{\delta}_{-i}\right)\) is unbiased that \(\mathbb{E}_{\boldsymbol{\xi}_{i}\sim\mathcal{D}_{i}(\boldsymbol{\theta})} \nabla_{\boldsymbol{\delta}_{i}}J_{i}\left(\boldsymbol{\xi}_{i};\boldsymbol{ \delta}_{i},\boldsymbol{\delta}_{-i}\right)=G_{\boldsymbol{\theta}}^{(i)} \left(\boldsymbol{\delta}_{i},\boldsymbol{\delta}_{-i}\right)\) and there exist constants \(\sigma_{0},\sigma_{1}\geq 0\) such that \(\sum_{i=1}^{n}\mathbb{E}_{\boldsymbol{\xi}_{i}\sim\mathcal{D}_{i}(\boldsymbol{ \theta})}\left\|\nabla_{\boldsymbol{\delta}_{i}}J_{i}\left(\boldsymbol{\xi}_{i };\boldsymbol{\delta}_{i},\boldsymbol{\delta}_{-i}\right)-G_{\boldsymbol{ \theta}}^{(i)}\left(\boldsymbol{\delta}_{i},\boldsymbol{\delta}_{-i}\right) \right\|_{2}^{2}\leq\sigma_{0}^{2}+\sigma_{1}^{2}\left\|\boldsymbol{\theta}- \boldsymbol{\theta}^{\text{\tiny{pse}}}\right\|_{2}^{2},\forall\boldsymbol{ \theta},\boldsymbol{\delta}\in\boldsymbol{\Omega}\).

**Theorem 4.2**.: _Define \(\widetilde{\mu}:=\mu-\sum_{i=1}^{n}L_{i}\varepsilon_{i}\max_{j\in[n]}\sqrt{p_{ ij}}\) and \(\nu:=3\left(\sigma_{1}^{2}+3\sum_{i=1}^{n}L_{i}^{2}\left(1+\varepsilon_{i}^{2} \max_{j\in[n]}p_{ij}\right)\right)\). Suppose that Assumptions 2.1-2.5 and 4.1 hold and \(\widetilde{\mu}>0\). By Algorithm 1, if the stepsize satisfies \(\sup_{t\in[T]}\gamma_{t}\leq\frac{\widetilde{\mu}}{\nu}\), then, the performative regret of the game (1) is bounded by_

\[\mathcal{R}_{i}(T)\leq\mathcal{O}\left(\sqrt{\frac{T}{\widetilde{\mu}}\left( \frac{1}{\gamma_{T}}+\sum_{t=1}^{T}\gamma_{t}\right)}\right),\forall i\in[n].\]

_Further, the constraint violation is bounded by_

\[\mathcal{R}_{g}(T)\leq\mathcal{O}\left(\frac{1}{\gamma_{T}}\sqrt{\left(\frac{1 }{\gamma_{T}}+\sum_{t=1}^{T}\gamma_{t}\right)\left(1+\sum_{t=1}^{T}\gamma_{t}^ {2}\right)}\right).\]

For a sequence of diminishing stepsize \(\gamma_{t}=\tau_{1}^{\eta}(\tau_{2}t+\tau_{1})^{-\eta}\), where \(\tau_{1},\tau_{2}>0\) and \(0<\eta<1\), we have that: 1) \(\sum_{t=1}^{T}\gamma_{t}\leq\mathcal{O}\left(T^{1-\eta}\right)\); 2) \(\sum_{t=1}^{T}\gamma^{2}(t)\leq\mathcal{O}\left(T^{1-2\eta}\right)\). Plugging the above results into Theorem 4.2 yields

\[\mathcal{R}_{i}(T)\leq\mathcal{O}\left(T^{\frac{1+\eta}{2}}+T^{1-\frac{\eta}{2 }}\right),i\in[n]\quad\text{and}\quad\mathcal{R}_{g}(T)\leq\mathcal{O}\left(T ^{\frac{1}{2}\eta}+T^{\frac{1+\eta}{2}}+T^{1-\frac{\eta}{2}}\right).\]

Based on the above two inequalities, the best choice of \(\eta\) is \(\frac{1}{2}\) such that \(\mathcal{R}_{i}(T)\leq\mathcal{O}(T^{\frac{3}{4}}),\forall i\in[n]\) and \(\mathcal{R}_{g}(T)\leq\mathcal{O}(T^{\frac{3}{4}})\). This convergence speed matches that of the decentralized noncooperative game without performativity (Lu et al., 2020).

The proof of Theorem 4.2 is provided in Appendix E. According to Theorem 4.2, the performative effect reduces the convergence rate by amplifying the coefficient \(\frac{1}{\widetilde{\mu}}\) in the regret bounds. Specifically, as the sensitivity parameters \(\varepsilon_{i}\) increase, the coefficient \(\widetilde{\mu}\) decreases, leading to a slower convergence rate of \(\mathcal{R}_{i}(T)\) for all \(i\in[n]\). This occurs because a larger \(\varepsilon_{i}\) indicates a stronger performative influence, which more significantly impacts the algorithm's convergence. Nevertheless, the performative effect does not degrade the convergence order of Algorithm 1 compared to the case without performativity (Lu et al., 2020).

## 5 Numerical Experiments

In this section, we evaluate the effectiveness of our algorithm and theoretical results by conducting numerical experiments on a networked Cournot game (Abolhassani et al., 2014), which is a foundational model in economic theory (Allaz and Vila, 1993) for analyzing oligopolistic competitions. Weconsider a networked Cournot game with five firms selling a single commodity across three markets. Each firm aims to maximize its profit by determining the quantities it serves in all markets. The total accommodated quantity in each market is limited by its market capacity. The simulation details and additional numerical results are presented in Appendix F.1. We also provide an additional experiment on a ride-share market in Appendix F.2.

Fig. 1 illustrates the convergence of the time-average regrets of five firms, denoted by \(\mathcal{R}_{i}(t)/t\), \(\forall i\in[5]\), and the convergence of the time-average constraint violations of three markets, denoted by \(\frac{1}{t}\sum_{t^{\prime}=1}^{t}\sum_{i=1}^{n}g_{ij}(\boldsymbol{\theta}_{i} ^{t^{\prime}})\), \(\forall j\in[3]\). The results demonstrate that both \(\mathcal{R}_{i}(t)/t\) and \(\frac{1}{t}\sum_{t^{\prime}=1}^{t}\sum_{i=1}^{n}g_{ij}(\boldsymbol{\theta}_{i} ^{t^{\prime}})\) approach zero as the iterations increase. This verifies the sublinear convergence of the regrets and constraint violations in Theorem 4.2.

Fig. 2 (a) compares the normalized distance between \(\boldsymbol{\theta}^{t}\), generated by Algorithm 1, and the NE point \(\boldsymbol{\theta}^{\mathrm{ne}}\), denoted as \(\|\boldsymbol{\theta}^{t}-\boldsymbol{\theta}^{\mathrm{ne}}\|_{2}/\|\boldsymbol {\theta}^{t}\|_{2}\). The NE point is computed based on perfect knowledge of \(\{\mathcal{D}_{i}\}_{i\in[n]}\). We consider three different performative strengths: \(\varepsilon=0.2\), \(0.4\), and \(0.6\). It is observed that \(\|\boldsymbol{\theta}^{t}-\boldsymbol{\theta}^{\mathrm{ne}}\|_{2}/\|\boldsymbol {\theta}^{t}\|_{2}\) stabilizes at values approximately equal to or smaller than \(10^{-1}\) with iterations, varifying the effectiveness of Algorithm 1. Additionally, a larger performative strength leads to a wider normalized distance between the convergent point of \(\boldsymbol{\theta}^{t}\) and \(\boldsymbol{\theta}^{\mathrm{ne}}\). In Fig. 2 (b), we compare the total revenues, denoted by \(-\sum_{i=1}^{5}\mathrm{PR}_{i}(\boldsymbol{\theta}^{t})\) under the same three \(\varepsilon\) settings. We consider two scenarios: 1) "\(\mathrm{pse}\)", where \(\boldsymbol{\theta}^{t}\) is generated by Algorithm 1; 2). "\(\mathrm{ne}\)", where \(\boldsymbol{\theta}^{t}\) is generated by performing the same procedures as Algorithm 1 but with perfect information on the distributions \(\{\mathcal{D}_{i}(\boldsymbol{\theta})\}_{i\in[n]}\). The result demonstrates the close performance of the "\(\mathrm{pse}\)" approach and the "\(\mathrm{ne}\)" approach. More numerical results can be found in Appendix F.

**Conclusions:** We have studied the performative phenomenon in a decentralized noncooperative game where selfish players seek to maximize their individual profits while adhering to coupled inequality constraints. We have derived sufficient conditions for the E&U of both PSE and NE and provided the first upper bound on the distance between these two equilibria. Furthermore, we have developed a decentralized stochastic primal-dual algorithm for efficiently computing of the PSE point. Theoretical analysis has demonstrated the same order of convergence speed of our algorithm as the case without performativity. Finally, numerical simulations have been provided to verify the effectiveness of our algorithm and theoretical results.

Figure 1: Convergence of time-average regrets and time-average constraint violations.

## References

* Abolhassani et al. (2014) Melika Abolhassani, Mohammad Hossein Bateni, MohammadTaghi Hajiaghayi, Hamid Mahini, and Anshul Sawant. 2014. Network cournot competition. In _International Conference on Web and Internet Economics_. Springer, 15-29.
* Allaz and Vila (1993) Blaise Allaz and Jean-Luc Vila. 1993. Cournot competition, forward markets and efficiency. _Journal of Economic theory_ 59, 1 (1993), 1-16.
* Bertsekas (2014) Dimitri P Bertsekas. 2014. _Constrained optimization and Lagrange multiplier methods_. Academic press.
* Boyd and Vandenberghe (2004) Stephen P Boyd and Lieven Vandenberghe. 2004. _Convex optimization_. Cambridge university press.
* Chan et al. (2020) Alex Chan, Ahmed Alaa, Zhaozhi Qian, and Mihaela Van Der Schaar. 2020. Unlabelled data improves bayesian uncertainty calibration under covariate shift. In _International conference on machine learning_. PMLR, 1392-1402.
* Cust and Poelhekke (2015) James Cust and Steven Poelhekke. 2015. The local economic impacts of natural resource extraction. _Annu. Rev. Resour. Econ._ 7, 1 (2015), 251-268.
* Dean et al. (2023) Sarah Dean, Mihaela Curmei, Lillian J. Ratliff, Jamie Morgenstern, and Maryam Fazel. 2023. Emergent segmentation from participation dynamics and multi-learner retraining. _arXiv preprint arXiv:2206.02667_ (2023).
* Dong et al. (2018) Jinshuo Dong, Aaron Roth, Zachary Schutzman, Bo Waggoner, and Zhiwei Steven Wu. 2018. Strategic classification from revealed preferences. In _Proceedings of the 2018 ACM Conference on Economics and Computation_. 55-70.
* Drusvyatskiy and Xiao (2023) Dmitriy Drusvyatskiy and Lin Xiao. 2023. Stochastic optimization with decision-dependent distributions. _Mathematics of Operations Research_ 48, 2 (2023), 954-998.
* Naqa and Murphy (2015) Issam El Naqa and Martin J Murphy. 2015. _What is machine learning?_ Springer.
* Facchinei and Pang (2003) Francisco Facchinei and Jong-Shi Pang. 2003. _Finite-dimensional variational inequalities and complementarity problems_. Springer.
* Facchinei and Pang (2010) Francisco Facchinei and Jong-Shi Pang. 2010. Nash equilibria: the variational approach. _Convex optimization in signal processing and communications_ (2010), 443.
* Fattouh and Mahadeva (2014) Bassam Fattouh and Lavan Mahadeva. 2014. Causes and implications of shifts in financial participation in commodity markets. _Journal of Futures Markets_ 34, 8 (2014), 757-787.
* Hong et al. (2006) Yiguang Hong, Jiangping Hu, and Linxin Gao. 2006. Tracking control for multi-agent consensus with an active leader and variable topology. _Automatica_ 42, 7 (2006), 1177-1182.
* Horn and Johnson (2012) Roger A Horn and Charles R Johnson. 2012. _Matrix analysis_. Cambridge university press.
* Izzo et al. (2021) Zachary Izzo, Lexing Ying, and James Zou. 2021. How to learn when data reacts to your model: performative gradient descent. In _International Conference on Machine Learning_. PMLR, 4641-4650.
* Jagadeesan et al. (2022) Meena Jagadeesan, Tijana Zrnic, and Celestine Mendler-Dunner. 2022. Regret minimization with performative feedback. In _International Conference on Machine Learning_. PMLR, 9760-9785.
* Li et al. (2022) Qiang Li, Chung-Yiu Yau, and Hoi-To Wai. 2022. Multi-agent performative prediction with greedy deployment and consensus seeking agents. _Advances in Neural Information Processing Systems_ 35 (2022), 38449-38460.
* Lu et al. (2018) Jie Lu, Anjin Liu, Fan Dong, Feng Gu, Joao Gama, and Guangquan Zhang. 2018. Learning under concept drift: A review. _IEEE transactions on knowledge and data engineering_ 31, 12 (2018), 2346-2363.
* Lu et al. (2020) Kaihong Lu, Guangqi Li, and Long Wang. 2020. Online distributed algorithms for seeking generalized Nash equilibria in dynamic environments. _IEEE Trans. Automat. Control_ 66, 5 (2020), 2289-2296.
* Lu (2023) Songtao Lu. 2023. Bilevel optimization with coupled decision-dependent distributions. In _International Conference on Machine Learning_. PMLR, 22758-22789.
* Mandal et al. (2023) Debmalya Mandal, Stelios Triantafyllou, and Goran Radanovic. 2023. Performative reinforcement learning. In _International Conference on Machine Learning_. PMLR, 23642-23680.
* Miller et al. (2021) John P Miller, Juan C Perdomo, and Tijana Zrnic. 2021. Outside the echo chamber: Optimizing the performative risk. In _International Conference on Machine Learning_. PMLR, 7710-7720.
* Miller et al. (2018)* Mori et al. (2015) Usue Mori, Alexander Mendiburu, Maite Alvarez, and Jose A Lozano. 2015. A review of travel time estimation and forecasting for advanced traveller information systems. _Transportmetrica A: Transport Science_ 11, 2 (2015), 119-157.
* Moshari et al. (2010) Amir Moshari, GR Yousefi, Akbar Ebrahimi, and Saeid Haghbin. 2010. Demand-side behavior in the smart grid environment. In _2010 IEEE PES Innovative Smart Grid Technologies Conference Europe (ISGT Europe)_. IEEE, 1-7.
* Narang et al. (2023) Adhyan Narang, Evan Faulkner, Dmitriy Drusvyatskiy, Maryam Fazel, and Lillian J Ratliff. 2023. Multiplayer performative prediction: Learning in decision-dependent games. _Journal of Machine Learning Research_ 24, 202 (2023), 1-56.
* Perdomo et al. (2020) Juan Perdomo, Tijana Zrnic, Celestine Mendler-Dunner, and Moritz Hardt. 2020. Performative prediction. In _Proceedings of the 37th International Conference on Machine Learning (ICML 2020)_. PMLR, 7599-7609.
* Piliouras and Yu (2023) Georgios Piliouras and Fang-Yi Yu. 2023. Multi-agent performative prediction: From global stability and optimality to chaos. In _Proceedings of the 24th ACM Conference on Economics and Computation_. 1047-1074.
* Quinonero-Candela et al. (2008) Joaquin Quinonero-Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil D Lawrence. 2008. _Dataset shift in machine learning_. Mit Press.
* Shan et al. (2023) Jia-Wei Shan, Peng Zhao, and Zhi-Hua Zhou. 2023. Beyond Performative Prediction: Open-environment Learning with Presence of Corruptions. In _International Conference on Artificial Intelligence and Statistics_. PMLR, 7981-7998.
* Varian (2009) Hal R Varian. 2009. Online ad auctions. _American Economic Review_ 99, 2 (2009), 430-434.
* Wang et al. (2023) Xiaolu Wang, Chung-Yiu Yau, and Hoi To Wai. 2023. Network effects in performative prediction games. In _International Conference on Machine Learning_. PMLR, 36514-36540.
* Wood et al. (2021) Killian Wood, Gianluca Bianchin, and Emiliano Dall'Anese. 2021. Online projected gradient descent for stochastic optimization with decision-dependent distributions. _IEEE Control Systems Letters_ 6 (2021), 1646-1651.
* Wu et al. (2021) Ruihan Wu, Chuan Guo, Yi Su, and Kilian Q Weinberger. 2021. Online adaptation to label distribution shift. _Advances in Neural Information Processing Systems_ 34 (2021), 11340-11351.
* Yan and Cao (2024a) Wenjing Yan and Xuanyu Cao. 2024a. Decentralized Multi-Task Online Convex Optimization Under Random Link Failures. _IEEE Transactions on Signal Processing_ (2024).
* Yan and Cao (2024b) Wenjing Yan and Xuanyu Cao. 2024b. Zero-regret performative prediction under inequality constraints. _Advances in Neural Information Processing Systems_ 36 (2024).
* Zhou (2022) Zhi-Hua Zhou. 2022. Open-environment machine learning. _National Science Review_ 9, 8 (2022), nwac123.

Related Work

In recent years, the exploration of distribution shifts in machine learning systems has been extended beyond traditional exogenous shifts (Quinonero-Candela et al., 2008), such as covariate (Chan et al., 2020), label (Wu et al., 2021), and concept (Lu et al., 2018) drifts, to include endogenous shifts resulting from strategic behaviors within the learning platforms themselves. Perdomo et al. (2020) introduced the framework of performative prediction, which captures the platform's strategic responses using decision-dependent distribution mappings. Following this seminal work, significant research effort has been dedicated to investigating the phenomenon of performativity in various scenarios. In particular, (Shan et al., 2023) studied the endogenous distribution change in open environments, where data are obtained from a corrupted decision-dependent distribution. They proposed an effective algorithm with theoretical guarantees by decoupling the two sources of effects. Lu (2023) investigated the presence of performativity in bilevel optimization. They first established sufficient conditions for the existence of performatively stable solutions and then developed a stochastic algorithm to find the PS point. In (Mandal et al., 2023), the authors examined the performative effect in a regularized reinforcement learning problem and showed that repeatedly optimizing this objective converges to a performatively stable policy under reasonable assumptions on the transition dynamics. It is demonstrated in (Drusvyatskiy and Xiao, 2023) that typical gradient-based stochastic algorithms can be applied to find performative stable equilibria with a biased gradient oracle.

While most existing work focused on finding performative stable points, there are studies aimed at identifying the optimal solutions for performative prediction problems (Miller et al., 2021; Izzo et al., 2021; Jagadeesan et al., 2022). The optimality gap of performative stable points was first presented in (Perdomo et al., 2020), where their bound is proportional to the strong convexity parameter and inversely proportional to the smoothness parameter of cost functions and the sensitivity parameter of the decision-dependent distributions. The primary challenges in computing optimal points in performative prediction problems lie in the unknown decision-dependent data distributions. To address this challenge, a commonly used method is to make parametric assumptions on the data distributions and then design algorithms to estimate them. For instance, (Miller et al., 2021) proposed a two-stage algorithm to find the performative optima for distribution maps in the location family. Izzo et al. (2021) proposed a PerfGD algorithm by exploiting the exponential structure of the underlying distribution maps.

Among the numerous existing studies, (Narang et al., 2023) and (Wang et al., 2023) are, at a conceptual level, the closest papers to our own since they have considered performative behaviors in games. On a technical level, however, these two works are quite distinct from ours since we study completely different problem settings. One defining distinction is that, in our model, the collective strategies of all players must adhere to the learning system's constraints, whereas both (Narang et al., 2023) and (Wang et al., 2023) are unconstrained. Constraints are unavoidable in certain game scenarios, such as safety and cost constraints in transportation, relevance and diversity constraints in advertising, and risk tolerance and portfolio constraints in financial trading. The constrained problem in our work results in a fundamentally different algorithm design and convergence analysis from these two papers. Our work utilizes the primal-dual technique and necessitates consensus, whereas their approach only requires local stochastic gradient descent. Additionally, there are distinctions in the problem settings. In (Wang et al., 2023), the private cost function of each player is structured in a specific form, involving a local cost depending solely on its own strategy and a regularizer quantifying the similarity of strategies among neighbors. In contrast, we consider a mathematically richer setting where each player's private cost function depends on the strategies of all players in the game, thus encompassing the model in (Wang et al., 2023). Moreover, our algorithm design takes into account the practical implementation where players can only communicate with their neighbors, while (Narang et al., 2023) assumes that the strategies of all players are publicly accessible across the entire network. This more practical setting poses challenges for each player in observing the entire network. More importantly, although (Narang et al., 2023) and (Wang et al., 2023) demonstrated the existence and uniqueness of the PSE and NE for their respective game settings, neither of them offers insights into the distance between these two equilibria. This paper makes a significant contribution by presenting the first upper bound on this distance.

Furthermore, there are works on decentralized optimization of multiagent performative prediction (Li et al., 2022; Piliouras and Yu, 2023). Specifically, (Li et al., 2022) focused on decentralizedoptimization with consensus-seeking agents, where the data distribution of each agent depends only on its own decision. Although (Piliouras and Yu, 2023) considers multiagent, their study is in a centralized fashion and their data distributions are restricted to location-scale families. Lastly, it is worth mentioning that one paper (Yan and Cao, 2024b) has considered constrained optimization in the context of performative prediction. However, (Yan and Cao, 2024b) studied the single-agent case, while this work considers a more complex model with decentralized noncooperative players and partially observed information about competitors' strategies. Additionally, this paper contributes to the evaluation of equilibria, whereas such analysis has not been involved in (Yan and Cao, 2024b).

## Appendix B Existence and Uniqueness of Performative Stable Equilibrium

From the definition of the mapping \(\mathcal{T}(\bm{\theta})\), we have that

\[\bm{\theta}_{i}^{\prime}=\mathcal{T}_{i}(\bm{\theta})=\operatorname* {arg\,min}_{\bm{u}_{i}\in\bm{\Omega}_{i}}\quad\mathbb{E}_{\bm{\xi}_{i}\sim \mathcal{D}_{i}(\bm{\theta})}J_{i}\left(\bm{\xi}_{i};\bm{u}_{i},\bm{\theta}_{- i}^{\prime}\right)\quad\mathrm{s.t.}\quad\bm{g}_{i}(\bm{u}_{i})+\sum_{j\neq i}\bm{g}_{j} \left(\bm{\theta}_{j}^{\prime}\right)\leq\bm{0},\quad\forall i\in[n],\] \[\bm{\delta}_{i}^{\prime}=\mathcal{T}_{i}(\bm{\delta})=\operatorname* {arg\,min}_{\bm{u}_{i}\in\bm{\Omega}_{i}}\quad\mathbb{E}_{\bm{\xi}_{i}\sim \mathcal{D}_{i}(\bm{\delta})}J_{i}\left(\bm{\xi}_{i};\bm{u}_{i},\bm{\delta}_{- i}^{\prime}\right)\quad\mathrm{s.t.}\quad\bm{g}_{i}(\bm{u}_{i})+\sum_{j\neq i}\bm{g}_{j} \left(\bm{\delta}_{j}^{\prime}\right)\leq\bm{0},\quad\forall i\in[n].\]

Define \(\mathbb{E}_{\bm{\xi}_{j}\sim\mathcal{D}_{i}(\bm{\theta})}\nabla_{\bm{\theta}_{ j}}J_{i}\left(\bm{\xi}_{i};\bm{\theta}_{i}^{\prime},\bm{\theta}_{-i}^{\prime} \right):=G_{\bm{\theta}}^{(i)}(\bm{\theta}_{i}^{\prime},\bm{\theta}_{-i}^{ \prime})\). From the optimality condition of constrained optimization, we have

\[\left\langle G_{\bm{\theta}}^{(i)}\left(\bm{\theta}^{\prime}\right),\bm{ \theta}_{i}^{\prime}-\bm{\delta}_{i}^{\prime}\right\rangle\leq 0,\quad\forall i \in[n].\]

Define a vector \(G_{\bm{\theta}}(\bm{\theta}^{\prime}):=\operatorname{col}\left(G_{\bm{\theta}}^ {(1)}(\bm{\theta}^{\prime}),\cdots,G_{\bm{\theta}}^{(n)}(\bm{\theta}^{\prime})\right)\) that concatenates all the \(G_{\bm{\theta}}^{(i)}(\bm{\theta}^{\prime})\), \(i\in[n]\). Then, we have

\[\left\langle G_{\bm{\theta}}\left(\bm{\theta}^{\prime}\right),\bm{\theta}^{ \prime}-\bm{\delta}^{\prime}\right\rangle\leq 0.\] (A1)

Similarly, we have

\[\left\langle G_{\bm{\delta}}\left(\bm{\delta}^{\prime}\right),\bm{\theta}^{ \prime}-\bm{\delta}^{\prime}\right\rangle\geq 0.\] (A2)

Further, from the monotonicity of the gradient mapping \(\nabla J\left(\bm{\xi};\bm{\theta}\right)\) in Assumption 2.1, we have

\[\left\langle G_{\bm{\theta}}(\bm{\theta}^{\prime})-G_{\bm{\theta}}(\bm{\delta }^{\prime}),\bm{\theta}^{\prime}-\bm{\delta}^{\prime}\right\rangle=\mathbb{E}_ {\bm{\xi}\sim\mathcal{D}(\bm{\theta})}\left\langle\nabla J\left(\bm{\xi};\bm{ \theta}^{\prime}\right)-\nabla J\left(\bm{\xi};\bm{\delta}^{\prime}\right),\bm {\theta}^{\prime}-\bm{\delta}^{\prime}\right\rangle\geq\mu\|\bm{\theta}^{ \prime}-\bm{\delta}^{\prime}\|_{2}^{2},\] (A3)

where \(\mathcal{D}(\bm{\theta}):=\mathcal{D}_{1}(\bm{\theta})\times\cdots\times \mathcal{D}_{n}(\bm{\theta})\). Plugging (A1) and (A2) into (A3) gives

\[\mu\|\bm{\theta}^{\prime}-\bm{\delta}^{\prime}\|_{2}^{2} \leq\left\langle-G_{\bm{\theta}}\left(\bm{\delta}^{\prime} \right),\bm{\theta}^{\prime}-\bm{\delta}^{\prime}\right\rangle\] \[\leq\left\langle G_{\bm{\delta}}\left(\bm{\delta}^{\prime} \right)-G_{\bm{\theta}}\left(\bm{\delta}^{\prime}\right),\bm{\theta}^{\prime}- \bm{\delta}^{\prime}\right\rangle\] \[\leq\left\|G_{\bm{\delta}}\left(\bm{\delta}^{\prime}\right)-G_{ \bm{\theta}}\left(\bm{\delta}^{\prime}\right)\right\|_{2}\left\|\bm{\theta}^{ \prime}-\bm{\delta}^{\prime}\right\|_{2}.\] (A4)

From Assumption 2.2, \(\mathcal{W}_{1}\left(\mathcal{D}_{i}\left(\bm{\theta}\right),\mathcal{D}_{i} \left(\bm{\theta}^{\prime}\right)\right)\leq\varepsilon_{i}\sqrt{\sum_{j=1}^{ n}p_{ij}\left\|\bm{\theta}_{j}-\bm{\theta}_{j}^{\prime}\right\|_{2}^{2}}\). Along with Assumption 2.4, we have that

\[\left\|G_{\bm{\delta}}\left(\bm{\delta}^{\prime}\right)-G_{\bm{ \theta}}\left(\bm{\delta}^{\prime}\right)\right\|_{2}^{2} \leq\sum_{i=1}^{n}\sum_{j=1}^{n}L_{i}^{2}\varepsilon_{i}^{2}p_{ij} \left\|\bm{\delta}_{j}-\bm{\theta}_{j}\right\|_{2}^{2}\] \[\leq\sum_{i=1}^{n}L_{i}^{2}\varepsilon_{i}^{2}\max_{j\in[n]}p_{ij} \left\|\bm{\delta}-\bm{\theta}\right\|_{2}^{2}.\]

Plugging the above result into (A4) yields

\[\|\bm{\theta}^{\prime}-\bm{\delta}^{\prime}\|_{2}\leq\frac{1}{\mu}\sqrt{\sum_{i=1 }^{n}L_{i}^{2}\varepsilon_{i}^{2}\max_{j\in[n]}p_{ij}}\left\|\bm{\delta}-\bm{ \theta}\right\|_{2}.\]From the RRM procedure, we know that \(\bm{\theta}^{t+1}=\mathcal{T}(\bm{\theta}^{t})\) and the PSE satisfies \(\bm{\theta}^{\rm{pse}}=\mathcal{T}(\bm{\theta}^{\rm{pse}})\). Then, we have

\[\left\|\bm{\theta}^{t+1}-\bm{\theta}^{\rm{pse}}\right\|_{2} \leq\frac{1}{\mu}\sqrt{\sum_{i=1}^{n}L_{i}^{2}\varepsilon_{i}^{2} \max_{j\in[n]}p_{ij}}\left\|\bm{\theta}^{t}-\bm{\theta}^{\rm{pse}}\right\|_{2}\] \[\leq\left(\frac{1}{\mu}\sqrt{\sum_{i=1}^{n}L_{i}^{2}\varepsilon_{ i}^{2}\max_{j\in[n]}p_{ij}}\right)^{t}\left\|\bm{\theta}^{1}-\bm{\theta}^{ \rm{pse}}\right\|_{2}.\]

Further, if for any player \(i\), its distribution \(\mathcal{D}_{i}\) depends only on its own decision \(\bm{\theta}_{i}\), i.e., \(p_{ij}=0\) and \(p_{ii}=1\) for all \(i,j\in[n]\) and \(j\neq i\), then, we have

\[\left\|\left(G_{\bm{\delta}}\left(\bm{\delta}^{\prime}\right)-G_{\bm{\theta}} \left(\bm{\delta}^{\prime}\right)\right)\right\|_{2}\leq\sqrt{\sum_{i=1}^{n}L_ {i}^{2}\varepsilon_{i}^{2}\left\|\bm{\delta}_{i}-\bm{\theta}_{i}\right\|_{2}^ {2}}\leq\max_{i\in[n]}L_{i}\varepsilon_{i}\left\|\bm{\delta}-\bm{\theta}\right\| _{2}.\] (A5)

Plugging (A5) into (A4) yields

\[\left\|\bm{\theta}^{\prime}-\bm{\delta}^{\prime}\right\|_{2}\leq \frac{1}{\mu}\max_{i\in[n]}L_{i}\varepsilon_{i}\left\|\bm{\delta}-\bm{\theta} \right\|_{2}.\]

Correspondingly, we have

\[\left\|\bm{\theta}^{t+1}-\bm{\theta}^{\rm{pse}}\right\|_{2}\leq \left(\frac{1}{\mu}\max_{i\in[n]}L_{i}\varepsilon_{i}\right)^{t}\left\|\bm{ \theta}^{1}-\bm{\theta}^{\rm{pse}}\right\|_{2}.\]

## Appendix C Existence and Uniqueness of Nash Equilibrium

Based on the results in Facchinei and Pang (2003, Theorem 2.3.3(b)), to show the existence and uniqueness of NE, we need to prove that the gradient mapping \(\nabla{\rm{PR}}(\bm{\theta})\) of the performative game (1) is strongly monotone, i.e., there exists a \(\alpha>0\) such that \(\left\langle\nabla{\rm{PR}}(\bm{\theta})-\nabla{\rm{PR}}(\bm{\theta}),\bm{ \theta}-\bm{\delta}\right\rangle\geq\alpha\left\|\bm{\theta}-\bm{\delta}\right\| _{2}^{2}\), where \(\alpha\) denotes the strongly-monotone parameter. Since \(\nabla{\rm{PR}}(\bm{\theta})=G_{\bm{\theta}}(\bm{\theta})+H_{\bm{\theta}}(\bm{ \theta})\), we have

\[\left\langle\nabla{\rm{PR}}(\bm{\theta})-\nabla{\rm{PR}}(\bm{\delta}),\bm{ \theta}-\bm{\delta}\right\rangle=\left\langle G_{\bm{\theta}}(\bm{\theta})-G_ {\bm{\delta}}(\bm{\delta}),\bm{\theta}-\bm{\delta}\right\rangle+\left\langle H _{\bm{\theta}}(\bm{\theta})-H_{\bm{\delta}}(\bm{\delta}),\bm{\theta}-\bm{ \delta}\right\rangle.\]

From Assumption 2.2, we have

\[\left\langle G_{\bm{\theta}}(\bm{\theta})-G_{\bm{\delta}}(\bm{\theta}),\bm{ \theta}-\bm{\delta}\right\rangle\geq-\sum_{i=1}^{n}L_{i}\varepsilon_{i}\max_ {j\in[n]}\sqrt{p_{ij}}\left\|\bm{\theta}-\bm{\delta}\right\|_{2}^{2}.\]

Moreover, from the monotonicity of the gradient mapping \(\nabla J\left(\bm{\xi};\bm{\theta}\right)\) in Assumption 2.1, we have

\[\left\langle G_{\bm{\delta}}(\bm{\theta})-G_{\bm{\delta}}(\bm{\delta}),\bm{ \theta}-\bm{\delta}\right\rangle=\mathbb{E}_{\bm{\xi}\sim\mathcal{D}(\bm{ \delta})}\left\langle\nabla J(\bm{\xi};\bm{\theta})-\nabla J(\bm{\xi};\bm{ \delta}),\bm{\theta}-\bm{\delta}\right\rangle\geq\mu\left\|\bm{\theta}-\bm{ \delta}\right\|_{2}^{2}.\]

Combining the above two inequalities yields

\[\left\langle G_{\bm{\theta}}(\bm{\theta})-G_{\bm{\delta}}(\bm{ \delta}),\bm{\theta}-\bm{\delta}\right\rangle =\left\langle G_{\bm{\theta}}(\bm{\theta})-G_{\bm{\delta}}(\bm{ \theta}),\bm{\theta}-\bm{\delta}\right\rangle+\left\langle G_{\bm{\delta}}( \bm{\theta})-G_{\bm{\delta}}(\bm{\delta}),\bm{\theta}-\bm{\delta}\right\rangle\] \[\geq\left(\mu-\sum_{i=1}^{n}L_{i}\varepsilon_{i}\max_{j\in[n]} \sqrt{p_{ij}}\right)\left\|\bm{\theta}-\bm{\delta}\right\|_{2}^{2}.\] (A6)

Further, let \(\gamma(s)=\bm{\theta}^{\prime}+s\left(\bm{\theta}-\bm{\theta}^{\prime}\right)\) for \(s\in(0,1)\). Then, we have

\[J_{i}\left(\bm{\xi}_{i};\bm{\theta}\right)-J_{i}\left(\bm{\xi}_{ i};\bm{\theta}^{\prime}\right) =\int_{0}^{1}\left\langle\nabla J_{i}\left(\bm{\xi}_{i};\bm{\theta}^{ \prime}+s\left(\bm{\theta}-\bm{\theta}^{\prime}\right)\right),\bm{\theta}-\bm{ \theta}^{\prime}\right\rangle{\rm{d}}s\] \[=\int_{0}^{1}\left\langle\nabla J_{i}\left(\bm{\xi}_{i};\gamma(s) \right),\bm{\theta}-\bm{\theta}^{\prime}\right\rangle{\rm{d}}s.\] (A7)From the definition of \(H_{\bm{\theta}}^{(i)}(\bm{\delta})\) that \(H_{\bm{\theta}}^{(i)}(\bm{\delta}):=\left.\nabla_{\bm{u}_{i}}\mathbb{E}_{\bm{ \xi}_{i}\sim\mathcal{D}_{i}\left(\bm{u}_{i},\bm{\theta}_{-i}\right)}\left[J_{i} \left(\bm{\xi}_{i};\bm{\delta}\right)\right]\right|_{\bm{u}_{i}=\bm{\theta}_{i}}\), we have that

\[H_{\bm{\theta}}^{(i)}(\bm{\theta})-H_{\bm{\theta}}^{(i)}(\bm{ \theta}^{\prime}) =\left.\nabla_{\bm{u}_{i}}\mathbb{E}_{\bm{\xi}_{i}\sim\mathcal{D}_ {i}\left(\bm{u}_{i},\bm{\theta}_{-i}\right)}\left[\int_{0}^{1}\left\langle \nabla J_{i}\left(\bm{\xi}_{i};\gamma(s)\right),\bm{\theta}-\bm{\theta}^{\prime }\right\rangle\mathrm{d}s\right]\right|_{\bm{u}_{i}=\bm{\theta}_{i}}\] \[=\left.\int_{0}^{1}\nabla_{\bm{u}_{i}}\mathbb{E}_{\bm{\xi}_{i} \sim\mathcal{D}_{i}\left(\bm{u}_{i},\bm{\theta}_{-i}\right)}\left\langle \nabla J_{i}\left(\bm{\xi}_{i};\gamma(s)\right),\bm{\theta}-\bm{\theta}^{\prime }\right\rangle\right|_{\bm{u}_{i}=\bm{\theta}_{i}}\mathrm{d}s.\] (A8)

From Assumption 2.4, we have

\[\left\|\mathbb{E}_{\bm{\xi}_{i}\sim\mathcal{D}_{i}}\nabla J_{i} \left(\bm{\xi}_{i};\bm{\theta}\right)-\mathbb{E}_{\bm{\xi}_{i}^{\prime}\sim \mathcal{D}_{i}^{\prime}}\nabla J_{i}\left(\bm{\xi}_{i}^{\prime};\bm{\theta} \right)\right\|_{2}\leq L_{i}\mathcal{W}_{1}(\mathcal{D}_{i},\mathcal{D}_{i}^ {\prime}).\]

Along with Assumption 2.2, we know that the function \(\mathbb{E}_{\bm{\xi}_{i}\sim\mathcal{D}_{i}\left(\bm{\theta}_{i},\bm{\theta}_ {-i}\right)}\nabla J_{i}\left(\bm{\xi}_{i};\bm{\theta}^{\prime}\right)\) is \(L_{i}\varepsilon_{i}p_{ii}\)-Lipschitz continuous w.r.t \(\bm{\theta}_{i}\), and thus its gradient satisfies

\[\left\|\nabla_{\bm{u}_{i}}\mathbb{E}_{\bm{\xi}_{i}\sim\mathcal{D}_{i}\left( \bm{u}_{i},\bm{\theta}_{-i}\right)}\left[\nabla J_{i}\left(\bm{\xi}_{i};\gamma (s)\right)\right]\right|_{\bm{u}_{i}=\bm{\theta}_{i}}\Big{\|}_{2}\leq L_{i} \varepsilon_{i}p_{ii}.\] (A9)

Combing (A8) and (A9) gives

\[\left\|H_{\bm{\theta}}^{(i)}(\bm{\theta})-H_{\bm{\theta}}^{(i)}( \bm{\theta}^{\prime})\right\|_{2} \leq\int_{0}^{1}\left\|\nabla_{\bm{u}_{i}}\mathbb{E}_{\bm{\xi}_{i }\sim\mathcal{D}_{i}\left(\bm{u}_{i},\bm{\theta}_{-i}\right)}\left[\nabla J_{ i}\left(\bm{\xi}_{i};\gamma(s)\right)\right]\right|_{\bm{u}_{i}=\bm{\theta}_{i}} \left\|\bm{\theta}-\bm{\theta}^{\prime}\right\|_{2}\mathrm{d}s\] \[\leq L_{i}\varepsilon_{i}p_{ii}\left\|\bm{\theta}-\bm{\theta}^{ \prime}\right\|_{2},\]

where the first inequality holds due to the Cauchy-Schwartz inequality. This further implies that

\[\left\|H_{\bm{\theta}}(\bm{\theta})-H_{\bm{\theta}}(\bm{\theta}^ {\prime})\right\|_{2} =\sqrt{\sum_{i=1}^{n}\left\|H_{\bm{\theta}}^{(i)}(\bm{\theta})-H_ {\bm{\theta}}^{(i)}(\bm{\theta}^{\prime})\right\|_{2}^{2}}\] \[\leq\sqrt{\sum_{i=1}^{n}L_{i}^{2}\varepsilon_{i}^{2}p_{ii}}\left\| \bm{\theta}-\bm{\theta}^{\prime}\right\|_{2}.\]

Following prior work (Narang et al., 2023) and (Wang et al., 2023) on performative games, we assume that the mapping \(H_{\bm{\delta}}(\bm{\theta})\) is monotone w.r.t \(\bm{\delta}\), i.e., \(\left\langle H_{\bm{\theta}}(\bm{\theta})-H_{\bm{\delta}}(\bm{\theta}),\bm{ \theta}-\bm{\delta}\right\rangle\geq 0\). Then, we have that

\[\left\langle\nabla\mathrm{PR}(\bm{\theta})-\nabla\mathrm{PR}(\bm{ \delta}),\bm{\theta}-\bm{\delta}\right\rangle =\left\langle G_{\bm{\theta}}(\bm{\theta})-G_{\bm{\delta}}(\bm{ \delta}),\bm{\theta}-\bm{\delta}\right\rangle+\left\langle H_{\bm{\theta}}( \bm{\theta})-H_{\bm{\delta}}(\bm{\delta}),\bm{\theta}-\bm{\delta}\right\rangle\] \[=\left\langle G_{\bm{\theta}}(\bm{\theta})-G_{\bm{\delta}}(\bm{ \theta}),\bm{\theta}-\bm{\delta}\right\rangle+\left\langle H_{\bm{\theta}}(\bm{ \theta})-H_{\bm{\delta}}(\bm{\theta}),\bm{\theta}-\bm{\delta}\right\rangle\] \[\geq\left(\mu-\sum_{i=1}^{n}L_{i}\varepsilon_{i}\max_{j\in[n]} \sqrt{p_{ij}}-\sqrt{\sum_{i=1}^{n}L_{i}^{2}\varepsilon_{i}^{2}p_{ii}}\right) \left\|\bm{\theta}-\bm{\delta}\right\|_{2}^{2}.\]

Based on the classical result that a strongly monotone game over a non-empty, closed, and convex set admits a unique NE Facchinei and Pang (2003, Theorem 2.3.3(b)), we have the \(\mathrm{E}\&\mathrm{U}\) condition for the NE of the game (1) as given in theorem 3.4.

## Appendix D Distance Between PSE and NE

The computation on the distance between the PSE and NE of the game (1) is based on the strong duality (Boyd and Vandenberghe, 2004; Facchinei and Pang, 2010). Recall the definitions in Section 4.1 that

\[\mathcal{L}_{\bm{\delta}}^{(i)}(\bm{\theta}_{i},\bm{\theta}_{-i},\bm{\lambda}):= \mathbb{E}_{\bm{\xi}_{i}\sim\mathcal{D}_{i}\left(\bm{\delta}\right)}J_{i}\left( \bm{\xi}_{i};\bm{\theta}_{i},\bm{\theta}_{-i}\right)+\left\langle\bm{\lambda}, \bm{g}_{i}(\bm{\theta}_{i})+\sum_{j\neq i}\bm{g}_{j}\left(\bm{\theta}_{j} \right)\right\rangle.\]

Moreover, define a gradient mapping \(\phi_{i}(\bm{\xi}_{i};\bm{\theta},\bm{\lambda}):=\nabla_{\bm{\theta}_{i}}J_{i} \left(\bm{\xi}_{i};\bm{\theta}\right)+\nabla_{\bm{g}_{i}}(\bm{\theta}_{i})^{\top} \bm{\lambda}\) and a concatenation vector \(\bm{\phi}:=[\phi_{1},\cdots,\phi_{n}]^{\top}\). For any \(i\in[n]\), since \((\bm{\theta}_{i}^{\mathrm{pres}},\bm{\lambda}^{\mathrm{pres}})\) is a saddle point of the Lagrangian \(\mathcal{L}_{\bm{\theta}^{\mathrm{pres}}}^{(i)}(\bm{\theta}_{i},\bm{\theta}_{-i} ^{\mathrm{pres}},\bm{\lambda})\) under \(\bm{\xi}_{i}\sim\mathcal{D}_{i}(\bm{\theta}^{\mathrm{pres}})\), we have that

\[\mathcal{L}_{\bm{\theta}^{\mathrm{pres}}}^{(i)}\left(\bm{\theta}_{i}^{\mathrm{pres }},\bm{\theta}_{-i}^{\mathrm{pres}},\bm{\lambda}\right)\leq\mathcal{L}_{\bm{ \theta}^{\mathrm{pres}}}^{(i)}\left(\bm{\theta}_{i}^{\mathrm{pres}},\bm{ \theta}_{-i}^{\mathrm{pres}},\bm{\lambda}^{\mathrm{pres}}\right)\leq\mathcal{L}_{ \bm{\theta}^{\mathrm{pres}}}^{(i)}\left(\bm{\theta}_{i},\bm{\theta}_{-i}^{ \mathrm{pres}},\bm{\lambda}^{\mathrm{pres}}\right)\quad\forall\bm{\theta}_{i} \in\bm{\Omega}_{i},\bm{\lambda}\in\mathbb{R}_{+}^{m}.\]Similarly, for any \(i\in[n]\), \((\bm{\theta}_{i}^{\mathrm{ne}},\bm{\lambda}^{\mathrm{ne}})\) the saddle point of the regularized Lagrangian \(\mathcal{L}_{\bm{\theta}_{i},\bm{\theta}_{-i}^{\mathrm{ne}}}^{(i)}(\bm{\theta}_ {i},\bm{\theta}_{-i}^{\mathrm{ne}},\bm{\lambda})\) with decision-dependent distribution \(\bm{\xi}_{i}\sim\mathcal{D}_{i}(\bm{\theta}_{i},\bm{\theta}_{-i}^{\mathrm{ne}})\). Setting \(\bm{\lambda}=\bm{\lambda}^{\mathrm{ne}}\) in the first part of the proceeding inequality, we obtain

\[\bm{0}\leq\mathcal{L}_{\bm{\theta}^{\mathrm{ne}}}^{(i)}\left(\bm{\theta}_{i}^ {\mathrm{ne}},\bm{\theta}_{-i}^{\mathrm{ne}},\bm{\lambda}^{\mathrm{pse}}\right) -\mathcal{L}_{\bm{\theta}^{\mathrm{ne}}}^{(i)}\left(\bm{\theta}_{i}^{\mathrm{ pse}},\bm{\theta}_{-i}^{\mathrm{ne}},\bm{\lambda}^{\mathrm{ne}}\right)=\left(\bm{ \lambda}^{\mathrm{pse}}-\bm{\lambda}^{\mathrm{ne}}\right)^{\top}\bm{g}\left( \bm{\theta}^{\mathrm{pse}}\right),\forall i\in[n],\]

where \(\left(\bm{\lambda}^{\mathrm{pse}}-\bm{\lambda}^{\mathrm{ne}}\right)^{\top}\bm{g }\left(\bm{\theta}^{\mathrm{pse}}\right)=\sum_{j=1}^{m}\left(\lambda_{j}^{ \mathrm{pse}}-\lambda_{j}^{\mathrm{ne}}\right)\left(\sum_{i=1}^{n}g_{ji}\left( \bm{\theta}_{i}^{\mathrm{pse}}\right)\right)\). By the convexity of \(g_{ji}(\cdot)\) for all \(j\in[m]\), \(i\in[n]\), we have that

\[\sum_{i=1}^{n}g_{ji}\left(\bm{\theta}_{i}^{\mathrm{pse}}\right) \leq\sum_{i=1}^{n}\left(g_{ji}\left(\bm{\theta}_{i}^{\mathrm{ne}} \right)+\left\langle\nabla g_{ji}\left(\bm{\theta}_{i}^{\mathrm{pse}}\right), \bm{\theta}_{i}^{\mathrm{pse}}-\bm{\theta}_{i}^{\mathrm{ne}}\right)\right)\] \[\leq\sum_{i=1}^{n}\left\langle\nabla g_{ji}\left(\bm{\theta}_{i}^ {\mathrm{pse}}\right),\bm{\theta}_{i}^{\mathrm{pse}}-\bm{\theta}_{i}^{\mathrm{ ne}}\right\rangle,\forall j\in[m],\]

where the last inequality follows from that \(g_{j}(\bm{\theta}^{\mathrm{ne}})=\sum_{i=1}^{n}g_{ji}\left(\bm{\theta}_{i}^{ \mathrm{ne}}\right)\leq 0\). Multiplying the preceding inequality with \(\lambda_{j}^{\mathrm{pse}}\) and adding over all \(j\in[m]\), we obtain

\[\sum_{j=1}^{m}\sum_{i=1}^{n}\lambda_{j}^{\mathrm{pse}}g_{ji}\left( \bm{\theta}_{i}^{\mathrm{pse}}\right)=\left(\bm{\lambda}^{\mathrm{pse}}\right)^ {\top}\bm{g}\left(\bm{\theta}^{\mathrm{pse}}\right) \leq\sum_{i=1}^{n}\left\langle\sum_{j=1}^{m}\lambda_{j}^{\mathrm{ pse}}\nabla g_{ji}\left(\bm{\theta}_{i}^{\mathrm{pse}}\right),\bm{\theta}_{i}^{ \mathrm{pse}}-\bm{\theta}_{i}^{\mathrm{ne}}\right\rangle\] \[=\sum_{i=1}^{n}\left\langle\nabla\bm{g}_{i}(\bm{\theta}_{i}^{ \mathrm{pse}})^{\top}\bm{\lambda}^{\mathrm{pse}},\bm{\theta}_{i}^{\mathrm{ pse}}-\bm{\theta}_{i}^{\mathrm{ne}}\right\rangle.\] (A10)

By the definition of the mapping \(\phi_{i}(\cdot)\), for any \(\bm{\xi}_{i}\in\bm{\Xi}_{i}\), we have that,

\[\nabla\bm{g}_{i}(\bm{\theta}_{i}^{\mathrm{pse}})^{\top}\bm{\lambda}^{\mathrm{ pse}}=\phi_{i}(\bm{\xi}_{i};\bm{\theta}^{\mathrm{pse}},\bm{\lambda}^{\mathrm{pse}})- \nabla_{\bm{\theta}_{i}}J_{i}\left(\bm{\xi}_{i};\bm{\theta}^{\mathrm{pse}}\right),\forall i\in[n].\] (A11)

Plugging (A11) into (A10) gives

\[\left(\bm{\lambda}^{\mathrm{pse}}\right)^{\top}\bm{g}\left(\bm{\theta}^{ \mathrm{pse}}\right)\leq\sum_{i=1}^{n}\left\langle\phi_{i}(\bm{\xi}_{i};\bm{ \theta}^{\mathrm{pse}},\bm{\lambda}^{\mathrm{pse}})-\nabla_{\bm{\theta}_{i}}J _{i}\left(\bm{\xi}_{i};\bm{\theta}^{\mathrm{pse}}\right),\bm{\theta}_{i}^{ \mathrm{pse}}-\bm{\theta}_{i}^{\mathrm{ne}}\right\rangle,\forall i\in[n].\] (A12)

Likewise, we have the following inequality based on the convexity of the functions \(\{g_{ji}(\cdot)\}\):

\[g_{ji}\left(\bm{\theta}_{i}^{\mathrm{pse}}\right)\geq g_{ji}\left(\bm{\theta}_{ i}^{\mathrm{ne}}\right)+\left\langle\nabla g_{ji}\left(\bm{\theta}_{i}^{ \mathrm{ne}}\right),\bm{\theta}_{i}^{\mathrm{pse}}-\bm{\theta}_{i}^{\mathrm{ ne}}\right\rangle,\forall j\in[m],i\in[n].\]

Multiplying the preceding inequality with \(-\lambda_{j}^{\mathrm{ne}}\) and summing over \(j\in[m]\), we obtain

\[-\sum_{j=1}^{m}\lambda_{i}^{\mathrm{ne}}\sum_{i=1}^{n}g_{ji}\left( \bm{\theta}_{i}^{\mathrm{pse}}\right) \leq-\sum_{j=1}^{m}\lambda_{j}^{\mathrm{ne}}\sum_{i=1}^{n}g_{ji} \left(\bm{\theta}_{i}^{\mathrm{ne}}\right)-\sum_{i=1}^{n}\left\langle\sum_{j=1}^ {m}\lambda_{j}^{\mathrm{ne}}\nabla g_{ji}\left(\bm{\theta}_{i}^{\mathrm{ne}} \right),\bm{\theta}_{i}^{\mathrm{pse}}-\bm{\theta}_{i}^{\mathrm{ne}}\right\rangle\] \[=\sum_{i=1}^{n}\left\langle\nabla\bm{g}_{i}\left(\bm{\theta}_{i}^{ \mathrm{ne}}\right)^{\top}\bm{\lambda}^{\mathrm{ne}},\bm{\theta}_{i}^{\mathrm{ ne}}-\bm{\theta}_{i}^{\mathrm{pse}}\right\rangle,\]

where the equality follows from that \(\sum_{j=1}^{m}\lambda_{j}^{\mathrm{ne}}\sum_{i=1}^{n}g_{ji}\left(\bm{\theta}_{i}^{ \mathrm{ne}}\right)=\left(\bm{\lambda}^{\mathrm{ne}}\right)^{\top}\bm{g}\left( \bm{\theta}^{\mathrm{ne}}\right)=0\), which holds by the complementary slackness condition of the Lagrangian \(\mathcal{L}_{\bm{\theta}_{i},\bm{\theta}_{-i}^{\mathrm{ne}}}^{(i)}(\bm{\theta}_{i}, \bm{\theta}_{-i}^{\mathrm{ne}},\bm{\lambda})\) for all \(i\in[n]\). Similar to (A12), we have

\[-\left(\bm{\lambda}^{\mathrm{ne}}\right)^{\top}\bm{g}\left(\bm{\theta}^{ \mathrm{pse}}\right)\leq\sum_{i=1}^{n}\left\langle\phi_{i}(\bm{\xi}_{i};\bm{ \theta}^{\mathrm{ne}},\bm{\lambda}^{\mathrm{ne}})-\nabla_{\bm{\theta}_{i}}J_{i} \left(\bm{\xi}_{i};\bm{\theta}^{\mathrm{pse}}\right),\bm{\theta}_{i}^{\mathrm{ ne}}-\bm{\theta}_{i}^{\mathrm{pse}}\right\rangle.\] (A13)

Combining (A12) and (A13) yields

\[\left(\bm{\lambda}^{\mathrm{pse}}-\bm{\lambda}^{\mathrm{ne}} \right)^{\top}\bm{g}\left(\bm{\theta}^{\mathrm{pse}}\right) \leq\sum_{i=1}^{n}\left\langle\phi_{i}(\bm{\xi}_{i};\bm{\theta}^{ \mathrm{pse}},\bm{\lambda}^{\mathrm{pse}})-\phi_{i}(\bm{\xi}_{i};\bm{\theta}^{ \mathrm{ne}},\bm{\lambda}^{\mathrm{ne}}),\bm{\theta}_{i}^{\mathrm{pse}}-\bm{ \theta}_{i}^{\mathrm{ne}}\right\rangle\] \[\Taking expectation on both sides of the above inequality over the distribution \(\mathcal{D}_{i}(\bm{\theta}^{\mathrm{pse}})\) for all \(i\in[n]\) gives

\[\left(\bm{\lambda}^{\mathrm{pse}}-\bm{\lambda}^{\mathrm{ne}}\right) ^{\top}\bm{g}\left(\bm{\theta}^{\mathrm{pse}}\right) \leq\sum_{i=1}^{n}\mathbb{E}_{\bm{\xi}_{i}\sim\mathcal{D}_{i}( \bm{\theta}^{\mathrm{pse}})}\left\langle\phi_{i}(\bm{\xi}_{i};\bm{\theta}^{ \mathrm{pse}},\bm{\lambda}^{\mathrm{pse}})-\phi_{i}(\bm{\xi}_{i};\bm{\theta}^{ \mathrm{nse}},\bm{\lambda}^{\mathrm{ne}}),\bm{\theta}_{i}^{\mathrm{pse}}-\bm{ \theta}_{i}^{\mathrm{ne}}\right\rangle\] \[\quad-\sum_{i=1}^{n}\left\langle G_{\bm{\theta}^{\mathrm{pse}}}^{ \left(i\right)}\left(\bm{\theta}^{\mathrm{pse}}\right)-G_{\bm{\theta}^{ \mathrm{pse}}}^{\left(i\right)}\left(\bm{\theta}^{\mathrm{ne}}\right),\bm{ \theta}_{i}^{\mathrm{pse}}-\bm{\theta}_{i}^{\mathrm{ne}}\right\rangle.\] (A14)

Since \((\bm{\theta}_{i}^{\mathrm{pse}},\bm{\lambda}^{\mathrm{pse}})\) is a saddle point of the Lagrangian \(\mathcal{L}_{\bm{\theta}^{\mathrm{pse}}}^{\left(i\right)}(\bm{\theta}^{ \mathrm{pse}},\bm{\lambda}^{\mathrm{pse}})\) given \(\bm{\xi}_{i}\sim\mathcal{D}_{i}(\bm{\theta}^{\mathrm{pse}})\), we have that

\[\mathbb{E}_{\bm{\xi}_{i}\sim\mathcal{D}_{i}(\bm{\theta}^{\mathrm{pse}})} \left\langle\phi_{i}(\bm{\xi}_{i};\bm{\theta}^{\mathrm{pse}},\bm{\lambda}^{ \mathrm{pse}}),\bm{\theta}_{i}^{\mathrm{pse}}-\bm{\theta}_{i}^{\mathrm{ne}} \right\rangle\leq 0,\forall i\in[n].\] (A15)

Furthermore, for any \(i\in[n]\), we have

\[\mathbb{E}_{\bm{\xi}_{i}\sim\mathcal{D}_{i}(\bm{\theta}^{\mathrm{ pse}})}\phi_{i}(\bm{\xi}_{i};\bm{\theta}^{\mathrm{nse}},\bm{\lambda}^{\mathrm{ ne}}) =G_{\bm{\theta}^{\mathrm{pse}}}^{\left(i\right)}\left(\bm{\theta}^{ \mathrm{ne}}\right)+\nabla g_{i}(\bm{\theta}_{i}^{\mathrm{ne}})^{\top}\bm{ \lambda}^{\mathrm{ne}}\] \[\quad+\nabla_{\bm{\theta}_{i}}\mathrm{PR}_{i}(\bm{\theta}_{i}^{ \mathrm{ne}},\bm{\theta}_{-i}^{\mathrm{ne}})-\nabla_{\bm{\theta}_{i}}\mathrm{ PR}_{i}(\bm{\theta}_{i}^{\mathrm{ne}},\bm{\theta}_{-i}^{\mathrm{ne}}).\] (A16)

Since \((\bm{\theta}_{i}^{\mathrm{ne}},\bm{\lambda}^{\mathrm{ne}})\) is a saddle point of the Lagrangian \(\mathcal{L}_{\bm{\theta}_{i}^{\mathrm{ne}}}^{\left(i\right)}(\bm{\theta}_{i}, \bm{\theta}_{-i}^{\mathrm{ne}},\bm{\lambda}^{\mathrm{ne}})\) with decision-dependent distribution \(\mathcal{D}_{i}(\bm{\theta}_{i},\bm{\theta}_{-i}^{\mathrm{ne}})\), we have that

\[-\left\langle\nabla_{\bm{\theta}}\mathrm{PR}_{i}(\bm{\theta}_{i}^{\mathrm{ne} },\bm{\theta}_{-i}^{\mathrm{ne}})+\nabla g_{i}(\bm{\theta}_{i}^{\mathrm{ne}}) ^{\top}\bm{\lambda}^{\mathrm{ne}},\bm{\theta}_{i}^{\mathrm{pse}}-\bm{\theta}_{ i}^{\mathrm{ne}}\right\rangle\leq 0,\forall i\in[n].\] (A17)

Plugging (A15), (A16), and (A17) into (A14) yields

\[0 \leq(\bm{\lambda}^{\mathrm{pse}}-\bm{\lambda}^{\mathrm{ne}})^{ \top}\bm{g}\left(\bm{\theta}^{\mathrm{pse}}\right)\] \[\leq\sum_{i=1}^{n}\left\langle\nabla_{i}\mathrm{PR}_{i}(\bm{ \theta}_{i}^{\mathrm{ne}},\bm{\theta}_{-i}^{\mathrm{ne}})-G_{\bm{\theta}^{ \mathrm{pse}}}^{\left(i\right)}\left(\bm{\theta}^{\mathrm{ne}}\right),\bm{ \theta}_{i}^{\mathrm{pse}}-\bm{\theta}_{i}^{\mathrm{ne}}\right\rangle\] \[\quad-\sum_{i=1}^{n}\left\langle G_{\bm{\theta}^{\mathrm{pse}}}^{ \left(i\right)}\left(\bm{\theta}^{\mathrm{pse}}\right)-G_{\bm{\theta}^{ \mathrm{pse}}}^{\left(i\right)}\left(\bm{\theta}^{\mathrm{ne}}\right),\bm{ \theta}_{i}^{\mathrm{pse}}-\bm{\theta}_{i}^{\mathrm{ne}}\right\rangle\] \[=\sum_{i=1}^{n}\left\langle H_{\bm{\theta}^{\mathrm{pse}}}^{ \left(i\right)}(\bm{\theta}^{\mathrm{ne}})+G_{\bm{\theta}^{\mathrm{ne}}}^{ \left(i\right)}\left(\bm{\theta}^{\mathrm{ne}}\right)-G_{\bm{\theta}^{ \mathrm{pse}}}^{\left(i\right)}\left(\bm{\theta}^{\mathrm{pse}}\right),\bm{ \theta}_{i}^{\mathrm{pse}}-\bm{\theta}_{i}^{\mathrm{ne}}\right\rangle.\]

Then, we have

\[\left\langle G_{\bm{\theta}^{\mathrm{pse}}}\left(\bm{\theta}^{\mathrm{pse}} \right)-G_{\bm{\theta}^{\mathrm{ne}}}\left(\bm{\theta}^{\mathrm{ne}}\right),\bm{ \theta}^{\mathrm{pse}}-\bm{\theta}^{\mathrm{ne}}\right\rangle\leq\left\langle H _{\bm{\theta}^{\mathrm{ne}}}(\bm{\theta}^{\mathrm{ne}}),\bm{\theta}^{\mathrm{ pse}}-\bm{\theta}^{\mathrm{ne}}\right\rangle.\]

From the result in (A6) and the Cauchy-Schwarz inequality, we have

\[\left(\mu-\sum_{i=1}^{n}L_{i}\varepsilon_{i}\max_{j\in[n]}\sqrt{p_{ij}}\right) \|\bm{\theta}^{\mathrm{pse}}-\bm{\theta}^{\mathrm{ne}}\|_{2}^{2}\leq\|H_{\bm{ \theta}^{\mathrm{nse}}}(\bm{\theta}^{\mathrm{ne}})\|_{2}\|\bm{\theta}^{\mathrm{ pse}}-\bm{\theta}^{\mathrm{ne}}\|_{2}.\]

Since the cost function \(J_{i}(\cdot)\) is \(G_{i}\) Lipschitz for any \(i\in[n]\), along with Assumption 2.2, we have

\[\|H_{\bm{\theta}^{\mathrm{nse}}}(\bm{\theta}^{\mathrm{ne}})\|_{2}=\sqrt{\sum_{i=1} ^{n}\|H_{\bm{\theta}_{i}^{\mathrm{ne}},\bm{\theta}_{-i}^{\mathrm{ne}}}^{\left(i \right)}(\bm{\theta}_{i}^{\mathrm{ne}},\bm{\theta}_{-i}^{\mathrm{ne}})\|_{2}^{2}} \leq\sqrt{\sum_{i=1}^{n}G_{i}^{2}\varepsilon_{i}^{2}p_{ii}}.\]

Combining the above results yields

\[\|\bm{\theta}^{\mathrm{pse}}-\bm{\theta}^{\mathrm{ne}}\|_{2}\leq\frac{\sqrt{ \sum_{i=1}^{n}G_{i}^{2}\varepsilon_{i}^{2}p_{ii}}}{\mu-\sum_{i=1}^{n}L_{i} \varepsilon_{i}\max_{j\in[n]}\sqrt{p_{ij}}}.\]

Further, from Assumption 2.2, we have

\[|\mathrm{PR}_{i}(\bm{\theta}^{\mathrm{pse}})-\mathrm{PR}_{i}(\bm{ \theta}^{\mathrm{ne}})| \leq G_{i}\|\bm{\theta}^{\mathrm{pse}}-\bm{\theta}^{\mathrm{ne}}\|_{2}+G_{ i}\varepsilon_{i}\sqrt{\sum_{j=1}^{n}p_{ij}\left\|\bm{\theta}_{j}^{\mathrm{pse}}-\bm{ \theta}_{j}^{\mathrm{ne}}\right\|_{2}^{2}}\] \[\leq G_{i}\left(1+\varepsilon_{i}\max_{j\in[n]}\sqrt{p_{ij}} \right)\|\bm{\theta}^{\mathrm{pse}}-\bm{\theta}^{\mathrm{ne}}\|_{2}.\]Then, we have

\[|\mathrm{PR}(\bm{\theta}^{\mathrm{pse}})-\mathrm{PR}(\bm{\theta}^{ \mathrm{ne}})| =\sum_{i=1}^{n}|\mathrm{PR}_{i}(\bm{\theta}^{\mathrm{pse}})-\mathrm{ PR}_{i}(\bm{\theta}^{\mathrm{ne}})|\] \[\leq\left(\sum_{i=1}^{n}G_{i}\left(1+\varepsilon_{i}\max_{j\in[n] }\sqrt{p_{ij}}\right)\right)\frac{\sqrt{\sum_{i=1}^{n}G_{i}^{2}\varepsilon_{i}^ {2}p_{ii}}}{\mu-\sum_{i=1}^{n}L_{i}\varepsilon_{i}\max_{j\in[n]}\sqrt{p_{ij}}}.\]

## Appendix E Convergence of the Decentralized Stochastic Primal-Dual Algorithm

The proof of this section utilizes the following supporting lemmas.

**Lemma E.1**.: _Based on the update rule of the dual variable \(\bm{\lambda}\) in Algorithm 1, for any \(\gamma_{t}\geq 0\), \(\bm{\lambda}_{i}^{t}\in\mathbb{R}_{+}^{m}\), \(i\in[n]\), and \(t\in[T]\), we have that \(\sum_{i=1}^{n}\|\gamma_{t}\bm{\lambda}_{i}^{t}\|_{2}^{2}\leq nB^{2}\)._

**Lemma E.2**.: _Define \(\overline{\bm{\lambda}}^{t}:=\frac{1}{n}\sum_{i=1}^{n}\bm{\lambda}_{i}^{t}\) the average of the dual variable over all players at the \(t\)th iteration. Then, for any \(\gamma_{t}\geq 0\) and \(t\in[T]\), we have the following relationship:_

\[-\sum_{t=1}^{T}\sum_{i=1}^{n}\gamma_{t}(\bm{\lambda}_{i}^{t})^{ \top}\bm{g}_{i}(\bm{\theta}_{i}^{t})\leq -\sum_{t=1}^{T}\sum_{i=1}^{n}\gamma_{t}\bm{\lambda}^{\top}\bm{g}_{ i}\left(\bm{\theta}_{i}^{t}\right)+\frac{n}{2}\left(1+\sum_{t=1}^{T}\gamma_{t}^ {2}\right)\|\bm{\lambda}\|_{2}^{2}+\frac{9}{2}\sum_{t=1}^{T}\sum_{i=1}^{n}\left \|\bm{\lambda}_{i}^{t}-\overline{\bm{\lambda}}^{t}\right\|_{2}^{2}\] \[+2(1+\sqrt{n})B\sum_{t=1}^{T}\gamma_{t}\sum_{i=1}^{n}\left\|\bm{ \lambda}_{i}^{t}-\overline{\bm{\lambda}}^{t}\right\|_{2}+4nB^{2}\sum_{t=1}^{T} \gamma_{t}^{2}.\]

Moreover, we require the following Lemma on the weight matrix \(\bm{\mathrm{A}}\).

**Lemma E.3**.: _Let \(\sigma_{2}(\bm{\mathrm{A}})\) denote the second-largest eigenvalue of the weight matrix \(\bm{\mathrm{A}}\). Since \(\bm{\mathrm{A}}\) is assumed to be doubly stochastic, it holds that \(\sigma_{2}(\bm{\mathrm{A}})<1\)(Horn and Johnson, 2012). Furthermore, for any \(i\in[n]\), we construct a weight matrix \(\bm{\mathrm{A}}_{i}^{-}\) by removing the \(i\)th row and column of \(\bm{\mathrm{A}}\). Let \(\beta\) represent the maximum eigenvalue of \(\bm{\mathrm{A}}_{i}^{-}\) for all \(i\in[n]\). It has been established in Hong et al. (2006, Lemma 3) that \(\beta<1\)._

With Lemma E.3, we have the following results.

**Lemma E.4**.: _Define \(\bm{e}_{ih}^{t}:=\widehat{\bm{\theta}}_{ih}^{t}-\bm{\theta}_{h}^{t}\) the estimation error of player \(i\) on the decision of player \(h\) at the \(t\)th iteration, for all \(i,h\in[n]\) and \(t\in[T]\). Let \(\bm{e}_{h}^{t}\) denote the concatenation of \(\bm{e}_{ih}^{t}\) that \(\bm{e}_{h}^{t}:=\mathrm{col}\left(\bm{e}_{1h}^{t},\cdots,\bm{e}_{(h-1)h}^{t}, \bm{e}_{(h+1)h}^{t},\cdots,\bm{e}_{nh}^{t}\right)\). Then, the sum of \(\|\bm{e}_{h}^{t}\|_{2}\) over \(h\in[n]\) and \(t\in[T]\) satisfies_

\[\sum_{t=1}^{T}\sum_{h=1}^{n}\mathbb{E}\|\bm{e}_{h}^{t}\|_{2}\leq\frac{nC}{1- \beta}+\frac{n\sqrt{n-1}(G+\sqrt{n}BG_{g})}{1-\beta}\sum_{t=1}^{T}\gamma_{t}= \mathcal{O}\left(\sum_{t=1}^{T}\gamma_{t}\right).\]

_Moreover, the sum of \(\|\bm{e}_{ih}^{t}\|_{2}^{2}\) over \(h\in[n]\) and \(t\in[T]\) satisfies_

\[\sum_{t=1}^{T}\sum_{h=1}^{n}\mathbb{E}\|\bm{e}_{h}^{t}\|_{2}^{2}\leq\frac{2nC^ {2}}{1-\beta}+\frac{2n(n-1)(G+\sqrt{n}BG_{g})^{2}}{(1-\beta)^{2}}\sum_{t=1}^{T} \gamma_{t}=\mathcal{O}\left(\sum_{t=1}^{T}\gamma_{t}\right).\]

**Lemma E.5**.: _With the definition \(\overline{\bm{\lambda}}^{t}:=\frac{1}{n}\sum_{i=1}^{n}\bm{\lambda}_{i}^{t}\), we have the following relationship on the consensus error of the dual variable \(\bm{\lambda}_{i}^{t}\), given by \(\bm{\lambda}_{i}^{t}-\overline{\bm{\lambda}}^{t}\), for all \(i\in[n]\) and \(t\in[T]\):_

\[\sum_{t=1}^{T}\sum_{i=1}^{n}\left\|\bm{\lambda}_{i}^{t}-\overline {\bm{\lambda}}^{t}\right\|_{2}\leq\frac{2(n+\sqrt{n})B}{1-\sigma_{2}(\bm{ \mathrm{A}})}\sum_{t=1}^{T}\gamma_{t}=\mathcal{O}\left(\sum_{t=1}^{T}\gamma_{t} \right),\] \[\sum_{t=1}^{T}\sum_{i=1}^{n}\left\|\bm{\lambda}_{i}^{t}-\overline {\bm{\lambda}}^{t}\right\|_{2}^{2}\leq\frac{4(n+\sqrt{n})^{2}B^{2}}{(1-\sigma_{ 2}(\bm{\mathrm{A}}))^{2}}\sum_{t=1}^{T}\gamma_{t}=\mathcal{O}\left(\sum_{t=1}^{ T}\gamma_{t}\right).\]Next, we start the proof of Theorem 4.2. For ease of proposition, we define the following gradient mappings: for any \(t\in[T]\), \(\phi_{i}^{t}(\bm{\xi}_{i};\bm{\theta}_{i},\bm{\theta}_{-i},\bm{\lambda}):=\nabla_{ i}J_{i}\left(\bm{\xi}_{i};\bm{\theta}_{i},\bm{\theta}_{-i},\bm{\theta}\right)+ \gamma_{t}\nabla\bm{g}_{i}(\bm{\theta}_{i})^{\top}\bm{\lambda}\), \(\bm{\phi}^{t}(\cdot):=[\phi_{i}^{t}(\cdot),\cdots,\phi_{t}^{t}(\cdot)]^{\top}\), \(\Phi_{\bm{\delta}}^{i,t}(\bm{\theta},\bm{\lambda}):=G_{\bm{\delta}}^{(i)}\left( \bm{\theta}\right)+\gamma_{t}\nabla\bm{g}_{i}(\bm{\theta}_{i})^{\top}\bm{\lambda}\), and \(\Phi_{\bm{\delta}}^{t}(\bm{\theta},\bm{\lambda}):=\left[\Phi_{\bm{\delta}}^{1, t}(\bm{\theta},\bm{\lambda}),\cdots,\Phi_{\bm{\delta}}^{n,t}(\bm{\theta},\bm{ \lambda})\right]^{\top}\). Then, we have

\[\mathbb{E}\left\|\bm{\theta}^{t+1}-\bm{\theta}^{\text{pse}}\right\| _{2}^{2} =\sum_{i=1}^{n}\mathbb{E}\left\|P_{\bm{\Omega}_{i}}\left[\bm{ \theta}_{i}^{t}-\gamma_{t}\phi_{i}^{t}\left(\bm{\xi}_{i}^{t};\bm{\theta}_{i}^ {t},\widehat{\bm{\theta}}_{i}^{t},\bm{\lambda}_{i}^{t}\right)\right]-P_{\bm{ \Omega}_{i}}\left[\bm{\theta}_{i}^{\text{pse}}-\gamma_{t}\Phi_{\bm{\theta}^{ \text{pse}}}^{i,t}(\bm{\theta}^{\text{pse}},\bm{\lambda}^{\text{pse}})\right] \right\|_{2}^{2}\] \[\leq\mathbb{E}\left\|\bm{\theta}^{t}-\bm{\theta}^{\text{pse}} \right\|_{2}^{2}+\gamma_{t}^{2}\sum_{i=1}^{n}\mathbb{E}\left\|\phi_{i}^{t} \left(\bm{\xi}_{i}^{t};\bm{\theta}_{i}^{t},\widehat{\bm{\theta}}_{i}^{t},\bm{ \lambda}_{i}^{t}\right)-\Phi_{\bm{\theta}^{\text{pse}}}^{i,t}(\bm{\theta}^{ \text{pse}},\bm{\lambda}^{\text{pse}})\right\|_{2}^{2}\] \[\quad-2\gamma_{t}\sum_{i=1}^{n}\mathbb{E}\left\langle\bm{\theta} _{i}^{t}-\bm{\theta}_{i}^{\text{pse}},\phi_{i}^{t}\left(\bm{\xi}_{i}^{t};\bm{ \theta}_{i}^{t},\widehat{\bm{\theta}}_{i}^{t},\bm{\lambda}_{i}^{t}\right)- \Phi_{\bm{\theta}^{\text{pse}}}^{i,t}(\bm{\theta}^{\text{pse}},\bm{\lambda}^{ \text{pse}})\right\rangle.\] (A18)

The second term on the right side of (A18) is handled as follows.

\[\gamma_{t}^{2}\sum_{i=1}^{n}\mathbb{E}\left\|\phi_{i}^{t}\left( \bm{\xi}_{i}^{t};\bm{\theta}_{i}^{t},\widehat{\bm{\theta}}_{i}^{t},\bm{ \lambda}_{i}^{t}\right)-\Phi_{\bm{\theta}^{\text{pse}}}^{i,t}(\bm{\theta}^{ \text{pse}},\bm{\lambda}^{\text{pse}})\right\|_{2}^{2}\] \[=\gamma_{t}^{2}\sum_{i=1}^{n}\mathbb{E}\left\|\phi_{i}^{t}\left( \bm{\xi}_{i}^{t};\bm{\theta}_{i}^{t},\widehat{\bm{\theta}}_{i}^{t},\bm{ \lambda}_{i}^{t}\right)-\Phi_{\bm{\theta}^{\text{pse}}}^{i,t}\left(\bm{\theta} _{i}^{t},\widehat{\bm{\theta}}_{i}^{t},\bm{\lambda}_{i}^{t}\right)+\Phi_{\bm{ \theta}^{\text{pse}}}^{i,t}\left(\bm{\theta}_{i}^{t},\widehat{\bm{\theta}}_{i}^ {t},\bm{\lambda}_{i}^{t}\right)-\Phi_{\bm{\theta}^{\text{pse}}}^{i,t}(\bm{ \theta}^{\text{pse}},\bm{\lambda}^{\text{pse}})\right\|_{2}^{2}\] \[\leq\underbrace{3\gamma_{t}^{2}\sum_{i=1}^{n}\mathbb{E}\left\| \phi_{i}^{t}\left(\bm{\xi}_{i}^{t};\bm{\theta}_{i}^{t},\widehat{\bm{\theta}}_{i}^ {t},\bm{\lambda}_{i}^{t}\right)-\Phi_{\bm{\theta}^{\text{pse}}}^{i,t}\left( \bm{\theta}_{i}^{t},\widehat{\bm{\theta}}_{i}^{t},\bm{\lambda}_{i}^{t}\right) \right\|_{2}^{2}}_{(a)}+\underbrace{3\gamma_{t}^{2}\sum_{i=1}^{n}\mathbb{E} \left\|G_{\bm{\theta}^{t}}^{(i)}\left(\bm{\theta}_{i}^{t},\widehat{\bm{\theta}}_ {i}^{t}\right)-G_{\bm{\theta}^{\text{pse}}}^{(i)}\left(\bm{\theta}^{\text{ pse}}\right)\right\|_{2}^{2}}_{(b)}\] \[\quad+\underbrace{3\gamma_{t}^{4}\sum_{i=1}^{n}\mathbb{E}\left\| \nabla\bm{g}_{i}\left(\bm{\theta}_{i}^{t}\right)^{\top}\bm{\lambda}_{i}^{t}- \nabla\bm{g}_{i}\left(\bm{\theta}_{i}^{\text{pse}}\right)^{\top}\bm{\lambda}^{ \text{pse}}\right\|_{2}^{2}}_{(c)}.\] (A19)

We have the following results on these three terms in the last inequality of (A19).

\[(a) =3\gamma_{t}^{2}\sum_{i=1}^{n}\mathbb{E}\left\|\nabla_{\bm{\theta} _{i}}J_{i}\left(\bm{\xi}_{i}^{t};\bm{\theta}_{i}^{t},\widehat{\bm{\theta}}_{i}^{t }\right)-G_{\bm{\theta}^{\text{p}}}^{(i)}\left(\bm{\theta}_{i}^{t},\widehat{\bm{ \theta}}_{i}^{t}\right)\right\|_{2}^{2}\] \[\leq 3\gamma_{t}^{2}\left(\sigma_{0}^{2}+\sigma_{1}^{2}\mathbb{E} \left\|\bm{\theta}^{t}-\bm{\theta}^{\text{pse}}\right\|_{2}^{2}\right).\]

\[(b) =3\gamma_{t}^{2}\sum_{i=1}^{n}\mathbb{E}\left\|G_{\bm{\theta}^{t}} ^{(i)}\left(\bm{\theta}_{i}^{t},\widehat{\bm{\theta}}_{i}^{t}\right)-G_{\bm{ \theta}^{\text{p}}}^{(i)}\left(\bm{\theta}^{t}\right)+G_{\bm{\theta}^{\text{p}}}^{ (i)}\left(\bm{\theta}^{t}\right)-G_{\bm{\theta}^{\text{pse}}}^{(i)}+G_{\bm{ \theta}^{\text{pse}}}^{(i)}\left(\bm{\theta}^{\text{pse}}\right)-G_{\bm{\theta}^ {\text{pse}}}^{(i)}\left(\bm{\theta}^{\text{pse}}\right)\right\|_{2}^{2}\] \[\leq 9\gamma_{t}^{2}\sum_{i=1}^{n}\mathbb{E}\left(L_{i}^{2}\left\| \widehat{\bm{\theta}}_{i}^{t}-\bm{\theta}_{-i}^{t}\right\|_{2}^{2}+L_{i}^{2} \left\|\bm{\theta}^{t}-\bm{\theta}^{\text{pse}}\right\|_{2}^{2}+L_{i}^{2} \varepsilon_{i}^{2}\max_{j\in[n]}p_{ij}\left\|\bm{\theta}^{t}-\bm{\theta}^{ \text{pse}}\right\|_{2}^{2}\right),\]

where the last inequality is based on Assumptions 2.2 and 2.4. Further, since the constraint function \(\bm{g}_{i}(\cdot)\) is \(G_{g}\) Lipschitz for all \(i\in[n]\), we have that

\[(c) \leq 6\gamma_{t}^{4}\sum_{i=1}^{n}\mathbb{E}\left\|\nabla\bm{g}_{i }\left(\bm{\theta}_{i}^{t}\right)^{\top}\bm{\lambda}_{i}^{t}\right\|_{2}^{2}+6 \gamma_{t}^{4}\sum_{i=1}^{n}\mathbb{E}\left\|\nabla\bm{g}_{i}\left(\bm{ \theta}_{i}^{\text{pse}}\right)^{\top}\bm{\lambda}^{\text{pse}}\right\|_{2}^{2}\] \[\leq 6\gamma_{twhere the last inequality is based on Lemma E.1.

Plugging the results of \((a)\), \((b)\), and \((c)\) into (A19) gives

\[\gamma_{t}^{2}\sum_{i=1}^{n}\mathbb{E}\left\|\phi_{i}^{t}\left( \boldsymbol{\xi}_{i}^{t};\boldsymbol{\theta}_{i}^{t},\boldsymbol{\widehat{ \theta}}_{i}^{t},\boldsymbol{\lambda}_{i}^{t}\right)-\Phi_{\boldsymbol{\theta} ^{\text{\tiny{new}}}}^{i,t}\left(\boldsymbol{\theta}^{\text{\tiny{new}}}, \boldsymbol{\lambda}^{\text{\tiny{new}}}\right)\right\|_{2}^{2}\] \[\leq 3\gamma_{t}^{2}\sigma_{0}^{2}+3\gamma_{t}^{2}\left(\sigma_{1} ^{2}+3\sum_{i=1}^{n}L_{i}^{2}\left(1+\varepsilon_{i}^{2}\max_{j\in[n]}p_{ij} \right)\right)\mathbb{E}\left\|\boldsymbol{\theta}^{t}-\boldsymbol{\theta}^{ \text{\tiny{new}}}\right\|_{2}^{2}\] \[\quad+9\gamma_{t}^{2}\sum_{i=1}^{n}L_{i}^{2}\mathbb{E}\left\| \boldsymbol{\widehat{\theta}}_{i}^{t}-\boldsymbol{\theta}_{-i}^{t}\right\|_{2 }^{2}+6\gamma_{t}^{2}nB^{2}G_{g}^{2}+6\gamma_{t}^{4}nG_{g}^{2}\|\boldsymbol{ \lambda}^{\text{\tiny{new}}}\|_{2}^{2}.\] (A20)

Next, we deal with the last term on the right side of (A18). First, we have the following inequality:

\[\mathbb{E}\left[\phi_{i}^{t}\left(\boldsymbol{\xi}_{i}^{t}; \boldsymbol{\theta}_{i}^{t},\boldsymbol{\widehat{\theta}}_{i}^{t}, \boldsymbol{\lambda}_{i}^{t}\right)-\Phi_{\boldsymbol{\theta}^{\text{\tiny{ new}}}}^{i,t}\left(\boldsymbol{\theta}^{\text{\tiny{new}}}, \boldsymbol{\lambda}^{\text{\tiny{new}}}\right)\right]\] \[=\mathbb{E}\left[G_{\boldsymbol{\theta}^{t}}^{(i)}\left( \boldsymbol{\theta}_{i}^{t},\boldsymbol{\widehat{\theta}}_{i}^{t}\right)-G_{ \boldsymbol{\theta}^{\text{\tiny{new}}}}^{(i)}\left(\boldsymbol{\theta}^{ \text{\tiny{new}}}\right)\right]+\gamma_{t}\mathbb{E}\left[\nabla\boldsymbol{g} _{i}\left(\boldsymbol{\theta}_{i}^{t}\right)^{\top}\boldsymbol{\lambda}_{i}^{t }-\nabla\boldsymbol{g}_{i}\left(\boldsymbol{\theta}_{i}^{\text{\tiny{new}}} \right)^{\top}\boldsymbol{\lambda}^{\text{\tiny{new}}}\right].\]

Moreover, we have

\[-2\gamma_{t}\sum_{i=1}^{n}\mathbb{E}\left\langle\boldsymbol{\theta }_{i}^{t}-\boldsymbol{\theta}_{i}^{\text{\tiny{new}}},G_{\boldsymbol{\theta} ^{\text{\tiny{new}}}}^{(i)}\left(\boldsymbol{\theta}_{i}^{t},\boldsymbol{ \widehat{\theta}}_{i}^{t}\right)-G_{\boldsymbol{\theta}^{\text{\tiny{new}}}} ^{(i)}\left(\boldsymbol{\theta}^{\text{\tiny{new}}}\right)\right\rangle\] \[=-2\gamma_{t}\sum_{i=1}^{n}\mathbb{E}\left\langle\boldsymbol{ \theta}_{i}^{t}-\boldsymbol{\theta}_{i}^{\text{\tiny{new}}},G_{\boldsymbol{ \theta}^{\text{\tiny{new}}}}^{(i)}\left(\boldsymbol{\theta}_{i}^{t},\boldsymbol {\widehat{\theta}}_{i}^{t}\right)-G_{\boldsymbol{\theta}^{\text{\tiny{new}}}} ^{(i)}\left(\boldsymbol{\theta}^{\text{\tiny{new}}}\right)\right\rangle-2 \gamma_{t}\mathbb{E}\left\langle\boldsymbol{\theta}^{t}-\boldsymbol{\theta}^{ \text{\tiny{new}}},G_{\boldsymbol{\theta}^{t}}\left(\boldsymbol{\theta}^{t} \right)-G_{\boldsymbol{\theta}^{\text{\tiny{new}}}}\left(\boldsymbol{\theta}^{ \text{\tiny{new}}}\right)\right\rangle\] \[\leq 4C\gamma_{t}\sum_{i=1}^{n}L_{i}\mathbb{E}\left\|\boldsymbol{ \widehat{\theta}}_{i}^{t}-\boldsymbol{\theta}_{-i}^{t}\right\|_{2}-2\mu\gamma _{t}\mathbb{E}\left\|\boldsymbol{\theta}^{t}-\boldsymbol{\theta}^{\text{\tiny {new}}}\right\|_{2}^{2}+2\gamma_{t}\sum_{i=1}^{n}L_{i}\varepsilon_{i}\max_{j \in[n]}\sqrt{p_{ij}}\mathbb{E}\left\|\boldsymbol{\theta}^{t}-\boldsymbol{ \theta}^{\text{\tiny{new}}}\right\|_{2}^{2},\] (A21)

where the last inequality is from Assumptions 2.2, 2.3, 2.4 and the Cauchy-Schwarz inequality.

Further, we have

\[-2\gamma_{t}^{2}\sum_{i=1}^{n}\mathbb{E}\left\langle\boldsymbol{ \theta}_{i}^{t}-\boldsymbol{\theta}_{i}^{\text{\tiny{new}}},\nabla \boldsymbol{g}_{i}\left(\boldsymbol{\theta}_{i}^{t}\right)^{\top}\boldsymbol{ \lambda}_{i}^{t}-\nabla\boldsymbol{g}_{i}\left(\boldsymbol{\theta}_{i}^{\text{ \tiny{new}}}\right)^{\top}\boldsymbol{\lambda}^{\text{\tiny{new}}}\right\rangle\] \[\leq 2\gamma_{t}^{2}\sum_{i=1}^{n}\mathbb{E}\left\langle\boldsymbol{ \theta}_{i}^{\text{\tiny{new}}}-\boldsymbol{\theta}_{i}^{t},\nabla \boldsymbol{g}_{i}\left(\boldsymbol{\theta}_{i}^{t}\right)^{\top}\boldsymbol{ \lambda}_{i}^{t}\right\rangle+4\gamma_{t}^{2}CG_{g}\|\boldsymbol{\lambda}^{ \text{\tiny{new}}}\|_{2}\] \[\leq 2\gamma_{t}^{2}\sum_{i=1}^{n}\mathbb{E}\left[\left( \boldsymbol{g}_{i}\left(\boldsymbol{\theta}_{i}^{\text{\tiny{new}}}\right)- \boldsymbol{g}_{i}\left(\boldsymbol{\theta}_{i}^{t}\right)\right)^{\top} \boldsymbol{\lambda}_{i}^{t}\right]+4\gamma_{t}^{2}CG_{g}\|\boldsymbol{\lambda}^{ \text{\tiny{new}}}\|_{2}\] \[\leq 2\gamma_{t}^{2}\mathbb{E}\left[\sum_{i=1}^{n}\boldsymbol{g}_{i }\left(\boldsymbol{\theta}_{i}^{\text{\tiny{new}}}\right)^{\top}\left( \boldsymbol{\lambda}_{i}^{t}-\overline{\boldsymbol{\lambda}}^{t}\right)+ \boldsymbol{g}\left(\boldsymbol{\theta}^{\text{\tiny{new}}}\right)^{\top} \overline{\boldsymbol{\lambda}}^{t}-\sum_{i=1}^{n}\boldsymbol{g}_{i}\left( \boldsymbol{\theta}_{i}^{t}\right)^{\top}\boldsymbol{\lambda}_{i}^{t}\right]+4 \gamma_{t}^{2}CG_{g}\|\boldsymbol{\lambda}^{\text{\tiny{new}}}\|_{2}\] \[\leq 2\gamma_{t}^{2}\sum_{i=1}^{n}\mathbb{E}\left[\left\| \boldsymbol{g}_{i}\left(\boldsymbol{\theta}_{i}^{\text{\tiny{new}}}\right)\right\|_{2 }\left\|\boldsymbol{\lambda}_{i}^{t}-\overline{\boldsymbol{\lambda}}^{t}\right\|_{2 }-\boldsymbol{g}_{i}\left(\boldsymbol{\theta}_{i}^{t}\right)^{\top} \boldsymbol{\lambda}_{i}^{t}\right]+4\gamma_{t}^{2}CG_{g}\|\boldsymbol{\lambda}^{ \text{\tiny{new}}}\|_{2},\] (A22)

where the last inequality uses the fact that \(\boldsymbol{g}\left(\boldsymbol{\theta}^{\text{\tiny{new}}}\right)^{\top}\overline{ \boldsymbol{\lambda}}^{t}\leq 0\).

Define \(\widetilde{\mu}:=\mu-\sum_{i=1}^{n}L_{i}\varepsilon_{i}\max_{j\in[n]}\sqrt{p_{ij}}\), \(\nu:=3\left(\sigma_{1}^{2}+3\sum_{i=1}^{n}L_{i}^{2}\left(1+\varepsilon_{i}^{2} \max_{j\in[n]}p_{ij}\right)\right)\), and \(\pi:=3\sigma_{0}^{2}+6nB^{2}G_{g}^{2}+6nG_{g}^{2}\|\boldsymbol{\lambda}^{ \text{\tiny{new}}}\|_{2}^{2}+4CG_{g}\|\boldsymbol{\lambda}^{\text{\tiny{new}}}\|\). Plugging the results in (A20), (A21), and (A22) into (A18) yields

\[\mathbb{E}\left\|\bm{\theta}^{t+1}-\bm{\theta}^{\text{pse}}\right\|_ {2}^{2}\] \[\leq\left(1-2\gamma_{t}\widetilde{\mu}+\nu\gamma_{t}^{2}\right) \mathbb{E}\left\|\bm{\theta}^{t}-\bm{\theta}^{\text{pse}}\right\|_{2}^{2}+4C \gamma_{t}\sum_{i=1}^{n}L_{i}\mathbb{E}\left\|\widetilde{\bm{\theta}}_{i}^{t}- \bm{\theta}_{-i}^{t}\right\|_{2}+9\gamma_{t}^{2}\sum_{i=1}^{n}L_{i}^{2} \mathbb{E}\left\|\widetilde{\bm{\theta}}_{i}^{t}-\bm{\theta}_{-i}^{t}\right\|_ {2}^{2}\] \[\quad+2\gamma_{t}^{2}\sum_{i=1}^{n}\mathbb{E}\left[B\left\|\bm{ \lambda}_{i}^{t}-\overline{\bm{\lambda}}^{t}\right\|_{2}-\bm{g}_{i}\left(\bm{ \theta}_{i}^{t}\right)^{\top}\bm{\lambda}_{i}^{t}\right]+\pi\gamma_{t}^{2}.\] (A23)

Let \(\sup_{t\geq 1}\gamma_{t}\leq\frac{\widetilde{\mu}}{\nu}\), then \(1-2\widetilde{\mu}\gamma_{t}+\nu\gamma_{t}^{2}\leq 1-\widetilde{\mu} \gamma_{t}\). Thus, we have

\[\mathbb{E}\left\|\bm{\theta}^{t}-\bm{\theta}^{\text{pse}}\right\| _{2}^{2}\] \[\leq\frac{1}{\widetilde{\mu}\gamma_{t}}\left(\mathbb{E}\left\|\bm {\theta}^{t}-\bm{\theta}^{\text{pse}}\right\|_{2}^{2}-\mathbb{E}\left\|\bm{ \theta}^{t+1}-\bm{\theta}^{\text{pse}}\right\|_{2}^{2}\right)+\frac{4C}{ \widetilde{\mu}}\sum_{i=1}^{n}L_{i}\mathbb{E}\left\|\widetilde{\bm{\theta}}_{i }^{t}-\bm{\theta}_{-i}^{t}\right\|_{2}\] \[\quad+\frac{9\gamma_{t}}{\widetilde{\mu}}\sum_{i=1}^{n}L_{i}^{2} \mathbb{E}\left\|\widetilde{\bm{\theta}}_{i}^{t}-\bm{\theta}_{-i}^{t}\right\| _{2}^{2}+\frac{2\gamma_{t}}{\widetilde{\mu}}\sum_{i=1}^{n}\mathbb{E}\left[B \left\|\bm{\lambda}_{i}^{t}-\overline{\bm{\lambda}}^{t}\right\|_{2}-\bm{g}_{ i}\left(\bm{\theta}_{i}^{t}\right)^{\top}\bm{\lambda}_{i}^{t}\right]+\frac{ \pi\gamma_{t}}{\widetilde{\mu}}.\]

Summing the above inequality over \(t\in[T]\) and plugging into the result of Lemma E.2 yields

\[\sum_{t=1}^{T}\mathbb{E}\left\|\bm{\theta}^{t}-\bm{\theta}^{\text {pse}}\right\|_{2}^{2} \leq\sum_{t=1}^{T}\frac{1}{\widetilde{\mu}\gamma_{t}}\left(\mathbb{E} \left\|\bm{\theta}^{t}-\bm{\theta}^{\text{pse}}\right\|_{2}^{2}-\mathbb{E} \left\|\bm{\theta}^{t+1}-\bm{\theta}^{\text{pse}}\right\|_{2}^{2}\right)+\frac {4C}{\widetilde{\mu}}\sum_{t=1}^{T}\sum_{i=1}^{n}L_{i}\mathbb{E}\left\| \widetilde{\bm{\theta}}_{i}^{t}-\bm{\theta}_{-i}^{t}\right\|_{2}\] \[\quad+\frac{9}{\widetilde{\mu}}\sum_{t=1}^{T}\gamma_{t}\sum_{i=1} ^{n}L_{i}^{2}\mathbb{E}\left\|\widetilde{\bm{\theta}}_{i}^{t}-\bm{\theta}_{-i} ^{t}\right\|_{2}^{2}+\frac{2}{\widetilde{\mu}}\left(3+2\sqrt{n}\right)B\sum_{ t=1}^{T}\gamma_{t}\sum_{i=1}^{n}\mathbb{E}\left\|\bm{\lambda}_{i}^{t}- \overline{\bm{\lambda}}^{t}\right\|_{2}\] \[\quad+\frac{9}{\widetilde{\mu}}\sum_{t=1}^{T}\sum_{i=1}^{n}\left\| \bm{\lambda}_{i}^{t}-\overline{\bm{\lambda}}^{t}\right\|_{2}^{2}+\frac{\pi}{ \widetilde{\mu}}\sum_{t=1}^{T}\gamma_{t}+\frac{8nB^{2}}{\widetilde{\mu}}\sum_ {t=1}^{T}\gamma_{t}^{2}\] \[\quad-\frac{2}{\widetilde{\mu}}\sum_{t=1}^{T}\sum_{i=1}^{n}\gamma_ {t}\bm{\lambda}^{\top}\bm{g}_{i}(\bm{\theta}_{i}^{t})+\frac{n}{\widetilde{\mu} }\left(1+\sum_{t=1}^{T}\gamma_{t}^{2}\right)\|\bm{\lambda}\|_{2}^{2}.\] (A24)

Since \(\left\|\bm{\theta}^{t}-\bm{\theta}^{\text{pse}}\right\|_{2}^{2}\leq 4C^{2}\), we have that

\[\sum_{t=1}^{T}\frac{1}{\gamma_{t}}\left(\mathbb{E}\left\|\bm{ \theta}^{t}-\bm{\theta}^{\text{pse}}\right\|_{2}^{2}-\mathbb{E}\left\|\bm{ \theta}^{t+1}-\bm{\theta}^{\text{pse}}\right\|_{2}^{2}\right)\] \[=\frac{1}{\gamma_{1}}\mathbb{E}\left\|\bm{\theta}^{1}-\bm{\theta} ^{\text{pse}}\right\|_{2}^{2}-\frac{1}{\gamma_{T}}\mathbb{E}\left\|\bm{ \theta}^{T+1}-\bm{\theta}^{\text{pse}}\right\|_{2}^{2}+\sum_{t=2}^{T}\left( \frac{1}{\gamma_{t}}-\frac{1}{\gamma_{t-1}}\right)\mathbb{E}\left\|\bm{ \theta}^{t}-\bm{\theta}^{\text{pse}}\right\|_{2}^{2}\] \[\leq\frac{1}{\gamma_{1}}4C^{2}+\sum_{t=2}^{T}\left(\frac{1}{ \gamma_{t}}-\frac{1}{\gamma_{t-1}}\right)4C^{2}\leq\frac{4C^{2}}{\gamma_{T}},\] (A25)

where in the last inequality is based on the fact that \(\frac{1}{\gamma_{t}}-\frac{1}{\gamma_{t-1}}\geq 0\) because \(\gamma_{t}\) is a non-increasing sequence. Further, we have the following relations:

\[\sum_{i=1}^{n}L_{i}^{2}\mathbb{E}\left\|\widetilde{\bm{\theta}}_{i }^{t}-\bm{\theta}_{-i}^{t}\right\|_{2}^{2} \leq\max_{i}L_{i}\sum_{i=1}^{n}\sum_{h\neq i}\left\|\widetilde{\bm{\theta}}_{ ih}^{t}-\bm{\theta}_{h}^{t}\right\|_{2}^{2}=\max_{i}L_{i}\sum_{h=1}^{n}\|\bm{e}_{h}^{t}\|_{2}^{2},\] (A26) \[\sum_{i=1}^{n}L_{i}\mathbb{E}\left\|\widetilde{\bm{\theta}}_{i}^{t }-\bm{\theta}_{-i}^{t}\right\|_{2} \leq\max_{i}L_{i}\sum_{i=1}^{n}\sqrt{\sum_{h\neq i}\left\| \widetilde{\bm{\theta}}_{ih}^{t}-\bm{\theta}_{h}^{t}\right\|_{2}^{2}}\] \[\leq\max_{i}L_{i}\sqrt{n\sum_{i=1}^{n}\sum_{h\neq i}\left\|\widetilde {\bm{\theta}}_{ih}^{t}-\bm{\theta}_{h}^{t}\right\|_{2}^{2}}\] \[\leq\max_{i}L_{i}\sqrt{n}\sum_{h=1}^{n}\|\bm{e}_{h}^{t}\|_{2},\] (A27)where the last inequality is based on the fact that \(\sqrt{a+b+c}\leq\sqrt{a}+\sqrt{b}+\sqrt{c}\) for any \(a,b,c\geq 0\). Plugging (A25), (A26) and (A27) into (A24) and utilizing the results in Lemmas E.4 and E.5, we have that

\[\sum_{t=1}^{T}\mathbb{E}\left\|\boldsymbol{\theta}^{t}-\boldsymbol {\theta}^{\text{\rm{pse}}}\right\|_{2}^{2}+\frac{2}{\widetilde{\mu}}\sum_{t=1 }^{T}\sum_{i=1}^{n}\gamma_{t}\boldsymbol{\lambda}^{\top}\boldsymbol{g}_{i} \left(\boldsymbol{\theta}_{i}^{t}\right)-\frac{n}{\widetilde{\mu}}\left(1+\sum _{t=1}^{T}\gamma_{t}^{2}\right)\|\boldsymbol{\lambda}\|_{2}^{2}\] \[\leq\mathcal{O}\left(\frac{1}{\widetilde{\mu}\gamma_{T}}+\frac{1 }{\widetilde{\mu}}\sum_{t=1}^{T}\gamma_{t}\right).\] (A28)

Since any \(\boldsymbol{\lambda}\in\mathbb{R}_{+}^{m}\) satisfies the above inequality, by setting \(\boldsymbol{\lambda}=\frac{\left[\sum_{t=1}^{T}\gamma_{t}\sum_{i=1}^{n} \boldsymbol{g}_{i}\left(\boldsymbol{\theta}_{i}^{t}\right)\right]_{+}}{n \left(1+\sum_{t=1}^{T}\gamma_{t}^{2}\right)}\), we have that

\[\frac{2}{\widetilde{\widetilde{\mu}}}\boldsymbol{\lambda}^{\top}\left(\sum_{t =1}^{T}\gamma_{t}\sum_{i=1}^{n}\boldsymbol{g}_{i}\left(\boldsymbol{\theta}_{i} ^{t}\right)\right)-\frac{n}{\widetilde{\mu}}\left(1+\sum_{t=1}^{T}\gamma_{t}^ {2}\right)\|\boldsymbol{\lambda}\|_{2}^{2}=\frac{\left\|\left[\sum_{t=1}^{T} \gamma_{t}\sum_{i=1}^{n}\boldsymbol{g}_{i}\left(\boldsymbol{\theta}_{i}^{t} \right)\right]_{+}\right\|_{2}^{2}}{\widetilde{\mu}n\left(1+\sum_{t=1}^{T} \gamma_{t}^{2}\right)}.\] (A29)

As the terms in (A29) is non-negative, omitting it in (A28) gives

\[\sum_{t=1}^{T}\mathbb{E}\left\|\boldsymbol{\theta}^{t}-\boldsymbol {\theta}^{\text{\rm{pse}}}\right\|_{2}^{2}\leq\mathcal{O}\left(\frac{1}{ \widetilde{\mu}\gamma_{T}}+\frac{1}{\widetilde{\mu}}\sum_{t=1}^{T}\gamma_{t} \right).\]

Furthermore, since \(\mathbb{E}_{\boldsymbol{\xi}_{i}\sim\mathcal{D}\left(\boldsymbol{\theta}^{ \text{\rm{pse}}}\right)}|J_{i}(\boldsymbol{\xi}_{i};\boldsymbol{\theta}_{i}^{ \text{\rm{pse}}})-J_{i}(\boldsymbol{\xi}_{i};\boldsymbol{\theta}^{\text{\rm{ pse}}})|\leq G_{i}\left\|\boldsymbol{\theta}_{i}^{t}-\boldsymbol{\theta}_{i}^{\text{\rm{ pse}}}\right\|_{2}\), for any \(i\in[n]\), we have that

\[\mathcal{R}_{i}(T) =\sum_{t=1}^{T}\left(\mathbb{E}_{\boldsymbol{\xi}_{i}\sim\mathcal{ D}\left(\boldsymbol{\theta}^{\text{\rm{pse}}}\right)}\left[J\left(\boldsymbol{\xi}_{i}; \boldsymbol{\theta}_{i}^{t},\boldsymbol{\theta}_{-i}^{\text{\rm{pse}}}\right)- J\left(\boldsymbol{\xi}_{i};\boldsymbol{\theta}^{\text{\rm{pse}}}\right)\right]\right)\] \[\leq G_{i}\sum_{t=1}^{T}\left\|\boldsymbol{\theta}_{i}^{t}- \boldsymbol{\theta}_{i}^{\text{\rm{pse}}}\right\|_{2}^{2}\] \[\leq\mathcal{O}\left(\sqrt{\frac{T}{\widetilde{\mu}}\left(\frac{ 1}{\gamma_{T}}+\sum_{t=1}^{T}\gamma_{t}\right)}\right),\forall i\in[n].\]

On the other hand, plugging (A29) into (A28) and omitting the non-negative term \(\sum_{t=1}^{T}\mathbb{E}\left\|\boldsymbol{\theta}^{t}-\boldsymbol{\theta}^{ \text{\rm{pse}}}\right\|_{2}^{2}\), we have

\[\frac{\left\|\left[\sum_{t=1}^{T}\gamma_{t}\sum_{i=1}^{n} \boldsymbol{g}_{i}\left(\boldsymbol{\theta}_{i}^{t}\right)\right]_{+}\right\| _{2}^{2}}{\widetilde{\mu}n\left(1+\sum_{t=1}^{T}\gamma_{t}^{2}\right)}\leq \mathcal{O}\left(\frac{1}{\widetilde{\mu}\gamma_{T}}+\frac{1}{\widetilde{\mu}} \sum_{t=1}^{T}\gamma_{t}\right).\]

\[\left\|\left[\sum_{t=1}^{T}\gamma_{t}\sum_{i=1}^{n}\boldsymbol{g}_ {i}\left(\boldsymbol{\theta}_{i}^{t}\right)\right]_{+}\right\|_{2}\leq\mathcal{O }\left(\sqrt{\left(\frac{1}{\gamma_{T}}+\sum_{t=1}^{T}\gamma_{t}\right)\left( 1+\sum_{t=1}^{T}\gamma_{t}^{2}\right)}\right).\]

Then, we prove that

\[\mathcal{R}_{g}(T)\leq\mathcal{O}\left(\frac{1}{\gamma_{T}}\sqrt{ \left(\frac{1}{\gamma_{T}}+\sum_{t=1}^{T}\gamma_{t}\right)\left(1+\sum_{t=1}^{ T}\gamma_{t}^{2}\right)}\right).\]

### Proof of Lemma e.1

From the update rule of the dual variables, for any \(\bm{\lambda}_{i}^{t}\in\mathbb{R}_{+}^{m}\), \(i\in[n]\), and \(t\in[T]\), we have that

\[\sum_{i=1}^{n}\left\|\bm{\lambda}_{i}^{t+1}\right\|_{2}^{2}\leq \sum_{i=1}^{n}\left\|\sum_{j=1}^{n}a_{ij}\left[\left(1-\gamma_{t}^ {2}\right)\bm{\lambda}_{j}^{t}+\gamma_{t}\bm{g}_{i}(\bm{\theta}_{i}^{t}) \right]\right\|_{2}^{2}\] \[\leq \sum_{i=1}^{n}\sum_{j=1}^{n}a_{ij}\left\|(1-\gamma_{t}^{2})\bm{ \lambda}_{j}^{t}+\gamma_{t}^{2}\frac{\bm{g}_{i}(\bm{\theta}_{i}^{t})}{\gamma_ {t}}\right\|_{2}^{2}\] \[\leq \sum_{i=1}^{n}\sum_{j=1}^{n}a_{ij}\left[\left(1-\gamma_{t}^{2} \right)\left\|\bm{\lambda}_{j}^{t}\right\|_{2}^{2}+\left\|\bm{g}_{i}(\bm{ \theta}_{i}^{t})\right\|_{2}^{2}\right]\] \[\leq (1-\gamma_{t}^{2})\sum_{i=1}^{n}\left\|\bm{\lambda}_{i}^{t} \right\|_{2}^{2}+\sum_{i=1}^{n}\left\|\bm{g}_{i}(\bm{\theta}_{i}^{t})\right\| _{2}^{2}\] \[\leq (1-\gamma_{t}^{2})\sum_{i=1}^{n}\left\|\bm{\lambda}_{i}^{t} \right\|_{2}^{2}+nB^{2}.\]

We next bound \(\sum_{i=1}^{n}\left\|\bm{\lambda}_{i}^{t}\right\|_{2}^{2}\), \(\forall t\in[T]\) by deduction. First, since \(\bm{\lambda}_{i}^{1}=\bm{0}\), \(\gamma_{1}\leq 1\), and \(\|\bm{g}_{i}(\bm{\theta}_{i}^{1})\|_{2}^{2}\leq B^{2}\), \(\forall i\in[n]\), we have that \(\sum_{i=1}^{n}\left\|\bm{\lambda}_{i}^{2}\right\|_{2}^{2}\leq\sum_{i=1}^{n} \left\|\bm{g}_{i}(\bm{\theta}_{i}^{1})\right\|_{2}^{2}\leq nB^{2}\leq\frac{nB^ {2}}{\gamma_{t}^{2}}\). Assume that \(\sum_{i=1}^{n}\left\|\bm{\lambda}_{i}^{t}\right\|_{2}^{2}\leq\frac{nB^{2}}{ \gamma_{t}^{2}}\). Since \(\{\gamma_{t}\}_{t\in[T]}\) is a non-increasing sequence, and thus \(\sum_{i=1}^{n}\left\|\bm{\lambda}_{i}^{t+1}\right\|_{2}^{2}\leq(1-\gamma_{t}^ {2})\frac{nB^{2}}{\gamma_{t}^{2}}+nB^{2}=\frac{nB^{2}}{\gamma_{t}^{2}}\). Therefore, for any \(t\in[T]\), we have \(\sum_{i=1}^{n}\left\|\bm{\lambda}_{i}^{t+1}\right\|_{2}^{2}\leq\frac{nB^{2}} {\gamma_{t}^{2}}\leq\frac{nB^{2}}{\gamma_{t+1}^{2}}\), i.e., \(\sum_{i=1}^{n}\left\|\gamma_{t}\bm{\lambda}_{i}^{t}\right\|_{2}^{2}\leq nB^{2}\), which completes the proof.

### Proof of Lemma e.2

From the update rule of the dual variables \(\bm{\lambda}_{i}\), for any \(\bm{\lambda}\in\mathbb{R}_{+}^{m}\), we have that

\[\sum_{i=1}^{n}\left\|\bm{\lambda}_{i}^{t+1}-\bm{\lambda}\right\|_ {2}^{2}= \sum_{i=1}^{n}\left\|\left[\left(1-\gamma_{t}^{2}\right)\sum_{j \in\mathcal{N}_{i}}a_{ij}\bm{\lambda}_{j}^{t}+\gamma_{t}\bm{g}_{i}\left(\bm{ \theta}_{i}^{t}\right)\right]_{+}-\bm{\lambda}\right\|_{2}^{2}\] \[\leq \sum_{i=1}^{n}\left\|\left(1-\gamma_{t}^{2}\right)\sum_{j\in \mathcal{N}_{i}}a_{ij}\left(\bm{\lambda}_{j}^{t}-\bm{\lambda}_{i}^{t}\right)+ \left(\bm{\lambda}_{i}^{t}-\bm{\lambda}\right)+\gamma_{t}\left(\bm{g}_{i}\left( \bm{\theta}_{i}^{t}\right)-\gamma_{t}\bm{\lambda}_{i}^{t}\right)\right\|_{2}^ {2}\] \[\leq \sum_{i=1}^{n}\left(\sum_{j\in\mathcal{N}_{i}}a_{ij}\left\|\bm{ \lambda}_{j}^{t}-\bm{\lambda}_{i}^{t}\right\|_{2}^{2}+\left\|\bm{\lambda}_{i}^{ t}-\bm{\lambda}\right\|_{2}^{2}+\gamma_{t}^{2}\left\|\bm{g}_{i}\left(\bm{ \theta}_{i}^{t}\right)-\gamma_{t}\bm{\lambda}_{i}^{t}\right\|_{2}^{2}\right.\] \[\left.+2\gamma_{t}\sum_{j\in\mathcal{N}_{i}}a_{ij}\left\|\bm{ \lambda}_{j}^{t}-\bm{\lambda}_{i}^{t}\right\|_{2}\left\|\bm{g}_{i}\left(\bm{ \theta}_{i}^{t}\right)-\gamma_{t}\bm{\lambda}_{i}^{t}\right\|_{2}\right),\] (A30)

where we use the fact \(1-\gamma_{t}^{2}\leq 1\) in (A30). Next, we simplify the terms in (A30). First, based on the inequality \((a-b)^{2}\leq 2\left(a^{2}+b^{2}\right)\) for any \(a,b\geq 0\), we have that

\[\sum_{i=1}^{n}\sum_{j=1}^{n}a_{ij}\left\|\bm{\lambda}_{j}^{t}-\bm{\lambda}_{i}^{t }\right\|_{2}^{2}=\sum_{i=1}^{n}\sum_{j=1}^{n}a_{ij}\left(\left\|\left(\bm{ \lambda}_{j}^{t}-\overline{\bm{\lambda}}^{t}\right)-\left(\bm{\lambda}_{i}^{t}- \overline{\bm{\lambda}}^{t}\right)\right\|_{2}^{2}\right)\leq 4\sum_{i=1}^{n}\left\|\bm{\lambda}_{i}^{t}- \overline{\bm{\lambda}}^{t}\right\|_{2}^{2}.\]In addition, with the result in Lemma E.1, we know that

\[\sum_{i=1}^{n}\left\|\bm{g}_{i}\left(\bm{\theta}_{i}^{t}\right)- \gamma_{t}\bm{\lambda}_{i}^{t}\right\|_{2}^{2}\leq 2\sum_{i=1}^{n}\left\|\bm{g}_{i} \left(\bm{\theta}_{i}^{t}\right)\right\|_{2}^{2}+2\sum_{i=1}^{n}\left\|\gamma_ {t}\bm{\lambda}_{i}^{t}\right\|_{2}^{2}\leq 2nB^{2}+2nB^{2}=4nB^{2},\] \[\left\|\bm{g}_{i}\left(\bm{\theta}_{i}^{t}\right)-\gamma_{t}\bm{ \lambda}_{i}^{t}\right\|_{2}\leq\left\|\bm{g}_{i}\left(\bm{\theta}_{i}^{t} \right)\right\|_{2}+\left\|\gamma_{t}\bm{\lambda}_{i}^{t}\right\|_{2}\leq B+ \sqrt{n}B=(1+\sqrt{n})B.\]

Moreover, based on the fact that for any \(\bm{z}\in\mathbb{R}^{m}\), we have that

\[\sum_{i=1}^{n}\sum_{j=1}^{n}a_{ij}\left\langle\bm{\lambda}_{j}^{t }-\bm{\lambda}_{i}^{t},\bm{\lambda}_{i}^{t}-\bm{\lambda}\right\rangle =\sum_{i=1}^{n}\sum_{j=1}^{n}a_{ij}\left\langle\bm{\lambda}_{j}^{t }-\bm{\lambda}_{i}^{t},\bm{\lambda}_{i}^{t}-\overline{\bm{\lambda}}^{t}\right\rangle\] \[\leq\frac{1}{2}\sum_{i=1}^{n}\sum_{j=1}^{n}a_{ij}\left(\left\| \bm{\lambda}_{j}^{t}-\bm{\lambda}_{i}^{t}\right\|_{2}^{2}+\left\|\bm{\lambda }_{i}^{t}-\overline{\bm{\lambda}}^{t}\right\|_{2}^{2}\right)\] \[\leq\frac{5}{2}\sum_{i=1}^{n}\left\|\bm{\lambda}_{i}^{t}-\overline {\bm{\lambda}}^{t}\right\|_{2}^{2}.\]

Furthermore, notice that

\[\left\langle\bm{\lambda}_{i}^{t}-\bm{\lambda},\bm{g}_{i}\left( \bm{\theta}_{i}^{t}\right)-\gamma_{t}\bm{\lambda}_{i}^{t}\right\rangle =\left\langle\bm{\lambda}_{i}^{t}-\bm{\lambda},\bm{g}_{i}\left( \bm{\theta}_{i}^{t}\right)\right\rangle-\gamma_{t}\|\bm{\lambda}_{i}^{t}\|_{2 }^{2}+\gamma_{t}\bm{\lambda}^{\top}\bm{\lambda}_{i}^{t}\] \[\leq\left\langle\bm{\lambda}_{i}^{t}-\bm{\lambda},\bm{g}_{i} \left(\bm{\theta}_{i}^{t}\right)\right\rangle+\frac{\gamma_{t}}{2}\left(\left\| \bm{\lambda}\right\|_{2}^{2}-\left\|\bm{\lambda}_{i}^{t}\right\|_{2}^{2}\right),\]

where the last inequality follows that \(\bm{\lambda}^{\top}\bm{\lambda}_{i}^{t}=\frac{1}{2}(\left\|\bm{\lambda}\right\| _{2}^{2}+\left\|\bm{\lambda}_{i}^{t}\right\|_{2}^{2})\). We also have

Plugging all the above results into (A30), we obtain

\[\sum_{i=1}^{n}\left\|\bm{\lambda}_{i}^{t+1}-\bm{\lambda}\right\|_ {2}^{2}\leq \sum_{i=1}^{n}\left(\left\|\bm{\lambda}_{i}^{t}-\bm{\lambda}\right\| _{2}^{2}+9\left\|\bm{\lambda}_{i}^{t}-\overline{\bm{\lambda}}^{t}\right\|_{2}^ {2}\right.\] \[+2\gamma_{t}\left\langle\bm{\lambda}_{i}^{t}-\bm{\lambda},\bm{g} _{i}\left(\bm{\theta}_{i}^{t}\right)\right\rangle+\gamma_{t}^{2}\left(\left\| \bm{\lambda}\right\|_{2}^{2}-\left\|\bm{\lambda}_{i}^{t}\right\|_{2}^{2}\right)\] \[+4\gamma_{t}(1+\sqrt{n})B\left\|\bm{\lambda}_{i}^{t}-\overline{\bm {\lambda}}^{t}\right\|_{2}\right)+4nB^{2}\gamma_{t}^{2}.\]

Rearranging the terms in the above inequality and summing over \(t\in[T]\) gives

\[\sum_{t=1}^{T}\sum_{i=1}^{n}\gamma_{t}\left\langle\bm{\lambda}_{i }^{t}-\bm{\lambda},\bm{g}_{i}\left(\bm{\theta}_{i}^{t}\right)\right\rangle+ \sum_{t=1}^{T}\frac{n\gamma_{t}^{2}}{2}\|\bm{\lambda}\|_{2}^{2}\] \[\geq\frac{1}{2}\sum_{t=1}^{T}\sum_{i=1}^{n}\left(\left\|\bm{ \lambda}_{i}^{t+1}-\bm{\lambda}\right\|_{2}^{2}-\left\|\bm{\lambda}_{i}^{t}- \bm{\lambda}\right\|_{2}^{2}\right)\] \[\quad-2(1+\sqrt{n})B\sum_{t=1}^{T}\gamma_{t}\sum_{i=1}^{n}\left\| \bm{\lambda}_{i}^{t}-\overline{\bm{\lambda}}^{t}\right\|_{2}+\sum_{t=1}^{T} \sum_{i=1}^{n}\frac{\gamma_{t}^{2}}{2}\left\|\bm{\lambda}_{i}^{t}\right\|_{2}^ {2}.\]

The last term on the right side of the above inequality is non-negative and can be omitted. Besides, since \(\bm{\lambda}_{i}^{1}=\bm{0}\) for all \(i\in[n]\), then \(\sum_{t=1}^{T}\left(\left\|\bm{\lambda}_{i}^{t+1}-\bm{\lambda}\right\|_{2}^{2}- \left\|\bm{\lambda}_{i}^{t}-\bm{\lambda}\right\|_{2}^{2}\right)\geq-\|\bm{ \lambda}\|_{2}^{2}\) for any \(\bm{\lambda}_{i}^{T+1}\in\mathbb{R}^{m}\).

\(\mathbb{R}_{+}^{m}\). Thus, we have

\[\sum_{t=1}^{T}\sum_{i=1}^{n}\gamma_{t}\left((\bm{\lambda}_{i}^{t})^{ \top}\bm{g}_{i}(\bm{\theta}_{i}^{t})-\bm{\lambda}^{\top}\bm{g}_{i}(\bm{\theta}_ {i}^{t})\right)\] \[\geq-\frac{n}{2}\left(1+\sum_{t=1}^{T}\gamma_{t}^{2}\right)\|\bm{ \lambda}\|_{2}^{2}-\frac{9}{2}\sum_{t=1}^{T}\sum_{i=1}^{n}\left\|\bm{\lambda}_ {i}^{t}-\overline{\bm{\lambda}}^{t}\right\|_{2}^{2}\] \[\quad-2(1+\sqrt{n})B\sum_{t=1}^{T}\gamma_{t}\sum_{i=1}^{n}\left\| \bm{\lambda}_{i}^{t}-\overline{\bm{\lambda}}^{t}\right\|_{2}-4nB^{2}\sum_{t=1 }^{T}\gamma_{t}^{2}.\]

Rearranging the terms in the above inequality yields

\[-\sum_{t=1}^{T}\sum_{i=1}^{n}\gamma_{t}(\bm{\lambda}_{i}^{t})^{ \top}\bm{g}_{i}(\bm{\theta}_{i}^{t})\leq -\sum_{t=1}^{T}\sum_{i=1}^{n}\gamma_{i}\bm{\lambda}^{\top}\bm{g}_ {i}(\bm{\theta}_{i}^{t})+\frac{n}{2}\left(1+\sum_{t=1}^{T}\gamma_{t}^{2} \right)\|\bm{\lambda}\|_{2}^{2}+\frac{9}{2}\sum_{t=1}^{T}\sum_{i=1}^{n}\left\| \bm{\lambda}_{i}^{t}-\overline{\bm{\lambda}}^{t}\right\|_{2}^{2}\] \[+2(1+\sqrt{n})B\sum_{t=1}^{T}\gamma_{t}\sum_{i=1}^{n}\left\|\bm{ \lambda}_{i}^{t}-\overline{\bm{\lambda}}^{t}\right\|_{2}+4nB^{2}\sum_{t=1}^{T }\gamma_{t}^{2},\]

which completes the proof.

### Proof of Lemma e.4

Based on the update rule of \(\widehat{\bm{\theta}}_{ih}^{t}\) that \(\widehat{\bm{\theta}}_{ih}^{t+1}=\sum_{k\neq h}a_{ik}\widehat{\bm{\theta}}_{ kh}^{t}+a_{ih}\bm{\theta}_{h}^{t},\forall h\neq i\) and \(i,h\in[n]\), we have that

\[\bm{e}_{ih}^{t+1}:=\widehat{\bm{\theta}}_{ih}^{t+1}-\bm{\theta}_ {h}^{t+1} =\sum_{k\neq h}a_{ik}\widehat{\bm{\theta}}_{kh}^{t}+a_{ih}\bm{ \theta}_{h}^{t}-\bm{\theta}_{h}^{t+1}+\bm{\theta}_{h}^{t}-\bm{\theta}_{h}^{t}\] \[=\sum_{k\neq h}a_{ik}\bm{e}_{kh}^{t}-\left(\bm{\theta}_{h}^{t+1}- \bm{\theta}_{h}^{t}\right).\]

Recall that \(\bm{\Lambda}_{h}^{-}\) is the weight matrix formed by removing the \(h\)th row and \(h\)th column of the weight matrix \(\bm{\Lambda}\) for any \(h\in[n]\), and \(\bm{e}_{h}^{t}:=\mathrm{col}\left(\bm{e}_{1h}^{t},\cdots,\bm{e}_{(h-1)h}^{t}, \bm{e}_{(h+1)h}^{t},\cdots,\bm{e}_{nh}^{t}\right)\). Then,

\[\bm{e}_{h}^{t+1}=(\bm{\Lambda}_{h}^{-}\otimes\bm{\mathrm{I}}_{d})\bm{e}_{h}^{t }+\bm{1}_{n-1}\otimes\left(\bm{\theta}_{h}^{t+1}-\bm{\theta}_{h}^{t}\right).\]

Since \(\beta\) is the maximum eigenvalue of \(\bm{\Lambda}_{h}^{-}\) for all \(h\in[n]\), we have that

\[\mathbb{E}\|\bm{e}_{h}^{t+1}\|_{2} \leq\mathbb{E}\left\|(\bm{\Lambda}_{h}^{-}\otimes\bm{\mathrm{I}} _{d})\bm{e}_{h}^{t}\right\|_{2}+\mathbb{E}\left\|\bm{1}_{n-1}\otimes\left(\bm{ \theta}_{h}^{t+1}-\bm{\theta}_{h}^{t}\right)\right\|_{2}\] \[\leq\beta\mathbb{E}\|\bm{e}_{h}^{t}\|_{2}+\sqrt{n-1}\gamma_{t} \mathbb{E}\left\|\phi_{h}^{t}\left(\bm{\xi}_{h}^{t};\bm{\theta}_{h}^{t},\bm{ \theta}_{h}^{t},\bm{\lambda}_{h}^{t}\right)\right\|_{2}\] \[\leq\beta\mathbb{E}\|\bm{e}_{h}^{t}\|_{2}+\sqrt{n-1}\gamma_{t} \mathbb{E}\left\|\nabla_{\bm{\theta}_{h}}J_{h}\left(\bm{\xi}_{h}^{t};\bm{ \theta}_{h}^{t},\bm{\widehat{\theta}}_{h}^{t}\right)\right\|_{2}+\sqrt{n-1} \gamma_{t}^{2}\mathbb{E}\left\|\nabla\bm{g}_{h}(\bm{\theta}_{h})^{\top}\bm{ \lambda}_{h}^{t}\right\|_{2}\] \[\leq\beta\mathbb{E}\|\bm{e}_{h}^{t}\|_{2}+\sqrt{n-1}\gamma_{t}(G+ G_{g}\mathbb{E}\|\gamma_{t}\bm{\lambda}_{h}^{t}\|_{2})\] \[\leq\beta^{t}\mathbb{E}\|\bm{e}_{h}^{t}\|_{2}+\sqrt{n-1}\sum_{k=0 }^{t-1}\beta^{k}\gamma_{t-k}(G+\sqrt{n}BG_{g}).\] (A31)

Further, since \(\bm{\theta}_{ih}^{1}=\bm{0}\) for any \(i,h\in[n]\), then, from Assumption 2.3, \(\mathbb{E}\|\bm{e}_{ih}^{1}\|_{2}=\|\bm{\theta}_{h}^{1}\|_{2}\leq C\). Summing the above inequality over \(t\in[T]\) and \(h\in[n]\), we obtain

\[\sum_{t=1}^{T}\sum_{h=1}^{n}\mathbb{E}\|\bm{e}_{h}^{t}\|_{2} \leq nC\sum_{t=1}^{T}\beta^{t-1}+n\sqrt{n-1}(G+\sqrt{n}BG_{g}) \sum_{t=1}^{T}\sum_{k=0}^{t-2}\beta^{k}\gamma_{t-k-1}\] \[\leq\frac{nC}{1-\beta}+n\sqrt{n-1}(G+\sqrt{n}BG_{g})\sum_{k=1}^{T }\sum_{t=k+1}^{T}\beta^{t-k-1}\gamma_{k}\] \[\leq\frac{nC}{1-\beta}+\frac{n\sqrt{n-1}(G+\sqrt{n}BG_{g})}{1- \beta}\sum_{k=1}^{T}\gamma_{k}.\]On the other hand, taking square on both sides of (A31), we have

\[\mathbb{E}\|\bm{e}_{h}^{t}\|_{2}^{2}\leq 2\beta^{t}\mathbb{E}\left\|\bm{e}_{h}^{1} \right\|_{2}^{2}+2(n-1)(G+\sqrt{n}BG_{g})^{2}\left(\sum_{k=0}^{t-2}\beta^{k} \gamma_{t-k-1}\right)^{2}.\] (A32)

Using the Cauchy-Schwarz inequality yields

\[\left(\sum_{k=0}^{t-2}\beta^{k}\gamma_{t-k-1}\right)^{2}\leq\left(\sum_{k=0}^{ t-2}\beta^{k}\right)\left(\sum_{k=0}^{t-2}\beta^{k}\gamma_{t-k-1}^{2}\right) \leq\frac{\sum_{k=0}^{t-2}\beta^{k}\gamma_{t-k-1}}{1-\beta}.\] (A33)

Plugging (A33) into (A32) and summing over \(t\in[T]\), we have that

\[\sum_{t=1}^{T}\sum_{h=1}^{n}\mathbb{E}\|\bm{e}_{h}^{t}\|_{2}^{2} \leq 2nC^{2}\sum_{t=1}^{T}\beta^{t}+\frac{2n(n-1)(G+\sqrt{n}BG_{g} )^{2}}{1-\beta}\left(\sum_{t=1}^{T}\sum_{k=0}^{t-2}\beta^{k}\gamma_{t-k-1}\right)\] \[\leq\frac{2nC^{2}}{1-\beta}+\frac{2n(n-1)(G+\sqrt{n}BG_{g})^{2}}{ (1-\beta)^{2}}\sum_{k=1}^{T}\gamma_{k}.\]

### Proof of Lemma e.5

Let \(\bm{\omega}_{i}^{t}:=\left[\left(1-\gamma_{t}^{2}\right)\sum_{j\in\mathcal{N }_{i}}a_{ij}\bm{\lambda}_{j}^{t}+\gamma_{t}\bm{g}_{i}\left(\bm{\theta}_{i}^{t} \right)\right]_{+}-\sum_{j\in\mathcal{N}_{i}}a_{ij}\bm{\lambda}_{j}^{t}\). Then, for any \(i\in[n]\), we have that

\[\left\|\bm{\omega}_{i}^{t}\right\|_{2} =\left\|\left[\left(1-\gamma_{t}^{2}\right)\sum_{j\in\mathcal{N }_{i}}a_{ij}\bm{\lambda}_{j}^{t}+\gamma_{t}\bm{g}_{i}\left(\bm{\theta}_{i}^{t} \right)\right]_{+}-\sum_{j\in\mathcal{N}_{i}}a_{ij}\bm{\lambda}_{j}^{t}\right\| _{2}\] \[\leq\left\|-\gamma_{t}\sum_{j\in\mathcal{N}_{i}}a_{ij}\gamma_{t} \bm{\lambda}_{j}^{t}+\gamma_{t}\bm{g}_{i}\left(\bm{\theta}_{i}^{t}\right) \right\|_{2}\] \[\leq\gamma_{t}\sum_{j\in\mathcal{N}_{i}}a_{ij}\left\|\gamma_{t} \bm{\lambda}_{j}^{t}\right\|_{2}+\gamma_{t}\left\|\bm{g}_{i}\left(\bm{\theta} _{i}^{t}\right)\right\|_{2}\] \[\leq\gamma_{t}(\sqrt{n}+1)B.\] (A34)

The first inequality in (A34) results from the nonexpansive property of projection, and the third inequality holds by using Lemma E.1. By the update rule of \(\bm{\lambda}_{i}\) for any \(i\in[n]\), we have that

\[\bm{\lambda}_{i}^{t+1}=\sum_{j\in\mathcal{N}_{i}}a_{ij}\bm{\lambda}_{j}^{t}+ \bm{\omega}_{i}^{t}.\]

Define concatenation vectors \(\bm{\lambda}_{o}^{t}=\operatorname{col}\left(\bm{\lambda}_{1}^{t},\cdots,\bm{ \lambda}_{n}^{t}\right)\) and \(\bm{\omega}_{o}^{t}=\operatorname{col}\left(\bm{\omega}_{1}^{t},\cdots,\bm{ \omega}_{n}^{t}\right)\). Then, for any \(t\in[T]\), we have

\[\bm{\lambda}_{o}^{t+1}=\left(\mathbf{A}\otimes\mathbf{I}_{m}\right)\bm{ \lambda}_{o}^{t}+\bm{\omega}_{o}^{t}.\] (A35)

Since \(\overline{\bm{\lambda}}^{t}=\frac{1}{n}\sum_{i=1}^{n}\bm{\lambda}_{i}^{t}\), we have that

\[\bm{\Delta}^{t}:=\bm{\lambda}_{o}^{t}-\left(\mathbf{1}_{n}\otimes\mathbf{I}_{m }\right)\overline{\bm{\lambda}}^{t}=\left(\left(\mathbf{I}_{n}-\frac{\mathbf{1 }_{n}\mathbf{1}_{n}^{T}}{n}\right)\otimes\mathbf{I}_{m}\right)\bm{\lambda}_{o }^{t},\forall t\in[T].\] (A36)

Combining (A35) and (A36) yields

\[\bm{\Delta}^{t+1}=\left(\mathbf{A}\otimes\mathbf{I}_{m}\right)\bm{\Delta}^{t} +\left(\left(\mathbf{I}-\frac{\mathbf{1}\mathbf{1}^{T}}{n}\right)\otimes \mathbf{I}_{m}\right)\bm{\omega}_{o}^{t},\forall t\in[T].\]Since \(\bm{\lambda}_{i}^{1}=\bm{0}\) for all \(i\in[n]\), then \(\bm{\Delta}^{1}=\bm{0}\). Based on the fact that \(\left\|\mathbf{I}-\frac{\bm{1}\bm{1}^{T}}{n}\right\|_{\mathrm{F}}\leq 2\), we have that

\[\sum_{i=1}^{n}\left\|\bm{\lambda}_{i}^{t+1}-\overline{\bm{\lambda} }^{t+1}\right\|_{2}=\left\|\bm{\Delta}^{t+1}\right\|_{2} =\left\|(\bm{\Lambda}\otimes\mathbf{I}_{m})\,\bm{\Delta}^{t}+ \left(\left(\mathbf{I}-\frac{\bm{1}\bm{1}^{T}}{n}\right)\otimes\mathbf{I}_{m} \right)\bm{\omega}_{o}^{t}\right\|_{2}\] \[\leq\left\|(\bm{\Lambda}\otimes\mathbf{I}_{m})\,\bm{\Delta}^{t} \right\|_{2}+\left\|\left(\left(\mathbf{I}-\frac{\bm{1}\bm{1}^{T}}{n}\right) \otimes\mathbf{I}_{m}\right)\bm{\omega}_{o}^{t}\right\|_{2}\] \[\leq 2\sum_{k=0}^{t-1}\sigma_{2}(\bm{\Lambda})^{k}\left\|\bm{ \omega}_{o}^{t-k}\right\|_{2}\] \[\leq 2(n+\sqrt{n})B\sum_{k=0}^{t-1}\sigma_{2}(\bm{\Lambda})^{k} \gamma_{t-k},\]

where the last inequality is based on the result in (A34). Summing the above inequality over \(t\in[T]\) yields

\[\sum_{t=1}^{T}\sum_{i=1}^{n}\left\|\bm{\lambda}_{i}^{t}-\overline {\bm{\lambda}}^{t}\right\|_{2} \leq 2(n+\sqrt{n})B\sum_{t=1}^{T}\sum_{k=0}^{t-2}\sigma_{2}(\bm{ \Lambda})^{k}\gamma_{t-1-k}\] \[\leq\frac{2(n+\sqrt{n})B}{1-\sigma_{2}(\bm{\Lambda})}\sum_{k=1}^{ T}\gamma_{k}.\]

Similarly to the calculation of \(\sum_{t=1}^{T}\sum_{h=1}^{n}\|\bm{e}_{h}^{t}\|_{2}^{2}\) in Section E.3, we have that

\[\sum_{t=1}^{T}\sum_{i=1}^{n}\left\|\bm{\lambda}_{i}^{t}-\overline {\bm{\lambda}}^{t}\right\|_{2}^{2}\leq\frac{4(n+\sqrt{n})^{2}B^{2}}{(1-\sigma _{2}(\bm{\Lambda}))^{2}}\sum_{k=1}^{T}\gamma_{k}.\]

## Appendix F Simulation Details

### Networked Cournot Game

The Cournot game is a foundational model in economic theory (Allaz and Vila, 1993) for analyzing oligopolistic competition, where a limited number of firms dominate a specific market. In Cournot games, all firms sell a homogeneous commodity and aim to maximize their individual profits by independently and simultaneously determining optimal production quantities. The total quantity produced by all firms is constrained by factors such as market capacity, raw material availability, and environmental considerations. The profit of each firm depends not only on its own production quantity but also on the quantities chosen by its competitors, as they influence the demand price determined

Figure 3: A networked Cournot game with five firms and three markets.

by the market's demand curve and the total production quantity. There are strategic interactions between firms and markets in the Cournot game. According to the law of supply and demand, an increased production quantity drives down the demand price, and vice versa. The Cournot game model has diverse applications in various fields, including supply chain management, electricity market competition, natural resource extraction, online advertising auctions, and the telecommunications industry.

In this experiment, we consider a networked Cournot game comprising \(n\) firms selling a single commodity across \(m\) markets, as illustrated in Fig. 3. Each firm \(i\in[n]\) determines its output quantity \(\boldsymbol{\theta}_{i}=\mathrm{col}\left(\theta_{i1},\cdots,\theta_{im}\right)\) subject to the constraint of its production capacity \(Q_{i}\) that \(\sum_{j=1}^{m}\theta_{ij}\leq Q_{i}\). Here, \(\theta_{ij}\) denotes the quantity of player \(i\) sold to the \(j\)th market. The total quantity allocated to market \(j\) is limited by its market capacity \(B_{j}\), satisfying the condition that \(\sum_{i=1}^{n}\theta_{ij}\leq B_{j}\)\(\forall j\in[m]\). Thus, the local constraint of player \(i\) associated with market \(j\) is

\[g_{ij}(\boldsymbol{\theta}_{i})=\theta_{ij}-B_{j}/n,\forall i\in[n],j\in[m].\]

Let \(\boldsymbol{g}_{i}(\boldsymbol{\theta}_{i}):=\mathrm{col}\left(g_{i1}( \boldsymbol{\theta}_{i}),\cdots,g_{im}(\boldsymbol{\theta}_{i})\right)\), \(\forall i\in[n]\).

Figure 4: The demand prices of three markets.

Figure 5: The serving quantities of five firms to three markets.

The cost function of firm \(i\) is defined as

\[J_{i}=\bm{d}_{i}^{\top}\bm{\theta}_{i}-\sum_{j=1}^{m}p_{j}\theta_{ij},\]

where \(\bm{d}_{i}=\operatorname{col}\left(d_{i1},\cdots,d_{im}\right)\) and \(d_{ij}\) represents the cost that firm \(i\) sells a unit of its product to the \(j\)th market, \(\forall i\in[n],j\in[m]\). \(\bm{d}_{i}\) includes the cost of raw material, transportation, maintenance, etc. In \(J_{i}\), the term \(p_{j}\) denotes the unit demand price of market \(j\) determined by its market demand curve and the total production quantity, given by

\[p_{j}=\xi_{j}+\Lambda_{j}\left(c_{j}+\frac{1}{d_{j}}\sum_{i=1}^{n}\theta_{ij} \right)^{-\frac{1}{\tau_{j}}},\forall j\in[m],\] (A37)

where \(c_{j}\), \(d_{j}\)\(\Lambda_{j}\), and \(\tau_{j}>0\) are constants, \(\xi_{j}\) is a random variable. Due to the interaction between firms and markets, the demand price can fluctuate with production quantities, represented by \(\xi_{j}\sim\mathcal{D}_{j}(\bm{\theta})\). Note that the quantity-dependent distributions \(\mathcal{D}_{j}(\bm{\theta})\) for all \(j\in[m]\) are unknown by players. For any \(j\in[m]\), the variable \(\xi_{j}\) is defined as

\[\xi_{j}=\xi_{j}^{o}+\varepsilon\frac{\alpha_{j}}{\sum_{j^{\prime}=1}^{m} \alpha_{j^{\prime}}}\left(\sum_{i=1}^{n}\theta_{ij}\right),\]

where \(\xi_{j}^{o}\) is the random base component, \(\varepsilon\geq 0\) represents the performative strength of markets, and \(\alpha_{j}\) is the relative strength of market \(j\) for any \(j\in[m]\). According to the law of supply and demand, an increased production quantity generally decreases a market's demand price, which corresponds to the setup that \(\alpha_{j}\leq 0\) for all \(j\in[m]\). Thus, the objective of each play \(i\in[n]\) in the network Cournot game is formulated by

\[\min_{\bm{\theta}_{i}\in\bm{\Omega}_{i}} \mathbb{E}_{p_{j}\sim\mathcal{D}_{j}(\theta_{ij},\forall i\in[n] ),j\in[m]}\left[\bm{d}_{i}^{\top}\bm{\theta}_{i}-\sum_{j=1}^{m}p_{j}\theta_{ij}\right]\] subject to \[\theta_{ij}+\sum_{i^{\prime}\neq i}\theta_{i^{\prime}j}\leq B_{j}, \forall j\in[m].\]

In the simulation, we set \(n=5\) and \(m=3\). The network structure is as depicted in Fig. 3. Each element of the communication weight matrix \(A=\left(a_{ij}\right)_{n\times n}\) is set to be \(a_{ij}=\frac{1}{|\mathcal{N}_{i}|}\), and \(|\mathcal{N}_{i}|\) is the cardinality of \(\mathcal{N}_{i}\). The production capacity \(Q_{i}\) is randomly and uniformly drawn from \([10,12]\) for all \(i\in[5]\), and the market's capacity \(B_{j}\) is randomly and uniformly drawn from \([10,15]\) for all \(j\in[m]\). All entries in \(\bm{d}_{i}\), \(\forall i\in[n]\) are randomly and uniformly drawn from \([1,1.5]\). The distribution of \(\xi_{j}^{o}\) is set to \(\min(\max(\mathcal{N}(2.5,1),2.5),7.5)\). The performative power \(\alpha_{j}\) is randomly and uniformly drawn from \((-1,0]\), for all \(j\in[3]\). Other settings are: \(\Lambda_{j}=10\), \(c_{j}=10\), \(d_{j}=5\) and \(\tau_{j}=2\), \(\forall j\in[3]\).

Fig. 4 compares the demand prices of three markets at PSE and NE with performative strength \(\varepsilon=0.2\), \(0.4\), and \(0.6\) and Fig. 5 compares the corresponding serving quantities of five firms to these three markets. The results suggest that, although a larger performative strength leads to a wider gap, the difference in these two indicators between the PSE and NE remains insignificant. This confirms the effectiveness of PSE solutions and our distance analysis between the PSE and NE as stated in Theorem 3.5.

### Ride-Share Market

We further examine an example of a ride-share market, where multiple platforms compete to maximize their individual revenue by offering shared rides in competitive areas, taking into account operational constraints and market demands. This experiment builds upon the semi-synthetic simulation conducted in (Narang et al., 2023), adapting it to our constrained noncooperative game setting.

Consider a ride-share market with \(n\) platforms competing in \(m\) areas. Each platform \(i\in[n]\) aims to maximize its revenue by determining the quantities it offers at the \(j\)th area, denoted as \(\theta_{ij}\), for all \(j\in[m]\). Let \(\bm{\theta}_{i}=[\theta_{i1},\cdots,\theta_{im}]^{\top}\). The total number of rides provided by each platform \(i\) cannot exceed a predefined limit \(Q_{i}\), given by \(\sum_{j=1}^{m}\theta_{ij}\leq Q_{i}\), \(\forall i\in[n]\). Let \(p_{j}\) denote the demand price at the \(j\)th location, which fluctuates with the total offered quantity at the area following the law of supply and demand. We adopt the same model for \(\{p_{j}\}\) as in the network Cournot game, given by (A37). Additionally, the maintenance costs associated with platform operations may vary across locations due to factors such as distance or labor costs. Let \(\bm{d}_{i}\in\mathbb{R}^{m}\) represent the cost vector of platform \(i\) at all areas. Then, the inverse of the revenue function for each platform can be expressed as

\[J_{i}=-\sum_{j=1}^{m}p_{j}\theta_{ij}+\bm{d}_{i}^{\top}\bm{\theta}_{i},\forall i \in[n].\]

Assume that each platform only offers one type of ride. Considering the diverse ride characteristics, such as shape and speed, we use \(h_{i}\) to denote the spatial occupancy of each ride offered by platform \(i\). The accommodated ride quantity at each location is constrained by \(B_{j}\) due to parking availability and road conditions, such that \(\sum_{i=1}^{n}h_{i}\theta_{ij}\leq B_{j}\). Then, the objective of each platform \(i\in[n]\) in the ride-share market is formulated as

\[\begin{split}\min_{\bm{\theta}_{i}\in\bm{\Omega}_{i}}& \quad\mathbb{E}_{p_{j}\sim\mathcal{D}_{j}(\theta_{ij},\forall i\in[n]), \forall j\in[m]}\left[-\sum_{j=1}^{m}p_{j}\theta_{ij}+\bm{d}_{i}^{\top}\bm{ \theta}_{i}\right]\\ \text{subject to}&\quad h_{i}\theta_{ij}+\sum_{i^{ \prime}\neq i}h_{i^{\prime}}\theta_{i^{\prime}j}\leq B_{j},\forall j\in[m]. \end{split}\] (A38)

The simulation setup is based on dataset from a prior Kaggle competition.2 Our study focuses on three ride-share platforms (Uber, Lyft, and Via) and eight competing areas within New York. We randomly and uniformly assign the total number of rides, \(Q_{i}\), from the range \([200,400]\) for each platform \(i\in[3]\). Similarly, the accommodated capacity, \(B_{j}\), is randomly and uniformly drawn from \([50,150]\) for all \(j\in[8]\). All entries in \(\bm{d_{i}}\), \(\forall i\in[n]\) are randomly and uniformly drawn from \([0.2,2.2]\). The distribution of \(\xi_{j}^{o}\) is set as \(\min(\max(\mathcal{N}(1,1),1),5)\). Additionally, we set the following values for all areas \(j\in[8]\): \(\Lambda_{j}=5\), \(c_{j}=5\), \(d_{j}=5\), and \(\tau_{j}=2\).

Footnote 2: The data is publicly available at https://www.kaggle.com/brllrb/uber-and-lyft-dataset-boston-ma

Fig. 6 compares the convergence of the time-average revenues of these three platforms: Uber, Lyft, and Via, denoted by \(-\frac{1}{t}\sum_{t^{\prime}=1}^{t}\mathbb{E}_{\bm{p}^{t}\sim\mathcal{D}(\bm{ \theta}^{\prime})}[J_{i}(\bm{p}^{t};\bm{\theta}^{\prime})]\). We consider three

Figure 6: Convergence of the time-average revenues of three platforms.

Figure 7: Convergence of the time-average constraint violations at eight areas.

\(\varepsilon=0.1,0.2,\) and \(0.3\). Similarly to Fig. 2 (b), we compare the performance of Algorithm 1, represented by "pse", and the performance of Algorithm 1with perfect knowledge of data distributions \(\mathcal{D}_{j}(\bm{\theta})\) for all \(j\in[m]\). It is observed that, with a mild performative strength \(\varepsilon\), the revenues achieved by the "pse" are close to those of the "ne" for all three platforms. However, as \(\varepsilon\) increases, the gap between the two approaches widens, although it remains relatively small. This observation confirms the analytical result presented in Theorem 3.5.

Fig. 7 shows the convergence of the time-average constraint violations at eight areas by Algorithm 1, denoted by \(\frac{1}{t}\sum_{t^{\prime}=1}^{t}\sum_{i=1}^{3}g_{ij}(\bm{\theta}_{i}^{t^{ \prime}}),j=1,\cdots,8\), with performative strengths of \(\varepsilon=0.1,\)\(0.2,\) and \(0.3\). The constraints hold for all three performative strengths. However, as \(\varepsilon\) increases, the platform tends to allocate fewer rides. This may be attributed to larger market fluctuations associated with a higher \(\varepsilon\), leading to a more conservative allocation.

Fig. 8 compares the normalized distance between \(\bm{\theta}^{t}\) and the NE point \(\bm{\theta}^{\text{ne}}\), denoted as \(\|\bm{\theta}^{t}-\bm{\theta}^{\text{ne}}\|_{2}/\|\bm{\theta}^{t}\|_{2}\), with performative strengths: \(\varepsilon=0.1,\)\(0.2,\) and \(0.3\). The result is quantitatively analogous to the findings presented in Fig. 8. Firstly, \(\bm{\theta}^{t}\) gradually approaches \(\bm{\theta}^{\text{ne}}\) with iterations. Secondly, a higher performative strength leads to a wider normalized distance between the convergent point of \(\bm{\theta}^{t}\) and \(\bm{\theta}^{\text{ne}}\).

Fig. 9 compares the demand prices of eight areas and the ride quantities offered to them by three platforms at PSE and NE. We consider performative strengths \(\varepsilon=0.1\) and \(\varepsilon=0.3\). It is observed that the values of these indicators at the PSE and NE are close to each other when \(\varepsilon=0.1\). However, a noticeable discrepancy arises when \(\varepsilon=0.3\).

Additionally, we display the demand prices of eight areas in New York in Fig. 10, with different performative strengths: \(\varepsilon=0.1,\)\(0.2,\) and \(0.3\). It can be observed that, while prices vary by location, smaller values of \(\varepsilon\) generally correspond to higher prices. The offered quantities of these three platforms to the eight locations are illustrated in Fig. 11. The results indicate a conservative allocation as the performative strength increases. Furthermore, with the cost of these three platforms at different locations in Fig. 12, we obtain the revenues of the platforms Uber, Lyft, and Via in different areas, as illustrated in Fig. 13. Clearly, performativity has an inverse effect on revenues, and the stronger the performative strength, the lower the revenues.

Figure 10: The demand prices of different areas.

Figure 9: The demand prices of eight areas and the ride quantities offered to them by three platforms.

Figure 11: The quantities of platforms offered to different areas.

Figure 12: The cost of platforms in different areas.

Figure 13: The revenues of platforms in different areas.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes]
2. **Limitations:** Does the paper discuss the limitations of the work performed by the authors? [No] Answer: [No]
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes]
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes]
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [No]
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes]
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes]
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes]
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes]
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [No]
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)?Answer: [NA]
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes]
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA]
14. **Crowdsourcing and Research with Human Subjects Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA]
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA]**