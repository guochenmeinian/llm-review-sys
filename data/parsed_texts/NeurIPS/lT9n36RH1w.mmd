# Unconstrained Dynamic Regret via Sparse Coding

 Zhiyu Zhang

Harvard University

zhiyuz@seas.harvard.edu &Ashok Cutkosky

Boston University

ashok@cutkosky.com &Ioannis Ch. Paschalidis

Boston University

yannisp@bu.edu

Work done at Boston University. Future versions available at https://arxiv.org/abs/2301.13349.

###### Abstract

Motivated by the challenge of nonstationarity in sequential decision making, we study Online Convex Optimization (OCO) under the coupling of two problem structures: the domain is unbounded, and the comparator sequence \(u_{1},\ldots,u_{T}\) is arbitrarily time-varying. As no algorithm can guarantee low regret simultaneously against all comparator sequences, handling this setting requires moving from minimax optimality to comparator adaptivity. That is, sensible regret bounds should depend on certain complexity measures of the comparator relative to one's prior knowledge. This paper achieves a new type of such adaptive regret bounds leveraging a sparse coding framework. The complexity of the comparator is measured by its energy and its sparsity on a user-specified dictionary, which offers considerable versatility. For example, equipped with a wavelet dictionary, our framework improves the state-of-the-art bound [1] by adapting to both (\(i\)) the magnitude of the comparator average \(\|\bar{u}\|=\|\sum_{t=1}^{T}u_{t}/T\|\), rather than the maximum \(\max_{t}\|u_{t}\|\); and (\(ii\)) the comparator variability \(\sum_{t=1}^{T}\|u_{t}-\bar{u}\|\), rather than the uncentered sum \(\sum_{t=1}^{T}\|u_{t}\|\). Furthermore, our analysis is simpler due to decoupling function approximation from regret minimization.

## 1 Introduction

Nonstationarity is prevalent in sequential decision making, which poses a critical challenge to the vast majority of existing approaches developed offline. Consider weather forecasting for example [2]. A meteorologist typically starts from the governing physical equations and simulates them online using high performance computing; the imperfection of this physical model can lead to time-varying patterns in its forecasting error. Alternatively, a machine learning scientist may build a data-driven model from historical weather datasets, but its online deployment is subject to distribution shifts. If the structure of such nonstationarity can be exploited in our algorithm, then we may expect better forecasting performance. This paper investigates the problem from a theoretical angle - we aim to improve nonstationary online decision making by incorporating _temporal representations_.

Concretely, we study _Online Convex Optimization_ (OCO), which is a repeated game between us (the player) and an adversarial environment \(\mathcal{E}\). In each (the \(t\)-th) round, with a mutually known Lipschitz constant \(G\):

1. We make a prediction \(x_{t}\in\mathbb{R}^{d}\) based on the observations before the \(t\)-th round.
2. The environment \(\mathcal{E}\) reveals a convex loss function \(l_{t}:\mathbb{R}^{d}\rightarrow\mathbb{R}\) dependent on our prediction history \(x_{1},\ldots,x_{t}\); \(l_{t}\) is \(G\)-Lipschitz with respect to \(\left\lVert\cdot\right\rVert_{2}\).
3. We suffer the loss \(l_{t}(x_{t})\).

The game ends after \(T\) rounds, and then, our total loss is compared to that of an alternative sequence of predictions \(u_{1},\ldots,u_{T}\in\mathbb{R}^{d}\). Without knowing the time horizon \(T\), the environment \(\mathcal{E}\) and the_comparator sequence_\(\{u_{t}\}_{t\in\mathbb{Z}}\), our goal is to achieve low _unconstrained dynamic regret_

\[\operatorname{Regret}_{T}(u_{1:T}):=\sup_{\mathcal{E}}\left[\sum_{t=1}^{T}l_{t} (x_{t})-\sum_{t=1}^{T}l_{t}(u_{t})\right].\] (1)

Fixing any comparator \(\{u_{t}\}_{t\in\mathbb{Z}}\): if such an expression can be upper-bounded by a sublinear function of \(T\), then asymptotically, in any environment, we perform at least as well as the \(\{u_{t}\}_{t\in\mathbb{Z}}\) sequence.

The above setting deviates from the most standard setting of OCO [11, 12] in two ways.

* **Structure 1.** The domain \(\mathbb{R}^{d}\) is unbounded.
* **Structure 2.** The comparator is allowed to be time-varying.

While the latter has been studied extensively in the literature (since [11]) to account for nonstationarity, most existing approaches require a _time-invariant bounded domain_ to set the hyperparameters properly, which, to some extent, limits the amount of nonstationarity they can handle. One might argue that most practical problems have a finite range, which could be heuristically estimated from offline datasets. However, such a heuristic is not robust in nature, as underestimates will invalidate the theoretical analysis, and overestimates will make the regret bound excessively conservative. It is thus important to study the more challenging unconstrained dynamic setting2 combining the two problem structures, where algorithms cannot rely on pre-selected range estimates at all.

Footnote 2: It is known that unconstrained OCO algorithms can also handle _time-varying_ (but not necessarily bounded) domains in a black-box manner [13, Section 4].

Taking a closer look at their analysis, it is perhaps a little surprising that these two problem structures share a common theme, despite being studied mostly separately. In either the unconstrained static setting [12, 11, 10] or the bounded dynamic setting [11, 10, 14], the standard form of _minimax optimality_[1, 2, 13] becomes vacuous, as it is impossible to guarantee that \(\sup_{u_{1:T}}\operatorname{Regret}_{T}(u_{1:T})\) is sublinear in \(T\). Circumventing this issue relies on _comparator adaptivity3_ - instead of only depending on \(T\), any appropriate regret upper bound, denoted by \(\operatorname{Bound}_{T}(u_{1:T})\), should also depend on the comparator \(u_{1:T}\) through a certain _complexity measure_. Intuitively, despite the intractability of hard comparators, nonvacuous bounds can be established against "easy ones". A total loss bound then follows from the _oracle inequality_

Footnote 3: In general, adaptivity means achieving near minimax optimality simultaneously for many restricted subclasses of the problem, where minimax optimality is well-defined [12, Chapter 6].

\[\sum_{t=1}^{T}l_{t}(x_{t})\leq\inf_{u_{1:T}}\left[\sum_{t=1}^{T}l_{t}(u_{t})+ \operatorname{Bound}_{T}(u_{1:T})\right].\] (2)

A crucial observation is that the complexity of \(u_{1:T}\) is not uniquely defined: one could imagine bounding \(\operatorname{Regret}_{T}(u_{1:T})\) by many different non-comparable functions of \(u_{1:T}\). Essentially, this complexity measure serves as a _Bayesian prior_:4 choosing it amounts to assigning different priorities to different comparators \(u_{1:T}\in\mathbb{R}^{d\times T}\). The associated algorithm guarantees lower \(\operatorname{Bound}_{T}(u_{1:T})\) against comparators with higher priority, and due to Eq.(2), the total loss of our algorithm is low if some of these high priority comparators _actually_ achieve low loss \(\sum_{t=1}^{T}l_{t}(u_{t})\). Such a Bayesian reasoning highlights the importance of versatility in this workflow: in order to place an arbitrary application-dependent prior, we need a versatile algorithmic framework that adapts to a wide range of complexity measures. This leads to the limitations of existing results, discussed next.

Footnote 4: The prior can be selected on the fly, depending on the observation history. This brings key practical benefits: Appendix E discusses how an empirical forecaster based on domain knowledge or deep learning could be “robustified” using our framework.

To our knowledge, [14] is the only existing work that considers our setting. Two unconstrained dynamic regret bounds are presented based on three statistics of the comparator sequence, the _maximum range_\(M:=\max_{t}\left\|u_{t}\right\|_{2}\), the _norm sum_\(S:=\sum_{t=1}^{T}\left\|u_{t}\right\|_{2}\) and the _path length_\(P:=\sum_{t=1}^{T-1}\left\|u_{t+1}-u_{t}\right\|_{2}\). First, using a 1D unconstrained static algorithm as a simple range scaler, the paper achieves [14, Lemma 10]

\[\operatorname{Regret}_{T}(u_{1:T})\leq\tilde{O}\left(\sqrt{(M+P)MT}\right).\] (3)Then, by developing a customized mirror descent approach, most of the effort is devoted to improving \(MT\) to \(S\)[14, Theorem 4], i.e., adapting to the magnitude of individual \(u_{t}\).

\[\mathrm{Regret}_{T}(u_{1:T})\leq\tilde{O}\left(\sqrt{(M+P)S}\right).\] (4)

Despite the strengths of these results and their nontrivial analysis, a shared limitation is that both bounds depend explicitly on the path length \(P\). Intuitively, it means that good performance is only guaranteed in _almost static_ environments: in the typical situation of \(S=\Theta(T)\), these bounds are only sublinear when \(P=o(T)\), which rules out important persistent dynamics such as periodicity. Moreover, even the second bound still depends on \(MS\) instead of a finer characterization of each individual \(u_{t}\)'s magnitude. That is, the mission of removing \(M\) is not fully accomplished yet.5

Footnote 5: The significance of this issue could be seen through an analogy to (static \(D\)-bounded domain) _gradient adaptive_ OCO: although there are algorithms achieving the already adaptive \(O\left(D\sqrt{G\sum_{t=1}^{T}\left\|g_{t}\right\|_{2}}\right)\) static regret bound, the hallmark of gradient adaptivity is the so-called “second-order bound” \(O\left(D\sqrt{\sum_{t=1}^{T}\left\|g_{t}\right\|_{2}^{2}}\right)\), popularized by AdaGrad[10]. In a rough but related sense, we aim to achieve “second order comparator adaptivity”, which is only manifested in the less studied dynamic regret setting.

The goal of this paper is to extend comparator adaptivity to a wider range of complexity measures. For almost static environments in particular, quantitative benefits will be obtained from specific instances of this general approach.

### Contribution

The contributions of this paper are twofold.

1. First, we present an algorithmic framework achieving a new type of unconstrained dynamic regret bounds. It is based on a conversion to vector-output _Online Linear Regression_ (OLR): given a dictionary \(\mathcal{H}\) of orthogonal feature vectors spanning the _sequence space_\(\mathbb{R}^{dT}\), we use an unconstrained static OCO algorithm to linearly aggregate these feature vectors, which are themselves time-varying prediction sequences. Such a procedure guarantees \[\mathrm{Regret}_{T}(u_{1:T})\leq\tilde{O}\left(\sqrt{E\cdot\mathrm{ Sparsity}_{\mathcal{H}}}\right),\] (5) where \(E=\sum_{t=1}^{T}\left\|u_{t}\right\|_{2}^{2}\) is the _energy_ of the comparator \(u_{1:T}\), and \(\mathrm{Sparsity}_{\mathcal{H}}\) measures the sparsity of \(u_{1:T}\) on the dictionary \(\mathcal{H}\).6 Both \(E\) and \(\mathrm{Sparsity}_{\mathcal{H}}\) are unknown beforehand. Compared to [14], the main advantage of this framework is its versatility. Prior knowledge on the _transform domain_ can be incorporated by picking \(\mathcal{H}\), and favorable algorithmic properties can be conveniently inherited from static online learning. Footnote 6: For conciseness, we omit \(u_{1:T}\) in the notation. Throughout this paper, the regularity parameters on the RHS of the regret bound generally depend on \(u_{1:T}\). A list of these parameters is presented in Appendix A, including their relations.
2. Our second contribution is quantitative: although [14] is specifically crafted to handle almost static environments, we show that equipped with a _Haar wavelet_ dictionary, our framework actually guarantees better bounds (Table 1) in this setting, which is a surprising finding to us.
3. With the _comparator average_\(\bar{u}:=\sum_{t=1}^{T}u_{t}/T\) and the _first order variability_\(\bar{S}:=\sum_{t=1}^{T}\left\|u_{t}-\bar{u}\right\|_{2}\), our Haar wavelet algorithm guarantees \[\mathrm{Regret}_{T}(u_{1:T})\leq\tilde{O}\left(\left\|\bar{u}\right\|_{2}\sqrt {T}+\sqrt{P\bar{S}}\right).\]

\begin{table}
\begin{tabular}{|c|c|c|c|c|} \hline
**Algorithm** & \(P\)**-dependent bound** & \(K\)**-switching regret** & **Example 1** & **Example 2** \\ \hline \hline Ader[14] (meta-expert OGD) & \(\tilde{O}\left(\sqrt{(D+P)DT}\right)\) & \(\tilde{O}\left(D\sqrt{(1+K)T}\right)\) & N/A & \(\tilde{O}(T^{3/4})\) \\
[14, Algorithm 6] (range scaling) & \(\tilde{O}\left(\sqrt{(M+P)MT}\right)\) & \(\tilde{O}\left(M\sqrt{(1+K)T}\right)\) & \(\tilde{O}(T)\) & \(\tilde{O}(T^{3/4})\) \\
[14, Algorithm 2] (centered MD) & \(\tilde{O}\left(\sqrt{(M+P)S}\right)\) & \(\tilde{O}\left(\sqrt{(1+K)MS}\right)\) & \(\tilde{O}(T^{3/4})\) & \(\tilde{O}(T^{3/4})\) \\ \hline Ours (Haar OLR) & \(\tilde{O}\left(\left\|\bar{u}\right\|_{2}\sqrt{T}+\sqrt{P\bar{S}}\right)\) & \(\tilde{O}\left(\left\|\bar{u}\right\|_{2}\sqrt{T}+\sqrt{K\bar{E}}\right)\) & \(\tilde{O}(\sqrt{T})\) & \(\tilde{O}(\sqrt{T})\) \\ \hline \end{tabular}
\end{table}
Table 1: Comparison in almost static environments. Each row improves the previous row (omitting logarithmic factors), c.f., Appendix A.

It improves Eq.(4) by (\(i\)) a better dependence on the comparator magnitude (\(\sqrt{MS}\to\left\|\bar{u}\right\|_{2}\sqrt{T}\)); and (\(ii\)) decoupling the bias \(\bar{u}\) from the characterization of variability (\(\sqrt{PS}\to\sqrt{PS}\)).
* With the _number of switches_\(K:=\sum_{t=1}^{T-1}\mathbf{1}[u_{t+1}\neq u_{t}]\) and the _second order variability_\(\bar{E}:=\sum_{t=1}^{T}\left\|u_{t}-\bar{u}\right\|_{2}^{2}\), the same Haar wavelet algorithm guarantees an _unconstrained switching regret bound_ \[\mathrm{Regret}_{T}(u_{1:T})\leq\tilde{O}\left(\left\|\bar{u}\right\|_{2}\sqrt{ T}+\sqrt{K\bar{E}}\right),\] which improves the existing \(\tilde{O}\left(\sqrt{(1+K)MS}\right)\) bound resulting from Eq.(4) and \(P=O(KM)\). Due to the _local property_ of wavelets, our algorithm runs in \(O(d\log T)\) time per round, matching that of the baselines. As for the regret, our bounds are never worse than the baselines, and in two examples corresponding to \(\left\|\bar{u}\right\|_{2}\ll M\) and \(\bar{S}\ll S\), they reduce to clearly improved rates in \(T\). Furthermore, our analysis follows from the generic regret bound Eq.(5) and the _wavelet approximation theory_, providing an intriguing connection between disparate fields.

The paper concludes with an application in fine-tuning time series forecasters, where unconstrained dynamic OCO is naturally motivated. Due to limited space, this is deferred to Appendix E, with experiments that support our theoretical results.

### Related work

Our paper addresses the connection between unconstrained OCO and dynamic OCO. Although they both embody the idea of comparator adaptivity, unified studies have been scarce.

Unconstrained OCOTo obtain static regret bounds in OCO, _Online Gradient Descent_ (OGD) [20] is often the default approach. With learning rate \(\eta\), it guarantees \(O(\eta^{-1}\left\|u\right\|_{2}^{2}+\eta T)\) regret with respect to any _unconstrained_ static comparator \(u\in\mathbb{R}^{d}\), and the optimal choice in hindsight is \(\eta=O(\left\|u\right\|_{2}/\sqrt{T})\). Without the oracle knowledge of \(\left\|u\right\|_{2}\), it is impossible to tune \(\eta\) optimally. To address this issue, a series of works (also called _parameter-free online learning_) [21, 22, 23, 24, 25, 26, 27, 28, 29] developed vastly different strategies to achieve the _oracle optimal rate_\(O(\left\|u\right\|\sqrt{T})\) up to logarithmic factors. That is, the algorithm performs as if the complexity measure \(\left\|u\right\|\) is known beforehand.

There is certain flexibility in the choice of the norm \(\left\|\cdot\right\|\): \(L_{1}\) and \(L_{2}\) norm bounds were presented in [21], while Banach norm bounds were developed by [17, 28]. Historically, the connection between the \(L_{1}\) norm and sparsity has powered breakthroughs in batch data science, including LASSO [20] and compressed sensing [16]. However, the parallel path in online learning remains less studied: while the sparsity implication of the \(L_{1}\) norm adaptive bounds has been discussed in the literature [21, 18, 19], there is in general a lack of downstream investigations with concrete benefits. In this paper, we show that the sparsity of the comparator can be naturally associated to the _structural simplicity_ of a nonstationary environment.

Dynamic OCOComparing against dynamic sequences is a classical research topic. It is clear that one cannot go beyond linear regret in the worst case, therefore various notions of complexity should be introduced.

* The closest topic to ours is the _universal dynamic regret_, where the regret bound adapts to the complexity of an arbitrary \(u_{1:T}\) on a bounded domain with \(L_{p}\)-diameter \(D\). In the most common framework, the complexity measure is an \(L_{p,q}\) norm of the difference sequence \(\{u_{t+1}-u_{t}\}\), such as the \(L_{p,1}\) norm, i.e., the path length \(P=\sum_{t=1}^{T-1}\left\|u_{t+1}-u_{t}\right\|_{p}\)[19].7 Omitting the dependence on the dimension \(d\) (thus also the choice of \(p\)), the optimal bound under convex Lipschitz losses is \(\tilde{O}\left(\sqrt{(D+P)DT}\right)\)[20, 21, 22, 23], while the accelerated rate8\(\tilde{O}(P^{2/3}T^{1/3}\lor 1)\) can be achieved with strong convexity [20, 21]. Improvements have been studied under the additional smoothness assumption [22, 22, 23, 24]. These bounds subsume results in _switching (a.k.a., shifting) regret_, where the complexity of \(u_{1:T}\) is measured by its number of switches \(K\), as \(P\) is dominated by \(DK\). A notable exception is the _dynamic model_ framework from [14, 23]. Still considering a bounded domain, it takes a collection of dynamic models as input, which are mappings from the domain to itself. Then, the complexity of a comparator \(u_{1:T}\) is measured by how well it can be reconstructed by the best dynamic model in hindsight. Essentially, the use of temporal representations is somewhat similar to the dictionary in our framework. The important difference is that instead of using the best feature (or the best convex combination of the features) to measure the comparator, we use _linear combinations_ of the features - this allows handling unconstrained domains through subspace modeling.
* this is an important setting in our investigation. Footnote 9: Notably, [19, 20] creatively employed wavelet techniques to detect change-points of the environment, which, to the best of our knowledge, is the only existing use of wavelets in the online learning literature.

Unconstrained (universal) dynamic regretTo our knowledge, [13] is the only work studying the universal dynamic regret without a bounded domain, whose contributions have been summarized in our Introduction. Here we survey some negative results in the literature.

* The restricted dynamic regret is a special case of the universal dynamic regret, therefore lower bounds for the former apply to the latter as well. For convex Lipschitz losses [16] and strongly convex losses [19], any algorithm should suffer the dynamic regret of \(\Omega(P)\) and \(\Omega(P^{2})\), respectively.
* For dynamic OCO on bounded domains, a recurring analysis goes through the notion of _strong adaptivity_[17]: one first achieves low _static_ regret bounds on _every subinterval_ of the time horizon \([1:T]\), and then assembles these local bounds appropriately to bound the global dynamic regret [15, 14, 20, 21]. Following this route in the unconstrained setting appears to be challenging, as [13, Section 4] showed that (a natural form of) strong adaptivity cannot be achieved there. Additional discussions of related works are deferred to Appendix B, including the more general problem of _online nonparametric regression_, the more specific problem of _parametric time series forecasting_, and other orthogonal uses of sparsity in online learning.

### Notation

For two integers \(a\leq b\), \([a:b]\) is the set of all integers \(c\) such that \(a\leq c\leq b\). The brackets are removed when on the subscript, denoting a tuple with indices in \([a:b]\). Treating all vectors as column vectors, \(\mathrm{span}(A)\) represents the column space of a matrix \(A\). \(\log\) is natural logarithm when the base is omitted, and \(\log_{+}(\cdot):=0\vee\log(\cdot)\). \(\mathrm{polylog}\) denotes a poly-logarithmic function of its input. \(0\) represents a zero vector whose dimension depends on the context.

## 2 The general sparse coding framework

This section presents our sparse coding framework, achieving the generic sparsity adaptive regret bound Eq.(5). The key idea is to view online learning on the sequence space \(\mathbb{R}^{dT}\), rather than the default domain \(\mathbb{R}^{d}\). Despite its central role in signal processing (e.g., the _Fourier transform_), such a view is (in our opinion) under-explored by the online learning community.10

### Setting

To begin with, we follow the conventions in online learning [11, 14] to linearize convex losses. Consider that instead of the full loss function \(l_{t}\), we only observe its subgradient \(g_{t}\in\partial l_{t}(x_{t})\) at our prediction \(x_{t}\). By using the linear loss \(\langle g_{t},\cdot\rangle\) as a surrogate, we can still upper bound the regret Eq.(1) due to \(l_{t}(x_{t})-l_{t}(u)\leq\langle g_{t},x_{t}-u\rangle\). The linear loss problem is also called _Online Linear Optimization_ (OLO), where each observation \(g_{t}\) is a \(d\) dimensional vector satisfying \(\left\|g_{t}\right\|_{2}\leq G\).

Now, consider the length \(T\) sequences of predictions \(x_{1:T}\), gradients \(g_{1:T}\) and comparators \(u_{1:T}\). Let us flatten everything and treat them as \(dT\) dimensional vectors, concatenating per-round quantities in \(\mathbb{R}^{d}\). These are called _signals_. The comparator statistics could be more succinctly represented using vector notations, e.g., the energy \(E=\sum_{t=1}^{T}\left\|u_{t}\right\|_{2}^{2}=\left\|u_{1:T}\right\|_{2}^{2}\).

Our framework requires a _dictionary_ matrix \(\mathcal{H}\in\mathbb{R}^{dT\times N}\), possibly revealed online, whose columns are \(N\) nonzero _feature vectors_. We write \(\mathcal{H}\) in an equivalent block form as \([h_{t,n}]_{1\leq t\leq T,1\leq n\leq N}\), where each block \(h_{t,n}\in\mathbb{R}^{d\times 1}\). The accompanied linear transform \(u=\mathcal{H}\tilde{u}\) relates a signal \(u\in\mathbb{R}^{dT}\) to a coefficient vector \(\hat{u}\in\mathbb{R}^{N}\) (if it exists). Adopting the convention in signal processing, we will call \(\mathbb{R}^{dT}\) the _time domain_, and \(\mathbb{R}^{N}\) the _transform domain_. In general, symbols without hat refer to time domain quantities, while their transform domain counterparts are denoted with hat.

Summarizing the above, we consider the following concise interaction protocol.11 Despite its parametric appearance, our main focus is on the _nonparametric_ regime, where the dictionary size \(N\) scales with the amount of data \(T\).

Footnote 11: Despite also using features, the considered setting slightly differs from the standard notion of regression, as the loss function here does not necessarily have a minimizer. We use the term OLR for cleaner exposition.

Vector-output OLR with linear lossesIn the \(t\)-th round, our algorithm observes a \(d\)-by-N feature matrix \(\mathcal{H}_{t}:=[h_{t,n}]_{1\leq n\leq N}\), linearly combines its columns into a prediction \(x_{t}\in\mathbb{R}^{d}\), receives a loss gradient \(g_{t}\in\mathbb{R}^{d}\), and then suffers the linear loss \(\langle g_{t},x_{t}\rangle\). We assume that12\(\left\|h_{t,n}\right\|_{2}\leq 1\), \(\sum_{t=1}^{T}\left\|h_{t,n}\right\|_{2}^{2}\geq 1\) and \(\left\|g_{t}\right\|_{2}\leq G\). The performance metric is the unconstrained dynamic regret defined in Eq.(1).

Footnote 12: The assumptions on the features are mild: an important special case is \(\max_{t}\left\|h_{t,n}\right\|_{2}=1\), as in the Haar wavelet dictionary. We impose these assumptions to apply unconstrained static algorithms verbatim.

### Main result

In a nutshell, our strategy is to apply an unconstrained static OLO algorithm on the transform domain, and in a coordinate-wise fashion. This is remarkably simple, but also contains a few twists. To make it concrete, let us start with a single feature vector.

Size 1 dictionaryConsider an index \(n\in[1:N]\), which is associated to the feature \(h_{1:T,n}:=[h_{1,n},\ldots,h_{T,n}]\in\mathbb{R}^{dT}\). We suppress the index \(n\) and write it as \(h_{1:T}=[h_{1},\ldots,h_{T}]\). For any comparator \(u_{1:T}\in\mathrm{span}(h_{1:T})\), there exists \(\hat{u}\in\mathbb{R}\) such that \(u_{1:T}=h_{1:T}\hat{u}\). The cumulative loss of \(u_{1:T}\) can be rewritten as

\[\langle g_{1:T},u_{1:T}\rangle=\langle g_{1:T},h_{1:T}\rangle\,\hat{u}=\sum_{t =1}^{T}\left\langle g_{t},h_{t}\right\rangle\hat{u},\]

which is the loss of the coefficient \(\hat{u}\) in a 1D OLO problem with surrogate loss gradients \(\langle g_{t},h_{t}\rangle\). Essentially, to compete with a 1D comparator subspace \(\mathrm{span}(h_{1:T})\), it suffices to run a 1D static regret algorithm \(\mathcal{A}\) that competes with \(\hat{u}\in\mathbb{R}\). Such a procedure is presented as Algorithm 1.

It still remains to choose the static algorithm \(\mathcal{A}\). Technically, all known static comparator adaptive algorithms can be applied. As an illustrative example, we adopt the FreeGrad algorithm [15], which simultaneously achieves static comparator adaptivity and _second order gradient adaptivity_[15].13 Its pseudocode and static regret bound are presented in Appendix C.1 for completeness.

Footnote 13: A gradient adaptive regret bound refines our definition Eq.(1) by depending on the _actually encountered_ environment \(\mathcal{E}\) as well. FreeGrad enjoys another favorable property called _scale-freeness_: the predictions are invariant to any positive scaling of the loss gradients and the Lipschitz constant \(G\).

In summary, our single feature learner (Algorithm 1) has the following simplified guarantee, with the full gradient adaptive version deferred to Appendix C.

**Lemma 2.1**.: _Let \(\varepsilon>0\) be an arbitrary hyperparameter for FreeGrad (Algorithm 3 in Appendix C.1). Applying its 1D version as the static subroutine, for all \(T\in\mathbb{N}_{+}\) and \(u_{1:T}\in\mathrm{span}(h_{1:T})\), Algorithm 1 guarantees_

\[\mathrm{Regret}_{T}(u_{1:T})\leq\varepsilon G+\left\|u_{1:T}\right\|_{2}G\cdot \mathrm{polylog}\left(\max_{t}\left\|u_{t}\right\|_{2},T,\varepsilon^{-1} \right).\]

Note that the hyperparameter \(\varepsilon\) can be arbitrarily small. Further neglecting poly-logarithmic factors, the bound is essentially \(\tilde{O}\left(G\left\|u_{1:T}\right\|_{2}\right)\).

General dictionaryGiven the above single feature learner, let us turn to the general setting with \(N\) features. We run \(N\) copies of Algorithm 1 in parallel, aggregate their predictions, and the regret bound sums Lemma 2.1, similar to [10] in the static setting. The pseudocode is presented as Algorithm 2, and the regret bound is Theorem 1.

```
0: A dictionary \(\mathcal{H}=[h_{t,n}]\), where \(h_{t,n}\in\mathbb{R}^{d}\); and a hyperparameter \(\varepsilon>0\).
1: For all \(n\in[1:N]\), initialize a copy of Algorithm 1 as \(\mathcal{A}_{n}\). It runs the 1D version of Algorithm 3 as a subroutine, with hyperparameter \(\varepsilon/N\).
2:for\(t=1,2,\dots\)do
3: Receive \(\mathcal{H}_{t}=[h_{t,n}]_{1\leq n\leq N}\). For all \(n\), send \(h_{t,n}\) to \(\mathcal{A}_{n}\), and query its prediction \(w_{t,n}\).
4: Predict \(x_{t}=\sum_{n=1}^{N}w_{t,n}\).
5: Receive loss gradient \(g_{t}\), and send it to \(\mathcal{A}_{1},\dots,\mathcal{A}_{N}\) as loss gradients.
6:endfor ```

**Algorithm 2** Sparse coding with general dictionary.

**Theorem 1**.: _Consider any collection of signals \(z^{(n)}\in\mathrm{span}(h_{1:T,n})\), \(\forall n\). We define its reconstruction error (for the comparator \(u_{1:T}\)) as \(z^{(0)}=u_{1:T}-\sum_{n=1}^{N}z^{(n)}\in\mathbb{R}^{dT}\). Then, for all \(T\in\mathbb{N}_{+}\) and \(u_{1:T}\in\mathbb{R}^{dT}\), Algorithm 2 guarantees_

\[\mathrm{Regret}_{T}(u_{1:T})\leq\varepsilon G+G\left(\sum_{n=1}^{N}\left\|z^{ (n)}\right\|_{2}\right)\cdot\mathrm{polylog}\left(\max_{t,n}\left\|z^{(n)}_{t }\right\|_{2},T,N,\varepsilon^{-1}\right)+G\sum_{t=1}^{T}\left\|z^{(0)}_{t} \right\|_{2},\]

_where \(z^{(n)}_{t}\in\mathbb{R}^{d}\) is the \(t\)-th round component of the sequence \(z^{(n)}\in\mathbb{R}^{dT}\)._

To interpret this very general result, let us consider a few concrete settings.

* **Static regret.** If the size \(N=d\) and the dictionary \(\mathcal{H}_{t}=I_{d}\), then for any static comparator (\(u_{t}=u\in\mathbb{R}^{d}\)), we can let \(z^{(n)}\) be the projection of the sequence \(u_{1:T}\) onto \(\mathrm{span}(h_{1:T,n})\). This leaves zero reconstruction error, i.e., \(u_{1:T}=\sum_{n=1}^{N}z^{(n)}\). Theorem 1 reduces to \[\mathrm{Regret}_{T}(u_{1:T})\leq\varepsilon G+\left\|u\right\|_{1}G\sqrt{T} \cdot\mathrm{polylog}\left(\left\|u\right\|_{\infty},T,d,\varepsilon^{-1} \right),\] (6) which recovers a standard \(\tilde{O}(\left\|u\right\|_{1}\sqrt{T})\) bound in coordinate-wise unconstrained static OLO [14, Section 9.3]. The gradient adaptive version yields a better \(\tilde{O}(\left\|u\right\|_{2}\sqrt{T})\) bound, c.f., Appendix C.2.
* **Orthogonal dictionary.** Entering the dynamic realm, we now consider the situation where feature vectors are orthogonal (standard in signal processing), and the comparator \(u_{1:T}\in\mathrm{span}(\mathcal{H})\). Same as the static setting, we are free to define \(z^{(n)}\) as the projection \[z^{(n)}=\left\langle h_{1:T,n},u_{1:T}\right\rangle\frac{h_{1:T,n}}{\left\|h_{1 :T,n}\right\|_{2}^{2}}.\]Due to orthogonality, the projection preserves the energy of the time domain signal, i.e, \(E=\left\|u_{1:T}\right\|_{2}^{2}=\sum_{n=1}^{N}\left\|z^{(n)}\right\|_{2}^{2}\). By further defining \(\mathrm{Sparsity}_{\mathcal{H}}:=(\sum_{n=1}^{N}\left\|z^{(n)}\right\|_{2})^{2}/ \sum_{n=1}^{N}\left\|z^{(n)}\right\|_{2}^{2}\) (arbitrary when the denominator is zero), Theorem 1 reduces to \[\mathrm{Regret}_{T}(u_{1:T})\leq\tilde{O}\left(\sqrt{E\cdot\mathrm{Sparsity}_{ \mathcal{H}}}\right).\] (7) Note that as the squared \(L_{1}\)/\(L_{2}\) ratio, \(\mathrm{Sparsity}_{\mathcal{H}}\) is a classical sparsity measure [10] of the decomposed signals \(\{z^{(n)}\}_{1\leq n\leq N}\): if there are only \(N_{0}\leq N\) nonzero vectors within this collection, then \(\mathrm{Sparsity}_{\mathcal{H}}\leq N_{0}\) due to the Cauchy-Schwarz inequality. Therefore, the generic sparsity adaptive bound Eq.(7) depends on (\(i\)) the energy of the comparator \(u_{1:T}\); and (\(ii\)) the sparsity of its representation, without knowing either condition beforehand. The easier the comparator is (low energy, and sparse on \(\mathcal{H}\)), the lower the bound becomes.
* the regret bound adapts to the quality of the optimal (comparator-dependent) sub-dictionary \(\tilde{\mathcal{H}}\).

How to choose the dictionary \(\mathcal{H}\)? In practice, we may use prior knowledge on the dynamics of the environment. For example, if the environment is periodic, such as the weather or the traffic, then a good choice could be the Fourier dictionary. Similarly, wavelet dictionaries are useful for piecewise regular environments. Another possibility is to learn the dictionary from offline datasets, which is also called _representation learning_. Overall, such prior knowledge is not required to be _correct_ - our algorithm can take any dictionary as input, and the regret bound naturally adapts to its quality. The established connection between adaptivity and signal structures is a key benefit of our framework.

Power lawFor a more specific discussion, let us consider an empirically justified setup. In signal processing, the study of sparsity has been partially motivated by the _power law_[11]: under the standard Fourier or wavelet transforms, the \(n\)-th largest transform domain coefficient of many real signals can have magnitude roughly proportional to \(n^{-\alpha}\), where \(\alpha\in(0.5,1)\). We also observe this phenomenon from a weather dataset, with details presented in Appendix E.1. Figure 1 plots the sorted Fourier coefficients of an actual temperature sequence, on a log-log scale. A fitted dashed line is shown in orange, with (negative) slope \(\alpha=0.68\).

When the power law holds, our bound Eq.(7) has a more interpretable form. Assuming \(d=1\) and \(N=T\),

\[\mathrm{Sparsity}_{\mathcal{H}}=\frac{(\sum_{n=1}^{T}n^{-\alpha})^{2}}{\sum_{ n=1}^{T}n^{-2\alpha}}=O\left(T^{2-2\alpha}\right).\]

In a typical setting of \(E=\Theta(T)\), we obtain a sublinear \(\tilde{O}(T^{1.5-\alpha})\) dynamic regret bound.

## 3 The Haar OLR algorithm

This section presents the quantitative contributions of this paper: despite its generality, our sparse coding framework can improve existing results [1]. Our workhorse is the ability of wavelet bases to sparsely represent smooth signals.

### Haar wavelet

Wavelet is a fundamental topic in signal processing, with long lasting impact throughout modern data science. Roughly, the motivation is that a signal can simultaneously exhibit nonstationarity at different time scales, such as slow drifts and fast jumps, therefore to faithfully represent it, we should apply feature vectors with different resolutions. We will only use the simplest Haar wavelets, which is already sufficient. Readers are referred to [17, 18] for a thorough introduction to this topic.

Figure 1: The power law.

Specifically, we start from the 1D setting (\(d=1\)) with a dyadic horizon (\(T=2^{m}\), for some \(m\in\mathbb{N}_{+}\)). The Haar wavelet dictionary consists of \(T\) (unnormalized) orthogonal feature vectors, indexed by a _scale_ parameter \(j\in[1:\log_{2}T]\) and a _location_ parameter \(l\in[1:2^{-j}T]\). Given a \((j,l)\) pair, define a feature \(h^{(j,l)}=[h^{(j,l)}_{1},\dots,h^{(j,l)}_{T}]\in\mathbb{R}^{T}\) entry-wise as

\[h^{(j,l)}_{t}=\begin{cases}1,&t\in[2^{j}(l-1)+1:2^{j}(l-1)+2^{j-1}];\\ -1,&t\in[2^{j}(l-1)+2^{j-1}+1:2^{j}l];\\ 0,&\text{else}.\end{cases}\]

It means that \(h^{(j,l)}\) is only nonzero on a length-\(2^{j}\) interval, while changing its sign once in the middle of this interval. Collecting all the \((j,l)\) pairs yield \(T-1\) features; then, we incorporate an extra all-one feature \(h^{*}=[1,\dots,1]\) to complete this size \(T\) dictionary.

The defined features can be assembled into the columns of a matrix \(\operatorname{Haar}_{m}\). To help with the intuition, \(\operatorname{Haar}_{2}\) with \(T=4\) is presented in Eq.(8). The columns from the left to the right are \(h^{*}\), \(h^{(2,1)}\), \(h^{(1,1)}\) and \(h^{(1,2)}\). Observe that they are orthogonal, and the norm assumption from Section 2.1 is satisfied. Therefore, our sparsity adaptive regret bound Eq.(7) is applicable.

\[\operatorname{Haar}_{2}=\begin{bmatrix}1&1&1&0\\ 1&1&-1&0\\ 1&-1&0&1\\ 1&-1&0&-1\end{bmatrix}.\] (8)

Given this 1D Haar wavelet dictionary, we apply a minor variant of Algorithm 2 to prevent the dimension \(d\) from appearing in the regret bound. When \(d=1\), the algorithm is exactly Algorithm 2, where intuitions are most clearly demonstrated. Then, the doubling trick [11, Section 2.3.1] is adopted to relax the knowledge of \(T\). The pseudocode is presented as Algorithm 5 in Appendix D.

ComputationAn appealing property is that most Haar wavelet features are supported on short local intervals. Despite \(N=T\), there are only \(\log_{2}T\) active features in each round. Therefore, the runtime of our algorithm is \(O(d\log T)\) per round, matching that of all the baselines we compare to. This local property holds for compactly supported wavelets, most notably the _Daubechies family_[1, 1]. The latter can represent more general, piecewise polynomial signals.

### Main result

For almost static environments, our Haar OLR algorithm guarantees the following bounds, by relating comparator smoothness to the sparsity of its Haar wavelet representation. Different from [1] which only contains \(P\)-dependent bounds, we also provide a \(K\)-switching regret bound, in order to avoid using \(P=O(KM)\).14 Interestingly, the proofs of the following two bounds are quite different: the first uses _exact sparsity_, while the second uses _approximate sparsity_.

Footnote 14: Recall that one of our motivations is to remove \(M\) from the existing bounds.

**Theorem 2** (Switching regret).: _For all \(T\in\mathbb{N}_{+}\) and \(u_{1:T}\in\mathbb{R}^{dT}\), Algorithm 5 guarantees_

\[\operatorname{Regret}_{T}(u_{1:T})\leq\tilde{O}\left(\left\|\bar{u}\right\|_{2 }\sqrt{T}+\sqrt{K\bar{E}}\right).\] (9)

**Theorem 3** (Path length bound).: _For all \(T\in\mathbb{N}_{+}\) and \(u_{1:T}\in\mathbb{R}^{dT}\), Algorithm 5 guarantees_

\[\operatorname{Regret}_{T}(u_{1:T})\leq\tilde{O}\left(\left\|\bar{u}\right\|_{2 }\sqrt{T}+\sqrt{P\bar{S}}\right).\] (10)

It can be verified (Appendix A) that for _all_ comparators \(u_{1:T}\), our bounds are at least as good as prior works (Table 1). The optimality is a more subtle issue, as one should compare _upper bound functions_ (of \(u_{1:T}\)) to _lower bound functions_ in a global manner, rather than comparing the exponents of \(T\) in minimax online learning.

Nonetheless, we present two examples of \(u_{1:T}\), where the improvement can be clearly seen through better exponents of \(T\). To give it a concrete background, suppose we want to sequentially predict a 1D time series \(z_{1},\dots,z_{T}\in\mathbb{R}\). This could be formulated as a OCO problem where the decision \(x_{t}\) there is our prediction of \(z_{t}\), and the loss function is the absolute loss \(l_{t}(x)=|x-z_{t}|\). A natural choice of the comparator is the ground truth sequence \(z_{1:T}\), and due to Eq.(2), any upper bound on \(\mathrm{Regret}_{T}(z_{1:T})\) also upper-bounds the total forecasting loss of our algorithm. Below we present specific 1D comparator sequences \(u_{1:T}\) to demonstrate the strength of our results, which could be intuitively thought as the true time series \(z_{1:T}\) in this more restricted discussion.

**Example 1** (Tracking outliers).: _Consider the situation where \(u_{1:T}\) has a locally outlying scale: we set all the instantaneous comparators \(u_{t}\) to \(1\), except \(k\leq\sqrt{T}\) consecutive members which are set to \(\sqrt{T}\). Crucially, \(|\bar{u}|=O(1)\) and \(\bar{S}=O(k\sqrt{T})\), while \(M=\sqrt{T}\) and \(S=\Theta(T)\). With details deferred to Appendix D.7, both our bounds, i.e., Eq.(9) and (10), are \(\tilde{O}(\sqrt{kT})\), while the fine baseline Eq.(4) is \(\tilde{O}(T^{3/4})\), and the coarse baseline Eq.(3) is \(\tilde{O}(T)\). The largest gain is observed when \(k\) is a constant, i.e., the comparator is subject to a short but large perturbation._

**Example 2** (Persistent oscillation).: _Consider the situation where \(\bar{u}=1\), and all the instantaneous comparators oscillate around \(\bar{u}\): \(u_{t}=\bar{u}+\alpha_{t}/\sqrt{T}\). \(\alpha_{t}=1\) or \(-1\), and it only switches sign for \(k\) times. Notice that \(\bar{S}=\sqrt{T}\), while \(S=\Theta(T)\). All the baselines are \(\tilde{O}\left(\sqrt{T}+k^{1/2}T^{1/4}\right)\), while both our bounds are \(\tilde{O}(\sqrt{T})\). The largest gain is observed when \(k=T-1\), i.e., the comparator switches in every round._

In summary, we show that existing bounds are suboptimal, while the optimality of our results remains to be studied. It highlights the importance of _comparator energy_ and _variability_ in the pursuit of better algorithms, which have not received enough attention in the literature. Next, we briefly sketch the proofs of these bounds.

Proof sketchThe switching regret bound mostly follows from a very simple observation: if a sequence is constant throughout the support of a Haar wavelet feature, then its transform domain coefficient for this feature is zero. As features on the same scale \(j\) do not overlap, a \(K\)-switching comparator can only induce \(K\) nonzero coefficients on the \(j\)-th scale. There are at most \(K\log_{2}T\) nonzero coefficients in total, therefore \(\mathrm{Sparsity}_{\mathcal{H}}=\tilde{O}(K)\). The bound Eq.(9) is obtained by applying this argument after taking out the average of \(u_{1:T}\).

As for the path length bound, the idea is to consider the _reconstructed_ sequences, using transform domain coefficients on a single scale \(j\). These are usually called _detail sequences_ in the wavelet literature [14]. Each detail sequence has a relatively simple structure, whose path length and variability can be associated to the magnitude of its transform domain coefficients. Moreover, as these detail sequences are certain "locally averaged" and "globally centered" versions of the actual comparator \(u_{1:T}\), their regularities are dominated by the regularity of \(u_{1:T}\) itself. In combination, this yields a relation between \(P\bar{S}\) and the coefficients' \(L_{1}\) norm, i.e., \(\sum_{n=1}^{N}\left\|z^{(n)}\right\|_{2}\) in Theorem 1, from which the bound is established.

Compared to the analysis of [13], the key advantage of our analysis is the decoupling of function approximation from the generic sparsity-based regret bound. The former is algorithm-independent, while the latter can be conveniently combined with advances in static online learning. With the help of approximation theory (e.g., Fourier features, wavelets, and possibly deep learning further down the line), intuitions are arguably clearer in this way, and solutions could be more precise (compared to analyses that "mix" function approximation with regret minimization).

Additional discussionFinally, due to limited space, we defer additional discussion of our technical results to Appendix F, including

* The related use of _Multi-Resolution Analysis_ (MRA) in the existing online learning literature.
* The comparison between Lipschitz and strongly convex losses in unconstrained dynamic OCO.

## 4 Conclusion

This paper presents a unified study of unconstrained and dynamic online learning, where the two problem structures are naturally connected via comparator adaptivity. Building on the synergy between static parameter-free algorithms and temporal representations, we develop an algorithmic framework achieving a generic sparsity-adaptive regret bound. Equipped with the wavelet dictionary, our framework improves the quantitative results from [13], by adapting to finer characterizations of the comparator sequence.

## Acknowledgments and Disclosure of Funding

We thank Vivek Goyal for helpful pointers to the signal processing literature, and the NeurIPS reviewers for their constructive feedback. This research was partially supported by the NSF under grants CCF-2200052, DMS-1664644, and IIS-1914792, by the ONR under grant N00014-19-1-2571, by the DOE under grant DE-AC02-05CH11231, by the NIH under grant UL54 TR004130, and by Boston University.

## References

* [AABR09] Jacob Abernethy, Alekh Agarwal, Peter L Bartlett, and Alexander Rakhlin. A stochastic view of optimal regret through minimax duality. In _Conference on Learning Theory_, 2009.
* [ABRT08] Jacob Abernethy, Peter L Bartlett, Alexander Rakhlin, and Ambuj Tewari. Optimal strategies and minimax lower bounds for online convex games. In _Conference on Learning Theory_, pages 415-423, 2008.
* [AHMS13] Oren Anava, Elad Hazan, Shie Mannor, and Ohad Shamir. Online learning for time series prediction. In _Conference on learning theory_, pages 172-184. PMLR, 2013.
* [AHZ15] Oren Anava, Elad Hazan, and Assaf Zeevi. Online time series prediction with missing data. In _International conference on machine learning_, pages 2191-2199. PMLR, 2015.
* [AM16] Oren Anava and Shie Mannor. Heteroscedastic sequences: beyond gaussianity. In _International Conference on Machine Learning_, pages 755-763. PMLR, 2016.
* [AW01] Katy S Azoury and Manfred K Warmuth. Relative loss bounds for on-line density estimation with the exponential family of distributions. _Machine Learning_, 43(3):211-246, 2001.
* [BGZ15] Omar Besbes, Yonatan Gur, and Assaf Zeevi. Non-stationary stochastic optimization. _Operations research_, 63(5):1227-1244, 2015.
* [BW19] Dheeraj Baby and Yu-Xiang Wang. Online forecasting of total-variation-bounded sequences. _Advances in Neural Information Processing Systems_, 32, 2019.
* [BW20] Dheeraj Baby and Yu-Xiang Wang. Adaptive online estimation of piecewise polynomial trends. _Advances in Neural Information Processing Systems_, 33:20462-20472, 2020.
* [BW21] Dheeraj Baby and Yu-Xiang Wang. Optimal dynamic regret in exp-concave online learning. In _Conference on Learning Theory_, pages 359-409. PMLR, 2021.
* [BW22] Dheeraj Baby and Yu-Xiang Wang. Optimal dynamic regret in proper online learning with strongly convex losses and beyond. In _International Conference on Artificial Intelligence and Statistics_, pages 1805-1845. PMLR, 2022.
* [BZW21] Dheeraj Baby, Xuandong Zhao, and Yu-Xiang Wang. An optimal reduction of TV-denoising to adaptive online learning. In _International Conference on Artificial Intelligence and Statistics_, pages 2899-2907. PMLR, 2021.
* [CDV93] Albert Cohen, Ingrid Daubechies, and Pierre Vial. Wavelets on the interval and fast wavelet transforms. _Applied and computational harmonic analysis_, 1993.
* [CLW21] Liyu Chen, Haipeng Luo, and Chen-Yu Wei. Impossible tuning made possible: A new expert algorithm and its applications. In _Conference on Learning Theory_, pages 1216-1259. PMLR, 2021.
* [CO18] Ashok Cutkosky and Francesco Orabona. Black-box reductions for parameter-free online learning in banach spaces. In _Conference On Learning Theory_, pages 1493-1529. PMLR, 2018.
* [CRT06] Emmanuel J Candes, Justin Romberg, and Terence Tao. Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information. _IEEE Transactions on information theory_, 52(2):489-509, 2006.
* [Cut19] Ashok Cutkosky. Combining online learning guarantees. In _Conference on Learning Theory_, pages 895-913. PMLR, 2019.
* [Cut20] Ashok Cutkosky. Parameter-free, dynamic, and strongly-adaptive online learning. In _International Conference on Machine Learning_, pages 2250-2259. PMLR, 2020.

* [CWW19] Xi Chen, Yining Wang, and Yu-Xiang Wang. Nonstationary stochastic optimization under \(L_{p,q}\)-variation measures. _Operations Research_, 67(6):1752-1765, 2019.
* [Dau88] Ingrid Daubechies. Orthonormal bases of compactly supported wavelets. _Communications on pure and applied mathematics_, 41(7):909-996, 1988.
* [DGSS15] Amit Daniely, Alon Gonen, and Shai Shalev-Shwartz. Strongly adaptive online learning. In _International Conference on Machine Learning_, pages 1405-1411. PMLR, 2015.
* [DHS11] John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and stochastic optimization. _Journal of machine learning research_, 12(7), 2011.
* [DSSST10] John C Duchi, Shai Shalev-Shwartz, Yoram Singer, and Ambuj Tewari. Composite objective mirror descent. In _COLT_, volume 10, pages 14-26. Citeseer, 2010.
* [FKK16] Dean Foster, Satyen Kale, and Howard Karloff. Online sparse linear regression. In _Conference on Learning Theory_, pages 960-970. PMLR, 2016.
* [FKMS17] Dylan J Foster, Satyen Kale, Mehryar Mohri, and Karthik Sridharan. Parameter-free online learning via model selection. _Advances in Neural Information Processing Systems_, 30, 2017.
* [FRS18] Dylan J Foster, Alexander Rakhlin, and Karthik Sridharan. Online learning: Sufficient statistics and the Burkholder method. In _Conference On Learning Theory_, pages 3028-3064. PMLR, 2018.
* [Ger13] Sebastien Gerchinovitz. Sparsity regret bounds for individual sequences in online linear regression. _The Journal of Machine Learning Research_, 14(1):729-769, 2013.
* [GG15] Pierre Gaillard and Sebastien Gerchinovitz. A chaining algorithm for online nonparametric regression. In _Conference on Learning Theory_, pages 764-796. PMLR, 2015.
* [GS16] Andras Gyorgy and Csaba Szepesvari. Shifting regret, mirror descent, and matrices. In _International Conference on Machine Learning_, pages 2943-2951. PMLR, 2016.
* [GW18] Pierre Gaillard and Olivier Wintenberger. Efficient online algorithms for fast-rate regret bounds under sparsity. _Advances in Neural Information Processing Systems_, 31, 2018.
* [GY14] Sebastien Gerchinovitz and Jia Yuan Yu. Adaptive and optimal online linear regression on \(L_{1}\)-balls. _Theoretical Computer Science_, 519:4-28, 2014.
* [Haz16] Elad Hazan. Introduction to online convex optimization. _Foundations and Trends(r) in Optimization_, 2(3-4):157-325, 2016.
* [HLS\({}^{+}\)18] Elad Hazan, Holden Lee, Karan Singh, Cyril Zhang, and Yi Zhang. Spectral filtering for general linear dynamical systems. _Advances in Neural Information Processing Systems_, 31, 2018.
* [HR09] Niall Hurley and Scott Rickard. Comparing measures of sparsity. _IEEE Transactions on Information Theory_, 55(10):4723-4741, 2009.
* [HW01] Mark Herbster and Manfred K Warmuth. Tracking the best linear predictor. _The Journal of Machine Learning Research_, 1:281-309, 2001.
* [HW15] Eric C Hall and Rebecca M Willett. Online convex optimization in dynamic environments. _IEEE Journal of Selected Topics in Signal Processing_, 9(4):647-662, 2015.
* [JC22] Andrew Jacobsen and Ashok Cutkosky. Parameter-free mirror descent. In _Conference on Learning Theory_, pages 4160-4211. PMLR, 2022.
* [Joh19] Iain M Johnstone. Gaussian estimation: Sequence and wavelet models. _Unpublished lecture notes_, 2019. https://imjohnstone.su.domains/GE_09_16_19.pdf.
* [JOWW17] Kwang-Sung Jun, Francesco Orabona, Stephen Wright, and Rebecca Willett. Improved strongly adaptive online learning using coin betting. In _Artificial Intelligence and Statistics_, pages 943-951. PMLR, 2017.
* [JRSS15] Ali Jadbabaie, Alexander Rakhlin, Shahin Shahrampour, and Karthik Sridharan. Online optimization: Competing with dynamic comparators. In _Artificial Intelligence and Statistics_, pages 398-406. PMLR, 2015.
* [Kal14] Satyen Kale. Open problem: Efficient online sparse regression. In _Conference on Learning Theory_, pages 1299-1301. PMLR, 2014.

* [KKLP17] Satyen Kale, Zohar Karnin, Tengyuan Liang, and David Pal. Adaptive feature selection: Computationally efficient online sparse linear regression under rip. In _International Conference on Machine Learning_, pages 1780-1788. PMLR, 2017.
* [KM16] Vitaly Kuznetsov and Mehryar Mohri. Time series prediction and online learning. In _Conference on Learning Theory_, pages 1190-1213. PMLR, 2016.
* [LLZ09] John Langford, Lihong Li, and Tong Zhang. Sparse online learning via truncated gradient. _Journal of Machine Learning Research_, 10(3), 2009.
* [LS15] Haipeng Luo and Robert E Schapire. Achieving all with no parameters: Adamormalhedge. In _Conference on Learning Theory_, pages 1286-1304. PMLR, 2015.
* [MA13] Brendan McMahan and Jacob Abernethy. Minimax optimal algorithms for unconstrained linear optimization. _Advances in Neural Information Processing Systems_, 26:2724-2732, 2013.
* [Mal08] Stephane Mallat. _A Wavelet Tour of Signal Processing: The Sparse Way_. Academic Press, 2008.
* [MK20] Zakaria Mhammedi and Wouter M Koolen. Lipschitz and comparator-norm adaptivity in online learning. In _Conference on Learning Theory_, pages 2858-2887. PMLR, 2020.
* [MO14] H Brendan McMahan and Francesco Orabona. Unconstrained online linear learning in hilbert spaces: Minimax algorithms and normal approximations. In _Conference on Learning Theory_, pages 1020-1039. PMLR, 2014.
* [OP16] Francesco Orabona and David Pal. Coin betting and parameter-free online learning. _Advances in Neural Information Processing Systems_, 29, 2016.
* [Ora19] Francesco Orabona. A modern introduction to online learning. _arXiv preprint arXiv:1912.13213_, 2019.
* [Pri21] Eric Price. Sparse recovery. In Tim Roughgarden, editor, _Beyond the Worst-Case Analysis of Algorithms_, page 140-164. Cambridge University Press, 2021.
* [RS14a] Alexander Rakhlin and Karthik Sridharan. Online non-parametric regression. In _Conference on Learning Theory_, pages 1232-1264. PMLR, 2014.
* [RS14b] Alexander Rakhlin and Karthik Sridharan. Statistical learning and sequential prediction. _Unpublished lecture notes_, 2014. http://www.mit.edu/~rakhlin/courses/stat928/stat928_notes.pdf.
* [SBG\({}^{+}\)21] Martin G Schultz, Clara Betancourt, Bing Gong, Felix Kleinert, Michael Langguth, Lukas Hubert Leufen, Amirpasha Mozaffari, and Scarlet Stadtler. Can deep learning beat numerical weather prediction? _Philosophical Transactions of the Royal Society A_, 379(2194):20200097, 2021.
* [SM12] Matthew Streeter and Brendan Mcmahan. No-regret algorithms for unconstrained online convex optimization. _Advances in Neural Information Processing Systems_, 25, 2012.
* [SS11] Shai Shalev-Shwartz. Online learning and online convex optimization. _Foundations and trends in Machine Learning_, 4(2):107-194, 2011.
* [SST11] Shai Shalev-Shwartz and Ambuj Tewari. Stochastic methods for \(L_{1}\)-regularized loss minimization. _Journal of Machine Learning Research_, 12:1865-1892, 2011.
* [Tib96] Robert Tibshirani. Regression shrinkage and selection via the lasso. _Journal of the Royal Statistical Society: Series B (Methodological)_, 58(1):267-288, 1996.
* [vdH19] Dirk van der Hoeven. User-specified local differential privacy in unconstrained adaptive online learning. _Advances in Neural Information Processing Systems_, 32, 2019.
* [Vov01] Volodya Vovk. Competitive on-line statistics. _International Statistical Review_, 69(2):213-248, 2001.
* [Xia09] Lin Xiao. Dual averaging method for regularized stochastic learning and online optimization. _Advances in Neural Information Processing Systems_, 22, 2009.
* [YZJY16] Tianbao Yang, Lijun Zhang, Rong Jin, and Jinfeng Yi. Tracking slowly moving clairvoyant: Optimal dynamic regret of online learning with true and noisy gradient. In _International Conference on Machine Learning_, pages 449-457. PMLR, 2016.

* [ZCP22] Zhiyu Zhang, Ashok Cutkosky, and Ioannis Paschalidis. PDE-based optimal strategy for unconstrained online learning. In _International Conference on Machine Learning_, pages 26085-26115. PMLR, 2022.
* [Zin03] Martin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In _Proceedings of the 20th International Conference on Machine Learning_, pages 928-936, 2003.
* [ZLZ18] Lijun Zhang, Shiyin Lu, and Zhi-Hua Zhou. Adaptive online learning in dynamic environments. _Advances in neural information processing systems_, 31, 2018.
* [ZYY\({}^{+}\)17] Lijun Zhang, Tianbao Yang, Jinfeng Yi, Rong Jin, and Zhi-Hua Zhou. Improved dynamic regret for non-degenerate functions. _Advances in Neural Information Processing Systems_, 30, 2017.
* [ZYZ\({}^{+}\)18] Lijun Zhang, Tianbao Yang, Zhi-Hua Zhou, et al. Dynamic regret of strongly adaptive methods. In _International conference on machine learning_, pages 5882-5891. PMLR, 2018.
* [ZZZZ20] Peng Zhao, Yu-Jie Zhang, Lijun Zhang, and Zhi-Hua Zhou. Dynamic regret of convex and smooth functions. _Advances in Neural Information Processing Systems_, 33:12510-12520, 2020.
* [ZZZZ21] Peng Zhao, Yu-Jie Zhang, Lijun Zhang, and Zhi-Hua Zhou. Adaptivity and non-stationarity: Problem-dependent dynamic regret for online convex optimization. _arXiv preprint arXiv:2112.14368_, 2021.

## Appendix

OrganizationAppendix A summarizes a list of comparator statistics involved in our theoretical analysis. Appendix B surveys additional related works. Appendix C, D and E respectively present details of our general sparse coding framework, its special version with wavelet dictionaries, and applications in time series forecasting. Finally, Appendix F presents additional discussion of our technical results.

## Appendix A List of comparator statistics

A major task in comparator adaptive online learning is finding suitable statistics to quantify the regularity of a comparator sequence. Several such statistics are defined throughout this paper, which are summarized in Table 2. Note that for the definition of sparsity on the last line, we assume the dictionary \(\mathcal{H}\) is orthogonal, and the sequence \(u_{1:T}\) is contained in its span. Then, \(z^{(n)}\) is defined as the projection of \(u_{1:T}\) onto a feature vector \(h_{1:T,n}\), i.e.,

\[z^{(n)}=\left\langle h_{1:T,n},u_{1:T}\right\rangle\frac{h_{1:T,n}}{\left\|h_{ 1:T,n}\right\|_{2}^{2}}.\]

This is well defined due to our assumption \(\left\|h_{1:T,n}\right\|_{2}\geq 1\) from Section 2.1.

Next, let us discuss their relations, in order to interpret our quantitative contribution more clearly (Table 1). It is clear that \(S\leq MT\), therefore the fine baseline Eq.(4) from [3] improves the coarse one Eq.(3); comparing their associated switching regret bounds follows the same reasoning.

To compare our results to the baselines, observe that

\[\left\|\bar{u}\right\|_{2}\sqrt{T}=\left\|\frac{1}{\sqrt{T}}\sum_{t=1}^{T}u_{ t}\right\|_{2}\leq\sum_{t=1}^{T}\frac{1}{\sqrt{T}}\left\|u_{t}\right\|_{2}\leq \sqrt{E}\leq\sqrt{MS},\]

\[\bar{S}=\sum_{t=1}^{T}\left\|u_{t}-\bar{u}\right\|_{2}\leq\sum_{t=1}^{T}\left\| u_{t}\right\|_{2}+T\left\|\bar{u}\right\|_{2}=\sum_{t=1}^{T}\left\|u_{t} \right\|_{2}+\left\|\sum_{t=1}^{T}u_{t}\right\|_{2}\leq 2S,\]

\[\bar{E}=\sum_{t=1}^{T}\left\|u_{t}-\bar{u}\right\|_{2}^{2}\leq 2M\bar{S}\leq 4MS.\]

Therefore,

\[\left\|\bar{u}\right\|_{2}\sqrt{T}+\sqrt{PS}\leq\sqrt{MS}+2\sqrt{2PS}=O\left( \sqrt{(M+P)S}\right),\]

\[\left\|\bar{u}\right\|_{2}\sqrt{T}+\sqrt{K\bar{E}}\leq\sqrt{MS}+2\sqrt{KMS}=O \left(\sqrt{(1+K)MS}\right).\]

\begin{table}
\begin{tabular}{c c c} Name & Notation & Definition \\ \hline Maximum range & \(M\) & \(\max_{t}\left\|u_{t}\right\|\) \\ Comparator average & \(\bar{u}\) & \(\frac{1}{T}\sum_{t=1}^{T}u_{t}\) \\ Path length & \(P\) & \(\sum_{t=1}^{T-1}\left\|u_{t+1}-u_{t}\right\|_{2}\) \\ Norm sum & \(S\) & \(\sum_{t=1}^{T}\left\|u_{t}\right\|_{2}\) \\ First order variability & \(\bar{S}\) & \(\sum_{t=1}^{T}\left\|u_{t}-\bar{u}\right\|_{2}\) \\ Energy & \(E\) & \(\sum_{t=1}^{T}\left\|u_{t}\right\|_{2}^{2}\) \\ Second order variability & \(\bar{E}\) & \(\sum_{t=1}^{T}\left\|u_{t}-\bar{u}\right\|_{2}^{2}\) \\ Number of switches & \(K\) & \(\sum_{t=1}^{T}\mathbf{1}\!\left[u_{t+1}\neq u_{t}\right]\) \\ Sparsity on a dictionary \(\mathcal{H}\) & \(\mathrm{Sparsity}_{\mathcal{H}}\) & \(\frac{(\sum_{t=1}^{n}\left\|z^{(n)}\right\|_{2})^{2}}{\sum_{t=1}^{n}\left\|z^{ (n)}\right\|_{2}^{2}}\) \\ \end{tabular}
\end{table}
Table 2: A list of comparator statistics.

That is, both our path-length-dependent bound and the switching regret bound are at least as good as the results from [13]. Concrete benefits are demonstrated in Example 1 and 2.

Finally, as a sanity check, our path-length-dependent bound does not violate the lower bound \(\Omega(P)\): even when \(\bar{u}=0\),

\[P=\sum_{t=1}^{T-1}\left\|u_{t+1}-u_{t}\right\|_{2}\leq\sum_{t=1}^{T-1}\left\|u_ {t+1}-\bar{u}\right\|_{2}+\sum_{t=1}^{T-1}\left\|u_{t}-\bar{u}\right\|_{2}\leq 2 \bar{S},\]

therefore our bound is never better than \(\tilde{O}(P)\).

## Appendix B More on related work

Online regressionOur sparse coding framework converts unconstrained dynamic OCO to a special form of online regression. The standard setting of the latter [14] considers a repeated game as well: in each round, we observe a covariate \(x_{t}\in\mathbb{R}^{d}\), make a prediction \(\hat{y}_{t}\in\mathbb{R}\) (which depends on \(x_{t}\)), and then observe a label \(y_{t}\in\mathbb{R}\). The performance metric is the minimax regret under the square loss

\[\mathrm{Regret}_{T}(\mathcal{F})=\sum_{t=1}^{T}(\hat{y}_{t}-y_{t})^{2}-\inf_{ f\in\mathcal{F}}\sum_{t=1}^{T}(f(x_{t})-y_{t})^{2}.\]

Roughly, the problem is of a nonparametric type if the complexity of the function class \(\mathcal{F}\) is not fixed a priori, but grows with \(T\) (i.e., the amount of data).

Overall, such an online regression problem is highly general, as static OCO is recovered if \(x_{t}\) is time-invariant. The setting we utilize is a variant with (\(i\)) vector output; (\(ii\)) general convex losses; (\(iii\)) \(x_{t}\) specified by the dictionary, possibly being sparse itself (e.g., wavelets); and (\(iv\)) the function class \(\mathcal{F}\) being linear, but unbounded. As discussed in Footnote 11, our setting deviates from the conventional definition of regression, as a general convex loss function does not necessarily have minimizers. We adopt the terminology of "regression" for streamlined exposition.

Existing works on online nonparametric regression [14, 1] have established the relation of this problem to certain path length characterizations of dynamic regret. However, the generality of this setting makes the analysis challenging, and especially, algorithms can be computationally expensive. With a bounded domain assumption (on predictions \(\hat{y}_{t}\)), a recent breakthrough [1] simultaneously achieved several notions of optimality for path-length-dependent bounds, with efficient computation. Readers are referred to [1, Appendix A] for a thorough discussion of this line of works.

For the special case of _Online Linear Regression_ (OLR) with square losses, the celebrated VAW forecaster [1, 2] guarantees \(O(N\log T)\) regret against any unbounded coefficient vector \(\hat{u}\in\mathbb{R}^{N}\), where \(N\) is the dimension of the feature space. Such a fast rate becomes vacuous in the nonparametric regime (when \(N>T\)) [1], therefore [10] proposed a _sparsity regret bound_\(\tilde{O}(\left\|\hat{u}\right\|_{0})\) and an accompanying inefficient algorithm as its high dimensional generalization. Efficient computation was addressed by [1], but the obtained result only applies to bounded \(\hat{u}\). In a rough sense, such sparsity regret bounds are the square loss and feature-based analogue of the \(L_{1}\)-norm parameter-free bounds in OLO [12, Chapter 9]. They are also closely related to _sparsity oracle inequalities_ in statistics, as reviewed by [1].

Parametric time series modelsFor time series forecasting, most prior works are devoted to parametric strategies with strong inductive bias, such as the ARMA model, state space models, and more recent deep learning models. Online learning has been applied to such models as well [1, 2, 1, 13, 14], leading to forecasting guarantees under mild statistical assumptions. When convexity is present, some of these problems could be reframed as special cases of our OLR problem, with a constant-size dictionary that does not grow with \(T\); for example, learning the _autoregressive_ model corresponds to defining the features as the fixed-length observation history. Also, Appendix E shows that given a parametric time series forecaster (possibly without performance guarantees), our algorithm can be applied on top of it, in order to provably correct its nonstationary bias.

Other sparsity topics in OLFinally, we review other sparsity-related topics in online learning, which do not fit into the scope of this paper. [1, 2, 13, 12] considered usingonline learning to solve batch \(L_{1}\) regularized problems. The goal is to achieve sparse predictions instead of sparsity adaptive regret bounds. [12, 13, 14] studied _online sparse regression_, where only a subset of features are available in each round. The challenge is to handle bandit feedback in OLR.

## Appendix C Detail on the general framework

This section presents details on our general sparse coding framework. Appendix C.1 introduces the static subroutine we adopt from [10]. Appendix C.2 proves our main results, but with additional gradient adaptivity compared to the main paper.

### Unconstrained static subroutine

The following static OCO algorithm and its guarantee are due to [10, Section 3.1]. We assume that \(\left\lVert\hat{g}_{t}\right\rVert_{2}\leq\hat{G}\), and \(\hat{G}>0\).

```
0: A hyperparameter \(\varepsilon>0\); dimension \(d\); Lipschitz constant \(\hat{G}\).
1: Initialize a gradient sum counter \(s=0\in\mathbb{R}^{d}\) and a variance counter \(v=\hat{G}^{2}\).
2:for\(t=1,2,\ldots\)do
3: Predict \[\hat{x}_{t}=-\varepsilon s\cdot\frac{(2v+\hat{G}\left\lVert s\right\rVert_{2}) \hat{G}^{2}}{2(v+\hat{G}\left\lVert s\right\rVert_{2})^{2}\sqrt{v}}\cdot \exp\left(\frac{\left\lVert s\right\rVert_{2}^{2}}{2v+2\hat{G}\left\lVert s \right\rVert_{2}}\right).\]
4: Observe the loss gradient \(\hat{g}_{t}\).
5: Update \(s\gets s+\hat{g}_{t}\), and \(v\gets v+\hat{g}_{t}^{2}\).
6:endfor ```

**Algorithm 3** FreeGrad[10, Definition 4]: scale-free and gradient adaptive unconstrained static OLO.

**Lemma C.1** (Theorem 20 of [10]).: _With any hyperparameter \(\varepsilon>0\), for all \(T\in\mathbb{N}_{+}\) and \(\hat{u}\in\mathbb{R}\), Algorithm 3 guarantees_

\[\sum_{t=1}^{T}\left\langle\hat{g}_{t},\hat{x}_{t}-\hat{u}\right\rangle\leq \varepsilon\hat{G}+\left[2\left\lVert\hat{u}\right\rVert_{2}\sqrt{V_{T}\log_{ +}\left(\frac{2\left\lVert\hat{u}\right\rVert_{2}V_{T}}{\varepsilon\hat{G}^{2 }}\right)}\right]\vee\left[4\left\lVert\hat{u}\right\rVert_{2}\hat{G}\log \left(\frac{4\left\lVert\hat{u}\right\rVert_{2}\sqrt{V_{T}}}{\varepsilon\hat{G }}\right)\right],\]

_where_

\[V_{T}=\hat{G}^{2}+\sum_{t=1}^{T}\left\lVert\hat{g}_{t}\right\rVert_{2}^{2}.\]

### Proof of the main result

We now present the analysis of our general sparse coding framework. The following lemma is a slightly more general version of Lemma 2.1 in the main paper, which characterizes the performance of our single direction learner (Algorithm 1). Recall that \(g_{t}\in\partial l_{t}(x_{t})\) from the OCO-OLO reduction.

**Lemma C.2** (Lemma 2.1, full).: _Let \(\varepsilon>0\) be an arbitrary hyperparameter for Algorithm 3. Applying its 1D version as the static subroutine, for all \(T\in\mathbb{N}_{+}\) and \(u_{1:T}\in\mathrm{span}(h_{1:T})\), against any adversary \(\mathcal{E}\), Algorithm 1 guarantees_

\[\sum_{t=1}^{T}l_{t}(x_{t})-\sum_{t=1}^{T}l_{t}(u_{t})\leq\varepsilon G+\left( G\frac{\left\lVert u_{1:T}\right\rVert_{2}}{\left\lVert h_{1:T}\right\rVert_{2}}+ \sqrt{\sum_{t=1}^{T}\left\langle g_{t},u_{t}\right\rangle^{2}}\right)\cdot \mathrm{polylog}\left(\max_{t}\left\lVert u_{t}\right\rVert_{2},T,\varepsilon^ {-1}\right).\]

The simplified form (Lemma 2.1) is recovered by using \(\left\lVert h_{1:T}\right\rVert_{2}\geq 1\) and \(\left\lVert g_{t}\right\rVert_{2}\leq G\).

Proof of Lemma 2.1.: Subsuming poly-logarithmic factors, the static regret bound of our static subroutine (Algorithm 3) can be written as

\[\sum_{t=1}^{T}\hat{g}_{t}\left(\hat{x}_{t}-\hat{u}\right)\leq\varepsilon\hat{G}+ \left|\hat{u}\right|\left(\hat{G}+\sqrt{\sum_{t=1}^{T}\hat{g}_{t}^{2}}\right) \cdot\mathrm{polylog}\left(\left|\hat{u}\right|,T,\varepsilon^{-1}\right),\]

where \(\hat{u}\) is any 1D static comparator that the subroutine handles.

Now, for any single-directional comparator \(u_{1:T}\in\mathrm{span}(h_{1:T})\) considered in this lemma, there exists \(\hat{u}\in\mathbb{R}\) such that \(u_{1:T}=\hat{u}h_{1:T}\). The dynamic regret can be rewritten as

\[\sum_{t=1}^{T}l_{t}(x_{t})-\sum_{t=1}^{T}l_{t}(u_{t})\leq\sum_{t=1}^{T}\left<g _{t},x_{t}-u_{t}\right>=\sum_{t=1}^{T}\left<g_{t},h_{t}\hat{x}_{t}-h_{t}\hat {u}\right>=\sum_{t=1}^{T}\hat{g}_{t}(\hat{x}_{t}-\hat{u}),\]

and the RHS can be bounded using the static regret bound above. Note that \(\left|\hat{g}_{t}\right|=\left|\left<g_{t},h_{t}\right>\right|\leq G\), therefore the surrogate Lipschitz constant \(\hat{G}\) from the static regret bound can be assigned to \(G\).

In summary,

\[\sum_{t=1}^{T}l_{t}(x_{t})-\sum_{t=1}^{T}l_{t}(u_{t}) \leq\varepsilon G+\left|\hat{u}\right|\left(G+\sqrt{\sum_{t=1}^{ T}\left<g_{t},h_{t}\right>^{2}}\right)\cdot\mathrm{polylog}\left(\left|\hat{u} \right|,T,\varepsilon^{-1}\right)\] \[=\varepsilon G+\left(G\frac{\left\|u_{1:T}\right\|_{2}}{\left\|h _{1:T}\right\|_{2}}+\sqrt{\sum_{t=1}^{T}\left<g_{t},u_{t}\right>^{2}}\right) \cdot\mathrm{polylog}\left(\frac{\left\|u_{1:T}\right\|_{2}}{\left\|h_{1:T} \right\|_{2}},T,\varepsilon^{-1}\right)\] \[\leq\varepsilon G+\left(G\frac{\left\|u_{1:T}\right\|_{2}}{\left\| h_{1:T}\right\|_{2}}+\sqrt{\sum_{t=1}^{T}\left<g_{t},u_{t}\right>^{2}}\right) \cdot\mathrm{polylog}\left(\max_{t}\left\|u_{t}\right\|_{2},T,\varepsilon^{-1 }\right),\]

where the last line is due to our assumption that \(\left\|h_{1:T}\right\|_{2}\geq 1\). 

Next, we prove the unconstrained dynamic regret bound with general dictionaries (Theorem 1).

**Theorem 4** (Theorem 1, full).: _Consider any collection of signals \(z^{(n)}\in\mathrm{span}(h_{1:T,n})\), \(\forall n\). We define its reconstruction error (for the comparator \(u_{1:T}\)) as \(z^{(0)}=u_{1:T}-\sum_{n=1}^{N}z^{(n)}\in\mathbb{R}^{dT}\). Then, for all \(T\in\mathbb{N}_{+}\) and \(u_{1:T}\in\mathbb{R}^{dT}\), against any adversary \(\mathcal{E}\), Algorithm 2 guarantees_

\[\sum_{t=1}^{T}l_{t}(x_{t})-\sum_{t=1}^{T}l_{t}(u_{t})\leq \varepsilon G-\sum_{t=1}^{T}\left<g_{t},z_{t}^{(0)}\right>\\ +\left(G\sum_{n=1}^{N}\frac{\left\|z^{(n)}\right\|_{2}}{\left\|h _{1:T,n}\right\|_{2}}+\sum_{n=1}^{N}\sqrt{\sum_{t=1}^{T}\left<g_{t},z_{t}^{(n) }\right>^{2}}\right)\cdot\mathrm{polylog}\left(\max_{t,n}\left\|z_{t}^{(n)} \right\|_{2},T,N,\varepsilon^{-1}\right),\]

_where \(z_{t}^{(n)}\in\mathbb{R}^{d}\) is the \(t\)-th round component of the sequence \(z^{(n)}\in\mathbb{R}^{dT}\)._

Proof of Theorem 4.: The idea of this theorem is a dynamic analogue of [10] to aggregate the regret bound of single direction learners. For all decomposition \(u_{1:T}=\sum_{n=0}^{N}z^{(n)}\) such that \(z^{(n)}\in\mathrm{span}(h_{1:T,n})\) for all \(n\in[1:T]\), we have

\[\sum_{t=1}^{T}l_{t}(x_{t})-\sum_{t=1}^{T}l_{t}(u_{t})\leq\left<g_{1:T},x_{1:T}-u _{1:T}\right>=\left<-g_{1:T},z^{(0)}\right>+\sum_{n=1}^{N}\left<g_{1:T},w_{1:T,n}-z^{(n)}\right>.\]For the first term on the RHS, \(\left\langle-g_{1:T},z^{(0)}\right\rangle=-\sum_{t=1}^{T}\left\langle g_{t},z_{t}^ {(n)}\right\rangle\). As for the rest, we plug in Lemma C.2, with hyperparameter \(\varepsilon/N\).

\[\sum_{n=1}^{N}\left\langle g_{1:T},w_{1:T,n}-z^{(n)}\right\rangle\] \[\leq \sum_{n=1}^{N}\left\{\varepsilon N^{-1}G+\left(G\frac{\left\|z^{( n)}\right\|_{2}}{\left\|h_{1:T,n}\right\|_{2}}+\sqrt{\sum_{t=1}^{T}\left\langle g _{t},z_{t}^{(n)}\right\rangle^{2}}\right)\cdot\mathrm{polylog}\left(\max_{t} \left\|z_{t}^{(n)}\right\|_{2},T,N,\varepsilon^{-1}\right)\right\}\] \[\leq \varepsilon G+\left(G\sum_{n=1}^{N}\frac{\left\|z^{(n)}\right\|_{2 }}{\left\|h_{1:T,n}\right\|_{2}}+\sum_{n=1}^{N}\sqrt{\sum_{t=1}^{T}\left\langle g _{t},z_{t}^{(n)}\right\rangle^{2}}\right)\cdot\mathrm{polylog}\left(\max_{t, n}\left\|z_{t}^{(n)}\right\|_{2},T,N,\varepsilon^{-1}\right).\qed\]

Next, we show how this dynamic regret bound recovers the static regret bound in \(\mathbb{R}^{d}\). As discussed in Section 2.2, the static setting amounts to picking \(N=d\) and \(\mathcal{H}_{t}=I_{d}\), and the decomposed signals \(z^{(n)}\) are determined by orthogonal projection of the static comparator sequence \(u_{1:T}=[u,\ldots,u]\).

Specifically, \(z_{t}^{(n)}\) is a \(d\)-dimensional vector which is zero except the \(n\)-th entry; its \(n\)-th entry equals the \(n\)-th entry of the static comparator \(u\). If we index the gradient as \(g_{t}=[g_{t,1},\ldots,g_{t,d}]\in\mathbb{R}^{d}\) and the static comparator as \(u=[u_{1},\ldots,u_{d}]\in\mathbb{R}^{d}\), then \(\left\langle g_{t},z_{t}^{(n)}\right\rangle=g_{t,n}u_{n}\). Applying Theorem 4, against static \(u_{1:T}\),

\[\sum_{t=1}^{T}l_{t}(x_{t})-\sum_{t=1}^{T}l_{t}(u_{t})\] \[\leq\varepsilon G+\left(G\sum_{n=1}^{N}\frac{\left\|z^{(n)} \right\|_{2}}{\left\|h_{1:T,n}\right\|_{2}}+\sum_{n=1}^{N}\sqrt{\sum_{t=1}^{T }\left\langle g_{t},z_{t}^{(n)}\right\rangle^{2}}\right)\cdot\mathrm{polylog} \left(\max_{t,n}\left\|z_{t}^{(n)}\right\|_{2},T,N,\varepsilon^{-1}\right)\] \[\leq\varepsilon G+\left(G\sum_{i=1}^{d}\frac{\left|u_{i}\right| \sqrt{T}}{\sqrt{T}}+\sum_{i=1}^{d}\left|u_{i}\right|\sqrt{\sum_{t=1}^{T}g_{t,i }^{2}}\right)\cdot\mathrm{polylog}\left(\left\|u\right\|_{\infty},T,N, \varepsilon^{-1}\right)\] \[\leq\varepsilon G+\left(G\left\|u\right\|_{1}+\left\|u\right\|_{2 }\sqrt{\sum_{t=1}^{T}\left\|g_{t}\right\|_{2}^{2}}\right)\cdot\mathrm{polylog} \left(\left\|u\right\|_{\infty},T,N,\varepsilon^{-1}\right).\qed\]

In the asymptotic regime with large \(T\), \(\mathrm{Regret}_{T}(u_{1:T})=\tilde{O}(\left\|u\right\|_{2}\sqrt{T})\).

## Appendix D Detail on the wavelet algorithm

This section presents details of our wavelet algorithm. The pseudocode is presented in Appendix D.1. Appendix D.2 introduces the wavelet-specific notations for our analysis. Appendix D.3 presents a generic sparsity based bound for our algorithm. Appendix D.4 and D.5 prove our main results. Auxiliary lemmas are contained in Appendix D.6. Finally, Appendix D.7 works out the details of the two examples from the main paper.

### Pseudocode

For all \(m\in\mathbb{N}_{+}\), let \(T=2^{m}\), and let \(\mathrm{Haar}_{m}\) be the \(T\times T\) Haar dictionary matrix defined in Section 3.1, for \(d=1\). We apply the following variant (Algorithm 4) of our sparse coding framework, in order to remove all \(d\) dependence from the final regret bound. It adopts the \(d\) dimensional version of the static subroutine (FreeGrad), instead of the 1D version in Section 2. The pseudocode mirrors the combination of Algorithm 1 and 2.

It is equivalent to view Algorithm 4 as operating on a \(dT\times dT\) "master" dictionary matrix \(\mathcal{H}\), defined block-wise as the following: for all \((i,j)\in[1:T]^{2}\), the \((i,j)\)-th block of \(\mathcal{H}\) is the product of the \((i,j)\)-th entry of \(\operatorname{Haar}_{m}\) (which is a scalar) and the \(d\)-dimensional identity matrix \(I_{d}\). That is, \(\mathcal{H}\) is a block matrix; each block is a diagonal matrix with equal diagonal entries determined by \(\operatorname{Haar}_{m}\). Roughly, the algorithm measures distances in \(\mathbb{R}^{d}\) by the \(L_{2}\) norm, while measuring \(\mathbb{R}^{T}\) by the \(L_{1}\) norm.

Algorithm 4 alone is not sufficient for our purpose: it must take an integer \(m\) and run for a fixed \(T=2^{m}\) rounds. We apply a meta algorithm (Algorithm 5), which simply restarts the known \(T\) algorithm using the classical doubling trick, c.f., [11, Section 2.3.1].

```
1:for\(m=1,2,\ldots,\)do
2: Run Algorithm 4 for \(2^{m}\) rounds, which uses the matrix \(\operatorname{Haar}_{m}\). The hyperparameter is set to 1.
3:endfor ```

**Algorithm 5** Anytime Haar OLR (Algorithm 4 with doubling trick).

### More background

Although the analysis of our framework is simpler than [10], a challenge is carefully indexing all the quantities to account for the vectorized setting. It is thus important to introduce a few notations to streamline the presentation. \(\operatorname{Haar}_{m}\) is the \(T\times T\) Haar dictionary matrix defined in Section 3.1, with \(T=2^{m}\). Recall the statistics of the comparator sequence, summarized in Appendix A.

Local intervalGiven any scale-location pair \((j,l)\), let the support \(I^{(j,l)}\) be the time interval where the feature \(h^{(j,l)}\) is nonzero. That is,

\[I^{(j,l)}:=[2^{j}(l-1)+1:2^{j}l].\]

Moreover, let \(I^{(j,l)}_{+}\) denote the first half of this interval, and \(I^{(j,l)}_{-}\) for the second half. \(h^{(j,l)}\) is \(1\) on \(I^{(j,l)}_{+}\), and \(-1\) on \(I^{(j,l)}_{-}\).

NormalizationLet \(\tilde{\operatorname{Haar}}_{m}\) be the orthonormal matrix obtained by scaling the columns of \(\operatorname{Haar}_{m}\). The normalized feature vectors are also denoted by tilde, i.e., instead of \(h^{*}\) and \(h^{(j,l)}\), the normalized features are \(\tilde{h}^{*}\) and \(\tilde{h}^{(j,l)}\). They are vectors in \(\mathbb{R}^{T}\), with the \(t\)-th component denoted by \(\tilde{h}^{*}_{t}\) and \(\tilde{h}^{(j,l)}_{t}\), in \(\mathbb{R}\).

Coordinate sequenceConsider any comparator sequence \(u_{1:T}\in\mathbb{R}^{dT}\). For all coordinate \(i\in[1:d]\), we define its \(i\)-th coordinate sequence as \(u^{(i)}_{1:T}\in\mathbb{R}^{T}\): the \(t\)-th entry of this coordinate sequence \(u^{(i)}_{1:T}\), denoted by \(u^{(i)}_{t}\), is the \(i\)-th coordinate of \(u_{t}\).

Transform domain coefficientWe will also use the transform domain coefficients of \(u_{1:T}\), under the Haar wavelet transform. Recall that in the single-feature, generic setting (Section 2.2), we denoted a single transform domain coefficient by \(\hat{u}\in\mathbb{R}\). With wavelets, the transform domain encodes \(dT\)-dimensional vectors. According to our convention so far, we will denote them by scale-location pairs \((j,l)\): given a \((j,l)\) pair, the "coefficient" \(\hat{u}^{(j,l)}\) is a \(d\)-dimensional vector. There are \(T-1\) pairs of \((j,l)\) in total; complementing the representation, we use another \(\hat{u}^{*}\in\mathbb{R}^{d}\) to represent the "coefficient" for the all-one feature.

Given any scale parameter \(j\in[1:\log_{2}T]\) and location parameter \(l\in[1:2^{-j}T]\), let

\[\hat{u}^{(j,l)}:=\left[\left\langle\tilde{h}^{(j,l)},u_{1:T}^{(1)}\right\rangle,\ldots,\left\langle\tilde{h}^{(j,l)},u_{1:T}^{(d)}\right\rangle\right],\]

and for the all-one feature,

\[\hat{u}^{*}:=\left[\left\langle\tilde{h}^{*},u_{1:T}^{(1)}\right\rangle,\ldots,\left\langle\tilde{h}^{*},u_{1:T}^{(d)}\right\rangle\right].\]

That is, each entry is the inner product between the normalized feature and a coordinate sequence from \(u_{1:T}\).

Due to the orthonormality of the applied transform (specified by the normalized features \(\tilde{h}^{*}\) and \(\tilde{h}^{(j,l)}\)), the energy is preserved between the time domain and the transform domain, i.e.,

\[E=\left\|u_{1:T}\right\|_{2}^{2}=\left\|\hat{u}^{*}\right\|_{2}^{2}+\sum_{j,l }\left\|\hat{u}^{(j,l)}\right\|_{2}^{2},\]

and also the second order variability (the energy of the centered dynamic component within \(u_{1:T}\)),

\[\bar{E}=\sum_{t=1}^{T}\left\|u_{t}-\bar{u}\right\|_{2}^{2}=\sum_{j,l}\left\| \hat{u}^{(j,l)}\right\|_{2}^{2}.\] (11)

Moreover, since \(\tilde{h}^{*}\) equals \(1/\sqrt{T}\) times the all-one vector,

\[\left\|\hat{u}^{*}\right\|_{2}^{2}=\sum_{i=1}^{d}\left\langle\tilde{h}^{*},u_ {1:T}^{(i)}\right\rangle^{2}=\sum_{i=1}^{d}\left(\frac{1}{\sqrt{T}}\sum_{t}u_ {1:T}^{(i)}\right)^{2}=T\sum_{i=1}^{d}\left(\frac{1}{T}\sum_{t}u_{1:T}^{(i)} \right)^{2}=\left\|\bar{u}\right\|_{2}^{2}T.\] (12)

Detail reconstructionGiven the transform domain coefficients, we can reconstruct details of the comparator \(u_{1:T}\) on the time domain. Similar to our notation in the generic framework (Section 2.2), we keep the letter \(z\), but replace the index \(n\) by \((j,l)\), which is more suitable for indexing wavelets.

Let \(z^{(j,l)}\in\mathbb{R}^{dT}\) be the detail of \(u_{1:T}\) along the \((j,l)\)-th feature. It is the concatenation of \(T\) vectors in \(\mathbb{R}^{d}\), and for all \(t\), the \(t\)-th of these vectors is defined by

\[z_{t}^{(j,l)}:=\hat{u}^{(j,l)}\tilde{h}_{t}^{(j,l)}\in\mathbb{R}^{d}.\]

Similarly, we can define the detail \(z^{*}\) along the feature \(\tilde{h}^{*}\). Its \(t\)-th component is

\[z_{t}^{*}:=\hat{u}^{*}\tilde{h}_{t}^{*},\]

and clearly, the RHS does not depend on \(t\) since \(\tilde{h}^{*}\) is the normalization of the all-one feature \(h^{*}\).

Let us also sum the details across different locations. Given a scale \(j\), let

\[z^{(j)}:=\sum_{l}z^{(j,l)}\in\mathbb{R}^{dT}.\]

Note that the summands are sequences that do not overlap: at each entry, only one of the summand sequence is nonzero. The full reconstruction is obtained by summing all the details,

\[u_{1:T}:=z^{*}+\sum_{j=1}^{\log_{2}T}z^{(j)}.\]Statistics of the detail sequenceWe can define statistics of the detail sequences just like the statistics of the comparator \(u_{1:T}\). Specifically, define the first order variability of the \((j,l)\)-th detail as

\[\bar{S}^{(j,l)}:=\sum_{t=1}^{T}\left\|z_{t}^{(j,l)}\right\|_{2}.\]

Note that since the \(z_{t}^{(j,l)}\) sequence is centered (with average being equal to \(0\)), its first order variability equals its norm sum, c.f., Appendix A. Summing over the locations, the first order variability at the \(j\)-th scale is

\[\bar{S}^{(j)}:=\sum_{t=1}^{T}\left\|z_{t}^{(j)}\right\|_{2},\]

which equals \(\sum_{l}\bar{S}^{(j,l)}\).

Similarly, we can define the path length of the detail sequences. A caveat is that we only count the path length _within_ the support \(I^{(j,l)}\) of the feature \(h^{(j,l)}\),

\[P^{(j,l)}:=\sum_{t=2^{j}(l-1)+1}^{2^{j}l-1}\left\|z_{t+1}^{(j,l)}-z_{t}^{(j,l)} \right\|_{2}.\]

The comparator's movement when the support changes does not count. Summing over the locations,

\[P^{(j)}:=\sum_{l}P^{(j,l)}.\]

### Generic sparsity adaptive bound

With the notation from the previous subsection, we now present a generic sparsity adaptive regret bound for Algorithm 4 (fixed \(T\) Haar OLR). Since the latter is a variant of our main sparse coding framework (Section 2), the result can be analogously derived, although the notations need to be treated carefully.

**Lemma D.1**.: _For any \(m\), \(T=2^{m}\) and \(u_{1:T}\in\mathbb{R}^{dT}\), with any hyperparameter \(\varepsilon>0\), Algorithm 4 guarantees_

\[\operatorname{Regret}_{T}(u_{1:T})\leq\varepsilon G+G\left(\left\|z^{*} \right\|_{2}+\sum_{j=1}^{\log_{2}T}\sum_{l=1}^{2^{-j}T}\left\|z^{(j,l)} \right\|_{2}\right)\cdot\operatorname{polylog}\left(M,T,\varepsilon^{-1} \right).\]

The proof sums the regret bound of the \(d\)-dimensional version of the static subroutine (Lemma C.1), across \(T\) different copies. It is very similar to Theorem 1, therefore omitted.

It might be more convenient to use the transform domain coefficients \(\hat{u}^{(j,l)}\) in the bound, rather than the reconstructed details \(z^{(j,l)}\). In this case, we have

\[\left\|z^{(j,l)}\right\|_{2}^{2}=\sum_{t}\left\|z_{t}^{(j,l)}\right\|_{2}^{2 }=\sum_{t}\left[\left\|\hat{u}^{(j,l)}\right\|_{2}^{2}\left|\tilde{h}_{t}^{(j,l)}\right|^{2}\right]=\left\|\hat{u}^{(j,l)}\right\|_{2}^{2}\sum_{t}\left| \tilde{h}_{t}^{(j,l)}\right|^{2}=\left\|\hat{u}^{(j,l)}\right\|_{2}^{2}.\]

Similarly,

\[\left\|z^{*}\right\|_{2}^{2}=\left\|\hat{u}^{*}\right\|_{2}^{2}.\]

Therefore,

\[\operatorname{Regret}_{T}(u_{1:T})\leq\varepsilon G+G\left(\left\|\hat{u}^{*} \right\|_{2}+\sum_{j=1}^{\log_{2}T}\sum_{l=1}^{2^{-j}T}\left\|\hat{u}^{(j,l)} \right\|_{2}\right)\cdot\operatorname{polylog}\left(M,T,\varepsilon^{-1} \right).\] (13)

### Unconstrained switching regret

In the \(K\)-switching regret, the complexity of the comparator is characterized by its amount of switches. The idea is that, if the comparator \(u_{1:T}\) is static on a support \(I^{(j,l)}\) for some \((j,l)\), then the corresponding transform domain coefficient \(\hat{u}^{(j,l)}=0\in\mathbb{R}^{d}\). We have the following bound for the fixed \(T\) algorithm (Algorithm 4).

**Lemma D.2**.: _For any \(m,\,T=2^{m}\) and \(u_{1:T}\in\mathbb{R}^{dT}\), Algorithm 4 with the hyperparameter \(\varepsilon=1\) guarantees_

\[\mathrm{Regret}_{T}(u_{1:T})=\tilde{O}\left(\left\|\bar{u}\right\|_{2}\sqrt{T} +\sqrt{K\bar{E}}\right).\]

Proof of Lemma d.2.: Consider any scale \(j\). Since the supports \(\{I^{(j,l)}\}_{l}\) do not overlap, if \(u_{1:T}\) shifts \(K\) times, then there are at most \(K\) choices of location \(l\) such that the transform domain coefficient \(\hat{u}^{(j,l)}\) is nonzero. Furthermore, since there are \(\log_{2}T\) scales in total, there are at most \(K\log_{2}T\) pairs of \((i,l)\) such that \(\hat{u}^{(j,l)}\) is nonzero. Therefore, using Cauchy-Schwarz and Eq.(11),

\[\sum_{j,l}\left\|\hat{u}^{(j,l)}\right\|_{2}\leq\sqrt{K\log_{2}T}\sqrt{\sum_{ j,l}\left\|\hat{u}^{(j,l)}\right\|_{2}^{2}}=\sqrt{K\bar{E}\log_{2}T}.\]

Plugging this into Eq.(13), and further using Eq.(12) for \(\left\|\hat{u}^{*}\right\|_{2}\) complete the proof. 

The anytime bound in general follows from the classical doubling trick. A twist is that the analysis is slightly more involved than the standard one, e.g., [11, Section 2.3.1], as we also need to relate the comparator statistics on each block to those for the entire signal \(u_{1:T}\).

**Theorem 2** (Switching regret).: _For all \(T\in\mathbb{N}_{+}\) and \(u_{1:T}\in\mathbb{R}^{dT}\), Algorithm 5 guarantees_

\[\mathrm{Regret}_{T}(u_{1:T})\leq\tilde{O}\left(\left\|\bar{u}\right\|_{2}\sqrt {T}+\sqrt{K\bar{E}}\right).\] (9)

Proof of Theorem 2.: First, assume \(T\) can be exactly decomposed into \(m^{*}\) segments with dyadic lengths \(2^{1},\ldots,2^{m^{*}}\). We use \(\bar{u}_{m}\), \(K_{m}\) and \(\bar{E}_{m}\) to represent the statistics of the comparator sequence on the length \(2^{m}\) block, and let \(I^{m}\) denote the time interval that this block operates on. \(\bar{u}\), \(K\) and \(S\) denote the statistics of the entire signal \(u_{1:T}\), c.f., Appendix A. From Lemma D.2,

\[\mathrm{Regret}_{T}(u_{1:T}) \leq\sum_{m=1}^{m^{*}}\tilde{O}\left(\left\|\bar{u}_{m}\right\|_ {2}\sqrt{2^{m}}+\sqrt{K_{m}\bar{E}_{m}}\right)\] \[\leq\tilde{O}\left[\left\|\bar{u}\right\|_{2}\left(\sum_{m=1}^{m^ {*}}\sqrt{2^{m}}\right)+\sum_{m=1}^{m^{*}}\left\|\bar{u}_{m}-\bar{u}\right\|_ {2}\sqrt{2^{m}}+\sum_{m=1}^{m^{*}}\sqrt{K_{m}\bar{E}_{m}}\right].\] (14)

The first term follows from the standard doubling trick analysis [11, Section 2.3.1],

\[\sum_{m=1}^{m^{*}}\sqrt{2^{m}}\leq\frac{\sqrt{2}}{\sqrt{2-1}}\sqrt{2^{m^{*}}} =O\left(\sqrt{T}\right).\] (15)

As for the second term in Eq.(14), using Cauchy-Schwarz,

\[\sum_{m=1}^{m^{*}}\left\|\bar{u}_{m}-\bar{u}\right\|_{2}\sqrt{2^{m}}\leq\sqrt {m^{*}\left(\sum_{m=1}^{m^{*}}2^{m}\left\|\bar{u}_{m}-\bar{u}\right\|_{2}^{2} \right)}.\]

\(m^{*}=O(\log T)\), and also observe that the sum (in the parenthesis) on the RHS equals the second order variability of the following signal: for any time \(t\) in the \(m\)-th block, the signal's component is \(\bar{u}_{m}\in\mathbb{R}^{d}\). This signal is a locally averaged version of the original comparator \(u_{1:T}\), and the key idea is that local averaging decreases the variability. Formally, due to Lemma D.7, we have

\[\sum_{m=1}^{m^{*}}\left\|\bar{u}_{m}-\bar{u}\right\|_{2}\sqrt{2^{m}}\leq\tilde {O}\left(\sqrt{\bar{E}}\right).\] (16)

For the third term in Eq.(14), using Cauchy-Schwarz again,

\[\sum_{m=1}^{m^{*}}\sqrt{K_{m}\bar{E}_{m}}\leq\sqrt{\left(\sum_{m=1}^{m^{*}}K_{ m}\right)\left(\sum_{m=1}^{m^{*}}\bar{E}_{m}\right)}\leq\sqrt{K\bar{E}}.\]The sum of \(K_{m}\) is straightforward. The inequality for the sum of \(\bar{E}_{m}\) follows from the observation that on the \(m\)-th block, \(\bar{u}_{m}\) minimizes \(\sum_{t\in I^{m}}\left\|u_{t}-x\right\|_{2}^{2}\) with respect to \(x\in\mathbb{R}^{d}\).

Also, notice that the second term in Eq.(14) is dominated by the third term. If \(K=0\), then both \(\sqrt{E}\) and \(\sqrt{K\bar{E}}\) equal 0. If \(K\geq 1\), then \(\sqrt{\bar{E}}\leq\sqrt{K\bar{E}}\). Therefore, Eq.(14) can be written as

\[\mathrm{Regret}_{T}(u_{1:T})\leq\tilde{O}\left(\left\|\bar{u}\right\|_{2} \sqrt{T}+\sqrt{K\bar{E}}\right).\]

As for the general setting where \(T\) cannot be exactly decomposed into dyadic blocks: consider the smallest \(T^{*}>T\) such that \(T^{*}\) can be decomposed. Due to doubling intervals, \(T^{*}\leq 2T\). Let us consider a hypothetical length \(T^{*}\) game with the rounds \(t\geq T\) constructed as follows: the loss gradient \(g_{t}=0\in\mathbb{R}^{d}\), and \(u_{t}=\bar{u}\). In this case, with \(K\) and \(\bar{E}\) still representing the statistics of the length \(T\) sequence \(u_{1:T}\), the number of switches on the entire time interval \([1:T^{*}]\) is at most \(K+1\), and the second order variability on \([1:T^{*}]\) is \(\bar{E}\); furthermore, it is clear that \((K+1)\bar{E}\leq 2K\bar{E}\). The regret of any algorithm on this hypothetical length \(T^{*}\) game is the same as the length \(T\) game, therefore bounding the latter follows from bounding the former. 

### Path-length-based bound

Next, we turn to bounds that depend on the path length \(P\) of the comparator \(u_{1:T}\). Similar to the switching regret analysis, we will first consider the setting with fixed dyadic \(T\) (Algorithm 4), and then extend its guarantee through a doubling trick.

#### d.5.1 Fixed dyadic horizon

In the following, we consider Algorithm 4; assume \(T=2^{m}\) for some \(m\). The static component (i.e., \(z^{*}\)) and the dynamic component (i.e., \(u_{1:T}-z^{*}\)) of \(u_{1:T}\) are analyzed separately; the former is fairly standard, while the latter is more challenging. We will first consider the dynamic component, and proceed in three steps.

Step 1Considering any scale \(j\), we aim to show \(\sum_{l}\left\|\hat{u}^{(j,l)}\right\|_{2}\leq\sqrt{P^{(j)}\bar{S}^{(j)}}\), which relates the transform domain coefficients to the regularity of the reconstructed signals.

**Lemma D.3**.: _For all \((j,l)\) pair,_

\[\left\|\hat{u}^{(j,l)}\right\|_{2}=2^{-1/2}\sqrt{P^{(j,l)}\bar{S}^{(j,l)}},\]

_and_

\[\sum_{l}\left\|\hat{u}^{(j,l)}\right\|_{2}\leq 2^{-1/2}\sqrt{P^{(j)}\bar{S}^{(j)}}.\]

Proof of Lemma d.3.: Let us start from the first part of this lemma, and express the detail sequence \(z^{(j,l)}\), and equivalently \(z^{(j)}\), more explicitly on its support \(I^{(j,l)}\).

\[z^{(j)}_{t}=\begin{cases}2^{-j/2}\hat{u}^{(j,l)},&t\in I^{(j,l)}_{+};\\ -2^{-j/2}\hat{u}^{(j,l)},&t\in I^{(j,l)}_{-}.\end{cases}\]

Rewriting \(P^{(j,l)}\) and \(\bar{S}^{(j,l)}\),

\[P^{(j,l)}=\sum_{t=2^{j}(l-1)+1}^{2^{j}l-1}\left\|z^{(j)}_{t+1}-z^{(j)}_{t} \right\|_{2}=2^{1-j/2}\left\|\hat{u}^{(j,l)}\right\|_{2}.\]

\[\bar{S}^{(j,l)}=\sum_{t\in I^{(j,l)}}\left\|z^{(j)}_{t}\right\|_{2}=2^{-j/2} \left\|\hat{u}^{(j,l)}\right\|_{2}\cdot 2^{j}=2^{j/2}\left\|\hat{u}^{(j,l)} \right\|_{2},\]

which yields the equality in the lemma. The second part follows from Cauchy-Schwarz.

Step 2Showing that \(P^{(j)}\leq P\) and \(\bar{S}^{(j)}\leq\bar{S}\). That is, the reconstructed signals are easier than the original comparator \(u_{1:T}\). Here, \(P\) and \(\bar{S}\) should be considered separately.

**Lemma D.4**.: _For any \(u_{1:T}\) and any scale parameter \(j^{*}\), \(P^{(j^{*})}\leq P\)._

Proof of Lemma D.4.: From the definition of \(P\) and the reconstruction of \(u_{1:T}\) from detail sequences,

\[P=\sum_{t=1}^{T-1}\left\|u_{t+1}-u_{t}\right\|_{2}=\sum_{t=1}^{T-1}\left\|z_{t+ 1}^{*}-z_{t}^{*}+\sum_{j}\left(z_{t+1}^{(j)}-z_{t}^{(j)}\right)\right\|_{2}= \sum_{t=1}^{T-1}\left\|\sum_{j}\left(z_{t+1}^{(j)}-z_{t}^{(j)}\right)\right\|_ {2},\]

where the last equality is due to \(z^{*}\) being a constant sequence.

Consider removing "shorter" scales with \(1\leq j<j^{*}\), which is equivalent to local averaging, c.f., Appendix D.6. Due to Lemma D.7, the path length does not increase, i.e,

\[\sum_{t=1}^{T-1}\left\|\sum_{j}\left(z_{t+1}^{(j)}-z_{t}^{(j)}\right)\right\| _{2}\geq\sum_{t=1}^{T-1}\left\|\sum_{j\geq j^{*}}\left(z_{t+1}^{(j)}-z_{t}^{(j )}\right)\right\|_{2}.\]

Then, we can further remove the rounds where the path length is not counted in \(P^{(j^{*})}\), i.e., when a time \(t\in I^{(j^{*},l)}\) but \(t+1\in I^{(j^{*},l+1)}\).

\[\text{RHS}\geq\sum_{l}\sum_{t=2^{j^{*}}(l-1)+1}^{2^{j^{*}}l-1}\left\|\sum_{j \geq j^{*}}\left(z_{t+1}^{(j)}-z_{t}^{(j)}\right)\right\|_{2}.\]

Now, consider any location \(l\), which determines the time interval \(I^{(j^{*},l)}=[2^{j^{*}}(l-1)+1:2^{j^{*}}l]\). Any detail sequence \(z^{(j)}\) with scale \(j>j^{*}\) is constant on this time interval, thus removing it does not change the path length at all. Therefore,

\[P\geq\sum_{l}\sum_{t=2^{j^{*}}(l-1)+1}^{2^{j^{*}}l-1}\left\|z_{t+1}^{(j^{*})}- z_{t}^{(j^{*})}\right\|_{2}=P^{(j^{*})}.\qed\]

As for the first order variability,

**Lemma D.5**.: _For any \(u_{1:T}\) and any scale parameter \(j^{*}\), \(\bar{S}^{(j^{*})}\leq\bar{S}\)._

Proof of Lemma D.5.: From the definition, noticing that \(\bar{u}\) is entirely captured by the all-one feature,

\[\bar{S}=\sum_{t=1}^{T}\left\|u_{t}-\bar{u}\right\|_{2}=\sum_{t=1}^{T}\left\| \sum_{j=1}^{\log_{2}T}z_{t}^{(j)}\right\|_{2}.\]

Due to Lemma D.7, removing short scales amounts to local averaging, which decreases the variability.

\[\bar{S}\geq\sum_{t=1}^{T}\left\|\sum_{j\geq j^{*}}z_{t}^{(j)}\right\|_{2}= \sum_{l}\sum_{t\in I^{(j^{*},l)}}\left\|z_{t}^{(j^{*})}+\sum_{j>j^{*}}z_{t}^{ (j)}\right\|_{2}.\]

For any \(l\), consider the support of the \((j^{*},l)\)-th feature, \(I^{(j^{*},l)}\). Observe that \(\sum_{j>j^{*}}z_{t}^{(j)}\) is time invariant throughout \(I^{(j^{*},l)}\), let us denote it as \(v\in\mathbb{R}^{d}\). Meanwhile, for some \(w\in\mathbb{R}^{d}\), \(z_{t}^{(j^{*})}\) equals \(w\) on \(I_{+}^{(j^{*},l)}\), the first half of this interval, while being \(-w\) on the second half \(I_{-}^{(j^{*},l)}\) of this interval. Therefore,

\[\sum_{t\in I^{(j^{*},l)}}\left\|z_{t}^{(j^{*})}+\sum_{j>j^{*}}z_{t}^{(j)} \right\|_{2}=2^{j^{*}-1}\left(\left\|v+w\right\|_{2}+\left\|v-w\right\|_{2} \right)\geq 2^{j^{*}}\left\|w\right\|_{2}=\sum_{t\in I^{(j^{*},l)}}\left\|z_{t}^{( j^{*})}\right\|_{2}.\]

Combining the above,

\[\bar{S}\geq\sum_{l}\sum_{t\in I^{(j^{*},l)}}\left\|z_{t}^{(j^{*})}\right\|_{2} =\bar{S}^{(j^{*})}.\qed\]Step 3Summarizing the above relations, and using the property that there are only \(\log_{2}T\) scales.

**Lemma D.6**.: _For any \(m\), \(T=2^{m}\) and \(u_{1:T}\in\mathbb{R}^{dT}\), Algorithm 4 with the hyperparameter \(\varepsilon=1\) guarantees_

\[\operatorname{Regret}_{T}(u_{1:T})=\tilde{O}\left(\left\|\bar{u}\right\|_{2} \sqrt{T}+\sqrt{PS}\right).\]

Proof of Lemma D.6.: Starting from the generic regret bound, Eq.(13) for Algorithm 4.

\[\operatorname{Regret}_{T}(u_{1:T})\leq\varepsilon G+G\left(\left\|\hat{u}^{*} \right\|_{2}+\sum_{j,l}\left\|\hat{u}^{(j,l)}\right\|_{2}\right)\cdot \operatorname{polylog}\left(M,T,\varepsilon^{-1}\right).\]

Due to Eq.(12), \(\left\|\hat{u}^{*}\right\|_{2}=\left\|\bar{u}\right\|_{2}\sqrt{T}\). Then, combining Lemma D.3, D.4 and D.5,

\[\sum_{j,l}\left\|\hat{u}^{(j,l)}\right\|_{2}\leq O\left(\sqrt{PS}\log_{2}T \right).\]

Plugging it into the generic bound completes the proof. 

#### d.5.2 Anytime bound

Now we are ready to prove an anytime unconstrained dynamic regret bound that depends on the path length.

**Theorem 3** (Path length bound).: _For all \(T\in\mathbb{N}_{+}\) and \(u_{1:T}\in\mathbb{R}^{dT}\), Algorithm 5 guarantees_

\[\operatorname{Regret}_{T}(u_{1:T})\leq\tilde{O}\left(\left\|\bar{u}\right\|_{2 }\sqrt{T}+\sqrt{PS}\right).\] (10)

Proof of Theorem 3.: Similar to the analysis of the switching regret (Theorem 2), we first consider the situation where the time horizon \(T\) can be exactly decomposed into \(m^{*}\) segments with dyadic lengths \(2^{1},\ldots,2^{m^{*}}\). In this situation, we have

\[\operatorname{Regret}_{T}(u_{1:T}) \leq\tilde{O}\left[\sum_{m=1}^{m^{*}}\left\|\bar{u}_{m}\right\|_{ 2}\sqrt{2^{m}}+\sum_{m=1}^{m^{*}}\sqrt{P_{m}\bar{S}_{m}}\right]\] \[\leq\tilde{O}\left[\left\|\bar{u}\right\|_{2}\sqrt{T}+\sqrt{ \bar{E}}+\sum_{m=1}^{m^{*}}\sqrt{P_{m}\bar{S}_{m}}\right],\]

where the second line follows from the proof of Theorem 2, specifically Eq.(15) and Eq.(16).

Now let us consider the remaining sum on the RHS. Using Cauchy-Schwarz,

\[\sum_{m=1}^{m^{*}}\sqrt{P_{m}\bar{S}_{m}}\leq\sqrt{\left(\sum_{m=1}^{m^{*}}P_ {m}\right)\left(\sum_{m=1}^{m^{*}}\bar{S}_{m}\right)}\leq\sqrt{P\left(\sum_{m =1}^{m^{*}}\sum_{t=2^{m}-1}^{2^{m+1}-2}\left\|u_{t}-\bar{u}_{m}\right\|_{2} \right)},\]

where

\[\sum_{m=1}^{m^{*}}\sum_{t=2^{m}-1}^{2^{m+1}-2}\left\|u_{t}-\bar{u}_{m}\right\| _{2}\leq\sum_{m=1}^{m^{*}}\sum_{t=2^{m}-1}^{2^{m+1}-2}\left(\left\|u_{t}-\bar{ u}\right\|_{2}+\left\|\bar{u}_{m}-\bar{u}\right\|_{2}\right)=\bar{S}+\sum_{m=1}^{m^{ *}}2^{m}\left\|\bar{u}_{m}-\bar{u}\right\|_{2}.\]

The last sum on the RHS is the first order variability of a locally averaged version of \(u_{1:T}\). Due to Lemma D.7,

\[\sum_{m=1}^{m^{*}}2^{m}\left\|\bar{u}_{m}-\bar{u}\right\|_{2}\leq\bar{S}.\]

Combining everything above,

\[\operatorname{Regret}_{T}(u_{1:T})\leq\tilde{O}\left(\left\|\bar{u}\right\|_{ 2}\sqrt{T}+\sqrt{\bar{E}}+\sqrt{PS}\right).\]It remains to show that \(\sqrt{E}\leq\sqrt{PS}\), thus the former can be absorbed into the latter. Plugging in the definitions, this is equivalent to showing

\[\sum_{t=1}^{T}\left\|u_{t}-\bar{u}\right\|_{2}^{2}\leq\sum_{t=1}^{T}P\left\|u_{t }-\bar{u}\right\|_{2},\]

and it suffices to prove \(\left\|u_{t}-\bar{u}\right\|\leq P\) for all \(t\in[1:T]\). This is completed in Lemma D.8. Till this point, we have shown the desirable result in the situation of "exact dyadic partitioning".

To complete the proof, we turn to the general situation where \(T\) cannot be partitioned into dyadic blocks. This follows from a similar "padding" construction from the proof of Theorem 2. Let \(T^{*}=2^{\lceil\log_{2}T\rceil}\), and by definition, \(T^{*}\leq 2T\). Let us consider a hypothetical length \(T^{*}\) game with the rounds \(t>T\) constructed as follows: the loss gradient \(g_{t}=0\in\mathbb{R}^{d}\), and \(u_{t}=\bar{u}\). Then, the regret of any algorithm on the length \(T^{*}\) hypothetical game equals its regret on the actual length \(T\) game, and the regret bound for the former applies to the latter as well: if we write \(P^{*}\) and \(\bar{S}^{*}\) as the statistics of the extended length \(T^{*}\) comparator, then

\[\operatorname{Regret}_{T}(u_{1:T})\leq\tilde{O}\left(\left\|\bar{u}\right\|_ {2}\sqrt{T^{*}}+\sqrt{P^{*}\bar{S}^{*}}\right).\]

Clearly, \(\bar{S}^{*}=\bar{S}\) and \(T^{*}\leq 2T\). As for the path length, \(P^{*}=P+\left\|u_{T}-\bar{u}\right\|_{2}\), and due to Lemma D.8, \(\left\|u_{T}-\bar{u}\right\|_{2}\leq P\). Plugging it back completes the proof. 

### Useful lemma

Our analysis uses two auxiliary lemmas. First, we show that local averaging makes a signal "more regular". Consider any signal \(u_{1:T}\in\mathbb{R}^{dT}\), with the \(t\)-th round component \(u_{t}\in\mathbb{R}^{d}\). Local averaging refers to replacing any \(k\) consecutive components of \(u_{1:T}\) by their average, i.e., setting

\[u_{\tau+1},\ldots,u_{\tau+k}=k^{-1}\sum_{i=1}^{k}u_{\tau+i},\]

for some \(\tau\in[0:T-k]\).

**Lemma D.7**.: _Let a signal \(w_{1:T}\in\mathbb{R}^{dT}\) be the result of \(u_{1:T}\) after local averaging, and \(\bar{w}=T^{-1}\sum_{t=1}^{T}w_{t}\in\mathbb{R}^{d}\). Then, the path length, the norm sum and the energy of \(w_{1:T}\), including their centered versions, are all dominated by those of \(u_{1:T}\). That is,_

1. \(\sum_{t=1}^{T-1}\left\|w_{t+1}-w_{t}\right\|_{2}\leq\sum_{t=1}^{T-1}\left\|u _{t+1}-u_{t}\right\|_{2}\)_;_
2. \(\sum_{t=1}^{T}\left\|w_{t}-\bar{w}\right\|_{2}\leq\sum_{t=1}^{T}\left\|u_{t}- \bar{u}\right\|_{2}\)_;_
3. \(\sum_{t=1}^{T}\left\|w_{t}-\bar{w}\right\|_{2}^{2}\leq\sum_{t=1}^{T}\left\|u _{t}-\bar{u}\right\|_{2}^{2}\)_._
4. \(\sum_{t=1}^{T}\left\|w_{t}\right\|_{2}\leq\sum_{t=1}^{T}\left\|u_{t}\right\|_ {2}\)_, and_ \(\sum_{t=1}^{T}\left\|w_{t}\right\|_{2}^{2}\leq\sum_{t=1}^{T}\left\|u_{t}\right\| _{2}^{2}\)_._

Proof of Lemma d.7.: Starting from the first part of the lemma, we prove for the general case of \(0<\tau<T-k\). The boundary cases (\(\tau=0\) and \(\tau=T-k\)) are analogous.

Local averaging only affects the path length caused by the averaged entries \(u_{\tau+1},\ldots,u_{\tau+k}\), and the two entries \(u_{\tau}\) and \(u_{\tau+k+1}\) right besides averaging boundary; this original path length quantity in \(u_{1:T}\) is \(\sum_{i=0}^{k}\left\|u_{\tau+i+1}-u_{\tau+i}\right\|_{2}\). After averaging, the path length among these entries becomes

\[\left\|u_{\tau}-k^{-1}\sum_{i=1}^{k}u_{\tau+i}\right\|_{2}+\left\|k ^{-1}\sum_{i=1}^{k}u_{\tau+i}-u_{\tau+k+1}\right\|_{2}\] \[=\] \[\leq\] \[= \sum_{i=0}^{k}\left\|u_{\tau+i+1}-u_{\tau+i}\right\|_{2}.\]

Now consider the second part of the lemma. After local averaging, \(\bar{w}=\bar{u}\). The affected part of the signal contributes to the following first order variability

\[\sum_{t=1}^{k}\left\|w_{\tau+i}-\bar{w}\right\|_{2}=k\left\|k^{-1}\sum_{i=1}^{ k}u_{\tau+i}-\bar{u}\right\|_{2}=\left\|\sum_{i=1}^{k}u_{\tau+i}-k\bar{u} \right\|_{2}\leq\sum_{t=1}^{k}\left\|u_{\tau+i}-\bar{u}\right\|_{2}.\]

As for the third part of the lemma,

\[\sum_{t=1}^{k}\left\|w_{\tau+i}-\bar{w}\right\|_{2}^{2}=k\left\|k^{-1}\sum_{i =1}^{k}u_{\tau+i}-\bar{u}\right\|_{2}^{2}\leq k^{-1}\left(\sum_{i=1}^{k} \left\|u_{\tau+i}-\bar{u}\right\|_{2}\right)^{2}\leq\sum_{t=1}^{k}\left\|u_{ \tau+i}-\bar{u}\right\|_{2}^{2},\]

where the last inequality is due to AM-QM inequality.

The final part of the proof is the uncentered version of Part 2 and 3, which follows the same steps. In fact, any fixed reference point (for the variability) works, i.e., for all \(v\in\mathbb{R}^{d}\),

\[\sum_{t=1}^{T}\left\|w_{t}-v\right\|_{2}\leq\sum_{t=1}^{T}\left\|u_{t}-v \right\|_{2},\]

\[\sum_{t=1}^{T}\left\|w_{t}-v\right\|_{2}^{2}\leq\sum_{t=1}^{T}\left\|u_{t}-v \right\|_{2}^{2}.\qed\]

We also use another simple lemma.

**Lemma D.8**.: _Consider any comparator sequence \(u_{1:T}\). For all \(t\), we have \(\left\|u_{t}-\bar{u}\right\|_{2}\leq P\)._

Proof of Lemma D.8.: Starting from the definition,

\[\left\|u_{t}-\bar{u}\right\|_{2}=\left\|u_{t}-\sum_{i=1}^{T}T^{-1}u_{i} \right\|_{2}\leq T^{-1}\sum_{i=1}^{T}\left\|u_{t}-u_{i}\right\|_{2},\]

and for all \(i,t\in[1:T]\), \(\left\|u_{t}-u_{i}\right\|_{2}\leq P\) due to triangle inequality. 

### Quantitative example

This subsection presents details of our two quantitative examples, Example 1 and 2.

Tracking outliersWe first calculate the relevant statistics of the comparator \(u_{1:T}\). Note that we assume \(k\leq\sqrt{T}\), and in this way, there is only a small amount of \(u_{t}\) with large magnitude, which can then be called outliers.

\[\bar{u}=\frac{1}{T}\left(k\sqrt{T}+T-k\right),\]

\(|\bar{u}|=\Theta(1)\), \(M=\sqrt{T}\), \(K=1\) or \(2\), \(P=\Theta(\sqrt{T})\), \(\bar{E}\leq E=kT+T-k=\Theta(kT)\). As for \(S\) and \(\bar{S}\),

\[S=k\sqrt{T}+T-k=\Theta(T),\] \[\bar{S} =k(\sqrt{T}-\bar{u})+(T-k)(\bar{u}-1)\] \[=2kT^{-1}(T-k)(\sqrt{T}-1)\] \[\leq O(k\sqrt{T}).\]

Intuitively, we have \(|\bar{u}|=\Theta(1)\) while \(M=\sqrt{T}\); \(\bar{S}=O(k\sqrt{T})\) while \(S=\Theta(T)\). This explains the improvements detailed next. For each algorithm considered in Table 1, we evaluate both its switching regret bound and its path-length-dependent bound.

* The minimax algorithm Ader[1] is not applicable, as \(M\) grows with \(T\) and can be larger than any fixed diameter \(D\).
* The \(P\)-dependent bound of the coarse baseline [1, Algorithm 6], c.f., Eq.(3), is \[\tilde{O}\left(\sqrt{(M+P)MT}\right)=\tilde{O}(T).\] With \(P=O(KM)\), the resulting \(K\)-dependent bound is \[\tilde{O}\left(M\sqrt{(1+K)T}\right)=\tilde{O}(T).\]
* The \(P\)-dependent bound of the fine baseline [1, Algorithm 2], c.f., Eq.(4), is \[\tilde{O}\left(\sqrt{(M+P)\bar{S}}\right)=\tilde{O}\left(T^{3/4}\right).\] With \(P=O(KM)\), the resulting \(K\)-dependent bound is \[\tilde{O}\left(\sqrt{(1+K)MS}\right)=\tilde{O}(T^{3/4}).\]
* Our path length bound is \[\tilde{O}\left(|\bar{u}|\,\sqrt{T}+\sqrt{P\bar{S}}\right)=\tilde{O}\left( \sqrt{kT}\right).\] Same for our switching regret bound, \[\tilde{O}\left(|\bar{u}|\,\sqrt{T}+\sqrt{K\bar{E}}\right)=\tilde{O}\left( \sqrt{kT}\right).\]

Persistent oscillationAgain, we calculate the statistics of the comparator \(u_{1:T}\). \(\bar{u}=1\), \(M\leq 2\), \(K=k\), \(P=\Theta(k/\sqrt{T})\). Crucially, \(\tilde{S}=\sqrt{T}\) and \(\bar{E}=\Theta(1)\), while \(S=\Theta(T)\) and \(E=\Theta(T)\). Here the \(K\)-dependent bounds of the baselines are loose compared to their corresponding \(P\)-dependent bounds, due to using the relation \(P=O(KM)\). Therefore we will only evaluate their \(P\)-dependent bounds.

* Suppose one knows that \(M\leq 2\) beforehand, then Ader can be applied with \(D=2\). The regret bound is \[\tilde{O}\left(\sqrt{(D+P)DT}\right)=\tilde{O}\left(\sqrt{T}+k^{1/2}T^{1/4} \right).\]
* One could check that the \(P\)-dependent bounds of the coarse and the fine baselines are also \[\tilde{O}\left(\sqrt{(M+P)MT}\right)=\tilde{O}\left(\sqrt{T}+k^{1/2}T^{1/4} \right),\] \[\tilde{O}\left(\sqrt{(M+P)\bar{S}}\right)=\tilde{O}\left(\sqrt{T}+k^{1/2}T^{1 /4}\right).\]
* For our algorithm, the \(P\)-dependent bound is \[\tilde{O}\left(|\bar{u}|\,\sqrt{T}+\sqrt{P\bar{S}}\right)=\tilde{O}\left( \sqrt{T}\right).\] The \(K\)-dependent bound is \[\tilde{O}\left(|\bar{u}|\,\sqrt{T}+\sqrt{K\bar{E}}\right)=\tilde{O}\left( \sqrt{T}\right).\]Application: Time series forecasting

This section presents an application of our framework in time series forecasting.15 Roughly speaking, we aim to address the following question:

Footnote 15: Code is available at https://github.com/zhiyuzz/NeurIPS2023-Sparse-Coding.

Given a _black box_ forecaster, can we make it provably robust against (structured) nonstationarity?

Along the way, our objective is to show that

* Simultaneously handling unconstrained domains and dynamic comparators in online learning brings downstream benefits in time series forecasting.
* Our sparse coding framework can enhance empirically developed forecasting strategies.

SettingLet us consider the following forecasting problem, which resembles the online learning game introduced at the beginning of this paper. The difference is that, here, we further assume access to a black box forecaster \(\mathcal{A}\). In each (the \(t\)-th) round,

1. The black box forecaster \(\mathcal{A}\) produces a prediction \(a_{t}\in\mathbb{R}^{d}\) based on the observed history (\(z_{1:t-1}\) and \(l_{1:t-1}\)).
2. After observing \(a_{t}\), we make a prediction \(x_{t}\in\mathbb{R}^{d}\).
3. The environment reveals a true value \(z_{t}\in\mathbb{R}^{d}\) and a convex loss function \(l_{t}:\mathbb{R}^{d}\rightarrow\mathbb{R}\). \(l_{t}\) is \(G\)-Lipschitz with respect to \(\left\lVert\cdot\right\rVert_{2}\), and \(z_{t}\) is one of its minimizer satisfying \(l_{t}(z_{t})=0\).

Our goal is to achieve low total loss \(\sum_{t=1}^{T}l_{t}(x_{t})\). Since trivially picking \(x_{t}=a_{t}\) already achieves a total loss of \(\sum_{t=1}^{T}l_{t}(a_{t})\), our goal is to improve it in certain situations, by designing a more sophisticated prediction rule based on \(a_{t}\).

IntuitionIn the above setting, \(\mathcal{A}\) can be _any_ algorithm that predicts \(z_{1:T}\) in a reasonable, but non-robust manner. Taking the weather forecasting for example, there are a few notable cases.

* \(\mathcal{A}\) is a simulator of the governing meteorological equations, which uses the online observations \(z_{1:t-1}\) as boundary conditions.
* \(\mathcal{A}\) is an autoregressive model, which predicts a linear combination of the past observations. The coefficients are determined by statistical modeling.
* \(\mathcal{A}\) is a large deep learning model trained on offline datasets (e.g., the weather history at geographically similar locations).

Even though such forecasters typically lack performance guarantees, their predictions can be used to construct time-varying Bayesian priors (see our discussion in the Introduction): given \(a_{t}\), we will apply a _fine-tuning_ adjustment \(\delta_{t}\) to predict \(x_{t}=a_{t}+\delta_{t}\). Intuitively, the total loss is low if \(a_{t}\) is close to the true value \(z_{t}\), i.e., when the prior is good.

Reduction to unconstrained dynamic regretConcretely, if \(x_{t}=a_{t}+\delta_{t}\), then due to convexity, for all subgradients \(g_{t}\in\partial l_{t}(x_{t})\) we have \(l_{t}(x_{t})-l_{t}(z_{t})\leq\langle g_{t},\delta_{t}\rangle-\langle g_{t},z _{t}-a_{t}\rangle\). The RHS is the instantaneous regret of \(\delta_{t}\) in an OLO problem with loss gradient \(g_{t}\) and comparator \(z_{t}-a_{t}\). Applying our unconstrained dynamic OLO algorithm, the total loss in forecasting can be bounded as

\[\sum_{t=1}^{T}l_{t}(x_{t})\leq\operatorname{Regret}_{T}(z_{1:T}-a_{1:T}).\]

That is, the total loss bound adapts to the complexity of the _error sequence_\(z_{1:T}-a_{1:T}\) (of the given black box forecaster). This contains \(a_{1:T}=0\) as a special case, where no side information is assumed.

Let us compare this bound to the baseline \(\sum_{t=1}^{T}l_{t}(a_{t})\), which corresponds to trivially picking \(x_{t}=a_{t}\).

* If \(z_{1:T}=a_{1:T}\), i.e., the black box \(\mathcal{A}\) is perfect, then the baseline loss is \(\sum_{t=1}^{T}l_{t}(a_{t})=0\). In this case, due to Theorem 4, our general sparse coding framework guarantees \(\sum_{t=1}^{T}l_{t}(x_{t})\leq\varepsilon G\), where \(\varepsilon>0\) is an arbitrary hyperparameter. That is, our algorithm is worse than the baseline by at most a constant.

* If \(z_{1:T}\neq a_{1:T}\), then in general, the baseline loss \(\sum_{t=1}^{T}l_{t}(a_{t})\) is linear in \(T\). In contrast, our algorithm could guarantee a sublinear \(\operatorname{Regret}_{T}(z_{1:T}-a_{1:T})\), thus also a sublinear total loss, when the error sequence \(z_{1:T}-a_{1:T}\) is structurally simple (e.g., sparse under a transform, or low path length) with respect to our prior knowledge.

In summary, the idea is that by sacrificing at most a constant loss when \(\mathcal{A}\) is perfect (\(z_{1:T}=a_{1:T}\)), we could robustify \(\mathcal{A}\) against certain structured unseen environments, improving the linear total loss to a sublinear rate.

Importance of unconstrained domainThe above application critically relies on the ability of our algorithm to handle unconstrained domains. To demonstrate this, suppose we instead use the bounded domain algorithm from [11] to pick the fine-tuning adjustment \(\delta_{t}\). Then, the above analysis only holds if an upper bound \(D\) of the maximum error \(\max_{t}\left\lVert z_{t}-a_{t}\right\rVert_{2}\) is known a priori - this is a stringent requirement in practice. Furthermore, when \(z_{1:T}=a_{1:T}\), such an alternative approach only guarantees \(\sum_{t=1}^{T}l_{t}(x_{t})\leq\tilde{O}(D\sqrt{T})\), which is considerably worse than the baseline \(0\). In other words, the alternative fine-tuning strategy could ruin the black box forecaster \(\mathcal{A}\), when the latter performs well.

In the rest of this section, we present experiments for this time series application. Appendix E.1 demonstrates the power law phenomenon, which shows that both the time series \(z_{1:T}\) and the error sequence \(z_{1:T}-a_{1:T}\) could exhibit exploitable structures. This implies good performance guarantees using our theoretical framework. Appendix E.2 goes one step further by actually testing the fine-tuning performance of our algorithm.

### Power law phenomenon

This subsection further verifies the power law phenomenon discussed in Section 2.2, with both wavelet and Fourier dictionaries. The goal is to present concrete examples where signal structures can be exploited by our framework, generating more interpretable, sublinear regret bounds.

Wavelet dictionaryWe first verify the power law on the Haar wavelet dictionary. Intuitively it is suitable when the dynamics of the environment exhibits switching behavior. To this end, consider the following stochastic time series model

\[z_{t}=z_{t-1}\beta_{t}+\zeta_{t},\] (17)

where \(\{\beta_{t}\}\) and \(\{\zeta_{t}\}\) are iid random variables satisfying \(\zeta_{t}\sim\operatorname{Uniform}(-q,q)\) and

\[\beta_{t}=\begin{cases}-1,&\text{w.p.}\quad p,\\ 1,&\text{w.p.}\quad 1-p.\end{cases}\]

Picking \(T=2^{15}=32768\), \(p=0.0005\) and \(q=0.005\), we generate four sample paths of \(z_{1:T}\) using four _arbitrary_ random seeds (2020, 2021, 2022 and 2023), and the obtained time domain signals are plotted in the first row of Figure 2. As the switching probability \(p\) is chosen to be low enough, all the sample paths exhibit a small amount of sharp switches, corrupted by the noise term \(\zeta_{t}\). According to our intuition from signal processing, the Haar wavelet transform of these signals is sparse.

Now let us verify this intuition. We take the Haar wavelet transform of these signals, sort the transform domain coefficients and plot the results on log-log scales - these are shown as the solid blue lines in the second row of Figure 2. Using the largest 100 transform domain coefficients on each plot, we fit a liner model using least square, which is shown as the dashed orange line. The slope of each line is \(-\alpha\), where \(\alpha\) is displayed in the legend. It can be seen that for all four sample paths, the fitted \(\alpha\) is within \((0.5,1)\), thus justifying the power law phenomenon [10]. Given \(\alpha\), the regret of our Haar wavelet algorithm is \(\tilde{O}(T^{1.5-\alpha})\), as shown in Section 2.2.

As for the implication in time series forecasting, let us consider forecasting \(z_{1:T}\) with \(a_{1:T}=0\), i.e., without the external forecaster \(\mathcal{A}\). Given the power law, the total forecasting loss of our fine-tuning approach is \(\sum_{t=1}^{T}l_{t}(x_{t})\leq\tilde{O}(T^{1.5-\alpha})\).

We also remark that although only four sample paths are demonstrated, we observe the power law phenomenon on all random seeds we tried in the experiment.

Fourier dictionaryNext, we verify the power law on the Fourier dictionary. Here we use the Jena weather forecasting dataset,16 which records the weather data at a German city, Jena, every 10 minutes. We take the data from Jan 1st, 2010 till July 1st, 2022, consisting of \(T=656956\) time steps. Two different modalities, namely the temperature and the humidity, are considered. The actual temperature and humidity sequences are plotted in Figure 3.

Footnote 16: Available at https://www.bgc-jena.mpg.de/wetter/.

For the sequence of temperature \(z_{1:T}\), we perform its _Discrete Fourier Transform_ (DFT), which returns \(T\) complex number as the frequency domain coefficients. We discard the second half of the coefficients due to symmetry, since the input of the transform is real. For the remaining coefficients, we take their absolute values, sort them and plot the result on a log-log plot. Similar to the wavelet experiment, we also fit a linear model using the largest 100 transform domain coefficients. These are shown as Figure 4 (Left), which exhibit the power law phenomenon.

Furthermore, we perform the same procedure on the temperature difference sequence \(\{z_{t+1}-z_{t}\}\), where the \(t\)-th entry is the change of temperature from the \(t\)-th time step to the \(t+1\)-th time step. The result is shown as Figure 4 (Right). Although the tail is heavier, we can still observe similar power-law phenomenon for large transform domain coefficients.

Now, let us discuss again the implication of the observed power law in time series forecasting. First, consider forecasting \(z_{1:T}\) without \(\mathcal{A}\). Given the power law of \(z_{1:T}\) itself, the Fourier version of our forecaster guarantees sublinear total loss. Next, consider forecasting \(z_{1:T}\) with \(\mathcal{A}\) being the _zeroth-order hold_ forecaster, i.e, \(a_{t}=z_{t-1}\). The power law of the difference sequence \(\{z_{t+1}-z_{t}\}\) implies good forecasting performance of our framework in this context.

Figure 3: Time domain behavior of the weather data.

Figure 2: Verifying the power law on the Haar Wavelet dictionary. First row: time domain signals. Second row: sorted transform domain coefficients on a log-log plot. The dashed orange line is the best linear fit on the log-log plot, using the largest 100 transform domain coefficients. From left to right: four arbitrary random seeds.

Parallel results on the humidity sequence are reported in Figure 5, with a similar qualitative behavior. It illustrates the prevalence of the power law across different types of the data.

### Fine-tuning forecaster

Finally, we test the performance of our forecasting framework on the synthetic switching data and the actual temperature sequence. For the first case, our framework is equipped with the Haar wavelet dictionary. The Fourier dictionary is adopted in the second case. In both cases, we compare our algorithm against the baseline from [3]. More specifically, we take our online learning algorithm (Algorithm 2) and the algorithm from [3], plug them both into the time series forecasting workflow introduced at the beginning of this section, and then compare their total forecasting loss.

Concretely, let us start from the wavelet dictionary.

Wavelet dictionaryIn this case, consider the setting without the external forecaster \(\mathcal{A}\). We run both online learning algorithms (our Algorithm 2 and the baseline [3, Algorithm 2]), and use their outputs directly as the time series predictions. Our Algorithm 2 is equipped with the Haar wavelet dictionary defined in Section 3.1. The configurations of the time series model are the same as the previous subsection, with \(T=2^{15}=32768\), \(p=0.0005\) and \(q=0.005\). The loss functions \(l_{t}\) are the absolute loss.

Both algorithms require a confidence hyperparameter \(\varepsilon\), and we set it to \(1\). Since the time series data Eq.(17) is random, we run both algorithms on 10 random seeds, and calculate their total loss. Our algorithm achieves a total loss of 44048, which is considerably lower than the baseline's total loss 62465. This is consistent with the theoretical results developed so far.

Figure 4: Verifying the power law on the Fourier dictionary. Left: the DFT of the temperature sequence. Right: the DFT of the temperature difference sequence.

Figure 5: Verifying the power law on the Fourier dictionary. Left: the DFT of the humidity sequence. Right: the DFT of the humidity difference sequence.

Fourier dictionaryNext, we turn to the task of temperature forecasting. The data is reported in the previous subsection. We take its first \(T=50000\) entries, and assign it to the true time series \(z_{1:T}\); the loss functions \(l_{t}\) are the absolute loss. The black box forecaster \(\mathcal{A}\) is assigned to the zeroth-order hold forecaster, i.e., \(a_{t}=z_{t-1}\).

For our framework, we need to specify the dictionary. Although using the entire DFT matrix could lead to low regret guarantees (as demonstrated by the power law), this is computationally challenging. Instead, we exploit the fact that the weather is naturally periodic, with the period of one day. Picking the base frequency \(\omega\) accordingly, we define features indexed by \(k\) (the harmonic order) as

\[h_{t,2k-1}=\cos(k\omega t),\]

\[h_{t,2k}=\sin(k\omega t).\]

By specifying the maximum order \(K\), we obtain \(2K\) features \(\{h_{t,2k-1},h_{t,2k}\}_{k\in[1:K]}\) from this construction. An all-one feature is further added, making the dictionary size \(N=2K+1\).

Again, we set the confidence hyperparameter \(\varepsilon=1\) for our algorithm. The total loss as a function of the dictionary size \(N\) is plotted in Figure 6. Notably, the case of \(N=0\) is equivalent to trivially following the advice of the given forecaster \(\mathcal{A}\): \(x_{t}=a_{t}=z_{t-1}\). It can be seen that our fine-tuning framework (\(N>0\)) actually results in better performance, due to exploiting the structures in the error sequence \(z_{1:T}-a_{1:T}\).

We also test the fine-tuning performance of the algorithm from [1]. Same as the above, we set \(\varepsilon=1\). The total loss achieved by this alternative algorithm is 8238, which is around the same as \(\mathcal{A}\) itself, and significantly higher than the total loss of our algorithm with moderate amount of features (\(N>5\)). This fits the intuition from this paper: the environment contains persistent dynamics, which the algorithm from [1] cannot handle.

## Appendix F Additional discussion

MRA in online learningOn a broader scope, wavelets embody the idea of _Multi-Resolution Analysis_ (MRA), which is reminiscent of the classical _geometric covering_ (GC) construction in adaptive online learning [15]. Such a construction starts from a class of _GC time intervals_, which are equivalent to the support of Haar wavelet features. On each GC interval, a static online learning algorithm is defined (corresponding to using an all-one feature, c.f., Section 2.2); and then, the outputs of these "local" algorithms are aggregated by a _sleeping expert_ algorithm on top [14, 16]. Algorithmically, our innovation is introducing sign changes in the features, accompanied by a different, additive way to aggregate base algorithms. For tackling nonstationarity, both approaches have their own strengths: the GC construction can produce _strongly adaptive_ guarantees on subintervals of the time horizon, while our algorithm does not need a bounded domain. Their possible connections are intriguing.

Figure 6: Testing our algorithm for temperature forecasting.

Lipschitz vs strongly convex lossesWe also comment on the choice of loss functions in unconstrained dynamic OCO. Besides the Lipschitz assumption we impose, a fruitful line of works by Baby and Wang [1, 20, 21, 22, 23] considered an alternative setting with strong convexity, motivated by the prevalence of the square loss in statistics. Their focus is primarily on bounded domains, as [1] showed that evaluated under the square loss, a lower bound for the unconstrained dynamic regret is \(\Omega(P^{2})\). A sublinear regret bound here requires \(P=o(\sqrt{T})\), rather than \(P=o(T)\) with Lipschitz losses - that is, the environment is required to be "more static" than the typical requirement in the Lipschitz setting.

Essentially, such a behavior is due to the large penalty that the square loss imposes on outliers. An adversary in online learning can deliberately pick the loss functions such that some of the player's predictions are large outliers with "huge" (square) losses, while the offline optimal comparator sequence suffers zero losses. Using the Lipschitz losses instead may offer an advantage on unbounded domains, due to being more tolerant to these outliers. Furthermore, Lipschitz losses do not necessarily have minimizers - this is useful for _decision_ problems (as opposed to _estimation_), where a ground truth may not exist.17

Footnote 17: An example is financial investment without budget constraints: doubling the invested amount also doubles the return.

Future workFor future works, several interesting questions could stem from this paper. For example,

* Our regret bound is stated against individual comparator sequences. One could investigate the implication of this result in stochastic environments, where the comparator statistics may take more concrete forms.
* Besides the sparsity and the energy studied in this paper, an interesting open problem is investigating alternative complexity measures of the comparator, possibly drawing connections to statistical learning theory.
* Our framework builds on pre-defined dictionary inputs. The quantitative benefit of using a data-dependent dictionary is unclear.
* Beyond wavelets, one may investigate the combination of the sparse coding framework with other function approximators, such as neural networks.