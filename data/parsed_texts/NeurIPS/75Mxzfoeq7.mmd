# No-Regret Learning in Dynamic Competition with Reference Effects Under Logit Demand

 Mengzi Amy Guo

IEOR Department

UC Berkeley

mengzi_guo@berkeley.edu &Donghao Ying

IEOR Department

UC Berkeley

donghaoy@berkeley.edu &Javad Lavaei

IEOR Department

UC Berkeley

lavaei@berkeley.edu &Zuo-Jun Max Shen

IEOR Department

UC Berkeley

maxshen@berkeley.edu

###### Abstract

This work is dedicated to the algorithm design in a competitive framework, with the primary goal of learning a stable equilibrium. We consider the dynamic price competition between two firms operating within an opaque marketplace, where each firm lacks information about its competitor. The demand follows the multinomial logit (MNL) choice model, which depends on the consumers' observed price and their reference price, and consecutive periods in the repeated games are connected by reference price updates. We use the notion of stationary Nash equilibrium (SNE), defined as the fixed point of the equilibrium pricing policy for the single-period game, to simultaneously capture the long-run market equilibrium and stability. We propose the online projected gradient ascent algorithm (OPGA), where the firms adjust prices using the first-order derivatives of their log-revenues that can be obtained from the market feedback mechanism. Despite the absence of typical properties required for the convergence of online games, such as strong monotonicity and variational stability, we demonstrate that under diminishing step-sizes, the price and reference price paths generated by OPGA converge to the unique SNE, thereby achieving the no-regret learning and a stable market. Moreover, with appropriate step-sizes, we prove that this convergence exhibits a rate of \(\mathcal{O}(1/t)\).

## 1 Introduction

The memory-based reference effect is a well-studied strategic consumer behavior in marketing and economics literature, which refers to the phenomenon that consumers shape their price expectations (known as reference prices) based on the past encounters and then use them to judge the current price (see [1] for a review). A substantial body of empirical research has shown that the current demand is significantly influenced by the historical prices through reference effects (see, e.g., [2, 3, 4, 5]). Driven by the ubiquitous evidence, many studies have investigated various pricing strategies in the presence of reference effects [6, 7, 8, 9]. However, the aforementioned works have all focused on the case with a monopolistic seller, leaving the understanding of how the reference effect functions in a competition relatively limited compared to its practical importance. This issue becomes even more pronounced with the surge of e-commerce, as the increased availability of information incentivizes consumers to make comparisons among different retailers.

Moreover, we notice that in competitive markets, the pricing problem with reference effects is further complicated by the lack of transparency, where firms are cautious about revealing confidential information to their rivals. Although the rise of digital markets greatly accelerates data transmission and promotes the information transparency, which is generally considered beneficial because of the improvement in marketplace efficiency [10], many firms remain hesitant to fully embrace such transparency for fear of losing their informational advantages. This concern is well-founded in the literature, for example the work [11] demonstrates that dealers with lower transparency levels generate higher profits than their more transparent counterparts, and [12] highlights that in reverse auctions, transparency typically enables buyers to drive the price down to the firm's marginal cost. Hence, as recommended by [13], companies should focus on the strategic and selective disclosure of information to enhance their competitive edge, rather than pursuing complete transparency.

Inspired by these real-world practices, in this article, we study the _duopoly competition with reference effects in an opaque market_, where each firm has access to its own information but does not possess any knowledge about its competitor, including their price, reference price, and demand. The consumer demand follows the multinomial logit (MNL) choice model, which naturally reflects the cross-product effects among substitutes. Furthermore, given the intertemporal characteristic of the memory-based reference effect, we consider the game in a dynamic framework, i.e., the firms engage in repeated competitions with consecutive periods linked by reference price updates. In this setting, it is natural to question _whether the firms can achieve some notion of stable equilibrium by employing common online learning algorithms to sequentially set their prices_. A vast majority of the literature on online games with incomplete information targets the problem of finding no-regret algorithms that can direct agents toward a Nash equilibrium, a stable state at which the agents have no incentive to revise their actions (see, e.g., [14; 15; 16]). Yet, the Nash equilibrium alone is inadequate to determine the stable state for our problem of interest, given the evolution of reference prices. For instance, even if an equilibrium price is reached in one period, the reference price update makes it highly probable that the firms will deviate from this equilibrium in subsequent periods. As a result, to jointly capture the market equilibrium and stability, we consider the concept of _stationary Nash equilibrium_ (SNE), defined as the fixed point of the equilibrium pricing policy for the single-period game. Attaining this long-term market stability is especially appealing for firms in a competitive environment, as a stable market fosters favorable conditions for implementing efficient planning strategies and facilitating upstream operations in supply chain management [17]. In contrast, fluctuating demands necessitate more carefully crafted strategies for effective logistics management [18; 19; 20].

The concept of SNE has also been investigated in [21] and [22]. Specifically, [21] examines the long-run market behavior in a duopoly competition with linear demand and a common reference price for both products. However, compared to the MNL demand in our work, linear demand models generally fall short in addressing interdependence among multiple products [4; 23; 24]. On the other hand, [22] adopts the MNL demand with product-specific reference price formulation; yet, their analysis of long-term market dynamics relies on complete information and is inapplicable to an opaque market. In contrast, our work accommodates both the partial information setting and MNL choice model. We summarize our main contributions below:

1. _Formulation._ We introduce a duopoly competition framework with an opaque market setup that takes into account both cross-period and cross-product effects through consumer reference effects and the MNL choice model. We use the notion of _stationary Nash equilibrium_ (SNE) to simultaneously depict the equilibrium price and market stability.
2. _Algorithm and convergence._ We propose a no-regret algorithm, namely the _Online Projected Gradient Ascent_ (OPGA), where each firm adjusts its posted price using the first-order derivative of its log-revenue. When the firms execute OPGA with diminishing step-sizes, we show that their prices and reference prices converge to the unique SNE, leading to the long-run market equilibrium and stability. Furthermore, when the step-sizes decrease appropriately in the order of \(\Theta(1/t)\), we demonstrate that the prices and reference prices converge at a rate of \(\mathcal{O}(1/t)\).
3. _Analysis._ We propose a novel analysis for the convergence of OPGA by exploiting characteristic properties of the MNL demand model. General convergence results for online games typically require restrictive assumptions such as strong monotonicity [25; 14; 16] or variational stability [26; 15; 27; 28], as well as the convexity of the loss function [29; 30]. However, our problem lacks these favorable properties, rendering the existing techniques inapplicable. Additionally, compared to standard games where the underlying environment is static, the reference price evolution in this work further perplexes the convergence analysis.

4. _Managerial insights._ Our study illuminates a common issue in practice, where the firms are willing to cooperate but are reluctant to divulge their information to others. The OPGA algorithm can help address this issue by guiding the firms to achieve the SNE as if they had perfect information, while still preserving their privacy.

## 2 Related literature

Our work on the dynamic competition with reference effects in an opaque market is related to the several streams of literature.

**Modeling of reference effect.** The concept of reference effects can be traced back to the adaptation-level theory proposed by [31], which states that consumers evaluate prices against the level they have adapted to. Extensive research has been dedicated to the formulation of reference effects in the marketing literature, where two mainstream models emerge: memory-based reference price and stimulus-based reference price [4]. The memory-based reference model, also known as the internal reference price, leverages historical prices to form the benchmark (see, e.g., [3; 32; 5]). On the contrary, the stimulus-based reference model, or the external reference price, asserts that the price judgment is established at the moment of purchase utilizing current external information such as the prices of substitutable products, rather than drawing on past memories (see, e.g., [33; 2]). According to the comparative analysis by [4], among different reference models, the memory-based model that relies on a product's own historical prices offers the best fit and strongest predictive power in multi-product settings. Hence, our paper adopts this type of reference model, referred to as the brand-specific past prices formulation in [4].

**Dynamic pricing in monopolist market with reference effect.** The research on reference effects has recently garnered increasing attention in the field of operations research, particularly in monopolist pricing problems. As memory-based reference effect models give rise to the intertemporal nature, the price optimization problem is usually formulated as a dynamic program. Similar to our work, their objectives typically involve determining the long-run market stability under the optimal or heuristic pricing strategies. The classic studies by [7] and [6] show that in either discrete- or continuous-time framework, the optimal pricing policy converges and leads to market stabilization under both loss-neutral and loss-averse reference effects. More recent research on reference effects primarily concentrates on the piecewise linear demand in single-product contexts and delves into more comprehensive characterizations of myopic and optimal pricing policies (see, e.g., [34; 8]). Deviating from the linear demand, [9] and [24] employ the logit demand and analyze the long-term market behaviors under the optimal pricing policy, where the former emphasizes on consumer heterogeneity and the later innovates in the multi-product setting.

While the common assumption in the aforementioned studies is that the firm knows the demand function, another line of research tackles the problem under uncertain demand, where they couple monopolistic dynamic pricing with reference effects and online demand learning [35; 36]. Although these works include an online learning component, our paper distinguishes itself from them in two aspects. Firstly, the uncertainty that needs to be learned is situated in different areas. The works by [35] and [36] assume that the seller recognizes the structure of the demand function (i.e., linear demand) but requires to estimate the model's responsiveness parameters. By contrast, in our competitive framework, the firms are aware of their own demands but lack knowledge about their rivals that should be learned. Secondly, the objectives of [35] and [36] are to design algorithms to boost the total revenues from a monopolist perspective, whereas our algorithm aims to guide firms to reach Nash equilibrium and market stability concurrently.

**Price competition with reference effects.** Our work is pertinent to the studies on price competition with reference effects [37; 38; 21; 39; 22]. In particular, [38] is concerned with single-period price competitions under various reference price formulations. The paper [37] expands the scope to a dynamic competition with symmetric reference effects and linear demand, though their theoretical analysis on unique subgame perfect Nash equilibrium is confined to a two-period horizon. The more recent work [39] further extends the game to the multi-stage setting, where they obtain the Markov perfect equilibrium for consumers who are either loss-averse or loss-neutral. Nonetheless, unlike the discrete-time framework in [37] and this paper, [39] employs the continuous-time framework, which significantly differs from its discrete-time counterpart in terms of analytical techniques. The recent article [22] also studies the long-run market behavior and bears similarity to our work in model formulations. However, a crucial difference exists: [22] assumes a transparent market setting,whereas we consider the more realistic scenario where the market is opaque and firms cannot access information of their competitors.

More closely related to our work, the work [21] also looks into the long-run market stability of the duopoly price competition in an opaque marketplace. However, there are two notable differences between our paper and theirs. The key distinction lies in the selection of demand function. We favor the logit demand over the linear demand used in [21], as the logit demand exhibits superior performance in the presence of reference effects [23; 9]. However, the logit model imposes challenges for convergence result since a crucial part of the analysis in [21] hinges on the demand linearity [21; Lemma 9.1], which is not satisfied by the logit demand. Second, [21] assumes a uniform reference price for both products, whereas we consider the product-specific reference price, which has the best empirical performance as illustrated in [4]. These adaptations, even though beneficial to the expressiveness and flexibility of the model, render the convergence analysis in [21] not generalizable to our setting.

**General convergence results for online games.** Our paper is closely related to the study of online games, where a typical research question is whether online learning algorithms can achieve the Nash equilibrium for multiple agents who aim to minimize their local loss functions. In this section, we review a few recent works in this field. For games with continuous actions, [14] and [40] show that the online mirror descent converges to the Nash equilibrium in strongly monotone games. The work [16] further relaxes the strong monotonicity assumption and examines the last-iterate convergence for games with unconstrained action sets that satisfy the so-called "cocoercive" condition. In addition, [26] and [15] establish the convergence of the dual averaging method under a more general condition called global variational stability, which encompasses the cocoercive condition as a subcase. More recently, [41; 27; 28] demonstrate that extra-gradient approaches, such as the optimistic gradient method, can achieve faster convergence to the Nash equilibrium in monotone and variationally stable games. We point out that in the cited literature above, either the assumption itself implies the convexity of the local loss function such as the strong monotonicity or the convergence to the Nash equilibrium additionally requires the loss function to be convex. By contrast, in our problem, the revenue function of each firm is not concave in its price and does not satisfy either of the properties listed above. Additionally, incorporating the reference effect further complicates the analysis, as the standard notion of Nash equilibrium is insufficient to characterize convergence due to the dynamic nature of reference price.

## 3 Problem formulation

### MNL demand model with reference effects

We study a duopoly price competition with reference price effects, where two firms each offer a substitutable product, labeled as \(H\) and \(L\), respectively. Both firms set prices simultaneously in each period throughout an infinite-time horizon. To accommodate the interaction between the two products, we employ a multinomial logit (MNL) model, which inherently captures such cross-product effects. The consumers' utility at period \(t\), which depends on the posted price \(p_{i}^{t}\) and reference price \(r_{i}^{t}\), is defined as:

\[U_{i}\left(p_{i}^{t},r_{i}^{t}\right)=u_{i}\left(p_{i}^{t},r_{i}^{t}\right)+ \epsilon_{i}^{t}=a_{i}-b_{i}\cdot p_{i}^{t}+c_{i}\cdot\left(r_{i}^{t}-p_{i}^ {t}\right)+\epsilon_{i}^{t},\quad\forall i\in\{H,L\},\] (1)

where \(u_{i}(p_{i}^{t},r_{i}^{t})\) is the deterministic component, and \((a_{i},b_{i},c_{i})\) are the given parameters. In addition, the notation \(\epsilon_{i}^{t}\) denotes the random fluctuation following the i.i.d. standard Gumbel distribution. According to the random utility maximization theory [42], the demand/market share at period \(t\) with the posted price \(\mathbf{p}^{t}=(p_{H}^{t},p_{L}^{t})\) and reference price \(\mathbf{r}^{t}=(r_{H}^{t},r_{L}^{t})\) for product \(i\in\{H,L\}\) is given by

\[d_{i}\big{(}\mathbf{p}^{t},\mathbf{r}^{t}\big{)}=d_{i}\big{(}(p_{i}^{t},p_{-i} ^{t}),(r_{i}^{t},r_{-i}^{t})\big{)}=\frac{\exp\big{(}u_{i}(p_{i}^{t},r_{i}^{t} )\big{)}}{1+\exp\big{(}u_{i}(p_{i}^{t},r_{i}^{t})\big{)}+\exp\big{(}u_{-i}(p_{ -i}^{t},r_{-i}^{t})\big{)}},\] (2)

where the subscript \(-i\) denotes the other product besides product \(i\). Consequently, the expected revenue for each firm/product at period \(t\) can be expressed as

\[\Pi_{i}(\mathbf{p}^{t},\mathbf{r}^{t})=\Pi_{i}\big{(}(p_{i}^{t},p_{-i}^{t}),( r_{i}^{t},r_{-i}^{t})\big{)}=p_{i}^{t}\cdot d_{i}(\mathbf{p}^{t},\mathbf{r}^{t}), \quad\forall i\in\{H,L\}.\] (3)

The interpretation of parameters \((a_{i},b_{i},c_{i})\) in Eq. (1) is as follows. For product \(i\in\{H,L\}\), \(a_{i}\) refers to product's intrinsic value, \(b_{i}\) represents consumers' responsiveness to price, also known as price sensitivity, and \(c_{i}\) corresponds to the reference price sensitivity. When the offered price exceeds the internal reference price \((r_{i}^{t}<p_{i}^{t})\), consumers perceive it as a loss or surcharge, whereas the price below this reference price \((r_{i}^{t}>p_{i}^{t})\) is regarded as a gain or discount. These sensitivity parameters are assumed to be positive, i.e., \(b_{i},c_{i}>0\) for \(i\in\{H,L\}\), which aligns with consumer behaviors towards substitutable products and has been widely adopted in similar pricing problems (see, e.g., [34; 8; 21; 24; 22]). Precisely, this assumption guarantees that an increase in \(p_{i}^{t}\) would result in a lower consumer utility for product \(i\), which in turn reduces its demand \(d_{i}(\mathbf{p}^{t},\mathbf{r}^{t})\) and increases the demand of the competing product \(d_{-i}(\mathbf{p}^{t},\mathbf{r}^{t})\). Conversely, a rise in the reference price \(r_{i}^{t}\) increases the utility for product \(i\), consequently influencing the consumer demands in the opposite direction.

We stipulate the feasible range for price and reference price to be \(\mathcal{P}=[p,\overline{p}]\), where \(p,\overline{p}>0\) denote the price lower bound and upper bound, respectively. This boundedness of prices is in accordance with real-world price floors or price ceilings, whose validity is further reinforced by its frequent use in the literature on price optimization with reference effects (see, e.g., [34; 8; 21]).

We formulate the reference price using the brand-specific past prices (_PastBRSP_) model proposed by [4], which posits that the reference price is product-specific and memory-based. This model is preferred over other reference price models evaluated in [4], as it exhibits superior performance in terms of fit and prediction. In particular, the reference price for product \(i\) is constructed by applying exponential smoothing to its own historical prices, where the memory parameter \(\alpha\in[0,1]\) governs the rate at which the reference price evolves. Starting with an initial reference price \(r_{0}\), the reference price update for each product at period \(t\) can be described as

\[r_{i}^{t+1}=\alpha\cdot r_{i}^{t}+(1-\alpha)\cdot p_{i}^{t},\quad\forall i\in \{H,L\},\quad t\geq 0.\] (4)

The exponential smoothing technique is among the most prevalent and empirically substantiated reference price update mechanism in the existing literature (see, e.g., [7; 1; 6; 34; 8]). We remark that the theories established in this work are readily generalizable to the scenario of time-varying memory parameters \(\alpha\), and we present the static setting only for the sake of brevity.

### Opaque market setup

In this study, we consider the partial information setting where the firms possess no knowledge of their competitors, their own reference prices, as well as the reference price update scheme. Each firm \(i\) is only aware of its own sensitivity parameters \(b_{i},c_{i}\), and its previously posted price. Under this configuration, the firms cannot directly compute their demands from the expression in Eq. (2). However, it is legitimate to assume that each firm can access its own last-period demands through market feedback, i.e., determining the demand as the received revenue divided by the posted price. We point out that, in this non-transparent and non-cooperative market, the presence of feedback mechanisms is crucial for price optimization.

### Market equilibrium and stability

The goal of our paper is to find a simple and intuitive pricing mechanism for firms so that the market equilibrium and stability can be achieved in the long-run while protecting firms' privacy. Before introducing the equilibrium motion considered in this work, we first define the _equilibrium pricing policy_ denoted by \(\mathbf{p}^{\star}(\mathbf{r})=\big{(}p_{H}^{\star}(\mathbf{r}),p_{L}^{\star} (\mathbf{r})\big{)}\), which is a function that maps reference price to price and achieves the pure strategy Nash equilibrium in the single-period game. Mathematically, the equilibrium pricing policy satisfies that

\[p_{i}^{\star}(\mathbf{r})=\operatorname*{arg\,max}_{p_{i}\in\mathcal{P}}\;p_{i }\cdot d_{i}\big{(}(p_{i},p_{-i}^{\star}(\mathbf{r})),\mathbf{r}\big{)},\quad \forall i\in\{H,L\}.\] (5)

Next, we formally introduce the concept of stationary Nash equilibrium, which is utilized to jointly characterize the market equilibrium and stability.

**Definition 3.1** (Stationary Nash equilibrium): _A point \(\mathbf{p}^{\star\star}\) is considered a stationary Nash equilibrium (SNE) if \(\mathbf{p}^{\star}(\mathbf{p}^{\star\star})=\mathbf{p}^{\star\star}\), i.e., the equilibrium price is equal to its reference price._

The notion of SNE has also been studied in [21; 22]. From Eq. (5) and Definition 3.1, we observe that an SNE possesses the following two properties:* **Equilibrium.** The revenue function for each firm \(i\in\{H,L\}\) satisfies \(\Pi_{i}\big{(}(p_{i},p_{-i}^{\star\star}),\mathbf{p}^{\star\star}\big{)}\leq\Pi_ {i}\big{(}\mathbf{p}^{\star\star},\mathbf{p}^{\star\star}\big{)}\) for all \(p_{i}\in\mathcal{P}\), i.e., when the reference price and firm \(-i\)'s price are equal to the SNE price, the best-response price for firm \(i\) is the SNE price \(p_{i}^{\star\star}\).
* **Stability.** If the price and the reference price attain the SNE at some period \(t\), the reference price remains unchanged in the following period, i.e., \(\mathbf{p}^{t}=\mathbf{r}^{t}=\mathbf{p}^{\star\star}\) implies that \(\mathbf{r}^{t+1}=\mathbf{p}^{\star\star}\).

As a result, when the market reaches the SNE, the firms have no incentive to deviate, and the market remains stable in subsequent competitions. The following proposition states the uniqueness of the SNE and characterizes the boundedness of the SNE.

**Proposition 3.1**: _There exists a unique stationary Nash equilibrium, denoted by \(\mathbf{p}^{\star\star}=(p_{H}^{\star\star},p_{L}^{\star\star})\). In addition, it holds that_

\[\frac{1}{b_{i}+c_{i}}<p_{i}^{\star\star}<\frac{1}{b_{i}+c_{i}}+\frac{1}{b_{i}} W\left(\frac{b_{i}}{b_{i}+c_{i}}\exp\left(a_{i}-\frac{b_{i}}{b_{i}+c_{i}} \right)\right),\quad\forall i\in\{H,L\},\] (6)

_where \(W(\cdot)\) is the Lambert \(W\) function (see definition in Eq. (22))._

Without loss of generality, we assume that the feasible price range \(\mathcal{P}^{2}=[\underline{p},\overline{p}]^{2}\) is sufficiently large to contain the unique SNE, i.e., \(\mathbf{p}^{\star\star}\in[\underline{p},\overline{p}]^{2}\). Proposition 3.1 provides a quantitative characterization for this assumption: it suffices to choose the price lower bound \(\underline{p}\) to be any real number between \(\big{(}0,\min_{i\in\{H,L\}}\{1/(b_{i}+c_{i})\}\big{]}\), and the price upper bound \(\overline{p}\) can be any value such that

\[\overline{p}\geq\max_{i\in\{H,L\}}\left\{\frac{1}{b_{i}+c_{i}}+\frac{1}{b_{i} }W\left(\frac{b_{i}}{b_{i}+c_{i}}\exp\left(a_{i}-\frac{b_{i}}{b_{i}+c_{i}} \right)\right)\right\}.\] (7)

This assumption is mild as the bound in Eq. (7) is independent of both the price and reference price, and it does not grow exponentially fast with respect to any parameters. Hence, there is no need for \(\overline{p}\) to be excessively large. For example, when \(a_{H}=a_{L}=10\) and \(b_{H}=b_{L}=c_{H}=c_{L}=1\), Eq. (7) becomes \(\overline{p}\geq 7.3785\). We refer the reader to Appendix B for further discussions on the structure and computation of the equilibrium pricing policy and SNE, as well as the proof of Proposition 3.1.

## 4 No-regret learning: Online Projected Gradient Ascent

In this section, we examine the long-term dynamics of the the price and reference price paths to determine if the market stabilizes over time. As studied in [22], under perfect information, the firms operating with full rationality will follow the equilibrium pricing policy in each period, while those functioning with bounded rationality will adhere to the best-response pricing policy throughout the planning horizon. In both situations, the market would stabilize in the long run. However, with partial information, the firms are incapable of computing either the equilibrium or the best-response policies due to the unavailability of reference prices and their competitor's price. Thus, one viable strategy to boost firms' revenues is to dynamically modify prices in response to market feedback.

In light of the success of gradient-based algorithms in the online learning literature (see, e.g., [43; 44; 45]), we propose the Online Projected Gradient Ascent (OPGA) method, as outlined in Algorithm 1. Specifically, in each period, both firms update their current prices using the first-order derivatives of their log-revenues with the same learning rate (see Eq. (9)). It is noteworthy that the difference between the derivatives of the log-revenue and the standard revenue is a scaling factor equal to the revenue itself, i.e.,

\[\frac{\partial\log\left(\Pi_{i}(\mathbf{p},\mathbf{r})\right)}{\partial p_{i} }=\frac{1}{\Pi_{i}(\mathbf{p},\mathbf{r})}\cdot\frac{\partial(\Pi_{i}(\mathbf{ p},\mathbf{r}))}{\partial p_{i}},\quad\forall i\in\{H,L\}.\] (8)

Therefore, the price update in Algorithm 1 can be equivalently viewed as an adaptively regularized gradient ascent using the standard revenue function, where the regularizer at period \(t\) is \(\big{(}1/\Pi_{H}(\mathbf{p}^{t},\mathbf{r}^{t}),1/\Pi_{L}(\mathbf{p}^{t}, \mathbf{r}^{t})\big{)}\).

We highlight that by leveraging the structure of MNL model, each firm \(i\) can obtain the derivative of its log-revenue \(D_{i}^{t}\) in Eq. (9) through the market feedback mechanism, i.e., last-period demand. The firms do not need to know their own reference price when executing the OPGA algorithm, and the reference price update in Line 6 is automatically performed by the market. In fact, computing the derivative \(D_{i}\) is identical to querying the first-order oracle, which is a common assumption in the optimization literature [46]. Further, this derivative can also be acquired through a minor perturbation of the posted price, even when the firms lack access to historical prices and market feedback, making the algorithm applicable in a variety of scenarios.

There are two potential ways to analyze Algorithm 1 using well-established theories. Below, we briefly introduce these methods and the underlying challenges, while referring readers to Appendix A for a more detailed discussion.

* First, by adding two virtual firms to represent the reference price, the game can be converted into a standard four-player online game, effectively eliminating the evolution of the underlying state (reference price). However, the challenge in analyzing this four-player game arises from the fact that, while real firms have the flexibility to dynamically adjust their step-sizes, the learning rate for virtual firms is fixed to the constant \((1-\alpha)\), where \(\alpha\) is the memory parameter for reference price updates. This disparity hinders the direct application of the existing results from multi-agent online learning literature, as these results typically require the step-sizes of all agents either diminish at comparable rates or remain as a small enough constant [47; 48; 14; 15].
* The second approach involves translating the OPGA algorithm into a discrete nonlinear system by treating \((\mathbf{p}^{t+1},\mathbf{r}^{t+1})\) as a vector-valued function of \((\mathbf{p}^{t},\mathbf{r}^{t})\), i.e., \((\mathbf{p}^{t+1},\mathbf{r}^{t+1})=\mathbf{f}(\mathbf{p}^{t},\mathbf{r}^{t})\) for some function \(\mathbf{f}(\cdot)\). In this context, analyzing the convergence of Algorithm 1 is equivalent to examining the stability of the fixed point of \(\mathbf{f}(\cdot)\), which is related to the spectral radius of the Jacobian matrix \(\nabla\mathbf{f}(\mathbf{p}^{\star\star},\mathbf{p}^{\star\star})\)[49; 50]. However, the SNE lacks a closed-form expression, making it difficult to calculate the eigenvalues of \(\nabla\mathbf{f}(\mathbf{p}^{\star\star},\mathbf{p}^{\star\star})\). In addition, the function \(\mathbf{f}(\cdot)\) is non-smooth due to the presence of the projection operator and can become non-stationary when the firms adopt time-varying step-sizes, such as diminishing step-sizes. Moreover, typical results in dynamical systems only guarantee local convergence [51], i.e., the asymptotic stability of the fixed point, whereas our goal is to establish the global convergence of both the price and reference price.

In the following section, we show that the OPGA algorithm with diminishing step-sizes converges to the unique SNE by exploiting characteristic properties of our model. This convergence result indicates that the OPGA algorithm provably achieves the no-regret learning, i.e., in the long run, the algorithm performs at least as well as the best fixed action in hindsight. However, it is essential to note that the reverse is not necessarily true: being no-regret does not guarantee the convergence at all, let alone the convergence to an equilibrium (see, e.g., [52; 53]). In fact, beyond the finite games, the agents may exhibit entirely unpredictable and chaotic behaviors under a no-regret policy [54].

## 5 Convergence results

In this section, we investigate the convergence properties of the OPGA algorithm. First, in Theorem 5.1, we establish the global convergence of the price path and reference price to the unique SNE under diminishing step-sizes. Subsequently, in Theorem 5.2, we further show that this convergence exhibits a rate of \(\mathcal{O}(1/t)\), provided that the step-sizes are selected appropriately. The primary proofs for this section can be found in Appendices C and D, while supporting lemmas are located in Appendix F.

**Theorem 5.1** (Global convergence): _Let the step-sizes \(\{\eta^{t}\}_{t\geq 0}\) be a non-increasing sequence such that \(\lim_{t\to\infty}\eta^{t}=0\) and \(\sum_{t=0}^{\infty}\eta^{t}=\infty\) hold. Then, the price paths and reference price paths generated by Algorithm 1 converge to the unique stationary Nash equilibrium._

Theorem 5.1 demonstrates the global convergence of the OPGA algorithm to the SNE, thus ensuring the market equilibrium and stability in the long-run. Compared to [22] that establishes the convergence to SNE under the perfect information setting, Theorem 5.1 ensures that such convergence can also be achieved in an opaque market where the firms are reluctant to share the information with their competitors. The only condition we need for the convergence is diminishing step-sizes such that \(\lim_{t\to\infty}\eta^{t}=0\) and \(\sum_{t=0}^{\infty}\eta^{t}=\infty\). This assumption is widely adopted in the study of online games (see, e.g., [15, 14, 40]). Since the firms will likely become more familiar with their competitors through repeated competitions, it is reasonable for the firms to gradually become more conservative in adjusting their prices and decrease their learning rates.

As discussed in Sections 2 and 4, the existing methods in the online game and dynamical system literatures are not applicable to our problem due to the absence of standard structural properties and the presence of the underlying dynamic state, i.e., reference price. Consequently, we develop a novel analysis to prove Theorem 5.1, leveraging the characteristic properties of the MNL demand model. We provide a proof sketch below, with the complete proof deferred to Appendix C. Our proof consists of two primary parts:

* In **Part 1** (Appendix C.1), we show that the price path \(\{\mathbf{p}^{t}\}_{t\geq 0}\) would enter the neighborhood \(N_{\epsilon}^{1}:=\left\{\mathbf{p}\in\mathcal{P}^{2}\mid\varepsilon(\mathbf{ p})<\epsilon\right\}\) infinitely many times for any \(\epsilon>0\), where \(\varepsilon(\cdot)\) is a weighted \(\ell_{1}\) distance function defined as \(\varepsilon(\mathbf{p}):=|p_{H}^{\star\star}-p_{H}|/(b_{H}+c_{H})+|p_{L}^{ \star\star}-p_{L}|/(b_{L}+c_{L})\). To prove Part 1, we divide \(\mathcal{P}^{2}\) into four quadrants with \(\mathbf{p}^{\star\star}\) as the origin. Then, employing a contradiction-based argument, we suppose that the price path only visits \(N_{\epsilon}^{1}\) finitely many times. Yet, we show that this forces the price path to oscillate between adjacent quadrants and ultimately converge to the SNE, which violates the initial assumption.
* In **Part 2** (Appendix C.2), we show that when the price path \(\{\mathbf{p}^{t}\}_{t\geq 0}\) enters the \(\ell_{2}\)-neighborhood \(N_{\epsilon}^{2}:=\left\{\mathbf{p}\in\mathcal{P}^{2}\mid\|\mathbf{p}-\mathbf{ p}^{\star\star}\|_{2}<\epsilon\right\}\) for some sufficiently small \(\epsilon>0\) and with small enough step-sizes, the price path will remain in \(N_{\epsilon}^{2}\) in subsequent periods. The proof of Part 2 relies on a local property of the MNL demand model around the SNE, with which we demonstrate that the price update provides adequate ascent to ensure the price path stays within the target neighborhood.

Owing to the equivalence between different distance functions in Euclidean spaces [55], these two parts jointly imply the convergence of the price path to the SNE. Since the reference price is equal to an exponential smoothing of the historical prices, the convergence of the reference price path follows that of the price path.

It is worth noting that [21, Theorem 5.1] also employs a two-part proof and shows the asymptotic convergence of online mirror descent [56, 57] to the SNE in the linear demand setting. However, their analysis heavily depends on the linear structure of the demand, which ensures that a property similar to the variational stability is globally satisfied [21, Lemma 9.1]. In contrast, such properties no longer hold for the MNL demand model considered in this paper. Therefore, we come up with two distinct distance functions for the two parts of the proof, respectively. Moreover, the proof by [21] relies on an assumption concerning the relationship between responsiveness parameters, whereas our convergence analysis only requires the minimum assumption that the responsiveness parameters are positive (otherwise, the model becomes counter-intuitive for substitutable products).

**Theorem 5.2** (Convergence rate): _When both firms adopt Algorithm 1, there exists a sequence of step-sizes \(\{\eta^{t}\}_{t\geq 0}\) with \(\eta^{t}=\Theta(1/t)\) and constants \(d_{p},d_{r}>0\) such that_

\[\left\|\mathbf{p}^{\star\star}-\mathbf{p}^{t}\right\|_{2}^{2}\leq\frac{d_{p}} {t},\quad\left\|\mathbf{p}^{\star\star}-\mathbf{r}^{t}\right\|_{2}^{2}\leq \frac{d_{r}}{t},\quad\forall t\geq 1.\] (10)

Theorem 5.2 improves the result of Theorem 5.1 by demonstrating the non-asymptotic convergence rate for the price and reference price. Although non-concavity usually anticipates slower convergence, our rate of \(\mathcal{O}(1/t)\) matches [21, Theorem 5.2] that assumes linear demand and exhibits concavity.

The proof of Theorem 5.2 is primarily based on the local convergence rate when the price vector remains in a specific neighborhood \(N_{\epsilon_{0}}^{2}\) of the SNE after some period \(T_{\epsilon_{0}}\). As the choice \(\eta^{t}=\Theta(1/t)\)ensures that \(\lim_{t\to\infty}\eta^{t}=0\) and \(\sum_{\epsilon=0}^{\infty}\eta^{t}=\infty\), the existence of such a period \(T_{\epsilon_{0}}\) is guaranteed by Theorem 5.1. Utilizing an inductive argument, we first show that the difference between price and reference price decreases at a faster rate of \(\mathcal{O}(1/t^{2})\), i.e., \(\left\|\mathbf{r}^{t}-\mathbf{p}^{t}\right\|_{2}^{2}=\mathcal{O}\left(1/t^{2} \right),\,\forall t\geq 1\) (see Eq. (67)). Then, by exploiting a local property around the SNE (Lemma F.3), we use another induction to establish the convergence rate of the price path after it enters the neighborhood \(N_{\epsilon_{0}}^{2}\). In the meanwhile, the convergence rate of the reference price path can be determined through a triangular inequality: \(\left\|\mathbf{p}^{\star\star}-\mathbf{r}^{t}\right\|_{2}^{2}=\left\|\mathbf{p }^{\star\star}-\mathbf{p}^{t}+\mathbf{p}^{t}-\mathbf{r}^{t}\right\|_{2}^{2} \leq 2\left\|\mathbf{p}^{\star\star}-\mathbf{p}^{t}\right\|_{2}^{2}+2 \left\|\mathbf{p}^{t}-\mathbf{r}^{t}\right\|_{2}^{2}\). Finally, due to the boundedness of the feasible price range \(\mathcal{P}^{2}\), we can obtain the global convergence rate for all \(t\geq 1\) by choosing sufficiently large constants \(d_{p}\) and \(d_{r}\).

**Remark 5.3** (Constant step-sizes): _The convergence analysis presented in this work can be readily extended to accommodate constant step-sizes. Particularly, our theoretical framework supports the selection of \(\eta^{t}\equiv\mathcal{O}(\epsilon_{0})\), where \(\epsilon_{0}\) refers to the size of the neighborhood utilized in Theorem 5.2. When \(\eta^{t}\equiv\mathcal{O}(\epsilon_{0})\), an approach akin to **Part 1** can be employed to demonstrate that the price path enters the neighborhood \(N_{\epsilon}^{1}\) infinitely many times for any \(\epsilon\geq\mathcal{O}(\epsilon_{0})\). Subsequently, by exploiting the local property in a manner similar to **Part 2**, we can establish that once the price path enters the neighborhood \(N_{\epsilon}^{2}\) for some \(\epsilon=\mathcal{O}(\epsilon_{0})\), it will remain within that neighborhood._

We perform two numerical experiments, differentiated solely by their sequences of step-sizes, to highlight the significance of step-sizes in achieving the convergence. In particular, Example 1 (see Figure 0(a)) corroborates Theorem 5.1 by demonstrating that the price and reference price trajectories converge to the unique SNE when we choose diminishing step-sizes that fulfill the criteria specified in Theorem 5.1. By comparison, the over-large constant step-sizes employed in Example 2 (see Figure 0(b)) fails to ensure convergence, leading to cyclic patterns in the long run. Moreover, in Example 3 (see Figure 0(c)), we compare the OPGA algorithm and the repeated application of the equilibrium pricing policy in Eq. (5) by plotting the reference price trajectories produced by both approaches. Figure 0(c) conveys that the two algorithms reach the SNE at a comparable rate, which indicates that the OPGA algorithm allows firms to attain the market equilibrium and stability as though they operate under perfect information, while preventing excessive information disclosure.

## 6 Extensions

In previous sections, we assume that each firm \(i\) possesses accurate information regarding its sensitivity parameters \((b_{i},c_{i})\) as well as its realized market share \(d_{i}^{t}\). This is equivalent to having access to an exact first-order oracle. However, a more practical scenario to consider is one where the firm can only obtain a rough approximation for its market share and needs to estimate the sensitivities from historical data. This would bring extra noise to the computation of the first-order derivative \(D_{i}^{t}\) in Eq. (9). In this section, we first elaborate on the feasibility of estimating the market share and sensitivities from realistic data. Then, we discuss the impact of an inexact first-order oracle on the convergence.

We consider the approximation of market share and the calibration of sensitivities under both _uncensored_ and _censored_ data cases. With uncensored data, both purchase and no-purchase data are

Figure 1: Price and reference price paths for Examples 1, 2, and 3, where the parameters are \((a_{H},b_{H},c_{H})=(8.70,2.00,0.82)\), \((a_{L},b_{L},c_{L})=(4.30,1.20,0.32)\), \((r_{H}^{0},r_{L}^{0})=(0.10,2.95)\), \((p_{H}^{0},p_{L}^{0})=(4.85,4.86)\), and \(\alpha=0.90\).

available, a scenario analogous to firms selling substitute goods on third-party online retail platforms like Amazon. The platform can track the non-purchase statistics by monitoring consumers who visited its website but did not purchase any product. Consequently, this facilitates a direct estimation of the total market size and, when complemented with sales quantities, allows for a precise computation of the firm's market share. Additionally, sensitivity parameters can be efficiently calibrated through the classical Maximum Likelihood Estimation (MLE) method. Due to the concavity of the log-likelihood function for the MNL model with respect to its parameters, many numerical algorithms (e.g., Newton-Raphson, BHHH-2 [58], and the steepest ascent) are guaranteed to improve at each iteration and achieve fast convergence [59, 60].

In many cases, the traditional transaction data only captures the realized demand, with non-purchases typically unrecorded. This scenario is known as the censored data case. In this case, the sensitives and the total market size of the MNL model can be estimated via the generalized expectation-maximization (GEM) gradient method proposed by [59], which is an iterative algorithm that is inspired by the expectation-maximization (EM) approach. The capability to approximate the sensitivity parameters, the market share, and thereby the gradient \(D_{i}^{t}\) enhances the credibility and practicability of the OPGA algorithm, suggesting its great potential for broader applications in retailing.

In the presence of approximation errors, firms cannot precisely compute the derivative \(D_{i}^{t}\). Hence, the convergence results in Section 5 are not directly applicable. Indeed, if the errors are disruptive enough, one can anticipate Algorithm 1 to possibly not show any convergent behavior. However, if the errors are uniformly bounded by some small number \(\delta\), the following theorem demonstrates that both the price and reference price paths converge to a \(\mathcal{O}(\delta)\)-neighborhood of the unique SNE.

**Theorem 6.1** (Inexact first-order oracle): _Suppose both firms only have access to an inexact first-order oracle such that \(|D_{i}^{t}-\partial\log(\Pi_{i}(\mathbf{p}^{t},\mathbf{r}^{t}))/\partial p_{ i}|\leq\delta,\;\forall i\in\{H,L\}\) and \(\forall t\geq 0\). Let the step-sizes \(\{\eta^{t}\}_{t\geq 0}\) be a non-increasing sequence such that \(\lim_{t\rightarrow\infty}\eta^{t}=0\) and \(\sum_{t=0}^{\infty}\eta^{t}=\infty\) hold. Then, the price paths reference price paths generated by Algorithm 1 converge to a neighborhood with radius \(\mathcal{O}(\delta)\) of the unique SNE._

We remark that the inexact first-order oracle studied in our setting is different from the stochastic gradient, which generally assumes a zero-mean noise with finite variance. In that case, it is possible to derive the convergence to a limiting point in expectation or with high probability. In contrast, the noise in \(D_{i}^{t}\) is a kind of approximation error without any distributional properties. Therefore, with the step-sizes defined in Theorem 6.1, we expect the price and reference price paths to converge to the neighborhood of the SNE, but continue to fluctuate around the neighborhood without admitting a limiting point.

The proof of Theorem 6.1 is based upon Theorem 5.1. Specifically, we demonstrate that the inexact gradient still guides the price path toward the SNE if the magnitude of the true gradient dominates the noise. Conversely, if noise levels are comparable with the true gradient, we show that the price path is already close to the SNE. The formal proof of Theorem 6.1 can be found in Appendix E

## 7 Conclusion and future work

This article considers the price competition with reference effects in an opaque market, where we formulate the problem as an online game with an underlying dynamic state, known as reference price. We accomplish the goal of simultaneously capturing the market equilibrium and stability via proposing the no-regret algorithm named OPGA and providing the theoretical guarantee for its global convergence to the SNE. In addition, under appropriate step-sizes, we show that the OPGA algorithm has the convergence rate of \(\mathcal{O}(1/t)\).

In this paper, we focus on the symmetric reference effects, where consumers exhibit equal sensitivity to the gains and losses. As empirical studies suggest that consumers may display asymmetric reactions [61, 32, 62], one possible extension involves accounting for asymmetric reference effects displayed by loss-averse and gain-seeking consumers. Additionally, while our study considers the duopoly competition between two firms, it would be valuable to explore the more general game involving \(n\) players. Lastly, our research is based on a deterministic setting and pure strategy Nash equilibrium. Another intriguing direction for future work is to investigate mixed-strategy learning [63] in dynamic competition problems.

## Acknowledgement

We extend our gratitude to the anonymous reviewers for their insightful comments. This research was particularly supported by NSF China Grant 71991462.

## References

* [1] Tridib Mazumdar, Sevilimedu P Raj, and Indrajit Sinha. Reference price research: Review and propositions. _Journal of Marketing_, 69(4):84-102, 2005.
* [2] Bruce GS Hardie, Eric J Johnson, and Peter S Fader. Modeling loss aversion and reference dependence effects on brand choice. _Marketing Science_, 12(4):378-394, 1993.
* [3] James M Lattin and Randolph E Bucklin. Reference effects of price and promotion on brand choice behavior. _Journal of Marketing Research_, 26(3):299-310, 1989.
* [4] Richard A Briesch, Lakshman Krishnamurthi, Tridib Mazumdar, and Sevilimedu P Raj. A comparative analysis of reference price models. _Journal of Consumer Research_, 24(2):202-214, 1997.
* [5] Gurumurthy Kalyanaram and Russell S Winer. Empirical generalizations from reference price research. _Marketing Science_, 14(3_supplement):G161-G169, 1995.
* [6] Ioana Popescu and Yaozhong Wu. Dynamic pricing strategies with reference effects. _Operations Research_, 55(3):413-429, 2007.
* [7] Gadi Fibich, Arieh Gavious, and Oded Lowengart. Explicit solutions of optimization models and differential games with nonsmooth (asymmetric) reference-price effects. _Operations Research_, 51(5):721-734, 2003.
* [8] Xin Chen, Peng Hu, and Zhenyu Hu. Efficient algorithms for the dynamic pricing problem with reference price effect. _Management Science_, 63(12):4389-4408, 2017.
* [9] Hansheng Jiang, Junyu Cao, and Zuo-Jun Max Shen. Intertemporal pricing via nonparametric estimation: Integrating reference effects and consumer heterogeneity. _Manufacturing & Service Operations Management_, Article in advance, 2022.
* [10] Don Tapscott and David Ticoll. _The naked corporation: How the age of transparency will revolutionize business_. Simon and Schuster, 2003.
* [11] Robert Bloomfield and Maureen O'Hara. Can transparent markets survive? _Journal of Financial Economics_, 55(3):425-459, 2000.
* [12] Tim Wilson. B2b sellers fight back on pricing. _Internet Week_, 841:1-2, 2000.
* [13] Nelson Granados and Alok Gupta. Transparency strategy: Competing with information in a digital world. _MIS quarterly_, pages 637-641, 2013.
* [14] Mario Bravo, David Leslie, and Panayotis Mertikopoulos. Bandit learning in concave n-person games. _Advances in Neural Information Processing Systems_, 31, 2018.
* [15] Panayotis Mertikopoulos and Zhengyuan Zhou. Learning in games with continuous action sets and unknown payoff functions. _Mathematical Programming_, 173:465-507, 2019.
* [16] Tianyi Lin, Zhengyuan Zhou, Panayotis Mertikopoulos, and Michael Jordan. Finite-time last-iterate convergence for multi-agent learning in games. In _International Conference on Machine Learning_, pages 6161-6171. PMLR, 2020.
* [17] Richard E Caves and Michael E Porter. Market structure, oligopoly, and stability of market shares. _The Journal of Industrial Economics_, pages 289-313, 1978.
* [18] Jing-Sheng Song and Paul Zipkin. Inventory control in a fluctuating demand environment. _Operations Research_, 41(2):351-370, 1993.

* [19] Yossi Aviv and Awi Federgruen. Capacitated multi-item inventory systems with random and seasonally fluctuating demands: implications for postponement strategies. _Management Science_, 47(4):512-531, 2001.
* [20] James T Treharne and Charles R Sox. Adaptive inventory control for nonstationary demand and partial information. _Management Science_, 48(5):607-624, 2002.
* [21] Negin Golrezaei, Patrick Jaillet, and Jason Cheuk Nam Liang. No-regret learning in price competitions under consumer reference effects. _Advances in Neural Information Processing Systems_, 33:21416-21427, 2020.
* [22] Mengzi Amy Guo and Zuo-Jun Max Shen. Duopoly price competition with reference effects under logit demand. _Available at SSRN 4389003_, 2023.
* [23] Ruxian Wang. When prospect theory meets consumer choice models: Assortment and pricing management with reference prices. _Manufacturing & Service Operations Management_, 20(3):583-600, 2018.
* [24] Mengzi Amy Guo, Hansheng Jiang, and Zuo-Jun Max Shen. Multi-product dynamic pricing with reference effects under logit demand. _Available at SSRN 4189049_, 2022.
* [25] Tatiana Tatarenko and Maryam Kamgarpour. Learning generalized nash equilibria in a class of convex games. _IEEE Transactions on Automatic Control_, 64(4):1426-1439, 2018.
* [26] Panayotis Mertikopoulos and Mathias Staudigl. Convergence to nash equilibrium in continuous games with noisy first-order feedback. In _2017 IEEE 56th Annual Conference on Decision and Control (CDC)_, pages 5609-5614. IEEE, 2017.
* [27] Yu-Guan Hsieh, Kimon Antonakopoulos, and Panayotis Mertikopoulos. Adaptive learning in continuous games: Optimal regret bounds and convergence to nash equilibrium. In _Conference on Learning Theory_, pages 2388-2422. PMLR, 2021.
* [28] Yu-Guan Hsieh, Kimon Antonakopoulos, Volkan Cevher, and Panayotis Mertikopoulos. No-regret learning in games with noisy feedback: Faster rates and adaptivity via learning rate separation. _Advances in Neural Information Processing Systems_, 35:6544-6556, 2022.
* [29] Jacob Abernethy, Peter L Bartlett, Alexander Rakhlin, and Ambuj Tewari. Optimal strategies and minimax lower bounds for online convex games. _COLT '08: Proceedings of the 21st Annual Conference on Learning Theory_, pages 415-423, 2008.
* [30] Geoffrey J Gordon, Amy Greenwald, and Casey Marks. No-regret learning in convex games. In _Proceedings of the 25th international conference on Machine learning_, pages 360-367, 2008.
* [31] Harry Helson. _Adaptation-level theory: An experimental and systematic approach to behavior_. Harper and Row: New York, 1964.
* [32] Gurumurthy Kalyanaram and John DC Little. An empirical analysis of latitude of price acceptance in consumer package goods. _Journal of Consumer Research_, 21(3):408-418, 1994.
* [33] John G Lynch Jr and Thomas K Srull. Memory and attentional factors in consumer choice: Concepts and research methods. _Journal of Consumer Research_, 9(1):18-37, 1982.
* [34] Zhenyu Hu, Xin Chen, and Peng Hu. Dynamic pricing with gain-seeking reference price effects. _Operations Research_, 64(1):150-157, 2016.
* [35] Arnoud V den Boer and N Bora Keskin. Dynamic pricing with demand learning and reference effects. _Management Science_, 68(10):7112-7130, 2022.
* [36] Sheng Ji, Yi Yang, and Cong Shi. Online learning and pricing for multiple products with reference price effects. _Available at SSRN 4349904_, 2023.
* [37] Brian Coulter and Srini Krishnamoorthy. Pricing strategies with reference effects in competitive industries. _International transactions in operational Research_, 21(2):263-274, 2014.

* [38] Awi Federgruen and Lijian Lu. Price competition based on relative prices. _Columbia Business School Research Paper_, (13-9), 2016.
* [39] Luca Colombo and Paola Labrecciosa. Dynamic oligopoly pricing with reference-price effects. _European Journal of Operational Research_, 288(3):1006-1016, 2021.
* [40] Tianyi Lin, Zhengyuan Zhou, Wenjia Ba, and Jiawei Zhang. Optimal no-regret learning in strongly monotone games with bandit feedback. _arXiv preprint arXiv:2112.02856_, 2021.
* [41] Noah Golowich, Sarath Pattathil, and Constantinos Daskalakis. Tight last-iterate convergence rates for no-regret learning in multi-player games. _Advances in neural information processing systems_, 33:20766-20778, 2020.
* [42] Daniel McFadden. Conditional logit analysis of qualitative choice behavior. _Frontiers in Econometrics_, pages 105-142, 1974.
* [43] Martin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In _Proceedings of the 20th international conference on machine learning (icml-03)_, pages 928-936, 2003.
* [44] Elad Hazan, Amit Agarwal, and Satyen Kale. Logarithmic regret algorithms for online convex optimization. _Machine Learning_, 69(2-3):169-192, 2007.
* [45] Jacob Abernethy, Peter L Bartlett, and Elad Hazan. Blackwell approachability and no-regret learning are equivalent. In _Proceedings of the 24th Annual Conference on Learning Theory_, pages 27-46. JMLR Workshop and Conference Proceedings, 2011.
* [46] Yurii Nesterov. _Introductory lectures on convex optimization: A basic course_, volume 87. Springer Science & Business Media, 2003.
* [47] Anna Nagurney and Ding Zhang. _Projected dynamical systems and variational inequalities with applications_, volume 2. Springer Science & Business Media, 1995.
* [48] Gesualdo Scutari, Daniel P Palomar, Francisco Facchinei, and Jong-Shi Pang. Convex optimization, game theory, and variational inequality theory. _IEEE Signal Processing Magazine_, 27(3):35-49, 2010.
* [49] David K Arrowsmith, Colin M Place, CH Place, et al. _An introduction to dynamical systems_. Cambridge university press, 1990.
* [50] Peter J Olver. Nonlinear systems. _Lecture Notes, University of Minnesota_, 2015.
* [51] H.K. Khalil. _Nonlinear Systems_. Pearson Education. Prentice Hall, 2002.
* [52] Panayotis Mertikopoulos, Christos Papadimitriou, and Georgios Piliouras. Cycles in adversarial regularized learning. _SODA '18: Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete Algorithms_, pages 2703-2717, 2018.
* [53] Panayotis Mertikopoulos, Bruno Lecouat, Houssam Zenati, Chuan-Sheng Foo, Vijay Chandrasekhar, and Georgios Piliouras. Optimistic mirror descent in saddle-point problems: Going the extra (gradient) mile. In _ICLR 2019-7th International Conference on Learning Representations_, pages 1-23, 2019.
* [54] Gerasimos Palaiopanos, Ioannis Panageas, and Georgios Piliouras. Multiplicative weights update with constant step-size in congestion games: Convergence, limit cycles and chaos. _Advances in Neural Information Processing Systems_, 30, 2017.
* [55] W. Rudin. _Real and Complex Analysis_. Mathematics series. McGraw-Hill, 1987.
* [56] Zhengyuan Zhou, Panayotis Mertikopoulos, Aris L Moustakas, Nicholas Bambos, and Peter Glynn. Mirror descent learning in continuous games. In _2017 IEEE 56th Annual Conference on Decision and Control (CDC)_, pages 5776-5783. IEEE, 2017.
* [57] Steven CH Hoi, Doyen Sahoo, Jing Lu, and Peilin Zhao. Online learning: A comprehensive survey. _Neurocomputing_, 459:249-289, 2021.

* [58] Ernst R Berndt, Bronwyn H Hall, Robert E Hall, and Jerry A Hausman. Estimation and inference in nonlinear structural models. In _Annals of Economic and Social Measurement, Volume 3, Number 4_, pages 653-665. NBER, 1974.
* [59] Ruxian Wang and Zizhuo Wang. Consumer choice models with endogenous network effects. _Management Science_, 63(11):3944-3960, 2017.
* [60] Kenneth E Train. _Discrete choice methods with simulation_. Cambridge university press, 2009.
* [61] MU Kalwani, CK Yim, HJ Rinne, and Y Sugita. 0a price expectations model of consumer brand choice. _V Journal of Marketing Research_, 27, 1990.
* [62] Robert Slonim and Ellen Garbarino. Similarities and differences between stockpiling and reference effects. _Managei and Decision Economics_, 30(6):351-371, 2009.
* [63] Steven Perkins, Panayotis Mertikopoulos, and David S Leslie. Mixed-strategy learning with continuous action sets. _IEEE Transactions on Automatic Control_, 62(1):379-384, 2015.
* [64] Eric Mazumdar, Lillian J Ratliff, and S Shankar Sastry. On gradient-based learning in continuous games. _SIAM Journal on Mathematics of Data Science_, 2(1):103-131, 2020.
* [65] Eric W Weisstein. Lambert w-function. _https://mathworld. wolfram. com/_, 2002.

## Appendix A Discussion about alternative methods

As we briefly mentioned in Section 3, our problem can also be translated into a four-player online game or a dynamical system. In this section, we will discuss these alternative methods and explain why existing tools from the literature of online game and dynamical system cannot be applied.

### Four-player online game formulation

By viewing the underlying state variables \((r_{H},r_{L})\) as virtual players that undergo deterministic transitions, we are able to convert our problem into a general four-player game. Specifically, we can construct revenue functions \(R_{i}(p_{i},r_{i})\) for \(i\in\{H,L\}\) and a common sequence of step-sizes \(\{\eta_{r}^{t}\}_{t\geq 0}\) for the two virtual players such that when firms \(H\), \(L\) and virtual players implement OPGA using the corresponding step-sizes, the resulting price path \(\{\mathbf{p}^{t}\}_{t\geq 0}\) and reference price path \(\{\mathbf{r}^{t}\}_{t\geq 0}\) recover those generated by Algorithm 1. The functions \(R_{i}(\cdot,\cdot),\forall i\in\{H,L\}\) and step-sizes \(\{\eta_{r}^{t}\}_{t\geq 0}\) are specified as follows

\[R_{i}(p_{i},r_{i}) =-\frac{1}{2}r_{i}^{2}+r_{i}\cdot p_{i},\quad\forall i\in\{H,L\};\] (11) \[\eta_{r}^{t} \equiv 1-\alpha,\quad\forall t\geq 0.\]

Then, given the initial reference price \(\mathbf{r}^{0}\) and initial price \(\mathbf{p}^{0}\), the four players respectively update their states through the online projected gradient ascent specified as follows, for \(t\geq 0\):

\[\left\{\begin{array}{l}p_{H}^{t+1}=\mathrm{Proj}_{\mathcal{P}} \left(p_{H}^{t}+\eta^{t}\cdot\frac{\partial\log\left(\Pi_{H}(\mathbf{p}^{t}, \mathbf{r}^{t})\right)}{\partial p_{H}}\right)=\mathrm{Proj}_{\mathcal{P}} \left(p_{H}^{t}+\eta^{t}D_{H}^{t}\right),\\ p_{L}^{t+1}=\mathrm{Proj}_{\mathcal{P}}\left(p_{L}^{t}+\eta^{t}\cdot\frac{ \partial\log\left(\Pi_{L}(\mathbf{p}^{t},\mathbf{r}^{t})\right)}{\partial p_{ L}}\right)=\mathrm{Proj}_{\mathcal{P}}\left(p_{L}^{t}+\eta^{t}D_{L}^{t} \right),\\ r_{H}^{t+1}=\mathrm{Proj}_{\mathcal{P}}\left(r_{H}^{t}+\eta_{r}^{t}\cdot\frac{ \partial R_{H}(p_{H}^{t},r_{H}^{t})}{\partial r_{H}}\right)=\mathrm{Proj}_{ \mathcal{P}}\left(\alpha r_{H}^{t}+(1-\alpha)p_{H}^{t}\right),\\ r_{L}^{t+1}=\mathrm{Proj}_{\mathcal{P}}\left(r_{L}^{t}+\eta_{r}^{t}\cdot\frac{ \partial R_{L}(p_{L}^{t},r_{L}^{t})}{\partial r_{L}}\right)=\mathrm{Proj}_{ \mathcal{P}}\left(\alpha r_{L}^{t}+(1-\alpha)p_{L}^{t}\right).\end{array}\right.\] (12)

It can be easily seen that the pure strategy Nash equilibrium of this four-player static game is equivalent to the SNE of the original two-player dynamic game, as defined in Definition 3.1. However, even after converting to the static game, no general convergence results are readily applicable in this setting. One obstacle on the convergence analysis comes from the absence of critical properties, such as monotonicity of the static game [14, 16] or variational stability at its Nash equilibrium [26, 15].

Meanwhile, anther obstacle stems from the asynchronous updates for real firms (price players) and virtual firms (reference price players). While the real firms have the flexibility in adopting time-varying step-sizes, the updates for the two virtual firms in Eq. (12) stick to the constant step-size of \((1-\alpha)\). As a result, this rigidity of virtual players perplexes the analysis, given that the typical convergence results of online games call for the step-sizes of multiple players to have the same pattern (all diminishing or constant step-sizes) [47, 48, 14, 15].

### Dynamical system formulation

The study of the limiting behavior of a competitive gradient-based learning algorithm is related to dynamical system theories [64]. In fact, the update of Algorithm 1 can be viewed as a nonlinear dynamical system. Assume a constant step-size is employed, i.e., \(\eta^{t}\equiv\eta\), \(\forall t\geq 0\). Then, Lines 5 and 6 in Algorithm 1 are equivalent to the dynamical system

\[(\mathbf{p}^{t+1},\mathbf{r}^{t+1})=\mathbf{f}(\mathbf{p}^{t},\mathbf{r}^{t}),\quad\forall t\geq 0,\] (13)where \(\mathbf{f}(\cdot)\) is a vector-valued function defined as

\[\mathbf{f}(\mathbf{p},\mathbf{r}):=\left(\begin{array}{c}\mathrm{ Proj}_{\mathcal{P}}\left(p_{H}+\eta\left(\frac{1}{p_{H}}+(b_{H}+c_{H})\cdot d_{H}( \mathbf{p},\mathbf{r})-(b_{H}+c_{H})\right)\right)\\ \mathrm{Proj}_{\mathcal{P}}\left(p_{L}+\eta\left(\frac{1}{p_{L}}+(b_{L}+c_{L}) \cdot d_{L}(\mathbf{p},\mathbf{r})-(b_{L}+c_{L})\right)\right)\\ \mathrm{Proj}_{\mathcal{P}}\left(\alpha r_{H}+(1-\alpha)p_{H}\right)\\ \mathrm{Proj}_{\mathcal{P}}\left(\alpha r_{L}+(1-\alpha)p_{L}\right)\end{array} \right).\] (14)

Under the assumption that \(\mathbf{p}^{\star\star}\in\mathcal{P}^{2}\), it is evident that \(\mathbf{p}^{\star\star}\) is the unique fixed point of the system in Eq. (13). Generally, fixed points can be categorized into three classes:

* _asymptotically stable_, when all nearby solutions converge to it,
* _stable_, when all nearby solutions remain in close proximity,
* _unstable_, when almost all nearby solutions diverge away from the fixed point.

Hence, if we can demonstrate the asymptotic stability of \(\mathbf{p}^{\star\star}\), we can at least prove the local convergence of the price and reference price.

Standard dynamical systems theory [49; 50] states that \(\mathbf{p}^{\star\star}\) is asymptotically stable if the spectral radius of the Jacobian matrix \(\nabla\mathbf{f}(\mathbf{p}^{\star\star},\mathbf{p}^{\star\star})\) is strictly less than one. However, computing the spectral radius is not straightforward. The primary challenge stems from the fact that, while the entries of \(\nabla\mathbf{f}(\mathbf{p}^{\star\star},\mathbf{p}^{\star\star})\) contain \(\mathbf{p}^{\star\star}\) and \(d_{i}(\mathbf{p}^{\star\star},\mathbf{p}^{\star\star})\), there is no closed-form expression for \(\mathbf{p}^{\star\star}\).

Apart from the above issue, it is worth noting that the function \(f(\cdot)\) is not globally smooth due to the presence of the projection operator. Furthermore, the function \(f(\cdot)\) also depends on the step-size \(\eta\). When firms adopt time-varying step-sizes, the dynamical system in Eq. (13) becomes non-stationary, i.e., \((\mathbf{p}^{t+1},\mathbf{r}^{t+1})=\mathbf{f}^{t}(\mathbf{p}^{t},\mathbf{r} ^{t})\). Although the sequence of functions \(\mathbf{f}^{t}_{t\geq 0}\) shares the same fixed point, verifying the convergence (stability) of the system requires examining the spectral radius of \(\nabla\mathbf{f}^{t}(\mathbf{p}^{\star\star},\mathbf{p}^{\star\star})\) for all \(t\geq 0\).

Most importantly, even if asymptotic stability holds, it can only guarantee local convergence of Algorithm 1. Our goal, however, is to prove global convergence, such that both the price and reference price converge to the SNE for arbitrary initializations.

## Appendix B More details about SNE

### Connection between equilibrium pricing policy and SNE

First, we further elaborate on the connection between equilibrium pricing policy and SNE. The work [22] investigates the properties of equilibrium pricing policy under the full information setting. They demonstrate that the policy \(\mathbf{p}^{\star}(\mathbf{r})\) is a well-defined function since it outputs a unique equilibrium price for every given reference price \(\mathbf{r}\). Further, for any given reference price \(\mathbf{r}\), the equilibrium price \(\left(p_{H}^{\star}(\mathbf{r}),p_{L}^{\star}(\mathbf{r})\right)\) is the unique solution to the following system of first-order equations [22, Eq. (B.10)]:

\[\left\{\begin{array}{rl}p_{H}^{\star}(\mathbf{r})&=\frac{1}{(b_{H}+c_{H}) \cdot\left(1-d_{H}(\mathbf{p}^{\star}(\mathbf{r}),\mathbf{r})\right)},\\ \\ p_{L}^{\star}(\mathbf{r})&=\frac{1}{(b_{L}+c_{L})\cdot\left(1-d_{L}( \mathbf{p}^{\star}(\mathbf{r}),\mathbf{r})\right)}.\end{array}\right.\] (15)

The intertemporal aspect of the memory-based reference effect prompts researchers to examine the long-term consequence of repeatedly applying the equilibrium pricing policy in conjunction with reference price updates. Theorem 4 in [22] confirms that in the complete information setting, the price paths and reference price paths generated by the equilibrium pricing policy will converge to the SNE in the long run. Moreover, based on Eq. (15) for the equilibrium pricing policy, the SNE \(\mathbf{p}^{\star\star}\) is the unique solution of the following system of equations:

\[\left\{\begin{aligned} & p_{H}^{\star\star}=\frac{1}{(b_{H}+c_{H}) \cdot\left(1-d_{H}(\mathbf{p}^{\star\star},\mathbf{p}^{\star\star})\right)}= \frac{1+\exp(a_{H}-b_{H}\cdot p_{H}^{\star\star})+\exp(a_{L}-b_{L}\cdot p_{L}^ {\star\star})}{(b_{H}+c_{H})\cdot(1+\exp(a_{L}-b_{L}\cdot p_{L}^{\star\star}))},\\ & p_{L}^{\star\star}=\frac{1}{(b_{L}+c_{L})\cdot\left(1-d_{L}( \mathbf{p}^{\star\star},\mathbf{p}^{\star\star})\right)}=\frac{1+\exp(a_{H}-b_ {H}\cdot p_{H}^{\star\star})+\exp(a_{L}-b_{L}\cdot p_{L}^{\star\star})}{(b_{L} +c_{L})\cdot(1+\exp(a_{H}-b_{H}\cdot p_{H}^{\star\star}))}.\end{aligned}\right.\] (16)

It can be seen from Eq. (16) that the value of SNE depends only on the model parameters.

### Proof of Proposition 3.1

Proof.: Firstly, the uniqueness of SNE has been established in the discussion in Appendix B.1. Below, we show the boundedness of the SNE. By performing a transformation on Eq. (16), we obtain the following inequality for \(\mathbf{p}^{\star\star}\):

\[\frac{\exp(a_{i}-b_{i}\cdot p_{i}^{\star\star})}{(b_{i}+c_{i})p_{i}^{\star \star}-1}=1+\exp(a_{-i}-b_{-i}\cdot p_{-i}^{\star\star})>1,\quad\forall i\in \{H,L\}.\] (17)

To make the above inequality valid, it immediately follows that

\[\frac{1}{b_{i}+c_{i}}<p_{i}^{\star\star}<\frac{1+\exp(a_{i}-b_{i}\cdot p_{i}^{ \star\star})}{b_{i}+c_{i}},\quad\forall i\in\{H,L\}.\] (18)

Now, we derive the upper bound for \(p_{i}^{\star\star}\) from the second inequality in Eq. (18). Since the quantity on the right-hand side of Eq. (18) is monotone decreasing in \(p_{i}^{\star\star}\), the value of \(p_{i}^{\star\star}\) must be upper-bounded by the unique solution to the following equation with respect to \(p_{i}\):

\[p_{i}=\frac{1+\exp(a_{i}-b_{i}\cdot p_{i})}{b_{i}+c_{i}}.\] (19)

Define \(x:=-b_{i}/(b_{i}+c_{i})+b_{i}\cdot p_{i}\). Then, one can easily verify that the above equation can be converted into

\[x\exp(x)=\frac{b_{i}}{b_{i}+c_{i}}\exp\left(a_{i}-\frac{b_{i}}{b_{i}+c_{i}} \right),\] (20)

which implies that

\[x=W\left(\frac{b_{i}}{b_{i}+c_{i}}\exp\left(a_{i}-\frac{b_{i}}{b_{i}+c_{i}} \right)\right),\] (21)

where \(W(\cdot)\) is known as the Lambert \(W\) function [65]. For any value \(y\geq 0\), \(W(y)\) is defined as the unique real solution to the equation

\[W(y)\cdot\exp\left(W(y)\right)=y.\] (22)

Hence, we have

\[p_{i}^{\star\star}<p_{i}=\frac{1}{b_{i}+c_{i}}+\frac{1}{b_{i}}W\left(\frac{b_{ i}}{b_{i}+c_{i}}\exp\left(a_{i}-\frac{b_{i}}{b_{i}+c_{i}}\right)\right).\] (23)

Together with the lower bound provided in Eq. (18), this completest the proof. 

## Appendix C Proof of Theorem 5.1

Proof.: In this section, we present the proof of Theorem 5.1. By Lemma F.1, when the step-sizes in Algorithm 1 are non-increasing and \(\lim_{t\to\infty}\eta^{t}=0\), the difference between reference price and price converges to zero as \(t\) goes to infinity, i.e., \(\lim_{t\to\infty}\left(\mathbf{r}^{t}-\mathbf{p}^{t}\right)=0\). Thus, we are left to verify that the price path \(\{\mathbf{p}^{t}\}_{t\geq 0}\) converges to the unique SNE, denoted by \(\mathbf{p}^{\star\star}\) (see Definition 3.1). Recall that the uniqueness of the SNE is established in Proposition 3.1.

Consider the following weighted \(\ell_{1}\)-distance between a point \(\mathbf{p}\) and the SNE \(\mathbf{p}^{\star\star}\):

\[\varepsilon(\mathbf{p}):=\frac{|p_{H}^{\star\star}-p_{H}|}{b_{H}+c_{H}}+\frac{ |p_{L}^{\star\star}-p_{L}|}{b_{L}+c_{L}}.\] (24)

In a nutshell, our proof contains the following two parts:* In **Part 1** (Appendix C.1), we show that the price path \(\left\{\mathbf{p}^{t}\right\}_{t\geq 0}\) would enter the \(\ell_{1}\)-neighborhood \(N^{1}_{\epsilon_{0}}:=\left\{\mathbf{p}\in\mathcal{P}^{2}\mid\varepsilon( \mathbf{p})<\epsilon_{0}\right\}\) infinitely many times for any \(\epsilon_{0}>0\).
* In **Part 2** (Appendix C.2), we show that when the price path \(\left\{\mathbf{p}^{t}\right\}_{t\geq 0}\) enters the \(\ell_{2}\)-neighborhood \(N^{2}_{\epsilon_{0}}:=\left\{\mathbf{p}\in\mathcal{P}^{2}\mid\|\mathbf{p}- \mathbf{p}^{\star\star}\|_{2}<\epsilon_{0}\right\}\) for some sufficiently small \(\epsilon_{0}>0\) with small enough step-sizes, the price path will stay in \(N^{2}_{\epsilon_{0}}\) during subsequent periods.

Due to the diminishing step-sizes and the equivalence between \(\ell_{1}\) and \(\ell_{2}\) norms, **Part 1** guarantees that the price path would enter any \(\ell_{2}\)-neighborhood \(N^{2}_{\epsilon_{0}}\) of \(\mathbf{p}^{\star\star}\) with arbitrarily small step-sizes. Together with **Part 2**, this proves that for any sufficiently small \(\epsilon_{0}>0\), there exists some \(T_{\epsilon_{0}}>0\) such that \(\|\mathbf{p}^{t}-\mathbf{p}^{\star\star}\|_{2}\leq\epsilon_{0}\) for every \(t\geq T_{\epsilon_{0}}\), which implies the convergence to the SNE.

### Proof of Part 1

We argue by contradiction. Suppose there exists \(\epsilon_{0}>0\) such that \(\left\{\mathbf{p}\right\}_{t\geq 0}\) only visits \(N^{1}_{\epsilon_{0}}\) finitely many times. This is equivalent to say that \(\exists T^{\epsilon_{0}}\) such that \(\left\{\mathbf{p}^{t}\right\}_{t\geq 0}\) never visits \(N^{1}_{\epsilon_{0}}\) if \(t\geq T^{\epsilon_{0}}\).

Firstly, let \(G_{i}(\mathbf{p},\mathbf{r})\) be the scaled partial derivative of the log-revenue, defined as

\[G_{i}(\mathbf{p},\mathbf{r}):=\frac{1}{b_{i}+c_{i}}\cdot\frac{\partial\log \left(\Pi_{i}(\mathbf{p},\mathbf{r})\right)}{\partial p_{i}}=\frac{1}{(b_{i} +c_{i})p_{i}}+d_{i}(\mathbf{p},\mathbf{r})-1,\quad\forall i\in\{H,L\}.\] (25)

For the ease of notation, we denote \(\mathcal{P}_{i}:=\left\{p/(b_{i}+c_{i})\mid p\in\mathcal{P}\right\}\) as the scaled price range. Then, the price update in Line 5 of Algorithm 1 is equivalent to

\[\frac{p_{i}^{t+1}}{b_{i}+c_{i}}=\mathrm{Proj}_{\mathcal{P}_{i}}\left(\frac{p_{ i}^{t}}{b_{i}+c_{i}}+\eta^{t}\frac{D_{i}^{t}}{b_{i}+c_{i}}\right)=\mathrm{Proj}_{ \mathcal{P}_{i}}\left(\frac{p_{i}^{t}}{b_{i}+c_{i}}+\eta^{t}G_{i}(\mathbf{p}^ {t},\mathbf{r}^{t})\right).\] (26)

Let \(\mathrm{sign}(\cdot)\) be the sign function defined as

\[\mathrm{sign}(x):=\left\{\begin{array}{ll}1,&\text{ if }x>0,\\ 0,&\text{ if }x=0,\\ -1,&\text{ if }x<0.\end{array}\right.\] (27)

Then, an essential observation from Eq. (26) is that: if \(\mathrm{sign}(p_{i}^{\star\star}-p_{i}^{t})\cdot G_{i}(\mathbf{p}^{t},\mathbf{ r}^{t})>0\), we have that \(\mathrm{sign}(p_{i}^{t+1}-p_{i}^{t})=\mathrm{sign}\left(G_{i}(\mathbf{p}^{t}, \mathbf{r}^{t})\right)=\mathrm{sign}(p_{i}^{\star\star}-p_{i}^{t})\), i.e., the update from \(p_{i}^{t}\) to \(p_{i}^{t+1}\) is toward the direction of the SNE price \(p_{i}^{\star\star}\). Conversely, if \(\mathrm{sign}(p_{i}^{\star\star}-p_{i}^{t})\cdot G_{i}(\mathbf{p}^{t},\mathbf{ r}^{t})<0\), the update from \(p_{i}^{t}\) to \(p_{i}^{t+1}\) is deviating from \(p_{i}^{\star\star}\).

We separate the whole feasible price range into four quadrants with \(\mathbf{p}^{\star\star}\) being the origin:

\[\begin{split} N_{1}&:=\left\{\mathbf{p}\in\mathcal{P }^{2}\mid p_{H}>p_{H}^{\star\star}\text{ and }p_{L}\geq p_{L}^{\star\star}\right\};\;N_{2}:=\left\{\mathbf{p}\in\mathcal{P }^{2}\mid p_{H}\leq p_{H}^{\star\star}\text{ and }p_{L}>p_{L}^{\star\star}\right\};\\ N_{3}&:=\left\{\mathbf{p}\in\mathcal{P}^{2}\mid p_{H}<p_{H}^{ \star\star}\text{ and }p_{L}\leq p_{L}^{\star\star}\right\};\;N_{4}:=\left\{\mathbf{p}\in\mathcal{P }^{2}\mid p_{H}\geq p_{H}^{\star\star}\text{ and }p_{L}<p_{L}^{\star\star}\right\}.\end{split}\] (28)

Below, we first show that _when \(t\) is sufficiently large, prices in consecutive periods cannot always stay within a same region._ We prove it by a contradiction argument. Suppose that there exists some period \(T_{1}^{\epsilon_{0}}>T^{\epsilon_{0}}\), after which the price path \(\left\{\mathbf{p}^{t}\right\}_{t\geq T_{1}^{\epsilon_{0}}}\) stays within a same region, i.e.,\[\begin{split}\operatorname{sign}\left(p_{H}^{\star\star}-p_{H}^{t_{1}} \right)&=\operatorname{sign}\left(p_{H}^{\star\star}-p_{H}^{t_{2}} \right),\forall t_{1},t_{2}\geq T_{1}^{\epsilon_{0}},\forall i\in\{H,L\}.\end{split}\] (29)

where we use the property of the projection operator in \((\Delta_{1})\). The equality \((\Delta_{2})\) follows since \(\operatorname{sign}\left(p_{i}^{\star\star}-p_{i}^{t+1}\right)= \operatorname{sign}\left(p_{i}^{\star\star}-p_{i}^{t}\right)\) for \(i\in\{H,L\}\), and the projection does not change the sign, then we have

\[\operatorname{sign}\left(\frac{p_{i}^{\star\star}}{b_{i}+c_{i}}-\eta^{t}G_{i} (\mathbf{p}^{t},\mathbf{r}^{t})-\frac{p_{i}^{t}}{b_{i}+c_{i}}\right)= \operatorname{sign}\left(p_{i}^{\star\star}-p_{i}^{t}\right),\quad\forall i \in\{H,L\}.\]

The inequality \((\Delta_{3})\) results from Lemma F.5. In particular, since \(\left\|\nabla_{\mathbf{r}}G_{i}(\mathbf{p},\mathbf{r})\right\|_{2}\leq\ell_{r}\), where \(\ell_{r}=(1/4)\sqrt{c_{H}^{2}+c_{L}^{2}}\), it follows that

\[\left|G_{i}(\mathbf{p}^{t},\mathbf{r}^{t})-G_{i}(\mathbf{p}^{t},\mathbf{p}^{t })\right|\leq\left\|\nabla_{\mathbf{r}}G_{i}(\mathbf{p},\mathbf{r})\right\|_{ 2}\cdot\left\|\mathbf{r}^{t}-\mathbf{p}^{t}\right\|_{2}\leq\ell_{r}\left\| \mathbf{r}^{t}-\mathbf{p}^{t}\right\|_{2},\quad\forall i\in\{H,L\}.\] (30)

In step \((\Delta_{4})\), we introduce the function \(\mathcal{G}(\mathbf{p})\), which is defined as

\[\mathcal{G}(\mathbf{p}):=\operatorname{sign}(p_{H}^{\star\star}-p_{H})\cdot G _{H}(\mathbf{p},\mathbf{p})+\operatorname{sign}(p_{L}^{\star\star}-p_{L}) \cdot G_{L}(\mathbf{p},\mathbf{p}),\quad\forall\mathbf{p}\in\mathcal{P}^{2}.\] (31)Finally, the last step \((\Delta_{5})\) is due to Lemma F.2, which states that \(\exists M_{\epsilon_{0}}>0\) such that \(\mathcal{G}(\mathbf{p})\geq M_{\epsilon_{0}}\) for every \(\mathbf{p}\in\mathcal{P}^{2}\) with \(\varepsilon(\mathbf{p})>\epsilon_{0}\). Since for \(t\geq T_{1}^{\epsilon_{0}}>T^{\epsilon_{0}}\), we have \(\varepsilon(\mathbf{p}^{t})\geq\epsilon_{0}\) by the premise, it follows that \(\mathcal{G}(\mathbf{p}^{t})\geq M_{\epsilon_{0}}\).

By Lemma F.1, the difference \(\{\mathbf{r}^{t}-\mathbf{p}^{t}\}_{t\geq 0}\) converges to \(0\) as \(t\) approaches to infinity. As a result, we can always find \(T_{2}^{\epsilon_{0}}>0\) to ensure \(\|\mathbf{r}^{t}-\mathbf{p}^{t}\|_{2}\leq M_{\epsilon_{0}}/(4\ell_{r})\) for all \(t\geq T_{2}^{\epsilon_{0}}\). Then, the last line in Eq. (29) can be further upper-bounded as

\[\varepsilon(\mathbf{p}^{t+1}) \leq\varepsilon(\mathbf{p}^{t})-\eta^{t}\Big{(}M_{\epsilon_{0}}- 2\ell_{r}\|\mathbf{r}^{t}-\mathbf{p}^{t}\|_{2}\Big{)}\] (32) \[\leq\varepsilon(\mathbf{p}^{t})-\eta^{t}\Big{(}M_{\epsilon_{0}}- \frac{1}{2}M_{\epsilon_{0}}\Big{)}\] \[\leq\varepsilon(\mathbf{p}^{t})-\frac{1}{2}\eta^{t}M_{\epsilon_{ 0}},\quad\forall t\geq\widehat{T}^{\epsilon_{0}}:=\max\{T_{1}^{\epsilon_{0}},T _{2}^{\epsilon_{0}}\}.\]

By a telescoping sum from any period \(T-1\geq\widehat{T}^{\epsilon_{0}}\) down to period \(\widehat{T}^{\epsilon_{0}}\), we have that

\[\varepsilon(\mathbf{p}^{T})\leq\varepsilon(\mathbf{p}^{\widehat{T}^{\epsilon_ {0}}})-\frac{M_{\epsilon_{0}}}{2}\sum_{t=\widehat{T}^{\epsilon_{0}}}^{T-1}\eta ^{t}.\] (33)

Since the step-sizes satisfy \(\sum_{t=0}^{\infty}\eta^{t}=\infty\), we have that \(\lim_{T\to\infty}(M_{\epsilon_{0}}/2)\sum_{t=\widehat{T}^{\epsilon_{0}}}^{T-1} \eta^{t}=\infty\), which further implies the contradiction that \(\lim_{T\to\infty}\varepsilon(\mathbf{p}^{T})\to-\infty\). Thus, _the prices in consecutive period will not always stay in the same region, i.e., the price path \(\{\mathbf{p}^{t}\}_{t\geq 0}\) keeps oscillating between different regions \(N_{j}\) for \(j\in\{1,2,3,4\}\)_.

Next, we prove that \(\exists T_{3}^{\epsilon_{0}}\geq T^{\epsilon_{0}}\)_such that the price path \(\left\{\mathbf{p}^{t}\right\}_{t\geq T_{3}^{\epsilon_{0}}}\) only oscillates between adjacent quadrants._ Arguing by contradiction, we assume \(\eta_{3}^{T_{3}^{\epsilon_{0}}}<\epsilon_{0}/(2M_{G})\), where \(M_{G}\) is the upper bound of \(\left|G_{i}(\mathbf{p},\mathbf{r})\right|\) defined in Lemma F.5. If \(\mathbf{p}^{t}\in N_{1}\) (or \(N_{2}\)) and \(\mathbf{p}^{t+1}\in N_{3}\) (or \(N_{4}\)), i.e., \(\operatorname{sign}\left(p_{i}^{\star\star}-p_{i}^{t}\right)\neq\operatorname {sign}\left(p_{i}^{\star\star}-p_{i}^{t+1}\right)\) for both \(i\in\{H,L\}\), then it automatically follows from the update rule (see Eq. (26)) that

\[\varepsilon(\mathbf{p}^{t+1}) \leq\eta^{t}\cdot\big{(}\left|G_{H}(\mathbf{p}^{t},\mathbf{r}^{t })\right|+\left|G_{L}(\mathbf{p}^{t},\mathbf{r}^{t})\right|\big{)}\] (34) \[\leq\frac{\epsilon_{0}}{2M_{G}}\cdot 2M_{G}=\epsilon_{0},\]

which again contradicts the premise that \(\{\mathbf{p}^{t}\}_{t\geq T^{\epsilon_{0}}}\) never visits \(N_{\epsilon_{0}}^{1}\). Thus, _when \(t\geq T_{3}^{\epsilon_{0}}\), the price path \(\{\mathbf{p}^{t}\}_{t\geq T_{3}^{\epsilon_{0}}}\) only oscillates between adjacent quadrants._

Because of the following two established facts: \((i)\) when \(t\geq\max\{T_{2}^{\epsilon_{0}},T_{3}^{\epsilon_{0}}\}\), the price path will not remain in the same quadrant but can only oscillate between adjacent quadrants, and \((ii)\) the step-sizes \(\{\eta^{t}\}_{t\geq 0}\) decrease to \(0\) as \(t\to\infty\), we conclude that the price path \(\{\mathbf{p}\}_{t\geq 0}\) must visit the set

\[\widehat{N}_{\epsilon_{1}}:=\left\{\mathbf{p}\in\mathcal{P}^{2}\;\bigg{|}\; \frac{\left|p_{i}^{\star\star}-p_{H}\right|}{b_{H}+c_{H}}<\epsilon_{1}\text{ or }\frac{\left|p_{i}^{\star\star}-p_{L}\right|}{b_{L}+c_{L}}<\epsilon_{1}\right\}\] (35)

infinitely many times for any \(\epsilon_{1}>0\). Intuitively, set \(\widehat{N}_{\epsilon_{1}}\) can be understood as the boundary regions between adjacent quadrants. We define \(\mathcal{T}_{\epsilon_{1}}\) as the set of "jumping periods" from \((N_{1}\cup N_{3})\cap\widehat{N}_{\epsilon_{1}}\) to \((N_{2}\cup N_{4})\cap\widehat{N}_{\epsilon_{1}}\) after \(T^{\epsilon_{0}}\), i.e.,

\[\mathcal{T}_{\epsilon_{1}}:=\big{\{}t\geq T^{\epsilon_{0}}\;\big{|}\;\mathbf{p} ^{t}\in(N_{1}\cup N_{3})\cap\widehat{N}_{\epsilon_{1}}\text{ and }\mathbf{p}^{t+1}\in(N_{2}\cup N_{4})\cap\widehat{N}_{\epsilon_{1}}\big{\}}.\] (36)

Then, the above fact \((i)\) implies that \(\left|\mathcal{T}_{\epsilon_{1}}\right|=\infty\) for any \(\epsilon_{1}>0\).

The key idea of the following proof is that _if \(\{\mathbf{p}^{t}\}_{t\geq 0}\) visits \(\widehat{N}_{\epsilon_{1}}\) with some sufficiently small \(\epsilon_{1}\) and a relatively smaller step-size, it will stay in \(\widehat{N}_{\epsilon_{1}}\) and converge to \(N_{\epsilon_{0}}^{1}\) concurrently._ This results in a contradiction with our initial assumption that \(\{\mathbf{p}^{t}\}_{t\geq 0}\) never visits \(N_{\epsilon_{0}}^{1}\) when \(t\geq T^{\epsilon_{0}}\).

Let \(T_{1}^{\epsilon_{1}}\in\mathcal{T}_{\epsilon_{1}}\) be a jumping period with \(\epsilon_{1}\ll\epsilon_{0}\). Without loss of generality, suppose that \(\big{|}p_{H}^{\star\star}-p_{H}^{T_{1}^{\epsilon_{1}}}\big{|}/(b_{H}+c_{H})< \epsilon_{1}\). Then, since \(\mathbf{p}^{T_{1}^{\epsilon_{1}}}\not\in N_{\epsilon_{0}}^{1}\), we accordingly have that \(\epsilon_{0}-\epsilon_{1}\). By the update rule of price in Eq. (26), it holds that

\[\frac{\left|p_{L}^{\star\star}-p_{L}^{T_{1}^{\epsilon_{1}}+1}\right|}{b_{L}+c_{L}} =\operatorname{sign}\left(p_{L}^{\star\star}-p_{L}^{T_{1}^{ \epsilon_{1}}+1}\right)\cdot\frac{p_{L}^{\star\star}-p_{L}^{T_{1}^{\epsilon_{1 }}+1}}{b_{L}+c_{L}}\] (37) \[=\operatorname{sign}\left(p_{L}^{\star\star}-p_{L}^{T_{1}^{ \epsilon_{1}}+1}\right)\cdot\left(\frac{p_{L}^{\star\star}}{b_{L}+c_{L}}- \operatorname{Proj}_{\mathcal{P}_{L}}\left(\frac{p_{L}^{T_{1}^{\epsilon_{1}}}}{ b_{L}+c_{L}}+\eta^{T_{1}^{\epsilon_{1}}}G_{L}\big{(}\mathbf{p}^{T_{1}^{ \epsilon_{1}}},\mathbf{r}^{T_{1}^{\epsilon_{1}}}\big{)}\right)\right)\] \[\leq\operatorname{sign}\left(p_{L}^{\star\star}-p_{L}^{T_{1}^{ \epsilon_{1}}+1}\right)\cdot\left(\frac{p_{L}^{\star\star}-p_{L}^{T_{1}^{ \epsilon_{1}}}}{b_{L}+c_{L}}-\eta^{T_{1}^{\epsilon_{1}}}G_{L}\big{(}\mathbf{p} ^{T_{1}^{\epsilon_{1}}},\mathbf{r}^{T_{1}^{\epsilon_{1}}}\big{)}\right)\] \[=\operatorname{sign}\left(p_{L}^{\star\star}-p_{L}^{T_{1}^{ \epsilon_{1}}}\right)\cdot\frac{p_{L}^{\star\star}-p_{L}^{T_{1}^{\epsilon_{1 }}}}{b_{L}+c_{L}}-\operatorname{sign}\left(p_{L}^{\star\star}-p_{L}^{T_{1}^{ \epsilon_{1}}}\right)\cdot\left(\eta^{T_{1}^{\epsilon_{1}}}G_{L}\big{(} \mathbf{p}^{T_{1}^{\epsilon_{1}}},\mathbf{r}^{T_{1}^{\epsilon_{1}}}\big{)} \right).\]

We note that, the last step above is due to the premise that the step-size is sufficiently small: since \(\left|p_{L}^{\star\star}-p_{L}^{T_{1}^{\epsilon_{1}}}\right|/(b_{L}+c_{L})> \epsilon_{0}-\epsilon_{1}\), the equality \(\operatorname{sign}\left(p_{L}^{\star\star}-p_{L}^{T_{1}^{\epsilon_{1}}+1} \right)=\operatorname{sign}\left(p_{L}^{\star\star}-p_{L}^{T_{1}^{\epsilon_{1 }}}\right)\) holds if \(\eta^{T_{1}^{\epsilon_{1}}}<(\epsilon_{0}-\epsilon_{1})/M_{G}\). Next, we show that the second term on the right-hand side of Eq. (37) is upper-bounded away from zero:

\[\operatorname{sign}\left(p_{L}^{\star\star}-p_{L}^{T_{1}^{ \epsilon_{1}}}\right)\cdot G_{L}\big{(}\mathbf{p}^{T_{1}^{\epsilon_{1}}}, \mathbf{r}^{T_{1}^{\epsilon_{1}}}\big{)}\] (38) \[\geq\] \[\stackrel{{(\Delta_{1})}}{{\geq}}\operatorname{sign} \left(p_{L}^{\star\star}-p_{L}^{T_{1}^{\epsilon_{1}}}\right)\cdot G_{L}\big{(} \mathbf{p}^{T_{1}^{\epsilon_{1}}},\mathbf{p}^{T_{1}^{\epsilon_{1}}}\big{)}- \ell_{r}\big{\|}\mathbf{r}^{T_{1}^{\epsilon_{1}}}-\mathbf{p}^{T_{1}^{ \epsilon_{1}}}\big{\|}_{2}\] \[=\] \[\geq \operatorname{sign}\left(p_{L}^{\star\star}-p_{L}^{T_{1}^{ \epsilon_{1}}}\right)\cdot\left[\frac{1}{(b_{L}+c_{L})p_{L}^{T_{1}^{ \epsilon_{1}}}}+d_{L}\big{(}p_{H}^{\star\star},p_{L}^{T_{1}^{\epsilon_{1}}} \big{)},\big{(}p_{H}^{\star\star},p_{L}^{T_{1}^{\epsilon_{1}}}\big{)}\right)-1\right]\] \[-\left|d_{L}(\mathbf{p}^{T_{1}^{\epsilon_{1}}},\mathbf{p}^{T_{1}^ {\epsilon_{1}}})-d_{L}\Big{(}\big{(}p_{H}^{\star\star},p_{L}^{T_{1}^{ \epsilon_{1}}}\big{)},\big{(}p_{H}^{\star\star},p_{L}^{T_{1}^{\epsilon_{1}}} \big{)}\Big{)}\right|-\ell_{r}\big{\|}\mathbf{r}^{T_{1}^{\epsilon_{1}}}- \mathbf{p}^{T_{1}^{\epsilon_{1}}}\big{\|}_{2}\] \[\stackrel{{(\Delta_{2})}}{{\geq}}\operatorname{sign} \left(p_{L}^{\star\star}-p_{L}^{T_{1}^{\epsilon_{1}}}\right)\cdot\left[\frac{1}{ (b_{L}+c_{L})p_{L}^{T_{1}^{\epsilon_{1}}}}+d_{L}\Big{(}(p_{H}^{\star\star},p_{ L}^{T_{1}^{\epsilon_{1}}}),(p_{H}^{\star\star},p_{L}^{T_{1}^{\epsilon_{1}}} \big{)}\Big{)}-1\right]-\ell_{r}\big{\|}\mathbf{r}^{T_{1}^{\epsilon_{1}}}- \mathbf{p}^{T_{1}^{\epsilon_{1}}}\big{\|}_{2}\] \[-\max_{\mathbf{p}\in\mathcal{P}}\left\{\left|\frac{\partial d_{L}( \mathbf{p},\mathbf{p})}{\partial p_{H}}\right|\right\}\cdot\left|p_{H}^{\star \star}-p_{H}^{T_{1}^{\epsilon_{1}}}\right|\] \[\stackrel{{(\Delta_{3})}}{{\geq}}\operatorname{sign} \left(p_{L}^{\star\star}-p_{L}^{T_{1}^{\epsilon_{1}}}\right)\cdot\left[\frac{1}{ (b_{L}+c_{L})p_{L}^{T_{1}^{\epsilon_{1}}}}+d_{L}\Big{(}(p_{H}^{\star\star},p_{ L}^{T_{1}^{\epsilon_{1}}}),(p_{H}^{\star\star},p_{L}^{T_{1}^{\epsilon_{1}}} \big{)}\Big{)}-1\right]-\ell_{r}\big{\|}\mathbf{r}^{T_{1}^{\epsilon_{1}}}- \mathbf{p}^{T_{1}^{\epsilon_{1}}}\big{\|}_{2}\] \[-\frac{1}{4}b_{H}(b_{H}+c_{H})\epsilon_{1}\] \[= \mathcal{G}\big{(}(p_{H}^{\star\star},p_{L}^{T_{1}^{\epsilon_{1}}} \big{)}-\ell_{r}\big{\|}\mathbf{r}^{T_{1}^{\epsilon_{1}}}-\mathbf{p}^{T_{1}^{ \epsilon_{1}}}\big{\|}_{2}-\frac{1}{4}b_{H}(b_{H}+c_{H})\epsilon_{1},\]

where \((\Delta_{1})\) holds because of the mean value theorem and the fact that \(\left\|\nabla_{\mathbf{r}}G_{L}(\mathbf{p},\mathbf{r})\right\|_{2}\leq\ell_{r}\) for \(\mathbf{p},\mathbf{r}\in\mathcal{P}^{2}\) by Lemma F.5, inequality \((\Delta_{2})\) applies the mean value theorem again to the demand function. In \((\Delta_{3})\), we use the assumption that \(\left|p_{H}^{\star\star}-p_{H}^{T_{1}^{\epsilon_{1}}}\right|<(b_{H}+c_{H}) \epsilon_{1}\) and apply a similar argument as Eq. (101) to derive that

\[\left|\frac{\partial d_{L}(\mathbf{p},\mathbf{p})}{\partial p_{H}}\right|=|b_{H} \cdot d_{L}(\mathbf{p},\mathbf{p})\cdot d_{H}(\mathbf{p},\mathbf{p})|\leq\frac{ 1}{4}b_{H},\quad\forall\mathbf{p}\in\mathcal{P}^{2}.\] (39)

Since \(\varepsilon(\left(p_{H}^{\star\star},p_{L}^{T_{1}^{e_{1}}}\right))>\epsilon_{ 0}-\epsilon_{1}\), by Lemma F.2, there exists a constant \(M_{\epsilon_{0}-\epsilon_{1}}>0\), such that \(\mathcal{G}\big{(}(p_{H}^{\star\star},p_{L}^{T_{1}^{e_{1}}})\big{)}\geq M_{ \epsilon_{0}-\epsilon_{1}}\). Meanwhile, we can choose \(\epsilon_{1}\) sufficiently smaller than \(\epsilon_{0}\) to ensure that \((1/2)M_{\epsilon_{0}-\epsilon_{1}}-(1/4)b_{H}(b_{H}+c_{H})\epsilon_{1}>0\). Furthermore, recall that \(T_{1}^{\epsilon_{1}}\) can be arbitrarily chosen from \(\mathcal{T}_{\epsilon_{1}}\), where \(|\mathcal{T}_{\epsilon_{1}}|=\infty\). Thus, we can always find a sufficiently large \(T_{1}^{\epsilon_{1}}\in\mathcal{T}_{\epsilon_{1}}\) to guarantee that \(\ell_{r}\big{\|}\mathbf{r}_{1}^{T_{1}^{e_{1}}}-\mathbf{p}_{1}^{T_{1}^{e_{1}} }\big{\|}_{2}\leq(1/2)M_{\epsilon_{0}-\epsilon_{1}}-(1/4)b_{H}(b_{H}+c_{H}) \epsilon_{1}\) by Lemma F.1. Back to Eq. (38), it follows that

\[\begin{split}&\operatorname{sign}\big{(}p_{L}^{\star\star}-p_{L}^{T_{1}^ {e_{1}}}\big{)}\cdot G_{L}\big{(}\mathbf{p}_{1}^{T_{1}^{e_{1}}},\mathbf{r}_{ 1}^{T_{1}^{e_{1}}}\big{)}\\ &\geq\mathcal{G}\big{(}(p_{H}^{\star\star},p_{L}^{T_{1}^{e_{1}}} \big{)}\big{)}-\ell_{r}\big{\|}\mathbf{r}_{1}^{T_{1}^{e_{1}}}-\mathbf{p}_{1}^ {T_{1}^{e_{1}}}\big{\|}_{2}-\frac{1}{4}b_{H}(b_{H}+c_{H})\epsilon_{1}\\ &\geq M_{\epsilon_{0}-\epsilon_{1}}-\left(\frac{1}{2}M_{\epsilon_ {0}-\epsilon_{1}}-\frac{1}{4}b_{H}(b_{H}+c_{H})\epsilon_{1}\right)-\frac{1}{4} b_{H}(b_{H}+c_{H})\epsilon_{1}\\ &=\frac{1}{2}M_{\epsilon_{0}-\epsilon_{1}}.\end{split}\] (40)

By substituting Eq. (40) into Eq. (37), we further derive that

\[\begin{split}\frac{\big{|}p_{L}^{\star\star}-p_{L}^{T_{1}^{e_{1}} +1}\big{|}}{b_{L}+c_{L}}&\leq\operatorname{sign}\big{(}p_{L}^{ \star\star}-p_{L}^{T_{1}^{e_{1}}}\big{)}\cdot\frac{p_{L}^{\star\star}-p_{L}^ {T_{1}^{e_{1}}}}{b_{L}+c_{L}}-\operatorname{sign}\big{(}p_{L}^{\star\star}-p_{ L}^{T_{1}^{e_{1}}}\big{)}\cdot\left(\eta^{T_{1}^{e_{1}}}G_{L}\big{(}\mathbf{p}_{1}^{T_{1}^{ e_{1}}},\mathbf{r}_{1}^{T_{1}^{e_{1}}}\big{)}\right)\\ &\leq\frac{\big{|}p_{L}^{\star\star}-p_{L}^{T_{1}^{e_{1}}}\big{|} }{b_{L}+c_{L}}-\frac{1}{2}\eta^{T_{1}^{e_{1}}}M_{\epsilon_{0}-\epsilon_{1}}. \end{split}\] (41)

This indicates that the price update from \(p_{L}^{T_{1}^{e_{1}}}\) to \(p_{L}^{T_{1}^{e_{1}}+1}\) is towards the SNE price \(p_{L}^{\star\star}\) when \(\big{|}p_{H}^{\star\star}-p_{H}^{T_{1}^{e_{1}}}\big{|}<(b_{H}+c_{H})\epsilon_{1}\).

Now, we use a strong induction to show that \(\big{|}p_{H}^{\star\star}-p_{H}^{t}\big{|}/(b_{H}+c_{H})<\epsilon_{1}\)_holds for all \(t\geq T_{1}^{\epsilon_{1}}\) provided that \(\epsilon_{1}\) is sufficiently small and \(T_{1}^{\epsilon_{1}}\) is sufficiently large._ Suppose there exists \(T_{2}^{\epsilon_{1}}\geq T_{1}^{\epsilon_{1}}\) such that \(\big{|}p_{H}^{\star\star}-p_{H}^{t}\big{|}/(b_{H}+c_{H})<\epsilon_{1}\) holds for all \(t=T_{1}^{e_{1}},T_{1}^{e_{1}}+1,\ldots,T_{2}^{e_{1}}\), we aim to show that \(\big{|}p_{H}^{\star\star}-p_{H}^{T_{2}^{e_{1}}+1}\big{|}/(b_{H}+c_{H})<\epsilon_ {1}\). Following the same derivation from Eq. (37) to Eq. (41), it holds that

\[\frac{\big{|}p_{L}^{\star\star}-p_{L}^{t+1}\big{|}}{b_{L}+c_{L}}\leq\frac{ \big{|}p_{L}^{\star\star}-p_{L}^{t}\big{|}}{b_{L}+c_{L}}-\frac{1}{2}\eta^{t}M_{ \epsilon_{0}-\epsilon_{1}},\quad t=T_{1}^{\epsilon_{1}},T_{1}^{\epsilon_{1}}+ 1,\ldots,T_{2}^{\epsilon_{1}}.\] (42)

By telescoping the above inequality from \(T_{2}^{\epsilon_{1}}-1\) down to \(T_{1}^{\epsilon_{1}}\), we have that

\[\frac{\big{|}p_{L}^{\star\star}-p_{L}^{T_{2}^{e_{1}}}\big{|}}{b_{L}+c_{L}}\leq \frac{\big{|}p_{L}^{\star\star}-p_{L}^{T_{1}^{e_{1}}}\big{|}}{b_{L}+c_{L}}-\frac{ M_{\epsilon_{0}-\epsilon_{1}}}{2}\sum_{t=T_{1}^{e_{1}}}^{T_{2}^{e_{1}}-1}\eta^{t} \leq\frac{\big{|}p_{L}^{\star\star}-p_{L}^{T_{1}^{e_{1}}}\big{|}}{b_{L}+c_{L}}.\] (43)

Additionally, we note that \(\big{|}p_{H}^{\star\star}-p_{H}^{t}\big{|}/(b_{H}+c_{H})<\epsilon_{1}\) and \(\mathbf{p}^{t}\not\in N_{\epsilon_{0}}^{1}\) together imply that \(\big{|}p_{L}^{\star\star}-p_{L}^{t}\big{|}/(b_{L}+c_{L})>(\epsilon_{0}-\epsilon_ {1})\) for all \(t=T_{1}^{e_{1}},T_{1}^{\epsilon_{1}}+1,\ldots,T_{2}^{e_{1}}\). As the step-size is sufficiently small, we conclude that the price path \(\{p_{L}^{t}\}_{L=T_{1}^{e_{1}}}^{T_{2}^{e_{1}}}\) lies on the same side of the SNE price \(p_{L}^{\star\star}\), and thus \(\operatorname{sign}\big{(}p_{L}^{\star\star}-p_{L}^{T_{1}^{e_{1}}}\big{)}= \operatorname{sign}\big{(}p_{L}^{\star\star}-p_{L}^{T_{1}^{e_{1}}}\big{)}\). Below, we discuss two cases based on the value of \(\big{|}p_{H}^{\star\star}-p_{H}^{T_{2}^{e_{1}}}\big{|}\):

**Case 1:**\(\big{|}p_{H}^{\star\star}-p_{H}^{T_{2}^{e_{1}}}\big{|}/(b_{H}+c_{H})<\epsilon_{1}- \eta^{T_{1}^{e_{1}}}M_{G}\).

Following a similar derivation as Eq.(37), we have that

\[\frac{\left|p_{H}^{\star\star}-p_{H}^{T_{2}^{\varepsilon_{1}}+1} \right|}{b_{H}+c_{H}} \leq\mathrm{sign}\left(p_{H}^{\star\star}-p_{H}^{T_{1}^{ \varepsilon_{1}}}\right)\cdot\frac{p_{H}^{\star\star}-p_{H}^{T_{1}^{ \varepsilon_{1}}}}{b_{H}+c_{H}}-\eta^{T_{2}^{\varepsilon_{1}}}\mathrm{sign} \left(p_{H}^{\star\star}-p_{H}^{T_{2}^{\varepsilon_{1}}}\right)\cdot G_{H} \big{(}\mathbf{p}^{T_{2}^{\varepsilon_{1}}},\mathbf{r}^{T_{2}^{\varepsilon_{1 }}}\big{)}.\] (44) \[\leq\frac{\left|p_{H}^{\star\star}-p_{H}^{T_{1}^{\varepsilon_{1}} }\right|}{b_{H}+c_{H}}+\eta^{T_{2}^{\varepsilon_{1}}}\Big{|}G_{H}\big{(} \mathbf{p}^{T_{2}^{\varepsilon_{1}}},\mathbf{r}^{T_{2}^{\varepsilon_{1}}} \big{)}\Big{|}\] \[\stackrel{{\eqref{eq:p_H}}}{{\leq}}\epsilon_{1},\]

where \((\Delta_{1})\) is from Lemma F.5 that \(\big{|}G_{H}(\mathbf{p},\mathbf{r})\big{|}\leq M_{G}\) for \(\mathbf{p},\mathbf{r}\in\mathcal{P}^{2}\), and \((\Delta_{2})\) is because the sequence of step-sizes is non-increasing, hence \(\eta^{T_{1}^{\varepsilon_{1}}}\geq\eta^{T_{2}^{\varepsilon_{1}}}\).

**Case 2:**\(\left|p_{H}^{\star\star}-p_{H}^{T_{2}^{\varepsilon_{1}}}\right|/(b_{H}+c_{H}) \in\big{[}\epsilon_{1}-\eta^{T_{1}^{\varepsilon_{1}}}M_{G},\epsilon_{1}\big{)}\).

It suffices to show that \(\big{|}p_{H}^{\star\star}-p_{H}^{T_{2}^{\varepsilon_{1}}+1}\big{|}\leq\big{|} p_{H}^{\star\star}-p_{H}^{T_{2}^{\varepsilon_{1}}}\big{|}\). According to the observation below Eq. (27), this is equivalent to showing that

\[\mathrm{sign}\left(p_{H}^{\star\star}-p_{H}^{T_{1}^{\varepsilon_{1}}}\right) \cdot G_{H}\big{(}\mathbf{p}^{T_{2}^{\varepsilon_{1}}},\mathbf{r}^{T_{2}^{ \varepsilon_{1}}}\big{)}\geq 0.\] (45)

We further discuss two scenarios depending on whether \(\mathbf{p}^{T_{2}^{\varepsilon_{1}}}\in N_{1}\cup N_{3}\) or \(\mathbf{p}^{T_{2}^{\varepsilon_{1}}}\in N_{2}\cup N_{4}\).

1. Suppose that \(\mathbf{p}^{T_{2}^{\varepsilon_{1}}}\in N_{1}\cup N_{3}\). According to the definition of set \(\mathcal{T}_{\epsilon_{1}}\) in Eq. (36), we have that \(\mathbf{p}^{T_{1}^{\varepsilon_{1}}}\in N_{1}\cup N_{3}\) since \(T_{1}^{\varepsilon_{1}}\in\mathcal{T}_{\epsilon_{1}}\) is a jumping period. Together with the established fact that \(\mathrm{sign}\left(p_{L}^{\star\star}-p_{L}^{T_{1}^{\varepsilon_{1}}}\right)= \mathrm{sign}\left(p_{L}^{\star\star}-p_{L}^{T_{1}^{\varepsilon_{1}}}\right)\) (see the argument below Eq. (43)), we conclude that \(\mathbf{p}^{T_{2}^{\varepsilon_{1}}}\) and \(\mathbf{p}^{T_{1}^{\varepsilon_{1}}}\) are in the same quadrant, and \(\mathrm{sign}\left(p_{H}^{\star\star}-p_{H}^{T_{2}^{\varepsilon_{1}}}\right)= \mathrm{sign}\left(p_{H}^{\star\star}-p_{H}^{T_{1}^{\varepsilon_{1}}}\right)\). Then, we can write that \[\mathrm{sign}\left(p_{H}^{\star\star}-p_{H}^{T_{2}^{\varepsilon_{1 }}}\right)\cdot G_{H}\big{(}\mathbf{p}^{T_{2}^{\varepsilon_{1}}},\mathbf{r}^{ T_{2}^{\varepsilon_{1}}}\big{)}\] (46) \[\geq\mathrm{sign}\left(p_{H}^{\star\star}-p_{H}^{T_{2}^{ \varepsilon_{1}}}\right)\cdot G_{H}\big{(}\mathbf{p}^{T_{2}^{\varepsilon_{1}}}, \mathbf{p}^{T_{2}^{\varepsilon_{1}}}\big{)}-\ell_{r}\|\mathbf{r}^{T_{2}^{ \varepsilon_{1}}}-\mathbf{p}^{T_{2}^{\varepsilon_{1}}}\|_{2}\] \[\stackrel{{\eqref{eq:p_H}}}{{\geq}}\mathrm{sign} \left(p_{H}^{\star\star}-p_{H}^{T_{2}^{\varepsilon_{1}}}\right)\cdot G_{H}\big{(} \big{(}p_{H}^{T_{2}^{\varepsilon_{1}}},p_{L}^{T_{1}^{\varepsilon_{1}}}\big{)}, \big{(}p_{H}^{T_{2}^{\varepsilon_{1}}},p_{L}^{T_{1}^{\varepsilon_{1}}}\big{)} \big{)}-\ell_{r}\|\mathbf{r}^{T_{2}^{\varepsilon_{1}}}-\mathbf{p}^{T_{2}^{ \varepsilon_{1}}}\|_{2}\] \[=\mathrm{sign}\left(p_{H}^{\star\star}-p_{H}^{T_{1}^{\varepsilon_ {1}}}\right)\cdot G_{H}\big{(}\mathbf{p}^{T_{1}^{\varepsilon_{1}}},\mathbf{p}^{ T_{1}^{\varepsilon_{1}}}\big{)}-\ell_{r}\|\mathbf{r}^{T_{2}^{ \varepsilon_{1}}}-\mathbf{p}^{T_{2}^{\varepsilon_{1}}}\|_{2}\] \[\quad+\mathrm{sign}\left(p_{H}^{\star\star}-p_{H}^{T_{1}^{ \varepsilon_{1}}}\right)\cdot\big{(}G_{H}\big{(}(p_{H}^{T_{2}^{\varepsilon_{1}}},p_ {L}^{T_{1}^{\varepsilon_{1}}}),(p_{H}^{T_{2}^{\varepsilon_{1}}},p_{L}^{T_{1}^{ \varepsilon_{1}}})\big{)}-G_{H}\big{(}\mathbf{p}^{T_{1}^{\varepsilon_{1}}}, \mathbf{p}^{T_{1}^{\varepsilon_{1}}}\big{)}\big{)},\] where we apply Lemma F.4 in \((\Delta)\) by utilizing the relation \(\big{|}p_{L}^{\star\star}-p_{L}^{T_{2}^{\varepsilon_{1}}}\big{|}\leq\big{|}p_{ L}^{\star\star}-p_{L}^{T_{1}^{\varepsilon_{1}}}\big{|}\) proved in Eq. (43). Next, as \(T_{1}^{\varepsilon_{1}}\) is a jumping period, it follows from the price update rule in Eq. (26) that \(\big{|}p_{H}^{\star\star}-p_{H}^{T_{1}^{\varepsilon_{1}}}\big{|}/(b_{H}+c_{H}) \leq\big{|}\eta^{T_{1}^{\varepsilon_{1}}}G_{H}\big{(}\mathbf{p}^{T_{1}^{ \varepsilon_{1}}},\mathbf{p}^{T_{1}^{\varepsilon_{1}}})\big{)}\big{|}\leq\eta^{T _{1}^{\varepsilon_{1}}}M_{G}\). Thus, when the chosen jumping period \(T_{1}^{\varepsilon_{1}}\) is sufficiently large so that the step-size \(\eta^{T_{1}^{\varepsilon_{1}}}\) is considerably smaller than \(\epsilon_{1}\), we further derive that \[\big{|}p_{H}^{\star\star}-p_{H}^{T_{2}^{\varepsilon_{1}}}\big{|}\geq(b_{H}+c_{H}) \cdot(\epsilon_{1}-\eta^{T_{1}^{\varepsilon_{1}}}M_{G})\geq(b_{H}+c_{H}) \cdot\eta^{T_{1}^{\varepsilon_{1}}}M_{G}\geq\big{|}p_{H}^{\star\star}-p_{H}^{T _{1}^{\varepsilon_{1}}}\big{|}.\] (47)With Eq. (47), we use Lemma F.4 again to upper-bound the last term on the right-hand side of Eq. (46):

\[\begin{split}&\operatorname{sign}\left(p_{H}^{\star\star}-p_{H}^{T_{ 1}^{\tau_{1}}}\right)\cdot\left(G_{H}\big{(}(p_{H}^{T_{1}^{\tau_{1}}},p_{L}^{T_ {1}^{\tau_{1}}}),(p_{H}^{T_{2}^{\tau_{1}}},p_{L}^{T_{1}^{\tau_{1}}})\big{)}-G_ {H}\big{(}\mathbf{p}^{T_{1}^{\tau_{1}}},\mathbf{p}^{T_{1}^{\tau_{1}}}\big{)} \big{)}\\ =&\operatorname{sign}\left(p_{H}^{\star\star}-p_{H}^{T _{1}^{\tau_{1}}}\right)\cdot G_{H}\big{(}(p_{H}^{T_{1}^{\tau_{1}}},p_{L}^{T_{1 }^{\tau_{1}}}),(p_{H}^{T_{2}^{\tau_{1}}},p_{L}^{T_{1}^{\tau_{1}}})\big{)}- \operatorname{sign}\left(p_{H}^{\star\star}-p_{H}^{T_{1}^{\tau_{1}}}\right) \cdot G_{H}\big{(}\mathbf{p}^{T_{1}^{\tau_{1}}},\mathbf{p}^{T_{1}^{\tau_{1}}} \big{)}\\ \stackrel{{(\Delta_{1})}}{{=}}&\Bigg{|} \left(\frac{1}{(b_{H}+c_{H})p_{H}^{T_{1}^{\tau_{1}}}}+d_{H}\big{(}(p_{H}^{T_{ 1}^{\tau_{1}}},p_{L}^{T_{1}^{\tau_{1}}}),(p_{H}^{T_{2}^{\tau_{1}}},p_{L}^{T_{1 }^{\tau_{1}}})\big{)}-1\right)\\ &\hskip 28.452756pt-\left(\frac{1}{(b_{H}+c_{H})p_{H}^{T_{1}^{ \tau_{1}}}}+d_{H}\big{(}\mathbf{p}^{T_{1}^{\tau_{1}}},\mathbf{p}_{1}^{T_{1}^{ \tau_{1}}}\big{)}-1\right)\Bigg{|}\\ &\hskip 28.452756pt=\Bigg{|}\underbrace{\frac{1}{b_{H}+c_{H}} \left(\frac{1}{p_{H}^{T_{1}^{\tau_{1}}}}-\frac{1}{p_{H}^{T_{1}^{\tau_{1}}}} \right)}_{\operatorname{diff}_{1}}+\underbrace{\left[d_{H}\big{(}(p_{H}^{T_{1} ^{\tau_{1}}},p_{L}^{T_{1}^{\tau_{1}}}),(p_{H}^{T_{1}^{\tau_{1}}},p_{L}^{T_{1} ^{\tau_{1}}})\big{)}-d_{H}\big{(}\mathbf{p}^{T_{1}^{\tau_{1}}},\mathbf{p}^{T_{ 1}^{\tau_{1}}}\big{)}\right]}_{\operatorname{diff}_{2}}\Bigg{|}\\ \stackrel{{(\Delta_{2})}}{{\geq}}&\frac{1}{b _{H}+c_{H}}\left|\frac{1}{p_{H}^{T_{1}^{\tau_{1}}}}-\frac{1}{p_{H}^{T_{1}^{ \tau_{1}}}}\right|,\end{split}\] (48)

where \((\Delta_{1})\) holds since the difference in the previous step is non-negative by Lemma F.4. Furthermore, it is straightforward to observe that the terms \(\operatorname{diff}_{1}\) and \(\operatorname{diff}_{2}\) have the same sign, which results in the final inequality \((\Delta_{2})\). We substitute Eq. (48) back into Eq. (46):

\[\begin{split}&\operatorname{sign}\left(p_{H}^{\star\star}-p_{H}^{T _{2}^{\tau_{1}}}\right)\cdot G_{H}\big{(}\mathbf{p}^{T_{2}^{\tau_{1}}}, \mathbf{r}^{T_{2}^{\tau_{1}}}\big{)}\\ \geq&\operatorname{sign}\left(p_{H}^{\star\star}-p_{H }^{T_{1}^{\tau_{1}}}\right)\cdot G_{H}\big{(}\mathbf{p}^{T_{1}^{\tau_{1}}}, \mathbf{p}^{T_{1}^{\tau_{1}}}\big{)}-\ell_{r}\|\mathbf{r}^{T_{2}^{\tau_{1}}}- \mathbf{p}^{T_{2}^{\tau_{1}}}\|_{2}+\frac{1}{b_{H}+c_{H}}\left|\frac{1}{p_{H}^{ T_{2}^{\tau_{1}}}}-\frac{1}{p_{H}^{T_{1}^{\tau_{1}}}}\right|\\ \geq&\operatorname{sign}\left(p_{H}^{\star\star}-p_{H }^{T_{1}^{\tau_{1}}}\right)\cdot G_{H}\big{(}\mathbf{p}^{T_{1}^{\tau_{1}}}, \mathbf{r}^{T_{1}^{\tau_{1}}}\big{)}-\ell_{r}\big{(}\|\mathbf{r}^{T_{2}^{\tau_ {1}}}-\mathbf{p}^{T_{2}^{\tau_{1}}}\|_{2}+\|\mathbf{r}^{T_{1}^{\tau_{1}}}- \mathbf{p}^{T_{1}^{\tau_{1}}}\|_{2}\big{)}\\ &\hskip 28.452756pt+\frac{1}{b_{H}+c_{H}}\left|\frac{1}{p_{H}^{ T_{2}^{\tau_{1}}}}-\frac{1}{p_{H}^{T_{1}^{\tau_{1}}}}\right|\\ &\hskip 28.452756pt\stackrel{{(\Delta_{1})}}{{\geq}} -\ell_{r}\big{(}\|\mathbf{r}^{T_{2}^{\tau_{1}}}-\mathbf{p}^{T_{2}^{\tau_{1}}} \|_{2}+\|\mathbf{r}^{T_{1}^{\tau_{1}}}-\mathbf{p}^{T_{1}^{\tau_{1}}}\|_{2} \big{)}+\frac{\left|p_{H}^{T_{2}^{\tau_{1}}}-p_{H}^{T_{1}^{\tau_{1}}}\right| }{(b_{H}+c_{H})\cdot\left(p_{H}^{T_{2}^{\tau_{1}}}-p_{H}^{T_{1}^{\tau_{1}}} \right)}\\ &\hskip 28.452756pt\stackrel{{(\Delta_{2})}}{{\geq}} -\ell_{r}\big{(}\|\mathbf{r}^{T_{2}^{\tau_{1}}}-\mathbf{p}^{T_{2}^{\tau_{1}}} \|_{2}+\|\mathbf{r}^{T_{1}^{\tau_{1}}}-\mathbf{p}^{T_{1}^{\tau_{1}}}\|_{2} \big{)}+\frac{\left|\left(\epsilon_{1}-\eta^{T_{1}^{\tau_{1}}}M_{G}\right)- \eta^{T_{1}^{\tau_{1}}}M_{G}\right|}{(b_{H}+c_{H})\cdot\overline{p}^{2}}.\\ \end{split}\] (49)

In inequality \((\Delta_{1})\), we use the fact that \(\operatorname{sign}\left(p_{H}^{\star\star}-p_{H}^{T_{1}^{\tau_{1}}}\right) \cdot G_{H}\big{(}\mathbf{p}^{T_{1}^{\tau_{1}}},\mathbf{r}^{T_{1}^{\tau_{1}}} \big{)}>0\) since \(T_{1}^{\tau_{1}}\) is a jumping period in \(\mathcal{T}_{\epsilon_{1}}\). Then, inequality \((\Delta_{2})\) is implied by the properties that \(\operatorname{sign}\left(p_{H}^{\star\star}-p_{H}^{T_{1}^{\tau_{1}}}\right)= \operatorname{sign}\left(p_{H}^{\star\star}-p_{H}^{T_{1}^{\tau_{1}}}\right)\), \(\left|p_{H}^{\star\star}-p_{H}^{T_{2}^{\tau_{1}}}\right|/(b_{H}+c_{H})\geq \epsilon_{1}-\eta^{T_{1}^{\epsilon_{1}}}M_{G}\), and \(\left|p_{H}^{\star\star}-p_{H}^{T_{1}^{\tau_{1}}}\right|/(b_{H}+c_{H})\leq\eta^{T _{1}^{\epsilon_{1}}}M_{G}\). Since both the step-size \(\eta^{t}\) and the difference \(\|\mathbf{r}^{t}-\mathbf{p}^{t}\|_{2}\) decrease to \(0\) as \(t\to\infty\), by choosing a sufficiently large jumping period \(T_{1}^{\epsilon_{1}}\) from \(\mathcal{T}_{\epsilon_{1}}\), the right-hand side of Eq. (46) is guaranteed to be non-negative, i.e., \(\operatorname{sign}\left(p_{H}^{\star\star}-p_{H}^{T_{2}^{\tau_{1}}} \right)\cdot G_{H}\big{(}\mathbf{p}^{T_{2}^{\tau_{1}}},\mathbf{r}^{T_{2}^{ \tau_{1}}}\big{)}\geq 0\). This completes the proof of scenario 1.

2. Suppose \(\mathbf{p}^{T_{2}^{\epsilon_{1}}}\in N_{2}\cup N_{4}\). We deduce that \[\begin{split}&\operatorname{sign}\big{(}p_{H}^{\star\star}-p_{H}^{T _{2}^{\epsilon_{1}}}\big{)}\cdot G_{H}\big{(}\mathbf{p}^{T_{2}^{\epsilon_{1}}}, \mathbf{r}^{T_{2}^{\epsilon_{1}}}\big{)}\\ \geq&\operatorname{sign}\big{(}p_{H}^{\star\star}-p_{ H}^{T_{2}^{\epsilon_{1}}}\big{)}\cdot G_{H}\big{(}\mathbf{p}^{T_{2}^{\epsilon_{1}}}, \mathbf{p}^{T_{2}^{\epsilon_{1}}}\big{)}-\ell_{r}\|\mathbf{r}^{T_{2}^{\epsilon _{1}}}-\mathbf{p}^{T_{2}^{\epsilon_{1}}}\|_{2}\\ \stackrel{{(\Delta_{1})}}{{\geq}}& \operatorname{sign}\big{(}p_{H}^{\star\star}-p_{H}^{T_{1}^{\epsilon_{1}}} \big{)}\cdot G_{H}\big{(}(p_{H}^{T_{1}^{\epsilon_{1}}},p_{L}^{\star\star}),(p_ {H}^{T_{2}^{\epsilon_{1}}},p_{L}^{\star\star})\big{)}-\ell_{r}\|\mathbf{r}^{T_ {2}^{\epsilon_{1}}}-\mathbf{p}^{T_{2}^{\epsilon_{1}}}\|_{2}\\ \stackrel{{(\Delta_{2})}}{{=}}& \mathcal{G}\big{(}(p_{H}^{T_{2}^{\epsilon_{1}}},p_{L}^{\star\star})\big{)}- \ell_{r}\|\mathbf{r}^{T_{2}^{\epsilon_{1}}}-\mathbf{p}^{T_{2}^{\epsilon_{1}}} \|_{2}\\ \stackrel{{(\Delta_{3})}}{{\geq}}& M_{ \widehat{\epsilon}_{1}}-\ell_{r}\|\mathbf{r}^{T_{2}^{\epsilon_{1}}}-\mathbf{p} ^{T_{2}^{\epsilon_{1}}}\|_{2},\quad\text{where }\widehat{\epsilon}_{1}:=\epsilon_{1}-\eta^{T_{2}^{ \epsilon_{1}}}M_{G}.\end{split}\] (50) The inequality \((\Delta_{1})\) follows from Lemma F.4, where \(\operatorname{sign}\big{(}p_{H}^{\star\star}-p_{H}\big{)}\cdot G_{H}\big{(} \mathbf{p},\mathbf{p}\big{)}\) is deceasing when \(|p_{L}^{\star\star}-p_{L}|\) decreases. The equality \((\Delta_{2})\) is due to the definition of \(\mathcal{G}(\mathbf{p})\) in Eq. (31) and the fact that \(\operatorname{sign}(p_{L}^{\star\star}-p_{H}^{\star\star})=0\). Finally, in the last line \((\Delta_{3})\), we leverage the initial assumption of **Case 2**, which implies that \(\varepsilon\big{(}(p_{H}^{T_{2}^{\epsilon_{1}}},p_{L}^{\star\star})\big{)}= \big{|}p_{H}^{\star\star}-p_{H}^{T_{2}^{\epsilon_{1}}}\big{|}/(b_{H}+c_{H}) \in\big{[}\epsilon_{1}-\eta^{T_{1}^{\epsilon_{1}}}M_{G},\epsilon_{1})\). Then, by Lemma F.2, there must exist \(M_{\widehat{\epsilon}_{1}}>0\) with \(\widehat{\epsilon}_{1}:=\epsilon_{1}-\eta^{T_{2}^{\epsilon_{1}}}M_{G}\) such that \(\mathcal{G}\big{(}(p_{H}^{T_{2}^{\epsilon_{1}}},p_{L}^{\star\star})\big{)} \geq M_{\widehat{\epsilon}_{1}}\). As \(|\mathcal{T}_{\epsilon_{1}}|=\infty\), we can pick a sufficiently large \(T_{1}^{\epsilon_{1}}\in\mathcal{T}_{\epsilon_{1}}\) to guarantee that \(\ell_{r}\big{\|}\mathbf{r}^{t}-\mathbf{p}^{t}\big{\|}_{2}\leq M_{G}\) for \(t\geq T_{1}^{\epsilon_{1}}\) by Lemma F.1. Consequently, we obtain the desired conclusion that \(\operatorname{sign}\big{(}p_{H}^{\star\star}-p_{H}^{T_{2}^{\epsilon_{1}}} \big{)}\cdot G_{H}\big{(}\mathbf{p}^{T_{2}^{\epsilon_{1}}},\mathbf{r}^{T_{2}^ {\epsilon_{1}}}\big{)}>0\) when \(\mathbf{p}^{T_{2}^{\epsilon_{1}}}\in N_{2}\cup N_{4}\), which completes the proof of scenario 2.

Combining **Case 1** and **Case 2**, we have shown that \(\big{|}p_{H}^{\star\star}-p_{H}^{T_{2}^{\epsilon_{1}}+1}\big{|}/(b_{H}+c_{H})< \epsilon_{1}\), which completes the strong induction, i.e., \(\big{|}p_{H}^{\star\star}-p_{H}^{t}\big{|}/(b_{H}+c_{H})<\epsilon_{1}\) for all \(t\geq T_{1}^{\epsilon_{1}}\). Under the assumption that \(\{\mathbf{p}^{t}\}_{t\geq 0}\) never visits \(N_{\epsilon_{0}}^{\dagger}\) if \(t\geq T^{\epsilon_{0}}\), we accordingly have that \(\big{|}p_{L}^{\star\star}-p_{L}^{t}\big{|}/(b_{L}+c_{L})>(\epsilon_{0}- \epsilon_{1})\) for all \(t\geq T_{1}^{\epsilon_{1}}\). Therefore, following the derivations from Eq. (37) to Eq. (41), we deduce that Eq. (42) holds for all \(t\geq T_{1}^{\epsilon_{1}}\). Using a telescoping sum, it holds for any period \(T>T_{1}^{\epsilon_{1}}\) that

\[\frac{\big{|}p_{L}^{\star\star}-p_{L}^{T}\big{|}}{b_{L}+c_{L}}\leq \frac{\big{|}p_{L}^{\star\star}-p_{L}^{T_{1}^{\epsilon_{1}}}\big{|}}{b_{L}+c_{L }}-\frac{M_{\epsilon_{0}-\epsilon_{1}}}{2}\sum_{t=T_{1}^{\epsilon_{1}}}^{T-1} \eta^{t}.\] (51)

Since \(M_{\epsilon_{0}-\epsilon_{1}}>0\) is a constant and \(\lim_{T\to\infty}\sum_{t=T_{1}^{\epsilon_{1}}}^{T-1}\eta^{t}=\infty\), we arrive at the contradiction that \(\big{|}p_{L}^{\star\star}-p_{L}^{T}\big{|}/(b_{L}+c_{L})\to-\infty\) as \(T\to\infty\). Consequently, our initial assumption is incorrect and the price path \(\{\mathbf{p}^{t}\}_{t\geq 0}\) would visit the \(\ell_{1}\)-neighborhood \(N_{\epsilon_{0}}^{1}\) infinitely many times for any \(\epsilon_{0}>0\), which completes the proof of **Part 1**.

### Proof of Part 2

In particular, we show that when \(\mathbf{p}^{t}\in N_{\epsilon_{0}}^{2}\) for some sufficiently large \(t\), then it also holds \(\mathbf{p}^{t+1}\in N_{\epsilon_{0}}^{2}\). The value of \(\epsilon_{0}\) will be specified later in the proof.

By the update rule of Algorithm 1, it holds that

\[\left|p_{i}^{\star\star}-p_{i}^{t+1}\right|^{2} =\left|p_{i}^{\star\star}-\operatorname{Proj}_{\mathcal{P}}\left(p_ {i}^{t}+\eta^{t}D_{i}^{t}\right)\right|^{2}\] (52) \[\leq\left|p_{i}^{\star\star}-\left(p_{i}^{t}+\eta^{t}D_{i}^{t} \right)\right|^{2}\] \[=\left|\left(p_{i}^{\star\star}-p_{i}^{t}\right)-\eta^{t}(b_{i}+c _{i})\cdot G_{i}(\mathbf{p}^{t},\mathbf{r}^{t})\right|^{2}\] \[=\left|p_{i}^{\star\star}-p_{i}^{t}\right|^{2}-2\eta^{t}(b_{i}+c _{i})\cdot G_{i}(\mathbf{p}^{t},\mathbf{r}^{t})\cdot\left(p_{i}^{\star\star}-p _{i}^{t}\right)+\left(\eta^{t}(b_{i}+c_{i})\cdot G_{i}(\mathbf{p}^{t},\mathbf{ r}^{t})\right)^{2}\] \[=\left|p_{i}^{\star\star}-p_{i}^{t}\right|^{2}-2\eta^{t}(b_{i}+c _{i})\cdot G_{i}(\mathbf{p}^{t},\mathbf{p}^{t})\cdot\left(p_{i}^{\star\star}-p _{i}^{t}\right)+\left(\eta^{t}(b_{i}+c_{i})\cdot G_{i}(\mathbf{p}^{t},\mathbf{ r}^{t})\right)^{2}\] \[\quad+2\eta^{t}(b_{i}+c_{i})\cdot\left(G_{i}(\mathbf{p}^{t}, \mathbf{p}^{t})-G_{i}(\mathbf{p}^{t},\mathbf{r}^{t})\right)\cdot\left(p_{i}^{ \star\star}-p_{i}^{t}\right)\] \[\leq\left|p_{i}^{\star\star}-p_{i}^{t}\right|^{2}-2\eta^{t}(b_{i} +c_{i})\cdot G_{i}(\mathbf{p}^{t},\mathbf{p}^{t})\cdot\left(p_{i}^{\star\star} -p_{i}^{t}\right)+\left(\eta^{t}M_{G}(b_{i}+c_{i})\right)^{2}\] \[\quad+2\eta^{t}(b_{i}+c_{i})\cdot\left|p_{i}^{\star\star}-p_{i}^ {t}\right|\cdot\ell_{r}\|\mathbf{r}^{t}-\mathbf{p}^{t}\|_{2},\]

where we use \(|G_{i}(\mathbf{p},\mathbf{r})|\leq M_{G}\) and the mean value theorem in the last inequality (see Lemma F.5). Let \(\mathcal{H}(\mathbf{p})\) be a function defined as

\[\mathcal{H}(\mathbf{p}):=(b_{H}+c_{H})\cdot G_{H}(\mathbf{p},\mathbf{p})\cdot (p_{H}^{\star\star}-p_{H})+(b_{L}+c_{L})\cdot G_{L}(\mathbf{p},\mathbf{p})\cdot (p_{L}^{\star\star}-p_{L}).\] (53)

Then, by summing Eq. (52) over both products \(i\in\{H,L\}\), we have that

\[\left\|\mathbf{p}^{\star\star}-\mathbf{p}^{t+1}\right\|_{2}^{2} \leq\left\|\mathbf{p}^{\star\star}-\mathbf{p}^{t}\right\|_{2}^{2} -2\eta^{t}\sum_{i\in\{H,L\}}(b_{i}+c_{i})\cdot G_{i}(\mathbf{p}^{t},\mathbf{p} ^{t})\cdot\left(p_{i}^{\star\star}-p_{i}^{t}\right)\] (54) \[\quad+(\eta^{t}M_{G})^{2}\sum_{i\in\{H,L\}}(b_{i}+c_{i})^{2}+2 \eta^{t}\ell_{r}\|\mathbf{r}^{t}-\mathbf{p}^{t}\|_{2}\sum_{i\in\{H,L\}}(b_{i}+c _{i})\cdot\left|p_{i}^{\star\star}-p_{i}^{t}\right|\] \[=\left\|\mathbf{p}^{\star\star}-\mathbf{p}^{t}\right\|_{2}^{2}-2 \eta^{t}\mathcal{H}(\mathbf{p}^{t})+(\eta^{t}M_{G})^{2}\sum_{i\in\{H,L\}}(b_{ i}+c_{i})^{2}\] \[\quad+2\eta^{t}\ell_{r}\|\mathbf{r}^{t}-\mathbf{p}^{t}\|_{2}\sum_ {i\in\{H,L\}}(b_{i}+c_{i})\cdot\left|p_{i}^{\star\star}-p_{i}^{t}\right|\] \[\leq\left\|\mathbf{p}^{\star\star}-\mathbf{p}^{t}\right\|_{2}^{2} -\eta^{t}\bigg{(}2\mathcal{H}(\mathbf{p}^{t})-\eta^{t}C_{1}-C_{2}\|\mathbf{r} ^{t}-\mathbf{p}^{t}\|_{2}\bigg{)}\]

where we denote \(C_{1}:=(M_{G})^{2}\cdot\sum_{i\in\{H,L\}}(b_{i}+c_{i})^{2}\) and \(C_{2}=2\ell_{r}|\overline{p}-\underline{p}|\cdot\sum_{i\in\{H,L\}}(b_{i}+c_{i})\).

By Lemma F.3, there exist \(\gamma>0\) and a open set \(U_{\gamma}\ni\mathbf{p}^{\star\star}\) such that \(\mathcal{H}(\mathbf{p})\geq\gamma\cdot\|\mathbf{p}-\mathbf{p}^{\star\star}\|_ {2}^{2}\), \(\forall\mathbf{p}\in U_{\gamma}\). Consider \(\epsilon_{0}>0\) such that the \(\ell_{2}\)-neighborhood \(N_{\epsilon_{0}}^{2}=\left\{\mathbf{p}\in\mathcal{P}^{2}\mid\|\mathbf{p}- \mathbf{p}^{\star\star}\|_{2}<\epsilon_{0}\right\}\subset U_{\gamma}\). Furthermore, let \(T_{\gamma}\) be some period such that

\[\eta^{t}\left(\eta^{t}C_{1}+\sqrt{2}C_{2}(\overline{p}-\underline{p})\right) \leq\frac{\epsilon_{0}^{2}}{4},\text{ and }\eta^{t}C_{1}+C_{2}\|\mathbf{r}^{t}-\mathbf{p}^{t}\|_{2}\leq\frac{\gamma( \epsilon_{0})^{2}}{2},\quad\forall t>T_{\gamma}.\] (55)

The existence of such a number \(T_{\gamma}\) follows from the fact that \(\lim_{t\to\infty}\eta^{t}=0\) and \(\lim_{t\to\infty}\|\mathbf{r}^{t}-\mathbf{p}^{t}\|_{2}=0\) (see Lemma F.1). Below, we discuss two cases depending on the location of \(\mathbf{p}^{t}\) in \(N_{\epsilon_{0}}^{2}\).

**Case 1: \(\mathbf{p}^{t}\in N_{\epsilon_{0}/2}^{2}\subset N_{\epsilon_{0}}^{2}\)**, i.e., \(\left\|\mathbf{p}^{\star\star}-\mathbf{p}^{t}\right\|_{2}<\epsilon_{0}/2\).

Since \(\mathcal{H}(\mathbf{p})\geq 0\), \(\forall\mathbf{p}\in U_{\gamma}\) by Lemma F.3, it follows from Eq. (54) and Eq. (55) that

\[\begin{split}\left\|\mathbf{p}^{\star\star}-\mathbf{p}^{t+1} \right\|_{2}^{2}&\leq\left\|\mathbf{p}^{\star\star}-\mathbf{p}^{t} \right\|_{2}^{2}+\eta^{t}\bigg{(}\eta^{t}C_{1}+C_{2}\|\mathbf{r}^{t}-\mathbf{p }^{t}\|_{2}\bigg{)}\\ &\overset{(\Delta)}{\leq}\frac{(\epsilon_{0})^{2}}{4}+\eta^{t} \left(\eta^{t}C_{1}+\sqrt{2}C_{2}(\overline{p}-\underline{p})\right)\\ &\leq\frac{(\epsilon_{0})^{2}}{4}+\frac{(\epsilon_{0})^{2}}{4}\\ &<(\epsilon_{0})^{2},\end{split}\] (56)

where inequality \((\Delta)\) is due to \(\|\mathbf{r}^{t}-\mathbf{p}^{t}\|_{2}\leq\sqrt{2}(\overline{p}-\underline{p})\). Eq. (56) implies that \(\mathbf{p}^{t+1}\in N_{\epsilon_{0}}^{2}\).

**Case 2: \(\mathbf{p}^{t}\in N_{\epsilon_{0}}^{2}\backslash N_{\epsilon_{0}/2}^{2}\)**, i.e., \(\left\|\mathbf{p}^{\star\star}-\mathbf{p}^{t}\right\|_{2}\in[\epsilon_{0}/2, \epsilon_{0})\).

By Lemma F.3, we have that \(\mathcal{H}(\mathbf{p}^{t})\geq\gamma\big{\|}\mathbf{p}^{\star\star}-\mathbf{ p}^{t}\big{\|}_{2}^{2}\geq\gamma(\epsilon_{0})^{2}/4\). Thus, again by Eq. (54) and Eq. (55), we have that

\[\begin{split}\left\|\mathbf{p}^{\star\star}-\mathbf{p}^{t+1} \right\|_{2}^{2}&\leq\left\|\mathbf{p}^{\star\star}-\mathbf{p}^{t }\right\|_{2}^{2}-\eta^{t}\bigg{(}2\mathcal{H}(\mathbf{p}^{t})-\eta^{t}C_{1}- C_{2}\|\mathbf{r}^{t}-\mathbf{p}^{t}\|_{2}\bigg{)}\\ &\leq\left\|\mathbf{p}^{\star\star}-\mathbf{p}^{t}\right\|_{2}^{2} -\eta^{t}\bigg{(}\frac{\gamma(\epsilon_{0})^{2}}{2}-\eta^{t}C_{1}-C_{2}\| \mathbf{r}^{t}-\mathbf{p}^{t}\|_{2}\bigg{)}\\ &\leq\left\|\mathbf{p}^{\star\star}-\mathbf{p}^{t}\right\|_{2}^{2} \\ &\leq(\epsilon_{0})^{2},\end{split}\] (57)

which implies \(\mathbf{p}^{t+1}\in N_{\epsilon_{0}}^{2}\). Therefore, we conclude by induction that the price path will stay in the \(\ell_{2}\)-neighborhood \(N_{\epsilon_{0}}^{2}\). This completes the proof of Theorem 5.1. 

## Appendix D Proof of Theorem 5.2

Proof.: Recall the function \(\mathcal{H}(\mathbf{p})\) defined in Eq. (53). By Lemma F.3, there exist \(\gamma>0\) and a open set \(U_{\gamma}\ni\mathbf{p}^{\star\star}\) such that \(\mathcal{H}(\mathbf{p})\geq\gamma\cdot\|\mathbf{p}-\mathbf{p}^{\star\star}\|_{ 2}^{2}\), \(\forall\mathbf{p}\in U_{\gamma}\). Consider \(\epsilon_{0}>0\) such that the \(\ell_{2}\)-neighborhood \(N_{\epsilon_{0}}^{2}=\left\{\mathbf{p}\in\mathcal{P}^{2}\ |\ \|\mathbf{p}-\mathbf{p}^{\star\star}\|_{2}< \epsilon_{0}\right\}\subset U_{\gamma}\). Below, we first show that the price path \(\{\mathbf{p}^{t}\}_{t\geq 0}\) enjoys the sublinear convergence rate in \(N_{\epsilon_{0}}^{2}\) when \(t\) is greater than some constant \(T_{\epsilon_{0}}\). Then, we will show that this convergence rate also holds for any \(t\leq T_{\epsilon_{0}}\).

By **Part 2** in the proof of Theorem 5.1, there exists \(T_{\epsilon_{0}}>0\) such that \(\mathbf{p}^{t}\in N_{\epsilon_{0}}^{2}\) for every \(t\geq T_{\epsilon_{0}}\). Following a similar argument as Eq. (52) and Eq. (54), we have that

\[\begin{split}\left\|\mathbf{p}^{\star\star}-\mathbf{p}^{t+1} \right\|_{2}^{2}\\ \overset{(\Delta_{1})}{\leq}\left\|\mathbf{p}^{\star\star}- \mathbf{p}^{t}\right\|_{2}^{2}-2\eta^{t}\mathcal{H}(\mathbf{p}^{t})+C_{1}(\eta ^{t})^{2}+2\eta^{t}\ell_{r}\|\mathbf{r}^{t}-\mathbf{p}^{t}\|_{2}\sum_{i\in\{H,L \}}(b_{i}+c_{i})\cdot\left|p_{i}^{\star\star}-p_{i}^{t}\right|\\ \overset{(\Delta_{2})}{\leq}\left\|\mathbf{p}^{\star\star}- \mathbf{p}^{t}\right\|_{2}^{2}-2\eta^{t}\gamma\big{\|}\mathbf{p}^{\star\star}- \mathbf{p}^{t}\big{\|}_{2}^{2}+C_{1}(\eta^{t})^{2}+2\eta^{t}\ell_{r}\|\mathbf{r} ^{t}-\mathbf{p}^{t}\|_{2}\cdot\hat{k}\big{\|}\mathbf{p}^{\star\star}-\mathbf{p} ^{t}\big{\|}_{2}\\ \overset{(\Delta_{3})}{\leq}\left\|\mathbf{p}^{\star\star}- \mathbf{p}^{t}\right\|_{2}^{2}-2\eta^{t}\gamma\big{\|}\mathbf{p}^{\star\star}- \mathbf{p}^{t}\big{\|}_{2}^{2}+C_{1}(\eta^{t})^{2}+\eta^{t}\ell_{r}\hat{k}\left[ \frac{\gamma}{\ell_{r}\hat{k}}\big{\|}\mathbf{p}^{\star\star}-\mathbf{p}^{t} \big{\|}_{2}^{2}+\frac{\ell_{r}\hat{k}}{\gamma}\big{\|}\mathbf{r}^{t}-\mathbf{p} ^{t}\big{\|}_{2}^{2}\right]\\ \overset{(\Delta_{4})}{\leq}\left\|\mathbf{p}^{\star\star}- \mathbf{p}^{t}\right\|_{2}^{2}-\eta^{t}\gamma\big{\|}\mathbf{p}^{\star\star}- \mathbf{p}^{t}\big{\|}_{2}^{2}+C_{1}(\eta^{t})^{2}+\eta^{t}k\big{\|}\mathbf{r} ^{t}-\mathbf{p}^{t}\big{\|}_{2}^{2}.\end{split}\] (58)In step \((\Delta_{1})\), \(\ell_{r}\) is the Lipschitz constant defined in Eq. (100) and the constant \(C_{1}\) is defined in Eq. (54). In step \((\Delta_{2})\), we utilize Lemma F.3 and the following inequality

\[\sum_{i\in\{H,L\}}(b_{i}+c_{i})\big{|}p_{i}^{\star\star}-p_{i}^{t} \big{|} \leq\max_{i\in\{H,L\}}\{b_{i}+c_{i}\}\big{\|}\mathbf{p}^{\star \star}-\mathbf{p}^{t}\big{\|}_{1}\] (59) \[\leq\sqrt{2}\max_{i\in\{H,L\}}\{b_{i}+c_{i}\}\big{\|}\mathbf{p}^{ \star\star}-\mathbf{p}^{t}\big{\|}_{2}\] \[=\hat{k}\big{\|}\mathbf{p}^{\star\star}-\mathbf{p}^{t}\big{\|}_{2},\]

where we define \(\hat{k}:=\sqrt{2}\max_{i\in\{H,L\}}\{b_{i}+c_{i}\}\). Step \((\Delta_{3})\) in Eq. (58) follows from the inequality of arithmetic and geometric means, i.e., \(2xy\leq Ax^{2}+(1/A)y^{2}\) for any constant \(A>0\). The value of constant \(k\) in \((\Delta_{4})\) is given by \(k:=(\ell_{r}\hat{k})^{2}/\gamma=2\big{(}\ell_{r}\max_{i\in\{H,L\}}\{b_{i}+c_{ i}\}\big{)}^{2}/\gamma\).

To upper-bound the right-hand side of Eq. (58), we first focus on the term \(\big{\|}\mathbf{r}^{t}-\mathbf{p}^{t}\big{\|}_{2}^{2}\) and inductively show that

\[\big{\|}\mathbf{r}^{t}-\mathbf{p}^{t}\big{\|}_{2}^{2}=\mathcal{O}\left(\frac{ 1}{t^{2}}\right),\quad\forall t\geq T_{\lambda}:=\frac{\sqrt{\lambda+1}}{\sqrt {\lambda+1}-\sqrt{2\lambda}},\] (60)

where \(\lambda:=(1+\alpha^{2})/2<1\). We use the notation \(\mathbf{D}^{t}:=\big{(}D_{H}^{t},D_{L}^{t}\big{)}=\big{(}(b_{H}+c_{H})G_{H}( \mathbf{p}^{t},\mathbf{r}^{t}),(b_{L}+c_{L})G_{L}(\mathbf{p}^{t},\mathbf{r}^{ t})\big{)}\), where we recall that \(D_{i}^{t}\) is the partial derivative specified in Eq. (9) and function \(G_{i}(\cdot,\cdot)\) is defined in Eq. (25). Then, the term \(\big{\|}\mathbf{r}^{t}-\mathbf{p}^{t}\big{\|}_{2}^{2}\) can be upper-bounded as follows

\[\big{\|}\mathbf{r}^{t}-\mathbf{p}^{t}\big{\|}_{2}^{2}\] (61) \[=\big{\|}\alpha\mathbf{r}^{t-1}+(1-\alpha)\mathbf{p}^{t-1}- \mathbf{p}^{t}\big{\|}_{2}^{2}\] \[=\alpha^{2}\big{\|}\mathbf{r}^{t-1}-\mathbf{p}^{t-1}\big{\|}_{2}^ {2}+\big{\|}\mathbf{p}^{t-1}-\mathbf{p}^{t}\big{\|}_{2}^{2}+2\alpha(\mathbf{r} ^{t-1}-\mathbf{p}^{t-1})^{\top}(\mathbf{p}^{t-1}-\mathbf{p}^{t})\] \[\stackrel{{(\Delta_{1})}}{{\leq}}\alpha^{2}\big{\|} \mathbf{r}^{t-1}-\mathbf{p}^{t-1}\big{\|}_{2}^{2}+\big{\|}\eta^{t-1}\mathbf{D} ^{t-1}\big{\|}_{2}^{2}+2\alpha\big{\|}\mathbf{r}^{t-1}-\mathbf{p}^{t-1}\big{\|} _{2}\big{\|}\eta^{t-1}\mathbf{D}^{t-1}\big{\|}_{2}\] \[\stackrel{{(\Delta_{2})}}{{\leq}}\alpha^{2}\big{\|} \mathbf{r}^{t-1}-\mathbf{p}^{t-1}\big{\|}_{2}^{2}+\big{\|}\eta^{t-1}\mathbf{D} ^{t-1}\big{\|}_{2}^{2}+\frac{1-\alpha^{2}}{2}\big{\|}\mathbf{r}^{t-1}-\mathbf{ p}^{t-1}\big{\|}_{2}^{2}+\frac{2\alpha^{2}}{1-\alpha^{2}}\big{\|}\eta^{t-1} \mathbf{D}^{t-1}\big{\|}_{2}^{2}\] \[=\lambda\big{\|}\mathbf{r}^{t-1}-\mathbf{p}^{t-1}\big{\|}_{2}^{2}+ \frac{1+\alpha^{2}}{1-\alpha^{2}}\cdot\left(\sum_{i\in\{H,L\}}(b_{i}+c_{i})^{2 }\left[G_{i}(\mathbf{p}^{t-1},\mathbf{r}^{t-1})\right]^{2}\right)\cdot(\eta^{t -1})^{2}\] \[\stackrel{{(\Delta_{3})}}{{\leq}}\lambda\big{\|} \mathbf{r}^{t-1}-\mathbf{p}^{t-1}\big{\|}_{2}^{2}+\underbrace{\left(\frac{1+ \alpha^{2}}{1-\alpha^{2}}\cdot(M_{G})^{2}\sum_{i\in\{H,L\}}(b_{i}+c_{i})^{2} \right)}_{\lambda_{0}}\cdot(\eta^{t-1})^{2},\]

where \((\Delta_{1})\) holds due to the Cauchy-Schwarz inequality and the property of the projection operator (see Line 5 in Algorithm 1). Step \((\Delta_{2})\) is derived from the inequality of arithmetic and geometric means. Lastly, step \((\Delta_{3})\) applies the upper bound on function \(G_{i}(\cdot,\cdot)\) in Lemma F.5 and the definition of \(C_{1}\) in Eq. (54). For the simplicity of notation, we denote the coefficient of \((\eta^{t-1})^{2}\) in the last line as \(\lambda_{0}\).

Let the step-size be \(\eta^{t}=d_{\eta}/(t+1)\) for \(t\geq 0\), where \(d_{\eta}\) is some constant that will be determined later. Suppose that there exists a constant \(d_{rp}\) such that

\[\big{\|}\mathbf{r}^{t-1}-\mathbf{p}^{t-1}\big{\|}_{2}^{2}\leq\frac{d_{rp}}{(t-1 )^{2}},\] (62)for some \(t\geq T_{\lambda}+1\). Then, together with Eq. (61), we have that

\[\left\|\mathbf{r}^{t}-\mathbf{p}^{t}\right\|_{2}^{2} \leq\lambda\big{\|}\mathbf{r}^{t-1}-\mathbf{p}^{t-1}\big{\|}_{2}^{2 }+\lambda_{0}(\eta^{t-1})^{2}\] \[\leq\frac{\lambda d_{rp}}{(t-1)^{2}}+\frac{\lambda_{0}(d_{\eta})^ {2}}{t^{2}}\] \[=\frac{\lambda d_{rp}}{t^{2}}\cdot\frac{t^{2}}{(t-1)^{2}}+\frac{ \lambda_{0}(d_{\eta})^{2}}{t^{2}}\] (63) \[\overset{(\Delta)}{\leq}\frac{\lambda d_{rp}}{t^{2}}\cdot\frac{ \lambda+1}{2\lambda}+\frac{\lambda_{0}(d_{\eta})^{2}}{t^{2}}\] \[=\frac{0.5(\lambda+1)\cdot d_{rp}+\lambda_{0}(d_{\eta})^{2}}{t^{2 }},\]

where the inequality \((\Delta)\) results from the choice of \(T_{\lambda}\). Hence, the induction follows if \(0.5(\lambda+1)d_{rp}+\lambda_{0}(d_{\eta})^{2}\leq d_{rp}\), which is further equivalent to

\[d_{rp}\geq\frac{2\lambda_{0}(d_{\eta})^{2}}{1-\lambda}.\] (64)

Lastly, the base case of the induction requires that \(\left\|\mathbf{r}^{T_{\lambda}}-\mathbf{p}^{T_{\lambda}}\right\|_{2}^{2}\leq \frac{d_{rp}}{(T_{\lambda})^{2}}\). Therefore, by Eq. (64) and the definition of feasible price range \(\mathcal{P}=[\underline{p},\overline{p}]\), it suffices to choose

\[d_{rp}=\max\left\{\frac{2\lambda_{0}(d_{\eta})^{2}}{1-\lambda},\;2(T_{\lambda} )^{2}(\overline{p}-\underline{p})^{2}\right\},\] (65)

where the constants \(\lambda_{0}\) and \(T_{\lambda}\) are respectively defined in Eq. (61)and Eq. (60). Note that, under this choice of constant \(d_{rp}\), it also holds that

\[\left\|\mathbf{r}^{t}-\mathbf{p}^{t}\right\|_{2}^{2}\leq 2(\overline{p}- \underline{p})^{2}<\frac{2(T_{\lambda})^{2}(\overline{p}-\underline{p})^{2}} {t^{2}}\leq\frac{d_{rp}}{t^{2}},\quad\forall 1\leq t<T_{\lambda}.\] (66)

Together with Eq. (60), we derive that

\[\left\|\mathbf{r}^{t}-\mathbf{p}^{t}\right\|_{2}^{2}\leq\frac{d_{rp}}{t^{2}}, \quad\forall t\geq 1.\] (67)

For every \(t\geq T_{\epsilon_{0}}\), we can further upper-bound the right-hand side of Eq. (58) by exploiting the upper bound of \(\left\|\mathbf{r}^{t}-\mathbf{p}^{t}\right\|_{2}^{2}\) in Eq. (67) and the choice of \(\eta_{t}=d_{\eta}/(t+1)\):

\[\left\|\mathbf{p}^{\star\star}-\mathbf{p}^{t+1}\right\|_{2}^{2} \leq\left(1-\frac{\gamma d_{\eta}}{t+1}\right)\left\|\mathbf{p}^{ \star\star}-\mathbf{p}^{t}\right\|_{2}^{2}+\frac{C_{1}(d_{\eta})^{2}}{(t+1)^{2 }}+\frac{d_{\eta}k\cdot d_{rp}}{(t+1)t^{2}}\] \[\leq\left(1-\frac{\gamma d_{\eta}}{t+1}\right)\left\|\mathbf{p}^{ \star\star}-\mathbf{p}^{t}\right\|_{2}^{2}+\frac{1}{t(t+1)}\underbrace{ \left(C_{1}(d_{\eta})^{2}+\frac{d_{\eta}kd_{rp}}{T_{\epsilon_{0}}}\right)}_{C_ {3}}.\] (68)

Now, we inductively show that

\[\left\|\mathbf{p}^{\star\star}-\mathbf{p}^{t}\right\|_{2}^{2}=\mathcal{O} \left(\frac{1}{t}\right),\quad\forall t\geq T_{\epsilon_{0}}.\] (69)

Suppose there exists a constant \(d_{p}\) such that for a fixed period \(t\geq T_{\epsilon_{0}}\)

\[\left\|\mathbf{p}^{\star\star}-\mathbf{p}^{t}\right\|_{2}^{2}\leq\frac{d_{p}}{ t}.\] (70)

To establish the induction, it suffices for the following inequality to hold

\[\left\|\mathbf{p}^{\star\star}-\mathbf{p}^{t+1}\right\|_{2}^{2}\leq\left(1- \frac{\gamma d_{\eta}}{t+1}\right)\frac{d_{p}}{t}+\frac{C_{3}}{t(t+1)}\leq\frac {d_{p}}{t+1},\] (71)which is further equivalent to

\[(\gamma d_{\eta}-1)d_{p}\geq C_{3}.\] (72)

To satisfy the base case of the induction, we can select \(d_{p}\) such that \(d_{p}\geq T_{\epsilon_{0}}\cdot\left\|\mathbf{p}^{\star\star}-\mathbf{p}^{T_{ \epsilon_{0}}}\right\|_{2}^{2}\). In summary, one possible set of constants \((d_{\eta},d_{rp},d_{p})\) that satisfies all the requirements can be

\[d_{\eta}=\frac{2}{\gamma},\quad d_{rp}=\max\left\{\frac{2\lambda_{0}(d_{\eta}) ^{2}}{1-\lambda},\;2(T_{\lambda})^{2}(\overline{p}-\underline{p})^{2}\right\},\quad d_{p}=\max\{C_{3},2T_{\epsilon_{0}}(\overline{p}-\underline{p})^{2}\},\] (73)

where the constants \(\lambda_{0}\), \(T_{\lambda}\), and \(C_{3}\) are respectively defined in Eq. (61), Eq. (60), and Eq. (68). Now, for any period \(1\leq t<T_{\epsilon_{0}}\), it follows that

\[\left\|\mathbf{p}^{\star\star}-\mathbf{p}^{t}\right\|_{2}^{2}\leq 2(\overline{p} -\underline{p})^{2}<\frac{2T_{\epsilon_{0}}(\overline{p}-\underline{p})^{2}} {t}\leq\frac{d_{p}}{t}.\] (74)

Together with Eq. (69), this proves the convergence rate for the price path, i.e.,

\[\left\|\mathbf{p}^{\star\star}-\mathbf{p}^{t}\right\|_{2}^{2}\leq\frac{d_{p}} {t},\quad\forall t\geq 1.\] (75)

Finally, the convergence rate of the reference price path can be deduced from the following triangular inequality:

\[\left\|\mathbf{p}^{\star\star}-\mathbf{r}^{t}\right\|_{2}^{2} =\left\|\mathbf{p}^{\star\star}-\mathbf{p}^{t}+\mathbf{p}^{t}- \mathbf{r}^{t}\right\|_{2}^{2}\] (76) \[\leq 2\left\|\mathbf{p}^{\star\star}-\mathbf{p}^{t}\right\|_{2}^{ 2}+2\left\|\mathbf{p}^{t}-\mathbf{r}^{t}\right\|_{2}^{2}\] \[\overset{(\Delta)}{\leq}\frac{2d_{p}}{t}+\frac{2d_{rp}}{t^{2}}\] \[\leq\frac{2d_{p}+2d_{rp}}{t},\quad\forall t\geq 1,\]

where \((\Delta)\) follows from Eq. (67) and Eq. (75). Therefore, it suffices to choose \(d_{r}:=2d_{p}+2d_{rp}\), and this completes the proof.

## Appendix E Proof of Theorem 6.1

Proof.: Recall the definition of \(G_{i}(\mathbf{p},\mathbf{r})\) from Eq. (25). We can write the inexact derivative as \(D_{i}^{t}=(b_{i}+c_{i})G_{i}(\mathbf{p}^{t},\mathbf{r}^{t})+n_{i}^{t}\), where \(n_{i}^{t}\) represents the error satisfying \(|n_{i}^{t}|<\delta\), \(\forall i\in\{H,L\}\) and \(\forall t\geq 0\).

We also recall the two-part proof for Theorem 5.1: in Part 1, we show that the price path and reference price paths converge towards the SNE and visit the neighborhood \(N_{\epsilon}^{1}\) infinitely many times, for any \(\epsilon>0\). In Part 2, we establish that, given \(\epsilon\) is below a certain threshold \(\epsilon_{0}\), the price vector would remain in the neighborhood \(N_{\epsilon}^{2}\) after entering it with a sufficiently small step-size. Since the relative scale of \(\delta\) and \(\epsilon_{0}\) is unsure, our proof below is mainly based on Part 1.

In Part 1, the original proof assuming the exact gradient oracle employs a contradiction-based argument. Suppose the price path does not converge to the SNE, the proof consists of the following major steps (different from Appendix C, we use \(\epsilon\) in lieu of \(\epsilon_{0}\) to avoid confusion in the following proof):

* In Eq. (29), it is demonstrated that the price path steadily approaches the SNE if it stays in the same quadrant defined in Eq. (28). The main technique we use is \(\mathcal{G}(\mathbf{p})>M_{\epsilon}\) when \(\varepsilon(\mathbf{p})>\epsilon\). The definition of \(\mathcal{G}(\mathbf{p})\) and the validation for the technique are stated in Lemma F.2.
* In Eq. (34), we show that the price path only oscillates between adjacent quadrants provided the step-sizes are sufficiently small.
* From Eqs (37) to (41), we prove that even when the price path does not stay in the same quadrant, it will still converge toward the SNE if it is at the boundary regions between two quadrants. The pivotal inequality employed here is again \(\mathcal{G}((p_{H}^{\star\star},p_{L}^{T_{1}^{\epsilon_{1}}}))\geq M_{ \epsilon-\epsilon_{1}}\), provided \(\varepsilon((p_{H}^{\star\star},p_{L}^{T_{1}^{\epsilon_{1}}}))>\epsilon- \epsilon_{1}\) (see the end of Eqs. (38) and (40)).

* Finally, in Eq. (44) and subsequent equations, we provide supplementary justification for the above bullet that the price path remains adjacent to the boundaries given that the step-size is small. A crucial consideration here is opting for a much smaller \(\epsilon_{1}\) relative to \(\epsilon\) when defining the boundary region. In addition, the inequality \(\mathcal{G}((p_{H}^{T_{1}^{\epsilon_{1}}},p_{L}^{\star}))\geq M_{\widehat{ \epsilon}_{1}}\) is also utilized in Eq. (50).

To summarize, the key to the proof is Lemma F.2., i.e., \(\mathcal{G}(\mathbf{p})>M_{\epsilon}>0\) as long as \(\varepsilon(\mathbf{p})>\epsilon\). By definition, \(\mathcal{G}(\mathbf{p}^{t})\) approximately characterizes the difference \(\varepsilon(\mathbf{p}^{t})-\varepsilon(\mathbf{p}^{t+1})\) as seen in Eq. (29). As a result, the effect of the lower bound \(M_{\epsilon}\) is that, if other terms can be upper-bounded by \(M_{\epsilon}\), we can show that the updated price is closer to the SNE. For example, in the right-hand side of Eq. (29), once the term \(2\ell_{r}\|\mathbf{r}^{t}-\mathbf{p}^{t}\|_{2}\) is below \(M_{\epsilon}\), it suggests that the price vector is heading towards the SNE.

With inexact first-order oracles, the immediate consequence is that there will always be an error term accompanying \(\mathcal{G}(\mathbf{p})\). For instance, given \(D_{i}^{t}=(b_{i}+c_{i})G_{i}(\mathbf{p}^{t},\mathbf{r}^{t})+n_{i}^{t}\), we observe that Eq. (29) evolves to

\[\varepsilon(\mathbf{p}^{t+1})\leq\varepsilon(\mathbf{p}^{t})-\eta^{t}\left(M _{\epsilon}-2\ell_{r}\|\mathbf{r}^{t}-\mathbf{p}^{t}\|_{2}-\sum_{i\in\{H,L\}} \frac{n_{i}^{t}}{(b_{i}+c_{i})}\right).\] (77)

This observation is consistent across the proof. Thus, if the error \(n_{i}^{t}\) is substantially smaller than \(M_{\epsilon}\), the proof of Theorem 5.1 remains valid, implying that the price vector converges towards the SNE. The subtlety arises when the size of \(n_{i}^{t}\) is comparable with \(M_{\epsilon}\). Under such circumstances, the analysis in both Eq. (29) and Eqs. (37) to (41) becomes invalid, as the errors are substantial enough to negate any assurance that the price path strictly approaches the SNE.

However, if the error \(n_{i}^{t}\) is similar in magnitude to \(\mathcal{G}(\mathbf{p})\), we can show that the price vector \(\mathbf{p}\) is already close to the SNE \(\mathbf{p}^{\star\star}\). More precisely, since the errors are bounded by \(\delta\), it is equivalent to show that \(\mathcal{G}(\mathbf{p})=\mathcal{O}(\delta)\) also implies \(\|\mathbf{p}-\mathbf{p}^{\star\star}\|_{2}=\mathcal{O}(\delta)\). This can be proved by a refined version of Lemma F.2.

**Lemma E.1** (**Refined Lemma F.2**): _Let \(\mathcal{G}(\mathbf{p})\) be the function defined in Eq. (86). Then, it holds that_

\[\mathcal{G}(\mathbf{p})\geq\sum_{i}\frac{|p_{i}-p_{i}^{\star\star}|}{(b_{i}+c _{i})p_{i}^{\star\star}\bar{p}},\] (78)

_i.e., \(\mathcal{G}(\mathbf{p})\) is lower-bounded by a weighted \(\ell_{1}\) distance between \(\mathbf{p}\) and \(\mathbf{p}^{\star\star}\). By the equivalence of norms in the Euclidean space, there exists some constant \(C\) such that \(\mathcal{G}(\mathbf{p})\geq C\cdot\|\mathbf{p}-\mathbf{p}^{\star\star}\|_{2}\)._

Proof.: Similar to the proof of the original Lemma F.2, we separately consider the four possible scenarios where \(\mathbf{p}\) belongs to one of the quadrant defined in Eq. (28).

1. Suppose \(p_{H}>p_{H}^{\star\star}\) and \(p_{L}\geq p_{L}^{\star\star}\), i.e., \(\mathbf{p}\in N_{1}\). Since \(G_{i}(\mathbf{p}^{\star\star})=0\), we have that \[\mathcal{G}(\mathbf{p})=\mathcal{G}(\mathbf{p})-\mathcal{G}(\mathbf{p}^{\star \star})=\sum_{i}\frac{1}{b_{i}+c_{i}}\left(\frac{1}{p_{i}^{\star\star}}-\frac{ 1}{p_{i}}\right)+d_{0}(\mathbf{p},\mathbf{p})-d_{0}(\mathbf{p}^{\star\star}, \mathbf{p}^{\star\star}).\] (79) By definition of the non-purchase probability, we observe that \(d_{0}(\mathbf{p},\mathbf{p})-d_{0}(\mathbf{p}^{\star\star},\mathbf{p}^{\star \star})>0\). Hence, the above equation implies that \[\mathcal{G}(\mathbf{p})>\sum_{i}\frac{1}{b_{i}+c_{i}}\cdot\frac{p_{i}-p_{i}^{ \star\star}}{p_{i}^{\star\star}p_{i}}\geq\sum_{i}\frac{1}{b_{i}+c_{i}}\cdot \frac{p_{i}-p_{i}^{\star\star}}{p_{i}^{\star\star}\bar{p}}=\sum_{i}\frac{|p_{i} -p_{i}^{\star\star}|}{(b_{i}+c_{i})p_{i}^{\star\star}\bar{p}},\] (80) where we use the fact that \(p_{i}\in\mathcal{P}=[\underline{p},\bar{p}]\) and the presumption \(\mathbf{p}\in N_{1}\).
2. Suppose \(p_{H}\leq p_{H}^{\star\star}\) and \(p_{L}>p_{L}^{\star\star}\), i.e., \(\mathbf{p}\in N_{2}\). Again, using the fact that \(G_{i}(\mathbf{p}^{\star\star})=0\), we derive that \[\mathcal{G}(\mathbf{p})= \frac{1}{b_{H}+c_{H}}\left(\frac{1}{p_{H}}-\frac{1}{p_{H}^{\star \star}}\right)+\frac{1}{b_{L}+c_{L}}\left(\frac{1}{p_{L}^{\star\star}}-\frac{1}{ p_{L}}\right)\] (81) \[+[d_{H}(\mathbf{p},\mathbf{p})-d_{H}(\mathbf{p}^{\star\star}, \mathbf{p}^{\star\star})]+[d_{L}(\mathbf{p}^{\star\star},\mathbf{p}^{\star \star})-d_{L}(\mathbf{p},\mathbf{p})]\,.\] Since \(\mathbf{p}\in N_{2}\), we have that \(d_{H}(\mathbf{p},\mathbf{p})-d_{H}(\mathbf{p}^{\star\star},\mathbf{p}^{\star \star})>0\) and \(d_{L}(\mathbf{p}^{\star\star},\mathbf{p}^{\star\star})-d_{L}(\mathbf{p},\mathbf{ p})>0\). Hence, similar to the first case, it follows that \[\mathcal{G}(\mathbf{p})>\frac{1}{b_{H}+c_{H}}\left(\frac{1}{p_{H}}-\frac{1}{p_{H}^{ \star\star}}\right)+\frac{1}{b_{L}+c_{L}}\left(\frac{1}{p_{L}^{\star\star}}- \frac{1}{p_{L}}\right)\geq\sum_{i}\frac{|p_{i}-p_{i}^{\star\star}|}{(b_{i}+c_{i} )p_{i}^{\star}\bar{p}}.\] (82)The same conclusion can be drawn when \(\mathbf{p}\in N_{3}\cup N_{4}\), and the proof is intrinsically the same. Hence, we conclude the proof of this lemma. 

Finally, due to Lemma E.1, we have that \(\|\mathbf{p}-\mathbf{p}^{\star\star}\|_{2}\leq 1/C\cdot\mathcal{G}(\mathbf{p})\). Therefore, when \(\mathcal{G}(\mathbf{p})=\mathcal{O}(\delta)\), we also have \(\|\mathbf{p}-\mathbf{p}^{\star\star}\|_{2}=\mathcal{O}(\delta)\), i.e., the price vector is already in a \(\mathcal{O}(\delta)\) neighborhood of the SNE. This completes the proof of Theorem 6.1. 

## Appendix F Supporting lemmas

**Lemma F.1** (Convergence of price to reference price): _Let \(\{\mathbf{p}^{t}\}_{t\geq 0}\) and \(\{\mathbf{r}^{t}\}_{t\geq 0}\) be the price path and reference path generated by Algorithm 1 with non-increasing step-sizes \(\{\eta^{t}\}_{t\geq 0}\) such that \(\lim_{t\to\infty}\eta^{t}=0\). Then, their difference \(\{\mathbf{r}^{t}-\mathbf{p}^{t}\}_{t\geq 0}\) converges to \(0\) as \(t\) goes to infinity._

Proof.: First, we recall that \(D_{i}^{t}=(b_{i}+c_{i})\cdot G_{i}(\mathbf{p}^{t},\mathbf{r}^{t})\), where \(G_{i}(\mathbf{p},\mathbf{r})\) is the scaled partial derivative defined in (25). Thus, it follows from Lemma F.5 that \(|D_{i}^{t}|\leq(b_{i}+c_{i})M_{G}\). Since \(\{\eta^{t}\}_{t\geq 0}\) is a non-increasing sequence with \(\lim_{t\to\infty}\eta^{t}=0\), for any constant \(\eta>0\), there exists \(T_{\eta}\in\mathbb{N}\) such that \(|\eta^{t}D_{i}^{t}|\leq\eta\) for every \(t\geq T_{\eta}\) and for every \(i\in\{H,L\}\). Therefore, it holds that

\[\left|p_{i}^{t+1}-p_{i}^{t}\right|=\left|\mathrm{Proj}_{\mathcal{P}}\left(p_{ i}^{t}+\eta^{t}D_{i}^{t}\right)-p_{i}^{t}\right|\leq\left|\eta^{t}D_{i}^{t} \right|\leq\eta,\quad\forall t\geq T_{\eta},\] (83)

where the first inequality is due to the property of the projection operator. Then, by the reference price update, we have for \(t\geq T_{\eta}\) and for \(i\in\{H,L\}\) that

\[\left|r_{i}^{t+1}-p_{i}^{t+1}\right| =\left|\alpha r_{i}^{t}+(1-\alpha)p_{i}^{t}-p_{i}^{t+1}\right|\] (84) \[=\left|\alpha\left(r_{i}^{t}-p_{i}^{t}\right)+\left(p_{i}^{t+1}-p _{i}^{t}\right)\right|\] \[\leq\alpha\left|r_{i}^{t}-p_{i}^{t}\right|+\left|p_{i}^{t+1}-p_{ i}^{t}\right|\] \[\leq\alpha\left|r_{i}^{t}-p_{i}^{t}\right|+\eta,\]

where the last line follows from the upper bound in Eq. (83). Applying Eq. (84) recursively from \(t\) to \(T_{\eta}\), we further derive that

\[\left|r_{i}^{t+1}-p_{i}^{t+1}\right| \leq\alpha^{t+1-T_{\eta}}\cdot\left|r_{i}^{T_{\eta}}-p_{i}^{T_{ \eta}}\right|+\eta\sum_{\tau=T_{\eta}}^{t}\alpha^{\tau-T_{\eta}}\] (85) \[\leq\alpha^{t+1-T_{\eta}}\cdot(\overline{p}-\underline{p})+\frac {\eta}{1-\alpha},\quad\forall i\in\{H,L\}.\]

Since \(\eta\) can be arbitrarily close to \(0\), we have that \(|r_{i}^{t}-p_{i}^{t}|\to 0\) as \(t\to\infty\), which completes the proof of the convergence. 

**Lemma F.2**: _Define the function \(\mathcal{G}(\mathbf{p})\) as_

\[\mathcal{G}(\mathbf{p}):=\mathrm{sign}(p_{H}^{\star\star}-p_{H})\cdot G_{H}( \mathbf{p},\mathbf{p})+\mathrm{sign}(p_{L}^{\star\star}-p_{L})\cdot G_{L}( \mathbf{p},\mathbf{p}),\] (86)

_where \(G_{i}(\mathbf{p},\mathbf{r})\) is the scaled partial derivative introduced in Eq. (25). Then, it always holds that \(\mathcal{G}(\mathbf{p})>0,\forall\mathbf{p}\in\mathcal{P}^{2}\backslash\{ \mathbf{p}^{\star\star}\}\), where \(\mathbf{p}^{\star\star}=(p_{H}^{\star\star},p_{L}^{\star\star})\) denotes the unique SNE, and the function \(\mathrm{sign}(\cdot)\) is defined in Eq. (27)._

_Furthermore, for every \(\epsilon>0\), there exists \(M_{\epsilon}>0\) such that \(\mathcal{G}(\mathbf{p})\geq M_{\epsilon}\) if \(\varepsilon(\mathbf{p})\geq\epsilon\), where \(\varepsilon(\mathbf{p})\) is the weighted \(\ell_{1}\)-distance function defined in Eq. (24)._

Proof.: Firstly, by the first-order condition at the SNE (see Eq. (16)), we have \(G_{H}(\mathbf{p}^{\star\star},\mathbf{p}^{\star\star})=G_{L}(\mathbf{p}^{\star \star},\mathbf{p}^{\star\star})=0\), which also implies \(\mathcal{G}(\mathbf{p}^{\star\star})=0\). Then, we recall the definition of four regions \(N_{1}\), \(N_{2}\), \(N_{3}\), and \(N_{4}\) in Eq. (28). We show that \(\mathcal{G}(\mathbf{p})>0\) when \(\mathbf{p}\) belongs to either one of the four regions.

1. When \(\mathbf{p}\in N_{1}\), i.e., \(p_{H}>p_{H}^{\star\star}\) and \(p_{L}\geq p_{L}^{\star\star}\), the function \(\mathcal{G}(\mathbf{p})\) becomes \[\mathcal{G}(\mathbf{p}) =-G_{H}(\mathbf{p},\mathbf{p})-G_{L}(\mathbf{p},\mathbf{p})\] \[=-\frac{1}{(b_{H}+c_{H})p_{H}}-\frac{1}{(b_{L}+c_{L})p_{L}}- \left(d_{H}(\mathbf{p},\mathbf{p})+d_{L}(\mathbf{p},\mathbf{p})\right)+2\] \[=-\frac{1}{(b_{H}+c_{H})p_{H}}-\frac{1}{(b_{L}+c_{L})p_{L}}+d_{0} (\mathbf{p},\mathbf{p})+1\] \[=-\frac{1}{(b_{H}+c_{H})p_{H}}-\frac{1}{(b_{L}+c_{L})p_{L}}+\frac {1}{1+\exp(a_{H}-b_{H}p_{H})+\exp(a_{L}-b_{L}p_{L})}+1,\] (87) where \(d_{0}(\mathbf{p},\mathbf{r})=1-d_{H}(\mathbf{p},\mathbf{r})-d_{L}(\mathbf{p},\mathbf{r})\) denotes the no purchase probability. We observe from Eq. (87) that \(\mathcal{G}(\mathbf{p})\) is strictly increasing in \(p_{H}\) and \(p_{L}\). Together with the fact that \(p_{H}\) and \(p_{L}\) are lowered bounded by \(p_{H}^{\star\star}\) and \(p_{L}^{\star\star}\), respectively, and \(\mathcal{G}(\mathbf{p}^{\star\star})=0\), we verify that \(\mathcal{G}(\mathbf{p})>0\) when \(\mathbf{p}\in N_{1}\). With the similar approach, we show that when \(\mathbf{p}\in N_{3}\), i.e., \(p_{H}<p_{H}^{\star\star}\) and \(p_{L}\leq p_{L}^{\star\star}\), it also follows that \(\mathcal{G}(\mathbf{p})>0\).
2. When \(\mathbf{p}\in N_{2}\), i.e., \(p_{H}\leq p_{H}^{\star\star}\) and \(p_{L}>p_{L}^{\star\star}\), the function \(\mathcal{G}(\mathbf{p})\) becomes \[\mathcal{G}(\mathbf{p}) =G_{H}(\mathbf{p},\mathbf{p})-G_{L}(\mathbf{p},\mathbf{p})\] (88) \[=\frac{1}{(b_{H}+c_{H})p_{H}}-\frac{1}{(b_{L}+c_{L})p_{L}}+d_{H}( \mathbf{p},\mathbf{p})-d_{L}(\mathbf{p},\mathbf{p})\] \[=\frac{1}{(b_{H}+c_{H})p_{H}}-\frac{1}{(b_{L}+c_{L})p_{L}}+\frac{ \exp(a_{H}-b_{H}p_{H})-\exp(a_{L}-b_{L}p_{L})}{1+\exp(a_{H}-b_{H}p_{H})+\exp(a_ {L}-b_{L}p_{L})}.\] By Eq. (88), we notice that \(\mathcal{G}(\mathbf{p})\) under region \(N_{2}\) is strictly decreasing in \(p_{H}\) and strictly increasing in \(p_{L}\). Meanwhile, since \(p_{H}\leq p_{H}^{\star\star}\), \(p_{L}>p_{L}^{\star\star}\), and \(\mathcal{G}(\mathbf{p}^{\star\star})=0\), it implies that \(\mathcal{G}(\mathbf{p})>0\) when \(\mathbf{p}\in N_{2}\). Moreover, by similar reasoning, we show that when \(\mathbf{p}\in N_{4}\), i.e., \(p_{H}\geq p_{H}^{\star\star}\) and \(p_{L}<p_{L}^{\star\star}\), the inequality \(\mathcal{G}(\mathbf{p})>0\) also holds.

Finally, we are left to establish the existence of \(M_{\epsilon}\). It suffices to show that

\[\min_{\varepsilon(\mathbf{p})=\epsilon_{1}}\mathcal{G}(\mathbf{p})>\min_{ \varepsilon(\mathbf{p})=\epsilon_{2}}\mathcal{G}(\mathbf{p}).\] (89)

for every \(\epsilon_{1}>\epsilon_{2}>0\). Suppose \(\mathbf{p}^{\epsilon_{1}}:=\arg\min_{\epsilon(\mathbf{p})=\epsilon_{1}} \mathcal{G}(\mathbf{p})\). Define \(\mathbf{p}^{\epsilon_{2}}:=(\epsilon_{2}/\epsilon_{1})\mathbf{p}^{\epsilon_{ 1}}+(1-\epsilon_{2}/\epsilon_{1})\mathbf{p}^{\star\star}\), which satisfies that \(\varepsilon(\mathbf{p}^{\epsilon_{2}})=\epsilon_{2}\). Then, we have that

\[\mathcal{G}(\mathbf{p}^{\epsilon_{2}}) =\operatorname{sign}(p_{H}^{\star\star}-p_{H}^{\epsilon_{2}})\cdot G _{H}(\mathbf{p}^{\epsilon_{2}},\mathbf{p}^{\epsilon_{2}})+\operatorname{sign} (p_{L}^{\star\star}-p_{L}^{\epsilon_{2}})\cdot G_{L}(\mathbf{p}^{\epsilon_{2}}, \mathbf{p}^{\epsilon_{2}})\] (90) \[\stackrel{{(\Delta_{1})}}{{=}}\operatorname{sign}\left( \frac{\epsilon_{2}}{\epsilon_{1}}(p_{H}^{\star\star}-p_{H}^{\epsilon_{1}}) \right)\cdot G_{H}(\mathbf{p}^{\epsilon_{2}},\mathbf{p}^{\epsilon_{2}})+ \operatorname{sign}\left(\frac{\epsilon_{2}}{\epsilon_{1}}(p_{L}^{\star\star}-p _{L}^{\epsilon_{1}})\right)\cdot G_{L}(\mathbf{p}^{\epsilon_{2}},\mathbf{p}^{ \epsilon_{2}})\] \[=\operatorname{sign}(p_{H}^{\star\star}-p_{H}^{\epsilon_{1}}) \cdot G_{H}(\mathbf{p}^{\epsilon_{2}},\mathbf{p}^{\epsilon_{2}})+ \operatorname{sign}(p_{L}^{\star\star}-p_{L}^{\epsilon_{1}})\cdot G_{L}( \mathbf{p}^{\epsilon_{2}},\mathbf{p}^{\epsilon_{2}})\] \[\stackrel{{(\Delta_{2})}}{{\leq}}\operatorname{sign}(p_{ H}^{\star\star}-p_{H}^{\epsilon_{1}})\cdot G_{H}(\mathbf{p}^{\epsilon_{1}}, \mathbf{p}^{\epsilon_{1}})+\operatorname{sign}(p_{L}^{\star\star}-p_{L}^{ \epsilon_{1}})\cdot G_{L}(\mathbf{p}^{\epsilon_{1}},\mathbf{p}^{\epsilon_{1}})= \mathcal{G}(\mathbf{p}^{\epsilon_{1}}),\]

where \((\Delta_{1})\) follows from substituting \(p_{i}^{\epsilon_{2}}\) in \(\operatorname{sign}(p_{i}^{\star\star}-p_{i}^{\epsilon_{2}})\) with \(p_{i}^{\epsilon_{2}}=(\epsilon_{2}/\epsilon_{1})p_{i}^{\epsilon_{1}}+(1-\epsilon_{ 2}/\epsilon_{1})p_{i}^{\star\star}\). To see why \((\Delta_{2})\) holds, recall that we have shown in Eq. (87) and Eq. (88) that when two prices are in the same region (see four regions defined in Eq. (28)), the price closer to \(\mathbf{p}^{\star\star}\) in terms of the metric \(\varepsilon(\cdot)\) has a greater value of \(\mathcal{G}(\mathbf{p})\). Since \(\mathbf{p}^{\epsilon_{1}}\) and \(\mathbf{p}^{\epsilon_{2}}\) are from the same region and \(\epsilon_{1}>\epsilon_{2}\), we conclude that \(\min_{\varepsilon(\mathbf{p})=\epsilon_{1}}\mathcal{G}(\mathbf{p})=\mathcal{G}( \mathbf{p}^{\epsilon_{1}})>\mathcal{G}(\mathbf{p}^{\epsilon_{2}})\geq\min_{ \varepsilon(\mathbf{p})=\epsilon_{2}}\mathcal{G}(\mathbf{p})\). 

**Lemma F.3**: _Define function \(\mathcal{H}(\mathbf{p})\) as follows_

\[\mathcal{H}(\mathbf{p}):=(b_{H}+c_{H})\cdot G_{H}(\mathbf{p},\mathbf{p})\cdot(p_{H}^ {\star\star}-p_{H})+(b_{L}+c_{L})\cdot G_{L}(\mathbf{p},\mathbf{p})\cdot(p_{L}^{ \star\star}-p_{L})\] (91)

_Then, there exist \(\gamma>0\) and a open set \(U_{\gamma}\ni\mathbf{p}^{\star\star}\) such that_

\[\mathcal{H}(\mathbf{p})\geq\gamma\cdot\|\mathbf{p}-\mathbf{p}^{\star\star}\|_{2 }^{2},\quad\forall\mathbf{p}\in U_{\gamma}.\] (92)

_Proof._ According to the partial derivatives in Eq. (98a) and Eq. (98b) from Lemma F.5, we have

\[\frac{\partial G_{i}(\mathbf{p},\mathbf{p})}{\partial p_{i}} =-\frac{1}{(b_{i}+c_{i})p_{i}^{2}}-b_{i}\cdot d_{i}(\mathbf{p}, \mathbf{p})\cdot\big{(}1-d_{i}(\mathbf{p},\mathbf{p})\big{)};\] (93) \[\frac{\partial G_{i}(\mathbf{p},\mathbf{p})}{\partial p_{-i}} =b_{-i}\Then, to compute the gradient \(\nabla\mathcal{H}(\mathbf{p})=[\partial\mathcal{H}(\mathbf{p})/\partial p_{H}, \partial\mathcal{H}(\mathbf{p})/\partial p_{L}]\), we utilize partial derivatives of \(G_{i}(\mathbf{p},\mathbf{p})\) in Eq. (93) and obtain the partial derivatives of \(\mathcal{H}(\mathbf{p})\) for \(i\in\{H,L\}\):

\[\frac{\partial\mathcal{H}(\mathbf{p})}{\partial p_{i}}= (b_{i}+c_{i})\left[\frac{\partial G_{i}(\mathbf{p},\mathbf{p})}{ \partial p_{i}}(p_{i}^{\star\star}-p_{i})-G_{i}(\mathbf{p},\mathbf{p})\right]+ (b_{-i}+c_{-i})(p_{-i}^{\star\star}-p_{-i})\frac{\partial G_{-i}(\mathbf{p}, \mathbf{p})}{\partial p_{i}}\] \[= -\frac{p_{i}^{\star\star}}{p_{i}^{2}}-(b_{i}+c_{i})\big{(}d_{i}( \mathbf{p},\mathbf{p})-1\big{)}-b_{i}(b_{i}+c_{i})\cdot d_{i}(\mathbf{p}, \mathbf{p})\cdot\big{(}1-d_{i}(\mathbf{p},\mathbf{p})\big{)}(p_{i}^{\star \star}-p_{i})\] \[+b_{i}(b_{-i}+c_{-i})\cdot d_{i}(\mathbf{p},\mathbf{p})\cdot d_{- i}(\mathbf{p},\mathbf{p})\cdot(p_{-i}^{\star\star}-p_{-i}).\] (94)

From the definition of \(G_{i}(\cdot,\cdot)\) in Eq. (31) and the system equations of first-order condition in Eq. (16), we have \(G_{i}(\mathbf{p}^{\star\star},\mathbf{p}^{\star\star})=1/\big{[}(b_{i}+c_{i})p _{i}^{\star\star}\big{]}+(d_{i}^{\star\star}-1)=0\), where \(d_{i}^{\star\star}:=d_{i}(\mathbf{p}^{\star\star},\mathbf{p}^{\star\star})\) denotes the market share of product \(i\) at the SNE. Thereby, it follows that \(\nabla\mathcal{H}(\mathbf{p}^{\star\star})=0\).

Next, the Hessian matrix \(\nabla^{2}\mathcal{H}(\mathbf{p})\) evaluated at \(\mathbf{p}^{\star\star}\) can be computed as

\[\nabla^{2}\mathcal{H}(\mathbf{p}^{\star\star})\] \[= \left[\begin{array}{cc}\frac{2p_{H}^{\star\star}}{(p_{H}^{ \star\star})^{3}}+2b_{H}(b_{H}+c_{H})\cdot d_{H}^{\star\star}\big{(}1-d_{H}^{ \star\star}\big{)},&-\big{[}b_{H}(b_{L}+c_{L})+b_{L}(b_{H}+c_{H})\big{]}\cdot d _{H}^{\star\star}d_{L}^{\star\star}\\ -\big{[}b_{H}(b_{L}+c_{L})+b_{L}(b_{H}+c_{H})\big{]}\cdot d_{H}^{\star\star}d_ {L}^{\star\star},&\frac{2p_{L}^{\star\star}}{(p_{L}^{\star\star})^{3}}+2b_{L}( b_{L}+c_{L})\cdot d_{L}^{\star\star}\big{(}1-d_{L}^{\star\star}\big{)} \end{array}\right]\] \[= \left[\begin{array}{cc}2(b_{H}+c_{H})\cdot\big{(}1-d_{H}^{ \star\star}\big{)}\cdot\big{[}(b_{H}+c_{H})-c_{H}d_{H}^{\star\star}\big{]},&- \big{[}b_{H}(b_{L}+c_{L})+b_{L}(b_{H}+c_{H})\big{]}\cdot d_{H}^{\star\star}d_ {L}^{\star\star}\\ -\big{[}b_{H}(b_{L}+c_{L})+b_{L}(b_{H}+c_{H})\big{]}\cdot d_{H}^{\star\star}d_ {L}^{\star\star},&2(b_{L}+c_{L})\cdot\big{(}1-d_{L}^{\star\star}\big{)}\cdot \big{[}(b_{L}+c_{L})-c_{L}d_{L}^{\star\star}\big{]}\end{array}\right].\]

Note that the last equality results again from substituting in the identity \(G_{i}(\mathbf{p}^{\star\star},\mathbf{p}^{\star\star})=1/\big{[}(b_{i}+c_{i}) \cdot p_{i}^{\star\star}\big{]}+(d_{i}^{\star\star}-1)=0\).

The diagonal entries of \(\nabla^{2}\mathcal{H}(\mathbf{p}^{\star\star})\) are clearly positive. For \(i\in\{H,L\}\), define \(k_{i}:=b_{i}/(b_{i}+c_{i})\in[0,1]\). Then, the determinant of \(\nabla^{2}\mathcal{H}(\mathbf{p}^{\star\star})\) can be computed as follows:

\[\det\left(\nabla^{2}\mathcal{H}(\mathbf{p}^{\star\star})\right)\] (95) \[=\] \[\quad-\left(\big{[}b_{H}(b_{L}+c_{L})+b_{L}(b_{H}+c_{H})\big{]} \cdot d_{H}^{\star\star}d_{L}^{\star\star}\right)^{2}\] \[=\] \[\quad\qquad\qquad\qquad\qquad\qquad\qquad\qquad-(k_{H}+k_{L})^{2 }\big{(}d_{H}^{\star\star}d_{L}^{\star\star}\big{)}^{2}\Big{)}\] \[\stackrel{{(\Delta_{1})}}{{\geq}}4(b_{H}+c_{H})^{2 }(b_{L}+c_{L})^{2}\cdot\Big{(}\big{(}1-d_{H}^{\star\star}\big{)}\big{(}1-d_{L} ^{\star\star}\big{)}\cdot\big{[}1-(1-k_{H})d_{H}^{\star\star}\big{]}\big{[}1-( 1-k_{L})d_{L}^{\star\star}\big{)}^{2}\Big{)}\] \[\stackrel{{(\Delta_{2})}}{{\geq}}4(b_{H}+c_{H})^{2 }(b_{L}+c_{L})^{2}\cdot d_{H}^{\star\star}d_{L}^{\star\star}\Big{(}\big{[}1-( 1-k_{H})d_{H}^{\star\star}\big{]}\big{[}1-(1-k_{L})d_{L}^{\star\star}\big{]}-d_ {H}^{\star\star}d_{L}^{\star\star}\Big{)}\] \[\stackrel{{(\Delta_{3})}}{{\geq}}4(b_{H}+c_{H})^{2 }(b_{L}+c_{L})^{2}\cdot d_{H}^{\star\star}d_{L}^{\star\star}\Big{[}\big{(}1-d_ {H}^{\star\star}\big{)}\big{(}1-d_{L}^{\star\star}\big{)}-d_{H}^{\star\star}d_ {L}^{\star\star}\Big{]}\] \[=\] \[\stackrel{{(\Delta_{4})}}{{>}}0,\]

where inequalities respectively result from the following facts \((\Delta_{1})\): \(k_{H}+k_{L}\leq 2\); \((\Delta_{2})\): \(1-d_{i}^{\star\star}>d_{i}^{\star\star}\) for \(i\in\{H,L\}\); \((\Delta_{3})\): \(1-k_{i}\leq 1\) for \(i\in\{H,L\}\); \((\Delta_{4})\): \(d_{H}^{\star\star}+d_{L}^{\star\star}<1\). Thus, we conclude that \(\nabla^{2}\mathcal{H}(\mathbf{p}^{\star\star})\) is positive definite.

By the continuity of \(\nabla^{2}\mathcal{H}(\mathbf{p})\), there exists some constant \(\gamma>0\) and a open set \(U_{\gamma}\ni\mathbf{p}^{\star\star}\) such that \(\nabla^{2}\mathcal{H}(\mathbf{p})\succeq 2\gamma I_{2}\), \(\forall\mathbf{p}\in U_{\gamma}\), where \(I_{2}\) is the \(2\times 2\) identity matrix. Using the second-order Taylor expansion at \(\mathbf{p}^{\star\star}\), for all \(\mathbf{p}\in U_{\gamma}\), there exists \(\widetilde{\mathbf{p}}\in U_{\gamma}\) such that

\[\mathcal{H}(\mathbf{p}) =\mathcal{H}(\mathbf{p}^{\star\star})+\nabla\mathcal{H}(\mathbf{ p}^{\star\star})\cdot\big{(}\mathbf{p}-\mathbf{p}^{\star\star}\big{)}+\frac{1}{2} \big{(}\mathbf{p}-\mathbf{p}^{\star\star}\big{)}^{\top}\cdot\nabla^{2}\mathcal{ H}(\widetilde{\mathbf{p}})\cdot\big{(}\mathbf{p}-\mathbf{p}^{\star\star}\big{)}\] (96) \[=\] \[\geq\] \[= \gamma\|\mathbf{p}-\mathbf{p}^{\star\star}\|_{2}^{2},\]

where the second equality arises from that \(\mathcal{H}(\mathbf{p}^{\star\star})=0\) and \(\nabla\mathcal{H}(\mathbf{p}^{\star\star})=0\). 

**Lemma F.4**: _For any product \(i\in\{H,L\}\), let_

\[\widehat{G}_{i}(\mathbf{p}):=\mathrm{sign}\left(p_{i}^{\star\star}-p_{i}\right) \cdot G_{i}\big{(}\mathbf{p},\mathbf{p}\big{)},\] (97)

_where \(G_{i}(\mathbf{p},\mathbf{r})\) is the scaled partial derivative defined in Eq. (25). Then, \(\widehat{G}_{i}(\mathbf{p})\) is always increasing as \(|p_{i}^{\star\star}-p_{i}|\) increases, and_

1. _when_ \(\mathbf{p}\in N_{1}\cup N_{3}\) _(see the definition in Eq. (_28_)),_ \(\widehat{G}_{i}(\mathbf{p})\) _is decreasing as_ \(|p_{-i}^{\star\star}-p_{-i}|\) _increases;_
2. _when_ \(\mathbf{p}\in N_{2}\cup N_{4}\)_,_ \(\widehat{G}_{i}(\mathbf{p})\) _is increasing as_ \(|p_{-i}^{\star\star}-p_{-i}|\) _increases._

_Proof._ Without loss of generality, consider the case that product \(i=H\) and product \(-i=L\).

Apparently, we have \(\mathrm{sign}\left(p_{H}^{\star\star}-p_{H}\right)\leq 0\) in \(N_{1}\cup N_{4}\), and \(\mathrm{sign}\left(p_{H}^{\star\star}-p_{H}\right)\geq 0\) in \(N_{2}\cup N_{3}\) by definitions (see Eq. (28)). On the other hand, by Eq. (98b) in Lemma F.5, it holds that \(\partial G_{H}\big{(}\mathbf{p},\mathbf{p}\big{)}/\partial p_{H}<0\) and \(\partial G_{H}\big{(}\mathbf{p},\mathbf{p}\big{)}/\partial p_{L}>0\), \(\forall\mathbf{p}\in\mathcal{P}^{2}\). Thus,

1. in \(N_{1}\cup N_{4}\), \(G_{H}\big{(}\mathbf{p},\mathbf{p}\big{)}\) is decreasing as \(|p_{H}^{\star\star}-p_{H}|\) increases; in \(N_{2}\cup N_{3}\), \(G_{H}\big{(}\mathbf{p},\mathbf{p}\big{)}\) is increasing as \(|p_{H}^{\star\star}-p_{H}|\) increases;2. in \(N_{1}\cup N_{2}\), \(G_{H}\big{(}\mathbf{p},\mathbf{p}\big{)}\) is increasing as \(|p_{L}^{\star\star}-p_{L}|\) increases; conversely, \(G_{H}\big{(}\mathbf{p},\mathbf{p}\big{)}\) is decreasing as \(|p_{L}^{\star\star}-p_{L}|\) increases in \(N_{3}\cup N_{4}\).

The final results directly follows by combining the above pieces together. 

**Lemma F.5**: _Let \(G_{i}(\mathbf{p},\mathbf{r})\) be the scaled partial derivative defined in Eq. (25), then partial derivatives of \(G_{i}(\mathbf{p},\mathbf{r})\) with respect to \(\mathbf{p}\) and \(\mathbf{r}\) are given as_

\[\frac{\partial G_{i}(\mathbf{p},\mathbf{r})}{\partial p_{i}} =-\frac{1}{(b_{i}+c_{i})p_{i}^{2}}-(b_{i}+c_{i})\cdot d_{i}( \mathbf{p},\mathbf{r})\cdot\big{(}1-d_{i}(\mathbf{p},\mathbf{r})\big{)};\] (98a) \[\frac{\partial G_{i}(\mathbf{p},\mathbf{r})}{\partial p_{-i}} =(b_{-i}+c_{-i})\cdot d_{i}(\mathbf{p},\mathbf{r})\cdot d_{-i}( \mathbf{p},\mathbf{r});\] (98b) \[\frac{\partial G_{i}(\mathbf{p},\mathbf{r})}{\partial r_{i}} =c_{i}\cdot d_{i}(\mathbf{p},\mathbf{r})\cdot\big{(}1-d_{i}( \mathbf{p},\mathbf{r})\big{)};\] (98c) \[\frac{\partial G_{i}(\mathbf{p},\mathbf{r})}{\partial r_{-i}} =-c_{-i}\cdot d_{i}(\mathbf{p},\mathbf{r})\cdot d_{-i}(\mathbf{p },\mathbf{r}).\] (98d)

_Meanwhile, \(G_{i}(\mathbf{p},\mathbf{r})\) and its gradient are bounded as follows_

\[\big{|}G_{i}(\mathbf{p},\mathbf{r})\big{|}\leq M_{G},\quad\big{\|}\nabla_{ \mathbf{r}}G_{i}(\mathbf{p},\mathbf{r})\big{\|}_{2}\leq\ell_{r},\quad\forall \mathbf{p},\mathbf{r}\in\mathcal{P}^{2}\text{ and }\forall i\in\{H,L\},\] (99)

_where the upper bound constant \(M_{G}\) and the Lipschitz constant \(\ell_{r}\) are defined as_

\[M_{G}:=\max\left\{\frac{1}{(b_{H}+c_{L})\underline{p}},\frac{1}{(b_{L}+c_{L}) \underline{p}}\right\}+1,\quad\ell_{r}:=\frac{1}{4}\sqrt{c_{H}^{2}+c_{L}^{2}}.\] (100)

_Proof._ We first verify the partial derivatives from Eq. (98a) to Eq. (98d):

\[\begin{split}\frac{\partial G_{i}(\mathbf{p},\mathbf{r})}{ \partial p_{i}}&=\frac{1}{(b_{i}+c_{i})p_{i}^{2}}+\frac{\partial d _{i}(\mathbf{p},\mathbf{r})}{\partial p_{i}}\\ &=\frac{1}{(b_{i}+c_{i})p_{i}^{2}}-\frac{(b_{i}+c_{i})\cdot\exp \big{(}u_{i}(p_{i},r_{i})\big{)}\cdot\Big{(}1+\exp\big{(}u_{-i}(p_{-i},r_{-i}) \big{)}\Big{)}}{\Big{(}1+\exp\big{(}u_{i}(p_{i},r_{i})\big{)}+\exp\big{(}u_{-i} (p_{-i},r_{-i})\big{)}\Big{)}^{2}}\\ &=\frac{1}{(b_{i}+c_{i})p_{i}^{2}}-(b_{i}+c_{i})\cdot d_{i}( \mathbf{p},\mathbf{r})\cdot\big{(}1-d_{i}(\mathbf{p},\mathbf{r})\big{)}.\end{split}\] (101)

\[\begin{split}\frac{\partial G_{i}(\mathbf{p},\mathbf{r})}{ \partial p_{-i}}&=\frac{\partial d_{i}(\mathbf{p},\mathbf{r})}{ \partial p_{-i}}\\ &=\frac{(b_{-i}+c_{-i})\cdot\exp\big{(}u_{i}(p_{i},r_{i})\big{)} \cdot\exp\big{(}u_{-i}(p_{-i},r_{-i})\big{)}}{\Big{(}1+\exp\big{(}u_{i}(p_{i}, r_{i})\big{)}+\exp\big{(}u_{-i}(p_{-i},r_{-i})\big{)}\Big{)}^{2}}\\ &=(b_{-i}+c_{-i})\cdot d_{i}(\mathbf{p},\mathbf{r})\cdot d_{-i}( \mathbf{p},\mathbf{r}).\end{split}\]

Then, the partial derivatives with respect to \(\mathbf{r}\), as shown in Eq. (98c) and Eq. (98d), can be similarly computed.

In the next part, we show that \(G_{i}(\mathbf{p},\mathbf{r})\) is bounded for \(\mathbf{p},\mathbf{r}\in\mathcal{P}^{2}\):

\[\begin{split}\big{|}G_{i}(\mathbf{p},\mathbf{r})\big{|}& =\bigg{|}\frac{1}{(b_{i}+c_{i})p_{i}}+d_{i}(\mathbf{p},\mathbf{r})-1\bigg{|} \\ &\leq\bigg{|}\frac{1}{(b_{i}+c_{i})p_{i}}\bigg{|}+\big{|}d_{i}( \mathbf{p},\mathbf{r})-1\big{|}\\ &\leq\frac{1}{(b_{i}+c_{i})\underline{p}}+1.\end{split}\] (102)

[MISSING_PAGE_EMPTY:37]