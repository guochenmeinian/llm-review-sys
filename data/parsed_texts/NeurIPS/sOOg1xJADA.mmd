# Projection-Free Online Convex Optimization via Efficient Newton Iterations

Khashayar Gatmiry

MIT

gatmiry@mit.com

&Zakaria Mhammedi

MIT

mhammedi@mit.edu

###### Abstract

This paper presents new projection-free algorithms for Online Convex Optimization (OCO) over a convex domain \(\mathcal{K}\subset\mathbb{R}^{d}\). Classical OCO algorithms (such as Online Gradient Descent) typically need to perform Euclidean projections onto the convex set \(\mathcal{K}\) to ensure feasibility of their iterates. Alternative algorithms, such as those based on the Frank-Wolfe method, swap potentially-expensive Euclidean projections onto \(\mathcal{K}\) for linear optimization over \(\mathcal{K}\). However, such algorithms have a sub-optimal regret in OCO compared to projection-based algorithms. In this paper, we look at a third type of algorithms that output approximate Newton iterates using a self-concordant barrier for the set of interest. The use of a self-concordant barrier automatically ensures feasibility without the need of projections. However, the computation of the Newton iterates requires a matrix inverse, which can still be expensive. As our main contribution, we show how the stability of the Newton iterates can be leveraged to only compute the inverse Hessian a vanishing fractions of the rounds, leading to a new efficient projection-free OCO algorithm with a state-of-the-art regret bound.

## 1 Introduction

We consider the Online Convex Optimization (OCO) problem over a convex set \(\mathcal{K}\subset\mathbb{R}^{d}\), in which a learner (algorithm) plays a game against an adaptive adversary for \(T\) rounds. At each round \(t\in[T]\), the learner picks \(w_{t}\in\mathcal{K}\) given knowledge of the history \(\mathcal{H}_{t-1}\coloneqq\{(\ell_{s},w_{s})\}_{s<t}\). Then, the adversary picks a convex loss function \(\ell_{t}:\mathcal{K}\to\mathbb{R}\) with the knowledge of \(\mathcal{H}_{t-1}\) and the iterate \(w_{t}\), and the learner suffers loss \(\ell_{t}(w_{t})\) and proceeds to the next round. The goal of the learner is to minimize the regret after \(T\) rounds:

\[\operatorname{Reg}_{T}(w)=\sum_{t=1}^{T}\ell_{t}(w_{t})-\sum_{t=1}^{T}\ell_{t} (w),\]

against any comparator \(w\in\mathcal{K}\). The aim of this paper is to design computationally-efficient (projection-free) algorithms for OCO that enjoy the optimal (up to log-factor in \(T\)) \(\widetilde{O}(\sqrt{T})\) regret.

The OCO framework captures many optimization settings relevant to machine learning applications. For example, OCO algorithms can be used in offline convex optimization as more computationally- and memory-efficient alternatives to interior-point and cutting plane methods whenever the dimension \(d\) is large [14; 16]. OCO algorithms are also often used in stochastic convex optimization, where the standard \(O(\sqrt{T})\) regret (achieved by, e.g. Online Gradient Descent) translates into the optimal \(O(1/\sqrt{T})\) rate1 via the classical online-to-batch conversion technique [3; 37]. It has been shown that OCO algorithms can also achieve state-of-the-art accelerated rates in both the offline and stochastic optimization settings despite being designed for the more general OCO framework [6; 28]. What ismore, it has recently been shown that even non-convex (stochastic) optimization can be reduced to online linear optimization (a special case of OCO), where it is then possible to recover the best-known convergence rates for the setting [7].

Given the prevalent use of OCO algorithms in machine learning applications, it is important to have computationally-efficient algorithms that scale well with the dimension \(d\) of the ambient space. However, most OCO algorithms fall short of being efficient because of the need of performing (Euclidean) projections onto \(\mathcal{K}\) (potentially at each iteration) to ensure that the iterates are feasible. These projections are often inefficient, especially in high-dimensional settings with complex feasible sets. Existing projection-free OCO algorithms address this computational challenge by swapping potentially-expensive Euclidean projections for often much cheaper linear optimization or separation over the feasible set \(\mathcal{K}\). However, existing projection-free algorithms have sub-optimal regret guarantees in terms of their dependence in \(T\), or have potentially unbounded "condition numbers" for the feasible set multiplying their regret guarantee.

Contributions.In this paper, we address these computational and performance challenges by revisiting an existing (but somewhat overlooked) type of projection-free OCO algorithms. Unlike existing algorithms, our proposed method does not require linear optimization or separation over the feasible set \(\mathcal{K}\). Instead, the algorithm, Barrier-Regularized Online Newton Step (BARONS),2 uses a self-concordant barrier \(\Phi\) for the set \(\mathcal{K}\) to always output iterates that are guaranteed to be within \(\mathcal{K}\); much like interior point methods for offline optimization. In particular, our algorithm outputs Newton iterates with respect to time-varying, translated versions of \(\Phi\). The main novelty of our work is in devising a new efficient way of computing the Newton iterates without having to evaluate the inverse of the Hessian of the barrier at every iteration, which can be computationally expensive in high-dimensional settings. Our algorithm only needs to compute a full inverse of the Hessian a vanishing \(O(1/\sqrt{T})\) fraction of the rounds. For the rest of the rounds, the computational cost is dominated by that of evaluating the gradient of the barrier \(\Phi\), which can be much cheaper than evaluating the inverse of its Hessian in many cases.

Footnote 2: We credit the name BARONS to [27] who used barrier-regularized Newton steps for the portfolio selection problem.

For the special case of a polytope with \(m\) constraints, we show that there is a choice of a barrier (e.g. the Lee-Sidford barrier) that when used within our algorithm, reduces the per-round computational cost to essentially \(\widetilde{O}(1)\) linear-system-solves of size \(m\times d\). We show that this is often cheaper than performing linear optimization over \(\mathcal{K}\), which other projection-free algorithms require. More importantly, our algorithm achieves a _dimension-free_\(\widetilde{O}(\sqrt{T})\) regret bound. This improves over the existing regret bounds of projection-free algorithms over polytopes. For example, among projection-free algorithms that achieve a \(O(\sqrt{T})\) regret, the algorithms by [28, 11, 26], which require a separation/membership Oracle for \(\mathcal{K}\), have a multiplicative \(\kappa=R/r\) factor multiplying their regret bounds, where \(r,R>0\) are such that \(\mathcal{B}(r)\subseteq\mathcal{K}\subseteq\mathcal{B}(R)\). The constant \(\kappa\), known as the _asphercity_[12], can in principle be arbitrarily large. Even after applying a potentially expensive pre-processing step, which would typically involve putting the set \(\mathcal{K}\) into (near-) isotropic position [9, 38], \(\kappa\) can still be as large as \(d\) in the worst-case, and so the regret bounds achieved by the algorithms of [28, 11, 26] can be of order \(O(d\sqrt{T})\); this is worse than ours by a \(d\) factor. Other projection-free algorithms based on the Frank-Wolfe method, e.g. those in [10, 35, 19], also have multiplicative condition numbers that are even less benign that the asphercity \(\kappa\). In fact, the condition numbers in the regret bounds for polytopes appearing in, e.g. [10], can in principle be arbitrarily large regardless of any pre-processing.

Finally, another advantage of our algorithm is that it can guarantee a sublinear regret even for non-Lipschitz losses (i.e. where the norm of the sub-gradients may be unbounded). In particular, we show that the general guarantee of BARONS implies a \(\widetilde{O}(\sqrt{dT})\) regret bound for the portfolio selection problem [5] and a problem of linear prediction with log-loss [36], all while keeping the per-round computational cost under \(\widetilde{O}(d^{2})\), when \(T\geq d\). The losses in both of these problems are neither bounded or Lispchitz.

Related works.In the past decade, many projection-free OCO algorithms have been developed to address the computational shortcoming of their projection-based counter parts [14, 16, 15, 18, 28, 11]. Most projection-free algorithms are based on the Frank-Wolfe method and perform linear optimization (typically once per round) over \(\mathcal{K}\) instead of Euclidean projection. Under no additional assumptionsother than convexity and lipschitzness of the losses, the best-known regret bound for such algorithms scales as \(O(T^{3/4})\)[15]. While this bound is still sublinear in \(T\) and has no dependence in the dimension \(d\), it is sub-optimal compared to the \(O(\sqrt{T})\) regret bound achievable with projection-based algorithms. In the recent years, there have been improvements to this bound under additional assumptions such as when the functions are smooth and/or strongly convex [15; 18], or when the convex set \(\mathcal{K}\) is smooth and/or strongly convex [1; 23; 29; 24]. For the case where \(\mathcal{K}\) is a polytope, [10] presented a linear-optimization-based algorithm that enjoys a \(O(\mu\sqrt{dT})\) regret bound, where \(\mu\) is a conditioning number for the set \(\mathcal{K}\). Unfortunately, \(\mu\) can be large for many sets of interests as it essentially scales inversely with the minimum distance between the vertices of \(\mathcal{K}\). In this work, we achieve a _dimension-free_\(\widetilde{O}(\sqrt{T})\) regret bound without the \(\mu\) factor.

More recently a new type of projection-free algorithms have emerged which use membership/separation oracle calls instead of linear optimization [28; 11; 24; 26]. From a computational perspective, separation-based and linear optimization-based algorithms are not really comparable, since there are sets over which separation is cheaper than linear optimization, and vice-versa. On the regret side, separation-based algorithms have been show to achieve a \(O(\kappa\sqrt{T})\) regret bound, where \(\kappa\) is the asphercity of the set \(\mathcal{K}\). Separation-based algorithms are simple, often easy to analyze, and achieve the optimal-in-\(T\) regret bound, unlike linear optimization-based algorithms. However, the multiplicative factor \(\kappa\) in their regret bounds means that a pre-conditioning step may be required to ensure it is appropriately bounded. This precondition step would involve putting the set into (near-) isotropic position [9]; an operation, that can cost \(\widetilde{O}(d^{4})\) arithmetic operations [38]; and even after such a pre-processing step, \(\kappa\) can still be as large as \(d\) in the worst-case. Our algorithm has the benefit of not requiring any pre-processing step.

A third type of algorithms avoid projections by outputting Newton iterates that are guaranteed to be feasible thanks to the use of a self-concordant barrier. The first such algorithm in the context of online learning was introduced by [2]. They presented a general recipe for using self-concordant barriers with Newton steps in online linear optimization. However, their approach falls short of being computationally-efficient as their algorithm needs to compute the inverse of the Hessian of the barrier at every iteration. Inspired by the work of [2], [31] used damped Newton steps with quadratic terms added to the barrier to design an efficient algorithm for the classical portfolio selection problem. Closer to our work is that of [30] who used a similar barrier for designing an algorithm for exp-concave optimization that can be viewed as a computationally-efficient version of the Online Newton Step [13]. Similar to our work, [30] also leverage the stability of the Newton iterates to avoid computing the inverse of the Hessian of the barrier at every step. However, their approach and analysis, which are tailored to the exp-concave setting do not necessarily lead to improved regret bounds in the general OCO setting we consider. In particular, their algorithm does not lead to a \(O(\sqrt{T})\) regret bound over polytopes.

Finally, for our application to polytopes, we make use of recent tools and techniques developed for solving linear programs efficiently. In particular, we make use of the Lee-Sidford barrier [20; 21; 22], which can be computed efficiently and, when used to compute Newton iterates, leads to the state-of-the-art \(\widetilde{O}(\sqrt{d})\) iteration upper-bound for solving a linear program. For the OCO setting, we show that using the Lee-Sidford barrier within our algorithm leads to a \(\widetilde{O}(\sqrt{T})\) regret bound. We also note that ideas similar to the ones we use to avoid computing the inverse of the Hessian of the barrier at every round were used to amortize computations in the context of solving linear programs (see e.g. [4; 39; 40]).

Outline.In section 2, we present our notation and relevant definitions. In Section 3, we present our algorithm and guarantees. In Section 4, we apply our results to the case of a polytope. All the proof are differed to the appendix.

## 2 Preliminaries

Throughout the paper, we let \(\mathcal{K}\) be a closed convex subset of \(\mathbb{R}^{d}\). We denote by \(\|\cdot\|\) the Euclidean norm and by \(\mathcal{B}(R)\subset\mathbb{R}^{d}\) the Euclidean ball of radius \(R>0\). We let \(\operatorname{int}\mathcal{K}\) denote the interior of \(\mathcal{K}\).

Our main algorithm, which can be viewed as an "online" counter-part to the Newton iterations [33], uses a self-concordant barrier over the set of interest to avoid the need of performing Euclidean projections onto \(\mathcal{K}\). Next, we present the definition of a self-concordant barrier.

Self-concordant barriers.For the rest of this section, we let \(\mathcal{K}\) be a convex compact set with non-empty interior \(\operatorname{int}\mathcal{K}\). For a twice [resp. thrice] differentiable function, we let \(\nabla^{2}f(\bm{u})\) [resp. \(\nabla^{3}f(\bm{u})\)] be the Hessian [resp. third derivative tensor] of \(f\) at \(\bm{u}\).

**Definition 1** (Self-concordant function).: _A convex function \(f\colon\operatorname{int}\mathcal{K}\to\mathbb{R}\) is called self-concordant with constant \(M_{f}\geq 0\), if \(f\) is \(C^{3}\) and satisfies_

* \(f(x_{k})\to+\infty\) _for_ \(x_{k}\to x\in\partial\mathcal{K}\)_; and_
* _For all_ \(x\in\operatorname{int}\mathcal{K}\) _and_ \(u\in\mathbb{R}^{d}\)_,_ \(|\nabla^{3}f(x)[u,u,u]|\leq 2M_{f}\|u\|_{\nabla^{2}f(x)}^{3}\)_._

**Definition 2** (Self-concordant barrier).: _For \(M_{f},\nu\geq 0\), we say that \(f\colon\operatorname{int}\mathcal{K}\to\mathbb{R}\) is a \((M_{f},\nu)\)-self-concordant barrier for \(\mathcal{K}\) if \(f\) is a self-concordant function over \(\mathcal{K}\) with constant \(M_{f}\) and_

\[\forall w\in\operatorname{int}\mathcal{K},\quad\nabla f(w)^{\top}\nabla^{-2}f (w)\nabla f(w)\leq\nu.\]

Computational Oracles.We will assume that our algorithm has access to a self-concordant function over the set \(\mathcal{K}\) through the following gradient and Hessian Oracles.

**Definition 3** (Gradient Oracle).: _Given a point \(w\in\operatorname{int}\mathcal{K}\) and a tolerance \(\varepsilon>0\), the gradient Oracle \(\mathcal{O}_{\varepsilon}^{\mathsf{grad}}(\Phi)\) returns an \(\varepsilon\)-approximate vector \(\widehat{\nabla}_{w}\) of the gradient \(\nabla\Phi(w)\) in the dual local norm of the Hessian:_

\[\left\|\widehat{\nabla}_{w}-\nabla\Phi(w)\right\|_{\nabla^{-2}\Phi(w)}\leq\varepsilon.\]

_We denote by \(\mathcal{O}_{\varepsilon}^{\mathsf{grad}}(\Phi)\) the computational cost of one call to \(\mathcal{O}_{\varepsilon}^{\mathsf{grad}}(\Phi)\)._

When clear from the context, we will simply write \(\mathcal{O}_{\varepsilon}^{\mathsf{grad}}\) and \(\mathcal{O}_{\varepsilon}^{\mathsf{grad}}\) for \(\mathcal{O}_{\varepsilon}^{\mathsf{grad}}(\Phi)\) and \(\mathcal{O}_{\varepsilon}^{\mathsf{grad}}(\Phi)\), respectively.

**Definition 4** (Hessian Oracle).: _Given a point \(w\in\operatorname{int}\mathcal{K}\) and a tolerance \(\varepsilon>0\), the Hessian Oracle \(\mathcal{O}_{\varepsilon}^{\mathsf{hess}}(\Phi)\) returns a matrix \(H\) and its inverse \(H^{-1}\) which are \(1\pm\varepsilon\) spectral approximations of the Hessian and inverse Hessian of \(\Phi\) at \(w\):_

\[(1-\varepsilon)\nabla^{2}\Phi(w)\leq H\leq(1+\varepsilon)\nabla^{2}\Phi(w) \quad\text{and}\quad(1-\varepsilon)\nabla^{-2}\Phi(w)\leq H^{-1}\leq(1+ \varepsilon)\nabla^{-2}\Phi(w).\]

_We denote by \(\mathcal{O}_{\varepsilon}^{\mathsf{hess}}(\Phi)\) the computational cost of one call to \(\mathcal{O}_{\varepsilon}^{\mathsf{hess}}(\Phi)\)._

When clear from the context, we will simply write \(\mathcal{O}_{\varepsilon}^{\mathsf{hess}}\) and \(\mathcal{O}_{\varepsilon}^{\mathsf{hess}}\) for \(\mathcal{O}_{\varepsilon}^{\mathsf{hess}}(\Phi)\) and \(\mathcal{O}_{\varepsilon}^{\mathsf{hess}}(\Phi)\), respectively.

Additional notation.We use the notation \(f\lesssim g\) to mean \(f\leq Cg\) for some universal constant \(C>0\). We also write \(f\leq\widetilde{O}g\) to mean \(f\leq\operatorname{polylog}(T,d)\cdot g\). We let \(\nabla^{-2}\coloneqq(\nabla^{2})^{-1}\) and \(\nabla^{-1/2}\) refer to the inverse of the Hessian and the inverse of the square root of the Hessian, respectively.

## 3 Algorithm and Regret Guarantees

In this section, we construct a projection-free algorithm for Online Convex Optimization. The algorithm in question (Alg. 1) outputs approximate Newton iterates with respect to "potential functions" \((\Phi_{t})\) that take the following form:

\[\Phi_{t}(w)\coloneqq\Phi(w)+w^{\top}\sum_{s=1}^{t-1}g_{s},\]

where \((g_{s}\in\partial\ell_{s}(w_{s}))\) are the sub-gradients of the losses \((\ell_{s})\) at the iterates \((w_{s})\) of Algorithm 1, and \(\Phi\) is a self-concordant function over \(\mathcal{K}\). Algorithm 1 uses the the approximate gradient and Hessian Oracles of \(\Phi\) (see 2) to output iterates \((w_{t})\) approximate Newton iterates in the following sense:

\[\forall t\in[T],\quad w_{t+1}\approx w_{t}-\nabla^{-2}\Phi_{t+1}(w_{t})\nabla \Phi_{t+1}(w_{t}).\] (1)

As is by now somewhat standard in the analyses of online Newton iterates of the form in (1), we will bound the regret of Algorithm 1 by showing that:* The iterates \((w_{t})\) are close (in the norm induced by the Hessian \(\nabla^{2}\Phi(w_{t})\)) to the FTRL iterates, which are given by \[w_{t}^{*}\in\operatorname*{argmin}_{w\in\mathcal{K}}\Phi_{t}(w).\] (2)
* The regret of FTRL is bounded by \(O(\sqrt{T})\).

Our main contribution is an algorithm that outputs iterates \((w_{t})\) that satisfy the first bullet point (i.e. iterates that satisfy (1)) while only calling a Hessian Oracle (which is potentially computationally expensive) a \(O(1/\sqrt{T})\) fraction of the rounds after \(T\) rounds. As we show in Section 4, for the case where \(\mathcal{K}\) is a polytope with \(m\in\mathbb{N}\) constraints, the algorithm achieves a \(\widetilde{O}(\sqrt{T})\) regret bound, where the per-iteration computational cost essentially reduces to a linear-system-solve involving a \(d\times m\) matrix. Among existing OCO algorithms that achieve a \(\widetilde{O}(\sqrt{T})\) regret bound, none can achieve this computational complexity for general polytopes with \(m\) constraints (see Section 4 for more details).

### Efficient Computation of the Newton Iterates with Barons

The key feature of BARONS (Algorithm 1) is that is uses an amortized computation of the Hessians. Namely, BARONS computes the inverse of the Hessian of the barrier \(\Phi\) only for a small fractions of the iterates \((w_{t})\). Henceforth, we refer to the iterates where the algorithm computes the full inverse of the Hessian as _landmark iterates_; these are the iterates \((u_{t})\) in Lines 13 and 16 of Algorithm 1. The idea behind this is that for a sufficiently curved3 barrier \(\Phi\), the Newton iterates with respect to \(\Phi\) are stable enough that it suffices to compute the inverse of the Hessian of \(\Phi\) at the closest landmark iterate. For example, this is what was done in [30] to design an efficient algorithm for exp-concave optimization.

Footnote 3: Informally, the “curvature” of a convex function is high when the rate of change of its gradients is high.

Unlike the setting of [30], where it is possible to add quadratic terms to the barrier for additional stability, in our setting we cannot do that without sacrificing performance in terms of regret. Without the quadratic terms, the Newton iterates are not stable enough for our desired guarantee. Instead of adding regularization terms, BARONS takes \(\widetilde{O}(1)\) Newton steps per round to get "closer" to the Newton iterate with the true Hessian matrix. This simple approach is key to the success of our approach.

In the next subsection, we give a generic guarantee for BARONS.

### Generic Regret Guarantee of Barons

In this subsection, we present a general regret and computational guarantee for BARONS under minimal assumptions on the sequence of losses and without turning the "step size" \(\eta\). In the next subsection, we will instantiate the regret guarantee when additional assumptions on the sequence of losses are available. We now state the main guarantee of BARONS (the proof in Appendix C.1).

**Theorem 5** (Master theorem).: _Let \(\Phi\) be a self-concordant function over \(\mathcal{K}\) with constant \(M_{\Phi}>0\), and let \(b,\eta,\varepsilon,\alpha>0\) and \(m_{\mathtt{Newton}}\in\mathbb{N}\) be such that \(\eta\leq\frac{1}{10000M_{\Phi}}\), \(\varepsilon\leq\frac{1}{20000M_{\Phi}}\), \(\alpha=0.001\), and \(m_{\mathtt{Newton}}\coloneqq\Theta(\log\frac{1}{\varepsilon M_{\Phi}})\). Further, let \((w_{t})\) be the iterates of Algorithm 1 with input (\(\eta\), \(\varepsilon\), \(\alpha\), \(m_{\mathtt{Newton}}\)) and suppose that the corresponding sub-gradients \((g_{t})\) satisfy \(\|g_{t}\|_{\nabla^{-2}\Phi(w_{t})}\leq b\), for all \(t\geq 1\). Then, the regret of Algorithm 1 is bounded as:_

\[\sum_{t=1}^{T}(\ell_{t}(w_{t})-\ell_{t}(w))\lesssim\frac{1}{\eta}\Phi(w)\ +\eta\sum_{t=1}^{T}\big{\|}g_{t}\big{\|}_{\nabla^{-2}\Phi(w_{t})}^{2}+ \varepsilon\sum_{t=1}^{T}\big{\|}g_{t}\big{\|}_{\nabla^{-2}\Phi(w_{t})},\ \ \ \forall w\in\operatorname{ int}\mathcal{K}.\] (3)

_Furthermore, the computational cost of the algorithm is bounded by_

\[O\left((\mathcal{C}_{\varepsilon}^{\mathtt{grad}}+d^{2})\cdot T\cdot\log\frac {1}{\varepsilon M_{\Phi}}+\mathcal{C}_{\alpha}^{\mathtt{hess}}\cdot\left(M_{ \Phi}T\varepsilon+M_{\Phi}\sum_{t=1}^{T}\eta\|g_{t}\|_{\nabla^{-2}\Phi(w_{t})} \right)\right).\]

Theorem 5 essentially shows that it is possible to achieve the same regret as FTRL, while only computing the inverse of the Hessian of \(\Phi\) at most \(\widetilde{O}(M_{\Phi}T\eta)\) number of times.

### Regret Guarantee Under Local and Euclidean Norm Bounds on the Sub-Gradients

We now instantiate the guarantee in Theorem 5 with a \((M_{\Phi},\nu)\)-self-concordant barrier \(\Phi\) for the set \(\mathcal{K}\), with respect to which the local norms of the sub-gradients are bounded; that is, when \(\left\|g_{t}\right\|_{\nabla^{-2}\Phi(w_{t})}\leq b\). We note that the regret bound in (36) has an additive \(\Phi(w)\) which may be unbounded near the boundary of \(\mathcal{K}\). However, it is still possible to compete against comparators in \(\operatorname{int}\mathcal{K}\) by making additional assumptions on the range of the losses [27; 32]. We discuss some of these assumptions in the sequel. For the next theorem, we will state the regret bound of BARONS relative to comparators in the restricted set:

\[\mathcal{K}_{c}\coloneqq(1-c)\mathcal{K}\oplus\{cw^{*}\},\] (4)

where \(\oplus\) denotes the Minkowski sum, \(w^{*}\in\operatorname{argmin}_{w\in\mathcal{K}}\Phi(w)\), and \(c\in(0,1)\) is a parameter.

With this, we now state a regret bound for BARONS when the sub-gradients of the losses have bounded local norms. The proof of the next theorem is in Appendix C.2.

**Theorem 6** (Local norm bound).: _Let \(\Phi\) be an \((M_{\Phi},\nu)\)-self-concordant barrier for \(\mathcal{K}\) and let \(c\in(0,1),b>0\). Further, suppose that for all \(t\in[T]\), \(\left\|g_{t}\right\|_{\nabla^{-2}\Phi(w_{t})}\leq b\), where \((w_{t})\) are the iterates of BARONS with input parameters \(\left(\eta,\varepsilon,\alpha,m_{\mathtt{Newton}}\right)\) such that_

\[\eta\coloneqq\sqrt{\frac{\nu\log c}{b^{2}T}},\quad\varepsilon\coloneqq\sqrt{ \frac{\nu}{T}},\quad\alpha\coloneqq 0.001,\quad\text{and}\quad m_{\mathtt{Newton}} \coloneqq\Theta\left(\log\frac{1}{\varepsilon M_{\Phi}}\right).\] (5)

_For \(T\geq 1\) large enough such that \(\eta\leq\frac{1}{1000bhM_{\Phi}}\), \(\varepsilon\leq\frac{1}{20000M_{\Phi}}\), the regret of BARONS is bounded as_

\[\operatorname{Reg}_{T}^{\mathtt{BARONS}}(w)\lesssim b\sqrt{\nu T\log c},\quad \forall w\in\mathcal{K}_{c},\] (6)

_where \(\mathcal{K}_{c}\subset\mathcal{K}\) is as in (4). Further, the computational complexity of BARONS in this case is bounded by_

\[O\left(\left(\mathcal{C}_{\varepsilon}^{\mathtt{grad}}+d^{2}\right)\cdot T \cdot\log\frac{T}{\nu M_{\Phi}}+\mathcal{C}_{\alpha}^{\mathtt{hess}}\cdot M_{ \Phi}\sqrt{T\nu\log c}\right).\]

**Remark 1**.: _The regret bound in Theorem 6 is stated with respect to comparators in the restricted set \(\mathcal{K}_{c}\) defined in (4). It is possible to extend this guarantee to all comparators in \(\operatorname{int}\mathcal{K}\) under an additional assumption on the range of the losses. For example, if for \(w^{\star}\in\operatorname{argmin}_{w\in\mathcal{K}}\Phi(w)\), we have_

\[\sup_{w\in\operatorname{int}\mathcal{K},t\in[T]}\ell_{t}\left( \left(1-\frac{1}{T}\right)\cdot w+\frac{1}{T}\cdot w^{\star}\right)-\ell(w) \leq O\left(\frac{1}{\sqrt{T}}\right),\] (7)

_then the regret guarantee in (6) can be extended to all comparators in \(\operatorname{int}\mathcal{K}\) up to an additive \(O(\sqrt{T})\) term (see Lemma 7 in the appendix). In this case, the \(\log c\) term in the computational complexity need be replaced by \(\log T\). We note that the condition in (7) does not require a uniform bound on the losses. Instead, it only restrict the rate of growth of the losses \((\ell_{t}(w))\) as \(w\) approaches the boundary of \(\mathcal{K}\). As we show in the sequel (SS4.2), (7) is satisfied for some popular losses which are not Lipschitz._

We now instantiate the guarantee in Theorem 5 when the sub-gradients are bounded in Euclidean norm (instead of local norm); that is, we assume that for all \(t\in[T]\), \(\|g_{t}\|\leq G\) for some \(G>0\). We note that this assumption implies (7), and we will be able to bound the regret against all comparators in \(\operatorname{int}\mathcal{K}\) as alluded to in Remark 1. The proof of the next theorem is in Appendix C.3).

**Theorem 7** (Euclidean norm bound).: _Let \(\Psi\) be an \((M_{\Psi},\nu)\) self-concordant barrier for \(\mathcal{K}\) and let \(\Phi(\cdot)\coloneqq\Psi(\cdot)+\frac{\nu}{2R^{2}}\|\cdot\|^{2}\). Further, let \(G,R>0\) and suppose that \(\mathcal{K}\subseteq\mathcal{B}(R)\) and for all \(t\in[T]\), \(\|g_{t}\|\leq G\), where \(g_{t}\in\partial\ell_{t}(w_{t})\) and \((w_{t})\) are the iterates of BARONS with input parameters \((\eta,\varepsilon,\alpha,m_{\mathtt{Newton}})\) such that_

\[\eta\coloneqq\frac{\nu}{RG}\sqrt{\frac{\log T+1}{T}},\quad \varepsilon\coloneqq\sqrt{\frac{\nu}{T}},\quad\alpha\coloneqq 0.001,\quad\text{and}\quad m_{\mathtt{Newton}} \coloneqq\Theta\left(\log\frac{1}{\varepsilon M_{\Psi}}\right).\] (8)

_For \(T\geq 1\) large enough such that \(\eta\leq\frac{1}{1000GM\nu}\), \(\varepsilon\leq\frac{1}{20000M_{\Psi}}\), the regret of BARONS is bounded as_

\[\operatorname{Re}_{T}^{\mathtt{BARONS}}(w)\lesssim RG\sqrt{T\log T },\quad\forall w\in\operatorname{int}\mathcal{K}.\] (9)

_Further, the computational complexity of BARONS in this case is bounded by_

\[O\left(\left(\mathcal{C}_{\varepsilon}^{\mathtt{grad}}(\Psi)+d ^{2}\right)\cdot T\cdot\log\frac{T}{\nu M_{\Psi}}+\mathcal{C}_{\alpha}^{ \mathtt{hess}}(\Psi)\cdot M_{\Psi}\sqrt{T\nu\log T}\right).\]

## 4 Application to Polytopes Using the Lee-Sidford Barrier

In this section, we assume that the set \(\mathcal{K}\) is a polytope in \(\mathbb{R}^{d}\) specified by \(m\) linear constraints:

\[\mathcal{K}=\{w\in\mathbb{R}^{d}\mid\ \forall i\in[m],\ a_{i}^{\top}w\geq b_{i}^{ \prime}\},\] (10)

and we construct efficient gradient and Hessian Oracles for a self-concordant barrier for \(\mathcal{K}\). This will then allow us to instantiate the guarantees of BARONS in Section 3 and provide explicit and state-of-the-art bounds on the regret of BARONS.

We will assume without loss of generality that \(\|a_{i}\|=1\), for all \(i\in[m]\), and let \(A\coloneqq(a_{1},\ldots,a_{m})^{\top}\in\mathbb{R}^{m\times d}\) denote the _constraint_ matrix of the set \(\mathcal{K}\). For the rest of this section, it will be convenient to define the "slack" variables \(s_{w,i}=a_{i}^{\top}w-b_{i}^{\prime}\), for \(i\in[m]\). Here, \(s_{w,i}\) essentially represents the distance of \(w\) to the \(i\)th facet of the polytope \(\mathcal{K}\). Further, we let \(S_{w}\coloneqq\operatorname{diag}(s_{w})\) be the diagonal matrix whose \(i\)th diagonal entry is \(s_{w,i}\).

The \(\mathtt{LS}\) barrier.To perform Online Convex Optimization over \(\mathcal{K}\), we pick the regularizer \(\Phi\) of BARONS to be the Lee-Sidford (LS) barrier \(\Phi^{\mathtt{LS}}\)[22] with parameter \(p>0\), which is defined as

\[\Phi^{\mathtt{LS}}(v)=\min_{v\in\mathbb{R}^{m}_{v>0}}-\log\det(A^{ \top}S_{w}VS_{w}A)+\frac{1}{1+p^{-1}}\operatorname{tr}(V^{1+1/p}),\]

where \(V=\operatorname{diag}(v)\). One way to think of the \(\mathtt{LS}\) barrier is as a weighted log-barrier. As we will discuss in the sequel, this choice will confer computational and performance (in terms of regret) advantages over the standard log-barrier.

Self-concordance of the LS barrier.According to [8, Theorem 30], the LS barrier with the choice \(p=O(\log(m))\) is a self-concordant function with parameter \(M_{\Phi^{\text{LS}}}\) satisfying

\[M_{\Phi^{\text{LS}}}=O(\log(m)^{2/5})=\widetilde{O}(1),\]

The other favorable property of this barrier is that its Newton decrement at any point \(w\in\mathcal{K}\) is of order \(\widetilde{O}(\sqrt{d})\); that is,

\[\|\nabla\Phi^{\text{LS}}(w)\|_{\nabla^{-2}\Phi^{\text{LS}}(w)}= \widetilde{O}(\sqrt{d}).\] (11)

Therefore, \(\Phi^{\text{LS}}\) is a \((\widetilde{O}(1),\widetilde{O}(d))\)-self-concordant barrier. For the log-barrier, the right-hand side of (11) would be \(\sqrt{m}\).

Cost of gradient and Hessian Oracles.We consider the computational complexities of gradient and Hessian Oracles for \(\Phi^{\text{LS}}\). By [22], we have that for \(\varepsilon>0\),

\[\mathcal{C}^{\text{grad}}_{\varepsilon}(\Phi^{\text{LS}})\leq \widetilde{O}\big{(}\mathcal{C}^{\text{sys}}\cdot\log(1/\varepsilon)\big{)}, \quad\text{and}\quad\mathcal{C}^{\text{hess}}_{\varepsilon}(\Phi^{\text{LS}}) \leq\widetilde{O}\big{(}\mathcal{C}^{\text{sys}}\sqrt{d}\cdot\log(1/ \varepsilon)\big{)},\]

where \(\mathcal{C}^{\text{sys}}\) is the computational cost of solving a linear system of the form \(A^{\top}\mathrm{diag}(v)Ax=y\), for vectors \(v\in\mathbb{R}_{\geq 0}^{d}\) and \(y\in\mathbb{R}^{d}\); we recall that \(A=(a_{1},\ldots,a_{m})^{\top}\) is the constraint matrix for \(\mathcal{K}\). In the worst-case, such a linear system can be solved with cost bounded as

\[\mathcal{C}^{\text{sys}}\leq O(md^{\omega-1}),\] (12)

where \(\omega\) is the exponent of matrix multiplication, and \(m\) is the number of constraints of \(\mathcal{K}\). However, as we show in the sequel, \(\mathcal{C}^{\text{sys}}\) can be much smaller in many practical applications.

With this, we immediately obtain the following corollary for the regret and run-time of BARONS under local norm and Euclidean norm bounds on the sub-gradients.

**Corollary 1** (OCO over a polytope with LS barrier).: _Let \(c\in(0,1),G,R,b>0\), and suppose \(\mathcal{K}\) is given by (10) and that \(\Phi^{\text{LS}}\) is the corresponding LS barrier. Further, let \((w_{t})\) be the iterates of BARONS, and let \(\mathcal{K}_{c}\) be the restricted version of \(\mathcal{K}\) defined in (4). Then, the following holds:_

* _Local norm bound:_ _If_ \(\|g_{t}\|_{\nabla^{-2}\Phi(w_{t})}\leq b\)_, for all_ \(t\geq 1\)_, and the parameters_ \((\eta,\varepsilon,\alpha,m_{\texttt{Newton}})\) _of_ BARONS _are set as in Theorem_ 6 _with_ \(\Phi=\Phi^{\text{LS}}\) _and_ \((M_{\Phi},\nu)=(\widetilde{O}(1),\widetilde{O}(d))\)_, then for_ \(T\) _large enough (as specified in Theorem_ 6_), the regret of_ BARONS _is bounded by_ \[\mathrm{Reg}_{T}^{\texttt{BARONS}}(w)\lesssim b\sqrt{dT\log c}, \quad\forall w\in\mathcal{K}_{c}.\] (13)
* _Euclidean norm bound:_ _If_ \(\mathcal{K}\subseteq\mathcal{B}(R)\) _and_ \(\|g_{t}\|\leq G\)_, for all_ \(t\geq 1\)_, and the parameters_ \((\eta,\varepsilon,\alpha,m_{\texttt{Newton}})\) _of_ BARONS _are set as in Theorem_ 7 _with_ \(\Phi(\cdot)=\Phi^{\text{LS}}(\cdot)+\frac{\nu}{2K^{2}}\|\cdot\|^{2}\) _and_ \((M_{\Psi},\nu)=(\widetilde{O}(1),\widetilde{O}(d))\)_, then for_ \(T\) _large enough (as in Theorem_ 7_)_ BARONS _has regret bounded as_ \[\mathrm{Reg}_{T}^{\texttt{BARONS}}(w)\lesssim RG\sqrt{T\log T}, \quad\forall w\in\mathrm{int}\,\mathcal{K}.\] (14)

_In either case, the computational complexity is bounded by_

\[\widetilde{O}\Big{(}\big{(}\mathcal{C}^{\text{sys}}+d^{2}\big{)} \cdot T+\mathcal{C}^{\text{sys}}\cdot d\sqrt{T}\Big{)},\] (15)

_where \(\mathcal{C}^{\text{sys}}\) is the computational cost of solving a linear system of the form \(A^{\top}\mathrm{diag}(v)Ax=y\), for vectors \(v\in\mathbb{R}_{\geq 0}^{d}\) and \(y\in\mathbb{R}^{d}\) (recall that \(A\) is the constraint matrix for the polytope \(\mathcal{K}\))._

Using the log-barrier.We note that since \(\mathcal{K}\) is a polytope, we could have used the standard log-barrier

\[\Phi^{\log}(w)=\sum_{i=1}^{m}\log(b^{\prime}_{i}-a^{\top}_{i}w ).\] (16)

This barrier is \((1,m)\)-self-concordant, and so instantiating Theorem 5 with it would imply a \(\widetilde{O}(b\sqrt{mdT})\) regret bound in the case of local sub-gradient norms bounded by \(b>0\). Using the LS barrier replaces the \(\sqrt{m}\) term in this bound by \(\sqrt{d}\) regardless of the number of constraints--see(13). However, this comes at a \(\mathcal{C}^{\tt sys}\) computational cost, which can be as high as \(md^{\omega-1}\) in the worst-case (see (12)). In the case of the log-barrier, this cost would be replaced by \(md\) (essentially because \(\mathcal{C}^{\tt grad}_{\tt c}(\Phi^{\log})\leq O(md)\)). Thus, when \(m\) is of the order of \(d\), using the log-barrier may be more computational-efficient compared to using the \(\tt LS\) barrier. In the next corollary, we bound the regret of \(\tt BARONS\) when \(\Phi=\Phi^{\log}\); this result is an immediate consequence of Theorem 7.

**Corollary 2** (OCO over a polytope with the \(\tt log\) barrier).: _Let \(G,b>0\), and suppose \(\mathcal{K}\) is given by (10) and that \(\Phi^{\log}\) is the corresponding \(\log\)-barrier. Further, let \((w_{t})\) be the iterates of \(\tt BARONS\). If \(\mathcal{K}\subseteq\mathcal{B}(R)\) and \(\|g_{t}\|\leq G\), for all \(t\geq 1\), and the parameters \((\eta,\varepsilon,\alpha,m_{\tt Newton})\) of \(\tt BARONS\) are set as in Theorem 7 with \(\Phi(\cdot)=\Phi^{\log}(\cdot)+\frac{\nu}{2R^{2}}\|\cdot\|^{2}\) and \((M_{\Psi},\nu)=(1,m)\), then for \(T\) large enough (as in Theorem 7) \(\tt BARONS\) has regret bounded as_

\[\operatorname{Re}_{T}^{\tt BARONS}(w)\lesssim RG\sqrt{T\log T},\quad\forall w \in\operatorname{int}\mathcal{K}.\] (17)

_The computational complexity is bounded by_

\[\widetilde{O}\Big{(}(md+d^{2})\cdot T+md^{\omega-1}\sqrt{mT}\Big{)}.\] (18)

### Implications for Lipschitz Losses

We now discuss implications of Corollary 1, and compare the bound of \(\tt BARONS\) to those of existing algorithms for Lipschitz losses.

Dimension-free regret bound.We note when the Euclidean norms of the sub-gradients are bounded, \(\tt BARONS\) achieves a _dimension-free_\(O(\sqrt{T})\) regret bound. In contrast, the best dimension-free regret bound4 achieved by existing projection-free algorithms is of order \(O(T^{3/4})\) (see e.g. [14, 11]). We also note that existing separation/membership-based algorithms that achieve a \(\sqrt{T}\) regret; for examples those presented in [28, 11, 26], are not dimension-free. Their regret bounds are of order \(O(\kappa\sqrt{T})\), where \(\kappa=R/r\) with \(r,R>0\) such that \(\mathcal{B}(r)\subseteq\mathcal{K}\subseteq\mathcal{B}(R)\). The asphericity parameter can depend on the dimension \(d\)[28], and even after a pre-conditioning step (which would involve putting the set \(\mathcal{K}\) into near-isotropic position and can cost up to \(\Omega(d^{4})\)[25]), \(\kappa\) can be as large as \(d\) in the worst-case. Of course, to make a fair comparison with existing projection-free algorithms, we also need to take computational complexity into account. This is what we do next.

Footnote 4: The dependence in \(T\) can be improved under additional structure such as smoothness or strong-convexity of the losses.

Computational cost.The computational cost in (15) should be compared with that of existing projection-free algorithms. For linear optimization-based projection-free algorithms, the computational cost after \(T\) rounds is typically of order \(\mathcal{C}^{\tt lin}\cdot T\), where \(\mathcal{C}^{\tt lin}\) is the cost of performing linear optimization over \(\mathcal{K}\) which, for a polytope \(\mathcal{K}\), reduces to solving a linear program. Using state-of-the-art interior point methods for solving such a linear program would cost \(\mathcal{C}^{\tt lin}\leq\widetilde{O}(\sqrt{d}\cdot\mathcal{C}^{\tt sys})\); see e.g. [22]. Thus, linear optimization-based projection-free algorithms5 can have a cost that is a factor \(\sqrt{d}\) worse than that of \(\tt BARONS\) in the setting of Corollary 1. On the other hand, separation/membership-based algorithms, the computational cost scales with \(O(\mathcal{C}^{\tt sep}\cdot T)\) after \(T\) rounds, where \(\mathcal{C}^{\tt sep}\) is the cost of performing separation for the set \(\mathcal{K}\). For a general polytope in \(\mathbb{R}^{d}\) with \(m\) constraints, we have \(\mathcal{C}^{\tt sep}\leq O(md)\), which may be smaller than \(\mathcal{C}^{\tt sys}\) (the latter can be as large as \(md^{\omega-1}\) in the worse case;see (12)). Here, it may be more appropriate to compare against the computational guarantee of \(\tt BARONS\) given in Corollary 2; by (18), we have that for \(T\geq d^{\omega-2}\sqrt{m}\), the computational cost of \(\tt BARONS\) in the setting of the corollary is dominated by \((md+d^{2})\cdot T\), which is comparable to that of existing separation-based algorithms.

Footnote 5: This only concerns algorithms that use an interior point method to implement linear optimization over \(\mathcal{K}\).

### Implications for Non-Lipschitz Losses

Another advantage \(\tt BARONS\) has over projection-free, and even projection-based, algorithms is that it has a regret bound that scales with a bound on the local norms of the gradients--see (13). We now showcase two online learning settings where this leads to non-trivial performance and computational improvements over existing OCO algorithms.

Online Portfolio Selection [5].The portfolio selection problem is a classical online learning problem where the gradients of the losses can be unbounded. In this paragraph, we demonstrate how the guarantee of BARONS in Corollary 1 leads to a non-trivial guarantee for this setting both in terms of regret and computational complexity. In the online portfolio setting, at each round \(t\), a learner (algorithm) chooses a distribution \(w_{t}\in\Delta_{d}\) over a fixed set of \(d\) portfolios. Then, the environment reveals a return vector \(r_{t}\in\mathbb{R}_{\geq 0}^{d}\), and the learner suffers a loss

\[\ell_{t}(w_{t})\coloneqq-\log w_{t}^{\top}r_{t}.\]

The goal of the learner is to minimize the regret \(\operatorname{Reg}_{T}(w)\coloneqq\sum_{t=1}^{T}(\ell_{t}(w_{t})-\ell_{t}(w))\) after \(T\geq 1\) rounds. For this problem, it is known that a logarithmic regret is achievable, but the specialized algorithms that achieve this have a computational complexity that scales with \(\min(d^{3}T,d^{2}T^{2})\)[5, 27, 32, 41, 17]. On the other hand, applying the generic Online Gradient Descent or the Online Newton Step to this problem leads to regret bounds that scale with the maximum norm of the gradient (which can be unbounded). Instantiating the guarantees of BARONS in Corollary 1 with \(\Phi\) set to the standard log-barrier for the simplex6, in particular the bound in (13), to the online portfolio selection problem leads to an \(\widetilde{O}(\sqrt{dT})\) regret bound, which does not depend on the norm of the observed gradients. Furthermore, we have \(\mathcal{C}^{\mathsf{sys}}\leq O(d)\), and so by (15) the computational complexity is essentially \(O(d^{2}T)\) after \(T\) rounds. Technically, the bound in (13) is only against comparators in the restricted set \(\mathcal{K}_{c}\). However, by setting \(c=1/T\), it possible to extend this guarantee to all comparators in \(\operatorname{int}\mathcal{K}\) as explained in Remark 1, since the losses in this case satisfy (6) [27, Lemma 10].

Footnote 6: Technically, we need to use a barrier for the set \(\{\tilde{w}\in\mathbb{R}_{\geq 0}^{d}\mid\sum_{i\in[d-1]}\tilde{w}_{i}\leq 1\}\); see e.g. [32].

Linear prediction with the log-loss.Another classical online learning problem with unbounded gradients is that of linear prediction with the log-loss [36]. For this problem, at each round \(t\), the learner receives a feature vector \(x_{t}\in\mathcal{X}\subseteq\mathbb{R}^{d}\), outputs \(w_{t}\in\mathcal{W}\subseteq\mathbb{R}^{d}\), then observes label \(y_{t}\in\mathcal{Y}\coloneqq\{-1,1\}\) and suffers loss

\[\ell_{t}(w_{t})\coloneqq-\mathbb{I}\{y_{t}=1\}\cdot\log(1-w_{t}^{\top}x_{t})- \mathbb{I}\{y_{t}=0\}\cdot\log(1-w_{t}^{\top}x_{t}).\]

In the settings, where \((\mathcal{X},\mathcal{W})=(\Delta_{d},\mathcal{B}_{\infty}(1))\) and \((\mathcal{X},\mathcal{W})=(\mathcal{B}_{\infty}(1),\Delta_{d})\), we have that \(\|\nabla\ell_{t}(w)\|_{\nabla^{2}\coloneqq\Phi(w)}\leq O(1)\) for all \(w\in\operatorname{int}\mathcal{W}\), where \(\Phi\) is set to the corresponding log-barrier for \(\mathcal{W}\). Thus, instantiating Corollary 1 (in particular (13)) in this setting implies that BARONS achieves a regret bound of the form:

\[\widetilde{O}(\sqrt{dT}),\] (19)

and has computational complexity bounded by \(\widetilde{O}(d^{2}T)\), as long as \(T\geq d\). Again, we emphasize that the bound in (19) does not depend on the norm of the gradients, which may be unbounded.

Finally, we note that there exist a few specialized algorithms that provide sublinear regret bounds for non-lipschitz losses. This includes, for example, the Soft-Bayes algorithm [34]. However, this algorithm is specialized to the log-loss with a particular dependence on the predictions, and it is not clear, for example, what regret bound it would have in the linear prediction setting and other similar settings with non-Lipschitz losses.

## Acknowledgments and Disclosure of Funding

ZM acknowledges support from the ONR through awards N00014-20-1-2336 and N00014-20-1-2394.

## References

* Abernethy et al. [2018] Jacob Abernethy, Kevin A Lai, Kfir Y Levy, and Jun-Kun Wang. Faster rates for convex-concave games. In _Conference On Learning Theory_, pages 1595-1625. PMLR, 2018.
* Abernethy et al. [2009] Jacob D Abernethy, Elad Hazan, and Alexander Rakhlin. Competing in the dark: An efficient algorithm for bandit linear optimization. 2009.
* Cesa-Bianchi et al. [2004] Nicolo Cesa-Bianchi, Alex Conconi, and Claudio Gentile. On the generalization ability of on-line learning algorithms. _IEEE Transactions on Information Theory_, 50(9):2050-2057, 2004.
* Cohen et al. [2021] Michael B Cohen, Yin Tat Lee, and Zhao Song. Solving linear programs in the current matrix multiplication time. _Journal of the ACM (JACM)_, 68(1):1-39, 2021.
* Cover [1991] Thomas M Cover. Universal portfolios. _Mathematical Finance_, 1(1):1-29, 1991.
* Cutkosky [2019] Ashok Cutkosky. Anytime online-to-batch, optimism and acceleration. In _International Conference on Machine Learning_, pages 1446-1454. PMLR, 2019.
* Cutkosky et al. [2023] Ashok Cutkosky, Harsh Mehta, and Francesco Orabona. Optimal stochastic non-smooth non-convex optimization through online-to-non-convex conversion. _arXiv preprint arXiv:2302.03775_, 2023.
* Fazel et al. [2022] Maryam Fazel, Yin Tat Lee, Swati Padmanabhan, and Aaron Sidford. Computing lewis weights to high precision. In _Proceedings of the 2022 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)_, pages 2723-2742. SIAM, 2022.
* Flaxman et al. [2005] Abraham D Flaxman, Adam Tauman Kalai, and H Brendan McMahan. Online convex optimization in the bandit setting: gradient descent without a gradient. In _Proceedings of the sixteenth annual ACM-SIAM symposium on Discrete algorithms_, pages 385-394, 2005.
* Garber and Hazan [2016] Dan Garber and Elad Hazan. A linearly convergent variant of the conditional gradient algorithm under strong convexity, with applications to online and stochastic optimization. _SIAM Journal on Optimization_, 26(3):1493-1528, 2016.
* Garber and Kretzu [2022] Dan Garber and Ben Kretzu. New projection-free algorithms for online convex optimization with adaptive regret guarantees. In _Conference on Learning Theory_, pages 2326-2359. PMLR, 2022.
* Goffin [1988] JL Goffin. Affine and projective transformations in nondifferentiable optimization. _Trends in Mathematical Optimization_, pages 79-91, 1988.
* Hazan et al. [2007] Elad Hazan, Amit Agarwal, and Satyen Kale. Logarithmic regret algorithms for online convex optimization. _Machine Learning_, 69(2-3):169-192, 2007.
* Hazan and Kale [2012] Elad Hazan and Satyen Kale. Projection-free online learning. In _Proceedings of the 29th International Coference on International Conference on Machine Learning_, pages 1843-1850, 2012.
* Hazan and Minasyan [2020] Elad Hazan and Edgar Minasyan. Faster projection-free online learning. In _Conference on Learning Theory_, pages 1877-1893. PMLR, 2020.
* Jaggi [2013] Martin Jaggi. Revisiting frank-wolfe: Projection-free sparse convex optimization. In _International conference on machine learning_, pages 427-435. PMLR, 2013.
* Jezequel et al. [2022] Remi Jezequel, Dmitri M Ostrovskii, and Pierre Gaillard. Efficient and near-optimal online portfolio selection. _arXiv preprint arXiv:2209.13932_, 2022.
* Kretzu and Garber [2021] Ben Kretzu and Dan Garber. Revisiting projection-free online learning: the strongly convex case. In _International Conference on Artificial Intelligence and Statistics_, pages 3592-3600. PMLR, 2021.

* [19] Simon Lacoste-Julien and Martin Jaggi. On the global linear convergence of frank-wolfe optimization variants. _Advances in neural information processing systems_, 28, 2015.
* [20] Yin Tat Lee and Aaron Sidford. Path finding methods for linear programming: Solving linear programs in o (vrank) iterations and faster algorithms for maximum flow. In _2014 IEEE 55th Annual Symposium on Foundations of Computer Science_, pages 424-433. IEEE, 2014.
* [21] Yin Tat Lee and Aaron Sidford. Efficient inverse maintenance and faster algorithms for linear programming. In _2015 IEEE 56th Annual Symposium on Foundations of Computer Science_, pages 230-249. IEEE, 2015.
* [22] Yin Tat Lee and Aaron Sidford. Solving linear programs with sqrt (rank) linear system solves. _arXiv preprint arXiv:1910.08033_, 2019.
* [23] Kfir Levy and Andreas Krause. Projection free online learning over smooth sets. In _The 22nd International Conference on Artificial Intelligence and Statistics_, pages 1458-1466. PMLR, 2019.
* [24] Ning Liu and Benjamin Grimmer. Gauges and accelerated optimization over smooth and/or strongly convex sets. _arXiv preprint arXiv:2303.05037_, 2023.
* [25] Laszlo Lovasz and Santosh Vempala. Simulated annealing in convex bodies and an o*(n4) volume algorithm. _Journal of Computer and System Sciences_, 72(2):392-417, 2006.
* [26] Zhou Lu, Nataly Brukhim, Paula Gradu, and Elad Hazan. Projection-free adaptive regret with membership oracles. In _International Conference on Algorithmic Learning Theory_, pages 1055-1073. PMLR, 2023.
* [27] Haipeng Luo, Chen-Yu Wei, and Kai Zheng. Efficient online portfolio with logarithmic regret. _Advances in neural information processing systems_, 31, 2018.
* [28] Zakaria Mhammedi. Efficient projection-free online convex optimization with membership oracle. In _Conference on Learning Theory_, pages 5314-5390. PMLR, 2022.
* [29] Zakaria Mhammedi. Exploiting the curvature of feasible sets for faster projection-free online learning. _arXiv preprint arXiv:2205.11470_, 2022.
* [30] Zakaria Mhammedi and Khashayar Gatmiry. Quasi-newton steps for efficient online expconcave optimization. _arXiv preprint arXiv:2211.01357_, 2022.
* [31] Zakaria Mhammedi and Alexander Rakhlin. Damped online newton step for portfolio selection. In _Conference on Learning Theory, 2-5 July 2022, London, UK_, volume 178, pages 5561-5595. PMLR, 2022.
* [32] Zakaria Mhammedi and Alexander Rakhlin. Damped online newton step for portfolio selection. In _Conference on Learning Theory_, pages 5561-5595. PMLR, 2022.
* [33] Yurii Nesterov et al. _Lectures on convex optimization_, volume 137. Springer, 2018.
* [34] Laurent Orseau, Tor Lattimore, and Shane Legg. Soft-bayes: Prod for mixtures of experts with log-loss. In _International Conference on Algorithmic Learning Theory_, pages 372-399. PMLR, 2017.
* [35] Fabian Pedregosa, Geoffrey Negiar, Armin Askari, and Martin Jaggi. Linearly convergent frank-wolfe with backtracking line-search. In _International conference on artificial intelligence and statistics_, pages 1-10. PMLR, 2020.
* [36] Alexander Rakhlin and Karthik Sridharan. Sequential probability assignment with binary alphabets and large classes of experts. _arXiv preprint arXiv:1501.07340_, 2015.
* [37] Shai Shalev-Shwartz et al. Online learning and online convex optimization. _Foundations and trends in Machine Learning_, 4(2):107-194, 2011.
* [38] Tomasz Tkocz. Asymptotic convex geometry lecture notes. 2018.

* [39] Jan van den Brand. A deterministic linear program solver in current matrix multiplication time. In _Proceedings of the Fourteenth Annual ACM-SIAM Symposium on Discrete Algorithms_, pages 259-278. SIAM, 2020.
* [40] Jan van den Brand, Yin Tat Lee, Aaron Sidford, and Zhao Song. Solving tall dense linear programs in nearly linear time. In _Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing_, pages 775-788, 2020.
* [41] Julian Zimmert, Naman Agarwal, and Satyen Kale. Pushing the efficiency-regret pareto frontier for online learning of portfolios and quantum states. In _Conference on Learning Theory_, pages 182-226. PMLR, 2022.

Self-concordance properties

Throughout, for a twice-differentiable function \(f\colon\operatorname{int}\mathcal{K}\to\mathbb{R}\), we let \(\lambda(x,f)\coloneqq|\!\operatorname{\nabla}f(x)|\!|_{\operatorname{\nabla}^{-2} f(x)}\) denote the _Newton decrement_ of \(f\) at \(x\in\operatorname{int}\mathcal{K}\).

**Lemma 1**.: _Let \(f\colon\operatorname{int}\mathcal{K}\to\mathbb{R}\) be a self-concordant function with constant \(M_{f}\geq 1\). Further, let \(x\in\operatorname{int}\mathcal{K}\) and \(x_{f}\in\operatorname{argmin}_{x\in\mathcal{K}}f(x)\). Then,_ **I)** _whenever \(\lambda(x,f)<1/M_{f}\), we have_

\[\|x-x_{f}\|_{\operatorname{\nabla}^{2}f(x_{f})}\vee\|x-x_{f}\|_{\operatorname {\nabla}^{2}f(x)}\leq\lambda(x,f)/(1-M_{f}\lambda(x,f));\]

_and_ **II)** _for any \(M\geq M_{f}\), the Newton step \(x^{+}\coloneqq x-\operatorname{\nabla}^{-2}f(x)\nabla f(x)\) satisfies \(x^{+}\in\operatorname{int}\mathcal{K}\) and \(\lambda(x^{+},f)\leq M\lambda(x,f)^{2}/(1-M\lambda(x,f))^{2}\)._

**Lemma 2**.: _Let \(f\colon\operatorname{int}\mathcal{K}\to\mathbb{R}\) be a self-concordant function with constant \(M_{f}\) and \(x\in\operatorname{int}\mathcal{K}\). Then, for any \(w\) such that \(r\coloneqq\|w-x\|_{\operatorname{\nabla}^{2}f(x)}<1/M_{f}\), we have_

\[(1-M_{f}r)^{2}\operatorname{\nabla}^{2}f(w)\preceq\operatorname{\nabla}^{2}f (x)\preceq(1-M_{f}r)^{-2}\operatorname{\nabla}^{2}f(x).\]

The following result from [33, Theorem 5.1.5] will be useful to show that the iterates of algorithms are always in the feasible set.

**Lemma 3**.: _Let \(f\colon\operatorname{int}\mathcal{K}\to\mathbb{R}\) be a self-concordant function with constant \(M_{f}\geq 1\) and \(x\in\operatorname{int}\mathcal{K}\). Then, \(\mathcal{E}_{x}\coloneqq\{w\in\mathbb{R}^{d};\,\|w-x\|_{x}<1/M_{f}\}\subseteq \operatorname{int}\mathcal{K}\). Furthermore, for all \(w\in\mathcal{E}_{x}\), we have_

\[\|w-x\|_{w}\leq\frac{\|w-x\|_{x}}{1-M_{f}\|w-x\|_{x}}.\]

Finally, we will also make use of the following result due to [31]:

**Lemma 4**.: _Let \(f\colon\operatorname{int}\mathcal{K}\to\mathbb{R}\) be a self-concordant function with constant \(M_{f}>0\). Then, for any \(x,w\in\operatorname{int}\mathcal{K}\) such that \(r\coloneqq\|x-w\|_{\operatorname{\nabla}^{2}f(x)}<1/M_{f}\), we have_

\[\|\operatorname{\nabla}f(x)-\operatorname{\nabla}f(w)\|_{\operatorname{\nabla }^{-2}f(x)}^{2}\leq\frac{1}{(1-M_{f}r)^{2}}\|w-x\|_{\operatorname{\nabla}^{2} f(x)}^{2}.\]

## Appendix B Technical Lemmas

Our analysis relies on the crucial fact that the Newton decrement can be sufficiently decreased by taking a Newton step using only approximate gradients and Hessians. We state this fact next; the proof is in SSD.1.

**Lemma 5** (Decrease in the Newton decrement).: _Let \(\Phi\) be a self-concordant function over \(\operatorname{int}\mathcal{K}\) with constant \(M_{\Phi}>0\), and let \(y\in\mathbb{R}^{d}\) be such that \(\lambda(y,\Phi)\leq 1/(40M_{\Phi})\). Further, let \(H\in\mathbb{R}^{d\times d}\) and \(\widehat{\nabla}_{y}\in\mathbb{R}^{d}\) be such that_

\[\|\widehat{\nabla}_{y}-\operatorname{\nabla}\Phi(y)\|_{\operatorname{\nabla}^{ -2}\Phi(y)}\leq\varepsilon<\frac{1}{40M_{\Phi}},\] (20)

\[(1-\alpha)\operatorname{\nabla}^{2}\Phi(y)\preccurlyeq H\preccurlyeq(1+ \alpha)\operatorname{\nabla}^{2}\Phi(y),\] (21)

_for \(\alpha<1/5\). Then, for \(\tilde{y}^{+}\coloneqq y-H^{-1}\operatorname{\nabla}\Phi(y)\) and \(y^{+}\coloneqq y-H^{-1}\widehat{\nabla}_{y}\), we have_

\[\lambda(\tilde{y}^{+},\Phi) \leq 9M_{\Phi}\lambda(y,\Phi)^{2}+2.5\alpha\lambda(y,\Phi),\] \[\lambda(y^{+},\Phi) \leq 20(1+\alpha)\varepsilon+(1+20(1+\alpha)\varepsilon)\cdot \lambda(\tilde{y}^{+},\Phi).\]

Next, we show that as long as the Newton decrement is small enough at the current iterate \(w_{t-1}\), the "intermediate" Newton iterates \((w_{t}^{m})\) remain close to the landmark point \(u_{t-1}\); this will be important for the proof of Theorem 5. The proof is in SSD.2.

**Lemma 6** (Invariance under Newton iterations).: _Let \(\Phi\) be a self-concordant function over \(\operatorname{int}\mathcal{K}\) with constant \(M_{\Phi}>0\). Let \(b>0\), \(m_{\texttt{Newton}}\coloneqq\Theta(\log\frac{1}{\varepsilon M_{\Phi}})\), \(\alpha\leq 1/\big{(}1000M_{\Phi}\big{)}\), \(\varepsilon<1/\big{(}20000M_{\Phi}\big{)}\), \(\alpha=0.001\), and \(\eta\leq 1/(1000M_{\Phi}b)\). Further, let \(\big{(}w_{t},w_{t}^{m},u_{t},g_{t},H_{t}\big{)}\) be as in Algorithm 1 with input \((\eta,\varepsilon,\alpha,m_{\texttt{Newton}})\). Suppose that at round \(t-1\) of Algorithm 1, we have_

\[\lambda(w_{t-1},\Phi_{t-1})\leq\alpha\quad\text{and}\quad\|u_{t-1}-w_{t-1}\|_{ \operatorname{\nabla}^{2}\Phi(u_{t-1})}\leq\frac{1}{40M_{\Phi}}.\] (22)_For \(t>1\), if the sub-gradient \(g_{t-1}\) at round \(t-1\) satisfies \(\left\|g_{t-1}\right\|_{\nabla^{-2}\Phi(w_{t-1})}\leq b\), then_

\[\lambda(w_{t}^{m},\Phi_{t})\leq\left(\frac{15}{16}\right)^{m-1}\lambda(w_{t}^{1 },\Phi_{t})+500\varepsilon\leq\frac{1}{40M_{\Phi}}.\] (23)

_Furthermore, we have for all \(m\in[m_{\mathtt{Newton}}]\):_

\[\frac{1}{2}\nabla^{2}\Phi(w_{t}^{m})\preccurlyeq\nabla^{2}\Phi(w_{t}^{*}) \preccurlyeq 2\nabla^{2}\Phi(w_{t}^{m}),\] (24)

\[\left\|w_{t}^{m}-u_{t-1}\right\|_{H_{t-1}}\leq\frac{1}{10M_{\Phi}},\] (25)

\[\left\|w_{t}^{m}-w_{t}^{*}\right\|_{\nabla^{2}\Phi(w_{t}^{*})}\leq\frac{1}{49M _{\Phi}}\left(\frac{15}{16}\right)^{m-1}+240\varepsilon,\] (26)

\[\left|w_{t}^{m}-u_{t-1}\right\|_{H_{t-1}}-\left|w_{t-1}-u_{t-1}\right\|_{H_{ t-1}}\right|\leq 2\eta\left\|g_{t-1}\right\|_{\nabla^{2}\Phi(w_{t-1})}+\frac{1}{4 0M_{\Phi}}\left(\frac{15}{16}\right)^{m-1}+500\varepsilon+2\alpha,\] (27)

_where \(w_{t}^{*}\in\operatorname*{argmin}_{w\in\mathcal{K}}\Phi_{t}(w)\) is the optimum solution of \(\Phi_{t}\)._

We note that we have not made an attempt to optimize over the constants in Lemma 6.

**Lemma 7**.: _Let \(\Phi\) be a \((M_{\Phi},\nu)\)-self-concordant barrier for \(\mathcal{K}\), and let \(w^{*}\in\operatorname*{argmin}_{w\in\mathcal{K}}\Phi(w)\). Further, suppose that the losses satisfy:_

\[\sup_{w\in\mathcal{K},t\in[T]}\ell_{t}\left(\left(1-\frac{1}{T}\right)\cdot w +\frac{1}{T}\cdot w^{*}\right)-\ell(w)\leq O\left(\frac{1}{\sqrt{T}}\right),\] (28)

_Then, for any \(w\in\mathcal{K}\), there exists \(\tilde{w}\in\mathcal{K}_{1/T}\) (where \(\mathcal{K}_{c}\) is as in (4)) such that_

\[\sum_{t=1}^{T}(\ell_{t}(w_{t})-\ell_{t}(w))\leq\sum_{t=1}^{T}(\ell_{t}(w_{t}) -\ell_{t}(\tilde{w})+O(\sqrt{T}).\] (29)

Proof.: Fix \(w\in\mathcal{K}\) and define \(\tilde{w}=\frac{1}{T}w^{*}+\left(1-\frac{1}{T}\right)w\in\mathcal{K}_{1/T}\). Then, by (28), we have, for all \(t\in[T]\),

\[\ell_{t}(w_{t})-\ell_{t}(w)\leq\ell_{t}(\tilde{w}_{t})-\ell_{t}(\tilde{w})+O( T^{-1/2}).\] (30)

Summing this over \(t=1,\ldots,T\) leads to the desired result. 

## Appendix C Proofs of the Main Results

Next, we present the proof of Theorem 5.

### Proof of Theorem 5

Proof.: The proof consists of three parts: I) First, we show that BARONS keeps the Newton decrements \(\lambda(w_{t},\Phi_{t}),t\geq 1,\) small--this is the main invariant of BARONS; II) Then, we bound the regret of BARONS using this invariant and the results of Lemma 6; III) Finally, we bound the runtime of BARONS.

**Bounding the Newton decrements.** We will show that the Newton decrements satisfy

\[\lambda(w_{s},\Phi_{s})\leq\alpha\coloneqq\min\left\{\frac{1}{1000M_{\Phi}},1 000\varepsilon\right\},\] (31)

for all \(s\geq 1\). We will show (31) by induction over \(t\geq 1\).

**Base case.** The base case follows by the facts that \(w_{1}\in\operatorname*{argmin}_{w\in\mathcal{K}}\Phi(w)\), \(\Phi_{1}\equiv\Phi\) and that the Newton decrement is zero at the minimizer.

**Induction step.** Suppose that (31) holds with \(s=t-1\) for some \(t\geq 1\). We will show that it holds for \(s=t\). First, note that by the update rule of landmark (see Lines 12 and 17 of Alg. 1), we have that

\[\left\|w_{t-1}-u_{t-1}\right\|_{H_{t-1}}\leq\frac{1}{41M_{\Phi}},\]

[MISSING_PAGE_FAIL:16]

Thus, the overall computational cost of recalculating the Hessians and their inverses at the landmark iterates is bounded by

\[\mathcal{C}_{\alpha}^{\texttt{hess}}\cdot\left(M_{\Phi}T\varepsilon+M_{\Phi} \sum_{t=1}^{T}\eta\|g_{t}\|_{\nabla^{-2}\Phi(w_{t})}\right).\]

where the multiplicative cost \(\mathcal{C}_{\alpha}^{\texttt{hess}}\) reflects the fact that the instance of BARONS in the theorem's statement needs \(1\pm\alpha\) accurate approximations of the Hessians and their inverses (in the sense of Definition 4) at the landmark iterates. Moreover, BARONS needs to compute an \(\varepsilon\)-approximate gradient of \(\Phi\) at every point \(w_{t}^{m}\) for all \(t\in[T]\) and \(m\in[m_{\texttt{Newton}}]\). Thus, the cost of computing the gradients is \(\mathcal{C}_{\varepsilon}^{\texttt{grad}}\cdot T\log\frac{1}{\varepsilon M_ {\Phi}}\). Finally, the matrix-vector product \(H_{t}^{-1}\nabla\Phi_{t}(w)\) in BARONS costs \(O(d^{2})\) work, and so overall the computational cost is

\[O\left((\mathcal{C}_{\varepsilon}^{\texttt{grad}}+d^{2})\cdot T\log\frac{1}{ \varepsilon M_{\Phi}}+\mathcal{C}_{\alpha}^{\texttt{hess}}\cdot\left(M_{\Phi }T\varepsilon+M_{\Phi}\sum_{t=1}^{T}\eta\|g_{t}\|_{\nabla^{-2}\Phi(w_{t})} \right)\right).\]

### Proof of Theorem 6

Proof.: Note that without having any effect on the algorithm, we can add an arbitrary constant to the barrier \(\Phi\). Thus, without loss of generality, we assume \(\Phi(w^{*})=0\), which implies \(\Phi(w)\geq 0\), for all \(w\in\mathcal{K}\). We define the restricted comparator class

\[\widetilde{\mathcal{K}}\coloneqq\{w\in\mathcal{K}:\Phi(w)\leq\Phi(w^{*})+\nu \log c\}.\]

By [33, Corollary 5.3.3] and the fact that \(\Phi\) is an \((M_{\Phi},\nu)\)-self-concordant barrier for \(\mathcal{K}\), we have that

\[\mathcal{K}_{c}\subseteq\widetilde{\mathcal{K}},\] (36)

and so it suffices to bound the regret against comparators in \(\widetilde{\mathcal{K}}\). Fix \(\tilde{w}\in\widetilde{\mathcal{K}}\). Under the assumptions of the theorem, the preconditions of Theorem 5 are satisfied and so we have,

\[\sum_{t=1}^{T}(\ell_{t}(w_{t})-\ell_{t}(\tilde{w})) \lesssim\frac{1}{\eta}\Phi(\tilde{w})\ +\eta\sum_{t=1}^{T}\|g_{t}\|_{\nabla^{-2}\Phi(w_{t})}^{2}+ \varepsilon\sum_{t=1}^{T}\|g_{t}\|_{\nabla^{-2}\Phi(w_{t})},\] \[=\frac{1}{\eta}\nu\log c+\eta b^{2}T+\varepsilon Tb,\quad\text{( since $\tilde{w}\in\widetilde{\mathcal{K}}$ and $\|g_{t}\|_{\nabla^{-2}\Phi(w_{t})}\leq b$)}\] \[=2b\sqrt{\nu T\log c}+b\sqrt{\nu T},\]

where in the last step we used the choices of \(\eta\) and \(\varepsilon\) in (5). Combining this with (36) implies the desired regret bound. The bound on the computational complexity follows immediately from Theorem 5, the fact that \(\|g_{t}\|_{\nabla^{-2}\Phi(w_{t})}\leq b\), and the choices of \(\eta\) and \(\varepsilon\) in (5). 

### Proof of Theorem 7

Proof.: Similar to the proof of Theorem 6, and without loss of generality, we assume that \(\Psi\) is zero at its minimum, i.e. \(\Psi(w^{*})=0\). We define the restricted comparator class

\[\widetilde{\mathcal{K}}\coloneqq\{w\in\mathcal{K}:\Psi(w)\leq\Psi(w^{*})+\nu \log T\}.\] (37)

By [33, Corollary 5.3.3] and the fact that \(\Psi\) is an \((M_{\Psi},\nu)\)-self-concordant barrier for \(\mathcal{K}\), we have that

\[\mathcal{K}_{1/T}\subseteq\widetilde{\mathcal{K}}.\] (38)

On the other hand, by Lemma 7 we have that

\[\sup_{w\in\operatorname{int}\mathcal{K}}\sum_{t=1}^{T}(\ell_{t}(w_{t})-\ell_{t }(w))\leq\sup_{\tilde{w}\in\operatorname{int}\mathcal{K}}\sum_{t=1}^{T}(\ell_ {t}(w_{t})-\ell_{t}(\tilde{w})+O(\sqrt{T}).\]

Combining this with (38) implies that it suffices to bound the regret against comparators in \(\widetilde{\mathcal{K}}\). Fix \(\tilde{w}\in\widetilde{\mathcal{K}}\). Note that since \(\Phi\) is equal to \(\Psi\) plus a quadratic, \(\Phi\) is also a self-concordant function with constant \(M_{\Phi}=M_{\Psi}\)[33]. Thus, under the assumptions of the theorem the preconditions of Theorem 5 are satisfied and so we have,

\[\sum_{t=1}^{T}(\ell_{t}(w_{t})-\ell_{t}(\tilde{w}))\lesssim\frac{1}{ \eta}\Phi(\tilde{w})\ +\eta\sum_{t=1}^{T}\|g_{t}\|_{\nabla^{-2}\Phi(w_{t})}^{2}+ \varepsilon\sum_{t=1}^{T}\|g_{t}\|_{\nabla^{-2}\Phi(w_{t})}.\] (39)

Now, by the choice of \(\Phi\), we have that

\[\|g_{t}\|_{\nabla^{-2}\Phi(w_{t})}\leq R\|g_{t}\|/\sqrt{\nu}\leq RG /\sqrt{\nu}.\]

Moreover, from the condition that \(\mathcal{K}\subseteq\mathcal{B}(R)\), (37) and the fact that \(\Psi(w^{\star})=0\), we have for all \(w\in\widetilde{\mathcal{K}}\):

\[\Phi(w)\leq\nu\log T+\frac{\nu}{2}.\]

Plugging this into (39) and using that \(\tilde{w}\in\mathcal{K}\), we get

\[\sum_{t=1}^{T}(\ell_{t}(w_{t})-\ell_{t}(\tilde{w})) =\frac{1}{\eta}\nu\log T+\frac{1}{2\eta}+\eta\frac{R^{2}G^{2}}{ \nu}T+\varepsilon\frac{TRG}{\sqrt{\nu}},\] \[=2RG\sqrt{T\log T}+\frac{5}{2}RG\sqrt{T},\]

where in the last step we used the choices of \(\eta\) and \(\varepsilon\) in (8). Combining this with (38) implies the desired regret bound. The bound on the computational complexity follows from the computational complexity in Theorem 5 and the fact a gradient Oracle \(\mathcal{O}_{\varepsilon}^{\mathsf{grad}}(\Phi)\) [resp. Hessian Oracle \(\mathcal{O}_{\alpha}^{\mathsf{grad}}(\Psi)\)] for \(\Phi(\cdot)=\Psi(\cdot)+\frac{\nu}{2R^{2}}\|\cdot\|^{2}\) can be implemented with one call to \(\mathcal{O}_{\varepsilon}^{\mathsf{grad}}(\Psi)\) [resp. \(\mathcal{O}_{\alpha}^{\mathsf{hess}}(\Psi)\)] plus \(d\) arithmetic operations. 

## Appendix D Proofs of the Technical Lemmas

### Proof of Lemma 5

Proof.: Throughout, we let \(h\) is the Newton step based on the exact gradient \(\nabla\Phi(y)\):

\[h=-H^{-1}\nabla\Phi(y).\]

Recall that \(\tilde{y}^{+}\) and \(y^{+}\) from the lemma's statement satisfy

\[\tilde{y}^{+}=y+h\quad\text{and}\quad y^{+}=y-H^{-1}\bar{\nabla }_{y}.\]

Bounding the Newton decrement at \(\tilde{y}^{+}\).First, we bound the Newton decrement at \(\tilde{y}^{+}\). By definition, the square of the Newton decrement at \(\tilde{y}^{+}=y+h\) is

\[\lambda(\tilde{y}^{+},\Phi)=\nabla\Phi(y+h)^{\top}\nabla^{-2} \Phi(y+h)\nabla\Phi(y+h).\]

Now for the vector \(z\) defined below, we define the function \(F\) as

\[z\triangleq\nabla^{-2}\Phi(y+h)\nabla\Phi(y+h)\quad\text{and} \quad F(y)\coloneqq\nabla\Phi(y)^{\top}z.\] (40)

The partial derivative of \(F\) in direction \(h\) is given by

\[DF(y)[h] =-h^{\top}\nabla^{2}\Phi(y)z,\] \[=-\nabla\Phi(y)^{\top}H^{-1}\nabla^{2}\Phi(y)z,\] \[=-\nabla\Phi(y)^{\top}H^{-1/2}H^{-1/2}\nabla^{2}\Phi(y)H^{-1/2}H ^{1/2}z,\] \[=-\nabla\Phi(y)^{\top}H^{-1/2}(H^{-1/2}\nabla^{2}\Phi(y)H^{-1/2}- I)H^{1/2}z-\nabla\Phi(y)^{\top}z.\] (41)

Now, by (21), we have

\[\|H^{-1/2}\nabla^{2}\Phi(y)H^{-1/2}-I\|\leq\frac{\alpha}{1-\alpha}.\]Thus, the first term on the right-hand side of (41) can be bounded as

\[\nabla\Phi(y)^{\top}H^{-1/2}(H^{-1/2}\nabla^{2}\Phi(y)H^{-1/2}-I)H^{1/ 2}z\] \[\leq\frac{\alpha}{1-\alpha}\big{\lvert}\nabla\Phi(y)^{\top}H^{-1/2 }\big{\lVert}H^{1/2}z\big{\rVert},\] \[=\frac{\alpha}{1-\alpha}\big{\lvert}\nabla\Phi(y)\big{\rvert}_{H^ {-1}}\lVert z\big{\rvert}_{H},\] \[\leq\frac{\alpha(1+\alpha)}{(1-\alpha)^{2}}\lVert\nabla\Phi(y) \rVert_{\nabla^{-2}\Phi(y)}\lVert z\rVert_{\nabla^{2}\Phi(y)},\] \[=\frac{\alpha(1+\alpha)}{(1-\alpha)^{2}}\lambda(y,\Phi)\cdot \lVert z\rVert_{\nabla^{2}\Phi(y)}.\]

Plugging this into (41) and using the definition \(z\) in (40), we obtain

\[\big{\lvert}DF(y)[h]+F(y)\big{\rvert}\leq\frac{\alpha(1+\alpha)}{(1-\alpha)^{ 2}}\lambda(y,\Phi)\cdot\lVert z\rVert_{\nabla^{2}\Phi(y)}.\] (42)

Now, let \(\bm{y}(s)\coloneqq y+sh\) and \(F\circ\bm{y}(s)\coloneqq F(y(s))\). With this, we have

\[(F\circ\bm{y})^{\prime}(s)-(F\circ\bm{y})^{\prime}(0)=h^{\top}(\nabla^{2}\Phi (y(s))-\nabla^{2}\Phi(y(0)))z.\] (43)

On the other hand, by Lemma 8 and our assumption on \(\lambda(y,\Phi)\), we have

\[\lVert\bm{y}(s)-y\rVert_{\nabla^{2}\Phi(y)}=s\lVert h\rVert_{ \nabla^{2}\Phi(y)}\leq\frac{s}{1-\alpha}\lVert\nabla\Phi(y)\rVert_{\nabla^{- 2}\Phi(y)} \leq\frac{1}{1-\alpha}\lambda(y,\Phi),\] (44) \[<\frac{1}{30M_{\Phi}}.\] (45)

Thus, by Lemma 1, we have

\[(1-M_{\Phi}\lVert\bm{y}(s)-y\rVert_{\nabla^{2}\Phi(y)}^{2})^{2}\nabla^{2}\Phi (y)\leq\nabla^{2}\Phi(y(s))\leq\frac{1}{(1-M_{\Phi}\lVert\bm{y}(s)-y\rVert_{ \nabla^{2}\Phi(y)})^{2}}\nabla^{2}\Phi(y).\]

This, together with (45) also implies that

\[(1-3M_{\Phi}\lVert\bm{y}(s)-y\rVert_{\nabla^{2}\Phi(y)})\nabla^{2}\Phi(y) \leq\nabla^{2}\Phi(y(s))\leq(1+3M_{\Phi}\lVert\bm{y}(s)-y\rVert_{\nabla^{2} \Phi(y)})\nabla^{2}\Phi(y).\]

After rearranging, this becomes

\[-3M_{\Phi}\lVert\bm{y}(s)-y\rVert_{\nabla^{2}\Phi(y)}\nabla^{2}\Phi(y)\leq \nabla^{2}\Phi(y(s))-\nabla^{2}\Phi(y)\leq 3M_{\Phi}\lVert\bm{y}(s)-y\rVert_{ \nabla^{2}\Phi(y)}\nabla^{2}\Phi(y).\]

Combining this with (44) and the fact that \(c\leq\frac{1}{4}\) gives

\[-4M_{\Phi}\lambda(y,\Phi)\nabla^{2}\Phi(y)\leq\nabla^{2}\Phi(y(s))-\nabla^{2} \Phi(y)\leq 4M_{\Phi}\lambda(y,\Phi)\nabla^{2}\Phi(y).\] (46)

Finally, by Lemma 9 and (46), we obtain the following bound on the right-hand side of (43):

\[(F\circ\bm{y})^{\prime}(s)-(F\circ\bm{y})^{\prime}(0)\leq 6M_{\Phi}\lambda(y, \Phi)\lVert h\rVert_{\nabla^{2}\Phi(y)}\lVert z\rVert_{\nabla^{2}\Phi(y)}.\]

Integrating this over \(s\) gives

\[\nabla\Phi(y+h)^{\top}z =(F\circ\bm{y})(1)\] \[=(F\circ\bm{y})(0)+(F\circ\bm{y})^{\prime}(0)+\int_{0}^{1}\big{(} (F\circ\bm{y})^{\prime}(s)-(F\circ\bm{y})^{\prime}(0)\big{)}ds\] \[\leq\nabla\Phi(y)^{\top}z+DF(y)[z]+6M_{\Phi}\lambda(y,\Phi)\lVert h \rVert_{\nabla^{2}\Phi(y)}\lVert z\rVert_{\nabla^{2}\Phi(y)},\] \[\leq\nabla\Phi(y)^{\top}z+DF(y)[z]+\frac{6M_{\Phi}}{1-\alpha} \lambda(y,\Phi)^{2}\lVert z\rVert_{\nabla^{2}\Phi(y)},\] (47)

where the last inequality follows by (44). Now, note that from (46) (with \(s=1\)) and the assumption that \(\lambda(w,\Phi)\leq 1/(40M_{\Phi})\), we have

\[\nabla^{2}\Phi(y)\leq\frac{10}{9}\nabla^{2}\Phi(y+h).\]This implies

\[\|z\|_{\nabla^{2}\Phi(y)}\leq\frac{10}{9}\|z\|_{\nabla^{2}\Phi(y^{+h})}=\frac{10} {9}\lambda(y+h,\Phi).\]

Plugging this into (47) and using (42), we get

\[\nabla\Phi(y+h)^{\top} z\leq\big{|}\nabla\Phi(y)^{\top}z+DF(y)[h]\big{|}+\frac{20M_{\Phi}}{ 3(1-\alpha)}\lambda(y,\Phi)^{2}\lambda(y+h,\Phi)\] \[\leq\frac{\alpha(1+\alpha)}{(1-\alpha)^{2}}\lambda(y,\Phi)\big{|} z\big{|}_{\nabla^{2}\Phi(y)}+\frac{20M_{\Phi}}{3(1-\alpha)}\lambda(y,\Phi)^{2} \lambda(y+h,\Phi),\] \[\leq\frac{10\alpha(1+\alpha)}{9(1-\alpha)^{2}}\lambda(y,\Phi) \lambda(y+h,\Phi)+\frac{20M_{\Phi}}{3(1-\alpha)}\lambda(y,\Phi)^{2}\lambda(y+ h,\Phi).\]

Now, from the definition of \(z\), we have

\[\nabla\Phi(y+h)^{\top}z=\lambda(y+h,\Phi)^{2}.\]

Thus, since \(\alpha<1/4\), we finally get

\[\lambda(y+h,\Phi)\leq 9M_{\Phi}\lambda(y,\Phi)^{2}+2.5\alpha \lambda(y,\Phi).\]

This proves the first part of the claim, i.e. (43).

Bounding the Newton decrement at \(y^{+}\).We now bound the Newton decrement at \(y^{+}=y-H^{-1}\widehat{\nabla}_{y}\) in terms of that of \(\tilde{y}^{+}=y+h\). Note that

\[\tilde{y}^{+}-y^{+}=H^{-1}(\nabla\Phi(y)-\widehat{\nabla}_{y}).\]

On the other hand, from (64) and (45), we have

\[\nabla^{2}\Phi(\tilde{y}^{+})\leq(1+3M_{\Phi}\big{|}h\big{|}) \nabla^{2}\Phi(y)\leq\frac{7}{4}\nabla^{2}\Phi(y)\leq\frac{7}{4}(1+\alpha)H,\] (48)

which implies that

\[\|\nabla^{2}\Phi(\tilde{y}^{+})^{1/2}H^{-1}\nabla^{2}\Phi(\tilde{y }^{+})^{1/2}\big{|}\leq\frac{7}{4}(1+\alpha).\]

Therefore,

\[\|\tilde{y}^{+}-y^{+}\|_{\nabla^{2}\Phi(\tilde{y}^{+})}^{2}\] \[=(\nabla\Phi(y)-\widehat{\nabla}_{y})^{\top}H^{-1}\nabla^{2}\Phi (\tilde{y}^{+})H^{-1}(\nabla\Phi(y)-\widehat{\nabla}_{y}),\] \[=(\nabla\Phi(\tilde{y}^{+})-\widehat{\nabla}_{y})^{\top}\nabla^{ -1/2}\Phi(\tilde{y}^{+})\Big{(}\nabla^{2}\Phi(\tilde{y}^{+})^{1/2}H^{-1} \nabla^{2}\Phi(\tilde{y}^{+})^{1/2}\Big{)}^{2}\nabla^{-1/2}\Phi(\tilde{y}^{+}) (\nabla\Phi(y)-\widehat{\nabla}_{y}),\] \[\leq\frac{49}{16}(1+\alpha)^{2}(\nabla\Phi(y)-\widehat{\nabla}_{ y})^{\top}\nabla^{-2}\Phi(\tilde{y}^{+})(\nabla\Phi(y)-\widehat{\nabla}_{y}),\] \[=\frac{49}{16}(1+\alpha)^{2}\|\nabla\Phi(y)-\widehat{\nabla}_{y} \|_{\nabla^{-2}\Phi(\tilde{y}^{+})}.\]

Combining this with (48) and our assumption on \(\widehat{\nabla}_{y}\) from (20) implies

\[\|\tilde{y}^{+}-y^{+}\|_{\nabla^{2}\Phi(\tilde{y}^{+})}\leq\frac{7}{2}(1+ \alpha)\|\nabla\Phi(y)-\widehat{\nabla}_{y}\|_{\nabla^{-2}\Phi(y)}\leq 5(1+ \alpha)\varepsilon.\] (49)

Thus, by Lemma 1, we have

\[\Big{(}(1-5(1+\alpha)\varepsilon M_{\Phi})^{2}-1\Big{)}\nabla^{2} \Phi(y^{+})\leq\nabla^{2}\Phi(\tilde{y}^{+})-\nabla^{2}\Phi(y^{+})\leq\left( \frac{1}{(1-5(1+\alpha)\varepsilon M_{\Phi})^{2}}-1\right)\nabla^{2}\Phi(y^{+}).\]

Since \(\varepsilon<1/(40M_{\Phi})\), we get

\[-20(1+\alpha)\varepsilon\nabla^{2}\Phi(y^{+})\leq\nabla^{2}\Phi(\tilde{y}^{+ })-\nabla^{2}\Phi(y^{+})\leq 20(1+\alpha)\varepsilon\nabla^{2}\Phi(y^{+}).\] (50)Now, by Lemma 4 instantiated with \(x=\tilde{y}^{+}\) and \(w=y^{+}\), we have

\[\sqrt{(\nabla\Phi(\tilde{y}^{+})-\nabla\Phi(y^{+}))^{\top}\nabla^{- 2}\Phi(\tilde{y}^{+})(\nabla\Phi(\tilde{y}^{+})-\nabla\Phi(y^{+}))} \leq\frac{\|y^{+}-\tilde{y}^{+}\|_{\nabla^{2}\Phi(\tilde{y}^{+})} }{(1-M_{\Phi}\|y^{+}-\tilde{y}^{+}\|_{\nabla^{2}\Phi(\tilde{y}^{+})}},\] \[\leq 10(1+\alpha)\varepsilon,\] (51)

where in the last inequality we used (49) and the fact that \(\varepsilon\leq 1/(40M_{\Phi})\).

Using the triangle inequality, we can bound the Newton decrement at \(y^{+}\) as

\[\lambda(y^{+},\Phi) \leq\sqrt{(\nabla\Phi(\tilde{y}^{+})-\nabla\Phi(y^{+}))^{\top} \nabla^{-2}\Phi(y^{+})(\nabla\Phi(\tilde{y}^{+})-\nabla\Phi(y^{+}))}\] \[\quad+\sqrt{\nabla\Phi(\tilde{y}^{+})^{\top}\nabla^{-2}\Phi(y^{+ })\nabla\Phi(\tilde{y}^{+})},\] \[\leq 2\sqrt{(\nabla\Phi(\tilde{y}^{+})-\nabla\Phi(y^{+}))^{\top} \nabla^{-2}\Phi(\tilde{y}^{+})(\nabla\Phi(\tilde{y}^{+})-\nabla\Phi(y^{+}))}\] \[\quad+\sqrt{\nabla\Phi(\tilde{y}^{+})^{\top}\nabla^{-2}\Phi(y^{+ })\nabla\Phi(\tilde{y}^{+})},\quad\text{(by (\ref{eq:1}) and $\varepsilon\leq 1/(40M_{\Phi})$)}\] \[\leq 20(1+\alpha)\varepsilon+(1+20(1+\alpha)\varepsilon)\cdot \lambda(\tilde{y}^{+},\Phi),\]

where the last inequality follows by (50) and (51). This completes the proof. 

### Proof of Lemma 6

Proof.: By definition of (\(w_{t}^{m}\)) in Algorithm 1, we have \(w_{t}^{1}=w_{t-1}\) and \(w_{t}=w_{t}^{m_{\mathtt{Newton}}}\). We show properties (23), (25), (26), and 27 using induction over \(m=1,\ldots,m_{\mathtt{Newton}}\).

Base case.We start with the base case; \(m=1\). Note that from the assumption in (22) and definition of \(w_{t}^{1}\), we have

\[\|w_{t}^{1}-u_{t-1}\|_{\nabla^{2}\Phi(u_{t-1})}\leq 1/(40M_{\phi}).\] (52)

Now, by definition of the Oracle \(\mathcal{O}_{\alpha}^{\mathtt{hess}}\) and the fact that \(H_{t-1}=\mathcal{O}_{\alpha}^{\mathtt{hess}}(u_{t-1})\) (see Algorithm 1) with \(\alpha=0.001\), we have

\[(1-0.001)\nabla^{2}\Phi(u_{t-1})\leq H_{t-1}\leq(1+0.001)\nabla^{2}\Phi(u_{t- 1}).\] (53)

Combining this with (52) implies property (25) for the base case. Furthermore, since \(w_{t}^{1}=u_{t-1}\) (by definition), (27) follows trivially for the base case.

Now, using that \(\Phi_{t}(w)=\Phi_{t-1}(w)+\eta g_{t-1}^{\top}w,\) we have

\[\lambda(w_{t}^{1},\Phi_{t})^{2} =\lambda(w_{t-1},\Phi_{t})^{2}\] \[=(\nabla\Phi_{t-1}(w_{t-1})+\eta g_{t-1})^{\top}\nabla^{-2}\Phi(w _{t-1})(\nabla\Phi_{t-1}(w_{t-1})+\eta g_{t-1})\] \[\leq 2\nabla\Phi_{t-1}(w_{t-1})^{\top}\nabla^{-2}\Phi(w_{t-1}) \nabla\Phi_{t-1}(w_{t-1})+2\eta^{2}g_{t-1}\nabla^{-2}\Phi(w_{t-1})g_{t-1}\] \[=2\lambda(w_{t-1},\Phi_{t-1})^{2}+2\eta^{2}g_{t-1}{}^{\top} \nabla^{-2}\Phi(w_{t-1})g_{t-1}\] (54) \[\leq 2\alpha^{2}+2\eta^{2}b^{2}\leq 1/(2500M_{\Phi}^{2}),\] (55)

where the last inequality follows by (22) and the fact that \(\|g_{t-1}\|_{\nabla^{-2}\Phi(w_{t-1})}\leq b\). This shows property (23) for the base case. Thus, by Lemma 1, we have, for \(w_{t}^{*}\in\operatorname*{argmin}_{w\in\mathcal{K}}\Phi_{t}(w)\),

\[\|w_{t}^{1}-w_{t}^{*}\|_{\nabla^{2}\Phi(w_{t}^{1})}=\|w_{t}^{1}-w_{t}^{*}\|_{ \nabla^{2}\Phi_{t}(w_{t}^{1})}\leq\lambda(w_{t}^{1},\Phi_{t})/(1-M_{\Phi} \lambda(w_{t}^{1},\Phi_{t}))\leq\frac{1}{49M_{\Phi}}.\] (56)

Now, combining (53) with the fact that \(\|u_{t-1}-w_{t}^{1}\|_{\nabla^{2}\Phi(u_{t-1})}=\|u_{t-1}-w_{t-1}\|_{\nabla^{2 }\Phi(u_{t-1})}\leq 1/(40M_{\Phi})\) (see (22)) and Lemma 2, we obtain

\[\left(\frac{31}{32}\right)^{2}H_{t-1}\leq\nabla^{2}\Phi(w_{t}^{1})\leq\left( \frac{32}{31}\right)^{2}H_{t-1},\] (57)

Plugging (57) into (56), we get

\[\|w_{t}^{1}-w_{t}^{*}\|_{H_{t-1}}\leq 1/(40M_{\Phi}).\] (58)Now, by the triangle inequality

\[\|u_{t-1}-w_{t}^{*}\|_{H_{t-1}} \leq\|u_{t-1}-w_{t}^{1}\|_{H_{t-1}}+\|w_{t}^{1}-w_{t}^{*}\|_{H_{t-1}}\] \[\leq 1/(20\Phi_{M}),\] (59)

where in the last inequality we used (22) and (58). Combining (59) with (53) and Lemma 1, we get

\[(4/5)\nabla^{2}\Phi(w_{t}^{*})\leq H_{t-1}\leq(5/4)\nabla^{2}\Phi(w_{t}^{*}).\] (60)

Combining Equations (60) and (57) implies property (24) for the base of Induction. Furthermore, note that from Lemma 1:

\[\|w_{t}^{1}-w_{t}^{*}\|_{\nabla^{2}\Phi(w_{t}^{*})}\leq\frac{50}{49}\lambda(w_ {t}^{1},\Phi_{t})\leq\frac{1}{49M_{\Phi}},\]

which shows property (26) for the base case.

Induction step.Now, assume that properties (23), (25), (26), and (27) hold for \(m\geq 1\). We will show that these properties holds for \(m+1\). From the hypothesis of induction, we have

\[\|w_{t}^{m}-u_{t-1}\|_{H_{t-1}}\leq\frac{1}{12M_{\Phi}},\]

which combined with (53) and Lemma 1 implies

\[0.84\nabla^{2}\Phi(w_{t}^{m})\leq H_{t-1}\leq 1.2\nabla^{2}\Phi(w_{t}^{m}).\] (61)

Thus, by Lemma 5 (instantiated with \(c=1/5\)) and the fact that \(\lambda(w_{t}^{m},\Phi_{t})\leq 1/(40M_{\Phi})\) (by the induction hypothesis), we get that for \(\tilde{w}_{t}^{m+1}\coloneqq w_{t}^{m}-H_{t-1}^{-1}\nabla\Phi_{t}(w_{t}^{m})\):

\[\lambda(\tilde{w}_{t}^{m+1},\Phi_{t})\leq 9M_{\Phi}\lambda(w_{t}^{m},\Phi_{t} )^{2}+2.5c\lambda(w_{t}^{m},\Phi_{t})\leq(7/8)\lambda(w_{t}^{m},\Phi_{t}).\]

Again, by Lemma 5 with \(c=1/5\), we have

\[\lambda(w_{t}^{m+1},\Phi_{t}) \leq 20(1+c)\varepsilon+(1+20(1+c)\varepsilon)\lambda(\tilde{w}_{t }^{m+1},\Phi)\] \[\leq 25\varepsilon+\left(\frac{15}{16}\right)\lambda(w_{t}^{m}, \Phi_{t})\leq 1/(50M_{\Phi}).\] (62)

By the induction hypothesis, we also have that \(\lambda(w_{t}^{m},\Phi_{t})\leq\left(\frac{15}{16}\right)^{m-1}\lambda(w_{t}^ {1},\Phi_{t})+500\varepsilon\). Combining this with (62), we get

\[\lambda(w_{t}^{m+1},\Phi_{t})\leq \left(\frac{15}{16}\right)^{m}\lambda(w_{t}^{1},\Phi_{t})+500\varepsilon.\] (63)

This shows that (23) holds with \(m\) replaced by \(m+1\).

Next, we show that (25) holds with \(m\) replaced by \(m+1\). Combining (62) with Lemma 1 implies

\[\|w_{t}^{m+1}-w_{t}^{*}\|_{\nabla^{2}\Phi(w_{t}^{*})}\leq\lambda(w_{t}^{m+1}, \Phi_{t})/(1-M_{\Phi}\lambda(w_{t}^{m+1},\Phi_{t}))\leq 1/(49M_{\Phi}).\]

This, together with (60) gives

\[\|w_{t}^{m+1}-w_{t}^{*}\|_{H_{t-1}}\leq 1/(32M_{\Phi}).\] (64)

Combining (59) with (64) gives:

\[\|w_{t}^{m+1}-u_{t-1}\|_{H_{t-1}}\leq\frac{1}{12M_{\Phi}},\]

which proves that (25) holds with \(m\) replaced by \(m+1\).

Next, we show that (26) holds with \(m\) replaced by \(m+1\). By (63) and Lemma 1, we have

\[\|w_{t}^{m+1}-w_{t}^{*}\|_{\nabla^{2}\Phi(w_{t}^{*})} \leq\frac{50}{49}\left(\frac{15}{16}\right)^{m}\lambda(w_{t}^{1},\Phi_{t})+240\varepsilon,\] \[\leq\frac{1}{49M_{\Phi}}\left(\frac{15}{16}\right)^{m}+240 \varepsilon\leq\frac{1}{20M_{\Phi}},\] (65)where in the last inequality we used (55) and the bound on \(\varepsilon\) in the lemma's statement. This shows that (26) holds with \(m\) replaced by \(m+1\).

Next, we show that (27) holds with \(m\) replaced by \(m+1\). By plugging (60) into (65), we get

\[\|w_{t}^{m+1}-w_{t}^{*}\|_{H_{t-1}}\leq\frac{1}{40M_{\Phi}}\left(\frac{15}{16} \right)^{m}+300\varepsilon.\] (66)

On the other hand, by (54), we have

\[\lambda(w_{t}^{1},\Phi_{t}) \leq\sqrt{\nabla\Phi_{t-1}(w_{t-1})^{\top}(\nabla^{2}\Phi(w_{t-1} ))^{-1}\nabla\Phi_{t-1}(w_{t-1})}+\sqrt{\eta^{2}{g_{t-1}}^{\top}(\nabla^{2} \Phi(w_{t-1}))^{-1}g_{t-1}}\] \[=\lambda(w_{t-1},\Phi_{t-1})+\eta\|g_{t-1}\|_{\nabla^{-2}\Phi(w_{ t-1})}.\]

Plugging this into (56) and using (55), we get

\[\|w_{t}^{1}-w_{t}^{*}\|_{\nabla^{2}\Phi(w_{t}^{1})} \leq\frac{50}{49}(\lambda(w_{t-1},\Phi_{t-1})+\eta\|g_{t-1}\|_{ \nabla^{-2}\Phi(w_{t-1})}),\] \[\leq\frac{50}{49}(\alpha+\eta\|g_{t-1}\|_{\nabla^{-2}\Phi(w_{t-1 })}),\] (67)

where the last inequality follows by (22). Combining (67) with (61) (instantiated with \(m=1\)),

\[\|w_{t}^{1}-w_{t}^{*}\|_{H_{t-1}}\leq 2(\alpha+\eta\|g_{t-1}\|_{\nabla^{-2} \Phi(w_{t-1})}).\] (68)

Now, by (66), (68), and the triangle inequality, we have

\[\|w_{t}^{1}-w_{t}^{m+1}\|_{H_{t-1}}\leq 2\eta\|g_{t-1}\|_{\nabla^{-2}\Phi(w _{t-1})}+\frac{1}{40M_{\Phi}}\left(\frac{15}{16}\right)^{m}+500\varepsilon+2\alpha.\]

Via another triangle inequality, we get

\[\left|\|u_{t-1}-w_{t}^{m+1}\|_{H_{t-1}}-\|u_{t-1}-w_{t-1}\|_{H_{t- 1}}\right| \leq 2\eta\|g_{t-1}\|_{\nabla^{-2}\Phi(w_{t-1})}+\frac{1}{40M_{ \Phi}}\left(\frac{15}{16}\right)^{m}\] \[+500\varepsilon+2\alpha.\]

This shows that (27) holds with \(m\) replaced by \(m+1\). Finally, combining (60) with (61) implies

\[\frac{1}{2}\nabla^{2}\Phi(w_{t}^{m})\leqslant\nabla^{2}\Phi(w_{t}^{*})\leqslant 2 \nabla^{2}\Phi(w_{t}^{m}),\]

which completes the proof.

## Appendix E Helper Lemmas

**Lemma 8** (Bounding norm of the Newton step).: _Let \(y\in\mathcal{K}\) and \(H\in\mathbb{R}^{d\times d}\) be such that \((1-c)\nabla^{2}\Phi(y)\leqslant H\preccurlyeq(1+c)\nabla^{2}\Phi(y)\). Then, for \(h\coloneqq-H^{-1}\nabla\Phi(y)\), we have_

\[\|h\|_{\nabla^{2}\Phi(y)}\leq\frac{1}{1-c}\|\nabla\Phi(y)\|_{\nabla^{-2}\Phi( y)}.\]

Proof.: We can write

\[\|h\|_{\nabla^{2}\Phi(y)} =\|H^{-1}\nabla\Phi(y)\|_{\nabla^{2}\Phi(y)}\] \[=\sqrt{\nabla\Phi(y)^{\top}H^{-1}\nabla^{2}\Phi(y)H^{-1}\nabla \Phi(y)}\] \[=\sqrt{\nabla\Phi(y)^{\top}\nabla^{2}\Phi(y)^{-1/2}\Big{(}\nabla^ {2}\Phi(y)^{1/2}H^{-1}\nabla^{2}\Phi(y)^{1/2}\Big{)}^{2}\nabla^{2}\Phi(y)^{-1/ 2}\nabla\Phi(y)}.\] (69)

For the middle matrix \(\nabla^{2}\Phi(y)^{1/2}H^{-1}\nabla^{2}\Phi(y)^{1/2}\) we have that

\[\frac{1}{1+c}I\leqslant\nabla^{2}\Phi(y)^{1/2}H^{-1}\nabla^{2}\Phi(y)^{1/2} \leqslant\frac{1}{1-c}I,\]

since \((1-c)\nabla^{2}\Phi(y)\leqslant H\preccurlyeq(1+c)\nabla^{2}\Phi(y)\) by assumption. Plugging this back into (69), we get

\[\|h\|_{\nabla^{2}\Phi(y)}\leq\frac{1}{1-c}\big{|}\nabla\Phi(y)\|_{\nabla^{2} \Phi(y)^{-1}}.\]

**Lemma 9** (Cauchy-Schwarz).: _If \(-B\leqslant A\leqslant B\) are symmetric matrices and \(B\) is PSD, then_

\[x^{\top}Ay\leq\|x\|_{B}\|y\|_{B}.\]