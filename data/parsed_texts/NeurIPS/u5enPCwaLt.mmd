# Towards Estimating Bounds on the Effect of Policies under Unobserved Confounding

 Alexis Bellot*  Silvia Chiappa

Google DeepMind

London, UK

Correspondence to Alexis Bellot: abellot@google.com

###### Abstract

As many practical fields transition to provide personalized decisions, data is increasingly relevant to support the evaluation of candidate plans and policies (_e.g._, guidelines for the treatment of disease, government directives, etc.). In the machine learning literature, significant efforts have been put into developing machinery to predict the effectiveness of policies efficiently. The challenge is that, in practice, the effectiveness of a candidate policy is not always identifiable, _i.e._, not uniquely estimable from the combination of the available data and assumptions about the domain at hand (_e.g._, encoded in a causal graph). In this paper, we develop graphical characterizations and estimation tools to bound the effect of policies given a causal graph and observational data collected in non-identifiable settings. Specifically, our contributions are two-fold: (1) we derive analytical bounds for general probabilistic and conditional policies that are tighter than existing results, (2) we develop an estimation framework to estimate bounds from finite samples, applicable in higher-dimensional spaces and continuously-valued data. We further show that the resulting estimators have favourable statistical properties such as fast convergence and robustness to model misspecification.

## 1 Introduction

Understanding how to act upon the world around us requires humans and artificial systems to thoughtfully evaluate the effect of different plans, policies, and interventions one might consider. Data and methods that facilitate this process are increasingly relevant for high-stakes decision-making, notably in medical care with the rise of precision medicine [41], but also in education [25], law enforcement [13], public policy [44], and economics [2]. The interventions that a practitioner might consider, could consist of complex policies where a variable is set to follow a conditional or stochastic relationship depending on other variables in the system. For example, policy-makers might contemplate higher taxes on processed foods and stronger campaigns on its health risks targeted to overweight individuals. A sensible question in this context could be "what is the effect of a policy that reduces the consumption of processed foods by \(50\%\) in people with a body mass index above 30?". Contrary to atomic (also called hard) interventions that force a particular value, this policy suggests a _softer_ intervention.

The identifiability and estimation of policies from data is a widely studied problem in the reinforcement learning [37; 39] and causal inference [2; 12; 15; 31; 32; 40] literatures. Despite the generality entailed by many common approaches in these fields, they often rely on an impractical condition: the assumption that the effectiveness of the policy is uniquely computable from the observed data and

[MISSING_PAGE_FAIL:2]

For a sample set \(\mathcal{D}:=\{\bm{v}^{(i)}\}_{i=1,\ldots,n}\sim P\), we use \(\mathbb{E}_{\mathcal{D}}[f(\bm{V})]:=(1/n)\sum_{i=1}^{n}f(\bm{v}^{(i)})\). We use \(\|f\|_{P}:=\sqrt{\mathbb{E}_{P}[\{f(\bm{V})\}^{2}]}\). \(\hat{f}-f=o_{P}(r_{n})\) denotes that a function \(\hat{f}\) is a consistent estimator of \(f\) at a rate \(r_{n}\), \(\hat{f}-f=O_{P}(r_{n})\) denotes that it is bounded in probability at rate \(r_{n}\).

## 2 Partial Identification of the Effect of Policies

A policy \(\bm{\pi}\) over a subset \(\bm{X}\subset\bm{V}\) is a sequence of decision rules or plans \(\bm{\pi}:=\{\pi_{X}\}_{X\in\bm{X}}\) for determining the assignment of variables \(\bm{X}\). In its most general form, every \(\pi_{X}:\text{supp}_{X}\times\text{supp}_{\mathcal{C}_{X}}\to[0,1]\) is a probability mapping from domain of \(\bm{C}_{X}\subset\bm{C}\subset\bm{V}\) to the domain of \(X\).

Qualitatively different types of interventions may be modelled with \(\pi_{X}\). Specifically, a deterministic intervention setting \(X:=g(\bm{c}_{X})\) based on the values of \(\bm{C}_{X}\) can be encoded as \(\pi_{X}(x\mid\bm{c}_{X}):=\mathbb{1}_{g(\bm{c}_{X})}(x)\) while a probabilistic intervention may be written \(\pi_{X}(x\mid\bm{c}_{X}):=P_{\text{induced by}\pi_{X}}(X=x\mid\bm{c}_{x})\). The intervened model \(\mathcal{M}_{\bm{\pi}}\) represents a different regime in which the assignment \(\{f_{X}\}_{X\in\bm{X}}\) is replaced with the assignment induced by \(\bm{\pi}\). For an outcome \(Y\in\bm{V}\), the interventional distribution \(P_{\mathcal{M}_{\bm{\pi}}}(Y)\), equivalently \(P_{\bm{\pi}}(Y)\), is defined as the distribution over \(Y\) in \(\mathcal{M}_{\bm{\pi}}\). It will be useful to adopt the notation \(\bar{\bm{\pi}}:=\prod_{X\in\bm{X}}\pi_{X}(x\mid\bm{c}_{X})\) to denote the product of policy assignments on individual variables subject to intervention in \(\bm{\pi}\).

**Example 1** (Illustration of policies).: In the context of a public health program, let \(X\) be a measure of an individual's weekly physical exercise routine, \(C\) an individual's family history of metabolic diseases, and \(Y\) hospital admissions related to heart disease. Consider the causal diagram Fig. 0(a); currently, an individuals exercise voluntarily, which depends on unobserved factors that could be associated with risk of heart disease. The government is considering an incentive plan aimed at increasing the frequency of exercise depending individual's family history of metabolic diseases (with some probability). The proposed intervention can be encoded as \(\bm{\pi}=\{\pi_{X}\}\) and sets the new assignment \(\tilde{f}_{X}\) such that the variable \(X\) follows the pre-specified distribution. Graphically, this policy is represented by Fig. 0(b) (with the new edge corresponding to the implementation of the policy highlighted in blue) and may be evaluated with the following quantity,

\[\mathbb{E}_{P_{\bm{\pi}}}[Y]=\sum_{x,c}\mathbb{E}_{P_{\bm{\pi}}}[Y\mid x,c]\pi _{X}(x\mid c)P_{\bm{\pi}}(c).\] (1)

The inferential challenge is that this quantity is not uniquely computable from \(P(x,y,c)\) and \(\mathcal{G}\), requiring more complex and nuanced notions of policy evaluation.

Formally, we are interested in the evaluation of the effectiveness of a plan or policy \(\bm{\pi}\), acting on a (potentially multivariate) discrete action \(\bm{X}\) based on values of observed covariates \(\bm{C}\in\mathbb{R}^{d}\), on an outcome of interest \(Y\in[0,1]\)2.

Footnote 2: An upper bound of 1 is assumed for simplicity; the following results could be generalized to more general bounded random variables.

**Definition 1** (Average treatment effect).: _The effectiveness of a policy \(\bm{\pi}\) on \(Y\) is \(\mathbb{E}_{P_{\bm{\pi}}}[Y]\)._

From the investigator's perspective, only the causal diagram \(\mathcal{G}\) of the environment \(\mathcal{M}\) is available. No assumptions about the form or shape of \(P(\bm{U})\) and \(\mathcal{F}\) are made, but for the structural knowledge encoded in \(\mathcal{G}\). In general, there might exist multiple SCMs \(\mathcal{M}\) that induce the same causal diagram \(\mathcal{G}\) and entail \(P(\bm{V})\) but result in different values of \(\mathbb{E}_{P_{\bm{\pi}}}[Y]\). The identification of a _set_ of possible solutions that contain the true value of \(\mathbb{E}_{P_{\bm{\pi}}}[Y]\) leads to the notion of _partial identification_.

**Definition 2** (Partial Identification).: _The effectiveness of a policy \(\bm{\pi}\) is said to be partially identifiable from \(\mathcal{G}\) and \(P(\bm{v})\) if_

\[\psi^{\ell}(P)\leq\mathbb{E}_{P_{\mathcal{M}_{\bm{\pi}}}}[Y]\leq\psi^{u}(P), \quad\text{ for any $\mathcal{M}$ such that }\mathcal{G}_{\mathcal{M}}=\mathcal{G},P_{\mathcal{M}}(\bm{v})=P(\bm{v}),\] (2)

_where \((\psi^{\ell},\psi^{u})\) are functionals of \(P\) that are bounded away from \(0\) and \(1\), respectively._

The earliest bound on the effect of policies, the so-called _natural bounds_, were developed considering discrete atomic interventions, i.e. of the form \(\pi_{X}=\mathbb{1}_{x}(X),X\in\{1,\ldots,d_{X}\}\).

Figure 1: Graphs for Example 1.

**Proposition 1** (Natural Bounds).: _For any \(\bm{x}\), \(\mathbb{E}_{P}[Y\bm{1}_{\bm{x}}(\bm{X})]\leqslant\mathbb{E}_{P_{\bm{x}}}[Y] \leqslant\mathbb{E}_{P}[(Y-1)\bm{1}_{\bm{x}}(\bm{X})]+1.\)_

Remarkably, these inequalities hold irrespective of the causal graph of the system \(\mathcal{G}\); a result that dates back to [27; 33]. Similarly, we could adapt the underlying proof strategy to derive functionals of \(P\) that bound the effect of more general probabilistic or conditional policies \(\bm{\pi}\), given as follows.

**Proposition 2** (Natural Policy Bounds (NPB)).: _For any \(\bm{\pi}\), \(\mathbb{E}_{P}[Y\bm{\bar{\pi}}]\leqslant\mathbb{E}_{P_{\bm{x}}}[Y]\leqslant \mathbb{E}_{P}[(Y-1)\bm{\bar{\pi}}]+1.\)_

These inequalities also hold irrespective of the causal graph of the system. The natural bounds from [27; 33] are a special case of the natural policy bounds (NPBs) by setting \(\bm{\pi}:=\{\pi_{X}\}_{X\in\bm{X}}\) where \(\pi_{X}:=\mathbb{I}_{x}(X)\), and therefore \(\bm{\bar{\pi}}=\mathbb{I}_{\bm{x}}(\bm{X})\). We could show that the NPBs are tight in some cases. For example, in Example 1, provably, no better bounds for \(\mathbb{E}_{P_{\bm{x}}}[Y]\) than those defined by Prop. 2 could be derived (a result given in Prop. 10 in Appendix B). For other systems that involve variables that are "separated" in \(\mathcal{G}\), however, better bounds may be derived by exploiting the implications of the causal graph and definition of the policy on the induced observational and interventional distributions. Consider the following example as a first illustration of this idea.

**Example 2** (Tighter bounds with causal diagram).: We are interested in evaluating the effect of a policy \(\bm{\pi}:=\{\pi_{X_{1}}(x_{1}\mid c),\mathbb{I}_{x_{2}}(X_{2})\}\) from \(P(x_{1},c,x_{2},y)\) and \(\mathcal{G}\) in Fig. 1(a). In particular, this problem involves a stochastic conditional intervention on \(X_{1}\) given \(C\) and a deterministic intervention on \(X_{2}\); both variables having differing dependencies onto the rest of the system. We could show that,

\[\mathbb{E}_{P_{\bm{\pi}}}[Y]=\mathbb{E}_{P_{\bm{x}_{X_{1}}}}[Y]\geqslant \mathbb{E}_{P}[Y\pi_{X_{1}}]=\psi^{\ell}(P).\] (3)

The inequality gives an expression for the bound in terms of \(P\) that exploits the fact that intervening on \(X_{2}\) does not influence \(Y\), and is tighter that the natural policy lower bound as \(\psi^{\ell}(P)\geqslant\mathbb{E}_{P}[Y\pi_{X_{1}}]P(X_{2}=x_{2})=\mathbb{E}_{ P}[Y\pi_{X_{1}}\mathbb{I}_{x_{2}}(X_{2})]\)\((=\text{NPB})\). For the upper bound we could similarly establish that,

\[\mathbb{E}_{P_{\bm{\pi}}}[Y]\leqslant\mathbb{E}_{P}\left[(Y-1)\pi_{X_{1}} \right]+1=\psi^{u}(P).\] (4)

which is smaller than the natural policy bound as \(\psi^{u}(P)\leqslant\mathbb{E}_{P}[(Y-1)\pi_{X_{1}}\mathbb{I}_{x_{2}}(X_{2}) ]+1\)\((=\text{NPB})\).

This example, although relatively straightforward, serves to illustrate the potential of causal diagrams (and the constraints they imply on the effect of policies) for defining tighter bounds.

## 3 Graphical Criteria for Partial Identification

This section aims to consider more general separation statements between variables encoded in a causal diagram and the decomposition they imply to provide a systematic algorithm to bound the effectiveness of policies. We start by introducing the notion of _partial adjustment sets_ (Def. 3) that is applicable with multiple intervention variables.

**Definition 3** (Partial adjustment set).: _Let \(\bm{\pi}:=\{\pi_{\bm{X}_{1}},\pi_{\bm{X}_{2}}\}\) be a policy on \(\{\bm{X}_{1},\bm{X}_{2}\}\) with a conditioning set \(\bm{C}\). A set \(\bm{W}\subseteq\bm{V}\backslash(\bm{X}_{1}\cup\bm{X}_{2}\cup\bm{C}\cup\bm{V})\) is said to be a partial adjustment set for \(\pi_{\bm{X}_{2}}\) in \(\mathcal{G}\) if \((Y\bm{\perp}_{d}\bm{X}_{2}\mid\bm{W},\bm{C},\bm{X}_{1})_{\mathcal{G}_{\pi_{\bm{ X}_{1}}}\bm{X}_{2}}\)._

**Proposition 3**.: _Let \(\bm{\pi}:=\{\pi_{\bm{X}_{1}},\pi_{\bm{X}_{2}}\}\) be a policy mapping a set of covariates \(\bm{C}\) to a set of treatment variables \(\{\bm{X}_{1},\bm{X}_{2}\}\). Let \(\bm{W}\) be a partial adjustment set for \(\pi_{\bm{X}_{2}}\) in \(\mathcal{G}\). Then,_

\[\mathbb{E}_{P}[Y\bm{\bar{\pi}}\gamma]\leqslant\mathbb{E}_{P_{\bm{\pi}}}[Y] \leqslant\mathbb{E}_{P}[(Y-1)\bm{\bar{\pi}}\gamma]+1,\] (5)

_where \(\gamma:=\gamma(\bm{X},\bm{C},\bm{W})=1/P(\bm{X}_{2}\mid\bm{C},\bm{W})\)._

In words, partial adjustment sets are designed to exploit the unconfounded status of some intervention variables with respect to the outcome, and could be leveraged to derive tighter bounds when available.

Figure 2: Graphs used in Sec. 2 and 3.

**Example 3** (Tighter bounds with partial adjustment sets).: Consider the problem of evaluating the effect of a policy \(\bm{\pi}:=\{\pi_{X_{1}}(x_{1}\mid c),\pi_{X_{2}}(x_{2}\mid c)\}\) from \(P(x_{1},c,x_{2},w,y)\) and \(\mathcal{G}\) in Fig. 1(b). Following Def. 3, we could establish that \(\bm{W}=\emptyset\) is a valid partial adjustment set for \(\pi_{X_{2}}\) since we can verify that \((Y\mbox{\scalebox{1.0}{$\perp\mskip-1.0mu \perp$}}_{d}X_{2}\mid C,X_{2}) _{\mathcal{G}_{\pi_{X_{1}}}X_{2}}\). Prop. 3 then gives us a valid expression for bounding the effect of the policy,

\[\mathbb{E}_{P_{\bm{\pi}}}[Y]\geq\mathbb{E}_{P}\left[Y\bar{\bm{\pi}}/P(X_{2} \mid C)\right] (\geq\mathbb{E}_{P}[Y\bar{\bm{\pi}}],\text{ the NPB}).\] (6)

For the upper bound we similarly find that,

\[\mathbb{E}_{P_{\bm{\pi}}}[Y]\leq\mathbb{E}_{P}\left[(Y-1)\bar{\bm{\pi}}/P(X_{2} \mid C)\right]+1 (\leq\mathbb{E}_{P}[(Y-1)\bar{\bm{\pi}}]+1,\text{ the NPB}).\] (7)

Next, we define a second useful notion, so-called _partial conditional instrumental variables sets_, that can be exploited to evaluate bounds in \(\bm{z}\)-specific distributions \(P(\mathbbm{1}_{\bm{z}}(\bm{Z})/P(\bm{Z}))\) instead of in \(P\) as described in Prop. 4.

**Definition 4** (Partial conditional instrumental set).: _A set \(\bm{Z}\subseteq\bm{V}\) is said to be a partial instrumental set conditional on \(\bm{R}\) for a policy \(\bm{\pi}\) in \(\mathcal{G}\) if \((Y\mbox{\scalebox{1.0}{$\perp\mskip-1.0mu \perp$}}_{d}\bm{Z}\mid\bm{R})_{\mathcal{G}_{\bm{\pi}}}\)._

For illustration, we give a simple criterion below to show how this subgroup structure could be exploited to derive tighter bounds.

**Proposition 4**.: _Let \(\bm{Z}\) be an unconditional partial instrumental set with respect to a policy \(\bm{\pi}\), i.e. \((Y\mbox{\scalebox{1.0}{$\perp\mskip-1.0mu \perp$}}_{d}\bm{Z})_{\mathcal{G}_{\bm{\pi}}}\). Then,_

\[\max_{\bm{z}}\mathbb{E}_{P}[Y\bar{\bm{\pi}}\mathbbm{1}_{\bm{z}}(\bm{Z})/P(\bm {Z})]\leq\mathbb{E}_{P_{\bm{\pi}}}[Y]\leq\min_{\bm{z}}\mathbb{E}_{P}[(Y-1) \bar{\bm{\pi}}\mathbbm{1}_{\bm{z}}(\bm{Z})/P(\bm{Z})]+1.\] (8)

The following example shows that partial adjustment sets and partial conditional instrumental sets may be usefully combined to derive tighter bounds than would be available had each proposition (Props. 3 and 4) been applied in isolation.

**Example 4** (Tighter bounds with partial adjustment and instrumental sets).: For this example, consider the evaluation of an atomic intervention \(\bm{\pi}:=\{\mathbbm{1}_{x_{1}}(X_{1}),\mathbbm{1}_{x_{2}}(X_{2})\}\) in the causal diagram \(\mathcal{G}\) given in Fig. 1(c). Note that \(\bar{\bm{\pi}}=\mathbbm{1}_{\bm{x}}(\bm{X})\). Following Def. 3, \(\{\emptyset\}\) is a valid partial adjustment set for \(\pi_{X_{1}}\) since we can verify that \((Y\mbox{\scalebox{1.0}{$\perp\mskip-1.0mu \perp$}}_{d}X_{2}\mid X_{1})_{ \mathcal{G}_{\pi_{X_{1}}}X_{2}}\). Further, we could verify that \(\{Z\}\) is a partial instrumental set conditional on \(\{X_{2}\}\) with respect to \(\pi_{X_{1}}\) since \((Y\mbox{\scalebox{1.0}{$\perp\mskip-1.0mu \perp$}}_{d}Z\mid X_{2})_{ \mathcal{G}_{\pi_{X_{1}}}}\). These two separation statements in (manipulated versions of) \(\mathcal{G}\) could be leveraged to derive a tighter bound than previously considered:

\[\max_{z}\mathbb{E}_{P}[Y\bar{\bm{\pi}}\mathbbm{1}_{z}(Z)/P(X_{2},Z)]\leq\mathbb{E}_{P_{\bm{\pi}}}[Y]\] \[\leq\min_{z}\mathbb{E}_{P}[(Y-1)\bar{\bm{\pi}}\mathbbm{1}_{z}(Z) /P(X_{2},Z)]+1.\]

To derive bounds in a more systematic fashion, combining the notions developed so far, we present Alg. 1 that recursively seeks to find partial adjustment and partial instrumental sets in an efficient and automatic manner.

Intuitively, Alg. 1 seeks to recursively simplify the query. First by omitting the intervened variables that have no effect on the outcome; second by finding the set of intervened variables for which a partial adjustment set could be used to tighten the bound, and third by finding the set of variables that act as valid partial instrumental sets to evaluate bounds on the most favorable conditional distributions rather than on the joint distribution.

[MISSING_PAGE_FAIL:6]

Estimation of the Effect of Policies

This section aims to develop an estimation framework for the effect of a policy \(\mathbb{E}_{P_{\bm{\pi}}}[Y]\) given finite samples from \(P\) that partially identifies its value. The key observation of this section is that multiple characterizations for estimation could be derived for a given bound returned by lines 20-21 in Alg. 1.

In a first instance, parameterized by the probability ratio given in Alg. 1 defined by \(\bm{\gamma}=(\gamma_{1},\gamma_{2})\),

\[T^{\text{PW},\ell}:=\mathbb{E}_{P}[\gamma_{2}Y]\ \ \ (=\psi_{\bm{z}}^{\ell}),\qquad \gamma_{2}:=\bar{\pi}_{\bm{U}}\gamma_{1},\quad\gamma_{1}:=\bar{\pi}_{\bm{T}} \mathbbm{1}_{\bm{z}}(\bm{Z})/P(\bm{T},\bm{Z}\mid\bm{W}\backslash\bm{Z},\bm{C}).\] (10)

In a second instance, parameterized by a collection of regression parameters \(\bm{\mu}=(\mu_{0},\mu_{1},\tilde{\mu}_{1},\mu_{2})\) where

\[\mu_{2} :=\mu_{2}(\bm{R},\bm{C},\bm{W},\bm{Z})=\mathbb{E}_{P}[Y\mid\bm{R},\bm{C},\bm{W},\bm{Z}],\] (11) \[\tilde{\mu}_{1} :=\tilde{\mu}_{1}(\bm{R},\bm{C},\bm{W},\bm{Z})=\bar{\pi}_{\bm{U}} (\bm{U}\mid\bm{C})\mu_{2}(\bm{R},\bm{C},\bm{W},\bm{Z}),\] (12) \[\mu_{1} :=\mu_{1}(\bm{T},\bm{C},\bm{W},\bm{Z})=\mathbb{E}_{P}[\tilde{\mu }_{1}(\bm{R},\bm{C},\bm{W},\bm{Z})\mid\bm{T},\bm{C},\bm{W},\bm{Z}],\] (13) \[\mu_{0} :=\mu_{0}(\bm{C},\bm{W},\bm{Z})=\sum_{\bm{t}}\mu_{1}(\bm{t},\bm{C},\bm{W},\bm{Z})\bar{\pi}_{\bm{T}}(\bm{t}\mid\bm{C}).\] (14)

\(T^{\text{REG},\ell}:=\mathbb{E}_{P}[\mu_{0}(\bm{C},\bm{W},\bm{z})]\) could be shown to equal \(\psi_{\bm{z}}^{\ell}\).

Both formulations define equivalent but different estimation targets for the lower bound3 and may be combined leveraging the double machine learning (DML) toolkit for more efficient and robust inferences [10].

Footnote 3: For the upperbound, a similar construction could be derived by defining \(T^{\text{PW},u}:=\mathbb{E}_{P}[\gamma_{2}(Y-1)]+1\), and \(T^{\text{REG},u}:=\mathbb{E}_{P}[\mu_{0}(\bm{C},\bm{W},\bm{z})]+1\) with \(Y\) replaced by \(Y-1\) in the definition of \(\mu_{2}\). Both estimators could be shown to be unbiased, i.e. equal to \(\psi_{\bm{u}}^{\ell}\) defined in Alg. 1.

The following procedure is the main contribution of this section. It defines a DML estimator for bounding the effectiveness \(\mathbb{E}_{P_{\bm{\pi}}}[Y]\) of a policy \(\bm{\pi}\).

**Definition 5** (DML Estimator).: _Given \(\bm{\pi}\) and \(\mathcal{G}\), let \(\{\bm{R},\bm{T},\bm{W},\bm{C},\bm{Z},Y\}\) be defined as in Alg. 1. Consider a finite sample of data \(\mathcal{D}\sim P\), randomly split into \(K\) folds. The \(k\)'th partition of the sample is denoted \(\mathcal{D}^{(k)}\) and \(\mathcal{D}^{(-k)}:=\mathcal{D}\backslash\mathcal{D}^{(k)}\). For each \(k\), learn approximate nuisances \((\hat{\bm{\gamma}}_{k},\hat{\bm{\mu}}_{k})\) with \(D^{(-k)}\). Then, define_

\[\Big{(}\max_{\bm{z}}\ \hat{T}^{\text{DML},\ell}\,\ \min_{\bm{z}}\ \hat{T}^{\text{DML},u}\ \Big{)}\] (15)

_to be an estimate for the bounds on \(\mathbb{E}_{P_{\bm{\pi}}}[Y]\) where,_

\[\hat{T}^{\text{DML},\ell} :=\frac{1}{K}\sum_{k=1}^{K}\mathbb{E}_{\mathcal{D}^{(k)}}[\hat{ \gamma}_{2,k}\{Y-\hat{\mu}_{2,k}\}]+\mathbb{E}_{\mathcal{D}^{(k)}}[\hat{\gamma }_{1,k}\{\hat{\hat{\mu}}_{1,k}-\hat{\mu}_{1,k}\}]+\mathbb{E}_{\mathcal{D}^{(k )}}[\hat{\mu}_{0,k}]\] \[\hat{T}^{\text{DML},u} :=1+\frac{1}{K}\sum_{k=1}^{K}\mathbb{E}_{\mathcal{D}^{(k)}}[\hat{ \gamma}_{2,k}\{(Y-1)-\hat{\mu}_{2,k}\}]+\mathbb{E}_{\mathcal{D}^{(k)}}[\hat{ \gamma}_{1,k}\{\hat{\hat{\mu}}_{1,k}-\hat{\mu}_{1,k}\}]+\mathbb{E}_{\mathcal{ D}^{(k)}}[\hat{\mu}_{0,k}].\]

To analyse the error of the DML estimator, we consider the case that nuisances can be estimated consistently. Thus requirement is relatively mild in practice as accurate probability estimation employing off-the-shelf classification and regression methods is feasible in general. Its error with respect to the true bounds is given by the following proposition.

**Proposition 8** (Error rates).: _Suppose the nuisance estimates \((\hat{\bm{\mu}},\hat{\bm{\gamma}})\) are \(L_{2}\)-consistent and bounded. Then, the error of the DML estimator \(\hat{T}^{\text{DML}}\in\{\hat{T}^{\text{DML},\ell},\hat{T}^{\text{DML},u}\}\) in Def. 5 is given as follows_

\[\hat{T}^{\text{DML}}-T^{\text{DML}}=\frac{1}{K}\sum_{k=1}^{K}R_{k}+O_{P}\Big{(} \|\hat{\gamma}_{2,k}-\gamma_{2}\|\hat{\mu}_{2,k}-\mu_{2}\|\Big{)}+O_{P}\Big{(} \|\hat{\gamma}_{1,k}-\gamma_{1}\|\hat{\mu}_{1,k}-\hat{\hat{\hat{\mu}}}_{1,k} \|\Big{)}\]

_where \(R_{k}\) is a random variable that converges to zero at a rate \(\mathcal{O}_{P}(1/\sqrt{n})\)._

In words, the DML estimator exhibits a robustness property since the error of \(\hat{T}^{\text{DML}}\) is bounded in probability at \(n^{-1/2}\) rate whenever the nuisances converge at a rate \(n^{-1/4}\). Note that the term \(\|\hat{\hat{\mu}}_{1,k}-\hat{\mu}_{1,k}\|\) quantifies the error in approximating the conditional expectation in Eq. (13) for a given \(\hat{\mu}_{1}\) estimated at that stage, and that the estimation error of \(\hat{\gamma}_{2}\) and \(\hat{\gamma}_{2}\) are equivalent since they are deterministic transformations of each other. The following proposition is a corollary that shows that the DML estimator is unbiased under misspecification.

**Proposition 9** (Bias under misspecification).: _Suppose either \(\hat{\gamma}_{1}=\gamma_{1}\) or \(\hat{\mu}_{2}=\mu_{2}\) and that either \(\hat{\gamma}_{1}=\gamma_{1}\) or \(\hat{\hat{\bar{\mu}}}_{1}=\hat{\mu}_{1}\). Then, \(\hat{T}^{\text{DML}}\in\{\hat{T}^{\text{DML},\hat{t}},\hat{T}^{\text{DML},u}\}\) is an unbiased estimator of the corresponding bound defined in Alg. 1._

## 5 Experiments

This section evaluates the quality of policy effect estimation from finite samples. Our goal is to illustrate the computation of bounds and provide empirical evidence of the fast convergence and robustness to misspecification of estimators.

Finite sample bounds are estimated with gradient boosting classification and regression models (for conditional expectations) or by taking sample averages (for unconditional expectations). We truncated estimates of probability mass functions in the interval \([0.01,0.99]\) to ensure positivity. We assess the quality of an estimator \(\hat{T}\) by computing the absolute average error (AAE) with respect to (a proxy for) the true bounds (estimated in practice with larger sample sizes), _i.e._, AAE = \(|\hat{T}^{u}-\min_{z}\psi_{\mathbf{z}}^{u}|+|\hat{T}^{\ell}-\max_{\mathbf{z}} \psi_{\mathbf{z}}^{\ell}|\). Throughout, we report various statistics: 25th, 50th, 75th percentile, etc., across evaluation runs with ten different random seeds. Further details of the simulations are provided in Appendix C.

### Synthetic Simulations

The synthetic simulations consider 4 data generating mechanisms constructed according to the graphs in Fig. 4. They highlight the use of partial instrumental sets, partial adjustment sets, high-dimensional partial adjustment sets, and combinations of partial instrumental and adjustment sets of varying dimensionality. The task is to estimate bounds on the effectiveness of a policy \(\boldsymbol{\pi}:=\{\pi_{X_{1}},\pi_{X_{2}}\}\) defined as follows.

\[\pi_{X_{1}}:=\pi_{X_{1}}(X_{1}=1)=0.5,\quad\pi_{X_{2}}:=\pi_{X_{2}}(X_{2}=1 \mid c)=1/(1-\exp\{-c\}).\] (16)

Figure 4: Experimental results on bounding the effectiveness of policies with the proposed estimators. Different rows highlight evaluations on different data generating mechanisms: the first row tests estimation with a partial instrumental set, the second row tests estimation with a partial adjustment set, the third row tests estimation with a high-dimensional partial adjustment set (\(\boldsymbol{W}\in\mathbb{R}^{100}\)), and the fourth row tests estimation with a combination of partial adjustment and instrumental sets.

That is the policy assigns \(X_{1}\in\{0,1\}\) randomly with probability \(0.5\), and assigns \(X_{2}\in\{0,1\}\) as a function of \(C\) with the probability of \(X_{2}=1\) increasing with the value of \(C\).

To estimate bounds on \(\mathbb{E}_{P_{\bm{\pi}}}[Y]\), we consider the proposed estimators, labelled: \(T^{\text{PW}}\), estimated with the nuisances in Eq. (10), \(T^{\text{REG}}\), estimated with the nuisances in Eq. (11), and \(T^{\text{DML}}\) estimated with the procedure in Def. 5. Our evaluations test performance across 4 different settings designed to highlight various properties.

* **Setting 1**: All nuisances estimated correctly. This setting aims to show that all estimators converge to the bound of interest.
* **Setting 2**: Nuisances \(\hat{\bm{\gamma}}\) are sampled from a uniform distribution to induce misspecification in the estimation of \(\bm{\gamma}\).
* **Setting 3**: Nuisances \(\hat{\bm{\mu}}\) are sampled from a uniform distribution to induce misspecification in the estimation of \(\bm{\mu}\). Settings 2 and 3 aim to demonstrate the doubly-robustness property of the DML estimator.
* **Setting 4**: Noise \(\epsilon\) is introduced in the estimation of all nuisances \((\bm{\gamma},\bm{\mu})\) to emphasize error due to finite sample variation. Specifically, noise \(\epsilon\sim\text{Normal}(n^{-\alpha},n^{-\alpha}),\alpha=1/4\), that induces a slower rate of convergence as a function of sample size, inspired by [24, 20]. This setting aims to show that the fast convergence behavior of the DML estimator compared to competing estimators.

The results are given in Fig. 44. We observe that across all data generating mechanisms, estimators improve with the size of the dataset and converge under no misspecification (Setting 1) to the underlying bounds. It is interesting to note also the differing accuracy of estimators in the small sample regime. \(T^{\text{PW}}\), based the estimation of a ratio of probabilities, can be unstable with low sample sizes if the ratio denominator is estimated to be close to zero while \(T^{\text{REG}}\), based on a sequence of regression tasks, tends to be better behaved. \(T^{\text{DML}}\) in contrast is constructed as a combination of elements of \(T^{\text{PW}}\) and \(T^{\text{REG}}\). In particular, note in Def. 5 the use of nuisances \(\bm{\mu}\) and \(\bm{\gamma}\). As a result, \(T^{\text{DML}}\) has quite a different performance profile. Settings 2 and 3 in Fig. 4 show that the DML estimator \(T^{\text{DML}}\) is robust to misspecification in either the nuisances \(\bm{\mu}\) or \(\bm{\gamma}\) that highlights the robustness property. Further, when decaying noise is introduced in the estimation of nuisances (Setting 4), the DML estimator outperforms in general with a faster convergence rate. We also observe that performance remains close to optimal with high-dimensional variables \(\bm{W}\), demonstrating that the DML estimator provides a practical toolkit for bounding in practice.

Footnote 4: For the first row, the policy evaluated is: \(\pi_{X}:=\pi_{X}(X=1\mid c)=1/(1-\exp\{-c\})\).

#### 5.1.1 Width of Bounds According to Different Graphical Criteria

This section evaluates the width of the bounds returned by exploiting the different graphical criteria provided in Sec. 3. The simulations are based on the data generating mechanism described by causal diagram illustrated in the fourth row of Fig. 4. We consider evaluating the policy in Eq. (16) and compute the bounds obtained by applying Prop. 2 (most conservative), Prop. 3 (using the partial adjustment set \(W\) only), Prop. 4 (using the partial instrumental set \(Z\) only), and finally Alg. 1 (that combines all propositions and is the proposed approach). Fig. 5 gives the results over 10 seeds of the data and across multiple data sizes, highlighting the gain achieved by exploiting the causal structure using the proposed approaches.

**Remark** (Actual width of bounds in practice). The majority of our empirical evaluations are spent on evaluating the accuracy of different methods at estimating bounds, without addressing whether the returned bounds are actually informative. In practice, the graph structure can play an important role in tightening bounds but the actual width of the bounds in a particular problem are primarily driven by the distribution of data. Here is an example to make this more concrete.

For a given policy \(\bm{\pi}\), Prop. 2 defines tight bounds (under some circumstances) on \(\mathbb{E}_{P_{\bm{\pi}}}[Y]\). The width of this bound is given by \(1-\mathbb{E}_{P}\big{[}\overline{\bm{\pi}}\big{]}\) that is ultimately driven by \(P(x)\). This term may therefore evaluate to anything between 0 and 1 depending on \(P(x)\) and \(\bm{\pi}\).

Figure 5: Width of bounds.

For more complex causal structures, the bounds proposed in Props. 3 and 4 (and Alg. 1) reduce the width of the interval above. Loosely written, from \(1-\mathbb{E}_{P}[\bar{\bm{\pi}}]\) to \(1-\mathbb{E}_{P}[\bar{\bm{\pi}}]\times\alpha\) for some \(\alpha\) that is a function of the joint distribution \(P\) and the structure of the graph. But again, the actual width of the interval is ultimately determined by the values of \(P\) and \(\bm{\pi}\) that may be large or small depending on the value probabilities involved.

### Evaluating Health Campaigns

This section illustrates the evaluation of lifestyle recommendations for the mitigation of obesity in individuals from Colombia, Peru and Mexico [30]. The data was collected from anonymous users using a web platform, and includes reported obesity levels measured according to BMI \((Y)\), age \((A)\), smoking status \((S)\), frequency of consumption of high caloric food \((H)\), whether individuals monitored their calorie intake \((M)\), family history being overweight \((F)\), exercise frequency \((E)\), and time using technology devices \((T)\). Obesity is a multi-factored medical condition for which several causes have been acknowledged in the literature; causal diagrams relating the variables above have been curated in several related studies [1; 9]. We considered these findings to construct the causal diagram in Fig. 5(a) that we assumed for this example.

We aim to study the effect of a health campaign designed to lower the intake of high caloric food \((H)\) and increase the frequency of exercise \((E)\) on obesity levels \((Y)\). For instance, we could hypothesize that the campaign leads to an increase in the observed proportion of individuals rarely consuming of high caloric food (\(H\)) from \(0.12\) to \(0.5\) and that of individuals doing exercise (\(E\)) regularly from \(0.05\) to \(0.5\). These statements could be formulated as a stochastic policy \(\bm{\pi}^{\alpha}:=\{\pi_{H}^{\alpha},\pi_{E}^{\alpha}\}\) acting on \(H\) and \(E\), with new assignments,

\[\pi_{H}^{\alpha}:=\pi_{H}^{\alpha}(H=\texttt{ rarely})=\alpha,\quad\pi_{E}^{ \alpha}:=\pi_{E}^{\alpha}(E=\texttt{regularly})=\alpha.\] (17)

We consider the evaluation of expected BMI levels \(\mathbb{E}_{P_{\bm{\pi}^{\alpha}}}[Y]\) that range from \(12\) to \(50\) in the population, with a mean of \(29.3\). First note that this or other policies acting on \((H,E)\) are not identifiable due to the bi-directed edge \(\{H\texttt{ \textless}\ldots\texttt{ \textless}Y\}\), but may nevertheless be bounded using Alg. 1. We find that

\[\max_{t}\mathbb{E}_{P}[Y\gamma]\leqslant\mathbb{E}_{P_{\bm{\pi}^{\alpha}}}[Y ]\leqslant\min_{t}\mathbb{E}_{P}[(Y-1)\gamma]+1,\quad\gamma:=\bar{\pi}_{\pi_ {\alpha}}\mathbb{1}_{t}(T)/P(E,T\mid A,S,F).\] (18)

To illustrate the inference of. bounds with the DML estimator, we consider evaluating policies with \(\alpha=0.2,0.4,0.6,0.8\). Fig. 5(b) gives the results. The end-points of the intervals denote estimated lower and upper bounds. We see that policies that promote a healthier lifestyle (larger values of \(\alpha\)) are expected to reduce obesity levels on average but substantial uncertainty is still expected.

## 6 Conclusions

The evaluation of policies is arguably one of the critical ingredients enabling more personalized decision-making systems. When the effect of policies is not identifiable, bounds can provide an effective support for making informed decisions. In this paper we developed partial identification and estimation tools for bounding the effect of a (stochastic or conditional) policy given data and assumptions encoded in a causal graph. We introduced several graphical characterizations that induce tighter bounds, and developed an estimation framework that exhibit robustness to noise and fast convergence. The results of this paper were illustrated through synthetic simulations and a real-world health campaign example for the reduction of obesity levels.

Figure 6: Health campaign evaluations.

## Acknowledgements

We thank the anonymous reviewers for helpful comments.

## References

* Allender et al. [2015] Steven Allender, Brynle Owen, Jill Kuhlberg, Janette Lowe, Phoebe Nagorcka-Smith, Jill Whelan, and Colin Bell. A community based systems diagram of obesity causes. _PloS one_, 10(7):e0129683, 2015.
* Athey and Imbens [2017] Susan Athey and Guido W Imbens. The state of applied econometrics: Causality and policy evaluation. _Journal of Economic perspectives_, 31(2):3-32, 2017.
* Meresht et al. [2022] Vahid Balazadeh Meresht, Vasilis Syrgkanis, and Rahul G Krishnan. Partial identification of treatment effects with implicit generative models. _Advances in Neural Information Processing Systems_, 35:22816-22829, 2022.
* Balke and Pearl [1997] Alexander Balke and Judea Pearl. Bounds on treatment effects from studies with imperfect compliance. _Journal of the American Statistical Association_, 92(439):1171-1176, 1997.
* Bellot [2024] Alexis Bellot. Towards bounding causal effects under Markov equivalence. In _The 40th Conference on Uncertainty in Artificial Intelligence_. PMLR, 2024.
* Bellot et al. [2022] Alexis Bellot, Anish Dhir, and Giulia Prando. Generalization bounds and algorithms for estimating conditional average treatment effect of dosage. _arXiv preprint arXiv:2205.14692_, 2022.
* Bennett and Kallus [2019] Andrew Bennett and Nathan Kallus. Policy evaluation with latent confounders via optimal balance. _Advances in neural information processing systems_, 32, 2019.
* Bhattacharya et al. [2022] Rohit Bhattacharya, Razieh Nabi, and Ilya Shpitser. Semiparametric inference for causal effects in graphical models with hidden variables. _The Journal of Machine Learning Research_, 23(1):13325-13400, 2022.
* Butland et al. [2007] Bryony Butland, Susan Jebb, Peter Kopelman, Klim McPherson, Sandy Thomas, Jane Mardell, Vivienne Parry, et al. _Tackling obesities: future choices-project report_, volume 10. Citeseer, 2007.
* Chernozhukov et al. [2018] Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, and James Robins. Double/debiased machine learning for treatment and structural parameters, 2018.
* Chickering and Pearl [1996] David Maxwell Chickering and Judea Pearl. A clinician's tool for analyzing non-compliance. In _Proceedings of the National Conference on Artificial Intelligence_, pages 1269-1276, 1996.
* Correa and Bareinboim [2020] Juan Correa and Elias Bareinboim. A calculus for stochastic interventions: Causal effect identification and surrogate experiments. In _Proceedings of the AAAI conference on artificial intelligence_, volume 34, pages 10093-10100, 2020.
* Drake et al. [2009] Elizabeth K Drake, Steve Aos, and Marna G Miller. Evidence-based public policy options to reduce crime and criminal justice costs: Implications in washington state. _Victims and offenders_, 4(2):170-196, 2009.
* Finkelstein and Shpitser [2020] Noam Finkelstein and Ilya Shpitser. Deriving bounds and inequality constraints using logical relations among counterfactuals. In _Conference on Uncertainty in Artificial Intelligence_, pages 1348-1357. PMLR, 2020.
* Gultchin et al. [2023] Limor Gultchin, Virginia Aglietti, Alexis Bellot, and Silvia Chiappa. Functional causal Bayesian optimization. In _Uncertainty in Artificial Intelligence_, pages 756-765. PMLR, 2023.
* Hu et al. [2021] Yaowei Hu, Yongkai Wu, Lu Zhang, and Xintao Wu. A generative adversarial framework for bounding confounded causal effects. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 35, pages 12104-12112, 2021.

* [17] Andrew Jesson, Soren Mindermann, Yarin Gal, and Uri Shalit. Quantifying ignorance in individual-level causal-effect estimates under hidden confounding. In _International Conference on Machine Learning_, pages 4829-4838. PMLR, 2021.
* [18] Shalmali Joshi, Junzhe Zhang, and Elias Bareinboim. Towards safe policy learning under partial identifiability: A causal approach. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 38, pages 13004-13012, 2024.
* [19] Yonghan Jung, Jin Tian, and Elias Bareinboim. Estimating identifiable causal effects on Markov equivalence class through double machine learning. In _International Conference on Machine Learning_, pages 5168-5179. PMLR, 2021.
* [20] Yonghan Jung, Jin Tian, and Elias Bareinboim. Estimating joint treatment effects by combining multiple experiments. In _International Conference on Machine Learning_, pages 15451-15527. PMLR, 2023.
* [21] Nathan Kallus, Xiaojie Mao, and Angela Zhou. Interval estimation of individual-level causal effects under unobserved confounding. In _The 22nd international conference on artificial intelligence and statistics_, pages 2281-2290. PMLR, 2019.
* [22] Nathan Kallus and Angela Zhou. Confounding-robust policy improvement. _Advances in neural information processing systems_, 31, 2018.
* [23] Nathan Kallus and Angela Zhou. Confounding-robust policy evaluation in infinite-horizon reinforcement learning. _Advances in neural information processing systems_, 33:22293-22304, 2020.
* [24] Edward H Kennedy. Towards optimal doubly robust estimation of heterogeneous causal effects. _arXiv preprint arXiv:2004.14497_, 2020.
* [25] Travis Mandel, Yun-En Liu, Sergey Levine, Emma Brunskill, and Zoran Popovic. Offline policy evaluation across representations with applications to educational games. In _AAMAS_, volume 1077, 2014.
* [26] Henry B Mann and Abraham Wald. On stochastic limit and order relationships. _The Annals of Mathematical Statistics_, 14(3):217-226, 1943.
* [27] Charles F Manski. Nonparametric bounds on treatment effects. _The American Economic Review_, 80(2):319-323, 1990.
* [28] Miruna Oprescu, Jacob Dorn, Marah Ghoummaid, Andrew Jesson, Nathan Kallus, and Uri Shalit. B-learner: Quasi-oracle bounds on heterogeneous causal effects under hidden confounding. _arXiv preprint arXiv:2304.10577_, 2023.
* [29] Kirtan Padh, Jakob Zeitler, David Watson, Matt Kusner, Ricardo Silva, and Niki Kilbertus. Stochastic causal programming for bounding treatment effects. _arXiv preprint arXiv:2202.10806_, 2022.
* [30] Fabio Mendoza Palechor and Alexis de la Hoz Manotas. Dataset for estimation of obesity levels based on eating habits and physical condition in individuals from colombia, peru and mexico. _Data in brief_, 25:104344, 2019.
* [31] Judea Pearl. _Causality_. Cambridge university press, 2009.
* [32] Judea Pearl and James M Robins. Probabilistic evaluation of sequential plans from causal models with hidden variables. In _UAI_, volume 95, pages 444-453. Citeseer, 1995.
* [33] James M Robins. The analysis of randomized and non-randomized aids treatment trials using a new approach to causal inference in longitudinal studies. _Health service research methodology: a focus on AIDS_, pages 113-159, 1989.
* [34] Paul R Rosenbaum, P Briskman Rosenbaum, and Briskman. _Design of observational studies_, volume 10. Springer, 2010.

* Rotnitzky et al. [2017] Andrea Rotnitzky, James Robins, and Lucia Babino. On the multiply robust estimation of the mean of the g-functional. _arXiv preprint arXiv:1705.08582_, 2017.
* Shalit et al. [2017] Uri Shalit, Fredrik D Johansson, and David Sontag. Estimating individual treatment effect: generalization bounds and algorithms. In _International conference on machine learning_, pages 3076-3085. PMLR, 2017.
* Sutton and Barto [2018] Richard S Sutton and Andrew G Barto. _Reinforcement learning: An introduction_. MIT press, 2018.
* Tan [2006] Zhiqiang Tan. A distributional approach for causal inference using propensity scores. _Journal of the American Statistical Association_, 101(476):1619-1637, 2006.
* Thomas and Brunskill [2016] Philip Thomas and Emma Brunskill. Data-efficient off-policy policy evaluation for reinforcement learning. In _International Conference on Machine Learning_, pages 2139-2148. PMLR, 2016.
* Tian [2012] Jin Tian. Identifying dynamic sequential plans. _arXiv preprint arXiv:1206.3292_, 2012.
* Tsiatis et al. [2019] Anastasios A Tsiatis, Marie Davidian, Shannon T Holloway, and Eric B Laber. _Dynamic treatment regimes: Statistical methods for precision medicine_. CRC press, 2019.
* van der Laan and Gruber [2012] Mark J van der Laan and Susan Gruber. Targeted minimum loss based estimation of causal effects of multiple time point interventions. _The international journal of biostatistics_, 8(1), 2012.
* van der Zander [2020] Benito van der Zander. _Algorithms of Identifying Causal Effects in Graphical Models_. PhD thesis, Universitat zu Lubeck, 2020.
* Vedung [2017] Evert Vedung. _Public policy and program evaluation_. Routledge, 2017.
* Yadlowsky et al. [2018] Steve Yadlowsky, Hongseok Namkoong, Sanjay Basu, John Duchi, and Lu Tian. Bounds on the conditional and average treatment effect with unobserved confounding factors. _arXiv preprint arXiv:1808.09521_, 2018.
* Zhang [2020] Junzhe Zhang. Designing optimal dynamic treatment regimes: A causal reinforcement learning approach. In _International Conference on Machine Learning_, pages 11012-11022. PMLR, 2020.
* Zhang and Bareinboim [2021] Junzhe Zhang and Elias Bareinboim. Bounding causal effects on continuous outcome. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 35, pages 12207-12215, 2021.
* Zhang et al. [2021] Junzhe Zhang, Jin Tian, and Elias Bareinboim. Partial counterfactual identification from observational and experimental data. _arXiv preprint arXiv:2110.05690_, 2021.
* Zhang et al. [2020] Yao Zhang, Alexis Bellot, and Mihaela Schaar. Learning overlapping representations for the estimation of individualized treatment effects. In _International Conference on Artificial Intelligence and Statistics_, pages 1005-1014. PMLR, 2020.

## Appendix

### Table of Contents

* 1 Preliminaries, Related Work, and Impact Statement
	* 1.1 Preliminaries
	* 1.2 Related Work
	* 1.3 Broader Impact Statement
	* 1.2 Proofs
	* 1.3 Proofs of statements in Sec. 2
	* 1.4 Proofs of statements in Sec. 4.1.1 Details on experiments
		* 1.4.1 Simulations
		* 1.4.2 Health Campaign Evaluation
		* 1.4.3 NeurIPS Paper Checklist
Preliminaries, Related Work, and Impact Statement

### Preliminaries

For the derivation of results, we use the notion of counterfactuals defined as follows.

For an SCM \(\mathcal{M}\), arbitrary subsets of endogenous variables \(\bm{X},\bm{Y}\), the potential outcome of \(\bm{Y}\) to intervention \(do(\bm{x})\), denoted by \(\bm{Y}_{\bm{x}}(\bm{u})\), is the solution for \(\bm{Y}\) with \(\bm{U}=\bm{u}\) in the sub-model \(\mathcal{M}_{\bm{x}}\). It can be read as the counterfactual sentence "the value that \(\bm{Y}\) would have obtained in situation \(\bm{U}=\bm{u}\), had \(\bm{X}\) been \(\bm{x}\).". Statistically, averaging \(\bm{u}\) over the distribution \(P(\bm{u})\) leads to the counterfactual variables \(\bm{Y}_{\bm{x}}\). The distribution of the variable \(\bm{Y}_{\bm{x}}\) is denoted \(P(\bm{Y}_{\bm{x}})\). With this formalism, we can express all the quantities in the main body of this paper in the language of counterfactuals. For instance, the distribution of \(\bm{Y}\) in sub-model \(\mathcal{M}_{\bm{x}}\) can alternatively be written \(P(\bm{Y}_{\bm{x}})\equiv P_{\bm{x}}(\bm{Y})\). Moreover, \(\mathbb{E}_{P}[f(\bm{Y}_{\bm{x}})\mid\bm{z}]\), also written \(\mathbb{E}_{P(\cdot\mid\bm{z})}[f(\bm{Y}_{\bm{x}})]\), denotes the conditional expectation of \(f(\bm{Y})\) over \(P(\bm{y}_{\bm{x}}\mid\bm{z})\). Similarly, the distribution over \(Y\) in the sub-model \(\mathcal{M}_{\bm{x}}\) can be written \(P_{\mathcal{M}}(Y_{\bm{x}})\), or \(P(Y_{\bm{x}})\equiv P_{\bm{x}}(Y)\) for short. See [31, Chapter 7] for further context on counterfactuals.

**Definition 6** (The Axioms of Counterfactuals, Chapter 7.3.1 [31]).: _For any three sets of endogenous variables \(\bm{X},\bm{Y},\bm{W}\) in a causal model and \(\bm{x},\bm{w}\) in the domains of \(\bm{X}\) and \(\bm{W}\), the following holds:_

* _Composition:_ \(\bm{W}_{\bm{x}}=\bm{w}\) _implies that_ \(\bm{Y}_{\bm{x},\bm{w}}=\bm{Y}_{\bm{x}}\)_._
* _Effectiveness:_ \(\bm{X}_{\bm{w},\bm{x}}=\bm{x}\)_._
* _Reversibility:_ \(\bm{Y}_{\bm{x},\bm{w}}=\bm{y}\) _and_ \(\bm{W}_{\bm{x},\bm{y}}=\bm{w}\) _imply that_ \(\bm{Y}_{\bm{x}}=\bm{y}\)_._

**Theorem 1** (Soundness and Completeness of the Axioms Theorems 7.3.3, 7.3.6 [31]).: _The Axioms of counterfactuals are sound and complete for all causal models._

The following rules to manipulate experimental distributions produced by policies extend the calculus and will be used for the proof of several theoretical statements [12].

**Theorem 2** (Inference Rules \(\sigma\)-calculus [12]).: _Let \(\mathcal{G}\) be a causal diagram compatible with an SCM \(\mathcal{M}\), with endogenous variables \(\bm{V}\). For any disjoint subsets \(\bm{X},\bm{Y},\bm{Z}\subseteq\bm{V}\), two disjoint subsets \(\bm{T},\bm{W}\subseteq\bm{V}\backslash(\bm{Z}\cup\bm{Y})\) (i.e., possibly including \(\bm{X}\)), the following rules are valid for any intervention strategies \(\pi_{\bm{X}}\), \(\pi_{\bm{Z}}\), and \(\pi^{\prime}_{\bm{Z}}\) such that \(\mathcal{G}_{\pi_{\bm{X}}\pi_{\bm{Z}}}\), \(\mathcal{G}_{\pi_{\bm{X}}\pi^{\prime}_{\bm{Z}}}\) have no cycles:_

* _Rule 1 (Insertion/Deletion of observations):_ \[P_{\pi_{\bm{X}}}(\bm{y}\mid\bm{w},\bm{t})=P_{\pi_{\bm{X}}}(\bm{y}\mid\bm{w}) \quad\text{ if }(\bm{T}\rotatebox[origin={c}]{$\bot$}_{d}\bm{Y}\mid\bm{W})\text{ in }\mathcal{G}_{\pi_{\bm{X}}}.\]
* _Rule 2 (Change of regimes under observation):_ \[P_{\pi_{\bm{X}},\pi_{\bm{Z}}}(\bm{y}\mid\bm{z},\bm{w})=P_{\pi_{\bm{X}},\pi^{ \prime}_{\bm{Z}}}(\bm{y}\mid\bm{z},\bm{w})\quad\text{ if }(\bm{Y}\rotatebox[origin={c}]{$\bot$}_{d}\bm{Z}\mid\bm{W})\text{ in }\mathcal{G}_{\pi_{\bm{X}},\pi_{\bm{Z}},\bm{Z}}\text{ and }\mathcal{G}_{\pi_{\bm{X}},\pi^{\prime}_{\bm{Z}},\bm{Z}}\]
* _Rule 3 (Change of regimes without observation):_ \[P_{\pi_{\bm{X}},\pi_{\bm{Z}}}(\bm{y}\mid\bm{w})=P_{\pi_{\bm{X}},\pi^{\prime}_{ \bm{Z}}}(\bm{y}\mid\bm{w})\quad\text{ if }(\bm{Y}\rotatebox[origin={c}]{$\bot$}_{d}\bm{Z}\mid\bm{W})\text{ in }\mathcal{G}_{\pi_{\bm{X}},\pi_{\bm{Z}},\bm{Z}(\bm{W})}\text{ and }\mathcal{G}_{\pi_{\bm{X}},\pi^{\prime}_{\bm{Z}},\bm{Z}(\bm{W})}\]

_where \(\bm{Z}(\bm{W})\) is the set of elements in \(\bm{Z}\) that are not ancestors of \(\bm{W}\) in \(\mathcal{G}_{\pi_{\bm{X}}}\)._

### Related Work

Active experimentation by physically manipulating reality is generally not feasible for many consequential applications. This motivates the study of causal effect identification and estimation. The former studies the problem of inferring whether a unique expression or bound of the desired causal effect could be derived from the available data and assumptions. The latter studies the problem of providing efficient estimators from finite samples to compute causal effects or bounds on causal effects in practice. In the following, we review these two lines of work to better contextualize our contribution.

**Partial identification**. The natural bounds were derived to demonstrate that useful inference about causal effects could be drawn without making identifying assumptions beyond the observed data [27]. Relatedly, an analysis of bounds of causal effects was also provided for studies with imperfect compliance under a set of instrumental variable assumptions that are not sufficient however to identify the causal effect of interest [33]. These bounds may be written in closed form and have recently been extended as a more general strategy for bounding causal effects given assumptions encoded in causal diagrams in discrete systems [5, 46]. Recent work has also considered bounds in closed form with access to both observational and interventional distributions [18]. These techniques were developed alongside a second line of research that employs a polynomial optimization program to compute causal bounds given a causal diagram [4]. They proposed a family of canonical models parameterized according to the causal diagram, reducing the bounding problem to a series of equivalent linear programs. [11] further used Bayesian techniques to investigate the sharpness of these bounds with regard to the observational sample size. Recently, [14, 48] describe a polynomial programming approach to solve the partial identification for general causal graphs. More recent proposals consider parameterizations in the space of linear combinations of a set of fixed basis functions [29] and neural networks [3, 16].

In parallel, a number of works have adopted sensitivity assumptions (as an alternative or in combination with a causal diagram) that quantify the degree of unobserved confounding through various data statistics, such as odds ratios, propensity scores, etc. A rich literature on sensitivity assumptions exists, including Tan's sensitivity model [38] and Rosenbaum's sensitivity model [34]. Under these models, [17, 21, 28, 45], among others, present methods that achieve validity and rate properties for the resulting estimators. These approaches start with estimators that optimize the average or conditional treatment effect bounds subject to constraints implied by the sensitivity model. Several of these works leverage Neyman orthogonality techniques to obtain rate guarantees and doubly-robustness properties. For instance, [17, 21, 28] study the estimation of bounds under Tan's sensitivity model which quantifies the degree of unobserved confounding through odds ratios, and propose estimators with various validity, sharpness, and favourable convergence rate guarantees. In contrast, [45] study the estimation of bounds under Rosenbaum's sensitivity model also deriving estimators with sharpness and fast convergence guarantees.

While some works have considered policy evaluation under various sensitivity models in the context of Reinforcement Learning, e.g., [7, 22, 23], most works target estimation of bounds on the effect of atomic interventions. We interpret this line of work as complementary (applicable under different assumptions, i.e., sensitivity models rather than causal diagrams) to the techniques proposed in this paper.

**Causal effect estimation.** With a causal diagram as input, causal effect estimation has traditionally focused on a subset of identifiable scenarios, relying on assumptions such as backdoor criterion or the availability of adjustment sets. Identification expressions in those cases are given by (sequential) covariate adjustments that have lead to statistically appealing estimators from observational data [32]. Notable examples are doubly robust estimators [10, 35, 42]. Recently these techniques have been extended to settings identifiable from multiple experimental distributions [8, 19, 20]. To our knowledge, no estimation framework specific to the estimation of analytical expressions derived for bounds on the effect of policies or atomic interventions has been developed.

### Broader Impact Statement

Our work investigates the conditions under which policies may be bounded from observational data. Issues of policy evaluation are central to fields of application involved in decision-making as well as AI and ML. We believe that a tool to bound the effect of stochastic and conditional policies in systems with unobserved confounding is an important addition to the scientific toolbox. Reasoning instead without acknowledging for the potential of unobserved confounding may lead researchers to operate on a more heuristical basis. For instance, the hypothetical effect of public policies might be misrepresented if informed by the evaluation of an idealized atomic intervention that is difficult to implement in practice. And, once implemented, might have unintended consequences. With this background, we believe that research on the partial identification and estimation of policies based on stochastic or conditional interventions can help scientists and individuals make more informed decisions.

In this work, we start from the assumption that a causal diagram that is consistent with the underlying data generating system of interest is available. In general, this requires domain knowledge. While some of the bounds provided do not require full knowledge of the causal graph, whenever a \(d\)-separation is assumed its truth value should be justified by prior knowledge or experiment. It is important also to make the distinction between the task of partial identification, that is inferring an expression for bounds on causal effects, and that of estimation, that is providing efficient estimators from finite samples to compute bounds in practice. This set of results concerns both of these tasks. The first objective of our procedure is to provide an expression for lower and upper bounds, irrespective of the accuracy with which one is able to approximate \(P(\bm{V})\) from finite samples. The second objective is introduce efficient estimators for bounds on the effect of policies using finite samples from \(P(\bm{V})\). In higher-dimensional systems, the computational complexity of estimating the conditional distributions that define lower and upper bounds on causal effects is a substantial challenge. Consequently, practitioners must exercise caution when deploying the proposed method in small sample scenarios where estimators may be inaccurate. Moreover, we have stated our convergence guarantees in the infinite sample limit, without quantifying the finite-sample estimation uncertainty. Finite-sample properties could be explored similarly to [24] given a particular choice of function class to extend our results with high-probability bounds. Finally, we emphasize that simulations on real and synthetic data are provided for illustration purposes only. These results do not recommend or advocate for the implementation of a particular policy, and should be considered in practice in combination with other aspects of the decision-making process.

Proofs

This section presents proofs for theoretical statements in the main body of this paper.

### Proofs of statements in Sec. 2

**Prop. 1 restated**.: _For any \(\bm{x}\), \(\mathbb{E}_{P}[Y\mathbbm{1}_{\bm{x}}(\bm{X})]\leq\mathbb{E}_{P_{\bm{x}}}[Y]\leq \mathbb{E}_{P}[(Y-1)\mathbbm{1}_{\bm{x}}(\bm{X})]+1\)._

Proof.: Consider the derivation of the lower bound.

\[\mathbb{E}_{P}[Y_{\bm{x}}] =\sum_{\bm{x}^{\prime}}\mathbb{E}_{P}[Y_{\bm{x}}\mid\bm{x}^{ \prime}]P(\bm{x}^{\prime})\] \[\geq\mathbb{E}_{P}[Y_{\bm{x}}\mid\bm{x}]P(\bm{x})\] \[\overset{(1)}{=}\mathbb{E}_{P}[Y\mid\bm{x}]P(\bm{x})\] \[=\sum_{y}yP(y\mid\bm{x})P(\bm{x})\] \[=\sum_{y,x}y\mathbbm{1}_{\bm{x}}(\bm{x})P(y,\bm{x})\] \[=\mathbb{E}_{P}[Y\mathbbm{1}_{\bm{x}}(\bm{X})]\]

(1) follows by the composition axiom of counterfactuals.

Consider the derivation of the upper bound. It holds that,

\[\mathbb{E}_{P}[Y_{\bm{x}}] =\sum_{\bm{x}^{\prime}}\mathbb{E}_{P}[Y_{\bm{x}}\mid\bm{x}^{ \prime}]P(\bm{x}^{\prime})\] \[=\mathbb{E}_{P}[Y_{\bm{x}}\mid\bm{x}]P(\bm{x})+\sum_{\bm{x}^{ \prime}\neq\bm{x}}\mathbb{E}_{P}[Y_{\bm{x}}\mid\bm{x}^{\prime}]P(\bm{x}^{ \prime})\] \[\overset{(1)}{\lessapprox}\mathbb{E}_{P}[Y\mid\bm{x}]P(\bm{x})+ \sum_{\bm{x}^{\prime}\neq\bm{x}}P(\bm{x}^{\prime})\] \[=\mathbb{E}_{P}[Y\mid\bm{x}]P(\bm{x})+1-P(\bm{x})\] \[=\mathbb{E}_{P}[Y\mathbbm{1}_{\bm{x}}(\bm{X})]+1-\mathbb{E}_{P}[ \mathbbm{1}_{\bm{x}}(\bm{X})]\] \[=\mathbb{E}_{P}[(Y-1)\mathbbm{1}_{\bm{x}}(\bm{X})]+1.\]

(1) follows by the boundedness of \(Y\), here assumed bounded by 1 for simplifying the derivation. 

**Proposition 10**.: _The natural bounds are tight in general._

Proof.: We show this statement by providing a pair of SCMs that agree on the input observational distribution but evaluate to the lower and upperbounds, respectively, specified by the natural bounds. Let \(\mathbb{M}(\mathcal{G})\) denote the space of SCMs that induce the causal diagram \(\mathcal{G}\) in Fig. 0(a). We introduce a pair of SCMs compatible with the causal diagram \(\mathcal{G}\) that evaluate to lower and upper bounds respectively. Let \(X\) be binary, \(Y\in[0,1]\), and \(C\in\mathbb{R}\), and consider \(\mathcal{M}_{1},\mathcal{M}_{2}\in\mathbb{M}(\mathcal{G})\) defined as follows,

\[\mathcal{M}_{1}:=\begin{cases}x:=f_{X}(u_{1})\\ c:=f_{C}(u_{2})\\ y:=\begin{cases}f_{Y}(x,c,u_{1},u_{2})&\text{if }x=f_{X}(u_{1}),\\ 0&\text{otherwise}.\end{cases}\end{cases}\]

and,

\[\mathcal{M}_{2}:=\begin{cases}x:=f_{X}(u_{1})\\ c:=f_{C}(u_{2})\\ y:=\begin{cases}f_{Y}(x,c,u_{1},u_{2})&\text{if }x=f_{X}(u_{1}),\\ 1&\text{otherwise}.\end{cases}\end{cases}\]For a \(P_{\mathcal{M}_{1}}(\bm{u})=P_{\mathcal{M}_{2}}(\bm{u})\), both SCMs agree on observational distributions \(P_{\mathcal{M}_{1}}(x,y,c)=P_{\mathcal{M}_{2}}(x,y,c)\). However the following derivations show that the interventional expectation \(\mathbb{E}_{P_{\mathcal{M}_{1}}}[Y\mid do(x=1)]\) differs across models: for \(\mathcal{M}_{1}\) equal to the analytical lower bound, and for \(\mathcal{M}_{2}\) equal to the analytical upper bound demonstrating that (in this case) the bound is tight. In particular,

\[\mathbb{E}_{P_{\mathcal{M}_{1}}}[Y\mid do(x=1)]\] \[\qquad=\mathbb{E}_{P_{\mathcal{M}_{1}}}[Y\mid x=1,u:x=f_{X}(u)]P( u:x=f_{X}(u))\] \[\qquad+\mathbb{E}_{P_{\mathcal{M}_{1}}}[Y\mid x=1,u:x\neq f_{X}(u) ]P(u:x\neq f_{X}(u))\] \[\qquad=\mathbb{E}_{P_{\mathcal{M}_{1}}}[Y\mid x=1]P(x=1)\] \[\qquad=\mathbb{E}_{P}[Y\mid x=1]P(x=1)\] \[\qquad=\mathbb{E}_{P}[Y1_{1}(X)]\] \[\mathbb{E}_{P_{\mathcal{M}_{2}}}[Y\mid do(x=1)]\] \[\qquad=\mathbb{E}_{P_{\mathcal{M}_{2}}}[Y\mid x=1,u:x=f_{X}(u)]P( u:x=f_{X}(u))\] \[\qquad+\mathbb{E}_{P_{\mathcal{M}_{2}}}[Y\mid x=1,u:x\neq f_{X}(u )]P(u:x\neq f_{X}(u))\] \[\qquad=\mathbb{E}_{P_{\mathcal{M}_{2}}}[Y\mid x=1]P(x=1)+\mathbb{E }_{P_{\mathcal{M}_{2}}}[Y\mid x=1,u:x=f_{X}(u)]P(u:x=f_{X}(u))\] \[\qquad=\mathbb{E}_{P_{\mathcal{M}_{2}}}[Y\mid x=1]P(x=1)+1-P(x=1)\] \[\qquad=\mathbb{E}_{P}[(Y-1)\mathbbm{1}_{1}(X)]+1.\]

**Prop. 2 restated**.: _For any \(\bm{\pi}\), \(\mathbb{E}_{P}[Y\bm{\bar{\pi}}]\leqslant\mathbb{E}_{P_{\bm{\pi}}}[Y]\leqslant \mathbb{E}_{P}[(Y-1)\bm{\bar{\pi}}]+1\)._

Proof.: Consider the derivation of the lower bound. Let \(\bm{\pi}\) denote a policy from an arbitrary set of covariates \(\bm{C}\) to \(\bm{X}\). By marginalizing over \(\bm{X},\bm{C}\) we find that

\[\mathbb{E}_{P_{\bm{\pi}}}[Y]=\mathbb{E}_{P}[Y_{\bm{\pi}}]=\int\mathbb{E}_{P}[Y _{\bm{\pi}}\mid\bm{x},\bm{c}]\prod_{X\in\bm{X}}\pi_{X}(x\mid\bm{c}_{X})P(\bm{ c})\ d\bm{c}\bm{x}.\]

\(\bm{C}_{X}\) denotes the subset of \(\bm{C}\) that is used to inform the intervention on \(X\). Moreover,

\[\mathbb{E}_{P}[Y_{\bm{\pi}}\mid\bm{x},\bm{c}] \overset{(1)}{=}\mathbb{E}_{P}[Y_{\bm{\pi}}\mid\bm{c}]\] \[=\sum_{\bm{x}^{\prime}}\mathbb{E}_{P}[Y_{\bm{\pi}}\mid\bm{x}^{ \prime},\bm{c}]P(\bm{x}^{\prime}\mid\bm{c})\] \[\geqslant\mathbb{E}_{P}[Y_{\bm{x}}\mid\bm{x},\bm{c}]P(\bm{x}\mid \bm{c})\] \[\overset{(2)}{=}\mathbb{E}_{P}[Y\mid\bm{x},\bm{c}]P(\bm{x}\mid \bm{c}).\]

(1) holds by Rule 2 in Thm. 2 by swapping the policy \(\bm{\pi}\) by the do intervention \(do(\bm{X}=\bm{x})\): given that the policy acts on \(\bm{X}\) taking as inputs \(\bm{C}\) it is always true that \(Y\_\bot_{d}\bm{X}\mid\bm{C}\) in \(\mathcal{G}_{\bm{\pi}\bm{X}}\) and \(\mathcal{G}_{\bm{X}\overline{\bm{X}}}\) in any graph \(\mathcal{G}\). The following equality follows by marginalizing over the domain of \(\bm{X}\), which is assumed discrete. (2) follows by the composition axiom of counterfactuals. By combining these two expressions we get

\[\mathbb{E}_{P}[Y_{\bm{\pi}}] \geqslant\int\prod_{X\in\bm{X}}\pi(x\mid\bm{c}_{X})P(\bm{c}) \mathbb{E}_{P}[Y\mid\bm{x},\bm{c}]P(\bm{x}\mid\bm{c})\ d\bm{c}d\bm{x}\] \[=\int\bm{\bar{\pi}}yP(y\mid\bm{x},\bm{c})P(\bm{x}\mid\bm{c})P(\bm {c})\ d\bm{c}d\bm{x}\] \[=\mathbb{E}_{P}[Y\bm{\bar{\pi}}].\]

[MISSING_PAGE_FAIL:20]

For the upper bound, consider the following derivation,

\[\mathbb{E}_{P}[Y_{\bm{\pi}}\mid\bm{x},\bm{c}]\] \[=\int\mathbb{E}_{P}[Y_{\bm{x}_{1}}\mid\bm{x}_{2},\bm{w},\bm{c}]P( \bm{w}\mid\bm{c})\ d\bm{w}\] \[=\int\sum_{\bm{x}_{1}^{\prime}}\{\mathbb{E}_{P}[Y_{\bm{x}_{1}} \mid\bm{x}_{1}^{\prime},\bm{x}_{2},\bm{w},\bm{c}]P(\bm{x}_{1}^{\prime}\mid\bm {x}_{2},\bm{w},\bm{c})\}P(\bm{w}\mid\bm{c})\ d\bm{w}\] \[=\int\left\{\mathbb{E}_{P}[Y_{\bm{x}_{1}}\mid\bm{x}_{1},\bm{x}_ {2},\bm{w},\bm{c}]P(\bm{x}_{1}\mid\bm{x}_{2},\bm{w},\bm{c})P(\bm{w}\mid\bm{c})\right.\] \[+\left.\sum_{\bm{x}_{1}^{\prime}\neq\bm{x}_{1}}\mathbb{E}_{P}[Y_ {\bm{x}_{1}}\mid\bm{x}_{1}^{\prime},\bm{x}_{2},\bm{w},\bm{c}]P(\bm{x}_{1}^{ \prime}\mid\bm{x}_{2},\bm{w},\bm{c})P(\bm{w}\mid\bm{c})\right\}d\bm{w}\] \[\leq\int\left\{\mathbb{E}_{P}[Y\mid\bm{x}_{1},\bm{x}_{2},\bm{w}, \bm{c}]P(\bm{x}_{1}\mid\bm{x}_{2},\bm{w},\bm{c})P(\bm{w}\mid\bm{c})+\sum_{\bm{ x}_{1}^{\prime}\neq\bm{x}_{1}}P(\bm{x}_{1}^{\prime}\mid\bm{x}_{2},\bm{w},\bm{c})P( \bm{w}\mid\bm{c})\right\}d\bm{w}\] \[=\int\left\{\mathbb{E}_{P}[Y\mid\bm{x}_{1},\bm{x}_{2},\bm{w},\bm{ c}]P(\bm{x}_{1}\mid\bm{x}_{2},\bm{w},\bm{c})P(\bm{w}\mid\bm{c})+(1-P(\bm{x}_{1} \mid\bm{x}_{2},\bm{w},\bm{c}))P(\bm{w}\mid\bm{c})\right\}d\bm{w}\] \[=\int\mathbb{E}_{P}[Y\mid\bm{x}_{1},\bm{x}_{2},\bm{w},\bm{c}]P( \bm{x}_{1}\mid\bm{x}_{2},\bm{w},\bm{c})P(\bm{w}\mid\bm{c})\ d\bm{w}+1-\int P (\bm{x}_{1}\mid\bm{x}_{2},\bm{w},\bm{c}))P(\bm{w}\mid\bm{c})\ d\bm{w}.\]

The inequality follows from the boundedness of \(Y\) and the rest of the arguments are analogous to the lower bound derivation. Combining this expression with the decomposition of the policy effect implies that,

\[\mathbb{E}_{P_{\bm{\pi}}}[Y]\leq\mathbb{E}_{P}[(Y-1)\bar{\bm{\pi}}/P(\bm{X}_{ 2}\mid\bm{W},\bm{C})]+1.\]

**Prop. 4 restated**. _Let \(\bm{Z}\) be an unconditional partial instrumental set with respect to a policy \(\bm{\pi}\), i.e. \((Y\_\_\_dZ)_{\mathcal{G}_{\bm{\pi}}}\). Then,_

\[\mathbb{E}_{P_{\bm{\pi}}}[Y] \geq\max_{\bm{z}}\mathbb{E}_{P}[Y\bar{\bm{\pi}}\mathbbm{1}_{\bm {z}}(\bm{Z})/P(\bm{Z})]\] \[\mathbb{E}_{P_{\bm{\pi}}}[Y] \leq\min_{\bm{z}}\mathbb{E}_{P}[(Y-1)\bar{\bm{\pi}}\mathbbm{1}_{ \bm{z}}(\bm{Z})/P(\bm{Z})]+1.\]

Proof.: Consider the derivation of the lower bound. Let \(\bm{\pi}\) denote a policy from an arbitrary set of covariates \(\bm{C}\) to \(\bm{X}\). Given that \((Y\_\_dZ)_{\mathcal{G}_{\bm{\pi}}}\), by marginalizing over \(\bm{X},\bm{C}\) we find that

\[\mathbb{E}_{P_{\bm{\pi}}}[Y]=\mathbb{E}_{P}[Y_{\bm{\pi}}]=\mathbb{E}_{P}[Y_{ \bm{\pi}}\mid\bm{z}]=\int\mathbb{E}_{P}[Y_{\bm{\pi}}\mid\bm{x},\bm{c},\bm{z}] \prod_{X\in\bm{X}}\pi_{X}(x\mid\bm{c}_{X})P(\bm{c}\mid\bm{z})\ ded\bm{x}.\]

\(\bm{C}_{X}\) denotes the subset of \(\bm{C}\) that is used to inform the intervention on \(X\). Moreover,

\[\mathbb{E}_{P}[Y_{\bm{\pi}}\mid\bm{x},\bm{c},\bm{z}] \stackrel{{(1)}}{{=}}\mathbb{E}_{P}[Y_{\bm{x}}\mid \bm{c},\bm{z}]\] \[=\sum_{\bm{x}^{\prime}}\mathbb{E}_{P}[Y_{\bm{x}}\mid\bm{x}^{ \prime},\bm{c},\bm{z}]P(\bm{x}^{\prime}\mid\bm{c},\bm{z})\] \[\geq\mathbb{E}_{P}[Y_{\bm{x}}\mid\bm{x},\bm{c},\bm{z}]P(\bm{x} \mid\bm{c},\bm{z})\] \[\stackrel{{(2)}}{{=}}\mathbb{E}_{P}[Y\mid\bm{x},\bm{c },\bm{z}]P(\bm{x}\mid\bm{c},\bm{z}).\]

(1) holds by Rule 2 in Thm. 2 by swapping the policy \(\bm{\pi}\) by the do intervention \(do(\bm{X}=\bm{x})\): given that the policy acts on \(\bm{X}\) taking as inputs \(\bm{C}\) it is always true that \(Y\_\_dX\mid\bm{C}\) in \(\mathcal{G}_{\bm{\pi}\bm{X}}\) and \(\mathcal{G}_{\bm{\bar{X}}\bm{\bar{X}}}\) in any graph \(\mathcal{G}\). The following equality follows by marginalizing over the domain of \(\bm{X}\), which is assumed discrete. (2) follows by the composition axiom of counterfactuals. By combining these two expressions we get

\[\mathbb{E}_{P}[Y_{\bm{\pi}}] \geqslant\int\prod_{X\in\bm{X}}\pi(x\mid\bm{c}_{X})P(\bm{c}\mid\bm{z })\mathbb{E}_{P}[Y\mid\bm{x},\bm{c},\bm{z}]P(\bm{x}\mid\bm{c},\bm{z})\ d\bm{c}d\bm{x}\] \[=\int\bar{\bm{\pi}}yP(y\mid\bm{x},\bm{c},\bm{z})P(\bm{x}\mid\bm{c },\bm{z})P(\bm{c}\mid\bm{z})\ dyd\bm{c}d\bm{x}\] \[=\mathbb{E}_{P}[Y\bar{\bm{\pi}}\mid\bm{z}]\] \[=\mathbb{E}_{P}[Y\bar{\bm{\pi}}\bm{1}_{\bm{z}}(\bm{Z})/P(\bm{Z})].\]

And since the l.h.s. does not depend on \(\bm{Z}\) we can further tighten the bound by writing,

\[\mathbb{E}_{P}[Y_{\bm{\pi}}]\geqslant\max_{\bm{z}}\mathbb{E}_{P}[Y\bar{\bm{ \pi}}\bm{1}_{\bm{z}}(\bm{Z})/P(\bm{Z})].\]

Consider the derivation of the upper bound. It holds that,

\[\mathbb{E}_{P}[Y_{\bm{\pi}}\mid\bm{x},\bm{c},\bm{z}] =\mathbb{E}_{P}[Y_{\bm{x}}\mid\bm{c},\bm{z}]\] \[=\sum_{\bm{x}^{\prime}}\mathbb{E}_{P}[Y_{\bm{x}}\mid\bm{x}^{ \prime},\bm{c},\bm{z}]P(\bm{x}^{\prime}\mid\bm{c},\bm{z})\] \[=\mathbb{E}_{P}[Y_{\bm{x}}\mid\bm{x},\bm{c},\bm{z}]P(\bm{x}\mid \bm{c},\bm{z})+\sum_{\bm{x}^{\prime}\neq\bm{x}}\mathbb{E}_{P}[Y_{\bm{x}}\mid \bm{x}^{\prime},\bm{c},\bm{z}]P(\bm{x}^{\prime}\mid\bm{c},\bm{z})\] \[\overset{(1)}{\leqslant}\mathbb{E}_{P}[Y\mid\bm{x},\bm{c},\bm{z}] P(\bm{x}\mid\bm{c},\bm{z})+\sum_{\bm{x}^{\prime}\neq\bm{x}}P(\bm{x}^{\prime} \mid\bm{c},\bm{z})\] \[=\mathbb{E}_{P}[Y\mid\bm{x},\bm{c},\bm{z}]P(\bm{x}\mid\bm{c},\bm{z })+1-P(\bm{x}\mid\bm{c},\bm{z}).\]

(1) follows by the boundedness of \(Y\), here assumed bounded by 1 for simplifying the derivation. As above by combining this inequality with the decomposition of the policy effect we get

\[\mathbb{E}_{P_{\bm{\pi}}}[Y] \leqslant\int\prod_{X\in\bm{X}}\pi(x\mid\bm{c}_{X})P(\bm{c}\mid \bm{z})\left\{\mathbb{E}_{P}[Y\mid\bm{x},\bm{c},\bm{z}]P(\bm{x}\mid\bm{c},\bm {z})+1-P(\bm{x}\mid\bm{c},\bm{z})\right\}\ d\bm{c}d\bm{x}\] \[=\mathbb{E}_{P}[Y\bar{\bm{\pi}}\mid\bm{z}]+1-\mathbb{E}_{P}[\bar{ \bm{\pi}}\mid\bm{z}]\] \[=\mathbb{E}_{P}[(Y-1)\bar{\bm{\pi}}\mid\bm{z}]+1\] \[=\mathbb{E}_{P}[(Y-1)\bar{\bm{\pi}}\bm{1}_{\bm{z}}(\bm{Z})/P(\bm {Z})]+1.\]

And since the l.h.s. does not depend on \(\bm{Z}\) we can further tighten the bound by writing,

\[\mathbb{E}_{P}[Y_{\bm{\pi}}]\geqslant\min_{\bm{z}}\mathbb{E}_{P}[(Y-1)\bar{\bm {\pi}}\bm{1}_{\bm{z}}(\bm{Z})/P(\bm{Z})]+1.\]

**Prop. 5 restated.**_Alg. 1 is sound._

Proof.: For the soundness of Alg. 1, we will consider each operation in turn and show that recovered adjustment sets and conditional instrumental sets lead to a valid bound.

_1. Omit redundant intervention variables._ For a policy \(\bm{\pi}:=\{\pi_{X}(\bm{c}_{X})\}_{X\in\bm{X}}\) denote \(\pi_{\bm{R}}:=\{\pi_{X}(\bm{c}_{X})\}_{X\in\bm{R}},\bm{R}\subseteq\bm{X}\). Let \(\bm{R}=\bm{X}\cap An(Y)\) in \(\mathcal{G}_{\bm{\pi}}\). By Rule 3 of the \(\sigma\)-calculus we have that,

\[\mathbb{E}_{P_{\bm{\pi}}}[Y]=\mathbb{E}_{P_{\bm{\pi}_{\bm{R}}}}[Y],\]

since \(Y\mbox{\text to }\!\!\perp_{d}\!\!\!X\backslash\bm{R}\) in \(\mathcal{G}_{\bm{\pi},\overline{\bm{X}\backslash\bm{R}}}\) and \(\mathcal{G}_{\pi_{\bm{R}},\overline{\bm{X}\backslash\bm{R}}}\) as there are no directed paths from \(\bm{X}\backslash\bm{R}\) to \(Y\) by definition of \(\bm{R}\). The first two lines therefore reduce the number of intervention variables. We proceed to bound the equivalent \(\mathbb{E}_{P_{\bm{\pi}_{\bm{R}}}}[Y]\).

_2. Find partial adjustment sets \(\bm{W}\)._ Line 4-11 consider finding partial adjustment sets by traversing the set of treatment variables \(R\in\bm{R}\). Recall that

\[\mathbb{E}_{P_{\bm{\pi}_{\bm{R}}}}[Y]=\mathbb{E}_{P}[Y_{\pi_{\bm{R}}}]=\int \mathbb{E}_{P}[Y_{\pi_{\bm{R}}}\mid\bm{r},\bm{c}]\prod_{X\in\bm{R}}\pi_{X}(x \mid\bm{c}_{X})P(\bm{c})\ d\bm{c}d\bm{r}.\]Denote \(\bar{\pi}_{\bm{R}}:=\prod_{X\in\bm{R}}\pi_{X}(x\mid\bm{c}_{X})\). In words lines 4-11 iteratively considers the existence of separators sets between \(R\in\bm{R}\) and \(Y\) to reduce the scope of the policy on \(Y\), i.e. \(Y_{\pi_{R}}\). By [43, Lemma 3.18.], if there exists a separator \(\bm{W}\) between two sets of variables \(\bm{X}\) and \(\bm{Y}\) such that \(\bm{S}\subseteq\bm{W}\subseteq\bm{K}\) in a graph \(\mathcal{G}\), i.e. \(\bm{X}\rotatebox[origin={c}]{$\perp_{d}$}\bm{Y}\mid\bm{W}\) in \(\mathcal{G}\), then \(\bm{W}=An(\bm{X}\cup\bm{Y}\cup\bm{S})\cap\bm{K}\) is also a valid separator. The definition of \(\bm{W}_{R}\) in line 7 aims to leverage this result to check for the existence of separators in our case.

Consider a \(R\in\bm{R}\), let \(\bm{S}=\bm{R}\backslash R\), \(\bm{K}=\bm{V}\backslash(\bm{X}\cup\bm{C}\cup Y)\). In particular, if there exist a set \(\{\bm{C},\bm{R}\}\subset\bm{W}\subset\bm{K}\) such that \((Y\rotatebox[origin={c}]{$\perp_{d}$}R\mid\bm{W})\) in \(\mathcal{G}_{\pi_{S},\bm{R}}\) then \(\bm{W}_{R}=An(\bm{R}\cup Y\cup\bm{C})\cap\bm{K}=An(Y\cup\bm{C})\cap\bm{K}\) in \(\mathcal{G}_{\pi_{S}}\) satisfies \((Y\rotatebox[origin={c}]{$\perp_{d}$}R\mid\bm{W}_{R})\) in \(\mathcal{G}_{\pi_{S},\bm{R}}\), i.e. \(\bm{W}_{R}\) is a separator if one exists. Note that \(\bm{W}_{R}\) does not include any member of \(\{\bm{C},\bm{R},Y\}\). Assume this separation holds and that the if statement in line 8 is triggered. Then,

\[\mathbb{E}_{P}[Y_{\pi_{\bm{R}}}\mid\bm{r},\bm{c}] =\mathbb{E}_{P}[Y_{\bm{r}}\mid\bm{c}]\] \[=\mathbb{E}_{P}[Y_{\bm{s},r}\mid\bm{c}]\] \[=\int\mathbb{E}_{P}[Y_{\bm{s},r}\mid\bm{c},\bm{w}_{\bm{R}}]P(\bm {w}_{R}\mid\bm{c})\ d\bm{w}_{R}\] \[=\int\mathbb{E}_{P}[Y_{\bm{s}}\mid\bm{r},\bm{c},\bm{w}_{\bm{R}}]P (\bm{w}_{R}\mid\bm{c})\ d\bm{w}_{R}.\]

The last equality holds by assumption \((Y\rotatebox[origin={c}]{$\perp_{d}$}R\mid\bm{W}_{R})\) in \(\mathcal{G}_{\overline{\bm{S}},\overline{\bm{R}}}\).

Now considering the term \(\mathbb{E}_{P}[Y_{\bm{s}}\mid r,\bm{c},\bm{w}_{R}]\), for the second pass through the for loop, we can see that if the \(d\)-separation statement in the if condition is fulfilled we can further reduce the scope of the intervention on \(\bm{S}\). In particular, for \(R^{\prime}\in\bm{R}\backslash R\), assuming that the if statement is triggered for \(\bm{W}_{R^{\prime}}\) we have that,

\[\mathbb{E}_{P}[Y_{\bm{s}}\mid r,\bm{c},\bm{w}_{R}] =\int\mathbb{E}_{P}[Y_{\bm{s}}\mid r,\bm{c},\bm{w}_{R},\bm{w}_{R^ {\prime}}]P(\bm{w}_{R^{\prime}}\mid\bm{w}_{R},\bm{c})\ d\bm{w}_{R^{\prime}}\] \[=\int\mathbb{E}_{P}[Y_{\bm{s}\backslash r^{\prime}}\mid r^{ \prime},r,\bm{c},\bm{w}_{R},\bm{w}_{R^{\prime}}]P(\bm{w}_{R^{\prime}}\mid\bm{ w}_{R},\bm{c})\ d\bm{w}_{R^{\prime}}.\]

Upon reaching the end of the for loop we have for \(\bm{W}\) defined in line 9, \(\bm{T}=\{R:\bm{W}_{R}\in\bm{W}\},\bm{U}=\bm{R}\backslash\bm{T}\) that,

\[\mathbb{E}_{P}[Y_{\bm{\pi}}\mid\bm{r},\bm{c}]=\int\mathbb{E}_{P}[Y_{\bm{u}} \mid\bm{t},\bm{c},\bm{w}]P(\bm{w}\mid\bm{c})\ d\bm{w}.\]

_3. Find partial instrumental sets \(\bm{Z}\)._ Starting line 12, we look for partial conditional instrumental sets. Consider first the case that a potential instruments \(Z\in\bm{W}\) is evaluated in the for loop. On line 15, assume that the if statement is triggered, i.e. \((Y\rotatebox[origin={c}]{$\perp_{d}$}Z\mid\bm{W}\backslash Z,\bm{T})\) in \(\mathcal{G}_{\overline{\bm{U}}}\) It then holds that,

\[\mathbb{E}_{P}[Y_{\bm{\pi}}\mid\bm{r},\bm{c}] :=\int\mathbb{E}_{P}[Y_{\bm{u}}\mid\bm{w},\bm{t},\bm{c}]P(\bm{w} \mid\bm{c})\ d\bm{w}\] \[=\int\mathbb{E}_{P}[Y_{\bm{u}}\mid\bm{w}\backslash z,z,\bm{t}, \bm{c}]\int_{z}P(\bm{w}\mid\bm{c})\ d\bm{w}\] \[=\int\mathbb{E}_{P}[Y_{\bm{u}}\mid\bm{w}\backslash z,z,\bm{t},\bm {c}]P(\bm{w}\backslash z\mid\bm{c})\ d\bm{w}\backslash z.\]

In turn, for the case that some \(Z^{\prime}\notin\bm{W}\) is evaluated in the for loop, if \((Y\rotatebox[origin={c}]{$\perp_{d}$}Z^{\prime}\mid\bm{W},\bm{T})\) in \(\mathcal{G}_{\overline{\bm{U}}}\),

\[\mathbb{E}_{P}[Y_{\bm{\pi}}\mid\bm{r},\bm{c}] :=\int\mathbb{E}_{P}[Y_{\bm{u}}\mid\bm{w},\bm{t},\bm{c}]P(\bm{w} \mid\bm{c})\ d\bm{w}\] \[=\int\mathbb{E}_{P}[Y_{\bm{u}}\mid\bm{w},\bm{t},z^{\prime},\bm{c}]P (\bm{w}\mid\bm{c})\ d\bm{w}\]

For the \(\bm{Z}\) obtained in line 15, we derive that,

\[\mathbb{E}_{P}[Y_{\bm{\pi}}\mid\bm{r},\bm{c}] =\int\mathbb{E}_{P}[Y_{\bm{u}}\mid\bm{w}\backslash\bm{z},\bm{z}, \bm{t},\bm{c}]P(\bm{w}\backslash\bm{z}\mid\bm{c})\ d\bm{w}\backslash\bm{z}.\]_4. Return bounds._ We now proceed to use the expression above to lower and upper bound the effect of interest. In particular, for the lower bound we have that,

\[\mathbb{E}_{P}[Y_{\bm{\pi}}\mid\bm{x},\bm{c}] =\int\mathbb{E}_{P}[Y_{\bm{u}}\mid\bm{w}\backslash\bm{z},\bm{z}, \bm{t},\bm{c}]P(\bm{w}\backslash\bm{z}\mid\bm{c})\ d\bm{w}\backslash\bm{z}\] \[=\int\sum_{\bm{u}^{\prime}}\mathbb{E}_{P}[Y_{\bm{u}}\mid\bm{u}^{ \prime},\bm{w}\backslash\bm{z},\bm{z},\bm{t},\bm{c}]P(\bm{u}^{\prime}\mid\bm{w }\backslash\bm{z},\bm{z},\bm{t},\bm{c})P(\bm{w}\backslash\bm{z}\mid\bm{c})\ d \bm{w}\backslash\bm{z}\] \[\geq\int\mathbb{E}_{P}[Y_{\bm{u}}\mid\bm{u},\bm{w}\backslash\bm{z },\bm{z},\bm{t},\bm{c}]P(\bm{u}\mid\bm{w}\backslash\bm{z},\bm{z},\bm{t},\bm{c} )P(\bm{w}\backslash\bm{z}\mid\bm{c})\ d\bm{w}\backslash\bm{z}\] \[=\int\mathbb{E}_{P}[Y\mid\bm{u},\bm{w}\backslash\bm{z},\bm{z},\bm {t},\bm{c}]P(\bm{u}\mid\bm{w}\backslash\bm{z},\bm{z},\bm{t},\bm{c})P(\bm{w} \backslash\bm{z}\mid\bm{c})\ d\bm{w}\backslash\bm{z}.\]

By combining the inequality above with the decomposition of the policy effect we get

\[\mathbb{E}_{P_{\bm{\pi}}}[Y]\] \[\geq\int\prod_{X\in\bm{R}}\pi(x\mid\bm{c}_{X})P(\bm{c})\mathbb{E} _{P}[Y\mid\bm{u},\bm{w}\backslash\bm{z},\bm{z},\bm{t},\bm{c}]P(\bm{u}\mid\bm{w }\backslash\bm{z},\bm{z},\bm{t},\bm{c})P(\bm{w}\backslash\bm{z}\mid\bm{c})\ d \bm{c}d\bm{r}d\bm{w}\backslash\bm{z}\] \[=\int\bar{\pi}_{\bm{R}}yP(y\mid\bm{r},\bm{w}\backslash\bm{z},\bm{z },\bm{c})P(\bm{u}\mid\bm{w}\backslash\bm{z},\bm{z},\bm{t},\bm{c})P(\bm{w} \backslash\bm{z}\mid\bm{c})P(\bm{c})\ dcd\bm{r}d\bm{w}\backslash\bm{z}dy\] \[=\int\bar{\pi}_{\bm{R}}yP(y\mid\bm{r},\bm{w}\backslash\bm{z},\bm{z },\bm{c})P(\bm{u}\mid\bm{w}\backslash\bm{z},\bm{t},\bm{c})\frac{P(\bm{t},\bm{z }\mid\bm{w}\backslash\bm{z},\bm{c})}{P(\bm{t},\bm{z}\mid\bm{w}\backslash\bm{z}, \bm{c})}P(\bm{w}\backslash\bm{z}\mid\bm{c})P(\bm{c})\mathbbm{1}_{\bm{z}}(\bm{z })\ dcd\bm{r}d\bm{w}\backslash\bm{z}dyd\bm{z}\] \[=\int\bar{\pi}_{\bm{R}}yP(y,\bm{r},\bm{w}\backslash\bm{z},\bm{z },\bm{c})\frac{\mathbbm{1}_{\bm{z}}(\bm{z})}{P(\bm{t},\bm{z}\mid\bm{w} \backslash\bm{z},\bm{c})}\ dcdrd\bm{w}\backslash\bm{z}dyd\bm{z}\] \[=\mathbb{E}_{P}[Y\gamma]\]

where \(\gamma:=\bar{\pi}_{\bm{R}}\mathbbm{1}_{\bm{z}}(\bm{Z})/P(\bm{T},\bm{Z}\mid\bm {W}\backslash\bm{Z},\bm{C})\). Note that we have used the definition \(\bm{R}=\bm{T}\cup\bm{U}\).

In turn, for the upper bound we have that,

\[\mathbb{E}_{P}[Y_{\bm{\pi}}\mid\bm{x},\bm{c}] =\int\mathbb{E}_{P}[Y_{\bm{u}}\mid\bm{w}\backslash\bm{z},\bm{z},\bm{t},\bm{c}]P(\bm{w}\backslash\bm{z}\mid\bm{c})\ d\bm{w}\backslash\bm{z}\] \[=\int\sum_{\bm{u}^{\prime}}\mathbb{E}_{P}[Y_{\bm{u}}\mid\bm{u}^{ \prime},\bm{w}\backslash\bm{z},\bm{z},\bm{t},\bm{c}]P(\bm{u}^{\prime}\mid\bm{w }\backslash\bm{z},\bm{z},\bm{t},\bm{c})P(\bm{w}\backslash\bm{z}\mid\bm{c})\ d \bm{w}\backslash\bm{z}\] \[=\int\mathbb{E}_{P}[Y_{\bm{u}}\mid\bm{u},\bm{w}\backslash\bm{z}, \bm{z},\bm{t},\bm{c}]P(\bm{u}\mid\bm{w}\backslash\bm{z},\bm{z},\bm{t},\bm{c})P( \bm{w}\backslash\bm{z}\mid\bm{c})\ d\bm{w}\backslash\bm{z}\] \[+\int\sum_{\bm{u}^{\prime}\neq\bm{u}}\mathbb{E}_{P}[Y_{\bm{u}} \mid\bm{u}^{\prime},\bm{w}\backslash\bm{z},\bm{z},\bm{t},\bm{c}]P(\bm{u}^{ \prime}\mid\bm{w}\backslash\bm{z},\bm{z},\bm{t},\bm{c})P(\bm{w}\backslash\bm{z }\mid\bm{c})\ d\bm{w}\backslash\bm{z}\] \[\leq\int\mathbb{E}_{P}[Y_{\bm{u}}\mid\bm{u},\bm{w}\backslash\bm{z },\bm{z},\bm{t},\bm{c}]P(\bm{u}\mid\bm{w}\backslash\bm{z},\bm{z},\bm{t},\bm{c})P( \bm{w}\backslash\bm{z}\mid\bm{c})\ d\bm{w}\backslash\bm{z}\] \[+\int\sum_{\bm{u}^{\prime}\neq\bm{u}}P(\bm{u}^{\prime}\mid\bm{w} \backslash\bm{z},\bm{z},\bm{t},\bm{c})P(\bm{w}\backslash\bm{z}\mid\bm{c})\ d \bm{w}\backslash\bm{z}\] \[=\int\mathbb{E}_{P}[Y\mid\bm{u},\bm{w}\backslash\bm{z},\bm{z},\bm{t },\bm{c}]P(\bm{u}\mid\bm{w}\backslash\bm{z},\bm{z},\bm{t},\bm{c})P(\bm{w} \backslash\bm{z}\mid\bm{c})\ d\bm{w}\backslash\bm{z}\] \[+\int(1-P(\bm{u}\mid\bm{w}\backslash\bm{z},\bm{z},\bm{t},\bm{c}))P( \bm{w}\backslash\bm{z}\mid\bm{c})\ d\bm{w}\backslash\bm{z}\] \[=1+\int\mathbb{E}_{P}[Y-1\mid\bm{u},\bm{w}\backslash\bm{z},\bm{z}, \bm{t},\bm{c}]P(\bm{u}\mid\bm{w}\backslash\bm{z},\bm{z},\bm{t},\bm{c})P(\bm{w} \backslash\bm{z}\mid\bm{c})\ d\bm{w}\backslash\bm{z}\]By combining the inequality above with the decomposition of the policy effect we get

\[\mathbb{E}_{P_{\bm{\pi}}}[Y]\] \[\leq 1+\int\prod_{X\in\bm{R}}\pi(x\mid\bm{c}_{X})P(\bm{c})\mathbb{E} _{P}[Y-1\mid\bm{u},\bm{w}\backslash\bm{z},\bm{z},\bm{t},\bm{c}]P(\bm{u}\mid\bm {w}\backslash\bm{z},\bm{z},\bm{t},\bm{c})P(\bm{w}\backslash\bm{z}\mid\bm{c})\ d\bm{c}d\bm{r}d\bm{w} \backslash\bm{z}\] \[=1+\int\bar{\pi}_{\bm{R}}(y-1)P(y\mid\bm{r},\bm{w}\backslash\bm{z},\bm{z},\bm{c})P(\bm{u}\mid\bm{w}\backslash\bm{z},\bm{z},\bm{t},\bm{c})P(\bm{w} \backslash\bm{z}\mid\bm{c})P(\bm{c})\ d\bm{c}d\bm{r}d\bm{w}\backslash\bm{z}d\] \[=1+\int\bar{\pi}_{\bm{R}}(y-1)P(y,\bm{r},\bm{w}\backslash\bm{z}, \bm{z},\bm{c})\frac{\mathbbm{1}_{\bm{z}}(\bm{z})}{P(\bm{t},\bm{z}\mid\bm{w} \backslash\bm{z},\bm{c})}\ d\bm{c}d\bm{r}d\bm{w}\backslash\bm{z}d\bm{z}\] \[=1+\mathbb{E}_{P}[(Y-1)\gamma]\]

where \(\gamma:=\bar{\pi}_{\bm{R}}\mathbbm{1}_{\bm{z}}(\bm{Z})/P(\bm{T},\bm{Z}\mid\bm {W}\backslash\bm{Z},\bm{C})\). Note that we have used the definition \(\bm{R}=\bm{T}\cup\bm{U}\). 

**Prop. 6 restated**.: _Let \(k\) be the number of variables and \(m\) be the number of edges in \(\mathcal{G}\). The run time of Alg. 1 is \(\mathcal{O}(k(k^{2}+m))\)._

Proof.: Let \(k\) be the number of variables and \(m\) be the number of edges in \(\mathcal{G}\). Operations in Alg. 1, such as computing ancestors (e.g. lines 2,7), could be done in \(\mathcal{O}(k^{2})\) time, e.g. with a Breadth-First Search algorithm. Checking for \(d\)-separation is commonly done with the Bayes-Ball algorithm that can be implemented with a reachability search method, e.g. [43, Sec. 3.2.1], and could be done in \(\mathcal{O}(k+m)\) time by [43, Prop. 3.17]. The sets \(\bm{R}\) and \(\bm{Z}\) have size at most \(k\), so the for loops in lines 5 and 14 are executed at most \(k\) times each. Combining these we get that Alg. 1 requires \(\mathcal{O}(k(k^{2}+m))\) time to return the bounds. 

**Prop. 7 restated**.: _Let \(\bm{\pi}:=\{\pi_{\bm{X}_{1}},\pi_{\bm{X}_{2}}\}\) be a policy on \(\{\bm{X}_{1},\bm{X}_{2}\}\) with a conditioning set \(\bm{C}\). All partial adjustment sets may be enumerated in time \(\mathcal{O}(k(k+m))\) where \(k\) are the number of variables and \(m\) be the number of edges in \(\mathcal{G}\)._

Proof.: This proposition is adapts Proposition 3.20 in [43] to find partial adjustment sets using the ListSep algorithm. ListSep performs backtracking to enumerate all separator sets \(\bm{Z}\) between \(\bm{X}\) and \(\bm{Y}\) such that \(\bm{I}\subseteq\bm{Z}\subseteq\bm{R}\), aborting branches that will not find a valid separator. In particular, it calls the TestSep and FindSep algorithms recursively.

The TestSep algorithm takes as input a graph, two sets of nodes to be separated, and a candidate separator set. By setting the graph to be \(\mathcal{G}_{\pi_{\bm{X}_{1}},\underline{X}_{2}}\), the two sets to be separated to be \(Y\) and \(\bm{X}_{2}\), and the separator set \(\bm{Z}\), TestSep will provably return whether \(\bm{W}=\bm{Z}\backslash(\bm{C},\bm{X}_{1})\) is a partial adjustment set.

The FindSep algorithm uses the observation that if there exists a separator \(\bm{Z}\) between \(\bm{X}\) and \(\bm{Y}\) such that \(\bm{I}\subseteq\bm{Z}\subseteq\bm{R}\) then \(\bm{Z}:=An(\bm{X}\cup\bm{Y}\cup\bm{I})\cap\bm{R}\) is a separator. For each possible partition \((\bm{X}_{1},\bm{X}_{2})\) of \(\bm{X}\), we can therefore find a separator by testing (using TestSep) whether \(An(\bm{X}\cup Y\cup\bm{C})\cap(\bm{V}\backslash(\bm{X}\cup Y))\) in \(\mathcal{G}_{\pi_{\bm{X}_{1}},\underline{X}_{2}}\) is a separator. If it is then we have found a partial adjustment set.

To find all partial adjustment sets, we then proceed as follows. For each possible partition \((\bm{X}_{1},\bm{X}_{2})\) of \(\bm{X}\), apply the ListSep algorithm with graph \(\mathcal{G}_{\pi_{\bm{X}_{1}},\underline{X}_{2}}\), sets to be separated \(Y\) and \(\bm{X}_{2}\), and possible separator sets \(\bm{Z}\) constrained as \(\bm{C},\bm{X}_{1}\subseteq\bm{Z}\subseteq\overline{\bm{V}\backslash}(\bm{X} \cup Y)\). Then, for every separator set \(\bm{Z}\) found, output partial adjustment sets \(\bm{W}=\bm{Z}\backslash(\bm{C},\bm{X}_{1})\).

This procedure finds all possible partial adjustment sets in time \(\mathcal{O}(k(k+m))\) where \(k\) are the number of variables and \(m\) be the number of edges in \(\mathcal{G}\) by Proposition 3.20 [43]. 

### Proofs of statements in Sec. 4

We make use of two auxiliary lemmas from the literature.

**Lemma 1** (Continuous Mapping Theorem, [26]).: _Let \(\{X_{n}\}_{n\in\mathbb{N}^{n}}\)\(X\) be random elements defined on a metric space \(S\). Consider a continuous function \(g:S\to S^{\prime}\) (where \(S^{\prime}\) is another metric space). Then,_

\[X_{n}\rightarrow_{p}X\Rightarrow g(X_{n})\rightarrow_{p}g(X).\]

**Lemma 2** (Lemma 2, [24]).: _Let \(f_{\eta}:=f(\bm{V};\eta)\) denote a finite and continuous functional and \(\eta\) denote its nuisances. For \(n\) independent samples of \(P\), \(D:=\{\bm{v}^{(i)}\}_{i=1,\dots,n}\sim P\), let \(\hat{T}=\mathbb{E}_{D}[f_{\hat{\eta}}]\) and \(T:=\mathbb{E}_{P}[f_{\eta}]\) for some \(\eta\). Let \(\mathbb{E}_{D-P}[f_{\eta}]:=\mathbb{E}_{D}[f_{\eta}]-\mathbb{E}_{P}[f_{\eta}]\). Then, the following decomposition holds:_

\[\mathbb{E}_{D}[f_{\hat{\eta}}]-\mathbb{E}_{P}[f_{\eta}]=\underbrace{\mathbb{ E}_{D-P}[f_{\eta}]}_{=A}+\underbrace{\mathbb{E}_{D-P}[f_{\hat{\eta}}-f_{ \eta}]}_{=B}+\mathbb{E}_{P}[f_{\hat{\eta}}-f_{\eta}].\] (19)

_Suppose further that samples used for estimating \(\eta\) are independent and separate; and the nuisances are consistent. Then, \(R=A+B\) is a random variable that converges to zero at a rate \(\mathcal{O}_{P}(1/\sqrt{n})\)._

**Prop. 8 restated.**_Suppose the nuisance estimates \((\hat{\bm{\mu}},\hat{\bm{\gamma}})\) are \(L_{2}\)-consistent and bounded. Then, the error of the DML estimator \(\hat{T}^{\text{DML}}\in\{\hat{T}^{\text{DML},\ell},\hat{T}^{\text{DML},u}\}\) in Def. 5 is given as follows_

\[\hat{T}^{\text{DML}}-T^{\text{DML}}=\frac{1}{K}\sum_{k=1}^{K}R_{k}+O_{P}\Big{(} \|\hat{\gamma}_{2,k}-\gamma_{2}\|\hat{\mu}_{2,k}-\mu_{2}\|\Big{)}+O_{P}\Big{(} \|\hat{\gamma}_{1,k}-\gamma_{1}\|\hat{\mu}_{1,k}-\hat{\hat{\mu}}_{1,k}\|\Big{)}\]

_where \(R_{k}\) is a random variable that converges to zero at a rate \(\mathcal{O}_{P}(1/\sqrt{n})\)._

Proof.: In this proof we consider the estimation of the lower bund without loss of generality. Recall the definition of nuisance functions and estimators:

\[\gamma_{2}:=\bar{\bm{\mu}}_{\bm{V}}\gamma_{1},\quad\gamma_{1}:=\bar{\bm{\pi}}_ {\bm{T}}\mathbbm{1}_{\bm{z}}(\bm{Z})/P(\bm{T},\bm{Z}\mid\bm{W}\backslash\bm{Z },\bm{C}),\]

with \(T^{\text{PW},\ell}:=\mathbb{E}_{P}[\gamma_{2}Y]=\psi_{\bm{z}}^{\ell}\). And \(\bm{\mu}=(\mu_{0},\mu_{1},\tilde{\mu}_{2},\mu_{2})\) defined by

\[\mu_{2}:=\mu_{2}(\bm{R},\bm{C},\bm{W},\bm{Z})=\mathbb{E}_{P}[Y\mid \bm{R},\bm{C},\bm{W},\bm{Z}],\] \[\tilde{\mu}_{1}:=\tilde{\mu}_{2}(\bm{R},\bm{C},\bm{W},\bm{Z})= \bar{\pi}_{\bm{U}}(\bm{U}\mid\bm{C})\mu_{2}(\bm{R},\bm{C},\bm{W},\bm{Z}),\] \[\mu_{1}:=\mu_{1}(\bm{T},\bm{C},\bm{W},\bm{Z})=\mathbb{E}_{P}[ \tilde{\mu}_{2}(\bm{R},\bm{C},\bm{W},\bm{Z})\mid\bm{T},\bm{C},\bm{W},\bm{Z}],\] \[\mu_{0}:=\mu_{0}(\bm{C},\bm{W},\bm{Z})=\sum_{\bm{t}}\mu_{1}(\bm{ t},\bm{C},\bm{W},\bm{Z})\bar{\pi}_{\bm{T}}(\bm{t}\mid\bm{C}).\]

We first verify that the population level value of the regression estimator coincides with the lower bound \(\psi_{\bm{z}}^{\ell}\). This can be seen with the following derivation,

\[T^{\text{REG},\ell} :=\mathbb{E}_{P}[\mu_{0}(\bm{W}\backslash\bm{Z},\bm{C},\bm{z})]\] \[=\sum_{\bm{w}\backslash\bm{z},\bm{c}}\mu_{0}(\bm{w},\bm{c},\bm{z })P(\bm{w}\backslash\bm{z},\bm{c})\] \[=\sum_{\bm{w}\backslash\bm{z},\bm{c}}\left(\sum_{\bm{t}}\mu_{1}( \bm{t},\bm{w},\bm{c},\bm{z})\bar{\pi}_{\bm{T}}\right)P(\bm{w}\backslash\bm{z },\bm{c})\] \[=\sum_{\bm{t},\bm{w}\backslash\bm{z},\bm{c}}\left(\sum_{u}\mu_{2} (\bm{t},\bm{u},\bm{c},\bm{w}\backslash\bm{z},\bm{z})\bar{\pi}_{\bm{U}}P(\bm{u} \mid\bm{t},\bm{z},\bm{w}\backslash\bm{z},\bm{c})\right)\frac{\bar{\pi}_{\bm{T }}}{P(\bm{t},\bm{z}\mid\bm{w}\backslash\bm{z},\bm{c})}P(\bm{t},\bm{z},\bm{w} \backslash\bm{z},\bm{c})\] \[=\sum_{\bm{t},\bm{w}\backslash\bm{z},\bm{c}}\left(\sum_{y}yP(y \mid\bm{t},\bm{u},\bm{z},\bm{w}\backslash\bm{z},\bm{c})\right)\frac{\bar{\pi}_ {\bm{R}}}{P(\bm{t},\bm{z}\mid\bm{w}\backslash\bm{z},\bm{c})}P(\bm{t},\bm{u}, \bm{z},\bm{w},\bm{c})\] \[=\sum_{y,\bm{t},\bm{u},\bm{z}^{\prime},\bm{w}\backslash\bm{z}^{ \prime},\bm{c}}y\frac{\bar{\pi}_{\bm{R}}\mathbbm{1}_{\bm{z}}(\bm{z}^{\prime})}{ P(\bm{t},\bm{z}^{\prime}\mid\bm{w}\backslash\bm{z}^{\prime},\bm{c})}P(y,\bm{t},\bm{u}, \bm{z}^{\prime},\bm{w}\backslash\bm{z}^{\prime},\bm{c})\] \[=\mathbb{E}_{P}[Y\bar{\pi}_{\bm{R}}\mathbbm{1}_{\bm{z}}(\bm{Z})/P( \bm{T},\bm{Z}\mid\bm{W}\backslash\bm{Z},\bm{C})]\] \[=\psi_{\bm{z}}^{\ell}\]

The DML estimator is similarly unbiased as,

\[T^{\text{DML},\ell} :=\mathbb{E}_{P}[\gamma_{2}\{Y-\mu_{2}\}]+\mathbb{E}_{P}[\gamma_{ 1}\{\tilde{\mu}_{1}-\mu_{1}\}]+\mathbb{E}_{P}[\mu_{0}]\] \[=\mathbb{E}_{P}[\gamma_{2}\{\mathbb{E}_{P}[Y\mid\bm{R},\bm{W} \backslash\bm{Z},\bm{C},\bm{Z}]-\mu_{2}\}]+\mathbb{E}_{P}[\gamma_{1}\{\tilde{\mu }_{1}-\mu_{1}\}]+\mathbb{E}_{P}[\mu_{0}]\] \[=\mathbb{E}_{P}[\gamma_{2}\{\mu_{2}-\mu_{2}\}]+\mathbb{E}_{P}[ \gamma_{1}\{\mathbb{E}_{P}[\tilde{\mu}_{1}\mid\bm{T},\bm{C},\bm{W} \backslash\bm{Z},\bm{Z}]-\mu_{1}\}]+\mathbb{E}_{P}[\mu_{0}]\] \[=\mathbb{E}_{P}[\gamma_{1}\{\mu_{1}

Consider the estimated value of \(T^{\text{DML},\ell}\) following the procedure in Def. 5,

\[\hat{T}^{\text{DML},\ell}:=\frac{1}{K}\sum_{k=1}^{K}\hat{T}_{k}^{\text{DML},\ell },\quad\hat{T}_{k}^{\text{DML},\ell}:=\mathbb{E}_{\mathcal{D}^{(k)}}[\hat{ \gamma}_{2}\{Y-\hat{\mu}_{2}\}]+\mathbb{E}_{\mathcal{D}^{(k)}}[\hat{\gamma}_{1 }\{\hat{\tilde{\mu}}_{1}-\hat{\mu}_{1}\}]+\mathbb{E}_{\mathcal{D}^{(k)}}[\hat{ \mu}_{0}],\]

We could then write,

\[\hat{T}_{k}^{\text{DML},\ell}-T^{\text{DML},\ell}=A+B+C\]

where,

\[A =\mathbb{E}_{\mathcal{D}^{(k)}-P}\Big{[}\gamma_{2}\{Y-\mu_{2}\}+ \gamma_{1}\{\tilde{\mu}_{1}-\mu_{1}\}+\mu_{0}\Big{]}\] \[B =\mathbb{E}_{\mathcal{D}^{(k)}-P}\Big{[}\Big{(}\gamma_{2}\{Y-\mu _{2}\}]+\gamma_{1}\{\tilde{\mu}_{1}-\mu_{1}\}+\mu_{0}\Big{)}-\Big{(}\hat{ \gamma}_{2}\{Y-\hat{\mu}_{2}\}+\hat{\gamma}_{1}\{\hat{\tilde{\mu}}_{1}-\hat{ \mu}_{1}\}+\hat{\mu}_{0}\Big{)}\Big{]}\] \[C =\mathbb{E}_{P}\Big{[}\Big{(}\gamma\{Y-\mu_{2}\}]+\gamma\{\tilde{ \mu}_{1}-\mu_{1}\}+\mu_{0}\Big{)}-\Big{(}\hat{\gamma}_{2}\{Y-\hat{\mu}_{2}\}+ \hat{\gamma}_{1}\{\hat{\tilde{\mu}}_{1}-\hat{\mu}_{1}\}+\hat{\mu}_{0}\Big{)} \Big{]}\]

By the construction in Def. 5, the samples used for estimating \((\gamma_{1},\gamma_{2},\mu_{0},\mu_{1},\tilde{\mu}_{1},\mu_{2})\) and evaluating the outer expectation are independent and separate. Under the assumption that nuisance parameters \((\hat{\gamma}_{1},\hat{\gamma}_{2},\hat{\mu}_{0},\hat{\mu}_{1},\hat{\tilde{ \mu}}_{1},\hat{\mu}_{2})\) are consistent, \(R=A+B\) converges to zero at a rate \(\mathcal{O}_{P}(1/\sqrt{|\mathcal{D}^{(k)}|})\) by Lem. 2.

Before manipulating \(C\) and deriving its large sample behaviour, consider the following intermediate results:

\[\mathbb{E}_{P}[\mu_{0}] =\sum_{\bm{c},\bm{w}}\mu_{0}(\bm{c},\bm{w},\bm{z})P(\bm{c},\bm{w})\] \[=\sum_{\bm{c},\bm{w}}\sum_{\bm{t}}\bar{\pi}_{\bm{T}}\mu_{1}(\bm{t },\bm{c},\bm{w},\bm{z})P(\bm{c},\bm{w})\] \[=\sum_{\bm{c},\bm{w},\bm{z}^{\prime},\bm{t}}\bar{\pi}_{\bm{T}} \mathbbm{1}_{\bm{z}}(\bm{z}^{\prime})\mu_{1}(\bm{t},\bm{c},\bm{w},\bm{z}^{ \prime})P(\bm{c},\bm{w})\] \[=\sum_{\bm{c},\bm{w},\bm{z}^{\prime},\bm{t}}\frac{\bar{\pi}_{\bm{ T}}\mathbbm{1}_{\bm{z}}(\bm{z}^{\prime})}{P(\bm{t},\bm{z}^{\prime}\mid\bm{c},\bm{w})} \mu_{1}(\bm{t},\bm{c},\bm{w},\bm{z}^{\prime})P(\bm{t},\bm{c},\bm{w},\bm{z}^{ \prime})\] \[=\mathbb{E}_{P}[\gamma_{1}\mu_{1}],\]

and similarly \(\mathbb{E}_{P}[\hat{\mu}_{0}]=\mathbb{E}_{P}[\gamma_{1}\hat{\mu}_{1}]\). Note further that,

\[\mathbb{E}_{P}[\gamma_{2}\mu_{2}] =\sum_{\bm{c},\bm{w},\bm{t},\bm{u},\bm{z}^{\prime}}\frac{\bar{\pi }_{\bm{T}}\bar{\pi}_{\bm{U}}\mathbbm{1}_{\bm{z}}(\bm{z}^{\prime})}{P(\bm{t},\bm{ z}^{\prime}\mid\bm{c},\bm{w})}\mu_{2}(\bm{c},\bm{w},\bm{t},\bm{u},\bm{z}^{ \prime})P(\bm{c},\bm{w},\bm{t},\bm{u},\bm{z}^{\prime})\] \[=\sum_{\bm{c},\bm{w},\bm{t},\bm{u},\bm{z}^{\prime}}\gamma_{1}\bar{ \pi}_{\bm{U}}\mu_{2}(\bm{c},\bm{w},\bm{t},\bm{u},\bm{z}^{\prime})P(\bm{c},\bm{w},\bm{t},\bm{u},\bm{z}^{\prime})\] \[=\sum_{\bm{c},\bm{w},\bm{t},\bm{u},\bm{z}^{\prime}}\gamma_{1}\tilde {\mu}_{1}(\bm{c},\bm{w},\bm{t},\bm{u},\bm{z}^{\prime})P(\bm{c},\bm{w},\bm{t}, \bm{z}^{\prime})\] \[=\mathbb{E}_{P}[\gamma_{1}\hat{\mu}_{1}],\]

and similarly \(\mathbb{E}_{P}[\gamma_{2}\hat{\mu}_{2}]=\mathbb{E}_{P}[\gamma_{1}\hat{\tilde{ \mu}}_{1}]\).

Now consider \(C=C_{1}+C_{2}+C_{3}\) where,

\[C_{1} :=\mathbb{E}_{P}[\hat{\gamma}_{2}\{Y-\hat{\mu}_{2}\}-\gamma_{2}\{Y- \mu_{2}\}]=\mathbb{E}_{P}[\hat{\gamma}_{2}\{\mu_{2}-\hat{\mu}_{2}\}]\] \[C_{2} :=\mathbb{E}_{P}[\hat{\gamma}_{1}\{\hat{\tilde{\mu}}_{1}-\hat{\mu} _{1}\}-\gamma_{1}\{\tilde{\mu}_{1}-\mu_{1}\}]\] \[C_{3} :=\mathbb{E}_{P}[\hat{\mu}_{0}-\mu_{0}]=\mathbb{E}_{P}[\gamma_{1} \hat{\mu}_{1}-\gamma_{1}\mu_{1}]\]where the last equality follows from the result above. Therefore

\[C =\mathbb{E}_{P}\Big{[}\hat{\gamma}_{2}\{\mu_{2}-\hat{\mu}_{2}\}+\hat{ \gamma}_{1}\{\hat{\bar{\mu}}_{1}-\hat{\mu}_{1}\}-\gamma_{1}\{\tilde{\mu}_{1}- \mu_{1}\}+\gamma_{1}(\hat{\mu}_{1}-\mu_{1})\Big{]}\] \[=\mathbb{E}_{P}\Big{[}\{\hat{\gamma}_{2}-\gamma_{2}\}\{\mu_{2}- \hat{\mu}_{2}\}+\gamma_{2}\{\mu_{2}-\hat{\mu}_{2}\}+\hat{\gamma}_{1}\{\hat{ \bar{\mu}}_{1}-\hat{\mu}_{1}\}-\gamma_{1}\{\tilde{\mu}_{1}-\mu_{1}\}+\gamma_{1 }(\hat{\mu}_{1}-\mu_{1})\Big{]}\] \[=\mathbb{E}_{P}\Big{[}\{\hat{\gamma}_{2}-\gamma_{2}\}\{\mu_{2}- \hat{\mu}_{2}\}\Big{]}+\mathbb{E}_{P}\Big{[}\gamma_{2}\{\mu_{2}-\hat{\mu}_{2} \}+\hat{\gamma}_{1}\{\hat{\bar{\mu}}_{1}-\hat{\mu}_{1}\}-\gamma_{1}\{\tilde{ \mu}_{1}-\hat{\mu}_{1}\}\Big{]}\] \[\stackrel{{(1)}}{{=}}\mathbb{E}_{P}\Big{[}\{\hat{ \gamma}_{2}-\gamma_{2}\}\{\mu_{2}-\hat{\mu}_{2}\}\Big{]}+\mathbb{E}_{P}\Big{[} \gamma_{1}\{\tilde{\mu}_{1}-\hat{\bar{\mu}}_{1}\}+\hat{\gamma}_{1}\{\hat{\bar {\mu}}_{1}-\hat{\mu}_{1}\}-\gamma_{1}\{\tilde{\mu}_{1}-\hat{\mu}_{1}\}\Big{]}\] \[=O_{P}\Big{(}\|\hat{\gamma}_{2}-\gamma_{2}\|\|\mu_{2}-\hat{\mu}_{ 2}\|\Big{)}+O_{P}\Big{(}\|\hat{\gamma}_{1}-\gamma_{1}\|\|\hat{\bar{\mu}}_{1}- \hat{\mu}_{1}\|\Big{)}\]

(1) holds by the equalities \(\mathbb{E}_{P}[\gamma_{2}\mu_{2}]=\mathbb{E}_{P}[\gamma_{1}\tilde{\mu}_{1}], \mathbb{E}_{P}[\gamma_{2}\hat{\mu}_{2}]=\mathbb{E}_{P}[\gamma_{1}\hat{\bar{ \mu}}_{1}]\).

Finally, this implies that

\[\hat{T}^{\text{DML},\ell}-T^{\text{DML},\ell}=R+O_{P}\Big{(}\|\hat{\gamma}_{2} -\gamma_{2}\|\|\mu_{2}-\hat{\mu}_{2}\|\Big{)}+O_{P}\Big{(}\|\hat{\gamma}_{1}- \gamma_{1}\|\|\hat{\bar{\mu}}_{1}-\hat{\mu}_{1}\|\Big{)}\] (20)

where \(R\) is a random variable that converges to zero at a rate \(\mathcal{O}_{P}(1/\sqrt{n})\).

For the upper bound, consider the following definition of nuisance functions and estimators:

\[\gamma_{2}:=\bar{\pi}_{\bm{U}}\gamma_{1},\quad\gamma_{1}:=\bar{\pi}_{\bm{T}} \mathbbm{1}_{\bm{z}}(\bm{Z})/P(\bm{T},\bm{Z}\mid\bm{W}\bm{\backslash}\bm{Z}, \bm{C}),\]

with \(T^{\text{PW},\ell}:=\mathbb{E}_{P}[\gamma_{2}(Y-1)]+1=\psi_{\bm{z}}^{\ell}\). And \(\bm{\mu}=(\mu_{0},\mu_{1},\hat{\mu}_{2},\mu_{2})\) defined by

\[\mu_{2}:=\mu_{2}(\bm{R},\bm{C},\bm{W},\bm{Z})=\mathbb{E}_{P}[Y-1 \mid\bm{R},\bm{C},\bm{W},\bm{Z}],\] \[\tilde{\mu}_{1}:=\tilde{\mu}_{2}(\bm{R},\bm{C},\bm{W},\bm{Z})= \bar{\pi}_{\bm{U}}(\bm{U}\mid\bm{C})\mu_{2}(\bm{R},\bm{C},\bm{W},\bm{Z}),\] \[\mu_{1}:=\mu_{1}(\bm{T},\bm{C},\bm{W},\bm{Z})=\mathbb{E}_{P}[ \tilde{\mu}_{2}(\bm{R},\bm{C},\bm{W},\bm{Z})\mid\bm{T},\bm{C},\bm{W},\bm{Z}],\] \[\mu_{0}:=\mu_{0}(\bm{C},\bm{W},\bm{Z})=\sum_{\bm{t}}\mu_{1}(\bm{t },\bm{C},\bm{W},\bm{Z})\bar{\pi}_{\bm{T}}(\bm{t}\mid\bm{C}).\]

We first verify that the population level value of the regression estimator coincides with the lower bound \(\psi_{\bm{z}}^{\ell}\). This can be seen with the following derivation,

\[T^{\text{REG},u}:=\mathbb{E}_{P}[\mu_{0}(\bm{W}\bm{\backslash}\bm{Z},\bm{C}, \bm{z})]+1\]

\[=1+\sum_{\bm{w}\bm{\backslash}\bm{z},\bm{c}}\left(\sum_{\bm{t}}\mu_{1}(\bm{t },\bm{w},\bm{c},\bm{z})\bar{\pi}_{\bm{T}}\right)P(\bm{w}\bm{\backslash}\bm{z}, \bm{c})\]

\[=1+\sum_{\bm{t},\bm{w}\bm{\backslash}\bm{z},\bm{c}}\left(\sum_{u}\mu_{2}(\bm{t },\bm{u},\bm{c},\bm{w}\bm{\backslash}\bm{z},\bm{z})\bar{\pi}_{\bm{U}}P(\bm{u} \mid\bm{t},\bm{z},\bm{w}\bm{\backslash}\bm{z},\bm{c})\right)\frac{\bar{\pi}_{ \bm{T}}}{P(\bm{t},\bm{z}\mid\bm{w}\bm{\backslash}\bm{z},\bm{c})}P(\bm{t},\bm{z },\bm{w}\bm{\backslash}\bm{z},\bm{c})\]

\[=1+\sum_{\bm{t},\bm{w}\bm{\backslash}\bm{z},\bm{c}}\left(\sum_{y}(y-1)P(y \mid\bm{t},\bm{u},\bm{z},\bm{w}\bm{\backslash}\bm{z},\bm{c})\right)\frac{\bar{ \pi}_{\bm{R}}}{P(\bm{t},\bm{z}\mid\bm{w}\bm{\backslash}\bm{z},\bm{c})}P(\bm{t}, \bm{u},\bm{z},\bm{w},\bm{c})\]

\[=1+\sum_{\bm{t},\bm{u},\bm{z}^{\prime},\bm{w}\bm{\backslash}\bm{z}^{\prime}, \bm{c}}(y-1)\frac{\bar{\pi}_{\bm{R}}\mathbbm{1}_{\bm{z}}(\bm{z}^{\prime})}{P( \bm{t},\bm{z}^{\prime}\mid\bm{w}\bm{\backslash}\bm{z}^{\prime},\bm{c})}P(y,\bm{t },\bm{u},\bm{z}^{\prime},\bm{w}\bm{\backslash}\bm{z}^{\prime},\bm{c})\]

\[=1+\mathbb{E}_{P}[(Y-1)\bar{\pi}_{\bm{R}}\mathbbm{1}_{\bm{z}}(\bm{Z})/P(\bm{T}, \bm{Z}\mid\bm{W}\bm{\backslash}\bm{Z},\bm{C})]\]

\[=\psi_{\bm{z}}^{u}\]

The DML estimator is similarly unbiased as,

\[T^{\text{DML},u}:=\mathbb{E}_{P}[\gamma_{2}\{(Y-1)-\mu_{2}\}]+ \mathbb{E}_{P}[\gamma_{1}\{\tilde{\mu}_{1}-\mu_{1}\}]+\mathbb{E}_{P}[\mu_{0}]+1\] \[\qquad\qquad\qquad\qquad=\mathbb{E}_{P}[\gamma_{2}\{\mathbb{E}_{P}[Y-1 \mid\bm{R},\bm{W}\bm{\backslash}\bm{Z},\bm{C},\bm{Z}]-\mu_{2}\}]+\mathbb{E}_{P}[ \gamma_{1}\{\tilde{\mu}_{1}-\mu_{1}\}]+\mathbb{E}_{P}[\mu_{0}]+1\] \[\qquad\qquad\qquad=\mathbb{E}_{P}[\gamma_{2}\{\mu_{2}-\mu_{2}\}]+ \mathbb{E}_{P}[\gamma_{1}\{\mathbb{E}_{P}[\tilde{\mu}_{1}\mid\bm{T},\bm{C}, \bm{W}\bm{\backslash}\bm{Z},\bm{Z}]-\mu_{1}\}]+\mathbb{E}_{P}[\mu_{0}]+1\] \[\qquad\qquad\qquad=\mathbb{E}_{P}[\gamma_{1}\{\mu_{1}-\mu_{1}\}]+ \mathbb{E}_{P}[\mu_{0}]+1\] \[\qquad\qquad\qquad=\mathbb{E}_{P}[\mu_{0}]+1\] \[\qquad\qquad\qquad=\psi_{\bm{z}}^{u}.\]The arguments of the proof are now analogous to that of the lower bound. We can conclude therefore that,

\[\hat{T}^{\text{DML},u}-T^{\text{DML},u}=R+O_{P}\Big{(}\|\hat{\gamma}_{2}-\gamma_{ 2}\|\|\mu_{2}-\hat{\mu}_{2}\|\Big{)}+O_{P}\Big{(}\|\hat{\gamma}_{1}-\gamma_{1} \|\|\hat{\tilde{\mu}}_{1}-\hat{\mu}_{1}\|\Big{)}.\] (21)

**Prop. 9 restated**.: _Suppose either \(\hat{\gamma}_{1}=\gamma_{1}\) or \(\hat{\mu}_{2}=\mu_{2}\) and that either \(\hat{\gamma}_{1}=\gamma_{1}\) or \(\hat{\tilde{\mu}}_{1}=\hat{\mu}_{1}\). Then, \(\hat{T}^{\text{DML}}\in\{\hat{T}^{\text{DML},\ell},\hat{T}^{\text{DML},u}\}\) is an unbiased estimator of the corresponding bound defined in Alg. 1._

Proof.: Consider the estimated value of \(T^{\text{DML},\ell}\) following the procedure in Def. 5,

\[\hat{T}^{\text{DML},\ell}:=\frac{1}{K}\sum_{k=1}^{K}\hat{T}_{k}^{\text{DML}, \ell},\quad\hat{T}_{k}^{\text{DML},\ell}:=\mathbb{E}_{\mathcal{D}^{(k)}}[\hat{ \gamma}_{2}\{Y-\hat{\mu}_{2}\}]+\mathbb{E}_{\mathcal{D}^{(k)}}[\hat{\gamma}_{ 1}\{\hat{\tilde{\mu}}_{1}-\hat{\mu}_{1}\}]+\mathbb{E}_{\mathcal{D}^{(k)}}[ \hat{\mu}_{0}],\]

Under the assumption that,

\[\mathbb{E}_{P}[\hat{T}^{\text{DML},\ell}]=\mathbb{E}_{P}[\hat{\gamma}_{2}\{Y- \hat{\mu}_{2}\}]+\mathbb{E}_{P}[\hat{\gamma}_{1}\{\hat{\tilde{\mu}}_{1}-\hat{ \mu}_{1}\}]+\mathbb{E}_{P}[\hat{\mu}_{0}]\]

The bias of the estimator is given by,

\[\mathbb{E}_{P}[\hat{T}^{\text{DML},\ell}]-T^{\text{DML},\ell}\] \[=\mathbb{E}_{P}\Big{[}\Big{(}\gamma\{Y-\mu_{2}\}]+\gamma\{\tilde{ \mu}_{1}-\mu_{1}\}+\mu_{0}\Big{)}-\Big{(}\hat{\gamma}_{2}\{Y-\hat{\mu}_{2}\}+ \hat{\gamma}_{1}\{\hat{\tilde{\mu}}_{1}-\hat{\mu}_{1}\}+\hat{\mu}_{0}\Big{)} \Big{]}\] \[=\mathbb{E}_{P}\Big{[}\{\hat{\gamma}_{2}-\gamma_{2}\}\{\mu_{2}- \hat{\mu}_{2}\}\Big{]}+\mathbb{E}_{P}\Big{[}\{\hat{\gamma}_{1}-\gamma_{1}\} \{\hat{\tilde{\mu}}_{1}-\hat{\mu}_{1}\}\Big{]}\]

The last equality follows from the derivation of (C) in the proof of Prop. 8.

If either \(\hat{\gamma}_{1}=\gamma_{1}\) or \(\hat{\mu}_{2}=\mu_{2}\) and that either \(\hat{\gamma}_{1}=\gamma_{1}\) or \(\hat{\tilde{\mu}}_{1}=\tilde{\mu}_{1}\) then this expression equals 0 and we have that,

\[\mathbb{E}_{P}[\hat{T}^{\text{DML},\ell}]-T^{\text{DML},\ell}=0.\]

An analogous result holds for the upper bound.

[MISSING_PAGE_FAIL:30]

Example 3.The data generating mechanism for the third scenario is given by:

\[U_{X_{1}Y},U_{X_{2}W},U_{X_{2}},U_{X_{1}}, U_{C} \sim\mathcal{N}(0,1),\] \[\bm{W} :=\{W_{1},\ldots,W_{100}\}\text{ s.t. }W_{i}\sim\mathcal{N}(0,1),i=1,\ldots,100,\] \[C :=f_{C}(U_{C}),\] \[X_{1} :=f_{X_{1}}(C,U_{X_{1}Y},U_{X_{1}}),\] \[X_{2} :=f_{X_{2}}(\bm{W},U_{X_{2}}),\] \[Y :=f_{Y}(X_{1},X_{2},C,\bm{W},U_{X_{1}Y}),\]

where,

\[f_{C}(U_{C}) :=U_{C},\] \[f_{X_{1}}(C,U_{X_{1}Y},U_{X_{1}}) :=\mathbbm{1}\{U_{X_{1}Y}\cdot(1+\exp\{0.75C+0.5\})>U_{X_{1}}\},\] \[f_{X_{2}}(\bm{W},U_{X_{2}}) :=\mathbbm{1}\{W_{1}+W_{2}+U_{X_{2}}>0\},\] \[f_{Y}(X_{1},X_{2},C,\bm{W},U_{X_{1}Y}) :=(2X_{1}-1)\cdot(C+1)+2\sin(2C\cdot(2X_{1}-1))\] \[-2(2U_{X_{1}Y}-1)(1+0.5C)+X_{2}+\sum_{i=1,\ldots,100}W_{i}/100.\]

The outcome \(Y\) is then re-scaled to lie in the \([0,1]\) interval. The target for estimation can be derived with Alg. 1 and equals, for the lower and upper bound respectively,

\[\mathbb{E}_{P}[\bar{\bm{\pi}}Y/P(X_{2}\mid\bm{W},C)],\qquad\mathbb{E}_{P}[ \bar{\bm{\pi}}(Y-1)/P(X_{2}\mid\bm{W},C)]+1.\]

Example 4.The data generating mechanism for the fourth scenario is given by:

\[U_{Z},U_{X_{1}Y},U_{X_{2}},U_{X_{1}},U_{C}, U_{Z} \sim\mathcal{N}(0,1),\] \[Z :=f_{Z}(U_{Z})\] \[\bm{W} :=\{W_{1},\ldots,W_{5}\}\text{ s.t. }W_{i}\sim\mathcal{N}(0,1),i=1, \ldots,5,\] \[C :=f_{C}(U_{C}),\] \[X_{1} :=f_{X_{1}}(C,Z,U_{X_{1}Y},U_{X_{1}},Z),\] \[X_{2} :=f_{X_{2}}(\bm{W},U_{X_{2}}),\] \[Y :=f_{Y}(X_{1},X_{2},C,W,U_{X_{1}Y}),\]

where,

\[f_{C}(U_{C}) :=U_{C},\] \[f_{Z}(U_{Z}) :=\mathbbm{1}\{U_{Z}>0\},\] \[f_{X_{1}}(U_{X_{1}Y},U_{X_{1}},Z,U_{C}) :=\mathbbm{1}\{U_{X_{1}Y}\cdot(1+\exp\{0.75U_{C}+0.5Z+0.5\})>U_{X _{1}}\},\] \[f_{X_{2}}(\bm{W},U_{X_{2}}) :=\mathbbm{1}\{W_{1}+W_{2}+U_{X_{2}}>0\},\] \[f_{Y}(X_{1},X_{2},C,\bm{W},U_{X_{1}Y}) :=(2X_{1}-1)\cdot(C+1)+2\sin(2C\cdot(2X_{1}-1))\] \[-2(2U_{X_{1}Y}-1)(1+0.5C)+X_{2}+W_{1}\]

The outcome \(Y\) is then re-scaled to lie in the \([0,1]\) interval. The target for estimation can be derived with Alg. 1 and equals, for the lower and upper bound respectively,

\[\max_{z\in\{0,1\}}\mathbb{E}_{P}[\bar{\pi}\mathbbm{1}_{z}(Z)Y/P(Z,X_{2}\mid \bm{W},C)],\quad\min_{z\in\{0,1\}}\mathbb{E}_{P}[\bar{\pi}\mathbbm{1}_{z}(Z)(Y -1)/P(Z,X_{2}\mid\bm{W},C)]+1.\]

### Health Campaign Evaluation

The data was curated from anonymous from Colombia, Peru and Mexico, using a web platform [30]. The exact questions considered in the survey can be found in [30]. The authors made the data available under a Creative Commons license5 and is currently hosted by Kaggle as a c.s.v file, accessible through the following link: kaggle.com/code/mpwoolke/obesity-levels-life-style/.

We considered a number of pre-processing steps. In particular, we created a BMI variable from weight and height data that were a posteriori removed from the dataset, imputed (with median or mode among observed instances) missing values, scaled continuously-valued covariates by subtracting the mean and dividing by the standard deviation, and scaled the outcome BMI to lie in the interval \([0,1]\). Several covariates were ignored, including data on the consumption of water, consumption of vegetables, consumption of food between meals, consumption of alcohol, and number of main meals. These may be interpreted as unobserved variables, potentially confounding other relationships in the data as specified by the assumed causal diagram. The data from a total of \(2111\) individuals was recorded in this study.

The bounds on the effect of a policy \(\bm{\pi}^{\alpha}:=\{\pi_{H}^{\alpha},\pi_{E}^{\alpha}\}\) acting on \(H\) and \(E\), with new assignments defined as \(\{P_{\text{new}}(H=\texttt{ rarely})=\alpha\},P_{\text{new}}(E=\texttt{ regularly})=\alpha\}\) are approximated from the expression in Prop. 4. Following this proposition we find that Age \((A)\), Smoking \((S)\), calories consumption Monitoring \((M)\), and Family history with overweight \((F)\), that is \(\bm{W}=\{A,S,M,F\}\), form a partial adjustment set for \(\pi_{E}^{\alpha}\) given that \((Y\rotatebox[origin={c}]{$\perp_{d}$}E\mid\bm{W},H)_{\mathcal{G}_{\pi_{H}E}}\). We can verify also that \(\bm{Z}=\{T\}\) is a partial instrumental set for \(\bm{\pi}\) since \((Y\rotatebox[origin={c}]{$\perp_{d}$}T)_{\mathcal{G}_{\pi}}\). For illustration, the corresponding mutilated diagrams are shown in Fig. 7. Finally, we partition the data equally to obtain two sets of samples for training first and second stage classifiers and regressors, respectively, obtaining a first estimate of bounds, before then switching the role of the two data samples and averaging over the resulting estimates.

Figure 7: Obesity diagrams.

## Appendix D NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: The claims made match the theoretical and experimental results presented in the paper. The impact statement in the Appendix reflects how much the results can be expected to generalize to other settings. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: We include several remarks in the paper to qualify our contribution, e.g. the remark in Sec. 3, and include an Impact Statement in the Appendix to more thoroughly describe the limitations of our analysis, assumptions, and applicability in real-world settings. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs**Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: All theoretical statement are quoted in full in the paper. We have attempted to provide an example to illustrate the significance of each theoretical statement and highlight its implications. The formal proof of all statements is given in the Appendix. * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: We provide the data generating mechanisms, details of the target of estimation and information as to what python functions and libraries can be used to fit the proposed estimators. We do not, however, disclose an open source implementation of the proposed methods at this moment. * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] and [No] Justification: The data is publicly available and we have provided full details as to where to access the data and how to run the synthetic data generation pipeline. The code will not be open sourced at this moment but we believe to have provided sufficient details to reproduce our results. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: We provided details where applicable. In our case, data splits, hyperparameters, optimizers, etc., are not significant for the implementation the method. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: We report our results as box plots that include several statistics, e.g. median, 25th, 75th, percentiles, etc., to summarize our results for different seeds of the data and algorithm. Guidelines:* The answer NA means that the paper does not include experiments.
* The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.
* The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).
* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [NA] Justification: Experiments were run on a single CPU in under a few minutes of wall time. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: We have read the guidelines and we do not think that our work presents any notable concerns. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes]Justification: We include a broader impact statement in the Appendix. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. * If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: No risk of misuse. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [NA] Justification: The paper does not use existing asset Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL.

* The name of the license (e.g., CC-BY 4.0) should be included for each asset.
* For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.
* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.

13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: The paper does not release new assets. Guidelines:

* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.

14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.

15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.

* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.