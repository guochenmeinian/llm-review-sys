# User-Creator Feature Polarization in Recommender Systems with Dual Influence

 Tao Lin

Harvard University

tlin@g.harvard.edu

&Kun Jin1

Google

kunjin@google.com

&Andrew Estornell

ByteDance

andrew.estornell@bytedance.com

&Xiaoying Zhang

ByteDance

zhangxiaoying.xy@bytedance.com

&Yiling Chen

Harvard University

yiling@seas.harvard.edu

&Yang Liu

University of California, Santa Cruz

yangliu@ucsc.edu

Footnote 1: The first two authors contributed equally to this work. And this work was done when Kun was at TikTok.

###### Abstract

Recommender systems serve the dual purpose of presenting relevant content to users and helping content creators reach their target audience. The dual nature of these systems naturally influences both users and creators: users' preferences are affected by the items they are recommended, while creators may be incentivized to alter their content to attract more users. We define a model, called user-creator feature dynamics, to capture the dual influence of recommender systems. We prove that a recommender system with dual influence is guaranteed to polarize, causing diversity loss in the system. We then investigate, both theoretically and empirically, approaches for mitigating polarization and promoting diversity in recommender systems. Unexpectedly, we find that common diversity-promoting approaches do not work in the presence of dual influence, while relevancy-optimizing methods like top-\(k\) truncation can prevent polarization and improve diversity of the system.

## 1 Introduction

From restaurant selection, video watching, to apartment renting, recommender systems play a pivotal role across a plethora of real-world domains. These systems match users with content they like, and help creators (those producing the content) identify their target audiences. Nevertheless, behind such success, concerns have emerged regarding possible harmful outcomes of recommender systems, in particular, _filter bubbles_[32, 5] and _polarization_[36] - outcomes with insufficient _recommendation diversity_ and _creation diversity_. Recommendation diversity, meaning the diversity of the contents recommended to a user, is key to users' engagement and retention on the platform. Meanwhile, creation diversity, meaning the variety of content created on the platform, is a determinant of the platform's long-term health. In extreme cases, insufficient creation diversity can lead to consensus or polarization, where the latter can cause conflict and hatred, diminish people's mutual understanding, and cause societal crises. Therefore, from both business and social responsibility perspectives, championing and improving diversity in recommender systems is equally important as optimizing recommendation relevancy.

There is increasing emphasis in academia and industry on investigating and improving the diversity of recommender systems, combating filter bubbles and polarization. Popular diversity-boosting approaches include applying post-processing procedures such as re-ranking [11; 47] and setting diversity-aware objectives in addition to relevance maximization [38; 44; 22; 39; 12]. These methods aim to increase the recommendation diversity for users. Assuming that the contents on the platform are static, these methods have been shown to bring diversity gain to the system.

However, an important aspect that is overlooked in the aforementioned approaches is that: users and contents on a recommendation platform are not static entities - they can be _influenced_ by the recommendation made by the system. In content creation platforms like YouTube, TikTok, and Twitter, recommendations naturally affect both content users and content creators. It is well known that the exposure to recommended items can shift a user's preference [24; 26; 14]. On the other hand, the creators have the incentive to change their creation styles constantly to attract their audience better (and to make more profits from the platform) [15; 20; 23]. While the effects of recommendation on either users or creators have been investigated separately, to our knowledge no previous work considers both effects. The dual influence of recommendation on users and creators causes complicated dynamics where users and creators interact and their preferences evolve together. Such evolution might exacerbate filter bubble and polarization effects. Whether the aforementioned diversity-boosting approaches still work in a dynamic environment with dual influence is questionable.

Our contributionsThe first contribution of our work is to define a novel, natural dynamics model that captures the dual influence of a recommender system on users and creators, which we call user-creator feature dynamics (Section 2). We leverage the users' and items'/creators' embedding vectors to represent their preferences and creation styles, and use cosine similarity to characterize the relevance of creations and users' interests (which is common in the recommender system literature and practice). This model allows us to formally reason about the impact of various design choices on the long-term diversity of a recommender system with dual influence.

Our second contribution is to demonstrate that, under realistic conditions, the user-creator feature dynamics of any recommender system with dual influence must unavoidably converge to polarization (Section 3), i.e., the preferences of users and the contents of creators will become tightly clustered into two opposite groups, significantly reducing the diversity of the system. We demonstrate that this phenomenon still occurs even after applying diversity-boosting interventions to the system.

Then, (in Section 4) we investigate some real-world designs of recommendation algorithms in order to look for techniques that mitigate polarization. Interestingly, we find that some common efficiency-improving methods, such as top-\(k\) truncation, can both prevent the system from polarization and improve the creation diversity. We also provide empirical results (Section 5) on both synthetic and real-world (MovieLens) data. As predicted by our theory, we find that systems with dual influence more easily converge to polarization under diversity-boosting designs, while efficiency-oriented and relevance-optimizing designs can in fact improve the long-term diversity of the system. This could explain why polarization does not always happen in reality. Section 6 concludes.

### Related Work

Diversity in recommendationsDiversity, filter bubbles, and polarization in recommendations have been important research topics in recent years, and they are closely related concepts with different focuses. On the one hand, filter bubbles are frequently defined as decreasing recommendation diversity over time [5], which describes both the process and the outcome of insufficiently diverse recommendations. On the other hand, polarization describes the negative outcome of insufficient mutual understanding between people [36]. In content platforms, an example of polarization is people creating content with strong agreement or disagreement with other content under the same topic, e.g., political opinions. To combat these negative outcomes, previous works propose diversity-boosting approaches including re-ranking [11; 47] and diversity-aware objective optimization [38; 44; 22; 39; 12; 45]. Despite having positive effects in situations where user preferences and creation styles are fixed, these approaches overlooked the dynamic nature of recommender systems and our work shows that certain approaches will make long-term outcomes worse under the dual influence.

Opinion dynamicsOpinion dynamics study the effect of people exchanging opinions with others on social networks [37; 17; 29; 4]. Our model of a recommender system with dual influence on usersand creators resembles a bipartite social network, and our conclusion that the system converges to polarization is conceptually similar to people reaching consensus on social networks [1; 10; 31; 46]. However, the technique we use to prove our conclusion (absorbing Markov chain) significantly differs from the main technique (stability of ODE) in the mentioned works.

Performative effects of recommender systemsThe phenomenon that predictive systems like recommender systems can impact the individuals interacting with those systems (e.g., users and creators) is related to the literature of performative prediction [34; 18]. These impacts can be direct, such as individuals ostensibly modifying their features in order to obtain more desirable outcomes [27]. Prior works on the performative effects of recommender systems (e.g., [7; 24; 14; 41; 15; 42; 35; 20; 3; 43; 2; 23]) only consider one-sided impact, either on users or on creators. Differing from them, our work studies two-sided impacts, i.e., on both users and creators. We provide a table to compare our work with previous works in Appendix A.

## 2 Model: User-Creator Feature Dynamics

We define a _dynamics_ model for user preferences and content/creator features in a recommender system. Let \(\bm{U}^{t}=[\bm{u}^{t}_{j}]_{j=1}^{m}=[\bm{u}^{t}_{1},\dots,\bm{u}^{t}_{m}]\in \mathbb{R}^{d\times m}\) be a population of \(m\) users and \(\bm{V}^{t}=[\bm{v}^{t}_{i}]_{i=1}^{n}=[\bm{v}^{t}_{1},\dots,\bm{v}^{t}_{n}]\in \mathbb{R}^{d\times n}\) be a population of \(n\) creators at time \(t\), where each vector \(\bm{u}^{t}_{j},\bm{v}^{t}_{i}\in\mathbb{S}^{d-1}\) represent the preference/feature vector of each user and creator respectively, assumed to be on the unit sphere \(\mathbb{S}^{d-1}\) with \(\ell_{2}\)-norm. Then \((\bm{U}^{t},\bm{V}^{t})\) denotes the state of the dynamics at time \(t\). The dynamics evolve as follows at each time step \(t\geq 0\):

**1) Recommendation:** Each user \(j\in[m]\) is recommended a creator, where creator \(i\in[n]\) is chosen with a probability

\[p^{t}_{ij}=p^{t}_{ij}(\bm{U}^{t},\bm{V}^{t}).\] (1)

While we allow a wide array of different functions \(p^{t}_{ij}(\cdot)\), a common example of such functions is the so-called _softmax function_:

\[p^{t}_{ij}=\mathrm{softmax}(\bm{u}^{t}_{j},\bm{V}^{t};\beta)=\frac{\exp(\beta \langle\bm{u}^{t}_{j},\bm{v}^{t}_{i}\rangle)}{\sum_{i=1}^{n}\exp(\beta\langle \bm{u}^{t}_{j},\bm{v}^{t}_{i}\rangle)}.\] (2)

A larger \(\beta\) means that the recommendation is more sensitive to the _relevance_ of a creator to a user, measured by \(\langle\bm{u}^{t}_{j},\bm{v}^{t}_{i}\rangle\).

**2) User update:** After recommendation, each user \(j\in[m]\) updates their feature vector \(\bm{u}^{t}_{j}\), based on which creator, say \(i^{t}_{j}\), was recommended to them:

\[\bm{u}^{t+1}_{j}=\mathcal{P}\big{(}\bm{u}^{t}_{j}+\eta_{u}f(\bm{v}^{t}_{i^{ \prime}_{j}},\bm{u}^{t}_{j})\bm{v}^{t}_{i^{\prime}_{j}}\big{)}.\] (3)

Here, \(\eta_{u}\in[0,1]\) is a parameter controlling the rate of update, \(f(\bm{v}_{i},\bm{u}_{j})\) is a function that quantifies the impact of creator \(i\)'s content on user \(j\) (discussed in detail later), and \(\mathcal{P}(\bm{x})=\frac{\bm{x}}{\|\bm{x}\|_{2}}\) is the projection back onto the unit sphere. Our user update model generalizes [14], which considers \(\bm{u}^{t+1}_{j}=\mathcal{P}(\bm{u}^{t}_{j}+\eta_{u}\langle\bm{v}^{t}_{i^{ \prime}_{j}},\bm{u}^{t}_{j}\rangle\bm{v}^{t}_{i^{\prime}_{j}})\), by replacing the inner product with a general function \(f\).

**3) Creator update:** Creators also update their feature vectors based on which users are recommended their content. For each creator \(i\in[n]\), let \(J^{t}_{i}=\{j:i^{t}_{j}=i\}\) be the set of users being recommended creator \(i\), then \(\bm{v}^{t}_{i}\) is updated by:

\[\bm{v}^{t+1}_{i}=\mathcal{P}\Big{(}\bm{v}^{t}_{i}+\frac{\eta_{c}}{|J^{t}_{i}|} \sum_{j\in J^{t}_{i}}g(\bm{u}^{t}_{j},\bm{v}^{t}_{i})\bm{u}^{t}_{j}\Big{)},\] (4)

where \(\eta_{c}\in[0,1]\) is a parameter controlling the rate of update, and \(g(\bm{u}_{j},\bm{v}_{i})\) is a function that quantifies the impact of user \(j\) on creator \(i\).

Impact functions \(f\) and \(g\)Our results apply to any impact functions \(f\) and \(g\) that satisfy the following natural assumptions. First, \(f(\bm{v}_{i},\bm{u}_{j})\) and the inner product \(\langle\bm{v}_{i},\bm{u}_{j}\rangle\) have the same sign: \(f(\bm{v}_{i},\bm{u}_{j})\) is \(\begin{cases}>0&\text{if }\langle\bm{v}_{i},\bm{u}_{j}\rangle>0\\ <0&\text{if }\langle\bm{v}_{i},\bm{u}_{j}\rangle<0\\ =0&\text{if }\langle\bm{v}_{i},\bm{u}_{j}\rangle=0.\end{cases}\) This means that if a user _likes_ the content (\(\langle\bm{v}^{t}_{i},\bm{u}^{t}_{j}\rangle>0\)), then the user vector \(\bm{u}_{j}^{t}\) will be updated _towards_ the direction of the creator vector \(\bm{v}_{j}^{t}\). If the user _dislikes_ the content \((\langle\bm{v}_{i}^{t},\bm{u}_{j}^{t}\rangle<0)\), then the user vector \(\bm{u}_{j}^{t}\) will move _away from_\(\bm{v}_{j}^{t}\). Such "biased assimilation" user behavior is well documented in the literature [14]. Further, we assume upper and lower bounds on \(|f|\):

\[|f(\bm{v}_{i},\bm{u}_{j})|\leq 1,\qquad|f(\bm{v}_{i},\bm{u}_{j})|\geq L_{f}>0\text{ whenever } \langle\bm{v}_{i},\bm{u}_{j}\rangle\neq 0.\]

The lower bound \(|f(\bm{v}_{i},\bm{u}_{j})|\geq L_{f}\) means that the exposure to an item that a user likes or dislikes always has some non-negligible impact on the user's preference. For example, \(f(\bm{v}_{i},\bm{u}_{j})=\operatorname{sign}(\langle\bm{v}_{i},\bm{u}_{j} \rangle)a+b\langle\bm{v}_{i},\bm{u}_{j}\rangle\) satisfies both assumptions when \(L_{f}=a>0\) and \(b\geq 0\).

For \(g\), likewise assume that its sign is the same as \(\langle\bm{u}_{j},\bm{v}_{i}\rangle\): \(g(\bm{u}_{j},\bm{v}_{i})\) is \(\begin{cases}>0&u\ (\bm{u}_{j},\bm{v}_{i})>0\\ <0&u\ (\bm{u}_{j},\bm{v}_{i})<0\end{cases}\) Intuitively, this captures the incentive of a creator who aims to maximize the average ratings from users who are recommended their items. On video platforms for example, if the creators are rewarded based on the average rating of their videos, they will try to reinforce their creation styles based on the users who give positive feedback (\(\langle\bm{u}_{j},\bm{v}_{i}\rangle>0\)) so that their creations are more likely to be recommended to those users. Meanwhile, the creators will also change their creation styles based on negative feedback (\(\langle\bm{u}_{j},\bm{v}_{i}\rangle<0\)), but in the opposite direction of the negative-feedback users' interests, so that their creations are less likely to be recommended to those users. Taking both scenarios into account, the creator moves towards the weighted average of user preferences \(\sum_{j\in J_{i}^{t}}g(\bm{u}_{j}^{t},\bm{v}_{i}^{t})\bm{u}_{j}^{t}\), which is captured by our update rule (4). A particular example of \(g\) is the sign function \(g(\bm{u}_{j},\bm{v}_{i})=\operatorname{sign}(\langle\bm{u}_{j},\bm{v}_{i} \rangle)\in\{-1,0,1\}\). We will only consider the sign function \(g\) in order to simplify the theoretical presentation. We believe that all our results can be generalized to other \(g\) functions satisfying similar conditions as \(f\); the details are left as future work.

## 3 Unavoidable Polarization

Having defined the user-creator feature dynamics in a recommender system with dual influence, we now theoretically study how such dynamics evolve. Our main result is: if every creator can be recommended to every user with some non-zero probability, then the dynamics must eventually _polarize_.

**Definition 3.1** (consensus and bi-polarization).: _Let \(R>0\). The dynamics \((\bm{U}^{t},\bm{V}^{t})\) is said to reach:_

* \(R\)-consensus _if there exists a vector_ \(\bm{c}\in\mathbb{R}^{d}\) _such that every feature vector is_ \(R\)_-close to_ \(\bm{c}\)_:_ \(\forall\bm{u}_{j}^{t},\|\bm{u}_{j}^{t}-\bm{c}\|_{2}\leq R\) _and_ \(\forall\bm{v}_{i}^{t},\|\bm{v}_{i}^{t}-\bm{c}\|_{2}\leq R\)_._
* \(R\)-bi-polarization _if there exists a vector_ \(\bm{c}\in\mathbb{R}^{d}\) _such that every feature vector is_ \(R\)_-close to_ \(+\bm{c}\) _or_ \(-\bm{c}\)_:_ \(\forall\bm{u}_{j}^{t}\)_,_ \(\|\bm{u}_{j}^{t}-\bm{c}\|_{2}\leq R\) _or_ \(\|\bm{u}_{j}^{t}+\bm{c}\|_{2}\leq R\)_, and_ \(\forall\bm{v}_{i}^{t}\)_,_ \(\|\bm{v}_{i}^{t}-\bm{c}\|_{2}\leq R\) _or_ \(\|\bm{v}_{i}^{t}+\bm{c}\|_{2}\leq R\)_._

_The dynamics is said to reach \((R,\bm{c})\)-consensus (or \((R,\bm{c})\)-bi-polarization) if the dynamics reaches \(R\)-consensus (or \(R\)-bi-polarization) with the vector \(\bm{c}\)._

Consensus is any state where all users and creators have similar feature vectors (with maximum difference \(R\)), implying that they have similar interests or preferences. Bi-polarization is any state where all users and creators are clustered into two groups with exactly opposite features (e.g., Republicans vs Democrats). Mathematically, consensus is a special case of bi-polarization.

**Proposition 3.2**.: _Bi-polarization states are absorbing: once the dynamics reaches \((R,\bm{c})\)-bi-polarization with some \(R\in[0,1]\) and \(\bm{c}\in\mathbb{S}^{d-1}\), it will satisfy \((R,\bm{c})\)-bi-polarization forever. The same holds for consensus._

A natural property of a recommender system is that every creator can be recommended to every user with some non-zero probability: \(p_{ij}^{t}\geq p_{0}>0\) with some constant \(p_{0}\). This is satisfied by the softmax function, which is a rough model of real-world recommendation algorithms [13; 26]: \(p_{ij}^{t}=\frac{\exp(\beta(\bm{u}_{j}^{t},\bm{v}_{j}^{t}))}{\sum_{i=1}^{n} \exp(\beta(\bm{u}_{j}^{t},\bm{v}_{j}^{t}))}\geq\frac{\exp(-\beta)}{n\exp(\beta)} =p_{0}>0\). Moreover, many large-scale real-world recommendation systems (e.g., Yahoo! [28] and Kuaishou [16]) intentionally insert small random traffic attempting to improve recommendation diversity or explore users' interests [25; 40], which will cause all recommendation probabilities to be non-zero. We show in Theorem 3.3 that, however, a recommender system satisfying \(p_{ij}^{t}\geq p_{0}>0\) must converge to polarization, under some additional conditions on the users' and creators' update rates:

**Theorem 3.3**.: _Suppose \(g(\bm{u}_{j},\bm{v}_{i})=\operatorname{sign}(\langle\bm{u}_{j},\bm{v}_{i}\rangle)\), the update rates \(\eta_{c}\leq\frac{\eta_{u}L_{f}}{2}\) and \(\eta_{u}<\frac{1}{2}\), and the recommendation probability \(p_{ij}^{t}\geq p_{0}>0,\forall i,j,t\). Then, from almost all initial states, the dynamics \((\bm{U}^{t},\bm{V}^{t})\) will eventually reach \(R\)-consensus or \(R\)-bi-polarization for any \(R>0\)._

In other words, if the users' and creators' updates are not too fast and all recommendation probabilities are non-zero, then all users and creators will eventually converge to at most two clusters (regardless of the feature dimension \(d\)). Since creators in one cluster produce similar contents, users in such a polarized system can never receive diverse recommendations. This means that the naive attempt of imposing \(p_{ij}^{t}\geq p_{0}>0\) cannot improve the diversity of a recommender system with dual influence. The conditions on the update rates \(\eta_{u},\eta_{c}\) are only assumed to simplify the proof of Theorem 3.3. Our experiments (in Section 5) will show that polarization still occurs even without those conditions.

Theorem 3.3 does not characterize the rate of convergence of the user-creator feature dynamics to polarization, which we leave as an open question.

The proof of Theorem 3.3 is an absorbing Markov chain argument. It uses the following lemma:

**Lemma 3.4**.: _Suppose \(\eta_{c}\leq\frac{\eta_{u}L_{f}}{2}\) and \(\eta_{u}<\frac{1}{2}\). For any \(R>0\), for almost every state \((\bm{U}^{t},\bm{V}^{t})\) in the state space, there exists a path \((\bm{U}^{t},\bm{V}^{t})\to(\bm{U}^{t+1},\bm{V}^{t+1})\to\cdots\to(\bm{U}^{t+T},\bm{V}^{t+T})\) of finite length that leads to an \(R\)-bi-polarization state \((\bm{U}^{t+T},\bm{V}^{t+T})\)._

The proof of this lemma (in Appendix F) is involved. It uses induction on the number of creators \(n\). The base case of \(n=1\) is proved by a potential function argument. For \(n\geq 2\), we first construct a path that leads the _subsystem_ of \(n-1\) creators and all users to \(R\)-bi-polarization. Then, depending on where the remaining creator is, we construct a sequence of recommendations that leads the remaining creator to one of the two clusters formed by the \(n-1\) creators and all users. Such recommendations will move some users out of the formed clusters, which requires extra care in the proof.

Proof of Theorem 3.3.: For any state \((\bm{U}^{t},\bm{V}^{t})\) in the state space, by Lemma 3.4 there exists a path \((\bm{U}^{t},\bm{V}^{t})\to\cdots\to(\bm{U}^{t+T},\bm{V}^{t+T})\) of length \(T\) that leads to \(R\)-bi-polarization. Because every creator can be recommended to a user with probability at least \(p_{0}\), each transition \((\bm{U}^{t^{\prime}},\bm{V}^{t^{\prime}})\to(\bm{U}^{t^{\prime}+1},\bm{V}^{t^ {\prime}+1})\) happens with probability at least \(p_{0}^{m}\). So, the path of length \(T\) has probability at least \(p_{0}^{mT}>0\), and the probability that the dynamics _does not_ reach \(R\)-bi-polarization after \(KT\) steps is at most \((1-p_{0}^{mT})^{K}\), which \(\to 0\) as \(K\to\infty\). Therefore, with probability \(1\) the dynamics will reach \(R\)-bi-polarization eventually. 

## 4 Discussions on Real-World Designs

Next, we discuss how 4 types of real-world recommender system designs affect the user-creator feature dynamics: top-\(k\) truncation, threshold truncation, diversity-boosting, and uniform traffic.

(1) Top-\(k\) TruncationA prevalent practice in modern two-stage recommendation algorithms on large-scale platforms, such as YouTube [13], is to first filter out items that are unlikely to be relevant to a user, then make recommendations from the remaining items. In particular, we consider the top-\(k\) truncation policy: for every user \(j\), find the \(k\) most relevant creators, namely, the \(k\) creators whose inner products with the user \(\langle\bm{v}_{i}^{t},\bm{u}_{j}^{t}\rangle\) are largest (equivalently, the \(k\) creators whose probabilities \(p_{ij}^{t}\) of being recommended to user \(j\) are highest), then recommend one of those \(k\) creators to user \(j\) with probability proportional to \(p_{ij}^{t}\). The other creators will not be recommended. This practice significantly reduces the computation cost and improves the relevancy of recommendations. Interestingly, we show that such a practice also has the potential to improve the long-term diversity of a recommender system with dual influence.

**Definition 4.1** (clusters).: _We say a state \((\bm{U}^{t},\bm{V}^{t})\) forms \(q\) clusters if there exist \(\bm{c}_{1},\dots,\bm{c}_{q}\in\mathbb{R}^{d}\) and a small number \(R>0\) such that every feature vector is in the \(\ell_{2}\) ball of some \(\bm{c}_{i}\) with radius \(R\) (denoted by \(B(\bm{c}_{\ell},R)=\{\bm{x}:\|\bm{x}-\bm{c}_{\ell}\|_{2}\leq R\}\)), and \(B(\bm{c}_{\ell},2R)\cap B(\bm{c}_{\ell^{\prime}},2R)=\emptyset\) for \(\ell\neq\ell^{\prime}\)._

It is clear that consensus has a single cluster, and bi-polarization has two.

**Proposition 4.2**.: _With top-\(k\) truncation, there exist states \((\bm{U}^{t},\bm{V}^{t})\) that form \(\lfloor n/k\rfloor\) clusters and are absorbing (i.e., once the system forms \(\lfloor n/k\rfloor\) clusters forever)._This result is in contrast with Theorem 3.3 which shows that a recommender system where every creator can be recommended to every user (\(p_{ij}^{t}>0\)) is doomed to polarize. With top-\(k\) truncation where some \(p_{ij}^{t}=0\), polarization can be avoided. Experiments in Section 5.3 support our prediction that top-\(k\) truncation can reduce polarization and improve diversity.

(2) Threshold TruncationBesides top-\(k\) truncation, threshold truncation is another way to filter out irrelevant creators: set a threshold \(\tau\in[-1,1]\) such that any user-creator pair with inner product \(\langle\bm{u}_{i},\bm{v}_{j}\rangle<\tau\) is not recommended. A natural choice is \(\tau=0\), meaning that users will not receive recommendations predicted to be "disliked" by them. Increasing \(\tau\) is similar to increasing the \(\beta\) in the softmax function, which improves recommendation relevance.

**Proposition 4.3**.: _In \(d\)-dimensional feature space, if user-creator pairs with \(\langle\bm{u}_{i},\bm{v}_{j}\rangle<0\) are not recommended, then there exist stable states with \(d+1\) clusters._

Although truncation at \(\tau=0\) allows stable states with \(d+1\) clusters to exist, the dynamics does not necessarily converge to such states; it can still end up with stable states with fewer clusters. In fact, experiments (in Appendix B.2) show that truncation at \(\tau=0\) is _not good_ for diversity and causes severe polarization, while truncation at a large threshold like \(\tau=0.707\) is better at reducing polarization.

(3) Diversity Boosting Diversity boosting aims to explore users' interests and improve users' experience by diversifying recommendation. For example, when making recommendations, the model optimizes the objective:

\[h_{rel}(\langle\bm{u}_{i},\bm{v}_{j}\rangle)+\rho h_{div}(list_{i},\bm{v}_{j}),\] (5)

where \(h_{rel},h_{div}\) rewards the recommendation relevance and diversity respectively and \(list_{i}\) records the recent list of recommended items to user \(i\). \(h_{div}\) can take a simple form of \(\sum_{j^{\prime}\in list_{i}}1-\langle\bm{v}_{j^{\prime}},\bm{v}_{j}\rangle\), and \(\rho>0\) controls the strength of diversity-boosting. Despite being successful when users' preferences and items are fixed, this design alone cannot prevent bi-polarization in our dual-influence dynamics, since the conditions in Theorem 3.3 are still satisfied and the users' and creators' update rules remain the same. Experiments in Section 5.2 support our claim.

(4) Uniform TrafficAdding a small fraction of uniform traffic to the personalized recommendations is another method proposed in previous works to improve recommendation diversity or to explore user preferences [25; 16; 9; 8; 30]. This method gives a non-zero lower bound on the probability of every creator being recommended to every user. So, as a corollary of our Theorem 3.3, it causes a recommender system with dual influence to polarize. Such an observation is striking as it demonstrates that optimizing for recommendation diversity in a static setting can ultimately lead to a huge loss of the system diversity in the long run.

## 5 Experiments

We present experimental results on the behavior of user-creator feature dynamics on synthetic data and real-world (MovieLens 20M) data and the effect of top-\(k\) truncation and threshold truncation on the dynamics.

### Synthetic Data Experiments

SetupThe dynamics is initialized by randomly generating user and creator features on the unit sphere in \(\mathbb{R}^{d}\). We pick \(d=10\), number of creators \(n=50\), number of users \(m=100\). We use the softmax recommendation probability function (2). We simulate the dynamics for \(T=1000\) steps, repeated \(100\) times each with a new initialization. We choose the sign impact function \(g(\bm{u}_{j},\bm{v}_{i})=\operatorname{sign}(\langle\bm{u}_{j},\bm{v}_{i}\rangle)\) for creator updates. For user updates, we choose inner product \(f(\bm{v}_{i},\bm{u}_{j})=\langle\bm{v}_{i},\bm{u}_{j}\rangle\). The inner product function is studied in previous works on users' preference dynamics (but not creators') [14]. Note that the inner product does not satisfy the condition \(|f(\bm{v}_{i},\bm{u}_{j})|\geq L_{f}\) needed in Theorem 3.3. However, we still observe convergence to polarization in nearly all experiments. Thus, even when this condition does not hold, users and creators still tend towards polarization in practice.

Three key parameters in our model are \(\beta\) (sensitivity of the softmax function), \(\eta_{c}\) (creator update rate), and \(\eta_{u}\) (user update rate). We set them to \(\beta=1,\eta_{c}=\eta_{u}=0.1\), and change one parameter at a time to see its effect on the dynamics. We also test what happens when some dimensions of the user features are _fixed_ features that are not updated.

MeasuresTo quantify the behavior of the dynamics, given user and creator feature vectors \((\bm{U},\bm{V})\) we compute the following measures, which cover diversity, relevancy, and polarization of the system:

* _Creator Diversity_ (CD): diversity of the creator features, measured by their average pairwise distance [47, 33]: \(\mathrm{CD}(\bm{V})=\frac{1}{n(n-1)}\sum_{i=1}^{n}\sum_{j\neq i}\|\bm{v}_{i}- \bm{v}_{j}\|\).
* _Recommendation Diversity_ (RD): diversity of the contents recommended to a user, measured by the weighted variance of the contents: \(\mathrm{RD}(\bm{U},\bm{V};\beta)=\frac{1}{m}\sum_{j=1}^{m}\sum_{i=1}^{n}p_{ij }\|\bm{v}_{i}-\overline{\bm{v}}_{j}\|^{2}\), where \(\overline{\bm{v}}_{j}=\sum_{i=1}^{n}p_{ij}\bm{v}_{i}\) and \(p_{ij}=\frac{\exp(\beta(\bm{u}_{j},\bm{v}_{i}))}{\sum_{i=1}^{n}\exp(\beta(\bm {u}_{j},\bm{v}_{i}))}\).
* _Recommendation Relevance_ (RR): relevance of the contents recommended to a user, measured by the weighted average of inner products: \(\mathrm{RR}(\bm{U},\bm{V};\beta)=\frac{1}{m}\sum_{j=1}^{m}\sum_{i=1}^{n}p_{ij }\langle\bm{u}_{j},\bm{v}_{i}\rangle\).
* _Tendency to Polarization_ (TP): This is a novel measure we propose to quantify how close the system is to consensus or bi-polarization, measured by the average absolute inner products between the creators: \(\mathrm{TP}(\bm{V})=\frac{1}{n^{2}}\sum_{i=1}^{n}\sum_{k=1}^{n}|\langle\bm{v }_{i},\bm{v}_{k}\rangle|\). \(\mathrm{TP}(\bm{V})\) being closer to 1 means that the system is more polarized, because the term \(|\langle\bm{v}_{i},\bm{v}_{k}\rangle|\) is 1 iff the two vectors \(\bm{v}_{i},\bm{v}_{k}\) are equal or opposite to each other.

It is worth noting that a high creator diversity is necessary for simultaneously achieving high recommendation relevance and high recommendation diversity. For example, they cannot be simultaneously achieved in a polarized state.

Sensitivity Parameter \(\beta\)A larger \(\beta\) means that a user will be recommended more relevant content/creator with a higher probability. \(\beta=0\), on the other hand, means that the user receives uniform recommendations across all creators. **Our main observation** from the experiments is: _a larger \(\beta\) leads to higher creator diversity and alleviated polarization in the long run_.

Figure 1 shows snapshots of the dynamics at different time steps under different \(\beta\) values. Here, we choose dimension \(d=3\) instead of \(10\) so the feature vectors can be visualized on a 3d sphere. We see that the system tends to form more clusters at time \(t=200\) as \(\beta\) increases.

Figure 2 shows the changes of the 4 measures CD, RD, RR, TP over time under different \(\beta\) values. We see that a more diverse recommendation policy (a smaller \(\beta\)) leads to lower creator diversity and a higher level of polarization in the long run. In particular, while Creator Diversity reaches a similar level under different \(\beta\) in the end, it _drops at a slower rate_ with a _larger \(\beta\)_ (see \(\beta=5,6\)). Moreover, from the plot of Tendency to Polarization, we see that a larger \(\beta\)_alleviates_ polarization, which means improvement in the diversity of the whole system.

An explanation for our observation is the following: When \(\beta\) is smaller, each user receives more uniform recommendations across all creators. So, for different creators, the sets of users recommended

Figure 1: Snapshots of the dynamics simulated with the same initialization but different recommendation sensitivity \(\beta\). A larger \(\beta\) resulted in more clusters at time step \(t=200\).

to those creators have larger intersections. Since the creator updates are based on the sets of recommended users, different creators will be moving towards more similar directions. This leads to faster polarization. One can also predict this observation from Theorem 3.3: when \(\beta\) is large, the minimum recommendation probability \(p_{0}\) of the softmax function tends to \(0\), so it might take a long time for the system to converge to polarization, while with a small \(\beta\) the system polarizes quickly.

Update Rates \(\eta_{c}\) and \(\eta_{u}\)A larger \(\eta_{c}\) means that creator features are updated faster, and intuitively should lead to faster polarization. This is validated in experiments: Figure 3 shows that a larger \(\eta_{c}\) indeed causes more extreme polarization and lower diversity (both CD and RD). A larger \(\eta_{u}\) means that user features are updated faster. It has a similar effect of exacerbating polarization as \(\eta_{c}\) does, as shown in Figure 4.

Number of Fixed DimensionsWe also consider the scenario where some dimensions of the user feature vectors are fixed features and thus not updated from round to round (e.g., age, gender), which is a realistic scenario. Detailed results are in Appendix B.1. The **main observation** is: _as the number of fixed dimensions increases, the diversity of the system improves and the degree of polarization is reduced._ This is similar to the effect of decreasing user update rate \(\eta_{u}\). The observation that

Figure 4: Changes of measures over time under different user update rate \(\eta_{u}\), on synthetic data

Figure 3: Changes of measures over time under different creator update rate \(\eta_{c}\), on synthetic data

Figure 2: Changes of measures over time under different sensitivity parameter \(\beta\), on synthetic data. \(\beta=0\) means uniform (non-personalized) recommendation. \(\beta=\infty\) means hard-max recommendation: only recommend the single most relevant creator to a user. Larger \(\beta\) reduces the tendency to polarization.

fixed dimensions of user features help to improve diversity might be a reason why the recommender systems in practice are not as polarized as our theoretical prediction.

### Real-World Data Experiments

In this part, we conduct experiments on the MovieLens 20M dataset [19]. We use a real-world two-tower recommendation model with 16-dimensional tower tops as the user and creator embeddings (Figure 9). The model is initialized by fitting a two-tower model [21] on the existing MovieLens rating data and using the tower tops as the initial user and creator embeddings. Then we follow Algorithm 1 to simulate the dynamics.

Figure 5 shows the effect of the recommendation sensitivity parameter \(\beta\) on the system. Similar to the synthetic data experiments, a smaller \(\beta\) (more diverse recommendation for the users in the short term) results in faster polarization. We note that the joint results on CD and TP are more informative than each one alone: despite \(\beta=0\) has a higher creator diversity than \(\beta=2\) at \(T=500\), the system reaches polarization more quickly under \(\beta=0\). The higher creator diversity under \(\beta=0\) is because the two clusters in the bi-polarized state are more balanced so the average pairwise distance between the creators is higher under \(\beta=0\) than under \(\beta=2\).

Figure 6 shows the effect of using diversity-aware objective (Eq. 5) for diversity boosting. We see that myopically promoting the short-term recommendation diversity (using a larger \(\rho\)) results a higher creation diversity but also a higher tendency to polarization. A possible explanation for this phenomenon is, similar to the case with \(\beta\), the system polarizes into two balanced clusters which actually have a large average pairwise distance. In this case, Tendency to Polarization is a better measure for diversity loss than Creator Diversity (average pairwise distance).

### Top-\(k\) Truncation and Threshold Truncation

We experimented with top-\(k\) truncation on the synthetic data (Table 1) and the MovieLens dataset (Appendix C). Our **main observation** is: _a small \(k\) improves the diversity of the recommender system and reduces polarization_. This is consistent with our theoretical prediction (Proposition 4.2). However, there is a tradeoff between the diversity of recommendations to users (RD) and the diversity of creations in the system (CD and TP). A top-\(k\) truncation policy with small \(k\) is "not diverse" for users because it exposes a user only to a small set of contents. However, such a policy can lead to a more diverse outcome in the whole system. This tradeoff is worth further studying.

Figure 5: Experiment on MovieLens 20M dataset under different recommendation sensitivity \(\beta\)

Figure 6: Experiment on MovieLens 20M dataset with diversity-aware objective under different \(\rho\)

We also experimented with threshold truncation on synthetic data (Appendix B.2) and MovieLens data (Appendix C). The effect of a large truncation threshold \(\tau\) is similar to the effect of a small \(k\) in top-\(k\) truncation.

## 6 Conclusion

Our work defines a dynamics model to capture the dual influence of recommender systems on user preferences and content creation. Although our model is a theoretical abstraction, we believe that it captures the essence of a real-world recommender system, and our effort is an important initial endeavor to study diversity in recommender systems with dual influence. (See Appendix H for some additional discussions on real-world recommender systems.) We specifically point out different concepts of diversity in recommender systems (creation diversity, recommendation diversity, and tendency to polarization) and provide theoretical and empirical evidences to show that, due to dual influence, myopically optimizing recommendation diversity might hurt the long-term creation diversity and result in polarization of the system. We also explore popular design choices in recommender systems and show an interesting and somewhat counter-intuitive result that designs purely targeting efficiency improvement (e.g., top-\(k\) truncation) can alleviate polarization. We believe that the insights from our work are valuable to building healthy and sustainable recommender systems, and our results can inspire more sophisticated solutions for improving the long-term diversity of recommender systems to be developed.

## References

* Acemoglu et al. [2013] Daron Acemoglu, Giacomo Como, Fabio Fagnani, and Asuman Ozdaglar. Opinion fluctuations and disagreement in social networks. _Mathematics of Operations Research_, 38(1):1-27, 2013. ISSN 0364765X, 15265471. URL http://www.jstor.org/stable/23358646.
* Acharya et al. [2024] Krishna Acharya, Varun Vangala, Jingyan Wang, and Juba Ziani. Producers equilibria and dynamics in engagement-driven recommender systems. _arXiv preprint arXiv:2401.16641_, 2024.
* Agarwal and Brown [2023] Arpit Agarwal and William Brown. Online recommendations for agents with discounted adaptive preferences. _arXiv preprint arXiv:2302.06014_, 2023.
* Altafini and Lini [2015] Claudio Altafini and Gabriele Lini. Predictable dynamics of opinion forming for networks with antagonistic interactions. _IEEE Transactions on Automatic Control_, 60(2):342-357, 2015. doi: 10.1109/TAC.2014.2343371.
* Aridor et al. [2020] Guy Aridor, Duarte Goncalves, and Shan Sikdar. Deconstructing the filter bubble: User decision-making recommender systems. In _Proceedings of the 14th ACM Conference on Recommender Systems_, RecSys '20, page 82-91, New York, NY, USA, 2020. Association for Computing Machinery. ISBN 9781450375832. doi: 10.1145/3383313.3412246. URL https://doi.org/10.1145/3383313.3412246.

\begin{table}
\begin{tabular}{|c|c||c|c|c|} \hline \(\beta\) & \(k\) & Creator Diversity & Recommendation Diversity & Recommendation Relevance & Tendency to Polarization \\ \hline
50 & \(1.00_{\pm.03}\) & \(\mathbf{0.42_{\pm 0.01}}\) & \(0.76_{\pm 0.01}\) & \(1.00_{\pm 10^{-3}}\) \\
25 & \(0.52_{\pm 32}\) & \(0.03_{\pm 0.03}\) & \(0.97_{\pm 0.02}\) & \(0.91_{\pm 0.13}\) \\
1 & \(0\) & \(0.91_{\pm 15}\) & \(0.00_{\pm 0.01}\) & \(1.00_{\pm 0.01}\) & \(0.68_{\pm 0.12}\) \\
10 & \(10\) & \(1.17_{\pm 06}\) & \(0.00_{\pm 10^{-3}}\) & \(1.00_{\pm 10^{-3}}\) & \(0.50_{\pm 0.07}\) \\
5 & \(1.31_{\pm 02}\) & \(0.00_{\pm 10^{-3}}\) & \(1.00_{\pm 10^{-3}}\) & \(0.35_{\pm 0.03}\) \\
1 & \(\mathbf{1.40_{\pm 10^{-3}}}\) & \(0.00_{\pm 10^{-3}}\) & \(\mathbf{1.00_{\pm 10^{-3}}}\) & \(\mathbf{0.27_{\pm 10^{-3}}}\) \\ \hline \end{tabular}
\end{table}
Table 1: Diversity improvement by top-\(k\) truncation on synthetic data * Bansal and Gupta [2019] Nikhil Bansal and Anupam Gupta. Potential-Function Proofs for Gradient Methods. _Theory of Computing_, 15(4):1-32, 2019. doi: 10.4086/toc.2019.v015a004. URL https://theoryofcomputing.org/articles/v015a004. Publisher: Theory of Computing.
* Ben-Porat and Tennenholtz [2018] Omer Ben-Porat and Moshe Tennenholtz. A game-theoretic approach to recommendation systems with strategic content providers. _Advances in Neural Information Processing Systems_, 31, 2018.
* Bonner and Vasile [2018] Stephen Bonner and Flavian Vasile. Causal embeddings for recommendation. In _Proceedings of the 12th ACM Conference on Recommender Systems_, pages 104-112, Vancouver British Columbia Canada, September 2018. ACM. ISBN 978-1-4503-5901-6. doi: 10.1145/3240323.3240360. URL https://dl.acm.org/doi/10.1145/3240323.3240360.
* Borgs et al. [2023] Christian Borgs, Jennifer Chayes, Christian Ikeokwu, and Ellen Vitercik. Bursting the Filter Bubble: Disincentivizing Echo Chambers in Social Networks. In _Proceedings of EAAMO'23: ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization_, 2023.
* A_, 35(9):4241-4268, 2015. ISSN 1553-5231. doi: 10.3934/dcds.2015.35.4241. URL http://aimsciences.org/article/doi/10.3934/dcds.2015.35.4241.
* Carbonell and Goldstein [1998] Jaime Carbonell and Jade Goldstein. The use of mmr, diversity-based reranking for reordering documents and producing summaries. In _Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval_, SIGIR '98, page 335-336, New York, NY, USA, 1998. Association for Computing Machinery. ISBN 1581130155. doi: 10.1145/290941.291025. URL https://doi.org/10.1145/290941.291025.
* Cheng et al. [2017] Peizhe Cheng, Shuaiqiang Wang, Jun Ma, Jiankai Sun, and Hui Xiong. Learning to recommend accurate and diverse items. In _Proceedings of the 26th International Conference on World Wide Web_, WWW '17, page 183-192, Republic and Canton of Geneva, CHE, 2017. International World Wide Web Conferences Steering Committee. ISBN 9781450349130. doi: 10.1145/3038912.3052585. URL https://doi.org/10.1145/3038912.3052585.
* Covington et al. [2016] Paul Covington, Jay Adams, and Emre Sargin. Deep Neural Networks for YouTube Recommendations. In _Proceedings of the 10th ACM Conference on Recommender Systems_, pages 191-198, Boston Massachusetts USA, September 2016. ACM. ISBN 978-1-4503-4035-9. doi: 10.1145/2959100.2959190. URL https://dl.acm.org/doi/10.1145/2959100.2959190.
* Dean and Morgenstern [2022] Sarah Dean and Jamie Morgenstern. Preference Dynamics Under Personalized Recommendations. In _Proceedings of the 23rd ACM Conference on Economics and Computation_, pages 795-816, Boulder CO USA, July 2022. ACM. ISBN 978-1-4503-9150-4. doi: 10.1145/3490486.3538346. URL https://dl.acm.org/doi/10.1145/3490486.3538346.
* Eilat and Rosenfeld [2023] Itay Eilat and Nir Rosenfeld. Performative Recommendation: Diversifying Content via Strategic Incentives, June 2023. URL http://arxiv.org/abs/2302.04336. arXiv:2302.04336 [cs].
* Gao et al. [2022] Chongming Gao, Shijun Li, Yuan Zhang, Jiawei Chen, Biao Li, Wenqiang Lei, Peng Jiang, and Xiangnan He. Kuairand: An unbiased sequential recommendation dataset with randomly exposed videos. In _Proceedings of the 31st ACM International Conference on Information & Knowledge Management_, CIKM '22, page 3953-3957, New York, NY, USA, 2022. Association for Computing Machinery. ISBN 9781450392365. doi: 10.1145/3511808.3557624. URL https://doi.org/10.1145/3511808.3557624.
* Golub and Jackson [2010] Benjamin Golub and Matthew O. Jackson. Naive learning in social networks and the wisdom of crowds. _American Economic Journal: Microeconomics_, 2(1):112-49, February 2010. doi: 10.1257/mic.2.1.112. URL https://www.aeaweb.org/articles?id=10.1257/mic.2.1.112.
* Hardt et al. [2022] Moritz Hardt, Meena Jagadeesan, and Celestine Mendler-Dunner. Performative power. _Advances in Neural Information Processing Systems_, 35:22969-22981, 2022.

* Harper and Konstan [2015] F Maxwell Harper and Joseph A Konstan. The movielens datasets: History and context. _Acm transactions on interactive intelligent systems (tiis)_, 5(4):1-19, 2015.
* Hron et al. [2023] Jiri Hron, Karl Krauth, Michael I. Jordan, Niki Kilbertus, and Sarah Dean. Modeling Content Creator Incentives on Algorithm-Curated Platforms, July 2023. URL http://arxiv.org/abs/2206.13102. arXiv:2206.13102 [cs, stat].
* Huang et al. [2013] Po-Sen Huang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Acero, and Larry Heck. Learning deep structured semantic models for web search using clickthrough data. In _Proceedings of the 22nd ACM international conference on Information & Knowledge Management_, pages 2333-2338, San Francisco California USA, October 2013. ACM. ISBN 978-1-4503-2263-8. doi: 10.1145/2505515.2505665. URL https://dl.acm.org/doi/10.1145/2505515.2505665.
* Hurley [2013] Neil J. Hurley. Personalised ranking with diversity. In _Proceedings of the 7th ACM Conference on Recommender Systems_, RecSys '13, page 379-382, New York, NY, USA, 2013. Association for Computing Machinery. ISBN 9781450324090. doi: 10.1145/2507157.2507226. URL https://doi.org/10.1145/2507157.2507226.
* Jagadeesan et al. [2024] Meena Jagadeesan, Nikhil Garg, and Jacob Steinhardt. Supply-side equilibria in recommender systems. _Advances in Neural Information Processing Systems_, 36, 2024.
* Jiang et al. [2019] Ray Jiang, Silvia Chiappa, Tor Lattimore, Andras Gyorgy, and Pushmeet Kohli. Degenerate Feedback Loops in Recommender Systems. In _Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society_, pages 383-390, Honolulu HI USA, January 2019. ACM. ISBN 978-1-4503-6324-2. doi: 10.1145/3306618.3314288. URL https://dl.acm.org/doi/10.1145/3306618.3314288.
* Moller et al. [2018] Natali Helberger Judith Moller, Damian Trilling and Bram van Es. Do not blame it on the algorithm: an empirical assessment of multiple recommender systems and their impact on content diversity. _Information, Communication & Society_, 21(7):959-977, 2018. doi: 10.1080/1369118X.2018.1444076. URL https://doi.org/10.1080/1369118X.2018.1444076.
* Kalimeris et al. [2021] Dimitris Kalimeris, Smriti Bhagat, Shankar Kalyanaraman, and Udi Weinsberg. Preference amplification in recommender systems. In _Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining_, KDD '21, page 805-815, New York, NY, USA, 2021. Association for Computing Machinery. ISBN 9781450383325. doi: 10.1145/3447548.3467298. URL https://doi.org/10.1145/3447548.3467298.
* Levanon and Rosenfeld [2022] Sagi Levanon and Nir Rosenfeld. Generalized strategic classification and the case of aligned incentives. In _International Conference on Machine Learning_, pages 12593-12618. PMLR, 2022.
* Li et al. [2010] Lihong Li, Wei Chu, John Langford, and Robert E. Schapire. A contextual-bandit approach to personalized news article recommendation. In _Proceedings of the 19th International Conference on World Wide Web_, WWW '10, page 661-670, New York, NY, USA, 2010. Association for Computing Machinery. ISBN 97816055879998. doi: 10.1145/1772690.1772758. URL https://doi.org/10.1145/1772690.1772758.
* Li and Spong [2014] Wei Li and Mark W. Spong. Unified cooperative control of multiple agents on a sphere for different spherical patterns. _IEEE Transactions on Automatic Control_, 59(5):1283-1289, 2014. doi: 10.1109/TAC.2013.2286897.
* Liu et al. [2023] Dugang Liu, Pengxiang Cheng, Zinan Lin, Xiaolian Zhang, Zhenhua Dong, Rui Zhang, Xiuqiang He, Weike Pan, and Zhong Ming. Bounding System-Induced Biases in Recommender Systems with a Randomized Dataset. _ACM Transactions on Information Systems_, 41(4):1-26, October 2023. ISSN 1046-8188, 1558-2868. doi: 10.1145/3582002. URL https://dl.acm.org/doi/10.1145/3582002.
* Markdahl et al. [2018] Johan Markdahl, Johan Thunberg, and Jorge Goncalves. Almost Global Consensus on the SnS -Sphere. _IEEE Transactions on Automatic Control_, 63(6):1664-1675, June 2018. ISSN 0018-9286, 1558-2523. doi: 10.1109/TAC.2017.2752799. URL https://ieeexplore.ieee.org/document/8038829/.

* Masrour et al. [2020] Farzan Masrour, Tyler Wilson, Heng Yan, Pang-Ning Tan, and Abdol Esfahanian. Bursting the filter bubble: Fairness-aware network link prediction. _Proceedings of the AAAI Conference on Artificial Intelligence_, 34(01):841-848, Apr. 2020. doi: 10.1609/aaai.v34i01.5429. URL https://ojs.aaai.org/index.php/AAAI/article/view/5429.
* Nguyen et al. [2014] Tien T. Nguyen, Pik-Mai Hui, F. Maxwell Harper, Loren Terveen, and Joseph A. Konstan. Exploring the filter bubble: the effect of using recommender systems on content diversity. In _Proceedings of the 23rd International Conference on World Wide Web_, WWW '14, page 677-686, New York, NY, USA, 2014. Association for Computing Machinery. ISBN 9781450327442. doi: 10.1145/2566486.2568012. URL https://doi.org/10.1145/2566486.2568012.
* Perdomo et al. [2020] Juan Perdomo, Tijana Zrnic, Celestine Mendler-Dunner, and Moritz Hardt. Performative prediction. In _International Conference on Machine Learning_, pages 7599-7609. PMLR, 2020.
* Prasad et al. [2023] Siddharth Prasad, Martin Mladenov, and Craig Boutilier. Content prompting: Modeling content provider dynamics to improve user welfare in recommender ecosystems. _arXiv preprint arXiv:2309.00940_, 2023.
* Santos et al. [2021] Fernando P. Santos, Yphtach Lelkes, and Simon A. Levin. Link recommendation algorithms and dynamics of polarization in online social networks. _Proceedings of the National Academy of Sciences_, 118(50):e2102141118, 2021. doi: 10.1073/pnas.2102141118. URL https://www.pnas.org/doi/abs/10.1073/pnas.2102141118.
* Sarlette et al. [2007] Alain Sarlette, Rodolphe Sepulchre, and Naomi Ehrich Leonard. Autonomous rigid body attitude synchronization. In _2007 46th IEEE Conference on Decision and Control_, pages 2566-2571, 2007. doi: 10.1109/CDC.2007.4434153.
* Su et al. [2013] Ruilong Su, Li'Ang Yin, Kailong Chen, and Yong Yu. Set-oriented personalized ranking for diversified top-n recommendation. In _Proceedings of the 7th ACM Conference on Recommender Systems_, RecSys '13, page 415-418, New York, NY, USA, 2013. Association for Computing Machinery. ISBN 9781450324090. doi: 10.1145/2507157.2507207. URL https://doi.org/10.1145/2507157.2507207.
* Wilhelm et al. [2018] Mark Wilhelm, Ajith Ramanathan, Alexander Bonomo, Sagar Jain, Ed H. Chi, and Jennifer Gillenwater. Practical diversified recommendations on youtube with determinantal point processes. In _Proceedings of the 27th ACM International Conference on Information and Knowledge Management_, CIKM '18, page 2165-2173, New York, NY, USA, 2018. Association for Computing Machinery. ISBN 9781450360142. doi: 10.1145/3269206.3272018. URL https://doi.org/10.1145/3269206.3272018.
* Yang et al. [2018] Longqi Yang, Yin Cui, Yuan Xuan, Chenyang Wang, Serge Belongie, and Deborah Estrin. Unbiased offline recommender evaluation for missing-not-at-random implicit feedback. In _Proceedings of the 12th ACM Conference on Recommender Systems_, RecSys '18, page 279-287, New York, NY, USA, 2018. Association for Computing Machinery. ISBN 9781450359016. doi: 10.1145/3240323.3240355. URL https://doi.org/10.1145/3240323.3240355.
* Yao et al. [2022] Fan Yao, Chuanhao Li, Denis Nekipelov, Hongning Wang, and Haifeng Xu. Learning from a learning user for optimal recommendations. In _Proceedings of the 39th International Conference on Machine Learning_, volume 162 of _Proceedings of Machine Learning Research_, pages 25382-25406. PMLR, 17-23 Jul 2022. URL https://proceedings.mlr.press/v162/yao22a.html.
* Yao et al. [2023] Fan Yao, Chuanhao Li, Denis Nekipelov, Hongning Wang, and Haifeng Xu. How Bad is Top-K Recommendation under Competing Content Creators? In _Proceedings of the 40th International Conference on Machine Learning_, volume 202 of _Proceedings of Machine Learning Research_, pages 39674-39701. PMLR, July 2023. URL https://proceedings.mlr.press/v202/yao23b.html.
* Yao et al. [2024] Fan Yao, Yiming Liao, Mingzhe Wu, Chuanhao Li, Yan Zhu, James Yang, Jingzhou Liu, Qifan Wang, Haifeng Xu, and Hongning Wang. User welfare optimization in recommender systems with competing content creators. In _Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining_, KDD '24, page 3874-3885, New York, NY, USA, 2024. Association for Computing Machinery. ISBN 9798400704901. doi: 10.1145/3637528.3672021. URL https://doi.org/10.1145/3637528.3672021.

* Zhang and Hurley [2008] Mi Zhang and Neil Hurley. Avoiding monotony: improving the diversity of recommendation lists. In _Proceedings of the 2008 ACM Conference on Recommender Systems_, RecSys '08, page 123-130, New York, NY, USA, 2008. Association for Computing Machinery. ISBN 9781605580937. doi: 10.1145/1454008.1454030. URL https://doi.org/10.1145/1454008.1454030.
* Zhang et al. [2023] Xiaoying Zhang, Hongning Wang, and Hang Li. Disentangled representation for diversified recommendations. In _Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining_, pages 490-498, 2023.
* Zhang et al. [2022] Ziqiao Zhang, Said Al-Abri, and Fumin Zhang. Opinion Dynamics on the Sphere for Stable Consensus and Stable Bipartite Dissensus. _9th IFAC Conference on Networked Systems NECSYS 2022_, 55(13):288-293, January 2022. ISSN 2405-8963. doi: 10.1016/j.ifacol.2022.07.274.
* Ziegler et al. [2005] Cai-Nicolas Ziegler, Sean M. McNee, Joseph A. Konstan, and Georg Lausen. Improving recommendation lists through topic diversification. In _Proceedings of the 14th International Conference on World Wide Web_, WWW '05, page 22-32, New York, NY, USA, 2005. Association for Computing Machinery. ISBN 1595930469. doi: 10.1145/1060745.1060754.

## Appendix A Additional Discussions on Related Works

## Appendix B Additional Experiments on Synthetic Data

### Number of Fixed Dimensions

In this part, we consider the case where some dimensions of the user feature vectors are fixed features and thus not updated from round to round (e.g., ages, genders). Formally, we fix the first \(k\leq d\) dimensions. The remaining \(d-k\) dimensions \(\bm{u}_{j}^{t}[k+1:d]=(u_{j}^{t}[k+1],\dots,u_{j}^{t}[d])\) are updated according to the following rule: \(\bm{u}_{j}^{t+1}[k+1:d]=\|\bm{u}_{j}^{t}[k+1:d]\|\cdot\mathcal{P}\big{(}\bm{u }_{j}^{t}[k+1:d]+\eta_{u}f(\bm{v}_{i}^{t},\bm{u}_{j}^{t})\bm{v}_{i}^{t}[k+1:d] \big{)}\). The multiplication by \(\|\bm{u}_{j}^{t}[k+1:d]\|\) ensures unit norm \(\|\bm{u}_{j}^{t+1}\|=1\). The effect of the number of fixed dimensions on the dynamics is shown in Figure 7. We see that the diversity of the system _improves_ as the number of fixed dimensions increases, and the degree of polarization is reduced. This is similar to the effect of decreasing user update rate \(\eta_{u}\) in Figure 4. The observation that fixed user features encourage diversity might be a reason why the recommender systems in practice are not as polarized as our theoretical prediction.

\begin{table}
\begin{tabular}{|l|l|l|l|l|l|} \hline
**Works** & **Adaptive** & **Adaptive** & **Creator Reward** & **Dynamics or** & **Content Adjustment Model** \\ \cline{2-5}  & **Users?** & **Yes** & **User engagement** & **Dynamics** & **Conditioned on previous time step;** \\  & **Yes** & **Yes** & **User engagement** & **Dynamics** & **implicit cost of content adjustment** \\ \hline
[15] & **No** & **Yes** & **Exposure** & **Dynamics** & **Conditioned on previous time step;** \\  & **No** & **Yes** & **User engagement** & **Dynamics** & **explicit cost of content adjustment** \\ \hline
[42] & **No** & **Yes** & **User engagement** & **Dynamics** & **Freely choose without cost** \\ \hline
[35] & **No** & **Yes** & **User engagement** & **Dynamics** & **Freely choose without cost** \\ \hline
[23] & **No** & **Yes** & **Exposure** & **Equilibrium** & **Freely choose with cost** \\ \hline
[20] & **No** & **Yes** & **Exposure** & **Equilibrium** & **Freely choose without cost** \\ \hline
[7] & **No** & **Yes** & **Exposure** & **Equilibrium** & **Freely choose without cost** \\ \hline
[2] & **No** & **Yes** & **User engagement** & **Equilibrium** & **Freely choose without cost** \\ \hline
[43] & **No** & **Yes** & **Designed by a welfare-maximizing platform** & **Dynamics** & **Freely choose without cost** \\ \hline
[14] & **Yes** & **No\({}^{1}\)** & **N/A** & **Dynamics** & **N/A** \\ \hline
[41] & **Yes** & **No\({}^{1}\)** & **N/A** & **Dynamics** & **N/A** \\ \hline
[3] & **Adaptive and adversarial** & **No\({}^{1}\)** & **N/A** & **Dynamics** & **N/A** \\ \hline \end{tabular}

* \({}^{1}\): These works study the design of recommendation algorithms for the platform with a fixed set of content, without explicitly modeling the content creators.

\end{table}
Table 2: Comparison between our work and some previous works on performative effects of recommender systems

Figure 7: Changes of measures over time under different numbers of fixed dimensions, on synthetic data

### Threshold Truncation

Table 3 shows that the effect of different thresholds in threshold truncation on the long-term diversity of the system. We see that truncating at \(\tau=0\), which corresponds to \(90^{\circ}\) angle between \(\bm{u}_{j}\) and \(\bm{v}_{i}\), is _not good_ for diversity, resulting in the lowest creator diversity measure (CD) and highest tendency to polarization (TP). Truncating at a large threshold like \(0.707\) is good for diversity, instead.

Figure 8 shows how the diversity measures change over time, under different truncation thresholds.

\begin{table}
\begin{tabular}{c|c|c c c c} \(\beta\) & threshold \(\tau\) & CD & RD & RR & TP \\ \hline \hline \multirow{5}{*}{0} & \(-\cos(60^{\circ})=-0.5\) & \(1.00\pm 0.03\) & \(0.00\pm 10^{-3}\) & \(1.00\pm 10^{-3}\) & \(0.99\pm 10^{-3}\) \\  & \(-\cos(72^{\circ})=-0.309\) & \(0.96\pm 0.06\) & \(\bm{0.01\pm 0.02}\) & \(1.00\pm 0.02\) & \(0.92\pm 0.10\) \\  & \(\cos(90^{\circ})=0\) & \(0.03\pm 0.16\) & \(0.00\pm 10^{-3}\) & \(1.00\pm 10^{-3}\) & \(0.99\pm 0.04\) \\  & \(\cos(72^{\circ})=0.309\) & \(0.72\pm 0.30\) & \(0.00\pm 10^{-3}\) & \(1.00\pm 10^{-3}\) & \(0.81\pm 0.12\) \\  & \(\cos(60^{\circ})=0.5\) & \(1.16\pm 0.11\) & \(0.00\pm 10^{-3}\) & \(1.00\pm 10^{-3}\) & \(0.47\pm 0.10\) \\  & \(\cos(45^{\circ})=0.707\) & \(\bm{1.37\pm 0.02}\) & \(0.00\pm 10^{-3}\) & \(\bm{1.00\pm 10^{-3}}\) & \(\bm{0.33\pm 0.02}\) \\  & \(\cos(30^{\circ})=0.866\) & \(1.30\pm 0.03\) & \(0.00\pm 10^{-3}\) & \(1.00\pm 10^{-3}\) & \(0.55\pm 0.05\) \\ \hline \multirow{5}{*}{1} & \(-\cos(60^{\circ})=-0.5\) & \(0.98\pm 0.04\) & \(0.00\pm 0.02\) & \(1.00\pm 0.01\) & \(0.96\pm 0.04\) \\  & \(-\cos(72^{\circ})=-0.309\) & \(0.92\pm 0.08\) & \(0.00\pm 0.02\) & \(0.99\pm 0.02\) & \(0.87\pm 0.10\) \\  & \(\cos(90^{\circ})=0\) & \(0.13\pm 0.31\) & \(0.00\pm 10^{-3}\) & \(1.00\pm 10^{-3}\) & \(0.97\pm 0.08\) \\  & \(\cos(72^{\circ})=0.309\) & \(0.85\pm 0.16\) & \(0.00\pm 10^{-3}\) & \(1.00\pm 10^{-3}\) & \(0.76\pm 0.11\) \\  & \(\cos(60^{\circ})=0.5\) & \(1.21\pm 0.07\) & \(0.00\pm 10^{-3}\) & \(1.00\pm 10^{-3}\) & \(0.43\pm 0.08\) \\  & \(\cos(45^{\circ})=0.707\) & \(\bm{1.38\pm 0.01}\) & \(0.00\pm 10^{-3}\) & \(\bm{1.00\pm 10^{-3}}\) & \(\bm{0.30\pm 0.01}\) \\  & \(\cos(30^{\circ})=0.866\) & \(1.33\pm 0.02\) & \(0.00\pm 10^{-3}\) & \(1.00\pm 10^{-3}\) & \(0.47\pm 0.04\) \\ \hline \multirow{5}{*}{3} & \(-\cos(60^{\circ})=-0.5\) & \(0.91\pm 0.18\) & \(\bm{0.01\pm 0.02}\) & \(1.00\pm 0.01\) & \(0.83\pm 0.10\) \\  & \(-\cos(72^{\circ})=-0.309\) & \(0.85\pm 0.23\) & \(0.00\pm 10^{-3}\) & \(1.00\pm 10^{-3}\) & \(0.78\pm 0.11\) \\  & \(\cos(90^{\circ})=0\) & \(0.64\pm 0.33\) & \(0.00\pm 10^{-3}\) & \(1.00\pm 10^{-3}\) & \(0.81\pm 0.12\) \\ \cline{1-1}  & \(\cos(72^{\circ})=0.309\) & \(1.01\pm 0.14\) & \(0.00\pm 10^{-3}\) & \(1.00\pm 10^{-3}\) & \(0.64\pm 0.14\) \\ \cline{1-1}  & \(\cos(60^{\circ})=0.5\) & \(1.26\pm 0.05\) & \(0.00\pm 10^{-3}\) & \(1.00\pm 10^{-3}\) & \(0.38\pm 0.06\) \\ \cline{1-1}  & \(\cos(45^{\circ})=0.707\) & \(\bm{1.39\pm 0.01}\) & \(0.00\pm 10^{-3}\) & \(\bm{1.00\pm 10^{-3}}\) & \(\bm{0.28\pm 0.01}\) \\ \cline{1-1}  & \(\cos(30^{\circ})=0.866\) & \(1.37\pm 0.01\) & \(0.00\pm 10^{-3}\) & \(1.00\pm 10^{-3}\) & \(0.34\pm 0.01\) \\ \end{tabular}
\end{table}
Table 3: Diversity improvement by threshold truncation on synthetic dataFigure 8: Changes of measures over time under different truncation threshold \(\tau\), with \(\beta=1\), on synthetic data

Additional Experiments on Real-World Dataset

### Details of the Recommendation Algorithm

``` Input:\(t=0\), actual embedding \(U^{(0)},V^{(0)}\), true labels \(Y^{(0)}_{ij}:=y(u^{(0)}_{i},v^{(0)}_{j})\), initial parameter \(\bm{\theta}^{(0)}\) (which includes the predicted embedding \(\hat{U}^{(0)},\hat{V}^{(0)}\)) repeat  Let temporary parameter \(\bm{w}^{(0)}\leftarrow\bm{\theta}^{(t)}\)  Compute loss \(\mathcal{L}(\bm{\theta}^{(t)},Y^{(t)})\) for\(s=1\)to\(m-1\)do \(\bm{w}^{(s+1)}\leftarrow\bm{\theta}^{(s)}-\eta\nabla_{\bm{w}}\mathcal{L}(\bm{w} ^{(s)},Y^{(t)})\) endfor \(\bm{\theta}^{(t+1)}\leftarrow\bm{w}^{(m)}\)  Deliver recommendations based on \(\hat{U}^{(t+1)},\hat{V}^{(t+1)}\)  Update \(U^{(t+1)},V^{(t+1)}\), and \(Y^{(t+1)}\) \(t\gets t+1\) until\(\|\bm{\theta}^{(t)}-\bm{\theta}^{(t-1)}\|_{2}\leq\delta\) ```

**Algorithm 1** Real-world Recommendation with Dual Influence

Figure 9: Two tower model for the MovieLens experiment, where the two towers both have size \(16\times 16\) with linear layers and ReLu activations.

[MISSING_PAGE_EMPTY:19]

[MISSING_PAGE_EMPTY:20]

Useful Lemmas

This section provides some lemmas that will be used in the proofs. They are mainly about some properties of the dynamics update rule.

**Claim D.1**.: _For vectors \(\bm{x},\bm{y}\in\mathbb{R}^{d}\) with unit norm \(\|\bm{x}\|_{2}=\|\bm{y}\|_{2}=1\), we have:_

* \(\|\bm{x}-\bm{y}\|_{2}^{2}=2(1-\langle\bm{x},\bm{y}\rangle)\)_._
* \(\langle\bm{x},\bm{y}\rangle=1-\frac{1}{2}\|\bm{x}-\bm{y}\|_{2}^{2}\)_._

**Lemma D.2** (Convex Cone Property).: _Let \(\bm{z}_{1},\ldots,\bm{z}_{k}\in\mathbb{R}^{d}\) be vectors with norm \(\|\bm{z}_{i}^{t}\|_{2}=1\). Suppose \(\langle\bm{z}_{i},\bm{y}\rangle>0\) for every \(i=1,\ldots,k\) for some \(\bm{y}\in\mathbb{R}^{d}\). Let \(\bm{x}=\mathcal{P}(\sum_{i=1}^{k}a_{i}\bm{z}_{i})\) for some \(a_{1},\ldots,a_{k}\geq 0\) (namely, \(\bm{x}\) is the normalization of some vector in the convex cone formed by \(\bm{z}_{1},\ldots,\bm{z}_{k}\)). Then, we have_

\[\langle\bm{x},\bm{y}\rangle\ \geq\ \min_{i=1}^{k}\langle\bm{z}_{i},\bm{y} \rangle\ >\ 0\quad\text{ and }\quad\|\bm{x}-\bm{y}\|_{2}\ \leq\ \max_{i=1}^{k}\|\bm{z}_{i}-\bm{y}\|_{2}\ >\ 0.\]

Proof.: \[\langle\bm{x},\,\bm{y}\rangle =\ \Big{\langle}\frac{\sum_{i=1}^{k}a_{i}\bm{z}_{i}}{\|\sum_{i=1}^{k}a_{i} \bm{z}_{i}\|_{2}}\,,\,\bm{y}\Big{\rangle}\ =\ \frac{1}{\|\sum_{i=1}^{k}a_{i}\bm{z}_{i}\|_{2}}\sum_{i=1}^{k}a_{i} \langle\bm{z}_{i},\bm{y}\rangle\] \[\geq\ \frac{1}{\|\sum_{i=1}^{k}a_{i}\bm{z}_{i}\|_{2}}\sum_{i=1}^{k}a_ {i}\min_{i=1}^{k}\langle\bm{z}_{i},\bm{y}\rangle\ =\ \min_{i=1}^{k}\langle\bm{z}_{i},\bm{y}\rangle\frac{\sum_{i=1}^{k}a_{i}}{\|\sum_ {i=1}^{k}a_{i}\bm{z}_{i}\|_{2}}\] \[\geq\ \min_{i=1}^{k}\langle\bm{z}_{i},\bm{y}\rangle\frac{\sum_{i=1}^{k}a _{i}}{\sum_{i=1}^{k}a_{i}}\ =\ \min_{i=1}^{k}\langle\bm{z}_{i},\bm{y}\rangle.\]

This proves the first inequality. To prove the second inequality, we use Claim D.1 and the first inequality:

\[\|\bm{x}-\bm{y}\|_{2}\ =\ \sqrt{2(1-\langle\bm{x},\bm{y}\rangle)}\ \leq\ \sqrt{2(1-\min_{i}\langle\bm{z}_{i},\bm{y}\rangle)}\ =\ \max_{i}\sqrt{2(1-\langle\bm{z}_{i},\bm{y}\rangle)}\ =\ \max_{i=1}^{k}\|\bm{z}_{i}-\bm{y}\|_{2}.\]

**Lemma D.3**.: _Let \(\bm{x}^{t},\bm{y},\bm{z}^{t}\in\mathbb{R}^{d}\) be vectors with norm \(\|\bm{x}^{t}\|_{2}=1\), \(\|\bm{y}\|_{2}\geq 0\), \(\|\bm{z}^{t}\|_{2}\leq 1\). Suppose \(\langle\bm{x}^{t},\bm{y}\rangle\geq 0\), \(\langle\bm{z}^{t},\bm{y}\rangle\geq 0\). After the update \(\bm{x}^{t+1}=\mathcal{P}(\bm{x}^{t}+\eta\bm{z}^{t})\), we have_

\[\langle\bm{x}^{t+1}-\bm{x}^{t},\,\bm{y}\rangle\ \geq\ \frac{\eta}{1+\eta\|\bm{z}^{t}\|_{2}} \Big{(}\langle\bm{z}^{t},\bm{y}\rangle-\|\bm{z}^{t}\|_{2}\langle\bm{x}^{t},\bm {y}\rangle\Big{)}.\]

_As a corollary, if \(\bm{y}=\bm{z}^{t}\) and \(\|\bm{z}^{t}\|_{2}=1\), then_

\[\langle\bm{x}^{t+1}-\bm{x}^{t},\,\bm{z}^{t}\rangle\ \geq\ \frac{\eta}{1+\eta}\Big{(}1- \langle\bm{x}^{t},\bm{z}^{t}\rangle\Big{)}.\]

Proof.: By definition,

\[\langle\bm{x}^{t+1}-\bm{x}^{t},\,\bm{y}\rangle =\ \Big{\langle}\frac{\bm{x}^{t}+\eta\bm{z}^{t}}{\|\bm{x}^{t}+\eta \bm{z}^{t}\|_{2}}-\bm{x}^{t},\,\bm{y}\Big{\rangle}\] \[=\ \Big{(}\frac{1}{\|\bm{x}^{t}+\eta\bm{z}^{t}\|_{2}}-1\Big{)} \cdot\langle\bm{x}^{t},\bm{y}\rangle\,+\,\frac{\eta}{\|\bm{x}^{t}+\eta\bm{z}^{t }\|_{2}}\cdot\langle\bm{z}^{t},\bm{y}\rangle\] \[\geq\ \Big{(}\frac{1}{1+\eta\|\bm{z}^{t}\|_{2}}-1\Big{)}\cdot \langle\bm{x}^{t},\bm{y}\rangle\,+\,\frac{\eta}{1+\eta\|\bm{z}^{t}\|_{2}}\cdot \langle\bm{z}^{t},\bm{y}\rangle\] \[=\ \frac{\eta}{1+\eta\|\bm{z}^{t}\|_{2}}\Big{(}\langle\bm{z}^{t}, \bm{y}\rangle-\|\bm{z}^{t}\|_{2}\langle\bm{x}^{t},\bm{y}\rangle\Big{)}.\]

**Lemma D.4**.: _Let \(\bm{x}^{t},\bm{z}^{t}\in\mathbb{R}^{d}\) be vectors with norm \(\|\bm{x}^{t}\|_{2}=1\), \(\|\bm{z}^{t}\|_{2}\leq 1\). Suppose \(\langle\bm{x}^{t},\bm{z}^{t}\rangle\geq 0\) and \(\eta>0\). Then the update \(\bm{x}^{t+1}=\mathcal{P}(\bm{x}^{t}+\eta\bm{z}^{t})\) satisfies_* \(\langle\bm{x}^{t+1}-\bm{x}^{t},\bm{z}^{t}\rangle\,\geq\,\frac{1}{\eta}\|\bm{x}^{t+1 }-\bm{x}^{t}\|_{2}^{2}\).
* \(\|\bm{x}^{t+1}-\bm{x}^{t}\|_{2}\,\leq\,\eta\|\bm{z}^{t}\|_{2}\).

Proof.: Let \(\tilde{\bm{x}}^{t+1}=\bm{x}^{t}+\eta\bm{z}^{t}\), so \(\bm{x}^{t}=\mathcal{P}(\tilde{\bm{x}}^{t+1})\) and \(\bm{z}^{t}=\frac{1}{\eta}(\tilde{\bm{x}}^{t+1}-\bm{x}^{t})\). Then we have

\[\langle\bm{x}^{t+1}-\bm{x}^{t},\,\bm{z}^{t}\rangle\,\,=\,\,\frac{1}{\eta} \langle\bm{x}^{t+1}-\bm{x}^{t},\,\tilde{\bm{x}}^{t+1}-\bm{x}^{t}\rangle.\]

Because \(\langle\bm{x}^{t},\bm{z}^{t}\rangle\geq 0\), the vector \(\tilde{\bm{x}}^{t+1}=\bm{x}^{t}+\eta\bm{z}^{t}\) has length \(\geq 1\) and hence is outside (or on the surface) of the \(d\)-dimensional unit ball. Since \(\bm{x}^{t}=\mathcal{P}(\tilde{\bm{x}}^{t+1})\) is the projection of \(\tilde{\bm{x}}^{t+1}\) onto the unit ball, and \(\bm{z}^{t}\) is another vector inside the unit ball, by the "Pythagorean property" (Proposition 2.2 in [6]), we must have \(\langle\bm{x}^{t}-\bm{x}^{t+1},\tilde{\bm{x}}^{t+1}-\bm{x}^{t+1}\rangle\leq 0\). This implies

\[\langle\bm{x}^{t+1}-\bm{x}^{t},\,\bm{z}^{t}\rangle\,\,\geq\,\, \frac{1}{\eta}\Big{(}\langle\bm{x}^{t+1}-\bm{x}^{t},\,\tilde{\bm{x}}^{t+1}-\bm {x}^{t}\rangle+\langle\bm{x}^{t}-\bm{x}^{t+1},\,\tilde{\bm{x}}^{t+1}-\bm{x}^{t +1}\rangle\Big{)}\] \[\,\,=\,\,\frac{1}{\eta}\langle\bm{x}^{t+1}-\bm{x}^{t},\,\bm{x}^{t +1}-\bm{x}^{t}\rangle\,\,=\,\,\frac{1}{\eta}\|\bm{x}^{t+1}-\bm{x}^{t}\|_{2}^{2},\]

which proves the first claim. To prove the second claim, we use Cauchy-Schwarz inequality:

\[\frac{1}{\eta}\|\bm{x}^{t+1}-\bm{x}^{t}\|_{2}^{2}\,\leq\,\langle\bm{x}^{t+1}- \bm{x}^{t},\,\bm{z}^{t}\rangle\,\,\leq\,\,\|\bm{x}^{t+1}-\bm{x}^{t}\|_{2}\| \bm{z}^{t}\|_{2}.\]

This implies \(\|\bm{x}^{t+1}-\bm{x}^{t}\|_{2}\leq\eta\|\bm{z}^{t}\|_{2}\). 

**Lemma D.5**.: _Consider a creator \(\bm{v}_{i}^{t}\) and a user \(\bm{u}_{j}^{t}\). Suppose the user is always recommended creator \(i\) (so the user is updated by \(\bm{u}_{j}^{t+1}=\mathcal{P}(\bm{u}_{j}^{t}+\eta_{u}f(\bm{v}_{i}^{t},\bm{u}_{j }^{t})\bm{v}_{i}^{t})\)), and creator \(i\) is updated by \(\bm{v}_{i}^{t+1}=\mathcal{P}(\bm{v}_{i}^{t}+\eta_{c}\bm{\alpha}_{i}^{t})\) with \(\|\bm{\alpha}_{i}^{t}\|_{2}\leq 1\) and \(\langle\bm{v}_{i}^{t},\bm{\alpha}_{i}^{t}\rangle\geq 0\) at each time step. Assume:_

* _The inner product_ \(\langle\bm{u}_{j}^{0},\bm{v}_{i}^{0}\rangle>0\) _initially. (Note that_ \(\langle\bm{u}_{j}^{0},\bm{u}_{j^{\prime}}^{0}\rangle\) _needs not hold.)_
* _There exists some constant_ \(L_{f}>0\) _such that_ \(f(\bm{v}_{i},\bm{u}_{j})\geq L_{f}>0\) _whenever_ \(\langle\bm{u}_{j},\bm{v}_{i}\rangle>0\)_._
* \(\eta_{c}\leq\frac{\eta_{u}L_{f}}{2}\) _and_ \(0\leq\eta_{u}<\frac{1}{2}\)_._

_Then, we have \(\langle\bm{u}_{j}^{t},\bm{v}_{i}^{t}\rangle>0\) in all time steps._

Proof.: We prove by induction. Suppose \(\langle\bm{u}_{j}^{t},\bm{v}_{i}^{t}\rangle>0\) already holds. We prove that \(\langle\bm{u}_{j}^{t+1},\bm{v}_{i}^{t+1}\rangle>0\) will also hold. Take the difference between \(\langle\bm{u}_{j}^{t+1},\bm{v}_{i}^{t+1}\rangle\) and \(\langle\bm{u}_{j}^{t},\bm{v}_{i}^{t}\rangle\):

\[\langle\bm{u}_{j}^{t+1},\bm{v}_{i}^{t+1}\rangle-\langle\bm{u}_{j}^{t},\bm{v}_{i }^{t}\rangle\,=\,\langle\bm{u}_{j}^{t+1},\bm{v}_{i}^{t+1}-\bm{v}_{i}^{t} \rangle+\langle\bm{u}_{j}^{t+1}-\bm{u}_{j}^{t},\bm{v}_{i}^{t}\rangle.\]

For \(\langle\bm{u}_{j}^{t+1}-\bm{u}_{j}^{t},\bm{v}_{i}^{t}\rangle\), using Lemma D.3 with \(\bm{x}^{t}=\bm{u}_{j}^{t},\bm{z}^{t}=\bm{v}_{i}^{t}\), and \(\eta=\eta_{u}f(\bm{v}_{i}^{t},\bm{u}_{j}^{t})\), we get

\[\langle\bm{u}_{j}^{t+1}-\bm{u}_{j}^{t},\bm{v}_{i}^{t}\rangle\,\geq\,\,\frac{ \eta_{u}f(\bm{v}_{i}^{t},\bm{u}_{j}^{t})}{1+\eta_{u}f(\bm{v}_{i}^{t},\bm{u}_{j }^{t})}\big{(}1-\langle\bm{u}_{j}^{t},\bm{v}_{i}^{t}\rangle\big{)}\,\,\geq\,\, \frac{\eta_{u}L_{f}}{1+\eta_{u}L_{f}}\big{(}1-\langle\bm{u}_{j}^{t},\bm{v}_{i}^{ t}\rangle\big{)}.\]

For \(\langle\bm{u}_{j}^{t+1},\bm{v}_{i}^{t+1}-\bm{v}_{i}^{t}\rangle\), by Cauchy-Schwarz inequality and Lemma D.4,

\[\langle\bm{u}_{j}^{t+1},\bm{v}_{i}^{t+1}-\bm{v}_{i}^{t}\rangle\,\geq\,\,-\,\|\bm{ u}_{j}^{t+1}\|_{2}\cdot\|\bm{v}_{i}^{t+1}-\bm{v}_{i}^{t}\|_{2}\,\geq\,\,-\,1\cdot \eta_{c}\|\bm{\alpha}_{i}^{t}\|_{2}\,\,\geq\,\,-\,\eta_{c}.\]

* If \(1-\langle\bm{u}_{j}^{t},\bm{v}_{i}^{t}\rangle>\frac{1}{2}(1+\eta_{u}L_{f})\), then we have \[\langle\bm{u}_{j}^{t+1},\bm{v}_{i}^{t+1}\rangle-\langle\bm{u}_{j}^{t},\bm{v}_{i }^{t}\rangle\,>\,\eta_{u}L_{f}\frac{1}{2}-\eta_{c}\,\geq 0\] by the assumption of \(\eta_{c}\leq\frac{\eta_{u}L_{f}}{2}\).
* If \(1-\langle\bm{u}_{j}^{t},\bm{v}_{i}^{t}\rangle\leq\frac{1}{2}(1+\eta_{u}L_{f})\), then we have \[\langle\bm{u}_{j}^{t+1},\bm{v}_{i}^{t+1}\rangle-\langle\bm{u}_{j}^{t},\bm{v}_{ i}^{t}\rangle\,\geq\,0-\eta_{c}\] \[\implies\,\langle\bm{u}_{j}^{t+1},\bm{v}_{i}^{t+1}\rangle\,\geq\, \langle\bm{u}_{j}^{t},\bm{v}_{i}^{t}\rangle-\eta_{c}\,\geq\,\frac{1}{2}-\frac{1}{ 2}\eta_{u}L_{f}-\eta_{c}\,>\,0\] under the assumption of \(\eta_{c}\leq\frac{\eta_{u}L_{f}}{2}\) and \(\eta_{u}<\frac{1}{2}\).

The above two cases together ensure \(\langle\bm{u}_{j}^{t+1},\bm{v}_{i}^{t+1}\rangle>0\). 

**Lemma D.6**.: _Consider a system of one user and one creator that satisfies \(\langle\bm{u}_{j}^{0},\bm{v}_{i}^{0}\rangle>0\) and \(\langle\bm{u}_{j}^{0},\bm{y}\rangle>\langle\bm{v}_{i}^{0},\bm{y}\rangle>0\) for some \(\bm{y}\in\mathbb{R}^{d}\) with \(\|\bm{y}\|\leq 1\) initially. The creator is always recommended to the user (so the updates are \(\bm{u}_{j}^{t+1}=\mathcal{P}(\bm{u}_{j}^{t}+\eta_{u}f(\bm{v}_{i}^{t},\bm{u}_{j} ^{t})\bm{v}_{i}^{t})\) and \(\bm{v}_{i}^{t+1}=\mathcal{P}(\bm{v}_{i}^{t}+\eta_{c}\bm{u}_{j}^{t})\)). Suppose \(\eta_{c}\leq\frac{\eta_{u}L_{f}}{2}\) and \(0\leq\eta_{u}<\frac{1}{2}\). Then, we have:_

* \(\langle\bm{u}_{j}^{t},\bm{y}\rangle>\langle\bm{v}_{i}^{t},\bm{y}\rangle>0\) _for all_ \(t\geq 1\)_._
* _Suppose_ \(\langle\bm{u}_{j}^{0},\bm{y}\rangle-\langle\bm{v}_{i}^{0},\bm{y}\rangle=D>0\)_. For any_ \(R<D\)_, after_ \(T=\frac{8}{3\eta_{u}L_{f}}\ln\frac{2}{R^{2}}\) _steps, we have_ \(\langle\bm{v}_{i}^{T},\bm{y}\rangle-\langle\bm{v}_{i}^{0},\bm{y}\rangle\geq \frac{\eta_{c}}{\eta_{u}+\eta_{c}}(D-R)\)_._

Proof.: We prove the first item by induction. Suppose \(\langle\bm{u}_{j}^{t},\bm{y}\rangle>\langle\bm{v}_{i}^{t},\bm{y}\rangle>0\) holds. Consider \(t+1\). First, by Lemma D.2, \(\langle\bm{v}_{i}^{t+1},\bm{y}\rangle>0\) holds. Then, we prove \(\langle\bm{u}_{j}^{t+1},\bm{y}\rangle>\langle\bm{v}_{i}^{t+1},\bm{y}\rangle\). Let \(f=f(\bm{v}_{i}^{t},\bm{u}_{j}^{t})\).

\[\langle\bm{u}_{j}^{t+1},\bm{y}\rangle-\langle\bm{v}_{i}^{t+1},\bm {y}\rangle\ =\ \Big{\langle}\frac{\bm{u}_{j}^{t}+\eta_{u}f\bm{v}_{i}^{t}}{\|\bm{u}_{j}^{t}+ \eta_{u}f\bm{v}_{i}^{t}\|_{2}},\bm{y}\Big{\rangle}-\Big{\langle}\frac{\bm{v}_ {i}^{t}+\eta_{c}\bm{u}_{j}^{t}}{\|\bm{v}_{i}^{t}+\eta_{c}\bm{u}_{j}^{t}\|_{2}}, \bm{y}\Big{\rangle}\] \[=\ \Big{(}\frac{1}{\|\bm{u}_{j}^{t}+\eta_{u}f\bm{v}_{i}^{t}\|_{2} }-\frac{\eta_{c}}{\|\bm{v}_{i}^{t}+\eta_{c}\bm{u}_{j}^{t}\|_{2}}\Big{)}\langle \bm{u}_{j}^{t},\bm{y}\rangle-\Big{(}\frac{1}{\|\bm{v}_{i}^{t}+\eta_{c}\bm{u}_{j }^{t}\|_{2}}-\frac{\eta_{u}f}{\|\bm{u}_{j}^{t}+\eta_{u}f\bm{v}_{i}^{t}\|_{2}} \Big{)}\langle\bm{v}_{i}^{t},\bm{y}\rangle\] \[>\ \Big{(}\frac{1}{\|\bm{u}_{j}^{t}+\eta_{u}f\bm{v}_{i}^{t}\|_{2} }-\frac{\eta_{c}}{\|\bm{v}_{i}^{t}+\eta_{c}\bm{u}_{j}^{t}\|_{2}}\Big{)}\langle \bm{v}_{i}^{t},\bm{y}\rangle-\Big{(}\frac{1}{\|\bm{v}_{i}^{t}+\eta_{c}\bm{u}_{ j}^{t}\|_{2}}-\frac{\eta_{u}f}{\|\bm{u}_{j}^{t}+\eta_{u}f\bm{v}_{i}^{t}\|_{2}} \Big{)}\langle\bm{v}_{i}^{t},\bm{y}\rangle\] \[=\ \Big{(}\frac{1+\eta_{u}f}{\|\bm{u}_{j}^{t}+\eta_{u}f\bm{v}_{i}^{ t}\|_{2}}-\frac{1+\eta_{c}}{\|\bm{v}_{i}^{t}+\eta_{c}\bm{u}_{j}^{t}\|_{2}}\Big{)} \langle\bm{v}_{i}^{t},\bm{y}\rangle\] \[=\ \Big{(}\frac{1+\eta_{u}f}{\sqrt{1+2\eta_{u}f\langle\bm{u}_{j}^{ t},\bm{v}_{i}^{t}\rangle+(\eta_{u}f)^{2}}}-\frac{1+\eta_{c}}{\sqrt{1+2\eta_{c} \langle\bm{u}_{j}^{t},\bm{v}_{i}^{t}\rangle+(\eta_{c})^{2}}}\Big{)}\langle \bm{v}_{i}^{t},\bm{y}\rangle.\]

Let \(a=\langle\bm{u}_{j}^{t},\bm{v}_{i}^{t}\rangle\leq 1\). We note that the function

\[h(\eta)=\frac{1+\eta}{\sqrt{1+2\eta a+\eta^{2}}}=\sqrt{\frac{1+2\eta+\eta^{2 }}{1+2\eta a+\eta^{2}}}=\sqrt{1+\frac{(2-2a)\eta}{1+2\eta a+\eta^{2}}}=\sqrt{ 1+\frac{2(1-a)}{\frac{1}{\eta}+2a+\eta}}\]

is increasing in \(\eta\in[0,1]\). Under the assumption of \(\eta_{c}\leq\frac{\eta_{u}L_{f}}{2}\leq\frac{\eta_{u}f}{2}<\eta_{u}f\), we have \(h(\eta_{c})\leq h(\eta_{u}f)\) and hence

\[\langle\bm{u}_{j}^{t+1},\bm{y}\rangle-\langle\bm{v}_{i}^{t+1},\bm{y}\rangle\ >\ \big{(}h(\eta_{u}f)-h(\eta_{c})\big{)}\langle\bm{v}_{i}^{t},\bm{y}\rangle\ \geq\ 0.\]

We then prove the second item. Using Lemma D.3 for \(\bm{v}_{i}^{t+1}=\mathcal{P}(\bm{v}_{i}^{t}+\eta_{c}\bm{u}_{j}^{t})\), we get

\[\langle\bm{v}_{i}^{t+1}-\bm{v}_{i}^{t},\bm{y}\rangle\geq\frac{\eta_{c}}{1+\eta_ {c}}\Big{(}\langle\bm{u}_{j}^{t},\bm{y}\rangle-\langle\bm{v}_{i}^{t},\bm{y} \rangle\Big{)}.\]

Using Lemma D.3 for \(\bm{u}_{j}^{t+1}=\mathcal{P}(\bm{u}_{j}^{t}+\eta_{u}f(\bm{v}_{i}^{t},\bm{u}_{j}^{t}) \bm{v}_{i}^{t})\) and using the fact \(\langle\bm{v}_{i}^{t},\bm{y}\rangle-\langle\bm{u}_{j}^{t},\bm{y}\rangle<0\) proved in item 1,

\[\langle\bm{u}_{j}^{t+1}-\bm{u}_{j}^{t},\bm{y}\rangle\geq\frac{\eta_{u}f(\bm{v}_{i}^ {t},\bm{u}_{j}^{t})}{1+\eta_{u}f(\bm{v}_{i}^{t},\bm{u}_{j}^{t})}\Big{(}\langle \bm{v}_{i}^{t},\bm{y}\rangle-\langle\bm{u}_{j}^{t},\bm{y}\rangle\Big{)}\geq \frac{\eta_{u}}{1+\eta_{a}}\Big{(}\langle\bm{v}_{i}^{t},\bm{y}\rangle-\langle\bm{u}_ {j}^{t},\bm{y}\rangle\Big{)}.\]

Rearranging the above two inequalities:

\[\frac{1+\eta_{c}}{\eta_{c}}\Big{(}\langle\bm{v}_{i}^{t+1},\bm{y} \rangle-\langle\bm{v}_{i}^{t},\bm{y}\rangle\Big{)}\geq\langle\bm{u}_{j}^{t},\bm{y }\rangle-\langle\bm{v}_{i}^{t},\bm{y}\rangle;\] \[\frac{1+\eta_{u}}{\eta_{u}}\Big{(}\langle\bm{u}_{j}^{t+1},\bm{y} \rangle-\langle\bm{u}_{j}^{t},\bm{y}\rangle\Big{)}\geq\langle\bm{v}_{i}^{t},\bm{y }\rangle-\langle\bm{u}_{j}^{t},\bm{y}\rangle.\]Summing the above two inequalities over \(t=0,1,\ldots,T-1\):

\[\frac{1+\eta_{c}}{\eta_{c}}\Big{(}\langle\bm{v}_{i}^{T},\bm{y}\rangle-\langle\bm {v}_{i}^{0},\bm{y}\rangle\Big{)}+\frac{1+\eta_{u}}{\eta_{u}}\Big{(}\langle\bm{u }_{j}^{T},\bm{y}\rangle-\langle\bm{u}_{j}^{0},\bm{y}\rangle\Big{)}\geq 0.\] (6)

According to Lemma F.1, after at most \(T=\frac{8}{3\eta_{u}Lt}\ln\frac{2}{R^{2}}\) steps, we have \(\|\bm{u}_{j}^{T}-\bm{v}_{i}^{T}\|_{2}\leq R\). This implies and hence

\[\Big{(}\langle\bm{v}_{i}^{T},\bm{y}\rangle-\langle\bm{v}_{i}^{0},\bm{y} \rangle\Big{)}-\Big{(}\langle\bm{u}_{j}^{T},\bm{y}\rangle-\langle\bm{u}_{j}^{0 },\bm{y}\rangle\Big{)}=\Big{(}\langle\bm{u}_{j}^{0},\bm{y}\rangle-\langle\bm {v}_{i}^{0},\bm{y}\rangle\Big{)}-\Big{(}\langle\bm{u}_{j}^{T},\bm{y}\rangle- \langle\bm{v}_{i}^{T},\bm{y}\rangle\Big{)}\geq D-R.\] (7)

Multiplying (7) by \(\frac{1+\eta_{u}}{\eta_{u}}\) and adding to (6):

\[\Big{(}\frac{1+\eta_{c}}{\eta_{c}}+\frac{1+\eta_{u}}{\eta_{u}}\Big{)}\Big{(} \langle\bm{v}_{i}^{T},\bm{y}\rangle-\langle\bm{v}_{i}^{0},\bm{y}\rangle\Big{)} \geq\frac{1+\eta_{u}}{\eta_{u}}(D-R).\]

This implies

\[\langle\bm{v}_{i}^{T},\bm{y}\rangle-\langle\bm{v}_{i}^{0},\bm{y}\rangle\geq \frac{\frac{1+\eta_{u}}{\eta_{c}}}{\frac{1+\eta_{c}}{\eta_{c}}+\frac{1+\eta_{ u}}{\eta_{u}}}(D-R)=\frac{\eta_{c}(1+\eta_{u})}{\eta_{u}(1+\eta_{c})+\eta_{c}(1+ \eta_{u})}(D-R)\geq\frac{\eta_{c}}{\eta_{u}+\eta_{c}}(D-R).\]

given \(\eta_{c}\leq\eta_{u}\). 

The following lemma shows that, when we _reflect_ some of the feature vectors in a system \((U^{t},V^{t})=(\{\bm{u}_{j}^{t}\}_{j\in[m]},\{\bm{v}_{i}^{t}\}_{i\in[n]})\), there is a correspondence between the behaviors of the system with the reflected vectors and the original system.

**Lemma D.7** (Reflection).: _Let \((U^{t},V^{t})=(\{\bm{u}_{j}^{t}\}_{j\in[m]},\{\bm{v}_{i}^{t}\}_{i\in[n]})\) be a system of \(m\) users and \(n\) creators with impact functions \(f,g\). Let \(a_{i},b_{j}\in\{+1,-1\}\), \(\forall i\in[n]\), \(\forall i\in[m]\) be some binary constants. Define:_

\[\tilde{\bm{u}}_{j}^{t}=b_{j}\bm{u}_{j}^{t}=\pm\bm{u}_{j}^{t},\qquad\tilde{\bm{ v}}_{i}^{t}=a_{i}\bm{v}_{i}^{t}=\pm\tilde{\bm{v}}_{i}^{t}.\]

_and impact functions_

\[\tilde{f}(\tilde{\bm{v}}_{i},\tilde{\bm{u}}_{j})=a_{i}b_{j}f(\bm{v}_{i},\bm{u }_{j}),\qquad\tilde{g}(\tilde{\bm{u}}_{j},\tilde{\bm{v}}_{i})=a_{i}b_{j}g(\bm{ u}_{j},\bm{v}_{i}).\]

_Then:_

* _There is a "correspondence" between the evolution of the system_ \((U^{t},V^{t})\) _with impact functions_ \(f,g\) _and the evolution of the system_ \((\tilde{U}^{t},\tilde{V}^{t})=(\{\tilde{\bm{u}}_{j}^{t}\}_{j\in[m]},\{\tilde{ \bm{v}}_{i}^{t}\}_{i\in[n]})\) _with impact functions_ \(\tilde{f},\tilde{g}\)_. Formally, suppose every user is recommended the same creator in the two systems, then the updated vectors in the two systems still satisfy the relations:_ \(\tilde{\bm{u}}_{j}^{t+1}=b_{j}\bm{u}_{j}^{t+1}\)_,_ \(\tilde{\bm{v}}_{i}^{t+1}=a_{i}\bm{v}_{i}^{t+1}\)_._
* _If the system_ \((\tilde{U}^{t},\tilde{V}^{t})\) _is in_ \(R\)_-bi-polarization, then the original system_ \((U^{t},V^{t})\) _is also in_ \(R\)_-bi-polarization._

Proof.: Consider the first item. Suppose user \(i\) is recommended creator \(j\) at time step \(t\) in the two systems. Then by definition, the updated user vectors in the two systems satisfy

\[\tilde{\bm{u}}_{j}^{t+1} =\ \mathcal{P}\big{(}\tilde{\bm{u}}_{j}^{t}+\eta_{u}\tilde{f}( \tilde{\bm{v}}_{i}^{t},\tilde{\bm{u}}_{j}^{t})\tilde{\bm{v}}_{i}^{t}\big{)}\ =\ \mathcal{P}\big{(}b_{j}\bm{u}_{j}^{t}+\eta_{u}a_{i}b_{j}f(\bm{v}_{i}^{t},\bm{u }_{j}^{t})a_{i}\bm{v}_{i}^{t}\big{)}\] \[=\ \mathcal{P}\big{(}b_{j}\bm{u}_{j}^{t}+\eta_{u}b_{j}f(\bm{v}_{i}^ {t},\bm{u}_{j}^{t})\bm{v}_{i}^{t}\big{)}\ =\ b_{j}\mathcal{P}\big{(}\bm{u}_{j}^{t}+\eta_{u}f(\bm{v}_{i}^ {t},\bm{u}_{j}^{t})\bm{v}_{i}^{t}\big{)}\ =\ b_{j}\bm{u}_{j}^{t+1}\]

Suppose creator \(i\) is recommended to the set of users \(J\) at time step \(t\) in the two systems. Then,

\[\tilde{\bm{v}}_{i}^{t+1} =\ \mathcal{P}\big{(}\tilde{\bm{v}}_{i}^{t}+\frac{\eta_{c}}{|J|}\sum_ {j\in J}g(\tilde{\bm{u}}_{j}^{t},\tilde{\bm{v}}_{i}^{t})\tilde{\bm{u}}_{j}^{t} \big{)}\] \[=\ \mathcal{P}\big{(}a_{i}\bm{v}_{i}^{t}+\frac{\eta_{c}}{|J|}\sum_ {j\in J}a_{i}b_{j}g(\bm{u}_{j}^{t},\bm{v}_{i}^{t})b_{j}\bm{u}_{j}^{t}\big{)}\] \[=\ \mathcal{P}\big{(}a_{i}\bm{v}_{i}^{t}+\frac{\eta_{c}}{|J|}\sum_ {j\in J}a_{i}g(\bm{u}_{j}^{t},\bm{v}_{i}^{t})\bm{u}_{j}^{t}\big{)}\] \[=\ a_{i}\mathcal{P}\big{(}\bm{v}_{i}^{t}+\frac{\eta_{c}}{|J|}\sum_ {j\in J}g(\bm{u}_{j}^{t},\bm{v}_{i}^{t})\bm{u}_{j}^{t}\big{)}\ =\ a_{i}\bm{v}_{i}^{t+1}.\]This means that the evolution of the system \((\tilde{U}^{t},\tilde{V}^{t})\) has a correspondence to the evolution of the original system \((U^{t},V^{t})\).

Consider the second item. Suppose \((\tilde{U}^{t},\tilde{V}^{t})\) is in \(R\)-bi-polarization, so \(\tilde{\bm{v}}_{i}^{t}=\pm\bm{v}_{i}^{t}\) is \(R\)-close to \(\pm\bm{c}\) and \(\tilde{\bm{u}}_{j}^{t}=\pm\bm{u}_{j}^{t}\) is \(R\)-close to \(\pm\bm{c}\) with some vector \(\bm{c}\in\mathbb{S}^{d-1}\). This implies that \(\bm{v}_{i}^{t}\) is \(R\)-close to \(\pm\bm{c}\) and \(\bm{u}_{j}^{t}\) is \(R\)-close to \(\pm\bm{c}\). So, the system \((U^{t},V^{t})\) satisfies \(R\)-bi-polarization. 

## Appendix E Proof of Proposition 3.2

Proof.: Let \((\bm{U}^{t},\bm{V}^{t})\) be an \((R,\bm{c})\)-bi-polarization state with \(R\in[0,1]\) and \(\bm{c}\in\mathbb{S}^{d-1}\), where all \(\bm{u}_{j}^{t}\) and \(\bm{v}_{i}^{t}\) are within distance \(R\) to \(+\bm{c}\) or \(-\bm{c}\). We show that, after one step of update, \(\bm{u}_{j}^{t+1}\) and \(\bm{v}_{i}^{t+1}\) are still within distance \(R\) to \(+\bm{c}\) or \(-\bm{c}\), so \((\bm{U}^{t+1},\bm{V}^{t+1})\) still satisfies \((R,\bm{c})\)-bi-polarization.

Consider \(\bm{u}_{j}^{t}\). Without loss of generality, suppose \(\bm{u}_{j}^{t}\) is close to \(+\bm{c}\), so \(\|\bm{u}_{j}^{t}-\bm{c}\|_{2}\leq R\). Suppose user \(j\) is recommended creator \(i\) at step \(t\). Let \(\tilde{\bm{v}}_{i}^{t}=\bm{v}_{i}^{t}\) if \(\langle\bm{v}_{i}^{t},\bm{u}_{j}^{t}\rangle\geq 0\) and \(\tilde{\bm{v}}_{i}^{t}=-\bm{v}_{i}^{t}\) if \(\langle\bm{v}_{i}^{t},\bm{u}_{j}^{t}\rangle<0\). Then, the user update is

\[\bm{u}_{j}^{t+1}=\mathcal{P}\Big{(}\bm{u}_{j}^{t}+\eta_{u}f(\bm{v}_{i}^{t},\bm {u}_{j}^{t})\bm{v}_{i}^{t}\Big{)}=\mathcal{P}\Big{(}\bm{u}_{j}^{t}+\eta_{u}|f (\bm{v}_{i}^{t},\bm{u}_{j}^{t})|\tilde{\bm{v}}_{i}^{t}\Big{)}.\]

Since \(\tilde{\bm{v}}_{i}^{t}\) is close to \(+\bm{c}\) or \(-\bm{c}\), \(\langle\tilde{\bm{v}}_{i}^{t},\bm{u}_{j}^{t}\rangle>0\), and \(\bm{u}_{j}^{t}\) is close to \(+\bm{c}\), it must be that \(\tilde{\bm{v}}_{i}^{t}\) is close to \(+\bm{c}\), so \(\|\tilde{\bm{v}}_{i}^{t}-\bm{c}\|_{2}\leq R\). Then, since \(\bm{u}_{j}^{t+1}\) is the normalization of a vector in the convex cone formed by \(\bm{u}_{j}^{t}\) and \(\tilde{\bm{v}}_{i}^{t}\), by Lemma D.2, we have

\[\|\bm{u}_{j}^{t+1}-\bm{c}\|_{2}\ \leq\ \max\big{\{}\|\bm{u}_{j}^{t}-\bm{c}\|_{2}, \ \|\tilde{\bm{v}}_{i}^{t}-\bm{c}\|_{2}\big{\}}\ \leq\ R.\]

Consider \(\bm{v}_{i}^{t}\). Suppose \(\|\bm{v}_{i}^{t}-\bm{c}\|_{2}\leq R\). Let \(J\) be the set of users that are recommended creator \(i\) at step \(t\). For each \(j\in J\), let \(\tilde{\bm{u}}_{j}^{t}=\bm{u}_{j}^{t}\) if \(\langle\bm{u}_{j}^{t},\bm{v}_{i}^{t}\rangle\geq 0\) and \(\tilde{\bm{u}}_{j}^{t}=-\bm{u}_{j}^{t}\) if \(\langle\bm{u}_{j}^{t},\bm{v}_{i}^{t}\rangle<0\). Then, the creator update is

\[\bm{v}_{i}^{t+1}=\mathcal{P}\Big{(}\bm{v}_{i}^{t}+\frac{\eta_{c}}{|J|}\sum_{j \in J}g(\bm{u}_{j}^{t},\bm{v}_{i}^{t})\bm{u}_{j}^{t}\Big{)}=\mathcal{P}\Big{(} \bm{v}_{i}^{t}+\frac{\eta_{c}}{|J|}\sum_{j\in J}|g(\bm{u}_{j}^{t},\bm{v}_{i}^{ t})|\tilde{\bm{u}}_{j}^{t}\Big{)}.\]

We note that every \(\tilde{\bm{u}}_{j}^{t}\) satisfies \(\|\tilde{\bm{u}}_{j}^{t}-\bm{c}\|_{2}\leq R\) (by the same reasoning as above). Then, since \(\bm{v}_{i}^{t+1}\) is the normalization of a vector in the convex cone formed by \(\bm{v}_{i}^{t}\) and \(\{\tilde{\bm{u}}_{j}^{t}\}_{j\in J}\), by Lemma D.2, we have

\[\|\bm{v}_{i}^{t+1}-\bm{c}\|_{2}\ \leq\ \min\Big{\{}\|\bm{v}_{i}^{t}-\bm{c}\|_{2}, \ \min_{j\in J}\|\tilde{\bm{u}}_{j}^{t}-\bm{c}\|_{2}\Big{\}}\ \leq\ R.\qed\]

## Appendix F Proof of Lemma 3.4

Lemma 3.4 is proved by induction on the number \(n\) of creators. We first show that any system with 1 creator and multiple users must converge to \(R\)-bi-polarization in finite steps for any \(R>0\). Using the result for \(1\) creator, we then construct a finite length path that leads to \(R\)-bi-polarization for any system with \(n\geq 2\) creators.

### Base Case: Convergence Results for \(n=1\) Creator

We prove some convergence results for the special case of only one creator. This will serve as the basis for the proof for \(n\geq 2\) creators. Recall that we have the following dynamics update rule:

* User: \(\bm{u}_{j}^{t+1}=\mathcal{P}(\bm{u}_{j}^{t}+\eta_{u}f(\bm{v}_{i}^{t},\bm{u}_{j}^{ t})\bm{v}_{i}^{t})\) where \(\bm{v}_{i}^{t}\) is the creator recommended to user \(j\); \(f(\bm{v}_{i},\bm{u}_{j})\) satisfies: \[f(\bm{v}_{i},\bm{u}_{j})\text{ is }\begin{cases}>0&\text{if }\langle\bm{v}_{i},\bm{u}_{j} \rangle>0\\ <0&\text{if }\langle\bm{v}_{i},\bm{u}_{j}\rangle<0\\ =0&\text{if }\langle\bm{v}_{i},\bm{u}_{j}\rangle=0.\end{cases}\] (8)
* Creator: \(\bm{v}_{i}^{t+1}=\mathcal{P}(\bm{v}_{j}^{t}+\frac{\eta_{c}}{|J|}\sum_{j\in J}g (\bm{u}_{j}^{t},\bm{v}_{i}^{t})\bm{u}_{j}^{t})\) where \(J\) is the set of users being recommended creator \(i\).

**Lemma F.1**.: _Consider a system of \(1\) creator \(\bm{v}_{i}^{t}\) and \(|J|\) users \(\{\bm{u}_{j}^{t}\}_{j\in J}\), where the creator is recommended to all users at every time step. Assume:_

* _Initially,_ \(\forall j\in J,\langle\bm{u}_{j}^{0},\bm{v}_{i}^{0}\rangle>0\)_._
* _There exists some constant_ \(L_{f}>0\) _such that_ \(f(\bm{v}_{i},\bm{u}_{j})\geq L_{f}>0\) _whenever_ \(\langle\bm{v}_{i},\bm{u}_{j}\rangle>0\)_._
* \(g(\bm{u}_{j},\bm{v}_{i})=1\) _when_ \(\langle\bm{u}_{j},\bm{v}_{i}\rangle>0\)_._
* \(\eta_{c}\leq\frac{\eta_{u}L_{f}}{2}\) _and_ \(0\leq\eta_{u}<\frac{1}{2}\)_._

_Then, for any \(R>0\), after at most \(\frac{8}{3\eta_{u}L_{f}}\ln\frac{2|J|}{R^{2}}\) steps, \(\sum_{j\in J}\|\bm{u}_{j}^{t}-\bm{v}_{i}^{t}\|_{2}^{2}\leq R^{2}\) will hold forever. In particular, each user vector will satisfy \(\|\bm{u}_{j}^{t}-\bm{v}_{i}^{t}\|_{2}\leq R\)._

Proof.: We first note that, by Lemma D.5, all user vectors satisfy \(\langle\bm{u}_{j}^{t},\bm{v}_{i}^{t}\rangle>0\) in all time steps \(t>0\). Hence, the creator update is always \(\bm{v}_{i}^{t+1}=\mathcal{P}(\bm{v}_{i}^{t}+\frac{\eta_{c}}{|J|}\sum_{j\in J} g(\bm{u}_{j}^{t},\bm{v}_{i}^{t})\bm{u}_{j}^{t})=\mathcal{P}(\bm{v}_{i}^{t}+\eta_{c} \frac{1}{|J|}\sum_{j\in J}\bm{u}_{j}^{t})\).

Let \(a_{t}=1/(1-\frac{3\eta_{u}L_{f}}{8})^{t}\). Define the following potential function:

\[\Phi^{t}\;=\;a_{t}\sum_{j\in J}\frac{1}{2}\|\bm{u}_{j}^{t}-\bm{v}_{i}^{t}\|_{ 2}^{2}\;=\;a_{t}\sum_{j\in J}\big{(}1-\langle\bm{u}_{j}^{t},\bm{v}_{i}^{t} \rangle\big{)}.\] (9)

We will show that \(\Phi^{t}\) is monotonically decreasing. Take the difference between \(\Phi^{t+1}\) and \(\Phi^{t}\):

\[\Phi^{t+1}-\Phi^{t} =\;a_{t+1}\sum_{j\in J}\Big{(}\langle\bm{u}_{j}^{t},\bm{v}_{i}^{t }\rangle-\langle\bm{u}_{j}^{t+1},\bm{v}_{i}^{t+1}\rangle\Big{)}\;+\;(a_{t+1}-a _{t})\sum_{j\in J}\big{(}1-\langle\bm{u}_{j}^{t},\bm{v}_{i}^{t}\rangle\big{)}\] \[=\;a_{t+1}\bigg{(}\sum_{j\in J}\langle\bm{v}_{i}^{t},\bm{u}_{j}^{t }-\bm{u}_{j}^{t+1}\rangle+\sum_{j\in J}\langle\bm{u}_{j}^{t},\bm{v}_{i}^{t}- \bm{v}_{i}^{t+1}\rangle+\sum_{j\in J}\langle\bm{u}_{j}^{t+1}-\bm{u}_{j}^{t}, \bm{v}_{i}^{t}-\bm{v}_{i}^{t+1}\rangle\bigg{)}\] \[\qquad+\;(a_{t+1}-a_{t})\sum_{j\in J}\big{(}1-\langle\bm{u}_{j}^{t },\bm{v}_{i}^{t}\rangle\big{)}.\]

Using Lemma D.3 with \(\bm{x}^{t}=\bm{u}_{j}^{t}\), \(\bm{z}^{t}=\bm{v}_{i}^{t}\), and \(\eta=\eta_{u}f(\bm{v}_{i}^{t},\bm{u}_{j}^{t})\), we get

\[\langle\bm{v}_{i}^{t},\bm{u}_{j}^{t}-\bm{u}_{j}^{t+1}\rangle\;\leq\;-\;\frac{ \eta_{u}f(\bm{v}_{i}^{t},\bm{u}_{j}^{t})}{1+\eta_{u}f(\bm{v}_{i}^{t},\bm{u}_{j} ^{t})}\big{(}1-\langle\bm{u}_{j}^{t},\bm{v}_{i}^{t}\rangle\big{)}\;\leq\;-\; \frac{\eta_{u}L_{f}}{2}\big{(}1-\langle\bm{u}_{j}^{t},\bm{v}_{i}^{t}\rangle \big{)}.\]

Using Lemma D.4 with \(\bm{x}^{t}=\bm{u}_{j}^{t}\), \(\bm{z}^{t}=\bm{v}_{i}^{t}\), and \(\eta=\eta_{u}f(\bm{v}_{i}^{t},\bm{u}_{j}^{t})\), we get

\[\langle\bm{v}_{i}^{t},\bm{u}_{j}^{t}-\bm{u}_{j}^{t+1}\rangle\;\leq\;-\;\frac{ 1}{\eta_{u}f(\bm{v}_{i}^{t},\bm{u}_{j}^{t})}\|\bm{u}_{j}^{t+1}-\bm{u}_{j}^{t}\|_ {2}^{2}\;\leq\;-\;\frac{1}{\eta_{u}}\|\bm{u}_{j}^{t+1}-\bm{u}_{j}^{t}\|_{2}^{2}.\]

Using Lemma D.4 with \(\bm{x}^{t}=\bm{v}_{i}^{t}\), \(\bm{z}^{t}=\frac{1}{|J|}\sum_{j\in J}\bm{u}_{j}^{t}\), and \(\eta=\eta_{c}\), we get

\[\sum_{j\in J}\langle\bm{u}_{j}^{t},\bm{v}_{i}^{t}-\bm{v}_{i}^{t+1}\rangle\;=\;| J|\langle\frac{1}{|J|}\sum_{j\in J}\bm{u}_{j}^{t},\bm{v}_{i}^{t}-\bm{v}_{i}^{t+1} \rangle\;\leq\;-\;\frac{|J|}{\eta_{c}}\|\bm{v}_{i}^{t+1}-\bm{v}_{i}^{t}\|_{2}^{2}.\]

[MISSING_PAGE_EMPTY:27]

Proof.: Let \(J^{+}=\{j\in J:\langle\bm{u}^{0}_{j},\bm{v}^{0}_{i}\rangle>0\}\) be the set of users with positive inner products with creator \(i\) initially; let \(J^{-}=\{j\in J:\langle\bm{u}^{0}_{j},\bm{v}^{0}_{i}\rangle<0\}\). Let \(\tilde{\bm{u}}^{t}_{j}=-\bm{u}^{t}_{j}\) for \(j\in J^{-}\) and \(\tilde{\bm{u}}^{t}_{j}=\bm{u}^{t}_{j}\) for \(j\in J^{+}\). Then, the system consisting of \(\{\tilde{\bm{u}}^{t}_{j}\}_{j\in J}\) and \(\bm{v}^{t}_{i}\) satisfies the initial condition \(\langle\tilde{\bm{u}}^{0}_{j},\bm{v}^{0}_{i}\rangle>0\) in Lemma F.1. So, by Lemma F.1, it reaches \(R\)-consensus after at most \(\frac{8}{3\eta_{n}L_{f}}\ln\frac{2\left|J\right|}{R^{2}}\) steps. Then by the reflection lemma (Lemma D.7), the original system, consisting of \(\{\bm{u}^{t}_{j}\}_{j\in J}\) and \(\bm{v}^{t}_{i}\), must reach \(R\)-bi-polarization. 

### Inductive Step: Proof of Lemma 3.4

**Lemma F.3**.: _Consider a system of \(n\geq 1\) creators \(\{\bm{v}^{t}_{1},\ldots,\bm{v}^{t}_{n}\}\) and \(\left|J\right|\) users \(\{\bm{u}^{t}_{j}\}_{j\in J}\). Assume:_

* _Initially,_ \(\langle\bm{v}^{0}_{i},\bm{v}^{0}_{i^{\prime}}\rangle>0\) _for every_ \(i,i^{\prime}\)_, and_ \(\langle\bm{v}^{0}_{i},\bm{u}^{0}_{j}\rangle>0\) _for every_ \(i,j\)_._
* _Assumptions of Lemma F.1._

_Then, for any \(R\in(0,1)\), there exists a path of finite length that leads the initial state \((\bm{U}^{0},\bm{V}^{0})\) to \(R\)-consensus._

Proof.: Fix any \(R\in(0,1)\). Choose \(R_{1}\) such that \(\sqrt{(\frac{\eta_{n}}{\eta_{c}}+2)4R_{1}}=R\). Clearly, \(R_{1}<R\). We construct a path that leads the state \((\bm{U}^{0},\bm{V}^{0})\) to \(R\)-consensus as follows.

_Step (1): Consider the subsystem of the first \(n-1\) creators and all users \(J\). By induction, there exists a path of length \(T_{1}=L_{n-1,R_{1}}<+\infty\) that leads the subsystem to \((R_{1},\bm{c}^{T_{1}})\)-consensus with some \(\bm{c}^{T_{1}}\in\mathbb{S}^{d-1}\)._ So, after these \(T_{1}\) steps, all creators \(i\in\{1,\ldots,n-1\}\) and all users \(j\in J\) satisfy \(\|\bm{v}^{T_{1}}_{i}-\bm{c}^{T_{1}}\|\leq R_{1}\) and \(\|\bm{u}^{T_{1}}_{j}-\bm{c}^{T_{1}}\|\leq R_{1}\). Creator \(n\) does not update during these \(T_{1}\) steps, so \(\bm{v}^{T_{1}}_{n}=\bm{v}^{0}_{n}\), and it still has positive inner products with the first \(n-1\) creators and all users by the convex cone property (Lemma D.2). Let's then consider the distance between creators \(n\) and the consensus center \(\bm{c}^{T_{1}}\): \(\|\bm{v}^{T_{1}}_{n}-\bm{c}^{T_{1}}\|\). If \(\|\bm{v}^{T_{1}}_{n}-\bm{c}^{T_{1}}\|\leq R\), then the system has satisfied \((R,\bm{c}^{T_{1}})\)-consensus, so our construction is finished. Otherwise, \(\|\bm{v}^{T_{1}}_{n}-\bm{c}^{T_{1}}\|>R\). We continue the construction as follows:

_Step (2): Pick any user \(j_{0}\in J\), recommend creator \(n\) to user \(j_{0}\) for \(T_{2}=\frac{8}{3\eta_{n}L_{f}}\ln\frac{2}{R_{1}^{2}}\) steps, while recommending creator 1 to all other users._ From the \((R_{1},\bm{c}^{T_{1}})\)-consensus in step (1) we know \(\|\bm{u}^{T_{1}}_{j_{0}}-\bm{c}^{T_{1}}\|\leq R_{1}\), so

\[\langle\bm{u}^{T_{1}}_{j_{0}},\bm{c}^{T_{1}}\rangle = 1-\tfrac{1}{2}\|\bm{u}^{T_{1}}_{j_{0}}-\bm{c}^{T_{1}}\|^{2}\ \geq\ 1-\tfrac{R_{1}^{2}}{2}\ >\ 1-\tfrac{R^{2}}{2}\ \geq\ 1-\tfrac{1}{2}\|\bm{v}^{T_{1}}_{n}-\bm{c}^{T_{1}}\|^{2}\ =\ \langle\bm{v}^{T_{1}}_{2},\bm{c}^{T_{1}}\rangle.\]

Thus, we can apply Lemma D.6 with \(\bm{y}=\bm{c}^{T_{1}}\) to derive that, after these \(T_{2}\) steps,

\[\langle\bm{v}^{T_{1}+T_{2}}_{n},\bm{c}^{T_{1}}\rangle-\langle\bm{v }^{T_{1}}_{n},\bm{c}^{T_{1}}\rangle \geq \tfrac{\eta_{c}}{\eta_{u}+\eta_{c}}\Big{(}\langle\bm{u}^{T_{1}}_{ j_{0}},\bm{c}^{T_{1}}\rangle-\langle\bm{v}^{T_{1}}_{n},\bm{c}^{T_{1}}\rangle-R_{1} \Big{)}\] \[\geq \tfrac{\eta_{c}}{\eta_{u}+\eta_{c}}\Big{(}1-\tfrac{R_{1}^{2}}{2} -\langle\bm{v}^{T_{1}}_{n},\bm{c}^{T_{1}}\rangle-R_{1}\Big{)}.\] \[\implies \langle\bm{v}^{T_{1}+T_{2}}_{n},\bm{c}^{T_{1}}\rangle \geq \langle\bm{v}^{T_{1}}_{n},\bm{c}^{T_{1}}\rangle+\tfrac{\eta_{c}}{ \eta_{u}+\eta_{c}}\Big{(}1-\tfrac{R_{1}^{2}}{2}-\langle\bm{v}^{T_{1}}_{n},\bm{c }^{T_{1}}\rangle-R_{1}\Big{)}.\] (10)

For the inner product between creator \(n\) and user \(j_{0}\), by Lemma F.1 \(\|\bm{v}^{T_{1}+T_{2}}_{n}-\bm{u}^{T_{1}+T_{2}}_{j_{0}}\|\leq R_{1}\), so

\[\langle\bm{v}^{T_{1}+T_{2}}_{n},\bm{u}^{T_{1}+T_{2}}_{j_{0}}\rangle = 1-\tfrac{1}{2}\|\bm{v}^{T_{1}+T_{2}}_{n}-\bm{u}^{T_{1}+T_{2}}_{j_{0}} \|^{2}\ \geq\ 1-\tfrac{R_{1}^{2}}{2}.\] (11)

Consider the inner products between creator \(n\) and the first \(n-1\) creators and the users in \(J\setminus\{j_{0}\}\). Because the first \(n-1\) creators and the users in \(J\setminus\{j_{0}\}\) form \((R_{1},\bm{c}^{T_{1}})\)-consensus at time step \(T_{1}\), by Observation 3.2, they still form \((R_{1},\bm{c}^{T_{1}})\)-consensus at time step \(T_{1}+T_{2}\), so \(\|\bm{v}^{T_{1}+T_{2}}_{i}-\bm{c}^{T_{1}}\|\leq R_{1}\) and \(\|\bm{u}^{T_{1}+T_{2}}_{j}-\bm{c}^{T_{1}}\|\leq R_{1}\). This implies, for \(i\neq n\),

\[\langle\bm{v}^{T_{1}+T_{2}}_{n},\bm{v}^{T_{1}+T_{2}}_{j_{0}}\rangle \ \geq \ \langle\bm{v}^{T_{1}+T_{2}}_{n},\bm{c}^{T_{1}}\rangle-\|\bm{v}^{T_{1}+T _{2}}_{i}-\bm{c}^{T_{1}}\|\] \[\geq \ \langle\bm{v}^{T_{1}+T_{2}}_{2},\bm{c}^{T_{1}}\rangle-R_{1}\] (12) \[\geq \ \langle\bm{v}^{T_{1}}_{n},\bm{c}^{T_{1}}\rangle+\tfrac{\eta_{c}}{ \eta_{u}+\eta_{c}}\Big{(}1-\tfrac{R_{1}^{2}}{2}-\langle\bm{v}^{T_{1}}_{n},\bm{c}^{T_ {1}}\rangle-R_{1}\Big{)}-R_{1},\]

[MISSING_PAGE_EMPTY:29]

_Repeat steps (2) and (3) for \(K\) times._ Then, using (15) for \(K\) times,

\[F^{T_{1}+K(T_{2}+T_{3})} \leq\ \frac{\eta_{u}}{\eta_{u}+\eta_{c}}F^{T_{1}+(K-1)(T_{2}+T_{3})}+ \frac{\eta_{c}}{\eta_{u}+\eta_{c}}\Big{(}\frac{R_{1}^{2}}{2}+R_{1}\Big{)}+2R_{1}\] \[\leq\ \frac{\eta_{u}}{\eta_{u}+\eta_{c}}\bigg{(}\frac{\eta_{u}}{ \eta_{u}+\eta_{c}}F^{T_{1}+(K-2)(T_{2}+T_{3})}+\frac{\eta_{c}}{\eta_{u}+\eta_{ c}}\Big{(}\frac{R_{1}^{2}}{2}+R_{1}\Big{)}+2R_{1}\bigg{)}+\frac{\eta_{c}}{\eta_{u}+ \eta_{c}}\Big{(}\frac{R_{1}^{2}}{2}+R_{1}\Big{)}+2R_{1}\] \[\vdots\] \[\leq\ \big{(}\frac{\eta_{u}}{\eta_{u}+\eta_{c}}\big{)}^{K}F^{T_{1}}+ \Big{(}1+\frac{\eta_{u}}{\eta_{u}+\eta_{c}}+\cdots+\big{(}\frac{\eta_{u}}{\eta _{u}+\eta_{c}}\big{)}^{K-1}\Big{)}\Big{(}\frac{\eta_{c}}{\eta_{u}+\eta_{c}} \Big{(}\frac{R_{1}^{2}}{2}+R_{1}\Big{)}+2R_{1}\Big{)}\] \[\leq\ \big{(}\frac{\eta_{u}}{\eta_{u}+\eta_{c}}\big{)}^{K}\cdot 1+ \frac{1}{1-\frac{\eta_{u}}{\eta_{u}+\eta_{c}}\Big{(}\frac{\eta_{c}}{\eta_{u}+ \eta_{c}}\Big{(}\frac{R_{1}^{2}}{2}+R_{1}\Big{)}+2R_{1}\Big{)}}\] \[=\ \big{(}\frac{\eta_{u}}{\eta_{u}+\eta_{c}}\big{)}^{K}+\frac{R_{1 }^{2}}{2}+R_{1}+\frac{\eta_{u}+\eta_{c}}{\eta_{c}}2R_{1}\] \[\leq\ \frac{R_{1}^{2}}{2}+\frac{R_{1}^{2}}{2}+R_{1}+\frac{\eta_{u}+ \eta_{c}}{\eta_{c}}2R_{1}\ \leq\ \big{(}\frac{\eta_{u}}{\eta_{c}}+2)2R_{1},\]

by choosing \(K=\frac{\ln\frac{2}{R_{1}^{2}}}{\ln\frac{2\eta_{u}+\eta_{c}}{\eta_{u}}}\leq \frac{\eta_{u}+\eta_{c}}{\eta_{c}}\ln\frac{2}{R_{1}^{2}}\). This means that, after repeating steps (2) and (3) for \(K\) times, we must have

\[\|\bm{v}_{n}^{T_{1}+K(T_{2}+T_{3})}-\bm{c}^{T_{1}+K(T_{2}+T_{3})}\| =\ \sqrt{2\big{(}1-\langle\bm{v}_{n}^{T_{1}+K(T_{2}+T_{3})},\bm{c}^{T_{1}+K(T_ {2}+T_{3})}\rangle\big{)}}\] \[=\ \sqrt{2F^{T_{1}+K(T_{2}+T_{3})}}\ \leq\ \sqrt{2\big{(}\frac{\eta_{u}}{\eta_{c}}+2)2R_{1}}\ =\ R.\]

The above inequality, together with the fact that other creators \(i\neq n\) and all users in \(J\) already satisfy \((R_{1}\leq R,\bm{c}^{T_{1}+K(T_{2}+T_{3})})\)-consensus after step (3), implies that the whole system has reached \((R,\bm{c}^{T_{1}+K(T_{2}+T_{3})})\)-consensus.

The length of the path constructed above is at most:

\[T_{1}+K(T_{2}+T_{3})\ \leq\ L_{n-1,R_{1}}+\frac{\eta_{u}+\eta_{c}}{\eta_{c}}\ln \frac{2}{R_{1}^{2}}\Big{(}\frac{8}{3\eta_{u}L_{f}}\ln\frac{2|J|}{R_{1}^{2}}+L_ {n-1,R_{1}}\Big{)}\ =\ L_{n,R}\ <\ +\infty,\]

which is finite. 

**Lemma F.4**.: _Consider a subsystem of \(n\) creators \(\{\bm{v}_{1}^{t},\ldots,\bm{v}_{n}^{t}\}\) and \(|J|\) users \(\{\bm{u}_{j}^{t}\}_{j\in J}\). Assume:_

* _Initially, the first_ \(n-1\) _creators and all users are in_ \(R_{0}\)_-consensus:_ \(\|\bm{v}_{i}^{0}-\bm{c}\|\leq R_{0}\)_,_ \(\|\bm{u}_{j}^{0}-\bm{c}\|\leq R_{0}\)_, with_ \(0<R_{0}<\frac{\eta_{c}}{5(\eta_{c}+\eta_{u})}\)_._
* \(\langle\bm{v}_{n}^{0},\bm{u}_{j_{0}}^{0}\rangle>0\) _for some_ \(j_{0}\in J\)_._
* \(g(\bm{u}_{j},\bm{v}_{i})=\mathrm{sign}(\langle\bm{u}_{j},\bm{v}_{i}\rangle)\)_._
* _Assumption of Lemma F.1._

_Then, for any \(R\in(0,1)\), there exists a path of finite length that leads the initial state \((\bm{U}^{0},\bm{V}^{0})\) to \(R\)-consensus._

Proof.: First, we recommend creator \(n\) to user \(j_{0}\) for \(T=\frac{8}{3\eta_{u}L_{f}}\ln\frac{2}{R_{0}^{2}}\) steps, while recommending other creators to other users arbitrarily. Applying Lemma D.6 with \(\bm{y}=\bm{u}_{j_{0}}^{0}\), we get

\[\langle\bm{v}_{n}^{T},\bm{u}_{j_{0}}^{0}\rangle-\langle\bm{v}_{n}^{0},\bm{u}_{j _{0}}^{0}\rangle\ \geq\ \frac{\eta_{c}}{\eta_{u}+\eta_{c}}\Big{(}\langle\bm{u}_{j_{0}}^{0},\bm{u}_{j_{0 }}^{0}\rangle-\langle\bm{v}_{n}^{0},\bm{u}_{j_{0}}^{0}\rangle-R_{0}\Big{)}\ =\ \frac{\eta_{c}}{\eta_{u}+\eta_{c}}\Big{(}1-\langle\bm{v}_{n}^{0},\bm{u}_{j_{0}}^{0 }\rangle-R_{0}\Big{)}.\] (16)

On the other hand, because the first \(n-1\) creators and all users in \(J\setminus\{j_{0}\}\) form an \((R_{0},\bm{c})\)-consensus at time step \(0\), according to Observation 3.2, they still form an \((R_{0},\bm{c})\)-consensus at time step \(T\), so \(\|\bm{v}_{i}^{T}-\bm{c}\|\leq R_{0}\) for every \(i\in\{1,\ldots,n-1\}\). This implies, for every \(i\in\{1,\ldots,n-1\}\),

\[\langle\bm{v}_{n}^{T},\bm{v}_{i}^{T}\rangle-\langle\bm{v}_{n}^{T},\bm{u}_{j_{0 }}^{0}\rangle\ \geq\ -\|\bm{v}_{i}^{T}-\bm{u}_{j_{0}}^{0}\|\ \geq\ -\|\bm{v}_{i}^{T}-\bm{c}\|-\|\bm{c}-\bm{u}_{j_{0}}^{0}\|\ \geq\ -2R_{0}.\] (17)Adding (16) and (17) and moving \((\bm{v}_{n}^{0},\bm{u}_{j_{0}}^{0})\) to the right side, we get

\[\langle\bm{v}_{n}^{T},\bm{v}_{i}^{T}\rangle \geq \langle\bm{v}_{n}^{T},\bm{u}_{j_{0}}^{0}\rangle+\frac{\eta_{c}}{ \eta_{u}+\eta_{c}}\big{(}1-\langle\bm{v}_{n}^{0},\bm{u}_{j_{0}}^{0}\rangle-R_{ 0}\big{)}-2R_{0}\] \[= \frac{\eta_{c}}{\eta_{u}+\eta_{c}}\langle\bm{v}_{n}^{0},\bm{u}_{j _{0}}^{0}\rangle+\frac{\eta_{c}}{\eta_{u}+\eta_{c}}\big{(}1-R_{0}\big{)}-2R_{0}\] \[> 0+\frac{\eta_{c}}{\eta_{u}+\eta_{c}}\big{(}1-R_{0}\big{)}-2R_{0} \;>\;0,\]

under the condition of \(R_{0}<\frac{\eta_{c}}{5(\eta_{u}+\eta_{c})}\). Moreover, for every \(j\in J\setminus\{j_{0}\}\), because \(\|\bm{u}_{j}^{T}-\bm{v}_{i}^{T}\|\leq\|\bm{u}_{j}^{T}-\bm{c}\|+\|\bm{c}-\bm{v}_ {i}^{T}\|\leq 2R_{0}\),

\[\langle\bm{v}_{n}^{T},\bm{u}_{j}^{T}\rangle\;\geq\;\langle\bm{v}_{n}^{T},\bm{ v}_{i}^{T}\rangle-\|\bm{u}_{j}^{T}-\bm{v}_{i}^{T}\|\;\geq\;\frac{\eta_{c}}{\eta_{u}+ \eta_{c}}\big{(}1-R_{0}\big{)}-4R_{0}>0.\]

For \(j_{0}\), by Lemma F.1, \(\|\bm{v}_{n}^{T}-\bm{u}_{j_{0}}^{T}\|\leq R_{0}\), so

\[\langle\bm{v}_{n}^{T},\bm{u}_{j_{0}}^{T}\rangle\;=\;1-\tfrac{1}{2}\|\bm{v}_{n} ^{T}-\bm{u}_{j_{0}}^{T}\|^{2}\;\geq\;1-\tfrac{R_{0}^{2}}{2}\;>\;0.\]

For the inner product between any creator \(i\in\{1,\ldots,n-1\}\) and the users:

\[\langle\bm{v}_{i}^{T},\bm{u}_{j_{0}}^{T}\rangle\;\geq\;\langle\bm{v}_{i}^{T}, \bm{v}_{n}^{T}\rangle-\|\bm{v}_{n}^{T}-\bm{u}_{j_{0}}^{T}\|\;\geq\;\tfrac{\eta _{c}}{\eta_{u}+\eta_{c}}\big{(}1-R_{0}\big{)}-2R_{0}-R_{0}\;=\;\tfrac{\eta_{c} }{\eta_{u}+\eta_{c}}\big{(}1-R_{0}\big{)}-3R_{0}\;>\;0;\]

\[\forall j\in J\setminus\{j_{0}\},\quad\langle\bm{v}_{i}^{T},\bm{u}_{j}^{T} \rangle\;=\;1-\tfrac{1}{2}\|\bm{v}_{i}^{T}-\bm{u}_{j}^{T}\|^{2}\;\geq\;1- \tfrac{1}{2}\big{(}\|\bm{v}_{i}^{T}-\bm{c}\|+\|\bm{c}-\bm{u}_{j}^{T}\|\big{)}^ {2}\;>\;1-\tfrac{1}{2}(2R_{0})^{2}\;>\;0.\]

All of the "\(>0\)" inequalities above show that the system of \(\{\bm{v}_{i}^{T}\}_{i\in[n]}\) and \(\{\bm{u}_{j}^{T}\}_{j\in J}\) satisfies the condition of Lemma F.3. So, there exists a path of finite length \(T_{2}<+\infty\) that leads the system to \(R\)-consensus by Lemma F.3. The total length of path \(T+T_{2}=\frac{8}{3\eta_{u}L_{f}}\ln\frac{2^{|J|}}{R_{0}^{2}}+T_{2}<+\infty\) is finite. 

**Lemma 3.4**.: _Suppose \(\eta_{c}\leq\frac{\eta_{u}L_{f}}{2}\) and \(\eta_{u}<\frac{1}{2}\). For any \(R>0\), for almost every state \((\bm{U}^{t},\bm{V}^{t})\) in the state space, there exists a path \((\bm{U}^{t},\bm{V}^{t})\to(\bm{U}^{t+1},\bm{V}^{t+1})\to\cdots\to(\bm{U}^{t+T},\bm{V}^{t+T})\) of finite length that leads to an \(R\)-bi-polarization state \((\bm{U}^{t+T},\bm{V}^{t+T})\)._

Proof.: We prove this lemma by induction on the number of creators \(n\). The case for \(n=1\) directly follows from Corollary F.2 which shows that, for any system of \(n=1\) creator and \(|J|\) users with no \(\langle\bm{v}_{i}^{0},\bm{u}_{j}^{0}\rangle=0\), there exists a path of length at most \(L_{1}^{R}=\frac{8}{3\eta_{u}L_{f}}\ln\frac{2^{|J|}}{R^{2}}<+\infty\) that leads to \(R\)-bi-polarization.

Consider \(n\geq 2\). Consider the subsystem consisting of the first \(n-1\) creators \(\{\bm{v}_{1}^{t},\ldots,\bm{v}_{n-1}^{t}\}\) and all users. Let \(R_{0}=\frac{\eta_{c}}{6(\eta_{c}+\eta_{u_{0}})}\). By induction, there exists a path of finite length \(T_{1}=L_{n-1}^{R_{0}}<+\infty\) that leads the subsystem to \(R_{0}\)-bi-polarization, with some vector \(\bm{c}_{0}\in\mathbb{S}^{d-1}\), so every \(\bm{v}_{i}^{T_{1}}\) is \(R_{0}\)-close to \(+\bm{c}_{0}\) or \(-\bm{c}_{0}\), for \(i\neq n\), and every \(\bm{u}_{j}^{T_{1}}\) is \(R_{0}\)-close to \(+\bm{c}_{0}\) or \(-\bm{c}_{0}\). Define:

\[\tilde{\bm{v}}_{i}^{t}=\begin{cases}\bm{v}_{i}^{t}&\text{if $\bm{v}_{i}^{T_{1}}$ is $R_{0}$-close to $+\bm{c}$}\\ -\bm{v}_{i}^{t}&\text{if $\bm{v}_{i}^{T_{1}}$ is $R_{0}$-close to $-\bm{c}$} \end{cases}\quad\forall i\neq n,\qquad\quad\tilde{\bm{u}}_{j}^{t}=\begin{cases} \bm{u}_{j}^{t}&\text{if $\bm{u}_{j}^{T_{1}}$ is $R_{0}$-close to $+\bm{c}$}\\ -\bm{u}_{j}^{t}&\text{if $\bm{u}_{j}^{T_{1}}$ is $R_{0}$-close to $-\bm{c}$}\end{cases}\quad\forall j\in J.\]

By definition, we have

\[\|\tilde{\bm{v}}_{i}^{T_{1}}-\bm{c}_{0}\|\leq R_{0},\;\;\;\forall i\neq n, \qquad\quad\|\tilde{\bm{u}}_{j}^{T_{1}}-\bm{c}_{0}\|\leq R_{0},\;\;\;\forall j \in J.\]

This means that \(\{\tilde{\bm{v}}_{i}^{T_{1}}\}_{i\neq n}\) and \(\{\tilde{\bm{u}}_{j}^{T_{1}}\}_{j\in J}\) form an \((R_{0},\bm{c}_{0})\)-consensus. Consider creator \(n\). Let

\[\tilde{\bm{v}}_{n}^{t}=\begin{cases}\bm{v}_{n}^{t}&\text{if $\langle\bm{v}_{i}^{T_{1}},\tilde{\bm{u}}_{j}^{T_{1}} \rangle>0$ for some $j_{0}\in J$}\\ -\bm{v}_{n}^{t}&\text{if $\langle\bm{v}_{i}^{T_{1}},\tilde{\bm{u}}_{j}^{T_{1}} \rangle<0$ for all $j\in J$.}\end{cases}\]

(The case where \(\langle\bm{v}_{n}^{T_{1}},\tilde{\bm{u}}_{j}^{T_{1}}\rangle=0\) for some \(j\in J\) is ignored because the initial states that can lead to such states have measure \(0\).) By definition, we have

\[\langle\tilde{\bm{v}}_{n}^{T_{1}},\tilde{\bm{u}}_{j_{0}}^{T_{1}}\rangle>0\text { for some $j_{0}\in J$.}\]

Note that, at time step \(T_{1}\), the system consisting of \(\{\tilde{\bm{v}}_{i}^{T_{1}}\}_{i\in[n]}\) and \(\{\tilde{\bm{u}}_{j}^{T_{1}}\}_{j\in J}\) satisfies the condition of Lemma F.4, so there exists a path of length \(T_{2}=\tilde{L}_{n}^{R}<+\infty\) that leads the system to \(R\)-consensus. Then by the reflection lemma (Lemma D.7), the original system \(\{\bm{vMissing Proofs from Section 4

### Proof of Proposition 4.2

Let \(R>0\) be any small number. Let \(\bm{c}_{1},\ldots,\bm{c}_{\lfloor n/k\rfloor}\in\mathbb{R}^{d}\) be \(\lfloor n/k\rfloor\) vectors that satisfy \(B(\bm{c}_{\ell},2R)\cap B(\bm{c}_{\ell^{\prime}},2R)=\emptyset\) for \(\ell\neq\ell^{\prime}\), where \(B(\bm{c},R)\) is the ball centered at \(\bm{c}\) with radius \(R\): \(\{\bm{x}\in\mathbb{R}^{d}:\|\bm{x}-\bm{c}\|_{2}\leq R\}\). Consider user and creator features \((\bm{U}^{t},\bm{V}^{t})\) that satisfy: every ball \(B(\bm{c}_{\ell},R)\) (\(\ell=1,\ldots,\lfloor n/k\rfloor\)) contains \(k\) creator vectors, and every user vector \(\bm{u}^{t}_{j}\) is in one of the balls \(B(\bm{c}_{\ell},R)\). By definition, \((\bm{U}^{t},\bm{V}^{t})\) form \(\lfloor n/k\rfloor\) clusters. We show that, after one step of update, the new state \((\bm{U}^{t+1},\bm{V}^{t+1})\) must still form \(\lfloor n/k\rfloor\) clusters. Consider any user \(j\). Suppose \(\bm{u}^{t}_{j}\in B(\bm{c}_{\ell},R)\), then the distance from \(\bm{u}^{t}_{j}\) to any creator \(\bm{v}^{t}_{i}\in B(\bm{c}_{\ell},R)\) is at most \(2R\):

\[\|\bm{u}^{t}_{j}-\bm{v}^{t}_{i}\|\leq 2R.\]

The distance from \(\bm{u}^{t}_{j}\) to any creator \(\bm{v}^{t}_{i^{\prime}}\) not in \(B(\bm{c}_{\ell},R)\) is greater than \(2R\):

\[\|\bm{u}^{t}_{j}-\bm{v}^{t}_{i^{\prime}}\|>2R\]

because \(\bm{v}^{t}_{i^{\prime}}\) is in some other ball \(B(\bm{c}_{\ell^{\prime}},R)\) that satisfies \(B(\bm{c}_{\ell^{\prime}},2R)\cap B(\bm{c}_{\ell},2R)=\emptyset\). This implies that the inner products between user \(j\) and the creators in ball \(B(\bm{c}_{\ell},R)\) are greater than that with the creators in other ball:

\[\forall\bm{v}^{t}_{i}\in B(\bm{c}_{\ell},R),\ \ \langle\bm{u}^{t}_{j},\bm{v}^{t}_{i} \rangle=1-\frac{1}{2}\|\bm{u}^{t}_{j}-\bm{v}^{t}_{i}\|_{2}^{2}\geq 1-\frac{1}{ 2}(2R)^{2}>1-\frac{1}{2}\|\bm{u}^{t}_{j}-\bm{v}^{t}_{i^{\prime}}\|=\langle\bm {u}^{t}_{j},\bm{v}^{t}_{i}\rangle,\ \ \forall\bm{v}^{t}_{i^{\prime}}\in B(\bm{c}_{\ell^{ \prime}},R).\]

Since \(B(\bm{c}_{\ell},R)\) contains \(k\) creators, these \(k\) creators are the \(k\)-most relevant ones to user \(j\), so user \(j\) will only be recommended these creators. Then, by applying Observation 3.2 to each of the \(\lfloor n/k\rfloor\) balls separately, we see that each ball is a \(R\)-consensus and hence absorbing. So, the new state \((\bm{U}^{t+1},\bm{V}^{t+1})\) still forms \(\lfloor n/k\rfloor\) clusters with these \(\lfloor n/k\rfloor\) balls.

### Proof of Proposition 4.3

The \(d\)-dimensional simplex centered at the original has \(d+1\) vectors with negative inner products with each other. They form \(d+1\) clusters. Since user-creator pairs with negative inner product \(\langle\bm{u}_{i},\bm{v}_{j}\rangle<0\) are not recommended, recommendations only happen within each cluster. By Observation 3.2, each cluster is absorbing, so the whole system is stable, keep forming \(d+1\) clusters forever.

## Appendix H Additional Discussion on Real-World Recommender Systems

Here we further discuss real-world recommender systems' properties and designs that are currently not covered in our main paper. We plan to generalize our model in the future to further capture these features and discuss insightful findings, but having them in the current paper may be a distraction to our main findings.

### User and Creator Retention and Activeness

In our current model, the users and creators will stay in the system from the start to the end. However, in real-world recommender systems, users and creators may leave the platform either permanently or for a certain period. Meanwhile, new users and creators will join the platform. Such join and leave dynamics are also influenced by the recommendations' relevance and diversity, which further complicate the problem. Moreover, users and creators have different activeness levels on the platform, e.g., some users may watch a lot more videos than others, and some creators may post a lot more creations, these effects will also be strongly correlated with the dual influence of the recommender system.

### Creation Quality

Creation quality is a major factor influencing users' feedback in addition to the creation style, e.g., well-made cuisine videos could also be fun and liked by gamers and pet lovers, which we need more than a collaborative filtering type of modeling like our current model to capture such features. A potential solution to boost both long-term system diversity and single-shot recommendation diversity is to design mechanisms that can incentivize creators to create higher-quality videos instead of changing their creation styles.

### Cold Start

Cold Start is widely used in real-world recommender systems for newly published items. Due to the lack of user-item interactions on new items, the systems randomly recommend these new items to users and collect data for collaborative filtering. In our current model, if we consider the creators creating new items in each time step under their current time creation style, then cold start guarantees the conditions in Theorem 3.3. But if we consider the system to have good enough content understanding ability and can accurately predict the new creations' embeddings, the cold start is not necessary and our model and results in the top-\(k\) truncation and threshold truncation parts are valid. We also highlight a subtle difference between cold start and random traffic, if cold start is used on creators instead of items, then after the creator is exposed to users a certain number of times, the system will not guarantee to provide a non-zero probability of recommending this creator, and thus the conditions in Theorem 3.3 may not hold.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: Limitations are discussed in Section 6 and Section H. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes]Justification: Proof sketches are given in the body and the full proofs are in the appendix. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: Experiment details are provided in Section 5 and Section C. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?Answer: [Yes] Justification: Provided in the supplemental file. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: See Section 5. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors). * It should be clear whether the error bar is the standard deviation or the standard error of the mean. ** It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [NA] Justification: Computer resources are not a limitation in our experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: Discussed in Section 6. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. * If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. * If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets?Answer: [NA] Justification: Guidelines:

* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.