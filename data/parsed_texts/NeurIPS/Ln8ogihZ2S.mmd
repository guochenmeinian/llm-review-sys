# eXponential FAmily Dynamical Systems (XFADS):

Large-scale nonlinear Gaussian state-space modeling

 Matthew Dowling

Champalimaud Research, Champalimaud Foundation, Portugal

matthew.dowling@research.fchampalimaud.org

&Yuan Zhao

National Institute of Mental Health, USA

yuan.zhao@nih.gov

&Il Memming Park

Champalimaud Research, Champalimaud Foundation, Portugal

memming.park@research.fchampalimaud.org

###### Abstract

State-space graphical models and the variational autoencoder framework provide a principled apparatus for learning dynamical systems from data. State-of-the-art probabilistic approaches are often able to scale to large problems at the cost of flexibility of the variational posterior or expressivity of the dynamics model. However, those consolidations can be detrimental if the ultimate goal is to learn a generative model capable of explaining the spatiotemporal structure of the data and making accurate forecasts. We introduce a low-rank structured variational autoencoding framework for nonlinear Gaussian state-space graphical models capable of capturing dense covariance structures that are important for learning dynamical systems with predictive capabilities. Our inference algorithm exploits the covariance structures that arise naturally from sample based approximate Gaussian message passing and low-rank amortized posterior updates - effectively performing approximate variational smoothing with time complexity scaling linearly in the state dimensionality. In comparisons with other deep state-space model architectures our approach consistently demonstrates the ability to learn a more predictive generative model. Furthermore, when applied to neural physiological recordings, our approach is able to learn a dynamical system capable of forecasting population spiking and behavioral correlates from a small portion of single trials.

## 1 Introduction

State-space models (SSM) are invaluable for understanding the temporal structure of complex natural phenomena through their underlying dynamics [1, 2, 3]. While engineering or physics problems often assume the dynamical laws of the system of interest are known to a high degree of accuracy, in an unsupervised data-driven investigation, they have to be learned from the observed data. The variational autoencoder (VAE) framework makes it possible to jointly learn the parameters of the state-space description and an inference network to amortize posterior computation of the unknown latent state [4, 5, 6, 7]. However, it can be challenging to structure the variational approximation and design an inference network that permits fast evaluation of the loss function (evidence lower bound or ELBO) while preserving the temporal structure of the posterior.

In this work, we develop a structured variational approximation, approximate ELBO, and inference network architecture for generative models specified by nonlinear dynamical systems with Gaussian state noise. Our main contributions are as follows,

1. A structured amortized variational approximation that combines the prior dynamics with low-rank data updates to parameterize Gaussian distributions with dense covariance matrices.
2. Conceptualizing the approximate smoothing problem as an approximate filtering problem for pseudo-observations that encode a representation of current and future data, and,
3. An inference algorithm that scales \(\mathcal{O}(TL(Sr+S^{2}+r^{2}))-\) made possible by exploiting the low-rank structure of the amortization network as well as Monte Carlo integration of the latent state through the dynamics.

## 2 Background

State-space models are probabilistic graphical models where observations \(\mathbf{y}_{t}\) in discrete time are conditionally independent given a continuous latent state, \(\mathbf{z}_{t}\), evolving according to Markovian dynamics, so that the complete data likelihood for \(T\) consecutive observations factorizes as,

\[p(\mathbf{y}_{1:T},\mathbf{z}_{1:T})=p_{\boldsymbol{\theta}}(\mathbf{z}_{1}) \,p_{\boldsymbol{\psi}}(\mathbf{y}_{1}\,|\,\mathbf{z}_{1})\times\prod\nolimits _{t=2}^{T}p_{\boldsymbol{\psi}}(\mathbf{y}_{t}\,|\,\mathbf{z}_{t})\,p_{ \boldsymbol{\theta}}(\mathbf{z}_{t}\,|\,\mathbf{z}_{t-1})\]

where \(\mathbf{z}_{t}\in\mathbb{R}^{L}\) are real-valued latent states, \(\boldsymbol{\theta}\) parameterizes the dynamics and initial condition, and \(\boldsymbol{\psi}\) parameterizes the observation model. When the generative model, \((\boldsymbol{\theta},\boldsymbol{\psi})\), is known, the statistical inference problem is to compute the smoothing posterior, \(p(\mathbf{z}_{1:T}\,|\,\mathbf{y}_{1:T})^{2}\). Otherwise, \((\boldsymbol{\theta},\boldsymbol{\psi})\) have to be learned from the data - known as system identification[8].

Variational inference makes it possible to accomplish these goals in a harmonious way. The variational expectation maximization (vEM) algorithm iterates two steps: first, we maximize a lower bound to the log-marginal likelihood - the ELBO - with respect to the parameters of an approximate posterior, \(q(\mathbf{z}_{1:T})\approx p(\mathbf{z}_{1:T}\,|\,\mathbf{y}_{1:T})\); then, with the approximate posterior fixed, the ELBO is maximized with respect to parameters of the generative model[9]. For large scale problems, vEM can be slow due to the need to fully optimize the variational parameters before taking gradient steps on parameters of the generative model. Therefore, the variational autoencoder (VAE) is better suited for large scale problems for its ability to simultaneous learn the generative model and inference network - an expressive parametric function that maps data to the parameters of approximate posterior [10; 11].

**Model specifications.** Although our approach is applicable to any exponential family state-space process, given their ubiquity, we focus on dynamical systems driven by Gaussian noise so that,

\[p_{\boldsymbol{\theta}}(\mathbf{z}_{t}\,|\,\mathbf{z}_{t-1})=\mathcal{N}( \mathbf{z}_{t}\,|\,\mathbf{m}_{\boldsymbol{\theta}}(\mathbf{z}_{t-1}),\mathbf{ Q}_{\boldsymbol{\theta}})\] (1)

where \(\mathbf{m}_{\boldsymbol{\theta}}:\mathbb{R}^{L}\rightarrow\mathbb{R}^{L}\) might be a nonlinear neural network function with learnable parameters \(\boldsymbol{\theta}\), and \(\mathbf{Q}_{\boldsymbol{\theta}}\in\mathbb{R}^{L\times L}\) is a learnable state-noise covariance matrix. Given the favorable properties of exponential family distributions [12; 13; 14; 15], especially in the context of variational inference, we write the prior dynamics in their exponential family representation (natural parameter form),

\[p_{\boldsymbol{\theta}}(\mathbf{z}_{t}\,|\,\mathbf{z}_{t-1})=h(\mathbf{z}_{t}) \exp\big{(}\mathcal{T}(\mathbf{z}_{t})^{\top}\boldsymbol{\lambda}_{ \boldsymbol{\theta}}(\mathbf{z}_{t-1})-A(\boldsymbol{\lambda}_{\boldsymbol{ \theta}}(\mathbf{z}_{t-1}))\big{)}\] (2)

where \(h\) is the base measure, \(\mathcal{T}(\mathbf{z}_{t})\) the sufficient statistics, \(A(\cdot)\) the log-partition function, and \(\boldsymbol{\lambda}_{\boldsymbol{\theta}}(\cdot)\) is a map \(\mathbb{R}^{L}\mapsto\mathbb{R}^{L^{2}+L}\) that transforms \(\mathbf{z}_{t-1}\) to natural parameters for \(\mathbf{z}_{t}\). For a Gaussian distribution, the sufficient statistics can be defined as \(\mathcal{T}(\mathbf{z}_{t})^{\top}=\begin{bmatrix}\mathbf{z}_{t}^{\top}&- \frac{1}{2}\mathbf{z}_{t}\mathbf{z}_{t}^{\top}\end{bmatrix}\), so that \(\boldsymbol{\lambda}_{\boldsymbol{\theta}}(\cdot)\) for (1) is given by,

\[\boldsymbol{\lambda}_{\boldsymbol{\theta}}(\mathbf{z}_{t-1})=\begin{bmatrix} \mathbf{Q}_{\boldsymbol{\theta}}^{-1}\mathbf{m}_{\boldsymbol{\theta}}( \mathbf{z}_{t-1})\\ \mathbf{Q}_{\boldsymbol{\theta}}^{-1}\end{bmatrix}\qquad\text{(dynamics model in natural paramter form)}\] (3)

As it will simplify subsequent analysis, the _mean parameter_ mapping corresponding to this natural parameter mapping (guaranteed to exist as long as the exponential family is minimal[12]) is given by

\[\boldsymbol{\mu}_{\boldsymbol{\theta}}(\mathbf{z}_{t-1})=\mathbb{E}_{p_{ \boldsymbol{\theta}}(\mathbf{z}_{t}|\mathbf{z}_{t-1})}\left[\mathcal{T}( \mathbf{z}_{t})\right]=\begin{bmatrix}\mathbf{m}_{\boldsymbol{\theta}}( \mathbf{z}_{t-1})\\ -\frac{1}{2}\left(\mathbf{m}_{\boldsymbol{\theta}}(\mathbf{z}_{t-1}) \mathbf{m}_{\boldsymbol{\theta}}(\mathbf{z}_{t-1})^{\top}+\mathbf{Q}_{ \boldsymbol{\theta}}\right)\end{bmatrix}\qquad\begin{pmatrix}\text{mean}\\ \text{parameter}\\ \text{form}\end{pmatrix}\] (4)

Furthermore, we make the following assumptions **i)** the state-noise, \(\mathbf{Q}_{\boldsymbol{\theta}}\), is diagonal or structured for efficient matrix-vector multiplications. **ii)**\(\mathbf{m}_{\boldsymbol{\theta}}(\cdot)\), is a nonlinear smooth function. **ii)** the likelihood, \(p_{\boldsymbol{\psi}}(\mathbf{y}_{t}\,|\,\mathbf{z}_{t})\), may be non-conjugate. **iv)**\(L\) may be large enough so that \(L^{3}\) is comparable to \(T\).

**Amortized inference for state-space models.** A useful property of SSMs is that, \(\mathbf{z}_{t}\) conditioned on \(\mathbf{z}_{t-1}\) and \(\mathbf{y}_{t:T}\), is independent of \(\mathbf{y}_{1:t-1}\), i.e., \(p(\mathbf{z}_{t}\,|\,\mathbf{z}_{t-1},\mathbf{y}_{1:T})=p(\mathbf{z}_{t}\,|\, \mathbf{z}_{t-1},\mathbf{y}_{t:T})\)[5, 16]. It thus suffices to construct an approximate posterior that factorizes forward in time,

\[q(\mathbf{z}_{1:T})=q(\mathbf{z}_{1})\prod q(\mathbf{z}_{t}\,|\,\mathbf{z}_{t -1})\] (5)

and introduce learnable function approximators to amortize inference by mapping \(\mathbf{z}_{t-1}\) and \(\mathbf{y}_{t:T}\) to the parameters of \(q(\mathbf{z}_{t}\,|\,\mathbf{z}_{t-1})\). This makes it simple to sample \(\mathbf{z}_{1:T}\) from the approximate posterior (using the reparameterization trick) and evaluate the ELBO (a.k.a. negative variational free energy),

\[\mathcal{L}(q)=\sum\mathbb{E}_{q_{t}}\left[\log p(\mathbf{y}_{t}\,|\,\mathbf{ z}_{t})\right]-\mathbb{E}_{q_{t-1}}\left[\mathbb{D}_{\text{KL}}(q( \mathbf{z}_{t}\,|\,\mathbf{z}_{t-1})||\,p_{\boldsymbol{\theta}}(\mathbf{z}_{ t}\,|\,\mathbf{z}_{t-1}))\right]\leq\log p(\mathbf{y}_{1:T})\] (6)

where \(\mathbb{D}_{\text{KL}}(\cdot||\cdot)\) is the Kullback-Leibler (KL) divergence and \(\mathbb{E}_{q_{t}}\equiv\mathbb{E}_{\mathbf{z}_{t}\sim q(\mathbf{z}_{t}, \mathbf{y}_{1:T})}\), so that the generative model and inference network parameters can be learned through stochastic backpropagation. Many works for Gaussian \(q(\mathbf{z}_{t}\,|\,\mathbf{z}_{t-1})\), such as Krishnan et al. [6], Alaa and van der Schaar [17], Girin et al. [18], Hafner et al. [19], construct inference networks that parameterize the variational posterior as

\[q(\mathbf{z}_{t}\,|\,\mathbf{z}_{t-1})=\mathcal{N}(\mathbf{m}_{\boldsymbol{ \phi}}(\mathbf{z}_{t-1},\mathbf{y}_{1:T}),\mathbf{P}_{\boldsymbol{\phi}}( \mathbf{z}_{t-1},\mathbf{y}_{1:T})).\] (7)

There are limitless ways to construct \(\mathbf{m}_{\boldsymbol{\phi}}(\cdot)\) and \(\mathbf{P}_{\boldsymbol{\phi}}(\cdot)\) so \(\boldsymbol{\phi}\) can be learned through gradient ascent on the ELBO, but a straightforward and illustrative approach [6, 17] is to transform future data, \(\mathbf{y}_{t:T}\), using a recurrent neural network (RNN), or any efficient autoregressive sequence to sequence model, and then mapping the preceding latent state, \(\mathbf{z}_{t-1}\), using a feed-forward neural network, so that a complete inference network description could be,

\[(\mathbf{m}_{\boldsymbol{\phi}}(\mathbf{z}_{t-1},\mathbf{y}_{t:T}),\mathbf{P} _{\boldsymbol{\phi}}(\mathbf{z}_{t-1},\mathbf{y}_{t:T}))=\text{NN}([\mathbf{z} _{t-1},\mathbf{u}_{t}]),\hskip 28.452756pt\mathbf{u}_{t}=\text{S2S}([ \mathbf{u}_{t+1},\mathbf{y}_{t}])\] (8)

where \(\text{S2S}(\cdot)\) is a parametric sequence-to-sequence function that maintains a hidden state \(\mathbf{u}_{t}\) and takes as input \(\mathbf{y}_{t}\), and \(\text{NN}(\cdot)\) is a parametric function designed to output approximate posterior parameters. This leads to a backward-forward algorithm, meaning that data \(\mathbf{y}_{1:T}\) are mapped to \(\mathbf{u}_{1:T}\) in reverse time, and then samples are drawn from \(q(\mathbf{z}_{t}\,|\,\mathbf{z}_{t-1})\) forward in time.

Possible drawbacks of this inference framework are **i)** missing observations obstruct inference (the example networks cannot naturally accommodate missing data); **ii)** sampling entire trajectories to approximate the expected KL term can potentially lead to high-variance gradient estimators, and **iii)** statistics of the marginals (e.g. second moments) can only be approximated through sample averages.

## 3 Related works

Many existing works also explore inference and data-driven learning for state-space graphical models within the VAE framework. We highlight the most closely related studies and note specific limitations that our work seeks to address. The structured variational autoencoder (SVAE) [20] makes it possible to efficiently evaluate the ELBO while preserving the temporal structure of the posterior by restricting the prior to a _linear dynamical system_ (LDS) and then constructing the approximation as \(q(\mathbf{z}_{1:T})\propto p_{\boldsymbol{\theta}}(\mathbf{z}_{1:T})\prod \exp(t(\mathbf{z}_{t})^{\top}\psi(\mathbf{y}_{t}))\) so that its statistics can be obtained using efficient message passing algorithms. However, the SVAE is not directly applicable when the dynamics are nonlinear since the joint prior will no longer be Gaussian (thereby not allowing for efficient conjugate updates). Recently, Zhao and Linderman [21] expanded on the SVAE framework by exploiting the LDS structure and associative scan operations to improve its scalability.

The deep Kalman filter (DKF) [6] uses black-box inference networks to make drawing joint samples from the full posterior simple. However, pure black-box amortization networks such as those can make learning the parameters of the generative model dynamics difficult because their gradients will not propagate through the expected log-likelihood term [5]. In contrast, we consider inference networks inspired by the fundamental importance of the prior for evaluating Bayesian conjugate updates. The deep variational Bayes filter (DVBF) also considers inference and learning in state-space graphical models [5]. Difficulties of learning the generative model that arise as a result of more standard VAE implementations defining inference networks independent of the prior are handled by forcing samples from the approximate posterior to traverse through the dynamics. Our work extends this concept, by directly specifying the parameters of the variational approximation in terms of the prior.

Our approach constructs an inference network infused with the prior similar to the SVAE and DVBF but i) avoids restrictions to LDS and ii) affords easy access to approximations of the marginal statistics (such as the dense latent state covariances) without having to average over sampled trajectories (or store them directly which would be prohibitive as the latent dimensionality becomes large).

Method

An alternative to constructing variational approximations through specification of conditional distributions, as in Eq. (7), involves the use of data-dependent Gaussian potentials, that we refer to as pseudo-observations:

\[p(\tilde{\mathbf{y}}_{t}\,|\mathbf{z}_{t})\propto\exp(\tilde{\mathbf{\lambda}}_{ \Phi}(\mathbf{y}_{1:T})^{\top}\mathcal{T}(\mathbf{z}_{t}))\equiv\exp(\tilde{ \mathbf{\lambda}}_{t}^{\top}\mathcal{T}(\mathbf{z}_{t}))=\exp\left(\mathbf{k} _{t}^{\top}\mathbf{z}_{t}-\tfrac{1}{2}\|\mathbf{K}_{t}\mathbf{z}_{t}\|^{2}\right)\] (9)

These Gaussian potentials can then be combined with the prior through Bayes' rule, yielding the approximation

\[q(\mathbf{z}_{1:T})=\frac{\prod p(\tilde{\mathbf{y}}_{t}\,|\,\mathbf{z}_{t})p_ {\theta}(\mathbf{z}_{1:T})}{p(\tilde{\mathbf{y}}_{1:T})}\] (10)

A benefit of this formulation, is that it inherently imposes the latent dependency structure of the generative model onto the amortized posterior. This parameterization, was introduced in Johnson et al. [20], where an important point highlighted, is that the Gaussian potentials can encode any arbitrary subset of observations; for example, \(p(\tilde{\mathbf{y}}_{t}\,|\,\mathbf{z}_{t})\) could be made to depend on \(\mathbf{y}_{t}\) alone, or even the entire dataset, \(\mathbf{y}_{1:T}\). Regardless of that particular design choice, the corresponding ELBO for the variational approximation of Eq. (10) is

\[\mathcal{L}(q)=\sum\mathbb{E}_{q_{t}}\left[\log p(\mathbf{y}_{t}\,|\,\mathbf{ z}_{t})\right]-\mathbb{E}_{q_{t}}\left[\log p(\tilde{\mathbf{y}}_{t}\,|\, \mathbf{z}_{t})\right]+\log p(\tilde{\mathbf{y}}_{1:T})\] (11)

For linear Gaussian latent dynamics, conjugate potentials could be efficiently integrated with the prior using exact message passing, yielding filtered and smoothed marginal statistics. The smoothed statistics can be used to evaluate the first two terms on the right-hand side, while the filtered statistics can be used to evaluate the final term, the log-marginal likelihood of the pseudo-observations.

However, this approach does not directly apply to nonlinear dynamical systems, where the variational posterior is no longer Gaussian. Since evaluating the smoothed marginals and the log-marginal likelihood of pseudo-observations relies on first obtaining the filtered marginals, a logical starting point is to develop a method for approximating these filtered marginals. To this end, we propose a differentiable approximate message passing algorithm specifically designed to compute filtered posterior statistics in models characterized by nonlinear latent dynamics and observations represented as Gaussian potentials. Building on this foundation, we then return to the subsequent challenges of efficiently computing smoothed posterior statistics and evaluating the ELBO.

**Differentiable nonlinear filtering.** Bayesian filtering is often conceptualized as a two step procedure [2]. In the _predict_ step, our belief of the latent state is integrated through the dynamics, yielding \(q(\mathbf{z}_{t}\,|\,\tilde{\mathbf{y}}_{1:t-1})=\int p_{\theta}(\mathbf{z}_ {t}\,|\,\mathbf{z}_{t-1})q(\mathbf{z}_{t-1}\,|\,\tilde{\mathbf{y}}_{1:t-1})\, \mathrm{d}\mathbf{z}_{t-1}\) (a.k.a. the predictive distribution). Then, applying Bayes' rule, \(q(\mathbf{z}_{t}\,|\,\tilde{\mathbf{y}}_{1:t})\propto p(\tilde{\mathbf{y}}_{t} \,|\,\mathbf{z}_{t})q(\mathbf{z}_{t}\,|\,\tilde{\mathbf{y}}_{1:t-1})\), we _update_ our belief. Evidently then, developing an approximate filtering algorithm that exploits the conjugacy of the pseudo observations can be recast as the problem: given an approximation \(\pi(\mathbf{z}_{t-1})\approx q(\mathbf{z}_{t-1}\,|\,\tilde{\mathbf{y}}_{1:t-1})\), find an approximation to the predictive distribution, \(\bar{\pi}(\mathbf{z}_{t})\approx q(\mathbf{z}_{t}\,|\,\tilde{\mathbf{y}}_{1: t-1})\). The recursion would continue forward by updating our belief analytically, setting \(\pi(\mathbf{z}_{t})\propto p(\tilde{\mathbf{y}}_{t}\,|\,\mathbf{z}_{t})\bar{ \pi}(\mathbf{z}_{t})\), then finding a Gaussian approximation of \(\bar{\pi}(\mathbf{z}_{t+1})\) and so forth.

With the problem restated this way, we propose an approximate filtering solution designed to exploit two key factors at play **i)** the approximate beliefs are constrained to the same exponential family as the latent state transitions **ii)** the pseudo observations are encoded as conjugate potentials. Our approach involves recursively solving intermediary variational problems (their fixed point solutions on the right),

\[\boxed{\begin{array}{rcl}\text{Variational filtering}&\xrightarrow{}\\ \text{(i)}&\bar{\pi}(\mathbf{z}_{t})=\operatorname{argmin}\,\,\mathbb{D}_{ \text{KL}}\big{(}\mathbb{E}_{\pi_{t-1}}\left[p_{\theta}(\mathbf{z}_{t}\,|\, \mathbf{z}_{t-1})\right]\big{|}\,\bar{\pi}(\mathbf{z}_{t})\big{)}&\Longrightarrow& \bar{\mu}_{t}=\mathbb{E}_{\pi_{t-1}}\left[\boldsymbol{\mu}_{\theta}(\mathbf{ z}_{t-1})\right]\end{array}}\] (12) \[\Rightarrow \quad\boldsymbol{\lambda}_{t}=\bar{\boldsymbol{\lambda}}_{t}+ \bar{\boldsymbol{\lambda}}_{t}\] (13)

Steps (i) and (ii) can be thought of as variational analogues of the predict/update steps of Bayesian filtering, and importantly, finding their fixed point solutions does not require an iterative procedure because of our problem specifications. Reassuringly, iterating (i) and (ii) in the case of an LDS generative model would exactly recover the information form Kalman filtering equations. In the case of nonlinear dynamical systems, directly taking the expectation in (i) is intractable. We can overcome this by employing the reparameterization trick to obtain a differentiable sample approximation of the parameters, \(\bar{\bm{\mu}}_{t}\), of the fixed point solution. Naturally now, the statistics of the approximate filtered beliefs can be used to approximate the log-marginal likelihood of the pseudo observations as,

\[\log p(\tilde{\mathbf{y}}_{1:T})=\sum\log\int p(\tilde{\mathbf{y}}_{t}\,|\, \mathbf{z}_{t})q(\mathbf{z}_{t}\,|\,\tilde{\mathbf{y}}_{1:t-1})\,\mathrm{d} \mathbf{z}_{t}\approx\sum\log\int p(\tilde{\mathbf{y}}_{t}\,|\,\mathbf{z}_{t} )\bar{\pi}(\mathbf{z}_{t})\,\mathrm{d}\mathbf{z}_{t}\] (14)

where the last integral can be evaluated analytically as a result of the Gaussian forms of the approximations and pseudo observations. While formulating step (ii) as a variational problem may appear superfluous given the conjugate structure, it hints at the possibility of approximating smoothed posterior marginal statistics within a variational framework. However, pursuing this idea further reveals significant challenges. Trying to develop a backward recursion for the distribution \(q_{t}\) minimizing \(\mathbb{D}_{\text{KL}}\!\left(\mathbb{E}_{q_{t+1}}[q_{t[t+1]}]\right|\!\big{|} \,q_{t}\right)\), by using the forward KL divergence (as in step (i)), leads to an intractable problem because the backward Markov transitions, \(q_{t[t+1]}\), are not conditionally Gaussian. Conversely, a fixed point solution of the reverse KL objective (as in step(ii)), \(\mathbb{D}_{\text{KL}}\!\left(q_{t}\big{|}\,\big{|}\,\mathbb{E}_{q_{t+1}}[q_{ t[t+1]}]\right)\), necessitates an iterative procedure, which can be computationally expensive.

**Smoothing as filtering.** In light of these difficulties, we offer a simple solution that exploits the flexibility in choosing the pseudo observation data dependence: define the parameters, \(\mathbf{k}_{t}\) and \(\mathbf{K}_{t}\), of each pseudo observation, \(\tilde{\mathbf{y}}_{t}\), to be a function of current _and_ future data, \(\mathbf{y}_{t:T}\), so that,

\[p(\tilde{\mathbf{y}}_{t}\,|\,\mathbf{z}_{t})\propto\exp(\tilde{\bm{\lambda}}_ {\bm{\phi}}(\mathbf{y}_{t:T})^{\top}\mathcal{T}(\mathbf{z}_{t}))\] (15)

With this choice, filtered statistics of the latent state--relative to the pseudo-observations--can be used to approximate posterior smoothed marginals, i.e. \(\pi(\mathbf{z}_{t})\approx q(\mathbf{z}_{t}\,|\,\tilde{\mathbf{y}}_{1:t}) \approx p(\mathbf{z}_{t}\,|\,\mathbf{y}_{1:T})\). This solution circumvents the challenges associated with backward message computation and only requires a single pass through the pseudo observations to obtain approximate smoothed posterior statistics. Substituting, \(\pi_{t}\), as an approximation to \(q_{t}\), in Eq. (11), leads to the following approximation of the ELBO.

\[\boxed{\hat{\mathcal{L}}(\pi)=\sum\mathbb{E}_{\pi_{t}}\left[\log p (\mathbf{y}_{t}\,|\,\mathbf{z}_{t})\right]-\mathbb{E}_{\pi_{t}}\left[\log p( \tilde{\mathbf{y}}_{t}\,|\,\mathbf{z}_{t})\right]+\log\mathbb{E}_{\pi_{t}} \left[p(\tilde{\mathbf{y}}_{t}\,|\,\mathbf{z}_{t})\right]}\] (16) \[=\sum\mathbb{E}_{\pi_{t}}\left[\log p(\mathbf{y}_{t}\,|\,\mathbf{ z}_{t})\right]-\mathbb{D}_{\text{KL}}(\pi(\mathbf{z}_{t}))\|\,\bar{\pi}( \mathbf{z}_{t}))\] (17)

By expressing the approximate ELBO compactly as Eq.(17), we highlight that it promotes learning models where the posterior at time \(t\) aligns closely with the one-step posterior predictive at that time (which depends on the generative model and the posterior at time \(t-1\)). The KL term in Eq.(17) can be evaluated in closed form, while the expected log-likelihood term can be approximated using the reparameterization trick[4]. However, a point of practical importance should be raised now: every filtering step and evaluation of the KL term has a time complexity of \(\mathcal{O}(L^{3})\), which may become a bottleneck for large \(L\). In the following discussion, we will explore effective strategies to parameterize the Gaussian potential inference network that produces \(\tilde{\bm{\lambda}}_{1:T}\), to reduce the computational burden that filtering and evaluating \(\hat{\mathcal{L}}(\pi)\) pose in the large \(L\) regime.

**Local and backward encoders.** For state-space models, inferences about the latent state should be possible even with missing observations. To enable the amortized inference network to process missing observations in a principled way, we decompose the natural parameter update into two additive components: **i)** a _local_ encoder, \(\bm{\alpha}_{\bm{\phi}}(\cdot)\), for current observation, and **ii)** a _backward_ encoder, \(\bm{\beta}_{\bm{\phi}}(\cdot)\), for future observations, i.e.,

\[\tilde{\bm{\lambda}}_{\bm{\phi}}(\mathbf{y}_{t:T})=\bm{\alpha}_{\bm{\phi}}( \mathbf{y}_{t})+\bm{\beta}_{\bm{\phi}}(\mathbf{y}_{t+1:T})\quad\text{(or for the sake of brevity)}\quad\tilde{\bm{\lambda}}_{t}=\bm{\alpha}_{t}+\bm{\beta}_{t+1}\] (18)

Furthermore, by building the dependence of \(\bm{\beta}_{\bm{\phi}}(\cdot)\) on \(\mathbf{y}_{t+1:T}\) through their representation as \(\bm{\alpha}_{t+1:T}\), so that \(\bm{\beta}_{\bm{\phi}}(\mathbf{y}_{t+1:T})=\bm{\beta}_{\bm{\phi}}(\bm{\alpha}_ {t+1:T})\), a missing observation at time \(t\) is handled by setting \(\bm{\alpha}_{t}=\bm{0}\). While a data dependent natural parameter update of \(\bm{0}\) faithfully represents a missing observation - in the absence of data, the prior should not be updated - alternatively setting \(\mathbf{y}_{t}=\bm{0}\) would introduce a harmful inductive bias into the inference network, since an observation of \(\bm{0}\) can be arbitrarily informative. Given the impracticality of \(\mathcal{O}(TL^{2})\) memory requirements, it is appealing to consider a low-rank parameterization for the local and backward encoders - we consider

\[\bm{\alpha}_{t}=\begin{pmatrix}\mathbf{a}_{t}\\ \mathbf{A}_{t}\mathbf{A}_{t}^{\top}\end{pmatrix}\coloneqq\begin{pmatrix} \mathbf{a}(\mathbf{y}_{t})\\ \mathbf{A}(\mathbf{y}_{t})\mathbf{A}(\mathbf{y}_{t})^{\top}\end{pmatrix}\quad \bm{\beta}_{t}=\begin{pmatrix}\mathbf{b}_{t}\\ \mathbf{B}_{t}\mathbf{B}_{t}^{\top}\end{pmatrix}\coloneqq\begin{pmatrix} \mathbf{b}(\bm{\alpha}_{t:T})\\ \mathbf{B}(\bm{\alpha}_{t:T})\mathbf{B}(\bm{\alpha}_{t:T})^{\top}\end{pmatrix}\] (19)where \(\mathbf{A}_{t}\in\mathbb{R}^{L\times r_{\alpha}}\) with \(\mathbf{B}_{t}\in\mathbb{R}^{L\times r_{\beta}}\) parameterize low-rank local/backward precision updates, and \(\mathbf{a}_{t}\in\mathbb{R}^{L}\) with \(\mathbf{b}_{t}\in\mathbb{R}^{L}\) parameterize local/backward precision-scaled mean updates. Using these descriptions and the additive decomposition (18), the parameters of a single pseudo observation are,

\[\tilde{\bm{\lambda}}_{t}=\begin{pmatrix}\mathbf{k}_{t}\\ \mathbf{K}_{t}\mathbf{K}_{t}^{\top}\end{pmatrix}\coloneqq\begin{pmatrix} \mathbf{k}(\mathbf{y}_{t:T})\\ \mathbf{K}(\mathbf{y}_{t:T})\mathbf{K}(\mathbf{y}_{t:T})^{\top}\end{pmatrix}= \begin{pmatrix}\mathbf{a}_{t}+\mathbf{b}_{t}\\ \left[\mathbf{A}_{t}\;\mathbf{B}_{t}\right]\left[\mathbf{A}_{t}\;\mathbf{B}_{ t}\right]^{\top}\end{pmatrix}\] (20)

where \(\mathbf{K}\in\mathbb{R}^{L\times r}\) if \(r=r_{\alpha}+r_{\beta}\) and \(\mathbf{k}\in\mathbb{R}^{L}\). The low-rank structure of the natural parameter updates will be a key component to develop an efficient approximate message passing algorithm for obtaining sufficient statistics of the approximate posterior and evaluating the ELBO. Analogous to the inference network description (8), a differentiable architecture producing \(\bm{\alpha}_{1:T}\) and \(\bm{\beta}_{1:T}\) could be,

\[\bm{\alpha}_{t}=\text{NN}(\mathbf{y}_{t}) \bm{\beta}_{t}=\text{S2S}([\bm{\beta}_{t+1},\bm{\alpha}_{t}]),\] (21)

which overall defines the map \(\mathbf{y}_{1:T}\mapsto(\bm{\alpha}_{1:T},\bm{\beta}_{1:T})\). In addition, the separation of local and backward encoders can reduce the complexity of the backward encoder for \(L<N\). Those familiar with sequential Monte-Carlo (SMC) methods [22] can view the backward encoder similar to twisting functions used to combine future information with filtered state beliefs to produce smoothing approximations [23, 24].

**Exploiting structure for efficient filtering.** A benefit of using the forward KL to design a variational analogue to the exact Bayesian predict step is immediate access to the fixed point solution. While nonlinear specification of the latent dynamical system make the expectation of Eq. (12) intractable, using the reparameterization trick with \(\mathbf{z}_{t-1}^{s}\sim\pi(\mathbf{z}_{t-1})\), gives the approximation,

\[\bar{\bm{\mu}}_{t}=\nicefrac{{1}}{{S}}\sum\nolimits_{s=1}^{S} \left[-\frac{1}{2}\begin{pmatrix}\mathbf{m}_{\bm{\theta}}(\mathbf{z}_{t-1}^{s })\mathbf{m}_{\bm{\theta}}(\mathbf{z}_{t-1}^{s})^{\top}+\mathbf{Q}_{\bm{ \theta}}\end{pmatrix}\right]\] (22)

where \(S\) is the total number of samples. Converting this finite sample estimate from mean parameter coordinates to a mean/covariance representation, we get that,

\[\bar{\mathbf{m}}_{t}=\nicefrac{{1}}{{S}}\sum\nolimits_{s=1}^{S} \mathbf{m}_{\bm{\theta}}(\mathbf{z}_{t-1}^{s}) \bar{\mathbf{P}}_{t}=\bar{\mathbf{M}}_{t}^{c}\bar{\mathbf{M}}_{t}^{ c\top}+\mathbf{Q}_{\bm{\theta}}\] (23)

where \(\bar{\mathbf{M}}_{t}^{c}\) is the \(L\times S\) matrix of samples passed through the dynamics function, then centered by the mean, defined for convenience as,

\[\bar{\mathbf{M}}_{t}^{c}=\nicefrac{{1}}{{\sqrt{S}}}\left[\mathbf{m}_{\bm{ \theta}}(\mathbf{z}_{t-1}^{1})-\bar{\mathbf{m}}_{t},\cdots,\mathbf{m}_{\bm{ \theta}}(\mathbf{z}_{t-1}^{S})-\bar{\mathbf{m}}_{t}\right]\in\mathbb{R}^{L\times S}\] (24)

Writing the covariance estimate as it is in Eq. (23), reveals that it can alternatively be represented by the pair \((\bar{\mathbf{M}}_{t}^{c},\mathbf{Q}_{\bm{\theta}})\). In the regime where \(L>S\), significant computational savings can be afforded by capitalizing on the low-rank structure of the covariance as estimated via the reparameterization trick. This structure can be exploited for efficient linear algebraic operations involving \(\bar{\mathbf{P}}_{t}\) (and its inverse, after application of the Woodbury identity). Consequently, the natural parameters of \(\pi_{t}\), after updating \(\bar{\pi}_{t}\), are

\[\mathbf{P}_{t}^{-1}\mathbf{m}_{t}=\bar{\mathbf{P}}_{t}^{-1}\bar{ \mathbf{m}}_{t}+\mathbf{k}_{t} \mathbf{P}_{t}^{-1}=\bar{\mathbf{P}}_{t}^{-1}+\mathbf{K}_{t}\mathbf{K}_{t}^ {\top}\] (25)

Figure 1: **Smoothing and predictive performance on bouncing ball and pendulum.** To the left of the red line are samples from the posterior during the data window projected to image space, to the right of the red line are samples unrolled from \(p_{\bm{\theta}}(\mathbf{z}_{t}\,|\,\mathbf{z}_{t-1})\). **a)** while all methods are adept at smoothing in the context window, our methods predictive performance is better by a noticeable margin as measured by the \(R^{2}\). **b)** similar results hold for the bouncing ball dataset.

and also admit structured representations. Without _both_ the sample approximation structure (during the variational predict step) and low-rank parameterization (during the variational update step), the cost of approximate filtering each time-step would be dominated by an \(\mathcal{O}(L^{3})\) cost. Instead, recognizing the potential computational advantages of exploiting these structures, and never instantiating the predictive/updated covariance and precision matrices, makes it possible to develop an approximate filtering algorithm, where in the case \(L\) is significantly larger than \(S\) or \(r\), has complexity of \(\mathcal{O}(L(Sr+r^{2}+S^{2}))\) per step. More details regarding time complexity are in App. B.5.

**Efficient sampling and ELBO evaluation.** When \(\mathbb{E}_{\pi_{t}}\left[\log p(\mathbf{y}_{t}\,|\,\mathbf{z}_{t})\right]\) can not be evaluated in closed form, Monte-Carlo integration can be used as a differentiable approximation. To sample from \(\pi(\mathbf{z}_{t})\) without explicitly constructing \(\mathbf{P}_{t}\), we can take \(\mathbf{\bar{z}}_{t}^{s}\sim\mathcal{N}(\mathbf{0},\mathbf{\bar{P}}_{t})\) and \(\mathbf{w}_{t}^{s}\sim\mathcal{N}(\mathbf{0},\mathbf{I}_{L+S})\) and set,

\[\mathbf{z}_{t}^{s}=\mathbf{m}_{t}+\mathbf{\bar{z}}_{t}^{s}-\mathbf{K}_{t} \,\mathbf{\Upsilon}_{t}\,\mathbf{\Upsilon}_{t}^{\top}(\mathbf{K}_{t}^{\top} \mathbf{\bar{z}}_{t}^{s}+\mathbf{w}_{t}^{s}).\] (26)

While more details are provided in App. B.4, this can be done efficiently since samples can be drawn cheaply from \(\bar{\pi}(\mathbf{z}_{t})\) using Eq. (23). Whereas Monte-Carlo approximations of the expected log-likelihood term might be unavoidable, the closed form solution for the KL between two Gaussian distributions should be used to avoid further stochastic approximations. The only difficulty, is that the time complexity of naively evaluating the KL term,

\[\mathbb{D}_{\text{KL}}(\pi(\mathbf{z}_{t})||\,\bar{\pi}(\mathbf{z}_{t}))= \tfrac{1}{2}\big{[}(\bar{\mathbf{m}}_{t}-\mathbf{m}_{t})^{\top}\bar{\mathbf{ P}}_{t}^{-1}(\bar{\mathbf{m}}_{t}-\mathbf{m}_{t})+\text{tr}(\bar{\mathbf{P}}_{t}^ {-1}\mathbf{P}_{t})+\log(|\bar{\mathbf{P}}_{t}|/|\mathbf{P}_{t}|)-L\big{]}\] (27)

scales \(\mathcal{O}(L^{3})\). However, since matrix vector multiplies with \(\bar{\mathbf{P}}_{t}^{-1}\) can be performed efficiently and the trace/log-determinant terms can be rewritten using the square-root factors acquired during the forward pass, as we describe in App. C.1, it is possible to evaluate the KL in \(\mathcal{O}(LSr+LS^{2}+Lr^{2})\) time. After a complete forward pass through the encoded data, we acquire the samples \(\mathbf{z}_{1:T}^{1:S}\) and all necessary quantities for efficient ELBO evaluation. We detail the variational filtering algorithm in Alg. 2 in App. C.2 and the complete end-to-end learning procedure in Alg. 1.

Causal amortized inference for streaming data.In constructing a fully differentiable variational approximation, the parameters of the approximate marginals were effectively amortized according to a recursion in the natural parameter space by iterating Eqs. (12) and (13). This recursion can be recognized more easily by introducing the function, \(\mathbf{\bar{\gamma}}_{\boldsymbol{\theta}}(\cdot)\), and writing

\[\boldsymbol{\lambda}_{t}=\mathbf{\bar{\gamma}}_{\boldsymbol{\theta}}( \boldsymbol{\lambda}_{t-1})+\boldsymbol{\alpha}_{t}+\boldsymbol{\beta}_{t+1} \text{ with }\mathbf{\bar{\gamma}}_{\boldsymbol{\theta}}(\boldsymbol{\lambda}_{t-1})= \nabla A^{*}\left(\int\pi(\mathbf{z}_{t-1};\boldsymbol{\lambda}_{t-1}) \boldsymbol{\mu}_{\boldsymbol{\theta}}(\mathbf{z}_{t-1})\,\mathrm{d}\mathbf{z }_{t-1}\right)\] (28)

Figure 2: **a)** Empirical time complexity scaling. Since complexity is a function of \(L\), \(S\), and \(r\), we vary \(L\) (top) for fixed \(r=10\) and (bottom) for fixed \(S=5\); we examine several values of the variable not fixed. Examining wall-clock time shows empirically our implementation scales linearly in \(L\); on the (bottom) we plot wall-clock time for a Kalman filter implementation, showing the standard cubic dependence on \(L\). **b)** (top) Negative ELBO as a function of training epoch when \(N=L\) (bottom) when \(N=L/5\); the left column shows the case \(L=50\) and the right when \(L=100\). Different colors indicate different settings of the local/backward encoder rank; zooming in for \(L=100\), shows low-rank updates can match diagonal ones. **c)** Persitimulus time histogram (PSTH) for the DMFC RSG dataset for different trial condition averages; we consider a context window of \(1.3\)s and a prediction window of \(1.3\)s. **d)** BPS for each method for context/prediction windows.

\(\nabla A^{*}:(\mathbf{m},-\frac{1}{2}(\mathbf{P}+\mathbf{mm}^{\top}))\mapsto( \mathbf{P}^{-1}\mathbf{m},\mathbf{P}^{-1})\), and \(A^{*}(\cdot)\) is the convex conjugate of the log-partition function [12]. So that, \(\mathfrak{F}_{\boldsymbol{\theta}}(\cdot)\) can be thought of as mapping \(\boldsymbol{\lambda}_{t-1}\) forward in time by first taking the expectation of (4) with respect to \(\pi(\mathbf{z}_{t-1};\boldsymbol{\lambda}_{t-1})\), and then applying the mean-to-natural coordinate transformation.

One limitation of amortizing inference through the recursion (28) is its inability to produce approximations for the filtering distributions, \(p(\mathbf{z}_{t}\,|\,\mathbf{y}_{1:t})\), which can be valuable in streaming or online settings, as well as for testing hypotheses of causality. However, since (17) only depends on the posterior and posterior predictive marginal statistics, we have the freedom to alter our inference network in a way such that filtered marginal statistics are a by-product of obtaining smoothed marginal statistics. For example, an alternative sequence-to-sequence map for \(\boldsymbol{\lambda}_{t}\) could be defined by,

\[\boldsymbol{\lambda}_{t}=\mathfrak{F}_{\boldsymbol{\theta}}(\boldsymbol{ \lambda}_{t-1}-\boldsymbol{\beta}_{t})+\boldsymbol{\alpha}_{t}+\boldsymbol{ \beta}_{t+1},\] (29)

so that \(\check{\boldsymbol{\lambda}}_{t}\equiv\boldsymbol{\lambda}_{t}-\boldsymbol{ \beta}_{t+1}\) obey the recursion \(\check{\boldsymbol{\lambda}}_{t}=\mathfrak{F}_{\boldsymbol{\theta}}(\check{ \boldsymbol{\lambda}}_{t-1})+\boldsymbol{\alpha}_{t}\) and are natural parameters of an approximate filtering distribution, \(\check{\pi}(\mathbf{z}_{t})\approx p(\mathbf{z}_{t}\,|\,\,\mathbf{y}_{1:t})\). Consequently the approximations to posterior and predictive distributions will have a more complicated relationship than they previously did; while efficient sampling and ELBO evaluation are more intricate as a result - linear time scaling in the state-dimension can still be achieved with additional algebraic manipulations, as we show in App. C.2.

``` Input:\(\mathbf{y}_{1:T}\) while not converged do for\(t=T\) to 1 do \(\boldsymbol{\alpha}_{t}=\text{NN}(\mathbf{y}_{t})\) # local encoder \(\boldsymbol{\beta}_{t}=\text{S2S}([\boldsymbol{\beta}_{t+1}\,\,\boldsymbol{ \alpha}_{t}])\) # backward encoder \(\mathbf{k}_{t}=\mathbf{a}_{t}+\mathbf{b}_{t}\) \(\mathbf{K}_{t}=[\mathbf{A}_{t}\,\,\mathbf{B}_{t}]\) endfor \(\mathbf{z}_{1:T}^{1:S},\mathbf{m}_{1:T},\mathbf{\check{m}}_{1:T},\mathbf{ \check{\boldsymbol{\Upsilon}}}_{1:T}=\text{Alg.}\,2(\mathbf{k}_{1:T},\mathbf{ K}_{1:T})\) \(\check{\mathcal{L}}(\pi)=\sum[S^{-1}\sum\log p(\mathbf{y}_{t}\,|\,\mathbf{z}_{t}^{*} )-\mathcal{D}_{\text{KL}}(\pi_{t}||\,\bar{\pi}_{t})]\) \((\boldsymbol{\phi},\boldsymbol{\theta},\boldsymbol{\psi})\leftarrow( \boldsymbol{\phi},\boldsymbol{\theta},\boldsymbol{\psi})-\nabla\check{\mathcal{ L}}(\pi)\) endwhile Output:\(\mathbf{z}_{1:T}^{1:S},\,\mathbf{m}_{1:T},\,\mathbf{\check{m}}_{1:T}\), \(\mathbf{\check{\boldsymbol{\Upsilon}}}_{1:T}\) ```

**Algorithm 1** End-to-end learning

## 5 Experiments

Time complexity & low-rank precision updates.We first investigated the properties of low-rank variational Gaussian approximations in the large \(L\) regime. To guide us, we had several questions in mind such as: i) how does the performance of low-rank approximations compare to full-rank and diagonal covariance approximations, ii) how large compared to \(L\) should the rank of precision updates be to achieve satisfactory results, and iii) how does convergence using low-rank approximations compare to diagonal approximations, considering that they require a larger number of parameters. We expect that full-rank approximations would perform best (given a sufficient amount of data), since the true posterior will have dense second-order statistics due to the interactions of latent states in both the dynamics and observation models. However, it remains unclear how many dimensions are necessary for a low-rank approximation to achieve similar performance and whether this number will be practical.

We simulated data from \(50\)D and \(100\)D linear dynamical systems and compared the convergence between dense and diagonal approximations (Fig. 2**b**); we examined the ELBO for different rank parameterizations in two regimes i) observations and states are of the same dimensionality, \(N=L\) (Fig. 2**b** - top), and ii) observations are lower dimensional than states, \(N=L/5\) (Fig. 2**b** - bottom). While not surprising that dense variational Gaussian approximations achieve superior performance, message passing in latent Gaussian models with dense covariance scales like \(\mathcal{O}(L^{3})\)[25] and becomes prohibitive for large \(L\); thus it is reassuring that in both regimes, low-rank approximate posterior parameterizations achieve comparable results for precision matrix updates of relatively low rank compared to \(L\). To empirically examine time complexity scaling as a function of \(L\), \(S\), and \(r\), in Fig. 2**a**, we plot wall-clock times for fixed \(r\) while varying \(S\) and \(L\) (bottom), and for fixed \(S\) while varying \(r\) and \(L\) (top); reassuringly, inference time complexity scales \(\mathcal{O}(L)\).

Baseline comparisons - pendulum & bouncing ball.Next, we wondered how our approach fared against other modern deep state-space models when it came to learning complex dynamical systems from data. To explore this, we considered two popular datasets: **i)** a pendulum system [26] and **ii)** a bouncing ball [27, 28]. Each dataset consists of sequences of observations that are \(16\times 16\) pixel images that are governed by a low-dimensional dynamical system. An interesting aspect of these datasets is that images can be reconstructed with impartial knowledge of the latent state, but for accurate long-term predictions, the dynamics will need to propagate features of the latent state that are irrelevant to the likelihood (e.g. pendulum angular velocity). For benchmarks, three other deep SSM approaches were included: **i)** deep variational Bayes filter(DVBF) [5]**ii)** deep Kalman filter(DKF) [29]**iii)** structured VAE(SVAE) [20]. We denote our causal amortization network with (c) and the noncausal version with (n).

We trained all models in context windows of \(50\) consecutive images and then sampled future \(50\) / \(25\) time-step latent states from the learned dynamical system for pendulum / bouncing ball. To measure quality of learned latent representation and dynamics, we fit angular velocity / position decoders from training set latent states inferred from pendulum / bouncing ball observations. Then, on held-out test data, we measured the \(R^{2}\) of velocity / position predictions during the context (smoothing) and forecast (prediction) windows. Fig. 1 shows that all methods are able to reconstruct well in context windows, however, when prediction is concerned, where the underlying dynamics would need to be learned well for accurate forecasts, our method consistently performs better.

Neural population dynamics.We consider two neuroscientific datasets where previous studies have shown the importance of population dynamics in generating plausible hypothesis about underlying neural computation. In addition to DKF, DVBF, and SVAE, we include the LFADS method [7]. First, we considered recordings from motor cortex of a monkey performing a reaching task [30] and evaluate each methods' ability to forecast neural spiking and behavioral correlates. We measure the performance by bits-per-spike (BPS) using inferred spike-train rates [31] and \(R^{2}\) for decoding hand velocity. Similar to the previous experiment, we evaluate the performance in two regimes: **i)** a \(700\)ms context window and **ii)** a \(500\)ms prediction window following an initial context window of \(200\)ms. Fig. 3**c** shows that, while all the methods excel at smoothing in the context window, our method makes more informative

Figure 3: **Predict behavior from a causally inferred initial condition.****a)** Actual reaches. **b)** (top) Reaches linearly decoded from smoothed (\(R^{2}=0.89\)), causally filtered (\(R^{2}=0.88\)), & predicted (\(R^{2}=0.74\)) latent trajectories starting from an initial condition causally inferred during the preparatory period. (bottom) Top 3 principal latent dimensions per regime (smoothing/filtering/prediction) for three example trials. **c)** bps / \(R^{2}\) of predicted hand velocity using rates inferred from the \(700\)ms context window and the \(500\)ms prediction window. **d)** Velocity decoding \(R^{2}\) using predicted trajectories as a function of how far into the trial the latent state was filtered until it was only sampled from the autonomous dynamics; by the the movement onset, behavioral predictions using latent trajectory predictions are nearly on par with behavior decoded from the smoothed posterior.

predictions in terms of \(R^{2}\) and BPS. Next, we examined how well the monkey's behavior could be predicted given only causal estimates of the latent state; we trained a model using the causal amortized inference network, given by Eq. (29), then use learned inference network to infer latent states to predict behavior in three regimes: smoothing, filtering, and prediction. Fig. 3**b** shows that hand velocity can be decoded nearly as well in the filtering regime (without access to future data) as in the smoothing regime. In Fig. 3**d**, we plot how the quality of predictions change as filtered latent states are unrolled through the learned dynamics at different points in the trial; showing that forecasts starting prior to movement onset exhibit strong predictive capability.

Next, we investigated our method's performance with data exhibiting a more intricate trial structure. Specifically, we analyzed physiological recordings from the DMFC region of a monkey engaged in a timing interval reproduction task [32]. During this task, the monkey observes a random interval of time (termed the'ready'-'set' period) demarcated by two cues, and the goal of the monkey is to reproduce that interval (termed the'set'-'go' period). We perform a similar procedure as before, but for this experiment we use the period before'set' as the context window, and use the learned dynamics to make predictions onward; in Fig. 2**d** we show the BPS measured on test data during the context and forecast windows. To further investigate the predictive capabilities, we examined condition averaged PSTH produced by samples from the latent state posterior during the joint context/prediction windows. Using the trained model, we sample spike valued observations for the context/prediction windows and then computed condition averaged PSTHs; the results shown in Fig. 2**c**, show that PSTHs sampled from the model remain true to the data, even during the lengthy prediction window.

## 6 Discussion

We presented a new approximate variational filtering/smoothing algorithm, variational learning objective, and Gaussian inference network parameterization for nonlinear state-space models. Focusing on approximations parameterized by dense covariances forced us to consider strategies that ensured computational feasibility for inference and learning with large \(L\). The introduced approximate variational filtering algorithm, while especially useful for the nonlinear dynamics we considered, could also be applied to high-dimensional linear systems where exact computations might be infeasible for large \(L\). Although our variational objective loses the property of lower-bounding the original data log-marginal likelihood, experiments showed that our method consistently outperforms approaches using potentially tight lower bounds. Quantifying this gap or considering potential corrections present interesting directions for future work. Furthermore, while the same variational approach is applicable to any exponential family dynamical system, specific distributions will have their own associated challenges, offering avenues for further research.

Given that neural computation is inherently nonlinear, system identification methods capable of modeling nonlinear dynamical systems are essential for advancing neuroscience. General SSMs can perform well on inferring smoothed latent state trajectories _without_ learning a good model of the nonlinear dynamics. Our proposed method, XFADS, can not only perform efficient system identification and smoothing but also forecast future state evolution for population recordings--a hallmark of a meaningful nonlinear dynamical model; using a causal inference network, XFADS can be used for real-time monitoring, feedback control, and online optimal experimental design, opening the door for new kinds of basic and clinical neuroscience experiments. Future work will focus on developing network architectures for precision matrix updates that are more parameter efficient when the rank those updates become moderate. Moreover, while Alg. 1 remains applicable in the confines of the generative model constraints considered, in certain scenarios, such as when \(S>L\), modifications will need to be made to Alg. 2 to minimize time complexity.

## Acknowledgements

We would like to thank the anonymous reviewers and Scott Linderman for their insightful comments and constructive feedback, which greatly improved the quality of this paper. We thank Mahmoud Elmakki for help with organizing the code base and developing helpful demos. Yuan Zhao was supported in part by the National Institute of Mental Health Intramural Research Program (ZIC-MH002968). This work was supported by NIH RF1-DA056404 and the Portuguese Recovery and Resilience Plan (PPR), through project number 62, Center for Responsible AI, and the Portuguese national funds, through FCT - Fundacao para a Ciencia e a Tecnologia - in the context of the project UIDB/04443/2020.

## References

* Kailath et al. [2000] Kailath, T., Sayed, A. H. & Hassibi, B. _Linear estimation_. Prentice Hall, 2000.
* Sarkka [2013] Sarkka, S. _Bayesian filtering and smoothing_. Cambridge University Press, 2013. ISBN 9781107619289.
* Anderson & Moore [1979] Anderson, B. D. O. & Moore, J. B. _Optimal Filtering_. Prentice-Hall, Englewood Cliffs, N.J., 1979. ISBN 978-0-13-638122-8.
* Kingma & Welling [2014] Kingma, D. P. & Welling, M. Auto-Encoding variational bayes. In _International Conference on Learning Representation_, May 2014.
* Karl et al. [2017] Karl, M., Soelch, M., Bayer, J. & Smagt, P.van der. Deep variational Bayes filters: Unsupervised learning of state space models from raw data. In _International Conference on Learning Representations_, 2017.
* Krishnan et al. [2016] Krishnan, R. G., Shalit, U. & Sontag, D. A. Structured inference networks for nonlinear state space models. In _AAAI Conference on Artificial Intelligence_, 2016.
* Pandarinath et al. [2018] Pandarinath, C., O'Shea, D. J., Collins, J., Jozefowicz, R., Stavisky, S. D., Kao, J. C., Trautmann, E. M., Kaufman, M. T., Ryu, S. I., Hochberg, L. R. & others,. Inferring single-trial neural population dynamics using sequential auto-encoders. _Nature methods_, 15(10):805-815, 2018.
* Van Overschee & De Moor [1996] Van Overschee, P. & De Moor, B. _Subspace identification for linear systems_. Springer US, Boston, MA, 1996. ISBN 9781461380610,9781461304654.
* Turner & Sahani [2011] Turner, R. E. & Sahani, M. Two problems with variational expectation maximisation for time-series models. In Barber, D., Cemgil, T. & Chiappa, S., editors, _Bayesian Time series models_, chapter 5, pages 109-130. Cambridge University Press, 2011.
* Kingma & Ba [2014] Kingma, D. P. & Ba, J. Adam: A method for stochastic optimization. _arXiv preprint arXiv:1412.6980_, 2014.
* Rezende et al. [2014] Rezende, D. J., Mohamed, S. & Wierstra, D. Stochastic backpropagation and approximate inference in deep generative models. In _International conference on machine learning_, pages 1278-1286. PMLR, 2014.
* Wainwright & Jordan [2008] Wainwright, M. J. & Jordan, M. I. Graphical models, exponential families, and variational inference. _Foundations and Trends in Machine Learning_, 1(1-2):1-305, 2008.
* Diaconis & Ylvisaker [1979] Diaconis, P. & Ylvisaker, D. Conjugate priors for exponential families. _The Annals of statistics_, pages 269-281, 1979.
* Seeger [2005] Seeger, M. Expectation propagation for exponential families. Technical report, University of California at Berkeley, 2005.
* Khan & Lin [2017] Khan, M. & Lin, W. Conjugate-Computation Variational Inference : Converting Variational Inference in Non-Conjugate Models to Inferences in Conjugate Models. In Singh, A. & Zhu, J., editors, _Proceedings of the 20th International Conference on Artificial Intelligence and Statistics_, volume 54 of _Proceedings of Machine Learning Research_, pages 878-887. PMLR, 20-22 Apr 2017.
* Beal [2003] Beal, M. J. _Variational algorithms for approximate Bayesian inference_. University of London, University College London (United Kingdom), 2003.
* Alaa & Schaar [2019] Alaa, A. M. & Schaar, M.van der. Attentive state-space modeling of disease progression. _Advances in neural information processing systems_, 32, 2019.
* Girin et al. [2020] Girin, L., Leglaive, S., Bie, X., Diard, J., Hueber, T. & Alameda-Pineda, X. Dynamical variational autoencoders: A comprehensive review. _arXiv preprint arXiv:2008.12595_, 2020.
* Hafner et al. [2019] Hafner, D., Lillicrap, T., Fischer, I., Villegas, R., Ha, D., Lee, H. & Davidson, J. Learning latent dynamics for planning from pixels. In _International conference on machine learning_, pages 2555-2565. PMLR, 2019.
* Johnson et al. [2016] Johnson, M. J., Duvenaud, D., Wiltschko, A. B., Datta, S. R. & Adams, R. P. Structured VAEs: Composing probabilistic graphical models and variational autoencoders. _arXiv preprint arXiv:1603.06277_, 2:2016, 2016.
* Zhao & Linderman [2023] Zhao, Y. & Linderman, S. Revisiting structured variational autoencoders. In _International Conference on Machine Learning_, pages 42046-42057. PMLR, 2023.

* [22] Douc, R., Moulines, E. & Stoffer, D. _Nonlinear time series: theory, methods and applications with R examples_. CRC press, 2014.
* [23] Whiteley, N. & Lee, A. Twisted particle filters. 2014.
* [24] Lawson, D., Raventos, A., Warrington, A. & Linderman, S. Sixo: Smoothing inference with twisted objectives. _Advances in Neural Information Processing Systems_, 35:38844-38858, 2022.
* [25] Cseke, B. & Heskes, T. Approximate marginals in latent gaussian models. _The Journal of Machine Learning Research_, 12:417-454, 2011.
* [26] Botev, A., Jaegle, A., Wirnsberger, P., Hennes, D. & Higgins, I. Which priors matter? Benchmarking models for learning latent dynamics. _arXiv preprint arXiv:2111.05458_, 2021.
* [27] Jiang, X., Missel, R., Li, Z. & Wang, L. Sequential latent variable models for few-shot high-dimensional time-series forecasting. In _The Eleventh International Conference on Learning Representations_.
* [28] Missel, R. Torch-Neural-SSM. https://github.com/qu-gg/torchsm, 2022.
* [29] Krishnan, R. G., Shalit, U. & Sontag, D. Deep Kalman filters. _arXiv preprint arXiv:1511.05121_, 2015.
* [30] Churchland, M. M., Cunningham, J. P., Kaufman, M. T., Foster, J. D., Nuyujukian, P., Ryu, S. I. & Shenoy, K. V. Neural population dynamics during reaching. _Nature_, 487(7405):51-56, 2012.
* [31] Pei, F., Ye, J., Zoltowski, D. M., Wu, A., Chowdhury, R. H., Sohn, H., O'Doherty, J. E., Shenoy, K. V., Kaufman, M. T., Churchland, M., Jazayeri, M., Miller, L. E., Pillow, J., Park, I. M., Dyer, E. L. & Pandarinath, C. Neural latents benchmark '21: evaluating latent variable models of neural population activity. In _Advances in Neural Information Processing Systems (NeurIPS), Track on Datasets and Benchmarks_, 2021.
* [32] Sohn, H., Narain, D. & Jazayeri, N. M. M. Bayesian computation through cortical latent dynamics. _Neuron_, 103(5):934-947, sep 2019.
* [33] Khan, M. E. & Rue, H. The bayesian learning rule. _arXiv preprint arXiv:2107.04562_, 2021.
* [34] Cong, Y., Chen, B. & Zhou, M. Fast simulation of hyperplane-truncated multivariate normal distributions. 2017.
* [35] Elfwing, S., Uchibe, E. & Doya, K. Sigmoid-weighted linear units for neural network function approximation in reinforcement learning. _Neural Networks_, 107:3-11, 2018.
* [36] Jiang, X., Missel, R., Li, Z. & Wang, L. Sequential latent variable models for few-shot high-dimensional time-series forecasting. In _The Eleventh International Conference on Learning Representations_, 2023.
* [37] Li, X., Wong, T.-K. L., Chen, R. T. & Duvenaud, D. Scalable gradients for stochastic differential equations. In _International Conference on Artificial Intelligence and Statistics_, pages 3870-3882. PMLR, 2020.

###### Contents

* A Nomenclature
* B Variational filtering
* B.1 Variational predict step
* B.2 Variational update step
* B.3 Variational smoothing step
* B.4 Efficiently sampling structured marginals
* B.5 Efficient filtering
* C Evaluating the KL using low-rank structure
* C.1 Smoothing inference network
* C.2 Causal/streaming inference network
* D Comparison method details
* D.1 SVAE
* D.2 DVBF
* D.3 DKF
* E Experimental details
* E.1 High-dimensional linear dynamical system
* E.2 Time complexity
* E.3 Pendulum
* E.4 Bouncing ball
* E.5 MC_Maze
* E.6 DMFC_RSG
* E.7 Collated results
* F Useful expressions
* G Forward KL fixed point
* H Linear Gaussian (information form) smoothing

## Appendix A Nomenclature

\begin{tabular}{p{142.3pt} p{142.3pt}} \hline \hline Symbol & Description \\ \hline SSM & state-space model \\ LGSSM & linear and Gaussian state-space model \\ \(\pi(\mathbf{z}_{t})\) & variational approximation, \(\pi(\mathbf{z}_{t})\approx p(\mathbf{z}_{t}\,|\,\mathbf{y}_{1:T})\) \\ \(\boldsymbol{\lambda}_{t}\) & natural parameters of \(\pi(\mathbf{z}_{t})\) \\ \(\boldsymbol{\mu}_{t}\) & mean parameters of \(\pi(\mathbf{z}_{t})\) \\ \(\boldsymbol{\mathrm{m}}_{t}\) / \(\mathbf{P}_{t}\) & mean / covariance of \(\pi(\mathbf{z}_{t})\) \\ \(\boldsymbol{\alpha}_{t}\) & local natural parameter update, \(\boldsymbol{\alpha}_{\boldsymbol{\phi}}(\mathbf{y}_{t})\) \\ \(\boldsymbol{\beta}_{t+1}\) & backward natural parameter update, \(\boldsymbol{\beta}_{\boldsymbol{\phi}}(\mathbf{y}_{t+1:T})\) \\ \(\bar{\pi}(\mathbf{z}_{t})\) & variational approximation with mean parameters \(\bar{\boldsymbol{\mu}}_{t}=\mathbb{E}_{\pi_{t-1}}\left[\boldsymbol{\mu}_{ \boldsymbol{\theta}}(\mathbf{z}_{t-1})\right]\) \\ \(\bar{\boldsymbol{\lambda}}_{t}\) & natural parameters of \(\bar{\pi}(\mathbf{z}_{t})\) \\ \(\bar{\boldsymbol{\mu}}_{t}\) & mean parameters of \(\bar{\pi}(\mathbf{z}_{t})\) \\ \(\bar{\boldsymbol{\mathrm{m}}}_{t}\) / \(\bar{\mathbf{P}}_{t}\) & mean / covariance of \(\bar{\pi}(\mathbf{z}_{t})\) \\ \(\boldsymbol{\theta}\) & parameters of the dynamics and initial condition \\ \(p_{\boldsymbol{\theta}}(\mathbf{z}_{t}\,|\,\mathbf{z}_{t-1})\) & prior over state transitions \\ \(p_{\boldsymbol{\theta}}(\mathbf{z}_{1})\) & prior over initial condition \\ \(\boldsymbol{\psi}\) & parameters of the observation model/likelihood \\ \(p\boldsymbol{\psi}(\mathbf{y}_{t}\,|\,\mathbf{z}_{t})\) & observation model/likelihood \\ \hline \hline \end{tabular}

## Appendix B Variational filtering

Principles of Bayesian inference make it straightforward to write down an algorithm recursively computing the filtering posterior, \(p(\mathbf{z}_{t}\,|\,\mathbf{y}_{1:t})^{2}\). Given, \(p(\mathbf{z}_{t-1}\,|\,\mathbf{y}_{1:t-1})\), updating our belief to \(p(\mathbf{z}_{t}\,|\,\mathbf{y}_{1:t})\) after observing \(\mathbf{y}_{t}\) can be broken down into two steps: first, we marginalize \(p(\mathbf{z}_{t-1}\,|\,\mathbf{y}_{1:t-1})\) through the dynamics to obtain the predictive distribution,

\[\bar{p}(\mathbf{z}_{t}\,|\,\mathbf{y}_{1:t-1})=\mathbb{E}_{p(\mathbf{z}_{t-1} |\mathbf{y}_{1:t-1})}\left[p_{\boldsymbol{\theta}}(\mathbf{z}_{t}\,|\, \mathbf{z}_{t-1})\right]\qquad\text{\bf(predict step)}\] (30)

Then, we update our belief by incorporating \(\mathbf{y}_{t}\) through Bayes' rule,

\[p(\mathbf{z}_{t}\,|\,\mathbf{y}_{1:t})\propto p_{\boldsymbol{\psi}}(\mathbf{y }_{t}\,|\,\mathbf{z}_{t})\bar{p}(\mathbf{z}_{t}\,|\,\mathbf{y}_{1:t-1})\qquad \text{\bf(update step)}\] (31)

With all of the filtered/predictive beliefs, the **smoothing step** is given by,

\[p(\mathbf{z}_{t}\,|\,\mathbf{y}_{1:T})=\mathbb{E}_{p(\mathbf{z}_{t+1}|\, \mathbf{y}_{1:T})}\left[p(\mathbf{z}_{t}\,|\,\mathbf{z}_{t+1},\mathbf{y}_{1:t })\right]=p(\mathbf{z}_{t}\,|\,\mathbf{y}_{1:t})\frac{\mathbb{E}_{p(\mathbf{z }_{t+1}|\,\mathbf{y}_{1:T})}\left[p_{\boldsymbol{\theta}}(\mathbf{z}_{t+1}\,| \,\mathbf{z}_{t})\right]}{\mathbb{E}_{p(\mathbf{z}_{t}|\,\mathbf{y}_{1:t})} \left[p_{\boldsymbol{\theta}}(\mathbf{z}_{t+1}\,|\,\mathbf{z}_{t})\right]}\] (32)

However, these steps can usually not be evaluated in closed form when we depart from assumptions of Gaussianity and linearity. For nonlinear Gaussian dynamics the predict step can not be carried out exactly, and for nonlinear or non-Gaussian observations neither can the update step.

Alternatively, by considering variational analogues of the predict / update steps, we can develop a recursive and fully differentiable procedure for finding approximations \(\pi(\mathbf{z}_{t})\approx p(\mathbf{z}_{t}\,|\,\mathbf{y}_{1:t})\). In developing the variational analogues, it is assumed the approximations belong to an exponential family of distributions, (i.e. \(\pi\in\mathcal{Q}\) where \(\mathcal{Q}\) is an exponential family distribution) - not necessarily Gaussian.

### Variational predict step

Similar to developing a recursive algorithm as in the exact case, given \(\pi(\mathbf{z}_{t-1})\approx p(\mathbf{z}_{t-1}\,|\,\mathbf{y}_{1:t-1})\), we approximately marginalize \(\pi(\mathbf{z}_{t-1})\) through the dynamics, by solving the following variational (forward KL / moment-matching) problem,

\[\bar{\pi}(\mathbf{z}_{t})=\operatorname*{argmin}_{\bar{\pi}\in\mathcal{Q}}\, \mathbb{D}_{\text{KL}}\big{(}\mathbb{E}_{\pi(\mathbf{z}_{t-1})}\left[p_{ \boldsymbol{\theta}}(\mathbf{z}_{t}\,|\,\mathbf{z}_{t-1})\right]\big{|}\, \bar{\pi}(\mathbf{z}_{t})\big{)}\] (33)

So that if \(p_{\boldsymbol{\theta}}(\mathbf{z}_{t}\,|\,\mathbf{z}_{t-1})\in\mathcal{Q}\), the optimization problem is minimized when the mean parameters of \(\bar{\pi}(\mathbf{z}_{t})\), denoted \(\bar{\boldsymbol{\mu}}_{t}\), are set to the expected mean parameter transformation under \(\pi(\mathbf{z}_{t-1})\),

\[\bar{\boldsymbol{\mu}}_{t}=\mathbb{E}_{\pi(\mathbf{z}_{t-1})}\left[\boldsymbol{ \mu}_{\boldsymbol{\theta}}(\mathbf{z}_{t-1})\right]\qquad\text{\bf(variational predict step)}\] (34)For a LGSSM with \(p_{\bm{\theta}}(\mathbf{z}_{t}|\,\mathbf{z}_{t-1})=\mathcal{N}(\mathbf{F}\mathbf{z }_{t-1},\mathbf{Q})\), using the fact that,

\[\bm{\mu}_{\bm{\theta}}(\mathbf{z}_{t-1})=\begin{bmatrix}\mathbf{F}\mathbf{z}_{t -1}\\ -\frac{1}{2}\left(\mathbf{F}\mathbf{z}_{t-1}\mathbf{z}_{t-1}^{\top}\mathbf{F}^ {\top}+\mathbf{Q}_{\bm{\theta}}\right)\end{bmatrix}\] (35)

means that if \(\pi(\mathbf{z}_{t-1})=\mathcal{N}(\mathbf{m}_{t-1},\mathbf{P}_{t-1})\), setting the mean and variance of \(\bar{\pi}(\mathbf{z}_{t})\) to,

\[\bar{\mathbf{m}}_{t} =\mathbf{F}\mathbf{m}_{t-1}\] (36) \[\bar{\mathbf{P}}_{t} =\mathbf{F}\mathbf{P}_{t-1}\mathbf{F}^{\top}+\mathbf{Q}_{\bm{ \theta}}\] (37)

minimizes the forward KL objective, and reassuringly, recovers the familiar Kalman filter predict step.

### Variational update step

For the variational analogue of the filtering update step, we use \(\bar{\pi}(\mathbf{z}_{t})\) as a prior for the latest observation, \(\mathbf{y}_{t}\), and solve the following variational (reverse KL) problem,

\[\pi(\mathbf{z}_{t})=\operatorname*{argmin}_{\pi\in\mathcal{Q}}\,\mathbb{D}_{ \text{KL}}(\pi(\mathbf{z}_{t})||\,p_{\bm{\psi}}(\mathbf{y}_{t}\,|\,\mathbf{z }_{t})\bar{\pi}(\mathbf{z}_{t}))\] (38)

If we denote the natural parameters of \(\pi(\mathbf{z}_{t})\) by \(\bm{\lambda}_{t}\), then the optimal \(\bm{\lambda}_{t}\) satisfy the implicit equation [33],

\[\bm{\lambda}_{t}=\nabla_{\bm{\mu}_{t}}\mathbb{E}_{\pi_{t}}\left[\log p_{\bm{ \psi}}(\mathbf{y}_{t}\,|\,\mathbf{z}_{t})\right]+\bar{\bm{\lambda}}_{t}\qquad \text{({variational update step})}\] (39)

This usually requires an iterative optimization procedure, except when the likelihood is conjugate to \(\pi(\mathbf{z}_{t})\) in which case, the likelihood must take the following form with respect to \(\mathbf{z}_{t}\),

\[p_{\bm{\psi}}(\mathbf{y}_{t}\,|\,\mathbf{z}_{t})\propto\exp(\mathcal{T}( \mathbf{z}_{t})^{\top}\tilde{\bm{\lambda}}_{t})\] (40)

so that, as expected, the natural parameters of the solution are given as Bayes' rule would suggest - by adding the data dependent update to the natural parameters of the prior so that,

\[\bm{\lambda}_{t}=\tilde{\bm{\lambda}}_{t}+\bar{\bm{\lambda}}_{t}\] (41)

For a LGSSM with \(p_{\bm{\psi}}(\mathbf{y}_{t}\,|\,\mathbf{z}_{t})=\mathcal{N}(\mathbf{C} \mathbf{z}_{t},\mathbf{R})\), this results in the following updates,

\[\mathbf{h}_{t} =\bar{\mathbf{h}}_{t}+\mathbf{C}^{\top}\mathbf{R}^{-1}\mathbf{y} _{t}\] (42) \[\mathbf{J}_{t} =\bar{\mathbf{J}}_{t}+\mathbf{C}^{\top}\mathbf{R}^{-1}\mathbf{C}\] (43)

which reassuringly recover the information form of the Kalman filter update step [16].

### Variational smoothing step

Letting \(\tilde{q}(\mathbf{z}_{t})\approx p(\mathbf{z}_{t}\,|\,\mathbf{y}_{1:t})\) and \(q(\mathbf{z}_{t+1})\approx p(\mathbf{z}_{t+1}\,|\,\mathbf{y}_{1:T})\), we can calculate the statistics of \(q(\mathbf{z}_{t})\) approximating the smoothed marginal posterior, by minimizing the following objective with respect to the marginal distribution, \(q(\mathbf{z}_{t})\),

\[\mathcal{L}_{S}(\tilde{q}) =\mathbb{D}_{\text{KL}}\big{(}\bar{q}(\mathbf{z}_{t})\big{|}\big{|} \,\mathbb{E}_{\bar{q}(\mathbf{z}_{t+1})}\left[q(\mathbf{z}_{t}\,|\,\mathbf{z }_{t+1})\right]\big{)}\] (44) \[=\mathbb{D}_{\text{KL}}(\bar{q}(\mathbf{z}_{t})||\,q(\mathbf{z}_ {t}))-\mathbb{E}_{\bar{q}(\mathbf{z}_{t})}\left[\log\mathbb{E}_{\bar{q}( \mathbf{z}_{t+1})}\left[\frac{p_{\bm{\theta}}(\mathbf{z}_{t+1}\,|\,\mathbf{z }_{t})}{\mathbb{E}_{q(\mathbf{z}_{t})}\left[p_{\bm{\theta}}(\mathbf{z}_{t+1}\,| \,\mathbf{z}_{t})\right]}\right]\right]\] (45) \[\approx\mathbb{D}_{\text{KL}}(\bar{q}(\mathbf{z}_{t})||\,q( \mathbf{z}_{t}))-\mathbb{E}_{\bar{q}(\mathbf{z}_{t})}\left[\log\mathbb{E}_{ \bar{q}(\mathbf{z}_{t+1})}\left[\frac{p_{\bm{\theta}}(\mathbf{z}_{t+1}\,|\, \mathbf{z}_{t})}{\bar{q}(\mathbf{z}_{t+1})}\right]\right]\coloneqq\widehat{ \mathcal{L}}_{S}(\tilde{q})\] (46)

taking natural gradients, we find that at a fixed point, the smoothed marginal posterior parameters satisfy the implicit relationship,

\[\bm{\lambda}_{t}=\tilde{\mathbf{X}}_{t}+\nabla_{\bm{\mu}_{t}}\mathbb{E}_{q( \mathbf{z}_{t})}\left[A\left(\bm{\lambda}_{\bm{\theta}}(\mathbf{z}_{t})+\bm{ \lambda}_{t+1}-\bar{\bm{\lambda}}_{t+1}\right)-A\left(\bm{\lambda}_{\bm{\theta}} (\mathbf{z}_{t})\right)\right]\] (47)

### Efficiently sampling structured marginals

``` Input:\(\mathbf{k}_{1:T}\), \(\mathbf{K}_{1:T}\) for\(t=1\)to\(T\)do \(\bar{\mathbf{m}}_{t}=S^{-1}\sum\mathbf{m}_{\theta}(\mathbf{z}_{t-1}^{s})\) \(\bar{\mathbf{M}}_{t}^{c}=S^{-1/2}\left[\mathbf{m}_{\theta}(\mathbf{z}_{t-1}^{ \top})-\bar{\mathbf{m}}_{t}\cdots\mathbf{m}_{\theta}(\mathbf{z}_{t-1}^{S})- \bar{\mathbf{m}}_{t}\right]\) \(\bar{\mathbf{T}}_{t}=\text{Cholesky}(\mathbf{I}_{S}+\bar{\mathbf{M}}_{t}^{c \top}\mathbf{Q}^{-1}\bar{\mathbf{M}}_{t}^{c})^{-1}\) \(\bar{\mathbf{h}}_{t}=\bar{\mathbf{P}}_{t}^{-1}\bar{\mathbf{m}}_{t}\) # using \([\mathbf{Q},\bar{\mathbf{M}}_{t}^{c},\bar{\mathbf{\Upsilon}}_{t}]\) and Eq. (50) \(\mathbf{T}_{t}=\text{Cholesky}(\mathbf{I}_{r}+\mathbf{K}_{t}^{\top}\bar{ \mathbf{P}}_{t}\mathbf{K}_{t})^{-1}\) # using \([\mathbf{Q},\bar{\mathbf{M}}_{t}^{c}]\) and Eq. (23) \(\mathbf{h}_{t}=\mathbf{h}_{t}+\mathbf{k}_{t}\) \(\mathbf{m}_{t}=\mathbf{P}_{t}\mathbf{h}_{t}\) # using \([\mathbf{Q},\bar{\mathbf{M}}_{t}^{c},\mathbf{K}_{t},\mathbf{\Upsilon}_{t}]\) and Eqs. (52) and (23) \(\bar{\mathbf{w}}_{t}^{s}\sim\mathcal{N}(\mathbf{0},\mathbf{I}_{L+S})\) \(\bar{\mathbf{z}}_{t}^{s}=\bar{\mathbf{P}}_{t}^{1/2}\bar{\mathbf{w}}_{t}^{s}\) # using \([\mathbf{Q},\bar{\mathbf{M}}_{t}^{c}]\) and Eq. (23) \(\mathbf{w}_{t}^{s}\sim\mathcal{N}(\mathbf{0},\mathbf{I}_{r})\) \(\mathbf{z}_{t}^{s}=\mathbf{m}_{t}+\bar{\mathbf{z}}_{t}^{s}-\mathbf{K}_{t} \mathbf{\Upsilon}_{t}\mathbf{\Upsilon}_{t}^{\top}(\mathbf{K}_{t}^{\top}\bar{ \mathbf{z}}_{t}^{s}+\mathbf{w}_{t}^{s})\) endfor Output:\(\mathbf{z}_{1:T}^{1:S}\), \(\mathbf{m}_{1:T}\), \(\bar{\mathbf{m}}_{1:T}\), \(\mathbf{\Upsilon}_{1:T}\) ```

**Algorithm 2** Nonlinear variational filtering

While \(\mathbf{P}_{t}\) has a structured representation, drawing samples from \(\pi(\mathbf{z}_{t})\) is not straightforward because we do not have a structured representation for a square-root of \(\mathbf{P}_{t}\). However, using the factorization of \(\bar{\mathbf{P}}_{t}\) in Eq. (23), it is possible to sample from \(\mathcal{N}(\mathbf{0},\bar{\mathbf{P}}_{t})\) efficiently since \(\bar{\mathbf{P}}_{t}^{1/2}=[\bar{\mathbf{M}}_{t}^{c}\ \mathbf{Q}^{1/2}]\). Now, combining the fact that the posterior marginal can be written as,

\[\pi(\mathbf{z}_{t})=\mathcal{N}(\mathbf{m}_{t},\mathbf{P}_{t})\] \[=\mathcal{N}(\mathbf{m}_{t},(\bar{\mathbf{P}}_{t}^{-1}+\mathbf{K}_ {t}\mathbf{K}_{t}^{\top})^{-1})\] (48)

with the result from Cong et al. [34], stating that sampling \(\mathbf{z}_{t}^{s}\sim\pi(\mathbf{z}_{t})\) is equivalent to sampling \(\mathbf{w}_{t}^{s}\sim\mathcal{N}(\mathbf{0},\mathbf{I}_{L+S})\) and \(\bar{\mathbf{z}}_{t}^{s}\sim\mathcal{N}(\mathbf{0},\bar{\mathbf{P}}_{t})\), and then setting

\[\mathbf{z}_{t}^{s}=\mathbf{m}_{t}+\bar{\mathbf{z}}_{t}^{s}-\mathbf{K}_{t} \mathbf{\Upsilon}_{t}\mathbf{\Upsilon}_{t}^{\top}(\mathbf{K}_{t}^{\top}\bar{ \mathbf{z}}_{t}^{s}+\mathbf{w}_{t}^{s}),\] (49)

makes it possible to efficiently draw samples from the posterior marginal.

### Efficient filtering

Evaluating \(\bar{\mathbf{h}}_{t}=\bar{\mathbf{P}}_{t}^{-1}\bar{\mathbf{m}}_{t}\) and MVMs with \(\bar{\mathbf{P}}_{t}^{-1}\), can be carried out in \(\mathcal{O}(LS+S^{2})\) time, after an initial cost of \(\mathcal{O}(LS^{2}+S^{3})\) to factorize \(\bar{\mathbf{\Upsilon}}_{t}\bar{\mathbf{\Upsilon}}_{t}^{\top}=(\mathbf{I}_{S} +\bar{\mathbf{M}}_{t}^{c\top}\mathbf{Q}_{\boldsymbol{\theta}}^{-1}\bar{ \mathbf{M}}_{t}^{c})^{-1}\), by applying the Woodbury identity to (23),

\[\bar{\mathbf{P}}_{t}^{-1}=\mathbf{Q}_{\boldsymbol{\theta}}^{-1}-\mathbf{Q}_{ \boldsymbol{\theta}}^{-1}\bar{\mathbf{M}}_{t}^{c}\bar{\mathbf{\Upsilon}}_{t} \bar{\mathbf{\Upsilon}}_{t}^{\top}\bar{\mathbf{M}}_{t}^{c\top}\mathbf{Q}_{ \boldsymbol{\theta}}^{-1}\] (50)

Since this specifies all quantities that characterize \(\bar{\pi}(\mathbf{z}_{t})\), following (13), next is to update our belief by adding the information from the pseudo observation to them,

\[\mathbf{h}_{t}=\bar{\mathbf{h}}_{t}+\mathbf{k}_{t} \mathbf{P}_{t}^{-1}=\bar{\mathbf{P}}_{t}^{-1}+\mathbf{K}_{t} \mathbf{K}_{t}^{\top}\] (51)

As a result, the multiplication in \(\mathbf{m}_{t}=\mathbf{P}_{t}\mathbf{h}_{t}\) requires \(\mathcal{O}(LS+Lr)\) time, and, analogous to (50), the square root factor \(\mathbf{\Upsilon}_{t}\) in

\[\mathbf{P}_{t}=\bar{\mathbf{P}}_{t}-\bar{\mathbf{P}}_{t}\mathbf{K}_{t}\mathbf{ \Upsilon}_{t}\mathbf{\Upsilon}_{t}^{\top}\mathbf{K}_{t}^{\top}\bar{\mathbf{P}}_{t}\] (52)

requires \(\mathcal{O}(r^{3}+LSr+S^{2}r)\) time where \(\mathbf{\Upsilon}_{t}\mathbf{\Upsilon}_{t}^{\top}=(\mathbf{I}_{r}+\mathbf{K}_{t }^{\top}\bar{\mathbf{P}}_{t}\mathbf{K}_{t})^{-1}\).

## Appendix C Evaluating the KL using low-rank structure

### Smoothing inference network

Efficient training of the generative model and inference networks require efficient numerical evaluation of the ELBO. We take advantage of the structured precision matrices arising from low-rank updatesand sample approximations. The expected log likelihood can be evaluated using a Monte Carlo approximation from samples during the filtering pass. The KL term,

\[\mathbb{D}_{\text{KL}}(\pi(\mathbf{z}_{t})||\,\bar{\pi}(\mathbf{z}_{t}))=\tfrac{1 }{2}\left[(\bar{\mathbf{m}}_{t}-\mathbf{m}_{t})^{\top}\bar{\mathbf{P}}_{t}^{-1} (\bar{\mathbf{m}}_{t}-\mathbf{m}_{t})+\text{tr}(\bar{\mathbf{P}}_{t}^{-1} \mathbf{P}_{t})+\log\frac{|\bar{\mathbf{P}}_{t}|}{|\mathbf{P}_{t}|}-L\right]\] (53)

can be evaluated in closed form and we can expand each term as,

**Log-determinant.** Writing

\[\log|\mathbf{P}_{t}| =-\log|\bar{\mathbf{P}}_{t}^{-1}+\mathbf{K}_{t}\mathbf{K}_{t}^{ \top}|\] (54) \[=\log|\bar{\mathbf{P}}_{t}|-\log|\mathbf{I}+\mathbf{K}_{t}^{\top }\bar{\mathbf{P}}_{t}\mathbf{K}_{t}|\] (55)

gives

\[\log\frac{|\bar{\mathbf{P}}_{t}|}{|\mathbf{P}_{t}|} =\log|\mathbf{I}+\mathbf{K}_{t}^{\top}\bar{\mathbf{P}}_{t} \mathbf{K}_{t}|\] (56) \[=-2\sum\nolimits_{i=1}^{r}[\boldsymbol{\Upsilon}_{t}]_{i,i}\] (57)

**Trace.** Writing,

\[\text{tr}(\bar{\mathbf{P}}_{t}^{-1}\mathbf{P}_{t}) =\text{tr}(\mathbf{I}_{L}-\mathbf{K}_{t}(\mathbf{I}+\mathbf{K}_{ t}^{\top}\bar{\mathbf{P}}_{t}\mathbf{K}_{t})^{-1}\mathbf{K}_{t}^{\top}\bar{ \mathbf{P}}_{t})\] (58) \[=L-\text{tr}(\bar{\mathbf{P}}_{t}^{\top/2}\mathbf{K}_{t}(\mathbf{ I}+\mathbf{K}_{t}^{\top}\bar{\mathbf{P}}_{t}\mathbf{K}_{t})^{-1}\mathbf{K}_{t}^{ \top}\bar{\mathbf{P}}_{t}^{1/2})\] (59) \[=L-\text{tr}(\boldsymbol{\Upsilon}_{t}^{\top}\mathbf{K}_{t}^{\top }\bar{\mathbf{P}}_{t}\mathbf{K}_{t}\boldsymbol{\Upsilon}_{t})\] (60)

which by taking \(\boldsymbol{\Upsilon}_{t}\) to be an \(r\times r\) square root such that,

\[\boldsymbol{\Upsilon}_{t}\boldsymbol{\Upsilon}_{t}^{\top}=(\mathbf{I}+\mathbf{ K}_{t}^{\top}\bar{\mathbf{P}}_{t}\mathbf{K}_{t})^{-1}\] (61)

further simplifies to

\[\text{tr}(\bar{\mathbf{P}}_{t}^{-1}\mathbf{P}_{t}) =L-\text{tr}(\bar{\mathbf{M}}_{t}^{\text{c}\top}\mathbf{K}_{t} \boldsymbol{\Upsilon}_{t}\boldsymbol{\Upsilon}_{t}^{\top}\mathbf{K}_{t}^{\top }\bar{\mathbf{M}}_{t}^{c})-\text{tr}(\mathbf{Q}^{\top/2}\mathbf{K}_{t} \boldsymbol{\Upsilon}_{t}\boldsymbol{\Upsilon}_{t}^{\top}\mathbf{K}_{t}^{\top }\mathbf{Q}^{1/2})\] (62) \[=L-\text{tr}(\bar{\mathbf{M}}_{t}^{\text{c}\top}\mathbf{K}_{t} \boldsymbol{\Upsilon}_{t}\boldsymbol{\Upsilon}_{t}^{\top}\mathbf{K}_{t}^{\top }\bar{\mathbf{M}}_{t}^{c})-\text{tr}(\boldsymbol{\Upsilon}_{t}^{\top}\mathbf{ K}_{t}^{\top}\mathbf{Q}^{1/2}\mathbf{Q}^{\top/2}\mathbf{K}_{t}\boldsymbol{ \Upsilon}_{t})\] (63)

note that the size of the triple product, \(\bar{\mathbf{M}}_{t}^{\text{c}\top}\mathbf{K}_{t}\boldsymbol{\Upsilon}_{t}\), is \(S\times r\).

### Causal/streaming inference network

When the real-time parameterization of the inference network is used the expressions become slightly more complicated due to the more intricate relationship between the posterior at time \(t\) and the posterior predictive at time \(t\).

**Log-determinant.** We need to first find \(\log|\bar{\mathbf{P}}_{t|T}|-\log|\mathbf{P}_{t}|\) so begin with using the matrix-determinant lemma to write,

\[|\bar{\mathbf{P}}_{t|T}| =|\mathbf{M}_{t|T}^{\text{c}}\mathbf{M}_{t|T}^{\text{c}\top}+ \mathbf{Q}|\] (64) \[=|\mathbf{I}_{S}+\mathbf{M}_{t|T}^{\text{c}\top}\mathbf{Q}^{-1} \mathbf{M}_{t|T}^{\text{c}}|\times|\mathbf{Q}|\] (65)

then expand the smoothed covariance to write,

\[|\mathbf{P}_{t}| =|(\bar{\mathbf{P}}_{t}^{-1}+\mathbf{B}_{t}\mathbf{B}_{t}^{\top}) ^{-1}|\] (66) \[=|\bar{\mathbf{P}}_{t}^{-1}+\mathbf{B}_{t}\mathbf{B}_{t}^{\top}|^ {-1}\] (67) \[=(|\mathbf{I}_{r_{\alpha}}+\mathbf{B}_{t}^{\top}\bar{\mathbf{P}}_ {t}\mathbf{B}_{t}|\times|\bar{\mathbf{P}}_{t}^{-1}|)^{-1}\] (68) \[=|\mathbf{I}_{r_{\beta}}+\mathbf{B}_{t}^{\top}\bar{\mathbf{P}}_ {t}\mathbf{B}_{t}|^{-1}|\bar{\mathbf{P}}_{t}|\] (69)

and another time to write,

\[|\bar{\mathbf{P}}_{t}^{-1}| =|\bar{\mathbf{P}}_{t}^{-1}+\mathbf{A}_{t}\mathbf{A}_{t}^{\top}|\] (70) \[=|\mathbf{I}_{r_{\alpha}}+\mathbf{A}_{t}^{\top}\bar{\mathbf{P}}_ {t}\mathbf{A}_{t}|\times|\bar{\mathbf{P}}_{t}^{-1}|\] (71)and another time,

\[|\bar{\mathbf{P}}_{t}| =|\mathbf{M}_{t}^{c}\mathbf{M}_{t}^{c\top}+\mathbf{Q}|\] (72) \[=|\mathbf{I}_{S}+\mathbf{M}_{t}^{c\top}\mathbf{Q}^{-1}\mathbf{M}_{ t}^{c}|\times|\mathbf{Q}|\] (73)

When combined we are finally able to write

\[\log|\bar{\mathbf{P}}_{t|T}|-\log|\mathbf{P}_{t}| =\log|\mathbf{I}_{S}+\mathbf{M}_{t|T}^{c\top}\mathbf{Q}^{-1} \mathbf{M}_{t|T}^{c}|+\log|\mathbf{I}_{r_{\beta}}+\mathbf{B}_{t}^{\top}\bar{ \mathbf{P}}_{t}\mathbf{B}_{t}|\] (74) \[+\log|\mathbf{I}_{r_{\alpha}}+\mathbf{A}_{t}^{\top}\bar{\mathbf{ P}}_{t}\mathbf{A}_{t}|-\log|\mathbf{I}_{S}+\mathbf{M}_{t}^{c\top}\mathbf{Q}^{-1} \mathbf{M}_{t}^{c}|\] (75)

For the initial condition we have,

\[\log|\bar{\mathbf{P}}_{1}|-\log|\mathbf{P}_{1}|=\log|\mathbf{I}_{r_{\beta}}+ \mathbf{B}_{1}^{\top}\bar{\mathbf{P}}_{1}\mathbf{B}_{1}|+\log|\mathbf{I}_{r_ {\alpha}}+\mathbf{A}_{1}^{\top}\bar{\mathbf{P}}_{1}\mathbf{A}_{1}|\] (76)

**Trace.** For the trace,

\[\operatorname{tr}(\bar{\mathbf{P}}_{t|T}^{-1}\mathbf{P}_{t}) =\operatorname{tr}(\mathbf{Q}^{-1}\mathbf{P}_{t})-\operatorname{ tr}(\mathbf{Q}^{-1}\mathbf{M}_{t|T}^{c}(\mathbf{I}_{S}+\mathbf{M}_{t|T}^{c\top} \mathbf{Q}^{-1}\mathbf{M}_{t|T}^{c})^{-1}\mathbf{M}_{t|T}^{c\top}\mathbf{Q}^{- 1}\mathbf{P}_{t})\] (77) \[=\operatorname{tr}(\mathbf{Q}^{-1}\mathbf{P}_{t})-\operatorname{ tr}(\mathbf{Q}^{-1}\mathbf{M}_{t|T}^{c}\bar{\mathbf{T}}_{t|T}\bar{\mathbf{T}}_{t|T}^{c \top}\mathbf{M}_{t|T}^{c\top}\mathbf{Q}^{-1}\mathbf{P}_{t})\] (78) \[=\operatorname{tr}(\mathbf{P}_{t}\mathbf{Q}^{-1})-\operatorname{ tr}([\mathbf{P}_{t}\mathbf{Q}^{-1}\mathbf{M}_{t|T}^{c}\bar{\mathbf{T}}_{t|T}]\bar{ \mathbf{T}}_{t|T}^{\top}\mathbf{M}_{t|T}^{c\top}\mathbf{Q}^{-1})\] (79)

where we expand the first rhs term for a numerically efficient implementation by writing

\[\operatorname{tr}(\mathbf{P}_{t}\mathbf{Q}^{-1})=\operatorname{ tr}(\bar{\mathbf{P}}_{t}\mathbf{Q}^{-1})-\operatorname{tr}(\bar{\mathbf{P}}_{t} \mathbf{A}_{t}(\mathbf{I}_{r_{\alpha}}+\mathbf{A}_{t}^{\top}\bar{\mathbf{P}}_ {t}\mathbf{A}_{t})^{-1}\mathbf{A}_{t}^{\top}\bar{\mathbf{P}}_{t}\mathbf{Q}^{-1})\] (80) \[-\operatorname{tr}(\bar{\mathbf{P}}_{t}\mathbf{B}_{t}(\mathbf{I}_ {r_{\beta}}+\mathbf{B}_{t}^{\top}\bar{\mathbf{P}}_{t}\mathbf{B}_{t})^{-1} \mathbf{B}_{t}^{\top}\bar{\mathbf{P}}_{t}\mathbf{Q}^{-1})\] (81)

To reduce notational clutter we define,

\[\widehat{\mathbf{T}}_{t}\widehat{\mathbf{T}}_{t}^{\top} =(\mathbf{I}_{S}+\mathbf{M}_{t}^{c\top}\mathbf{Q}^{-1}\mathbf{M }_{t}^{c})^{-1}\] (82) \[\widehat{\mathbf{T}}_{t|T}\widehat{\mathbf{T}}_{t|T}^{\top} =(\mathbf{I}_{S}+\mathbf{M}_{t|T}^{c\top}\mathbf{Q}^{-1}\mathbf{ M}_{t|T}^{c})^{-1}\] (83) \[\widehat{\mathbf{T}}_{t}\widehat{\mathbf{T}}_{t}^{\top} =(\mathbf{I}_{r_{\alpha}}+\mathbf{A}_{t}^{\top}\bar{\mathbf{P}}_{ t}\mathbf{A}_{t})^{-1}\] (84) \[\boldsymbol{\Upsilon}_{t}\boldsymbol{\Upsilon}_{t}^{\top} =(\mathbf{I}_{r_{\beta}}+\mathbf{B}_{t}^{\top}\bar{\mathbf{P}}_{ t}\mathbf{B}_{t})^{-1}\] (85)

and so the trace is

\[\operatorname{tr}(\bar{\mathbf{P}}_{t|T}^{-1}\mathbf{P}_{t})=L+ \operatorname{tr}(\mathbf{M}_{t}^{c\top}\mathbf{Q}^{-1}\mathbf{M}_{t}^{c}) -\operatorname{tr}(\mathbf{Q}^{-1/2}\bar{\mathbf{P}}_{t}\mathbf{A}_{t} \bar{\mathbf{T}}_{t}\bar{\mathbf{T}}_{t}^{\top}\bar{\mathbf{A}}_{t}^{\top} \bar{\mathbf{P}}_{t}\mathbf{Q}^{-1/2})\] (86) \[-\operatorname{tr}(\mathbf{Q}^{-1/2}\bar{\mathbf{P}}_{t}\mathbf{B }_{t}\mathbf{T}_{t}\boldsymbol{\Upsilon}_{t}^{\top}\mathbf{B}_{t}^{\top}\bar{ \mathbf{P}}_{t}\mathbf{Q}^{-1/2})\] (87) \[-\operatorname{tr}([\mathbf{P}_{t}\mathbf{Q}^{-1}\mathbf{M}_{t|T}^ {c}\bar{\mathbf{T}}_{t|T}]\bar{\mathbf{T}}_{t|T}^{c\top}\mathbf{M}_{t|T}^{c \top}\mathbf{Q}^{-1})\] (88)

which is now in a form that is easy to handle using fast MVMs with \(\bar{\mathbf{P}}_{t}\), \(\bar{\mathbf{P}}_{t}\), \(\mathbf{P}_{t}\).

For the initial condition term we use the fact that \(\bar{\mathbf{P}}_{1}\) is diagonal,

\[\operatorname{tr}(\mathbf{P}_{1}\bar{\mathbf{P}}_{1}^{-1})=L- \operatorname{tr}(\bar{\mathbf{P}}_{1}^{1/2}\mathbf{A}_{1}\bar{\mathbf{T}}_{1} \bar{\mathbf{T}}_{1}^{\top}\mathbf{A}_{1}^{\top}\bar{\mathbf{P}}_{1}^{1/2})- \operatorname{tr}(\bar{\mathbf{P}}_{1}^{-1/2}\bar{\mathbf{P}}_{1}\mathbf{B}_{1} \boldsymbol{\Upsilon}_{1}\boldsymbol{\Upsilon}_{1}^{\top}\mathbf{B}_{1}^{\top} \bar{\mathbf{P}}_{1}\bar{\mathbf{P}}_{1}^{-1/2})\] (89)

## Appendix D Comparison method details

### Svae

For the SVAE[20], the latent state prior is a linear dynamical system parameterized as,

\[p_{\theta}(\mathbf{z}_{t}\,|\,\mathbf{z}_{t-1})=\mathcal{N}(\mathbf{z}_{t}\,|\, \mathbf{F}\mathbf{z}_{t-1},\mathbf{Q})\] (90)

Using conjugate potentials, with likelihood \(p(\tilde{\mathbf{y}}_{t}\,|\,\mathbf{z}_{t})=\exp(t(\mathbf{z}_{t})^{\top} \boldsymbol{\alpha}(\mathbf{y}_{t}))\), the approximate posterior is given by \(q(\mathbf{z}_{1:T})=\prod p(\tilde{\mathbf{y}}_{t}\,|\,\mathbf{z}_{t})p_{ \theta}(\mathbf{z}_{1:T})\) so that its statistics can be found by applying Kalman filtering/smoothing to the pseudo-observations. In this case, the ELBO can be evaluated as

\[\mathcal{L}(q)=\sum\mathbb{E}_{q_{t}}\left[\log p(\mathbf{y}_{t}\,|\,\mathbf{z}_{t}) \right]-\mathbb{E}_{q_{t}}\left[\log p(\tilde{\mathbf{y}}_{t}\,|\,\mathbf{z}_{t}) \right]+\log\mathbb{E}_{\bar{q}_{t}}\left[p(\tilde{\mathbf{y}}_{t}\,|\, \mathbf{z}_{t})\right]\] (91)

where \(\bar{q}_{t}:=\bar{q}(\mathbf{z}_{t})=p(\mathbf{z}_{t}\,|\,\tilde{\mathbf{y}}_{1:t-1})\) is the filtering predictive distribution. These expressions can be evaluated in closed form and written concisely in terms of natural/mean parameters and log-partition functions as

\[\mathcal{L}(q)=\sum\mathbb{E}_{q_{t}}\left[\log p(\mathbf{y}_{t}\,|\,\mathbf{z}_{t}) \right]-\boldsymbol{\mu}_{t}^{\top}\boldsymbol{\alpha}_{t}+A(\bar{ \boldsymbol{\lambda}}_{t}+\boldsymbol{\alpha}_{t})-A(\bar{\boldsymbol{\lambda}}_{t})\] (92)

where \(\boldsymbol{\mu}_{t}=\nabla A(\bar{\boldsymbol{\lambda}}_{t}+\boldsymbol{\alpha}_{t }+\boldsymbol{\beta}_{t+1})\). Using the identities given in App. F, these expressions can be written in more familiar mean/covariance parameters.

### Dvbf

For the DVBF [5], we parameterize the latent state prior using a nonlinear dynamical system of the same form as Eq. (1). Then, using an inference network that encodes data in reverse-time to produce the parameters of a diagonal Gaussian distribution, \(\mathbf{w}_{t}\sim q(\mathbf{w}_{t})=\mathcal{N}(\mathbf{m}_{t},\mathrm{diag}( \mathbf{s}_{t}))\), we sample the latent trajectory forward using the recursion, \(\mathbf{z}_{t}=\mathbf{m}_{\boldsymbol{\theta}}(\mathbf{z}_{t-1})+\mathbf{Q}^ {1/2}\mathbf{w}_{t}\). Parameters of the generative model/inference network are learned jointly by minimizing the ELBO,

\[\mathcal{L}(q)=\sum\mathbb{E}_{q(\mathbf{z}_{t})}\left[\log p_{\boldsymbol{ \psi}}(\mathbf{y}_{t}\,|\,\mathbf{z}_{t})\right]-\mathbb{D}_{\text{KL}}(q( \mathbf{w}_{t})||\,p(\mathbf{w}_{t}))\] (93)

where, \(p(\mathbf{w}_{t})=\mathcal{N}(\mathbf{0},\mathbf{I})\).

### Dkf

For the DKF [6], the latent state is also parameterized using a nonlinear dynamical system of the same form as Eq. (1). We follow the parameterization outlined in the text with \(\mathrm{S2S}(\cdot)\) implemented using a recurrent neural network. We sample trajectories using the inference network and jointly train all parameters on the ELBO,

\[\mathcal{L}(q)=\sum\mathbb{E}_{q_{t}}\left[\log p(\mathbf{y}_{t}\,|\,\mathbf{ z}_{t})\right]-\mathbb{E}_{q_{t-1}}\left[\mathbb{D}_{\text{KL}}(q(\mathbf{z}_{t} \,|\,\mathbf{z}_{t-1}))\|\,p_{\boldsymbol{\theta}}(\mathbf{z}_{t}\,|\, \mathbf{z}_{t-1}))\right]\leq\log p(\mathbf{y}_{1:T})\] (94)

## Appendix E Experimental details

In describing the neural network architectures used to parameterize the inference model, it will be useful to define the following multilayer perceptron (MLP), with SiLU nonlinearity [35], that gets used repeatedly:

\[\mathcal{L}(q)=\sum\mathbb{E}_{q_{t}}\left[\log p(\mathbf{y}_{t}\,|\,\mathbf{ z}_{t})\right]-\mathbb{E}_{q_{t-1}}\left[\mathbb{D}_{\text{KL}}(q(\mathbf{z}_{t} \,|\,\mathbf{z}_{t-1})||\,p_{\boldsymbol{\theta}}(\mathbf{z}_{t}\,|\,\mathbf{ z}_{t-1}))\right]\leq\log p(\mathbf{y}_{1:T})\] (95)

### High-dimensional linear dynamical system

We simulated data from an LDS generative model (with dynamics restricted to the set of matrices with singular values less than \(1\)) for latent dimensions \(L\in[20,50,100]\) over \(3\) random seeds for two scenarios **i)**\(N=L\) and **ii)**\(N=L/5\). For each scenario, we also vary the rank of the local/backward encoder precision updates.

### Time complexity

We generate random LDS systems of appropriate dimension and measure the average time to complete one forward pass and take a gradient step. The system used for benchmarking wall-clock time was an RTX \(4090\) with \(128\)GB of RAM with an AMD 5975WX processor.

### Pendulum

We consider the pendulum system from [26]. We generate \(500\)/\(150\)/\(150\) trials of length \(100\) for training/validation/testing. All methods are trained for \(5000\) epochs for \(3\) different random seeds. We consider a context window of \(50\) images and a forecast window of \(50\) images. A decoder was fit from the latent state on the training set during the context window; then, for held out data, we examine performance of the decoder during the context and forecast windows.

The generative model is parameterized as:

* \(L=4\)
* \(N=256\)
* \(T=50\)
* likelihood\[\begin{array}{l}\mbox{\boldmath{$p_{\phi}$}}(\mathbf{y}_{t}\,|\,\mathbf{z}_{t})= \mathcal{N}(\mathbf{z}_{t}\,|\,\mathbf{C}_{\bm{\psi}}(\mathbf{z}_{t})+\mathbf{ b},\mathbf{R})\\ \mbox{\boldmath{$-$}}\ \mathbf{C}_{\bm{\psi}}:\mathrm{MLP}(4,128,256)\end{array}\]

For each method, inference is amortized using the following neural network architectures:

* our inference network
* \(\bm{\alpha_{\phi}}\): \(\mathrm{MLP}(256,128,20)\)
* \(\bm{\beta_{\phi}}\): \([\mathrm{GRU}(128),\mathrm{Linear}(128,20)]\)
* DKF inference network
* \(\mathbf{u_{\phi}}\): \(\mathrm{GRU}(128)\)
* \((\mathbf{m_{\phi}},\log\mathbf{P_{\phi}})\): \(\mathrm{MLP}(132,128,8)\)
* DVBF inference network
* \(\mathbf{u_{\phi}}\): \([\mathrm{GRU}(128)]\)
* \((\bm{\mu_{\phi}},\log\bm{\sigma_{\phi}})\): \(\mathrm{MLP}(132,128,8)\)
* SVAE inference network
* \(\bm{\alpha_{\phi}}\): \(\mathrm{MLP}(256,128,20)\)

Optimization and training details:

* optimizer: \(\mathrm{Adam}(\mathrm{lr}=0.001)\)
* batch size: 128

### Buncing ball

We consider a bouncing ball dataset commonly used as a baseline to benchmark the performance of inference and learning in deep state-space models [26, 36, 36]. For this dataset we take \(500/150/150\) trials of length \(75\) for training/validation/testing. All methods are trained for \(5000\) epochs for 3 different random seeds. The generative model is parameterized as:

* \(L=8\)
* \(N=256\)
* \(T=50\)

* \(p_{\bm{\psi}}(\mathbf{y}_{t}\,|\,\mathbf{z}_{t})=\mathcal{N}(\mathbf{z}_{t}\, |\,\mathbf{C}_{\bm{\psi}}(\mathbf{z}_{t})+\mathbf{b},\mathbf{R})\)

For each method, inference is amortized using the following neural network architectures:

* our inference network
* \(\bm{\alpha_{\phi}}\): \(\mathrm{MLP}(256,128,72)\)

Figure 4: **Learned covariance of nonlinear SSMs**. (top) single trial of a pendulum. Below are the posterior covariances output by the causal and non-causal variants of XFADS.

* \(\bm{\beta}_{\bm{\phi}}\): \([\mathrm{GRU}(128),\mathrm{Linear}(128,40)]\)
* DKF inference network
* \(\mathbf{u}_{\bm{\phi}}\): \(\mathrm{GRU}(128)\)
* \((\mathbf{m}_{\bm{\phi}},\log\mathbf{P}_{\bm{\phi}})\): \(\mathrm{MLP}(132,128,16)\)
* DVBF inference network
* \(\mathbf{u}_{\bm{\phi}}\): \([\mathrm{GRU}(128)]\)
* \((\bm{\mu}_{\bm{\phi}},\log\bm{\sigma}_{\bm{\phi}})\): \(\mathrm{MLP}(132,128,16)\)
* SVAE inference network
* \(\bm{\alpha}_{\bm{\phi}}\): \(\mathrm{MLP}(256,128,72)\)

Optimization and training details:

* optimizer: \(\mathrm{Adam}(\mathrm{lr}=0.001)\)
* batch size: 128

### MC_Maze

The monkey reaching dataset of [30] was the first real dataset examined in the main text. For this dataset, we partitioned \(1800\)/200/\(200\) training/validation/testing trials sampled at \(20\)ms per bin. All methods are trained for \(1000\) epochs for 3 different random seeds. The generative model is parameterized as:

* \(L=40\)
* \(N=182\)
* \(T=35\)

* \(\mathbf{P}_{\bm{\phi}}(\mathbf{y}_{t}\,|\,\mathbf{z}_{t})=\mathrm{Poisson}( \mathbf{z}_{t}\,|\,\mathbf{C}_{\bm{\psi}}(\mathbf{z}_{t})+\mathbf{b})\)
* \(\mathbf{C}_{\bm{\psi}}\): \(\mathrm{Linear}(40,182)\)

For each method, inference is amortized using the following neural network architectures:

* our inference network
* \(\bm{\alpha}_{\bm{\phi}}\): \(\mathrm{MLP}(182,128,640)\)
* \(\bm{\beta}_{\bm{\phi}}\): \([\mathrm{GRU}(128),\mathrm{Linear}(128,240)]\)
* DKF inference network
* \(\mathbf{u}_{\bm{\phi}}\): \(\mathrm{GRU}(128)\)
* \((\mathbf{m}_{\bm{\phi}},\log\mathbf{P}_{\bm{\phi}})\): \(\mathrm{MLP}(128,128,80)\)

Figure 5: **Learned covariance of nonlinear SSMs. (top) single trial of a bouncing ball. Below are the posterior covariances output by the nonlinear SSMs considered – qualitatively, we observe more complex covariance structures arise when the ball hits the wall that diagonal approximations cannot capture.**

* DVBF inference network
* SVAE inference network

Optimization and training details:

* optimizer: \(\mathrm{Adam}(\mathrm{lr}=0.001)\)
* batch size: 128

### Dmfc_Rsg

The second real dataset examined was the timing interval reproduction task of [32] samples at \(10\)ms bins. For this dataset, we partitioned \(700/150/150\) training/validation/testing trials. All methods are trained for \(1000\) epochs for 3 different random seeds. The generative model is parameterized as:

* \(L=40\)
* \(N=54\)
* \(T=130\)

For each method, inference is amortized using the following neural network architectures:

* our inference network

Figure 6: **XFADS predictive capabilities on real data.** On the left are example reaches the monkey made during several trials. Using the learned model from the monkey reaching experiment, we filtered neural activity starting from \(-240\)ms up until \(-80\)ms before movement onset (each vertical panel represents the result from filtering more and more data) and unroll the final filtered states through the dynamics (starting from the dashed red line) to make predictions.

## Appendix F Useful expressions

mean/natural parameter inner productOne common expression that frequently arises is the inner product between a mean and natural parameter, i.e.

\[\boldsymbol{\mu}_{t}^{\top}\boldsymbol{\alpha}_{t}\] (96)

where in the Gaussian case if the mean/natural parameter coordinates are,

\[\boldsymbol{\mu}_{t}=\begin{pmatrix}\mathbf{m}_{t}\\ -\frac{1}{2}(\mathbf{P}_{t}+\mathbf{m}_{t}\mathbf{m}_{t}^{\top})\end{pmatrix} \boldsymbol{\alpha}_{t}=\begin{pmatrix}\mathbf{a}_{t}\\ \mathbf{A}_{t}\mathbf{A}_{t}^{\top}\end{pmatrix}\] (97)

then,

\[\boldsymbol{\mu}_{t}^{\top}\boldsymbol{\alpha}_{t}=\mathbf{m}_{t}^{\top} \mathbf{a}_{t}-\tfrac{1}{2}||\mathbf{A}_{t}^{\top}\mathbf{m}_{t}||^{2}-\tfrac {1}{2}\operatorname{tr}(\mathbf{A}_{t}^{\top}\mathbf{P}_{t}\mathbf{A}_{t})\] (98)

Figure 7: **Collated results including the latent SDE (L-SDE)[37]**. We ran an additional baseline on pendulum/bouncing ball/monkey reaching datasets. L-SDE achieves results with a similar level of performance as the other models. Listed are the \(R^{2}\) values for decoding angular velocity/x-y position/reach velocity from the latent representations learned for each dataset in both smoothing and prediction regimes.

difference of log partition functionsAnother common expression that frequently arises is given by,

\[A(\bar{\bm{\lambda}}_{t}+\bm{\alpha}_{t})-A(\bar{\bm{\lambda}}_{t})\] (99)

so that if,

\[\bar{\bm{\lambda}}_{t}=\begin{pmatrix}\bar{\mathbf{P}}_{t}^{-1}\bar{\mathbf{m}}_ {t}\\ \bar{\mathbf{P}}_{t}^{-1}\end{pmatrix}\] (100)

then,

\[A(\bar{\bm{\lambda}}_{t}+\bm{\alpha}_{t})- A(\bar{\bm{\lambda}}_{t})\] (101) \[=\tfrac{1}{2}\bar{\mathbf{m}}_{t}^{\top}(\bar{\mathbf{P}}_{t}^{-1 }+\mathbf{A}_{t}\mathbf{A}_{t}^{\top})\bar{\mathbf{m}}_{t}-\tfrac{1}{2}\log| \bar{\mathbf{P}}_{t}^{-1}+\mathbf{A}_{t}\mathbf{A}_{t}^{\top}|\] (102) \[-\tfrac{1}{2}\bar{\mathbf{m}}_{t}\bar{\mathbf{P}}_{t}^{-1}\bar{ \mathbf{m}}_{t}+\tfrac{1}{2}\log|\bar{\mathbf{P}}_{t}^{-1}|\] \[=\tfrac{1}{2}\left(||\bar{\mathbf{m}}_{t}||_{\bar{\mathbf{P}}_{t }^{-1}}^{2}-||\bar{\mathbf{m}}_{t}||_{\bar{\mathbf{P}}_{t}^{-1}}^{2}+||\mathbf{ A}_{t}^{\top}\bar{\mathbf{m}}_{t}||^{2}-\log|\mathbf{I}+\mathbf{A}_{t}^{\top} \bar{\mathbf{P}}_{t}\mathbf{A}_{t}|\right)\] (103)

conditional linear Gaussian log partitionFor a Gaussian distribution, the log-partition function in terms of the natural parameters, \(\bm{\lambda}=(\mathbf{h},\mathrm{vec}(\mathbf{J}))\), is given by

\[A(\bm{\lambda})=\tfrac{1}{2}\mathbf{h}^{\top}\mathbf{J}^{-1} \mathbf{h}-\tfrac{1}{2}\log|\mathbf{J}|\] (104)

so that, when

\[\mathbf{F}=\begin{pmatrix}\mathbf{Q}^{-1}\mathbf{A}&\bm{0}\\ \bm{0}&\bm{0}\end{pmatrix}\qquad\mathbf{f}=\begin{pmatrix}\bm{0}\\ \mathbf{Q}^{-1}\end{pmatrix}\] (105)

and \(\mathbf{u}^{\top}=\begin{pmatrix}\mathbf{u}_{1}^{\top}&\mathrm{vec}(\mathbf{ u}_{2})^{\top}\end{pmatrix}\) is an arbitrary constant, we can write \(A(\mathbf{F}t(\mathbf{z})+\mathbf{f}+\mathbf{u})=\mathbf{a}^{\top}t(\mathbf{ z})+b\) for some \(\mathbf{a}\) and \(b\). To show this, we can just expand the log partition function

\[A(\mathbf{F}t(\mathbf{z})+\mathbf{f}+\mathbf{u}) =\tfrac{1}{2}\mathbf{z}^{\top}\mathbf{A}^{\top}\mathbf{Q}^{-1}( \mathbf{Q}^{-1}+\mathbf{u}_{2})^{-1}\mathbf{Q}^{-1}\mathbf{A}\mathbf{z}+ \mathbf{z}^{\top}\mathbf{A}^{\top}\mathbf{Q}^{-1}(\mathbf{Q}^{-1}+\mathbf{u}_{ 2})^{-1}\mathbf{u}_{1}\] (106) \[\qquad+\tfrac{1}{2}\mathbf{u}_{1}^{\top}(\mathbf{Q}^{-1}+ \mathbf{u}_{2})^{-1}\mathbf{u}_{1}-\tfrac{1}{2}\log|\mathbf{u}_{2}+\mathbf{Q} ^{-1}|\] \[=\mathbf{a}^{\top}t(\mathbf{z})+b\] (107)

then \(\mathbf{a}\) and \(b\) can be identified as

\[\mathbf{a}=\begin{pmatrix}\mathbf{A}^{\top}\mathbf{Q}^{-1}( \mathbf{Q}^{-1}+\mathbf{U}_{2})^{-1}\mathbf{u}_{1}\\ -\mathbf{A}^{\top}\mathbf{Q}^{-1}(\mathbf{Q}^{-1}+\mathbf{U}_{2})^{-1} \mathbf{Q}^{-1}\mathbf{A}\end{pmatrix}\quad b=\tfrac{1}{2}\mathbf{u}_{1}^{ \top}(\mathbf{Q}^{-1}+\mathbf{u}_{2})^{-1}\mathbf{u}_{1}-\tfrac{1}{2}\log| \mathbf{Q}^{-1}+\mathbf{u}_{2}|\] (108)

Then, for a LGSSM, we can evaluate the following expression which describes the difference between predictive and smoothed marginals,

\[\bm{\lambda}_{t}-\bar{\bm{\lambda}}_{t} =\bm{\alpha}_{t}+\nabla_{\bm{\mu}_{t}}\mathbb{E}_{q(\mathbf{z}_{t })}\left[A\left(\bm{\lambda}_{\bm{\theta}}(\mathbf{z}_{t})+\bm{\lambda}_{t+1}- \bar{\bm{\lambda}}_{t+1}\right)-A\left(\bm{\lambda}_{\bm{\theta}}(\mathbf{z}_{t })\right)\right]\] (109) \[=\bm{\alpha}_{t}+\begin{pmatrix}\mathbf{A}^{\top}\mathbf{Q}^{-1} (\mathbf{Q}^{-1}+\mathbf{P}_{t+1}^{-1}-\bar{\mathbf{P}}_{t+1}^{-1})^{-1}( \mathbf{h}_{t+1}-\bar{\mathbf{h}}_{t+1})\\ \mathbf{A}^{\top}\mathbf{S}_{t+1}\mathbf{A}\end{pmatrix}\] (110) \[=\bm{\alpha}_{t}+\bm{\beta}_{t+1}\] (111)

where \(\mathbf{S}_{t+1}=\mathbf{Q}^{-1}-\mathbf{Q}^{-1}(\mathbf{Q}^{-1}+\mathbf{P}_{t+ 1}^{-1}-\bar{\mathbf{P}}_{t+1}^{-1})^{-1}\mathbf{Q}^{-1}\).

Forward KL fixed point

Using the moment matching property of the fixed point solution to the forward KL objective, we can write

\[\bar{\bm{\mu}}_{t+1}^{*} =\int t(\mathbf{z}_{t+1})\operatorname{\mathbb{E}}_{q_{t}}\left[p_{ \bm{\theta}}(\mathbf{z}_{t+1}\,|\,\mathbf{z}_{t})\right]\mathrm{d}\mathbf{z}_{t+1}\] (112) \[=\int t(\mathbf{z}_{t+1})\] (113) \[\quad\times\left[\int h(\mathbf{z}_{t})h(\mathbf{z}_{t+1}) \exp\left(t(\mathbf{z}_{t+1})^{\top}\bm{\lambda}_{\bm{\theta}}(\mathbf{z}_{t}) +t(\mathbf{z}_{t})^{\top}\bm{\lambda}_{t}-A(\bm{\lambda}_{t})-A(\bm{\lambda}_ {\bm{\theta}}(\mathbf{z}_{t}))\right)\mathrm{d}\mathbf{z}_{t}\right]\mathrm{d }\mathbf{z}_{t+1}\] \[=\int h(\mathbf{z}_{t})\exp\left(t(\mathbf{z}_{t})^{\top}\bm{ \lambda}_{t}-A(\bm{\lambda}_{t})\right)\] (114) \[\quad\times\left[\int t(\mathbf{z}_{t+1})h(\mathbf{z}_{t+1}) \exp\left(t(\mathbf{z}_{t+1})^{\top}\bm{\lambda}_{\bm{\theta}}(\mathbf{z}_{t} )-A(\bm{\lambda}_{\bm{\theta}}(\mathbf{z}_{t}))\right)\mathrm{d}\mathbf{z}_{t +1}\right]\mathrm{d}\mathbf{z}_{t}\] \[=\operatorname{\mathbb{E}}_{q_{t}}\left[\bm{\mu}_{\bm{\theta}}( \mathbf{z}_{t})\right]\] (115)

This result holds for any setting where stochastic transitions, \(p_{t+1|t}\), and the approximate marginal distributions, \(q_{t}\), are restricted to the same exponential family distribution.

## Appendix H Linear Gaussian (information form) smoothing

Using the derived relation,

\[\mathbf{P}_{t}^{-1}=\bar{\mathbf{P}}_{t}^{-1}+\mathbf{C}^{\top} \mathbf{R}^{-1}+\mathbf{F}^{\top}\mathbf{S}_{t+1}\mathbf{F}\] (116)

means that,

\[\mathbf{P}_{t}^{-1}-\bar{\mathbf{P}}_{t}^{-1}=\mathbf{C}^{\top} \mathbf{R}^{-1}\mathbf{C}+\mathbf{F}^{\top}\mathbf{S}_{t+1}\mathbf{F}\] (117)

so that using the definition of \(\mathbf{S}_{t}\) (rewritten for convenience) then plugging in, we get,

\[\mathbf{S}_{t} =\mathbf{Q}^{-1}-\mathbf{Q}^{-1}(\mathbf{Q}^{-1}+\mathbf{P}_{t}^ {-1}-\bar{\mathbf{P}}_{t}^{-1})^{-1}\mathbf{Q}^{-1}\] (118) \[=\mathbf{Q}^{-1}-\mathbf{Q}^{-1}(\mathbf{Q}^{-1}+\mathbf{C}^{ \top}\mathbf{R}^{-1}\mathbf{C}+\mathbf{F}^{\top}\mathbf{S}_{t+1}\mathbf{F}) \mathbf{Q}^{-1}\] (119)

which gives a recurrence backward in time for \(\mathbf{S}_{1:T}\) starting from \(\mathbf{S}_{T+1}=\mathbf{0}\). Now since,

\[\mathbf{h}_{t}-\bar{\mathbf{h}}_{t}=\mathbf{F}^{\top}\mathbf{Q} ^{-1}(\mathbf{Q}^{-1}+\mathbf{P}_{t+1}^{-1}-\bar{\mathbf{P}}_{t+1}^{-1})^{-1}( \mathbf{h}_{t+1}-\bar{\mathbf{h}}_{t+1})\] (120)

and,

\[(\mathbf{Q}^{-1}+\mathbf{C}^{\top}\mathbf{R}^{-1}\mathbf{C}+ \mathbf{F}^{\top}\mathbf{S}_{t+1}\mathbf{F})^{-1}=\mathbf{Q}-\mathbf{Q} \mathbf{S}_{t}\mathbf{Q}\] (121)

we have that,

\[\mathbf{F}^{\top}\mathbf{s}_{t}=\mathbf{F}^{\top}\mathbf{Q}^{-1} (\mathbf{Q}^{-1}+\mathbf{C}^{\top}\mathbf{R}^{-1}\mathbf{C}+\mathbf{F}^{\top} \mathbf{S}_{t+1}\mathbf{F})^{-1}(\mathbf{C}^{\top}\mathbf{R}^{-1}\mathbf{y}_{t+ 1}+\mathbf{F}^{\top}\mathbf{s}_{t+1})\] (122)

which simplifies into a recursion for \(\mathbf{s}_{1:T}\) backward in time starting from \(\mathbf{s}_{T+1}=\mathbf{0}\), given by,

\[\mathbf{s}_{t} =\mathbf{Q}^{-1}(\mathbf{Q}^{-1}+\mathbf{C}^{\top}\mathbf{R}^{-1} \mathbf{C}+\mathbf{F}^{\top}\mathbf{S}_{t+1}\mathbf{F})^{-1}(\mathbf{C}^{\top} \mathbf{R}^{-1}\mathbf{y}_{t+1}+\mathbf{F}^{\top}\mathbf{s}_{t+1})\] (123) \[=(\mathbf{I}-\mathbf{S}_{t}\mathbf{Q})(\mathbf{C}^{\top}\mathbf{R} ^{-1}\mathbf{y}_{t+1}+\mathbf{F}^{\top}\mathbf{s}_{t+1})\] (124)

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: we try to clearly state our contributions. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: We discuss potential limitations of the work. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: We list assumptions about the types of generative models we consider. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.

* All assumptions should be clearly stated or referenced in the statement of any theorems.
* The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.
* Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.
* Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: We provide experimental details in the appendix that include the architectures and training regimes. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: We provide sufficient instructions and algorithmic details. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.

* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: We provide details about splits, optimization, and parameterizations in the appendix. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: We discuss the neuroscientific implications of the results our model could be used to discover from neural data. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors). * It should be clear whether the error bar is the standard deviation or the standard error of the mean. * It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified. * For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). * If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.

8. **Experiments Compute Resources** Question: we provide our computing setup. Answer: [Yes] Justification: We provide the specifications of our computing setup. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: we adhere to the code of ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: We discuss the broader impacts. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. * If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA]Justification: the paper poses no such risks Guidelines:

* The answer NA means that the paper poses no such risks.
* Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.
* Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.
* We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
* **License for existing assets*
* Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: we produced all code to run the experiments, we cite real data from where they were procured. Guidelines:
* The answer NA means that the paper does not use existing assets.
* The authors should cite the original paper that produced the code package or dataset.
* The authors should state which version of the asset is used and, if possible, include a URL.
* The name of the license (e.g., CC-BY 4.0) should be included for each asset.
* For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.
* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: the paper does not release new assets Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: This paper does not involve crowdsourcing or human subjects. Guidelines:* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: this paper does not involve human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.