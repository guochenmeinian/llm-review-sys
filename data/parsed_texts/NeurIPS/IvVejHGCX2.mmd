# An undetectable watermark for generative image models

Sam Gunn

UC Berkeley

Equal contribution. Email addresses: gunn@berkeley.edu xuandongzhao@berkeley.edu

Xuandong Zhao

UC Berkeley

&Dawn Song

UC Berkeley

###### Abstract

We present the first undetectable watermarking scheme for generative image models. _Undetectability_ ensures that no efficient adversary can distinguish between watermarked and un-watermarked images, even after making many adaptive queries. In particular, an undetectable watermark does not degrade image quality under any efficiently computable metric. Our scheme works by selecting the initial latents of a diffusion model using a pseudorandom error-correcting code (Christ and Gunn, 2024), a strategy which guarantees undetectability and robustness. We experimentally demonstrate that our watermarks are quality-preserving and robust using Stable Diffusion 2.1. Our experiments verify that, in contrast to _every prior scheme_ we tested, our watermark does not degrade image quality. Our experiments also demonstrate robustness: existing watermark removal attacks fail to remove our watermark from images without significantly degrading the quality of the images. Finally, we find that we can robustly encode 512 bits in our watermark, and up to 2500 bits when the images are not subjected to watermark removal attacks.

## 1 Introduction

As AI-generated content grows increasingly realistic, so does the threat of AI-generated disinformation. AI-generated images have already appeared online in attempts to influence politics (Ryan-Mosley, 2023). Watermarking has the potential to mitigate this issue: If AI providers embed watermarks in generated content, then that content can be flagged using the watermarking key. Recognizing this, governments have begun putting pressure on companies to implement watermarks (Biden, 2023; California State Legislature, 2024; European Union, 2024). However, despite an abundance of available watermarking schemes in the literature, adoption has remained limited (Seetharaman and Barnum, 2023). There are at least a few potential explanations for this.

First, some clients are willing to pay a premium for un-watermarked content. For instance, a student using generative AI for class might find a watermark problematic. Any company implementing a watermark could therefore put itself at a competitive disadvantage.

Second, existing watermarking schemes noticeably degrade the quality of generated content. Some schemes guarantee that the distribution of a _single_ response is unchanged, but introduce correlations across generations.1 While this might be acceptable for small models, it is questionable whether anyone would be willing to use such a watermark for a model that cost over $100 million just to train (Knight, 2023). In other words, given the vast effort put into optimizing models, any observable change in the model's behavior is probably unacceptable.

Footnote 1: One scheme with this guarantee is to fix the randomness of the sampling algorithm, so that the model can only generate one unique response for each prompt.

**Undetectable watermarks.**_Undetectability_, originally defined in the context of watermarking by Christ et al. (2024), addresses both of these issues. For an undetectable watermark, it is computationally infeasible for anyone who doesn't hold the detection key to distinguish generations with the watermark from generations without -- even if one is allowed to make many adaptive queries. Crucially, an undetectable watermark provably preserves quality under any efficiently-computable metric, including quality metrics that are measured across many generations (such as FID (Heuselet al., 2017), CLIP (Radford et al., 2021) and Inception Score (Salimans et al., 2016) for images). Therefore one can confidently use an undetectable watermark without any concern that the quality might degrade. And if the detection key is kept sufficiently private, then the competitive disadvantage to using the watermark can be minimized: One can give the detection key only to mass distributors of information (like Meta and X), so that broad dissemination of AI-generated disinformation can be filtered without interfering in users' personal affairs. Since only the mass information distributors would be able to detect the watermark, it would not harm the value of the content except to bad actors.

**The PRC watermark.** In this paper, we introduce the first undetectable2 watermarking scheme for image generation models. Our scheme works for latent diffusion models (Rombach et al., 2022), with which we generate watermarked images by progressively de-noising initial watermarked noise within the latent space. The key component in our scheme is a pseudorandom error-correcting code, or pseudorandom code (PRC), a cryptographic object introduced by Christ and Gunn (2024). We therefore refer to our scheme as the **PRC watermark** in this work.

Footnote 2: See Appendix E.3 for a discussion of the extent to which our scheme is cryptographically undetectable for various choices of parameters.

At a high level, a PRC allows us to embed a _cryptographically pseudorandom pattern_ that is robustly distributed across the entire latent space, ensuring that the watermark operates at a semantic level. The fact that our watermark is embedded at the semantic level, combined with the PRC's error-correcting properties, makes our watermark highly robust -- especially to pixel-level watermark removal attacks (Zhao et al., 2023).

Additionally, since the PRC from Christ and Gunn (2024) can be used to encode and decode messages, we can _robustly embed large messages_ within the PRC watermark. While the decoder is somewhat less robust than the detector, the detector can still be effectively used in cases where the decoder fails.

Finally, the PRC watermark is highly flexible, requiring no additional model training or fine-tuning, and can be seamlessly incorporated into existing diffusion model APIs. It allows the user to independently set the message length and a desired upper bound on the false positive rate (FPR) at the time of watermark key generation. The false positive rate is rigorous, rather than empirical: If the user sets the desired upper bound on the false positive rate to \(F\), then we prove in Theorem 2 that the false positive rate will not exceed \(F\).

**Results.** Experiments on quality and detectability are presented in Section 3.1. We emphasize that undetectability theoretically ensures quality preservation, and our scheme is undetectable by the results of Christ and Gunn (2024). Therefore we perform experiments on quality and detectability only to ensure that our scheme is secure enough with our finite choice of parameters.

We demonstrate the undetectability of our scheme in three key ways:

* We show in Table 1 that the quality, as measured by the FID, CLIP, and Inception Score, are all preserved by the PRC watermark. This is in contrast to **every other scheme we tested**.
* We show in Table 2 that the perceptual variability of responses, as measured by the LPIPS score (Zhang et al., 2019), is preserved under the PRC watermark. This is in contrast to **every other comparable scheme we tested**.
* We show in Figure 1 that an image classifier fails to learn to detect the PRC watermark. The same image classifier quickly learns to detect **every other scheme we tested**.

We demonstrate the robustness of our scheme in Section 3.2. We find that watermark removal attacks fail to remove the PRC watermark without significantly degrading the quality of the image. We test the robustness under ten different types of watermark removal attacks with varying strengths and compare PRC watermark to eight different state-of-the-art watermarking schemes. Among the three watermarking schemes with the lowest impact on image quality,3 the PRC watermark is the most robust to all attacks.

Footnote 3: These are the DwtDct, DwtDctSvd, and PRC watermarks.

Finally, we show in Section 3.2 that the PRC watermark can be used to encode and decode long messages in generated images. The encoding algorithm is exactly the same, except that the user passes it a message, and the scheme remains heuristically undetectable. These messages could be used to encode, for instance, timestamps, user IDs, digital signatures, or model specifications. We find in Figure 10 that the robustness of the decoder for 512-bit messages is comparable to, although slightly less than, the robustness of the detector. For non-attacked images, we show in Figure 11 that we can increase the message capacity to at least 2500 bits.

Due to space limitations, the discussion of related work is deferred to Appendix A.

## 2 Method

Threat model.We consider a setting where users make queries to a provider, and the provider responds to these queries with images produced by some image generation model. In watermarking, the provider holds a _watermarking key_ that is used to sample from a modified, _watermarked_ distribution over images. Anyone holding the watermarking key can, with high probability, distinguish between samples from the un-watermarked distribution and the watermarked distribution. Since the watermark may be undesirable to some users, some of them may attempt to remove the watermark. We are therefore interested in _robust_ watermarks, for which watermark detection still functions even when the image is subjected to a watermark removal attack. We assume that the adversary performing such a removal attack is restricted in two ways. First, the adversary should have weaker capabilities than the provider. If the adversary can generate their own images of high quality, then they don't need to engage in watermark removal attacks. Second, we are only interested in adversaries that produce high-quality images after the removal attack. If removal attacks require significantly degrading the quality of the image, then there is incentive to leave the watermark. We are also interested in _spoofing attacks_, whereby an adversary who doesn't know the watermarking key attempts to add a watermark to an un-watermarked image. We only perform limited experiments on spoofing attacks, so we do not discuss the adversarial capabilities here. However, we note that our techniques, together with the ideas on unforgeable public attribution from Christ and Gunn (2024), immediately yield a scheme that is provably resilient to spoofing attacks.

### Overview of the PRC watermark

Image generation and randomness recovery.Before describing our watermarking scheme, let us establish some notation. Let Generate be a randomized algorithm that takes as input (1) a prompt string \(\bm{\pi}\in\Sigma^{*}\) over some alphabet \(\Sigma\) and (2) a standard Gaussian in \(\mathbb{R}^{n}\), and produces an output in \(\mathbb{R}^{d}\). Our method applies to any such algorithm, but in this work, we are interested in the case that \(\mathsf{Generate}\) is a generative image model taking prompts in \(\Sigma^{*}\) and initial (random) latents in \(\mathbb{R}^{n}\) to images in \(\mathbb{R}^{d}\).

Some of the most popular generative image models today are latent diffusion models (Rombach et al., 2022), which consist of a diffusion model specified by a de-noising neural network \(\epsilon\), a (possibly-randomized) function \(f_{\epsilon}\) depending on \(\epsilon\), a number of diffusion iterations \(T\), and an autoencoder \((\mathcal{E},\mathcal{D})\). For a latent diffusion model, \(\mathsf{Generate}\) works as follows.

**Algorithm**\(\mathsf{Generate}(\bm{\pi},\bm{z}^{(T)}):\)

1. For \(i=T\) down to 1:
2. \(\bm{z}^{(i-1)}\gets f_{\epsilon}(\bm{\pi},\bm{z}^{(i)},i)\)
3. \(\bm{x}\leftarrow\mathcal{D}(\bm{z}^{(0)})\)
4. **Output**\(\bm{x}\)

In words, \(\mathsf{Generate}\) works by starting with a normally distributed latent and iteratively de-noising it. The de-noised latent is then decoded by the autoencoder. In order to produce an image for the prompt \(\bm{\pi}\) using \(\mathsf{Generate}\), we use \(\mathsf{Sample}\) defined as follows.

**Algorithm**\(\mathsf{Sample}(\bm{\pi}):\)

1. Sample \(\bm{z}^{(T)}\sim\mathcal{N}(0,\bm{I}_{n})\)
2. Compute \(\bm{x}\leftarrow\mathsf{Generate}(\bm{\pi},\bm{z}^{(T)})\)
3. **Output**\(\bm{x}\)Detection of the watermark will rely on a separate algorithm, Recover, that recovers an approximation of the latent in \(\mathbb{R}^{n}\) from a given image \(\bm{x}\in\mathbb{R}^{d}\). For latent diffusion models, the key component in Recover is an _inverse diffusion process_\(\delta\) that attempts to invert \(\epsilon\) without knowledge of the text prompt \(\bm{\pi}\). There is also some (possibly-randomized) function \(g_{\delta}\) that determines how \(\delta\) is used to perform each update.

**Algorithm**\(\mathsf{Recover}(\bm{x})\) :

1. Compute an initial estimate \(\bm{z}^{(0)}\leftarrow\mathcal{E}(\bm{x})\) of the de-noised latent.4 Footnote 4: In fact, the algorithm of Hong et al. (2023) further uses gradient descent on \(\bm{z}^{(0)}\) to minimize \(\|\mathcal{D}(\bm{z}^{(0)})-\bm{x}\|\), initializing with \(\bm{z}^{(0)}=\mathcal{E}(\bm{x})\). They call this “decoder inversion,” and it significantly reduces the recovery error.
2. For \(i=0\) to \(T-1\):
3. \(\bm{z}^{(i+1)}\gets g_{\delta}(\bm{z}^{(i)},i)\)
4. **Output**\(\bm{z}^{(T)}\)

There has been increasing interest in tracing the diffusion model generative process back (Recover). Diffusion inversion has been important for various applications such as image editing (Hertz et al., 2022) and style transfer (Zhang et al., 2023). A commonly used method for reversing the diffusion process is Denoising Diffusion Implicit Models (DDIM) (Song et al., 2021) inversion, which leverages the formulation of the denoising process in diffusion models as an ordinary differential equation (ODE). However, the result of DDIM inversion, \(\bm{z}^{(T)}\), is an approximation even when the input text is known. For our implementation of Generate, we employ Stable Diffusion with DPM-solvers (Lu et al., 2022) for sampling. In our implementation of Recover, we adopt the exact inversion method proposed in Hong et al. (2023) for more accurate inversion.

Embedding and detecting the watermark.Our watermarking scheme works by passing to Generate a vector \(\tilde{\bm{z}}^{(T)}\) which is computationally indistinguishable from a sample from \(\mathcal{N}(\bm{0},\bm{I}_{n})\). To sample \(\tilde{\bm{z}}^{(T)}\), we rely on a cryptographic object called a pseudorandom code (PRC), introduced by Christ and Gunn (2024). A PRC is a keyed error-correction scheme with the property that any polynomial number of encoded messages are jointly indistinguishable from random strings. For watermarking, it suffices to use a _zero-bit_ PRC which only encodes the message '1.' If one wishes to encode long messages in the watermark, we can do this as well; see Appendix E for details on how this is accomplished. For simplicity we focus on the zero-bit case in this section.

Our PRC consists of four algorithms, given in Appendix D:

* \(\mathsf{PRC}.\mathsf{KeyGen}(n,F,t)\) samples a PRC key \(\mathsf{k}\), which will also serve as the watermarking key. The parameter \(n\) is the block length, which in our case is the dimension of the latent space; \(F\) is the desired false positive rate; and \(t\) is a parameter which may be increased for improved undetectability at the cost of robustness.
* \(\mathsf{PRC}.\mathsf{Encode}_{\mathsf{k}}\) samples a PRC codeword.
* \(\mathsf{PRC}.\mathsf{Detect}_{\mathsf{k}}(\bm{c})\) tests whether the given string \(\bm{c}\) came from the PRC.
* \(\mathsf{PRC}.\mathsf{Decode}_{\mathsf{k}}(\bm{c})\) decodes the message from the given string \(\bm{c}\), if it exists. The decoder is slower and less robust than the detector.

As our PRC, we use the LDPC construction from Christ and Gunn (2024), modified to handle soft decisions. Essentially, this PRC works by sampling random \(t\)-sparse parity checks and using noisy solutions to the parity checks as PRC codewords. For appropriate choices of parameters, Christ and Gunn (2024) prove that this distribution is cryptographically pseudorandom. We describe how the PRC works in detail in Appendix D, and we describe our watermarking algorithms in detail in Appendix E.

To set up our robust and undetectable watermark, we simply sample a key \(\mathsf{k}\) using \(\mathsf{PRC}.\mathsf{KeyGen}\). To sample a watermarked image, we choose \(\tilde{\bm{z}}^{(T)}\) to be a sample from \(\mathcal{N}(\bm{0},\bm{I}_{n})\)_conditioned on having signs chosen according to the PRC_ and then apply Generate. In more detail, we sample \(\tilde{\bm{z}}^{(T)}\) using the following algorithm.

**Algorithm**\(\mathsf{PRCWat.Sample_{k}}(\bm{\pi}):\)

1. Sample a PRC codeword \(\bm{c}\in\{-1,1\}^{n}\) using \(\mathsf{PRC.Encode}(\mathsf{k})\)
2. Sample \(\bm{y}\sim\mathcal{N}(\bm{0},\bm{I}_{n})\)
3. Let \(\tilde{\bm{z}}^{(T)}\in\mathbb{R}^{n}\) be the vector defined by \(\tilde{z}_{i}^{(T)}=c_{i}\cdot|y_{i}|\) for all \(i\in[n]\)
4. Compute \(\bm{x}\leftarrow\mathsf{Generate}(\bm{\pi},\tilde{\bm{z}}^{(T)})\)
5. **Output \(\bm{x}\)**

For a full description of the algorithm, see Algorithm 6.

Since the signs of \(\bm{z}^{(T)}\sim\mathcal{N}(\bm{0},\bm{I}_{n})\) are uniformly random, the pseudorandomness of the PRC implies that any polynomial number of samples \(\tilde{\bm{z}}^{(T)}\) in \(\mathsf{PRCWat.Sample}\) are indistinguishable from samples \(\bm{z}^{(T)}\sim\mathcal{N}(\bm{0},\bm{I}_{n})\). As \(\mathsf{Generate}\) is an efficient algorithm, this yields Theorem 1, which says that our watermarking scheme is undetectable against \(\mathsf{poly}(n)\)-time adversaries for latent space of dimension \(n\), as long as the underlying PRC is.

**Theorem 1** (Undetectability).: _Let \(\mathsf{PRC}\) be any PRC, and let \(\mathsf{PRCWat.Sample}\) be as defined above. Then for any efficient algorithm \(\mathcal{A}\) and any \(c>0\),_

\[\left|\operatorname*{Pr}_{\mathsf{k}\sim\mathsf{PRC}.\mathsf{KeyGen}}[ \mathcal{A}^{\mathsf{PRCWat.Sample_{k}}}(1^{n})=1]-\Pr\bigl{[}\mathcal{A}^{ \mathsf{Sample}}(1^{n})=1]\right|\leq\frac{1}{2}+O(n^{-c}).\]

The notation \(\mathcal{A}^{\mathcal{O}}(1^{n})\) means that \(\mathcal{A}\) is allowed to run in any time that is polynomial in \(n\), making an arbitrary number of queries to \(\mathcal{O}\). For our experiments, we do not strictly adhere to the parameter bounds required for the pseudorandomness proof of Christ and Gunn (2024) to hold; as a result of this and the fact that we use small finite choices of parameters, our scheme should not be used for undetectability-critical applications. See Appendix E.3 for a discussion on this point.

To detect the watermark with the watermarking key, we use (roughly) the following algorithm. As long as \(\mathsf{Recover}\) reproduces a good enough approximation to the latent that was originally used to generate an image, \(\mathsf{PRCWat.Detect}\) will recognize the watermark.

**Algorithm**\(\mathsf{PRCWat.Detect_{k}}(\bm{x}):\)

1. Compute \(\bm{z}^{(T)}\leftarrow\mathsf{Recover}(\bm{x})\)
2. Let \(\bm{c}\) be the vector of signs of \(\bm{z}^{(T)}\)
3. Compute \(\operatorname*{result}\leftarrow\mathsf{PRC.Detect_{k}}(\bm{c})\)
4. **Output**\(\operatorname*{result}\)

For our actual detector, we use a slightly more complicated algorithm that accounts for the fact that coordinates of \(\bm{z}^{(T)}\) with larger magnitude are more reliable. The complete algorithm is given in Algorithm 7.

It turns out that, for low error rates, the PRC from Christ and Gunn (2024) can be used to encode and decode long messages using an algorithm called _belief propagation_. We can therefore include long messages in our watermark. Our algorithm for decoding the message from an image is \(\mathsf{PRCWat.Decode}\), described in Algorithm 8. \(\mathsf{PRCWat.Decode}\) is slower and less robust than \(\mathsf{PRCWat.Detect}\), but we find that it still achieves an interesting level of robustness.

Finally, our PRC watermark allows the user to set a desired false positive rate, \(F\). We prove Theorem 2, which says that our PRC watermark detector has false positive rate at most \(F\), in Appendix E.2.

**Theorem 2** (False positive rate).: _Let \(n,t\in\mathbb{N}\) and \(F>0\). For any image \(\bm{x}\),_

\[\operatorname*{Pr}_{\mathsf{k}\sim\mathsf{PRCWat.KeyGen}(n,F,t)}[\mathsf{PRCWat.Detect_{k}}(\bm{x})=\mathsf{True}]\leq F\]

_and_

\[\operatorname*{Pr}_{\mathsf{k}\sim\mathsf{PRCWat.KeyGen}(n,F,t)}[\mathsf{PRCWat.Decode_{k}}(\bm{x})\neq\mathsf{None}]\leq F.\]

In words, Theorem 2 says that any image generated independently of the watermarking key has at most a probability of \(F\) of being identified as "watermarked" by our watermark detector or decoder.

## 3 Experiments

Experiment overview.Our experiments focus on text-to-image latent diffusion models, primarily using the Stable Diffusion framework (Rombach et al., 2022). We evaluate various watermarking schemes with Stable Diffusion-v2.15. Images are generated at a resolution of 512\(\times\)512 with 50 steps using DPMSolver (Lu et al., 2022), applying a classifier-free guidance scale of 3.0. PRC watermarking and VAE models (Kingma and Welling, 2013) are explored in Appendix F, utilizing the inversion method from Hong et al. (2023). All experiments are conducted on NVIDIA H100 GPUs. We compare post-processing methods like DwtDct (Al-Haj, 2007), StegaStamp (Tancik et al., 2020), SSL Watermark (Fernandez et al., 2022), and others, along with in-processing methods like Stable Signature (Fernandez et al., 2023) and Gaussian Shading (Yang et al., 2024). Bit-length varies from 32 to 96, and we encode 512 random bits for PRC. Baseline methods use publicly available code with default parameters. Figure 4 shows visual examples. Watermarking is evaluated on MS-COCO (Lin et al., 2014) and the Stable Diffusion Prompt dataset.6 We generate 500 images and assess effectiveness (TPR@FPR=0.01), image quality, robustness, and detectability. PRC watermark achieves TPR=1.0@FPR=0.01. For a more detailed description of the experiment setup, please refer to Appendix B.

Footnote 5: https://huggingface.co/stabilityai/stable-diffusion-2-1-base

Footnote 6: https://huggingface.co/datasets/Gustavosta/Stable-Diffusion-Prompts

### Quality and detectability

To evaluate the image quality of watermarked images, we compute the Frechet Inception Distance (FID) (Heusel et al., 2017), CLIP Score (Radford et al., 2021), and Inception Score (Salimans et al., 2016) to measure the distance between generated watermarked and un-watermarked images, and between watermarked and real images. For our comparison to real images, we use the MS-COCO-2017 training set; for the comparison to un-watermarked images, we use 8,000 images generated by the un-watermarked diffusion model using prompts from the SDP dataset. We calculate FID and CLIP Scores over five-fold cross-validation and report the mean and standard error. To assess perceptual variability (diversity), we select 10 diverse prompts from the PromptHero website7 and use different in-processing watermark methods to generate 100 images for each prompt. We calculate perceptual similarity for all image pairs using the LPIPS (Zhang et al., 2019) score, averaging the results over the 10 prompts and reporting the standard error. Higher LPIPS scores indicate better variability for a given prompt. This evaluation is essential since, for image generation tasks, users typically generate multiple images from a single prompt and then select the best one (e.g., Midjourney).

\begin{table}
\begin{tabular}{l c c c c c} \hline \hline \multirow{2}{*}{**Watermark**} & \multicolumn{3}{c}{**COCO Dataset**} & \multicolumn{3}{c}{**Stable Diffusion Prompts Dataset**} \\ \cline{2-6}  & **FID \(\downarrow\)** & **CLIP Score \(\uparrow\)** & **Inception Score \(\uparrow\)** & **FID \(\downarrow\)** & **CLIP Score \(\uparrow\)** & **Inception Score \(\uparrow\)** \\ \hline Original & 76.3987\({}_{0.1419}\) & 0.47929\({}_{0.0022}\) & 17.5438\({}_{0.1229}\) & 63.4625\({}_{0.2577}\) & 0.6119\({}_{0.0031}\) & 7.4903\({}_{0.0031}\) \\ DwtDct & 76.5676\({}_{0.2217}\) & 0.47010\({}_{0.0022}\) & 17.4686\({}_{0.1283}\) & 61.6912\({}_{0.2583}\) & 0.6674\({}_{0.0031}\) & 7.1336\({}_{0.0031}\) \\ DwtDct & 76.3322\({}_{0.2799}\) & 0.47270\({}_{0.0022}\) & 17.4328\({}_{0.1483}\) & 61.4763\({}_{0.2107}\) & 0.5949\({}_{0.0016}\) & 7.1253\({}_{0.0004}\) \\ RivRGAN & 77.7440\({}_{0.1400}\) & 0.4719\({}_{0.0003}\) & 17.2602\({}_{0.1283}\) & 65.7114\({}_{0.1284}\) & 6.6964\({}_{0.0047}\) & 7.1258\({}_{0.0046}\) \\ StegaStamp & 79.8856\({}_{0.2016}\) & 0.4638\({}_{0.0023}\) & 16.8832\({}_{0.1307}\) & 66.8853\({}_{0.2013}\) & 61.0308\({}_{0.0155}\) & 6.3343\({}_{0.1053}\) \\ SSL & 77.9349\({}_{0.2470}\) & 0.47010\({}_{0.0014}\) & 17.1920\({}_{0.1277}\) & 65.0303\({}_{0.0034}\) & 6.0694\({}_{0.0046}\) & 7.0923\({}_{0.0022}\) \\ \hline Stable Signature & 78.2577\({}_{0.3333}\) & 0.47010\({}_{0.0014}\) & 16.5785\({}_{0.1317}\) & 77.2162\({}_{0.2583}\) & 0.5941\({}_{0.0031}\) & 61.312\({}_{0.1229}\) \\ Tree-Ring & 77.3445\({}_{0.1733}\) & 0.4795\({}_{0.0031}\) & 17.3988\({}_{0.1999}\) & 67.8192\({}_{0.1379}\) & 6.5964\({}_{0.1032}\) & 7.4178\({}_{0.0040}\) \\ Gaussian Shading & 77.927\({}_{0.148}\) & 0.4766\({}_{0.0023}\) & 17.0650\({}_{0.0022}\) & 0.9333\({}_{0.1227}\) & 0.6132\({}_{0.0013}\) & 7.3035\({}_{0.0732}\) \\ \hline PRC & 76.5978\({}_{0.247}\) & 0.4773\({}_{0.0003}\) & 17.4734\({}_{0.4477}\) & 64.7578\({}_{0.3001}\) & 64.1666\({}

Table 1 presents the empirical results for FID, CLIP, and Inception Scores for different watermarking schemes on both the COCO and SDP datasets. The table compares original image quality, post-processing watermark quality, and in-processing watermark quality (separated by dashed lines). We observe that StegaStamp results in the most significant quality degradation among post-processing watermark schemes, and the PRC watermark is the only method that consistently preserves image quality across all three metrics on both datasets. Table 2 presents the results of the variability analysis. Since post-processing methods are expected to have minimal impact on image variability, they are excluded from this table. The PRC watermark demonstrates variability comparable to un-watermarked images, outperforming the other in-processing schemes in this regard.

To evaluate detectability, we use ResNet18 (He et al., 2016) as the backbone model and train it on 7,500 un-watermarked images and 7,500 watermarked images (or 7,500 images watermarked with key 1 and 7,500 with key 2) to perform binary classification. Each experiment tests different watermarking schemes, with results shown in Figure 1. For the PRC watermark, the neural network slowly converges to perfect detection on the training set but achieves only 50% accuracy (random guess) on the validation set, indicating that the network is memorizing the training samples rather than learning the watermark pattern. In contrast, for all other schemes, the network performs perfectly on the validation set, demonstrating that the watermark is learnable.

### Robustness of the Detector

To comprehensively evaluate the robustness of the PRC watermark and compare it to baseline watermarking methods, we tested nine distinct watermarking techniques against ten different types of attacks. Detailed descriptions of the attack configurations can be found in Appendix C.1.

The robustness of the various watermarking methods under these attacks is shown in Figure 5. We evaluated the quality of the attacked images using PSNR, SSIM, and FID metrics, comparing them to the original watermarked images. Notably, the PRC watermark demonstrates high resilience to most attacks. Even under sophisticated attacks, no method successfully reduced the true positive rate (TPR) below 0.99 while keeping the FID score under 70. This demonstrates that current watermark removal techniques struggle to erase our watermark without significantly degrading image quality. For instance, as shown in Figure 5, a JPEG compression attack with a quality factor of 20 only reduced the TPR from 1.0 to 0.94, but the resulting images displayed noticeable blurriness and a loss of detail (see Figure 3). Finally, in Figure 7 we demonstrate increased robustness for \(t=2\).8 However, for \(t=2\) there exist fast attacks on the undetectability of the PRC watermark, so we do not explore this choice further.

Footnote 8: For our other experiments we set \(t=3\). See Appendix D for details on the meaning of the parameter \(t\).

Encoding long messages in the watermark.The use of a PRC allows us to embed long messages in our watermarks, as described in Appendix E. We find in Figure 10 that the decoder is highly robust for 512-bit messages, although the detector is slightly more robust in this case. We find in Figure 11 that the decoder can reliably recover up to 2500 bits of information if the images are not subjected to removal attacks.

Figure 1: Top: Training a model to detect the watermark without the key. Bottom: Training a model to distinguish between watermarked images generated with different watermarking keys.

Security of the PRC watermark under spoofing attacks.To test the spoofing robustness of different watermarks, we followed the approach in Saberi et al. (2023), aiming to classify non-watermarked images as watermarked (increasing the false positive rate). Spoofing attacks can damage the reputation of generative model developers by falsely attributing watermarks to images. We used a PGD-based (Madry et al., 2018) method similar to that of the surrogate model adversarial attacks, flipping the surrogate model's prediction from un-watermarked to watermarked. Just as with the adversarial surrogate attack, this attack cannot work against any undetectable watermark such as PRC watermark.

Possibility of extension.The PRC watermark can also be applied to other generative models, particularly those sampling from Gaussian distributions. We have set up a demo experiment working for traditional VAE models, as detailed in Appendix F. We would also be interested to see the PRC watermark applied to emerging generative models such as Flow matching (Lipman et al., 2022); whether or not this is possible hinges only on the existence of a suitable Recover algorithm.

## 4 Conclusion

We give a new approach to watermarking for generative image models that incurs no observable shift in the generated image distribution and encodes long messages. We show that these strong guarantees do not preclude strong robustness: Our watermarks achieve robustness that is competitive with state-of-the-art schemes that incur large, observable shifts in the generated image distribution.

Figure 3: Example images under the JPEG 20 attack with a PSNR of 28.39. Notice the blurriness and lack of detail in the attacked image.

Figure 2: Robustness under the strongest attacks, excluding the embedding attack. We show all points from the corresponding plot in Figure 5 for which there is no other point with a higher FID and TPR. In the figure on the right, we only include the in-processing watermarks. The TPR for the PRC watermark drops after the FID reaches 75; this corresponds to the JPEG 20 attack, of which we give an example in Figure 3.

[MISSING_PAGE_FAIL:9]

* Golowich and Moitra (2024) Noah Golowich and Ankur Moitra. Edit distance robust watermarks for language models. _IACR Cryptol. ePrint Arch._, pp. 898, 2024. URL https://eprint.iacr.org/2024/898.
* He et al. (2016) Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In _Proceedings of the IEEE conference on computer vision and pattern recognition_, pp. 770-778, 2016.
* Hertz et al. (2022) Amir Hertz, Ron Mokady, Jay Tenenbaum, Kfir Aberman, Yael Pritch, and Daniel Cohen-Or. Prompt-to-prompt image editing with cross attention control. _arXiv preprint arXiv:2208.01626_, 2022.
* Heusel et al. (2017) Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. GANs trained by a two time-scale update rule converge to a local nash equilibrium. _Advances in neural information processing systems_, 30, 2017.
* Holt and Nguyen (2023) William Holt and Duy Nguyen. Essential aspects to Bayesian data imputation. _SSRN Electronic Journal_, June 28 2023. Available at SSRN: https://ssrn.com/abstract=4494311 or http://dx.doi.org/10.2139/ssrn.4494311.
* Hong et al. (2023) Seongmin Hong, Kyeonghyun Lee, Suh Yoon Jeon, Hyeon Bae, and Se Young Chun. On exact inversion of DPM-solvers. _CoRR_, abs/2311.18387, 2023. doi: 10.48550/ARXIV.2311.18387. URL https://doi.org/10.48550/arXiv.2311.18387.
* Hostetter (2020) Matt Hostetter. Galois: A performant NumPy extension for Galois fields, 11 2020. URL https://github.com/mhostetter/galois.
* Kingma and Welling (2013) Diederik P. Kingma and Max Welling. Auto-encoding variational bayes. _CoRR_, abs/1312.6114, 2013.
* Knight (2023) Will Knight. OpenAI's CEO says the age of giant AI models is already over. _Wired_, 2023. URL https://www.wired.com/story/openai-ceo-sam-altman-the-age-of-giant-ai-models-is-already-over/.
* Lin et al. (2014) Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollar, and C Lawrence Zitnick. Microsoft COCO: Common objects in context. In _Computer Vision-ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13_, pp. 740-755. Springer, 2014.
* Lipman et al. (2022) Yaron Lipman, Ricky TQ Chen, Heli Ben-Hamu, Maximilian Nickel, and Matt Le. Flow matching for generative modeling. _arXiv preprint arXiv:2210.02747_, 2022.
* Liu et al. (2018) Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Large-scale celebfaces attributes (celeba) dataset. _Retrieved August_, 15(2018):11, 2018.
* Lu et al. (2022) Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu. DPM-solver: A fast ODE solver for diffusion probabilistic model sampling in around 10 steps. _Advances in Neural Information Processing Systems_, 35:5775-5787, 2022.
* Madry et al. (2018) Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. Towards deep learning models resistant to adversarial attacks. _ICLR_, 2018.
* Navas et al. (2008) KA Navas, Mathews Cheriyan Ajay, M Lekshmi, Tampy S Archana, and M Sasikumar. Dwt-dct-svd based watermarking. In _2008 3rd International Conference on Communication Systems Software and Middleware and Workshops (COMSWARE'08)_, pp. 271-274. IEEE, 2008.
* Radford et al. (2021) Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In _International conference on machine learning_, pp. 8748-8763. PMLR, 2021.
* Roffe (2022) Joschka Roffe. LDPC: Python tools for low density parity check codes, 2022. URL https://pypi.org/project/ldpc/.

Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bjorn Ommer. High-resolution image synthesis with latent diffusion models. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pp. 10684-10695, 2022.
* Ryan-Mosley (2023) Tate Ryan-Mosley. How generative AI is boosting the spread of disinformation and propaganda. _MIT Technology Review_, 2023. URL https://www.technologyreview.com/2023/10/04/1080801/generative-ai-boosting-disinformation/. In a new report, Freedom House documents the ways governments are now using the tech to amplify censorship.
* Saberi et al. (2023) Mehrdad Saberi, Vinu Sankar Sadasivan, Keivan Rezaei, Aounon Kumar, Atoosa Chegini, Wenxiao Wang, and Soheil Feizi. Robustness of AI-image detectors: Fundamental limits and practical attacks. In _The Twelfth International Conference on Learning Representations_, 2023.
* Salimans et al. (2016) Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved techniques for training GANs. _Advances in neural information processing systems_, 29, 2016.
* Seetharaman and Barnum (2023) Deepa Seetharaman and Matt Barnum. There's a tool to catch students cheating with ChatGPT. OpenAI hasn't released it. _The Wall Street Journal_, 2023. URL https://www.wsj.com/tech/ai/openai-tool-chatgpt-cheating-writing-135b755a.
* Song et al. (2021) Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. In _International Conference on Learning Representations_, 2021.
* Tancik et al. (2020) Matthew Tancik, Ben Mildenhall, and Ren Ng. StegaStamp: Invisible hyperlinks in physical photographs. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pp. 2117-2126, 2020.
* Wan et al. (2022) Wenbo Wan, Jun Wang, Yunming Zhang, Jing Li, Hui Yu, and Jiande Sun. A comprehensive survey on robust image watermarking. _Neurocomputing_, 488:226-247, 2022.
* 16, 2023_, 2023. URL http://papers.nips.cc/paper_files/paper/2023/hash/b54d1757c190ba20dbc4f9e4a2f54149-Abstract-Conference.html.
* Yang et al. (2024) Zijin Yang, Kai Zeng, Kejiang Chen, Han Fang, Wei Ming Zhang, and Nenghai Yu. Gaussian shading: Provable performance-lossless image watermarking for diffusion models. _CoRR_, abs/2404.04956, 2024. doi: 10.48550/ARXIV.2404.04956. URL https://doi.org/10.48550/arXiv.2404.04956.
* Zhang et al. (2019) Kevin Alex Zhang, Lei Xu, Alfredo Cuesta-Infante, and Kalyan Veeramachaneni. Robust invisible video watermarking with attention. _arXiv preprint arXiv:1909.01285_, 2019.
* Zhang et al. (2024) Lijun Zhang, Xiao Liu, Antoni Viros Martin, Cindy Xiong Bearfield, Yuriy Brun, and Hui Guan. Robust image watermarking using stable diffusion. _arXiv preprint arXiv:2401.04247_, 2024.
* Zhang et al. (2018) Richard Zhang, Phillip Isola, Alexei A. Efros, Eli Shechtman, and Oliver Wang. The unreasonable effectiveness of deep features as a perceptual metric. In _2018 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2018, Salt Lake City, UT, USA, June 18-22, 2018_, pp. 586-595. Computer Vision Foundation / IEEE Computer Society, 2018. doi: 10.1109/CVPR.2018.00068. URL http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_The_Unreasonable_Effectiveness_CVPR_2018_paper.html.
* Zhang et al. (2023) Yuxin Zhang, Nisha Huang, Fan Tang, Haibin Huang, Chongyang Ma, Weiming Dong, and Changsheng Xu. Inversion-based style transfer with diffusion models. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pp. 10146-10156, 2023.
* Zhao et al. (2023) Xuandong Zhao, Kexun Zhang, Zihao Su, Saastha Vasan, Ilya Grishchenko, Christopher Kruegel, Giovanni Vigna, Yu-Xiang Wang, and Lei Li. Invisible image watermarks are provably removable using generative AI. _arXiv preprint arXiv:2306.01953_, 2023.

Related work

There is a rich history of digital watermarking techniques, ranging from conventional steganography to modern methods based on generative models. Following the taxonomy in An et al. (2024), watermarking methods are categorized into two types: post-processing and in-processing schemes.

* **Post-processing schemes** embed the watermark after image generation and have been used for decades due to their broad applicability.
* **In-processing schemes** modify the generative model or sampling process to embed the watermark directly in the generated content.

Our PRC watermark falls under the in-processing category. Note that post-processing watermarks cannot be made undetectable without introducing extra modeling assumptions: One can always distinguish between a fixed image and any modification of it. We refer the reader to surveys (Cox et al., 2008; Wan et al., 2022; An et al., 2024) for more on post-processing methods. Below, we focus on two popular in-processing techniques: Tree-Ring and Gaussian Shading watermarks.

Tree-Ring watermark.Wen et al. (2023) introduced Tree-Ring watermark, the first in-processing watermark that modifies the latent sampling distribution and employs an inverse diffusion process for detection. Our PRC watermark builds on this framework but adopts a different latent distribution. The Tree-Ring watermark works by fixing concentric rings in the Fourier domain of the latent space to be 0. To detect the watermark, one uses DDIM inversion (Song et al., 2021) to estimate the initial latent, and the watermark is considered present if the latent estimate has unusually small values in the watermarked rings. Follow-up works have extended this approach by refining the heuristic latent pattern in the watermarking process (Zhang et al., 2024; Ci et al., 2024). However, under Tree-Ring's strategy, the initial latent significantly deviates from the Gaussian latent distribution, leading to reduced image quality and variability, as shown in Tables 1 and 2. Furthermore, the Tree-Ring watermark is a zero-bit scheme and cannot encode messages. While the Tree-Ring watermark is robust to several attacks, it is highly susceptible to the adversarial surrogate attack since the latent pattern is easy to learn with a neural network. In Figure 5, we find that this attack removes the Tree-Ring watermark with minimal effect on image quality.

Gaussian Shading watermark.The basic Gaussian Shading watermark (Yang et al., 2024) works by choosing a fixed quadrant of latent space as the watermarking key, and only generating images from latents in that quadrant. Detection involves recovering the latent and determining if it lies unusually close to the watermarked quadrant. In their paper, Yang et al. (2024) include a proof that Gaussian Shading has "lossless performance." However, this proof only shows that the distribution of a _single_ watermarked image is the same as that of a single un-watermarked image. Crucially, even standard quality metrics such as the FID (Heusel et al., 2017), CLIP Score (Radford et al., 2021), and Inception Score (Salimans et al., 2016) account for correlations between generated images, so their proof of lossless performance _does not guarantee perfect quality under these metrics_. Indeed, we find in Table 1 that the Gaussian Shading watermark significantly degrades the FID and Inception Score.9 We expand on this by measuring the "variability" of watermarked images. Since images under the Gaussian Shading watermark all come from the same quadrant in latent space, we expect that the variability should be reduced. We use the LPIPS perceptual similarity score (Zhang et al., 2018) to measure the diversity among different watermarked images for a fixed prompt. As shown in Table 2, the perceptual similarity between images is significantly higher with the Gaussian Shading watermark, confirming the diminished variability.

Footnote 9: Table 1 of Yang et al. (2024) appears to show that the FID against the COCO dataset is preserved under Gaussian Shading. However, from their code repository it appears that this table is generated by _re-sampling the watermarking key for every generation_. To be consistent with the intended use case, in this work we use the same random watermarking key to generate many images and compute the quality score.

Undetectability.Undetectable watermarks were initially defined by Christ et al. (2024) in the context of language models. Subsequent to Christ and Gunn (2024), alternative constructions of PRCs have been given by Golowich and Moitra (2024) and Ghentiyala and Guruswami (2024). It would be interesting to see if these PRCs yield improved image watermarks, but we did not investigate this.

More on experiment setup

In our primary experiments, we focus on text-to-image latent diffusion models, utilizing the widely adopted Stable Diffusion framework (Rombach et al., 2022). Specifically, we evaluate the performance of various watermarking schemes using the Stable Diffusion-v2.11 model, a state-of-the-art generative model for high-fidelity image generation. Additionally, we explore applying PRC watermarking to other generative models, as demonstrated with VAE (Kingma and Welling, 2013) models in Appendix F. All images are generated at a resolution of 512\(\times\)512 with a latent space of 4\(\times\)64\(\times\)64. During inference, we apply a classifier-free guidance scale of 3.0 and sample over 50 steps using DPMSolver (Lu et al., 2022). As described in Section 2, we perform diffusion inversion using the exact inversion method from Hong et al. (2023) to obtain the latent variable \(\bm{z}^{(T)}\). In particular, we use 50 inversion steps and an inverse order of 0 to expedite detection, balancing accuracy and computational efficiency. All experiments are conducted on NVIDIA H100 GPUs.

Footnote 11: https://huggingface.co/stabilityai/stable-diffusion-2-1-base

**Watermark baselines.** We conduct comparative evaluations against various watermarking schemes, including in-, and post-processing techniques, as defined in Appendix A. For post-processing methods, we compare with DwtDct (Al-Haj, 2007), DwtDctSvd (Navas et al., 2008), RivaGAN (Zhang et al., 2019), StegaStamp (Tancik et al., 2020), and SSL Watermark (Fernandez et al., 2022). For in-processing methods, we include a comparison with Stable Signature (Fernandez et al., 2023), Tree-Ring (Wen et al., 2023) and Gaussian Shading (Yang et al., 2024). Most baseline methods are designed to embed multi-bit strings within an image. Specifically, we set 32 bits for DwtDctSvd, RivaGAN, and SSL Watermark; 96 bits for StegaStamp; and 48 bits for Stable Signature. We employ publicly available code for each method, using the default inference and fine-tuning parameters specified in original respective papers for post- and in-processing methods. For Tree-Ring and Gaussian Shading watermarks, we use the same diffusion model and inference parameter settings as those used in PRC. We encode 512 random bits in the PRC watermark. If the decoder is successful, then with high probability, the bits are recovered correctly. Figure 4 illustrates examples of different watermarking schemes applied to a specific text prompt, highlighting the visual impact of each approach.

**Datasets and evaluation.** We evaluate watermarking methods on two datasets: MS-COCO (Lin et al., 2014) and the Stable Diffusion Prompt (SDP) dataset.12 We generate 500 un-watermarked images using MS-COCO captions or SDP prompts, and apply post-processing watermark methods to generate watermarked images. In-processing methods directly generate watermarked images from prompts. To assess the performance of the different watermarking schemes, we primarily examine four aspects: effectiveness, image quality, robustness, and detectability. For effectiveness, which involves performing binary classification between watermarked and un-watermarked images, we calculate the true positive rate (TPR) at a fixed false positive rate (FPR). Specifically, we report TPR@FPR=0.01. Without any attacks, the PRC watermark achieves TPR=1.0@FPR=0.01. Note that for PRC watermarking, the FPR is set at 1%, though it can be easily made smaller depending on the use case (see long message experiments in Section 3.2).

Footnote 12: https://huggingface.co/datasets/Gustavosta/Stable-Diffusion-Prompts

## Appendix C Additional experiment results and details on robustness

### Additional experiment results

The figures included in this section are:

* Figure 4, examples of different watermarks applied to one text prompt.
* Figure 5, a comprehensive evaluation of watermarking schemes under the attacks described in Appendix C.2.
* Figure 6, the performance of the embedding attack on in-processing watermarks.
* Figure 7, a brief evaluation of the robustness of our PRC watermark with \(t=2\).
* Figure 8, the performance of the spoofing attack against in-processing watermarks.

* Figure 9, example images under the embedding attack.
* Figure 10, a brief evaluation of the robustness of our PRC watermark decoder for 512 bits.
* Figure 11, the length of messages which can be reliably encoded and decoded with out PRC watermark when there is no watermark removal attack.

### Details on robustness

We applied a range of attacks, categorized into photometric distortions, degradation distortions, regeneration attacks, adversarial attacks, and spoofing attacks. Each type is described in detail below.

Photometric distortions.We applied two photometric distortion attacks: brightness and contrast adjustments. For brightness, we tested enhancement factors of \([2,4,6,8,12]\), where a factor of 0.0 results in a completely black image, and 1.0 retains the original image. Similarly, for contrast, we

Figure 4: Examples of different watermarks applied to the image generated with the prompt: _“red dead redemption 2, cinematic view, epic sky, detailed, concept art, low angle, high detail, warm lighting, volumetric, godrays, vivid, beautiful, trending on artsation, by Jordan grimmer, huge scene, grass, art greg rukowski”_. For post-processing watermark methods, the watermarks directly perturb the un-watermarked image. Notably, the StegaStamp watermark introduces visible blurring artifacts.

Figure 5: Robustness of various watermarking schemes. PSNR and SSIM are used to measure the similarity between a _single_ original image and attacked image. FID is used to measure distance between the _distribution_ of un-watermarked images and attacked images. The vertical dotted red line in the FID plots is the FID for un-perturbed watermarked images. Note that the strange behavior of the FID for certain watermarks under the Regen-Diffusion attack can be explained by the attack simply correcting its own errors.

Figure 8: Spoofing attack results. Tree-Ring and StegaStamp are vulnerable to spoofing attacks. Even with the target FPR set to 0.01, adversaries can significantly raise the FPR, causing the watermark detector to misclassify unwatermarked images as watermarked, which can damage the watermark owner’s reputation. The spoofing attack does not affect undetectable watermarks like the PRC watermark.

Figure 6: Embedding attack for different watermarks. Only the PRC watermark can attain FID below a certain threshold. Above this threshold, StegaStamp is the strongest scheme we tested against the embedding attack. The embedding attack is quite powerful, as it assumes the attacker knows the VAE used in the diffusion model for embedding latents. However, its effectiveness could be mitigated by employing an adversarially robust VAE encoder or keeping the VAE component of the diffusion model private.

Figure 7: We observe improved robustness for \(t=2\).

Figure 9: Example images under the embedding attack. Even the strength-2 embedding attack, for which the PRC attains a detection rate of over 95%, noticeably deteriorates the image quality on close inspection.

Figure 11: Testing the decoder for large message lengths with no adversarial perturbations. The PRC watermark parameters we used for this experiment are \(t=4\), \(F=1\)e-9, and \(\sigma=0\).

Figure 10: Comparison between robustness of the decoder for 512 bits and the detector. The detector is faster and consistently more robust than the decoder, but the detector does not recover messages in the watermark. The TPR for the decoder is the rate at which the message is correctly decoded.

used enhancement factors of \([2,3,4,5,6,7]\), where a factor of 0.0 produces a solid gray image, and 1.0 preserves the original image.

Degradation distortions.Three types of degradation distortions were applied: Gaussian blur, Gaussian noise, and JPEG compression. Specifically:

* **Gaussian Blur:** We varied the radius from \([2,4,6,8,10,12]\).
* **Gaussian Noise:** Noise was introduced with a mean of 0 and standard deviations of \([5,10,15,20,25,30]\).
* **JPEG Compression:** Compression quality was set at \([10,20,30,40,50,60]\), with lower quality levels leading to higher degradation.

Regeneration attacks.Regeneration attacks (Zhao et al., 2023) alter an image's latent representation by first introducing noise and then applying a denoising process. We implemented two forms of regeneration attacks: diffusion model-based and VAE-based approaches.

* **Diffusion Model Regeneration:** We employed the Stable-Diffusion-2-1base model as the backbone and conducted \([10,20,30,50,80,100,150,200]\) diffusion steps to attack the image. As the number of steps increased, the image diverged further from the original, often causing a performance drop. Interestingly, for the FID metric, we observed that more diffusion steps sometimes improved the FID score, as the diffusion model's inherent purification process preserved a natural appearance while altering textures and styles.
* **VAE-Based Regeneration:** We used two pre-trained image compression models from the CompressAI library12: Bmshj2018 Balle et al. (2018) and Cheng2020 Cheng et al. (2020), referred to as Regen-VAE-B and Regen-VAE-C, respectively. Compression factors were set to \([1,2,3,4,5,6]\), where lower compression factors resulted in more heavily degraded images. Footnote 12: https://github.com/InterDigitalInc/CompressAI

Adversarial attacks.We also explored adversarial attacks, focusing on surrogate detector-based and embedding-based adversarial methods.

* **Surrogate Detector Attacks:** Following (Saberi et al., 2023), we trained a ResNet18 model (He et al., 2016) on watermarked and non-watermarked images to act as a surrogate classifier. Specifically, we train the model for 10 epochs with a batch size of 128 and a learning rate of 1e-4. Using this model, we applied Projected Gradient Descent (PGD) adversarial attacks (Madry et al., 2018) on test images, simulating an adversary who knows either un-watermarked images and watermarked images (Adversarial-Cls), or watermarked images with two different keys (Adversarial-Cls-Diff-Key). The goal was to perturb the images with one key such that the detector misclassifies them as being associated with the other key. The attack was tested on four watermarking methods: Tree-Ring, Gaussian Shading, PRC, and StegaStamp watermark, with epsilon values of \([4,8,12]\). Since the PRC watermark is undetectable, we find in Figure 1 that the surrogate classifier cannot even be trained!
* **Embedding-Based Adversarial Attacks:** Adversarial perturbations were also applied to the image embedding space. Given an encoder \(f:\mathcal{X}\rightarrow\mathcal{Z}\) that maps images to latent features, we crafted adversarial images \(x_{\text{adv}}\) to diverge from the original watermarked image \(x\), constrained within an \(l_{\infty}\) perturbation limit. This was solved using the PGD algorithm (Madry et al., 2018). The VAE model for the original diffusion model stabilityai/sd-vae-ft-mse was assumed to be known for this attack.

## Appendix D The pseudorandom code

We use the construction of a PRC from Christ and Gunn (2024), which is secure under the certain-subexponential hardness of LPN. The proof of pseudorandomness, assuming the \(2^{\omega(\sqrt{\lambda})}\) hardness of LPN, from the technical overview of Christ and Gunn (2024) applies identically here. The PRC works by essentially embedding random parity checks in codewords. The key generation and encoding algorithms are given in Algorithms 1 and 2.

Since the work of Christ and Gunn (2024), at least two new constructions of PRCs have been introduced using different assumptions (Golowich and Moitra (2024); Ghentiyala and Guruswami (2024)). It would be interesting to see if any of these new constructions yield image watermarks with improved robustness.

The main difference between the PRC used here and the one from the technical overview of Christ and Gunn (2024) is that ours is optimized for our setting by allowing soft decisions on the recovered bits. That is, PRC.Detect takes in not a bit-string but a vector \(\bm{s}\) of values in the interval \([-1,1]\). If the PRC codeword is \(\bm{c}\), then \(s_{i}\) should be the expected value \((-1)^{c_{i}}\) conditioned on the user's observation. We present PRC.Detect in Algorithm 3 and explain how we designed it in Appendix E.1.

Christ and Gunn (2024) show that any zero-bit PRC (i.e., a PRC with a Detect algorithm but no Decode) can be generically converted to one that encodes information at a linear rate. However, that construction requires increasing the block-length of the PRC, which could harm the practical performance of our watermark. Instead, we use belief propagation with ordered statistics decoding to directly decode the message. Note that belief propagation cannot handle a constant rate of errors if the sparsity is greater than a constant; therefore, this only works when Recover produces an accurate approximation to the initial latent. Still, since our robustness experiments use a small sparsity of \(t=3\), we find that our decoder functions even when the image is subjected to significant perturbation.

```
0: k, \(\bm{s}\)
0: Decoded message \(\bm{m}\in\{0,1\}^{k}\) or None
1: Parse \((n,\mathrm{message\_length},F,t,\lambda,\eta,\mathrm{num\_test\_bits},k,r, \max\_bp\_iter,\mathsf{otp},\mathsf{testbits},\bm{G},\bm{P})\leftarrow\) k;
2: For \(i\in[n]\), let \(s_{i}\leftarrow(-1)^{\mathsf{otp}_{i}}\cdot(1-2\eta)\cdot s_{i}\);
3: For each parity check \(\bm{w}\in\bm{P}\), let \(\hat{s}_{\bm{w}}\leftarrow\prod_{i\in\bm{w}}s_{i}\);
4:\(C\leftarrow\frac{1}{2}\sum_{\bm{w}\in\bm{P}}\log^{2}\left(\frac{1+\hat{s}_{i}} {1-\hat{s}_{i}}\right)\);
5:if \[\sum_{\bm{w}\in\bm{P}}\log\left(\frac{1+\hat{s}_{\bm{w}}}{2}\right)\geq\sqrt{C \log(1/F)}+\frac{1}{2}\sum_{\bm{w}\in\bm{P}}\log\left(\frac{1-\hat{s}_{\bm{w}} ^{2}}{4}\right)\]
6: then
7: Output True;
8:else
9: Output False; ```

**Algorithm 4**PRC.Decode

The only parameters that need to be set in PRC.KeyGen are:

* \(n\), the block length, which is the dimension of the image latents in the PRC watermark. Holding the other parameters constant, larger \(n\) will yield a more robust PRC.
* \(\mathrm{message\_length}\), the length of messages that can be encoded by PRC.Encode. Increasing \(\mathrm{message\_length}\) yields a less robust PRC.
* \(F\), the desired false positive rate. We prove in Theorem 2 that the scheme will always have a false positive rate of at most \(F\), as long as the string being tested does not depend on the PRC key.
* \(t\), the sparsity of parity checks. Larger \(t\) yields undetectability against more-powerful adversaries, but decreased robustness.

For watermark detection and decoding, we allow the user to set an estimated error \(\sigma\). This should be the standard deviation of the error \(\bm{z}^{\prime}-\bm{z}\) that the user expects. In cases where the watermark does not need to be robust to perturbations of the image, one can set \(\sigma=0\). If \(\sigma\) is not set by the user, we use a default of \(\sigma=\sqrt{3/2}\) which we found to be effective for robust watermarking.

We use the Galois package of Hostetter (2020) for conveniently handling linear algebra over \(\mathbb{F}_{2}\). We use the belief propagation implementation of Roffe (2022) to decode messages in the watermark.

Details on the PRC watermark

Watermark key generation, Algorithm 5, is exactly the same as PRC key generation.

```
0:\(n\), \(\mathrm{message\_length}\), \(F\), \(t\)
0:Watermarking key k
1:\(\mathrm{k}\leftarrow\mathsf{PRC.KeyGen}(n,\mathrm{message\_length},F,t)\);
2:\((n,\mathrm{message\_length},F,t,\lambda,\eta,\mathrm{num\_test\_bits},k,r, \mathrm{max\_bp\_iter},\mathsf{otp},\mathsf{testbits},\bm{G},\bm{P})\leftarrow \mathrm{k}\);
3:Output k; ```

**Algorithm 5**\(\mathsf{PRCWat.KeyGen}\)

Watermarked image generation works by sampling the initial latents to have signs chosen according to a PRC codeword. If a message is to be encoded in the watermark, the message is simply encoded into the PRC.

```
0:Watermarking key k and message \(\bm{m}\)
0:Generated image \(\bm{x}\)
1:\(\mathrm{c}\leftarrow\mathsf{PRC.Encode}(\bm{k},\bm{m})\);
2:Sample \(\tilde{\bm{z}}\sim\mathcal{N}(\bm{0},\bm{I}_{n})\);
3:for\(i\in[n]\)do
4:\(\tilde{z}_{i}\gets c_{i}\cdot|\tilde{z}_{i}|\);
5:\(\bm{x}\leftarrow\mathsf{Generate}(\bm{\pi},\tilde{\bm{z}})\);
6:Output \(\bm{x}\); ```

**Algorithm 6**\(\mathsf{PRCWat.Sample}\)

Our detection algorithm \(\mathsf{PRC.Detect}\) is given in Algorithm 3. In Appendix E.1 we will explain how we designed the detector, and in Appendix E.2 we will prove Theorem 2 which says that \(\mathsf{PRC.Detect}\) and \(\mathsf{PRC.Decode}\) have false positive rates of at most \(F\). Note that \(\mathsf{PRC.Decode}\) is guaranteed to have a false positive rate of at most \(F\) simply because of testbits.

```
0:Watermarking key k, image \(\bm{x}\), and estimated error \(\sigma\)
0:Detection result True or False
1:\(\bm{z}\leftarrow\mathsf{Recover}(\bm{x})\);
2:for\(i\in[n]\)do
3:\(s_{i}=\mathrm{erf}\left(\frac{z_{i}}{\sqrt{2\sigma^{2}(1+\sigma^{2})}}\right)\);
4:\(\mathrm{result}\leftarrow\mathsf{PRC.Detect}(\mathsf{k},\bm{s})\);
5:Output \(\mathrm{result}\); ```

**Algorithm 7**\(\mathsf{PRCWat.Detect}\)

### Designing the watermark detector

Let \(\bm{z}\) be the initial latent and \(\bm{z}^{\prime}\) be the recovered latent. We will compute the probability that a given parity check \(w\) is satisfied by \(\mathrm{sign}(\bm{z})\) (after accounting for the noise and one-time pad), conditioned on the observation of \(\bm{z}^{\prime}\). In order for this to be possible, we need to model the distributions of \(\bm{z}\) and \(\bm{z}^{\prime}\): We use \(\bm{z}\sim\mathcal{N}(\bm{0},\bm{I}_{n})\) and \(\bm{z}^{\prime}\sim\mathcal{N}(\bm{z},\sigma^{2}\bm{I}_{n})\) for some \(\sigma>0\).

Crucially, when we bound the false positive rate in Appendix E.2, we will do it in a way that _does not depend_ on the distribution of \(\bm{z}^{\prime}\); we only use the facts that \(\bm{z}\sim\mathcal{N}(\bm{0},\bm{I}_{n})\) and \(\bm{z}^{\prime}\sim\mathcal{N}(\bm{z},\sigma^{2}\bm{I}_{n})\) to inform the design of our detector. In other words, Theorem 2 holds _unconditionally_, even though our detector is designed to have the highest true positive rate for a particular distribution of \(\bm{z}^{\prime}\).

Our first step is to compute the posterior distribution on \(\mathrm{sign}(\bm{z})\), conditioned on the observation \(\bm{z}^{\prime}\).

**Fact 1**.: _If \(z\sim\mathcal{N}(0,1)\) and \(z^{\prime}\sim\mathcal{N}(z,\sigma^{2})\) then_

\[\mathbb{E}[\mathrm{sign}(z)\mid z^{\prime}]=\mathrm{erf}\left(\frac{z^{\prime}} {\sqrt{2\sigma^{2}(1+\sigma^{2})}}\right).\]

Proof.: The joint distribution of \((z,z^{\prime})\) is

\[\begin{pmatrix}z\\ z^{\prime}\end{pmatrix}\sim\mathcal{N}\left(\begin{pmatrix}0\\ 0\end{pmatrix},\begin{pmatrix}1&1\\ 1&1+\sigma^{2}\end{pmatrix}\right).\]

Using the formula for the conditional multivariate normal distribution,13 the distribution of \(z\) conditioned on \(z^{\prime}\) is

Footnote 13: See, for instance, (Holt & Nguyen, 2023, Theorem 3).

\[z\sim N\left(\frac{z^{\prime}}{1+\sigma^{2}},\frac{\sigma^{2}}{1+\sigma^{2}} \right).\]

Therefore

\[\Pr[z\geq 0\mid z^{\prime}]=\Phi\left(\frac{z^{\prime}}{\sigma\sqrt{1+ \sigma^{2}}}\right),\]

where \(\Phi\) is the cumulative distribution function of the standard normal distribution, so

\[\mathbb{E}[\mathrm{sign}(z)\mid z^{\prime}] =2\Pr[z\geq 0\mid z^{\prime}]-1\] \[=2\Phi\left(\frac{z^{\prime}}{\sigma\sqrt{1+\sigma^{2}}}\right)-1\] \[=\mathrm{erf}\left(\frac{z^{\prime}}{\sqrt{2\sigma^{2}(1+\sigma^{ 2})}}\right),\]

where we have used the fact that \(\Phi(x)=(1+\mathrm{erf}(x/\sqrt{2}))/2\). 

Recall from Algorithm 2 that, in the PRC case, we generate the \(i\)th bit of the PRC codeword \(\mathrm{sign}(z_{i})\) by XORing the \(i\)th bit of a vector satisfying the parity checks with a random \(e_{i}\sim\mathrm{Ber}(\eta)\) variable and the \(i\)th bit of the one-time pad \(\mathsf{opt}_{i}\). Therefore we have

\[\mathbb{E}[(-1)^{\mathsf{opt}_{i}\oplus e_{i}}\cdot\mathrm{sign}(z_{i})\mid z _{i}^{\prime}]=(-1)^{\mathsf{opt}_{i}}\cdot(1-2\eta)\cdot\mathrm{erf}\left( \frac{z_{i}^{\prime}}{\sqrt{2\sigma^{2}(1+\sigma^{2})}}\right).\]

Let

\[s_{i}=\mathbb{E}[(-1)^{e_{i}}\cdot\mathrm{sign}(z_{i})\mid z_{i}^{\prime}]=(1 -2\eta)\cdot\mathrm{erf}\left(\frac{z_{i}^{\prime}}{\sqrt{2\sigma^{2}(1+ \sigma^{2})}}\right).\]

for each \(i\in[n]\). Let \(a_{\bm{w}}=\prod_{j\in\bm{w}}(-1)^{\mathsf{opt}_{j}}\) and \(\hat{s}_{\bm{w}}=\prod_{j\in\bm{w}}s_{j}\) for each \(\bm{w}\in\bm{P}\). Then \((1+a_{\bm{w}}\hat{s}_{\bm{w}})/2\) is the probability that \((-1)^{\mathsf{opt}\oplus\mathsf{ie}}\cdot\mathrm{sign}(\bm{z})\) satisfies \(\bm{w}\).

Our detector simply checks whether

\[\log\prod_{\bm{w}\in\bm{P}}\left(\frac{1+a_{\bm{w}}\hat{s}_{\bm{w}}}{2}\right) =\sum_{\bm{w}\in\bm{P}}\log\left(\frac{1+a_{\bm{w}}\hat{s}_{\bm{w}}}{2}\right)\]

is greater than some threshold. We set the threshold by computing a bound on the false positive rate.

[MISSING_PAGE_FAIL:23]

Then \(X_{\bm{w}}\leq b_{\bm{w}}\) and

\[\mathbb{E}X_{\bm{w}}^{2} =\mathbb{E}|X_{\bm{w}}|^{2}\] \[=\left|\frac{\log f_{\bm{w}}(1)-\log f_{\bm{w}}(-1)}{2}\right|^{2}\] \[=b_{\bm{w}}^{2}.\]

Applying Fact 2, we find that

\[\Pr\left[\sum_{\bm{w}\in\bm{P}}\log f_{\bm{w}}(a_{\bm{w}})\geq\tau+\sum_{\bm{w }\in\bm{P}}\frac{\log f_{\bm{w}}(1)+\log f_{\bm{w}}(-1)}{2}\right]\leq\exp\left( -\tau^{2}/C\right)\]

where \(C=2\sum_{\bm{w}\in\bm{P}}\mathbb{E}X_{\bm{w}}^{2}\). By the definition of \(f_{\bm{w}}\),

\[\frac{\log f_{\bm{w}}(1)+\log f_{\bm{w}}(-1)}{2}=\frac{1}{2}\log\left(\frac{1 -\hat{s}_{\bm{w}}^{2}}{4}\right)\]

and

\[\mathbb{E}X_{\bm{w}}^{2}=\frac{1}{4}\log^{2}\left(\frac{1+\hat{s}_{\bm{w}}}{1 -\hat{s}_{\bm{w}}}\right).\]

Therefore

\[\Pr\left[\sum_{\bm{w}\in\bm{P}}\log f_{\bm{w}}(a_{\bm{w}})\geq\tau+\frac{1}{2} \sum_{\bm{w}\in\bm{P}}\log\left(\frac{1-\hat{s}_{\bm{w}}^{2}}{4}\right)\right] \leq\exp\left(-\tau^{2}/C\right)\]

where \(C=\frac{1}{2}\sum_{\bm{w}\in\bm{P}}\log^{2}\left(\frac{1+\hat{s}_{\bm{w}}}{1- \hat{s}_{\bm{w}}}\right)\). The claim follows by setting \(\tau=\sqrt{C\log(1/F)}\). 

### Practical undetectability

We have not yet discussed the extent to which our scheme is undetectable for practical image sizes. As observed by Christ et al. (2024), the undetectability of any watermarking scheme can be broken with enough samples and computational resources: Undetectability just means that the resources required to detect the watermark _without_ the key scale super-polynomially with the resources required to detect the watermark _with_ the key. And under the same assumptions as in Christ & Gunn (2024), our scheme is asymptotically undetectable for the right scaling of parameters. We refer to our scheme as "undetectable" because of this, and because our experiments on quality and detectability demonstrate that it is undetectable enough for the main practical applications. However, for the specific, concrete choices of parameters used in our experiments, undetectability is not guaranteed against motivated adversaries.

For the PRC watermark, there exists a brute-force attack on undetectability that runs in time \(O(n^{t-1})\), counting queries to the generative model as \(O(1)\), where \(n\) is the dimension of the image latents and \(t\) is the sparsity of parity checks which can be set by the user (larger \(t\) decreases the robustness). This attack works by simply iterating over \(t\)-sparse parity checks until one used by the watermark is found. We did not attempt to optimize the attack, so it is possible that faster attacks could be found.

In our experiments we have \(n=2^{14}\) dimensional image latents, and we set \(t=3\) for most of our experiments demonstrating robustness. To ensure cryptographic undetectability, a better choice would be \(t=\log_{2}(n)/2=7\). The watermark detector still works with \(t=7\) for non-perturbed images, but we choose \(t=3\) for most experiments because of the improved robustness. Note that \(O(n^{2})\) is far greater than the \(O(1)\) time required to detect prior watermarks without the key, but _a motivated adversary can still break the undetectability of our scheme_. We therefore stress that our scheme, in its current form, should not be used for undetectability-critical applications such as steganography.

The reason there exists a relatively fast brute-force distinguishing attack against our scheme is that there exist quasi-polynomial time attacks against the PRC of Christ & Gunn (2024). The alternative constructions of PRCs due to Golowich & Moitra (2024) and Ghentiyala & Guruswami (2024) also suffer from quasi-polynomial time attacks. It is an interesting open question to construct PRCs that do not have quasi-polynomial time attacks; using our transformation, any such PRC would generically yield a watermarking scheme with improved undetectability. We hope that generative image model watermarks with improved undetectability can be built in the future.

## Appendix F Demo: PRC watermark for VAEs

The PRC watermark can be applied to VAEs (Kingma and Welling, 2013) as well. Using the same gradient descent technique as Hong et al. (2023), we optimize the latent to obtain the decoder inversion result for watermark detection. We test the PRC watermark on a VAE with a 256-dimensional latent space, trained on the CelebA dataset (Liu et al., 2018). By setting \(t=2\) and FPR as 0.05, we achieve over 90% TPR when embedding a zero-bit PRC watermark in the images. We show example generated images in Figure 12. We did not investigate the robustness or quality of the PRC watermark for VAEs in-depth, so this section is only to demonstrate the generality of our technique.

Figure 12: Comparison of unwatermark and PRC watermark images on VAE.