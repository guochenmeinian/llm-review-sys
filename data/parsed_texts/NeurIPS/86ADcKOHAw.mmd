# Nearest Neighbour with Bandit Feedback

 Stephen Pasteris

The Alan Turing Institute

London UK

spasteris@turing.ac.uk

&Chris Hicks

The Alan Turing Institute

London UK

c.hicks@turing.ac.uk

&Vasilios Mavroudis

The Alan Turing Institute

London UK

vmavroudis@turing.ac.uk

###### Abstract

In this paper we adapt the nearest neighbour rule to the contextual bandit problem. Our algorithm handles the fully adversarial setting in which no assumptions at all are made about the data-generation process. When combined with a sufficiently fast data-structure for (perhaps approximate) adaptive nearest neighbour search, such as a navigating net, our algorithm is extremely efficient - having a per trial running time polylogarithmic in both the number of trials and actions, and taking only quasi-linear space. We give generic regret bounds for our algorithm and further analyse them when applied to the stochastic bandit problem in euclidean space. We note that our algorithm can also be applied to the online classification problem.

## 1 Introduction

In this paper we adapt the classic _nearest neighbour_ rule to the contextual bandit problem and develop an extremely efficient algorithm. The problem proceeds in trials, where on trial \(t\): (1) a _context_\(x_{t}\) is revealed to us, (2) we must select an _action_\(a_{t}\), and (3) the _loss_\(\ell_{t,a_{t}}\in[0,1]\) of action \(a_{t}\) on trial \(t\) is revealed to us. We assume that the contexts are points in a metric space and the distance between two contexts represents their similarity. A _policy_ is a mapping from contexts to actions and the inductive bias of our algorithm is towards learning policies that typically map similar contexts to similar actions. Our main result has absolutely no assumptions whatsoever about the generation of the context/loss sequence and has no restriction on what policies we can compare our algorithm to.

Our algorithm requires, as a subroutine, a data-structure that performs \(c\)-nearest neighbour search. This data-structure must be _adaptive_ - in that new contexts can be inserted into it over time. An example of such a data-structure is the _Navigating net_[17] which, given mild conditions on our metric and dataset, performs both search and insertion in polylogarithmic time. When utilising a data-structure of this speed our algorithm is extremely efficient - with a per-trial time complexity polylogarithmic in both the number of trials and actions, and requiring only quasi-linear space.

As an example we will apply our methodology to the special case of the contextual bandit problem in which the context sequence is drawn i.i.d. from a probability distribution over the \(d\)-dimensional hypercube. In this case, for any policy \(\hat{y}\) with a finite-volume decision boundary, our algorithm achieves \(\tilde{\mathcal{O}}\left(\hat{\alpha}T^{d/(d+1)}K^{1/(d+1)}\right)\) regret w.r.t. \(\hat{y}\), where \(\hat{\alpha}\) measures the magnitude of what is essentially the part of the decision boundary of \(\hat{y}\) that lies in the support of the probability distribution.

In the course of this paper we develop some novel algorithmic techniques, including a new algorithmic framework CanProp and efficient algorithms for searching in trees, which may find further application.

We now describe related works. The bandit problem [20] was first introduced in [28] but was originally studied in the stochastic setting in which all losses are drawn i.i.d. at random [18], [1], [3]. However, our world is very often not i.i.d. stochastic. The work of [4] introduced the seminal Exp3 algorithm which handled the case in which the losses were selected arbitrarily. This work alsointroduced the Exp4 algorithm for contextual bandits. In general this algorithm is exponential time but in some situations can be implemented in polynomial time - such as their Exp3.S algorithm, which was a bandit version of the classic FixedShare algorithm [14]. In [12] the Exp3.S setting was greatly generalised to the situation in which the contexts where vertices of a graph. They utilised the methodology of [8], [16] and [13] in order to develop extremely efficient algorithms. Although inspiring this work, these algorithms cannot be utilised in our situation as they inherently require the set of queried contexts to be known a-priori. In the stochastic case another class of contextual bandit problems are _linear bandits_[21], [5] in which the contexts are mappings from the actions into \(\mathbb{R}^{d}\). Here the queried contexts need not be known in advance but the losses must be drawn i.i.d. from a distribution that has mean linear in the respective context. The \(k\) nearest neighbour algorithm was first analysed in [6]. The work [26] utilised the \(k\) nearest neighbour methodology and the works [9] and [18] to handle a stochastic contextual bandit problem. However, their setting is extremely more restricted than ours. In particular, the context/loss pairs must be drawn i.i.d. at random and the probability distribution they are sampled from must obey certain strict conditions. In addition, on each trial the contexts seen so far must be ordered in increasing distance from the current context and operations must be performed on this sequence, making their algorithm exponentially slower than ours. Our algorithm utilises the works of [22] and [7] as subroutines. It should be noted that the later work, which was based on [23], was improved on in [11] - we leave it as an open problem as to whether we can utilise their work in our algorithm.

Algorithms for contextual bandits in metric spaces have been studied in [15; 19; 24; 25; 27; 29; 30; 31; 2; 26] but as far as we know ours is the first work to give a non-trivial bound for our problem in general (with no additional assumptions). As far as we are aware our above example bound for the fully stochastic case in euclidean space (with finite decision boundary) is also novel - the works [30; 24; 26] scale as \(\tilde{\mathcal{O}}(T^{(d+1)/(d+2)})\) in general (and [24; 26] also require additional assumptions). As far as we are aware we are also the first work, stochastic or otherwise, to give a regret scaling as \(\tilde{\mathcal{O}}(T^{1/2})\) when the contexts are drawn from well-separated clusters (i.e. there is a positive distance between all pairs of clusters) in a finite-dimensional metric space, and the comparator policy is constant on each cluster (we do, however, conjecture that in the stochastic case [26] can obtain such a regret scaling here - but, as stated above, it is exponentially slower).

## 2 Notation

Let \(\mathbb{N}\) be the set of natural numbers not including \(0\). Given a natural number \(m\in\mathbb{N}\) we define \([m]:=\{j\in\mathbb{N}\mid j\leq m\}\). Given a predicate \(p\) we define \(\llbracket p\rrbracket:=1\) if \(p\) is true and \(\llbracket p\rrbracket:=0\) otherwise. We define \(\log(\cdot)\) and \(\ln(\cdot)\) to be the logarithms with base \(2\) and \(e\) respectively. Given sets \(\mathcal{A}\) and \(\mathcal{B}\) we denote by \(\mathcal{B}^{\mathcal{A}}\) the set of all functions \(f:\mathcal{A}\rightarrow\mathcal{B}\) and by \(2^{\mathcal{A}}\) the set of all subsets of \(\mathcal{A}\). We write \(x\sim[0,1]\) to mean that the value \(x\) is drawn from the uniform distribution on \([0,1]\).

All trees in this paper are considered rooted. Given a tree \(\mathcal{J}\) we denote its root by \(r(\mathcal{J})\), its vertex set by \(\mathcal{J}\), its leaves by \(\mathcal{J}^{\star}\), and its internal vertices by \(\mathcal{J}^{\dagger}\). Given a vertex \(v\) in a tree \(\mathcal{J}\) we denote its parent by \(\uparrow_{\mathcal{J}}(v)\) and the subtree of all its descendants by \(\Downarrow_{\mathcal{J}}(v)\). Given an internal node \(v\) in a (full) binary tree \(\mathcal{J}\) we denote its left and right children by \(\triangle_{\mathcal{J}}(v)\) and \(\triangleright_{\mathcal{J}}(v)\) respectively. Internal nodes \(v\) in a (full) ternary tree \(\mathcal{J}\) have an additional child \(\triangledown_{\mathcal{J}}(v)\) called the _centre_ child. Given vertices \(v\) and \(v^{\prime}\) in a tree \(\mathcal{J}\) we denote by \(\Gamma_{\mathcal{J}}(v,v^{\prime})\) the _least common ancestor_ of \(v\) and \(v^{\prime}\): i.e. the vertex of maximum depth which is an ancestor of both \(v\) and \(v^{\prime}\). We will drop the subscript \(\mathcal{J}\) in all these functions when unambiguous. Given a tree \(\mathcal{J}\), a _subtree_ of \(\mathcal{J}\) is a tree whose edge set is a subset of that of \(\mathcal{J}\).

## 3 Results

### The General Result

We consider the following game between _Learner_ (us) and _Nature_ (our adversary). We call this game the _similarity bandit problem_. We have \(K\)_actions_. Learning proceeds in \(T\) trials. A-priori Nature chooses a sequence \(\langle n(t)\mid t\in[T]\setminus\{1\}\rangle\) where for all \(t\in[T]\setminus\{1\}\) we have \(n(t)\in[t-1]\). A-priori Nature also chooses a sequence of loss vectors \(\langle\boldsymbol{\ell}_{t}\mid t\in[T]\rangle\subseteq[0,1]^{K}\), but does not reveal them to Learner. On the \(t\)-th trial the following happens:1. If \(t>1\) then Nature reveals \(n(t)\) to Learner.
2. Learner chooses some action \(a_{t}\in[K]\).
3. Nature reveals \(\ell_{t,a_{t}}\) to Learner.

Intuitively, given a trial \(t\in[T]\setminus\{1\}\), \(n(t)\) is a _similar_ trial to \(t\). Our inductive bias is that if an action \(a\in[K]\) is good for trial \(t\) then it is likely that \(a\) will also be good for the similar trial \(n(t)\). We will measure our performance with respect to any policy \(\bm{y}\), where a policy is defined as a vector in \([K]^{T}\). Specifically, we wish to minimise the _\(\bm{y}\)-regret_, which is defined as the difference between the total cumulative loss suffered by Learner and that which Learner would have suffered if it had instead chosen \(a_{t}\) equal to \(y_{t}\) for all trials \(t\). Formally, this quantity is defined as follows:

**Definition 3.1**.: _Given a policy \(\bm{y}\in[K]^{T}\) we define the \(\bm{y}\)-regret of Learner as:_

\[R(\bm{y}):=\sum_{t\in[T]}\ell_{t,a_{t}}-\sum_{t\in[T]}\ell_{t,y_{t}}\,.\]

The following quantity quantifies how much a policy agrees with our inductive bias.

**Definition 3.2**.: _Given a policy \(\bm{y}\in[K]^{T}\) we define the complexity of \(\bm{y}\) by:_

\[\Phi(\bm{y}):=1+\sum_{t\in[T]\setminus\{1\}}\llbracket y_{t}\neq y_{n(t)} \rrbracket\,.\]

We now state our main result:

**Theorem 3.3**.: _Consider the similarity bandit problem described above. Our algorithm CBNN takes a single parameter \(\rho>0\) and, for all policies \(\bm{y}\in[K]^{T}\) simultaneously, obtains an expected \(\bm{y}\)-regret bounded by:_

\[\mathbb{E}[R(\bm{y})]\in\tilde{\mathcal{O}}\left(\left(\rho+\frac{\Phi(\bm{y })}{\rho}\right)\sqrt{KT}\right)\]

_where the expectation is taken over the randomisation of the algorithm. CBNN needs no initialisation time and has a per-trial time complexity of:_

\[\mathcal{O}(\ln(T)^{2}\ln(K))\,.\]

### Bandits in a Metric Space

We consider the following game between _Learner_ (us) and _Nature_ (our adversary). We call this game the _metric bandit problem_. We have \(K\)_actions_ and a metric space \((\mathcal{C},\Delta)\) where \(\mathcal{C}\) is a (possibly infinite) set of _contexts_ and for all \(x,x^{\prime}\in\mathcal{C}\) we have that \(\Delta(x,x^{\prime})\) is the _distance_ from \(x\) to \(x^{\prime}\). We assume that Learner does not necessarily know \((\mathcal{C},\Delta)\) a-priori but has access to an oracle for computing \(\Delta(x,x^{\prime})\) for any \(x,x^{\prime}\in\mathcal{C}\). Learning proceeds in \(T\) trials. A-priori Nature chooses a sequence of contexts \(\langle x_{t}\,|\,t\in[T]\rangle\subseteq\mathcal{C}\) and a sequence of loss vectors \(\langle\bm{\ell}_{t}\,|\,t\in[T]\rangle\subseteq[0,1]^{K}\), but does not reveal them to Learner. On the \(t\)-th trial the following happens:

1. Nature reveals \(x_{t}\) to Learner.
2. Learner chooses some action \(a_{t}\in[K]\).
3. Nature reveals \(\ell_{t,a_{t}}\) to Learner.

Here, our inductive bias is that if an action \(a\in[K]\) is good for a context \(x\in\mathcal{C}\) then it is likely also good for contexts that are near to \(x\) with respect to the metric \(\Delta\). Our algorithm for this problem will be based on the concept of a \(c\)-nearest neighbour which is defined as follows.

**Definition 3.4**.: _Given some \(c\geq 1\), a finite set \(\mathcal{S}\subseteq\mathcal{C}\), and a context \(x\in\mathcal{C}\) we have that some \(\hat{x}\in\mathcal{S}\) is a \(c\)-nearest neighbour of \(x\) in the set \(\mathcal{S}\) if and only if:_

\[\Delta(x,\hat{x})\leq c\min_{x^{\prime}\in\mathcal{S}}\Delta(x,x^{\prime})\,.\]

In order to utilise CBNN for this problem we need a data-structure for _adaptive nearest neighbour search_. This problem is as follows. We maintain a finite set \(\mathcal{S}\subseteq\mathcal{C}\). At any point in time we must either:* Insert a new context \(x\in\mathcal{C}\) into the set \(\mathcal{S}\) and update the data-structure.
* Given a context \(x\in\mathcal{C}\), utilise the data-structure to find a \(c\)-nearest neighbour of \(x\) in the set \(\mathcal{S}\).

An efficient example of such a data-structure is the _navigating net_[17].

We can now reduce the metric bandit problem to the similarity bandit problem as follows. On any trial \(t\in[T]\setminus\{1\}\) choose \(\hat{x}_{t}\) to be a \(c\)-nearest neighbour of \(x_{t}\) in the set \(\{x_{t^{\prime}}\,|\,t^{\prime}\in[t-1]\}\). Then choose \(n(t)\in[t-1]\) such that \(x_{n(t)}=\hat{x}_{t}\).

We will utilise the following definition in order to bound the complexity of policies when \(n(\cdot)\) is chosen in this way.

**Definition 3.5**.: _Given a function \(\hat{y}:\mathcal{C}\to[K]\) and a set \(\mathcal{X}\subseteq\mathcal{C}\) then for all \(x\in\mathcal{C}\) define:_

\[\gamma(x,\hat{y},\mathcal{X}):=\min\{\Delta(x,x^{\prime})\mid x^{\prime}\in \mathcal{X}\,\wedge\,\hat{y}(x^{\prime})\neq\hat{y}(x)\}\,.\]

We can now bound the complexity of policies as follows, noting that by Theorem 3.3 this leads directly to a regret bound.

**Theorem 3.6**.: _Assume we have a sequence \(\langle x_{t}\,|\,t\in[T]\rangle\subseteq\mathcal{C}\) and a function \(\hat{y}:\mathcal{C}\to[K]\). Define \(\mathcal{X}:=\{x_{t}\,|\,t\in[T]\}\) and for all \(t\in[T]\) define \(y_{t}:=\hat{y}(x_{t})\). Assume that for all \(t\in[T]\setminus\{1\}\) we have that \(x_{n(t)}\) is a \(c\)-nearest neighbour of \(x_{t}\) in the set \(\{x_{t^{\prime}}\,|\,t^{\prime}\in[t-1]\}\). Then \(\Phi(\bm{y})\) is no greater than the minimum cardinality of any set \(\mathcal{S}\subseteq\mathcal{C}\) in which for all \(x^{\prime}\in\mathcal{X}\) there exists \(x\in\mathcal{S}\) with \(\Delta(x,x^{\prime})<\gamma(x,\hat{y},\mathcal{X})/3c\)._

A strength of our algorithm is that it can be combined with _binning_ algorithms, where the contexts \(x_{t}\) are partitioned into sets called _bins_ and, for each bin, all contexts in that bin are replaced by a single context called the _centre_ of the bin. The advantage of binning is that \(\gamma(x,\hat{y},\mathcal{X})\) can increase, so that by Theorem 3.6 we may have that \(\Phi(\bm{y})\) decreases. However, when a context \(x_{t}\) is binned (i.e. replaced by its bin centre) its label \(\hat{y}(x_{t})\) can change, increasing the final regret by \(\mathcal{O}(1)\). In Section 3.3 we give an example of the utilisation of binning.

### Stochastic Bandits in Euclidean Space

As an example we now consider the utilisation of the above algorithms for the problem of stochastic bandits in \([0,1]^{d}\) for some arbitrary \(d\in\mathbb{N}\) which we view as a constant in our bounds. Here we will only focus on what happens in the limit \(T\to\infty\). We focus on stochastic bandits for simplicity, but the same methodology can be used to study the limiting behaviour of adversarial bandits. In this problem we have an unknown probability density \(\tilde{\mu}:[0,1]^{d}\times[0,1]^{K}\to\mathbb{R}\). We have \(T\) trials. On trial \(t\) the following happens:

1. Nature draws \((z_{t},\bm{\ell}_{t})\) from \(\tilde{\mu}\).
2. Nature reveals \(z_{t}\) to Learner.
3. Learner chooses some action \(a_{t}\in[K]\).
4. Nature reveals \(\ell_{t,a_{t}}\) to Learner.

To aid us in this problem we will first quantise the contexts \(z_{t}\) to a grid. Note that this is an example of binning. The grid is defined as follows:

**Definition 3.7**.: _Given \(q\in\mathbb{N}\) define \(\mathcal{G}_{q}^{d}\) to be the set of vectors in \([0,1]^{d}\) in which each component is an integer multiple of \(1/q\)._

On each trial \(t\) we will first quantise the vector \(z_{t}\) by defining \(x_{t}\) to be its nearest neighbour (w.r.t. the euclidean metric) in \(\mathcal{G}_{q}^{d}\), where \(q:=(T/K)^{1/(d+1)}\). Note that this can be done in constant time per trial. As in Section 3.2 we then use CBNN to solve the problem by defining \(n(t)\) such that \(x_{n(t)}\) is a \(c\)-nearest neighbour (w.r.t. the euclidean metric) of \(x_{t}\) in the set \(\{x_{t^{\prime}}\,|\,t^{\prime}\in[t-1]\}\). We consider \(c\) as a constant in our bounds.

As before, we will compare our cumulative loss to that of a policy that follows a function \(\hat{y}:[0,1]^{d}\to[K]\). Our regret bound will be based on the following quantities:

**Definition 3.8**.: _Let \(\mu\) be the marginal of \(\hat{\mu}\) with respect to its first argument and let \(\Delta\) be the euclidean metric on \([0,1]^{d}\). For all \(\epsilon>0\) define:_

\[\mathcal{E}(\mu,\epsilon):=\{x\in[0,1]^{d}\,|\,\exists\,x^{\prime}\in[0,1]^{d} \,:\,\mu(x^{\prime})\neq 0\,\wedge\,\Delta(x,x^{\prime})\leq\epsilon\}\]

_which is the set of contexts that are within distance \(\epsilon\) of the support of \(\mu\). Given \(\hat{y}:[0,1]^{d}\to[K]\) we make the following definitions. For any \(\delta>0\) define:_

\[\mathcal{M}(\hat{y},\mu,\epsilon,\delta):=\{x\in[0,1]^{d}\,|\,\exists\,x^{ \prime}\in\mathcal{E}(\mu,\epsilon)\,:\,\Delta(x,x^{\prime})\leq\delta\, \wedge\,\hat{y}(x)\neq\hat{y}(x^{\prime})\}\]

_which is the set of contexts that are at distance no more than \(\delta\) from the intersection of the decision boundary of \(\hat{y}\) and \(\mathcal{E}(\mu,\epsilon)\). We then define:_

\[\alpha(\hat{y},\mu):=\lim_{\epsilon\to 0}\lim_{\delta\to 0}\frac{1}{\delta}\int_ {x\in\mathcal{M}(\hat{y},\mu,\epsilon,\delta)}1\qquad;\qquad\tilde{\alpha}( \hat{y},\mu):=\lim_{\epsilon\to 0}\lim_{\delta\to 0}\frac{1}{\delta}\int_{x\in \mathcal{M}(\hat{y},\mu,\epsilon,\delta)}\mu(x)\]

_which are essentially the volumes of the part of the decision boundary of \(\hat{y}\) that lies in the support of \(\mu\), with respect to the uniform density and the density \(\mu\) respectively._

With these definitions in hand we now present our regret bound, which utilises Theorem 3.6 in its proof:

**Theorem 3.9**.: _Let \(q:=\lceil(T/K)^{1/(d+1)}\rceil\). For all \(t\in[T]\) let \(x_{t}\) be the nearest neighbour of \(z_{t}\) in the set \(\mathcal{G}_{q}^{d}\). For all \(t\in[T]\setminus\{1\}\) let \(n(t)\) be such that \(x_{n(t)}\) is a \(c\)-nearest neighbour of \(x_{t}\) in the set \(\{x_{t^{\prime}}\,t^{\prime}\in[t-1]\}\). Given some \(\hat{y}:[0,1]^{d}\to[K]\) let \(y_{t}:=\hat{y}(z_{t})\) for all \(t\in[T]\). Then when \(\rho:=q^{\frac{d-1}{2}}\) CBNN gives us:_

\[\mathbb{E}[R(\bm{y})]\in\tilde{\mathcal{O}}\left((1+\alpha(\hat{y},\mu)+ \tilde{\alpha}(\hat{y},\mu))T^{\frac{d}{d+1}}K^{\frac{1}{d+1}}\right)\]

_as \(T\to\infty\)._

We note that varying \(q\) and \(\rho\) in Theorem 3.9 will allow us to trade off the values \(1\), \(\alpha(\hat{y},\mu)\) and \(\tilde{\alpha}(\hat{y},\mu)\) in different ways.

## 4 The Algorithm

In this section we describe our algorithm CBNN, for solving the similarity bandit problem, and give the pseudocode for the novel subroutines. In the appendix we give a more detailed description of how CBNN works and prove our theorems.

Instead of working directly with trial numbers we create a sequence of distinct _nodes_\(\langle x_{t}\,|\,t\in[T]\rangle\) and define, for all \(t\in[T]\setminus\{1\}\), the node \(n(x_{t}):=x_{n(t)}\). Let \(\mathcal{X}:=\{x_{i}\mid t\in[T]\}\). We can now represent policies as functions from \(\mathcal{X}\) into \([K]\). Hence, given some \(y:\mathcal{X}\to[K]\), we define the _\(y\)-regret_ and the _complexity_ of \(y\) as:

\[R(y):=\sum_{t\in[T]}\ell_{t,a_{t}}-\sum_{t\in[T]}\ell_{t,y(x_{t})}\qquad; \qquad\Phi(y):=1+\sum_{x\in\mathcal{X}\setminus\{x_{1}\}}[\![y(x)\neq y(n(x))]\!]\]

respectively.

### A Simple but Inefficient Algorithm

To give the reader intuition we first describe our initial idea - a simple algorithm which attains our desired regret bound but is exponentially slower - taking a per-trial time of \(\tilde{\Theta}(KT)\). The algorithm is based on Exp4[4] which we now describe. On every trial \(t\) we maintain a weighting \(\hat{w}_{t}:[K]^{\mathcal{X}}\to[0,1]\). We are free to choose the initial weighting \(\hat{w}_{1}\) to be any probability distribution. On each trial \(t\) the following happens:

1. For all \(a\in[K]\) set \(p_{t,a}\leftarrow\sum_{y\in[K]^{\mathcal{X}}}[\![y(x_{t})=a]\!]\hat{w}_{t}(y)\,\).
2. Set \(a_{t}\gets a\) with probability proportional to \(p_{t,a}\,\).
3. Receive \(\ell_{t,a_{t}}\,\).

4. For all \(a\in[K]\) set \(\hat{\ell}_{t,a}\leftarrow[\![a=a_{t}]\!]\ell_{t,a_{t}}||\boldsymbol{p}_{t}||_{1} /p_{t,a_{t}}\,.\)
5. For all \(y\in[K]^{\mathcal{X}}\) set \(\hat{w}_{t+1}(y)\leftarrow\hat{w}_{t}(y)\exp(-\eta\hat{\ell}_{t,y(x_{t})})\,.\)

For us we choose, for all \(y:\mathcal{X}\rightarrow[K]\,\), an initial weight of:

\[\hat{w}_{1}(y):=(1/K)(T(K-1))^{-\Phi(y)}\,(1-1/T)^{(T-1-\Phi(y))}\,\,.\]

Of course, we don't know \(\Phi(y)\) a-priori, and hence we cannot implement Exp4 explicitly (and it would take exponential time even if we did know \(\Phi(y)\) a-priori). Our crucial insight is the following. For any \(t\in[T]\) let \(\mathcal{X}_{t}:=\{x_{t^{\prime}}\,|\,t^{\prime}\in[t]\}\) and for any \(y:\mathcal{X}\rightarrow[K]\) let \(y^{t}\) be the restriction of \(y\) onto \(\mathcal{X}_{t}\). Then for any \(t\in[T]\) and for any \(y^{\prime}:\mathcal{X}_{t}\rightarrow[K]\) we have:

\[\sum_{y\in[K]^{\mathcal{X}}\,:\,y^{\prime}=y^{\prime}}\hat{w}_{1}(y)\propto \prod_{x\in\mathcal{X}_{t}\setminus\{x_{1}\}}\left(\frac{[\![y^{\prime}(n(x)) \neq y^{\prime}(x)]\!]}{T(K-1)}+[\![y^{\prime}(n(x))=y^{\prime}(x)]\!]\left(1- \frac{1}{T}\right)\right)\,.\] (1)

Note that, for all \(t\in[T]\) and \(a\in[K]\,\), we can write \(p_{t,a}\) as follows:

\[p_{t,a} =\sum_{y\in[K]^{\mathcal{X}}}[\![y(x_{t})=a]\!]\hat{w}_{1}(y)\prod _{t^{\prime}\in[t-1]}\exp(-\eta\hat{\ell}_{t,y(x_{t})})\] \[=\sum_{y^{\prime}\in[K]^{\mathcal{X}_{t}}}[\![y^{\prime}(x_{t})=a ]\left(\prod_{t^{\prime}\in[t-1]}\exp(-\eta\hat{\ell}_{t,y^{\prime}(x_{t})}) \right)\sum_{y\in[K]^{\mathcal{X}}\,:\,y^{\prime}=y^{\prime}}\hat{w}_{1}(y)\,.\]

By substituting in Equation (1) we have now brought \(p_{t,a}\) into a form that can be solved via _Belief propagation_[23] over the tree with vertex set \(\mathcal{X}_{t}\) and in which, for all \(t^{\prime}\in[t]\setminus\{1\}\,\), the parent of \(x_{t^{\prime}}\) is \(n(x_{t^{\prime}})\).

It is well known that for any \(y:\mathcal{X}\rightarrow[K]\,\), Exp4 attains a \(y\)-regret of at most \(\ln(\hat{w}_{1}(y))/\eta+\eta KT/2\). By setting \(\eta:=\rho/\sqrt{KT}\) and noting our choice of \(\hat{w}_{1}\) we obtain our desired regret bound.

### Cancellation Propagation

In the remainder of this section we describe our algorithm CBNN, which is based on the same idea as the simple algorithm of Section 4.1.

In this subsection we describe a novel algorithmic framework CanProp for designing contextual bandit algorithms with a running time logarithmic in \(K\). It is inspired by Exp3[4], specialist algorithms [8] and online decision-tree pruning algorithms [10] but is certainly not a simple combination of these works. CBNN will be an efficient implementation of an instance of CanProp. Although in general CanProp requires a-priori knowledge, CBNN is designed in a way that, crucially, does not need it to be known.

We assume, without loss of generality, that \(K\) and \(T\) are integer powers of two. CanProp, which takes a parameter \(\eta>0\), works on a full, balanced binary tree \(\mathcal{B}\) with leaves \(\mathcal{B}^{*}=[K]\). On every trial \(t\) each pair \((v,\mathcal{S})\in\mathcal{B}\times 2^{\mathcal{X}}\) has a weight \(w_{t}(v,\mathcal{S})\in[0,1]\). These weights induce a function \(\theta_{t}:\mathcal{B}\rightarrow[0,1]\) defined by:

\[\theta_{t}(v):=\sum_{\mathcal{S}\in 2^{\mathcal{X}}}[\![x_{t}\in\mathcal{S}]\!]w_{t }(v,\mathcal{S})\,.\]

On each trial \(t\) a root-to-leaf path \(\{v_{t,j}\mid j\in[\log(K)]\cup\{0\}\}\) is sampled such that \(v_{t,0}:=r(\mathcal{B})\) and, given \(v_{t,j}\,\), we have that \(v_{t,(j+1)}\) is sampled from \(\{\sphericalangle(v_{t,j}),\triangleright(v_{t,j})\}\) with probability proportional to the value of \(\theta_{t}\) when applied to each of these vertices. The action \(a_{t}\) is then chosen equal to \(v_{t,\log(K)}\). Once the loss has been observed we climb back up the root-to-leaf path, updating the function \(w_{t}\) to \(w_{t+1}\).

CanProp (at trial \(t\)) is given in Algorithm 1. We note that if \(w_{t+1}(v,\mathcal{S})\) is not set in the pseudocode then it is defined to be equal to \(w_{t}(v,\mathcal{S})\).

In Appendix B we give a general regret bound for CanProp. For CBNN we set:

\[\eta:=\rho\sqrt{\ln(K)\ln(T)/KT}\]and for all \((v,\mathcal{S})\in\mathcal{B}\times 2^{\mathcal{X}}\) we set:

\[w_{1}(v,\mathcal{S}):=\frac{1}{4}\prod_{x\in\mathcal{X}\setminus\{x_{1}\}}\left( \sigma(x,\mathcal{S})\frac{1}{T}+(1-\sigma(x,\mathcal{S}))\left(1-\frac{1}{T} \right)\right)\] (2)

where:

\[\sigma(x,\mathcal{S}):=\llbracket[\![x\in\mathcal{S}]\!]\neq\llbracket\![n(x) \in\mathcal{S}]\!]\rrbracket.\]

This choice gives us the regret bound in Theorem 3.3. We note that CBNN will be implemented in such a way that \(n\) need not be known a-priori.

### Ternary Search Trees

As we shall see, CBNN works by storing a binary tree \(\mathcal{A}(v)\) at each vertex \(v\in\mathcal{B}\). In order to perform efficient operations on these trees we will utilise the rebalancing data-structure defined in [22] which here we shall call a _ternary search tree_ (TST) due to the fact that it is a generalisation of the classic _binary search tree_ and, as we shall show, has searching applications. However, as for binary search trees, the applications of TSTs are more than just searching: we shall also utilise them for online belief propagation.

We now define what is meant by a TST. Suppose we have a full binary tree \(\mathcal{J}\). A TST of \(\mathcal{J}\) is a full ternary tree \(\mathcal{D}\) which satisfies the following. The vertex set of \(\mathcal{D}\) is partitioned into two sets \(\mathcal{D}^{\circ}\) and \(\mathcal{D}^{\bullet}\) where each vertex \(s\in\mathcal{D}\) is associated with a vertex \(\mu(s)\in\mathcal{J}\) and every \(s\in\mathcal{D}^{\bullet}\) is also associated with a vertex \(\mu^{\prime}(s)\in\Downarrow(\mu(s))^{\dagger}\). In addition, each internal vertex \(s\in\mathcal{D}^{\dagger}\) is associated with a vertex \(\xi(s)\in\mathcal{J}\). For all \(u\in\mathcal{J}\) there exists an unique leaf \(\mathcal{T}_{\mathcal{D}}(u)\in\mathcal{D}^{\bullet}\) in which \(\mu(\mathcal{T}_{\mathcal{D}}(u))=u\).

Essentially, each vertex \(s\in\mathcal{D}\) corresponds to a subtree \(\hat{\mathcal{J}}(s)\) of \(\mathcal{J}\) where \(\hat{\mathcal{J}}(r(\mathcal{D}))=\mathcal{J}\). Such a vertex \(s\) is a leaf of \(\mathcal{D}\) if and only if \(|\hat{\mathcal{J}}(s)|=1\). For each internal vertex \(s\in\mathcal{D}^{\dagger}\) the subtree \(\hat{\mathcal{J}}(s)\) is _split_ at the vertex \(\xi(s)\) into the subtrees \(\hat{\mathcal{J}}(\triangleleft(s))\), \(\hat{\mathcal{J}}(\triangledown(s))\), and \(\hat{\mathcal{J}}(\triangleright(s))\) corresponding to the children of \(s\). The process continues recursively.

For completeness we now describe the rules that a TST \(\mathcal{D}\) of \(\mathcal{J}\) must satisfy. We have that \(r(\mathcal{D})\in\mathcal{D}^{\circ}\) and \(\mu(r(\mathcal{D})):=r(\mathcal{J})\). Each vertex \(s\in\mathcal{D}\) represents a subtree \(\hat{\mathcal{J}}(s)\) of \(\mathcal{J}\). If \(s\in\mathcal{D}^{\circ}\) then \(\hat{\mathcal{J}}(s):=\Downarrow(\mu(s))\) and otherwise \(\hat{\mathcal{J}}(s)\) is the set of all descendants of \(\mu(s)\) which are not proper descendants of \(\mu^{\prime}(s)\). Given that \(s\in\mathcal{D}^{\dagger}\) this subtree is _split_ at the vertex \(\xi(s)\) where if \(s\in\mathcal{D}^{\bullet}\) we have that \(\xi(s)\) lies on the path from \(\mu(s)\) to \(\mu^{\prime}(s)\). The children of \(s\) are then defined so that \(\hat{\mathcal{J}}(\triangleleft(s))=\hat{\mathcal{J}}(s)\cap\Downarrow( \triangleleft(\xi(s)))\) and \(\hat{\mathcal{J}}(\triangleright(s))=\hat{\mathcal{J}}(s)\cap\Downarrow(\triangleright (\xi(s)))\) and \(\hat{\mathcal{J}}(\triangledown(s))=\hat{\mathcal{J}}(s)\setminus(\hat{ \mathcal{J}}(\triangleleft(s))\cup\hat{\mathcal{J}}(\triangleright(s)))\).

```
1:\(a_{t}\gets v_{t,\log(K)}\)
2:\(\tilde{\pi}_{t}\leftarrow\prod_{j\in\log(K)}\pi_{t}(v_{t,j})\)
3:\(\psi_{t,\log(K)}\leftarrow\exp(-\eta\ell_{t,a_{t}}/\tilde{\pi}_{t})\)
4:for\(j=\log(K),(\log(K)-1),\cdots,1\)do
5:\(\psi_{t,(j-1)}\gets 1-(1-\psi_{t,j})\pi_{t}(v_{t,j})\)
6:\(\psi^{\prime}_{t,j}\leftarrow\psi_{t,j}/\psi_{t,j-1}\)
7:if\(v_{t,j}=\triangleleft(v_{t,j-1})\)then
8:\(\tilde{v}_{t,j}\leftarrow\triangleright(v_{t,j-1})\)
9:else
10:\(\tilde{v}_{t,j}\leftarrow\triangleleft(v_{t,j-1})\)
11:endif
12:for\(\mathcal{S}\in 2^{\mathcal{X}}:x_{t}\in\mathcal{S}\)do
13:\(w_{t+1}(v_{t,j},\mathcal{S})\gets w_{t}(v_{t,j},\mathcal{S})\psi^{\prime}_{t,j}\)
14:\(w_{t+1}(\tilde{v}_{t,j},\mathcal{S})\gets w_{t}(\tilde{v}_{t,j},\mathcal{S})/ \psi_{t,j-1}\)
15:endfor
16:endfor ```

**Algorithm 1**CanProp at trial \(t\)

For completeness we now describe the rules that a TST \(\mathcal{D}\) of \(\mathcal{J}\) must satisfy. We have that \(r(\mathcal{D})\in\mathcal{D}^{\circ}\) and \(\mu(r(\mathcal{D})):=r(\mathcal{J})\). Each vertex \(s\in\mathcal{D}\) represents a subtree \(\hat{\mathcal{J}}(s)\) of \(\mathcal{J}\). If \(s\in\mathcal{D}^{\circ}\) then \(\hat{\mathcal{J}}(s):=\Downarrow(\mu(s))\) and otherwise \(\hat{\mathcal{J}}(s)\) is the set of all descendants of \(\mu(s)\) which are not proper descendants of \(\mu^{\prime}(s)\). Given that \(s\in\mathcal{D}^{\dagger}\) this subtree is _split_ at the vertex \(\xi(s)\) where if \(s\in\mathcal{D}^{\bullet}\) we have that \(\xi(s)\) lies on the path from \(\mu(s)\) to \(\mu^{\prime}(s)\). The children of \(s\) are then defined so that \(\hat{\mathcal{J}}(\triangleleft(s))=\hat{\mathcal{J}}(s)\cap\Downarrow( \triangleleft(\xi(s)))\) and \(\hat{\mathcal{J}}(\triangleright(s))=\hat{\mathcal{J}}(s)\cap\Downarrow( \triangleright(\xi(s)))\) and \(\hat{\mathcal{J}}(\triangledown(s))=\hat{\mathcal{J}}(s)\setminus(\hat{ \mathcal{J}}(\triangleleft(s))\cup\hat{\mathcal{J}}(\triangleright(s)))\).

else

\(\tilde{v}_{t,j}\leftarrow\triangleleft(v_{t,j-1})\)

\(v_{t,j+1}\leftarrow\triangleleft(v_{t,j})\)

\(v_{t,j+1}\leftarrow\triangleright(v_{t,j})\)
For all binary trees \(\mathcal{J}\) in our algorithm we shall maintain a TST \(\mathcal{H}(\mathcal{J})\) of \(\mathcal{J}\) with height \(\mathcal{O}(\ln(|\mathcal{J}|))\). Such trees \(\mathcal{J}\) are _dynamic_ in that on any trial it is possible that two vertices, \(u\) and \(u^{\prime}\), are added to the tree \(\mathcal{J}\) such that \(u^{\prime}\) is inserted between a non-root vertex of \(\mathcal{J}\) and its parent, and \(u\) is designated as a child of \(u^{\prime}\). We define the subroutine \(\textsc{Rebalance}(\mathcal{H}(\mathcal{J}),u)\) as one which rebalances the TST \(\mathcal{H}(\mathcal{J})\) after this insertion, so that the height of \(\mathcal{H}(\mathcal{J})\) always remains in \(\mathcal{O}(\ln(|\mathcal{J}|))\). The work of [22] describes how this subroutine can be implemented in a time of \(\mathcal{O}(\ln(|\mathcal{J}|))\) and we refer the reader to this work for details (noting that they use different notation).

### Contractions

Define the quantity \(\phi_{0}:=0\) and for all \(j\in\mathbb{N}\cup\{0\}\) inductively define:

\[\phi_{j+1}:=\left(1-\frac{1}{T}\right)\phi_{j}+\frac{1}{T}(1-\phi_{j})\,.\]

At any trial \(t\) the contexts in \(\{x_{s}\mid s\in[t]\}\) naturally form a tree by designating \(n(x_{s})\) as the parent of \(x_{s}\). However, to utilise the TST data-structure we must only have binary trees. Hence, we will work with a (dynamic) full binary tree \(\mathcal{Z}\) which, on trial \(t\), is a _binarisation_ of the above tree. The relationship between these two trees is given by a map \(\gamma:\mathcal{Z}_{t}\to\{x_{s}\mid s\in[t]\}\) where \(\mathcal{Z}_{t}\) is the tree \(\mathcal{Z}\) on trial \(t\). For all \(x\in\{x_{s}\mid s\in[t]\}\) we will always have an unique leaf \(\tilde{\gamma}(x)\in\mathcal{Z}_{t}^{*}\) in which \(\gamma(\tilde{\gamma}(x))=x\). We also maintain a balanced TST \(\mathcal{H}(\mathcal{Z})\) of \(\mathcal{Z}\).

Algorithm 2 gives the subroutine \(\textsc{Grow}_{t}\) which updates \(\mathcal{Z}\) at the start of trial \(t\). Note that \(\textsc{Grow}_{t}\) also defines a function \(d:\mathcal{Z}\to\mathbb{N}\) such that \(d(u)\) is the number of times the function \(n\) must be applied to \(\gamma(u)\) to reach \(x_{1}\).

```
1:\(u\leftarrow\tilde{\gamma}(n(x_{t}))\)
2:\(u^{*}\leftarrow\uparrow(u)\)
3:\(u^{\prime}\leftarrow\textsc{NewVertex}\)
4:\(u^{\prime\prime}\leftarrow\textsc{NewVertex}\)
5:\(\gamma(u^{\prime})\gets n(x_{t})\)
6:\(\gamma(u^{\prime\prime})\gets x_{t}\)
7:\(\tilde{\gamma}(x_{t})\gets u^{\prime\prime}\)
8:if\(u=\triangleleft(u^{*})\)then
9:\(\triangleleft(u^{*})\gets u^{\prime}\) ```

**Algorithm 2**\(\textsc{Grow}_{t}\) which works on \(\mathcal{Z}\)

A _contraction_ (of \(\mathcal{Z}\)) is defined as a full binary tree \(\mathcal{J}\) in which the following holds. (1) The vertices of \(\mathcal{J}\) are a subset of those of \(\mathcal{Z}\). (2) \(r(\mathcal{J})=r(\mathcal{Z})\). (3) Given a vertex \(u\in\mathcal{J}\) we have \(\triangleleft_{\mathcal{J}}(u)\in\mathbb{J}_{\mathcal{Z}}(\triangleleft_{ \mathcal{Z}}(u))\) and \(\triangleright_{\mathcal{J}}(u)\in\Downarrow_{\mathcal{Z}}(\triangleright_{ \mathcal{Z}}(u))\). (4) Any leaf of \(\mathcal{J}\) is a leaf of \(\mathcal{Z}\).

CBNN will maintain, on every vertex \(v\in\mathcal{B}\), a contraction \(\mathcal{A}(v)\) as well as a TST \(\mathcal{H}(\mathcal{A}(v))\) of \(\mathcal{A}(v)\). Given \(\mathcal{J}\) is one of these contractions, we also maintain, for all \(i,i^{\prime}\in\{0,1\}\) and all \(u\in\mathcal{J}\), a value \(\tau_{i,i^{\prime}}(\mathcal{J},u)\in\mathbb{R}_{+}\). Technically these quantities, which depend on the above function \(d\), define a _bayesian network_ on \(\mathcal{J}\) which is explained in Appendix C.3. For all \(i\in\{0,1\}\) and all \(u\in\mathcal{J}\) we also maintain a value \(\kappa_{i}(\mathcal{J},u)\) initialised equal to \(1\).

On each of our contractions \(\mathcal{J}\) we will define, on trial \(t\), a subroutine \(\textsc{Insert}_{t}(\mathcal{J})\) that simply modifies \(\mathcal{J}\) so that \(\tilde{\gamma}(x_{t})\) is added to its leaves. This subroutine is only called on certain trials \(t\). Specifically, it is called on the contraction \(\mathcal{A}(v)\) only when \(v\) is involved in CanProp on trial \(t\). Although the effect of this subroutine is simple to describe, its polylogarithmic-time implementation is quite complex. A function that is used many times during this subroutine is \(\nu:\mathcal{Z}\times\mathcal{Z}\to\{\,\,\blacktriangleright,\blackblackblack\}\) in which \(\nu(u,u^{\prime})\) is equal to \(\blacktriangleleft\), \(\blacktriangleright\) or \(\blacktriangleleft\) if \(u^{\prime}\) is contained in \(\Downarrow_{\mathcal{Z}}(\triangleleft_{\mathcal{Z}}(u))\), in \(\Downarrow_{\mathcal{Z}}(\triangleright_{\mathcal{Z}}(u))\) or in neither, respectively. Algorithm 3 shows how to compute this function. Now that we have a subroutine for computing \(\nu\) we can turn to the pseudocode for the subroutine \(\textsc{Insert}_{t}(\mathcal{J})\) in Algorithm 4. In the appendix we give a full description of how and why this subroutine works.

```
1:\(\mathcal{E}\leftarrow\mathcal{H}(\mathcal{Z})\)
2:if\(u=u^{\prime}\)then
3:return\(\blacktriangle\)
4:endif
5:\(\tilde{s}\leftarrow\Upsilon_{\mathcal{E}}(u)\)
6:\(\tilde{s}^{\prime}\leftarrow\Upsilon_{\mathcal{E}}(u^{\prime})\)
7:\(s^{*}\leftarrow\Gamma_{\mathcal{E}}(\tilde{s},\tilde{s}^{\prime})\)
8:for\(s\in\{\triangle(s^{*}),\,\forall(s^{*}),\triangleright(s^{*})\}\)do
9:if\(\tilde{s}\in\Downarrow(s)\)then
10:\(\hat{s}\gets s\)
11:endif
12:if\(\tilde{s}^{\prime}\in\Downarrow(s)\)then
13:\(\hat{s}^{\prime}\gets s\)
14:endif
15:endfor
16:if\(\hat{s}\neq\triangledown(s^{*})\)then
17:return\(\blacktriangle\)
18:endif
19:if\(\xi(s^{*})=u\wedge\hat{s}^{\prime}=\triangle(s^{*})\)then
20:return\(\blacktriangle\)
21:endif
22:if\(\xi(s^{*})=u\wedge\hat{s}^{\prime}=\triangleright(s^{*})\)then
23:endif
24:\(s\leftarrow\hat{s}\)
25:while True do
26:if\(s\in\mathcal{E}^{\circ}\)then
27:return\(\blacktriangle\)
28:elseif\(u=\xi(s)\wedge\triangle(s)\in\mathcal{E}^{\bullet}\)then
29:return\(\blacktriangle\)
30:elseif\(u=\xi(s)\wedge\triangleright(s)\in\mathcal{E}^{\bullet}\)then
31:return\(\blacktriangleright\)
32:endif
33:for\(s^{\prime}\in\{\triangle(s),\,\forall(s),\triangleright(s)\}\)do
34:if\(\tilde{s}\in\Downarrow(s^{\prime})\)then
35:\(s\gets s^{\prime}\)
36:endif
37:endif
38:endfor
39:endwhile ```

**Algorithm 3** Computing \(\nu(u,u^{\prime})\) for \(u,u^{\prime}\in\mathcal{Z}\)

```
1:\(\mathcal{E}\leftarrow\mathcal{H}(\mathcal{Z})\)
2:\(\mathcal{D}\leftarrow\mathcal{H}(\mathcal{J})\)
3:\(s\gets r(\mathcal{D})\)
4:\(u_{t}\leftarrow\tilde{\gamma}(x_{t})\)
5:while\(s\in\mathcal{D}^{\dagger}\)do
6:if\(\nu(\xi(s),u_{t})=\blacktriangle\)then
7:\(s\leftarrow\triangle(s)\)
8:elseif\(\nu(\xi(s),u_{t})=\blacktriangleright\)then
9:\(s\leftarrow\triangleright(s)\)
10:elseif\(\nu(\xi(s),u_{t})=\blacktriangle\)then
11:\(s\leftarrow\triangledown(s)\)
12:endif
13:endwhile ```

**Algorithm 4** The operation \(\textsc{Insert}_{t}(\mathcal{J})\) on a contraction \(\mathcal{J}\) of \(\mathcal{Z}\) at trial \(t\)

```
2:\(u^{*}\leftarrow\mu(s)\)
3:\(u^{\prime}\leftarrow\uparrow_{\mathcal{J}}(\hat{u})\)
3:if\(\hat{u}=\triangle_{\mathcal{J}}(u^{\prime})\)then
3:\(\triangle_{\mathcal{J}}(u^{\prime})\gets u^{*}\)
3:else
4:\(\triangleright_{\mathcal{J}}(u^{\prime})\gets u^{*}\)
5:endif
6:if\(\nu(u^{*},\hat{u})=\blacktriangle\)then
7:\(\triangle_{\mathcal{J}}(u^{*})\leftarrow\hat{u}\)
8:\(\triangleright_{\mathcal{J}}(u^{*})\gets u_{t}\)
9:else
10:\(\triangleright_{\mathcal{J}}(u^{*})\leftarrow\hat{u}\)
11:\(\triangle_{\mathcal{J}}(u^{*})\gets u_{t}\)
12:endif
13:for\(i\in\{0,1\}\)do
14:\(\kappa_{i}(\mathcal{J},u^{*})\gets 1\)
15:\(\kappa_{i}(\mathcal{J},u_{t})\gets 1\)
16:endfor
17:for\(u\in\{u^{*},\hat{u},u_{t}\}\)do
18:\(\delta(u)\gets d(u)-d(\uparrow_{\mathcal{J}}(u))\)
19:endfor
20:for\((i,i^{\prime})\in\{0,1\}\times\{0,1\}\)do
21:if\(i=i^{\prime}\)then
22:\(\tau_{i,i^{\prime}}(\mathcal{J},u)\gets 1-\phi_{\delta(u)}\)
23:else
24:\(\tau_{i,i^{\prime}}(\mathcal{J},u)\leftarrow\phi_{\delta(u)}\)
25:endif
26:endfor
27:\(\textsc{Rebalance}(\mathcal{H}(\mathcal{J}),u_{t})\) ```

**Algorithm 5** The operator \(\textsc{Insert}_{t}(\mathcal{J})\) on a contraction \(\mathcal{J}\) of \(\mathcal{Z}\) at trial \(t\)

### Online Belief Propagation

In this subsection we utilise the work of [7] in order to be able to efficiently compute the function \(\theta_{t}\) that appears in CanProp.

Given a vertex \(u\) in one of our contractions \(\mathcal{J}\) we define \(\mathcal{F}(\mathcal{J},u):=\{f\in\{0,1\}^{\mathcal{J}}\mid f(u)=1\}\) and then define:

\[\Lambda(\mathcal{J},u):=\sum_{f\in\mathcal{F}(\mathcal{J},u)}\ \prod_{u^{\prime}\in \mathcal{J}\setminus\{r(\mathcal{J})\}}\tau_{f(\uparrow_{\mathcal{J}}(u^{ \prime})),f(u^{\prime})}(\mathcal{J},u^{\prime})\kappa_{f(u^{\prime})}( \mathcal{J},u^{\prime})\,.\]

As stated in the previous subsection, when a vertex \(v\in\mathcal{B}\) becomes involved in CanProp on trial \(t\), CBNN will add \(\tilde{\gamma}(x_{t})\) to the leaves of \(\mathcal{A}(v)\) via the operation Insert\({}_{t}(\mathcal{A}(v))\). In the appendix we shall show that for each such \(v\) we then have:

\[\theta_{t}(v)=\Lambda(\mathcal{A}(v),\tilde{\gamma}(x_{t}))/4\,.\]

We now outline how to compute this efficiently, deferring a full description for Appendix D.3. First note that for all contractions \(\mathcal{J}\) and all \(u\in\mathcal{J}\) we have that \(\Lambda(\mathcal{J},u)\) is of the exact form to be solved by the classic _Belief propagation_ algorithm [23]. The work of [7] shows how to compute this term in logarithmic time by maintaining a data-structure based on a balanced TST of \(\mathcal{J}\) - in our case the TST \(\mathcal{H}(\mathcal{J})\). Whenever, for some \(i\in\{0,1\}\) and \(u^{\prime}\in\mathcal{J}\), the value \(\kappa_{i}(\mathcal{J},u^{\prime})\) changes, the data-structure is updated in logarithmic time. We define the subroutine Evidence\((\mathcal{J},u^{\prime})\) as that which updates this data-structure after \(\kappa_{i}(\mathcal{J},u^{\prime})\) changes. We also make sure that the data-structure is updated whenever \(\textsc{{Rebalance}}(\mathcal{H}(\mathcal{J}),\cdot)\) is called. We then define the subroutine Marginal\((\mathcal{J},u)\) as that which computes \(\Lambda(\mathcal{J},u)/4\). Hence, the output of Marginal\((\mathcal{A}(v),\tilde{\gamma}(x_{t}))\) is equal to \(\theta_{t}(v)\).

### Cbnn

Now that we have defined all our subroutines we give, in Algorithm 5, the algorithm CBNN which is an efficient implementation of CanProp with initial weighting given in Equation (2).

```
1:\(\textsc{Grow}_{t}\)
2:\(u_{t}\leftarrow\tilde{\gamma}(x_{t})\)
3:\(v_{t,0}\gets r(\mathcal{B})\)
4:for\(j=0,1,\cdots,(\log(K)-1)\)do
5:for\(v\in\{\triangle v_{(t,j)},\triangleright v_{(t,j)}\}\)do
6: Insert\({}_{t}(\mathcal{A}(v))\)
7:\(\theta_{t}(v)\leftarrow\textsc{{Marginal}}(\mathcal{A}(v),u_{t})\)
8:endfor
9:\(z_{t,j}\leftarrow\theta_{t}(\triangle(v_{t,j}))+\theta_{t}(\triangleright(v_{t,j}))\)
10:for\(v\in\{\triangle v_{(t,j)},\triangleright(v_{t,j})\}\)do
11:\(\pi_{t}(v)\leftarrow\theta_{t}(v)/z_{t,j}\)
12:endfor
13:\(\zeta_{t,j}\sim[0,1]\)
14:if\(\zeta_{t,j}\leq\pi_{t}(\triangle v_{(t,j)})\)then
15:\(v_{t,j+1}\leftarrow\triangle v(v_{t,j})\)
16:else
17:\(v_{t,j+1}\leftarrow\triangleright(v_{t,j})\)
18:endfor ```

**Algorithm 5** CBNN at trial \(t\)

## 5 Acknowledgments

We would like to thank Mark Herbster (University College London) for valuable discussions.

Research funded by the Defence Science and Technology Laboratory (Dstl) which is an executive agency of the UK Ministry of Defence providing world class expertise and delivering cutting-edge science and technology for the benefit of the nation and allies. The research supports the Autonomous Resilient Cyber Defence (ARCD) project within the Dstl Cyber Defence Enhancement programme.

## References

* 1078, 1995.
* [2] S. Arya and Y. Yang. Randomized allocation with nonparametric estimation for contextual multi-armed bandits with delayed rewards. _Statistics & Probability Letters_, 2020.
* [3] P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit problem. _Machine Learning_, 47:235-256, 2002.
* [4] P. Auer, N. Cesa-Bianchi, Y. Freund, and R. E. Schapire. The nonstochastic multiarmed bandit problem. _SIAM J. Comput._, 32:48-77, 2002.
* [5] W. Chu, L. Li, L. Reyzin, and R. E. Schapire. Contextual bandits with linear payoff functions. In _International Conference on Artificial Intelligence and Statistics_, 2011.
* [6] T. M. Cover and P. E. Hart. Nearest neighbor pattern classification. _IEEE Trans. Inf. Theory_, 13:21-27, 1967.
* [7] A. L. Delcher, A. J. Grove, S. Kasif, and J. Pearl. Logarithmic-time updates and queries in probabilistic networks. _J. Artif. Intell. Res._, 4:37-59, 1995.
* [8] Y. Freund, R. E. Schapire, Y. Singer, and M. K. Warmuth. Using and combining predictors that specialize. In _Symposium on the Theory of Computing_, 1997.
* [9] A. Garivier and O. Cappe. The kl-ucb algorithm for bounded stochastic bandits and beyond. In _Annual Conference Computational Learning Theory_, 2011.
* [10] D. P. Helmbold and R. E. Schapire. Predicting nearly as well as the best pruning of a decision tree. _Machine Learning_, 27:51-68, 1995.
* [11] M. Herbster, S. Pasteris, and F. Vitale. Online sum-product computation over trees. In _NIPS_, 2012.
* [12] M. Herbster, S. Pasteris, F. Vitale, and M. Pontil. A gang of adversarial bandits. In _Neural Information Processing Systems_, 2021.
* [13] M. Herbster and J. Robinson. Online prediction of switching graph labelings with cluster specialists. In _Neural Information Processing Systems_, 2018.
* [14] M. Herbster and M. K. Warmuth. Tracking the best expert. _Machine Learning_, 32:151-178, 1995.
* [15] S. M. Kakade, S. Shalev-Shwartz, and A. Tewari. Efficient bandit algorithms for online multiclass prediction. In _International Conference on Machine Learning_, 2008.
* [16] W. M. Koolen, D. Adamskiy, and M. K. Warmuth. Putting bayes to sleep. In _NIPS_, 2012.
* [17] R. Krauthgamer and J. R. Lee. Navigating nets: simple algorithms for proximity search. In _ACM-SIAM Symposium on Discrete Algorithms_, 2004.
* [18] T. L. Lai and H. E. Robbins. Asymptotically efficient adaptive allocation rules. _Advances in Applied Mathematics_, 6:4-22, 1985.
* [19] J. Langford and T. Zhang. The epoch-greedy algorithm for contextual multi-armed bandits. In _NIPS 2007_, 2007.
* [20] T. Lattimore and C. Szepesvari. Bandit algorithms. 2020.
* [21] L. Li, W. Chu, J. Langford, and R. E. Schapire. A contextual-bandit approach to personalized news article recommendation. In _The Web Conference_, 2010.
* [22] K. Matsuzaki and A. Morihata. Balanced ternary-tree representation of binary trees and balancing algorithms. In _Mathematical Engineering Technical Reports_, 2008.

* [23] J. Pearl. Reverend bayes on inference engines: A distributed hierarchical approach. _Probabilistic and Causal Inference_, 1982.
* [24] V. Perchet and P. Rigollet. The multi-armed bandit problem with covariates. _The Annals of Statistics_, 2013.
* [25] W. Qian and Y. Yang. Kernel estimation and model combination in a bandit problem with covariates. _J. Mach. Learn. Res._, 17:149:1-149:37, 2016.
* [26] H. W. J. Reeve, J. C. Mellor, and G. Brown. The k-nearest neighbour ucb algorithm for multi-armed bandits with covariates. _Algorithmic Learning Theory_, 2018.
* [27] P. Rigollet and A. J. Zeevi. Nonparametric bandits with covariates. In _Annual Conference Computational Learning Theory_, 2010.
* [28] H. E. Robbins. Some aspects of the sequential design of experiments. _Bulletin of the American Mathematical Society_, 58:527-535, 1952.
* [29] Y. Seldin, P. Auer, F. Laviolette, J. Shawe-Taylor, and R. Ortner. Pac-bayesian analysis of contextual bandits. In _NIPS_, 2011.
* [30] A. Slivkins. Contextual bandits with similarity information. _Journal of Machine Learning Research_, 2014.
* [31] C.-C. Wang, S. R. Kulkarni, and H. V. Poor. Arbitrary side observations in bandit problems. _Adv. Appl. Math._, 34:903-938, 2005.

Introduction to the Appendix

We now turn to the full description and analysis of our algorithm CBNN. In Appendix B we describe our novel algorithmic framework CanProp. In Appendix C we describe contractions and bayesian networks on them, showing how CanProp can be implemented with them. Finally, in Appendix D we describe TSTs and how they are used to perform our required operations efficiently. In Appendix E we prove, in order, all of the theorems stated in this paper.

Recall that we created a sequence of distinct _nodes_\(\langle x_{t}\mid t\in[T]\rangle\) and defined, for all \(t\in[T]\setminus\{1\}\), the node \(n(x_{t}):=x_{n(t)}\). Let \(\mathcal{X}:=\{x_{t}\mid t\in[T]\}\). Given some \(y:\mathcal{X}\to[K]\), we defined the _\(y\)-regret_ and the _complexity_ of \(y\) as:

\[R(y):=\sum_{t\in[T]}\ell_{t,a_{t}}-\sum_{t\in[T]}\ell_{t,y(x_{t})}\qquad; \qquad\Phi(y):=1+\sum_{x\in\mathcal{X}\setminus\{x_{1}\}}\llbracket y(x)\neq y (n(x))\rrbracket\]

respectively.

## Appendix B Cancellation Propagation

### The General CanProp Algorithm

We now introduce a general algorithmic framework CanProp for handling contextual bandit problems with a per-trial time logarithmic in \(K\). Without loss of generality assume that \(K\) is an integer power of two. Let \(\mathcal{B}\) be a full, balanced binary tree whose leaves are the set of actions \([K]\). Let \(\mathcal{B}^{\prime}:=\mathcal{B}\setminus\{r(\mathcal{B})\}\). CanProp takes a parameter \(\eta\in\mathbb{R}_{+}\) called the _learning rate_. On each trial \(t\) CanProp maintains a function:

\[w_{t}:\mathcal{B}^{\prime}\times 2^{\mathcal{X}}\to[0,1]\,.\]

The function \(w_{1}\) is free to be defined how one likes, as long as it satisfies the constraint that for all internal vertices \(v\in\mathcal{B}^{\dagger}\) we have:

\[\sum_{\mathcal{S}\in 2^{\mathcal{X}}}(w_{1}(\triangleleft(v),\mathcal{S})+w_{1}( \triangleright(v),\mathcal{S}))=1\,.\]

We now describe how CanProp acts on trial \(t\). For all \(v\in\mathcal{B}^{\prime}\) we define:

\[\theta_{t}(v):=\sum_{\mathcal{S}\in 2^{\mathcal{X}}}\llbracket x_{t}\in \mathcal{S}\rrbracket w_{t}(v,\mathcal{S})\]

and for all \(v\in\mathcal{B}^{\dagger}\) we define:

\[\pi_{t}(\triangleleft(v)):=\frac{\theta_{t}(\triangleleft(v))}{\theta_{t}( \triangleleft(v))+\theta_{t}(\triangleright(v))}\qquad;\qquad\pi_{t}( \triangleright(v)):=\frac{\theta_{t}(\triangleright(v))}{\theta_{t}(\triangleleft(v ))+\theta_{t}(\triangleright(v))}\,.\]

As we shall see CanProp needs only compute these values for \(\mathcal{O}(\ln(K))\) vertices \(v\). CanProp samples a root-to-leaf path \(\{v_{t,j}\mid j\in[\log(K)]\cup\{0\}\}\) as follows. \(v_{t,0}\) is defined equal to \(r(\mathcal{B})\). For all \(j\in[\log(K)-1]\cup\{0\}\), once \(v_{t,j}\) has been sampled we sample \(v_{t,(j+1)}\) from the probability distribution defined by:

\[\mathbb{P}[v_{t,(j+1)}=v]:=\llbracket\uparrow(v)=v_{t,j}\rrbracket\pi_{t}(v) \ \ \forall v\in\mathcal{B}^{\prime}\]

noting that \(v_{t,(j+1)}\) is a child of \(v_{t,j}\). We define:

\[\mathcal{P}_{t}:=\{v_{t,j}\mid j\in[\log(K)]\cup\{0\}\}\,.\]

CanProp then selects:

\[a_{t}:=v_{t,\log(K)}\]

and then receives the loss \(\ell_{t,a_{t}}\). The function \(w_{t}\) is then updated to \(w_{t+1}\) as follows. Firstly we define,

\[w_{t+1}(v,\mathcal{S}):=w_{t}(v,\mathcal{S})\ \ \ \ \ \forall(v,\mathcal{S})\in\{v^{ \prime}\in\mathcal{B}^{\prime}\mid\uparrow(v^{\prime})\notin\mathcal{P}_{t}\} \times 2^{\mathcal{X}}\,.\]

We then define:

\[\psi_{t,\log(K)}:=\exp\left(\frac{-\eta\ell_{t,a_{t}}}{\prod_{j\in[\log(K)]} \pi_{t}(v_{t,j})}\right)\,.\]Once we have defined \(\psi_{t,j}\) for some \(j\in[\log(K)]\) we then define:

\[\psi_{t,(j-1)}:=1-(1-\psi_{t,j})\pi_{t}(v_{t,j})\]

\[\beta_{t}(v):=\frac{\llbracket v\in\mathcal{P}_{t}\rrbracket\psi_{t,j}+ \llbracket v\notin\mathcal{P}_{t}\rrbracket}{\psi_{t,(j-1)}}\quad\forall v\in \{\triangleleft(v_{t,(j-1)}),\triangleright(v_{t,(j-1)})\}\]

\[w_{t+1}(v,\mathcal{S}):=(\llbracket x_{t}\in\mathcal{S}\rrbracket\beta_{t}(v)+ \llbracket x_{t}\notin\mathcal{S}\rrbracket)w_{t}(v,\mathcal{S})\quad\forall(v,\mathcal{S})\in\{\triangleleft(v_{t,(j-1)}),\triangleright(v_{t,(j-1)})\}\times 2 ^{\mathcal{X}}\,.\]

The regret bound of CanProp is given by the following theorem.

**Theorem B.1**.: _Suppose we have a function \(y:\mathcal{X}\to[K]\). For all \(v\in\mathcal{B}\) define:_

\[\mathcal{Q}(y,v):=\left\{x\in\mathcal{X}\mid y(x)\in\mathbb{J}(v)\right\}.\]

_Then the expected \(y\)-regret of CanProp is bounded by:_

\[\mathbb{E}[R(y)]\leq\frac{\eta KT}{2}-\frac{1}{\eta}\sum_{v\in\mathcal{B}^{ \prime}}\llbracket\mathcal{Q}(y,v)\neq\emptyset\rrbracket\ln(w_{1}(v,\mathcal{ Q}(y,v)))\,.\]

### Our Parameter Tuning

We now describe and analyse the initial weighting \(w_{1}\) and the learning rate \(\eta\) that we will use. Define \(\mathcal{X}^{\prime}:=\mathcal{X}\setminus\{x_{1}\}\). For all \((x,\mathcal{S})\in\mathcal{X}^{\prime}\times 2^{\mathcal{X}}\) define:

\[\sigma(x,\mathcal{S}):=\llbracket\llbracket x\in\mathcal{S}\rrbracket\neq \llbracket n(x)\in\mathcal{S}\rrbracket\rrbracket\,.\]

For all \((v,\mathcal{S})\in\mathcal{B}^{\prime}\times 2^{\mathcal{X}}\) we define:

\[w_{1}(v,\mathcal{S}):=\frac{1}{4}\prod_{x\in\mathcal{X}^{\prime}}\left(\sigma (x,\mathcal{S})\frac{1}{T}+(1-\sigma(x,\mathcal{S}))\left(1-\frac{1}{T} \right)\right)\,.\]

Given our parameter \(\rho\) we choose our learning rate as:

\[\eta:=\rho\sqrt{\frac{\ln(K)\ln(T)}{KT}}\,.\]

Given this initial weighting and learning rate, Theorem B.1 implies the following regret bound.

**Theorem B.2**.: _Given \(w_{1}\) and \(\eta\) are defined as above, then for any \(y:\mathcal{X}\to[K]\) the expected \(y\)-regret of CanProp is bounded by:_

\[\mathbb{E}[R(y)]\in\mathcal{O}\left(\left(\rho+\frac{\Phi(y)}{\rho}\right) \sqrt{\ln(K)\ln(T)KT}\right)\,.\]

## Appendix C Implementation with Contractions

### A Sequence of Binary Trees

For any trial \(t\) we have a natural tree-structure on the set \(\{x_{t^{\prime}}\mid t^{\prime}\in[t]\}\) formed by making \(n(x_{t^{\prime}})\) the parent of \(x_{t^{\prime}}\) for all \(t^{\prime}\in[t]\setminus\{1\}\). However, in order to utilise the methodology of [22] we need to work with binary trees. Hence, we now inductively define a sequence of binary trees \(\langle\mathcal{Z}_{t}\mid t\in[T]\setminus\{1\}\rangle\) where the vertices of \(\mathcal{Z}_{t}\) are a subset of those of \(\mathcal{Z}_{t+1}\). We also define a function \(\gamma:\mathcal{Z}_{T}\to\mathcal{X}\). This function \(\gamma\) has the property that for any \(t\in[T]\) and for any distinct leaves \(u,u^{\prime}\in\mathcal{Z}_{t}^{*}\) we have that \(\gamma(u)\neq\gamma(u^{\prime})\), and that:

\[\{\gamma(u^{\prime\prime})\mid u^{\prime\prime}\in\mathcal{Z}_{t}^{*}\}=\{x_{t ^{\prime}}\mid t^{\prime}\in[t]\}\,.\]

We define \(\mathcal{Z}_{2}\) to contain three vertices \(\{r(\mathcal{Z}_{2}),\triangleleft(r(\mathcal{Z}_{2})),\triangleright(r( \mathcal{Z}_{2}))\}\) where:

\[\gamma(r(\mathcal{Z}_{2})):=\gamma(\triangleleft(r(\mathcal{Z}_{2}))):=x_{1} \quad\quad;\quad\gamma(\triangleright(r(\mathcal{Z}_{2})):=x_{2}\,.\]

Now consider a trial \(t\in[T]\). We have that \(\mathcal{Z}_{t+1}\) is constructed from \(\mathcal{Z}_{t}\) via the following algorithm \(\textsc{Grow}_{t+1}\):

1. Let \(u\) be the unique leaf in \(\mathcal{Z}_{t}^{*}\) in which \(\gamma(u)=n(x_{t+1})\) and let \(u^{*}:=\uparrow(u)\).

2. Create two new vertices \(u^{\prime}\) and \(u^{\prime\prime}\).
3. Set \(\gamma(u^{\prime})\gets n(x_{t+1})\) and \(\gamma(u^{\prime\prime})\gets x_{t+1}\).
4. If \(u=\triangleleft(u^{*})\) then set \(\triangleleft(u^{*})\gets u^{\prime}\). Else set \(\triangleright(u^{*})\gets u^{\prime}\).
5. Set \(\triangleleft(u^{\prime})\gets u^{\prime\prime}\) and \(\triangleright(u^{\prime})\gets u\).

We also define a function \(d:\mathcal{Z}_{T}\to\mathbb{N}\cup\{0\}\) as follows. Define \(d^{\prime}(x_{1}):=0\) and for all \(t\in[T]\setminus\{1\}\) inductively define \(d^{\prime}(x_{t}):=d^{\prime}(n(x_{t}))+1\). Finally define \(d(u):=d^{\prime}(\gamma(u))\) for all \(u\in\mathcal{Z}_{T}\). Since for all \(t\in[T]\) we have that the vertices of \(\mathcal{Z}_{t}\) are a subset of those of \(\mathcal{Z}_{T}\) we have that \(d\) also defines a function over \(\mathcal{Z}_{t}\) for all \(t\in[T]\).

For all \(t\in[T]\) we define \(u_{t}\) to be the unique leaf of \(\mathcal{Z}_{t}\) for which \(\gamma(u_{t})=x_{t}\).

### Contractions

Our efficient implementation of CanProp will have a data-structure at every vertex \(v\in\mathcal{B}^{\prime}\). However, to achieve polylogarithmic time per trial we can only update a polylogarithmic number of these data-structures per trial. This necessitates the use of _contractions_ of our trees \(\{\mathcal{Z}_{t}\mid t\in[T]\setminus\{1\}\}\) which are defined as follows. A _contraction_ of a full binary tree \(\mathcal{Q}\) is another full binary tree \(\mathcal{J}\) which satisfies the following:

* The vertices of \(\mathcal{J}\) are a subset of those of \(\mathcal{Q}\).
* \(r(\mathcal{J})=r(\mathcal{Q})\).
* Given an internal vertex \(u\in\mathcal{J}^{\dagger}\) we have \(\triangleleft_{\mathcal{J}}(u)\in\Downarrow_{\mathcal{Q}}(\triangleleft_{ \mathcal{Q}}(u))\) and \(\triangleright_{\mathcal{J}}(u)\in\Downarrow_{\mathcal{Q}}(\triangleright_{ \mathcal{Q}}(u))\).
* Any leaf of \(\mathcal{J}\) is a leaf of \(\mathcal{Q}\).

Note that any contraction of \(\mathcal{Z}_{t}\) is also a contraction of \(\mathcal{Z}_{t+1}\) and hence, by induction, a contraction of \(\mathcal{Z}_{t^{\prime}}\) for all \(t^{\prime}\geq t\). Given a trial \(t\) and a contraction \(\mathcal{J}\) of \(\mathcal{Z}_{t-1}\) we now define the operation \(\textsc{Insert}_{t}(\mathcal{J})\) which acts on \(\mathcal{J}\) by the following algorithm:

1. Let \(\hat{u}\) be the unique vertex in \(\mathcal{J}\setminus\{r(\mathcal{J})\}\) such that \(u_{t}\) is in the maximal subtree of \(\mathcal{Z}_{t}\) with \(\hat{u}\) and \(\uparrow_{\mathcal{J}}(\hat{u})\) as leaves.
2. Let \(u^{*}:=\Gamma_{\mathcal{Z}_{t}}(u_{t},\hat{u})\).
3. Add the vertices \(u^{*}\) and \(u_{t}\) to the tree \(\mathcal{J}\).
4. Let \(u^{\prime}:=\uparrow_{\mathcal{J}}(\hat{u})\).
5. If \(\hat{u}=\triangleleft_{\mathcal{J}}(u^{\prime})\) then set \(\triangleleft_{\mathcal{J}}(u^{\prime})\gets u^{*}\). Else set \(\triangleright_{\mathcal{J}}(u^{\prime})\gets u^{*}\).
6. If \(\hat{u}\in\Downarrow_{\mathcal{Z}_{t}}(\triangleleft_{\mathcal{Z}_{t}}(u^{* }))\) then set \(\triangleleft_{\mathcal{J}}(u^{*})\leftarrow\hat{u}\) and \(\triangleright_{\mathcal{J}}(u^{*})\gets u_{t}\). Else set \(\triangleright_{\mathcal{J}}(u^{*})\leftarrow\hat{u}\) and \(\triangleleft_{\mathcal{J}}(u^{*})\gets u_{t}\). \(\triangleleft_{\mathcal{J}}(u^{*})\gets u_{t}\).

Later in this paper we will show how this operation can be done in polylogarithmic time. Note that after the operation we have that \(\mathcal{J}\) is a contraction of \(\mathcal{Z}_{t}\) and \(u_{t}\) has been added to it's leaves. From now on when we use the term _contraction_ we mean any contraction of \(\mathcal{Z}_{T}\).

### Contraction-Based Bayesian Networks

Here we shall define a bayesian network over any contraction \(\mathcal{J}\) and show how it can be utilised to compute certain quantities required by CanProp. First define the quantity \(\phi_{0}:=0\) and for all \(j\in\mathbb{N}\cup\{0\}\) inductively define:

\[\phi_{j+1}:=\left(1-\frac{1}{T}\right)\phi_{j}+\frac{1}{T}(1-\phi_{j})\,.\]

The algorithm must compute these quantities for all \(j\in[T]\). However, for all \(t\in[T]\) we have that \(\phi_{t}\) doesn't have to be computed until trial \(t\) so computing these quantities is constant time per trial. Given a contraction \(\mathcal{J}\), a vertex \(u\in\mathcal{J}\setminus r(\mathcal{J})\) and indices \(i,i^{\prime}\in\{0,1\}\) define:

\[\tau_{i,i^{\prime}}(\mathcal{J},u):=\llbracket i\neq i^{\prime}\rrbracket\phi _{(d(u)-d(\uparrow_{\mathcal{J}}(u)))}+\llbracket i=i^{\prime}\rrbracket\left(1- \phi_{(d(u)-d(\uparrow_{\mathcal{J}}(u)))}\right)\]which defines the transition matrix from \(\uparrow_{\mathcal{J}}(u)\) to \(u\) in a bayesian network over \(\mathcal{J}\). We shall now show how belief propagation over such bayesian networks can be used to compute the quantities we need in CanProp. Suppose we have a contraction \(\mathcal{J}\) and a function \(\lambda:\mathcal{J}^{\star}\to\mathbb{R}_{+}\). This function \(\lambda\) induces a function \(\lambda^{\prime}:\mathcal{X}\to\mathbb{R}_{+}\) defined as follows. Given \(x\in\mathcal{X}\), if there exists a leaf \(u\in\mathcal{J}^{\star}\) with \(\gamma(u)=x\) then \(\lambda^{\prime}(x)=\lambda(u)\). Otherwise \(\lambda^{\prime}(x)=1\). For all \(\mathcal{S}\in 2^{\mathcal{X}}\) define:

\[\tilde{w}(\mathcal{J},\lambda,\mathcal{S}):=\left(\prod_{x\in\mathcal{S}} \lambda^{\prime}(x)\right)\left(\prod_{x\in\mathcal{X}^{\prime}}\left(\sigma(x,\mathcal{S})\frac{1}{T}+(1-\sigma(x,\mathcal{S}))\left(1-\frac{1}{T}\right) \right)\right)\,.\]

For the CanProp algorithm we will need to compute

\[\sum_{\mathcal{S}\in 2^{\mathcal{X}}}[\gamma(\hat{u})\in\mathcal{S}]\tilde{w}( \mathcal{J},\lambda,\mathcal{S})\] (3)

for some leaf \(\hat{u}\in\mathcal{J}^{\star}\) and some function \(\lambda:\mathcal{J}^{\star}\to\mathbb{R}_{+}\). We shall now show how we can compute this quantity via belief propagation on the bayesian network. In particular, we shall construct a quantity \(\tilde{\Lambda}(\mathcal{J},\lambda,u)\) equal to the quantity in Equation (3). To do this, first define the function \(\lambda^{\star}:\mathcal{J}\to\mathbb{R}_{+}\) so that for all \(u\in\mathcal{J}^{\star}\) we have \(\lambda^{\star}(u)=\lambda(u)\) and for all \(u\in\mathcal{J}^{\dagger}\) we have \(\lambda^{\star}(u)=1\). For all vertices \(u\in\mathcal{J}\) and all indices \(i\in\{0,1\}\) define:

\[\tilde{\kappa}_{i}(\mathcal{J},\lambda,u):=[\![i=0]\!]+[\![i=1]\!]\lambda^{ \star}(u)\,.\]

For all \(\hat{u}\in\mathcal{J}\) define:

\[\mathcal{F}(\mathcal{J},\hat{u}):=\{f\in\{0,1\}^{\mathcal{J}}\mid f(\hat{u})=1\}\]

and then define:

\[\tilde{\Lambda}(\mathcal{J},\lambda,\hat{u}):=\sum_{f\in\mathcal{F}( \mathcal{J},\hat{u})}\;\prod_{u\in\mathcal{J}\setminus r(\mathcal{J})}\tau_{f (\uparrow_{\mathcal{J}}(u)),f(u)}(\mathcal{J},u)\tilde{\kappa}_{f(u)}( \mathcal{J},\lambda,u)\,.\]

The equality of this quantity and that given in Equation (3) is given by the following theorem.

**Theorem C.1**.: _Given a contraction \(\mathcal{J}\), a function \(\lambda:\mathcal{J}^{\star}\to\mathbb{R}_{+}\) and some leaf \(\hat{u}\in\mathcal{J}^{\star}\) we have:_

\[\tilde{\Lambda}(\mathcal{J},\lambda,\hat{u})=\sum_{\mathcal{S}\in 2^{ \mathcal{X}}}[\![\gamma(\hat{u})\in\mathcal{S}]\tilde{w}(\mathcal{J},\lambda, \mathcal{S})\,.\]

Note that \(\tilde{\Lambda}(\mathcal{J},\lambda,\hat{u})\) is of the exact form to be solved via belief propagation over \(\mathcal{J}\). However, belief propagation is too slow (taking \(\Theta(|\mathcal{J}|)\) time) - we will remedy this later.

### Cancelation Propagation with Contractions

We now describe how to implement CanProp with contractions. For each \(v\in\mathcal{B}^{\prime}\) we maintain a contraction \(\mathcal{A}(v)\) and a function \(\lambda_{v}:\mathcal{A}(v)^{\star}\to\mathbb{R}_{+}\). We initialise with \(\mathcal{A}(v)\) identical to \(\mathcal{Z}_{2}\) and \(\lambda_{v}(u)=1\) for both leaves \(u\in\mathcal{Z}_{2}^{\star}\). Via induction over \(t\) we will have that at the start of each trial \(t\) we have, for all sets \(\mathcal{S}\in 2^{\mathcal{X}}\), that:

\[w_{t}(v,\mathcal{S})=\tilde{w}(\mathcal{A}(v),\lambda_{v},\mathcal{S})/4\,.\] (4)

On trial \(t\) we do as follows. First we update \(\mathcal{Z}_{t-1}\) to \(\mathcal{Z}_{t}\) using the algorithm \(\textsc{Grow}_{t}\). We will perform the necessary modifications to our contractions as we sample the path \(\mathcal{P}_{t}\). In particular, we first set \(v_{t,0}:=r(\mathcal{B})\) and then for each \(j\in[\log(K)-1]\cup\{0\}\) in turn we do as follows. For each \(v\in\{\!\!\triangleleft(v_{t,j}),\triangleright(v_{t,j})\}\) run \(\textsc{Insert}_{t}(\mathcal{A}(v))\) and set \(\lambda_{v}(u_{t})\gets 1\). Since \(\lambda_{v}(u_{t})=1\) Equation (4) still holds and hence, by Theorem C.1, we have:

\[\theta_{t}(v)=\tilde{\Lambda}(\mathcal{A}(v),\lambda_{v},u_{t})/4\,.\]

After \(\theta_{t}(v)\) has been computed for both \(v\in\{\!\!\triangleleft(v_{t,j}),\triangleright(v_{t,j})\}\) we can now sample \(v_{t,j+1}\).

Once we have selected the action \(a_{t}\) we then update the functions \(\{\lambda_{v}\mid\uparrow_{\mathcal{B}}(v)\in\mathcal{P}_{t}\}\) by setting \(\lambda_{v}(u_{t})\leftarrow\beta_{t}(v)\) for all \(v\in\mathcal{B}^{\prime}\) with \(\uparrow_{\mathcal{B}}(v)\in\mathcal{P}_{t}\). It is clear now that Equation (4) holds inductively.

### Notational Relationship to the Main Body

We now point out how the notation in this section relates to that of the main body. In particular, we have, for all \(v\in\mathcal{B}^{\prime}\), all \(u\in\mathcal{A}(v)\) and all \(i,i^{\prime}\in\{0,1\}\), that:

* \(\kappa_{i}(\mathcal{A}(v),u)=\tilde{\kappa}_{i}(\mathcal{A}(v),\lambda_{v},u)\).
* \(\Lambda(\mathcal{A}(v),u)=\tilde{\Lambda}(\mathcal{A}(v),\lambda_{v},u)\).

We note that the function \(\lambda_{v}\) does not explicity appear in our pseudocode since it can be inferred from \(\kappa_{i}(\mathcal{A}(v),\cdot)\).

## Appendix D Utilising Ternary Search Trees

There are now only two things left to do in order to achieve polylogarithmic time per trial - to make an efficient online implementation of the \(\textsc{Insert}_{t}(\cdot)\) operation and an efficient online algorithm to perform belief propagation over our contractions. In order to do this we will utilise the methodology of [22] which we now describe. However, we do not give the full details of the rebalancing technique and refer the reader to [22] for these details (noting that [22] uses different notation).

### Ternary Search Trees

In this section we will consider a full binary tree \(\mathcal{J}\). A _(full) ternary tree_\(\mathcal{D}\) is a rooted tree in which each internal vertex \(s\in\mathcal{D}^{\dagger}\) has three children denoted by \(\triangleleft(s)\), \(\triangledown(s)\), \(\triangleright(s)\) and called the _left_, _centre_, and _right_ children respectively. We now define what it means for a ternary tree \(\mathcal{D}\) to be a ternary search tree (TST) of \(\mathcal{J}\). Firstly, the vertex set of \(\mathcal{D}\) is partitioned into two sets \(\mathcal{D}^{\diamond}\) and \(\mathcal{D}^{\bullet}\). Every vertex \(s\in\mathcal{D}\) is associated with a vertex \(\mu(s)\in\mathcal{J}\) and every \(s\in\mathcal{D}^{\bullet}\) is also associated with a vertex \(\mu^{\prime}(s)\in\Downarrow_{\mathcal{J}}(\mu(s))^{\dagger}\). The root \(r(\mathcal{D})\) is contained in \(\mathcal{D}^{\diamond}\) and \(\mu(r(\mathcal{D})):=r(\mathcal{J})\). Each internal vertex \(s\in\mathcal{D}^{\dagger}\) is associated with a vertex \(\xi(s)\in\mathcal{J}\). If \(s\in\mathcal{D}^{\diamond}\) then \(\xi(s)\in\Downarrow(\mu(s))^{\dagger}\) and if \(s\in\mathcal{D}^{\bullet}\) then \(\xi(s)\) lies on the path (in \(\mathcal{J}\)) from \(\mu(s)\) to \(\uparrow(\mu^{\prime}(s))\). For all \(s\in\mathcal{D}^{\dagger}\) we have:

* \(\triangledown(s)\in\mathcal{D}^{\bullet}\), \(\mu(\triangledown(s)):=\mu(s)\) and \(\mu^{\prime}(\triangledown(s)):=\xi(s)\).
* \(\triangleleft(s)\) satisfies:
* If \(s\in\mathcal{D}^{\diamond}\) then \(\triangleleft(s)\in\mathcal{D}^{\diamond}\) and \(\mu(\triangleleft(s)):=\triangleleft(\xi(s))\).
* If \(s\in\mathcal{D}^{\bullet}\) and \(\mu^{\prime}(s)\in\Downarrow(\xi(s))\) then \(\triangleleft(s)\in\mathcal{D}^{\diamond}\) and \(\mu(\triangleleft(s)):=\triangleleft(\xi(s))\).
* Else \(\triangleleft(s)\in\mathcal{D}^{\bullet}\), \(\mu(\triangleleft(s)):=\triangleleft(\xi(s))\) and \(\mu^{\prime}(\triangleleft(s)):=\mu^{\prime}(s)\).
* \(\triangleright(s)\) satisfies:
* If \(s\in\mathcal{D}^{\diamond}\) then \(\triangleright(s)\in\mathcal{D}^{\diamond}\) and \(\mu(\triangleright(s)):=\triangleright(\xi(s))\).
* If \(s\in\mathcal{D}^{\bullet}\) and \(\mu^{\prime}(s)\in\Downarrow(\zeta(\xi(s)))\) then \(\triangleright(s)\in\mathcal{D}^{\diamond}\) and \(\mu(\triangleright(s)):=\triangleright(\xi(s))\).
* Else \(\triangleright(s)\in\mathcal{D}^{\bullet}\), \(\mu(\triangleright(s)):=\triangleright(\xi(s))\) and \(\mu^{\prime}(\triangleright(s)):=\mu^{\prime}(s)\).

Finally, for each leaf \(s\in\mathcal{D}^{\star}\) we have:

* If \(s\in\mathcal{D}^{\diamond}\) then \(\mu(s)\) is a leaf of \(\mathcal{J}\).
* If \(s\in\mathcal{D}^{\bullet}\) then there exists \(u\in\mathcal{J}^{\dagger}\) such that \(\mu(s)=\mu^{\prime}(s)=u\).

Intuitively, each vertex \(s\in\mathcal{D}\) is associated with a subtree \(\hat{\mathcal{J}}(s)\) of \(\mathcal{J}\). If \(s\in\mathcal{D}^{\diamond}\) then \(\hat{\mathcal{J}}(s):=\Downarrow(\mu(s))\) and if \(s\in\mathcal{D}^{\bullet}\) then \(\hat{\mathcal{J}}(s)\) is the subtree of all descendants of \(\mu(s)\) which are not proper descendants of \(\mu^{\prime}(s)\). For every \(s\in\mathcal{D}\) such that \(\hat{\mathcal{J}}(s)\) contains only a single vertex, we have that \(s\) is a leaf of \(\mathcal{D}\). Otherwise \(s\) is an internal vertex of \(\mathcal{D}\) and its children are as follows. We say that \(\hat{\mathcal{J}}(s)\) is _split_ at the vertex \(\xi(s)\in\hat{\mathcal{J}}(s)^{\dagger}\). If \(s\in\mathcal{D}^{\bullet}\) we require that \(\xi(s)\) is on the path in \(\mathcal{J}\) from \(\mu(s)\) to \(\mu^{\prime}(s)\). The action of splitting \(\hat{\mathcal{J}}(s)\) at \(\xi(s)\) partitions \(\hat{\mathcal{J}}(s)\) into the subtrees \(\hat{\mathcal{J}}(\triangleleft(s))\), \(\hat{\mathcal{J}}(\triangledown(s))\) and \(\hat{\mathcal{J}}(\triangleright(s))\) defined as follows:

* \(\hat{\mathcal{J}}(\triangleleft(s)):=\Downarrow(\triangleleft(\xi(s)))\cap\hat{ \mathcal{J}}(s)\).
* \(\hat{\mathcal{J}}(\triangleright(s)):=\Downarrow(\triangleright(\xi(s)))\cap\hat{ \mathcal{J}}(s)\).

* \(\hat{\mathcal{J}}(\triangledown(s)):=\hat{\mathcal{J}}(s)\setminus(\hat{ \mathcal{J}}(\triangle(s))\cup\hat{\mathcal{J}}(\triangleright(s)))\).

Utilising the methodology of [22] we will maintain TSTs of \(\mathcal{Z}_{t}\) (at each trial \(t\)) and the trees in \(\{\mathcal{A}(v)\mid v\in\mathcal{B}^{\prime}\}\), each with height \(\mathcal{O}(\ln(T))\). Note that these trees are dynamic, in that vertices are inserted into them over time. [22] shows how, after such an insertion, the corresponding TST can be _rebalanced_, in time \(\mathcal{O}(\ln(T))\), so that its height is still in \(\mathcal{O}(\ln(T))\). This rebalancing is performed via a sequence of \(\mathcal{O}(\ln(T))\)_tree rotations_, which generalise the concept of tree rotations in binary search trees.

### Searching

In this section we show how we can use our TSTs to implement the operation \(\textsc{Insert}_{t}(\mathcal{J})\) on any trial \(t\) and contraction \(\mathcal{J}\) of \(\mathcal{Z}_{t-1}\). To do this we need to perform the following two search operations:

1. Find the unique vertex \(\hat{u}\in\mathcal{J}\setminus\{r(\mathcal{J})\}\) such that \(u_{t}\) is in the maximal subtree of \(\mathcal{Z}_{t}\) with \(\hat{u}\) and \(\uparrow_{\mathcal{J}}(\hat{u})\) as leaves.
2. Find \(u^{*}:=\Gamma_{\mathcal{Z}_{t}}(u_{t},\hat{u})\).

To perform these tasks in polylogarithmic time we will utilise TSTs \(\mathcal{E}\) and \(\mathcal{D}\) of \(\mathcal{Z}_{t}\) and \(\mathcal{J}\) respectively. Both the searching tasks utilise a function \(\nu:\mathcal{Z}_{t}^{2}\rightarrow\{\blacktriangle,\blacktriangleleft, \blacktriangleright\}\) defined, for all \(u,u^{\prime}\in\mathcal{Z}_{t}\) as follows. If \(u^{\prime}\in\Downarrow_{\mathcal{Z}_{t}}(\triangle(u))\) or \(u^{\prime}\in\Downarrow_{\mathcal{Z}_{t}}(\triangleright(u))\) then \(\nu(u,u^{\prime}):=\blacktriangle\) or \(\nu(u,u^{\prime}):=\blacktriangleright\) respectively. Otherwise \(\nu(u,u^{\prime}):=\blacktriangle\). This can be computed as follows. If \(u=u^{\prime}\) then \(\nu(u,u^{\prime})=\blacktriangle\). Otherwise let \(\tilde{s}\) and \(\tilde{s}^{\prime}\) be the unique leaves of \(\mathcal{E}\) such that \(\mu(\tilde{s})=u\) and \(\mu(\tilde{s}^{\prime})=u^{\prime}\). Let \(s^{*}:=\Gamma_{\mathcal{E}}(\tilde{s},\tilde{s}^{\prime})\) and let \(\hat{s}\) and \(\hat{s}^{\prime}\) be the children of \(s^{*}\) which are ancestors of \(\tilde{s}\) and \(\tilde{s}^{\prime}\) respectively. If \(\hat{s}\neq\triangledown(s^{*})\) then we have \(\nu(u,u^{\prime})=\blacktriangle\). If \(\xi(s^{*})=u\) then we have \(\nu(u,u^{\prime})=\blacktriangle\) or \(\nu(u,u^{\prime})=\blacktriangle\) if \(\hat{s}^{\prime}=\triangle(s^{*})\) or \(\hat{s}^{\prime}=\triangleright(s^{*})\) respectively. If \(\hat{s}=\triangledown(s^{*})\) and \(\xi(s^{*})\neq u\) then we perform the following process. Start with \(s\) equal to \(\hat{s}\). At any point in the process we do as follows. If \(s\in\mathcal{E}^{\circ}\) then the process terminates with \(\nu(u,u^{\prime}):=\blacktriangle\). If \(s\in\mathcal{E}^{\bullet}\) and \(u=\xi(s)\) then the process terminates with \(\nu(u,u^{\prime})=\blacktriangle\) or \(\nu(u,u^{\prime})=\blacktriangleright\) if \(\triangle(s)\in\mathcal{E}^{\bullet}\) or \(\triangleright(s)\in\mathcal{E}^{\bullet}\) respectively. If \(s\in\mathcal{E}^{\bullet}\) and \(u\neq\xi(s)\) then we reset \(s\) as equal to the child of \(s\) which is an ancestor of \(\tilde{s}\) and continue the process.

The vertex \(\hat{u}\) can be found as follows. We construct a root-to-leaf path in \(\mathcal{D}\) such that, given a vertex \(s\) in the path, the next vertex in the path is \(\trianglelefteq(s)\), \(\triangleright(s)\) or \(\triangledown(s)\) if \(\nu(\xi(s),u_{t})\) is equal to \(\blacktriangle\), \(\blacktriangleright\) or \(\blacktriangle\) respectively. Given that \(s^{\prime}\) is the leaf of \(\mathcal{D}\) that is in this path we have \(\hat{u}=\mu(s^{\prime})\).

The vertex \(u^{*}\) can then be found as follows. We construct a root-to-leaf path in \(\mathcal{E}\) such that, given a vertex \(s\) in the path, the next vertex in the path is found as follows. If \(\nu(\xi(s),u_{t})=\nu(\xi(s),\hat{u})\) then given \(\nu(\xi(s),u_{t})\) is equal to \(\blacktriangle\), \(\blacktriangleright\) or \(\blacktriangle\), the next vertex is equal to \(\trianglelefteq(s)\), \(\triangleright(s)\) or \(\triangledown(s)\) respectively. Otherwise, the next vertex is \(\triangledown(s)\). Given that \(s^{\prime}\) is the leaf of \(\mathcal{E}\) that is in this path we have \(u^{*}=\mu(s^{\prime})\).

The fact that these algorithms find the correct vertices is given in the following theorem:

**Theorem D.1**.: _The above algorithms are correct._

### Belief Propagation

Here we utilise the methodology of [7] in order to efficiently compute the function \(\tilde{\Lambda}\) that appears in the CanProp implementation. i.e. given a contraction \(\mathcal{J}\), a function \(\lambda:\mathcal{J}^{\star}\rightarrow\mathbb{R}_{+}\) and some leaf \(\hat{u}\in\mathcal{J}^{\star}\) we need to compute \(\tilde{\Lambda}(\mathcal{J},\lambda,\hat{u})\). For brevity let us define, for all \(i,i^{\prime}\in\{0,1\}\), and all vertices \(u\in\mathcal{J}\setminus\{r(\mathcal{J})\}\), the quantities:

\[\hat{\tau}_{i,i^{\prime}}(u):=\tau_{i,i^{\prime}}(\mathcal{J},u)\quad\quad;\quad \hat{\kappa}_{i}(u):=\tilde{\kappa}_{i}(\mathcal{J},\lambda,u)\,.\]

For simplicity of presentation we will utilise a tree \(\mathcal{J}^{\prime}\) which is defined as identical to \(\mathcal{J}\) except with a single vertex added as the parent of \(r(\mathcal{J})\). For all \(i,i^{\prime}\in\{0,1\}\) we define \(\hat{\kappa}_{i}(r(\mathcal{J}^{\prime})):=1\) and \(\hat{\tau}_{i,i^{\prime}}(r(\mathcal{J}))=\llbracket i=i^{\prime}\rrbracket\). For all \(u\in\mathcal{J}\) we will define \(\uparrow(u):=\uparrow_{\mathcal{J}^{\prime}}(u)\)

We will utilise a TST \(\mathcal{D}\) of \(\mathcal{J}\) by maintaining _potentials_ on the vertices of \(\mathcal{D}\) defined as follows. First, as in Section D.1, for any vertex \(s\in\mathcal{D}\) we define the subtree \(\hat{\mathcal{J}}(s)\) of \(\mathcal{J}\) to be equal to \(\Downarrow_{\mathcal{J}}(\mu(s))\) if \(s\in\mathcal{D}^{\circ}\) and equal to the subtree in \(\mathcal{J}\) of all descendants of \(\mu(s)\) which are not proper descendants of \(\mu^{\prime}(s)\) if \(s\in\mathcal{D}^{\bullet}\). For all \(s\in\mathcal{D}^{\circ}\) and \(i\in\{0,1\}\) we define:

\[\Psi_{i}(s):=\sum_{f\in\{0,1\}^{\hat{\mathcal{J}}(s)\cup\{\uparrow(u(s))\}}} \llbracket f(\uparrow(\mu(s)))=i\rrbracket\prod_{u\in\hat{\mathcal{J}}(s)}\hat{ \tau}_{f(\uparrow(u)),f(u)}(u)\hat{\kappa}_{f(u)}(u)\]and for all \(s\in\mathcal{D}^{\bullet}\) and \(i,i^{\prime}\in\{0,1\}\) we define:

\[\Omega_{i,i^{\prime}}(s):=\sum_{f\in\{0,1\}^{\mathcal{J}(s)\cup\{\tau(\mu(s))\}}} \llbracket f(\uparrow(\mu(s)))=i\rrbracket[\![f(\mu^{\prime}(s))=i^{\prime}] \!]\prod_{u\in\hat{\mathcal{J}}(s)}\hat{\tau}_{f(\uparrow(u)),f(u)}(u)\hat{ \kappa}_{f(u)}(u)\,.\]

We have the following recurrence relations for these potentials. Suppose we have an internal vertex \(s\in\mathcal{D}^{\dagger}\) and \(i,i^{\prime}\in\{0,1\}\). If \(s\in\mathcal{D}^{\circ}\) we have:

\[\Psi_{i}(s)=\sum_{i^{\prime\prime}\in\{0,1\}}\Omega_{i,i^{\prime\prime}}( \triangledown(s))\Psi_{i^{\prime\prime}}(\triangleup(s))\Psi_{i^{\prime \prime}}(\triangleright(s))\,.\]

If, instead, \(s\in\mathcal{D}^{\bullet}\) then, by letting \(s^{\prime}:=\triangleup(s)\), \(s^{\prime\prime}:=\triangleright(s)\) if \(\triangleup(s)\in\mathcal{D}^{\bullet}\) and \(s^{\prime}:=\triangleright(s)\), \(s^{\prime\prime}:=\triangleup(s)\) otherwise, we have:

\[\Omega_{i,i^{\prime}}(s)=\sum_{i^{\prime\prime}\in\{0,1\}}\Omega_{i,i^{\prime \prime}}(\triangledown(s))\Omega_{i^{\prime\prime},i^{\prime}}(s^{\prime}) \Psi_{i^{\prime\prime}}(s^{\prime\prime})\,.\]

If, on a trial \(t\), we perform the operation \(\textsc{Insert}_{t}(\mathcal{J})\) or change the value of \(\lambda(u_{t})\) these recurrence relations can be used (in conjunction with the tree rotations) to update the potentials in logarithmic time.

Now that we have defined our potentials we will show how to use them to compute \(\tilde{\Lambda}(\mathcal{J},\lambda,\hat{u})\) in logarithmic time. To do this we recursively define the following quantities for \(i\in\{0,1\}\). Let \(\omega_{i}(r(\mathcal{D})):=1\). Given an internal vertex \(s\in\mathcal{D}^{\circ}\) we define:

\[\omega_{i}(\triangledown(s)):=\omega_{i}(s)\ \ ;\ \ \omega_{i}^{ \prime}(\triangledown(s)):=\Psi_{i}(\triangleup(s))\Psi_{i}(\triangleright(s))\] \[\omega_{i}(\triangleup(s)):=\Psi_{i}(\triangleright(s))\sum_{i^{ \prime}\in\{0,1\}}\omega_{i^{\prime}}(s)\Omega_{i^{\prime},i}(\triangledown(s ))\ ;\ \ \omega_{i}(\triangleright(s)):=\Psi_{i}(\triangleup(s))\sum_{i^{ \prime}\in\{0,1\}}\omega_{i^{\prime}}(s)\Omega_{i^{\prime},i}(\triangledown( s))\,.\]

Given an internal vertex \(s\in\mathcal{D}^{\bullet}\) define \(s^{\prime}:=\triangleup(s)\), \(s^{\prime\prime}:=\triangleright(s)\) if \(\triangleup(s)\in\mathcal{D}^{\bullet}\) and \(s^{\prime}:=\triangleright(s)\), \(s^{\prime\prime}:=\triangleup(s)\) otherwise. Then:

\[\omega_{i}(\triangledown(s)):=\omega_{i}(s)\ \ ;\ \ \omega_{i}^{ \prime}(\triangledown(s)):=\Psi_{i}(s^{\prime\prime})\sum_{i^{\prime}\in\{0,1 \}}\Omega_{i,i^{\prime}}(s^{\prime})\omega_{i^{\prime}}^{\prime}(s)\] \[\omega_{i}(s^{\prime}):=\sum_{i^{\prime}\in\{0,1\}}\omega_{i^{ \prime}}(s)\Omega_{i^{\prime},i}(s)\Psi_{i}(s^{\prime\prime})\ \ ;\ \ \omega_{i}^{ \prime}(s^{\prime}):=\omega_{i}^{\prime}(s)\] \[\omega_{i}(s^{\prime\prime}):=\sum_{i^{\prime},i^{\prime\prime} \in\{0,1\}}\omega_{i^{\prime}}(s)\Omega_{i^{\prime},i}(\triangledown(s))\omega _{i^{\prime\prime}}^{\prime}(s)\Omega_{i,i^{\prime\prime}}(s^{\prime})\,.\]

For \(s\in\mathcal{D}^{\circ}\), \(\omega_{i}^{\prime}(s)\) is not required and hence is arbitrary. We inductively compute the values \(\{\omega_{i}(s),\omega_{i}^{\prime}(s)\mid i\in\{0,1\}\}\) for all \(s\) in the path from \(r(\mathcal{D})\) to the unique leaf \(\hat{s}\in\mathcal{D}^{\star}\) in which \(\mu(\hat{s})=\hat{u}\). We then have \(\tilde{\Lambda}(\mathcal{J},\lambda,\hat{u})=\omega_{1}(\hat{s})\).

Since this is known methodology we do not include a proof in this paper and direct the reader to [7].

## Appendix E Proofs

### Theorem 3.3

This theorem is proved in appendices B to D and the theorems therein.

### Theorem 3.6

For all \(x\in\mathcal{C}\) define \(\hat{\gamma}(x):=\gamma(x,\hat{y},\mathcal{X})\).

Choose a set \(\mathcal{S}\subseteq\mathcal{C}\) in which for all \(t\in[T]\) there exists \(x\in\mathcal{S}\) with \(\Delta(x,x_{t})<\hat{\gamma}(x)/3c\). For all trials \(t\) let \(\mathcal{S}_{t}\) be the set of all contexts \(x\in\mathcal{S}\) in which there exists \(s\in[t]\) with \(\Delta(x,x_{s})<\hat{\gamma}(x)/3c\). Now consider a trial \(t\in[T]\setminus\{1\}\) in which \(\hat{y}(x_{t})\neq\hat{y}(x_{n(t)})\) and choose \(x\in\mathcal{S}\) with \(\Delta(x,x_{t})<\hat{\gamma}(x)/3c\).

Assume, for contradiction, that \(x\in\mathcal{S}_{t-1}\). Then there exists \(s\in[t-1]\) with \(\Delta(x,x_{s})<\hat{\gamma}(x)/3c\) so that by the triangle inequality we have:

\[\Delta(x_{t},x_{s})\leq\Delta(x,x_{s})+\Delta(x,x_{t})<2\hat{\gamma}(x)/3c\]

which implies that \(\Delta(x_{t},x_{n(t)})<2\hat{\gamma}(x)/3\). By the triangle inequality we then have that:

\[\Delta(x,x_{n(t)})\leq\Delta(x_{t},x_{n(t)})+\Delta(x,x_{t})<2\hat{\gamma}(x)/ 3+\hat{\gamma}(x)/3c\leq 3\hat{\gamma}(x)/3=\hat{\gamma}(x)\]

Since \(\Delta(x,x_{t})<\hat{\gamma}(x)\) we have \(y(x)=y(x_{t})\) and hence that \(y(x)\neq y(x_{n(t)})\). But this contradicts the fact that \(\Delta(x,x_{n(t)})<\hat{\gamma}(x)\).

We have hence shown that \(x\notin\mathcal{S}_{t-1}\). Since \(x\in\mathcal{S}_{t}\) we then have that \(|\mathcal{S}_{t}|\geq|\mathcal{S}_{t-1}|\). Since \(|\mathcal{S}_{1}|\geq 1\) this implies that:

\[\Phi(\bm{y})=1+\sum_{t\in[T]\setminus\{1\}}[\hat{y}(x_{t})\neq\hat{y}(x_{n(t) })]\leq|\mathcal{S}_{T}|\leq|\mathcal{S}|\]

as required.

### Theorem 3.9

Let \(\epsilon\) be such that:

\[\lim_{\delta\to 0}\frac{1}{\delta}\int_{x\in\mathcal{M}(\hat{y},\mu,2e, \delta)}1\leq 2\alpha(\hat{y},\mu)\qquad;\qquad\lim_{\delta\to 0}\frac{1}{ \delta}\int_{x\in\mathcal{M}(\hat{y},\mu,2e,\delta)}\mu(x)\leq 2\hat{\alpha}( \hat{y},\mu)\] (5)

Since we are only interested in the behaviour as \(q\to\infty\) assume, without loss of generality, that \(\sqrt{d}/q<\epsilon/3\). Choose \(\lambda>0\) and \(\lambda^{\prime}>0\) sufficiently small for this proof to work. For all \(x\in\mathcal{G}_{q}^{d}\) let \(\mathcal{H}(x)\) be the set of points \(x^{\prime}\in[0,1]^{d}\) such that \(x\) is the nearest neighbour (or one of them if the nearest neighbour is not unique) of \(x^{\prime}\) in \(\mathcal{G}_{q}^{d}\). Let \(\mathcal{L}\) be the set of all \(x\in\mathcal{G}_{q}^{d}\) for which there exists \(x^{\prime},x^{\prime\prime}\in\mathcal{H}(x)\cap\mathcal{E}(\mu,\epsilon)\) with \(\hat{y}(x^{\prime})\neq\hat{y}(x^{\prime\prime})\). Note that for all \(x^{\prime}\in\mathcal{L}\) we have \(\mathcal{H}(x^{\prime})\subseteq\mathcal{M}(\hat{y},\mu,2\epsilon,\sqrt{d}/q)\) so:

\[\frac{q}{\sqrt{d}}\int_{x\in\mathcal{M}(\hat{y},\mu,2e,\sqrt{d}/q)}1\geq\frac {q}{\sqrt{d}}\sum_{x^{\prime}\in\mathcal{L}}\int_{x\in\mathcal{H}(x^{\prime}) }1=\frac{q}{\sqrt{d}}|\mathcal{L}|q^{-d}=\frac{1}{q^{d-1}\sqrt{d}}|\mathcal{L}|\]

By considering the limit of this inequality as \(q\to\infty\), and noting that \(d\) is being treated as a constant, we then have, by Equation (5), that:

\[|\mathcal{L}|\in\mathcal{O}(\alpha(\hat{y},\mu)q^{d-1})\] (6)

Now define:

\[p:=\sum_{x^{\prime}\in\mathcal{L}}\int_{x\in\mathcal{H}(x^{\prime})}\mu(x)\]

Since \(\mathcal{H}(x^{\prime})\subseteq\mathcal{M}(\hat{y},\mu,2\epsilon,\sqrt{d}/q)\) for all \(x^{\prime}\in\mathcal{L}\), we have:

\[\frac{q}{\sqrt{d}}p\leq\frac{q}{\sqrt{d}}\int_{x\in\mathcal{M}(\hat{y},\mu,2e, \sqrt{d}/q)}\mu(x)\]

By considering the limit of this inequality as \(q\to\infty\), and noting that \(d\) is being treated as a constant, we then have, by Equation (5), that:

\[p\in\mathcal{O}(\tilde{\alpha}(\hat{y},\mu)/q)\] (7)

Let \(\mathcal{D}\) be the set of all \(x\in\mathcal{G}_{q}^{d}\) such that there exists \(x^{\prime}\in\mathcal{H}(x)\) with \(\mu(x)\neq 0\). Now define \(\hat{y}^{\prime}:[0,1]^{d}\to[K]\) such that for all \(x\in[0,1]^{d}\) we have:

* If \(x\in\mathcal{D}\setminus\mathcal{L}\) then \(\hat{y}^{\prime}(x)\) is the unique \(a\in[K]\) such that there exists \(x^{\prime}\in\mathcal{H}(x)\) with \(\mu(x^{\prime})\neq 0\) and \(a=\hat{y}(x^{\prime})\). Note that if there existed more than one such \(a\) then we would have \(x\in\mathcal{L}\) which is a contradiction.
* If \(x\notin\mathcal{D}\setminus\mathcal{L}\) then \(\hat{y}^{\prime}(x)=\hat{y}^{\prime}(\hat{x})\) where \(\hat{x}\) is the nearest neighbour of \(x\) in \(\mathcal{D}\setminus\mathcal{L}\)Let \(\mathcal{A}\) be a finite set of points in \(\mathbb{R}^{d}\) such that for all \(x\in\mathbb{R}^{d}\) with \(\Delta(x,0)\leq 1\) there exists \(x^{\prime}\in\mathcal{A}\) with \(\Delta(x,x^{\prime})<\lambda\). Define:

\[\mathcal{A}^{\prime}:=\bigcup_{i\in[\lceil\log(qd)\rceil]}\{2^{i}x/q\,|\,x\in \mathcal{A}\}\]

Note that:

\[|\mathcal{A}^{\prime}|\in\mathcal{O}(\ln(q))\] (8)

We now show that for all \(x\in\mathbb{R}^{d}\) with \(1/q\leq\Delta(x,0)\leq d\) there exists \(x^{\prime\prime}\in\mathcal{A}^{\prime}\) with:

\[\Delta(x,x^{\prime\prime})<2\Delta(x,0)\lambda\] (9)

To show this choose any such \(x\) and let \(i\in\mathbb{N}\) be such that \(2^{i-1}/q\leq\Delta(x,0)<2^{i}/q\). By the assumption on \(x\) we have that \(i\in[\lceil\log(qd)\rceil]\). Since \(\Delta(xq2^{-i},0)<1\) choose \(x^{\prime}\in\mathcal{A}\) such that \(\Delta(xq2^{-i},x^{\prime})<\lambda\). Then we have:

\[\Delta(x,2^{i}x^{\prime}/q)=(2^{i}/q)\Delta(xq2^{-i},x^{\prime})<(2^{i}/q) \lambda\leq 2\Delta(x,0)\lambda\]

so, since \(2^{i}x^{\prime}/q\in\mathcal{A}^{\prime}\), we have proved that Equation (9) is true.

We now let \(\mathcal{S}^{\prime}\) be a finite set of points in \(\mathbb{R}^{d}\) such that for all \(x\in[0,1]^{d}\) there exists some \(x^{\prime}\in\mathcal{S}^{\prime}\) with \(\Delta(x,x^{\prime})<\lambda^{\prime}\epsilon\). Now define:

\[\mathcal{S}:=\mathcal{L}\cup\mathcal{S}^{\prime}\cup\bigcup_{x\in\mathcal{L}} \{x^{\prime}+x\,|\,x^{\prime}\in\mathcal{A}^{\prime}\}\]

Let \(\mathcal{X}:=\{x_{t}\,|\,t\in[T]\}\). Take any \(x\in\mathcal{X}\). We now show that there exists \(x^{\dagger}\in\mathcal{S}\) with \(\Delta(x,x^{\dagger})<\gamma(x^{\dagger},\hat{y}^{\prime},\mathcal{X})/3c\). We have three cases:

* First consider the case that \(\Delta(x,x^{\prime})>\epsilon/3\). Let \(x^{\prime}\) be the nearest neighbour of \(x\) in \([0,1]^{d}\) with \(\hat{y}^{\prime}(x)\neq\hat{y}^{\prime}(x^{\prime})\). Choose \(x^{\dagger}\in\mathcal{S}^{\prime}\) such that \(\Delta(x,x^{\dagger})<\lambda^{\prime}\epsilon\). Since \(\Delta(x,x^{\dagger})<\epsilon/3\) we must have \(\hat{y}^{\prime}(x^{\dagger})=\hat{y}^{\prime}(x)\). Let \(x^{\prime\prime}\) be the nearest neighbour of \(x^{\dagger}\) in \(\mathcal{X}\) with \(\hat{y}^{\prime}(x^{\prime\prime})\neq\hat{y}^{\prime}(x^{\dagger})\). Since \(\hat{y}^{\prime}(x^{\dagger})=\hat{y}^{\prime}(x)\) we must have that \(\hat{y}^{\prime}(x^{\prime\prime})\neq\hat{y}^{\prime}(x)\) so that \(\Delta(x,x^{\prime\prime})>\epsilon/3\). By the triangle inequality we then have: \[\epsilon/3<\Delta(x,x^{\prime\prime})\leq\Delta(x,x^{\dagger})+\Delta(x^{ \dagger},x^{\prime\prime})<\lambda^{\prime}\epsilon+\Delta(x^{\dagger},x^{ \prime\prime})=\lambda^{\prime}\epsilon+\gamma(x^{\dagger},\hat{y}^{\prime},\mathcal{X})\] Hence \(\gamma(x^{\dagger},\hat{y}^{\prime},\mathcal{X})>(1/3-\lambda^{\prime})\epsilon\) so that: \[\Delta(x,x^{\dagger})<\lambda^{\prime}\epsilon<\frac{\lambda^{\prime}}{1/3- \lambda^{\prime}}\gamma(x^{\dagger},\hat{y}^{\prime},\mathcal{X})<\gamma(x^{ \dagger},\hat{y}^{\prime},\mathcal{X})/3c\] as required.
* Now consider the case that \(x\in\mathcal{L}\). In this case we trivially have the result with \(x^{\dagger}:=x\).
* Finally consider the case that \(x\notin\mathcal{L}\) and \(\Delta(x,x^{\prime})\leq\epsilon/3\). Let \(x^{\prime}\) be the nearest neighbour of \(x\) in \([0,1]^{d}\) with \(\hat{y}^{\prime}(x)\neq\hat{y}^{\prime}(x^{\prime})\). Let \(\hat{x}\) and \(\hat{x}^{\prime}\) be the nearest neighbours of \(x\) and \(x^{\prime}\) in \(\mathcal{D}\setminus\mathcal{L}\) respectively. Note that by definition of \(\hat{y}^{\prime}\) we have \(\hat{y}^{\prime}(\hat{x})=\hat{y}^{\prime}(x)\) and \(\hat{y}^{\prime}(\hat{x}^{\prime})=\hat{y}^{\prime}(x^{\prime})\). By definition of \(\mathcal{D}\) we must have \(x\in\mathcal{D}\), so since \(x\notin\mathcal{L}\) we have \(\hat{x}=x\). Noting that \(\Delta(x^{\prime},\hat{x}^{\prime})\leq\Delta(x^{\prime},\hat{x})\) we must then have that \(\Delta(x^{\prime},\hat{x}^{\prime})\leq\Delta(x^{\prime},x)\) which means, by the triangle inequality, that \(\Delta(x,\hat{x}^{\prime})\leq 2\Delta(x,x^{\prime})\). Since \(x,\hat{x}^{\prime}\in\mathcal{D}\) choose \(z\in\mathcal{H}(x)\) and \(z^{\prime}\in\mathcal{H}(\hat{x}^{\prime})\) such that \(\mu(z),\mu(z^{\prime})\neq 0\). Since \(x,\hat{x}^{\prime}\in\mathcal{D}\setminus\mathcal{L}\) we have: \[\hat{y}(z)=\hat{y}^{\prime}(z)=\hat{y}^{\prime}(x)\neq\hat{y}^{\prime}(\hat{x}^{ \prime})=\hat{y}^{\prime}(z^{\prime})=\hat{y}(z^{\prime})\] By the triangle inequality and above we have: \[\Delta(z,z^{\prime})\leq\Delta(z,x)+\Delta(x,\hat{x}^{\prime})+\Delta(\hat{x}^{ \prime},z^{\prime})\leq 2\Delta(x,x^{\prime})+\sqrt{d}/q\leq\epsilon\] (10) so since \(\mu(z),\mu(z^{\prime})\neq 0\) we must have that the straight line from \(z\) to \(z^{\prime}\) is entirely contained in \(\mathcal{E}(\mu,\epsilon/2)\). Since \(\hat{y}(z)\neq\hat{y}(z^{\prime})\) we can then choose some \(z^{\dagger}\) in the line from \(z\) to \(z^{\prime}\) that is on the decision boundary of \(\hat{y}\) (i.e. any open set around \(z^{\dagger}\) contains some \(\tilde{z}\) with \(\hat{y}(\tilde{z})\neq\hat{y}(z^{\dagger})\)). Since there exists an open set around \(z^{\dagger}\) that is entirely contained in \(\mathcal{E}(\mu,\epsilon)\)we must now have, by definition of \(\mathcal{L}\), that there exists \(\hat{z}\in\mathcal{L}\) such that \(z^{\dagger}\in\mathcal{H}(\hat{z})\). By the triangle inequality and Equation (10) we have:

\[\Delta(x,\hat{z}) \leq\Delta(x,z)+\Delta(z,z^{\dagger})+\Delta(z^{\dagger},\hat{z}) \leq\Delta(z,z^{\dagger})+\sqrt{d}/q\leq\Delta(z,z^{\prime})+\sqrt{d}/q\] \[\leq 2\Delta(x,x^{\prime})+2\sqrt{d}/q\] (11)

Since \(x\in\mathcal{D}\setminus\mathcal{L}\) we have \(\hat{y}^{\prime}(\hat{z})=\hat{y}^{\prime}(x)\) for all \(\hat{z}\in\mathcal{H}(x)\) and hence we must have \(x^{\prime}\notin\mathcal{H}(x)\) so that \(\Delta(x,x^{\prime})\geq\sqrt{d}/(2q)\). By Equation (11) this means that:

\[\Delta(x,x^{\prime})\geq\Delta(x,\hat{z})/6\] (12)

By Equation (9) choose \(z^{\prime\prime}\in\mathcal{A}^{\prime}\) such that:

\[\Delta(x-\hat{z},z^{\prime\prime})<2\Delta(x-\hat{z},0)\lambda\] (13)

and define \(x^{\dagger}=\hat{z}+z^{\prime\prime}\). Since \(\hat{z}\in\mathcal{L}\) we have \(x^{\dagger}\in\mathcal{S}\) as required. Note that by equations (12) and (13) we have:

\[\Delta(x,x^{\dagger})=\Delta(x-\hat{z},z^{\prime\prime})<2\Delta(x,\hat{z}) \lambda\leq 12\Delta(x,x^{\prime})\lambda\] (14)

Since \(2\lambda<1/6\) we now have, from equations (12) and (14), that \(\Delta(x,x^{\dagger})<\Delta(x,x^{\prime})\) so that \(\hat{y}^{\prime}(x)=\hat{y}^{\prime}(x^{\dagger})\). Let \(x^{\prime\prime}\) be the nearest neighbour of \(x^{\dagger}\) in \(\mathcal{X}\) with \(\hat{y}^{\prime}(x^{\prime\prime})\neq\hat{y}^{\prime}(x^{\dagger})\). Since \(\hat{y}^{\prime}(x^{\dagger})=\hat{y}^{\prime}(x)\) we must have that \(\hat{y}^{\prime}(x^{\prime\prime})\neq\hat{y}^{\prime}(x)\) so that \(\Delta(x,x^{\prime\prime})\geq\Delta(x,x^{\prime})\). By the triangle inequality and Equation (14) we then have:

\[\Delta(x,x^{\prime}) \leq\Delta(x,x^{\prime\prime})\leq\Delta(x,x^{\dagger})+\Delta(x^ {\dagger},x^{\prime\prime})<12\Delta(x,x^{\prime})\lambda+\Delta(x^{\dagger},x ^{\prime\prime})\] \[=12\Delta(x,x^{\prime})\lambda+\gamma(x^{\dagger},\hat{y}^{ \prime},\mathcal{X})\]

Hence \(\gamma(x^{\dagger},\hat{y}^{\prime},\mathcal{X})>(1-12\lambda)\Delta(x,x^{ \prime})\) so that by Equation (14) we have:

\[\Delta(x,x^{\dagger})<12\Delta(x,x^{\prime})\lambda<\frac{12\lambda}{1-12 \lambda}\gamma(x^{\dagger},\hat{y}^{\prime},\mathcal{X})<\gamma(x^{\dagger}, \hat{y}^{\prime},\mathcal{X})/3c\]

as required.

Let \(\boldsymbol{y}^{\prime}\in[K]^{T}\) be such that \(y^{\prime}_{t}:=\hat{y}^{\prime}(x_{t})\) for all \(t\in[T]\). We have shown that for all \(x\in\mathcal{X}\) there exists \(x^{\dagger}\in\mathcal{S}\) with \(\Delta(x,x^{\dagger})<\gamma(x^{\dagger},\hat{y}^{\prime},\mathcal{X})/3c\). By equations (6) and (8) we have that:

\[|\mathcal{S}|\in\mathcal{O}(|\mathcal{L}|\ln(q))\subseteq\mathcal{O}(\alpha( \hat{y},\mu)q^{d-1}\ln(q))\subseteq\tilde{\mathcal{O}}(\alpha(\hat{y},\mu)q^{ d-1})\]

Invoking Theorem 3.6 then gives us:

\[\Phi(\boldsymbol{y}^{\prime})\in\mathcal{O}(\alpha(\hat{y},\mu)q^{d-1})\]

so by Theorem 3.3 we have:

\[\mathbb{E}[R(\boldsymbol{y}^{\prime})]\in\tilde{\mathcal{O}}\left(\left(\rho+ \frac{\Phi(\boldsymbol{y}^{\prime})}{\rho}\right)\sqrt{KT}\right)\subseteq \tilde{\mathcal{O}}\left((1+\alpha(\hat{y},\mu))q^{\frac{d-1}{2}}\sqrt{KT}\right)\] (15)

We also have:

\[R(\boldsymbol{y})-R(\boldsymbol{y}^{\prime})=\sum_{t\in[T]}(\ell_{t,y_{t}}- \ell_{t,y^{\prime}_{t}})=\sum_{t\in[T]}(\ell_{t,\hat{y}(z_{t})}-\ell_{t,\hat{y }^{\prime}(x_{t})})\leq\sum_{t\in[T]}[\hat{y}(z_{t})\neq\hat{y}^{\prime}(x_{t })]\]

But \(\hat{y}(z_{t})\neq\hat{y}^{\prime}(x_{t})\) implies that \(x_{t}\notin\mathcal{D}\setminus\mathcal{L}\) so since \(x_{t}\in\mathcal{D}\) we must have \(x_{t}\in\mathcal{L}\) which happens with probability \(p\) and hence, by Equation (7), we have:

\[\mathbb{E}[R(\boldsymbol{y})-R(\boldsymbol{y}^{\prime})]\leq pT\in\mathcal{O}(T \tilde{\alpha}(\hat{y},\mu)/q)\] (16)

Combining equations (15) and (16) gives us:

\[\mathbb{E}[R(\boldsymbol{y})]\in\tilde{\mathcal{O}}((1+\alpha(\hat{y},\mu))q^{ \frac{d-1}{2}}\sqrt{KT}+T\tilde{\alpha}(\hat{y},\mu)/q)\]

Since \(q:=\lceil(T/K)^{1/(d+1)}\rceil\) we have now shown that:

\[\mathbb{E}[R(\boldsymbol{y})]\in\tilde{\mathcal{O}}\left((1+\alpha(\hat{y},\mu) +\tilde{\alpha}(\hat{y},\mu))T^{\frac{d}{d+1}}K^{\frac{1}{d+1}}\right)\]

as required.

### Theorem b.1

For every trial \(t\in[T]\) define:

\[\Delta_{t}:=-\sum_{v\in\mathcal{B}^{\prime}}[\![\mathcal{Q}(y,v)\neq\emptyset]\ln (w_{t}(v,\mathcal{Q}(y,v)))\]

Choose some arbitrary trial \(t\in[T]\). From here until we say otherwise all probabilities and expectations (i.e. whenever we use \(\mathbb{P}[\cdot]\) or \(\mathbb{E}[\cdot]\)) are implicitly conditional on the state of the algorithm at the start of trial \(t\). Note first that we have:

\[\Delta_{t}-\Delta_{t+1}=\sum_{v\in\mathcal{B}^{\prime}}[\![\mathcal{Q}(y,v) \neq\emptyset]\ln\left(\frac{w_{t+1}(v,\mathcal{Q}(y,v))}{w_{t}(v,\mathcal{Q}( y,v))}\right)\] (17)

For all \(j\in[\log(K)]\cup\{0\}\) let \(\gamma_{t,j}\) be the ancestor (in \(\mathcal{B}\)) of \(y(x_{t})\) at depth \(j\). Note that for all \(v\in\mathcal{X}\setminus\{\gamma_{t,j}\mid j\in[\log(K)]\cup\{0\}\}\) we have \(y(x_{t})\notin\Downarrow(v)\) so that \(x_{t}\notin\mathcal{Q}(y,v)\) and hence, directly from the CanProp algorithm, we have \(w_{t+1}(v,\mathcal{Q}(y,v))=w_{t}(v,\mathcal{Q}(y,v))\). By Equation (17) and the fact that \(\mathcal{Q}(y,v)\neq\emptyset\) for all ancestors \(v\) of \(y(x_{t})\) this implies that:

\[\Delta_{t}-\Delta_{t+1}=\sum_{j\in[\log(K)]}\ln\left(\frac{w_{t+1}(\gamma_{t,j },\mathcal{Q}(y,\gamma_{t,j}))}{w_{t}(\gamma_{t,j},\mathcal{Q}(y,\gamma_{t,j} ))}\right)\] (18)

For all \(j\in[\log(K)]\) define:

\[\lambda_{t,j}:=\ln\left(\frac{w_{t+1}(\gamma_{t,j},\mathcal{Q}(y,\gamma_{t,j} ))}{w_{t}(\gamma_{t,j},\mathcal{Q}(y,\gamma_{t,j}))}\right)\]

and:

\[\epsilon_{t,j}:=\mathbb{E}[\ln(\psi_{t,j})\mid\gamma_{t,j}\in\mathcal{P}_{t}]\]

Now choose some arbitrary \(j\in[\log(K)]\). If \(\gamma_{t,(j-1)}\in\mathcal{P}_{t}\) then \(\gamma_{t,(j-1)}=v_{t,(j-1)}\) so \(\uparrow(\gamma_{t,j})=v_{t,(j-1)}\) and hence, since \(x_{t}\in\mathcal{Q}(y,\gamma_{t,j})\), we have \(\lambda_{t,j}=\ln(\beta_{t}(\gamma_{t,j}))\). By definition of \(\beta_{t}(\gamma_{t,j})\) this means that:

\[\mathbb{E}[\lambda_{t,j}\mid\gamma_{t,j}\in\mathcal{P}_{t}\,,\,\gamma_{t,(j- 1)}\in\mathcal{P}_{t}]=\epsilon_{t,j}-\mathbb{E}[\ln(\psi_{t,(j-1)})\mid \gamma_{t,j}\in\mathcal{P}_{t}\,,\,\gamma_{t,(j-1)}\in\mathcal{P}_{t}]\]

and that:

\[\mathbb{E}[\lambda_{t,j}\mid\gamma_{t,j}\notin\mathcal{P}_{t}\,,\,\gamma_{t,(j -1)}\in\mathcal{P}_{t}]=-\mathbb{E}[\ln(\psi_{t,(j-1)})\mid\gamma_{t,j}\notin \mathcal{P}_{t}\,,\,\gamma_{t,(j-1)}\in\mathcal{P}_{t}]\]

Multiplying these two equations by \(\mathbb{P}[\gamma_{t,j}\in\mathcal{P}_{t}\mid\gamma_{t,(j-1)}\in\mathcal{P}_{t}]\) and \(\mathbb{P}[\gamma_{t,j}\notin\mathcal{P}_{t}\mid\gamma_{t,(j-1)}\in\mathcal{P }_{t}]\) respectively, and summing them together, then gives us:

\[\mathbb{E}[\lambda_{t,j}\mid\gamma_{t,(j-1)}\in\mathcal{P}_{t}]=\mathbb{P}[ \gamma_{t,j}\in\mathcal{P}_{t}\mid\gamma_{t,(j-1)}\in\mathcal{P}_{t}]\epsilon_ {t,j}-\mathbb{E}[\ln(\psi_{t,(j-1)}\mid\gamma_{t,(j-1)}\in\mathcal{P}_{t}]\]

Since \(\mathbb{P}[\gamma_{t,j}\in\mathcal{P}_{t}\mid\gamma_{t,(j-1)}\in\mathcal{P}_{t} ]=\pi_{t}(\gamma_{t,j})\) we then have:

\[\mathbb{E}[\lambda_{t,j}\mid\gamma_{t,(j-1)}\in\mathcal{P}_{t}]=\pi_{t}( \gamma_{t,j})\epsilon_{t,j}-\epsilon_{t,(j-1)}\] (19)

If, on the other hand, \(\gamma_{t,(j-1)}\notin\mathcal{P}_{t}\) then \(\uparrow(\gamma_{t,j})\notin\mathcal{P}_{t}\) so \(\lambda_{t,j}=0\). This means that:

\[\mathbb{E}[\lambda_{t,j}]=\mathbb{P}[\gamma_{t,(j-1)}\in\mathcal{P}_{t}] \mathbb{E}[\lambda_{t,j}\mid\gamma_{t,(j-1)}\in\mathcal{P}_{t}]\] (20)

Since the probability that \(\gamma_{t,(j-1)}\in\mathcal{P}_{t}\) is equal to \(\prod_{j^{\prime}\in[j-1]}\pi_{t}(\gamma_{t,j^{\prime}})\) we then have, by combining equations (19) and (20), that:

\[\mathbb{E}[\lambda_{t,j}]=\epsilon_{t,j}\prod_{j^{\prime}\in[j]}\pi_{t}(\gamma _{t,j^{\prime}})-\epsilon_{t,(j-1)}\prod_{j^{\prime}\in[j-1]}\pi_{t}(\gamma_{t, j^{\prime}})\]

By substituting into Equation (18) (after taking expectations) we then have that:

\[\mathbb{E}[\Delta_{t}-\Delta_{t+1}] =-\epsilon_{t,0}+\epsilon_{t,\log(K)}\prod_{j\in[\log(K)]}\pi_{t}( \gamma_{t,j})\] \[=-\mathbb{E}[\ln(\psi_{t,0})]+\mathbb{E}[\ln(\psi_{t,\log(K)}) \mid a_{t}=\gamma_{t,\log(K)}]\prod_{j\in[\log(K)]}\pi_{t}(\gamma_{t,j})\] (21)Note that if \(a_{t}=\gamma_{t,\log(K)}\) then \(\gamma_{t,j}=v_{t,j}\) for all \(j\in[\log(K)]\). By definition of \(\psi_{t,\log(K)}\) and the fact that \(\gamma_{t,\log(K)}=y(x_{t})\), Equation (21) then gives us:

\[\mathbb{E}[\Delta_{t}-\Delta_{t+1}]=-\mathbb{E}[\ln(\psi_{t,0})]-\eta\ell_{t,y (x_{t})}\] (22)

For all \((v,a)\in\mathcal{B}\times[K]\) define:

\[p_{t,a}(v)=\mathbb{P}[a_{t}=a\mid v\in\mathcal{P}_{t}]\]

noting that this is non-zero only when \(a\in\Downarrow(v)\). Suppose we have some \(v\in\mathcal{B}\setminus\{r(\mathcal{B})\}\) and some \(a\in\Downarrow(v)\cap[K]\). Then, since \(\mathbb{P}[a_{t}=a\mid v\notin\mathcal{P}_{t}]=0\), we have:

\[p_{t,a}(\uparrow(v))=\mathbb{P}[a_{t}=a\mid\uparrow(v)\in\mathcal{P}_{t}]= \mathbb{P}[a_{t}=a\mid v\in\mathcal{P}_{t}]\mathbb{P}[v\in\mathcal{P}_{t}\mid \uparrow(v)\in\mathcal{P}_{t}]=\pi_{t}(v)p_{t,a}(v)\]

Since \(p_{t,a}(v)=0\) whenever \(a\notin\Downarrow(v)\), this implies that for all \((v,a)\in\mathcal{B}^{\dagger}\times[K]\) we have:

\[p_{t,a}(v)=\pi_{t}(\triangleleft(v))p_{t,a}(\triangleleft(v))+\pi_{t}( \triangleright(v))p_{t,a}(\triangleright(v))\] (23)

For all \(a\in[K]\) define:

\[\hat{\ell}_{t,a}=\frac{[a_{t}=a]\ell_{t,a}}{\mathbb{P}[a_{t}=a]}\]

We now take the inductive hypothesis that for all \(j\in[\log(K)]\cup\{0\}\) we have:

\[\psi_{t,j}=\sum_{a\in[K]}p_{t,a}(v_{t,j})\exp(-\eta\hat{\ell}_{t,a})\]

and prove this via reverse induction (i.e. from \(j=\log(K)\) to \(j=0\)). Note that given \(a^{\prime}:=a_{t}\) we have \(\mathbb{P}[a_{t}=a^{\prime}]=\prod_{j\in[\log(K)]}\pi_{t}(v_{t,j})\) and hence:

\[\psi_{t,\log(K)}=\exp(-\eta\hat{\ell}_{t,a_{t}})\]

so the inductive hypothesis holds for \(j=\log(K)\). Now suppose that we have some \(j^{\prime}\in[\log(K)]\) and that the inductive hypothesis holds for \(j=j^{\prime}\). We shall now show that it holds also for \(j=j^{\prime}-1\). Let \(v^{\prime}\) be the child of \(v_{t,(j^{\prime}-1)}\) that is not equal to \(v_{t,j^{\prime}}\). Note that \(a_{t}\notin\Downarrow(v^{\prime})\) and hence \(\exp(-\eta\hat{\ell}_{t,a})=1\) for all \(a\in\Downarrow(v^{\prime})\) (i.e. whenever \(p_{t,a}(v^{\prime})\neq 0\)) which implies:

\[\sum_{a\in[K]}p_{t,a}(v^{\prime})\exp(-\eta\hat{\ell}_{t,a})=1\] (24)

For all \(a\in[K]\), Equation (23) gives us:

\[p_{t,a}(v_{t,(j^{\prime}-1)})\exp(-\eta\hat{\ell}_{t,a})=\pi_{t}(v^{\prime})p _{t,a}(v^{\prime})\exp(-\eta\hat{\ell}_{t,a})+\pi_{t}(v_{t,j^{\prime}})p_{t,a }(v_{t,j^{\prime}})\exp(-\eta\hat{\ell}_{t,a})\]

Substituting Equation (24) and the inductive hypothesis into this equation (when summed over all \(a\in[K]\)) then gives us:

\[\sum_{a\in[K]}p_{t,a}(v_{t,(j^{\prime}-1)})\exp(-\eta\hat{\ell}_{t,a})=\pi_{t }(v^{\prime})+\pi_{t}(v_{t,j^{\prime}})\psi_{t,j^{\prime}}\]

Since \(\pi_{t}(v^{\prime})+\pi_{t}(v_{t,j^{\prime}})=1\) we have, direct from the algorithm, that \(\pi_{t}(v^{\prime})+\pi_{t}(v_{t,j^{\prime}})\psi_{t,j^{\prime}}=\psi_{t,(j^{ \prime}-1)}\) so the inductive hypothesis holds for \(j=j^{\prime}-1\). We have hence shown that the inductive hypothesis holds for all \(j\in[\log(K)]\cup\{0\}\) and in particular for \(j=0\). Since \(p_{t,a}(v_{t,0})=\mathbb{P}[a_{t}=a]\) we then have:

\[\psi_{t,0}=\sum_{a\in[K]}\mathbb{P}[a_{t}=a]\exp(-\eta\hat{\ell}_{t,a})\] (25)

Since \(\exp(-z)\leq 1-z+z^{2}/2\) for all \(z\in\mathbb{R}_{+}\) we have, from Equation (25), that:

\[\psi_{t,0}\leq\sum_{a\in[K]}\mathbb{P}[a_{t}=a]\left(1-\eta\hat{\ell}_{t,a}+ \frac{\eta^{2}\hat{\ell}_{t,a}}{2}\right)=1-\eta\sum_{a\in[K]}\mathbb{P}[a_{t }=a]\hat{\ell}_{t,a}+\frac{\eta^{2}}{2}\sum_{a\in[K]}\mathbb{P}[a_{t}=a]\hat{ \ell}_{t,a}^{2}\]

so since \(\ln(1+z)\leq z\) for all \(z\in\mathbb{R}\) we have:

\[\ln(\psi_{t,0})\leq-\eta\sum_{a\in[K]}\mathbb{P}[a_{t}=a]\hat{\ell}_{t,a}+ \frac{\eta^{2}}{2}\sum_{a\in[K]}\mathbb{P}[a_{t}=a]\hat{\ell}_{t,a}^{2}\] (26)Noting that \(\mathbb{P}[a_{t}=a]\hat{\ell}_{t,a}=[\![a_{t}=a]\hat{\ell}_{t,a}\) for all \(a\in[K]\), we have:

\[\mathbb{E}\left[\sum_{a\in[K]}\mathbb{P}[a_{t}=a]\hat{\ell}_{t,a}\right]= \mathbb{E}[\ell_{t,a_{t}}]\]

and:

\[\mathbb{E}\left[\sum_{a\in[K]}\mathbb{P}[a_{t}=a]\hat{\ell}_{t,a}^{2}\right]= \mathbb{E}\left[\sum_{a\in[K]}\frac{[\![a_{t}=a]\!]\ell_{t,a}^{2}}{\mathbb{P}[ a_{t}=a]}\right]=\sum_{a\in[K]}\ell_{t,a}^{2}\leq K\]

Substituting these equations into Equation (26) (after taking expectations) gives us:

\[\mathbb{E}[\ln(\psi_{t,0})]\leq-\eta\mathbb{E}[\ell_{t,a_{t}}]+\eta^{2}K/2\]

which, upon substitution into Equation (22) gives us:

\[\mathbb{E}[\Delta_{t}-\Delta_{t+1}]\geq\eta(\mathbb{E}[\ell_{t,a_{t}}]-\ell_ {t,y(x_{t})})-\eta^{2}K/2\] (27)

Note that this equation implies that the same equation also holds when the expectation is not implicitly conditional on the state of the algorithm at the start of trial \(t\). Hence, we now drop the assumption that the expectation is conditional on the state of the algorithm at the start of trial \(t\). Summing Equation (27) over all trials \(t\in[T]\) and then rearranging gives us:

\[\mathbb{E}[R(y)]\leq\frac{1}{\eta}(\mathbb{E}[\Delta_{1}]-\mathbb{E}[\Delta_ {T+1}])+\frac{\eta KT}{2}\] (28)

Now consider a trial \(t\). For all \(v\in\mathcal{B}^{\dagger}\) let:

\[V_{t}(v):=\sum_{\mathcal{S}\in 2^{\mathcal{X}}}[\![x_{t}\in\mathcal{S}]\!]w_{t+1} (\triangleleft(v),\mathcal{S})+\sum_{\mathcal{S}\in 2^{\mathcal{X}}}[\![x_{t}\in \mathcal{S}]\!]w_{t+1}(\triangleright(v),\mathcal{S})\]

Now take any \(j\in[\log(K)-1]\cup\{0\}\) and let \(v:=v_{t,j}\). Note that:

\[V_{t}(v)=\beta_{t}(\triangleleft(v))\theta_{t}(\triangleleft(v))+\beta_{t}( \triangleright(v))\theta_{t}(\triangleright(v))\]

so that by definition of \(\pi_{t}(\triangleleft(v))\) and \(\pi_{t}(\triangleright(v))\) we have:

\[V_{t}(v)=(\theta_{t}(\triangleleft(v))+\theta_{t}(\triangleright(v)))(\pi_{t}( \triangleleft(v))\beta_{t}(\triangleleft(v))+\pi_{t}(\triangleright(v))\beta_{ t}(\triangleright(v)))\]

Without loss of generality assume that \(\triangleleft(v)\in\mathcal{P}_{t}\). Then the above equation implies that:

\[V_{t}(v)=(\theta_{t}(\triangleleft(v))+\theta_{t}(\triangleright(v)))\frac{\pi _{t}(\triangleleft(v))\psi_{t,j+1}+\pi_{t}(\triangleright(v))}{\psi_{t,j}}\]

so by definition of \(\psi_{t,j}\) we have:

\[V_{t}(v)=(\theta_{t}(\triangleleft(v))+\theta_{t}(\triangleright(v)))=\sum_{ \mathcal{S}\in 2^{\mathcal{X}}}[\![x_{t}\in\mathcal{S}]\!]w_{t}(\triangleleft(v), \mathcal{S})+\sum_{\mathcal{S}\in 2^{\mathcal{X}}}[\![x_{t}\in\mathcal{S}]\!]w_{t}( \triangleright(v),\mathcal{S})\]

Note that this equation trivially holds for all \(v\in\mathcal{B}^{\dagger}\setminus\mathcal{P}_{t}\) and hence holds for all \(v\in\mathcal{B}^{\dagger}\). Since for all such \(v\) and all \(\mathcal{S}\) with \(x_{t}\notin\mathcal{S}\) we have \(w_{t+1}(\triangleleft(v),\mathcal{S})=w_{t}(\triangleleft(v),\mathcal{S})\) and \(w_{t+1}(\triangleright(v),\mathcal{S})=w_{t}(\triangleright(v),\mathcal{S})\) we then have:

\[\sum_{\mathcal{S}\in 2^{\mathcal{X}}}w_{t+1}(\triangleleft(v),\mathcal{S})+\sum_{ \mathcal{S}\in 2^{\mathcal{X}}}w_{t+1}(\triangleright(v),\mathcal{S})=\sum_{ \mathcal{S}\in 2^{\mathcal{X}}}w_{t}(\triangleleft(v),\mathcal{S})+\sum_{\mathcal{S} \in 2^{\mathcal{X}}}w_{t}(\triangleright(v),\mathcal{S})\]

so, by induction on \(t\) we have, for all \(t\in[T+1]\), that:

\[\sum_{\mathcal{S}\in 2^{\mathcal{X}}}w_{t}(\triangleleft(v),\mathcal{S})+\sum_{ \mathcal{S}\in 2^{\mathcal{X}}}w_{t}(\triangleright(v),\mathcal{S})=1\]

Hence, for all \(v\in\mathcal{B}\setminus r(\mathcal{B})\) and \(\mathcal{S}\in 2^{\mathcal{X}}\), we have \(w_{t}(v,\mathcal{S})\in[0,1]\). We have now shown that \(\Delta_{T+1}\geq 0\) so that Equation 28 gives us:

\[\mathbb{E}[R(y)]\leq\frac{1}{\eta}\mathbb{E}[\Delta_{1}]+\frac{\eta KT}{2}\]

which, by definition of \(\Delta_{1}\), gives us the desired result.

### Theorem b.2

The fact that the weighting \(w_{1}\) is valid is given by the following lemma:

**Lemma E.1**.: _For all \(v\in\mathcal{B}^{\dagger}\) we have:_

\[\sum_{\mathcal{S}\in 2^{\mathcal{X}}}(w_{1}(\mathcal{\triangle}(v),\mathcal{S})+w _{t}(\triangleright(v),\mathcal{S}))=1\]

Proof.: We will show that for all \(v\in\mathcal{B}^{\prime}\) we have:

\[\sum_{\mathcal{S}\in 2^{\mathcal{X}}}w_{1}(v,\mathcal{S})=\frac{1}{2}\]

which directly implies the result. So take some arbitrary \(v\in\mathcal{B}^{\prime}\). Define, for all \(t\in[T]\), the sets:

\[\mathcal{X}^{\prime}_{t}:=\{x_{s}\mid s\in[t]\}\setminus\{x_{1}\}\quad\mathrm{ and}\quad\mathcal{F}_{t}:=\{0,1\}^{\mathcal{X}^{\prime}_{t}\cup\{x_{1}\}}\]

and for all \(x\in\mathcal{X}^{\prime}_{t}\) and \(f\in\mathcal{F}_{t}\) define the quantity:

\[\beta(x,f):=[\![f(x)\neq f(n(x))]\!]1/T+[\![f(x)=f(n(x))]\!](1-1/T)\]

which is defined since \(n(x)\in\mathcal{X}^{\prime}_{t}\cup\{x_{1}\}\). For all \(t\in[T-1]\) we have:

\[\sum_{f\in\mathcal{F}_{t+1}}\prod_{x\in\mathcal{X}^{\prime}_{t+1}}\beta(x,f)= \sum_{f\in\mathcal{F}_{t}}\left(\prod_{x\in\mathcal{X}^{\prime}_{t}}\beta(x,f )\right)\sum_{f(x_{t+1})\in\{0,1\}}\beta(x_{t+1},f)\] (29)

Given any \(f\in\mathcal{F}_{t}\) we have:

\[\sum_{f(x_{t+1})\in\{0,1\}}\beta(x_{t+1},f)=(1-1/T)+1/T=1\]

and hence by Equation (29) we have:

\[\sum_{f\in\mathcal{F}_{t+1}}\prod_{x\in\mathcal{X}^{\prime}_{t+1}}\beta(x,f)= \sum_{f\in\mathcal{F}_{t}}\prod_{x\in\mathcal{X}^{\prime}_{t}}\beta(x,f)\]

Since \(\mathcal{X}^{\prime}_{T}=\mathcal{X}^{\prime}\) this implies, by induction, that:

\[\sum_{f\in\mathcal{F}_{T}}\prod_{x\in\mathcal{X}^{\prime}}\beta(x,f)=\sum_{f \in\mathcal{F}_{1}}\prod_{x\in\mathcal{X}^{\prime}_{1}}\beta(x,f)=\sum_{f\in \mathcal{F}_{1}}\prod_{x\in\emptyset}\beta(x,f)=\sum_{f\in\mathcal{F}_{1}}1= |\mathcal{F}_{1}|=2\] (30)

Note that we have a bijection \(\mathcal{G}:\mathcal{F}_{T}\to 2^{\mathcal{X}}\) defined by:

\[\mathcal{G}(f):=\{x\in\mathcal{X}\mid f(x)=1\}\quad\forall f\in\mathcal{F}_{T}\]

and that for all \((f,x)\in\mathcal{F}_{T}\times\mathcal{X}^{\prime}\) we have:

\[\beta(x,f)=\sigma(x,\mathcal{G}(f))/T+(1-\sigma(x,\mathcal{G}(f)))(1-1/T)\]

Hence, Equation (30) shows us that:

\[\sum_{\mathcal{S}\in 2^{\mathcal{X}}}\prod_{x\in\mathcal{X}^{\prime}}\left( \sigma(x,\mathcal{S})\frac{1}{T}+(1-\sigma(x,\mathcal{S}))\left(1-\frac{1}{T }\right)\right)=2\]

This implies that:

\[\sum_{\mathcal{S}\in 2^{\mathcal{X}}}w_{1}(v,\mathcal{S})=\frac{1}{2}\]

which implies the result.

Now that we have shown that the weighting \(w_{1}\) is valid we can utilise Theorem B.1 to prove our regret bound. For any set \(\mathcal{S}\in 2^{\mathcal{X}}\) define:

\[\phi(\mathcal{S}):=\sum_{x\in\mathcal{X}^{\prime}}\sigma(x,\mathcal{S})\]

Note that for all \(v\in\mathcal{B}^{\dagger}\) and \(\mathcal{S}\in 2^{\mathcal{X}}\) we have:

\[w_{1}(v,\mathcal{S})=\frac{1}{4}\left(\frac{1}{T}\right)^{\phi(\mathcal{S})} \left(1-\frac{1}{T}\right)^{T-1-\phi(\mathcal{S})}\geq\frac{1}{4}\left(\frac{ 1}{T}\right)^{\phi(\mathcal{S})}\left(1-\frac{1}{T}\right)^{T}\]

so since \(T\ln(1-1/T)\in\mathcal{O}(1)\) we have:

\[-\ln(w_{1}(v,\mathcal{S}))\leq\ln(4)+\phi(\mathcal{S})\ln(T)-T\ln(1-1/T)\in \mathcal{O}(\phi(\mathcal{S})\ln(T)+1)\] (31)

As in the statement of Theorem B.1 define, for all \(v\in\mathcal{B}\), the set:

\[\mathcal{Q}(y,v):=\{x\in\mathcal{X}\mid y(x)\in\Downarrow(v)\}\]

First note that the graph (with vertex set \(\mathcal{X}\)) formed by linking \(x\) to \(n(x)\) for every \(x\in\mathcal{X}^{\prime}\) is a tree so that \(\Phi(y)\geq|\{y(x)\mid x\in\mathcal{X}\}|-1\). So since for all \(v\in\mathcal{B}^{\prime}\) we have \(\mathcal{Q}(y,v)\neq\emptyset\) if and only if \(v\) has a descendent in \(\{y(x)\mid x\in\mathcal{X}\}\) and each element of \(\{y(x)\mid x\in\mathcal{X}\}\) has \(\log(K)\) ancestors in \(\mathcal{B}^{\prime}\) we have:

\[\sum_{v\in\mathcal{B}^{\prime}}\llbracket\mathcal{Q}(y,v)\neq\emptyset \rrbracket\leq\log(K)|\{y(x)\mid x\in\mathcal{X}\}|\leq\log(K)(\Phi(y)+1)\] (32)

Now suppose we have some \(x\in\mathcal{X}^{\prime}\). If \(y(x)=y(n(x))\) then for all \(v\in\mathcal{B}^{\prime}\) we have \(x,n(x)\in\mathcal{Q}(y,v)\) or \(x,n(x)\notin\mathcal{Q}(y,v)\) and hence \(\sigma(x,\mathcal{Q}(y,v))=0\). On the other hand, if \(y(x)\neq y(n(x))\) then for any \(v\in\mathcal{B}^{\prime}\) with \(\sigma(x,\mathcal{Q}(y,v))=1\) we must have that either \(x\in\mathcal{Q}(y,v)\) or \(n(x)\in\mathcal{Q}(y,v)\) so \(v\) is an ancestor of either \(x\) or \(n(x)\) and hence there can be at most \(2\log(K)\) such \(v\). So in any case we have:

\[\sum_{v\in\mathcal{B}^{\prime}}\sigma(x,\mathcal{Q}(y,v))\leq\llbracket y(x) \neq y(n(x))\rrbracket 2\log(K)\]

Hence we have:

\[\sum_{v\in\mathcal{B}^{\prime}}\phi(\mathcal{Q}(y,v))=\sum_{x\in\mathcal{X}^{ \prime}}\sum_{v\in\mathcal{B}^{\prime}}\sigma(x,\mathcal{Q}(y,v))\leq 2\log(K) \Phi(y)\] (33)

Equation (31) gives us:

\[-\sum_{v\in\mathcal{B}^{\prime}}\llbracket\mathcal{Q}(y,v)\neq\emptyset \rrbracket\ln(w_{1}(v,\mathcal{Q}(y,v)))\in\mathcal{O}\left(\ln(T)\sum_{v\in \mathcal{B}^{\prime}}\phi(\mathcal{Q}(y,v))+\sum_{v\in\mathcal{B}^{\prime}} \llbracket\mathcal{Q}(y,v)\neq\emptyset\rrbracket\right)\]

Substituting in equations (32) and (33) then gives us:

\[-\sum_{v\in\mathcal{B}^{\prime}}\llbracket\mathcal{Q}(y,v)\neq\emptyset \rrbracket\ln(w_{1}(v,\mathcal{Q}(y,v)))\in\mathcal{O}(\ln(K)\ln(T)\Phi(y))\]

so by Theorem B.1 we have:

\[\mathbb{E}[R(y)]\in\mathcal{O}\left(\frac{\eta KT}{2}+\frac{\ln(K)\ln(T)\Phi (y)}{\eta}\right)\]

Since \(\eta=\rho\sqrt{\ln(K)\ln(T)/KT}\) we obtain the result.

### Theorem c.1

Recall our sequence of trees \(\langle\mathcal{Z}_{t}\mid t\in[T]\setminus\{1\}\rangle\) noting that each of these trees is a contraction so that \(\tau_{i,i^{\prime}}(\mathcal{Z}_{t},\cdot)\) is defined for all \(i,i^{\prime}\in\{0,1\}\). Let \(\epsilon:=1/T\). Define \(\lambda^{\prime}:\mathcal{X}\to\mathbb{R}_{+}\) as follows. Given \(x\in\mathcal{X}\), if there exists a leaf \(u\in\mathcal{J}^{\star}\) with \(\gamma(u)=x\) then \(\lambda^{\prime}(x)=\lambda(u)\). Otherwise \(\lambda^{\prime}(x)=1\). Given \(t\in[T]\) define \(\hat{\lambda}_{t}:\mathcal{Z}_{t}\to\mathbb{R}_{+}\) such that for all \(u\in\mathcal{Z}_{t}\) we have that \(\hat{\lambda}_{t}(u):=\lambda^{\prime}(\gamma(u))\) if \(u\) is a leaf of \(\mathcal{Z}_{t}\) and \(\hat{\lambda}_{t}(u):=1\) otherwise. For all \(t\in[T]\) and \(f:\{x_{t^{\prime}}\mid t^{\prime}\in[t]\}\to\{0,1\}\) define:

\[\mathcal{N}(f):=\{f^{\prime}\in\{0,1\}^{\mathcal{Z}_{t}}\mid\forall u\in \mathcal{Z}_{t}^{\star}\,,f^{\prime}(u)=f(\gamma(u))\}\]and:

\[\hat{w}(f):=\left(\prod_{t^{\prime}\in[t]:f(x_{t^{\prime}})=1}\lambda^{\prime}(x_{ t})\right)\prod_{t^{\prime}\in[t]\setminus\{1\}}([\![f(x_{t})\neq f(n(x_{t}))]\!] \epsilon+[\![f(x_{t})=f(n(x_{t}))]\!](1-\epsilon))\]

and:

\[\hat{\nu}(f):=\sum_{f^{\prime}\in\mathcal{N}(f)}\prod_{u\in\mathcal{Z}_{i} \setminus\{r(\mathcal{Z}_{i})\}}\tau_{f^{\prime}(\uparrow_{\mathcal{Z}_{i}}(u )),f^{\prime}(u)}(\mathcal{Z}_{t},u)\tilde{\kappa}_{f^{\prime}(u)}(\mathcal{Z }_{t},\hat{\lambda}_{t},u)\]

We now have the following lemma:

**Lemma E.2**.: _For all \(t\in[T]\) and \(f:\{x_{t^{\prime}}\mid t^{\prime}\in[t]\}\to\{0,1\}\) we have:_

\[\hat{w}(f)=\hat{\nu}(f)\]

Proof.: We prove by induction on \(t\). Suppose the result holds for \(t=s\) (for some \(s\geq 2\)). We now show that it holds for \(t=s+1\) as well. Let \(f^{*}\) be the restriction of \(f\) onto the set \(\{x_{t^{\prime}}\mid t^{\prime}\in[s]\}\). Let \(u^{*}\) and \(u^{\prime}\) be the unique leaves in \(\mathcal{Z}_{s+1}^{*}\) of which \(\gamma(u^{\prime})=n(x_{s+1})\) and \(\gamma(u^{*})=x_{s+1}\). By the construction of \(\mathcal{Z}_{s+1}\) these vertices are siblings. Let \(u^{\prime\prime}\) be the parent (in \(\mathcal{Z}_{s+1}\)) of both \(u^{*}\) and \(u^{\prime}\). First note that:

\[[\![f(x_{s+1})=0]\!]+[\![f(x_{s+1})=1]\!]\lambda^{\prime}(x_{s+1})=\tilde{ \kappa}_{f(x_{s+1})}(\mathcal{Z}_{s+1},\hat{\lambda}_{s+1},u^{*})\] (34)

Since, by the construction of \(\mathcal{Z}_{s+1}\), we have \(\gamma(\uparrow_{\mathcal{Z}_{s+1}}(u^{*}))=\gamma(u^{\prime\prime})=n(x_{s+1})\) we also have that \(d(\uparrow_{\mathcal{Z}_{s+1}}(u^{*}))=d(u^{*})-1\) so that, since \(\phi_{1}=\epsilon\), we have:

\[[\![f(x_{s+1})\neq f(n(x_{s+1}))]\!]\epsilon+[\![f(x_{s+1})=f(n(x_{s+1}))]\!] (1-\epsilon)=\tau_{f(n(x_{s+1})),f(x_{s+1})}(\mathcal{Z}_{s+1},u^{*})\] (35)

Equations (34) and (35) give us:

\[\hat{w}(f)=\hat{w}(f^{*})\tau_{f(n(x_{s+1})),f(x_{s+1})}(\mathcal{Z}_{s+1},u^ {*})\tilde{\kappa}_{f(x_{s+1})}(\mathcal{J},\hat{\lambda}_{s+1},u^{*})\] (36)

Now suppose we have some \(f^{\prime}\in\mathcal{N}(f)\). We have \(\gamma(u^{\prime\prime})=\gamma(u^{\prime})\) and hence \(d(\uparrow_{\mathcal{Z}_{s+1}}(u^{\prime}))=d(u^{\prime\prime})=d(u^{\prime})\) so since \(f^{\prime}(u^{\prime})=f(n(x_{s+1}))\) and \(\phi_{0}=0\) we have:

\[\tau_{f^{\prime}(\uparrow_{\mathcal{Z}_{s+1}}(u^{\prime})),f^{\prime}(u^{ \prime})}(\mathcal{Z}_{s+1},u^{\prime})=\tau_{f^{\prime}(u^{\prime\prime}),f^{ \prime}(u^{\prime})}(\mathcal{Z}_{s+1},u^{\prime})=[\![f^{\prime}(u^{\prime \prime})=f(n(x_{s+1}))]\!]\] (37)

Since, by the construction of \(\mathcal{Z}_{s+1}\), we have \(\uparrow_{\mathcal{Z}_{s+1}}(u^{\prime\prime})=\uparrow_{\mathcal{Z}_{s}}(u^{ \prime})\) and (as above) we have \(d(u^{\prime\prime})=d(u^{\prime})\), we also have:

\[\tau_{f^{\prime}(\uparrow_{\mathcal{Z}_{s+1}}(u^{\prime\prime})),f^{\prime}(u^{ \prime\prime})}(\mathcal{Z}_{s+1},u^{\prime\prime})=\tau_{f^{\prime}(\uparrow_ {\mathcal{Z}_{s}}(u^{\prime})),f^{\prime}(u^{\prime\prime})}(\mathcal{Z}_{s},u ^{\prime})\] (38)

Since \(f^{\prime}(u^{*})=f(x_{s+1})\) and \(\uparrow_{\mathcal{Z}_{s+1}}(u^{*})=u^{\prime\prime}\) we have:

\[\tau_{f^{\prime}(\uparrow_{\mathcal{Z}_{s+1}}(u^{*})),f^{\prime}(u^{*})}( \mathcal{Z}_{s+1},u^{*})=\tau_{f^{\prime}(u^{\prime\prime}),f(x_{s+1})}( \mathcal{Z}_{s+1},u^{*})\] (39)

Now let:

\[\zeta^{*}:=\tau_{f(n(x_{s+1})),f(x_{s+1})}(\mathcal{Z}_{s+1},u^{*})\ \ ;\ \ \zeta^{ \prime}:=\tau_{f^{\prime}(\uparrow_{\mathcal{Z}_{s}}(u^{\prime})),f(n(x_{s+1}))}( \mathcal{Z}_{s},u^{\prime})\]

Define:

\[g(f^{\prime}):=\prod_{u\in\mathcal{Z}_{s}\setminus\{r(\mathcal{Z}_{s})\}}\tau_{ f^{\prime}(\uparrow_{\mathcal{Z}_{s}}(u)),f^{\prime}(u)}(\mathcal{Z}_{s},u)\]

and:

\[g^{\prime}(f^{\prime}):=\prod_{u\in\mathcal{Z}_{s+1}\setminus\{r(\mathcal{Z}_{s+ 1})\}}\tau_{f^{\prime}(\uparrow_{\mathcal{Z}_{s+1}}(u)),f^{\prime}(u)}(\mathcal{ Z}_{s+1},u)\]

Combining equations (37), (38) and (39) gives us:

\[\prod_{u\in\{u^{*},u^{\prime},u^{\prime\prime}\}}\tau_{f^{\prime}(\uparrow_{ \mathcal{Z}_{s+1}}(u)),f^{\prime}(u)}(\mathcal{Z}_{s+1},u)=[\![f^{\prime}(u^{ \prime\prime})=f(n(x_{s+1}))]\!]\zeta^{*}\zeta^{\prime}\] (40)

For all \(u\in\mathcal{Z}_{s+1}\setminus\{u^{*},u^{\prime},u^{\prime\prime}\}\) we have \(\uparrow_{\mathcal{Z}_{s+1}}(u)=\uparrow_{\mathcal{Z}_{s}}(u)\) so that:

\[\tau_{f^{\prime}(\uparrow_{\mathcal{Z}_{s+1}}(u)),f^{\prime}(u)}(\mathcal{Z}_{s+1 },u)=\tau_{f^{\prime}(\uparrow_{\mathcal{Z}_{s}}(u)),f^{\prime}(u)}(\mathcal{Z}_{s},u)\]and hence, since \(f(n(x_{s+1}))=f^{\prime}(u^{\prime})\), we have:

\[g^{\prime}(f^{\prime})=\frac{g(f^{\prime})}{\zeta^{\prime}}\prod_{u\in\{u^{*},u^ {\prime},u^{\prime\prime}\}}\tau_{f^{\prime}(\uparrow_{\mathcal{Z}_{s+1}(u)),f^ {\prime}(u)}}(\mathcal{Z}_{s+1},u)\]

Substituting in Equation (40) gives us:

\[g^{\prime}(f^{\prime})=g(f^{\prime})[\![f^{\prime}(u^{\prime\prime})=f(n(x_{s+ 1}))]\![\zeta^{*}\] (41)

We have \(\tilde{\kappa}_{f^{\prime}(u^{\prime\prime})}(\mathcal{Z}_{s+1},\hat{\lambda} _{s+1},u^{\prime\prime})=1\) and for all \(u\in\mathcal{Z}_{s}\) we have \(\tilde{\kappa}_{f^{\prime}(u)}(\mathcal{Z}_{s+1},\hat{\lambda}_{s+1},u)= \tilde{\kappa}_{f^{\prime}(u)}(\mathcal{Z}_{s},\hat{\lambda}_{s},u)\). Substituting into Equation (41) gives us:

\[g^{\prime}(f^{\prime})\prod_{u\in\mathcal{Z}_{s+1}}\tilde{\kappa }_{f^{\prime}(u)}(\mathcal{Z}_{s+1},\hat{\lambda}_{s+1},u)\] \[=[\![f^{\prime}(u^{\prime\prime})=f(n(x_{s+1}))]\![\tilde{\kappa }_{f^{\prime}(u^{*})}(\mathcal{Z}_{s+1},\hat{\lambda}_{s+1},u^{*})\zeta^{*}g(f ^{\prime})\prod_{u\in\mathcal{Z}_{s}}\tilde{\kappa}_{f^{\prime}(u)}(\mathcal{Z }_{s},\hat{\lambda}_{s},u)\]

Summing over all \(f^{\prime}\in\mathcal{N}(f)\) and noting that \(f^{\prime}(u^{*})=f(x_{s+1})\) and that:

\[\tilde{\kappa}_{f^{\prime}(r(\mathcal{Z}_{s+1}))}(\mathcal{Z}_{s+1},\hat{ \lambda}_{s+1},r(\mathcal{Z}_{s+1}))=1=\tilde{\kappa}_{f^{\prime}(r(\mathcal{Z }_{s}))}(\mathcal{Z}_{s},\hat{\lambda}_{s},r(\mathcal{Z}_{s}))\]

gives us:

\[\hat{\nu}(f)=\tilde{\kappa}_{f(x_{s+1})}(\mathcal{Z}_{s+1},\hat{\lambda}_{s+1 },u^{*})\zeta^{*}\hat{\nu}(f^{*})\]

By the inductive hypothesis we then have:

\[\hat{\nu}(f)=\tilde{\kappa}_{f(x_{s+1})}(\mathcal{Z}_{s+1},\hat{\lambda}_{s+1 },u^{*})\zeta^{*}\hat{w}(f^{*})\]

which, by Equation (36), is equal to \(\hat{w}(f)\). We have hence shown that if the inductive hypothesis holds for \(t=s\) then it holds for \(t=s+1\) also. An identical argument shows that the inductive hypothesis holds for \(t=2\). We have hence shown that the inductive hypothesis holds for all \(t\in[T]\setminus\{1\}\). 

We now define a bijection \(\mathcal{G}:\{0,1\}^{\mathcal{X}}\to 2^{\mathcal{X}}\) by:

\[\mathcal{G}(f):=\{x\in\mathcal{X}\mid f(x)=1\}\ \ \forall f\in\{0,1\}^{ \mathcal{X}}\]

Note that for all \(f:\mathcal{X}\to\{0,1\}\) and all \(x\in\mathcal{X}\setminus\{x_{1}\}\) we have:

\[\sigma(x,\mathcal{G}(f))\epsilon+(1-\sigma(x,\mathcal{G}(f)))(1-\epsilon)=[\![ f(x)\neq f(n(x))]\![\epsilon+[\![f(x)=f(n(x))]\![(1-\epsilon)\]

and:

\[\prod_{x\in\mathcal{G}(f)}\lambda^{\prime}(x)=\prod_{t^{\prime}\in[T]:f(x_{t^ {\prime}})=1}\lambda^{\prime}(x_{t})\]

so that:

\[\tilde{w}(\mathcal{J},\lambda,\mathcal{G}(f))=\hat{w}(f)\]

and hence, by Lemma E.2, we have:

\[\tilde{w}(\mathcal{J},\lambda,\mathcal{G}(f))=\hat{\nu}(f)\]

so that:

\[\sum_{\mathcal{S}\in 2^{\mathcal{X}}}[\![\gamma(\hat{u})\in\mathcal{S}]\!]\tilde{w}( \lambda,\epsilon,\mathcal{S})=\sum_{f\in\{0,1\}^{\mathcal{X}}}[\![f(\gamma( \hat{u}))=1]\!]\hat{\nu}(f)\] (42)

Since:

\[\bigcup\{\mathcal{N}(f)\mid f\in\{0,1\}^{\mathcal{X}},f(\gamma(\hat{u}))=1 \}=\{f^{\prime}\in\{0,1\}^{\mathcal{Z}_{T}}\mid f^{\prime}(\hat{u})=1\}\]

and all sets in this union are disjoint, the right hand side of Equation (42) is equal to:

\[\sum_{f^{\prime}\in\{0,1\}^{\mathcal{Z}_{T}}}[\![f^{\prime}(\hat{u})=1]\!]\prod _{u\in\mathcal{Z}_{T}\setminus\{r(\mathcal{Z}_{T})\}}\tau_{f^{\prime}(\uparrow_{ \mathcal{Z}_{T}}(u)),f^{\prime}(u)}(\mathcal{Z}_{T},u)\tilde{\kappa}_{f^{ \prime}(u)}(\mathcal{Z}_{T},\hat{\lambda}_{T},u)\] (43)

Given a vertex \(u\in\mathcal{Z}_{T}\setminus\{r(\mathcal{Z}_{T})\}\) define:

\[\mathcal{H}(u):=\Downarrow_{\mathcal{Z}_{T}}(u)\cup\{\uparrow_{\mathcal{Z}_{T }}(u)\}\]

and for all \(f:\mathcal{H}(u)\to\{0,1\}\) define:

\[\hat{\zeta}(u,f):=\prod_{u^{\prime}\in\Downarrow_{\mathcal{Z}_{T}}(u)}\tau_{f( \uparrow_{\mathcal{Z}_{T}}(u^{\prime})),f(u^{\prime})}(\mathcal{Z}_{T},u^{ \prime})\]

**Lemma E.3**.: _Given a vertex \(u^{\prime}\in\mathcal{Z}_{T}\setminus\{r(\mathcal{Z}_{T})\}\) and an index \(i\in\{0,1\}\) we have:_

\[\sum_{f\in\{0,1\}^{\mathcal{H}(u^{\prime})}}[\![f(\uparrow_{\mathcal{Z}_{T}}(u^ {\prime}))=i]\!]\hat{\zeta}(u^{\prime},f)=1\]

Proof.: We prove by induction on the height of \(\Downarrow_{\mathcal{Z}_{T}}(u^{\prime})\). If this height is equal to zero then \(\mathcal{H}(u^{\prime})=\{u^{\prime},\uparrow_{\mathcal{Z}_{T}}(u^{\prime})\}\) and for all \(f:\mathcal{H}(u)\to\{0,1\}\) we have:

\[\hat{\zeta}(u^{\prime},f)=\tau_{f(\uparrow_{\mathcal{Z}_{T}}(u^{\prime})),f(u ^{\prime})}(\mathcal{Z}_{T},u^{\prime})\]

Since:

\[\tau_{i,0}(\mathcal{Z}_{T},u^{\prime})+\tau_{i,1}(\mathcal{Z}_{T},u^{\prime})=1\] (44)

we immediately have the result for the case that the height of \(\Downarrow_{\mathcal{Z}_{T}}(u^{\prime})\) is zero. Now suppose that the result holds whenever the height of \(\Downarrow_{\mathcal{Z}_{T}}(u^{\prime})\) is equal to \(j\) (for some \(j\in\mathbb{N}\)). We will now show that it holds whenever the height of \(\Downarrow_{\mathcal{Z}_{T}}(u^{\prime})\) is equal to \(j+1\) which will prove that the result holds always. By the inductive hypothesis we have, for all \(i^{\prime}\in\{0,1\}\), that:

\[\sum_{f\in\{0,1\}^{\mathcal{H}(\cdot(u^{\prime}))}}[\![f(u^{\prime})=i^{\prime }]\!]\hat{\zeta}(\spherical(u^{\prime}),f)=1\]

and

\[\sum_{f\in\{0,1\}^{\mathcal{H}(\cdot(u^{\prime}))}}[\![f(u^{\prime})=i^{\prime }]\!]\hat{\zeta}(\triangleright(u^{\prime}),f)=1\]

so:

\[\sum_{f\in\{0,1\}^{\mathcal{H}(u^{\prime})}}[\![f(\uparrow_{\mathcal{Z}_{T}}( u^{\prime}))=i]\!][\![f(u^{\prime})=i^{\prime}]\!]\hat{\zeta}(\spherical(u^{ \prime}),f)\hat{\zeta}(\triangleright(u^{\prime}),f)=1\]

and hence:

\[\sum_{f\in\{0,1\}^{\mathcal{H}(u^{\prime})}}[\![f(\uparrow_{\mathcal{Z}_{T}}( u^{\prime}))=i]\!][\![f(u^{\prime})=i^{\prime}]\!]\hat{\zeta}(u^{\prime},f)= \tau_{i,i^{\prime}}(\mathcal{Z}_{T},u)\]

Summing over \(i^{\prime}\in\{0,1\}\) and noting Equation (44) then shows us the result holds for this case and hence, by induction, holds always. 

Given \(u^{\prime},u^{\prime\prime}\in\mathcal{Z}_{T}\) with \(u^{\prime\prime}\in\Downarrow_{\mathcal{Z}_{T}}(u^{\prime})\) we define \(\hat{\mathcal{H}}(u^{\prime},u^{\prime\prime})\) to be the maximal subtree of \(\mathcal{Z}_{T}\) which has \(u^{\prime}\) and \(u^{\prime\prime}\) as leaves. Given, in addition, \(f:\hat{\mathcal{H}}(u^{\prime},u^{\prime\prime})\to\{0,1\}\) we define:

\[\tilde{\zeta}(u^{\prime},u^{\prime\prime},f):=\prod_{u\in\hat{\mathcal{H}}(u^ {\prime},u^{\prime\prime})\setminus\{u^{\prime}\}}\tau_{f(\uparrow_{\mathcal{Z }_{T}}(u)),f(u)}(\mathcal{Z}_{T},u)\]

and:

\[\delta(u^{\prime},u^{\prime\prime}):=d(u^{\prime\prime})-d(u^{\prime})\]

We now have the following lemma.

**Lemma E.4**.: _Given \(u^{\prime},u^{\prime\prime}\in\mathcal{Z}_{T}\) with \(u^{\prime\prime}\in\Downarrow_{\mathcal{Z}_{t}}(u^{\prime})\setminus\{u^{ \prime}\}\) and indices \(i^{\prime},i^{\prime\prime}\in\{0,1\}\) we have that:_

\[\sum_{f\in\{0,1\}^{\mathcal{H}(u^{\prime},u^{\prime\prime})}}[\![f(u^{\prime}) =i^{\prime}]\!][\![f(u^{\prime\prime})=i^{\prime\prime}]\!]\tilde{\zeta}(u^{ \prime},u^{\prime\prime},f)\]

_is equal to_

\[[\![i^{\prime}\neq i^{\prime\prime}]\!]\phi_{\delta(u^{\prime},u^{\prime \prime})}+[\![i^{\prime}=i^{\prime\prime}]\!](1-\phi_{\delta(u^{\prime},u^{ \prime\prime})})\]

Proof.: We prove by induction on the distance from \(u^{\prime}\) to \(u^{\prime\prime}\) in \(\mathcal{Z}_{T}\). If this distance is one then we have \(u^{\prime}=\uparrow_{\mathcal{Z}_{T}}(u^{\prime\prime})\) and \(\hat{\mathcal{H}}(u^{\prime},u^{\prime\prime})=\{u^{\prime},u^{\prime\prime}\}\) so we have:

\[\sum_{f\in\{0,1\}^{\mathcal{H}(u^{\prime},u^{\prime\prime})}}[\![f(u^{\prime})=i ^{\prime}]\!][\![f(u^{\prime\prime})=i^{\prime\prime}]\!]\tilde{\zeta}(u^{ \prime},u^{\prime\prime},f)=\tau_{i^{\prime},i^{\prime\prime}}(\mathcal{Z}_{T}, u^{\prime\prime})\]

which immediately implies that the inductive hypothesis holds in this case. Now suppose that the inductive hypothesis holds whenever the distance from \(u^{\prime}\) to \(u^{\prime\prime}\) is \(j\). We now consider the casethat the distance from \(u^{\prime}\) to \(u^{\prime\prime}\) is \(j+1\). Let \(u^{*}\) be the child of \(u^{\prime}\) that lies in \(\hat{\mathcal{H}}(u^{\prime},u^{\prime\prime})\). Without loss of generality assume that \(u^{\prime\prime}\) is a descendant of \(\vartriangle(u^{*})\). Now choose any \(i^{*}\in\{0,1\}\). Given \(f:\hat{\mathcal{H}}(u^{\prime},u^{\prime\prime})\to\{0,1\}\) let:

\[h(i^{*},f)=\llbracket f(u^{\prime})=i^{\prime}\rrbracket\llbracket f(u^{\prime \prime})=i^{\prime\prime}\rrbracket\llbracket f(u^{*})=i^{*}\rrbracket\]

and let \(f^{\prime}\) and \(f^{\prime\prime}\) be the restriction of \(f\) onto the sets \(\hat{\mathcal{H}}(u^{*},u^{\prime\prime})\) and \(\mathcal{H}(\vartriangle(u^{*}))\) respectively. Note that

\[\tilde{\zeta}(u^{\prime},u^{\prime\prime},f)=\tau_{f(u^{\prime}),f(u^{*})}( \mathcal{Z}_{T},u^{*})\tilde{\zeta}(u^{*},u^{\prime\prime},f^{\prime})\hat{ \zeta}(\vartriangle(u^{*}),f^{\prime\prime})\]

By Lemma E.3 and the inductive hypothesis we then have that the quantity:

\[\sum_{f\in\{0,1\}^{\mathcal{H}(u^{\prime},u^{\prime\prime})}}h(i^{*},f)\tilde {\zeta}(u^{\prime},u^{\prime\prime},f)\]

is equal to the quantity:

\[\tau_{i^{*},i^{*}}(\mathcal{Z}_{T},u^{*})(\llbracket i^{*}\neq i^{\prime\prime }\rrbracket\phi_{\delta(u^{*},u^{\prime\prime})}+\llbracket i^{*}=i^{\prime \prime}\rrbracket(1-\phi_{\delta(u^{*},u^{\prime\prime})}))\]

Summing over \(i^{*}\in\{0,1\}\) gives us the result. We have hence proved the result in general. 

Suppose we have some \(f:\mathcal{J}\to\{0,1\}\). Let:

\[\hat{\mathcal{F}}(f):=\{f^{\prime}\in\{0,1\}^{\mathcal{Z}_{T}}\mid\forall u \in\mathcal{J}\,,\,f^{\prime}(u)=f(u)\}\]

Given \(u\in\mathcal{J}\) we have that:

\[\llbracket f(\uparrow_{\mathcal{J}}(u))\neq f(u)\rrbracket\phi_{\delta( \uparrow_{\mathcal{J}}(u),u)}+\llbracket f(\uparrow_{\mathcal{J}}(u))=f(u) \rrbracket(1-\phi_{\delta(\uparrow_{\mathcal{J}}(u),u)})\]

is equal to \(\tau_{f(\uparrow_{\mathcal{J}}(u)),f(u)}(\mathcal{J},u)\) and hence Lemma E.4 implies that:

\[\sum_{f^{\prime}\in\hat{\mathcal{H}}(\uparrow_{\mathcal{J}}(u),u)}\llbracket f ^{\prime}(\uparrow_{\mathcal{J}}(u))=f(\uparrow_{\mathcal{J}}(u))\rrbracket \llbracket f^{\prime}(u)=f(u)\rrbracket\tilde{\zeta}(\uparrow_{\mathcal{J}}(u),u,f^{\prime})=\tau_{f(\uparrow_{\mathcal{J}}(u)),f(u)}(\mathcal{J},u)\]

so since, by the definition of a contraction, the edge sets of the subtrees in \(\{\hat{\mathcal{H}}(\uparrow_{\mathcal{J}}(u),u)\mid u\in\mathcal{J}\setminus\{ r(\mathcal{J})\}\}\) partition the edge set of \(\mathcal{Z}_{T}\) we have, by definition of \(\tilde{\zeta}\), that:

\[\sum_{f^{\prime}\in\hat{\mathcal{F}}(f)}\prod_{u\in\mathcal{Z}_{T}\setminus\{ r(\mathcal{Z}_{T})\}}\tau_{f^{\prime}(\uparrow_{\mathcal{Z}_{T}}(u)),f^{ \prime}(u)}(\mathcal{Z}_{T},u)=\prod_{u\in\mathcal{J}\setminus\{r(\mathcal{J })\}}\tau_{f(\uparrow_{\mathcal{J}}(u)),f(u)}(\mathcal{J},u)\]

Since for all \(f^{\prime}\in\hat{\mathcal{F}}(f)\) and for all \(u\in\mathcal{Z}_{T}\setminus\mathcal{J}\) we have \(\tilde{\kappa}_{f^{\prime}(u)}(\mathcal{Z}_{T},\hat{\lambda}_{T},u)=1\) we have now shown that the quantity:

\[\sum_{f^{\prime}\in\hat{\mathcal{F}}(f)}\prod_{u\in\mathcal{Z}_{T}\setminus\{ r(\mathcal{Z}_{T})\}}\tau_{f^{\prime}(\uparrow_{\mathcal{Z}_{T}}(u)),f^{ \prime}(u)}(\mathcal{Z}_{T},u)\tilde{\kappa}_{f^{\prime}(u)}(\mathcal{Z}_{T}, \hat{\lambda}_{T},u)\]

is equal to the quantity:

\[\prod_{u\in\mathcal{J}\setminus\{r(\mathcal{J})\}}\tau_{f(\uparrow_{\mathcal{J }}(u)),f(u)}(\mathcal{J},u)\tilde{\kappa}_{f(u)}(\mathcal{Z}_{T},\hat{\lambda} _{T},u)\]

Summing over all \(f\in\mathcal{F}(\mathcal{J},\hat{u})\) and noting Equations (42) and (43) gives us the result.

### Theorem d.1

**Lemma E.5**.: _Given \(u,u^{\prime}\in\mathcal{Z}_{t}\) the algorithm for computing \(\nu(u,u^{\prime})\) is correct._

Proof.: If \(u=u^{\prime}\) then the proof is trivial. Otherwise we consider the following cases:

* Consider first the case that \(\hat{s}\neq\triangledown(s^{*})\). Without loss of generality assume \(\hat{s}=\vartriangle(s^{*})\). Then we have \(u\in\Downarrow(\vartriangle(\xi(s^{*})))\) and since \(\hat{s}^{\prime}\neq\vartriangle(s^{*})\) we have \(u^{\prime}\notin\Downarrow(\vartriangle(\xi(s^{*})))\). Hence \(u^{\prime}\notin\Downarrow(u)\) so \(\nu(u,u^{\prime})=\blacktriangle\) as required.

* If \(u=\xi(s^{*})\) then \(\hat{s}=\triangledown(s^{*})\) so either \(\hat{s}^{\prime}=\triangleleft(s^{*})\) or \(\hat{s}^{\prime}=\triangleright(s^{*})\). In the former case we have \(u^{\prime}\in\left\|\!\left(\triangleleft\!\left\{\xi(s^{*})\right\}\right)\right) =\(\left\|\!\left(\triangleleft\!\left\{\alpha(u)\right\}\right)\right)\right.\) so that \(\nu(u,u^{\prime})=\blacktriangleleft\) and similarly in the later case we have \(\nu(u,u^{\prime})=\blacktriangleright\) as required.
* If \(\hat{s}=\triangledown(s^{*})\) and \(u\neq\xi(s^{*})\) then we invoke the process. Consider the vertex \(s\) at any stage in the process. By induction we have that if \(s\in\mathcal{E}^{\blacktriangle}\) then \(u^{\prime}\in\Downarrow(\mu^{\prime}(s))\). This is because if \(s\in\mathcal{E}^{\blacktriangle}\) then \(\mu^{\prime}(s)\) is an ancestor of \(\mu^{\prime}(\uparrow_{\mathcal{E}}(s))\). This further implies that when \(s\neq\hat{s}\) we have \(u^{\prime}\in\Downarrow(\mu^{\prime}(\uparrow_{\mathcal{E}}(s)))\). Now suppose that \(s\in\mathcal{E}^{\circ}\) and without loss of generality assume \(s=\triangleleft(\uparrow_{\mathcal{E}}(s))\). Then \(u\in\left\|\!\left(\triangleleft\!\left\{\xi(\uparrow_{\mathcal{E}}(s)) \right\}\right)\right)\) and \(\mu^{\prime}(\uparrow_{\mathcal{E}}(s))\in\Downarrow(\triangleright(\xi( \uparrow_{\mathcal{E}}(s))))\) so that, since \(u^{\prime}\in\Downarrow(\mu^{\prime}(\uparrow_{\mathcal{E}}(s)))\), we have \(u^{\prime}\notin\Downarrow(u)\) and hence \(\nu(u,u^{\prime})=\blacktriangle\) as required. Suppose now that \(s\in\mathcal{E}^{\blacktriangle}\) and that \(u=\xi(s)\). If \(\triangleleft\!\left\{\alpha(s)\in\mathcal{E}^{\blacktriangle}\right\}\) then we have \(\mu^{\prime}(s)\in\Downarrow(\triangleleft\!\left\{\xi(s)\right\})=\Downarrow( \triangleleft\!\left\{u\right\})\right.\) so that, by above, \(u^{\prime}\in\Downarrow(\triangleleft\!\left\{\alpha(u)\right\})\) and hence \(\nu(u,u^{\prime})=\blacktriangle\) as required. Similarly, if \(\triangleright(s)\in\mathcal{E}^{\blacktriangle}\) then \(\nu(u,u^{\prime})=\blacktriangleright\) as required. This completes the proof.

**Lemma E.6**.: _The algorithm correctly finds \(\hat{u}\)._

Proof.: By induction on the depth of \(s\) we have, for all vertices \(s\) in the constructed path, that:

* If \(s\in\mathcal{D}^{\circ}\) then \(u_{t}\) lies in the maximal subtree of \(\mathcal{Z}_{t}\) containing \(\mu(s)\) and having \(\uparrow_{\mathcal{J}}(\mu(s))\) as a leaf.
* If \(s\in\mathcal{D}^{\blacktriangle}\) then \(u_{t}\) lies in the maximal subtree of \(\mathcal{Z}_{t}\) with \(\uparrow_{\mathcal{J}}(\mu(s))\) and \(\mu^{\prime}(s)\) as leaves.

Let \(s^{\prime}\) be the unique leaf of \(\mathcal{D}\) that is on the constructed path. If \(s^{\prime}\in\mathcal{D}^{\circ}\) then \(\mu(s^{\prime})\) is a leaf of \(\mathcal{J}\) and hence also a leaf of \(\mathcal{Z}_{t}\). So by above we have that \(u_{t}\) lies in the maximal subtree of \(\mathcal{Z}_{t}\) with \(\uparrow_{\mathcal{J}}(\mu(s^{\prime}))\) and \(\mu(s^{\prime})\) as leaves. If, on the other hand, \(s^{\prime}\in\mathcal{D}^{\blacktriangle}\) then since \(s^{\prime}\) is a leaf of \(\mathcal{D}\) we have that \(\mu(s^{\prime})=\mu^{\prime}(s^{\prime})\) and hence, by above, we have that \(u_{t}\) lies in the maximal subtree of \(\mathcal{Z}_{t}\) with \(\uparrow_{\mathcal{J}}(\mu(s^{\prime}))\) and \(\mu(s^{\prime})\) as leaves. In either case we have \(\hat{u}=\mu(s^{\prime})\) as required. 

**Lemma E.7**.: _The algorithm correctly finds \(u^{*}\)._

Proof.: By induction on the depth of \(s\) we have, for all vertices \(s\) in the constructed path, that:

* If \(s\in\mathcal{E}^{\circ}\) then \(\Gamma_{\mathcal{Z}_{t}}(u_{t},\hat{u})\) lies in \(\Downarrow_{\mathcal{Z}_{t}}(\mu(s))\).
* If \(s\in\mathcal{E}^{\blacktriangle}\) then \(\Gamma_{\mathcal{Z}_{t}}(u_{t},\hat{u})\) lies in the maximal subtree of \(\mathcal{Z}_{t}\) with \(\mu(s)\) and \(\mu^{\prime}(s)\) as leaves.

Let \(s^{\prime}\) be the unique leaf of \(\mathcal{E}\) that is on the constructed path. If \(s^{\prime}\in\mathcal{E}^{\circ}\) then \(\mu(s^{\prime})\) is a leaf of \(\mathcal{Z}_{t}\) and hence, by above, \(\Gamma_{\mathcal{Z}_{t}}(u_{t},\hat{u})=\mu(s^{\prime})\) as required. If \(s\in\mathcal{E}^{\blacktriangle}\) then \(\mu(s)=\mu^{\prime}(s)\) and hence, by above, \(\Gamma_{\mathcal{Z}_{t}}(u_{t},\hat{u})=\mu(s^{\prime})\) as required.