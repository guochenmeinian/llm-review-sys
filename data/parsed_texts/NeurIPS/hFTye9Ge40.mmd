# Fixed Confidence Best Arm Identification in the Bayesian Setting

 Kyoungseok Jang

Universita degli Studi di Milano

ksajks@gmail.com

&Junpei Komiyama

New York University / RIKEN AIP

junpei@komiyama.info

&Kazutoshi Yamazaki

The University of Queensland

k.yamazaki@uq.edu.au

###### Abstract

We consider the fixed-confidence best arm identification (FC-BAI) problem in the Bayesian setting. This problem aims to find the arm of the largest mean with a fixed confidence level when the bandit model has been sampled from the known prior. Most studies on the FC-BAI problem have been conducted in the frequentist setting, where the bandit model is predetermined before the game starts. We show that the traditional FC-BAI algorithms studied in the frequentist setting, such as track-and-stop and top-two algorithms, result in arbitrarily suboptimal performances in the Bayesian setting. We also obtain a lower bound of the expected number of samples in the Bayesian setting and introduce a variant of successive elimination that has a matching performance with the lower bound up to a logarithmic factor. Simulations verify the theoretical results.

## 1 Introduction

In many sequential decision-making problems, the learner repeatedly chooses an arm (option) to play with and observes a reward drawn from the unknown distribution of the corresponding arm. One of the most widely-studied instances of such problems is the multi-armed bandit problem [19, 18, 17], where the goal is to maximize the sum of rewards during the rounds. Since the learner does not know the distribution of rewards, they need to explore the different arms, and yet, exploit the arms of the most rewarding arms so far. Different from the classical bandit formulation, there are situations where one is more interested in collecting information rather than maximizing intermediate rewards. The best arm identification (BAI) is a sequential decision-making problem in which the learner is only interested in identifying the arm with the highest mean reward. While the origin of this problem dates back to at least the 1950s [1, 17, 18], recent work in the field of machine learning reformulated the problem [1]. In the BAI, the learner needs to pull arms efficiently for better identification. To achieve efficiency and accuracy, the learner should determine which arm to choose based on the history, when to stop the sampling, and which arm to recommend as the learner's final decision.

There are two types of BAI problems depending on the optimization objective. In the fixed-budget (FB) setting [1], the learner attempts to minimize the probability of error (misidentification of the best arm) given a limited number of arm pulls \(T\). In the fixed confidence (FC) setting [1], the learner attempts to minimize the number of arm pulls, subject to a predefined probability of error \(\delta\in(0,1)\). In this paper, we shall focus on the FC setting, which is useful when we desire a rigorous statistical guarantee.

Most of the previous BAI studies focus on the frequentist setting, where the bandit model is chosen adversarially from some hypothesis class beforehand. In this setting, several algorithms, such as Track and Stop (Kaufmann et al., 2016a) and Top-two algorithms (Russo, 2016; Qin et al., 2017b; Jourdan et al., 2022), are widely known. These algorithms have an optimal sample complexity, meaning that they are one of the most sample-efficient algorithms among the class of \(\delta\)-correct algorithms.

The sample complexity of these algorithms is problem-dependent. To see this, consider the following example.

**Example 1**.: (A/B/C testing) Consider A/B/C testing of web designs. We have three arms (web designs) from which we would like to find the largest retention rate via allocating users to web designs \(i=1,2,3\). If we attempt to find the best arm with confidence \(\delta\), we may need a large number of samples (users) when the suboptimality gap (the gap between the retention rate of the best arm and the second best arm) is small because in such a case the identification of the best arm is difficult - the minimum number of samples required is inversely proportional to the square of the suboptimality gap(Kaufmann et al., 2014). For example, when comparing the testing of retention rates of (0.9, 0.5, 0.1) with (0.9, 0.89, 0.1), the second case requires around \(\left(\frac{0.9-0.5}{0.9-0.89}\right)^{2}=1600\) times more samples compared to the first case.

In practice, the retention rate of \(0.89\) in the second case may be acceptably good compared to the optimal retention rate of \(0.9\), and we may stop exploration at the moment the learner identifies a reasonably good arm, which is the first or the second arm in this example. This idea is formalized in several ways. The literature of Ranking and Selection (R&S) usually considers the indifference-zone formulation (Hong et al., 2021). In the context of best arm identification, a similar notion of \(\epsilon\)-best answer identification has also been considered (Maron and Moore, 1993; Even-Dar et al., 2006; Gabillon et al., 2012; Kaufmann and Kalyanakrishnan, 2013; Jourdan et al., 2023). In these settings, the learner accepts a sub-optimal arm whose means are at most \(\epsilon\) worse than the mean of the optimal arm. Other related settings include the good arm identification problem (Kano et al., 2019; Tabata et al., 2020; Zhao et al., 2023), where the goal is to identify an arm that exceeds the predefined threshold, and the thresholding bandit problem (Locatelli et al., 2016; Xu et al., 2019), where the goal is to identify whether the mean of each arm is above or below the threshold. All these problem settings require an extra parameter, like \(\epsilon\) or an acceptance threshold, that directly determines the acceptance level. Even though the algorithm's performance depends on this parameter, it is often challenging to determine a reasonable value for it in advance.

In this paper, we study an alternative approach based on the Bayesian setting. In particular, we consider the prior distribution on the model parameters. We relax the requirement on the correctness of the best arm identification by using the prior belief. Rather than requiring the frequentist \(\delta\)-correctness for any model, we require the learner to have marginalized correctness over the prior distribution, which we call Bayesian \(\delta\)-correctness.

We study the fixed confidence BAI (FC-BAI) problem in the Bayesian setting. Our contributions are as follows.

* **First,** we find that in the Bayesian setting, the performance of the traditional frequentist setting-based algorithms, such as Track and Stop and Top-two algorithms, can be arbitrarily worse (Section 3). This is because frequentist approaches spend too many resources when the suboptimality gap is narrow.
* **Second,** we prove that the lower bound of the number of expected samples should attain at least the order of \(\Omega(\frac{L(\bm{H})^{2}}{\delta})\) as \(\delta\to 0\) (Section 4). Here \(L(\bm{H})\) is our novel quantity that represents the sample complexity with respect to the prior distribution \(\bm{H}\). This order is different from the existing lower bound in the frequentist setting1, implying that the Bayesian setting is essentially different from the frequentist setting. Footnote 1: In fact, marginalizing the frequentist sample complexity over the prior distribution leads to an unbounded value.
* **Third,** we design an algorithm whose expected sample size is upper-bounded by \(O(\frac{L(\bm{H})^{2}}{\delta}\log\frac{L(\bm{H})}{\delta})\) (Section 5). Our algorithm is based on the elimination algorithm (Maron and Moore, 1993; Even-Dar et al., 2006; Frazier, 2014), but we add an early stopping criterion to prevent over-commitment of the algorithm for a bandit model with a narrow suboptimality gap. Our algorithm has a matching upper bound up to the logarithmic factor.

We also conduct simulation to demonstrate that the sample complexity of frequentist algorithms does indeed diverge in a bandit model with a small suboptimality gap, even in very simple cases (Section 6).

### Related work

To our knowledge, BAI problems studied for the Bayesian setting have been limited to the fixed budget setting (Komiyama et al., 2023; Asidakou et al., 2023). Komiyama et al. (2023) showed that, in the fixed-budget setting, a simple non-Bayesian algorithm has an optimal simple regret up to a constant factor, implying that the advantage the learner could get from the prior is small when the budget is large. This is very different from our fixed-confidence setting, where utilizing the prior distribution is necessary.

Several FC-BAI algorithms used Bayesian ideas on the structure of the algorithm, although most of those studies used frequentist settings for measuring the guarantee. The 'Top-Two' type of algorithms are the leading representatives in this direction. The first instance of top-two algorithms, which is called Top-Two Thompson sampling (TTTS), is introduced in the context of Bayesian best arm identification. TTTS requires a prior distribution, and Russo (2016) showed that the sample complexity of posterior convergence of TTTS which is the same as the sample complexity of the frequentist fixed-confidence best arm identification. Subsequent research analyzed the performance of TTTS from the frequentists' viewpoint (Shang et al., 2020). Later on, the idea of top-two sampling is then extended into many other algorithms, such as Top-Two Transportation Cost (Shang et al., 2020), Top-Two Expected Improvement (TTEI, Qin et al., 2017), Top-Two Upper Confidence bound (TTUCB, Jourdan and Degenne 2022). Even though some of the top two algorithms adapt a prior, they implicitly solve the optimization that is justified in view of frequentist.

Another line of Bayesian sequential decision-making is Bayesian optimization (Srinivas et al., 2010; Mockus, 2012; Shahriari et al., 2016; Jamieson and Talwalkar, 2016; Frazier, 2018), where the goal is to find the best arm in Bayesian setting. Note that Bayesian optimization tends to deal with structured identification, especially for Gaussian processes, and most of the algorithms for Bayesian optimization do not have specific stopping criteria.

## 2 Problem setup

We study the fixed confidence best arm identification problem (FC-BAI) in a Bayesian setting. In this setup, we have \(k\) arms in the set \([k]:=\{1,2,\ldots,k\}\) with _unknown_ distribution \(\bm{P}=(P_{1},\cdots,P_{k})\) which is drawn from a _known_ prior distribution at time 0, namely \(\bm{H}=(H_{1},\cdots,H_{k})\). The unknown bandit model \(P_{i}\) is a one-parameter distribution, and \(\bm{P}\) is specified by \(\bm{\mu}:=(\mu_{1},\cdots,\mu_{k})\). To simplify the problem, we will focus on the Gaussian case, where each \(P_{i}\) is a Gaussian distribution with known variance \(\sigma_{i}^{2}\). Each mean of \(P_{i}\), denoted \(\mu_{i}\), is drawn from a known prior Gaussian distribution \(H_{i}\), which can be written as \(N(m_{i},\xi_{i}^{2})\).

At every time step \(t=1,2,\cdots\), the forecaster chooses an arm \(A_{t}\in[k]\) and observes a reward \(X_{t}\), which is drawn independently from \(P_{A_{t}}\). Since we focus on the Gaussian case, \(X_{t}\sim N(\mu_{A_{t}},\sigma_{A_{t}}^{2})\) conditionally given \(A_{t}\) and \(\mu_{A_{t}}\). After each sampling, the forecaster must decide whether to continue the sampling process or stop sampling and make a recommendation \(J\in[k]\).

Let \(\mathcal{F}_{t}=\sigma(A_{1},X_{1},A_{2},X_{2},\cdots,A_{t},X_{t})\) be the \(\sigma\)-field generated by observations up to time \(t\). The algorithm of the forecaster \(\pi:=((A_{t})_{t},\tau,J)\) is defined by the following triplet (Kaufmann et al., 2016):

* A sampling rule \((A_{t})_{t}\), which determines the arm to draw at round \(t\) based on the previous history (each \(A_{t}\) must be \(\mathcal{F}_{t-1}\) measurable).
* A stopping rule \(\tau\), which means when to stop the sampling (i.e., stopping time with respect to \(\mathcal{F}_{t}\)).
* A decision rule \(J\), which determines the arm the forecaster recommends based on his sampling history (i.e., \(J\) is \(\mathcal{F}_{\tau}\)-measurable).

In FC-BAI, the forecaster aims to recommend arm \(J\) that correctly identifies (one of) the best arm(s) \(i^{*}(\bm{\mu}):=\arg\max_{i\in[k]}\mu_{i}\) with probability at least \(1-\delta\). Since the case of multiple best arms is of measure zero under \(\bm{H}\), we can focus on \(\bm{\mu}\) such that \(i^{*}(\bm{\mu})\) is unique. For the FC-BAI problem in the Bayesian setting, we use the _expected_ probability of misidentification:

\[\mathrm{PoE}(\pi;\bm{H}):=\mathbb{E}_{\bm{\mu}\sim\bm{H}}\bigg{[} \mathbb{P}\Big{(}J\neq i^{*}(\bm{\mu})|\mathcal{H}_{\bm{\mu}}\Big{)}\bigg{]},\] (1)

where \(\mathcal{H}_{\bm{\mu}}:=\{\bm{\mu}\) is the correct bandit model\(\}\). Now we formally define the algorithm of interest as follows:

**Definition 1**.: (Bayesian \(\delta\)-correctness) For a prior distribution \(\bm{H}\), an algorithm \(\pi=((A_{t}),\tau,J)\) is said to be Bayesian \((\bm{H},\delta)\)-correct if it satisfies \(\mathrm{PoE}(\pi;\bm{H})\leq\delta\). Let \(\mathcal{A}^{b}(\delta,\bm{H})\) be the set of Bayesian \((\bm{H},\delta)\)-correct algorithms for the prior distribution \(\bm{H}\).

The objective of the FC-BAI problem in the Bayesian setting is to find an algorithm \(\pi=((A_{t})_{t},\tau,J)\in\mathcal{A}^{b}(\delta,\bm{H})\) that minimizes \(\mathbb{E}_{\bm{\mu}\sim\bm{H}}[\tau]\).

TerminologyDefine \(N_{i}(t)=\sum_{s=1}^{t-1}\bm{1}[A_{s}=i]\) as the number of times arm \(i\) is pulled before timestep \(t\). Let \(h_{i}\) be the probability density function of \(H_{i}\). Since we consider Gaussian prior, \(h_{i}(\mu_{i}):=(1/\sqrt{2\pi}\xi_{i})\exp(-(\mu_{i}-m_{i})^{2}/(2\xi_{i}^{2}))\). Let \(i^{*},j^{*}:\mathbb{R}^{k}\to[k]\) be the best and the second best arm under the input such that for each \(\bm{\mu}\in\{\mathbf{x}\in\mathbb{R}^{k}:x_{i}\neq x_{j}\forall i\neq j\}\), \(i^{*}(\bm{\mu})=\arg\max_{i\in[K]}\mu_{i}\) and \(j^{*}(\bm{\mu})=\arg\max_{i\in[K]\setminus\{i^{*}(\bm{\mu})\}}\mu_{i}\).

Let \(\mathrm{KL}_{i}(a\|b):=\frac{(a-b)^{2}}{2\sigma_{i}^{2}}\) represent the KL-divergence between two Gaussian distributions with equal variances (the variance of the \(i\)-th arm \(\sigma_{i}^{2}\)) but different means, denoted as \(a\) and \(b\). Similarly, \(d(a,b):=a\log(a/b)+(1-a)\log((1-a)/(1-b))\) is the KL divergence between two Bernoulli distributions with means \(a\) and \(b\). Throughout this paper, \(\mathbb{E}_{\bm{\mu}}\) and \(\mathbb{P}_{\bm{\mu}}\) denote the expectation and probability when the bandit model is fixed as \(\bm{\mu}\in\mathbb{R}^{k}\), i.e., \(\mathbb{E}_{\bm{\mu}}=\mathbb{E}[\cdot|\mathcal{H}_{\bm{\mu}}]\) and \(\mathbb{P}_{\bm{\mu}}=\mathbb{P}(\cdot|\mathcal{H}_{\bm{\mu}})\). We will abuse the notation \(\mathrm{PoE}\) so that for \(\bm{\lambda}\in\mathbb{R}^{k}\), \(\mathrm{PoE}(\pi;\bm{\lambda})\) means

\[\mathrm{PoE}(\pi;\bm{\lambda}):=\mathbb{P}_{\bm{\lambda}}\big{(}J\neq i^{*}( \bm{\lambda})|\mathcal{H}_{\bm{\lambda}}\big{)}.\]

Naturally, \(\mathrm{PoE}(\pi;\bm{H})=\mathbb{E}_{\bm{\mu}\sim\bm{H}}\big{[}\mathrm{PoE}( \pi;\bm{\mu})\big{]}\).

Lastly, we introduce the constant \(L(\bm{H})\) that characterizes the sample complexity in the Bayesian setting.

**Definition 2**.: For each \(i,j\in[k]\), define \(L_{ij}(\bm{H})\) and \(L(\bm{H})\) as follows:

\[L(\bm{H}):=\sum_{i,j\in[k],i\neq j}L_{ij}(\bm{H})\text{ where }L_{ij}(\bm{H}):= \int_{-\infty}^{\infty}h_{i}(x)h_{j}(x)\prod_{s:s\in[k]\setminus\{i,j\}}H_{s}( x)\,\mathrm{d}x.\]

This constant has the following interesting property which we call a volume lemma:

**Lemma 1** (Volume Lemma, informal).: For \(\Delta\in(0,1)\), let

\[L(\bm{H},\Delta):=\frac{1}{\Delta}\mathbb{P}_{\bm{\mu}\sim\bm{H}} \Big{[}\mu_{i^{*}(\bm{\mu})}-\mu_{j^{*}(\bm{\mu})}\leq\Delta\Big{]}.\]

Then, \(\lim_{\Delta\to 0^{+}}L(\bm{H},\Delta)=L(\bm{H})\). In particular, for \(\Delta<\frac{L(H)}{\sum_{i\in[k]}\frac{2(k-1)}{\xi_{i}}}\), \(L(H,\Delta)\in(\frac{1}{2}L(H),2L(H))\).

The volume lemma states that the volume of prior where the suboptimality gap is smaller than \(\Delta\) is proportional to \(L(\bm{H})\Delta\) when \(\Delta\) is small. We will see in Section 3 that such small-gap cases, which require a large amount of exploration to identify the best arm, dominate the Bayesian expectation of the stopping time. Therefore, \(L(\bm{H})\) defines the Bayesian sample complexity. The formal version of this lemma, which involves some regularity conditions, is shown in Appendix B.

**Remark 1**.: Here, we elaborate on how the Bayesian sample complexity is defined. As will be shown in Section 3, for an algorithm to have a finite expected stopping time, it must determine whether the current instance is difficult or not. In particular, if an algorithm tries to identify even the top-\(O(\delta)\) 'hardest instances'2 in the prior, the algorithm cannot achieve the finite expected stopping time. ByLemma 1, the suboptimality gap of the top-\(O(\delta)\) hardest instance is given by \(L(\mathcal{H})\Delta\approx\delta\), and the corresponding (frequentist) sample complexity is proportional to \(\Delta^{-2}=(L(\mathcal{H})/\delta)^{2}\)(Kaufmann et al., 2014). Such instances constitute an \(O(\delta)\) fraction of the prior, and thus the Bayesian sample complexity is:

\[O\left(\frac{(L(\mathcal{H}))^{2}}{\delta^{2}}\times\delta\right)=O\left( \frac{(L(\mathcal{H}))^{2}}{\delta}\right).\]

## 3 Limitation of traditional frequentist approaches in the Bayesian setting

Existing BAI studies mainly focused on the Frequentist \(\delta\)-correct algorithms which are defined as follows:

**Definition 3** (Frequentist \(\delta\)-correctness).: An algorithm \(\pi=((A_{t}),\tau,J)\) is said to be frequentist \(\delta\)-correct if, for any bandit instance \(\bm{\mu}\in\mathbb{R}^{k}\) such that \(i^{*}(\bm{\mu})\) is unique, it satisfies \(\mathrm{PoE}(\pi;\bm{\mu})\leq\delta\). Let \(\mathcal{A}^{f}(\delta)\) be the set of all frequentist-\(\delta\)-correct algorithms.

For the frequentist \(\delta\)-correct algorithms, Garivier and Kaufmann (2016) proved a lower bound for the expected stopping time as follows: for all bandit instance \(\bm{\mu}\)\(\in\mathbb{R}^{k}\) and for all \(((A_{t}),\tau,J)\in\mathcal{A}^{f}(\delta)\),

\[\mathbb{E}_{\bm{\mu}}\left[\tau\right]\geq\log(\delta^{-1})T^{*}(\bm{\mu})+o( \log(\delta^{-1}))\] (2)

where \(T^{*}(\bm{\mu})\) is a sample complexity function dependent on the bandit instance \(\bm{\mu}\).3 Moreover, many of the known frequentist \(\delta\)-correct algorithms achieve asymptotic optimality (Garivier and Kaufmann, 2016; Russo, 2016; Tabata et al., 2023; Qin et al., 2017), meaning that they are orderwisely tight up to the lower bound on Eq. (2) as \(\delta\to 0\). However, little is known, or at least discussed, about their performance in the Bayesian setting.

Footnote 3: For details about \(T^{*}(\bm{\mu})\), a reader may refer to Garivier and Kaufmann (2016).

One can check that a frequentist \(\delta\)-correct algorithm is also Bayesian \(\delta\)-correct as well (\(\mathcal{A}^{f}(\delta)\subset\mathcal{A}^{b}(\delta,\bm{H})\) for all \(\bm{H}\)). Naturally, our interest is whether or not the most efficient classes of frequentist \(\delta\)-correct algorithms, such as Tracking algorithms and Top-two algorithms, are efficient in Bayesian settings. Somewhat surprisingly, the following theorem states that any \(\delta\)-correct algorithm is suboptimal in Bayesian settings.

**Theorem 2**.: For all \(\delta>0,\bm{H}\) and \(((A_{t}),\tau,J)\in\mathcal{A}^{f}(\delta)\), \(\mathbb{E}_{\bm{\mu}\sim\bm{H}}\left[\tau\right]=+\infty\).

Proof of Theorem 2 is found in Appendix C. To illustrate the proof, we will use a two-armed Gaussian instance as an example.

### Special case - two armed Gaussian case

Here we present one intuitive corollary of the lower bound theorem (Kaufmann et al., 2016; Garivier and Kaufmann, 2016; Kaufmann et al., 2016) that uses a standard information-theoretic technique.

**Corollary 3**(Kaufmann et al. 2014).: Let \(\delta\in(0,1)\). For any frequentist \(\delta\)-correct algorithm \(((A_{t}),\tau,J)\) and for any fixed mean vector \(\bm{\mu}=(\mu_{1},\mu_{2})\in\mathbb{R}^{2}\), \(\mathbb{E}_{\bm{\mu}}[\tau]\geq\frac{d(\delta,1-\delta)}{(\mu_{1}-\mu_{2})^{ 2}}>\frac{\log\frac{1}{2\delta}}{(\mu_{1}-\mu_{2})^{2}}\).

In the frequentist setting, Corollary 3 implies the lower bound of \(\mathbb{E}_{\bm{\mu}}[\tau]=\Omega(\log(\delta^{-1})/(\mu_{1}-\mu_{2})^{2})\), which is \(\Omega(\log(\delta^{-1}))\) when we view parameters \((\mu_{1},\mu_{2})\) as constants. However, in the Bayesian setting, the algorithm is given the prior distribution \(\bm{H}\) on \(\bm{\mu}\), and thus the stopping time is marginalized over \(\bm{H}\). In particular, limiting our interest to the case of \(|\mu_{1}-\mu_{2}|<\Delta\) for small enough \(\Delta>0\), we can obtain the following lower bound:

\[\mathbb{E}_{\bm{\mu}\sim\bm{H}}[\tau] \geq\mathbb{E}_{\bm{\mu}\sim\bm{H}}[\tau\cdot\bm{1}[|\mu_{1}-\mu_ {2}|\leq\Delta]]\] (Since \[\tau\] is positive r.v.) \[\geq\mathbb{E}_{\bm{\mu}\sim\bm{H}}\left[\mathbb{E}[\tau|\bm{\mu} ]\cdot\bm{1}[|\mu_{1}-\mu_{2}|\leq\Delta]\right]\] (Law of total expectation) \[\geq\mathbb{E}_{\bm{\mu}\sim\bm{H}}\left[\frac{\log\delta^{-1}}{( \mu_{1}-\mu_{2})^{2}}\cdot\bm{1}[|\mu_{1}-\mu_{2}|\leq\Delta]\right]\] (Corollary 3) \[\geq\frac{\log\delta^{-1}}{\Delta^{2}}\mathbb{P}_{\bm{\mu}\sim\bm {H}}[|\mu_{1}-\mu_{2}|\leq\Delta]\geq\frac{\log\delta^{-1}}{\Delta^{2}}\frac{L( \bm{H})}{2}\Delta\] (Lemma 1)\[=\Omega\left(\frac{L(\bm{H})\log\delta^{-1}}{\Delta}\right).\]

This inequality implies that if we naively use a known frequentist \(\delta\)-correct algorithm in the Bayesian setting, the expected stopping time will diverge because we can choose an arbitrarily small \(\Delta\). The case of a small gap is _difficult to identify_, and the expected stopping time can be very large for such a case if we aim to identify the best arm for any model.

## 4 Lower bound

This section will elaborate on the lower bound of the stopping time in the Bayesian setting. Theorem 4 below states that any Bayesian \((\bm{H},\delta)\)-correct algorithm requires the expected stopping time of at least \(\Omega(\frac{L(\bm{H})^{2}}{\delta})\).

**Theorem 4**.: Define \(\sigma_{\min}=\min_{i\in[k]}\sigma_{i}^{2}\) and \(N_{V}=\frac{L(\bm{H})^{2}\sigma_{\min}^{2}\ln 2}{1664\delta}\). Let \(\delta<\delta_{L}(\bm{H})\) be sufficiently small.4 Then, for any BAI algorithms \(\pi=((A_{t}),\tau,J)\), if \(\mathbb{E}_{\bm{\mu}\sim\bm{H}}[\tau]\leq N_{V}\), then \(\mathrm{PoE}(\pi;\bm{H})\geq\delta\).

Footnote 4: In particular, \(\delta_{L}(\bm{H})\) is defined in Appendix G.

In this main body, we will use the two-armed Gaussian bandit model with homogeneous variance condition (i.e. \(\sigma_{1}=\sigma_{2}=\sigma\)) for easier demonstration of the proof sketch. Theorem 4, which is more general in the sense that it can deal with \(k>2\) arms with heterogeneous variances, is proven in Appendix D.

Sketch of the proof, for \(k=2\):It suffices to show that the following is an empty set:

\[\mathcal{A}^{b}(\delta,\bm{H},N_{V}):=\{\pi\in\mathcal{A}^{b}(\delta,\bm{H}): \mathbb{E}_{\bm{\mu}\sim\bm{H}}[\tau]\leq N_{V}\}.\]

Assume that \(\mathcal{A}^{b}(\delta,\bm{H},N_{V})\neq\emptyset\) and choose an arbitrary \(\pi\in\mathcal{A}^{b}(\delta,\bm{H},N_{V})\). We start from the following transportation lemma:

**Lemma 5** (Kaufmann et al. 2016a, Lemma 1).: Let \(\delta\in(0,1)\). For any algorithm \(((A_{t}),\tau,J)\), any \(\mathcal{F}_{\tau}\)-measurable event \(\mathcal{E}\), any bandit models \(\bm{\mu},\bm{\lambda}\in\{(x,y)\in\mathbb{R}^{2}:x\neq y\}\) such that \(i^{*}(\bm{\mu})\neq i^{*}(\bm{\lambda})\),

\[\mathbb{E}_{\bm{\mu}}\left[\sum_{i=1}^{2}\mathrm{KL}_{i}(\mu_{i},\lambda_{i}) N_{i}(\tau)\right]\geq d(\mathbb{P}_{\bm{\mu}}(\mathcal{E}),\mathbb{P}_{\bm{ \lambda}}(\mathcal{E})).\]

Note that the above Lemma holds for any algorithm, and thus works for any stopping time \(\tau\). Now define \(\bm{\nu}(\bm{\mu})\) as a swapped version of \(\bm{\mu}\in\mathbb{R}^{2}\), which means \((\bm{\nu}(\bm{\mu}))_{1}=\mu_{2},\bm{\nu}(\bm{\mu})_{2}=\mu_{1}\), and let \(\mathcal{E}=\{J\neq i^{*}(\bm{\mu})\}\), the event that the recommendation of the algorithm is wrong. Substituting \(\bm{\lambda}\) with \(\bm{\nu}(\bm{\mu})\) from the above equation of Lemma 5 leads to

\[\mathbb{E}_{\bm{\mu}}\Bigg{[}\frac{(\mu_{1}-\mu_{2})^{2}}{2\sigma^{2}}\tau \Bigg{]}\geq d(\mathrm{PoE}(\pi;\bm{\mu}),1-\mathrm{PoE}(\pi;\bm{\nu}))\geq \log\frac{2}{2.4(\mathrm{PoE}(\pi;\bm{\mu})+\mathrm{PoE}(\pi;\bm{\nu}))}.\] (3)

Note that the first inequality comes from the fact that \(\mathcal{E}\), the failure event of the bandit model \(\bm{\mu}\), is exactly a success event of \(\bm{\nu}(\bm{\mu})\) in this two-armed case, and the last inequality is from our modified lemma (Lemma 11) from Eq. (3) of Kaufmann et al. (2016a). One can rewrite the above inequality as

\[\frac{\mathrm{PoE}(\pi;\bm{\mu})+\mathrm{PoE}(\pi;\bm{\nu})}{2}\geq\frac{1}{2. 4}\exp\Biggl{(}\mathbb{E}_{\bm{\mu}}\biggl{[}-\frac{(\mu_{1}-\mu_{2})^{2}}{2 \sigma^{2}}\tau\biggr{]}\Biggr{)}.\] (4)

We can rewrite the conditions of \(\mathcal{A}^{b}(\delta,\bm{H},N_{V})\) as

\[\mathrm{PoE}(\pi;\bm{H})=\int_{\bm{\mu}\in\mathbb{R}^{2}}\mathrm{PoE}(\pi;\bm {\mu})\,\mathrm{d}\bm{H}(\bm{\mu})\leq\delta\qquad\text{and}\quad\int_{\bm{ \mu}\in\mathbb{R}^{2}}\mathbb{E}_{\bm{\mu}}[\tau]\,\mathrm{d}\bm{H}(\bm{\mu}) \leq N_{V}.\] (Opt0)

Using Eq. (4) and with some symmetry tricks, we get \(V_{0}\leq\mathrm{PoE}(\pi;\bm{H})\) where

\[V_{0}:=\int_{\bm{\mu}\in\mathbb{R}^{2}}\frac{1}{2.4}\exp\left(-\frac{(\mu_{1} -\mu_{2})^{2}}{2\sigma^{2}}\mathbb{E}_{\bm{\mu}}[\tau]\right)\mathrm{d}\bm{H}( \bm{\mu})\leq\delta\;\;\text{and}\;\int_{\bm{\mu}\in\mathbb{R}^{2}}\mathbb{E}_ {\bm{\mu}}[\tau]\,\mathrm{d}\bm{H}(\bm{\mu})\leq N_{V}.\] (Opt1)

[MISSING_PAGE_EMPTY:7]

\(\Delta_{0}:=\frac{\delta}{4L(\bm{H})}\) which satisfies the following condition, thanks to Lemma 1:

\[\mathbb{P}_{\bm{\mu}\sim\bm{H}}(\mu_{i^{*}(\bm{\mu})}-\mu_{j^{*}(\bm{\mu})}\leq \Delta_{0})\leq\frac{\delta}{2}.\]

In each iteration of the **while** loop of Algorithm 1, the learner selects and observes each arm in the active set. After drawing each arm once, the algorithm calculates the confidence bounds for each arm in the active set using the formula as follows: let \(\mathrm{Conf}(i,t)\) and \(\hat{\mu}_{i}(t)\) be the confidence width and the empirical mean of arm \(i\) at time \(t\) as

\[\mathrm{Conf}(i,t):=\sqrt{2\sigma_{i}^{2}\frac{\log(6(N_{i}(t))^{2}/((\frac{ \delta^{2}}{2K})\pi^{2}))}{N_{i}(t)}},\qquad\hat{\mu}_{i}(t):=\sum_{s=1}^{t-1}X _{s}\bm{1}[A_{s}=i].\]

Then the upper and lower confidence bounds of arm \(i\) at timestep \(t\), denoted as \(\mathrm{UCB}\) and \(\mathrm{LCB}\) respectively, can be defined in the following manner:

\[\mathrm{UCB}(i,t):=\hat{\mu}_{i}(t)+\mathrm{Conf}(i,t),\qquad\mathrm{LCB}(i,t ):=\hat{\mu}_{i}(t)-\mathrm{Conf}(i,t).\] (5)

This confidence bounds ensure that, with high probability, for all \(t\in[T]\) and \(i\in[K]\), \(\mu_{i}\in(\mathrm{UCB}(i,t),\mathrm{LCB}(i,t))\) (See Lemma 15 in Appendix for details). After calculating \(\mathrm{UCB}\) and \(\mathrm{LCB}\), the algorithm eliminates arms with \(\mathrm{UCB}\) smaller than the largest \(\mathrm{LCB}\) and maintains only arms that could be optimal in the active set \(\mathcal{A}\). Up to this point, it follows the traditional elimination approach.

The main difference in our algorithm lies in the stopping criterion. At the end of each iteration, the algorithm checks the stopping criterion. Unlike typical elimination algorithms that continue until only one arm remains, we have introduced an additional indifference condition. This condition arises when the suboptimality gap is so small that identifying them would require an excessive number of samples. In such cases, our algorithm stops additional attempts to identify differences between arms in the active set and randomly recommends one from the active set instead.

**Remark 2**.: In the context of PAC-(\(\epsilon\), \(\delta\)) identification, Even-Dar et al. (2006, Remark 9) introduced a similar approach. The largest difference is that they use the parameter \(\epsilon\) as a parameter that defines the indifference-zone level, whereas our parameter \(\Delta_{0}\) is spontaneously derived from the prior \(\bm{H}\) and the confidence level \(\delta\) without specifying the indifference-zone.

Theorem 6 describes the theoretical guarantee of the Algorithm 1.

**Theorem 6**.: For \(\delta<4L(\bm{H})\cdot\min\biggl{(}\frac{L(\bm{H})}{\sum_{i\in[k]}\frac{k-1}{ \xi_{i}}},\Bigl{(}\min_{i,j\in[k]}\xi_{i}L_{ij}(\bm{H})\Bigr{)}^{2}\biggr{)}\), Algorithm 1 which consists of \(((A_{t}),\tau,J)\) has the expected stopping time upper bound as follows:

\[\mathbb{E}_{\bm{\mu}\sim\bm{H}}[\tau]\leq C\cdot\sigma_{\max}^{2}\frac{L(\bm{ H})^{2}}{\delta}\log\left(\frac{L(\bm{H})}{\delta}\right)+O(\log\delta^{-1}),\] (6)

where \(C=320\Bigl{(}\frac{\pi^{2}}{3}+1\Bigr{)}\) is a universal constant and \(\sigma_{\max}=\max_{i\in[k]}\sigma_{i}\). Here, \(O(\log\delta^{-1})\) is a function of \(\delta\) and \(\bm{H}\) that is proportional to \(\log\delta^{-1}\) when we view prior parameters \(\bm{H}\) as constants. Plus, the strategy defined by Algorithm 1 is in \(\mathcal{A}^{b}(\delta,\bm{H})\).

See Appendix E for the formal proof of Theorem 6.

**Remark 3**.: When we compare the lower bound (Theorem 4) with the upper bound of Algorithm 1 (Theorem 6), we can see the algorithm is near-optimal. If we view \(\sigma_{\max}/\sigma_{\min}\) as a constant, the bounds are tight up to a \(\log\frac{L(\bm{H})}{\delta}\) factor.

**Remark 4**.: The condition \(\delta<4L(\bm{H})\cdot\min\Bigl{(}L(\bm{H})/\sum_{i\in[k]}\frac{k-1}{\xi_{i}},\min_{i,j\in[k]}\bigl{(}\xi_{i}L_{ij}(\bm{H})\bigr{)}^{2}\Bigr{)}\) is only for cleaner illustration of the regret bound in Theorem 6. The non-asymptotic result, when \(\delta\) is a moderately large constant, can be found in Appendix E.1.

Proof sketch of Theorem 6We summarize the general strategy for the proof as follows. By the law of total expectation, \(\mathbb{E}_{\bm{\mu}\sim\bm{H}}[\tau]=\mathbb{E}_{\bm{\mu}\sim\bm{H}}\Bigl{[} \mathbb{E}_{\bm{\mu}}[\tau]\Bigr{]}\). Therefore, we first derive a frequentist upper bound of \(\mathbb{E}_{\bm{\mu}}[\tau]\), and then marginalize it to obtain the expected Bayesian stopping time.

First, with the confidence bound defined as Eq. (5) we have the following guarantee that the true means for all arms are in the confidence bound interval with high probability.

**Lemma 7**.: For any fixed \(\bm{\mu}\in\{\mathbf{v}\in\mathbb{R}^{k}:v_{i}\neq v_{j}\text{ for all }i,j\in[k]\}\), let \(\mathcal{X}(\bm{\mu}):=\{\forall i\in[k]\text{ and }t\in\mathbb{N},\ \mu_{i}\in( \operatorname{LCB}(i,t),\operatorname{UCB}(i,t))\}\). Then, \(\mathbb{P}_{\bm{\mu}}\big{[}\mathcal{X}(\bm{\mu})\big{]}\geq 1-\delta^{2}\).

Now we can rewrite \(\mathbb{E}_{\bm{\mu}\sim\bm{H}}\left[\tau\right]\) as follows:

\[\mathbb{E}_{\bm{\mu}\sim\bm{H}}\left[\tau\right]= \mathbb{E}_{\bm{\mu}\sim\bm{H}}\left[\mathbb{E}_{\bm{\mu}}[ \tau]\right]\] (Law of Total Expectation) \[= \mathbb{E}_{\bm{\mu}\sim\bm{H}}\left[\mathbb{E}_{\bm{\mu}}[\tau \mathbf{1}[\mathcal{X}(\bm{\mu})]]\right]+\mathbb{E}_{\bm{\mu}\sim\bm{H}} \left[\mathbb{E}_{\bm{\mu}}[\tau\mathbf{1}[\mathcal{X}(\bm{\mu})^{c}]]\right]\] \[= \sum_{i}\mathbb{E}_{\bm{\mu}\sim\bm{H}}\Big{[}\mathbb{E}_{\bm{\mu }}[N_{i}(\tau)\mathbf{1}[\mathcal{X}(\bm{\mu})]]\Big{]}+\mathbb{E}_{\bm{\mu} \sim\bm{H}}\left[\mathbb{E}_{\bm{\mu}}[\tau\mathbf{1}[\mathcal{X}(\bm{\mu})^{ c}]]\right].\] (7)

Let \(\Delta_{i}=\Delta_{i}(\bm{\mu}):=(\max_{s\in[k]}\mu_{s})-\mu_{i}\) and \(R_{0}(\Delta)\approx\lceil C\sigma_{\max}^{2}\cdot\frac{\log\Delta^{-1}}{ \Delta^{2}}\rceil\). For the first term, under \(\mathcal{X}(\bm{\mu})\), we can bound \(N_{i}(\tau)\) by \(R_{0}(\max(\Delta_{0},\Delta_{i}))\) (Lemma 17 in Appendix E), and integrate it over the prior distribution to obtain the leading factor. For the second term, thanks to the indifference stopping condition (\(\hat{\Delta}^{\text{safe}}(t)\leq\Delta_{0}\)), one can prove that \(\tau\) is always smaller than \(R(\Delta_{0})\) (Lemma 14 in Appendix E), which leads to non-leading term.

To check that the expected probability of error is below \(\delta\), we have an additional lemma:

**Lemma 8** (Probability of dropping \(i^{*}(\bm{\mu})\)).: For any \(\bm{\mu}_{0}\), under \(\mathcal{H}_{\bm{\mu}_{0}}\), \(\mathcal{X}(\bm{\mu}_{0})\subset\bigcap_{t}\left\{i^{*}(\bm{\mu}_{0})\in \mathcal{A}(t)\right\}.\)

This lemma means under the event \(\mathcal{X}(\bm{\mu})\), the best arm is never dropped. We can also prove that under the event \(\mathcal{X}(\bm{\mu})\), if \(\Delta_{i}(\bm{\mu})>\Delta_{0}\), the sub-optimal arm will eventually be dropped before the algorithm terminates (Lemma 14 in Appendix E). These two facts mean there are only two cases in which the prediction of Algorithm 1 could be wrong.

* Under \(\mathcal{X}(\bm{\mu})^{c}\), both facts cannot guarantee the correct identification. From Lemma 7, \(\mathbb{P}_{\bm{\mu}}[\mathcal{X}(\bm{\mu})^{c}]\leq\delta^{2}\) for all \(\bm{\mu}\), and thus \(\mathbb{P}_{\bm{\mu}\sim\bm{H}}[\mathcal{X}(\bm{\mu})^{c}]\leq\delta^{2}\).
* When \(\Delta_{i}(\bm{\mu})\leq\Delta_{0}\). From Lemma 1 and the definition of \(\Delta_{0}\), the probability of drawing such \(\bm{\mu}\) from the prior is at most \(\delta/2\).

Therefore, by union bound, Algorithm 1 has the expected probability of misidentification guarantee smaller than \(\delta^{2}+\delta/2<\delta\).

## 6 Simulation

We conduct two experiments to demonstrate that the expected stopping times of frequentist \(\delta\)-correct algorithms diverge in a Bayesian setting and that the elimination process in Algorithm 1 is necessary for more efficient sampling. In Tables 1 and 2, each column 'Avg', 'Max', and 'Error' represents the average stopping time, maximum stopping time, and the ratio of the misidentification, respectively.5 More details of these experiments are in Appendix F.

Footnote 5: We include the computation time in the Appendix F.3

Frequentist algorithms diverge in Bayesian SettingWe evaluate the empirical performance of our Elimination algorithm (Algorithm 1) by comparing it with other frequentist algorithms such as Top-two Thompson Sampling (TTTS) (Russo, 2016) and Top-two UCB (TTUCB) (Jourdan and Degenne, 2022b).

We design an experiment setup that has \(k=2\) arms with standard Gaussian prior distribution, which means \(m_{i}=0,\xi_{i}=1\) for all \(i\in[k]\). We set \(\delta=0.1\) and ran \(N=1000\) Bayesian FC-BAI simulations to estimate the expected stopping time and success rate.

In Table 1, one can see that the two top-two algorithms exhibit very large maximum stopping time. This supports our theoretical result in Section 3 that the expected stopping time of Frequentist \(\delta\)-correct algorithms will diverge in the Bayesian setting. We did not check the track and stop algorithm (Garivier and Kaufmann, 2016) because it needs to solve an optimization for each round, but the fact that the expected stopping time of the track and stop is at least half of the TTTS and TTUCB for a small \(\delta\) implies that the performance of track and stop is similar to that of top-two algorithms. Algorithm 1 shows a significantly smaller average stopping time as well as an average computation time than that of these algorithms.

Effect of the elimination processWe implemented the modification of Algorithm 1 (denoted as NoElim) that never eliminates an arm from \(\mathcal{A}(t)\)6 In this setup, we have \(k=10\) arms with standard Gaussian prior distribution, which means \(m_{i}=0,\xi_{i}=1\) for all \(i\in[k]\). We set \(\delta=0.01\) and ran \(N=1000\) Bayesian FC-BAI simulations.

Footnote 6: See Appendix F.2 for the pseudocode.

As one can check from Table 2, elimination of arms helps the efficient use of samples and reduces stopping time and computation time.

## 7 Discussion and future works

We have considered the Gaussian Bayesian best arm identification with fixed confidence. We show that the traditional Frequentist FC-BAI algorithms do not stop in finite time in expectation, which implies the suboptimality of such algorithms in the Bayesian FC-BAI problem. We have established a lower bound of the Bayesian expected stopping time, which is of order \(\Omega(\frac{L(\bm{H})^{2}}{\delta})\). Moreover, we have introduced the elimination and early stopping algorithm, which achieves a matching stopping time up to a polylogarithmic factor of \(L(\bm{H})\) and \(\delta\). We conduct simulations to support our results.

In the future, we will attempt to tighten the logarithmic and \(\left(\frac{\max_{i}\sigma_{i}}{\min_{i}\sigma_{i}}\right)^{2}\) gap between the lower and upper bound, extend the indifference zone strategy for other traditional BAI algorithms in the Bayesian setting, extend our analysis from Gaussian bandit instances to general exponential families, and design a robust algorithm against misspecified priors.

## Acknowledgements

K. Jang acknowledge the financial support from the MUR PRIN grant 2022EKNE5K (Learning in Markets and Society), the FAIR (Future Artificial Intelligence Research) project, funded by the NextGenerationEU program within the PNRR-PE-AI scheme, and the the EU Horizon CL4-2022-HUMAN-02 research and innovation action under grant agreement 101120237, project ELIAS (European Lighthouse of AI for Sustainability).

J. Komiyama was supported by NYU Stern School of Business Research Scholars Fund no. 10-83004-BF478.

K. Yamazaki was supported by JSPS KAKENHI grant no. JP20K03758, JP24K06844 and JP24H00328 and the start-up grant by the School of Mathematics and Physics of the University of Queensland.

## References

* Atsidakou et al. (2023) Alexia Atsidakou, Sumeet Katariya, Sujay Sanghavi, and Branislav Kveton. Bayesian fixed-budget best-arm identification, 2023.
* Audibert et al. (2010) Jean-Yves Audibert, Sebastien Bubeck, and Remi Munos. Best arm identification in multi-armed bandits. In _Conference on Learning Theory_, pages 41-53, 2010. URL http://colt2010.haifa.il.ibm.com/papers/COLT2010proceedings.pdf#page=49.
* Bechhofer (1954) Robert E Bechhofer. A single-sample multiple decision procedure for ranking means of normal populations with known variances. _The Annals of Mathematical Statistics_, pages 16-39, 1954.
* Bechhofer (1961)

\begin{table}
\begin{tabular}{c|c c c} \hline \hline  & Avg & Max & Error \\ \hline Alg. 1 & \(1.06\times 10^{4}\) & \(2.35\times 10^{5}\) & 1.5\% \\ TTTS & \(1.56\times 10^{5}\) & \(1.09\times 10^{8}\) & 0.5\% \\ TTUCB & \(1.95\times 10^{5}\) & \(1.13\times 10^{8}\) & 0\% \\ \hline \hline \end{tabular}
\end{table}
Table 1: Comparison of two top-two algorithms and Algorithm 1.

\begin{table}
\begin{tabular}{c|c c c} \hline \hline  & Avg & Max & Error \\ \hline Alg. 1 & \(2.69\times 10^{5}\) & \(1.66\times 10^{7}\) & 0.6\% \\ NoElim & \(1.29\times 10^{6}\) & \(8.25\times 10^{7}\) & 0\% \\ \hline \hline \end{tabular}
\end{table}
Table 2: Comparison of Algorithm 1 and the no-elimination version of it.

[MISSING_PAGE_FAIL:11]

Emilie Kaufmann, Olivier Cappe, and Aurelien Garivier. On the complexity of a/b testing. In _Conference on Learning Theory_, pages 461-481. PMLR, 2014.
* Kaufmann et al. (2016a) Emilie Kaufmann, Olivier Cappe, and Aurelien Garivier. On the complexity of best-arm identification in multi-armed bandit models. _Journal of Machine Learning Research_, 17(1):1-42, 2016a.
* Kaufmann et al. (2016b) Emilie Kaufmann, Olivier Cappe, and Aurelien Garivier. On the complexity of best arm identification in multi-armed bandit models, 2016b.
* Komiyama et al. (2023) Junpei Komiyama, Kaito Ariu, Masahiro Kato, and Chao Qin. Rate-optimal bayesian simple regret in best arm identification. _Mathematics of Operations Research, Ahead of Print_, 2023. doi: 10.1287/moor.2022.0011. URL https://doi.org/10.1287/moor.2022.0011.
* 1114, 1987. doi: 10.1214/aos/1176350495. URL https://doi.org/10.1214/aos/1176350495.
* Locatelli et al. (2016) Andrea Locatelli, Maurilio Gutzeit, and Alexandra Carpentier. An optimal algorithm for the thresholding bandit problem. In Maria-Florina Balcan and Kilian Q. Weinberger, editors, _Proceedings of the 33nd International Conference on Machine Learning, ICML 2016, New York City, NY, USA, June 19-24, 2016_, volume 48 of _JMLR Workshop and Conference Proceedings_, pages 1690-1698. JMLR.org, 2016. URL http://proceedings.mlr.press/v48/locatelli16.html.
* Maron and Moore (1993) Oded Maron and Andrew W. Moore. Hoeffding races: Accelerating model selection search for classification and function approximation. In Jack D. Cowan, Gerald Tesauro, and Joshua Alspector, editors, _Advances in Neural Information Processing Systems 6, [7th NIPS Conference, Denver, Colorado, USA, 1993]_, pages 59-66. Morgan Kaufmann, 1993. URL http://papers.nips.cc/paper/841-hoeffding-races-accelerating-model-selection-search-for-classification-and-function-approximation.
* Mockus (2012) J. Mockus. _Bayesian Approach to Global Optimization: Theory and Applications_. Mathematics and its Applications. Springer Netherlands, 2012. ISBN 9789400909090. URL https://books.google.fr/books?id=VuKoCAAAQBAJ.
* 180, 1964. doi: 10.1214/aoms/1177703739. URL https://doi.org/10.1214/aoms/1177703739.
* Qin et al. (2017a) Chao Qin, Diego Klabjan, and Daniel Russo. Improving the expected improvement algorithm. In _Advances in Neural Information Processing Systems_, volume 30, pages 5381-5391, 2017a.
* Qin et al. (2017b) Chao Qin, Diego Klabjan, and Daniel Russo. Improving the expected improvement algorithm. _Advances in Neural Information Processing Systems_, 30, 2017b.
* 535, 1952.
* Russo (2016) Daniel Russo. Simple bayesian algorithms for best arm identification. In _29th Annual Conference on Learning Theory_, volume 49 of _Proceedings of Machine Learning Research_, pages 1417-1418. PMLR, 23-26 Jun 2016.
* Shahriari et al. (2016) Bobak Shahriari, Kevin Swersky, Ziyu Wang, Ryan P. Adams, and Nando de Freitas. Taking the human out of the loop: A review of bayesian optimization. _Proc. IEEE_, 104(1):148-175, 2016. doi: 10.1109/JPROC.2015.2494218. URL https://doi.org/10.1109/JPROC.2015.2494218.
* Shang et al. (2020) Xuedong Shang, Rianne Heide, Pierre Menard, Emilie Kaufmann, and Michal Valko. Fixed-confidence guarantees for bayesian best-arm identification. In _International Conference on Artificial Intelligence and Statistics_, pages 1823-1832. PMLR, 2020.
* Srinivas et al. (2010) Niranjan Srinivas, Andreas Krause, Sham M. Kakade, and Matthias W. Seeger. Gaussian process optimization in the bandit setting: No regret and experimental design. In Johannes Furnkranz and Thorsten Joachims, editors, _Proceedings of the 27th International Conference on Machine Learning (ICML-10), June 21-24, 2010, Haifa, Israel_, pages 1015-1022. Omnipress, 2010. URL https://icml.cc/Conferences/2010/papers/422.pdf.
* Sridharan et al. (2016)Koji Tabata, Atsuyoshi Nakamura, Junya Honda, and Tamiki Komatsuzaki. A bad arm existence checking problem: How to utilize asymmetric problem structure? _Mach. Learn._, 109(2):327-372, 2020. doi: 10.1007/S10994-019-05854-7. URL https://doi.org/10.1007/s10994-019-05854-7.
* Tabata et al. (2023) Koji Tabata, Junpei Komiyama, Atsuyoshi Nakamura, and Tamiki Komatsuzaki. Posterior tracking algorithm for classification bandits. In Francisco J. R. Ruiz, Jennifer G. Dy, and Jan-Willem van de Meent, editors, _International Conference on Artificial Intelligence and Statistics, 25-27 April 2023, Palau de Congressos, Valencia, Spain_, volume 206 of _Proceedings of Machine Learning Research_, pages 10994-11022. PMLR, 2023. URL https://proceedings.mlr.press/v206/tabata23a.html.
* Thompson (1933) William R Thompson. On the likelihood that one unknown probability exceeds another in view of the evidence of two samples. _Biometrika_, 25(3/4):285-294, 1933.
* Xu et al. (2019) Yichong Xu, Xi Chen, Aarti Singh, and Artur Dubrawski. Thresholding bandit problem with both duels and pulls. _CoRR_, abs/1910.06368, 2019. URL http://arxiv.org/abs/1910.06368.
* Zhao et al. (2023) Yao Zhao, Connor Stephens, Csaba Szepesvari, and Kwang-Sung Jun. Revisiting simple regret: Fast rates for returning a good arm. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors, _International Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA_, volume 202 of _Proceedings of Machine Learning Research_, pages 42110-42158. PMLR, 2023. URL https://proceedings.mlr.press/v202/zhao23g.html.

## Appendix A Notation table

## Appendix B Proof of Lemma 1

We will use the following formal version of the volume lemma for the proof. The first result is used for the upper bound, and the second result is used for the lower bound.

**Lemma 9** (Volume Lemma, formal).: Let \(\Theta_{ij}:=\{\bm{\mu}\in\mathbb{R}^{k}:i^{*}(\bm{\mu})=i,j^{*}(\bm{\mu})=j\}\).

1. For any \(\Delta\in(0,1)\), define \[L_{ij}(\bm{H},\Delta):=\frac{1}{\delta}\int_{\Theta_{ij}}\mathbf{1}[|\mu_{i}- \mu_{j}|\leq\Delta]\,\mathrm{d}\bm{H}(\bm{\mu}).\]

\begin{table}
\begin{tabular}{l l} symbol & definition \\ \hline \(R\) & \(e^{-4}\) \\ \(\tilde{\Delta}\) & \(\frac{32e^{4}}{L(\bm{H})}\delta\) \\ \(\bm{\nu}(\bm{\mu})\) & alternative model where the top-two means are swapped \\ \(n_{i}(\bm{\mu})\) & \(\mathbb{E}_{\bm{\mu}}[N_{i}(\tau)]\) \\ \(D_{0}(\bm{H})\) & \(\begin{cases}W(-\frac{1}{32\max_{i\in[k]}\xi_{i}^{3/2}})&\text{If }\max_{i\in[k]}\xi_{i}> \sqrt[3]{\frac{e^{2}}{2^{10}}}\\ 1&\text{Otherwise}\end{cases}\) (\(W\) is the Lambert W function.) \\ \(D_{1}(\bm{H})\) & \(\min_{i\neq j}\biggl{[}\left|\frac{m_{i}}{\sigma_{i}^{2}}-\frac{m_{j}}{ \sigma_{j}^{2}}\right|^{-1},\left[\frac{1}{2\sigma_{i}^{2}}+\frac{1}{2\sigma_{ j}^{2}}\right]^{-2}\biggr{]}\) \\ \(\delta_{L}(\bm{H})\) & \(\frac{L(\bm{H})}{32e^{4}}\cdot\min\biggl{(}D_{0}(\bm{H}),D_{1}(\bm{H}),\min_{ i\in[k]}\frac{1}{4m_{i}^{2}},\frac{L(\bm{H})}{4(k-1)\sum_{i\in[k]}\frac{1}{ \xi_{i}}}\biggr{)}\) \\ \end{tabular}
\end{table}
Table 4: Notations for the lower bound proof, Section D

\begin{table}
\begin{tabular}{l l} symbol & definition \\ \hline \(k\) & number of the arms \\ \(\delta\) & confidence level \\ \(\bm{\mu}\) & means \((=(\mu_{1},\mu_{2},\ldots,\mu_{k}))\) \\ \(\bm{H}\) & prior distribution of \(\bm{\mu}\) \\ \(H_{i}\) & prior distribution of \(\mu_{i}\) \\ \(h_{i}\) & prior density of \(\mu_{i}\) \\ \(m_{i},\xi_{i}\) & mean and standard deviation of \(h_{i}\) \\ \(N_{i}(t)\) & \(\sum_{s=1}^{t-1}\mathbf{1}[A_{s}=i]\) \\ \(L(\bm{H})\) & See Definition 2 \\ \(i^{*}(\bm{\mu}),j^{*}(\bm{\mu})\) & best arm and second best arm \\ \(\bm{\nu}(\bm{\mu})\) & alternative model where the top-two means of \(\bm{\mu}\) are swapped \\ \(\mathrm{KL}_{i}(\cdot,\cdot)\) & KL divergence between two distributions \\ \(d(p,q)\) & KL divergence between two Bernoulli distributions with parameters \(p\) and \(q\) \\ \(N_{i}(t)\) & number of draws on arm \(i\) before time step \(t\) \\ \(B\) & \(320\max_{i\in[k]}\sigma_{i}^{2}\) \\ \(B_{0}\) & \(\left(\frac{\pi^{2}}{3}+1\right)B\) \\ \(\Theta_{i}\) & \(\{\bm{\mu}\in\mathbb{R}^{k}:i^{*}(\bm{\mu})=i\}\) \\ \(\Theta_{ij}\) & \(\{\bm{\mu}\in\mathbb{R}^{k}:i^{*}(\bm{\mu})=i,j^{*}(\bm{\mu})=j\}\) \\ \(\bm{\mu}_{\setminus i}\) ( \(\bm{\mu}_{\setminus i,j}\)) & the vector projection which omits \(i\)-th coordinate (\(i,j\)-th, respectively) \\ \(\bm{H}_{\setminus i}\) ( \(\bm{H}_{\setminus i,j}\)) & the distribution which omits \(i\)-th coordinate (\(i,j\)-th, respectively) \\ \end{tabular}
\end{table}
Table 3: Major notationThen, \[L_{ij}(\bm{H},\Delta)\in\bigg{[}L_{ij}(\bm{H})-\frac{1}{\xi_{i}}\Delta,L_{ij}(\bm{ H})+\frac{1}{\xi_{i}}\Delta\bigg{]}.\] (8) In particular, when \(\Delta<\frac{L(\bm{H})}{\sum_{i\in[k]}\frac{k-1}{\xi_{i}}}\), \(L(\bm{H},\Delta)\leq 2L(\bm{H})\).
2. (Volume lemma for the lower bound) For small enough positive real number \(\Delta<\min\bigg{[}\frac{1}{4\max_{i\in[k]}m_{i}^{2}},D_{0}(\bm{H})\bigg{]}\)7 let Footnote 7: See Appendix G for the definition of \(D_{0}(\bm{H})\).

\[L^{\prime}_{ij}(\bm{H},\Delta):=\frac{1}{\Delta}\int_{\Theta_{ij}}\bm{1}[|\mu _{i}-\mu_{j}|\leq\Delta]\bm{1}[|\mu_{i}|,|\mu_{j}|\leq\frac{1}{\sqrt{\Delta}} ]\,\mathrm{d}\bm{H}(\bm{\mu}).\] Then, \[L^{\prime}_{ij}(\bm{H},\Delta)\in\bigg{[}L_{ij}(\bm{H})-\frac{2}{\xi_{i}} \Delta,L_{ij}(\bm{H})+\frac{1}{\xi_{i}}\Delta\bigg{]}.\] (9) In particular, when \(\Delta<\min\Bigg{[}\frac{1}{4\max_{i\in[k]}m_{i}^{2}},D_{0}(\bm{H}),\frac{L( \bm{H})}{\sum_{i\in[k]}\frac{4(k-1)}{\xi_{i}}}\Bigg{]}\), \(L^{\prime}(\bm{H},\Delta)\in\Big{[}\frac{1}{2}L(\bm{H}),2L(\bm{H})\Big{]}\).

Proof.: First, let us prove the upper bound of Eq. (8), i.e. \(L_{ij}(\bm{H},\delta)\leq L_{ij}(\bm{H})+\frac{1}{\xi_{i}}\Delta\).

Recall for \(i,j\in[k]\), \(\Theta_{ij}=\{\mu:i^{*}(\mu)=i,j^{*}(\mu)=j\}\). We have

\[\int_{\Theta_{ij}}\bm{1}\left[|\mu_{i}-\mu_{j}|\leq\Delta\right] \mathrm{d}\bm{H}(\bm{\mu}) =\int_{-\infty}^{\infty}\int_{\mu_{j}}^{\mu_{j}+\Delta}h_{i}(\mu_{ i})\,\mathrm{d}\mu_{i}\prod_{k\neq i,j}\int_{-\infty}^{\mu_{j}}h_{k}(\mu_{k})\, \mathrm{d}\mu_{k}h_{j}(\mu_{j})\,\mathrm{d}\mu_{j}\] \[\leq\Delta\int_{-\infty}^{\infty}\biggl{[}h_{i}(\mu_{j})+\frac{e ^{-1/2}}{\xi_{i}}\Delta\bigg{]}\prod_{k\neq i,j}\int_{-\infty}^{\mu_{j}}h_{k}( \mu_{k})\,\mathrm{d}\mu_{k}h_{j}(\mu_{j})\,\mathrm{d}\mu_{j}\]

(by the Lipschitz property of the Gaussian density, \(e^{-1/2}/\xi_{i}\) is the steepest slope of \(N(m_{i},\xi_{i}^{2})\))

\[\leq\Delta\left(\underbrace{\int_{-\infty}^{\infty}h_{i}(\mu_{j})\prod_{k\neq i,j}\int_{-\infty}^{\mu_{j}}h_{k}(\mu_{k})\,\mathrm{d}\mu_{k}h_{j}(\mu_{j})\, \mathrm{d}\mu_{j}}_{=L_{ij}(\bm{H})}+\right[\frac{e^{-1/2}}{\xi_{i}}\Delta \bigg{]}\right).\]

\begin{table}
\begin{tabular}{l l} symbol & definition \\ \hline \(\mathrm{Conf}(i,t)\) & confidence bound (Section 5) \\ \(\mathrm{UCB}(i,t),\mathrm{LCB}(i,t)\) & upper and lower confidence bounds (Section 5) \\ \(\hat{\Delta}^{\mathrm{safe}}(t)\) & \(\max_{i\in\mathcal{A}(t)}\mathrm{UCB}(i,t)-\max_{i\in\mathcal{A}(t)}\mathrm{ LCB}(i,t)\) \\ \(\Delta_{0}\) & \(\frac{\delta}{4L(\bm{H})}\) \\ \(\Delta_{thr}\) & \(\min\left(\frac{6\sqrt{k}}{\delta\pi},\frac{1}{B}\right)\) \\ \(R_{0}(\Delta)\) & \(B\frac{\log\min(\Delta,\Delta_{thr})^{-1}}{\min(\Delta,\Delta_{thr})^{2}}\) \\ \(T_{0}\) & \(kR_{0}(\Delta_{0})\) \\ \(\Delta_{s}(\bm{\mu})\) & \(\mu_{i^{*}(\bm{\mu})}-\mu_{s}\) \\ \(\mathcal{X}(\bm{\mu})\) & Event \(\bigcap_{i\in[k]}\Big{[}\Big{(}\bigcap_{t=1}^{\infty}\{\mathrm{LCB}(i,t)\leq \mu_{i}\}\Big{)}\bigcap\Big{(}\bigcap_{t=1}^{\infty}\{\mathrm{UCB}(i,t)\geq \mu_{i}\}\Big{)}\Big{]}\). (Eq. (24)) \\ \end{tabular}
\end{table}
Table 5: Notations for the upper bound proof, Section E Therefore, we verified the upper bound side of Eq. (8).

For the lower bound, by following the same steps, one can prove \(\int_{\Theta_{ij}}\mathbf{1}\left[|\mu_{i}-\mu_{j}|\leq\Delta\right]\mathrm{d} \boldsymbol{H}(\boldsymbol{\mu})\geq(L_{ij}(\boldsymbol{H})-\frac{1}{\xi_{i}} \Delta)\Delta\).

For the proof of Eq. (9), by Chernoff's method we can bound the tail probability as follows:

\[\int_{\Theta_{ij}}\mathbf{1}\left[|\mu_{i}-m_{i}|>\frac{1}{\sqrt{ \Delta}}\right]\mathrm{d}H(\boldsymbol{\mu})<\int_{\mathbb{R}^{k}}\mathbf{1} \left[|\mu_{i}-m_{i}|>\frac{1}{\sqrt{\Delta}}\right]\mathrm{d}H(\boldsymbol{ \mu})<2\exp\!\left(-\frac{1}{2\Delta\xi_{i}^{2}}\right)\!.\]

When \(|m_{i}|<\frac{1}{2\sqrt{\Delta}}\), then we can change the above inequality as:

\[\int_{\Theta_{ij}}\mathbf{1}\left[|\mu_{i}|>\frac{1}{\sqrt{ \Delta}}\right]\mathrm{d}H(\boldsymbol{\mu}) \leq\int_{\mathbb{R}^{k}}\mathbf{1}\left[|\mu_{i}|>\frac{1}{ \sqrt{\Delta}}\right]\mathrm{d}H(\boldsymbol{\mu})\] \[\leq\int_{\mathbb{R}^{k}}\mathbf{1}\left[|\mu_{i}-m_{i}|>\frac{1 }{2\sqrt{\Delta}}\right]\mathrm{d}H(\boldsymbol{\mu})<2\exp\!\left(-\frac{1} {8\Delta\xi_{i}^{2}}\right)\!.\]

Therefore,

\[\int_{\Theta_{ij}}\mathbf{1}[|\mu_{i}-\mu_{j}|\leq\Delta] \mathbf{1}[|\mu_{i}|,|\mu_{j}|\leq\frac{1}{\sqrt{\Delta}}]\mathrm{d} \boldsymbol{H}(\boldsymbol{\mu})\geq\int_{\Theta_{ij}}\mathbf{1}\left[|\mu_{i} -\mu_{j}|\leq\Delta\right]\mathrm{d}\boldsymbol{H}(\boldsymbol{\mu})\] \[\geq(L_{i}(\boldsymbol{H})-\frac{1}{\xi_{i}}\Delta)\Delta-2\exp \!\left(-\frac{1}{8\Delta\xi_{i}^{2}}\right)-2\exp\!\left(-\frac{1}{8\Delta \xi_{j}^{2}}\right)\] \[\geq(L_{i}(\boldsymbol{H})-\frac{2}{\xi_{i}}\Delta)\Delta\] (by \[\Delta<D_{0}(\boldsymbol{H})\] )

for \(\Delta<\min\!\left[\min_{i\in[k]}\frac{1}{4m_{i}^{2}},D_{0}(\boldsymbol{H})\right]\). 

## Appendix C Proof of Theorem 2

For \(\Delta>0\), let \(\Theta_{i}(\Delta):=\{\boldsymbol{\mu}\in\mathbb{R}^{k}:i^{*}(\boldsymbol{\mu}) =i,\mu_{i}-\mu_{j^{*}(\boldsymbol{\mu})}\leq\Delta\}\). From Lemma 9, we have

\[\mathbb{P}_{\boldsymbol{\mu}\sim\boldsymbol{H}}\Big{[}i^{*}( \boldsymbol{\mu})=i,\mu_{i}-\mu_{j^{*}(\boldsymbol{\mu})}\leq\Delta\Big{]} =\sum_{j\neq i}\mathbb{P}_{\boldsymbol{\mu}\sim\boldsymbol{H}} \Big{[}i^{*}(\boldsymbol{\mu})=i,j^{*}(\boldsymbol{\mu})=j,\mu_{i}-\mu_{j} \leq\Delta\Big{]}\] \[\geq\sum_{j\neq i}\frac{1}{2}L_{ij}(\boldsymbol{H})\Delta.\]

Now, for each \(\boldsymbol{\mu}\in\mathbb{R}^{k}\), let \(\nu:\mathbb{R}^{k}\rightarrow\mathbb{R}^{k}\) be a function such that for \(s\in[k]\),

\[\nu(\boldsymbol{\mu})_{s}:=\begin{cases}\mu_{i^{*}(\boldsymbol{\mu})}&\text{ when }s=j^{*}(\boldsymbol{\mu})\\ \mu_{j^{*}(\boldsymbol{\mu})}&\text{when }s=i^{*}(\boldsymbol{\mu})\\ \mu_{s}&\text{Otherwise.}\end{cases}\]

For any \(\boldsymbol{\mu}\in\mathbb{R}^{k}\), let \(\mathcal{E}(\boldsymbol{\mu})=\{J\neq i^{*}(\boldsymbol{\mu})\}\) and \(\boldsymbol{\nu}=\nu(\boldsymbol{\mu})\). By Lemma 1 in Kaufmann et al. (2016a), for any frequentist \(\delta\)-correct algorithm \(\pi=((A_{t})_{t},\tau,J)\), we have

\[\sum_{s\in[k]}\mathbb{E}_{\boldsymbol{\mu}}[N_{s}(\tau)]\mathrm{KL}_{s}(\mu_{ s}||\nu_{s})\geq d(P_{\boldsymbol{\mu}}(\mathcal{E}(\boldsymbol{\mu})),P_{ \boldsymbol{\nu}}(\mathcal{E}(\boldsymbol{\mu}))),\quad\boldsymbol{\mu}\in \mathbb{R}^{k}.\] (10)

For the left side, from the construction of \(\boldsymbol{\nu}\),\[\mathrm{KL}_{s}(\mu_{s}||\nu_{s}):=\begin{cases}\frac{(\mu_{i^{*}(\bm{\mu})}-\mu_{j^ {*}(\bm{\mu})})^{2}}{2\sigma_{s}^{2}}&s=i^{*}(\bm{\mu}),j^{*}(\bm{\mu})\\ 0&\text{Otherwise.}\end{cases}\]

Since \(\pi\in\mathcal{A}^{f}(\delta)\) and from the definition of \(\mathcal{E}(\bm{\mu})\) and \(\bm{\nu}\), \(\mathbb{P}_{\bm{\mu}}(\mathcal{E}(\bm{\mu}))\leq\delta\) and \(\mathbb{P}_{\bm{\nu}}(\mathcal{E}(\bm{\mu}))\geq 1-\delta\).

Overall, we can rewrite Eq. (10) to the following simpler form:

\[\mathbb{E}_{\bm{\mu}}[N_{i^{*}(\bm{\mu})}(\tau)]\frac{(\mu_{i^{*} (\bm{\mu})}-\mu_{j^{*}(\bm{\mu})})^{2}}{2\sigma_{i^{*}(\bm{\mu})}^{2}}+ \mathbb{E}_{\bm{\mu}}[N_{j^{*}(\bm{\mu})}(\tau)]\frac{(\mu_{i^{*}(\bm{\mu})}- \mu_{j^{*}(\bm{\mu})})^{2}}{2\sigma_{j^{*}(\bm{\mu})}^{2}}\geq d(\delta,1-\delta)\] \[\implies\mathbb{E}_{\bm{\mu}}[N_{i^{*}(\bm{\mu})}(\tau)+N_{j^{*} (\bm{\mu})}(\tau)]\geq\frac{2d(\delta,1-\delta)\min_{s\in[k]}\sigma_{s}^{2}}{ (\mu_{i^{*}(\bm{\mu})}-\mu_{j^{*}(\bm{\mu})})^{2}}.\]

Since \(\tau=\sum_{s=1}^{k}N_{s}(\tau)\), we can lower bound the expected stopping time when \(\bm{\mu}\) is given as follows:

\[\mathbb{E}_{\bm{\mu}}[\tau]\geq\mathbb{E}_{\bm{\mu}}[N_{i^{*}(\bm{\mu})}(\tau )+N_{j^{*}(\bm{\mu})}(\tau)]\geq\frac{2d(\delta,1-\delta)\min_{s\in[k]}\sigma_ {s}^{2}}{(\mu_{i^{*}(\bm{\mu})}-\mu_{j^{*}(\bm{\mu})})^{2}}.\] (11)

Now, when we compute marginal \(\mathbb{E}_{\bm{\mu}}[\tau]\) over \(\bm{\mu}\), we have

\[\mathbb{E}_{\bm{\mu}\sim\bm{H}}[\tau] =\mathbb{E}_{\bm{\mu}\sim\bm{H}}\Big{[}\mathbb{E}_{\bm{\mu}}[ \tau]\Big{]}\] (Law of total expectation) \[\geq\mathbb{E}_{\bm{\mu}\sim\bm{H}}\Big{[}\mathbb{E}_{\bm{\mu}}[ \tau]\bm{1}_{\Theta_{i}(\Delta)}\Big{]}\] (Eq. (11)) \[\geq\mathbb{E}_{\bm{\mu}\sim\bm{H}}\bigg{[}\frac{2d(\delta,1- \delta)\min_{s\in[k]}\sigma_{s}^{2}}{\Delta^{2}}\bm{1}_{\Theta_{i}(\Delta)} \Big{]}\] \[\geq\frac{\Big{(}\sum_{j\neq i}L_{ij}(\bm{H})\Big{)}d(\delta,1- \delta)\min_{s\in[k]}\sigma_{s}^{2}}{\Delta^{2}}=\frac{\Big{(}\sum_{j\neq i}L _{ij}(\bm{H})\Big{)}d(\delta,1-\delta)\min_{s\in[k]}\sigma_{s}^{2}}{\Delta}.\]

Now since \(\Delta\) is an arbitrary small positive number, we can conclude that \(\mathbb{E}_{\bm{\mu}\sim\bm{H}}[\tau]\) diverges.

## Appendix D Proof of Theorem 4

In this subsection, we will prove the following theorem:

**Theorem 10** (Restatement of Theorem 4).: Let \(\delta>0\) be sufficiently small such that \(\delta<\delta_{L}(\bm{H})\). For any best arm identification algorithm, if

\[\int_{\mathbb{R}^{k}}\left(\sum_{i\in[k]}n_{i}(\bm{\mu})\right)\mathrm{d}\bm{ H}(\bm{\mu})\leq N_{V},\]

then

\[\int_{\mathbb{R}^{k}}\mathbb{P}_{\bm{\mu}}[J\neq i^{*}(\bm{\mu})]\,\mathrm{d} \bm{H}(\bm{\mu})\geq\delta.\]

Proof.: By Lemma 1 in Kaufmann et al. (2016a), for any stopping time \(\tau\), we have

\[\sum_{i\in[k]}\mathbb{E}_{\bm{\mu}}[N_{i}(\tau)]\mathrm{KL}_{i}(\mu_{i}||\nu _{i})\geq d(\mathbb{P}_{\bm{\mu}}(\mathcal{E}(\bm{\mu})),\mathbb{P}_{\bm{\nu} }(\mathcal{E}(\bm{\mu}))),\quad\bm{\mu}\in\mathbb{R}^{k}.\] (12)

To modify the RHS of Eq. (12), we will use the following lemma:

**Lemma 11**.: For any \(p,q^{\prime},q\in(0,1)\) such that \(q^{\prime}\leq q\), we have

\[\ln\frac{1}{4(p+q)}\leq d(p,1-q^{\prime}).\]

By using Lemma 11 and the fact that \(\mathbb{P}_{\boldsymbol{\nu}}(\mathcal{E}(\boldsymbol{\mu}))\geq 1-\mathbb{P}_{ \boldsymbol{\nu}}[J\neq i^{*}(\boldsymbol{\nu})]\) by definition, we can transform (12) into

\[\sum_{i\in[k]}\mathbb{E}_{\boldsymbol{\mu}}[N_{i}(\tau)]\mathrm{KL}_{i}(\mu_ {i}||\nu_{i})\geq\ln\frac{1}{4(\mathbb{P}_{\boldsymbol{\mu}}[J\neq i^{*}( \boldsymbol{\mu})]+\mathbb{P}_{\boldsymbol{\nu}}[J\neq i^{*}(\boldsymbol{\nu })])},\quad\forall\boldsymbol{\mu}\in\mathbb{R}^{k}.\] (13)

Note that \(\mathbb{P}_{\boldsymbol{\mu}}(\mathcal{E}(\boldsymbol{\mu}))\) is exactly the error probability, and we are interested in the marginal error probability \(\mathbb{E}_{\boldsymbol{\mu}\sim H}[\mathbb{P}_{\boldsymbol{\mu}}(\mathcal{E})]\). Let \(n_{i}(\boldsymbol{\mu})=\mathbb{E}_{\boldsymbol{\mu}}[N_{i}(\tau)]\), and \(\tilde{\Delta}\) is an arbitrary small enough positive variable which we will define later on Eq. (19). Then, by rearrangement, we can induce the following inequalities

\[\int_{\mathbb{R}^{k}}\mathbb{P}_{\boldsymbol{\mu}}[J\neq i^{*}( \boldsymbol{\mu})]\,\mathrm{d}\boldsymbol{H}(\boldsymbol{\mu})\] \[=\sum_{i\in[k]}\sum_{j\neq i}\int_{\Theta_{ij}}\mathbb{P}_{ \boldsymbol{\mu}}[J\neq i]\,\mathrm{d}\boldsymbol{H}(\boldsymbol{\mu})\] \[=\frac{1}{2}\left(\sum_{i\in[k]}\sum_{j\neq i}\int_{\Theta_{ij}} \mathbb{P}_{\boldsymbol{\mu}}[J\neq i]\,\mathrm{d}\boldsymbol{H}(\boldsymbol {\mu})+\sum_{j\in[k]}\sum_{i\neq j}\int_{\Theta_{ji}}\mathbb{P}_{ \boldsymbol{\nu}(\boldsymbol{\mu})}[J\neq j]h_{i}(\mu_{j})h_{j}(\mu_{i}) \left(\prod_{s\neq i,j}h_{s}(\mu_{s})\right)\mathrm{d}\boldsymbol{\mu}\right)\] (Symmetry of the Lebesgue measure) \[=\frac{1}{2}\left(\sum_{i\in[k]}\sum_{j\neq i}\int_{\Theta_{ij}} \Big{[}\mathbb{P}_{\boldsymbol{\mu}}[J\neq i]h_{i}(\mu_{i})h_{j}(\mu_{j})+ \mathbb{P}_{\boldsymbol{\nu}(\boldsymbol{\mu})}[J\neq j]h_{i}(\mu_{j})h_{j}( \mu_{i})\Big{]}\left(\prod_{s\neq i,j}h_{s}(\mu_{s})\right)\mathrm{d} \boldsymbol{\mu}\right)\] \[\geq\sum_{i\in[k]}\sum_{j\neq i}\int_{\Theta_{ij}}\frac{\mathbb{P }_{\boldsymbol{\mu}}[J\neq i^{*}(\boldsymbol{\mu})]+\mathbb{P}_{\boldsymbol{ \nu}}[J\neq i^{*}(\boldsymbol{\nu})]}{2}\min\left(h_{i}(\mu_{i})h_{j}(\mu_{j})h _{i}(\mu_{j})h_{j}(\mu_{i})\right)\mathrm{d}\boldsymbol{\mu}\] (A.13) \[\geq\sum_{i\in[k]}\sum_{j\neq i}\int_{\Theta_{ij}}\frac{\exp\left( -n_{i}(\boldsymbol{\mu})\mathrm{KL}_{i}(\mu_{i},\mu_{j})-n_{j}(\boldsymbol{ \mu})\mathrm{KL}_{j}(\mu_{j},\mu_{i})\right)}{8}\min\left(1,\frac{h_{i}(\mu_{ j})h_{j}(\mu_{i})}{h_{i}(\mu_{i})h_{j}(\mu_{j})}\right)h_{i}(\mu_{i})h_{j}(\mu_{j}) \,\mathrm{d}\boldsymbol{\mu}\] \[\geq e^{-4}\sum_{i\in[k]}\sum_{j\neq i}\int_{\Theta_{ij}}\frac{ \exp\left(-n_{i}(\boldsymbol{\mu})\mathrm{KL}_{i}(\mu_{i},\mu_{j})-n_{j}( \boldsymbol{\mu})\mathrm{KL}_{j}(\mu_{j},\mu_{i})\right)}{8}\mathbf{1}\Bigg{[} |\mu_{i}|,|\mu_{j}|\leq\frac{1}{\sqrt{\tilde{\Delta}}}\Bigg{]}\,\mathrm{d}H( \boldsymbol{\mu}).\] (Lemma 12)

For the last inequality, we used the following lemma. The proof for this lemma is found in Subsection D.1.2.

**Lemma 12** (Ratio Lemma).: For all \(a,b\in\mathbb{R}\) which satisfy \(|a-b|\leq D_{1}(\boldsymbol{H})\) and \(|a|,|b|\leq\frac{1}{\sqrt{D_{1}(\boldsymbol{H})}}\) for some fixed \(D_{1}(\boldsymbol{H})\)8, \(\frac{h_{i}(a)h_{j}(b)}{h_{i}(b)h_{j}(a)}\geq e^{-4}\) for all \(i,j\in[k]\).

Footnote 8: \(D_{1}(\boldsymbol{H}):=\min_{i\neq j}\left[\left|\frac{m_{b}}{\sigma_{i}^{2}}- \frac{m_{j}}{\sigma_{j}^{2}}\right|^{-1},\left[\frac{1}{2\sigma_{i}^{2}}+\frac {1}{2\sigma_{j}^{2}}\right]^{-2}\right]\)

In short, we have

\[\int_{\mathbb{R}^{k}} \mathbb{P}_{\boldsymbol{\mu}}[J\neq i^{*}(\boldsymbol{\mu})]\, \mathrm{d}\boldsymbol{H}(\boldsymbol{\mu})\] \[\geq e^{-4}\sum_{i\in[k]}\sum_{j\neq i}\int_{\Theta_{ij}}\frac{ \exp\left(-n_{i}(\boldsymbol{\mu})\mathrm{KL}_{i}(\mu_{i},\mu_{j})-n_{j}( \boldsymbol{\mu})\mathrm{KL}_{j}(\mu_{j},\mu_{i})\right)}{8}\mathbf{1}\Bigg{[} |\mu_{i}|,|\mu_{j}|\leq\frac{1}{\sqrt{\tilde{\Delta}}}\Bigg{]}\,\mathrm{d}H( \boldsymbol{\mu})\] (14)and the following statement is a stronger statement than Theorem 10.

\[\text{If }\int\!\left(\sum_{i\in[k]}n_{i}(\bm{\mu})\right)\mathrm{d}\bm{H}(\bm{ \mu})\leq N_{V},\text{ then (RHS of Eq. (14))}\geq\delta.\]

RHS of Eq. (14) is represented in terms of \(n:=(n_{1},\cdots,n_{k}):\mathbb{R}^{k}\rightarrow[0,\infty)^{k}\) (the expected number of arm pulls) and does hold for any algorithm given \(n\). To prove the above statement, since'set of all expected number of arm pulls' is a subset of \(\{\tilde{n}:\mathbb{R}^{k}\rightarrow[0,\infty)\}\), it suffices to show that the optimal value \(V\) of the following objective

\[V^{\min} :=\inf_{\tilde{n}:\mathbb{R}^{k}\rightarrow[0,\infty)^{k}}\,V( \tilde{n})\] (15) \[\text{s.t.}\ \ \int_{\mathbb{R}^{k}}\left(\sum_{s=1}^{k}\tilde{n}_{s}(\bm{ \mu})\right)\mathrm{d}\bm{H}(\bm{\mu})\leq N_{V}\]

where \( V(\tilde{n}):=e^{-4}\sum_{i\in[k]}\sum_{j\neq i}\int_{\Theta_{ ij}}\dfrac{\exp\left(-\tilde{n}_{i}(\bm{\mu})\mathrm{KL}_{i}(\mu_{i},\mu_{j})- \tilde{n}_{j}(\bm{\mu})\mathrm{KL}_{j}(\mu_{j},\mu_{i})\right)}{8}\bm{1}\! \left[|\mu_{i}|,|\mu_{j}|\leq\dfrac{1}{\sqrt{\tilde{\Delta}}}\right]\mathrm{d}H (\bm{\mu})\) is greater than \(\delta\).

Let \(\tilde{\Theta}_{ij}:=\{\bm{\mu}\in\Theta_{ij}:|\mu_{i}-\mu_{j}|\leq\tilde{ \Delta},|\mu_{i}|\leq\frac{1}{\sqrt{\tilde{\Delta}}},|\mu_{j}|\leq\frac{1}{ \sqrt{\tilde{\Delta}}}\}\). Then, it holds that \(V^{\min}\geq V_{1}^{\min}\) where

\[V_{1}^{\min} :=\inf_{\tilde{n}:\mathbb{R}^{k}\rightarrow[0,\infty)^{k}}\,\,V_ {1}(\tilde{n})\] (16) \[\text{s.t.}\ \ \sum_{i\in[k]}\sum_{j\neq i}\int_{\tilde{\Theta}_{ ij}}\left(\sum_{s=1}^{k}\tilde{n}_{s}(\bm{\mu})\right)\mathrm{d}\bm{H}(\bm{\mu}) \leq N_{V}\] \[\text{where}\ \ \ V_{1}(\tilde{n}):=e^{-4}\sum_{i\in[k]}\sum_{j\neq i}\int_{ \tilde{\Theta}_{ij}}\dfrac{\exp\left(-\tilde{n}_{i}(\bm{\mu})\mathrm{KL}_{i} (\mu_{i},\mu_{j})-\tilde{n}_{j}(\bm{\mu})\mathrm{KL}_{j}(\mu_{j},\mu_{i}) \right)}{8}\,\mathrm{d}H(\bm{\mu}).\]

To see this, suppose \(\hat{n}\) is an optimal solution to (15). Then, by the constraint of optimization problem (15), \(\int_{\mathbb{R}^{k}}\!\left(\sum_{s\in[k]}\hat{n}_{s}(\bm{\mu})\right)\mathrm{ d}\bm{H}(\bm{\mu})\leq N_{V}\) and since \(\hat{n}\) is a collection of positive functions, \(\sum_{i,j\in[k]:i>j}\int_{\tilde{\Theta}_{ij}\cup\tilde{\Theta}_{ji}}\left( \sum_{s=1}^{k}\tilde{n}_{s}(\bm{\mu})\right)\mathrm{d}\bm{H}(\bm{\mu})\leq N_{V}\), which means \(\hat{n}\) satisfies the constraint of (16). By the minimality, \(V_{1}^{\min}\leq V_{1}(\hat{n})\), and since \(\exp\) is a positive function, we have \(V_{1}(\hat{n})\leq V(\hat{n})=V^{\min}\).

Moreover, \(V_{1}^{\min}\geq V_{2}^{\min}\) holds for

\[V_{2}^{\min} :=\inf_{\tilde{n}:\mathbb{R}^{k}\rightarrow[0,\infty)^{k}}\,\,V_ {2}(\tilde{n})\] (17) \[\text{s.t.}\ \ \sum_{i\in[k]}\sum_{j\neq i}\int_{\tilde{\Theta}_{ij}} \left(\sum_{s=1}^{k}\tilde{n}_{s}(\bm{\mu})\right)\mathrm{d}\bm{H}(\bm{\mu}) \leq N_{V}\] \[\text{where}\ \ \ V_{2}(\tilde{n}):=e^{-4}\sum_{i\in[k]}\sum_{j\neq i} \int_{\tilde{\Theta}_{ij}}\dfrac{\exp\left(-\Big{(}\tilde{n}_{i}(\bm{\mu})+ \tilde{n}_{j}(\bm{\mu})\Big{)}\frac{\tilde{\Delta}^{2}}{2\min(\sigma_{s}^{2})_ {s\in[k]}}\right)}{8}\,\mathrm{d}\bm{H}(\bm{\mu})\]

by using the fact that \(\mathrm{KL}_{i}(\mu_{i},\mu_{j})=\frac{\tilde{\Delta}^{2}}{2\sigma_{i}^{2}} \leq\frac{\tilde{\Delta}^{2}}{2\min(\sigma_{s}^{2})_{s\in[k]}}\).

**Claim 1**.: We abuse our notation slightly so that \(\bm{H}(E)=\int_{E}\mathrm{d}\bm{H}(\bm{\mu})\) for any Lebesgue measurable set \(E\), and let \(\tilde{\Theta}=\cup_{i,j\in[k];i\neq j}\tilde{\Theta}_{ij}\) (note that all \(\tilde{\Theta}_{ij}\) are mutually disjoint except for the measure zero sets). Then, the following \(n^{opt}\) is an optimal solutions to (17)

\[n_{s}^{opt}(\bm{\mu}):=\frac{N_{V}}{2\bm{H}(\tilde{\Theta})}\bm{1}\bigg{[}\bm {\mu}\in\left(\cup_{j\neq s}\tilde{\Theta}_{sj}\right)\cup\left(\cup_{i\neq s} \tilde{\Theta}_{is}\right)\bigg{]}.\]

Proof.: Choose an arbitrary \(\tilde{n}:\mathbb{R}^{k}\rightarrow[0,\infty)^{k}\) which satisfies the constraint of optimization problem (17). Let \(\tilde{N}(\bm{\mu}):=\sum_{s\in[k]}\tilde{n}_{s}(\bm{\mu})\). Now, since the function \(\rho:x\mapsto\frac{1}{8R}\exp(-x\cdot\frac{\tilde{\Delta}^{2}}{2\min(\sigma_{s }^{2})_{s\in[k]}})\) is a convex and decreasing function, by Jensen's inequality we can say that

\[V_{2}(\tilde{n}) =\sum_{i\in[k]}\sum_{j\neq i}\int_{\tilde{\Theta}_{ij}}\rho\bigg{(} \tilde{n}_{i}(\bm{\mu})+\tilde{n}_{j}(\bm{\mu})\Big{)}\,\mathrm{d}\bm{H}(\bm{ \mu})\] \[\geq\sum_{i\in[k]}\sum_{j\neq i}\bm{H}(\tilde{\Theta}_{ij})\rho \Bigg{(}\frac{1}{\bm{H}(\tilde{\Theta}_{ij})}\int_{\tilde{\Theta}_{ij}}\! \Big{(}\tilde{n}_{i}(\bm{\mu})+\tilde{n}_{j}(\bm{\mu})\Big{)}\,\mathrm{d}\bm{H} (\bm{\mu})\Bigg{)}\] (Jensen's inequality for each integral on \[\tilde{\Theta}_{ij}\] ) \[=\bm{H}(\tilde{\Theta})\cdot\sum_{i\in[k]}\sum_{j\neq i}\frac{\bm {H}(\tilde{\Theta}_{ij})}{\bm{H}(\tilde{\Theta})}\rho\Bigg{(}\frac{1}{\bm{H}( \tilde{\Theta}_{ij})}\int_{\tilde{\Theta}_{ij}}\!\Big{(}\tilde{n}_{i}(\bm{\mu} )+\tilde{n}_{j}(\bm{\mu})\Big{)}\,\mathrm{d}\bm{H}(\bm{\mu})\Bigg{)}\] \[\geq\bm{H}(\tilde{\Theta})\cdot\rho\Bigg{(}\sum_{i\in[k]}\sum_{j \neq i}\frac{\bm{H}(\tilde{\Theta}_{ij})}{\bm{H}(\tilde{\Theta})}\frac{1}{\bm {H}(\tilde{\Theta}_{ij})}\int_{\tilde{\Theta}_{ij}}\!\Big{(}\tilde{n}_{i}(\bm {\mu})+\tilde{n}_{j}(\bm{\mu})\Big{)}\,\mathrm{d}\bm{H}(\bm{\mu})\Bigg{)}\] (Jensen's inequality) \[\geq\bm{H}(\tilde{\Theta})\cdot\rho\Bigg{(}\sum_{i\in[k]}\sum_{j \neq i}\frac{1}{\bm{H}(\tilde{\Theta})}\int_{\tilde{\Theta}_{ij}}\!\left(\! \sum_{s\in[k]}\!\tilde{n}_{s}\right)\mathrm{d}\bm{H}(\bm{\mu})\Bigg{)}\] (\[\tilde{n}_{i}+\tilde{n}_{j}\leq\sum_{s\in[k]}\tilde{n}_{s}\] and \[\rho\] is a decreasing function.) Therefore, \[n^{opt}\] is an optimal solution of optimization problem ( 17 ). 

Using Lemma 9, we can get

\[H(\tilde{\Theta})=\sum_{i\neq j}\int_{\Theta_{ij}}\bm{1}[|\mu_{i}-\mu_{j}|\leq \tilde{\Delta}]\bm{1}[|\mu_{i}|,|\mu_{j}|\leq\frac{1}{\sqrt{\tilde{\Delta}}} ]\,\mathrm{d}\bm{H}(\bm{\mu})=L^{\prime}_{ij}(\bm{H},\tilde{\Delta}).\] (18)

Now applying Claim 1 and Eq. (18) on Optimization (17) implies the following result:

\[V_{2}^{\min} =V_{2}(n^{opt})\] (Claim 1) \[=\frac{\exp\left(-\frac{N_{V}}{2L^{\prime}(\bm{H},\tilde{\Delta}) }\frac{\tilde{\Delta}^{2}}{2\min(\sigma_{s}^{2})_{s\in[k]}}\right)}{8e^{4}} \sum_{i\neq j}\int_{\Theta_{ij}}\bm{1}[|\mu_{i}-\mu_{j}|\leq\tilde{\Delta}]\bm{ 1}[|\mu_{i}|,|\mu_{j}|\leq\frac{1}{\sqrt{\tilde{\Delta}}}]\,\mathrm{d}H(\bm{ \mu})\] (Eq. ( 18 )) \[\geq\frac{\exp\left(-\frac{N_{V}\tilde{\Delta}}{2\min(\sigma_{s} ^{2})_{s\in[k]}L^{\prime}(\bm{H},\tilde{\Delta})}\right)}{8e^{4}}\times L^{ \prime}(\bm{H},\tilde{\Delta})\tilde{\Delta}.\] (Eq. ( 18 ))

If \(V\leq\delta\) is true, then \(V_{2}\leq\delta\), which implies\[\frac{\exp\left(-\frac{N_{V}\tilde{\Delta}}{2\min(\sigma_{s}^{2})_{s\in[k]}L^{ \prime}(\bm{H},\tilde{\Delta})}\right)}{8e^{4}}\times L^{\prime}(\bm{H},\tilde{ \Delta})\leq\delta\Longleftrightarrow N_{V}\geq\frac{2\min(\sigma_{s}^{2})_{s \in[k]}L^{\prime}(\bm{H},\tilde{\Delta})}{\tilde{\Delta}}\ln\frac{L^{\prime}( \bm{H},\tilde{\Delta})}{8e^{4}\delta}.\]

To make this lower bound greater than 0, \(\ln\frac{L^{\prime}(\bm{H},\tilde{\Delta})}{8e^{4}\delta}>1\). From Lemma 9, we know that for small enough \(\tilde{\Delta}^{\text{9}}\), \(L^{\prime}(\bm{H},\tilde{\Delta})\in[\frac{1}{2}L(\bm{H}),2L(\bm{H})]\). Setting

\[\tilde{\Delta}:=\frac{32e^{4}}{L(\bm{H})}\delta,\] (19)

we have

\[N_{V}\geq\min(\sigma_{s}^{2})_{s\in[k]}\frac{L(\bm{H})^{2}}{16e^{4}}\ln 2\] (20)

which is the inequality we desired. 

### Proof of Lemmas

#### d.1.1 Proof of lemma 11

Proof.: It is equivalent to prove \(p+q\geq\frac{1}{4}\exp(-d(p,1-q^{\prime}))\) for any \(p,q,q^{\prime}\in(0,1)\) such that \(q^{\prime}\leq q\). First, if \(p\geq 1/4\) or \(q\geq 1/4\) it trivially holds, and thus we assume \(p<1/4\) and \(q<1/4\). We have

\[d(p,1-q^{\prime})d(p,1-q) (p,q\leq\frac{1}{4})\] \[\leq d(p+q,1-(p+q)) (p+q<\frac{1}{2})\] \[\leq\log\frac{1}{2.4(p+q)} \text{(Eq.(\ref{eq:1}) of Kaufmann et al. (2016a))}\]

and transforming this yields

\[p+q\geq\frac{1}{2.4}e^{-(d(p,1-q^{\prime}))}.\]

This completes the proof. 

#### d.1.2 Proof of the Lemma 12

Proof.: We have

\[\frac{h_{i}(a)h_{j}(b)}{h_{i}(b)h_{j}(a)} =\exp\Biggl{(}-\frac{(a-m_{i})^{2}}{2\sigma_{i}^{2}}+\frac{(b-m_ {i})^{2}}{2\sigma_{i}^{2}}-\frac{(b-m_{j})^{2}}{2\sigma_{j}^{2}}+\frac{(a-m_{ j})^{2}}{2\sigma_{j}^{2}}\Biggr{)}\] \[=\exp\Biggl{(}-\frac{(a-b)(a+b-2m_{i})}{2\sigma_{i}^{2}}-\frac{( b-a)(a+b-2m_{j})}{2\sigma_{j}^{2}}\Biggr{)}\] \[=\exp\Biggl{(}2(a-b)\Biggl{[}\frac{m_{i}}{\sigma_{i}^{2}}-\frac{m _{j}}{\sigma_{j}^{2}}\Biggr{]}-(a-b)(a+b)\Biggl{[}\frac{1}{2\sigma_{i}^{2}}+ \frac{1}{2\sigma_{j}^{2}}\Biggr{]}\Biggr{)}\] \[\geq\exp\Biggl{(}-2|a-b|\left|\frac{m_{i}}{\sigma_{i}^{2}}-\frac{m _{j}}{\sigma_{j}^{2}}\right|-|(a-b)(a+b)|\Biggl{[}\frac{1}{2\sigma_{i}^{2}}+ \frac{1}{2\sigma_{j}^{2}}\Biggr{]}\Biggr{)}\] \[\geq\exp\Biggl{(}-2\delta\left|\frac{m_{i}}{\sigma_{i}^{2}}-\frac {m_{j}}{\sigma_{j}^{2}}\right|-2\sqrt{\delta}\Biggl{[}\frac{1}{2\sigma_{i}^{2}} +\frac{1}{2\sigma_{j}^{2}}\Biggr{]}\Biggr{)}\frac{1}{R_{ij}^{\prime}(\bm{H}, \delta)}.\]

Define \(R^{\prime}(\bm{H},\delta)=\min_{i\neq j}R_{ij}^{\prime}(\bm{H},\delta)\) which satisfies the condition of the Ratio lemma. For \(\delta\) such that

\[\delta<D_{1}(\bm{H}):=\min_{i\neq j}\left[\left|\frac{m_{i}}{\sigma_{i}^{2}}- \frac{m_{j}}{\sigma_{j}^{2}}\right|^{-1},\left[\frac{1}{2\sigma_{i}^{2}}+\frac{ 1}{2\sigma_{j}^{2}}\right]^{-2}\right],\]we have \(R^{\prime}(\bm{H},\delta)\leq e^{4}\).

## Appendix E Proof of Theorem 6

For notational convenience, define \(\Delta_{s}(\bm{\mu}):=\mu_{i^{*}(\bm{\mu})}-\mu_{s}\) for \(s\in[k]\), \(\Delta(\bm{\mu}):=\min_{s\neq i^{*}(\bm{\mu})}\Delta_{s}=\Delta_{j^{*}(\bm{\mu})}\). Let \(\mathcal{A}(t)\) be the subset of arms that have not been eliminated at time \(t\).

Since \(\delta<\frac{4L^{2}(\bm{H})}{\sum_{i\in[k]}\frac{\mathrm{LCB}}{\mathrm{LCB}}}\), \(\Delta_{0}=\frac{\delta}{4L(\bm{H})}\leq\frac{L(\bm{H})}{\sum_{i\in[k]}\frac{ \mathrm{LCB}}{\mathrm{LCB}}}\) and we have

\[\mathbb{P}_{\bm{\mu}\sim\bm{H}}(\Delta_{0}\geq\Delta(\bm{\mu})) =\sum_{i\neq j}\int_{\Theta_{ij}}\bm{1}[|\mu_{i}-\mu_{j}|\leq \Delta_{0}|\,\mathrm{d}\bm{H}(\bm{\mu})\] \[= L(\bm{H},\Delta_{0})\Delta_{0}\leq 2L(\bm{H})\cdot\Delta_{0}\] (Lemma 9) \[\leq\frac{\delta}{2}.\] (21)

Next, we consider the upper bound estimator such that \(\hat{\Delta}^{\mathrm{safe}}(t)\geq\Delta\) holds with high probability. Namely,

\[\mathrm{UCB}(i,t),\mathrm{LCB}(i,t) =\hat{\mu}_{i}(t)\pm\mathrm{Conf}(i,t),\] \[\mathrm{Conf}(i,t) =\sqrt{2\sigma_{i}^{2}\frac{\log(6(N_{i}(t))^{2}/((\frac{\delta ^{2}}{2k})\pi^{2}))}{N_{i}(t)}},\] \[\hat{\Delta}^{\mathrm{safe}}(t) =\max_{i}\mathrm{UCB}(i,t)-\max_{j}\mathrm{LCB}(j,t).\]

From the definition above, we can calculate how many arm pulls the learner needs to narrow down the confidence width.

**Lemma 13**.: Define \(B:=320\mathrm{max}_{i\in[k]}\,\sigma_{i}^{2}\) and \(\Delta_{thr}:=\min\Bigl{(}\log\frac{4\sqrt{k}}{\delta\pi},\frac{1}{B}\Bigr{)}\). Let \(R_{0}(\Delta):=B\frac{\log\min(\Delta,\Delta_{thr})^{-1}}{\min(\Delta,\Delta_ {thr})^{2}}\). Then, for any \(\Delta\in(0,\infty)\) and for a timestep \(t\) which satisfies \(N_{i}(t)\geq R_{0}(\Delta)\), \(\mathrm{Conf}(i,t)\leq\Delta/4\).

Proof of Lemma 13.: Only for this part of the proof, let \(\Delta^{\prime}:=\min(\Delta,\Delta_{thr})\) for notational convenience. Then,

\[\mathrm{Conf}(i,t) =\sqrt{2\sigma_{i}^{2}\frac{\log(6(N_{i}(t))^{2}/((\frac{\delta^ {2}}{2k})\pi^{2}))}{N_{i}(t)}}\] \[\leq\sqrt{2\sigma_{i}^{2}\frac{\log(6R_{0}(\Delta)^{2}/(\frac{ \delta^{2}}{2k})\pi^{2}))}{R_{0}(\Delta)}}\] (assumption on \[t\] ) \[=\Delta^{\prime}\sqrt{2\sigma_{i}^{2}}\sqrt{\frac{\log(6(B\times \frac{\log(\Delta^{\prime}{}^{-1})}{\Delta^{\prime}{}^{2}})^{2}/((\frac{\delta ^{2}}{2k})\pi^{2}))}{B\times\log(\Delta^{\prime}{}^{-1})}}\] \[\leq\Delta^{\prime}\sqrt{2\sigma_{i}^{2}}\sqrt{\frac{\log(6( \frac{B}{\Delta^{\prime}{}^{3}})^{2}/((\frac{\delta^{2}}{2k})\pi^{2}))}{B \log(\Delta^{\prime}{}^{-1})}}\] \[=\Delta^{\prime}\sqrt{2\sigma_{i}^{2}}\sqrt{\frac{6\log(\Delta^{ \prime}{}^{-1})+2\log B+\log\frac{12k}{\delta^{2}\pi^{2}}}{B\log(\Delta^{ \prime}{}^{-1})}}\] \[\leq\Delta^{\prime}\sqrt{2\sigma_{i}^{2}}\sqrt{\frac{6}{B}+\frac {2}{B}+\frac{2}{B}}\] (Definition of \[\Delta_{thr}\], \[\Delta_{thr}\geq\Delta^{\prime}\] ) \[=\Delta^{\prime}\sqrt{\frac{20\sigma_{i}^{2}}{B}}\leq\frac{1}{4} \Delta^{\prime}\leq\frac{1}{4}\Delta.\]From this lemma, one could induce the following corollary which states that Algorithm 5 always terminates before a certain timestep:

**Corollary 14**.: Let \(\tau\) (and \(\gamma\)) be the stopping time (and the last iteration of the while loop in Algorithm 1, respectively) where Algorithm 1 meets the stopping condition. Then, \(\gamma\) is always bounded by \(R_{0}(\Delta_{0})\) and \(\tau\) is uniformly bounded by \(T_{0}:=k\cdot R_{0}(\Delta_{0})\).

Proof of Corollary 14.: Let us assume that \(\tau>T_{0}+1\). Then, by Lemma 13, each \(i\in\mathcal{A}_{T_{0}}\) satisfies \(\mathrm{Conf}(i,T_{0})\leq\Delta_{0}/4\). Let \(i^{ucb}(t)=\arg\max_{i\in\mathcal{A}(t)}\mathrm{UCB}(i,t)\) and \(i^{clb}(t)=\arg\max_{i\in\mathcal{A}(t)}\mathrm{LCB}(i,t)\). From definition,

\[\hat{\Delta}^{\mathrm{safe}}(T_{0}) =\max_{i\in\mathcal{A}(T_{0})}\mathrm{UCB}(i,T_{0})-\max_{i\in \mathcal{A}(T_{0})}\mathrm{LCB}(i,T_{0})\] \[=\mathrm{UCB}(i^{ucb}(T_{0}),T_{0})-\mathrm{LCB}(i^{clb}(T_{0}), T_{0})\] \[=2\mathrm{Conf}(i^{ucb}(T_{0}),T_{0})+2\mathrm{Conf}(i^{clb}(T_{0} ),T_{0})+\mathrm{LCB}(i^{ucb}(T_{0}),T_{0})-\mathrm{UCB}(i^{clb}(T_{0}),T_{0})\] \[\leq\Delta_{0}+\mathrm{LCB}(i^{ucb}(T_{0}),T_{0})-\mathrm{UCB}(i^ {clb}(T_{0}),T_{0})\] \[\leq\Delta_{0}\] (Since both arms survived from the elimination phase)

which implies \(\hat{\Delta}^{\mathrm{safe}}\leq\Delta_{0}\), contradicting \(\tau\geq T_{0}\) since the algorithm should be terminated by Line 18 at timestep \(T_{0}\). Therefore, \(\tau\leq T_{0}\). 

Lemma 14 implies Algorithm 1 always stops before \(T_{0}\) samples. Morever, the following lemma states that with high probability, true mean \(\boldsymbol{\mu}\) is in between \(\mathrm{UCB}\) and \(\mathrm{LCB}\) for all time steps.

**Lemma 15**.: (Uniform confidence bound) The following holds for all \(i\in[k]\):

\[\mathbb{P}_{\boldsymbol{\mu}}\left[\bigcap_{t=1}^{\infty}\{ \mathrm{LCB}(i,t)\leq\mu_{i}\}\right] \geq 1-\frac{\delta^{2}}{2k},\] (22) \[\mathbb{P}_{\boldsymbol{\mu}}\left[\bigcap_{t=1}^{\infty}\{\mu_{ i}\leq\mathrm{UCB}(i,t)\}\right] \geq 1-\frac{\delta^{2}}{2k}.\] (23)

Proof of Lemma 15.: The following derives the upper bound part, Eq. (23). The lower bound is derived by following the same steps.

Since each arm is independent of each other, Eq. (23) boils down to prove

\[\mathbb{P}_{\boldsymbol{\mu}}\left[\bigcap_{s=1}^{\infty}\{\mu_{i}\leq \mathrm{UCB}(i,t_{i}(s))\}\right]\geq 1-\frac{\delta^{2}}{2k},\]

where \(t_{i}(s)=\min\{t\in\mathbb{N}:N_{i}(t)\geq s\}\) and \(t_{i}(s)=\infty\) if \(\{t\in\mathbb{N}:N_{i}(t)\geq s\}=\emptyset\). For each event \(\{\mu_{i}\leq UCB_{i}(t_{i}(s))\}\), since each arm pull is independent of each other, by Hoeffding's inequality we have

\[\mathbb{P}_{\boldsymbol{\mu}}\left(\frac{1}{s}\sum_{j=1}^{s}(X_{j}^{i}-\mu_{i })\leq-\epsilon\right)\leq\exp\left(-\frac{s\epsilon^{2}}{2\sigma_{0}^{2}}\right)\]

for any \(\epsilon>0\). If we set \(\epsilon=\mathrm{Conf}(i,t_{i}(s))\), we can transform the above inequality to

\[\mathbb{P}_{\boldsymbol{\mu}}\big{(}\mathrm{UCB}(i,t_{i}(s))\leq\mu_{i}\big{)} \leq\frac{\delta^{2}}{2ks^{2}}\cdot\frac{6}{\pi^{2}}.\]

By the union bound,

\[\mathbb{P}_{\boldsymbol{\mu}}\left[\bigcap_{s=1}^{\infty}\{\mu_{i}\leq \mathrm{UCB}(i,t_{i}(s))\}\right]\geq 1-\sum_{s=1}^{\infty}\mathbb{P}_{ \boldsymbol{\mu}}\left[\mu_{i}\geq\mathrm{UCB}(i,t_{i}(s))\right]\]\[\geq 1-\sum_{s=1}^{\infty}\frac{\delta^{2}}{2ks^{2}}\cdot\frac{6}{ \pi^{2}}\] \[\geq 1-\sum_{s=1}^{\infty}\frac{\delta^{2}}{2ks^{2}}\cdot\frac{6}{ \pi^{2}}=1-\frac{\delta^{2}}{2k},\]

and the proof is completed. 

Let us define a good event based on Lemma 15 as

\[\mathcal{X}(\bm{\mu}):=\bigcap_{i\in[k]}\left[\left(\bigcap_{t=1}^{\infty} \left\{\mathrm{LCB}(i,t)\leq\mu_{i}\right\}\right)\bigcap\left(\bigcap_{t=1}^ {\infty}\left\{\mathrm{UCB}(i,t)\geq\mu_{i}\right\}\right)\right].\] (24)

We now prove that, under \(\mathcal{H}_{\bm{\mu}}\) and under this good event \(\mathcal{X}(\bm{\mu})\)

* The best arm \(i^{*}(\bm{\mu})\) is always in the active arm set \(\mathcal{A}(t)\) for all \(t\) (Lemma 16),
* Each count of the suboptimal arm pull, \(N_{i}(T_{0})\), is bounded by roughly \(O(\frac{\log\Delta_{i}}{\Delta_{i}^{2}})\) (Lemma 17).

**Lemma 16**.: Let

\[\mathcal{X}^{\prime}(\bm{\mu})=\bigcap_{t=1}^{\infty}\left\{i^{*}(\bm{\mu}) \in\mathcal{A}(t)\right\}.\]

Then, under \(\mathcal{H}_{\bm{\mu}}\), \(\mathcal{X}(\bm{\mu})\subset\mathcal{X}^{\prime}(\bm{\mu})\) and therefore

\[\mathbb{P}_{\bm{\mu}}\left[(\mathcal{X}^{\prime}(\bm{\mu}))^{c}\right]\leq \delta^{2}.\]

Proof of Lemma 16.: Suppose that event \(\mathcal{X}(\bm{\mu})\) occurs under \(\mathcal{H}_{\bm{\mu}}\). Then for all \(i\in[k]\) and for all \(t\), \(\hat{\mu}_{i}-\mathrm{Conf}(i,t)\leq\mu_{i}\) and \(\hat{\mu}_{i}+\mathrm{Conf}(i,t)\geq\mu_{i}\). Now, for any \(i\neq i^{*}\),

\[\mathrm{LCB}(i,t)-\mathrm{UCB}(i^{*},t) =\hat{\mu}_{i}-\mathrm{Conf}(i,t)-(\hat{\mu}_{i^{*}}+\mathrm{ Conf}(i^{*},t))\] \[\leq\mu_{i}+\mathrm{Conf}(i,t)-\mathrm{Conf}(i,t)-(\mu_{i^{*}}- \mathrm{Conf}(i^{*},t)+\mathrm{Conf}(i^{*},t))\] (Event \[\mathcal{X}\] occurs) \[=\mu_{i}-\mu_{i^{*}}<0\]

which means when event \(\mathcal{X}\) occurs, the optimal arm will never be dropped, and thus \(\mathcal{X}\subset\mathcal{X}^{\prime}\). By Lemma 15,

\[\mathbb{P}_{\bm{\mu}}(\mathcal{X}^{\prime}(\bm{\mu}))\geq\mathbb{P}_{\bm{\mu}} (\mathcal{X}(\bm{\mu}))\geq 1-\delta^{2}.\]

**Lemma 17**.: For any \(i\neq i^{*}\), under \(\mathcal{H}_{\bm{\mu}}\) we have

\[\left\{N_{i}(T_{0})>R_{0}\big{(}\mathrm{max}(\Delta_{i},\Delta_{0})\big{)} \right\}\subset\mathcal{X}(\bm{\mu})^{c},\] (25)

and therefore, \(\mathbb{E}_{\bm{\mu}}[N_{i}(T_{0})\mathbf{1}[\mathcal{X}(\bm{\mu})]]\leq R_{0 }\big{(}\mathrm{max}(\Delta_{i},\Delta_{0})\big{)}\).

Proof of Lemma 17.: Only for this part of the proof, let \(T_{i}:=R_{0}\big{(}\mathrm{max}(\Delta_{i},\Delta_{0})\big{)}\) for brevity.

When \(\Delta_{i}<\Delta_{0}\), \(\mathrm{max}(\Delta_{i},\Delta_{0})=\Delta_{0}\), which, combined with Corollary 14, implies that \(\left\{N_{i}(T_{0})\geq T_{i}\right\}\) always holds.

For the case of \(\Delta_{i}>\Delta_{0}\), suppose that the learner is under the events \(\mathcal{X}(\bm{\mu})\) and \(\left\{i\in\mathcal{A}(T_{i})\right\}\). Note that

\[\mathrm{Conf}(a,T_{i})\leq\frac{\Delta_{i}}{4},\quad\forall a\in\mathcal{A}(T _{i}).\]

Then,

\[\max_{a\in\mathcal{A}(T_{i})}\mathrm{LCB}_{a}(T_{i})-\mathrm{UCB}_{i}(T_{i}) \geq\mathrm{LCB}_{i^{*}}(T_{i})-\mathrm{UCB}_{i}(T_{i})\]\[=\hat{\mu}_{i^{*}}-\mathrm{Conf}_{i^{*}}(T_{i})-(\hat{\mu}_{i}+ \mathrm{Conf}_{i}(T_{i}))\] \[\geq\mu_{i^{*}}-2\mathrm{Conf}_{i^{*}}(T_{i})-(\mu_{i}+2\mathrm{Conf }_{i}(T_{i}))\] ( \[\mathcal{X}\] occurs) \[\geq\mu_{i^{*}}-\mu_{i}-\Delta_{i}=0.\]

Therefore, when \(\mathcal{X}\) occurs, \(\mu_{i}\) should be eliminated after timestep \(T_{i}\) so \(N_{i}(T_{0})\leq T_{i}\). 

Lemmas 16 and 17 guarantee the Bayesian \(\delta\)-correctness of our Algorithm 1.

**Theorem 18**.: (\(\delta\)-correctness) The Bayesian PoE of Algorithm 1 is at most \(\delta\), i.e.,

\[\int_{\mathbb{R}^{k}}\mathrm{PoE}(\bm{\mu})\,\mathrm{d}\bm{H}(\bm{\mu})\leq\delta.\] (26)

Proof of Theorem 18.: Throughout the proof, we use the following results.

* The probability that \(\mu_{i^{*}(\bm{\mu})}-\mu_{j^{*}(\bm{\mu})}\leq\Delta_{0}\) is at most \(\frac{\delta}{2}\) by Eq. (21).
* The event \(\mathcal{X}\) fails to hold with probability at most \(\delta^{2}\) by Lemma 15.
* When \(\mu_{i^{*}(\bm{\mu})}-\mu_{j^{*}(\bm{\mu})}>\Delta_{0}\) and event \(\mathcal{X}\) occurs, by Lemmas 16 and 17, all suboptimal arms will be eliminated before \(T_{j^{*}}\) and only the optimal arm will remain in the set. This means \(\mathcal{E}(\bm{\mu})\subset\mathcal{X}(\bm{\mu})\cup\{\mu_{i^{*}(\bm{\mu})} -\mu_{j^{*}(\bm{\mu})}\leq\Delta_{0}\}\).

Therefore,

\[\mathrm{PoE}(\pi;\bm{H}) =\mathbb{E}_{\bm{\mu}\sim\bm{H}}\bigg{[}\mathbb{P}\Big{(}J\neq i ^{*}(\bm{\mu})|\mathcal{H}_{\bm{\mu}}\Big{)}\bigg{]}=\mathbb{E}_{\bm{\mu} \sim\bm{H}}\Big{[}\mathbb{E}[\bm{1}(\mathcal{E}(\bm{\mu}))|\mathcal{H}_{\bm{ \mu}}]\Big{]}\] \[\leq\mathbb{E}_{\bm{\mu}\sim\bm{H}}\Big{[}\mathbb{E}[\bm{1}(\{\mu _{i^{*}(\bm{\mu})}-\mu_{j^{*}(\bm{\mu})}\leq\Delta_{0}\})+\bm{1}(\mathcal{X}( \bm{\mu}))|\mathcal{H}_{\bm{\mu}}]\Big{]}\] \[\leq\frac{\delta}{2}+\delta^{2}<\delta.\]

Finally, Lemma 19 shows the upper bound of the expected stopping time of our algorithm.

**Lemma 19**.: We have \(\mathbb{E}[\tau]\leq B_{0}\frac{L(\bm{H})^{2}}{\delta}\log\Big{(}\frac{L(\bm {H})}{\delta}\Big{)}+O(\log\delta^{-1})\).

Proof.: We have

\[\mathbb{E}[\tau] =\sum_{s=1}^{k}\mathbb{E}[N_{s}(T_{0})]=\sum_{s=1}^{k}\mathbb{E} [\mathbb{E}_{\bm{\mu}}[N_{s}(T_{0})]]\] \[=\sum_{s=1}^{k}\mathbb{E}\Big{[}\mathbb{E}_{\bm{\mu}}[N_{s}(T_{0} )\bm{1}[\mathcal{X}(\bm{\mu})]]\Big{]}+\sum_{s=1}^{k}\mathbb{E}\Big{[} \mathbb{E}_{\bm{\mu}}[N_{s}(T_{0})\bm{1}[\mathcal{X}^{c}(\bm{\mu})]]\Big{]}\] \[\leq\sum_{s=1}^{k}\mathbb{E}\Big{[}\mathbb{E}_{\bm{\mu}}[N_{s}(T_{ 0})\bm{1}[\mathcal{X}(\bm{\mu})]]\Big{]}+T_{0}\cdot\delta^{2}\] (Corollary 14 and Lemma 15)

and since \(\Delta_{0}<\Delta_{thr}\) by assumption,

\[T_{0}\cdot\delta^{2}=k\cdot R_{0}(\Delta_{0})\cdot\delta^{2}\leq kB\cdot\frac{ \log\Delta_{0}^{-1}}{\Delta_{0}^{2}}\cdot\delta^{2}.\] (27)

Therefore, it remains to compute the scale of the first term, \(\sum_{s=1}^{k}\mathbb{E}\Big{[}\mathbb{E}_{\bm{\mu}}[N_{s}(T_{0})\bm{1}[ \mathcal{X}(\bm{\mu})]\Big{]}\).

[MISSING_PAGE_FAIL:26]

\[+B\frac{\log\Delta_{0}^{-1}}{\Delta_{0}^{2}}\underbrace{\mathbb{P}(i^ {*}(\mu)=i,\mu_{i}-\mu_{s}\leq\Delta_{0})}_{(P_{is})}+B\frac{\log\Delta_{thr}^{-1 }}{\Delta_{thr}^{2}}.\]

We first deal with the term \((A)\). The following splits \((A)\) into the sum of two integrals \((A1)\) and \((A2)\):

\[(A) =\int_{\mu_{i}\in\mathbb{R}}h_{i}(\mu_{i})\!\!\left[\prod_{k\in[k] \setminus\{i,s\}}H_{k}(\mu_{i})\right]\int_{\mu_{s}=-\infty}^{\mu_{i}-\Delta_{ 0}}\frac{1}{(\mu_{i}-\mu_{s})^{2}}h_{s}(\mu_{s})\,\mathrm{d}\mu_{s}\,\mathrm{ d}\mu_{i}\] \[=\underbrace{\sum_{l=1}^{\lceil\frac{1}{2\sqrt{\Delta_{0}}}\rceil -1}\int_{\mu_{i}\in\mathbb{R}}h_{i}(\mu_{i})\!\!\left[\prod_{k\in[k]\setminus \{i,s\}}H_{k}(\mu_{i})\right]\int_{\mu_{s}=\mu_{i}-(l+1)\Delta_{0}}^{\mu_{i}-l \Delta_{0}}\frac{1}{(\mu_{i}-\mu_{s})^{2}}h_{s}(\mu_{s})\,\mathrm{d}\mu_{s}\, \mathrm{d}\mu_{i}}_{(A1)}\] \[\quad+\underbrace{\int_{\mu_{i}\in\mathbb{R}}h_{i}(\mu_{i})\!\! \left[\prod_{k\in[k]\setminus\{i,s\}}H_{k}(\mu_{i})\right]\int_{\mu_{s}=- \infty}^{\mu_{i}-\lceil\frac{1}{2\sqrt{\Delta_{0}}}\rceil\Delta_{0}}\frac{1}{ (\mu_{i}-\mu_{s})^{2}}h_{s}(\mu_{s})\,\mathrm{d}\mu_{s}\,\mathrm{d}\mu_{i}}_{( A2)}.\]

For \((A1)\), we have

\[(A1) \leq\sum_{l=1}^{\lceil\frac{1}{2\sqrt{\Delta_{0}}}\rceil-1}\int_{ \mu_{i}\in\mathbb{R}}h_{i}(\mu_{i})\!\!\left[\prod_{k\in[k]\setminus\{i,s\}}H _{k}(\mu_{i})\right]\int_{\mu_{s}=\mu_{i}-(l+1)\Delta_{0}}^{\mu_{i}-l\Delta_{ 0}}\frac{1}{l^{2}\Delta_{0}^{2}}h_{s}(\mu_{s})\,\mathrm{d}\mu_{s}\,\mathrm{d} \mu_{i}\] \[=\sum_{l=1}^{\lceil\frac{1}{2\sqrt{\Delta_{0}}}\rceil-1}\frac{1}{ l^{2}\Delta_{0}^{2}}\mathbb{P}(i^{*}(\boldsymbol{\mu})=i,\mu_{i}-\mu_{s}\in[l \Delta_{0},(l+1)\Delta_{0}])\] \[\leq\sum_{l=1}^{\lceil\frac{1}{2\Delta_{0}^{2}}\rceil-1}\frac{1}{ l^{2}\Delta_{0}^{2}}\cdot 2\mathbb{P}(i^{*}(\boldsymbol{\mu})=i,\mu_{i}-\mu_{s}\leq \Delta_{0})\] (Lemma 20) \[\leq\sum_{l=1}^{\infty}\frac{1}{l^{2}\Delta_{0}^{2}}\cdot 2P_{is}\] \[=\frac{\pi^{2}}{3\Delta_{0}^{2}}P_{is}.\] (29)

Now for \((A2)\), we evaluate the inner integral of \((A2)\):

\[(\text{Inner}-A2) :=\frac{1}{\sqrt{2\pi}\sigma_{s}}\int_{-\infty}^{\mu_{i}-\lceil \frac{1}{2\sqrt{\Delta_{0}}}\rceil\Delta_{0}}\frac{1}{(\mu_{i}-\mu_{s})^{2}} \exp\!\left(-\frac{(\mu_{s}-m_{s})^{2}}{2\sigma_{s}^{2}}\right)\mathrm{d}\mu_{s}\] \[=\frac{1}{\sqrt{2\pi}\sigma_{s}}\!\left[\frac{1}{(\mu_{i}-\mu_{s}) }\exp\!\left(-\frac{(\mu_{s}-m_{s})^{2}}{2\sigma_{s}^{2}}\right)\right]\!\! \left.\!\!\right]_{-\infty}^{\mu_{i}-\lceil\frac{1}{2\sqrt{\Delta_{0}}}\rceil \Delta_{0}}\] \[+\frac{1}{\sqrt{2\pi}\sigma_{s}}\int_{-\infty}^{\mu_{i}-\lceil \frac{1}{2\sqrt{\Delta_{0}}}\rceil\Delta_{0}}\frac{\mu_{s}-m_{s}}{\sigma_{s}^ {2}(\mu_{i}-\mu_{s})}\exp\!\left(-\frac{(\mu_{s}-m_{s})^{2}}{2\sigma_{s}^{2}} \right)\mathrm{d}\mu_{s}\] (partial integration) \[\leq\frac{1}{\sqrt{2\pi}\sigma_{s}}\frac{1}{\lceil\frac{1}{2\sqrt{ \Delta_{0}}}\rceil\Delta_{0}}+\frac{1}{\sqrt{2\pi}\sigma_{s}^{3}}\int_{-\infty}^ {\mu_{i}-\lceil\frac{1}{2\sqrt{\Delta_{0}}}\rceil\Delta_{0}}\!\left(\frac{\mu_ {i}-m_{s}}{\mu_{i}-\mu_{s}}-1\right)\exp\!\left(-\frac{(\mu_{s}-m_{s})^{2}}{2 \sigma_{s}^{2}}\right)\mathrm{d}\mu_{s}\] ( \[\mu_{i}>\mu_{s}\] )\[\leq\frac{1}{\sqrt{2\pi}\sigma_{s}}\frac{1}{\lceil\frac{1}{2\sqrt{ \Delta_{0}}}\rceil\Delta_{0}}+\frac{1}{\sqrt{2\pi}\sigma_{s}^{3}}\int_{-\infty} ^{\mu_{i}-\lceil\frac{1}{2\sqrt{\Delta_{0}}}\rceil\Delta_{0}}\frac{\mu_{i}-m_{ s}}{\frac{1}{\lceil\frac{1}{2\sqrt{\Delta_{0}}}\rceil\Delta_{0}}\exp\!\left(- \frac{(\mu_{s}-m_{s})^{2}}{2\sigma_{s}^{2}}\right)\mathrm{d}\mu_{s}\] \[\leq\frac{1}{\sqrt{2\pi}\sigma_{s}}\frac{1}{\lceil\frac{1}{2\sqrt {\Delta_{0}}}\rceil\Delta_{0}}+\max\!\left[\frac{1}{\sigma_{s}^{2}}\frac{\mu_ {i}-m_{s}}{\lceil\frac{1}{2\sqrt{\Delta_{0}}}\rceil\Delta_{0}},0\right]\!.\]

By integrating above over variable \(i\), we have

\[(A2) \leq\int_{\mathbb{R}}h_{i}(\mu_{i})\!\left[\prod_{k\in[k]\setminus \{i,s\}}\!H_{k}(\mu_{i})\right]\!\left(\frac{1}{\sqrt{2\pi}\sigma_{s}}\frac{1 }{\lceil\frac{1}{2\sqrt{\Delta_{0}}}\rceil\Delta_{0}}+\max\!\left[\frac{1}{ \sigma_{s}^{2}}\frac{\mu_{i}-m_{s}}{\lceil\frac{1}{2\sqrt{\Delta_{0}}} \rceil\Delta_{0}},0\right]\right)\mathrm{d}\mu_{i}\] \[\leq\int_{\mathbb{R}}h_{i}(\mu_{i})\!\left(\frac{1}{\sqrt{2\pi} \sigma_{s}}\frac{1}{\lceil\frac{1}{2\sqrt{\Delta_{0}}}\rceil\Delta_{0}}+\max \!\left[\frac{1}{\sigma_{s}^{2}}\frac{\mu_{i}-m_{s}}{\lceil\frac{1}{2\sqrt{ \Delta_{0}}}\rceil\Delta_{0}},0\right]\right)\mathrm{d}\mu_{i}\] ( \[=\frac{1}{\sqrt{2\pi}\sigma_{s}}\frac{1}{\lceil\frac{1}{2\sqrt{ \Delta_{0}}}\rceil\Delta_{0}}+\frac{1}{\sigma_{s}^{2}\lceil\frac{1}{2\sqrt{ \Delta_{0}}}\rceil\Delta_{0}}\!\left[\int_{\mathbb{R}}h_{i}(\mu_{i})\max\! \left[\mu_{i}-m_{s},0\right]\mathrm{d}\mu_{i}\right]\] \[\leq\frac{1}{\sqrt{2\pi}\sigma_{s}}\frac{1}{\lceil\frac{1}{2\sqrt {\Delta_{0}}}\rceil\Delta_{0}}+\frac{1}{\sigma_{s}^{2}\lceil\frac{1}{2\sqrt{ \Delta_{0}}}\rceil\Delta_{0}}\!\left[\int_{\mathbb{R}}h_{i}(\mu_{i})|\mu_{i}- m_{s}|\,\mathrm{d}\mu_{i}\right]\] \[\leq\frac{1}{\sqrt{2\pi}\sigma_{s}}\frac{1}{\lceil\frac{1}{2\sqrt {\Delta_{0}}}\rceil\Delta_{0}}+\frac{1}{\sigma_{s}^{2}\lceil\frac{1}{2\sqrt{ \Delta_{0}}}\rceil\Delta_{0}}(|m_{i}-m_{s}|+\frac{\sigma_{i}\sqrt{2}}{\sqrt{ \pi}})\] (Mean of Half normal distribution is \[\frac{\sigma_{1}\sqrt{2}}{\sqrt{\pi}}\] ) \[=\frac{1}{\lceil\frac{1}{2\sqrt{\Delta_{0}}}\rceil\Delta_{0}} \underbrace{\left[\frac{1}{\sqrt{2\pi}\sigma_{s}}+\frac{1}{\sigma_{s}^{2}}(|m_ {i}-m_{s}|+\frac{\sigma_{i}\sqrt{2}}{\sqrt{\pi}})\right]}_{S_{is}(\boldsymbol{ H})/2}\leq\frac{S_{is}(\boldsymbol{H})}{\sqrt{\Delta_{0}}}=O(\Delta_{0}^{-1/2}).\] (30)

Therefore, by Eq. (29) and Eq. (30),

\[(A)=(A1)+(A2)=\frac{1}{\Delta_{0}^{2}}\cdot\frac{\pi^{2}}{3}P_{is}+O(\Delta_{ 0}^{-1/2}),\]

and therefore

\[\int_{\mu\in\Theta_{i}}\mathcal{T}_{s}(\boldsymbol{\mu})\,\mathrm{d} \boldsymbol{H}(\boldsymbol{\mu})\leq \frac{B\log\Delta_{0}^{-1}}{\Delta_{0}^{2}}P_{is}\!\left[\frac{\pi ^{2}}{3}+1\right]+O(\Delta_{0}^{-1/2}).\] (31)

Case 2: \(s=i\)In this case, let

\[\int_{\mu\in\Theta_{s}}\mathcal{T}_{s}(\boldsymbol{\mu})\, \mathrm{d}\boldsymbol{H}(\boldsymbol{\mu}) =\sum_{j\neq s}\int_{\boldsymbol{\mu}\in\Theta_{sj}}\mathcal{T}_{s }(\boldsymbol{\mu})\,\mathrm{d}\boldsymbol{H}(\boldsymbol{\mu})\] \[\leq\sum_{j\neq s}\int_{\boldsymbol{\mu}\in\Theta_{sj}}\max_{i \neq s}(\mathcal{T}_{i}(\boldsymbol{\mu}))\,\mathrm{d}\boldsymbol{H}(\boldsymbol {\mu})\] ( \[N_{s}(t)\]  increases only when \[|\mathcal{A}_{t}|>1\], so there should be a competitor) \[\leq\sum_{j\neq s}\int_{\boldsymbol{\mu}\in\Theta_{sj}}\max_{i \neq s}\!\left[R_{0}(\Delta_{i}(\boldsymbol{\mu}),\Delta_{0})\right]\mathrm{d} \boldsymbol{H}(\boldsymbol{\mu})\] (Lemma 17) \[\leq\sum_{j\neq s}\int_{\boldsymbol{\mu}\in\Theta_{sj}}\!\left[R_{0}( \Delta_{j}(\boldsymbol{\mu}),\Delta_{0})\right]\mathrm{d}\boldsymbol{H}( \boldsymbol{\mu})\]and by the same calculation as Case 1, we obtain

\[\int_{\mu\in\Theta_{sj}}\Bigl{[}R_{0}(\Delta_{j}(\bm{\mu}),\Delta_{0})\Bigr{]}\, \mathrm{d}\bm{\mu}\leq\frac{B\log\Delta_{0}^{-1}}{\Delta_{0}^{2}}P_{sj}\biggl{[} \frac{\pi^{2}}{3}+1\biggr{]}+O(\Delta_{0}^{-1/2}),\]

and therefore

\[\int_{\mu\in\Theta_{s}}\mathcal{T}_{s}(\bm{\mu})\,\mathrm{d}\bm{H}(\bm{\mu}) \leq\frac{B\log\Delta_{0}^{-1}}{\Delta_{0}^{2}}\biggl{[}\frac{\pi^{2}}{3}+1 \biggr{]}\sum_{j\neq s}P_{sj}+O(\Delta_{0}^{-1/2}).\] (32)

For notational convenience, let \(B_{0}=B\cdot\left[\frac{\pi^{2}}{3}+1\right]\). From Eq. (28), Eq. (31), Eq. (32), we get

\[\mathbb{E}[N_{s}(T_{0})] =\mathbb{E}_{\bm{\mu}\sim\bm{H}}\Bigl{[}\mathbb{E}_{\bm{\mu}}[N_ {s}(T_{0})\bm{1}[\mathcal{X}(\bm{\mu})]]\Bigr{]}+\mathbb{E}_{\bm{\mu}\sim\bm{ H}}\Bigl{[}\mathbb{E}_{\bm{\mu}}[N_{s}(T_{0})\bm{1}[\mathcal{X}(\bm{\mu})^{c}]] \Bigr{]}\] (33) \[\leq\sum_{i=1}^{k}\int_{\mu\in\Theta_{i}}\mathcal{T}_{s}(\bm{\mu })\,\mathrm{d}\bm{H}(\bm{\mu})+\mathbb{E}_{\bm{\mu}\sim\bm{H}}\Bigl{[}\mathbb{ E}_{\bm{\mu}}[N_{s}(T_{0})\bm{1}[\mathcal{X}(\bm{\mu})^{c}]]\Bigr{]}\] (Eq. (28)) \[\leq\sum_{i\neq s}\int_{\mu\in\Theta_{i}}\mathcal{T}_{s}(\bm{\mu })\,\mathrm{d}\bm{H}(\bm{\mu})+\int_{\mu\in\Theta_{s}}\mathcal{T}_{s}(\bm{\mu })\,\mathrm{d}\bm{H}(\bm{\mu})+\mathbb{E}_{\bm{\mu}\sim\bm{H}}\Bigl{[}\mathbb{ E}_{\bm{\mu}}[N_{s}(T_{0})\bm{1}[\mathcal{X}(\bm{\mu})^{c}]]\Bigr{]}\] \[\leq\frac{B_{0}\log\Delta_{0}^{-1}}{\Delta_{0}^{2}}\Biggl{[}\sum_ {i\neq s}P_{is}+\sum_{j\neq s}P_{sj}\Biggr{]}+O(\Delta_{0}^{-1/2})+\mathbb{E}_ {\bm{\mu}\sim\bm{H}}\Bigl{[}\mathbb{E}_{\bm{\mu}}[N_{s}(T_{0})\bm{1}[ \mathcal{X}(\bm{\mu})^{c}]]\Bigr{]}\] (34) \[=\frac{B_{0}\log\Delta_{0}^{-1}}{\Delta_{0}^{2}}\Bigl{[}\mathbb{P} (i^{*}(\bm{\mu})\neq s,\mu_{i^{*}(\bm{\mu})}-\mu_{s}\leq\Delta_{0})+\mathbb{P} (i^{*}(\bm{\mu})=s,\mu_{s}-\mu_{j^{*}(\bm{\mu})}\leq\Delta_{0})\Bigr{]}\] \[+O(\Delta_{0}^{-1/2})+\mathbb{E}_{\bm{\mu}\sim\bm{H}}\Bigl{[} \mathbb{E}_{\bm{\mu}}[N_{s}(T_{0})\bm{1}[\mathcal{X}(\bm{\mu})^{c}]]\Bigr{]}.\]

Now, the total stopping time is bounded as follows:

\[\mathbb{E}[\tau] =\mathbb{E}[\sum_{s=1}^{k}N_{s}(T_{0})]\] \[=\frac{B_{0}\log\Delta_{0}^{-1}}{\Delta_{0}^{2}}\Biggl{[}\underbrace {\sum_{s=1}^{k}\mathbb{P}(i^{*}(\bm{\mu})\neq s,\mu_{i^{*}(\bm{\mu})}-\mu_{s} \leq\Delta_{0})}_{\text{Psum1}}+\underbrace{\sum_{s=1}^{k}\mathbb{P}(i^{*}( \bm{\mu})=s,\mu_{s}-\mu_{j^{*}(\bm{\mu})}\leq\Delta_{0})}_{\text{Psum2}}\Biggr{]}\] \[+O(\Delta_{0}^{-1/2})+\mathbb{E}[\tau\bm{1}[\mathcal{X}^{c}]].\] (Eq. ( 34 )

The final task we have left is bounding \((\text{Psum1})\) and \((\text{Psum2})\). Let us define \(k^{*}(\bm{\mu})\) as the third best arm in \(\bm{\mu}\). For \((\text{Psum1})\),

\[(\text{Psum1}) =\sum_{s=1}^{k}\mathbb{P}(i^{*}(\bm{\mu})\neq s,\mu_{i^{*}(\bm{\mu} )}-\mu_{s}\leq\Delta_{0})\] \[=\sum_{s=1}^{k}\mathbb{P}(j^{*}(\bm{\mu})=s,\mu_{i^{*}(\bm{\mu})} -\mu_{s}\leq\Delta_{0})+\sum_{s=1}^{k}\mathbb{P}(j^{*}(\bm{\mu})\neq s,\mu_{i^{* }(\bm{\mu})}-\mu_{s}\leq\Delta_{0})\] \[\leq\mathbb{P}(\mu_{i^{*}(\bm{\mu})}-\mu_{j^{*}(\bm{\mu})}\leq \Delta_{0})+\sum_{s=1}^{k}\mathbb{P}(\mu_{i^{*}(\bm{\mu})}-\mu_{k^{*}(\bm{\mu}) }\leq\Delta_{0})\] \[\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad \qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad \qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad \qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad \qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad \qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad \qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad \\[\leq 2k\frac{B_{0}\log\Delta_{thr}^{-1}}{\Delta_{thr}^{2}}\leq\text{Eq. \eqref{eq:24}}.\]

In summary, we obtain Eq. (37).

### Proof of Lemmas

#### e.2.1 Proof of Lemma 20

**Lemma 20**.: For \(S+1\leq\frac{1}{\sqrt{\delta}}\) and for \(\delta\leq\big{(}\xi_{i}L_{is}(\bm{H})\big{)}^{2}\), we have

\[\mathbb{P}(i^{*}(\bm{\mu})=i,\mu_{i}-\mu_{s}\in[S\delta,(S+1)\delta])\leq 2 \mathbb{P}(i^{*}(\bm{\mu})=i,\mu_{i}-\mu_{s}\leq\delta).\]

Proof.: We have

\[\int_{\Theta_{i}}\bm{1}\left[\left|\mu_{i}-\mu_{s}\right|\in[S \delta,(S+1)\delta]\right]\mathrm{d}\bm{H}(\bm{\mu}) =\int_{\Theta_{\setminus i}}\int_{\mu_{i}=\mu_{s}+S\delta}^{\mu_{ i}+(S+1)\delta}h_{i}(\mu_{i})\,\mathrm{d}\mu_{i}\,\mathrm{d}\bm{H}_{\setminus i}( \bm{\mu}_{\setminus i})\] \[\leq\int_{\Theta_{\setminus i}}\delta\bigg{[}h_{i}(\mu_{s})+ \frac{e^{-1/2}}{\xi_{i}}(S+1)\delta\bigg{]}\,\mathrm{d}\bm{H}_{\setminus i}( \bm{\mu}_{\setminus i})\] (by Lipschitz property of Gaussian, \[e^{-1/2}/\xi_{i}\] is the steepest slope of \[N(m_{i},\xi_{i}^{2})\] ) \[=\delta(\underbrace{\left[\int_{\Theta_{\setminus i}}h_{i}(\mu_{ s})\,\mathrm{d}\bm{H}(\bm{\mu}_{\setminus i})\right]}_{L_{is}(\bm{H})}+\frac{e^{-1/2}}{ \xi_{i}}(S+1)\delta)\] \[\leq(L_{is}(\bm{H})+\frac{1}{\xi_{i}}(S+1)\delta)\delta.\]

When \(S+1<\frac{1}{\sqrt{\delta}}\) and \(\sqrt{\delta}<L_{is}(\bm{H})\xi_{i}\), we have

\[\int_{\Theta_{i}}\bm{1}\left[\left|\mu_{i}-\mu_{j}\right|\in[S \delta,(S+1)\delta]\right]\mathrm{d}\bm{H}(\bm{\mu})\leq 2L_{is}(\bm{H})\delta\]

as intended. 

#### e.2.2 Proof of Lemma 21

We will show that the probability that three or more arms are \(\delta\)-close is \(O(\delta^{2})\). Namely:

**Lemma 21**.: We have \(\mathbb{P}(\mu_{i^{*}(\bm{\mu})}-\mu_{k^{*}(\bm{\mu})}\leq\Delta_{0})=O( \delta^{2})\).

Proof.: For any \(i\neq j\neq k\in[k]\), we have

\[\int\bm{1}\left[\left|\mu_{i}-\mu_{j}\right|,\left|\mu_{i}-\mu_{k }\right|\leq\delta\right]\mathrm{d}\bm{H}(\bm{\mu})\] \[=\int_{\bm{\mu}_{\setminus jk}}\int_{\mu_{j}=\mu_{i}-\delta}^{\mu _{i}+\delta}\int_{\mu_{k}=\mu_{i}-\delta}^{\mu_{i}+\delta}h_{j}(\mu_{j})h_{k} (\mu_{k})\,\mathrm{d}\mu_{k}\,\mathrm{d}\mu_{j}\,\mathrm{d}\bm{H}_{\setminus jk }(\bm{\mu}_{\setminus jk})\] \[\leq\int_{\bm{\mu}_{\setminus jk}}\int_{\mu_{j}=\mu_{i}-\delta}^ {\mu_{i}+\delta}\int_{\mu_{k}=\mu_{i}-\delta}^{\mu_{i}+\delta}\Bigg{(}h_{j}( \mu_{i})+\frac{e^{-1/2}\delta}{\xi_{j}}\Bigg{)}\bigg{(}h_{k}(\mu_{i})+\frac{e^ {-1/2}\delta}{\xi_{k}}\bigg{)}\,\mathrm{d}\mu_{k}\,\mathrm{d}\mu_{j}\,\mathrm{ d}\bm{H}_{\setminus jk}(\bm{\mu}_{\setminus jk})\] (Lipschitz property of Gaussian) \[\leq(2\delta)^{2}\underbrace{\int_{\bm{\mu}_{\setminus jk}} \Big{[}h_{j}(\mu_{i})h_{k}(\mu_{i})+O(\delta)\Big{]}\,\mathrm{d}\bm{H}_{ \setminus jk}(\bm{\mu}_{\setminus jk})}_{=:Q_{ijk}(\bm{H})}=O(\delta^{2}).\]

## Appendix F Experimental details

The code used in the experiments for this paper can be found at the following link: https://github.com/jaajang/FC_BAI_Bayes.

### Stopping condition

TTTSWe use our theoretical results stated in Section 5 for our stopping criterion. For TTTS, we use Chernoff's stopping rule, as Garivier and Kaufmann (2016); Jourdan et al. (2022) did. Here is the description of how it works: for each arm \(i,j\in[k]\), let

\[\hat{\mu}_{ij}(t):=\frac{N_{i}(t)}{N_{i}(t)+N_{j}(t)}\hat{\mu}_{i}(t)+\frac{N_{ j}(t)}{N_{i}(t)+N_{j}(t)}\hat{\mu}_{j}(t),\]

and define

\[Z_{ij}(t):=N_{i}(t)\cdot KL_{i}(\hat{\mu}_{i},\hat{\mu}_{ij})+N_{j}(t)\cdot KL _{j}(\hat{\mu}_{j},\hat{\mu}_{ij}).\]

Now the stopping time is defined as:

\[\tau_{TTTS}:=\inf\{t\in\mathbb{N}:\max_{a\in[k]}\min_{b\in[k]\setminus a}Z_{ ab}(t)\geq\beta(t,\delta)\}\]

for some threshold function \(\beta(t,\delta)\), which is defined by the following proposition of Garivier and Kaufmann (2016):

**Theorem 22** (Garivier and Kaufmann 2016, Proposition 12).: Let \(\boldsymbol{\mu}\) be an exponential family bandit model. Let \(\delta\in(0,1)\) and \(\alpha>1\). There exists a constant \(C=C(\alpha,k)\) such that whatever the sampling strategy, using Chernoff's stopping rule with the threshold

\[\beta(t,\delta)=\log\frac{Ct^{\alpha}}{\delta}\]

ensures that for all \(\boldsymbol{\mu}\), \(\mathbb{P}_{\boldsymbol{\mu}}\big{(}\tau<\infty,J\neq i^{*}(\boldsymbol{\mu}) \big{)}\leq\delta\).

In this theorem, we give an advantage to the stopping time of TTTS by setting \(\alpha=1,C=1\). Theoretically, \(C(\alpha,k)>1\) and \(C\to\infty\) as \(\alpha\to 1_{+}\), but we set the threshold smaller than the theoretical guarantee so that TTTS stops earlier.

TTUCBWe followed the stopping rule of the original paper Jourdan and Degenne (2022). Let \(\mathcal{C}_{G}(x):=\min_{\lambda\in[\frac{1}{2},1]}\frac{2\lambda-2\lambda \log(4\lambda)+\log\zeta(2\lambda)-0.5\log(1-\lambda)+x}{\lambda}\) where \(\zeta\) is a Riemann \(\zeta\) function, and

\[c(n,\delta):=2\mathcal{C}_{G}(\frac{1}{2}\log\frac{k-1}{\delta})+4\log(4+\log \frac{n}{2}).\]

Let \(\hat{i}_{t}:=\arg\max_{i\in[k]}\hat{\mu}_{i}(t)\), the empirical best arm at step \(t\). The TTUCB algorithm stops when

\[\min_{i\neq i_{t}}\frac{\hat{\mu}_{i}(t)-\hat{\mu}_{i}(t)}{\sqrt{\frac{1}{N_{ i_{t}}^{*}(t)}+\frac{1}{N_{i}(t)}}}\geq\sqrt{c(t,\delta)}.\]

When the algorithm stops sampling, the TTUCB algorithm recommends the empirical best arm as its final suggestion.

Since the computation of \(\mathcal{C}_{G}(x)\) involves optimization, it is computationally heavy when the number of samples is excessively large (as our Table 1). Instead, we approximated \(\mathcal{C}_{G}(x)\approx x+\log x\) as mentioned in Jourdan and Degenne (2022).

### NoElim algorithm

The NoElim algorithm is shown in Algorithm 2.

### Tables including computation time

For all tables in this section, Comp represents the average computation time (second).

### Additional experiment results - Multiple arms, different prior mean/variance

In Section 6, we only used \(k=2\) arms for the simulation of Table 1. We made a brief comparison between Algorithm 1 and TTUCB in \(k=10\) arm environment with a prior distribution where prior means and variances are all different.

* Number of arms \(K=10\)
* Prior means: we sample 10 random numbers from \(N(0,1)\) before the experiment starts, and set them as prior means. Here is the list of prior means: [-0.053 0.528 -0.332 -0.368 -0.273 0.909 0.418 -1.17 0.873 -0.405]
* Prior variance: we sample 10 random numbers from \(\textsf{Unif}([0.5,1.5])\) before the experiment starts, and set them as prior means. Here is the list of prior std: [0.604 1.477 1.163 0.988 0.560 0.513 0.997 1.332 0.828 0.833]
* Instance variance: we sample 10 random numbers from \(\textsf{Unif}([0.5,1.5])\) before the experiment starts, and set them as prior means. Here is the list of instance std: [1.498, 1.262, 1.485, 0.963, 1.375, 0.969, 1.357, 1.238, 1.088, 0.699]
* Number of experiments: 500

\begin{table}
\begin{tabular}{c|c c c} \hline \hline  & Avg & Max & Error & Comp. \\ \hline Alg. 1 & \(1.06\times 10^{4}\) & \(2.35\times 10^{5}\) & 1.5\% & 0.17 \\ TTTS & \(1.56\times 10^{5}\) & \(1.09\times 10^{8}\) & 0.5\% & 27.6 \\ TTUCB & \(1.95\times 10^{5}\) & \(1.13\times 10^{8}\) & 0\% & 5.07 \\ \hline \hline \end{tabular}
\end{table}
Table 6: Extended version of Table 1 with computation time.

\begin{table}
\begin{tabular}{c|c c c} \hline \hline  & Avg & Max & Error & Comp. \\ \hline Alg. 1 & \(2.69\times 10^{5}\) & \(1.66\times 10^{7}\) & 0.6\% & \(1.59\) \\ NoElim & \(1.29\times 10^{6}\) & \(8.25\times 10^{7}\) & 0\% & 5.5 \\ \hline \hline \end{tabular}
\end{table}
Table 7: Extended version of Table 2 with computation time.

* We stop additional sampling of TTUCB when its number of samples is over \(10^{8}\) because of the time constraint. This means we gave some 'advantage' on TTUCB about expected stopping time (since it makes TTUCB stop earlier than it should.)

ResultOur algorithm had the average stopping time of \(1.1\times 10^{5}\), while TTUCB had the average stopping time of \(7.1\times 10^{5}\), again proving the superiority of Algorithm 1 over TTUCB in Bayesian settings.

### Miscellaneous

Computation of \(\Delta_{0}\)From Definition 2,

\[L_{ij}(\bm{H}):=\int_{-\infty}^{\infty}h_{i}(x)h_{j}(x)\prod_{s:s\in[k] \setminus\{i,j\}}H_{s}(x)\,\mathrm{d}x.\]

In **Scipy** package, there are functions for computing the cumulative function of Gaussian \(H_{s}\) (scipy.norm.cdf) and \(h_{i}\) (scipy.norm.pdf). **Scipy** package also supports the numerical integration (scipy.integrate.quad) which we use to numerically compute \(L_{ij}\) in our experiments.

CodesThe codes are in the following GitHub repository: https://github.com/jajaang/FC_BAI_Bayes.

HardwareWe used Python 3.7 as our programming language and Macbook Pro M2 16 inch as our hardware.

## Appendix G Scale restriction on \(\delta\) for each theorem

The second result of the Lemma 9 is used for the lower bound. For this result to hold, we need the following two conditions for \(D_{1}\):

* Proof of Lemma 1, second result: For the proof of Eq. (9), we used \(|m_{i}|\leq\frac{1}{2\sqrt{\Delta}}\).
* Proof of Lemma 1, second result: For the proof of Eq. (9), we used \(\frac{1}{\xi_{i}}\Delta^{2}>2\exp\!\left(-\frac{1}{8\Delta\xi_{i}^{2}}\right)+ 2\exp\!\left(-\frac{1}{8\Delta\xi_{i}^{2}}\right)\). To satisfy this condition, \(\Delta<D_{0}(\bm{H})\) where \[D_{0}(\bm{H}):=\begin{cases}W(-\frac{1}{32\max_{i\in[k]}\xi_{i}^{3/2}})&\text {If }\max_{i\in[k]}\xi_{i}>\sqrt[3]{\frac{\pi^{2}}{2^{10}}}\\ 1&\text{Otherwise}\end{cases}.\] Here \(W\) is the Lambert W function with the principal branch.

For the lower bound proof, we consider sufficiently small \(\delta\) subject to the following constraints on \(\bar{\Delta}=\frac{32e^{\epsilon}}{L(\bm{H})}\delta\):

* Two conditions above for Lemma 9.
* For the Lemma 12: \(\tilde{\Delta}<D_{1}(\bm{H}):=\min_{i\neq j}\!\left[\left|\frac{m_{i}}{\sigma _{i}^{2}}-\frac{m_{j}}{\sigma_{j}^{2}}\right|^{-1},\left[\frac{1}{2\sigma_{i} ^{2}}+\frac{1}{2\sigma_{j}^{2}}\right]^{-2}\right]\).
* To make \(L^{\prime}(\bm{H},\tilde{\Delta})\tilde{\Delta}\in(\frac{1}{2}L(\bm{H}),2L(\bm {H}))\), \(\tilde{\Delta}\leq\frac{L(\bm{H})}{4\sum_{i\in[k]}\frac{\delta-1}{\xi_{i}}}\).

\begin{table}
\begin{tabular}{c|c c c c} \hline \hline  & Avg & Max & Error & Comp. \\ \hline Alg. 1 & \(1.1\times 10^{5}\) & \(2.58\times 10^{6}\) & 1.5\% & \(1.52\) \\ TTUCB & \(7.1\times 10^{5}\) & \(10^{8}\)(capped) & 0.1\% & \(6.22\) \\ \hline \hline \end{tabular}
\end{table}
Table 8: Multiple arms.

In summary, Theorem 1 holds for any

\[\delta\leq\delta_{L}:=\frac{L(\bm{H})}{32e^{4}}\cdot\min\Biggl{(}D_{0}(\bm{H}),D_ {1}(\bm{H}),\min_{i\in[k]}\frac{1}{4m_{i}^{2}},\frac{L(\bm{H})}{4(k-1){\sum_{i \in[k]}\frac{1}{\xi_{i}}}}\Biggr{)}.\]

For the upper bound proof (Theorem 6), we consider \(\delta\) such that \(\Delta_{0}=\frac{\delta}{4L(\bm{H})}\) satisfies the following conditions:

* \(\Delta_{0}<\frac{L(\bm{H})}{\sum_{i\in[k]}\frac{k-1}{\xi_{i}}}\) to make \(L(\bm{H},\Delta_{0})\cdot\Delta_{0}\leq 2L(\bm{H})\Delta_{0}\) by the first result of Lemma 9.
* \(\Delta_{0}\leq\min_{i,j\in[k],i\neq j}(L_{ij}\xi_{i})^{2}\) for the proof and usage of Lemma 20, and
* \(\Delta_{0}<\Delta_{thr}\).

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: We accurately present the paper's contributions and scope in the abstract and introduction. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: We present our limitations and possible future works in discussion and future works. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof?Answer: [Yes] Justification: We provide the full set of assumptions and problem settings in Section 2 and Appendix G. Additionally, we include all the proofs in the Appendix. Throughout multiple revisions, we have ensured the correctness of our proofs. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: We provide all the experimental details in Section 6 and Appendix F. Additionally, we provide our code to facilitate the reproduction of our results. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.

5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: We provide open access to the data and code with sufficient instructions. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: We specify all the experimental details in Section 6 and Appendix F. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: In Section 6 we provide average stopping time, maximum stopping time, and the ratio of misidentification to report our result statistically. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).

* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: We provide the full information on the computer resource in Appendix F. In addition, we provide the full table in Appendix F to present our time of execution. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: This research conforms with the NeurIPS Code of Ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: There is no societal impact of the work performed. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.

* Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.
* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: This work poses no such risks. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [NA] Justification: This paper does not use existing assets. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.

* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: This paper does not release new assets. Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.