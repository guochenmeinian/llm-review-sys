# Bayesian Optimisation of Functions on Graphs

Xingchen Wan, Pierre Osselin, Henry Kenlay

Binxin Ru, Michael A. Osborne, Xiaowen Dong

Department of Engineering Science, University of Oxford

{xwan,osselinp,kenlay,robin,mosb,xdong}@robots.ox.ac.uk

Equal contribution.

###### Abstract

The increasing availability of graph-structured data motivates the task of optimising over functions defined on the node set of graphs. Traditional graph search algorithms can be applied in this case, but they may be sample-inefficient and do not make use of information about the function values; on the other hand, Bayesian optimisation is a class of promising black-box solvers with superior sample efficiency, but it has scarcely been applied to such novel setups. To fill this gap, we propose a novel Bayesian optimisation framework that optimises over functions defined on generic, large-scale and potentially unknown graphs. Through the learning of suitable kernels on graphs, our framework has the advantage of adapting to the behaviour of the target function. The local modelling approach further guarantees the efficiency of our method. Extensive experiments on both synthetic and real-world graphs demonstrate the effectiveness of the proposed optimisation framework.

## 1 Introduction

Data collected in a network environment, such as transportation, financial, social, and biological networks, have become pervasive in modern data analysis and processing tasks. Mathematically, such data can be modelled as functions defined on the node set of graphs that represent the networks. This then poses a new type of optimisation problem over functions on graphs, i.e. searching for the node that possesses the most extreme value of the function. Real-world examples of such optimisation tasks are abundant. For instance, if the function measures the amount of delay at different locations in an infrastructure network, one may think about identifying network bottlenecks; if it measures the amount of influencing power users have in a social network platform, one may be interested in finding the most influential users; if it measures the time when individuals were infected in an epidemiological contact network, an important task would be to identify "patient zero" of the disease.

Optimisation of functions on graphs is challenging. Graphs are an example of discrete domains, and conventional algorithms, which are mainly designed for continuous spaces, do not apply straightforwardly. Real-world graphs are often extremely large and sometimes may not even be fully observable. Finally, the target function, such as in the examples given above, is often a black-box function that is expensive to evaluate at the node level and may exhibit complex behaviour on the graph.

Traditional methods to traverse the graph, such as breadth-first search (BFS) or depth-first search (DFS) [14], are heuristics that may be adopted in this setting for small-scale graphs, but inefficient to deal with large-scale real-world graphs and complex functions. Furthermore, these search methods only rely on the graph topology and ignore the function on the graph, which can be exploited to make the search more efficient. On the other hand, Bayesian optimisation (BO) [16] is a sample-efficient sequential optimisation technique with proven successes in various domains and is suitable for solving black-box, expensive-to-evaluate optimisation problems. However, while BO has been combined with graph-related settings, e.g. optimising for _graph structures_ (i.e. the _individual configurations_that we optimise for are graphs) in the context of neural architecture search [20; 34], graph adversarial examples [42] or molecule design [23], it has not been applied to the problem of optimising over functions on graphs (i.e. the _search space_ is a graph and the configurations we optimise for are _nodes_ in the graph). The closest attempt was COMBO [27], which is a framework designed for a specific purpose, i.e. combinatorial optimisation, where the search space is modelled as a synthetic graph restricted to one that can be expressed as a Cartesian product of subgraphs. It also assumes that the graph structure is available and that the function values are smooth in the graph space to facilitate using a diffusion kernel. All these assumptions may not hold in the case of optimisation over generic functions on real-world graphs.

We address these limitations in our work, and our main contributions are as follows: we consider the problem setting of optimising functions that are supported by the node set of a potentially generic, large-scale, and potentially unknown graph - _a setup that is by itself novel_ to the best of our knowledge in the BO literature. We then propose a novel BO framework that effectively optimises in such a problem domain with 1) appropriate kernels to handle the aforementioned graph search space derived by spectral learning on the local subgraph structure and is therefore flexible in terms of adapting to the behaviour of the target function, and 2) efficient local modelling to handle the challenges that the graphs in question can be large and/or not completely known a-priori. Finally, we deploy our method in various novel optimisation tasks on both synthetic and real-world graphs and demonstrate that it achieves very competitive results against baselines.

## 2 Preliminaries

BO is a zeroth-order (i.e. gradient-free) and sample-efficient sequential optimisation algorithm that aims to find the global optimum \(x^{*}\) of a black-box function defined over search space \(\mathcal{X}\): \(x^{*}=\arg\min_{x\in\mathcal{X}}f(x)\) (we consider a minimisation problem without loss of generality). BO uses a statistical surrogate model to approximate the objective function and an acquisition function \(\alpha(x)\) to balance exploitation and exploration under the principle of optimism in the face of uncertainty. At the \(t\)-th iteration of BO, the objective function is queried with a configuration \(x_{t}\) and returns an output \(y_{t}\), a potentially noisy estimator of the objective function \(y_{t}=\bar{f}(x_{t})+\epsilon,\epsilon\sim\mathcal{N}(0,\sigma_{n}^{2})\) where \(\sigma_{n}^{2}\) is the noise variance. The statistical surrogate is trained on the observed data up to \(t\)-th observation \(\mathcal{D}_{t}=\{(x_{i},y_{i})\}_{i=1}^{t}\) to approximate the objective function. In this work, we use a Gaussian process (GP) surrogate, which is query-efficient and gives analytic posterior mean and variance estimates on the unknown configurations. Formally, a GP is denoted as \(f(x)\sim\text{GP}\left(m\left(x\right),k\left(x,x^{\prime}\right)\right)\), where \(m\left(x\right)\) and \(k\left(x,x^{\prime}\right)\) are the mean function and the covariance function (or the _kernel_), respectively. While the mean function is often set to zero or a simple function, the covariance function encodes our belief on the property of the function we would like to model, the choice of which is a crucial design decision when using GP. The covariance function typically has some kernel hyperparameters \(\theta\) and are typically optimised by maximising the _log-marginal

Figure 1: Illustration of one iteration of _BayesOptG_ on an example graph. **(a)** At iteration \(t\), we construct a local subgraph \(\tilde{G}_{t}\) centred around \(v_{t}^{*}\) whose nodes are marked in orange-red, with darker shade denoting a shorter distance to \(v_{t}^{*}\), the best node seen so far (marked in black), and nodes outside \(\tilde{G}_{t}\) are marked in grey. The readers are referred to ยง3.2 for the details; **(b)** we place a GP surrogate with the covariance function defined in ยง3.1 on \(\tilde{G}_{t}\) and pick the maximiser of the acquisition function (the acquisition function values are marked in shades of blue, with a darker shade denoting a higher acquisition value) as the node to query for iteration \(t+1\) (\(v_{t+1}\)) (ยง3.2) and **(c)** if querying \(v_{t+1}\) leads to a better objective function value (\(f(v_{t+1})<f(v_{t}^{*})\), assuming minimisation), the neighbourhood around it is selected as the new subgraph \(\tilde{G}_{t+1}\). The process continues until convergence or a pre-set number of evaluations is reached.

likelihood_ (the readers are referred to detailed derivations in Rasmussen [31]). With \(m(\cdot)\) and \(k(\cdot,\cdot)\) defined, at iteration \(t\), with \(\mathbf{X}_{t}=[x_{1},...,x_{t}]^{\top}\) and the corresponding output vector \(\mathbf{y}_{1:t}=[y_{1},...,y_{t}]^{\top}\), a GP gives analytic posterior mean \(\mu(x_{t+1}|\mathcal{D}_{t})=\mathbf{k}(x_{t+1},\mathbf{X}_{1:t})\mathbf{K}_{1: t}^{-1}\mathbf{y}_{1:t}\) and variance \(k(x_{t+1},x_{t+1}^{\prime}|\mathcal{D}_{t})=k(x_{t+1},x_{t+1}^{\prime})- \mathbf{k}(x_{t+1},\mathbf{X}_{1:t})\mathbf{K}_{1:t}^{-1}\mathbf{k}(\mathbf{X} _{1:t},x_{t+1}^{\prime}))\) estimates on an unseen configuration \(x_{t+1}\), where \([\mathbf{K}_{1:t}]_{i,j}=k(x_{i},x_{j})\) is the \((i,j)\)-th element of the Gram matrix induced on the \((i,j)\)-th training samples by \(k(\cdot,\cdot)\), the covariance function. With the posterior mean and variance predictions, the acquisition function is optimised at each iteration to recommend the configuration (or a batch of configurations for the case of batch BO) to be evaluated for the \(t+1\)-th iteration. For additional details of BO, the readers are referred to Frazier [15].

## 3 Bayesian Optimisation on Graphs

Problem setting.Formally, we consider a novel setup with a graph \(G\) defined by \((\mathcal{V},\mathcal{E})\), where \(\mathcal{V}=\{v_{i}\}_{i=1}^{n}\) are the nodes and \(\mathcal{E}=\{e_{k}\}_{k=1}^{m}\) are the edges where each edge \(e_{k}=\{v_{i^{\prime}},v_{j^{\prime}}\}\) connects nodes \(v_{i^{\prime}}\) and \(v_{j^{\prime}}\). The topology \(G\) may be succinctly represented by an adjacency matrix \(\mathbf{A}\in\{0,1\}^{n\times n}\); in our case, \(m\) and \(n\) are potentially large, and the overall topology is not necessarily fully revealed to the search algorithm at running time. It is worth noting that, for simplicity, we focus on the setup of _undirected, unweighted_ graph where elements of \(\mathbf{A}\) are binary and symmetrical (i.e. \(A_{ij}=A_{ji}\))2. Specifically, we aim to optimise the black-box, typically expensive objective function that is defined _over the nodes_, i.e. it assigns a scalar value to each node in the graph. In other words, the search space (i.e. \(\mathcal{X}\) in SS2) in our setup is the set of nodes \(\mathcal{V}\) and the goal of the optimisation problem is to find the configuration(s) (i.e. \(x\) in SS2) that minimise the objective function \(v^{*}=\arg\min_{v\in\mathcal{V}}f(v)\).

Footnote 2: We note that it is possible to extend the proposed method to more complex cases by using the corresponding definitions of Laplacian matrix. We defer thorough analysis to future work.

Promises and challenges of BO on graphs.We argue that BO is particularly appealing under the described setup as (1) it is known to be query-efficient, making it suitable for optimising expensive functions, and (2) it is fully black-box and gradient-free; indeed, we often can only observe inputs and outputs of many real-world functions, and gradients may not even exist in a practical setup. However, there exist various challenges in our setup that make the adaptation of BO highly non-trivial, and despite the prevalence of problems that may be modelled as such and the successes of BO, it has not been extended to the optimisation of functions on graphs. Some examples of such challenges are:

1. [label=()]
2. **Exotic search space.** BO is conventionally applied in continuous Euclidean spaces, whereas we focus on discrete graph search spaces. The differences in search space imply that key notions to BO, such as the similarity between two configurations and expected smoothness of objective functions (the latter is often used as a key criterion in selecting the covariance function to use), could differ significantly. For example, while comparing the similarity between two points in a Euclidean space requires only the computation of simple distance metrics (like \(\ell_{2}\) distance), careful thinking is required to achieve the same in comparing two nodes in a graph that additionally accounts for the topological properties of the graph.
3. **Scalability.** Real-world graphs such as citation and social networks can often feature a very large number of nodes while not presenting convenient properties such as the graph Cartesian product assumption in Oh et al. [27] to accelerate computations. Therefore, it is a technical challenge to adapt BO in this setting while still retaining computational tractability.
4. **Imperfect knowledge on the graph structure.** Related to the previous point, it may also be prohibitively expensive or even impossible to obtain perfect, complete knowledge on real-world graphs beforehand or at any point during optimisation (e.g. obtaining the full contact tracing graph for epidemiology modelling); as such, any prospective method should be able to handle the situation where the graph structure is only revealed incrementally, on-the-fly.

Overview of _BayesOptG._To effectively address these challenges while retaining the desirable properties of BO, we propose to extend BO to this novel setup and are, to the best of our knowledge, the first to do so. To achieve that, we propose Bayesian Optimisation on Graphs, or _BayesOptG_ in short, and an illustration of the overall procedure is shown in Fig. 1, and an algorithmic description is available in Algorithm 1. For the rest of this section, we discuss in detail the key components of _BayesOptG_ and how the method specifically addresses the challenges identified above.

### Kernels for BO on Graphs

Kernel design.Covariance functions are crucial to GP-based BO. To use BO in our setup, a covariance function that gives a principled similarity measure between two nodes \(\{v_{i},v_{j}\}\subseteq\mathcal{V}\) is required to interpolate signals on the graph effectively. In this paper, we study several kernels, including both those proposed in the literature (e.g. the _diffusion kernel on graphs_ and the _graph Matern kernel_[4]) and two novel kernels designed by us. Following Smola & Kondor [37], all the kernels investigated can be considered in a general formulation. Formally, for a generic graph \(\tilde{G}=(\tilde{\mathcal{V}},\tilde{\mathcal{E}})\) with \(\tilde{n}\) nodes and \(\tilde{m}\) edges, we define \(\tilde{\mathbf{L}}:=\frac{1}{2}\left(\mathbf{I}-\tilde{\mathbf{D}}^{-\frac{1} {2}}\tilde{\mathbf{A}}\tilde{\mathbf{D}}^{-\frac{1}{2}}\right)\), where \(\mathbf{I}\) is the identity matrix of order \(\tilde{n}\), \(\tilde{\mathbf{A}}\) and \(\tilde{\mathbf{D}}\) are the _adjacency matrix_ and the _degree matrix_ of \(\tilde{G}\), respectively (the term after \(\frac{1}{2}\) is known as the _normalised Laplacian matrix_ with eigenvalues in the range of \([0,2]\); we scale it such that the eigenvalues are in the range of \([0,1]\)). It is worth emphasising that here we use notations with the tilde (e.g., \(\tilde{G},\tilde{n}\) and \(\tilde{m}\)) to make the distinction that this graph is, in general, different from, and is typically a subgraph of, the overall graph \(G\) discussed at the start of this section, which might be too large or not be fully available at the start of the optimisation; we defer a full discussion on this in SS3.2. We further note that \(\tilde{\mathbf{L}}=\mathbf{U}\mathbf{\Lambda}\mathbf{U}^{\top}\) with \(\mathbf{\Lambda}=\operatorname{diag}(\lambda_{1},...,\lambda_{\tilde{n}})\) and \(\mathbf{U}=[\mathbf{u}_{1},...,\mathbf{u}_{\tilde{n}}]\), where \(\{\lambda_{1},...,\lambda_{\tilde{n}}\}\) are the eigenvalues of \(\mathbf{\Lambda}\) sorted in an ascending order and \(\{\mathbf{u}_{1},...,\mathbf{u}_{\tilde{n}}\}\) are the corresponding (unit) eigenvectors.

Let \(p,q\in\{1,...,\tilde{n}\}\) be two indices over the nodes of \(\tilde{G}\), we may express our covariance function to compute the covariance between an arbitrary pair of nodes \(v_{p},v_{q}\) in terms of a _regularisation function_ of eigenvalues \(r(\lambda_{i})\,\forall\,i\in\{1,...,\tilde{n}\}\), as described in Smola & Kondor [37]:

\[k(v_{p},v_{q})=\sum_{i=1}^{\tilde{n}}r^{-1}(\lambda_{i})u_{i}[p]u_{i}[q],\] (1)

where \(u_{i}[p]\) and \(u_{i}[q]\) are the \(p\)-th and \(q\)-th elements of the \(i\)-th eigenvector \(\mathbf{u}_{i}\). The specific functional form of \(r(\lambda_{i})\) depends on the kernel choice, and the kernels considered in this work are listed in Table 1. We note that all kernels encode the smoothness of the function on the local subgraph \(\tilde{G}\). In particular, the diffusion kernel has been adopted in Oh et al. [27]; the polynomial and Matern kernels are inspired by recent work in the literature of graph signal processing [11, 46, 3]; finally, the sum-of-inverse polynomials kernel is designed as a variant of the polynomial kernel: in terms of the regularisation function, it can be interpreted as (while ignoring \(\epsilon\)) a scaled harmonic mean of the different degree components of the polynomial kernel. We next discuss the behaviours of these kernels from the perspective of kernel hyperparameters.

Kernel hyperparameters.\(\boldsymbol{\beta}:=[\beta_{0},...,\beta_{\eta-1}]^{\top}\in\mathbb{R}_{\geq 0 }^{\eta}\) (for polynomial and sum-of-inverse polynomials) or \([\beta_{1},...,\beta_{\tilde{n}}]^{\top}\in\mathbb{R}_{\geq 0}^{\tilde{n}}\) (for the diffusion kernel) define the characteristics of the kernel. We constrain \(\boldsymbol{\beta}\) in both kernels to be non-negative to ensure the positive semi-definiteness of the resulting covariance matrix and are learned jointly via GP log-marginal likelihood optimisation. The parameter \(\nu\) controls the mean-square differentiability in the classical GP literature with the Matern kernel. The polynomial and the sum-of-inverse polynomials kernels in Table 1 feature an additional hyperparameter of _kernel order_\(\eta\in\mathbb{Z}_{\geq 0}\). We set it to be \(\min\{5,\textit{diameter}\}\) where _diameter_ is thelength of the shortest path between the most distanced pair of nodes in \(\tilde{G}\) (a thorough ablation study on \(\eta\) is presented in App. D.). We argue that this allows both kernels to strike a balance between expressiveness, as all eigenvalues contained in the graphs are used in full without truncation, and regularity, as fewer kernel hyperparameters need to be learned. This is in contrast to, for example, diffusion kernels on graphs in Table 1, which typically has to learn \(\tilde{n}\) hyperparameters for a graph of size \(\tilde{n}\), whose optimisation can be prone to overfitting. To address this issue, previous works often had to resort to strong sparsity priors (e.g. horseshoe priors [6]) and approximately marginalising with Monte Carlo samplers that significantly increase the computational costs and reduce the scalability of the algorithm [27]. In contrast, by constraining the order of the polynomials to a smaller value, the resulting kernels may adapt to the behaviour of the target function and can be better regularised against overfitting in certain problems, as we will validate in SS5.

### Tractable Optimisation via Local Modelling

As discussed previously, it is a technical challenge to develop high-performing yet efficient methods in 1) large, real-world graphs (e.g. social network graphs) and 2) graphs for which it is expensive, or even impossible, to obtain complete topological information beforehand (e.g. if we model the interactions between individuals as a graph, the complete topology of the graph may only be obtained after exhaustive interviews and contact tracing with all people involved). The previous work in Oh et al. [27] cannot handle the second scenario and only addresses the first issue by assuming a certain structure of the graph (e.g. the Cartesian product of subgraphs), but these techniques are not applicable when we are dealing with a general graph \(G\).

To address the dual challenges, and inspired by trust region-based BO methods [7; 13; 43; 10; 44], we adapt and simplify the techniques to our use case: we propose to leverage _local modelling_ by focusing on a subset of nodes that evolves as the optimisation progresses. At iteration \(t\in\{1,...,T\}\), assuming the collection of our observed configurations and outputs is \(\mathcal{D}_{t}=\{v_{t^{\prime}},y_{t^{\prime}}\}_{t^{\prime}=1}^{t}\), we first find the node that leads to the best objective function so far \(v_{t}^{*}=\arg\min_{v\in\{v_{t}\}_{t^{\prime}}^{1}}\int\{v\}\). We then use Algorithm 2 to select a _neighbourhood_ around \(v_{t}^{*}\) that is a subgraph of the overall graph \(G\): \(\tilde{G}_{t}\subseteq G\) with \(Q\) number of nodes (we will discuss how to choose \(Q\) in the next paragraph), in a procedure similar to the neighbourhood sampling in the GraphSAGE framework [18] as illustrated in Fig. 2: in particular, during sampling, the closer nodes to \(v_{t}^{*}\) takes precedence over further nodes - we only sample the latter if the subgraph consisting of \(v_{t}^{*}\) and the closer nodes has fewer than \(Q\) nodes; hence the local subgraph is a form of an _ego-network_ of the central node \(v_{t}^{*}\). We then only impose the GP and compute the covariance matrix _over this subgraph only_: First, this effectively limits the computational cost - note that the time complexity in our case depends on _both_ the number of training examples \(N\) and the size of the graph \(\tilde{n}\) we impose the GP on (\(\mathcal{O}(\tilde{n}^{3}+N^{3})\)), assuming a naive eigen-decomposition algorithm. Second, it also effectively addresses the setup where the

\begin{table}
\begin{tabular}{l l l} \hline Kernel & Regularisation function \(r(\lambda_{i})\) & Kernel function \(K(\mathcal{V},\mathcal{V})\) \\ \hline Diffusion\({}^{\dagger}\)[37; 27] & \(\exp(\beta_{i}\lambda_{i})\) & \(\sum_{i=1}^{\tilde{n}}\exp(-\beta_{i}\lambda_{i})\mathbf{u}_{i}\mathbf{u}_{i} ^{\top}\) \\ Polynomial\({}^{*}\) & \(\sum_{\alpha=0}^{\eta-1}\beta_{\alpha}\lambda_{i}^{\alpha}+\epsilon\) & \(\sum_{i=1}^{\tilde{n}}\bigg{(}\sum_{\alpha=0}^{\eta-1}\beta_{\alpha}\lambda_{ i}^{\alpha}+\epsilon\bigg{)}^{-1}\mathbf{u}_{i}\mathbf{u}_{i}^{\top}\) \\ Sum-of-inverse & \(\Big{(}\sum_{\alpha=0}^{\eta-1}\frac{1}{\beta_{\alpha}\lambda_{i}^{\alpha}+ \epsilon}\Big{)}^{-1}\) & \(\sum_{i=1}^{\tilde{n}}\bigg{(}\sum_{\alpha=0}^{\eta-1}\frac{1}{\beta_{\alpha} \lambda_{i}^{\alpha}+\epsilon}\bigg{)}\mathbf{u}_{i}\mathbf{u}_{i}^{\top}\) \\ Mapram [4] & \(\Big{(}\beta\nu+\lambda_{i}\Big{)}^{\nu}\) & \(\sum_{i=1}^{\tilde{n}}\bigg{(}\beta\nu+\lambda_{i}\bigg{)}^{-\nu}\mathbf{u}_{i} \mathbf{u}_{i}^{\top}\) \\ \hline \multicolumn{3}{l}{\({}^{\dagger}\) Can be ARD or non-ARD: for ARD, \(\{\beta_{i}\}_{i=1}^{\tilde{n}}\) coefficients are learned; for non-ARD, a single, scalar \(\beta\) is learned.} \\ \multicolumn{3}{l}{\({}^{*}\{\beta_{\alpha}\}_{\alpha=0}^{\eta-1}\) coefficients to be learned. \(\epsilon\): small positive constant (e.g. \(10^{-8}\)). \(\eta\): order of kernel.} \\ \end{tabular}
\end{table}
Table 1: Kernels considered in terms of the regularisation function \(r(\lambda_{i})\). We derive the semi-definiteness of polynomial and sum-of-inverse polynomial kernels in App. A.

Figure 2: Subgraphs \(\tilde{G}_{t}\) determined by Algorithm 2, marked in red, with a darker shade denoting a closer distance to the central node \(v_{t}^{*}=\arg\min_{v\in\{v_{t}\}_{t^{\prime}=1}^{t}}f(v)\) in the figure, marked in black), for a high-degree node (**Left**) and a node far from high-degree node (**Right**). Note for the latter case, the local subgraph can include nodes that are much further away.

entire \(\tilde{G}\) is not available a-priori, as we only need to query and reveal the topological structure of the subgraph \(\tilde{G}_{t}\)_on the fly_.

```
1:Inputs: Best input up to iteration \(t\) since the last restart: \(v_{t}^{*}\), subgraph size \(Q\).
2:Output: local subgraph \(\tilde{G}_{t}\) with \(Q\) nodes.
3: Initialise: \(\tilde{\mathcal{V}}_{t}\leftarrow\{v_{t}^{*}\}\), \(h\gets 1\).
4:while\(|\tilde{\mathcal{V}}_{t}|<Q\)do
5: Find \(\mathcal{N}_{h}\), the \(h\)-hop neighbours of \(v_{t}^{*}\).
6:if\(|\tilde{\mathcal{V}}_{t}|+|\mathcal{N}_{h}|\leq Q\)then
7: Add all \(h\)-hop neighbours to \(\tilde{\mathcal{V}}_{t}\): \(\tilde{\mathcal{V}}_{t}\leftarrow\tilde{\mathcal{V}}_{t}\cup\mathcal{N}_{h}\).
8: Increment \(h\): \(h\gets h+1\)
9:else
10: Randomly sample \(Q-|\tilde{\mathcal{V}}|_{t}\) nodes from \(\mathcal{N}_{h}\) and add to \(\tilde{\mathcal{V}}_{t}\)
11:endif
12:endwhile
13:return the subgraph \(\tilde{G}_{t}\) induced by \(\tilde{\mathcal{V}}_{t}\) (i.e. the ego-network). ```

**Algorithm 2** Selecting a local subgraph

It is worth noting that while conceptually influenced by previous trust region-BO methods, the local graph construction we use differs from these methods in several crucial aspects. First, we use a bespoke distance metric in the graph space. Second, whereas the purpose of trust regions in previous works is to alleviate over-exploration in high-dimensional spaces, local subgraphs in our case also uniquely serve the crucial purpose of allowing _BayesOptG_ to handle imperfect knowledge about the graphs, as we only need to reveal the topology of the subgraph (as opposed to the entire graph) at any given iteration. Lastly, we discussed, that using trust regions also improves scalability - this can be concretely exemplified by the massive speed-up shown in Fig. 3.

**Optimisation of the acquisition function.** With the local subgraph obtained, we then fit a GP surrogate with the covariance function defined in SS3.1 and optimise log-marginal likelihood. Given that the local search space in our case is finite (of size \(Q\)), we simply enumerate all nodes _within_\(\tilde{G}_{t}\) to compute their _acquisition function_\(\operatorname{acq}(\cdot)\) values (which is computed from the predictive mean and variance of the GP surrogate) and pick the maximiser as the recommended location to query the _objective function_\(f(\cdot)\) for iteration \(t+1\) as \(v_{t+1}=\operatorname*{arg\,max}_{v\in\tilde{\mathcal{V}}_{t}}\operatorname{ acq}(v)\). Any off-the-shelf acquisition function may be used, and we adopt expected improvement (EI) [16] in our experiments. It is worth noting that _BayesOptG_ is also fully compatible with existing approaches such as Kriging believer fantasisation [17] for batch BO.

## 4 Related Work

The setup we consider is by itself novel and largely under-explored. One of the few existing methods that can be used for optimisation over a graph search space is COMBO [27], where the search space is modelled as a graph that captures the relationship between different values for a group of

Figure 3: _Trust regions enable efficient optimisation on large graphs_: Wall-clock time with and without trust regions in _BayesOptG_ with different kernels over graphs of different sizes.

categorical variables. It is, therefore, designed explicitly for combinatorial optimisation. Several studies modified COMBO in various ways but followed essentially the same framework for similar tasks, e.g., optimisation over categorical variables [12; 19; 24]. Similarly, Ramachandram et al. [30] propose a specific graph construction to optimise multimodal fusion architectures. Our work differs from these studies in that: 1) we focus on optimisation over generic, large-scale and potentially unknown graphs; 2) the nodes of the graph are not limited to combinations of values for categorical variables and can represent any entities; 3) the kernel we propose is not limited to diffusion-based ones and can adapt to the behaviour of the function to be optimised. Finally, the _graph bandit setting_ ([5; 39; 38]) can be seen to be similar to ours in the sense that it also aims at finding extreme values associated with nodes in a graph. However, the bandit problem considers a stochastic setting where nodes are influenced in a probabilistic fashion, and the objective function is actively shaped by this process; in comparison, in our case, we consider an underlying deterministic and black-box function, which is more aligned with the classical BO setting. Moreover, both Valko et al. [39] and Thaker et al. [38] require _full_ graph access and require prohibitive operation on the full graph Laplacian (decomposition/inversion), whereas _BayesOptG_ may work on-the-fly with initially unknown graphs and is much more scalable thanks to the designs in SS3.2. Several works also leverage kernels on graphs to build Gaussian processes for graph-structured data [26; 41; 40; 46; 28; 4; 29]. While the kernels proposed in these approaches can, in theory, be used in a BO framework, these studies do not address the optimisation problem we consider.

Another line of work focuses on optimisation _over graph inputs_ (in contrast to a _graph search space_) where each input configuration itself is a graph. In contrast, in our case, each input configuration is a _node_. Examples of the former include Ru et al. [34] who model neural architectures as graphs and use Weisfeiler-Lehman kernels [36] to perform BO, and Wan et al. [42], who devise a BO agent for adversarial attack on graph classification models. Other representative examples include Kandasamy et al. [20], Korovina et al. [23] and Cui et al. [8; 9]. We emphasise that, while related, these works deal with a different setup and thus require a different method compared to the present work. For example, the kernels over graphs used in these methods typically aim to find vector embedding of graphs that account for their topologies. However, once the embedding is computed, standard Euclidean covariance functions (e.g., the dot product or squared-exponential kernel) are applied. On the other hand, in the present work, we aim to compute similarities over nodes, where topological information is crucial _during_ the covariance computation itself.

## 5 Experiments

We first validate the predictive power of the GPs with the adopted kernels on graphs and then demonstrate the optimisation performance of _BayesOptG_ in both synthetic and real-world tasks. We compare _BayesOptG_ against baselines, including random and local search optimisation algorithms as

Figure 4: Validation of predictive powers of kernels considered on a BA graph of size \(n=200\) nodes and parameter \(m=1\), with **(a)** function values on the nodes corresponding to elements of the eigenvector corresponding to the second smallest eigenvalue and **(b)** same as above, but corrupted with noise standard deviation \(\sigma=0.05\). The leftmost column shows the visualisation of the ground truth, and the right columns show the GP posterior mean and standard deviation (error bars) learned by the different kernels against ground truth with Spearman correlation \(\rho\) and learned \(r^{-1}(\lambda)\) (Eq. 1).

well as BFS and DFS. The description of these baselines is given in the App. B.2. In all figures, lines, and shades denote mean and standard error, respectively, across ten trials.

### Validating Predictive Power of Kernels

We first validate the predictive power of the adopted kernels in controlled regression experiments. To do so, we generate functions that are simply the eigenvectors of the graph Laplacian and compare the predictive performance of the kernels using three graph types: 2D grid, Barabasi-Albert (BA) [1] and Watts-Strogatz (WS) [45]. We compare the performance in terms of validation error and show the results in Fig. 4 (results for other graph types are shown in App. C.1). We find that in the noiseless case, all kernels learn the underlying function effectively (except that the diffusion with ARD kernel learns a non-smooth transform on the spectrum due to its over-parameterisation, resulting in underestimations of the uncertainty in the noisy case). Still, the better-regularised kernels (described in SS3.1) are considerably more robust to noise corruption.

Figure 5: _Maximising centrality scores_ with the **BA** random graph model and \(n=1000\) nodes. Different graphs show different values of the BA hyperparameter \(m\in\{2,3,4\}\) and centrality metrics (betweenness/eigenvector centrality).

Figure 6: _Maximising centrality scores_ with the **WS** random graph model and \(n=2000\) nodes. Refer to Fig. 5 for legend and additional explanations.

Figure 7: _Synthetic test functions_ task with Ackley/Rosenbrock functions with noise standard deviation \(\sigma\in\{0.5,1\}\). Regrets shown in log-scale for Rosenbrock; refer to Fig. 5 for legend.

### Optimisation Tasks

We conduct experiments on a number of synthetic and real-life tasks that involve or imitate expensive optimisation, and we show all results in terms of _simple regret_ (i.e., the difference between the objective function value and the ground-truth optimum). We consider the following synthetic tasks:

* **Maximising centrality scores** (Fig. 5 and 6; Fig. 18 in App. C.2): we aim to find the node with maximum centrality measure, from a graph sampled from a random graph model. We consider both _eigenvector centrality_ and _betweenness centrality_ as the centrality metrics, and use BA and WS with different hyperparameters as the random graph-generating models. We consider graphs with sizes in the range of \(10^{3}\) in Fig. 5 and 6. In Fig. 18, we further scale the size of graphs considered to \(10^{6}\) nodes to demonstrate the scalability of our method in a large-scale setup.
* **Synthetic test functions** (Fig. 7): we optimise a suite of discretised versions of commonly used synthetic test functions (Ackley and Rosenbrock) on graphs defined as a 2D-grid in both noiseless and noisy setups. The readers are referred to App. B.3.2 for additional implementation details.

We consider the following real-life tasks:

* **Identifying the patient zero** (Fig. 8; Fig. 20 to 23 in App. C.3): we aim to find the "patient zero" of an epidemic in a contact network, who is to the person identified as the first carrier of a communicable disease in an epidemic outbreak. We use a real-world contact network based on Bluetooth proximity [2], and on top of simulating the epidemic process using the _SIR model_, the canonical compartmental model in epidemiology [22]. The function values are the time instants when an individual is infected; the readers are referred to App. B.4.1 for more details of this task.
* **Identifying influential users in a social network** (Fig. 9): we aim to find the most influential user in a social network. There are multiple ways of defining the influence power of a user, and for simplicity, we follow the common practice of taking _node degree_ as a proxy of influence [21]. We

Figure 8: _Identifying the patient zero_ task with different SIR model hyperparameters \(\beta\in\{0.1,0.2\}\) and \(\gamma\in\{0.015,0.15\}\) and probability of recovery \(\epsilon\) of 0. Refer to Fig. 20 โ 23 for experiments with other hyperparameter combinations.

Figure 10: _Team optimisation_ task with \(s\) (number of skills) \(\in\{2,4\}\) and \(\alpha\in\{1,10\}\) with Jaccard index threshold of 0.3 (refer to App. B.4.3 for explanations). Refer to Fig. 8 for legend and Fig. 24 โ 26 for experiments with other hyperparameter combinations.

use three real-world networks, namely the _Enron email network_[25], _Facebook page network_[33], and _Twitch social network_[32]. The readers are referred to App. B.4.2 for more details.
* **Team optimisation** (Fig. 10; Fig. 24 to 26 in App. C.4): we design a task of optimising team structure, where the objective is to find a team that contains members who are experts in different skills, and their collective expertise represents a diverse skill set. In this case, the teams are modelled as nodes, and edges represent the a priori similarity between teams. While there are various possible ways to model these similarities, in our experiment, we consider that an edge exists between two nodes if the Jaccard index between the two sets of team members is greater than a certain threshold. We include additional details and a formal description of the objective function in the App. B.4.3.

We designed these tasks to imitate expensive but realistic black-box optimisation problems on which the use of Bayesian optimisation is ideal. For example, the _identifying patient zero_ task imitates real-life contact tracing. If executed in real life, each function evaluation requires expensive and potentially disruptive procedures like interviews about the individuals' travel history and the people they were in contact with. On the other hand, the _centrality maximisation_ & _identifying influential social network users_ problems mirror common online advertising tasks to identify the influential users without access to the full social network information (which would be near-impossible to obtain given the number of users). Real-life social media often limits how much one may interact with their platform through pay-per-use APIs or hard limits (e.g. upper limit of views). In either case, there is a strong reason to identify the influential users in the most query-efficient manner.

Discussions.In addition to the task-specific results, we further aggregate the performance of the different methods over all tasks in terms of relative ranking in Fig. 11. We find that within individual tasks and aggregated across the different tasks, _BayesOptG with any kernel choice_ generally outperforms all baselines in terms of efficiency, final converged values, or both. Specifically, _Random_ is simple but typically weak for larger graphs, except for very rough/noisy functions (like Ackley), or the variation in function values is generally small; _DFS_ and _BFS_ are relatively weak as they consider graph topology information only but not the node information (on which the objective function is defined) and can be sensitive to initialisation; _Local search_ is, on balance, the strongest baseline, and it does particularly well on smoother functions with fewer local minima.

As is the case for any GP-based method, the kernel choice impacts the performance, and the performance is stronger when the underlying assumptions of the kernel match the actual objective function. For example, diffusion kernels work well for patient zero identification (Fig. 8) and team optimisation (Fig. 10), as the underlying generative functions for both problems, are indeed smooth (in fact, the SIR model in disease propagation is heavily connected to diffusion processes). Diffusion without ARD further enforces isotropy, assuming the diffusion coefficient in all directions is the same, and thus typically underperforms except for team optimisation, where the generated graph is well structured and Ackley, which is indeed isotropic and symmetric. We recommend only if we know that the underlying function satisfies its rather stringent assumptions. Finally, the SumInverse and DiffARD kernels are generally better, as they offer more flexibility in learning from the data; _we recommend using one of these as default without prior knowledge suggesting otherwise_.

## 6 Conclusion

We address the problem of optimising over functions on graphs, a hitherto under-investigated problem. We demonstrate that BO, combined with learned kernels on graphs and efficient local modelling, provides an effective solution. The proposed framework works with generic, large-scale and potentially unknown graphs, a setting that existing BO methods cannot handle. Results on a diverse range of tasks support the effectiveness of the proposed method. The current work, however, only considers the case where the optimisation is over _nodes_; possible future works include extensions to related settings, such as optimising over functions defined on _edges_ and/or on hypergraphs.

Figure 11: Aggregated ranks of the methods (lower is better) vs. the number of evaluations averaged across all experiments.

## Acknowledgement

The authors would like to acknowledge the following sources of funding in direct support of this work: X.W. is supported by the Clarendon Scholarship at University of Oxford; P.O. is supported by the EPSRC Centre for Doctoral Training in Autonomous Intelligent Machines and Systems EP/L015897/1; X.D. acknowledges support from the Oxford-Man Institute of Quantitative Finance and the EPSRC (EP/T023333/1). The authors declare no conflict of interest.

## References

* [1] Barabasi, A.-L. and Albert, R. Emergence of scaling in random networks. _science_, 286(5439):509-512, 1999.
* [2] Barrat, A., Cattuto, C., Kivela, M., Lehmann, S., and Saramaki, J. Effect of manual and digital contact tracing on covid-19 outbreaks: a study on empirical contact data. _Journal of the Royal Society Interface_, 18(178):20201000, 2021.
* [3] Borovitskiy, V., Azangulov, I., Terenin, A., Mostowsky, P., Deisenroth, M., and Durrande, N. Matern gaussian processes on graphs. In _International Conference on Artificial Intelligence and Statistics_, pp. 2593-2601. PMLR, 2021.
* [4] Borovitskiy, V., Azangulov, I., Terenin, A., Mostowsky, P., Deisenroth, M. P., and Durrande, N. Matern Gaussian processes on graphs. In _International Conference on Artificial Intelligence and Statistics_, 2021.
* [5] Carpentier, A. and Valko, M. Revealing graph bandits for maximizing local influence. In _International Conference on Artificial Intelligence and Statistics_, 2016.
* [6] Carvalho, C. M., Polson, N. G., and Scott, J. G. Handling sparsity via the horseshoe. In _Artificial Intelligence and Statistics_, pp. 73-80. PMLR, 2009.
* [7] Conn, A. R., Gould, N. I., and Toint, P. L. _Trust region methods_. SIAM, 2000.
* [8] Cui, J., Yang, B., and Hu, X. Deep bayesian optimization on attributed graphs. In _Proceedings of the AAAI Conference on Artificial Intelligence_, 2019.
* [9] Cui, J., Tan, Q., Zhang, C., and Yang, B. A novel framework of graph bayesian optimization and its applications to real-world network analysis. _Expert Systems with Applications_, 170 (114524), 2021.
* [10] Daulton, S., Eriksson, D., Balandat, M., and Bakshy, E. Multi-objective bayesian optimization over high-dimensional search spaces. In _Uncertainty in Artificial Intelligence_, pp. 507-517. PMLR, 2022.
* [11] Defferrard, M., Bresson, X., and Vandergheynst, P. Convolutional neural networks on graphs with fast localized spectral filtering. _Advances in neural information processing systems_, 29, 2016.
* [12] Deshwal, A., Belakaria, S., and Doppa, J. R. Mercer Features for Efficient Combinatorial Bayesian Optimization. In _AAAI Conference on Artificial Intelligence_, 2021.
* [13] Eriksson, D., Pearce, M., Gardner, J., Turner, R. D., and Poloczek, M. Scalable global optimization via local bayesian optimization. _Advances in neural information processing systems_, 32, 2019.
* [14] Even, S. _Graph algorithms_. Cambridge University Press, 2011.
* [15] Frazier, P. I. A tutorial on bayesian optimization. _arXiv preprint arXiv:1807.02811_, 2018.
* [16] Garnett, R. _Bayesian Optimization_. Cambridge University Press, 2023.
* [17] Ginsbourger, D., Le Riche, R., and Carraro, L. Kriging is well-suited to parallelize optimization. _Computational intelligence in expensive optimization problems_, pp. 131-162, 2010.

* [18] Hamilton, W., Ying, Z., and Leskovec, J. Inductive representation learning on large graphs. _Advances in neural information processing systems_, 30, 2017.
* [19] Imani, M. and Ghoreishi, S. F. Graph-based bayesian optimization for large-scale objective-based experimental design. _IEEE Transactions on Neural Networks and Learning Systems_, 33(10):5913-5925, 2022.
* [20] Kandasamy, K., Neiswanger, W., Schneider, J., Poczos, B., and Xing, E. P. Neural architecture search with Bayesian optimisation and optimal transport. In _Advances in Neural Information Processing Systems (NIPS)_, pp. 2016-2025, 2018.
* [21] Kempe, D., Kleinberg, J., and Tardos, E. Maximizing the spread of influence through a social network. In _Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining_, pp. 137-146, 2003.
* [22] Kermack, W. O. and McKendrick, A. G. A contribution to the mathematical theory of epidemics. _Proceedings of the royal society of london. Series A, Containing papers of a mathematical and physical character_, 115(772):700-721, 1927.
* [23] Korovina, K., Xu, S., Kandasamy, K., Neiswanger, W., Poczos, B., Schneider, J., and Xing, E. P. Chembo: Bayesian optimization of small organic molecules with synthesizable recommendations. In _Artificial Intelligence and Statistics_, 2020.
* [24] Krummenauer, J., Kammoun, N., Stein, B., and Goetze, J. Encoding categorical variables in physics-informed graphs for Bayesian Optimization. In _International Conference on Omni-layer Intelligent Systems_, 2022.
* [25] Leskovec, J., Lang, K. J., Dasgupta, A., and Mahoney, M. W. Community structure in large networks: Natural cluster sizes and the absence of large well-defined clusters. _Internet Mathematics_, 6(1):29-123, 2009.
* [26] Ng, Y. C., Colombo, N., and Silva, R. Bayesian semi-supervised learning with graph Gaussian processes. In _Conference on Neural Information Processing Systems_, 2018.
* [27] Oh, C., Tomczak, J. M., Gavves, E., and Welling, M. Combinatorial Bayesian Optimization using the Graph Cartesian Product. In _Conference on Neural Information Processing Systems_, 2019.
* [28] Opolka, F. L. and Lio, P. Graph convolutional Gaussian processes for link prediction. In _ICML Workshop on Graph Representation Learning and Beyond_, 2020.
* [29] Opolka, F. L., Zhi, Y.-C., Lio, P., and Dong, X. Adaptive gaussian processes on graphs via spectral graph wavelets. In _International Conference on Artificial Intelligence and Statistics_, 2022.
* [30] Ramachandram, D., Lisicki, M., Shields, T. J., Amer, M. R., and Taylor, G. W. Bayesian optimization on graph-structured search spaces: Optimizing deep multimodal fusion architectures. _Neurocomputing_, 298:80-89, 2018.
* [31] Rasmussen, C. E. _Gaussian processes in machine learning_. Springer, 2004.
* [32] Rozemberczki, B., Allen, C., and Sarkar, R. Multi-scale attributed node embedding, 2019.
* [33] Rozemberczki, B., Davies, R., Sarkar, R., and Sutton, C. Gemsec: Graph embedding with self clustering. In _Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2019_, pp. 65-72. ACM, 2019.
* [34] Ru, B., Wan, X., Dong, X., and Osborne, M. Interpretable neural architecture search via bayesian optimisation with weisfeiler-lehman kernels. _International Conference on Learning Representations (ICLR)_, 2021.
* [35] Sapiezynski, P., Stopczynski, A., Lassen, D. D., and Lehmann, S. Interaction data from the copenhagen networks study. _Scientific Data_, 6(1):1-10, 2019.

* [36] Shervashidze, N., Schweitzer, P., Van Leeuwen, E. J., Mehlhorn, K., and Borgwardt, K. M. Weisfeiler-lehman graph kernels. _Journal of Machine Learning Research_, 12(9), 2011.
* [37] Smola, A. J. and Kondor, R. Kernels and regularization on graphs. In _Learning theory and kernel machines_, pp. 144-158. Springer, 2003.
* [38] Thaker, P., Malu, M., Rao, N., and Dasarathy, G. Maximizing and satisficing in multi-armed bandits with graph information. _Advances in Neural Information Processing Systems_, 35:2019-2032, 2022.
* [39] Valko, M., Munos, R., Kveton, B., and Kocak, T. Spectral bandits for smooth graph functions. In _International Conference on Machine Learning_, pp. 46-54. PMLR, 2014.
* [40] Venkitaraman, A., Chatterjee, S., and Handel, P. Gaussian processes over graphs. In _IEEE International Conference on Acoustics, Speech and Signal Processing_, 2020.
* [41] Walker, I. and Glocker, B. Graph convolutional Gaussian processes. In _International Conference on Machine Learning_, 2019.
* [42] Wan, X., Kenlay, H., Ru, B., Blaas, A., Osborne, M. A., and Dong, X. Adversarial attacks on graph classifiers via bayesian optimisation. _Conference on Neural Information Processing Systems_, 2021.
* [43] Wan, X., Nguyen, V., Ha, H., Ru, B., Lu, C., and Osborne, M. A. Think global and act local: Bayesian optimisation over high-dimensional categorical and mixed search spaces. _International Conference on Machine Learning (ICML)_, 2021.
* [44] Wan, X., Lu, C., Parker-Holder, J., Ball, P. J., Nguyen, V., Ru, B., and Osborne, M. Bayesian generational population-based training. In _First Conference on Automated Machine Learning (Main Track)_, 2022.
* [45] Watts, D. J. and Strogatz, S. H. Collective dynamics of'small-world' networks. _Nature_, 393 (6684):440-442, 1998.
* [46] Zhi, Y.-C., Ng, Y. C., and Dong, X. Gaussian processes on graphs via spectral kernel learning. _IEEE Transactions on Signal and Information Processing over Networks_, 2023.

Proof of Semi-Definiteness

In this section, we show that all kernels considered in this paper are positive semi-definite (p.s.d). Specifically, we note that using the terminology defined in Eq. 1, any map \(r\rightarrow\mathbb{R}\rightarrow[0,+\infty]\) defines a valid covariance kernel. Indeed,

\[\forall\mathbf{X}\subset\mathcal{V},k(\mathbf{X},\mathbf{X})=\sum_{i=1}^{ \tilde{n}}r^{-1}(\lambda_{i})\mathbf{u}_{i}[\mathbf{X}]\mathbf{u}_{i}[ \mathbf{X}]^{\top},\] (2)

where \(\mathbf{u}_{i}[\mathbf{X}]=\left[u_{i}[x_{1}],u_{i}[x_{2}],...,u_{i}[x_{l}] \right]^{\top}\) with \(l=|\mathbf{X}|\). The matrix \(u_{i}[\mathbf{X}]u_{i}[\mathbf{X}]^{\top}\) is symmetric p.s.d as the outer product of one non-zero vector: \(\forall\mathbf{x}\in\mathbb{R}^{l},\mathbf{x}^{\top}u_{i}[\mathbf{X}]u_{i}[ \mathbf{X}]^{\top}\mathbf{x}=\|u_{i}[\mathbf{X}]^{\top}x\|_{2}^{2}\geq 0\). As a result, our covariance matrix is symmetric p.s.d as the weighted sum of symmetric positive semidefinite matrices with positive coefficients. The kernels we presented in this paper correspond to a positive \(r\); hence, they are all p.s.d.

## Appendix B Experimental Details

### Random Graph Models

**Barabasi-Albert model (BA).** The network begins with an initial connected network of \(m_{0}\) nodes. New nodes are added to the network one at a time. Each new node is connected to \(m\leq m_{0}\) existing nodes with a probability that is proportional to the number of links that the existing nodes already have. The probability \(p_{i}\) that the new node is connected to node \(i\) is:

\[p_{i}=\frac{k_{i}}{\sum_{j}k_{j}}\]

where \(k_{j}\) is the degree of node \(j\).

**Watts-Strogatz model (WS).** The WS model was introduced to explain the "small-world" phenomena in a variety of networks. It achieves this by interpolating between a randomized structure close to ER graphs and a regular ring lattice. Given a mean degree \(K\) and a parameter \(\beta\in[0,1]\). An undirected graph is constructed with \(N\) nodes and \(NK/2\) edges as follows:

1. Constructs a regular one-dimensional network with only local connections of range \(K\), meaning each node is connected to its \(K/2\) nearest neighbours on each side.
2. For every node \(i=0,...,N-1\) take every edge connecting \(i\) to its \(K/2\) rightmost neighbours. Rewire each of these edges with probability \(\beta\) to random nodes while avoiding self-loop and link duplicates.

### Baseline Algorithms

**Breadth first search (BFS) and depth-first search (DFS).** These algorithms aim to explore the whole graph data structure. It starts with a root node and explores according to the depth or breadth of the graph. In the former, the algorithm explores as far as possible along each branch before backtracking. In the latter, the algorithm explores all nodes at the present depth prior to moving on to the nodes at the next depth level.

**Random search.** In this algorithm, at each time step, a random node is selected for evaluation of our objective function.

**Local search.** In this algorithm, at each time step, we sample and query a random node from a neighbour of the node of the maximum value encountered so far, and we move to a neighbour node if the queried value is better than the incumbent best. When the algorithm reaches a local optimum (i.e., all neighbours have worse values than the current optimum), we allow our algorithm to restart at a random, unvisited node in the graph.

### Synthetic Optimisation Tasks

#### b.3.1 Maximising network centrality

Centrality measures were introduced in network analysis to study the importance of certain vertices with respect to desired characteristics. In this paper, we used two centrality measures: _betweenness_ centrality and _eigenvalue_ centrality. We show examples of these functions on sample BA/WS graphs in Fig. 12.

**Betweenness centrality.** This centrality focuses not just on overall connectedness but on the occupying positions that are pivotal to the network's connectivity. The following formula gives the betweenness of node \(v\):

\[g(v)=\sum_{\begin{subarray}{c}s,t\in\mathcal{V}\setminus\{v\}\\ s\neq t\end{subarray}}\frac{\sigma_{st}(v)}{\sigma_{st}},\]

where \(\sigma_{st}\) is the total number of shortest paths from node \(s\) to node \(t\) and \(\sigma_{st}(v)\) is the number of those paths that pass through \(v\). \(\mathcal{V}\setminus\{v\}\) denotes the set of neighbouring nodes of \(v\) except the node \(v\) itself.

**Eigenvector centrality.** This centrality measure accounts for the influence of a particular node within the network. The centrality score for the whole set of vertices, represented as a vector \(\mathbf{x}\), is a solution to the equation:

\[\mathbf{A}\mathbf{x}=\lambda\mathbf{x},\]

where the matrix \(\mathbf{A}\) represents the adjacency matrix and \(\lambda\) represents the largest eigenvalue of the adjacency matrix.

#### b.3.2 Synthetic test functions

In this subsection, we describe the Rosenbrock and Ackley test functions used for our task, both of which are discretised versions of their original, continuous function forms. The mathematical definitions of the test functions are listed below and are visualized in Fig. 13.

**Rosenbrock function**.

\[f(x,y)=100(y-x^{2})^{2}+(x-1)^{2}\]

**Ackley function**.

\[f(x,y)=-20\exp\big{(}-0.2\sqrt{0.5(x^{2}+y^{2})}\big{)}-\exp\big{(}-0.5(\cos 2 \pi x+\cos 2\pi y)\big{)}+20+\exp(1)\]

**Additive noise**. In order to alter the smoothness property of our graph signal defined over the grid, we add random noise governed by noise standard deviation \(\sigma_{n}\) to be added to the loss function \(\hat{f}(x,y)=f(x,y)+\epsilon\) with \(\epsilon\sim\mathcal{N}(0,\sigma_{n}^{2})\). In our experiment, we vary the noise standard deviation \(\sigma_{n}\in\{0,0.1,1,5\}\) for the Ackley function and \(\sigma_{n}\in\{0,0.1,0.5,1\}\) for the Rosenbrock function.

Figure 12: Betweeness/Eigenvector Centrality on BA/WS graphs.

### Real-World Optimisation Tasks

#### b.4.1 Finding patient zero in a contact network

In this task, we simulate the diffusion processes over a graph via epidemics SIR models Kermack & McKendrick [22]. We slightly modify this model to allow for a parameter \(\epsilon\) representing the probability of spontaneous infection from unknown factors.

More formally, given a graph \(\mathcal{G}=\{\mathcal{V},\mathcal{E}\}\), our model has three parameters. Parameter \(\beta\) encodes the probability of infection, \(\beta\) the probability of recovery \(\epsilon\) the probability of spontaneous infection, and \(T\) the time spent since the beginning of the outbreak. Let time \(t=1,...T\) be the current time, \(\mathbf{x}_{v,t}\in\{I,S,R\}\) the node status (Infected, Susceptible, Recovered) and \(\mathcal{S}_{I,t},\mathcal{S}_{S,t},\mathcal{S}_{R,t}\) the set of nodes in each category at time t. We have:

\[\forall v\in\mathcal{S}_{I,t},\begin{cases}\mathbb{P}[\mathbf{x}_{v,t+1}=R]= \gamma\\ \mathbb{P}[\mathbf{x}_{v,t+1}=I]=1-\gamma.\end{cases}\] (3)

\[\forall v\in\mathcal{S}_{S,t},\begin{cases}\mathbb{P}[\mathbf{x}_{v,t+1}=I]=1 -(1-\epsilon)\times(1-\beta)^{|N(v)\cap\mathcal{S}_{I,t}|}\\ \mathbb{P}[\mathbf{x}_{v,t+1}=S]=(1-\epsilon)\times(1-\beta)^{|N(v)\cap \mathcal{S}_{I,t}|}.\end{cases}\] (4)

\[\forall v\in\mathcal{S}_{R,t},\mathbb{P}[\mathbf{x}_{v,t+1}=R]=1.\] (5)

Given such a process, we construct an objective function indicating how close a certain node is to the source of the infection as follows. At time \(T\), where we consider the diffusion to have ended (or corresponding to the present moment when looking for patient zero), for every node in \(\mathcal{S}_{R,T}\cup\mathcal{S}_{I,T}\) we denote by \(\tau_{v}\) the first time of infection. The objective function is then defined as:

\[\forall v\in\mathcal{V},f(v)=\begin{cases}0&\text{if }v\in\mathcal{S}_{S,T}\\ (1-\frac{\tau_{v}}{T})^{2}&\text{if }v\in\mathcal{S}_{I,T}\cup\mathcal{S}_{R,T} \end{cases}\] (6)

This function takes value in \([0,1]\) and is maximised when the node corresponds to the patient zero. We expect local methods to perform well in this setting as local behaviour can trace the source of the infection through diffusion, and the variation of the functions on the graph is relatively smooth. The introduction of parameter \(\epsilon\) nevertheless adds some sources of "local" minima in the graph objective function - we show some examples of such phenomenon in Fig. 14, where we give exemplary graph signals induced by the generative process we described in this section.

Figure 14: Simulation of the SIR process on BA/WS graphs. It is worth noting that some local optima are visible due to the \(\epsilon\) parameter.

Figure 13: Test function values taken on a regular graph corresponding to the input space: Rosenbrock (**left**); Ackley (**right**).

#### b.4.2 Finding influential users in a social network

In this task, we consider a common problem in identifying the most influential person within a social network. Influence, in this context, is often quantified approximately using degree centrality, which may account for, for example, the number of followers or connections an individual possesses. However, the enormity of social network graphs often restricts our access to complete graph information, necessitating alternative search approaches. To validate our methodology, we conduct tests on various real-world graphs derived from diverse social networks. These include the Enron email network, which represents email communication between members of a corporation; the Facebook page network, which is a network of interconnected Facebook pages; and the Twitch social network, which provides insight into the relationships among users on the Twitch platform.

#### b.4.3 Team optimisation

In this task, we aim to tackle the problem of optimising the performance of a team of individuals with different skills. We will assume that a team would perform most effectively when 1) all skills are covered by combining individual skills and 2) some individuals master every skill. More formally, we will consider a pool of \(N\) individuals. Each individual can be represented by a vector of skills \(\mathbf{x}_{i}\in[0,1]^{K}\) where \(K\) is the number of skills. This setup fits our framework well in the scenario where the skills of individuals are unknown, and the pool of potential candidates is also unknown in advance. A sample graph generated from this problem is shown in Fig. 15.

Skill generative process.In each experiment, we will assume individual skills to be generated according to a Dirichlet distribution with parameter \(\alpha\):

\[\mathbf{x}_{i}\sim\mathrm{Dir}(\boldsymbol{\alpha}),\boldsymbol{\alpha}=[ \alpha_{1},...,\alpha_{D}]^{\top}\]

The parameter \(\alpha\) encodes the sparsity of skill expertise in the general population. Small \(\alpha\) generates individuals with specialised skills with more probability than large \(\alpha\) where all skill levels concentrate to a score of \(0.5\).

Graph construction.To solve this task and allow flexible exploration of teams with a varying number of individuals, we construct a graph where nodes represent teams and edges are based on the Jaccard index between each pair of team member sets. More specifically, given two teams \(s_{1}\subset\mathbb{N}\) and \(s_{2}\subset\mathbb{N}\) the similarity between them is computed as \(w(s_{1},s_{2})=\frac{s_{1}\cap s_{2}}{s_{1}\cup s_{2}}\). Given \(N\) teams, we can then construct an undirected graph with edges:

\[\forall s_{1},s_{2}\subset[N],(s_{1},s_{2})\in\mathcal{E}\iff w(s_{1},s_{2})> \text{Median}(\{w(s_{1},s_{2}):s_{1},s_{2}\subset[N]\})\]

Objective function.To model the two desirable properties in terms of team composition, we choose the following objective function:

\[\forall s\subset[N]:f(s)=H_{k}[\mathbb{E}_{n}[\mathbf{x}]]-\mathbb{E}_{n}[H_{ k}[\mathbf{x}]]\]

Intuitively, the first term of the objective corresponds to the entropy of the skill distribution of the whole team, which is maximised when the skill distribution is close to the uniform distribution. The second term corresponds to the expected entropy of the distribution of skills of each individual, which is minimised (and the objective maximised) when each individual specialises in one skill. As a result, we can expect this objective to be well suited for modelling an ideal composition of a team.

## Appendix C Additional Experiments

### Kernel Validation

Complementary to Fig. 4 in the main text, we conduct further regression analyses to confirm the expressive power of the investigated kernels. The results are shown in Fig. 16 and Fig. 17.

Figure 15: An exemplary graph induced from the team optimisation problem.

### Centrality Maximisation on Large Graphs

In this section, we consider a similar problem of centrality maximisation as described in App. B.3.1, but on significantly larger graphs: we use BA and WS random graph generators similar to the experiments in Fig. 5 and Fig. 6 in the main text, but we generate graphs with \(10^{6}\) nodes instead and increase the query budget. We show the results in Fig. 18, and we find that the superiority of _BayesOptG_ methods persists in this setting over the baseline methods.

### Finding Patient Zero Task in Real-World Graphs

**Setup.** In this section, we consider several SIR diffusion problems as described in App. B.4.1 where we aim to find the patient zero on a real-world interaction network from the Copenhagen Networks Study [35]. This network represents physical proximity among participants (estimated via Bluetooth signal strength) in a population of more than 700 university students and thus is a good testbed to examine the diffusion process of a hypothetical epidemic outbreak. The visualization of the function on this graph is given by Fig. 19.

Figure 16: Expressiveness of kernels on a grid graph of size \(n=200\) nodes. Refer to Fig. 4 for more explanations.

Figure 17: Expressiveness of kernels on a WS graph of size \(n=200\) nodes. Refer to Fig. 4 for more explanations.

**Results.** The performance of each algorithm is presented in Fig. 20 - 23 where we use different values of initially infected population fraction and probability of recovery - it is clear that due to the increased complexity as revealed in Fig. 19, there is some performance degradation in all algorithms considered. However, we can see that in most cases, our method performs at least as well as the local search baseline.

### Team Optimisation

We show additional results for the team optimisation tasks in Fig. 24 to 26. We can observe that the key findings from the main text on this problem (Fig. 10) largely hold true for these tasks induced by different parameters.

## Appendix D Ablation and Sensitivity Studies

In this section, we perform a thorough ablation and sensitivity study on how much the additionally introduced hyperparameters affect the algorithm's performance. We report sensitivity analyses to the most important hyperparameters below, namely \(Q_{0}\) (initial trust region size), fail_tol, \(\eta\)

Figure 19: Diffusion objective function on the real-world interaction network.

Figure 18: _Maximising centrality scores_ with the **BA/WS** random graph model and \(n=10^{6}\) nodes.

(order of the kernels) and \(\gamma\) (the trust region multiplier in case of successive successes or failures). We also additionally study the effect of introducing the trust region in this section. We perform ablation experiments in the setting with BA graphs and synthetic function optimization. We show the sensitivity analysis in Fig. 27 to 29 - it is evident that our algorithm is largely robust to the choice of hyperparameters as long as a value within a sensible range is chosen.

Use of trust regions.We compared, on some relatively small graphs (1000 nodes) in Fig. 31 - as observed, while there is a small drop in performance because of the use of local modelling compared to constructing a surrogate model on the whole graph, it is worth noting that, as shown in Fig. 3 in the main text, the full Bayesian optimisation procedure with kernels defined on the whole graph becomes too prohibitive, even for a relatively small graph of size \(1000\), and that when the graph is unknown, it is impossible in the first place to construct a whole-graph GP. This verifies that the trust region strikes a promising balance between efficiency and performance.

Figure 20: _Identifying the patient zero_ task with different SIR model hyperparameters \(\beta\in\{0.1,0.2,0.3\}\) and \(\gamma\in\{0.005,0.015,0.15\}\). A fraction of \(\mathbf{0.0003}\) of the initial population was infected initially. The probability of recovery \(\epsilon\) is set to \(\mathbf{0}\).

Figure 21: _Identifying the patient zero_ task with different SIR model hyperparameters \(\beta\in\{0.1,0.2,0.3\}\) and \(\gamma\in\{0.005,0.015,0.15\}\). A fraction of **0.0003** of the initial population was infected initially. The probability of recovery \(\epsilon\) is set to **0.005**.

Figure 22: _Identifying the patient zero_ task with different SIR model hyperparameters \(\beta\in\{0.1,0.2,0.3\}\) and \(\gamma\in\{0.005,0.015,0.15\}\). A fraction of **0.003** of the initial population was infected initially. The probability of recovery \(\epsilon\) is set to **0**.

Figure 23: _Identifying the patient zero_ task with different SIR model hyperparameters \(\beta\in\{0.1,0.2,0.3\}\) and \(\gamma\in\{0.005,0.015,0.15\}\). A fraction of **0.003** of the initial population was infected initially. The probability of recovery \(\epsilon\) is set to **0.005**.

Figure 24: _Team optimisation_ task with \(s\in\{2,4\}\) and \(\alpha\in\{1,10\}\) with Jaccard index threshold of \(\mathbf{0.1}\) (refer to App. B.4.3 for explanations)

Figure 25: _Team optimisation_ task with \(s\in\{2,4\}\) and \(\alpha\in\{1,10\}\) with Jaccard index threshold of \(\mathbf{0.2}\) (refer to App. B.4.3 for explanations)

Figure 26: _Team optimisation_ task with \(s\in\{2,4\}\) and \(\alpha\in\{1,10\}\) with Jaccard index threshold of **0.3** (refer to App. B.4.3 for explanations)

Figure 27: Sensitivity of performance to \(Q_{0}\) on different tasks and kernels. From left to right: Centrality maximisation on Enron, Facebook and Twitch networks. Kernels from top to bottom: polynomial, sum-of-inverse polynomials, diffusion (with ARD), diffusion (without ARD), and graph Matรฉrn.

Figure 28: Sensitivity of performance to fail_tol on different tasks and kernels. Refer to Fig. 27 for additional explanations.

Figure 30: Sensitivity of performance to \(\eta\) on different tasks and kernels. Refer to Fig. 27 for additional explanations. Note that only Polynomial and Sum-of-inverse-polynomial kernels requiring non-trivial \(\eta\) selection are included.

Figure 29: Sensitivity of performance to \(\gamma\) on different tasks and kernels. Refer to Fig. 27 for additional explanations.

[MISSING_PAGE_EMPTY:29]