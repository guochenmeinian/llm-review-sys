# On Representation of Natural Image Patches

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

To optimize survival, organisms need to accurately and efficiently relay new information throughout their systems for processing and responses. Furthermore, they benefit from predicting environmental occurrences, or in mathematical terms, understanding the probability distribution of their environment, based on both personal experiences and inherited evolutionary memory. These twin objectives of information transmission and learning environmental probabilistic distributions form the core of an organism's information processing system. While the early vision neuroscience field has primarily focused on the former, employing information theory as a guiding framework [3; 32; 19; 1; 9; 28], the latter is largely explored by the machine learning community via probabilistic generative models. However, the relationship between these two objectives has not been thoroughly investigated. In this paper, we study a biologically inspired information processing model and prove that these two objectives can be achieved independently. By evenly partitioning the input space to model input probability, our model bypasses the often intractable normalization factor computation. When applied to image patches, this model produces a sparse, nonlinear binary population code similar to early visual systems, with features like edge-detection and orientation-selective units. Our results not only offer potential new insights into the functioning of neurons in early vision systems, but also present a novel approach to represent natural image patches.

## 1 Introduction

Nature, through billions of years of evolution, has likely developed optimal methods for processing visual information within the constraints of biological feasibility. However, attempting to precisely emulate every detail of these biological systems [30; 21] in order to construct an optimal visual information processing model presents significant complexities, especially without a comprehensive understanding of the underlying principles.

In parallel, deep learning models, particularly Convolutional Neural Networks (CNNs), have demonstrated exceptional performance in various computer vision tasks, such as image classification, object detection, and semantic segmentation. Despite their success, these models still fall short of biological vision systems in several key areas such as the ability to generalize from limited data, robustness to variations, 3D understanding, and processing speed and efficiency.

Moreover, deep learning models pose several unresolved challenges. Firstly, their decision-making processes are often opaque, leading to the "black box" label. Secondly, deep learning architectures typically involve numerous layers without explicit functions associated with each layer [12; 8], unlike the biological brain where each stage of visual processing has a distinct role and purpose [7]. Lastly,hesequence of information processing in deep learning models is largely dictated by their architectural structure. It is still a question how to ascertain when one processing stage is finished and when it's appropriate to pass information to the next layer.

Drawing inspiration from biological systems and prior studies [19; 1; 9; 28], and with a view to find an alternative approach to the current deep learning framework, this paper aims to explore the fundamentals of the first stage of an optimal visual information processing system. This exploration is undertaken incrementally, starting from a single pixel, and progressively advancing to image patches.

## 2 One Pixel

We begin with the simplest conceivable case, where the input to the model consists of a single pixel with one color channel. Although seemingly trivial, this model can represent various biological units. For example, it could model the eyespot of single-celled organisms like Euglena, the large monopolar cells found in an insect's compound eye or the bipolar cells in the retina. The single pixel case has been studied [14; 1]. We aim to review it to introduce the central concepts and the main theory, which will also be applicable to more complex scenarios.

Let us denote the light intensity of the pixel as \(x\), and let \(p(x)\) represent its probability distribution. We define an information processing unit (IPU) as a model that receives inputs and passes processed information to subsequent stages. As the first stage in an organism's information processing system, the single pixel IPU carries the same dual objectives as later stages: transmitting information and learning environmental probabilistic distributions. Therefore, the two objectives for the single pixel IPU are to transmit information about \(x\) efficiently through its output and to learn \(p(x)\).

Information is quantified by Shannon entropy. To compute the Shannon entropy of the input, we assume \(x\) is a discrete variable with \(M\) states, after all light intensity is quantized according to quantum mechanics, although \(M\) could be a very large number, making \(x\) practically indistinguishable from a continuous variable. The information obtained from the pixel when we know the intensity is \(x\) can be represented as \(I(x)=-\log p(x)\). The average information a state of the pixel contains, the Shannon entropy, is given by:

\[H_{p}=-\sum_{i=1}^{M}p(x_{i})\log p(x_{i}).\] (1)

The IPU transforms the input \(x\) into the output \(y=f(x)\), where the output space comprises \(N\) distinct states. In contrast to previous studies that assumed one-to-one mapping between input and output, here we posit that \(N\ll M\). This assumption is more congruent with biological constraints; for instance, the luminance resolution levels at synapse terminals in a zebrafish's retina are only about 10 [25]. Moreover, this assures that after processing the information is significantly reduced, thereby simplifying the tasks for subsequent stages.

The function \(f(x)\) assigns \(x\) into \(N\) groups, each corresponding to a fixed \(y\). We denote all \(x\) values in group \(j\) as \(G_{j}\), and the size of this group as \(n_{j}\). The entropy of the output is given by

\[H_{Q}=-\sum_{j=1}^{N}Q(y_{j})\log Q(y_{j}),\] (2)

where \(Q(y)\) represents the probability distribution of the output states.

Previous research [14; 1] has primarily emphasized the first objective of an IPU, which is maximizing the rate of transmission [19]. This goal is particularly relevant for early-stage IPUs, where the distinction between signal and noise is not yet clear. Maximizing the rate of transmission is equivalent to maximizing \(H_{Q}\) (see proof in Appendix A), leading to a constant \(Q(y)\). Biological neurons have been observed to follow this coding scheme [14].

Simultaneously, an IPU should also strive to fullfil the second objective and model \(p(x)\) as accurately as possible. Mathematically, this involves minimizing the Kullback-Leibler divergence between \(p(x)\) and the distribution learned by the IPU. This raises an interesting question: Are these two optimization objectives contradictory, or do they essentially represent the same task?

## 3 Even Code Principle

To determine how an IPU models \(p(x)\) we need to translate the output probability distribution \(Q(y)\) into the input space as \(q(x)\). \(q(x)\) is a step function:

\[q(x)=q_{j},\text{ for }x\in G_{j},\] (3)

and we have the following relations:

\[Q(y_{j})=\sum_{x\in G_{j}}p(x)=\sum_{x\in G_{j}}q(x)=n_{j}q_{j}.\] (4)

Minimizing the difference between \(p(x)\) and \(q(x)\) can be achieved by minimizing their Kullback-Leibler divergence:

\[D_{KL}(p||q) = H_{pq}-H_{p},\] (5)

where \(H_{pq}\) is the cross entropy. It can be proved that the cross entropy \(H_{pq}\) is equal to the entropy of the learned distribution in the input space defined as (see proof in Appendix B):

\[H_{q}=-\sum_{x}q(x)\log q(x),\] (6)

and we get

\[D_{KL}(p||q)=H_{q}-H_{p}.\] (7)

Since \(H_{p}\) is fixed, minimizing the KL divergence requires minimizing \(H_{q}\). The previous question now transforms into understanding the relationship between maximizing the entropy of the distribution in the output space (\(H_{Q}\)) and minimizing the entropy of the learned distribution in the input space (\(H_{q}\)).

Suppose we have two adjacent zones in the transformed space where the corresponding \(Q(y_{1})\) and \(Q(y_{2})\) are not equal, let's assume \(Q(y_{1})>Q(y_{2})\). One can reduce the inequality by shifting the boundary between these two zones and moving one x value from \(G_{1}\) to \(G_{2}\). This shift corresponds to a small change of probability, \(\delta\), for both zones. Note that \(\delta\) is comparable to \(q_{1}\) and \(q_{2}\), as we assume the distribution is smooth. We know that reducing the inequality of \(Q(y_{1})\) and \(Q(y_{2})\) always increases \(H_{Q}\). If the two optimization problems are the same, then \(H_{q}\) should increase; if they are contradictory, \(H_{q}\) should decrease. The change of \(H_{q}\) can be calculated as:

\[\Delta H_{q} =-[Q(y_{1})-\delta]\log\frac{Q(y_{1})-\delta}{n_{1}-1}-[Q(y_{2}) +\delta]\log\frac{Q(y_{2})+\delta}{n_{2}+1}\] \[\quad+Q(y_{1})\log\frac{Q(y_{1})}{n_{1}}+Q(y_{2})\log\frac{Q(y_{ 2})}{n_{2}}\] (8) \[=q_{2}-q_{1}+\delta(\log q_{1}-\log q_{2}+\frac{1}{n_{1}}+\frac{ 1}{n_{2}})+O(\delta^{2})+O(\frac{1}{n_{1}^{2}})+O(\frac{1}{n_{2}^{2}})\] (9) \[\approx q_{2}-q_{1}+\delta\log\frac{q_{1}}{q_{2}}.\] (10)

The change can either be positive or negative depending on \(q_{1}\) and \(q_{2}\). Since minimizing \(H_{q}\) and maximizing \(H_{Q}\) are not contradictory, these objectives can be tackled independently. Given a fixed number of output levels \(N\), we first maximize \(H_{Q}\) to retain as much input information as possible. If further refinement of \(p(x)\) modeling is required, we can increase the output resolution \(N\).

The aforementioned reasoning extends naturally to multivariate scenarios, as no assumptions about one-dimensionality of the input were made. We articulate the goal of a general information processing unit as follows: An information processing unit (IPU) transforms input space with \(M\) states into output space with \(N\) states, where \(N\ll M\). Given a smooth input probability distribution as \(M\rightarrow\infty\) and a piecewise smooth transformation function, the _sole_ goal of an IPU with a fixed output resolution \(N\) is to yield an even output probability distribution, hence retaining maximum information from the input. To attain better modeling precision, the output resolution \(N\) of the IPU should be increased. This will be referred to as the principle of even code. In the next sections, we will apply the even code principle to more complex inputs.

Two Pixels

For two pixels \((x_{1},x_{2})\), we can either use one IPU directly to model \(p(x_{1},x_{2})\) or use two IPUs to model \(p(x_{1})\) and \(p(x_{2})\) separately, followed by another IPU to model the outputs \(p(y_{1},y_{2})\). We will use the second approach, as processing as much information locally reduces the cost of information transfer. In fact, when images are stored on computers, gamma encoding is utilized to create an approximately even distribution of pixel values. When these images are displayed, pixel values undergo gamma correction to recover the original statistics for human eyes to process. In the following sections, we will assume that all pixel values \(x\) have already been processed by dedicated IPUs, resulting in a roughly even probability distribution.

The probability distribution \(p(x_{1},x_{2})\) of natural images is relatively simple. The majority of the probability is concentrated around the diagonal line \(x_{1}-x_{2}=0\), with \(p(x_{1},x_{2})\) rapidly decaying as \(|x_{1}-x_{2}|\) increases (see Fig. 1 (a) for example). Intuitively, we can use lines parallel or/and perpendicular to \(x_{1}-x_{2}=0\) to divide the probability distribution into even partitions.

### One Basis

To investigate how IPUs learn \(p(x_{1},x_{2})\), we conduct numerical experiments using a multilayer perceptron (MLP) as the IPU to approximate \(y=f(x)\) and model \(p(x)\)[23]. Other function approximation methods may also be applicable. To partition the input probability distribution with one set of parallel lines, only one IPU with \(N\) output nodes is needed. According to the even code principle, for each input, only one of the \(N\) output nodes should be activated, and the probability of activating any one of the \(N\) output nodes should be equal. We use the softmax function as the last layer of the MLP to ensure each output value is within [0, 1], and that if a node is activated (output value equals 1), it is the only node being activated. We use stochastic gradient descent and the following loss function to train the MLP:

\[E=\sum_{i}\langle y_{si}\rangle_{s}\log\langle y_{si}\rangle_{s}+k\langle- \sum_{i}y_{si}\log y_{si}\rangle_{s}.\] (11)

\(y_{si}\) represents the value of the i-th output node for the s-th input sample, while \(\langle\rangle_{s}\) denotes the average over all samples in a training batch. The first term in the loss function ensures each output node has an equal chance to be activated on average. The second term promotes activation of only one node per input while suppressing the remaining nodes, mimicking lateral inhibition when combined with the softmax function. The factor \(k\) balances the two terms to achieve the desired result. Fig. 1 (a) show the results learned by MLPs with 16 output nodes.

### Multiple Bases

To partition the input space with two sets of orthogonal lines we need two MLPs. The orthogonality is achieved by enforcing

\[Q(y_{1},y_{2})=\frac{1}{N_{1}N_{2}},\] (12)

where \(N_{1}\) and \(N_{2}\) represent the number of output nodes of the two MLPs (refer Appendix C for proof). If more than two orthogonal bases are required for partitioning the space, we can enforce Eq. (12) for each combination of two bases to ensure orthogonality between them. The loss function for multiple orthogonal bases with independent states is

\[E=\frac{1}{\binom{B}{2}}\sum_{<b,b^{\prime}>}\sum_{ij}\langle y_{bsi}y_{b^{ \prime}sj}\rangle_{s}\log\langle y_{bsi}y_{b^{\prime}sj}\rangle_{s}+\frac{k}{ B}\langle-\sum_{b=1}^{B}\sum_{i}y_{bsi}\log y_{bsi}\rangle_{s},\] (13)

where \(b\) is the base index, and \(B\) is the number of bases. \(\sum_{<b,b^{\prime}>}\) denotes the sum over all \(\binom{B}{2}\) combinations of two distinct bases. \(y_{bsi}y_{b^{\prime}sj}\) is the probability \(Q(y_{b},y_{b^{\prime}})\) for the sample s when \(y_{b}\) and \(y_{b^{\prime}}\) take their i-th and j-th value respectively.

Fig. 1 (b) shows an example of two-pixel input space partitioning using two orthogonal bases. For a more detailed discussion on the experiments and additional results, refer to Appendix D.

Additionally, it's worth noting that orthogonal bases with independent states might model grid cells [11] in the entorhinal cortex, though this topic is beyond the scope of the current paper.

## 5 Image Patches

Next we move on to study gray and color image patches. We use **x** to represent the vector of input pixel values of the image patch. The multivariate input probability distribution \(p(\textbf{x})\) is considerably more complex compared to the previous examples. If we use only one basis to discretize the input probability space (e.g. Fig. 1 (a) in Appendix D), the required number of independent states for a good approximation would be very large, making the evaluation of the softmax function computationally expensive. On the other hand, using multiple orthogonal bases would also significantly increase the computational cost to ensure orthogonality if the number of bases is more than just a few. Additionally, determining the optimal number of bases and the number of independent states for each basis are challenging.

Aside from the computational cost, another issue arises when working with image patches: we want the representation to capture the similarity between inputs. However, using orthogonal bases with independent states makes it difficult to gauge input similarity through methods such as calculating the difference between representations, even if we can establish an order for the states of each basis. Therefore, we need a more suitable coding scheme for complex inputs like image patches.

Real-valued vectors are a natural choice, given their extensive use in representing a variety of entities such as images, texts, and categorical variables [13; 22; 10]. The norm of the difference between two vectors can function as a measure of similarity. Nevertheless, if we want the representation **y** to mirror input similarity, each value of **y** should encapsulate all samples perceived as identical within the same group \(G\). Under this constraint, \(Q(\textbf{y})\) cannot remain constant, thereby conflicting with the even code principle.

Figure 1: Evenly partitioning the two-pixel probability distribution learned by multilayer perceptrons (MLPs). The X and Y axes represent the rescaled intensities \(x_{1}\) and \(x_{2}\) of the two pixels in the range [0, 1]. The quantity \(n(x_{1},x_{2})+1\) is plotted in gray on a log scale, where \(n(x_{1},x_{2})\) denotes the number of occurrences of the two-pixel values among the sampled data. Color lines indicate the boundaries of states for each basis learned by an MLP, with one color representing one basis. (a) One basis with 16 independent states, which partitions the space based on the total intensity \(x_{1}+x_{2}\). (b) Two orthogonal bases, each with 10 independent states, dividing the space based on the total intensity \(x_{1}+x_{2}\) and the contrast \(x_{1}-x_{2}\) approximately.

The resolution to this conflict involves permitting the representation to mirror input similarity at the most granular level, while enforcing the even code principle at a larger scale in the transformed space. We will detail this method in subsequent sections.

### Loss Function

To promote even distribution, we incorporate a loss function that compels input samples to repel each other in the transformed space. This repulsive force diminishes with increasing distance, as described by the following equation:

\[E=\langle-\ln|\mathbf{y}_{s}-\mathbf{y}_{s^{\prime}}|\rangle_{<s,s^{\prime}>}.\] (14)

Here, \(-\ln|\mathbf{y}_{s}-\mathbf{y}_{s^{\prime}}|\) represents the potential energy due to the repulsive force, which is proportional to the inverse of the Minkowski distance between the representations of samples \(s\) and \(s^{\prime}\) in the transformed space. Alternative forms of potential energy and distance measures could also be applicable. \(\langle\rangle_{<s,s^{\prime}>}\) denotes the average over all sample pairs.

Should numerous samples converge at one point in the transformed space, they will exert a strong repulsive force in the surrounding area, thereby discouraging other samples from occupying nearby positions. To prevent samples from pushing each other infinitely far apart, we restrict the representation values to be within the range \([0,1]\). With this constraint, the repulsive force pushes samples towards the vertices of the unit hypercube, effectively reducing the representations from real vectors to binary vectors. As a result, an even distribution is achieved on a larger scale in the transformed space, which consists solely of the vertices.

In the context of binary vectors, the collection of output nodes can be viewed as a vocabulary, and activated nodes by an input image patch act as its representative tokens. Unlike fixed-length representations with real-valued vectors, binary representations can employ fewer tokens for more common image patches (e.g., homogeneous patches), and more tokens for less common, structurally-rich patches. This can be accomplished by introducing a second term, \(\langle|\mathbf{y}_{s}|\rangle_{s}\), to the loss function, which echoes the sparsity regularization term found in various studies [9, 16, 26, 27, 29, 4]. The updated loss function becames:

\[E=\langle-\ln|\mathbf{y}_{s}-\mathbf{y}_{s^{\prime}}|\rangle_{<s,s^{\prime}> }+\alpha\langle|\mathbf{y}_{s}|\rangle_{s},\] (15)

where \(\alpha\) is a free parameter to adjust sparsity.

In practice, we add a small value \(\epsilon=10^{-38}\) to the distance, allowing slightly different samples to share the same representation and enhancing numerical stability. Another approach to improve numerical stability involves using a theoretically equivalent form of the loss function, which instead of allowing samples to repel each other in the output space, we enable nodes to repel one another, encouraging output nodes to be as independent as possible [24].

### Experiments

In the following experiments, we use either a single MLP with N outputs, or N MLPs each with one output, as the IPU to approximate the transformation function \(\mathbf{y}=f(\mathbf{x})\) and model \(p(\mathbf{x})\). The last layer of the MLP is a sigmoid layer, ensuring the output value ranges between 0 and 1. Our training data comprises random image patches extracted from the COCO 2017 image dataset [18] or the ImageNet dataset [6]. No image preprocessing is used. Additional training details are provided in Appendix E.

#### 5.2.1 Output Statistics

First, we examine the statistics of the learned representation. Across all experiments, we observe qualitatively similar output statistics, irrespective of the IPU architectures and training specifics, provided the training has properly converged. For illustration, we present an example using a model trained on \(5\times 5\) color image patches. It uses 96 MLPs, each with one output node and a middle layer of 48 nodes, as the IPU. Following training, the model is used to generate representations for 1 million random image patches for this analysis.

Fig. 2 (a) presents the histogram of output values on a logarithmic scale. The vast majority of output values are either at 0 or 1. As such during inference, we can round the outputs to yield a binary representation. Fig. 2 (b) illustrates the probability of an output node being activated by a random image patch. All nodes demonstrate similar activation probabilities, indicating an even distribution at this coarse scale. Further statistical analysis of the output representation is available in Appendix F.

#### 5.2.2 Image Patch Similarity

Next, to examine how the learned representation reflects the similarity between image patches, we display 16 random image patches, each followed by 9 image patches similar to them in the binary representation space, as shown in Fig. 3 (a). The same \(5\times 5\) color image patch model is used. The learned representation clearly captures perceptual similarity. The results shown in Fig. 2, Fig. 3 (a), and additional results in Appendix E confirm that with the loss function Eq. (15), we can indeed learn a sparse binary representation which reflects the image similarity while adhering to the even code principle.

For comparison with a traditional convolutional neural network, we present the results generated with the first 10 layers of a VGG16 model [31] pre-trained on ImageNet in Fig. 3 (b). The image patch representation from the first 10 layers of the VGG16 model is a float vector of size 128. The even code model, with only 96 binary outputs, achieves results similar to the VGG16 model. These 96 binary outputs occupy the same storage space as a float vector of length 3 -- just 1/42 of the VGG16 representation's size, which underscores the exceptional efficiency of the even code method in image patch representation.

#### 5.2.3 Local Edge Detectors and Orientation-Selective Units

Biological visual systems' initial stages are known to possess local edge detectors and orientation-selective units [17, 2]. While CNNs have been successfully trained to detect boundaries via supervised learning [20], their initial layers have not shown proficiency in edge detection [15]. Notably, prevalent local edge detection algorithms, such as the Canny edge detector [5], still primarily rely on non-deep learning methods.

Does the even code model, proposed as the initial stage of an optimal image processing system, resemble biological systems more closely? To answer this, we trained an even code model on \(4\times 4\) grayscale image patches and applied it to images with a stride of 1 pixel, generating feature maps for each output node. The model comprises a MLP with 64 outputs and an intermediary layer with 100 nodes. Fig. 4 illustrates the feature maps of 4 output nodes of the even code model for 4 different input images. It also shows edges generated by the Canny edge detector as comparison. Interestingly,

Figure 2: Statistical analysis of the learned representation using the loss function Eq. (15). (a) Histogram of the modelâ€™s output values on a log scale. (b) Probability of an output node being activated by a random image patch.

with this simple network architecture, the even code model demonstrated a remarkable capability in edge detection, rivaling the multi-stage Canny edge detector.

Furthermore, Fig. 5 shows the feature maps of 5 output nodes for a sample bike image. Spokes of different orientations activate different nodes, indicating that these output nodes of the even code model have varying orientation preferences, similar to orientation-selective units found in bilogical systems.

## 6 Conclusion

In summary, this paper demonstrates that maximizing the information-carrying capacity of output channels and modeling the input probability distribution are not mutually exclusive objectives and can be pursued independently. Given a specific output resolution, the sole goal of an information processing unit is to preserve as much information from the input as possible by ensuring an even distribution of samples in the output space. We applied the even code principle to study the probability distributions of two-pixel systems and image patches. For the two-pixel system, we learned orthogonal bases with independent states to model its probability distribution. For image patches, the even code approach naturally led to a nonlinear sparse binary representation. The even code model also shares additional similarities with early visual systems, such as the presence of local edge-detecting and orientation-selective units. These similarities suggest that the even code model could potentially serve as a new representation for neurons in early visual systems.

Figure 3: Image patches with the shortest distance in the representation space to 16 randomly selected image patches. The first column presents the 16 random image patches, while the succeeding nine columns display patches that are closest to the first-column patches in the same row. (a) Distances are computed using using an even code model with 96 binary outputs. (b) Distances are computed using the first 10 layers of a pretrained VGG16 model with 128 real outputs.

There are several intriguing directions for future research. First, the even code model has been applied to inputs ranging from as simple as one pixel to more complex color image patches. Can we extend its application beyond the early stage of visual information processing? Second, the even code model could be extended to videos by incorporating an additional time dimension alongside color, width, and height dimensions. Investigating time-varying inputs, which produce spike train-like outputs, and conducting an in-depth comparison with early visual systems would be very interesting. Third, the even code model can also be extended to binocular vision data by adding another input dimension of size two. Whether the model with binocular and/or video data can construct a 3D model of the world based on data of two spatial dimensions is an intriguing question. Fourth, while this paper focuses on visual information, the even code model is a general method that could be applied to model other multivariate probability distributions as well. Lastly, on the application side, the even code model has potential in various areas, including local edge detection, image and video compression/denoising/retrieval, texture classification, and multispectral/hyperspectral image processing.

## References

* [1] Joseph J. Atick. Could information theory provide an ecological theory of sensory processing? _Network: Computation in neural systems_, 3(2):213-251, 1992.
* [2] Tom Baden, Philipp Berens, Katrin Franke, Miroslav Roman Roson, Matthias Bethge, and Thomas Euler. The functional diversity of retinal ganglion cells in the mouse. _Nature_, 529(7586):345-350, 2016.

Figure 4: Feature maps of nodes resembling local edge detectors. The first column presents four grayscale test images. Each subsequent column, except the last one, displays the feature maps corresponding to the same output node for the four test images. The last column shows edges generated by the multi-stage Canny edge detector for comparison.

Figure 5: Feature maps of five orientation-selective nodes applied to a test image. Spokes in different orientations activate distinct nodes, illustrating the orientation-selectivity of these nodes.

* Barlow et al. [1961] Horace B Barlow et al. Possible principles underlying the transformation of sensory messages. _Sensory communication_, 1(01):217-233, 1961.
* Beyeler et al. [2019] Michael Beyeler, Emily L. Rounds, Kristofor D. Carlson, Nikil Dutt, and Jeffrey L. Krichmar. Neural correlates of sparse coding and dimensionality reduction. _PLOS Computational Biology_, 15(6):e1006908, jun 2019.
* Canny [1986] John Canny. A computational approach to edge detection. _IEEE Transactions on pattern analysis and machine intelligence_, (6):679-698, 1986.
* Deng et al. [2009] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In _2009 IEEE conference on computer vision and pattern recognition_, pages 248-255. Ieee, 2009.
* DiCarlo et al. [2012] James J DiCarlo, Davide Zoccolan, and Nicole C Rust. How does the brain solve visual object recognition? _Neuron_, 73(3):415-434, 2012.
* Dosovitskiy et al. [2020] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. An image is worth 16x16 words: Transformers for image recognition at scale. _arXiv preprint arXiv:2010.11929_, 2020.
* Field [1994] David J. Field. What Is the Goal of Sensory Coding? _Neural Computation_, 6(4):559-601, jul 1994.
* Guo and Berkhahn [2016] Cheng Guo and Felix Berkhahn. Entity embeddings of categorical variables. _arXiv preprint arXiv:1604.06737_, 2016.
* Hafting et al. [2005] Torkel Hafting, Marianne Fyhn, Sturla Molden, May Britt Moser, and Edvard I. Moser. Microstructure of a spatial map in the entorhinal cortex. _Nature 2005 436:7052_, 436(7052):801-806, jun 2005.
* He et al. [2015] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. arxiv 2015. _arXiv preprint arXiv:1512.03385_, 14, 2015.
* Hinton and Salakhutdinov [2006] G. E. Hinton and R. R. Salakhutdinov. Reducing the Dimensionality of Data with Neural Networks. _Science_, 313(5786):504-507, 2006.
* Laughlin [1981] Simon Laughlin. A Simple Coding Procedure Enhances a Neuron's Information Capacity. _Zeitschrift fur Naturforschung C_, 36(9-10):910-912, oct 1981.
* Le and Kayal [2021] Minh Le and Subhradeep Kayal. Revisiting edge detection in convolutional neural networks. In _2021 International Joint Conference on Neural Networks (IJCNN)_, pages 1-9. IEEE, 2021.
* Lee et al. [2003] Ann B Lee, Kim S Pedersen, and David Mumford. The Nonlinear Statistics of High-Contrast Patches in Natural Images. _International Journal of Computer Vision_, 54(5413):83-103, 2003.
* Levick [1967] William R Levick. Receptive fields and trigger features of ganglion cells in the visual streak of the rabbit's retina. _The Journal of physiology_, 188(3):285, 1967.
* Lin et al. [2014] Tsung-Yi Lin, Michael Maire, Serge Belongie, Lubomir Bourdev, Ross Girshick, James Hays, Pietro Perona, Deva Ramanan, C. Lawrence Zitnick, and Piotr Dollar. Microsoft coco: Common objects in context, 2014.
* Linsker [1988] Ralph Linsker. Self-organization in a perceptual network. _Computer_, 21(3):105-117, 1988.
* Martin et al. [2004] David R Martin, Charless C Fowlkes, and Jitendra Malik. Learning to detect natural image boundaries using local brightness, color, and texture cues. _IEEE transactions on pattern analysis and machine intelligence_, 26(5):530-549, 2004.
* Masland [2012] Richard H. Masland. The Neuronal Organization of the Retina, oct 2012.

* [22] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word representations in vector space. _arXiv preprint arXiv:1301.3781_, 2013.
* [23] Guido Montufar, Razvan Pascanu, Kyunghyun Cho, and Yoshua Bengio. On the Number of Linear Regions of Deep Neural Networks. _Advances in Neural Information Processing Systems_, 4(January):2924-2932, feb 2014.
* [24] Jean Pierre Nadal and Nestor Parga. Nonlinear neurons in the low-noise limit: a factorial code maximizes information transfer. _http://dx.doi.org/10.1088/0954-898X_5\(4\)008_, 5(4):565-581, 2009.
* [25] Benjamin Odermatt, Anton Nikolaev, and Leon Lagnado. Encoding of Luminance and Contrast by Linear and Nonlinear Synapses in the Retina. _Neuron_, 73:758-773, 2012.
* [26] Bruno A Olshausen. sparse codes and spikes. _Probabilistic models of the brain_, page 257, 2002.
* [27] Bruno A Olshausen and David J Field. Sparse coding of sensory inputs. _Current opinion in neurobiology_, 14(4):481-487, 2004.
* [28] Bruno A. Olshausen and David J. Field. Emergence of simple-cell receptive field properties by learning a sparse code for natural images. _Nature_, oct 2015.
* [29] Marc'Aurelio Ranzato, Christopher Poultney, Sumit Chopra, and Yann Cun. Efficient learning of sparse representations with an energy-based model. _Advances in neural information processing systems_, 19, 2006.
* [30] Joshua R. Sanes and S. Lawrence Zipursky. Design Principles of Insect and Vertebrate Visual Systems, 2010.
* [31] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. _arXiv preprint arXiv:1409.1556_, 2014.
* [32] JH van Hateren. A theory of maximizing sensory information. _Biol. Cybern_, 68:23-29, 1992.