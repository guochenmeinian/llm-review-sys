# SanFlow: Semantic-Aware Normalizing Flow for Anomaly Detection and Localization

 Daehyun Kim1 Sungyong Baik2 Tae Hyun Kim3

Dept. of Artificial Intelligence1, Dept. of Data Science2, Dept. of Computer Science3

Hanyang University

{daehyun, dsybaik, taehyunkim}@hanyang.ac.kr

Correspondence to: Tae Hyun Kim <taehyunkim@hanyang.ac.kr>.

###### Abstract

Visual anomaly detection, the task of detecting abnormal characteristics in images, is challenging due to the rarity and unpredictability of anomalies. In order to reliably model the distribution of normality and detect anomalies, a few works have attempted to exploit the density estimation ability of normalizing flow (NF). However, previous NF-based methods forcibly transform the distribution of all features into a single distribution (e.g., unit normal distribution), even when the features can have locally distinct semantic information and thus follow different distributions. We claim that forcibly learning to transform such diverse distributions to a single distribution with a single network will cause the learning difficulty, thereby limiting the capacity of a network to discriminate between normal and abnormal data. As such, we propose to transform the distribution of features at each location of a given input image to different distributions. Specifically, we train NF to map the feature distributions of normal data to different distributions at each location in the given image. Furthermore, to enhance the discriminability, we also train NF to map the distribution of abnormal data to a distribution significantly different from that of normal data. The experimental results highlight the efficacy of the proposed framework in improving the density modeling and thus anomaly detection performance.

## 1 Introduction

Abnormal events that deviate significantly from expected and typical characteristics are often unwanted and are referred to as anomalies. The objective of anomaly detection is to identify such abnormal events. As such, anomaly detection is applicable across domains (e.g., video-surveillance, product defect detection, medical image analysis, etc.), where abnormal events can indicate or lead to critical issues. However, abnormal events occur rarely and can appear in various forms that cannot be known in advance, making it infeasible to collect a large amount of abnormal data in many real-world scenarios. The difficulty in collecting abnormal data has prevented anomaly detection from exploiting the recent breakthrough in supervised learning, leaving the field still challenging.

Acknowledging the difficulty of collecting abnormal data, many works have formulated anomaly detection as unsupervised learning, one-class learning, or few-shot learning [4, 5, 45, 49, 8, 47], in which the goal is to accurately model a distribution of normal data. Then, any data that deviates from the learned distribution of normal data is considered as an anomaly. The approaches to unsupervised anomaly detection differ by how they recognize the differences between normal and abnormal data. Reconstruction-based methods learn to reconstruct normal images and thus distinguish input images as abnormal if the reconstruction error is high [1, 42, 12, 35]. Meanwhile, representation-based approaches aim to learn a feature space, where normal images are brought close to each otherand abnormal images are placed far away from normal images [11; 8; 36]. Another line of works aims to simulate abnormalities through data augmentation [54; 26]. On the other hand, a recently emerging trend is to employ normalizing flow (NF) for a more reliable estimation of normal data distribution [51; 20; 37].

NF aims to achieve better density estimation by learning a sequence of reversible functions to map a complex distribution of input data into a simple distribution (e.g., normal distribution). The goal of NF aligns with that of anomaly detection in that a reliable density estimation of normal samples leads to the accurate detection of anomalies. However, previous NF-based methods have solely relied on the capability of NF to model complex distributions as simple ones. Although features at different locations, scales and images can follow different distributions, previous works have attempted to map such multi-modal distribution to simply a single normal distribution.

Considering that features at different locations and images may follow different distributions, we propose to adaptively embed the features at each location of each image into different distributions accordingly. We make two contributions in this work: First, we propose a novel NF-based framework that transforms the feature distribution of normal data at each location into Gaussian distributions with zero mean but different variances. The variance at each location is estimated by an external network that is conditioned on image features and semantics. Second, to enhance the detection of anomalies, we train NF to transform abnormal features into a distinct Gaussian distribution with a mean that is distant from the distributions of normal features. By embedding the features to locally different distributions, we facilitate the training of NF. We demonstrate that the estimated variance is lower for simple regions such as the background, while it increases for more complex regions. A description of the proposed approach is shown in Figure 1 and evaluation examples by category are shown in Figure 2.

The proposed framework demonstrates outstanding performance in both anomaly detection and localization. The strong empirical results underline the effectiveness of the proposed method in learning a more reliable density estimation, suggesting the importance of learning different target distributions for abnormal features and different normal features.

## 2 Related Work

Unsupervised anomaly detection tackles a challenging scenario, in which training images only consist of normal images that are free of anomalies. Under such challenging scenarios, standard supervised learning algorithms fail to work since training data is available for only one class (normal data), therefore often referred to as one-class learning. Methodologies that have emerged to overcome this issue largely differ by how they recognize the differences between normal data and abnormal data [9].

**Reconstruction based.** Reconstruction based approaches are hinged on the motivation that reconstruction models can reconstruct images well, if images are drawn from the same distribution as training images. Thus, these approaches distinguish images with high reconstruction error as abnormal. Several methods perform reconstruction by using auto-encoder architecture [41; 57; 6; 55; 32; 48; 45; 5] or the generator part of GAN models [1; 10; 31; 40].

Figure 1: Motivation Overview: Different semantic features can be observed in different regions. Abnormal regions (red box) exhibit significantly distinct features compared to normal features (orange and blue boxes). Moreover, normal regions also display different semantic features based on the complexity of the region. Upon our observation, we propose Semantic-Aware Normalizing Flow (SANFlow) that enables more accurate density estimation by adaptively embedding semantic feature distribution into corresponding but different base distributions.

**Data augmentation based.** A few methods have proposed to generate abnormal images through data augmentation that is based on either cut-out [13], random erasing [43], noise generation [54], or geometric transformations [17; 16; 21]. In particular, CutPaste [26] introduces a new data augmentation to generate more fine-grained and subtle abnormal local patches in normal images. Furthermore, other research areas use synthesized abnormal images to improve performance such as semantic segmentation [23; 19; 7] or image classification [25].

**Representation based.** Another recent line of research has focused on designing systems that can leverage the strong representation power of pre-trained convolutional neural networks. [11; 36; 8; 49; 46; 56; 34]. Then, anomaly detection is performed by measuring the distances between test image features and normal image features. The methods differ by how the features of normal image are maintained or modeled and how the distance is measured. SPADE [8] employs k-nearest neighbor (k-NN) for normal image features retrieval and feature correspondence for measuring the differences. To mitigate the complexity issue with nearest neighbor search, PatchCore [36] maintains a subset of features via coreset subsampling. Meanwhile, PaDiM [11] models the normal features as a multivariate Gaussian distribution and uses Mahalanobis distance [30] as a distance measure, instead of the k-NN algorithm, to improve the inference complexity.

**Normalizing flow based.** Recently, a few works have shifted the attention to employing normalizing flow (NF) to better estimate the distribution of the features of normal patches. Through a sequence of learnable and invertible transformations, NF embeds the feature distribution into a simple normal distribution. DifferNet [37] is one of the first to employ NF to transform the distribution of CNN features to a normal distribution, where anomaly detection is performed at image level by measuring the likelihood of samples. Then, CFLOW-AD [20] extends NF-based methodology to pixel-level anomaly detection. FastFlow [51] further improves the performance by utilizing normalizing flow in two-dimensional space, unlike previous one-dimensional NF-based anomaly detection algorithms. In addition, CS-Flow [38] proposed a new kind of NF model that jointly processes multiple feature maps across different scales. However, they forcefully embed different feature distributions of semantic patches to a single normal distribution, despite recent findings in classification that it is beneficial to transform images of different semantics into different distributions [22; 3]. By contrast, we propose to train NF to transform the distributions at different locations to simple, but different distributions to better exploit the density estimation capability of NF by assuming locally varying base distributions.

## 3 Proposed method

In this section, we describe the overall pipeline of our framework, dubbed Semantic-Aware Normalizing Flow (SANFlow), as depicted in Figure 3. Given an image \(\bm{x}\), a pre-trained feature extractor \(f\) is used to obtain features \(\bm{v}_{i}\sim V_{i}\) at the \(i\)-th position. Then, we employ normalizing flow (NF) \(g^{-1}:V_{i}\to Z_{i}\) to embed the feature distribution \(V_{i}\) (a.k.a. target distribution) to simple and well-known distribution \(Z_{i}\) (a.k.a. base distribution). To further guide NF to map feature distributions \(V_{i}\) into different base distributions \(Z_{i}\) upon semantics, we introduce an external network \(h\) which allows us to predict statistics of \(\bm{z}_{i}\) for each feature \(\bm{v}_{i}\). Moreover, similar to [26], we employ data

Figure 2: Anomaly localization results by our proposed framework on MVTec benchmark dataset. From top to bottom: anomaly localization prediction, GT mask, anomaly score map and estimated variance map of input image. Variance maps are derived from mode values of \(\alpha\) and \(\beta\) of each pixel and bright areas represent high variance and dark areas represent low variance values for corresponding distribution.

augmentation to synthesize local anomalies within the input image in order to train NF to embed the distribution of anomaly features into a distribution \(Z_{i}^{a}\) that is distinct from the distributions of normal features \(Z_{i}^{n}\).

Then, we modify the standard objective function of NF to account for different base distributions (Section 3.5). Finally, at test time, we use the trained NF to estimate the probability of given features to be normal, the negation of which is used as an anomaly score function to detect anomalies in a given image (Section 3.6).

### Background on normalizing flow

Normalizing flow (NF) [33] aims to learn a function \(g\) that transforms the latent variable \(\bm{z}\), which follows a simple and tractable base distribution \(Z\), into the variable \(\bm{v}\), which follows a complex target distribution \(V\). To do so, NF formulates \(g\) as the composition of invertible functions \(\{g^{l}\}_{l=1}^{l}\), i.e., \(g=g^{L}\circ g^{L-1}\circ\cdots\circ g^{1}\), where \(L\) is the number of invertible functions. Such transformation of a complex distribution into a simple one allows for efficient and exact density estimation, serving as a powerful tool in density estimation. By applying the change of variables theorem in a sequence, the log-likelihood of the target distribution \(p_{V}(\bm{v})\) can be expressed in terms of the log-likelihood of the base distribution \(p_{Z}(\bm{z})\):

\[\log p_{V}(\bm{v})=\log p_{Z}(\bm{z})-\sum_{l=1}^{L}\log\bigg{|}\mathrm{det} \,\frac{dg^{l}}{d\bm{z}^{l-1}}\bigg{|},\] (1)

where \(\bm{z}^{l}\) represents the resulting random variable after applying up to the \(l\)-th function \(g^{l}\) on \(\bm{z}\). Note that \(\bm{z}^{0}\) corresponds to \(\bm{z}\) while \(\bm{z}^{L}\) corresponds to \(\bm{v}\). For efficient computation of the log-likelihood, functions \(\{g^{l}\}_{l=1}^{L}\) need to be invertible and have easy-to-compute Jacobian determinant. To meet such requirements, one of popular NF instances, RealNVP [14], formulated each function \(g^{l}\) as an affine coupling block. In an affine coupling block, the input is first divided into two equal-dimension parts. Then, each part undergoes affine transformation, whose parameters are generated by a network conditioned on the other part. The transformed parts, in turn, are put back together via concatenation.

Then, the log-likelihood in Equation 1 is maximized (or the negative log-likelihood is minimized) to train the parameters of transformation function. A base distribution \(Z\) is commonly chosen as a normal distribution \(\mathcal{N}(\bm{0},\bm{I})\) in previous NF-based anomaly detection algorithms [20; 51; 37], resulting in a loss function (i.e., negative log-likelihood) as follows:

\[\mathcal{L}_{\text{NLL}}=\frac{||\bm{z}||_{2}^{2}}{2}+\sum_{l=1}^{L}\log \bigg{|}\mathrm{det}\,\frac{dg^{l}}{d\bm{z}^{l-1}}\bigg{|}.\] (2)

### Synthetic anomaly generation

In unsupervised anomaly detection scenarios, abnormal training images are typically not available. Therefore, we synthesize abnormal images to facilitate training of NF. Abnormal images usually differ from normal images only in local regions, which are semantically or structurally similar to surrounding normal regions. To generate such abnormal data, CutPaste [26] introduces data augmentation technique that disturbs local regions of normal images with semantically similar patches. The extracted patches, in turn, undergo transformations (e.g., random flip, rotate, blur, and color jittering) and replace the region of other normal images of the same category at random location. In this work, we use the CutPaste method to synthesize abnormal images. We modify this method slightly to generate more realistic abnormal images by blurring the borders of extracted patches and applying diverse color jittering values to these patches. Also, we make abnormal patches by taking small rectangular patches like CutPaste or newly used circular patches. Size of patches are random and from a normal image to retain diversity of abnormal regions and use the same ratio of all types of patches and normal data for training. Then, during training, our NF model handles normal and abnormal regions of each input image \(\bm{x}\) differently by assuming locally different base distributions. To achieve this, we introduce a binary mask \(\bm{M}\) as shown in Figure 3 for each synthetic anomaly image \(\bm{x}\) to denote whether each pixel at pixel location \((w,h)\) belongs to the normal region (\(\bm{M}_{w,h}=1\)) or the abnormal region (\(\bm{M}_{w,h}=0\)).

### Feature extractor

Recently, features extracted by convolutional neural networks (CNN) pre-trained on ImageNet [39] have been shown to be helpful in anomaly detection, by providing useful semantic information [11; 5; 8; 20; 48]. In particular, several methods have employed a multi-scale feature pyramid [27] to handle anomalies of diverse sizes [20; 48; 8]. This is because features of different scales capture information about regions of corresponding sizes (i.e., effective receptive field) in the image [29]. Motivated by previous findings, we also employ a pre-trained CNN [11; 20; 36] to obtain a \(K\)-level feature pyramid. The feature map at the \(k\)-th scale is denoted by \(\bm{A}^{k}\in\mathbb{R}^{C_{k}\times H_{k}\times W_{k}}\) where \(C_{k}\) is the number of channels and \(H_{k}\) and \(W_{k}\) are the height and width of the feature maps, respectively.

### Semantic-aware normalizing flow

#### 3.4.1 Scale- and spatial-aware normalizing flow

We train NF to map our feature vectors computed by CNN to latents which follow simple base distributions. However, features can follow complex distributions at each scale and spatial location of feature map. Thus, using a single NF model to map such complex features to a single base distribution can be difficult. Aiming to bridge the gap, CFLOW-AD [20] applied two modifications to a standard NF baseline model RealNVP [14]: independent NF models for each scale and conditioning NF on position embedding vector [15; 44], similar to [2]. Inspired by CFLOW-AD, we also employ \(K\) independent NF models to handle features across different scales as we have \(K\)-level pyramid features and position embedding vector conditioning. Moreover, we train the NF model to map features to latents that follow a spatially varying underlying distribution. This allows NF to consider semantic information, such as feature complexity, for corresponding locations in the image.

To be specific, we create a set of vectors by taking a feature vector \(\bm{v}_{i}^{k}\) at the \(i\)-th position (i.e., 2D coordinate) of the \(k\)-th scale feature map \(\bm{A}^{k}\), as done in the previous work [20]. Note that, we omit the scale index \(k\) from this point on to avoid cluttered notation. To retain the spatial information, each feature vector \(\bm{v}_{i}\) is concatenated with the corresponding position embedding vector \(\bm{p}_{i}\in\mathbb{R}^{D}\), whose values are composed of sinusoidal harmonics and unique to each \(i\)-th position [15; 44]. The resulting vector \(\bm{c}_{i}=(\bm{v}_{i},\bm{p}_{i})\) is now used to condition each transformation function \(g^{l}\) in NF, making it process position-aware [2]. Then, the log-likelihood of feature distribution becomes:

\[\log p_{V_{i}}(\bm{v}_{i})=\log p_{Z_{i}}(\bm{z}_{i})-\sum_{l=1}^{L}\log\left| \det\frac{dg^{l}}{d\bm{z}_{i}^{l-1}}\right|,\] (3)

Figure 3: The overview of our proposed SANFlow framework. Firstly, with synthetic augmentation process, make binary mask \(\bm{M}\) and anomaly image \(\bm{x}\) from normal image. Then, a pre-trained feature extractor \(f\) is applied to extract multi-scale feature maps (\(K\)=\(3\), number of scales in this work) for \(\bm{x}\). For each \(i\)-th position at feature map of \(k\)-th level, each feature vector \(\bm{v}_{i}^{k}\) is concatenated with a position embedding vector \(\bm{p}_{i}^{k}\) before being fed into NF, which is independently trained for each scale. To be specific, NF consists of 8 coupling blocks (i.e., \(L\)=\(8\)), which maps given feature distributions to base distributions. Each base distribution is different in terms of statistics (variance in this work) which are dependent on semantic features of the corresponding location in the given image. In particular, we condition our statistics prediction network \(h\) on the input image to generate parameters of inverse Gamma distribution such as \(\alpha\) and \(\beta\), to estimate the variances of base distributions, which are assumed to follow inverse Gamma distributions.

where \(Z_{i}\) is a simple, yet locally varying base distribution corresponding to a feature vector \(\bm{v}_{i}\).

However, just making NF scale- and spatial-aware is insufficient to handle variations that exist within the same object category. This is because objects are not perfectly aligned across different images of the same category, resulting in images with different semantic information even at the identical spatial location and scale. Thus, in order to enhance the density estimation of our NF model, we propose to embed feature distributions into different base distributions, leveraging the semantic information encoded in the features. Further details on this approach are provided in the following section.

#### 3.4.2 Semantic-aware base distribution

In this study, we instantiate semantic-dependent base distributions as Gaussian distributions with statistics that are estimated based on semantic information of features. Inspired by an algorithm that estimates the statistics of non-i.i.d. noise [52], we employ a lightweight statistics prediction network \(h\) to estimate the statistics for the given feature \(\bm{v}_{i}\). We condition the network, parameterized by \(\bm{\theta}_{h}\), on the semantic features to be able to estimate appropriate statistics of corresponding base distributions. As we will discuss in our experiments, we empirically observe that estimating both mean (\(\mu_{i}\)) and variance (\(\sigma_{i}^{2}\)) of the base distribution is difficult and that estimating variance (\(\sigma_{i}^{2}\)) alone is beneficial (Section 4.3). Therefore, we fix \(\mu_{i}\) to be \(0\) for normal regions and \(1\) for abnormal regions. In doing so, we map abnormal features to a base distribution with minimal overlap with that of normal features during training, thereby aiding NF in mapping normal and abnormal regions into distinct distributions. When samples are non-i.i.d., the distribution of sample variance can be assumed to follow the inverse Gamma distribution [52]. Since image pixels and semantic features are non-i.i.d., we formulate the variances of the corresponding base distributions to follow the inverse Gamma distribution as IG(\(\cdot|\alpha,\beta\)) with parameters \(\alpha\) and \(\beta\). We set \(\alpha\) to be \((\frac{p^{2}}{2}-1)\) and \(\beta\) to be \(\frac{p^{2}\xi}{2}\), where \(p^{2}\) denotes the area of the corresponding receptive field of size \(p\times p\) and \(\xi\) is the mode of the inverse Gamma distribution [52, 50]. In this work, \(\xi\) is a hyperparameter, the value of which is empirically found to be \(0.1\). Upon the assumption, we train the network \(h\) to estimate \(\alpha_{i}\) and \(\beta_{i}\) for each \(\bm{v}_{i}\), resulting in the following regularization loss as:

\[\mathcal{L}_{KL} =D_{KL}(IG(\alpha_{i},\beta_{i})\,|\,IG(\alpha,\beta))\] \[=\sum_{i=1}^{H_{k}\times W_{k}}\{(\alpha_{i}-\alpha)\psi(\alpha_ {i})+(\log\Gamma(\alpha)-\log\Gamma(\alpha_{i}))+\alpha(\log\beta_{i}-\log \beta)+\alpha_{i}(\frac{\beta}{\beta_{i}}-1)\},\] (4)

where \(D_{KL}(IG(\alpha_{i},\beta_{i})\,|\,IG(\alpha,\beta))\) computes a KL divergence between the estimated distribution by the network \(h\) and the distribution of variance \(\sigma_{i}^{2}\), which we assume to follow \(IG(\alpha,\beta)\) as mentioned above; \(\psi\) is a digamma function and \(\Gamma\) is a gamma function. Notably, \(\mathcal{L}_{KL}\) with \(\alpha\) and \(\beta\) acts as regularization to guide the statistics prediction network for stable training. The derivation details and detailed explanations can be found in the supplementary material.

### Loss function

In this section, we delineate the overall objective function which our model is trained to minimize. First, we need to modify the log-likelihood of \(\bm{z}_{i}\) corresponding to feature \(\bm{v}_{i}\) in Equation 3 to account for handling both normal and abnormal features differently:

\[\log p_{Z_{i}}(\bm{z}_{i})=m_{i}\cdot\log p_{Z_{i}^{n}}(\bm{z}_{i})+(1-m_{i}) \cdot\log p_{Z_{i}^{n}}(\bm{z}_{i}),\] (5)

where the binary indicator \(m_{i}\) is set to be \(1\) when the corresponding location in the binary mask \(\bm{M}\) is \(1\), and \(0\), otherwise. Note that, \(Z_{i}^{n}\) represents the corresponding base distribution when \(\bm{v}_{i}\) is a normal feature, while \(Z_{i}^{a}\) represents the base distribution when \(\bm{v}_{i}\) is an abnormal feature. In practice, to compute the likelihood at the \(k\)-th scale, the binary mask \(\bm{M}\) is resized to match the size of the feature map \(\bm{A}^{k}\), which has height \(H_{k}\) and width \(W_{k}\). The resizing is done using nearest-neighbor interpolation to preserve the binary nature of the mask. In turn, each log-likelihood term can be formulated as follows (detailed derivations can be found in the supplementary material):\[\log p_{Z_{i}^{n}}(\bm{z}_{i})=-\frac{1}{2}\log 2\pi-\frac{1}{2}(\log\beta_{i}- \psi(\alpha_{i}))-\frac{\alpha_{i}}{2\beta_{i}}||\bm{z}_{i}||_{2}^{2},\] (6)

and,

\[\log p_{Z_{i}^{o}}(\bm{z}_{i})=-\frac{1}{2}\log 2\pi-\frac{1}{2}(\log\beta_{i}- \psi(\alpha_{i}))-\frac{\alpha_{i}}{2\beta_{i}}||\bm{z}_{i}-1||_{2}^{2}.\] (7)

Moreover, to further aid NF in distinguishing normal and abnormal features, we can also train NF to perform binary classification using the loss function as follows:

\[\mathcal{L}_{\text{BCE}}=\mathbb{BC}\mathbb{E}(s(\bm{z}_{i}),m_{i}),\] (8)

where \(\mathbb{BC}\mathbb{E}\) denotes the conventional binary cross-entropy loss, while \(s(\bm{z}_{i})\) measures the probability of \(\bm{z}_{i}\) being classified as normal (i.e., \(s(\bm{z}_{i})=\frac{p_{Z_{i}^{n}}(\bm{z}_{i})}{p_{Z_{i}^{n}}(\bm{z}_{i})+p_{Z_ {i}^{n}}(\bm{z}_{i})}\)). Note that the log-likelihood of \(\bm{z}_{i}\) being abnormal (Equation 7) can be used only during training such that our framework learns to map abnormal features to base distribution \(Z^{a}\) that has small overlap with the base distributions of normal features \(Z^{n}\). This allows NF to transform normal and abnormal features to two distinct base distributions, thereby enhancing the discriminability.

Together with \(\mathcal{L}_{\text{KL}}\) from Equation 4, the overall objective function \(\mathcal{L}_{\text{overall}}\) to minimize is given by,

\[\mathcal{L}_{\text{overall}}=\mathcal{L}_{\text{NLL}}+\lambda_{1}\cdot \mathcal{L}_{\text{BCE}}+\lambda_{2}\cdot\mathcal{L}_{\text{KL}},\] (9)

where \(\lambda_{1}\) and \(\lambda_{2}\) are hyperparameters to adjust the associated weights of \(\mathcal{L}_{\text{BCE}}\) and \(\mathcal{L}_{\text{KL}}\).

### Anomaly score functions

During inference, given a test image \(\bm{x}\in\mathbb{R}^{H\times W\times 3}\), we first compute the log-likelihood of each feature \(\bm{v}_{i}\) at each \(k\)-th scale via Equation 3, where the log-likelihood of \(\bm{z}_{i}\) is computed with Equation 6. Then, the likelihood map \(\bm{P}^{k}\in\mathbb{R}^{H_{k}\times W_{k}}\) for the \(k\)-th scale is obtained by taking exponential of the log-likelihood 6. We obtain the final likelihood map \(\bm{P}\in\mathbb{R}^{H\times W}\) by summing the likelihood map \(\bm{P}^{k}\) from all scales. These likelihood maps are first upsampled to the image resolution \(\mathbb{R}^{H\times W}\) using bilinear interpolation, following the approach described in [20]. Finally, the anomaly score map is computed as the negative of \(\bm{P}\), resulting in \(-\bm{P}\).

## 4 Experiments

In this section, we evaluate our framework to validate its capability in both pixel-level anomaly localization and image-level anomaly detection. We will release our code and data upon acceptance, and more details and results can be found in the supplementary material.

### Experimental settings

**Dataset.** The experiments are conducted on two commonly used datasets for unsupervised anomaly detection: STC (ShanghaiTech Campus) dataset [28] and MVTec dataset [4]. STC is a video surveillance dataset, which provides static videos of 13 different scenes of \(856\times 480\) resolution. It contains \(274,515\) frames for training and \(42,883\) frames for evaluation. The training set consists of only normal sequences, while the evaluation set consists of \(300,308\) regular frames and \(42,883\) irregular frames. MVTec is a dataset that consists of images of industrial products categorized into 5 texture categories and 10 object categories. To evaluate the unsupervised anomaly detection performance, the training set includes only defect-free (e.g., normal) images: \(3,629\) normal images are available for training while \(1,725\) normal and abnormal images are used as test set. Among the test images, \(1,258\) images contain defects (e.g., abnormal images). For data augmentation, abnormal patches undergo random vertical, horizontal flip and rotation during training, as described in 3.2. We evaluate and compare algorithms in terms of area under the receiver operating characteristic curve (AUROC) and area under the per-region-overlap curve (AUPRO), as used in [4; 20]. AUPRO scores can be found in the supplementary.

**Implementation details.** Following other works [4; 20; 36], our models are trained and evaluated separately for each category. Similar to CFLOW-AD [20], we use \(K\)=3 scales for feature pyramid; normalizing flow consists of \(L\)=8 transformation blocks; the dimension of position embedding vector \(D\) is \(512\); Adam optimizer with a learning rate of 5e-4 and 80 train epochs for training. The loss weight hyperparameters \(\lambda_{1}\) and \(\lambda_{2}\) are set to be \(1.0\) and \(0.2\), respectively. The statistics prediction network \(h\) consists of five convolutional layers with a skip connection as illustrated in Figure 3. At last, we use NVIDIA RTX8000 for training and the model shows near real-time performance by running at 13fps.

### Experimental results

We provide the anomaly localization and detection performance on the STC dataset in Table 1 while the results on MVTec dataset are reported in Table 2 and Table 3. All results presented in this study are obtained using the same backbone architecture, WRN-50 [53], while additional results on MVTec are reported for PatchCore [36] and our method with a larger backbone, WRN-101 [53]. The experimental results demonstrate that the performance of our proposed method is comparable with other state-of-the-art methods. In Table 1, compare to other anomaly detection models that are not video targeted, our method shows outstanding performances in both detection and localization.

\begin{table}
\begin{tabular}{l|c c c c c c c c c} \hline \hline  & **FramePred**[28] & **MemAE**[18] & **SPADE**[8] & **PaDiM**[11] & **CFLOW-AD**[20] & **PatchCore-10**[36] & **SANFlow (Ours)** \\ \hline Image-wise & 72.8 & 71.2 & 71.9 & - & 72.63 & - & **76.1** \\ Pixel-wise & - & - & 89.9 & 91.2 & 94.48 & 91.8 & **94.8** \\ \hline \hline \end{tabular}
\end{table}
Table 1: Anomaly detection and localization results w.r.t. AUROC metric by various methods with WRN-50 backbone for feature extraction on STC [28].

\begin{table}
\begin{tabular}{l|c c c c c c c c c c} \hline \hline \multirow{2}{*}{Category} & \(\frac{AE_{SSIM}}{\lambda}\) & \(\gamma\)-VAE+grad & PatchSVDD & PathSM & CutBase & CFLOW-AD & PatchCore-10 & PatchCore-10 & **SANFlow** & **SANFlow** \\  & WRN-50 & WRN-50 & WRN-50 & WRN-50 & WRN-50 & WRN-50 & WRN-50 & WRN-50 & WRN-101 & WRN-50 & WRN-101 \\ \hline bottle & 89.0 & 93.1 & 98.1 & 98.3 & 97.6 & 98.6 & 98.6 & 98.6 & 98.6 & 98.6 & **99.1** \\ cable & 82.0 & 88.0 & 96.8 & 96.7 & 90.0 & 97.6 & 98.5 & 98.4 & 98.5 & **98.8** \\ capsule & 94.0 & 91.7 & 95.8 & 98.5 & 97.4 & 98.8 & 98.9 & **99.1** & **99.1** & 98.9 \\ carpet & 87.0 & 72.7 & 92.6 & 99.1 & 98.3 & 99.2 & 99.1 & 98.7 & 99.3 & **99.4** \\ grid & 94.0 & 97.9 & 96.2 & 97.3 & 97.5 & 96.8 & 98.7 & 98.7 & 98.5 & **99.3** \\ hazelnut & 97.0 & 98.8 & 97.5 & 98.2 & 97.3 & 98.2 & 98.7 & 98.8 & **99.2** & 99.0 \\ leather & 78.0 & 89.7 & 97.4 & 99.2 & 99.5 & 99.6 & 99.3 & 99.3 & 99.6 & **99.8** \\ metal nut & 89.0 & 91.4 & 98.0 & 97.2 & 93.1 & 98.56 & 98.4 & **98.8** & 98.5 & 98.7 \\ pill & 91.0 & 93.5 & 95.1 & 95.7 & 95.7 & 98.9 & 97.6 & 97.8 & **99.2** & 99.1 \\ screw & 96.0 & 97.2 & 95.7 & 98.5 & 96.7 & 98.0 & **99.4** & 99.3 & 99.0 & 99.2 \\ tile & 59.0 & 58.1 & 91.4 & 94.1 & 90.5 & 97.1 & 95.9 & 96.1 & 98.9 & **99.1** \\ toothnush & 92.0 & 98.3 & 98.1 & 98.8 & 98.1 & 98.5 & 98.7 & 98.8 & 98.9 & **99.2** \\ transistor & 90.0 & 93.1 & 97.0 & **97.5** & 93.0 & 93.2 & 96.4 & 96.4 & 94.4 & 95.1 \\ wood & 73.0 & 80.9 & 90.8 & **94.9** & 95.5 & 94.49 & 95.1 & 95.1 & 96.4 & **97.9** \\ zipper & 88.0 & 87.1 & 95.1 & 98.5 & 99.3 & 98.41 & 98.9 & 98.9 & 98.9 & **99.6** \\ \hline average & 87.0 & 88.8 & 95.7 & 97.5 & 96.0 & 97.9 & 98.1 & 98.2 & 98.5 & **98.8** \\ \hline \hline \end{tabular}
\end{table}
Table 2: Quantitative comparisons on anomaly localization performance in MVTec dataset [4] with respect to AUROC metric. For each category, the best and second best performance is **bolded** and underlined, respectively.

\begin{table}
\begin{tabular}{l|c c c c c c c c c c} \hline \hline \multirow{2}{*}{Category} & GANonly & OCSVM & PatchSVDD & DiffeNet & PalDM & CFLOW-AD & CutBase & PatchCore-10 & PatchCore-10 & **SANFlow** & **SANFlow** \\  & WRN-50 & WRN-50 & WRN-50 & WRN-50 & WRN-50 & WRN-50 & WRN-50 & WRN-50 & WRN-101 & WRN-50 & WRN-101 \\ \hline bottle & 89.2 & 99 & 98.6 & 99.0 & - & **100** & 98.2 & **100** & **100** & **100** & **100** \\ cable & 75.7 & 80.3 & 90.3 & 95.9 & - & 97.59 & 81.2 & 94.4 & 99.6 & 99.4 & **99.7** \\ capsule & 73.2 & 54.4 & 76.7 & 86.9 & - & 97.68 & 95.2 & 97.8 & 95.2 & 97.7 & **95.9** \\ carpet & 69.9 & 62.7 & 92.9 & 92.9 & - & 98.73 & 93.9 & 98.7 & 98.4 & 98.8 &Plus, Table 2 and Table 3 reports that our proposed method performs better than existing NF-based anomaly detection algorithms (CFLOW-AD [20] and DifferNet [37]) and other anomaly detection algorithms such as \(AE_{SSIM}\)[4], \(\gamma\)-VAE+grad [12], PatchSVDD [49], PaDiM [11] and PatchCore-1, 10 [36]. In particular, the results demonstrate the effectiveness of our proposed semantic-aware base distribution mapping approach in enhancing the density estimation performance of the proposed NF model.

### Ablation study

We conduct ablation experiments to evaluate the efficacy of each component of our framework. Specifically, we perform ablation studies on the loss function (Table 4), synthetic anomaly generation (Table 5), and statistics estimated by our statistics prediction network \(h\) (Table 6). All ablation experiments are reported with respect to AUROC, using the WRN-50 backbone, and all average AUROC values over all categories are reported for image-wise anomaly detection.

In Table 4, we analyze the efficacy of our proposed loss functions. To do so, we first compare against a baseline NF model trained using the standard negative log-likelihood loss of NF in Equation 2 (Model **(1a)**). Compared to Model **(1a)**, SANFlow brings substantial improvement, thereby validating the effectiveness of all three proposed loss functions (\(\mathcal{L}_{\text{NLL}}\) in Equation 3 using Equation 5, \(\mathcal{L}_{\text{KL}}\), and \(\mathcal{L}_{\text{ECE}}\)). We validate the efficacy of each loss function separately by applying only \(\mathcal{L}_{\text{NLL}}\) using Equation 3 and 5 (Model **(1b)**) or disabling either \(\mathcal{L}_{\text{KL}}\) (Model **(1c)**) or \(\mathcal{L}_{\text{ECE}}\) (Model **(1d)**). While each variant leads to performance improvement, using all three proposed loss functions leads to the largest improvement, suggesting that all three proposed loss functions coordinate and play critical roles in our overall framework.

In Table 5, we evaluate the impact of synthetic anomaly augmentation (generation) on the final performance of our framework. Training without anomaly augmentation and thus without any anomaly data results in performance degradation (Model **(2a)**). Also, Model **(1d)** (Table 4) which has only difference at doing anomaly augmentation in training, performs better than Model **(2a)**. Thus, the ablation result suggests that not only embedding semantic features to different base distributions but training NF with synthetic anomalies is also an important process. For better understanding, Figure 4 visualizes anomaly score maps based on estimated distribution \(Z^{a}\) **(b)** for test images. As described in Section 3.6, Figure 4 **(a)** can be found with Equation 3 and 6 while Figure 4 **(b)** can be found with Equation 3 and 7. We note that both maps agree on the abnormal region (highlighted with bright colors), validating that training NF to map normal and abnormal features to distant base distributions helps the model discriminate abnormal regions from normal regions.

\begin{table}
\begin{tabular}{c|c c c c c} \hline  & \(\mu_{i}\) & \(\sigma_{i}^{2}\) & STC & MVTec \\ \hline Model **(3a)** & fixed & fixed & 75.9 & 97.6 \\ Model **(3b)** & estimated & fixed & 75.1 & 97.0 \\ Model **(3c)** & estimated & estimated & 74.5 & 98.1 \\
**SAFNlow (Ours)** & fixed & estimated & **76.1** & **98.7** \\ \hline \end{tabular}
\end{table}
Table 6: Ablation study on statistics estimation in MVTec and STC datasets.

Figure 4: Visualization of anomaly score map based on **(a)**\(Z^{n}\) and **(b)**\(Z^{a}\) on MVTec dataset.

\begin{table}
\begin{tabular}{c|c c c c c c} \hline  & \(C_{\text{NLL}}\) & \(\mathcal{L}_{\text{OCE}}\) & \(\mathcal{L}_{\text{KL}}\) & STC & MVTec \\ \hline Model **(1d)** & \(\mathcal{L}_{\text{E}}\)(2) & ✗ & ✗ & ✗ & 72.6 & 98.3 \\ Model **(1e)** & Eq. **(3)**(3)**(5) & ✗ & ✗ & 73.5 & 98.2 \\ Model **(1e)** & Eq. **(3)**(3)**(5) & ✗ & ✗ & 73.1 & 98.3 \\ Model **(1e)** & Eq. **(3)**(3)**(5) & ✗ & ✓ & 74.2 & 98.5 \\
**SAFNlow** & ✗ & ✓ & ✓ & **76.1** & **98.7** \\ \hline \end{tabular}
\end{table}
Table 4: Ablation study on loss functions in MVTec and STC datasets.

Table 6 reports ablation results after fixing either mean (\(\mu_{i}\)), variance (\(\sigma_{i}^{2}\)), or both statistics of base distributions. If \(\mu_{i}\) is fixed, it is set to be \(0\) for normal features and \(1\) for abnormal features. If \(\sigma_{i}^{2}\) is fixed, it is empirically set to be \(0.1\) for both normal and abnormal features. The performance is observed to decrease noticeably when \(\mu_{i}\) is estimated alone (Model **(3b)**) or together with \(\sigma_{i}^{2}\) (Model **(3c)**). On the other hand, estimating only \(\sigma_{i}^{2}\) while fixing \(\mu_{i}\) brings significant performance improvement. The performance degradation from estimating \(\mu_{i}\) may be due to learning complexity. Furthermore, to enhance the persuasiveness of the mean margin, we conducted additional experiments on the MVTec dataset, comparing performance at margin values of 0.5, 1.0, and 1.5 in WRN-50 backbone. For margin values 0.5, 1.0, and 1.5, the proposing method shows 98.6, 98.7, and 98.1 AUROC for image-wise and 98.4, 98.5, and 98.3 AUROC for pixel-wise. As the margin of 1.0 yields the highest results in both image- and pixel- wise, we could confirm that the mean margin of 1.0 is a persuasive choice.

### Experiments on other datasets

Although the MVTec dataset is a benchmark that is widely used for anomaly detection and localization, there is difficulty in identifying the advantage of the proposing method with it due to performance saturation. Therefore, we provide a performance comparison in the VisA dataset [58]. Our proposed method with a WRN-50 backbone achieves an image-wise AUROC of 93.4, 98.6, and a PRO score of 89.4, while CFLOW-AD [20] and PaDiM [11] achieve 91.5, 59.8, and 89.1, 85.9 of an image-wise AUROC and a PRO score, respectively. The results show that our approach demonstrates competitive performance against other methods, including other flow-based approaches, demonstrating the effectiveness of our framework in greatly improving the density estimation capability of normalizing flow for anomaly detection and localization. Plus, while our approach excels at detecting anomalies within images, its effectiveness in tasks involving image-wise semantic outlier detection, like CutPaste [26] and CFLOW-AD, is limited. Nonetheless, we conducted an additional experiment with CIFAR-10 [24], where our proposed method achieved an AUROC of 80.8, outperforming performances of CutPaste (69.4) and CFLOW-AD (79.32).

## 5 Conclusion

In this work, we propose to improve the density estimation of normalizing flow (NF) for anomaly detection, by training NF to dynamically embed given feature distribution to different base distributions. In particular, base distributions are Gaussian distribution with statistics estimated by our statistics prediction network. As a result, our NF framework learns to map not only diverse normal features but also abnormal features to corresponding yet different base distributions, enhancing the density estimation capability.

**Limitation** While SANFlow has the capability of mapping different semantic features to different base distributions, it requires anomaly augmentation to map anomaly features to a base distribution distant from base distributions of normal features for better anomaly detection. However, augmentations require domain knowledge and do not cover new anomalies that may occur. But, we would like to note that our ablation study reveals that our framework brings improvements even without anomaly augmentation. Nonetheless, reducing the dependence on anomaly augmentations in the proposed framework is an interesting future research direction.

**Broader Impacts** Finding anomalies in product during fabrication is important to ensure the quality of products. Anomaly detection algorithms can automate the process, which can offload the burden from human workers. This will allow human workers to focus on other important aspects of fabrication, improving the overall process of fabrication and thus the quality of products. Furthermore, anomaly detection can be used to frequently check anomalies of objects that may be difficult for humans but crucial to human safety (e.g., tall buildings, bridges, nuclear power plants, etc.).

**Acknowledgements** This work was supported by Institute of Information & communications Technology Planning & Evaluation (IITP) grant funded by the Korea government(MSIT) (No. RS-2023-00220628, Artificial intelligence for prediction of structure-based protein interaction reflecting physicochemical principles, 50%) and Samsung Electronics Co., Ltd, and Samsung Research Funding Center of Samsung Electronics (No. SRFCTI1901- 06, 50%).

## References

* [1] Samet Akcay, Amir Atapour-Abarghouei, and Toby P Breckon. Ganomaly: Semi-supervised anomaly detection via adversarial training. In _Proceedings of the Asian Conference on Computer Vision (ACCV)_. Springer, 2018.
* [2] Lynton Ardizzone, Carsten Luth, Jakob Kruse, Carsten Rother, and Ullrich Kothe. Guided image generation with conditional invertible neural networks. _arXiv preprint arXiv:1907.02392_, 2019.
* [3] Lynton Ardizzone, Radek Mackowiak, Carsten Rother, and Ullrich Kothe. Training normalizing flows with the information bottleneck for competitive generative classification. In _Advances in Neural Information Processing Systems (NeurIPS)_, 2020.
* [4] Paul Bergmann, Michael Fauser, David Sattlegger, and Carsten Steger. Mvtec ad-a comprehensive real-world dataset for unsupervised anomaly detection. In _Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)_, 2019.
* [5] Paul Bergmann, Michael Fauser, David Sattlegger, and Carsten Steger. Uninformed students: Student-teacher anomaly detection with discriminative latent embeddings. In _Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)_, 2020.
* [6] Paul Bergmann, Sindy Lowe, Michael Fauser, David Sattlegger, and Carsten Steger. Improving unsupervised defect segmentation by applying structural similarity to autoencoders. _arXiv preprint arXiv:1807.02011_, 2018.
* [7] Victor Besnier, Andrei Bursuc, David Picard, and Alexandre Briot. Triggering failures: Out-of-distribution detection by learning from local adversarial attacks in semantic segmentation. In _Proceedings of the IEEE International Conference on Computer Vision (ICCV)_, pages 15701-15710, 2021.
* [8] Niv Cohen and Yedid Hoshen. Sub-image anomaly detection with deep pyramid correspondences. _arXiv preprint arXiv:2005.02357_, 2020.
* [9] Yajie Cui, Zhaoxiang Liu, and Shiguo Lian. A survey on unsupervised industrial anomaly detection algorithms. _arXiv preprint arXiv:2204.11161_, 2022.
* [10] Lucas Deecke, Robert Vandermeulen, Lukas Ruff, Stephan Mandt, and Marius Kloft. Image anomaly detection with generative adversarial networks. In _Joint european conference on machine learning and knowledge discovery in databases_. Springer, 2018.
* [11] Thomas Defard, Aleksandr Setkov, Angelique Loesch, and Romaric Audigier. Padim: A patch distribution modeling framework for anomaly detection and localization. In _Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)_, pages 475-489, 2021.
* [12] David Dehaene, Oriel Frigo, Sebastien Combrexelle, and Pierre Eline. Iterative energy-based projection on a normal data manifold for anomaly localization. In _Proceedings of the International Conference on Learning Representations (ICLR)_, 2020.
* [13] Terrance DeVries and Graham W Taylor. Improved regularization of convolutional neural networks with cutout. _arXiv preprint arXiv:1708.04552_, 2017.
* [14] Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio. Density estimation using real nvp. _arXiv preprint arXiv:1605.08803_, 2016.
* [15] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. In _Proceedings of the International Conference on Learning Representations (ICLR)_, 2021.
* [16] Spyros Gidaris, Praveer Singh, and Nikos Komodakis. Unsupervised representation learning by predicting image rotations. _arXiv preprint arXiv:1803.07728_, 2018.

* [17] Izhak Golan and Ran El-Yaniv. Deep anomaly detection using geometric transformations. In _Advances in Neural Information Processing Systems (NeurIPS)_, volume 31, 2018.
* [18] Dong Gong, Lingqiao Liu, Vuong Le, Budhaditya Saha, Moussa Reda Mansour, Svetha Venkatesh, and Anton van den Hengel. Memorizing normality to detect anomaly: Memory-augmented deep autoencoder for unsupervised anomaly detection. In _Proceedings of the IEEE International Conference on Computer Vision (ICCV)_, 2019.
* [19] Matej Grcic., Petra Bevandic., and Sinisa Segvic. Dense open-set recognition with synthetic outliers generated by real nvp. In _Proceedings of the International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications (VISAPP)_, pages 133-143. INSTICC, SciTePress, 2021.
* [20] Denis Gudovskiy, Shun Ishizaka, and Kazuki Kozuka. Cflow-ad: Real-time unsupervised anomaly detection with localization via conditional normalizing flows. In _Proceedings of the IEEE Winter Conference on Applications of Computer Vision (WACV)_, 2022.
* [21] Dan Hendrycks, Mantas Mazeika, Saurav Kadavath, and Dawn Song. Using self-supervised learning can improve model robustness and uncertainty. In _Advances in Neural Information Processing Systems (NeurIPS)_, volume 32, 2019.
* [22] Pavel Izmailov, Polina Kirichenko, Marc Finzi, and Andrew Gordon Wilson. Semi-supervised learning with normalizing flows. In _International Conference on Machine Learning (ICML)_. PMLR, 2020.
* [23] Shu Kong and Deva Ramanan. Opengan: Open-set recognition via open data generation. In _Proceedings of the IEEE International Conference on Computer Vision (ICCV)_, pages 813-822, 2021.
* [24] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.
* [25] Kimin Lee, Kibok Lee, Honglak Lee, and Jinwoo Shin. Training confidence-calibrated classifiers for detecting out-of-distribution samples. In _Proceedings of the International Conference on Learning Representations (ICLR)_, 2018.
* [26] Chun-Liang Li, Kihyuk Sohn, Jinsung Yoon, and Tomas Pfister. Cutpaste: Self-supervised learning for anomaly detection and localization. In _Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)_, 2021.
* [27] Tsung-Yi Lin, Piotr Dollar, Ross Girshick, Kaiming He, Bharath Hariharan, and Serge Belongie. Feature pyramid networks for object detection. In _Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)_, 2017.
* [28] Wen Liu, Weixin Luo, Dongze Lian, and Shenghua Gao. Future frame prediction for anomaly detection-a new baseline. In _Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)_, 2018.
* [29] Wenjie Luo, Yujia Li, Raquel Urtasun, and Richard Zemel. Understanding the effective receptive field in deep convolutional neural networks. In _Advances in Neural Information Processing Systems (NeurIPS)_, 2016.
* [30] Prasanta Chandra Mahalanobis. On the generalized distance in statistics. _Sankhya: The Indian Journal of Statistics, Series A (2008-)_, 80:S1-S7, 2018.
* [31] Stanislav Pidhorskyi, Ranya Almohsen, and Gianfranco Doretto. Generative probabilistic novelty detection with adversarial autoencoders. In _Advances in Neural Information Processing Systems (NeurIPS)_, 2018.
* [32] Jonathan Pirnay and Keng Chai. Inpainting transformer for anomaly detection. In _International Conference on Image Analysis and Processing_, 2022.
* [33] Danilo Jimenez Rezende and Shakir Mohamed. Variational inference with normalizing flows. In _International Conference on Machine Learning (ICML)_, 2015.

* [34] Oliver Rippel, Patrick Mertens, and Dorit Merhof. Modeling the distribution of normal data in pre-trained deep features for anomaly detection. In _International Conference on Pattern Recognition_. IEEE, 2021.
* [35] Nicolae-Catalin Ristea, Neelu Madan, Radu Tudor Ionescu, Kamal Nasrollahi, Fahad Shahbaz Khan, Thomas B Moeslund, and Mubarak Shah. Self-supervised predictive convolutional attentive block for anomaly detection. In _Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)_, 2022.
* [36] Karsten Roth, Latha Pemula, Joaquin Zepeda, Bernhard Scholkopf, Thomas Brox, and Peter Gehler. Towards total recall in industrial anomaly detection. In _Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)_, 2022.
* [37] Marco Rudolph, Bastian Wandt, and Bodo Rosenhahn. Same same but differnet: Semi-supervised defect detection with normalizing flows. In _Proceedings of the IEEE Winter Conference on Applications of Computer Vision (WACV)_, 2021.
* [38] Marco Rudolph, Tom Wehrbein, Bodo Rosenhahn, and Bastian Wandt. Fully convolutional cross-scale-flows for image-based defect detection. In _Proceedings of the IEEE Winter Conference on Applications of Computer Vision (WACV)_, 2022.
* [39] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, and Li Fei-Fei. Imagenet large scale visual recognition challenge. _International Journal of Computer Vision (IJCV)_, 115(3):211-252, 2015.
* [40] Mohammad Sabokrou, Mohammad Khalooei, Mahmood Fathy, and Ehsan Adeli. Adversarially learned one-class classifier for novelty detection. In _Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)_, 2018.
* [41] Mayu Sakurada and Takehisa Yairi. Anomaly detection using autoencoders with nonlinear dimensionality reduction. In _Proceedings of the MLSDA 2014 2nd workshop on machine learning for sensory data analysis_, 2014.
* [42] Thomas Schlegl, Philipp Seebock, Sebastian M Waldstein, Ursula Schmidt-Erfurth, and Georg Langs. Unsupervised anomaly detection with generative adversarial networks to guide marker discovery. In _International conference on information processing in medical imaging_. Springer, 2017.
* [43] Tareq Tayeh, Sulaiman Aburakhia, Ryan Myers, and Abdallah Shami. Distance-based anomaly detection for industrial surfaces using triplet networks. In _2020 11th IEEE Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON)_, pages 0372-0377. IEEE, 2020.
* [44] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. In _Advances in Neural Information Processing Systems (NeurIPS)_, 2017.
* [45] Shashanka Venkataramanan, Kuan-Chuan Peng, Rajat Vikram Singh, and Abhijit Mahalanobis. Attention guided anomaly localization in images. In _Proceedings of the European Conference on Computer Vision (ECCV)_. Springer, 2020.
* [46] Shenzhi Wang, Liwei Wu, Lei Cui, and Yujun Shen. Glancing at the patch: Anomaly localization with global and local feature comparison. In _Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)_, 2021.
* [47] Ze Wang, Yipin Zhou, Rui Wang, Tsung-Yu Lin, Ashish Shah, and Ser Nam Lim. Few-shot fast-adaptive anomaly detection. _Advances in Neural Information Processing Systems (NeurIPS)_, 2022.
* [48] Jie Yang, Yong Shi, and Zhiquan Qi. Unsupervised anomaly segmentation via deep feature reconstruction. _Neurocomputing_, 2021.

* [49] Jihun Yi and Sungroh Yoon. Patch svdd: Patch-level svdd for anomaly detection and segmentation. In _Proceedings of the Asian Conference on Computer Vision (ACCV)_, 2020.
* [50] Hongwei Yong, Deyu Meng, Wangmeng Zuo, and Lei Zhang. Robust online matrix factorization for dynamic background subtraction. _IEEE Transactions on Pattern Analysis and Machine Intelligence_, 40(7):1726-1740, 2018.
* [51] Jiawei Yu, Ye Zheng, Xiang Wang, Wei Li, Yushuang Wu, Rui Zhao, and Liwei Wu. Fastflow: Unsupervised anomaly detection and localization via 2d normalizing flows. _arXiv preprint arXiv:2111.07677_, 2021.
* [52] Zongsheng Yue, Hongwei Yong, Qian Zhao, Lei Zhang, and Deyu Meng. Variational denoising network: Toward blind noise modeling and removal. In _Advances in Neural Information Processing Systems (NeurIPS)_, 2019.
* [53] Sergey Zagoruyko and Nikos Komodakis. Wide residual networks. In _Proceedings of the British Machine Vision Conference (BMVC)_, 2016.
* a discriminatively trained reconstruction embedding for surface anomaly detection. In _Proceedings of the IEEE International Conference on Computer Vision (ICCV)_, 2021.
* [55] Vitjan Zavrtanik, Matej Kristan, and Danijel Skocaj. Reconstruction by inpainting for visual anomaly detection. _Pattern Recognition_, 2021.
* [56] Ye Zheng, Xiang Wang, Rui Deng, Tianpeng Bao, Rui Zhao, and Liwei Wu. Focus your distribution: Coarse-to-fine non-contrastive learning for anomaly detection and localization. In _International Conference on Multimedia and Expo (ICME)_, 2022.
* [57] Bo Zong, Qi Song, Martin Renqiang Min, Wei Cheng, Cristian Lumezanu, Daeki Cho, and Haifeng Chen. Deep autoencoding gaussian mixture model for unsupervised anomaly detection. In _Proceedings of the International Conference on Learning Representations (ICLR)_, 2018.
* [58] Yang Zou, Jongheon Jeong, Latha Pemula, Dongqing Zhang, and Onkar Dabeer. Spot-the-difference self-supervised pre-training for anomaly detection and segmentation. In _Proceedings of the European Conference on Computer Vision (ECCV)_, pages 392-408. Springer, 2022.

Loss Function Derivation

In this section, we show the detailed derivations for Equation 4 in Section 3.4.2 and Equation 6 and 7 in Section 3.5.

### KL-Divergence

We present the detailed derivations of our KL divergence loss \(\mathcal{L}_{\text{KL}}\), where \(IG(\alpha_{i},\beta_{i})\) and \(IG(\alpha,\beta)\) represent the probability density function of the inverse Gamma distribution with their corresponding parameters \(\alpha_{i},\beta_{i}\) and \(\alpha,\beta\). Furthermore, \(\bm{s}_{i}\) and \(\bm{s}\) denote random variables that follow the corresponding distributions \(IG(\alpha_{i},\beta_{i})\) and \(IG(\alpha,\beta)\), respectively. The detailed formulations are as follows:

\[\begin{split}\mathcal{L}_{KL}&=D_{KL}(IG(\alpha_{ i},\beta_{i})\,|\,IG(\alpha,\beta))\\ &=\sum_{i=1}^{H_{k}\times W_{k}}E[\log IG(\alpha_{i},\beta_{i})- \log IG(\alpha,\beta)]\\ &=\sum_{i=1}^{H_{k}\times W_{k}}\{E[-\log IG(\alpha,\beta)]-E[- \log IG(\alpha_{i},\beta_{i})]\}\\ &=\sum_{i=1}^{H_{k}\times W_{k}}\{E[-\alpha\log\beta+\log\Gamma( \alpha)+(\alpha+1)\log\bm{s}+\frac{\beta}{\bm{s}}]\\ &\hskip 28.452756pt-E[-\alpha_{i}\log\beta_{i}+\log\Gamma(\alpha_ {i})+(\alpha_{i}+1)\log\bm{s}_{i}+\frac{\beta_{i}}{\bm{s}_{i}}]\}\\ &=\sum_{i=1}^{H_{k}\times W_{k}}\{[\alpha+\log\beta\Gamma(\alpha) -(\alpha+1)\psi(\alpha)]-[\alpha_{i}+\log\beta_{i}\Gamma(\alpha_{i})-(\alpha_ {i}+1)\psi(\alpha_{i})]\}\\ &=\sum_{i=1}^{H_{k}\times W_{k}}\{(\alpha_{i}-\alpha)\psi(\alpha_ {i})+(\log\Gamma(\alpha)-\log\Gamma(\alpha_{i}))+\alpha(\log\beta_{i}-\log \beta)+\alpha_{i}(\frac{\beta}{\beta_{i}}-1)\}.\end{split}\] (S1)

### Log-likelihood Derivation

To calculate the semantic-aware variance \(\sigma_{i}\) for log-likelihood computation, we approximate it using the mode value (\(\sigma_{i}\)) from the inverse Gamma distribution \(IG(\alpha_{i},\beta_{i})\). This approximation is employed for computational efficiency, following the approach used in VDNet [52]. Therefore, in Equation S2 and Equation S3, we use \(h(\sigma_{i}^{2}|\bm{x})\) that predicts statistics of semantic-aware variances (i.e., \(\sigma_{i}\)) from input image \(\bm{x}\) as:

\[\begin{split}\log p_{z_{i}^{n}}(\bm{z}_{i})&=E_{h( \sigma_{i}^{2}|\bm{x})}[\log p(\bm{z}_{i}|0,\sigma_{i}^{2})]\\ &=\int h(\sigma_{i}^{2}|\bm{x})\log p(\bm{z}_{i}|0,\sigma_{i}^{2} )d\sigma^{2}\\ &=\int h(\sigma_{i}^{2}|\bm{x})\{-\frac{1}{2}\log 2\pi-\frac{1}{ 2}\log\sigma_{i}^{2}-\frac{||\bm{z}_{i}||_{2}^{2}}{2\sigma_{i}^{2}}\}d\sigma^{ 2}\\ &=-\frac{1}{2}\log 2\pi-\frac{1}{2}\int h(\sigma_{i}^{2}|\bm{x}) \log\sigma_{i}^{2}d\sigma_{i}^{2}-\frac{1}{2}||\bm{z}_{i}||_{2}^{2}\int h( \sigma_{i}^{2}|\bm{x})\frac{1}{\sigma_{i}^{2}}d\sigma_{i}^{2}\\ &=-\frac{1}{2}\log 2\pi-\frac{1}{2}E[\log\sigma_{i}^{2}]-\frac{1}{ 2}||\bm{z}_{i}||_{2}^{2}E[\frac{1}{\sigma_{i}^{2}}]\\ &=-\frac{1}{2}\log 2\pi-\frac{1}{2}(\log\beta_{i}-\psi(\alpha_{i}))- \frac{\alpha_{i}}{2\beta_{i}}||\bm{z}_{i}||_{2}^{2},\end{split}\] (S2)and

\[\log p_{Z_{i}^{n}}(\bm{z}_{i}) =E_{h(\sigma_{i}^{2}|\bm{x})}[\log p(\bm{z}_{i}|1,\sigma_{i}^{2})]\] (S3) \[=\int h(\sigma_{i}^{2}|\bm{x})\log p(\bm{z}_{i}|1,\sigma_{i}^{2})d \sigma^{2}\] \[=\int h(\sigma_{i}^{2}|\bm{x})\{-\frac{1}{2}\log 2\pi-\frac{1}{2} \log\sigma_{i}^{2}-\frac{||\bm{z}_{i}-1||_{2}^{2}}{2\sigma_{i}^{2}}\}d\sigma^{2}\] \[=-\frac{1}{2}\log 2\pi-\frac{1}{2}\int h(\sigma_{i}^{2}|\bm{x}) \log\sigma_{i}^{2}d\sigma_{i}^{2}-\frac{1}{2}||\bm{z}_{i}-1||_{2}^{2}\int h( \sigma_{i}^{2}|\bm{x})\frac{1}{\sigma_{i}^{2}}d\sigma_{i}^{2}\] \[=-\frac{1}{2}\log 2\pi-\frac{1}{2}E[\log\sigma_{i}^{2}]-\frac{1}{2} ||\bm{z}_{i}-1||_{2}^{2}E[\frac{1}{\sigma_{i}^{2}}]\] \[=-\frac{1}{2}\log 2\pi-\frac{1}{2}(\log\beta_{i}-\psi(\alpha_{i})) -\frac{\alpha_{i}}{2\beta_{i}}||\bm{z}_{i}-1||_{2}^{2}.\]

## Appendix B Implementation Details

### Hyperparameters

As described in the main manuscript, our overall framework comprises a pre-trained feature extractor \(f\), a normalizing flow \(g\), and a statistics prediction network \(h\). For the feature extraction process, we utilize a multi-scale feature pyramid approach. Specifically, we extract features from three different scales (\(K=3\)) using a pre-trained feature extractor. Regarding the normalizing flow model, we employ \(L=8\) transformation blocks for each scale.

Similar to VDNet [52], our statistics prediction network takes an image as input and consists of five convolutional layers and a skip-connection. Each convolutional layer comprises 64 filters with a size of \(3\times 3\) except for the last layer. In particular, the last layer of the statistics prediction network produces a two-channel output: one for \(\alpha\) and the other for \(\beta\).

During training phase on the MVTec dataset [4], we fixed the learning rate to 5e-4. Moreover, we empirically determined the hyperparameters \(\lambda_{1}\) and \(\lambda_{2}\). Specifically, we selected the values for \(\lambda_{1}\) and \(\lambda_{2}\) from the set \(\{0.1,0.2,0.3,0.5,1.0,2.0\}\) based on their impact on the validation results, and we use \(\lambda_{1}=1.0\) and \(\lambda_{2}=0.2\).

As for STC (ShanghaiTech Campus) dataset [28], all training details and hyperparameters are the same, except for a learning rate that is set to be \((2e^{-4})\).

### Data Augmentation

* Small-sized rectangular shaped mask: \(2\leq H\leq 32\), \(10\leq W\leq 50\)
* Medium-sized rectangular shaped mask: \(16\leq H\leq 64\), \(64\leq W\leq 256\)
* Circular shaped mask: \(10\leq radius\leq 25\)

To generate anomaly data, we first extracted patches based on the masks described above. These masks corresponded to small and medium-sized rectangular shapes, as well as circular shapes. Subsequently, the extracted patches underwent distortions to simulate anomalies, where we randomly perform color jittering between 0 and 0.1 (brightness, contrast, saturation, and hue). Additionally, we introduce random horizontal and vertical flips to further augment the dataset. These patches are then applied at the random locations of normal images from the same category. Figures S1 and S2 present categorical examples of synthetic anomaly images, with anomalies generated using rectangular patches in Figure S1 and circular patches in Figure S2.

We constructed a batch of size 8 by including an equal number of normal images and three types of abnormal images, with each type corresponding to a specific mask shape. This ensured a balanced representation of normal and abnormal samples within the batch, allowing for effective training of our model.

[MISSING_PAGE_EMPTY:17]

during inference, there are instances where it tends to segment only localized regions or produce high scores in unrelated areas. This may be due to discrepancies between abnormal augmentation used during training and actual anomalies during test. Since, \(s(\bm{z}_{i})\) is computed based on both negative log-likelihood (NLL) of normal and abnormal features, it is necessary for the model to project normal and abnormal features precisely. However, Figure S5 illustrates that the projection of abnormal features is not as accurate as as normal features, showing unsatisfactory results with \(s(\bm{z}_{i})\) as a anomaly scoring function. Therefore, it does not exhibit suitability comparable to NLL for anomaly scoring. In the future, we have plans to utilize \(s(\bm{z}_{i})\) for performance enhancement.

### Additional Analysis for Table 6

While estimating both mean and variance to give higher performance due to more flexibility gives a high expectation for the performances, we observe that giving too much flexibility and increasing training difficulty, thereby resulting in performance degradation as observed in Table 6 of the main paper and Figure S6. To better support the claim, we allow the model to estimate both mean and variance (i.e., Model (**3c**)) and plot the distribution of estimated mean by utilizing histogram in Figure S6. Graphs demonstrates that there are significant degree of overlap between normal (blue) and abnormal (orange) distributions, when considering variance as well.

Figure S3: Visualization of anomaly score maps produced by our proposed framework and Model **(2a)** on texture and object categories of MVTec benchmark dataset. From top to bottom: GT mask, anomaly score map of proposed model and anomaly score map of Model **(2a)**.

Figure S6: Results of Model **(3c)** (model that estimates both mean and variance), including ground truth, score map, prediction, normal mean estimated map, abnormal mean estimated map and histogram. For histogram plots, each displays estimated mean distribution of normal and abnormal features for each category: bottle, cable, and zipper. Orange part of histogram represents estimated abnormal means and blue part of histogram represents estimated normal means.

[MISSING_PAGE_EMPTY:21]