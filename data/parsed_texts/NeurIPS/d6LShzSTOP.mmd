# Unsupervised Image Denoising with Score Function

Yutong Xie

Peking University

yutongxie_research@163.com &Mingze Yuan

Peking University

mzyuan@pku.edu.cn Bin Dong

Peking University

dongbin@bicmr.pku.edu.cn &Quanzheng Li

Massachusetts General Hospital and Harvard Medical School

li.quanzheng@mgh.harvard.edu

###### Abstract

Though achieving excellent performance in some cases, current unsupervised learning methods for single image denoising usually have constraints in applications. In this paper, we propose a new approach which is more general and applicable to complicated noise models. Utilizing the property of score function, the gradient of logarithmic probability, we define a solving system for denoising. Once the score function of noisy images has been estimated, the denoised result can be obtained through the solving system. Our approach can be applied to multiple noise models, such as the mixture of multiplicative and additive noise combined with structured correlation. Experimental results show that our method is comparable when the noise model is simple, and has good performance in complicated cases where other methods are not applicable or perform poorly.

## 1 Introduction

Image denoising [4, 20, 26] has been studied for many years. Suppose \(\mathbf{x}\) is a clean image, \(\mathbf{y}\) is a noisy image of \(\mathbf{x}\), and \(p\left(\mathbf{y}\mid\mathbf{x}\right)\) is the noise model. Supervised learning methods try to train a model representing a mapping from \(\mathbf{y}\) to \(\mathbf{x}\). Due to the difficulty of collecting paired clean and noisy images in practice, methods in unsupervised learning manner are focus of research. Noise2Noise [12] is the first to use pairs of two different noisy images constructed from the same clean image to train a denoising model. Strictly speaking, Noise2Noise is not an unsupervised learning method. Collecting noisy pairs is still difficult. Despite all this, many other methods [2, 10, 11, 24, 25] are inspired from Noise2Noise or borrow the idea behind of it. These methods achieve good performance in some simple noise models.

The main drawback of current methods is the constraint of application. Once the noise model is complicated, they either are not applicable or have poor performance. Noisier2Noise [16] can only handle additive noise and pepper noise. Recorrupted-to-Recorrupted [17] is limited to Gaussian noise. Neighbor2Neighbor [7] requires that the noise model is pixel-wise independent and unbiased (_i.e._\(\mathbb{E}\left[\mathbf{y}\mid\mathbf{x}\right]=\mathbf{x}\)). Noise2Score [9] applies Tweedie's Formula to image denoising and provides a unified framework for those noise models that follow exponential family distributions. However, the practical noise model will be more complicated. It may contain both multiplicative and additive noise, even combining with structural correlation.

In this paper, we propose a new unified approach to handle more noise models. The key of our approach is a theoretical property about score function, \(\nabla_{\mathbf{y}}\log p(\mathbf{y})\), which is shown in Proposition 3.1. This property indicates that the score function of \(\mathbf{y}\) is the average of the score function of \(\mathbf{y}\mid\mathbf{x}\) under the posterior distribution \(p\left(\mathbf{x}\mid\mathbf{y}\right)\). Based on it, we define a system that the score function of \(\mathbf{y}\) equals to the score function of \(\mathbf{y}\mid\mathbf{x}\), which turns out to be an equation about \(\mathbf{x}\) since \(\mathbf{y}\) is known. Wediscover that the solution of this equation can be regarded as the denoised result of \(\mathbf{y}\). Implementing our approach practically contains two steps: the first is to estimate the score function of \(\mathbf{y}\) and the second is to solve the system defined above according to the specific noise model. The overall flow is shown in Figure 1. All the model training is the estimation of score function, which is represented by a neural network. We adapt the amortized residual denoising autoencoder (AR-DAE) [13] to figure out it. More details can be seen in Section 3.3.

Our approach is so powerful that as long as the score function of \(\mathbf{y}\mid\mathbf{x}\) is known and the system is solvable, any kind of noise model is applicable. It means our approach is even able to solve sophisticated noise models such as mixture noise. Another advantage of our approach is that regardless of noise models, the training process of the score function neural network is identical. Therefore, once the assumption of the noise model does not hold or parameters of noise are corrected, we only change the equation system to be solved and resolve it without training the model again. In summary, our main contribution are: (1) We propose a general unsupervised approach for image denoising, which is based on the score function. (2) Experimental results show that our approach is competitive for simple noise models and achieves excellent performance for complicated noise models where other unsupervised methods is invalid.

## 2 Related Works

Here we briefly review the existing deep learning methods for image denoising. When the pairs of clean images and noisy images are available, the supervised training [26] is to minimize \(\mathbb{E}_{\mathbf{x},\mathbf{y}}\left[\mathrm{d}\left(\mathbf{x},f(\mathbf{y};\theta)\right)\right]\), where \(f(\cdot;\theta)\) is a neural network and \(\mathrm{d}\left(\cdot,\cdot\right)\) is a distance metric. Though supervised learning has great performance, the difficult acquisition for training data hampers its application in practice.

To avoid the issues of acquisition for paired clean and noisy images, unsupervised1 approaches are proposed to use noisy image pairs to learn image denoising, which is started from Noise2Noise (N2N) [12]. While N2N can achieve comparable results with supervised methods, collecting noisy image pairs from real world is still intracTable Motivated by N2N, the followed-up works try to learn image denoising with individual noisy images. Mask-based unsupervised approaches [2] design mask schemes for denoising on individual noisy images and then they train the network to predict the masked pixels according to noisy pixels in the input receptive field. Noise2Void [10] also proposes the blind-spot network (BSN) to avoid learning the identity function. Noisier2Noise [16], Noisy-A-Clean [25] and Recorrupted-to-Recorrupted [17] require a single noisy realization of each training sample and a statistical model of the noise distribution. Noisier2Noise first generates a synthetic noisy sample from the statistical noise model, adds it to the already noisy image, and asks the network to predict the original noisy image from the doubly noisy image. Besides the blind-spot network design, Self2Self [19] is proposed on blind denoising to generate paired data from a single noisy image by applying Bernoulli dropout. Recently, Neighbor2Neighbor [7] proposes to create subsampled paired images based on the pixel-wise independent noise assumption and then a denoising network is trained on generated pairs, with additional regularization loss for better performance. Noise2Score [9] is another type of unsupervised methods that can deal with any noise model which follows an exponential family distribution. It utilize Tweedie's Formula [21; 6] and the estimation of score function to denoise noisy images.

Footnote 1: Sometimes self-supervised is used.

Figure 1: The overall flow of our approach. The first step is to estimate the score function \(\mathbf{s}(\mathbf{y})\) and the second step is to solve an equation.

[MISSING_PAGE_FAIL:3]

**Theorem 3.1**: _Given \(\mathbf{y}\), suppose the Hessian matrix \(\mathbf{f}\left(\mathbf{x},\mathbf{y}\right)\) is bounded, \(\mathbf{f}\left(\mathbf{x},\mathbf{y}\right)\) is invertible with respect to \(\mathbf{x}\), and its inverse function is Lipschitz continuous. Denote \(\hat{\mathbf{x}}\) as the solution of Eq. 7, then,_

\[\left\|\hat{\mathbf{x}}-\mathbb{E}_{\mathbf{x}\mid\mathbf{y}}\left[\mathbf{x}\right]\right\|_{2 }\leq C\mathrm{Tr}\left(\mathrm{Cov}\left[\mathbf{x}\mid\mathbf{y}\right]\right)+o\left( \mathrm{Tr}\left(\mathrm{Cov}\left[\mathbf{x}\mid\mathbf{y}\right]\right)\right), \tag{8}\]

_where \(\mathrm{Cov}\left[\mathbf{x}\mid\mathbf{y}\right]\) is the covariance matrix and \(C\) is a constant._

The proof of Theorem 3.1 is in Supplementary Material. Theorem 3.1 shows the lower noise level, the smaller the error between \(\hat{\mathbf{x}}\) and \(\mathbb{E}_{\mathbf{x}\mid\mathbf{y}}\left[\mathbf{x}\right]\), which guarantees the effectiveness of proposed method.

Next, in Section 3.2 we will derive the specific algorithm for solving \(\mathbf{x}\) in Eq. 7 under different noise models, including additive Gaussian noise in Section 3.2.1, multiplicative noise in Section 3.2.2 and mixture noise in Section 3.2.3. Estimating score function \(\mathbf{s}\left(\mathbf{y}\right)\) will be introduced in Section 3.3.

### Application Examples

#### 3.2.1 Additive Gaussian Noise

Suppose the noise model is \(\mathbf{y}=\mathbf{x}+\mathbf{\epsilon}\) where \(\mathbf{\epsilon}\) follows a multi-variable Gaussian distribution with mean of \(\mathbf{0}\) and covariance matrix of \(\mathbf{\Sigma}\) denoted by \(\mathcal{N}\left(\mathbf{0},\mathbf{\Sigma}\right)\), _i.e._

\[p\left(\mathbf{y}\mid\mathbf{x}\right)=\frac{\exp\left\{-\frac{1}{2}\left(\mathbf{y}-\mathbf{x }\right)^{\top}\mathbf{\Sigma}^{-1}\left(\mathbf{y}-\mathbf{x}\right)\right\}}{\sqrt{2\pi ^{d}}\left|\mathbf{\Sigma}\right|^{\frac{1}{2}}} \tag{9}\]

Then, we derive that \(\mathbf{f}\left(\mathbf{x},\mathbf{y}\right)=\nabla_{\mathbf{y}}\log p\left(\mathbf{y}\mid\mathbf{x} \right)=-\mathbf{\Sigma}^{-1}\left(\mathbf{y}-\mathbf{x}\right)\). We consider the following four kinds of \(\mathbf{\Sigma}\): (1) \(\mathbf{\Sigma}=\sigma^{2}\mathbf{I}\); (2) \(\mathbf{\Sigma}=\sigma^{2}\mathbf{A}^{\top}\mathbf{A}\); (3) \(\mathbf{\Sigma}=\mathbf{\Sigma}\left(\mathbf{x}\right)=\mathrm{diag}\left(a\mathbf{x}+b\mathbf{1} \right)^{2}\); (4) \(\mathbf{\Sigma}=\mathbf{\Sigma}\left(\mathbf{x}\right)=\mathbf{A}^{\top}\mathrm{diag}\left(a \mathbf{x}+b\mathbf{1}\right)^{2}\mathbf{A}\). In the second and fourth cases, \(\mathbf{A}\) usually represents a convolution transform which describes the correlation between adjacent pixels.

For the first and second cases, \(\mathbf{\Sigma}\) is a constant matrix. By solving Eq. 7, we have

\[\hat{\mathbf{x}}=\mathbf{\Sigma}\mathbf{s}\left(\mathbf{y}\right)+\mathbf{y}. \tag{10}\]

While in the third and fourth cases, \(\mathbf{\Sigma}\) is related to \(\mathbf{x}\) and Eq. 10 is a fixed point equation. Therefore, we use an iterative trick to solve it as shown in Algorithm 2.

```
0: noisy image \(\mathbf{y}\), \(\mathbf{s}\left(\mathbf{y}\right)\), the parameters of \(\mathbf{\Sigma}\left(\cdot\right)\) and the number of iterations \(n\).
0:\(\hat{\mathbf{x}}\), the solution.
1: Initial value of \(\hat{\mathbf{x}}\) is set as \(\mathbf{y}\).
2:for\(i=1,...,n\)do
3:\(\hat{\mathbf{x}}\leftarrow\mathbf{\Sigma}\left(\hat{\mathbf{x}}\right)\mathbf{s}\left(\mathbf{y} \right)+\mathbf{y}\).
4:endfor
```

**Algorithm 2** An iterative trick to solve \(\mathbf{x}=\mathbf{\Sigma}\left(\mathbf{x}\right)\mathbf{s}\left(\mathbf{y}\right)+\mathbf{y}\)

#### 3.2.2 Multiplicative Noise

Firstly, we discuss three types of multiplicative noise model, Gamma, Poisson and Rayleigh noise. Then, we consider the situation where the convolution transform \(\mathbf{A}\) exists.

**Gamma Noise** is constructed from Gamma distribution, \(\mathcal{G}\left(\alpha,\beta\right)\): \(p(x;\alpha,\beta)=\frac{\beta^{\alpha}}{\Gamma\left(\alpha\right)}x^{\alpha-1}e ^{-\beta x}\), and is defined as \(\mathbf{y}=\mathbf{\eta}\odot\mathbf{x}\), where \(\eta_{i}\sim\mathcal{G}\left(\alpha,\alpha\right)\), \(\alpha>1\), and \(\odot\) means component-wise multiplication, _i.e._

\[p\left(\mathbf{y}\mid\mathbf{x}\right)=\prod_{i=1}^{d}\frac{\alpha^{\alpha}}{\Gamma \left(\alpha\right)}\left(\frac{y_{i}}{x_{i}}\right)^{\alpha-1}\exp\left\{- \frac{\alpha y_{i}}{x_{i}}\right\}\cdot\frac{1}{x_{i}}. \tag{11}\]Then, we derive that \(\mathbf{f}\left(\mathbf{x},\mathbf{y}\right)=\nabla_{\mathbf{y}}\log p\left(\mathbf{y}\mid\mathbf{x} \right)=\frac{\alpha-1}{\mathbf{y}}-\frac{\alpha}{\mathbf{x}}\). Here, the division is component-wise division. In the residual part of this paper, we neglect such annotation if it is not ambiguous. By solving Eq. 7, we have

\[\hat{\mathbf{x}}=\frac{\alpha\mathbf{y}}{\alpha-1-\mathbf{y}\odot\mathbf{s}\left(\mathbf{y}\right)}. \tag{12}\]

**Poisson Noise** is constructed from Poisson distribution, \(\mathcal{P}\left(\lambda\right)\): \(\Pr(x=k)=\frac{\lambda^{k}}{k!}e^{-\lambda},k=0,1,\cdots\), and is defined as \(\mathbf{y}=\frac{1}{\lambda}\mathbf{\eta}\), \(\eta_{i}\sim\mathcal{P}\left(\lambda x_{i}\right)\), \(\lambda>0\), _i.e._

\[\Pr\left(\mathbf{y}\mid\mathbf{x}\right)=\prod_{i=1}^{d}\frac{\left(\lambda x_{i} \right)^{\lambda_{i}y_{i}}}{\left(\lambda y_{j}\right)!}e^{-\lambda x_{i}}. \tag{13}\]

Then, we derive that \(\mathbf{f}\left(\mathbf{x},\mathbf{y}\right)=\nabla_{\mathbf{y}}\log\Pr\left(\mathbf{y}\mid\mathbf{x} \right)=\lambda\log\left(\lambda\mathbf{x}\right)-\lambda\log\left(\lambda\mathbf{y}+ \frac{1}{2}\right)\). By solving Eq. 7, we have

\[\hat{\mathbf{x}}=\left(\mathbf{y}+\frac{1}{2\lambda}\right)\odot\exp\left\{\frac{\mathbf{s }\left(\mathbf{y}\right)}{\lambda}\right\}, \tag{14}\]

**Rayleigh Noise** is constructed from Rayleigh distribution, \(\mathcal{R}\left(\sigma\right)\): \(p(x;\sigma)=\frac{x}{\sigma^{2}}\exp\left\{-\frac{x^{2}}{2\sigma^{2}}\right\}\), and is defined as \(\mathbf{y}=\left(\mathbf{\eta}+\mathbf{1}\right)\odot\mathbf{x}\), \(\eta_{i}\sim\mathcal{R}\left(\sigma\right)\), \(\sigma>0\), _i.e._

\[p\left(\mathbf{y}\mid\mathbf{x}\right)=\prod_{i=1}^{d}\frac{1}{x_{i}}\frac{y_{i}-x_{i} }{x_{i}\sigma^{2}}\exp\left\{-\frac{\left(y_{i}-x_{i}\right)^{2}}{2x_{i}^{2} \sigma^{2}}\right\}. \tag{15}\]

Then, we derive that \(\mathbf{f}\left(\mathbf{x},\mathbf{y}\right)=\nabla_{\mathbf{y}}\log p\left(\mathbf{y}\mid\mathbf{x} \right)=\frac{1}{\mathbf{y}-\mathbf{x}}-\frac{\mathbf{y}-\mathbf{x}}{\sigma^{2}\mathbf{x}^{2}}\). Solving Eq. 7 directly is not easy. Here we provide an iterative algorithm to solve it. It is illustrated in Algorithm 3.

```
1: noisy image \(\mathbf{y}\), \(\mathbf{s}\left(\mathbf{y}\right)\), the parameter of Rayleigh noise \(\sigma\) and the number of iterations \(n\).
2:\(\hat{\mathbf{x}}\), the solution of Eq. 7.
3: Initial value of \(\hat{\mathbf{x}}\) is set as \(\mathbf{y}\).
4:for\(i=1,...,n\)do
5: Compute \(\mathbf{b}=\sigma^{2}\mathbf{s}\left(\mathbf{y}\right)\odot\hat{\mathbf{x}}\).
6: Compute \(\mathbf{t}=\frac{1}{2}\left(-\mathbf{b}+\sqrt{\mathbf{b}\odot\mathbf{b}+4\sigma^{2}\mathbf{1}}\right)\).
7:\(\hat{\mathbf{x}}\leftarrow\frac{\mathbf{y}}{\mathbf{t}+\mathbf{1}}\).
8:endfor
```

**Algorithm 3** An iterative method to solve Eq. 7 in the case of Rayleigh noise

Now, we consider the situation where the convolution transform \(\mathbf{A}\) exists. Suppose the noise model is represented by \(\mathbf{y}=\mathbf{A}\mathbf{z}\), \(\mathbf{z}=N\left(\mathbf{x}\right)\), where \(N\left(\mathbf{x}\right)\) can be any multiplicative noise model discussed above. Then, we have \(\nabla_{\mathbf{y}}\log p_{\mathbf{y}}\left(\mathbf{y}\mid\mathbf{x}\right)=\mathbf{A}^{-1,\top} \nabla_{\mathbf{z}}\log p_{\mathbf{z}}\left(\mathbf{A}^{-1}\mathbf{y}\mid\mathbf{x}\right)\). To avoid confusion, we use subscripts to distinguish different distribution. Therefore, we can apply Algorithm 4 to solve Eq. 7, which is shown as follows.

```
1:\(\mathbf{y}\), \(\mathbf{s}\left(\mathbf{y}\right)\), \(\mathbf{A}\) and \(\widehat{\mathbf{f}}\left(\mathbf{x},\mathbf{z}\right)=\nabla_{\mathbf{z}}\log p_{\mathbf{z}}\left( \mathbf{z}\mid\mathbf{x}\right)\).
2:\(\hat{\mathbf{x}}\), the solution of Eq. 7.
3: Computing \(\tilde{\mathbf{s}}=\mathbf{A}^{\top}\mathbf{s}\left(\mathbf{y}\right)\).
4: Computing \(\mathbf{z}=\mathbf{A}^{-1}\mathbf{y}\).
5: Solve \(\tilde{\mathbf{s}}=\widehat{\mathbf{f}}\left(\mathbf{x},\mathbf{z}\right)\) by the corresponding Algorithm
```

**Algorithm 4** The general framework to solve Eq. 7 for correlated multiplicative noise model

#### 3.2.3 Mixture Noise

In this paper, the mixture noise model is composed of a multiplicative noise and an additive Gaussian noise. We denote it as \(\mathbf{y}=\mathbf{z}+\mathbf{\epsilon},\epsilon\sim\mathcal{N}\left(0,\sigma^{2}\mathbf{I}\right)\), \(\mathbf{z}=\mathbf{A}N\left(\mathbf{x}\right)\), where \(N\left(\mathbf{x}\right)\) is any multiplicative noise model that can be solved by our approach and \(\mathbf{A}\) is either a convolution transform or identity matrix. It is easy to derive that \(p_{\mathbf{y}}\left(\mathbf{y}\mid\mathbf{x}\right)=\int p_{\mathbf{y}}\left(\mathbf{y}\mid \mathbf{z}\right)p_{\mathbf{z}}\left(\mathbf{z}\mid\mathbf{x}\right)\mathrm{d}\mathbf{z}\). Generally speaking, \(p_{\mathbf{y}}\left(\mathbf{y}\mid\mathbf{x}\right)\) has not an explicit analytical form. In this paper, we assume that the additive Gaussian noise is far smaller than the multiplicative noise. Thus, we utilize Taylor expansion to approximate \(p_{\mathbf{y}}\left(\mathbf{y}\mid\mathbf{x}\right)\). We have the following conclusion:

\[p_{\mathbf{y}}\left(\mathbf{y}\mid\mathbf{x}\right)\approx p_{\mathbf{z}}\left(\bar{ \mathbf{z}}\mid\mathbf{x}\right)+\nabla_{\mathbf{z}}p_{\mathbf{z}}\left(\bar{\mathbf{z}} \mid\mathbf{x}\right)^{T}\left(\mathbf{y}-\bar{\mathbf{z}}\right), \tag{16}\]

where \(\bar{\mathbf{z}}=\mathbb{E}\left[\mathbf{z}\mid\mathbf{y}\right]\). Then, we can further derive that

\[\nabla_{\mathbf{y}}\log p_{\mathbf{y}}\left(\mathbf{y}\mid\mathbf{x}\right)\approx\nabla_ {\mathbf{z}}\log p_{\mathbf{z}}\left(\bar{\mathbf{z}}\mid\mathbf{x}\right). \tag{17}\]

The full and rigorous derivations of Eq. 16 and Eq. 17 are in Supplementary Material. Applying Eq. 10 in Section 3.2.1, we have \(\bar{\mathbf{z}}=\mathbf{y}+\sigma^{2}\mathbf{s}\left(\mathbf{y}\right)\). Thus, the equation to be solve is \(\mathbf{s}\left(\mathbf{y}\right)=\mathbf{f}\left(\mathbf{x},\bar{\mathbf{z}}\right)\). The full denoising process is illustrated in Algorithm 5.

```
0:\(\mathbf{y}\), \(\mathbf{s}\left(\mathbf{y}\right)\).
0:\(\hat{\mathbf{x}}\), the solution of \(\mathbf{s}\left(\mathbf{y}\right)=\mathbf{f}\left(\mathbf{x},\bar{\mathbf{z}}\right)\).
1: Computing \(\bar{\mathbf{z}}=\mathbf{y}+\sigma^{2}\mathbf{s}\left(\mathbf{y}\right)\).
2: Solve \(\mathbf{s}\left(\mathbf{y}\right)=\mathbf{f}\left(\mathbf{x},\bar{\mathbf{z}}\right)\) through the corresponding algorithm discussed in Section 3.2.2.
```

**Algorithm 5** The full denoising process for mixture noise \(\mathbf{y}=\mathbf{z}+\mathbf{\epsilon}\)

### Estimation of Score Function

So far, we assume that the score function of \(\mathbf{y}\), \(\mathbf{s}\left(\mathbf{y}\right)\), is known. However, it is usually unknown and should be estimated from the dataset of noisy images \(\left\{\mathbf{y}\right\}\). We use the same method, the amortized residual Denoising Auto Encoder (AR-DAE) [13] discussed in Noise2Score. Suppose \(\mathbf{s}\left(\cdot;\theta\right)\) is a neural network used to represent the score function of \(\mathbf{y}\). The following objective function is used to train the model:

\[L=\mathbb{E}_{\mathbf{y},\mathbf{u}\sim\mathcal{N}\left(\mathbf{0},\mathbf{I}\right)}\left\|\bm {u}+\sigma_{a}\mathbf{s}\left(\mathbf{y}+\sigma_{a}\mathbf{u};\theta\right)\right\|_{2}^{2 }, \tag{18}\]

where \(\sigma_{a}\) is a fixed value. Given \(\sigma_{a}\), the optimal model \(\mathbf{s}(\mathbf{y};\theta^{*})\) that minimizes \(L\) is the score function of perturbed \(\mathbf{y}\), \(\mathbf{y}+\sigma_{a}\mathbf{u}\). In other words, we can approximate the score function \(\mathbf{s}\left(\mathbf{y}\right)\) by using a sufficiently small \(\sigma_{a}\). Related analysis can also be seen in [8; 23; 1]. During the training process, the value of \(\sigma_{a}\) will be decreasing gradually to a very small value. This progressive process is helpful to numerically stabilize the model training. The only model training is to estimate \(\mathbf{s}\left(\mathbf{y}\right)\) by \(\mathbf{s}\left(\cdot;\theta\right)\), which is served as the first step of our approach. After the score function model is trained, we apply the denoising algorithms given in Section 3.1 to obtain denoised results and no more training is required.

## 4 Experiment

Dataset and Implementation DetailsWe evaluate the proposed method for color images in the three benchmark datasets containing RGB natural images: Kodak dataset, CBSD68 [15] and CSet9. DIV2K [22] and CBSD500 dataset [3] are used as training datasets. The synthetic noise images for each noise model are generated and fixed through the training process. For the sake of fair comparison, we use the same modified U-Net [5] for all methods. When training, we randomly clip the training images to patches with the resolution of \(128\times 128\). AdamW optimizer [14] is used to train the network. We train each model for 5000 steps with the batch size of 32. To reduce memory, we utilize the tricks of cumulative gradient and mixed precision training. The learning rate is initialized to \(1\times 10^{-4}\) for first 4000 steps and it is decreased to \(1\times 10^{-5}\) for final 1000 steps. All the models are implemented in PyTorch [18] with NVidia V100. The pixel value range of all clean images is \([0,255]\) and the parameters of noise models are built on it. Noisy images will be scaled when fed into the network. When an iterative algorithm is needed to solve Eq. 7, we set the number of iterations as \(10\). The more details of implementation are described in Supplementary Material.

Baseline and Comparison MethodsWe use supervised learning with MSE loss as the baseline model. Noisier2Noise and Neighbor2Neighbor are used as comparison methods. Since our approach is identical to Noise2Score when the noise model follows exponential family distributions, we do not compare to it through metrics. Because Noisier2Noise can only be applied to additive noise, we do not train models by Noisier2Noise for other noise models. Though Neighbor2Neighbor is not suitable for some noise models from the perspective of theoretical analysis, we still train corresponding models and report its results. Table 1 shows the comparison of application range for different methods, including additive Gaussian noise, multiplicative noise and mixture noise. Based on it our experiments are conducted. Only supervised learning and our approach can handle all noise models listed in Table 1.

Parameters of Noise ModelsHere, we emphasize that for all noise models in our experiments, \(\mathbf{A}\) is set as a \(3\times 3\) convolution transform with the kernel of

\[\begin{pmatrix}0.05&0.1&0.05\\ 0.1&0.4&0.1\\ 0.05&0.1&0.05\end{pmatrix} \tag{19}\]

if it is used. The additive Gaussian noise in every mixture noise model is set as \(\mathcal{N}\left(\mathbf{0},100\mathbf{I}\right)\). Other parameters will be given later. Finally, all parameters are assumed to be known in our experiments.

Additive Gaussian NoiseUsing additive Gaussian noise, we consider four kinds of noise models with different \(\mathbf{\Sigma}\) corresponding from No.1 to No.4 in Table 1. Our method is compared to supervised learning, Noisier2Noise and Neighbor2Neighbor as shown in Table 2. For the first two noise models \(\sigma\) is \(25\), and for the rest \(a=0.98\) and \(b=25\). As expected, supervised learning performs best. In the cases without \(\mathbf{A}\) Neighbor2Neighbor is the best among three other unsupervised learning methods. However, in the cases with \(\mathbf{A}\) Neighbor2Neighbor performs very poorly. Our approach outperform other unsupervised learning methods in the second noise model and is competitive in the whole.

Multiplicative NoiseWe consider the combination of three various multiplicative noise model (Gamma, Poisson and Rayleigh) and a convolution transform \(\mathbf{A}\). They are corresponding from No.\(5\) to No.\(10\) in Table 1. Our method is compared to supervised learning and Neighbor2Neighbor and the results are shown in Table 3. Because Noisier2Noise can not address such multiplicative noise models, we neglect it. Though the noise is not pixel-wise independent when the convolution transform exists,

\begin{table}
\begin{tabular}{c c c c c c c} \hline No. & Noise Model & SL & Nr2N & Nb2Nb & N2S & Ours \\ \hline
1 & \(\mathbf{y}=\mathbf{x}+\mathbf{\epsilon},\mathbf{\epsilon}\sim\mathcal{N}\left(\mathbf{0},\sigma^{2} \mathbf{I}\right)\) & ✓ & ✓ & ✓ & ✓ & ✓ \\
2 & \(\mathbf{y}=\mathbf{x}+\mathbf{\epsilon},\mathbf{\epsilon}\sim\mathcal{N}\left(\mathbf{0},\sigma^{2} \mathbf{A}^{\top}\mathbf{A}\right)\) & ✓ & ✓ & \(\times^{*}\) & ✓ & ✓ \\
3 & \(\mathbf{y}=\mathbf{x}+\mathbf{\epsilon},\mathbf{\epsilon}\sim\mathcal{N}\left(\mathbf{0},\mathrm{ diag}\left(a\mathbf{x}+b\mathbf{1}\right)^{2}\right)\) & ✓ & ✓ & ✓ & \(\times\) & ✓ \\
4 & \(\mathbf{y}=\mathbf{x}+\mathbf{\epsilon},\mathbf{\epsilon}\sim\mathcal{N}\left(\mathbf{0},\mathbf{A}^{ \top}\mathrm{diag}\left(a\mathbf{x}+b\mathbf{1}\right)^{2}\mathbf{A}\right)\) & ✓ & ✓ & \(\times^{*}\) & \(\times\) & ✓ \\
5 & \(\mathbf{y}=\mathbf{\eta}\odot\mathbf{x},\eta_{i}\sim\mathcal{G}\left(\alpha,\alpha\right)\) & ✓ & \(\times\) & ✓ & ✓ & ✓ \\
6 & \(\mathbf{y}=\mathbf{A}\mathbf{\eta}\odot\mathbf{x},\eta_{i}\sim\mathcal{G}\left(\alpha,\alpha\right)\) & ✓ & \(\times\) & ✓* & ✓ & ✓ \\
7 & \(\mathbf{y}=\frac{1}{\lambda}\mathbf{\eta},\eta_{i}\sim\mathcal{P}\left(\lambda x_{i}\right)\) & ✓ & \(\times\) & ✓ & ✓ & ✓ \\
8 & \(\mathbf{y}=\frac{1}{\lambda}\mathbf{A}\mathbf{\eta},\eta_{i}\sim\mathcal{P}\left(\lambda x_{i}\right)\) & ✓ & \(\times\) & ✓* & ✓ & ✓ \\
9 & \(\mathbf{y}=\left(\mathbf{\eta}+\mathbf{1}\right)\odot\mathbf{x},\eta_{i}\sim\mathcal{R}\left( \sigma\right)\) & ✓ & \(\times\) & \(\times^{*}\) & \(\times\) & ✓ \\
10 & \(\mathbf{y}=\mathbf{A}\left(\mathbf{\eta}+\mathbf{1}\right)\odot\mathbf{x},\eta_{i}\sim\mathcal{R}\left( \sigma\right)\) & ✓ & \(\times\) & \(\times^{*}\) & \(\times\) & ✓ \\
11 & \(\mathbf{y}=\mathbf{\eta}\odot\mathbf{x}+\mathbf{\epsilon},\eta_{i}\sim\mathcal{G}\left(\alpha, \alpha\right),\epsilon\sim\mathcal{N}\left(0,\sigma^{2}\mathbf{I}\right)\) & ✓ & \(\times\) & ✓ & \(\times\) & ✓ \\
12 & \(\mathbf{y}=\mathbf{A}\mathbf{\eta}\odot\mathbf{x}+\mathbf{\epsilon},\eta_{i}\sim\mathcal{G}\left( \alpha,\alpha\right),\epsilon\sim\mathcal{N}\left(0,\sigma^{2}\mathbf{I}\right)\) & ✓ & \(\times\) & \(\times^{*}\) & \(\times\) & ✓ \\
13 & \(\mathbf{y}=\frac{1}{\lambda}\mathbf{\eta}+\mathbf{\epsilon},\eta_{i}\sim\mathcal{P}\left( \lambda x_{i}\right),\epsilon\sim\mathcal{N}\left(0,\sigma^{2}\mathbf{I}\right)\) & ✓ & \(\times\) & ✓ & \(\times\) & ✓ \\
14 & \(\mathbf{y}=\frac{1}{\lambda}\mathbf{A}\mathbf{\eta}+\mathbf{\epsilon},\eta_{i}\sim\mathcal{P} \left(\lambda x_{i}\right),\epsilon\sim\mathcal{N}\left(0,\sigma^{2}\mathbf{I}\right)\) & ✓ & \(\times\) & \(\times^{*}\) & \(\times\) & ✓ \\
15 & \(\mathbf{y}=\left(\mathbf{\eta}+\mathbf{1}\right)\odot\mathbf{x},\eta_{i}\sim\mathcal{R}\left( \sigma\right),\epsilon\sim\mathcal{N}\left(0,\sigma^{2}\mathbf{I}\right)\) & ✓ & \(\times\) & \(\times^{*}\) & \(\times\) & ✓ \\
16 & \(\mathbf{y}=\mathbf{A}\left(\mathbf{\eta}+\mathbf{1}\right)\odot\mathbf{x},\eta_{i}\sim\mathcal{R} \left(\sigma\right),\epsilon\sim\mathcal{N}\left(0,\sigma^{2}\mathbf{I}\right)\) & ✓ & \(\times\) & \(\times^{*}\) & \(\times\) & ✓ \\ \hline \end{tabular}
\end{table}
Table 1: The application range of different methods including supervised learning (SL), Noisier2Noise (Nr2N), Neighbor2Neighbor (Nb2Nb), Noise2Score (N2S) and ours. ✓ means applicable and \(\times\) means not applicable or incapable to perform. For Neighbor2Neighbor, ✓\({}^{*}\) means that direct application is not feasible but indirect application is; \(\times^{*}\) means that the application is not feasible but model training is executable.

we can execute its inverse transform on \(\mathbf{y}\) so that the requirement of pixel-wise independence is satisfied for Neighbor2Neighbor. Therefore, tackling noise models with a convolution transform is equivalent to the situations without \(\mathbf{A}\). That is why we do not provide corresponding metrics result for Neighbor2Neighbor in Table 3. We set \(\alpha\) as \(26\) for the Gamma noise, \(\lambda\) as \(0.2\) for the Poisson noise, and \(\sigma\) as \(0.3\) for the Rayleigh noise. When the noise model is based on Gamma or Poisson noise, it is unbiased, _i.e._\(\mathbb{E}\left[\mathbf{y}\mid\mathbf{x}\right]=\mathbf{x}\). In these cases, Neighbor2Neighbor is better than ours. However, when the noise model is based on Rayleigh noise which is biased our approach still has excellent performance while Neighbor2Neighbor is poor.

Mixture NoiseWe also consider the combination of three various multiplicative noise model (Gamma, Poisson and Rayleigh) and a convolution transform \(\mathbf{A}\). For each one, additive Gaussian noise with \(\mathbf{\Sigma}=100\mathbf{I}\) is added to construct mixture noise models. They are corresponding from No.\(11\) to No.\(16\) in Table 1. Because of the same reason discussed before, our method is compared to supervised learning and Neighbor2Neighbor, and Noisier2Noise is neglected. The experimental

\begin{table}
\begin{tabular}{l l l l l l l} \hline \hline  & \multicolumn{2}{l}{No.1: Gaussian, \(\sigma=25\) w/o \(\mathbf{A}\)} & \multicolumn{2}{l}{No.2: Gaussian, \(\sigma=25\) w/ \(\mathbf{A}\)} \\ \cline{2-7} Method & Kodak & CSet9 & CBSD68 & Kodak & CSet9 & CBSD68 \\ \cline{2-7} SL & _32.44/0.887_ & _30.27/0.891_ & _31.32/0.892_ & _34.80/0.928_ & _32.53/0.924_ & _34.08/0.938_ \\ Nr2N & 31.80/0.863 & 29.75/0.878 & 30.84/0.871 & 33.87/**0.914** & 32.02/**0.916** & 33.40/**0.926** \\ Nb2Nb & **31.96/0.875** & **29.90/0.882** & **30.92/0.880** & 27.89/0.673 & 27.88/0.742 & 27.86/0.722 \\ Ours & 31.92/0.870 & 29.86/0.875 & 30.91/0.877 & **33.99/0.914** & **32.16/0.914** & **33.45/0.926** \\ \hline \hline \end{tabular} 
\begin{tabular}{l l l l l l l l} \hline \hline  & \multicolumn{2}{l}{No.3: Gaussian, \(a=0.98,b=25\) w/o \(\mathbf{A}\)} & \multicolumn{2}{l}{No.4: Gaussian, \(a=0.98,b=25\) w/ \(\mathbf{A}\)} \\ \cline{2-7} Method & Kodak & CSet9 & CBSD68 & Kodak & CSet9 & CBSD68 \\ \cline{2-7} SL & _30.92/0.856_ & _28.69/0.860_ & _29.68/0.856_ & _33.02/0.904_ & _30.76/0.900_ & _32.11/0.912_ \\ Nr2N & 30.07/0.813 & 28.02/0.834 & 28.99/0.818 & **32.28/0.884** & **29.98/0.886** & **31.55/0.896** \\ Nb2Nb & **30.42/0.840** & **28.22/0.848** & **29.29/0.842** & 25.02/0.557 & 24.44/0.621 & 25.01/0.619 \\ Ours & 29.68/0.797 & 27.58/0.806 & 28.70/0.806 & 31.88/**0.884** & 29.50/0.874 & 31.14/0.895 \\ \hline \hline \end{tabular}
\end{table}
Table 2: Quantitative comparison for various parameters of \(\mathbf{\Sigma}\) in additive Gaussian noise using different methods in terms of PNSR (dB)/SSIM. Bold indicates the best result among three unsupervised methods, while underlined indicates the second-best result.

\begin{table}
\begin{tabular}{l l l l l l l} \hline \hline  & \multicolumn{2}{l}{No.5: Gamma, \(\alpha=26\) w/o \(\mathbf{A}\)} & \multicolumn{2}{l}{No.6: Gamma, \(\alpha=26\) w/ \(\mathbf{A}\)} \\ \cline{2-7} Method & Kodak & CSet9 & CBSD68 & Kodak & CSet9 & CBSD68 \\ \cline{2-7} SL & _33.51/0.916_ & _30.72/0.898_ & _32.44/0.922_ & _33.02/0.916_ & _30.41/0.897_ & _32.15/0.921_ \\ Nb2Nb & **32.98/0.908** & **30.33/0.890** & **31.97/0.913** & - & - & - \\ Ours & 32.61/0.894 & 29.89/0.870 & 31.51/0.898 & 31.90/0.877 & 29.26/0.858 & 30.63/0.878 \\ \hline \hline \end{tabular} \begin{tabular}{l l l l l l l} \hline \hline  & \multicolumn{2}{l}{No.7: Poisson, \(\lambda=0.2\) w/o \(\mathbf{A}\)} & \multicolumn{2}{l}{No.8: Poisson, \(\lambda=0.2\) w/ \(\mathbf{A}\)} \\ \cline{2-7} Method & Kodak & CSet9 & CBSD68 & Kodak & CSet9 & CBSD68 \\ \cline{2-7} SL & _32.90/0.902_ & _30.56/0.894_ & _31.87/0.908_ & _32.55/0.902_ & _30.27/0.894_ & _31.64/0.907_ \\ Nb2Nb & **32.50/0.893** & **30.17/0.886** & **31.48/0.899** & - & - & - \\ Ours & 32.38/0.886 & 29.98/0.874 & 31.31/0.891 & 31.84/0.872 & 29.48/0.864 & 30.56/0.873 \\ \hline \hline \end{tabular} 
\begin{tabular}{l l l l l l l l} \hline \hline  & \multicolumn{2}{l}{No.9: Rayleigh, \(\sigma=0.3\) w/o \(\mathbf{A}\)} & \multicolumn{2}{l}{No.10: Rayleigh, \(\sigma=0.3\) w/ \(\mathbf{A}\)} \\ \cline{2-7} Method & Kodak & CSet9 & CBSD68 & Kodak & CSet9 & CBSD68 \\ \cline{2-7} SL & _35.29/0.939_ & _32.44/0.922_ & _34.39/0.947_ & _34.63/0.939_ & _31.97/0.920_ & _33.94/0.946_ \\ Nb2Nb & 16.55/0.865 & 15.16/0.844 & 16.74/0.862 & - & - & - \\ Ours & **34.25/0.915** & **31.45/0.892** & **33.34/0.923** & **32.87/0.894** & **30.30/0.869** & **31.85/0.901** \\ \hline \hline \end{tabular}
\end{table}
Table 3: Quantitative comparison for various multiplicative noise models using different methods in terms of PNSR (dB)/SSIM. For Neighbor2Neighbor (Nb2Nb), if the noise model is constructed with \(\mathbf{A}\), it can be regarded as the one without \(\mathbf{A}\) through \(\mathbf{A}^{-1}\mathbf{y}\). Thus we do not provide the metrics. Bold indicates the better result between two unsupervised methods.

results are shown in Table 4. Due to the additive Gaussian Noise, Neighbor2Neighbor are not able to handle the cases with \(\mathbf{A}\) through the inverse convolution transform. The correlation of noise hampers the performance of Neigh2bor2Neighbor. Except the first noise model in Table 4, our approach all outperforms Neighbor2Neighbor and achieve excellent performance near to supervised learning.

Robustness EvaluationTo apply our approach, the parameters of noise models have to be known beforehand. Therefore their precision may impact on the performance. We choose No.14 and No.15 noise models in Table 1 as examples to show the robustness to parameters' precision. Suppose \(k\) is one of parameters, we disturb it by \((a+1)k\) where \(a\sim\mathcal{N}(0,r^{2})\) and \(r\) is called the disturbance rate. The larger \(r\), the less precise the noise model. As \(r\) is increasing, the PSNR of the denoised result is shown in Figure 2. When \(r=0.1\), the PSNR reduces about 1 dB, which displays the robustness.

## 5 Conclusion

In this paper, we propose a new approach for unsupervised image denoising. The key part is Proposition 3.1. Based on it, we construct an equation, Eq. 7 about the clean image \(\mathbf{x}\) and the noisy image \(\mathbf{y}\). After the score function of \(\mathbf{y}\) is estimated, the denoised result can be obtained by solving the equation. Our approach can be applied to many different noise model as long as Eq. 7 is solvable. The denoising performance is competitive for simple noise models and excellent for complicated ones. We hope that this work is helpful to address sophisticated image denoising problems in practice.

\begin{table}
\begin{tabular}{l l l l l l l} \hline \hline  & \multicolumn{2}{c}{No.11: Gamma, \(\alpha=26\) w/o \(\mathbf{A}\)} & \multicolumn{2}{c}{No.12: Gamma, \(\alpha=26\) w/ \(\mathbf{A}\)} \\ \cline{2-7} Method & Kodak & CSet9 & CBSD68 & Kodak & CSet9 & CBSD68 \\ \cline{2-7} SL & _32.86/0.902_ & _30.23/0.889_ & _31.70/0.906_ & _33.02/0.882_ & _29.30/0.875_ & _30.42/0.882_ \\ Nb2Nb & **32.30/0.892** & **29.80/0.880** & **31.21/0.896** & 26.93/0.676 & 25.06/0.663 & 26.33/0.710 \\ Ours & 32.13/0.880 & 29.61/0.861 & 31.08/0.887 & **30.74/0.853** & **28.40/0.841** & **29.58/0.854** \\ \hline  & \multicolumn{2}{c}{No.13: Poisson, \(\lambda=0.2\) w/o \(\mathbf{A}\)} & \multicolumn{2}{c}{No.14: Poisson, \(\lambda=0.2\) w/ \(\mathbf{A}\)} \\ \cline{2-7} Method & Kodak & CSet9 & CBSD68 & Kodak & CSet9 & CBSD68 \\ \cline{2-7} SL & _32.49/0.892_ & _30.18/0.887_ & _31.40/0.897_ & _31.44/0.877_ & _29.36/0.876_ & _30.32/0.878_ \\ Nb2Nb & 32.03/**0.884** & **29.74/0.880** & 30.98/**0.888** & 26.82/0.646 & 25.48/0.669 & 26.32/0.688 \\ Ours & **32.10/**0.879** & 29.70/0.870 & **31.03/0.883** & **31.11/0.855** & **28.80/0.851** & **29.85/0.856** \\ \hline  & \multicolumn{2}{c}{No.15: Rayleigh, \(\sigma=0.3\) w/o \(\mathbf{A}\)} & \multicolumn{2}{c}{No.16: Rayleigh, \(\sigma=0.3\) w/ \(\mathbf{A}\)} \\ \cline{2-7} Method & Kodak & CSet9 & CBSD68 & Kodak & CSet9 & CBSD68 \\ \cline{2-7} SL & _34.38/0.926_ & _31.79/0.913_ & _33.39/0.933_ & _32.83/0.908_ & _30.48/0.898_ & _31.74/0.910_ \\ Nb2Nb & 16.54/0.856 & 15.15/0.838 & 16.71/0.851 & 16.40/0.704 & 15.06/0.738 & 16.56/0.736 \\ Ours & **33.54/0.902** & **30.94/0.883** & **32.68/0.913** & **31.14/0.867** & **28.94/0.847** & **30.23/0.876** \\ \hline \hline \end{tabular}
\end{table}
Table 4: Quantitative comparison for various mixture noise models using different methods in terms of PNSR (dB)/SSIM. For each noise model, additive Gaussian noise with \(\mathbf{\Sigma}=100\mathbf{I}\) is added. Bold indicates the better result between two unsupervised methods.

Figure 2: PSNR V.S. disturbance rate for No.14 and No.15 noise models.

Figure 3: Qualitative Comparison using CBSD68 dataset (cropped to \(256\times 256\)). From the first row to the last: (1) Gaussian noise, \(\sigma=25\) w/o \(\mathbf{A}\); (2) Gaussian noise, \(\sigma=25\) w/ \(\mathbf{A}\); (3) Rayleigh noise, \(\sigma=0.3\) w/ \(\mathbf{A}\); (5) Poisson noise, \(\lambda=0.2\) w/ \(\mathbf{A}\) added by Gaussian Noise with \(\sigma=10\); (6) Rayleigh noise, \(\sigma=0.3\) w/o \(\mathbf{A}\) added by Gaussian Noise with \(\sigma=10\). Noisy image, GT: ground-truth image, SL: supervised learning, Nb2Nb: Neighbor2Neighbor, Nr2N: Noisier2Noise.

## References

* [1] Guillaume Alain and Yoshua Bengio. What regularized auto-encoders learn from the data-generating distribution. _The Journal of Machine Learning Research_, 15(1):3563-3593, 2014.
* [2] Joshua Batson and Loic Royer. Noise2self: Blind denoising by self-supervision. In _International Conference on Machine Learning_, pages 524-533. PMLR, 2019.
* [3] Lalit Chaudhary and Yogesh Yogesh. A comparative study of fruit defect segmentation techniques. In _2019 International Conference on Issues and Challenges in Intelligent Computing Techniques (ICICT)_, volume 1, pages 1-4. IEEE, 2019.
* [4] Kostadin Dabov, Alessandro Foi, Vladimir Katkovnik, and Karen Egiazarian. Image denoising with block-matching and 3d filtering. In _Image processing: algorithms and systems, neural networks, and machine learning_, volume 6064, pages 354-365. SPIE, 2006.
* [5] Prafulla Dhariwal and Alexander Nichol. Diffusion models beat gans on image synthesis. _Advances in Neural Information Processing Systems_, 34:8780-8794, 2021.
* [6] Bradley Efron. Tweedie's formula and selection bias. _Journal of the American Statistical Association_, 106(496):1602-1614, 2011.
* [7] Tao Huang, Songjiang Li, Xu Jia, Huchuan Lu, and Jianzhuang Liu. Neighbor2neighbor: Self-supervised denoising from single noisy images. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pages 14781-14790, 2021.
* [8] Aapo Hyvarinen and Peter Dayan. Estimation of non-normalized statistical models by score matching. _Journal of Machine Learning Research_, 6(4), 2005.
* [9] Kwanyoung Kim and Jong Chul Ye. Noise2score: tweedie's approach to self-supervised image denoising without clean images. _Advances in Neural Information Processing Systems_, 34:864-874, 2021.
* [10] Alexander Krull, Tim-Oliver Buchholz, and Florian Jug. Noise2void-learning denoising from single noisy images. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pages 2129-2137, 2019.
* [11] Alexander Krull, Tomas Vicar, Mangal Prakash, Manan Lalit, and Florian Jug. Probabilistic noise2void: Unsupervised content-aware denoising. _Frontiers in Computer Science_, 2:5, 2020.
* [12] Jaakko Lehtinen, Jacob Munkberg, Jon Hasselgren, Samuli Laine, Tero Karras, Miika Aittala, and Timo Aila. Noise2noise: Learning image restoration without clean data. In _International Conference on Machine Learning_, page 2965-2974. PMLR, 2018.
* [13] Jae Hyun Lim, Aaron Courville, Christopher Pal, and Chin-Wei Huang. Ar-dae: towards unbiased neural entropy gradient estimation. In _International Conference on Machine Learning_, pages 6061-6071. PMLR, 2020.
* [14] Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. _arXiv preprint arXiv:1711.05101_, 2017.
* [15] David Martin, Charless Fowlkes, Doron Tal, and Jitendra Malik. A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics. In _Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001_, volume 2, pages 416-423. IEEE, 2001.
* [16] Nick Moran, Dan Schmidt, Yu Zhong, and Patrick Coady. Noisier2noise: Learning to denoise from unpaired noisy data. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pages 12064-12072, 2020.
* [17] Tongyao Pang, Huan Zheng, Yuhui Quan, and Hui Ji. Recorrupted-to-recorrupted: unsupervised deep learning for image denoising. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pages 2043-2052, 2021.

* [18] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in pytorch. 2017.
* [19] Yuhui Quan, Mingqin Chen, Tongyao Pang, and Hui Ji. Self2self with dropout: Learning self-supervised denoising from single image. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pages 1890-1898, 2020.
* [20] Sathish Ramani, Thierry Blu, and Michael Unser. Monte-carlo sure: A black-box optimization of regularization parameters for general denoising algorithms. _IEEE Transactions on image processing_, 17(9):1540-1554, 2008.
* [21] H Robbins. An empirical bayes approach to statistics, proceedings of the third berkeley symposium on mathematical statistics and probability, 1956.
* [22] Radu Timofte, Shuhang Gu, Jiqing Wu, and Luc Van Gool. Ntire 2018 challenge on single image super-resolution: Methods and results. In _Proceedings of the IEEE conference on computer vision and pattern recognition workshops_, pages 852-863, 2018.
* [23] Pascal Vincent. A connection between score matching and denoising autoencoders. _Neural computation_, 23(7):1661-1674, 2011.
* [24] Xiaobe Wu, Ming Liu, Yue Cao, Dongwei Ren, and Wangmeng Zuo. Unpaired learning of deep image denoising. In _European conference on computer vision_, pages 352-368. Springer, 2020.
* [25] Jun Xu, Yuan Huang, Ming-Ming Cheng, Li Liu, Fan Zhu, Zhou Xu, and Ling Shao. Noisy-as-clean: Learning self-supervised denoising from corrupted image. _IEEE Transactions on Image Processing_, 29:9316-9329, 2020.
* [26] Kai Zhang, Wangmeng Zuo, Yunjin Chen, Deyu Meng, and Lei Zhang. Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising. _IEEE transactions on image processing_, 26(7):3142-3155, 2017.