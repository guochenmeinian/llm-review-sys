# Generalized test utilities for long-tail performance in extreme multi-label classification

Erik Schultheis

Aalto University

Helsinki, Finland

erik.schultheis@aalto.fi

&Marek Wydmuch

Poznan University of Technology

Poznan, Poland

mwydmuch@cs.put.poznan.pl

Wojciech Kotlowski

Poznan University of Technology

Poznan, Poland

wkotlowski@cs.put.poznan.pl

&Rohit Babbar

University of Bath / Aalto University

Bath, UK / Helsinki, Finland

rb2608@bath.ac.uk

Krzysztof Dembczynski

Yahoo! Research / Poznan University of Technology

New York, USA / Poznan, Poland

krzysztof.dembczynski@yahooinc.com

###### Abstract

Extreme multi-label classification (XMLC) is the task of selecting a small subset of relevant labels from a very large set of possible labels. As such, it is characterized by long-tail labels, i.e., most labels have very few positive instances. With standard performance measures such as precision@k, a classifier can ignore tail labels and still report good performance. However, it is often argued that correct predictions in the tail are more "interesting" or "rewarding," but the community has not yet settled on a metric capturing this intuitive concept. The existing propensity-scored metrics fall short on this goal by confounding the problems of long-tail and missing labels. In this paper, we analyze generalized metrics budgeted "at k" as an alternative solution. To tackle the challenging problem of optimizing these metrics, we formulate it in the _expected test utility_ (ETU) framework, which aims to optimize the expected performance on a fixed test set. We derive optimal prediction rules and construct computationally efficient approximations with provable regret guarantees and robustness against model misspecification. Our algorithm, based on block coordinate ascent, scales effortlessly to XMLC problems and obtains promising results in terms of long-tail performance.

## 1 Introduction

Extreme multi-label classification (XMLC) is a challenging task with a wide spectrum of real-life applications, such as tagging of text documents [10], content annotation for multimedia search [14], or different type of recommendation [5, 1, 33, 44, 53, 28, 7]. Because of the nature of its applications, the typical approach in XMLC is to predict exactly \(k\) labels (e.g., corresponding to \(k\) slots in the user interface) which optimize a standard performance metric such as precision or (normalized) discounted cumulative gain. Given the enormous number of labels in XMLC tasks, which can reach millions or more, it is not surprising that many of them are very sparse, and hence make the label distribution strongly long-tailed [2]. It has been noticed that algorithms can achieve high performance on the standard metrics, but never predict any tail labels [42]. Therefore, there is a need to developa metric that prefers "rewarding" [48], "diverse" [3], and "rare and informative" [34] labels over frequently-occurring head labels. Currently, the XMLC community attempts to capture this need using _propensity-scored_ performance metrics [15]. These metrics give increased weight to tail labels, but have been derived from the perspective of missing labels, and as such they are not really solving the problem of tail labels [41].

In Table 1 we compare different metrics for budgeted at \(k\) predictions. We train a PLT model [17] on the full AmazonCat-13K dataset [27] and a reduced version with the \(1000\) most popular labels only. The test is performed for both models on the full set of labels. The standard metrics are only slightly perturbed by reducing the label space to the head labels. This holds even for propensity-scored precision, which decreases by just 1%-20% despite discarding over 90% of the label space. In contrast, macro measures and coverage decrease between 60% and 90% if tail labels are ignored. These results show that budgeted-at-\(k\) macro measures might be very attractive in the context of long tails. Macro-averaging treats all the labels equally important, preventing the labels with a small number of positive examples to be ignored. Furthermore, the budget of \(k\) labels "requires" the presence of long-tail labels in a compact set of predicted labels.

While we can easily use these measures to evaluate and compare different methods, we also would like to make predictions that directly optimize these metrics. The existing approaches to macro-averaged metrics consider the unconstrained case, in which label-wise optimization is possible [47, 11, 23, 16, 22]. Each binary problem can be then solved under one of two frameworks for optimizing complex performance measures, namely _population utility_ (PU) or _expected test utility_ (ETU) [49, 12]. The former aims at optimizing the performance on the population level. The latter optimizes the performance directly on a given test set. Interestingly, in both frameworks the optimal solution is based on thresholding conditional label probabilities [12], but the resulting thresholds are different with the discrepancy diminishing with the size of the test set. The threshold tuning for PU is usually performed on a validation set [47, 26], while the exact optimization for ETU is performed on a test set. It requires cubic time in a general case and quadratic time in some special cases [49, 32]. Approximate solutions can be obtained in linear time [25, 12].

These approaches cannot be directly applied if prediction of exactly \(k\) labels for each instance is required. In such case, the optimization problems for different labels are tightly coupled through this constraint, making the final problem much more difficult. Despite the fact that optimization of complex performance metrics is a well-established problem, considered not only in binary and multi-label classification as discussed above, but also in multi-class classification [30, 31], the results presented in this paper go beyond the state-of-the-art as budgeted-at-\(k\) predictions have not yet been analyzed in this context. Let us underline that the requirement of \(k\) predictions is natural for recommendation systems, in which exactly \(k\) slots are available in the user interface to display recommendations. Even in situations where this does not apply, requiring the prediction to be "at \(k\)" can be advantageous, as it prevents trivial solutions such as predicting nothing (for precision) or everything (for recall).

In this paper, we investigate optimal solutions for the class of utility functions that can be linearly decomposed over labels into binary utilities, which includes both instance-wise weighted measures and macro-averages. We solve the problem in the ETU framework which is well-suited, for example, to recommendation tasks in which recommendations for all users or items are rebuilt in regular intervals. In this case, we can first obtain probability estimates of individual labels for each instance in the test set, and then provide optimal predictions for a given metric based on these estimates. We

\begin{table}
\begin{tabular}{l|c c c|c c c} \hline \hline Metric & \multicolumn{3}{c|}{full labels} & \multicolumn{3}{c}{head labels} \\  & @1 & @3 & @5 & @1 (diff.) & @3 (diff.) & @5 (diff.) \\ \hline Precision & 93.03 & 78.51 & 63.74 & 93.08 (+0.05\%) & 76.42 (2.66\%) & 58.21 (-8.67\%) \\ nDCG & 93.03 & 87.25 & 85.35 & 93.08 (+0.05\%) & 85.75 (-1.71\%) & 80.91 (-5.19\%) \\ PS-Precision & 49.76 & 62.63 & 70.35 & 49.07 (-1.39\%) & 57.71 (-7.84\%) & 57.41 (-18.40\%) \\ \hline Macro-Precision & 13.28 & 32.65 & 44.16 & 4.31 (-67.54\%) & 5.28 (-83.82\%) & 4.32 (-90.21\%) \\ Macro-Recall & 1.38 & 11.06 & 30.57 & 0.47 (-65.61\%) & 2.69 (-75.71\%) & 4.10 (-86.99\%) \\ Macro-F1 & 2.26 & 14.67 & 32.84 & 0.74 (-67.37\%) & 3.10 (-78.88\%) & 3.77 (-88.51\%) \\ Coverage & 15.19 & 40.53 & 60.88 & 5.11 (-66.32\%) & 7.37 (-81.82\%) & 7.52 (-87.65\%) \\ \hline \hline \end{tabular}
\end{table}
Table 1: Performance measures (%) on AmazonCat-13k of a classifier trained on the full set of labels and a classifier trained with only 1k head labels.

derive optimal prediction rules and construct computationally efficient approximations with provable guarantees, formally quantifying the influence of the estimation error of the label probabilities on the suboptimality of the resulting classifier. This result is expressed in the form of a regret bound [4; 30; 22; 13]. It turns out that for most metrics of interest, a small estimation error results in at most a small drop of the performance, which confirms our method is viable for applications. Our general algorithm, based on block coordinate ascent, scales effortlessly to XMLC problems and obtains promising empirical results.

## 2 Setup and notation

Let \(\mathbf{x}\in\mathcal{X}\) denote an input instance, and \(\mathbf{y}\in\{0,1\}^{m}\eqqcolon\mathcal{Y}\) the vector indicating the relevant labels, distributed according to \(\mathds{P}(\mathbf{y}|\mathbf{x})\). We consider the prediction problem in the _expected test utility_ (ETU) framework, that is, we assume that we are given a known set of \(n\) instances \(\mathbf{X}=[\mathbf{x}_{1},\ldots,\mathbf{x}_{n}]^{\mathsf{T}}\in\mathcal{X}^{n}\) with unknown labels, on which we have to make predictions.1 Our goal is to assign each instance \(\mathbf{x}_{i}\) a set of exactly \(k\) (out of \(m\)) labels represented as a \(k\)-hot vector \(\hat{\mathbf{y}}_{i}\in\mathcal{Y}_{k}\coloneqq\{\mathbf{y}\in\mathcal{Y}:~{}\|\mathbf{y} \|_{1}=k\}\), and we let \(\hat{\mathbf{Y}}=[\hat{\mathbf{y}}_{1},\ldots,\hat{\mathbf{y}}_{n}]^{\mathsf{T}}\) denote the entire \(n\times m\) prediction matrix for a set of instances \(\mathbf{X}\).

Footnote 1: We use calligraphic letters for sets \(\mathcal{S}\), bold font for vectors \(\mathbf{v}\) with entries \(v_{i}\), bold capital letters for matrices \(\mathbf{Y}\) with entries \(y_{ij}\), rows \(\mathbf{y}_{i}\), and columns \(\mathbf{y}_{:j}\). \(\mathds{1}[S]\) denotes the indicator of event \(S\), and \([s]\coloneqq\{1,\ldots,s\}\)

In the ETU framework, we treat \(\mathbf{X}\) as given and only make an assumption about the labeling process for the test sample: the labels \(\mathbf{y}_{i}\in\mathcal{Y}\) corresponding to \(\mathbf{x}_{i}\in\mathcal{X}\) do not depend on any other instances, that is \(\mathds{P}(\mathbf{Y}|\mathbf{X})=\prod_{i=1}^{n}\mathds{P}(\mathbf{y}_{i}|\mathbf{x}_{i})\), where we use \(\mathbf{Y}=[\mathbf{y}_{1},\ldots,\mathbf{y}_{n}]^{\mathsf{T}}\in\mathcal{Y}^{m}\) to denote the entire label matrix. We assume the quality of predictions \(\hat{\mathbf{Y}}\) is jointly evaluated against the observed labels \(\mathbf{Y}\) by a _task utility_\(\Psi(\mathbf{Y},\hat{\mathbf{Y}})\), and define the _optimal (Bayes) prediction_\(\hat{\mathbf{Y}}^{\star}\) as the one maximizing the _expected task utility_\(\Psi_{\text{ETU}}\):

\[\hat{\mathbf{Y}}^{\star}=\operatorname*{argmax}_{\mathbf{Y}\in\mathcal{Y}^{n}_{\mathbf{X} }}\mathds{E}_{\mathbf{Y}|\mathbf{X}}[\Psi(\mathbf{Y},\hat{\mathbf{Y}})]\eqqcolon\operatorname *{argmax}_{\mathbf{Y}\in\mathcal{Y}^{n}_{\mathbf{X}}}\Psi_{\text{ETU}}(\hat{\mathbf{Y}})\,. \tag{1}\]

We consider task utilities \(\Psi(\mathbf{Y},\hat{\mathbf{Y}})\) that linearly decompose over labels, i.e., there exists \(\psi^{j}\) such that

\[\Psi(\mathbf{Y},\hat{\mathbf{Y}})=\sum_{j=1}^{m}\psi^{j}(\mathbf{y}_{:j},\hat{\mathbf{y}}_{:j} )\,. \tag{2}\]

We allow the functions \(\psi^{j}\) to be non-linear themselves and different for each label \(j\). This is a large class of functions, which encompasses weighted instance-wise and macro-averaged utilities, the two groups of functions which we thoroughly analyze in the next sections.

Let us next define the binary confusion matrix \(\mathbf{C}(\mathbf{y},\hat{\mathbf{y}})\) for a vector \(\mathbf{y}\) of \(n\) ground truth labels and a corresponding vector \(\hat{\mathbf{y}}\) of binary predictions:

\[\mathbf{C}(\mathbf{y},\hat{\mathbf{y}})\coloneqq\left(\frac{\frac{1}{n}\sum_{i=1}^{n}(1-y _{i})(1-\hat{y}_{i})}{\frac{1}{n}\sum_{i=1}^{n}y_{i}(1-\hat{y}_{i})}\frac{ \frac{1}{n}\sum_{i=1}^{n}(1-y_{i})\hat{y}_{i}}{\frac{1}{n}\sum_{i=1}^{n}y_{i} y_{i}}\right)\,. \tag{3}\]

By indexing from 0, the entry \(c_{00}\) corresponds to true negatives, \(c_{01}\) to false positives, \(c_{10}\) to false negatives, and \(c_{11}\) to true positives.We define the _multi-label confusion tensor2\(\mathbf{\mathrm{C}}(\mathbf{Y},\hat{\mathbf{Y}}):=[\mathbf{C}(\mathbf{y}_{:1},\hat{\mathbf{y}}_{:1} ),\ldots,\mathbf{C}(\mathbf{y}_{:m},\hat{\mathbf{y}}_{:m})]\)_ being the concatenation of binary confusion matrices of all \(m\) labels.

Footnote 2: Notice that the confusion matrix can be computed either for multi-label predictions for a given instance \(\mathbf{x}\) or binary predictions for label \(j\) obtained on a set of instances \(\mathbf{X}\). In the following, we focus on the latter.

Assuming the utility function (2) to be invariant under instance reordering, i.e., its value does not change if rows of both matrices are re-ordered using the same permutation, we can define \(\Psi\) in terms of confusion matrices, instead of ground-truth labels and predictions (shown in Appendix A.1):

\[\Psi(\mathbf{Y},\hat{\mathbf{Y}})=\Psi(\mathbf{\mathrm{C}}(\mathbf{Y},\hat{\mathbf{Y}}))=\sum_{j=1}^ {m}\psi^{j}(\mathbf{C}(\mathbf{y}_{:j},\hat{\mathbf{y}}_{:j}))\,. \tag{4}\]

Finally, we assume that we have access to a _label probability estimator (LPE)_\(\hat{\mathbf{\eta}}(\mathbf{x})\) that estimates the marginal probability of each label given the instance, \(\mathbf{\eta}(\mathbf{x})=(\eta_{1}(\mathbf{x}),\ldots,\eta_{m}(\mathbf{x}))\coloneqq\mathds{E }_{\mathbf{y}|\mathbf{x}}[\mathbf{y}]\). Such an LPE can be attained by fitting a model on an additional training set of \(n^{\prime}\) examples \((\mathbf{x}_{i},\mathbf{y}_{i})_{i=1}^{n^{\prime}}\) using a proper composite loss function [37], which is a common approach in XMLC, e.g., [18].

Performance measures for tail labels

### Instance-wise weighted utility functions

By assigning utility (or cost) to each correct/wrong prediction for each label, we can construct an _instance-wise weighted utility_\(u_{\mathbf{w}}\colon\mathcal{Y}\times\mathcal{Y}\longrightarrow\mathds{R}_{ \geq 0}\) with labels \(\boldsymbol{y}\in\mathcal{Y}\) and predictions \(\hat{\boldsymbol{y}}\in\mathcal{Y}\) as

\[u_{\mathbf{w}}(\boldsymbol{y},\hat{\boldsymbol{y}})=\sum_{j=1}^{m}w_{00}^{j}(1 -y_{j})(1-\hat{y}_{j})+w_{01}^{j}(1-y_{j})\hat{y}_{j}+w_{10}^{j}y_{j}(1-\hat{y }_{j})+w_{11}^{j}y_{j}\hat{y}_{j}\,. \tag{5}\]

We use \(w_{00}^{j}\), \(w_{01}^{j}\), \(w_{10}^{j}\), and \(w_{11}^{j}\) to express the utility of true negatives, false positives, false negatives, and true positives, respectively. The corresponding task loss results from summing over all instances. By interchanging the order of summation, we can see that it is of form (4):

\[\Psi(\boldsymbol{Y},\hat{\boldsymbol{Y}})=\sum_{i=1}^{n}u_{\mathbf{w}}( \boldsymbol{y}_{i},\hat{\boldsymbol{y}}_{i})=\sum_{j=1}^{m}w_{00}^{j}c_{00}^{ j}+w_{01}^{j}c_{01}^{j}+w_{10}^{j}c_{10}^{j}+w_{11}^{j}c_{11}^{j}=\sum_{j=1}^{m} \!\psi^{j}(\boldsymbol{C}(\boldsymbol{y}_{\cdot j},\hat{\boldsymbol{y}}_{\cdot j }))\,. \tag{6}\]

In other words, the instance-wise weighted utilities can be seen as _linear_ confusion-based metrics. By choosing \(w_{00}^{j}=w_{11}^{j}=m^{-1}\) and \(w_{01}^{j}=w_{10}^{j}=0\), the expression (5) reduces to the \(@k\)-variant of the _Hamming utility_. Similarly, \(w_{11}^{j}=k^{-1}\) and \(w_{00}^{j}=w_{01}^{j}=w_{10}^{j}=0\) yield precision\(@k\).

Another example is the popular _propensity-scoring_ approach [15], commonly used as a tail-performance metric in XMLC. Here, the weights are computed based on training data through

\[w_{11}^{j,\text{prop}}=k^{-1}\left(1+(\log n^{\prime}-1)(b+1)^{a}(n^{\prime} \hat{\pi}_{j}+b)^{-a}\right), \tag{7}\]

where \(n^{\prime}\) is the number of training instances, \(\hat{\pi}_{j}\) is the empirical prior of label \(j\), and parameters \(a\) and \(b\) are (potentially) dataset-dependent. This form of weighting has been derived from a missing-labels perspective, so its application to tail labels is not fully justified [41]. Also, it introduces two more hyperparameters, which makes the interpretation and comparison of its values rather difficult. It is not less heuristical than other approaches like power-law or logarithmic weighting, given by:

\[w_{11}^{j,\text{pl}}\propto\hat{\pi}_{j}^{-\beta},\quad w_{11}^{j,\text{log}} \propto-\log\left(\hat{\pi}_{j}\right)\,. \tag{8}\]

### Macro-average of non-decomposable utilities

Macro-averaging usually concerns non-decomposable binary utilities such as the F-measure. In this case, we set up \(\psi^{j}(\cdot,\cdot)=m^{-1}\psi(\cdot,\cdot)\) for all labels \(j\) in (2), yielding:

\[\Psi(\boldsymbol{Y},\hat{\boldsymbol{Y}})=m^{-1}\sum_{j=1}^{m}\psi( \boldsymbol{y}_{\cdot j},\hat{\boldsymbol{y}}_{\cdot j})=m^{-1}\sum_{j=1}^{m} \psi(\boldsymbol{C}(\boldsymbol{y}_{\cdot j},\hat{\boldsymbol{y}}_{\cdot j}) )\,. \tag{9}\]

By using \(\psi_{\text{pr}}(\boldsymbol{C})\coloneqq c_{11}/(c_{11}+c_{01})\), this becomes _macro-precision_, for \(\psi_{\text{rec}}(\boldsymbol{C})\coloneqq c_{11}/(c_{11}+c_{10})\) we get _macro-recall_, and for \(\psi_{\mathds{F}_{\beta}}(\boldsymbol{C})\coloneqq(\beta+1)c_{11}/((1+\beta)c _{11}+\beta^{2}c_{10}+c_{01})\) the _macro-F-measure_.

Another measure that is promising for the evaluation of long-tailed performance is _coverage_. It is sometimes used as an auxiliary measure in XMLC [15, 3, 42, 41]. This metric detects for how many different labels the classifier is able to make _at least one_ correct prediction. In our framework, this is achieved by using an indicator function on the true positives, \(\psi_{\text{cov}}(\boldsymbol{C})\coloneqq\mathds{1}[c_{11}>0]\).

## 4 Optimal predictions

Let us start with the observation that the label probabilities \(\boldsymbol{\eta}\) are sufficient to make optimal predictions. With the assumption that \(\mathds{P}(\boldsymbol{Y}|\boldsymbol{X})=\prod_{i=1}^{n}\mathds{P}( \boldsymbol{y}_{i}|\boldsymbol{x}_{i})\), we obtain (cf. Appendix A.2):

\[\mathds{E}_{\boldsymbol{Y}|\boldsymbol{X}}[\Psi(\boldsymbol{Y},\hat{ \boldsymbol{Y}})]=\sum_{j=1}^{m}\sum_{\boldsymbol{y}^{\prime}\in\{0,1\}^{n}} \Bigl{(}\prod_{i=1}^{n}\eta_{j}(\boldsymbol{x}_{i})y_{i}^{\prime}+(1-\eta_{j}( \boldsymbol{x}_{i}))(1-y_{i}^{\prime})\Bigr{)}\psi^{j}(\boldsymbol{y}^{ \prime},\hat{\boldsymbol{y}}_{\cdot j})\,. \tag{10}\]

This equation lays out a daunting optimization task, as is requires summing over \(2^{n}\) summands \(\boldsymbol{y}^{\prime}\). In case of binary classification, there exist methods to solve the problem exactly in \(\mathcal{O}(n^{3})\), or in \(\mathcal{O}(n^{2})\)in some special cases [32]. By using _semi-empirical_ quantities (defined below), [12] provides an approximate algorithm that runs in \(O(n)\). Following this approach, we construct a semi-empirical ETU approximation. If this approximation results in a _linear_ function of the predictions, the problem decomposes over instances and can be solved easily. Otherwise, we use an algorithm that leads to locally optimal predictions. A minor modification of this algorithm can be used for coverage.

### Semi-empirical ETU approximation

Since the entries of the confusion matrix are linearly dependent, it suffices to use three independent combinations. More precisely, we parameterize the confusion matrix by the true positives \(t=c_{11}\), predicted positives \(q=c_{11}+c_{01}\), and ground-truth positives \(p=c_{11}+c_{10}\), and use \(\mathbf{t}=(t_{1},\ldots,t_{m})\), \(\mathbf{q}=(q_{1},\ldots,q_{m})\), and \(\mathbf{p}=(p_{1},\ldots,p_{m})\) to reformulate the ETU objective:

\[\Psi_{\text{ETU}}(\hat{\mathbf{Y}})=\mathds{E}_{\mathbf{Y}|\mathbf{X}}[\Psi( \mathds{C}(\mathbf{Y},\hat{\mathbf{Y}}))]=\mathds{E}_{\mathbf{Y}|\mathbf{X}}[\Psi(\mathbf{t},\mathbf{ q},\mathbf{p})]=\mathds{E}_{\mathbf{Y}|\mathbf{X}}\Big{[}\sum_{j=1}^{m}\psi^{j}(t_{j},q_{j},p_{j })\Big{]}\,. \tag{11}\]

In order to compute \(\Psi_{\text{ETU}}\), one needs to take into account every possible combination of confusion-matrix values, and calculate the corresponding value of \(\Psi\), which is then averaged according to the respective probabilities. A computationally easier approach is to take the expectation over the labels first, leading to _semi-empirical_ quantities:

\[\tilde{\mathbf{t}}\coloneqq\mathds{E}_{\mathbf{Y}|\mathbf{X}}[\mathbf{t}]\,,\quad \tilde{\mathbf{q}}\coloneqq\mathds{E}_{\mathbf{Y}|\mathbf{X}}[\mathbf{q}]=\mathbf{q}\,,\quad\tilde{ \mathbf{p}}\coloneqq\mathds{E}_{\mathbf{Y}|\mathbf{X}}[\mathbf{p}]\,, \tag{12}\]

where \(\tilde{\mathbf{q}}=\mathbf{q}\) follows because the number of predicted positives depends only on the predictions \(\hat{\mathbf{Y}}\). This allows us to define the semi-empirical ETU risk

\[\tilde{\Psi}_{\text{ETU}}(\hat{\mathbf{Y}})\coloneqq\Psi(\tilde{\mathbf{t}},\mathbf{q}, \tilde{\mathbf{p}})\approx\mathds{E}_{\mathbf{Y}|\mathbf{X}}[\Psi(\mathbf{t},\mathbf{q},\mathbf{p})]= \Psi_{\text{ETU}}(\hat{\mathbf{Y}})\,. \tag{13}\]

In particular, the third argument to \(\Psi\), \(\tilde{\mathbf{p}}\), is a constant that does not depend on predictions.

Note that, if \(\Psi\) is _linear_ in all arguments _depending on the random variable \(\mathbf{Y}\)_, then the approximation is exact, due to the linearity of expectations. Aside from instance-wise measures, which we showed to be linear above, the approximation is also exact for the more general class of functions of the form

\[\psi(t,q,p)=f_{\text{t}}(q)\cdot t+f_{\text{q}}(q)+f_{\text{p}}(q)\cdot p\,. \tag{14}\]

An important example is macro-precision, with \(f_{\text{t}}(q)=q^{-1}\) and \(f_{\text{q}}=f_{\text{p}}=0\). In the general case, \(\tilde{\Psi}_{\text{ETU}}\) as a surrogate for \(\Psi_{\text{ETU}}\) leads only to \(\mathcal{O}(1/\sqrt{n})\) error as will be shown in Theorem 5.2, while substantially simplifying the optimization process.

### Linear confusion-matrix measures

We start the discussion on optimization of (13) with a special case in which \(\tilde{\Psi}_{\text{ETU}}\) is _linear in the prediction-dependent arguments_\(t,q\), that is, if

\[\psi(t,q,p)=f_{\text{t}}(p)\cdot t+f_{\text{q}}(p)\cdot q\,, \tag{15}\]

i.e., both \(f_{\text{t}}(p)\) and \(f_{\text{q}}(p)\) depend on \(p\) only, and \(f_{\text{p}}(p)\cdot p\) can be dropped as it is a constant.

Aside from instance-wise weighted utilities (cf. Appendix A.3), which are linear in all arguments, this form also holds for weights dependent on the (empirical) label priors, e.g., power law weights of the form \(f_{\text{t}}(p)=p^{-\alpha}\) and \(f_{\text{q}}=0\), which reduce to macro-recall for \(\alpha=1\). If one defines the weights with respect to externally determined label priors, i.e., approximations to \(\mathds{E}[y_{j}]\), which are fixed and thus independent of the test sample \(\mathbf{X}\), then the power-law metrics turn into instance-wise weighted utilities.

From (6) we know that we can reformulate the optimization problem using an instance-wise weighted utility \(u_{\text{w}}\) with weights:

\[w_{11}^{j}=f_{\text{t}}(p_{j})+f_{\text{q}}(p_{j})\,,\quad w_{01}^{j}=f_{\text {q}}(p_{j})\,,\quad w_{10}^{j}=0\,,\quad w_{00}^{j}=0\,. \tag{16}\]

Hence, the optimal predictions can be derived for each instance \(\mathbf{x}\in\mathcal{X}\) separately, leading to

\[\hat{\mathbf{y}}^{*}=\operatorname*{argmax}_{\hat{\mathbf{y}}\in\mathcal{Y}_{k}} \mathds{E}_{\mathbf{y}|\mathbf{x}}[u_{\text{w}}(\mathbf{y},\hat{\mathbf{y}})]. \tag{17}\]

Plugging in the definition of \(u_{\text{w}}\) from (5), and collecting terms, the expected loss is of the form

\[\mathds{E}_{\mathbf{y}|\mathbf{x}}[u_{\text{w}}(\mathbf{y},\hat{\mathbf{y}})]=\sum_{j=1}^{m} \mathds{E}_{\mathbf{y}|\mathbf{x}}\Big{[}w_{11}^{j}y_{j}\hat{y}_{j}+w_{01}^{j}(1-y_{j} )\hat{y}_{j}\Big{]}=\sum_{j=1}^{m}\hat{y}_{j}\left(\eta_{j}(\mathbf{x})f_{\text{t} }(p_{j})+f_{\text{q}}(p_{j})\right)\,, \tag{18}\]

[MISSING_PAGE_FAIL:6]

### Optimization of coverage

One measure for which the ETU approximation is not exact is coverage as \(\psi_{\text{cov}}(t,q,p)\coloneqq\mathds{1}[t>0]\) is _nonlinear_. In this case, we can do better than Algorithm 1, by reformulating \(\Psi_{\text{ETU}}\) for coverage as

\[\Psi_{\text{ETU}}(\hat{\mathbf{Y}})=\mathds{E}_{\mathbf{Y}\mid\mathbf{X}}\Big{[}m^{-1}\sum_ {j=1}^{m}\mathds{1}[t_{j}>0]\Big{]}=1-m^{-1}\sum_{j=1}^{m}\prod_{i=1}^{n}\left( 1-\eta_{j}(\mathbf{x}_{i})\hat{y}_{ij}\right)\,, \tag{24}\]

and performing block coordinate ascent directly on this expression, as detailed in Appendix B.3.

## 5 Regret bounds

Computing optimal predictions relies on an access to the conditional marginal probabilities \(\mathbf{\eta}(\mathbf{x})\). In practice, however, \(\mathbf{\eta}(\mathbf{x})\) are unknown, and are replaced by the LPE \(\hat{\mathbf{\eta}}(\mathbf{x})\) to do inference (_plug-in_ approach). Furthermore, we replaced the ETU objective \(\Psi_{\text{ETU}}\) with an approximation \(\tilde{\Psi}_{\text{ETU}}\). As generally \(\hat{\mathbf{\eta}}(\mathbf{x})\neq\mathbf{\eta}(\mathbf{x})\) and \(\Psi_{\text{ETU}}\neq\tilde{\Psi}_{\text{ETU}}\), this procedure may result in sub-optimal predictions, the errors of which we would like to control.

If we are able to control the change of the utility under small changes in its arguments, we can show that the suboptimality of the plug-in predictor relative to the optimal predictor (called _\(\Psi\)-regret_) decreases with increasing test size \(n\) and decreasing probability estimation error.

To this end we assume that each \(\psi^{j}\) is a _\(p\)-Lipschitz_ function, which allows us to bound the approximation error.

**Definition 5.1** (\(p\)-Lipschitz [13]).: A binary classification metric \(\psi(t,q,p)\) is said to be \(p\)-Lipschitz if

\[|\psi(t,q,p)-\psi(t^{\prime},q^{\prime},p^{\prime})|\leq L_{\mathrm{t}}(p)|t-t ^{\prime}|+L_{\mathrm{q}}(p)|q-q^{\prime}|+L_{\mathrm{p}}(p)|p-p^{\prime}|, \tag{25}\]

for any \(q,q^{\prime}\in[0,1]\), \(p,p^{\prime}\in(0,1)\), \(0\leq t\leq\min(p,q)\), and \(0\leq t^{\prime}\leq\min(p^{\prime},q^{\prime})\). The constants \(L_{\mathrm{t}}(p),L_{\mathrm{q}}(p),L_{\mathrm{p}}(p)\) are allowed to depend on \(p\), in contrast to the standard Lipschitz functions.

As shown in Appendix C.3, most of metrics of interest satisfy \(p\)-Lipschitz assumption, including the linear confusion-matrix measures (6) with fixed weights (e.g., Hamming utility, precision), macro-recall, macro-F-measure, etc., with macro-precision and coverage being notable exceptions.

**Theorem 5.2**.: _Let each \(\psi^{j}\) be \(p\)-Lipschitz with constants \(L_{\mathrm{q}}^{j}(p),L_{\mathrm{q}}^{j}(p),L_{\mathrm{p}}^{j}(p)\). For any \(\hat{\mathbf{Y}}\) it holds:_

\[|\Psi_{\text{ETU}}(\hat{\mathbf{Y}};\mathbf{X})-\tilde{\Psi}_{\text{ETU}}(\hat{\mathbf{Y} };\mathbf{X})|\leq\frac{1}{2\sqrt{n}}\left(\sum_{j=1}^{m}(L_{\mathrm{t}}^{j}( \tilde{p}_{j})+L_{\mathrm{p}}^{j}(\tilde{p}_{j}))\right)\,. \tag{26}\]

Thus, using \(\tilde{\Psi}_{\text{ETU}}\) as a surrogate for \(\Psi_{\text{ETU}}\) leads only to \(\mathcal{O}(1/\sqrt{n})\) error, diminishing with the test size, while substantially simplifying the optimization process.

Given a decomposable metric of the form (4), let \(\hat{\mathbf{Y}}^{\dagger}\) be the plug-in prediction matrix optimizing the semi-empirical ETU with plugged-in probability estimates, \(\Psi\big{(}\mathds{E}_{\mathbf{y}\sim\hat{\mathbf{\eta}}(\mathbf{X})}[\mathbf{t}],\mathbf{q}, \mathds{E}_{\mathbf{y}\sim\hat{\mathbf{\eta}}(\mathbf{X})}[\mathbf{p}]\big{)}\).

**Theorem 5.3**.: _Let \(\hat{\mathbf{Y}}^{\dagger}\) be defined as above. Under the assumptions of Theorem 5.2:_

\[\Psi_{\text{ETU}}(\hat{\mathbf{Y}}^{\star};\mathbf{X})-\Psi_{\text{ETU}}\big{(}\hat{\bm {Y}}^{\dagger};\mathbf{X}\big{)}\leq\frac{m}{\sqrt{n}}B+2\frac{\sqrt{m}}{n}B\sum_{ i=1}^{n}\|\mathbf{\eta}(\mathbf{x}_{i})-\hat{\mathbf{\eta}}(\mathbf{x}_{i})\|_{2}, \tag{27}\]

_where \(B\coloneqq\sqrt{m^{-1}\sum_{j=1}^{m}(L_{\mathrm{t}}^{j}(\tilde{p}_{j})+L_{ \mathrm{p}}^{j}(p_{j}))^{2}}\) is the quadratic mean of the Lipschitz constants._

A similar statement, presented in Appendix C.4, can be made for the unapproximated ETU case.

Thus, the methods described in Section 4 can be used with probability estimates replacing the true marginals, and as long as the estimator is reliable, the resulting predictions will have small \(\Psi\)-regret. This also justifies the plug-in approach used in the experiments in Section 7.

## 6 Efficient inference

The optimization algorithms introduced so far need to obtain \(\hat{\eta}_{j}(\mathbf{x}_{i})\) for _all_ labels and instances first. Then, the BCA inference is of \(\mathcal{O}(nm)\) time and \(\mathcal{O}(nm)\) space complexity for a single iteration. Thisis problematic in the setting of XMLC, where many methods aim to predict probabilities only for top labels in time sublinear in \(m\). Fortunately, this characteristic of XMLC algorithms can be combined with the introduced algorithms to efficiently obtain an approximate solution. Instead of predicting all \(\boldsymbol{\eta}\), we can predict probabilities only for top-\(k^{\prime}\) labels with highest \(\hat{\eta}_{j}\), where \(k\ll k^{\prime}\ll m\). For all other labels we then assume \(\hat{\eta}_{j}=0\). Under the natural assumption that \(\psi\) is _non-decreasing_ in true positives and _non-increasing_ in predicted positives, we can leverage the sparsity and consider labels with non-zero \(\hat{\eta}_{j}\) only (using sparse vectors to represent \(\hat{\boldsymbol{\eta}}(\boldsymbol{x}_{i})\)) to reduce the time and space complexity to \(\mathcal{O}(n(k^{\prime}+k\log k))\) and \(\mathcal{O}(n(k^{\prime}+k))\), respectively. As in real-world datasets the number of relevant labels \(\|\boldsymbol{y}\|_{1}\) is much lower than \(m\), and most \(\eta_{j}(\boldsymbol{x}_{i})\) are close to 0, with reasonably selected \(k^{\prime}\), according to Theorem 5.3, we should only slightly increase the regret. A pseudocode for the sparse variant of Algorithm 1 can be found in Appendix D.

Alternatively, we can leverage probabilistic label trees (PLTs) [16], a popular approach in XMLC [35; 45; 19; 50; 7], to efficiently search for "interesting" labels. Originally, PLTs find top labels with the highest \(\hat{\eta}_{j}\). In [46], an \(A^{*}\)-search algorithm has been introduced for finding \(k\) labels with highest value of \(g_{j}\eta_{j}(\boldsymbol{x})\), where \(g_{j}\in[0,\infty)\) is a gain assigned to label \(j\). In Appendix F, we present a more general version of this procedure that can be used to efficiently obtain an exact solution of presented BCA or Greedy algorithms for some of the metrics considered in this work.

## 7 Experiments

To empirically test the introduced framework, we use popular benchmarks from the XMLC repository [6]. We train the LightXML [18] model (with suggested default hyper-parameters) on provided training sets to obtain \(\hat{\boldsymbol{\eta}}\) for all test instances. We then plug these estimates into different inference strategies and report the results across the discussed measures. To run the optimization algorithm efficiently, we use \(k^{\prime}=100\) or \(k^{\prime}=1000\) to pre-select for each instance the top \(k^{\prime}\) labels with the highest \(\hat{\eta}_{j}\) as described in Section 6.3

Footnote 3: A code to reproduce all the experiments: [https://github.com/mwydmuch/xCOLUMNs](https://github.com/mwydmuch/xCOLUMNs)

We use the following inference strategies:

* Top-K- the optimal strategy for precision\(@k\): selection of \(k\) labels with the highest \(\eta_{j}\) (default prediction strategy in many XMLC methods).
* PS-K- the optimal strategy for propensity-scored precision\(@k\): selection of \(k\) labels with the highest \(w_{11}^{j,\text{prop}}\eta_{j}\), with \(w_{11}^{j,\text{prop}}\) given by the empirical model of Jain et al. [15] (Equation 7) with values \(a\) and \(b\) recommended by the authors.
* Pow-K, Log-K- the optimal strategy for power-law and log weighted instance-wise utilities: selection of \(k\) labels with the highest \(w_{11}^{j,\text{pl}}\eta_{j}\) or \(w_{11}^{j,\text{log}}\eta_{j}\). For power-law, we use \(\beta=0.5\).
* Macro-P\({}_{\text{bca}}\), Macro-R\({}_{\text{bca}}\), Macro-F\({}_{\text{lca}}\), Co\({}_{\text{Vaca}}\)- the block coordinate ascent (Algorithm 1) for optimizing macro-precision, -recall, -F1, and coverage,

We expect a strategy suited for a given metric to obtain the best results on this metric. Nevertheless, this might not always be the case, as in the derivation of our algorithms, we needed to apply different types of approximation to scale them to XMLC problems. We are mainly interested in the performance on the general non-decomposable macro measures since they seem to be well-tailored to long tails, and their optimization is the most challenging. The results are presented in Table 2. Notice that in almost all cases, the specialized inference strategies are indeed the best on the measure they aim to optimize and achieve substantial gains on corresponding metrics compared to the basic Top-K inference. The other weighted strategies, PS-K, Pow-K, Log-K, usually provide a much smaller improvement over Top-K and never beat strategies designed for specific macro measures. As the reported performance depends on three things: the inherent difficulty of the data, the success of the inference algorithm, and the quality of the provided

Figure 1: Results of an inference strategy with a mixed utility on AmazonCat-13K and \(k=3\). The green line shows the results for different interpolations between two measures.

marginal probabilities, the results might diverge from expectations in some cases. In Appendix E, we provide more details and conduct further experiments to investigate the impact of randomness, stopping conditions, quality of probability estimates, and shortlisting on the results. We also present similar experiments with probabilistic label trees used as an LPE.

Unfortunately, our results show that optimization of macro-measures comes with the cost of a significant drop in performance on instance-wise measures. Ideally, we would like to improve the performance on tail labels without sacrificing too much of general performance. To achieve such a trade-off, we can use straight-forward interpolation of instance-wise precision-at-k, as it is covered by our framework, and a selected macro-measure, since the considered class of utility functions is closed under linear combinations. Such an objective can be optimized by the proposed block-coordinate algorithm without any modification. As an example, we plot in Table 7 the results of optimizing a linear combination of instance-wise precision and the macro-F1 measure: \(\Psi(\mathbf{Y},\hat{\mathbf{Y}})=(1-\alpha)\Psi_{\text{Instance-F}}(\mathbf{Y},\hat{\mathbf{Y} })+\alpha\Psi_{\text{Macro-F1}}(\mathbf{Y},\hat{\mathbf{Y}})\), using different values of \(\alpha\in[0,1]\). In Appendix E.5, we provide more plots for different utilities, datasets, and values of \(k\). All the plots show that the instance-vs-macro curve has a nice concave shape that dominates simple baselines. In particular, the initial significant improvement on macro-measures comes with a minor drop in instance-measures, and only if one wants to optimize more strongly for macro-measures, the drop on instance-wise measures becomes more severe.

\begin{table}
\begin{tabular}{l|c|c c c c c c c|c c c c c c c c} \hline \hline Inference & Instance & \(\#3\) & \multicolumn{3}{c|}{Macro \(\#3\)} & \multicolumn{3}{c|}{Instance \(\#5\)} & \multicolumn{3}{c|}{Macro \(\#5\)} & \multicolumn{3}{c}{Instance \(\#10\)} & \multicolumn{3}{c}{Macro \(\#10\)} \\ strategy & P & R & P & R & F1 & Cov & P & R & P & R & F1 & Cov & P & R & F1 & Cov \\ \hline \multicolumn{11}{c}{**Euclidean**-K-\(\times\) 100} \\ \hline Tor-K & **57.240** & **44.21** & 24.85 & 16.45 & 18.63 & 31.27 & **6.231** & **40.89** & 27.43 & 25.99 & 25.50 & 39.76 & **39.22** & **75.11** & 22.15 & 36.59 & 26.01 & 47.55 \\ PS-K & 69.01 & 41.06 & 30.12 & 23.72 & 25.08 & 40.29 & 60.77 & 59.17 & 29.10 & 29.89 & 28.17 & 44.03 & 38.98 & 74.54 & 21.36 & 38.27 & 25.78 & 49.47 \\ Pow-K & 66.35 & 38.95 & 34.09 & **23.62** & 25.92 & 42.94 & 61.11 & 58.53 & 71.01 & 28.88 & 37.25 & 28.53 & 45.48 & 34.76 & 36.07 & 20.77 & **38.85** & 25.43 & 50.33 \\ Lo-K & 71.03 & 42.09 & 30.24 & 23.90 & 22.10 & 21.20 & 37.99 & 51.97 & 53.91 & 53.82 & 28.48 & 27.76 & 22.32 & 42.06 & 27.40 & 26.00 & 37.92 & 25.83 & 48.61 \\ \hline Macro-P\({}_{\text{rec}}\) & 41.13 & 24.29 & **38.78** & 16.77 & 27.63 & 20.63 & 40.60 & 31.05 & 30.33 & **38.70** & 18.46 & 21.59 & 41.66 & 18.45 & 35.65 & **23.94** & 20.28 & 21.82 & 42.89 \\ Macro-Rec\({}_{\text{rec}}\) & 41.47 & 24.61 & 30.36 & 22.56 & 24.37 & 3.48 & 32.82 & 37.54 & 28.97 & 32.77 & 27.05 & 49.04 & 29.80 & 57.88 & 22.19 & 38.84 & 25.99 & 52.17 \\ Macro-F1\({}_{\text{rec}}\) & 41.96 & 30.44 & 24.51 & 23.78 & 44.72 & 36.18 & 54.04 & 17.82 & 39.52 & **30.18** & 45.13 & 35.49 & 24.29 & 27.32 & **12.04** & 44.77 & 37.56 \\ Cov\({}_{\text{exc}}\) & 24.00 & 14.03 & 31.46 & 21.30 & 19.05 & **47.19** & 16.40 & 15.95 & 29.86 & 24.53 & 18.81 & **50.09** & 9.31 & 18.05 & 26.99 & 28.28 & 17.41 & **52.84** \\ \hline \multicolumn{11}{c}{**Euclidean**-Cover-\(\times\) 17k - 100} \\ \hline Tor-K & **58.10** & **43.01** & 25.71 & 11.37 & 13.83 & 33.05 & **6.881** & **79.21** & 33.92 & 31.34 & 28.28 & 52.60 & **41.27** & **89.41** & 24.63 & 51.76 & 28.84 & 68.61 \\ PS-K & 79.09 & 60.15 & 43.89 & 38.64 & 38.56 & 62.06 & 66.63 & _77.89_ & 38.41 & 45.00 & 38.34 & 65.82 & 47.50 & 89.11 & 22.56 & 58.69 & 28.59 & 74.29 \\ Pow-K & 66.25 & 50.75 & 38.18 & 46.42 & 39.26 & 67.06 & 59.64 & 38.14 & 31.56 & 54.06 & 36.70 & 19.55 & 36.37 & 39.12 & 66.06 & 46.29 & 27.27 \\ Lo-K & 75.30 & 56.79 & 41.93 & 39.22 & 56.06 & 56.47 & 52.17 & 34.40 & 36.78 & 66.71 & 68.41 & 40.66 & 88.05 & 20.39 & 55.85 & 28.91 & 73.37 \\ \hline Macro-P\({}_{\text{rec}}\) & 54.97 & 41.61 & **64.27** & 29.22 & 37.56 & 76.18 & 41.53 & 49.66 & **43.81** & 30.43 & 35.99 & 76.25 & 25.32 & 57.33 & **61.84** & 33.06 & 36.08 & 78.17 \\ Macro-Rec\({}_{\text{rec}}\) & 47.74 & 37.11 & **43.10** & **48.82** & 34.68 & 80.87 & 38.93 & 48.26 & 25.17 & **26.87** & 33.27 & 25.97 & 26.50 & 61.99 & 17.35 & **22.83** & 23.24 & **84.84** \\ Macro-Rec\({}_{\text{rec}}\) & 70.61 & 53.86 & 51.95 & 42.22 & 42.87 & 87.03 & 70.91 & 52.32 & **32.08** & **29.63** & 76.33 & 28.24 & 49.51 & 35.17 & **29.81** & 81.39 \\ Cov\({}_{\text{exc}}\) & 4.53 & 2.29 & 34.93 & 35.16 & 15.91 & **28.70** & 3.20 & 2.63 & 29.40 & 30.95 & 14.23 & **54.30** & 21.13 & 3.36 & 19.02 & 44.28 & 10.74 & **85.40** \\ \hline \multicolumn{11}{c}{**Winjectural**-\(\times\) 100} \\ \hline Tor-K & **57.17** & **13.48** & 2.01 & 0.50 & 0.72 & 2.54 & **68.81** & **19.99** & 2.66 & 0.92 & 1.42 & 3.72 & **23.00** & **29.05** & 3.55 & 2.07 & 2.34 & 6.14 \\ PS-K & _67.95_ & _11.89_ & 3.89 & 1.47 & 1.93 & 47.62 & _1.687_ & _4.25_ & _1.807_ & 4.21 & 2.14 & 2.56 & 6.54 & 30.16 & 28.20 & 4.64 & 3.62 & 3.61 & 9.01 \\ Pow-K & _55.96_ & 9.59 & 4.49 & 2.14 & 2.59 & 6.98 & 50.12 & 1.40 & 4.83 & 3.17 & 3.87 & 5.03 & 21.27 & 25.07 & 5.00 & 3.16 & 4.47 & 1.37 \\ Lo-K & 65.20 & 11.34 & 3.40 & 1.24 & 1.66 & 4.84 & 57.74 & 16.49 & 3.74 & 1.86 & 2.25 & 5.99 & 4.32 & 24.37 & 4.24 & 3.46 & 3.37 & 8.61 \\ \hline Macro-P\({}_{\text{rec}}\) & 32.36 & 5.66 & **43.23** & 3.58 & 3.81 & 32.5 & 3.86 & **9.88** & 2.86 & 3.74 & 9.82 & 2.41 & 13.62 & **0.79** & 2.98 & 3.04 \\ Macro-Rec\({}_{\text{rec}}\) & 13.78 & 2.

## 8 Discussion

The advantage of the ETU framework is that one can use multiple inference strategies without re-training a model. This is especially useful in cases where it is not a-priori clear which performance measure should be optimized, or predictions for different purposes are needed at the same time. On the other hand, as this framework optimizes the performance directly on a given test set, it is not designed to make predictions for single instances independently. The ETU framework has mainly been studied in the case of binary classification problems. We are not aware of any work that focuses on optimizing the complex performance metrics in the ETU framework for multi-label classification. One could try to generalize the results from binary classification, but the existing algorithms might not scale well to the extreme number of labels and they do not take the budget of \(k\) labels into account.

Our paper gives novel and non-trivial results regarding this challenging optimization problem. We have thoroughly analyzed the ETU framework for a wide class of performance metrics, derived optimal prediction rules and constructed their computationally efficient approximations with provable regret guarantees and being robust against model misspecification. Our algorithm, based on block coordinate descent, scales effortlessly to XMLC problems and obtains promising empirical results.

Overall, we identified four categories of utilities, that differ in the complexity of the optimization algorithm--whether to use instance-wise optimization as in Section 4.2, or the block coordinate-ascent (Algorithm 1)-- and the guarantees for the result--whether semi-empirical quantities (Section 4.1) lead to an optimal solution, or a suboptimal with error bounded by Theorem 5.2. These are given as follows and summarized in Table 3:

* **Fully linear**: Optimal predictions for metrics that are linear in all entries of the confusion matrix, as (6), can be solved _exactly_ in an _instance-wise_ manner. Examples are classical metrics such as instance-wise precision\(@k\), or propensity-scored precision\(@k\).
* **Linear in predictions**: _Approximately optimal_ predictions for metrics that are linear in the predictions as given in (15) can be obtained using _instance-wise_ optimization, by switching from \(\Psi_{\text{ETU}}\) to \(\tilde{\Psi}_{\text{ETU}}\). An example is macro recall\(@k\).
* **Linear in labels**: If a metric is linear in the label variables as given in (14), then \(\tilde{\Psi}_{\text{ETU}}\equiv\Psi_{\text{ETU}}\). However, the resulting combinatorial optimization problem for \(\tilde{\Psi}_{\text{ETU}}\) is still complex enough, and we can solve it _only locally_. An example is macro precision\(@k\).
* **Nonlinear metrics**: If none of the above apply, we have \(\tilde{\Psi}_{\text{ETU}}\neq\Psi_{\text{ETU}}\), and have to solve it _locally_ using _block-coordinate ascent_. This is the case of macro \(F\)-measure\(@k\), or coverage\(@k\).

The macro-averaged metrics budgeted at \(k\) are attractive for measuring the long-tail performance. Macro-averaging treats all the labels as equally important, while the budget of \(k\) predictions requires the prediction algorithm to choose the labels "wisely." We believe that this approach is substantially better than the one based on propensity-scored metrics. It is important to make the distinction between a metric used as a surrogate for training or inference, and its use as a performance metric in itself. While the former might be well justified for many metrics, the latter not necessarily as a metric might not have a clear interpretation of the calculated numbers.

Finally, the proposed framework is a plug-in approach that works on estimates of marginal probabilities and can be seamlessly applied to many existing state-of-the-art XMLC algorithms that are able to output such predictions, including XR-Transformer [51], CascadeXML [20], and algorithmic approaches for dealing with missing labels [40, 36]. It can also be combined with recently proposed methods that try to improve predictive performance on the tail labels by, e.g., leveraging labels features to estimate labels-correlations [29, 39, 9, 52] or to do data augmentation and generate new training points for tail labels [43, 21, 8].

\begin{table}
\begin{tabular}{l l l} \hline \hline Linear in & Approx. & Algorithm \\ \hline \(t\), \(q\), \(p\) & No & Instance-wise \\ \(t\), \(q\) & Yes & Instance-wise \\ \(t\), \(p\) & No & Block-Coordinate \\ — & Yes & Block-Coordinate \\ \hline \hline \end{tabular}
\end{table}
Table 3: Four different classes of utilities

## Acknowledgments

A part of computational experiments for this paper had been performed in Poznan Supercomputing and Networking Center. We want to acknowledge the support of Academy of Finland via grants 347707 and 348215, and also thank Mohammadreza Qaraei for providing pre-generated LPEs, \(\tilde{\eta}\), obtained by LightXML using computational resources of CSC - IT Center for Science, Finland.

## References

* Agrawal et al. [2013] Rahul Agrawal, Archit Gupta, Yashoteja Prabhu, and Manik Varma. Multi-label learning with millions of labels: Recommending advertiser bid phrases for web pages. In _22nd International World Wide Web Conference, WWW '13, Rio de Janeiro, Brazil, May 13-17, 2013_, pages 13-24. International World Wide Web Conferences Steering Committee / ACM, 2013.
* Babbar and Scholkopf [2017] Rohit Babbar and Bernhard Scholkopf. Dismec: Distributed sparse machines for extreme multi-label classification. In _Proceedings of the tenth ACM international conference on web search and data mining_, pages 721-729, 2017.
* Babbar and Scholkopf [2019] Rohit Babbar and Bernhard Scholkopf. Data scarcity, robustness and extreme multi-label classification. _Machine Learning_, 108(8):1329-1351, 2019.
* Bartlett et al. [2006] Peter L Bartlett, Michael I Jordan, and Jon D McAuliffe. Convexity, classification, and risk bounds. _Journal of the American Statistical Association_, 101(473):138-156, 2006.
* Beygelzimer et al. [2009] Alina Beygelzimer, John Langford, Yury Lifshits, Gregory B. Sorkin, and Alexander L. Strehl. Conditional probability tree estimation analysis and algorithms. In _UAI 2009, Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence, Montreal, QC, Canada, June 18-21, 2009_, pages 51-58. AUAI Press, 2009.
* Bhatia et al. [2016] Kush. Bhatia, Kunal. Dahiya, Himanshu Jain, Anshul Mittal, Yashoteja Prabhu, and Manik Varma. The extreme classification repository: Multi-label datasets and code, 2016. URL [http://manikvarma.org/downloads/XC/XMLRepository.html](http://manikvarma.org/downloads/XC/XMLRepository.html).
* Chang et al. [2020] Wei-Cheng Chang, Hsiang-Fu Yu, Kai Zhong, Yiming Yang, and Inderjit S. Dhillon. Taming pretrained transformers for extreme multi-label text classification. In Rajesh Gupta, Yan Liu, Jiliang Tang, and B. Aditya Prakash, editors, _KDD '20: The 26th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Virtual Event, CA, USA, August 23-27, 2020_, pages 3163-3171. ACM, 2020.
* Chien et al. [2023] Eli Chien, Jiong Zhang, Cho-Jui Hsieh, Jyun-Yu Jiang, Wei-Cheng Chang, Olgica Milenkovic, and Hsiang-Fu Yu. Pina: Leveraging side information in extreme multi-label classification via predicted instance neighborhood aggregation. _arXiv preprint arXiv:2305.12349_, 2023.
* Dahiya et al. [2021] Kunal Dahiya, Ananye Agarwal, Deepak Saini, K Gururaj, Jian Jiao, Amit Singh, Sumeet Agarwal, Purushottam Kar, and Manik Varma. Siamesexml: Siamese networks meet extreme classifiers with 100m labels. In _International Conference on Machine Learning_, pages 2330-2340. PMLR, 2021.
* Dekel and Shamir [2010] Ofer Dekel and Ohad Shamir. Multiclass-multilabel classification with more classes than examples. In _Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, AISTATS 2010, Chia Laguna Resort, Sardinia, Italy, May 13-15, 2010_, volume 9 of _JMLR Proceedings_, pages 137-144. JMLR.org, 2010.
* Dembczynski et al. [2013] Krzysztof Dembczynski, Arkadiusz Jachnik, Wojciech Kotlowski, Willem Waegeman, and Eyke Hullermeier. Optimizing the f-measure in multi-label classification: Plug-in rule approach versus structured loss minimization. In _International conference on machine learning_, pages 1130-1138. PMLR, 2013.
* Dembczynski et al. [2017] Krzysztof Dembczynski, Wojciech Kotlowski, Oluwasanmi Koyejo, and Nagarajan Natarajan. Consistency analysis for binary classification revisited. In _Proceedings of the 34th International Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017_, volume 70 of _Proceedings of Machine Learning Research_, pages 961-969. PMLR, 2017.

* Dembczynski et al. [2017] Krzysztof Dembczynski, Wojciech Kotlowski, Oluwasanmi Koyejo, and Nagarajan Natarajan. Consistency analysis for binary classification revisited. In _Proceedings of the 34th International Conference on Machine Learning (ICML 2017)_, volume 70 of _Proceedings of Machine Learning Research_, pages 961-969. PMLR, 2017.
* Deng et al. [2011] Jia Deng, Sanjeev Satheesh, Alexander C. Berg, and Fei-Fei Li. Fast and balanced: Efficient label tree learning for large scale object recognition. In _Advances in Neural Information Processing Systems 24: 25th Annual Conference on Neural Information Processing Systems 2011. Proceedings of a meeting held 12-14 December 2011, Granada, Spain._, pages 567-575, 2011.
* Jain et al. [2016] Himanshu Jain, Yashoteja Prabhu, and Manik Varma. Extreme multi-label loss functions for recommendation, tagging, ranking and other missing label applications. In _Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining_, KDD '16, page 935-944. Association for Computing Machinery, 2016. ISBN 9781450342322.
* Jasinska et al. [2016] Kalina Jasinska, Krzysztof Dembczynski, Robert Busa-Fekete, Karlson Pfannschmidt, Timo Klerx, and Eyke Hullermeier. Extreme F-measure maximization using sparse probability estimates. In _Proceedings of the 33nd International Conference on Machine Learning, ICML 2016, New York City, NY, USA, June 19-24, 2016_, volume 48 of _JMLR Workshop and Conference Proceedings_, pages 1435-1444. JMLR.org, 2016.
* Jasinska-Kobus et al. [2020] Kalina Jasinska-Kobus, Marek Wydmuch, Krzysztof Dembczynski, Mikhail Kuznetsov, and Robert Busa-Fekete. Probabilistic label trees for extreme multi-label classification. _CoRR_, abs/2009.11218, 2020.
* Jiang et al. [2021] Ting Jiang, Deqing Wang, Leilei Sun, Huayi Yang, Zhengyang Zhao, and Fuzhen Zhuang. Lightxml: Transformer with dynamic negative sampling for high-performance extreme multi-label text classification. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 35, pages 7987-7994, 2021.
* Khandagale et al. [2020] Sujay Khandagale, Han Xiao, and Rohit Babbar. Bonsai: diverse and shallow trees for extreme multi-label classification. _Machine Learning_, 109(11):2099-2119, 2020.
* Kharbanda et al. [2022] Siddhant Kharbanda, Atmadeep Banerjee, Erik Schultheis, and Rohit Babbar. Cascadexml: Rethinking transformers for end-to-end multi-resolution training in extreme multi-label classification. _Advances in Neural Information Processing Systems_, 35:2074-2087, 2022.
* Kharbanda et al. [2022] Siddhant Kharbanda, Devaansh Gupta, Erik Schultheis, Atmadeep Banerjee, Vikas Verma, and Rohit Babbar. Gandalf: Data augmentation is all you need for extreme classification. 2022.
* Kotlowski and Dembczynski [2017] Wojciech Kotlowski and Krzysztof Dembczynski. Surrogate regret bounds for generalized classification performance metrics. _Machine Learning_, 10:549-572, 2017.
* Koyejo et al. [2015] Oluwasanmi Koyejo, Nagarajan Natarajan, Pradeep Ravikumar, and Inderjit S. Dhillon. Consistent multilabel classification. In _Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems 2015, December 7-12, 2015, Montreal, Quebec, Canada_, pages 3321-3329, 2015.
* Lam et al. [2015] Siu Kwan Lam, Antoine Pitrou, and Stanley Seibert. Numba: A llvm-based python jit compiler. In _Proceedings of the Second Workshop on the LLVM Compiler Infrastructure in HPC_, pages 1-6, 2015.
* Lewis [1995] David D. Lewis. Evaluating and optimizing autonomous text classification systems. In _SIGIR'95, Proceedings of the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. Seattle, Washington, USA, July 9-13, 1995 (Special Issue of the SIGIR Forum)_, pages 246-254. ACM Press, 1995.
* Lin and Lin [2023] Yu-Jen Lin and Chih-Jen Lin. On the thresholding strategy for infrequent labels in multi-label classification. In _Proceedings of the 32nd ACM International Conference on Information and Knowledge Management_, CIKM '23, page 1441-1450, New York, NY, USA, 2023. Association for Computing Machinery.

* McAuley et al. [2015] Julian McAuley, Rahul Pandey, and Jure Leskovec. Inferring networks of substitutable and complementary products. In _Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining_, pages 785-794, 2015.
* Medini et al. [2019] Tharun Kumar Reddy Medini, Qixuan Huang, Yiqiu Wang, Vijai Mohan, and Anshumali Shrivastava. Extreme classification in log memory using count-min sketch: A case study of amazon search with 50m products. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d' Alche-Buc, E. Fox, and R. Garnett, editors, _Advances in Neural Information Processing Systems 32_, pages 13265-13275. Curran Associates, Inc., 2019.
* Mittal et al. [2021] Anshul Mittal, Noveen Sachdeva, Sheshansh Agrawal, Sumeet Agarwal, Purushottam Kar, and Manik Varma. Eclare: Extreme classification with label graph correlations. In _Proceedings of the Web Conference 2021_, pages 3721-3732, 2021.
* Narasimhan et al. [2015] Harikrishna Narasimhan, Harish Ramaswamy, Aadirupa Saha, and Shivani Agarwal. Consistent multiclass algorithms for complex performance measures. In Francis Bach and David Blei, editors, _Proceedings of the 32nd International Conference on Machine Learning_, volume 37 of _Proceedings of Machine Learning Research_, pages 2398-2407, Lille, France, 07 2015. PMLR.
* Narasimhan et al. [2022] Harikrishna Narasimhan, Harish G. Ramaswamy, Shiv Kumar Tavker, Drona Khurana, Praneeth Netrapalli, and Shivani Agarwal. Consistent multiclass algorithms for complex metrics and constraints, 2022. URL [https://arxiv.org/abs/2210.09695](https://arxiv.org/abs/2210.09695).
* Natarajan et al. [2016] Nagarajan Natarajan, Oluwasanmi Koyejo, Pradeep Ravikumar, and Inderjit Dhillon. Optimal classification with multivariate losses. In Maria Florina Balcan and Kilian Q. Weinberger, editors, _Proceedings of The 33rd International Conference on Machine Learning_, volume 48 of _Proceedings of Machine Learning Research_, pages 1530-1538, New York, New York, USA, 20-22 Jun 2016. PMLR.
* August 24
- 27, 2014_, pages 263-272. ACM, 2014.
* Prabhu et al. [2018] Yashoteja Prabhu, Anil Kag, Shilpa Gopinath, Kunal Dahiya, Shrutendra Harsola, Rahul Agrawal, and Manik Varma. Extreme multi-label learning with label features for warm-start tagging, ranking & recommendation. In _Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining_, pages 441-449, 2018.
* Prabhu et al. [2018] Yashoteja Prabhu, Anil Kag, Shrutendra Harsola, Rahul Agrawal, and Manik Varma. Parabel: Partitioned label trees for extreme classification with application to dynamic search advertising. In _Proceedings of the 2018 World Wide Web Conference on World Wide Web, WWW 2018, Lyon, France, April 23-27, 2018_, pages 993-1002. ACM, 2018.
* Qaraei et al. [2021] Mohammadreza Qaraei, Erik Schultheis, Priyanshu Gupta, and Rohit Babbar. Convex surrogates for unbiased loss functions in extreme classification with missing labels. In _Proceedings of The Web Conference 2021_, WWW '21, New York, NY, USA, 2021. Association for Computing Machinery. doi:10.1145/3442381.3450139. URL [https://doi.org/10.1145/3442381.3450139](https://doi.org/10.1145/3442381.3450139).
* Reid and Williamson [2010] Mark Reid and Robert Williamson. Convexity of proper composite binary losses. In Yee Whye Teh and Mike Titterington, editors, _Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics_, volume 9 of _Proceedings of Machine Learning Research_, pages 637-644, Chia Laguna Resort, Sardinia, Italy, 13-15 May 2010. PMLR. URL [https://proceedings.mlr.press/v9/reid10a.html](https://proceedings.mlr.press/v9/reid10a.html).
* Russell and Norvig [2009] Stuart J. Russell and Peter Norvig. _Artificial Intelligence: a modern approach_. Pearson, 3 edition, 2009.
* Saini et al. [2021] Deepak Saini, Arnav Kumar Jain, Kushal Dave, Jian Jiao, Amit Singh, Ruofei Zhang, and Manik Varma. Galaxy: Graph neural networks with labelwise attention for extreme classification. In _Proceedings of the Web Conference 2021_, pages 3733-3744, 2021.

* Saito et al. [2020] Yuta Saito, Suguru Yaginuma, Yuta Nishino, Hayato Sakata, and Kazuhide Nakata. Unbiased recommender learning from missing-not-at-random implicit feedback. In _Proceedings of the 13th International Conference on Web Search and Data Mining_, WSDM '20, page 501-509, New York, NY, USA, 2020. Association for Computing Machinery. ISBN 9781450368223. doi: 10.1145/3336191.3371783. URL [https://doi.org/10.1145/3336191.3371783](https://doi.org/10.1145/3336191.3371783).
* Schultheis et al. [2022] Erik Schultheis, Marek Wydmuch, Rohit Babbar, and Krzysztof Dembczynski. On missing labels, long-tails and propensities in extreme multi-label classification. In _Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining_, pages 1547-1557, 2022.
* Wei and Li [2020] Tong Wei and Yu-Feng Li. Does tail label help for large-scale multi-label learning? _IEEE Transactions on Neural Networks and Learning Systems_, 31(7):2315-2324, 2020.
* Wei et al. [2021] Tong Wei, Wei-Wei Tu, Yu-Feng Li, and Guo-Ping Yang. Towards robust prediction on tail labels. In _Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining_, pages 1812-1820, 2021.
* Weston et al. [2013] Jason Weston, Ameesh Makadia, and Hector Yee. Label partitioning for sublinear ranking. In _Proceedings of the 30th International Conference on Machine Learning, ICML 2013, Atlanta, GA, USA, 16-21 June 2013_, volume 28 of _JMLR Workshop and Conference Proceedings_, pages 181-189. JMLR.org, 2013.
* Wydmuch et al. [2018] Marek Wydmuch, Kalina Jasinska, Mikhail Kuznetsov, Robert Busa-Fekete, and Krzysztof Dembczynski. A no-regret generalization of hierarchical softmax to extreme multi-label classification. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, _Advances in Neural Information Processing Systems 31_, pages 6355-6366. Curran Associates, Inc., 2018.
* Wydmuch et al. [2021] Marek Wydmuch, Kalina Jasinska-Kobus, Rohit Babbar, and Krzysztof Dembczynski. Propensity-scored probabilistic label trees. In _Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval_, SIGIR '21, page 2252-2256, New York, NY, USA, 2021. Association for Computing Machinery. ISBN 9781450380379.
* Yang [2001] Yiming Yang. A study of thresholding strategies for text categorization. In _Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval_, SIGIR '01, page 137-145, New York, NY, USA, 2001. Association for Computing Machinery. ISBN 1581133316.
* Ye et al. [2020] Hui Ye, Zhiyu Chen, Da-Han Wang, and Brian Davison. Pretrained generalized autoregressive model with adaptive probabilistic label clusters for extreme multi-label text classification. In _International Conference on Machine Learning_, pages 10809-10819. PMLR, 2020.
* July 1, 2012_. icml.cc / Omnipress, 2012.
* You et al. [2019] Ronghui You, Zihan Zhang, Zijve Wang, Suyang Dai, Hiroshi Mamitsuka, and Shanfeng Zhu. Attentionxml: Label tree-based attention-aware deep model for high-performance extreme multi-label text classification. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d Alche-Buc, E. Fox, and R. Garnett, editors, _Advances in Neural Information Processing Systems 32_, pages 5812-5822. Curran Associates, Inc., 2019.
* Zhang et al. [2021] Jiong Zhang, Wei-Cheng Chang, Hsiang-Fu Yu, and Inderjit Dhillon. Fast multi-resolution transformer fine-tuning for extreme multi-label text classification. _Advances in Neural Information Processing Systems_, 34:7267-7280, 2021.
* Zhang et al. [2022] Ruohong Zhang, Yau-Shan Wang, Yiming Yang, Donghan Yu, Tom Vu, and Likun Lei. Long-tailed extreme multi-label text classification with generated pseudo label descriptions. _arXiv preprint arXiv:2204.00958_, 2022.
* Zhuo et al. [2020] Jingwei Zhuo, Ziru Xu, Wei Dai, Han Zhu, Han Li, Jian Xu, and Kun Gai. Learning optimal tree models under beam search. In _Proceedings of the 37th International Conference on Machine Learning_, Vienna, Austria, 2020. PMLR.

Order-invariant linearly decomposable task metrics

In this section, we provide a closer look at the family \(\mathcal{L}_{\mathrm{OI}}\) of order-invariant task utilities that can be decomposed into a sum of label-specific functions as laid out in Section 2 in the main paper.

We first formalize the notion of instance-order invariance, and then show that this implies the possibility of reformulating the utility function based on the confusion matrix. We further prove that it is sufficient to know the _marginal_ label probabilities \(\mathbf{\eta}(\mathbf{x})\) for each instance \(\mathbf{x}\) in order to evaluate any utility \(\psi\in\mathcal{L}_{\mathrm{OI}}\) in the ETU-framework.

### Order-invariant task utilities as confusion-matrix metrics

We show in Theorem A.3 that any utility function \(\Psi(\mathbf{Y},\hat{\mathbf{Y}})\) that is invariant under instance reordering can be defined in terms of confusion matrices. In this way, we justify our choice in the main paper to focus on losses of the form given in (4).

More precisely, let \(\sigma\in\mathfrak{S}(n)\) be a permutation of rows, that is, for \(\mathbf{Y}=[\mathbf{y}_{1},\ldots,\mathbf{y}_{n}]^{\mathsf{T}}\), we define \(\sigma\mathbf{Y}=[\mathbf{y}_{\sigma(1)},\ldots,\mathbf{y}_{\sigma(n)}]^{\mathsf{T}}\). Then we can make the following definition:

**Definition A.1** (Invariant under instance reordering).: Let \(n,m\in\mathds{N}\) and \(\Psi\colon\{0,1\}^{n\times m}\times\{0,1\}^{n\times m}\longrightarrow\mathds{R}\) be a function of discrete labels and predictions. If \(\Psi\) remains unchanged for every permutation of rows \(\sigma\in\mathfrak{S}(n)\), i.e.,

\[\Psi(\mathbf{Y},\hat{\mathbf{Y}})=\Psi(\sigma\mathbf{Y},\sigma\hat{\mathbf{Y}})\,, \tag{28}\]

then we call \(\Psi\) a function that is _invariant under instance reordering_. We denote the set of instance-order-invariant losses with \(m\) labels as

\[\mathcal{I}_{m}\coloneqq\left\{\Psi\colon\{0,1\}^{n\times m}\times\{0,1\}^{n \times m}\longrightarrow\mathds{R}\colon\Psi\text{ is invariant under instance reordering}\right\}. \tag{29}\]

We further define the set of all possible confusion matrices with \(n\) instances as

\[\mathcal{C}(n)\coloneqq\left\{\mathbf{C}\colon n\mathbf{C}\in\mathds{N}^{2\times 2}, \|\mathbf{C}\|_{1,1}=1\right\}, \tag{30}\]

where \(\mathds{N}\) is the set of natural numbers including 0. Now we are ready to provide a lemma for the binary case:

**Lemma A.2**.: _Let \(\psi\colon\{0,1\}^{n}\times\{0,1\}^{n}\longrightarrow\mathds{R}\) be a binary loss function that is invariant under instances reordering. Then there exists a function \(\phi\colon\mathcal{C}(n)\longrightarrow\mathds{R}\) such that \(\psi=\phi\circ\mathbf{C}\)._

Proof.: We provide an explicit construction of \(\psi\). To that end, let \(\tilde{\mathbf{C}}\in\mathcal{C}(n)\) be one such confusion matrix, then there exists \((\mathbf{y},\hat{\mathbf{y}})\in\{0,1\}^{n}\times\{0,1\}^{n}\) given by

\[(\mathbf{y},\hat{\mathbf{y}})=[\underbrace{(1,1),\ldots,(1,1)}_{\times n\cdot\tilde{ \varepsilon}_{11}},\underbrace{(0,1),\ldots,(0,1)}_{\times n\cdot\tilde{ \varepsilon}_{01}},\underbrace{(1,0),\ldots,(1,0)}_{\times n\cdot\tilde{ \varepsilon}_{10}},\underbrace{(0,0),\ldots,(0,0)}_{\times n\cdot\tilde{ \varepsilon}_{00}}]^{\mathsf{T}}\,. \tag{31}\]

Define \(\phi\) such that \(\phi(\tilde{\mathbf{C}})=\psi(\mathbf{y},\hat{\mathbf{y}})\).

Now, let \((\mathbf{y}^{\prime},\hat{\mathbf{y}}^{\prime})\in\{0,1\}^{n}\times\{0,1\}^{n}\) be an arbitrary label-prediction combination, with \(\mathbf{C}(\mathbf{y}^{\prime},\hat{\mathbf{y}}^{\prime})=\tilde{\mathbf{C}}\). Then there exists a permutation \(\sigma\) such that \(\sigma\mathbf{y}^{\prime}=\mathbf{y}\) and \(\sigma\hat{\mathbf{y}}^{\prime}=\hat{\mathbf{y}}\). By the invariance assumption, it holds that

\[\psi(\mathbf{y}^{\prime},\hat{\mathbf{y}}^{\prime})=\psi(\sigma\mathbf{y}^{\prime},\sigma \hat{\mathbf{y}}^{\prime})=\psi(\mathbf{y},\hat{\mathbf{y}})=\phi(\tilde{\mathbf{C}})=\phi( \mathbf{C}(\mathbf{y}^{\prime},\hat{\mathbf{y}}^{\prime})). \tag{32}\]

As the original \(\tilde{\mathbf{C}}\in\mathcal{C}(n)\) was arbitrary, the statement is shown. 

We can now extend this lemma to show the equivalence of two definitions of the task losses considered in this paper:

**Theorem A.3** (Equivalence of order-invariance and confusion-matrix losses).: _Let \(n,m\in\mathds{N}\), and \(\mathcal{Y}=\{0,1\}^{m}\). Define the set of instance-order invariant, label-averaged losses as_

\[\mathcal{L}_{\mathrm{OI}}\coloneqq\left\{\Psi\in\mathcal{I}_{m}:(\mathbf{Y},\hat{ \mathbf{Y}})\mapsto\sum_{j=1}^{m}\psi^{j}(\mathbf{y}_{j\cdot j},\hat{\mathbf{y}}_{j\cdot j })\right\}, \tag{33}\]

[MISSING_PAGE_FAIL:16]

Block Coordinate Ascent

In this section, we provide additional analysis and variations of the block coordinate ascent algorithm. We first give an intuition into the gain-based selection of labels performed by the algorithm in the case of macro-precision. Then, we will illustrate how, for metrics that are linear in the prediction argument as per (15), the algorithm will recover the closed-form solution given in (19). Afterwards, we present an alternative formulation specifically for coverage, and conclude with greedy versions of the BCA algorithm.

### Example: Macro-Precision

As an example, consider the optimization of macro-precision. In this case, \(\psi^{j}(t,q,p)=t/q\). Plugging into the gain formula gives

\[g_{j}=\frac{t^{j}+\hat{\eta}_{j}(\mathbf{x}_{s})}{q^{j}+1}-\frac{t^{j}}{q^{j}}= \frac{p^{j}(t^{j}+\hat{\eta}_{j}(\mathbf{x}_{s}))-t^{j}(q^{j}+1)}{q^{j}(q^{j}+1)}= \frac{q^{j}\hat{\eta}_{j}(\mathbf{x}_{s})-t^{j}}{q^{j}(q^{j}+1)}\,. \tag{40}\]

This term is positive only if \(t^{j}/q^{j}<\hat{\eta}_{j}(\mathbf{x}_{s})\), i.e., predicting the label has a positive impact on the overall utility if its chance of being relevant, \(\hat{\eta}_{j}(\mathbf{x}_{s})\), is larger than the current estimate of precision for label \(j\). Of course, the "at-\(k\)" constraint means that, for a given instance, it may not be possible to select all labels with positive gain, or necessary to select some labels with negative gain to fulfill the constraint.

### Global optimality for linear metrics

If \(\psi^{j}\) is a linear function, i.e., it corresponds to an instance-wise measure as in (6), the gain \(\mathbf{g}\), defined through lines 9-11 in Algorithm 1, becomes

\[\psi^{j}(t+\hat{\eta}_{j}(\mathbf{x}_{s}),q+1,p)-\psi^{j}(t,q,p) =(t+\hat{\eta}_{j}(\mathbf{x}_{s})-t)f_{\text{t}}(p)+(q+1-q)f_{\text{ q}}(p)\] \[=\hat{\eta}_{j}(\mathbf{x}_{s})f_{\text{t}}(p)+f_{\text{q}}(p)\,, \tag{41}\]

because the influence of the other instances cancels out. This exactly reproduces the gain formula from Section 4.2, which means that for each instance, the block coordinate-ascent algorithm will select the globally (approximately) optimal decision on the first pass. If the metric is fully linear, this will be the Bayes-optimal decision, otherwise, it is approximately optimal in the sense of Theorem 5.2. In both cases, the algorithm will perform a second pass over the entire dataset in order to check the stopping criterion. This second pass will leave all predictions unchanged.

### The ETU approach for coverage

In this section, we derive the ETU risk presented initially in Section 4.4. Then, we present a block coordinate ascent algorithm for optimizing it. The step-by-step derivation of (24) is given below:

\[\Psi_{\text{ETU}}(\hat{\mathbf{Y}};\mathbf{X})=\mathds{E}_{\mathbf{Y}|\mathbf{X}} [\Psi_{\text{cov}}(\mathbf{t}(\mathbf{Y},\hat{\mathbf{Y}}),\mathbf{q}(\mathbf{Y},\hat{\mathbf{Y}}),\bm {p}(\mathbf{Y},\hat{\mathbf{Y}}))]\\ =\mathds{E}_{\mathbf{Y}|\mathbf{X}}\bigg{[}\frac{1}{m}\sum_{j=1}^{m} \mathds{1}[t_{j}>0]\bigg{]}=\mathds{E}_{\mathbf{Y}|\mathbf{X}}\bigg{[}\frac{1}{m}\sum_ {j=1}^{m}\left(1-\mathds{1}[t_{j}=0]\right)\bigg{]}\\ =\mathds{E}_{\mathbf{Y}|\mathbf{X}}\bigg{[}\frac{1}{m}\sum_{j=1}^{m} \left(1-\prod_{i=1}^{j}\left(1-y_{ij}\hat{y}_{ij}\right)\right)\bigg{]}= \mathds{E}_{\mathbf{Y}|\mathbf{X}}\bigg{[}1-\frac{1}{m}\sum_{j=1}^{m}\prod_{i=1}^{j} \left(1-y_{ij}\hat{y}_{ij}\right)\bigg{]}\,. \tag{42}\]

Because we assume labels for one instance to be independent on all other instances, i.e., \(\mathds{P}(\mathbf{Y}|\mathbf{X})=\prod_{i=1}^{n}\mathds{P}(\mathbf{y}_{i}|\mathbf{x}_{i})\), we obtain:

\[\Psi_{\text{ETU}}(\hat{\mathbf{Y}};\mathbf{X}) =1-\frac{1}{m}\sum_{j=1}^{m}\prod_{i=1}^{n}\left(1-\mathds{E}_{ \mathbf{Y}|\mathbf{X}}[y_{ij}\hat{y}_{ij}]\right)=1-\frac{1}{m}\sum_{j=1}^{m}\prod_{i =1}^{n}\left(1-\mathds{P}[y_{ij}=1|\mathbf{x}_{i}]\right)\] \[=1-\frac{1}{m}\sum_{j=1}^{m}\prod_{i=1}^{n}\left(1-\eta_{j}(\mathbf{x }_{i})\hat{y}_{ij}\right)\,. \tag{43}\]Based on this result we can construct a block coordinate ascent procedure which, for predictions being fixed for all instances except \(\mathbf{x}_{s}\), optimizes the following problem:

\[\max_{\mathbf{z}\in\mathcal{Y}_{k}}\sum_{j=1}^{m}\psi_{\text{cov}}^{j}(z_{j})=\sum_{j =1}^{m}\left(1-(1-\eta_{j}(\mathbf{x}_{s})z_{j})\underset{i\in[n]\setminus\{s\}}{ \prod}(1-\eta_{j}(\mathbf{x}_{i})\hat{y}_{ij})\right)\,. \tag{44}\]

Analogously to Section 4.3, everything except \(z_{j}\in\{0,1\}\) is given and we can define a gain vector with elements \(g_{j}=\psi_{\text{cov}}^{j}(1)-\psi_{\text{cov}}^{j}(0)\). Again the optimal prediction \(\mathbf{z}^{*}\) is then given by \(\mathbf{z}^{*}=\text{select-top-}k(\mathbf{g})\), and we get \(\hat{\mathbf{Y}}^{t+1}\) by replacing the \(s^{\text{th}}\) row of \(\hat{\mathbf{Y}}^{t}\) with \(\mathbf{z}^{*}\). Then we switch to the next instance \(s\gets s+1\), and repeat this process until no more progress is made.

Notice that \(\prod_{i=1}^{n}\left(1-\eta_{j}(\mathbf{x}_{i})\hat{y}_{ij}\right)\) corresponds to the probability of label \(j\) being irrelevant for all instances it was selected for. We denote this value as \(f_{j}\) and use it to speed up computations in each iteration of the algorithm:

\[f_{j}^{0}\coloneqq\prod_{i=1}^{n}\left(1-\eta_{j}(\mathbf{x}_{i})\hat{y}_{ij}^{0} \right)\,,\quad f_{j}^{t+1}\coloneqq f_{j}^{t}\frac{1-\eta_{j}(\mathbf{x}_{s})\hat {y}_{sj}^{t+1}}{1-\eta_{j}(\mathbf{x}_{s})\hat{y}_{sj}^{t}}\,. \tag{45}\]

We can then compute the gain vector using the following formula:

\[g_{j}=\left(1-f_{j}^{t}\frac{1-\eta_{j}(\mathbf{x}_{s})}{1-\eta_{j}(\mathbf{x}_{s}) \hat{y}_{sj}^{t}}\right)-\left(1-f_{j}^{t}\frac{1}{1-\eta_{j}(\mathbf{x}_{s})\hat{ y}_{sj}^{t}}\right)=\frac{\eta_{j}(\mathbf{x}_{s})f_{j}^{t}}{1-\eta_{j}(\mathbf{x}_{s}) \hat{y}_{sj}^{t}}\,. \tag{46}\]

This block coordinate ascent procedure for coverage is presented as Algorithm 2.

```
1:\(\tilde{\mathbf{t}}\leftarrow\mathbf{0}\), \(\mathbf{q}\leftarrow\mathbf{0}\), \(\tilde{\mathbf{p}}\leftarrow\mathbf{0}\)
2:for\(i\in[n]\)do
3:\(\tilde{\mathbf{p}}\leftarrow\tilde{\mathbf{p}}+\frac{1}{n}\tilde{\mathbf{\eta}}(\mathbf{x}_{i})\)
4:for\(j\in[m]\)do
5:\(\psi^{j}(1)\leftarrow\psi(\tilde{t}_{j}+\frac{1}{n}\hat{y}_{s}(\mathbf{x}_{s}),q_{j }+\frac{1}{n},\tilde{p}_{j})\)
6:\(\psi^{j}(0)\leftarrow\psi(\tilde{\mathbf{t}}_{j},\mathbf{q}_{j},\tilde{\mathbf{p}}_{j})\)
7:\(g_{j}\leftarrow\psi^{j}(1)-\psi^{j}(\mathbf{0})\)
8:\(\hat{\mathbf{y}}_{i}\leftarrow\text{select top-}k(\mathbf{g})\)
9:\(\tilde{\mathbf{t}}\leftarrow\tilde{\mathbf{t}}+\frac{1}{n}\tilde{\mathbf{\eta}}(\mathbf{x}_{i })\odot\hat{\mathbf{y}}_{i}\)
10:\(\mathbf{q}\leftarrow\mathbf{q}+\frac{1}{n}\hat{\mathbf{y}}_{i}\)
11:return\(\hat{\mathbf{Y}}\)
```

**Algorithm 3** Greedy \((\mathbf{X},\hat{\mathbf{\eta}},k)\)

### Greedy version of block coordinate-ascent

The inference strategy presented in Algorithm 1 requires multiple passes over the entire data. This might be computationally expensive and requires the whole dataset to be available at once. We, thus, propose a greedy version of the algorithm, that performs just a _single pass_ over the dataset and makes decisions for each instance by taking into account only statistics of _previously seen_ instances instead of all other instances in the dataset. This allows to apply this algorithm to the semi-online setting, where the algorithm observes and predicts for instances one by one, but does not receive immediate feedback for its decisions, in contrast to the usual online learning setting. The procedure is outlined as Algorithm 3, and its greedy variant as Algorithm 4. The results of this algorithm in comparison to the BCA approach are given later in Appendix E.

```
1:\(\mathbf{f}\leftarrow\mathbf{1}\)
2:for\(i\in[n]\)do
3:\(\mathbf{g}\leftarrow\mathbf{f}\odot\tilde{\mathbf{\eta}}(\mathbf{x}_{i})\)
4:\(\hat{\mathbf{y}}_{i}\leftarrow\text{select top-}k(\mathbf{g})\)
5:\(\mathbf{f}\leftarrow\mathbf{f}\odot(\mathbf{1}-\hat{\mathbf{\eta}}(\mathbf{x}_{i})\odot\hat{\mathbf{y }}_{i})\)
6:return\(\hat{\mathbf{Y}}\)
```

**Algorithm 4** Greedy for coverage \((\mathbf{X},\hat{\mathbf{\eta}},k)\)

```
1:\(\mathbf{f}\leftarrow\mathbf{1}\)
2:for\(i\in[n]\)do
3:\(\mathbf{g}\leftarrow\mathbf{f}\odot\tilde{\mathbf{\eta}}(\bmDetailed Regret Analysis

In this section, we discuss the \(p\)-Lipschitzness condition of the metrics of interest, and prove Theorem 5.2 and Theorem 5.3.

### \(p\)-Lipschitz utility functions

First, recall the definition from the main paper:

**Definition 5.1** (\(p\)-Lipschitz [13]).: A binary classification metric \(\psi(t,q,p)\) is said to be \(p\)-Lipschitz if

\[|\psi(t,q,p)-\psi(t^{\prime},q^{\prime},p^{\prime})|\leq L_{\mathrm{t}}(p)|t-t^ {\prime}|+L_{\mathrm{q}}(p)|q-q^{\prime}|+L_{\mathrm{p}}(p)|p-p^{\prime}|, \tag{25}\]

for any \(q,q^{\prime}\in[0,1]\), \(p,p^{\prime}\in(0,1)\), \(0\leq t\leq\min(p,q)\), and \(0\leq t^{\prime}\leq\min(p^{\prime},q^{\prime})\). The constants \(L_{\mathrm{q}}(p),L_{\mathrm{q}}(p),L_{\mathrm{p}}(p)\) are allowed to depend on \(p\), in contrast to the standard Lipschitz functions.

The rationale behind this definition is that while we need to control the change in value of the metric under small changes in its arguments, a standard definition of Lipschitzness (with global constant) would not be satisfied by many popular metrics. For the same reason, we only require stability for _non-trivial_ problems, that is, in cases where the rate of positives \(p\) is neither zero nor one.

Relaxing the definition to allow the constants vary as a function of \(p\) suffices to prove our stability results as well as regret bounds, while it is satisfied by most of the metrics of interest, as shown below. The notable exception not present in Table 4 is the _precision_ metric, which is not \(p\)-Lipschitz due to its behavior for \(q\to 0\).

**Lemma C.1**.: _The linear confusion-matrix measures defined by (6):_

\[\Psi(\mathbf{Y},\hat{\mathbf{Y}})=\sum_{j=1}^{m}\left(w_{00}^{j}c_{00}^{j}+w_{01}^{j}c _{01}^{j}+w_{10}^{j}c_{10}^{j}+w_{11}^{j}c_{11}^{j}\right) \tag{47}\]

_with fixed coefficient matrices \(\{\mathbf{W}^{j}\}_{j=1}^{m}\) are decomposable functions with \(p\)-Lipschitz components._

Proof.: The metric can be rewritten in a decomposable form \(\Psi=\sum_{j}\psi^{j}\), where each \(\psi^{j}\) in the \((t,q,p)\)-parameterization has the following form:

\[\psi^{j}(t,q,p)=T_{j}\cdot t+Q_{j}\cdot q+P_{j}\cdot p+C_{j} \tag{48}\]

where \(T_{j},Q_{j},P_{j},C_{j}\) are some combinations of the coefficient matrices \(\left\{\mathbf{W}^{j}\right\}_{j=1}^{m}\). Being a linear function of \(t,q,p\), \(\psi^{j}\) is Lipschitz. 

**Lemma C.2** (\(p\)-Lipschitzness of common utilities [13]).: _All metrics in Table 4 are \(p\)-Lipschitz._

Proof.: Here, we only prove the lemma for recall, which has not been covered by Proposition 1 of Dembczynski et al. [13].

\[|\psi(t,q,p)-\psi(t^{\prime},q^{\prime},p^{\prime})| =\left|\frac{t}{p}-\frac{t^{\prime}}{p}\right|=\left|\frac{t-t^{ \prime}}{p}+\frac{t^{\prime}}{p^{\prime}}\frac{p^{\prime}-p}{p}\right|\] \[\leq\underbrace{\frac{1}{p}}_{=L_{\mathrm{t}}(p)}|t-t^{\prime}|+ \underbrace{\frac{t^{\prime}}{p^{\prime}}}_{\leq 1}\cdot\underbrace{\frac{1}{p}}_{=L_{ \mathrm{t}}(p)}|p-p^{\prime}|\,. \tag{49}\]

\begin{table}
\begin{tabular}{l l l} \hline \hline Metric & Definition & \(\psi(t,q,p)\) \\ \hline Accuracy & \(\mathrm{tp}+\mathrm{tn}\) & \(1+2t-q-p\) \\ Recall & \(\frac{\mathrm{tp}}{\mathrm{tp}+\mathrm{fn}}\) & \(\frac{t}{p}\) \\ Bal. Acc. & \(\frac{\mathrm{tp}/2}{\mathrm{tp}+\mathrm{fn}}+\frac{\mathrm{tn}/2}{\mathrm{tn} +\mathrm{fp}}\) & \(\frac{t+p(1-q-p)}{2(1-p)}\) \\ \(F_{\beta}\) & \(\frac{(1+\beta^{2})\mathrm{tp}}{(1+\beta^{2})\mathrm{tp}+\beta^{2}\mathrm{ fn}+\mathrm{fp}}\) & \(\frac{(1+\beta^{2})t}{\beta^{2}p+q}\) \\ Jaccard & \(\frac{\mathrm{tp}}{\mathrm{tp}+\mathrm{fp}+\mathrm{fn}}\) & \(\frac{p+q-2t}{p+q-t}\) \\ G-Mean & \(\sqrt{\frac{\mathrm{tp}-\mathrm{tn}}{(\mathrm{tp}+\mathrm{fn})(\mathrm{tn}+ \mathrm{fp})}}\) & \(\frac{t(1-q-p+t)}{p(1-p)}\) \\ AUC & \(\frac{\mathrm{fp}-\mathrm{fn}}{(\mathrm{tp}+\mathrm{fn})(\mathrm{fp}+\mathrm{ tn})}\) & \(\frac{(q-t)(p-t)}{p(1-p)}\) \\ \hline \hline \end{tabular}
\end{table}
Table 4: Examples of \(p\)-Lipschitz metrics. We use \(\mathrm{tp}\), \(\mathrm{fp}\), \(\mathrm{fn}\), and \(\mathrm{tn}\) to denote true positives, false positives, false negatives, and true negatives.

### Stability of the semi-ETU approximation

We are now ready to prove that when the metric of interest has \(p\)-Lipschitz components, the semi-ETU approximation \(\tilde{\Psi}_{\mathrm{ETU}}\) presented in Section 4.1 remains close to the true objective \(\Psi_{\mathrm{ETU}}\). For the sake of convenience, let us recall the definition of the ETU objective:

\[\Psi_{\mathrm{ETU}}(\hat{\mathbf{Y}};\mathbf{X})=\mathds{E}_{\mathbf{Y}|\mathbf{X}}[\Psi(\mathbf{Y},\hat{\mathbf{Y}})]=\sum_{j=1}^{m}\mathds{E}_{\mathbf{Y}|\mathbf{X}}\big{[}\psi^{j}(t(\mathbf{ y}_{\cdot j},\hat{\mathbf{y}}_{\cdot j}),q(\hat{\mathbf{y}}_{\cdot j}),p(\mathbf{y}_{\cdot j})) \big{]}\,, \tag{50}\]

as well as its approximation:

\[\tilde{\Psi}_{\mathrm{ETU}}(\hat{\mathbf{Y}};\mathbf{X})=\sum_{j=1}^{m}\psi^{j}\big{(} \mathds{E}_{\mathbf{Y}|\mathbf{X}}[t(\mathbf{y}_{\cdot j},\hat{\mathbf{y}}_{\cdot j})],q(\hat{ \mathbf{y}}_{\cdot j}),\mathds{E}_{\mathbf{Y}|\mathbf{X}}[p(\mathbf{y}_{\cdot j})]\big{)}. \tag{51}\]

We prove the following result:

**Theorem 5.2**.: _Let each \(\psi^{j}\) be \(p\)-Lipschitz with constants \(L^{j}_{\mathrm{t}}(p),L^{j}_{\mathrm{d}}(p),L^{j}_{\mathrm{p}}(p)\). For any \(\hat{\mathbf{Y}}\) it holds:_

\[|\Psi_{\mathrm{ETU}}(\hat{\mathbf{Y}};\mathbf{X})-\tilde{\Psi}_{\mathrm{ ETU}}(\hat{\mathbf{Y}};\mathbf{X})|\leq\frac{1}{2\sqrt{n}}\left(\sum_{j=1}^{m}(L^{j}_{ \mathrm{t}}(\tilde{p}_{j})+L^{j}_{\mathrm{p}}(\tilde{p}_{j}))\right)\,. \tag{26}\]

Proof.: For the sake of the analysis, denote the Lipschitz constants as \(L^{j}_{\mathrm{t}}\coloneqq L^{j}_{\mathrm{t}}(\tilde{p}_{j})\) and \(L^{j}_{\mathrm{p}}\coloneqq L^{j}_{\mathrm{p}}(\tilde{p}_{j})\). Using definitions (50) and (51) and applying Jensen's inequality, we have

\[|\Psi_{\mathrm{ETU}}(\hat{\mathbf{Y}};\mathbf{X})-\tilde{\Psi}_{\mathrm{ ETU}}(\hat{\mathbf{Y}};\mathbf{X})| =\big{|}\sum_{j=1}^{m}\big{(}\mathds{E}_{\mathbf{Y}|\mathbf{X}}\big{[} \psi^{j}(t_{j},q_{j},p_{j})\big{]}-\psi^{j}(\tilde{t}_{j},q_{j},\tilde{p}_{j} )\big{)}\big{|}\] \[\leq\sum_{j=1}^{m}\mathds{E}_{\mathbf{Y}|\mathbf{X}}\big{[}\big{|}\psi^{j }(t_{j},q_{j},p_{j})-\psi^{j}(\tilde{t}_{j},q_{j},\tilde{p}_{j})\big{|}\big{]}\,, \tag{52}\]

We now bound each term in the sum by \((L^{j}_{\mathrm{t}}+L^{j}_{\mathrm{p}})/(2\sqrt{n})\), which will prove the theorem.

For each \(j\in[m]\), using \(p\)-Lipschitzness of \(\psi_{j}\) we have:

\[\big{|}\psi^{j}(t_{j},q_{j},p_{j})-\psi^{j}(\tilde{t}_{j},q_{j}, \tilde{p}_{j})\big{|} =\big{|}\psi^{j}(\tilde{t}_{j},q_{j},\tilde{p}_{j})-\psi^{j}(t_{j},q_{j},p_{j})\big{|}\] \[\leq L^{j}_{\mathrm{t}}|t_{j}-\tilde{t}_{j}|+L^{j}_{\mathrm{p}}|p _{j}-\tilde{p}_{j}|\,. \tag{53}\]

Taking expectation on both sides gives:

\[\mathds{E}_{\mathbf{Y}|\mathbf{X}}\big{[}\big{|}\psi^{j}(t_{j},q_{j},p_{j })-\psi^{j}(\tilde{t}_{j},q_{j},\tilde{p}_{j})\big{|}\big{]}\leq L^{j}_{ \mathrm{t}}\,\mathds{E}_{\mathbf{Y}|\mathbf{X}}[|t_{j}-\tilde{t}_{j}|]+L^{j}_{\mathrm{ p}}\,\mathds{E}_{\mathbf{Y}|\mathbf{X}}[|p_{j}-\tilde{p}_{j}|]\] \[\leq L^{j}_{\mathrm{t}}\sqrt{\mathds{E}_{\mathbf{Y}|\mathbf{X}}[(t_{j}- \tilde{t}_{j})^{2}]}+L^{j}_{\mathrm{p}}\sqrt{\mathds{E}_{\mathbf{Y}|\mathbf{X}}[(p_{j }-\tilde{p}_{j})^{2}]}\,, \tag{54}\]

where the last inequality follows from Jensen's inequality applied to a concave function \(x\mapsto\sqrt{x}\). Using the fact that \(\tilde{t}_{j}=\mathds{E}_{\mathbf{Y}|\mathbf{X}}[t_{j}]\) and \(\tilde{p}_{j}=\mathds{E}_{\mathbf{Y}|\mathbf{X}}[p_{j}]\), we have

\[\mathds{E}_{\mathbf{Y}|\mathbf{X}}\big{[}(t_{j}-\tilde{t}_{j})^{2}\big{]}=\mathrm{ Var}_{\mathbf{Y}|\mathbf{X}}(t_{j})\leq\frac{1}{4n}\,, \tag{55}\]

as \(t_{j}=n^{-1}\sum_{i=1}^{n}y_{ij}\hat{y}_{ij}\) is an average of \(n\) Bernoulli i.i.d. random variables \(y_{ij}\hat{y}_{ij}\), each having variance at most \(\frac{1}{4}\); and using the same argument, \(\mathds{E}_{\mathbf{Y}|\mathbf{X}}\big{[}(p_{j}-\tilde{p}_{j})^{2}\big{]}\leq\frac{1}{4 n}\). This gives

\[\mathds{E}_{\mathbf{Y}|\mathbf{X}}\big{[}\big{|}\psi^{j}(\tilde{t}_{j},q_{j},\tilde{p}_{ j})-\psi^{j}(t_{j},q_{j},p_{j})\big{|}\big{]}\leq\frac{L^{j}_{\mathrm{t}}+L^{j}_{ \mathrm{p}}}{2\sqrt{n}}\,, \tag{56}\]

and finishes the proof. 

### Regret of semi-ETU under model misspecification

In this section, we quantify the influence of the estimation error of marginal probabilities, proving Theorem 5.3.

NotationTo emphasize the dependence of \(\Psi_{\text{ETU}}\) on the label probability estimates, in this section we will write

\[\Psi_{\text{ETU}}(\hat{\mathbf{Y}};\mathbf{X})=\mathds{E}_{\mathbf{Y}\sim\mathbf{\eta}(\mathbf{X})}[ \Psi(\mathbf{Y},\hat{\mathbf{Y}})]\eqqcolon\Psi_{\text{ETU}}(\hat{\mathbf{Y}};\mathbf{\eta})\,, \tag{57}\]

This notation is well-defined, as we have shown in Appendix A.2 that in fact, the dependence on \(\mathbf{X}\) is mediated _only_ through the marginal label probabilities \(\mathbf{\eta}(\mathbf{X})=(\mathbf{\eta}(\mathbf{x}_{1}),\ldots,\mathbf{\eta}(\mathbf{x}_{n}))\), and we abbreviate \(\mathbf{\eta}(\mathbf{X})\) as \(\mathbf{\eta}\). Similarly, we will write

\[\tilde{t}_{j}(\mathbf{\eta}) =\mathds{E}_{\mathbf{y}_{j}\sim\eta_{j}(\mathbf{X})}[t(\mathbf{y}_{:j},\hat{ \mathbf{y}}_{:j})]=n^{-1}\sum_{i=1}^{n}\eta_{j}(\mathbf{x}_{i})\tilde{y}_{ij}\,,\] \[\tilde{p}_{j}(\mathbf{\eta}) =\mathds{E}_{\mathbf{y}_{j}\sim\eta_{j}(\mathbf{X})}[p(\mathbf{y}_{:j})]=n^{ -1}\sum_{i=1}^{n}\eta_{j}(\mathbf{x}_{i})\,. \tag{58}\]

Note that \(q\) is independent of \(\mathbf{\eta}\). This allows us to write the semi-ETU objective as

\[\tilde{\Psi}_{\text{ETU}}(\hat{\mathbf{Y}};\mathbf{\eta})\coloneqq\Psi(\tilde{\mathbf{t}}, \mathbf{q},\tilde{\mathbf{p}})\,, \tag{59}\]

where we dropped the dependence of \(\tilde{\mathbf{t}}\) and \(\tilde{\mathbf{p}}\) on \(\mathbf{\eta}\) as clear from the context. The optimal (Bayes) predictor \(\hat{\mathbf{Y}}^{\star}\) is the one which maximizes the expected utility with regard to the _true_ label probabilities. In the notation of this chapter, (1) reads

\[\hat{\mathbf{Y}}^{\star}=\operatorname*{argmax}_{\mathbf{Y}\in\mathcal{Y}^{\star}_{k}} \Psi_{\text{ETU}}(\hat{\mathbf{Y}};\mathbf{\eta})\,. \tag{60}\]

Unfortunately, the learning algorithm does not know the true label marginals \(\mathbf{\eta}(\mathbf{X})\), but has only access to the estimates \(\tilde{\mathbf{\eta}}(\mathbf{X})=(\tilde{\mathbf{\eta}}(\mathbf{x}_{1}),\ldots,\tilde{\mathbf{ \eta}}(\mathbf{x}_{n}))\) for the considered set of instances. The algorithm computes its predictions \(\hat{\mathbf{Y}}^{\dagger}\) by using the estimates in place of the true marginals. Thus, it can only generate

\[\hat{\mathbf{Y}}^{\dagger}=\operatorname*{argmax}_{\mathbf{\tilde{Y}}\in\mathcal{ \hat{Y}}^{\star}_{k}}\Psi_{\text{ETU}}(\hat{\mathbf{Y}};\tilde{\mathbf{\eta}})\,. \tag{61}\]

We can make the same definitions also for the semi-empirical ETU optimization, leading to

\[\tilde{\mathbf{Y}}^{\star}=\operatorname*{argmax}_{\mathbf{\tilde{Y}}\in\mathcal{ \hat{Y}}^{\star}_{k}}\tilde{\Psi}_{\text{ETU}}(\hat{\mathbf{Y}};\mathbf{\eta})\quad \text{and}\quad\tilde{\mathbf{Y}}^{\dagger}=\operatorname*{argmax}_{\mathbf{\tilde{Y}} \in\mathcal{\hat{Y}}^{\star}_{k}}\tilde{\Psi}_{\text{ETU}}(\hat{\mathbf{Y}};\tilde {\mathbf{\eta}})\,. \tag{62}\]

Regret for semi-ETU approximationFirst, we show that for metrics with \(p\)-Lipschitz components, the \(\Psi\)_-regret_ of the resulting semi-ETU predictor (62), which is the suboptimality of \(\tilde{\mathbf{Y}}^{\dagger}\) (with respect to \(\hat{\mathbf{Y}}^{\star}\)) in terms of \(\Psi_{\text{ETU}}\), is well-controlled and upper-bounded by the estimation error of the marginals. As the resulting expression is somewhat unwieldy, we then apply some further bounding to arrive at the much simpler result stated in the main paper in Theorem 5.3.

**Lemma C.3** (Misspecification for semi-ETU approximation).: _Let \(\Psi\in\mathcal{L}_{\text{OI}}\) be an instance-order invariant linearly decomposable loss function that is \(p\)-Lipschitz, and \(\hat{\mathbf{Y}}\) an arbitrary set of predictions. Then, the difference of the semi-empirical ETU risk when using two different versions of the marginals, \(\mathbf{\eta}\) and \(\mathbf{\eta}^{\prime}\), is bounded by the difference \(\mathbf{\eta}-\mathbf{\eta}^{\prime}\) through_

\[|\tilde{\Psi}_{\text{ETU}}(\hat{\mathbf{Y}};\mathbf{\eta})-\tilde{\Psi}_{\text{ETU}}( \hat{\mathbf{Y}};\mathbf{\eta}^{\prime})|\leq n^{-1}\sum_{j=1}^{m}\left(L^{j}_{\text{t }}(\hat{t}^{j}(\mathbf{\eta}))+L^{j}_{\text{p}}(\hat{p}^{j}(\mathbf{\eta}))\right)\sum _{i=1}^{n}|\eta_{j}(\mathbf{x}_{i})-\eta_{j}{}^{\prime}(\mathbf{x}_{i})|\,. \tag{63}\]

Proof.: Plugging in the definitions, we have

\[|\tilde{\Psi}_{\text{ETU}}(\hat{\mathbf{Y}};\mathbf{\eta})-\tilde{\Psi}_{ \text{ETU}}(\hat{\mathbf{Y}};\mathbf{\eta})|=\Bigl{|}\sum_{j=1}^{m}\psi^{j}\bigl{(} \tilde{t}^{j}(\mathbf{\eta}),q^{j},\tilde{p}^{j}(\mathbf{\eta})\bigr{)}-\sum_{j=1}^{m }\psi^{j}\bigl{(}\tilde{t}^{j}(\mathbf{\eta}^{\prime}),q^{j},\tilde{p}^{j}(\mathbf{ \eta}^{\prime})\bigr{)}\Bigr{|}\] \[\qquad\leq\sum_{j=1}^{m}L^{j}_{\text{t}}(\tilde{t}^{j}(\mathbf{\eta} ))\left|\tilde{t}^{j}(\mathbf{\eta})-\tilde{t}^{j}(\mathbf{\eta}^{\prime})\right|+L^{j}_ {\text{p}}(\tilde{p}^{j}(\mathbf{\eta}))\left|\tilde{p}^{j}(\mathbf{\eta})-\tilde{p}^{ j}(\mathbf{\eta}^{\prime})\right|\,, \tag{64}\]

where the last line used the definition of \(p\)-Lipschitzness.

The terms under the sum can be bounded by the estimation error of \(\mathbf{\eta}^{\prime}\):

\[|\tilde{t}_{j}(\mathbf{\eta})-\tilde{t}_{j}(\mathbf{\eta}^{\prime})|=\left|n ^{-1}\sum_{i=1}^{n}\hat{y}_{ij}(\eta_{j}(\mathbf{x}_{i})-{\eta_{j}}^{\prime}(\mathbf{x} _{i}))\right|\leq n^{-1}\sum_{i=1}^{n}\left|\eta_{j}(\mathbf{x}_{i})-{\eta_{j}}^{ \prime}(\mathbf{x}_{i})\right|,\] \[|\tilde{p}_{j}(\mathbf{\eta})-\tilde{p}_{j}(\mathbf{\eta}^{\prime})|=\left| n^{-1}\sum_{i=1}^{n}(\eta_{j}(\mathbf{x}_{i})-{\eta_{j}}^{\prime}(\mathbf{x}_{i})) \right|\leq n^{-1}\sum_{i=1}^{n}\left|\eta_{j}(\mathbf{x}_{i})-{\eta_{j}}^{\prime }(\mathbf{x}_{i})\right|, \tag{65}\]

where in the first line we used \(\hat{y}_{ij}\in\{0,1\}\). 

**Lemma C.4** (Regret bound for semi-ETU approximation).: _Let \(\Psi\in\mathcal{L}_{\mathrm{OI}}\) be an instance-order invariant linearly decomposable loss function that is \(p\)-Lipschitz. Then we have_

\[\Psi_{\mathrm{ETU}}(\hat{\mathbf{Y}}^{\star};\mathbf{X})-\Psi_{\mathrm{ ETU}}\big{(}\tilde{\mathbf{Y}}^{\dagger};\mathbf{X}\big{)}\leq\frac{1}{\sqrt{n}}\sum_{j=1}^ {m}\bigl{(}L_{\mathrm{t}}^{j}(\tilde{p}_{j}(\mathbf{\eta}))+L_{\mathrm{p}}^{j}( \tilde{p}_{j}(\mathbf{\eta}))\bigr{)}+\\ 2\sum_{j=1}^{m}\frac{L_{\mathrm{t}}^{j}(\tilde{p}_{j}(\mathbf{\eta} ))+L_{\mathrm{p}}^{j}(p_{j}(\mathbf{\eta}))}{n}\sum_{i=1}^{n}\left|\eta_{j}(\mathbf{x} _{i})-\hat{\eta}_{j}(\mathbf{x}_{i})\right|. \tag{66}\]

Proof.: Using the optimality of \(\tilde{\mathbf{Y}}^{\dagger}\) and a supremum bound, we get

\[\Psi_{\mathrm{ETU}}(\hat{\mathbf{Y}}^{\star};\mathbf{\eta})-\Psi_{\mathrm{ ETU}}\big{(}\tilde{\mathbf{Y}}^{\dagger};\mathbf{\eta}\big{)}=\Psi_{\mathrm{ETU}}( \hat{\mathbf{Y}}^{\star};\mathbf{\eta})-\tilde{\Psi}_{\mathrm{ETU}}(\hat{\mathbf{Y}}^{ \star};\hat{\mathbf{\eta}})\\ +\tilde{\Psi}_{\mathrm{ETU}}(\hat{\mathbf{Y}}^{\star};\hat{\mathbf{\eta}} )-\tilde{\Psi}_{\mathrm{ETU}}(\tilde{\mathbf{Y}}^{\dagger};\hat{\mathbf{\eta}})\\ +\tilde{\Psi}_{\mathrm{ETU}}(\tilde{\mathbf{Y}}^{\dagger};\hat{\mathbf{\eta }})-\tilde{\Psi}_{\mathrm{ETU}}(\tilde{\mathbf{Y}}^{\dagger};\mathbf{\eta})\\ \leq\Psi_{\mathrm{ETU}}(\tilde{\mathbf{Y}}^{\star};\mathbf{\eta})-\tilde{ \Psi}_{\mathrm{ETU}}(\tilde{\mathbf{Y}}^{\star};\hat{\mathbf{\eta}})\\ +\tilde{\Psi}_{\mathrm{ETU}}(\tilde{\mathbf{Y}}^{\dagger};\hat{\mathbf{ \eta}})-\tilde{\Psi}_{\mathrm{ETU}}(\tilde{\mathbf{Y}}^{\dagger};\mathbf{\eta})\\ \leq 2\sup_{\hat{\mathbf{Y}}}|\Psi_{\mathrm{ETU}}(\hat{\mathbf{Y}};\mathbf{ \eta})-\tilde{\Psi}_{\mathrm{ETU}}(\hat{\mathbf{Y}};\hat{\mathbf{\eta}})|. \tag{68}\]

We then use Theorem 5.2 and Lemma C.3 to bound

\[\left|\Psi_{\mathrm{ETU}}(\hat{\mathbf{Y}};\mathbf{\eta})-\tilde{\Psi}_{ \mathrm{ETU}}(\hat{\mathbf{Y}};\hat{\mathbf{\eta}})\right|\\ =\left|\Psi_{\mathrm{ETU}}(\hat{\mathbf{Y}};\mathbf{\eta})-\tilde{\Psi}_{ \mathrm{ETU}}(\hat{\mathbf{Y}};\mathbf{\eta})+\tilde{\Psi}_{\mathrm{ETU}}(\hat{\mathbf{Y} };\mathbf{\eta})-\tilde{\Psi}_{\mathrm{ETU}}(\hat{\mathbf{Y}};\hat{\mathbf{\eta}})\right|\\ \leq\left|\Psi_{\mathrm{ETU}}(\hat{\mathbf{Y}};\mathbf{\eta})-\tilde{\Psi }_{\mathrm{ETU}}(\hat{\mathbf{Y}};\mathbf{\eta})\right|+\left|\tilde{\Psi}_{\mathrm{ ETU}}(\hat{\mathbf{Y}};\mathbf{\eta})-\tilde{\Psi}_{\mathrm{ETU}}(\hat{\mathbf{Y}};\hat{\mathbf{\eta}})\right|\\ \leq\frac{1}{2\sqrt{n}}\left(\sum_{j=1}^{m}\bigl{(}L_{\mathrm{t}}^ {j}(\tilde{p}_{j})+L_{\mathrm{p}}^{j}(\tilde{p}_{j})\bigr{)}\right)+\sum_{j=1}^ {m}\frac{L_{\mathrm{t}}^{j}(\tilde{p}_{j})+L_{\mathrm{p}}^{j}(\tilde{p}_{j})}{ n}\sum_{i=1}^{n}\left|\eta_{j}(\mathbf{x}_{i})-\hat{\eta}_{j}(\mathbf{x}_{i})\right|, \tag{69}\]

where we use the shorthand \(\tilde{p}_{j}=\tilde{p}_{j}(\mathbf{\eta})\). 

At the cost of having a less strict bound, we can simplify this to

**Theorem 5.3**.: _Let \(\tilde{\mathbf{Y}}^{\dagger}\) be defined as above. Under the assumptions of Theorem 5.2:_

\[\Psi_{\mathrm{ETU}}(\tilde{\mathbf{Y}}^{\star};\mathbf{X})-\Psi_{\mathrm{ ETU}}\big{(}\tilde{\mathbf{Y}}^{\dagger};\mathbf{X}\big{)}\leq\frac{m}{\sqrt{n}}B+2\frac{ \sqrt{m}}{n}B\sum_{i=1}^{n}\|\mathbf{\eta}(\mathbf{x}_{i})-\hat{\mathbf{\eta}}(\mathbf{x}_{i}) \|_{2}, \tag{70}\]

_where \(B\coloneqq\sqrt{m^{-1}\sum_{j=1}^{m}(L_{\mathrm{t}}^{j}(\tilde{p}_{j})+L_{ \mathrm{p}}^{j}(p_{j}))^{2}}\) is the quadratic mean of the Lipschitz constants._Proof.: Using Cauchy-Schwartz, we can bound

\[\sum_{j=1}^{m}\frac{L_{\mathrm{t}}^{j}(\tilde{p}_{j}(\mathbf{\eta}))+L_{ \mathrm{p}}^{j}(p_{j}(\mathbf{\eta}))}{n}\sum_{i=1}^{n}|\eta_{j}(\mathbf{x}_{i})-\hat{ \eta}_{j}(\mathbf{x}_{i})|\] \[\qquad\leq n^{-1}\sum_{i=1}^{n}\sqrt{\sum_{j=1}^{m}\bigl{(}L_{ \mathrm{t}}^{j}(\tilde{p}_{j}(\mathbf{\eta}))+L_{\mathrm{p}}^{j}(p_{j}(\mathbf{\eta})) \bigr{)}^{2}}\cdot\sqrt{\sum_{j=1}^{m}(\eta_{j}(\mathbf{x}_{i})-\hat{\eta}_{j}(\bm {x}_{i}))^{2}}\] \[\qquad=n^{-1}\sqrt{\sum_{j=1}^{m}\bigl{(}L_{\mathrm{t}}^{j}( \tilde{p}_{j}(\mathbf{\eta}))+L_{\mathrm{p}}^{j}(p_{j}(\mathbf{\eta}))\bigr{)}^{2}} \cdot\sum_{i=1}^{n}\sqrt{\|\mathbf{\eta}(\mathbf{x}_{i})-\hat{\mathbf{\eta}}(\mathbf{x}_{i})\|_ {2}^{2}}\] \[\qquad=\frac{\sqrt{m}}{n}B\sum_{i=1}^{n}\|\mathbf{\eta}(\mathbf{x}_{i})- \hat{\mathbf{\eta}}(\mathbf{x}_{i})\|_{2}\,. \tag{70}\]

For the other term, we can use the inequality between arithmetic and quadratic mean, so that

\[\sum_{j=1}^{m}\bigl{(}L_{\mathrm{t}}^{j}(\tilde{p}_{j}(\mathbf{\eta}))+L_{\mathrm{p }}^{j}(\tilde{p}_{j}(\mathbf{\eta}))\bigr{)}\leq m\sqrt{m^{-1}\sum_{j=1}^{m}\bigl{(} L_{\mathrm{t}}^{j}(\tilde{p}_{j}(\mathbf{\eta}))+L_{\mathrm{p}}^{j}(\tilde{p}_{j}(\mathbf{ \eta}))\bigr{)}^{2}}=mB\,. \tag{71}\]

### Regret for non-approximated ETU

We can formulate the equivalent of Lemma C.4 also for the maximizer of the true empirical ETU risk, \(\hat{\mathbf{Y}}^{\dagger}\):

**Lemma C.5** (Regret bound for ETU maximization).: _Let \(\Psi\in\mathcal{L}_{\mathrm{OI}}\) be an instance-order invariant linearly decomposable loss function that is \(p\)-Lipschitz. Then we have_

\[\Psi_{\mathrm{ETU}}(\hat{\mathbf{Y}}^{\star};\mathbf{X})-\Psi_{\mathrm{ETU }}(\hat{\mathbf{Y}}^{\dagger};\mathbf{X})\leq\frac{1}{\sqrt{n}}\sum_{j=1}^{m}\bigl{(} L_{\mathrm{t}}^{j}(\tilde{p}_{j}(\mathbf{\eta}))+L_{\mathrm{t}}^{j}(\tilde{p}_{j}( \hat{\mathbf{\eta}}))+L_{\mathrm{p}}^{j}(\tilde{p}_{j}(\mathbf{\eta}))+L_{\mathrm{p}}^{ j}(\tilde{p}_{j}(\hat{\mathbf{\eta}}))\bigr{)}+\] \[\qquad 2\sum_{j=1}^{m}\frac{L_{\mathrm{t}}^{j}(\tilde{p}_{j}(\mathbf{ \eta}))+L_{\mathrm{p}}^{j}(p_{j}(\mathbf{\eta}))}{n}\sum_{i=1}^{n}|\eta_{j}(\mathbf{x} _{i})-\hat{\eta}_{j}(\mathbf{x}_{i})|\,. \tag{72}\]

Proof.: Following the same line of argument as for Lemma C.4, we get

\[\Psi_{\mathrm{ETU}}(\hat{\mathbf{Y}}^{\star};\mathbf{\eta})-\Psi_{\mathrm{ ETU}}(\hat{\mathbf{Y}}^{\dagger};\mathbf{\eta})=\Psi_{\mathrm{ETU}}(\hat{\mathbf{Y}}^{ \star};\mathbf{\eta})-\Psi_{\mathrm{ETU}}(\hat{\mathbf{Y}}^{\star};\hat{\mathbf{\eta}})\] \[\qquad\qquad+\Psi_{\mathrm{ETU}}(\hat{\mathbf{Y}}^{\star};\hat{\mathbf{ \eta}})-\Psi_{\mathrm{ETU}}(\hat{\mathbf{Y}}^{\dagger};\hat{\mathbf{\eta}})\] \[\qquad\qquad+\Psi_{\mathrm{ETU}}(\hat{\mathbf{Y}}^{\dagger};\hat{\mathbf{ \eta}})-\Psi_{\mathrm{ETU}}(\hat{\mathbf{Y}}^{\dagger};\mathbf{\eta})\] \[\qquad\qquad\leq\Psi_{\mathrm{ETU}}(\hat{\mathbf{Y}}^{\star};\mathbf{\eta })-\Psi_{\mathrm{ETU}}(\hat{\mathbf{Y}}^{\star};\hat{\mathbf{\eta}})\] \[\qquad\qquad\qquad+\Psi_{\mathrm{ETU}}(\hat{\mathbf{Y}}^{\dagger};\hat {\mathbf{\eta}})-\Psi_{\mathrm{ETU}}(\hat{\mathbf{Y}}^{\dagger};\mathbf{\eta})\] \[\qquad\qquad\leq 2\sup_{\hat{\mathbf{Y}}}|\Psi_{\mathrm{ETU}}(\hat{\mathbf{Y}} ;\mathbf{\eta})-\Psi_{\mathrm{ETU}}(\hat{\mathbf{Y}};\hat{\mathbf{\eta}})|\;. \tag{73}\]

Next, we make use of the semi-empirical ETU risk to bound

\[|\Psi_{\mathrm{ETU}}(\hat{\mathbf{Y}};\mathbf{\eta})-\Psi_{\mathrm{ETU}}( \hat{\mathbf{Y}}^{\star};\hat{\mathbf{\eta}})|\leq|\Psi_{\mathrm{ETU}}(\hat{\mathbf{Y}}^{ \star};\mathbf{\eta})-\tilde{\Psi}_{\mathrm{ETU}}(\hat{\mathbf{Y}}^{\star};\mathbf{\eta})|\] \[\qquad\qquad\qquad+|\tilde{\Psi}_{\mathrm{ETU}}(\hat{\mathbf{Y}}^{ \star};\hat{\mathbf{\eta}})-\tilde{\Psi}_{\mathrm{ETU}}(\hat{\mathbf{Y}}^{\star};\hat{ \mathbf{\eta}})|\] \[\qquad\qquad\qquad+|\tilde{\Psi}_{\mathrm{ETU}}(\hat{\mathbf{Y}}^{ \star};\hat{\mathbf{\eta}})-\Psi_{\mathrm{ETU}}(\hat{\mathbf{Y}}^{\star};\hat{\mathbf{\eta}})| \tag{74}\]

The individual terms can now again be bounded by Theorem 5.2 and Lemma C.3.

```
1:\(\hat{\mathbf{y}}^{\text{\tiny{\rm{ext}}}}_{i}\leftarrow\) select-random-\(k(m)\) for all \(i\in[n]\)
2:\(\bar{\mathbf{t}}\leftarrow\frac{1}{n}\sum_{i=1}^{n}\hat{\mathbf{y}}^{\text{\tiny{\rm{ext }}}}(\mathbf{x}_{i})\odot\hat{\mathbf{y}}^{\text{\tiny{\rm{ext}}}}_{i}\)
3:\(\mathbf{q}\leftarrow\frac{1}{n}\sum_{i=1}^{n}\hat{\mathbf{y}}^{\text{\tiny{\rm{ext}}}}_ {i}\)
4:\(\bar{\mathbf{p}}\leftarrow\frac{1}{n}\sum_{i=1}^{n}\hat{\mathbf{y}}^{\text{\tiny{\rm{ext }}}}(\mathbf{x}_{i})\)
5:\(u_{\text{\tiny{\rm{old}}}}\leftarrow\infty\), \(u_{\text{\tiny{\rm{new}}}}\leftarrow\Psi(\bar{\mathbf{t}},\mathbf{q},\bar{\mathbf{p}})\)
6:while\(u_{\text{\tiny{\rm{new}}}}>u_{\text{\tiny{\rm{old}}}}+\epsilon\)do
7:for\(s\in\text{shuffle}[(n])\)do
8:\(\bar{\mathbf{t}}\leftarrow\bar{\mathbf{t}}-\frac{1}{n}\hat{\mathbf{y}}^{\text{\tiny{\rm{ int}}}}_{s}(\mathbf{x}_{s})\odot\hat{\mathbf{y}}^{\text{\tiny{\rm{ext}}}}_{s}\)
9:\(\mathbf{q}\leftarrow\mathbf{q}-\frac{1}{n}\hat{\mathbf{y}}^{\text{\tiny{\rm{ext}}}}_{s}\)
10:\(\mathbf{g}^{\text{\tiny{\rm{ext}}}}\leftarrow\mathbf{0}\)
11:for\((j,\hat{\eta}_{j}(\mathbf{x}_{s}))\in\hat{\mathbf{y}}^{\text{\tiny{\rm{ext}}}}_{s}( \mathbf{x}_{i})\)do
12:\(\psi^{j}(1)\leftarrow\psi\big{(}\hat{t}_{j}+\frac{1}{n}\hat{\eta}_{j}(\mathbf{x}_{ s}),q_{j}+\frac{1}{n},\tilde{p}_{j}\big{)}\)
13:\(\psi^{j}(0)\leftarrow\psi(\tilde{t}_{j},q_{j},\tilde{p}_{j})\)
14:\(\mathbf{g}^{\text{\tiny{\rm{ext}}}}\leftarrow\mathbf{g}^{\text{\tiny{\rm{ext}}}}\cup \{(j,\psi^{j}(1)-\psi^{j}(0))\}\)
15:\(\hat{\mathbf{y}}^{\text{\tiny{\rm{ext}}}}_{s}\leftarrow\) select-top-\(k(\mathbf{g}^{\text{\tiny{\rm{ext}}}})\)
16:\(\bar{\mathbf{t}}\leftarrow\bar{\mathbf{t}}+\frac{1}{n}\hat{\mathbf{y}}^{\text{\tiny{\rm{ext }}}}_{s}(\mathbf{x}_{s})\odot\hat{\mathbf{y}}^{\text{\tiny{\rm{ext}}}}_{s}\)
17:\(\mathbf{q}\leftarrow\mathbf{q}+\frac{1}{n}\hat{\mathbf{y}}^{\text{\tiny{\rm{ext}}}}_{s}\)
18:\(u_{\text{\tiny{\rm{old}}}}\leftarrow u_{\text{\tiny{\rm{new}}}}\), \(u_{\text{\tiny{\rm{new}}}}\leftarrow\Psi(\bar{\mathbf{t}},\mathbf{q},\bar{\mathbf{p}})\)
19:return\(\hat{\mathbf{Y}}^{\text{\tiny{\rm{ext}}}}\)
```

**Algorithm 7** Sparse greedy \((\mathbf{X},\hat{\mathbf{\eta}}^{\text{\tiny{\rm{ext}}}},k,\epsilon)\)

```
1:\(\hat{\mathbf{y}}^{\text{\tiny{\rm{ext}}}}_{i}\leftarrow\) select-random-\(k(m)\) for all \(i\in[n]\)
2:\(\bar{\mathbf{t}}\leftarrow\frac{1}{n}\sum_{i=1}^{n}\hat{\mathbf{y}}^{\text{\tiny{\rm{ ext}}}}_{i}\)
3:\(\bar{\mathbf{p}}\leftarrow\frac{1}{n}\sum_{i=1}^{n}\hat{\mathbf{y}}^{\text{\tiny{\rm{ ext}}}}_{i}\)
4:\(\bar{\mathbf{p}}\leftarrow\frac{1}{n}\sum_{i=1}^{n}\hat{\mathbf{y}}^{\text{\tiny{\rm{ ext}}}}(\mathbf{x}_{i})\)
5:\(u_{\text{\tiny{\rm{old}}}}\leftarrow\infty\), \(u_{\text{\tiny{\rm{new}}}}\leftarrow\Psi(\bar{\mathbf{t}},\mathbf{q},\bar{\mathbf{p}})\)
6:while\(u_{\text{\tiny{\rm{new}}}}>u_{\text{\tiny{\rm{old}}}}+\epsilon\)do
7:for\(s\in\text{shuffle}[(n])\)do
8:\(\mathbf{q}\leftarrow\mathbf{q}-\frac{1}{n}\hat{\mathbf{y}}^{\text{\tiny{\rm{ext}}}}_{s}\)
9:\(\mathbf{q}^{\text{\tiny{\rm{ext}}}}\leftarrow\mathbf{q}+\frac{1}{n}\hat{\mathbf{y}}^{ \text{\tiny{\rm{ext}}}}_{s}\)
10:\(u_{\text{\tiny{\rm{old}}}}\leftarrow u_{\text{\tiny{\rm{new}}}}\), \(u_{\text{\tiny{\rm{new}}}}\leftarrow\Psi(\bar{\mathbf{t}},\mathbf{q},\bar{\mathbf{p}})\)
11:return\(\hat{\mathbf{Y}}^{\text{\tiny{\rm{ext}}}}\)
```

**Algorithm 8** Sparse BCA for coverage \((\mathbf{X},\hat{\mathbf{\eta}}^{\text{\tiny{\rm{ext}}}},k,\epsilon)\)

```
1:\(\hat{\mathbf{y}}^{\text{\tiny{\rm{ext}}}}_{i}\leftarrow\) select-random-\(k(m)\) for all \(i\in[n]\)
2:\(\bar{\mathbf{t}}\leftarrow\mathbf{1}\)
3:for\(i\in[n]\)do
4:for\((j,\hat{\eta}_{j}(\mathbf{x}_{i}))\in\hat{\mathbf{\eta}}^{\text{\tiny{\rm{ext}}}}( \mathbf{x}_{i})\odot\hat{\mathbf{y}}_{i}\)do
5:\(f_{j}\gets f_{j}(1-\hat{\eta}_{j}(\mathbf{x}_{i}))\)
6:\(u_{\text{\tiny{\rm{old}}}}\leftarrow-\infty\), \(u_{\text{\tiny{\rm{new}}}}\gets 1-(m^{-1}\sum_{j=1}^{m}f_{j})\)
7:while\(u_{\text{\tiny{\rm{new}}}}>u_{\text{\tiny{\rm{old}}}}+\epsilon\)do
8:for\(s\in\text{shuffle}[(n])\)do
9:for\((j,\hat{\eta}_{j}(\mathbf{x}_{s}))\in\hat{\mathbf{\eta}}^{\text{\tiny{\rm{ext}}}}( \mathbf{x}_{s})\odot\hat{\mathbf{y}}^{\text{\tiny{\rm{ex}}}}_{s}\)do
10:\(f_{j}\gets f_{j}(1-\hat{\eta}_{j}(\mathbf{x}_{s}))\)
11:\(\mathbf{g}^{\text{\tiny{\rm{ext}}}}\leftarrow\emptyset\)
12:for\((j,\hat{\eta}_{j}(\mathbf{x}_{s}))\in\hat{\mathbf{\eta}}^{\text{\tiny{\rm{ext}}}}( \mathbf{x}_{s})\)do
13:\(\mathbf{g}^{\text{\tiny{\rm{ext}}}}\leftarrow\mathbf{g}^{\text{\tiny{\rm{ext}}}}\cup \{(j,\hat{\eta}_{j}(\mathbf{x}_{s})f_{j})\}\)
14:\(\hat{\mathbf{y}}^{\text{\tiny{\rm{ext}}}}_{s}\leftarrow\) select-top-\(k(\mathbf{g}^{\text{\tiny{\rm{ext}}}})\)
15:for\((j,\hat{\eta}_{j}(\mathbf{x}_{s}))\in\hat{\mathbf{\eta}}^{\text{\tiny{\rm{ext}}}}( \mathbf{x}_{s})\odot\hat{\mathbf{y}}^{\text{\tiny{\rm{ex}}}}_{s}\)do
16:\(f_{j}\gets f_{j}(1-\hat{\eta}_{j}(\mathbf{x}_{s}))\)
17:\(u_{\text{\tiny{\rm{old}}}}\leftarrow u_{\text{\tiny{\rm{new}}}}\), \(u_{\text{\tiny{\rm{new}}}}\gets 1-(m^{-1}\sum_{j=1}^{m}f_{j})\)
18:return\(\hat{\mathbf{Y}}^{\text{\tiny{\rm{ext}}}}\)
```

**Algorithm 9** Sparse BCA for coverage \((\mathbf{X},\hat{\mathbf{\eta}}^{\text{\tiny{\rm{ext}}}},k,\epsilon)\)

## Appendix D Sparse and greedy algorithms

In this section, we present pseudocodes for sparse variants of the introduced algorithms, which we used in the main experiment to compute efficiently the results for large datasets. These variants use _compressed sparse row_ (CSR) representation for row vectors. CSR vectors are represented as a list of tuples \(\mathbf{a}^{\text{\tiny{\rm{ext}}}}_{i}:=\{(\text{index},\text{\tiny{\rm{value}}}): \text{value}\neq\emptyset\}\). In these algorithms, we replace \(\hat{\mathbf{\eta}}(\mathbf{x}_{i})\) and \(\hat{\mathbf{y}}_{i}\) with their sparse variants, \(\hat{\mathbf{\eta}}^{\text{\tiny{\rm{ext}}}}(\mathbf{x}_{i}):=\{(j,\hat{\eta}_{j}(\mathbf{x}_{ i})):\hat{\eta}_{j}(\mathbf{x}_{i})\neq\emptyset\}\) and \(\hat{\mathbf{y}}^{\text{\tiny{\rm{ext}}}}:=\{(j,\hat{y}_{ij}):\hat{y}_{ij}\neq\emptyset\}\), respectively. We need to ensure that both \(\hat{\mathbf{\eta}}^{\text{\tiny{\rm{ext}}}}(\mathbf{x}_{i})\) and \(\hat{\mathbf{y}}^{\text{\tiny{\rm{ext}}}}_{i}\) are ordered by their indices for efficient element-wise multiplication (Hadamard product) between them. If we assume that the size of \(|\hat{\mathbf{y}}^{\text{\tiny{\rm{ext}}}}_{i}|=k\) and \(|\hat{\mathbf{\eta}}^{\text{\tiny{\rm{ext}}}}_{i}(\mathbf{x}_{i})|=k^{\prime}\), the resulting time and space complexity of the sparse algorithms are \(\mathcal{O}(n(k^{\prime}+k\log k))\) and \(\mathcal{O}(n(k^{\prime}+k))\), respectively. Additionally, we present the greedy variants of sparse BCA algorithms introduced so far that do only one pass over the dataset.

We present the sparse variant of BCA (Algorithm 1) in Algorithm 5 and the sparse variant of Greedy (Algorithm 3) in Algorithm 7. The sparse versions of their specialized counterparts for coverage are presented in Algorithm 6 and Algorithm 8.

Extended results, experiments and details of empirical comparison

### Datasets characteristics

In Table 5 we include an overview of the main characteristics of the datasets used in this paper.

### Extended results of the main experiment

In this section, we present the extended results of our main experiment from Section 7. Here in Table 6 and Table 7, we present additional results for \(k=1\), as well as results for additional methods:

* Macro-P\({}_{\textsc{greed}}\), Macro-F1\({}_{\textsc{greed}}\), Cov\({}_{\textsc{greed}}\)- the greedy algorithms (Algorithm 3) for optimizing macro-precision, -F1, and coverage (Algorithm 4),
* Macro-R\({}_{\textsc{prio}}\)- the optimal strategy for macro-recall: selection of \(k\) labels with the highest \(p_{j}^{-1}\eta_{j}\), with \(p\) estimated on the training set.

Because both greedy and block coordinate-ascent algorithms depend on the order in which examples are presented, we check if this has a significant influence on the results. We ran the procedures 5 times with different seeds and presented both mean and standard deviation, which is mostly less than \(0.25\) for the macro measures.

### Results on true labels

In the main experiment, the reported performance depends on three things: the inherent difficulty of the data, the success of the inference algorithm and the quality of the provided marginal probabilities. To be able to judge these terms, we also ran the inference algorithms on probabilities generated from the test set labels: \(\eta_{j}(\mathbf{x}_{i})=1\) iff \(Y_{ij}=1\) to rest only our inference strategy. We present the result of this experiment in Table 8. Notice that in this experiment, the specialized inference strategies are almost always the best on measures they aim to optimize. Also, the obtained results for macro measures are significantly below 100%. This is because, in this datasets, not all labels are represented with even one positive training example in the test set. Still, there remains a significant gap between these results and the results of the main experiments, with probability estimates coming from the LightXML model.

Impact of stopping criterion and using only top-\(k^{\prime}\) predictions on predictive and computational performance.

In this section, we investigate the impact of stopping criterion and using precalculated top-\(k^{\prime}\) predictions on the predictive performance as well as computational performance.

To materialize all marginal probability estimates for datasets like WikipediaLarge-500K and Amazon-670K, one requires an enormous amount of memory and time. Because of that, we are not able to calculate the exact results for these datasets, and instead, we used pre-select top-\(k^{\prime}\) labels with the highest \(\hat{\eta}_{j}\) as described in Section 6. In the main experiment in Section 7, we used \(k^{\prime}=100\) for smaller datasets (Eurlex-4K, Wiki-31K, AmazonCat-13K) and \(k^{\prime}=1000\) for larger datasets (WikipediaLarge-500K and Amazon-670K). Here, we additionally compare the results for \(k^{\prime}=100\) and \(k^{\prime}=1000\) for WikipediaLarge-500K and Amazon-670K investigating the impact of predictive and computational performance.

\begin{table}
\begin{tabular}{l|r r r r r r} \hline \hline Dataset & \#Labels & \#Training & \#Testing & \#Features & APoL & ALpP \\ \hline Eurlex-4K & \(3,993\) & \(15,539\) & \(3,809\) & \(5,000\) & \(25.7\) & \(5.3\) \\ Wiki-31K & \(30,938\) & \(14,146\) & \(6,616\) & \(101,938\) & \(8.5\) & \(18.6\) \\ AmazonCat-13K & \(13,330\) & \(1,186,239\) & \(306,782\) & \(203,882\) & \(448.6\) & \(5.0\) \\ WikipedialLarge-500K & \(501,070\) & \(1,813,391\) & \(783,743\) & \(2,381,304\) & \(24.8\) & \(4.8\) \\ Amazon-670K & \(670,091\) & \(490,449\) & \(153,025\) & \(135,909\) & \(4.0\) & \(5.5\) \\ \hline \hline \end{tabular}
\end{table}
Table 5: Multi-label datasets from XMLC repository [6]. APoL and ALpP represent average points per label and average labels per point, respectively.

[MISSING_PAGE_FAIL:26]

\begin{table}
\begin{tabular}{l|c|c|c|c|c|c|c|c|c|c|c|c|c} \hline Inference & \multicolumn{3}{c|}{Instance \(\#5\)} & \multicolumn{3}{c|}{Macro \(\#5\)} & \multicolumn{3}{c|}{Instance \(\#10\)} & \multicolumn{3}{c}{Macro \(\#10\)} & \multicolumn{3}{c}{Macro \(\#10\)} \\ strategy & P \(\downarrow\)null & R \(\downarrow\)null & P \(\downarrow\)null & R \(\downarrow\)null & C \(\downarrow\)null & P \(\downarrow\)null & R \(\downarrow\)null & P \(\downarrow\)null & R \(\downarrow\)null & F \(\downarrow\)null & C \(\sigma\)null \\ \hline \multicolumn{10}{c}{Elliptic-4K} \\ \hline Tor-K & **62.31\(\pm\)0.000** & **60.99\(\pm\)00** & 27.43\(\pm\)0.000 & 25.99\(\pm\)0.000 & 25.50\(\pm\)0.000 & 39.76\(\pm\)0.000 & **28.11\(\pm\)0.000** & 22.15\(\pm\)0.000 & 36.99\(\pm\)0.000 & 26.01\(\pm\)0.000 & 47.55\(\pm\)0.000 \\ P-K & 60.77\(\pm\)0.000 & 59.17\(\pm\)0.000 & 29.90\(\pm\)0.000 & 28.71\(\pm\)0.000 & 44.45\(\pm\)0.000 & 38.90\(\pm\)0.000 & 74.54\(\pm\)0.000 & 21.36\(\pm\)0.000 & 38.27\(\pm\)0.000 & 25.78\(\pm\)0.000 & 49.47\(\pm\)0.000 \\ Pour-K & 61.65\(\pm\)0.000 & 61.68\(\pm\)0.000 & 28.75\(\pm\)0.000 & 29.23\(\pm\)0.000 & 27.74\(\pm\)0.000 & 43.23\(\pm\)0.000 & 39.70\(\pm\)0.000 & 74.72\(\pm\)0.000 & 21.50\(\pm\)0.000 & 38.00\(\pm\)0.000 & 25.88\(\pm\)0.000 & 49.14\(\pm\)0.000 \\ Pour-K & 60.55\(\pm\)0.000 & 57.10\(\pm\)0.000 & 28.58\(\pm\)0.000 & 28.57\(\pm\)0.000 & 45.45\(\pm\)0.000 & 38.80\(\pm\)0.000 & 37.66\(\pm\)0.000 & 27.01\(\pm\)0.000 & 38.45\(\pm\)0.000 & 55.24\(\pm\)0.000 & 50.51\(\pm\)0.000 \\ Loo-K & 67.57\(\pm\)0.000 & 59.87\(\pm\)0.000 & 28.48\(\pm\)0.000 & 28.47\(\pm\)0.000 & 27.36\(\pm\)0.000 & 42.32\(\pm\)0.000 & 39.72\(\pm\)0.000 & 74.80\(\pm\)0.000 & 21.60\(\pm\)0.000 & 37.49\(\pm\)0.000 & 25.83\(\pm\)0.000 & 48.61\(\pm\)0.000 \\ \hline Macro-Pain & 41.75\(\pm\)0.200 & 40.22\(\pm\)0.007 & 28.97\(\pm\)0.000 & 27.42\(\pm\)0.000 & 42.39\(\pm\)0.000 & 46.64\(\pm\)0.000 & 15.25\(\pm\)0.000 & 49.39\(\pm\)0.000 & 24.62\(\pm\)0.000 & 31.40\(\pm\)0.000 & 23.44\(\pm\)0.000 & 41.46\(\pm\)0.001 \\ Macro-Pain & 30.15\(\pm\)0.300 & 30.33\(\pm\)0.000 & 28.00\(\pm\)0.000 & 14.86\(\pm\)0.000 & 12.91\(\pm\)0.000 & 42.19\(\pm\)0.000 & 18.18\(\pm\)0.000 & 35.66\(\pm\)0.000 & 26.02\(\pm\)0.000 & 22.18\(\pm\)0.000 & 42.28\(\pm\)0.000 \\ Macro-Pain & 48.36\(\pm\)0.000 & 42.22\(\pm\)0.000 & 27.08\(\pm\)0.000 & 32.87\(\pm\)0.000 & 37.36\(\pm\)0.000 & 43.85\(\pm\)0.000 & 15.00\(\pm\)0.000 & 67.34\(\pm\)0.000 & 19.74\(\pm\)0.000 & 42.28\(\pm\)0.000 & 51.64\(\pm\)0.000 \\ Macro-Pain & 38.32\(\pm\)0.370 & 37.54\(\pm\)0.000 & 28.97\(\pm\)0.000 & 27.70\(\pm\)0.000 & 27.70\(\pm\)0.000 & 40.90\(\pm\)0.000 & 25.80\(\pm\)0.000 & 57.38\(\pm\)0.000 & 29.90\(\pm\)0.000 & 38.04\(\pm\)0.000 & 52.15\(\pm\)0.000 \\ Macro-Pain & 54.88\(\pm\)0.150 & 51.53\(\pm\)0.000 & 29.36\(\pm\)0.000 & 31.46\(\pm\)0.000 & 28.00\(\pm\)0.000 & 47.39\(\pm\)0.000 & 13.91\(\pm\)0.000 & 65.06\(\pm\)0.000 & 23.88\(\pm\)0.000 & 35.17\(\pm\)0.000 & 26.00\(\pm\)000 & 49.81\(\pm\)0.000 \\ Macro-Pain & 56.18\(\pm\)0.000 & 51.18\(\pm\)0.000 & 47.18\(\pm\)0.000 & 51.49\(\pm\)0.000 & 47.39\(\pm\)0.000 & 51.32\(\pm\)0.000 & 64.29\(\pm\)0.000 & 37.27\(\pm\)0.000 & 47.56\(\pm\)0.000 & 47.56\(\pm\)0.000 \\ CoVain & 18.81\(\pm\)0.181 & 18.19\(\pm\)0.000 & 23.48\(\pm\)0.000 & 29.52\(\pm\)0.000 & 31.43\(\pm\)0.000 & 45.99\(\pm\)0.000 & 33.59\(\pm\)0.000 & 64.29\(\pm\)0.000 & 18.44\(\pm\)0.000 & 29.62\(\pm\)0.000 & 17.41\(\pm\)0.000 & **52.84\(\pm\)0.000** \\ CoVain & 18.81\(\pm\)0.181 & 18.19\(\pm\)0.000 & 23.48\(\pm\)0.000 & 15.49\(\pm\)0.000 & 15.84\(\pm\)0.000 & 15.93\(\pm\)0.000 & 15.32\(\pm\)0.000 & 64.29\(\pm\)0.000 & 15.76\(\pm\)0.000 & 26.58\(\pm\)0.000 \\ CoVain & 16.40\(\pm\)0.000 & 15.95\(\pm\)0.000 & 29.36\(\pm\)0.000 & 24.53\(\pm\)0.000 & 18.81\(\pm\)0.000 & **50.000** & 19.31\(\pm\)0.000 & 15.00\(\pm\)0.000 & 24.18\(\pm\)0.000 & 22.88\(\pm\)0.000 & 17.41\(\pm\)0.000 & **52.84\(\pm\)0.000** \\ \hline \multicolumn{10}{c}{Auxiliary-1X} \\ \hline Tor-K & **68.01\(\pm\)0.000** & **70.10\(\pm\)0.000** & 33.92\(\pm\)0.000 & 31.34\(\pm\)0.000 & 29.28\(\pm\)0.000 & 52.60\(\pm\)0.000 & **41.72\(\pm\)0.000** & **39.41\(\pm\)0.000** & 24.63\(\pm\)0.000 & 51.76\(\pm\)0.000 & 28.84\(\pm\)000 \\ P-K & 66.65\(\pm\)0.000 & 67.27\(\pm\)0.000 & 36.77\(\pm\)0.000 & 36.81\(\pm\)0.000 & 45.00\(\pm\)0.000 & 38.34\(\pm\)0.000 & 65.82\(\pm\)0.000 & 47.50\(\pm\)0.000 & 89.71\(\pm\)0.000 & 25.66\(\pm\)0.000 & 60.00\(\pm\)0.000 & 25.99\(\pm\)0.000 & 74.72\(\pm\)0.000 \\ P-K & 66.53\(\pm\)0.000 & 77.29\(\pm\)0.000 & 36.74\(\pm\)0.000 & 45.96\(\pm\)0.000 & 38.15\(\pm\)0.000 & 45.00\(\pm\)0.000 & 38.34\(\pm\)0.000 & 60.83\(\pm\)0.000 & 38.50\(\pm\)0.00

[MISSING_PAGE_FAIL:28]

[MISSING_PAGE_FAIL:29]

Figure 2: Comparison of the baseline algorithms with the BCA inference with mixed objectives with \(k=3\). The green line shows the results for different interpolations between two measures.

Figure 3: Comparison of the baseline algorithms with the BCA inference with mixed objectives with \(k=5\). The green line shows the results for different interpolations between two measures.

a mixed utility that is a linear combination of instance-wise measures and selected macro-measures. Here, we present the results for three such mixed utilities (combinations of instance-precision with macro-precision, macro-f1-measure, and coverage):

\[\Psi_{1}(\mathbf{Y},\hat{\mathbf{Y}}) :=(1-\alpha)\Psi_{\text{Instance-P}}(\mathbf{Y},\hat{\mathbf{Y}})+\alpha \Psi_{\text{Macro-P}}(\mathbf{Y},\hat{\mathbf{Y}})\] \[=\sum_{j=1}^{m}(1-\alpha)\psi_{\text{Instance-P}}(\mathbf{y}_{:j}, \hat{\mathbf{y}}_{:j})+\alpha\psi_{\text{Macro-P}}(\mathbf{y}_{:j},\hat{\mathbf{y}}_{:j})\] \[=\sum_{j=1}^{m}(1-\alpha)\frac{t_{j}}{k}+\alpha\frac{t_{j}}{mq_{j }}\,,\] \[\Psi_{2}(\mathbf{Y},\hat{\mathbf{Y}}) :=(1-\alpha)\Psi_{\text{Instance-P}}(\mathbf{Y},\hat{\mathbf{Y}})+\alpha \Psi_{\text{Macro-F1}}(\mathbf{Y},\hat{\mathbf{Y}})\] \[=\sum_{j=1}^{m}(1-\alpha)\psi_{\text{Instance-P}}(\mathbf{y}_{:j}, \hat{\mathbf{y}}_{:j})+\alpha\psi_{\text{Macro-F1}}(\mathbf{y}_{:j},\hat{\mathbf{y}}_{:j})\] \[=\sum_{j=1}^{m}(1-\alpha)\frac{t_{j}}{k}+\alpha\frac{2t_{j}}{m(q_ {j}+p_{j})}\,,\] \[\Psi_{3}(\mathbf{Y},\hat{\mathbf{Y}}) :=(1-\alpha)\Psi_{\text{Instance-P}}(\mathbf{Y},\hat{\mathbf{Y}})+\alpha \Psi_{\text{Cov}}(\mathbf{Y},\hat{\mathbf{Y}})\] \[=\sum_{j=1}^{m}(1-\alpha)\psi_{\text{Instance-P}}(\mathbf{y}_{:j}, \hat{\mathbf{y}}_{:j})+\alpha\psi_{\text{Cov}}(\mathbf{y}_{:j},\hat{\mathbf{y}}_{:j})\] \[=\sum_{j=1}^{m}(1-\alpha)\frac{t_{j}}{k}+\alpha\frac{\mathds{1}[ t_{j}>0]}{m}\,, \tag{75}\]

In Figure 2 and Figure 3, we present the plots with results on two combined measures for different values of \(\alpha\in\{0.01,0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.95,0.99,0.995,0.999\}\). Once again, the presented results are the mean values over 5 runs with different seeds. The plots show that the instance-vs-macro curve has a nice concave shape that dominates simple baselines. In particular, we can initially improve macro-measures significantly with only a minor drop in instance-measures, and only if we want to optimize even more strongly for macro-measures, we get larger drops in instance-wise measures. A particularly notable feature of the plug-in approach is that the curves in the figure are cheap to produce since there is no requirement for expensive re-training of the entire architecture, so one can easily select an optimal interpolation constant according to some criteria, such as a maximum decrease of instance-wise performance.

### Hardware

The LightXML model was trained on a workstation with a single Nvidia Tesla V100 GPU with 32 GB of memory and 64 GB of RAM. All the inference strategies were then run on the workstation with 64 GB of RAM. However, to run them, one requires only 16 GB of memory.

Efficient inference with Probabilistic Label Trees

In this section, we describe probabilistic labels trees (PLTs) [16], which allow for efficient retrieval of only the top-\(k\) labels with the highest conditional probabilities. Then, we introduce a weighted version and show how to modify it to achieve efficient and exact optimal prediction for any \(g_{j}(\eta_{j}(\mathbf{x}))\) that is monotonous in \(\eta_{j}(\mathbf{x})\). Thus, if the LPE \(\mathbf{\eta}\) is modeled by a PLT, this provides an alternative to the sparse inference introduced in Appendix D that also scales to XMLC problems.

### Probabilistic labels trees

We denote a tree by \(\mathcal{T}\), the set of all its nodes by \(\mathcal{V}_{\mathcal{T}}\), the root node by \(\mathsf{r}_{\mathcal{T}}\), and the set of its leaves by \(\mathcal{L}_{\mathcal{T}}\). The leaf \(\mathsf{l}_{j}\in\mathcal{L}_{\mathcal{T}}\) corresponds to the label \(j\in[m]\). The parent node of \(\mathsf{v}\) is denoted by \(\mathrm{pa}(\mathsf{v})\), and the set of child nodes by \(\mathrm{ch}(\mathsf{v})\). The set of leaves of a (sub)tree rooted in node \(\mathsf{v}\) is denoted by \(\mathcal{L}_{\mathsf{v}}\), and path from node \(\mathsf{v}\) to the root by \(\mathrm{path}(\mathsf{v})\).

A PLT uses a tree \(\mathcal{T}\) to factorize conditional probabilities of labels, \(\eta_{j}(\mathbf{x})=\mathds{P}[y_{j}=1\mid\mathbf{x}]\), \(j\in[m]\), by using the chain rule. Let us define an event that \(\mathcal{L}_{\mathsf{v}}\) contains at least one relevant label in \(\mathbf{y}\), denoting \(z_{\mathsf{v}}\coloneqq\mathds{1}[\exists j:\mathsf{l}_{j}\in\mathcal{L}_{ \mathsf{v}}\wedge y_{j}=1]\). Now for every node \(\mathsf{v}\in\mathcal{V}_{\mathcal{T}}\), the conditional probability of containing at least one relevant label is given by:

\[\eta_{\mathsf{v}}(\mathbf{x})\coloneqq\mathds{P}[z_{\mathsf{v}}=1\mid\mathbf{x}]= \hskip-10.0pt\prod_{\mathsf{v}^{\prime}\in\mathrm{path}(\mathsf{v})}\hskip-10.0pt \eta(\mathbf{x},\mathsf{v}^{\prime})\,, \tag{76}\]

where \(\eta(\mathbf{x},\mathsf{v})\coloneqq\mathds{P}\big{[}z_{\mathsf{v}}=1\mid z_{ \mathsf{pa}(\mathsf{v})}=1,\mathbf{x}\big{]}\) for non-root nodes, and \(\eta(\mathbf{x},\mathsf{v})\coloneqq\mathds{P}[z_{\mathsf{v}}=1\mid\mathbf{x}]\) for the root. Notice that (76) can also be stated recursively as

\[\eta_{\mathsf{v}}(\mathbf{x})=\eta(\mathbf{x},\mathsf{v})\cdot\eta_{\mathrm{pa}( \mathsf{v})}(\mathbf{x})\,, \tag{77}\]

and that for leaf nodes we get the conditional probabilities of labels

\[\eta_{\mathsf{l}_{j}}(\mathbf{x})=\eta_{j}(\mathbf{x})\,,\quad\text{for }\mathsf{l}_{j} \in\mathcal{L}_{\mathcal{T}}\,. \tag{78}\]

To obtain a PLT, it suffices, for a given \(\mathcal{T}\), to train probabilistic classifiers estimating \(\eta(\mathbf{x},\mathsf{v})\) for all \(\mathsf{v}\in\mathcal{V}_{\mathcal{T}}\). Analogously to the main paper, we denote estimates of \(\eta\) by \(\hat{\eta}\).

### Weighted PLTs

[46] introduced an \(A^{*}\)-search based algorithm for efficiently finding the \(k\) leaves with the highest gain \(g(\mathsf{l}_{j},\mathbf{x})=w_{j}\eta_{j}(\mathbf{x})\), where \(w_{j}\in[0,\infty)\) is the weight given to label \(j\). The outline of the search method presented below is an adapted description from [46].

For the gain function \(g(\mathsf{l}_{j},\mathbf{x})=w_{j}\hat{\eta}_{j}(\mathbf{x})\), the procedure uses a cost function \(c(\mathsf{l}_{j},\mathbf{x})\) for each path from the root to a leaf. Notice that the following holds:

\[g(\mathsf{l}_{j},\mathbf{x})=w_{j}\hat{\eta}_{j}(\mathbf{x})=\exp\left(-\left(-\log w _{j}-\sum\log\hat{\eta}(\mathbf{x},\mathsf{v})\right)\right)\,. \tag{79}\]

Because \(\exp\) is monotonous, we can define the following cost function for a selected label \(j\), which the algorithm will aim to minimize:

\[c(\mathsf{l}_{j},\mathbf{x})\coloneqq-\log w_{j}-\hskip-10.0pt\sum_{\mathsf{v}\in \mathrm{path}(\mathsf{l}_{j})}\hskip-10.0pt\log\hat{\eta}(\mathbf{x},\mathsf{v})\,. \tag{80}\]

We can then guide the \(A^{*}\)-search with the function \(\overline{c}(\mathsf{v},\mathbf{x})=p(\mathsf{v},\mathbf{x})+h(\mathsf{v},\mathbf{x})\), estimating the value of the optimal path in the subtree of node \(\mathsf{v}\), where

\[p(\mathsf{v},\mathbf{x})=-\hskip-10.0pt\sum_{\mathsf{v}^{\prime}\in\mathrm{path}( \mathsf{v})}\hskip-10.0pt\log\hat{\eta}(\mathbf{x},\mathsf{v}^{\prime}) \tag{81}\]

is the cost of reaching tree node \(\mathsf{v}\) from the root, and

\[h(\mathsf{v},\mathbf{x})=-\log\max_{j\in\mathcal{L}_{\mathsf{v}}}w_{j} \tag{82}\]

is a heuristic function estimating the cost of reaching the best leaf from node \(\mathsf{v}\). The \(A^{*}\)-search in our procedure evaluates nodes in ascending order of their estimated cost values \(\overline{c}(\mathsf{l}_{j},\mathbf{x})\).

This approach has been proven by [46] to guarantee that \(A^{*}\)-search finds the optimal solution--top-\(k\) labels with the highest \(c(\mathsf{l}_{j},\mathbf{x})\) and thereby top-\(k\) labels with the highest \(w_{j}\eta_{j}(\mathbf{x})\)--in the optimally efficient way, i.e., there is no other algorithm used with this heuristic that expands fewer nodes [38].

### PLTs for monotonous gain functions

Notice that in Weighted PLTs instead of minimizing cost, one can directly optimize gain by using a tree-search procedure that evaluates nodes in descending order of their estimated gain \(\overline{g}(\mathsf{v},\mathbf{x})=p(\mathsf{v},\mathbf{x})\cdot h(\mathsf{v},\mathbf{x})\), where \(p(\mathsf{v},\mathbf{x})=\sum_{\mathsf{v}^{\prime}\in\mathrm{path}(\mathsf{v})} \tilde{\eta}(\mathbf{x},\mathsf{v}^{\prime})\) and \(h(\mathsf{v},\mathbf{x})=\max_{j\in\mathcal{L}_{v}}w_{j}\). To generalize this formulation and apply it to the proposed algorithms, we need to be able to find the top-\(k\) with any gain function \(g_{j}(\eta_{j}(\mathbf{x}))\) that is monotonous with \(\eta_{j}(\mathbf{x})\).

We can guide the tree search using the estimated gain function \(\overline{g}(\mathsf{v},\mathbf{x})=h(\mathsf{v},p(\mathsf{v},\mathbf{x}))\), where

\[p(\mathsf{v},\mathbf{x})=\prod_{\mathsf{v}^{\prime}\in\mathrm{path}(\mathsf{v})} \tilde{\eta}(\mathbf{x},\mathsf{v}^{\prime})\,, \tag{83}\]

the same as in the case of Weighted PLT, it simply corresponds to the conditional probability of finding at least one positive label in the subtree of node \(\mathsf{v}\), and the heuristic part is:

\[h(\mathsf{v},\mathbf{x})=\max_{j\in\mathcal{L}_{v}}\left(g_{j}(p(\mathsf{v},\mathbf{x }))\right)\,. \tag{84}\]

As in the case of Weighted PLT, we would like to guarantee that this search procedure finds the optimal solution--the top-\(k\) labels with the highest \(g(\mathsf{l}_{j},\mathbf{x})\). To do that, we need to ensure that \(\overline{g}(\mathsf{v},\mathbf{x})\) is admissible, i.e., in case of maximization, it never underestimates the gain from reaching a leaf node [38]. We also would like \(\overline{g}(\mathsf{v},\mathbf{x})\) to be consistent, making the proposed tree search procedure optimally efficient, i.e., there is no other algorithm used with the same \(\overline{g}(\mathsf{v},\mathbf{x})\) that expands fewer nodes [38]. Algorithm 9 outlines this procedure for finding the top-\(k\) labels with highest values of \(g_{j}(\eta_{j}(\mathbf{x}))\) that is monotonous with \(\eta_{j}(\mathbf{x})\), and that can replace the select top-\(\mathsf{k}(\mathbf{g})\) operation in the proposed BCA and Greedy algorithms. Unfortunately, not all gain functions \(g_{j}(\eta_{j}(\mathbf{x}))\) can be calculated efficiently. To calculate the semi-empirical quantity \(\tilde{p}\) exactly, one needs to know _all_ the \(\eta_{j}(\mathbf{x})\). To obtain them, the whole tree need to be evaluated, which prevents this method from being efficient. Because of that, we use this technique to get exact predictions for the measures that are defined solely on \(\tilde{t}\) and \(\tilde{q}\), like macro-precision and coverage.

```
1:\(\hat{\mathbf{y}}\gets 0^{m}\)\(\triangleright\) Initialize prediction \(\hat{\mathbf{y}}\) vector to all zeros
2:\(\mathcal{Q}\leftarrow\emptyset\)\(\triangleright\) Initialize priority queue \(\mathcal{Q}\), ordered descending by \(\overline{g}(\mathsf{v},\mathbf{x})\)
3:\(p(r\tau,\mathbf{x})\leftarrow\hat{\eta}(\mathbf{x},\tau_{\tau})\)\(\triangleright\) Calculate estimated conditional probability \(p(r\tau,\mathbf{x})\) for the tree root
4:\(\overline{g}(r\tau,\mathbf{x})\leftarrow\max_{j\in\mathcal{L}_{\tau}}\left(g_{j} (p(r\tau,\mathbf{x}))\right)\)\(\triangleright\) Calculate estimated gain \(\overline{g}(r\tau,\mathbf{x})\) for the tree root
5:\(\mathcal{Q}.\mathrm{add}((r,p(\mathsf{v}^{\prime},\mathbf{x}),\overline{g}( \mathsf{v}^{\prime},\mathbf{x})))\)\(\triangleright\) Add the tree root with estimates \(p(\tau_{\tau},\mathbf{x})\) and \(\overline{g}(r_{\tau},\mathbf{x})\) to the queue
6:while\(||\mathsf{v}||<k\)do\(\triangleright\) While the number of predicted labels is less than \(k\)
7:\((\mathsf{v},\mathsf{p}(\mathsf{v},\mathbf{x}_{\cdot})\leftarrow\mathcal{Q}.\mathrm{ pop}(\mathsf{v})\)\(\triangleright\) Pop the element with the lowest cost from the queue
8:if\(\mathsf{v}\) is a leaf then\(\hat{y}_{\mathsf{v}}\gets 1\)\(\triangleright\) If the node is a leaf, set the corresponding label in the prediction vector
9:elsefor\(\mathsf{v}^{\prime}\in\mathrm{ch}(\mathsf{v})\)do\(\triangleright\) If the node is an internal node, for all child nodes
10:\(p(\mathsf{v}^{\prime},\mathbf{x})\gets p(\mathsf{v},\mathbf{x})\hat{\eta}(\mathbf{x}, \mathsf{v}^{\prime})\)\(\triangleright\) Calculate \(p(\mathsf{v}^{\prime},\mathbf{x})\)
11:\(\overline{g}(\mathsf{v}^{\prime},\mathbf{x})\leftarrow\max_{j\in\mathcal{L}_{v}} \left(g_{j}(p(\mathsf{v}^{\prime},\mathbf{x}))\right)\)\(\triangleright\) Calculate estimate \(\overline{g}(\mathsf{v}^{\prime},\mathbf{x})\)
12:\(\mathcal{Q}.\mathrm{add}((\mathsf{v}^{\prime},p(\mathsf{v}^{\prime},\mathbf{x}), \overline{g}(\mathsf{v}^{\prime},\mathbf{x})))\)\(\triangleright\) Add \(\mathsf{v}^{\prime}\), and its estimates \(p(\tau_{\tau},\mathbf{x})\) and \(\overline{g}(r_{\tau},\mathbf{x})\) to the queue
13:return\(\hat{\mathbf{y}}\)\(\triangleright\) Return the prediction vector
```

**Algorithm 9** Select top-\(k\) labels with highest gain using PLTs (\(\mathcal{T},\hat{\eta},\mathbf{x},k,g_{j}(\cdot)\))

### Experimental comparison of inference with PLTs

In this experiment, we evaluate the inference using probabilistic label trees that can efficiently perform the exact select top-\(\mathsf{k}(\mathbf{g})\) operation. We compare inference times of these variants of the methods that require only one pass over the dataset: Top-K, PS-K, Pow-K, Log-K, Macro-Perged, Macro-RPRIOR, and CovGFRED, for \(k=\{3,5\}\). As a baseline, we use the same PLT to obtain the \(k^{\prime}=100\) and \(k^{\prime}=1000\) highest \(\mathbf{\eta}(\mathbf{x}_{i})\), and then run the sparse algorithms on top of these predictions. We use a modified implementation of PS-PLT [46; 17], trained with default settings.

We present the results in Table 10. As in the case of the main experiment, we again observe that the specialized inference strategies are indeed the best on the measure they aim to optimize. Compared to the cost of obtaining marginals for \(k^{\prime}=100\) and \(k^{\prime}=1000\) labels, which can be later used with one of the proposed inference algorithms (the cost of running this step is not included in the table), the greedy methods combined with PLT-based search consistently achieve speed-up when compared totop \(k^{\prime}=1000\) inference. Unfortunately, they are also often slower than \(k^{\prime}=100\) inference. As we showed in the previous section, \(k^{\prime}=100\) is usually enough to get good predictive performance on macro measures using BCA and Greedy algorithms. However, here, the PLT-based methods obtain the exact solution for finding the prediction with the highest expected gain. While it is worth noting that tree structure and the type of node estimator have an impact on the performance of PLT-based algorithms and we conducted this experiment with just a single setup, we believe that this experiment shows that PLT-based inference, in some cases, can be an alternative to inference with sparse marginal estimates.

\begin{table}
\begin{tabular}{l|c|c|c c c c c|c c c c c c c c} \hline \hline \multicolumn{1}{c|}{\begin{tabular}{c} Influence & Instance & 03 \\ \end{tabular} } & \multicolumn{3}{c|}{\begin{tabular}{c} Macro & 03 \\ \end{tabular} } & \multicolumn{3}{c|}{\begin{tabular}{c} Time/Spec-seq & 03 \\ \end{tabular} } & \multicolumn{3}{c|}{\begin{tabular}{c} Instance & 05 \\ \end{tabular} } & \multicolumn{3}{c|}{\begin{tabular}{c} Macro 05 \\ \end{tabular} } & \multicolumn{3}{c}{
\begin{tabular}{c} Time/Spec-seq & 09 \\ \end{tabular} } \\ \cline{2-13} \multicolumn{1}{c|}{strategy} & P & R & P & R & F1 & Cov & T & \(k^{\prime}\)=1000 & F & R & P & R & F1 & Cov & T & \(k^{\prime}\)=1000 & F \\ \hline \multicolumn{13}{c|}{Eval-14K} \\ \hline \hline

[MISSING_PAGE_POST]

oc-R** & **65.28** & **11.26** & 3.22 & 0.22 & 1.17 & 5.99 & 7.38 & 3.24 & 3.65 & 5.72 & 25.68 & 5.83 & 2.39 & 2.99 & 1.01 & 7.384 & 3.26 &