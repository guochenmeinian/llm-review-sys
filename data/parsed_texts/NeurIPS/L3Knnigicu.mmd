# Adversarial Schrodinger Bridge Matching

 Nikita Gushchin

Sklotech\({}^{\dagger}\)

Moscow, Russia

n.gushchin@skoltech.ru

&Daniil Selikhanovych

Skoltech\({}^{\dagger}\)

Moscow, Russia

selikhanovychdaniil@gmail.com

Sergei Kholkin

Skoltech\({}^{\dagger}\)

Moscow, Russia

s.kholkin@skoltech.ru

&Evgeny Burnaev

Skoltech\({}^{\dagger}\)

Moscow, Russia

e.burnaev@skoltech.ru

&Alexander Korotin

Skoltech\({}^{\dagger}\)

Moscow, Russia

a.korotin@skoltech.ru

Equal contribution

Skolkovo Institute of Science and Technology

Artificial Intelligence Research Institute

###### Abstract

The Schrodinger Bridge (SB) problem offers a powerful framework for combining optimal transport and diffusion models. A promising recent approach to solve the SB problem is the Iterative Markovian Fitting (IMF) procedure, which alternates between Markovian and reciprocal projections of continuous-time stochastic processes. However, the model built by the IMF procedure has a long inference time due to using many steps of numerical solvers for stochastic differential equations. To address this limitation, we propose a novel Discrete-time IMF (D-IMF) procedure in which learning of stochastic processes is replaced by learning just a few transition probabilities in discrete time. Its great advantage is that in practice it can be naturally implemented using the Denoising Diffusion GAN (DD-GAN), an already well-established adversarial generative modeling technique. We show that our D-IMF procedure can provide the same quality of unpaired domain translation as the IMF, using only several generation steps instead of hundreds. We provide the code at https://github.com/Daniil-Selikhanovych/ASBM.

Figure 1: Our D-IMF approach performs unpaired image-to-image translation in just a few steps, achieving results comparable to the hundred-step IMF [47]. Celeba [33], _male\(\rightarrow\)female_ (\(128\times 128\)).

Introduction

Recent generative models based on the Flow Matching [27] and Rectified Flows [30] show great potential as a successor of classical denoising diffusion models such as DDPM [15]. Both these approaches consider the same problem of learning an Ordinary Differential Equation (ODE) that interpolates one given distribution to the other one, e.g., noise to data. Thanks to the close connection to the theory of Optimal Transport (OT) problem [52], Flow Matching and Rectified Flows approaches typically have faster inference compared to classical diffusion models [32, 39]. Also, it was shown that they can outperform diffusion models on the high-resolution text-to-image synthesis: they even lie in the foundation of the recent Stable Diffusion 3 model [8].

The extension of Flow Matching and Rectified Flow approaches to the SDE are Bridge Matching (Markovian projection) and **Iterative Markovian fitting** (IMF) procedures [36, 47, 35], respectively. They also have a close connection with the OT theory. Specifically, it is known [47, 35] that IMF converges to the solution of the dynamic formulation of entropic optimal transport (EOT), also known as the Schrodinger Bridge (SB). However, learning continuous-time SDEs in IMF is non-trivial and, unfortunately, leads to **long inference** due to the necessity to use many steps of numerical solvers.

**Contributions.** This paper addresses the above-mentioned limitation of the existing Iterative Markovian Fitting (IMF) framework by introducing a novel approach to learn the Schrodinger Bridge.

1. **Theory I.** We introduce a Discrete Iterative Markovian Fitting **(D-IMF)** procedure (SS3.2, 3.3), which innovatively applies discrete Markovian projection to solve the Schrodinger Bridge problem without relying on Stochastic Differential Equations. This approach significantly simplifies the inference process, enabling it to be accomplished (theoretically) in just a few evaluation steps.
2. **Theory II.** We derive closed-form update formulas for the D-IMF procedure when dealing with high-dimensional Gaussian distributions. This advancement permits a detailed empirical analysis of our method's convergence rate and enhances its theoretical foundation (SS3.4, 4.1).
3. **Practice.** For general data distributions available by samples, we propose an algorithm **(ASBM)** to implement the discrete Markovian projection and our D-IMF procedure in practice (SS4.2). Our algorithm is based on adversarial learning and Denoising Diffusion GAN [53]. Our learned SB model uses just \(4\) evaluation steps for inference (SS3.5) instead of hundreds of the basic IMF [47].

**Notations.** In the paper, we simultaneously work with the continuous stochastic processes and discrete stochastic processes in the \(D\)-dimensional Euclidean space \(\mathbb{R}^{D}\). We denote by \(\mathcal{P}(C([0,1]),\mathbb{R}^{D})\) the set of continuous stochastic processes with time \(t\in[0,1]\), i.e., the set of distributions on continuous trajectories \(f:[0,1]\rightarrow\mathbb{R}^{D}\). We use \(dW_{t}\) to denote the differential of the standard Wiener process.

To establish a link between continuous and discrete stochastic processes, we fix \(N\geq 1\) intermediate time moments \(0=t_{0}<t_{1}<\cdots<t_{N}<t_{N+1}=1\) together with \(t_{0}=0\) and \(t_{N+1}=1\). We consider discrete stochastic processes with those time-moments as the elements of the set \(\mathcal{P}(\mathbb{R}^{D\times(N+2)})\) of probability distributions on \(\mathbb{R}^{D\times(N+2)}\). Among such discrete processes, we are specifically interested in subset \(\mathcal{P}_{2,ac}(\mathbb{R}^{D\times(N+2)})\subset\mathcal{P}(\mathbb{R}^{D \times(N+2)})\) of absolutely continuous distributions on \(\mathbb{R}^{D\times(N+2)}\) which have a finite second moment and entropy. For any such \(q\in\mathcal{P}_{2,ac}(\mathbb{R}^{D\times(N+2)})\), we write \(q(x_{0},x_{t_{1}},\ldots,x_{t_{N+1}})\) to denote its density at a point \((x_{0},x_{t_{1}},\ldots,x_{t_{N}},x_{1})\in\mathbb{R}^{D\times(N+2)}\). For continuous process \(T\), we denote by \(p^{T}\in\mathcal{P}(\mathbb{R}^{D\times(N+2)})\) the discrete process which is the finite-dimensional projection of \(T\) to time moments \(0=t_{0}<t_{1}<\cdots<t_{N}<t_{N+1}=1\). For convenience we also use the notation \(x_{\text{in}}=(x_{t_{1}},\ldots,x_{t_{N}})\) to denote the vector of all intermediate-time variables. In what follows, KL is a short notation for the Kullback-Leibler divergence.

## 2 Background

We start with recalling the Bridge Matching and Iterative Propotional Fitting procedures developed for continuous-time stochastic processes (SS2.1). Next, we discuss the Schrodinger Bridge problem, the solution to which is the unique fixed point of Iterative Markovian Fitting procedure (SS2.2).

### Bridge Matching and Iterative Markovian Fitting Procedures

Modern diffusion and flow generative modeling are mainly about the construction of a model that interpolates one probability distribution \(p_{0}\in\mathcal{P}_{2,ac}(\mathbb{R}^{D})\) to some another probability distribution \(p_{1}\in\mathcal{P}_{2,ac}(\mathbb{R}^{D})\). One of the general approaches for this task is the Bridge Matching [29, 31, 3].

**Reciprocal processes.** The Bridge Matching procedure is applied to the processes, which are represented as a mixture of Brownian Bridges. Consider the Wiener process \(W^{\epsilon}\) with the volatility \(\epsilon\) which start at \(p_{0}\), i.e., the process given by the SDE: \(dx_{t}=\sqrt{\epsilon}dW_{t}\), \(x_{0}\sim p_{0}\). Let \(W^{\epsilon}_{|x_{0},x_{1}}\) denote the stochastic process \(W^{\epsilon}\) conditioned on values \(x_{0},x_{1}\) at times \(t=0,1\), respectively. This process \(W^{\epsilon}_{|x_{0},x}\) is called the Brownian Bridge [17, Chapter 9]. For some \(q(x_{0},x_{1})\in\mathcal{P}_{2,ac}(\mathbb{R}^{D\times 2})\) with \(q(x_{0})=p_{0}(x_{0})\) and \(q(x_{1})=p_{1}(x_{1})\) the process \(T_{q}\stackrel{{\text{def}}}{{=}}\int W^{\epsilon}_{|x_{0},x_{1} }dq(x_{0},x_{1})\) is called the mixture of Brownian Bridges. Following [47], we say that mixtures of Brownian Bridges form a _reciprocal class_ of processes (for the Brownian Bridge). For brevity, we call these processes just reciprocal processes.

**Bridge matching [29, 31].** The goal of Bridge Matching (with the Brownian Bridge) is to construct continuous-time Markovian process \(M\) from \(p_{0}\) to \(p_{1}\) in the form of SDE: \(dx_{t}=v(x_{t},t)dt+\sqrt{\epsilon}dW_{t}\). This is achieved by using the _Markovian projection_ of a reciprocal process \(T_{q}=\int W^{\epsilon}_{|x_{0},x_{1}}dq(x_{0},x_{1})\), which aims to find the Markovian process \(M\) which is the most similar to \(T_{q}\) in the sense of KL:

\[\text{proj}_{\mathcal{M}}(T_{q})\stackrel{{\text{def}}}{{=}} \operatorname*{arg\,min}_{M\in\mathcal{M}}\text{KL}\left(T_{q}\|M\right),\]

where \(\mathcal{M}\subset\mathcal{P}(C([0,1]),\mathbb{R}^{D})\) is the set of all Markovian processes. For the Brownian Bridge \(W^{\epsilon}_{|x_{0},x_{1}}\) it is known [47, 11] that the SDE and the drift \(v(x_{t},t)\) of \(\text{proj}_{\mathcal{M}}(T_{q})\) is given by:

\[dx_{t}=v(x_{t},t)dt+\sqrt{\epsilon}dW_{t},\quad v(x_{t},t)=\int\frac{x_{1}-x_ {t}}{1-t}p^{T_{q}}(x_{1}|x_{t})dx_{1},\]

where \(p^{T_{q}}(x_{1}|x_{t})\) the conditional distribution of the stochastic process \(T_{q}\) at time moments \(t\) and \(1\). The process \(\text{proj}_{\mathcal{M}}(T_{q})\) has the same time marginal distributions \(p^{T_{q}}(x_{t})\) as the original Brownian bridge mixture \(T_{q}\). However, the joint distribution \(p^{T_{q}}(x_{0},x_{1})\) of \(T_{q}\) and the joint distribution \(p^{\text{proj}_{\mathcal{M}}(T_{q})}(x_{0},x_{1})\) of its projection \(\text{proj}_{\mathcal{M}}(T_{q})\) do not coincide in the general case [6], see Figure 2.

**Iterative Markovian Fitting [47, 35, 1].** The Iterative Markovian Fitting procedure introduces a second type of projection of continuous-time stochastic processes called the _Reciprocal projection_. For a process \(T\), it is is defined by \(\text{proj}_{\mathcal{R}}(T)=\int W^{\epsilon}_{|x_{0},x_{1}}dp^{T}(x_{0},x_{1})\), see illustrative Figure 3.

The process \(\text{proj}_{\mathcal{R}}(T)\) is called a projection, since:

\[\text{proj}_{\mathcal{R}}(T)=\operatorname*{arg\,min}_{R\in\mathcal{R}}\text {KL}\left(T\|R\right),\]

where \(\mathcal{R}\subset\mathcal{P}(C([0,1]),\mathbb{R}^{D})\) is the set of all reciprocal processes. The Iterative Markovian Fitting procedure is an alternation between Markovian and Reciprocal projections:

\[T^{2l+1}=\text{proj}_{\mathcal{M}}(T^{2l}),\quad T^{2l+2}=\text{proj}_{ \mathcal{R}}(T^{2l+1}),\]

It is known that the procedure converges to the unique stochastic process \(T^{*}\), which is known as a solution to the Schrodinger Bridge (SB) problem between \(p_{0}\) and \(p_{1}\). Furthermore, the SB \(T^{*}\) is the only process starting at \(p_{0}\) and ending at \(p_{1}\) that is both Markovian and reciprocal [25].

Figure 3: Reciprocal projection of a stochastic process \(T\), i.e., \(\text{proj}_{\mathcal{R}}(T)=\int W^{\epsilon}_{|x_{0},x_{1}}dp^{T}(x_{0},x_{1})\).

Figure 2: Markovian projection of a reciprocal stochastic process \(T_{q}\).

### Schrodinger Bridge (SB) Problem

**Schrodinger Bridge problem.** The Schrodinger Bridge problem [44] was proposed in 1931/1932 by Erwin Schrodinger. For the Wiener prior \(W^{\epsilon}\) Schrodinger Bridge problem between two probability distributions \(p_{0}\in\mathcal{P}_{2,ac}(\mathbb{R}^{D})\) and \(p_{1}\in\mathcal{P}_{2,ac}(\mathbb{R}^{D})\) is to minimize the following objective:

\[\min_{T\in\mathcal{F}(p_{0},p_{1})}\text{KL}\left(T\|W^{\epsilon}\right),\] (1)

where \(\mathcal{F}(p_{0},p_{1})\subset\mathcal{P}(C([0,1]),\mathbb{R}^{D})\) is the subset of stochastic processes which starts at distribution \(p_{0}\) (at the time \(t=0\)) and end at \(p_{1}\) (at \(t=1\)). The Scr\(\ddot{\text{o}}\)dinger Bridge has a unique solution, which is a diffusion process \(T^{*}\) described by the SDE: \(dX_{t}=v^{*}(X_{t},t)dt+\sqrt{\epsilon}dW_{t}\)[25]. The process \(T^{*}\) is called _the Schrodinger Bridge_ and \(v^{*}:\mathbb{R}^{D}\times[0,1]\rightarrow\mathbb{R}^{D}\) is called _the optimal drift_.

From the practical point of view, the solution to the SB problem \(T^{*}\) tends to preserve the Euclidean distance between start point \(x_{0}\) and endpoint \(x_{1}\). The equivalent form of SB problem, the static Schrodinger Bridge problem, explains this property more clearly.

**Static Schrodinger Bridge problem.** One may decompose \(\text{KL}(T\|W^{\epsilon})\) as [51, Appendix C]:

\[\text{KL}(T\|W^{\epsilon})=\text{KL}\big{(}p^{T}(x_{0},x_{1})\|p^{W^{*}}(x_{0},x_{1})\big{)}+\int\text{KL}(T_{|x_{0},x_{1}|}\|W^{\epsilon}_{|x_{0},x_{1}})dp ^{T}(x_{0},x_{1}),\] (2)

i.e., KL divergence between \(T\) and \(W^{\epsilon}\) is a sum of two terms: the 1st represents the similarity of the processes' joint marginal distributions at start and finish times \(t=0,1\), while the 2nd term represents the average similarity of conditional processes \(T_{|x_{0},x_{1}}\) and \(W^{\epsilon}_{|x_{0},x_{1}}\). In [25, Proposition 2.3], the authors show that if \(T^{*}\) solves (1), then \(T^{*}_{|x_{0},x_{1}}=W^{\epsilon}_{|x_{0},x_{1}}\). Hence, one may optimize (1) over \(T\) for which \(T_{|x_{0},x_{1}}=W^{\epsilon}_{|x_{0},x_{1}}\) for every \(x_{0},x_{1}\), i.e., over reciprocal processes \(T\):

\[\text{(1)}=\min_{T\in\mathcal{F}(p_{0},p_{1})\cap\mathcal{R}}\text{KL}\big{(}p ^{T}(x_{0},x_{1})\|p^{W^{*}}(x_{0},x_{1})\big{)}=\min_{q\in\Pi(p_{0},p_{1})} \text{KL}\big{(}q(x_{0},x_{1})\|p^{W^{*}}(x_{0},x_{1})\big{)},\] (3)

where \(\Pi(p_{0},p_{1})\subset\mathcal{P}_{2,ac}(\mathbb{R}^{D\times 2})\) is the set of joint probability distributions with marginal distributions \(p_{0}\) and \(p_{1}\). Thus, the initial Schrodinger Bridge problem can be solved by optimizing only over a reciprocal process's joint distribution \(q(x_{0},x_{1})\) at \(t=0,1\). This problem is called the Static Schrodinger Bridge problem. In turn, the problem can be rewritten in the following way [12, Eq. 7]:

\[\min_{q\in\Pi(p_{0},p_{1})}\epsilon\text{KL}(q\|p^{W^{\epsilon}}(x_{0},x_{1})) =\min_{q\in\Pi(p_{0},p_{1})}\int\frac{\|x_{0}-x_{1}\|^{2}}{2}dq(x_{0},x_{1})- \epsilon\cdot\text{Entropy}(q)+C,\] (4)

i.e., as finding a joint distribution \(q(x_{0},x_{1})\) which tries to minimize the Euclidian distance \(\frac{\|x-y\|^{2}}{2}\) between \(x_{0}\) and \(x_{1}\) (preserve similarity between \(x_{0}\) and \(x_{1}\)), but with the addition of entropy regularizer \(\epsilon\cdot\text{Entropy}(q)\) with the coefficient \(\epsilon\). Thus, the coefficient \(\epsilon>0\), which is the same for all problems considered above, regulates the stochastic or diversity of samples from \(q(x_{0},x_{1})\). The last problem (4) is also known as the entropic optimal transport (EOT) problem [4, 38, 25].

## 3 Adversarial Schrodinger Bridge Matching (ASBM)

The IMF framework [35, 47] works with _continuous_ time stochastic processes: it is built on the well-celebrated result that the only process which is both Markovian and reciprocal is the Schrodinger bridge \(T^{*}\)[25]. We derive an analogous theoretical result but for processes in _discrete_ time. We provide proofs for all the theorems and propositions in Appendix B.

In SS3.1, we give preliminaries on discrete processes with Markovian and reciprocal properties. In SS3.2, we present the main theorem of our paper, which is the foundation of our **Discrete-time Iterative Markovian Fitting (D-IMF)** framework. In SS3.3, we describe D-IMF procedure itself and prove that it allows us to solve the Schrodinger Bridge problem. In SS3.4, we provide an analysis of applying our D-IMF for solving the Schrodinger Bridge between Gaussian distributions. In SS3.5, we present the practical implementation of our D-IMF procedure using adversarial learning.

### Discrete Markovian and reciprocal stochastic processes

**Discrete reciprocal processes.** We define the discrete reciprocal processes similarly to the continuous case by considering the finite-time projection of the Brownian bridge \(W^{\epsilon}_{|x_{0},x_{1}}\), which is given by:

\[p^{W^{\epsilon}}(x_{t_{1}},\dots,x_{t_{N}}|x_{0},x_{1})=\prod_{n=1}^{N}p^{W^{ \epsilon}}(x_{t_{n}}|x_{t_{n-1}},x_{1}),\] (5)\[p^{W^{\epsilon}}(x_{t_{n}}|x_{t_{n-1}},x_{1})=\mathcal{N}(x_{t_{n}}|x_{t_{n-1}}+ \frac{t_{n}-t_{n-1}}{1-t_{n-1}}(x_{1}-x_{t_{n-1}}),\epsilon\frac{(t_{n}-t_{n-1}) (1-t_{n})}{1-t_{n-1}}).\] (6)

This joint distribution \(p^{W^{\epsilon}}(x_{t_{1}},\ldots,x_{t_{N}}|x_{0},x_{1})\) defines a discrete stochastic process, which we call a discrete Brownian bridge. In turn, we say that a distribution \(q\in\mathcal{P}_{2,ac}(\mathbb{R}^{D\times(N\times 2)})\) is a mixture of discrete Brownian bridges if it satisfies

\[q(x_{0},x_{t_{1}},\ldots,x_{t_{N}},x_{1})=p^{W^{\epsilon}}(x_{t_{1}},\ldots,x_ {t_{N}}|x_{0},x_{1})q(x_{0},x_{1}),\]

where \(q(x_{0},x_{1})\) denotes its joint marginal distribution of \(q\) at times \(0,1\). That is, its "inner" part at times \(t_{1},\ldots,t_{N}\) is the discrete Brownian Bridge. We denote the set of all such mixtures as \(\mathcal{R}(N)\subset\mathcal{P}_{2,ac}(\mathbb{R}^{D\times(N+2)})\) and call them discrete reciprocal processes.

**Discrete Markovian processes.** We say that a discrete process \(q\in\mathcal{P}_{2,ac}(\mathbb{R}^{D\times(N+2)})\) is Markovian if its density can be represented in the following form (recall that \(t_{0}=0,t_{N+1}=1\)):

\[q(x_{0},x_{t_{1}},x_{t_{2}},\ldots,x_{t_{N}},x_{1})=q(x_{0})\prod_{n=1}^{N+1}q (x_{t_{n}}|x_{t_{n-1}}).\] (7)

We denote the set of all such discrete Markovian processes as \(\mathcal{M}(N)\subset\mathcal{P}_{2,ac}(\mathbb{R}^{D\times(N+2)})\).

### Main Theorem

**Theorem 3.1** (Discrete Markovian and reciprocal process is the solution of static SB).: _Consider any discrete process \(q\in\mathcal{P}_{2,ac}(\mathbb{R}^{D\times(N+2)})\), which is simultaneously reciprocal and markovian, i.e. \(q\in\mathcal{R}(N)\) and \(q\in\mathcal{M}(N)\) and has marginals \(q(x_{0})=p_{0}(x_{0})\) and \(q(x_{1})=p_{1}(x_{1})\):_

\[q(x_{0},x_{t_{1}},\ldots,x_{t_{N}},x_{1})=p^{W^{\epsilon}}(x_{t_{1}},\ldots,x_ {t_{N}}|x_{0},x_{1})q(x_{0},x_{1})=q(x_{0})\prod_{n=1}^{N+1}q(x_{t_{n}}|x_{t_{ n-1}}),\]

_Then \(q(x_{0},x_{t_{1}},\ldots,x_{t_{N}},x_{1})=p^{T^{*}}(x_{0},x_{t_{1}},\ldots,x_ {t_{N}},x_{1})\), i.e., it is the finite-dimensional projection of the Schrodinger Bridge \(T^{*}\) to the considered times. Moreover, its joint marginal \(q(x_{0},x_{1})\) at times \(t=0,1\) is the solution to the **static SB** problem (4) between \(p_{0}\) and \(p_{1}\), i.e., \(q(x_{0},x_{1})=p^{T^{*}}(x_{0},x_{1})\)._

Thus, to solve the static SB problem, it is enough to find a Markovian mixture of discrete Brownian bridges. To do so, we propose the Discrete-time Iterative Markovian Fitting (D-IMF) procedure.

### Discrete-time Iterative Markovian Fitting (D-IMF) procedure

Similar to the IMF procedure, our proposed Discrete-time IMF is based on two alternating projections of discrete stochastic processes: reciprocal and Markovian. We start with the reciprocal projection.

**Definition 3.2** (Discrete Reciprocal Projection).: Assume that \(q\in\mathcal{P}_{2,ac}(\mathbb{R}^{D\times(N+2)})\) is a discrete stochastic process. Then the reciprocal projection \(\text{proj}_{\mathcal{R}}(q)\) is a discrete stochastic process with the joint distribution given by:

\[\big{[}\text{proj}_{\mathcal{R}}(q)\big{]}(x_{0},x_{t_{1}},\ldots,x_{t_{N}},x_ {1})=p^{W^{\epsilon}}(x_{t_{1}},\ldots,x_{t_{N}}|x_{0},x_{1})q(x_{0},x_{1}).\] (8)

This projection takes the joint distribution of start and end points \(q(x_{0},x_{1})\) and inserts the Brownian Bridge for intermediate time moments, see Figure 4. The prop. below justifies the projection's name.

**Proposition 3.3** (Discrete Reciprocal projection minimizes KL divergence with reciprocal processes).: _Under mild assumptions, the reciprocal projection \(\text{proj}_{\mathcal{R}}(q)\) of a stochastic discrete process \(q\in\mathcal{P}_{2,ac}(\mathbb{R}^{D\times(N+2)})\) is the unique solution for the following optimization problem:_

\[\text{proj}_{\mathcal{R}}(q)=\operatorname*{arg\,min}_{r\in\mathcal{R}(N)} \text{KL}\left(q\|r\right).\] (9)

Similarly to the discrete reciprocal projection, we introduce discrete Markovian projection.

**Definition 3.4** (Discrete Markovian Projection).: Assume that \(q\in\mathcal{P}_{2,ac}(\mathbb{R}^{D\times(N+2)})\) is a discrete stochastic process. The Markovian projection of \(q\) is a discrete stochastic process \(\text{proj}_{\mathcal{M}}(q)\in\mathcal{P}_{2,ac}(\mathbb{R}^{D\times(N+2)})\) whose joint distribution given by:

\[\big{[}\text{proj}_{\mathcal{M}}(q)\big{]}(x_{0},x_{t_{1}},...,x_{t_{N}},x_{1 })=q(x_{0})\prod_{n=1}^{N+1}q(x_{t_{n}}|x_{t_{n-1}}).\] (10)

Despite it is possible to use any discrete stochastic process \(q\) as an input to a discrete markovian projection, in the rest of the paper only discrete reciprocal processes are considered as an input. For such cases, we provide a visualization of the markovian projection in Figure 5.

As with the reciprocal projection, our following proposition justifies the name of the projection.

**Proposition 3.5** (Discrete Markovian projection minimizes KL divergence with Markovian processes).: _Under mild assumptions, the Markovian projection \(\text{proj}_{\mathcal{M}}(q)\) of a stochastic discrete process \(q\in\mathcal{P}_{2,ac}(\mathbb{R}^{D\times(N+2)})\) is a unique solution to the following optimization problem:_

\[\text{proj}_{\mathcal{M}}(q)=\operatorname*{arg\,min}_{m\in\mathcal{M}(N)} \text{KL}\left(q\|m\right).\] (11)

Now we are ready to define our D-IMF procedure. For two given distributions \(p_{0}\in\mathcal{P}_{2,ac}(\mathbb{R}^{D})\) and \(p_{1}\in\mathcal{P}_{2,ac}(\mathbb{R}^{D})\) at times \(t=0\) and \(t=1\), respectively, it starts with any discrete Brownian mixture \(p^{W^{\prime}}(x_{t_{1}},\ldots,x_{t_{N}}|x_{0},x_{1})q(x_{0},x_{1})\), where \(q(x_{0},x_{1})\in\Pi(p_{0},p_{1})\cap\mathcal{P}_{2,ac}(\mathbb{R}^{D\times 2})\). Then, it constructs the following sequence of discrete stochastic processes:

\[q^{2l+1}=\text{proj}_{\mathcal{M}}(q^{2l}),\quad q^{2l+2}=\text{proj}_{ \mathcal{R}}(q^{2l+1}).\] (12)

**Theorem 3.6** (D-IMF procedure converges to the the Schrodinger Bridge).: _Under mild assumptions, the sequence \(q^{l}\) constructed by our D-IMF procedure converges in KL to \(p^{T^{*}}\). In particular, \(q^{l}(x_{0},x_{1})\) convergence to the solution \(p^{T^{*}}(x_{0},x_{1})\) of the static SB. Namely, we have_

\[\lim_{l\to\infty}\text{KL}\left(q^{l}\|p^{T^{*}}\right)=0,\qquad\text{and} \qquad\lim_{l\to\infty}\text{KL}\left(q^{l}(x_{0},x_{1})\|p^{T^{*}}(x_{0},x_{1 })\right)=0.\]

### Closed form Updates of D-IMF for Gaussian Distributions

In this section, we show that our D-IMF updates (12) can be derived in the closed form for the Gaussian case. Let \(p_{0}=\mathcal{N}(x_{0}|\mu_{0},\Sigma_{0})\) and \(p_{1}=\mathcal{N}(x_{1}|\mu_{1},\Sigma_{1})\) be Gaussians. Consider any initial discrete Gaussian process \(q\in\mathcal{P}_{2,ac}(\mathbb{R}^{D\times(N+2)})\) that has joint distribution \(q(x_{0},x_{1})\in\Pi(p_{0},p_{1})\):

\[x_{01}\stackrel{{\text{def}}}{{=}}\begin{pmatrix}x_{0}\\ x_{1}\end{pmatrix},\quad\mu_{01}\stackrel{{\text{def}}}{{=}} \begin{pmatrix}\mu_{0}\\ \mu_{1}\end{pmatrix},\quad\Sigma=\begin{pmatrix}\Sigma_{0}&\Sigma_{\text{cov}} \\ \Sigma_{\text{cov}}^{T}&\Sigma_{1}\end{pmatrix},\quad q(x_{0},x_{1})\stackrel{{ \text{def}}}{{=}}\mathcal{N}(x_{01}|\mu_{01},\Sigma)\] (13)

where \(\Sigma\in\mathbb{R}^{2D\times 2D}\) is positive definite and symmetric and \(\Sigma_{\text{cov}}\) is the covariance of \(x_{0}\) and \(x_{1}\). In this case, the result of updates (12) is always a discrete Gaussian processes with specific parameters. To show this, we introduce two auxiliary matrices \(U\in\mathbb{R}^{ND\times 2D}\) and \(K\in\mathbb{R}^{ND\times ND}\):

\[U\stackrel{{\text{def}}}{{=}}\begin{pmatrix}(1-t_{1})I_{D}&t_{1}I_ {D}\\ (1-t_{2})I_{D}&t_{2}I_{D}\\ \vdots&\vdots\\ (1-t_{N})I_{D}&t_{N}I_{D}\end{pmatrix},\quad K\stackrel{{\text{ def}}}{{=}}\begin{pmatrix}t_{1}(1-t_{1})I_{D}&t_{1}(1-t_{2})I_{D}&\ldots&t_{1}(1-t_{N})I_{D}\\ t_{1}(1-t_{2})I_{D}&t_{2}(1-t_{2})I_{D}&\ldots&t_{2}(1-t_{N})I_{D}\\ \vdots&\vdots&\ldots&\vdots\\ t_{1}(1-t_{N})I_{D}&t_{2}(1-t_{N})I_{D}&\ldots&t_{N}(1-t_{N})I_{D}\end{pmatrix}\]

Here \(I_{D}\) is an identity matrix with the shape \(D\times D\). Below we present updates for both projections.

Figure 5: Markovian projection of a reciprocal discrete stochastic process \(q\).

**Theorem 3.7** (Reciprocal projection of a process whose joint marginal distribution is Gaussian).: _Assume that \(q\in\mathcal{P}_{2,ac}(\mathbb{R}^{D\times(N+2)})\) has Gaussian joint distribution \(q(x_{0},x_{1})\) given by (13). Then_

\[[\text{proj}_{\mathcal{R}}q](x_{\text{in}},x_{0},x_{1})=\mathcal{N}(\left( \begin{matrix}x_{\text{in}}\\ x_{01}\end{matrix}\right)|\left(\begin{matrix}U\mu_{01}\\ \mu_{01}\end{matrix}\right),\Sigma_{R}),\quad\Sigma_{R}\overset{\text{def}}{= }\left(\begin{matrix}\epsilon K+U\Sigma U^{T}&U\Sigma\\ (U\Sigma)^{T}&\Sigma\end{matrix}\right)\] (14)

**Theorem 3.8** (Markovian projection of a discrete Gaussian process).: _Assume that \(q\in\mathcal{P}_{2,ac}(\mathbb{R}^{D\times(N+2)})\) is a discrete Gaussian process with \(q(x_{0},x_{1})\) given by (13) and the density_

\[q(x_{\text{in}},x_{0},x_{1})=\mathcal{N}(\left(\begin{matrix}x_{\text{in}}\\ x_{01}\end{matrix}\right)|\left(\begin{matrix}\mu_{\text{in}}\\ \mu_{01}\end{matrix}\right),\widetilde{\Sigma}_{R}),\quad\mu_{in}=(\mu_{t_{1} },\ldots,\mu_{t_{N}}),\]

_where \(\mu_{\text{in}}\) and \(\widetilde{\Sigma}_{R}\) are some parameters of \(q\). Then its Markovian projection is given by:_

\[[\text{proj}_{\mathcal{M}}q](x_{\text{in}},x_{0},x_{1})=q(x_{0})\prod_{n=1}^{ N+1}q(x_{t_{n}}|x_{t_{n-1}}),\quad q(x_{t_{n}}|x_{t_{n-1}})=\mathcal{N}(x_{t_{n}}| \widehat{\mu}_{t_{n}}(x_{t_{n-1}}),\widehat{\Sigma}_{t_{n}}),\]

\[\widehat{\mu}_{t_{n}}(x_{t_{n-1}})=\mu_{t_{n}}+(\widetilde{\Sigma}_{R})_{t_{n },t_{n-1}}((\widetilde{\Sigma}_{R})_{t_{n-1},t_{n-1}})^{-1}(x_{t_{n-1}}-\mu_{t _{n-1}}),\]

\[\widehat{\Sigma}_{t_{n}}=(\widetilde{\Sigma}_{R})_{t_{n},t_{n}}-(\widetilde{ \Sigma}_{R})_{t_{n},t_{n-1}}((\widetilde{\Sigma}_{R})_{t_{n-1},t_{n-1}})^{-1}( (\widetilde{\Sigma}_{R})_{t_{n},t_{n-1}})^{T}.\]

_In turn, the joint distribution \([\text{proj}_{\mathcal{M}}q](x_{0},x_{1})\) is given by_

\[\text{proj}_{\mathcal{M}}q](x_{0},x_{1})=\mathcal{N}(\left(\begin{matrix}x_{0} \\ x_{1}\end{matrix}\right)|\left(\begin{matrix}\mu_{0}\\ \mu_{1}\end{matrix}\right),\left(\begin{matrix}\Sigma_{0}&\Sigma_{01}\\ (\Sigma_{01})^{T}&\Sigma_{1}\end{matrix}\right)),\Sigma_{01}^{T}=\Big{[}\prod_{n =1}^{N+1}(\widetilde{\Sigma}_{R})_{t_{n+1},t_{n}}((\widetilde{\Sigma}_{R})_{t _{n},t_{n}})^{-1}\Big{]}\Sigma_{0}.\]

_Here \((\widetilde{\Sigma}_{R})_{t_{i},t_{j}}\) is the submatrix of \(\widetilde{\Sigma}_{R}\) denoting the covariance of \(x_{t_{i}}\) and \(x_{t_{j}}\), while \(\Sigma_{0}\) and \(\Sigma_{1}\) are covariance matrices of \(x_{0}\) and \(x_{1}\), respectively._

Thus, if we start D-IMF from some discrete process \(q^{0}\) with marginals \(q^{0}(x_{0})=p_{0}(x_{0})\), \(q^{0}(x_{1})=p_{1}(x_{1})\) and Gaussian \(q(x_{0},x_{1})\), then at each iteration of our D-IMF procedure \(q^{l}\) will be discrete Gaussian process with the same marginals and eventually will converge to \(q^{*}\). In SS4.1, we use our derived closed-form to perform an experimental analysis of D-IMF's convergence depending on the number of intermediate time moments \(N\) and the value of coefficient \(\epsilon\).

### Practical Implementation of D-IMF: ASBM Algorithm

To implement our D-IMF procedure in practice, one should choose the process \(q^{0}\) and implement both discrete Markovian and reciprocal projections. Note that one is usually not interested in the processes' density but only needs the ability to sample endpoints \(x_{1}\) (or trajectories \(x_{0},x_{t_{1}},\ldots,x_{t_{N}},x_{1}\)) given a starting point \(x_{0}\) (\(=x_{t_{0}}\)). Thus, to solve SB between \(p_{0}(x_{0})\) and \(p_{1}(x_{1})\) one should choose \(q^{0}\) to have start and end marginals \(q^{0}(x_{0})=p_{0}(x_{0})\) and \(q^{0}(x_{1})=p(x_{1})\) accessible by samples.

**Implementation of the discrete reciprocal projection.** The reciprocal projection (8) of a given discrete process \(q(x_{0},x_{\text{in}},x_{1})\) is easy if one can sample from \(q(x_{0},x_{1})\). To sample from \(\text{proj}_{\mathcal{R}}(q)\) it is enough to sample first a pair \((x_{0},x_{1})\sim q(x_{0},x_{1})\) and then sample intermediate points \(x_{t_{1}},\ldots,x_{t_{N}}\) from the Brownian bridge \(p^{W^{\prime}}(x_{t_{1}},\ldots,x_{t_{N}}|x_{0},x_{1})\). This can be straightforwardly done using the formula (5) where the involved distributions (6) are simple Gaussians which are easy to sample from.

**Implementation of the discrete Markovian projection via DD-GAN.** To find the Markovian projection (10) of a reciprocal process \(q\in\mathcal{R}(N)\), one just needs to estimate the transition probabilities between sequential time moments, i.e., the set \(\{q(x_{t_{n}}|x_{t_{n-1}})\}_{n=1}^{N+1}\) and use the starting marginal \([\text{proj}_{\mathcal{M}}q](x_{0})=q(x_{0})=p_{0}(x_{0})\). The natural way to find transition probabilities is to set to parametrize all these distributions as \(\{q_{\theta}(x_{t_{n}}|x_{t_{n-1}})\}_{n=1}^{N+1}\) and solve

\[\min_{\theta}\sum_{n=1}^{N+1}\mathbb{E}_{q(x_{t_{n-1}})}D_{\text{adv}}\big{(}q(x _{t_{n}}|x_{t_{n-1}})||q_{\theta}(x_{t_{n}}|x_{t_{n-1}})\big{)},\] (15)

where \(D_{\text{adv}}\) is some distance or divergence between probability distributions. In this case, a minimum of such loss is achieved when \(q_{\theta}(x_{t_{n}}|x_{t_{n-1}})=q(x_{t_{n}}|x_{t_{n-1}})\) for each \(n\in\{1,2,\ldots,N+1\}\).

We note that a related setting is considered in the Denoising Diffusion GANs (DD-GAN), see [53, Eq. 4]. The difference is in the nature of \(q\): there \(q\) comes from the standard noising diffusion process, while in our case it is a given reciprocal process. Overall, the authors show that problems like (15)can be efficiently approached via time-conditioned GANs. Therefore, we naturally pick _DD-GAN approach as the backbone_ to learn our discrete Markovian projection and use their best practices.

In short, following DD-GAN, we parameterize \(q_{\theta}(x_{t_{n}}|x_{t_{n-1}})\) via a time-conditioned generator network \(G_{\theta}(x_{t_{n-1}},z,t_{n-1})\). As in DD-GAN, we use the non-saturating GAN loss [10] as \(D_{\text{adv}}\), which optimizes softened reverse KL-divergence [46]. To optimize this loss, an additional conditional discriminator network \(D(x_{t_{n-1}},x_{t_{n}},t_{n-1})\) is needed. We do not recall technical details here as they are the same as in DD-GAN. For further details on DD-GAN learning, we refer to Appendix D.1.

Note that after learning \(\{q_{\theta}(x_{t_{n}}|x_{t_{n-1}})\}_{n=1}^{N+1}\) the sampling assumes to take sample from \(q_{0}(x_{0})=p(x_{0})\) and then sample from \(\{q_{\theta}(x_{t_{n}}|x_{t_{n}-1})\}_{n=1}^{N+1}\). Hence it is guaranteed that \(q_{0}(x_{0})=p(x_{0})\), but there may be an approximation error in estimating \(q_{1}(x_{1})\approx p(x_{1})\). This is due to the asymmetry of the definition of Markovian projection, i.e., it can be written in two equivalent ways:

\[\big{[}\text{proj}_{\mathcal{M}}(q)\big{]}(x_{0},x_{t_{1}},...,x_{t_{N}},x_{1} )=q(x_{0})\prod_{n=1}^{N+1}q(x_{t_{n}}|x_{t_{n-1}})=q(x_{1})\prod_{n=1}^{N+1}q (x_{t_{n-1}}|x_{t_{n}}).\]

Analogously to the implementation of IMF [47, Algorithm 1], we address this asymmetry in our D-IMF by alternatively learning Markovian projection in forward and reverse directions. To learn Markovian projection in the reverse direction, we just need to use starting marginal \([\text{proj}_{\mathcal{M}}q](x_{1})=p_{1}(x_{1})\), parametrize \(\{q_{\eta}(x_{t_{n-1}}|x_{t_{n}})\}_{n=1}^{N+1}\) and solve:

\[\min_{\eta}\sum_{n=1}^{N+1}\mathbb{E}_{q(x_{t_{n}})}D_{\text{adv}}\big{(}q(x_ {t_{n-1}}|x_{t_{n}})||q_{\eta}(x_{t_{n-1}}|x_{t_{n}})\big{)}.\] (16)

In this case \(q(x_{1})=p_{1}(x_{1})\) is guaranteed, while \(q(x_{0})\approx p_{0}(x_{0})\).

**Implementation of the D-IMF procedure (ASBM algorithm)**. We start with initialization of \(q^{0}\) by the reciprocal process. Depending on the setup we use initialization with the independent coupling, i.e. \(q^{0}(x_{0},x_{1})\) = \(p_{0}(x_{0})p_{1}(x_{1})\) or a minibatch OT coupling [9, 39], see Appendix D.3 for details.

We follow the best practices of IMF [47] and in the Markovian projection steps, we alternately learn models in the direction \(p_{0}{\rightarrow}\,p_{1}\) and in the reverse direction \(p_{1}{\rightarrow}\,p_{0}\) by using functionals (15) and (16) respectively to avoid the accumulation of errors due to the asymmetry in the definition of the Markovian projection. For details, see Appendix D.2. At the reciprocal projection steps, we use the model \(q_{\theta}(x_{0},x_{in},x_{1})\) or \(q_{\eta}(x_{0},x_{in},x_{1})\) learned to approximate \(q^{2l+1}\) to sample pair \((x_{0},x_{1})\) and then sample intermediate points from Brownian bridge. We use the term **outer iteration** (\(K\)) for a sequence of two reciprocal projections and two Markovian projections in different directions.

### Relation to Prior Works

There exists a variety of algorithms for learning SB based on different underlying principles: dual form entropic optimal transport algorithms [5, 34, 24, 11, 12, 45], iterative proportional fitting (IPF) algorithms [51, 7, 2], bridge matching [49, 29] and iterative Markovian fitting (IMF) algorithms [47, 35, 28, 20], adversarial algorithms [21], etc. We refer to [13] for a benchmark and to [24, Table 1] for a quick survey of many of them. In turn, in our paper, we specifically focus on the advancement of IMF-type algorithms [47, 35] as it they are not only theoretically well-grounded but also closely connected to the rectified flow approach [30] which works well in large-scale generative modeling [32, 54]. Below we discuss the relation of our contributions (SS1) to the prior works in IMF [47, 35].

**Theory I**. As we detailed in SS2, basic IMF operates with stochastic processes in continuous time and iteratively performs Markovian and reciprocal projections. Our D-IMF procedure (SS3) does the same but in the discrete time, so it might _deceptively_ seem like our D-IMF is just an approximation of IMF. However, this is a misleading viewpoint. Indeed, the Markovian projection in the discrete time, in general, does not match with the continuous time Markovian projection. Still our D-IMF procedure _provably_ converges to SB. Furthermore, D-IMF procedure can theoretically work with just one intermediate time step (when \(N=1\)). Overall, its convergence rate varies depending on the number of intermediate points, see SS4.1. Naturally, we conjecture that in the limit \(N\rightarrow\infty\) (when the time steps \(t_{1},\ldots,t_{N}\) densely fill \([0,1]\)) our D-IMF behaves the same as IMF since the discrete and continuous Markovian projections start to be close, see discussion in [47, Appendix E].

**Theory II**. In SS3.4, we derive the closed-form expression for our D-IMF updates in the Gaussian case. For the continuous IMF, there exists an analogous result [35, SS6.1]. However, unlike our result,that one is not explicit in the seme that it requires solving the matrix-valued ODE (35, Eq. 39) to get the actual projection. The analytical solution is known only when \(D=1\), i.e., 1-dimensional case, see also (47, Appendix D). In contrast, our Gaussian D-IMF updates work in any dimension \(D\).

**Practice.** Default continuous-time IMF (47; 35) in practice is naturally implemented via the Bridge Matching approach which learns an SDE. In our case, at each D-IMF step we learn several transitional probabilities and do this via also well-established adversarial techniques. In this sense, our practical implementation differs - each approach is based on its own backbone - bridge matching vs. adversarial learning - and naturally inherits the benefits/drawbacks of the respective backbone. They are fairly well stated in the discussion of the generative learning trilemma in (53).

## 4 Experiments

We evaluate our adversarial SB matching (**ASBM**) algorithm, which implements our D-IMF procedure on setups with Gaussian distributions (SS4.1) for which we have closed form update formulas (SS3.4) and real image data distributions (SS4.2). We additionally provide results for an illustrative 2D example in Appendix C.1, results for the Colored MNIST dataset in Appendix C.3, and results on the standard SB benchmark in Appendix C.2. The code for our algorithm and all experiments with it is written in Pytorch, is available in the supplementary materials, and will be made public. We provide all the technical details in Appendix D.

### Gaussian-to-Gaussian Schrodinger Bridge

We analyze the convergence of our D-IMF procedure depending on the number of intermediate time steps \(N\geq 1\) (we use \(t_{n}=n/N+1\)) and the value \(\epsilon>0\) in the Gaussian case. In this case, the static SB solution \(p^{T^{*}}(x_{0},x_{1})\) is analytically known, see, e.g., (18). This provides us an opportunity to analyse how fast \(\text{KL}\left(q^{l}(x_{0},x_{1})\|p^{T^{*}}(x_{0},x_{1})\right)\) decreases when \(l\to\infty\).

We conduct experiments by using our analytical formulas for D-IMF from SS3.4. We follow setup from (12) and consider Schrodinger Bridge problem with the dimensionality \(D=16\) and \(\epsilon\in\{1,3,10\}\) for centered Gaussians \(p_{0}=\mathcal{N}(0,\Sigma_{0})\) and \(p_{1}=\mathcal{N}(0,\Sigma_{1})\). To construct \(\Sigma_{0}\) and \(\Sigma_{1}\), sample their eigenvectors from the uniform distribution on the unit sphere and sample their eigenvalues from the log uniform distribution on \([-\log 2,\log 2]\). We use the same \(p_{0}\) and \(p_{1}\) for all experiments.

We start our D-IMF procedure from the reciprocal process with \(q^{0}(x_{0},x_{1})=p_{0}(x_{0})p_{1}(x_{1})\), i.e. from the independent joint distribution at times \(t=0,1\). We present the convergence plots in Figures 5(a) and 5(b). In both plots, we use \(10^{-10}\) as a threshold corresponding to the exact matching of distributions to prevent numerical instabilities. We see that our D-IMF procedure empirically shows the exponential rate of convergence in all the cases. As we can see from Figure 5(a), the convergence speed dependence on \(N\) quickly saturates. Thus, even several time moments, e.g., \(N=5\), provide quick convergence speed. From Figure 5(b), we clearly see that the convergence speed is highly influenced by the chosen value of the parameter \(\epsilon\). For instance, the transition from \(\epsilon=1\) to \(\epsilon=10\) requires ten times more D-IMF iterations. Thus, this hyperparameter may be important in practice.

### Unpaired Image-to-image Translation

To test our approach on real data, we consider the unpaired image-to-image translation setup of learning _male \(\to\) female_ faces of Celeba dataset (33). We use \(10\%\) of _male_ and _female_ images as the test set for evaluation. We train our ABM algorithm based on the D-IMF procedure with \(\epsilon=1\) and \(\epsilon=10\). Following the best practices of DD-GAN (53), we use \(N=3\), intermediate times \(t_{1}=\frac{1}{4},t_{2}=\frac{2}{4},t_{3}=\frac{3}{4}\) and \(K=5\) outer iterations of D-IMF. We provide qualitative results and the FID metric (14) on the test set in Figures 6(b) and 6(e). Since we use \(N=3\) intermediate time moments, our algorithm requires only \(4\) number of function evaluations (NFE) at the inference stage.

Figure 6: Dependence of convergence of **our** D-IMF procedure on \(N\) and \(\epsilon\).

We focus our comparison on the DSBM algorithm based on the IMF-procedure [47] since it is closely related to our method. We train DSBM following the authors [47] and use \(\text{NFE}=100\). As well as for ASBM, we use \(5\) outer iterations of IMF, corresponding to the same number of reciprocal and Markovian projections, but for continuous processes. We use approximately the same number of parameters of neural networks used for models in Markovian projections for ASBM and DSBM (see Appendix D.3). For other details, see Appendix D.4. We present results for DSBM in Figure 6(c) and Figure 6(f). Our algorithm provides better results while using only \(4\) evaluation steps. Further additional results and measurements for ASBM and DSBM algorithms on the Celeba dataset are presented in Appendix E.

Thus, our D-IMF procedure allows us to solve the Schrodinger Bridge efficiently without learning the time-continuous stochastic process, which in turn speeds up inference by an order of magnitude. This aligns with the results obtained in the Gaussian-to-Gaussian setups about exponentially fast convergence of D-IMF even with several intermediate time moments.

## 5 Discussion

**Potential impact.** Beside the pure speed up of the inference of IMF, we want to point to another great advantage of our developed D-IMF framework. In the continuous IMF, one is forced to do Markovian projection via time-consuming learning of continuous-time SDEs (using procedures like bridge matching). In our D-IMF framework, one needs to **learn several transition probabilities**. We do this via adversarial learning [10], but actually this can be done **using** almost **any other generative modeling technique** (moment matching [26], normalizing flows [23; 41], energy-based models [56], score-based models [48], etc.). We believe that this observation opens great possibilities for ML community to further explore and improve generative modeling algorithms based on Schrodinger Bridges, Markovian projections (bridge matching) and related techniques, e.g., flow matching [27].

Limitations and broader impact are discussed in Appendix A.

Figure 7: Results of Celeba, _male\(\rightarrow\)female_ translation learned with ASBM (ours), and DSBM learned on Celeba dataset with 128 resolution size for \(\epsilon\in\{1,10\}\).

## Acknowledgements

The work was supported by the Analytical center under the RF Government (subsidy agreement 000000D730321P5Q0002, Grant No. 70-2021-00145 02.11.2021).

## References

* [1] Rob Brekelmans and Kirill Neklyudov. On schrodinger bridge matching and expectation maximization. In _NeurIPS 2023 Workshop Optimal Transport and Machine Learning_, 2023.
* [2] Tianrong Chen, Guan-Horng Liu, and Evangelos Theodorou. Likelihood training of schrodinger bridge using forward-backward sdes theory. In _International Conference on Learning Representations_, 2021.
* [3] Hyungjin Chung, Jeongsol Kim, and Jong Chul Ye. Direct diffusion bridge using data consistency for inverse problems. _Advances in Neural Information Processing Systems_, 36, 2024.
* [4] Marco Cuturi. Sinkhorn distances: Lightspeed computation of optimal transport. _Advances in neural information processing systems_, 26, 2013.
* [5] Max Daniels, Tyler Maunu, and Paul Hand. Score-based generative neural networks for large-scale optimal transport. _Advances in neural information processing systems_, 34:12955-12965, 2021.
* [6] Valentin De Bortoli, Guan-Horng Liu, Tianrong Chen, Evangelos A Theodorou, and Weilie Nie. Augmented bridge matching. _arXiv preprint arXiv:2311.06978_, 2023.
* [7] Valentin De Bortoli, James Thornton, Jeremy Heng, and Arnaud Doucet. Diffusion schrodinger bridge with applications to score-based generative modeling. _Advances in Neural Information Processing Systems_, 34:17695-17709, 2021.
* [8] Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas Muller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, et al. Scaling rectified flow transformers for high-resolution image synthesis. In _Forty-first International Conference on Machine Learning_, 2024.
* [9] Kilian Fatras, Younes Zine, Remi Flamary, Remi Gribonval, and Nicolas Courty. Learning with minibatch wasserstein: asymptotic and gradient properties. In _International Conference on Artificial Intelligence and Statistics_, pages 2131-2141. PMLR, 2020.
* [10] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In _Advances in neural information processing systems_, pages 2672-2680, 2014.
* [11] Nikita Gushchin, Sergei Kholkin, Evgeny Burnaev, and Alexander Korotin. Light and optimal schrodinger bridge matching. In _Forty-first International Conference on Machine Learning_, 2024.
* [12] Nikita Gushchin, Alexander Kolesov, Alexander Korotin, Dmitry Vetrov, and Evgeny Burnaev. Entropic neural optimal transport via diffusion processes. In _Advances in Neural Information Processing Systems_, 2023.
* [13] Nikita Gushchin, Alexander Kolesov, Petr Mokrov, Polina Karpikova, Andrey Spiridonov, Evgeny Burnaev, and Alexander Korotin. Building the bridge of schr\(\backslash\)" odinger: A continuous entropic optimal transport benchmark. In _Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track_, 2023.
* [14] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. GANs trained by a two time-scale update rule converge to a local nash equilibrium. In _Advances in neural information processing systems_, pages 6626-6637, 2017.
* [15] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. _Advances in neural information processing systems_, 33:6840-6851, 2020.
* [16] Xun Huang, Ming-Yu Liu, Serge Belongie, and Jan Kautz. Multimodal unsupervised image-to-image translation. In _Proceedings of the European conference on computer vision (ECCV)_, pages 172-189, 2018.
* [17] Oliver Ibe. _Markov processes for stochastic modeling_. Newnes, 2013.

* [18] Hicham Janati, Boris Muzellec, Gabriel Peyre, and Marco Cuturi. Entropic optimal transport between unbalanced gaussian measures has a closed form. _Advances in neural information processing systems_, 33:10468-10479, 2020.
* [19] Sadeep Jayasumana, Srikumar Ramalingam, Andreas Veit, Daniel Glasner, Ayan Chakrabarti, and Sanjiv Kumar. Rethinking fid: Towards a better evaluation metric for image generation. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pages 9307-9315, 2024.
* [20] Sergei Kholkin, Grigoriy Ksenofontov, David Li, Nikita Kornilov, Nikita Gushchin, Evgeny Burnaev, and Alexander Korotin. Diffusion & adversarial schr\(\backslash\)". onginger bridges via iterative proportional markovian fitting. _arXiv preprint arXiv:2410.02601_, 2024.
* [21] Beomsu Kim, Gihyun Kwon, Kwanyoung Kim, and Jong Chul Ye. Unpaired image-to-image translation via neural schrodinger bridge. In _The Twelfth International Conference on Learning Representations_, 2024.
* [22] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. _arXiv preprint arXiv:1412.6980_, 2014.
* [23] Durk P Kingma and Prafulla Dhariwal. Glow: Generative flow with invertible 1x1 convolutions. _Advances in neural information processing systems_, 31, 2018.
* [24] Alexander Korotin, Nikita Gushchin, and Evgeny Burnaev. Light schr\(\backslash\)". onginger bridge. In _International Conference on Learning Representations_, 2024.
* [25] Christian Leonard. A survey of the schr\(\backslash\)". onginger problem and some of its connections with optimal transport. _arXiv preprint arXiv:1308.0215_, 2013.
* [26] Yujia Li, Kevin Swersky, and Rich Zemel. Generative moment matching networks. In _International conference on machine learning_, pages 1718-1727. PMLR, 2015.
* [27] Yaron Lipman, Ricky TQ Chen, Heli Ben-Hamu, Maximilian Nickel, and Matthew Le. Flow matching for generative modeling. In _The Eleventh International Conference on Learning Representations_, 2022.
* [28] Guan-Horng Liu, Yaron Lipman, Maximilian Nickel, Brian Karrer, Evangelos Theodorou, and Ricky TQ Chen. Generalized schrodinger bridge matching. In _The Twelfth International Conference on Learning Representations_, 2023.
* [29] Guan-Horng Liu, Arash Vahdat, De-An Huang, Evangelos A Theodorou, Weili Nie, and Anima Anandkumar. 12sb: image-to-image schrodinger bridge. In _Proceedings of the 40th International Conference on Machine Learning_, pages 22042-22062, 2023.
* [30] Xingchao Liu, Chengyue Gong, et al. Flow straight and fast: Learning to generate and transfer data with rectified flow. In _The Eleventh International Conference on Learning Representations_, 2022.
* [31] Xingchao Liu, Lemeng Wu, Mao Ye, et al. Let us build bridges: Understanding and extending diffusion generative models. In _NeurIPS 2022 Workshop on Score-Based Methods_, 2022.
* [32] Xingchao Liu, Xiwen Zhang, Jianzhu Ma, Jian Peng, et al. Instaflow: One step is enough for high-quality diffusion-based text-to-image generation. In _The Twelfth International Conference on Learning Representations_, 2023.
* [33] Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild. In _Proceedings of International Conference on Computer Vision (ICCV)_, December 2015.
* [34] Petr Mokrov, Alexander Korotin, Alexander Kolesov, Nikita Gushchin, and Evgeny Burnaev. Energy-guided entropic neural optimal transport. In _The Twelfth International Conference on Learning Representations_, 2024.
* [35] Stefano Peluchetti. Diffusion bridge mixture transports, schrodinger bridge problems and generative modeling. _Journal of Machine Learning Research_, 24(374):1-51, 2023.
* [36] Stefano Peluchetti. Non-denoising forward-time diffusions. _arXiv preprint arXiv:2312.14589_, 2023.
* [37] Kaare Brandt Petersen, Michael Syskind Pedersen, et al. The matrix cookbook. _Technical University of Denmark_, 7(15):510, 2008.
* [38] Gabriel Peyre, Marco Cuturi, et al. Computational optimal transport. _Foundations and Trends(r) in Machine Learning_, 11(5-6):355-607, 2019.

* [39] Aram-Alexandre Pooladian, Heli Ben-Hamu, Carles Domingo-Enrich, Brandon Amos, Yaron Lipman, and Ricky TQ Chen. Multisample flow matching: Straightening flows with minibatch couplings. In _International Conference on Machine Learning_, pages 28100-28127. PMLR, 2023.
* [40] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In _International conference on machine learning_, pages 8748-8763. PMLR, 2021.
* [41] Danilo Rezende and Shakir Mohamed. Variational inference with normalizing flows. In _International conference on machine learning_, pages 1530-1538. PMLR, 2015.
* [42] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In _Medical image computing and computer-assisted intervention-MICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18_, pages 234-241. Springer, 2015.
* [43] Ludger Ruschendorf. Convergence of the iterative proportional fitting procedure. _The Annals of Statistics_, pages 1160-1174, 1995.
* [44] Erwin Schrodinger. _Uber die umkehrung der naturgesetze_. Verlag der Akademie der Wissenschaften in Kommission bei Walter De Gruyter u..., 1931.
* [45] Vivien Seguy, Bharath Bhushan Damodaran, Remi Flamary, Nicolas Courty, Antoine Rolet, and Mathieu Blondel. Large scale optimal transport and mapping estimation. In _International Conference on Learning Representations_, 2018.
* [46] Matt Shannon, Ben Poole, Soroosh Mariooryad, Tom Bagby, Eric Battenberg, David Kao, Daisy Stanton, and RJ Skerry-Ryan. Non-saturating gan training as divergence minimization. _arXiv preprint arXiv:2010.08029_, 2020.
* [47] Yuyang Shi, Valentin De Bortoli, Andrew Campbell, and Arnaud Doucet. Diffusion schrodinger bridge matching. In _Thirty-seventh Conference on Neural Information Processing Systems_, 2023.
* [48] Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data distribution. _Advances in neural information processing systems_, 32, 2019.
* [49] Alexander Tong, Nikolay Malkin, Kilian Fatras, Lazar Atanackovic, Yanlei Zhang, Guillaume Huguet, Guy Wolf, and Yoshua Bengio. Simulation-free schr\(\backslash\)" _o_dinger bridges via score and flow matching. _arXiv preprint arXiv:2307.03672_, 2023.
* [50] Tim Van Erven and Peter Harremos. Renyi divergence and kullback-leibler divergence. _IEEE Transactions on Information Theory_, 60(7):3797-3820, 2014.
* [51] Francisco Vargas, Pierre Thodoroff, Austen Lamacraft, and Neil Lawrence. Solving schrodinger bridges via maximum likelihood. _Entropy_, 23(9):1134, 2021.
* [52] Cedric Villani. _Optimal transport: old and new_, volume 338. Springer Science & Business Media, 2008.
* [53] Zhisheng Xiao, Karsten Kreis, and Arash Vahdat. Tackling the generative learning trilemma with denoising diffusion GANs. In _International Conference on Learning Representations_, 2022.
* [54] Hanshu Yan, Xingchao Liu, Jiachun Pan, Jun Hao Liew, Qiang Liu, and Jiashi Feng. Perflow: Piecewise rectified flow as universal plug-and-play accelerator, 2024.
* [55] Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shechtman, and Oliver Wang. The unreasonable effectiveness of deep features as a perceptual metric. In _Proceedings of the IEEE conference on computer vision and pattern recognition_, pages 586-595, 2018.
* [56] Yang Zhao, Jianwen Xie, and Ping Li. Learning energy-based generative models via coarse-to-fine expanding and sampling. In _International Conference on Learning Representations_, 2020.

Limitations and Future Work

**Adversarial training**. It is a generic knowledge that the adversarial training may be non trivial to conduct due to instabilities, mode collapse and related issues. Fortunately, our ABM algorithm relies on the already well-established and carefully tuned DD-GAN [53] technique as a backbone. The latter is specifically designed to address many such limitations and is known to score good metrics in generative modeling.

**Theoretical convergence rate**. We derive the generic convergence result for our D-IMF procedure (Theorem 3.6) but without the particular convergence rate. Empirically we observe the exponentially fast convergence (SS4.1), but theoretically proving this rate is an important task for the future work.

**Broader Impact.** This paper presents work whose goal is to advance the field of Artificial Intelligence, Machine Learning and Generative Modeling. There are many potential societal consequences of our work, none which we feel must be specifically highlighted here.

## Appendix B Proofs

Here we provide the proof of our theoretical results one-by-one. Additionally, we introduce and prove several auxiliary results to simplify the derivation of the main results.

Proof of Theorem 3.1.: We split the proof in 2 stages. The 1st is auxiliary for the 2nd.

**Stage 1.** Here we show that if some \(q(x_{0},x_{1})\in\mathcal{P}_{2,ac}(\mathbb{R}^{D\times 2})\) with marginals \(p_{0}(x_{0})=q(x_{0})\) and \(p_{1}(x_{1})=q(x_{1})\) has the density in the form

\[q(x_{0},x_{1})=q(x_{0})\widehat{C}(x_{0})\exp\biggl{(}-\frac{||x_{1}-x_{0}||^{ 2}}{2\epsilon}\biggr{)}\widehat{\phi}(x_{1}),\]

then it solves the Static SB between distributions \(p_{0}(x_{0})\) and \(p_{1}(x_{1})\). It is known [25], that the solution \(q^{*}(x_{0},x_{1})\stackrel{{\text{def}}}{{=}}p^{T^{*}}(x_{0},x _{1})\) of Static SB between \(p_{0}\) and \(p_{1}\) has the density:

\[q^{*}(x_{0},x_{1})=\psi^{*}(x_{0})\exp\biggl{(}-\frac{||x_{1}-x_{0}||^{2}}{2 \epsilon}\biggr{)}\phi^{*}(x_{1}).\]

Hence, the conditional density \(q^{*}(x_{1}|x_{0})\) is expressed as:

\[q^{*}(x_{1}|x_{0})=\frac{\psi^{*}(x_{0})}{\underbrace{p_{0}(x_{0})}_{\#C^{*}( x_{0})}}\exp\biggl{(}-\frac{||x_{1}-x_{0}||^{2}}{2\epsilon}\biggr{)}\phi^{*}(x_{1} )=C^{*}(x_{0})\exp\biggl{(}-\frac{||x_{1}-x_{0}||^{2}}{2\epsilon}\biggr{)} \phi^{*}(x_{1}).\]

Thus, both \(q(x_{0},x_{1})\) and \(q^{*}(x_{0},x_{1})\) have their densities in the same functional form and the same marginals \(q(x_{0})=q^{*}(x_{0})=p_{0}(x_{0})\) and \(q(x_{1})=q^{*}(x_{1})=p_{1}(x_{1})\). However, we want to prove that in this case \(q(x_{0},x_{1})\) and \(q^{*}(x_{0},x_{1})\) are equal, i.e., \(\text{KL}\,(q^{*}||q)=0\).

\[\text{KL}\,(q^{*}(x_{0},x_{1})\|q(x_{0},x_{1}))=\int\log\frac{q^{* }(x_{0},x_{1})}{q(x_{0},x_{1})}q^{*}(x_{0},x_{1})dx_{0}dx_{1}=\] \[\int\log\frac{C^{*}(x_{0})\exp\Bigl{(}-\frac{||x_{1}-x_{0}||^{2} }{2\epsilon}\Bigr{)}\phi^{*}(x_{1})}{\widehat{C}(x_{0})\exp\Bigl{(}-\frac{||x _{1}-x_{0}||^{2}}{2\epsilon}\Bigr{)}\widehat{\phi}(x_{1})}q^{*}(x_{0},x_{1}) dx_{0}dx_{1}=\]

[MISSING_PAGE_FAIL:15]

Then, we use the formula for the Brownian Bridge density:

\[\log q(x_{1}|x_{0})=\log q(x_{t}|x_{0})+\log q(x_{1}|x_{t})-C+\frac{1 }{2\epsilon t(1-t)}||x_{t}-(tx_{1}+(1-t)x_{0})||^{2}=\] \[\log q(x_{t}|x_{0})+\log q(x_{1}|x_{t})-C+\] \[\frac{1}{2\epsilon t(1-t)}(||x_{t}||^{2}+||tx_{1}||^{2}+||(1-t)x_ {0}||^{2}-2tx_{t}^{T}x_{1}-2(1-t)x_{t}^{T}x_{0}+2t(1-t)x_{0}^{T}x_{1})=\] \[\log q(x_{t}|x_{0})+\log q(x_{1}|x_{t})-C+\] \[\underbrace{\frac{||(1-t)x_{0}||^{2}}{2\epsilon t(1-t)}+\frac{|| tx_{1}||^{2}}{2\epsilon t(1-t)}+\frac{||tx_{1}||^{2}}{2\epsilon t(1-t)}-\frac{x _{t}^{T}x_{1}}{\epsilon(1-t)}-\frac{x_{t}^{T}x_{0}}{\epsilon t}+\frac{x_{0}^{T }x_{1}}{\epsilon}}_{\stackrel{{\text{def}}}{{=}}f_{1}(x_{t},x_{1})}+\] \[\underbrace{\frac{||(1-t)x_{0}||^{2}}{2\epsilon t(1-t)}+\log q(x _{t}|x_{0})-\frac{x_{t}^{T}x_{0}}{\epsilon t}+\frac{x_{0}^{T}x_{1}}{\epsilon}} _{\stackrel{{\text{def}}}{{=}}f_{2}(x_{t},x_{0})}+\]

Thus,

\[\log q(x_{1}|x_{0})=f_{1}(x_{t},x_{1})+f_{2}(x_{t},x_{0})+\frac{x _{0}^{T}x_{1}}{\epsilon},\] \[\underbrace{\frac{\log q(x_{1}|x_{0})-\frac{x_{0}^{T}x_{1}}{ \epsilon}}{\epsilon t_{f_{3}}(x_{0},x_{1})}}_{\stackrel{{\text{ def}}}{{=}}f_{3}(x_{t},x_{1})}=f_{1}(x_{t},x_{1})+f_{2}(x_{t},x_{0}),\] \[f_{3}(x_{0},x_{1})=f_{1}(x_{t},x_{1})+f_{2}(x_{t},x_{0}).\] (20)

Below, we prove that \(f_{3}(x_{0},x_{1})=g_{1}(x_{0})+g_{2}(x_{1})\) for some functions \(g_{1}\) and \(g_{2}\). We note that

\[f_{3}(x_{0},0)=f_{1}(x_{t},0)+f_{2}(x_{t},x_{0})\qquad\Rightarrow\qquad f_{2 }(x_{t},x_{0})=f_{3}(x_{0},0)-f_{1}(x_{t},0).\] (21)

We substitute (21) to (20):

\[f_{3}(x_{0},x_{1})=f_{1}(x_{t},x_{1})+\underbrace{f_{3}(x_{0},0)-f_{1}(x_{t}, 0)}_{=f_{2}(x_{t},x_{0})}\] \[f_{3}(x_{0},x_{1})-f_{3}(x_{0},0)=f_{1}(x_{t},x_{1})-f_{1}(x_{t}, 0).\] (22)

Since there is no dependence on \(x_{0}\) in the right part of (22), we conclude that \(f_{3}(x_{0},x_{1})-f_{3}(x_{0},0)\) is a function of only \(x_{1}\). We define \(g_{1}(x_{1})\stackrel{{\text{def}}}{{=}}f_{3}(x_{0},x_{1})-f_{3} (x_{0},0)\) and \(g_{2}(x_{0})\stackrel{{\text{def}}}{{=}}f_{3}(x_{0},0)\). Now we have the desired result:

\[f_{3}(x_{0},x_{1})=g_{1}(x_{1})+f_{3}(x_{0},0)=g_{1}(x_{1})+g_{2}(x_{0}).\] (23)

Thus,

\[f_{3}(x_{0},x_{1})=\log q(x_{1}|x_{0})-\frac{x_{0}^{T}x_{1}}{ \epsilon}=g_{1}(x_{1})+g_{2}(x_{0}).\]

Now, we can use this result about the separation of variables together with the result from the first **stage** to conclude the proof of the theorem.

\[\log q(x_{1}|x_{0})=g_{1}(x_{1})+g_{2}(x_{0})+\frac{x_{0}^{T}x_{1 }}{\epsilon}=\] \[g_{1}(x_{1})+\frac{||x_{1}||^{2}}{2\epsilon}+g_{2}(x_{0})+\frac{ ||x_{0}||^{2}}{2\epsilon}-\frac{||x_{0}-x_{1}||^{2}}{2\epsilon},\] \[q(x_{1}|x_{0})=\underbrace{\exp\biggl{(}g_{2}(x_{0})+\frac{||x_{0 }||^{2}}{2\epsilon}\biggr{)}}_{\stackrel{{\text{def}}}{{=}}C(x_{0} )}\exp\biggl{(}-\frac{||x_{0}-x_{1}||^{2}}{2\epsilon}\biggr{)}\underbrace{ \exp\biggl{(}g_{1}(x_{1})+\frac{||x_{1}||^{2}}{2\epsilon}\biggr{)}}_{ \stackrel{{\text{def}}}{{=}}\phi(x_{1})}=\]\[q(x_{1}|x_{0})=C(x_{0})\exp\biggl{(}-\frac{||x_{0}-x_{1}||^{2}}{2 \epsilon}\biggr{)}\phi(x_{1}),\] \[q(x_{0},x_{1})=q(x_{0})C(x_{0})\exp\biggl{(}-\frac{||x_{0}-x_{1}|| ^{2}}{2\epsilon}\biggr{)}\phi(x_{1}).\]

Hence, from the first **stage** of this proof it follows that \(q(x_{0},x_{1})\) is the solution to the Static SB between \(q(x_{0})=p_{0}(x_{0})\) and \(q(x_{1})=p_{1}(x_{1})\) with the coefficient \(\epsilon\). That is, \(p^{T^{*}}(x_{0},x_{1})=q(x_{0},x_{1})\). Since \(q(x_{t_{1}},\ldots,x_{t_{N}}|x_{0},x_{1})=p^{W^{\epsilon}}(x_{t_{1}},\ldots,x _{t_{N}}|x_{0},x_{1})\) by the assumptions of the current theorem, we also conclude that \(q(x_{0},x_{t_{1}},\ldots,x_{t_{N}},x_{1})=p^{T^{*}}(x_{0},x_{t_{1}},\ldots,x _{t_{N}},x_{1})\), i.e., the discrete processes coincide. 

### Proofs for Statements in Section 3.3

The logic of our justification of D-IMF for discrete processes generally follows the respective logic of the justification of IMF for continuous stochastic processes [47].

Proof of Proposition 3.3.: The mild assumption here consists in the existence of at least one process \(r\in\mathcal{R}(N)\) for which \(\text{KL}\left(q\|r\right)<\infty\). The reciprocal process \(r\in\mathcal{R}(N)\) has its density in the form \(r(x_{0},x_{t_{1}},\ldots,x_{t_{N}},x_{1})=p^{W^{\epsilon}}(x_{t_{1}},\ldots,x _{t_{N}}|x_{0},x_{1})r(x_{0},x_{1})\) (see (7)). Thus, we need to optimize only the part \(r(x_{0},x_{1})\). Below we show, that \(r(x_{0},x_{1})\) should be equal \(q(x_{0},x_{1})\) to minimize the functional.

\[\text{KL}\left(q\|r\right)=\int\log\frac{q(x_{0},x_{\text{in}},x_{ 1})}{r(x_{0},x_{\text{in}},x_{1})}q(x_{0},x_{\text{in}},x_{1})dx_{0}dx_{\text{ in}}dx_{1}=\] \[\int\log\frac{q(x_{\text{in}}|x_{0},x_{1})q(x_{0},x_{1})}{r(x_{0 },x_{1})}q(x_{0},x_{\text{in}},x_{1})dx_{0}dx_{\text{in}}dx_{1}=\] \[\underbrace{\int\log\frac{q(x_{\text{in}}|x_{0},x_{1})}{p^{W^{*} }(x_{\text{in}}|x_{0},x_{1})}q(x_{0},x_{\text{in}},x_{1})dx_{0}dx_{\text{in}} dx_{1}}_{=\text{Const}}+\int\log\frac{q(x_{0},x_{1})}{r(x_{0},x_{1})}q(x_{0},x_{ \text{in}},x_{1})dx_{0}dx_{\text{in}}dx_{1}=\] \[\text{Const}+\underbrace{\int\log\frac{q(x_{0},x_{1})}{r(x_{0},x_{ 1})}q(x_{0},x_{1})dx_{0}dx_{1}}_{=\text{KL}(q(x_{0},x_{1})\|r(x_{0},x_{1}))}= \text{Const}+\text{KL}\left(q(x_{0},x_{1})\right)\]

Hence, \(\text{proj}_{\mathcal{R}}(q)=\arg\min_{r\in\mathcal{R}(N)}\text{KL}\left(q\|r \right)=p^{W^{\epsilon}}(x_{\text{in}}|x_{0},x_{1})q(x_{0},x_{1})\). 

Proof of Proposition 3.5.: Similar to the previous proposition, the mild assumption here consists in the existence of at least one process \(m\in\mathcal{M}(N)\) for which \(\text{KL}\left(q\|m\right)<\infty\). This proof is a bit more technical than for the reciprocal projection. We need to define new notation \(x_{t_{n},t_{n-1}}^{\text{not}}=(x_{t_{0}},\ldots,x_{t_{n-2}},x_{t_{n+1}},\ldots,x_{t_{N+1}})\) for a vector of variables for all time moment except two time moments \(t_{n}\) and \(t_{n-1}\).

\[\text{KL}\left(q\|m\right)=\int\log\frac{q(x_{0},x_{\text{in}},x _{1})}{m(x_{0},x_{\text{in}},x_{1})}q(x_{0},x_{\text{in}},x_{1})dx_{0}dx_{\text{ in}}dx_{1}=\] \[\int\log\frac{q(x_{0},x_{\text{in}},x_{1})}{m(x_{0})\prod_{n=1}^{ N+1}m(x_{t_{n}}|x_{t_{n-1}})}q(x_{0},x_{\text{in}},x_{1})dx_{0}dx_{\text{in}}dx_{1}=\] \[\int\log\frac{q(x_{0})}{m(x_{0})}q(x_{0},x_{\text{in}},x_{1})dx_{0 }dx_{\text{in}}dx_{1}+\int\log\frac{q(x_{\text{in}},x_{1}|x_{0})}{\prod_{n=1}^{ N+1}m(x_{t_{n}}|x_{t_{n-1}})}q(x_{0},x_{\text{in}},x_{1})dx_{0}dx_{\text{in}}dx_{1}=\] \[\underbrace{\int\log\frac{q(x_{0})}{m(x_{0})}q(x_{0})dx_{0}}_{ \text{KL}(q(x_{0})\|m(x_{0}))}+\int\log\frac{q(x_{\text{in}},x_{1}|x_{0})}{ \prod_{n=1}^{N+1}m(x_{t_{n}}|x_{t_{n-1}})}q(x_{0},x_{\text{in}},x_{1})dx_{0}=\]\[\text{KL}\left(q(x_{0})\|m(x_{0})\right)+\int\log\frac{q(x_{\text{in}},x_{1}|x_{0} )}{\prod_{n=1}^{N+1}m(x_{t_{n}}|x_{t_{n-1}})}q(x_{0},x_{\text{in}},x_{1})dx_{0} dx_{\text{in}}dx_{1}+\] (24) \[\underbrace{N\int\log\frac{q(x_{0},x_{\text{in}},x_{1})}{q(x_{0},x_{\text{in}},x_{1})}q(x_{0},x_{\text{in}},x_{1})dx_{0}dx_{\text{in}}dx_{1}}_{ =0}+\underbrace{\int\log\frac{q(x_{0})}{q(x_{0})}q(x_{0},x_{\text{in}},x_{1}) dx_{0}dx_{\text{in}}x_{1}}_{=0}=\] (25) \[\text{KL}\left(q(x_{0})\|m(x_{0})\right)+\int\log\frac{\prod_{n=1 }^{N+1}q(x_{0},x_{\text{in}},x_{1})}{\prod_{n=1}^{N+1}m(x_{t_{n}}|x_{t_{n-1}}) }q(x_{0},x_{\text{in}},x_{1})dx_{0}dx_{\text{in}}dx_{1}-\] \[\left(N\int\log q(x_{0},x_{\text{in}},x_{1})q(x_{0},x_{\text{in}},x_{1})dx_{0}dx_{\text{in}}dx_{1}+\int\log q(x_{0})q(x_{0})dx_{0}dx_{\text{in}} dx_{1}\right)=\] \[\text{KL}\left(q(x_{0})\|m(x_{0})\right)+\sum_{n=1}^{N+1}\int \log\frac{q(x_{0},x_{\text{in}},x_{1})}{m(x_{t_{n}}|x_{t_{n-1}})}q(x_{0},x_{ \text{in}},x_{1})dx_{0}dx_{\text{in}}dx_{1}-\] \[\underbrace{\left(N\int\log q(x_{0},x_{\text{in}},x_{1})q(x_{0}, x_{\text{in}},x_{1})dx_{0}dx_{\text{in}}dx_{1}+\int\log q(x_{0})q(x_{0})dx_{0} dx_{\text{in}}dx_{1}\right)}_{\stackrel{{\text{def}}}{{=}}C_{1}}=\] \[\text{KL}\left(q(x_{0})\|m(x_{0})\right)-C_{1}+\] \[\sum_{n=1}^{N+1}\int\log\frac{q(x_{t_{n}}|x_{t_{n-1}})q(x_{t_{n-1 }})q(x_{t_{n},t_{n-1}}^{\text{not}}|x_{t_{n}},x_{t_{n-1}})}{m(x_{t_{n}}|x_{t_{n -1}})}q(x_{0},x_{\text{in}},x_{1})dx_{0}dx_{\text{in}}dx_{1}=\] \[\text{KL}\left(q(x_{0})\|m(x_{0})\right)+C_{2}+\sum_{n=1}^{N+1} \big{(}\underbrace{\int\log\frac{q(x_{t_{n}}|x_{t_{n-1}})}{m(x_{t_{n}}|x_{t_{n -1}})}q(x_{t_{n}}|x_{t_{n-1}})dx_{t_{n}}}_{\text{KL}\left(q(x_{t_{n}}|x_{t_{n -1}})\|m(x_{t_{n}}|x_{t_{n-1}})\right)}q(x_{t_{n-1}})dx_{t_{n-1}}=\] \[\text{KL}\left(q(x_{0})\|m(x_{0})\right)+\sum_{n=1}^{N+1}\int \text{KL}\left(q(x_{t_{n}}|x_{t_{n-1}})\|m(x_{t_{n}}|x_{t_{n-1}})\right)q(x_{t _{n-1}})dx_{t_{n-1}}+C_{2}.\]

In the line (25), we add terms equal to zero, to match each \(m(x_{t_{n}}|x_{t_{n-1}})\) by the separate term \(q(x_{0},x_{\text{in}},x_{1})\) in the line (25). We need it to as we want to place each term \(m(x_{t_{n}}|x_{t_{n-1}})\) in the separate KL-divergence in the final expression. Hence, the minimizer of the objective \(m^{*}\in\mathcal{M}(N)\) has \(m^{*}(x_{0})=q(x_{0})\) and all transitional distributions \(m^{*}(x_{t_{n}}|x_{t_{n-1}})=q(x_{t_{n}}|x_{t_{n-1}})\), i.e. is given by

\[m^{*}(x_{0},x_{\text{in}},x_{1})=[\text{proj}_{\mathcal{M}}(q)](x_{0},x_{\text{ in}},x_{1})=q(x_{0})\prod_{n=1}^{N+1}q(x_{t_{n}}|x_{t_{n-1}}).\]

**Proposition B.1** (Pythagorean theorems for projections).: _Assume that \(r\in\mathcal{R}(N)\) and \(m\in\mathcal{M}(N)\). If \(\text{KL}\left(r\|m\right)<\infty\) and \(\text{KL}\left(r\|\text{proj}_{\mathcal{M}}(r)\right)<\infty\), then_

\[\text{KL}\left(r\|m\right)=\text{KL}\left(r\|\text{proj}_{\mathcal{M}}(r) \right)+\text{KL}\left(\text{proj}_{\mathcal{M}}(r)\|m\right)\] (26)

_and if \(\text{KL}\left(m\|r\right)<\infty\), \(\text{KL}\left(m\|\text{proj}_{\mathcal{R}}(m)\right)<\infty\) then_

\[\text{KL}\left(m\|r\right)=\text{KL}\left(m\|\text{proj}_{\mathcal{R}}(m) \right)+\text{KL}\left(\text{proj}_{\mathcal{R}}(m)\|r\right)\]

Proof of Proposition b.1.: Before proving the first equation (26) we prove the additional property of \(r\in\mathcal{R}(N)\) for any \(n\in[1,2,\ldots,N+1]\):

\[[\text{proj}_{\mathcal{M}}r](x_{t_{n}},x_{t_{n-1}})=r(x_{t_{n}},x_{t_{n-1}}).\]\[[\text{proj}_{\mathcal{M}}r](x_{t_{n}},x_{t_{n-1}})=[\text{proj}_{\mathcal{M}}r](x_{ t_{n}}|x_{t_{n-1}})[\text{proj}_{\mathcal{M}}r](x_{t_{n}})=r(x_{t_{n}}|x_{t_{n-1}})r(x_{t_{n}}).\] (27)

Since \([\text{proj}_{\mathcal{M}}r](x_{t_{n}}|x_{t_{n-1}})=r(x_{t_{n}}|x_{t_{n-1}})\) by the definition and since Markovian projection preserve all intermediate time marginals. Now we prove the first equation (26).

\[\text{KL}\left(r\|m\right)=\int\log\frac{r(x_{0},x_{\text{in}},x_{1})}{m(x_{0 },x_{\text{in}},x_{1})}r(x_{0},x_{\text{in}},x_{1})dx_{0}dx_{\text{in}}dx_{1}=\]

\[\int\log\frac{r(x_{0},x_{\text{in}},x_{1})}{m(x_{0},x_{\text{in}},x_{1})}r(x_ {0},x_{\text{in}},x_{1})dx_{0}dx_{\text{in}}dx_{1}+\]

\[\underbrace{\int\log\frac{[\text{proj}_{\mathcal{M}}(r)](x_{0},x_{\text{in}}, x_{1})}{[\text{proj}_{\mathcal{M}}(r)](x_{0},x_{\text{in}},x_{1})}r(x_{0},x_{ \text{in}},x_{1})dx_{0}dx_{\text{in}}dx_{1}}_{=0}=\]

\[\underbrace{\int\log\frac{r(x_{0},x_{\text{in}},x_{1})}{[\text{proj}_{ \mathcal{M}}(r)](x_{0},x_{\text{in}},x_{1})}r(x_{0},x_{\text{in}},x_{1})dx_{0} dx_{\text{in}}dx_{1}}_{\text{KL}\left(r\|\text{proj}_{\mathcal{M}}(r)\right)}+\]

\[\int\log\frac{[\text{proj}_{\mathcal{M}}(r)](x_{0},x_{\text{in}},x_{1})}{m(x_ {0},x_{\text{in}},x_{1})}r(x_{0},x_{\text{in}},x_{1})dx_{0}dx_{\text{in}}dx_{1} =\]

\[\text{KL}\left(r\|\text{proj}_{\mathcal{M}}(r)\right)+\int\log\frac{[\text{ proj}_{\mathcal{M}}(r)](x_{0})\prod_{n=1}^{N+1}[\text{proj}_{\mathcal{M}}(r)](x_{t_{n}}|x_{t_{n-1 }})}{m(x_{0})\prod_{n=1}^{N+1}m(x_{t_{n}}|x_{t_{n-1}})}r(x_{0},x_{\text{in}},x_ {1})dx_{0}dx_{\text{in}}dx_{1}=\]

\[\text{KL}\left(r\|\text{proj}_{\mathcal{M}}(r)\right)+\text{KL}\left([\text{ proj}_{\mathcal{M}}(r)](x_{0})\|m(x_{0})\right)+\]

\[\sum_{n=1}^{N+1}\int\log\frac{[\text{proj}_{\mathcal{M}}(r)](x_{t_{n}}|x_{t_{n- 1}})}{m(x_{t_{n}}|x_{t_{n-1}})}r(x_{0},x_{\text{in}},x_{1})dx_{0}dx_{\text{in}} dx_{1}=\]

\[\text{KL}\left(r\|\text{proj}_{\mathcal{M}}(r)\right)+\text{KL}\left([\text{ proj}_{\mathcal{M}}(r)](x_{0})\|m(x_{0})\right)+\]

\[\sum_{n=1}^{N+1}\int\log\frac{[\text{proj}_{\mathcal{M}}(r)](x_{t_{n}}|x_{t_{n- 1}})}{m(x_{t_{n}}|x_{t_{n-1}})}\underbrace{r(x_{t_{n}},x_{t_{n-1}})}_{=[\text{ proj}_{\mathcal{M}}(r)](x_{t_{n}},x_{t_{n-1}})}dx_{t_{n}}dx_{t_{n-1}}=\]

\[\text{KL}\left(r\|\text{proj}_{\mathcal{M}}(r)\right)+\text{KL}\left([\text{ proj}_{\mathcal{M}}(r)](x_{0})\|m(x_{0})\right)+\]

\[\text{KL}\left(r\|\text{proj}_{\mathcal{M}}(r)\right)+\text{KL}\left([\text{ proj}_{\mathcal{M}}(r)](x_{0})\|m(x_{0})\right)+\]

\[\sum_{n=1}^{N+1}\int\log\frac{[\text{proj}_{\mathcal{M}}(r)](x_{t_{n}}|x_{t_{n- 1}})}{m(x_{t_{n}}|x_{t_{n-1}})}[\text{proj}_{\mathcal{M}}(r)](x_{0},x_{\text{in}},x_{1})dx_{0}dx_{\text{in}}dx_{1}=\]

\[\text{KL}\left(r\|\text{proj}_{\mathcal{M}}(r)\right)+\underbrace{\int\log \frac{[\text{proj}_{\mathcal{R}}](q)(x_{0})}{m(x_{0})}[\text{proj}_{\mathcal{R }}](q)(x_{0})dx_{0}}_{=\text{KL}\left((\text{proj}_{\mathcal{M}}(r)](x_{0})\|m(x_ {0})\right)}+\]

\[\int\log\frac{\prod_{n=1}^{N+1}[\text{proj}_{\mathcal{M}}(r)](x_{t_{n}}|x_{t_{n- 1}})}{\prod_{n=1}^{N+1}m(x_{t_{n}}|x_{t_{n-1}})}[\text{proj}_{\mathcal{M}}(r)](x _{0},x_{\text{in}},x_{1})dx_{0}dx_{\text{in}}dx_{1}=\]

\[\text{KL}\left(r\|\text{proj}_{\mathcal{M}}(r)\right)+\underbrace{\int\log \frac{[\text{proj}_{\mathcal{M}}(r)](x_{0},x_{\text{in}},x_{1})}{m(x_{0},x_ {\text{in}},x_{1})}[\text{proj}_{\mathcal{M}}(r)](x_{0},x_{\text{in}},x_{1}) dx_{0}dx_{\text{in}}dx_{1}}_{=\text{KL}\left((\text{proj}_{\mathcal{M}}(r)\|m)\right)}+\]

\[\text{KL}\left(r\|\text{proj}_{\mathcal{M}}(r)\right)+\text{KL}\left((\text{ proj}_{\mathcal{M}}(r)\|m)\right).\]

That concludes the proof of the first equation (26). The proof for the second equation (27) is similar.

\[\text{KL}\left(m\|r\right)=\int\log\frac{m(x_{0},x_{\text{in}},x_{1})}{r(x_{0},x _{\text{in}},x_{1})}m(x_{0},x_{\text{in}},x_{1})dx_{0}dx_{\text{in}}dx_{1}+\]\[\int\log\underbrace{\frac{\left[\text{proj}_{\mathcal{R}}(m)\right] (x_{0},x_{\text{in}},x_{1})}{\left[\text{proj}_{\mathcal{R}}(m)\right](x_{0},x_ {\text{in}},x_{1})}}_{=0}m(x_{0},x_{\text{in}},x_{1})dx_{0}dx_{\text{in}}dx_{1}=\] \[\underbrace{\int\log\frac{m(x_{0},x_{\text{in}},x_{1})}{\left[ \text{proj}_{\mathcal{R}}(m)\right](x_{0},x_{\text{in}},x_{1})}m(x_{0},x_{\text {in}},x_{1})dx_{0}dx_{\text{in}}dx_{1}}_{\text{KL}(m\|\text{proj}_{\mathcal{R}} (m))}+\] \[\int\log\frac{\left[\text{proj}_{\mathcal{R}}(m)\right](x_{0},x_{ \text{in}},x_{1})}{r(x_{0},x_{\text{in}},x_{1})}m(x_{0},x_{\text{in}},x_{1})dx _{0}dx_{\text{in}}dx_{1}=\] \[\text{KL}\left(m\|\text{proj}_{\mathcal{R}}(m)\right)+\] \[\text{KL}\left(m\|\text{proj}_{\mathcal{R}}(m)\right)+\] \[\text{KL}\left(m\|\text{proj}_{\mathcal{R}}(m)\right)+\] \[\text{KL}\left(m\|\text{proj}_{\mathcal{R}}(m)\right)+\int\log \frac{\left[\text{proj}_{\mathcal{R}}(m)\right](x_{0},x_{1})}{r(x_{0},x_{1})} [\text{proj}_{\mathcal{R}}(m)](x_{0},x_{1})dx_{0}dx_{1}=\] \[\text{KL}\left(m\|\text{proj}_{\mathcal{R}}(m)\right)+\int\log \frac{\left[\text{proj}_{\mathcal{R}}(m)\right](x_{0},x_{1})}{r(x_{0},x_{1})} [\text{proj}_{\mathcal{R}}(m)](x_{0},x_{1})dx_{0}dx_{1}=\] \[\text{KL}\left(m\|\text{proj}_{\mathcal{R}}(m)\right)+\int\log \frac{\left[\text{proj}_{\mathcal{R}}(m)\right](x_{0},x_{1})}{r(x_{0},x_{1})} [\text{proj}_{\mathcal{R}}(m)](x_{0},x_{1})dx_{0}dx_{1}=\] \[\text{KL}\left(m\|\text{proj}_{\mathcal{R}}(m)\right)+\int\log \frac{\left[\text{proj}_{\mathcal{R}}(m)\right](x_{0},x_{\text{in}},x_{1})}{r (x_{0},x_{1})}[\text{proj}_{\mathcal{R}}(m)](x_{0},x_{1})dx_{0}dx_{1}=\] \[\text{KL}\left(m\|\text{proj}_{\mathcal{R}}(m)\right)+\int\log \frac{\left[\text{proj}_{\mathcal{R}}(m)\right](x_{0},x_{\text{in}},x_{1})}{r (x_{0},x_{1})}[\text{proj}_{\mathcal{R}}(m)](x_{0},x_{1})dx_{0}dx_{\text{in}}dx _{1}=\] \[=\text{KL}\left(m\|\text{proj}_{\mathcal{R}}(m)\right)+\text{KL} \left(\text{proj}_{\mathcal{R}}(m)\|r\right)\]

That concludes the proof of the second equation (27).

**Proposition B.2**.: _Assume that we have a sequence of processes \(\{q^{l}\}_{l=0}^{\infty}\) from D-IMF procedure starting from \(q^{0}\) for which \(\text{KL}\left(q^{0}\|q^{*}\right)<\infty\). Assume that for each reciprocal and Markovian projection in a sequence \(\text{KL}\left(q^{l}\|q^{l+1}\right)<\infty\). Then \(\text{KL}\left(q^{l+1}\|q^{*}\right)\leq\text{KL}\left(q^{l}\|q^{*}\right)\) and \(\lim_{l\to\infty}\text{KL}\left(q^{l}\|q^{l+1}\right)=0\)._

Proof of Proposition b.2.: We use the same technique as was used in the proof of IMF procedure [47, Proposition 7], and for forward KL in [43]. We apply Proposition B.1 and for every \(l\) we have:

\[\text{KL}\left(q^{l}\|q^{*}\right)=\text{KL}\left(q^{l}\|q^{l+1}\right)+\text{ KL}\left(q^{l+1}\|q^{*}\right)\]

Since the KL divergence is non-negative, it follows that \(\text{KL}\left(q^{l+1}\|q^{*}\right)\leq\text{KL}\left(q^{l}\|q^{*}\right)\). Applying this proposition for each \(l\leq L\in\mathbb{N}\), we have

\[\text{KL}\left(q^{0}\|q^{*}\right)=\text{KL}\left(q^{0}\|q^{1}\right)+\text{ KL}\left(q^{1}\|q^{*}\right)=\sum_{l=0}^{L}\text{KL}\left(q^{l}\|q^{l+1} \right)+\text{KL}\left(q^{L+1}\|q^{*}\right).\]

Since KL is non-negative and \(\text{KL}\left(q^{0}\|q^{*}\right)<\infty\), we get \(\lim_{l\to\infty}\text{KL}\left(q^{l}\|q^{l+1}\right)=0\). 

Proof of Theorem 3.6.: The mild assumptions here are the assumptions of the Propositon B.2, i.e. \(\text{KL}\left(q^{l}\|q^{l+1}\right)<\infty\). To prove the current theorem, we follow the proof of [47, Theorem 8] but do the derivations for discrete stochastic processes instead of continuous. By our previous Proposition B.2 it holds that \(\text{KL}\left(q^{l}\|q^{*}\right)\leq\text{KL}\left(q^{0}\|q^{*}\right)<\infty\) for every \(l\). Hence the sequence \((q^{l})_{l=0}^{\infty}\) and its subsequences of markovian \((m^{l})_{l=1}^{\infty}=(q^{2l+1})_{l=1}^{\infty}\) and reciprocal processes \((r^{l})_{l=1}^{\infty}=(q^{2l})_{l=1}^{\infty}\) are subsets of a set \(\{q\in\mathcal{P}_{2,ac}(\mathbb{R}^{D\times(N+2)}):\text{KL}\left(q\|q^{*} \right)\leq\text{KL}\left(q^{0}\|q^{*}\right)\}\) which is compact [50, Theorem 20]. Hence, \((m_{l})_{l=1}^{\infty}\) contains a convergent subsequence \((m^{l_{k}})_{k=1}^{\infty}\to m^{*}\). In turn, the subsequence \((r^{k_{j}})_{k=1}^{\infty}\) contains a convergent subsequence \((r^{k_{j}})_{j=1}^{\infty}\to r^{*}\). Since sets of Markovian \(\mathcal{M}(N)\) and reciprocal \(\mathcal{R}(N)\) processes are closed under weak convergence, we have \(m^{*}\in\mathcal{M}(N)\) and \(r^{*}\in\mathcal{R}(N)\). From the lower semicontinuity of KL divergence in the weak topology [50, Theorem 19] and \(\lim_{l\to\infty}\text{KL}\left(q^{l}\|q^{l+1}\right)=0\) (see Proposition B.2):

\[0\leq\text{KL}\left(m^{*}\|r^{*}\right)\leq\lim_{j\to\infty}\text{KL}\left(m^{ l_{k_{j}}}\|r^{k_{j}}\right)=0.\] (28)

Thus, \(m^{*}=r^{*}\stackrel{{\text{def}}}{{=}}q^{\text{lim}}\). We know that \(q^{\text{lim}}\) has the same marginals \(p_{0}(x_{0})=q(x_{0})\) and \(p_{1}(x_{1})=q(x_{1})\) since both Markovian and reciprocal projections preserve marginals. By our Theorem 3.1 since \(q^{\text{lim}}\in\mathcal{M}(N)\cap\mathcal{R}(N)\), then \(q^{\text{lim}}(x_{0},x_{\text{in}},x_{1})=p^{T^{*}}(x_{0},x_{\text{in}},x_{1})\). Finally, \(\lim_{l\to\infty}\text{KL}\left(q^{l}(x_{0},x_{\text{in}},x_{1})\|p^{T^{*}}( x_{0},x_{\text{in}},x_{1})\right)=0\) follows using

\[\lim_{j\to\infty}\text{KL}\left(r^{k_{j}}(x_{0},x_{\text{in}},x_{1})\|p^{T^{*} }(x_{0},x_{\text{in}},x_{1})\right)=0\]

and the mononotonicity of \(\text{KL}\left(q^{l}\|q^{*}\right)\), see Proposition B.2. 

### Proofs of the Statements in SS3.4

The proofs in this subsection are the most technical as there are a lot of manipulations with matrices.

Proof of Theorem 3.7.: From (6) and (5) follows that the discrete Brownian Bridge \(p^{W^{*}}(x_{\text{in}}|x_{0},x_{1})\) has also a Gaussian distribution. The covariance of the Brownian Bridge with coefficient \(\epsilon\) at times \(s<t\)[17, Eq. 9.14] is \(\epsilon s(1-t)\). Thus, the matrix \(\epsilon K\) is a covariance matrix for all pairs of time moments \(t,t^{\prime}\in[t_{1},\dots,t_{N}]\) of the considered discrete Brownian Bridge \(p^{W^{*}}(x_{\text{in}}|x_{0},x_{1})\). The mean value \(\mathbb{E}[x_{t_{n}}|x_{0},x_{1}]\) of Brownian Bridge at time \(t_{n}\) is equal to \(t_{n}x_{1}+(1-t_{n})x_{0}\). Thus, the discrete Brownian Bridge has the following distribution: \(p^{W^{*}}(x_{\text{in}}|x_{0},x_{1})=\mathcal{N}(x_{\text{in}}|Ux_{01},\epsilon K)\).

Recall that the reciprocal projection is given by:

\[[\text{proj}_{\mathcal{R}}q](x_{\text{in}},x_{0},x_{1})=p^{W^{*}}(x_{\text{in }}|x_{0},x_{1})q(x_{0},x_{1}).\] (29)

Since it is a product of two Gaussian distributions, which itself is also a Gaussian distribution, our goal is to find the mean vector and covariance matrix of \([\text{proj}_{\mathcal{R}}q](x_{\text{in}},x_{0},x_{1})\). Further we denote \([\text{proj}_{\mathcal{R}}q](x_{\text{in}},x_{0},x_{1})\) as \(r(x_{0},x_{\text{in}},x_{1})\) for convenience.

The **mean vector** of \([\text{proj}_{\mathcal{R}}q](x_{\text{in}},x_{0},x_{1})\) for each \(t_{n}\) is given by

\[\mathbb{E}_{r(x_{t_{n}})}x_{t_{n}}=\int\mathbb{E}_{r(x_{t_{n}}|x_{0},x_{1})}[x _{t_{n}}|x_{0},x_{1}]q(x_{0},x_{1})dx_{0}dx_{1}=\]

\[\int\mathbb{E}_{p^{W^{\epsilon}}(x_{t_{n}}|x_{0},x_{1})}[x_{t_{n}}|x_{0},x_{1} ]q(x_{0},x_{1})dx_{0}dx_{1}=\int\big{[}x_{0}+t_{n}(x_{1}-x_{0})\big{]}q(x_{0},x_ {1})dx_{0}dx_{1}=\]

\[(1-t_{n})\int x_{0}q(x_{0},x_{1})dx_{0}dx_{1}+t_{n}\int x_{1}q(x_{0},x_{1})dx_{0 }dx_{1}=t_{n}\mu_{1}+(1-t_{n})\mu_{0}.\]

where \(\mu_{0}\) and \(\mu_{1}\) are the means of \(q(x_{0})\) and \(q(x_{1})\), respectively. Thus, the mean vector of \([\text{proj}_{\mathcal{R}}q](x_{\text{in}},x_{0},x_{1})\) is given by \((U\mu_{01},\mu_{0},\mu_{1})\).

Now, we are going to find the **covariance matrix**\(\Sigma_{R}\). We will first find the inverse covariance

\[\Sigma_{R}^{-1}=\begin{pmatrix}A&B\\ B^{T}&C\end{pmatrix}\]

of \([\text{proj}_{\mathcal{R}}q](x_{\text{in}},x_{0},x_{1})\). Here \(A\) has shape \(ND\times ND\) as the matrix \(K\), while the matrix \(C\) has the shape \(2D\times 2D\) as the matrix \(\Sigma\). Matrices \(A\) and \(C\) are symmetric since they are a part of the inversed symmetric matrix \(\Sigma_{R}\). We exploit the fact that the logarithm of a Gaussian distribution has the form (by **Const** we denote all terms that does not depend on \(x_{\text{in}}\) or \(x_{01}\)):

\[\log\big{(}[\text{proj}_{\mathcal{R}}q](x_{\text{in}},x_{0},x_{1})\big{)}=\]

\[\text{Const}-\frac{1}{2}((x_{\text{in}},x_{01})-(U\mu_{01},\mu_{01}))^{T} \Sigma_{R}^{-1}((x_{\text{in}},x_{01})-(U\mu_{01},\mu_{01}))=\]\[\text{Const}-\frac{1}{2}((x_{\text{in}},x_{01})-(U\mu_{01},\mu_{01}))^ {T}\begin{pmatrix}A&B\\ B^{T}&C\end{pmatrix}((x_{\text{in}},x_{01})-(U\mu_{01},\mu_{01}))=\] \[\text{Const}-\frac{1}{2}(x_{\text{in}}-U\mu_{01})^{T}A(x_{\text{ in}}-U\mu_{01})-\frac{1}{2}(x_{01}-\mu_{01})^{T}C(x_{01}-\mu_{01})-\] \[(x_{\text{in}}-U\mu_{01})^{T}B(x_{01}-\mu_{01})=\] \[\text{Const}-\frac{1}{2}x_{\text{in}}^{T}Ax_{\text{in}}+(U\mu_{0 1})^{T}Ax_{\text{in}}-\frac{1}{2}x_{01}^{T}Cx_{01}+\mu_{01}^{T}Cx_{01}-\] \[x_{\text{in}}^{T}Bx_{01}-x_{\text{in}}^{T}B\mu_{01}-(U\mu_{01})^ {T}Bx_{01}-(U\mu_{01})^{T}B\mu_{01}=\] \[\text{Const}-\frac{1}{2}x_{\text{in}}^{T}Ax_{\text{in}}+(U\mu_{ 01})^{T}Ax_{\text{in}}-\frac{1}{2}x_{01}^{T}Cx_{01}+\mu_{01}^{T}Cx_{01}-\] \[x_{\text{in}}^{T}Bx_{01}-x_{\text{in}}^{T}B\mu_{01}-(U\mu_{01})^ {T}Bx_{01}.\]

In turn, from (29) we have:

\[\log\left([\text{proj}_{R}q](x_{\text{in}},x_{0},x_{1})\right)= \log p^{W^{*}}(x_{\text{in}}|x_{0},x_{1})+\log q(x_{0},x_{1})=\] \[\text{Const}-\frac{1}{2}(x_{\text{in}}-Ux_{01})^{T}(\epsilon K)^{ -1}(x_{\text{in}}-Ux_{01})-\frac{1}{2}(x_{01}-\mu_{01})^{T}\Sigma^{-1}(x_{01} -\mu_{01})=\] \[\text{Const}-\frac{1}{2}x_{\text{in}}^{T}(\epsilon K)^{-1}x_{ \text{in}}+x_{\text{in}}^{T}(\epsilon K)^{-1}Ux_{01}-\frac{1}{2}(Ux_{01})^{T} (\epsilon K)^{-1}Ux_{01}-\] \[\frac{1}{2}x_{01}^{T}\Sigma^{-1}x_{01}+x_{01}^{T}\Sigma^{-1}\mu_ {01}-\frac{1}{2}\mu_{01}\Sigma^{-1}\mu_{01}=\] \[\text{Const}-\frac{1}{2}x_{\text{in}}^{T}\underbrace{(\epsilon K )}_{=A}x_{\text{in}}+x_{\text{in}}^{T}\underbrace{(\epsilon K)^{-1}U}_{=B}x_{ 01}-\frac{1}{2}x_{01}^{T}\underbrace{(U^{T}(\epsilon K)^{-1}U+\Sigma^{-1})}_{= C}x_{01}+x_{01}^{T}\Sigma^{-1}\mu_{01}.\]

By matching the formulas above, it follows:

\[A=(\epsilon K)^{-1},\quad B=-(\epsilon K)^{-1}U,\quad C=U^{T}(\epsilon K)^{-1 }U+\Sigma^{-1}.\] (30)

Thus, we have:

\[\Sigma_{R}^{-1}=\begin{pmatrix}A&B\\ B^{T}&C\end{pmatrix}=\begin{pmatrix}(\epsilon K)^{-1}&-(\epsilon K)^{-1}U\\ -((\epsilon K)^{-1}U)^{T}&U^{T}(\epsilon K)^{-1}U+\Sigma^{-1}\end{pmatrix}\]

By using the formula of block-wise matrix inversion [37, Section 9.1.3] :

\[\begin{pmatrix}A&B\\ B^{T}&C\end{pmatrix}^{-1}=\begin{pmatrix}A^{-1}+A^{-1}B(C-B^{T}A^{-1}B)^{-1}B^ {T}A^{-1}&-A^{-1}B(C-B^{T}A^{-1}B)^{-1}\\ -(C-B^{T}A^{-1}B)^{-1}B^{T}A^{-1}&(C-B^{T}A^{-1}B)^{-1}\end{pmatrix}.\] (31)

Applying this formula, we have:

\[(C-B^{T}A^{-1}B)^{-1}=(U^{T}(\epsilon K)^{-1}U+\Sigma^{-1}-U^{T} (\epsilon K)^{-1}(\epsilon K)(\epsilon K)^{-1}U)^{-1}=(\Sigma^{-1})^{-1}=\Sigma.\] \[A^{-1}+A^{-1}B(C-B^{T}A^{-1}B)^{-1}B^{T}A^{-1}=\] \[\epsilon K+\epsilon K(\epsilon K)^{-1}U\Sigma\Sigma^{-1}\Sigma U^{T} \epsilon K(\epsilon K)^{-1}=\epsilon K+U\Sigma U^{T}.\] \[-A^{-1}B(C-B^{T}A^{-1}B)^{-1}=\epsilon K(\epsilon K)^{-1}U\Sigma= U\Sigma.\]

Thus, we obtain the desired result:

\[\Sigma_{R}=\begin{pmatrix}\epsilon K+U\Sigma U^{T}&U\Sigma\\ (U\Sigma)^{T}&\Sigma\end{pmatrix}.\]

Proof of Theorem 3.8.: Part 1. Since from the assumptions of the theorem \(q(x_{\text{in}},x_{0},x_{1})\) has Gaussian distribution, it follows that joint distribution of two time moments \(q(x_{t_{n}},x_{t_{n-1}})\) is also Gaussian and is given by:

\[q(x_{t_{n}},x_{t_{n-1}})=\mathcal{N}(\begin{pmatrix}x_{t_{n}}\\ x_{t_{n-1}}\end{pmatrix}|\begin{pmatrix}\mu_{t_{n}}\\ \mu_{t_{n-1}}\end{pmatrix}\begin{pmatrix}(\widetilde{\Sigma}_{R})_{t_{n},t_{n}}& (\widetilde{\Sigma}_{R})_{t_{n},t_{n-1}}\\ (\widetilde{\Sigma}_{R})_{t_{n-1},t_{n}}&(\widetilde{\Sigma}_{R})_{t_{n-1},t_{n-1}} \end{pmatrix})\] (32)Recall that here \((\widetilde{\Sigma}_{R})_{t_{i},t_{j}}\) represents submatrix of \(\widetilde{\Sigma}_{R}\) with covariance of \(x_{t_{i}}\) and \(x_{t_{j}}\). Hence, the conditional distributions are given by [37, Sec 8.1.3]:

\[q(x_{t_{n}}|x_{t_{n-1}})=\mathcal{N}(x_{t_{n}}|\widehat{\mu}_{t_{n}}(x_{t_{n-1 }}),\widehat{\Sigma}_{t_{n}}),\]

\[\widehat{\mu}_{t_{n}}(x_{t_{n-1}})\stackrel{{\text{def}}}{{=}}\mu_ {t_{n}}+(\widetilde{\Sigma}_{R})_{t_{n},t_{n-1}}((\widetilde{\Sigma}_{R})_{t_{ n-1},t_{n-1}})^{-1}(x_{t_{n-1}}-\mu_{t_{n-1}}),\] (33)

\[\widehat{\Sigma}_{t_{n}}\stackrel{{\text{def}}}{{=}}( \widetilde{\Sigma}_{R})_{t_{n},t_{n}}-(\widetilde{\Sigma}_{R})_{t_{n},t_{n-1}} ((\widetilde{\Sigma}_{R})_{t_{n-1},t_{n-1}})^{-1}((\widetilde{\Sigma}_{R})_{t_ {n},t_{n-1}})^{T}.\]

That concludes the first part of our proof about the whole distribution \([\text{proj}_{\mathcal{M}}q](x_{0},x_{\text{in}},x_{1})\) of Markovian projection.

Part 2. Next, we find the distribution of \([\text{proj}_{\mathcal{M}}q](x_{0},x_{1})\), but before we proceed, we introduce new notation to improve readability:

\[q_{\mathcal{M}}(x_{0},x_{\text{in}},x_{1})\stackrel{{\text{def}} }{{=}}[\text{proj}_{\mathcal{M}}q](x_{0},x_{\text{in}},x_{1}).\] (34)

Since the process \(q_{\mathcal{M}}(x_{0},x_{\text{in}},x_{1})\) is Gaussian, all its joint and conditional distributions are also Gaussian. Moreover, we know that from the definition of the Markovian projection (10) follows that it preserve all marginal distributions, i.e. \(q_{\mathcal{M}}(x_{t_{n}})=q(x_{t_{n}})\), hence we can already write that \(q_{\mathcal{M}}(x_{0},x_{1})\) is given by:

\[q_{\mathcal{M}}(x_{0},x_{1})=\mathcal{N}(\binom{x_{0}}{x_{1}}]\binom{\mu_{0}}{ \mu_{1}},\binom{\Sigma_{0}}{(\Sigma_{01})^{T}}\ \ \Sigma_{1}\end{pmatrix},\] (35)

where \(\mu_{0}\) and \(\mu_{1}\) are the means of \(q(x_{0})\) and \(q(x_{1})\), while \(\Sigma_{0}\) and \(\Sigma_{1}\) are the covariance matricies of \(q(x_{0})\) and \(q(x_{1})\). Thus, only \(\Sigma_{01}\) is unknown. Again, by using the formula for the conditional distributions [37, Sec 8.1.3] we have that:

\[q_{\mathcal{M}}(x_{1}|x_{0})=\mathcal{N}(x_{1}|\widetilde{\mu}_{ 1}(x_{0}),\widetilde{\Sigma}_{1}(x_{0})),\] \[\widetilde{\mu}_{1}(x_{0})\stackrel{{\text{def}}}{{=}} \mu_{1}+\underbrace{\Sigma_{01}^{T}\Sigma_{0}^{-1}}_{\stackrel{{ \text{def}}}{{=}}G}\] \[\widehat{\Sigma}_{1}\stackrel{{\text{def}}}{{=}} \Sigma_{1}-\Sigma_{01}^{T}\Sigma_{0}^{-1}\Sigma_{01}.\]

Since the mean \(\widetilde{\mu}_{1}(x_{0})\) of the conditional distribution is a affine map of \(x_{0}\) with the matrix \(G\) we can derive:

\[\Sigma_{01}^{T}=G\Sigma_{0}.\]

Thus, we need to find the expression for \(G\), by considering the expression for \(\widetilde{\mu}_{1}(x_{0})\). To derive the expression of the mean \(\widetilde{\mu}_{1}(x_{0})\) of \(q_{\mathcal{M}}(x_{1}|x_{0})\) we consider the sequence \(q_{\mathcal{M}}(x_{t_{n}}|x_{0})\) for \(n\in[1,\ldots,N+1]\). We already know the expression for \(n=1\) which is given by \([\text{proj}_{\mathcal{M}}q](x_{t_{1}}|x_{0})=q(x_{t_{1}}|x_{0})\) in the first part of the proof. For other \(n\), we use the following expression:

\[q_{\mathcal{M}}(x_{t_{n}}|x_{0})=\int q(x_{t_{n}}|x_{t_{n-1}})q_{\mathcal{M}}( x_{t_{n-1}}|x_{0})dx_{t_{n-1}}.\] (36)

Since \(q_{\mathcal{M}}(x_{t_{n}}|x_{0})\) is Gaussian we denote \(q_{\mathcal{M}}(x_{t_{n}}|x_{0})=\mathcal{N}(x_{t_{n}}|\widetilde{\mu}_{t_{n}} (x_{0}),\widetilde{\Sigma}_{t_{n}})\). We derive the mean \(\widetilde{\mu}_{t_{n}}(x_{0})\) by using the properties of conditional expectations as follows:

\[\widetilde{\mu}_{t_{n}}(x_{0})=\mathbb{E}_{q_{\mathcal{M}}(x_{t_{n}}|x_{0})}[x _{t_{n}}]=\int\underbrace{\Big{(}\mathbb{E}_{q(x_{t_{n}}|x_{t_{n-1}})}[x_{t_{n} }]\Big{)}}_{\widetilde{\mu}_{t_{n}}(x_{t_{n-1}})}q_{\mathcal{M}}(x_{t_{n-1}}|x _{0})dx_{t_{n-1}}=\]

\[\int\Big{(}\mu_{t_{n}}+(\widetilde{\Sigma}_{R})_{t_{n},t_{n-1}}((\widetilde{ \Sigma}_{R})_{t_{n-1},t_{n-1}})^{-1}(x_{t_{n-1}}-\mu_{t_{n-1}})\Big{)}q_{ \mathcal{M}}(x_{t_{n-1}}|x_{0})dx_{t_{n-1}}=\]

\[\mu_{t_{n}}+(\widetilde{\Sigma}_{R})_{t_{n},t_{n-1}}((\widetilde{\Sigma}_{R})_{t_ {n-1},t_{n-1}})^{-1}\Big{(}\big{(}\underbrace{\mathbb{E}_{q_{\mathcal{M}}(x_{t_{n- 1}}|x_{0})}x_{t_{n-1}}}_{=\widetilde{\mu}(x_{t_{n-1}})(x_{0})}\big{)}-\mu_{t_{n-1 }}\Big{)}=\]

\[\mu_{t_{n}}+(\widetilde{\Sigma}_{R})_{t_{n},t_{n-1}}((\widetilde{\Sigma}_{R})_{t_ {n-1},t_{n-1}})^{-1}\Big{(}\widetilde{\mu}_{t_{n-1}}(x_{0})-\mu_{t_{n-1}})= \widehat{\mu}_{t_{n}}(\widetilde{\mu}_{t_{n-1}}(x_{0})).\] (37)Note that in the line (37), we use equation (33) for \(\widehat{\mu}_{t_{n}}(x_{t_{n-1}})\) with \(x_{t_{n-1}}=\widetilde{\mu}_{t_{n-1}}(x_{0})\) to simplify the expression. Since \(\widetilde{\mu}_{t_{n}}(x_{0})=\widehat{\mu}_{t_{n}}(\widetilde{\mu}_{t_{n-1}} (x_{0}))\) we can derive \(\widetilde{\mu}_{1}(x_{0})\) recursively as follows:

\[\widetilde{\mu}_{1}(x_{0})=\widetilde{\mu}_{t_{N+1}}(x_{0})=\widehat{\mu}_{t_ {N+1}}(\widetilde{\mu}_{t_{N}}(x_{0}))=\widehat{\mu}_{t_{N+1}}(\widehat{\mu}_ {t_{N}}(\dots\widehat{\mu}_{0}(x_{0})\dots)),\]

where each \(\widehat{\mu}_{t_{n}}(x_{t_{n-1}})\) is a affine map given by (33) with the matrix given by

\[(\widetilde{\Sigma}_{R})_{t_{n},t_{n-1}}((\widetilde{\Sigma}_{R})_{t_{n-1},t _{n-1}})^{-1}.\]

Hence, \(\widetilde{\mu}_{1}(x_{0})\) is a composition of affine maps, and its matrix is given by the product of matrices \(\widetilde{\mu}_{t_{n}}(x_{t_{n-1}})\) as follows:

\[G=\Big{[}\prod_{n=1}^{N+1}(\widetilde{\Sigma}_{R})_{t_{n},t_{n-1}}(( \widetilde{\Sigma}_{R})_{t_{n-1},t_{n-1}})^{-1}\Big{]},\]

in turn \(\Sigma_{01}^{T}\) is given by:

\[\Sigma_{01}^{T}=G\Sigma_{0}=\Big{[}\prod_{n=1}^{N+1}(\widetilde{\Sigma}_{R})_{ t_{n},t_{n-1}}((\widetilde{\Sigma}_{R})_{t_{n-1},t_{n-1}})^{-1}\Big{]}\Sigma_{0}.\]

This concludes the proof.

## Appendix C Additional Experiments

### Illustrative 2D Example

Here we consider the SB problem with \(p_{0}\) as a 2D Gaussian distribution and \(p_{1}\) as the Swiss-roll distribution. We use independent \(q^{0}(x_{0},x_{1})=p_{0}(x_{0})p_{1}(x_{1})\), \(N=3\) (\(t_{n}=\frac{n}{N+1}\)) and \(K=20\) outer iterations. We run our ASBM algorithm with different values of parameter \(\epsilon\) and present our results in Figure 8. In all the cases, we observe the convergence to the target distribution. Overall, the trajectories are similar to the Brownian bridge and the closeness of start and endpoints is preserved. In Figure 9, we show the evolution of trajectories for different D-IMF iterations, which become more straight when number of iterations increase.

### Benchmark

We use the SB mixtures benchmark proposed by [13, SS4] to experimentally verify that our ASBM algorithm is indeed able to solve the Schrodinger Bridge between \(p_{0}\) and \(p_{1}\). The benchmark provides continuous probability distribution pairs \(p_{0},p_{1}\) for dimensions \(D\in\{2,16,64,128\}\) with the known static SB solution \(p^{T^{*}}(x_{0},x_{1})\) for parameters \(\epsilon\in\{0.1,1.10\}\). To evaluate the quality of our recovered SB solution, we use \(\mathsf{cB}\mathbb{W}_{2}^{2}\)-UVP metric as suggested by the authors [13, SS5] and provide results in Table 1. Additionally, we study how our approach learns the target distribution

Figure 8: The final process \(q_{\theta}\) learned with ASBM **(ours)** in _Gaussian\(\operatorname{\rightarrow}\)Swiss roll_ example.

\(p_{1}\) in Table 2. In all the cases, we run our ASBM algorithm starting from the independent coupling between \(p_{0}\) and \(p_{1}\).

As the baselines, we consider other neural bridge matching methods [49, 47]. The first one (SF\({}^{2}\)M-Sink) is based on minibatch OT approximations, while the latter implements continuous IMF (DSBM). Additionally, we include the results of the best algorithm (for each setup) from the benchmark [13].

As shown in the Table 1, our algorithm demonstrates superior performance on \(\epsilon=10\), superior performance or comparable performance on \(\epsilon=1\), slightly worse performance w.r.t. SF\({}^{2}\)M-Sink [49] and superior performance w.r.t. DSBM [47] on \(\epsilon=0.1\). Also, from Table 2 one may note that ASBM fits target distribution better then other Bridge Matching SB algorithms.

**Remark.** There exist recent light SB algorithms [24, 11] which do not use neural parameterization and rely on the Gaussian mixtures instead. However, these methods have very strong inductive bias towards the benchmark as it is also constructed using Gaussian mixtures. Therefore, we exclude them from comparison, see the comments of the authors in [24, SS5.2] and [11, SS5.2]

### Colored MNIST

Here we test ASBM (ours, NFE=4) and DSBM (NFE=100) algorithms starting from mini-batch OT coupling [49] on transfer between colorized MNIST digits of classes "2" and "3" with \(\epsilon\in\{1,10\}\). We learn ASBM and DSBM on _train_ set of digits and show the translated _test_ images in Figures 10 and 11 along with calcualted _test_ FID in Table 3.

For \(\epsilon=1\) the color stays almost exactly the same through translation and there are minor shape diversity for both ASBM and DSBM, see Figures (10, 10, 11, 11). In turn, \(\epsilon=10\) introduces more stochastistity to the solutions, and expectedly the color and shape vary a bit but overall stays similar to input data for both ASBM and DSBM, see Figures (10, 10, 11, 11). As one can see from Table 3, ASBM has better FID on both \(\epsilon\in\{1,10\}\). However DSBM experiences a notable

\begin{table}
\begin{tabular}{c c c c c c c c c c c c c c} \hline \hline  & & \multicolumn{4}{c}{\(\epsilon=0.1\)} & \multicolumn{4}{c}{\(\epsilon=1\)} & \multicolumn{4}{c}{\(\epsilon=10\)} \\  & Algorithm Type & \(D\!=\!2\) & \(D\!=\!16\) & \(D\!=\!64\) & \(D\!=\!128\) & \(D\!=\!2\) & \(D\!=\!16\) & \(D\!=\!64\) & \(D\!=\!128\) & \(D\!=\!2\) & \(D\!=\!16\) & \(D\!=\!64\) & \(D\!=\!128\) \\ \hline Best algorithm on benchmark\({}^{\dagger}\) & Varies & \(1.94\) & \(13.67\) & \(11.74\) & \(11.4\) & \(1.04\) & \(9.08\) & \(18.05\) & \(15.23\) & \(1.40\) & \(1.27\) & \(2.36\) & \(\mathbf{1.31}\) \\ \hline DSBM & \(1.21\) & \(4.61\) & \(9.81\) & \(19.8\) & \(0.68\) & \(\mathbf{0.63}\) & \(\mathbf{5}\) & \(\mathbf{29}.5\) & \(0.23\) & \(5.45\) & \(68.9\) & \(362\) \\ SF\({}^{2}\)M-Sink\({}^{\dagger}\) & Bridge matching & \(\mathbf{0.54}\) & \(\mathbf{3}\) & \(\mathbf{7}\) & \(\mathbf{9}\) & \(\mathbf{10}\) & \(\mathbf{0}\) & \(2.1\) & \(9\) & \(23\) & \(0.31\) & \(4.9\) & \(319\) & \(819\) \\ ASBM (**ours**) & \(0.89\) & \(8.2\) & \(13.5\) & \(53.7\) & \(\mathbf{0.10}\) & \(1.6\) & \(\mathbf{5}\) & \(\mathbf{10}\) & \(\mathbf{5}\) & \(\mathbf{10}\) & \(\mathbf{0}\) & \(\mathbf{10}\) & \(\mathbf{0}\) & \(\mathbf{4}\) & \(\mathbf{10}\) & \(\mathbf{4}\) \\ \hline \hline \end{tabular}
\end{table}
Table 1: Comparisons of \(\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\texttexttexttexttexttexttexttexttext     }}}}}}}}}}}}}}\)-UV \(\downarrow\) (%) between the static SB solution \(p^{T}(x_{0},x_{1})\) and the learned \(q_{\theta}(x_{0},x_{1})\) on the SB benchmark. The best metric over _bridge Matching algorithm_ is **bolded**. Results marked with \(\dagger\) are taken from [11].

\begin{table}
\begin{tabular}{c c c c c c c c c c c c c c} \hline \hline  & & \multicolumn{4}{c}{\(\epsilon=0.1\)} & \multicolumn{4}{c}{\(\epsilon=1\)} & \multicolumn{4}{c}{\(\epsilon=10\)} \\  & Algorithm Type & \(D\!=\!2\) & \(D\!=\!16\) & \(D\!=\!64\) & \(D\!=\!128\) & \(D\!=\!2\) & \(D\!=\!16\) & \(D\!=\!64\) & \(D\!=\!128\) & \(D\!=\!2\) & \(D\!=\!16\) & \(D\!=\!64\) & \(D\!=\!128\) \\ \hline Best algorithm on benchmark\({}^{\dagger}\) & Varies & \(1.94\) & \(13.67\) & \(11.74\) & \(11.4\) & \(1.04\) & \(9.08\) & \(18.05\) & \(15.23\) & \(1.40\) & \(1.27\) & \(2.36\) & \(\mathbf{1.31}\) \\ \hline DSBM & \(1.21\) & \(4.61\) & \(9.81\) & \(19.8\) & \(0.68\) & \(\mathbf{0.63}\) & \(\mathbf{5}\) & \(\mathbf{29}.5\) & \(0.23\) & \(5.45\) & \(68.9\) & \(362\) \\ SF\({}^{2}\)M-Sink\({}^{\dagger}\) & Bridge matching & \(\mathbf{0.54}\) & \(\mathbf{3}\) & \(\mathbf{7}\) & \(\mathbf{9}\) & \(\mathbf{10}\) & \(\mathbf{0}\) & \(2.1\) & \(9\) & \(23\) & \(0.31\) & \(4.9\) & \(319\) & \(819\) \\ ASBM (**ours**) & \(0.89\) & \(8.2\) & \(13.5\) & \(53.7\) & \(\mathbf{0.10}\) & \(1.6\) & \(\mathbf{5}\) & \(\mathbf{8}\) & \(\mathbf{10}\) & \(\mathbf{5}\) & \(\mathbf{0}\) & \(\mathbf{10}\) & \(\mathbf{0}\) & \(\mathbf{10}\) & \(\mathbf{0}\) & \(\mathbf{4}\) & \(\mathbf{10}\) & \(\mathbf{4}\) \\ \hline \hline \end{tabular}
\end{table}
Table 1: Comparisons of \(\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\texttexttexttexttexttexttexttexttexttexttexttexttexttexttexttexttexttexttexttexttexttext {\texttexttexttexttexttext@@@textincrease in FID with \(\epsilon=10\). We conjecture that this is due to the FID unstability w.r.t. slightly noisy images which may appear in DSBM due to the neccesity to integrate noisy trajectories (for large \(\epsilon\)).

## Appendix D Experimental Details

### Details of DDGAN Implementation for Learning Markovian Projection

Below, we discuss the parametrization of the discriminator and generator in detail. In general we follow [53], but we change their DDPM diffusion inner process on the Brownian bridge process.

**Parametrization and objective for the discriminator.** As in the DD-GAN paper [53] we use a time-conditional discriminator \(D_{\xi}(x_{t_{n}},x_{t_{n-1}},t_{n-1})\): \(\mathbb{R}^{D}\times\mathbb{R}^{D}\times[0,1]\rightarrow[0,1]\). For each time moment \(t\) and object \(x_{t_{n-1}}\), the role of this discriminator is to check whether the sample \(x_{t_{n}}\) is from the distribution \(q(x_{t_{n}}|x_{t_{n-1}})\). As well as in the DD-GAN paper [53], we train this discriminator by optimizing the following objective:

\[\min_{\xi}\sum_{n=1}^{N+1}\mathbb{E}_{q(x_{t_{n-1}})}[\mathbb{E}_ {q(x_{t_{n}}|x_{t_{n-1}})}[-\log D_{\xi}(x_{t},x_{t_{n-1}},t_{n-1})]\] (38) \[+\mathbb{E}_{q(x_{t_{n}}|x_{t_{n-1}})}[-\log\bigl{(}1-D_{\xi}(x_{ t},x_{t_{n-1}},t_{n-1})\bigr{)}]]\]

Here, the samples from \(q(x_{t_{n}}|x_{t_{n-1}})\) play the role of true samples, while the samples obtained from the parametrized distribution \(q_{\theta}(x_{t_{n}}|x_{t_{n-1}})\) play role of fake samples in terms of original GANs. To estimate the first expectation \(\mathbb{E}_{q(x_{t_{n-1}})}\mathbb{E}_{q(x_{t_{n}}|x_{t_{n-1}})}=\mathbb{E}_{q( x_{t_{n}},x_{t_{n-1}})}\) one should sample from \(q(x_{t_{n}},x_{t_{n-1}})\). To sample a pair \((x_{t_{n}},x_{t_{n-1}})\sim q(x_{t_{n}},x_{t_{n-1}})\), we use the properties (5) and (6) of

Figure 11: Samples from ASBM (**ours**) and DSBM learned on Colored MNIST _3\(\rightarrow\)2_ (\(32\times 32\)) translation for \(\epsilon\in\{1,10\}\).

\begin{table}
\begin{tabular}{|c|c|c|c|} \hline Model & \(\epsilon\) & FID (\(2\to 3\)) & FID (\(3\to 2\)) \\ \hline ASBM (**ours**) & 1 & 2.7 & 2.8 \\ \hline DSBM & 1 & 6.2 & 5.3 \\ \hline ASBM (**ours**) & 10 & 4.3 & 4.53 \\ \hline DSBM & 10 & 58.7 & 59.9 \\ \hline \end{tabular}
\end{table}
Table 3: C-MNIST FID \(\downarrow\) values for ASBM and DSBM with \(\epsilon\in\{1,10\}\)the reciprocal process \(q\):

\[q(x_{t_{n}},x_{t_{n-1}})=\int p^{W^{\epsilon}}(x_{t_{n}}|x_{t_{n-1}},x_{1})p^{W^{ \epsilon}}(x_{t_{n-1}}|x_{0},x_{1})q(x_{1},x_{0})dx_{1}dx_{0}.\]

Sampling from \(q(x_{t_{n-1}})q_{\theta}(x_{t_{n}}|x_{t_{n-1}})\) for estimation of second expectation is given in detail below.

**Parametrization and objective for the generator.** We follow the same setup as the authors of DD-GAN [53] and parametrize \(q_{\theta}(x_{t_{n}}|x_{t_{n-1}})\) implicitly through the generator \(G_{\theta}(x_{t_{n-1}},z,t):\mathbb{R}^{D}\times\mathbb{R}^{Z}\times[0,1] \rightarrow\mathbb{R}^{D}\) as follows:

\[q_{\theta}(x_{t_{n}}|x_{t_{n-1}})\stackrel{{\text{def}}}{{=}} \int_{\mathbb{R}^{D}}q_{\theta}(x_{1}|x_{t_{n-1}})p^{W^{\epsilon}}(x_{t_{n}}|x _{t_{n-1}},x_{1})dx_{1}=\]

\[\int_{\mathbb{R}^{Z}}p^{W^{\epsilon}}(x_{t_{n}}|x_{t_{n-1}},x_{1}=G_{\theta}(x _{t_{n-1}},z,t))p_{z}(z)dz,\]

where \(q_{\theta}(x_{1}|x_{t_{n-1}})\) should match \(q(x_{1}|x_{t_{n-1}})\) and \(p_{z}(z)\) is the auxiliary probability distribution for the generator \(G_{\theta}\) to model samples from \(q_{\theta}(x_{1}|x_{t_{n-1}})\). Thus, for a given \(x_{t_{n-1}}\) sample \(x_{t_{n}}\sim q_{\theta}(x_{t_{n}}|x_{t_{n-1}})\) is obtained by first sampling \(x_{1}\) from the generator \(G_{\theta}\) and then using sampling from the Brownian bridge \(p^{W^{\epsilon}}(x_{t_{n}}|x_{t_{n-1}},x_{1})\). While in the DD-GAN, the authors use the intermediate time distribution \(q(x_{\text{in}}|x_{0},x_{1})\) from DDPM [15] and it is the main difference between our Markovian projection and one which the authors of DD-GAN used. As in the non-saturation GANs [10], we train the generator by optimizing the following objective:

\[\max_{\theta}\sum_{n=1}^{N+1}\mathbb{E}_{q(x_{t_{n-1}})}\mathbb{E}_{q_{\theta }(x_{t_{n}}|x_{t_{n-1}})}[\log\bigl{(}D_{\phi}(x_{t},x_{t_{n-1}},t_{n-1}) \bigr{)}].\]

### Details of D-IMF Implementation

**General description of the ASBM algorithm.** D-IMF algorithm is parametrized by the number \(K\) of outer D-IMF iterations, number of inner D-IMF iterations (number of generator gradient optimization steps inside one IMF iteration), ASBM number of inner steps \(N\) and starting coupling \(q^{0}(x_{0},x_{1})\) used in the initial reciprocal process \(q^{0}(x_{0},x_{\text{in}},x_{1})=p^{W^{\epsilon}}(x_{\text{in}}|x_{0},x_{1})q ^{0}(x_{0},x_{1})\). Our ASBM Algorithm 1 for D-IMF procedure is analog of DSBM [47, Algorithm 1] for IMF procedure.

```
0:number of intermediate steps \(N\);  initial process \(q^{0}(x_{0},x_{t_{1}},\dots,x_{t_{N}},x_{1})\) accessible by samples;  number of outer iteration \(K\in\mathbb{N}\);  forward transitional density network \(\{q_{\theta}(x_{t_{n}}|x_{t_{n-1}})\}_{n=1}^{N+1}\);  backward transitional density network \(\{q_{\eta}(x_{t_{n-1}|x_{t_{n}}})\}_{n=1}^{N+1}\); Output:\(p_{0}(x_{0})\prod_{n=1}^{N+1}q_{\theta}(x_{t_{n}}|x_{t_{n-1}})\approx p_{1}(x_{1}) \prod_{n=1}^{N+1}q_{\eta}(x_{t_{n-1}}|x_{t_{n}})\approx p^{T^{\epsilon}}(x_{0 },x_{\text{in}},x_{1})\). for\(k=0\)to\(K-1\)do  Learn \(\{q_{\theta}(x_{t_{n}}|x_{t_{n-1}})\}_{n=1}^{N+1}\) using 15 with \(q^{4k}\);  Let \(q^{4k+1}\) be given by \(p_{0}(x_{0})\prod_{n=1}^{N+1}q_{\theta}(x_{t_{n}}|x_{t_{n-1}})\);  Let \(q^{4k+2}\) be given by \(p^{W^{\epsilon}}(x_{\text{in}}|x_{0},x_{1})q_{\theta}(x_{0},x_{1})\);  Learn \(\{q_{\eta}(x_{t_{n-1}}|x_{t_{n}})\}_{n=1}^{N+1}\) using 16 with \(q^{4k+2}\);  Let \(q^{4k+3}\) be given by \(p_{1}(x_{1})\prod_{n=1}^{N+1}q_{\eta}(x_{t_{n-1}}|x_{t_{n}})\);  Let \(q^{4k+4}\) be given by \(p^{W^{\epsilon}}(x_{\text{in}}|x_{0},x_{1})q_{\eta}(x_{0},x_{1})\); ```

**Algorithm 1**Adversarial SB matching (ASBM).

We do not reinitialize neural networks during the ASBM algorithm.

**Special pretraining on the \(0\)-th outer iteration.** While, in general, Algorithm 1 implements our scheme, in our experiments, we slightly modify the initial outer iteration based on purely empirical reasons. We train both forward and backward models \(\{q_{\theta}(x_{t_{n}}|x_{t_{n-1}})\}_{n=1}^{N+1}\) and \(\{q_{\eta}(x_{t_{n-1}|x_{t_{n}}})\}_{n=1}^{N+1}\) with \(q^{0}\) and the let \(q^{1}\) be \(p_{0}(x_{0})\prod_{n=1}^{N+1}q_{\theta}(x_{t_{n}}|x_{t_{n-1}})\). We use more gradient setups on this iteration than on the further outer iterations. We do that to "pretrain" both processes \(q_{\theta}\) and \(q_{\eta}\) to model \(p_{1}\) and \(p_{0}\) respectively. Then we proceed to other iterations as described in Algorithm 1.

### Hyperparameters of ASBM

For all the experiments, Discrete Markovian Projection is conducted using the DD-GAN code [53]:

https://github.com/NVlabs/denoising-diffusion-gan

The only thing that we modify is the replacement of the DDPM [15] posterior sampling for generator with our Brownian Bridge posterior sampling, see Appendix D.1. In all the experiments we use a uniform time discretization, i.e., for the number of inner times points \(N\), \(t_{n}=\frac{n}{N+1}\) for \(n\in[0,N+1]\).

In Toy 2D (Appendix C.1) and SB Benchmark (Appendix C.2) experiments, both generator and discriminator are parametrized by MLPs with inner layer widths \([256,256,256]\), LeakyReLU activations and \(2\)-dimensional time embeddings using torch.nn.Embeddings. In CelebA (SS4.2) and Colored MNIST (Appendix C.3) experiments, generator is parametrized by U-Net [42] and discriminator by a ResNet-like architectures with addition of positional time encoding as in [53]. Neural networks are optimized with the Adam optimizer [22] and apply the Exponential Moving Averaging (EMA) on generator's weights. At the start of a new D-IMF iteration, both the generator, generator (EMA), discriminator and optimizers are initialized using checkpoints from the end of the previous D-IMF iteration. Inside each D-IMF iteration (except the initial one), EMA generator weights are used for sampling from previous Discrete Markovian Projections. Starting coupling \(q^{0}(x_{0},x_{1})\) may be either Ind, i.e. \(q^{0}(x_{0},x_{1})=p_{0}(x_{0})p_{1}(x_{1})\), or Mini Batch Optimal Transport coupling (MB), i.e. discrete Optimal Transport solved on mini-batch samples [49].

**Other details & pre-processing.** Test FID is calculated using pytorch-fid package. Working with CelabA dataset [33], we use all 84434 male and 118165 female samples (\(90\%\) train, \(10\%\) test of each class). Each sample is resized to \(128\times 128\) and normalized by \(0.5\) mean and \(0.5\) std. Generator and discriminator are the same as for CelebA-HQ in DDBGAN [53] (42M Generator parameters and 27M Discriminator parameters). Working with Colorized MNIST [12], we pick digits of classes "2" and "3" (we use the default MNIST _train/test_ split), resize them to \(32\times 32\) and normalize by \(0.5\) mean and \(0.5\) std. We use the same generator and discriminator as DDGAN uses in CIFAR10 [53].

**Computational time.** The most time challenging experiment on CelebA runs for approximately \(7\) days on \(1\) GPUs A100. Experiment with Colored MNIST takes less then \(2\) days of training on GPU A100. Toy2D and Schrodinger Bridge benchmark experiments take several hours on GPU A100.

### Details of DSBM Baseline

DSBM [47] implementation is taken from the official code:

https://github.com/yuyang-shi/dsbm-pytorch

For CelebA experiment all the hyperparameters, except for 200k training iterations for the first IMF iteration (Bridge Matching **pretrain**, Appx I.3 [47]) and number of overall IMF iterations (that is taken the same as for corresponding ASBM experiment, see Table 4), were taken from [47]. As a neural network time conditional U-Net model (38M parameters) was used. Hyperparameters and neural network for Colored MNIST experiment were taken from MNIST \(\leftrightarrow\) E-MNIST experiment [47, SS6]. Starting coupling is exactly the same as for ASBM in corresponding experiments (Table 4).

\begin{table}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|} \hline Experiment & \begin{tabular}{c} Start coupling \\ \(q^{0}(x_{0},x_{1})\) \\ \end{tabular} & \begin{tabular}{c} D-IMF \\ outer iters \\ \end{tabular} & \begin{tabular}{c} D-IMF=0 \\ grad updates \\ \end{tabular} & \begin{tabular}{c} D-IMF \\ grad updates \\ \end{tabular} & \(N\) & Batch Size & \begin{tabular}{c} \(D/G\) opt \\ ratio \\ \end{tabular} & \begin{tabular}{c} EMA \\ decay \\ \end{tabular} & \begin{tabular}{c} Lr \(G\) \\ \end{tabular} & 
\begin{tabular}{c} Lr \(D\) \\ \end{tabular} \\ \hline
2D Toy & Ind & 20 & 400000 & 40000 & 3 & 512 & 1:1 & 0.999 & 1e-4 & 1e-4 \\ \hline SB Bench & Ind & 2 & 133000 & 67000 & 31 & 128 & 3:1 & 0.999 & 1e-4 & 1e-4 \\ \hline C-MNIST & MB & 3 & 100000 & 50000 & 3 & 64 & 1:1 & 0.999 & 1.25e-4 & 1.6e-4 \\ \hline CelebA & MB & 5 & 1000000 & 40000 & 3 & 32 & 1:1 & 0.9999 & 1.25e-4 & 1.6e-4 \\ \hline \end{tabular}
\end{table}
Table 4: Hyperparameters for experiments. \(D\) stands for Discriminator and \(G\) stands for Generator. Ratio of Discriminator optimization steps w.r.t. Generator optimization steps is denoted by \(D\)/\(G\) opt ratio. Lr stands for learning rate.

Additional results on CelebA

### Extended Evaluation using Other Metrics

**FID for _female\(\rightarrow\)male_**. We evaluate the backward model (_female\(\rightarrow\)male_) trained for unpaired CelebA (128\(\times\)128) image-to-image translation (SS4.2) and present the test FID in Table 5.

**CMMD**. To strengthen the unpaired CelebA (128\(\times\)128) _male\(\rightarrow\)female_ image-to-image translation (SS4.2) experimental results, we add CMMD [19] metric. CMMD is a recent analogue of the FID that enjoys unbiased estimation and rich CLIP [40] embeddings. We estimate CMMD on CelebA for the same DSBM and ASBM models as for the FID calculation (SS7) using all available _female_ test samples and present results in Table 6. It can be seen that the CMMD values correlate with the FID values.

**Training with different NFE**. In the unpaired CelebA (128\(\times\)128) _male\(\rightarrow\)female_ image-to-image translation (SS 4.2), number of inner steps \(N=3\) is considered. However, it is possible to train the model with different values of \(N\), which correspond to the model NFE minus one. For completeness, we provide experimental results with training and evaluation at \(N=1\) and \(N=7\) (NFE\(=2\) and NFE\(=8\)). Here all training hyperparameters are the same as for \(N=3\), see Appendix D. Samples and test FID are shown in Figure 12.

**Inference with different NFE**. Although in practice models are trained with a fixed NFE (see Appendix D), it is possible to use different NFE at the inference stage by exploiting the continuity of the time-conditional module, see Algorithm 2. We take the model for _male\(\rightarrow\)female_ trained on NFE\(=3\) with \(\epsilon=1\) and evaluate it with different NFE \(\in\{1,2,3,4,8,16,32\}\), see the results in Figure 13, and do quantitative evaluation using FID and MSE cost (MSE between inputs and outputs) in Table 7. As can be seen, the MSE cost increases with NFE and the FID is optimal at NFE=4.

\begin{table}
\begin{tabular}{|c|c|c|} \hline Model & \(\epsilon=1\) & \(\epsilon=10\) \\ \hline DSBM & 0.365 & 1.140 \\ \hline ASBM (ours) & 0.216 & 0.231 \\ \hline \end{tabular}
\end{table}
Table 6: CMMD\(\downarrow\)[19] metric for unpaired CelebA (128\(\times\)128) _male\(\rightarrow\)female_ image-to-image translation estimated on _female_ test set.

Figure 12: Unpaired CelebA (128\(\times\)128) _male\(\rightarrow\)female_ image-to-image translation samples and FID\(\downarrow\) values for ASBM trained with different NFE \(\in\{2,4,8\}\) with \(\epsilon=1\).

\begin{table}
\begin{tabular}{|c|c|c|} \hline Model & \(\epsilon=1\) & \(\epsilon=10\) \\ \hline DSBM & 24.06 & 92.15 \\ \hline ASBM (ours) & 16.86 & 17.44 \\ \hline \end{tabular}
\end{table}
Table 5: Test FID\(\downarrow\) values for CelebA _female\(\rightarrow\)male_ image-to-image translation.

**LPIPS diversity**. To measure the generation diversity of our model on CelebA _male\(\rightarrow\)female_ translation, we compute the LPIPS variance [16]. Specifically, we take a subset of 500 images from the test part of the Celeba dataset and sample a batch of 16 generated images for each input image. We then compute the average LPIPS [55] distance between all possible pairs of these images and average these values. We present the results in the Table 8 for DSBM and ASBM with different values of the coefficient \(\epsilon=1\) and \(\epsilon=10\).

**LPIPS perceptual similarity**. To evaluate the content preservation during the unpaired image-to-image _male\(\rightarrow\)female_ translation on CelebA, we calculate the perceptual similarity. Namely, we take the test samples from CelebA dataset, translate them using learned DSBM and ASBM models with parameters \(\epsilon=1\) and \(\epsilon=10\) and then calculate LPIPS [55] between inputs and generated outputs and average results. One can see results in the Table 9.

\begin{table}
\begin{tabular}{|c|c|c|c|c|c|c|} \hline NFE & 1 & 2 & 3 & 4 & 8 & 16 & 32 \\ \hline FID & 58.71 & 32.27 & 17.67 & 16.62 & 55.72 & 67 & 86.97 \\ \hline MSE cost & 0.009 & 0.023 & 0.047 & 0.113 & 0.288 & 0.354 & 0.50 \\ \hline \end{tabular}
\end{table}
Table 7: Quantitative evaluation of ASBM model trained with NFE\(=4\) and evaluated with NFE\(\in\{1,2,3,4,8,16,32\}\). FID\(\downarrow\) and MSE cost are calculated on the test set.

Figure 13: CelebA _male\(\rightarrow\)female_ translation samples of ASBM trained with NFE\(=4\) and evaluated with NFE\(\in\{1,2,3,4,8,16,32\}\).

\begin{table}
\begin{tabular}{|c|c|c|} \hline Model & \(\epsilon=1\) & \(\epsilon=10\) \\ \hline DSBM & 0.1047 & 0.1909 \\ \hline ASBM (ours) & 0.0933 & 0.1878 \\ \hline \end{tabular}
\end{table}
Table 8: Average diversity of DSBM and ASBM generative models for _male\(\rightarrow\)female_ translation measured by using LPIPS variance [16].

[MISSING_PAGE_FAIL:31]

[MISSING_PAGE_FAIL:32]

Figure 17: ASBM (ours) Celeba _male\(\rightarrow\)female_ (\(128\times 128\)) samples for \(\epsilon\in\{1,10\}\)

Figure 18: ASBM _female\(\rightarrow\)male_ (\(128\times 128\)) samples for \(\epsilon\in\{1,10\}\)

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: For every contribution in introduction there are links to sections about them. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: Limitations are discussed in Appendix A Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes]Justification: Proofs along with assumptions are provided in Appendix B. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: Experimental details are discussed in Appendix D. Code for the experiments is provided in supplementary materials. All the datasets are available in public. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?Answer: [Yes] Justification: Code will be made public after the paper acceptance (now we provide it in the supplementary). Experimental details are provided in Appendix D. All the datasets are publicly available. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: Experimental details are discussed in Appendix D Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [No] Justification: Unfortunately running experiments several times to calculate statistics and error bars would be too computationally expensive. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: Computational time and used computational resources details were reported for several experiments in D.3 Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: Research conforms with NeurIPS Code of Ethics. Societal impact related information was discussed in A Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: Broader impact was discussed in A Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.

* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: Presented research doesn't need safeguards Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licensees for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: All the used assets are cited. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.

* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [Yes] Justification: Code is provided in supplementary material. License for the code will be included after the paper acceptance. Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.