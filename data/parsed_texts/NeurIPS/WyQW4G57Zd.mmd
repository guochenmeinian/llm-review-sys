# Stochastic Optimal Control for Diffusion Bridges in Function Spaces

 Byoungwoo Park\({}^{1}\), Jungwon Choi\({}^{1}\), Sungbin Lim\({}^{2,3}\); Juho Lee\({}^{1}\)

KAIST\({}^{1}\), Korea University\({}^{2}\), LG AI Research\({}^{3}\)

{bw.park, jungwon.choi, juholee}@kaist.ac.kr,

sungbin@korea.ac.kr

Equal advising.

###### Abstract

Recent advancements in diffusion models and diffusion bridges primarily focus on finite-dimensional spaces, yet many real-world problems necessitate operations in infinite-dimensional function spaces for more natural and interpretable formulations. In this paper, we present a theory of stochastic optimal control (SOC) tailored to infinite-dimensional spaces, aiming to extend diffusion-based algorithms to function spaces. Specifically, we demonstrate how Doob's \(h\)-transform, the fundamental tool for constructing diffusion bridges, can be derived from the SOC perspective and expanded to infinite dimensions. This expansion presents a challenge, as infinite-dimensional spaces typically lack closed-form densities. Leveraging our theory, we establish that solving the optimal control problem with a specific objective function choice is equivalent to learning diffusion-based generative models. We propose two applications: 1) learning bridges between two infinite-dimensional distributions and 2) generative models for sampling from an infinite-dimensional distribution. Our approach proves effective for diverse problems involving continuous function space representations, such as resolution-free images, time-series data, and probability density functions. Code is available at https://github.com/bw-park/DBFS.

## 1 Introduction

Stochastic Optimal Control (SOC) is designed to steer a noisy system toward a desired state by minimizing a specific cost function. This methodology finds extensive applications across various fields in science and engineering, including rate event simulation [33, 35], stochastic filtering and data assimilation [47, 55, 72], non-convex optimization [9], modeling population dynamics [8, 43]. SOC is also related to diffusion-based sampling methods that are predominant in machine learning literature. Specifically, if we choose the terminal cost of a control problem as the log density ratio between a target distribution and a simple prior distribution, solving the optimal control reduces to learning a diffusion-based generative models [56, 73, 77] built upon the Schrodinger bridge problem [12, 54].

While SOC associated diffusion-based generative models have been well-established for finite-dimensional spaces [5, 10, 11, 44], their theoretical foundations and practical algorithms for infinite-dimensional spaces remain underexplored. There is a growing interest in developing generative models in function spaces. Examples include learning neural operators for partial differential equations (PDEs) [37, 39, 40], interpreting images as discretized functions through implicit neural representations (INRs) [21, 63], and operating in function spaces for Bayesian neural networks (BNNs) [65, 74]. Models that operate in function spaces are more parameter-efficient as they avoid resolution-specific parameterizations. In response to this demand, several extensions ofdiffusion-based generative models for infinite-dimensional function spaces have been proposed [3; 25; 32; 41; 42; 53]. However, SOC theory for building diffusion bridges in function spaces is still demanding in the community of generative modeling.

To address these challenges, this work introduces an extension of SOC for diffusion bridges in infinite-dimensional Hilbert spaces, particularly focusing on its applications in sampling problems. Specifically, we demonstrate the idea of Doob's \(h\)-transform [13; 59] can be derived from SOC theory and extend its formulation into Hilbert spaces. Due to the absence of a density with respect to the Lebesgue measure in infinite-dimensional spaces, building a diffusion bridge between function spaces is a nontrivial task separated from the finite-dimensional cases [51; 61]. To this end, we propose a Radon-Nikodym derivative relative to a specified Gaussian reference measure in Hilbert space. Leveraging the infinite-dimensional Doob's \(h\)-transform and SOC, we then formulate diffusion bridge-based sampling algorithms in function spaces. While the infinite-dimensional Doob's \(h\)-transform has already been derived in [2; 26; 31], our main goal is not merely to derive it. Instead, we aim to generalize various finite-dimensional sampling problems [51; 61; 73; 77] into the infinite-dimensional space by exploiting the theory of infinite-dimensional SOC.

To demonstrate the applicability of our theory, we present learning algorithms for two representative problems. First, we introduce an infinite-dimensional bridge-matching algorithm as an extension of previous methods [51; 61] into Hilbert spaces, which learns a generative model to bridge two distributions defined in function spaces. As an example, we show that our framework can learn smooth transitions between two image distributions in a resolution-free manner. Second, we propose a simulation-based Bayesian inference algorithm [73; 77] that operates in function space. Instead of directly approximating the target Bayesian posterior, our algorithm learns a stochastic transition from the prior to the posterior within the function space. We demonstrate the utility of this approach by inferring Bayesian posteriors of stochastic processes, such as Gaussian processes. We summarize our contributions as follows:

* Based on the SOC theory, we derive the Doob's \(h\)-transform in Hilbert spaces. We propose a \(h\) function as a Random-Nikodym derivative with respect to a Gaussian measure in infinite-dimensional space.
* Based on the infinite-dimensional extension of the Doob's \(h\)-transform, we present the diffusion bridge and simulation-based Bayesian inference algorithm in function spaces.
* We demonstrate our method for various real-world problems involving function spaces, including resolution-free image translation and posterior sampling for stochastic processes.

Notation.Consider a real and separable Hilbert space \(\mathcal{H}\) with the norm and inner product denoted by \(\left\|\cdot\right\|_{\mathcal{H}}\) and \(\left\langle\cdot,\cdot\right\rangle_{\mathcal{H}}\). Throughout the paper, we consider a path measure denoted by \(\mathbb{P}^{(\cdot)}\) on the space of all continuous mappings \(\Omega=C([0,T],\mathcal{H})\). The stochastic processes associated with this path measure \(\mathbb{P}^{(\cdot)}\) are denoted by \(\mathbf{X}^{(\cdot)}\), and their time-marginal distribution at time \(t\in[0,T]\) as push-forward measure \(\mu_{t}^{(\cdot)}:=(\mathbf{X}_{t}^{(\cdot)})_{\#}\mathbb{P}^{(\cdot)}\). Furthermore, for a function \(\mathcal{V}:[0,T]\times\mathcal{H}\to\mathbb{R}\), we define \(D_{\mathbf{x}}\mathcal{V},D_{\mathbf{x}\mathbf{x}}\mathcal{V}\) as the first and second order Frechet derivatives with respect to the variable \(\mathbf{x}\in\mathcal{H}\), respectively, and \(\partial_{t}\mathcal{V}\) as the derivative with respect to the time variable \(t\in[0,T]\).

## 2 A Foundation on Stochastic Optimal Control for Diffusion Bridges

In this section, we first present a brief introduction to the theory of stochastic optimal control (SOC) in infinite dimensions and the Verification Theorem (Lemma 2.1), which is the key to understanding the theoretical connection between SOC and the diffusion bridges. Then we propose Doob's \(h\)-transform in Hilbert spaces based on the SOC theory (Theorems 2.2 and 2.3).

### Preliminaries

Gaussian Measure and Cameron-Martin Space.Let \((\Omega,\mathcal{F},\mathbb{Q})\) and \((\mathcal{H},\mathcal{B}(\mathcal{H}))\) be two measurable spaces and consider \(\mathcal{H}\)-valued random variable \(\mathbf{X}:\Omega\to\mathcal{H}\) such that the push-forward measure \(\mu:=\mathbf{X}_{\#}\mathbb{Q}\) induced by \(\mathbf{X}\) is Gaussian, i.e., a real-valued random variable \(\langle u,\mathbf{X}\rangle_{\mathcal{H}}\) follows Gaussian distribution on \(\mathbb{R}\) for any \(u\in\mathcal{H}\). Then, there exist a unique mean \(m_{\mathbf{X}}\in\mathcal{H}\) given by \(\langle m_{\mathbf{X}},u\rangle_{\mathcal{H}}=\mathbf{E}_{\mu}\left[\langle \mathbf{X},u\rangle_{\mathcal{H}}\right]\) and a nonnegative, symmetric, and self-adjoint covariance operator \(Q:\mathcal{H}\to\mathcal{H}\) defined by \(\langle u,Qv\rangle_{\mathcal{H}}=\mathbb{E}_{\mu}\left[\langle\mathbf{X}-m_ {\mathbf{X}},u\rangle_{\mathcal{H}},\langle\mathbf{X}-m_{\mathbf{X}},v\rangle _{\mathcal{H}}\right]\) for any \(u,v\in\mathcal{H}\).

We write \(\mu=\mathcal{N}(m_{\mathbf{X}},Q)\) and say \(\mathbf{X}\) is centered if \(m_{\mathbf{X}}=0\). For a covariance operator \(Q\), we assume \(\mathcal{H}\)-valued centered \(\mathbf{X}\) follows the distribution \(\mathcal{N}(0,Q)\) supported on \(\mathcal{H}\) so that \(Q\) is guaranteed to be compact. Hence, there exists an eigen-system \(\{(\lambda^{(k)},\phi^{(k)})\in\mathbb{R}\times\mathcal{H}:k\in\mathbb{N}\}\) such that \(Q(\phi^{(k)})=\lambda^{(k)}\phi^{(k)}\) holds and \(\text{Tr}(Q)=\sum_{k=1}^{\infty}\lambda^{(k)}<\infty\). We define the _Cameron-Martin space_ by \(\mathcal{H}_{0}:=Q^{1/2}(\mathcal{H})\), \(\mathcal{H}_{0}\subseteq\mathcal{H}\) is a separable Hilbert space endowed with the inner product \(\langle u,v\rangle_{\mathcal{H}_{0}}:=\langle Q^{-1/2}u,Q^{-1/2}v\rangle_{ \mathcal{H}}\).

Stochastic Differential Equations in Hilbert Spaces.The standard \(\mathbb{R}^{d}\)-valued Wiener process has independent increments \(w_{t+\Delta_{t}}-w_{t}\sim\mathcal{N}(0,\Delta_{t}\mathbf{I}_{d})\). In the case of infinite-dimensional Hilbert space \(\mathcal{H}_{0}\), however, such identity covariance may not be a trace class. We consider a larger space \(\mathcal{H}_{0}\subset\mathcal{H}_{1}\) such that \(\mathcal{H}_{0}\) is embedded into \(\mathcal{H}_{1}\) with a Hilbert-Schmidt embedding \(J:\mathcal{H}_{0}\rightarrow\mathcal{H}_{1}\). Let \(Q:=JJ^{*}\) and we define \(\mathcal{H}_{1}\)-valued \(Q\)-Wiener process [17, Proposition 4.7] as \(\mathbf{W}_{t}^{Q}=\sum_{k=1}^{\infty}Q^{1/2}\phi^{(k)}w_{t}^{(k)}\). We focus on the Cameron-Martin space \(\mathcal{H}_{0}\) where the Wiener process has increments \(\mathcal{N}(0,\Delta_{t}\mathbf{I}_{t})\), and a larger space \(\mathcal{H}_{1}=\mathcal{H}\), where the Wiener process has increments \(\mathcal{N}(0,\Delta_{t}Q)\). Then we define a path measure \(\mathbb{P}\) and associated stochastic differential equation (SDE) in \(\mathcal{H}\) as follows

\[d\mathbf{X}_{t}=\mathcal{A}\mathbf{X}_{t}+\sigma d\mathbf{W}_{t}^{Q},\quad \mathbf{X}_{0}\in\mathcal{H},\quad t\in[0,T],\] (1)

where \(\mathcal{A}:\mathcal{H}\rightarrow\mathcal{H}\) is a linear operator, a constant \(\sigma>0\) and a \(Q\)-Wiener process \(\mathbf{W}^{Q}\) defined on a probability space \((\Omega,\mathcal{F},(\mathcal{F}_{t})_{t\geq 0},\mathbb{P})\). For a more comprehensive understanding, see [17, 29].

### Stochastic Optimal Control in Hilbert Spaces

From the _uncontrolled_ SDE introduced in equation (1), various sampling problems in \(\mathbb{R}^{d}\) including density sampling [5, 73, 77] and generative modeling [10, 11] can be solved by adjusting the SDE with proper drift (control) function \(\alpha\in\mathbb{R}^{d}\). Motivated by these approaches, introducing stochastic optimal control (SOC) to solve real-world sampling problems, we aim to introduce SOC to the infinite-dimensional Hilbert space \(\mathcal{H}\). We consider that a controlled path measures \(\mathbb{P}^{\alpha}\) is induced by following infinite-dimensional SDE defined as follows:

\[d\mathbf{X}_{t}^{\alpha}=\left[\mathcal{A}\mathbf{X}_{t}^{\alpha}+\sigma Q^{1 /2}\alpha_{t}\right]dt+\sigma d\mathbf{\tilde{W}}_{t}^{Q},\quad\mathbf{X}_{0}^ {\alpha}=\mathbf{x}_{0},\quad t\in[0,T]\] (2)

where \(\alpha_{(\cdot)}:[0,T]\times\mathcal{H}\rightarrow\mathcal{H}\) is infinite-dimensional Markov control (see Section A.1.2 for more details). We refer to the SDE in equation (2) as _controlled_ SDE. The controlled SDE can be exploited to the various problems. In general, it can be done by finding the optimal control function that minimizes the objective functional with suitably chosen cost functionals depending on the problem:

\[\mathcal{J}(t,\mathbf{x}_{t},\alpha)=\mathbb{E}_{\mathbb{P}^{\alpha}}\left[ \int_{t}^{T}\left[R(\alpha_{s})\right]ds+G(\mathbf{X}_{T}^{\alpha})\big{|} \mathbf{X}_{t}^{\alpha}=\mathbf{x}_{t}\right],\] (3)

where \(R:\mathcal{H}\rightarrow\mathbb{R}\) are running cost and \(G:\mathcal{H}\rightarrow\mathbb{R}\) is terminal cost. The measurable function \(\mathcal{J}(t,\mathbf{x},\alpha)\), representing the total cost incurred by the control \(\alpha\) over the interval \([t,T]\), given that the control strategy from the interval \([0,t]\) has resulted in \(\mathbf{X}_{t}^{\alpha}=\mathbf{x}\). The objective is to minimize the objective functional in (3) over all admissible control policies \(\alpha\in\mathcal{U}\), where \(\mathcal{U}\) is the Hilbert space of all square-integrable \(\mathcal{H}\)-valued processes adapted to \(\mathbf{W}^{Q}\) defined on \([0,T]\). Then we define the _value function_\(\mathcal{V}(t,\mathbf{x})=\inf_{\alpha\in\mathcal{U}}\mathcal{J}(t,\mathbf{x},\alpha)\), the optimal costs conditioned on \((t,\mathbf{x})\in[0,T]\times\mathcal{H}\). By using the dynamic programming [23], we can solve the Hamilton-Jacobi-Bellman (HJB) equation,

\[\partial_{t}\mathcal{V}_{t}+\mathcal{L}\mathcal{V}_{t}+\inf_{\alpha\in\mathcal{ U}}\left[\langle\alpha,\sigma Q^{1/2}D_{\mathbf{x}}\mathcal{V}_{t}\rangle+R \right]=0,\quad\mathcal{V}(T,\mathbf{x})=G(\mathbf{x}),\] (4)

where \(\mathcal{L}\mathcal{V}_{t}:=\langle\mathbf{X}_{t}^{\alpha},\mathcal{A}D_{ \mathbf{x}}\mathcal{V}_{t}\rangle_{\mathcal{H}}+\frac{1}{2}\text{Tr}\left[ \sigma^{2}QD_{\mathbf{x}\mathbf{x}}\mathcal{V}_{t}\right]\). We demonstrate that with specific choices of cost functionals \(R\) and \(G\) in (3), the optimal control \(\alpha^{*}\) of the minimization problem aligns with the proper drift function for sampling problems we will discuss later. To do so, we start with how the HJB equation can characterize the optimal controls.

**Lemma 2.1** (Verification Theorem).: _Let \(\mathcal{V}\) be a solution of HJB equation (4) with \(R(\alpha):=\frac{1}{2}\left\|\alpha\right\|_{\mathcal{H}}^{2}\) satisfying the assumptions in A.1. Then, we have \(\mathcal{V}(t,\mathbf{x})\leq\mathcal{J}(t,x,\alpha)\) for every \(\alpha\in\mathcal{U}\) and \((t,\mathbf{x})\in[0,T]\times\mathcal{H}\). Let \((\alpha^{*},\mathbf{X}^{\alpha^{*}})\) be an admissible pair such that_

\[\alpha_{s}^{*}=\operatorname*{arg\,inf}_{\alpha\in\mathcal{U}}\left[\langle \alpha_{s},\sigma Q^{1/2}D_{\mathbf{x}}\mathcal{V}_{t}\rangle+\frac{1}{2} \left\|\alpha_{s}\right\|_{\mathcal{H}}^{2}\right]=-\sigma Q^{1/2}D_{\mathbf{x}} \mathcal{V}(s,\mathbf{X}_{s}^{\alpha^{*}})\] (5)

_for almost every \(s\in[t,T]\) and \(\mathbb{P}\)-almost surely. Then \((\alpha^{*},\mathbf{X}^{\alpha^{*}})\) satisfying \(\mathcal{V}(t,\mathbf{x})=\mathcal{J}(t,\mathbf{x},\alpha^{*})\)._Lemma 2.1 demonstrate that with specific choices of running costs, the solution to the HJB equation in (4) is the optimal cost of the minimization problem in (3) with the closed-form optimal control \(\alpha_{t}^{*}=-\sigma Q^{1/2}D\mathcal{V}_{t}\). In the subsequent subsection, we reveal the connection between the optimal controlled process, characterized by the controlled SDE with optimal control \(\alpha^{*}\), and the conditioned SDE in \(\mathcal{H}\). Additionally, we show various problems depending on the choice of the terminal cost \(G\).

### Doob's \(h\)-transform for Diffusion Bridges in Hilbert Spaces

The _conditioned_ SDE is a stochastic process that is guaranteed to satisfy a set constraint defined over the interval \([0,T]\). For instance, a _Diffusion Bridge_ is a stochastic process that satisfies both terminal constraints \(\mathbf{X}_{0}=\mathbf{x}_{0}\), \(\mathbf{X}_{T}=\mathbf{x}_{T}\) for any \(\mathbf{x}_{0},\mathbf{x}_{T}\in\mathcal{H}\). We will show that with a proper choice of the terminal cost \(G\), the conditioned SDE is a special case of controlled SDE. For this, let us define the function \(h:[0,T]\times\mathcal{H}\to\mathbb{R}\):

\[h(t,\mathbf{x})=\int_{\mathcal{H}}\tilde{G}(\mathbf{z})\mathcal{N}_{e^{(T-t) }A_{\mathbf{x}},Q_{T-t}}(d\mathbf{z})=\mathbb{E}_{\mathbb{P}}\left[\tilde{G} (\mathbf{X}_{T})|\mathbf{X}_{t}=\mathbf{x}\right],\] (6)

where \(\mathcal{N}_{e^{t}A_{\mathbf{x}},Q_{t}}\) is a Gaussian measure with mean function \(e^{tA}\mathbf{x}\) and covariance operator \(Q_{t}=\int_{0}^{t}e^{(t-s)A}Qe^{(t-s)A}ds\) and \(\tilde{G}:=e^{-G}\) for the function \(G\) in (3). The function \(h\) evaluates the future states \(\mathbf{X}_{T}\) using \(\tilde{G}\) which propagated by (1) for a given initial \(\mathbf{x}\) at time \(t\in[0,T]\). It can be shown that the function \(h\) satisfies the Kolmogorov-backward equation [17] with terminal condition,

\[\partial_{t}h_{t}+\mathcal{L}h_{t}=0,\quad h(T,\mathbf{x})=\tilde{G}( \mathbf{x}).\] (7)

Now, we employ the Hopf-Cole transformation [24] to establish an inherent connection between two classes of PDEs, the linear PDE in (7) and the HJB equation in (4), which provide us a key insight to deriving the Doob's \(h\)-transform in function spaces utilizing the SOC theory.

**Theorem 2.2** (Hopf-Cole Transform).: _Let \(\mathcal{V}_{t}=-\log h_{t}\). Then \(\mathcal{V}_{t}\) satisfies the HJB equation:_

\[\partial_{t}\mathcal{V}_{t}+\mathcal{L}\mathcal{V}_{t}-\frac{1}{2}\left\| \sigma Q^{1/2}D_{\mathbf{x}}\mathcal{V}_{t}\right\|_{\mathcal{H}}^{2}=0,\quad \mathcal{V}(T,\mathbf{x})=G(\mathbf{x}).\] (8)

According to Theorem 2.2, the solution of linear PDE in equation (7) is negative exponential to the solution of the HJB equation in (8). Given that it already verified that the optimal control \(\alpha^{*}\) results the value function \(\mathcal{V}_{t}\), which has explicit form as described in (8), we find that the relationship of two PDEs through \(\mathcal{V}_{t}=-\log h_{t}\) leads to a distinct form of optimal control \(\alpha^{*}=-\sigma Q^{1/2}D_{\mathbf{x}}\mathcal{V}=\sigma Q^{1/2}D_{\mathbf{ x}}\log h\), where \(D_{\mathbf{x}}\log h:=D_{\mathbf{x}}h/h\). Consequently, it yields another class of SDE as follows:

\[d\mathbf{X}_{t}^{h}=\left[\mathcal{A}\mathbf{X}_{t}^{h}dt+\sigma^{2}QD_{ \mathbf{x}}\log h(t,\mathbf{X}_{t}^{h})\right]dt+\sigma d\mathbf{\hat{W}}_{t }^{Q},\quad\mathbf{X}_{0}^{h}=\mathbf{x}_{0},\] (9)

where \(\mathbf{\hat{W}}_{t}^{Q}\) is a \(Q\)-Wiener process on \(\mathbb{P}^{h}\). This representation is consistent with infinite-dimensional conditional SDE [2, 26] which induces an expansion of Doob's \(h\)-transform [59] in Hilbert space \(\mathcal{H}\).

The Doob's \(h\)-transform in finite-dimensional spaces is well-established to construct the diffusion bridge process under the assumption that \(h(t,\mathbf{x})=\mathbb{P}(\mathbf{X}_{T}\in d\mathbf{x}_{T}|\mathbf{X}_{t}= \mathbf{x})\) has an explicit Radon-Nikodym density function [46, 60], enable to simulate the bridge SDEs. In contrast, although the choice of \(\tilde{G}(\mathbf{x})=\mathbf{1}_{d\mathbf{x}_{T}}(\mathbf{x}_{T})\) in (6) yields same representation of \(h(t,\mathbf{x})=\mathbb{P}(\mathbf{X}_{T}\in d\mathbf{x}_{T}|\mathbf{X}_{t}= \mathbf{x})\), we cannot easily define the Radon-Nikodym density in \(\mathcal{H}\) due to the absence of an equivalent form of Lesbesgue measure which hinder the computation of \(D_{\mathbf{x}}\log h(t,\mathbf{X}_{t}^{h})\) in (9) explicitly. Hence, to define the diffusion bridge process in \(\mathcal{H}\), we need to identify an explicit density form of \(h(t,\mathbf{x})=\mathbb{P}(\mathbf{X}_{T}\in d\mathbf{x}_{T}|\mathbf{X}_{t} =\mathbf{x})\). The following theorem reveals the explicit form of \(h\) function and becomes a key ingredient in deriving infinite dimensional diffusion bridge processes.

**Theorem 2.3** (Explicit Representation of \(h\)).: _For any \(t>0\) and any \(\mathbf{x}\in\mathcal{H}\), the measure \(\mathcal{N}_{e^{t}A_{\mathbf{x}},Q_{t}}\) and \(\mathcal{N}_{0,Q_{\infty}}\) are equivalent, where \(\mathcal{N}_{0,Q_{\infty}}\) is an invariant measure of \(\mathbb{P}\) in (1) as \(t\to\infty\) where \(Q_{\infty}=-\frac{1}{2}Q\mathcal{A}^{-1}\). Moreover, for any \(\mathbf{x},\mathbf{y}\in\mathcal{H}\), the Radon-Nikodym density \(\frac{d\mathcal{N}_{e^{t}A_{\mathbf{x}},Q_{t}}}{d\mathcal{N}_{0,Q_{\infty}}}( \cdot)=q_{t}(\mathbf{x},\cdot)\) is given by_

\[q_{t}(\mathbf{x},\mathbf{y}) =\text{det}(1-\Theta_{t})^{-1/2}\exp\bigg{[}-\frac{1}{2}\langle(1 -\Theta_{t})^{-1}Q_{\infty}^{-1/2}e^{tA}\mathbf{x},Q_{\infty}^{-1/2}e^{tA} \mathbf{x}\rangle_{\mathcal{H}}\] (10) \[+\langle(1-\Theta_{t})^{-1}e^{tA}Q_{\infty}^{-1/2}\mathbf{x},Q_{ \infty}^{-1/2}\mathbf{y}\rangle_{\mathcal{H}}-\frac{1}{2}\langle\Theta_{t}(1- \Theta_{t})^{-1}Q_{\infty}^{-1/2}\mathbf{y},Q_{\infty}^{-1/2}\mathbf{y} \rangle_{\mathcal{H}}\bigg{]},\] (11)

_where \(\Theta_{t}=Q_{\infty}^{1/2}(Q_{t}^{-1/2}e^{tA})^{*}(Q_{\infty}^{-1/2}Q_{t}^{1/2} )^{*}(Q_{\infty}^{1/2}(Q_{t}^{-1/2}e^{tA})^{*}(Q_{\infty}^{-1/2}Q_{t}^{1/2})^{*})\), \(t\geq 0\)._Theorem 2.3 states that the marginal distribution of certain classes of SDEs described in (1) has an explicit Radon-Nikodym density with respect to their invariant measure. Therefore, by the time-homogeneity of the process in (1), it allows us to define the \(h\) function explicitly:

\[h(t,\mathbf{x})=\int_{\mathcal{H}}\tilde{G}(\mathbf{z})\mathcal{N}_{e^{(T-t)A_{ \mathbf{x}},Q_{T-t}}}(d\mathbf{z})=\int_{\mathcal{H}}\tilde{G}(\mathbf{z})q_{T -t}(\mathbf{x},\mathbf{z})\mathcal{N}_{0,Q_{\infty}}(d\mathbf{z}).\] (12)

This framework enables the construction of an infinite-dimensional bridge process, by selecting \(\tilde{G}\) in (12) properly. Below, we demonstrate the infinite-dimensional diffusion bridge.

**Example 2.4** (Diffusion Bridge in \(\mathcal{H}\)).: _Let \(\{(\lambda^{(k)},\phi^{(k)})\in\mathbb{R}\times\mathcal{H}:k\in\mathbb{N}\}\) be an eigen-system of \(\mathcal{H}\). Then for each \(k\in\mathbb{N}\), the SDE system in equation (1) can be represented as:_

\[d\mathbf{X}_{t}^{(k)}=-a_{k}\mathbf{X}_{t}^{(k)}dt+\sigma\sqrt{\lambda^{(k)}} d\mathbf{W}_{t}^{(k)},\quad\mathbf{X}^{(k)}(0)=\mathbf{x}_{0}^{(k)},\] (13)

_where \(\mathcal{A}\phi^{(k)}=-a_{k}\phi^{(k)}\), \(Q\phi^{(k)}=\lambda^{(k)}\phi^{(k)}\), \(\mathbf{X}_{t}^{(k)}=\langle\mathbf{X}_{t},\phi^{(k)}\rangle_{\mathcal{H}}\) and \(\mathbf{W}_{t}^{(k)}=\langle\mathbf{W}_{t},\phi^{(k)}\rangle_{\mathcal{H}}\). Then, for any \(\mathbf{x}_{T}\in\mathcal{H}\), the conditional law of \(\mathbf{x}_{T}^{(k)}\) given \(\mathbf{X}_{t}^{(k)}\) is a Gaussian \(\mathcal{N}(\mathbf{m}_{T|t}^{(k)}\mathbf{X}_{t}^{(k)},\mathbf{\Sigma}_{T|t}^ {(k)})\) with_

\[\mathbf{m}_{T|t}^{(k)}=e^{-a_{k}(T-t)},\quad\mathbf{\Sigma}_{T|t}^{(k)}=\sigma ^{2}\frac{\lambda_{k}}{2a_{k}}\left(1-e^{-2a_{k}(T-t)}\right).\] (14)

_Now, by setting the terminal condition in (6) as \(\tilde{G}(\mathbf{x}):=\mathbf{1}_{\mathbf{x}_{T}}(\mathbf{x})\) (i.e., Dirac delta of \(\mathbf{x}_{T}\)) then \(h(t,\mathbf{x})=q_{T-t}(\mathbf{x},\mathbf{x}_{T})\). Thus, for each coordinate \(k\), we get following representation:_

\[d\mathbf{X}_{t}^{(k)}=\left[-a_{k}\mathbf{X}_{t}^{(k)}+\frac{2a_{k}e^{-a_{k}( T-t)}}{1-e^{-2a_{k}(T-t)}}(\mathbf{x}_{T}^{(k)}-e^{-a_{k}(T-t)}\mathbf{X}_{t}^{(k)} )\right]dt+\sigma\sqrt{\lambda^{(k)}}d\mathbf{W}_{t}^{(k)},\] (15)

_with two end points conditions \(\mathbf{X}_{0}^{(k)}=\mathbf{x}_{0}^{(k)}\) and \(\mathbf{X}_{T}^{(k)}=\mathbf{x}_{T}^{(k)}\)._

### Approximating path measures

Since the function \(h\) is intractable for a general terminal cost \(\tilde{G}\) in (12), simulating the conditioned SDEs in (9) requires some approximation techniques. As observed in Theorem 2.2, finding the function \(h\) is equal to learning the control function \(\alpha\) such that \(\mathbb{P}^{\alpha}\) is equal to \(\mathbb{P}^{\star}:=\mathbb{P}^{\alpha^{\star}}=\mathbb{P}^{h}\). Therefore, with a parametrization \(\alpha:=\alpha(\cdot,\theta)\) the approximation can be done by neural network parameterization \(\textit{i.e.},\alpha^{\star}\approx\alpha^{\theta^{\star}}\) with local minimum \(\theta^{\star}=\arg\min_{\theta}D(\mathbb{P}^{\alpha}||\mathbb{P}^{\star})\), where\(D(\mathbb{P}^{\alpha}||\mathbb{P}^{\star})\) is a divergence between \(\mathbb{P}^{\alpha}\) and \(\mathbb{P}^{\star}\). For example, the cost functional described in equation (3) can be represented as relative-entropy loss \(D_{\text{rel}}(\mathbb{P}^{\alpha}||\mathbb{P}^{\star})=\mathbb{E}_{\mathbb{P} ^{\alpha}}\left[\log\frac{d\mathbb{P}^{\alpha}}{d\mathbb{P}^{\alpha}}\right]^ {2}\). Therefore, the training loss for \(\theta\) can be estimated by first simulating the parameterized control path and then calculating (3) for a specified cost functional \(R,G\). Moreover, if we can access to the \(\mathbb{P}^{\star}\), one can define the variational optimization [69] where the loss is defined as cross-entropy loss \(D_{\text{cross}}(\mathbb{P}^{\alpha}||\mathbb{P}^{\star})=\mathbb{E}_{\mathbb{P} ^{\star}}\left[\log\frac{d\mathbb{P}^{\star}}{d\mathbb{P}^{\alpha}}\right]\). See [20; 48] for more details about the approximation technique and other loss functions.

## 3 Simulating Diffusion Bridges in Infinite Dimensional Spaces

Leveraging the SOC theory within \(\mathcal{H}\), we show how our approach generalizes existing diffusion-based sampling methods. Specifically, incorporating the relation between _controlled_ SDEs (2) and _conditioned_ SDEs (9), we introduce two learning algorithms that allow us to simulate various diffusion bridge-based sampling algorithms.

### Infinite Dimensional Bridge Matching

In this section, our objective is to learn a control \(\alpha\) that yields \(\mathbb{P}^{\alpha}\) such that \(\{\mathbf{X}_{t}^{\alpha}\}_{t\in[0,T]}\) satisfies \(\mu_{t}^{\alpha}\approx\mu_{t}^{\star}\) for all pre-specified \(\mu_{t}^{\star}\) over the interval \(t\in[0,T]\). Specifically, we assume that the end-point marginals \(\mu_{0}^{\star}\) and \(\mu_{T}^{\star}\) follow the laws of two data distributions \(\pi_{0}\) and \(\pi_{T}\), respectively, and the intermediate marginals \(\{\mu_{t}^{\star}\}_{t\in(0,T)}\) are defined as a mixture of diffusion bridge paths. Thislearning problem is referred to as the _Bridge Matching_ (BM) algorithm [45, 50, 61] and can be expressed as a solution of the SOC problem structured as

\[\inf_{\alpha}D(\mathbb{P}^{\alpha}|\mathbb{P}^{\star}),\text{ such that }d\mathbf{X}_{t}^{\alpha}=\left[d \mathbf{X}_{t}^{\alpha}+\sigma Q^{1/2}\alpha_{t}\right]dt+\sigma d\mathbf{ \tilde{W}}_{t}^{Q},\quad\mathbf{X}_{0}^{\alpha}\sim\pi_{0}.\] (16)

In (16), various divergences can be chosen for the same learning problem, as discussed in Section 2.4. Here, we will choose the cross-entropy because the relative entropy requires the appropriate selection of the terminal cost \(G\) in (3), which is intractable since we do not have access to the distributional form of \(\pi_{0},\pi_{T}\)[44]. Furthermore, keeping the entire computational graph of \(\mathbb{P}^{\alpha}\) with parameterized \(\alpha\) can become resource-intensive, especially for higher-dimensional datasets like images [11].

Now, we specify the optimal path measure \(\mathbb{P}^{\star}\) for a problem in (16). Let \(\mathbb{P}_{|0,T}\) be a path measure induced by (15) and \(\mu_{t|0,T}\) be a marginal distribution of \(\mathbb{P}_{|0,T}\). Moreover, let \(\mathbb{P}^{\star}=\mathbb{P}_{|0,T}\Pi_{0,T}\) for an independent coupling \(\Pi_{0,T}=\pi_{0}\otimes\pi_{T}\). Then the optimal path measure \(\mathbb{P}^{\star}\) is defined as _Mixture of bridge_. Under regular assumptions, the optimal control \(\alpha^{\star}\) that induces the optimal path measure \(\mathbb{P}^{\star}\) can be constructed as a mixture of functions \(h\) in (9) by choosing \(G(\mathbf{x})=\mathbf{1}_{\mathbf{x}_{T}}(\mathbf{x})\).

**Theorem 3.1** (Mixture of Bridges in \(\mathcal{H}\)).: _Let us consider a marginal distribution of \(\mathbb{P}^{\star}\) at \(t\in[0,T]\), \(\mu_{t}^{\star}(d\mathbf{x}_{t})=\int\mu_{t|0,T}(d\mathbf{x}_{t})\Pi_{0,T}(d \mathbf{x}_{0},d\mathbf{x}_{T})\) has density \(p_{t}^{\star}\) with respect to some Gaussian reference measure \(\mu_{\text{rsf}}\,i.e.,\mu_{t}^{\star}(d\mathbf{x}_{t})/\mu_{\text{rsf}}(d \mathbf{x}_{t})=p_{t}^{\star}(\mathbf{x}_{t})\). Then the optimal path measure \(\mathbb{P}^{\star}\) associated with:_

\[d\mathbf{X}_{t}^{\star}=\left[\mathcal{A}\mathbf{X}_{t}^{\star}+\mathbb{E}_{ \mathbf{x}_{T}\sim\mathbb{P}^{\star}(d\mathbf{x}_{T}|\mathbf{X}_{t}^{\star})} \left[\sigma^{2}QD_{\mathbf{x}}\log\mathcal{N}(\mathbf{x}_{T};\mathbf{m}_{T|t} \mathbf{X}_{t}^{\star},\boldsymbol{\Sigma}_{T|t})\right]\right]dt+\sigma d \mathbf{\hat{W}}_{t}^{Q},\] (17)

_where \(\mathbf{m}_{T|t}=e^{(T-t)\mathcal{A}}\) and \(\boldsymbol{\Sigma}_{T|t}=\sigma^{2}\int_{0}^{T-t}e^{(T-t-s)\mathcal{A}}Qe^{(T -t-s)\mathcal{A}}ds\) and \(\mathbf{X}_{t}^{\star}\sim\mu_{t}\) for \(t\in[0,T]\)._

Objective Functional for Bridge Matching.With the structure of \(\mathbb{P}^{\star}\) specified in (17) we can estimate the divergence between the optimal target path measure \(\mathbb{P}^{\star}\) and a path measure \(\mathbb{P}^{\alpha}\). To accomplish this, we first define

\[\gamma(t,\mathbf{x};\theta)=Q^{1/2}\left[\mathbb{E}_{\mathbf{x}_{T}\sim \mathbb{P}^{\star}(d\mathbf{x}_{T}|\mathbf{x})}\left[\sigma Q^{1/2}D_{ \mathbf{x}}\log\mathcal{N}(\mathbf{x}_{T};\mathbf{m}_{T|t}\mathbf{X}_{t}^{ \star},\boldsymbol{\Sigma}_{T|t})\right]-\alpha(t,\mathbf{x};\theta)\right].\] (18)

Then, by applying the Girsanov theorem3 which provides us the Radon-Nikodym derivative between \(\mathbb{P}^{\star}\) and \(\mathbb{P}^{\alpha}\), we can derive the cross-entropy loss in equation (16):

Footnote 3: See Sec A.5 for details.

\[D_{\text{cross}}(\mathbb{P}^{\alpha^{\theta}}|\mathbb{P}^{\star})=\mathbb{E}_ {\mathbb{P}^{\star}}\left[\log\frac{d\mathbb{P}^{\star}}{d\mathbb{P}^{\alpha^{ \theta}}}\right]=\mathbb{E}_{\mathbb{P}^{\star}}\left[\int_{0}^{T}\frac{1}{2} \left\|\gamma(t,\mathbf{X}_{t}^{\star};\theta)\right\|_{\mathcal{H}_{0}}^{2} ds\right]\] (19)

Then, under the neural network parameterization of control function \(\alpha^{\theta}\), we can reformulate the SOC problem in (16) as a learning problem with the training loss function represented by:

\[\mathcal{L}_{\text{BM}}(\theta)=\mathbb{E}_{t\sim\mathcal{U}_{0,T}}\mathbb{E} _{\mathbb{P}^{\star}(\mathbf{x}_{T}\sim d\mathbf{x}_{T}|\mathbf{X}_{t}^{ \star})}\left[\frac{1}{2}\left\|\sigma Q^{1/2}D_{\mathbf{x}}\log\mathcal{N}( \mathbf{x}_{T};\mathbf{m}_{T|t}\mathbf{X}_{t}^{\star},\boldsymbol{\Sigma}_{T|t })-\alpha(t,\mathbf{X}_{t}^{\star};\theta)\right\|_{\mathcal{H}}^{2}\right]\] (20)

The \(\mathcal{L}_{\text{BM}}(\theta)\) in (20) yields the infinite-dimensional BM summarized in Alg 1.

``` Input: Initial condition \(\mathbf{x}_{0}\), energy functional \(\mathcal{U}\) for\(n=1,\cdots,N\)do  Simulate \(\mathbf{X}_{0,T}^{\theta^{\theta}}\sim\mathbb{P}^{\alpha^{\theta}}\) with \(\mathbf{X}_{0}^{\theta^{\theta}}=\mathbf{x}_{0}\)  Compute \(\mathcal{L}_{\text{Bayes}}(\theta_{k})\) with (24)  Update \(\theta_{n+1}\) with \(\nabla_{\theta_{n}}\mathcal{L}_{\text{Bayes}}(\theta_{n})\) endfor Output: Approximated optimal control \(\alpha^{\theta^{\star}}\) ```

**Algorithm 2** Bayesian Learning in \(\mathcal{H}\)

### Bayesian Learning in Function Space

In the previous section, we observed that by appropriately defining a terminal cost functional \(G\) in (3), the SOC problem aligns with the sampling problem, where optimal control effectively steersthe distribution from \(\pi_{0}\) to the target distribution \(\pi_{T}\), where we can access samples from \(\pi_{0}\) and \(\pi_{T}\). However, accessing samples from unknown target distribution \(\pi_{T}\) is generally not feasible. For instance, for a \(\pi_{T}\), a posterior distribution over function. In this case, although direct samples from \(\pi_{T}\) are unattainable, its distributional representation is given as [3; 66]:

\[\frac{d\pi_{T}}{d\mu_{\text{prior}}}(\mathbf{X}_{T})\propto\exp\left(-\mathcal{ U}(\mathbf{X}_{T})\right),\quad\mu_{\text{prior}}=\mathcal{N}(\mathbf{m}_{ \text{prior}},Q_{\text{prior}}),\] (21)

where \(\mathcal{U}\) is a energy function. Here, our primary objective is to sample from a distribution over function \(\pi_{T}:=\mu_{T}^{\star}\) by simulating the controlled diffusion process \(\{\mathbf{X}_{t}^{\alpha}\}_{t\in[0,T]}\) over finite horizon \([0,T]\) with \(T<\infty\). It can be represented as a solution of the following SOC problem:

\[\inf_{\alpha}D(\mathbb{P}^{\alpha}|\mathbb{P}^{\star}),\text{ such that }d\mathbf{X}_{t}^{\alpha}=\left[\mathcal{A}\mathbf{X}_{t}^{\alpha}+\sigma Q^{1/2} \alpha_{t}\right]dt+\sigma d\mathbf{\tilde{W}}_{t}^{Q},\quad\mathbf{X}_{0}^{ \alpha}=\mathbf{x}_{0}.\] (22)

The following theorem implies that with a suitable terminal cost functional \(G\) in (3), it is possible to achieve \(\mathbf{X}_{T}^{\alpha^{*}}\sim\pi_{T}\) as an expansion of [54; 71] for infinite dimensional space \(\mathcal{H}\).

**Theorem 3.2** (Exact sampling in \(\mathcal{H}\)).: _Consider that the initial distribution \(\mu_{0}\) is given as the Dirac measure \(\delta_{\mathbf{x}_{0}}\) for some \(\mathbf{x}_{0}\in\mathcal{H}\) and the following objective functional_

\[\mathcal{J}(\alpha)=\mathbb{E}_{\mathbb{P}^{\alpha}}\left[\int_{0}^{T}\frac{1 }{2}\left\|\alpha_{s}\right\|_{\mathcal{H}}^{2}ds-\log\frac{d\pi_{T}}{d\mu_{T} }(\mathbf{X}_{T}^{\alpha})\right]\] (23)

_where \(\mu_{T}=\mathcal{N}(e^{T\mathcal{A}}\mathbf{x}_{0},Q_{T})\) as a marginal distribution of \(\mathbf{X}_{T}\) in (1) with a well-defined terminal cost \(\frac{d\pi_{T}}{d\mu_{T}}\) by Theorem 2.3. Then, \(\mathbf{X}_{T}^{\alpha^{*}}\sim\pi_{T}\)._

Objective Functional for Bayesian Learning.Unlike problem in (16) where we can access to the target path measure \(\mathbb{P}^{*}\) directly, it is not feasible here because \(h(t,\mathbf{x})=\mathbb{E}_{\mathbb{P}}\left[-\frac{d\pi_{T}}{d\mu_{T}}( \mathbf{X}_{T})|\mathbf{X}_{t}=\mathbf{x}\right]\) does not have an explicit solution. Therefore, we will use the relative-entropy loss as our training loss function:

\[\mathcal{L}_{\text{Bayes}}(\theta)=D_{\text{rel}}(\mathbb{P}^{\alpha^{\theta}} |\mathbb{P}^{*})=\mathbb{E}_{\mathbb{P}^{\alpha^{\theta}}}\left[\int_{0}^{T} \frac{1}{2}\left\|\alpha(s,\mathbf{X}_{s}^{\alpha^{\theta}};\theta)\right\|_{ \mathcal{H}}^{2}ds-\log\frac{d\pi_{T}}{d\mu_{T}}(\mathbf{X}_{T}^{\alpha^{ \theta}})\right].\] (24)

The key difference from previous algorithms [73; 77] is that the Radon-Nikodym derivative \(\frac{d\pi_{T}}{d\mu_{T}}(\mathbf{X}_{T}^{\alpha})\) may not be well-defined on \(\mathcal{H}\) due to the absence of the Lesbesgue measure. However, the Theorem 2.3 suggests that by choosing certain classes of Gaussian measure \(i.e.,\mu_{\text{prior}}:=\mathcal{N}(e^{t\mathcal{A}}\mathbf{x},Q_{t})\), the Radon-Nikodym density of \(\frac{d\pi_{T}}{d\mu_{\text{prior}}}\) and \(\frac{d\mu_{T}}{d\mu_{\text{prior}}}\) has explicit form since \(\mu_{\text{prior}}\) and \(\mathcal{N}(0,Q_{\infty})\) are equivalent. Thus, using the chain rule, the terminal cost for any \(\mathbf{x}\in\mathcal{H}\) can be computed as follows:

\[\log\frac{d\pi_{T}}{d\mu_{T}}(\mathbf{x})=-\mathcal{U}(\mathbf{x})-\log\frac{ d\mu_{\text{prior}}}{d\mathcal{N}(0,Q_{\infty})}(\mathbf{x})+\log\frac{d\mu_{T}}{d \mathcal{N}(0,Q_{\infty})}(\mathbf{x}).\] (25)

With \(\mathcal{L}_{\text{Bayes}}(\theta)\) in (24), the infinite-dimensional bayesian learning algorithm is summarized in Alg 2.

## 4 Related Work

Most diffusion models operate within the framework of time-reversal [1], where the generation process is learned from its corresponding time-reversed SDEs [64]. In contrast, diffusion models based on conditioned SDEs, such as diffusion bridges, built upon the theory of Doob's \(h\)-transform, offer a conceptually simpler approach as they solely rely on a forward process. [50] proposes generative models with this concept, showing that the mixture of forward diffusion bridge processes effectively transports between couplings of two distributions. [76] introduces a family of first hitting diffusion models that generate data with a forward diffusion process at a random first hitting time based on Doob's \(h\)-transform. Combining time-reversal with the \(h\)-transform, [46] proposes a diffusion bridge process on constrained domains. Moreover, [51; 61] presented that the Schrodinger bridge problem can be solved by an iterative algorithm, which is improved by [18] to enhance efficiency. Furthermore, [44] generalizes the Schrodinger bridge matching algorithm by introducing an approximation scheme with a non-trivial running cost. Compared to prior works, which primarily focus on finite-dimensional spaces, our work extends the formulation of Doob's \(h\)-transform into Hilbert space, enabling the development of various sampling algorithms in function spaces.

Experiments

This section details the experimental setup and the application of the proposed Diffusion Bridges in Function Spaces (**DBFS**) for generating functional data. We interpret the data from a functional perspective, known as _field_ representation [75; 79], where data are seen as a finite collection of function evaluations \(\{\mathbf{Y}[\mathbf{p}_{i}],\mathbf{p}_{i}\}_{i}^{N}\). Here, a function \(\mathbf{Y}\) maps points \(\mathbf{p}_{i}\) from a coordinate space \(\mathcal{X}\) to a signal space \(\mathcal{Y}\), i.e., \(\mathbf{Y}:\mathcal{X}\rightarrow\mathcal{Y}\). Additional experimental details are provided in Appendix A.8.

### Bridge Matching

First, we present empirical results for the infinite-dimensional BM algorithm discussed in Sec 3.1, applied to 1D and 2D data. For 1D data, we consider \(\mathcal{X}=\mathbb{R}\) and \(\mathcal{Y}=\mathbb{R}\). For 2D data, we assume \(\mathcal{X}=\mathbb{R}^{2}\) and \(\mathcal{Y}=\mathbb{R}\) for probability density or grayscale images, and \(\mathcal{Y}=\mathbb{R}^{3}\) for RGB images.

**Bridging Field.** We begin by validating our bridge matching Algorithm in Alg 1 on bridging probability density function within \(\mathcal{H}\). Specifically, we set \(\pi_{0}:=\delta_{p_{0}}\) with a ring-shaped density function \(p_{0}\) and \(\pi_{T}:=\delta_{p_{T}}\) characterized by a Gaussian mixture density function \(p_{T}\). The functions map each grid points \(\mathbf{p}_{i}\) to the probability in \(\mathcal{Y}=\mathbb{R}\). Therefore, both density functions can be represented as their field representations \(\{p_{0}[\mathbf{p}_{i}],\mathbf{p}_{i}\}_{i}^{N},\{p_{T}[\mathbf{p}_{i}], \mathbf{p}_{i}\}_{i}^{N}\), respectively. Figure 1 illustrates the progressive propagation of the target optimal bridge process \(\mathbb{P}^{\star}\) from \(p_{0}\) to \(p_{T}\). Despite the \(\alpha^{\star}\) is trained on the functions generated from \(\mathbb{P}^{\star}\) which are evaluated on a coarse grid \(\{\mathbf{p}_{i}\}_{i}^{32^{2}}\), \(\mathbb{P}^{\alpha^{\star}}\) is capable of producing accurate functional evaluations on a finer grid \(\{\mathbf{p}_{i}\}_{i}^{256^{2}}\). This resolution-invariance property indicates that our method is adept at learning continuous functional representations, rather than merely memorizing the discrete evaluations.

**1D function generation.** We conducted an experiment on a 1D function generation task, comparing our baseline methods [22; 52] on three datasets: Quadratic, Melbourne, and Gridwatch, following the setup from [52]. For generative modeling, we set the initial distribution \(\pi_{0}\) as \(\mathcal{N}(0,Q)\) with RBF kernel for the covariance operator \(Q\) and the terminal distribution as data distribution \(\pi_{T}\), respectively. We employing the bridge matching algorithm in Alg 1. For quantitative evaluation, we used the power of a kernel two-sample hypothesis test to distinguish between generated and ground-truth samples. Table 1 shows that our method performs comparably to baseline infinite-dimensional methods. Additionaly, The generated samples compared to the ground-truth for each dataset are provided in Figure 2.

**Unpaired Image Transfer.** We compare our proposed model with a finite (fixed)-dimensional baseline through an experiment on unpaired image transfer between the MNIST and EMNIST datasets at \(32^{2}\) resolution, as well as wild and cat images from the AFHQ dataset [14], downsampled to \(64^{2}\) resolution (AFHQ-64). Specifically, we evaluate the performance of [51; 61] and our DBFS model. For a fair comparison, we follow the iterative training scheme of [51] based on

\begin{table}
\begin{tabular}{l|c|c|c} \hline  & **NDP**[22] & **SP-SGM**[52] & **DBFS** (Ours) \\ \hline Quadratic & \(\geq\) 99.0 & 5.4 \(\pm\) 0.7 & **5.1 \(\pm\) 0.4** \\ Melbourne & 12.8 \(\pm\) 0.4 & **5.3 \(\pm\) 0.7** & 9.67 \(\pm\) 0.45 \\ Gridwatch & 16.3 \(\pm\) 1.8 & 4.7 \(\pm\) 0.5 & **3.9 \(\pm\) 0.4** \\ \hline \end{tabular}
\end{table}
Table 1: A Power\((\%)\) of a kernel two-sample test.

Figure 2: Results on 1D function generation. (Left) Real data and (Right) generated samples from our model.

the public repository4, where two forward and backward control networks are trained alternately. For quantitative evaluation, we estimate the FID score between the generated samples and real datasets. We set \(\sigma=1\) for both [51] and our method, while FID scores for [61] are taken from [18]. Table 2 shows that our method performs comparably to the finite-dimensional method. Additionally, we provide generated samples at various unseen resolutions in Figure 3 to demonstrate the resolution-invariant property of our infinite-dimensional models. We note that our method may have slightly lower FID scores compared to finite-dimensional baselines, which may align with the observation in [79] that resolution-agnostic methods tend to have lower FID scores compared to resolution-specific ones. This could be because resolution-specific methods can incorporate domain-specific design features in their score networks. Samples generated from the reverse direction can be found in Figure A.2.

Footnote 4: https://github.com/stepelu/idbm-pytorch, under MIT License.

### Bayesian Learning

We validate our Bayesian learning algorithm for modeling functional data. Specifically, we will consider the temporal data as a function. We denote \(\mathbf{Y}[\mathbf{O}]=\{\mathbf{Y}[\mathbf{p}_{i}]\}_{i=1}^{|\mathbf{O}|}\) as a collection of a function evaluation on a set of 1-dimensional observation grid \(\mathbf{O}=\{\mathbf{p}_{i}\}_{i}^{|\mathbf{O}|}\) where \(0\leq\mathbf{p}_{0}<\cdots<\mathbf{p}_{|\mathbf{O}|}\leq I\). We assume that each observed time series approximates a corresponding underlying continuous function \(\mathbf{X}:\mathbb{R}\rightarrow\mathbb{R}^{d}\) as the number of observations increases \(\bm{i.e.},\{\mathbf{Y}[\mathbf{p}_{i}]\}_{i=1}^{|\mathbf{O}|\rightarrow\infty} \approx\mathbf{X}\). For given observations \(\mathbf{Y}[\mathbf{O}]\), our goal is to infer the posterior distribution on some set of unobserved grid \(\mathbf{T}=[0,I]-\mathbf{O}\)\(\bm{i.e.},\mathbb{P}(\mathbf{Y}[\mathbf{T}]|\mathbf{Y}[\mathbf{O}])\) and therefore modeling distribution over \(\mathbf{X}\) on \([0,I]\). Please refer to Section A.8.2 for further details.

Functional RegressionTo verify the effectiveness of the proposed DBFS in generating functions in the 1D domain, we conducted regression experiments using synthetic data generated from the Gaussian Process (GP) by following the experimental settings in [38]. Figure 4 shows the sampled trajectories of a controlled dynamics \(\mathbf{X}_{t}^{\alpha}\) for \(t\in[0,\frac{T}{2},T]\) trained on data generated from GP with RBF covariance kernel. The stochastic process begins from the deterministic function \(\mathbf{X}_{0}^{\alpha}=\mathbf{x}_{0}\) at \(t=0\) and propagates towards the conditional posterior distribution \(\mathbf{X}_{T}^{\alpha}\sim\mathbb{P}(\mathbf{Y}[\mathbf{T}]|\mathbf{Y}[ \mathbf{O}])\) at \(t=T\).

\begin{table}
\begin{tabular}{c|c c} \hline Method & **(A)** & **(B)** \\ \hline IDBM [51] & 8.2 & - \\ DSDM\({}^{\dagger}\)[61] & **6.0** & **25.4** \\ \hline
**DBFS** (Ours) & 9.1 & 44.4 \\ \hline \end{tabular} \(\dagger\) result from [18].

\end{table}
Table 2: Test FID on unpaired image transfer task. **(A)** EMNIST \(\rightarrow\) MNIST, **(B)** AFHQ-64 Wild \(\rightarrow\) Cat. (Left) Real data and (Right) generated samples from our model. For generation at unseen resolutions, the images within the red and blue boxed initial conditions were upsampled (using bi-linear transformation) from the observed resolution (\(32^{2}\)) for EMNIST and (\(64^{2}\)) for AFHQ-64 Wild, respectively.

Figure 3: Results on Unpaired image transfer task. **(Up)** EMNIST \(\rightarrow\) MNIST **(Down)** AFHQ-64 Wild \(\rightarrow\) Cat. (Left) Real data and (Right) generated samples from our model. For generation at unseen resolutions, the images within the red and blue boxed initial conditions were upsampled (using bi-linear transformation) from the observed resolution (\(32^{2}\)) for EMNIST and (\(64^{2}\)) for AFHQ-64 Wild, respectively.

Imputation.We evaluate our method against recent diffusion-based imputation method where the goal is to infer the conditional distribution \(p(\mathbf{Y}[\mathbf{T}]|\mathbf{Y}[\mathbf{O}])\) of unobserved grid \(\mathbf{Y}[\mathbf{T}]\) give observations \(\mathbf{Y}[\mathbf{O}]\). CSDI [68] utilizes DDPM [34] to learn the reverse process by treating the temporal data \(\mathbf{Y}[\mathbf{O}]\) as a \(\mathbb{R}^{|\mathbf{O}|\times d}\) dimensional feature. Extending this, DSDP-GP [6] enhances CSDI by incorporating noise derived from a stochastic process, instead of simple Gaussian noise. We maintained the same training setup as these models, including random seeds and the model architecture for control \(\alpha^{\theta}\) in (2). Consistent with their methodology, we employed the Physionet dataset [30], which comprises medical time-series data collected on an hourly rate. Since the dataset inherently contains missing values, we selected certain degrees of observed values to create an imputation test set for evaluation. We then reported the results on this test set, varying the degrees of missingness. Table 3 shows that we outperform the previous methods even though it solely relies on forward propagation of controlled SDEs in (9) without denoising procedure.

## 6 Conclusion and Limitation

In this work, we shed light on the application of the infinite-dimensional Doob's \(h\)-transform, exploiting SOC theory in infinite-dimensional spaces. By developing an explicit Radon-Nikodym density, we address the challenge posed by the absence of an equivalent to the Lebesgue measure. With specified cost functions for control objectives, it enables us to extend previous algorithm based on the finite-dimensional Doob's \(h\)-transform into infinite-dimensional function spaces, such as resolution-free unpaired image transfer and functional Bayesian posterior sampling.

Compared to the recent infinite-dimensional score-based diffusion model [42], our work restricts the coefficients for the stochastic dynamics to be time-independent. This limitation prevents us from defining a noise schedule for the diffusion model [78], which may hinder performance improvements. Additionally, in Bayesian learning, computing the gradient of the proposed training loss function (24) can be computationally demanding. Thus, developing a more scalable algorithm would be an interesting direction for future work. Furthermore, as our model can be applied to any functional domain, we have limited our experiments to regular 1D and 2D domains, leaving the extension to more general domains for future work.

## Broader Societal Impact

Similar to other works in the literature, our proposed method holds the potential for both beneficial outcomes, such as automated data synthesis, and adverse implications, such as the deep fakes, depending on how it is used. We adhere to ethical standards for using our model in generative AI.

\begin{table}
\begin{tabular}{c|c c|c c|c c} \hline \hline \multirow{2}{*}{Method} & \multicolumn{2}{c}{RBF} & \multicolumn{2}{c}{Mat\#rn 5/2} & \multicolumn{2}{c}{Periodic} \\ \cline{2-7}  & context & target & context & target & context & target \\ \hline CNP & 0.97 \(\pm\) 0.01 & 0.45 \(\pm\) 0.01 & 0.85\(\pm\) 0.01 & 0.21 \(\pm\) 0.02 & -0.16\(\pm\) 0.01 & -1.75 \(\pm\) 0.02 \\ NP & 0.90 \(\pm\) 0.01 & 0.42 \(\pm\) 0.01 & 0.77 \(\pm\) 0.01 & 0.20 \(\pm\) 0.03 & -0.18 \(\pm\) 0.01 & -1.34 \(\pm\) 0.03 \\ \hline
**DBFS** & **1.02 \(\pm\) 0.01** & **0.47 \(\pm\) 0.01** & **0.93 \(\pm\) 0.01** & **0.25 \(\pm\) 0.01** & **-0.15 \(\pm\) 0.01** & -1.88 \(\pm\) 0.02 \\ \hline \hline \end{tabular}
\end{table}
Table 4: Regression results. “context” and “target” refer to the log-likelihoods at \(\mathbf{O}\) and \(\mathbf{T}\), respectively.

Figure 4: Sampled functions from a learned stochastic process \(\mathbf{X}_{t}^{\alpha}\) evaluated on \([0,I]\) for \(t\in[0,\frac{T}{2},T]\). The grey line represents the mean function \(\mathbb{E}[\mathbf{X}_{t}^{\alpha}]\) and the blue-shaded region represents the confidence interval. (Left) GP with RBF kernel. (Right) Physionet.

\begin{table}
\begin{tabular}{c|c|c|c} \hline \hline Model & \(10\%\) & \(50\%\) & \(90\%\) \\ \hline CSDI\({}^{\dagger}\)[68] & 0.60 \(\pm\) 0.27 & 0.66 \(\pm\) 0.06 & 0.84 \(\pm\) 0.04 \\ DSDP-GP\({}^{\dagger}\)[6] & 0.52 \(\pm\) 0.04 & 0.64 \(\pm\) 0.05 & 0.81 \(\pm\) 0.03 \\ \hline
**DBFS** (Ours) & **0.50 \(\pm\) 0.04** & **0.61 \(\pm\) 0.04** & **0.77 \(\pm\) 0.03** \\ \hline \hline \end{tabular} \(\dagger\) results from [6].

\end{table}
Table 3: Test imputation RMSE on Physionet.

## Acknowledgements

This work was partly supported by Institute of Information & communications Technology Planning & Evaluation(IITP) grant funded by the Korea government(MSIT) (No.RS-2019-II190075, Artificial Intelligence Graduate School Program(KAIST), No.2022-0-00184, Development and Study of AI Technologies to Inexpensively Conform to Evolving Policy on Ethics, No. 2022-0-00612, Geometric and Physical Commonsense Reasoning based Behavior Intelligence for Embodied AI) and the National Research Foundation of Korea(NRF) grant funded by the Korea government(MSIT) (NRF-2021M3E5D9025030, NRF-2022R1A5A708390812, RS-2024-00410082).

## References

* [1] Brian D.O. Anderson. Reverse-time diffusion equation models. _Stochastic Processes and their Applications_, 12(3):313-326, 1982.
* [2] Elizabeth Louise Baker, Gefan Yang, Michael L Severinsen, Christy Anna Hipsley, and Stefan Sommer. Conditioning non-linear and infinite-dimensional diffusion processes. _arXiv preprint arXiv:2402.01434_, 2024.
* [3] Lorenzo Baldassari, Ali Siahkoohi, Josselin Garnier, Knut Solna, and Maarten V de Hoop. Conditional score-based diffusion models for bayesian inference in infinite dimensions. _Advances in Neural Information Processing Systems_, 36, 2024.
* [4] Y.I. Belopolskaya and Y.L. Dalecky. _Stochastic Equations and Differential Geometry_. Mathematics and its Applications. Springer Netherlands, 2012.
* [5] Julius Berner, Lorenz Richter, and Karen Ullrich. An optimal control perspective on diffusion-based generative modeling. _Transactions on Machine Learning Research_, 2024.
* [6] Marin Bilos, Kashif Rasul, Anderson Schneider, Yuriy Nevmyvaka, and Stephan Gunnemann. Modeling temporal data as continuous functions with stochastic process diffusion. In _International Conference on Machine Learning_, pages 2452-2470. PMLR, 2023.
* [7] Vladimir Bogachev, Giuseppe Da Prato, and Michael Rockner. Uniqueness for solutions of fokker-planck equations on infinite dimensional spaces. _Communications in Partial Differential Equations_, 36(6):925-939, 2011.
* [8] R. Carmona and F. Delarue. _Probabilistic Theory of Mean Field Games with Applications I: Mean Field FBSDEs, Control, and Games_. Probability Theory and Stochastic Modelling. Springer International Publishing, 2018.
* [9] Pratik Chaudhari, Adam Oberman, Stanley Osher, Stefano Soatto, and Guillaume Carlier. Deep relaxation: partial differential equations for optimizing deep neural networks. _Research in the Mathematical Sciences_, 5:1-30, 2018.
* [10] Tianrong Chen, Jiatao Gu, Laurent Dinh, Evangelos Theodorou, Joshua M. Susskind, and Shuangfei Zhai. Generative modeling with phase stochastic bridge. In _The Twelfth International Conference on Learning Representations_, 2024.
* [11] Tianrong Chen, Guan-Horng Liu, and Evangelos Theodorou. Likelihood training of schrodinger bridge using forward-backward SDEs theory. In _International Conference on Learning Representations_, 2022.
* [12] Yongxin Chen, Tryphon T. Georgiou, and Michele Pavon. Stochastic control liaisons: Richard sinkhorn meets gaspard monge on a schrodinger bridge. _SIAM Review_, 63(2):249-313, 2021.
* [13] Raphael Chetrite and Hugo Touchette. Nonequilibrium markov processes conditioned on large deviations. In _Annales Henri Poincare_, volume 16, pages 2005-2057. Springer, 2015.
* [14] Yunjey Choi, Youngjung Uh, Jaejun Yoo, and Jung-Woo Ha. Stargan v2: Diverse image synthesis for multiple domains. In _Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_, 2020.

* [15] G. Da Prato and J. Zabczyk. Differentiability of the feynman-kac semigroup and a control application. _Atti della Accademia Nazionale dei Lincei. Classe di Scienze Fisiche, Matematiche e Naturali. Rendiconti Lincei. Matematica e Applicazioni_, 8(3):183-188, 10 1997.
* [16] G. Da Prato and J. Zabczyk. _Second Order Partial Differential Equations in Hilbert Spaces_. London Mathematical Society Lecture Note Series. Cambridge University Press, 2002.
* [17] G. Da Prato and J. Zabczyk. _Stochastic Equations in Infinite Dimensions_. Encyclopedia of Mathematics and its Applications. Cambridge University Press, 2014.
* [18] Valentin De Bortoli, Iryna Korshunova, Andriy Mnih, and Arnaud Doucet. Schr\(\backslash\)" odinger bridge flow for unpaired data translation. _arXiv preprint arXiv:2409.09347_, 2024.
* [19] Valentin De Bortoli, James Thornton, Jeremy Heng, and Arnaud Doucet. Diffusion schrodinger bridge with applications to score-based generative modeling. _Advances in Neural Information Processing Systems_, 34:17695-17709, 2021.
* [20] Carles Domingo-Enrich, Jiequ Han, Brandon Amos, Joan Bruna, and Ricky TQ Chen. Stochastic optimal control matching. _arXiv preprint arXiv:2312.02027_, 2023.
* [21] Emilien Dupont, Adam Golinski, Milad Alizadeh, Yee Whye Teh, and Arnaud Doucet. Coin: Compression with implicit neural representations. _arXiv preprint arXiv:2103.03123_, 2021.
* [22] Vincent Dutordoir, Alan Saul, Zoubin Ghahramani, and Fergus Simpson. Neural diffusion processes. In _International Conference on Machine Learning_, pages 8990-9012. PMLR, 2023.
* [23] Giorgio Fabbri, Fausto Gozzi, and Andrzej Swiech. Stochastic optimal control in infinite dimension. _Probability and Stochastic Modelling. Springer_, 2017.
* [24] Wendell H Fleming and Halil Mete Soner. _Controlled Markov processes and viscosity solutions_, volume 25. Springer Science & Business Media, 2006.
* [25] Giulio Franzese, Giulio Corallo, Simone Rossi, Markus Heinonen, Maurizio Filippone, and Pietro Michiardi. Continuous-time functional diffusion processes. _Advances in Neural Information Processing Systems_, 36, 2024.
* [26] Marco Fuhrman. A class of stochastic optimal control problems in hilbert spaces: Bsdes and optimal control laws, state constraints, conditioned processes. _Stochastic processes and their applications_, 108(2):263-298, 2003.
* [27] Marta Garnelo, Dan Rosenbaum, Christopher Maddison, Tiago Ramalho, David Saxton, Murray Shanahan, Yee Whye Teh, Danilo Rezende, and S. M. Ali Eslami. Conditional neural processes. In Jennifer Dy and Andreas Krause, editors, _Proceedings of the 35th International Conference on Machine Learning_, volume 80 of _Proceedings of Machine Learning Research_, pages 1704-1713. PMLR, 10-15 Jul 2018.
* [28] Marta Garnelo, Jonathan Schwarz, Dan Rosenbaum, Fabio Viola, Danilo J. Rezende, S. M. Ali Eslami, and Yee Whye Teh. Neural processes, 2018.
* [29] L. Gawarecki and V. Mandrekar. _Stochastic Differential Equations in Infinite Dimensions: with Applications to Stochastic Partial Differential Equations_. Probability and Its Applications. Springer Berlin Heidelberg, 2010.
* [30] A. L. Goldberger, L. A. N. Amaral, L. Glass, J. M. Hausdorff, P. Ch. Ivanov, R. G. Mark, J. E. Mietus, G. B. Moody, C.-K. Peng, and H. E. Stanley. PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals. _Circulation_, 101(23):e215-e220, 2000 (June 13). Circulation Electronic Pages: http://circ.ahajournals.org/content/101/23/e215.full PMID:1085218; doi: 10.1161/01.CIR.101.23.e215.
* [31] Ben Goldys and Bohdan Maslowski. The ornstein-uhlenbeck bridge and applications to markov semigroups. _Stochastic processes and their applications_, 118(10):1738-1767, 2008.

* [32] Paul Hagemann, Sophie Mildenberger, Lars Ruthotto, Gabriele Steidl, and Nicole Tianjiao Yang. Multilevel diffusion: Infinite dimensional score-based diffusion models for image generation. _arXiv preprint arXiv:2303.04772_, 2023.
* [33] Carsten Hartmann, Omar Kebiri, Lara Neureither, and Lorenz Richter. Variational approach to rare event simulation using least-squares regression. _Chaos: An Interdisciplinary Journal of Nonlinear Science_, 29(6), 2019.
* [34] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. _Advances in neural information processing systems_, 33:6840-6851, 2020.
* [35] Lars Holdijk, Yuanqi Du, Priyank Jaini, Ferry Hooft, Bernd Ensing, and Max Welling. Path integral stochastic optimal control for sampling transition paths. In _ICML 2022 2nd AI for Science Workshop_, 2022.
* [36] Andrew Jaegle, Sebastian Borgeaud, Jean-Baptiste Alayrac, Carl Doersch, Catalin Ionescu, David Ding, Skanda Koppula, Daniel Zoran, Andrew Brock, Evan Shelhamer, Olivier J Henaff, Matthew Botvinick, Andrew Zisserman, Oriol Vinyals, and Joao Carreira. Perceiver IO: A general architecture for structured inputs & outputs. In _International Conference on Learning Representations_, 2022.
* [37] Nikola Kovachki, Zongyi Li, Burigede Liu, Kamyar Azizzadenesheli, Kaushik Bhattacharya, Andrew Stuart, and Anima Anandkumar. Neural operator: Learning maps between function spaces with applications to pdes. _Journal of Machine Learning Research_, 24(89):1-97, 2023.
* [38] Juho Lee, Yoonho Lee, Jungtaek Kim, Eunho Yang, Sung Ju Hwang, and Yee Whye Teh. Bootstrapping neural processes. _Advances in neural information processing systems_, 33:6606-6615, 2020.
* [39] Zijie Li, Kazem Meidani, and Amir Barati Farimani. Transformer for partial differential equations' operator learning. _Transactions on Machine Learning Research_, 2023.
* [40] Zongyi Li, Nikola Borislavov Kovachki, Kamyar Azizzadenesheli, Burigede liu, Kaushik Bhattacharya, Andrew Stuart, and Anima Anandkumar. Fourier neural operator for parametric partial differential equations. In _International Conference on Learning Representations_, 2021.
* [41] Jae Hyun Lim, Nikola B Kovachki, Ricardo Baptista, Christopher Beckham, Kamyar Azizzadenesheli, Jean Kossaifi, Vikram Voleti, Jiaming Song, Karsten Kreis, Jan Kautz, et al. Score-based diffusion models in function space. _arXiv preprint arXiv:2302.07400_, 2023.
* [42] Sungbin Lim, Eunbi Yoon, Taehyun Byun, Taewoon Kang, Seungwoo Kim, Kyungjae Lee, and Sungjoon Choi. Score-based generative modeling through stochastic evolution equations in hilbert spaces. In _Thirty-seventh Conference on Neural Information Processing Systems_, 2023.
* [43] Guan-Horng Liu, Tianrong Chen, Oswin So, and Evangelos Theodorou. Deep generalized schrodinger bridge. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, _Advances in Neural Information Processing Systems_, 2022.
* [44] Guan-Horng Liu, Yaron Lipman, Maximilian Nickel, Brian Karrer, Evangelos Theodorou, and Ricky T. Q. Chen. Generalized schrodinger bridge matching. In _The Twelfth International Conference on Learning Representations_, 2024.
* [45] Guan-Horng Liu, Arash Vahdat, De-An Huang, Evangelos A Theodorou, Weili Nie, and Anima Anandkumar. I\({}^{2}\)sb: Image-to-image schrodinger bridge. _arXiv preprint arXiv:2302.05872_, 2023.
* [46] Xingchao Liu, Lemeng Wu, Mao Ye, and qiang liu. Learning diffusion bridges on constrained domains. In _The Eleventh International Conference on Learning Representations_, 2023.
* [47] S.K. Mitter. Filtering and stochastic control: a historical perspective. _IEEE Control Systems Magazine_, 16(3):67-76, 1996.
* [48] Nikolas Nusken and Lorenz Richter. Solving high-dimensional hamilton-jacobi-bellman pdes using neural networks: perspectives from the theory of controlled diffusions and measures on path space. _Partial differential equations and applications_, 2:1-48, 2021.

* [49] William Peebles and Saining Xie. Scalable diffusion models with transformers. In _Proceedings of the IEEE/CVF International Conference on Computer Vision_, pages 4195-4205, 2023.
* [50] Stefano Peluchetti. Non-denoising forward-time diffusions, 2022.
* [51] Stefano Peluchetti. Diffusion bridge mixture transports, schrodinger bridge problems and generative modeling. _Journal of Machine Learning Research_, 24(374):1-51, 2023.
* [52] Angus Phillips, Thomas Seror, Michael Hutchinson, Valentin De Bortoli, Arnaud Doucet, and Emile Mathieu. Spectral diffusion processes. _arXiv preprint arXiv:2209.14125_, 2022.
* [53] Jakiw Pidstrigach, Youssef Marzouk, Sebastian Reich, and Sven Wang. Infinite-dimensional diffusion models for function spaces. _arXiv e-prints_, pages arXiv-2302, 2023.
* [54] Paolo Dai Pra. A stochastic control approach to reciprocal diffusion processes. _Applied Mathematics and Optimization_, 23:313-329, 1991.
* [55] Sebastian Reich. Data assimilation: the schrodinger perspective. _Acta Numerica_, 28:635-711, 2019.
* [56] Lorenz Richter. _Solving high-dimensional PDEs, approximation of path space measures and importance sampling of diffusions_. PhD thesis, BTU Cottbus-Senftenberg, 2021.
* [57] Lorenz Richter and Julius Berner. Improved sampling via learned diffusions. In _The Twelfth International Conference on Learning Representations_, 2024.
* [58] Severi Rissanen, Markus Heinonen, and Arno Solin. Generative modelling with inverse heat dissipation. In _The Eleventh International Conference on Learning Representations_, 2023.
* [59] L Chris G Rogers and David Williams. _Diffusions, Markov processes and martingales: Volume 2, Ito calculus_, volume 2. Cambridge university press, 2000.
* [60] S. Sarkka and A. Solin. _Applied Stochastic Differential Equations_. Institute of Mathematical Statistics Textbooks. Cambridge University Press, 2019.
* [61] Yuyang Shi, Valentin De Bortoli, Andrew Campbell, and Arnaud Doucet. Diffusion schrodinger bridge matching. _Advances in Neural Information Processing Systems_, 36, 2024.
* [62] Isabel Simao. Regular transition densities for infinite dimensional diffusions. _Stochastic Analysis and Applications_, 11(3):309-336, 1993.
* [63] Vincent Sitzmann, Julien Martel, Alexander Bergman, David Lindell, and Gordon Wetzstein. Implicit neural representations with periodic activation functions. _Advances in neural information processing systems_, 33:7462-7473, 2020.
* [64] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. In _International Conference on Learning Representations_, 2021.
* [65] Shengyang Sun, Guodong Zhang, Jiaxin Shi, and Roger Grosse. FUNCTIONAL VARIATIONAL BAYESIAN NEURAL NETWORKS. In _International Conference on Learning Representations_, 2019.
* [66] Taiji Suzuki. Generalization bound of globally optimal non-convex neural network training: Transportation map estimation by infinite dimensional langevin dynamics. _Advances in Neural Information Processing Systems_, 33:19224-19237, 2020.
* [67] Matthew Tancik, Pratul Srinivasan, Ben Mildenhall, Sara Fridovich-Keil, Nithin Raghavan, Utkarsh Singhal, Ravi Ramamoorthi, Jonathan Barron, and Ren Ng. Fourier features let networks learn high frequency functions in low dimensional domains. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin, editors, _Advances in Neural Information Processing Systems_, volume 33, pages 7537-7547. Curran Associates, Inc., 2020.

* [68] Yusuke Tashiro, Jiaming Song, Yang Song, and Stefano Ermon. Csdi: Conditional score-based diffusion models for probabilistic time series imputation. In _Advances in Neural Information Processing Systems_, 2021.
* [69] Evangelos A. Theodorou, George I. Boutselis, and Kaivalya Bakshi. Linearly solvable stochastic optimal control for infinite-dimensional systems. In _2018 IEEE Conference on Decision and Control (CDC)_, pages 4110-4116, 2018.
* [70] Alexander Tong, Kilian FATRAS, Nikolay Malkin, Guillaume Huguet, Yanlei Zhang, Jarrid Rector-Brooks, Guy Wolf, and Yoshua Bengio. Improving and generalizing flow-based generative models with minibatch optimal transport. _Transactions on Machine Learning Research_, 2024. Expert Certification.
* [71] Belinda Tzen and Maxim Raginsky. Theoretical guarantees for sampling and inference in generative models with latent diffusions. In _COLT_, 2019.
* [72] Ramon Van Handel. Stochastic calculus, filtering, and stochastic control. _Course notes., URL http://www. princeton. edu/rvan/acm217/ACM217. pdf_, 14, 2007.
* [73] Francisco Vargas, Andrius Ovsianas, David Fernandes, Mark Girolami, Neil D Lawrence, and Nikolas Nusken. Bayesian learning via neural schrodinger-follmer flows. _Statistics and Computing_, 33(1):3, 2023.
* [74] Ziyu Wang, Tongzheng Ren, Jun Zhu, and Bo Zhang. Function space particle optimization for Bayesian neural networks. In _International Conference on Learning Representations_, 2019.
* [75] Yiheng Xie, Towaki Takikawa, Shunsuke Saito, Or Litany, Shiqin Yan, Numair Khan, Federico Tombari, James Tompkin, Vincent Sitzmann, and Srinath Sridhar. Neural fields in visual computing and beyond. _Computer Graphics Forum_, 41(2):641-676, 2022.
* [76] Mao Ye, Lemeng Wu, and qiang liu. First hitting diffusion models for generating manifold, graph and categorical data. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, _Advances in Neural Information Processing Systems_, 2022.
* [77] Qinsheng Zhang and Yongxin Chen. Path integral sampler: A stochastic control approach for sampling. In _International Conference on Learning Representations_, 2022.
* [78] Linqi Zhou, Aaron Lou, Samar Khanna, and Stefano Ermon. Denoising diffusion bridge models. In _The Twelfth International Conference on Learning Representations_, 2024.
* [79] Peiye Zhuang, Samira Abnar, Jiatao Gu, Alex Schwing, Joshua M. Susskind, and Miguel Angel Bautista. Diffusion probabilistic fields. In _The Eleventh International Conference on Learning Representations_, 2023.

Appendix

### Verification Theorem and Markov control

For the derivation, we will use the following assumption

**Assumption A.1**.: _The function \(\mathcal{V}:[0,T]\times\mathcal{H}\to\mathbb{R}\) and its derivatives \(D_{\mathbf{x}}\mathcal{V},D_{\mathbf{x}\mathbf{x}}\mathcal{V},\partial_{t} \mathcal{V}\) are uniformly continuous on bounded subsets of \([0,T]\times\mathcal{H}\) and \((0,T)\times\mathcal{H}\), respectively. Moreover, for all \((t,\mathbf{x})\in(0,T)\times\mathcal{H}\), there exists \(C_{1},C_{2}>0\) such that_

\[|\mathcal{V}(t,\mathbf{x})|+|D_{\mathbf{x}}\mathcal{V}(t,\mathbf{x})|+| \partial_{t}\mathcal{V}(t,\mathbf{x})|+\|D_{\mathbf{x}\mathbf{x}}\mathcal{V}(t,\mathbf{x})\|+|\mathcal{A}^{\star}D_{\mathbf{x}}\mathcal{V}(t,\mathbf{x})| \leq C_{1}(1+|\mathbf{x}|)^{C_{2}},\] (A.1)

_where \(\mathcal{A}^{\star}\) is adjoint operator of \(\mathcal{A}\)._

The HJB equation (4) can be derived by the following theorem.

**Theorem A.2**.: _Let assumptions A.1 hold and let the function \(\mathcal{V}\) with \(\mathcal{V}(T,\mathbf{x})=G(\mathbf{x})\) satisfying the dynamic programming principle for every \(0<t<t^{\prime}<T\), \(x\in\mathcal{H}\)_

\[\mathcal{V}(t,\mathbf{x})=\mathbb{E}_{\mathbb{P}^{\alpha}}\left[\int_{t}^{t^ {\prime}}\left[l(s,\mathbf{X}_{t}^{\alpha})+\psi(\alpha_{s})\right]ds+ \mathcal{V}(t^{\prime},\mathbf{X}_{t^{\prime}})|\mathbf{X}_{t}^{\alpha}= \mathbf{x}\right].\] (A.2)

_Then \(\mathcal{V}\) is a solution of the following equation:_

\[\partial_{t}\mathcal{V}+\mathcal{L}\mathcal{V}+\inf_{\alpha\in\mathcal{U}} \left[\langle\sigma Q_{\mathbf{x}}^{1/2}\mathcal{V},\alpha\rangle+\frac{1}{2} \left\|\alpha\right\|^{2}\right]=0,\quad\mathcal{V}(T,\mathbf{x})=G(\mathbf{x }),\] (A.3)

Proof.: The proof can be found in [23, Theorem 2.34]. 

#### a.1.1 Proof of Lemma 2.1

Proof.: To begin the proof, we can formally compute the minimum of \(F(D_{\mathbf{x}}\mathcal{V})\). Since [15]

\[F(\mathbf{x})=\inf_{\alpha\in\mathcal{U}}\left[\langle\mathbf{x},\alpha \rangle+\frac{1}{2}\left\|\alpha\right\|^{2}\right]=-\frac{1}{2}\left\|\mathbf{ x}\right\|^{2}.\] (A.4)

Therefore, \(F(\sigma Q^{1/2}D_{\mathbf{x}}\mathcal{V})\) takes the infimum at \(\alpha^{*}=-\sigma Q^{1/2}D_{\mathbf{x}}\mathcal{V}\). Next, applying Ito's formula [23, Proposition 1.165] to \(\mathcal{V}\) and taking expectation on both sides, we get

\[\mathbb{E}_{\mathbb{P}^{\alpha}}^{t,\mathbf{x}}\left[\mathcal{V}(T,\mathbf{X} _{T}^{\alpha})\right]=\mathcal{V}(t,\mathbf{x})+\mathbb{E}_{\mathbb{P}^{ \alpha}}^{t,\mathbf{x}}\left[\int_{t}^{T}\left(\partial_{t}\mathcal{V}(s, \mathbf{X}_{s}^{\alpha})+\mathcal{L}\mathcal{V}(s,\mathbf{X}_{s}^{\alpha})+ \langle\sigma Q^{1/2}D_{\mathbf{x}}\mathcal{V}(s,\mathbf{X}_{s}^{\alpha}), \alpha_{s}\rangle\right)ds\right],\] (A.5)

where we denote \(\mathbb{E}_{\mathbb{P}^{\alpha}}^{t,\mathbf{x}}\left[\cdot\right]=\mathbb{E}_ {\mathbb{P}^{\alpha}}\left[\cdot|\mathbf{X}_{t}=\mathbf{x}\right]\) By incorporating the fact that \(\mathcal{V}\) satisfies the equation in (A.3), we can derive the following by adding \(\mathbb{E}_{\mathbb{P}^{\alpha}}^{t,\mathbf{x}}\left[\int_{t}^{T}\frac{1}{2} \left\|\alpha_{s}\right\|^{2}ds\right]\) to both terms. The LHS of the equation (A.5) becomes:

\[\mathbb{E}_{\mathbb{P}^{\alpha}}^{t,\mathbf{x}}\left[\underbrace{\mathcal{V}( T,\mathbf{X}_{T}^{\alpha})}_{=G(\mathbf{X}_{T}^{\alpha})}\right]+\mathbb{E}_{ \mathbb{P}^{\alpha}}^{t,\mathbf{x}}\left[\int_{t}^{T}\frac{1}{2}\left\|\alpha_ {s}\right\|^{2}ds\right]=\mathcal{J}(t,\mathbf{x},\alpha).\] (A.6)

And for the RHS of the equation (A.5):

\[\mathcal{V}(t,\mathbf{x})+\mathbb{E}_{\mathbb{P}^{\alpha}}^{t, \mathbf{x}}\left[\int_{t}^{T}\frac{1}{2}\left\|\alpha_{s}\right\|^{2}ds\right] +\mathbb{E}_{\mathbb{P}^{\alpha}}^{t,\mathbf{x}}\bigg{[}\int_{t}^{T}\left( \partial_{t}\mathcal{V}(s,\mathbf{X}_{s}^{\alpha})+\mathcal{L}\mathcal{V}(s, \mathbf{X}_{s}^{\alpha})+\langle\sigma Q^{1/2}D_{\mathbf{x}}\mathcal{V}(s, \mathbf{X}_{s}^{\alpha}),\alpha_{s}\rangle\right)ds\bigg{]}\] (A.7)where the last equation can be derived by adding and subtracting \(\mathbb{E}_{\mathbb{P}^{\alpha}}^{t,\mathbf{x}}\left[\int_{t}^{T}F(D_{\mathbf{x}} \mathcal{V}(s,\mathbf{X}_{s}^{\alpha})ds\right]\) and incorporating the fact that \(\mathcal{V}\) satisfies the equation in (A.3) again. Hence, we get the following equation:

\[\mathcal{J}(t,\mathbf{x},\alpha)=\mathcal{V}(t,\mathbf{x})+ \mathbb{E}_{\mathbb{P}^{\alpha}}^{t,\mathbf{x}}\left[\int_{t}^{T}\left(\left[ \langle\sigma Q^{1/2}D_{\mathbf{x}}\mathcal{V}(s,\mathbf{X}_{s}^{\alpha}), \alpha_{s}\rangle+\frac{1}{2}\left\|\alpha_{s}\right\|^{2}\right]-F(\sigma Q^{1 /2}D_{\mathbf{x}}\mathcal{V}(s,\mathbf{X}_{s}^{\alpha}))\right)ds\right]\] (A.8)

Since, by definition

\[\left[\langle\sigma Q^{1/2}D_{\mathbf{x}}\mathcal{V}(s,\mathbf{X}_{s}^{\alpha }),\alpha_{s}\rangle+\frac{1}{2}\left\|\alpha_{s}\right\|^{2}\right]-F(D_{ \mathbf{x}}\mathcal{V}(s,\mathbf{X}_{s}^{\alpha}))\geq 0\] (A.9)

Therefore, by taking the infimum over \(\alpha\in\mathcal{U}\) in the RHS of (A.8),

\[\mathcal{J}(t,\mathbf{x},\alpha)\geq\mathcal{V}(t,\mathbf{x})\] (A.10)

Moreover, since we already verified that the \(F(\sigma Q^{1/2}D_{\mathbf{x}}\mathcal{V})\) has infimum at \(\alpha^{*}=-\sigma Q^{1/2}D_{\mathbf{x}}\mathcal{V}\). Therefore, by choosing \(u=\alpha^{*}\), we have

\[\left[\langle\sigma Q^{1/2}D_{\mathbf{x}}\mathcal{V}(s,\mathbf{X}_{s}^{u}),u _{s}\rangle+\frac{1}{2}\left\|u_{s}\right\|^{2}\right]-F(\sigma Q^{1/2}D_{ \mathbf{x}}\mathcal{V}(s,\mathbf{X}_{s}^{u}))=0\] (A.11)

Thus, we get

\[\mathcal{J}(t,\mathbf{x},u)=\mathcal{V}(t,\mathbf{x}).\] (A.12)

Therefore, together with (A.8), this implies that \((\alpha^{*},\mathbf{X}^{\alpha^{*}})\) is optimal at \((t,\mathbf{x})\in[0,T]\times\mathcal{H}\) This concludes the proof. 

#### a.1.2 Markov Control Formulation

Now, we introduce the following corollary that states the Markov control formulation.

**Corollary A.3** (Markov Control [23]).: _Let us consider the measurable function \(\phi_{t}:(t,T)\times\mathcal{H}\rightarrow\mathcal{U}\) which admit a mild solution \(\mathbf{X}^{\phi_{t}}\) of the following closed-loop equation:_

\[d\mathbf{X}_{s}^{\phi_{t}}=\left[\mathcal{A}\mathbf{X}_{s}^{\phi_{s}}+\sigma Q ^{1/2}\phi_{s}(s,\mathbf{X}_{s}^{\phi_{s}})\right]ds+d\mathbf{W}_{t}^{Q},\; \mathbf{X}_{t}=\mathbf{x}\] (A.13)

_Then the pair \((\alpha^{\phi_{t}},\mathbf{X}^{\phi_{t}})\), where the control \(\alpha^{\phi_{t}}\) is defined by the Markov feedback law \(\alpha_{s}^{\phi_{t}}=\phi(s,\mathbf{X}_{s}^{\phi_{t}})\) is admissible and it is optimal at \((t,\mathbf{x})\) for all \(s\in[t,T]\)._

Therefore, in the context of the initial value problem, such as in our case, we consider the form of the Markov control \(\alpha_{s}:=\alpha_{s}^{\phi_{0}}=\phi(s,\mathbf{X}_{s}^{\phi_{0}})\) for \(s\in[0,T]\). The proof and details can be found in [23, Chap 2.5.1].

### Proof of Theorem 2.2

Proof.: Let us consider the function \(\mathcal{V}(t,v)=-\log h(t,v)\).

\[\partial_{t}h=-h\partial_{t}\mathcal{V},\quad Dh=-hD_{\mathbf{x}}\mathcal{V},\quad D^{2}h=hD_{\mathbf{x}}\mathcal{V}\otimes D_{\mathbf{x}}\mathcal{V}-hD_ {\mathbf{x}\mathbf{x}}\mathcal{V},\] (A.14)

Recall that \(h\) satisfy the KBE in equation (7):

\[\partial_{t}h+\mathcal{L}h=0,\quad h_{T}=\tilde{G}.\] (A.15)

Since \(h=e^{-\mathcal{V}}\), hence \(\partial_{t}h=-\mathcal{L}h=\partial_{t}e^{-\mathcal{V}}=-\partial_{t} \mathcal{V}h\). Then,

\[\partial_{t}\mathcal{V}h =\mathcal{L}h\] (A.16) \[=\langle D_{\mathbf{x}}h,\mathcal{A}\mathbf{X}_{t}\rangle+\frac{1} {2}\text{Tr}\left[\sigma^{2}D_{\mathbf{x}\mathbf{x}}hQ\right]\] (A.17) \[=-\langle hD_{\mathbf{x}}\mathcal{V},\mathcal{A}\mathbf{X}_{t} \rangle+\frac{1}{2}\text{Tr}\left[\sigma^{2}\left(hD_{\mathbf{x}}\mathcal{V} \otimes D_{\mathbf{x}}\mathcal{V}-hD_{\mathbf{x}\mathbf{x}}\mathcal{V}\right) Q\right]\] (A.18) \[=-\langle hD_{\mathbf{x}}\mathcal{V},\mathcal{A}\mathbf{X}_{t} \rangle+\frac{1}{2}\text{Tr}\left[\sigma^{2}\left(hD_{\mathbf{x}}\mathcal{V} \otimes D_{\mathbf{x}}\mathcal{V}\right)Q\right]-\frac{1}{2}\text{Tr}\left[ \sigma^{2}hD_{\mathbf{x}\mathbf{x}}\mathcal{V}Q\right].\] (A.19)We can simplify the last equation as

\[\partial_{t}\mathcal{V} =-\langle D_{\mathbf{x}}\mathcal{V},\mathcal{A}\mathbf{X}_{t}\rangle+ \frac{1}{2}\text{Tr}\left[\sigma^{2}\left(D_{\mathbf{x}}\mathcal{V}\otimes D_{ \mathbf{x}}\mathcal{V}\right)Q\right]-\frac{1}{2}\text{Tr}\left[\sigma^{2}D_{ \mathbf{x}\mathbf{x}}\mathcal{V}Q\right]\] (A.20) \[=-\mathcal{L}\mathcal{V}+\frac{1}{2}\text{Tr}\left[\sigma^{2} \left(D_{\mathbf{x}}\mathcal{V}\otimes D_{\mathbf{x}}\mathcal{V}\right)Q \right].\] (A.21)

Following [69], the second term of RHS can be derived as follows

\[\frac{1}{2}\text{Tr}\left[\sigma^{2}\left(D_{\mathbf{x}}\mathcal{ V}\otimes D_{\mathbf{x}}\mathcal{V}\right)Q\right] =\frac{1}{2}\sum_{k\in\mathbb{N}}\langle\sigma^{2}(D_{\mathbf{x} }\mathcal{V}\otimes D_{\mathbf{x}}\mathcal{V})Q\phi^{(k)},\phi^{(k)}\rangle\] (A.22) \[=\frac{1}{2}\sum_{k\in\mathbb{N}}\langle\sigma^{2}D_{\mathbf{x}} \mathcal{V}\langle D_{\mathbf{x}}\mathcal{V},Q\phi^{(k)}\rangle,\phi^{(k)}\rangle\] (A.23) \[=\frac{1}{2}\sum_{k\in\mathbb{N}}\langle\sigma^{2}D_{\mathbf{x}} \mathcal{V},Q\phi^{(k)}\rangle\langle D_{\mathbf{x}}\mathcal{V},\phi^{(k)}\rangle\] (A.24) \[=\frac{1}{2}\sum_{k\in\mathbb{N}}\langle\sigma^{2}QD_{\mathbf{x}} \mathcal{V},\phi^{(k)}\rangle\langle D_{\mathbf{x}}\mathcal{V},\phi^{(k)}\rangle\] (A.25) \[=\frac{1}{2}\langle\sigma^{2}D_{\mathbf{x}}\mathcal{V},QD_{ \mathbf{x}}\mathcal{V}\rangle\] (A.26) \[=\frac{1}{2}\left\|\sigma Q^{1/2}D_{\mathbf{x}}\mathcal{V}\right\| _{\mathcal{H}}^{2}\] (A.27)

Therefore, combining the above results, we have

\[\partial_{t}\mathcal{V}+\mathcal{L}\mathcal{V}-\frac{1}{2}\left\|\sigma Q^{1/ 2}D_{\mathbf{x}}\mathcal{V}\right\|_{\mathcal{H}}^{2},\quad\mathcal{V}_{T}=G.\] (A.28)

Since (A.28) coincides with (4) with \(\psi(\cdot):=\frac{1}{2}\left\|\cdot\right\|_{\mathcal{H}}^{2}\), this concludes the proof. 

### Proof of Theorem 2.3

Proof.: A proof of Theorem 2.3 is based on [16, Chap. 10.3]. Since \(Q_{\infty}=-\frac{1}{2}Q\mathcal{A}^{-1}\) is a trace class, we define a trace class operator \(\Theta_{t}\) as follows:

\[\Theta_{t}=Q_{\infty}^{1/2}(Q_{t}^{-1/2}e^{t\mathcal{A}})^{*}(Q_{ \infty}^{-1/2}Q_{t}^{1/2})^{*}(Q_{\infty}^{1/2}(Q_{t}^{-1/2}e^{t\mathcal{A}})^ {*}(Q_{\infty}^{-1/2}Q_{t}^{1/2})^{*})^{*},\] (A.29)

for all \(t\geq 0\). Since \(Q_{t}=Q_{\infty}-e^{t\mathcal{A}}Q_{\infty}e^{t\mathcal{A}^{*}}\), we can rewrite \(Q_{t}\) in terms of \(\Theta_{t}\),

\[Q_{t} =Q_{\infty}-e^{t\mathcal{A}}Q_{\infty}e^{t\mathcal{A}^{*}}\] (A.30) \[=Q_{\infty}^{1/2}\left[1-(Q_{\infty}^{-1/2}e^{t\mathcal{A}})Q_{ \infty}(Q_{\infty}^{-1/2}e^{t\mathcal{A}})^{*}\right]Q_{\infty}^{1/2}\] (A.31) \[=Q_{\infty}^{1/2}(1-\Theta_{t})Q_{\infty}^{1/2}.\] (A.32)

Thus, we have \((1-\Theta_{t})\mathbf{x}=Q_{\infty}^{-1/2}Q_{t}Q_{\infty}^{-1/2}\mathbf{x}\) for all \(\mathbf{x}\in\mathcal{H}_{0}\). It implies that \(\langle(1-\Theta_{t})\mathbf{x},\mathbf{x}\rangle_{\mathcal{H}_{0}}\geq 0\), the non-negativity of \((1-\Theta_{t})\). Moreover it also implies that \((1-\Theta_{t})^{-1}\) is invertible:

\[(1-\Theta_{t})^{-1}=(Q_{t}^{-1/2}Q_{\infty}^{1/2})^{*}Q_{t}^{-1/2}Q_{\infty}^{1 /2}.\] (A.33)

Consequently, it yields the following formula [16, Proposition. 1.3.11]

\[q_{t}(0,\mathbf{y})=\text{det}(1-\Theta)^{-1/2}\exp\left[-\frac{1}{2}\langle \Theta_{t}(1-\Theta_{t})^{-1}Q_{\infty}^{-1/2}\mathbf{y},Q_{\infty}^{-1/2} \mathbf{y}\rangle_{\mathcal{H}}\right].\] (A.34)

Now, for the general case, by using the chain rule, we have:

\[q_{t}(\mathbf{x},\mathbf{y})=\frac{d\mathcal{N}_{e^{t\mathcal{A}} \mathbf{x},Q_{t}}}{d\mathcal{N}_{0,Q_{t}}}\frac{d\mathcal{N}_{0,Q_{t}}}{d \mathcal{N}_{0,Q_{\infty}}}(\mathbf{y})=\frac{d\mathcal{N}_{e^{t\mathcal{A}} \mathbf{x},Q_{t}}}{d\mathcal{N}_{0,Q_{t}}}(\mathbf{y})q_{t}(0,\mathbf{y}),\] (A.35)and utilizing Cameron-Martin theorem [16, Theorem. 1.3.6], we get:

\[\frac{d\mathcal{N}_{e^{t}A_{\mathbf{x}},Q_{t}}}{d\mathcal{N}_{0,Q_{t} }}(\mathbf{y})=\exp\bigg{[}\langle Q_{t}^{-1/2}e^{tA}\mathbf{x},Q_{t}^{-1/2} \mathbf{y}\rangle_{\mathcal{H}}-\frac{1}{2}\left\|Q_{t}^{-1/2}e^{tA}\mathbf{x }\right\|_{\mathcal{H}}^{2}\bigg{]}\] (A.36) \[=\exp\bigg{[}\langle Q_{t}^{-1/2}e^{tA}\mathbf{x},Q_{t}^{-1/2} \mathbf{y}\rangle_{\mathcal{H}}-\frac{1}{2}\langle Q_{t}^{-1/2}e^{tA}\mathbf{ x},Q_{t}^{-1/2}e^{tA}\mathbf{x}\rangle_{\mathcal{H}}\bigg{]}\] (A.37) \[=\exp\bigg{[}\langle Q_{\infty}^{1/2}Q_{t}^{-1}e^{tA}\mathbf{x},Q _{\infty}^{-1/2}\mathbf{y}\rangle_{\mathcal{H}}-\frac{1}{2}\langle Q_{\infty} ^{1/2}Q_{t}^{-1}e^{tA}\mathbf{x},Q_{\infty}^{-1/2}e^{tA}\mathbf{x}\rangle_{ \mathcal{H}}\bigg{]}\] (A.38) \[\overset{(i)}{=}\exp\bigg{[}\langle(1-\Theta_{t})^{-1}Q_{\infty} ^{-1/2}e^{tA}\mathbf{x},Q_{\infty}^{-1/2}\mathbf{y}\rangle_{\mathcal{H}}- \frac{1}{2}\langle(1-\Theta_{t})^{-1}Q_{\infty}^{-1/2}e^{tA}\mathbf{x},Q_{ \infty}^{-1/2}e^{tA}\rangle_{\mathcal{H}}\bigg{]}\] (A.39)

where \((i)\) follows from (A.33), \((1-\Theta_{t})^{-1}Q_{\infty}^{-1/2}=(Q_{t}^{-1/2}Q_{\infty}^{1/2})^{*}Q_{t}^ {-1/2}=Q_{\infty}^{1/2}Q_{t}^{-1}\). Thus, by substituting (A.34) and (A.39) into (A.35), we obtain the following result:

\[q_{t}(\mathbf{x},\mathbf{y}) =\text{\it det}(1-\Theta)^{-1/2}\exp\bigg{[}-\frac{1}{2}\langle \Theta_{t}(1-\Theta_{t})^{-1}Q_{\infty}^{-1/2}\mathbf{y},Q_{\infty}^{-1/2} \mathbf{y}\rangle_{\mathcal{H}}\] (A.40) \[+\langle(1-\Theta_{t})^{-1}Q_{\infty}^{-1/2}e^{tA}\mathbf{x},Q_{ \infty}^{-1/2}\mathbf{y}\rangle_{\mathcal{H}}-\frac{1}{2}\langle(1-\Theta_{t} )^{-1}Q_{\infty}^{-1/2}e^{tA}\mathbf{x},Q_{\infty}^{-1/2}e^{tA}\mathbf{x} \rangle_{\mathcal{H}}\bigg{]}.\] (A.41)

It concludes the proof. 

### Derivation of Example 2.4

For a diffusion bridge process, let us define the \(h\) function as:

\[h(t,T,\mathbf{x}_{t},\mathbf{x}_{T})=\mathbb{E}_{\mathscr{P}} \left[\tilde{G}(\mathbf{X}_{T},\mathbf{x}_{T})|\mathbf{X}_{t}=\mathbf{x}_{t} \right]=\int\tilde{G}(\mathbf{z},\mathbf{x}_{T})d\mathcal{N}_{e^{(T-t)}A_{ \mathbf{x}_{t}},Q_{T-t}}(\mathbf{z})\] (A.42)

If we choose \(\tilde{G}(\mathbf{x},\mathbf{y})=\mathbf{1}_{d\mathbf{y}}(\mathbf{x})\). Then, for any \(\mathbf{y}\in\mathcal{H}\) and \(t\in[0,T]\), Theorem 2.3 implies that

\[h(0,t,\mathbf{x}_{0},\mathbf{y}) =\int\tilde{G}(\mathbf{z},\mathbf{y})d\mathcal{N}_{e^{t}A_{ \mathbf{x}_{0}},Q_{t}}(\mathbf{z})\] (A.43) \[=\int\tilde{G}(\mathbf{z},\mathbf{y})\frac{d\mathcal{N}_{e^{t}A_{ \mathbf{x}_{0}},Q_{t}}}{d\mathcal{N}_{0,Q_{\infty}}}(\mathbf{z})d\mathcal{N}_ {0,Q_{\infty}}(\mathbf{z})\] (A.44) \[=\int\tilde{G}(\mathbf{z},\mathbf{y})q_{t}(\mathbf{x},\mathbf{z} )d\mathcal{N}_{0,Q_{\infty}}(\mathbf{z})\] (A.45) \[=q_{t}(\mathbf{x},\mathbf{y}).\] (A.46)

Moreover, with an eigen-system of \(\mathcal{H}\), \(\{(\lambda^{(k)},\phi^{(k)})\in\mathbb{R}\times\mathcal{H}:k\in\mathbb{N}\}\), \(q_{t}\) can be represented as [62]:

\[q_{t}(\mathbf{x},\mathbf{y})=\prod_{k\in\mathbb{N}}q_{t}^{(k)}( \mathbf{x}^{(k)},\mathbf{y}^{(k)}),\] (A.47)

where for each coordinated \(k\), \(q_{t}^{(k)}(\mathbf{x}^{(k)},\mathbf{y}^{(k)})\) has following representation:

\[q_{t}^{(k)}(\mathbf{x}^{(k)},\mathbf{y}^{(k)})=\bigg{(}\frac{ \lambda^{(k)}}{2a_{k}}(1-e^{-2a_{k}t})\bigg{)}^{-1/2}\exp\bigg{[}-\frac{( \mathbf{y}^{(k)}-e^{-a_{k}t}\mathbf{x}^{k})^{2}}{2\lambda^{(k)}(1-e^{-2a_{k} t})}+\frac{(\mathbf{y}^{(k)})^{2}}{2\lambda^{(k)}}\bigg{]}\] (A.48) \[\mathcal{A}\phi^{(k)}=-a_{k}\phi^{(k)},\quad Q\phi^{(k)}=\lambda^ {(k)}\phi^{(k)},\quad\mathbf{x}^{(k)}=\langle\mathbf{x},\phi^{(k)}\rangle_{ \mathcal{H}},\quad\mathbf{y}_{k}=\langle\mathbf{y},\phi^{(k)}\rangle_{ \mathcal{H}}.\] (A.49)

Therefore, since \(D_{\mathbf{x}}\log h(t,T,\mathbf{x},\mathbf{x}_{T})=D_{\mathbf{x}}\log q_{T-t }(\mathbf{x}_{t},\mathbf{x}_{T})\), by projecting \(D_{\mathbf{x}}\log q_{T-t}(\mathbf{x}_{t},\mathbf{x}_{T})\) to each coordinate \(\phi^{(k)}\), we obtain the following results:

\[\frac{d}{d\mathbf{x}^{(k)}}\log q_{T-t}^{(k)}(\mathbf{x}_{t}^{(k)},\mathbf{x}_ {T}^{(k)})=\frac{2a_{k}e^{-a_{k}(T-t)}}{\lambda^{(k)}(1-e^{-2a_{k}(T-t)})}( \mathbf{x}_{T}^{(k)}-e^{-a_{k}(T-t)}\mathbf{x}^{(k)})\] (A.50)

### Deriving Divergence Between Path Measures

Here we present an infinite-dimensional generalization of Girsanov's theorem [17, Theorem 10.14], which plays a crucial role in estimating the divergence between two path measures discussed in Sec 2.4. The theorem is formulated as follows:

**Theorem A.4** (Girsanov's Theorem in \(\mathcal{H}\)).: _Let \(\gamma\) be a \(\mathcal{H}_{0}\)-valued \(\mathcal{F}_{t}\)-predictable process such that_

\[\mathbb{P}\left(\int_{0}^{T}\left\|\gamma_{s}\right\|_{\mathcal{H}_{0}}^{2}ds< \infty\right)=1,\quad\mathbb{E}\left[\exp\left(\int_{0}^{t}\langle\gamma_{s},d\mathbf{W}_{t}^{Q}\rangle_{\mathcal{H}_{0}}-\frac{1}{2}\int_{0}^{T}\left\| \gamma_{s}\right\|_{\mathcal{H}_{0}}^{2}dt\right)\right]=1.\] (A.51)

_Then the process \(\tilde{\mathbf{W}}_{t}^{Q}=\mathbf{W}_{t}^{Q}-\int_{0}^{T}\gamma_{s}ds\) is a \(Q\)-Wiener process with respect to \(\{\mathcal{F}_{t}\}_{t\geq 0}\) on the probability space \((\Omega,\mathcal{F},\mathbb{Q})\) where_

\[d\mathbb{Q}=\exp\left(\int_{0}^{t}\langle\gamma_{s},d\mathbf{W}_{t}^{Q} \rangle_{\mathcal{H}_{0}}-\frac{1}{2}\int_{0}^{T}\left\|\gamma_{s}\right\|_{ \mathcal{H}_{0}}^{2}dt\right)d\mathbb{P}.\] (A.52)

_Or we can derive alternative formulation, by substituting \(\mathbf{W}_{t}^{Q}=\tilde{\mathbf{W}}_{t}^{Q}+\int_{0}^{T}\gamma_{s}ds\) to (A.52),_

\[d\mathbb{Q}=\exp\left(\int_{0}^{t}\langle\gamma_{s},d\tilde{\mathbf{W}}_{t}^{Q }\rangle_{\mathcal{H}_{0}}+\frac{1}{2}\int_{0}^{T}\left\|\gamma_{s}\right\|_{ \mathcal{H}_{0}}^{2}dt\right)d\mathbb{P}.\] (A.53)

Now, we will apply Girsanov's theorem to path measures related to (1) and (9). Let \(\mathbb{Q}:=\mathbb{P}^{\alpha}\) in (A.53). Then \(\gamma_{s}:=Q^{1/2}\alpha_{s}\) and we get

\[\frac{d\mathbb{P}^{\alpha}}{d\mathbb{P}}=\exp\left(\int_{0}^{t}\langle\alpha,d \tilde{\mathbf{W}}_{t}^{Q}\rangle_{\mathcal{H}_{0}}+\frac{1}{2}\int_{0}^{T} \left\|Q^{1/2}\alpha_{s}\right\|_{\mathcal{H}_{0}}^{2}dt\right).\] (A.54)

Proof.: Proof can be founded in [17, Theorem 10.14] 

Since our goal is find an optimal control \(\alpha^{\star}\) such that \(\mathbf{X}_{T}^{\alpha^{\star}}\) satisfying terminal constraints which is represented by function \(\tilde{G}\) in (6), we may define our target path measure \(\mathbb{P}^{\star}\) as \(\frac{d\mathbb{P}^{\star}}{d\mathbb{P}}=\frac{1}{\mathcal{Z}}\tilde{G}(\cdot)\)[57], where \(\mathcal{Z}=\mathbb{E}_{\mathbb{P}}\left[\tilde{G}(\mathbf{X}_{T})\right]\) Then, we can compute the logarithm of Radon Nikodym derivative as

\[\log\frac{d\mathbb{P}^{\alpha}}{d\mathbb{P}^{\star}} =\log\frac{d\mathbb{P}^{\alpha}}{d\mathbb{P}}+\log\frac{d\mathbb{ P}}{d\mathbb{P}^{\star}}-\mathcal{Z}\] (A.55) \[\approx\int_{0}^{t}\langle\alpha,d\tilde{\mathbf{W}}_{t}^{Q} \rangle_{\mathcal{H}_{0}}+\frac{1}{2}\int_{0}^{T}\left\|Q^{1/2}\alpha_{s} \right\|_{\mathcal{H}_{0}}^{2}dt+G(\cdot).\] (A.56)

Since \(\tilde{\mathbf{W}}_{t}^{Q}\) is \(Q\)-Wiener process on \(\mathbb{P}^{\alpha}\), we can compute the relative entropy loss in Sec 2.4:

\[D_{\text{ref}}(\mathbb{P}^{\alpha}|\mathbb{P}^{\star})=\mathbb{E}_{\mathbb{P} ^{\alpha}}\left[\log\frac{d\mathbb{P}^{\alpha}}{d\mathbb{P}^{\star}}\right]= \mathbb{E}_{\mathbb{P}^{\alpha}}\left[\frac{1}{2}\int_{0}^{T}\left\|\alpha_{s} \right\|_{\mathcal{H}}^{2}dt+G(\mathbf{X}_{T}^{\alpha})\right],\] (A.57)

where we denote \(\left\|(\cdot)\right\|_{\mathcal{H}_{0}}^{2}=\left\|Q^{-1/2}(\cdot)\right\|_{ \mathcal{H}}^{2}\) This representation matches with (3) when \(R(\cdot):=\frac{1}{2}\left\|\cdot\right\|_{\mathcal{H}}^{2}\). Similarly, the cross entropy loss in (19) can be derived by set \(\mathbb{Q}:=\mathbb{P}^{\star}\) and \(\mathbb{P}:=\mathbb{P}^{\alpha}\) in (A.53). Then \(\gamma_{s}\) can be defined as (18) and \(\tilde{\mathbf{W}}_{t}^{Q}=\tilde{\mathbf{W}}_{t}^{Q}+\int_{0}^{T}\gamma_{s}( \theta)ds\) is a \(Q\)-Wiener process on \(\mathbb{P}^{\star}\) where \(\mathbb{P}^{\alpha}\) satisfies the Radon-Nikodym derivative:

\[\frac{d\mathbb{P}^{\star}}{d\mathbb{P}^{\alpha}}=\exp\left(\int_{0}^{t} \langle\gamma_{s}(\theta),d\tilde{\mathbf{W}}_{t}^{Q}\rangle_{\mathcal{H}_{0} }+\frac{1}{2}\int_{0}^{T}\left\|\gamma_{s}(\theta)\right\|_{\mathcal{H}_{0}}^{2 }dt\right).\] (A.58)

Hence, the cross-entropy loss can be computed as in (19).

### Proof of Theorem 3.1

Proof.: Let us consider that the marginal distributions \(\{\mu_{t}^{\star}\}_{t\in 0,T}\) satisfying the following relation in a weak sense [4]:

\[\partial_{t}\int f(\mathbf{x}_{t})\mu_{t}^{\star}(d\mathbf{x}_{t})=\int f( \mathbf{x}_{t})\mathcal{L}_{t}^{\star}\mu_{t}^{\star}(d\mathbf{x}_{t})=\int \mathcal{L}_{t}f(\mathbf{x}_{t})\mu_{t}^{\star}(d\mathbf{x}_{t})\] (A.59)

where \(\mathcal{L}_{t}^{\star}\) is adjoint operator of \(\mathcal{L}_{t}\). Now, let us denote \(\mu_{t|0,T}(\mathbf{x}_{t})=\mu_{t}^{\star}(\mathbf{x}_{t}|\mathbf{x}_{0}, \mathbf{x}_{T})\) and consider factorizable marginal distribution \(\mu_{t}^{\star}(d\mathbf{x}_{t})=\int_{\Pi}\mu_{t}^{\star}(\mathbf{x}_{t}| \mathbf{x}_{0},\mathbf{x}_{T})\Pi(d\mathbf{x}_{0},d\mathbf{x}_{T})\), where \(\mu_{t}^{\star}(\mathbf{x}_{t}|\mathbf{x}_{0},\mathbf{x}_{T})\) satisfying the following relation:

\[\partial_{t}\int_{\mathcal{H}}f(\mathbf{x}_{t})\mu_{t}^{\star}(d \mathbf{x}_{t}|\mathbf{x}_{0},\mathbf{x}_{T})=\int_{\mathcal{H}}\mathcal{L}_{ t|0,T}f(\mathbf{x}_{t})\mu_{t}^{\star}(d\mathbf{x}_{0},\mathbf{x}_{T})\] \[=\int_{\mathcal{H}}\left[\langle\mathcal{A}\mathbf{x}_{t},D_{ \mathbf{x}}f(\mathbf{x}_{t})\rangle_{\mathcal{H}}+\langle h_{t|0,T}(\mathbf{ x}_{t}),D_{\mathbf{x}}f(\mathbf{x}_{t})\rangle_{\mathcal{H}}+\frac{1}{2}\text{Tr} \left[\sigma^{2}QD_{\mathbf{x}\mathbf{x}}f(\mathbf{x}_{t})\right]\right]\mu_{t }^{\star}(d\mathbf{x}_{t}|\mathbf{x}_{0},\mathbf{x}_{T}),\]

where we denote \(h_{t|0,T}(\mathbf{x}_{t}):=\sigma^{2}QD_{\mathbf{x}}\log h(t,\mathbf{x}_{t})\). Now, we can obtain the Kolmogorov operator associated with the diffusion process associated with the marginal distributions \(\mu_{t}^{\star}(d\mathbf{x}_{t})\) as follows

\[\partial_{t}\int_{\mathcal{H}}f(\mathbf{x}_{t})\mu_{t}^{\star}(d \mathbf{x}_{t})=\partial_{t}\int_{\Pi}\int_{\mathcal{H}}f(\mathbf{x}_{t})\mu_{ t}^{\star}(d\mathbf{x}_{t}|\mathbf{x}_{0},\mathbf{x}_{T})\Pi(d\mathbf{x}_{0},d \mathbf{x}_{T})\] (A.60) \[=\int_{\mathcal{H}}\left[\langle\mathcal{A}\mathbf{x}_{t},D_{ \mathbf{x}}f(\mathbf{x}_{t})\rangle_{\mathcal{H}}+\langle h_{t}^{\star}( \mathbf{x}_{t}),D_{\mathbf{x}}f(\mathbf{x}_{t})\rangle_{\mathcal{H}}+\frac{1} {2}\text{Tr}\left[\sigma^{2}QD_{\mathbf{x}\mathbf{x}}f(\mathbf{x}_{t})\right] \right]\mu_{t}^{\star}(d\mathbf{x}_{t})\] (A.61) \[=\int_{\mathcal{H}}\mathcal{L}_{t}f(\mathbf{x}_{t})\mu_{t}^{\star }(d\mathbf{x}_{t})=\int f(\mathbf{x}_{t})\mathcal{L}_{t}^{\star}\mu_{t}^{ \star}(d\mathbf{x}_{t}),\] (A.62)

where we have defined \(\int_{\mathcal{H}}h_{t}^{\star}(\mathbf{x}_{t})\mu_{t}^{\star}(d\mathbf{x}_{t}) :=\int_{\Pi}\int_{\mathcal{H}}h_{t|0,T}\mu_{t}^{\star}(d\mathbf{x}_{t}| \mathbf{x}_{0},\mathbf{x}_{T})\Pi(d\mathbf{x}_{0},d\mathbf{x}_{T})\). It implies that the diffusion dynamics \(d\mathbf{x}_{t}^{\star}\) associated with the Kolmogorov operator \(\mathcal{L}:=\langle d\mathbf{x}_{t},D_{\mathbf{x}}f(\mathbf{x}_{t})\rangle_{ \mathcal{H}}+\langle h_{t}^{\star}(\mathbf{x}_{t}),D_{\mathbf{x}}f(\mathbf{x} _{t})\rangle_{\mathcal{H}}+\frac{1}{2}\text{Tr}\left[\sigma^{2}QD_{\mathbf{x} \mathbf{x}}f(\mathbf{x}_{t})\right]\) also associated with Fokker-Planck equation [7]\(\mathcal{L}_{t}^{\star}\mu_{t}^{\star}(d\mathbf{x}_{t})=0\), meaning \(\mathbf{X}_{t}^{\star}\sim\mu_{t}^{\star}\) for all \(t\in[0,T]\). Now, for some reference measure \(\mu_{\text{ref}}\) where the Radon-Nikodym derivatives \(\frac{d\mu_{t}^{\star}}{d\mu_{\text{ref}}}(\mathbf{x}_{t})=p_{t}(\mathbf{x}_{t} ),\frac{d\mu_{t|0,T}}{d\mu_{\text{ref}}}(\mathbf{x}_{t})=p_{t|0,T}(\mathbf{x} _{t})\) exist. Then, under \(\mu_{\text{ref}}\), \(h_{t}^{\star}\) can be defined as follows:

\[h_{t}^{\star}(\mathbf{x}_{t})=\frac{\int_{\Pi}h_{t|0,T}(\mathbf{x}_{t})p_{t|0, T}(\mathbf{x}_{t})\Pi(d\mathbf{x}_{0},d\mathbf{x}_{T})}{p_{t}(\mathbf{x}_{t})}.\] (A.63)

Therefore, the diffusion process associated with marginal distributions \(\mu_{t}^{\star}(\mathbf{x}_{t})\) has following representation:

\[d\mathbf{X}_{t}^{\star}=\left[\mathcal{A}\mathbf{X}_{t}^{\star}+\sigma^{2}Q \mathbb{E}_{\mathbf{x}_{T}\sim\mathbb{P}^{h}(d\mathbf{x}_{T}|\mathbf{X}_{t}^{ \star})}\left[q_{T-t}(\mathbf{X}_{t}^{\star},\mathbf{x}_{T})\right]\right]dt+ \sigma d\mathbf{W}_{t}^{Q},\quad\mathbf{X}_{0}^{\star}\sim\mu_{0}^{\star}.\] (A.64)

This concludes the proof. 

### Proof of Theorem 3.2

Proof.: Let us assume the initial condition is fixed to deterministic point \(\mathbf{x}_{0}\in\mathcal{H}\) and define a reference measure \(\mu_{\text{ref}}=\mathcal{N}(0,Q_{\infty})\). Since our goal is \(\mathbf{X}_{T}^{\alpha}\) satisfying the terminal condition \(G\), define \(\mathbb{P}^{\star}\) as \(\frac{d\mathbb{P}^{\star}}{d\mathbb{P}}=\frac{1}{2}\tilde{G}(\cdot)\), where \(\mathcal{Z}=\mathbb{E}_{\mathbb{P}}[\tilde{G}(\mathbf{X}_{T})]\). Therefore, we have the following relation for marginal distributions \(d\mu_{T}^{\star}=\frac{1}{2}\tilde{G}(\mathbf{X}_{T})d\mu_{T}\). Moreover, since we have defined \(G(\mathbf{X}_{T})=-\log\frac{d\pi\pi}{d\mu_{T}}(\mathbf{X}_{T})\) in (23), then it result \(h(t,\mathbf{x})=\mathbb{E}_{\mathbb{P}}\left[\frac{d\pi_{T}}{d\mu_{T}}(\mathbf{X} _{T})|\mathbf{X}_{t}=\mathbf{x}\right]\) by following Theorem 2.2, we get \(\tilde{G}(\mathbf{X}_{T})=h(T,\mathbf{X}_{T})\). Hence, we have for any Borel set \(B\in\mathcal{B}(\mathcal{H})\),

\[\int_{B}d\mu_{T}^{\star}(v) =\int_{B}\frac{h(T,\mathbf{X}_{T})}{h(0,\mathbf{x}_{0})}d\mu_{T}\] (A.65) \[=\int_{B}\frac{\frac{d\pi_{T}}{d\mu_{T}}(\mathbf{X}_{T})}{\int_{ \mathcal{H}}\frac{d\pi}{d\mu_{T}}}d\mu_{T}=\int_{B}d\pi_{T}\] (A.66)

Now, given that we have confirmed that the conditioned SDE in (9) correspond to the controlled process (9) with optimal control, we can establish the result \(\mathbb{P}(\mathbf{X}_{T}^{\alpha}\in B)=\pi(B)\). This concludes the proof.

### Experimental Details

#### a.8.1 Experiment on 2D-Domain

Synthetic Experiment.In a synthetic experiment, we computed the log-probability of \(p_{0}\) and \(p_{T}\) across a uniformly sampled grid of \(64^{2}\) points, with each point \(\mathbf{p}_{i}\) ranging within \([-7,7]^{2}\). For \(p_{0}\), the log-probability was generated using an 8-Gaussian mixture model as specified in [70]. For \(p_{T}\), we employed the following log-density function:

\[\log p_{T}(\mathbf{p})=-\frac{\min(\left\|\mathbf{p}-1\right\|^{2},\left\| \mathbf{p}-3\right\|^{2},\left\|\mathbf{p}-5\right\|^{2})}{0.05}.\] (A.67)

Training was conducted using the Adam optimizer with a learning rate of \(1e-3\). The network was trained with a batch size of 24 for a total of 1000 iterations. We set \(\sigma=0.2\) in (1) for this experiment and set 100 discretization steps. We use a single A\(6000\) GPU for this experiment.

The control function was parameterized using a \(4\)-layer FNO-2D [40], with the cutoff number of Fourier modes set at \(8\) and each convolution layer having a width of \(32\).

Simulation of DBFS.We follow the simulation scheme introduced in [58, 42]. For \(\mathbf{x}=(x_{1},x_{2})\in\mathbb{R}^{2}\), we use the discrete cosine transformation (DCT) for projection. Specifically, the eigenvector \(\phi^{(k)}(\mathbf{x})\) and eigenvalue \(\lambda^{(k)}\) of the negative Laplacian operator \(-\Delta\), which is positive definite and Hermitian, and satisfies the zero Neumann boundary condition, are given by:

\[-\Delta\phi^{(k)}(\mathbf{x})=\lambda^{(k)}\phi^{(k)}(\mathbf{x})\] (A.68) \[\frac{\partial\phi^{(k)}(\mathbf{x})}{\partial x_{1}}=\frac{ \partial\phi^{(k)}(\mathbf{x})}{\partial x_{2}}=0,.\] (A.69)

It implies that the orthonormality of \(\phi^{(k)}(\cdot)\) with respect to the associated inner product, thereby enables computations in (A.47-A.50). Now, considering a rectangular domain with Cartesian coordinates, where pixels in the image are sampled from an underlying regular domain, the eigenbasis is given as a separable cosine basis:

\[\phi^{(n,m)}(x_{1},x_{2})\sim\cos\left(\frac{\pi nx_{1}}{W} \right)\cos\left(\frac{\pi mx_{2}}{H}\right)\] (A.70) \[\lambda^{(n,m)}=\pi^{2}\left(\frac{n^{2}}{W^{2}}+\frac{m^{2}}{H^ {2}}\right).\] (A.71)

Then, the negative Laplacian \(-\Delta\) can then by represented by an eigen decomposition \(-\Delta=\mathbf{E}\mathbf{D}\mathbf{E}^{T}\), where \(\mathbf{E}^{T}\) is the projection matrix for the DCT \(i.e.\), \(\tilde{\mathbf{X}}_{t}=\mathbf{E}^{T}\mathbf{X}_{t}=\texttt{DCT}(\mathbf{X}_ {t})\), and \(\mathbf{D}\) is a diagonal

Figure A.1: Transformer-based network architecture.

matrix containing the eigenvalues \(\lambda^{(n,m)}\). Hence the controlled SDEs (2) with \(Q=\mathbf{I}\) can be rewritten as

\[d\tilde{\mathbf{X}}_{t}^{\alpha}=\left[-\mathbf{D}\tilde{\mathbf{X}}_{t}^{\alpha }+\sigma\tilde{\alpha_{t}}\right]dt+\sigma d\tilde{\mathbf{W}}_{t},\quad t\in[0,T],\] (A.72)

where \(\tilde{\mathbf{X}}_{t}=\mathbf{E}^{T}\mathbf{X}_{t}\),\(\tilde{\alpha}_{t}=\mathbf{E}^{T}\alpha_{t}\), and \(\tilde{\mathbf{W}}_{t}\overset{d}{=}\mathbf{W}_{t}\) for all \(t\in[0,T]\).

**Sampling Algorithm.**  The sampling algorithm for DBFS in bridge matching, discussed in Section 5.1, is provided in detail in Algorithm 3.

**Unpaired dataset Transfer Experiment.**  For the experiment involving transfer between dataset, we followed the setup described in [51].

**(A)** For the EMNIST and MNIST datasets, the initial distribution, \(\pi_{0}\), was set as the MNIST dataset, while for the terminal distribution, \(\pi_{T}\), we used the EMNIST dataset with the first five lowercase and uppercase characters, as outlined by [19]. The iterative training scheme proposed by [51]. was adopted, which involved two neural networks, \(\alpha_{t}(t,\mathbf{x},\theta)\) and \(\alpha_{t}(t,\mathbf{x},\psi)\), each with around 20.7 million parameters. These networks approximate mixtures of bridges for the forward (\(\pi_{0}\rightarrow\pi_{T}\)) and reverse (\(\pi_{T}\rightarrow\pi_{0}\)) directions, respectively. The SDE was discretized into 30 steps without a noise schedule. The DBFS model was trained for 60 iterations, with each iteration comprising 5,000 gradient updates. Additionally, 2,560 cached images were used for training each network, updated every 250 steps. We used the Adam optimizer with a learning rate of 1e-4 and a batch size of 128, with the EMA rate set to 0.999. The complete DBFS training for the MNIST experiment took approximately 15 hours on a single A6000 GPU.

**(B)** For the AFHQ dataset [1-4]5, we evaluated DBFS between the wild and cat classes on a \(64^{2}\) grid, with each class containing approximately 5,000 samples. The control networks each contained about 120.3 million parameters. We discretized the SDE into 100 steps without using a noise schedule. The Adam optimizer was used with a learning rate of 1e-4, and the EMA rate was set to 0.999. We used a batch size of 64 and trained for 20 iterations, with a total of 400,000 gradient steps. Additionally, 2,560 cached images were used for training each network, updated every 1,000 steps. The training took approximately 8 days, using 8 A6000 GPUs for the experiment.

Footnote 5: https://github.com/clovaai/stargan-v2, under CC BY-NC 4.0 License.

For each control network \(\alpha\), we used a transformer network architecture inspired by PerceiverIO [36] from public repository6 to model functional representation. This transformer architecture was chosen for its efficiency in evaluating field representations over a large number of grid points and its 

[MISSING_PAGE_EMPTY:24]

#### a.8.2 Experiment on 1D-Domain

For the experiments on 1D-domain, we consistently set \(\mathcal{A}:=-\frac{1}{2}\) and \(Q:=\exp(-\left\|\mathbf{p}-\mathbf{p}^{\prime}\right\|^{2}/\gamma)\) and set \(\gamma=0.2\) and \(\gamma=0.02\) for GP regression and imputation, respectively. The choice of \(\gamma\) is hyper-parameter, we search over the set \([0,01,0.1,0.2,0.5,1.0]\) and find optimal value for GP regression. For imputation, we set \(\gamma=0.02\) by following [6].

Terminal Cost ComputationFor all experiments conducted in the 1D domain, we implemented a parameterized initial condition which takes as input the observed sequences \(\mathbf{X}_{\theta}^{\theta}=\mathbf{x}^{\theta}(\mathbf{Y}[\mathbf{O}])\). We employed the energy functional \(\mathcal{U}\) as the Gaussian negative log-likelihood (NLL). For each evaluation point on \(\mathbf{T}\), \(\mathcal{U}\) can be computed as follows:

\[\mathcal{U}(\mathbf{X}_{T}[\mathbf{T}])=-\log\mathcal{N}(\mathbf{X}_{T}[T] |\mathbf{Y},\sigma_{\theta})=\sum_{i=1}^{|\mathbf{T}|}\frac{\left\|\mathbf{X }_{T}[\mathbf{p}_{i}]-\mathbf{Y}[\mathbf{p}_{i}]\right\|^{2}}{2\sigma_{\theta }^{2}},\] (A.73)

where \(\sigma_{\theta}^{2}\) is set as an output from the neural network in accordance with [38] for GP regression, and fixed as \(\sigma_{\theta}^{2}=0.5\) for imputation, to establish a loss function analogous to [6]. Additionally, we specified a learnable prior distribution \(\mu_{\text{prior}}=\mathcal{N}(e^{-\frac{T}{2}\mathbf{x}^{\theta}},Q_{T})\). Consequently, the terminal cost retains only the NLL term, simplifying the computation.

GP regressionFor the GP regression, we borrow the experiment setting from [38]. The model trained with curves generated from GP with RBF kernel and tested in various settings such as data generated from GP with other type of kernel (Matern 5/2, Periodic). We generated \(\mathbf{p}\) uniformly on the interval \([-2,2]\) and generated \(\mathbf{Y}[\mathbf{p}]\) from using RBF kernel \(\kappa(\mathbf{p}_{i},\mathbf{p}_{j})=l_{1}^{2}\exp(-\left\|\mathbf{p}_{i}- \mathbf{p}_{j}\right\|^{2}/l_{2}^{2})\) with \(l_{1}\sim\text{Unif}(0.1,1.0)\) and \(l_{2}\sim\text{Unif}(0.1,0.6)\) and the white noise \(\xi\sim\mathcal{N}(0,1-2)\) is added. We set \(|\mathbf{O}|\) randomly from \(\text{Unif}(3,37)\) and \(|\mathbf{T}|\) from \(\text{Unif}(3,50-|\mathbf{O}|)\). For the other test data, we define \(\kappa(\mathbf{p}_{i},\mathbf{p}_{j})=l_{1}^{2}(1+\sqrt{5}d/l_{2}+5d^{2}/(3l_ {2}^{2}))exp(-\sqrt{5}d/l_{2})\) with \(d=(\left\|\mathbf{p}_{i}-\mathbf{p}_{j}\right\|)\), \(l_{1}\sim\text{Unif}(0.1,1.0)\) and \(l_{2}\sim\text{Unif}(0.1,0.6)\) for Matern kernel and \(\kappa(\mathbf{p}_{i},\mathbf{p}_{j})=l_{1}^{2}\exp(-2\sin^{2}(\pi\left\| \mathbf{p}_{i}-\mathbf{p}_{j}\right\|^{2}/p)/l_{2})\) with \(l_{1}\sim\text{Unif}(0.1,1.0)\), \(l_{2}\sim\text{Unif}(0.1,0.6)\) and \(p\sim\text{Unif}(0.1,0.5)\) for periodic kernel.

We set batch size of \(100\) and trained for \(100,000\) iterations. The Adam optimizer is used, the initial learning rate 5e-4 decayed with cosine annealing scheme. For testing, we evaluated the trained models using 3,000 batches, each consisting of 16 samples. We report the mean and standard deviation for five runs. We a single \(A6000\) GPU for this experiment.

The architectures for NP [28] and CNP [27], we use the same setting as described in [38]7. In our approach, we adapted the CNP architecture to incorporate a parameterized initial condition \(\mathbf{x}^{\theta}\) (add one linear layer to output \(\mathbf{x}^{\theta}\)). The total number of parameters is similar across all three models.

Footnote 7: https://github.com/juho-lee/bnp, under MIT License.

Physionet ImputationThe Physionet [30] contains \(4000\) clinical time series with \(35\) variables for \(48\) hours from intensive care unit. Following [68], we preprocess this datasets to hourly time-series which have \(48\) time steps. Since the dataset already contains around \(80\%\) of missingness, we randomly choose \(10/50/90\%\) of observed values as test data.

In the imputation experiments, we employed the same experimental setup as \([6]^{\lx@sectionsign}\) which is slight modification of original CSDI model. In this setup, the Gaussian noise of the DDPM model was replaced with GP noise employing an RBF kernel. Additionally, we adjusted the measurement approach to record the actual elapsed time rather than rounding to the nearest hour, better capturing the inherent timing characteristics of the Physionet dataset. We use a single A\(6000\) GPU for this experiment.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: Yes, the main claims made in the abstract and introduction are consistent with the scope of the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: The limitations are discussed in the conclusion section.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: Yes, we believe our proof and assumptions are both sufficient and correct.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: Yes, we believe we have provided all the necessary information to reproduce our results in Appendix A.8.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: We have provided the codebase used for our experiments, particularly for unpaired image transfer.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: Yes, we have provided the experimental details.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: Yes, when available, we conducted the experiments five times and reported the mean and standard deviations.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes]Justification: Yes, we provided the required resources in the experimental details section.
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: We support the NeurIPS Code of Ethics.
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: The broader impacts are discussed in the conclusion section.
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [Yes] Justification: We adhere to ethical standards for using our model in generative AI.
12. **Licensees for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: Yes, the license and terms of use are noted.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: The paper does not release new assets.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: We do not involve crowdsourcing or research with human subjects.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: We do not involve crowdsourcing or research with human subjects.