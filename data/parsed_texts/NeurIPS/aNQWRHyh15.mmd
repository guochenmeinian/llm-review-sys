# In-and-Out: Algorithmic Diffusion for

Sampling Convex Bodies

 Yunbum Kook

School of Computer Science

Georgia Institute of Technology

yb.kook@gatech.edu

&Santosh S. Vempala

School of Computer Science

Georgia Institute of Technology

vempala@gatech.edu

&Matthew S. Zhang

Department of Computer Science,

University of Toronto,

matthew.zhang@mail.utoronto.ca

###### Abstract

We present a new random walk for uniformly sampling high-dimensional convex bodies. It achieves state-of-the-art runtime complexity with stronger guarantees on the output than previously known, namely in Renyi divergence (which implies TV, \(\mathcal{W}_{2}\), KL, \(\chi^{2}\)). The proof departs from known approaches for polytime algorithms for the problem -- we utilize a stochastic diffusion perspective to show contraction to the target distribution with the rate of convergence determined by functional isoperimetric constants of the stationary density.

## 1 Introduction

Generating random samples from a high-dimensional convex body is a basic algorithmic problem with myriad connections and applications. The core of the celebrated result of [1], giving a randomized polynomial-time algorithm for computing the volume of a convex body, was the first polynomial-time algorithm for uniformly sampling convex bodies. In the decades since, the study of sampling has led to a long series of improvements in its algorithmic complexity [2, 3, 4, 5, 6], often based on uncovering new mathematical/geometric structure, establishing connections to other fields (e.g., functional analysis, matrix concentration) and developing new tools for proving isoperimetric inequalities and analyzing Markov chains. With the proliferation of data and the increasing importance of machine learning, sampling has also become an essential algorithmic tool, with applications needing samplers in very high dimension, e.g., scientific computing [7, 8, 9], systems biology [10, 11], differential privacy [12, 13] and machine learning [14, 15].

Samplers for convex bodies are based on Markov chains (see SS5 for a summary). Their analysis is based on bounding the _conductance_ of the associated Markov chain, which in turn bounds the mixing rate. Analyzing the conductance requires combining delicate geometric arguments with (Cheeger) isoperimetric inequalities for convex bodies. An archetypal example of the latter is the following: for any measurable partition \(S_{1},S_{2},S_{3}\) of a convex body \(\mathcal{K}\subset\mathbb{R}^{d}\), we have

\[\operatorname{vol}(S_{3})\geq\tfrac{d(S_{1},S_{2})}{C_{\mathcal{K}}}\min\{ \operatorname{vol}(S_{1}),\operatorname{vol}(S_{2})\}\,,\]

where \(d(\cdot,\cdot)\) is the (minimum) Euclidean distance, and \(C_{\mathcal{K}}\) is an isoperimetric constant of the uniform distribution over \(\mathcal{K}\). (The KLS conjecture posits that \(C_{\mathcal{K}}=\mathcal{O}(1)\) for any convex body \(\mathcal{K}\) in _isotropic position_, i.e., under the normalization that a random point from \(\mathcal{K}\) has identity covariance). The coefficient \(C_{\mathcal{K}}^{2}\) is bounded by the Poincare constant of the uniform distribution over \(\mathcal{K}\) (and they arein fact asymptotically equal). The classical proof of conductance uses geometric properties of the random walk at hand to reduce the analysis to a suitable isoperimetric inequality (see e.g., [3; 16]). The end result is a guarantee on the number of steps after which the total variation distance (TV distance) between the current distribution and the target is bounded by a desired error parameter. This framework has been widely used and effective in analyzing an array of candidate samplers, e.g., Ball walk [4], Hit-and-Run [17; 5], Riemannian Hamiltonian Monte Carlo [18] etc.

One successful approach, studied intensively over the past decade, is based on _diffusion_. The basic idea is to first analyze a continuous-time diffusion process, typically modeled by a _stochastic differential equation_ (SDE), and then show that a suitable time-discretization of the process, sometimes together with a Metropolis filter, converges to the desired distribution efficiently. A major success along this line is the Unadjusted Langevin Algorithm and its variants, studied first in [19]. These algorithms have strong guarantees for sampling "nice" distributions [20; 21; 22; 23], such as ones that are strongly log-concave, or more generally distributions satisfying isoperimetric inequalities, while also obeying some smoothness conditions. The analysis of these algorithms is markedly different from the conductance approach, and typically yields guarantees in stronger metrics such as the \(\mathsf{KL}\)-divergence.

Our starting point is the following question:

_Can diffusion-based approaches be used for the problem of sampling convex bodies?_

Despite remarkable progress, thus far, constrained sampling problems have evaded the diffusion approach, except as a high-level analogy (e.g., the Ball walk can be viewed as a discretization of Brownian motion, but this alone does not suggest a route for analysis) or with significantly worse convergence rates (e.g., [24; 25]).

Contributions.Our main finding is a simple diffusion-based algorithm that can be mapped to a stochastic process (and, importantly, to a pair of forward and backward processes), such that the rate of convergence is bounded directly by an appropriate functional inequality for the target distribution. As a consequence, for the first time, we obtain clean end-to-end guarantees in the Renyi divergence (which implies guarantees in other well known quantities such as \(\mathcal{W}_{2},\mathsf{TV},\mathsf{KL},\chi^{2}\) etc.), while giving state-of-the-art runtime complexity for sampling convex bodies (e.g., Ball walk or Speedy walk [3; 4]). Besides being a stronger guarantee on the output, Renyi divergence is of particular interest for differential privacy [13]. Perhaps most interesting is that our proof approach is completely different from prior work on convex body sampling. In summary,

* The guarantees hold for the \(q\)-Renyi divergences while matching the rates of previous work (prior work only had guarantees in the TV distance).
* The analysis is simple, modular, and easily extendable to several other settings.

Organization.In SS2, we provide some relevant notions for understanding our results. We then proceed to outline our algorithm in SS3. The algorithmic guarantees are provided in SS4, in which we also outline our proof and compare it with the analysis of Ball walk, Speedy walk. Lastly, we provide a detailed survey of the relevant literature in SS5 before concluding.

## 2 Preliminaries

Unless otherwise specified, we will use \(\|\cdot\|\) for the \(2\)-norm on \(\mathbb{R}^{d}\). We write \(a=\mathcal{O}(b)\), \(a\lesssim b\) to mean that \(a\leq cb\) for some universal constant \(c>0\). Similarly, \(a\gtrsim b\), \(a=\Omega(b)\) for \(a\geq cb\), while \(a=\Theta(b)\) means \(a\lesssim b,b\lesssim a\) simultaneously. We will also use \(a=\widetilde{\mathcal{O}}(b)\) to denote \(a=\mathcal{O}(b\operatorname{polylog}(b))\). Lastly, we will use measure and density interchangeably when there is no confusion.

To quantify the convergence rate, we introduce some common divergences between distributions.

**Definition 1** (Distance and divergence).: For two measures \(\mu,\nu\) on \(\mathbb{R}^{d}\), the _total variation_ distance between them is defined by

\[\|\mu-\nu\|_{\mathsf{TV}}:=\sup_{B\in\mathcal{F}}\left|\mu(B)-\nu(B)\right|,\]

where \(\mathcal{F}\) is the collection of all measurable subsets of \(\mathbb{R}^{d}\). The _\(2\)-Wasserstein distance_ is given by

\[\mathcal{W}_{2}^{2}(\mu,\nu):=\inf_{\gamma\in\Gamma(\mu,\nu)}\mathbb{E}_{(X,Y )\sim\gamma}[\|X-Y\|^{2}]\,,\]where \(\Gamma\) is the set of all couplings between \(\mu,\nu\). Next, we define the _\(f\)-divergence_ of \(\mu\) towards \(\nu\) with \(\mu\ll\nu\) (i.e., \(\mu\) is absolutely continuous with respect to \(\nu\)) as, for some convex function \(f:\mathbb{R}_{+}\to\mathbb{R}\) with \(f(1)=0\) and \(f^{\prime}(\infty)=\infty\),

\[D_{f}(\mu\,\|\,\nu):=\int f\big{(}\tfrac{\mathrm{d}\mu}{\mathrm{d}\nu}\big{)} \,\mathrm{d}\nu\,.\]

The _\(\mathsf{KL}\)-divergence_ arises when taking \(f(x)=x\log x\), the _\(\chi^{q}\)-divergence_ when taking \(f(x)=x^{q}-1\), and the _\(q\)-Renyi divergence_ is given by

\[\mathcal{R}_{q}(\mu\,\|\,\nu):=\tfrac{1}{q-1}\log\bigl{(}\chi^{q}(\mu\,\|\,\nu )+1\bigr{)}\,.\]

**Definition 2**.: We say that a probability measure \(\nu\) on \(\mathbb{R}^{d}\) satisfies a _Poincare inequality_ (PI) with parameter \(C_{\mathsf{Pl}}(\nu)\) if for all smooth functions \(f:\mathbb{R}^{d}\to\mathbb{R}\),

\[\mathrm{Var}_{\nu}f\leq C_{\mathsf{PI}}(\nu)\,\mathbb{E}_{\nu}[\|\nabla f\|^ {2}]\,,\] (PI)

where \(\mathrm{Var}_{\nu}f\coloneqq\mathbb{E}_{\nu}[|f-\mathbb{E}_{\nu}f|^{2}]\).

The Poincare inequality is implied by the log-Sobolev inequality.

**Definition 3**.: We say that a probability measure \(\nu\) on \(\mathbb{R}^{d}\) satisfies a _log-Sobolev inequality_ (LSI) with parameter \(C_{\mathsf{LSI}}(\nu)\) if for all smooth functions \(f:\mathbb{R}^{d}\to\mathbb{R}\),

\[\mathsf{Ent}_{\nu}(f^{2})\leq 2C_{\mathsf{LSI}}(\nu)\,\mathbb{E}_{\nu}[\| \nabla f\|^{2}]\,,\] (LSI-I)

where \(\mathsf{Ent}_{\nu}(f^{2}):=\mathbb{E}_{\nu}[f^{2}\log f^{2}]-\mathbb{E}_{\nu} [f^{2}]\log(\mathbb{E}_{\nu}[f^{2}])\). Equivalently, for any probability measure \(\mu\) over \(\mathbb{R}^{d}\) with \(\mu\ll\nu\),

\[2\,\mathsf{KL}(\mu\,\|\,\nu)\leq C_{\mathsf{LSI}}(\nu)\,\mathsf{FI}(\mu\,\|\, \nu)\,,\] (LSI-II)

where \(\mathsf{FI}(\mu\,\|\,\nu):=\mathbb{E}_{\mu}[\|\nabla\log\tfrac{\mathrm{d}\mu} {\mathrm{d}\nu}\|^{2}]\) is the _Fisher information_ of \(\mu\) with respect to \(\nu\).

## 3 Diffusion for uniform sampling

We propose the following \(\mathsf{In}\)-and-\(\mathsf{Out}\)1 sampler for uniformly sampling from \(\mathcal{K}\). Each iteration consists of two steps, one that might leave the body and the second accepted only if it is (back) in \(\mathcal{K}\).

Footnote 1: This name reflects the “geometry” of how the iterates are moving. As we elaborate in Remark 1, the name ‘proximal sampler’ may be more familiar to those from an optimization background.

It might be illuminating for the reader to compare this algorithm to the well-studied Ball walk (Algorithm 2); each proposed step is a uniform random point in a fixed-radius ball around the current point, and is accepted only if the proposed point is in the body \(\mathcal{K}\). In contrast, each iteration of \(\mathsf{In}\)-and-\(\mathsf{Out}\) is a two-step process, where the first step (Line 2) ignores the boundary of the body, and

Figure 1: Description of uniform samplers: (i) Ball walk: proposes a uniform random point \(z\) from \(B_{\delta}(x_{1})\), but \(z\notin\mathcal{K}\) so it stays at \(x_{1}=x_{2}\). (ii) Speedy walk: moves to \(x_{2}\) drawn uniformly at random from \(\mathcal{K}\cap B_{\delta}(x_{1})\). (iii) \(\mathsf{In}\)-and-\(\mathsf{Out}\): first moves to \(y_{2}\) obtained by taking a Gaussian step from \(x_{1}\), and then to \(x_{2}\) obtained by sampling the truncated Gaussian \(\mathcal{N}(y_{2},hI_{d})|_{\mathcal{K}}\).

the second step (Line 3) is accepted only if a proposal \(x_{i+1}\) is a feasible point in \(\mathcal{K}\). We will presently elaborate on the benefits of this variation.

Each successful iteration of the algorithm, i.e., one that is not declared "Failure", can be called a _proper_ step. We will see that the number of proper steps is directly bounded by isoperimetric constants (such as Poincare and log-Sobolev) of the target distribution. In fact, this holds quite generally without assuming the convexity of \(\mathcal{K}\). The implementation of an iteration is based on rejection sampling (Line 3), and our analysis of the efficiency of this step relies crucially on the convexity of \(\mathcal{K}\). This is reminiscent of the Speedy walk in the literature on convex body sampling (Algorithm 3), which is used as a tool to analyze proper steps of the Ball walk. We refer the reader to Appendix C for a brief survey on these and related walks.

This simple algorithm can be interpreted as a composition of "flows" in the space of measures. This view will allow us to use tools from stochastic analysis. In particular, we shall demonstrate how to interpret the two steps of one iteration of \(\mathsf{ln}\)-and-\(\mathsf{Out}\) as alternating _forward_ and _backward_ heat flows. We begin by defining an augmented probability measure on \(\mathbb{R}^{d}\times\mathbb{R}^{d}\) by

\[\pi(x,y)\propto\exp\bigl{(}-\tfrac{1}{2h}\|x-y\|^{2}\bigr{)}\,\mathds{1}_{ \mathcal{K}}(x)\,.\]

We denote by \(\pi^{X},\pi^{X|Y}(\cdot|y)\) the marginal distribution of its first component (resp. conditional distribution given the second component), and similarly denote by \(\pi^{Y},\pi^{Y|X}(\cdot|x)\) for the second component. In particular, the marginal in the first component \(\pi^{X}\) is the uniform distribution over \(\mathcal{K}\). Sampling from such a joint distribution to obtain the marginal on \(X\) (say), can be more efficient than directly working only with \(\pi^{X}\). This idea was utilized in Gaussian Cooling [6] and later as the restricted Gaussian Oracle (RGO) [26, 27].

Under this notation, Algorithm 1 corresponds to a Gibbs sampling scheme from the two marginals of \(\pi(x,y)\). To be precise, Line 2 and Line 3 correspond to sampling from

\[y_{i+1}\sim\pi^{Y|X}(\cdot|x_{i})=\mathcal{N}(x_{i},hI_{d})\qquad\text{ and }\qquad x_{i+1}\sim\pi^{X|Y}(\cdot|y_{i+1})=\mathcal{N}(y_{i+1},hI_{d})|_{ \mathcal{K}}\,.\]

We implement the latter step through rejection sampling; if the number of trials in Line 3 hits the threshold \(N\), then we halt and declare _failure_ of the algorithm. It is well known that such a Gibbs sampling procedure will ensure the desired stationarity of \(\pi(x,y)\). Note that, conditioned on the event that the algorithm does not fail, the resulting iterate will be an unbiased sample from the correct distribution.

Stochastic perspective: forward and backward heat flows.Our algorithm can be viewed through the lens of stochastic analysis, due to an improved analysis for the proximal sampling [27]. This view provides an interpolation in continuous-time, which is simple and powerful. To make this concrete, we borrow an exposition from [28, SS8.3]. We denote the successive laws of \(x_{i}\) and \(y_{i}\) by \(\mu_{i}^{X}\) and \(\mu_{i}^{Y}\), respectively. Recall that the first step of sampling from \(\pi^{Y|X}(\cdot|x_{i})\) (Line 2) yields \(\mu_{i+1}^{Y}=\int\pi^{Y|X=x}\,\mathrm{d}\mu_{i}^{X}(x)\). This is the result of evolving a probability measure under _(forward) heat flow_ of \(\mu_{i}^{X}\) for some time \(h\), given by the following stochastic differential equation: for \(Z_{0}\sim\mu_{i}^{X}\),

\[\mathrm{d}Z_{t}=\mathrm{d}B_{t}\] (FH)

where \(B_{t}\) is the standard Brownian process. We write \(\text{law}(Z_{t})=\mu_{i}^{X}P_{t}\). In particular, \(Z_{h}=Z_{0}+\zeta\sim\mu_{i}^{X}*\mathcal{N}(0,hI_{d})=\mu_{i+1}^{Y}\) for \(\zeta\sim\mathcal{N}(0,hI_{d})\). When \(\mu_{i}^{X}=\pi^{X}\), the first step of Algorithm 1 gives

\[\pi^{Y}(y)=[\pi^{X}*\mathcal{N}(0,hI_{d})](y)=\frac{1}{\operatorname{vol}( \mathcal{K})\,(2\pi h)^{d/2}}\int_{\mathcal{K}}\exp\bigl{(}-\frac{1}{2h}\|y-x \|^{2}\bigr{)}\,\mathrm{d}x\,.\] (3.1)The second step of sampling from \(\pi^{X|Y}(\cdot|y_{i+1})\) can be represented by \(\mu^{X}_{i+1}=\int\pi^{X|Y=y}\,\mathrm{d}\mu^{Y}_{i+1}(y)\) (Line 3). The continuous-time process corresponding to this step might not be obvious. However, let us consider (FH) with \(Z_{0}\sim\pi^{X}\). Then, \(Z_{h}\sim\pi^{Y}\), so the joint distribution of \((Z_{0},Z_{h})\) is simply \(\pi\). This implies that \((Z_{0}|Z_{h}=y)\sim\pi^{X|Y=y}\). Imagine there is an SDE _reversing_ the forward heat flow in a sense that if we are initialized deterministically at \(Z_{h}\sim\delta_{y}\) at time \(0\), then the law of the SDE at time \(h\) would be \(\mathsf{law}(Z_{0}|Z_{h}=y)=\pi^{X|Y=y}\). Then, this SDE would serve as a continuous-time interpolation of the second step.

Such a _time reversal_ SDE is indeed possible! The following SDE on \((Z_{t}^{\leftarrow})_{t\in[0,h]}\) initialized at \(Z_{0}^{\leftarrow}\sim\pi^{Y}=\pi^{X}P_{h}\) ensures \(Z_{h-t}\sim\mathsf{law}(Z_{t}^{\leftarrow})=\pi^{X}P_{h-t}\):

\[\mathrm{d}Z_{t}^{\leftarrow}=\nabla\log(\pi^{X}P_{h-t})(Z_{t}^{\leftarrow}) \,\mathrm{d}t+\mathrm{d}B_{t}\quad\text{for }t\in[0,h]\,.\] (BH)

Although this is designed to reverse (FH) **initialized by \(Z_{0}\sim\pi^{X}\)** (so \(Z_{h}=Z_{0}^{\leftarrow}\sim\pi^{Y}\)), its construction also ensures that if \(Z_{0}^{\leftarrow}\sim\delta_{y}\), a point mass, then \(Z_{h}^{\leftarrow}\sim\mathsf{law}(Z_{0}|Z_{h}=y)=\pi^{X|Y=y}\). Thus, if we initialize (BH) with \(Z_{0}^{\leftarrow}\sim\mu^{Y}_{i+1}\), then the law of \(Z_{h}^{\leftarrow}\) corresponds to \(\int\pi^{X|Y=y}\,\mathrm{d}\mu^{Y}_{i+1}(y)=\mu^{X}_{i+1}\).

_Remark 1_.: We note that \(\mathsf{ln}\)-and-Out is exactly the _proximal_ sampling scheme [26, 27, 29] for uniform distributions. The proximal sampler with a target density proportional to \(\exp(-V(x))\) considers an augmented distribution \(\pi(x,y)\propto\exp(-V(x)-\frac{1}{2h}\|x-y\|^{2})\) and then repeats the following two steps: (1) \(y_{i+1}\sim\pi^{Y|X=x_{i}}=\mathcal{N}(x_{i},hI_{d})\) and then (2) \(x_{i+1}\sim\pi^{X|Y=y_{i+1}}\). Naively, the proximal sampler is implemented by performing rejection sampling, with the Gaussian centered at the minimizer of \(\log\pi^{\cdot|Y=y_{i+1}}\) as the proposal. Realizing this would require a projection oracle (to \(\mathcal{K}\)), which is only known to be implementable with \(\mathcal{O}(d^{2})\) membership queries. \(\mathsf{ln}\)-and-Out completely avoids the need for a projection oracle.

## 4 Results

Our computational model is the classical general model for convex bodies [30]. We assume \(\mathrm{vol}(\mathcal{K})>0\) throughout this paper. Below, \(B_{r}(x)\) denotes the \(d\)-dimensional ball of radius \(r\) centered at \(x\).

**Definition 4** (Convex body oracle).: A _well-defined membership oracle_ for a convex body \(\mathcal{K}\subset\mathbb{R}^{d}\) is given by a point \(x_{0}\in\mathcal{K}\), a number \(D>0\), with the guarantee that \(B_{1}(x_{0})\subseteq\mathcal{K}\subseteq B_{D}(x_{0})\), and an oracle that correctly answers _YES_ or _NO_ to any query of the form "\(x\in\mathcal{K}\)?"

**Definition 5** (Warmness).: A distribution \(\mu\) is _\(M\)-warm_ with respect to another distribution \(\pi\) if for every \(x\) in the support of \(\pi\), we have \(\mathrm{d}\mu(x)\leq M\,\mathrm{d}\pi(x)\).

We now summarize our main result, which is further elaborated in Appendix B.4 (Theorem 5). Below, \(\pi^{\mathcal{K}}\) is the uniform distribution over \(\mathcal{K}\), and \(\mathcal{R}_{q}\) is the Renyi-divergence of order \(q\) (see Definition 1).

**Theorem 1** (Informal version of Theorem 5).: _For any given \(\eta,\varepsilon\in(0,1)\), \(q\geq 1\), and any convex body \(\mathcal{K}\) given by a well-defined membership oracle, there exist choices of parameters \(h,N\) such that \(\mathsf{ln}\)-and-\(\mathsf{Out}\), starting from an \(M\)-warm distribution, with probability at least \(1-\eta\), returns \(X\sim\mu\) such that \(\mathcal{R}_{q}(\mu\,\|\,\pi^{\mathcal{K}})\leq\varepsilon\). The number of proper steps is \(\widetilde{\mathcal{O}}(qd^{2}\Lambda\log^{2}\frac{M}{\eta\varepsilon})\), and the expected total number of membership queries is \(\widetilde{\mathcal{O}}(qMd^{2}\Lambda\log^{6}\frac{1}{\eta\varepsilon})\), where \(\Lambda\) is the largest eigenvalue of the covariance of \(\pi^{\mathcal{K}}\)._

_Remark 2_.: Despite our guarantee being in the much stronger "metric" of \(\mathcal{R}_{q}\) compared to the \(\mathsf{TV}\) guarantees of Ball walk, we do not have to incur any additional asymptotic complexity.

To obtain this result, one should choose the following values for the parameters: \(h^{-1}=\widetilde{\Theta}(d^{2}\log\frac{qM\Lambda}{\eta}\log\log\frac{1}{ \varepsilon})\), \(N=\widetilde{\Theta}(\frac{qMd^{2}\Lambda\log^{5}(1/\varepsilon)}{\eta})\). See Lemma 3 for more details.

\begin{table}
\begin{tabular}{c|c|c} \hline \hline  & Forward flow & Backward flow \\ \hline \hline SDE & \(\mathrm{d}Z_{t}=\mathrm{d}B_{t}\) & \(\mathrm{d}Z_{t}^{\leftarrow}=\nabla\log(\pi^{X}P_{h-t})(Z_{t}^{\leftarrow})\, \mathrm{d}t+\mathrm{d}B_{t}\) \\ \hline Fokker-Planck & \(\partial_{t}\mu_{t}=\frac{1}{2}\Delta\mu_{t}\) & \(\partial_{t}\mu_{t}^{\leftarrow}=-\operatorname{div}\bigl{(}\mu_{t}^{\leftarrow} \nabla\log(\pi^{X}P_{h-t})\bigr{)}+\frac{1}{2}\Delta\mu_{t}^{\leftarrow}\) \\ \hline \hline \end{tabular}
\end{table}
Table 1: The Fokker-Planck equations for the forward and backward heat flow describe how the laws of \(Z_{t}\) and \(Z_{t}^{\leftarrow}\) in (FH) and (BH) evolve over time. See Appendix B.2 for details.

Finally, while the assumption of warmness for the initialization may seem strong at the outset, for well-rounded convex bodies (\(\mathbb{E}_{X\sim\pi}[\|X\|^{2}]\leq C^{2}d\) for some constant \(C\)), it is possible to generate an \(\mathcal{O}(1)\) warm-start with complexity \(\widetilde{\mathcal{O}}(d^{3})\). See [6, 31] for details.

We note that for \(X\sim\pi^{\mathcal{K}}\),

\[\|\mathrm{Cov}(\pi^{\mathcal{K}})\|_{\mathsf{op}}\leq\mathrm{tr}(\mathrm{Cov}( \pi^{\mathcal{K}}))=\mathbb{E}[\|X-\mathbb{E}X\|^{2}]\leq D^{2}\,.\]

The above guarantee in the Renyi divergence immediately provides \(\mathcal{W}_{2},\mathsf{TV},\mathsf{KL}\), and \(\chi^{2}\) guarantees as special cases. For two distributions \(\mu\) and \(\pi\), we have

1. \(\mathsf{KL}(\mu\,\|\,\pi)=\lim_{q\downarrow 1}\mathcal{R}_{q}(\mu\|\,\pi) \leq\mathcal{R}_{q}(\mu\|\,\pi)\leq\mathcal{R}_{q^{\prime}}(\mu\|\,\pi)\leq \mathcal{R}_{\infty}(\mu\|\,\pi)=\log\sup\frac{\mathrm{d}\mu}{\mathrm{d}\pi}\), \(1<q\leq q^{\prime}\).
2. \(2\,\|\mu-\pi\|_{\mathsf{TV}}^{2}\leq\mathsf{KL}(\mu\,\|\,\pi)\leq\log(\chi^{2 }(\mu\,\|\,\pi)+1)=\mathcal{R}_{2}(\mu\,\|\,\pi)\).
3. \(\mathcal{W}_{2}^{2}(\mu,\pi)\leq 2C_{\mathsf{LSI}}(\pi)\,\mathsf{KL}(\mu\,\|\,\pi)\) (Talagrand's \(\mathsf{T}_{2}\)-inequality) and \(C_{\mathsf{LSI}}(\pi^{\mathcal{K}})\lesssim D^{2}\).
4. \(\mathcal{W}_{2}^{2}(\mu,\pi)\leq 2C_{\mathsf{PI}}(\pi)\,\chi^{2}(\mu\,\|\,\pi)\)[32] and \(C_{\mathsf{PI}}(\pi^{\mathcal{K}})\lesssim\|\mathrm{Cov}(\pi^{\mathcal{K}})\|_ {\mathsf{op}}\log d\).

The query complexity is better if the convex body is (near-)_isotropic_, i.e., the uniform distribution over the body has (near-)identity covariance. This relies on recent estimates of the worst-case Poincare constant for isotropic log-concave distributions [33, 34]. The condition that the convex body is isotropic can be achieved in practice through a _rounding_ procedure [35]. See SS5 for more details.

**Corollary 1**.: _Assume that \(\pi^{\mathcal{K}}\) is near-isotropic, i.e. the operator norm of its covariance is \(\mathcal{O}(1)\). Under the same setting as above, \(\mathsf{ln}\)-and-\(\mathsf{Out}\) succeeds with probability \(1-\eta\), returning \(X\sim\mu\) such that \(\mathcal{R}_{q}(\mu\,\|\,\pi^{\mathcal{K}})\leq\varepsilon\). The number of proper steps is \(\widetilde{\mathcal{O}}(qd^{2}\log^{2}\frac{M}{\eta\varepsilon})\), and the expected total number of membership queries is \(\widetilde{\mathcal{O}}(qMd^{2}\log^{6}\frac{1}{\eta\varepsilon})\)._

Our analysis will in fact show that the bound on the number of proper steps holds for general _non-convex bodies_ and _any feasible start_ in \(\mathcal{K}\). This is deduced under an \(M\)-warm start in Corollaries 2 and 3. We remark that such a bound for non-convex uniform sampling is not known for the Ball walk or the Speedy walk.

**Theorem 2**.: _For any given \(\varepsilon\in(0,1)\) and set \(\mathcal{K}\subset B_{D}(0)\) with \(\mathrm{vol}(\mathcal{K})>0\), \(\mathsf{ln}\)-and-\(\mathsf{Out}\) with variance \(h\) and \(M\)-warm initial distribution achieves \(\mathcal{R}_{q}(\mu_{m}^{X}\,\|\,\pi^{X})\leq\varepsilon\) after the following number of iterations:_

\[m=\min\begin{cases}\mathcal{O}\big{(}qh^{-1}C_{\mathsf{PI}}(\pi^{X})\log\frac{ M}{\varepsilon}\big{)}&\text{for }q\geq 2\,,\\ \mathcal{O}\big{(}qh^{-1}C_{\mathsf{LSI}}(\pi^{X})\log\frac{\log M}{\varepsilon }\big{)}&\text{for }q\geq 1\,.\end{cases}\]

We have two different convergence results above under (LSI-l) and (Pl). Under (LSI-l) we have a _doubly-logarithmic_ dependence on the warmness parameter \(M\). On the other hand, using (Pl), which is weaker than (LSI-l) (in general, \(C_{\mathsf{PI}}\leq C_{\mathsf{LSI}}\)), the dependence on \(M\) is logarithmic. We discuss implications of our results further in SS4.2.

### Outline of analysis.

We first record two fundamental lemmas, which introduce the mathematical formalism for our analysis. The first is the existence of forward and backward heat flows (Lemma 12), which will interpolate each line in Algorithm 1. These flow equations describe how the laws of \(Z_{t}\) and \(Z_{t}^{\leftarrow}\) in (FH) and (BH) evolve respectively over time. All proofs are deferred to Appendix B.

**Lemma 1**.: _The forward heat flow equation with initial distribution \(\mu_{0}\) is given by_

\[\partial_{t}\mu_{t}=\tfrac{1}{2}\Delta\mu_{t}\,,\]

_and its backward heat flow equation is given by_

\[\partial_{t}\mu_{t}^{\leftarrow}=-\operatorname{div}\!\left(\mu_{t}^{\leftarrow} \nabla\log(\pi^{X}P_{h-t})\right)+\tfrac{1}{2}\Delta\mu_{t}^{\leftarrow}\quad \text{with }\mu_{0}^{\leftarrow}=\mu_{h}\,.\]

_These admit (weak) solutions on \([0,h]\) for any initial distribution \(\mu_{0}\) with \(\frac{\mathrm{d}\mu_{0}}{\mathrm{d}\pi^{X}}\leq M<\infty\)._

One successful iteration of \(\mathsf{ln}\)-and-\(\mathsf{Out}\) is exactly the same as the composition of running the forward heat flow and then backward heat flow, both for time \(h\).

**Lemma 2**.: _Let \(\mu_{k}^{X}\) be the law of the \(k\)-th iterate \(x_{k}\) of \(\mathsf{In\mbox{-}and\mbox{-}Out}\). If (\(\mathsf{FH}\)) is initialized with \(\mathsf{law}(Z_{0})=\mu_{k}^{X}\), then \(\mathsf{law}(Z_{h})=\mu_{k+1}^{Y}\). If (\(\mathsf{BH}\)) is initialized with \(\mathsf{law}(Z_{0}^{\leftarrow})=\mu_{k+1}^{Y}\), then \(\mathsf{law}(Z_{h}^{\leftarrow})=\mu_{k+1}^{X}\)._

We summarize our proof strategy below, which requires us to demonstrate two facts: (i) The current distribution should converge to the uniform distribution, (ii) within each iteration of the algorithm, the failure probability and the expected number of rejections should be small enough. In this section we provide the main claims within each of these parts, and defer the remaining details to Appendix B.

While each individual component resembles pre-existing work in the literature, in their synthesis we will demonstrate how to interleave past developments in theoretical computer science, optimal transport, and functional analysis. The combination of these in this domain yields elegant and surprisingly simple proofs, as well as stronger results.

Part (i).Broadly speaking, we need to demonstrate that the corresponding Markov chain is rapidly mixing. Here, we use the heat flow perspective to derive mixing rates under any suitable divergence measure (such as \(\mathsf{KL}\), \(\chi^{2}\), or \(\mathcal{R}_{q}\)). This extends known results for the unconstrained setting [27]. To summarize the proof, by considering instead the solutions after small time \(t\), we invoke known contraction results from [27] and then use a continuity argument to conclude the proof.

**Theorem 3**.: _Let \(\mu_{k}^{X}\) be the law of the \(k\)-th output of \(\mathsf{In\mbox{-}and\mbox{-}Out}\) with initial distribution \(\mu_{0}^{X}\). Let \(C_{\mathsf{LSI}}\) be the (\(\mathsf{LSI}\)-) constant of the uniform distribution \(\pi^{X}\) over \(\mathcal{K}\). Then, for any \(q\geq 1\),_

\[\mathcal{R}_{q}(\mu_{k}^{X}\parallel\pi^{X})\leq\frac{\mathcal{R}_{q}(\mu_{0} ^{X}\parallel\pi^{X})}{(1+h/C_{\mathsf{LSI}})^{2k/q}}\,.\]

_For \(C_{\mathsf{PI}}\) the (\(\mathsf{PI}\)) constant of \(\pi^{X}\),_

\[\chi^{2}(\mu_{k}^{X}\parallel\pi^{X})\leq\frac{\chi^{2}(\mu_{0}^{X}\parallel \pi^{X})}{(1+h/C_{\mathsf{PI}})^{2k}}\,.\]

_Furthermore, for any \(q\geq 2\),_

\[\mathcal{R}_{q}(\mu_{k}^{X}\parallel\pi^{X})\leq\begin{cases}\mathcal{R}_{q}( \mu_{0}^{X}\parallel\pi^{X})-\frac{2k\log(1+h/C_{\mathsf{PI}})}{q}&\text{if }k\leq\frac{q(\mathcal{R}_{q}(\mu_{0}^{X}\parallel\pi^{X})-1)}{2\log(1+h/C_{ \mathsf{PI}})}\,,\\ (1+h/C_{\mathsf{PI}})^{-2(k-k_{0})/q}&\text{if }k\geq k_{0}:=\left\lceil\frac{q( \mathcal{R}_{q}(\mu_{0}^{X}\parallel\pi^{X})-1)}{2\log(1+h/C_{\mathsf{PI}})} \right\rceil.\end{cases}\]

The final result reduces the problem of obtaining a mixing guarantee to that of demonstrating a functional inequality on the target distribution. For this, it is not strictly necessary that \(\mathcal{K}\) be convex.

Part (ii).Convexity of \(\mathcal{K}\) is crucial this time unlike Part (i). We show in Appendix B.3 that the failure probability remains under control by taking a suitable variance \(h\) and threshold \(N\), and that the expected number of trials per iteration is of order \(\log N\), not \(N\). To do this, we apply a detailed argument involving local conductance and the convexity of \(\mathcal{K}\), which relies on techniques from [36].

**Lemma 3** (Per-iteration guarantees).: _Let \(\mathcal{K}\) be any convex body in \(\mathbb{R}^{d}\) presented by a well-defined membership oracle, \(\pi^{X}\) the uniform distribution over \(\mathcal{K}\), and \(\mu\) an \(M\)-warm initial distribution with respect to \(\pi^{X}\). For any given \(m\in\mathbb{N}\) and \(\eta\in(0,1)\), set \(Z=\frac{9mM}{\eta}(\geq 9)\), \(h=\frac{\log\log Z}{2d^{2}\log\mathbb{Z}}\) and \(N=Z\log^{4}Z=\widetilde{\mathcal{O}}(\frac{mM}{\eta})\). Then, the failure probability of one iteration of \(\mathsf{In\mbox{-}and\mbox{-}Out}\) is at most \(\eta/m\), and the expected membership queries per iteration is \(\mathcal{O}\big{(}M\log^{4}\frac{mM}{\eta}\big{)}\)._

### Discussion

No need to be lazy.Previous uniform samplers like \(\mathsf{Ball\ walk}\) are made _lazy_ (i.e., with probability \(1/2\), it does nothing), to ensure convergence to the target stationary distribution. However, our algorithm does not need this, as our sampler is shown to directly contract towards the target.

Unified framework.We remark that Theorem 2 places the previously known mixing guarantees for \(\mathsf{Ball\ walk}\), \(\mathsf{Speedy\ walk}\) in a unified framework. Existing tight guarantees for \(\mathsf{Speedy\ walk}\) are in TV distance and based on the log-Sobolev constant, assuming an oracle for implementing each step [37].

The known convergence guarantees of Ball walk (see Appendix C for details), namely the mixing time of \(\widetilde{\mathcal{O}}(Md^{2}D^{2}\log\frac{1}{\varepsilon})\) for TV distance, are for the composite algorithm [Speedy walk\(+\)rejection sampling]. Here Speedy walk records only the accepted steps of Ball walk, so its stationary distribution differs slightly from the uniform distribution (and can be corrected with a post-processing step). On the other hand, In-and-Out actually converges to \(\pi^{\mathcal{K}}\) without any adjustments and achieves stronger Renyi divergence bounds in the same asymptotic complexity. Our analysis shows that the mixing guarantee is determined by isoperimetric constants of the target (Poincare or log-Sobolev).

Effective step size.The Ball walk's largest possible step size is of order \(1/\sqrt{d}\) (see Appendix C) to keep the rejection probability bounded by a constant. This bound could also be viewed as an "effective" step size of In-and-Out, since the \(\ell_{2}\)-norm of the Gaussian \(\mathcal{N}(0,hI)\) is concentrated around \(\sqrt{hd}\) and we will set the variance \(h\) of In-and-Out to \(\widetilde{\mathcal{O}}(1/d^{2})\), so we have \(\sqrt{hd}\approx 1/\sqrt{d}\).

What has really changed?In-and-Out has clear similarities to both Ball walk and Speedy walk. What then are the changes that allow us to use continuous-time interpolation? One step of Ball walk is [random step (\(y\in B_{\delta}(x)\)) + Metropolis-filter (accept if \(y\in\mathcal{K}\))]. This filtering is an abrupt discrete step, and it is unclear how to control contraction. It could be replaced by a step of Speedy walk (\(x\sim\text{Unif}(B_{\delta}(y)\cap\mathcal{K})\)). Then, each iteration of In-and-Out can be viewed as a Gaussian version of a Ball walk's proposal\(+\)Speedy walk algorithm.

How can we compare In-and-Out with Speedy walk? Iterating speedy steps leads to a biased distribution. As clarified in Remark 3, one step of (a Gaussian version of) Speedy walk can be understood as a step of backward heat flow. Therefore, if one can control the isoperimetric constants of the biased distribution along the trajectory of the backward flow, then contraction of Speedy walk toward the biased distribution will follow from the simultaneous backward analysis.

## 5 Related work

Sampling from constrained log-concave distributions is a fundamental task arising in many fields. Uniform sampling with convex constraints is its simplest manifestation, which was first studied as a core subroutine for a randomized volume-computation algorithm [1]. Since then, this fundamental problem has been studied for over three decades [2; 3; 4; 38; 5; 25; 24]. We review these algorithms, grouping them under three categories -- geometric random walks, structured samplers, and diffusion-type samplers. Below, \(\mathcal{K}\) is convex.

Geometric random walk.We discuss two geometric random walks - Ball walk[3; 4] and Hit-and-Run [39; 17]. Ball walk is a simple metropolized random walk; it draws \(y\) uniformly at random from a ball of radius \(\delta\) centered at a current point \(x\), and moves to \(y\) if \(y\in\mathcal{K}\) and stays at \(x\) otherwise. In the literature, Ball walk actually refers to a composite algorithm consisting of [Speedy walk\(+\) rejection sampling], where Speedy walk records only the accepted steps of Ball walk (see Appendix C for details). The step size \(\delta\) should be set to \(\mathcal{O}(d^{-1/2})\) to avoid stepping outside of \(\mathcal{K}\). [4] showed that Ball walk needs \(\widetilde{\mathcal{O}}(Md^{2}D^{2}\log\frac{1}{\varepsilon})\) membership queries to be \(\varepsilon\)-close to \(\pi^{\mathcal{K}}\) in TV, where \(D\) is the diameter of \(\mathcal{K}\), and the warmness parameter \(M\) measures the closeness of the initial distribution to the target uniform distribution \(\pi^{\mathcal{K}}\).

Hit-and-Run is another zeroth-order algorithm that needs _no step size_; it picks a uniform random line \(\ell\) passing a current point, and move to a uniform random point on \(\ell\cap\mathcal{K}\). [5] shows that, if we define the second moment as \(R^{2}:=\mathbb{E}_{X\sim\pi^{\mathcal{K}}}[\|X-\mathbb{E}X\|^{2}]\), then Hit-and-Run requires \(\mathcal{O}(d^{2}R^{2}\log\frac{M}{\varepsilon})\) queries. Notably, this algorithm has a poly-logarithmic dependence on \(M\) as opposed to Ball walk.

Both algorithm are affected by skewed shape of \(\mathcal{K}\) (i.e., large \(D\) or \(R\)), so these samplers are combined with pre-processing step called _rounding_. This procedure finds a linear transformation that makes the geometry of \(\mathcal{K}\) less skewed and so more amenable to sampling. In literature, there exists a randomized algorithm [35] that rounds \(\mathcal{K}\) and generates a good warm start (i.e., \(M=\mathcal{O}(1)\)), with Ball walk used as a core subroutine. This algorithm takes up \(\widetilde{\mathcal{O}}(d^{3.5})\) queries in total, and in such position with the good warm start, Ball walk only needs \(\widetilde{\mathcal{O}}(d^{2}\log\frac{1}{\varepsilon})\) queries to sample from \(\pi^{\mathcal{K}}\).

Structured samplers.The aforementioned samplers based on geometric random walks require _only_ access to the membership oracle of the convex body _without_ any additional structural assumptions.

The alternate paradigm of _geometry-aware sampling_ attempts to exploit the _structure_ of convex constraints, with the aim of expediting the convergence of the resultant sampling schemes. One common assumption is to make available a _self-concordant barrier function_\(\phi\) which has regularity on its high-order derivatives and blows up when approaching the boundary \(\partial\mathcal{K}\). The Hessian of \(\phi\) encodes the local geometry of the constraint, and the samplers often work directly with \(\nabla^{2}\phi\).

The first canonical example of such a zeroth-order sampler is Dikin walk used when \(\mathcal{K}\) is given by \(m\) linear constraints [40]; it draws a uniform sample from an ellipsoid (characterized by \(\nabla^{2}\phi\)) of fixed radius around a current point, and is often combined with a Metropolis adjustment. [40] shows that Dikin walk mixes in \(\mathcal{O}(md\log\frac{M}{\varepsilon})\) steps, although each iteration is slightly more expensive than one membership query. This algorithm requires no rounding, but still needs a good warm-start, which can be achieved by an annealing-type algorithm using \(\tilde{\mathcal{O}}(md)\) iterations of Dikin walk [41].

Riemannian Hamiltonian Monte Carlo is a structured sampler that exploits the first-order information of the potential (i.e., \(\nabla\log(1/\pi)\)) [42]; its proposal is given as the solution to the Hamilton's ODE equation, followed by the Metropolis-filter. In the linear-constraint setting above, it requires \(\mathcal{O}(md^{2/3}\log\frac{M}{\varepsilon})\) many iterations to achieve \(\varepsilon\)-close distance to \(\pi^{\mathcal{K}}\)[18]. This sampler is further analyzed for practical ODE solvers [43] and for more sophisticated self-concordant barriers [44].

Similarly, Mirror Langevin [45, 46, 47, 48] is a class of algorithms which converts the constrained problem into an unconstrained one obtained by considering the pushforward of the constrained space by \(\nabla\phi\). The algorithm can also be metropolized [49]. The best known rate for this algorithm is \(\tilde{\mathcal{O}}(d\log\frac{1}{\varepsilon})\) under some strong assumptions on \(\phi\).

Diffusion-type samplers.Samplers based on discretizations of Ito diffusions, stochastic processes which rapidly mix to \(\pi\) in continuous time, have long been used for sampling without constraints [19, 20, 21, 28]. While the underlying stochastic processes generalize easily to constrained settings, the discretization analysis relies crucially on the smoothness of the target distribution. This is clearly impossible to achieve in the constrained setting, so some techniques are required to circumvent this difficulty. These algorithms, however, generalize easily to the more general problem of sampling from distributions of the form \(\tilde{\pi}^{X}\propto e^{-7}\mathds{1}_{\mathcal{K}}\), by incorporating first order information from \(f\).

The first approach for adapting diffusion-based samplers [50, 25, 51] iterates a two-step procedure. First, a random step is taken, with \(x_{k+1/2}\sim\mathcal{N}(x_{k},2hI_{d})\) for some appropriately chosen step \(h\),2 and then project it to \(\mathcal{K}\), i.e., \(x_{k+1}=\mathsf{proj}_{\mathcal{K}}(x_{k+1/2})\). The complexity is given in terms of queries to a _projection oracle_, each call to which can be implemented with a polynomial number of membership oracle queries; a total of \(\tilde{\mathcal{O}}(d^{2D^{3}}/\varepsilon^{4})\) queries are needed to be \(\varepsilon\)-close in \(\mathcal{W}_{2}\) to \(\pi^{X}\). Another approach, which uses an algorithmically designed "soft" penalty instead of a projection, was proposed in [52], and achieves a rate estimate of \(\tilde{\mathcal{O}}(\nicefrac{{d}}{{\varepsilon^{10}}})\).

Footnote 2: A gradient step can be added in the more general case, for sampling from \(\tilde{\pi}^{X}\).

A second approach, suggested by [24], considers a different proximal scheme, which performs a "soft projection" onto \(\mathcal{K}\), by taking steps like \(\mathcal{N}((1-h\lambda^{-1})x_{k}+h\mathsf{proj}_{\mathcal{K}}(x_{k}),2hI_{d})\). It is called Moreau-Yosida regularized Langevin, named after an analogous regularization scheme for constrained optimization. This scheme also relies on access to a projection oracle for \(\mathcal{K}\), and quantifies their query complexity accordingly. Their final rate estimate is \(\tilde{\mathcal{O}}(d^{\nicefrac{{d}}{{\varepsilon}}}/\varepsilon^{\nicefrac{{ \mathrm{e}}}{{\mathrm{e}}}})\) to be \(\varepsilon\)-close in \(\mathsf{TV}\) distance to \(\pi^{X}\).

Observing the prior work integrating diffusion-based sampling with convex constraints, the dependence on the key parameters \(d,\varepsilon\), while polynomial, are many orders worse than the rates for zeroth-order samplers such as Ball walk, Hit-and-Run. In contrast, our analysis not only recovers but in some sense surpasses the known rates for Ball walk, Hit-and-Run, while harmonizing well with the continuous-time perspective of diffusions.

Proximal schemes for sampling.The Gibbs sampling scheme used in this paper was inspired by the restricted Gaussian oracle introduced in [26] (in turn inspired by Gaussian Cooling [6]), which alternately iterates between a pure Gaussian step, and a "proximal" step (which we elaborate in our exposition). This scheme was given novel interpretations by [27], which showed that it interpolates the forward and backward heat flows, in the sense defined by [53]. The backward heat flow itself is intimately related to stochastic localization schemes, invented and popularized in [54, 55].

This formulation proved surprisingly powerful, allowing many existing rates in unconstrained sampling to be recovered from a relatively simple analysis. This was further extended by [29] to achieve the current state-of-the-art rate in unconstrained sampling. Finally, [56] suggest that this could be applied to tackle some constrained problems. However, the assumptions in this final mentioned work are not compatible with the uniform sampling problem on general convex bodies.

## 6 Conclusion

We propose \(\mathsf{ln}\)-and-Out for uniform sampling on convex bodies, and show that it obtains guarantees in \(\mathcal{R}_{q}\) divergence from an \(M\)-warm start, substantially stronger than prior work, and without increasing the computational complexity. Notably, our proof technique is quite different and provides a direct reduction to isoperimetric constants of the target distribution.

While the current work focuses on uniform sampling of convex bodies, there are a number of natural extensions that may be considered. It may be possible to prove analogous results for general log-concave distributions, and on non-log-concave distributions satisfying isoperimetric inequalities, e.g., it is open to find a polytime algorithm for sampling a general distribution satisfying a Poincare inequality presented by a function oracle (with no smoothness assumptions).

Acknowledgements.We are deeply grateful to Andre Wibisono and Sinho Chewi for helpful comments and pointers to the literature for Lemma 10. This work was supported in part by NSF award 210644, NSERC through the CGS-D award, and a Simons Investigator award.

## References

* [1] Martin Dyer, Alan Frieze, and Ravi Kannan. A random polynomial-time algorithm for approximating the volume of convex bodies. _Journal of the ACM (JACM)_, 38(1):1-17, 1991.
* [2] Laszlo Lovasz and Miklos Simonovits. The mixing rate of Markov chains, an isoperimetric inequality, and computing the volume. In _Foundations of Computer Science (FOCS)_, pages 346-354. IEEE, 1990.
* [3] Laszlo Lovasz and Miklos Simonovits. Random walks in a convex body and an improved volume algorithm. _Random Structures & Algorithms (RS&A)_, 4(4):359-412, 1993.
* [4] Ravi Kannan, Laszlo Lovasz, and Miklos Simonovits. Random walks and an \(O^{*}(n^{5})\) volume algorithm for convex bodies. _Random Structures & Algorithms (RS&A)_, 11(1):1-50, 1997.
* [5] Laszlo Lovasz and Santosh S Vempala. Hit-and-run from a corner. _SIAM Journal on Computing (SICOMP)_, 35(4):985-1005, 2006.
* [6] Ben Cousins and Santosh S Vempala. Gaussian Cooling and \(O^{*}(n^{3})\) algorithms for volume and Gaussian volume. _SIAM Journal on Computing (SICOMP)_, 47(3):1237-1273, 2018.
* [7] Ben Cousins and Santosh S Vempala. A practical volume algorithm. _Mathematical Programming Computation_, 8(2):133-160, 2016.
* [8] Hulda S Haraldsdottir, Ben Cousins, Ines Thiele, Ronan MT Fleming, and Santosh S Vempala. CHRR: coordinate hit-and-run with rounding for uniform sampling of constraint-based models. _Bioinformatics_, 33(11):1741-1743, 2017.
* [9] Yunbum Kook, Yin Tat Lee, Ruoqi Shen, and Santosh S Vempala. Sampling with Riemannian Hamiltonian Monte Carlo in a constrained space. In _Advances in Neural Information Processing Systems (NeurIPS)_, volume 35, pages 31684-31696, 2022.
* [10] Nathan E Lewis, Harish Nagarajan, and Bernhard O Palsson. Constraining the metabolic genotype-phenotype relationship using a phylogeny of in silico methods. _Nature Reviews Microbiology_, 10(4):291-305, 2012.

* Thiele et al. [2013] Ines Thiele, Neil Swainston, Ronan MT Fleming, Andreas Hoppe, Swagatika Sahoo, Maike K Aurich, Hulda Haraldsdottir, Monica L Mo, Ottar Rolfsson, Miranda D Stobbe, et al. A community-driven global reconstruction of human metabolism. _Nature Biotechnology_, 31(5):419-425, 2013.
* McSherry and Talwar [2007] Frank McSherry and Kunal Talwar. Mechanism design via differential privacy. In _Foundations of Computer Science (FOCS)_, pages 94-103. IEEE, 2007.
* Mironov [2017] Ilya Mironov. Renyi differential privacy. In _Computer Security Foundations Symposium (CSF)_, pages 263-275. IEEE, 2017.
* Bingham et al. [2019] Eli Bingham, Jonathan P. Chen, Martin Jankowiak, Fritz Obermeyer, Neeraj Pradhan, Theofanis Karaletsos, Rohit Singh, Paul A. Szerlip, Paul Horsfall, and Noah D. Goodman. Pyro: Deep universal probabilistic programming. _The Journal of Machine Learning Research (JMLR)_, 20:28:1-28:6, 2019.
* Team [2020] Stan Development Team. RStan: the R interface to Stan, 2020. URL http://mc-stan.org/. R package version 2.21.2.
* Vempala [2005] Santosh S Vempala. Geometric random walks: a survey. _Combinatorial and Computational Geometry_, 52(573-612):2, 2005.
* Lovasz [1999] Laszlo Lovasz. Hit-and-run mixes fast. _Mathematical Programming_, 86:443-461, 1999.
* Lee and Vempala [2018] Yin Tat Lee and Santosh S Vempala. Convergence rate of Riemannian Hamiltonian Monte Carlo and faster polytope volume computation. In _Symposium on Theory of Computing (STOC)_, pages 1115-1121, 2018.
* Besag et al. [1995] Julian Besag, Peter Green, David Higdon, and Kerrie Mengersen. Bayesian computation and stochastic systems. _Statistical Science_, pages 3-41, 1995.
* Dalalyan and Tsybakov [2012] Arnak S Dalalyan and Alexandre B Tsybakov. Sparse regression learning by aggregation and Langevin Monte-Carlo. _Journal of Computer and System Sciences_, 78(5):1423-1443, 2012.
* Dalalyan [2017] Arnak Dalalyan. Further and stronger analogy between sampling and optimization: Langevin Monte Carlo and gradient descent. In _Conference on Learning Theory (COLT)_, pages 678-689. PMLR, 2017.
* Durmus et al. [2019] Alain Durmus, Szymon Majewski, and Blazej Miasojedow. Analysis of Langevin Monte Carlo via convex optimization. _The Journal of Machine Learning Research (JMLR)_, 20(1):2666-2711, 2019.
* Vempala and Wibisono [2019] Santosh S Vempala and Andre Wibisono. Rapid convergence of the unadjusted Langevin algorithm: Isoperimetry suffices. _Advances in Neural Information Processing Systems (NeurIPS)_, 32, 2019.
* Brosse et al. [2017] Nicolas Brosse, Alain Durmus, Eric Moulines, and Marcelo Pereyra. Sampling from a log-concave distribution with compact support with proximal Langevin Monte Carlo. In _Conference on Learning Theory (COLT)_, volume 65, pages 319-342. PMLR, 2017.
* Bubeck et al. [2018] Sebastien Bubeck, Ronen Eldan, and Joseph Lehec. Sampling from a log-concave distribution with projected Langevin Monte Carlo. _Discrete & Computational Geometry (DCG)_, 59:757-783, 2018.
* Lee et al. [2021] Yin Tat Lee, Ruoqi Shen, and Kevin Tian. Structured logconcave sampling with a restricted Gaussian oracle. In _Conference on Learning Theory (COLT)_, pages 2993-3050. PMLR, 2021.
* Chen et al. [2022] Yongxin Chen, Sinho Chewi, Adil Salim, and Andre Wibisono. Improved analysis for a proximal algorithm for sampling. In _Conference on Learning Theory (COLT)_, pages 2984-3014. PMLR, 2022.
* Chewi [2024] Sinho Chewi. _Log-concave sampling_. Book draft available at https://chewisinho.github.io, 2024.

* [29] Jiaojiao Fan, Bo Yuan, and Yongxin Chen. Improved dimension dependence of a proximal algorithm for sampling. In _Conference on Learning Theory (COLT)_, pages 1473-1521. PMLR, 2023.
* [30] Martin Grotschel, Laszlo Lovasz, and Alexander Schrijver. _Geometric algorithms and combinatorial optimization_, volume 2. Springer, 1988.
* [31] Yunbum Kook and Matthew S Zhang. Renyi-infinity constrained sampling with \(d^{3}\) membership queries. In _To appear in Symposium on Discrete Algorithms (SODA)_, 2025.
* [32] Yuan Liu. The Poincare inequality and quadratic transportation-variance inequalities. _Electronic Journal of Probability_, 25(1):1-16, 2020.
* [33] Ravi Kannan, Laszlo Lovasz, and Miklos Simonovits. Isoperimetric problems for convex bodies and a localization lemma. _Discrete & Computational Geometry_, 13(3):541-559, 1995.
* [34] Boaz Klartag. Logarithmic bounds for isoperimetry and slices of convex sets. _Ars Inveniendi Analytica_, 2023.
* [35] He Jia, Aditi Laddha, Yin Tat Lee, and Santosh S Vempala. Reducing isotropy and volume to KLS: an \(O^{*}(n^{3}\psi^{2})\) volume algorithm. In _Symposium on Theory of Computing (STOC)_, pages 961-974, 2021.
* [36] Mikhail Belkin, Hariharan Narayanan, and Partha Niyogi. Heat flow and a faster algorithm to compute the surface area of a convex body. In _Foundations of Computer Science (FOCS)_, pages 47-56. IEEE, 2006.
* [37] Yin Tat Lee and Santosh Srinivas Vempala. Eldan's stochastic localization and the KLS hyperplane conjecture: An improved lower bound for expansion. In _Foundations of Computer Science (FOCS)_, pages 998-1007. IEEE, 2017.
* [38] Laszlo Lovasz and Santosh S Vempala. Hit-and-run is fast and fun. _preprint, Microsoft Research_, 2003.
* [39] Robert L Smith. Efficient Monte Carlo procedures for generating points uniformly distributed over bounded regions. _Operations Research_, 32(6):1296-1308, 1984.
* [40] Ravindran Kannan and Hariharan Narayanan. Random walks on polytopes and an affine interior point method for linear programming. _Mathematics of Operations Research_, 37(1):1-20, 2012.
* [41] Yunbum Kook and Santosh S Vempala. Gaussian Cooling and Dikin walks: The Interior-Point Method for logconcave sampling. _arXiv preprint arXiv:2307.12943_, 2023.
* [42] Mark Girolami and Ben Calderhead. Riemann manifold Langevin and Hamiltonian Monte Carlo methods. _Journal of the Royal Statistical Society: Series B (Statistical Methodology)_, 73(2):123-214, 2011.
* [43] Yunbum Kook, Yin Tat Lee, Ruoqi Shen, and Santosh S Vempala. Condition-number-independent convergence rate of Riemannian Hamiltonian Monte Carlo with numerical integrators. In _Conference on Learning Theory (COLT)_, volume 195, pages 4504-4569. PMLR, 2023.
* [44] Khashayar Gatmiry, Jonathan Kelner, and Santosh S Vempala. Sampling with barriers: Faster mixing via Lewis weights. _arXiv preprint arXiv:2303.00480_, 2023.
* [45] Kelvin Shuangjian Zhang, Gabriel Peyre, Jalal Fadili, and Marcelo Pereyra. Wasserstein control of mirror Langevin Monte Carlo. In _Conference on Learning Theory (COLT)_, pages 3814-3841. PMLR, 2020.
* [46] Qijia Jiang. Mirror Langevin Monte Carlo: the case under isoperimetry. _Advances in Neural Information Processing Systems (NeurIPS)_, 34:715-725, 2021.
* [47] Kwangjun Ahn and Sinho Chewi. Efficient constrained sampling via the mirror-Langevin algorithm. _Advances in Neural Information Processing Systems (NeurIPS)_, 34:28405-28418, 2021.

* [48] Ruilin Li, Molei Tao, Santosh S Vempala, and Andre Wibisono. The mirror Langevin algorithm converges with vanishing bias. In _International Conference on Algorithmic Learning Theory (ALT)_, pages 718-742. PMLR, 2022.
* [49] Vishwak Srinivasan, Andre Wibisono, and Ashia Wilson. Fast sampling from constrained spaces using the Metropolis-adjusted mirror Langevin algorithm. _arXiv preprint arXiv:2312.08823_, 2023.
* [50] Sebastien Bubeck, Ronen Eldan, and Joseph Lehec. Finite-time analysis of projected Langevin Monte Carlo. In _Advances in Neural Information Processing Systems (NeurIPS)_, volume 28, 2015.
* [51] Joseph Lehec. The Langevin Monte Carlo algorithm in the non-smooth log-concave case. _The Annals of Applied Probability_, 33(6A):4858-4874, 2023.
* [52] Mert Gurbuzbalaban, Yuanhan Hu, and Lingjiong Zhu. Penalized Langevin and Hamiltonian Monte Carlo algorithms for constrained sampling. _arXiv preprint arXiv:2212.00570_, 2022.
* [53] Boaz Klartag and Eli Putterman. Spectral monotonicity under Gaussian convolution. _arXiv preprint arXiv:2107.09496_, 2021.
* [54] Ronen Eldan. Thin shell implies spectral gap up to polylog via a stochastic localization scheme. _Geometric and Functional Analysis (GAFA)_, 23(2):532-569, 2013.
* [55] Yuansi Chen. An almost constant lower bound of the isoperimetric coefficient in the KLS conjecture. _Geometric and Functional Analysis (GAFA)_, 31:34-61, 2021.
* [56] Sivakanth Gopi, Yin Tat Lee, Daogao Liu, Ruoqi Shen, and Kevin Tian. Algorithmic aspects of the log-Laplace transform and a non-Euclidean proximal sampler. In _Conference on Learning Theory (COLT)_, volume 195, pages 2399-2439. PMLR, 2023.
* [57] Bo Yuan, Jiaojiao Fan, Jiaming Liang, Andre Wibisono, and Yongxin Chen. On a class of Gibbs sampling over networks. In _Conference on Learning Theory (COLT)_, pages 5754-5780. PMLR, 2023.
* [58] Djalil Chafai. Entropies, convexity, and functional inequalities, on phi-entropies and phi-sobolev inequalities. _Journal of Mathematics of Kyoto University_, 44(2):325-363, 2004.
* [59] Patrick Billingsley. _Probability and measure_. John Wiley & Sons, 1995.
* [60] Luigi Ambrosio, Nicola Fusco, and Diego Pallara. _Functions of bounded variation and free discontinuity problems_. Oxford University Press, 2000.
* [61] Ravi Kannan, Laszlo Lovasz, and Ravi Montenegro. Blocking conductance and mixing in random walks. _Combinatorics, Probability and Computing_, 15(4):541-570, 2006.
* [62] Jeff Cheeger. A lower bound for the smallest eigenvalue of the Laplacian. _Problems in analysis_, 625(195-199):110, 1970.
* [63] Emanuel Milman. On the role of convexity in isoperimetry, spectral gap and concentration. _Inventiones Mathematicae_, 177(1):1-43, 2009.
* [64] Michel Ledoux. A simple analytic proof of an inequality by P. Buser. _Proceedings of the American Mathematical Society_, 121(3):951-959, 1994.
* [65] Boaz Klartag and Joseph Lehec. Bourgain's slicing problem and KLS isoperimetry up to polylog. _Geometric and Functional Analysis (GAFA)_, 32(5):1134-1159, 2022.
* [66] Cedric Villani. _Optimal transport: old and new_, volume 338. Springer, 2009.
* [67] Luigi Ambrosio, Nicola Gigli, and Giuseppe Savare. _Gradient flows: in metric spaces and in the space of probability measures_. Springer Science & Business Media, 2005.

Helpful lemmas

Before proceeding, we state two important lemmas which are needed for our proofs. The first is the data-processing inequality for Renyi divergence and \(f\)-divergence, given below.

**Lemma 4** (Data-processing inequality).: _For measures \(\mu,\nu\), Markov kernel \(P\), \(f\)-divergence \(D_{f}\), and \(q\geq 1\), it holds that_

\[D_{f}(\mu P\,\|\,\nu P)\leq D_{f}(\mu\,\|\,\nu)\,,\quad\text{and}\quad\mathcal{ R}_{q}(\mu P\,\|\,\nu P)\leq\mathcal{R}_{q}(\mu\,\|\,\nu)\,.\]

Functional inequalities allow us to show exponential contraction of various divergences, through the following helpful inequality.

**Lemma 5** (Gronwall).: _Suppose that \(u,g:[0,T]\to\mathbb{R}\) are two continuous functions, with \(u\) being differentiable on \([0,T]\) and satisfying_

\[u^{\prime}(t)\leq g(t)\,u(t)\qquad\text{for all }t\in[0,T]\,.\]

_Then,_

\[u(t)\leq\exp\Bigl{(}\int_{0}^{t}g(s)\,\mathrm{d}s\Bigr{)}\,u(0)\qquad\text{ for all }t\in[0,T]\,.\]

## Appendix B Analysis

Before proceeding, we first give the proof of Lemma 2 in the main text. A more general version of Lemma 1 is proved in the form of Lemma 12.

Proof of Lemma 2.: We explicitly show that the forward and backward heat flows indeed interpolate the two discrete steps given in Algorithm 1. For the forward part, we have \(Z_{h}=Z_{0}+\zeta\) for \(\zeta\sim\mathcal{N}(0,hI_{d})\), so

\[\mathsf{law}(Z_{h})=\mathsf{law}(Z_{0})*\mathcal{N}(0,hI_{d})=\mu_{k}^{X}* \mathcal{N}(0,hI_{d})=\mu_{k+1}^{Y}\,.\]

Regarding the backward part, it is known from [27, Lemma 14] that the construction of the time-reversal SDE ensures that \((Z_{h}^{\leftarrow},Z_{0}^{\leftarrow})\) and \((Z_{0},Z_{h})\) have the same joint distribution, when \(Z_{0}\sim\pi^{X}\) (and so \(Z_{h}\sim\pi^{Y}\)). Hence, \(\mathsf{law}(Z_{h}^{\leftarrow}|Z_{0}^{\leftarrow}=y)=\mathsf{law}(Z_{0}|Z_{ h}=y)=\pi^{X|Y=y}\), where the last equality follows from \((Z_{0},Z_{h})\sim\pi\). Since we initialize (BH) with \(Z_{0}^{\leftarrow}=y\sim\mu_{k+1}^{Y}\), we have

\[\mathsf{law}(Z_{h}^{\leftarrow})=\int\mathsf{law}(Z_{h}^{\leftarrow}|Z_{0}^{ \leftarrow}=y)\,\mu_{k+1}^{Y}(\mathrm{d}y)=\int\pi^{X|Y}(\cdot|y)\,\mu_{k+1}^{ Y}(\mathrm{d}y)=\mu_{k+1}^{X}\,,\]

where the last follows from the definition of Line 3. 

### Functional inequalities

The contraction of an outer loop of our algorithm is controlled by isoperimetry of the uniform distribution \(\pi^{X}\), which is described precisely by a functional inequality. The most natural ones to consider in this setting are the Poincare inequality (Pl) and log-Sobolev inequality (LSI-l). In Appendix D, we provide a more detailed discussion of how these are related to other important notions of isoperimetry, such as the _Cheeger_ and _log-Cheeger_ inequalities.

Below, we use \(\mu,\nu\) to denote two arbitrary probability measures over \(\mathbb{R}^{d}\). The relationship between a Poincare inequality and the \(\chi^{2}\)-divergence is derived by substituting \(f=\frac{\mathrm{d}\nu}{\mathrm{d}\mu}\) into (Pl).

**Lemma 6**.: _Assume that \(\nu\) satisfies (Pl) with parameter \(C_{\mathrm{Pl}}(\nu)\). For any probability measure \(\mu\) over \(\mathbb{R}^{d}\) with \(\mu\ll\nu\), it holds that_

\[\chi^{2}(\mu\,\|\,\nu)\leq\frac{C_{\mathrm{Pl}}(\nu)}{2}\,\mathbb{E}_{\nu} \bigl{[}\bigl{\|}\nabla\frac{\mathrm{d}\mu}{\mathrm{d}\nu}\bigr{\|}^{2}\bigr{]}\,.\]

The Poincare inequality implies functional inequalities for the Renyi divergence.

**Lemma 7** ([23, Lemma 9]).: _Assume that \(\nu\) satisfies (Pl) with parameter \(C_{\mathsf{Pl}}(\nu)\). For any \(q\geq 2\) and probability measure \(\mu\) over \(\mathbb{R}^{d}\), it holds that_

\[1-\exp(-\mathcal{R}_{q}(\mu\,\|\,\nu))\leq\frac{q\,C_{\mathsf{Pl}}(\nu)}{4}\, \mathsf{RF}_{q}(\mu\,\|\,\nu)\,,\]

_where is the Renyi Fisher information of order \(q\) of \(\mu\) with respect to \(\nu\)._

The log-Sobolev inequality paired with the KL-divergence (LSI-lI) can be understood as a special case of the following inequality3 paired with the \(q\)-Renyi divergence for \(q\geq 1\).

Footnote 3: Such inequalities are often called Polyak-Lojasiewicz inequalities, which say for \(f:\mathbb{R}^{d}\to\mathbb{R}\), and all \(y\in\mathbb{R}^{d}\) that \(f(y)\leq c\,\|\nabla f(y)\|^{2}\) for some constant \(c\), if \(\min f(x)=0\).

**Lemma 8** ([23, Lemma 5]).: _Assume that \(\nu\) satisfies (LSI-lI) with parameter \(C_{\mathsf{LSI}}(\nu)\). For any \(q\geq 1\) and probability measure \(\mu\) over \(\mathbb{R}^{d}\), it holds that_

\[\mathcal{R}_{q}(\mu\,\|\,\nu)\leq\frac{q\,C_{\mathsf{LSI}}(\nu)}{2}\,\mathsf{ RF}_{q}(\mu\,\|\,\nu)\,.\]

_Note that \(\lim_{q\to 1}\mathcal{R}_{q}=\mathsf{KL}\) and \(\mathsf{RF}_{1}=\mathsf{Fl}\)._

We have collected below the functional inequalities used to establish the mixing of our algorithm (see Appendix D for a detailed presentation).

**Lemma 9**.: _Let \(\mathcal{K}\subset\mathbb{R}^{d}\) be a convex body with diameter \(D\), and \(\pi\) be the uniform distribution over \(\mathcal{K}\). Then, \(C_{\mathsf{Pl}}(\pi)\lesssim\|\mathrm{Cov}(\pi)\|_{\mathsf{op}}\,\log d\) and \(C_{\mathsf{LSI}}(\pi)\lesssim D^{2}\). If \(\pi\) is isotropic, then \(C_{\mathsf{Pl}}(\pi)\lesssim\log d\) and \(C_{\mathsf{LSI}}(\pi)\lesssim D\)._

### Contraction and mixing

We start by analyzing how many outer iterations of \(\mathsf{ln}\)-and-Out are required to be \(\varepsilon\)-close to \(\pi^{X}\), the uniform distribution over \(\mathcal{K}\). The contraction of Algorithm 1 comes from analyzing Lines 2 and 3 through the perspective of heat flows (see SS3). To exploit this view, we first revisit the previous contraction analysis in [27], which is carried out for distributions with _smooth_ densities. Although the uniform distribution is not even continuous, we prove a technical lemma (Lemma 12) that enables us to extend previously known results to the uniform distribution. Lastly, combining the previous results with our technical lemma, we obtain clean contraction results of Algorithm 1 toward the uniform distribution \(\pi^{X}\) in Theorem 3.

Part I: Contraction analysis for smooth distributions.In this part, we review the contraction results for heat flow and its time-reversal [27], which are intimately connected with our algorithm. We also provide key technical ingredients needed for its proof, such as the computations for measures evolving under simultaneous forward/backward heat flows. We refer interested readers to Appendix E for additional details. Only in **Part I**, we assume that \(\nu\) denotes a probability measure with smooth density.

Forward heat flow.We begin by introducing the "heat flow" equation (or also known as the _Fokker-Planck_ equation), which describes the evolution of the law of \(Z_{t}\) under (FH),

\[\partial_{t}\mu_{t}=\frac{1}{2}\,\Delta\mu_{t}=\frac{1}{2}\,\mathrm{div}(\mu_ {t}\nabla\log\mu_{t})\,.\] (FP-FH)

It is well known that one can realize this equation in discrete time through a Gaussian transition density, in the sense that, for \(\mu_{h}\) (the solution at time \(h>0\) to (FP-FH) with initial condition \(\mu_{0}\)), and for any smooth function \(f:\mathbb{R}^{d}\to\mathbb{R}\),

\[\mathbb{E}_{\mu_{h}}[f(x)]=\mathbb{E}_{\mu_{0}}[P_{h}f(x)]\,,\]

where \(P_{h}f(x)=\mathbb{E}_{\mathcal{N}(x,hI_{d})}[f]\).4 By this we can formally identify \(\mu_{h}=\mu_{0}P_{h}\), and also write \(\mu_{h}\) for the law of \(Z_{h}\), where \(\{Z_{h}\}_{h\geq 0}\) solves (FH).

Backward heat flow.Although there are many ways to define a "reversal" of \(P_{h}\), we will use the notion of _adjoint_ introduced by [53], which is the most immediately useful.

Given some initial measure \(\nu\) and some time horizon \(h\), the adjoint corresponds to reversing (FH) for times in \([0,h]\) when the initial distribution under consideration is \(Z_{0}\sim\nu\). For other measures, it must be interpreted more carefully, and is given by the following partial differential equation starting from some measure \(\mu_{0}^{\leftarrow}\) (see (E.1) and its derivation):

\[\partial_{t}\mu_{t}^{\leftarrow}=-\operatorname{div}\bigl{(}\mu_{t}^{ \leftarrow}\nabla\log(\nu P_{h-t})\bigr{)}+\frac{1}{2}\Delta\mu_{t}^{ \leftarrow}\quad\text{for }t\in[0,h]\,.\] (FP-BH)

Write \(\mu_{t}^{\leftarrow}=\mu_{0}^{\leftarrow}Q_{t}^{\nu,h}\), where \(\{Q_{t}^{\nu,h}\}_{t\in[0,h]}\) is a family of transition densities. Write \(\mathbf{P}_{0,h}\) for the joint distribution of the \((Z_{0},Z_{h})\)-marginals of (FH), when \(Z_{0}\sim\nu\), and \(\mathbf{P}_{0|h}\) for the conditional. Note that \(\mathbf{P}_{h|0}(\cdot|x)=\mathcal{N}(x,hI_{d})\). It is also known that (FP-BH) gives a time-reversal of the heat equation at the SDE level, in the sense that we can interpret \(\delta_{x}Q_{h}^{\nu,h}=\mathbf{P}_{0|h}(\cdot|Z_{h}=x)\). Thus \(\mu_{0}^{\leftarrow}Q_{h}^{\nu,h}=\int\mathbf{P}_{0|h}(\cdot|Z_{h}=x)\,\mu_{0 }^{\leftarrow}(\mathrm{d}x)\), and \(\nu P_{h}Q_{t}^{\nu,h}=\nu P_{h-t}\) for all \(t\in[0,h]\).

The ultimate purpose of this machinery is to affirm our earlier description of the Gibbs sampling procedure as alternating forward and backward heat flows. Indeed, notice that, if \(\mu_{i}^{X}\) is the law of the iterate at some iteration \(i\), then \(\mu_{i}^{X}P_{h}\) is precisely \(\mu_{i+1}^{Y}\) under our scheme, while \((\mu_{i}^{X}P_{h})Q_{h}^{\pi^{X},h}\) is \(\mu_{i+1}^{X}\), assuming \(Q_{h}^{\pi^{X},h}\) is well defined for non-smooth measures \(\pi^{X}\). Thus, while Algorithm 1 is implemented via discrete steps, it can be exactly analyzed through arguments in continuous time. We shall see the benefits of this shortly.

Instead of considering the change in metrics along the evolution of \(\mu P_{t}\) with respect to "fixed" \(\nu\), it will be useful to consider the _simultaneous_ evolution of \(\mu P_{t},\nu P_{t}\) (and similarly \(\mu Q_{t},(\nu P_{h})Q_{t}\)). This type of computation was carried out for specific metrics in earlier work [23, 27]. The following is a more generalized form of one appearing in [57, Lemma 2]. In the lemma below, we consider an arbitrary diffusion equation with corresponding Fokker-Planck equation:

\[\mathrm{d}X_{t}=b_{t}(X_{t})\,\mathrm{d}t+\,\mathrm{d}B_{t}\quad\text{and} \quad\partial_{t}\mu_{t}=-\nabla\cdot(b_{t}\mu_{t})+\frac{1}{2}\Delta\mu_{t}\] (B.1)

where \(b_{t}:\mathbb{R}^{d}\to\mathbb{R}^{d}\) is smooth, \(X_{t}\in\mathbb{R}^{d}\), and \(\mu_{t}=\text{Law}(X_{t})\) if \(X_{0}\sim\mu_{0}\).

**Lemma 10** (Decay along forward/backward heat flows).: _Let \((\mu_{t})_{t\geq 0},(\nu_{t})_{t\geq 0}\) denote the laws of the solutions to (B.1) starting at \(\mu_{0},\nu_{0}\) respectively. Then, for any differentiable function \(g\),_

\[\partial_{t}g\bigl{(}D_{f}(\mu_{t}\parallel\nu_{t})\bigr{)}=-\frac{1}{2}\,g^{ \prime}\bigl{(}D_{f}(\mu_{t}\parallel\nu_{t})\bigr{)}\times\mathbb{E}_{\mu_{t }}\Bigl{\langle}\nabla\bigl{(}f^{\prime}\circ\frac{\mu_{t}}{\nu_{t}}\bigr{)},\nabla\log\frac{\mu_{t}}{\nu_{t}}\Bigr{\rangle}\,.\]

Proof.: The case where \(g\neq\text{id}\) is an application of the chain rule, so it suffices to take \(g=\text{id}\) and simply differentiate an \(f\)-divergence.

For brevity, we drop the variable \(x\) of functions involved, and proceed as follows:

\[\partial_{t}D_{f}(\mu_{t}\parallel\nu_{t}) =\int\Bigl{\{}\bigl{(}f\circ\frac{\mu_{t}}{\nu_{t}}\bigr{)}\partial _{t}\nu_{t}+\bigl{(}f^{\prime}\circ\frac{\mu_{t}}{\nu_{t}}\bigr{)}\bigl{(} \frac{\mu_{t}}{\nu_{t}}\bigr{)}^{\prime}\nu_{t}\Bigr{\}}\,\mathrm{d}x\] \[=\int\Bigl{\{}\partial_{t}\nu_{t}\Bigl{(}\bigl{(}f\circ\frac{\mu_ {t}}{\nu_{t}}\bigr{)}-\bigl{(}f^{\prime}\circ\frac{\mu_{t}}{\nu_{t}}\bigr{)} \frac{\mu_{t}}{\nu_{t}}\Bigr{)}+\bigl{(}f^{\prime}\circ\frac{\mu_{t}}{\nu_{t}} \bigr{)}\partial_{t}\mu_{t}\Bigr{\}}\,\mathrm{d}x\] \[\quad+\int\bigl{[}-\nabla\cdot(b_{t}\mu_{t})+\frac{1}{2}\Delta\mu _{t}\bigr{]}\bigl{(}f^{\prime}\circ\frac{\mu_{t}}{\nu_{t}}\bigr{)}\,\mathrm{d}x\,,\]

where in \((i)\) we substitute the F-P equation from (B.1). Integrating by parts (i.e., \(\int f\operatorname{div}(\mathbf{G})=-\int\langle\nabla f,\mathbf{G}\rangle\) for a real-valued function \(f\) and vector-valued function \(\mathbf{G}\)), we have that

\[\int\bigl{[}-\nabla\cdot(b_{t}\nu_{t})\bigr{]}\bigl{(}f\circ\frac{\mu_{t}}{\nu_ {t}}\bigr{)}\,\mathrm{d}x=\int\Bigl{\langle}b_{t}\nu_{t},\bigl{(}f^{\prime} \circ\frac{\mu_{t}}{\nu_{t}}\bigr{)}\nabla\frac{\mu_{t}}{\nu_{t}}\Bigr{\rangle} \,\mathrm{d}x\,.\] (B.2)

On the other hand, we have that

\[-\int\bigl{[}-\nabla\cdot(b_{t}\nu_{t})\bigr{]}\bigl{(}f^{\prime}\circ\frac{\mu _{t}}{\nu_{t}}\bigr{)}\frac{\mu_{t}}{\nu_{t}}\,\mathrm{d}x=-\int\Bigl{\langle} b _{t}\nu_{t},\frac{\mu_{t}}{\nu_{t}}\nabla\bigl{(}f^{\prime}\circ\frac{\mu_{t}}{ \nu_{t}}\bigr{)}+\bigl{(}f^{\prime}\circ\frac{\mu_{t}}{\nu_{t}}\bigr{)}\nabla \frac{\mu_{t}}{\nu_{t}}\Bigr{\rangle}\,\mathrm{d}x\,.\]The second term cancels with the RHS of (B.2). We have a similar cancellation for the \(\frac{1}{2}\Delta\nu_{t}\) term:

\[\int\frac{1}{2}\Delta\nu_{t}\,\big{(}f\circ\frac{\mu_{t}}{\nu_{t}}\big{)}\, \mathrm{d}x=-\int\frac{1}{2}\Big{\langle}\nabla\nu_{t},\big{(}f^{\prime}\circ \frac{\mu_{t}}{\nu_{t}}\big{)}\nabla\frac{\mu_{t}}{\nu_{t}}\Big{\rangle}\, \mathrm{d}x\,,\]

and

Combining these, we are left with

\[\int\big{[}-\nabla\cdot(b_{t}\nu_{t})+ \frac{1}{2}\Delta\nu_{t}\big{]}\Big{(}\big{(}f\circ\frac{\mu_{t}}{ \nu_{t}}\big{)}-\big{(}f^{\prime}\circ\frac{\mu_{t}}{\nu_{t}}\big{)}\frac{\mu_ {t}}{\nu_{t}}\Big{)}\,\mathrm{d}x\] \[=-\int\Big{\langle}b_{t}\nu_{t}-\frac{1}{2}\nabla\nu_{t},\nabla \big{(}f^{\prime}\circ\frac{\mu_{t}}{\nu_{t}}\big{)}\frac{\mu_{t}}{\nu_{t}} \Big{\rangle}\,\mathrm{d}x\] \[=-\int\Big{\langle}b_{t}\mu_{t}-\frac{1}{2}\mu_{t}\nabla\log\nu_{ t},\nabla\big{(}f^{\prime}\circ\frac{\mu_{t}}{\nu_{t}}\big{)}\Big{\rangle}\, \mathrm{d}x\,.\]

Finally, we note that

\[\int\big{[}-\nabla\cdot(b_{t}\mu_{t})+\frac{1}{2}\Delta\mu_{t} \big{]}\big{(}f^{\prime}\circ\frac{\mu_{t}}{\nu_{t}}\big{)}\,\mathrm{d}x =\int\Big{\langle}b_{t}\mu_{t}-\frac{1}{2}\nabla\mu_{t},\nabla \big{(}f^{\prime}\circ\frac{\mu_{t}}{\nu_{t}}\big{)}\Big{\rangle}\, \mathrm{d}x\] \[=\int\Big{\langle}b_{t}\mu_{t}-\frac{1}{2}\mu_{t}\nabla\log\mu_{ t},\nabla\big{(}f^{\prime}\circ\frac{\mu_{t}}{\nu_{t}}\big{)}\Big{\rangle}\, \mathrm{d}x\,.\]

Putting it all together, noticing that the drift terms cancel, we are left with

\[\partial_{t}D_{f}(\mu_{t}\parallel\nu_{t})=-\int\frac{1}{2}\Big{\langle}\mu_ {t}\nabla\log\frac{\mu_{t}}{\nu_{t}},\nabla\big{(}f^{\prime}\circ\frac{\mu_{t} }{\nu_{t}}\big{)}\Big{\rangle}\,\mathrm{d}x=-\frac{1}{2}\mathbb{E}_{\mu_{t}} \Big{\langle}\nabla\log\frac{\mu_{t}}{\nu_{t}},\nabla\big{(}f^{\prime}\circ \frac{\mu_{t}}{\nu_{t}}\big{)}\Big{\rangle}\,,\]

which completes the proof. 

To recover the decay result for the \(q\)-Renyi divergence, one can substitute \(g(x)=\frac{1}{q-1}\log x\) and \(f(x)=x^{q}-1\). For the \(\chi^{2}\)-divergence, instead substitute \(g(x)=x\) and \(f(x)=x^{2}-1\). From this, we can obtain a single step of decay for the Renyi and \(\chi^{2}\)-divergences under different functional inequalities.

Before proceeding, we need a standard lemma on functional inequalities under (\(\mathsf{FH}\)).

**Lemma 11** (Functional inequalities under Gaussian convolutions, [58, Corollary 13]).: _The following inequality holds for any \(\pi\) with finite log-Sobolev and Poincare constants,_

\[C_{\mathsf{Pl}}(\pi P_{t})\leq C_{\mathsf{Pl}}(\pi)+t\,,\qquad\text{and}\qquad C _{\mathsf{LSI}}(\pi P_{t})\leq C_{\mathsf{LSI}}(\pi)+t\,.\]

Combining the previous two lemmas, we can establish contraction between \(\mu P_{h}Q_{h}\) and \(\nu\) after one forward/backward iteration.

**Theorem 4** ([27, Theorem 3 and 4]).: _Assume \(\nu\), a measure with smooth density, satisfies (\(\mathsf{LSI}\)-I) with constant \(C_{\mathsf{LSI}}\). For any \(q\geq 1\) and initial distribution \(\mu\) with a smooth density, denoting again \(Q_{h}:=Q_{h}^{\nu,h}\),_

\[\mathcal{R}_{q}(\mu P_{h}Q_{h}\parallel\nu)\leq\frac{\mathcal{R}_{q}(\mu \parallel\nu)}{(1+h/C_{\mathsf{LSI}})^{2/q}}\,.\]

_If \(\nu\) satisfies (\(\mathsf{PI}\)) with constant \(C_{\mathsf{PI}}\), then it follows that_

\[\chi^{2}(\mu P_{h}Q_{h}\parallel\nu)\leq\frac{\chi^{2}(\mu\parallel\nu)}{(1+h /C_{\mathsf{PI}})^{2}}\,.\]

_Moreover, for all \(q\geq 2\),_

\[\mathcal{R}_{q}(\mu P_{h}Q_{h}\parallel\nu)\leq\begin{cases}\mathcal{R}_{q}( \mu\parallel\nu)-\frac{2\log(1+h/C_{\mathsf{PI}})}{q}&\text{if }\mathcal{R}_{q}(\mu \parallel\nu)\geq 1\,,\\ \frac{\mathcal{R}_{q}(\mu\parallel\nu)}{(1+h/C_{\mathsf{PI}})^{2/q}}&\text{ if }\mathcal{R}_{q}(\mu\parallel\nu)\leq 1\,.\end{cases}\]Proof.: Since the SDE in (B.1) captures the forward heat flow (FH), we set \(\mu_{0}\) and \(\nu_{0}\) in Lemma 10 to \(\mu\) and \(\nu\), respectively, obtaining contraction along the forward heat flow as follows: Substituting the \(q\)-Renyi into Lemma 10, we have, from the definition of the Renyi divergence as \(\mathcal{R}_{q}(\mu\parallel\nu):=\frac{1}{q-1}\log(D_{f}(\mu\parallel\nu)+1)\), with \(f(x)=x^{q}-1\) and \(g(x)=\frac{1}{q-1}\log(x+1)\),

\[\partial_{t}\mathcal{R}_{q}(\mu P_{t}\parallel\nu P_{t}) =-\frac{q}{2}\,\frac{\mathbb{E}_{\mu P_{t}}\Big{[}\Big{\langle} \nabla\Big{(}\frac{\mu P_{t}}{\nu P_{t}}\Big{)}^{q-1},\nabla\log\frac{\mu P_{t }}{\nu P_{t}}\Big{\rangle}\Big{]}}{(q-1)\,\mathbb{E}_{\nu P_{t}}\Big{[}\Big{(} \frac{\mu P_{t}}{\nu P_{t}}\Big{)}^{q}\Big{]}}\] \[=-\frac{q}{2}\,\frac{\mathbb{E}_{\mu P_{t}}\Big{[}\Big{(}\frac{ \mu P_{t}}{\nu P_{t}}\Big{)}^{q-2}\langle\nabla\frac{\mu P_{t}}{\nu P_{t}}, \nabla\log\frac{\mu P_{t}}{\nu P_{t}}\Big{\rangle}\Big{]}}{\mathbb{E}_{\nu P _{t}}\Big{[}\Big{(}\frac{\mu P_{t}}{\nu P_{t}}\Big{)}^{q}\Big{]}}\] \[\underset{(ii)}{=}-\frac{q}{2}\,\frac{\mathbb{E}_{\nu P_{t}}\Big{[} \Big{(}\frac{\mu P_{t}}{\nu P_{t}}\Big{)}^{q}\|\nabla\log\frac{\mu P_{t}}{\nu P _{t}}\|^{2}\Big{]}}{\mathbb{E}_{\nu P_{t}}\Big{[}\Big{(}\frac{\mu P_{t}}{\nu P _{t}}\Big{)}^{q}\Big{]}}=-\frac{1}{2}\,\mathsf{R}\mathsf{F}_{q}(\mu P_{t} \parallel\nu P_{t})\,,\]

where in \((i)\), we use again that \(\nabla\big{[}f^{\prime}\big{(}\frac{\mu_{t}}{\nu_{t}}\big{)}\frac{\mu_{t}}{\nu _{t}}\big{]}=\nabla\big{(}f^{\prime}\circ\frac{\mu_{t}}{\nu_{t}}\big{)}\cdot \frac{\mu_{t}}{\nu_{t}}+f^{\prime}\big{(}\frac{\mu_{t}}{\nu_{t}}\big{)}\nabla \frac{\mu_{t}}{\nu_{t}}\), and \((ii)\) uses that \(\nabla\frac{\mu P_{t}}{\nu P_{t}}=\frac{\mu P_{t}}{\nu P_{t}}\nabla\log\frac{ \mu P_{t}}{\nu P_{t}}\), and the last equality recalls the definition of the Renyi Fisher information. This yields

\[\partial_{t}\mathcal{R}_{q}(\mu P_{t}\parallel\nu P_{t})=-\frac{1}{2}\mathsf{ R}\mathsf{F}_{q}(\mu P_{t}\parallel\nu P_{t})\underset{(i)}{\leq}-\frac{1}{q} \frac{\mathcal{R}_{q}(\mu P_{t}\parallel\nu P_{t})}{C_{\mathsf{LSI}}(\nu P_{t} )}\underset{(ii)}{\leq}-\frac{1}{q}\frac{\mathcal{R}_{q}(\mu P_{t}\parallel \nu P_{t})}{C_{\mathsf{LSI}}+t}\,,\]

where we used Lemma 8 in \((i)\) and Lemma 11 in \((ii)\). Applying Gronwall's inequality (Lemma 5),

\[\mathcal{R}_{q}(\mu P_{h}\parallel\nu P_{h})\leq\exp\Bigl{(}-\frac{1}{q}\int_ {0}^{h}\frac{1}{C_{\mathsf{LSI}}+t}\,\mathrm{d}t\Bigr{)}\mathcal{R}_{q}(\mu \parallel\nu)\leq\frac{\mathcal{R}_{q}(\mu\parallel\nu)}{(1+h/C_{\mathsf{LSI} })^{1/q}}\,.\]

Since the SDE (B.1) also captures the backward equation (BH), we set \(\mu_{0}\) and \(\nu_{0}\) in Lemma 10 to \(\mu P_{h}\) and \(\tilde{\nu}:=\nu P_{h}\) respectively, obtaining contraction along the backward heat flow:

\[\partial_{t}\mathcal{R}_{q}(\mu P_{h}Q_{t}\parallel\tilde{\nu}Q_{ t}) =-\frac{1}{2}\,\mathsf{R}\mathsf{F}_{q}(\mu P_{h}Q_{t}\parallel \tilde{\nu}Q_{t})\] \[\leq-\frac{1}{q}\,\frac{\mathcal{R}_{q}(\mu P_{h}Q_{t}\parallel \tilde{\nu}Q_{t})}{C_{\mathsf{LSI}}(\tilde{\nu}Q_{t})}\underset{(i)}{\leq}- \frac{1}{q}\frac{\mathcal{R}_{q}(\mu P_{h}Q_{t}\parallel\tilde{\nu}Q_{t})}{C_{ \mathsf{LSI}}+h-t}\,,\]

where \((i)\) follows from that \(\tilde{\nu}Q_{t}=\nu P_{h}Q_{t}=\nu P_{h-t}\) and \(C_{\mathsf{LSI}}(\tilde{\nu}Q_{t})\leq C_{\mathsf{LSI}}+h-t\) due to Lemma 11. Applying Lemma 5 again yields

\[\mathcal{R}_{q}(\mu P_{h}Q_{h}\parallel\nu)\leq\frac{\mathcal{R}_{q}(\mu P_{h }\parallel\tilde{\nu})}{(1+h/C_{\mathsf{LSI}})^{1/q}}\,.\]

Composing these two inequalities leads to the decay rate claimed in the theorem.

The result in the \(\chi^{2}\)-divergence can be derived entirely analogously. For instance, the decay from the forward part can be shown as follows:

\[\partial_{t}\chi^{2}(\mu P_{t}\parallel\nu P_{t})=-\frac{1}{2}\,\mathbb{E}_{\nu P _{t}}\Big{[}\Big{\|}\nabla\frac{\mu P_{t}}{\nu P_{t}}\Big{\|}^{2}\Big{]} \underset{(i)}{\leq}-\frac{\chi^{2}(\mu P_{t}\parallel\nu P_{t})}{C_{\mathsf{ Pl}}(\nu P_{t})}\leq-\frac{\chi^{2}(\mu P_{t}\parallel\nu P_{t})}{C_{ \mathsf{Pl}}+t}\,,\]

where \((i)\) follows from Lemma 6. Applying Gronwall's inequality then gives

\[\chi^{2}(\mu P_{h}\parallel\nu P_{h})\leq\exp\Bigl{(}-\int_{0}^{h}\frac{1}{C_{ \mathsf{Pl}}+t}\,\mathrm{d}t\Bigr{)}\,\chi^{2}(\mu\parallel\nu)\leq\frac{\chi^{ 2}(\mu\parallel\nu)}{1+h/C_{\mathsf{Pl}}}\,.\]

The decay along the backward heat flow in \(\chi^{2}\) is entirely analogous to the Renyi case. Then we combine two contraction results from the forward and backward flows, completing the proof.

The result in the \(\mathcal{R}_{q}\) under (Pl) can be shown in a similar manner. Only difference is that in forward and backward computations, one should use the functional inequality in Lemma 7 and the following standard inequalities:

\[1-\exp\bigl{(}-\mathcal{R}_{q}(\mu\parallel\nu)\bigr{)}\geq\begin{cases}\frac{ 1}{2}&\text{if }\mathcal{R}_{q}(\mu\parallel\nu)\geq 1\,,\\ \frac{1}{2}\mathcal{R}_{q}(\mu\parallel\nu)&\text{if }\mathcal{R}_{q}(\mu \parallel\nu)\leq 1\,.\end{cases}\]Part II: Extension to constrained distributions.We now prove a technical lemma that extends the contraction results to constrained distributions. This lemma guarantees the existence of weak solutions to two stochastic processes that describe the evolution of distributions involved in Line 2 and 3 in \(\ln\)-and-Out, in addition to lower-semicontinuity of \(f\)-divergence. We shall prove it for any measure that is absolutely continuous with respect to \(\pi^{\lambda}\), since this imposes no additional technical hurdles.

**Lemma 12**.: _Let \(\nu\) be a measure, absolutely continuous with respect to the uniform measure \(\pi^{X}\). The forward and backward heat flow equations given by_

\[\partial_{t}\mu_{t} =\frac{1}{2}\Delta\mu_{t}\,,\] \[\partial_{t}\mu_{t}^{\leftarrow}\]

_admit solutions on \((0,h]\), and the weak limit \(\lim_{t\to h}\mu_{t}^{\leftarrow}=\mu_{h}^{\leftarrow}\) exists for any initial measure \(\mu_{0}\) with bounded support. Moreover, for any \(f\)-divergence with \(f\) lower semi-continuous,_

\[D_{f}(\mu_{h}^{\leftarrow}\parallel\nu)\leq\lim_{t\downarrow 0}D_{f}(\mu_{h-t }^{\leftarrow}\parallel\nu_{t})\,.\]

Proof.: The existence of weak solutions for the forward equation is well-known, since \(\mu_{0}\) can be weakly approximated by measures with continuous density, for which the heat equation admits a unique solution for all time. In particular, the weak solution is \(C^{\infty}\) for \(t>0\).

The reverse SDE is more subtle, since \(\nabla\log\nu P_{t}\) will in general cease to be Lipschitz as \(t\to 0\). On the other hand, for any \(h>0\), we can write explicitly

\[\mu_{h}(x)=\frac{1}{(2\pi h)^{d/2}}\int\exp\bigl{(}-\frac{\|x-y\|^{2}}{2h} \bigr{)}\,\mathrm{d}\mu_{0}(y)\,.\]

If one considers the system started at \(\tilde{\mu}_{0}=\mu_{\epsilon}=\nu P_{\epsilon}\) and solve the forward-backward Fokker-Planck equations on times \([0,h-\epsilon]\), then \(\tilde{\mu}_{h-\epsilon}=\mu_{h}=\mu_{0}^{\leftarrow}=\tilde{\mu}_{0}^{ \leftarrow}\) and

\[\mu_{h-\epsilon}^{\leftarrow}(x)=\tilde{\mu}_{h-\epsilon}^{\leftarrow}(x)= \int\frac{\exp\bigl{(}-\frac{\|x-y\|^{2}}{2(h-\epsilon)}\bigr{)}\nu P_{ \epsilon}(x)}{\int\exp\bigl{(}-\frac{\|z-y\|^{2}}{2h}\bigr{)}\nu P_{\epsilon}(z )\,\mathrm{d}z}\,\mathrm{d}\mu_{h}(y)\,.\]

This follows from that if we consider system started at time \(\epsilon>0\), with initial distribution \(\mu_{\epsilon}\), then we obtain the above through the Bayesian perspective on the forward and reverse heat semigroups, elaborated in Appendix E.

We now show that the following integral is indeed integrable, so \(\tilde{\mu}_{h}^{\leftarrow}\) is well-defined:

\[\tilde{\mu}_{h}^{\leftarrow}\,(x):=\int\frac{\exp\bigl{(}-\frac{\|x-y\|^{2}}{ 2h}\bigr{)}\nu(x)}{\int\exp\bigl{(}-\frac{\|z-y\|^{2}}{2h}\bigr{)}\nu(z)\, \mathrm{d}z}\,\mathrm{d}\mu_{h}(y)\,.\]

For fixed \(x\) and \(\epsilon<h/2\),

\[\int\exp\bigl{(}-\frac{\|z-y\|^{2}}{2(h-\epsilon)}\bigr{)}\nu(z)\,\mathrm{d}z \gtrsim\exp\bigl{(}-\frac{(\|y-x_{0}\|+D)^{2}}{2(h-\epsilon)}\bigr{)}\,,\]

as the support of \(\nu\) is constrained to \(\mathcal{K}\subset B_{D}(x_{0})\). Since \(\mu_{0}\) has bounded support, \(\mu_{h}(y)\lesssim\exp(-\frac{\|y\|^{2}}{a})\) for some constant \(a>0\). Thus,

\[\frac{\exp\bigl{(}-\frac{\|x-y\|^{2}}{2(h-\epsilon)}\bigr{)}\,\mu_ {h}(y)}{\int\exp\bigl{(}-\frac{\|z-y\|^{2}}{2(h-\epsilon)}\bigr{)}\nu P_{ \epsilon}(z)\,\mathrm{d}z} \lesssim\frac{\exp\bigl{(}-\frac{\|x-y\|^{2}}{2(h-\epsilon)} \bigr{)}\,\mu_{h}(y)}{\exp(-\frac{(\|y-x_{0}\|+D)^{2}}{2(h-\epsilon)})}\] \[\lesssim\exp\Bigl{(}\frac{\langle 2(x-x_{0}),y\rangle+2D\|y-x_{0}\|} {h}-\frac{\|y\|^{2}}{a}\Bigr{)}\,,\]

and the last bound is integrable in \(y\).

We then show the pointwise convergence of \(\hat{\mu}_{h-\epsilon}^{\leftarrow}\) to \(\hat{\mu}_{h}^{\leftarrow}\) as \(\epsilon\to 0\). Note that \(\nu P_{\epsilon}\to\nu\), as \(\nu\) has a bounded support. Also, the denominator is independent of \(\epsilon\) due to

\[\frac{1}{(2\pi(h-\epsilon))^{d/2}}\int\exp\bigl{(}-\frac{\|z-y\|^{2}}{2(h- \epsilon)}\bigr{)}\nu P_{\epsilon}(z)\,\mathrm{d}z=\mathcal{N}(0,(h-\epsilon) I)\ast\nu P_{\epsilon}=\nu\ast\mathcal{N}(0,hI)\,.\]

Hence, for \(\epsilon\leq d^{-1}\),

\[\frac{\exp\bigl{(}-\frac{\|x-y\|^{2}}{2(h-\epsilon)}\bigr{)}}{ \int\exp\bigl{(}-\frac{\|z-y\|^{2}}{2(h-\epsilon)}\bigr{)}\nu P_{\epsilon}(z) \,\mathrm{d}z} \leq\Bigl{(}\frac{h}{h-\epsilon}\Bigr{)}^{d/2}\frac{\exp\bigl{(} -\frac{\|x-y\|^{2}}{2h}\bigr{)}}{\int\exp\bigl{(}-\frac{\|z-y\|^{2}}{2h} \bigr{)}\nu(z)\,\mathrm{d}z}\] \[\lesssim\frac{\exp\bigl{(}-\frac{\|x-y\|^{2}}{2h}\bigr{)}}{\int \exp\bigl{(}-\frac{\|z-y\|^{2}}{2h}\bigr{)}\nu(z)\,\mathrm{d}z}\,.\]

As shown above, the last bound is integrable with respect to \(\mu_{h}\), so the dominated convergence theorem implies

\[\lim_{\epsilon\to 0}\int\frac{\exp\bigl{(}-\frac{\|x-y\|^{2}}{2(h-\epsilon)} \bigr{)}}{\int\exp\bigl{(}-\frac{\|z-y\|^{2}}{2(h-\epsilon)}\bigr{)}\nu P_{ \epsilon}(z)\,\mathrm{d}z}\,\mathrm{d}\mu_{h}(y)=\int\frac{\exp\bigl{(}-\frac{ \|x-y\|^{2}}{2h}\bigr{)}}{\int\exp\bigl{(}-\frac{\|z-y\|^{2}}{2h}\bigr{)}\nu(z )\,\mathrm{d}z}\,\mathrm{d}\mu_{h}(y)\,,\]

Thus, the pointwise convergence follows. Note that if we take \(\nu(x)=\pi^{X}(x)=\frac{\mathbf{l}_{\mathcal{K}}(x)}{\operatorname{vol}( \mathcal{K})}\), then \(\tilde{\mu}_{h}^{\leftarrow}\) is the distribution of the backwards step of our algorithm. In particular, this corresponds to first sampling \(x\sim\mu_{h}\), then \(y\sim Q_{h}^{\nu,h}(\cdot|x)\), which is precisely the law of \(\mu_{h}^{\leftarrow}\) given by (FP-BH).

As for the second statement, it follows from Scheffe's lemma [59, Theorem 16.12] that the pointwise convergence of \(\hat{\mu}_{h-\varepsilon}^{\leftarrow}\to\mu_{h}^{\leftarrow}\) leads to its \(\mathsf{TV}\)-convergence, which in turn implies the weak convergence. It follows from lower semicontinuity of \(D_{f}\)[60, Theorem 2.34] that the weak convergence ensures \(D_{f}(\mu_{h}^{\leftarrow}\parallel\nu)\leq\lim_{t\downarrow 0}D_{f}(\mu_{h-t}^{ \leftarrow}\parallel\nu_{h-t}^{\leftarrow})\). 

In the sequel, we will only consider \(\nu=\pi^{X}\). Since the Renyi divergence is a continuous function of the \(\chi^{q}\) divergence (see Definition 1), which itself is an \(f\)-divergence, it enjoys the same lower-semicontinuity properties. Using this lower-semicontinuity together with the decay results in Theorem 4, we can easily derive the contraction results of \(\mathsf{ln}\)-and-Out in \(\mathcal{R}_{q}\) and \(\chi^{q}\) for any \(q\geq 1\). We remark that this result does not require convexity of \(\mathcal{K}\).

Proof of Theorem 3.: Let us set \(\mu_{0}=\mu_{0}^{X}\) and \(\pi_{0}=\pi^{X}\). Then, \(\mu_{h}=\mu_{0}^{\leftarrow}=\mu_{1}^{Y}\), \(\pi_{h}=\pi_{0}^{\leftarrow}=\pi^{Y}\), and \(\mu_{h}^{\leftarrow}=\mu_{1}^{X}\), \(\pi_{h}^{\leftarrow}=\pi^{X}\). For small \(\epsilon>0\), as \(\mu_{\epsilon}=(\mu_{0}^{X})_{\epsilon}=\mu_{0}^{X}\ast\mathcal{N}(0,\epsilon I _{d})\) is \(C^{\infty}\)-smooth, we can now invoke the decay results with step size \(h-\epsilon\) in Theorem 4. Thus, for contraction constants \(C_{\epsilon}=(1+\frac{h-\epsilon}{\epsilon_{\mathrm{l}\mathrm{l}\mathrm{l} \mathrm{l}}+\epsilon})^{-2/q}\) and \(C_{\epsilon}=(1+\frac{h-\epsilon}{C_{\mathrm{l}\mathrm{l}\mathrm{l}\mathrm{l} }+\epsilon})^{-2}\) respectively when \(\Phi=\mathcal{R}_{q}\) and \(\Phi=\chi^{2}\),

\[\Phi(\mu_{h-\epsilon}^{\leftarrow}\parallel\pi_{\epsilon})\leq C_{\epsilon} \cdot\Phi(\mu_{\epsilon}\parallel\pi_{\epsilon})\leq C_{\epsilon}\cdot\Phi(\mu_{ 0}\parallel\pi_{0})\,,\]

where we used the data-processing inequality for the last inequality. By the second result of Lemma 12, sending \(\epsilon\to 0\) leads to

\[\Phi(\mu_{1}^{X}\parallel\pi^{X})=\Phi(\mu_{h}^{\leftarrow}\parallel\pi_{0}) \leq C\cdot\Phi(\mu_{0}\parallel\pi_{0})=C\cdot\Phi(\mu_{0}^{X}\parallel\pi^{X })\,.\]

Repeating this argument \(k\) times completes the proof. 

### Failure probability and wasted steps

We begin by defining a suitable version of _local conductance_[4].

**Definition 6** (Local conductance).: The local conductance \(\ell\) on \(\mathbb{R}^{d}\) is defined by

\[\ell(x)\stackrel{{\mathrm{def}}}{{=}}\frac{\int_{\mathcal{K}} \exp(-\frac{1}{2h}\|x-y\|^{2})\,\mathrm{d}y}{\int_{\mathbb{R}^{d}}\exp(-\frac{ 1}{2h}\|x-y\|^{2})\,\mathrm{d}y}=\frac{\int_{\mathcal{K}}\exp(-\frac{1}{2h}\|x -y\|^{2})\,\mathrm{d}y}{(2\pi h)^{d/2}}\,.\]

The local conductance at \(y\) quantifies the success probability of the proposal at \(y\) in Line 3. Then the expected number of trials until the first success of Line 3 is \(1/\ell(y)\). Revisiting (3.1), we can notice \(\pi^{Y}(y)=\ell(y)/\operatorname{vol}(\mathcal{K})\).

Naive analysis for expected number of trials.Starting from \(\pi^{X}\), when we just naively sample from \(\pi^{Y|X}(\cdot|x)\) for all \(x\) without imposing any _failure_ condition, the expected number of trials for one iteration is that for the probability density \(p_{x}\) of \(\mathcal{N}(x,hI_{d})\),

\[\int_{\mathcal{K}}\int_{\mathbb{R}^{d}}\frac{1}{\ell(y)}\,p_{x}(\mathrm{d}y) \pi^{X}(\mathrm{d}x)=\int_{\mathbb{R}^{d}}\frac{1}{\ell(y)}\,\pi^{Y}(\mathrm{d }y)=\int_{\mathbb{R}^{d}}\frac{1}{\ell(y)}\,\frac{\ell(y)}{\mathrm{vol}( \mathcal{K})}\,\mathrm{d}y=\infty\,.\]

This suggests that one should consider the algorithm as having "failed" if the number of trials exceeds some threshold.

Refined analysis under a failure condition.Going forward, we assume an \(M\)-warm start as in previous work for uniform sampling algorithms. By induction we have \(\frac{\mathrm{d}\mu_{i}^{X}}{\mathrm{d}\pi_{i}^{X}}\leq M\) for all \(i\).

**Lemma 13** (Propagation of warm-start).: _From an \(M\)-warm start, we have \(\nicefrac{{\mathrm{d}\mu_{i}^{X}}}{{\mathrm{d}\pi^{X}}}\leq M\) for all \(i\)._

Proof.: Assume that \(\mu_{i}^{X}\) satisfies the \(M\)-warm start. Then, for any measurable \(S\) and the transition kernel \(T_{x}\) of Algorithm 1 at \(x\),

\[\mu_{i+1}^{X}(S)=\int_{\mathcal{K}}T_{x}(S)\,\mathrm{d}\mu_{i}^{X}(x)\leq M \int_{\mathcal{K}}T_{x}(S)\,\mathrm{d}\pi^{X}(x)=M\pi^{X}(S)\,,\]

where the last equality follows from the stationarity of \(\pi\). Hence, \(\mathrm{d}\mu_{i+1}^{X}/\mathrm{d}\pi^{X}\leq M\). 

We now establish a lemma that comes in handy when analyzing the failure probability of the algorithm. In essence, this lemma bounds the probability that taking a Gaussian step from \(\pi^{X}\) in Line 2 gets \(\delta\)-distance away from \(\mathcal{K}\). Let us denote the \(\delta\)-blowup of \(\mathcal{K}\) by \(\mathcal{K}_{\delta}:=\{x\in\mathbb{R}^{d}:d(x,\mathcal{K})\leq\delta\}\).

**Lemma 14**.: _For a convex body \(\mathcal{K}\subset\mathbb{R}^{d}\) containing a unit ball \(B_{1}(0)\),_

\[\pi^{Y}(\mathcal{K}_{\delta}^{c})\leq\exp\bigl{(}-\frac{\delta^{2}}{2h}+ \delta d\bigr{)}\,.\]

Proof.: For \(y\in\partial\mathcal{K}_{\delta}\), we can take the supporting half-space \(H(y)\) at \(\mathsf{proj}_{\mathcal{K}}(y)\) containing \(\mathcal{K}\), due to convexity of \(\mathcal{K}\). Then,

\[\pi^{Y}(\mathcal{K}_{\delta}^{c}) =\frac{1}{\mathrm{vol}(\mathcal{K})}\int_{\mathcal{K}_{\delta}^{c }}\int_{\mathcal{K}}\frac{\exp(-\frac{1}{2h}\|y-x\|^{2})}{(2\pi h)^{d/2}}\, \mathrm{d}x\,\mathrm{d}y\] \[\leq\frac{1}{\mathrm{vol}(\mathcal{K})}\int_{\mathcal{K}_{\delta}^ {c}}\int_{H(y)}\frac{\exp(-\frac{1}{2h}\|y-x\|^{2})}{(2\pi h)^{d/2}}\,\mathrm{d }x\,\mathrm{d}y\] \[=\frac{1}{\mathrm{vol}(\mathcal{K})}\int_{\mathcal{K}_{\delta}^{c }}\int_{d(y,\mathcal{K})}^{\infty}\frac{\exp(-\frac{z^{2}}{2h})}{\sqrt{2\pi h} }\,\mathrm{d}z\,\mathrm{d}y\,.\] (B.3)

Let us denote the tail probability of the \(1\)-dimensional Gaussian with variance \(h\) by

\[\mathsf{T}(s):=\mathbb{P}_{\mathcal{N}(0,h)}(Z\geq s)=1-\Phi(h^{-1/2}s)\,,\]

where \(\Phi\) is the CDF of the standard Gaussian. By the co-area formula and integration by parts,

\[\int_{\mathcal{K}_{\delta}^{c}}\int_{d(y,\mathcal{K})}^{\infty} \frac{\exp(-\frac{1}{2h}z^{2})}{\sqrt{2\pi h}}\,\mathrm{d}z\mathrm{d}y=\int_{ \delta}^{\infty}\mathsf{T}(s)\,\mathrm{vol}(\partial\mathcal{K}_{s})\, \mathrm{d}s\] \[=\Bigl{[}\underbrace{\mathsf{T}(s)\int_{0}^{s}\mathrm{vol}( \partial\mathcal{K}_{z})\,\mathrm{d}z}_{=:\mathsf{F}}\Bigr{]}_{\delta}^{ \infty}+\int_{\delta}^{\infty}\frac{1}{\sqrt{2\pi h}}\exp\bigl{(}-\frac{s^{2}}{ 2h}\bigr{)}\int_{0}^{s}\mathrm{vol}(\partial\mathcal{K}_{z})\,\mathrm{d}z\, \mathrm{d}s\,.\] (B.4)

Recall that \(\mathsf{T}(s)\leq\frac{1}{2}\exp(-\frac{1}{2}(h^{-1/2}s)^{2})\) for \(h^{-1/2}s\geq 0\) due to a standard tail bound on a Gaussian distribution. This tail bound, combined with

\[\int_{0}^{s}\mathrm{vol}(\partial\mathcal{K}_{z})\,\mathrm{d}z=\mathrm{vol}( \mathcal{K}_{s})-\mathrm{vol}(\mathcal{K})\leq\mathrm{vol}\bigl{(}(1+s)\, \mathcal{K}\bigr{)}-\mathrm{vol}(\mathcal{K})=\bigl{(}(1+s)^{d}-1\bigr{)} \,\mathrm{vol}(\mathcal{K})\,,\]ensures that \(\mathsf{F}\) vanishes at \(s=\infty\). Hence, bounding the first term in (B.4) by \(0\) results in

\[\int_{\mathcal{K}_{\delta}^{c}}\int_{d(y,\mathcal{K})}^{\infty} \frac{\exp(-\frac{1}{2h}z^{2})}{\sqrt{2\pi h}}\,\mathrm{d}z\,\mathrm{d}y \leq\frac{1}{\sqrt{2\pi h}}\int_{\delta}^{\infty}\exp\bigl{(}- \frac{s^{2}}{2h}\bigr{)}\bigl{(}\underbrace{(1+s)^{d}}_{\leq\exp(sd)}-1\bigr{)} \operatorname{vol}(\mathcal{K})\,\mathrm{d}s\] \[\leq\frac{\operatorname{vol}(\mathcal{K})}{\sqrt{2\pi h}}\exp(hd ^{2}/2)\int_{\delta}^{\infty}\exp\bigl{(}-\frac{1}{2h}\,(s-hd)^{2}\bigr{)}\, \mathrm{d}s\] \[\leq\operatorname{vol}(\mathcal{K})\exp(hd^{2}/2)\exp\bigl{(}- \frac{(\delta-hd)^{2}}{2h}\bigr{)}\] \[=\operatorname{vol}(\mathcal{K})\exp\bigl{(}-\frac{\delta^{2}}{2h }+\delta d\bigr{)}\,,\]

where in \((i)\) we used the tail bound for a Gaussian. 

This core lemma suggests taking \(\delta=\nicefrac{{t}}{{d}}\) and \(h=\nicefrac{{c}}{{d^{2}}}\) for some \(t,c>0\), under which we have

\[\pi^{Y}(\mathcal{K}_{\delta}^{c})\leq\exp\bigl{(}-\frac{t^{2}}{2c}+t\bigr{)}\,.\]

Now we choose a suitable threshold \(N\) for bounding the failure probability. Following (B.3) in the proof, one can notice that for \(y\in\mathcal{K}_{\delta}^{c}\), \(\delta=\Omega(1/d)\), and \(h=\Theta(d^{-2})\),

\[\ell(y)\leq\int_{d(y,\mathcal{K})}^{\infty}\frac{\exp(-\frac{1}{2h}z^{2})}{ \sqrt{2\pi h}}\,\mathrm{d}z=\mathbb{P}_{Z\sim\mathcal{N}(0,h)}(Z\geq\delta) \leq\exp(-\Omega(t^{2}))\,.\]

Thus, the expected number of trials from \(\mathcal{K}_{\delta}^{c}\) for the rejection sampling in Line 3 is \(\ell(y)^{-1}\geq\exp(\Omega(t^{2}))\). Intuitively, one can ignore whatever happens in \(\mathcal{K}_{\delta}^{c}\), since \(\mathcal{K}_{\delta}\) takes up most of measure of \(\pi^{Y}\). As the number of trials from \(\mathcal{K}_{\delta}^{c}\) is at least \(\exp(\Omega(t^{2}))\) in expectation, the most straightforward way to ignore algorithmic behaviors from \(\mathcal{K}_{\delta}^{c}\) is simply to set the threshold to \(N=\widetilde{\mathcal{O}}(\exp(t^{2}))\). Even though the threshold is \(N\), the expected number of trials is much lower.

Lemma 3 bounds the failure probability and expected number of trials per iteration.

Proof of Lemma 3.: For \(\mu_{h}:=\mu*\mathcal{N}(0,hI_{d})\), the failure probability is \(\mathbb{E}_{\mu_{h}}[(1-\ell)^{N}]\). Since \(\mathrm{d}\mu/\mathrm{d}\pi^{X}\leq M\) implies \(\mathrm{d}\mu_{h}/\mathrm{d}(\pi^{X})_{h}=\mathrm{d}\mu_{h}/\mathrm{d}\pi^{Y} \leq M\), it follows that

\[\mathbb{E}_{\mu_{h}}[(1-\ell)^{N}]\leq M\,\mathbb{E}_{\pi^{Y}}[(1-\ell)^{N}]\,.\]

Then,

\[\int_{\mathbb{R}^{d}}\underbrace{(1-\ell)^{N}\,\mathrm{d}\pi^{Y}} _{=\mathsf{A}} =\int_{\mathcal{K}_{\delta}^{c}}\mathsf{A}+\int_{\mathcal{K}_{ \delta}\cap[\ell\geq N^{-1}\log(3mM/\eta)]}\mathsf{A}+\int_{\mathcal{K}_{ \delta}\cap[\ell<N^{-1}\log(3mM/\eta)]}\mathsf{A}\] \[\leq\pi^{Y}(\mathcal{K}_{\delta}^{c})+\int_{[\ell\geq N^{-1} \log(3mM/\eta)]}\exp(-\ell N)\,\mathrm{d}\pi^{Y}\] \[\qquad\qquad+\int_{\mathcal{K}_{\delta}\cap[\ell<N^{-1}\log(3mM/ \eta)]}\frac{\ell(y)}{\operatorname{vol}(\mathcal{K})}\,\mathrm{d}y\] \[\leq\exp\bigl{(}-\frac{t^{2}}{2c}+t\bigr{)}+\frac{\eta}{3mM}+\frac {\log(3mM/\eta)}{N}\,\frac{\operatorname{vol}(\mathcal{K}_{\delta})}{ \operatorname{vol}(\mathcal{K})}\] \[\leq\exp\bigl{(}-\frac{t^{2}}{2c}+t\bigr{)}+\frac{\eta}{3mM}+\frac {e^{t}}{N}\,\log\frac{3mM}{\eta}\,,\]

where we used \(\operatorname{vol}(\mathcal{K}_{\delta})\subset\operatorname{vol}\bigl{(}(1+ \delta)\mathcal{K}\bigr{)}=(1+\delta)^{d}\operatorname{vol}(\mathcal{K})\leq e ^{t}\operatorname{vol}(\mathcal{K})\). Taking \(c=\frac{\log\log Z}{2\log Z}\), \(t=\sqrt{8}\log\log Z\), and \(N=Z(\log Z)^{4}\), we can bound the last line by \(\frac{\eta}{mM}\). Therefore,

\[\mathbb{E}_{\mu_{h}}[(1-\ell(\cdot))^{N}]\leq M\,\mathbb{E}_{\pi^{Y}}[(1-\ell (\cdot))^{N}]\leq\frac{\eta}{m}\,.\]We now bound the expected number of trials per iteration. Let \(X\) be the minimum of the threshold \(N\) and the number of trials until the first success. Then the expected number of trials per step is bounded by \(M\mathbb{E}_{\pi^{Y}}X\) since \(\mathrm{d}\mu_{h}/\mathrm{d}\pi^{Y}\leq M\). Thus,

\[\int_{\mathbb{R}^{d}}\bigl{(}\frac{1}{\ell}\wedge N\bigr{)}\, \mathrm{d}\pi^{Y} \leq\int_{\mathcal{K}_{\delta}}\frac{1}{\ell}\,\mathrm{d}\pi^{Y}+N \pi^{Y}(\mathcal{K}_{\delta}^{c})=\frac{\mathrm{vol}(\mathcal{K}_{\delta})}{ \mathrm{vol}(\mathcal{K})}+N\pi^{Y}(\mathcal{K}_{\delta}^{c})\] \[\leq e^{t}+N\exp\bigl{(}-\frac{t^{2}}{2c}+t\bigr{)}\leq(\log Z)^{ 3}+3(\log Z)^{4}=\mathcal{O}\bigl{(}\log^{4}\frac{mM}{\eta}\bigr{)}\,.\]

Therefore, the expected number of trials per step is \(\mathcal{O}(M\log^{4}\frac{mM}{\eta})\), and the claim follows since each trial uses one query to the membership oracle of \(\mathcal{K}\). 

### Putting it together

We can now show that \(\mathsf{In}\)-and-Out subsumes previous results on uniform sampling from convex bodies (such as \(\mathsf{Ball}\) walk and \(\mathsf{Speedy}\) walk), providing detailed versions of the main results in SS4.

We first establish that the query complexity of \(\mathsf{In}\)-and-Out matches that of the \(\mathsf{Ball}\) walk under stronger divergences. Recall that \(2\|\cdot\|_{\mathsf{TV}}^{2}\leq\mathsf{KL}\leq\log(1+\chi^{2})\leq\chi^{2}\).

**Theorem 5**.: _For any given \(\eta,\varepsilon\in(0,1)\), \(q\geq 1\), \(m\in\mathbb{N}\) defined below and any convex body \(\mathcal{K}\) given by a well-defined membership oracle, consider \(\mathsf{In}\)-and-Out (Algorithm 1) with an \(M\)-warm initial distribution \(\mu_{0}^{X}\), \(h=(2d^{2}\log\frac{9mM}{\eta})^{-1}\), and \(N=\widetilde{\mathcal{O}}(\frac{mM}{\eta})\). For \(\pi^{X}\) the uniform distribution over \(\mathcal{K}\),_

* _It achieves_ \(\mathcal{R}_{q}(\mu_{m}^{X}\,\|\,\pi^{X})\leq\varepsilon\) _after_ \(m=\widetilde{\mathcal{O}}(qd^{2}\|\mathrm{Cov}(\pi^{X}))\|_{\mathsf{op}}\log^{ 2}\frac{M}{\eta\varepsilon})\) _iterations. With probability_ \(1-\eta\)_, the algorithm iterates this many times without failure, using_ \(\widetilde{\mathcal{O}}(qMd^{2}\|\mathrm{Cov}(\pi^{X})\|_{\mathsf{op}}\log^{6} \frac{1}{\eta\varepsilon})\) _expected number of membership queries in total._
* _For isotropic_ \(\pi^{X}\)_, with probability_ \(1-\eta\)_, the algorithm achieves_ \(\mathcal{R}_{q}(\mu_{m}^{X}\,\|\,\pi^{X})\leq\varepsilon\) _with_ \(m=\widetilde{\mathcal{O}}(qd^{2}\log^{2}\frac{M}{\eta\varepsilon})\) _iterations, using_ \(\widetilde{\mathcal{O}}(qMd^{2}\log^{6}\frac{1}{\eta\varepsilon})\) _membership queries in expectation._

Proof.: We just put together Lemma 3 and Theorem 3. For target accuracy \(\varepsilon>0\), we use the \(\mathcal{R}_{q}\)-decay under (Pl) for \(q\geq 2\) in Theorem 3. The \(M\)-warm start assumption guarantees \(\mathcal{R}_{q}(\mu_{0}^{X}\,\|\,\pi^{X})\lesssim\log M\). Due to \(C_{\mathsf{Pl}}(\pi^{X})=\mathcal{O}(\|\mathrm{Cov}(\pi^{X})\|_{\mathsf{op}} \,\log d)\) (Lemma 9), \(\mathsf{In}\)-and-Out can achieve \(\mathcal{R}_{q}(\mu_{m}^{X}\,\|\,\pi^{X})\leq\varepsilon\) after \(m=\widetilde{\mathcal{O}}(qd^{2}\|\mathrm{Cov}(\pi^{X})\|_{\mathsf{op}}\log^{ 2}\frac{M}{\eta\varepsilon})\) iterations. Since each iteration has \(\eta/m\)-failure probability by Lemma 3, the union bound ensures that the total failure probability is at most \(\eta\) throughout \(m\) iterations. Lastly, each iteration requires \(\widetilde{\mathcal{O}}(M\log^{4}\frac{1}{\eta\varepsilon})\) membership queries in expectation by Lemma 3. Therefore, \(\mathsf{In}\)-and-Out uses \(\widetilde{\mathcal{O}}(qMd^{2}\min(D^{2},\|\mathrm{Cov}(\pi^{X})\|_{\mathsf{ op}})\log^{6}\frac{1}{\eta\varepsilon})\) expected number of membership queries over \(m\) iterations. Since \(\mathcal{R}_{q}\) is non-decreasing in \(q\), we can obtain the desired bound on \(\mathcal{R}_{q}\) for \(q\in[1,2)\).

For isotropic \(\pi^{X}\), we have \(\mathrm{Cov}(\pi^{X})=I_{d}\), so the claim immediately follows from \(C_{\mathsf{Pl}}(\pi^{X})=\mathcal{O}(\log d)\) (see Lemma 9). 

We now show that the number of proper steps is bounded as claimed for general _non-convex bodies_ and _any feasible start_ in \(\mathcal{K}\). We first establish this result under an \(M\)-warm start (Theorem 2).

Proof of Theorem 2.: By the Renyi-decay under (\(\mathsf{LSI}\)-) in Theorem 3, \(\mathsf{In}\)-and-Out can achieve \(\varepsilon\)-distance to \(\pi^{X}\) after \(\mathcal{O}\bigl{(}qh^{-1}C_{\mathsf{LSI}}(\pi^{X})\log^{\frac{\mathcal{R}_{q}( \mu_{0}^{X}\,\|\,\pi^{X})}{\varepsilon}}\bigr{)}\) iterations for \(q\geq 1\).

For \(q\geq 2\), we use the decay result under (Pl). In this case, \(\mathsf{In}\)-and-Out decays under two different rates depending on the value of \(\mathcal{R}_{q}(\cdot\,\|\,\pi^{X})\). It first needs \(\mathcal{O}(qh^{-1}C_{\mathsf{Pl}}(\pi^{X})\mathcal{R}_{q}(\mu_{0}^{X}\,\|\, \pi^{X}))\) iterations until \(\mathcal{R}_{q}(\cdot\,\|\,\pi^{X})\) reaches \(1\). Then, \(\mathsf{In}\)-and-Out additionally needs \(\mathcal{O}(qh^{-1}C_{\mathsf{Pl}}(\pi^{X})\log\frac{1}{\varepsilon})\) iterations, and thus it needs \(\mathcal{O}(qh^{-1}C_{\mathsf{Pl}}(\pi^{X})\bigl{(}\mathcal{R}_{q}(\mu_{0}^{X}\, \|\,\pi^{X})+\log\frac{1}{\varepsilon}\bigr{)})\) iterations in total. By substituting \(\mathcal{R}_{q}(\mu_{0}^{X}\,\|\,\pi^{X})\lesssim\log M\), we complete the proof. 

Next, we show that \(\mathsf{In}\)-and-Out mixes from any start.

**Corollary 2**.: _For any given \(\varepsilon\in(0,1)\) and set \(\mathcal{K}\subset B_{D}(0)\), \(\mathsf{In}\)-and-\(\mathsf{Out}\) with variance \(h\) and any feasible start \(x_{0}\in\mathcal{K}\) achieves \(\mathcal{R}_{q}(\mu_{m}^{X}\,\|\,\pi^{X})\leq\varepsilon\) after \(m=\widetilde{\mathcal{O}}(qh^{-1}C_{\mathsf{LSI}}(\pi^{X})\log\frac{d+D^{2}/h}{ \varepsilon})\) iterations._

Proof.: We first bound the warmness of \(\mu_{1}^{X}\) w.r.t. \(\pi^{X}\) when \(\mu_{0}^{X}=\delta_{x_{0}}\). One can readily check that

\[\mu_{1}^{X}(x)=\mathds{1}_{\mathcal{K}}(x)\cdot\int\frac{\exp\bigl{(}-\frac{1} {2h}\|y-x\|^{2}\bigr{)}\exp\bigl{(}-\frac{1}{2h}\|y-x_{0}\|^{2}\bigr{)}}{(2\pi h )^{d/2}\int_{\mathcal{K}}\exp\bigl{(}-\frac{1}{2h}\|y-x\|^{2}\bigr{)}\,\mathrm{ d}x}\,\mathrm{d}y\,.\]

By Young's inequality, \(\|y-x\|^{2}\leq(\|y\|+D)^{2}\leq\frac{3}{2}\|y\|^{2}+3D^{2}\) for \(x\in\mathcal{K}\). Hence,

\[\int\frac{\exp\bigl{(}-\frac{1}{2h}\|y-x\|^{2}\bigr{)}\exp\bigl{(} -\frac{1}{2h}\|y-x_{0}\|^{2}\bigr{)}}{\int_{\mathcal{K}}\exp\bigl{(}-\frac{1} {2h}\|y-x\|^{2}\bigr{)}\,\mathrm{d}x}\,\mathrm{d}y\] \[\leq \frac{\exp(2h^{-1}D^{2})}{\mathrm{vol}(\mathcal{K})}\int\exp \Bigl{(}-\frac{1}{2h}\bigl{(}\|y-x\|^{2}+\|y-x_{0}\|^{2}-\frac{3}{2}\|y\|^{2} \bigr{)}\Bigr{)}\,\mathrm{d}y\] \[= \frac{\exp(2h^{-1}D^{2})}{\mathrm{vol}(\mathcal{K})}\int\exp \Bigl{(}-\frac{1}{2h}\bigl{(}\frac{1}{2}\|y-2(x+x_{0})\|^{2}+(\|x\|^{2}+\|x_{ 0}\|^{2}-2\|x+x_{0}\|^{2})\bigr{)}\Bigr{)}\,\mathrm{d}y\] \[\leq \frac{\exp(5h^{-1}D^{2})}{\mathrm{vol}(\mathcal{K})}\int\exp \Bigl{(}-\frac{1}{4h}\|y-2(x+x_{0})\|^{2}\Bigr{)}\,\mathrm{d}y\] \[= \frac{\exp(5h^{-1}D^{2})}{\mathrm{vol}(\mathcal{K})}(4\pi h)^{d/2}\,.\]

Therefore, \(M=\operatorname{ess}\sup\frac{\mu^{X}_{0}}{\pi^{X}}\leq 2^{d/2}\exp(5h^{-1}D^{2})\). By Theorem 2 under (LSI-l), \(\mathsf{In}\)-and-\(\mathsf{Out}\) needs \(\widetilde{\mathcal{O}}(qh^{-1}C_{\mathsf{LSI}}(\pi^{X})\log\frac{d+D^{2}/h}{ \varepsilon})\) iterations. 

We then obtain the following corollary for a convex body \(\mathcal{K}\).

**Corollary 3**.: _For any given \(\varepsilon\in(0,1)\) and convex body \(\mathcal{K}\subset B_{D}(0)\), \(\mathsf{In}\)-and-\(\mathsf{Out}\) with variance \(h\) and an \(M\)-warm initial distribution achieves \(\mathcal{R}_{q}(\mu_{m}^{X}\,\|\,\pi^{X})\leq\varepsilon\) after \(m=\widetilde{\mathcal{O}}(qh^{-1}D^{2}\log\frac{1}{\varepsilon})\) iterations. If \(\pi^{X}\) is isotropic, then \(\mathsf{In}\)-and-\(\mathsf{Out}\) only needs \(\widetilde{\mathcal{O}}(qh^{-1}D\log\frac{d+d^{2}/h}{\varepsilon})\) iterations._

Proof.: For convex \(\mathcal{K}\), it follows from Lemma 9 that \(C_{\mathsf{LSI}}(\pi^{X})=\mathcal{O}(D^{2})\) and \(C_{\mathsf{LSI}}(\pi^{X})=\mathcal{O}(D)\) for isotropic \(\mathcal{K}\). The rest of the proof can be completed in a similar way. 

For \(h=\tilde{\Theta}(d^{-2})\), \(\mathsf{In}\)-and-\(\mathsf{Out}\) requires \(\widetilde{\mathcal{O}}(qd^{2}D^{2})\) iterations and in particular \(\widetilde{\mathcal{O}}(qd^{2}D)\) iteration for isotropic uniform distributions. These results match those of Speedy walk[61, 37] (see Theorem 7).

## Appendix C Ball walk and Speedy walk

We restate the previously known guarantees for uniform sampling by Ball walk and Speedy walk. Below, let \(B_{r}(x)\) denote the \(d\)-dimensional ball of radius \(r\) centered at \(x\).

``` Input: initial distribution \(\pi_{0}\), convex body \(\mathcal{K}\subset\mathbb{R}^{d}\), iterations \(T\), step size \(\delta>0\).
1: Sample \(x_{0}\sim\pi_{0}\).
2:for\(i=1,\ldots,T\)do
3: Sample \(y\sim\mathsf{Unif}(B_{\delta}(x_{i-1}))\).
4: If \(y\in\mathcal{K}\), then \(x_{i}\gets y\). Else, \(x_{i}\gets x_{i-1}\).
5:endfor ```

**Algorithm 2** Ball walk

Ball walk is particularly simple; draw a uniform random point from \(B_{\delta}\) around the current point, and go there if the drawn point is inside of \(\mathcal{K}\) and stay at the current point otherwise. Its stationary distribution can be easily seen to be \(\pi\propto\mathds{1}_{\mathcal{K}}\), the uniform distribution over \(\mathcal{K}\).

In the literature, there are two approaches to analyzing the convergence rate of this sampler: (i) a direct analysis via the \(s\)-conductance of Ball walk and (ii) an indirect approach which first passes through Speedy walk.

Direct analysis.The following TV-guarantee is obtained by lower bounding the \(s\)-conductance of Ball walk, which requires a one-step coupling argument and the Cheeger inequality for \(\pi\). We refer interested readers to [16, SS5].

**Theorem 6** (Convergence of Ball walk).: _For any \(\varepsilon\in(0,1)\) and convex body \(\mathcal{K}\subset\mathbb{R}^{d}\) presented by a well-defined membership oracle, let \(\pi_{t}\) be the distribution after \(t\) steps of_ Ball walk _with an \(M\)-warm initial distribution \(\pi_{0}\). Then,_ Ball walk _with step size \(\delta=\Theta(\frac{\varepsilon}{M\sqrt{d}})\) achieves \(\|\pi_{t}-\pi\|_{\mathsf{TV}}\leq\varepsilon\) for \(t\gtrsim d^{2}D^{2}\frac{M^{2}}{\varepsilon^{2}}\log\frac{M}{\varepsilon}\). If \(\pi\) is isotropic, then_ Ball walk _needs \(\mathcal{O}(d^{2}\frac{M^{2}}{\varepsilon^{2}}\log d\log\frac{M}{\varepsilon})\) iterations._

The mixing time of Ball walk under this approach has a polynomial dependence on \(1/\varepsilon\), rather than a polylogarithmic dependence.

Indirect analysis through Speedy walk.[4] introduced Speedy walk, which could be viewed as a version of Ball walk and converges to a _speedy distribution_ (see Proposition 1), which is slightly biased from \(\pi\). Then, Speedy walk is used together with another algorithmic component (rejection sampling) [4, Algorithm 4.15] that converts the speedy distribution to the uniform distribution. In the literature, Ball walk often refers to 'Speedy walk combined with the conversion step', rather than a direct implementation of Algorithm 2. Strictly speaking, a mixing guarantee of this combined algorithm should not be referred to as a provable guarantee of Ball walk.

``` Input: initial distribution \(\pi_{0}\), convex body \(\mathcal{K}\subset\mathbb{R}^{d}\), iterations \(T\), step size \(\delta>0\).
1: Sample \(x_{0}\sim\pi_{0}\).
2:for\(i=1,\dots,T\)do
3: Sample \(x_{i}\sim\text{Unif}(\mathcal{K}\cap B_{\delta}(x_{i-1}))\).
4:endfor ```

**Algorithm 3**Speedy walk

As opposed to Ball walk, Speedy walk _always_ takes some step at each iteration. However, the problem of sampling from \(x_{i}\sim\text{Unif}(\mathcal{K}\cap B_{\delta}(x_{i-1}))\) in Line 3 is not straightforward. This step admits the following implementation based on rejection sampling, via a procedure denoted by \((*)\):

* Propose \(y\sim\text{Unif}(B_{\delta}(x_{i-1}))\).
* Set \(x_{i+1}\gets y\) if \(y\in\mathcal{K}\). Otherwise, repeat the proposal.

Each actual step (indexed by \(i\)) in Speedy walk is called a _proper step_, and rejected steps during \((*)\) are called _improper steps_. For example, if \(x_{1},x_{1},x_{2},x_{3},x_{3},x_{3},x_{4},\dots\) are the positions produced by Ball walk, then only proper steps \(x_{1},x_{2},x_{3},x_{4},\dots\) are recorded by Speedy walk.

To describe the theoretical guarantees of Speedy walk, we define the _local conductance_\(\ell(x)\) at \(x\in\mathcal{K}\), which measures the success probability of the rejection sampling scheme in \((*)\):

\[\ell(x):=\frac{\text{vol}(\mathcal{K}\cap B_{\delta}(x))}{\text{vol}(B_{\delta} (x))}\,,\]

and define the _average conductance_:

\[\lambda:=\mathbb{E}_{\pi}\ell=\frac{1}{\text{vol}(\mathcal{K})}\int_{\mathcal{ K}}\ell(x)\,\mathrm{d}x\,.\]

**Proposition 1** ([4]).: _The stationary distribution \(\nu\) of_ Speedy walk _has density_

\[\nu(x)=\frac{\ell(x)\,\mathds{1}_{\mathcal{K}}(x)}{\int_{\mathcal{K}}\ell(x) \,\mathrm{d}x}\,.\]

The speedy distribution \(\nu\) is indeed different from the uniform distribution \(\pi\), and this discrepancy is quantified in terms of the average conductance.

**Proposition 2** ([4, Page 22]).: \(\|\nu-\pi\|_{\mathsf{TV}}\leq\frac{1-\lambda}{\lambda}\)_._

One can relate the step size \(\delta\) to the average conductance.

**Proposition 3** (Bound on average conductance, [4, Corollary 4.5]).: \(\lambda\geq 1-\frac{\delta\sqrt{d}}{2}\)_._

The best known result for \(\mathsf{Speedy}\) walk's mixing is due to [61] devising the _blocking conductance_ and using the _log-Cheeger_ inequality. When \(\nu\) is isotropic (i.e., it has covariance proportional to the identity matrix), [37] improves the mixing bound via the _log-Cheeger_ constant.

**Theorem 7** (Mixing of \(\mathsf{Speedy}\) walk).: _For any \(\varepsilon\in(0,1)\) and convex body \(\mathcal{K}\subset\mathbb{R}^{d}\) presented by a well-defined membership oracle, let \(\nu_{t}\) be the distribution after \(t\) proper steps of \(\mathsf{Speedy}\) walk started at any feasible point \(x_{0}\in\mathcal{K}\). Then, \(\mathsf{Speedy}\) walk with step size \(\delta=\Theta(d^{-1/2})\) achieves \(\|\nu_{t}-\nu\|_{\mathsf{TV}}\leq\varepsilon\) for \(t\gtrsim(D^{2}+\log(D\sqrt{d}))\,d^{2}\log\frac{1}{\varepsilon}\). From an \(M\)-warm start, the expected number of improper steps during \(t\) iterations is \(\widetilde{\mathcal{O}}(tM)\). When \(\nu\) is isotropic, \(\mathsf{Speedy}\) walk needs \(\mathcal{O}(d^{2}D\log\frac{1}{\varepsilon}\log\log D)\) proper steps to achieve \(\varepsilon\)-\(\mathsf{TV}\) distance to \(\nu\)._

Then, [4] uses the following post-processing step to obtain an approximately uniform distribution on \(\mathcal{K}\), with a provable guarantee.

\(\mathcal{A}\): Call \(\mathsf{Speedy}\) walk to obtain a sample \(X\sim\nu_{t}\) until \(\frac{2d}{2d-1}\,X\in\mathcal{K}\). If so, return \(\bar{X}=\frac{2d}{2d-1}\,X\).

**Proposition 4** ([4, Theorem 4.16]).: _Under the same setting above, assume \(\|\nu_{t}-\nu\|_{\mathsf{TV}}\leq\varepsilon\) for step size \(\delta\leq(8d\log\frac{1}{\varepsilon})^{-1/2}\) and fixed \(t\in\mathbb{N}\). For \(\bar{\nu}=\mathsf{law}(\bar{X})\) given by \(\mathcal{A}\), it holds that \(\|\bar{\nu}-\pi\|_{\mathsf{TV}}\leq\varepsilon\), and the expected number of calls on the conversion algorithm is at most \(2\)._

Combining the previous two results, we conclude that the total expected number of membership queries to obtain a sample \(\varepsilon\)-close to \(\pi\) in \(\mathsf{TV}\) is \(\widetilde{\mathcal{O}}(Md^{2}D^{2}\log\frac{1}{\varepsilon})\), which now has a poly-logarithmic dependence on \(1/\varepsilon\).

_Remark 3_ (Backward heat flow analysis of \(\mathsf{Speedy}\) walk).: Consider a Gaussian version of \(\mathsf{Speedy}\) walk, whose one-step corresponds to \(x_{i+1}\sim\mathcal{N}(x_{i},hI_{d})|_{\mathcal{K}}\), and this transition kernel exactly matches integrating (BH) for time \(h\). Thus, \(\nu Q_{h}^{\pi^{X},h}=\nu\) due to the stationarity of \(\nu\) under \(\mathsf{Speedy}\) walk, where \(Q_{h}^{\pi^{X},h}\) is the transition kernel defined by the backward heat flow for time \(h\) that reverses \(\pi^{X}*\mathcal{N}(0,hI_{d})\) to \(\pi^{X}\). Hence, if we can control the LSI/PI constants of \(\nu\) along the backward heat-flow's trajectory, then we could directly analyze \(\mathsf{Speedy}\) walk by emulating computations in Lemma 4.

## Appendix D Functional inequalities

We provide full details on functional inequalities omitted in Appendix B.1. We use \(\mu\) and \(\mu_{\mathsf{LC}}\) to denote a probability measure and log-concave probability measure over \(\mathbb{R}^{d}\), respectively.

Cheeger and PI constants.The _Cheeger isoperimetric constant_\(C_{\mathsf{Ch}}(\mu)\) measures how large surface area a measurable subset with larger volume has, defined by

\[C_{\mathsf{Ch}}(\mu):=\inf_{S\subset\mathbb{R}^{d}}\frac{\mu^{+}(S)}{\min(\mu( S),\mu(S^{c}))}\,,\]

where the infimum is taken over all measurable subsets \(S\), and \(\mu^{+}(S)\) is the Minkowski content of \(S\) under \(\mu\) defined as, for \(S^{c}:=\{x\in X:d(x,S)<\varepsilon\}\),

\[\mu^{+}(S):=\liminf_{\varepsilon\to 0}\frac{\mu(S^{c})-\mu(S)}{\varepsilon}\,.\]

[62] established \(C_{\mathsf{PI}}(\mu)\lesssim C_{\mathsf{Ch}}^{-2}(\mu)^{5}\), and then [33] showed that for covariance matrix \(\Sigma_{\mu}:=\mathbb{E}_{\mu}[(\cdot-\mathbb{E}_{\mu}X)(\cdot-\mathbb{E}_{\mu }X)^{\mathsf{T}}]\),

\[C_{\mathsf{Ch}}(\mu_{\mathsf{LC}})\gtrsim\frac{1}{(\mathbb{E}_{\mu_{\mathsf{LC} }}[\|X-\mathbb{E}_{\mu_{\mathsf{LC}}}X\|^{2}])^{1/2}}=\frac{1}{(\operatorname{ tr}\Sigma_{\mu_{\mathsf{LC}}})^{1/2}}\,.\] (D.1)This immediately leads to \(C_{\text{Pl}}(\pi)\lesssim(\mathbb{E}_{\pi}[\|X-\mathbb{E}_{\pi}X\|^{2}])^{1/2}\leq D ^{2}\) for the uniform distribution \(\pi\) over a convex body \(\mathcal{K}\) with diameter \(D>0\).

Kannan et al. proposed the _KLS conjecture_ in the same paper, which says that for the spectral norm \(\|\cdot\|_{2}\),

\[C_{\text{Ch}}(\mu_{\text{LS}})\gtrsim\frac{1}{\|\Sigma_{\mu_{\text{LS}}}\|_{2} ^{1/2}}\,.\]

While the original result in [33] ensures \(C_{\text{Ch}}\gtrsim d^{-1/2}\) for an isotropic log-concave distribution (due to \(\Sigma=I_{d}\)), this conjecture indeed claims \(C_{\text{Ch}}\gtrsim 1\) for such case. Following a line of work [37, 55, 65, 34], the current bound is

\[C_{\text{Ch}}(\mu_{\text{LS}})\gtrsim\frac{(\log d)^{-1/2}}{\|\Sigma_{\mu_{ \text{LS}}}\|_{2}^{1/2}}\,,\]

which implies that \(C_{\text{Pl}}(\pi)\lesssim\log d\) when \(\pi\) is isotropic for convex \(\mathcal{K}\).

Log-Cheeger and LSI constants.Just as the Cheeger and PI constants are related above, there are known connections between LSI and _log-Cheeger_ constants. The log-Cheeger constant \(C_{\text{logCh}}(\mu)\) of a distribution \(\mu\in\mathcal{P}(\mathbb{R}^{d})\) is defined as

\[C_{\text{logCh}}(\mu):=\inf_{S\subset\mathbb{R}^{d};\mu(S)\leq\frac{1}{2}} \frac{\mu^{+}(S)}{\mu(S)\sqrt{\log\frac{1}{\mu(S)}}}\,.\]

[64] established that \(C_{\text{LSI}}(\mu)\lesssim C_{\text{logCh}}^{-2}(\mu)\)6, and [61] showed that any log-concave distributions with support of diameter \(D>0\) satisfy \(C_{\text{logCh}}(\mu_{\text{LS}})\gtrsim D^{-1}\). Later in 2016, [37] improved this to \(C_{\text{logCh}}(\mu_{\text{LS}})\gtrsim D^{-1/2}\) under isotropy. Therefore, for convex \(\mathcal{K}\), it follows that \(C_{\text{LSI}}(\pi)\lesssim D^{2}\) and that \(C_{\text{LSI}}(\pi)\lesssim D\) if \(\pi\) is isotropic.

Footnote 6: The opposite direction holds under dimension-scaling due to [64]: \(C_{\text{LSI}}(\mu)\gtrsim C_{\text{logCh}}^{-2}(\mu)/d\).

## Appendix E The Wasserstein geometry

We present additional technical background on the Wasserstein geometry and Markov semigroup theory. Interested readers can refer to [66, 67, 28] for standard references on Wasserstein spaces and applications to sampling.

Wasserstein gradient.Let \(\mathcal{P}_{2,\text{ac}}(\mathbb{R}^{d})\) be the space of probability measures admitting densities on \(\mathbb{R}^{d}\) with finite second moment. Although there are many ways to metrize \(\mathcal{P}_{2,\text{ac}}(\mathbb{R}^{d})\), the geometry induced by the Wasserstein-\(2\) distance \(\mathcal{W}_{2}\) is a particularly useful structure for analysis.

Under the \(\mathcal{W}_{2}\)-geometry, one can define a "gradient" of a functional defined over \(\mathcal{P}_{2,\text{ac}}(\mathbb{R}^{d})\). Specifically, for a functional \(\mathcal{F}:\mathcal{P}_{2,\text{ac}}(\mathbb{R}^{d})\to\mathbb{R}\cup\{\infty\}\), the _Wasserstein gradient_ of \(\mathcal{F}\) at \(\mu\in\mathcal{P}_{2,\text{ac}}(\mathbb{R}^{d})\) is defined as \(\nabla_{\mathcal{W}_{2}}\mathcal{F}(\mu)=\nabla(\delta\mathcal{F})(\mu)\in L ^{2}(\mu)\), where \(\nabla\) is the standard gradient and \(\delta\mathcal{F}\) is the first variation of \(\mathcal{F}\). Equipped with this \(\mathcal{W}_{2}\)-gradient, one can define the _Wasserstein gradient flow_ of \(\mathcal{F}\) that describes the evolution of a measure \(\{\mu_{t}\}_{t\geq 0}\), from some initial measure \(\mu_{0}\), as follows:

\[\partial_{t}\mu_{t}=\operatorname{div}\bigl{(}\mu_{t}\nabla_{\mathcal{W}_{2}} \mathcal{F}(\mu_{t})\bigr{)}\,.\]

More generally, we can identify the Wasserstein "velocity" for some measure \(\mu_{t}\) as \(v_{t}\) if the time derivative of \(\mu_{t}\) can be written in the form

\[\partial_{t}\mu_{t}=-\operatorname{div}(\mu_{t}v_{t})\,.\]

Under this identification, the time derivative of a functional \(\mathcal{F}\) on \(\mathcal{P}_{2,\text{ac}}(\mathbb{R}^{d})\) with smooth Wasserstein gradient under these dynamics can be written as

\[\partial_{t}\mathcal{F}(\mu_{t})=\mathbb{E}_{\mu_{t}}\langle\nabla_{\mathcal{W }_{2}}\mathcal{F}(\mu_{t}),v_{t}\rangle\,,\]when \(v_{t}\in\overline{\{\nabla\psi:\psi\in C^{\infty}_{c}(\mathbb{R}^{d})\}}^{L^{2}( \mu_{t})}\), where \(\overline{\{\cdot\}}^{L^{2}(\mu_{t})}\) denotes the closure of a set with respect to \(L^{2}(\mu_{t})\). This is the appropriate notion of tangent space in this geometry.

For instance, when we take the functional to be the entropy of the measure, \(\mathcal{H}(\mu)\coloneqq\frac{1}{2}\int\mu\log\mu\), one can verify \(\nabla_{\mathcal{W}_{2}}\mathcal{H}(\mu)=\frac{1}{2}\nabla\log\mu\). The heat flow equation can be written as \(\partial_{t}\mu_{t}=\frac{1}{2}\Delta\mu_{t}=\frac{1}{2}\operatorname{div}( \nabla\mu_{t})=\frac{1}{2}\operatorname{div}(\mu_{t}\nabla\log\mu_{t})\), which indicates that the velocity of measures \(\mu_{t}\) under the heat flow is \(v_{t}=-\frac{1}{2}\nabla\log\mu_{t}\). Hence, we can notice that \(\nabla_{\mathcal{W}_{2}}\mathcal{H}(\mu_{t})=-v_{t}\), and thus recover the heat flow as the Wasserstein gradient flow of the entropy of the measure.

Fokker-Planck equation and time-reversal of SDE.Consider a stochastic differential equation \((X_{t})\) given by

\[\mathrm{d}X_{t}=-a_{t}(X_{t})\,\mathrm{d}t+\,\mathrm{d}B_{t}\qquad\text{ with }X_{0}\sim\mu_{0}\,.\] (E.1)

It is well known that measures \(\mu_{t}\) described by

\[\partial_{t}\mu_{t}=\text{div}(\mu_{t}a_{t})+\frac{1}{2}\Delta\mu_{t}\,,\] (E.2)

correspond to \(\text{law}(X_{t})\). In this context, (E.2) is referred to as the _Fokker-Planck equation_ corresponding to (E.1).

From this equation, one can deduce the Fokker-Planck equation of the time reversal \(\mu_{t}^{\leftarrow}:=\mu_{T-t}\):

\[\partial_{t}\mu_{t}^{\leftarrow}=-\operatorname{div}(\mu_{t}^{\leftarrow}a_{ T-t})-\frac{1}{2}\Delta\mu_{t}^{\leftarrow}=-\operatorname{div}\bigl{(}\mu_{t}^{ \leftarrow}(a_{T-t}+\nabla\log\mu_{T-t})\bigr{)}+\frac{1}{2}\Delta\mu_{t}^{ \leftarrow}\]

In particular, this describes the evolution of \(\text{law}(X_{t})\) of the stochastic differential equation:

\[\mathrm{d}X_{t}=\bigl{(}a_{T-t}(X_{t})+\nabla\log\mu_{T-t}(X_{t})\bigr{)}\, \mathrm{d}t+\,\mathrm{d}B_{t}\qquad\text{with }X_{0}\sim\mu_{0}^{\leftarrow}=\mu_{T}\,.\] (E.3)

While the law of this process will give \(\mu_{T}^{\leftarrow}=\mu_{0}\) at time \(T\), it is also true that it will give \(\mu_{0|T}(\cdot|z)\) if one starts (E.3) at \(X_{0}=z\). This is a subtle fact, whose justification requires the introduction of a tool called _Doob's \(h\)-transform_. The presentation of this subject is beyond the scope of this paper, and we refer interested readers to [53] as a reference to its application in this context.

### NeurIPS Paper Checklist

The checklist is designed to encourage best practices for responsible machine learning research, addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove the checklist: **The papers not including the checklist will be desk rejected.** The checklist should follow the references and follow the (optional) supplemental material. The checklist does NOT count towards the page limit.

Please read the checklist guidelines carefully for information on how to answer these questions. For each question in the checklist:

* You should answer [Yes], [No], or [NA].
* [NA] means either that the question is Not Applicable for that particular paper or the relevant information is Not Available.
* Please provide a short (1-2 sentence) justification right after your answer (even for NA).

**The checklist answers are an integral part of your paper submission.** They are visible to the reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it (after eventual revisions) with the final version of your paper, and its final version will be published with the paper.

The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation. While "[Yes] " is generally preferable to "[No] ", it is perfectly acceptable to answer "[No] " provided a proper justification is given (e.g., "error bars are not reported because it would be too computationally expensive" or "we were unable to find the license for the dataset we used"). In general, answering "[No] " or "[NA] " is not grounds for rejection. While the questions are phrased in a binary way, we acknowledge that the true answer is often more nuanced, so please just use your best judgment and write a justification to elaborate. All supporting evidence can appear either in the main paper or the supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification please point to the section(s) where related material for the question can be found.

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: The primary claim is that we are presenting a new algorithm for uniform sampling convex bodies, with guarantees in Renyi divergence. This is achieved by Algorithm 1 through Theorem 5. Guidelines:
* The answer NA means that the abstract and introduction do not include the claims made in the paper.
* The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.
* The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.
* It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: The primary limitations of this work are due to the assumptions. The assumptions are clearly given when presenting our main results, and some potential extensions or relaxations are given in our conclusion. Guidelines:* The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.
* The authors are encouraged to create a separate "Limitations" section in their paper.
* The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.
* The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.
* The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.
* The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.
* If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.
* While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: The assumptions are provided for each theorem, and the full proofs can be found in Appendix B. A brief proof overview of the proofs are found in the main text, following the results. Guidelines:

* The answer NA means that the paper does not include theoretical results.
* All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
* All assumptions should be clearly stated or referenced in the statement of any theorems.
* The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.
* Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.
* Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [NA] Justification: The contribution of this paper is primarily theoretical, and the paper does not contain any experimental results. Guidelines:

* The answer NA means that the paper does not include experiments.
* If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.

* If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.
* Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.
* While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [NA] Justification: The paper does not contain experiments and therefore does not require data or code. Guidelines:
* The answer NA means that paper does not include experiments requiring code.
* Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [NA] Justification: The paper does not contain experiments.

Guidelines:

* The answer NA means that the paper does not include experiments.
* The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them.
* The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [NA] Justification: The paper does not contain experiments. Guidelines:

* The answer NA means that the paper does not include experiments.
* The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.
* The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).
* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [NA] Justification: The paper does not contain experiments. Guidelines:

* The answer NA means that the paper does not include experiments.
* The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.
* The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.
* The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: The paper conforms to the Code of Ethics and the guidelines prescribed therein. Guidelines:* The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
* If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.
* The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: The impact of this paper is primarily theoretical, and it is therefore difficult to quantify societal impact directly. The discussion surrounding the main theorems contains the benefits and limitations of our analysis, which we would hope also captures their societal impact. Guidelines:
* The answer NA means that there is no societal impact of the work performed.
* If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.
* Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.
* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: The paper does not release data or models. Guidelines:

* The answer NA means that the paper poses no such risks.
* Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.
* Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.
* We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected?Answer: [NA] Justification: The paper does not use existing assets. Guidelines:

* The answer NA means that the paper does not use existing assets.
* The authors should cite the original paper that produced the code package or dataset.
* The authors should state which version of the asset is used and, if possible, include a URL.
* The name of the license (e.g., CC-BY 4.0) should be included for each asset.
* For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.
* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.

13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: The paper does not release new assets. Guidelines:

* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.

14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: The paper involves neither crowdsourcing nor research with human subjects. Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.

15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA].

Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.