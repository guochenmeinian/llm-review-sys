# Universal Exact Compression of Differentially Private Mechanisms

Yanxiao Liu

The Chinese University of Hong Kong

yanxiaoliu@link.cuhk.edu.hk

&Wei-Ning Chen

Stanford University

wnchen@stanford.edu

&Ayfer Ozgur

Stanford University

aozgur@stanford.edu

&Cheuk Ting Li

The Chinese University of Hong Kong

ctli@ie.cuhk.edu.hk

###### Abstract

To reduce the communication cost of differential privacy mechanisms, we introduce a novel construction, called Poisson private representation (PPR), designed to compress and simulate any local randomizer while ensuring local differential privacy. Unlike previous simulation-based local differential privacy mechanisms, PPR exactly preserves the joint distribution of the data and the output of the original local randomizer. Hence, the PPR-compressed privacy mechanism retains all desirable statistical properties of the original privacy mechanism such as unbiasedness and Gaussianity. Moreover, PPR achieves a compression size within a logarithmic gap from the theoretical lower bound. Using the PPR, we give a new order-wise trade-off between communication, accuracy, central and local differential privacy for distributed mean estimation. Experiment results on distributed mean estimation show that PPR consistently gives a better trade-off between communication, accuracy and central differential privacy compared to the coordinate subsampled Gaussian mechanism, while also providing local differential privacy.

## 1 Introduction

In modern data science, there is a growing dependence on large amounts of high-quality data, often generated by edge devices (e.g., photos and videos captured by smartphones, or messages hosted by social networks). However, this data inherently contains personal information, making it susceptible to privacy breaches during acquisition, collection, or utilization. For instance, despite the significant recent advancement in foundational models [9], studies have shown that these models can accidentally memorize their training data. This poses a risk where malicious users, even with just API access, can extract substantial portions of sensitive information [14, 15]. In recent years, differential privacy (DP) [28] has emerged as a powerful framework for safeguarding users' privacy by ensuring that local data is properly randomized before leaving users' devices. Apart from privacy concerns, communicating local data from edge devices to the central server often becomes a bottleneck in the system pipeline, especially with high-dimensional data common in many machine learning scenarios. This leads to the following fundamental question: how can we efficiently communicate privatized data?

Recent works have shown that a wide range of differential privacy mechanisms can be "simulated" and "compressed" using shared randomness, resulting in a "compressed mechanism" which has a smaller communication cost compared to the original mechanism, while retaining the (perhaps slightly weakened) privacy guarantee. This can be done via rejection sampling [31], importance sampling [71, 78], or dithered quantization [56, 72, 46, 49, 80] with each approach having its own advantages and disadvantages. For example, importance-sampling-based methods [71, 78] and therejection-sampling-based method [31] can simulate a wide range of privacy mechanisms; however, the output distribution of the induced mechanism does not perfectly match the original mechanism. This is limiting in scenarios where the original mechanism is designed to satisfy some desired statistical properties, e.g. it is often desirable for the local randomizer to be unbiased or to be "summable" noise such as Gaussian or other infinitely divisible distributions. Since the induced mechanism is different from the original one, these statistical properties are not preserved. On the other hand, dithered-quantization-based approaches [48, 56, 72, 46, 49, 80] can ensure a correct simulated distribution, but they can only simulate additive noise mechanisms. More importantly, dithered quantization relies on shared randomness between the user and the server, and the server needs to know the dither for decoding. This annuls the local privacy guarantee on the user data, unless we are willing to assume a trusted aggregator [46], use an additional secure aggregation step [49], or restrict attention to specific privacy mechanisms (e.g., one-dimensional Laplace [72]).

#### Our contribution

In this paper, we introduce a novel "DP mechanism compressor" called _Poisson private representation (PPR)_, designed to compress and _exactly_ simulate _any_ local randomizer while ensuring local DP, through the use of shared randomness.1 We elaborate on three main advantages of PPR, namely universality, exactness and communication efficiency.

Footnote 1: Our code can be found in [https://github.com/cheuktingli/PoissonPrivateRepr](https://github.com/cheuktingli/PoissonPrivateRepr)

**Universality.** Unlike dithered-quantization-based approaches which can only simulate additive noise mechanisms, PPR can simulate any local or central DP mechanism with discrete or continuous input and output. Moreover, PPR is _universal_ in the sense that the user and the server only need to agree on the output space and a proposal distribution, and the user can simulate any DP mechanism with the same output space. The user can choose a suitable DP mechanism and privacy budget according to their communication bandwidth and privacy requirement, without divulging their choice to the server.

**Exactness.** Unlike previous DP mechanism compressors such as Feldman and Talwar [31], Shah et al. [71], Triastcyn et al. [78], PPR enables _exact_ simulation, ensuring that the reproduced distribution perfectly matches the original one. Exact distribution recovery offers several advantages. Firstly, the compressed sample maintains the same statistical properties as the uncompressed one. If the local randomizer is unbiased (a crucial requirement for many machine learning tasks like DP-SGD), the outcome of PPR remains unbiased. In contrast, reconstruction distributions in prior simulation-based compression methods [31, 71] are often biased unless specific debiasing steps are performed (only possible for certain DP mechanisms [71]). Secondly, when the goal is to compute the mean (e.g., for private mean or frequency estimation problems) and the local noise is "summable" (e.g., Gaussian noise or other infinitely divisible distributions [55, 42]), exact distribution recovery of the local noise enables precise privacy accounting for the final _central_ DP guarantee, without relying on generic privacy amplification techniques like shuffling [30, 32]. PPR can compress a central DP mechanism (e.g., the Gaussian mechanism [27]) and simultaneously achieve weaker local DP (i.e., with a larger \(\varepsilon_{\text{local}}\)) and stronger central DP (i.e., with a smaller \(\varepsilon_{\text{central}}\)), while maintaining exactly the same privacy-utility trade-offs as the uncompressed Gaussian mechanism.

**Communication efficiency.** PPR compresses the output of any DP mechanism to a size close to the theoretical lower bound. For a mechanism on the data \(X\) with output \(Z\), the compression size of PPR is \(I(X;Z)+\log(I(X;Z)+1)+O(1)\), with only a logarithmic gap from the mutual information lower bound \(I(X;Z)\).2 The "\(O(1)\)" constant can be given explicitly in terms of a tunable parameter \(\alpha>1\) which controls the trade-off between compression size, computational time and privacy.

Footnote 2: This is similar to channel simulation [45] and the strong functional representation lemma [61], though [45, 61] do not concern privacy.

The main technical tool we utilize for PPR is the Poisson functional representation [61, 60], which provides precise control over the reconstructed joint distribution in channel simulation problems [6, 45, 61, 35, 41, 10, 7, 21]. Channel simulation aims to achieve the minimum communication for simulating a channel (i.e., a specific conditional distribution). Typically, these methods rely on shared randomness between the user and server, and privacy is only preserved _when the shared randomness is hidden from the adversary_. This setup conflicts with local DP, where the server (which requires access to shared randomness for decoding) is considered adversarial. To ensure local DP, we introduce a randomized encoder based on the Poisson functional representation, which stochastically mapsa private local message to its representation. Hence, PPR achieves order-wise trade-offs between privacy, communication, and accuracy, while preserving the original distribution of local randomizers.

**Notations.** Entropy \(H(X)\), mutual information \(I(X;Y)\), KL divergence \(D(P\|Q)\) and logarithm are to the same base, e.g., they can be all in bits (base \(2\)), or all in nats (base \(e\)). For \(P,Q\), \(\mathrm{d}P(\cdot)/\mathrm{d}Q\) denotes the Radon-Nikodym derivative.

## 2 Related Work

Generic compression of local DP mechanisms.In this work, we consider both central DP [28] and local DP [79, 53]. Recent research has explored methods for compressing local DP randomizers when shared randomness is involved. For instance, when \(\varepsilon\leq 1\), Bassily and Smith [5] demonstrated that a single bit can simulate any local DP randomizer with a small degradation of utility, as long as the output can be computed using only a subset of the users' data. Bun et al. [12] proposed another generic compression technique based on rejection sampling, which compresses a \(\varepsilon\)-DP mechanism into a \(10\varepsilon\)-DP mechanism. Feldman and Talwar [31] proposed a distributed simulation approach using rejection sampling with shared randomness, while Shah et al. [71], Triastcyn et al. [78] utilized importance sampling (or more specifically, minimum random coding [20, 74, 47]). However, all these methods only _approximate_ the original local DP mechanism, unlike our scheme, which achieves an _exact_ distribution recovery.

Distributed mean estimation under DP.Mean estimation is the canonical problems in distributed learning and analytics. They have been widely studied under privacy [24, 8, 23, 4], communication [40, 11, 75], or both constraints [18, 31, 71, 43, 17, 19]. Among them, Asi et al. [4] has demonstrated that the optimal unbiased mean estimation scheme under local differential privacy is privUnit[8]. Subsequently, communication-efficient mechanisms introduced by Feldman and Talwar [31], Shah et al. [71], Isik et al. [51] aimed to construct communication-efficient versions of privUnit, either through distributed simulation or discretization. However, these approaches only approximate the privUnit distribution, while our proposed method ensures exact distribution recovery.

Distributed channel simulation.Our approach relies on the notion of channel simulation [6, 45, 61, 35, 41, 10, 7, 21]. One-shot channel simulation is a lossy compression task, which aims to find the minimum amount of communications over a noiseless channel that is in need to "simulate" some channel \(P_{Z|X}\) (a specific conditional distribution). By Harsha et al. [45], Li and El Gamal [61], the average communication cost is \(I(X;Z)+O(\log(I(X;Z)))\). In [45], algorithms based on rejection sampling are proposed, and it is further generalized in [39] by introducing the greedy rejection coding. Dithered quantization [81] has also been used to simulate an additive noise channel in [2] for neural compression. As also shown in [2], the time complexity of channel simulation protocols (e.g., in [61]) is usually high, and [76, 35, 41] try to improve the runtime under certain assumptions. Moreover, channel simulation tools have also been used in neural network compression [47], image compression via variational autoencoders [37], diffusion models with perfect realism [77] and differentially private federated learning [71].

Poisson functional representation.The Poisson functional representation is a channel simulation scheme studied in [61]. Also refer to [65] for related constructions for Monte Carlo simulations. Based on the Poisson functional representation, the Poisson matching lemma has been used in proving one-shot achievability results for various network information theory problems [60, 64]. Also see applications on unequal message protection [54], hypothesis testing [44], information hiding [63], minimax learning [62] and secret key generation [50]. A variation called the importance matching lemma [69] has also used in distributed lossy compression. By [38], the Poisson functional representation can be viewed as a certain variant of the A\({}^{*}\) sampling [66, 65], and hence an optimized version with better runtime for one-dimensional unimodal distribution has been proposed in [38].

## 3 Preliminaries

We begin by reviewing the formal definitions of differential privacy (DP). We consider two models of DP data analysis. In the central model, introduced in Dwork et al. [28], the data of the individuals is stored in a database \(X\in\mathcal{X}\) by the server. The server is then trusted to perform data analysis whose output \(Z=\mathcal{A}(X)\in\mathcal{Z}\) (where \(\mathcal{A}\) is a randomized algorithm), which is sent to an untrusted data analyst, does not reveal too much information about any particular individual's data. While this model requires a higher level of trust than the local model, it is possible to design significantly more accurate algorithms. We say that two databases \(X,X^{\prime}\in\mathcal{X}\) are neighboring if they differ in a single data point. More generally, we can consider a symmetric neighbor relation \(\mathcal{N}\subseteq\mathcal{X}^{2}\), and regard \(X,X^{\prime}\) as neighbors if \((X,X^{\prime})\in\mathcal{N}\).

On the other hand, in the local model, each individual (or client) randomizes their data before sending it to the server, meaning that individuals are not required to trust the server. A local DP mechanism [53] is a local randomizer \(\mathcal{A}\) that maps the local data \(X\in\mathcal{X}\) to the output \(Z=\mathcal{A}(X)\in\mathcal{Z}\). Note that here \(X\) is the data at one user, unlike central-DP where \(X\) is the database with the data of all users. We now review the notion of \((\varepsilon,\delta)\)-central and local DP.

**Definition 3.1** (Differential privacy [28, 53]).: Given a mechanism \(\mathcal{A}\) which induces the conditional distribution \(P_{Z|X}\) of \(Z=\mathcal{A}(X)\), we say that it satisfies \((\varepsilon,\delta)\)-DP if for any neighboring \((x,x^{\prime})\in\mathcal{N}\) and \(\mathcal{S}\subseteq\mathcal{Z}\), it holds that

\[\Pr(Z\in\mathcal{S}\,|\,X=x)\leq e^{\varepsilon}\Pr(Z\in\mathcal{S}\,|\,X=x^{ \prime})+\delta.\]

In particular, if \(\mathcal{N}=\mathcal{X}^{2}\), we say that the mechanism satisfies \((\varepsilon,\delta)\)-local DP [53].3

Footnote 3: Equivalently, local DP can be viewed as a special case of central DP with dataset size \(n=1\).

When a mechanism satisfies \((\varepsilon,0)\)-central/local DP, we will refer to it simply as \(\varepsilon\)-central/local DP. \(\varepsilon\)-DP can be generalized to _metric privacy_ by considering a metric \(d_{\mathcal{X}}(x,x^{\prime})\) over \(\mathcal{X}\)[16, 3].

**Definition 3.2** (\(\varepsilon\cdot d_{\mathcal{X}}\)-privacy [16, 3]).: Given a mechanism \(\mathcal{A}\) with conditional distribution \(P_{Z|X}\), and a metric \(d_{\mathcal{X}}\) over \(\mathcal{X}\), we say that \(\mathcal{A}\) satisfies \(\varepsilon\cdot d_{\mathcal{X}}\)-privacy if for any \(x,x^{\prime}\in\mathcal{X}\), \(\mathcal{S}\subseteq\mathcal{Z}\), we have

\[\Pr(Z\in\mathcal{S}\,|\,X=x)\leq e^{\varepsilon\cdot d_{\mathcal{X}}(x,x^{ \prime})}\Pr(Z\in\mathcal{S}\,|\,X=x^{\prime}).\]

This recovers the original \(\varepsilon\)-central DP by considering \(d_{\mathcal{X}}\) to be the Hamming distance among databases, and recovers the original \(\varepsilon\)-local DP by considering \(d_{\mathcal{X}}\) to be the discrete metric [16].

The reason we use \(X\) to refer to both the database in central DP and the user's data in local DP is that our proposed method can compress both central and local DP mechanisms in exactly the same manner. In the following sections, the mechanism \(\mathcal{A}\) to be compressed (often written as a conditional distribution \(P_{Z|X}\)) can be either a central or local DP mechanism, and the neighbor relation \(\mathcal{N}\) can be any symmetric relation. The "encoder" refers to the server in central DP, or the user in local DP. The "decoder" refers to the data analyst in central DP, or the server in local DP.

## 4 Poisson Private Representation

**Definition 4.1** (Poisson functional representation [61, 60]).: Let \((T_{i})_{i}\) be a Poisson process with rate \(1\) (i.e., \(T_{1},T_{2}-T_{1},T_{3}-T_{2},\ldots\stackrel{{ iid}}{{\sim}} \mathrm{Exp}(1)\)), independent of \(Z_{i}\stackrel{{ iid}}{{\sim}}Q\) for \(i=1,2,\ldots\). Then \((Z_{i},T_{i})_{i}\) is a Poisson process with intensity measure \(Q\times\lambda_{[0,\infty)}\)[57], where \(\lambda_{[0,\infty)}\) is the Lebesgue measure over \([0,\infty)\). Fix any distribution \(P\) over \(\mathcal{Z}\) that is absolutely continuous with respect to \(Q\). Let

\[\tilde{T}_{i}:=T_{i}\cdot\Big{(}\frac{\mathrm{d}P}{\mathrm{d}Q}(Z_{i})\Big{)} ^{-1}. \tag{1}\]

Then \((Z_{i},\tilde{T}_{i})\) is a Poisson process with intensity measure \(P\times\lambda_{[0,\infty)}\), which is from the mapping theorem [57]. The _Poisson functional representation_ (PFR) [61, 60] selects the point \(Z=Z_{K}\) with the smallest associated \(\tilde{T}_{K}\), i.e., let \(K:=\mathrm{argmin}_{i}\tilde{T}_{i}\) and \(Z:=Z_{K}\).4

Footnote 4: Since the \(T_{i}\)’s are continuous, with probability \(1\), there do not exist two equal values among \(\tilde{T}_{i}\)’s.

The PFR selects a sample following the target distribution \(P\) using another distribution \(Q\). It draws a random sequence \((Z_{i})_{i}\) from \(Q\) and a sequence of times \((T_{i})_{i}\) according to a Poisson process. If we select the sample \(Z_{i}\) with the smallest \(T_{i}\), then the selected sample follows \(Q\). To obtain a sample from \(P\) instead, we multiply the time by the factor \((\frac{\mathrm{d}P}{\mathrm{d}Q}(Z_{i}))^{-1}\) in (1) to give \(\tilde{T}_{i}\), so the \(Z_{i}\) with the smallest \(\tilde{T}_{i}\) will follow \(P\).

The Poisson functional representation guarantees that \(Z\sim P\)[61]. To simulate a DP mechanism with a conditional distribution \(P_{Z|X}\) using the Poisson functional representation, we can use \((Z_{i})_{i}\) as the shared randomness between the encoder and the decoder. 5 Upon observing \(X\), the encoder generates the Poisson process \((T_{i})_{i}\), computes \(\tilde{T}_{i}\) and \(K\) using \(P=P_{Z|X}\), and transmits \(K\) to the decoder. The decoder simply outputs \(Z_{K}\), which follows the conditional distribution \(P_{Z|X}\). The issue is that \(K\) is a function of \(X\) and the shared randomness \((Z_{i},T_{i})_{i}\), and a change of \(X\) may affect \(K\) in a deterministic manner, and hence this method cannot be directly used to protect the privacy of \(X\).

Footnote 5: The original Poisson functional representation [61, 60] uses the whole \((Z_{i},T_{i})_{i}\) as the shared randomness. It is clear that \((T_{i})_{i}\) is not needed by the decoder, and hence we can use only \((Z_{i})_{i}\) as the shared randomness.

**Poisson private representation.** To ensure privacy, we introduce randomness in the encoder by a generalization of the Poisson functional representation, which we call _Poisson private representation (PPR)_ with parameter \(\alpha\in(1,\infty]\), proposal distribution \(Q\) and the simulated mechanism \(P_{Z|X}\). Both \(X\) and \(Z\) can be discrete or continuous, though as a regularity condition, we require \(P_{Z|X}(\cdot|X)\) to be absolutely continuous with respect to \(Q\) almost surely. The PPR-compressed mechanism is given as:

1. We use \((Z_{i})_{i=1,2,\ldots}\), \(Z_{i}\stackrel{{ iid}}{{\sim}}Q\) as the shared randomness between the encoder and the decoder. Practically, the encoder and the decoder can share a random seed and generate \(Z_{i}\stackrel{{ iid}}{{\sim}}Q\) from it using a pseudorandom number generator.6 Footnote 6: We note that our analyses assume that the adversary knows both the index \(K\) and the shared randomness \((Z_{i})_{i}\), and we prove that the mechanism is still private despite the shared randomness between the encoder and the decoder, since the privacy is provided by locally randomizing \(K\) in Step 2c.
2. The encoder knows \((Z_{i})_{i},X,P_{Z|X}\) and performs the following steps: 1. Generates the Poisson process \((T_{i})_{i}\) with rate \(1\). 2. Computes \(\tilde{T}_{i}:=T_{i}\cdot(\frac{\mathrm{d}P}{\mathrm{d}Q}(Z_{i}))^{-1}\), where \(P:=P_{Z|X}(\cdot|X)\). Take \(\tilde{T}_{i}=\infty\) if \(\frac{\mathrm{d}P}{\mathrm{d}Q}(Z_{i})=0\). 3. Generates \(K\in\mathbb{Z}_{+}\) using local randomness with \[\Pr(K=k)=\frac{\tilde{T}_{k}^{-\alpha}}{\sum_{i=1}^{\infty}\tilde{T}_{i}^{- \alpha}}.\] 4. Compress \(K\) (e.g., using Elias delta coding [29]) and sends \(K\). 3. The decoder, which knows \((Z_{i})_{i},K\), outputs \(Z=Z_{K}\).

Note that when \(\alpha=\infty\), we have \(K=\mathrm{argmin}_{i}\tilde{T}_{i}\), and PPR reduces to the original Poisson functional representation [61, 60]. PPR can simulate the privacy mechanism \(P_{Z|X}\) precisely, as shown in the following proposition. The proof is in Appendix A.

**Proposition 4.2**.: _The output \(Z\) of PPR follows the conditional distribution \(P_{Z|X}\) exactly._

Due to the _exactness_ of PPR, it guarantees unbiasedness for tasks such as DME. If the goal is only to design a stand-alone privacy mechanism, we can focus on the privacy and utility of the mechanism without studying the output distribution. However, if the output of the mechanism is used for downstream tasks (e.g., for DME, after receiving information from clients, the server sends information about the aggregated mean to data analysts, where central DP is crucial), having an exact characterization of the conditional distribution of the output given the input allows us to obtain precise (central) privacy and utility guarantees.

Notably, PPR is _universal_ in the sense that only the encoder needs to know the simulated mechanism \(P_{Z|X}\). The decoder can decode the index \(K\) as long as it has access to the shared randomness \((Z_{i})_{i}\). This allows the encoder to choose an arbitrary mechanism \(P_{Z|X}\) with the same \(\mathcal{Z}\), and adapt the choice of \(P_{Z|X}\) to the communication and privacy constraints without explicitly informing the decoder which mechanism is chosen.

Practically, the algorithm cannot compute the whole infinite sequence \((\tilde{T}_{i})_{i}\). We can truncate the method and only compute \(\tilde{T}_{i},\ldots,\tilde{T}_{N}\) for a large \(N\) and select \(K\in\{1,\ldots,N\}\), which incurs a small distortion in the distribution of \(Z\).7 While this method is practically acceptable, it might defeat the purpose of having an exact algorithm that ensures the correct conditional distribution \(P_{Z|X}\). In Appendix B, we will present an exact algorithm for PPR that terminates in a finite amount of time, using a reparametrization that allows the encoder to know when the optimal point \(Z_{i}\) has already been encountered (see Algorithm 1 in Appendix B).

Footnote 7: The algorithm is called _hardware_, and it is called _hardware_.

By the lower bound for channel simulation [6, 61], we must have \(H(K)\geq I(X;Z)\), i.e., the compression size is at least the mutual information between the data \(X\) and the output \(Z\). The following result shows that the compression provided by PPR is "almost optimal", i.e., close to the theoretical lower bound \(I(X;Z)\). The proof is given in Appendix F.

**Theorem 4.3** (Compression size of PPR).: _For PPR with parameter \(\alpha>1\), when the encoder is given the input \(x\), the message \(K\) given by PPR satisfies_

\[\mathbb{E}[\log K]\leq D(P\|Q)+(\log(3.56))/\min\{(\alpha-1)/2,1\},\]

_where \(P:=P_{Z|X}(\cdot|x)\). As a result, when the input \(X\sim P_{X}\) is random, taking \(Q=P_{Z}\), we have_

\[\mathbb{E}[\log K]\leq I(X;Z)+(\log(3.56))/\min\{(\alpha-1)/2,1\}.\]

Note the running time complexity (which depends on the number of samples \(Z_{i}\) the algorithm must examine before outputting the index \(K\)) can be quite high. Since \(\mathbb{E}[\log K]\approx I(X;Z)\), \(K\) (and hence the running time) is at least exponential in \(I(X;Z)\). See more discussions in Section 8.

If a prefix-free encoding of \(K\) is required, then the number of bits needed is slightly larger than \(\log_{2}K\). For example, if Elias delta code [29] is used, the expected compression size is \(\leq\mathbb{E}[\log_{2}K]+2\log_{2}(\mathbb{E}[\log_{2}K]+1)+1\) bits. If the Shannon code [73] (an almost-optimal prefix-free code) for the Zipf distribution \(p(k)\propto k^{-\lambda}\) with \(\lambda=1+1/\mathbb{E}[\log_{2}K]\) is used, the expected compression size is \(\leq\mathbb{E}[\log_{2}K]+\log_{2}(\mathbb{E}[\log_{2}K]+1)+2\) bits (see [61]). Both codes yield an \(I(X;Z)+O(\log I(X;Z))\) size, within a logarithmic gap from the lower bound \(I(X;Z)\). This is similar to some other channel simulation schemes such as [45, 10, 61], though these schemes do not provide privacy guarantees.

Note that if \(P_{Z|X}\) is \(\varepsilon\)-DP, then by definition, for any \(z\in\mathcal{Z}\) and \(x,x_{0}\in\mathcal{X}\), it holds that

\[D\left(P_{Z|X=x}\big{\|}P_{Z|X=x_{0}}\right)=\mathbb{E}_{Z\sim P_{Z|X=x}}\left[ \log\left(\frac{\mathrm{d}P_{Z|X=x}}{\mathrm{d}P_{Z|X=x_{0}}}(Z)\right)\right] \leq\varepsilon\log e.\]

Setting the proposal distribution \(Q=P_{Z|X=x_{0}}\) for an arbitrary \(x_{0}\in\mathcal{X}\) gives the following bound.

**Corollary 4.4** (Compression size under \(\varepsilon\)-LDP).: _Let \(P_{Z|X}\) satisfy \(\varepsilon\)-differential privacy. Let \(x_{0}\in\mathcal{X}\) and \(Q=P_{Z|X=x_{0}}\). Then for PPR with parameter \(\alpha>1\), the expected compression size is at most \(\ell+\log_{2}(\ell+1)+2\) bits, where \(\ell:=\varepsilon\log_{2}e+(\log_{2}(3.56))/\min\left\{(\alpha-1)/2,1\right\}\)._

Next, we analyze the privacy guarantee of PPR. The PPR method induces a conditional distribution \(P_{(Z_{i})_{i},K|X}\) of the knowledge of the decoder \(((Z_{i})_{i},K)\), given the data \(X\). To analyze the privacy guarantee, we study whether the randomized mapping \(P_{(Z_{i})_{i},K|X}\) from \(X\) to \(((Z_{i})_{i},K)\) satisfies \(\varepsilon\)-DP or \((\varepsilon,\delta)\)-DP. 8 This is similar to the privacy condition in [71], and is referred as _decoder privacy_ in [72], which is stronger than _database privacy_ which concerns the privacy of the randomized mapping from \(X\) to the final output \(Z\)[72] (which is simply the privacy of the original mechanism \(P_{Z|X}\) to be compressed since PPR simulates \(P_{Z|X}\) precisely). Since the decoder knows \(((Z_{i})_{i},K)\), more than just the final output \(Z\), we expect that the PPR-compressed mechanism \(P_{(Z_{i})_{i},K|X}\) to have a worse privacy guarantee than the original mechanism \(P_{Z|X}\), which is the price of having a smaller communication cost. The following result shows that, if the original mechanism \(P_{Z|X}\) is \(\varepsilon\)-DP, then the PPR-compressed mechanism is guaranteed to be \(2\alpha\varepsilon\)-DP.

Footnote 8: Note that the encoder does not actually send \(((Z_{i})_{i},K)\); it only sends \(K\). The common randomness \((Z_{i})_{i}\) is independent of the data \(X\), and can be pre-generated using a common random seed in practice. While this seed must be communicated between the client and the server as a small overhead, the client and the server only ever need to communicate _one_ seed to initialize a pseudorandom number generator, that can be used in _all_ subsequent privacy mechanisms and communication tasks (to transmit high-dimensional data or use DP mechanisms for many times). The conditional distribution \(P_{(Z_{i})_{i},K|X}\) is only relevant for privacy analysis.

**Theorem 4.5** (\(\varepsilon\)-DP of PPR).: _If the mechanism \(P_{Z|X}\) is \(\varepsilon\)-differentially private, then PPR \(P_{(Z_{i})_{i},K|X}\) with parameter \(\alpha>1\) is \(2\alpha\varepsilon\)-differentially private._

Similar results also apply to \((\varepsilon,\delta)\)-DP and metric DP.

**Theorem 4.6** (\((\varepsilon,\delta)\)-DP of PPR).: _If the mechanism \(P_{Z|X}\) is \((\varepsilon,\delta)\)-differentially private, then PPR \(P_{(Z_{i})_{i},K|X}\) with parameter \(\alpha>1\) is \((2\alpha\varepsilon,2\delta)\)-differentially private._

**Theorem 4.7** (Metric privacy of PPR).: _If the mechanism \(P_{Z|X}\) satisfies \(\varepsilon\cdot d_{\mathcal{X}}\)-privacy, then PPR \(P_{(Z_{i})_{i},K|X}\) with parameter \(\alpha>1\) satisfies \(2\alpha\varepsilon\cdot d_{\mathcal{X}}\)-privacy._

Refer to Appendices C and D for the proofs. In Theorem 4.5 and Theorem 4.6, PPR imposes a multiplicative penalty \(2\alpha\) on the privacy parameter \(\varepsilon\). This penalty can be made arbitrarily close to \(2\) by taking \(\alpha\) close to \(1\), which increases the communication cost (see Theorem 4.3). Compared to minimal random coding which has a factor \(2\) penalty in the DP guarantee [47; 71], the \(2\alpha\) factor in PPR is slightly larger, though PPR ensures exact simulation (unlike [47; 71] which are approximate). The method in [31] does not have a penalty on \(\varepsilon\), but the utility and compression size depends on computational hardness assumptions on the pseudorandom number generator, and there is no guarantee that the compression size is close to the optimum. In comparison, the compression and privacy guarantees of PPR are _unconditional_ and does not rely on computational assumptions.

In order to make the penalty of PPR close to \(1\), we have to consider \((\varepsilon,\delta)\)-differential privacy, and allow a small failure probability, i.e., a small increase in \(\delta\). The following result shows that PPR can compress any \(\varepsilon\)-DP mechanism into a \((\approx\varepsilon,\approx 0)\)-DP mechanism as long as \(\alpha\) is close enough to \(1\) (i.e., almost no inflation). More generally, PPR can compress an \((\varepsilon,\delta)\)-DP mechanism into an \((\approx\varepsilon,\approx 2\delta)\)-DP mechanism for \(\alpha\) close to \(1\). The proof is in Appendix E.

**Theorem 4.8** (Tighter \((\varepsilon,\delta)\)-DP of PPR).: _If the mechanism \(P_{Z|X}\) is \((\varepsilon,\delta)\)-differentially private, then PPR \(P_{(Z_{i})_{i},K|X}\) with parameter \(\alpha>1\) is \((\alpha\varepsilon+\tilde{\varepsilon},\,2(\delta+\tilde{\delta}))\)-differentially private, for every \(\tilde{\varepsilon}\in(0,1]\) and \(\tilde{\delta}\in(0,1/3]\) that satisfy \(\alpha\leq e^{-4.2}\tilde{\delta}\tilde{\varepsilon}^{2}/(-\ln\tilde{\delta})+1\)._

## 5 Applications to Distributed Mean Estimation

We demonstrate the efficacy of PPR by applying it to distributed mean estimation (DME) [75]. Note that private DME is the core sub-routine in various private and federated optimization algorithms, such as DP-SGD [1] or DP-FedAvg [67].

Consider the following general distributed setting: each of \(n\) clients holds a local data point \(X_{i}\in\mathcal{X}\), and a central server aims to estimate a function of all local data \(\mu\left(X^{n}\right)\), subject to privacy and local communication constraints. To this end, each client \(i\) compresses \(X_{i}\) into a message \(Z_{i}\in\mathcal{Z}_{n}\) via a local encoder, and we require that each \(Z_{i}\) can be encoded into a bit string with an expected length of at most \(b\) bits. Upon receiving \(Z^{n}:=(Z_{1},\ldots,Z_{n})\), the central server decodes it and outputs a DP estimate \(\hat{\mu}\). Two DP criteria can be considered: the \((\varepsilon,\delta)\)-central DP of the randomized mapping from \(X^{n}\) to \(\hat{\mu}\), and the \((\varepsilon,\delta)\)-local DP of the randomized mapping from \(X_{i}\) to \(Z_{i}\) for each client \(i\).

In the distributed \(L_{2}\) mean estimation problem, \(\mathcal{X}=\mathcal{B}_{d}(C):=\left\{v\in\mathbb{R}^{d}\,\big{|}\,\big{\|}v \big{\|}_{2}\leq C\right\}\), and the central server aims to estimate the sample mean \(\mu(X^{n}):=\frac{1}{n}\sum_{i=1}^{n}X_{i}\) by minimizing the mean squared error (MSE) \(\mathbb{E}[\|\mu-\hat{\mu}\|_{2}^{2}]\). It is recently proved that under \(\varepsilon\)-local DP, privUnit [8; 4] is the optimal mechanism. By simulating privUnit with PPR and applying Corollary 4.4 and Theorem 4.6, we immediately obtain the following corollary:

**Corollary 5.1** (PPR simulating privUnit).: _Let \(P\) be the density defined by \(\varepsilon\)-privUnit\({}_{2}\) Bihownick et al. [8; Algorithm 1]. Let \(Q\) be the uniform density over the sphere \(\mathbb{S}^{d-1}\left(1/m\right)\) where the radius \(1/m\) is defined in Bhowmick et al. [8; (15)]. Let \(r^{*}:=e^{\varepsilon}\). Then the outcome of PPR (see Algorithm 1) satisfies (1) \(2\alpha\varepsilon\)-local DP; and (2) \((\alpha\varepsilon+\tilde{\varepsilon},2\tilde{\delta})\)-DP for any \(\alpha\leq e^{-4.2}\tilde{\delta}\tilde{\varepsilon}^{2}/\log(1/\tilde{ \delta})+1\). In addition, the average compression size is at most \(\ell+\log_{2}(\ell+1)+2\) bits where \(\ell:=\varepsilon+(\log_{2}\left(3.56\right))/\min\{(\alpha-1)/2,1\}\). Moreover, PPR achieves the same MSE as \(\varepsilon\)-privUnit\({}_{2}\), which is \(O\left(d/\min\left(\varepsilon,\varepsilon^{2}\right)\right)\)._

Note that PPR can simulate arbitrary local DP mechanisms. However, we present only the result of privUnit\({}_{2}\) because it achieves the optimal privacy-accuracy trade-off. Besides simulating local DP mechanisms, PPR can also compress central DP mechanisms while still preserving some (albeit weaker) local guarantees. We give a corollary of Theorems 4.3 and 4.6. The proof is in Appendix H.

**Corollary 5.2** (PPR-compressed Gaussian mechanism).: _Let \(\varepsilon,\delta\in(0,1)\). Consider the Gaussian mechanism \(P_{Z|X}(\cdot|x)=\mathcal{N}(x,\frac{\sigma^{2}}{n}\mathbb{I}_{d})\), and the proposal distribution \(Q=\mathcal{N}(0,(\frac{C^{2}}{d}+\frac{\sigma^{2}}{n})\mathbb{I}_{d})\), where \(\sigma\geq\frac{C\sqrt{2\ln(1.25/\delta)}}{\varepsilon}\). For each client \(i\), let \(Z_{i}\) be the output of PPR applied on \(P_{Z|X}(\cdot|X_{i})\). We have:_

* \(\hat{\mu}(Z^{n}):=\frac{1}{n}\sum_{i}Z_{i}\) _yields an unbiased estimator of_ \(\mu(X^{n})=\frac{1}{n}\sum_{i=1}^{n}X_{i}\) _satisfying_ \((\varepsilon,\delta)\)_-central DP and has MSE_ \(\mathbb{E}[\|\mu-\hat{\mu}\|_{2}^{2}]=\sigma^{2}d/n^{2}\)_._
* _As long as_ \(\varepsilon<1/\sqrt{n}\)_, PPR satisfies_ \((2\alpha\sqrt{n}\varepsilon,2\delta)\)_-local DP__._9__ Footnote 9: The restricted range on \(\varepsilon<1/\sqrt{n}\) is due to the simpler privacy accountant [25]. By using the Rényi DP accountant instead, one can achieve a tighter result that applies to any \(n\). We present the Rényi DP version of the corollary in Appendix G. Moreover, in the context of federated learning, \(n\) refers to the number of clients in _each round_, which is typically much smaller than the total number of clients. For example, as observed in [52], the per-round cohort size in Google’s FL application typically ranges from \(10^{3}\) to \(10^{5}\), significantly smaller than the number of trainable parameters \(d\in[10^{6},10^{9}]\) or the number of available users \(N\in[10^{6},10^{8}]\).
* _The average per-client communication cost is at most_ \(\ell+\log_{2}(\ell+1)+2\) _bits where_ \[\ell:=\frac{d}{2}\log_{2}\Big{(}\frac{C^{2}n}{d\sigma^{2}}+1\Big{)}+\eta_{ \alpha}\ \leq\ \frac{d}{2}\log_{2}\Big{(}\frac{n\varepsilon^{2}}{2d\ln(1.25/ \delta)}+1\Big{)}+\eta_{\alpha},\] _where_ \(\eta_{\alpha}:=(\log_{2}(3.56))/\min\{(\alpha-1)/2,\,1\}\)_._

A few remarks are in order. First, notice that when \(\alpha\) is fixed, for an \(O(\frac{C^{2}d}{n^{2}\varepsilon^{2}}\log(1/\delta))\) MSE, the per-client communication cost is

\[O\Big{(}d\log\Big{(}\frac{n\varepsilon^{2}}{d\log(1/\delta)}+1\Big{)}+1\Big{)},\]

which is at least as good as the \(O(n\varepsilon^{2}/\log(1/\delta)+1)\) bound in [75; 19], and can be better than \(O(n\varepsilon^{2}/\log(1/\delta)+1)\) when \(n\gg d\). Hence, the PPR-compressed Gaussian mechanism is order-wise optimal. Second, compared to other works that also compress the Gaussian mechanism, PPR is the only lossless compressor; schemes based on random sparsification, projection, or minimum random coding (e.g., Triastcyn et al. [78], Chen et al. [19]) are _lossy_, i.e., they introduce additional distortion on top of the DP noise. Finally, other DP mechanism compressors tailored to local randomizers [31; 71] do not provide the same level of central DP guarantees when applied to local Gaussian noise since the reconstructed noise is no longer Gaussian. Refer to Section 7 for experiments.

## 6 Applications to Metric Privacy

Metric privacy [16; 3] (see Definition 3.2) allows users to send privatized version \(Z\in\mathbb{R}^{d}\) of their data vectors \(X\in\mathbb{R}^{d}\) to an untrusted server, so that the server can know \(X\) approximately but not exactly. A popular mechanism is the _Laplace mechanism_[16; 3; 33; 34], where a \(d\)-dimensional Laplace noise is added to \(X\). The conditional density function of \(Z\) given \(X\) is \(f_{Z|X}(z|x)\propto e^{-\varepsilon d_{X}(x,z)}\), where \(\varepsilon\) is the privacy parameter, and the metric \(d_{X}(x,z)=\|x-z\|_{2}\) is the Euclidean distance. The Laplace mechanism achieves \(\varepsilon\cdot d_{\mathcal{X}}\)-privacy, and has been used, for example, in geo-indistinguishability to privatize the users' locations [3], and to privatize high-dimensional word embedding vectors [33; 34].

A problem is that the real vector \(Z\) cannot be encoded into finitely many bits. To this end, [3] studies a _discrete Laplace mechanism_ where each coordinate of \(Z\) is quantized to a finite number of levels, introducing additional distortion to \(Z\). PPR provides an alternative compression method that preserves the statistical behavior of \(Z\) (e.g., unbiasedness) exactly. We give a corollary of Theorems 4.3 and 4.7. The proof is in Appendix I. Refer to Appendix J for an experiment on metric privacy.

**Corollary 6.1** (PPR-compressed Laplace mechanism).: _Consider PPR applied to the Laplace mechanism \(P_{Z|X}\) where \(X\in\mathcal{B}_{d}(C)=\{x\in\mathbb{R}^{d}\,|\,\|x\|_{2}\leq C\}\), with a proposal distribution \(Q=\mathcal{N}(0,(\frac{C^{2}}{d}+\frac{d+1}{\varepsilon^{2}})\mathbb{I}_{d})\). It achieves an MSE \(\frac{d(d+1)}{\varepsilon^{2}}\), a \(2\alpha\epsilon\cdot d_{\mathcal{X}}\)-privacy, and a compression size at most \(\ell+\log_{2}(\ell+1)+2\) bits, where_

\[\ell:=\frac{d}{2}\log_{2}\Big{(}\frac{2}{e}\left(\frac{C^{2}\varepsilon^{2}}{d }+d+1\right)\Big{)}-\log_{2}\frac{\Gamma(d+1)}{\Gamma(\frac{d}{2}+1)}+\eta_{ \alpha},\]

_where \(\eta_{\alpha}:=(\log_{2}(3.56))/\min\{(\alpha-1)/2,\,1\}\)._Empirical Results

We empirically evaluate our scheme on the DME problem (which is formally introduced in Section 5), examine the privacy-accuracy-communication trade-off, and compare it with the Coordinate Subsampled Gaussian Mechanism (CSGM) [19, Algorithm 1], an order-optimal scheme for DME under central DP. In Chen et al. [19], each client only communicates partial information (via sampling a subset of the coordinates of the data vector) about its samples to amplify the privacy, and the compression is mainly from subsampling. Moreover, CSGM only guarantees central DP.

We use the same setup that has been used in [19]: consider \(n=500\) clients, and the dimension of local vectors is \(d=1000\), each of which is generated according to \(X_{i}(j)\stackrel{{\mathrm{i.i.d.}}}{{\sim}}(2\cdot\mathrm{Ber}(0.8)-1)\), where \(\mathrm{Ber}(0.8)\) is a Bernoulli random variable with parameter \(p=0.8\). We require \((\varepsilon,\delta)\)-central DP with \(\delta=10^{-6}\) and \(\varepsilon\in[0.05,6]\) and apply the PPR with \(\alpha=2\) to simulate the Gaussian mechanism, where the privacy budgets are accounted via Renyi DP.

We compare the MSE of PPR (\(\alpha=2\), using Theorem 4.3) and CSGM under various compression sizes in Figure 1 (the \(y\)-axis is in logarithmic scale).10 Note that the MSE of the (uncompressed) Gaussian mechanism coincides with the CSGM with \(1000\) bits, and the PPR with only \(400\) bits. We see that PPR consistently achieves a smaller MSE compared to CSGM for all \(\varepsilon\)'s and compression sizes considered. For \(\epsilon=1\) and we compress \(d=1000\) to \(50\) bits, CSGM has an MSE \(0.1231\), while PPR has an MSE \(0.08173\), giving a \(33.61\%\) reduction. For \(\epsilon=0.5\) and we compress \(d=1000\) to \(25\) bits (the case of high compression and conservative privacy), CSGM has an MSE \(0.3877\), while PPR has an MSE \(0.3011\), giving a \(22.33\%\) reduction. These reductions are significant, since all considered mechanisms are asymptotically close to optimal and a large improvement compared to an (almost optimal) mechanism is unexpected. See Section L for more about MSE against the compression sizes.

Footnote 10: Source code: [https://github.com/cheuttingli/PoissonPrivateRepr](https://github.com/cheuttingli/PoissonPrivateRepr). Experiments were executed on M1 Pro Macbook, 8-core CPU (\(\approx 3.2\) GHz) with 16GB memory. For PPR under a privacy budget \(\varepsilon\) and communication budget \(b\), we find the largest \(\varepsilon^{\prime}\leq\varepsilon\) such that the communication cost bound in Theorem 4.3 (with Shannon code [73]) for simulating the Gaussian mechanism with \((\varepsilon^{\prime},\delta)\)-central DP is at most \(b\), and use PPR to simulate this Gaussian mechanism. Thus, MSE of PPR in Figure 1 becomes flat for large \(\varepsilon\), as PPR falls back to using a smaller \(\varepsilon^{\prime}\) instead of \(\varepsilon\) due to the communication budget.

We also emphasize that PPR provides _both_ central and local DP guarantees according to Theorem 4.5, 4.6 and 4.8. In contrast, CSGM only provides central DP guarantees. Another advantage of PPR under conservative privacy (small \(\epsilon\)) is that the trade-off between \(\epsilon\) and MSE of PPR exactly coincides with the trade-off of the Gaussian mechanism for small \(\epsilon\) (see Figure 1), and CSGM is only close to (but strictly worse than) the Gaussian mechanism. This means that for small \(\epsilon\), PPR provides compression without any drawback in terms of \(\epsilon\)-MSE trade-off compared to the Gaussian mechanism (which requires an infinite size communication to exactly realize).

Moreover, although directly applying PPR on the \(d\)-dimensional vectors is impractical for a large \(d\), one can ensure an efficient \(O(d)\) running time (see Section 8 for details) by breaking the vector with \(d=1000\) dimensions into small chunks of fixed lengths (we use \(d_{\mathrm{chunk}}=50\) dimensions for each chunk), and apply the PPR to each chunk. We call it the _sliced PPR_ in Figure 1. Though the sliced PPR has a small penalty on the MSE (as shown in Figure 1), it still outperforms the CSGM (\(400\) bits) for the range of \(\varepsilon\) in the plot. For the sliced PPR for one \(d=1000\) vector, when \(\epsilon=0.05\), the running time is \(1.3348\) seconds on average.11 For larger \(\epsilon\)'s, we can choose smaller \(d_{\mathrm{chunk}}\)'s to have reasonable running time: For \(\epsilon=6\) and \(d_{\mathrm{chunk}}=2\) we have an average running time \(0.0127\) seconds and with \(d_{\mathrm{chunk}}=4\) we have an average running time \(0.6343\) seconds; for \(\epsilon=10\) and \(d_{\mathrm{chunk}}=2\) we have an average running time \(0.0128\) seconds and with \(d_{\mathrm{chunk}}=4\) we have an average running time \(0.7301\) seconds. See Appendix K for more experiments on the running time of the sliced PPR.

Footnote 11: The running time is calculated by \(\frac{1000}{500}\times T_{\mathrm{chunk}}\), where each chunk’s running time \(T_{\mathrm{chunk}}\) is averaged over \(1000\) trials. The estimate of the mean of \(T_{\mathrm{chunk}}\) is \(0.0667\), whereas the standard deviation is \(0.2038\).

## 8 Limitations

While PPR is communication-efficient, having only a logarithmic gap from the theoretical lower bound on the compression size as shown in Theorem 4.3, the running time complexity can be high. However, we note that an exponential complexity is also needed in sampling methods that do not ensure privacy, such as [65, 47]. It has been proved in [2] that no polynomial time general sampling based method exists (even without privacy constraint), if \(RP\neq NP\). All existing polynomial time exact channel simulation methods can only simulate specific noisy channels.12 Hence, a polynomial time algorithm for exactly compressing a general DP mechanism is likely nonexistent.

Footnote 12: For example, [36] and dithered-quantization-based schemes [48; 72] can only simulate additive noise mechanisms. Among these existing works, only [72] ensures local DP.

Nevertheless, this is not an obstacle for simulating local DP mechanisms, since the mutual information \(I(X;Z)\) for a reasonable local DP mechanism must be small, or else the leakage of the data \(X\) in \(Z\) would be too large. For an \(\varepsilon\)-local DP mechanism, we have \(I(X;Z)\leq\min\{\varepsilon,\varepsilon^{2}\}\) (in nats) [22]. Hence, the PPR algorithm can terminate quickly even if has a running time exponential in \(I(X;Z)\).

Another way to ensure a polynomial running time is to divide the data into small chunks and apply the mechanism to each chunk separately. For example, to apply the Gaussian mechanism to a high-dimensional vector, we break it into several shorter vectors and apply the mechanism to each vector. Experiments in Section 7 show that this greatly reduces the running time while having only a small penalty on the compression size. See Appendix K for experiments on the running time of PPR.

## 9 Conclusion

We proposed a novel scheme for compressing DP mechanisms, called Poisson private representation (PPR). Unlike previous schemes which are either constrained on special classes of DP mechanisms or introducing additional distortions on the output, our scheme can compress and exactly simulate arbitrary mechanisms while protecting differential privacy, with a compression size that is close to the theoretic lower bound. A future direction is to reduce the running time of PPR under certain restrictions on \(P_{Z|X}\). For example, the techniques in [38; 35] may be useful when \(P_{Z|X}\) is unimodal.

## Acknowledgment

YL was partially supported by the CUHK PhD International Mobility for Partnerships and Collaborations Award 2023-24. WC and AO were supported by the NSF grant CIF-2213223. CTL was partially supported by two grants from the Research Grants Council of the Hong Kong Special Administrative Region, China [Project No.s: CUHK 24205621 (ECS), CUHK 14209823 (GRF)].

Figure 1: MSE of distributed mean estimation for PPR and CSGM [19] for different \(\varepsilon\)’s.

## References

* [1] Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. Deep learning with differential privacy. In _Proceedings of the 2016 ACM SIGSAC conference on computer and communications security_, pages 308-318, 2016.
* [2] Eirikur Agustsson and Lucas Theis. Universally quantized neural compression. _Advances in neural information processing systems_, 33:12367-12376, 2020.
* [3] Miguel E Andres, Nicolas E Bordenabe, Konstantinos Chatzikokolakis, and Catuscia Palamidessi. Geo-indistinguishability: Differential privacy for location-based systems. In _Proceedings of the 2013 ACM SIGSAC conference on Computer & communications security_, pages 901-914, 2013.
* [4] Hilal Asi, Vitaly Feldman, and Kunal Talwar. Optimal algorithms for mean estimation under local differential privacy. In _International Conference on Machine Learning_, pages 1046-1056. PMLR, 2022.
* [5] Raef Bassily and Adam Smith. Local, private, efficient protocols for succinct histograms. In _Proceedings of the forty-seventh annual ACM symposium on Theory of computing_, pages 127-135, 2015.
* [6] Charles H Bennett, Peter W Shor, John Smolin, and Ashish V Thapliyal. Entanglement-assisted capacity of a quantum channel and the reverse Shannon theorem. _IEEE Trans. Inf. Theory_, 48(10):2637-2655, 2002.
* [7] Charles H Bennett, Igor Devetak, Aram W Harrow, Peter W Shor, and Andreas Winter. The quantum reverse shannon theorem and resource tradeoffs for simulating quantum channels. _IEEE Transactions on Information Theory_, 60(5):2926-2959, 2014.
* [8] Abhishek Bhowmick, John Duchi, Julien Freudiger, Gaurav Kapoor, and Ryan Rogers. Protection against reconstruction and its applications in private federated learning. _arXiv preprint arXiv:1812.00984_, 2018.
* [9] Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, et al. On the opportunities and risks of foundation models. _arXiv preprint arXiv:2108.07258_, 2021.
* [10] Mark Braverman and Ankit Garg. Public vs private coin in bounded-round information. In _International Colloquium on Automata, Languages, and Programming_, pages 502-513. Springer, 2014.
* [11] Mark Braverman, Ankit Garg, Tengyu Ma, Huy L Nguyen, and David P Woodruff. Communication lower bounds for statistical estimation problems via a distributed data processing inequality. In _Proceedings of the forty-eighth annual ACM symposium on Theory of Computing_, pages 1011-1020, 2016.
* [12] Mark Bun, Jelani Nelson, and Uri Stemmer. Heavy hitters and the structure of local privacy. In _Proceedings of the 37th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems_, SIGMOD/PODS '18, page 435-447, New York, NY, USA, 2018. Association for Computing Machinery.
* [13] Clement L Canonne, Gautam Kamath, and Thomas Steinke. The discrete Gaussian for differential privacy. _Advances in Neural Information Processing Systems_, 33:15676-15688, 2020.
* [14] Nicholas Carlini, Florian Tramer, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam Roberts, Tom Brown, Dawn Song, Ulfar Erlingsson, et al. Extracting training data from large language models. In _30th USENIX Security Symposium (USENIX Security 21)_, pages 2633-2650, 2021.
* [15] Nicolas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagielski, Vikash Sehwag, Florian Tramer, Borja Balle, Daphne Ippolito, and Eric Wallace. Extracting training data from diffusion models. In _32nd USENIX Security Symposium (USENIX Security 23)_, pages 5253-5270, 2023.
* [16] Konstantinos Chatzikokolakis, Miguel E Andres, Nicolas Emilio Bordenabe, and Catuscia Palamidessi. Broadening the scope of differential privacy using metrics. In _Privacy Enhancing Technologies: 13th International Symposium, PETS 2013, Bloomington, IN, USA, July 10-12, 2013. Proceedings 13_, pages 82-102. Springer, 2013.

* [17] Kamalika Chaudhuri, Chuan Guo, and Mike Rabbat. Privacy-aware compression for federated data analysis. In _Uncertainty in Artificial Intelligence_, pages 296-306. PMLR, 2022.
* [18] Wei-Ning Chen, Peter Kairouz, and Ayfer Ozgur. Breaking the communication-privacy-accuracy trilemma. _Advances in Neural Information Processing Systems_, 33:3312-3324, 2020.
* [19] Wei-Ning Chen, Dan Song, Ayfer Ozgur, and Peter Kairouz. Privacy amplification via compression: Achieving the optimal privacy-accuracy-communication trade-off in distributed mean estimation. _Advances in Neural Information Processing Systems_, 36, 2024.
* [20] Paul Cuff. Communication requirements for generating correlated random variables. In _2008 IEEE International Symposium on Information Theory_, pages 1393-1397. IEEE, 2008.
* [21] Paul Cuff. Distributed channel synthesis. _IEEE Trans. Inf. Theory_, 59(11):7071-7096, Nov 2013.
* [22] Paul Cuff and Lanqing Yu. Differential privacy as a mutual information constraint. In _Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security_, pages 43-54, 2016.
* [23] John Duchi and Ryan Rogers. Lower bounds for locally private estimation via communication complexity. In _Conference on Learning Theory_, pages 1161-1191. PMLR, 2019.
* [24] John C Duchi, Michael I Jordan, and Martin J Wainwright. Local privacy and statistical minimax rates. In _2013 IEEE 54th Annual Symposium on Foundations of Computer Science_, pages 429-438. IEEE, 2013.
* [25] Cynthia Dwork. Differential privacy. In _International colloquium on automata, languages, and programming_, pages 1-12. Springer, 2006.
* [26] Cynthia Dwork and Aaron Roth. The algorithmic foundations of differential privacy. _Foundations and Trends in Theoretical Computer Science_, 9(3-4):211-407, 2014.
* [27] Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya Mironov, and Moni Naor. Our data, ourselves: Privacy via distributed noise generation. In _Advances in Cryptology-EUROCRYPT 2006: 24th Annual International Conference on the Theory and Applications of Cryptographic Techniques, St. Petersburg, Russia, May 28-June 1, 2006. Proceedings 25_, pages 486-503. Springer, 2006.
* [28] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in private data analysis. In _Theory of cryptography conference_, pages 265-284. Springer, 2006.
* [29] Peter Elias. Universal codeword sets and representations of the integers. _IEEE transactions on information theory_, 21(2):194-203, 1975.
* [30] Ulfar Erlingsson, Vitaly Feldman, Ilya Mironov, Ananth Raghunathan, Kunal Talwar, and Abhradeep Thakurta. Amplification by shuffling: From local to central differential privacy via anonymity. In _Proceedings of the Thirtieth Annual ACM-SIAM Symposium on Discrete Algorithms_, pages 2468-2479. SIAM, 2019.
* [31] Vitaly Feldman and Kunal Talwar. Lossless compression of efficient private local randomizers. In _International Conference on Machine Learning_, pages 3208-3219. PMLR, 2021.
* [32] Vitaly Feldman, Audra McMillan, and Kunal Talwar. Hiding among the clones: A simple and nearly optimal analysis of privacy amplification by shuffling. In _2021 IEEE 62nd Annual Symposium on Foundations of Computer Science (FOCS)_, pages 954-964. IEEE, 2022.
* [33] Natasha Fernandes, Mark Dras, and Annabelle McIver. Generalised differential privacy for text document processing. In _Principles of Security and Trust: 8th International Conference, POST 2019_, pages 123-148. Springer International Publishing, 2019.
* [34] Oluwaseyi Feyisetan, Borja Balle, Thomas Drake, and Tom Diethe. Privacy-and utility-preserving textual analysis via calibrated multivariate perturbations. In _Proceedings of the 13th international conference on web search and data mining_, pages 178-186, 2020.
* [35] Gergely Flamich. Greedy poisson rejection sampling. _Advances in Neural Information Processing Systems_, 36, 2024.
* [36] Gergely Flamich and Lucas Theis. Adaptive greedy rejection sampling. In _2023 IEEE International Symposium on Information Theory (ISIT)_, pages 454-459. IEEE, 2023.

* [37] Gergely Flamich, Marton Havasi, and Jose Miguel Hernandez-Lobato. Compressing images by encoding their latent representations with relative entropy coding. _Advances in Neural Information Processing Systems_, 33:16131-16141, 2020.
* [38] Gergely Flamich, Stratis Markou, and Jose Miguel Hernandez-Lobato. Fast relative entropy coding with A* coding. In _International Conference on Machine Learning_, pages 6548-6577. PMLR, 2022.
* [39] Gergely Flamich, Stratis Markou, and Jose Miguel Hernandez Lobato. Faster relative entropy coding with greedy rejection coding. _arXiv preprint arXiv:2309.15746_, 2023.
* [40] Ankit Garg, Tengyu Ma, and Huy Nguyen. On communication cost of distributed statistical estimation and dimensionality. In _Advances in Neural Information Processing Systems_, pages 2726-2734, 2014.
* [41] Daniel Goc and Gergely Flamich. On channel simulation with causal rejection samplers. _arXiv preprint arXiv:2401.16579_, 2024.
* [42] Slawomir Goryczka and Li Xiong. A comprehensive comparison of multiparty secure additions with differential privacy. _IEEE transactions on dependable and secure computing_, 14(5):463-477, 2015.
* [43] Chuan Guo, Kamalika Chaudhuri, Pierre Stock, and Michael Rabbat. Privacy-aware compression for federated learning through numerical mechanism design. In _International Conference on Machine Learning_, pages 11888-11904. PMLR, 2023.
* [44] Yuanxin Guo, Sadaf Salehkalaibar, Stark C. Draper, and Wei Yu. One-shot achievability region for hypothesis testing with communication constraint. In _accepted at the IEEE Information Theory Workshop_. IEEE, 2024.
* [45] Prahladh Harsha, Rahul Jain, David McAllester, and Jaikumar Radhakrishnan. The communication complexity of correlation. _IEEE Trans. Inf. Theory_, 56(1):438-449, Jan 2010.
* [46] Burak Hasrucoglu and Deniz Gunduz. Communication efficient private federated learning using dithering. In _ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)_, pages 7575-7579. IEEE, 2024.
* [47] Marton Havasi, Robert Peharz, and Jose Miguel Hernandez-Lobato. Minimal random code learning: Getting bits back from compressed model parameters. In _7th International Conference on Learning Representations, ICLR 2019_, 2019.
* [48] Mahmoud Hegazy and Cheuk Ting Li. Randomized quantization with exact error distribution. In _2022 IEEE Information Theory Workshop (ITW)_, pages 350-355. IEEE, 2022.
* [49] Mahmoud Hegazy, Remi Leluc, Cheuk Ting Li, and Aymeric Dieuleveut. Compression with exact error distribution for federated learning. In _Proceedings of The 27th International Conference on Artificial Intelligence and Statistics_, volume 238 of _Proceedings of Machine Learning Research_, pages 613-621. PMLR, 02-04 May 2024.
* [50] Henri Hentila, Yanina Y Shkel, and Visa Koivunen. Communication-constrained secret key generation: Second-order bounds. _IEEE Transactions on Information Theory_, 2024.
* [51] Berivan Isik, Wei-Ning Chen, Ayfer Ozgur, Tsachy Weissman, and Albert No. Exact optimality of communication-privacy-utility tradeoffs in distributed mean estimation. _Advances in Neural Information Processing Systems_, 36, 2024.
* [52] Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurelien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al. Advances and open problems in federated learning. _Foundations and trends(r) in machine learning_, 14(1-2):1-210, 2021.
* [53] Shiva Prasad Kasiviswanathan, Homin K Lee, Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith. What can we learn privately? _SIAM Journal on Computing_, 40(3):793-826, 2011.
* [54] Ashish Khisti, Arash Behboodi, Gabriele Cesa, and Pratik Kumar. Unequal message protection: One-shot analysis via poisson matching lemma. In _2024 IEEE International Symposium on Information Theory (ISIT)_. IEEE, 2024.
* [55] Samuel Kotz, Tomasz Kozubowski, and Krzystof Podgorski. _The Laplace distribution and generalizations: a revisit with applications to communications, economics, engineering, and finance_. Springer Science & Business Media, 2012.

* [56] Natalie Lang, Elad Sofer, Tomer Shaked, and Nir Shlezinger. Joint privacy enhancement and quantization in federated learning. _IEEE Transactions on Signal Processing_, 71:295-310, 2023.
* [57] Gunter Last and Mathew Penrose. _Lectures on the Poisson process_, volume 7. Cambridge University Press, 2017.
* [58] Cheuk Ting Li. Pointwise redundancy in one-shot lossy compression via Poisson functional representation. _arXiv preprint_, 2024.
* [59] Cheuk Ting Li and Venkat Anantharam. Pairwise multi-marginal optimal transport and embedding for earth mover's distance. _arXiv preprint arXiv:1908.01388_, 2019.
* [60] Cheuk Ting Li and Venkat Anantharam. A unified framework for one-shot achievability via the Poisson matching lemma. _IEEE Transactions on Information Theory_, 67(5):2624-2651, 2021.
* [61] Cheuk Ting Li and Abbas El Gamal. Strong functional representation lemma and applications to coding theorems. _IEEE Transactions on Information Theory_, 64(11):6967-6978, Nov 2018.
* [62] Cheuk Ting Li, Xiugang Wu, Ayfer Ozgur, and Abbas El Gamal. Minimax learning for remote prediction. In _2018 IEEE ISIT_, pages 541-545, June 2018. doi: 10.1109/ISIT.2018.8437318.
* [63] Yanxiao Liu and Cheuk Ting Li. One-shot information hiding. In _accepted at the IEEE Information Theory Workshop_. IEEE, 2024.
* [64] Yanxiao Liu and Cheuk Ting Li. One-shot coding over general noisy networks. _arXiv preprint arXiv:2402.06021_, 2024.
* [65] Chris J Maddison. A Poisson process model for Monte Carlo. _Perturbation, Optimization, and Statistics_, pages 193-232, 2016.
* [66] Chris J Maddison, Daniel Tarlow, and Tom Minka. A* sampling. _Advances in neural information processing systems_, 27, 2014.
* [67] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-efficient learning of deep networks from decentralized data. In _Artificial intelligence and statistics_, pages 1273-1282. PMLR, 2017.
* [68] Ilya Mironov. Renyi differential privacy. In _2017 IEEE 30th computer security foundations symposium (CSF)_, pages 263-275. IEEE, 2017.
* [69] Buu Phan, Ashish Khisti, and Christos Louizos. Importance matching lemma for lossy compression with side information. In _International Conference on Artificial Intelligence and Statistics_, pages 1387-1395. PMLR, 2024.
* [70] John K Salmon, Mark A Moraes, Ron O Dror, and David E Shaw. Parallel random numbers: as easy as 1, 2, 3. In _Proceedings of 2011 international conference for high performance computing, networking, storage and analysis_, pages 1-12, 2011.
* [71] Abhin Shah, Wei-Ning Chen, Johannes Balle, Peter Kairouz, and Lucas Theis. Optimal compression of locally differentially private mechanisms. In _International Conference on Artificial Intelligence and Statistics_, pages 7680-7723. PMLR, 2022.
* [72] Ali Moradi Shahmiri, Chih Wei Ling, and Cheuk Ting Li. Communication-efficient laplace mechanism for differential privacy via random quantization. In _ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)_, pages 4550-4554. IEEE, 2024.
* [73] Claude E Shannon. A mathematical theory of communication. _Bell system technical journal_, 27(3):379-423, 1948.
* [74] Eva C Song, Paul Cuff, and H Vincent Poor. The likelihood encoder for lossy compression. _IEEE Trans. Inf. Theory_, 62(4):1836-1849, 2016.
* [75] Ananda Theertha Suresh, X Yu Felix, Sanjiv Kumar, and H Brendan McMahan. Distributed mean estimation with limited communication. In _International conference on machine learning_, pages 3329-3337. PMLR, 2017.
* [76] Lucas Theis and Noureldin Y Ahmed. Algorithms for the communication of samples. In _International Conference on Machine Learning_, pages 21308-21328. PMLR, 2022.
* [77] Lucas Theis, Tim Salimans, Matthew D Hoffman, and Fabian Mentzer. Lossy compression with Gaussian diffusion. _arXiv preprint arXiv:2206.08889_, 2022.

* [78] Aleksei Triastcyn, Matthias Reisser, and Christos Louizos. DP-REC: Private & communication-efficient federated learning. _arXiv preprint arXiv:2111.05454_, 2021.
* [79] Stanley L Warner. Randomized response: A survey technique for eliminating evasive answer bias. _Journal of the American Statistical Association_, 60(309):63-69, 1965.
* [80] Guangfeng Yan, Tan Li, Tian Lan, Kui Wu, and Linqi Song. Layered randomized quantization for communication-efficient and privacy-preserving distributed learning. _arXiv preprint arXiv:2312.07060_, 2023.
* [81] Jacob Ziv. On universal quantization. _IEEE Transactions on Information Theory_, 31(3):344-347, 1985.

Proof of Proposition 4.2

Write \((X_{i})_{i}\sim\mathrm{PP}(\mu)\) if the points \((X_{i})_{i}\) (as a multiset, ignoring the ordering) form a Poisson point process with intensity measure \(\mu\). Similarly, for \(f:[0,\infty)^{n}\to[0,\infty)\), we write \(\mathrm{PP}(f)\) for the Poisson point process with intensity function \(f\) (i.e., the intensity measure has a Radon-Nikodym derivative \(f\) against the Lebesgue measure).

Let \((T_{i})_{i}\sim\mathrm{PP}(1)\) be a Poisson process with rate \(1\), independent of \(Z_{1},Z_{2},\ldots\stackrel{{ iid}}{{\sim}}Q\). By the marking theorem [57], \((Z_{i},T_{i})_{i}\sim\mathrm{PP}(Q\times\lambda_{[0,\infty)})\), where \(Q\times\lambda_{[0,\infty)}\) is the product measure between \(Q\) and the Lebesgue measure over \([0,\infty)\). Let \(P=P_{Z|X}(\cdot|x)\), and \(\tilde{T}_{i}=T_{i}\cdot(\frac{\mathrm{d}P}{\mathrm{d}Q}(Z_{i}))^{-1}\). By the mapping theorem [57] (also see [61, 60]), \((Z_{i},\tilde{T}_{i})_{i}\sim\mathrm{PP}(P\times\lambda_{[0,\infty)})\). Note that the points \((Z_{i},\tilde{T}_{i})_{i}\) may not be sorted in ascending order of \(\tilde{T}_{i}\). Therefore, we will sort them as follows. Let \(j_{1}\) be the \(j\) such that \(\tilde{T}_{j}\) is the smallest, \(j_{2}\) be the \(j\) other than \(j_{1}\) such that \(\tilde{T}_{j}\) is the smallest, and so on. Break ties arbitrarily. Then \((\tilde{T}_{j_{i}})_{i}\) is an ascending sequence, and we still have \((Z_{j_{i}},\tilde{T}_{j_{i}})_{i}\sim\mathrm{PP}(P\times\lambda_{[0,\infty)})\) since we are merely rearranging the points. Comparing \((Z_{j_{i}},\tilde{T}_{j_{i}})_{i}\sim\mathrm{PP}(P\times\lambda_{[0,\infty)})\) with the definition of \((Z_{i},T_{i})_{i}\sim\mathrm{PP}(Q\times\lambda_{[0,\infty)})\), we can see that \((\tilde{T}_{j_{i}})_{i}\sim\mathrm{PP}(1)\) is independent of \(Z_{j_{1}},Z_{j_{2}},\ldots\stackrel{{ iid}}{{\sim}}P\). Recall that in PPR, we generate \(K\in\mathbb{Z}_{+}\) with

\[\mathrm{Pr}(K=k)=\frac{\tilde{T}_{k}^{-\alpha}}{\sum_{i=1}^{\infty}\tilde{T}_{ i}^{-\alpha}},\]

and the final output is \(Z_{K}\). Rearranging the points according to \((j_{i})_{i}\), the distribution of the final output remains the same if we instead generate \(K^{\prime}\in\mathbb{Z}_{+}\) with

\[\mathrm{Pr}(K^{\prime}=k)=\frac{\tilde{T}_{j_{k}}^{-\alpha}}{\sum_{i=1}^{ \infty}\tilde{T}_{j_{i}}^{-\alpha}},\]

and the final output is \(Z_{j_{K^{\prime}}}\). Since \((\tilde{T}_{j_{i}})_{i}\sim\mathrm{PP}(1)\) is independent of \(Z_{j_{i}}\stackrel{{ iid}}{{\sim}}P\), we know that \(K^{\prime}\) is independent of \((Z_{j_{i}})_{i}\), and hence \(Z_{j_{K^{\prime}}}\sim P\) follows the desired distribution.

## Appendix B Reparametrization and Detailed Algorithm of PPR

We now discuss the implementation of the Poisson private representation in Section 4. Practically, the algorithm cannot compute the whole infinite sequence \((\tilde{T}_{i})_{i}\). We now present an exact algorithm for PPR that terminates in a finite amount of time using a reparametrization.

In the proof of Theorem F.1, we showed that, letting \((T_{i})_{i}\sim\mathrm{PP}(1)\), \(Z_{1},Z_{2},\ldots\stackrel{{ iid}}{{\sim}}Q\), \(R_{i}:=(\mathrm{d}P/\mathrm{d}Q)(Z_{i})\), \(V_{1},V_{2},\ldots\stackrel{{ iid}}{{\sim}}\mathrm{Exp}(1)\), PPR can be equivalently expressed as

\[K=\operatorname*{argmin}_{k}T_{k}^{\alpha}R_{k}^{-\alpha}V_{k}.\]

The problem of finding \(K\) is that there is no stopping criteria for the argmin. For example, if we scan the points \((T_{i},R_{i},V_{i})_{i}\) in increasing order of \(T_{i}\), it is always possible that there is a future point with \(V_{i}\) so small that it makes \(T_{i}^{\alpha}R_{i}^{-\alpha}V_{i}\) smaller than the current minimum. If we scan the points in increasing order of \(V_{i}\) instead, it is likewise possible that there is a future point with a very small \(T_{i}\). We can scan the points in increasing order of \(U_{i}:=T_{i}^{\alpha}V_{i}\), but we would not know the indices of the points in the original process where \(T_{1}\leq T_{2}\leq\cdots\) is in increasing order, which is necessary to find out the \(Z_{i}\) corresponding to each point (recall that in PPR, the point with the smallest \(T_{i}\) corresponds to \(Z_{1}\), the second smallest \(T_{i}\) corresponds to \(Z_{2}\), etc.).

Therefore, we will scan the points in increasing order of \(B_{i}:=T_{i}^{\alpha}\min\{V_{i},1\}\) instead. By the mapping theorem [57], \((T_{i}^{\alpha})_{i}\sim\mathrm{PP}(\alpha^{-1}t^{1/\alpha-1})\). By the marking theorem [57],

\[(T_{i}^{\alpha},V_{i})_{i}\sim\mathrm{PP}(\alpha^{-1}t^{1/\alpha-1}e^{-v}).\]

By the mapping theorem,

\[(T_{i}^{\alpha},T_{i}^{\alpha}V_{i})_{i}\sim\mathrm{PP}(\alpha^{-1}t^{1/\alpha -2}e^{-vt^{-1}}).\]Since \(B_{i}=\min\{T_{i}^{\alpha},T_{i}^{\alpha}V_{i}\}\), again by the mapping theorem,

\[(B_{i})_{i} \sim\mathrm{PP}\Bigg{(}\int_{b}^{\infty}\alpha^{-1}b^{1/\alpha-2}e ^{-vb^{-1}}\mathrm{d}v\] \[\qquad\qquad+\int_{b}^{\infty}\alpha^{-1}t^{1/\alpha-2}e^{-bt^{-1 }}\mathrm{d}t\Bigg{)}\] \[=\mathrm{PP}\left(\alpha^{-1}b^{1/\alpha-1}e^{-1}+\alpha^{-1}b^{1 /\alpha-1}\gamma(1-\alpha^{-1},1)\right)\] \[=\mathrm{PP}\left(\alpha^{-1}\left(e^{-1}+\gamma_{1}\right)b^{1/ \alpha-1}\right),\]

where \(\gamma_{1}:=\gamma(1-\alpha^{-1},1)\) and \(\gamma(\beta,x)=\int_{b}^{x}e^{-\tau}\tau^{\beta-1}\mathrm{d}\tau\) is the lower incomplete gamma function. Comparing the distribution of \((B_{i})_{i}\) and \((T_{i}^{\alpha})_{i}\), we can generate \((B_{i})_{i}\) by first generating \((U_{i})_{i}\sim\mathrm{PP}(1)\), and then taking \(B_{i}=(U_{i}\alpha/(e^{-1}+\gamma_{1}))^{\alpha}\). The conditional distribution of \((T_{i},V_{i})\) given \(B_{i}=b\) is described as follows:

* With probability \(e^{-1}/(e^{-1}+\gamma_{1})\), we have \(T_{i}^{\alpha}=b\) and \(T_{i}^{\alpha}V_{i}\sim b(\mathrm{Exp}(1)+1)\), and hence \(T_{i}=b^{1/\alpha}\) and \(V_{i}\sim\mathrm{Exp}(1)+1\).
* With probability \(\gamma_{1}/(e^{-1}+\gamma_{1})\), we have \(T_{i}^{\alpha}V_{i}=b\) and \[T_{i}^{\alpha}\sim\frac{\alpha^{-1}t^{1/\alpha-2}e^{-bt^{-1}}}{\alpha^{-1} \gamma(1-\alpha^{-1},1)b^{1/\alpha-1}}.\] Hence, for \(0<\tau\leq 1\), \[\mathrm{Pr}(V_{i}\leq\tau)=\mathrm{Pr}(T_{i}^{\alpha}\geq b/\tau)=\frac{ \gamma(1-\alpha^{-1},\tau)}{\gamma(1-\alpha^{-1},1)},\] and \(V_{i}\) follows the truncated gamma distribution with shape \(1-\alpha^{-1}\) and scale \(1\), truncated within the interval \([0,1]\). We then have \(T_{i}=(b/V_{i})^{1/\alpha}\).

The algorithm is given in Algorithm 1. The encoder and decoder require a shared random seed \(s\). One way to generate \(s\) is to have the encoder and decoder maintain two synchronized pseudorandom number generators (PRNGs) that are always at the same state, and invoke the PRNGs to generate \(s\), guaranteeing that the \(s\) at the encoder is the same as the \(s\) at the decoder. The encoder maintains a collection of points \((T_{i},V_{i},\Theta_{i})\), stored in a heap to allow fast query and removal of the point with the smallest \(T_{i}\). The value \(\Theta_{i}\in\{0,1\}\) indicates whether it is possible that the point \((T_{i},V_{i})\) attains the minimum of \(T_{k}^{\alpha}R_{k}^{-\alpha}V_{k}\). The encoding algorithm repeats until there is no possible points left in the heap, and it is impossible for any future point to be better than the current minimum of \(T_{k}^{\alpha}R_{k}^{-\alpha}V_{k}\). The encoding time complexity is \(O(\sup_{z}(\mathrm{d}P/\mathrm{d}Q)(z)\log(\sup_{z}(\mathrm{d}P/\mathrm{d}Q) (z)))\), which is close to other sampling-based channel simulation schemes [45, 36].13 The decoding algorithm simply outputs the \(k\)-th sample generated using the random seed \(s\), which can be performed in \(O(1)\) time.14

Footnote 13: It was shown in [36] that greedy rejection sampling [45] runs in \(O(\sup_{z}(\mathrm{d}P/\mathrm{d}Q)(z))\) time. The PPR algorithm has an additional log term due to the use of heap.

Footnote 14: A counter-based PRNG [70] allows us to directly jump to the state after \(k\) uses of the PRNG, without the need of generating all \(k\) samples, greatly improving the decoding efficiency. This technique is applicable to greedy rejection sampling [45] and the original Poisson functional representation [61, 60] as well.

The PPR is implemented by Algorithm 1. We write \(x\leftarrow\mathrm{Exp}_{\mathscr{G}}(1)\) to mean that we generate an exponential random variate \(x\) with rate \(1\) using the pseudorandom number generator \(\mathscr{G}\). Write \(x\leftarrow\mathrm{Exp}_{\mathrm{local}}(1)\) to mean that \(x\) is generated using a local pseudorandom number generator (not \(\mathscr{G}\)).

## Appendix C Proofs of Theorem 4.5 and Theorem 4.7

First prove Theorem 4.5. Consider a \(\varepsilon\)-DP mechanism \(P_{Z|X}\). Consider neighbors \(x_{1},x_{2}\), and let \(P_{j}:=P_{Z|X}(\cdot|x_{j})\), \(\tilde{T}_{j,i}:=T_{i}/(\frac{\mathrm{d}P_{j}}{\mathrm{d}Q}(Z_{i}))\), and \(K_{j}\) be the output of PPR applied on \(P_{j}\), for \(j=1,2\). Since \(P_{Z|X}\) is \(\varepsilon\)-DP,

\[e^{-\varepsilon}\frac{\mathrm{d}P_{2}}{\mathrm{d}Q}(z)\leq\frac{\mathrm{d}P_{1 }}{\mathrm{d}Q}(z)\leq e^{\varepsilon}\frac{\mathrm{d}P_{2}}{\mathrm{d}Q}(z) \tag{2}\]```
1:Input: parameter \(\alpha>1\), distribution \(Q\), density \(r(z):=(\mathrm{d}P/\mathrm{d}Q)(z)\),
2: bound \(r^{*}\geq\sup_{z}r(z)\), random seed \(s\)
3:Output: index \(k\in\mathbb{Z}_{>0}\)
4:Initialize PRNG \(\mathscr{G}\) using the seed \(s\)
5:\(u\gets 0\), \(w^{*}\leftarrow\infty\), \(k\gets 0\), \(k^{*}\gets 0\), \(n\gets 0\)
6:\(\gamma_{1}\leftarrow\gamma(1-\alpha^{-1},1)=\int_{0}^{1}e^{-\tau}\tau^{-\alpha ^{-1}}\mathrm{d}\tau\)
7:\(h\leftarrow\emptyset\) (empty heap)
8:while true do
9:\(u\gets u+\mathrm{Exp}_{\mathrm{local}}(1)\)\(\triangleright\) Generated using local randomness (not \(\mathscr{G}\))
10:\(b\leftarrow(u\alpha/(e^{-1}+\gamma_{1}))^{\alpha}\)
11:if\(n=0\) and \(b(r^{*})^{-\alpha}\geq w^{*}\)then\(\triangleright\) No possible points left and future points impossible
12:return\(k^{*}\)
13:endif
14:if\(\mathrm{Unif}_{\mathrm{local}}(0,1)<e^{-1}/(e^{-1}+\gamma_{1})\)then\(\triangleright\) Run with prob. \(e^{-1}/(e^{-1}+\gamma_{1})\)
15:\(t\gets b^{1/\alpha}\), \(v\leftarrow\mathrm{Exp}_{\mathrm{local}}(1)+1\)
16:else
17:repeat
18:\(v\leftarrow\mathrm{Gamma}(1-\alpha^{-1},1)\)\(\triangleright\) Gamma distribution
19:until\(v\leq 1\)
20:\(t\leftarrow(b/v)^{1/\alpha}\)
21:endif
22:\(\theta\leftarrow\mathbf{1}\{(t/r^{*})^{\alpha}v\leq w^{*}\}\)\(\triangleright\) Is it possible for this point to be optimal
23: Push \((t,v,\theta)\) to \(h\)
24:\(n\gets n+\theta\)\(\triangleright\) Number of possible points in heap
25:while\(h\neq\emptyset\) and \(\min_{(t^{\prime},v^{\prime},\theta^{\prime})\in h}t^{\prime}\leq b^{1/\alpha}\)do\(\triangleright\) Assign \(Z_{i}\)'s to points in heap with small \(T_{i}\)
26:\((t,v,\theta)\leftarrow\arg\min_{(t^{\prime},v^{\prime},\theta^{\prime})\in h}t^{\prime}\), and pop \((t,v,\theta)\) from \(h\)
27:\(n\gets n-\theta\)
28:\(k\gets k+1\)
29: Generate \(z\sim Q\) using \(\mathscr{G}\)
30:\(w\leftarrow(t/r(z))^{\alpha}v\)
31:if\(w<w^{*}\)then
32:\(w^{*}\gets w\)
33:\(k^{*}\gets k\)
34:endif
35:endwhile
36:endwhile
```

**Procedure**\(\textsc{PPRDecode}(Q,k,s):\)

```
1:Input:\(Q\), index \(k\in\mathbb{Z}_{>0}\), seed \(s\)
2:Output: sample \(z\)
3:Initialize PRNG \(\mathscr{G}\) using the seed \(s\)
4:for\(i=1,2,\ldots,k\)do
5: Generate \(z\sim Q\) using \(\mathscr{G}\)\(\triangleright\) See footnote 14
6:endfor
7:return\(z\)
```

**Algorithm 1** Poisson private representation for \(Q\)-almost every \(z\),15 and hence \(e^{-\varepsilon}\bar{T}_{2,i}\leq\bar{T}_{1,i}\leq e^{\varepsilon}\bar{T}_{2,i}\). For \(k\in\mathbb{Z}_{+}\), we have, almost surely,

Footnote 15: \(\varepsilon\)-DP only implies that (2) holds for \(P_{1}\)-almost every \(z\) (or equivalently \(P_{2}\)-almost every \(z\) since \(P_{1},P_{2}\) are absolutely continuous with respect to each other). We now show that (2) holds for \(Q\)-almost every \(z\). Apply Lebesgue’s decomposition theorem to find measures \(\tilde{Q},\tilde{Q}\) such that \(Q=\tilde{Q}+\tilde{Q},\tilde{Q}\ll P_{1}\) and \(\tilde{Q}\perp P_{1}\). There exists \(\mathcal{Z}^{\prime}\subseteq\mathcal{Z}\) such that \(P_{1}(\mathcal{Z}^{\prime})=1\) and \(\tilde{Q}(\mathcal{Z}^{\prime})=0\). Since \(P_{1}\ll Q\), we have \(P_{1}\ll\tilde{Q}\). We have (2) for \(\tilde{Q}\)-almost every \(z\). Also, we have (2) for \(\tilde{Q}\)-almost every \(z\) since \(z\notin\mathcal{Z}^{\prime}\) gives \(\frac{\mathrm{d}P_{1}}{\mathrm{d}Q}(z)=\frac{\mathrm{d}P_{1}}{\mathrm{d}Q}(z)=0\) for \(\tilde{Q}\)-almost every \(z\), and also \(\frac{\mathrm{d}P_{2}}{\mathrm{d}Q}(z)=0\) for \(\tilde{Q}\)-almost every \(z\) since \(P_{2}\ll P_{1}\).

\[\Pr(K_{1}=k\,|\,(Z_{i},T_{i})_{i}) =\frac{\bar{T}_{1,i}^{-\alpha}}{\sum_{i=1}^{\infty}\bar{T}_{1,i}^ {-\alpha}}\] \[\leq\frac{e^{\alpha\varepsilon}\tilde{T}_{2,k}^{-\alpha}}{\sum_{i =1}^{\infty}e^{-\alpha\varepsilon}\bar{T}_{2,i}^{-\alpha}}\] \[=e^{2\alpha\varepsilon}\Pr(K_{2}=k\,|\,(Z_{i},T_{i})_{i}).\]

For any measurable \(\mathcal{S}\subseteq\mathcal{Z}^{\infty}\times\mathbb{Z}_{>0}\),

\[\Pr\left(((Z_{i})_{i},K_{1})\in\mathcal{S}\right)\] \[=\mathbb{E}\left[\sum_{k:\,((Z_{i})_{i},K_{1})\in\mathcal{S}} \Pr\left(K_{2}=k\,|\,(Z_{i},T_{i})_{i}\right)\right]\] \[=e^{2\alpha\varepsilon}\Pr\left(((Z_{i})_{i},K_{2})\in\mathcal{S }\right). \tag{3}\]

Hence, \(P_{(Z_{i})_{i},K|X}\) is \(2\alpha\varepsilon\)-DP.

For Theorem 4.7, consider a \(\varepsilon\cdot d_{\mathcal{X}}\)-private mechanism \(P_{Z|X}\), and consider \(x_{1},x_{2}\in\mathcal{X}\). We have

\[e^{-\varepsilon\cdot d_{\mathcal{X}}(x_{1},x_{2})}\frac{\mathrm{d}P_{2}}{ \mathrm{d}Q}(z)\leq\frac{\mathrm{d}P_{1}}{\mathrm{d}\tilde{Q}}(z)\leq e^{ \varepsilon\cdot d_{\mathcal{X}}(x_{1},x_{2})}\frac{\mathrm{d}P_{2}}{\mathrm{ d}Q}(z) \tag{4}\]

for \(Q\)-almost every \(z\). By exactly the same arguments as in the proof of Theorem 4.5, \(\Pr\left(((Z_{i})_{i},K_{1})\in\mathcal{S}\right)\leq e^{2\alpha\varepsilon \cdot d_{\mathcal{X}}(x_{1},x_{2})}\Pr\left(((Z_{i})_{i},K_{2})\in\mathcal{S }\right)\), and hence \(P_{(Z_{i})_{i},K|X}\) is \(2\alpha\varepsilon\cdot d_{\mathcal{X}}\)-private.

## Appendix D Proof of Theorem 4.6

Consider a \((\varepsilon,\delta)\)-DP mechanism \(P_{Z|X}\). Consider neighbors \(x_{1},x_{2}\), and let \(P_{j}:=P_{Z|X}(\cdot|x_{j})\), and \(K_{j}\) be the output of PPR applied on \(P_{j}\), for \(j=1,2\). By the definition of \((\varepsilon,\delta)\)-differential privacy, we have

\[\int\max\left\{\rho_{1}(z)-e^{\varepsilon}\rho_{2}(z),\,0\right\}Q(\mathrm{d}z) \leq\delta, \tag{5}\]

\[\int\max\left\{\rho_{2}(z)-e^{\varepsilon}\rho_{1}(z),\,0\right\}Q(\mathrm{d}z) \leq\delta. \tag{6}\]

Let

\[\overline{\rho}(z):=\min\left\{\max\left\{\rho_{1}(z),\,e^{-\varepsilon}\rho_{ 2}(z)\right\},\,e^{\varepsilon}\rho_{2}(z)\right\}.\]

Note that \(e^{-\varepsilon}\rho_{2}(z)\leq\overline{\rho}(z)\leq e^{\varepsilon}\rho_{2} (z)\). We then consider two cases:

Case 1: \(\int\overline{\rho}(z)Q(\mathrm{d}z)\leq 1\). Let \(\rho_{3}(z)\) be such that \(\int\rho_{3}(z)Q(\mathrm{d}z)=1\) and

\[\overline{\rho}(z)\leq\rho_{3}(z)\leq e^{\varepsilon}\rho_{2}(z).\]

We can always find such \(\rho_{3}\) by taking an appropriate convex combination of the lower bound above (which integrates to \(\leq 1\)) and the upper bound above (which integrates to \(\geq 1\)). We then have

\[e^{-\varepsilon}\rho_{2}(z)\leq\rho_{3}(z)\leq e^{\varepsilon}\rho_{2}(z). \tag{7}\]If \(\rho_{1}(z)-e^{\varepsilon}\rho_{2}(z)\leq 0\), then \(\rho_{1}(z)-\rho_{3}(z)\leq\rho_{1}(z)-\overline{\rho}(z)\leq 0\). If \(\rho_{1}(z)-e^{\varepsilon}\rho_{2}(z)>0\), then \(\rho_{3}(z)=\overline{\rho}(z)=e^{\varepsilon}\rho_{2}(z)\). Either way, we have \(\max\left\{\rho_{1}(z)-\rho_{3}(z),\,0\right\}=\max\left\{\rho_{1}(z)-e^{ \varepsilon}\rho_{2}(z),\,0\right\}\). By (5), we have

\[\int\max\left\{\rho_{1}(z)-\rho_{3}(z),\,0\right\}Q(\mathrm{d}z)\leq\delta.\]

Let \(P_{3}=\rho_{3}Q\) be the probability measure with \(\mathrm{d}P_{3}/\mathrm{d}Q=\rho_{3}\). Then the total variation distance \(d_{\mathrm{TV}}(P_{1},P_{3})\) between \(P_{1}\) and \(P_{3}\) is at most \(\delta\), and by (7),

\[e^{-\varepsilon}\frac{\mathrm{d}P_{2}}{\mathrm{d}Q}(z)\leq\frac{\mathrm{d}P_{ 3}}{\mathrm{d}Q}(z)\leq e^{\varepsilon}\frac{\mathrm{d}P_{2}}{\mathrm{d}Q}(z). \tag{8}\]

Case 2: \(\int\overline{\rho}(z)Q(\mathrm{d}z)>1\). Let \(\rho_{3}(z)\) be such that \(\int\rho_{3}(z)Q(\mathrm{d}z)=1\) and

\[e^{-\varepsilon}\rho_{2}(z)\leq\rho_{3}(z)\leq\overline{\rho}(z).\]

We can always find such \(\rho_{3}\) by taking an appropriate convex combination of the lower bound above (which integrates to \(\leq 1\)) and the upper bound above (which integrates to \(>1\)). We again have \(e^{-\varepsilon}\rho_{2}(z)\leq\rho_{3}(z)\leq e^{\varepsilon}\rho_{2}(z)\). If \(e^{-\varepsilon}\rho_{2}(z)-\rho_{1}(z)\leq 0\), then \(\rho_{3}(z)-\rho_{1}(z)\leq\overline{\rho}(z)-\rho_{1}(z)\leq 0\). If \(e^{-\varepsilon}\rho_{2}(z)-\rho_{1}(z)>0\), then \(\rho_{3}(z)=\overline{\rho}(z)=e^{-\varepsilon}\rho_{2}(z)\). Either way, we have \(\max\left\{\rho_{3}(z)-\rho_{1}(z),\,0\right\}=\max\left\{e^{-\varepsilon}\rho _{2}(z)-\rho_{1}(z),\,0\right\}\). By (6), we have

\[\int\max\left\{\rho_{3}(z)-\rho_{1}(z),\,0\right\}Q(\mathrm{d}z)\leq e^{- \varepsilon}\delta\leq\delta.\]

Let \(P_{3}=\rho_{3}Q\) be the probability measure with \(\mathrm{d}P_{3}/\mathrm{d}Q=\rho_{3}\). Again, we have \(d_{\mathrm{TV}}(P_{1},P_{3})\leq\delta\) and (8). Therefore, regardless of whether Case 1 or Case 2 holds, we can construct \(P_{3}\) satisfying \(d_{\mathrm{TV}}(P_{1},P_{3})\leq\delta\) and (8). Let \(K_{3}\) be the output of PPR applied on \(P_{3}\).

In the proof of Theorem F.1, we see that PPR has the following equivalent formulation. Let \((T_{i})_{i}\sim\mathrm{PP}(1)\) be a Poisson process with rate \(1\), independent of \(Z_{1},Z_{2},\ldots\stackrel{{ iid}}{{\sim}}Q\). Let \(R_{i}:=(\mathrm{d}P/\mathrm{d}Q)(Z_{i})\), and let its probability measure be \(P_{R}\). Let \(V_{1},V_{2},\ldots\stackrel{{ iid}}{{\sim}}\mathrm{Exp}(1)\). PPR can be equivalently expressed as

\[K=\operatorname*{argmin}_{k}\!T_{k}^{\alpha}R_{k}^{-\alpha}V_{k}=\operatorname *{argmin}_{k}\frac{T_{k}V_{k}^{1/\alpha}}{R_{k}}.\]

Note that \((T_{i}V_{i}^{1/\alpha})_{i}\sim\mathrm{PP}(\int_{0}^{\infty}v^{-1/\alpha}e^{- v}\mathrm{d}v)=\mathrm{PP}(\Gamma(1-\alpha^{-1}))\) is a uniform Poisson process. Therefore PPR is the same as the Poisson functional representation [61, 60] applied on \((T_{i}V_{i}^{1/\alpha})_{i}\). By the grand coupling property of Poisson functional representation [60, 59] (see [59, Theorem 3]), if we apply the Poisson functional representation on \(P_{1}\) and \(P_{3}\) to get \(K_{1}\) and \(K_{3}\) respectively, then

\[\mathrm{Pr}(K_{1}\neq K_{3})\leq 2d_{\mathrm{TV}}(P_{1},P_{3})\leq 2\delta.\]

Therefore, for any measurable \(\mathcal{S}\subseteq\mathcal{Z}^{\infty}\times\mathbb{Z}_{>0}\),

\[\mathrm{Pr}\left(((Z_{i})_{i},K_{1})\in\mathcal{S}\right) \leq\mathrm{Pr}\left(((Z_{i})_{i},K_{3})\in\mathcal{S}\right)+2\delta\] \[\leq e^{2\alpha\varepsilon}\mathrm{Pr}\left(((Z_{i})_{i},K_{2}) \in\mathcal{S}\right)+2\delta,\]

where the last inequality is by applying (3) on \(P_{3},P_{2}\) instead of \(P_{1},P_{2}\). Hence, \(P_{(Z_{i})_{i},K|X}\) is \((2\alpha\varepsilon,2\delta)\)-DP.

## Appendix E Proof of Theorem 4.8

We present the proof of \((\varepsilon,\delta)\)-DP of PPR (i.e., Theorem 4.8).

Proof.: We assume

\[\alpha-1\leq\frac{\beta\tilde{\delta}\tilde{\varepsilon}^{2}}{-\ln\tilde{ \delta}}, \tag{9}\]

[MISSING_PAGE_EMPTY:21]

[MISSING_PAGE_EMPTY:22]

\[e^{\tilde{\varepsilon}/2}\tau^{\alpha-1}\geq\sqrt{\frac{(\alpha-1)(-\ln\tau)}{\tau(2 \ln 2-1)}}+1. \tag{14}\]

Substituting (9), we have

\[e^{\tilde{\varepsilon}/2}\tau^{\alpha-1} \geq e^{\tilde{\varepsilon}/2}\tau^{\frac{\beta\tilde{\delta}\tilde {\varepsilon}^{2}}{-\ln\tilde{\delta}}}\] \[=\exp\left(\frac{\tilde{\varepsilon}}{2}+\left(\ln\frac{\tilde{ \delta}}{3}\right)\frac{\beta\tilde{\delta}\tilde{\varepsilon}^{2}}{-\ln\tilde {\delta}}\right)\] \[\geq\exp\left(\frac{\tilde{\varepsilon}}{2}+\left(2\ln\tilde{ \delta}\right)\frac{\beta\tilde{\varepsilon}}{-3\ln\tilde{\delta}}\right)\] \[=\exp\left(\tilde{\varepsilon}\left(\frac{1}{2}-\frac{2\beta}{3} \right)\right),\]

since \(0<\tilde{\delta}\leq 1/3\). Note that this also guarantees \(c=e^{\tilde{\varepsilon}/2}\tau^{\alpha-1}\in[1,2]\) since \(\beta=e^{-4.2}\) and \(0<\tilde{\varepsilon}\leq 1\). We also have

\[\frac{(\alpha-1)(-\ln\tau)}{\tau(2\ln 2-1)} \leq\frac{\frac{\beta\tilde{\varepsilon}^{2}}{-\ln\tilde{\delta}} (-\ln\tau)}{\tau(2\ln 2-1)}\] \[\leq\frac{\frac{-\beta\tilde{\delta}^{2}}{-\ln\tilde{\delta}}(-2 \ln\tilde{\delta})}{(\tilde{\delta}/3)(2\ln 2-1)}\] \[=\frac{6\beta\tilde{\varepsilon}^{2}}{2\ln 2-1}\] \[\leq 16\beta\tilde{\varepsilon}^{2}.\]

Hence,

\[\sqrt{\frac{(\alpha-1)(-\ln\tau)}{\tau(2\ln 2-1)}}+1 \leq 4\tilde{\varepsilon}\sqrt{\beta}+1\] \[\leq\exp\left(4\tilde{\varepsilon}\sqrt{\beta}\right)\] \[\overset{(a)}{\leq}\exp\left(\tilde{\varepsilon}\left(\frac{1}{ 2}-\frac{2\beta}{3}\right)\right)\] \[\leq e^{\tilde{\varepsilon}/2}\tau^{\alpha-1},\]

where (a) is by \(\beta=e^{-4.2}\). Hence (14) is satisfied, and

\[\Pr\Big{(}\sum_{i:\,\tilde{T}_{i}>\tau}\tilde{T}_{i}^{-\alpha}\geq\frac{e^{ \tilde{\varepsilon}/2}}{\alpha-1}\Big{)}\leq\frac{\tilde{\delta}}{3}.\]

Combining this with (11) and (12),

\[\Pr\Big{(}\sum_{i}\tilde{T}_{i}^{-\alpha}\notin\Big{[}\frac{e^{ -\tilde{\varepsilon}/2}}{\alpha-1},\,\frac{e^{\tilde{\varepsilon}/2}}{\alpha- 1}\Big{]}\Big{)}\] \[\leq\Pr\Big{(}\sum_{i}\tilde{T}_{i}^{-\alpha}\leq\frac{e^{- \tilde{\varepsilon}/2}}{\alpha-1}\Big{)}+\Pr(\min_{i}\tilde{T}_{i}\leq\tilde{ \delta}/3)\] \[\quad+\Pr\Big{(}\sum_{i:\,\tilde{T}_{i}>\tilde{\delta}/3}\tilde{ T}_{i}^{-\alpha}\geq\frac{e^{\tilde{\varepsilon}/2}}{\alpha-1}\Big{)}\] \[\leq\tilde{\delta}.\]

Consider an \((\varepsilon,\delta)\)-differentially private mechanism \(P_{Z|X}\). Consider neighbors \(x_{1},x_{2}\), and let \(P_{j}:=P_{Z|X}(\cdot|x_{j})\), \(\tilde{T}_{j,i}:=T_{i}/(\frac{\mathrm{d}P_{j}}{\mathrm{d}Q}(Z_{i}))\), and \(K_{j}\) be the output of PPR applied on \(P_{j}\), for \(j=1,2\). Wefirst consider the case \(\delta=0\), which gives \(\frac{\mathrm{d}P_{1}}{\mathrm{d}Q}(z)\leq e^{\varepsilon}\frac{\mathrm{d}P_{2}}{ \mathrm{d}Q}(z)\) for every \(z\). For any measurable \(\mathcal{S}\subseteq\mathcal{Z}^{\infty}\times\mathbb{Z}_{>0}\),

\[\Pr\left(((Z_{i})_{i},K_{1})\in\mathcal{S}\right)\] \[=\mathbb{E}\left[\Pr\left(((Z_{i})_{i},K_{1})\in\mathcal{S}\, \big{|}\,(Z_{i},T_{i})_{i}\right)\right]\] \[=\mathbb{E}\left[\sum_{k:\,((Z_{i})_{i},k)\in\mathcal{S}}\Pr \left(K_{1}=k\,\big{|}\,(Z_{i},T_{i})_{i}\right)\right]\] \[=\mathbb{E}\left[\sum_{k:\,((Z_{i})_{i},k)\in\mathcal{S}}\frac{ \tilde{T}_{1,k}^{-\alpha}}{\sum_{i}\tilde{T}_{1,i}^{-\alpha}}\right]\] \[\leq\mathbb{E}\left[\mathbf{1}\left\{\sum_{i}\tilde{T}_{1,i}^{- \alpha}\in\left[\frac{e^{-\tilde{\varepsilon}/2}}{\alpha-1},\,\frac{e^{\tilde{ \varepsilon}/2}}{\alpha-1}\right]\right\}\min\left\{\sum_{k:\,((Z_{i})_{i},k) \in\mathcal{S}}\frac{\tilde{T}_{1,k}^{-\alpha}}{\sum_{i}\tilde{T}_{1,i}^{- \alpha}},\,1\right\}\right]+\tilde{\delta}\] \[\leq\mathbb{E}\left[\min\left\{\sum_{k:\,((Z_{i})_{i},k)\in \mathcal{S}}\frac{\tilde{T}_{1,k}^{-\alpha}}{e^{-\tilde{\varepsilon}/2}/( \alpha-1)},\,1\right\}\right]+\tilde{\delta}\] \[=\mathbb{E}\left[\min\left\{\sum_{k:\,((Z_{i})_{i},k)\in\mathcal{ S}}\frac{(\frac{\mathrm{d}P_{2}}{\mathrm{d}Q}(Z_{k}))^{\alpha}T_{k}^{- \alpha}}{e^{-\tilde{\varepsilon}/2}/(\alpha-1)},\,1\right\}\right]+\tilde{\delta}\] \[\leq\mathbb{E}\left[\min\left\{\sum_{k:\,((Z_{i})_{i},k)\in \mathcal{S}}\frac{(\frac{e^{\varepsilon}\frac{\mathrm{d}P_{2}}{\mathrm{d}Q}(Z _{k}))^{\alpha}T_{k}^{-\alpha}}}{e^{-\tilde{\varepsilon}/2}/(\alpha-1)},\,1 \right\}\right]+\tilde{\delta}\] \[\leq\mathbb{E}\left[\mathbf{1}\left\{\sum_{i}\tilde{T}_{2,i}^{- \alpha}\in\left[\frac{e^{-\tilde{\varepsilon}/2}}{\alpha-1},\,\frac{e^{\tilde{ \varepsilon}/2}}{\alpha-1}\right]\right\}\min\left\{\sum_{k:\,((Z_{i})_{i},k) \in\mathcal{S}}\frac{(\frac{e^{\varepsilon}\frac{\mathrm{d}P_{2}}{\mathrm{d}Q} (Z_{k}))^{\alpha}T_{k}^{-\alpha}}}{e^{-\tilde{\varepsilon}/2}/(\alpha-1)},\,1 \right\}\right]+2\tilde{\delta}\] \[\leq\mathbb{E}\left[\min\left\{e^{\alpha\varepsilon}\sum_{k:\,( (Z_{i})_{i},k)\in\mathcal{S}}\frac{(\frac{\mathrm{d}P_{2}}{\mathrm{d}Q}(Z_{k} ))^{\alpha}T_{k}^{-\alpha}}{e^{-\tilde{\varepsilon}}\sum_{i}\tilde{T}_{2,i}^{ -\alpha}},\,1\right\}\right]+2\tilde{\delta}\] \[\leq\mathbb{E}\left[e^{\alpha\varepsilon+\tilde{\varepsilon}} \sum_{k:\,((Z_{i})_{i},k)\in\mathcal{S}}\frac{\tilde{T}_{2,k}^{-\alpha}}{\sum_ {i}\tilde{T}_{2,i}^{-\alpha}}\right]+2\tilde{\delta}\] \[=e^{\alpha\varepsilon+\tilde{\varepsilon}}\Pr\left(((Z_{i})_{i}, K_{2})\in\mathcal{S}\right)+2\tilde{\delta}. \tag{15}\]

Hence PPR is \((\alpha\varepsilon+\tilde{\varepsilon},\,2\tilde{\delta})\)-differentially private.

For the case \(\delta>0\), by the definition of \((\varepsilon,\delta)\)-differential privacy, we have

\[\int\max\left\{\frac{\mathrm{d}P_{1}}{\mathrm{d}Q}(z)-e^{\varepsilon}\frac{ \mathrm{d}P_{2}}{\mathrm{d}Q}(z),\,0\right\}Q(\mathrm{d}z)\leq\delta.\]

Let \(P_{3}\) be a probability measure that satisfies

\[\min\left\{\frac{\mathrm{d}P_{1}}{\mathrm{d}Q}(z),\,e^{\varepsilon}\frac{ \mathrm{d}P_{2}}{\mathrm{d}Q}(z)\right\}\leq\frac{\mathrm{d}P_{3}}{\mathrm{d} Q}(z)\leq e^{\varepsilon}\frac{\mathrm{d}P_{2}}{\mathrm{d}Q}(z),\]

for every \(z\). Such \(P_{3}\) can be constructed by taking an appropriate convex combination of the lower bound above (which integrates to \(\leq 1\)) and the upper bound above (which integrates to \(\geq 1\)) such that \(P_{3}\) integrates to \(1\). We have

\[\int\max\left\{\frac{\mathrm{d}P_{1}}{\mathrm{d}Q}(z)-\frac{\mathrm{d}P_{3}}{ \mathrm{d}Q}(z),\,0\right\}Q(\mathrm{d}z)\leq\delta,\]

and hence the total variation distance \(d_{\mathrm{TV}}(P_{1},P_{3})\) between \(P_{1}\) and \(P_{3}\) is at most \(\delta\). Let \(K_{3}\) be the output of PPR applied on \(P_{3}\).

In the proof of Theorem F.1, we see that PPR has the following equivalent formulation. Let \((T_{i})_{i}\sim\mathrm{PP}(1)\) be a Poisson process with rate \(1\), independent of \(Z_{1},Z_{2},\ldots\stackrel{{ iid}}{{\sim}}Q\). Let \(R_{i}:=(\mathrm{d}P/\mathrm{d}Q)(Z_{i})\), and let its probability measure be \(P_{R}\). Let \(V_{1},V_{2},\ldots\stackrel{{ iid}}{{\sim}}\mathrm{Exp}(1)\). PPR can be equivalently expressed as

\[K=\underset{k}{\mathrm{argmin}}T_{k}^{\alpha}R_{k}^{-\alpha}V_{k}=\underset{k }{\mathrm{argmin}}\frac{T_{k}V_{k}^{1/\alpha}}{R_{k}}.\]

Note that \((T_{i}V_{i}^{1/\alpha})_{i}\sim\mathrm{PP}(\int_{0}^{\infty}v^{-1/\alpha}e^{- v}\mathrm{d}v)=\mathrm{PP}(\Gamma(1-\alpha^{-1}))\) is a uniform Poisson process. Therefore PPR is the same as the Poisson functional representation [61, 60] applied on \((T_{i}V_{i}^{1/\alpha})_{i}\). By the grand coupling property of Poisson functional representation [60, 59] (see [59, Theorem 3]), if we apply the Poisson functional representation on \(P_{1}\) and \(P_{3}\) to get \(K_{1}\) and \(K_{3}\) respectively, then

\[\mathrm{Pr}(K_{1}\neq K_{3})\leq 2d_{\mathrm{TV}}(P_{1},P_{3})\leq 2\delta.\]

Therefore, for any measurable \(\mathcal{S}\subseteq\mathcal{Z}^{\infty}\times\mathbb{Z}_{>0}\),

\[\mathrm{Pr}\left(((Z_{i})_{i},K_{1})\in\mathcal{S}\right)\] \[\leq\mathrm{Pr}\left(((Z_{i})_{i},K_{3})\in\mathcal{S}\right)+2\delta\] \[\leq e^{\alpha\varepsilon+\tilde{\varepsilon}}\Pr\left(((Z_{i})_{ i},K_{2})\in\mathcal{S}\right)+2\tilde{\delta}+2\delta,\]

where the last inequality is by applying (15) on \(P_{3},P_{2}\) instead of \(P_{1},P_{2}\). This completes the proof.

## Appendix F Proof of Theorem 4.3

We now bound the size of the index output by the Poisson private representation. The following is a refined version of Theorem 4.3.

**Theorem F.1**.: _For PPR with parameter \(\alpha>1\), when the encoder is given the input \(x\), the message \(K\) given by PPR satisfies_

\[\mathbb{E}[\log K] \leq D(P\|Q)\] \[\quad+\inf_{\eta\in(0,1]\cap(0,\alpha-1)}\frac{1}{\eta}\log\left( \frac{\Gamma(1-\frac{\eta+1}{\alpha})\Gamma(\eta+1)}{(\Gamma(1-\frac{1}{ \alpha}))^{\eta+1}}+1\right) \tag{16}\] \[\leq D(P\|Q)+\frac{\log(3.56)}{\min\{(\alpha-1)/2,1\}}, \tag{17}\]

_where \(P:=P_{Z|X}(\cdot|x)\)._

Note that for \(\alpha=\infty\), (16) with \(\eta=1\) gives \(\mathbb{E}[\log K]\leq D(P\|Q)+\log 2\), recovering the bound in [58] (which strengthened [61]).

Proof.: Write \((X_{i})_{i}\sim\mathrm{PP}(\mu)\) if the points \((X_{i})_{i}\) (as a multiset, ignoring the ordering) form a Poisson point process with intensity measure \(\mu\). Similarly, for \(f:[0,\infty)^{n}\to[0,\infty)\), we write \(\mathrm{PP}(f)\) for the Poisson point process with intensity function \(f\) (i.e., the intensity measure has a Radon-Nikodym derivative \(f\) against the Lebesgue measure). Let \((T_{i})_{i}\sim\mathrm{PP}(1)\) be a Poisson process with rate \(1\), independent of \(Z_{1},Z_{2},\ldots\stackrel{{ iid}}{{\sim}}Q\). Let \(R_{i}:=(\mathrm{d}P/\mathrm{d}Q)(Z_{i})\), and let its probability measure be \(P_{R}\). We have \(\tilde{T}_{i}=T_{i}/R_{i}\). Let \(V_{1},V_{2},\ldots\stackrel{{ iid}}{{\sim}}\mathrm{Exp}(1)\). By the property of exponential random variables, for any \(p_{1},p_{2},\ldots\geq 0\) with \(\sum_{i}p_{i}<\infty\), we have \(\mathrm{Pr}(\mathrm{argmin}_{k}V_{k}/p_{k}=k)=p_{k}/\sum_{i}p_{i}\). Therefore, PPRF can be equivalently expressed as

\[K=\underset{k}{\mathrm{argmin}}T_{k}^{\alpha}R_{k}^{-\alpha}V_{k}.\]

By the marking theorem [57], \((T_{i},R_{i},V_{i})_{i}\) is a Poisson process over \([0,\infty)^{3}\) with intensity measure

\[(T_{i},R_{i},V_{i})_{i}\sim\mathrm{PP}\left(e^{-v}P_{R}(r)\right).\]By the mapping theorem [57], letting \(W_{i}:=T_{i}^{\alpha}R_{i}^{-\alpha}V_{i}\), we have

\[(T_{i},R_{i},W_{i})_{i}\sim\mathrm{PP}\left(r^{\alpha}t^{-\alpha}e^{-wr^{\alpha} t^{-\alpha}}P_{R}(r)\right). \tag{18}\]

Again by the mapping theorem,

\[(W_{i})_{i} \sim\mathrm{PP}\left(\mathbb{E}_{R\sim P_{R}}\left[\int_{0}^{ \infty}R^{\alpha}t^{-\alpha}e^{-wR^{\alpha}t^{-\alpha}}\mathrm{d}t\right]\right)\] \[=\mathrm{PP}\left(\mathbb{E}\left[\alpha^{-1}(wR^{\alpha})^{1/ \alpha-1}\Gamma(1-\alpha^{-1})R^{\alpha}\right]\right)\] \[=\mathrm{PP}\left(\mathbb{E}\left[\alpha^{-1}w^{1/\alpha-1}\Gamma (1-\alpha^{-1})R\right]\right)\] \[=\mathrm{PP}\left(\alpha^{-1}w^{1/\alpha-1}\Gamma(1-\alpha^{-1})\right)\]

since \(\mathbb{E}[R]=\int(\mathrm{d}P/\mathrm{d}Q)(z)Q(\mathrm{d}z)=1\). Recall that \(W_{K}=\min_{i}W_{i}\) by the definition of \(K\). We have

\[\mathrm{Pr}(W_{K}>w) =\exp\left(-\int_{0}^{w}\alpha^{-1}v^{1/\alpha-1}\Gamma(1-\alpha^ {-1})\mathrm{d}v\right)\] \[=\exp\left(-w^{1/\alpha}\Gamma(1-\alpha^{-1})\right).\]

Hence the probability density function of \(W_{K}\) is

\[-\frac{\mathrm{d}}{\mathrm{d}w}\exp\left(-w^{1/\alpha}\Gamma(1- \alpha^{-1})\right)\] \[=\alpha^{-1}w^{1/\alpha-1}\Gamma(1-\alpha^{-1})\exp\left(-w^{1/ \alpha}\Gamma(1-\alpha^{-1})\right). \tag{19}\]

By (18), the Radon-Nikodym derivative between the conditional distribution of \(R_{K}\) given \(W_{K}=w\) and \(P_{R}\) is

\[\mathrm{Pr}(R_{K}\in[r,r+\mathrm{d}r)\,|\,W_{K}=w)/P_{R}(\mathrm{d }r)\] \[=\frac{\int_{0}^{\infty}r^{\alpha}t^{-\alpha}e^{-wr^{\alpha}t^{- \alpha}}\mathrm{d}t}{\mathbb{E}_{R\sim P_{R}}\left[\int_{0}^{\infty}R^{\alpha }t^{-\alpha}e^{-wR^{\alpha}t^{-\alpha}}\mathrm{d}t\right]}\] \[=\frac{\alpha^{-1}w^{1/\alpha-1}\Gamma(1-\alpha^{-1})r}{\alpha^{ -1}w^{1/\alpha-1}\Gamma(1-\alpha^{-1})}\] \[=r\]

does not depend on \(w\). Hence \(R_{K}\) is independent of \(W_{K}\). By (18), for \(0\leq\eta<\alpha-1\),

\[\mathbb{E}[T_{K}^{\eta}\,|\,R_{K}=r,\,W_{K}=w]\] \[=\frac{\int_{0}^{\infty}t^{\eta}r^{\alpha}t^{-\alpha}e^{-wr^{ \alpha}t^{-\alpha}}\mathrm{d}t}{\int_{0}^{\infty}r^{\alpha}t^{-\alpha}e^{-wr^{ \alpha}t^{-\alpha}}\mathrm{d}t}\] \[=\frac{\alpha^{-1}w^{(\eta+1)/\alpha-1}\Gamma(1-(\eta+1)\alpha^{ -1})r^{\eta+1}}{\alpha^{-1}w^{1/\alpha-1}\Gamma(1-\alpha^{-1})r}. \tag{20}\]

Since \(R_{K}\) is independent of \(W_{K}\), using (20) and (19), for \(\eta\in(0,1]\cap(0,\alpha-1)\),

\[\mathbb{E}[T_{K}^{\eta}\,|\,R_{K}=r]\] \[=\int_{0}^{\infty}\alpha^{-1}w^{(\eta+1)/\alpha-1}\Gamma(1-(\eta+ 1)\alpha^{-1})r^{\eta}\exp\left(-w^{1/\alpha}\Gamma(1-\alpha^{-1})\right) \mathrm{d}w\] \[=r^{\eta}\Gamma(1-(\eta+1)\alpha^{-1})\int_{0}^{\infty}\alpha^{-1 }w^{(\eta+1)/\alpha-1}\exp\left(-w^{1/\alpha}\Gamma(1-\alpha^{-1})\right) \mathrm{d}w\] \[=r^{\eta}\Gamma(1-(\eta+1)\alpha^{-1})(\Gamma(1-\alpha^{-1}))^{-( \eta+1)}\Gamma(\eta+1)\] \[=:c_{\alpha,\eta}r^{\eta}, \tag{21}\]

[MISSING_PAGE_FAIL:27]

where (a) is because \(0.885\leq x\Gamma(x)=\Gamma(x+1)\leq 1\) for \(0<x\leq 1\). Hence,

\[\mathbb{E}[\log K] \leq D(P\|Q)+\eta^{-1}\log(c_{\alpha,\eta}+1),\] \[\leq D(P\|Q)+\frac{\log(3.56)}{\min\{(\alpha-1)/2,1\}}.\]

## Appendix G Distributed Mean Estimation with Renyi DP

In many machine learning applications, privacy budgets are often accounted in the moment space, and one popular moment accountant is the Renyi DP accountant. For completeness, we provide a Renyi DP version of Corollary 5.2 in this section. We begin with the following definition of Renyi DP:

**Definition G.1** (Renyi Differential privacy [1, 68]).: Given a mechanism \(\mathcal{A}\) which induces the conditional distribution \(P_{Z|X}\) of \(Z=\mathcal{A}(X)\), we say that it satisfies \((\gamma,\varepsilon)\)- Renyi DP if for any neighboring \((x,x^{\prime})\in\mathcal{N}\) and \(\mathcal{S}\subseteq\mathcal{Z}\), it holds that

\[D_{\gamma}\left(P_{Z|X=x}\big{\|}P_{Z|X=x^{\prime}}\right)\leq\varepsilon,\]

where

\[D_{\gamma}\left(P\|Q\right):=\frac{1}{\gamma-1}\log\left(\mathbb{E}_{Q}\left[ \left(\frac{P}{Q}\right)^{\gamma}\right]\right)\]

is the Renyi divergence between \(P\) and \(Q\). If \(\mathcal{N}=\mathcal{X}^{2}\), we say that the mechanism satisfies \((\gamma,\varepsilon)\)-local DP.

The following conversion lemma from [13] relates Renyi DP to \((\varepsilon_{\mathsf{DP}}(\delta),\delta)\)-DP.

**Lemma G.2**.: _If \(\mathcal{A}\) satisfies \((\gamma,\varepsilon)\)-Renyi DP for some \(\gamma\geq 1\), then, for any \(\delta>0\), \(\mathcal{A}\) satisfies \((\varepsilon_{\mathsf{DP}}(\delta),\delta)\)-DP, where_

\[\varepsilon_{\mathsf{DP}}(\delta)=\varepsilon+\frac{\log\left(1/\gamma\delta \right)}{\gamma-1}+\log(1-1/\gamma). \tag{23}\]

The following theorem states that, when simulating the Gaussian mechanism, PPR satisfies the following both central and local DP guarantee:

**Corollary G.3** (PPR-compressed Gaussian mechanism).: _Let \(\varepsilon\geq 0\) and \(\gamma\geq 1\). Consider the Gaussian mechanism \(P_{Z|X}(\cdot|x)=\mathcal{N}(x,\frac{\sigma^{2}}{n}\mathbb{I}_{d})\), and the proposal distribution \(Q=\mathcal{N}(0,(\frac{C^{2}}{d}+\frac{\sigma^{2}}{n})\mathbb{I}_{d})\), where \(\sigma\geq\sqrt{\frac{C\gamma}{2\varepsilon}}\). For each client \(i\), let \(Z_{i}\) be the output of PPR applied on \(P_{Z|X}(\cdot|X_{i})\). We have:_

* \(\hat{\mu}(Z^{n}):=\frac{1}{n}\sum_{i}Z_{i}\) _yields an unbiased estimator of_ \(\mu(X^{n})=\frac{1}{n}\sum_{i=1}^{n}X_{i}\) _satisfying_ \((\gamma,\varepsilon)\)_-(central) Renyi DP and_ \((\varepsilon_{\mathsf{DP}}(\delta),\delta)\)_-DP, where_ \(\varepsilon_{\mathsf{DP}}(\delta)\) _is defined in (_23_)._
* \(P_{Z|X_{i}}\) _satisfies_ \((2\alpha\tilde{\varepsilon}_{\mathsf{DP}}(\delta),2\delta)\)_-local DP, where_ \[\tilde{\varepsilon}_{\mathsf{DP}}(\delta):=\sqrt{n}\varepsilon+\frac{\log \left(1/\gamma\delta\right)}{\gamma-1}+\log(1-1/\gamma).\]
* \(\hat{\mu}(Z^{n})\) _has MSE_ \(\mathbb{E}[\|\mu-\hat{\mu}\|_{2}^{2}]=\sigma^{2}d/n^{2}\)_._
* _The average per-client communication cost is at most_ \(\ell+\log_{2}(\ell+1)+2\) _bits where_ \[\ell:=\frac{d}{2}\log_{2}\left(\frac{C^{2}n}{d\sigma^{2}}+1\right)+\eta_{ \alpha}\;\leq\;\frac{d}{2}\log_{2}\left(\frac{n\varepsilon^{2}}{2d\ln(1.25/ \delta)}+1\right)+\eta_{\alpha},\] _where_ \(\eta_{\alpha}:=(\log_{2}(3.56))/\min\{(\alpha-1)/2,\,1\}\)_._

Proof.: The central DP guarantee follows from [68] and Lemma G.2. The local DP guarantee follows from Lemma G.2 and Theorem 4.8. Finally, the communication bound can be obtained from the same analysis as in Corollary 5.2.

Proof of Corollary 5.2

Consider the PPR applied on the Gaussian mechanism \(P_{Z|X}(\cdot|x)=\mathcal{N}(x,\frac{\sigma^{2}}{n}\mathbb{I}_{d})\), with the proposal distribution \(Q=\mathcal{N}(0,(\frac{C^{2}}{d}+\frac{\sigma^{2}}{n})\mathbb{I}_{d})\). PPR ensures that \(Z_{i}\) follows the distribution \(\mathcal{N}(X_{i},\frac{\sigma^{2}}{n}\mathbb{I}_{d})\). Therefore the MSE is

\[\mathbb{E}\left[\|\mu-\hat{\mu}\|_{2}^{2}\right] =\mathbb{E}\left[\left\|\frac{1}{n}\sum_{i=1}^{n}(X_{i}-Z_{i}) \right\|_{2}^{2}\right]\] \[=\frac{1}{n}\cdot d\cdot\frac{\sigma^{2}}{n}\] \[=\frac{\sigma^{2}d}{n^{2}}.\]

For the compression size, for \(x\in\mathbb{R}^{d}\) with \(\|x\|_{2}\leq C\), we have

\[D(P_{Z|X}(\cdot|x)\|Q)\] \[=\mathbb{E}_{Z\sim P_{Z|X}(\cdot|x)}\left[\log\frac{\mathrm{d}P_{ Z|X}(\cdot|x)}{\mathrm{d}Q}(Z)\right]\] \[=\mathbb{E}_{Z\sim P_{Z|X}(\cdot|x)}\left[\log\frac{(2\pi\sigma^{ 2}/n)^{-d/2}\exp(-\frac{1}{2}\|Z-x\|_{2}^{2}/(\sigma^{2}/n))}{(2\pi(\frac{C^{2 }}{d}+\frac{\sigma^{2}}{n}))^{-d/2}\exp(-\frac{1}{2}\|Z\|_{2}^{2}/(\frac{C^{2} }{d}+\frac{\sigma^{2}}{n}))}\right]\] \[=\mathbb{E}_{Z\sim P_{Z|X}(\cdot|x)}\left[\frac{d}{2}\log\frac{ \frac{C^{2}}{d}+\frac{\sigma^{2}}{n}}{\sigma^{2}/n}+\frac{1}{2}\left(\frac{\| Z\|_{2}^{2}}{\frac{C^{2}}{d}+\frac{\sigma^{2}}{n}}-\frac{\|Z-x\|_{2}^{2}}{\sigma^{2 }/n}\right)\right]\] \[\leq\frac{d}{2}\log\frac{\frac{C^{2}}{d}+\frac{\sigma^{2}}{n}}{ \sigma^{2}/n}+\frac{1}{2}\left(\frac{C^{2}+\sigma^{2}d/n}{\frac{C^{2}}{d}+ \frac{\sigma^{2}}{n}}-\frac{\sigma^{2}d/n}{\sigma^{2}/n}\right)\] \[=\frac{d}{2}\log\left(\frac{C^{2}n}{d\sigma^{2}}+1\right).\]

Hence, by Theorem 4.3, the compression size is at most \(\ell+\log_{2}(\ell+1)+2\) bits, where

\[\ell :=\frac{d}{2}\log_{2}\left(\frac{C^{2}n}{d\sigma^{2}}+1\right)+ \eta_{\alpha}\] \[\leq\frac{d}{2}\log_{2}\left(\frac{n\epsilon^{2}}{2d\ln(1.25/ \delta)}+1\right)+\eta_{\alpha}\] \[\leq\frac{n\epsilon^{2}\log_{2}(e)}{4\ln(1.25/\delta)}+\eta_{ \alpha},\]

where \(\eta_{\alpha}:=(\log_{2}(3.56))/\min\{(\alpha-1)/2,\,1\}\).

The central-DP guarantee follows from \((\varepsilon,\delta)\)-DP of Gaussian mechanism [26, Appendix A] since the output distribution of PPR is exactly the same as the Gaussian mechanism, whereas the local-DP guarantee follows from Theorem 4.6 and [26, Appendix A].

## Appendix I Proof of Corollary 6.1

Let \(\|X-Z\|_{2}=RS\) where \(R\in[0,\infty)\) is the magnitude of \(X-Z\), and \(\|S\|_{2}=1\). As shown in [33], \(R\) follows the Gamma distribution with shape \(d\) and scale \(1/\varepsilon\). Hence the MSE is

\[\mathbb{E}\left[\|X-Z\|_{2}^{2}\right]=\mathbb{E}\left[R^{2}\right]=\left( \frac{d}{\varepsilon}\right)^{2}+\frac{d}{\varepsilon^{2}}=\frac{d(d+1)}{ \varepsilon^{2}}.\]The conditional differential entropy (in nats) of \(Z\) given \(X\) is

\[h(Z|X) =h(R)+h(S|R)\] \[=d+\ln\Gamma(d)-(d-1)\psi(d)-\ln\varepsilon+\mathbb{E}\left[\ln(nR ^{d-1}\text{Vol}(\mathcal{B}_{d}(1)))\right]\] \[=d+\ln\Gamma(d)-(d-1)\psi(d)-\ln\varepsilon+\ln d+\ln(\text{Vol}( \mathcal{B}_{d}(1)))+(d-1)\mathbb{E}\left[\ln R\right]\] \[=d+\ln\Gamma(d)-(d-1)\psi(d)-\ln\varepsilon+\ln d+\frac{d}{2}\ln \pi-\ln\Gamma\left(\frac{d}{2}+1\right)\] \[\qquad-(d-1)\ln\epsilon+(d-1)\psi(d)\] \[=d\ln\frac{e\sqrt{\pi}}{\varepsilon}+\ln\frac{d\Gamma(d)}{\Gamma( \frac{d}{2}+1)},\]

where \(\psi\) is the digamma function. Therefore, the KL divergence between \(P_{Z|X}(\cdot|x)\) and \(Q\) (in nats) is

\[D(P_{Z|X}(\cdot|x)\|Q)\] \[=\frac{d}{2}\ln\left(2\pi\left(\frac{C^{2}}{d}+\frac{d+1}{ \varepsilon^{2}}\right)\right)+\frac{\mathbb{E}_{2\sim P_{Z|X}(\cdot|x)}\left[ \|Z\|_{2}^{2}\right]}{2(\frac{C^{2}}{d}+\frac{d+1}{\varepsilon^{2}})}-d\ln \frac{e\sqrt{\pi}}{\varepsilon}-\ln\frac{d\Gamma(d)}{\Gamma(\frac{d}{2}+1)}\] \[\leq\frac{d}{2}\ln\left(2\pi\left(\frac{C^{2}}{d}+\frac{d+1}{ \varepsilon^{2}}\right)\right)+\frac{C^{2}+\frac{d(d+1)}{\varepsilon^{2}}}{2( \frac{C^{2}}{d}+\frac{d+1}{\varepsilon^{2}})}-d\ln\frac{e\sqrt{\pi}}{ \varepsilon}-\ln\frac{d\Gamma(d)}{\Gamma(\frac{d}{2}+1)}\] \[=\frac{d}{2}\ln\left(\frac{2}{e}\left(\frac{C^{2}\varepsilon^{2}} {d}+d+1\right)\right)-\ln\frac{\Gamma(d+1)}{\Gamma(\frac{d}{2}+1)}.\]

Hence, by Theorem 4.3, the compression size is at most \(\ell+\log_{2}(\ell+1)+2\) bits. The metric privacy guarantee follows from Theorem 4.7.

## Appendix J Experiments on Metric Privacy

We use PPR to simulate the Laplace mechanism [3, 33, 34]\(f_{Z|X}(z|x)\propto e^{-\varepsilon d_{X}(x,z)}\) discussed in Section 6. We consider \(X\in\mathcal{B}_{d}(C)\) where \(C=10000\) and \(d=500\). A large number of dimensions \(d\) is common, for example, in privatizing word embedding vectors [33, 34]. We compare the performance of PPR-compressed Laplace mechanism (Corollary 6.1) with the discrete Laplace mechanism [3]. The discrete Laplace mechanism is described as follows (slightly modified from [3] to work for the \(d\)-ball \(\mathcal{B}_{d}(C)\)): 1) generate a Laplace noise \(Y\) with probability density function \(f_{Y}(y)\propto e^{-\varepsilon\|y\|_{2}}\); 2) compute \(\hat{Z}=X+Y\); 3) truncate \(\hat{Z}\) to the closest point \(Z\) in \(\mathcal{B}_{d}(C)\); and 4) quantize each coordinate of \(Z\) by a quantizer with step size \(u>0\). The number of bits required by the discrete Laplace mechanism is \(\lceil\log_{2}(\text{Vol}(\mathcal{B}_{d}(C))/u^{d})\rceil\), where \(\text{Vol}(\mathcal{B}_{d}(C))/u^{d}\) is the number of quantization cells (hypercube of side length \(u\)) inside \(\mathcal{B}_{d}(C)\). The parameter \(u\) is selected to fit the number of bits allowed.

Figure 2 shows the mean squared error of PPR-compressed Laplace mechanism (\(\alpha=2\)) and the discrete Laplace mechanism for different \(\varepsilon\)'s, when the number of bits is limited to \(500\), \(1000\) and \(1500\).16 We can see that PPR performs better for larger \(\epsilon\) or smaller MSE, whereas the discrete Laplace mechanism performs better for smaller \(\epsilon\) or larger MSE. The performance of discrete Laplace mechanism for smaller \(\epsilon\) is due to the truncation step which limits \(Z\) to \(\mathcal{B}_{d}(C)\), which reduces the error at the expense of introducing distortion to the distribution of \(Z\), and making \(Z\) a biased estimate of \(X\). In comparison, PPR preserves the Laplace conditional distribution \(f_{Z|X}\) exactly, and hence produces an unbiased \(Z\).

Footnote 16: The MSE of PPR is computed using the closed-form formula in Corollary 6.1, which is tractable since \(Z\) follows the Laplace conditional distribution \(f_{Z|X}\) exactly. The number of bits used by PPR is given by the bound in Corollary 6.1. The MSE of the discrete Laplace mechanism is estimated using \(5000\) trials per data point. Although we do not plot the error bars, the largest coefficient of variation of the sample mean (i.e., standard error of the mean divided by the sample mean) is only 0.00117, which would be unnoticeable even if the error bars were plotted.

## Appendix K Running Time of PPR

As discussed in Section 7, we can ensure an \(O(d)\) running time for the Gaussian mechanism by using the sliced PPR, where the \(d\)-dimensional vector \(X\) is divided into \(\lceil d/d_{\rm chunk}\rceil\) chunks, each with a fixed dimension \(d_{\rm chunk}\) (possibly except the last chunk if \(d_{\rm chunk}\) is not a factor of \(d\)). The average total running time is \(\lceil d/d_{\rm chunk}\rceil T_{\rm chunk}\), where \(T_{\rm chunk}\) is the average running time of PPR applied on one chunk.17 Therefore, to study the running time of the sliced PPR, we study how \(T_{\rm chunk}\) depend on \(d_{\rm chunk}\).

Footnote 17: Note that the chunks may be processed in parallel for improved efficiency.

In Figure 3 we show the running time \(T_{\rm chunk}\) of PPR applied on one chunk with dimension \(d_{\rm chunk}\), where \(d_{\rm chunk}\) ranges from \(40\) to \(110\).18 With \(d=1000\), \(n=500\), \(\varepsilon=0.05\) and \(\delta=10^{-6}\), we require a Gaussian mechanism with noise \(\mathcal{N}(0,n\tilde{\sigma}^{2}\mathbb{I}_{d_{\rm chunk}})\) where \(\tilde{\sigma}=1.0917\) at each user in order to ensure \((\varepsilon,\delta)\)-central DP. We record the mean \(T_{\rm chunk}\) and the standard error of the mean19 of the running time of PPR applied to simulate this Gaussian mechanism (averaged over \(20000\) trials).

Footnote 18: Experiments were executed on M1 Pro Macbook, 8-core CPU (\(\approx 3.2\) GHz) with 16GB memory.

Figure 2: MSE of PPR-compressed Laplace mechanism and discrete Laplace mechanism [3] for different \(\varepsilon\)’s.

We plot the average running time (over \(20000\) trials for each data point) against the values of \(\epsilon\in[0.06,10]\), with \(d_{\rm chunk}\) always chosen to be \(4\). The average running time is denoted as \(T_{\rm chunk}\), and the standard error of the mean is given by \(\sigma_{\rm mean}=\sigma_{\rm time}/\sqrt{n_{\rm trials}}\), where \(\sigma_{\rm time}\) is the standard deviation of the running time among the \(\sigma_{\rm time}=20000\) trials.

## Appendix L MSE against Compression Size

We plot the MSE against the compression size (ranging from \(25\) to \(1000\) bits) for \(\epsilon\in\{0.25,0.5,1.0,2.0\}\) in the following figure.

Figure 4: Average running time (over \(20000\) trials), \(d_{\rm chunk}=4\) and \(\varepsilon\in[0.06,10]\), with error bars indicating the interval \(T_{\rm chunk}\pm 2\sigma_{\rm mean}\), where \(T_{\rm chunk}\) is the sample mean of the running time, and \(\sigma_{\rm mean}\) is the standard error of the mean.

Figure 3: Average running time of PPR applied to a chunk of dimension \(d_{\rm chunk}\), with error bars indicating the interval \(T_{\rm chunk}\pm 2\sigma_{\rm mean}\), where \(T_{\rm chunk}\) is the sample mean of the running time, and \(\sigma_{\rm mean}\) is the standard error of the mean (see Footnote 19).

Figure 5: The MSE of PPR and CSGM against the compression size in bits, where \(\varepsilon\) is chosen from \(\{0.25,0.5,1.0,2.0\}\) and compression sizes vary from \(25\) to \(1000\) bits. Note that parts of the curves for PPR are flat, because a lower compression size is already sufficient for PPR to exactly simulate the best Gaussian mechanism for that value of \(\varepsilon\), so a higher compression size than necessary will not affect the result.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: We have clearly stated our paper's contributions and scope in both the abstract and introduction. We try to answer the fundamental question: how can we efficiently communicate privatized data? The main contribution is our novel "DP mechanism compressor", whose main advantages: universality, exactness and communication efficiency, have been elaborated in the introduction. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: The main limitation of the proposed method is that it has a running time exponential with respect to the mutual information, though this is not an obstacle for simulating local DP mechanism (where the mutual information must be small). This is elaborated in Section 8. Note that there is no limitation on the type of DP mechanism that can be compressed by PPR (it can compress any DP mechanism to almost the theoretically smallest size). See Section 8 for details. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their bestjudgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: All theorems are precise mathematical statements, with all necessary assumptions included in either the theorem statement or the definition of PPR. Complete proofs are included in the appendices. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: The detailed pseudocode of the PPR method is given in Algorithm 1 in the appendix, and the implementation together with the codes and data for Section 7 have been submitted in the supplementary material. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. *3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: We have provided detailed implementations of Algorithm 1 and data for Figure 1 (the main experimental result) in the supplemental material. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines ([https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy)) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines ([https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy)) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: We have specified all the experiment details in Section 7. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes]Justification: For the PPR applied on the Gaussian mechanism in Section 7, the mean squared error is obtained by a closed-form formula, and the compression size is bounded using the expression in Theorem 4.3. Therefore, the plot about PPR in in Figure 1 is precise. For the running time of sliced PPR, we have reported the standard error of the mean of the running time via error bars in Figure 3. For the experiments on the Laplace mechanism in Appendix J, the standard error of the mean has been recorded for the estimation of the MSE of the discrete Laplace mechanism, and the largest coefficient of variation of the sample mean is reported, which is very small and would be unnoticeable even if the error bars were plotted. Guidelines:

* The answer NA means that the paper does not include experiments.
* The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.
* The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).
* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.

8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: We have provided all the necessary information on the experiments in Section 7, including the computer and CPU information. Figure 1 plotted according to closed-form formulas and hence can be immediately derived. Guidelines:

* The answer NA means that the paper does not include experiments.
* The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.
* The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.
* The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).

9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics [https://neurips.cc/public/EthicsGuidelines?](https://neurips.cc/public/EthicsGuidelines?) Answer: [Yes] Justification: We confirm that the research conducted in this paper conforms with the NeurIPS Code of Ethics.

Guidelines:

* The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
* If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.
* The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [No] Justification: We believe research on privacy preservation generally has a positive societal impact, and research on reducing the communication cost of privacy mechanisms (such as this paper) is beneficial. Nevertheless, we have not addressed this in the paper, since we believe our theoretical results has no specific societal impact outside of the general impacts of privacy and reduced communication cost. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. * If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: This piece of research is theoretical. We do not release any new dataset or pretrained model. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. ** We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: We have appropriately mentioned and cited the paper whenever we compare with it. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. * If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [Yes] Justification: This paper is mainly for theoretical research. We have provided the codes for our algorithm (implemented by Python) in the supplementary material, which is well documented. We do not release any new dataset. Guidelines: * The answer NA means that the paper does not release new assets. * Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. * The paper should discuss whether and how consent was obtained from people whose asset is used. * At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: This piece of research does not involve crowdsourcing or human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.

* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: This piece of research does not involve crowdsourcing or human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper. * We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution. * For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.