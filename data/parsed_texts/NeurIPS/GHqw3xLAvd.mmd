# Differentiable Quantum Computing for

Large-scale Linear Control

Connor Clayton\({}^{*,1,2}\)

Jiaqi Leng\({}^{*,1,3,5}\)

Gengzhi Yang\({}^{*,1,3}\)

Yi-Ling Qiao\({}^{2,4}\)

Ming C. Lin\({}^{2,4}\)

Xiaodi Wu\({}^{\dagger,1,2}\)

\({}^{1}\)Joint Center for Quantum Information and Computer Science, University of Maryland

\({}^{2}\)Department of Computer Science, University of Maryland

\({}^{3}\)Department of Mathematics, University of Maryland

\({}^{4}\)Center for Machine Learning, University of Maryland

\({}^{5}\)Department of Mathematics and Simons Institute for the Theory of Computing, UC Berkeley

\({}^{*}\)Equal Contribution

\({}^{\dagger}\)xiaodiwu@umd.edu

###### Abstract

As industrial models and designs grow increasingly complex, the demand for optimal control of large-scale dynamical systems has significantly increased. However, traditional methods for optimal control incur significant overhead as problem dimensions grow. In this paper, we introduce an end-to-end quantum algorithm for linear-quadratic control with provable speedups. Our algorithm, based on a policy gradient method, incorporates a novel quantum subroutine for solving the matrix Lyapunov equation. Specifically, we build a _quantum-assisted differentiable simulator_ for efficient gradient estimation that is more accurate and robust than classical methods relying on stochastic approximation. Compared to the classical approaches, our method achieves a _super-quadratic_ speedup. To the best of our knowledge, this is the first end-to-end quantum application to linear control problems with provable quantum advantage.

## 1 Introduction

Over the past few decades, the growing complexity of modern engineering designs has made the control of large-scale dynamical systems a crucial task across various application fields, such as power grid management [56], swarm robotics [16, 18], sensor networks [21], and airline scheduling [57]. These challenges often involve high-dimensional solution spaces with tens of thousands of degrees of freedom, presenting a significant obstacle for traditional optimal control methods.

The emergence of quantum computing has expanded the potential for designing efficient algorithms in numerical optimization and machine learning [1, 36, 62]. By leveraging the principles of quantum mechanics, such as superposition and entanglement, quantum computers excel at efficient data processing, making them promising for accelerating solutions to large-scale computational challenges [31].

Although there has been some progress in quantum algorithms for some specific optimal control problems arising in quantum sciences [37, 39], a viable pathway for accelerating general large-scale optimal control problems remains unclear. A conventional approach to optimal control involves solving the Algebraic Riccati Equation (ARE, see Section 1.1 for details), which is a nonlinear matrix equation. This problem has been less explored in thefield of quantum computing for two reasons. First, most proposed quantum algorithms for algebraic and differential equations focus on linear and vector-valued problems, and extending them to nonlinear matrix equations is highly challenging. Second, while efficient quantum algorithms exist for certain weakly nonlinear problems [41], they are not powerful enough to handle the nonlinearity present in the Algebraic Riccati Equation. A breakthrough in this direction calls for novel ideas in algorithm design.

Inspired by the recent advances in differentiable physics [37, 46, 53] and reinforcement learning [19, 45], we develop an end-to-end quantum algorithm that solves a fundamental optimal control problem called the linear-quadratic regulator (LQR). Given its widely applicable mathematical formulation, LQR has been extensively researched and serves as a standard case study for various computing and learning algorithms [25]; moreover, LQR is of significant practical relevance as many real-world optimal control problems can be formulated to address through linearization techniques. Our quantum algorithm is proven to output an \(\varepsilon\)-approximate optimal solution in time \(\widetilde{\mathcal{O}}\left(n\varepsilon^{-1.5}\right)\)1, where \(n\) is the dimension of the state vector and \(\varepsilon\) is an error tolerance parameter. The algorithm involves two major components: a quantum differentiable simulator and a quantum-accessible classical data structure. This hybrid quantum-classical framework enables us to employ a _policy gradient_ method that exhibits a fast convergence rate for the LQR problem. Since almost all known classical methods for the LQR problem heavily rely on subroutines such as matrix factorization and matrix inversion [6, 32, 34, 35], which require at least \(\mathcal{O}(n^{3})\) overhead in the problem dimension \(n\), our new linear-time quantum algorithm, with _super-quadratic_ speedup, offers significant promise for large-scale applications.

Footnote 1: The \(\widetilde{\mathcal{O}}(\cdot)\) notation suppresses the condition number dependence and polylogarithmic factors in \(n\) and \(\varepsilon\).

Notation.We use \(\mathbb{R}\) and \(\mathbb{C}\) to denote the set of real and complex numbers, respectively. \(\mathbb{I}\) denotes an identity operator with an appropriate dimension. For two real vectors \(u,v\in\mathbb{R}^{n}\), the Euclidean inner product \(\langle u,v\rangle=u^{T}v\), and the norm of a vector \(u\) is \(\|u\|=\sqrt{u^{T}u}\). Given a symmetric/Hermitian matrix \(M\), we denote \(\lambda_{\max}(M)\) (or \(\lambda_{\min}(M)\)) as the maximal/minimal eigenvalue of \(M\). The spectral norm of a matrix \(M\in\mathbb{R}^{m\times n}\) is denoted by \(\|M\|=\sup_{\|v\|=1}\|Mv\|\). The Frobenius norm of a matrix \(M\in\mathbb{R}^{m\times n}\) is denoted by \(\|M\|_{F}=\sum_{i,j}|M_{i,j}|^{2}=\operatorname{Tr}\bigl{[}M^{T}M\bigr{]}\). We say \(\xi\sim\mathcal{D}\) if the random variable \(\xi\in\mathbb{R}^{n}\) is distributed according to \(\mathcal{D}\).

### Problem Formulation

We focus on the infinite-horizon continuous-time linear-quadratic regulator (LQR) problem:

\[\min_{x,u}J =\mathbb{E}\left[\int_{0}^{\infty}\left(x^{\top}(t)Qx(t)+u^{\top }(t)Ru(t)\right)\mathrm{d}t\right]\] (1a) \[\text{subject to }\dot{x}=Ax+Bu,\ \ x(0)\sim\mathcal{D},\] (1b)

where \(x(t)\colon[0,\infty]\to\mathbb{R}^{n}\) is the state vector, \(u(t)\colon[0,\infty]\to\mathbb{R}^{m}\) is the control input. \(A\) and \(B\) are constant matrices of appropriate dimensions; \(Q\) and \(R\) are positive definite matrices.

**Definition 1**.: For a square matrix \(M\in\mathbb{R}^{n\times n}\), we say \(M\) is _Hurwitz_ if every eigenvalue of \(M\) has a strictly negative real part.

**Definition 2**.: For a controllable pair \((A,B)\), the set of stabilizing feedback gains is given by

\[S_{K}\coloneqq\{K\in\mathbb{R}^{m\times n}\colon A-BK\text{ is Hurwitz}\}.\] (2)

Given a controllable pair \((A,B)\), the optimal controller \(u(t)\) of problem (1) can be expressed as a linear function of the state vector \(x(t)\), namely

\[u(t)=-K^{*}x(t),\] (3)

where the matrix \(K^{*}\) is the optimal linear feedback gain. An analytical form of the optimal feedback gain is given by \(K^{*}=R^{-1}B^{\top}P^{*}\), where \(P^{*}\) is the unique positive solution to the Algebraic Riccati Equation (ARE),

\[A^{\top}P+PA+Q-PBR^{-1}B^{\top}P=0.\] (4)For large-scale control problems where the control input is much smaller than the state vector (i.e., \(m\ll n\)), it is often desired to compute the optimal feedback gain matrix \(K^{*}\) without explicitly solving for \(P^{*}\). To this end, we can rewrite the LQR objective function \(J(x,u)\) as a function solely depending on \(K\) by leveraging the linearity of the optimal controller \(u(t)=-Kx(t)\). With standard algebraic manipulation, it turns out that

\[J(x,u)=f(K)=\begin{cases}\operatorname{Tr}[P(K)\Sigma_{0}]&K\in\mathcal{S}_{ K},\\ \infty&\text{otherwise},\end{cases}\] (5)

where

\[P(K)=\int_{0}^{\infty}e^{(A-BK)^{\top}t}\left(Q+K^{\top}RK\right)e^{(A-BK)t} \ \mathrm{d}t,\] (6)

and \(\Sigma_{0}\coloneqq\mathbb{E}_{\xi\sim\mathcal{D}}[\xi\xi^{\top}]\). Given this reformulation, the search for the optimal feedback gain \(K^{*}\) reduces to minimizing the unconstrained objective function \(f(K)\).

In practice, the matrices \(A,B,Q,R\) often possess sparsity structures that can be leveraged by quantum computers. We make the assumptions on the efficient quantum access model.

**Assumption 1** (Sparse-access matrices).: We assume \(A\), \(B\), \(Q\), and \(R\) are \(s\)-sparse, i.e., there are at most \(s\) non-zero entries in each row/column. For \(M\in\{A,B,Q,R\}\), we assume access to an efficient procedure2 that loads the matrix into quantum data:

Footnote 2: This input model is sometimes referred to as the _sparse-input oracle_ model in the literature. It is a standard assumption in many applications, see [2, 13, 22] for details.

\[|i\rangle|k\rangle\mapsto|i\rangle|r_{i,k}\rangle,\quad|\ell\rangle|j \rangle\mapsto|c_{\ell,j}\rangle|j\rangle,\quad|i\rangle|j\rangle|0\rangle \mapsto|i\rangle|j\rangle|M_{ij}\rangle,\] (7)

where \(r_{i,k}\) is the index of the \(k\)-th non-zero entry of the \(i\)-th row of \(M\), \(c_{\ell,j}\) is the index of the \(\ell\)-th non-zero entry of the \(j\)-th column of \(M\), and \(M_{ij}\) is a fixed-length binary description of the \((i,j)\)-th entry of \(M\).

With quantum access to the problem data, we aim to determine the optimal linear feedback gain \(K^{*}\) so that the objective function \(f(K)\) is minimized, as summarized in the following problem statement:

**Problem 1**.: Assume \((A,B)\) is a controllable pair and \(Q\), \(R\) are positive-definite. Given quantum access to \(A,B,Q,R\) in the sense of Assumption 1, we want to compute an \(\varepsilon\)-approximate solution \(K\) such that \(\|K-K^{*}\|_{F}\leq\varepsilon\), where \(\varepsilon>0\) is prefixed.

### Main Contributions

In this paper, we propose an end-to-end quantum algorithm for solving LQR problems that exhibits the desired quantum advantage in the large-scale setting (i.e., in the parameter regime \(m\ll n\)). A detailed comparison between ours and various other methods is given in Table 1. Compared with state-of-the-art classical methods, our algorithm achieves a super-quadratic speedup in terms of the state vector dimension \(n\). To the best of our knowledge, this is the first end-to-end quantum application to linear control problems with provable speedup.

Our algorithm is based on a novel policy gradient strategy to find globally optimal solutions for linear-quadratic control problems. A brief overview of the policy gradient method for LQR is available in Section 3.2. In each iteration cycle, our algorithm executes a fast,

\begin{table}
\begin{tabular}{c|c} \hline \hline
**Methods** & **Time/Gate Complexity** \\ \hline Schur method [35, 48] & \(\widetilde{\mathcal{O}}(n^{3})\) \\ \hline Newton-Kleinman method [32, 47] & \(\widetilde{\mathcal{O}}(n^{3})\) \\ \hline (Model-based) policy gradient [45] & \(\widetilde{\mathcal{O}}(n^{3}\cdot\operatorname{poly}(\varepsilon^{-1}))\) \\ \hline
**Ours** & \(\widetilde{\mathcal{O}}(n\varepsilon^{-1.5})\) (Theorem 7) \\ \hline \hline \end{tabular}
\end{table}
Table 1: Asymptotic cost of different methods for LQR.

quantum-assisted differentiable simulator to obtain robust gradient estimates, as detailed in Theorem 31. The gradient estimates are then utilized by a classical computer to update the control policy \(K\).

As illustrated in Figure 1, with the back-and-forth iterations between the quantum simulator and a classical computer, the control policy \(K\) converges to the optimal policy \(K^{*}\) at a linear rate, leading to an end-to-end resolution of the LQR problem.

Our quantum algorithm design can be regarded as a novel realization of the hybrid quantum-classical computing paradigm, where collaboration between classical and quantum computers significantly reduces the burden on the quantum side. Moreover, we provide explicit constructions of the quantum simulator and analyze the convergence rate of the policy gradient based on our end-to-end model. These desirable attributes make our proposed design more practical and relevant in the early fault-tolerant era [29].

Notably, we propose a new quantum algorithm for solving the Lyapunov equation, a fundamental task in optimal control theory [25]. Based on an integral representation of the solution and a rich toolbox of methods for quantum numerical linear algebra, our algorithm can produce a quantum representation of the solution matrix in a cost that is polylogarithmic in the matrix dimension \(n\) (see Theorem 4), leading to an _exponential speedup_ over existing classical methods [51]. Moreover, since the matrix Lyapunov equation is fundamental to many control problems, we foresee that our quantum algorithm may play an important role in finding speedups for other tasks.

The fast quantum algorithm for the Lyapunov equation enables us to develop a quantum gradient estimation subroutine in near-optimal cost, as detailed in Theorem 31. Compared with the conventional gradient estimation techniques based on stochastic approximation (e.g., one- and two-point gradient estimators [45]), our quantum gradient estimation benefits from the explicit exploitation of the analytical form of the gradient. Numerical experiments suggest that our gradient estimation is robust and often leads to faster convergence in practice, as demonstrated in Section 5.3.

## 2 Related Work

We survey related work on model-based and model-free linear-quadratic control, differentiable physics, and quantum reinforcement learning in this section.

Model-based linear-quadratic control._Model-based_ optimal control [17, 50] refers to the scenario where historical measurement data explicitly gives (or estimates) the problem description. In this case, the optimal linear feedback gain \(K^{*}\) can be computed by solving the algebraic Riccati equation (ARE), as detailed in Section 1.1. Commonly used numerical methods for ARE include factorization methods (e.g., Schur method [35, 48]) and iterative methods (e.g., Newton-Kleinman method [20, 32, 47]). These methods require computing matrix factorization or matrix inverse, which in general leads to a \(O(n^{3})\) run time (assuming \(m\leq n\)). Some methods for ARE can achieve \(\mathcal{O}(n)\) runtime under strong assumptions such as the solution \(P^{*}\) is of low rank [8]. It is also possible to solve LQR by reformulating it as a semidefinite programming (SDP) problem [14]. We do not dive into the SPD approach as it does not demonstrate superior asymptotic scaling compared to other direct methods.

Model-free linear-quadratic control.LQR can be regarded as a continuous-time analog of the discrete Markov Decision Process (MDP) model and many techniques from reinforcement learning (RL) can be introduced to learn the optimal feedback gain (i.e., _control policy_), such as policy gradient [19, 45], natural gradient [25], and policy iteration [10].

Figure 1: Differentiable quantum computing for linear control.

These RL-based methods are particularly useful when we have access to the observed costs but the system model can not be directly constructed.

Differentiable physics and quantum computing.The differentiable programming paradigm has been applied to many dynamical systems for learning [46] and control [53]. Those gradient-based methods can be used in reinforcement learning [61], inverse problems [27], optimization [5], design [60], etc. People have developed differentiable pipelines for various dynamics including fluids [59], rigid body [49], soft body [26], and other hybrid systems [52]. Recently, [37] have derived a differentiable analog quantum computing pipeline for quantum optimization and control. In this work, we will focus on using differentiable quantum computing to accelerate a widely studied classical problem - linear control synthesis.

Quantum reinforcement learning.Recently, quantum-accelerated reinforcement learning has attracted significant attention as it demonstrates the potential for computational speedup [43]. It has been shown that quantum computers can be used to compute policy gradients given coherent access to a Markov Decision tree model [15, 28]. Some works also discuss the quantum policy iteration method for RL, see [12, 58]. It is worth noting that the existing works are usually based on a strong quantum access model and it remains unclear what the cost of constructing such models is in an _end-to-end_ sense.

## 3 Preliminaries

### Introduction to Quantum Computing

All quantum states of a quantum system form a Hilbert space, which is isomorphic to \(\mathbb{C}^{N}\). We may assume \(N=2^{n}\) and \(n\) is a non-negative integer. An element \(|\psi\rangle\) in this Hilbert space is then noted as a \(N\)-dimensional quantum state, where

\[|\psi\rangle=\begin{bmatrix}v_{0}\\ v_{1}\\ \vdots\\ v_{N-1}\end{bmatrix},\] (8)

where \(v_{i}\in\mathbb{C},i\in\{0,1,\cdots,N-1\}\). Also, we often use \(\langle\psi|\) to denote the conjugate transpose of \(|\psi\rangle\). For any \(c\neq 0\), \(c|\psi\rangle\) and \(|\psi\rangle\) refer to the same state, thus without loss of generality, \(\||\psi\rangle\|=1\) always holds. Specifically, a one qubit system corresponds to the aforementioned Hilbert space with \(n=1\).

Given \(m\) quantum states \(|\psi_{1}\rangle,|\psi_{2}\rangle,\cdots,|\psi_{m}\rangle\) from \(m\) quantum systems, then

\[|\psi\rangle=|\psi_{1}\rangle\otimes|\psi_{2}\rangle\otimes\cdots\otimes|\psi _{m}\rangle\] (9)

is a quantum state in the space that consists \(m\) subspaces.

The evolution of a quantum state can be described by a unitary operator \(U\), meaning

\[U^{\dagger}U=UU^{\dagger}=I.\] (10)

We often note these operations as gates on the quantum circuit. One important type of unitary operators are the Pauli operators, namely

\[X=\begin{bmatrix}0&1\\ 1&0\end{bmatrix},\quad Y=\begin{bmatrix}0&-i\\ i&0\end{bmatrix},\quad Z=\begin{bmatrix}1&0\\ 0&-1\end{bmatrix}.\] (11)

They form a basis of all the linear operators acting on \(\mathbb{C}^{2}\).

For the quantum measurement, given a quantum observable \(H\), we can do the measurement of a quantum state \(|\psi\rangle\). Specifically, after the measurement on \(|\psi\rangle\), the state collapses to \(\frac{P_{m}|\psi\rangle}{\sqrt{p_{m}}}\), and we get an outcome \(\lambda_{m}\) with probability \(p_{m}=\langle\psi|P_{m}|\psi\rangle\), where

\[H=\sum_{m}\lambda_{m}P_{m}\] (12)

is the spectral decomposition of \(H\).

### Policy Gradient for LQR

For all stabilizing feedback gains \(K\in S_{K}\), the gradient of the objective function \(f(K)\) as defined in (5) has the following closed-form expression [38, 40]:

\[\nabla f(K)=2(RK-B^{\top}P(K))X(K),\] (13)

where \(P(K)\) is given in (6), and \(X(K)\) is determined by

\[X(K)=\int_{0}^{\infty}e^{(A-BK)t}\Sigma_{0}e^{(A-BK)^{\top}t}\;\mathrm{d}t.\] (14)

The (direct) policy gradient method for LQR minimizes the objective \(f(K)\) via the vanilla gradient update rule \(K\gets K-s\nabla f(K)\), where \(s>0\) is a fixed step size. Given sufficiently small \(s\), it has been shown that the policy gradient method converges at a linear rate [45, Theorem 2]. In practice, however, the policy gradient is often estimated through stochastic approximation, such as one- and two-point estimation [45]. While these zeroth-order gradient estimation methods are less demanding in terms of computational cost, they tend to be sensitive to random perturbations and slow to converge.

In this paper, we propose a fast quantum algorithm that outputs a robust estimate of the gradient in \(\widetilde{\mathcal{O}}(n)\) time (assuming \(m\ll n\), see Theorem 31). Leveraging the quantum gradient estimation subroutine, we recover the linear convergence rate using robust gradient descent, as detailed in Proposition 34.

### Quantum Data Structure

To perform policy gradient in the training process, the linear feedback gain \(K\) is stored in a _quantum-accessible data structure_ as proposed in [30]. This data structure allows intermediate updates on \(K\) and efficient quantum queries to \(K\) as a block-encoded matrix. This data structure is a purely classical representation of \(K\), and quantum access to this data structure (e.g., through qRAM [23]) is required to build the block-encoding of \(K\). In the literature, this data structure is also known as _classical-write, quantum-read_ qRAM [7, 54].

**Definition 3** (Block-encoding).: Suppose that \(M\) is an \(p\)-qubit operator, \(\alpha,\varepsilon\in\mathbb{R}^{+}\) and \(r\in\mathbb{N}\), then we say that the \((p+r)\)-qubit unitary \(U_{M}\) is an \((\alpha,r,\varepsilon)\)-block-encoding of \(M\), if

\[\|M-\alpha(\left\langle 0\right|^{r}\otimes\mathbb{I})U_{M}(\left|0\right\rangle ^{r}\otimes\mathbb{I})\|\leq\varepsilon.\] (15)

In this paper, the growth of ancilla qubits (space complexity) is dominated by the number of elementary gates (gate complexity). Therefore, when referring to a specific block-encoding, we often omit the number of ancilla qubits (i.e., the parameter \(r\)) for simplicity.

**Lemma 1**.: _Let \(K\in\mathbb{R}^{m\times n}\). There exists a data structure to store \(K\) with the following properties: (1) the size of the data structure is \(\mathcal{O}\left(mn\log^{2}(mn)\right)\), (2) the time to store a new entry \((i,j,\hat{K}_{i,j})\) is \(\mathcal{O}\left(\log^{2}(mn)\right)\), and (3) for any \(\varepsilon>0\), a quantum algorithm can implement a \((\|K\|_{F},\lceil\log_{2}n\rceil+2,\varepsilon)\)-block-encoding of \(K\) in time \(\mathcal{O}\left(\operatorname{poly}\log(n,1/\varepsilon)\right)\). There also exists an analogous data structure for \(\hat{K}^{\top}\)._

Proof.: We use the data structure as described in [30, Theorem 5.1]. To construct the block-encoding, we utilize [22, Lemma 50]. 

### Quantum Simulation of Linear Dynamics

Quantum computers can simulate certain linear ordinary differential equations (ODEs) exponentially faster than classical computers [3, 4, 9, 22, 33]. In this paper, we present a quantum simulation subroutine based on quantum linear system solvers (QLSS) [9, 33], as described below. While this approach may not be optimal in terms of state preparation cost compared to quantum singular value transformation [22] or linear combination of Hamiltonian simulation [3, 4], it allows us to incorporate the Hurwitz stability of the system.

**Theorem 2** (Informal version of Theorem 17).: _Suppose that \(\mathcal{A}\in\mathbb{R}^{n\times n}\) is a Hurwitz matrix, and \(O_{\mathcal{A}}\) is an \((\alpha,0)\)-block-encoding of \(\mathcal{A}\). For an arbitrary \(t>0\), we can implement a \((\zeta t,\varepsilon)\)-block-encoding of \(e^{\mathcal{A}t}\) using \(\widetilde{\mathcal{O}}\left(\alpha\rho t\cdot\mathrm{poly}\log(1/\varepsilon)\right)\) queries to \(O_{A}\), and \(\widetilde{\mathcal{O}}\left(\alpha\rho t\cdot\mathrm{poly}\log(1/\varepsilon)\right)\) queries to additional gates. Here, the normalization factor \(\zeta=\mathcal{O}(\alpha\rho)\), and the constant \(\rho\) is solely determined by \(\mathcal{A}\)._

More details and the proof of Theorem 2 can be found in Appendix C. Note that the dependence on \(t\) in the above result can be further improved using a standard padding technique, but for simplicity, we do not discuss this minor improvement, as it does not affect our main end-to-end result. We also notice a technique called quantum eigenvalue transformation (QEVT), recently proposed by Low and Su [42]. While this method cannot be directly applied to Hurwitz-stable systems, it may be enhanced to provide a simulation algorithm with a similar cost, as discussed in Appendix D.

## 4 Quantum Algorithm for the Lyapunov Equation

The (continuous-time) Lyapunov equation is a linear matrix equation of the following form,

\[\mathcal{A}X+X\mathcal{A}^{\top}+\Omega=0.\] (16)

Since this equation is linear in terms of the matrix \(X\), it is possible to derive a vectorization form of (16) and solve it using a quantum linear system algorithm [11, 24]. In this paper, we propose a new quantum algorithm for solving the Lyapunov equation based on an integral representation formula. Our algorithm directly prepares a block-encoded solution matrix \(X^{*}\). Compared to the previous approach, our method leads to an exponentially faster quantum objective function evaluation algorithm (see Theorem 5) and a new quantum gradient estimation subroutine (see Theorem 6).

### Representation

Given a positive-definite \(Q\), there exists a unique positive-definite \(X^{*}\) satisfying (16) if and only if \(\mathcal{A}\) is Hurwitz. The unique positive solution is given by

\[X^{*}=\int_{0}^{\infty}e^{\mathcal{A}t}\Omega e^{\mathcal{A}^{\top}t}\ \mathrm{d}t.\] (17)

The integral formula (17) suggests that the solution to the Lyapunov equation can be computed using a numerical integration technique. For a finite \(\tau>0\), we define

\[X_{\tau}\coloneqq\int_{0}^{\tau}e^{\mathcal{A}t}\Omega e^{\mathcal{A}^{\top}t }\ \mathrm{d}t.\] (18)

For any arbitrary \(\varepsilon>0\), we find that a \(\tau=\widetilde{\mathcal{O}}(\log(1/\varepsilon))\) is sufficient to ensure an \(\varepsilon\)-approximate solution. We denote \(\kappa\coloneqq\left\|X^{*}\right\|/\lambda_{\min}(\Omega)\).

**Lemma 3** (Numerical integration).: _For any \(\varepsilon>0\), we have \(\left\|X^{*}-X_{\tau}\right\|\leq\varepsilon\), provided that_

\[\tau=\kappa\log\biggl{(}\frac{\left\|\Omega\right\|\left\|X^{*}\right\|\kappa }{\varepsilon\lambda_{\min}(X^{*})}\biggr{)}.\] (19)

Proof.: Note that \(\left\|X^{*}-X_{\tau}\right\|=\left\|\int_{\tau}^{\infty}e^{\mathcal{A}t} \Omega e^{\mathcal{A}^{\top}t}\ \mathrm{d}t\right\|\leq\int_{\tau}^{\infty}\left\|\Omega \right\|\|e^{\mathcal{A}t}\|\|e^{\mathcal{A}^{\top}t}\|\ \mathrm{d}t\), where \(\|e^{\mathcal{A}t}\|\) (or \(\|e^{\mathcal{A}^{\top}t}\|\)) is upper bounded by \(\frac{\left\|X^{*}\right\|}{\lambda_{\min}(X^{*})}e^{-t/\kappa}\) (see [44, Lemma 12]). It follows that \(\left\|X^{*}-X_{\tau}\right\|\leq\frac{\left\|\Omega\right\|\left\|X^{*}\right\| \kappa}{\lambda_{\min}(X^{*})}e^{-\tau/\kappa}\). Therefore, an integration time as given in (19) guarantees that \(\left\|X^{*}-X_{\tau}\right\|\leq\varepsilon\)

### Algorithm Complexity Analysis

The matrix \(X_{\tau}\) can be approximated by a trapezoidal rule with \((K+1)\) quadrature node points, namely,

\[X_{\tau}\approx\sum_{k=0}^{K}w_{k}e^{\mathcal{A}t_{k}}\Omega e^{\mathcal{A}^{ \top}t_{k}}=\sum_{k=0}^{K}w_{k}\mathscr{F}(t_{k}),\] (20)

where \(w_{k}=\frac{(2-1_{k=0,K})\tau}{2K}\), \(t_{k}=\frac{k_{\tau}}{K}\), and \(\mathscr{F}(t)\coloneqq e^{\mathcal{A}t}\Omega e^{\mathcal{A}^{\top}t}\). The summation in (20) can be computed on a quantum computer by performing linear combinations of block-encoded matrices, which we will explain shortly.

**Definition 4** (Select oracle).: Let \(\mathcal{A}\in\mathbb{R}^{n\times n}\) be a Hurwitz matrix. Given an integer \(K>0\) and two positive scalars \(\tau,\varepsilon>0\), we define the following unitary (named as the _select oracle_):

\[\mathrm{select}(\mathcal{A},\varepsilon)\coloneqq\sum_{k=0}^{K}|k\rangle\! \langle k|\otimes U_{k},\] (21)

where for each \(k=0,\ldots,K\), \(U_{k}\) is a \((\zeta t_{k},\varepsilon)\)-block-encoding of \(e^{\mathcal{A}t_{k}}\) with \(t_{k}=k\tau/K\). Here, \(\zeta\) denotes some parameter that only depends on \(\mathcal{A}\).

Now, we consider two select oracles:

\[\mathrm{select}(A,\varepsilon)\coloneqq\sum_{k=0}^{K}|k\rangle\! \langle k|\otimes U_{k},\quad\mathrm{select}(A^{\top},\varepsilon)\coloneqq \sum_{k=0}^{K}|k\rangle\!\langle k|\otimes V_{k},\] (22)

where for each \(k=0,\ldots,K\), \(U_{k}\) (or \(V_{k}\)) denotes a block-encoding of \(e^{\mathcal{A}t_{k}}\) (or \(e^{\mathcal{A}^{\top}t_{k}}\)) with normalization factor \(\zeta t_{k}\). Let \(O_{\Omega}\) be a \((\eta,0)\)-block-encoding of \(\Omega\), and we find that

\[\mathrm{select}(A,\varepsilon)(I\otimes O_{\Omega})\mathrm{select}(A^{\top}, \varepsilon)=\sum_{k=0}^{K}|k\rangle\!\langle k|\otimes W_{k},\] (23)

where \(W_{k}\coloneqq U_{k}O_{\Omega}V_{k}\) is a \((\eta\zeta^{2}t_{k}^{2},2\zeta\eta\varepsilon)\)-block-encoding of the matrix \(\mathscr{F}(t_{k})\). Denoting \(\lambda_{k}\coloneqq w_{k}k^{2}\), then it is clear that \(\sum_{k=0}^{K}\lambda_{k}W_{k}\) is a block-encoding of \(X_{\tau}\). Thus we can implement a block-encoded \(X_{\tau}\) on a quantum computer using a technique known as linear combination of unitaries (LCU) [22, Lemma 52]. The rigorous complexity of this quantum algorithm is given in the following theorem, for which a complete proof is provided in Appendix E.

**Theorem 4**.: _Suppose that \(\mathcal{A}\in\mathbb{R}^{n\times n}\) is Hurwitz and \(\Omega\in\mathbb{R}^{n\times n}\) is positive-definite. Let \(O_{\mathcal{A}}\) be an \((\alpha,0)\)-block-encoding of \(\mathcal{A}\) and \(O_{\Omega}\) be an \((\eta,0)\)-block-encoding of \(\Omega\). Then, we can implement a \((\gamma,\varepsilon)\)-block-encoding of \(X^{*}\), the unique solution to the Lyapunov equation (16), using a single query to \(O_{\Omega}\), \(\widetilde{\mathcal{O}}\left(\alpha^{2}\sqrt{\frac{\eta}{\varepsilon}}\right)\) queries to controlled \(O_{\mathcal{A}}\) and its inverse, and \(\widetilde{\mathcal{O}}\left(\alpha^{2}\sqrt{\frac{\eta}{\varepsilon}}\right)\) queries to other additional elementary gates. Here \(\gamma=\widetilde{\mathcal{O}}(\alpha^{2}\eta)\)._

### Objective Function Evaluation

As a direct consequence of Theorem 4, we can evaluate the objective function value \(f(K)\) for a given \(K\in\mathcal{S}_{K}\) in a cost that is logarithmic in the dimension parameter \(n\). This result demonstrates an exponential quantum advantage for the objective function evaluation task, as any known classical algorithm for this task requires at least matrix multiplication time.

**Theorem 5**.: _Assume that we have efficient procedures (as described in Assumption 1) to access the problem data \(A,B,Q,R\) in \(\widetilde{\mathcal{O}}(\mathrm{poly}\log(n))\) time. Let \(K\in\mathcal{S}_{K}\) be a stabilizing policy stored in a quantum-accessible data structure. We can estimate the objective function \(f(K)\) up to multiplicative error \(\theta\) in cost \(\widetilde{\mathcal{O}}\left(\frac{1}{\theta^{2}}\right)\)._

Proof.: Given a \(K\in\mathcal{S}_{K}\), we can evaluate the objective function \(f(K)\) via the formula \(f(K)=\mathrm{Tr}[P(K)\Sigma_{0}]\). Here, without loss of generality, we assume \(\Sigma_{0}=\mathbb{I}\). \(P(K)\) has a closed-form representation as in (6), which corresponds to the unique positive solution to the Lyapunov equation

\[(A-BK)^{\top}P+P(A-BK)+\left(Q+K^{\top}RK\right)=0.\] (24)We denote \(\mathcal{A}=A-BK\), and \(\Omega=Q+K^{\top}RK\). By Lemma 11 and Remark 1, we can block-encode \(\mathcal{A}\) with normalization factor \(s(\|K\|_{F}+1)\) and \(\Omega\) with normalization factor \(s(\|K\|_{F}^{2}+1)\), both in cost \(\mathcal{O}(\operatorname{poly}\log(n,s))\). Suppose that \(f(K)=a\), it follows from Lemma 8 that \(\|K\|_{F}\leq\mathcal{O}(a)\). Therefore, by Theorem 4, we can implement a \((\gamma,\varepsilon)\)-block-encoding of \(P(K)\) in cost \(\tilde{\mathcal{O}}\left(a^{3}\rho\sqrt{\frac{s^{5}}{\varepsilon}}\right)\), where \(\gamma\leq\widetilde{\mathcal{O}}(a^{4}\rho^{2}\kappa^{3})\). Note that \(P(K)\) is a Hermitian matrix, and \(\lambda_{\min}(P(K))\geq\lambda_{\min}(Q)\), by invoking Theorem 25, we can estimate \(f(K)=\operatorname{Tr}[P(K)]\) up to a multiplicative error \(\theta\) in cost \(\widetilde{\mathcal{O}}\left(\frac{a^{3}\rho}{\theta}\sqrt{\frac{\gamma^{3} \kappa^{5}}{\varepsilon}}\right)\leq\widetilde{\mathcal{O}}\left(\frac{a^{13 }\rho^{6}\kappa^{10}}{\theta^{2}}\right)\). Here, the error parameter must be chosen so that \(\varepsilon\leq\widetilde{\mathcal{O}}(\theta^{2}/\gamma^{2})\). 

## 5 Quantum Policy Gradient for Large-Scale Control

### Quantum Gradient Estimation

**Definition 5**.: Given any \(K\in\mathcal{S}_{K}\), we call \(G\in\mathbb{R}^{m\times n}\) a \(\theta\)-_robust estimate_ of \(\nabla f(K)\) if it approximates the gradient \(\nabla f(K)\) up to a multiplicative error \(\theta\), i.e.,

\[\|G-\nabla f(K)\|_{F}\leq\theta\|\nabla f(K)\|_{F}.\] (25)

Here, we utilize the close-form expression of the policy gradient \(\nabla f(K)\), as shown in (13), to construct a quantum algorithm for gradient estimation. The complete theorem statement and the proof are in Appendix G.

**Theorem 6** (Informal version of Theorem 31).: _Assume we have efficient procedures (as described in Assumption 1) to access \(A,B,Q,R\) in \(\mathcal{O}(\operatorname{poly}\log(n))\) time. Let \(K\in\mathcal{S}_{K}\) be a stabilizing policy stored in a quantum-accessible data structure. Provided that \(\|K-K^{*}\|>\varepsilon\) and \(m\ll n\), we can compute a \(\theta\)-robust estimate of \(\nabla f(K)\) in cost \(\widetilde{\mathcal{O}}\left(\frac{n}{\theta^{1.5}\varepsilon^{1.5}}\right)\)._

### Quantum Policy Gradient

Our main quantum algorithm for LQR is summarized in Algorithm 1.

``` Inputs:\(A,B,Q,R\) (problem data), \(K_{0}\in\mathcal{S}_{K}\) (initial guess), \(\sigma>0\) (step size/learning rate), \(\theta\) (robustness parameter), \(N\) (number of iterations) Output: an approximate solution \(K_{N}\) for\(k\in\{0,1,\ldots,N-1\}\)do  Compute a \(\theta\)-robust estimate of \(\nabla f(K_{k})\), denoted as \(G_{k}\), using Theorem 6.  Update the quantum-accessible data structure using the rule: \(K_{k+1}=K_{k}-\sigma G_{k}\). endfor ```

**Algorithm 1** Quantum policy gradient

We can prove that the iterates in Algorithm 1 converges to the optimal control policy \(K^{*}\) at a linear rate (Proposition 34). It follows that our algorithm can find an \(\varepsilon\)-approximate optimal policy with an end-to-end cost \(\widetilde{\mathcal{O}}\left(\frac{n}{\varepsilon^{1.5}}\right)\).

**Theorem 7** (Informal version of Theorem 35).: _Assume that we have efficient procedures (as described in Assumption 1) to access the problem data \(A,B,Q,R\) in \(\mathcal{O}(\operatorname{poly}\log(n))\) time. Let \(K_{0}\in\mathcal{S}_{K}\) be a stabilizing policy and assume that \(m\ll n\). Then, Algorithm 1 outputs an \(\varepsilon\)-approximate solution to Problem 1 in cost \(\widetilde{\mathcal{O}}\left(\frac{n}{\varepsilon^{1.5}}\right)\)._

### Numerical Experiments

Correctness.We conduct a numerical experiment to showcase the correctness of our quantum policy gradient algorithm. Following a similar setup as in [45], a mass-spring-damper system with \(g=4\) masses is used for constructing our LQR problem. The state \(x=[p^{\top},v^{\top}]^{\top}\in\mathbb{R}^{2g}\) contains positions and velocities, with dynamic and input matrices,

\[A=\begin{bmatrix}0&I\\ -T&-T\end{bmatrix},B=\begin{bmatrix}0\\ I\end{bmatrix},Q=I+100e_{1}e_{1}^{\top},R=I+4e_{2}e_{2}^{\top},\] (26)

where \(0,I\) are \(g\times g\) zero and identity matrices, \(e_{i}\) is the \(i\)th unit vector, and matrix \(T\) has 2 on the main diagonal and -1 on the first super- and sub-diagonal. In Figure 2, we run our method against the classical model-free gradient-based method [45]. It shows that our model-based policy gradient converges much faster to the ground truth ARE solution \(K^{*}\). In the benchmark example [45], ours converges within 750 iterations, while the classical method takes \(2\times 10^{4}\) iterations (_orders of magnitude_ longer). In Figure 2 (c), we increase the system size by scaling \(g\) from 4 to 64. Both methods run on a classical simulator with Intel i9-10980XE CPU. Our method runs much faster than [45] by **nearly 3 orders of magnitude**. The code for both methods can be seen at https://github.com/YilingQiao/diff_lqr. Additional numerical results can be found in Appendix I.

## 6 Conclusion and Future Work

In this paper, we propose the first quantum algorithm for solving linear-quadratic control problems that achieves end-to-end quantum speedups. Our quantum algorithm utilizes an exponentially faster quantum linear dynamics simulator combined with a policy gradient method. Compared to classical approaches relying on matrix factorization and iterations, our method achieves super-quadratic speedup in the large-scale regime (i.e., \(m\ll n\)). Moreover, the hybrid quantum-classical algorithm design makes our algorithm a promising candidate for practical quantum advantage in the near horizon. We also provide numerical evidence to demonstrate the robustness and favorable convergence behavior of our method.

Limitations and Future Work.Accelerating optimal control and reinforcement learning using quantum computers remains an emerging research topic. Our work has focused on the theoretical aspects of quantum advantage for LQR, a classic optimal control problem of fundamental importance in both theory and practice. However, for special cases [17], we have no guarantee that our quantum algorithm still applies, since Lemma 33 may not hold. In the future, we aim to explore both the practical utility of quantum computing for such tasks and its potential for handling more complex optimal control scenarios, such as non-quadratic and nonlinear problems.

## Acknowledgment

We thank Kaiqing Zhang for the helpful discussions and the anonymous reviewers for their helpful feedback. This work was supported in part by the U.S. Department of Energy Office of Science, National Quantum Information Science Research Centers, Quantum Systems Accelerator, Air Force Office of Scientific Research (Award#FA9550-21-1-0209), the U.S. National Science Foundation Career Grant (CCF-1942837), a Sloan research fellowship, Meta Research PhD Fellowship, National Science Foundation Graduate Research Fellowship (Grant No. DGE 2236417), the Simons Quantum Postdoctoral Fellowship, a Simons Investigator award (Grant No. 825053), and Dr. Barry Mersky & Capital One E-Nnovate Endowed Professorships.

Figure 2: **Numerical Results on Convergence.** Following the mass-spring-damper setup in [45], our policy gradient descent algorithm converges much faster than [45].

## References

* [1] Amira Abbas, Andris Ambainis, Brandon Augustino, Andreas Bartschi, Harry Buhrman, Carleton Coffrin, Giorgio Cortiana, Vedran Dunjko, Daniel J Egger, Bruce G Elmegreen, et al. Quantum optimization: Potential, challenges, and the path forward, 2023. arXiv:2312.02279.
* [2] Dorit Aharonov and Amnon Ta-Shma. Adiabatic quantum state generation and statistical zero knowledge. In _Proceedings of the thirty-fifth annual ACM symposium on Theory of computing_, pages 20-29, 2003.
* [3] Dong An, Andrew M Childs, and Lin Lin. Quantum algorithm for linear non-unitary dynamics with near-optimal dependence on all parameters, 2023. arXiv:2312.03916.
* [4] Dong An, Jin-Peng Liu, and Lin Lin. Linear combination of Hamiltonian simulation for nonunitary dynamics with optimal state preparation cost. _Physical Review Letters_, 131(15):150603, 2023.
* [5] Rika Antonova, Jingyun Yang, Krishna Murthy Jatavallabhula, and Jeannette Bohg. Rethinking optimization with differentiable simulation from a global perspective. In _Proceedings of The 6th Conference on Robot Learning_. PMLR, 2023.
* [6] William F Arnold and Alan J Laub. Generalized eigenproblem algorithms and software for algebraic Riccati equations. _Proceedings of the IEEE_, 72(12):1746-1754, 1984.
* [7] Brandon Augustino, Giacomo Nannicini, Tamas Terlaky, and Luis F Zuluaga. Quantum interior point methods for semidefinite optimization. _Quantum_, 7:1110, 2023.
* [8] Peter Benner, Zvonimir Bujanovic, Patrick Kurschner, and Jens Saak. A numerical comparison of different solvers for large-scale, continuous-time algebraic Riccati equations and lqr problems. _SIAM Journal on Scientific Computing_, 42(2):A957-A996, 2020.
* [9] Dominic W Berry. High-order quantum algorithm for solving linear differential equations. _Journal of Physics A: Mathematical and Theoretical_, 47(10):105301, 2014.
* [10] Steven J Bradtke, B Erik Ydstie, and Andrew G Barto. Adaptive linear quadratic control using policy iteration. In _Proceedings of 1994 American Control Conference-ACC'94_, volume 3, pages 3475-3479. IEEE, 1994.
* [11] Shantanav Chakraborty, Andras Gilyen, and Stacey Jeffery. The power of block-encoded matrix powers: improved regression techniques via faster Hamiltonian simulation, 2018. arXiv:1804.01973.
* [12] El Amine Cherrat, Iordanis Kerenidis, and Anupam Prakash. Quantum reinforcement learning via policy iteration. _Quantum Machine Intelligence_, 5(2):30, 2023.
* [13] Andrew M Childs, Robin Kothari, and Rolando D Somma. Quantum algorithm for systems of linear equations with exponentially improved dependence on precision. _SIAM Journal on Computing_, 46(6):1920-1950, 2017.
* [14] Alon Cohen, Avinatan Hasidim, Tomer Koren, Nevena Lazic, Yishay Mansour, and Kunal Talwar. Online linear quadratic control. In _International Conference on Machine Learning_, pages 1029-1038. PMLR, 2018.
* [15] Arjan Cornelissen, Yassine Hamoudi, and Sofiene Jerbi. Near-optimal quantum algorithms for multivariate mean estimation. In _Proceedings of the 54th Annual ACM SIGACT Symposium on Theory of Computing_, pages 33-43, 2022.
* [16] Nikolaus Correll. Parameter estimation and optimal control of swarm-robotic systems: A case study in distributed task allocation. In _2008 IEEE International Conference on Robotics and Automation_, pages 3302-3307. IEEE, 2008.
* [17] Sarah Dean, Horia Mania, Nikolai Matni, Benjamin Recht, and Stephen Tu. On the sample complexity of the linear quadratic regulator. _Foundations of Computational Mathematics_, 20(4):633-679, 2020.

* [18] Karthik Elamvazhuthi and Spring Berman. Optimal control of stochastic coverage strategies for robotic swarms. In _2015 ieee international conference on robotics and automation (icra)_, pages 1822-1829. IEEE, 2015.
* [19] Maryam Fazel, Rong Ge, Sham Kakade, and Mehran Mesbahi. Global convergence of policy gradient methods for the linear quadratic regulator. In _International conference on machine learning_, pages 1467-1476. PMLR, 2018.
* [20] Franziska Feitzinger, Timo Hylla, and Ekkehard W Sachs. Inexact Kleinman-Newton method for Riccati equations. _SIAM Journal on Matrix Analysis and Applications_, 31(2):272-288, 2009.
* [21] Greg Foderaro, Pingping Zhu, Hongchuan Wei, Thomas A Wettergren, and Silvia Ferrari. Distributed optimal control of sensor networks for dynamic target tracking. _IEEE Transactions on Control of Network Systems_, 5(1):142-153, 2016.
* [22] Andras Gilyen, Yuan Su, Guang Hao Low, and Nathan Wiebe. Quantum singular value transformation and beyond: exponential improvements for quantum matrix arithmetics. In _Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of Computing_, pages 193-204, 2019.
* [23] Vittorio Giovannetti, Seth Lloyd, and Lorenzo Maccone. Quantum random access memory. _Physical review letters_, 100(16):160501, 2008.
* [24] Aram W Harrow, Avinatan Hassidim, and Seth Lloyd. Quantum algorithm for linear systems of equations. _Physical review letters_, 103(15):150502, 2009.
* [25] Bin Hu, Kaiqing Zhang, Na Li, Mehran Mesbahi, Maryam Fazel, and Tamer Basar. Toward a theoretical foundation of policy optimization for learning control policies. _Annual Review of Control, Robotics, and Autonomous Systems_, 6:123-158, 2023.
* [26] Yuanming Hu, Luke Anderson, Tzu-Mao Li, Qi Sun, Nathan Carr, Jonathan Ragan-Kelley, and Fredo Durand. DiffTaichi: Differentiable programming for physical simulation. In _ICLR_, 2020.
* [27] Krishna Murthy Jatavallabhula, Miles Macklin, Florian Golemo, Vikram Voleti, Linda Petrini, Martin Weiss, Breandan Considine, Jerome Parent-Levesque, Kevin Xie, Kenny Erleben, Liam Paull, Florian Shkurti, Derek Nowrouzezahrai, and Sanja Fidler. gradsim: Differentiable simulation for system identification and visuomotor control. _International Conference on Learning Representations (ICLR)_, 2021.
* [28] Sofiene Jerbi, Arjan Cornelissen, Maris Ozols, and Vedran Dunjko. Quantum policy gradient algorithms, 2022. arXiv:2212.09328.
* [29] Amara Katabarwa, Katerina Gratsea, Athena Caesura, and Peter D Johnson. Early fault-tolerant quantum computing, 2023. arXiv:2311.14814.
* [30] Iordanis Kerenidis and Anupam Prakash. Quantum recommendation systems, 2016. arXiv:1603.08675.
* [31] Youngseok Kim, Andrew Eddins, Sajant Anand, Ken Xuan Wei, Ewout Van Den Berg, Sami Rosenblatt, Hasan Nayfeh, Yantao Wu, Michael Zaletel, Kristan Temme, et al. Evidence for the utility of quantum computing before fault tolerance. _Nature_, 618(7965):500-505, 2023.
* [32] David Kleinman. On an iterative technique for Riccati equation computations. _IEEE Transactions on Automatic Control_, 13(1):114-115, 1968.
* [33] Hari Krovi. Improved quantum algorithms for linear and nonlinear differential equations. _Quantum_, 7:913, 2023.
* [34] Peter Lancaster and Leiba Rodman. _Algebraic Riccati equations_. Clarendon press, 1995.
* [35] Alan Laub. A Schur method for solving algebraic Riccati equations. _IEEE Transactions on automatic control_, 24(6):913-921, 1979.

* [36] Jiaqi Leng, Ethan Hickman, Joseph Li, and Xiaodi Wu. Quantum Hamiltonian Descent, 2023. arXiv:2303.01471.
* [37] Jiaqi Leng, Yuxiang Peng, Yi-Ling Qiao, Ming Lin, and Xiaodi Wu. Differentiable analog quantum computing for optimization and control. _Advances in Neural Information Processing Systems_, 35:4707-4721, 2022.
* [38] William Levine and Michael Athans. On the determination of the optimal constant output feedback gains for linear multivariable systems. _IEEE Transactions on Automatic control_, 15(1):44-48, 1970.
* [39] Xiantao Li and Chunhao Wang. Efficient quantum algorithms for quantum optimal control. In _International Conference on Machine Learning_, pages 19982-19994. PMLR, 2023.
* [40] Fu Lin, Makan Fardad, and Mihailo R Jovanovic. Augmented lagrangian approach to design of structured optimal state feedback gains. _IEEE Transactions on Automatic Control_, 56(12):2923-2929, 2011.
* [41] Jin-Peng Liu, Herman Oie Kolden, Hari K Krovi, Nuno F Loureiro, Konstantina Trivisa, and Andrew M Childs. Efficient quantum algorithm for dissipative nonlinear differential equations. _Proceedings of the National Academy of Sciences_, 118(35):e2026805118, 2021.
* [42] Guang Hao Low and Yuan Su. Quantum eigenvalue processing, 2024. arXiv:2401.06240.
* [43] Nico Meyer, Christian Ufrecht, Maniraman Periyasamy, Daniel D Scherer, Axel Plinge, and Christopher Mutschler. A survey on quantum reinforcement learning, 2022. arXiv:2211.03464.
* [44] Hesameddin Mohammadi, Armin Zare, Mahdi Soltanolkotabi, and Mihailo R Jovanovic. Convergence and sample complexity of gradient methods for the model-free linear-quadratic regulator problem, 2019. arXiv:1912.11899.
* [45] Hesameddin Mohammadi, Armin Zare, Mahdi Soltanolkotabi, and Mihailo R Jovanovic. Convergence and sample complexity of gradient methods for the model-free linear-quadratic regulator problem. _IEEE Transactions on Automatic Control_, 67(5):2435-2450, 2021.
* [46] Miguel Angel Zamora Mora, Momchil Peychev, Sehoon Ha, Martin Vechev, and Stelian Coros. Pods: Policy optimization via differentiable simulation. In _International Conference on Machine Learning_, pages 7805-7817. PMLR, 2021.
* [47] Kirsten Morris and Carmeliza Navasca. Iterative solution of algebraic Riccati equations for damped systems. In _Proceedings of the 45th IEEE Conference on Decision and Control_, pages 2436-2440. IEEE, 2006.
* [48] Kirsten A Morris. _Introduction to feedback control_. Academic Press, Inc., 2000.
* [49] Yi-Ling Qiao, Junbang Liang, Vladlen Koltun, and Ming C. Lin. Efficient differentiable simulation of articulated bodies. In _ICML_, 2021.
* [50] Max Simchowitz, Horia Mania, Stephen Tu, Michael I Jordan, and Benjamin Recht. Learning without mixing: Towards a sharp analysis of linear system identification. In _Conference On Learning Theory_, pages 439-473. PMLR, 2018.
* [51] Valeria Simoncini. Computational methods for linear matrix equations. _SIAM Review_, 58(3):377-441, 2016.
* [52] Sanghyun Son, Yi-Ling Qiao, Jason Sewall, and Ming C. Lin. Differentiable hybrid traffic simulation. _ACM Transactions on Graphics (TOG)_, 2022.
* [53] Hyung Ju Suh, Max Simchowitz, Kaiqing Zhang, and Russ Tedrake. Do differentiable simulators give better policy gradients? In _Proceedings of the 39th International Conference on Machine Learning_, volume 162, pages 20668-20696. PMLR, 2022.

* [54] Joran van Apeldoorn and Andras Gilyen. Quantum algorithms for zero-sum games, 2019. arXiv:1904.03180.
* [55] Joran Van Apeldoorn, Andras Gilyen, Sander Gribling, and Ronald de Wolf. Quantum SDP-solvers: Better upper and lower bounds. In _2017 IEEE 58th Annual Symposium on Foundations of Computer Science (FOCS)_, pages 403-414. IEEE, 2017.
* [56] R Vinifa and A Kavitha. Linear quadratic regulator based current control of grid connected inverter for renewable energy applications. In _2016 International Conference on Energy Efficient Technologies for Sustainability (ICEETS)_, pages 106-111. IEEE, 2016.
* [57] Xin Wen, Xuting Sun, Yige Sun, and Xiaohang Yue. Airline crew scheduling: Models and algorithms. _Transportation research part E: logistics and transportation review_, 149:102304, 2021.
* [58] Simon Wiedemann, Daniel Hein, Steffen Udluft, and Christian Mendl. Quantum policy iteration via amplitude estimation and grover search-towards quantum advantage for reinforcement learning, 2022. arXiv:2206.04741.
* [59] Zhou Xian, Bo Zhu, Zhenjia Xu, Hsiao-Yu Tung, Antonio Torralba, Katerina Fragkiadaki, and Chuang Gan. Fluidlab: A differentiable environment for benchmarking complex fluid manipulation. In _International Conference on Learning Representations_, 2023.
* [60] Jie Xu, Tao Chen, Lara Zlokapa, Michael Foshey, Wojciech Matusik, Shinjiro Sueda, and Pulkit Agrawal. An End-to-End Differentiable Framework for Contact-Aware Robot Design. In _Proceedings of Robotics: Science and Systems_, Virtual, July 2021.
* [61] Jie Xu, Viktor Makoviychuk, Yashraj Narang, Fabio Ramos, Wojciech Matusik, Animesh Garg, and Miles Macklin. Accelerated policy learning with parallel differentiable simulation. In _International Conference on Learning Representations_, 2021.
* [62] Yao Zhang and Qiang Ni. Recent advances in quantum machine learning. _Quantum Engineering_, 2(1):e34, 2020.

## Appendix A LQR theory

**Definition 6**.: Given a positive number \(a>0\), we define the sublevel set \(S_{K}(a)\coloneqq\{K\in\mathbb{R}^{m\times n}\colon f(K)\leq a\}\). We have the following useful bound on \(K\).

**Lemma 8**.: _Over the sublevel set \(S_{K}(a)\) of the LQR objective function \(f(K)\), we have_

\[\operatorname{Tr}[X(K)] \leq a/\lambda_{\min}(Q),\] (27a) \[\nu/a \leq\lambda_{\min}(X(K)),\] (27b) \[\|K\|_{F} \leq a/\sqrt{\nu\lambda_{\min}(R)},\] (27c)

_where the constant_

\[\nu=\frac{1}{4}\left(\frac{\|A\|_{2}}{\sqrt{\lambda_{\min}(Q)}}+ \frac{\|B\|_{2}}{\sqrt{\lambda_{\min}(R)}}\right)^{-2}.\] (28)

Proof.: See [45, Lemma 16]. 

**Lemma 9**.: _For any \(K\in\mathcal{S}_{K}(a)\), we have_

\[\|K-K^{*}\|_{F}^{2}\leq\frac{a}{\nu\lambda_{\min}(R)}\left(f(K)- f(K^{*})\right),\] (29)

_where \(\nu\) is the same as in (28)._

Proof.: By [45, Lemma 2], we have

\[f(K)-f(K^{*})=\operatorname{Tr}\left[(K-K^{*})^{\top}R(K-K^{*}) X(K)\right]\geq\lambda_{\min}(R)\lambda_{\min}(X(K))\|K-K^{*}\|_{F}^{2}.\]

Combining the above result with Lemma 8, we end up with (29). 

**Lemma 10** (PL condition).: _Fix \(a>0\). For any \(K\in\mathcal{S}_{K}(a)\), we have_

\[\|\nabla f(K)\|_{F}^{2}\geq 2\mu_{f}(f(K)-f(K^{*})),\] (30)

_where \(\mu_{f}>0\) is a constant that only depends on the problem data and \(a\)._

Proof.: See [45, Remark 2]. 

## Appendix B Implementation of block-encoded matrices

**Lemma 11**.: _Assume that we have efficient procedures (as described in Assumption 1) to access the problem data \(A,B,Q,R\) in \(\mathcal{O}(\operatorname{poly}\log(n))\) time. For a fixed \(a>0\), suppose that \(K\in\mathcal{S}_{K}\) is a stabilizing policy stored in a quantum-accessible data structure. Then, we can implement_

1. \(a\)__\((s(\|K\|_{F}+1),\varepsilon)\)_-block-encoding of_ \(A-BK\) _in cost_ \(\mathcal{O}(\operatorname{poly}\log(n,s/\varepsilon))\)_,_
2. \(a\)__\((s(\|K\|_{F}^{2}+1),\varepsilon)\)_-block-encoding of_ \(Q+K^{\top}RK\) _in cost_ \(\mathcal{O}(\operatorname{poly}\log(n,s/\varepsilon))\)_._

Proof.: By [22, Lemma 48], we can implement a \((s,\varepsilon)\)-block-encoding of \(A\) (or \(B,Q,R\)) in cost \(\mathcal{O}(\operatorname{poly}\log(n,s/\varepsilon))\). Also, due to [22, Lemma 50], we can implement a \((\|K\|_{F},\varepsilon)\)-block-encoding of \(K\) in cost \(\mathcal{O}(\operatorname{poly}\log(n,1/\varepsilon))\). Therefore, by [22, Lemma 52, 53], a \((s(\|K\|_{F}+1),\varepsilon)\)-block-encoding of \(A-BK\) can be implement in cost \(\mathcal{O}(\operatorname{poly}\log(n,s/\varepsilon))\). Similarly, we can implement a \((s(\|K\|_{F}^{2}+1),\varepsilon)\)-block-encoding of \(Q+K^{\top}RK\) in cost \(\mathcal{O}(\operatorname{poly}\log(n,s/\varepsilon))\). 

**Remark 1**.: We observe that the block-encodings of \(A-BK\) and \(Q+K^{\top}RK\) can be implemented with high precisions, i.e., in cost \(\mathcal{O}(\operatorname{poly}\log(1/\varepsilon))\). To simplify our technical arguments, we assume these block-encodings can be implemented with no error, i.e., we can implement a \((s(\|K\|_{F}+1),0)\)-block-encoding of \(A-BK\) (or a \((s(\|K\|_{F}^{2}+1),0)\)-block-encoding of \(Q+K^{\top}RK\) in cost \(\mathcal{O}(\operatorname{poly}\log(n,s))\).

Matrix exponential based on quantum linear system solver

### Block-encoding for matrix inverse

**Lemma 12** (Modified from [42], Lemma 11).: _Let \(C\) be a matrix such that \(C/\alpha_{C}\) is block-encoded by \(O_{C}\) with some normalization factor \(\alpha_{C}\). Then we can implement a \((\mathcal{O}(\alpha_{C^{-1}}),\varepsilon)\)-block-encoding of \(C^{-1}\) using_

\[\mathcal{O}(\kappa_{C}\log(1/\varepsilon))\] (31)

_queries to \(O_{C}\). Here \(\kappa_{C}\) is the condition number of \(C\)._

Suppose we have an \((\alpha,\varepsilon)\)-block-encoding \(U_{M}\) that block-encodes \(M\). Denote

\[\alpha\langle 0|U_{M}|0\rangle-M=\Lambda,\] (32)

we have \(\|\Lambda\|\leq\varepsilon\). Then we can see \(U_{M}\) as an \((\alpha,0)\)-block-encoding of \(M+\Lambda/\alpha\). So with the lemma above, we have the theorem below:

**Theorem 13**.: _Suppose we have an \((\alpha,\varepsilon_{1})\)-block-encoding \(U_{M}\) that block-encodes \(M\), then we can implement a \((\mathcal{O}(\alpha_{M^{-1}}),\varepsilon_{2}+\frac{\alpha_{M^{-1}}^{2}}{ \alpha-\varepsilon_{1}\alpha_{M^{-1}}}\varepsilon_{1})\)-block-encoding for \(M^{-1}\) using_

\[\mathcal{O}(\kappa_{M}\log(1/\varepsilon_{2}))\] (33)

_queries to \(U_{M}\)._

Proof.: From the lemma above we know we can implement a \((\tilde{\alpha}_{M^{-1}},\varepsilon_{2})\)-block-encoding as \(\tilde{U}_{M^{-1}}\) for \((M+\Lambda/\alpha)\), where \(\tilde{\alpha}_{M^{-1}}=\mathcal{O}(\alpha_{M^{-1}})\). To analyze the error,

\[\|\tilde{\alpha}_{M^{-1}}\tilde{U}_{M^{-1}}-M^{-1}\| \leq\varepsilon_{2}+\|(M+\Lambda/\alpha)^{-1}-M^{-1}\|= \varepsilon_{2}+\|(I+M^{-1}\Lambda/\alpha)^{-1}M^{-1}-M^{-1}\|\] \[=\varepsilon_{2}+\|(I+M^{-1}\Lambda/\alpha)^{-1}-I\|\|M^{-1}\|= \varepsilon_{2}+\left\|\sum_{n=1}^{\infty}((-M^{-1}\Lambda)/\alpha)^{n}\right\| \|M^{-1}\|\] \[\leq\varepsilon_{2}+\sum_{n=1}^{\infty}\left\|((-M^{-1}\Lambda)/ \alpha)^{n}\right\|\|M^{-1}\|\leq\varepsilon_{2}+\frac{\alpha_{M^{-1}}^{2}}{ \alpha-\varepsilon_{1}\alpha_{M^{-1}}}\varepsilon_{1}.\] (34)

### Introduction to quantum linear system solver

The first quantum algorithm for solving linear differential equations was proposed by [9]. Since this work was done, several refinements have been made. Among these, [33] significantly loosen the requirement of performing the algorithm. We notice that this whole algorithm can be written in the form of block-encoding. Basically, for a linear differential equation

\[\frac{\mathrm{d}u}{\mathrm{d}t}=Au,\] (35)

upon appropriate discretization method and the method of line, one may construct a big matrix \(\mathbf{A}\) s.t.

\[\mathbf{A}\left[\begin{matrix}u(0)\\ u(h)\\ u(2h)\\ \vdots\\ u(T)\end{matrix}\right]=\left[\begin{matrix}u(0)\\ 0\\ 0\\ \vdots\\ 0\end{matrix}\right].\] (36)

Then it is easy to see that the matrix inverse \(\mathbf{A}^{-1}\) satisfies

\[(\langle k|\otimes I)\mathbf{A}^{-1}(|0\rangle\otimes u(0))=u(kh)=e^{khA}u(0).\] (37)

Because \(u(0)\) is arbitrarily chosen, we conclude

\[(\langle k|\otimes I)\mathbf{A}^{-1}(|0\rangle\otimes I)=e^{khA}.\] (38)

Suppose \(\mathbf{A}^{-1}\) is block-encoded in some \(U_{\mathbf{A}^{-1}}\), we have

\[(\langle k|\otimes I)((\langle 0^{a}|\otimes I)U_{\mathbf{A}^{-1}}(|0^{a} \rangle\otimes I))(|0\rangle\otimes I)=(\langle k0^{a}|\otimes I)U_{\mathbf{A}^ {-1}}(|0^{a+\ell}\rangle\otimes I).\] (39)

Here \(\ell\) satisfy \(2^{\ell}=T/h\), where \(T\) is the simulation time and \(h\) is the step size. Then it is obvious that \(U_{\mathbf{A}^{-1}}\) is also a block-encoding of \(e^{khA}\).

### Matrix exponential construction

**Lemma 14** (Modified from [33]).: _If we have a block-encoding \(U_{L}\) that block-encodes \(L\) defined as_

\[\begin{split} L&=I-N,\\ N&=\sum_{i=0}^{m}|i+1\rangle\!\langle i|\otimes M_{2}( I-M_{1})^{-1}+\sum_{i=m+1}^{2m}|i+1\rangle\!\langle i|\otimes I,\\ M_{1}&=\sum_{j=0}^{k-1}|j+1\rangle\!\langle j| \otimes\frac{Ah}{j+1},\\ M_{2}&=\sum_{j=0}^{k}|0\rangle\!\langle j|\otimes I,\end{split}\] (40)

_then the \((\alpha_{L^{-1}},\varepsilon)\)-block-encoding \(U_{L^{-1}}\) that block-encodes \(L^{-1}\) satisfies_

\[\left\|\alpha_{L^{-1}}(\langle r0^{a}|\otimes I)U_{L^{-1}}(|0^{a+s}\rangle \otimes I)-e^{TA}\right\|\leq\epsilon.\] (41)

_for any \(r\geq m+1\). Let \(2^{s-1}=m\), thus_

\[\alpha_{L^{-1}}(\langle 0^{a+s}|\otimes I)\left((X\otimes I_{s-1}\otimes I_{a} \otimes I)U_{L^{-1}}\right)(|0^{a+s}\rangle\otimes I)\approx e^{TA},\] (42)

_which means that \(((X\otimes I_{s-1}\otimes I_{a}\otimes I)U_{L^{-1}})\) is a block-encoding of \(e^{TA}\) with its normalization factor as \(\alpha_{L^{-1}}\) and error being at most \(\varepsilon\)._

Proof.: The proof of the correctness of \(L\) can be found in [33]. 

Now we turn to construct the block-encoding for \(L\).

**Lemma 15**.: _Assume we can query the \((\alpha_{A},0)\)-block-encoding \(U_{A}\) that encodes \(A\) and \(ho_{A}=\mathcal{O}(1)\), then we can construct a \((\mathcal{O}(k^{1.5}),k^{1/2}\epsilon)\)-block-encoding for \(L\) defined in (40) using \(\mathcal{O}(k\log(1/\epsilon))\) queries of \(U_{A}\) and same queries to additional elementary gates._

Proof.: First we need to block-encode \(M_{1}\). We will use the ADD operator defined as

\[\text{ADD}:=\sum_{j}|(j+1)\mod k\rangle\!\langle j|,\] (43)

and the controlled-rotation \(U_{R}\) as

\[U_{R}|j+1\rangle|0\rangle=|j+1\rangle\left(\frac{1}{j+1}|0\rangle+\sqrt{1- \frac{1}{(j+1)^{2}}}|1\rangle\right).\] (44)

Notice that

\[\begin{split}&(U_{R}\otimes I)(\text{ADD}\otimes I\otimes I) \left(\sum_{j=0}^{k-1}|j\rangle\!\langle j|\otimes I\otimes U_{A}\right)\\ &=\sum_{j=0}^{k-1}U_{R}\big{(}|j+1\mod k\rangle\!\langle j| \otimes I\big{)}\otimes U_{A}.\end{split}\] (45)

Post-select on the second register and the ancilla qubits of \(U_{A}\), we have

\[\begin{split}&(I\otimes\langle 0|\otimes\langle 0|)\left(\sum_{j=0} ^{k-1}U_{R}\big{(}|j+1\mod k\rangle\!\langle j|\otimes I\big{)}\otimes U_{A} \right)(I\otimes|0\rangle\otimes|0\rangle)\\ &=\sum_{j=0}^{k-1}|(j+1)\mod k\rangle\!\langle j|\otimes\frac{A/ \alpha_{A}}{j+1}.\end{split}\] (46)If we apply the operator on a state, namely

\[\left(\sum_{j=0}^{k-1}U_{R}\big{(}|(j+1)\mod k\rangle\!\langle j|\otimes I\big{)} \otimes U_{A}\right)|t\rangle|0\rangle|\psi\rangle=\frac{1}{\alpha_{A}(t+1)}|(t+ 1)\mod k\rangle|0\rangle A|\psi\rangle+|\bot\rangle.\] (47)

So we can apply one more multi-controlled-\(X\) gate to flip the flag register for the control register being \(|0\rangle\), then the whole thing becomes a \((\alpha_{A}h,0)\)-block-encoding for \(M_{1}\), using just one query to \(U_{A}\). We can then easily generate the block-encoding of \(I-M_{1}\) by LCU, with a \(1+\alpha_{A}h\) normalization factor. By the analysis in [33], we know \(\|I-M_{1}\|\|(I-M_{1})^{-1}\|\leq 2k\). Using Lemma 12, we can implement a \((\mathcal{O}(k),\epsilon_{1})\)-block-encoding of \((I-M_{1})^{-1}\) using \(\mathcal{O}(k\log(1/\varepsilon_{1}))\) queries to the block-encoding of \(I-M_{1}\) thus the same queries to \(U_{A}\).

For the block-encoding of \(M_{2}\), since it is sparse, we may directly implement it through the sparse input model. We may just assume the normalization factor to be \(\sqrt{k}\) and there is no error. Then we can implement a \((\mathcal{O}(k^{3/2}),\sqrt{k}\varepsilon_{1})\)-block-encoding of \((I-M_{1})^{-1}M_{2}\) using \(\mathcal{O}(k\log(1/\varepsilon_{1}))\) queries to \(U_{A}\) and other additional gates.

For the block-encoding for \(N\), we can see the normalization factor would be the same scaling as \(M_{2}(I-M_{1})^{-1}\), thus we implemented a \((\mathcal{O}(k^{3/2}),\mathcal{O}(\sqrt{k}\varepsilon_{1}))\)-block-encoding of \(N\). 

Now if we use QSVT to perform the matrix inverse, just as described in Theorem 13, we can implement an \((\alpha_{L^{-1}},\varepsilon_{2}+\frac{\alpha_{L^{-1}}^{2}}{\alpha_{L^{-1}} \alpha_{L^{-1}}}\sqrt{k}\varepsilon_{1})\)-block-encoding \(U_{L^{-1}}\) that encodes \(L^{-1}\) in cost \(\mathcal{O}(\kappa_{L}\log(1/\varepsilon_{2}))\) queries to \(U_{L}\), i.e. \(\mathcal{O}(\kappa_{L}\log(1/\varepsilon_{2})k\log(1/\varepsilon_{1}))\) queries to \(U_{A}\).

In order to perform the inverse of \(L\), we need to know the condition number of \(L\).

**Lemma 16** (Modified from [33], Theorem 3 & 4).: _Suppose \(E\) is the solution operator block-encoded by \(U_{L^{-1}}\) that approximates \(e^{AT}\) and \(m\) is the number of steps. Let_

\[(k+1)!\geq\frac{me^{3}}{\delta}C_{A},\] (48)

_where_

\[\sup_{t}\|\exp(At)\|\leq C_{A},\] (49)

_we have_

\[\|E-e^{AT}\|\leq\delta,\quad\|L^{-1}\|=\mathcal{O}(mC_{A}(1+\delta))\] (50)

_and_

\[\kappa_{L}\leq\mathcal{O}(m\sqrt{k}C_{A}(1+\delta)).\] (51)

Proof.: The proof can be seen at [33, Theorem 4]. 

**Theorem 17**.: _Let matrix \(A\) be a Hurwitz matrix with \(\sup_{t}\|\exp(tA)\|\) bounded by some constant \(\rho\), and \(O_{A}\) is a \((\alpha_{A},0)\)-block-encoding of \(A\). Then we can construct a \((\zeta T,\epsilon)\)-block-encoding of \(e^{AT}\) using_

\[\widetilde{\mathcal{O}}\left(\alpha_{A}\rho T\cdot\operatorname{poly}\log \left(\frac{1}{\epsilon}\right)\right)\] (52)

_queries to \(O_{A}\) and same queries to other additional elementary gates. Here \(\zeta=\mathcal{O}(\alpha_{A}\rho)\)._

Proof.: Firstly notice that \(m=\mathcal{O}(\alpha_{A}T)\) and \(k=\mathcal{O}\left(\frac{\log(T\alpha_{A}\rho/\delta)}{\log\log(T\alpha_{A} \rho/\delta)}\right)\). For a given accuracy \(\varepsilon\), we need \(\delta\leq\varepsilon\), which could be given by letting

\[\varepsilon_{2}+\frac{\alpha_{L^{-1}}^{2}}{\alpha_{L}-\varepsilon_{1}\alpha_ {L^{-1}}}\sqrt{k}\varepsilon_{1}\leq\varepsilon.\] (53)

Choose \(\varepsilon_{1}=\widetilde{\mathcal{O}}(\varepsilon/T^{2})\) and \(\varepsilon_{2}=\varepsilon/2\), from the discussion above we know we can implement an \((\alpha_{L^{-1}},\varepsilon)\)-block-encoding of \(e^{TA}\). Since \(\alpha_{L^{-1}}=\mathcal{O}(m\rho(1+\delta))\), the queries we need is \(\widetilde{\mathcal{O}}(\alpha_{A}\rho T\cdot\operatorname{poly}\log(1/ \varepsilon))\)

**Remark 2**.: If we directly use the theorem above to prepare the state \(|e^{AT}|\psi\rangle\rangle\) for some input state \(|\psi\rangle\), the dependence on \(T\) would be \(T^{2}\), which does not match the optimal scaling. This is actually due to our usage of QSVT to block-encode matrices inverses. If we adopt the common technique of padding in the quantum linear system solver, we can easily improve the current scaling into \(T^{3/2}\). However, for simplicity, we do not implement these standard improvements in this work, as they does not affect our end-to-end complexity result.

## Appendix D Quantum eigenvalue transformation for linear differential equations

Here we exploit a technique known as quantum eigenvalue transformation (QEVT) by Low and Su [42] to simulate linear dynamics \(\dot{x}=\mathcal{A}x\). The algorithm (QEVT) requires that the dynamics is stable under \(\mathcal{A}+\mathcal{A}^{\top}\leq 0\), which is stronger than \(\mathcal{A}\) is Hurwitz stable.

Notice that \(\mathcal{A}+\mathcal{A}^{\top}\leq 0\) is the stability under the common 2-norm, and \(\mathcal{A}\) satisfying the Lyapunov equation \(\mathcal{A}X+X\mathcal{A}^{\top}\leq 0\) (16) indicates the stability under the inner product induced by the matrix \(X\). We hence follow [42], use a sequence of polynomial functions (known as the Faber polynomials) to approximate the time-evolution operator \(e^{\mathcal{A}t}\).

**Lemma 18** (Faber truncation of matrix exponentials, [42, Lemma 27]).: _Suppose we have a matrix \(A\) where its numerical range \(\mathcal{W}(A):=\{\langle\psi|A|\psi\rangle|\|\psi\rangle\|=1\}\) is enclosed by a Faber region \(\mathcal{E}\) with associated conformal maps \(\Phi:\mathcal{E}^{c}\to\mathcal{D}^{c},\Psi:\mathcal{D}^{c}\to\mathcal{E}^{c}\) and Faber polynomials \(F_{s}(z)\). Given \(t>0\), let \(e^{tz}=\sum_{j=0}^{\infty}\beta_{j}F_{j}(z)\) be the Faber expansion of the complex exponential function \(e^{tz}\). Assume that \(\mathcal{E}\) is convex and symmetric with respect to the real axis, lying on the left half of the complex plane, then for sufficiently large \(s\),_

\[\left\|e^{At}-\sum_{k=0}^{s-1}\beta_{j}F_{j}(A)\right\|=\mathcal{O}\left( \left(\frac{ct}{s}\right)^{s}\right),\] (54)

_where \(c\) is a constant determined by the conformal maps._

By Lemma 18, given any \(\varepsilon>0\), it suffices to choose \(s\sim\mathcal{O}(t\log(\frac{1}{\varepsilon}))\) such that

\[\left\|e^{At}-\sum_{k=0}^{s-1}\beta_{j}F_{j}(A)\right\|\leq\varepsilon.\] (55)

**Definition 7**.: For some matrix \(A\) of size \(N\times N\) with its normalization factor \(\alpha_{A}\), denote the identity matrix of size \(N\times N\) as \(I_{N}\), and

\[L_{N}=\begin{bmatrix}0&&&&\\ 1&0&&\\ &1&0&&\\ &&\ddots&\ddots&\\ &&&1&0\end{bmatrix}_{N\times N}\] (56)

as the lower shift matrix of size \(N\times N\). We then define

\[\mathrm{PAD}(A):= |0\rangle\!\langle 0|\otimes\left(L_{N}\Psi(L_{N}^{-1})\otimes I_{N}-L _{N}\otimes\frac{A}{\alpha_{A}}\right)\] (57) \[+ |1\rangle\!\langle 0|\otimes|0\rangle\!\langle N-1|\otimes(-I_{N})+ |1\rangle\!\langle 1|\otimes(I_{N}-L_{N})\otimes I_{N},\]

and

\[\mathrm{PAD}(B):=|0\rangle\!\langle 0|\otimes\Psi^{\prime}(L_{N}^{-1}) \otimes I_{N}+|1\rangle\!\langle 1|\otimes I_{N}\otimes I_{N}.\] (58)

Note that the conformal map \(\Psi\) has its Laurent expansion, and so are \(\Psi^{\prime}(\omega)\) and \(\omega\Psi(\omega^{-1})\). Furthermore, \(\Psi^{\prime}(\omega)\) and \(\omega\Psi(\omega^{-1})\) only contains terms with non-negative exponents. Thus \(\Psi(L_{N}^{-1})\) and \(\Psi^{\prime}(L_{N}^{-1})\) are well-defined even though \(L_{N}^{-1}\) is not invertible itself.

With the matrices \(\mathrm{PAD}(A)\) and \(\mathrm{PAD}(B)\), we can compute the matrix \(\mathrm{PAD}(A)^{-1}\mathrm{PAD}(B)\), say

\[\mathrm{PAD}(A)^{-1}\mathrm{PAD}(B)=\left[\begin{array}{ccccc|ccccc}F_{0}( \frac{A}{\alpha_{A}})&0&\cdots&0&\vdots&0&0&\cdots&0\\ F_{1}(\frac{A}{\alpha_{A}})&F_{0}(\frac{A}{\alpha_{A}})&\ddots&\vdots&0&0& \cdots&0\\ \vdots&\ddots&\ddots&0&\vdots&\vdots&\ddots&\vdots\\ F_{s-1}(\frac{A}{\alpha_{A}})&F_{n-2}(\frac{A}{\alpha_{A}})&\cdots&F_{0}( \frac{A}{\alpha_{A}})&\vdots&0&\cdots&0\\ \vdots F_{s-1}(\frac{A}{\alpha_{A}})&F_{s-2}(\frac{A}{\alpha_{A}})&\cdots& \tilde{F_{0}}(\frac{A}{\alpha_{A}})&\vdots&I&0&\cdots&0\\ F_{s-1}(\frac{A}{\alpha_{A}})&F_{s-2}(\frac{A}{\alpha_{A}})&\cdots&F_{0}( \frac{A}{\alpha_{A}})&\vdots&I&\cdots&0\\ \vdots&\vdots&\cdots&\vdots&\vdots&\vdots&\ddots&0\\ F_{s-1}(\frac{A}{\alpha_{A}})&F_{s-2}(\frac{A}{\alpha_{A}})&\cdots&F_{0}( \frac{A}{\alpha_{A}})&\vdots&I&\cdots&I\end{array}\right].\] (59)

Note that this matrix has \((2s)\times(2s)\) blocks, and each block of size \(N\times N\).

**Definition 8**.: For a matrix \(A\) whose numerical range is enclosed by a Faber region \(\mathcal{E}\) with associated conformal maps \(\Phi:\mathcal{E}^{c}\rightarrow\mathcal{D}^{c},\Psi:\mathcal{D}^{c}\rightarrow \mathcal{E}^{c}\) and Faber polynomials \(F_{s}(z)\), consider some Faber expansion till \(s\)-th order, we then define

\[\rho\geq\max_{j=1,\cdots,s}\left\|\frac{F^{\prime}_{j}(\frac{A}{\alpha_{A}})}{ j}\right\|\] (60)

as an upper bound on the derivative of Faber polynomials.

**Lemma 19**.: _We are able to have a \((\xi,\varepsilon)\)-block-encoding to \((\mathrm{PAD}(A))^{-1}\) using \(\mathcal{O}(\xi\log\bigl{(}\frac{1}{\varepsilon}\bigr{)})\) queries to the block-encoding of \(A\) and \(\widetilde{\mathcal{O}}(1)\) additional elementary gates. Here \(\xi\sim\mathcal{O}(\rho s)\)._

Proof.: Since we know that \(\mathrm{PAD}(A)\) can be block-encoded with an \(\mathcal{O}(1)\) normalization factor with arbitrary precision using a single query to the block-encoding of \(A\) and a polylogarithmic number of elementary gates, and \(\|(\mathrm{PAD}(A))^{-1}\|=\mathcal{O}(s\rho)\), the rest of the proof is done by Lemma 12. 

**Theorem 20** (Modified version of Theorem 10. [42]).: _Let matrix \(A\) have its numerical range \(\mathcal{W}(A):=\{\langle\psi|A|\psi\rangle\big{|}\big{|}\big{|}\psi\rangle \|=1\}\) enclosed by a Faber region \(\mathcal{E}\) with associated conformal maps \(\Phi:\mathcal{E}^{c}\rightarrow\mathcal{D}^{c},\Psi:\mathcal{D}^{c}\rightarrow \mathcal{E}^{c}\) and Faber polynomials \(F_{s}(z)\). Let \(p(z)=\sum_{k=0}^{s-1}\beta_{k}F_{k}(z)\) be the Faber expansion of a degree-\((s-1)\) polynomial \(p\) and \(O_{\beta}|0\rangle=\sum_{k=0}^{s-1}\beta_{k}|n-1-k\rangle/\|\beta\|\) be the oracle preparing the coefficients. Then, we can construct a \((\xi^{\prime}\|\widetilde{\beta}\|,\|\beta\|\varepsilon)\)-block-encoding of \(\sum_{k=0}^{s-1}\beta_{k}F_{k}(A/\alpha_{A})\) using_

\[\mathcal{O}\left(\rho s\log\biggl{(}\frac{1}{\varepsilon}\biggr{)}\right)\] (61)

_queries to \(O_{A}\), one query to \(O_{\beta}\) and \(\widetilde{\mathcal{O}}(1)\) additional gate. Here, \(\xi^{\prime}\leq\mathcal{O}(\rho s)\)._

Proof.: First, we observe that

\[\langle\langle 0|\otimes\langle 0|\otimes I\rangle\left(\mathrm{PAD}(A)^{-1} \mathrm{PAD}(B)(X\otimes O_{\beta}\otimes I)\right)(|0\rangle\otimes|0\rangle \otimes I)=\sum_{k=0}^{s-1}\frac{\beta_{k}}{\|\beta\|}F_{k}(A/\alpha_{A}).\] (62)

The \(X\) is the quantum Pauli-X gate. Here the circuit has 3 registers, the first one only has one qubit, the second has \(\log_{2}s\) qubits, and the third one matches the size of \(A\).

By [42, Theorem 9], we can implement a block-encoding of \(\mathrm{PAD}(A)\) using a single query to the block-encoded matrix \(A/\alpha_{A}\). Also, given a constant

\[\rho\geq\max_{j=1,\cdots,s}\left\|\frac{F^{\prime}_{j}(\frac{A}{\alpha_{A}})}{ j}\right\|,\] (63)

we know that \(\|\mathrm{PAD}(A)^{-1}\|=\mathcal{O}(\rho s)\). By Lemma 19, we can construct a \((\xi,\varepsilon)\)-block-encoding of \(\mathrm{PAD}(A)^{-1}\) using \(\mathcal{O}(\xi\log(1/\epsilon))\) queries to the block-encoding of \(A/\alpha_{A}\).

Also, assume we can implement a block-encoding of \(\mathrm{PAD}(B)\) with a \(\mathcal{O}(1)\) normalization factor. Combining these two block-encodings together, we obtain a \((\xi^{\prime},\varepsilon)\)-block-encoding of \(\mathrm{PAD}(A)^{-1}\mathrm{PAD}(B)\), where \(\xi^{\prime}\leq\mathcal{O}(\rho s)\). Then, by (62), the block-encoding we implemented turns out to be a \((\xi^{\prime}\|\beta\|,\|\beta\|\varepsilon)\)-block-encoding of \(\sum_{k=0}^{s-1}\beta_{k}F_{k}(A/\alpha_{A})\). 

**Theorem 21** (Block-encoding of matrix exponential).: _Suppose that \(A\in\mathbb{R}^{m\times n}\) is a Hurwitz matrix, and \(O_{A}\) is a \((\alpha_{A},0)\)-block-encoding of \(A\). Then we can implement a \((\zeta t,\varepsilon)\)-block-encoding of \(e^{At}\) using_

\[\mathcal{O}\left(\alpha_{A}t\operatorname{poly}\log\!\left(\frac{1}{ \varepsilon}\right)\right)\] (64)

_queries to \(O_{A}\), one query to a state preparation oracle \(O_{\beta}\) and \(\widetilde{\mathcal{O}}(1)\) additional gate. Here \(\zeta=\mathcal{O}(\alpha_{A}\operatorname{poly}\log(1/\epsilon))\)._

Proof.: First we use Lemma 18 to \(e^{\alpha_{A}(A/\alpha_{A})t}\), then we know the polynomial should be of degree \(\mathcal{O}(\alpha_{A}t\log\!\left(\frac{1}{\varepsilon_{1}}\right))\) in order to have a \(\varepsilon_{1}\) accuracy. Then leverage Theorem 20, we need \(\mathcal{O}\left(\rho\left(\alpha_{A}t\log\!\left(\frac{1}{\varepsilon_{1}} \right)\right)\log\!\left(\frac{1}{\varepsilon_{2}}\right)\right)\) queries to \(O_{A}\) to construct a block-encoding of the polynomial. Since the Faber polynomial expansion of \(e^{At}\) converges absolutely, without loss of generality, we assume \(\|\beta\|\) is \(\mathcal{O}(1)\). Choosing \(\varepsilon_{1}=\frac{\varepsilon}{2}\) and \(\varepsilon_{2}=\frac{\varepsilon}{2\|\beta\|}\), we have a \((\zeta t,\varepsilon)\)-block-encoding of \(e^{At}\). 

## Appendix E Proof of Theorem 4

**Lemma 22** (Select oracle).: _Suppose that \(\mathcal{A}\) is Hurwitz, and \(O_{\mathcal{A}}\) is an \((\alpha,0)\)-block-encoding of \(\mathcal{A}\). Let \(K\) be a positive integer and \(\tau,\varepsilon>0\) are two real-valued scalars. The select oracle as defined in Definition 4 can be implemented using_

\[\widetilde{\mathcal{O}}\left(\alpha\rho\tau K\log(K)\cdot\operatorname{poly} \log\!\left(\frac{1}{\varepsilon}\right)\right)\] (65)

_queries to controlled \(O_{\mathcal{A}}\), and \(\widetilde{\mathcal{O}}\left(\alpha\rho\tau K\log(K)\cdot\operatorname{poly} \log\!\left(\frac{1}{\varepsilon}\right)\right)\) queries to other additional elementary gates._

Proof.: Firstly, \(t_{k}\) here attains \(t_{k}=\frac{k\tau}{K}\). By Theorem 17, for each \(k=0,\ldots,K\), we can implement a \((\zeta t_{k},\varepsilon)\)-block-encoding of \(e^{At_{k}}\) using \(\widetilde{\mathcal{O}}(\alpha\rho t_{k}\cdot\operatorname{poly}\log(1/ \varepsilon))\) queries to \(O_{\mathcal{A}}\). We denote this block-encoding as \(U_{k}\). Notice that the select oracle \(\mathrm{select}(\mathcal{A},\varepsilon)\) can be represented by

\[\mathrm{select}(\mathcal{A},\varepsilon)=\prod_{k=0}^{K}\left[(\mathbb{I}-|k \rangle\!\langle k|)\otimes\mathbb{I}+|k\rangle\!\langle k|\otimes U_{k}\right],\] (66)

where each unitary operator \([(\mathbb{I}-|k\rangle\!\langle k|)\otimes\mathbb{I}+|k\rangle\!\langle k| \otimes U_{k}]\) in this product is a \(k\)-controlled version of \(U_{k}\) that can be implemented with \(\widetilde{\mathcal{O}}(\alpha\rho t_{k}\log(K)\cdot\operatorname{poly}\log(1/ \varepsilon))\) queries to the controlled \(O_{\mathcal{A}}\) and other additional gates. Therefore, the overall query complexity is

\[\widetilde{\mathcal{O}}\left(\alpha\rho\tau\left(\sum_{k=0}^{K}t_{k}\right) \log(K)\cdot\operatorname{poly}\log\!\left(\frac{1}{\varepsilon}\right)\right) \leq\widetilde{\mathcal{O}}\left(\alpha\rho\tau K\log(K)\cdot\operatorname{ poly}\log\!\left(\frac{1}{\varepsilon}\right)\right),\] (67)

where the last step follows from \(\sum_{k=0}^{K}t_{k}=\sum_{k=0}^{K}\frac{k\tau}{K}=\frac{(K+1)\tau}{2}\). 

In the following proof, we will need a state preparation oracle

\[O_{\lambda}|0\rangle=\frac{1}{\sqrt{\|\lambda\|_{1}}}\sum_{k=0}^{K}\sqrt{ \lambda_{k}}|k\rangle,\] (68)where \(\lambda_{k}=w_{k}k^{2}\), \(\|\lambda\|_{1}=\sum_{k=0}^{K}|\lambda_{k}|\) and \(w_{k}=\frac{(2-1_{k=0,K})\tau}{2K}\). Since \(\lambda_{k}\) can be expressed as a smooth function of \(k\) for \(k\in\{0,1,\cdots,K\}\), this state preparation oracle can be implemented in \(\mathcal{O}(\mathrm{poly}\log(K))\) cost.

Now, we are ready to prove Theorem 4.

Proof.: The global error of the trapezoidal rule (see (20)) is proportional to

\[\max_{\xi\in[0,\tau]}\frac{\tau^{3}}{K^{2}}|F^{\prime\prime}(\xi)|,\] (69)

where

\[|F^{\prime\prime}(\xi)|=\big{|}\mathcal{A}^{2}F(\xi)+2\mathcal{A}F(\xi)A^{ \top}+F(\xi)(\mathcal{A}^{\top})^{2}\big{|}\leq 4\|\mathcal{A}\|^{2}\|\Omega\|.\]

Therefore, to achieve precision \(\varepsilon_{1}\), the total number of quadrature points is

\[K=\mathcal{O}\left(\frac{\tau^{3/2}\alpha\eta^{1/2}}{\varepsilon_{1}^{1/2}} \right).\] (70)

Now, we consider the following two select oracles, as defined in Definition 4:

\[\mathrm{select}(\mathcal{A},\varepsilon_{2}):=\sum_{k=0}^{K}|k\rangle\!\langle k |\otimes U_{k},\quad\mathrm{select}(\mathcal{A}^{\top},\varepsilon_{2}):=\sum _{k=0}^{K}|k\rangle\!\langle k|\otimes V_{k},\] (71)

where \(U_{k}\) (or \(V_{k}\)) is a \((\zeta t_{k},\varepsilon_{2})\)-block-encoding of \(e^{\mathcal{A}t_{k}}\) (or \(e^{\mathcal{A}^{\top}t_{k}}\)) for \(0\leq k\leq K\). Recall that \(O_{\Omega}\) is a \((\eta,0)\)-block-encoding of \(\Omega\), it turns out that

\[\mathrm{select}(\mathcal{A},\varepsilon)(I\otimes O_{\Omega})\mathrm{select}( \mathcal{A}^{\top},\varepsilon)=\sum_{k=0}^{K}|k\rangle\!\langle k|\otimes W_{ k},\] (72)

where \(W_{k}:=U_{k}U_{\Omega}V_{k}\) is a \((\eta\zeta^{2}t_{k}^{2},2\zeta t_{k}\eta\varepsilon_{2})\)-block-encoding of the matrix \(\mathscr{F}(t_{k})\).

Let \(O_{\lambda}\) be the state preparation oracle defined in (68). By the LCU technique [22, Lemma 52], we can implement a \((\gamma,\sum_{k=0}^{K}2|w_{k}|\eta\zeta t_{k}\varepsilon_{2})\)-block-encoding (where \(\gamma:=\sum_{k=0}^{K}|w_{k}|\zeta^{2}t_{k}^{2}\eta\)) of \(\sum_{k=0}^{K}w_{k}e^{\mathcal{A}t_{k}}\Omega e^{\mathcal{A}^{\top}t_{k}}\) using a single query to \(\mathrm{select}(A,\varepsilon_{2})\), \(\mathrm{select}(A^{\top},\varepsilon_{2})\), \(U_{\Omega}\), \(O_{\lambda}\) and its inverse.

Notice that

\[\sum_{k=0}^{K}|w_{k}|t_{k}\leq\sum_{k=0}^{K}\frac{\tau}{K}\frac{k\tau}{K}= \mathcal{O}(\tau^{2}),\] (73)

thus

\[\sum_{k=0}^{K}2|w_{k}|\eta\zeta t_{k}\varepsilon_{2}=\widetilde{\mathcal{O}} \left(\tau^{2}\eta\zeta\varepsilon_{2}\right).\] (74)

Given a positive scalar \(\varepsilon>0\), and set the integration time

\[\tau=\kappa\log\!\left(\frac{3\|X^{*}\|\kappa}{\varepsilon\|w\|_{1}\lambda_{ \min}(X^{*})}\right)\!,\] (75)

Note that

\[\varepsilon^{\delta}\mathrm{poly}\left(\log\!\left(\frac{1}{\varepsilon} \right)\right)\to 0,\] (76)

then if we choose

\[\varepsilon_{1}=\frac{\varepsilon}{3},\quad\varepsilon_{2}=\mathcal{O}( \varepsilon^{1+\delta}),\] (77)

where \(\delta>0\) is a constant positive number. By Lemma 3 and the error analysis above, we implement a \((\gamma,\varepsilon)\)-block-encoding of \(X^{*}\), with

\[\gamma=\sum_{k=0}^{K}|w_{k}|\zeta^{2}t_{k}^{2}\eta=\mathcal{O}(\zeta^{2}\eta \tau^{3})=\widetilde{\mathcal{O}}(\alpha^{2}\rho^{2}\kappa^{3}\eta).\] (78)It follows that the overall cost of this block-encoding is

\[\widetilde{\mathcal{O}}\left(\frac{\alpha^{2}\rho\kappa^{5/2}\eta^{1/2}}{\varepsilon ^{1/2}}\right)\] (79)

queries to \(O_{\mathcal{A}}\) and same queries to other additional elementary gates. 

## Appendix F Quantum trace estimation

Here we show how to estimate the trace of a positive definite block-encoded matrix. The main result is in Theorem 25.

**Lemma 23**.: _Let \(U_{H}\) be an \((\alpha,m,\varepsilon_{H})\)-block-encoding of a positive-definite Hermitian matrix \(H\in\mathbb{C}^{n\times n}\) and let \(\varepsilon\in(0,\frac{1}{3}]\). Let \(\lambda_{\min}>0\) be a known lower bound on the smallest eigenvalue of \(H\). Provided that \(\varepsilon_{H}\leq\mathcal{O}\left(\frac{\lambda_{\min}\varepsilon^{2}}{ \log(1/\varepsilon)}\right)\) is sufficiently small (where \(\varepsilon>0\) is a given number), we can construct a \((1,m+2,\varepsilon)\)-block-encoding of \(\sqrt{\frac{H/\alpha}{36}}\) using \(\mathcal{O}\left(\frac{\alpha}{\lambda_{\min}}\log(1/\varepsilon)\right)\) applications of \(U_{H}\) and \(U_{H}^{\dagger}\), a single application of controlled-\(U_{H}\), and \(\mathcal{O}\left(\frac{\alpha(m+1)}{\lambda_{\min}}\log(1/\varepsilon)\right)\) other one- and two-qubit gates. The description of this block-encoding circuit can be computed classically in time \(\mathcal{O}\left(\operatorname{poly}\left(\frac{\alpha}{\lambda_{\min}}\log( 1/\varepsilon)\right)\right)\)._

Proof.: Define \(\widetilde{\lambda}_{\min}\coloneqq\lambda_{\min}/\alpha\), such that \(\widetilde{\lambda}_{\min}I\preceq H/\alpha\preceq I\). We first find a polynomial approximation of \(f(x)\coloneqq\sqrt{\frac{x}{36}}\) over \(x\in[\widetilde{\lambda}_{\min},1]\) using [22, Corollary 66]. To use this corollary, let \(x_{0}\coloneqq 1\), \(r\coloneqq 1-\widetilde{\lambda}_{\min}\), \(\delta\coloneqq\widetilde{\lambda}_{\min}\), and observe that \(f(x_{0}+x)=\frac{1}{6}\sqrt{1+x}=\frac{1}{6}\sum_{\ell=0}^{\infty}\binom{1/2} {\ell}x^{\ell}\) whenever \(|x|\leq r+\delta=1\). Also note that \(\frac{1}{6}\sum_{\ell=0}^{\infty}\left|\binom{1/2}{\ell}\right|\leq\frac{1}{3}=:B\). Then there is an efficiently computable polynomial \(P_{0}\in\mathbb{C}[x]\) of degree \(d=\mathcal{O}\left(\frac{1}{\lambda_{\min}}\log(1/\varepsilon)\right)\) such that \(\|f(x)-P_{0}(x)\|\leq\frac{\varepsilon}{2}\) for \(x\in[\widetilde{\lambda}_{\min},1]\) and \(\|P_{0}(x)\|\leq\frac{\varepsilon}{2}+B\leq\frac{1}{2}\) for \(x\in[-1,1]\). It follows that defining \(P(x)\coloneqq\operatorname{Re}\left(P_{0}(x)\right)\) gives \(|f(x)-P(x)|_{[\widetilde{\lambda}_{\min},1]}\leq\frac{\varepsilon}{2}\) and \(|P(x)|_{[-1,1]}\leq\frac{1}{2}\).

Next, we use [22, Theorem 56] to construct construct a unitary \(V\) that is a \((1,m+2,\varepsilon/2)\)-encoding of \(P(H/\alpha)\) with the desired complexity, using the promise that \(\varepsilon_{H}\) is sufficiently small to satisfy \(4d\sqrt{\varepsilon_{H}/\alpha}\leq\varepsilon/4\). \(V\) is then a \((1,m+2,\varepsilon)\)-block-encoding of \(\sqrt{\frac{H/\alpha}{36}}\) since

\[\left\|\sqrt{\frac{H/\alpha}{36}}-(\ \langle 0|^{\otimes m+2} \otimes I)V(|0\rangle^{\otimes m+2}\otimes I\ )\right\|\] (80) \[\leq\left\|g(H/\alpha)-P(H/\alpha)\right\|+\frac{\varepsilon}{2}= \|\mathrm{diag}(g(\lambda_{H}/\alpha))-\mathrm{diag}(P(\lambda_{H}/\alpha))\| +\frac{\varepsilon}{2}\] \[=\max_{\lambda_{i}\in\lambda_{H}}|g(\lambda_{i}/\alpha)-P(\lambda _{i}/\alpha)|+\frac{\varepsilon}{2}\leq\frac{\varepsilon}{2}+\frac{ \varepsilon}{2}=\varepsilon,\]

where \(\lambda_{H}\in\mathbb{R}^{n}\) is the vector of eigenvalues of \(H\). 

**Lemma 24**.: _Let \(\mu>0\). Let \(A\) be an \(n\)-by-\(n\) Hermitian matrix such that \(0\preceq A\preceq I\) and let \(\widetilde{V}\) be a \((1,m,\mu/3)\)-block-encoding of \(\sqrt{A}\). Then there exists \(\widetilde{U}_{A}\) such that \(\left\|\left\|(\langle 0|\otimes I)\widetilde{U}_{A}|0\ldots 0\rangle \right\|^{2}-\frac{\operatorname{Tr}(A)}{n}\right|\leq\mu\) that uses 1 query to \(\widetilde{V}\) and \(\mathcal{O}(\log n)\) additional gates._

Proof.: Our proof is similar to the proof of [55, Lemma 13]. The idea is to first prepare the maximally entangled state \(\sum_{i=1}^{n}|i\rangle|i\rangle/\sqrt{n}\) (which requires \(\mathcal{O}(\log n)\) gates) and then apply the map \(\sqrt{A}\) to the first register. We can assume without loss of generality that \(\mu\leq 1\), otherwise the statement is trivial.

Note that \(\widetilde{V}_{0}:=(\langle 0|^{\otimes m}\otimes I\rangle\widetilde{V}(|0\rangle^{ \otimes m}\otimes I)\) is a \(\mu/3\)-approximation of \(\sqrt{A}\) by definition. We are interested in the probability \(p\) of measuring \(0^{\otimes m}\) in the first register after applying \(\widetilde{V}\).

\[\begin{split} p&\coloneqq\left\|(\langle 0|^{ \otimes m}\otimes I\rangle\widetilde{V}(|0\rangle^{\otimes m}\otimes I)\sum_{i =1}^{n}\frac{|i\rangle|i\rangle}{\sqrt{n}}\right\|^{2}=\left\|\widetilde{V}_{0 }\sum_{i=1}^{n}\frac{|i\rangle|i\rangle}{\sqrt{n}}\right\|^{2}\\ &=\frac{1}{n}\sum_{i=1}^{n}\langle i|\widetilde{V}_{0}^{\dagger} \widetilde{V}_{0}|i\rangle=\frac{1}{n}\operatorname{Tr}\bigl{(}\widetilde{V}_ {0}^{\dagger}\widetilde{V}_{0}\bigr{)}.\end{split}\] (81)

It remains to show that \(p\) is a good approximation of \(\operatorname{Tr}(A)/n\). For this, we show \(\widetilde{V}_{0}^{\dagger}\widetilde{V}_{0}\approx A\). Note that for all matrices \(B,\widetilde{B}\) with \(\|B\|\leq 1\), we have

\[\begin{split}\left\|B^{\dagger}B-\widetilde{B}^{\dagger} \widetilde{B}\right\|&=\left\|(B^{\dagger}-\widetilde{B}^{\dagger })B+B^{\dagger}(B-\widetilde{B})-(B^{\dagger}-\widetilde{B}^{\dagger})(B- \widetilde{B})\right\|\\ &\leq\left\|(B^{\dagger}-\widetilde{B}^{\dagger})B\right\|+ \left\|B^{\dagger}(B-\widetilde{B})\right\|+\left\|(B^{\dagger}-\widetilde{B} ^{\dagger})(B-\widetilde{B})\right\|\\ &\leq\left\|B^{\dagger}-\widetilde{B}^{\dagger}\right\|\left\|B \right\|+\left\|B^{\dagger}\right\|\left\|B-\widetilde{B}\right\|+\left\|B^{ \dagger}-\widetilde{B}^{\dagger}\right\|\left\|B-\widetilde{B}\right\|\\ &\leq 2\left\|B-\widetilde{B}\right\|+\left\|B-\widetilde{B}\right\|^ {2}.\end{split}\] (82)

Using equation (81) along with equation (82) (letting \(B=\sqrt{A}\) and \(\widetilde{B}=\widetilde{V}_{0}\)), we see

\[\left|\frac{\operatorname{Tr}(A)}{n}-p\right|=\frac{1}{n}\left|\operatorname{ Tr}\bigl{(}A-\widetilde{V}_{0}^{\dagger}\widetilde{V}_{0}\bigr{)}\right| \leq\left\|A-\widetilde{V}_{0}^{\dagger}\widetilde{V}_{0}\right\|\leq 2 \left(\frac{\mu}{3}\right)+\left(\frac{\mu}{3}\right)^{2}\leq\mu.\] (83)

**Theorem 25**.: _Let \(U_{H}\) be an \((\alpha,m,\varepsilon)\)-block-encoding of a Hermitian matrix \(H\in\mathbb{C}^{n\times n}\), where \(U_{H}\) can be implemented using \(T_{H}\) elementary gates. Suppose \(H\succ 0\) and let \(\lambda_{\min}>0\) be a known lower bound on the smallest eigenvalue of \(H\). Then, with probability at least \(4/5\), we can estimate \(\operatorname{Tr}(H)\) to within multiplicative error \(\theta\in(0,1]\) in cost_

\[\mathcal{O}\left(\frac{\alpha^{3/2}T_{H}}{\theta\lambda_{\min}^{3/2}}\log \biggl{(}\frac{\alpha}{\theta\lambda_{\min}}\biggr{)}\right),\] (84)

_provided that \(\varepsilon\leq\mathcal{O}\left(\frac{\lambda_{\min}^{3}\theta^{2}}{\alpha^{2 }\log(\alpha/\theta\lambda_{\min})}\right)\)._

Proof.: Our proof is similar to the proof of [55, Corollary 10]. Let \(A\coloneqq\frac{H/\alpha}{36}\) and note that since \(H/\alpha\succeq\lambda_{\min}I/\alpha\), we have

\[\frac{\operatorname{Tr}(A)}{n}\coloneqq\frac{\operatorname{Tr}(H/\alpha)}{36n }\geq\frac{\lambda_{\min}}{36\alpha}.\] (85)

Let \(\widetilde{U}_{A}\) be a \((1,m+2,\theta\lambda_{\min}/216\alpha)\)-block-encoding of \(\sqrt{A}\) constructed via Lemma 23. Using Lemma 24, we can construct a unitary circuit \(\tilde{V}\) such that

\[\left|\left\|(\langle 0|\otimes I\rangle\widetilde{V}|0\ldots 0)\right\|^{2}- \frac{\operatorname{Tr}(A)}{n}\right|\leq\frac{\theta\lambda_{\min}}{72 \alpha}\leq\frac{\theta}{2}\cdot\frac{\operatorname{Tr}(A)}{n}\leq\frac{ \operatorname{Tr}(A)}{2n}\] (86)

Therefore we have

\[\left\|(\langle 0|\otimes I\rangle\widetilde{V}|0\ldots 0)\right\|^{2}\geq\frac{ \operatorname{Tr}(A)}{n}-\frac{\operatorname{Tr}(A)}{2n}=\frac{\operatorname{Tr} (A)}{2n}\geq\frac{\lambda_{\min}}{72\alpha}\eqqcolon p_{\min}.\] (87)

as well as

\[\left\|(\langle 0|\otimes I\rangle\widetilde{V}|0\ldots 0)\right\|^{2}\leq \frac{\operatorname{Tr}(A)}{n}+\frac{\operatorname{Tr}(A)}{2n}=\frac{3 \operatorname{Tr}(A)}{2n}.\] (88)

Using the amplitude estimation technique of [55, Lemma 9] with \(p_{\min}=\lambda_{\min}/72\alpha\) and \(\mu=\theta/3\) gives us a \(\widetilde{p}\) that with probability at least \(4/5\) satisfies

\[\left|\widetilde{p}-\left\|(\langle 0|\otimes I\rangle\widetilde{V}|0\ldots 0 )\right\|^{2}\right|\leq\frac{\theta}{3}\left\|(\langle 0|\otimes I\rangle \widetilde{V}|0\ldots 0)\right\|^{2}\leq\frac{\theta}{2}\cdot\frac{\operatorname{Tr}(A)}{n}.\] (89)By combining (86) and (89) and using the triangle inequality, we get

\[\left|\frac{\operatorname{Tr}(A)}{n}-\tilde{p}\right|\leq\theta\cdot\frac{ \operatorname{Tr}(A)}{n}.\] (90)

Therefore, \(36\alpha n\widetilde{p}\) is a multiplicative \(\theta\)-approximation of \(\operatorname{Tr}(H)\).

It remains to show that the complexity statement holds. The construction of \(\widetilde{U}_{A}\) via Lemma 23 uses \(\mathcal{O}(T_{H}\cdot\frac{\alpha}{\lambda_{\min}}\log(\alpha/\theta\lambda _{\min}))\) elementary gates from the applications of \(U_{H}\), \(U_{H}^{\dagger}\), and controlled-\(U_{H}\), and \(\mathcal{O}((m+1)\frac{\alpha}{\lambda_{\min}}\log(\alpha/\theta\lambda_{\min}))\) other one- and two-qubit gates. The construction of \(\widetilde{V}\) requires an additional \(\mathcal{O}(\log n)\) gates. The amplitude estimation step requires \(\mathcal{O}(\sqrt{\alpha/\lambda_{\min}}/\theta)\) uses of \(\widetilde{V}\) and \(\widetilde{V}^{\dagger}\), and \(\mathcal{O}(\sqrt{\alpha/\lambda_{\min}}\log n/\theta)\) additional gates. So the overall complexity is

\[\mathcal{O}\left(\frac{\sqrt{\alpha/\lambda_{\min}}}{\theta}\left(\frac{ \alpha T_{H}}{\lambda_{\min}}\log\!\left(\frac{\alpha}{\theta\lambda_{\min}} \right)+\frac{(m+1)\alpha}{\lambda_{\min}}\log\!\left(\frac{\alpha}{\theta \lambda_{\min}}\right)+\log n\right)\right).\] (91)

Noting that \(T_{H}\geq m\) and \(T_{H}\geq\log n\) for any non-trivial \(U_{H}\) gives the stated bound. 

## Appendix G Quantum gradient estimation

**Lemma 26**.: _Given \(K\in\mathcal{S}_{K}(a)\) and \(\|K-K^{*}\|_{F}>\varepsilon\), we have_

\[\|\nabla f\|\geq c\varepsilon,\] (92)

_where the constant \(c=\sqrt{2\mu_{f}\nu\lambda_{\min}(R)/a}\)._

Proof.: This lemma follows directly from Lemma 9 and Lemma 10. 

**Lemma 27** (Block-encoded \(\nabla f(K)\)).: _Assume that we have efficient procedures (as described in Assumption 1) to access the problem data \(A,B,Q,R\) in \(\mathcal{O}(\operatorname{poly}\log(n))\) time. Let \(K\in\mathcal{S}_{K}(a)\) be a stabilizing policy stored in a quantum-accessible data structure. Given any \(\varepsilon_{b}>0\), we can implement a \((\gamma_{\nabla},\varepsilon_{b})\)-block-encoding of \(\nabla f(K)\) in cost \(\widetilde{\mathcal{O}}\left(a^{6}\rho^{3}\sqrt{\frac{\kappa^{11}}{ \varepsilon_{b}}}\right)\), where \(\gamma_{\nabla}\leq\widetilde{\mathcal{O}}(a^{6}\rho^{4}\kappa^{6})\)._

Proof.: We know that for the function \(f(K)\) defined in (5), the gradient has a closed-form expression: \(\nabla f(K)=2(RK-B^{\top}P(K))X(K)\). As shown in the proof of Theorem 5, we can implement a \((\gamma_{P},\varepsilon)\)-block-encoding of \(P(K)\) in cost \(\widetilde{\mathcal{O}}\left(a^{3}\rho\sqrt{\frac{\kappa^{5}}{\varepsilon}}\right)\), where \(\gamma_{P}\leq\widetilde{\mathcal{O}}(a^{4}\rho^{2}\kappa^{3})\). Similarly, since \(X(K)\) is the solution to the Lyapunov equation (assuming \(\Sigma_{0}=\mathbb{I}\))

\[(A-BK)X+X(A-BK)^{\top}+\mathbb{I}=0,\] (93)

we can implement a \((\gamma_{X},\varepsilon)\)-block-encoding of \(X(K)\) in cost \(\widetilde{\mathcal{O}}\left(a^{2}\rho\sqrt{\frac{\kappa^{5}}{\varepsilon}}\right)\), where \(\gamma_{X}\leq\widetilde{\mathcal{O}}(a^{2}\rho^{2}\kappa^{3})\). Based on our assumptions on the input procedures and the usage of quantum data structure, we can implement a \((s\|K\|_{F},0)\)-block-encoding of \(RK\) and a \((s\gamma_{P},s\varepsilon)\)-block-encoding of \(B^{\top}P(K)\). It follows that a \((\gamma_{\nabla},\varepsilon_{b})\)-block-encoding of \(\nabla f(K)\) can be implemented in cost \(\widetilde{\mathcal{O}}\left(a^{3}\rho\sqrt{\frac{\kappa^{5}}{\varepsilon}}\right)\), where

\[\gamma_{\nabla}\coloneqq\frac{1}{2}s\gamma_{X}(\gamma_{P}+\|K\|_{F})\leq \widetilde{O}\left(a^{6}\rho^{4}\kappa^{6}\right),\] (94)

and \(\varepsilon_{b}\leq\mathcal{O}((a+\gamma_{P}+\gamma_{X}\gamma_{P})\varepsilon)\). To achieve the desired precision, we pass the error parameter \(\varepsilon\to\varepsilon/(2(a+\gamma_{P}+\gamma_{X}\gamma_{P}))\) to the asymptotic cost.

**Definition 9**.: For a matrix \(G\) of size \(m\times n\), we could always write is as

\[G=\left[G_{1}\quad G_{2}\quad\cdots\quad G_{n}\right],\] (95)

where \(G_{i}\) is a column vector of size \(m\times 1\). Define \(|G_{\text{vec}}\rangle\) as

\[|G_{\text{vec}}\rangle=\begin{bmatrix}G_{1}\\ G_{2}\\ \vdots\\ G_{n}\end{bmatrix}/\|G\|_{F}.\] (96)

**Lemma 28** (Matrix Vectorization).: _Let \(U_{G}\) be a \(\left(\gamma_{\nabla},\varepsilon\right)\)-block-encoding of \(\left(\nabla f(K)\right)^{\top}\), and we denote_

\[G\coloneqq\gamma_{\nabla}(\langle 0^{r}|\otimes I)U_{G}(|0^{r}\rangle \otimes I),\] (97)

_where \(r\) is the number of ancilla qubits required. Then, we can prepare a quantum state \(|G_{\text{vec}}\rangle\) with \(\Omega(1)\) success probability using \(\widetilde{\mathcal{O}}\left(\frac{\gamma_{\nabla}\sqrt{m}}{\|G\|_{F}}\right)\) queries to \(U_{G}\) and its inverse._

Proof.: First, from Lemma 27 we know that we have \(U_{G}^{\top}\) that encodes \(\nabla f(K)^{\top}\). Notice that \(\nabla f(K)\) is of size \(m\times n\), so

\[\begin{split}& I^{r_{1}}\otimes(U_{G}^{r_{2},r_{3}})^{\top} \left(\frac{1}{\sqrt{m}}\sum_{i=0}^{m-1}|i\rangle^{r_{1}}\otimes(|0^{a}\rangle) ^{r_{2}}\otimes|i\rangle^{r_{3}}\right)\\ &=\frac{1}{\gamma_{\nabla}\sqrt{m}}\sum_{i=0}^{m-1}|i\rangle^{r_ {1}}\otimes(|0^{a}\rangle)^{r_{2}}\otimes(G^{\top}|i\rangle)^{r_{3}}+|\bot \rangle\\ &=\frac{\|G\|_{F}}{\gamma_{\nabla}\sqrt{m}}\frac{\sum_{i=0}^{m-1} |i\rangle^{r_{1}}\otimes(|0^{a}\rangle)^{r_{2}}\otimes(G^{\top}|i\rangle)^{r_ {3}}}{\|G\|_{F}}+|\bot\rangle\end{split}\] (98)

where \(r_{1},r_{2},r_{3}\) are the indexes for registers, where the \(r_{1}\) register has \(\log_{2}(m)\) qubits and the \(r_{3}\) register has \(\log_{2}(n)\) qubits(We can always assume \(m\) and \(n\) are the power of \(2\)). The state \(|\bot\rangle\) contains the state satisfy

\[(I^{r_{1}}\otimes\langle 0^{a}|^{r_{2}}\otimes I^{r_{3}})|\bot\rangle=0.\] (99)

By leveraging amplitude amplification, we can get the state \(|G_{\text{vec}}\rangle\) using \(\mathcal{O}(\frac{\gamma_{\nabla}\sqrt{m}}{\|G\|_{F}})\) queries to the block-encoding \(U_{G}^{\top}\). 

**Lemma 29** (Gradient entry estimation).: _Denote the state preparation in Lemma 28 for \(|G_{\text{vec}}\rangle\) as \(U_{G_{\text{vec}}}\), we are able to get the classical \(\mathcal{G}\) with_

\[\|\mathcal{G}-|G_{\text{vec}}\rangle\|\leq\varepsilon_{r}\] (100)

_using_

\[\widetilde{\mathcal{O}}\left(\frac{\gamma_{\nabla}}{\|G\|_{F}}\frac{m^{3/2}n} {\varepsilon_{r}}\right)\] (101)

_queries to \(U_{G}\) and \(\widetilde{\mathcal{O}}\left(\frac{\gamma_{\nabla}}{\|G\|_{F}}\frac{m^{3/2}n} {\varepsilon_{r}}\right)\) additional elementary gates._

Proof.: [7, Theorem 2] indicates that we can get \(\mathcal{G}\) using \(\widetilde{\mathcal{O}}(\frac{mn}{\varepsilon_{r}})\) queries to the oracle that prepares \(|G_{\text{vec}}\rangle\) and \(\widetilde{\mathcal{O}}\left(\frac{mn}{\varepsilon_{r}}\right)\) additional elementary gates. Since each \(U_{G_{\text{vec}}}\) requires

\[\widetilde{\mathcal{O}}\left(\frac{\gamma_{\nabla}\sqrt{m}}{\|G\|_{F}}\right)\] (102)

queries, we know the total cost should be

\[\widetilde{\mathcal{O}}\left(\frac{\gamma_{\nabla}}{\|G\|_{F}}\frac{m^{3/2}n} {\varepsilon_{r}}\right).\] (103)

**Lemma 30** (Gradient norm estimation).: _Suppose we have the block-encoding \(U_{G}\) defined in Lemma 27, where_

\[G=\gamma_{\nabla}(\langle 0|\otimes I)U_{G}(|0\rangle\otimes I),\] (104)

_then we are able to estimate \(\|G\|_{F}\) up an additive error \(\varepsilon_{a}\) using_

\[\mathcal{O}\left(\frac{\gamma_{\nabla}\sqrt{m}\|G\|_{F}}{\varepsilon_{a}^{2} +2\|G\|_{F}\varepsilon_{a}}\right)\] (105)

_queries to \(U_{G}\) and its inverse and also \(\widetilde{\mathcal{O}}\left(\frac{\gamma_{\nabla}\sqrt{m}\|G\|_{F}}{ \varepsilon_{a}^{2}+2\|G\|_{F}\varepsilon_{a}}\right)\) elementary gates._

Proof.: We still need the computation we did in equation 98, say

\[\begin{split}&\Gamma^{r_{1}}\otimes(U_{G}^{r_{2},r_{3}})^{\top} \left(\frac{1}{\sqrt{m}}\sum_{i=0}^{m-1}|i\rangle^{r_{1}}\otimes(|0^{a})^{r_{ 2}}\otimes|i\rangle^{r_{3}}\right)\\ &=\frac{\|G\|_{F}}{\gamma_{\nabla}\sqrt{m}}\frac{\sum_{i=0}^{m-1 }|i\rangle^{r_{1}}\otimes(|0^{a}\rangle)^{r_{2}}\otimes(G^{\top}|i\rangle)^{r_ {3}}}{\|G\|_{F}}+|\bot\rangle.\end{split}\] (106)

According to [55, Lemma 9], we can get the estimation to \(\left(\frac{\|G\|_{F}}{\gamma_{\nabla}\sqrt{m}}\right)^{2}\) with multiplicative error \(\mu\) using \(\mathcal{O}(\frac{\gamma_{\nabla}\sqrt{m}}{\mu\|G\|_{F}})\) queries to \(U_{G}^{\top}\). Note our estimator to \(\|G\|_{F}\) as \(a_{\text{est}}\), the goal we want to achieve is

\[|a_{\text{est}}-\|G\|_{F}|\leq\varepsilon_{a}.\] (107)

Consider our estimation to the amplitude as \(\left(\frac{a_{\text{est}}}{\gamma_{\nabla}\sqrt{m}}\right)^{2}\), set \(\mu=\frac{\varepsilon_{a}^{2}+2\varepsilon_{a}\|G\|_{F}}{\|G\|_{F}^{2}}\), we have

\[\begin{split}&\left(\frac{1}{\gamma_{\nabla}\sqrt{m}}\right)^{2} \left|a_{\text{est}}^{2}-\|G\|_{F}^{2}\right|=\left(\frac{1}{\gamma_{\nabla} \sqrt{m}}\right)^{2}\left(\left|a_{\text{est}}-\|G\|_{F}\right|\cdot\left|a_{ \text{est}}+\|G\|_{F}\right|\right)\\ &\leq\left(\frac{1}{\gamma_{\nabla}\sqrt{m}}\right)^{2}\left( \varepsilon_{a}\left(|a_{\text{est}}-\|G\|_{F}|+2\|G\|_{F}\right)\right)\leq \left(\frac{1}{\gamma_{\nabla}\sqrt{m}}\right)^{2}\left(\varepsilon_{a}^{2}+2 \varepsilon_{a}\|G\|_{F}\right)\\ &\leq\mu\left(\frac{\|G\|_{F}}{\gamma_{\nabla}\sqrt{m}}\right)^{ 2}.\end{split}\] (108)

This in turn gives us the estimation in 107. And this estimation requires

\[\mathcal{O}\left(\frac{\gamma_{\nabla}\sqrt{m}\|G\|_{F}}{\varepsilon_{a}^{2} +2\|G\|_{F}\varepsilon_{a}}\right)\] (109)

queries to \(U_{G}\) and its inverse. The gate complexity also follows from [55, Lemma 9]. 

**Theorem 31** (Quantum gradient estimation).: _Assume that we have efficient procedures (as described in Assumption 1) to access the problem data \(A,B,Q,R\) in \(\widetilde{\mathcal{O}}(\operatorname{poly}\log(n))\) time. Let \(K\in\mathcal{S}_{K}(a)\) be a stabilizing policy stored in a quantum-accessible data structure. Provided that \(\|K-K^{*}\|>\varepsilon\), we can compute a \(\theta\)-robust estimate of \(\nabla f(K)\) in cost_

\[\widetilde{\mathcal{O}}\left(\frac{m^{1.5}n}{\theta^{1.5}\varepsilon^{1.5}} \right).\] (110)

Proof.: We need an estimation to \(\nabla f(K)\) up to a multiplicative error \(\theta\). This requires a few steps as below:

**Block-Encoding.** From Lemma 27, we know we are able to construct a \((\gamma_{\nabla},\varepsilon_{b})\)-block-encoding to \(\nabla f(K)\) using

\[\widetilde{\mathcal{O}}\left(a^{6}\rho^{3}\sqrt{\frac{\kappa^{11}}{\varepsilon_ {b}}}\right)\] (111)

elementary gates. And we also have the estimation that \(\gamma_{\nabla}\leq\widetilde{\mathcal{O}}(a^{6}\rho^{4}\kappa^{6})\).

**Entry Retrieving.** The next step is to retrieve the entries in the estimation to \(\nabla f(K)\). We firstly use the technique introduced in Lemma 28 to get a state of the estimation to \(|G_{\text{vec}}\rangle\), and this step requires

\[\mathcal{O}\left(\frac{\gamma_{\nabla}\sqrt{m}}{\|G\|_{F}}\right)\] (112)

queries. Now we can use Lemma 29 to get the entries in \(|G_{\text{vec}}\rangle\) up to an additive error \(\epsilon_{r}\), using

\[\widetilde{\mathcal{O}}\left(\frac{\gamma_{\nabla}}{\|G\|_{F}}\frac{m^{3/2}n} {\varepsilon_{r}}\right)\] (113)

queries to \(U_{G}\).

**Norm Estimation.** The final step is to estimate the norm of \(G\). Lemma 30 tells us that we can achieve an additive error \(\varepsilon_{a}\) to \(\|G\|_{F}\) using

\[\mathcal{O}\left(\frac{\gamma_{\nabla}\sqrt{m}\|G\|_{F}}{\varepsilon_{a}^{2}+ 2\|G\|_{F}\varepsilon_{a}}\right)\] (114)

queries to \(U_{G}^{\top}\).

The rest of the theorem is just to assemble all these steps. Note the requirement is

\[\|G-\nabla f(K)\|_{F}\leq\theta\|f(K)\|_{F},\] (115)

and according to Lemma 26, \(\|\nabla f(K)\|_{F}\geq c\epsilon\) before convergence.

Denote the entries retrieved in the Entry Retrieving step form a matrix \(\mathcal{G}\) where \(\|\mathcal{G}\|_{F}=1\), the norm estimated in the Norm Estimation step as \(a_{\text{est}}\), our estimator is then \(a_{\text{est}}\mathcal{G}\). Choose

\[\varepsilon_{b}=\frac{c\theta\varepsilon}{3},\quad\varepsilon_{a}=\frac{c \theta\varepsilon}{3},\quad\varepsilon_{r}=\frac{1}{3+c\theta},\] (116)

we then know that \(\|G-\nabla f(K)\|\leq\frac{c\theta\varepsilon}{3}\), \(\nabla f(K)\geq c\varepsilon\), then

\[\mathcal{O}(\varepsilon)\leq\left|\|\nabla f(K)\|_{F}-\frac{c\theta\varepsilon }{3}\right|\leq\|G\|_{F}\leq\|\nabla f(K)\|_{F}+\frac{c\theta\varepsilon}{3}.\] (117)

Thus it is clear to see

\[\begin{split}&\|a_{\text{est}}\mathcal{G}-\nabla f(K)\|_{F}\\ &=\left\|a_{\text{est}}\mathcal{G}-\|G\|_{F}\mathcal{G}+\|G\|_{F} \mathcal{G}-G+G-\nabla f(K)\right\|_{F}\\ &\leq\left\|a_{\text{est}}\mathcal{G}-\|G\|_{F}\mathcal{G}\right\| _{F}+\left\|\|G\|_{F}\mathcal{G}-G\right\|_{F}+\left\|G-\nabla f(K)\right\|_{F }\\ &\leq\varepsilon_{a}+\|G\|_{F}\varepsilon_{r}+\varepsilon_{b} \leq\varepsilon_{a}+(\|\nabla f(K)\|_{F}+\frac{c\theta\varepsilon}{3}) \varepsilon_{r}+\varepsilon_{b}\\ &\leq\theta\|f(K)\|_{F}.\end{split}\] (118)

And the total gate complexity should be

\[\widetilde{\mathcal{O}}\left(\frac{a^{12}\rho^{7}\kappa^{11.5}m^{1.5}n}{\theta ^{1.5}\varepsilon^{1.5}}\right).\] (119)

## Appendix H Convergence analysis

**Lemma 32**.: _Given any \(K\in\mathcal{S}_{K}\), let \(G\) be a \(\theta\)-robust estimate of \(\nabla f(K)\). Then, we have_

\[\begin{split}\langle G,\nabla f(K)\rangle&\geq(1- \theta)\|\nabla f(K)\|_{F}^{2},\\ \|G\|_{F}^{2}&\leq(1+\theta)^{2}\|\nabla f(K)\|_{F}^{ 2}.\end{split}\] (120)Proof.: It is straightforward to verify that

\[\langle G,\nabla f(K)\rangle =\langle G-\nabla f(K)+\nabla f(K),\nabla f(K)\rangle=\langle G- \nabla f(K),\nabla f(K)\rangle+\|\nabla f(K)\|_{F}^{2}\] \[\geq-\|G-\nabla f(K)\|_{F}\|\nabla f(K)\|_{F}+\|\nabla f(K)\|_{F}^ {2}\geq(1-\theta)\|\nabla f(K)\|_{F}^{2}.\] (121)

\[\|G\|_{F}^{2} =\|G-\nabla f(K)+\nabla f(K)\|_{F}^{2}\leq(\|G-\nabla f(K)\|_{F}+ \|\nabla f(K)\|_{F})^{2}\] (122) \[\leq(1+\theta)^{2}\|\nabla f(K)\|_{F}^{2}.\]

**Lemma 33** (Descent lemma).: _Given \(K\in\mathcal{S}_{K}(a)\), and let \(G\) be a \(\theta\)-robust estimate of \(\nabla f(K)\). Then, there exists a positive \(\sigma_{m}\) such that for all \(\sigma\in[0,\sigma_{m}]\), we have_

\[f(K-\sigma G)-f(K^{*})\leq\left(1-\sigma/\mu\right)\left(f(K)-f(K^{*})\right),\] (123)

_where \(\mu\), \(\sigma_{m}\) only depends on \(A,B,R,Q\), and \(a\), and \(\mu>\sigma_{m}\)._

Proof.: This lemma is a direct consequence of Lemma 32 (with \(\theta<1/2\)) and [45, Proposition 6]. 

**Proposition 34**.: _For any initial stabilizing feedback gain \(K_{0}\in\mathcal{S}_{K}\), we denote \(a\coloneqq f(K_{0})\). Then, there exists constants \(\mu>\sigma_{m}>0\), depending only on \(A,B,Q,R\), and \(a\), such that for any fixed \(\sigma\in[0,\sigma_{m}]\), the iterates of Algorithm 1 satisfy_

\[f(K_{k})-f(K^{*})\leq\left(1-\sigma/\mu\right)^{k}\left(f(K_{0})- f(K^{*})\right),\] (124a) \[\|K_{k}-K^{*}\|^{2}\leq b(1-\sigma/\mu)^{k}\|K_{0}-K^{*}\|^{2},\] (124b)

_where \(b\) is an absolute constant that is independent of \(k\)._

Proof.: The first part (124a) is a direct corollary of Lemma 33. By Lemma 9 and (124a), we have

\[\|K_{k}-K^{*}\|_{F}^{2} \leq\frac{a}{\nu\lambda_{\min}(R)}\left(f(K_{k})-f(K^{*})\right)\] (125) \[\leq(1-\sigma/\mu)^{k}\left(f(K_{0})-f(K^{*})\right)\leq b(1- \sigma/\mu)^{k}\|K_{0}-K^{*}\|,\] (126)

where the last step follows from [45, Lemma 2] and \(b=\lambda_{\max}(RX(K_{0}))\). 

**Theorem 35** (Quantum policy gradient for LQR).: _Assume that we have efficient procedures (as described in Assumption 1) to access the problem data \(A,B,Q,R\) in \(\mathcal{O}(\operatorname{poly}\log(n))\) time. Let \(K_{0}\in\mathcal{S}_{K}\) be a stabilizing policy. Then, Algorithm 1 outputs an \(\varepsilon\)-approximate solution to Problem 1 in cost_

\[\widetilde{\mathcal{O}}\left(\frac{m^{1.5}n}{\varepsilon^{1.5}}\right).\] (127)

Proof.: Notice that with lemma 33, we need \(\log\left(\frac{1}{\varepsilon}\right)\) iterations. By Theorem 31, the quantum gradient estimation subroutine requires \(\widetilde{\mathcal{O}}\left(\frac{m^{1.5}n}{\varepsilon^{1.5}}\right)\) elementary gates. 

## Appendix I Extended numerical experiments

### Aircraft Control Problem

We perform another experiment on a practical problem that can be formulated as LQR. Here, we consider the aircraft flight control problem, specifically for pitch angle control. We adopt a linearized model of the aircraft around a steady flight condition. For a small aircraft, the pitch dynamics can be represented by the following state variables: pitch angle \(\theta\) (rad) and pitch rate \(q\) (rad/s). The control input is elevator deflection angle \(\delta\) (rad). The state-space model can be represented as \(\dot{x}=Ax+Bu\), where \(x=[\theta,q]^{\top}\), \(u=[\delta]\). We set \(A=[[0,1],[0,-0.5]]^{\top}\), \(B=[0,1]^{\top}\), \(Q=[[10,0],[0,1]]^{\top}\), and \(R=[0.1]\). The plot of our optimization curve is available in the Figure 3. Our method converges faster than the classical method.

### Relative Errors

We conducted further numerical experiments to understand how the optimality scales with problem size in Figure Figure 4. Here, we scale the number of masses in a spring-mass system from 2 to 4, and the problem dimension scales accordingly from 2 to 8. We measure the optimality by the relative error found in both our method and the classical method. The relative errors are \((J-J^{*})/j^{*}\) and \((f(K)-f(K^{*}))/f(K^{*})\). As the dimension scales up, the relative errors increase, while our method consistently outperforms the classical optimization method.

Figure 4: **Relative Error. We scale the size of a mass-spring system and our method consistently gets smaller relative error compared to [45].**

Figure 3: **Numerical Results on Convergence. In the aircraft control problem, our policy gradient descent algorithm converges much faster than classic method [45].**

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: The main claims made in the abstract accurately reflect the paper's technical contributions and scope. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: The limitations and future work of this work are discussed in the last section of the main paper. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs**Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: The full set of technical assumptions is provided in the introduction section (see "Problem Formulation"). A complete proof of our main theoretical results can be found in the main paper and the appendices. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: All information needed to reproduce the main experiment results of the paper is disclosed in the "Numerical Experiments" section. The code for the experiment is attached in the supplementary material. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset).

4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: The code for the experiment is attached in the supplementary material. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: All the training and test details are provided in the "Numerical Experiments" section. The source code for the experiment is attached in the supplementary material. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes]Justification: The paper reports error bars to reflect the statistical significance of the experiments, see the "Numerical Experiments" section and Figure 2. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors). * It should be clear whether the error bar is the standard deviation or the standard error of the mean. * It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified. * For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). * If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: The paper provides sufficient descriptive information on the computer resources, see the "Numerical Experiments" section. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: The research conducted in the paper conforms with the NeurIPS Code of Ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.

* The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: The paper discusses the societal impacts of the work performed in the "Conclusion and Future Work" section. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. * If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: The paper mainly focuses on the theoretical foundation of computer algorithms and poses no such risks. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets**Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [NA] Justification: The paper does not use existing assets. Guidelines:

* The answer NA means that the paper does not use existing assets.
* The authors should cite the original paper that produced the code package or dataset.
* The authors should state which version of the asset is used and, if possible, include a URL.
* The name of the license (e.g., CC-BY 4.0) should be included for each asset.
* For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.
* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.

13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [Yes] Justification: The source code of the numerical experiments is provided in the supplementary material with appropriate documentation. Guidelines:

* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.

14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.

* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper. * We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution. * For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.