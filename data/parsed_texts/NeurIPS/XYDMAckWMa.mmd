# Explicit Flow Matching:

On The Theory of Flow Matching Algorithms with Applications

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

This paper proposes a novel method, Explicit Flow Matching (ExFM), for training and analyzing flow-based generative models. ExFM leverages a theoretically grounded loss function, ExFM loss (a tractable form of Flow Matching (FM) loss), to demonstrably reduce variance during training, leading to faster convergence and more stable learning. Based on theoretical analysis of these formulas, we derived exact expressions for the vector field (and score in stochastic cases) for model examples (in particular, for separating multiple exponents), and in some simple cases, exact solutions for trajectories. In addition, we also investigated simple cases of diffusion generative models by adding a stochastic term and obtained an explicit form of the expression for score. While the paper emphasizes the theoretical underpinnings of ExFM, it also showcases its effectiveness through numerical experiments on various datasets, including high-dimensional ones. Compared to traditional FM methods, ExFM achieves superior performance in terms of both learning speed and final outcomes.

## 1 Introduction

In recent years, there has been a remarkable surge in Deep Learning, wherein the advancements have transitioned from purely neural networks to tackling differential equations. Notably, Diffusion Models [16] have emerged as key players in this field. This models transform a simple initial distribution, usually a standard Gaussian distribution, into a target distribution via a solution of Stochastic Differentiable Equation (SDE) [1] or Ordinary Differentiable Equation (ODE)[2] with right-hand side representing a trained neural network. The Conditional Flow Matching (CFM) [9] technique, which we focus on in our research, is a promising approach for constructing probability distributions using conditional probability paths, which is notably a robust and stable alternative for training Diffusion Models. The development of the CFM-based approach includes various techniques and heuristics [4; 7; 13] aimed at improving convergence or quality of learning or inference. For example, in the works [19; 20; 10] it was proposed to straighten the trajectories between points by different methods, which led to serious modifications of the learning process. We refer the reader for, example, to the paper [20] where different FM-based approaches are summarised, and to the paper [9] for the connection between Diffusion Models and CFM.

In our work, we introduced an approach which we called Explicit Flow Matching (ExFM), to consider the Flow Matching framework theoretically by modifying the loss and writing the explicit value of the vector field. Strictly speaking, the presented loss is a tractable form of the FM loss, see Eq. (5) of [9]. Base on this methods we can improve the convergence of the method in practical examples reducing the variance of the loss, but the main focus of our paper is on theoretical derivations.

Our method allows us to write an expression for the vector field in closed form for quite simple cases (Gaussian distributions), however, we note that Diffusion Models framework in the case of a Gaussian Mixture of two Gaussian as a target distribution is still under investigation, see recent publications [15; 8].

Our main contributions are:

1. A tractable form of the FM loss is presented, which reaches a minimum on the same function as the loss used in Conditional Flow Matching, but has a smaller variance;
2. The explicit expression in integral form for the vector field delivering the minimum to this loss (therefore for Flow Matching loss) is presented.
3. As a consequence, we derive expressions for the flow matching vector field and score in several particular cases (when linear conditional mapping is used, normal distribution, etc.);
4. Analytical analysis of SGD convergence showed that our formula have better training variance on several cases;
5. Numerical experiments show that we can achieve better learning results in fewer steps.

### Preliminaries

Flow matching is well known method for finding a flow to connect samples from two distribution with densities \(\rho_{0}\) and \(\rho_{1}\). It is done by solving continuity equation with respect to the time dependent vector field \(\overline{v}(x,t)\) and time-dependent density \(\rho(x,t)\) with boundary conditions:

\[\left\{\begin{aligned} \frac{\partial\rho(x,t)}{\partial t}& =-\operatorname{div}(\rho(x,t)\overline{v}(x,t)),\\ \rho(x,0)&=\rho_{0}(x),\quad\rho(x,1)=\rho_{1}(x). \end{aligned}\right.\] (1)

Function \(\rho(x,t)\) is called _probability density path_. Typically, the distribution \(\rho_{0}\) is known and it is chosen for convenience reasons, for example, as standard normal distribution \(\rho(x)=\mathcal{N}(x\mid 0,I)\). The distribution \(\rho_{1}\) is unknown and we only know the set of samples from it, so the problem is to approximate the vector field \(v(x,t)\approx\overline{v}(x,t)\) using these samples. To make problem (1) well defined, one usually imposes additional regularity conditions on the densities, such as smoothness. The rigorous justification of the obtained results we put in the Appendix, leaving the general formulations of theorems and ideas in the main text.

From a given vector field, we can construct a _flow_\(\phi_{t}\), _i. e._, a time-dependent map, satisfying the ODE \(\frac{\partial\phi_{t}(x)}{\partial t}=v(\phi_{t}(x),t)\) with initial condition \(\phi_{0}(x)=x\). Thus, one can sample a point \(x_{0}\) from the distribution \(\rho_{0}\) and then using this ODE obtain a point \(x_{1}=\phi_{1}(x_{0})\) which have a distribution approximately equal to \(\rho_{1}\). For given boundary \(\rho_{0}\) and \(\rho_{1}\), the vector field or path solutions are not the only solutions, but if we have found any solution, it will already allow us to sample from the unknown density \(rho_{1}\). However, if the problem is more narrowly defined, _e. g._, one needs to have a map that is close to the Optimal Transport (OT) map, we have to impose additional constraints.

The problem of finding any vector field \(v\) is solved in conditional manner in the paper [9], where so-called Conditional Flow Matching (CFM) is present. Namely, the following loss function was introduced for the training a model \(v_{\theta}\) which depends on parameters \(\theta\)

\[L_{\text{CFM}}(\theta)=\mathbb{E}_{t}\mathbb{E}_{x_{1},x_{0}}\big{\|}v_{ \theta}(\phi_{t,x_{1}}(x_{0}),\,t)-\phi_{t,x_{1}}^{\prime}(x_{0})\big{\|}^{2},\] (2)

where \(\phi_{t,x_{i}}(x_{0})\) is some flow, conditioned on \(x_{1}\) (one can take \(\phi_{t,x_{i}}(x_{0})=(1-t)x_{0}+tx_{1}+\sigma_{s}tx_{0}\) in the simplest case, where \(\sigma_{s}>0\) is a small parameter need for this map to be invertable at any \(0\leq t\leq 1\)). Hereinafter the dash indicates the time derivative. Time variable \(t\) is uniformly distributed: \(t\sim\mathcal{U}[0,1]\) and random variables \(x_{0}\) and \(x_{1}\) are distributed according to the initial and final distributions, respectively: \(x_{0}\sim\rho_{0}\), \(x_{1}\sim\rho_{1}\). Below we omit specifying of the symbol \(\mathbb{E}\) the distribution by which the expectation is taken where it does not lead to ambiguity.

### Why new method?

Model training using loss (2) have the following disadvantage: during training, due to the randomness of \(x_{0}\) and \(x_{1}\), significantly different values can be presented for model as output value at close model 

[MISSING_PAGE_EMPTY:3]

To obtain the modified loss, we return to end of the standard CFM loss representation in (3). It is written as the expectation over two random variables \(x_{1}\) and \(x_{t}\) having a common distribution density

\[\{x_{1},x_{t}\}\sim\rho_{j}(x_{1},x_{t},t)=\rho_{x_{1}}(x_{t},t)\rho_{1}(x_{1}),\] (4)

which, generally speaking, is not factorizable. Let us rewrite this expectations in terms of two independent random variables, each of which have its marginal distribution. The marginal distribution \(\rho_{m}\) of \(x_{t}\) can be obtained via integration:

\[\rho_{m}(x_{t},t)=\int\rho_{j}(x_{1},x_{t},t)\,\mathrm{d}x_{1}=\int\rho_{x_{1}} (x_{t},t)\rho_{1}(x_{1})\,\mathrm{d}x_{1}\,,\] (5)

while the marginal distribution of \(x_{1}\) is just (unknown) function \(\rho_{1}\). Let for convenience \(w(t,x_{1},x)=\phi^{\prime}_{t,x_{1}}\big{(}\phi^{-1}_{t,x_{1}}(x)\big{)}\)1. We have

Footnote 1: Note, that \(w(t,x_{1},x)\) is the conditional velocity at the given point \(x\).

\[L_{\text{CFM}}(\theta)=\mathbb{E}_{t,x_{1},x_{t}\sim\rho_{x_{1}} (\cdot,t)}\|v_{\theta}(x_{t},\,t)-w(t,x_{1},x_{t})\|^{2}=\\ \int_{0}^{1}\iint\|v_{\theta}(x_{t},\,t)-w(t,x_{1},x_{t})\|^{2} \rho_{x_{1}}(x,t)\rho_{1}(x_{1})\,\mathrm{d}x_{t}\,\mathrm{d}x_{1}\mathrm{d}t= \\ \int_{0}^{1}\iint\|v_{\theta}(x_{t},\,t)-w(t,x_{1},x_{t})\|^{2} \left.\big{(}\rho_{x_{1}}(x_{t},t)\big{/}\rho_{m}(x_{t},t)\big{)}\,\rho_{m}(x_ {t},t)\rho_{1}(x_{1})\,\mathrm{d}x_{t}\,\mathrm{d}x_{1}\mathrm{d}t=\\ \mathbb{E}_{t,x_{1},x\sim\rho_{m}(\cdot,t)}\|v_{\theta}(x,\,t)-w( t,x_{1},x)\|^{2}\,\rho_{c}(x|x_{1},t)/\rho_{1}(x_{1}),\] (6)

where we introduce a conditional distribution

\[\rho_{c}(x|x_{1},t):=\rho_{x_{1}}(x,t)\rho_{1}(x_{1})/\rho_{m}(x,t):=\rho_{x_{ 1}}(x,t)\rho_{1}(x_{1})\bigg{/}\int\rho_{x_{1}}(x,t)\rho_{1}(x_{1})\,\mathrm{ d}x_{1}.\] (7)

The key feature of the representation (6) is that the integration variables \(x_{1}\) and \(x\) are independent. Thus, we can evaluate them using Monte Carlo-like schemes in different ways. However, we go further and make a modification to this loss to reduce the variance of Monte Carlo methods.

### New loss and exact expression for vector field

Note that so far the expression for \(L_{\text{CFM}}\) have not changed, it has just been rewritten in different forms. Now we change this expression so that its numerical value, generally speaking, may be different, but the derivative of the model parameters will be the same. We introduce the following loss

\[L_{\text{ExFM}}(\theta)=\mathbb{E}_{t}\mathbb{E}_{x\sim\rho_{m} }\Big{\|}v_{\theta}(x,\,t)-\mathbb{E}_{x_{1}\sim\rho_{1}}w(t,x_{1},x)\rho_{c}( x|x_{1},t)/\rho_{1}(x_{1})\Big{\|}^{2}=\\ \int_{0}^{1}\int\Bigl{\|}v_{\theta}(x,\,t)-\int w(t,x_{1},x)\times \rho_{c}(x|x_{1},t)\,\mathrm{d}x_{1}\Bigr{\|}^{2}\rho_{m}(x,t)\,\mathrm{d}x \,\mathrm{d}t.\] (8)

**Theorem 2.1**.: _Losses \(L_{\text{CFM}}\) in Eq. (2) and \(L_{\text{ExFM}}\) in Eq. (8) have the same derivative with respect to model parameters:_

\[\mathrm{d}L_{\text{CFM}}(\theta)/\mathrm{d}\theta\,=\,\mathrm{d}L_{\text{ExFM} }(\theta)/\mathrm{d}\theta\.\] (9)

Proof is in the Appendix A.1.

In the presented loss \(L_{\text{ExFM}}\), the integration (outside the norm operator) proceeds on those variables on which the model depends, while inside this operator there are no other free variables. Thus, using this kind of loss, it is possible to find an exact analytical expression for the vector field for which the minimum of this loss is zero (unlike the loss \(L_{\text{CFM}}\)). Namely, we have

\[v(x,t)=\int w(t,x_{1},x)\rho_{c}(x|x_{1},t)\,\mathrm{d}x_{1}\,.\] (10)

We can obtain the exact form of this vector field given the particular map \(\phi_{t,x_{1}}\). For example, the following statement holds:

**Corollary 2.2**.: _Consider the linear conditioned flow \(\phi_{t,x_{1}}(x_{0})=(1-t)x_{0}+tx_{1}\) which is inevitable as \(0\leq t<1\). Then \(w(t,x_{1},x)=\frac{x_{1}-x}{1-t}\), \(\rho_{x_{1}}(x,t)=\rho_{0}\left(\frac{x-x_{1}t}{1-t}\right)\frac{1}{(1-t)^{d}}\) and the loss \(L_{\text{ExFM}}\) in Eq. (8) reaches zero value when the model of the vector field have the following analytical form_

\[v(x,t)=\int(x_{1}-x)\rho_{0}\left(\frac{x-x_{1}t}{1-t}\right)\rho_{1}(x_{1}) \,\mathrm{d}x_{1}\left/\left((1-t)\int\rho_{0}\left(\frac{x-x_{1}t}{1-t}\right) \rho_{1}(x_{1})\,\mathrm{d}x_{1}\right).\right.\] (11)

_This is the exact value of the vector field whose flow translates the given distribution \(\rho_{0}\) to \(\rho_{1}\)._

Complete proofs are in the Appendix A.3.1. Note that the result (11) is not totally new, for example, a similar result (though in the form of a general expression rather than an explicit formula), was given in [19], Eq. (9). However, our contribution consists of both the general form (10) and practical and theoretical conclusions from it (see below).

_Remark 2.3_.: In the case of the initial and final times \(t=0,\,1\), Eq. (11) is noticeably simpler

\[v(x,0)=\mathbb{E}_{x_{1}}x_{1}-x=\int x_{1}\rho_{1}(x_{1})\,\mathrm{d}x_{1}-x.\quad v(x,1)=x-\int x_{0}\rho_{0}(x_{0})\,\mathrm{d}x_{0}\,.\] (12)

This expression for the initial velocity means that each point first tends to the center of mass of the unknown distribution \(\rho_{1}\) regardless of its initial position.

Extensions to SDENow let the conditional map be stochastic: \(\phi_{t,x_{1}}=(1-t)x_{0}+tx_{1}+\sigma_{e}(t)\epsilon\), where \(\epsilon\sim\mathcal{N}(0,1)\). Typically, \(\sigma_{e}(0)=\sigma_{e}(1)=0\), for example, \(\sigma_{e}(t)=t(1-t)\sigma_{e}\).

Note that this formulation covers (with appropriate selection of the \(\sigma_{e}(t)\) parameter) the case of diffusion models [20].

Then, we can write the exact solution for a so-called _score and flow matching_ objective (see [20] for details)

\[\mathcal{L}_{[\mathrm{SF}]^{2}\mathrm{M}}(\theta)=\mathbb{E}\big{[}\underbrace {\|v_{\theta}(x,t)-u_{t}^{\circ}(x)\|^{2}}_{\text{flow matching loss}}+\lambda(t)^{2} \underbrace{\|s_{\theta}(x,t)-\nabla\log p_{t}(x)\|^{2}}_{\text{score matching loss}}\big{]}.\]

that corresponds to this map. In the last expression, the following explicit conditional expressions are considered in the cited paper for the case \(\sigma_{e}(t)=\sqrt{t(1-t)}\sigma_{e}\)

\[u_{t}^{\circ}(x)=\frac{1-2t}{t(1-t)}(x-(tx_{1}+(1-t)x_{0}))+(x_{1}-x_{0}),\; \;\nabla\log p_{t}(x)=\frac{tx_{1}+(1-t)x_{0}-x}{\sigma_{e}^{2}t(1-t)}.\]

The exact solution (our result, explicit analog of the Eq. (10) from [20]) under consideration has the form (44) and (46) and, for example for the for the Gaussian \(\rho_{0}\) this expressions reduced to the Eq. (49) and (50), correspondingly. See Appendix E for the details on this case.

Simple examplesConsider the case of Standard Normal Distribution as \(\rho_{0}\) and Gaussian Mixture of two Gaussians as \(\rho_{1}\). Vector field have a closed form (37) in this case, and we can fast numerically solve ODE for trajectories. Random generated trajectories and plot of the vector field are shown on Fig. 2 (a)-(b). Detailed explanation of this case is in the Sec. D.2. Another example is related to the case of a stochastic map in the form of Brownian Bridge, which briefly described in the last paragraph and considered in Sec. E.3.2 in details, see Fig. 2 (c)-(f). Note that at some \(\sigma_{e}\) values the trajectories are a little bit straightened in this case compared to the usual linear map, if we compare cases on the Fig. 6.

### Training scheme based on the modified loss

Let us consider the difference between our new scheme based on loss \(L_{\text{ExFM}}\) and the classical CFM learning scheme. As a basis for the implementation of the learning scheme, we take the open-source code2 from the works [20, 19].

Footnote 2: https://github.com/atong01/conditional-flow-matching

Consider a general framework of numerical schemes in classical CFM. We first sample \(m\) random time variables \(t\sim\mathcal{U}[0,1]\). Then we sample several values of \(x\). To do this, we sample a certain number \(n\) samples \(\{x_{0}^{i}\}_{i=1}^{n}\) from the "noisy" distribution \(\rho_{0}\), and the same number \(n\) of samples \(\{x_{1}^{i}\}_{i=1}^{n}\) fromthe unknown distribution \(\rho_{1}\). Then we pair them (according to some scheme), and get \(n\) samples as \(x^{j,i}=\phi_{t^{j},x_{1}^{i}}(x_{0}^{i})\) (_e. g._ a linear combination in the simple case of linear map: \(x^{j,i}=(1-t^{j})x_{0}^{i}+t^{j}x_{1}^{i}\)), \(\forall i=1,2,\ldots,n\); \(\forall j=1,2,\ldots,m\). Note, than one of the variable \(n\) or \(m\) (or both) can be equal to \(1\).

At the step 2, the following discrete loss is constructed from the obtained samples

\[L_{\text{CFM}}^{d}(\theta)=\sum_{j=1}^{m}\sum_{i=1}^{n}\norm{v_{\theta}(x^{j,i },\,t^{j})-\phi^{\prime}_{t^{j},x_{1}^{i}}(x_{0}^{i})}^{2}.\] (13)

Finally, we do a standard gradient descent step to update model parameters \(\theta\) using this loss.

The first and last step in our algorithm is the same as in the standard algorithm, but the second step is significantly different. Namely, we additionally generate a sufficiently large number \(N\gg n\cdot m\) of samples \(\overline{x}_{1}\) from the unknown distribution \(\rho_{1}\), sampling \((N-n)\) new samples and adding to it the samples \(\{x_{1}^{i}\}_{1}^{n}\) that are already obtained on the previous step.

Then we form the following discrete loss which replaces the integral on \(x_{1}\) in \(L_{\text{ExFM}}\) by its evaluation \(v^{d}\) by self-normalized importance sampling or rejection sampling (see Appendix B for details)

\[L_{\text{ExFM}}^{d}(\theta)=\sum_{j=1}^{m}\sum_{i=1}^{n}\norm{v_{\theta}(x^{j, i},\,t^{j})-v^{d}(x^{j,i},\,t^{j})}^{2}.\] (14)

For example, if we use self-normalized importance sampling and assume that the Jacobian \(\det\bigl{[}\partial\phi_{t,x_{1}}^{-1}(x)\bigr{/}\partial x\bigr{]}\) do not depend on \(x_{1}\), we can write

\[v^{d}(x,\,t)=\left(\sum_{k=1}^{N}w(t,\overline{x}_{1}^{k},x)\rho_{0}\bigl{(} \phi_{t,\overline{x}_{1}^{k}}^{-1}(x)\bigr{)}\right)\Bigg{/}\!\!\sum_{k=1}^{ N}\rho_{0}\bigl{(}\phi_{t,\overline{x}_{1}^{k}}^{-1}(x)\bigr{)}\.\] (15)

**Theorem 2.4**.: _Under mild conditions, the error variance of the integral gradient (9) using the Monte Carlo method (14) is lower than using formula (13) with the same number \(n\cdot m\) of samples for \(\{x\}\)._

Sketch of the proof is in the Appendix A.2. The steps of our scheme are formally summarized in Algorithm 1.

Particular case of linear map and Gaussian noiseLet \(\phi_{t,x_{1}}\) be the linear flow: \(\phi_{t,x_{1}}(x_{0})=(1-t)x_{0}+tx_{1}\). and consider the case of standard normal distribution for the initial density \(\rho_{0}\): \(\rho_{0}(x)\sim\mathcal{N}(x\mid 0,I)\). Then in the case of using self-normalized importance sampling, we have

\[v^{d}(x,\,t)=\sum_{k=1}^{N}\frac{\overline{x}_{1}^{k}-x}{1-t}\bigl{(}\mathrm{ SoftMax}(Y^{1},\,\ldots,\,Y^{N})\bigr{)}_{k},\quad\text{where}\quad Y^{k}=-\frac{1}{2} \frac{\norm{x-t\cdot\overline{x}_{1}^{k}}^{2}}{1-t}.\] (16)

Here, the lower index \(k\) in \(\mathrm{SoftMax}\) stands for the \(k\)-th component, and the \(\mathrm{SoftMax}\) operation itself came about due to exponents in the Gaussian density as a more stable substitute for computing than directly through exponents.

Extension of other maps and initial densities \(\rho_{0}\)Common expression (10) can be reduced to closed form for the particular choices of density \(\rho_{0}\) and map \(\phi\) (consequently, expression for \(w\)). We summarise several known approaches for which FM-based techniques can be applied in Table 13. See Appendix C and D for derivations of formulas and for more extensions.

Figure 2: Trajectories and vector field obtained in simple cases: (a) \(N=80\) random trajectories from \(\mathcal{N}\left(\cdot\middle|0,1^{2}\right)\) to GM; (b) 2D plot of the vector field in this case (c)–(f) \(N=40\) random trajectories from \(\mathcal{N}\left(\cdot\middle|0,1^{2}\right)\) to \(\mathcal{N}\left(\cdot\middle|2,3^{2}\right)\) and 2D plot of the vector fieldfor different \(\sigma_{e}\) for the Brownian Bridge map

ComplexityWe assume that the main running time of the algorithm is spent on training the model, especially if it is quite complex. Thus, the running time of one training step depends crucially on the number \(n\cdot m\) of samples \(\{x\}\) and it is approximately the same for both algorithms: the addition of points \(\overline{x}_{1}\) entails only an additional calculation using formula (16), which can be done quickly and, moreover, can be simple parallelized.

### Irreducible dispersion of gradient for CFM optimization

Ensuring the stability of optimization is vital. Let \(\Delta\theta\) be changes in parameters, obtained by SGD with step size \(\gamma/2\) applied to the functional from Eq. (13):

\[\Delta v(x^{j,i},t^{j})=-\gamma\cdot\big{(}v(x^{j,i},t^{j})-v^{d}(x^{j,i},\,t^{ j})\big{)}.\] (17)

For simplification, we consider a function, \(v_{\theta}(x,t)\), capable of perfectly fitting the CFM problem and providing an optimal solution for any point \(x\) and time \(t\). For a linear conditional flow at a specific point \(x^{j,i}\sim\rho_{x^{i}_{1}}(\cdot,t^{j})\) at time \(t^{j}\sim U(0,1)\), the update \(\Delta v(x^{j,i},t^{j})\) can be represented as follows:

\[\Delta v(x^{j,i},t^{j})=\gamma\left(x^{i}_{1}-\dot{x}^{i}_{0}-v(x^{j,i},t^{j}) \right),\] (18)

where \(\dot{x}^{i}_{0}=\frac{x^{j,i}-t^{j}x^{i}_{1}}{1-t^{j}}\). We define the dispersion \(\mathbb{D}_{x,x_{1}}f(x,x_{1})\) for \(x\sim\rho_{x_{1}}(\cdot,t)\) and \(x_{1}\sim\rho_{1}\) as:

\[\mathbb{D}_{x,x_{1}}f(x,x_{1})=\mathbb{E}_{x,x_{1}}f^{2}(x,x_{1})-(\mathbb{E} _{x,x_{1}}f(x,x_{1}))^{2}.\] (19)

**Proposition 2.5**.: _At the time \(t=0\), the dispersion of update in the form (18) have the following element-wise lower bound:_

\[\mathbb{D}_{x^{j,i},x^{i}_{1}}\Delta v(x^{j,i},0)=\gamma^{2}\mathbb{D}_{x^{i} _{1}}x^{i}_{1}+\gamma^{2}\mathbb{D}_{x^{j,i},x^{i}_{1}}(x^{j,i}+v(x^{j,i},0)) \geq\gamma^{2}\mathbb{D}_{x^{i}_{1}}x^{i}_{1}.\]

_Equality is reached when the model \(v(x^{j,i},0)\) has exact values equal to (12)._

Given that the dispersion cannot be reduced with an increase in batch size, the only available option is to decrease the step size of the optimization method, _i. e._, reduce the learning rate slowing down the convergence. The situation is much better for the proposed loss in (14). We can express the update \(\Delta v(x^{j,i},t^{j})\) in the case of ExFM objective as:

\[\Delta v(x^{j},t^{j})=\gamma^{2}\Big{(}\sum_{k=1}^{N}x^{k}_{1}\tilde{\rho} \left(x^{j,i}|x^{k}_{1},t^{j}\right)-x^{j,i}-v(x^{j,i},t^{j})\Big{)},\] (20)

where \(x^{j,i}\sim\rho_{x^{i}_{1}}(\cdot,t^{j})\), \(x^{k}_{1}\sim\rho_{1}\) and \(\tilde{\rho}\left(x^{j,i}|x^{k}_{1},t^{j}\right)=\rho_{0}\left(\frac{x^{j,i}- t^{j}x^{k}_{1}}{1-t^{j}}\right)/\sum_{k=1}^{N}\rho_{0}\left(\frac{x^{j,i}-t^{j}x^{k}_{ 1}}{1-t^{j}}\right)\). Similar to the derivations in the previous part, we can found simplified form for the dispersion of update at \(t=0\).

**Proposition 2.6**.: _At the time \(t=0\), the dispersion of update from (20) have the following element-wise lower bound:_

\[\mathbb{D}_{x^{j,i},x^{k}_{1}}\Delta v(x^{j,i},0)=\frac{\gamma^{2}}{N} \mathbb{D}_{x^{k}_{1}}x^{k}_{1}+\gamma^{2}\mathbb{D}_{x^{j,i},x^{k}_{1}}(x^{j,i}+v(x^{j,i},0))\geq\frac{\gamma^{2}}{N}\mathbb{D}_{x^{k}_{1}}x^{k}_{1}.\]

_Equality is reached when the model \(v(x^{j,i},0)\) has exact values equal to (12)._

\begin{table}
\begin{tabular}{l c c c|l} \hline \hline Probability Path & \(q(z)\) & \(\mu_{t}(z)\) & \(\sigma_{t}\) & 
\begin{tabular}{l} Explicit expressions: \\ vector field (VF) and score (S) \\ \end{tabular} \\ \hline Var. Exploding [17] & \(\rho_{1}(x_{1})\) & \(x_{1}\) & \(\sigma_{1-t}\) & VF: (32) \\ Var. Preserving [6] & \(\rho_{1}(x_{1})\) & \(\alpha_{1-t}x_{1}\) & \(\sqrt{1-\alpha_{1-t}^{2}}\) & VF: (31) \\ Flow Matching [9] & \(\rho_{1}(x_{1})\) & \(tx_{1}\) & \(t\sigma_{s}-t+1\) & VF: (11) if \(\sigma=0\); and (26) \\ Independent CFM & \(\rho_{0}(x_{0})\rho_{1}(x_{1})\) & \(tx_{1}+(1-t)x_{0}\) & \(\sigma\) & VF: (10) \\ Schrödinger Bridge CFM [20] & \(\rho_{0}(x_{0})\rho_{1}(x_{1})\) & \(tx_{1}+(1-t)x_{0}\) & \(\sigma\sqrt{t(1-t)}\) & Can be obtained by SDE using \\  & & & & VF: (49), S:(50) \\ \hline \hline \end{tabular}
\end{table}
Table 1: Correspondence between some methods which can reduced to FM framework and our theoretical descriptions of them.

In comparison to CFM, the dispersion of the update is \(N\) times smaller than the dispersion of the target distribution and could be controlled without impeding convergence by adjusting the number of samples \(N\). In Figure 1(b), we visually compare the dispersions of CFM and ExFM. The illustration aligns a standard normal distribution \(\mathcal{N}(0,I)\) with a shifted and scaled variant \(\mathcal{N}(\mu,I\sigma^{2})\). ExFM yields lower dispersion throughout the range \(t\in[0,1]\). Detailed analytical calculations of the optimal velocity \(v(x,t)\) and dispersion are provided in the Appendix G.

## 3 Numerical Experiments

Toy 2D dataWe conducted unconditional density estimation among eight distributions. Additional details of the experiments see in the Appendix H. We commence the exposition of our findings by showcasing a series of classical 2-dimensional examples, as depicted in Fig. 3 and Table 2. Our observations indicate that ExFM adeptly handles complex distribution shapes is particularly noteworthy, especially considering its ability to do so within a small number of epochs. Additionally, the visual comparison underscores the evident superiority of ExFM over the CFM approach.

\begin{table}
\begin{tabular}{l c c c c} \hline \hline Data & \multicolumn{2}{c}{MSE training loss} & \multicolumn{2}{c}{Energy Distance} \\ \cline{2-5} Data & ExFM & CFM & ExFM & CFM \\ \hline swissroll & 1.13e-02 & 2.12e+00 & **2.58e-03** & 1.07e-02 \\ moons & 9.96e-03 & 2.01e+00 & **2.74e-03** & 1.41e-02 \\ SQUASians & 2.40e-02 & 2.77e+00 & **4.90e-03** & 2.45e-02 \\ cicheles & 9.28e-03 & 3.79e+00 & **6.69e-04** & 1.32e-02 \\
2spirals & 8.92e-03 & 2.34e+00 & **1.27e-03** & 8.35e-03 \\ CHECKORDORD & 1.04e-02 & 3.12e+00 & **1.01e-02** & 1.63e-02 \\ pinvheel & 4.53e-03 & 2.12e+00 & **1.01e-03** & 9.22e-03 \\ rings & 8.60e-03 & 1.93e+00 & **3.55e-04** & 2.37e-03 \\ \hline \hline \end{tabular}
\end{table}
Table 2: ExFM and CFM metrics comparison table on toy 2D data.

Figure 3: Visual comparison of methods on toy 2D data. First row are original samples, second row sampled by ExFM, third row sampled by CFM.

\begin{table}
\begin{tabular}{l c c c} \hline \hline Data & ExFM & CFM & OT-CFM \\ \hline power & **-8.51e-02 \(\pm\) 4.85e-02** & 1.64e-01 \(\pm\) 4.18e-02 & 5.22e-02 \(\pm\) 3.92e-02 \\ GAS & **-5.55e+00 \(\pm\) 3.66e-02** & -5.06e-00 \(\pm\) 2.56e-02 & -5.48e+00 \(\pm\) 2.90e-02 \\ HFEMASS & 2.16e+01 \(\pm\) 6.31e-02 & **2.21e+01 \(\pm\) 4.13e-02** & 2.16e+01 \(\pm\) 4.32e-02 \\ gsds300 & -1.29e+02 \(\pm\) 8.40e-01 & -1.29e+02 \(\pm\) 8.97e-01 & **-1.32e+02 \(\pm\) 6.39e-01** \\ miniboone & **1.34e+01 \(\pm\) 1.95e-04** & 1.42e+01 \(\pm\) 1.29e-04 & 1.43e+01 \(\pm\) 9.22e-05 \\ \hline \hline \end{tabular}
\end{table}
Table 3: NLL comparison for ExFM, CFM and OT-CFM methods over 10 000 learning steps, mean and std taken from 10 sampling iterations.

Tabular dataWe conducted unconditional density estimation on five tabular datasets, namely power, gas, hepmass, minibone, and BSDS300. Additional details of the experiments see in the Appendix H. The empirical findings obtained from the numerical experiments from Table 3 indicate a statistically significant improvement in the performance of our proposed method. Notably, ExFM demonstrates a notable acceleration in convergence rate.

High-dimensional data and additional experimentsWe conducted experiments on high-dimensional data, among them experiments on CIFAR10 and MNIST dataset. FID results on CIFAR10 shows slightly better score among sampled images.

Additional details of the experiments and sampled images see in the Appendix H.

Stochastic ExFM (ExFM-S) on toy 2D dataWe evaluated the performance of the stochastic version of ExFM (ExFM-S) with use of expressions given in Sec. E.3.2 on four standard toy datasets. The primary experimental setup follows that used in [19]. Additional details on the hyperparameters used are available in Appendix H. Based on the findings presented in Table 4, we determine that ExFM-S surpasses I-CFM on all four datasets in terms of generative performance (\(\mathcal{W}_{2}\)) and also outperforms in terms of OT optimality (NPE) on two of them, exhibiting similar results on the remaining datasets. It also demonstrates performance similar to OT-CFM. While ExFM-S is not as robust as the basic ExFM, it enables the matching of one dataset to another (moons \(\rightarrow\) 8gaussians) as it does not necessitate the presence of an explicit formula for \(\rho_{0}\). Among other things, this experiment demonstrates the feasibility of our methods when both distributions \(\rho_{0}\) and \(\rho_{1}\) are unknown.

## 4 Conclusions

The presented method introduces a new loss function in tracrable form (in terms of integrals) that improves upon the existing Conditional Flow Matching approach. New loss as a function of the model parameters, reaches zero at its minimum. Thanks to this, we can: a) write an explicit expression for the vector field on which the loss minimum is achieved; b) get a smaller variance when training on the discrete version of the loss, therefore, we can learn the model faster and more accurately.

Numerical experiments conducted on toy 2D data show reliable outcomes under uniform conditions and parameters. Comparison of the absolute values of loss for the proposed method and for CFM for the same distributions show that the absolute values of loss for these models differ strikingly, by a factor of \(10^{2}\)-\(10^{3}\). Experiments on high-dimensional datasets also confirm the theoretical deductions about the variance reduction of our method. However, we emphasize that we do not expect to use the proposed method in its pure form. On the contrary, we expect that the theoretical implications of our formulas will contribute to the construction of better learning or inference algorithms in conjunction with other heuristics or methods.

Algebraic analysis of variance for some cases (in particular, for the case \(t=0\) or for the case of two Gaussians as initial and final distributions) show an improvement in variance when using the new loss. However, it is rather difficult to analyze in the general case, for all times \(t\) and general distributions \(\rho_{0}\) and \(\rho_{1}\).

Having the expression for the vector field and score in the form of integrals, we can explicitly write out their expressions for some simple cases; in the case of Gaussian distributions we can also write out the exact solution for the trajectories. Thus, our approach allows one to advance the theoretical study of FM-based and Diffusion Model-based frameworks.

\begin{table}
\begin{tabular}{c c c c c c c c c c} \hline Movie & \(\mathbf{\mathcal{W}_{1}}\) & \(\mathbf{\mathcal{W}_{2}}\) & \(\mathbf{\mathcal{W}_{3}}\) & \(\mathbf{\mathcal{W}_{4}}\) & \(\mathbf{\mathcal{W}_{5}}\) & \(\mathbf{\mathcal{W}_{6}}\) & \(\mathbf{\mathcal{W}_{7}}\) & \(\mathbf{\mathcal{W}_{8}}\) & \(\mathbf{\mathcal{W}_{9}}\) & \(\mathbf{\mathcal{W}_{10}}\) & \(\mathbf{\mathcal{W}_{11}}\) \\ \hline Algorithm 1. ExFM & \(0.522\pm 0.015\) & \(0.647\pm 0.075\) & \(0.496\pm 0.231\) & \(1.262\pm 0.076\) & \(0.328\pm 0.015\) & \(0.209\pm 0.089\) & \(0.495\pm 0.025\) & \(0.098\pm 0.04\) \\ \hline OT-CFM & \(0.472\pm 0.038\) & \(0.525\pm 0.033\) & \(0.569\pm 0.018\) & \(1.220\pm 0.056\) & \(0.465\pm 0.046\) & \(0.641\pm 0.088\) & \(0.047\pm 0.026\) & \(0.081\pm 0.024\) \\ ExFM & \(\mathbf{0.318\pm 0.016}\) & \(\mathbf{0.445\pm 0.057}\) & \(\mathbf{0.726\pm 0.043}\) & \(1.726\pm 0.043\) & \(0.325\pm 0.000\) & \(0.233\pm 0.012\) & \(0.069\pm 0.041\) \\ ExFM-S & \(0.486\pm 0.019\) & \(0.570\pm 0.053\) & \(0.728\pm 0.063\) & \(1.561\pm 0.181\) & \(0.55\pm 0.143\) & \(0.166\pm 0.019\) & \(0.346\pm 0.015\) & \(0.058\pm 0.059\) \\ \hline \end{tabular}
\end{table}
Table 4: ExFM-S evaluation on four toy datasets (\(\mu\pm\sigma\) over three seeds). For comparison we take I-CFM, OT-CFM, and ExFM (no values for moons \(\rightarrow\) 8gaussians due to the absence of explicit formula for \(\rho_{0}\)). Performance in generative modeling (\(\mathcal{W}_{2}\)) and dynamic OT optimality (NPE) is assessed. The best result for each metric is highlighted in bold. Instances where we outperform CFM are underscored.

## References

* [1]M. S. Albergo, N. M. Boffi, and E. Vanden-Eijnden (2023) Stochastic Interpolants: a unifying framework for Flows and Diffusions. In arXiv preprint 2303.08797, Cited by: SS1.
* [2]M. S. Albergo and E. Vanden-Eijnden (2023) Building Normalizing Flows with Stochastic Interpolants. In International Conference on Learning Representations (ICLR), Cited by: SS1.
* [3]G. Cardoso et al. (2022) BR-SNIS: bias Reduced Self-Normalized Importance Sampling. In Advances in Neural Information Processing Systems, C. B. S. Koyejo et al., Vol. 35, pp. 716-729. External Links: Link, Document Cited by: SS1.
* [4]R. T. Q. Chen and Y. Lipman (2023) Riemannian Flow Matching on General Geometries. In arXiv:2302.03660, Cited by: SS1.
* [5]R. T. Q. Chen et al. (2018) Neural Ordinary Differential Equations. In Advances in Neural Information Processing Systems, C. B. S. Bengio et al., Vol. 31, pp. 2018. External Links: Link, Document Cited by: SS1.
* [6]J. Ho, A. Jain, and P. Abbeel (2020) Denoising Diffusion Probabilistic Models. External Links: 2006.11239 Cited by: SS1.
* [7]A. Ramdas, N. Garcia Trillos, and M. Cuturi (2017) On wasserstein two-sample testing and related families of nonparametric tests. In Entropy 19.2, pp. 47. Cited by: SS1.
* [8]P. Li et al. (2023) On the Generalization Properties of Diffusion Models. In Advances in Neural Information Processing Systems, C. B. A. Oh et al., Vol. 36, pp. 2097-2127. External Links: Link, Document Cited by: SS1.
* [9]Y. Lipman et al. (2023) Flow Matching for Generative Modeling. In The Eleventh International Conference on Learning Representations, External Links: Link, Document Cited by: SS1.
* [10]Y. Lipman et al. (2023) A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics. In Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001, Vol. 2, pp. 416-423. External Links: Link, Document Cited by: SS1.
* [11]A. Parmar, R. Zhang, and J. Zhu (2022) On Aliased Resizing and Surprising Subtleties in GAN Evaluation. In CVPR, Cited by: SS1.
* [12]A. Parmar, R. Zhang, and J. Zhu (2022) On Aliased Resizing and Surprising Subtleties in GAN Evaluation. In CVPR, Cited by: SS1.
* [13]A. Parmar, R. Zhang, and J. Zhu (2022) On Aliased Resizing and Surprising Subtleties in GAN Evaluation. In CVPR, Cited by: SS1.
* [14]J. Sohl-Dickstein et al. (2015) Deep Unsupervised Learning using Nonequilibrium Thermodynamics. In Proceedings of the 32nd International Conference on Machine Learning, C. B. Francis Bach and D. Blei, Vol. 37, pp. 2256-2265. External Links: Link, Document Cited by: SS1.
* [15]K. Shah, S. Chen, and A. Klivans (2023) Learning Mixtures of Gaussians Using the DDPM Objective. In Thirty-seventh Conference on Neural Information Processing Systems, C. B. S. Koyejo et al., pp. 303-310. External Links: Link, Document Cited by: SS1.
* [16]J. Sohl-Dickstein et al. (2015) Deep Unsupervised Learning using Nonequilibrium Thermodynamics. In Proceedings of the 32nd International Conference on Machine Learning, C. B. Francis Bach and D. Blei, Vol. 37, pp. 2256-2265. External Links: Link, Document Cited by: SS1.
* [17]Y. Song and S. Ermon (2019) Generative Modeling by Estimating Gradients of the Data Distribution. In Neural Information Processing Systems (NeurIPS), Cited by: SS1.
* [18]G. J. Szekely (2003) E-statistics: the energy of statistical samples. In Bowling Green State University, Department of Mathematics and Statistics Technical Report 3.05, pp. 1-18.

* Tong et al. [2024] Alexander Tong et al. "Improving and generalizing flow-based generative models with mini-batch optimal transport". In: _Transactions on Machine Learning Research_ (2024). Expert Certification. ISSN: 2835-8856. url: https://openreview.net/forum?id=CD9Snc73AW.
* Tong et al. [2024] Alexander Tong et al. "Simulation-Free Schrodinger Bridges via Score and Flow Matching". In: _The 27th International Conference on Artificial Intelligence and Statistics_. 2024. url: https://virtual.aistats.org/virtual/2024/poster/6691.

NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: Theoretical things are proved in theorems in the main text and in the Appendix, and numerical experiments have been performed Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: Guidelines: Limitation is discussed both in the theoretical part (in particular, in the formulation of theorems) and in the practical part, where we can see at which cases our method works better or worse * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof?Answer: [Yes] Justification: All theorems are formulated according to strict mathematical rules. There are proofs or proof sketches in the text or Appendix. Guidelines:

* The answer NA means that the paper does not include theoretical results.
* All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
* All assumptions should be clearly stated or referenced in the statement of any theorems.
* The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.
* Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.
* Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: Yes, all parameters and hyperparameters required for reproducibility are described in the Appendix Guidelines:

* The answer NA means that the paper does not include experiments.
* If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.
* If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.
* Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.
* While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code**Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?

Answer: [NA]

Justification: We do not provide a code, paper is mostly theoretical. We use open datasets. Guidelines:

* The answer NA means that paper does not include experiments requiring code.
* Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: Yes, all parameters and hyperparameters required for reproducibility are described in the Appendix

Guidelines:

* The answer NA means that the paper does not include experiments.
* The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them.
* The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: For several experiments variances are given. Guidelines:

* The answer NA means that the paper does not include experiments.
* The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.
* The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).

* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: The experiments are simple enough to be reproduced on publicly available resources Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: The article and experiments meet all the requirements of the code of ethics, all citations for materials used are given. Guidelines: The research conducted in the article and its text meet the ethics code. * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: Paper is mostly theoretical, there's little chance there could be a negative impact. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.

* Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.
* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).

11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: Our work has a very low risk of misuse. Guidelines:

* The answer NA means that the paper poses no such risks.
* Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.
* Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.
* We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.

12. **Licensees for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: Links are provided to articles with open repositories whose code was used in the work Guidelines:

* The answer NA means that the paper does not use existing assets.
* The authors should cite the original paper that produced the code package or dataset.
* The authors should state which version of the asset is used and, if possible, include a URL.
* The name of the license (e.g., CC-BY 4.0) should be included for each asset.
* For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.

* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
3. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: We do not provide a code. All Theorems and Satetements are well formulated. Guidelines: * The answer NA means that the paper does not release new assets. * Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. * The paper should discuss whether and how consent was obtained from people whose asset is used. * At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
4. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: we have no crowdsourcing Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. * According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
5. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: There are no experiments with subjects in the paper, only numerical experiments. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.

* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.

Proof of the theorems

### Proof of the Theorem 2.1

Proof.: We need to proof, that \(\frac{\mathrm{d}L_{\text{CFM}}(\theta)}{\mathrm{d}\theta}=\frac{\mathrm{d}L_{ \text{EeFM}}(\theta)}{\mathrm{d}\theta}\).

To establish the equivalence of \(L_{\text{CFM}}\) and \(L_{\text{EeFM}}\) up to a constant term, we begin by expressing \(L_{\text{CFM}}\) in the format specified by equation (6):

\[L_{\text{CFM}}=\mathbb{E}_{t,x_{1},x\sim\rho_{m}(\cdot,t)}\norm{v_{\theta}(x, \,t)-w(t,x_{1},x)}^{2}\times\rho_{c}(x|x_{1},t)/\rho_{1}(x_{1}).\]

Utilizing the bilinearity of the 2-norm, we can rewrite \(L_{\text{CFM}}\) as:

\[L_{\text{CFM}}=\mathbb{E}_{t,x_{1},x\sim\rho_{m}(\cdot,t)}\frac{ \norm{v_{\theta}(x,\,t)}^{2}\rho_{c}(x|x_{1},t)}{\rho_{1}(x_{1})}-\\ 2\mathbb{E}_{t,x_{1},x\sim\rho_{m}(\cdot,t)}\frac{v_{\theta}(x, \,t)^{T}\cdot w(t,x_{1},x)\rho_{c}(x|x_{1},t)}{\rho_{1}(x_{1})}+C.\] (21)

Here, \(T\) denotes transposed vector, dot denotes scalar product, \(C\) represents a constant independent of \(\theta\).

Noting that \(\mathbb{E}_{x_{1}}\rho_{c}(x|x_{1},t)/\rho_{1}(x_{1})=1\):

\[\mathbb{E}_{x_{1}}\frac{\rho_{c}(x|x_{1},t)}{\rho_{1}(x_{1})}=\int\frac{\rho_ {x_{1}}(x,t)\rho_{1}(x_{1})\,\mathrm{d}x_{1}}{\int\rho_{x_{1}}(x,t)\rho_{1}(x _{1})\,\mathrm{d}x_{1}}=1,\]

we can simplify the first term in the expansion (21):

\[\mathbb{E}_{t,x_{1},x\sim\rho_{m}(\cdot,t)}\frac{\norm{v_{\theta} (x,\,t)}^{2}\rho_{c}(x|x_{1},t)}{\rho_{1}(x_{1})}=\\ E_{t,x\sim\rho_{m}(\cdot,t)}\norm{v_{\theta}(x,\,t)}^{2}\mathbb{E }_{x_{1}}\frac{\rho_{c}(x|x_{1},t)}{\rho_{1}(x_{1})}=E_{t,x\sim\rho_{m}(\cdot, t)}\norm{v_{\theta}(x,\,t)}^{2}.\] (22)

For our loss \(L_{\text{EeFM}}\) in the form (8) we also use the bilinearity of the norm:

\[L_{\text{EeFM}}=\mathbb{E}_{t,x\sim\rho_{m}(\cdot,t)}\norm{v_{\theta}(x,\,t)} ^{2}-2\mathbb{E}_{t,x\sim\rho_{m}(\cdot,t)}\mathbb{E}_{x_{1}}\frac{v_{\theta} (x,\,t)^{T}\cdot w(t,x_{1},x)\rho_{c}(x|x_{1},t)}{\rho_{1}(x_{1})}+C.\] (23)

Comparing the last expression and the Eq. (21) with the modification (22) and also taking into account the independence of random variables \(x\) and \(x_{1}\), we come to the conclusion that \(L_{\text{EeFM}}\) is equal to \(L_{\text{CFM}}\) up to some constant independent of the model parameters.

### Sketch of the proof of the Theorem 2.4

Proof.: We need to prove that \(\mathbb{D}\frac{\mathrm{d}L_{\text{CFM}}^{d}(\theta)}{\mathrm{d}\theta}\leq \mathbb{D}\frac{\mathrm{d}L_{\text{CFM}}^{d}(\theta)}{\mathrm{d}\theta}\), where \(L_{\text{EeFM}}^{d}(\theta)\) and \(L_{\text{CFM}}^{d}(\theta)\) discrete loss functions presented in (14) and (13). Firstly, let us rewrite the derivative of loss functions using the bilinearity:

\[\frac{\mathrm{d}L_{\text{EeFM}}^{d}(\theta)}{\mathrm{d}\theta}=2\sum_{i,j} \bigg{(}\frac{\mathrm{d}v_{\theta}(x^{j,i},\,t^{j})}{\mathrm{d}\theta}\bigg{)} ^{T}\cdot\big{(}v_{\theta}(x^{j,i},\,t^{j})-v^{d}(x^{j,i},t^{j})\big{)}.\]

Note that in this expression, values \(x^{j,i}\) as well as \(t^{j}\), which are included in the argument of the function \(v\), are fixed (our goal to calculate the variance with fixed model arguments). Thus, we need to consider the variance of the remaining expression arising from the randomness of \(\overline{x}_{1}^{k}\).

Recall (below we will omit the indices at variables \(x\) and \(t\)),

\[v^{d}(x,\,t)=\frac{\sum_{k=1}^{N}w(t,\overline{x}_{1}^{k},x)\cdot\rho_{0}\big{(} \phi_{t,\overline{x}_{1}^{k}}^{-1}(x)\big{)}}{\sum_{k=1}^{N}\rho_{0}\big{(}\phi_ {t,\overline{x}_{1}^{k}}^{-1}(x)\big{)}}.\]Note, that if \(N=1\), (_i. e._ we do not sample any additional points other than the ones we have already sampled) this expression is exactly the same as the derivative of the common discretized CFM loss \(\frac{\mathrm{d}L_{\text{CFM}}^{\ell}(\theta)}{\mathrm{d}\theta}\).

Moreover, recall that one of the points (without loss of generality, we can assume that its index is \(1\)) \(\overline{x}_{1}^{1}\) is added from the set from which point \(x\) was derived: \(x=\phi_{t,\overline{x}_{1}^{1}}(x_{0})\). (Here \(x_{0}\) is the paired point to \(\overline{x}_{1}^{1}\))

Thus, we can rewrite expression for \(v^{d}\):

\[v^{d}(x,\,t)=\frac{w(t,\overline{x}_{1}^{1},x)\rho_{0}(x_{0})+\sum_{k=2}^{N}w( t,\overline{x}_{1}^{k},x)\cdot\rho_{0}\left(\phi_{t,\overline{x}_{1}^{k}}^{-1}(x) \right)}{\rho_{0}(x_{0})+\sum_{k=2}^{N}\rho_{0}\left(\phi_{t,\overline{x}_{1} ^{1}}^{-1}(x)\right)}.\] (24)

Thus, our task was reduced to evaluating how well the additional terms (for \(k\) starting from \(2\)) improve approximate of the original integrals that are in loss (8).

So, we need to estimate the following dispersion ratio, where in the numerator is the variance of discrete loss CFM, and in the denominator -- the variance of loss ExFM:

\[k_{D}=\frac{\mathbb{D}\big{(}v_{\theta}(x,t)-w(t,\overline{x}_{1}^{1},x)\big{)} }{\mathbb{D}\left(v_{\theta}(x,t)-\frac{\sum_{k=1}^{N}w(t,\overline{x}_{1}^{k })\cdot\rho_{0}\left(\phi_{t,\overline{x}_{1}^{k}}^{-1}(x)\right)}{\sum_{k=1}^ {N}\rho_{0}\left(\phi_{t,\overline{x}_{1}^{k}}^{-1}(x)\right)}\right)}\]

The smaller coefficient \(k_{D}\) is, the better the proposed loss ExFM works.

Formally, we can write our problem as an importance sampling problem for the following integral:

\[I=\int f(x)p(x)\,\mathrm{d}x\,.\]

This integral we estimate by sample mean of the following expectation over some random variable with density function \(q(x)\):

\[I=\mathbb{E}_{x\sim q}\big{(}w(x)f(x)\big{)}\]

with

\[w(x)=\frac{p(x)}{q(x)}.\]

We replace the exact value of \(I\) with the value

\[\overline{I}=\frac{\sum_{k=1}^{N}w(\overline{x}_{1}^{1})f(\overline{x}_{1}^{k })}{\sum_{i=k}^{N}w(\overline{x}_{1}^{k})}.\]

It follows from the strong law of large numbers that in the limit \(N\to\infty\), \(I\to\overline{I}\) almost surely. From the central limit theorem we can find the asymptotic variance:

\[\mathbb{D}\overline{I}=\frac{1}{N}\mathbb{E}_{x\sim q}\big{(}w^{2}(x)(f(x)-I) ^{2}\big{)}.\] (25)

In our case (loss \(L_{\text{ExFM}}\)), we have \(q(x_{1})=\rho_{1}(x_{1})\), \(f(x_{1})=w(t,x_{1},x)\) and \(w(x_{1})=\rho_{0}\left(\phi_{t,x_{1}}^{-1}(x)\right)\). Despite the fact that the equation (25) for the variance contains \(N\) in the denominator, it is rather difficult to give an estimate of its behavior in general. The point is that this formula is well suited for the case when \(w\) in it is of approximately the same order. In the considered case, this is achieved at times \(t\) noticeably less than \(1\).

But in the case, when \(t\) is closed to \(1\) we have, for example, for the linear map, that

\[w(x_{1})=\rho_{0}\left(\phi_{t,x_{1}}^{-1}(x)\right)=\rho_{0}\left(\frac{x-x_{ 1}t}{1-t}\right)\]

and this function has a sharp peak near the point \(x/t\) if it is considered as a function of \(x_{1}\). Thus, at such values of \(t\), only a small number of summands will give a sufficient contribution to the sum compared to the first term.

Finally, inequality \(k_{D}<1\) is formally fulfilled, but how much \(k_{D}\) is less than one depends on many factors.

### Expressions for the regularized map

To justify the expression (11), we use a invertable transformation and then strictly take the limit \(\sigma_{s}\to 0\).

Expression Eq. (11), (16) are obtained for the simple map \(\phi_{t,x_{1}}(x_{0})=(1-t)x_{0}+tx_{1}\) which is not invertable at \(t=1\). For the map with small regularaziting parameter \(\sigma_{s}>0\ \phi_{t,x(x_{0})}=(1-t)x_{0}+tx_{1}+\sigma_{s}x_{0}\), which is invertable at all time values \(0\leq t\leq 1\), Eq. (11), (16) needs modifications. Namely, for this map the following exact formulas holds true

\[v(x,t)=\!\!\int\!\!w(t,x_{1},x)\rho_{c}(x|x_{1},t)\rho_{1}(x_{1})\,\mathrm{d}x_ {1}\!=\!\frac{\int\!\left(x_{1}-x(1-\sigma_{s})\right)\!\rho_{0}\left(\frac{x- x_{1}t}{1+\sigma_{s}t-t}\right)\rho_{1}(x_{1})\,\mathrm{d}x_{1}}{(1+\sigma_{s}t-t) \int\rho_{0}\left(\frac{x-x_{1}t}{1+\sigma_{s}t-t}\right)\rho_{1}(x_{1})\, \mathrm{d}x_{1}}.\] (26)

By direct substitution we make sure that for this vector field

\[v(x,\,0)=\int x_{1}\rho_{1}(x_{1})\,\mathrm{d}x_{1}-x(1-\sigma_{s})\] (27)

and

\[v(x,\,1)=\frac{\int(x-y)\rho_{0}(y)\rho_{1}(x-y\sigma_{s})\,\mathrm{d}y}{\int \rho_{0}(y)\rho_{1}(x-y\sigma_{s})\,\mathrm{d}y},\] (28)

where we perform change of the variables \(y\leftarrow\frac{x_{1}-x}{\sigma_{s}t}\).

#### a.3.1 Prof of the explicit formula (11) for the vector field

**Assumption A.1**.: Density \(\rho_{1}\) is continuous at any point \(x\in(-\infty,\,\infty)\).

**Theorem A.2**.: _In equations (26), (27) and (28) we can take the limit \(\sigma_{s}\to 0\) under integrals to get Eq. (11) and (12)._

Proof.: Assuming that the distribution \(\rho_{1}\) has a finite first moment: \(|\int\xi\rho_{1}(\xi)\,\mathrm{d}\xi|<C_{1}\) and that the density of \(\rho_{0}\) is bounded: \(\rho_{0}(x)<C_{2}\), \(\forall x\in(-\infty,\infty)\), we obtain that the integrand functions in the numerator and denominator in the Eq. (26) can be bounded by the following integrable functions independent of \(\sigma_{s}\) and \(t\):

\[\rho_{0}\left(\frac{x-x_{1}t}{1+\sigma_{s}-t}\right)\rho_{1}(x_{1})<C_{1}\rho _{1}(x_{1})\]

and

\[0\leq x_{1}\rho_{0}\left(\frac{x-x_{1}t}{1+\sigma_{s}t-t}\right)\rho_{1}(x_{1 })<x_{1}C_{1}\rho_{1}(x_{1}),\ \ \ x\geq 0,\]

\[0>x_{1}\rho_{0}\left(\frac{x-x_{1}t}{1+\sigma_{s}t-t}\right)\rho_{1}(x_{1})>x_ {1}C_{1}\rho_{1}(x_{1}),\ \ \ x<0.\]

It follows that both integrals in expression (26) converge absolutely and uniformly. So, we can swap the operations of taking the limit and integration, and we can take the limit \(\sigma_{s}\to 0\) in the integrand for any time \(t\in[0,\,t_{0}]\) for arbitrary \(t_{0}<1\).

Now, let us consider the case \(t=1\). From Assumption A.1 the boundedness of the density \(\rho_{1}\) follows: \(\rho_{1}(x)<C_{2}\), \(\forall x\in(-\infty,\,\infty)\). Thus, integrand functions in the numerator and denominator in the Eq. (28) can be bounded by the following integrable functions independent of \(\sigma_{s}\):

\[\rho_{0}(y)\rho_{1}(x-y\sigma_{s})<\rho_{0}(y)C_{2}\]

and

\[0\leq y\rho_{0}(y)\rho_{1}(x-y\sigma_{s})<yC_{2}\rho_{0}(y),\ \ \ y\geq 0,\]

\[0>y\rho_{0}(y)\rho_{1}(x-y\sigma_{s})>yC_{2}\rho_{0}(y),\ \ \ y<0.\]

The existence of the limit

\[\lim_{\sigma_{s}\to 0}\rho_{1}(x-y\sigma_{s})=\rho_{1}(x),\]

follows from Assumption A.1.

Finally, we conclude that formula (11), regarded as the limit \(\sigma_{s}\to 0\) of the (26) at any \(t\in[0,\,1]\), is true.

**Theorem A.3**.: _The vector field in Eq. (11) delivers minimum to the Flow Matching objective (see the work [9]),_

\[\mathbb{E}_{t}\mathbb{E}_{x\sim\rho(x,t)}\|\overline{v}(x,t)-v(x,t)\|,\]

_where \(\rho(x,t)\) and \(\overline{v}(x,t)\) satisfy the equation (1) with the given densities \(\rho_{0}\) and \(\rho_{1}\)._

Proof.: The proof is based on the previous statements and on a Theorem 1 from [9] (that the marginal vector field based on conditional vector fields generates the marginal probability path based on conditional probability paths.

To complete the proof, we must justify that, with \(\sigma_{s}\) tending to zero, the marginal path at \(t=1\) coincides with a given probability \(\rho_{1}\).

Consider the marginal probability path \(p_{t}(x,t)\)

\[p_{t}(x,t)=\int p_{t}(x|x_{1},\sigma_{s})\rho_{1}(x_{1})\mathrm{d}x_{1}\] (29)

where \(p_{t}(x|x_{1},\sigma_{s})\) is conditional probability paths obtained by regularized linear conditional map. Distribution \(p_{t}\) in the time \(t=0\) is equal to standard normal distribution \(p_{0}(x|x_{1},\sigma_{s})=\mathcal{N}(x\mid 0,1)\) and at the time \(t=1\) it is a stretched Gaussian centered at \(x_{1}\colon p_{1}(x|x_{1},\sigma_{s})=\mathcal{N}(x\mid x_{1},\sigma_{s}I)\).

Substituting \(p_{1}\) into the Eq. (29) and considering that there exists a limit \(\sigma_{s}\to 0\) due to Assumption A.1, we obtain

\[p_{1}(x)=\lim_{\sigma_{s}\to 0}\int p_{t}(x|x_{1},\sigma_{s})\rho_{1}(x_{1}) \mathrm{d}x_{1}=\rho_{1}(x_{1}).\]

This finish the proof. 

#### a.3.2 Learning procedure for \(\sigma_{s}>0\)

Using standard normal distribution as initial density \(\rho_{0}\), and the regularized map \(\phi_{t,x_{1}}(x_{0})=(1-t)x_{0}+tx_{1}+\sigma_{s}tx_{0}\) we obtain the following approximation formula

\[v^{d}(x,\,t)=\frac{\sum_{k=1}^{N}\frac{x_{1}^{k}-x(1-\sigma_{s})}{1-t(1-\sigma _{s})}\exp\bigl{(}Y^{k}\bigr{)}}{\sum_{k=1}^{N}\exp(Y^{k})},\quad\text{where} \quad Y^{k}=-\frac{1}{2}\frac{\left\|x-t\cdot\overline{x}_{1}^{k}\right\|_{ \mathbb{R}^{d}}^{2}}{1-t(1-\sigma_{s})}.\]

In practical applications, the exponent calculation is replaced by the \(\mathrm{SoftMax}\) function calculation, which is more stable.

## Appendix B Estimation of integrals

In general, we need to estimate the following expression

\[I(\eta)=\frac{\int w(x_{1},\,\eta)f(x_{1},\,\eta)\rho_{1}(x_{1})\,\mathrm{d}x _{1}}{\int f(x_{1},\,\eta)\rho_{1}(x_{1})\,\mathrm{d}x_{1}}.\]

In particular, substituting \(\eta\to\{x,t\}\), \(w(x,\eta)\to(x_{1}-x)/(1-t)\) we obtain formula (11) and similar ones with similar substitutions.

If we can sample from the \(\rho_{1}\) distribution, we can estimate this integral in two ways: _self-normalized importance sampling_ and _rejection sampling_.

Let \(\mathcal{X}=\{x_{1}^{k}\}_{k=1}^{N}\) be \(N\) samples from the distribution \(\rho_{1}\).

Self-normalized Importance SamplingIn this case

\[I(\eta)\approx\frac{\sum\limits_{k=1}^{N}w(x_{1}^{k},\eta)f(x_{1}^{k},\,\eta) \rho_{1}(x_{1}^{k})\,\mathrm{d}x_{1}}{\sum\limits_{k=1}^{N}f(x_{1}^{k},\,\eta) \rho_{1}(x_{1}^{k})\,\mathrm{d}x_{1}}.\] (30)

This estimate is biased in theory, but there several methods to reduce this bias and improve this estimate, see, for example, [3]. Our numerical experiments generally show that the estimation (30) in the form is already sufficient for stable results; we don not observe any bias.

Rejection samplingLet \(\mathcal{Y}=\{y^{k}\}_{k=1}^{M}\subset\mathcal{X}\) be a subset of the the initially given set of samples, which is formed according to the following rule. Let \(C=\sup_{x}\rho_{1}(x)\). For a given sample \(x_{1}^{j}\) we generate a random uniformly distributed variable \(\xi_{j}\sim\mathcal{U}(0,1)\) and if

\[f(x_{1}^{j})\geq C\xi_{j},\]

then we put the point \(x_{k}^{j}\) to the set \(\mathcal{Y}\); otherwise we reject it.

Having formed the set \(\mathcal{Y}\), we evaluate the integral as

\[I(\eta)\approx\frac{1}{M}\sum_{k=1}^{M}w(y^{k},\eta).\]

To justify the last estimation, we note, that the points from the set \(\mathcal{Y}\) are distributed according to (non-normalized) density \(\rho(x)f(x,\eta)\rho_{1}(x)\). One can show it using the proof of the rejection sampling method. This is the same density as in Eq. (7) and thus we estimate the expression (10) using Important Sampling without any additional denominator.

ComparisonWhen we apply these techniques to evaluating the expression for the vector field, we know that when the time parameter \(t\) is close to \(1\), the function \(f(x_{1},\eta)\) (which is a scaled \(\rho_{0}\)) has a peak at the point \(x=x_{1}\). This means that only a small number of points from the original set will end up in the set \(\mathcal{Y}\). Moreover, in the case when the time \(t\) is very close to one and the data are well separated, only one point \(x_{1}\) will end up in \(\mathcal{Y}\). This explains why we initially put this point in the set \(\mathcal{X}\), because otherwise it would be possible that the set \(\mathcal{Y}\) is empty and \(M=0\).

As a future work, we indicate a theoretical finding of the probability of hitting a particular point \(x_{1}\) in the set \(\mathcal{Y}\) and, thus, a modification of our algorithm, when the sample \(x_{1}\) will not always go to the set \(\mathcal{X}\), but with some probability -- the greater the \(t\) the closer this probability to \(1\).

## Appendix C The main Algorithm and extensions and generalization of the exact expression

```
0: Sampler from distribution \(\rho_{1}\) (or a set of samples); parameters \(n\) and \(m\) (number of spatial and time points, correspondingly); parameter \(N\) (number of averaging point); model \(v_{\theta}(x,t)\); algorithm with parameters for SGD
0: quasi-optimal parameters \(\theta\) for the trained model
1: Initialize \(\theta\) (maybe random)
2:while exit condition is not met do
3: Sample \(m\) points \(\{t^{j}\}\) from \(\mathcal{U}[0,1]\)
4: Sample \(n\) points pairs \(\{x_{0}^{i},x_{1}^{i}\}_{i=1}^{n}\) from joint distribution \(\pi\) (\(\pi(x_{0},x_{1})=\rho_{0}(x_{0})\rho_{1}(x_{1})\) if variables are independent)
5: Sample \(N-n\) points \(\{\hat{x}_{1}^{l}\}\) from \(\rho_{1}\) and form \(\{\overline{x}_{1}^{k}\}=\{x_{1}^{i}\}\cup\{\hat{x}_{1}^{l}\}\) // We can take all available samples as \(\{\overline{x}_{1}^{k}\}\) if we don't have access to a sampler, but only ready-made samples.
6: For all \(i\) and \(j\) calculate the sum at the right side of (14) (using (16) if \(\rho_{0}\) is standard Gaussian or (24) in general)
7: Calculate the sum on \(i\) and \(j\) in discrete loss (14), and take backward derivative, obtaining approximate grad \(G\approx\bm{\nabla}_{\theta}L_{\text{ExFM}}\) of loss \(L_{\text{ExFM}}\) on model parameters \(\theta\).
8: Update model parameters \(\theta\gets SGD(\theta,G)\)
9:endwhile ```

**Algorithm 1** Vector field model training algorithm

General form of the proposed Algorithm is given in Alg 1.

When using other maps, formula (11) is modified accordingly. For example, if we use the regularized map \(\phi_{t,x_{1}}(x_{0})=(1-t)x_{0}+tx_{1}+\sigma_{s}tx_{0}\), we get the formula (26).Note, that in this case the final density \(\rho(x,\,1)\), obtained from the continuity equation is not equal to \(\rho_{1}\), but is its smoothed modification.

When using a different initial density \(\rho_{0}\) (not the normal distribution), an obvious modification will be made to formula (16).

Diffusion-like modelsWe can treat so-called Variance Preserving [6] model as CFM with the map

\[\phi_{t,x_{1}}(x)=\alpha_{1-t}x+\sqrt{1-\alpha_{1-t}^{2}}x_{1}.\]

and \(\rho_{0}\) as standard normal distribution: \(\rho_{0}=\mathcal{N}\left(\cdot\big{|}\,0,1^{2}\right)\) In this case, the common expression (10) for vector filed transforms to

\[v(x,t)=\frac{\int(x\alpha_{1-t}-x_{1})\alpha_{1-t}^{\prime}\,\rho_{0}\left( \frac{x-x_{1}\alpha_{1-t}}{\sqrt{1-\alpha_{1-t}^{2}}}\right)\rho_{1}(x_{1})\, \mathrm{d}x_{1}}{(1-\alpha_{1-t}^{2})\int\rho_{0}\left(\frac{x-x_{1}\alpha_{1- t}}{\sqrt{1-\alpha_{1-t}^{2}}}\right)\rho_{1}(x_{1})\,\mathrm{d}x_{1}},\] (31)

where \(\alpha_{s}^{\prime}=\frac{\mathrm{d}\alpha_{s}}{\mathrm{d}s}\).

Similarity we can treat so-called Variance Exploding [17] model as CFM with the map

\[\phi_{t,x_{1}}(x)=\sigma_{1-t}x+x_{1}.\]

and \(\rho_{0}\) also as standard normal distribution: \(\rho_{0}=\mathcal{N}\left(\cdot\big{|}\,0,1^{2}\right)\) In this case, the common expression (10) for vector filed transforms to

\[v(x,t)=\frac{\int(x_{1}-x)\sigma_{1-t}^{\prime}\,\rho_{0}\left( \frac{x-x_{1}}{\sigma_{1-t}}\right)\rho_{1}(x_{1})\,\mathrm{d}x_{1}}{\sigma_{1 -t}\int\rho_{0}\left(\frac{x-x_{1}}{\sigma_{1-t}}\right)\rho_{1}(x_{1})\, \mathrm{d}x_{1}},\] (32)

where \(\sigma_{s}^{\prime}=\frac{\mathrm{d}\sigma_{s}}{\mathrm{d}s}\).

Joint DistributionMoreover, in addition to the independent densities \(x_{0}\sim\rho_{0}\) and \(x_{1}\sim\rho_{1}\), we can use the joint density \(\{x_{0},\,x_{1}\}\sim\pi(x_{0},\,x_{1})\). In the papers [20, 19], optimal transport (OT) and Schrodinger's bridge are taken as \(\pi\). In this case the expression for the vector field changes insignificantly: the conditional probability \(\rho_{c}\) from Eq. (7) is subject to change:

\[\rho_{c}(x|x_{1},t)=\frac{\pi\left(\phi_{t,x_{1}}^{-1}(x),x_{1} \right)\det\left[\frac{\partial\phi_{t,x_{1}}^{-1}(x)}{\partial x}\right]}{ \int\pi\left(\phi_{t,x_{1}}^{-1}(x),x_{1}\right)\det\left[\frac{\partial\phi_ {t,x_{1}}^{-1}(x)}{\partial x}\right]\mathrm{d}x_{1}}.\] (33)

Then, Eq. (10) remains the same in general case. In the case of linear \(\phi\), the extension of Eq. (11) reads

\[v(x,t)=\frac{\int(x_{1}-x)\,\pi\big{(}\phi_{t,x_{1}}^{-1}(x),x_{1} \big{)}\det\left[\frac{\partial\phi_{t,x_{1}}^{-1}(x)}{\partial x}\right] \mathrm{d}x_{1}}{(1-t)\int\pi\big{(}\phi_{t,x_{1}}^{-1}(x),x_{1}\big{)}\det \left[\frac{\partial\phi_{t,x_{1}}^{-1}(x)}{\partial x}\right]\mathrm{d}x_{1}}.\] (34)

In all of the above cases, the essence of Algorithm 1 does not change (except that in the case of dependent \(x_{0}\) and \(x_{1}\) we should be able either to calculate the value of \(\pi\big{(}\phi_{t,x_{1}}^{-1}(x),x_{1}\big{)}\,/\rho_{1}(x_{1})\) or to estimate it).

## Appendix D Several analytical results, following from the explicit formula

In this section, we present several analytical results that directly follow from our exact formulas for the vector field, which, to the best of our knowledge, have not been published before.

### Exact path from one Gaussian to another Gaussian

Consider the flow from a one-dimensional Gaussian distribution \(\rho_{0}\sim\mathcal{N}\left(\cdot\big{|}\,\mu_{0},\sigma_{0}^{2}\right)\) into another (with other parameters) Gaussian distribution \(\rho_{1}\sim\mathcal{N}\left(\cdot\big{|}\,\mu_{1},\sigma_{1}^{2}\right)\). Note that in this case the generalization to the multivariate case is done directly, so the spatial variables are separated.

From the general formula (11) we have:

\[v(x,t)=\frac{\int(x_{1}-x)\mathcal{N}\left(\frac{x-tx_{1}}{1-t} \Big{|}\,\mu_{0},\sigma_{0}^{2}\right)\mathcal{N}\left(x_{1}\big{|}\,\mu_{1}, \sigma_{1}^{2}\right)\mathrm{d}x_{1}}{(1-t)\int\mathcal{N}\left(\frac{x-tx_{1 }}{1-t}\Big{|}\,\mu_{0},\sigma_{0}^{2}\right)\mathcal{N}\left(x_{1}\big{|}\,\mu_ {1},\sigma_{1}^{2}\right)\mathrm{d}x_{1}}.=\] \[=\frac{\int(x_{1}-x)\exp\left(-\big{(}\frac{x-tx_{1}}{1-t}-\mu_{ 0}\big{)}^{2}/(2\sigma_{0}^{2})-(x_{1}-\mu_{1})^{2}/(2\sigma_{1}^{2})\right) \mathrm{d}x_{1}}{(1-t)\int\exp\left(-\big{(}\frac{x-tx_{1}}{1-t}-\mu_{0}\big{)} ^{2}/(2\sigma_{0}^{2})-(x_{1}-\mu_{1})^{2}/(2\sigma_{1}^{2})\right)\mathrm{d} x_{1}}.\]

Both integrals in the last expression are taken explicitly:

\[\int\mathcal{N}\left(\frac{x-tx_{1}}{1-t}\Big{|}\,\mu_{0},\sigma_ {0}^{2}\right)\mathcal{N}\left(x_{1}\big{|}\,\mu_{1},\sigma_{1}^{2}\right) \mathrm{d}x_{1}=\] \[=\frac{\exp\left(-\frac{(x-\mu_{0}(1-t)-\mu_{1}t)^{2}}{2\left( \sigma_{1}^{2}t^{2}+\sigma_{0}^{2}(1-t)^{2}\right)}\right)}{\sqrt{2\pi}\sqrt{ \sigma_{0}^{2}+\frac{\sigma_{1}^{2}t^{2}}{(t-1)^{2}}}}=\mathcal{N}\left(\frac {x}{1-t}\Big{|}\,\frac{\mu_{0}(1-t)+\mu_{1}t}{1-t},\sigma_{0}^{2}+\frac{ \sigma_{1}^{2}t^{2}}{(t-1)^{2}}\right).\]

Note that the last relation can be obtained as a distribution of two Gaussian random variables with corresponding parameters.

The second integral:

\[\int\frac{x_{1}-x}{1-t}\mathcal{N}\left(\frac{x-tx_{1}}{1-t} \Big{|}\,\mu_{0},\sigma_{0}^{2}\right)\mathcal{N}\left(x_{1}\big{|}\,\mu_{1}, \sigma_{1}^{2}\right)\mathrm{d}x_{1}=\] \[=\frac{\exp\left(-\frac{(x-\mu_{0}(1-t)-\mu_{1}t)^{2}}{2\left( \sigma_{1}^{2}t^{2}+\sigma_{0}^{2}(1-t)^{2}\right)}\right)}{\sqrt{2\pi}}\frac{ (1-t)\left(\sigma_{1}^{2}t(x-\mu_{0})+\sigma_{0}^{2}(t-1)(x-\mu_{1})\right)}{ \left(\sigma_{1}^{2}t^{2}+\sigma_{0}^{2}(1-t)^{2}\right)^{3/2}}.\]

Thus, in the considered case we can explicitly write the expression for the vector field \(v\):

\[v(x,t)=\frac{\sigma_{1}^{2}t(x-\mu_{0})-\sigma_{0}^{2}(1-t)(x-\mu_{1})}{ \sigma_{1}^{2}t^{2}+\sigma_{0}^{2}(1-t)^{2}}.\] (35)

For this vector field we can explicitly solve the equation for the path \(x(t)\) starting from the arbitrary point \(x_{0}\)

\[\left\{\begin{aligned} \frac{\partial x(t)}{\partial t}& =v(x(t),\,t),\\ x(0)&=x_{0}\end{aligned}.\right.\]

The solution is:

\[x(t)=(1-t)\mu_{0}+t\mu_{1}+(x_{0}-\mu_{0})\sqrt{(\sigma_{1}/ \sigma_{0})^{2}t^{2}+(1-t)^{2}}.\] (36)

Note that although this solution does not correspond to the Optimal Transport joint distribution, since the obtained path is not a straight line in general, (_i. e._ we do not have a solution to the Kantorovich's formulation of the OT problem) the endpoint \(x(1)=\mu_{1}+(x_{0}-\mu_{0})\frac{\sigma_{1}}{\sigma_{0}}\) falls exactly in the one that is optimal if we solve the OT problem in the Monge formulation. Thus, the map \(x(0)\to x(1)\) is the OT map for the case of 2 Gaussian.

See the Fig. 4 for the examples of the paths for the obtained solution.

### From one Gaussian to Gaussian Mixture

Let initial distribution be standard Gaussian \(\rho_{0}=\mathcal{N}\left(\cdot\big{|}\,0,1^{2}\right)\), and the target distribution be Gaussian Mixture (GM) of two symmetric Gaussians: \(\rho_{1}(x)=1/2(\mathcal{N}\left(x\big{|}\,\mu,\sigma^{2}\right))+\mathcal{N} \left(x\big{|}\,-\mu,\sigma^{2}\right))\), In this case, we can obtain exact form for \(v\)

\[\begin{split}& v(x,t)=\frac{\exp\left(-\frac{\mu^{2}}{2\sigma^{2}}+ \frac{\mu^{2}t^{2}+x^{2}}{\sigma^{2}t^{2}+(t-1)^{2}}-\frac{x^{2}}{2(t-1)^{2}} \right)}{(\sigma^{2}t^{2}+(t-1)^{2})\left(e^{\frac{(x-\mu t)^{2}}{2(\sigma^{2} t^{2}+(t-1)^{2})}}+e^{\frac{(x+\mu)^{2}}{2(\sigma^{2}t^{2}+(t-1)^{2})}}\right)} \times\\ &\left[\mu(t-1)\left(\exp\left(\frac{\left(\mu(t-1)^{2}-\sigma^{2 }tx\right){}^{2}}{2\sigma^{2}(t-1)^{2}\left(\sigma^{2}t^{2}+(t-1)^{2}\right)} \right)-\exp\left(\frac{\left(\mu(t-1)^{2}+\sigma^{2}tx\right){}^{2}}{2\sigma^ {2}(t-1)^{2}\left(\sigma^{2}t^{2}+(t-1)^{2}\right)}\right)\right)+\\ &+x\left(\sigma^{2}t+t-1\right)\left(\exp\left(\frac{\left(\mu(t -1)^{2}-\sigma^{2}tx\right){}^{2}}{2\sigma^{2}(t-1)^{2}\left(\sigma^{2}t^{2}+( t-1)^{2}\right)}\right)+\exp\left(\frac{\left(\mu(t-1)^{2}+\sigma^{2}tx\right){}^{2}}{2 \sigma^{2}(t-1)^{2}\left(\sigma^{2}t^{2}+(t-1)^{2}\right)}\right)\right)\right],\end{split}\] (37)

but the expression for the path \(x(t)\) is unknown.

Numerically solution of the differential equation with the obtained vector field give the trajectories shown in Fig. 5.

### From Gaussian to Gaussian with stochastic

Using Eq. (44)-(46) we can explicitly calculate vector field \(v\) and score \(s\) with the setup as in Sec. D.1 but with additional noise, _i. e._ in the stochastic case.

#### d.3.1 Gaussian to Gaussian with noise

Consider like in the Sec. D.1 the flow from a one-dimensional standard Gaussian distribution \(\rho_{0}\sim\mathcal{N}\left(\cdot\big{|}\,0,0^{2}\right)\) into another (with other parameters) Gaussian distribution \(\rho_{1}\sim\mathcal{N}\left(\cdot\big{|}\,\mu_{1},\sigma_{1}^{2}\right)\) but with additional noise as described above.

In this case we have for the field.

\[v(x,\,t)=\frac{x\big{(}t\sigma_{1}^{2}+(1-t)\sigma_{e}^{2}/2\big{)}-(x-\mu_{1}) \big{(}(1-t)+t\sigma_{e}^{2}/2\big{)}}{t(1-t)\sigma_{e}^{2}+\sigma_{1}^{2}t^{2} +(1-t)^{2}}\] (38)

We can solve ODE with this field and get the expression for the trajectories, starting from the given point \(x_{0}\):

\[x(t)=\mu_{1}t+x_{0}\sqrt{t(1-t)\sigma_{e}^{2}+\sigma_{1}^{2}t^{2}+(1-t)^{2}}.\] (39)

These trajectories, for different \(x_{0}\) are depicted in Fig. 6.

At the limit \(\sigma_{e}\to 0\) expressions (38) and (39) turn into expressions (35) and (36) as expected.

For the score \(s\) in the considered case we have

\[s(x,\,t)=\frac{t\mu_{1}-x}{(1-t)^{2}+t(1-t)\sigma_{e}^{2}+t^{2}\sigma_{1}^{2}}\]

Thus, we can explicitly write expressions for the stochastic process for the evolution from the initial distribution \(rho_{0}\) (standard Gaussian) to the final distribution \(\rho_{1}\):

\[\mathrm{d}x(x)=\left[\frac{x\big{(}t\sigma_{1}^{2}+(1-t)\sigma_{e }^{2}/2\big{)}-(x-\mu_{1})\big{(}(1-t)+t\sigma_{e}^{2}/2\big{)}}{t(1-t)\sigma_ {e}^{2}+\sigma_{1}^{2}t^{2}+(1-t)^{2}}\right.+\\ +\left.\frac{g^{2}(t)}{2}\frac{t\mu_{1}-x}{(1-t)^{2}+t(1-t)\sigma_ {e}^{2}+t^{2}\sigma_{1}^{2}}\right]\mathrm{d}t+g(t)\,\mathrm{d}W(t)\,.\]

Here \(g(t)\) is arbitrary smooth function. In the case of Shrodinger Bridge we take \(g(t)=\sigma_{e}\sqrt{t(1-t)}\).

Detail on the SDE case

### Optimal vector field and score for stochastic map

Following [20] we consider a so-called _Brownian bridge_\(B(t)\) from \(x_{0}\) to \(x_{1}\) with constant diffusion rate \(\sigma_{e}\). This stochastic process can be expressed through a multidimensional standard Winner process \(W(t)\) as

\[B(t\mid x_{0},x_{1})=(1-t)x_{0}+tx_{1}+\sigma_{e}(1-t)W\left(\frac{t}{1-t} \right).\] (40)

Thus, the conditional distribution \(p(t,x\mid x_{0},\,x_{1})\) conditioned on the starting \(x_{0}\) and end point \(x_{1}\) is Gaussian:

\[p(x,t\mid x_{0},\,x_{1})=\mathcal{N}\left(x\big{|}\,(1-t)x_{0}+tx_{1},\sigma_{ e}^{2}(t-t)\right).\]

We can not directly use the results Theorem 3 from [9] (or similar Theorem 2.1 from [19] ) for the Gaussian paths, as in this case \(\sigma(0)=0\). To circumvent this obstacle and to be able to write an expression for the conditional velocity, we assume that we have a Gaussian distribution with a very narrow peak at the initial (\(t=0\)) and final (\(t=1\)) points. In other words, we will consider conditional probabilities of the form

\[p(x,t\mid x_{0},\,x_{1})=\mathcal{N}\left(x\big{|}\,(1-t)x_{0}+tx_{1},\sigma_{ e}^{2}(t+\eta)(1-t+\eta)\right),\] (41)

where parameter \(\eta\) is small enough. Then we can use the above Theorems and immediately write

\[v_{x_{0},x_{1}}(x,t)=\frac{\sigma^{\prime}(t)}{\sigma(t)}\big{(}x-\mu(t)\big{)} +\mu^{\prime}(t)=\frac{1-2t}{2(t+\eta)(1-t+\eta)}\big{(}x-(1-t)x_{0}-tx_{1} \big{)}+x_{1}-x_{0}.\] (42)

After integrating over \(x_{0}\) and \(x_{1}\), we can take the limit \(\eta\to 0\). Thus, now for fixed \(x_{0}\) and \(x_{1}\) we do not have a fixed value of \(x_{t}\) in which to train the model, but a random one. In general case, we end up to the loss:

\[\mathcal{L}_{v}=\mathbb{E}_{t\sim\mathcal{U}(0,1),\,\{x_{1},x_{0}\}\sim\pi,\, x\sim p(\cdot,t\mid x_{0},x_{1})\|v_{\theta}(x,\,t)-v_{x_{0},x_{1}}(x,t)\|^{2},\] (43)

where \(\pi(x_{1},\,x_{0})\) is the density of the joint distributions with the marginal equal to the two given probabilities:

\[\int\pi(x_{1},\,x_{0})\,\mathrm{d}x_{1}=\rho_{0}(x_{0}),\quad\int\pi(x_{1},\, x_{0})\,\mathrm{d}x_{0}=\rho_{1}(x_{1}).\]

In the simple case, \(\pi(x_{1},\,x_{0})=\rho_{0}(x_{0})\rho_{1}(x_{1})\). Vector field in Eq. (43) if taken in the form of Eq. (42).

Now, we can obtain an explicit form for the vector field \(v\) at which the written loss is reached its minimum by performing the same calculations as in the derivation of formula (10):

\[v(x,t)=\frac{\iint v_{x_{0},x_{1}}(x,t)\,p(x,t\mid x_{0},\,x_{1})\,\pi(x_{0},x_{1})\,\mathrm{d}x_{0}\,\mathrm{d}x_{1}}{\iint p(x,t\mid x_{0},\,x_{1})\, \pi(x_{0},x_{1})\,\mathrm{d}x_{0}\,\mathrm{d}x_{1}}.\] (44)

As in the work [20] we can also train score network. Namely, as marginals for Brownian bridge are Gaussian, we can write explicit conditional score for conditional probabilistic path

\[\boldsymbol{\nabla}\log p(x,t\mid x_{0},\,x_{1})=\frac{\mu(t)-x}{\sigma_{e}^{ 2}(t)}=\frac{x_{0}(1-t)+x_{1}t-x}{\sigma_{e}^{2}t(1-t)}.\]

In the work [20] the following loss is introduced to train a model for this score

\[\mathcal{L}_{s}=\mathbb{E}_{t\sim\mathcal{U}(0,1),\,\{x_{1},x_{0}\}\sim\pi,\, x\sim p(\cdot,t\mid x_{0},x_{1})}\|s_{\theta}(x,t)-\nabla\log p(x,t\mid x_{0},\,x_{1}) \|^{2}.\] (45)

Similar to (44), for the optimal score \(s\) we have:

\[s(x,t)=\frac{\iint\boldsymbol{\nabla}\log p(x,t\mid x_{0},\,x_{1})\,p(x,t\mid x _{0},\,x_{1})\,\pi(x_{0},x_{1})\,\mathrm{d}x_{0}\,\mathrm{d}x_{1}}{\iint p(x,t \mid x_{0},\,x_{1})\,\pi(x_{0},x_{1})\,\mathrm{d}x_{0}\,\mathrm{d}x_{1}},\] (46)

where \(p\) is given in (41).

### Use stochastic

Note that the obtained vector field gives marginal distributions \(p(x,t)\), which (in the limit \(\eta\to 0\)) at \(t=1\) leads to the distribution we need: \(p(x,t=1)=\rho_{1}(x)\). However, the addition of the stochastic term allows us to extend the scope of application of the explicit formula for the vector field. In particular, it can be applied to the situation when we have two sets of samples and both distributions are unknown, as well as the possibility of constructing SDE and solving it using, for example, the Euler-Maruyama method (see examples below).

As consequence of Theorem 3.1 from [20] we have that, if \(v\) is given by Eq. (44) then ODE

\[\frac{\partial\rho(x,t)}{\partial t}=-\operatorname{div}\bigl{(}\rho(x,t)v(x, t)\bigr{)}\] (47)

recovers the marginal \(\rho(x,t)\) (with the given initial conditions) of the stochastic process \(P(t)\) which is obtained by marginalization conditional Brownian bridge (40) over initial and target distribution

\[P(t)=\int B(t\mid x_{0},x_{1})\pi(x_{0},x_{1})\,\mathrm{d}x_{0}\,\mathrm{d}x_ {1}\,.\]

As the second consequence of this Theorem, the SDE

\[\mathrm{d}x(t)=\Bigl{(}v\bigl{(}x(t),t\bigr{)}+\frac{g^{2}(t)}{2}s\bigl{(}x(t ),t\bigr{)}\Bigr{)}\,\mathrm{d}t+g(t)\,\mathrm{d}W(t)\] (48)

generates so-called Markovian of the process \(P(t)\). Indeed, we can rewrite PDE Eq. (47) in the form

\[\frac{\partial\rho(x,t)}{\partial t}=-\operatorname{div}\Bigl{(}\rho(x,t)v(x, t)+\frac{g^{2}(t)}{2}\boldsymbol{\nabla}\rho(x,t)\Bigr{)}+\frac{g^{2}(t)}{2} \Delta\rho(x,t),\]

where nabla operator is defined as \(\Delta=\operatorname{div}\boldsymbol{\nabla}\). Thus, we get the Fokker-Planck equation for the density of the stochastic process (48).

### Particular cases

In particular case of Brownian bridge when \(\sigma_{e}(t)=\sigma_{\epsilon}\sqrt{t(1-t)}\), then \(\sigma_{e}^{\prime}(t)=\sigma_{\epsilon}(1-2t)/\bigl{(}2\sqrt{t(1-t)}\bigr{)}\). In this section we consider simple case of separable variables \(\pi(x_{0},x_{1})=\rho_{0}(x_{0})\rho_{1}(x_{1})\).

#### e.3.1 Gaussian initial distribution

In the case, when \(\rho_{0}\) is standard Gaussian distribution: \(\rho_{0}=\mathcal{N}\left(\cdot\big{|}\,0,1^{2}\right)\), we can take integral on \(x_{0}\) and then take the limit \(\eta\to 0\) in the expressions for \(v\) and \(s\). First, consider the expression for \(v\): where we use explicit expression (41) for conditional density path and Eq. (42) for conditional velocity:

\[v(x,t)=\frac{\int w(x,t\mid x_{1})\mathcal{N}\left(x\big{|}\,x_ {1}t,\sigma_{e}^{2}t(1-t)+(1-t)^{2}\right)\rho_{1}(x_{1})\mathrm{d}x_{1}}{ \int\mathcal{N}\left(x\right|x_{1}t,\sigma_{e}^{2}t(1-t)+(1-t)^{2}\right)\rho _{1}(x_{1})\mathrm{d}x_{1}}=\\ =\frac{\int w(x,t\mid x_{1})\rho_{0}\Bigl{(}\frac{x-x_{1}t}{ \sqrt{\sigma_{e}^{2}t(1-t)+(1-t)^{2}}}\Bigr{)}\rho_{1}(x_{1})\mathrm{d}x_{1}}{ \int\rho_{0}\Bigl{(}\frac{x-x_{1}t}{\sqrt{\sigma_{e}^{2}t(1-t)+(1-t)^{2}}} \Bigr{)}\rho_{1}(x_{1})\mathrm{d}x_{1}},\] (49)

where \(w(x,t\mid x_{1})\) is the conditional velocity, generated by the conditional map \(\phi_{t,x_{1}}(x)=\sqrt{\sigma_{e}^{2}t(1-t)+(1-t)^{2}}+tx_{1}\):

\[w(x,t\mid x_{1})=\frac{x_{1}-x}{1-t+t\sigma_{e}^{2}}+\sigma_{e}^{2}\frac{(1-2t )x+tx_{1}}{2\bigl{(}(1-t)^{2}+(1-t)t\sigma_{e}^{2}\bigr{)}}.\]

Thus, note that in the case of Gaussian distributions, all the difference between this expression and the expression without the stochastic part is the appearance of additional (time-dependent, in general) variance. Marginal distributions are still Gaussian's.

Similar, using Eq. (46) we have for the score \(s\):

\[s(x,t)=\frac{\int(tx_{1}-x)\mathcal{N}\left(x\right|x_{1}t,\sigma_{ \epsilon}^{2}t(1-t)+(1-t)^{2}\right)\rho_{1}(x_{1})\mathrm{d}x_{1}}{\left((1-t )^{2}+(1-t)t\sigma_{\epsilon}^{2}\right)\int\mathcal{N}\left(x\right|x_{1}t, \sigma_{\epsilon}^{2}t(1-t)+(1-t)^{2}\right)\rho_{1}(x_{1})\mathrm{d}x_{1}}=\\ =\frac{\int(tx_{1}-x)\rho_{0}\Big{(}\frac{x-x_{1}t}{\sqrt{\sigma_ {\epsilon}^{2}t(1-t)+(1-t)^{2}}}\Big{)}\rho_{1}(x_{1})\mathrm{d}x_{1}}{\left((1 -t)^{2}+(1-t)t\sigma_{\epsilon}^{2}\right)\int\rho_{0}\Big{(}\frac{x-x_{1}t}{ \sqrt{\sigma_{\epsilon}^{2}t(1-t)+(1-t)^{2}}}\Big{)}\rho_{1}(x_{1})\mathrm{d}x _{1}}.\] (50)

#### e.3.2 Samples instead of distributions

Consider the case where we only have access to the samples \(\{x_{0}^{i}\}_{i=1}^{N_{0}}\) and \(\{x_{1}^{i}\}_{i=1}^{N_{1}}\) from both distributions, \(\rho_{0}\) and \(\rho_{1}\), but do not know their explicit expressions. In this case, we can estimate the vector field using by a method similar to the one we used to estimate the vector field in (15):

\[v(x,t)\approx\frac{\sum_{i=1}^{N_{0}}\sum_{j=1}^{N_{1}}v_{x_{0}^{i},x_{1}^{j}} (x,t)\,p(x,t\mid x_{0}^{i},\,x_{1}^{j})}{\sum_{i=1}^{N_{0}}\sum_{j=1}^{N_{1}}p (x,t\mid x_{0}^{i},\,x_{1}^{j})}.\] (51)

Similar for the score

\[s(x,t)\approx\frac{\sum_{i=1}^{N_{0}}\sum_{j=1}^{N_{1}}\bm{\nabla}p(x,t\mid x_ {0}^{i},x_{1}^{j})\,p(x,t\mid x_{0}^{i},\,x_{1}^{j})}{\sum_{i=1}^{N_{0}}\sum_{ j=1}^{N_{1}}p(x,t\mid x_{0}^{i},\,x_{1}^{j})}.\] (52)

In addition, we can also use the importance sampling method in this case. Namely we can use both approaches: self-normalized importance sampling and rejection sampling, similar to what is described in Sec. B

## Appendix F Consistency of Eq. (24) in the case of optimal transport

Let us analyze what happens if in formula (24) the joint density \(\pi\) represents the following Dirac delta-function4:

Footnote 4: Further reasoning is not absolutely rigorous, and in order not to introduce the axiomatics of generalized functions, we can assume that the delta function is the limit of the density of a normal distribution with mean \(0\) and variance tending to zero.

\[\pi(x_{0},x_{1})=\delta\big{(}x_{0}-F(x_{1})\big{)},\]

_i. e._ we have a deterministic mapping \(F\) from \(x_{1}\) to \(x_{0}\). Then, the Eq. (34) come to

\[v(x,t)=\frac{\int(x_{1}-x)\,\delta\big{(}\phi_{t,x_{1}}^{-1}(x)-F(x_{1})\big{)} \,\mathrm{d}x_{1}}{\left(1-t\right)\int\delta\big{(}\phi_{t,x_{1}}^{-1}(x)-F(x _{1})\big{)}\,\mathrm{d}x_{1}}.\]

Let \(y(x,t)\) be the unique solution of the equation

\[\phi_{t,y}^{-1}(x)=F(y),\] (53)

considered as an equation on \(y\). Then

\[v(x,t)=\frac{x-y(x,t)}{1-t}.\]

Now, let us use linear mapping \(\phi_{t,x_{1}}(x)=x_{1}t+x(1-t)\), with inverse \(\phi_{t,x_{1}}^{-1}(x)=\frac{x-tx_{1}}{1-t}\), and consider the simplest case when the original distribution is a \(d\)-dimensional standard Gaussian and \(\rho_{1}\) is a \(d\)-dimensional Gaussian with mean \(\mu\) and diagonal variance \(\Sigma=\text{diag}(\sigma)\). We know the OT correspondence between Gaussians, namely

\[\big{(}F(x_{1})\big{)}_{i}=\frac{(x_{1}-\mu)_{i}}{\Sigma_{ii}},\quad\forall 1 \geq i\geq d.\]Here and further by index \(i\) we denote \(i\)th component of the corresponding vector. Then, the Eq. (53) reads as

\[\frac{(x-yt)_{i}}{1-t}=\frac{(y-\mu)_{i}}{\Sigma_{ii}},\]

with the solution

\[\big{(}y(x,t)\big{)}_{i}=\frac{\mu_{i}(1-t)+x_{i}\Sigma_{ii}}{1+(\Sigma_{ii}-1) t}.\]

Then the expression for the vector field is

\[\big{(}v(x,t)\big{)}_{i}=\frac{\mu_{i}+x_{i}(\Sigma_{ii}-1)}{1+(\Sigma_{ii}-1) t}.\]

Now, knowing the expression for velocity, we can write the equations for the trajectories \(x(t)\):

\[\begin{cases}\big{(}x^{\prime}(t)\big{)}_{i}=\frac{\mu_{i}+(x(t))_{i}(\Sigma_ {ii}-1)}{1+(\Sigma_{ii}-1)t},\\ \quad x(0)_{i}=(x_{0})_{i}\end{cases}.\]

This equation have closed-form solution:

\[x(t)=\mu t+x_{0}-(1-\sigma)\,tx_{0}.\]

Analyzing the obtained solution, we conclude that, first, the trajectories obey the given mapping \(F\):

\[\big{(}F(x(1))\big{)}_{i}=(x_{0})_{i}=\frac{(x(1)-\mu)_{i}}{\Sigma_{ii}},\]

And, second, the trajectories are straight lines (in space), as they should be when the flow carries points along the optimal transport.

As a final conclusion, note that, of course, if we are mapping optimal transport \(F\), then it is meaningless to use numerical formula (16). However, usually the exact value of the mapping \(F\) is not known, and our theoretical formula (34) can help to rigorously establish the error that is committed when an approximate mapping is used instead of the optimal one.

## Appendix G Analytical derivations for example in Fig. 1(b)

### CFM dispersion

To derive the analytical expression for the optimal flow velocity in the case of two normal distributions \(\rho_{0}\sim N(0,I)\) and \(\rho_{1}\sim N(\mu,\sigma^{2}I)\), we start by substituting \(\mu_{0}=0\), \(\sigma_{0}=1\), \(\mu_{1}=\mu\), \(\sigma_{1}=\sigma\), to the exact expression (35) to get

\[v(x,t)=\frac{t\sigma^{2}+t-1}{(1-t)^{2}+t^{2}\sigma^{2}}x+\frac{1}{(1-t)^{2}+ t^{2}\sigma^{2}}(\mu-t\mu)=w(t)x+C,\] (54)

where

\[w(t)=\frac{t\sigma^{2}+t-1}{(1-t)^{2}+t^{2}\sigma^{2}},\]

and \(C\) is constant independent of \(x\). We then redefine the dispersion based on Eq. (19) using \(x=(1-t)x_{0}+tx_{1}\) with \(x_{0}\sim\rho_{0}\) and \(x_{1}\sim\rho_{1}\):

\[\mathbb{D}_{x,x_{1}}f(x,\,x_{1})=\mathbb{D}_{x_{0},x_{1}}f\big{(}(1-t)x_{0}+ tx_{1},\,x_{1}\big{)}\] (55)

This leads us to the final expression:

\[\mathbb{D}_{x,x_{1}}\Delta v(x,t) =\mathbb{D}_{x_{0},x_{1}}((1-w(t))x_{1}-(1+w(t)(1-t))x_{0})=\] \[=(1+w(t)(1-t))^{2}\mathbb{D}_{x_{0}}x_{0}+(1-w(t))^{2}\mathbb{D}_ {x_{1}}x_{1}.\]

This provides a comprehensive representation of the updated dispersion for the CFM objective at any given time \(t\).

### ExFM dispersion

The analytical derivation of the updated dispersion for the ExFM objective proves to be complex in practice. Therefore, for the example at hand, a numerical scheme was employed for evaluation. The procedure outlined in Alg. 2 was utilized for this task. The experiment's parameters for the algorithm were as follows: \(M=\) 200\(k\), \(N=128\), \(\rho_{0}=N(0,I)\), \(\rho_{1}=N(\mu,\sigma^{2}I)\), and the optimal model \(v(x,t)\) was derived from equation (54).

## Appendix H Additional Experiments

### 2D toy examples

To ensure the reliability and impartiality of the outcomes, we carried out the experiment under uniform conditions and parameters. Initially, we generated a training set of batch size \(N=\) 10,000 points. The employed model was a simple Multilayer Perceptron with ReLu activations and 2 hidden layers of 512 neurons, Adam optimizer with a learning rate of \(10^{-3}\), and no learning rate scheduler. We determined the number of iteration steps equal to 10000. Subsequently, we configured the mini batch size \(n=256\) during the training procedure, with the primary objective of minimizing the Mean Squared Error (MSE) loss. The full training algorithm and notations can be seen in Algorithm 1. To perform sampling, we employed the function odeint with dopri5 method from the python package torchdiffeq import odeint with atol and rtol equal \(1e-5\).

### Tabular

The power dataset (dimension = 6, train size = 1659917, test size = 204928) consisted of electric power consumption data from households over a period of 47 months. The gas dataset (dimension = 8, train size = 852174, test size = 105206) recorded readings from 16 chemical sensors exposed to gas mixtures. The heptass dataset (dimension = 21, train size = 315123, test size = 174987) described Monte Carlo simulations for high energy physics experiments. The minibone (dimension = 43, train size = 29556, test size = 3648) dataset contained examples of electron neutrino and muon neutrino. Furthermore, we utilized the BSDS300 dataset (dimension = 63, train size = 1000000, test size = 250000), which involved extracting random 8 x 8 monochrome patches from the BSDS300 datasets of natural images [11].

These diverse multivariate datasets are selected to provide a comprehensive evaluation of performance across various domains. To maintain consistency, we followed the code available at the given GitHub link5 to ensure that the same instances and covariates were used for all the datasets.

Footnote 5: https://github.com/gpapamak/maf

To ensure the correctness of the experiments we conduct them with the same parameters. To train the model we use the same MultiLayer Perceptron (1024 x 3) model with ReLu activations, Adam as optimizer with learning rate of \(10^{-3}\) and no learning rate scheduler. As in the pretrained step, we use separately training and testing sets for training the model and calculating metrics. We train the models on the full dataset (of size train_set_size) with batch size \(N=5000\) (batch_size)(except miniboone dataset, here we used 2000 since the smaller size of the dataset) and mini batches \(n=256\) elements (mini_batch_size), the number of epochs and steps for each dataset is adaptive num_epochs = train_set_size // batch_size and num_steps = batch_size // mini_batch_size.

For both 2D-toy an tabular data: we take \(m=n\) time variable, individual value of variable \(t\) corresponds to its pair \((x_{0},x_{1})\). The notations \(N\), \(n\) and \(m\) corresponds to those in Algorithm 1. To perform sampling, we employed the function odeint with dopri5 method from the python package torchdiffeq import odeint with atol and rtol equal \(1e-5\).

### ExFM-S evaluation

The models were assessed using four toy datasets of two dimensions each. A three-layer MLP network was utilized, featuring SeLU activations and a hidden dimension of 64. Optimization was carried out using the AdamW optimizer with a learning rate of \(10^{-3}\) and a weight decay of \(10^{-5}\)

\begin{table}
\begin{tabular}{l r r} \hline \hline Data & ExFM & CFM & OT-CFM \\ \hline power & **-8.51e-02 \(\pm\) 4.85e-02** & 1.64e-01 \(\pm\) 4.18e-02 & 5.22e-02 \(\pm\) 3.92e-02 \\ gas & **-5.53e+00 \(\pm\) 3.66e-02** & -5.00e+00 \(\pm\) 2.56e-02 & -5.48e+00 \(\pm\) 2.90e-02 \\ hepmass & 2.16e+01 \(\pm\) 6.31e-02 & **2.21e+01 \(\pm\) 6.13e-02** & 2.16e+01 \(\pm\) 4.32e-02 \\ bdss300 & -1.29e+02 \(\pm\) 8.40e-01 & -1.29e+02 \(\pm\) 8.97e-01 & **-1.32e+02 \(\pm\) 6.39e-01** \\ miniboone & **1.34e+01 \(\pm\) 1.95e-04** & 1.42e+01 \(\pm\) 1.29e-04 & 1.43e+01 \(\pm\) 9.22e-05 \\ \hline \hline \end{tabular}
\end{table}
Table 6: NLL comparison for ExFM, CFM and OT-CFM methods over 10 000 learning steps, mean and std taken from 10 sampling iterations.

\begin{table}
\begin{tabular}{l r r} \hline \hline Data & MLP layers & lr \\ \hline power & [512, 1024, 2048] & 1e-3 \\ gas & [512, 1024,1024] & 1e-4 \\ hepmass & [512, 1024] & 1e-3 \\ bsds300 & [512, 1024,1024] & 1e-4 \\ miniboone & [512, 1024] & 1e-3 \\ \hline \hline \end{tabular}
\end{table}
Table 5: Learning parameters for Tabular datasets.

Figure 7: Training loss comparison for ExFM, CFM and OT-CFM methods over \(10\,000\) learning steps.

[MISSING_PAGE_FAIL:34]

### Metrics

For evaluating 2D toy data we use Energy Distance and W2 metricis, for Tabular datasets we use Negative Log Likelihood, for CIFAR10 we took Frechet inception distance (FID) metrics. This choice is connected with an instability and poor evaluation quality of Energy Distance metrics and W2 among high-dimensional data.

#### h.5.1 Energy Distance

We use the generalized Energy Distance [18] (or E-metrics) to the metric space.

Consider the null hypothesis that two random variables, \(X\) and \(Y\), have the same probability distributions: \(\mu=\nu\).

For statistical samples from \(X\)and \(Y\):

\[\{x_{1},\ldots,x_{n}\}\quad\text{ and }\quad\{y_{1},\ldots,y_{m}\},\]

the following arithmetic averages of distances are computed between the \(X\) and the \(Y\) samples:

\[A=\frac{1}{nm}\sum_{i=1}^{n}\sum_{j=1}^{m}\|x_{i}-y_{j}\|,\quad B=\frac{1}{n^{2 }}\sum_{i=1}^{n}\sum_{j=1}^{n}\|x_{i}-x_{j}\|,\quad C=\frac{1}{m^{2}}\sum_{i=1} ^{m}\sum_{j=1}^{m}\|y_{i}-y_{j}\|.\]

\begin{table}
\begin{tabular}{l c c c} \hline Step & ExFM FID & CFM FID & OT-CFM FID \\ \hline

[MISSING_PAGE_POST]

 \hline \end{tabular}
\end{table}
Table 8: FID comparison for ExFM, CFM and OT-CFM methods over 400 000 learning steps, mean and std taken from 4 sampling iterations.

Figure 10: Training loss comparison for ExFM, CFM and OT-CFM methods, MNIST dataset.

Figure 11: FID comparison for ExFM, CFM and OT-CFM methods, CIFAR-10 dataset.

Figure 12: Sampled images from ExFM method, CIFAR-10 dataset.

The E-statistic of the underlying null hypothesis is defined as follows:

\[E_{n,m}(X,Y):=2A-B-C\]

#### h.5.2 2-Wasserstein distance (W2)

The 2-Wasserstein distance [14], also called the Earth mover's distance or the optimal transport distance \(W\) is a metric to describe the distance between two distributions, representing two different subsets \(A\) and \(B\). For continuous distributions, it is:

\[W:=W(F_{A},F_{B})=\left(\int_{0}^{1}\left|F_{A}^{-1}(u)-F_{B}^{-1}(u)\right|^{ 2}du\right)^{\frac{1}{2}},\]

where \(F_{A}\) and \(F_{B}\) are the corresponding cumulative distribution functions and \(F_{A}^{-1}\) and \(F_{B}^{-1}\) the respective quantile functions.

#### h.5.3 Negative Log Likelihood (NLL)

To compute the NLL, we first sampled \(N=5000\) samples \(\{x_{i}^{s}\}_{i=1}^{N}\) from the target distribution. Then we solved the following inverse flow ODE:

\[\left\{\begin{aligned} \frac{\partial x(t)}{\partial t}& =v_{\theta}(x(t),t),\\ x(1)&=x_{s}\end{aligned}\right.\]

for \(t\) from \(1\) to \(0\). For simplicity, changing time variable \(\tau=1-t\) we solve the following ODE:

\[\left\{\begin{aligned} \frac{\partial x(\tau)}{\partial\tau}& =-v_{\theta}(x(\tau),1-\tau),\\ x(0)&=x_{s}\end{aligned}\right.\]

Figure 13: Sampled images from ExFM method, MNIST dataset.

for \(\tau\) from \(0\) to \(1\). Thus we obtained \(N\) solutions \(\{x_{i}^{0}\}_{i=1}^{N}\) which are expected to be distributed according to the standard normal distribution \(\mathcal{N}(x\mid 0,I)\). So we calculate NLL as

\[\text{NLL}=-\frac{1}{N}\sum_{i=1}^{N}\ln\mathcal{N}(x_{i}^{0}\mid 0,I).\]

#### h.5.4 Frechet inception distance (FID)

For images evaluation we take Frechet inception distance (FID) metrics, in particular the implementation from [12]. The main idea of FID metrics is to measure the gap between two data distributions, such as between a training set and samples from a trained model. After resizing the images, and feature extraction, the mean \((\mu,\hat{\mu})\) and covariance matrix \((\Sigma,\hat{\Sigma})\) of the corresponding features are used to compute FID:

\[\mathrm{FID}=||\mu-\hat{\mu}||_{2}^{2}+\mathrm{Tr}(\Sigma+\hat{\Sigma}-2( \Sigma\hat{\Sigma})^{1/2}),\]

where \(Tr\) is the trace of the matrix.