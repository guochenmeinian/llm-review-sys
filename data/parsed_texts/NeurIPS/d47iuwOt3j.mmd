# On the Gini-impurity Preservation

For Privacy Random Forests

 Xin-Ran Xie, Man-Jie Yuan, Xue-Tong Bai, Wei Gao, Zhi-Hua Zhou

National Key Laboratory for Novel Software Technology, Nanjing University, China

School of Artificial Intelligence, Nanjing University, China

{xiexr,yuanmj,baixt,gaow,zhouzh}@lamda.nju.edu.cn

These authors contribute equally.

###### Abstract

Random forests have been one of the successful ensemble algorithms in machine learning. Various techniques have been utilized to preserve the privacy of random forests, such as anonymization, differential privacy, homomorphic encryption, etc. This work takes one step towards data encryption by incorporating some crucial ingredients of learning algorithm. Specifically, we develop a new encryption to preserve data's Gini impurity, which plays an important role during the construction of random forests. The basic idea is to modify the structure of binary search tree to store several examples in each node, and encrypt the data features by incorporating label and order information. Theoretically, our scheme is proven to preserve the minimum Gini impurity in ciphertexts without decrypting, and we also present the security guarantee for encryption. For random forests, we encrypt data features based on our Gini-impurity-preserving scheme, and take the homomorphic encryption scheme CKKS to encrypt data labels owing to their importance and privacy. We finally present extensive empirical studies to validate the effectiveness, efficiency and security of our proposed method.

## 1 Introduction

From the pioneer work [1], random forests have been one successful ensemble algorithm [2; 3; 4], with diverse applications such as ecology [5], computational biology [6], objection recognition [7], remote sensing [8], computer vision [9], etc. The basic idea is to construct a large number of random trees individually and make prediction based on an average of their predictions. Numerous variants of random forests have been developed to improve performance under different settings [10; 11; 12; 13; 14; 15; 16; 17; 18; 19; 20; 21; 22], as well as theoretical understandings on the success of random forests [23; 21; 24; 25; 26; 27]. The splitting criterion, such as Gini impurity and information gain, has been one of the most important ingredient during the construction of random forests [1; 28].

Various techniques have been adopted to preserve the privacy of random forests, especially for sensitive tasks such as medical diagnosis, financial predictions, and so on. For example, differential privacy [29] has been successfully applied to preserve the privacy of random forests [30; 31] and decision trees [32; 33; 34], by adding certain noise perturbations. Another relevant approach is the secure multi-party computation for random forests and decision tree [35; 36; 37; 38; 39], where the privacy is preserved by multi-party joint computation over respective data inputs without leakage.

Homomorphic encryption [40; 41; 42; 43] has been one of the most important cryptosystems in privacy-preserving computing [44; 45; 46; 47]. Based on such scheme, various algorithms have been developed to train privacy random forests and decision trees [48; 49; 50; 51; 52], while some other methods only considered inference without training due to computational costs [53; 54; 55; 56; 57; 58]. In addition, LeFevre et al. [59] tookthe anonymization [60] for random forests by grouping similar attributes so as to hardly identify specific individual information.

This work takes one step towards data encryption by incorporating some crucial ingredients of learning algorithm, and main contributions can be summarized as follows:

* We present a new encryption to preserve data's Gini impurity, and the basic idea is to modify the structure of binary search trees to maintain several samples on each node, and encrypt data's features by incorporating label and order information. Our scheme could change the data frequencies, which is also beneficial for data security.
* Theoretically, we prove the preservation of minimum Gini impurity in ciphertexts without decryption, which plays an important role on the construction of random forests. Our scheme also satisfies the security against Gini-impurity-preserving chosen plaintext attack.
* We focus on the privacy random forests in the popular client-server protocol, and take our Gini-impurity-preserving encryption for data features. We adopt homomorphic encryption CKKS to encrypt data labels. Our encrypted decision tree takes smaller communication and computational complexities, as shown in Table 1.
* Extensive experiments show that our encrypted random forests take significantly better performance than prior privacy random forests via encryption, anonymization and differential privacy, and are comparable to original (plaintexts) random forests without encryption. Our encrypted random forests make a good balance between computational cost and data security.

The rest of this work is constructed as follows: Section 2 introduces relevant work. Section 3 presents an encryption on data's Gini impurity. Section 4 proposes the encrypted random forests. Section 5 conducts extensive experiments. Section 6 concludes with future work.

## 2 Relevant Work

Homomorphic Encryption (HE) is a cryptosystem, which allows operations on encrypted data without access to a secret key [40]. We can perform some mathematical operations such as addition and multiplication operations on encrypted data without revealing sensitive information. Given an encryption function \(E(\cdot)\) and a decryption function \(D(\cdot)\), the HE scheme provides two operators \(\oplus\) and \(\otimes\) such that, for every pair of plaintexts \(x_{1}\) and \(x_{2}\),

\[D\left(E(x_{1})\oplus E(x_{2})\right)=x_{1}+x_{2}\quad\text{ and }\quad D \left(E(x_{1})\otimes E(x_{2})\right)=x_{1}\times x_{2}\;,\]

where \(+\) and \(\times\) denote standard addition and multiplication operations, respectively.

Various HE schemes have been developed during the past years, e.g., ElGamal [67], Paillier [68], CKKS [42] encryption, etc. Relevant techniques have been successfully applied to machine learning tasks such as regression problem [69; 70], neural network [71; 72; 73; 74; 75], collaborative filtering [76], etc. Generally, HE schemes are accompanied with high computational costs, and one main challenge is to maintain a good trade-off among security, effectiveness and computational cost in real applications.

\begin{table}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|} \hline \multirow{2}{*}{Scheme} & Training communication & Training comp. complexity & Predictive communication & Predictive comp. complexity & Privacy \\ \cline{2-9}  & Rounds & Bandwidth & Client & Server & Rounds & Bandwidth & Client & Server & of model \\ \hline SMCDT [61] & \(O(\kappa)\) & \(O(\beta r)\) & \(O(\kappa\beta r)\) & \(O(\kappa\beta r)\) & \(O(1)\) & \(O(1)\) & \(O(1)\) & \(O(h)\) & âœ— \\ PPD3 [36] & \(O(\kappa)\) & \(O(\beta r^{2}jrn)\) & \(O(\kappa\beta^{2}jrn)\) & \(O(\kappa\beta^{2}jrn)\) & \(O(1)\)Secure Multi-Party Computation (SMC) [77] is another cryptographic technique to jointly compute a function from multiple private inputs with confidential, which has been used for machine learning to protect privacy data, such as neural network [78, 79, 80], \(k\)-means clustering [81, 82, 83], random forests and decision trees [35, 36, 37, 38, 39], etc. Differential privacy is introduced to preserve individual privacy by taking statistically inconsequential changes to data [84], and relevant techniques have been utilized in neural network [85, 86, 87], random forests [30, 31] and decision trees [32, 33, 34].

We introduce some notations used in this work. Write \([\tau]=\{1,2,\cdots,\tau\}\) for integer \(\tau\geq 2\). Let \(\mathcal{X}\subset\mathbb{R}^{d}\) and \(\mathcal{Y}=[\tau]\) denote the feature and label space, respectively. A training sample is given by \(S_{n}=\{(\mathbf{x}_{1},y_{1}),(\mathbf{x}_{2},y_{2}),...,(\mathbf{x}_{n},y_{n})\}\). Let \(|A|\) be the cardinality of set \(A\), and \([\![\cdot]\!]\) denotes the corresponding encrypted value. Let \(\mathcal{N}(\mu,\sigma^{2})\) be a normal distribution of mean \(\mu\) and variance \(\sigma^{2}\).

## 3 An Encryption for Gini Impurity

This section presents the first encryption to preserve the minimum Gini impurity over encrypted data without decryption. For simplicity, we give the detailed encryption on one-dimensional feature by incorporating label information, and make similar considerations for other dimensions.

### Theoretical Analysis for Gini Impurity

Let \(A=\{(a_{1},y_{1}),\cdots,(a_{n},y_{n})\}\) be a dataset with labels \(y_{i}\in[\tau]\), and define the Gini value as

\[\text{Gini}(A)=1-\sum\nolimits_{y\in[\tau]}p_{y}^{2}\;,\]

where \(p_{y}\) denotes the proportion of the label \(y\). Let \(A_{a}^{l}=\{(a_{i},y_{i})\colon a_{i}\leq a,(a_{i},y_{i})\in A\}\) and \(A_{a}^{r}=\{(a_{i},y_{i})\colon a_{i}>a,(a_{i},y_{i})\in A\}\) be the left and right subsets of \(A\) w.r.t. a splitting point \(a\), respectively. We define the Gini impurity w.r.t. dataset \(A\) and splitting point \(a\) as

\[I_{G}(A,a)=w_{l}\cdot\text{Gini}(A_{a}^{l})+w_{r}\cdot\text{Gini}(A_{a}^{r})\;, \tag{1}\]

where \(w_{l}=|A_{a}^{l}|/n\) and \(w_{r}=|A_{a}^{r}|/n\). Let \(I_{G}^{*}(A)\) be the minimum Gini impurity of dataset \(A\), i.e.,

\[I_{G}^{*}(A)=\min\nolimits_{a\in\mathbb{R}}\{I_{G}(A,a)\}\;. \tag{2}\]

The minimum Gini impurity plays a crucial role on nodes splitting during the construction of random forests. We re-sort dataset \(A\) with a non-decreasing order for \(a_{1},a_{2},\cdots,a_{n}\) as follows:

\[A=\left\{(a_{(1)},y_{(1)}),(a_{(2)},y_{(2)}),\cdots,(a_{(n)},y_{(n)})\right\}\;, \tag{3}\]

where \(a_{(1)}\leq a_{(2)}\leq\cdots\leq a_{(n)}\), and \(y_{(1)},y_{(2)},\cdots,y_{(n)}\) denote their corresponding labels. By incorporating label information, we partition dataset \(A\) into several datasets \(\mathcal{I}_{1},\mathcal{I}_{2},\cdots,\mathcal{I}_{s}\) as follows:

\[\mathcal{I}_{1} = \left\{(a_{(1)},y_{(1)}),\cdots,(a_{\langle k_{1}\rangle},y_{(k_{ 1})})\right\}\;,\] \[\mathcal{I}_{2} = \left\{(a_{(k_{1}+1)},y_{(k_{1}+1)}),,\cdots,(a_{\langle k_{1}+k _{2}\rangle},y_{(k_{1}+k_{2})})\right\}\;,\] \[\cdots\] \[\mathcal{I}_{s} = \left\{(a_{(k_{1}+k_{2}+\cdots+k_{s-1}+1)},y_{\langle k_{1}+k_{2 }+\cdots+k_{s-1}+1\rangle}),\cdots,(a_{\langle n\rangle},y_{\langle n\rangle} )\right\}\;.\]

Here, any two adjacent datasets have different labels, and all samples have an identical label in one dataset \(\mathcal{I}_{j}\), i.e., \(y_{\langle i\rangle}=y_{\langle i^{\prime}\rangle}\) for every \((a_{\langle i\rangle},y_{\langle i\rangle})\in\mathcal{I}_{j}\) and \((a_{\langle i^{\prime}\rangle},y_{\langle i^{\prime}\rangle})\in\mathcal{I}_{j}\).

Figure 1: A simple illustration for our encryption: each plaintext is encrypted into a ciphertext vector \((c_{i},e_{i,j})\). Here, random numbers \(c_{1}<c_{2}<\cdots<c_{s}\) are introduced to preserve the Gini impurity for random forests, and we take homomorphic encryption scheme for \(e_{i,j}=\text{Enc}(k_{\text{pub}},j)\) in Eqn. (5), which is helpful for decryption.

We consider two important factors in encryption: i) preservation of the minimum Gini impurity \(I_{G}^{*}(A)\) over the encrypted data, and ii) a cryptosystem for encoding and decoding data. Based on such recognition, we introduce the following encryption, for every example \((a_{\langle i\rangle},y_{\langle i\rangle})\in\mathcal{I}_{j}\),

\[\llbracket a_{\langle i\rangle}\rrbracket=\begin{pmatrix}\llbracket a_{ \langle i\rangle}\rrbracket_{1},\llbracket a_{\langle i\rangle}\rrbracket_{2} \end{pmatrix}=\begin{cases}(c_{1},\text{Enc}(k_{\text{pub}},i))&\text{for }\;j=1 \;,\\ (c_{j},\text{Enc}(k_{\text{pub}},i-k_{1}-\cdots-k_{j-1}))&\text{for }\;2\leq j\leq s\;.\end{cases} \tag{5}\]

Here, \(c_{1},c_{2},\cdots,c_{s}\) are random numbers s.t. \(c_{1}<c_{2}<\cdots<c_{s}\), which aim to preserve the minimum Gini impurity. We take the homomorphic encryption scheme CKKS with a public key \(k_{\text{pub}}\) for \(\llbracket a_{\langle i\rangle}\rrbracket_{2}=\text{Enc}(k_{\text{pub}},i-k_ {1}-\cdots-k_{j-1})\) in Eqn. (5), and it is useful for decryption. Figure 1 presents a simple illustration for our encryption, and the detailed decryption is given in Appendix A.

We now present our main theorem as follows:

**Theorem 1**.: _We have \(I_{G}^{*}(A)=I_{G}^{*}(A^{\prime})\), for re-sort dataset \(A\) by Eqn. (3) and for the corresponding encrypted dataset \(A^{\prime}=\{(\llbracket a_{\langle 1\rangle}\rrbracket_{1},y_{\langle 1 \rangle}),\cdots,(\llbracket a_{\langle n\rangle}\rrbracket_{1},y_{\langle n \rangle})\}\) from Eqns. (4)-(5)._

This theorem shows that our encryption could preserve the minimum Gini impurity over encrypted data. The detailed proof is presented in Appendix B, which involves the proof of piecewise monotonicity of \(I_{G}(A,a)\) w.r.t. splitting point \(a\), and then solves the minimum splitting point on plaintexts, as well as the corresponding point on encrypted data.

### Binary Search Tree for Encryption

We now present new binary search tree to encrypt \(a_{1},\cdots,a_{n}\) dynamically, especially for un-ordered dataset \(A=\{(a_{1},y_{1}),\cdots,(a_{n},y_{n})\}\), or when example \((a_{i},y_{i})\) arrives in a streaming data. We begin with an alternative structure for binary search tree to maintain several samples on a node from Eqns. (4)-(5), rather than previous only one sample [88; 89]. Our new structure is given by

\[\textbf{Struct Tree}\left\{\text{Plaintext samples};\;\;\text{Ciphertext {\emph{cipher}}}_{1},\text{\emph{cipher}}_{2};\;\;\text{Tree \emph{left}\text{\emph{right}}}\right\}\;.\]

The _samples_ stores one or multiple samples from \(A\), and _cipher\({}_{1}\)_ and _cipher\({}_{2}\)_ are the first and second ciphertext in Eqn. (5), and _left_ and _right_ denote left and right child of the current node, respectively. We initialize an empty tree \(\mathcal{BT}=\emptyset\) and set its _cipher\({}_{1}=c_{\text{max}}/2\)_ with \(c_{\text{max}}=2^{\lambda\log_{2}n}\), and then we construct binary search tree iteratively. We maintain an interval \([t_{\text{min}},t_{\text{max}}]\) in each iteration so as to keep the increasing order of ciphertexts \(c_{1},c_{2},\cdots,c_{s}\) in Eqn. (5). During the \(i\)-th iteration, we receive a sample \((a_{i},y_{i})\), and then take two steps as follows:

**Step-I: Search a node for sample \((a_{i},y_{i})\) in binary search tree \(\mathcal{BT}\)**

Let \(t\) be a node pointer with the initialization of the root of \(\mathcal{BT}\). We search a path downward in \(\mathcal{BT}\) by comparing with \(a_{i}\), and the search will terminate when \(t\) is a leaf node or an empty node.

For an internal node \(t\), the search continues to its left child and updates \(t_{\text{max}}=t.\textit{cipher}_{1}\) if

\[\text{the left child }t.\textit{left}\neq\emptyset\quad\text{ and }\quad a_{i}< \max\{a_{j}\colon(a_{j},y_{j})\in t.\textit{left}.\textit{samples}\}\ ;\]

and the search continues to its right child and updates \(t_{\text{min}}=t.\textit{cipher}_{1}\) if

\[\text{the right child }t.\textit{right}\neq\emptyset\quad\text{ and }\quad a_{i} >\min\{a_{j}\colon(a_{j},y_{j})\in t.\textit{right}.\textit{samples}\}\ ;\]

otherwise, the search terminates. This procedure can be easily implemented with a while loop.

It is necessary to consider two special cases after the above search. We update \(t=t.\textit{left}\) if

\[t.\textit{left}\neq\emptyset,\ a_{i}<\min\{a_{j}:(a_{j},y_{j})\in t.\textit{ samples}\}\ \text{and}\ y_{i}=y_{j}\ \text{for all}\ (a_{j},y_{j})\in t.\textit{left}.\textit{samples}. \tag{6}\]

In a similar manner, we update \(t=t.\textit{right}\) if

\[t.\textit{right}\neq\emptyset,\ a_{i}>\max\{a_{j}:(a_{j},y_{j})\in t.\textit{ samples}\}\ \text{and}\ y_{i}=y_{j}\ \text{for all}\ (a_{j},y_{j})\in t.\textit{right}.\textit{samples}. \tag{7}\]

**Step-II: Update the binary search tree \(\mathcal{BT}\)**

After Step-I, we could find a node \(t\) for sample \((a_{i},y_{i})\) and the corresponding interval \([t_{\text{min}},t_{\text{max}}]\). We directly append the example \((a_{i},y_{i})\) into \(t.\textit{samples}\) if \(y_{i}=y_{j}\) for every \((a_{j},y_{j})\in t.\textit{samples}\); otherwise, it is necessary to split the node \(t\) according to \(a_{i}\).

We initialize an empty node \(l\) with \(l.\textit{samples}=\{(a_{j},y_{j})\in t.\textit{samples}\colon a_{j}<a_{i}\}\), and it is sufficient to consider \(l.\textit{samples}\neq\emptyset\). If \(t.\textit{left}\neq\emptyset\), then we set

\[l.\textit{cipher}_{1}=(t.\textit{left}.\textit{cipher}_{1}+t.\textit{cipher}_ {1})/2+\xi\quad\text{s.t.}\quad t.\textit{left}.\textit{cipher}_{1}<l.\textit{ cipher}_{1}<t.\textit{cipher}_{1}\, \tag{8}\]

and update \(l.\textit{left}=t.\textit{left}\), \(t.\textit{left}=l\); otherwise, we set

\[l.\textit{cipher}_{1}=(t_{\text{min}}+t.\textit{cipher}_{1})/2+\xi\quad\text{ s.t.}\quad l.\textit{cipher}_{1}\in(t_{\text{min}},t.\textit{cipher}_{1})\, \tag{9}\]

and update \(t.\textit{left}=l\). Here, \(\xi\) is a random number sampled from \(\mathcal{N}(0,1)\), and notice that we may randomly sample \(\xi\) multiple times so that the condition holds in Eqns (8)-(9), respectively.

We make similar update for the right child of node \(t\): initialize an empty node \(r\) with \(r.\textit{samples}=\{(a_{j},y_{j})\in t.\textit{samples}\colon a_{j}>a_{i}\}\), and consider \(r.\textit{samples}\neq\emptyset\). If \(t.\textit{right}\neq\emptyset\), then we set

\[r.\textit{cipher}_{1}=(t.\textit{cipher}_{1}+t.\textit{right}.\textit{cipher}_{ 1})/2+\xi\text{ s.t. }t.\textit{cipher}_{1}<r.\textit{cipher}_{1}<t.\textit{right}. \textit{cipher}_{1}\;, \tag{10}\]

and update \(r.\textit{right}=t.\textit{right}\), \(t.\textit{right}=r\); otherwise, we set

\[r.\textit{cipher}_{1}=(t.\textit{cipher}_{1}+t_{\text{max}})/2+\xi\text{ s.t. }r.\textit{cipher}_{1}\in(t.\textit{cipher}_{1},t_{\text{max}})\;, \tag{11}\]

and update \(t.\textit{right}=r\). Algorithm 2 presents the detailed descriptions on the splitting of node \(t\).

Algorithm 1 presents an overview of our Gini-impurity-preserving encryption, and the decryption is given in Appendix A. Our scheme does not only keep the minimum Gini impurity, but also change frequencies to prevent decryption from frequencies, which is also beneficial for encryption [90]. Our scheme takes an average of \(O(n\log n)\) computational complexity, since it requires \(O(\log n)\) and \(O(1)\) computational complexities to search and update a node in each iteration, respectively. Finally, the average and worst space complexities are \(O(\log n)\) and \(O(n)\) for our encryption, respectively.

```
Input: Encrypted datasets \(\llbracket S_{n}^{t}\rrbracket\), available splitting feature and position \(\llbracket s\rrbracket_{i=1}^{2}\), and secret key \(k_{\text{sec}}\) Output: index \(i^{*}\)  %% Server: for\(i\in[\jmath]\)do  Calculate Gini impurity \(I_{G}(\llbracket S_{n}^{t}\rrbracket,\llbracket s\rrbracket_{i})\) from Eqn. (12) w.r.t splitting feature and position \(\llbracket s\rrbracket_{i}\) endfor  Send ciphertexts \(\{I_{G}(\llbracket S_{n}^{t}\rrbracket,\llbracket s\rrbracket_{i})\}_{i\in[ \jmath]}\) to the client  %% Client:  Get the decrypted \(\{\text{Dec}(k_{\text{sec}},I_{G}(\llbracket S_{n}^{t}\rrbracket,\llbracket s \rrbracket_{i}))\}_{i\in[\jmath]}\)  Set \(i^{*}=-1\) if \(\text{Dec}(k_{\text{sec}},I_{G}(\llbracket S_{n}^{t}\rrbracket,\llbracket s \rrbracket_{i}))=0\) for every \(i\in[\jmath]\); otherwise, set \(i^{*}\) by Eqn. (13)  Send \(i^{*}\) to the server
```

**Algorithm 3** Finding the best splitting feature and position

### Security Analysis

For ciphertext vector \(\llbracket a\rrbracket_{1}\), since the security of \(\llbracket a\rrbracket_{2}\) has been analyzed in homomorphic encryption CKKS [42]. Following semantic security against chosen plaintext attacks [89, 91], we define a security game \(\text{Game}_{\text{GIPCPA}}\):

* An adversary chooses two sequences with distinct plaintexts \(\{a_{1}^{0},\cdots,a_{n}^{0}\}\) and \(\{a_{1}^{1},\cdots,a_{n}^{1}\}\), and sends them to a challenger;
* The challenger flips an unbiased coin \(b\in\{0,1\}\) to select \(\{a_{1}^{b},\cdots,a_{n}^{b}\}\), and randomly sets their corresponding labels \(\{y_{1}^{b},\cdots,y_{n}^{b}\}\) with each \(y_{i}^{b}\) drawn independently and uniformly over \([\tau]\). The challenger encrypts \(\{a_{1}^{b},\cdots,a_{n}^{b}\}\) by Eqns. (4) and (5), and sends the ciphertexts to the adversary;
* The adversary outputs a guess of \(b\), i.e., which sequence is selected for encryption.

We then introduce the security against Gini-impurity-preserving chosen plaintext attack as follows.

**Definition 2**.: A scheme is said to be indistinguishable under Gini-impurity-preserving chosen plaintext attack if the probability of outputs with the correct guess \(b\) is negligible for the adversary \(\mathcal{A}\) in \(\text{Game}_{\text{GIPCPA}}\), that is,

\[\Pr[\mathcal{A}(\text{Game}_{\text{GIPCPA}})=b]<1/2+\text{ small constant}\;.\]

The following theorem shows that our encrypted plaintexts sequences are indistinguishable.

**Theorem 3**.: _Our scheme for the first ciphertexts \(\llbracket a_{1}\rrbracket_{1},\llbracket a_{2}\rrbracket_{1},\cdots, \llbracket a_{n}\rrbracket_{1}\) in Section 3.2 is security against Gini-impurity-preserving chosen plaintext attack._

The detailed proof is presented in Appendix C, and the basic idea is inspired from [88]. We take induction on \(n\) to show that data point \((a_{i+1}^{b},y_{i+1})\) affects the constructed binary search trees with the same probability as \(b=0\) and \(b=1\), and then the ciphertexts of data points \((a_{i+1}^{b},y_{i+1})\) also follow the same distribution, i.e.,

\[P\left(\llbracket a_{1}^{0}\rrbracket,\cdots,\llbracket a_{i+1}^{0}\rrbracket|a _{1}^{0},\cdots,a_{i+1}^{0}\right)=P\left(\llbracket a_{1}^{1}\rrbracket, \cdots,\llbracket a_{i+1}^{1}\rrbracket|a_{1}^{1},\cdots,a_{i+1}^{1}\right)\;.\]

## 4 Encrypted Random Forests

For encrypted random forests, we follow the popular client-server protocols [51, 65, 66, 88]. A client encrypts training and testing data, and transfers encrypted data to an honest-but-curious server. The server trains random forests from the encrypted data with the aid of client, and finally returns predictions on encrypted testing data.

#### Encryption for training and testing datasets

Recall training data \(S_{n}=\{(\mathbf{x}_{1},y_{1}),\cdots,(\mathbf{x}_{n},y_{n})\}\) with \(\mathbf{x}_{i}=(x_{i,1},\cdots,x_{i,d})\). The client constructs \(d\) binary search trees \(\mathcal{BT}_{1},\mathcal{BT}_{2},\cdots,\mathcal{BT}_{d}\) according to Algorithm 1 over different dimensional features and labels in \(S_{n}\), where \(\mathcal{BT}_{j}\) is used to encrypt features \(\{x_{1,j},\cdots,x_{n,j}\}\) for \(j\in[d]\).

We take the homomorphic encryption CKKS [42] to encrypt training labels \(y_{1},\cdots,y_{n}\). Each label \(y_{i}\) is encoded with a vector of size \(\tau\) by one-hot method, and we encrypt the vector by homomorphic encryption CKKS with a public key \(k_{pub}\). The ciphertexts \([y_{i}]=[[y_{i,1}],\cdots,[y_{i,\tau}]]\) is given by

\[[\![y_{i,j}]\!]=\left\{\begin{array}{ll}\text{Enc}(k_{pub},1)&\text{for }j =y_{i},\\ \text{Enc}(k_{pub},0)&\text{otherwise}.\end{array}\right.\]

We obtain the final training data \([\![S_{n}]\!]=\{(\llbracket\mathbf{x}_{1}\rrbracket,[\![y_{1}]\!],\cdots,(\llbracket \mathbf{x}_{n}\rrbracket,[\![y_{n}]\!])\}\).

Let \(\tilde{S}_{n^{\prime}}=\{\tilde{\mathbf{x}}_{1},\cdots,\tilde{\mathbf{x}}_{n^{\prime}}\}\) be a testing data with instance \(\tilde{\mathbf{x}}_{i}=(\tilde{x}_{i,1},\cdots,\tilde{x}_{i,d})\). For every plaintext \(\tilde{x}_{i,j}\) with \(i\in[n^{\prime}]\) and \(j\in[d]\), we search a node \(t\) in the binary search tree \(\mathcal{BT}_{j}\), similarly to the node search (Step-I) in Section 3.2, and obtain its ciphertext \([\![\tilde{x}_{i,j}]\!]=[t.cipher,\text{Enc}(k_{pub},i)]\). We have the encrypted testing data \([\![\tilde{S}_{n^{\prime}}]\!]=\{[\![\tilde{\mathbf{x}}_{1}]\!],\cdots,[\![\tilde{ \mathbf{x}}_{n^{\prime}}]\!]\}\).

#### Construction on encrypted random forests

Encrypted random forests consist of individual decision trees \(\mathcal{DT}_{1},\cdots,\mathcal{DT}_{m}\), where each tree \(\mathcal{DT}_{i}\) is constructed as follows. We first take a bootstrap sample \([\![S^{\prime}_{n}]\!]\) from \([\![S_{n}]\!]\), and initialize \(\mathcal{DT}_{i}\) with one node of data \([\![S^{\prime}_{n}]\!]\). We repeat the following procedure recursively for each leaf node, until the number of training samples is smaller than \(\alpha\), or all instances have the same label in the leaf node:

* Select a \(k\)-subset \(\mathsf{B}\) from \(d\) available features randomly without replacement;
* Find the best splitting feature in \(\mathsf{B}\) and position by Gini impurity from the encrypted data;
* Split the current node into left and right children via the best splitting position and feature.

Such construction is essentially similar to original random forests [1], whereas we require a different way to find the best splitting feature and position based on Gini impurity from the encrypted data.

Let \(t\) be the current leaf node for further splitting with the encrypted training data \([\![S^{t}_{n}]\!]\subseteq[\![S_{n}]\!]\), and \([\![s]\!]_{1},\cdots,[\![s]\!]_{d}\) denote all possible splitting features and positions in the scope of the corresponding feature subset \(\mathsf{B}\) from \([\![S^{t}_{n}]\!]\). Here, the information of feature and position can be derived from the corresponding index \(i\in[\![j]\!]\) and subset \(\mathsf{B}\).

For each \(i\in[\![j]\!]\), the server partitions the current encrypted training data \([\![S^{t}_{n}]\!]\) into left and right subsets, i.e., \([\![S^{t}_{n}]\!]_{i}^{t}\) and \([\![S^{t}_{n}]\!]_{i}^{t}\), according to the splitting feature and position \([\![s]\!]_{i}\). Let \(n_{l}\) and \(n_{r}\) be the number of training examples in \([\![S^{t}_{n}]\!]_{i}^{t}\) and \([\![S^{t}_{n}]\!]_{i}^{t}\), respectively, and denote by

\[[\![S^{t}_{n}]\!]_{i}^{t}=\{([\![\mathbf{x}^{t}_{1}]\!],[\![y^{t}_{1}]\!]),\cdots,( [\![\mathbf{x}^{t}_{n_{l}}]\!],[\![y^{t}_{n_{l}}]\!])\}\quad\text{and}\quad[\![S^{ t}_{n}]\!]_{i}^{t}=\{([\![\mathbf{x}^{r}_{1}]\!],[\![y^{r}_{1}]\!]),\cdots,([\![\mathbf{x}^{r}_{n _{r}}]\!],[\![y^{r}_{n_{r}}]\!])\}\;.\]

From Eqn. (1), we have Gini impurity

\[I_{G}([\![S^{t}_{n}]\!],[\![s]\!]_{i})=\Big{[}\frac{n_{l}}{n_{l}+n_{r}}\otimes I _{G}([\![S^{t}_{n}]\!]_{i}^{t})\Big{]}\oplus\Big{[}\frac{n_{r}}{n_{l}+n_{r}} \otimes I_{G}([\![S^{t}_{n}]\!]_{i}^{t})\Big{]}\;, \tag{12}\]

\begin{table}
\begin{tabular}{|c|c c c|c c|c c|c c|c c|} \hline Datasets & \#Inst & \#Feat & Datasets & \#Inst & \#Feat & Datasets & \#Inst & \#Feat & Datasets & \#Inst & \#Feat \\ \hline wdbc & 569 & 30 & adver & 3,279 & 1,558 & allerons & 13,750 & 41 & adult & 48,842 & 14 \\ cancer & 569 & 31 & bibtex & 7,396 & 1,836 & house & 22,784 & 16 & mnist & 70,000 & 780 \\ breast & 699 & 9 & plp@b & 7,797 & 617 & a@a & 32,563 & 123 & miniboone & 72,998 & 51 \\ diabetes & 768 & 8 & pendigits & 10,992 & 16 & amazon & 32,769 & 9 & runwalk & 88,588 & 6 \\ german & 1,000 & 24 & phish & 11,055 & 30 & bank & 45,211 & 17 & covtype & 581,012 & 54 \\ \hline \end{tabular}
\end{table}
Table 2: Datasets

[MISSING_PAGE_FAIL:8]

## 5 Experiment

We conduct experiments on 20 datasets2 as summarized in Table 2. Most datasets have been well-studied in previous random forests. In addition to the original (plaintexts) random forests [1], we compare with six state-of-the-art privacy-preserving random forests in recent years.

Footnote 2: Downloaded from _www.openml.org_

* AnonyRFs: random forests based on anonymization with a top-down greedy search [59];
* DiffPrivRFs: random forests based on differential privacy [93];
* PPD-ERTs: extremely randomized trees from distributed structured data [64];
* PivotRFs: random forests based on a hybrid of threshold partially homomorphic encryption and secure multiparty computation techniques [62];
* MulPRFs: random forests based on the secure multiparty computation [94];
* HELdpRFs: random forests with fully homomorphic encryption and low-degree polynomial approximations [51].

For all random forests, we train 100 individual decision trees, and randomly select \(\lfloor\sqrt{d}\rfloor\) candidate features during node splitting. We set \(\alpha=10\) for datasets of size smaller than 20,000 for our encrypted random forests; otherwise, set \(\alpha=100\), following [95]. For multi-class datasets, we take the one-vs-all method for MulPRFs, since it is limited to binary classification. Other parameters are set according to their respective references, and more details can be found in Appendix D.

**Experimental comparisons**

The performance is evaluated by five trials of 5-fold cross validation, and final prediction accuracies are obtained by averaging over these 25 runs, as summarized in Table 3. It is evident that our encrypted random forests take comparable performance with original random forests [1] on plaintexts, which nicely supports our Theorem 1 on the preservation of minimum Gini impurity in the construction of random forests. Our encrypted random forests are also comparable to MulPRFs if they can obtain results within \(10^{6}\) seconds (about 11.6 days), since MulPRFs are essentially similar to original random forests, yet with different implementation of secure multi-party computation.

As can be seen from Table 3, our random forests take significantly better performance than AnonyRFs and DiffPrivRFs, since the win/tie/loss counts show that our random forests win for most times and never lose. This is because AnonyRFs combine features by anonymization, while DiffPrivRFs add perturbations to features via differential privacy, therefore, both of them cause information lost in privacy process. Our random forests also achieve better performance than PivotRFs, since PivotRFs have to limit trees' depth for random forests due to heavy computations for HE and communications for secure multi-party computation.

Our random forests also outperform PPD-ERTs and HELdpRFs if results are obtained in \(10^{6}\) seconds, since PPD-ERTs adopt completely-random splitting, rather than selecting the minimum Gini impurity, while HELdpRFs take homomorphic encryption on features and employ low-degree polynomial approximation. Those approaches have modified the structures of original random forests.

Figure 2: Comparisons of training running time on different random forests. Notice that the y-axis is in log-scale, and full black columns imply that no result was obtained after running out \(10^{6}\) seconds (about 11.6 days).

#### Running time

All experiments are performed by c++ on the Ubuntu with 256GB main memory (AMD Ryzen Threadripper 3970X). We compare the training running time of our encrypted random forests and others, and the average CPU time (in seconds) is shown in Figure 2.

As expected, original random forests take the least running time over raw datasets without privacy preservation. Our encrypted random forests take larger running time than AnonyRFs and DiffPrivRFs because they are essentially similar to original random forests, yet with some simple modifications or perturbations on features. Our encrypted random forests take better performance and higher security.

Our encrypted random forests take smaller running time than PPD-ERTs, PivotRFs, MulPRFs and HELdpRFs, in particular for large datasets or high-dimensional datasets, where no results are obtained even after running out \(10^{6}\) seconds (almost 11.6 days). Because PPD-ERTs, PivotRFs and MulPRFs require expensive communication cost for multi-parity computation, while PivotRFs and HELdpRFs take heavy computation costs on HE scheme.

#### Security analysis

We present security analysis for the first ciphertext \(\llbracket a\rrbracket_{1}\) in ciphertext vector \(\llbracket a\rrbracket=(\llbracket a\rrbracket_{1},\llbracket a\rrbracket_{2})\), and the second ciphertext \(\llbracket a\rrbracket_{2}\) can be ensured by HE scheme. We compare with four state-of-the-art encryptions: differential privacy [93], anonymization [59], order-preserving scheme [96] and HE scheme [42]. Here, we present results of six datasets and randomly selecting one feature, and trends are similar on other dimensions and datasets. More results can be found in Appendix D.

Figure 3 shows the comparison results, and we take the bitwise leakage matrices to measure the security as in [97]: the more red the area, the higher the security. As expected, HE scheme presents the highest security, yet with heavy computational costs, for example, no results are obtained for datasets of size exceeding 3000 even after running out \(10^{6}\) seconds. It is also observed that our scheme presents higher security than the other three schemes, since those schemes simply present perturbations, compression or preserve the entire order information regardless of learning ingredients. In comparison, our scheme could make a good balance between security and computational cost.

## 6 Conclusion

This work takes one step on data encryption from some crucial ingredients of learning algorithm. We present a new encryption to preserve data's Gini impurity, which plays a crucial role during the construction of random forests. For random forests, we encrypt data features based on our Gini-impurity-preserving scheme, and take the homomorphic encryption scheme CKKS to encrypt data labels. Both theoretically and empirically, we validate the effectiveness, efficiency and security of our proposed method. An interesting work is to exploit other learning ingredients, such as gini index and information gain, for data encryption in the future.

## Acknowledgements

The authors want to thank the reviewers for their helpful comments and suggestions. This research was supported by National Key R&D Program of China (2021ZD0112802), NSFC (61921006, 62376119), CAAI-Huawei MindSpore Open Fund, and Fundamental Research Funds for the Central Universities (2023300246). W. Gao is the corresponding author of this paper.

Figure 3: Security comparisons for different schemes: the more red the area, the higher the security.

## References

* [1] L. Breiman. Random forests. _Machine Learning_, 45(1):5-32, 2001.
* [2] G. Biau and E. Scornet. A random forest guided tour. _Test_, 25(2):197-227, 2016.
* [3] L. Mentch and S. Zhou. Randomization as regularization: A degrees of freedom explanation for random forest success. _Journal of Machine Learning Research_, 21:1-36, 2020.
* [4] M. Fernandez-Delgado, E. Cernadas, S. Barro, and D. Amorim. Do we need hundreds of classifiers to solve real world classification problems? _Journal of Machine Learning Research_, 15(1):3133-3181, 2014.
* [5] D. Cutler, T. Edwards Jr, K. Beard, A. Cutler, K. Hess, J. Gibson, and J. Lawler. Random forests for classification in ecology. _Ecology_, 88(11):2783-2792, 2007.
* [6] Y. Qi. Random forest for bioinformatics. In _Ensemble Machine Learning_, pages 307-323. Springer, 2012.
* [7] J. Shotton, A. Fitzgibbon, M. Cook, T. Sharp, M. Finocchio, R. Moore, A. Kipman, and A. Blake. Real-time human pose recognition in parts from single depth images. _Communications of the ACM_, 56(1):116-124, 2013.
* [8] M. Belgiu and L. Dragut. Random forest in remote sensing: A review of applications and future directions. _ISPRS Journal of Photogrammetry and Remote Sensing_, 114:24-31, 2016.
* [9] A. Criminisi and J. Shotton. _Decision forests for computer vision and medical image analysis_. Springer Science & Business Media, 2013.
* [10] S. Basu, K. Kumbier, J. Brown, and Bin B. Yu. Iterative random forests to discover predictive and stable high-order interactions. _Proceedings of the National Academy of Sciences_, 115(8):1943-1948, 2018.
* [11] M. Denil, D. Matheson, and N. Freitas. Consistency of online random forests. In _Proceedings of the 30th International Conference on Machine Learning_, pages 1256-1264, 2013.
* [12] G. Louppe, L. Wehenkel, A. Sutera, and P. Geurts. Understanding variable importances in forests of randomized trees. _Advances in Neural Information Processing Systems 26_, 2013.
* [13] P. Geurts, D. Ernst, and L. Wehenkel. Extremely randomized trees. _Machine Learning_, 63(1):3-42, 2006.
* [14] B. Lakshminarayanan, D. Roy, and Y. Teh. Mondrian forests: Efficient online random forests. _Advances in Neural Information Processing Systems 27_, pages 3140-3148, 2014.
* [15] X. Li, Y. Wang, S. Basu, K. Kumbier, and B. Yu. A debiased mdi feature importance measure for random forests. _Advances in Neural Information Processing Systems 32_, 2019.
* [16] Y. Lin and Y. Jeon. Random forests and adaptive nearest neighbors. _Journal of the American Statistical Association_, 101(474):578-590, 2006.
* [17] B. Menze, B. Kelm, D. Splitthoff, U. Koethe, and F. Hamprecht. On oblique random forests. In _Proceedings of the Joint European Conference on Machine Learning and Knowledge Discovery in Databases_, pages 453-469, 2011.
* [18] J. Rodriguez, L. Kuncheva, and C. Alonso. Rotation forest: A new classifier ensemble method. _IEEE Transactions on Pattern Analysis and Machine Intelligence_, 28(10):1619-1630, 2006.
* [19] S. Wager, T. Hastie, and B. Efron. Confidence intervals for random forests: The jackknife and the infinitesimal jackknife. _Journal of Machine Learning Research_, 15(1):1625-1651, 2014.
* [20] Z.-H. Zhou and J. Feng. Deep forest. _National Science Review_, 6(1):74-86, 2019.
* [21] W. Gao, F. Xu, and Z.-H. Zhou. Towards convergence rate analysis of random forests for classification. _Artificial Intelligence_, 313:103788, 2022.
* [22] J.-Q. Guo, M.-Z. Teng, W. Gao, and Z.-H. Zhou. Fast provably robust decision trees and boosting. In _Proceedings of the 39th International Conference on Machine Learning_, pages 8127-8144, 2022.
* [23] G. Biau, L. Devroye, and G. Lugosi. Consistency of random forests and other averaging classifiers. _Journal of Machine Learning Research_, 9:2015-2033, 2008.
* [24] G. Biau. Analysis of a random forests model. _Journal of Machine Learning Research_, 13(1):1063-1095, 2012.

* [25] E. Scornet, G. Biau, and J. Vert. Consistency of random forests. _Annals of Statistics_, 43(4):1716-1741, 2015.
* [26] J. Mourtada, S. Gaiffas, and E. Scornet. Universal consistency and minimax rates for online mondrian forests. _Advances in Neural Information Processing Systems 30_, pages 3758-3767, 2017.
* [27] C. Tang, D. Garreau, and U. von Luxburg. When do random forests fail. _Advances in Neural Information Processing Systems 31_, pages 2987-2997, 2018.
* [28] Z.-H. Zhou. _Ensemble Methods: Foundations and Algorithms_. CRC Press, 2012.
* [29] C. Dwork. Differential privacy. In _Proceedings of the 33rd International Colloquium on Automata, Languages, and Programming_, pages 1-12, 2006.
* [30] A. Patil and S. Singh. Differential private random forest. In _Proceedings of the 3rd International Conference on Advances in Computing, Communications and Informatics_, pages 2623-2630, 2014.
* [31] X. Li, B. Qin, Y.-Y. Luo, and D. Zheng. A differential privacy budget allocation algorithm based on out-of-bag estimation in random forest. _Mathematics_, 10(22):4338, 2022.
* [32] A. Blum, C. Dwork, F. McSherry, and K. Nissim. Practical privacy: The sulq framework. In _Proceedings of the 24th ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems_, pages 128-138, 2005.
* [33] A. Friedman and A. Schuster. Data mining with differential privacy. In _Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining_, pages 493-502, 2010.
* [34] S. Fletcher and M. Islam. Decision tree classification with differential privacy: A survey. _ACM Computing Surveys_, 52(4):1-33, 2019.
* [35] S. Samet and A. Miri. Privacy preserving ID3 using gini index over horizontally partitioned data. In _Proceedings of the 6th International Conference on Computer Systems and Applications_, pages 645-651, 2008.
* [36] J. Vaidya, C. Clifton, M. Kantarcioglu, and A. Patterson. Privacy-preserving decision trees over vertically partitioned data. _ACM Transactions on Knowledge Discovery from Data_, 2(3):1-27, 2008.
* [37] S. Hoogh, B. Schoenmakers, and P. Chen. Practical secure decision tree learning in a tele-treatment application. In _Proceedings of the 18th International Conference on Financial Cryptography and Data Security_, pages 179-194, 2014.
* [38] M. Joye and F. Salehi. Private yet efficient decision tree evaluation. In _Proceedings of the 32nd Annual IFIP Conference on Data and Applications Security and Privacy_, pages 243-259, 2018.
* [39] Y. Li, Z. Jiang, L. Yao, X. Wang, S. Yiu, and Z. Huang. Outsourced privacy-preserving C4.5 decision tree algorithm over horizontally and vertically partitioned dataset among multiple parties. _Cluster Computing_, 22(1):1581-1593, 2019.
* [40] C. Gentry. Fully homomorphic encryption using ideal lattices. In _Proceedings of the 41st Annual ACM Symposium on Theory of Computing_, pages 169-178, 2009.
* [41] L. Ducas and D. Micciancio. Fhew: Bootstrapping homomorphic encryption in less than a second. In _Proceedings of the 34th Annual International Conference on the Theory and Applications of Cryptographic Techniques_, pages 617-640, 2015.
* [42] J. Cheon, A. Kim, M. Kim, and Y. Song. Homomorphic encryption for arithmetic of approximate numbers. In _Proceedings of the 23rd International Conference on Theory and Application of Cryptology and Information Security_, pages 409-437, 2017.
* [43] I. Chillotti, N. Gama, M. Georgieva, and M. Izabachene. Tfhe: Fast fully homomorphic encryption over the torus. _Journal of Cryptology_, 33(1):34-91, 2020.
* [44] R. Gilad-Bachrach, N. Dowlin, K. Laine, K. Lauter, M. Naehrig, and J. Wernsing. Cryptonets: Applying neural networks to encrypted data with high throughput and accuracy. In _Proceedings of the 33rd International Conference on Machine Learning_, pages 201-210, 2016.
* [45] Q. Lou, W. Lu, C. Hong, and L. Jiang. Falcon: Fast spectral inference on encrypted data. _Advances in Neural Information Processing Systems 33_, pages 2364-2374, 2020.

* [46] Z. Ghodsi, N. Jha, B. Reagen, and S. Garg. Circa: Stochastic ReLUs for private deep learning. _Advances in Neural Information Processing Systems 34_, pages 2241-2252, 2021.
* [47] X. Li, R. Dowsley, and M. Cock. Privacy-preserving feature selection with secure multiparty computation. In _Proceedings of the 38th International Conference on Machine Learning_, pages 6326-6336, 2021.
* [48] A. Aloufi, P. Hu, H. Wong, and S. Chow. Blindfolded evaluation of random forests with multi-key homomorphic encryption. _IEEE Transactions on Dependable and Secure Computing_, 18(4):1821-1835, 2019.
* [49] J. Li, X. Kuang, S. Lin, X. Ma, and Y. Tang. Privacy preservation for machine learning training and classification based on homomorphic encryption schemes. _Information Sciences_, 526:166-179, 2020.
* [50] L. Pulido-Gaytan, A. Tchernykh, J. Cortes-Mendoza, M. Babenko, and G. Radchenko. A survey on privacy-preserving machine learning with fully homomorphic encryption. In _Proceedings of the 7th Latin American Conference on High Performance Computing_, pages 115-129, 2021.
* [51] A. Akavia, M. Leibovich, Y. Resheff, R. Ron, M. Shahar, and M. Vald. Privacy-preserving decision trees training and prediction. _ACM Transactions on Privacy and Security_, 25(3):1-30, 2022.
* [52] K. Cong, D. Das, J. Park, and H. Pereira. Sortinghat: Efficient private decision tree evaluation via homomorphic encryption and transciphering. In _Proceedings of the 29th ACM SIGSAC Conference on Computer and Communications Security_, pages 563-577, 2022.
* [53] J. Brickell, D. Porter, V. Shmatikov, and E. Witchel. Privacy-preserving remote diagnostics. In _Proceedings of the 14th ACM SIGSAC Conference on Computer and Communications Security_, pages 498-507, 2007.
* [54] M. Barni, P. Failla, V. Kolesnikov, R. Lazzeretti, A. Sadeghi, and T. Schneider. Secure evaluation of private linear branching programs with medical applications. In _Proceedings of the 17th European Symposium on Research in Computer Security_, pages 424-439, 2009.
* [55] R. Tai, J. Ma, Y. Zhao, and S. Chow. Privacy-preserving decision trees evaluation via linear functions. In _Proceedings of the 22nd European Symposium on Research in Computer Security_, pages 494-512, 2017.
* [56] A. Tueno, F. Kerschbaum, and S. Katzenbeisser. Private evaluation of decision trees using sublinear cost. _Proceedings on Privacy Enhancing Technologies_, 2019(1):266-286, 2019.
* [57] A. Kiss, M. Naderpour, J. Liu, N. Asokan, and T. Schneider. Sok: Modular and efficient private decision tree evaluation. In _Proceedings of Privacy Enhancing Technologies_, pages 187-208, 2019.
* [58] K. Sarpatwar, N. Ratha, K. Nandakumar, K. Shanmugam, J. Rayfield, S. Pankanti, and R. Vaculin. Privacy enhanced decision tree inference. In _Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_, pages 154-159, 2020.
* [59] K. LeFevre, D. DeWitt, and R. Ramakrishnan. Mondrian multidimensional k-anonymity. In _Proceedings of the 22nd International Conference on Data Engineering_, pages 25-25, 2006.
* [60] L. Sweeney. k-anonymity: A model for protecting privacy. _International Journal of Uncertainty, Fuzziness and Knowledge-based Systems_, 10(05):557-570, 2002.
* [61] W. Du and Z. Zhan. Building decision tree classifier on private data. In _Proceedings of the 14th IEEE International Conference on Privacy, Security and Data Mining_, pages 1-8, 2002.
* [62] Y. Wu, S. Cai, X. Xiao, G. Chen, and B. Ooi. Privacy preserving vertical federated learning for tree-based models. _CoRR/abstract_, 2008.06170, 2020.
* [63] K. Hamada, D. Ikarashi, R. Kikuchi, and K. Chida. Efficient decision tree training with new data structure for secure multi-party computation. _CoRR/abstract_, 2112.12906, 2021.
* [64] A. Aminifar, F. Rabbi, K. Pun, and Y. Lamo. Privacy preserving distributed extremely randomized trees. In _Proceedings of the 36th Annual ACM Symposium on Applied Computing_, pages 1102-1105, 2021.
* [65] M. De Cock, R. Dowsley, C. Horst, R. Katti, A. Nascimento, W. Poon, and S. Truex. Efficient and private scoring of decision trees, support vector machines and logistic regression modelsbased on pre-computation. _IEEE Transactions on Dependable and Secure Computing_, 16(2):217-230, 2017.
* [66] A. Tueno, Y. Boev, and F. Kerschbaum. Non-interactive private decision tree evaluation. In _Proceedings of the 34th Annual IFIP Conference on Data and Applications Security and Privacy_, pages 174-194, 2020.
* [67] T. ElGamal. A public key cryptosystem and a signature scheme based on discrete logarithms. _IEEE Transactions on Information Theory_, 31:469-472, 1985.
* [68] P. Paillier. Public-key cryptosystems based on composite degree residuosity classes. In _Proceedings of the 18th Annual International Conference on the Theory and Applications of Cryptographic Techniques_, pages 223-238, 1999.
* [69] K. Han, S. Hong, J. Cheon, and D. Park. Logistic regression on homomorphic encrypted data at scale. In _Proceedings of the 33rd AAAI Conference on Artificial Intelligence_, pages 9466-9471, 2019.
* A modular approach to the application of homomorphic encryption. In _Proceedings of the 34th AAAI Conference on Artificial Intelligence_, pages 3866-3873, 2020.
* [71] A. Sanyal, M. Kusner, A. Gascon, and V. Kanade. TAPAS: Tricks to accelerate (encrypted) prediction as a service. In _Proceedings of the 35th International Conference on Machine Learning_, pages 4497-4506, 2018.
* [72] Q. Lou, B. Feng, G. Fox, and L. Jiang. Glyph: Fast and accurately training deep neural networks on encrypted data. _Advances in Neural Information Processing Systems 33_, pages 9193-9202, 2020.
* [73] Q. Lou and L. Jiang. HEMET: A homomorphic-encryption-friendly privacy-preserving mobile neural network architecture. In _Proceedings of the 38th International Conference on Machine Learning_, pages 7102-7110, 2021.
* [74] S. Pentyala, R. Dowsley, and M. Cock. Privacy-preserving video classification with convolutional neural networks. In _Proceedings of the 38th International Conference on Machine Learning_, pages 8487-8499, 2021.
* [75] E. Lee, J. Lee, J. Lee, Y. Kim, Y. Kim, J. No, and W. Choi. Low-complexity deep convolutional neural networks on fully homomorphic encryption using multiplexed parallel convolutions. In _Proceedings of the 39th International Conference on Machine Learning_, pages 12403-12422, 2022.
* [76] J. Wang, Q. Tang, A. Arriaga, and P. Ryan. Novel collaborative filtering recommender friendly to privacy protection. In _Proceedings of the 28th International Joint Conference on Artificial Intelligence_, pages 4809-4815, 2019.
* [77] AC. Yao. Protocols for secure computations. In _Proceedings of the 23rd Annual Symposium on Foundations of Computer Science_, pages 160-164, 1982.
* [78] S. Sayyad. Privacy preserving deep learning using secure multiparty computation. In _Proceedings of the 2nd International Conference on Inventive Research in Computing Applications_, pages 139-142, 2020.
* [79] R. Shokri and V. Shmatikov. Privacy preserving deep learning. In _Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security_, pages 1310-1321, 2015.
* [80] K. Bonawitz, V. Ivanov, B. Kreuter, A. Marcedone, HB. McMahan, S. Patel, D. Ramage, A. Segal, and K. Seth. Practical secure aggregation for privacy-preserving machine learning. In _proceedings of the 24th ACM SIGSAC Conference on Computer and Communications Security_, pages 1175-1191.
* [81] J. Vaidya and C. Clifton. Privacy-preserving k-means clustering over vertically partitioned data. In _Proceedings of the 9th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining_, pages 206-215, 2003.
* [82] X. Yi and YC. Zhang. Equally contributory privacy preserving k-means clustering over vertically partitioned data. _Information Systems_, 38(1):97-107, 2013.
* [83] Y. Fan, J. Bai, X. Lei, W. Lin, Q. Hu, G. Wu, J. Guo, and G. Tan. PPMCK: Privacy-preserving multi-party computing for k-means clustering. _Parallel and Distributed Computing_, 154:54-63, 2021.

* [84] C. Dwork. Differential privacy: A survey of results. In _Proceedings of the 5th International Conference on Theory and Applications of Models of Computation_, pages 1-19, 2008.
* [85] M. Abadi, A. Chu, I. Goodfellow, HB. McMahan, I. Mironov, K. Talwar, and L. Zhang. Deep learning with differential privacy. In _Proceedings of the 23rd ACM SIGSAC Conference on Computer and Communications Security_, pages 308-318, 2016.
* [86] T. Ha, TK. Dang, TT. Dang, TA. Truong, and MT. Nguyen. Differential privacy in deep learning: An overview. In _Proceedings of the 12rd International Conference on Advanced Computing and Applications_, pages 97-102, 2019.
* [87] B. Ghazi, N. Golowich, R. Kumar, P. Manurangsi, and CY. Zhang. Deep learning with label differential privacy. _Advances in Neural Information Processing Systems 34_, pages 27131-27145, 2021.
* [88] R. Popa, F. Li, and N. Zeldovich. An ideal-security protocol for order-preserving encoding. In _Proceedings of the 34th IEEE Conference on Symposium on Security and Privacy_, pages 463-477, 2013.
* [89] K. Florian. Frequency hiding order preserving encryption. In _Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security_, pages 656-667, 2015.
* [90] M. Islam, M. Kuzu, and M. Kantarcioglu. Access pattern disclosure on searchable encryption: Ramification, attack and mitigationjq. In _Proceedings of the 19th Annual Network and Distributed System Security Symposium_, page 12, 2012.
* [91] S. Goldwasser and S. Micali. Probabilistic encryption how to play mental poker keeping secret all partial information. In _Proceedings of the 14th Annual ACM Conference on Symposium on Theory of Computing_, pages 365-377, 1982.
* [92] I. Chillotti, N. Gama, M. Georgieva, and M. Izabachene. Faster fully homomorphic encryption: Bootstrapping in less than 0.1 seconds. In _Proceedings of the 22nd International Conference on the Theory and Application of Cryptology and Information Security_, pages 3-33, 2016.
* [93] N. Holohan, S. Braghin, P. Mac Aonghusa, and K. Levacher. Diffprivlib: The IBM differential privacy library. _CoRR/abstract_, 1907.02444, 2019.
* [94] K. Marcel. MP-SPDZ: A versatile framework for multi-party computation. In _Proceedings of the 27th ACM SIGSAC Conference on Computer and Communications Security_, pages 1575-1590, 2020.
* [95] P. Probst, M. Wright, and A. Boulesteix. Hyperparameters and tuning strategies for random forest. _Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery_, 9(3):1301, 2019.
* [96] R. Agrawal, J. Kiernan, R. Srikant, and Y. Xu. Order preserving encryption for numeric data. In _Proceedings of the ACM SIGMOD International Conference on Management of Data_, pages 563-574, 2004.
* [97] C. Roy, B. Ding, S. Jha, W. Liu, and J. Zhou. Strengthening order preserving encryption with differential privacy. In _Proceedings of the 29th ACM SIGSAC Conference on Computer and Communications Security_, pages 2519-2533, 2022.
* [98] M. Tschantz, S. Sen, and A. Datta. Sok: Differential privacy as a causal property. In _Proceedings of the 41st IEEE Conference on Symposium on Security and Privacy_, pages 354-371, 2020.
* [99] B. Fuller, M. Varia, A. Yerukhimovich, E. Shen, A. Hamlin, V. Gadepally, R. Shay, J. Mitchell, and R. Cunningham. Sok: Cryptographically protected database search. In _Proceedings of the 38th IEEE Conference on Symposium on Security and Privacy_, pages 172-191, 2017.

## Appendix A Detailed Decryption for Our Encryption Method

### Decryption for Our Encryption in Section 3.1

We present the decryption for ciphertext \(\llbracket a_{i}\rrbracket=(\llbracket a_{i}\rrbracket_{1},\llbracket a_{i} \rrbracket_{2})\) in Eqn. (5) by the following steps:

* Find the partition \(\mathcal{I}_{j}\) according to \(\llbracket a_{i}\rrbracket_{1}\);
* Decrypt ciphertext \(\llbracket a_{i}\rrbracket_{2}\) by the CKKS secret key \(k_{\text{sec}}\), and get index \(\tau=\text{Dec}(k_{\text{sec}},\llbracket a_{i}\rrbracket_{2})\) in partition \(\mathcal{I}_{j}\).
* Obtain the plaintext \(a_{i}\) as the \(\tau\)-th sample in partition \(\mathcal{I}_{j}\).

### Decryption for Our Encryption of Binary Search Tree in Section 3.2

We decrypt a ciphertext \(\llbracket a_{i}\rrbracket=(\llbracket a_{i}\rrbracket_{1},\llbracket a_{i} \rrbracket_{2})\) based on binary search tree \(\mathcal{BT}\) (in Section 3.2) and the CKKS secret key \(k_{\text{sec}}\) by the following two steps, and Algorithm 4 presents the details of decryption:

* Let \(t\) be a node pointer with the initialization of the root of binary search tree \(\mathcal{BT}\). We then search a path downward in \(\mathcal{BT}\) by comparing with \(\llbracket a_{i}\rrbracket_{1}\). The search continues to its left child if \(\llbracket a_{i}\rrbracket_{1}<t.\mathit{cipher}_{1}\) and update \(t=t.\mathit{left}\); the search continues to its right child if \(\llbracket a_{i}\rrbracket_{1}>t.\mathit{cipher}_{1}\) and update \(t=t.\mathit{right}\) until \(\llbracket a_{i}\rrbracket_{1}=t.\mathit{cipher}_{1}\).
* Decrypt ciphertext \(\llbracket a_{i}\rrbracket_{2}\) by the CKKS secret key \(k_{\text{sec}}\), and get index \(\tau=\text{Dec}(k_{\text{sec}},\llbracket a_{i}\rrbracket_{2})\) in \(t.\mathit{samples}\). Then we use the index \(\tau\) to get the plaintext \(a_{i}=t.\mathit{samples}[\tau]\).

### Formal Definition of Our Gini-impurity-preserving Encryption

We present a formal definition of our Gini-impurity preserving encryption as follows:

* \(S\leftarrow\text{KeyGen}(t_{\text{max}})\): Generate the secret state \(S\) by initializing binary search tree \(\mathcal{BT}=\emptyset\), and a security parameter \(c_{\text{max}}\), which is a random number with \(c_{\text{max}}>n\). We maintain an interval \([t_{\text{min}},t_{\text{max}}]\) in each secret state \(S\) with \(t_{\text{min}}=0\) and \(t_{\text{max}}=c_{\text{max}}\) in the initial stage, so as to keep the order of ciphertexts \(c_{1},c_{2},\cdots,c_{s}\) in Eqn. (5). In this way, the ciphertexts are random numbers with semi-order of plaintexts, and we have different ciphertext even for the same plaintexts.
* \(S^{\prime},\llbracket a_{i}\rrbracket\leftarrow\text{Encrypt}(S,a_{i})\): Encrypt \(a_{i}\) and update the secret state to \(S^{\prime}\) as for receiving a sample \((a_{i},y_{i})\) as follows:
* Search a node for sample \((a_{i},y_{i})\) in binary search tree \(\mathcal{BT}\) as shown in Algorithm 1. Let \(t\) be a node pointer with the initialization of the root of \(\mathcal{BT}\). We search a path downward in \(\mathcal{BT}\) by comparing with \(a_{i}\). The search will terminate when \(t\) is a leaf or an empty node.
* Update the binary search tree \(\mathcal{BT}\). We directly append the example \((a_{i},y_{i})\) into \(t.\mathit{samples}\) if \(y_{i}=y_{j}\) for every \((a_{j},y_{j})\in t.\mathit{samples}\); otherwise, it is necessary to split the node \(t\) according to \(a_{i}\). Algorithm 2 presents the detailed descriptions on the splitting of node \(t\).
* Compute ciphertext \(\llbracket a_{i}\rrbracket\) and update the state from \(S\) to \(S^{\prime}\). Append example \((a_{i},y_{i})\) into \(t.\mathit{samples}\) and update \(t.\mathit{cipher}_{2}=\text{Enc}(k_{\text{pub}},|t.\mathit{samples}|)\). We then compute the ciphertext \(\llbracket a_{i}\rrbracket=(t.\mathit{cipher}_{1},t.\mathit{cipher}_{2})\), and update the state from \(S\) to \(S^{\prime}\) through our \(\mathcal{BT}\).
* \(a_{i}\leftarrow\) Decrypt(\(S^{\prime}\), \(\llbracket a_{i}\rrbracket\)): Solve plaintext \(a_{i}\) for ciphertext \(\llbracket a_{i}\rrbracket\) based on state \(S^{\prime}\) with binary search tree \(\mathcal{B}\mathcal{T}\) and the CKKS secret key \(k_{\text{sec}}\) as follows:
* Let \(t\) be a node pointer with initialing the root of binary search tree \(\mathcal{B}\mathcal{T}\). We then search a path downward in binary search tree \(\mathcal{B}\mathcal{T}\) by comparing with \(\llbracket a_{i}\rrbracket_{1}\). The search continues to its left child if \(\llbracket a_{i}\rrbracket_{1}<t.cipher_{1}\) and update \(t=t.\textit{left}\), the search continues to its right child if \(\llbracket a_{i}\rrbracket_{1}>t.cipher_{1}\) and update \(t=t.\textit{right}\) until \(\llbracket a_{i}\rrbracket_{1}=t.cipher_{1}\).
* Decrypt ciphertext \(\llbracket a_{i}\rrbracket_{2}\) by CKKS secret key \(k_{\text{sec}}\), and get index \(\tau=\text{Dec}(k_{\text{sec}},\llbracket a_{i}\rrbracket_{2})\) in \(t.\textit{samples}\). Then we use the index \(\tau\) to get the plaintext \(a_{i}=t.\textit{samples}[\tau]\).

## Appendix B Proof of Theorem 1

**Lemma 4**.: _For dataset \(A=\{(a_{1},y_{1}),\cdots,(a_{n},y_{n})\}\), let \(\mathcal{I}_{1},\mathcal{I}_{2},\cdots,\mathcal{I}_{s}\) be the corresponding partitions as defined by Eqn. (4). There exists a splitting point \(a^{*}\) such that \(I_{G}(A,a^{*})=I_{G}^{*}(A)\) and_

\[a^{*}\in\bigcup_{i\in[s-1]}\left\{\max\{a_{k}\colon(a_{k},y_{k})\in\mathcal{I} _{i}\}/2+\min\{a_{k}\colon(a_{k},y_{k})\in\mathcal{I}_{i+1}\}/2\right\}\;,\]

_where \(I_{G}(A,a^{*})\) and \(I_{G}^{*}(A)\) are defined by Eqns. (1) and (2), respectively._

Proof.: Without loss of generality, we assume that \(a_{1},a_{2},\cdots,a_{n}\) are distinct elements. Our goal is to solve the optimal splitting point \(a^{*}\in\arg\min_{a\in\mathbb{R}}\{I_{G}(A,a)\}\), and we begin with some notations used in our proof. For every label \(j\in[\tau]\), we denote by

\[\nu_{j}=\left|\{i\in[n]\colon y_{i}=j\}\right|\;,\]

i.e., the number of the label \(j\) in dataset \(A\). Let \(a\) be a splitting point, which splits \(A\) into left and right datasets \(A_{a}^{l}\) and \(A_{a}^{r}\), that is,

\[A_{a}^{l} = \{(a_{i},y_{i})\colon a_{i}\leq a,(a_{i},y_{i})\in A\}\;,\] \[A_{a}^{r} = \{(a_{i},y_{i})\colon a_{i}>a,(a_{i},y_{i})\in A\}\;.\]

For any given \(a\in\mathbb{R}\) and \(j\in[\tau]\), we further denote by

\[\nu_{j}^{l}=\left|\{i\in[n]\colon y_{i}=j,a_{i}\leq a\}\right|\;,\]

i.e., the number of label \(j\) in subsets \(A_{a}^{l}\). This follows that

\[I_{G}(A,a)=w_{l}-w_{l}\sum_{j\in[\tau]}\frac{(\nu_{j}^{l})^{2}}{|A_{a}^{l}|^{ 2}}+w_{r}-w_{r}\sum_{j\in[\tau]}\frac{(\nu_{j}-\nu_{j}^{l})^{2}}{(n-|A_{a}^{l }|)^{2}}\;,\]

where \(w_{l}=|A_{a}^{l}|/n\), and \(w_{r}=1-w_{l}\). In the following, we will explore the monotonicity of function \(I_{G}(A,a)\) when

\[a \geq \max\{a_{k}:(a_{k},y_{k})\in\mathcal{I}_{i-1}\}/2+\min\{a_{k}:(a _{k},y_{k})\in\mathcal{I}_{i}\}/2\] \[a \leq \max\{a_{k}:(a_{k},y_{k})\in\mathcal{I}_{i}\}/2+\min\{a_{k}:(a_ {k},y_{k})\in\mathcal{I}_{i+1}\}/2\;,\]

for \(i=2,3,\cdots,s-1\). It is easy to observe that \(\nu_{j}\) and \(\nu_{j}^{l}\) keep constants except for \(\nu_{j_{*}}^{l}\), where \(j_{*}\) denotes the label of instances in \(\mathcal{I}_{i}\). It remains to discuss the variable \(\nu_{j_{*}}^{l}\), and we have 

[MISSING_PAGE_EMPTY:18]

* We now consider the second case \[\sum_{j\in[\tau],j\neq j_{*}}\left(\left(\frac{\nu_{j}^{l}}{w_{l}}\right)^{2}- \left(\frac{\nu_{j}-\nu_{j}^{l}}{w_{r}}\right)^{2}\right)<0\;,\] and this follows that \[\sum_{j\in[\tau]}\left(\left(\frac{\nu_{j}^{l}}{w_{l}}\right)^{2}- \left(\frac{\nu_{j}-\nu_{j}^{l}}{w_{r}}\right)^{2}\right)<\left(\frac{\nu_{j_{ *}}^{l}}{w_{l}}\right)^{2}-\left(\frac{\nu_{j_{*}}-\nu_{j_{*}}^{l}}{w_{r}} \right)^{2}\] \[= \left(\frac{\nu_{j_{*}}^{l}}{w_{l}}+\frac{\nu_{j_{*}}-\nu_{j_{*}}^ {l}}{w_{r}}\right)\left(\frac{\nu_{j_{*}}^{l}}{w_{l}}-\frac{\nu_{j_{*}}-\nu_{j _{*}}^{l}}{w_{r}}\right)<2n\left(\frac{\nu_{j_{*}}^{l}}{w_{l}}-\frac{\nu_{j_{* }}-\nu_{j_{*}}^{l}}{w_{r}}\right)\;.\] We have \[n^{2}\frac{\partial I_{G}(A,a)}{\partial\nu_{j_{*}}^{l}} = \frac{1}{n}\sum\nolimits_{j\in[\tau]}\left(\left(\frac{\nu_{j}^{l }}{w_{l}}\right)^{2}-\left(\frac{\nu_{j}-\nu_{j}^{l}}{w_{r}}\right)^{2}\right) +2\left(\frac{\nu_{j_{*}}-\nu_{j_{*}}^{l}}{w_{r}}-\frac{\nu_{j_{*}}^{l}}{w_{l}}\right)\] \[< 2\left(\frac{\nu_{j_{*}}^{l}}{w_{l}}-\frac{\nu_{j_{*}}-\nu_{j_{* }}^{l}}{w_{r}}\right)+2\left(\frac{\nu_{j_{*}}-\nu_{j_{*}}^{l}}{w_{r}}-\frac{ \nu_{j_{*}}^{l}}{w_{l}}\right)=0\;,\] which proves the decreasing function of \(I_{G}(A,a)\).

In a summary, we prove the piecewise monotonicity of \(I_{G}(A,a)\) for

\[a \geq \max\{a_{k}\colon(a_{k},y_{k})\in\mathcal{I}_{i-1}\}/2+\min\{a_{k }\colon(a_{k},y_{k})\in\mathcal{I}_{i}\}/2\] \[a \leq \max\{a_{k}\colon(a_{k},y_{k})\in\mathcal{I}_{i}\}/2+\min\{a_{k }:(a_{k},y_{k})\in\mathcal{I}_{i+1}\}/2\;,\]

with \(i=2,3,\cdots,s-1\). Moreover, it is easy to observe the monotonicity of \(I_{G}(A,a)\) from \(\nu_{j}^{l}=0(j\neq j_{*})\) when

\[a\in\left(-\infty,\left(\max\{a_{k}:(a_{k},y_{k})\in\mathcal{I}_{1}\}+\min\{a_ {k}:(a_{k},y_{k})\in\mathcal{I}_{2}\}\right)/2\right]\;;\]

and from \(\nu_{j}-\nu_{j}^{l}=0\;(j\neq j_{*})\) when

\[a\in\left[\left(\max\{a_{k}:(a_{k},y_{k})\in\mathcal{I}_{s-1}\}+\min\{a_{k}:(a _{k},y_{k})\in\mathcal{I}_{s}\}\right)/2,+\infty\right)\;.\]

It is not necessary to consider the splitting point \(a^{*}>\max\{a_{k}:(a_{k},y_{k})\in\mathcal{I}_{s}\}\) with \(|A_{a}^{r}|=0\), as well as the splitting point \(a^{*}<\min\{a_{k}:(a_{k},y_{k})\in\mathcal{I}_{1}\}\) with \(|A_{a}^{l}|=0\), i.e., without splitting dataset \(A\). This completes the proof. 

**Proof of Theorem 1**

According to Lemma 6, we could find an optimal splitting point \(a^{*}\) such that

\[a^{*}\in\bigcup_{i\in[s-1]}\left\{\frac{\max\{a_{k}:(a_{k},y_{k})\in\mathcal{I }_{i}\}+\min\{a_{k}:(a_{k},y_{k})\in\mathcal{I}_{i+1}\}}{2}\right\}\;.\]

It is easy to observe that, for \(i\in[s-1]\)

\[I_{G}(A,(\max\{a_{k}:(a_{k},y_{k})\in\mathcal{I}_{i}\}+\min\{a_{k}:(a_{k},y_{k })\in\mathcal{I}_{i+1}\}/2)=I_{G}(A,(c_{i}+c_{i+1})/2)\;,\]

where \(c_{i}\) is the identical ciphertext for those elements in \(\in\mathcal{I}_{i}\), and we complete the proof. 

Based on Theorem 1, our encryption with binary search trees (Algorithm 1) can also preserve the minimum Gini impurity over encrypted data, which can be shown by the following theorem:

**Theorem 5**.: _We have \(I_{G}^{*}(A)=I_{G}^{*}(\hat{A})\), for re-sort dataset \(A\) by Eqn. (3) and for the corresponding encrypted dataset \(\hat{A}=\{([\![a_{(1)}]\!]_{1},y_{(1)}),\cdots,([\![a_{(n)}]\!]_{1},y_{(n)})\}\) from Algorithm 1._Proof.: Our constructed binary search tree \(\mathcal{BT}\) (Algorithm 1) maintains several samples on a node. For each node \(t\), we have \(t.\textit{cipher}_{1}<t.\textit{right}.\textit{cipher}_{1}\) and \(t.\textit{cipher}_{1}>t.\textit{left}.\textit{cipher}_{1}\). In this way, we can obtain a monotone increasing sequence \(\mathcal{I}_{1},\mathcal{I}_{2},\cdots,\mathcal{I}_{s}\) by inorder traversing the built Tree \(\mathcal{BT}\) in Algorithm 1. Each \(\mathcal{I}_{i}\) for \(j\in[s]\) contains several samples as follows:

\[\mathcal{I}_{1} = \big{\{}(a_{(1)},y_{(1)}),\cdots,(a_{(k_{1})},y_{(k_{1})})\big{\}}\] \[\mathcal{I}_{2} = \big{\{}(a_{(k_{1}+1)},y_{(k_{1}+1)}),\cdots,(a_{(k_{2})},y_{(k_{ 2})})\big{\}}\] \[\cdots\] \[\mathcal{I}_{s} = \big{\{}(a_{(k_{s-1}+1)},y_{(k_{s-1}+1)}),\cdots,(a_{(n)},y_{(n)} )\big{\}}\,\]

where \(a_{(i^{\prime})}<a_{(j^{\prime})}\) for \((a_{(i^{\prime})},y_{(i^{\prime})^{\prime}})\in\mathcal{I}_{i},(a_{(j^{\prime })^{\prime}},y_{(j^{\prime})^{\prime}})\in\mathcal{I}_{j}\) and \(i<j\).

For each \(\mathcal{I}_{i}\), if there is only one identical label, i.e., \(y_{(i)}=y_{(i^{\prime})}\) for every \((a_{(i)},y_{(i)}),(a_{(i^{\prime})},y_{(i^{\prime})})\in\mathcal{I}_{j}\), then we have \(I^{*}_{G}(A)=I^{*}_{G}(\hat{A})\) from Theorem 1. On the other hand, if the values are the same for all samples in \(\mathcal{I}_{j}\) (\(j\in[s]\)), i.e., \(a_{(i)}=a_{(i^{\prime})}\) for every \((a_{(i)},y_{(i)}),(a_{(i^{\prime})},y_{(i^{\prime})})\in\mathcal{I}_{j}\), then this splitting value is preserved without changing the minimum Gini-impurity of random forests. Hence, we also have \(I^{*}_{G}(A)=I^{*}_{G}(\hat{A})\), and this completes the proof. 

## Appendix C Proof of Theorem 3

Given two sequences of distinct plaintext \(A^{0}=\{a^{0}_{1},a^{0}_{2},\cdots,a^{0}_{n}\}\) and \(A^{1}=\{a^{1}_{1},a^{1}_{2},\cdots,a^{1}_{n}\}\), their corresponding labels are randomly set as follows:

* Sort \(A^{b}=\{a^{b}_{(1)},a^{b}_{(2)},\cdots,a^{b}_{(n)}\}\) in ascending order, i.e., \(a^{b}_{(1)}<a^{b}_{(2)}<\cdots<a^{b}_{(n)}\) for \(b\in\{0,1\}\).
* Set the corresponding labels \(\{y_{(1)},y_{(2)},\cdots,y_{(n)}\}\) randomly and independently from a uniform distribution on \([\tau]\).

Then, we have

**Lemma 6**.: _For \(a^{b}_{1}<a^{b}_{2}<\cdots<a^{b}_{n}\) with \(b=\{0,1\}\), we have the same Gini impurity for two sequences \(A^{0}=\{(a^{0}_{1},y_{1}),(a^{0}_{2},y_{2}),\cdots,(a^{0}_{n},y_{n})\}\) and \(A^{1}=\{(a^{1}_{1},y_{1}),(a^{1}_{2},y_{2}),\cdots,(a^{1}_{n},y_{n})\}\)._

Proof.: Let \(a^{b}_{i}\) be a splitting point for \(b\in\{0,1\}\) and \(i\in[n]\), and we split \(A^{b}\) into left and right datasets \(A^{l,b}_{a^{b}_{i}}\) and \(A^{r,b}_{a^{b}_{i}}\) according to \(a^{b}_{i}\), that is,

\[A^{l,b}_{a^{b}_{i}}=\{(a^{b}_{1},y_{1}),(a^{b}_{2},y_{2}),\cdots,(a^{b}_{i},y_ {i})\}\ \text{ and }\ A^{r,b}_{a^{b}_{i}}=\{(a^{b}_{i+1},y_{i+1}),(a^{b}_{i+2},y_ {i+2}),\cdots,(a^{b}_{n},y_{n})\}\.\]

For \(j\in[\tau]\), denote by \(\nu^{l,b}_{j}\) and \(\nu^{r,b}_{j}\) the cardinalities of subsets \(A^{l,b}_{a^{b}_{i}}\) and \(A^{r,b}_{a^{b}_{i}}\) with label \(j\), respectively. Then, the Gini impurity of dataset \(A^{b}\) and splitting point \(a^{b}_{i}\) is given by

\[I_{G}(A^{b},a^{b}_{i})=\frac{i}{n}-\frac{i}{n}\sum_{j\in[\tau]}\frac{(\nu^{l,b} _{j})^{2}}{(i)^{2}}+\frac{n-i}{n}-\frac{n-i}{n}\sum_{j\in[\tau]}\frac{(\nu^{r,b}_{j})^{2}}{(n-i)^{2}}\.\]

For \(b\in\{0,1\}\), \(A^{l,0}_{a^{0}_{i}}\) and \(A^{l,1}_{a^{1}_{1}}\) have the same labels \(\{y_{1},y_{2},\cdots,y_{i}\}\), and we have

\[\sum_{j\in[\tau]}(\nu^{l,0}_{j})^{2}=\sum_{j\in[\tau]}(\nu^{l,1}_{j})^{2}\.\]

Similarly, we have \(\sum_{j\in[\tau]}(\nu^{r,0}_{j})^{2}=\sum_{j\in[\tau]}(\nu^{r,1}_{j})^{2}\), and this completes the proof. 

We can show that adversary can not distinguish the ciphertext of \(\{(a^{0}_{(1)},y_{(1)}),\cdots,(a^{0}_{(n)},y_{(n)})\}\) from that of \(\{(a^{1}_{(1)},y_{(1)}),\cdots,(a^{1}_{(n)},y_{(n)})\}\) in a probabilistic perspective, i.e.,

\[\Pr\left(\llbracket a^{0}_{(1)}\rrbracket,\cdots,\llbracket a^{0 }_{(n)}\rrbracket|(a^{0}_{(1)},y_{(1)}),\cdots,(a^{0}_{(n)},y_{(n)})\right)\] \[= \Pr\left(\llbracket a^{1}_{(1)}\rrbracket,\cdots,\llbracket a^{1 }_{(n)}\rrbracket|(a^{1}_{(1)},y_{(1)}),\cdots,(a^{1}_{(n)},y_{(n)})\right). \tag{18}\]We will prove Eqn. (18) by induction on \(n\). We first have

For \(n=1\), we have \(\llbracket a^{0}_{\langle 1\rangle}\rrbracket=c^{0}_{max}/2\) and \(\llbracket a^{1}_{\langle 1\rangle}\rrbracket=c^{1}_{max}/2\) with \(c^{0}_{max}=c^{1}_{max}=2^{\lambda\log_{2}n}\), according to the initialization in Algorithm 1. This follows that

\[\Pr\left(\llbracket a^{0}_{\langle 1\rangle}\rrbracket|(a^{0}_{\langle 1 \rangle},y_{\langle 1\rangle})\right)=\Pr\left(\llbracket a^{0}_{\langle 1 \rangle}\rrbracket\right)=\Pr\left(\llbracket a^{1}_{\langle 1\rangle}\rrbracket \right)=\Pr\left(\llbracket a^{1}_{\langle 1\rangle}\rrbracket|(a^{1}_{\langle 1 \rangle},y_{\langle 1\rangle})\right)\;.\]

We assume that Eqn. (18) holds for \(n=i\)\((i>1)\), that is,

\[\Pr\left(\llbracket a^{0}_{\langle 1\rangle}\rrbracket,\cdots, \llbracket a^{0}_{\langle i\rangle}\rrbracket|(a^{0}_{\langle 1\rangle},y_{ \langle 1\rangle}),\cdots,(a^{0}_{\langle i\rangle},y_{\langle i\rangle})\right) \tag{19}\] \[= \Pr\left(\llbracket a^{1}_{\langle 1\rangle}\rrbracket,\cdots, \llbracket a^{1}_{\langle i\rangle}\rrbracket|(a^{1}_{\langle 1\rangle},y_{ \langle 1\rangle}),\cdots,(a^{1}_{\langle i\rangle},y_{\langle i\rangle})\right)\;.\]

Let us consider the case \(n=i+1\), and we add the sample \((a^{b}_{\langle i+1\rangle},y_{\langle i+1\rangle})\) in binary search tree \(\mathcal{BT}^{b}\) (Algorithm 1). It is sufficient to consider two cases as follows:

* If we do not need to split a node for sample \((a^{b}_{\langle i+1\rangle},y_{\langle i+1\rangle})\) in Algorithm 1, then we have \(\llbracket a^{1}_{\langle i+1\rangle}\rrbracket=\llbracket a^{0}_{\langle i+1 \rangle}\rrbracket\). This is because \(a^{b}_{\langle 1\rangle}<a^{b}_{\langle 2\rangle}<\cdots<a^{b}_{\langle i+1\rangle}\) for \(b=0\) and \(b=1\), along with the same labels \(\{y_{1},\cdots,y_{i+1}\}\). Hence, we obtain the same ciphertext for \(a^{0}_{\langle i+1\rangle}\) and \(a^{1}_{\langle i+1\rangle}\), i.e., \(t^{0}.\mathit{cipher}_{1}=t^{1}.\mathit{cipher}_{1}\). This follows that \[\Pr\left(\llbracket a^{0}_{\langle 1\rangle}\rrbracket,\cdots, \llbracket a^{0}_{\langle i\rangle}\rrbracket,\llbracket a^{0}_{\langle i+1 \rangle}\rrbracket|(a^{0}_{\langle 1\rangle},y_{\langle 1\rangle}),\cdots,(a^{0}_{ \langle i\rangle},y_{\langle i\rangle}),(a^{0}_{\langle i+1\rangle},y_{ \langle i+1\rangle})\right)\] \[= \Pr\left(\llbracket a^{0}_{\langle 1\rangle}\rrbracket,\cdots, \llbracket a^{0}_{\langle i\rangle}\rrbracket|(a^{0}_{\langle 1\rangle},y_{\langle 1 \rangle}),\cdots,(a^{0}_{\langle i\rangle},y_{\langle i\rangle})\right)\;,\] and \[\Pr\left(\llbracket a^{1}_{\langle 1\rangle}\rrbracket,\cdots, \llbracket a^{1}_{\langle i\rangle}\rrbracket,\llbracket a^{1}_{\langle i+1 \rangle}\rrbracket|(a^{1}_{\langle 1\rangle},y_{\langle 1\rangle}),\cdots,(a^{1}_{\langle i\rangle},y_{ \langle i\rangle}),(a^{1}_{\langle i+1\rangle},y_{\langle i+1\rangle})\right)\] \[= \Pr\left(\llbracket a^{1}_{\langle 1\rangle}\rrbracket,\cdots, \llbracket a^{1}_{\langle i\rangle}\rrbracket|(a^{1}_{\langle 1\rangle},y_{\langle 1 \rangle}),\cdots,(a^{1}_{\langle i\rangle},y_{\langle i\rangle})\right)\;.\] By induction assumption in Eqn. (19), we have \[\Pr\left(\llbracket a^{0}_{\langle 1\rangle}\rrbracket,\cdots, \llbracket a^{0}_{\langle i\rangle}\rrbracket,\llbracket a^{0}_{\langle i+1 \rangle}\rrbracket|(a^{0}_{\langle 1\rangle},y_{\langle 1\rangle}),\cdots,(a^{0}_{\langle i \rangle},y_{\langle i\rangle}),(a^{0}_{\langle i+1\rangle},y_{\langle i+1 \rangle})\right)\] \[= \Pr\left(\llbracket a^{1}_{\langle 1\rangle}\rrbracket,\cdots, \llbracket a^{1}_{\langle i\rangle}\rrbracket,\llbracket a^{1}_{\langle i+1 \rangle}\rrbracket|(a^{1}_{\langle 1\rangle},y_{\langle 1\rangle}),\cdots,(a^{1}_{\langle i \rangle},y_{\langle i\rangle}),(a^{1}_{\langle i+1\rangle},y_{\langle i+1 \rangle})\right)\;.\]
* If we need to split the node for \((a^{b}_{\langle i+1\rangle},y_{\langle i+1\rangle})\) in Algorithm 1, then we assume that \(t^{0}\) and \(t^{1}\) are the corresponding splitting nodes. We firstly initialize the empty node \(l^{b}\) and \(r^{b}\), and update the ciphertext \(l^{b}.\mathit{cipher}_{1}\) and \(r^{b}.\mathit{cipher}_{1}\) by Eqns (8)-(11), respectively. Notice that the random number \(\xi\) in Eqns (8)-(11) is sampled from \(\mathcal{N}(0,1)\), and thus \(l^{0}.\mathit{cipher}_{1}\) and \(l^{1}.\mathit{cipher}_{1}\) are sampled from the same distribution. We have \[\Pr\left(l^{0}.\mathit{cipher}_{1}|(a^{0}_{\langle 1\rangle},y_{\langle 1 \rangle}),\cdots,(a^{0}_{\langle i\rangle},y_{\langle i\rangle}),(a^{0}_{ \langle i+1\rangle},y_{\langle i+1\rangle})\right)\] \[= \Pr\left(l^{1}.\mathit{cipher}_{1}|(a^{1}_{\langle 1\rangle},y_{\langle 1 \rangle}),\cdots,(a^{1}_{\langle i\rangle},y_{\langle i\rangle}),(a^{1}_{ \langle i+1\rangle},y_{\langle i+1\rangle})\right)\;.\] Similarly, \(r^{0}.\mathit{cipher}_{1}\) and \(r^{1}.\mathit{cipher}_{1}\) are sampled from the same distribution, and we have \[\Pr\left(r^{0}.\mathit{cipher}_{1}|(a^{0}_{\langle 1\rangle},y_{\langle 1 \rangle}),\cdots,(a^{0}_{\langle i\rangle},y_{\langle i\rangle}),(a^{0}_{ \langle i+1\rangle},y_{\langle i+1\rangle})\right)\] \[= \Pr\left(r^{1}.\mathit{cipher}_{1}|(a^{1}_{\langle 1\rangle},y_{ \langle 1\rangle}),\cdots,(a^{1}_{\langle i\rangle},y_{\langle i\rangle}),(a^{1}_{ \langle i+1\rangle},y_{\langle i+1\rangle})\right)\;.\] For the \((i+1)\)-th iteration in Algorithm 1, we have \[\Pr\left(\llbracket a^{0}_{\langle 1\rangle}\rrbracket,\cdots, \llbracket a^{0}_{\langle i\rangle}\rrbracket,\llbracket a^{0}_{\langle i \rangle}\rrbracket|(a^{0}_{\langle 1\rangle},y_{\langle 1\rangle}),\cdots,(a^{0}_{\langle i\rangle},y_{ \langle i\rangle}),(a^{0}_{\langle i+1\rangle},y_{\langle i+1\rangle})\right)\] \[= \Pr\left(\llbracket a^{0}_{\langle 1\rangle}\rrbracket,\cdots, \llbracket a^{0}_{\langle i\rangle}\rrbracket|(a^{0}_{\langle 1\rangle},y_{\langle 1 \rangle}),\cdots,(a^{0}_{\langle i\rangle},y_{\langle i\rangle})\right)\] \[\times\Pr\left(l^{0}.\mathit{cipher}_{1}|(a^{0}_{\langle 1\rangle},y_{ \langle 1\rangle}),\cdots,(a^{0}_{\langle i\rangle},y_{\langle i\rangle}),(a^{0}_{ \langle i+1\rangle},y_{\langle i+1\rangle})\right)\] \[\times\Pr\left(r^{0}.\mathit{cipher}_{1}|(a^{0}_{\langle 1\rangle},y_{ \langle 1\rangle}),\cdots,(a^{0}_{\langle i\rangle},y_{\langle i\rangle}),(a^{0}_{ \langle i+1\rangle},y_{\langle i+1\rangle})\right)\;,\]and

\[\Pr\left([\![a^{1}_{\langle 1\rangle}]\!],\cdots,[\![a^{1}_{\langle i \rangle}]\!],[\![a^{1}_{\langle i+1\rangle}]\!]|(a^{1}_{\langle 1\rangle},y_{ \langle 1\rangle}),\cdots,(a^{1}_{\langle i\rangle},y_{\langle i\rangle}),(a^{1} _{\langle i+1\rangle},y_{\langle i+1\rangle})\right)\] \[= \Pr\left([\![a^{1}_{\langle 1\rangle}]\!],\cdots,[\![a^{1}_{ \langle i\rangle}]\!]|(a^{1}_{\langle 1\rangle},y_{\langle 1\rangle}),\cdots,(a^{1}_{ \langle i\rangle},y_{\langle i\rangle})\right)\] \[\times\Pr\left(l^{1}\mbox{\it.cipher}_{1}|(a^{1}_{\langle 1 \rangle},y_{\langle 1\rangle}),\cdots,(a^{1}_{\langle i\rangle},y_{\langle i \rangle}),(a^{1}_{\langle i+1\rangle},y_{\langle i+1\rangle})\right)\] \[\times\Pr\left(r^{1}\mbox{\it.cipher}_{1}|(a^{1}_{\langle 1 \rangle},y_{\langle 1\rangle}),\cdots,(a^{1}_{\langle i\rangle},y_{\langle i \rangle}),(a^{1}_{\langle i+1\rangle},y_{\langle i+1\rangle})\right)\.\]

This follows that

\[\Pr\left([\![a^{0}_{\langle 1\rangle}]\!],\cdots,[\![a^{0}_{ \langle i\rangle}]\!],[\![a^{0}_{\langle i+1\rangle}]\!]|(a^{0}_{\langle 1 \rangle},y_{\langle 1\rangle}),\cdots,(a^{0}_{\langle i\rangle},y_{\langle i \rangle}),(a^{0}_{\langle i+1\rangle},y_{\langle i+1\rangle})\right)\] \[= \Pr\left([\![a^{1}_{\langle 1\rangle}]\!],\cdots,[\![a^{1}_{ \langle i\rangle}]\!],[\![a^{1}_{\langle i+1\rangle}]\!]|(a^{1}_{\langle 1 \rangle},y_{\langle 1\rangle}),\cdots,(a^{1}_{\langle i\rangle},y_{\langle i \rangle}),(a^{1}_{\langle i+1\rangle},y_{\langle i+1\rangle})\right)\.\]

This completes the proof. 

## Appendix D Experimental Details

### Experimental settings

We now present some details of compared methods in this work.

* **Original RFs3**: The original plaintext random forests [1] implemented by sklearn; FPD-ERTS4: The extremely randomized trees algorithm for learning from distributed horizontal partition data [64]; FivotRFs5: A private and efficient solution for tree-based models in a vertical federated learning setting [62], based on a hybrid of threshold partially homomorphic encryption and secure multiparty computation techniques; Footnote 3: The code is downloaded from _github.com/scikit-learn/scikit-learn_
* **MulPRFs6**: The original random forest [1] with the secure multiparty computation library MP-SPDZ [94], based on the sh2 protocol to support semi-honest two-party computation; Footnote 6: The code is downloaded from _github.com/AminAminifar/RPDERT_cloud_
* **AnonyRFs7**: The random forests based on anonymization library Mondrian, is a top-down greedy data anonymization algorithm for relational dataset [59]; Footnote 7: The code is downloaded from _github.com/nusdsbystem/pivot_
* **DiffPrivRFs8**: Random forests based on differential privacy library Diffprivlib [93]. Footnote 8: The code is downloaded from _github.com/csiro-mlai/decision-tree-mpc_

Tables 4 and 5 summarizes some hyperparameters settings in our experiments. Except for parameters 'n_estimators' and '\(\alpha\)' in leaf splitting, other parameters are set according to their respective references. We set security parameter \(\lambda>6.4\) according to privacy-preserving requisites as in [89].

\begin{table}
\begin{tabular}{c|c c c c c c c c} \hline \hline Parameter & Our Work & PPD-ERTs & HileHopRFs & ProvRFs & MulPRFs & AnonyRFs & DiffPrivRFs & Original RFs \\ \hline max\_depth & None & None & 5 & 4 & None & None & None & None \\ \(n\)\_estimators & 100 & 100 & 100 & 100 & 100 & 100 & 100 & 100 & 100 \\ max\_features & \([\![\sqrt{d}]\!]\) & \([\![\sqrt{d}]\!]\) & \([\![\sqrt{d}]\!]\) & \([\![\sqrt{d}]\!]\) & \([\![\sqrt{d}]\!]\) & \([\![\sqrt{d}]\!]\) & \([\![\sqrt{d}]\!]\) & \([\![\sqrt{d}]\!]\) & \([\![\sqrt{d}]\!]\) \\ differentin privacy level \(\epsilon\) & â€“ & â€“ & â€“ & â€“ & â€“ & â€“ & 1 & â€“ \\ anonymization parameter \(k\) & â€“ & â€“ & â€“ & â€“ & â€“ & 10 & â€“ & â€“ \\ multi-party size \(p\) & 2 & 2 & 2 & 2 & 2 & 2 & â€“ & â€“ & â€“ \\ max\_bin & â€“ & â€“ & â€“ & 16 & â€“ & â€“ & â€“ & â€“ \\ \hline \hline \end{tabular}
\end{table}
Table 4: Hyperparameter settings for tree ensemble models in experiments. â€˜\(\cdots\)â€™ means that the parameter is not exist in the corresponding method, and â€˜max_binâ€™ denotes the maximum splitting point of each feature.

[MISSING_PAGE_FAIL:23]

assessment is visualized through a color map: the \(x\)-axis represents the individual bits (1 through 7), while the \(y\)-axis indicates the rank order of the 200 sampled datasets.

The color gradient, ranging from white to red, represents the degree of security, with white correlating to minimal security and red to maximal security. The security degree was normalized within a \([0,1]\) range to ensure results' consistency. For instance, a security degree of 0 with white color indicates no security, while a security degree of 1 with red color suggests the highest level of security.

As expected, the HE scheme presents the highest security, yet with heavy computational costs. For example, datasets exceeding \(3000\) samples yielded no results under the HE scheme, even with an extended runtime of \(10^{6}\) seconds. It is also observed that our proposed scheme demonstrated superior security efficacy compared to the other three scheme: differential privacy [93], anonymization [59] and order-preserving scheme [96]. Since those schemes rely on mere data perturbations, compressions, or order information preservation. In comparison, our scheme makes a good balance between security and computational cost.

## Appendix E Proof of Bitwise Leakage

In this section, we present a comprehensive evaluation of the security properties for our Gini-impurity preserving methods, full homomorphic encryption, anonymization technique, and differential privacy

\begin{table}
\begin{tabular}{c|c c c c c c c c} \hline \hline Dataset & Our encrypted RFs & Original RFs & AnonymRFs & DiffPrivRFs & PPD-EKTs & FvotRFs & MulPRFs & HELqpRFs \\ \hline wbc & 1 & \(\times 3\) & \(\times 3\) & \(\times 3\) & \(\times 38\) & \(\times 1,220\) & \(\times 93\) & \(\times 4,000\) \\ cancer & 1 & \(\times 28\) & \(\times 29\) & \(\times 25\) & \(\times 360\) & \(\times 11,052\) & \(\times 851\) & \(\times 41,911\) \\ breast & 1 & \(\times 25\) & \(\times 31\) & \(\times 27\) & \(\times 308\) & \(\times 11,631\) & \(\times 776\) & \(\times 44,736\) \\ german & 1 & \(\times 4\) & \(\times 5\) & \(\times 4\) & \(\times 115\) & \(\times 2,615\) & \(\times 421\) & \(\times 9,615\) \\ diabetes & 1 & \(\times 42\) & \(\times 35\) & \(\times 41\) & \(\times 411\) & \(\times 18,142\) & \(\times 1,642\) & \(\times 64,285\) \\ adver & 1 & \(\times 3\) & \(\times 4\) & \(\times 10\) & NA & \(\times 3,821\) & NA & NA \\ bibtex & 1 & \(\times 1\) & \(\times 1\) & \(\times 1\) & NA & \(\times 1,528\) & NA & NA \\ phpB0 & 1 & \(\times 4\) & \(\times 4\) & \(\times 4\) & NA & NA & NA & NA \\ pendigits & 1 & \(\times 6\) & \(\times 6\) & \(\times 10\) & \(\times 2384\) & \(\times 18,947\) & NA & NA \\ phish & 1 & \(\times 5\) & \(\times 8\) & \(\times 6\) & \(\times 1,966\) & \(\times 1,7619\) & \(\times 2,604\) & NA \\ alerons & 1 & \(\times 6\) & \(\times 9\) & \(\times 8\) & \(\times 1,581\) & \(\times 30,200\) & \(\times 3,600\) & NA \\ house & 1 & \(\times 6\) & \(\times 9\) & \(\times 8\) & \(\times 1,581\) & \(\times 30,400\) & \(\times 3,600\) & NA \\ a9a & 1 & \(\times 6\) & \(\times 10\) & \(\times 8\) & \(\times 5,482\) & \(\times 27,000\) & \(\times 3,250\) & NA \\ amazon & 1 & \(\times 10\) & \(\times 12\) & \(\times 12\) & \(\times 2,208\) & \(\times 54,500\) & \(\times 7,500\) & NA \\ bank & 1 & \(\times 14\) & \(\times 18\) & \(\times 20\) & \(\times 5,637\) & \(\times 75,500\) & \(\times 10,000\) & NA \\ adult & 1 & \(\times 4\) & \(\times 5\) & \(\times 4\) & \(\times 1,967\) & \(\times 22,054\) & \(\times 2,876\) & NA \\ mnist & 1 & \(\times 2\) & \(\times 3\) & \(\times 2\) & NA & NA & NA & NA \\ minibone & 1 & \(\times 6\) & \(\times 9\) & \(\times 9\) & \(\times 1,800\) & \(\times 75,000\) & NA & NA \\ runwak & 1 & \(\times 12\) & \(\times 18\) & \(\times 26\) & \(\times 2,413\) & \(\times 84,000\) & NA & NA \\ covtype & 1 & \(\times 7\) & \(\times 10\) & \(\times 8\) & \(\times 2,943\) & NA & NA & NA \\ \hline \hline \end{tabular}
\end{table}
Table 7: The orders of magnitude improvement compared to other approaches in Figure 4. â€˜NAâ€™ means that no results were obtained after running out \(10^{6}\) seconds (about 11.6 days).

Figure 4: Comparisons of the prediction running time on different random forest. Notice that the y-axis is in log-scale, and full black columns imply that no result was obtained after running out \(10^{6}\) seconds for training (about 11.6 days).

methods. The security analysis is conducted in the feature space using the bitwise leakage matrix which is proposed by [97].

We focus on a discrete and finite feature space with a fixed size as in [97]. The feature space is defined as \(\mathcal{X}=[0,2^{m-1}]\), which means that the feature size is \(m\) bits, and the space ranges from \(0\) to \(2^{m-1}\). Let \(\mathcal{D}\) be the true distribution over the feature space, and dataset \(S=\{a_{1},\ldots,a_{n}\}\) are sampled independently and identically from distribution \(\mathcal{D}\).

The adversary \(\mathcal{A}\) possesses two types of knowledge to achieve the goal of recovering plaintexts:

* Auxiliary knowledge about a distribution \(\mathcal{D}^{\prime}\) over the feature space \(\mathcal{X}\)[98], which provides additional information to the adversary.
* Ciphertexts \(\llbracket S\rrbracket\) corresponding to \(S\), which represents the snapshot of the encrypted data store, as described in Fuller et al. [99].

We re-sort dataset \(S\) with a non-decreasing order, i.e., \(S=\left\{a_{\langle 1\rangle},a_{\langle 2\rangle},\cdots,a_{\langle n\rangle}\right\}\) where \(a_{\langle 1\rangle}\leq a_{\langle 2\rangle}\leq\cdots\leq a_{\langle n\rangle}\). Let \(S\langle i\rangle\) be the \(i\)-th sample in \(S\), and \(S\langle i\rangle_{[j]}\) be the \(j\)-th bit of \(S\langle i\rangle\) with \(i\in[n]\) and \(j\in[m]\). Then, we denote by \(b\langle i\rangle_{[j]}\) the adversary's guess for \(S\langle i\rangle_{[j]}\) through the auxiliary knowledge distribution \(\mathcal{D}^{\prime}\) as follows:

\[b\langle i\rangle_{[j]}=\arg\max_{b\in\{0,1\}}\Pr_{\mathcal{D}^{\prime}}\left( S\langle i\rangle_{[j]}=b\right)=\left\{\begin{array}{ll}0&\text{for}\quad \mathbb{E}_{\mathcal{D}^{\prime}}[S\langle i\rangle_{[j]}]\leq 1/2\\ 1&\text{for}\quad\mathbb{E}_{\mathcal{D}^{\prime}}[S\langle i\rangle_{[j]}]>1/2 \end{array},\right.\]

for \(i\in[n]\) and \(j\in[m]\). The adversary aims to correctly guess the plaintext \(S\langle i\rangle_{[j]}\) using the auxiliary knowledge \(\mathcal{D}^{\prime}\). Let \(\mathcal{L}\) be a \(n\times m\) matrix with

\[\mathcal{L}(i,j)=\Pr\left(S\langle i\rangle_{[j]}=b\langle i\rangle_{[j]}| \mathcal{D},\mathcal{D}^{\prime}\right)\text{ for }i\in[n]\text{ and }j\in[m]\.\]

Similarly to [97], we have

\[\Pr_{\mathcal{D}}\left(S\langle i\rangle_{[j]}=0\right)=\sum_{s\in S^{j}_{0}} \Pr_{\mathcal{D}}\left(S\langle i\rangle=s\right)\text{ for }i\in[n]\text{ and }j\in[m]\,\]

and \(\Pr_{\mathcal{D}}\left(S\langle i\rangle_{[j]}=1\right)=1-\Pr_{\mathcal{D}} \left(S\langle i\rangle_{[j]}=0\right)\), where \(s_{[j]}\) denotes the \(j\)-th bit of \(s\) with \(S^{j}_{0}=\{s|s\in\mathcal{S}\text{ and }s_{[j]}=0\}\). This follows that

\[\mathcal{L}(i,j)=\Pr\left(S\langle i\rangle_{[j]}=b\langle i\rangle_{[j]}| \mathcal{D},\mathcal{D}^{\prime}\right)=\sum_{s\in S^{j}_{b\langle i\rangle_ {[j]}}}\Pr_{\mathcal{D}}\left(S\langle i\rangle=s\right)\.\]

The variable \(\mathcal{L}(i,j)\) represents the probability that an adversary can accurately guess the \(j\)-th bit of the plaintext \(S\langle i\rangle\). This metric can be considered as a measure of the information security for the ciphertexts \(\llbracket S\langle i\rangle\rrbracket\), in the sense that a lower value of \(\mathcal{L}(i,j)\) signifies a higher degree of security. Specifically, the bitwise information security of \(\llbracket S\langle i\rangle\rrbracket\) can be quantified as 1-\(\mathcal{L}(i,j)\), and this metric provides a precise and quantitative assessment of the encryption scheme's security properties.

Specifically, we investigate the correlation among elements of \(\mathcal{L}(i,j)\), plaintexts, ciphertexts and secret keys. We explore the impact of different encryption parameters on the structure and behavior of \(\mathcal{L}(i,j)\). Our analysis reveals that the leakage pattern of \(\mathcal{L}(i,j)\) is highly dependent on the specific encryption scheme. Therefore, it is crucial to carefully design and select the appropriate encryption scheme to minimize the risk of information leakage.

We now present the analysis of bitwise leakage matrix \(\mathcal{L}(i,j)\) for our encryption method as follows.

**Theorem 7**.: _For our Gini-impurity-preserving encryption and plaintexts \(S\), we have_

\[L(i,j)=\sum_{q\in[i,n-k+i]}\frac{\mathbb{I}(S\langle q\rangle_{[j]})=S\langle i \rangle_{[j]})}{n-k+1}\times\sum_{s\in S^{j}_{b\langle i\rangle_{[j]}}}\Pr_{D }\left(S\langle i\rangle=s\right)+\text{small constant}\.\]

Proof.: Our Gini-impurity-preserving encryption transfers multiple plaintexts in \(\mathcal{I}_{x^{\prime}}\) (\(i^{\prime}\in[k]\)) to the identical first dimension ciphertext, i.e., \(c_{i^{\prime}}\), as shown in Eqn. (5). Hence, the \(i^{\prime}\)-th ciphertext \(c_{i^{\prime}}\) corresponds to multiple plaintexts, and the adversary will guess the true plaintext \(S\langle i\rangle\) of ciphertext\(c_{i^{\prime}}\). Since the adversary only knows that \(i^{\prime}-1\) ciphertexts are smaller than \(c_{i^{\prime}}\) and \(k-i^{\prime}\) ciphertexts are larger than \(c_{i^{\prime}}\), the adversary can guess the plaintext \(S\langle i\rangle\) from

\[\{S\langle q\rangle|q\in[i,n-k+i]\}\]

with the same probability. In this way, the probability of adversary guessing \(S\langle i\rangle_{[j]}\) is

\[P_{i,j}=\sum_{q\in[i,n-k+i]}\frac{\mathbb{I}(S\langle q\rangle_{[j]}=S\langle i \rangle_{[j]})}{n-k+1}\;.\]

Let \(b\langle i\rangle_{[j]}\) be the adversary's guess for \(S\langle i\rangle_{[j]}\), we have

\[b\langle i\rangle_{[j]}=\arg\max_{b\in\{0,1\}}\Pr_{\mathcal{D}^{\prime}}\left(S \langle i\rangle_{[j]}=b\right)=\left\{\begin{array}{ll}0&\text{for}\quad \mathbb{E}_{\mathcal{D}^{\prime}}[S\langle i\rangle_{[j]}]\leq 1/2\\ 1&\text{for}\quad\mathbb{E}_{\mathcal{D}^{\prime}}[S\langle i\rangle_{[j]}]>1/ 2\;.\end{array}\right.\]

The probability for the adversary correctly identifies the \(j\)-th bit of the plaintext \(S\langle i\rangle\) is

\[L(i,j)=P_{i,j}\sum_{s\in\mathcal{S}_{b\langle i\rangle_{[j]}}^{\prime}}\Pr_{D} \left(S\langle i\rangle=s\right)+\text{ small constant}\;,\]

and we complete the proof from Lemma 8. 

**Lemma 8** (Roy et al. [97]).: _Let \(\mathcal{D}\) be the input distribution and \(S=\{a_{1},\ldots,a_{n}\}\) denotes the dataset with each data point sampled i.i.d. from \(\mathcal{D}\), then we have_

\[\Pr_{\mathcal{D}}\left(S\langle i\rangle=a^{\prime}\right)=\sum_{j=n-i+1}^{n} \binom{n}{j}\left(\Pr_{\mathcal{D}}\left(a<a^{\prime}\right)\right)^{n-j} \left(\Pr_{\mathcal{D}}\left(a=a^{\prime}\right)\right)^{j}\text{ for }\Pr_{ \mathcal{D}}\left(a>a^{\prime}\right)=0\;,\]

_and_

\[\Pr_{\mathcal{D}}\left(S\langle i\rangle=a^{\prime}\right)=\sum_{j=i}^{n} \binom{n}{j}\left(\Pr_{\mathcal{D}}\left(a=a^{\prime}\right)\right)^{j}\left( \Pr_{\mathcal{D}}\left(a>a^{\prime}\right)\right)^{n-j}\text{ for }\Pr_{ \mathcal{D}}\left(a<a^{\prime}\right)=0\;;\]

_otherwise,_

\[\Pr_{\mathcal{D}}\left(S\langle i\rangle=a^{\prime}\right)=\sum_{j=1}^{n} \sum_{k=\max\{1,i-j+1\}}^{\min\{i,n-j+1\}}\binom{n}{k-1,j,n-k-j+1)}\Delta_{k- 1,j,n-k-j+1}\;,\]

_where_

\[\Delta_{k-1,j,n-k-j+1}=\left(\Pr_{\mathcal{D}}\left(a<a^{\prime}\right) \right)^{k-1}\cdot\left(\Pr_{\mathcal{D}}\left(a=a^{\prime}\right)\right)^{j} \cdot\left(\Pr_{\mathcal{D}}\left(a>a^{\prime}\right)\right)^{n-k-j+1}\;.\]

Figure 5: Comparisons of the security degree for the feature space through the bitwise leakage matrix.

We now provide similar analysis of bitwise leakage matrix \(\mathcal{L}\) for \(\epsilon\)-local differential privacy.

**Theorem 9**.: _For \(\epsilon\)-local differential privacy, we have_

\[L(i,j)=\frac{\Pr\left(S\langle i\rangle_{[j]}=b\langle i\rangle_{[j]}\right)+\Pr \left(S\langle i\rangle_{[j]}=S^{\prime}\langle i\rangle_{[j]}\right)}{2}+\text{ small constant}\;,\]

_where \(S\) and \(S^{\prime}\) denotes the plaintexts and ciphertexts, respectively, and_

\[b\langle i\rangle_{[j]}=\arg\max_{b\in\{0,1\}}\Pr_{\mathcal{D}^{\prime}}\left( S\langle i\rangle_{[j]}=b\right)=\left\{\begin{array}{ll}0&\text{if}&\mathbb{E}_{ \mathcal{D}^{\prime}}\big{[}S\langle i\rangle_{[j]}\big{]}\leq 1/2\\ 1&\text{if}&\mathbb{E}_{\mathcal{D}^{\prime}}\big{[}S\langle i\rangle_{[j]} \big{]}>1/2\end{array},\right.\]

Proof.: We concern \(\epsilon\)-local differential privacy by adding noise to each individual value. If the adversary attempts to infer the original plaintext \(S\langle i\rangle\), then it relies on the \(\epsilon\)-differential privacy disturbed data \(S^{\prime}(i)\) and the auxiliary knowledge distribution \(\mathcal{D}^{\prime}\). The adversary guesses the \(j\)-th bit of the \(i\)-th plaintext \(S\langle i\rangle_{[j]}\) through a process of deduction as follows:

\[S\langle i\rangle_{[j]}=\begin{cases}1&\text{for }b\langle i\rangle_{[j]}=1 \text{ and }S^{\prime}\langle i\rangle_{[j]}=1\;,\\ 0&\text{for }b\langle i\rangle_{[j]}=0\text{ and }S^{\prime}\langle i\rangle_{[j]}=0 \;,\\ \text{randomly select from}\{0,1\}&\text{otherwise}\;.\end{cases}\]

This follows that

\[L(i,j)=\frac{\Pr\left(S\langle i\rangle_{[j]}=b\langle i\rangle_{[j]}\right)+ \Pr\left(S\langle i\rangle_{[j]}=S^{\prime}(i,j)\right)}{2}+\text{ small constant}\;.\]

This completes the proof. 

In order to gain a deeper understanding of the security for the \(k\)-anonymous algorithm, we conduct an analysis of the bitwise leakage matrix \(\mathcal{L}\). This matrix represents the amount of information leakage that occurs when the original data \(X\) is compressed into \(m\) partitions \(\mathcal{K}_{1},\mathcal{K}_{2},\cdots,\mathcal{K}_{t}\) by the \(k\)-anonymous algorithm as follows:

\[\mathcal{K}_{1} = \left\{a_{\langle 1\rangle},a_{\langle 2\rangle},\cdots,a_{\langle k _{1}\rangle}\right\}\] \[\mathcal{K}_{2} = \left\{a_{\langle k_{1}+1\rangle},a_{\langle k_{1}+2\rangle}, \cdots,a_{\langle k_{2}\rangle}\right\}\] \[\cdots\] \[\mathcal{K}_{t} = \left\{a_{\langle k_{t-1}+1\rangle},a_{\langle k_{t-1}+2\rangle}, \cdots,a_{\langle n\rangle}\right\}\;.\]

The bitwise leakage matrix \(\mathcal{L}\) quantifies the amount of information that can be inferred about an individual from the corresponding partitions. By analyzing this matrix, we can determine the level of privacy that is maintained by the \(k\)-anonymous algorithm and identify any potential vulnerabilities that could be exploited by an adversary. Then, we give the analysis of bitwise leakage matrix \(\mathcal{L}\) for \(k\)-anonymous algorithm as follows.

**Theorem 10**.: _For \(k\)-anonymous algorithm and the plaintexts \(S\), we have_

\[L(i,j)=\Pr\left(S\langle i\rangle_{[j]}=b\langle i\rangle_{[j]}\right)+\text{ small constant}\;,\]

_where \(S\langle i\rangle_{[j]}\) denotes the \(j\)-th bit of \(S\langle i\rangle\) with \(S\langle i\rangle\in\mathcal{K}_{q}(q\in[t])\) and_

\[b\langle i\rangle_{[j]}=\arg\max_{b\in\{0,1\}}\left\{\sum_{x\in\mathcal{K}_{q }}\mathbb{I}[x_{[j]}=b]\Pr_{\mathcal{D}^{\prime}}\left(x\right)\right\}\;.\]

Proof.: The \(k\)-anonymity is a privacy-preserving technique that aims to protect the identity of individuals in a dataset. It works by grouping together individuals with similar attributes and pooling their data in a larger group, thus making it difficult for an adversary to identify any specific individual in the group. The \(k\)-anonymity ensures that each group has at least \(k\) individuals with the same attribute values, which further enhances the security of the data.

When the original data \(S\langle i\rangle\) is pooled in the group \(\mathcal{K}_{q}(q\in[t])\), the adversary attempts to guess the \(j\)-th bit of the plaintext \(S\langle i\rangle\) using the auxiliary knowledge distribution \(\mathcal{D}^{\prime}\) and \(\mathcal{K}_{q}\). To achieve this,the adversary guesses \(b\langle i\rangle_{[j]}\) as the value corresponding to the maximum probability of the \(j\)-th bit in group \(\mathcal{K}_{q}\) as follows:

\[b\langle i\rangle_{[j]}=\arg\max_{b\in\{0,1\}}\left\{\sum_{x\in\mathcal{K}_{q}} \mathbb{I}[x_{[j]}=b]\Pr_{\mathcal{D}^{\prime}}(x)\right\}\;.\]

This completes the proof.