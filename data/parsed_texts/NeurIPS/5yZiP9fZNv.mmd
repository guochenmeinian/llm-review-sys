# Amortized Reparametrization: Efficient and Scalable Variational Inference for Latent SDEs

 Kevin Course

University of Toronto

kevin.course@mail.utoronto.ca

&Prasanth B. Nair

University of Toronto

prasanth.nair@utoronto.ca

###### Abstract

We consider the problem of inferring latent stochastic differential equations (SDEs) with a time and memory cost that scales independently with the amount of data, the total length of the time series, and the stiffness of the approximate differential equations. This is in stark contrast to typical methods for inferring latent differential equations which, despite their constant memory cost, have a time complexity that is heavily dependent on the stiffness of the approximate differential equation. We achieve this computational advancement by removing the need to solve differential equations when approximating gradients using a novel amortization strategy coupled with a recently derived reparametrization of expectations under linear SDEs. We show that, in practice, this allows us to achieve similar performance to methods based on adjoint sensitivities with more than an order of magnitude fewer evaluations of the model in training.

## 1 Introduction

Recent years have seen the rise of continuous time models for dynamical system modeling [1]. As compared to traditional autoregressive style models [2], continuous time models are useful because they can deal with non-evenly spaced observations, they enable multilevel/hierarchical and adaptive prediction schemes, and because physics is (mostly) done in continuous time. For example, recent developments in inferring continuous time differential equations from data has been met by a flurry of work in endowing models with physics informed priors [3, 4, 5].

Despite their advantages, continuous time models remain significantly more computationally challenging to train than their autoregressive counterparts due to their reliance on adjoint methods for estimating gradients. Adjoint methods introduce a significant computational burden in training because they require solving a pair of initial value problems to estimate gradients. Solving such initial value problems as a part of an iterative optimization procedure is computationally demanding for the following reasons:

1. Gradient based updates to models of differential equations can cause them to become extremely stiff. This will have the effect of causing the cost per iteration to explode mid-optimization.
2. With the exception of parareal methods [6], differential equation solvers are fundamentally _iterative sequential_ methods. This makes them poorly suited to being parallelized on modern parallel computing hardware.

In accordance with such challenges a number of methods have been introduced to speed up training of continuous time models including regularizing dynamics [7, 8] and replacing ordinary differential equation (ODE) solvers with integration methods where possible [9]. Despite the computational advancements brought about by such innovations, continuous time models remain expensive to train in comparison to discrete time models.

In addition to these computational challenges, it is well-known that adjoint methods suffer from stability issues when approximating gradients of time averaged quantities over long time intervals for chaotic systems [10].

In the current work, we present a memory and time efficient method for inferring nonlinear, latent stochastic differential equations (SDEs) from high-dimensional time-series datasets. In contrast to standard approaches for inferring latent differential equations that rely on adjoint sensitivities [1; 11; 12], our approach removes the requirement of solving differential equations entirely. We accomplish this advancement by coupling a novel amortization strategy with a recently derived reparametrization for expectations under Markov Gaussian processes [13]. We show that our approach can be used to approximate gradients of the evidence lower bound used to train latent SDEs with a time and memory cost that is independent of the amount of data, the length of the time series, and the stiffness of the approximate differential equations. The asymptotic complexity for our approach is compared to well-known methods from the literature in Table 1. We note that our method has a constant cost that is chosen by the user. Moreover, we will show that our method is embarrassingly parallel (i.e. all evaluations of the model can be performed in parallel over each iteration) whereas, we reiterate, differential equation solvers are iterative sequential methods.

The applications of our method span various standard generative modeling tasks, such as auto-encoding, denoising, inpainting, and super-resolution [15], particularly tailored for high-dimensional time-series. Crucially, the computational efficiency of our approach not only enables the allocation of more computational resources towards hyperparameter tuning but also democratizes access to state-of-the-art methods by making them feasible to train on lower performance hardware.

In the next section we provide a description of the theory underpinning our work with the main result of a stochastic, unbiased estimate for gradients appearing in Lemma 1. In Section 4 we provide a number of numerical studies including learning latent neural SDEs from video and performance benchmarking on a motion capture dataset. Notably we show that we are able to achieve comparable performance to methods based on adjoints with more than **one order of magnitude** fewer evaluations of the model in training (Section 4.1). We also demonstrate that our approach does not suffer from the numerical instabilities that plague adjoint methods for long time-series with chaotic systems (Section 4.2). Finally, we close with a discussion of the limitations of our approach as well as some suggestions for future work. All code is available at github.com/coursekevin/arlatentsde.

## 2 Method

### Problem description

Consider a time-series dataset \(\mathcal{D}=\{(x_{i},t_{i})\}_{i=1}^{N}\), where \(t_{i}\in\mathbb{R}\) is the time stamp associated with the observation, \(x_{i}\in\mathbb{R}^{D}\). For example \(x_{i}\) may be an indirect observation of some underlying dynamical system, a video-frame, or a snapshot of a spatio-temporal field. We assume that each observation was generated via the following process: first a latent trajectory, \(z(t)\), is sampled from a general,

\begin{table}
\begin{tabular}{l c c} \hline \hline Method & Time & Memory \\ \hline Deterministic adjoints (Neural ODE) [1] & \(\mathcal{O}(J)\) & \(\mathcal{O}(1)\) \\ Stochastic adjoints [12] & \(\mathcal{O}(J\log J)\) & \(\mathcal{O}(1)\) \\ Backprop through solver [14] & \(\mathcal{O}(J)\) & \(\mathcal{O}(J)\) \\ Amortized reparametrization (ours) & \(\mathcal{O}(R)\) & \(\mathcal{O}(R)\) \\ \hline \hline \end{tabular}
\end{table}
Table 1: Asymptotic complexity comparison for approximating gradients. Units are given by the number of evaluations of the differential equation (gradient field for ODEs or drift and diffusion function for SDEs). Here \(J\) is the number of _sequential_ evaluations and \(R\) is the number of _parallel_ evaluations. \(J\) is adaptively chosen by the differential equation solver and is a function of the stiffness of the differential equation meaning it can change (and possibly explode) while optimizing. In contrast, \(R\) is a fixed constant used to control the variance of gradient approximations. While we could choose \(R=1\) and would still arrive with unbiased approximations for gradients, in practice we found choosing \(R\approx 10^{2}\) worked well for the problems we considered.

nonlinear_ SDE with time-dependent diffusion,

\[dz=f_{\theta}(t,z)dt+L_{\theta}(t)d\beta,\] (1)

with initial condition \(p_{\theta}(z_{0})\) and then each \(x_{i}\) is generated from the conditional distribution \(p_{\theta}(x\mid z(t_{i}))\) where \(z(t_{i})\) is the realization of the latent trajectory at time stamp \(t_{i}\). Here \(f_{\theta}:\mathbb{R}\times\mathbb{R}^{d}\rightarrow\mathbb{R}^{d}\) is called the drift function, \(L_{\theta}:\mathbb{R}\rightarrow\mathbb{R}^{d\times d}\) is called the dispersion matrix, and \(\beta\) denotes Brownian motion with diffusion matrix \(\Sigma\). We will model both the drift function of the SDE and the conditional distribution using neural networks in this work. This combination of SDE and conditional distribution define the generative model that we wish to infer.

Like in the standard generative modeling setting, the "true" parameters defining the latent SDE and the conditional likelihood, as well as the specific realization of the latent state, remain unknown. In addition, the posterior over the latent state at a point in time, \(p_{\theta}(z(t)\mid\mathcal{D})\), is intractable. Our objectives are two-fold, we wish to: (i) infer a likely setting for the parameters, \(\theta\), that is well-aligned with the observed data and (ii) infer a parametric model for the posterior over the latent state at a particular point in time as a function of a small window of the observations, for example \(q_{\phi}(z(t)\mid x_{i},x_{i+1},\ldots,x_{i+M})\approx p_{\theta}(z(t)\mid \mathcal{D})\) for \(t\in[t_{i},t_{i+M}]\) and \(1\leq M<<N\). This latent variable model is depicted in Figure 1. In this work we will tackle this problem statement using the machinery of stochastic variational inference [16].

Before proceeding with an explanation of our approach, it is worthwhile taking a moment to consider why assuming the latent state is a realization of a SDE, as opposed to an ordinary differential equation (ODE) with random initial conditions [1, 11, 17], merits the additional mathematical machinery. First, there is a long history in using SDEs in the physical sciences to model systems (even deterministic systems) that lack predictability due to super-sensitivity to parameters and or initial conditions [18]. One reason for the preference towards this modeling paradigm is that deterministic ODEs with random initial conditions only permit uncertainty to enter in their initial condition. This means that we are assuming that all randomness which may affect the latent trajectory at all future points in time are precisely encoded in the uncertainty in the initial condition. In contrast, SDEs make the less restrictive assumption that uncertainty accumulates over time.

### Evidence lower bound

As is the case with standard latent variable models, training proceeds by specifying approximate posteriors over latent variables (in this case the latent state, \(z(t)\)) and then minimizing the Kullback-Leibler (KL) divergence between the approximate and true posterior. An added complication in our specific case comes from the fact that the latent state is defined by a stochastic process rather than a random-vector as is more typical. While it is possible to choose more general approximate posteriors [12], in this work we make the choice to approximate the posterior over the latent state as a Markov Gaussian Process (MGP) defined by the linear SDE,

\[dz=(-A_{\phi}(t)z+b_{\phi}(t))dt+L_{\theta}(t)d\beta,\] (2)

with Gaussian initial condition, \(z(t_{0})\sim\mathcal{N}(m_{0},S_{0})\) where \(m_{0}\in\mathbb{R}^{d}\) and \(S_{0}\in\mathbb{R}^{d\times d}\) is a symmetric positive definite. Here \(A_{\phi}:\mathbb{R}\rightarrow\mathbb{R}^{d\times d}\) and \(b_{\phi}:\mathbb{R}\rightarrow\mathbb{R}^{d}\) are symmetric matrix and vector-valued functions of time, respectively. Before proceeding, it is worth emphasizing that this choice of approximate posterior is not as restrictive as it may appear since it is only used to approximate the _posterior_ (i.e. the latent state given the observations \(p(z(t)\mid\mathcal{D})\) for \(t\in[t_{1},t_{N}]\)). When forecasting

Figure 1: The solid lines indicate the data generating process that depends on the parameters, \(\theta\). The dashed lines indicate the approximate variational posterior that depends on the parameters, \(\phi\).

beyond the data window, we will use the nonlinear SDE in (1). In this way, the approximate posterior primarily serves as a useful intermediary in training the generative model rather than the end-product.

For our purposes, MGPs are useful because the marginal distribution \(q_{\phi}(z(t))=\mathcal{N}(m_{\phi}(t),S_{\phi}(t))\) (i.e. the distribution of the latent state at time \(t\)) is a Gaussian whose mean and covariance are given by the solution to the following set of ODEs [19],

\[\begin{split}\dot{m}_{\phi}(t)&=-A_{\phi}(t)m_{ \phi}(t)+b_{\phi}(t),\\ \dot{S}_{\phi}(t)&=-A_{\phi}(t)S_{\phi}(t)-S_{\phi}( t)A_{\phi}(t)^{T}+L_{\theta}(t)\Sigma L_{\theta}(t)^{T},\end{split}\] (3)

where \(m(0)=m_{0}\) and \(S(0)=S_{0}\).

Using the reparametrization trick from [13], the evidence lower bound (ELBO) can be written as,

\[\begin{split}\mathcal{L}(\theta,\phi)=&\sum_{i=1}^{ N}\mathbb{E}_{z(t_{i})\sim q_{\phi}(z(t))}\left[\log p_{\theta}(x_{i}\mid z(t_{i})) \right]\\ &-\frac{1}{2}\int_{0}^{T}\mathbb{E}_{z(t)\sim q_{\phi}(z(t))} \left[||r_{\theta,\phi}(z(t),t)||^{2}_{C_{\theta}(t)}\right]\,dt,\end{split}\] (4)

where

\[r_{\theta,\phi}(z(t),t)= B(t)(m_{\phi}(t)-z(t))+\dot{m}_{\phi}(t)-f_{\theta}(z(t),t),\] (5)

\(C_{\theta}(t)=(L_{\theta}(t)\Sigma L_{\theta}(t)^{T})^{-1}\), \(B(t)=\text{vec}^{-1}\left((S_{\phi}(t)\oplus S_{\phi}(t))^{-1}\text{vec}(C_{ \theta}(t)^{-1}-\dot{S}_{\phi}(t))\right)\), \(\oplus\) indicates the Kronecker sum, \(\text{vec}:\mathbb{R}^{d\times d}\rightarrow\mathbb{R}^{d^{2}}\) maps a matrix into a vector by stacking columns, and \(\text{vec}^{-1}:\mathbb{R}^{d^{2}}\rightarrow\mathbb{R}^{d\times d}\) converts a vector into a matrix such that \(\text{vec}^{-1}(\text{vec}(B))=B\ \forall B\in\mathbb{R}^{d\times d}\). See Appendices A and B for a detailed derivation. We note that computing the residual, \(r_{\theta,\phi}\), scales linearly in the dimension of the state so long as \(S_{\phi}(t)\) and \(C_{\theta}(t)\) are diagonal. To ensure our approach remains scalable, we will make this assumption throughout the remainder of this work. In this case, we have

\[B(t)=\frac{1}{2}S_{\phi}(t)^{-1}(C_{\theta}(t)^{-1}-\dot{S}_{\phi}(t)).\] (6)

Often we may wish to place additional priors onto a subset of the generative model parameters, \(\theta\), and infer their posterior using stochastic variational inference as well. In this case we add the KL-divergence between the approximate posterior and prior onto the ELBO, \(KL(q_{\phi}(\theta)\mid\mid p(\theta))\) and rewrite all expectations with respect to \(q_{\phi}(z(t))\) and \(q_{\phi}(\theta)\); details are provided in Appendix C.

Remark 1:Despite having defined the approximate posterior in terms of an SDE with parameters \(A_{\phi}\) and \(b_{\phi}\), the ELBO only depends on the mean and covariance of the process at a particular point in time, \(m_{\phi}\) and \(S_{\phi}\). For this reason we can parametrize \(m_{\phi}\) and \(S_{\phi}\) directly while implicitly optimizing with respect to \(A_{\phi}\) and \(b_{\phi}\). In addition, we can efficiently compute \(\dot{m}_{\phi}\) and \(\dot{S}_{\phi}\) using automatic differentiation.

Remark 2:Despite the fact that the prior and approximate posterior are SDEs, all expectations in the ELBO are taken with respect to _normal distributions_. Moreover, in contrast to the approach in [20; 21] there are no differential equality constraints - instead we have been left with an integral over the window of observations.

Taken together, these observations allow us to infer the parameters of the generative model (a nonlinear, latent SDE with additive diffusion (1)), without the use of a forward solver.

### Amortization strategy

The implicit assumption in the ELBO in (4) is that the state mean and covariance will be approximated over the _entire_ window of observations. This can pose a serious computational bottleneck with long or complicated time-series. In this section we propose a novel amortization strategy that will allow us to effectively eliminate this cost by requiring that we only approximate the posterior over short partitions of total the data time-window at once.

Rather than attempting to compute and store the posterior over the entire latent trajectory, we will instead construct an approximation to the posterior over a small window of observations as a function of those observations. Consider a reindexing of the dataset by splitting it into \(N/M\) non-overlapping partitions where \(1\leq M<<N\),

\[\text{original indexing:} [t_{1},\ t_{2},\ \ldots,t_{M},t_{M+1},\ldots,t_{N}\ \ \ ]\] \[\text{reindexed dataset:} [t_{1}^{(1)},t_{2}^{(1)},\ldots,t_{M}^{(1)},t_{1}^{(2)},\ldots, \ t_{M}^{(N/M)}]\]

In the case that \(N\) is not evenly divisible by \(M\) we allow the final split to contain less elements. We approximate the latent state over each partition using only the \(M\) observations in each partition, \(q_{\phi}(z(t)\mid x_{1}^{(j)},x_{2}^{(j)},\ldots,x_{M}^{(j)})\approx p(z(t) \mid\mathcal{D})\) for \(t\in[t_{1}^{(j)},t_{1}^{(j+1)}]\). This can be interpreted as a probabilistic encoder over the time interval of the partition of observations. Letting \(t_{1}^{N/M+1}\equiv t_{M}^{N/M}\), the ELBO can be compactly rewritten as, \(\mathcal{L}(\theta,\phi)=\sum_{j=1}^{N/M}\mathcal{L}^{(j)}(\theta,\phi),\) where

\[\mathcal{L}^{(j)}(\theta,\phi)= \sum_{i=1}^{M}\mathbb{E}_{q_{\phi}(z(t_{1}^{(j)})|x_{1}^{(j)}, \ldots,x_{M}^{(j)})}\left[\log p_{\theta}(x_{i}^{(j)}\mid z(t_{i}^{(j)}))\right]\] (7) \[-\frac{1}{2}\int_{t_{1}^{(j)}}^{t_{1}^{(j+1)}}\mathbb{E}_{q_{ \phi}(z(t)|x_{1}^{(j)},\ldots,x_{M}^{(j)})}\left[||r_{\theta,\phi}(z,t)||_{C_{ \theta}(t)}^{2}\right]\,dt.\]

An additional advantage of this amortization strategy is that it allows our approach to scale to multiple trajectories without an increase to the overall computational cost. If there are multiple trajectories, we can reindex each trajectory independently and subsequently sum all sub loss functions.

To reiterate, the probabilistic encoder is a function which takes in \(M\) observations from a particular partition along with a time stamp, \(t\), and outputs a mean vector and covariance matrix as an estimate for the latent state at that particular time. In principle, any function which can transform a batch of snapshots and a time stamp into a mean and covariance could be used as an encoder in our work. In our implementation, we use deep neural networks to encode each \(x_{i}^{(j)}\) using \(i\in\mathcal{I}\) where \(\mathcal{I}\subset[x_{1}^{(j)},x_{2}^{(j)},\ldots,x_{M}^{(j)}]\) contains some temporal neighbours of \(x_{i}\) into a single latent vector. This approach yields a set of latent vectors associated with each observation in the partition \(h_{i}\) for \(i=1,2,\ldots,M\). We then interpolate between each latent vector using a deep kernel based architecture to construct the posterior approximation for any time stamp in the partition; see Appendix D for details. We emphasize this is one choice of encoding architecture that we found convenient, it is straightforward to incorporate an autoregressive or transformer based encoder in our methodology [22]

An important consideration is the selection of the partition parameter, \(M\). In practice, \(M\) should be large enough so that the assumption of a linear SDE for the approximate posterior is appropriate (i.e. we have enough observations in a partition so that the assumption of a Gaussian process over the latent state is reasonable). For example, as we will see in an upcoming numerical study, in the context of inferring latent SDEs from videos, we will need to choose \(M\) to be large enough so that we can reasonably infer both the position and velocity of the object in the video.

### Reparametrization trick

While the previous sections have demonstrated how to eliminate the need for a differential equation solver by replacing the initial value problem with an integral, in this section we show how the reparametrization trick can be combined with the previously described amortization strategy to construct unbiased gradient approximations for the ELBO with a time and memory cost that scales independently with the amount of data, the length of the time series, and the stiffness of the approximation to the differential equations. Consider a reparametrization to the latent state of the form \(z(t)=T(t,\epsilon,\phi)\) where \(\epsilon\sim p(\epsilon)\) so that \(z(t)\sim q_{\phi}(z(t)\mid x_{1}^{(j)},x_{2}^{(j)},\ldots,x_{M}^{(j)})\). We can rewrite the second term in the evidence lower bound as,

\[\int_{t_{1}^{(j)}}^{t_{1}^{(j+1)}}\mathbb{E}_{q_{\phi}(z(t))} \left[||r_{\theta,\phi}(z(t),t)||_{C_{\theta}(t)}^{2}\right]\,dt =\int_{t_{1}^{(j)}}^{t_{1}^{(j+1)}}\mathbb{E}_{p(\epsilon)} \left[||r_{\theta,\phi}(T(t,\epsilon,\phi),t)||_{C_{\theta}(t)}^{2}\right]\,dt\] (8) \[=(t_{1}^{(j+1)}-t_{1}^{(j)})\mathbb{E}_{p(\epsilon)p(t)}\left[||r_ {\theta,\phi}(T(t,\epsilon,\phi),t)||_{C_{\theta}(t)}^{2}\right]\]where \(p(t)\) is a uniform distribution, \(\mathcal{U}(t_{1}^{(j)},t_{1}^{(j+1)})\) and \(p(\epsilon)\sim\mathcal{N}(0,I)\) is a Gaussian. With this rearrangement, we can derive the main result of this work.

**Lemma 1**.: _An unbiased approximation of the gradient of the evidence lower bound, denoted as \(\nabla_{\theta,\phi}\mathcal{L}(\theta,\phi)\), with an \(\mathcal{O}(R)\) time and memory cost can be formulated as follows:_

\[\nabla_{\theta,\phi}\mathcal{L}(\theta,\phi)\approx \frac{N}{R}\sum_{i=1}^{M}\sum_{k=1}^{R}\nabla_{\theta,\phi}\log p _{\theta}(x_{i}^{(j)}\mid T(t_{i}^{(j)},\epsilon^{(k)},\phi))\] (9) \[-(t_{1}^{(j+1)}-t_{1}^{(j)})\frac{N}{2R}\sum_{k=1}^{R}\nabla_{ \theta,\phi}||r_{\theta,\phi}(T(t^{(k)},\epsilon^{(k)},\phi),t^{(k)})||_{C_{ \theta}(t^{(k)})}^{2}.\]

_where each \(t^{(k)}\sim\mathcal{U}(t_{1}^{(j)},t_{1}^{(j+1)})\) and each \(\epsilon^{(k)}\sim\mathcal{N}(0,I)\)._

The proof follows by applying the standard reparametrization trick [15] to estimating gradients of the amortized objective in (7).

**Remark 1:** In practice we found choosing \(R\sim 100\) worked well for the problems we considered. Note that in terms of elapsed time, \(100\) evaluations of this objective, which can be computed in parallel, is far cheaper than \(100\) evaluations of the SDE forward model evaluated as a part of an iterative sequential SDE solver. Moreover we found that adaptive stepping schemes required far more evaluations of the SDE forward model than our stochastic approach (see Section 4.1).

**Remark 2:** In the case that evaluations of the SDE drift term were relatively cheap compared to decoder evaluations (for example in the case the dimension of the latent state is much smaller than the dimension of the data), we found it useful to increase the number of samples used to approximate the integral over time without increasing the number of samples from the variational posterior. To do so, we made use of a nested Monte Carlo scheme to approximate the second term in the ELBO,

\[(t_{1}^{(j+1)}-t_{1}^{(j)})\mathbb{E}_{p(e)p(t)}\left[||r_{ \theta,\phi}(T(t,\epsilon,\phi),t)||_{C_{\theta}(t)}^{2}\right]\approx\\ \frac{t_{1}^{(j+1)}-t_{1}^{(j)}}{RS}\sum_{k=1}^{R}\sum_{l=1}^{S} \lVert r_{\theta,\phi}(T(t^{(k,l)},\epsilon^{(k)},\phi),t^{(k,l)})||_{C_{ \theta}(t^{(k,l)})}^{2},\] (10)

where, again, each \(\epsilon^{(k)}\sim\mathcal{N}(0,I)\) and each \(t^{(k,1)},t^{(k,2)},\ldots,t^{(k,S)}\sim\mathcal{U}(t_{1}^{(j)},t_{1}^{(j+1)})\). In addition, because the integral over time is one-dimensional we used stratified sampling to draw from \(\mathcal{U}(t_{1}^{(j)},t_{1}^{(j+1)})\) in order to further reduce the variance in the integral over time. In this case we often found we could choose \(R\sim 10\) and \(S\sim 10\). To be clear, (10) is simply a method for variance reduction that we found to be useful; it is not a necessary component for our approach.

## 3 Limitations & Related Work

Summary of assumptions.In the previous sections we introduced an ELBO which, when maximized, leaves us with a generative model in the form of a nonlinear, latent SDE with time-dependent diffusion and an approximation to the latent state over the time-window of observations in the form of a Gaussian process. To reiterate, we only assume that the approximating posterior, i.e. the distribution over the latent state given a batch of observations, is a Gaussian process; this is an assumption that is commonly made in the context of nonlinear state estimation, for example [23; 24]. When making predictions, we sample from the nonlinear SDE which characterizes the generative model (1).

Stochastic adjoint sensitivities.Li et al. [12] proposed the stochastic adjoint sensitivity method, enabling the inference of latent SDEs using a wide range of approximate posteriors over the latent state. In our work we choose to approximate the posterior over the latent state using a MGP which enables us to eliminate the requirement of solving any differential equations entirely; as we have discussed extensively this choice enables dramatic computational savings. A limitation of our approach as compared to the stochastic adjoint sensitivities method is that our method should only be used to approximate the posterior over the latent state when it is approximately a MGP. Intuitively, this limitation is akin to the limitations of mean-field stochastic variational inference as comparedto stochastic variational inference with an expressive approximate posterior such as normalizing flows [25]. From our practical experience working on a range of test cases, this has not been a limiting factor. It is worth reiterating that this limitation applies only to the approximate posterior over the time window of observations; the predictive posterior can be a complex distribution defined by a nonlinear SDE with a Gausian initial condition.

In addition, the stochastic adjoint sensitivity method allows for state dependent diffusion processes whereas our approach only allows for a time dependent diffusion process. In cases where a state dependent diffusion process is deemed necessary, our approach could be used to provide a good initial guess for the parameters of the drift function. It remains a topic of future work to determine if this limitation is mitigated by the fact that we are learning latent SDEs rather than SDEs in the original data space. Across the range of test cases we considered, we have not encountered a problem for which the assumption of a time-dependent diffusion matrix was limiting.

Latent neural ODEs.Chen et al. [1], Rubanova et al. [11], and Toth et al. [17] presented latent ordinary differential equations (ODEs) as generative models for high-dimensional temporal data. These approaches have two main limitations: (i) they encode all uncertainty in the ODE's initial condition and (ii) they rely on adjoint sensitivities, necessitating the solution of a sequence of initial value problems during optimization. As was discussed previously, SDEs provide a more natural modeling paradigm for estimating uncertainty, naturally capturing our intuition that uncertainty should accumulate over time [18]. Moreover, to reiterate, our work avoids solving differential equations entirely by relying on unbiased approximations of a one-dimensional integral instead; as we will show, this can result in a dramatic decrease in the number of required function evaluations in training as compared to methods based on adjoints. Moreover, we will show that our approach avoids the numerical instabilities of adjoint methods when they are used to approximate gradients of time averaged quantities over long time intervals for chaotic systems. It is worth mentioning that gradients computed by backpropagation of a forward solver are not consistent with the adjoint ODE in general [26] so we do not consider comparisons to such approaches here.

Weak form methods.Methods for inferring continuous time models of dynamical systems using the weak form of the differential equations were introduced in the context of learning ODEs with linear dependence on the parameters [27; 28]. More recently these methods were adapted for training neural ODEs more quickly than adjoint methods for time-series prediction problems [5]. These methods share some similarities to the present approach in how they achieve a computational speed-up - both methods transform the problem of solving differential equations into a problem of integration. In contrast to the present approach, these methods only allow for one to learn an ODE in the data coordinates (i.e. they do not allow for one to infer an autoencoder and a set of differential equations simultaneously). Moreover, these methods rely on a biased estimate for the weak form residual which will fail when observations become too widely spaced. In contrast, in the present approach, we rely on unbiased approximations to the evidence lower bound. Finally, these methods require the specification of a carefully designed test-space [29] - a consideration not required by our approach.

## 4 Numerical Studies

In this section we provide a number of numerical studies to demonstrate the utility of our approach. In the first study, we show that our approach can be used to train neural SDEs using far fewer evaluations of the model than adjoint methods. In the second study, we consider the problem of parameter tuning for a chaotic system over long time intervals. We show that our approach does not suffer from the numerical instabilities which are known to cause issues with adjoint methods on problems such as these. Finally we close this section with two practical test cases: the first demonstrating competitive performance on a motion capture benchmark and the second showing how our approach can be applied to learn neural SDEs from video. An additional numerical study exploring the effect of the nested Monte Carlo parameter, \(S\), is provided in Appendix H. Details on computing resources are provided Appendix F. All code required to reproduce results and figures is provided at github.com/coursekevin/arlatentsde.

### Orders of magnitude fewer function evaluations in training

In this numerical study we consider the task of building a predictive model from noisy observations of a predator-prey system. We simulated the Lotka-Volterra equations for \(50\) seconds collecting data at a frequency of \(10\)Hz. Observations were corrupted by Gaussian noise with a standard deviation of \(0.01\). Validation data was collected over the time inverval \([50,65]\) seconds. We then attempt to build a predictive model from the data using a neural ODE (NODE) and our method, amortized reparametrization for continuous time auto-encoding (ARCTA), with the same model for the ODE and drift function respectively. To make comparisons with the NODE fair, we set the decoder to be the identity function. We assume the diffusion matrix is constant and place a log-normal prior on its diagonal elements. We approximate the posterior over these elements using a log-normal variational posterior. Details on the architecture and hyperparameters are provided in Appendix G.1. For this experiment, as well as subsequent experiments, we made use of the Adam optimizer [30].

We considered three different tolerances on the NODE adaptive stepping scheme. We trained our model as well as the NODEs using 10 different random seeds while recording the validation RMSE and the number of evaluations of the model. Looking to Figure 2, we see that our approach required more than an order of magnitude fewer evaluations of the model to achieve a similar RMSE on the validation set. This remains true even when the tolerance of the ODE solver is reduced such that the validation RMSE is substantially higher than our approach.

### Numerical instabilities of adjoints

It is well-known that adjoint based methods produce prohibitively large gradients for long time averaged quantities of chaotic systems [10] and accordingly methods, such as least squares shadowing [31], have been introduced to address such concerns. In this section we reproduce this phenomena on a simple parameter tuning problem and show that our approach does not suffer these same issues.

Given the parametric form of the chaotic Lorenz equations,

\[\dot{x} =\sigma(y-x)\] (11) \[\dot{y} =x(\rho-z)-y\] (12) \[\dot{z} =xy-\beta z\] (13)

along with an initial guess for the parameters, \(\sigma_{0}\), \(\rho_{0}\), and \(\beta_{0}\), our goal is to tune the value of parameters such that they align with the observed data.

Figure 2: Lotka-Volterra benchmarking result. In the left figure we see our method (ARCTA) requires more than **one order of magnitude** fewer evaluations of the model (NFE) than the standard neural ODE (NODE) to achieve a similar validation accuracy. In the right figure we have plotted a probabilistic prediction on the test set along with three samples from the predictive distribution.

For this experiment we collect data at a frequency of 200Hz and corrupt observations by Gaussian noise with a covariance of \(1\). We generate five independent datasets over the time intervals \([0,1]\), \([0,10]\), \([0,50]\), and \([0,100]\). For each dataset we generated an initial guess for the parameters by sampling from a Gaussian whose mean is the true value of the parameters and standard deviation is \(20\)% of the mean. For the adjoint methods we report the \(\ell_{2}\)-norm of the gradient with respect to the parameters at the initial guess. For our method (ARCTA) we optimize for \(2000\) iterations (which tended to be enough iterations to successfully converge to a reasonable solution) and report the average gradient across all iterations. Details on hyperparameters and our architecture design are provided in Appendix G.2. Results are summarized in Figure 3. While adjoints expectedly provide prohibitively large gradients as the length of the time series is increased, our approach remains numerically stable.

### Motion capture benchmark

In this experiment we consider the motion capture dataset from [32]. The dataset consists of 16 training, 3 validation, and 4 independent test sequences of a subject walking. Each sequence consists of \(300\) time-series observations with a dimension of \(50\). We made use of the preprocessed data from [34]. Like previous approaches tackling this dataset, we chose a latent dimension of \(6\). We assume a Gaussian observation likelihood. We place a log-normal prior on the diagonal elements of the diffusion matrix and the noise on the observations. We approximate the posterior of the diffusion matrix and observation noise covariance using a log-normal approximate posterior. Details on our architecture design and hyperparameter selection are provided in Appendix G.3.

For our approach, we train 10 models and report their average performance on the test set due to the extremely limited number (4) of independent test sequences. Looking to Figure 4, we see that our approach provided competitive performance on this challenging dataset. This result, in combination with those presented previously demonstrating we require fewer function evaluations for similar

Figure 4: MOCAP benchmarking results, \({}^{\dagger}\) from [34] and \({}^{*}\) from [12]. Our score is computed by training 10 models with different seeds and averaging on the test set. Looking to the table, we see that our method performs similarly to other state-of-the-art methods. The plot shows the predictive posterior on the test set for some select outputs. Other benchmark results were compiled in [34, 12]. RMSE was computed from MSE by taking the square root of the mean and transforming the error via a first-order Taylor-series approximation.

Figure 3: Stability of gradients in chaotic systems. The log-scale on vertical axis shows our approach remains stable for longer time series, while adjoint-based gradients become unusable at \(50\) and \(100\) seconds.

forecasting accuracy and improved gradient stability for chaotic systems, make clear the utility of the present work. It is possible to achieve state-of-the-art performance at a significantly reduced computational cost as compared to adjoint based methods.

### Neural SDEs from video

In this experiment we attempt to learn a latent SDE from video. We generated \(32\times 32\) black and white frames of a nonlinear pendulum as it evolves for \(30\) seconds collecting data at a frequency of \(15\)Hz. We transform the \(1024\) dimensional state down to two dimensions using a convolutional architecture. Details on the hyperparameters and architecture are provided in Appendix G.4. This problem is similar to the problem considered in [3] except the dynamical system we consider is nonlinear. In this prior work, the authors were forced to regularize the latent space so that one set of coordinates resembles a generalized velocity. In the present work, no such regularization is required.

We assume a Bernoulli likelihood on the pixels. Like in previous numerical studies we place a log-normal prior on the diagonals of the diffusion term and approximate the posterior using a log-normal variational distribution. After training we generate a forecast that is visualized in Figure 5. We see that we were successfully able to build a generative model for this simple video. This result demonstrates the broad applicability of the present approach to standard generative modeling tasks.

## 5 Conclusions

Here we have presented a method for constructing unbiased approximations to gradients of the evidence lower bound used to train latent stochastic differential equations with a time and memory cost that scales independently with the amount of data, the length of the time-series, and the stiffness of the model for the latent differential equations. We achieve this result by trading off the numerical precision of adaptive differential equation solvers with Monte-Carlo approximations to expectations using a novel amortization strategy and a recently derived change of variables for expectations under Markov Gaussian processes [13].

We have demonstrated the efficacy of our approach in learning latent SDEs across a range of test problems. In particular we showed that our approach can reduce the number of function evaluations as compared to adjoint methods by more than one order of magnitude in training while avoiding the numerical instabilities of adjoint methods for long time series generated from chaotic systems. In addition, we showed that our approach can be used for generative modeling of a simple video.

In the immediate future, there is significant room for future work in applying variance reduction schemes to the expectation over time to further reduce the total number of required function evaluations. There are also opportunities to explore the utility of the proposed approach for generative modeling on more realistic problems. Finally, there are opportunities to apply our work in the context of implicit densities [35].

Figure 5: Neural SDEs from video. Here we used five frames to estimate the intial state and then forecast in the latent space for 30 seconds. The bottom plot shows the latent SDE. The top row shows 10 samples from the predictive posterior overlaid on the data.

## Acknowledgments and Disclosure of Funding

This research is funded by a grant from NSERC.

## References

* [1] Ricky T. Q. Chen, Yulia Rubanova, Jesse Bettencourt, and David Duvenaud. Neural Ordinary Differential Equations. In _Advances in neural information processing systems_, pages 6571-6583, 2018.
* [2] Sepp Hochreiter and Jurgen Schmidhuber. Long short-term memory. _Neural computation_, 9(8):1735-1780, 1997. Publisher: MIT press.
* [3] Sam Greydanus, Misko Dzamba, and Jason Yosinski. Hamiltonian Neural Networks. In _Advances in Neural Information Processing Systems_, pages 15353-15363, 2019.
* [4] Miles Cranmer, Sam Greydanus, Stephan Hoyer, Peter Battaglia, David Spergel, and Shirley Ho. Lagrangian Neural Networks. In _ICLR 2020 Workshop on Integration of Deep Neural Models and Differential Equations_, 2020.
* [5] Kevin Course, Trefor Evans, and Prasanth B. Nair. Weak Form Generalized Hamiltonian Learning. In _Advances in Neural Information Processing Systems_, volume 33, pages 18716-18726, 2020.
* [6] Emmanuel Lorin. Derivation and analysis of parallel-in-time neural ordinary differential equations. _Annals of Mathematics and Artificial Intelligence_, 88:1035-1059, 2020. Publisher: Springer.
* [7] Jacob Kelly, Jesse Bettencourt, Matthew J Johnson, and David K Duvenaud. Learning differential equations that are easy to solve. _Advances in Neural Information Processing Systems_, 33:4370-4380, 2020.
* [8] Chris Finlay, Jorn-Henrik Jacobsen, Levon Nurbekyan, and Adam Oberman. How to train your neural ODE: the world of Jacobian and kinetic regularization. In _International conference on machine learning_, pages 3154-3164, 2020.
* [9] Patrick Kidger, Ricky T. Q. Chen, and Terry J Lyons. "Hey, that's not an ODE": Faster ODE Adjoints via Seminorms. In _Proceedings of the 38th International Conference on Machine Learning_, volume 139 of _Proceedings of Machine Learning Research_, pages 5443-5452, July 2021.
* [10] Daniel J Lea, Myles R Allen, and Thomas WN Haine. Sensitivity analysis of the climate of a chaotic system. _Tellus A: Dynamic Meteorology and Oceanography_, 52(5):523-532, 2000. Publisher: Taylor & Francis.
* [11] Yulia Rubanova, Tian Qi Chen, and David K Duvenaud. Latent Ordinary Differential Equations for Irregularly-Sampled Time Series. In _Advances in Neural Information Processing Systems_, pages 5321-5331, 2019.
* [12] Xuechen Li, Ting-Kam Leonard Wong, Ricky T. Q. Chen, and David Duvenaud. Scalable Gradients for Stochastic Differential Equations. In Silvia Chiappa and Roberto Calandra, editors, _Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics_, volume 108 of _Proceedings of Machine Learning Research_, pages 3870-3882, August 2020.
* [13] Kevin Course and Prasanth B. Nair. State estimation of a physical system with unknown governing equations. _Nature_, 622(7982):261-267, October 2023.
* [14] Mike Giles and Paul Glasserman. Smoking adjoints: Fast monte carlo greeks. _Risk_, 19(1):88-92, 2006.
* [15] Diederik P Kingma and Max Welling. Auto-Encoding Variational Bayes. In _International Conference on Learning Representations_, 2014.
* [16] Matthew D Hoffman, David M Blei, Chong Wang, and John Paisley. Stochastic variational inference. _The Journal of Machine Learning Research_, 14(1):1303-1347, 2013. Publisher: JMLR. org.
* [17] Peter Toth, Danilo J. Rezende, Andrew Jaegle, Sebastien Racaniere, Aleksandar Botev, and Irina Higgins. Hamiltonian Generative Networks. In _International Conference on Learning Representations_, 2020.
* [18] James Glimm and David Sharp. Stochastic Partial Differential Equations: Selected Applications In Continuum Physics. In _Stochastic Partial Differential Equations: Six Perspectives, Mathematical Surveys and Monographs_, pages 3-44. American Mathematical Society, 1997.

* Sarkka and Solin [2019] Simo Sarkka and Arno Solin. _Applied stochastic differential equations_, volume 10. Cambridge University Press, 2019.
* Archambeau et al. [2007] Cedric Archambeau, Dan Cornford, Manfred Opper, and John Shawe-Taylor. Gaussian process approximations of stochastic differential equations. In _Gaussian Processes in Practice_, pages 1-16. PMLR, 2007.
* Archambeau et al. [2007] Cedric Archambeau, Manfred Opper, Yuan Shen, Dan Cornford, and John Shawe-taylor. Variational Inference for Diffusion Processes. In _Advances in Neural Information Processing Systems_, volume 20. Curran Associates, Inc., 2007.
* Vaswani et al. [2017] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. _Advances in neural information processing systems_, 30, 2017.
* Barfoot [2017] Timothy D. Barfoot. _State estimation for robotics a matrix Lie group approach_. Cambridge University Press, Cambridge, United Kingdom, 2017. ISBN 978-1-107-15939-6.
* Barfoot et al. [2020] Timothy D Barfoot, James R Forbes, and David J Yoon. Exactly sparse Gaussian variational inference with application to derivative-free batch nonlinear state estimation. _The International Journal of Robotics Research_, 39(13):1473-1502, 2020. Publisher: SAGE Publications Sage UK: London, England.
* Rezende and Mohamed [2015] Danilo Rezende and Shakir Mohamed. Variational inference with normalizing flows. In _International conference on machine learning_, pages 1530-1538. PMLR, 2015.
* Alexe and Sandu [2009] Mihai Alexe and Adrian Sandu. On the discrete adjoints of adaptive time stepping algorithms. _Journal of computational and applied mathematics_, 233(4):1005-1020, 2009. ISSN 0377-0427. doi: 10.1016/j.cam.2009.08.109. Place: Kidlington Publisher: Elsevier B.V.
* Schaeffer and McCalla [2017] Hayden Schaeffer and Scott G. McCalla. Sparse model selection via integral terms. _Physical Review E_, 96(2):023302, August 2017. doi: 10.1103/PhysRevE.96.023302.
* Pantazis and Tsamardinos [2019] Yannis Pantazis and Ioannis Tsamardinos. A unified approach for sparse dynamical system inference from temporal measurements. _Bioinformatics_, 35(18):3387-3396, September 2019. ISSN 1367-4803. doi: 10.1093/bioinformatics/btz065.
* Messenger and Bortz [2021] Daniel A Messenger and David M Bortz. Weak SINDy: Galerkin-based data-driven model selection. _Multiscale Modeling & Simulation_, 19(3):1474-1497, 2021. Publisher: SIAM.
* Kingma and Ba [2015] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In _International Conference on Learning Representations_, 2015.
* Wang et al. [2014] Qiqi Wang, Rui Hu, and Patrick Blonigan. Least squares shadowing sensitivity analysis of chaotic limit cycle oscillations. _Journal of Computational Physics_, 267:210-224, 2014. Publisher: Elsevier.
* Gan et al. [2015] Zhe Gan, Chunyuan Li, Ricardo Henao, David E Carlson, and Lawrence Carin. Deep temporal sigmoid belief networks for sequence modeling. _Advances in Neural Information Processing Systems_, 28, 2015.
* Heinonen et al. [2018] Markus Heinonen, Cagatay Yildiz, Henrik Mannerstrom, Jukka Intosalmi, and Harri Lahdesmaki. Learning unknown ODE models with Gaussian processes. In _International Conference on Machine Learning_, pages 1959-1968. PMLR, 2018.
* Yildiz et al. [2019] Cagatay Yildiz, Markus Heinonen, and Harri Lahdesmaki. ODE2VAE: Deep generative second order ODEs with Bayesian neural networks. _Advances in Neural Information Processing Systems_, 32, 2019.
* Kidger et al. [2021] Patrick Kidger, James Foster, Xuechen Li, and Terry J Lyons. Neural sdes as infinite-dimensional gans. In _International Conference on Machine Learning_, pages 5453-5463. PMLR, 2021.
* Wilson et al. [2016] Andrew Gordon Wilson, Zhiting Hu, Ruslan Salakhutdinov, and Eric P Xing. Deep kernel learning. In _Artificial intelligence and statistics_, pages 370-378. PMLR, 2016.
* Paszke et al. [2019] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. PyTorch: An Imperative Style, High-Performance Deep Learning Library. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d' Alche-Buc, E. Fox, and R. Garnett, editors, _Advances in Neural Information Processing Systems 32_, pages 8024-8035. Curran Associates, Inc., 2019.

Appendices

## Appendix A Expectations under linear SDEs

In this section we re-derive a result from [13] regarding how to rewrite expectations under linear stochastic differential equations. As we will explain in greater detail in Appendix B, it is this result that allowed [13] to rewrite the ELBO entirely in terms of quantities that do not require differential equation solvers.

**Theorem 1**.: _Consider the density, \(q(z(t))\), of the solution to a linear SDE \(dz=(-A(t)z+b(t))dt+L(t)d\beta\) with initial condition \(z_{0}\sim\mathcal{N}(m_{0},S_{0})\), where \(A:\mathbb{R}\to\mathbb{R}^{d\times d}\) is symmetric, \(b:\mathbb{R}\to\mathbb{R}^{d}\), \(L:\mathbb{R}\to\mathbb{R}^{d\times d}\), and \(\beta\) indicates Brownian motion with diffusion matrix \(\Sigma\). Then the expected value of a bounded functional, \(f\), satisfies_

\[\mathbb{E}_{z(t)\sim q(z(t))}\left[f(A(t),b(t),z(t))\right]=\mathbb{E}_{z(t) \sim\mathcal{N}(m(t),S(t))}\left[f(B(t),\dot{m}(t)+B(t)m(t),z(t))\right],\] (14)

_where \(B(t)=\text{vec}^{-1}((S(t)\oplus S(t))^{-1}\text{vec}(L(t)\Sigma L(t)^{T}- \dot{S}(t)))\) and \(m(t)\) and \(S(t)\) indicate the mean and covariance, respectively, of the SDE solution at time \(t\)._

Proof.: The solution of a linear SDE defines a Markov Gaussian process with marginal statistics, \(q(z(t))\sim\mathcal{N}(m(t),S(t))\), given by the solution to the ODEs,

\[\dot{m}(t) =(-A(t)m(t)+b(t)),\] (15) \[\dot{S}(t) =-A(t)S(t)-S(t)A(t)^{T}+L(t)\Sigma L(t)^{T},\] (16)

with initial condition \(m(0)=m_{0}\), \(S(0)=S_{0}\)[19]. Noticing that equation (16) defines a set of matrix Lyapunov equations in terms of \(A(t)\) allows us to express \(A(t)\) as a function of \(S(t)\) as follows,

\[A(t)=\text{vec}^{-1}\left((S(t)\oplus S(t))^{-1}\text{vec}(L(t)\Sigma L(t)^{T} -\dot{S}(t))\right),\] (17)

where \(\oplus\) is called the Kronecker sum and is defined as \(S\oplus S=I\otimes S+S\otimes I\) and \(\otimes\) indicates the standard Kronecker product. Letting \(B(t)=A(t)\) be the expression for \(A(t)\) written in terms of \(S(t)\), we can rearrange Equation (15) to solve for \(b(t)\) as,

\[b(t)=\dot{m}(t)+B(t)m(t).\] (18)

Substituting the expressions for \(A(t)\) and \(b(t)\) into Equation (14) yields the desired result. 

RemarkIn the case that \(S(t)\) and \(L(t)\Sigma L(t)^{T}\) are diagonal as we assume throughout this work, Equation 17 simplifies to,

\[A(t)=\frac{1}{2}S(t)^{-1}(L(t)\Sigma L(t)^{T}-\dot{S}(t)).\] (19)

## Appendix B Evidence lower bound derivation

Given a dataset of observations, \(\mathcal{D}=\left\{(x_{i},t_{i})\right\}_{i=1}^{N}\), a generative likelihood, \(p_{\theta}(x\mid z(t_{i}))\) a prior SDE, \(dz=f_{\theta}(z(t),t)dt+L_{\theta}(t)d\beta\), and an approximation to the posterior of the latent state, \(dz=(-A_{\phi}(t)z(t)+b_{\phi}(t))dt+L_{\theta}(t)d\beta\), it is possible to derive the ELBO [20; 12],

\[\begin{split}\mathcal{L}(\theta,\phi)=&\sum_{i=1}^ {N}\mathbb{E}_{z(t_{i})\sim q_{\phi}(z(t))}\left[\log p_{\theta}(x_{i}\mid z( t_{i}))\right]\\ &-\frac{1}{2}\int_{0}^{T}\mathbb{E}_{z(t)\sim q_{\phi}(z(t))} \left[||-A_{\phi}(t)z(t)+b(t)-f_{\theta}(z(t),t)||_{\mathcal{C}_{\theta}(t)} ^{2}\right]\,dt,\end{split}\] (20)

[MISSING_PAGE_FAIL:14]

generative variables, \(\theta=V(\nu,\phi)\) where \(\nu\sim p(\nu)\implies\theta\sim q_{\phi}(\theta)\). Then, building on Lemma 1, we can arrive at an unbiased estimate for the gradient of the modified ELBO which inherits all the properties discussed with the original approximation:

\[\nabla_{\phi}\mathcal{L}(\phi)\approx \frac{N}{R}\sum_{i=1}^{M}\sum_{k=1}^{R}\nabla_{\phi}\log p_{V(\nu^ {(k)},\phi)}(x_{i}^{(j)}\mid T(t_{i}^{(j)},\epsilon^{(k)},\phi))\] (25) \[-(t_{1}^{(j+1)}-t_{1}^{(j)})\frac{N}{2R}\sum_{k=1}^{R}\nabla_{\phi }||r_{V(\nu^{(k)},\phi),\phi}(T(t^{(k)},\epsilon^{(k)},\phi),t^{(k)})||_{C_{V( \nu^{(k)},\phi)}(t)}^{2}\] \[-D_{KL}(q_{\phi}(\theta)\mid\mid p(\theta)).\]

where each \(t^{(k)}\sim\mathcal{U}(t_{1}^{(j)},t_{1}^{(j+1)})\), each \(\epsilon^{(k)}\sim\mathcal{N}(0,I)\), and each \(\nu^{(k)}\sim p(\nu)\).

## Appendix D Detailed description of recognition network

This section details the deep kernel based encoder we used in all numerical studies. We found this particular encoding architecture to be useful for our purposes because it is interpretable and stable in training. With this being said, any encoder which can transform a batch of observations down to a reduced dimension latent state can be used in combination with Lemma 1 to arrive at an unbiased estimate for the gradient of the ELBO which retains all the properties discussed in the main body of this work.

Given a dataset, \(\mathcal{D}=\{(t_{i},x_{i})\}_{i=1}^{N}\), recall that the first step in our amortization strategy is to split the dataset into \(N/M\) non-overlapping partitions,

\[\begin{split}\text{original indexing:}&[t_{1},\ t_{2},\ \ldots,t_{M},t_{M+1},\ldots,t_{N}\quad]\\ \text{reindexed dataset:}&[t_{1}^{(1)},t_{2}^{(1)}, \ldots,t_{M}^{(1)},t_{1}^{(2)},\ldots,\ t_{M}^{(N/M)}]\end{split}\]

Recall that we would like to approximate the latent state over each partition using only the \(M\) observations in each partition, \(q_{\phi}(z(t)\mid x_{1}^{(j)},x_{2}^{(j)},\ldots,x_{M}^{(j)})\approx p(z(t) \mid\mathcal{D})\) for \(t\in[t_{1}^{(j)},t_{1}^{(j+1)}]\). Going forward we will drop writing the superscript as we will be only working on a single partition, \((t_{1},x_{1}),(t_{2},x_{2}),\ldots(t_{M},x_{M})\). The user first selects how many snapshots into the future they would like to use to estimate the latent state at the present time, \(K\); in our own studies we found choosing \(K\in[1,5]\) worked well for the problems we considered.

Given some encoding network, \(\text{ENC}_{\phi}\), we compute:

\[h_{i}=\text{ENC}_{\phi}(x_{i},x_{i+1},\ldots,x_{i+K}).\] (26)

where \(h_{i}\in\mathbb{R}^{2d}\) with \(d<D\). We will describe the particular architecture design for \(\text{ENC}_{\phi}\) in the context of each numerical study in Appendix G. We note that for our approach, it is often important to use at least a small number of neighbours (i.e. \(K>0\)) when estimating the latent state because we are limited to approximating MGPs over the latent state.

To explain this point more clearly, let us consider the example of inferring a latent SDE using video of a pendulum as we did in Section 4.4. If we choose a single frame near the center, we have no way of knowing from that frame alone if the pendulum is currently swinging left or right. In other words, if we were to build an encoder which takes in one single frame, the encoder should predict that the posterior given that single frame is multimodal. As our approach only allows for one to approximate the latent state using MGPs, this is not an option. Allowing the encoder to take in a few frames at a time remedies this issue. We also note that previous works for inferring latent differential equations made this same choice [1, 11, 12, 17].

Recall that we need to approximate the latent state at any time over the window of observations in the partition, \(t\in[t_{1}^{(j)},t_{1}^{(j+1)}]\). To accomplish this we effectively interpolate between encodings using a deep kernel [36]. Letting,

\[H=\begin{bmatrix}h_{1}^{T}\\ h_{2}^{T}\\ \vdots\\ h_{M}^{T}\end{bmatrix},\] (27)where \(H\in\mathbb{R}^{M\times 2d}\) and \(t_{\text{node}}=[t_{i},t_{1},\ldots,t_{M}]\), we construct the encoder for the mean and diagonal of the covariance over the latent state as,

\[\big{[}m_{\phi}(t)^{T}\quad\log S_{\phi}(t)^{T}\big{]}=k_{\phi}(t,t_{\text{node }})^{T}(k_{\phi}(t_{\text{node}},t_{\text{node}})^{-1}+\sigma_{n}^{2}I)^{-1}H.\] (28)

Here we note that the right hand side of (28) is a row vector of length \(2d\). We use the notation \(\big{[}m_{\phi}(t)^{T}\quad\log S_{\phi}(t)^{T}\big{]}\) to indicate that \(m_{\phi}(t)\) is given by the first \(d\) elements of this vector and \(\log S_{\phi}(t)\) is given by the next \(d\) elements. Here \(k_{\phi}\) is a so-called deep kernel and \(k_{\phi}(t,t_{\text{node}})\in\mathbb{R}^{M}\) and \(k_{\phi}(t_{\text{node}},t_{\text{node}})\in\mathbb{R}^{M\times M}\). In addition \(\sigma_{n}\in\mathbb{R}^{+}\) is tuned as a part of the optimization procedure. While many options for the base kernel are possible, we made use of a squared exponential kernel,

\[k_{\phi}(t,t_{*})=\sigma_{f}\exp\left(-\frac{||\text{DK}_{\phi}(t)-\text{DK}_{ \phi}(t_{*})||^{2}}{2\ell^{2}}\right),\] (29)

where \(\sigma_{f},\ell\in\mathbb{R}^{+}\) are positive constants tuned as a part of the optimization procedure and DK\({}_{\phi}\) is a neural network whose architecture we will describe in the context of the numerical studies. While the base kernel is stationary, the neural networks allow for the encoder to infer non-stationary relationships [36]. It is worth noting that without this deep-kernel our approach struggled to achieve good validation accuracy on the datasets we considered.

Advantages of this encoder design are that it can easily take in varying amounts of data, it is interpretable because \([m_{\phi}(t_{i})^{T}\log S_{\phi}(t_{i})^{T}]\approx h_{i}^{T}\), and it is cheap to compute so long as \(M\) is relatively small because evaluations of ENC\({}_{\phi}\) can be performed in parallel. Particular choices for ENC\({}_{\phi}\) and DK\({}_{\phi}\) are described in context in Appendix G.

## Appendix E Approximate posterior on diffusion term

This section summarizes the log-normal parameterization we used to approximate the posterior over the diagonal drift function terms in the main body of the paper. First, we note that in the loss function we only require access to the product, \(C_{\theta}(t)^{-1}=L_{\theta}(t)\Sigma L_{\theta}(t)^{T}\) so, rather than parametrizing \(L_{\theta}\) on its own, we parametrize \(C_{\theta}^{-1}\).

Specifically we parametrize \(C_{\theta}(t)^{-1}=\text{diag}(\theta)\), where \(\theta\in\mathbb{R}^{d}\). The prior is defined as,

\[p(\theta)=\prod_{i=1}^{d}\mathcal{LN}(\theta_{i}\mid\tilde{\mu}_{i},\tilde{ \sigma}_{i}^{2}).\] (30)

We parametrize the approximate posterior as,

\[q_{\phi}(\theta)=\prod_{i=1}^{d}\mathcal{LN}(\theta_{i}\mid\mu_{i},\sigma_{i} ^{2}),\] (31)

where \(\mu_{i}\) and \(\sigma_{i}\) are the variational parameters. The KL divergence between the posterior and prior is given by,

\[D_{KL}(q_{\phi}(\theta)\mid\mid p(\theta))=\sum_{i=1}^{d}(\log\tilde{\sigma}_ {i}-\log\sigma_{i})-\frac{1}{2}\left(d-\sum_{i=1}^{d}\frac{\sigma_{i}^{2}-( \mu_{i}-\tilde{\mu}_{i})^{2}}{\tilde{\sigma}_{i}^{2}}\right).\] (32)

## Appendix F Computing resources

Experiments were performed on an Ubuntu server with a dual E5-2680 v3 with a total of 24 cores, 128GB of RAM, and an NVIDIA GeForce RTX 4090 GPU. The majority of our code is written in PyTorch [37]. For benchmarking we made use of torchdiffeq[1], torchsde[12, 35], and pytorch_lightning. All code is available at github.com/coursekevin/arlatientsde.

## Appendix G Details on numerical studies

This section contains more details on the numerical studies including the specific architecture design and hyperparameter selection for each experiment. For each experiment we design an encoderconsisting of two neural networks, \(\text{ENC}_{\phi}(x_{i},\dots,x_{i+K})\) and \(\text{DK}_{\phi}(t)\) (see Appendix D), a decoder \(\text{DEC}_{\theta}(z(t))\), and a model for the SDE consisting of a drift, \(f_{\theta}(t,z)\), and dispersion matrix, \(L_{\theta}(t)\). For all numerical studies we place a log-normal prior on the dispersion matrix and assume that the approximate posterior is constant in time, see Appendix E. For all experiments we gradually increased the value of the KL-divergence (both the KL-divergence due to the SDE prior and the KL-divergence on the dispersion matrix parameters) from \(0\) to \(1\) using a linear schedule.

### Orders of magnitude fewer function evaluations

In this section we provide a more detailed description of the numerical study in Section 4.1. As a reminder, we tasked a neural ODE (NODE) and our approach with building a predictive model for the Lotka-Volterra system given a dataset of time-series observations. The Lotka-Volterra equations are a system of nonlinear ODEs usually written as,

\[\begin{split}\dot{x}&=\alpha x-\beta xy,\\ \dot{y}&=\delta xy-\gamma y.\end{split}\] (33)

In our experiment we chose \(\alpha=2/3\), \(\beta=4/3\), and \(\delta=\gamma=1\). We also assumed that there was some small amount of Brownian noise given by \(\Sigma=\text{diag}(10^{-3},10^{-3})\). Using the initial condition \(x=0.9\) and \(y=0.2\), we draw a sample from the system using the default adaptive stepping scheme in torchsde from time \(0\) to \(65\) with an initial step size of \(0.1\) and an absolute and relative tolerance of \(10^{-5}\). We then evaluate the solution at a frequency of \(50\)Hz and added Gaussian noise with a standard deviation of \(0.01\). We use the first \(50\) seconds for training and reserve the remaining \(15\) seconds for validation.

Both the NODE and our approach use the same model for the gradient field and drift function respectively, see Figure 5(a). The encoder and deep kernel architecture are provided in Figures 5(b) and 5(c) respectively. As mentioned in the main body of the paper, we set the decoder to be the identity function so as to force our model to learn the dynamics in the original coordinates. We selected a Gaussian likelihood with a constant standard deviation of \(0.01\).

In terms of hyperparameters we set the schedule on the KL-divergence to increase from \(0\) to \(1\) over \(1000\) iterations. We choose a learning rate of \(10^{-3}\) with exponential learning rate decay where the learning rate was decayed \(lr=\gamma lr\) every iteration with \(\gamma=\exp(\log(0.9)/1000)\) (i.e. the effective rate of learning rate decay is \(lr=0.9lr\) every \(1000\) iterations.). We used the nested Monte-Carlo approximation described in Equation (10) with \(R=1\), \(S=10\), and \(M=256\). In terms of kernel parameters, we initialized \(\ell=10^{-2}\), \(\sigma_{f}=1\), and \(\sigma_{n}=10^{-5}\). In terms of the diffusion term, set \(\mu_{i}=\sigma_{i}=10^{-5}\) and \(\tilde{\mu}_{i}=\tilde{\sigma}_{i}=1\).

### Adjoint instabilities experiment

In this section, we provide some additional details of the numerical study described in Section 4.2. Recall the parametric model for the Lorenz system in equations (11-13). As a reminder, given time-series dataset of observations, our goal was to infer the value of the parameters, \(\sigma\), \(\beta\), \(\rho\), which were likely to have generated the data starting from an initial guess: \(\theta_{0}=[\sigma_{0}\), \(\beta_{0}\), \(\rho_{0}]\). The true value of the parameters was chosen as \(\theta_{*}=[10,8/3,28]\). For all experiments we used the initial condition \([8,-2,36.05]\) as was suggested in [10]. We generated data by solving the differential equation using scipy's RK4(5) initial value problem solver with a relative and absolute tolerance of \(10^{-6}\) and \(10^{-8}\) respectively. We generated data at a frequency of \(200\)Hz over the time intervals \([0,1]\), \([0,10]\), \([0,50]\), and \([0,100]\). For each time interval we generated 5 datasets by adding independent Gaussian noise with a variance of 1 to the data.

To arrive at an initial guess we sample from the distribution \(\theta_{0}\sim\mathcal{N}(\theta_{*},(0.2\theta_{*})^{2})\). For each time series length we tasked our approach with inferring the true value of the parameters given 5 different guesses for the initial condition (i.e. one guess / dataset). The reported gradients for our approach are given by the average \(\ell_{2}\)-norm of the gradient of the ELBO with respect to the parameters \(\sigma\), \(\beta\), and \(\rho\) after optimizing for 2000 iterations. For the adjoint method, we report the gradient of the function:

\[\mathcal{L}(\theta)=\frac{1}{3N}\sum_{i=1}^{N}(x_{i}-x_{\theta}(t_{i}))^{2}+(y _{i}-y_{\theta}(t_{i}))^{2}+(z_{i}-z_{\theta}(t_{i}))^{2},\] (34)Figure 6: Architecture diagrams for the drift, deep kernel, and encoder used in the Lotka-Volterra problem are provided in Figures (a), (b), and (c) respectively. Note that we have used the shorthand \(m(t_{i})\), \(\log S(t_{i})\) to show how we have split the columns of \(h_{i}\) in two. The value of \([m(t_{i}),\log S(t_{i})]\) only \(\approx h_{i}\) unless \(\sigma_{n}=0\), see Appendix D. Note the arrow from \(x_{i}\) to \(m(t_{i})\) indicates a residual connection (which was useful in this case because we are learning a SDE in the original data coordinates).

Figure 7: Architecture diagrams for the deep kernel and encoder used in the Lorenz system parameter tuning problem are provided in Figures (a) and (b) respectively. Note that we have used the shorthand \(m(t_{i})\), \(\log S(t_{i})\) to show how we have split the columns of \(h_{i}\) in two. The value of \([m(t_{i}),\log S(t_{i})]\) only \(\approx h_{i}\) unless \(\sigma_{n}=0\), see Appendix D. Note the arrow from \(x_{i}\) to \(m(t_{i})\) indicates a residual connection (which was useful in this case because we are learning a SDE in the original data coordinates).

at the starting iteration. Note we cannot provide average gradients over the entire optimization procedure for the adjoint based method because the initial gradients are too large when the time interval was \([0,50]\) or \([0,100]\). The error bars are given by one standard deviation from the mean.

A description of the encoder architecture is provided in Figure 7. As was the case in the previous experiment, we set the decoder to be the identity function and placed a log-normal prior on the diffusion term.

In terms of hyperparameters, we choose \(M=128\), \(R=10\), and \(S=100\). We selected a learning rate of \(0.1\) and decayed the learning rate \(lr=\gamma lr\) every iteration with \(\gamma=\exp(\log(0.9)/1000)\). We linearly increased the value of the KL-divergence from \(0\) to \(1\) over the course of 100 iterations. In terms of kernel parameters we initialized \(\sigma_{f}=1\), \(\ell=10^{-2}\), and \(\sigma_{n}=10^{-5}\). For the diffusion term, we set \(\mu_{i}=\sigma_{i}=10^{-5}\) and \(\tilde{\mu}_{i}=\tilde{\sigma}_{i}=10^{-5}\).

### MOCAP experiment

For this experiment we use the preprocessed dataset provided by [34].

Like in previous examples, we place a log-normal prior on the diffusion term. Like previous works making use of the benchmark, we assume a Gaussian likelihood. We place a log-normal prior on the variance of the likelihood. A description of the architecture is provided in Figure 8. Note that the architecture we chose is very similar to the architecture used by [34, 12].

In terms of hyperparameters, we chose a batch size of 512. We used a linear schedule to update the weighting on the KL-divergence from \(0\) and \(1\) over the course of \(200\) iterations. We make use of the nested Monte-Carlo scheme in equation (10) with \(R=10\) and \(S=10\). We chose a learning rate of \(0.01\) and decayed the learning rate each iteration according to the schedule \(lr=\gamma lr\) with \(\gamma=\exp(\log(0.9)/1000)\). In terms of kernel parameters, we initialize \(\sigma_{n}=10^{-5}\), \(\ell=10^{-2}\), and \(\sigma_{f}=1\). In terms of the prior on the diffusion term we initialize \(\mu_{i}=\sigma_{i}=10^{-5}\) and set \(\tilde{\mu}_{i}=\tilde{\sigma}_{i}=1\). In terms of the prior on the variance of the observations, we initialize \(\mu_{i}=\sigma_{i}=10^{-2}\) and set \(\tilde{\mu}_{i}=\tilde{\sigma}_{i}=1\). We considered both Softplus [12] and tanh [34] nonlinearities and found that tanh nonlinearities provided improved validation performance. We train for \(100\) epochs testing validation accuracy every 10 epochs. We report the average test accuracy after training 10 models from different random seeds.

Previous studies tended to report mean-squared-error as, MSE \(\pm\) ERROR. We report RMSE \(\pm\) NEW ERROR so that error units are consistent with the units of the original dataset. To convert MSE to RMSE we used a first-order Taylor-series approximation,

RMSE \[=\sqrt{\text{MSE}}\] (35) NEW ERROR \[=\frac{1}{2}\text{ERROR}/\text{RMSE}\]

### Neural SDE from video

In this section, we provide a more detailed description on the numerical study described in Section 4.4. We generated data by simulating a nonlinear pendulum with the equations,

\[\dot{x} =p\] (36) \[\dot{p} =-\sin(x),\]

for \(30\) seconds while sampling the state at a frequency of 15Hz. The architecture we used for this experiment is provided in Figure 9.

In terms of hyperparameters, we chose a batch size of 128. We gradually increased the weighting of the KL-divergence term using a linear schedule over the course of \(1000\) iterations. We used the nested Monte-Carlo method suggested in Equation 10 and set \(R=20\) and \(S=10\). We chose a learning rate of \(0.001\) and decayed the learning rate each iteration according to the schedule \(lr=\gamma lr\) with \(\gamma=\exp(\log(0.9)/1000)\). In terms of kernel parameters, we initialized \(\sigma_{f}=1\), \(\sigma_{n}=10^{-5}\), and \(\ell=10^{-2}\). We placed a log-normal prior on the diffusion term and approximated the posterior using log-normal variational distribution. With regards to the prior on the diffusion term we initialize \(\mu_{i}=\sigma_{i}=0.1\) and set \(\tilde{\mu}_{i}=\tilde{\sigma}_{i}=10^{-5}\).

## 6 Conclusion

Figure 8: Architecture diagrams for the encoder, decoder, deep kernel and drift function used in the MOCAP benchmark. We used very similar architectures to [34, 12]. Here \(\mu(t)\) indicates the mean of the likelihood, \(p_{\theta}(x\mid z(t))\).

Figure 9: Architecture diagrams for the encoder, decoder, deep kernel and drift function used in the Neural SDE from video example.

Numerical study on the effect of Monte-Carlo parameters

In this study we investigate the effect of varying the number of nested Monte Carlo samples on the rate of validation RMSE convergence. To do so, we consider the problem of building a predictive model for a four-dimensional predator-prey system. The system consists of two predators and two prey where there is a competitive dynamic between the predators. The equations governing the dynamics of the system are,

\[\dot{x}_{1} =x_{1}\left(\alpha_{1}-\beta_{1}y_{1}-\gamma_{1}y_{2}\right)\left( 1-\frac{x_{1}}{k_{1}}\right),\] (37) \[\dot{x}_{2} =x_{2}\left(\alpha_{2}-\beta_{2}y_{1}-\gamma_{2}y_{2}\right)\left( 1-\frac{x_{2}}{k_{2}}\right),\] (38) \[\dot{y}_{1} =y_{1}\left(-\delta_{1}+\epsilon_{1}x_{1}+\xi_{1}x_{2}-\nu_{1}y_{ 2}\right),\] (39) \[\dot{y}_{2} =y_{2}\left(-\delta_{2}+\epsilon_{2}x_{1}+\xi_{2}x_{2}+\nu_{2}y_{ 1}\right),\] (40)

where \(\alpha_{i}\) is the grow rate of the prey \(x_{i}\), \(\beta_{i}\) is the rate that predator \(y_{1}\) is consuming prey \(x_{i}\), \(\gamma_{i}\) is the rate that predator \(y_{2}\) is consuming prey \(x_{i}\), \(k_{i}\) is the carrying capacity for prey \(x_{i}\), \(\delta_{i}\) is the death rate of predator \(y_{i}\), \(\epsilon_{i}\) is the conversion rate for predator \(y_{i}\) from \(x_{1}\), \(\xi_{i}\) is the conversion rate for predator \(y_{i}\) from prey \(x_{2}\), and \(\nu_{i}\) represents the competitive effects on \(y_{i}\) caused by the other predator.

We simulated the system for 300 units of time collecting data at a frequency of 10Hz. We assume a Gaussian noise with a standard deviation of \(10^{-2}\). For all experiments we used the following hyperparameters: a batch size of \(256\), \(1000\) warmup iterations, and a learning rate of \(10^{-3}\). In terms of kernel parameters, we initialized \(\sigma_{f}=1\), \(\ell=10^{-2}\), and \(\sigma_{n}=10^{-5}\). For the diffusion term we set \(\mu_{i}=\sigma_{i}=10^{-5}\) and \(\tilde{\mu}_{i}=\tilde{\sigma}_{i}=1\). The architecture description for the neural networks used in this example are provided in Figure 11.

Results are summarized in Figure 10 below. On this problem we find we are able to achieve a reasonable validation accuracy for \(S=10\), \(S=50\), and \(S=100\); however, it is challenging to know beforehand what gradient variance will be acceptable for a particular data set. We see that increasing \(S\) increases the total number of function evaluations. Note that the total number of parallel evaluations of the forward model in all cases remains constant.

Figure 10: Validation RMSE versus iteration (L) and number of function evaluations (R).

Figure 11: Architecture diagrams for the encoder, deep kernel and drift function used in the Monte-Carlo parameters study.