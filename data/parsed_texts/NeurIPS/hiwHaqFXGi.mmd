# Disentangled Generative Graph Representation Learning

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

Recently, generative graph models have shown promising results in learning graph representations through self-supervised methods. However, most existing generative graph representation learning (GRL) approaches rely on random masking across the entire graph, which overlooks the entanglement of learned representations. This oversight results in non-robustness and a lack of explainability. Furthermore, disentangling the learned representations remains a significant challenge and has not been sufficiently explored in GRL research. Based on these insights, this paper introduces **DiGGR** (**D**isentangled **G**enerative **G**raph **R**epresentation Learning), a self-supervised learning framework. DiGGR aims to learn latent disentangled factors and utilizes them to guide graph mask modeling, thereby enhancing the disentanglement of learned representations and enabling end-to-end joint learning. Extensive experiments on 11 public datasets for two different graph learning tasks demonstrate that DiGGR consistently outperforms many previous self-supervised methods, verifying the effectiveness of the proposed approach.

## 1 Introduction

Self-supervised learning (SSL) has received much attention due to its appealing capacity for learning data representation without label supervision. While contrastive SSL approaches are becoming increasingly utilized on images (Chen et al., 2020) and graphs (You et al., 2020), generative SSL has been gaining significance, driven by groundbreaking practices such as BERT for language (Devlin et al., 2018), BEiT (Bao et al., 2021), and MAE (He et al., 2022) for images. Along this line, there is a growing interest in constructing generative SSL models for other modalities, such as graph masked autoencoders (GMAE). Generally, the fundamental concept of GMAE (Tan et al., 2022) is to utilize an autoencoder architecture to reconstruct input node features, structures, or both, which are randomly masked before the encoding step. Recently, various well-designed GMAEs have emerged, achieving remarkable results in both node classification and graph classification (Hou et al., 2022; Tu et al., 2023; Tian et al., 2023).

Despite their significant achievements, most GMAE approaches typically treat the entire graph as holistic, ignoring the graph's latent structure. As a result, the representation learned for a node tends to encapsulate the node's neighborhood as a perceptual whole, disregarding the nuanced distinctions between different parts of the neighborhood (Ma et al., 2019; Li et al., 2021; Mo et al., 2023). For example, in a social network \(\bar{G}\), individual \(n\) is a member of both a mathematics group and several sports interest groups. Due to the diversity of these different communities, she may exhibit different characteristics when interacting with members from various communities. Specifically, the information about the mathematics group may be related to her professional research, while the information about sports clubs may be associated with her hobbies. However, the existing approach overlooks the heterogeneous factors of node \(n\), failing to identify and disentangle these pieces ofinformation effectively (Hou et al., 2022). Consequently, the learned features may be easily influenced by irrelevant factors, resulting in poor robustness and difficulty in interpretation.

To alleviate the challenge described above, there is an increasing interest in disentangled graph representation learning (Bengio et al., 2013; Li et al., 2021; Ma et al., 2019; Mo et al., 2023; Xiao et al., 2022), which aims at acquiring representations that can disentangle the underlying explanatory factors of variation in the graph. Specifically, many of these methods rely on a latent factor detection module, which learns the latent factors of each node by comparing node representations with various latent factor prototypes. By leveraging these acquired latent factors, these models adeptly capture factor-wise graph representations, effectively encapsulating the latent structure of the graph. Despite significant progress, few studies have endeavored to adapt these methods to to generative graph representation learning methods, such as GMAE. This primary challenge arises from the difficulty of achieving convergence in the latent factor detection module under the generative training target, thus presenting obstacles in practical implementation. As shown in Fig.1(a), directly applying the previous factor learning method to GMAE would make the factor learning module difficult to converge, resulting in undistinguished probabilities and misallocation of similar nodes to different latent factor groups.

To address these challenges, we introduce **D**isentangled **G**enerative **G**raph **R**epresentation Learning (**DiGGR**), a self-supervised graph generation representation learning framework. Generally speaking, DiGGR learns how to generate graph structures from latent disentangle factors \(z\) and leverages this to guide graph mask reconstruction, while enabling end-to-end joint learning. Specifically, \(i)\) To capture the heterogeneous factors in the nodes, we introduce the latent factor learning module. This module models how edges and nodes are generated from latent factors, allowing graphs to be factorized into multiple disentangled subgraphs. \(ii)\) To learn a deeper disentangled graph representation, we design a factor-wise self-supervised graph representation learning framework. For each subgraph, we employ a distinct masking strategy to learn an improved factor-specific graph representation. Evaluation shows that the proposed framework can achieve significant performance enhancement on various node and graph classification benchmarks.

The main contributions of this paper can be summarized as follows:

* We utilized the latent disentangled factor to guide mask modeling. A probabilistic graph generation model is employed to identify the latent factors within a graph, and it can be jointly trained with GMAE through variational inference.
* Introducing **DiGGR** (**D**isentangled **G**enerative **G**raph **R**epresentation Learning) to further capture the disentangled information in the latent factors, enhancing the disentanglement of the learned node representations.
* Empirical results show that the proposed DiGGR outperforms many previous self-supervised methods in various node- and graph-level classification tasks.

## 2 Related works

Graph Self-Supervised Learning:Graph SSL has achieved remarkable success in addressing label scarcity in real-world network data, mainly consisting of contrastive and generative methods. Con

Figure 1: The number of latent factors is set to 4. In Fig. 1(a), the probabilities of nodes belonging to different latent groups are similar, resulting in nodes of the same type being incorrectly assigned to different factors. In contrast, Fig. 1(b) shows that the probabilities of node-factor affiliation are more discriminative, correctly categorizing nodes of the same type into the same latent group.

trastive methods, includes feature-oriented approachesHu et al. (2019); Zhu et al. (2020); Velickovic et al. (2018), proximity-oriented techniques Hassani and Khasahmadi (2020); You et al. (2020), and graph-sampling-based methods Qiu et al. (2020). A common limitation across these approaches is their heavy reliance on the design of pretext tasks and augmentation techniques. Compared to contrastive methods, generative methods are generally simpler to implement. Recently, to tackle the challenge of overemphasizing neighborhood information at the expense of structural information Hassani and Khasahmadi (2020); Velickovic et al. (2018), the Graph Masked Autoencoder (GMAE) has been proposed. It applies a masking strategy to graph structure Li et al. (2023), node attributes Hou et al. (2022), or both Tian et al. (2023) for representation learning. Unlike most GMAEs, which employ random mask strategies, this paper builds disentangled mask strategies.

Disentangled Graph Learning:Disentangled representation learning aims to discover and isolate the fundamental explanatory factors inherent in the data Bengio et al. (2013). Existing efforts in disentangled representation learning have primarily focused on computer vision Higgins et al. (2017); Jiang et al. (2020). Recently, there has been a surge of interest in applying these techniques to graph-structured data Li et al. (2021); Ma et al. (2019); Mercatali et al. (2022); Mo et al. (2023). For example, DisenGCN Ma et al. (2019) utilizes an attention-based methodology to discriminate between distinct latent factors, enhancing the representation of each node to more accurately reflect its features across multiple dimensions. DGCL Li et al. (2021) suggests learning disentangled graph-level representations through self-supervision, ensuring that the factorized representations independently capture expressive information from various latent factors. Despite the excellent results achieved by the aforementioned methods on various tasks, these methods are difficult to converge in generative graph SSL, as we demonstrated in the experiment of Table.3. Therefore, this paper proposes a disentangled-guided framework for generative graph representation learning, capable of learning disentangled representations in an end-to-end self-supervised manner.

## 3 Proposed Method

In this section, we propose **DiGGR** (**D**isentangled **G**enerative **G**raph **R**epresentation Learning) for self-supervised graph representation learning with mask modeling. The framework was depicted in Figure 2, comprises three primary components: Latent Factor Learning (Section 3.2), Graph Factorization (Section 3.2) and Disentangled Graph Masked autoencoder (Section 3.3). Before elaborating on them, we first show some notations.

### Preliminaries

A graph \(G\) can be represented as a multi-tuple \(\mathcal{G}=\{V,A,X\}\) with \(N\) nodes and \(M\) edges, where \(|V|=N\) is the node set, \(|A|=M\) is the edge set, and \(X\in\mathbb{R}^{N\times L}\) is the feature matrix for \(N\) nodes with \(L\) dimensional feature vector. The topology structure of graph \(G\) can be found in its adjacency matrix \(A\in\mathbb{R}^{N\times N}\). \(z\in\mathbb{R}^{N\times K}\) is the latent disentangled factor matrix, and \(K\) is the predefined factor number. Since we aim to obtain the \(z\) to guide the mask modeling, we first utilize a probabilistic graph generation model to factorize the graph before employing the mask mechanism. Given the graph \(G\), it is factorized into \(\{G_{1},G_{2},...,G_{K}\}\), and each factor-specific graph \(G_{k}\) consists of its factor-specific edges \(A^{(k)}\), node set \(V^{(k)}\) and node feature matrix \(X^{(k)}\). Other notations will be elucidated as they are employed.

### Latent Factor Learning

In this subsection, we describe the latent factor learning method. In this phase, our objective is to derive factor-specific node sets \(\{V^{(1)},V^{(2)},...,V^{(K)}\}\) and adjacency matrices \(\{A^{(1)},A^{(2)},...,A^{(K)}\}\), serving as basic unit of the graph to guide the subsequent masking. The specific approach involves modeling the distribution of nodes and edges, utilizing the generative process developed in EPM Zhou (2015). The generative process of EPM under the Bernoulli-Poisson link Zhou (2015) can be described as:

\[\text{M}_{uv}\sim\text{Poisson}(\sum\nolimits_{k=1}^{K}\gamma_{k}z_{uk}z_{vk} ),\ \ z_{uk}\sim\text{Gamma}\left(\alpha,\beta\right),u,v\in[1,N]\] (1)

where \(K\) is the predefined number of latent factors, and \(u\) and \(v\) are the indexes of the nodes. Here, \(\text{M}_{uv}\) is the latent count variable between node \(u\) and \(v\); \(\gamma_{k}\) is a positive factor activation level indicator, which measures the node interaction frequency via factor \(k\); \(z_{uk}\) is a positive latent variable for node \(u\), which measures how strongly node \(u\) is affiliated with factor \(k\). The prior distribution of latent factor variable \(z_{uk}\) is set to Gamma distribution, where \(\alpha\) and \(\beta\) are normally set to 1. Therefore, the intuitive explanation for this generative process is that, with \(z_{uk}\) and \(z_{vk}\) measuring how strongly node \(u\) and \(v\) are affiliated with the \(k\)-th factor, respectively, the product \(\gamma_{k}z_{uk}z_{vk}\) measures how strongly nodes \(u\) and \(v\) are connected due to their affiliations with the \(k\)-th factor.

**Node Factorization:** Equation 1 can be further augmented as follows:

\[\text{M}_{uv}=\sum\nolimits_{k}^{K}\text{M}_{ukv},\ \text{M}_{ukv}\sim\text{ Poisson}\left(\gamma_{k}z_{uk}z_{vk}\right)\] (2)

where \(\text{M}_{ukv}\) represents how often nodes \(u\) and \(v\) interact due to their affiliations with the \(k\)-th factor. To represent how often node \(u\) is affiliated with the \(k\)-th factor, we further introduce the latent count \(\text{M}_{uk\cdot}=\sum_{v\neq u}\text{M}_{ukv}\). Then, we can soft assign node \(u\) to multiple factors in \(\{k:\text{M}_{uk\cdot}\}\geq 1\), or hard assign node \(u\) to a single factor using \(\operatorname*{arg\,max}_{k}\left(\text{M}_{uk\cdot}\right)\). However, our experiments show that soft assignment method results in significant overlap among node sets from different factor group, diminishing the distinctiveness. Note that previous study addressed a similar issue by selecting the top-k most attended regions (Kakogeorgiou et al., 2022). Thus, we choose the hard assign strategy to factorize the graph node set \(V\) graph into factor-specific node sets \(\{V^{(1)},V^{(2)},\cdots,V^{(K)}\}\).

**Edge Factorization:** To create factor-specific edges \(A^{(k)}\) for a factor-specific node set \(V^{(k)}\), a straightforward method involves removing all external nodes connected to other factor groups. This can be defined as:

\[A^{(k)}_{uv}=\left\{\begin{array}{l}A_{uv},\ \forall\,u,v\in V^{(k)};\ u,v\in \left[1,N\right];\\ 0,\ \ \exists\,u,v\notin V^{(k)};\ u,v\in\left[1,N\right].\end{array}\right.\] (3)

Besides, the global graph edge \(A\) can also be factorized into positive-weighted edges (He et al., 2022b) for each latent factor as:

\[A^{(k)}_{uv}=A_{uv}\cdot\frac{\exp\left(\gamma_{k}z_{uk}z_{vk}\right)}{\sum_{ k^{\prime}}\exp\left(\gamma_{k^{\prime}}z_{uk^{\prime}}z_{vk^{\prime}}\right)}; \ \ k\in\left[1,K\right],u,v\in\left[1,N\right].\] (4)

Applying Equation 4 to all pairs of nodes yields weighted adjacency matrices \(\{A^{(k)}\}_{k=1}^{k}\), with \(A^{(k)}\) corresponding to latent factor \(z_{k}\). Note that \(A^{(k)}\) has the same dimension as \(A\) and Equation 4

Figure 2: The overview of proposed DiGGR’s computation graph. The input data successively passes three modules described in Sections 3.2 and 3.3: Latent Factor Learning, Graph Factorization, and Disentangled Graph Mask Autoencoder. Graph information will be first processed through Latent Factor Learning and Graph Factorization, the former processed the input graph to get the latent factor \(z\); the latter performs graph factorization via \(z\), such that in each factorized subgraph, nodes exchange more information with intensively interacted neighbors. Hence, during the disentangled graph masking phase, we will individually mask each factorized subgraph to enhance the disentanglement of the obtained node representations.

presents a trainable weight for each edge, which can be jointly optimized through network training, showcasing an advantage over Equation 3 in this aspect. Therefore, we apply Equation 4 for edge factorization.

Variational Inference:The latent factor variable \(z\) determines the quality of node and edge factorization, so we need to approximate its posterior distribution. Denoting \(z_{u}=(z_{u1},...,z_{uK}),z_{u}\in\mathbb{R}_{+}^{K}\), which measures how strongly node \(u\) is affiliated with all the \(K\) latent factors, we adopt a Weibull variational graph encoder [22, He et al., 2022b]:

\[q(z_{u}\mid A,X)=\text{Weibull}(k_{u},\lambda_{u}),\ \ (k_{u},\lambda_{u})=\text{GNN }_{\text{EPM}}(A,X),\quad u\in[1,N]\] (5)

where \(\text{GNN}_{\text{EPM}}(\cdot)\) stands for graph neural networks, and we select a two-layer Graph Convolution Networks (_i.e._, GCN [14]) for our models; \(k_{u},\lambda_{u}\in\mathbb{R}_{+}^{K}\) are the shape and scale parameters of the variational Weibull distribution, respectively. The latent variable \(z_{u}\) can be conveniently reparameterized as:

\[z_{u}=\lambda_{u}(-\ln(1-\varepsilon))^{1/k_{u}},\ \ \varepsilon\sim\text{ Uniform}(0,1).\] (6)

The optimization objective of latent factor learning phase can be achieved by maximizing the evidence lower bound (ELBO) of the log marginal likelihood of edge \(\log p(A)\), which can be computed as:

\[\mathcal{L}_{\text{z}}=\mathbb{E}_{q(Z\mid A,X)}\left[\ln p\left(A\mid Z \right)\right]-\sum_{u=1}^{N}\mathbb{E}_{q(\boldsymbol{z}_{u}\mid A,X)}\left[ \ln\frac{q(\boldsymbol{z}_{u}\mid A,X)}{p(\boldsymbol{z}_{u})}\right]\] (7)

where the first term is the expected log-likelihood or reconstruction error of edge, and the second term is the Kullback-Leibler (KL) divergence that constrains \(q(z_{u})\) to be close to its prior \(p(z_{u})\). The analytical expression for the KL divergence and the straightforward reparameterization of the Weibull distribution simplify the gradient estimation of the ELBO concerning the decoder parameters and other parameters in the inference network.

### Disentangled Grpah Masked Autoencoder

With the latent factor learning phase discussed in 3.2, the graph can be factorized into a series of factor-specific subgraphs \(\{G_{1},G_{2},...,G_{K}\}\) via the latent factor \(z\). To incorporate the disentangled information encapsulated in \(z\) into the graph masked autoencoder, we proposed Disentangled Graph Masked Autoencoder in this section. Specifically, this section will first introduce the latent factor-wise GMAE and the graph-level GMAE.

#### 3.3.1 Latent Factor-wise Grpah Masked Autoencoder

To capture disentangled patterns within the latent factor \(z\), for each latent subgraph \(\mathcal{G}_{k}=(V^{(k)},A^{(k)},X^{(k)})\), the latent factor-wise GMAE can be described as:

\[H_{d}^{(k)}=\text{GNN}_{\text{enc}}(A^{(k)},\bar{X}^{(k)}),\tilde{X}^{d}= \text{GNN}_{\text{dec}}(A,H_{d}).\] (8)

where \(\bar{X}^{(k)}\) is the masked node feature matrix for the \(k\)-th latent factor, and \(\tilde{X}^{d}\) denotes the reconstructed node features. \(\text{GNN}_{\text{enc}}(.)\) and \(\text{GNN}_{\text{dec}}(.)\) are the graph encoder and decoder, respectively; \(H_{d}^{(k)}\in\mathbb{R}^{N\times D}\) are factor-wise hidden representations, and \(H_{d}=H_{d}^{(1)}\oplus H_{d}^{(2)}\cdots\oplus H_{d}^{(K)}\). After the concatenation operation \(\oplus\) in feature dimension, the multi factor-wise hidden representation becomes \(H_{d}\in\mathbb{R}^{N\times(K\cdot D)}\), which is used as the input of \(\text{GNN}_{\text{dec}}(.)\).

Regarding the mask operation, we uniformly random sample a subset of nodes \(\bar{V}^{(k)}\in V^{(k)}\) and mask each of their features with a mask token, such as a learnable vector \(X_{[M]}\in\mathbb{R}^{d}\). Thus, the node feature in the masked feature matrix can be defined as:

\[\bar{X}_{i}^{(k)}=\left\{\begin{array}{l}X_{[M]};\ \ v_{i}\in\bar{V}^{(k)}\ ;\\ X_{i}\ \ ;\ \ v_{i}\notin\bar{V}^{(k)}.\end{array}\right.\] (9)

The objective of latent factor-wise GMAE is to reconstruct the masked features of nodes in \(\bar{V}^{(k)}\) given the partially observed node signals \(\bar{X}^{(k)}\) and the input adjacency matrix \(A^{(k)}\). Another crucial component of the GMAE is the feature reconstruction criterion, often used in language as cross-entropy error [18] and in the image as mean square error [17]. However,texts and images typically involve tokenized input features, whereas graph autoencoders (GAE) do not have a universal tokenizer. We adopt the scored cosine error of GraphMAE [Hou et al., 2022] as the loss function. Generally, given the original feature \(X^{(k)}\) and reconstructed node feature \(\tilde{X}^{(k)}\), the defined SCE is:

\[\mathcal{L}_{\text{D}}=\frac{1}{|\bar{V}|}\underset{i\in\bar{V}}{\sum}\left(1- \frac{X_{i}^{T}\tilde{X}_{i}^{d}}{\|X_{i}\|\cdot\|\tilde{X}_{i}^{d}\|}\right)^ {\gamma},\ \ \gamma\geq 1\] (10)

where \(\bar{V}=\bar{V}^{(1)}\cup\bar{V}^{(2)}...\cup\bar{V}^{(K)}\) and Equation 10 are averaged over all masked nodes.The scaling factor \(\gamma\) is a hyper-parameter adjustable over different datasets. This scaling technique could also be viewed as adaptive sample reweighting, and the weight of each sample is adjusted with the reconstruction error. This error is also famous in the field of supervised object detection as the focal loss [Lin et al., 2017].

Graph-level Graph Mask Autoencoder:For the node classification task, we have integrated graph-level GMAE into DiGGR. We provide a detailed experimental analysis and explanation for this difference in Appendix A.1.2. The graph-level masked graph autoencoder is designed with the aim of further capturing the global patterns, which can be designed as:

\[H_{g}=\text{GNN}_{\text{enc}}(A,\bar{X}),\ \ \tilde{X}^{g}=\text{GNN}_{\text{ dec}}(A,H_{g}).\] (11)

\(\bar{X}\) is the masked node feature matrix, whose mask can be generated by uniformly random sampling a subset of nodes \(\tilde{V}\in V\), or obtained by concatenating the masks of all factor-specific groups \(\tilde{V}=\bar{V}^{(1)}\cup\bar{V}^{(2)}...\cup\bar{V}^{(K)}\). The global hidden representation encoded by \(\text{GNN}_{\text{enc}}(.)\) is \(H_{g}\), which is then passed to the decoder. Similar to Equation 10, we can define the graph-level reconstruct loss as:

\[\mathcal{L}_{\text{G}}=\frac{1}{|\bar{V}|}\underset{i\in\tilde{V}}{\sum}\left( 1-\frac{X_{i}^{T}\tilde{X}_{i}^{g}}{\|X_{i}\|\cdot\|\tilde{X}_{i}^{g}\|} \right)^{\gamma},\ \ \gamma\geq 1.\] (12)

which is averaged over all masked nodes.

### Joint Training and Inference

Benefiting from the effective variational inference method, the proposed latent factor learning and disentangled graph masked autoencoder can be jointly trained in one framework. We combine the aforementioned losses with three mixing coefficient \(\lambda_{d}\), \(\lambda_{g}\) and \(\lambda_{z}\) during training, and the loss for joint training can be written as

\[\mathcal{L}=\lambda_{d}\cdot\mathcal{L}_{\text{D}}+\lambda_{g}\cdot\mathcal{L }_{\text{G}}+\lambda_{z}\cdot\mathcal{L}_{\text{z}}.\] (13)

Since Weibull distributions have easy reparameterization functions, these parameters can be jointly trained by stochastic gradient descent with low-variance gradient estimation. We summarize the training algorithm at Algorithm 1 in Appendix A.4. For downstream applications, the encoder is applied to the input graph without any masking in the inference stage. The generated factor-wise node embeddings \(H_{d}\) and graph-level embeddings \(H_{g}\) can either be concatenated in the feature dimensions or used separately. The resulting final representation \(H\) can be employed for various graph learning tasks, such as node classification and graph classification. For graph-level tasks, we use a non-parameterized graph pooling (readout) function, _e.g._, MaxPooling and MeanPooling to obtain the graph-level representation.

**Time and space complexity:** Let's recall that in our context, \(N\), \(M\), and \(K\) represent the number of nodes, edges, and latent factors in the graph, respectively. The feature dimension is denoted by \(F\), while \(L_{1}\), \(L_{2}\), \(L_{3}\), and \(L_{4}\) represent the number of layers in the latent factor learning encoder, the latent factor-wise GMAE's encoder, the graph-level GMAE's encoder, and the decoder respectively. In DiGGR, we constrain the hidden dimension size in latent factor-wise GMAE's encoder to be \(1/K\) of the typical baseline dimensions. Consequently, the time complexity for training DiGGR can be expressed as \(O((L_{1}+L_{2}+L_{3})MF+(L_{1}+L_{2}/K+L_{3})NF^{2}+N^{2}F+L_{4}NF^{2})\), and the space complexity is \(O((L_{1}+L_{2}+L_{3}+L_{4})NF+KM+(L1+L2/K+L3+L_{4})F^{2})\), with \(O((L_{1}+L_{2}/K+L_{3}+L_{4})F^{2})\) attributed to model parameters. We utilize the Bayesian factor model in our approach to reconstruct edges. Its time complexity aligns with that of variational inference in SeeGera Li et al. [2023b], predominantly at \(O(N^{2}F)\); Therefore, the complexity of DiGGR is comparable to previous works.

## 4 Experiments

We compare the proposed self-supervised framework DiGGR against related baselines on two fundamental tasks: unsupervised representation learning on _node classification_ and _graph classification_. We evaluate DiGGR on 11 benchmarks. For node classification, we use 3 citation networks (Cora, Citeseer, Pubmed [13]), and protein-protein interaction networks (PPI) [17]. For graph classification, we use 3 bioinformatics datasets (MUTAG, NCI1, PROTEINS) and 4 social network datasets (IMDB-BINARY, IMDB-MULTI, REDDIT-BINARY and COLLAB). The specific information of the dataset and the hyperparameters used by the network are listed in the Appendix A.2 in table 5 and 6. We also provide the detailed experiment setup in Appendix A.2 for node classification (4.1) and graph classification (4.2)

### Node Classification

The baseline models for node classification can be divided into three categories: \(i)\) supervised methods, including GCN [19], DisenGCN[14], VEPM[11] and GAT [20]; \(ii)\) contrastive learning methods, including MVGRL [16], InfoGCL [21], DGI [22], GRACE [23], BGRL [20] and CCA-SSG [24]; \(iii)\) generative learning methods, including GraphMAE [14], GraphMAE2[14], Bandana[24], GiGaMAE[25], SeeGera[19], GAE and VGAE [19]. The node classification results were listed in Table 1. DiGGR demonstrates competitive results on the provided dataset, achieving results comparable to those of supervised methods.

### Graph Classification

Baseline ModelsWe categorized the baseline models into four groups: \(i)\) supervised methods, including GIN [21], DiffPool[13] and VEPM[11], \(ii)\) classical graph kernel methods: Weisfeiler-Lehman sub-tree kernel (WL) [12] and deep graph kernel (DGK) [20]; \(iii)\) contrastive learning methods, including GCC [22], graph2vec [15], Infograph [21], GraphCL [21], JOAO [22], MVGRL [16], and InfoGCL [21]; \(4)\) generative learning methods, including graph2vec [15], sub2vec [1], node2vec [17], GraphMAE [14], GraphMAE2[14], GAE and VGAE [19]. Per graph classification research tradition, we report results from previous papers if available.

\begin{table}
\begin{tabular}{l c c c c} \hline \hline Methods & Cora & Citeseer & Pubmed & PPI \\ \hline GCN [19] & 81.50 & 70.30 & 79.00 & 75.70 \(\pm\) 0.10 \\ GAT [20] & 83.00 \(\pm\) 0.70 & 72.50 \(\pm\) 0.70 & 79.00 \(\pm\) 0.30 & 97.30 \(\pm\) 0.20 \\ DisenGCN[14] & 83.7 & 73.4 & 80.5 & - \\ VEPM[11] & 84.3 \(\pm\) 0.1 & 72.5 \(\pm\) 0.1 & 82.4 \(\pm\) 0.2 & - \\ \hline MVGRL [16] & 83.50 \(\pm\) 0.40 & 73.30 \(\pm\) 0.50 & 80.10 \(\pm\) 0.70 & - \\ InfoGCL [21] & 83.50 \(\pm\) 0.30 & 73.50 \(\pm\) 0.40 & 79.10 \(\pm\) 0.20 & - \\ DGI [22] & 82.30 \(\pm\) 0.60 & 71.80 \(\pm\) 0.70 & 76.80 \(\pm\) 0.60 & 63.80 \(\pm\) 0.20 \\ GRACE [23] & 81.90 \(\pm\) 0.40 & 71.20 \(\pm\) 0.50 & 80.60 \(\pm\) 0.40 & 69.71 \(\pm\) 0.17 \\ BGRL [20] & 82.70 \(\pm\) 0.60 & 71.10 \(\pm\) 0.80 & 79.60 \(\pm\) 0.50 & 73.63 \(\pm\) 0.16 \\ CCA-SSG [24] & 84.20 \(\pm\) 0.40 & 73.10 \(\pm\) 0.30 & 81.00 \(\pm\) 0.40 & 73.34 \(\pm\) 0.17 \\ \hline GAE [19] & 71.50 \(\pm\) 0.40 & 65.80 \(\pm\) 0.40 & 72.10 \(\pm\) 0.50 & - \\ VGAE [19] & 76.30 \(\pm\) 0.20 & 66.80 \(\pm\) 0.20 & 75.80 \(\pm\) 0.40 & - \\ Bandana [24] & 84.62 \(\pm\) 0.37 & 73.60 \(\pm\) 0.16 & **83.53**\(\pm\) 0.51 & - \\ GiGaMAE[25] & 84.72 \(\pm\) 0.47 & 72.31 \(\pm\) 0.50 & - & - \\ SEEGERA [19] & 84.30 \(\pm\) 0.40 & 73.00 \(\pm\) 0.80 & 80.40 \(\pm\) 0.40 & - \\ GraphMAE[14] & 84.20 \(\pm\) 0.40 & 73.40 \(\pm\) 0.40 & 81.10 \(\pm\) 0.40 & 74.50 \(\pm\) 0.29 \\ GraphMAE2[14] & 84.50 \(\pm\) 0.60 & 73.40 \(\pm\) 0.30 & 81.40 \(\pm\) 0.50 & - \\ \hline
**DiGGR** & **84.96**\(\pm\) 0.32 & **73.98**\(\pm\) 0.27 & 81.30 \(\pm\) 0.26 & **78.30**\(\pm\) 0.71 \\ \hline \hline \end{tabular}
\end{table}
Table 1: Experiment results for node classification. Micro-F1 score is reported for PPI, and accuracy for other datasets. The best unsupervised method scores in each dataset are highlighted in bold.

Performance ComparisonThe graph classification results are presented in Table 2. In general, we find that DiGGR gained the best performance among other baselines on five out of seven datasets, while achieving competitive results on the other two datasets. The performance of DiGGR is comparable to that of supervised learning methods. For instance, the accuracy on IMDB-B and IMDB-M surpasses that of GIN and DiffPool. Moreover, within the reported datasets, our method demonstrates improved performance compared to random mask methods like GraphMAE, particularly on the IMDB-M, COLLAB, and PROTEINS datasets. This underscores the effectiveness of the proposed method.

### Exploratory Studies

Visualizing latent representationsTo examine the influence of the learned latent factor on classification results, we visualized the latent disentangled factor \(z\), which reflects the node-factor affiliation, and the hidden representation \(H\) used for classification. MUTAG is selected as the representative for classification benchmarks. We encodes the representations into 2-D space via t-SNE (Van der Maaten and Hinton, 2008). The result is shown in Figure 3(a), where each node is colored according to its node labels. The clusters in Figure 3(a) still exhibit differentiation in the absence of label supervision, suggesting that \(z\) obtained through unsupervised learning can enhance node information and offer a guidance for the mask modeling. We then visualize the hidden representation used for classification tasks, and color each node according to the latent factor to which it belongs. The results are depicted in Figure 3(b), showcasing separability among different color clusters. This illustrates the model's ability to extract information from the latent factor, thereby enhancing the quality of the learned representations.

Task-relevant factorsTo assess the statistical correlation between the learned latent factor and the task, we follow the approach in (He et al., 2022) and compute the Normalized Mutual Information (NMI) between the nodes in the factor label and the actual node labels. NMI is a metric that ranges from 0 to 1, where higher values signify more robust statistical dependencies between two random variables. In the experiment, we utilized the MUTAG dataset, comprising 7 distinct node types, and the NMI value we obtained was 0.5458. These results highlight that the latent factors obtained through self-supervised training are meaningful for the task, enhancing the correlation between the inferred latent factors and the task.

Disentangled representationsTo assess DiGGR's capability to disentangle the learned representation for downstream task, we provide a qualitative evaluation by plotting the correlation of the

\begin{table}
\begin{tabular}{c c c c c c c c} \hline \hline Methods & IMDB-B & IMDB-M & MUTAG & NCI1 & REDDIT-B & PROTEINS & COLLAB \\ \hline GIN & 75.1\(\pm\) 5.1 & 52.3 \(\pm\) 2.8 & 89.4 \(\pm\) 5.6 & 82.7 \(\pm\) 1.7 & 92.4 \(\pm\) 2.5 & 76.2 \(\pm\) 2.8 & 80.2 \(\pm\) 1.9 \\ DiffPool & 72.6 \(\pm\) 3.9 & - & 85.0 \(\pm\) 10.3 & - & 92.1 \(\pm\) 2.6 & 75.1 \(\pm\) 3.5 & 78.9 \(\pm\) 2.3 \\ VEPM & 76.7 \(\pm\) 3.1 & 54.1 \(\pm\) 2.1 & 93.6 \(\pm\) 3.4 & 83.9 \(\pm\) 1.8 & 90.5 \(\pm\) 1.8 & 80.5 \(\pm\) 2.8 & - \\ \hline WL & 72.30 \(\pm\) 3.44 & 46.95 \(\pm\) 0.46 & 80.72 \(\pm\) 3.00 & 80.31 \(\pm\) 0.46 & 68.82 \(\pm\) 0.41 & 72.92 \(\pm\) 0.56 & - \\ DGK & 66.96 \(\pm\) 0.56 & 44.55 \(\pm\) 0.52 & 87.44 \(\pm\) 2.72 & 80.31 \(\pm\) 0.46 & 78.04 \(\pm\) 0.39 & 73.30 \(\pm\) 0.82 & 73.09 \(\pm\) 0.25 \\ \hline Infograph & 73.03 \(\pm\) 0.87 & 49.69 \(\pm\) 0.53 & 89.01 \(\pm\) 1.13 & 76.20 \(\pm\) 1.06 & 82.50 \(\pm\) 1.42 & 74.44 \(\pm\) 0.31 & 70.65 \(\pm\) 1.13 \\ GraphCL & 71.14 \(\pm\) 0.44 & 48.58 \(\pm\) 0.67 & 86.80 \(\pm\) 1.34 & 77.87 \(\pm\) 0.41 & **89.53**\(\pm\) 0.84 & 74.39 \(\pm\) 0.45 & 71.36 \(\pm\) 1.15 \\ JOAO & 70.21 \(\pm\) 3.08 & 49.20 \(\pm\) 0.77 & 87.35 \(\pm\) 1.02 & 78.07 \(\pm\) 0.47 & 85.29 \(\pm\) 1.35 & 74.55 \(\pm\) 0.41 & 69.50 \(\pm\) 0.36 \\ GCC & 72.0 & 49.4 & - & - & 89.9 & - & 78.9 \\ MVGRL & 74.20 \(\pm\) 0.70 & 51.20 \(\pm\) 0.50 & 89.70 \(\pm\) 1.10 & - & 84.50 \(\pm\) 0.60 & - & - \\ InfoGCL & 75.10 \(\pm\) 0.90 & 51.40 \(\pm\) 0.80 & **91.20**\(\pm\) 1.30 & 80.20 \(\pm\) 0.60 & - & - & 80.00 \(\pm\) 1.30 \\ \hline graph2vec & 71.10 \(\pm\) 0.54 & 50.44 \(\pm\) 0.87 & 83.15 \(\pm\) 9.25 & 73.22 \(\pm\) 1.81 & 75.78 \(\pm\) 1.03 & 73.30 \(\pm\) 2.05 & - \\ sub2vec & 55.3 \(\pm\) 1.5 & 36.7 \(\pm\) 0.8 & 61.1 \(\pm\) 15.8 & 52.8 \(\pm\) 1.5 & 71.5 \(\pm\) 0.4 & 53.0 \(\pm\) 5.6 & - \\ node2vec & - & - & 72.6 \(\pm\) 10.2 & 54.9 \(\pm\) 1.6 & - & 57.5 \(\pm\) 3.6 & - \\ GAE & 52.1 \(\pm\) 0.2 & - & 84.0 \(\pm\) 0.6 & 73.3 \(\pm\) 0.6 & 74.8 \(\pm\) 0.2 & 74.1 \(\pm\) 0.5 & - \\ VGAE & 52.1 \(\pm\) 0.2 & - & 84.4 \(\pm\) 0.6 & 73.7 \(\pm\) 0.3 & 74.8 \(\pm\) 0.2 & 74.8 \(\pm\) 0.2 & - \\ GraphMAE & 75.52 \(\pm\) 0.66 & 51.63 \(\pm\) 0.52 & 88.19 \(\pm\) 1.26 & 80.40 \(\pm\) 0.30 & 88.01 \(\pm\) 0.19 & 75.30 \(\pm\) 0.39 & 80.32 \(\pm\) 0.46 \\ GraphMAE & 73.88 \(\pm\) 0.53 & 51.80 \(\pm\) 0.60 & 86.63 \(\pm\) 1.33 & 78.56 \(\pm\) 0.26 & 76.84 \(\pm\) 0.21 & 74.86 \(\pm\) 0.34 & 77.59 \(\pm\) 0.22 \\ \hline
**DiGGR** & **77.68**\(\pm\) 0.48 & **54.77**\(\pm\) 2.63 & 88.72 \(\pm\) 1.03 & **81.23**\(\pm\) 0.40 & 88.19 \(\pm\) 0.28 & **77.40**\(\pm\) 0.05 & **83.76**\(\pm\) 3.70 \\ \hline \hline \end{tabular}
\end{table}
Table 2: Experiment results in unsupervised representation learning for graph classification. We report accuracy (\(\%\)) for all datasets. The optimal outcomes for methods, excluding supervised approaches (GIN and DiffPool), on each dataset are emphasized in bold.

node representation in Figure 4. The figure shows the absolute values of the correlation between the elements of 512-dimensional graph representation and representation obtained from GraphMAE and DiGGR, respectively. From the results, we can see that the representation produced by GraphMAE exhibits entanglement, whereas DiGGR's representation displays a overall block-level pattern, indicating that DiGGR can capture mutually exclusive information in the graph and disentangle the hidden representation to some extent. Results for more datasets can be found in Appendix A.3.

**Why DiGGR works better:** To validate that disentangled learning can indeed enhance the quality of the representations learned by GMAE, we further conduct quantitative experiments. The Normalized Mutual Information (NMI) is used to quantify the disentangling degree of different datasets. Generally, the NMI represents the similarity of node sets between different factor-specific graphs, and the _lower NMI suggests a better-disentangled degree_ with lower similarity among factor-specific graphs. The NMI between latent factors and the corresponding performance gain (compared to GraphMAE) are shown in the Table.3. As the results show, DiGGR's performance improvement has a positive correlation with disentangled degree, where the better the disentangled degree, the more significant the performance improvement. For methods relying on Non-probabilistic Factor Learning, the NMI tends to approach 1. This is attributed to the challenges faced by the factor learning module in converging, thereby hindering the learning of distinct latent factors. The presence of confused latent factors offers misleading guidance for representation learning, consequently leading to decreased performance.

## 5 Conclusions

In this paper, we propose DiGGR (Disentangled Generative Graph Representation Learning), designed to achieve disentangled representations in graph masked autoencoders by leveraging latent disentangled factors. In particular, we achieve this by two steps: 1) We utilize a probabilistic graph generation model to factorize the graph via the learned disentangled latent factor; 2) We develop a Disentangled Graph Masked Autoencoder framework, with the aim of integrating the disentangled information into the representation learning of Graph Masked Autoencoders. Experiments demonstrate that our model can acquire disentangled representations, and achieve favorable results on downstream tasks.

\begin{table}
\begin{tabular}{c|c|c c c c c c c} \hline \hline  & Dataset & RDT-B & MUTAG & NCI-1 & IMDB-B & PROTEINS & COLLAB & IMDB-M \\ \hline \multirow{2}{*}{DiGGR} & NMI & 0.95 & 0.90 & 0.89 & 0.82 & 0.76 & 0.35 & 0.24 \\  & ACC Gain & + 0.18\% & + 0.53\% & + 0.83\% & + 2.16\% & + 2.1\% & + 3.44\% & + 3.14\% \\ \hline Non-probabilistic & NMI & 1.00 & 1.00 & 0.80 & 1.00 & 0.60 & 1.00 & 0.94 \\ Factor Learning & ACC Gain & -2.23\% & -2.02\% & -0.45\% & -0.80\% & -2.15\% & -3.00\% & -0.11\% \\ \hline \hline \end{tabular}
\end{table}
Table 3: The NMI between the latent factors extracted by DiGGR and Non-probabilistic factor learning method across various datasets, and its performance improvement compared to GraphMAE, are examined. A lower NMI indicates a more pronounced disentanglement between factor-specific graphs, resulting in a greater performance enhancement.

## References

* Chen et al. [2020] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework for contrastive learning of visual representations. In _International conference on machine learning_, pages 1597-1607. PMLR, 2020.
* You et al. [2020] Yuning You, Tianlong Chen, Yongduo Sui, Ting Chen, Zhangyang Wang, and Yang Shen. Graph contrastive learning with augmentations. _Advances in neural information processing systems_, 33:5812-5823, 2020.
* Devlin et al. [2018] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. _arXiv preprint arXiv:1810.04805_, 2018.
* Bao et al. [2021] Hangbo Bao, Li Dong, Songhao Piao, and Furu Wei. Beit: Bert pre-training of image transformers. _arXiv preprint arXiv:2106.08254_, 2021.
* He et al. [2022a] Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollar, and Ross Girshick. Masked autoencoders are scalable vision learners. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pages 16000-16009, 2022a.
* Tan et al. [2022] Qiaoyu Tan, Ninghao Liu, Xiao Huang, Rui Chen, Soo-Hyun Choi, and Xia Hu. Mgae: Masked autoencoders for self-supervised learning on graphs. _arXiv preprint arXiv:2201.02534_, 2022.
* Hou et al. [2022] Zhenyu Hou, Xiao Liu, Yukuo Cen, Yuxiao Dong, Hongxia Yang, Chunjie Wang, and Jie Tang. GraphMAE: Self-supervised masked graph autoencoders. In _Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining_, pages 594-604, 2022.
* Tu et al. [2023] Wenxuan Tu, Qing Liao, Sihang Zhou, Xin Peng, Chuan Ma, Zhe Liu, Xinwang Liu, and Zhiping Cai. Rare: Robust masked graph autoencoder. _arXiv preprint arXiv:2304.01507_, 2023.
* Tian et al. [2023] Yijun Tian, Kaiwen Dong, Chunhui Zhang, Chuxu Zhang, and Nitesh V Chawla. Heterogeneous graph masked autoencoders. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 37, pages 9997-10005, 2023.
* Ma et al. [2019] Jianxin Ma, Peng Cui, Kun Kuang, Xin Wang, and Wenwu Zhu. Disentangled graph convolutional networks. In _International conference on machine learning_, pages 4212-4221. PMLR, 2019.
* Li et al. [2021] Haoyang Li, Xin Wang, Ziwei Zhang, Zehuan Yuan, Hang Li, and Wenwu Zhu. Disentangled contrastive learning on graphs. _Advances in Neural Information Processing Systems_, 34:21872-21884, 2021.
* Mo et al. [2023] Yujie Mo, Yajie Lei, Jialie Shen, Xiaoshuang Shi, Heng Tao Shen, and Xiaofeng Zhu. Disentangled multiplex graph representation learning. In _International Conference on Machine Learning_, pages 24983-25005. PMLR, 2023.
* Bengio et al. [2013] Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation learning: A review and new perspectives. _IEEE transactions on pattern analysis and machine intelligence_, 35(8):1798-1828, 2013.
* Xiao et al. [2022] Teng Xiao, Zhengyu Chen, Zhimeng Guo, Zeyang Zhuang, and Suhang Wang. Decoupled self-supervised learning for graphs. _Advances in Neural Information Processing Systems_, 35:620-634, 2022.
* Hu et al. [2019] Weihua Hu, Bowen Liu, Joseph Gomes, Marinka Zitnik, Percy Liang, Vijay Pande, and Jure Leskovec. Strategies for pre-training graph neural networks. _arXiv preprint arXiv:1905.12265_, 2019.
* Zhu et al. [2020] Yanqiao Zhu, Yichen Xu, Feng Yu, Qiang Liu, Shu Wu, and Liang Wang. Deep graph contrastive representation learning. _arXiv preprint arXiv:2006.04131_, 2020.
* Velickovic et al. [2018] Petar Velickovic, William Fedus, William L Hamilton, Pietro Lio, Yoshua Bengio, and R Devon Hjelm. Deep graph infomax. _arXiv preprint arXiv:1809.10341_, 2018.
* Hassani and Khasahmadi [2020] Kaveh Hassani and Amir Hosein Khasahmadi. Contrastive multi-view representation learning on graphs. In _International conference on machine learning_, pages 4116-4126. PMLR, 2020.
* H. H. et al. [2020]Jiezhong Qiu, Qibin Chen, Yuxiao Dong, Jing Zhang, Hongxia Yang, Ming Ding, Kuansan Wang, and Jie Tang. Gcc: Graph contrastive coding for graph neural network pre-training. In _Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery & data mining_, pages 1150-1160, 2020.
* Li et al. [2023a] Jintang Li, Ruofan Wu, Wangbin Sun, Liang Chen, Sheng Tian, Liang Zhu, Changhua Meng, Zibin Zheng, and Weiqiang Wang. What's behind the mask: Understanding masked graph modeling for graph autoencoders. In _Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining_, pages 1268-1279, 2023a.
* Higgins et al. [2017] Irina Higgins, Loic Matthey, Arka Pal, Christopher P Burgess, Xavier Glorot, Matthew M Botvinick, Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual concepts with a constrained variational framework. _ICLR (Poster)_, 3, 2017.
* Jiang et al. [2020] Wentao Jiang, Si Liu, Chen Gao, Jie Cao, Ran He, Jiashi Feng, and Shuicheng Yan. Pgsan: Pose and expression robust spatial-aware gan for customizable makeup transfer. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pages 5194-5202, 2020.
* Mercatali et al. [2022] Giangiacomo Mercatali, Andre Freitas, and Vikas Garg. Symmetry-induced disentanglement on graphs. _Advances in neural information processing systems_, 35:31497-31511, 2022.
* Zhou [2015] Mingyuan Zhou. Infinite edge partition models for overlapping community detection and link prediction. In _Artificial intelligence and statistics_, pages 1135-1143. PMLR, 2015.
* Kakogeorgiou et al. [2022] Ioannis Kakogeorgiou, Spyros Gidaris, Bill Psomas, Yannis Avrithis, Andrei Bursuc, Konstantinos Karantzalos, and Nikos Komodakis. What to hide from your students: Attention-guided masked image modeling. In _European Conference on Computer Vision_, pages 300-318. Springer, 2022.
* He et al. [2020] Yilin He, Chaojie Wang, Hao Zhang, Bo Chen, and Mingyuan Zhou. A variational edge partition model for supervised graph representation learning. _Advances in Neural Information Processing Systems_, 35:12339-12351, 2022b.
* Zhang et al. [2018] Hao Zhang, Bo Chen, Dandan Guo, and Mingyuan Zhou. Whai: Weibull hybrid autoencoding inference for deep topic modeling. _arXiv preprint arXiv:1803.01328_, 2018.
* Kipf and Welling [2016a] Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. _arXiv preprint arXiv:1609.02907_, 2016a.
* Lin et al. [2017] Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Dollar. Focal loss for dense object detection. In _Proceedings of the IEEE international conference on computer vision_, pages 2980-2988, 2017.
* Li et al. [2023b] Xiang Li, Tiandi Ye, Caihua Shan, Dongsheng Li, and Ming Gao. Seegera: Self-supervised semi-implicit graph variational auto-encoders with masking. In _Proceedings of the ACM web conference 2023_, pages 143-153, 2023b.
* Yang et al. [2016] Zhilin Yang, William Cohen, and Ruslan Salakhudinov. Revisiting semi-supervised learning with graph embeddings. In _International conference on machine learning_, pages 40-48. PMLR, 2016.
* Hamilton et al. [2017] Will Hamilton, Zhitao Ying, and Jure Leskovec. Inductive representation learning on large graphs. _Advances in neural information processing systems_, 30, 2017.
* Velickovic et al. [2017] Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, Yoshua Bengio, et al. Graph attention networks. _stat_, 1050(20):10-48550, 2017.
* Xu et al. [2021] Dongkuan Xu, Wei Cheng, Dongsheng Luo, Haifeng Chen, and Xiang Zhang. Infogcl: Information-aware graph contrastive learning. _Advances in Neural Information Processing Systems_, 34:30414-30425, 2021.
* Thakoor et al. [2021] Shantanu Thakoor, Corentin Tallec, Mohammad Gheshlaghi Azar, Mehdi Azabou, Eva L Dyer, Remi Munos, Petar Velickovic, and Michal Valko. Large-scale representation learning on graphs via bootstrapping. _arXiv preprint arXiv:2102.06514_, 2021.
* Zhang et al. [2018]* Zhang et al. [2021] Hengrui Zhang, Qitian Wu, Junchi Yan, David Wipf, and Philip S Yu. From canonical correlation analysis to self-supervised graph neural networks. _Advances in Neural Information Processing Systems_, 34:76-89, 2021.
* Hou et al. [2023] Zhenyu Hou, Yufei He, Yukuo Cen, Xiao Liu, Yuxiao Dong, Evgeny Kharlamov, and Jie Tang. Graphmae2: A decoding-enhanced masked self-supervised graph learner. In _Proceedings of the ACM Web Conference 2023_, pages 737-746, 2023.
* Zhao et al. [2024] Ziwen Zhao, Yuhua Li, Yixiong Zou, Jiliang Tang, and Ruixuan Li. Masked graph autoencoder with non-discrete bandwidths. _arXiv preprint arXiv:2402.03814_, 2024.
* Shi et al. [2023] Yucheng Shi, Yushun Dong, Qiaoyu Tan, Jundong Li, and Ninghao Liu. Gigamae: Generalizable graph masked autoencoder via collaborative latent space reconstruction. In _Proceedings of the 32nd ACM International Conference on Information and Knowledge Management_, pages 2259-2269, 2023.
* Kipf and Welling [2016b] Thomas N Kipf and Max Welling. Variational graph auto-encoders. _arXiv preprint arXiv:1611.07308_, 2016b.
* Xu et al. [2018] Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural networks? _arXiv preprint arXiv:1810.00826_, 2018.
* Ying et al. [2018] Zhitao Ying, Jiaxuan You, Christopher Morris, Xiang Ren, Will Hamilton, and Jure Leskovec. Hierarchical graph representation learning with differentiable pooling. _Advances in neural information processing systems_, 31, 2018.
* Shervashidze et al. [2011] Nino Shervashidze, Pascal Schweitzer, Erik Jan Van Leeuwen, Kurt Mehlhorn, and Karsten M Borgwardt. Weisfeiler-lehman graph kernels. _Journal of Machine Learning Research_, 12(9), 2011.
* Yanardag and Vishwanathan [2015] Pinar Yanardag and SVN Vishwanathan. Deep graph kernels. In _Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining_, pages 1365-1374, 2015.
* Narayanan et al. [2017] Annamalai Narayanan, Mahinthan Chandramohan, Rajasekar Venkatesan, Lihui Chen, Yang Liu, and Shantanu Jaiswal. graph2vec: Learning distributed representations of graphs. _arXiv preprint arXiv:1707.05005_, 2017.
* Sun et al. [2019] Fan-Yun Sun, Jordan Hoffmann, Vikas Verma, and Jian Tang. Infograph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization. _arXiv preprint arXiv:1908.01000_, 2019.
* You et al. [2021] Yuning You, Tianlong Chen, Yang Shen, and Zhangyang Wang. Graph contrastive learning automated. In _International Conference on Machine Learning_, pages 12121-12132. PMLR, 2021.
* Adhikari et al. [2018] Bijaya Adhikari, Yao Zhang, Naren Ramakrishnan, and B Aditya Prakash. Sub2vec: Feature learning for subgraphs. In _Advances in Knowledge Discovery and Data Mining: 22nd Pacific-Asia Conference, PAKDD 2018, Melbourne, VIC, Australia, June 3-6, 2018, Proceedings, Part II 22_, pages 170-182. Springer, 2018.
* Grover and Leskovec [2016] Aditya Grover and Jure Leskovec. node2vec: Scalable feature learning for networks. In _Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining_, pages 855-864, 2016.
* Van der Maaten and Hinton [2008] Laurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. _Journal of machine learning research_, 9(11), 2008.
* Chang and Lin [2011] Chih-Chung Chang and Chih-Jen Lin. Libsvm: a library for support vector machines. _ACM transactions on intelligent systems and technology (TIST)_, 2(3):1-27, 2011.
* Andersen et al. [2006] Reid Andersen, Fan Chung, and Kevin Lang. Local graph partitioning using pagerank vectors. In _2006 47th Annual IEEE Symposium on Foundations of Computer Science (FOCS'06)_, pages 475-486. IEEE, 2006.

Appendix / supplemental material

Optionally include supplemental material (complete proofs, additional experiments and plots) in appendix. All such materials **SHOULD be included in the main submission.**

### Ablation Study

#### a.1.1 Number of factors

One of the crucial hyperparameters in DiGGR is the _number of latent factors_, denoted as \(K\). When \(K=1\) DiGGR degenerates into ordinary GMAE, only performing random masking over the entire input graph on the nodes. The influence of tuning \(K\) is illustrated in Figure 5. Given the relatively small size of the graphs in the dataset, the number of meaningful latent disentangled factor \(z\) is not expected to be very large. The optimal number of \(z\) that maximizes performance tends to be concentrated in the range of 2-4.

#### a.1.2 Representation for downstream tasks

We investigate the impact of various combinations of representation levels on downstream tasks. As illustrated in Table 4, for the node classification task, both \(H_{d}\) and \(H_{g}\) are required, _i.e._, concatenating them in feature dimension, whereas for the graph classification task, \(H_{d}\) alone is sufficient. This difference may be due to the former not utilizing pooling operations, while the latter does. Specifically, the graph pooling operation aggregates information from all nodes, providing a comprehensive view of the entire graph structure. Thus, in node classification, where the node representation has not undergone pooling, a graph-level representation (\(H_{g}\)) is more critical. In contrast, in graph classification, the node representation undergoes pooling, making disentangled information \(H_{d}\) more effective.

### Implementation Details

EnvironmentAll experiments are conducted on Linux servers equipped with an 12th Gen Intel(R) Core(TM) i7-12700, 256GB RAM and a NVIDIA 3090 GPU. Models of node and graph classification are implemented in PyTorch version 1.12.1, scikit-learn version 1.0.2 and Python 3.7.

Experiment Setup for Node ClassificationThe node classification task involves predicting the unknown node labels in networks. Cora, Citeseer, and Pubmed are employed for transductive learning, whereas PPI follows the inductive setup outlined in GraphSage (Hamilton et al., 2017). For evaluation,

\begin{table}
\begin{tabular}{c c|c c c c} \hline \hline \(H_{d}\) & \(H_{g}\) & Cora & IMDB-MULTI & Citeseer & PROTEINS \\ \hline ✓ & & 61.10 \(\pm\) 1.83 & **54.77**\(\pm\) 2.63 & 71.82 \(\pm\) 0.98 & **77.76**\(\pm\) 2.46 \\  & ✓ & 84.22 \(\pm\) 0.38 & 51.62 \(\pm\) 0.61 & 73.41 \(\pm\) 0.43 & 75.52 \(\pm\) 0.49 \\ ✓ & ✓ & **84.96**\(\pm\) 0.32 & 53.69 \(\pm\) 2.06 & **73.98**\(\pm\) 0.27 & 77.61 \(\pm\) 0.97 \\ \hline \hline \end{tabular}
\end{table}
Table 4: The average accuracy of datasets is calculated through 5 random initialization tests when using different representations.

Figure 5: Performance of the task under different choices of latent factor number \(K\), where the horizontal axis represents the change in \(K\) and the vertical axis is accuracy.

we use the concatenated representations of \(H_{d}\) and \(H_{g}\) in the feature dimension for the downstream task. We then train a linear classifier, report the mean accuracy on the test nodes through 5 random initializations. The graph encoder \(\text{GNN}_{\text{enc}(.)}\) and decoder \(\text{GNN}_{\text{dec}}(.)\) are both specified as standard GAT (Velickovic et al., 2017).We train the model using Adam Optimizer with \(\beta_{1}=0.9\), \(\beta_{2}=0.999\), \(\epsilon=1\times 10^{8}\), and we use the cosine learning rate decay without warmup. We follow the public data splits of Cora, Citeseer, and PubMed.

Experiment Setup for Graph ClassificationThe graph classification experiment was conducted on 7 benchmarks, in which node labels are used as input features in MUTAG, PROTEINS and NCI1, and node degrees are used in IMDB-BINARY, IMDB-MULTI, REDDIT-BINARY, and COLLAB. The backbone of encoder and decoder is GIN (Xu et al., 2018), which is commonly used in previous graph classification works. The evaluation protocol primarily follows GraphMAE (Hou et al., 2022). Notice that we only utilize the factor-wise latent representation \(H_{d}\) for the downstream task. Subsequently, we feed it into a downstream LIBSVM (Chang and Lin, 2011) classifier to predict the label and report the mean 10-fold cross-validation accuracy with standard deviation after 5 runs. We set the initial learning rate to 0.0005 with cosine learning rate decay for most cases. For the evaluation, the parameter C of SVM is searched in the sets \(\{10^{3},...,10\}\).

Data PreparationThe node features for the citation networks (Cora, Citeseer, Pubmed) are bag-of-words document representations. For the protein-protein interaction networks (PPI), the features of each node are composed of positional gene sets, motif gene sets and immunological signatures (50 in total). For graph classification, the MUTAG, PROTEINS, and NCI1 datasets utilize node labels as node features, represented in the form of one-hot encoding. For IMDB-B, IMDB-M, REDDIT-B, and COLLAB, which lack node features, we utilize the node degree and convert it into a one-hot encoding as a substitute feature. The maximum node degree is set to 400. Nodes with degrees surpassing 400 are uniformly treated as having a degree of 400, following the methodology of GraphMAE(Hou et al., 2022). Table 5 and Table 6 show the specific statistics of used datasets.

Details for VisualizationMUTAG is selected as the representative benchmark for visualization in 4.3. The MUTAG dataset comprises 3,371 nodes with seven node types. The distribution is highly skewed, as 3,333 nodes belong to three types, while the remaining four types collectively represent less than 1.2% of the nodes. For clarity in legend display, we have visualized only the nodes belonging to the first three types.

### Disentangled Representations Visualization

We chose PROTEINS and IMDB-MULTI as representatives of the graph classification dataset, and followed the same methodology as in Section 4.3 to visualize their representation correlation matrices on GraphMAE, and community representation correlation matrices on DiGGR, respectively. The feature dimensions of PROTEINS and IMDB-MULTI are both 512 dimensions, and the number of communities is set to 4.

\begin{table}
\begin{tabular}{c|c|c c c c} \hline \hline  & Dataset & Cora & Citeseer & Pubmed & PPI \\ \hline \multirow{4}{*}{Statistics} & \# node & 2708 & 3327 & 19717 & 56944 \\  & \# feature & 1433 & 3703 & 500 & 50 \\  & \# edges & 5429 & 4732 & 44338 & 818736 \\  & \# classes & 7(s) & 6(s) & 3(s) & 121(m) \\ \hline \multirow{4}{*}{Hyper-parameters} & Mask Rate & 0.5 & 0.5 & 0.75 & 0.5 \\  & Hidden Size & 512 & 512 & 1024 & 1024 \\ \cline{1-1}  & Max Epoch & 1750 & 200 & 1000 & 1000 \\ \cline{1-1}  & \(\lambda_{\text{d}}\); \(\lambda_{\text{g}}\); \(\lambda_{\text{g}}\) & 1; 1; 1 & 1; 1; 2 & 1; 1; 1 & 1; 1; 1 \\ \cline{1-1}  & Learning Rate & 0.001 & 0.0005 & 0.001 & 0.0001 \\ \cline{1-1}  & Factor\_Num & 4 & 4 & 2 & 2 \\ \hline \hline \end{tabular}
\end{table}
Table 5: Statistics for node classification datasets.

The result is presented in Figure 6. We can see from the results that the graph representations of GraphMAE are entangled. In contrast, the correlation pattern exhibited by DiGGR reveals four distinct diagonal blocks. This suggests that DiGGR is proficient at capturing mutually exclusive information within the latent factor, resulting in disentangled representations.

### Training Algorithm

\begin{table}
\begin{tabular}{c|c|c c c c c c c} \hline \hline  & Dataset & IMDB-B & IMDB-M & PROTEINS & COLLAB & MUTAG & REDDIT-B & NCI1 \\ \hline \multirow{4}{*}{Statistics} & Avg. \# node & 19.8 & 13.0 & 39.1 & 74.5 & 17.9 & 429.7 & 29.8 \\  & \# features & 136 & 89 & 3 & 401 & 7 & 401 & 37 \\  & \# graphs & 1000 & 1500 & 1113 & 5000 & 188 & 2000 & 4110 \\  & \# classes & 2 & 3 & 2 & 3 & 2 & 2 & 2 \\ \hline \multirow{4}{*}{
\begin{tabular}{c} Hyper- \\ parameters \\ \end{tabular} } & Mask Rate & 0.5 & 0.5 & 0.5 & 0.75 & 0.75 & 0.75 & 0.25 \\  & Hidden Size & 512 & 512 & 512 & 256 & 32 & 512 & 1024 \\  & Max Epoch & 300 & 200 & 50 & 20 & 20 & 200 & 200 \\  & Learning Rate & 0.0001 & 0.001 & 0.0005 & 0.001 & 0.001 & 0.0005 & 0.0005 \\  & \(\lambda_{\text{d}}\); \(\lambda_{\text{g}}\); \(\lambda_{\text{a}}\) & 1; 1; 1 & 1; 1; 1 & 1; 1; 1 & 1; 1; 1 & 1; 1; 1 & 1; 1; 0.5; 1 \\  & Batch\_Size & 32 & 32 & 32 & 32 & 32 & 16 & 32 \\  & Pooling\_Type & mean & mean & max & max & sum & max & max \\  & Factor\_Num & 2 & 4 & 4 & 4 & 2 & 2 & 4 \\ \hline \hline \end{tabular}
\end{table}
Table 6: Statistics for graph classification datasets.

Figure 6: The absolute correlation between the representations learned by GraphMAE and DiGGR is measured on the **PROTEINS** and **IMDB-MULTI** datasets when \(K=4\).

### Broader Impacts

This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none which we feel must be specifically highlighted here.

### Limitations

Despite the promising experimental justifications, our work might potentially suffer from limitation: Although the complexity of the model is discussed in Section 3.4, and it is comparable to previously published work, extending DiGGR to extremely large graph datasets remains challenging at this stage due to the incorporation of an additional probabilistic model into the generative graph framework. One potential solution to this problem could be utilizing PPR-Nibble (Andersen et al., 2006) for efficient implementation, a method that has proven effective in some graph generative models (Hou et al., 2023). This approach will be pursued in our future work.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: We listed our main contribution in the last paragraph of Section 1 Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: We've discuss about the limitations in Appendix A.6 Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [NA]Justification: This paper is not focus on theoretical explanations and assumptions Guidelines:

* The answer NA means that the paper does not include theoretical results.
* All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
* All assumptions should be clearly stated or referenced in the statement of any theorems.
* The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.
* Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.
* Theorems and Lemmas that the proof relies upon should be properly referenced.

## 4 Experimental Result Reproducibility

Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)?

Answer: [Yes]

Justification: We have listed the specific settings of the experiment in the appendix A.2 of the paper, including the datasets used and the hyperparameter settings of the model. We have also uploaded the code in the supplementary material.

Guidelines:

* The answer NA means that the paper does not include experiments.
* If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.
* If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.
* Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.
* While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code**Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?

Answer: [Yes] Justification: We have uploaded the code in the supplementary material. Guidelines:

* The answer NA means that paper does not include experiments requiring code.
* Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: We have listed the specific experimental setup in Appendix A.2 Guidelines:

* The answer NA means that the paper does not include experiments.
* The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them.
* The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: In the main experiment 4, we ran 5 different random seeds for each dataset and reported the average results and variances in the table6 and 5. Guidelines:

* The answer NA means that the paper does not include experiments.
* The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.
* The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).

* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: We listed the experiment environment in AppendixA.2 Guidelines: The answer NA means that the paper does not include experiments.
* The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.
* The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.
* The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: We conform with the NeurIPS Code of Ethics in every respect for this paper. Guidelines: The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
* If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.
* The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: We have discussed in appendix A.5 Guidelines: The answer NA means that there is no societal impact of the work performed.
* If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.
* Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.

* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: this paper poses no such risks. Guidelines: * The answer NA means that the paper poses no such risks.
* Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.
* Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.
* We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licensees for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: All these are properly credited. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.

* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: This paper does not release new assets. Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.