# Graph Edit Distance with General Costs

Using Neural Set Divergence

 Eeshaan Jain &Indradyumna Roy1\({}^{\ddagger}\)

Saswat Meher\({}^{\ddagger}\) Soumen Chakrabarti\({}^{\ddagger}\) Abir De\({}^{\ddagger}\)

\({}^{\dagger}\)EPFL \({}^{\ddagger}\)IIT Bombay

eeshaan.jain@epfl.ch

{saswatmeher,soumen,indraroy15,abir}@cse.iitb.ac.in

Equal contribution. Eeshaan Jain did this work while at IIT Bombay.

38th Conference on Neural Information Processing Systems (NeurIPS 2024).

###### Abstract

Graph Edit Distance (GED) measures the (dis-)similarity between two given graphs, in terms of the minimum-cost edit sequence that transforms one graph to the other. However, the exact computation of GED is NP-Hard, which has recently motivated the design of neural methods for GED estimation. However, they do not explicitly account for edit operations with different costs. In response, we propose GraphEdX, a neural GED estimator that can work with general costs specified for the four edit operations, _viz._, edge deletion, edge addition, node deletion and node addition. We first present GED as a quadratic assignment problem (QAP) that incorporates these four costs. Then, we represent each graph as a set of node and edge embeddings and use them to design a family of neural set divergence surrogates. We replace the QAP terms corresponding to each operation with their surrogates. Computing such neural set divergence require aligning nodes and edges of the two graphs. We learn these alignments using a Gumbel-Sinkhorn permutation generator, additionally ensuring that the node and edge alignments are consistent with each other. Moreover, these alignments are cognizant of both the presence and absence of edges between node-pairs. Experiments on several datasets, under a variety of edit cost settings, show that GraphEdX consistently outperforms state-of-the-art methods and heuristics in terms of prediction error. The code is available at https://github.com/structlearning/GraphEdX.

## 1 Introduction

The Graph Edit Distance (GED) between a source graph, \(G\), and a target graph, \(G^{\prime}\), quantifies the minimum cost required to transform \(G\) into a graph isomorphic to \(G^{\prime}\). This transformation involves a sequence of edit operations, which can include node and edge insertions, deletions and substitutions. Each type of edit operation may incur a different and distinctive cost, allowing the GED framework to incorporate domain-specific knowledge. Its flexibility has led to the widespread use of GED for comparing graphs across diverse applications including graph retrieval [5, 6], pattern recognition [47], image and video indexing [51, 49] and chemoinformatics [21]. Because costs for addition and deletion may differ, GED is not necessarily symmetric, _i.e._, \(\mathrm{GED}(G,G^{\prime})\neq\mathrm{GED}(G^{\prime},G)\). This flexibility allows GED to model a variety of graph comparison scenarios, such as finding the Maximum Common Subgraph [43] and checking for Subgraph Isomorphism [13]. In general, it is hard to even approximate GED [32]. Recent work [5, 6, 19, 56, 39] has leveraged graph neural networks (GNNs) to build neural models for GED computation, but many of these approaches cannot account for edit operations with different costs. Moreover, several approaches [40, 31, 56, 6] cast GED as the Euclidean distance between graph embeddings, leading to models that are overly attuned to cost-invariant edit sequences.

### Present work

We propose a novel neural model for computing GED, designed to explicitly incorporate the various costs of edit operations. Our contributions are detailed as follows.

Neural set divergence surrogates for GEDWe formulate GED under general (non-uniform) cost as a quadratic assignment problem (QAP) with four asymmetric distance terms representing edge deletion, edge addition, node deletion and node addition. The edge-edit operations involve quadratic dependencies on a node alignment plan -- a proposed mapping of nodes from the source graph to the target graph. To avoid the the complexity of QAP [45], we design a family of differentiable set divergence surrogates, which can replace the QAP objective with a more benign one. In this approach, each graph is represented as a set of embeddings of nodes and node-pairs (edges or non-edges). We replace the original QAP distance terms with their corresponding set divergences, and obtain the node alignment from a differentiable alignment generator modeled using a Gumbel-Sinkhorn network. This network produces a soft node permutation matrix based on contextual node embeddings from the graph pairs, enabling the computation of the overall set divergence in a differentiable manner, which facilitates end-to-end training. Our proposed model relies on late interaction, where the interactions between the graph pairs occur only at the final layer, rather than during the embedding computation in the GNN. This supports the indexing of embedding vectors, thereby facilitating efficient retrieval through LSH [25; 24; 12], inverted index [20], graph based ANN [34; 37]_etc_.

Learning all node-pair representationsThe optimal sequence of edits in GED is heavily influenced by the global structure of the graphs. A perturbation in one part of the graph can have cascading effects, necessitating edits in distant areas. To capture this sensitivity to structural changes, we associate both edges as well as non-edges with suitable expressive embeddings that capture the essence of subgraphs surrounding them. Note that the embeddings for non-edges are never explicitly computed during GNN message-passing operations. They are computed only once, after the GNN has completed its usual message-passing through _existing_ edges, thereby minimizing additional computational overhead.

Node-edge consistent alignmentTo ensure edge-consistency in the learned node alignment map, we explicitly compute the node-pair alignment map from the node alignment map and then utilize this derived map to compute collective edge deletion and addition costs. More precisely, if \((u,v)\in G\) and \((u^{\prime},v^{\prime})\in G^{\prime}\) are matched, then the nodes \(u\) and \(v\) are constrained to match with \(u^{\prime}\) and \(v^{\prime}\) (or, \(v^{\prime}\) and \(u^{\prime}\)) respectively. We call our neural framework as GraphEdX.

Our experiments across several real datasets show that (1) GraphEdX outperforms several state-of-the-art methods including those that use early interaction; (2) the performance of current state-of-the-art methods improves significantly when their proposed distance measures are adjusted to reflect GED-specific distances, as in our approach.

## 2 Related work

Heuristics for Graph Edit DistanceGED was first introduced in [46]. Bunke and Allermann [14] used it as a tool for non exact graph matching. Later on, [13] connected GED with maximum common subgraph estimation. Blumenthal [7] provide an excellent survey. As they suggest, combinatorial heuristics to solve GED predominantly follows three approaches: (1) Linear sum assignment problem with error-correction, which include [27; 41; 53; 55] (2) Linear programming, which predominantly uses standard tools like Gurobi, (3) Local search [42]. However, they can be extremely time consuming, especially for a large number of graph pairs. Among them Zheng et al. [55] operate in our problem setting, where the cost of edits are different across the edit operations, but for the same edit operation, the cost is same across node or node pairs.

Optimal TransportIn our work, we utilize Graph Neural Networks (GNNs) to represent each graph as a set of node embeddings. This transforms the inherent Quadratic Assignment Problem (QAP) of graph matching into a Linear Sum Assignment Problem (LSAP) on the sets of node embeddings. Essentially, this requires solving an optimal transport problem in the node embedding space. The use of neural surrogates for optimal transport was first proposed by Cuturi [16], who introduced entropy regularization to make the optimal transport objective strictly convex and utilized Sinkhorn iterations [50] to obtain the transport plan. Subsequently, Mena et al. [35] proposed the neural Gumbel Sinkhorn network as a continuous and differentiable surrogate of a permutation matrix, which we incorporate into our model.

In various generative modeling applications, optimal transport costs are used as loss functions, such as in Wasserstein GANs [1; 3]. Computing the optimal transport plan is a significant challenge, with approaches leveraging the primal formulation [52; 33], the dual formulation with entropy regularization [17; 48; 22], or Input Convex Neural Networks (ICNNs) [2].

Neural graph similarity computationMost earlier works on neural graph similarity computation have focused on training with GED values as ground truth [5; 6; 19; 40; 56; 39; 54; 31], while some have used MCS as the similarity measure [6; 5]. Current neural models for GED approximation primarily follow two approaches. The first approach uses a trainable nonlinear function applied to graph embeddings to compute GED [5; 39; 6; 54; 19]. The second approach calculates GED based on the Euclidean distance in the embedding space [31; 40].

Among these models, GOTSIM [19] focuses solely on node insertion and deletion, and computes node alignment using a combinatorial routine that is decoupled from end-to-end training. However, their network struggles with training efficiency due to the operations on discrete values, which are not amenable to backpropagation. With the exception of GREED [40] and Graph Embedding Network (GEN) [31], most methods use early interaction or nonlinear scoring functions, limiting their adaptability to efficient indexing and retrieval pipelines.

## 3 Problem setup

NotationThe source graph is denoted by \(G=(V,E)\) and the target graph by \(G^{\prime}=(V^{\prime},E^{\prime})\). Both graphs are undirected and are padded with isolated nodes to equalize the number of nodes to \(N\). The adjacency matrices for \(G\) and \(G^{\prime}\) after padding are \(\bm{A},\bm{A^{\prime}}\in\left\{0,1\right\}^{N\times N}\). (Note that we will use \(M^{\top}\), not \(M^{\prime}\), for the transpose of matrix \(M\).) The sets of padded nodes in \(G\) and \(G^{\prime}\) are denoted by \(\mathrm{PaddedNodes}_{G}\) and \(\mathrm{PaddedNodes}_{G^{\prime}}\) respectively. We construct \(\bm{\eta}\in\left\{0,1\right\}^{N}\), where \(\bm{\eta}[u]=0\) if \(u\in\mathrm{PaddedNodes}_{G}\) and \(1\) otherwise (same for \(G^{\prime}\)). The embedding of a node \(u\in V\) computed at propagation layer \(k\) by the GNN, is represented as \(\bm{x}_{k}(u)\). Edit operations, denoted by \(\mathrm{edit}\), belong to one of four types, _viz._, (i) node deletion, (ii) node addition, (iii) edge deletion, (iv) edge addition. Each operation \(\mathrm{edit}\) is assigned a \(\mathrm{cost}\,\mathrm{cost}(\mathrm{edit})\). The node and node-pair alignment maps are described using (hard) permutation matrices \(\bm{P}\in\left\{0,1\right\}^{N\times N}\) and \(\bm{S}\in\left\{0,1\right\}^{\binom{N}{2}\times\binom{N}{2}}\) respectively. Given that the graphs are undirected, node-pair alignment need only be specified across at most \(\binom{N}{2}\) pairs. When a hard permutation matrix is relaxed to a doubly-stochastic matrix, we call it a soft permutation matrix. We use \(\bm{P}\) and \(\bm{S}\) to refer to both hard and soft permutations, depending on the context. We denote \(\mathbb{P}_{N}\) as the set of all hard permutation matrices of dimension \(N\); \([N]\) as \(\left\{1,\ldots,N\right\}\) and \(\left\|\bm{A}\right\|_{1,1}\) to describe \(\sum_{u,v}|\bm{A}[u,v]|\). For two binary variables \(c_{1},c_{2}\in\left\{0,1\right\}\), we denote \(J(c_{1},c_{2})\) as (\(c_{1}\) XOR \(c_{2}\)), _i.e._, \(J(c_{1},c_{2})=c_{1}c_{2}+(1-c_{1})(1-c_{2})\).

Graph edit distance with general costWe define an _edit path_ as a sequence of edit operations \(\bm{o}=\{\mathrm{edit}_{1},\mathrm{edit}_{2},\ldots\}\); and \(\mathcal{O}(G,G^{\prime})\) as the set of all possible edit paths that transform the source graph \(G\) into a graph isomorphic to the target graph \(G^{\prime}\). Given \(\mathcal{O}(G,G^{\prime})\) and the cost associated with each operation \(\mathrm{edit}\), the GED between \(G\) and \(G^{\prime}\) is the minimum collective cost across all edit paths in \(\mathcal{O}(G,G^{\prime})\). Formally, we write [14; 7]:

\[\mathrm{GED}(G,G^{\prime})=\min_{\bm{o}=\{\mathrm{edit}_{1},\mathrm{edit}_{2 },\ldots\}\in\mathcal{O}(G,G^{\prime})}\ \sum_{i\in[|\bm{o}|]}\mathrm{cost}(\mathrm{edit}_{i}).\] (1)

In this work, we assume a fixed cost for each of the four types of edit operations. Specifically, we use \(a^{\ominus}\), \(a^{\oplus}\), \(b^{\ominus}\) and \(b^{\oplus}\) to represent the costs for edge deletion, edge addition, node deletion, and node addition, respectively. These costs are not necessarily uniform, in contrast to the assumptions made in previous works [5; 31; 56; 39]. Additional discussion on GED with node substitution in presence of labels can be found in Appendix B.

Problem statementOur objective is to design a neural architecture for predicting GED under a general cost framework, where the edit costs \(a^{\ominus}\), \(a^{\oplus}\), \(b^{\ominus}\) and \(b^{\oplus}\) are not necessarily the same. During the learning stage, these four costs are specified, and remain fixed across all training instances \(\mathcal{D}=\left\{(G_{i},G^{\prime}_{i},\mathrm{GED}(G_{i},G^{\prime}_{i})) \right\}_{i\in[n]}\). Note that the edit paths are not supervised. Later, given a test instance \(G,G^{\prime}\), assuming the same four costs, the trained system has to predict \(\mathrm{GED}(G,G^{\prime})\).

## 4 Proposed approach

In this section, we first present an alternative formulation of GED as described in Eq. (1), where the edit paths are induced by node alignment maps. Then, we adapt this formulation to develop GraphEdX, a neural set distance surrogate, amenable to end-to-end training. Finally, we present the network architecture of GraphEdX.

### GED computation using node alignment map

Given the padded graph pair \(G\) and \(G^{\prime}\), deleting a node \(u\in V\) can be viewed as aligning node \(u\) with some padded node \(u^{\prime}\in\mathrm{PaddedNodes}_{G^{\prime}}\). Similarly, adding a new node \(u^{\prime}\) to \(G\) can be seen as aligning some padded node \(u\in\mathrm{PaddedNodes}_{G}\) with node \(u^{\prime}\in V^{\prime}\). Likewise, adding an edge to \(G\) corresponds to aligning a non-edge \((u,v)\not\in E\) with an edge \((u^{\prime},v^{\prime})\in G^{\prime}\). Conversely, deleting an edge in \(G\) corresponds to aligning an edge \((u,v)\in G\) with a non-edge \((u^{\prime},v^{\prime})\notin G^{\prime}\).

Therefore, \(\mathrm{GED}(G,G^{\prime})\) can be defined in terms of a node alignment map. Let \(\Pi_{N}\) represent the set of all node alignment maps \(\pi:[N]\rightarrow[N]\) from \(V\) to \(V^{\prime}\). Recall that \(\bm{\eta}_{G}[u]=0\) if \(u\in\mathrm{PaddedNodes}_{G}\) and \(1\) otherwise.

\[\min_{\pi\in\Pi_{N}} \frac{1}{2}\sum_{u,v}\left(a^{\odot}\cdot\mathbb{I}\left[(u,v) \in E\wedge(\pi(u),\pi(v))\not\in E^{\prime}\right]+a^{\oplus}\cdot\mathbb{I} \left[(u,v)\not\in E\wedge(\pi(u),\pi(v))\in E^{\prime}\right]\right)\] \[+\sum_{u}\left(b^{\odot}\cdot\bm{\eta}_{G}[u]\left(1-\bm{\eta}_{G ^{\prime}}[\pi(u)]\right)+b^{\oplus}\cdot\left(1-\bm{\eta}_{G}[u]\right)\bm{ \eta}_{G^{\prime}}[\pi(u)]\right).\] (2)

In the above expression, the first sum iterates over all pairs of \((u,v)\in[N]\times[N]\) and the second sum iterates over \(u\in[N]\). Because both graphs are undirected, the fraction \(1/2\) accounts for double counting of the edges. The first and second terms quantify the cost of deleting and adding the edge \((u,v)\) from and to \(G\), respectively. The third and the fourth terms evaluate the cost of deleting and adding node \(u\) from and to \(G\), respectively.

GED as a Quadratic Assignment ProblemIn its current form, Eq. (2) cannot be immediately adapted to a differentiable surrogate. To circumvent this problem, we provide an equivalent matricized form of Eq. (2), using a hard node permutation matrix \(\bm{P}\) instead of the alignment map \(\pi\). We compute the asymmetric distances between \(\bm{A}\) and \(\bm{PA^{\prime}P^{\top}}\) and combine them with weights \(a^{\odot}\) and \(a^{\oplus}\). Notably, \(\mathrm{ReLU}\left(\bm{A}-\bm{PA^{\prime}P^{\top}}\right)[u,v]\) is non-zero if the edge \((u,v)\in E\) is mapped to a non-edge \((u^{\prime},v^{\prime})\in E^{\prime}\) with \(\bm{P}[u,u^{\prime}]=\bm{P}[v,v^{\prime}]=1\), indicating deletion of the edge \((u,v)\) from \(G\). Similarly, \(\mathrm{ReLU}\left(\bm{PA^{\prime}P^{\top}}-\bm{A}\right)[u,v]\) becomes non-zero if an edge \((u,v)\) is added to \(G\). Therefore, for the edit operations involving edges, we have:

\[\mathbb{I}\left[(u,v)\in E\wedge(\pi(u),\pi(v))\not\in E^{\prime} \right]=\mathrm{ReLU}\left(\bm{A}-\bm{PA^{\prime}P^{\top}}\right)[u,v],\] (3) \[\mathbb{I}\left[(u,v)\not\in E\wedge(\pi(u),\pi(v))\in E^{\prime} \right]=\mathrm{ReLU}\left(\bm{PA^{\prime}P^{\top}}-\bm{A}\right)[u,v].\] (4)

Similarly, we note that \(\mathrm{ReLU}\left(\bm{\eta}_{G}[u]-\bm{\eta}_{G^{\prime}}[\pi(u)]\right)>0\) if \(u\not\in\mathrm{PaddedNodes}_{G}\) and \(\pi(u)\in\mathrm{PaddedNodes}_{G^{\prime}}\), which allows us to compute the cost of deleting the node \(u\) from \(G\). Similarly, we use \(\mathrm{ReLU}\left(\bm{\eta}_{G^{\prime}}[\pi(u)]-\bm{\eta}_{G}[u]\right)\) to account for the addition of the node \(u\) to \(G\). Formally, we write:

\[\bm{\eta}_{G}[u]\left(1-\bm{\eta}_{G^{\prime}}[\pi(u)]\right) =\mathrm{ReLU}\left(\bm{\eta}_{G}[u]-\bm{\eta}_{G^{\prime}}[\pi(u )]\right),\] (5) \[\left(1-\bm{\eta}_{G}[u]\right)\bm{\eta}_{G^{\prime}}[\pi(u)] =\mathrm{ReLU}\left(\bm{\eta}_{G^{\prime}}[\pi(u)]-\bm{\eta}_{G}[ u]\right).\] (6)

Using Eqs. (3)-(6), we rewrite Eq. (2) as:

\[\mathrm{GED}(G,G^{\prime})= \min_{\bm{P}\in\mathbb{F}_{N}}\ \frac{a^{\odot}}{2}\left\|\mathrm{ReLU} \left(\bm{A}-\bm{PA^{\prime}P^{\top}}\right)\right\|_{1,1}+\frac{a^{\oplus}}{2} \left\|\mathrm{ReLU}\left(\bm{PA^{\prime}P^{\top}}-\bm{A}\right)\right\|_{1,1}\] \[+b^{\oplus}\left\|\mathrm{ReLU}\left(\bm{\eta}_{G}-\bm{P}\bm{ \eta}_{G^{\prime}}\right)\right\|_{1}+b^{\oplus}\left\|\mathrm{ReLU}\left( \bm{P}\bm{\eta}_{G^{\prime}}-\bm{\eta}_{G}\right)\right\|_{1}.\] (7)

The first and the second term denote the collective costs of deletion and addition of edges, respectively. The third and the fourth terms present a matricized representation of Eqs. (5)- (6). The above problem can be viewed as a quadratic assignment problem (QAP) on graphs, given that the hard node permutation matrix \(\bm{P}\) has a quadratic involvement in the first two terms. Note that, in general, \(\mathrm{GED}(G,G^{\prime})\neq\mathrm{GED}(G^{\prime},G)\). However, the optimal edit paths for these two GED values, encoded by the respective node permutation matrices, are inverses of each other, as formally stated in the following proposition (proven in Appendix B).

**Proposition 1**: _Given a fixed set of values of \(b^{\odot},b^{\oplus},a^{\odot},a^{\oplus}\), let \(\bm{P}\) be an optimal node permutation matrix corresponding to \(\mathrm{GED}(G,G^{\prime})\), computed using Eq. (7). Then, \(\bm{P}^{\prime}=\bm{P}^{\top}\) is an optimal node permutation corresponding to \(\mathrm{GED}(G^{\prime},G)\)._

Connection to different notions of graph matchingThe above expression of GED can be used to represent various notions of graph matching and similarity measures by modifying the edit costs. These include graph isomorphism, subgraph isomorphism, and maximum common edge subgraphdetection. For example, by setting all costs to one, \(\mathrm{GED}(G,G^{\prime})=\min_{\bm{P}}\frac{1}{2}||\bm{A}-\bm{P}\bm{A}^{\prime} \bm{P}^{\top}||_{1}+||\bm{\eta}_{G}-\bm{P}\bm{\eta}_{G^{\prime}}||_{1}\), which equals zero only when \(G\) and \(G^{\prime}\) are isomorphic. Further discussion on this topic is provided in Appendix B.

### GraphEdX model

Minimizing the objective in Eq. (7) is a challenging problem. In similar problems, recent methods have approximated the hard node permutation matrix \(\bm{P}\) with a soft permutation matrix obtained using Sinkhorn iterations on a neural cost matrix. However, the binary nature of the adjacency matrix and the pad indicator \(\bm{\eta}\) still impede the flow of gradients during training. To tackle this problem, we make relaxations in two key places within each term in Eq. (7), leading to our proposed GraphEdX model.

1. We replace the binary values in \(\bm{\eta}_{G},\bm{\eta}_{G^{\prime}},\bm{A}\) and \(\bm{A}^{\prime}\) with real values from node and node-pair embeddings: \(\bm{X}\in\mathbb{R}^{N\times d}\) and \(\bm{R}\in\mathbb{R}^{\binom{N}{2}\times D}\). These embeddings are computed using a GNN guided neural module \(\textsc{Embed}_{\theta}\) with parameter \(\theta\). Since the graphs are undirected, \(\bm{R}\) gathers the embeddings of the unique node-pairs, resulting in \(\binom{N}{2}\) rows instead of \(N^{2}\).
2. We substitute the hard node permutation matrix \(\bm{P}\) with a soft alignment matrix, generated using a differentiable alignment planner \(\textsc{PermNet}_{\phi}\) with parameter \(\phi\). Here, \(\bm{P}\) is a doubly stochastic matrix, with \(\bm{P}[u,u^{\prime}]\) indicating the "score" or "probability" of aligning \(u\mapsto u^{\prime}\). Additionally, we also compute the corresponding node-pair alignment matrix \(\bm{S}\).

Using these relaxations, we approximate the four edit costs in Eq. (7) with four continuous set distance surrogate functions.

\[\begin{split}&\left\|\mathrm{ReLU}\left(\bm{A}-\bm{P}\bm{A}^{ \prime}\bm{P}^{\top}\right)\right\|_{1,1}\rightarrow\Delta^{\odot}(\bm{R},\bm{ R}^{\prime}\,|\,\bm{S}),\quad\left\|\mathrm{ReLU}\left(\bm{P}\bm{A}^{\prime}\bm{P}^{ \top}-\bm{A}\right)\right\|_{1,1}\rightarrow\Delta^{\oplus}(\bm{R},\bm{R}^{ \prime}\,|\,\bm{S}),\\ &\left\|\mathrm{ReLU}\left(\bm{\eta}_{G}-\bm{P}\bm{\eta}_{G^{ \prime}}\right)\right\|_{1}\rightarrow\Delta^{\odot}(\bm{X},\bm{X}^{\prime} \,|\,\bm{P}),\quad\left\|\mathrm{ReLU}\left(\bm{P}\bm{\eta}_{G^{\prime}}-\bm{ \eta}_{G}\right)\right\|_{1}\rightarrow\Delta^{\oplus}(\bm{X},\bm{X}^{\prime} \,|\,\bm{P}).\end{split}\]

This gives us an approximated GED parameterized by \(\theta\) and \(\phi\).

\[\begin{split}\mathrm{GED}_{\theta,\phi}(G,G^{\prime})& =a^{\odot}\Delta^{\oplus}(\bm{R},\bm{R}^{\prime}\,|\,\bm{S})+a^{ \oplus}\Delta^{\oplus}(\bm{R},\bm{R}^{\prime}\,|\,\bm{S})\\ &+b^{\ominus}\Delta^{\oplus}(\bm{X},\bm{X}^{\prime}\,|\,\bm{P})+ b^{\oplus}\Delta^{\oplus}(\bm{X},\bm{X}^{\prime}\,|\,\bm{P}).\end{split}\] (8)

Note that since \(\bm{R}\) and \(\bm{R}^{\prime}\) contain the embeddings of each node-pair only once, there is no need to multiply \(1/2\) in the first two terms, unlike Eq. (7). Next, we propose three types of neural surrogates to approximate each of the four operations.

(1) AlignDiffGiven the node-pair embeddings \(\bm{R}\) and \(\bm{R}^{\prime}\) for the graph pairs \(G\) and \(G^{\prime}\), we apply the soft node-pair alignment \(\bm{S}\) to \(\bm{R}^{\prime}\). We then define the edge edits in terms of asymmetric

Figure 1: **Top:** Example graphs \(G\) and \(G^{\prime}\) are shown with color-coded nodes to indicate alignment corresponding to the optimal edit path transforming \(G\) to \(G^{\prime}\). **Bottom:** GraphEdXâ€™s GED prediction pipeline. \(G\) and \(G^{\prime}\) are independently encoded using \(\mathrm{MPNN}_{\theta}\), and then padded with zero vectors to equalize sizes, resulting in contextual node representations \(\bm{X},\bm{X}^{\prime}\in\mathbb{R}^{N\times d}\). For each node-pair, the corresponding embeddings and edge presence information are gathered and fed into \(\mathrm{MLP}_{\theta}\) to obtain \(\bm{R},\bm{R}^{\prime}\in\mathbb{R}^{N(N-1)/2\times D}\). Simultaneously, \(\bm{X},\bm{X}^{\prime}\) are fed into \(\textsc{PermNet}_{\phi}\) to obtain the soft node alignment \(\bm{P}\) (Eq.(16)) which constructs the node-pair alignment matrix \(\bm{S}\in\mathbb{R}^{N(N-1)/2\times N(N-1)/2}\) as \(\bm{S}[(u,v),(u^{\prime},v^{\prime})]=\bm{P}[u,u^{\prime}]\bm{P}[v,v^{\prime} ]+\bm{P}[u,v^{\prime}]\bm{P}[v,u^{\prime}]\). Finally, \(\bm{X},\bm{X}^{\prime},\bm{P}\) are used to approximate node insertion and deletion costs, while \(\bm{R},\bm{R}^{\prime},\bm{S}\) are used to approximate edge insertion and deletion costs. The four costs are summed to give the final prediction \(\mathrm{GED}_{\theta,\phi}(G,G^{\prime})\) (Eq.(8)).

differences between \(\bm{R}\) and \(\bm{SR^{\prime}}\), which serves as a replacement for the corresponding terms in Eq. (7). We write \(\Delta^{\odot}(\bm{R},\bm{R^{\prime}}\,|\,\bm{S})\) and \(\Delta^{\oplus}(\bm{R},\bm{R^{\prime}}\,|\,\bm{S})\) as:

\[\Delta^{\odot}(\bm{R},\bm{R^{\prime}}\,|\,\bm{S})=\left\|\mathrm{ReLU}\left(\bm {R}-\bm{SR^{\prime}}\right)\right\|_{1,1},\quad\Delta^{\oplus}(\bm{R},\bm{R^{ \prime}}\,|\,\bm{S})=\left\|\mathrm{ReLU}\left(\bm{SR^{\prime}}-\bm{R}\right) \right\|_{1,1}.\] (9)

Similarly, for the node edits, we can compute \(\Delta^{\odot}(\bm{X},\bm{X^{\prime}}\,|\,\bm{P})\) and \(\Delta^{\oplus}(\bm{X},\bm{X^{\prime}}\,|\,\bm{P})\) as:

\[\Delta^{\odot}(\bm{X},\bm{X^{\prime}}\,|\,\bm{P})=\left\|\mathrm{ReLU}\left( \bm{X}-\bm{PX^{\prime}}\right)\right\|_{1,1},\quad\Delta^{\oplus}(\bm{X},\bm{ X^{\prime}}\,|\,\bm{P})=\left\|\mathrm{ReLU}\left(\bm{PX^{\prime}}-\bm{X} \right)\right\|_{1,1}.\]

**(2) Diffalign** In Eq. (9), we first aligned \(\bm{R^{\prime}}\) using \(\bm{S}\) and then computed the difference from \(\bm{R}\). Instead, here we first computed the pairwise differences between \(\bm{R^{\prime}}\) and \(\bm{R}\) for all pairs of node-pairs (\(e,e^{\prime}\)), and then combine these differences with the corresponding alignment scores \(\bm{S}[e,e^{\prime}]\). We compute the edge edit surrogates \(\Delta^{\odot}(\bm{R},\bm{R^{\prime}}\,|\,\bm{S})\) and \(\Delta^{\oplus}(\bm{R},\bm{R^{\prime}}\,|\,\bm{S})\) as:

\[\Delta^{\odot}(\bm{R},\bm{R^{\prime}}\,|\,\bm{S})=\sum_{e,e^{\prime}}\left\| \mathrm{ReLU}\left(\bm{R}[e,:]-\bm{R^{\prime}}[e^{\prime},:]\right)\right\|_ {1}\bm{S}[e,e^{\prime}],\] (10)

\[\Delta^{\oplus}(\bm{R},\bm{R^{\prime}}\,|\,\bm{S})=\sum_{e,e^{\prime}}\left\| \mathrm{ReLU}\left(\bm{R^{\prime}}[e^{\prime},:]-\bm{R}[e,:]\right)\right\|_ {1}\bm{S}[e,e^{\prime}].\] (11)

Here, \(e\) and \(e^{\prime}\) represent node-pairs, which are not necessarily edges. When the node-pair alignment matrix \(\bm{S}\) is a hard permutation, \(\Delta^{\oplus}\) and \(\Delta^{\odot}\) remain the same across AlignDiff and Diffalign (as shown in Appendix B). Similar to Eqs. (10)--(11), we can compute \(\Delta^{\oplus}(\bm{X},\bm{X^{\prime}}\,|\,\bm{P})=\sum_{u,u^{\prime}}\left\| \mathrm{ReLU}\left(\bm{X}[u,:]-\bm{X^{\prime}}[u^{\prime},:]\right)\right\|_{ 1}\bm{P}[u,u^{\prime}]\) and \(\Delta^{\oplus}(\bm{X},\bm{X^{\prime}}\,|\,\bm{P})=\sum_{u,u^{\prime}}\left\| \mathrm{ReLU}\left(\bm{X^{\prime}}[u^{\prime},:]-\bm{X}[u,:]\right)\right\|_{ 1}\bm{P}[u,u^{\prime}]\).

**(3) XOR-Diffalign** As indicated by the combinatorial formulation of GED in Eq. (7), the edit cost of a particular node-pair is non-zero only when an edge is mapped to a non-edge or vice-versa. However, the surrogates for the edge edits in AlignDiff of Diffalign fail to capture this condition because they can assign non-zero costs to the pairs \((e=(u,v),e^{\prime}=(u^{\prime},v^{\prime}))\) even when both \(e\) and \(e^{\prime}\) are either edges or non-edges. To address this, we explicitly discard such pairs from the surrogates defined in Eqs. (10)-(11). This is ensured by applying a XOR operator \(\tilde{J}\big{(}\cdot,\cdot\big{)}\) between the corresponding entries in the adjacency matrices, _i.e._, \(\bm{A}[u,v]\) and \(\bm{A^{\prime}}[u^{\prime},v^{\prime}]\), and then multiplying this result with the underlying term. Hence, we write:

\[\Delta^{\odot}(\bm{R},\bm{R^{\prime}}\,|\,\bm{S})=\sum_{\begin{subarray}{c}e=(u,v)\\ e^{\prime}=(u^{\prime},v^{\prime})\end{subarray}}J\big{(}\bm{A}[u,v],\bm{A^{ \prime}}[u^{\prime},v^{\prime}]\big{)}\left\|\mathrm{ReLU}\left(\bm{R}[e,:]- \bm{R^{\prime}}[e^{\prime},:]\right)\right\|_{1}\bm{S}[e,e^{\prime}],\] (12)

\[\Delta^{\oplus}(\bm{R},\bm{R^{\prime}}\,|\,\bm{S})=\sum_{\begin{subarray}{c}e=(u,v)\\ e^{\prime}=(u^{\prime},v^{\prime})\end{subarray}}J\big{(}\bm{A}[u,v],\bm{A^{ \prime}}[u^{\prime},v^{\prime}]\big{)}\left\|\mathrm{ReLU}\left(\bm{R^{ \prime}}[e^{\prime},:]-\bm{R}[e,:]\right)\right\|_{1}\bm{S}[e,e^{\prime}].\] (13)

Similarly, the cost contribution for node operations arises from mapping a padded node to a non-padded node or vice versa. We account for this by multiplying \(J(\bm{\eta}_{G}[u],\bm{\eta}_{G^{\prime}}[u^{\prime}])\) with each term of \(\Delta^{\odot}(\bm{X},\bm{X^{\prime}}\,|\,\bm{P})\) and \(\Delta^{\oplus}(\bm{X},\bm{X^{\prime}}\,|\,\bm{P})\) computed using Diffalign. Hence, we compute \(\Delta^{\odot}(\bm{X},\bm{X^{\prime}}\,|\,\bm{P})=\sum_{u,u^{\prime}}J(\bm{ \eta}_{G}[u],\bm{\eta}_{G^{\prime}}[u^{\prime}])\left\|\mathrm{ReLU}\left(\bm{X }[u,:]-\bm{X^{\prime}}[u^{\prime},:]\right)\right\|_{1}\bm{P}[u,u^{\prime}]\) and \(\Delta^{\oplus}(\bm{X},\bm{X^{\prime}}\,|\,\bm{P})=\sum_{u,u^{\prime}}J(\bm{ \eta}_{G}[u],\bm{\eta}_{G^{\prime}}[u^{\prime}])\left\|\mathrm{ReLU}\left(\bm{X }[u^{\prime},:]-\bm{X}[u,:]\right)\right\|_{1}\bm{P}[u,u^{\prime}]\).

**Comparison between AlignDiff, Diffalign and XOR-Diffalign** AlignDiff and Diffalign become equivalent when \(\bm{S}\) is a hard permutation. However, when \(\bm{S}\) is doubly stochastic, the above three surrogates, AlignDiff, Diffalign and XOR-Diffalign, are not equivalent. As we move from AlignDiff to Diffalign to XOR-Diffalign, we increasingly align the design to the inherent inductive biases of GED, thereby achieving a better representation of its cost structure.

Suppose we are computing the GED between two isomorphic graphs, \(G\) and \(G^{\prime}\), with uniform costs for all edit operations. In this scenario, we ideally expect a neural network to consistently output a zero cost. Now consider a proposed soft alignment \(\bm{S}\) which is close to the optimal alignment. Under the AlignDiff design, the aggregated value \(\sum_{e^{\prime}}\bm{S}[e,e^{\prime}]\bm{R^{\prime}}[e^{\prime},:]\) -- where \(e\) and \(e^{\prime}\) represent two edges matched in the optimal alignment -- can accumulate over the large number of \(N(N-1)/2\) node-pairs. This aggregation leads to high values of \(||\bm{R}[e,:]-\bm{SR^{\prime}}[e^{\prime},:]||_{1}\), implying that AlignDiff captures an aggregate measure of the cost incurred by spurious alignments, but cannot disentangle the effect of individual misalignments, making it difficult for AlignDiff to learn the optimal alignment.

In contrast, the Diffalign approach, which relies on pairwise differences between embeddings to explicitly guide \(\bm{S}\) towards the optimal alignment, significantly ameliorates this issue. For example, in the aforementioned setting of GED with uniform costs, the cost associated with each pairing\((e,e^{\prime})\) is explicitly encoded using \(\|\bm{R}[e,:]-\bm{R^{\prime}}[e^{\prime},:]\|_{1}\), and is explicitly set to zero for pairs that are correctly aligned. Moreover, this representation allows DiffAlign to isolate the cost incurred by each misalignment, making it easier to train the model to reduce the cost of these spurious matches to zero.

However, DiffAlign does not explicitly set edge-to-edge and non-edge-to-non-edge mapping costs to zero, potentially leading to inaccurate GED estimates. XOR-DiffAlign addresses these concerns by applying a XOR of the adjacency matrices to the cost matrix, ensuring that non-zero cost is computed only when mapping an edge to a non-edge or vice versa. This resolves the issues in both AlignDiff and DiffAlign by focusing on mismatches between edges and non-edges, while disregarding redundant alignments that do not contribute to the GED.

**Amenability to indexing and approximate nearest neighbor (ANN) search.** All of the aforementioned distance surrogates are based on a late interaction paradigm, where the embeddings of \(G\) and \(G^{\prime}\) are computed independently of each other before computing the distances \(\Delta\). This is particularly useful in the context of graph retrieval, as it allows for the corpus graph embeddings to be indexed a-priori, thereby enabling efficient retrieval of relevant graphs for new queries.

When the edit costs are uniform, our predicted GED (8) becomes symmetric with respect to \(G\) and \(G^{\prime}\). In such cases, DiffAlign and AlignDiff yield a structure similar to the Wasserstein distance induced by \(L_{1}\) norm. This allows us to leverage ANN techniques like Quadtree or Flowtree [4]. However, while the presence of the XOR operator \(J\) within each term in Eq. (12) - (13) of XOR-DiffAlign enhances the interaction between \(G\) and \(G^{\prime}\), this same feature prevents XOR-DiffAlign from being cast to an ANN-amenable setup, unlike DiffAlign and AlignDiff.

### Network architecture of Embed\({}_{\theta}\) and PermNet\({}_{\phi}\)

In this section, we present the network architectures of the two components of GraphEdX, _viz._, Embed\({}_{\theta}\) and PermNet\({}_{\phi}\), as introduced in items (1) and (2) in Section 4.2. Notably, in our proposed graph representation, non-edges and edges alike are embedded as non-zero vectors. In other words, all node-pairs are endowed with non-trivial embeddings. We then explain the design approach for edge-consistent node alignment.

**Neural architecture of Embed\({}_{\theta}\)** Embed\({}_{\theta}\) consists of a message passing neural network \(\mathrm{MPNN}_{\theta}\) and a decoupled neural module \(\text{MLP}_{\theta}\). Given the graphs \(G,G^{\prime}\), \(\mathrm{MPNN}_{\theta}\) with \(K\) propagation layers is used to iteratively compute the node embeddings \(\left\{\bm{x}_{K}(u)\in\mathbb{R}^{d}\,|\,u\in V\right\}\) and \(\left\{\bm{x}^{\prime}_{K}(u)\in\mathbb{R}^{d}\,|\,u\in V^{\prime}\right\}\), then collect them into \(\bm{X}\) and \(\bm{X^{\prime}}\) after padding, _i.e._,

\[\bm{X}:=\left\{\bm{x}_{K}(u)\,|\,u\in[N]\right\}=\mathrm{MPNN}_{\theta}(G), \quad\bm{X^{\prime}}:=\left\{\bm{x}^{\prime}_{K}(u^{\prime})\,|\,u^{\prime} \in[N]\right\}=\mathrm{MPNN}_{\theta}(G^{\prime}).\] (14)

The optimal alignment \(\bm{S}\) is highly sensitive to the global structure of the graph pairs, _i.e._, \(\bm{S}[e,e^{\prime}]\) can significantly change when we perturb \(G\) or \(G^{\prime}\) in regimes distant from \(e\) or \(e^{\prime}\). Conventional representations mitigate this sensitivity while training models, by setting non-edges to zero, rendering them invariant to structural changes. To address this limitation, we utilize more expressive graph representations, where non-edges are also embedded using trainable non-zero vectors. This approach allows information to be captured from the structure around the nodes through both edges and non-edges, thereby enhancing the representational capacity of the embedding network. For each node-pair \(e=(u,v)\in G\) (and equivalently \((v,u)\)), and \(e^{\prime}=(u^{\prime},v^{\prime})\in G^{\prime}\), the embeddings of the corresponding nodes and their connectivity status are concatenated, and then passed through an MLP to obtain the embedding vectors \(\bm{r}(e),\bm{r^{\prime}}(e^{\prime})\in\mathbb{R}^{D}\). For \(e=(u,v)\in G\), we compute \(\bm{r}(e)\) as:

\[\bm{r}(e)=\text{MLP}_{\theta}(\bm{x}_{K}(u)\,||\,\bm{x}_{K}(v)\,||\,\bm{A}[u, v])+\text{MLP}_{\theta}(\bm{x}_{K}(v)\,||\,\bm{x}_{K}(u)\,||\,\bm{A}[v,u]).\] (15)

We can compute \(\bm{r^{\prime}}(e)\) in similar manner. The property \(\bm{r}((u,v))=\bm{r}((v,u))\) reflects the undirected property of graph. Finally, the vectors \(\bm{r}(e)\) and \(\bm{r^{\prime}}(e^{\prime})\) are stacked into matrices \(\bm{R}\) and \(\bm{R^{\prime}}\), both with dimensions \(\mathbb{R}^{\binom{N}{2}\times D}\). We would like to highlight that \(\bm{r}((u,v))\) or \(\bm{r^{\prime}}((u^{\prime},v^{\prime}))\) are computed only once for all node-pairs, after the MPNN completes its final \(K\)th layer of execution. The message passing in the MPNN occurs only over edges. Therefore, this approach does not significantly increase the time complexity.

**Neural architecture of PermNet\({}_{\phi}\)** The network PermNet\({}_{\phi}\) provides \(\bm{P}\) as a soft node alignment matrix by taking the node embeddings as input, _i.e._, \(\bm{P}=\text{PermNet}_{\phi}(\bm{X},\bm{X^{\prime}})\). PermNet\({}_{\phi}\) is implemented in two steps. In the first step, we apply a neural network \(c_{\phi}\) on both \(\bm{x}_{K}\) and \(\bm{x}^{\prime}_{K}\), and then compute the normed difference between their outputs to construct the matrix \(\bm{C}\), where \(\bm{C}[u,u^{\prime}]=\left\|c_{\phi}\left(\bm{x}_{K}(u)\right)-c_{\phi}\left( \bm{x}^{\prime}_{K}(u^{\prime})\right)\right\|_{1}\). Next, we apply iterative Sinkhorn normalizations [16,35] on \(\exp(-\bm{C}/\tau)\), to obtain a soft node alignment \(\bm{P}\). Therefore,

\[\bm{P}=\operatorname{Sinkhorn}\left(\left[\exp\left(-\left\|c_{\phi}\left(\bm{x}_ {K}(u)\right)-c_{\phi}\left(\bm{x}_{K}^{\prime}(u^{\prime})\right)\right\|_{1} /\tau\right)\right]_{(u,u^{\prime})\in[N]\times[N]}\right).\] (16)

Here, \(\tau\) is a temperature hyperparameter. In a general cost setting, \(\operatorname{GED}\) is typically asymmetric, so it may be desirable for \(\bm{C}[u,u^{\prime}]\) to be asymmetric with respect to \(\bm{x}\) and \(\bm{x}^{\prime}\). However, as noted in Proposition 1, when we compute \(\operatorname{GED}(G^{\prime},G)\), the alignment matrix \(\bm{P}^{\prime}=\textsc{PermNet}_{\phi}(\bm{X}^{\prime},\bm{X})\) should satisfy the condition that \(\bm{P}^{\prime}=\bm{P}^{\top}\), where \(\bm{P}\) is computed from Eq. (16). The current form of \(\bm{C}\) supports this condition, whereas an asymmetric form might not, as shown in Appendix B.

We construct \(\bm{S}\in\mathbb{R}^{\binom{N}{2}}\times\mathbb{R}^{\binom{N}{2}}\) as follows. Each pair of nodes \((u,v)\) in \(G\) and \((u^{\prime},v^{\prime})\) in \(G^{\prime}\) can be mapped in two ways, regardless of whether they are edges or non-edges: (1) node \(u\mapsto u^{\prime}\) and \(v\mapsto v^{\prime}\) which is denoted by \(\bm{P}[u,u^{\prime}]\bm{P}[v,v^{\prime}]\); (2) node \(u\mapsto v^{\prime}\) and \(v\mapsto u^{\prime}\), which is denoted by \(\bm{P}[u,v^{\prime}]\bm{P}[v,u^{\prime}]\) Combining these two scenarios, we compute the node-pair alignment matrix \(\bm{S}\) as: \(\bm{S}[(u,v),(u^{\prime},v^{\prime})]=\bm{P}[u,u^{\prime}]\bm{P}[v,v^{\prime}] +\bm{P}[u,v^{\prime}]\bm{P}[v,u^{\prime}]\). This explicit formulation of \(\bm{S}\) from \(\bm{P}\) ensures mutually consistent permutation across nodes and node-pairs.

## 5 Experiments

We conduct extensive experiments on GraphEdX to showcase the effectiveness of our method across several real-world datasets, under both uniform and non-uniform cost settings for GED. Addiitional experimental results can be found in Appendix D.

### Setup

**Datasets** We experiment with seven real-world datasets: Mutagenicity (Mutag) [18], Ogbg-Code2 (Code2) [23], Ogbg-Molhiv (Molhiv) [23], Ogbg-Molpcba (Molpcba) [23], AIDS [36], Linux [5] and Yeast [36]. For each dataset's training, test and validation sets \(\mathcal{D}_{\text{split}}\), we generate \(\binom{[\mathcal{D}_{\text{split}}]}{2}+|\mathcal{D}_{\text{split}}|\) graph pairs, considering combinations between every two graphs, including self-pairing. We calculate the exact ground truth GED using the F2 solver [29], implemented within GEDLIB [10]. For GED with uniform cost setting, we set the cost values to \(b^{\ominus}=b^{\oplus}=a^{\ominus}=a^{\oplus}=1\). For GED with non-uniform cost setting, we use \(b^{\ominus}=3,b^{\oplus}=1,a^{\ominus}=2,a^{\oplus}=1\). Further details on dataset generation and statistics are presented in Appendix C. In the main paper, we present results for the first five datasets under both uniform and non-uniform cost settings for GED. Additional experiments for Linux and Yeast, as well as GED with node label substitutions, are presented in Appendix D.

**Baselines** We compare our approach with nine state-of-the-art methods. These include two variants of GMN [31]: (1) GMN-Match and (2) GMN-Embed; (3) ISONET [44], (4) GREED [40], (5) ERIC [56], (6) SimGNN [5], (7) H2MN [54], (8) GraphSim [6] and (9) EGSC [39]. To compute the GED, GMN-Match, GMN-Embed, and GREED use the Euclidean distance between the vector representation of two graphs. ISONET uses an asymmetric distance specifically tailored to subgraph isomorphism. H2MN is an early interaction network that utilizes higher-order node similarity through hypergraphs. ERIC, SimGNN, and EGSC leverage neural networks to calculate the distance between two graphs. Furthermore, the last three methods predict a score based on the normalized GED in the form of \(\exp\left(-2\operatorname{GED}(G,G^{\prime})/(|V|+|V^{\prime}|)\right)\). Notably, none of these baseline approaches have been designed to incorporate non-uniform edit costs into their models. To address this limitation, when working with GED under non-uniform cost setting, we include the edit costs as initial features in the graphs for all baseline models. In Appendix D.3, we compare the performance of baselines without cost features.

**Evaluation** Given a dataset \(\mathcal{D}=\left\{(G_{i},G_{i}^{\prime},\operatorname{GED}(G_{i},G_{i}^{ \prime}))\right\}_{i\in[n]}\), we divide it into training, validation and test folds with a split ratio of 60:20:20. We train the models using the Mean Squared Error (MSE) between the predicted GED and the ground truth GED as the loss. For model evaluation, we calculate the Mean Squared Error (MSE) between the actual and predicted GED on the test set. For ERIC, SimGNN and EGSC, we rescale the predicted score to obtain the true (unscaled) GED as \(\operatorname{GED}(G,G^{\prime})=-(|V|+|V|^{\prime})\log(s)/2\). In Appendix D, we also report Kendall's Tau (KTau) to evaluate the rank correlation across different experiments.

### Results

**Selection of \(\Delta^{\bullet}(\bm{X},\bm{X}^{\prime}\,|\,\bm{P})\) and \(\Delta^{\bullet}(\bm{R},\bm{R}^{\prime}\,|\,\bm{S})\)** We start by comparing the performance of the nine different combinations (three for edge edits, and three for node edits) of our neural distance sur rogates from the cartesian space of Edge-{AlignDiff, DiffAlign, XOR-DiffAlign} \(\times\) Node-{AlignDiff, DiffAlign, XOR-DiffAlign}. Table 2 summarizes the results. We make the following observations. (1) The best combinations share the XOR-DiffAlign on the edge edit formulation, because, XOR-DiffAlign offers more inductive bias, by zeroing the edit cost of aligning an edge to edge and a non-edge to non-edge, as we discussed in Section 4.2. Consequently, one can limit the cartesian space to only three surrogates for node edits, while using XOR-DiffAlign as the fixed surrogate for edge edits. (2) There is no clear winner between DiffAlign and AlignDiff. GraphEdX is chosen from the model which has the lowest validation error, and the numbers in Table 2 are on the test set. Hence, in datasets such as AIDS under uniform cost, or Molhiv under non-uniform cost, the model chosen for GraphEdX doesn't have the best test performance.

Comparison with baselinesWe compare the performance of GraphEdX against all state-of-the-art baselines for GED with both uniform and non-uniform costs. Table 3 summarizes the results. We make the following observations. (1) GraphEdX outperforms all the baselines by a significant margin. For GED with uniform costs, this margin often goes as high as 15%. This advantage becomes even more pronounced for GED with non-uniform costs, where our method outperforms the baselines by a margin as high as 30%, as seen in Code2. (2) There is no clear second-best method. Among the baselines, EGSC and ERIC outperforms the others in two out of five datasets for both uniform and non-uniform cost settings. Also, EGSC demonstrates competitive performance in AIDS.

Impact of cost-guided GEDAmong the baselines, GMN-Match, GMN-Embed and GREED compute GED using the euclidean distance between the graph embeddings, _i.e._, \(\mathrm{GED}(G,G^{\prime})=\|\bm{x}_{G}-\bm{x}_{G^{\prime}}\|_{2}\), whereas we compute it by summing the set distance surrogates between the node and edge embedding sets. To understand the impact of our cost guided distance, we adapt it to the graph-level embeddings used by the above three baselines as follows: \(\mathrm{GED}(G,G^{\prime})=\frac{b^{\ominus}+a^{\ominus}}{2}\left\|\mathrm{ReLU }\left(\bm{x}_{G}-\bm{x}_{G^{\prime}}\right)\right\|_{1}+\frac{b^{\ominus}+a^ {\ominus}}{2}\left\|\mathrm{ReLU}\left(\bm{x}_{G^{\prime}}-\bm{x}_{G}\right) \right\|_{1}\). Table 4 summarizes the results in

\begin{table}
\begin{tabular}{l l|c c c c c|c c c c} \hline \multirow{2}{*}{Edge edit} & \multirow{2}{*}{Node edit} & \multicolumn{4}{c|}{GED with uniform cost} & \multicolumn{4}{c}{GED with non-uniform cost} \\ \cline{3-11}  & & Mitag & Code2 & Molhiv & Molpecha & AIDS & Mitag & Code2 & Molhiv & Molpecha & AIDS \\ \hline DiffAlign & DiffAlign & 0.579 & 0.740 & 0.820 & 0.778 & 0.603 & 1.205 & 2.451 & 1.855 & 1.825 & 1.417 \\ DiffAlign & AlignDiff & 0.557 & 0.742 & 0.806 & 0.779 & 0.597 & 1.211 & 1.166 & 1.887 & 1.811 & 1.319 \\ DiffAlign & XOR & 0.538 & 0.719 & 0.794 & 0.777 & 0.580 & 1.146 & 1.896 & 1.802 & 1.822 & 1.381 \\ AlignDiff & Diffusion & 0.537 & 0.513 & 0.815 & 0.773 & 0.606 & 1.155 & 1.689 & 1.874 & 1.758 & 1.391 \\ AllGDiff & AlignDiff & 0.578 & 0.929 & 0.833 & 0.773 & 0.593 & 1.338 & 1.488 & 1.903 & 1.859 & 1.326 \\ AlignDiff & XOR & 0.533 & 0.826 & 0.812 & 0.780 & 0.575 & 1.196 & 1.741 & 1.870 & 1.815 & 1.374 \\ XOR & AlignDiff & **0.492** & **0.429** & 0.788 & 0.766 & 0.555 & 1.134 & **1.478** & 1.872 & 1.742 & **1.252** \\ XOR & DiffAlign & 0.510 & 0.634 & **0.781** & 0.765 & 0.574 & 1.148 & 1.489 & 1.804 & 1.757 & 1.340 \\ XOR & XOR & 0.530 & 1.588 & 0.807 & 0.764 & **0.564** & 1.195 & 2.507 & 1.855 & 1.677 & 1.319 \\ \hline \multicolumn{1}{c}{GrapEdX} & 0.492 & 0.429 & 0.781 & 0.764 & 0.565 & 1.134 & 1.478 & 1.804 & 1.677 & 1.252 \\ \hline \end{tabular}
\end{table}
Table 2: Prediction error measured in terms of MSE of the nine combinations of our neural set distance surrogate across five datasets on test set, for GED with uniform costs and non-uniform costs. For GED with uniform (non-uniform) costs we have \(b^{\ominus}=b^{\ominus}=a^{\ominus}=a^{\oplus}=1\) (\(b^{\ominus}=3,b^{\oplus}=1,a^{\ominus}=2,a^{\oplus}=1\).) The GraphEdX model was selected based on the lowest MSE on the validation set, and we report the results of the MSE on the test set. Green ( yellow) numbers report the best (second best) performers.

\begin{table}
\begin{tabular}{l|c c c c|c c c c c c} \hline  & \multicolumn{4}{c|}{GED with uniform cost} & \multicolumn{4}{c}{GED with non-uniform cost} \\ \cline{2-13}  & Mutag & Code2 & Molhiv & Molpecha & AIDS & Mutag & Code2 & Molhiv & Molpecha & AIDS \\ \hline GMN-Match [31] & 0.797 & 1.677 & 1.318 & 1.073 & 0.821 & 69.210 & 13.472 & 76.923 & 23.985 & 31.522 \\ GMN-Embed [31] & 1.032 & 1.358 & 1.859 & 1.951 & 1.044 & 72.945 & 13.425 & 78.254 & 28.437 & 33.221 \\ ISONNET [44] & 1.187 & 0.879 & 1.354 & 1.106 & 1.640 & 3.369 & 3.025 & 3.451 & 2.781 & 5.513 \\ GREED [40] & 1.398 & 1.869 & 1.708 & 1.550 & 1.004 & 68.732 & 11.095 & 78.300 & 26.057 & 34.354 \\ ERIC [56] & 0.719 & 1.363 & 1.165 & 0.862 & 0.731 & 1.981 & 1.267 & 3.377 & 2.057 & 1.581 \\ SimMN [5] & 1.471 & 2.667 & 1.609 & 1.456 & 1.455 & 4.474 & 5.212 & 4.145 & 3.465 & 4.316 \\ H2MN [54] & 1.278 & 7.240 & 1.521 & 1.402 & 1.114 & 3.413 & 9.435 & 3.782 & 3.396 & 3.105 \\ GraphSim [6] & 2.005 & 3.139 & 2.577 & 1.656 & 1.936 & 5.730 & 7.405 & 6.643 & 3.928 & 5.266 \\ EGSC [39] & 0.765 & 4.165 & 1.138 & 0.938 & 0.627 & 1.758 & 3.957 & 2.371 & 2.133 & 1.693 \\ \hline GraphEdX & 0.492 & 0.429 & 0.781 & 0.764 & 0.565 & 1.134 & 1.478 & 1.804 & 1.677 & 1.252 \\ \hline \end{tabular}
\end{table}
Table 3: Prediction error measured in terms of MSE of GraphEdX and all the state-of-the-art baselines across five datasets on test set, for GED with uniform costs and non-uniform costs. For GED with uniform (non-uniform) costs we have \(b^{\ominus}=b^{\oplus}=a^{\ominus}=a^{\oplus}=1\) (\(b^{\ominus}=3,b^{\oplus}=1,a^{\ominus}=2,a^{\oplus}=1\).) GraphEdX represents the best model based on the validation set from the cartesian space of Edge-{AlignDiff, DiffAlign, XOR-DiffAlign} \(\times\) Node-{AlignDiff, DiffAlign}. Green ( yellow) numbers report the best (second best) performers.

terms of MSE, which shows that (1) our set-divergence-based cost guided distance reduces the MSE by a significant margin in most cases (2) the margin of improvement is more prominent with GED involving non-uniform costs, where the modeling of specific cost values is crucial (3) GraphEdX outperforms the baselines even after changing their default distance to our cost guided distance.

Performance for GED under node substitution costThe scoring function in Eq. 8 can also be extended to incorporate node label substitution cost, which has been described in Appendix B. Here, we compare the performance of our model with the baselines in terms of MSE where we include node substitution cost \(b^{\sim}\), with cost setting as \(b^{\ominus}=b^{\oplus}=b^{\sim}=a^{\ominus}=a^{\oplus}=1\). In Table 5, we report the results across 5 datasets equipped with node labels, passed as one-hot encoded node features. We observe that (1) our model outperforms all other baselines across all datasets by significant margin; (2) there is no clear second winner but ERIC, EGSC and ISONET performs better than the others.

Benefits of using all node-pairs representation(i) Edge-only (\(\mathrm{edge}\rightarrow\mathrm{edge}\)): where we only consider the edges that are present, resulting in \(\bm{S}\) being an edge-alignment matrix, and \(\bm{R},\bm{R^{\prime}}\in\mathbb{R}^{\max(|E|,|E^{\prime}|)\times D}\) (ii) Edge-only (\(\mathrm{pair}\rightarrow\mathrm{pair}\)): In this variant, the embeddings of the non-edges in \(\bm{R},\bm{R^{\prime}}\in\mathbb{R}^{N(N-1)/2\times D}\) are explicitly set to zero. in terms of MSE, which show that (1) both these sparse representations perform significantly worse compared to our method using non-trivial representations for both edges and non-edges, and (2) Edge-only (\(\mathrm{edge}\rightarrow\mathrm{edge}\)) performs better than Edge-only (\(\mathrm{pair}\rightarrow\mathrm{pair}\)). This underscores the importance of explicitly modeling trainable non-edge embeddings to capture the sensitivity of GED to global graph structure.

## 6 Conclusion

Our work introduces a novel neural model for computing GED that explicitly incorporates general costs of edit operations. By leveraging graph representations that recognize both edges and non-edges, together with the design of suitable set distance surrogates, we achieve a more robust neural surrogate for GED. Our experiments demonstrate that this approach outperforms state-of-the-art methods, especially in settings with general edit costs, providing a flexible and effective solution for a range of applications. Future work could focus on extending the GED formulation to richly-attributed graphs by modeling the structure of edit operations and the similarity of all node-pair features.

LimitationsOur neural model for GED showcases significant improvements in accuracy and flexibility for modeling edit costs. However, there are some limitations to consider. (1) While computing graph representations over \(\binom{N}{2}\times\binom{N}{2}\) node-pairs does not require additional parameters due to parameter-sharing, it does demand significant memory resources. This could pose challenges, especially with larger-sized graphs. (2) The assumption of fixed edit costs across all graph pairs within a dataset might not reflect real-world scenarios where costs vary based on domain-specific factors and subjective human relevance judgements. This calls for more specialized approaches to accurately model the impact of each edit operation, which may differ across node pairs.

AcknowledgementsIndradyumna acknowledges Qualcomm Innovation Fellowship, Abir and Soumen acknowledge grants from Amazon, Google, IBM and SERB.

\begin{table}
\begin{tabular}{l|c c c} \hline  & Mutag & Code2 & Molhiv \\ \hline Edge-only (\(\mathrm{edge}\rightarrow\mathrm{edge}\)) & 0.566 & 0.683 & 0.858 \\ Edge-only (\(\mathrm{pair}\rightarrow\mathrm{pair}\)) & 0.596 & 0.760 & 0.862 \\ \hline GraphEdX & **0.492** & **0.429** & 0.781 \\ \hline \end{tabular}
\end{table}
Table 6: Comparison of variants of edge representation under uniform cost setting. \(\mathsf{Green}\) (yellow) numbers report the best (second best) performers.

\begin{table}
\begin{tabular}{l|c c c|c c c} \hline  & \multicolumn{4}{c|}{Uniform cost} & \multicolumn{4}{c}{Non-uniform cost} \\ \hline  & Mutag & Code2 & Molhiv & Mutag & Code2 & Molhiv \\ \hline GMN-Match & 0.797 & 1.677 & 1.318 & 6920 & 13.472 & 76.923 \\ GMN-Match & **0.654** & **0.960** & **1.008** & **1.592** & **2.906** & **2.162** \\ \hline GMN-Embed & 1.032 & 1.358 & 1.592 & 2495 & 13.425 & 78.254 \\ GMN-Embed * & **1.011** & **1.179** & **1.409** & **2.368** & **3.272** & **3.413** \\ \hline GREED * & **1.398** & 1.690 & 1.708 & 68.732 & 11.095 & 78.300 \\ GREED * & 2.133 & **8.50** & **1.644** & **2.456** & **5.429** & **3.827** \\ \hline \(\mathsf{Gre}\mathsf{Ar}\mathsf{Pb}\mathsf{EdX}\) & **0.492** & 0.429 & 0.781 & 1.134 & 1.478 & 1.804 \\ \hline \end{tabular}
\end{table}
Table 4: Impact of cost guided distance in terms of MSE; * represents the variant of the baseline with cost-guided distance. \(\mathsf{Green}\) (**bold**) shows the best among all methods (only baselines).

\begin{table}
\begin{tabular}{l|c c c c} \hline  & Mutag & Code2 & Molhiv & Molge2 & AIDS \\ \hline GMN-Match & 1.057 & 5.224 & 1.388 & 1.432 & 0.868 \\ GMN-Embed & 2.159 & 4.070 & 3.523 & 4.657 & 1.818 \\ ISONET & 0.876 & 1.129 & 1.617 & 1.332 & 1.142 \\ GREED & 2.876 & 4.983 & 2.923 & 3.902 & 2.175 \\ ERIC & 0.886 & 6.323 & 1.537 & 1.278 & 1.602 \\ SimGNN & 1.160 & 5.909 & 1.888 & 2.172 & 1.418 \\ H2MN & 1.277 & 6.783 & 1.891 & 1.666 & 1.290 \\ GraphSim & 1.043 & 4.708 & 1.817 & 1.748 & 1.561 \\ EGSC & 0.776 & 8.742 & 1.723 & 1.426 & 1.270 \\ \hline GraphEdX & 0.441 & 0.820 & 0.792 & 0.846 & 0.538 \\ \hline \end{tabular}
\end{table}
Table 5: MSE for different methods with unit node substitution cost in uniform cost setting. \(\mathsf{Green}\) (yellow) show (second) best method.

## References

* Adler and Lunz [2018] J. Adler and S. Lunz. Banach wasserstein gan. _Advances in neural information processing systems_, 31, 2018.
* Amos et al. [2017] B. Amos, L. Xu, and J. Z. Kolter. Input convex neural networks. In _International Conference on Machine Learning_, pages 146-155. PMLR, 2017.
* Arjovsky et al. [2017] M. Arjovsky, S. Chintala, and L. Bottou. Wasserstein generative adversarial networks. In _International conference on machine learning_, pages 214-223. PMLR, 2017.
* Backurs et al. [2020] A. Backurs, Y. Dong, P. Indyk, I. Razenshteyn, and T. Wagner. Scalable nearest neighbor search for optimal transport. In _International Conference on machine learning_, pages 497-506. PMLR, 2020.
* Bai et al. [2019] Y. Bai, H. Ding, S. Bian, T. Chen, Y. Sun, and W. Wang. Simgnn: A neural network approach to fast graph similarity computation. In _Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining_, pages 384-392, 2019.
* Bai et al. [2020] Y. Bai, H. Ding, K. Gu, Y. Sun, and W. Wang. Learning-based efficient graph similarity computation via multi-scale convolutional set matching. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 34, pages 3219-3226, 2020.
* Blumenthal [2019] D. B. Blumenthal. New techniques for graph edit distance computation. _arXiv preprint arXiv:1908.00265_, 2019.
* Blumenthal and Gamper [2018] D. B. Blumenthal and J. Gamper. Improved lower bounds for graph edit distance. _IEEE Transactions on Knowledge and Data Engineering_, 30:503-516, 2018. URL https://api.semanticscholar.org/CorpusID:3438059.
* Blumenthal et al. [2018] D. B. Blumenthal, E. Daller, S. Bougleux, L. Brun, and J. Gamper. Quasimetric graph edit distance as a compact quadratic assignment problem. In _2018 24th International Conference on Pattern Recognition (ICPR)_, pages 934-939, 2018. doi: 10.1109/ICPR.2018.8546055.
* Blumenthal et al. [2019] D. B. Blumenthal, S. Bougleux, J. Gamper, and L. Brun. Gedlib: A c++ library for graph edit distance computation. In D. Conte, J.-Y. Ramel, and P. Foggia, editors, _Graph-Based Representations in Pattern Recognition_, pages 14-24, Cham, 2019. Springer International Publishing. ISBN 978-3-030-20081-7.
* Bougleux et al. [2017] S. Bougleux, L. Brun, V. Carletti, P. Foggia, B. Gauzere, and M. Vento. Graph edit distance as a quadratic assignment problem. _Pattern Recognition Letters_, 87:38-46, 2017. ISSN 0167-8655. doi: https://doi.org/10.1016/j.patrec.2016.10.001. URL https://www.sciencedirect.com/science/article/pii/S0167865516302665. Advances in Graph-based Pattern Recognition.
* Broder et al. [1998] A. Z. Broder, M. Charikar, A. M. Frieze, and M. Mitzenmacher. Min-wise independent permutations. In _Proceedings of the thirtieth annual ACM symposium on Theory of computing_, pages 327-336, 1998.
* Bunke [1997] H. Bunke. On a relation between graph edit distance and maximum common subgraph. _Pattern Recognition Letters_, 18(8):689-694, 1997.
* Bunke and Allermann [1983] H. Bunke and G. Allermann. Inexact graph matching for structural pattern recognition. _Pattern Recognition Letters_, 1(4):245-253, 1983.
* Chang et al. [2017] L. Chang, X. Feng, X. Lin, L. Qin, and W. Zhang. Efficient graph edit distance computation and verification via anchor-aware lower bound estimation. _arXiv preprint arXiv:1709.06810_, 2017.
* Cuturi [2013] M. Cuturi. Sinkhorn distances: Lightspeed computation of optimal transport. _Advances in neural information processing systems_, 26:2292-2300, 2013.
* Daniels et al. [2021] M. Daniels, T. Maunu, and P. Hand. Score-based generative neural networks for large-scale optimal transport. _Advances in neural information processing systems_, 34:12955-12965, 2021.

* [18] A. K. Debnath, R. L. Lopez de Compadre, G. Debnath, A. J. Shusterman, and C. Hansch. Structure-activity relationship of mutagenic aromatic and heteroaromatic nitro compounds. correlation with molecular orbital energies and hydrophobicity. _Journal of Medicinal Chemistry_, 34(2):786-797, 1991. doi: 10.1021/jm00106a046. URL https://doi.org/10.1021/jm00106a046.
* [19] K. D. Doan, S. Manchanda, S. Mahapatra, and C. K. Reddy. Interpretable graph similarity computation via differentiable optimal alignment of node embeddings. In _Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval_, pages 665-674, 2021.
* [20] M. Douze, A. Guzhva, C. Deng, J. Johnson, G. Szilvasy, P.-E. Mazare, M. Lomeli, L. Hosseini, and H. Jegou. The faiss library. _arXiv preprint arXiv:2401.08281_, 2024.
* [21] C. Garcia-Hernandez, A. Fernandez, and F. Serratosa. Ligand-based virtual screening using graph edit distance as molecular similarity measure. _Journal of chemical information and modeling_, 59(4):1410-1421, 2019.
* [22] A. Genevay, M. Cuturi, G. Peyre, and F. Bach. Stochastic optimization for large-scale optimal transport. _Advances in neural information processing systems_, 29, 2016.
* [23] W. Hu, M. Fey, M. Zitnik, Y. Dong, H. Ren, B. Liu, M. Catasta, and J. Leskovec. Open graph benchmark: Datasets for machine learning on graphs. _Advances in neural information processing systems_, 33:22118-22133, 2020.
* [24] P. Indyk and R. Motwani. Approximate nearest neighbors: towards removing the curse of dimensionality. In _Proceedings of the thirtieth annual ACM symposium on Theory of computing_, pages 604-613, 1998.
* [25] P. Indyk, R. Motwani, P. Raghavan, and S. Vempala. Locality-preserving hashing in multidimensional spaces. In _Proceedings of the twenty-ninth annual ACM symposium on Theory of computing_, pages 618-625, 1997.
* [26] S. Ivanov, S. Sviridov, and E. Burnaev. Understanding isomorphism bias in graph data sets. arXiv 1910.12091, 2019. URL https://arxiv.org/abs/1910.12091.
* [27] D. Justice and A. Hero. A binary linear programming formulation of the graph edit distance. _IEEE Transactions on Pattern Analysis and Machine Intelligence_, 28(8):1200-1214, 2006.
* [28] M. G. Kendall. A new measure of rank correlation. _Biometrika_, 30(1/2):81-93, 1938.
* [29] J. Lerouge, Z. Abu-Aisheh, R. Raveaux, P. Heroux, and S. Adam. New binary linear programming formulation to compute the graph edit distance. _Pattern Recognition_, 72:254-265, 2017. ISSN 0031-3203. doi: https://doi.org/10.1016/j.patcog.2017.07.029. URL https://www.sciencedirect.com/science/article/pii/S003132031730300X.
* [30] Y. Li, D. Tarlow, M. Brockschmidt, and R. Zemel. Gated graph sequence neural networks. _arXiv preprint arXiv:1511.05493_, 2015.
* [31] Y. Li, C. Gu, T. Dullien, O. Vinyals, and P. Kohli. Graph matching networks for learning the similarity of graph structured objects. In _International conference on machine learning_, pages 3835-3845. PMLR, 2019.
* [32] C.-L. Lin. Hardness of approximating graph transformation problem. In D.-Z. Du and X.-S. Zhang, editors, _Algorithms and Computation_, pages 74-82, Berlin, Heidelberg, 1994. Springer Berlin Heidelberg. ISBN 978-3-540-48653-4.
* [33] Z. Lou, J. You, C. Wen, A. Canedo, J. Leskovec, et al. Neural subgraph matching. _arXiv preprint arXiv:2007.03092_, 2020.
* [34] Y. A. Malkov and D. A. Yashunin. Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs. _IEEE transactions on pattern analysis and machine intelligence_, 42(4):824-836, 2018.

* Mena et al. [2018] G. Mena, D. Belanger, S. Linderman, and J. Snoek. Learning latent permutations with gumbel-sinkhorn networks. _arXiv preprint arXiv:1802.08665_, 2018. URL https://arxiv.org/pdf/1802.08665.pdf.
* Morris et al. [2020] C. Morris, N. M. Kriege, F. Bause, K. Kersting, P. Mutzel, and M. Neumann. Tudataset: A collection of benchmark datasets for learning with graphs, 2020.
* Naidan et al. [2015] B. Naidan, L. Boytsov, Y. Malkov, and D. Novak. Non-metric space library manual. _arXiv preprint arXiv:1508.05470_, 2015.
* Ozdemir and Gunduz-Demir [2013] E. Ozdemir and C. Gunduz-Demir. A hybrid classification model for digital pathology using structural and statistical pattern recognition. _IEEE Transactions on Medical Imaging_, 32(2):474-483, 2013. doi: 10.1109/TMI.2012.2230186.
* Qin et al. [2021] C. Qin, H. Zhao, L. Wang, H. Wang, Y. Zhang, and Y. Fu. Slow learning and fast inference: Efficient graph similarity computation via knowledge distillation. In _Thirty-Fifth Conference on Neural Information Processing Systems_, 2021.
* Ranjan et al. [2022] R. Ranjan, S. Grover, S. Medya, V. Chakaravarthy, Y. Sabharwal, and S. Ranu. Greed: A neural framework for learning graph distance functions. _Advances in Neural Information Processing Systems_, 35:22518-22530, 2022.
* Riesen and Bunke [2009] K. Riesen and H. Bunke. Approximate graph edit distance computation by means of bipartite graph matching. _Image and Vision Computing_, 27(7):950-959, 2009. ISSN 0262-8856. doi: https://doi.org/10.1016/j.imavis.2008.04.004. URL https://www.sciencedirect.com/science/article/pii/S026288560800084X. 7th IAPR-TC15 Workshop on Graph-based Representations (GbR 2007).
* Riesen et al. [2014] K. Riesen, A. Fischer, and H. Bunke. Combining bipartite graph matching and beam search for graph edit distance approximation. In _Artificial Neural Networks in Pattern Recognition: 6th IAPR TC 3 International Workshop, ANNPR 2014, Montreal, QC, Canada, October 6-8, 2014. Proceedings 6_, pages 117-128. Springer, 2014.
* Roy et al. [2022] I. Roy, S. Chakrabarti, and A. De. Maximum common subgraph guided graph retrieval: late and early interaction networks. _Advances in Neural Information Processing Systems_, 35:32112-32126, 2022.
* Roy et al. [2022] I. Roy, V. S. Velugoti, S. Chakrabarti, and A. De. Interpretable Neural Subgraph Matching for Graph Retrieval. _AAAI_, 2022.
* Sahni and Gonzalez [1976] S. Sahni and T. Gonzalez. P-complete approximation problems. _J. ACM_, 23(3):555-565, jul 1976. ISSN 0004-5411. doi: 10.1145/321958.321975. URL https://doi.org/10.1145/321958.321975.
* Sanfeliu and Fu [1983] A. Sanfeliu and K.-S. Fu. A distance measure between attributed relational graphs for pattern recognition. _IEEE transactions on systems, man, and cybernetics_, pages 353-362, 1983.
* Sanfeliu et al. [2002] A. Sanfeliu, R. Alquezar, J. Andrade, J. Climent, F. Serratosa, and J. Verges. Graph-based representations and techniques for image processing and image analysis. _Pattern recognition_, 35(3):639-650, 2002.
* Seguy et al. [2017] V. Seguy, B. B. Damodaran, R. Flamary, N. Courty, A. Rolet, and M. Blondel. Large-scale optimal transport and mapping estimation. _arXiv preprint arXiv:1711.02283_, 2017.
* Shearer et al. [2001] K. Shearer, H. Bunke, and S. Venkatesh. Video indexing and similarity retrieval by largest common subgraph detection using decision trees. _Pattern Recognition_, 34(5):1075-1091, 2001.
* Sinkhorn and Knopp [1967] R. Sinkhorn and P. Knopp. Concerning nonnegative matrices and doubly stochastic matrices. _Pacific Journal of Mathematics_, 21(2):343-348, 1967.
* Tirthapura et al. [1998] S. Tirthapura, D. Sharvit, P. Klein, and B. B. Kimia. Indexing based on edit-distance matching of shape graphs. In _Multimedia storage and archiving systems III_, volume 3527, pages 25-36. SPIE, 1998.

* [52] Y. Xie, M. Chen, H. Jiang, T. Zhao, and H. Zha. On scalable and efficient computation of large scale optimal transport. In _International Conference on Machine Learning_, pages 6882-6892. PMLR, 2019.
* [53] Z. Zeng, A. K. Tung, J. Wang, J. Feng, and L. Zhou. Comparing stars: On approximating graph edit distance. _Proceedings of the VLDB Endowment_, 2(1):25-36, 2009.
* [54] Z. Zhang, J. Bu, M. Ester, Z. Li, C. Yao, Z. Yu, and C. Wang. H2mn: Graph similarity learning with hierarchical hypergraph matching networks. In _Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining_, KDD '21, page 2274-2284, New York, NY, USA, 2021. Association for Computing Machinery. ISBN 9781450383325. doi: 10.1145/3447548.3467328. URL https://doi.org/10.1145/3447548.3467328.
* [55] W. Zheng, L. Zou, X. Lian, D. Wang, and D. Zhao. Efficient graph similarity search over large graph databases. _IEEE Transactions on Knowledge and Data Engineering_, 27(4):964-978, 2014.
* [56] W. Zhuo and G. Tan. Efficient graph similarity computation with alignment regularization. _Advances in Neural Information Processing Systems_, 35:30181-30193, 2022.

**Graph Edit Distance with General Costs**

**Using Neural Set Divergence**

**(Appendix)**

###### Contents

* A Broader impact
* B Discussion on our proposed formulation of GED
* B.1 Modification of scoring function from label substitution
* B.2 Proof of Proposition 1
* B.3 Connections with other notions of graph matching
* B.4 Relation between AlignDiff and DiffAlign
* B.5 Proof that our design ensures conditions of Proposition 1
* B.6 Alternative surrogate for GED
* C Details about experimental setup
* C.1 Generation of datasets
* C.2 Details about state-of-the-art baselines
* C.3 Details about GraphEdX
* C.4 Evaluation metrics
* C.5 Hardware and license
* D Additional experiments
* D.1 Comparison of performance of GraphEdX on non-uniform cost Edge-GED
* D.2 Comparison of GraphEdX with baselines on uniform and non-uniform cost setting
* D.3 Comparison of GraphEdX with baselines with and without cost features
* D.4 Comparison of GraphEdX with baselines with node substitution cost
* D.5 Performance evaluation for edge-only vs. all-node-pair representations
* D.6 Effect of using cost-guided scoring function on baselines
* D.7 Results on performance of the alternate surrogates for GED
* D.8 Comparison of zero-shot performance on other datasets
* D.9 Importance of node-edge consistency
* D.10 Comparison of nine possible combinations our proposed set distances
* D.11 Comparison of performance of our model with baselines using scatter plot
* D.12 Comparison of performance of our model with baselines using error distribution
* D.13 Comparison of combinatorial optimisation gadgets for GED prediction
* D.14 Prediction timing analysis
* D.15 Visualization (optimal edit path) + Pseudocode
Broader impact

Graphs serve as powerful representations across diverse domains, capturing complex relationships and structural notions inherent in various systems. From biological networks to social networks, transportation networks, and supply chains, graphs provide a versatile framework for modeling interactions between interconnected entities. In domains where structure-similarity based applications are prevalent, GED emerges as a valuable and versatile tool.

For example, in bio-informatics, molecular structures can naturally be represented as graphs. GED computation expedites tasks such as drug discovery, protein-protein interaction modeling, and molecular similarity analysis by identifying structurally similar molecular compounds. Similarly, in social network analysis, GED can measure similarities between user interactions, aiding in friend recommendation systems or community detection tasks. In transportation networks, GED-based tools assess similarity between road networks for route planning or traffic optimizations. Further applications include learning to edit scene graphs, analyzing gene regulatory pathways, fraud detection, and more

Moreover, our proposed variations of GED, particularly those amenable to hashing, find utility in retrieval based setups. In various information retrieval systems, hashed graph representations can be used to efficiently index and retrieve relevant items using our GED based scores. Such applications include image retrieval from image databases where images are represented as scene graphs, retrieval of relevant molecules from molecular databases, _etc_.

Furthermore, our ability to effectively model different edit costs in GED opens up new possibilities in various applications. In recommendation systems, it can model user preferences of varying importance, tailoring recommendations based on user-specific requirements or constraints. Similarly, in image or video processing, different types of distortions may have varying impacts on perceptual quality, and GED with adaptive costs can better assess similarity. In NLP tasks such as text similarity understanding and document clustering, assigning variable costs to textual edits corresponding to word insertion, deletions or substitutions, provides a more powerful framework for measuring textual similarity, improving performance in downstream tasks such as plagiarism detection, summarization, _etc_.

Lastly, and most importantly, the design of our model encourages interpretable alignment-driven justifications, thereby promoting transparency and reliability while minimizing potential risks and negative impacts, in high stake applications like drug discovery.

Discussion on our proposed formulation of GED

### Modification of scoring function from label substitution

To incorporate the effect of node substitution into account when formulating the GED, we first observe that the effect of node substitution cost \(b^{\sim}\) only comes into account when a non-padded node maps to a non-padded node. In all other cases, when a node is deleted or inserted, we do not additionally incur any substitution costs. Note that, we consider the case when node substitution cannot be replaced by node addition and deletion, _i.e._, \(b^{\sim}\leq b^{\ominus}+b^{\oplus}\). Such a constraint on costs has uses in multiple applications [9; 38]. Let \(\mathcal{L}\) denote the set of node labels, and \(\ell(u)\), \(\ell^{\prime}(u^{\prime})\in\mathcal{L}\) denote the node label corresponding to nodes \(u\) and \(u^{\prime}\) in \(G\) and \(G^{\prime}\) respectively. We construct the node label matrix \(\bm{L}\) for \(G\) as follows: \(\bm{L}\in\{0,1\}^{N\times|\mathcal{L}|}\), such that \(\bm{L}[i,:]=\texttt{one\_hot}(\ell(i))\), _i.e._, \(\bm{L}\) is the one-hot indicator matrix for the node labels, which each row corresponding to the one-hot vector of the label. Similarly, we can construct \(\bm{L}^{\prime}\) for \(G^{\prime}\). Then, the distance between labels of two nodes \(u\in V\) and \(u^{\prime}\in V^{\prime}\) can be given as \(\left\lVert\bm{L}[u,:]-\bm{L}^{\prime}[u^{\prime},:]\right\rVert_{1}\). To ensure that only valid node to node mappings contribute to the cost, we multiply the above with \(\Lambda(u,u^{\prime})=\text{AND}(\bm{\eta}_{G}[u],\bm{\eta}_{G^{\prime}}[u^{ \prime}])\). This allows us to write the expression for GED with node label substitution cost as

\[\mathrm{GED}(G,G^{\prime})=\min_{\bm{P}\in\mathbb{F}_{N}}\ \frac{a^{\ominus}}{2} \left\lVert\mathrm{ReLU}\left(\bm{A}-\bm{PA^{\prime}P}^{\top} \right)\right\rVert_{1,1}+\frac{a^{\oplus}}{2}\left\lVert\mathrm{ReLU}\left( \bm{PA^{\prime}P}^{\top}-\bm{A}\right)\right\rVert_{1,1}\] \[+b^{\ominus}\left\lVert\mathrm{ReLU}\left(\bm{\eta}_{G}-\bm{P} \bm{\eta}_{G^{\prime}}\right)\right\rVert_{1}+b^{\oplus}\left\lVert\mathrm{ ReLU}\left(\bm{P}\bm{\eta}_{G^{\prime}}-\bm{\eta}_{G}\right)\right\rVert_{1}\] \[+b^{\sim}\underbrace{\sum_{u,u^{\prime}}\Lambda(u,u^{\prime}) \left\lVert\bm{L}[u,:]-\bm{L}[u^{\prime},:]\right\rVert_{1}\bm{P}[u,u^{\prime }]}_{\Delta^{\sim}(\bm{L},\bm{L}^{\prime}|\bm{P})}\]

We can design a neural surrogate for above in the same way as done in Section 4.2, and write

\[\mathrm{GED}_{\theta,\phi}(G,G^{\prime})=a^{\ominus}\Delta^{ \oslash}(\bm{R},\bm{R}^{\prime}\,|\,\bm{S})+a^{\oplus}\Delta^{\oplus}(\bm{R}, \bm{R}^{\prime}\,|\,\bm{S})\] \[\qquad\qquad\qquad\qquad\qquad\qquad\qquad+b^{\ominus}\Delta^{ \ominus}(\bm{X},\bm{X}^{\prime}\,|\,\bm{P})+b^{\oplus}\Delta^{\oplus}(\bm{X}, \bm{X}^{\prime}\,|\,\bm{P})\] \[\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad+b^{\sim} \Delta^{\sim}(\bm{L},\bm{L}^{\prime}|\bm{P})\] (17)

In this case, to account for node substitutions in the proposed permutation, we use \(\bm{L}[u,:]\) and \(\bm{L}^{\prime}[u^{\prime},:]\) as the features for node \(u\) in \(G\) and node \(u^{\prime}\) in \(G^{\prime}\), respectively. We present the comparison of our method including substitution cost with state-of-the-art baselines in Appendix D.

### Proof of Proposition 1

PropositionGiven a fixed set of values of \(b^{\ominus},b^{\oplus},a^{\ominus},a^{\oplus}\), let \(\bm{P}\) be an optimal node permutation matrix corresponding to \(\mathrm{GED}(G,G^{\prime})\), computed using Eq. (7). Then, \(\bm{P}^{\prime}=\bm{P}^{\top}\) is an optimal node permutation corresponding to \(\mathrm{GED}(G^{\prime},G)\).

_Proof:_ Noticing that \(\mathrm{ReLU}\left(c-d\right)=\max(c,d)-d\), we can write

\[\left\lVert\mathrm{ReLU}\left(\bm{A}-\bm{PA^{\prime}P}^{\top} \right)\right\rVert_{1,1}=\left\lVert\max(\bm{A},\bm{PA^{\prime}P}^{\top})-\bm {PA^{\prime}P}^{\top}\right\rVert_{1,1}\] \[=\left\lVert\max(\bm{A},\bm{PA^{\prime}P}^{\top})\right\rVert_{1,1 }-2|E^{\prime}|\]

The last equality follows since \(\max(\bm{A},\bm{PA^{\prime}P}^{\top})\geq\bm{PA^{\prime}P}^{\top}\) element-wise, and \(\left\lVert\bm{PA^{\prime}P}^{\top}\right\rVert_{1,1}=\left\lVert\bm{A^{\prime }}\right\rVert_{1,1}=2|E^{\prime}|\). Similarly, we can rewrite \(\left\lVert\mathrm{ReLU}\left(\bm{PA^{\prime}P}^{\top}-\bm{A}\right)\right\rVert _{1,1}\), \(\left\lVert\mathrm{ReLU}\left(\bm{\eta}_{G}-\bm{P}\bm{\eta}_{G^{\prime}}\right) \right\rVert_{1}\), and \(\left\lVert\mathrm{ReLU}\left(\bm{P}\bm{\eta}_{G^{\prime}}-\bm{\eta}_{G} \right)\right\rVert_{1}\), and finally rewrite Eq. (7) as

\[\mathrm{GED}(G,G^{\prime})=\min_{\bm{P}\in\mathbb{P}_{N}}\frac{a^{ \oplus}+a^{\ominus}}{2} \left\lVert\max(\bm{A},\bm{PA^{\prime}P}^{\top})\right\rVert_{1,1}-a^{ \ominus}|E^{\prime}|-a^{\oplus}|E|\] (18) \[+\frac{b^{\oplus}+b^{\ominus}}{2}\left\lVert\max(\bm{\eta}_{G}, \bm{P}\bm{\eta}_{G^{\prime}}\,)\right\rVert_{1}-b^{\ominus}|V^{\prime}|-b^{ \oplus}|V|\] \[\mathrm{GED}(G^{\prime},G)=\min_{\bm{P}\in\mathbb{P}_{N}}\frac{a^{ \oplus}+a^{\ominus}}{2} \left\lVert\max(\bm{A}^{\prime},\bm{PA}P^{\top})\right\rVert_{1,1}-a^{ \ominus}|E|-a^{\oplus}|E^{\prime}|\] (19) \[+\frac{b^{\ominus}+b^{\ominus}}{2}\left\lVert\max(\bm{\eta}_{G^{ \prime}},\bm{P}\bm{\eta}_{G}\,)\right\rVert_{1}-b^{\ominus}|V|-b^{\oplus}|V^{ \prime}|\]We can rewrite the max term as follows:

\[\left\|\max(\bm{A},\bm{PA^{\prime}P}^{\top})\right\|_{1,1} =\sum_{u,v}\max(\bm{A},\bm{PA^{\prime}P}^{\top})[u,v]\] \[=\sum_{u,v}\max(\bm{PP}^{\top}\bm{APP}^{\top},\bm{PA^{\prime}P}^{ \top})[u,v]\] \[=\sum_{u,v}\bm{P}\max(\bm{P}^{\top}\bm{AP},\bm{A^{\prime}})\bm{P}^ {\top}[u,v]\] \[=\sum_{u,v}\max(\bm{P}^{\top}\bm{AP},\bm{A^{\prime}})[u,v]\] \[=\left\|\max(\bm{P}^{\top}\bm{AP},\bm{A^{\prime}})\right\|_{1,1}= \left\|\max(\bm{A^{\prime}},\bm{P}^{\top}\bm{AP})\right\|_{1,1}\]

Similarly we can re write \(\left\|\max(\bm{\eta}_{G},\bm{P}\bm{\eta}_{G^{\prime}})\right\|_{1}\) as \(\left\|\max(\bm{\eta}_{G^{\prime}},\bm{P}^{\top}\bm{\eta}_{G})\right\|_{1}\). Given a fixed set of cost function \(b^{\ominus},b^{\oplus},a^{\ominus},a^{\oplus}\), the terms containing \(|E^{\prime}|,|E|,|V^{\prime}|,|V|\) are constant and do not affect choosing an optimal \(\bm{P}\). Let \(C=-a^{\ominus}|E^{\prime}|-a^{\oplus}|E|-b^{\ominus}|V|-b^{\oplus}|V^{\prime}|\), Using the above equations, we can write:

\[\frac{a^{\oplus}+a^{\ominus}}{2}\left\|\max(\bm{A},\bm{PA^{\prime }P}^{\top})\right\|_{1,1}+\frac{b^{\oplus}+b^{\ominus}}{2}\left\|\max(\bm{\eta} _{G},\bm{P}\bm{\eta}_{G^{\prime}}\,)\right\|_{1}\] \[=\frac{a^{\oplus}+a^{\ominus}}{2}\left\|\max(\bm{A^{\prime}},\bm{ P}^{\top}\bm{AP})\right\|_{1,1}+\frac{b^{\oplus}+b^{\ominus}}{2}\left\|\max( \bm{\eta}_{G^{\prime}},\bm{P}^{\top}\bm{\eta}_{G})\right\|_{1}\]

Let the first term be \(\rho(G,G^{\prime}\,|\,\bm{P})\). Then second term can be expressed as \(\rho(G^{\prime},G\,|\,\bm{P}^{\top})\) and \(\rho(G,G^{\prime}\,|\,\bm{P})=\rho(G^{\prime},G\,|\,\bm{P}^{\top})\) for all \(\bm{P}\in\mathbb{P}_{N}\). If \(\bm{P}\) is the optimal solution of \(\min_{\bm{P}\in\mathbb{P}_{N}}\rho(G,G^{\prime}\,|\,\bm{P})\) then, \(\rho(G^{\prime},G\,|\,\bm{P}^{\top})=\rho(G,G^{\prime}\,|\,\bm{P})\leq\rho(G,G ^{\prime}\,|\,\widetilde{\bm{P}}^{\top})=\rho(G^{\prime},G\,|\,\widetilde{\bm{ P}})\) for any permutation \(\widetilde{\bm{P}}\). Hence, \(\bm{P}^{\prime}=\bm{P}^{\top}\in\mathbb{P}_{N}\) is one optimal permutation for \(\mathrm{GED}(G^{\prime},G)\).

### Connections with other notions of graph matching

Graph isomorphism:When we set all costs to zero, we can write that \(\mathrm{GED}(G,G^{\prime})=\min_{\bm{P}}0.5\left\|\bm{A}-\bm{PA^{\prime}P}^{ \top}\right\|_{1,1}+\left\|\bm{\eta}_{G}-\bm{P}\bm{\eta}_{G^{\prime}}\right\|_ {1}\). In such a scenario, \(\mathrm{GED}(G,G^{\prime})\) is symmetric, _i.e._, \(\mathrm{GED}(G^{\prime},G)=\mathrm{GED}(G,G^{\prime})\) and it becomes zero only when \(G\) and \(G^{\prime}\) are isomorphic.

Subgraph isomorphism:Assume \(b^{\ominus}=b^{\oplus}=0\). Then, if we set the cost of edge addition to be arbitrarily small as compared to the cost of edge deletion, _i.e._, \(a^{\oplus}\ll a^{\ominus}\). This yields \(\mathrm{GED}(G,G^{\prime})=\min_{\bm{P}}(b^{\ominus}\sum_{u,v}\mathrm{ReLU} \left(\bm{A}-\bm{PA^{\prime}P}^{\top}\right)[u,v])\), which can be reduced to zero for some permutation \(\bm{P}\), \(G\subseteq G^{\prime}\).

Maximum common edge subgraph:From Appendix B.2, we can write that \(\mathrm{GED}(G,G^{\prime})=\min_{\bm{P}}0.5(a^{\oplus}+a^{\ominus})\left\| \max(\bm{A},\bm{PA^{\prime}P}^{\top})\right\|_{1,1}+0.5(b^{\oplus}+b^{\ominus}) \left\|\max\{\bm{\eta}_{G},\bm{P}\bm{\eta}_{G^{\prime}}\}\right\|_{1}-a^{ \ominus}|E^{\prime}|-a^{\oplus}|E|-b^{\ominus}|V^{\prime}|-b^{\oplus}|V|\). When \(a^{\ominus}=a^{\oplus}=1\) and \(b^{\oplus}=b^{\ominus}=0\), then \(\mathrm{GED}(G,G^{\prime})=\left\|\max(\bm{A},\bm{PA^{\prime}P}^{\top}) \right\|_{1,1}=|E|+|E^{\prime}|-\left\|\min(\bm{A},\bm{PA^{\prime}P}^{\top}) \right\|_{1,1}\). Here, \(\min(\bm{A},\bm{PA^{\prime}P}^{\top})\) characterizes maximum common edge subgraph and \(\left\|\min(\bm{A},\bm{PA^{\prime}P}^{\top})\right\|_{1,1}\) provides the number of edges of it.

### Relation between AlignDiff and Diffalign

**Lemma 2**: _Let \(\bm{Z},\bm{Z}^{\prime}\in\mathbb{R}^{N\times M}\), and \(\bm{S}\in\mathbb{R}_{\geq 0}^{N\times N}\) be double stochastic. Then,_

\[\left\|\mathrm{ReLU}\left(\bm{Z}-\bm{SZ}^{\prime}\right)\right\|_{1,1}\leq\sum_ {i,j}\left\|\mathrm{ReLU}\left(\bm{Z}[i,:]-\bm{Z}^{\prime}[j,:]\right)\right\|_ {1}\bm{S}[i,j]\]Proof.: We can write,

\[\left\|\mathrm{ReLU}\left(\bm{Z}-\bm{SZ^{\prime}}\right)\right\|_{1,1} =\sum_{i,j}\left|\mathrm{ReLU}\left(\bm{Z}[i,j]-\sum\nolimits_{k} \bm{S}[i,k]\bm{Z^{\prime}}[k,j]\right)\right|\] \[\overset{(*)}{=}\sum_{i,j}\mathrm{ReLU}\left(\sum\nolimits_{k} \bm{S}[i,k]\bm{Z}[i,j]-\bm{S}[i,k]\bm{Z^{\prime}}[k,j]\right)\] \[\overset{(**)}{\leq}\sum_{i,j}\sum_{k}\bm{S}[i,k]\mathrm{ReLU} \left(\bm{Z}[i,j]-\bm{Z^{\prime}}[k,j]\right)\] \[=\sum_{i,k}\left\|\mathrm{ReLU}\left(\bm{Z}[i,:]-\bm{Z^{\prime}}[ k,:]\right)\right\|_{1}\bm{S}[i,k]\qed\]

where \((*)\) follows since \(\sum_{k}\bm{S}[i,k]=1\,\forall i\in[N]\), and \((**)\) follows due to convexity of \(\mathrm{ReLU}\left(\right)\). Now, notice that when \(\bm{S}\in\mathbb{P}_{N}\), then \(\bm{S}[i,:]\) is 1 at one element while 0 at the rest. In that case, we have

\[\sum_{i,j}\mathrm{ReLU}\left(\sum\nolimits_{k}\bm{S}[i,k]\bm{Z}[ i,j]-\bm{S}[i,k]\bm{Z^{\prime}}[k,j]\right) =\sum_{i,j}\mathrm{ReLU}\left(\bm{Z}[i,j]-\bm{Z^{\prime}}[k_{i}^ {*},j]\right)\] \[=\sum_{i,j}\sum_{k}\bm{S}[i,k]\mathrm{ReLU}\left(\bm{Z}[i,j]-\bm {Z^{\prime}}[k,j]\right)\]

where \(k_{i}^{*}\) is the index where \(\bm{S}[i,:]\) is 1. Hence, we have an equality when \(\bm{S}\) is a hard permutation. Replacing \((\bm{Z},\bm{Z^{\prime}})\) with \((\bm{R},\bm{R^{\prime}})\) and \((\bm{X},\bm{X^{\prime}})\), we get that AlignDiff and DiffAlign are equivalent when \(\bm{S}\) is a hard permutation matrix, and moreover DiffAlign is an upper bound on AlignDiff when \(\bm{S}\) is a soft permutation matrix.

### Proof that our design ensures conditions of Proposition 1

Here we show why it is necessary to have a symmetric form for \(\bm{C}[u,u^{\prime}]\) in PermNet\({}_{\phi}\).

For \(\mathrm{GED}(G,G^{\prime})\),

\[\bm{C}[u,v]=\left\|c_{\phi}\left(\bm{x}_{K}(u)\right)-c_{\phi}\left(\bm{x}_{K }^{\prime}(v)\right)\right\|_{1}\]

For \(\mathrm{GED}(G^{\prime},G)\),

\[\bm{C}^{\prime}[v,u]=\left\|c_{\phi}\left(\bm{x}_{K}^{\prime}(v)\right)-c_{ \phi}\left(\bm{x}_{K}(u)\right)\right\|_{1}\]

Because the Sinkhorn cost \(\bm{C}[u,v]\) is symmetric, using the above equations we can infer,

\[\bm{C}[u,v]=\bm{C}^{\prime}[v,u],\text{ which implies }\bm{C}^{\prime}=\bm{C}^{\top}\]

This leads to \(\bm{P}^{\prime}=\bm{P}^{\top}\). If we use an asymmetric Sinkhorn cost (\(\bm{C}[u,v]=\left\|\mathrm{ReLU}\left(c_{\phi}\left(\bm{x}_{K}(u)\right)-c_{ \phi}\left(\bm{x}_{K}^{\prime}(v)\right)\right)\right\|_{1}\)), we cannot ensure \(\bm{C}[u,v]=\bm{C}^{\prime}[v,u]\), which fails to satisfy \(\bm{P}=\bm{P}^{\top}\).

### Alternative surrogate for GED

From Appendix B.2, we have

\[\mathrm{GED}(G,G^{\prime})=\min_{\bm{P}\in\mathbb{P}_{N}}\frac{a^{\oplus}+a^{ \ominus}}{2}\left\|\max(\bm{A},\bm{PA^{\prime}}\bm{P}^{\top})\right\|_{1,1}-a ^{\ominus}|E^{\prime}|-a^{\oplus}|E|\]

Following the relaxations done in Section 4.2, we propose an alternative neural surrogate by replacing \(\left\|\max(\bm{A},\bm{PA^{\prime}}\bm{P}^{\top})\right\|_{1,1}\) by \(\left\|\max(\bm{R},\bm{SR^{\prime}})\right\|_{1,1}\) and \(\left\|\max(\bm{\eta}_{G},\bm{P}\bm{\eta}_{G^{\prime}})\right\|_{1}\) by \(\left\|\max(\bm{X},\bm{P}\bm{X^{\prime}})\right\|_{1,1}\), which gives us the approximated GED parameterized by \(\theta\) and \(\phi\) as

\[\mathrm{GED}_{\theta,\phi}(G,G^{\prime})=\frac{a^{\oplus}+a^{ \ominus}}{2}\left\|\max(\bm{R},\bm{SR^{\prime}})\right\|_{1,1}-a^{\ominus}|E ^{\prime}|-a^{\oplus}|E|\] (20) \[+\frac{b^{\oplus}+b^{\ominus}}{2}\left\|\max(\bm{X},\bm{P}\bm{X^ {\prime}})\right\|_{1,1}-b^{\ominus}|V^{\prime}|-b^{\oplus}|V|\]

We call this neural surrogate as MAX. We note that element-wise maximum over \(\bm{A}\) and \(\bm{PA^{\prime}}\bm{P}^{\top}\), only allows non-edge to non-edge mapping attribute a value of zero. However, the neural surrogate described in Equation 20 fails to capture this, due to the presence of the soft alignment matrix \(\bm{S}\). To address this, we explicitly discard such pairs from MAX by applying an OR operator over the edge presence between concerned node pairs, derived from the adjacency matrices \(\bm{A}\) and \(\bm{A^{\prime}}\) and populated in \(\text{OR}(\bm{A},\bm{A^{\prime}})\in\mathbb{R}^{\binom{n}{2}\times\binom{n}{2}}\) given by \(\text{OR}(\bm{A}[u,v],\bm{A^{\prime}}[u^{\prime},v^{\prime}])\). Similarly, the indication of node presence can be given be given as \(\text{OR}(\bm{\eta}_{G},\bm{\eta}_{G^{\prime}})[u,u^{\prime}]=\text{OR}(\bm{ \eta}_{G}[u],\bm{\eta}_{G^{\prime}}[u^{\prime}])\). Hence, we write

\[\begin{split}\operatorname{GED}_{\theta,\phi}(G,G^{\prime})= \frac{a^{\oplus}+a^{\ominus}}{2}\left\|\text{OR}(\bm{A},\bm{A^{\prime}})\odot \max(\bm{R},\bm{S}\bm{R^{\prime}})\right\|_{1,1}-a^{\ominus}|E^{\prime}|-a^{ \oplus}|E|\\ +\frac{b^{\oplus}+b^{\ominus}}{2}\left\|\text{OR}(\bm{\eta}_{G}, \bm{\eta}_{G^{\prime}})\odot\max(\bm{X},\bm{P}\bm{X^{\prime}})\right\|_{1,1} -b^{\ominus}|V^{\prime}|-b^{\oplus}|V|\end{split}\] (21)

We call this formulation as MAX-OR. We provide the comparison between MAX, MAX-OR, and our models in Appendix D.

Details about experimental setup

### Generation of datasets

We have evaluated the performance of our methods and baselines on seven real-world datasets: Mutagenicity (Mutag), Ogbg-Code2 (Code2), Ogbg-Molhiv (Molhiv), Ogbg-Molpcba (Molpcba), AIDS, Linux and Yeast. We split each dataset into training, validation, and test splits in ratio of 60:20:20. For each split \(\mathcal{D}\), we construct \((|\mathcal{D}|(|\mathcal{D}|+1))/2\) source and target graph instance pairs as follows: \(\mathcal{S}=\{(G_{i},G_{j}):G_{i},G_{j}\in\mathcal{D}\wedge i\leq j\}\). We perform experiment in _four_ GED regimes:

1. GED under uniform cost functions, where \(b^{\ominus}=b^{\oplus}=a^{\ominus}=a^{\oplus}=1\) and substitution costs are 0
2. GED under non-uniform cost functions, where \(b^{\ominus}=3,b^{\oplus}=1,a^{\ominus}=2,a^{\oplus}=1\) and substitution costs are 0
3. edge GED under non-uniform cost functions, where \(b^{\ominus}=b^{\oplus}=0\), \(a^{\ominus}=2,a^{\oplus}=1\), and substitution costs are 0
4. GED with node substitution under uniform cost functions, where \(b^{\ominus}=b^{\oplus}=a^{\ominus}=a^{\oplus}=1\), as well as the node substitution cost \(b^{\sim}=1\).

We emphasize that we generated clean datasets by filtering out isomorphic graphs from the original datasets before performing the training, validation, and test splits. This step is crucial to prevent isomorphism bias in the models, which can occur due to leakage between the training and testing splits, as highlighted by [26].

For each graph, we have limited the maximum number of nodes to twenty, except for Linux, where the limit is ten. Information about the datasets is summarized in Table 7. Mutag contains nitroaromatic compounds, with each node having labels representing atom types. Molhiv and Molpcba contain molecules with node features representing atomic number, chirality, and other atomic properties. Code2 contains abstract syntax trees generated from Python codes. AIDS contains graphs of chemical compounds, with node types representing different atoms. For Molhiv, Molpcba and Linux, we have randomly sampled 1,000 graphs from each original dataset.

### Details about state-of-the-art baselines

We compared our model against nine state-of-the-art neural baselines and three combinatorial GED baselines. Below, we provide details of the methodology and hyperparameter settings used for each baseline. We ensured that the number of model parameters were in a comparable range. Specifically, we set the number of GNN layers to 5, each with a node embedding dimension of 10, to ensure consistency and comparability with our model. The following hyperparameters are used for training: Adam optimiser with a learning rate of 0.001 and weight decay of 0.0005, batch size of 256, early stopping with patience of 100 epochs, and Sinkhorn temperature set to 0.01. **Neural Baselines:**

* **GMN-Match and GMN-Embed** Graph Matching Networks (GMN) use Euclidean distance to assess the similarity between graph-level embeddings of each graph. GMN is available in two variants: GMN-Embed, a late interaction model, and GMN-Match, an early interaction model. For this study, we used the official implementation of GMN to compute Graph Edit Distance (GED).1 Footnote 1: https://github.com/Lin-Yijie/Graph-Matching-Networks/tree/main
* **ISONET** ISONET utilizes the Gumbel-Sinkhorn operator to learn asymmetric edge alignments between two graphs for subgraph matching. In our study, we extend ISONET's approach to predict the Graph Edit Distance (GED) score. We utilized the official PyTorch implementation provided by the authors for our experiments.2

\begin{table}
\begin{tabular}{l|c c c c c c c} \hline  & \#Graphs & \#Train Pairs & \# Val Pairs & \# Test Pairs & Avg. \(|V|\) & Avg. \(|E|\) & Avg. GED & Avg. GED \\  & & & & & & uniform cost & non-uniform \\ \hline Mutag & 729 & 95703 & 10585 & 10878 & 16.01 & 15.76 & 11.15 & cost18.57 \\ Code2 & 128 & 2926 & 325 & 378 & 18.77 & 17.77 & 10.02 & 16.43 \\ Molhiv & 1000 & 180300 & 20100 & 20100 & 15.01 & 15.65 & 11.77 & 19.86 \\ Molpcba & 1000 & 180300 & 20100 & 20100 & 17.52 & 18.67 & 9.58 & 15.73 \\ AIDS & 911 & 149331 & 16653 & 16836 & 10.97 & 10.97 & 7.38 & 12.07 \\ Yeast & 1000 & 180300 & 20100 & 20100 & 16.59 & 17.04 & 10.65 & 17.74 \\ Linux & 89 & 1431 & 153 & 190 & 8.71 & 8.35 & 4.91 & 7.94 \\ \hline \end{tabular}
\end{table}
Table 7: Salient characteristics of data sets.

* **GERED** GREED utilizes a siamese network architecture to compute graph-level embeddings in parallel for two graphs. It calculates the Graph Edit Distance (GED) score by computing the norm of the difference between these embeddings. The official implementation provided by the authors was used for our experiments.3 Footnote 3: https://github.com/idea-iitd/greed
* **ERIC** ERIC utilizes a regularizer to learn node alignment, eliminating the need for an explicit node alignment module. The similarity score is computed using a Neural Tensor Network (NTN) and a Multi-Layer Perceptron (MLP) applied to the final graph-level embeddings of both graphs. These embeddings are derived by concatenating graph-level embeddings from each layer of a Graph Isomorphism Network (GIN). The model is trained using a combined loss from the regularizer and the predicted similarity score. For our experiments, we used the official PyTorch implementation to compute the Graph Edit Distance (GED). The GED scores were inverse normalized from the model output to predict the absolute GED.4 Footnote 4: https://github.com/Jhuow/ERIC
* **SimGNN** SimGNN leverages both graph-level and node-level embeddings at each layer of the GNN. The graph-level embeddings are processed through a Neural Tensor Network to obtain a pair-level embedding. Concurrently, the node-level embeddings are used to compute a pairwise similarity matrix between nodes, which is then converted into a histogram feature vector. A similarity score is calculated by passing the concatenation of these embeddings through a Multi-Layer Perceptron (MLP). We used the official PyTorch implementation of SimGNN and inverse normalization of the predicted Graph Edit Distance (GED) score to obtain the absolute GED value.5 Footnote 5: https://github.com/bendekrozemberczki/SimGNN
* **H2MN** H2MN presents an early interaction model for graph similarity tasks. Instead of learning pairwise node relations, this method attempts to find higher-order node similarity using hypergraphs. At each time step of the hypergraph convolution, a subgraph matching module is employed to learn cross-graph similarity. After the convolution layers, a readout function is utilized to obtain graph-level embeddings. These embeddings are then concatenated and passed through a Multi-Layer Perceptron (MLP) to compute the similarity score. We used the official PyTorch implementation of H2MN.6 Footnote 6: https://github.com/cszhangzhen/H2MN
* **GraphSim** GraphSim uses GNN, where at each layer, a node-to-node similarity matrix is computed using the node embeddings. These similarity matrices are then processed using Convolutional Neural Networks (CNNs) and Multi-Layer Perceptrons (MLPs) to calculate a similarity score. We utilized the official PyTorch implementation.7 Footnote 7: https://github.com/yunshengb/GraphSim
* **EGSC** We used the Teacher model proposed by Efficient Graph Similarity Computation (EGSC), which leverages an Embedding Fusion Network (EFN) at each layer of the Graph Isomorphism Network (GIN). The EFN generates a single embedding from a pair of graph embeddings. The embeddings of the graph pair from each layer are concatenated and subsequently passed through an additional EFN layer and a Multi-Layer Perceptron (MLP) to obtain the similarity score. To predict the absolute Graph Edit Distance (GED), we inversely normalized the GED score obtained from the output of EGSC. We utilized the official PyTorch implementation provided by the authors for our experiments. 8 Footnote 8: https://github.com/canqin001/Efficient_Graph_Similarity_Computation

Combinatorial Baselines:We use the GEDLIB9 library for implementation of all combinatorial baselines.

Footnote 9: https://github.com/dbblumenthal/gedlib

* **Bipartite**[41] Bipartite is an approximate algorithm that considers nodes and surrounding edges of nodes into account try to make a bipartite matching between two graphs. They use linear assignment algorithms to match nodes and their surroundings in two graphs.
* **Branch [8], Branch Tight [8]** improve upon [41] by decomposing graphs into branches. Branch Tight algorithm is another version of Branch that calculates a tighter lower bound but has a higher time complexity than Branch.
* **Anchor Aware GED** Chang et al. [15] provides an approximation algorithm that calculates a tighter lower bound using the anchor aware technique.

* **IPFP**[11] is an approximation algorithm which handles node and edge mapping simultaneously unlike previously discussed methods. This solves a quadratic assignment problem on edges and nodes.
* **F2**[29] uses a binary linear programming approach to find a higher lower bound on GED calculation. This method was used with a very high time limit to generate Ground truth for our experiments.

### Details about GraphEdX

At the high level, GraphEdX consists of two components Embed\({}_{\theta}\) and PermNet\({}_{\phi}\).

Neural Parameterization of Embed\({}_{\theta}\):Embed\({}_{\theta}\) consists of two modules: a GNN denoted as \(\mathrm{MPNN}_{\theta}\) and a MLP\({}_{\theta}\). The \(\mathrm{MPNN}_{\theta}\) consists of \(K=5\) propagation layers used to compute node embeddings of dimension \(d=10\). At each layer \(k\), we compute the updated the node embedding as follows:

\[\bm{x}_{k+1}(u)=\textsc{Update}_{\theta}\left(\bm{x}_{k}(u),\sum_{v\in\textsc {hbr}(u)}\textsc{LRL}_{\theta}(\bm{x}_{k}(u),\bm{x}_{k}(v))\right)\] (22)

where \(\textsc{LRL}_{\theta}\) is a Linear-ReLU-Linear network, with \(d=10\) features, and the Update\({}_{\theta}\) network consists of a Gated Recurrent Unit [30]. In case of GED setting under uniform cost and GED setting under non-uniform cost, we set the initial node features \(\bm{x}_{0}(u)=1\), following [30]. However, in case of computation of GED with node substitution costs, we explicitly provide the one-hot labels as node features. Given the node embeddings and edge-presence indicator obtained from the adjacency matrices, after \(5\) layer propogations, we compute the edge embeddings \(\bm{r}(e)\) using MLP\({}_{\theta}\), which is decoupled from \(\mathrm{MPNN}_{\theta}\). MLP\({}_{\theta}\) consists of a Linear-ReLU-Linear network that maps the \(2d+1=21\) dimensional input consisting of forward \((\bm{x}_{K}(u)\,||\,\bm{x}_{K}(v)\,||\,\bm{A}[u,v])\) and backward \((\bm{x}_{K}(v)\,||\,\bm{x}_{K}(u)\,||\,\bm{A}[v,u])\) signals to \(D=20\) dimensions.

Neural Parameterization of PermNet\({}_{\phi}\):Given the node embeddings \(\bm{x}_{K}(\cdot)\) and \(\bm{x}^{\prime}_{K}(\cdot)\), we first pass them through a neural network \(c_{\phi}\) which consists of a Linear-ReLU-Linear network transforming the features from \(d=10\) to \(N\) dimensions, which is the number of nodes after padding. Except for Linux where \(N=10\), all other datasets have \(N=20\). We obtain the matrix \(\bm{C}\) such that \(\bm{C}[u,u^{\prime}]=\left\|c_{\phi}(\bm{x}_{K}(u))-c_{\phi}(\bm{x}^{\prime}_{ K}(u^{\prime}))\right\|_{1}\). Using temperature \(\tau=0.01\), we perform Sinkhorn iterations on \(\exp(-C/\tau)\) as follows for \(T=20\) iterations to get \(\bm{P}\):

\[\bm{P}_{k}=\textsc{NormCol}\left(\textsc{NormRow}\left(\bm{P}_{k-1}\right)\right)\]

where \(\bm{P}_{0}=\exp(-\bm{C}/\tau)\). Here \(\textsc{NormRow}(\bm{M})[i,j]=\bm{M}[i,j]/\sum_{\ell}\bm{M}[\ell,j]\) denotes the row normalization function and \(\textsc{NormCol}(\bm{M})[i,j]=\bm{M}[i,j]/\sum_{\ell}\bm{M}[i,\ell]\) denotes the column normalization function. We note that the soft alignment \(\bm{P}\) obtained does not depend on the GED cost values, as discussed in Appendix B. The soft alignment \(\bm{P}\) for nodes is used to construct soft alignment \(\bm{S}\) for as follows: \(\bm{S}[(u,v),(u^{\prime},v^{\prime})]=\bm{P}[u,u^{\prime}]\bm{P}[v,v^{\prime} ]+\bm{P}[u,v^{\prime}]\bm{P}[v,u^{\prime}]\).

### Evaluation metrics

Given the dataset \(\mathcal{S}\) consisting of input pairs of graphs \((G,G^{\prime})\) along with the ground truth \(\textsc{GED}(G,G^{\prime})\) and model prediction \(\widehat{\textsc{GED}}(G,G^{\prime})\), we evaluate the performance of the model using the Root Mean Square Error (RMSE) and Kendall-Tau (KTau) [28] between the predicted GED scores and actual GED values.

* **MSE:** It evaluates how far the predicted GED values are from the ground truth. A better performing model is indicated by a lower MSE value. \[\text{MSE}=\frac{1}{|\mathcal{S}|}\sum_{(G,G^{\prime})\in\mathcal{S}}\left( \textsc{GED}(G,G^{\prime})-\widehat{\textsc{GED}}(G,G^{\prime})\right)^{2}\] (23)
* **KTau:** Selection of relevant corpus graphs via graph similarity scoring is crucial to graph retrieval setups. In this context, we would like the number of concordant pairs \(N_{+}\) (where the ranking of ground truth GED and model prediction agree) to be high, and the discordant pairs \(N_{-}\)(where the two disagree) to be low. Formally, we write \[\text{KTau}=\frac{N_{+}-N_{-}}{\binom{|\mathcal{S}|}{2}}\] (24)For the methods which compute a similarity score between the pair of graphs through the notion of normalized GED, we map the similarity score \(s\) back to the GED as \(\widehat{\text{GED}}(G,G^{\prime})=-\frac{|V|+|V|^{\prime}}{2}\log(s+\epsilon)\) where \(\epsilon=10^{-7}\) is added for stability of the logarithm.

### Hardware and license

We implement our models using Python 3.11.2 and PyTorch 2.0.0. The training of our models and the baselines was performed across servers containing Intel Xeon Silver 4216 2.10GHz CPUs, and Nvidia RTX A6000 GPUs. Running times of all methods are compared on the same GPU.

[MISSING_PAGE_FAIL:25]

[MISSING_PAGE_EMPTY:26]

### Comparison of GraphEdX with baselines with and without cost features

Table 12 reports performance in terms of MSE under non-uniform cost setting, with and without costs used as features to the baselines. We notice that that in some cases, providing cost features boost the performance of baselines significantly, and in a few cases, withholding the costs gives a slight improvement in performance. However, GraphEdX, which uses costs in the distance formulation rather than features, outperforms all baselines by a significant margin.

\begin{table}
\begin{tabular}{l|c c c c c c c c} \hline  & Cost used as & \multirow{2}{*}{Mutag} & \multirow{2}{*}{Code2} & \multirow{2}{*}{Molhiv} & \multirow{2}{*}{Molpchea} & \multirow{2}{*}{AIDS} & \multirow{2}{*}{Linux} & \multirow{2}{*}{Yeast} \\  & features & & & & & & & \\ \hline \multirow{2}{*}{GMN-Match} & âœ“ & 69.210 & 13.472 & **76.923** & **23.985** & **31.522** & 21.519 & 63.179 \\  & âœ— & **68.635** & **12.769** & 84.113 & 24.471 & 31.636 & **20.255** & **62.715** \\ \hline \multirow{2}{*}{GMN-Embed} & âœ“ & **72.495** & **13.425** & **78.254** & **28.437** & **33.221** & 20.591 & 60.499 \\  & âœ— & 87.581 & 18.189 & 80.797 & 30.276 & **34.752** & **20.227** & **59.941** \\ \hline \multirow{2}{*}{ISONET} & âœ“ & **3.369** & 3.025 & **3.451** & **2.781** & **5.513** & 3.031 & **4.555** \\  & âœ— & 3.850 & **1.780** & 3.507 & 2.906 & 5.865 & **2.771** & 4.861 \\ \hline \multirow{2}{*}{GREED} & âœ“ & **68.732** & **11.095** & **78.300** & **26.057** & 34.354 & **20.667** & 60.652 \\  & âœ— & 78.878 & 12.774 & 78.837 & 26.188 & **32.318** & 23.478 & **55.985** \\ \hline \multirow{2}{*}{ERIC} & âœ“ & 1.981 & 12.767 & 3.377 & **2.057** & 1.581 & **7.809** & 2.341 \\  & âœ— & **1.912** & **12.391** & **2.588** & 2.220 & **1.536** & 11.186 & **2.161** \\ \hline \multirow{2}{*}{SimGNN} & âœ“ & 4.747 & **5.212** & 4.145 & 3.465 & 4.316 & **5.369** & 4.496 \\  & âœ— & **2.991** & 8.923 & **4.062** & **3.397** & **3.470** & 6.623 & **4.289** \\ \hline \multirow{2}{*}{H2MN} & âœ“ & 3.413 & **9.435** & 3.782 & 3.396 & 3.105 & 5.848 & **3.678** \\  & âœ— & **3.287** & 14.892 & **3.611** & **3.377** & **3.064** & **5.576** & 3.776 \\ \hline \multirow{2}{*}{GraphSim} & âœ“ & 5.370 & **7.405** & 6.643 & 3.928 & **5.266** & 6.815 & 6.907 \\  & âœ— & **4.886** & 10.257 & **6.394** & **3.921** & 5.538 & **6.439** & **6.033** \\ \hline \multirow{2}{*}{EGSC} & âœ“ & **1.758** & **3.957** & **2.371** & **2.133** & 1.693 & 5.503 & **2.157** \\  & âœ— & 1.769 & 4.395 & 2.510 & 2.217 & **1.432** & **4.664** & 2.305 \\ \hline \multicolumn{2}{l|}{GraphEdX} & âœ— & 1.134 & 1.478 & 1.804 & 1.677 & 1.252 & 0.914 & 1.603 \\ \hline \end{tabular}
\end{table}
Table 12: Comparison of performance (MSE) of methods for the non-uniform cost setting when nodes are initialized with costs as features versus without. For each method, the better performance between with and without cost-feature initialization is highlighted in bold for both uniform and non-uniform cost settings. In each column, Green (yellow) numbers report the best (second best) performers.

### Comparison of GraphEdX with baselines with node substitution cost

In Tables 13 and 14, we compare the performance of GraphEdX with baselines under a node substitution cost \(b^{\sim}\). The cost setting is \(b^{\ominus}=b^{\oplus}=b^{\sim}=a^{\ominus}=a^{\oplus}=1\). This experiment includes only five datasets where node labels are present. We observe that GraphEdX outperforms all other baselines. There is no clear second-best model, but ERIC, EGSC, and ISONET perform better than the others.

### Performance evaluation for edge-only vs. all-node-pair representations

In this section, we compare the performance of using graph representation with two variants of our method. (i) Edge-only (edge \(\rightarrow\) edge): Here, \(\bm{R},\bm{R}^{\prime}\in\mathbb{R}^{\max(|E|,|E^{\prime}|)\times D}\) are computed using only the embeddings of node-pairs that are edges, and excluding non-edges. This means that \(\bm{S}\) becomes an edge-to-edge alignment matrix instead of a full node-pair alignment matrix. (ii) Edge-only (pair \(\rightarrow\) pair): In this variant, \(\bm{S}\) remains a node-pair alignment matrix, but the embeddings of the non-edges in \(\bm{R},\bm{R}^{\prime}\in\mathbb{R}^{N(N-1)/2\times D}\) are explicitly set to zero. Tables 15 and 16 contain extended results from Table 6 across seven datasets. The results are similar to those discussed in the main paper: (1) both these sparse representations perform significantly worse compared to our method using non-trivial representations for both edges and non-edges, and (2) Edge-only (edge \(\rightarrow\) edge) performs better than Edge-only (pair \(\rightarrow\) pair). This underscores the importance of explicitly modeling trainable non-edge embeddings to capture the sensitivity of GED to global graph structure.

\begin{table}
\begin{tabular}{l|c c c c c} \hline  & Mutag & Code2 & Molhiv & Molpcba & AIDS \\ \hline GMN-Match & 1.057 \(\pm\) 0.011 & 5.224 \(\pm\) 0.404 & 1.388 \(\pm\) 0.018 & 1.432 \(\pm\) 0.017 & 0.868 \(\pm\) 0.007 \\ GMN-Embed & 2.159 \(\pm\) 0.026 & 4.070 \(\pm\) 0.318 & 3.523 \(\pm\) 0.040 & 4.657 \(\pm\) 0.054 & 1.818 \(\pm\) 0.014 \\ ISONET & 0.876 \(\pm\) 0.008 & 1.129 \(\pm\) 0.084 & 1.617 \(\pm\) 0.020 & 1.332 \(\pm\) 0.014 & 1.142 \(\pm\) 0.010 \\ GREED & 2.876 \(\pm\) 0.032 & 4.983 \(\pm\) 0.531 & 2.923 \(\pm\) 0.033 & 3.902 \(\pm\) 0.044 & 2.175 \(\pm\) 0.016 \\ ERIC & 0.886 \(\pm\) 0.009 & 6.323 \(\pm\) 0.683 & 1.537 \(\pm\) 0.018 & 1.278 \(\pm\) 0.014 & 1.602 \(\pm\) 0.036 \\ SimGNN & 1.160 \(\pm\) 0.013 & 5.909 \(\pm\) 0.490 & 1.888 \(\pm\) 0.031 & 2.172 \(\pm\) 0.050 & 1.418 \(\pm\) 0.020 \\ H2MN & 1.277 \(\pm\) 0.014 & 6.783 \(\pm\) 0.587 & 1.891 \(\pm\) 0.024 & 1.666 \(\pm\) 0.021 & 1.290 \(\pm\) 0.011 \\ GraphSim & 1.043 \(\pm\) 0.010 & 4.708 \(\pm\) 0.425 & 1.817 \(\pm\) 0.021 & 1.748 \(\pm\) 0.021 & 1.561 \(\pm\) 0.021 \\ EGSC & 0.776 \(\pm\) 0.008 & 8.742 \(\pm\) 0.831 & 1.273 \(\pm\) 0.016 & 1.426 \(\pm\) 0.018 & 1.270 \(\pm\) 0.028 \\ \hline GraphEdX & 0.441 \(\pm\) 0.004 & 0.820 \(\pm\) 0.092 & 0.792 \(\pm\) 0.009 & 0.846 \(\pm\) 0.009 & 0.538 \(\pm\) 0.003 \\ \hline \end{tabular}
\end{table}
Table 13: Comparison with baselines in terms of MSE including standard error, in presence of the node substitution cost, which set to one in uniform cost setting: \(b^{\ominus}=b^{\oplus}=b^{\sim}=a^{\ominus}=a^{\oplus}=1\). **Green** (yellow) numbers report the best (second best) performers.

\begin{table}
\begin{tabular}{l|c c c c c c} \hline  & Mutag & Code2 & Molhiv & Molpcba & AIDS \\ \hline GMN-Match & 0.895 & 0.811 & 0.881 & 0.809 & 0.839 \\ GMN-Embed & 0.847 & 0.845 & 0.796 & 0.684 & 0.767 \\ ISONET & 0.906 & 0.925 & 0.868 & 0.815 & 0.812 \\ GREED & 0.827 & 0.829 & 0.822 & 0.710 & 0.746 \\ ERIC & 0.905 & 0.847 & 0.872 & 0.818 & 0.815 \\ SimGNN & 0.891 & 0.836 & 0.864 & 0.797 & 0.810 \\ H2MN & 0.886 & 0.818 & 0.858 & 0.789 & 0.802 \\ GraphSim & 0.896 & 0.846 & 0.860 & 0.782 & 0.795 \\ EGSC & 0.912 & 0.802 & 0.885 & 0.821 & 0.832 \\ \hline GraphEdX & 0.936 & 0.945 & 0.913 & 0.856 & 0.874 \\ \hline \end{tabular}
\end{table}
Table 14: Comparison with baselines in terms of KTau, in presence of the node substitution cost, which set to one in uniform cost setting: \(b^{\ominus}=b^{\oplus}=b^{\sim}=a^{\ominus}=a^{\oplus}=1\). **Green** (yellow) numbers report the best (second best) performers.

### Effect of using cost-guided scoring function on baselines

In Tables 17 and 18, we report the impact of replacing the baselines' scoring function with our proposed cost-guided scoring function on three baselines across seven datasets for uniform and non-uniform cost settings, respectively. We notice that similar to the results reported in Section 5.2, the cost-guided scoring function helps the baselines perform significantly better in both the cost settings.

### Results on performance of the alternate surrogates for GED

In Table 19, we present the performance of the alternate surrogates scoring function for GED discussed in B under non-uniform cost settings (\(b^{\odot}=3,b^{\oplus}=1,a^{\odot}=2,a^{\oplus}=1\)). From the results, we can infer that the alternate surrogates have comparable performance to GraphEdX however GraphEdX outperforms it by a small margin on six out of the seven datasets.

### Results on performance of the alternate surrogates for GED

In Table 19, we present the performance of the alternate surrogates scoring function for GED discussed in B under non-uniform cost settings (\(b^{\odot}=3,b^{\oplus}=1,a^{\odot}=2,a^{\oplus}=1\)). From the results, we can infer that the alternate surrogates have comparable performance to GraphEdX however GraphEdX outperforms it by a small margin on six out of the seven datasets.

### Comparison of zero-shot performance on other datasets

In Table 20, we compare all baselines with GraphEdX on zero-shot GED prediction on a new dataset. For each method, we select the best-performing models for {AIDS, Yeast, Mutag, Molhiv }, and test each one on the AIDS dataset under non-uniform cost setting.

\begin{table}
\begin{tabular}{l|c c c c c c c c} \hline  & Mutag & Code2 & Molhiv & Molpcka & AIDS & Linux & Yeast \\ \hline Edge-only (edge \(\rightarrow\) edge) & \(1.274\pm 0.017\) & \(1.817\pm 0.014\) & \(1.847\pm 0.019\) & \(1.793\pm 0.017\) & \(1.318\pm 0.014\) & \(0.907\pm 0.0129\) & \(1.649\pm 0.016\) \\ Edge-only (pair \(\rightarrow\) pair) & \(1.276\pm 0.017\) & \(1.879\pm 0.136\) & \(1.865\pm 0.020\) & \(1.779\pm 0.017\) & \(1.422\pm 0.015\) & \(0.992\pm 0.114\) & \(1.694\pm 0.017\) \\ \hline GraphEdX & \(1.134\pm 0.016\) & \(1.478\pm 0.118\) & \(1.804\pm 0.019\) & \(1.677\pm 0.016\) & \(1.252\pm 0.014\) & \(0.914\pm 0.110\) & \(1.603\pm 0.016\) \\ \hline \end{tabular}
\end{table}
Table 16: Comparison of using all-node-pairs against edge-only representations using MSE for non-uniform cost setting. **Green** (yellow) numbers report the best (second best) performers.

\begin{table}
\begin{tabular}{l|c c c c c c c c c} \hline  & Mutag & Code2 & Molhiv & Molpcka & AIDS & Linux & Yeast \\ \hline GMN-Match & \(69.210\pm 0.088\) & \(1.3472\pm 0.070\) & \(76.923\pm 0.082\) & \(23.985\pm 0.224\) & \(1.3522\pm 0.513\) & \(21.591\pm 2.256\) & \(63.175\pm 1.127\) \\ GMN-Match * & \(\bm{1.592\pm 0.027}\) & \(\bm{1.596\pm 0.285}\) & \(\bm{2.162\pm 0.042}\) & \(\bm{1.986\pm 0.021}\) & \(\bm{1.443\pm 0.017}\) & \(\bm{1.596\pm 0.211}\) & \(\bm{2.036\pm 0.022}\) \\ \hline GNN-Embed & \(72.495\pm 0.915\) & \(13.425\pm 0.105\) & \(78.254\pm 0.056\) & \(23.437\pm 0.268\) & \(33.221\pm 0.523\) & \(20.951\pm 1.236\) & \(0.949\pm 0.663\) \\ GMN-Embed & \(\bm{2.368\pm 0.039}\) & \(\bm{3.272\pm 0.289}\) & \(\bm{3.413\pm 0.037}\) & \(\bm{2.486\pm 0.043}\) & \(\bm{2.046\pm 0.025}\) & \(\bm{1.495\pm 0.200}\) & \(\bm{2.385\pm 0.042}\) \\ \hline GraphEdX & \(68.732\pm 0.867\) & \(16.995\pm 0.773\) & \(78.300\pm 0.795\) & \(26.057\pm 0.238\) & \(34.354\pm 0.557\) & \(26.67\pm 2.140\) & \(0.662\pm 0.704\) \\ GREED * & \(\bm{2.456\pm 0.040}\) & \(\bm{5.429\pm 0.517}\) & \(\bm{3.827\pm 0.043}\) & \(\bm{3.807\pm 0.040}\) & \(\bm{2.282\pm 0.028}\) & \(\bm{2.894\pm 0.394}\) & \(\bm{3.506\pm 0.038}\) \\ \hline GraphEdX & \(1.134\pm 0.016\) & \(1.478\pm 0.118\) & \(1.804\pm 0.019\) & \(1.677\pm 0.016\) & \(1.252\pm 0.014\) & \(0.914\pm 0.110\) & \(1.603\pm 0.016\) \\ \hline \end{tabular}
\end{table}
Table 18: Impact of cost-guided distance on MSE in non-uniform cost setting (\(b^{\odot}=3,b^{\oplus}=1,a^{\odot}=2,a^{\oplus}=1\)). \(a^{\oplus}=2,a^{\oplus}=1\). \(a^{\oplus}=1\). \(a^{\oplus}=1.9\).

[MISSING_PAGE_FAIL:30]

[MISSING_PAGE_EMPTY:31]

### Comparison of performance of our model with baselines using scatter plot

In Figure 25, we illustrate the performance of our model compared to the second-best performing model, under both uniform and non-uniform cost settings, by visualizing the distribution of outputs of the predicted GEDs by both models. We observe that predictions from our model consistently align closer to the \(y=x\) line across various datasets showcasing lower output variance as compared to the next best-performing model.

### Comparison of performance of our model with baselines using error distribution

In Figure 26, we plot the distribution of error (MSE) of our model against the second-best performing model, under both uniform and non-uniform cost settings. We observe that our model performs better, exhibiting a higher probability density for lower MSE values and a lower probability density for higher MSE values.

Figure 26: Error distribution of our model compared to the next best-performing model across various datasets under both uniform and non-uniform cost settings.

Figure 25: Scatter plot comparing the distribution of the predicted GED of our model with the next best-performing model across various datasets under both uniform and non-uniform cost settings.

### Comparison of combinatorial optimisation gadgets for GED prediction

We compare the runtime performance of six combinatorial optimization algorithms described in Appendix C (ipfp [11], anchor-aware GED [15], branch tight [8], F2 [29], bipartite [41] and branch [8]). We note that combinatorial algorithms are slow to approximate the GED between two graphs. Specifically, GraphEdX often predicts the GED in \(\sim 10^{-4}\) seconds per graph, however, the performance of the combinatorial baselines are extremely poor under such a time constraint. Hence, we execute the combinatorial algorithms with four different time limits per graph: ranging from \(10^{-2}\) seconds (100x our method) to \(10\) seconds (\(10^{5}\)x our method).

In Figure 27, we depict the MSE versus time limit for the aforementioned combinatorial algorithms under both uniform and non-uniform cost settings. We also showcase the inference time per graph of our method in the figure. It is evident that even with a time limit scaled by \(10^{5}\)x, most combinatorial algorithms struggle to achieve a satisfactory approximation for the GED.

Figure 27: Performance of combinatorial optimization algorithms on various datasets under both uniform and non-uniform cost settings is evaluated. We plot MSE against the time limit allocated to the combinatorial algorithms. Additionally, we include the amortized time of our model and its MSE.

### Prediction timing analysis

In Figure 28 illustrates the inference time per graph of our model versus under uniform cost settings, averaged over ten runs. From the figure, we observe the following (1) GraphEdX outperforms four of the baselines in terms of inference time, and is comparable to ISONET's inference time (2) GMN-Embed, GREED, ERIC, and EGSC run faster compared to all other methods due to lack of interaction between graphs, which results in poorer performance at predicting the GED.

### Visualization (optimal edit path) + Pseudocode

In Algorithm 1, we present the pseudocode to generate the optimal edit path given the learnt node and edge alignments from GraphEdX. Figure 29 demonstrates how the operations in the edit path can be utilized to convert \(G\) to \(G^{\prime}\).

```
1:functionGetEditPath(\(G,G^{\prime},\boldsymbol{\eta}_{G},\boldsymbol{\eta}_{G^{\prime}}\))
2:\(\boldsymbol{P},\boldsymbol{S}\leftarrow\textsc{GraphedX}(G,G^{\prime}, \boldsymbol{\eta}_{G},\boldsymbol{\eta}_{G^{\prime}})\)
3:\(\boldsymbol{P},\boldsymbol{S}\leftarrow\textsc{Hunigarian}(\boldsymbol{P})\), \(\textsc{Hunigarian}(\boldsymbol{S})\)
4:\(o\) = NewList()
5:for\((u,v)\in[N]\times[N]\)do
6:if\(\boldsymbol{P}[u,v]=1\) and \(\boldsymbol{\eta}_{G}[u]=0\) and \(\boldsymbol{\eta}_{G^{\prime}}[v]=1\)then
7: AddItem(\(o\),AddNode(\(u\)))
8:for\((u,v),(u^{\prime},v^{\prime})\in\{[N]\times[N]\}\times\{[N]\times[N]\}\)do
9:if\(\boldsymbol{S}[(u,v),(u^{\prime},v^{\prime})]=1\) and \(\boldsymbol{A}[u,v]=0\) and \(\boldsymbol{A}^{\prime}[u^{\prime},v^{\prime}]=1\)then
10: AddItem(\(o\),AddEdge(\((u,v)\)))
11:if\(\boldsymbol{S}[(u,v),(u^{\prime},v^{\prime})]=1\) and \(\boldsymbol{A}[u,v]=1\) and \(\boldsymbol{A}^{\prime}[u^{\prime},v^{\prime}]=0\)then
12: AddItem(\(o\),DelEdge(\((u,v)\)))
13:for\((u,v)\in[N]\times[N]\)do
14:if\(\boldsymbol{P}[u,v]=1\) and \(\boldsymbol{\eta}_{G}[u]=1\) and \(\boldsymbol{\eta}_{G^{\prime}}[v]=0\)then
15: AddItem(\(o\),DelNode(\(u\)))
16:return\(o\) ```

**Algorithm 1** Generation of Edit Path

Figure 28: GED inference time comparison between our model and baselines. We notice that GraphEdX is consistently the third-fastest amongst all baselines. Although GMN-Embed and GREED have the lowest inference time, GraphEdX has much lower MSE consistently.

Figure 29: An example of the sequence of edit operations performed to convert one graph into another.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: In Section 5, we present experiments and results to support the claims made in the abstract and introduction. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: In Conclusions, we discuss the limitations of our work. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: In Appendix B, we provide proof for the theoretical results mentioned in the paper. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.

* All assumptions should be clearly stated or referenced in the statement of any theorems.
* The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.
* Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.
* Theorems and Lemmas that the proof relies upon should be properly referenced.
* **Experimental Result Reproducibility*
* Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: We provide code and dataset in the supplementary material with instructions to reproduce the results. Guidelines:
* The answer NA means that the paper does not include experiments.
* If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.
* If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.
* Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general, releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.
* While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example
* If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm.
* If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully.
* If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset).
* We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
* **Open access to data and code*
* Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: In the supplementary material, we provide code for our model, baselines, and experimental datasets, as well as instructions for reproducing the results. Guidelines:
* The answer NA means that paper does not include experiments requiring code.
* Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: In Appendix C, we provide training details, such as hyperparameters and optimizer used. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: Along with Mean Squared Error we also provide Standard deviation to report the statistical significance of our results. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors). * It should be clear whether the error bar is the standard deviation or the standard error of the mean. * It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified. * For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). * If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes]Justification: In Appendix C we provide information on hardware used for running experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: Yes, the research conducted in the paper conforms, in every aspect, with Neurips Code of Ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: In Appendix A we have discuss broader impact of our work. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. * If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: We do not use any such dataset/method. Guidelines: * The answer NA means that the paper poses no such risks.

* Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.
* Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.
* We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
* **Licenses for existing assets*
* Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: We cite and provide URLs for datasets and codes that we use for the experiments. Guidelines:
* The answer NA means that the paper does not use existing assets.
* The authors should cite the original paper that produced the code package or dataset.
* The authors should state which version of the asset is used and, if possible, include a URL.
* The name of the license (e.g., CC-BY 4.0) should be included for each asset.
* For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.
* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [Yes] Justification: We provide our code and dataset with README file having instructions on how to run the experiments. Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: This work does not involve such research. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: This work does not involve such research. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.