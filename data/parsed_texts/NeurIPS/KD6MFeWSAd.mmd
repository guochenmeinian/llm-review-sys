[MISSING_PAGE_FAIL:1]

Taken together, these works paint an encouraging picture of our understanding of DDPMs which takes into account both the diversity of data in applications (including data distributions which are highly multimodal or supported on lower-dimensional manifolds), as well as the non-convex training process which is not guaranteed to accurately learn the score function uniformly in space.

Besides DDPMs, instead of implementing the time reversed diffusion as an SDE, it is also possible to implement it as an ordinary differential equation (ODE), called the _probability flow ODE_[15]; see SS2. The ODE implementation is often claimed to be faster than the SDE implementation [16, 17], with the rationale being that ODE discretization is typically more accurate than SDE discretization, so that one could use a larger step size. Indeed, the discretization error usually depends on the regularity of the trajectories, which is \(\mathcal{C}^{1}\) for ODEs but only \(\mathcal{C}^{\frac{1}{2}-}\) for SDEs (_i.e._, Holder continuous with any exponent less than \(\frac{1}{2}\)) due to the roughness of the Brownian motion driving the evolution.

Far from being able to capture this intuition, current analyses of SGMs cannot even provide a _polynomial-time_ analysis of the probability flow ODE. The key issue is that under our minimal assumptions (_i.e._, without log-concavity of the data distribution), the underlying dynamics of either the ODE or SDE implementation are not contractive, and hence small errors quickly accumulate and are magnified. The aforementioned analyses of DDPMs managed to overcome this challenge by leveraging techniques specific to the analysis of SDEs, through which we now understand that _stochasticity_ plays an important role in alleviating error accumulation. It is unknown, however, how to carry out the analysis for the purely deterministic dynamics inherent to the probability flow ODE.

Our first main contribution is to give the first convergence guarantees for SGMs with OU forward dynamics in which steps of the discretized probability flow ODE--referred to as _predictor steps_--are interleaved with _corrector steps_ which runs the overdamped Langevin diffusion with estimated score, as pioneered in [15]. Our results are akin to prior works on DDPMs in that they hold under minimal assumptions on the data distribution and under \(L^{2}\) bounds on the score estimation error, and our guarantees scale polynomially in all relevant problem parameters. Here, the corrector steps inject stochasticity which is crucial for our proofs; however, we emphasize that the use of corrector steps does _not_ simply reduce the problem to applying existing DDPM analyses. Instead, we must develop an entirely new framework based on Wasserstein-to-TV regularization, which is of independent interest; see SS4 for a detailed overview of our techniques. Our results naturally raise the question of whether the corrector steps are necessary in practice, and we discuss this further in SS5.

When the data distribution is log-smooth, then the dimension dependence of prior results on DDPMs, as well as our first result for the probability flow ODE with overdamped corrector, both scale as \(O(d)\). Does this contradict the intuition that ODE discretization is more accurate than SDE discretization? The answer is _no_; upon inspecting our proof, we see that the discretization error of the probability flow ODE is indeed smaller than what is incurred by DDPMs, and in fact allows for a larger step size of order \(1/\sqrt{d}\). The bottleneck in our result stems from the use of the overdamped Langevin diffusion for the corrector steps. Taking inspiration from the literature on log-concave sampling (see, _e.g._, [17] for an exposition), our second main contribution is to propose corrector steps based on the _underdamped_ Langevin diffusion (see SS2) which is known to improve the dimension dependence of sampling. In particular, we show that the probability flow ODE with underdamped Langevin corrector attains \(O(\sqrt{d})\) dimension dependence. This dependence is better than what was obtained for DDPMs in [17, 18, 19] and therefore highlights the potential benefits of the ODE framework. We note that the benefit to which we refer is at _generation time_, and not at training time.

Previously, [14] have proposed a "noise-denoise" sampler using the underdamped Langevin diffusion, but to our knowledge, our work is the first to use it in conjunction with the probability flow ODE. Although we provide preliminary numerical experiments in the Appendix, we leave it as a question for future work to determine whether the theoretical benefits of the underdamped Langevin corrector are also borne out in practice.

### Our contributions

In summary, our contributions are the following.

* We provide the first convergence guarantees for the probability flow ODE with overdamped Langevin corrector (DPOM; Algorithm 1).

* We propose an algorithm based on the probability flow ODE with underdamped Langevin corrector (DPUM; Algorithm 2).
* We provide the first convergence guarantees for DPUM. These convergence guarantees show improvement over (i) the complexity of DPOM (\(O(\sqrt{d})\) vs \(O(d)\)) and (ii) the complexity of DDPMs, _i.e._, SDE implementations of score-based generative models (again, \(O(\sqrt{d})\) vs \(O(d)\)).
* We provide preliminary numerical experiments in a toy example showing that DPUM can sample from a highly non log-concave distribution (see Appendix). The numerical experiments are not among our main contributions and are provided for illustration only. The Python code can be found in the Supplementary material.

Our main theorem can be summarized informally as follows; see SS3 for more detailed statements.

**Theorem 1** (Informal).: _Assume that the score function along the forward process is \(L\)-Lipschitz, and that the data distribution has finite second moment. Assume that we have access to \(\widetilde{O}(\varepsilon/\sqrt{L})\)\(L^{2}\)-accurate score estimates. Then, the probability flow ODE implementation of the reversed Ornstein-Uhlenbeck process, when interspersed with either the overdamped Langevin corrector (DPOM; Algorithm 1) or with the underdamped Langevin corrector (DPUM; Algorithm 2), outputs a sample whose law is \(\varepsilon\)-close in total variation distance to the data distribution, using \(\widetilde{O}(L^{3}d/\varepsilon^{2})\) or \(\widetilde{O}(L^{2}\sqrt{d}/\varepsilon)\) iterations respectively._

Our result provides the _first_ polynomial-time guarantees for the probability flow ODE implementation of SGMs, so long as it is combined with the use of corrector steps. Moreover, when the corrector steps are based on the underdamped Langevin diffusion, then the dimension dependence of our result is significantly smaller (\(O(\sqrt{d})\) vs. \(O(d)\)) than prior works on the complexity of DDPMs, and thus provides justification for the use of ODE discretization in practice, compared to SDEs.

Our main assumption on the data is that the score functions along the forward process are Lipschitz continuous, which allows for highly non-log-concave distributions, yet does not cover non-smooth distributions such as distributions supported on lower-dimensional manifolds. However, as shown in [10; 11; 12], we can also obtain polynomial-time guarantees without this smoothness assumption via early stopping (see Remark 1).

### Related works

The idea of using a time-reversed diffusion for sampling has been fruitfully exploited in the log-concave sampling literature via the _proximal sampler_[14; 1; 15; 16; 17; 18; 19], as put forth in [10], as well as through algorithmic stochastic localization [11; 21]. Although we do not aim to be comprehensive in our discussion of the literature, we mention, e.g., [1; 1] for alternative approaches for diffusion models. We also note that the recent work of [1] obtained a discretization analysis for the probability flow ODE (without corrector) in KL divergence, though their bounds have a large dependence on \(d\) and are exponential in the Lipschitz constant of the score integrated over time.

Since the original arXiv submission of this paper, there have been further works studying the probability flow ODE. The work of [1] also studied the probability flow ODE, but without providing discretization guarantees (and with possibly exponential dependencies). The work [10] provides polynomial-time guarantees for the probability flow ODE (without corrector steps), at the cost of larger polynomial dependencies and more stringent score assumptions (namely, bounds on the Jacobian of the score). Also, [20] study another variant of the predictor-corrector framework.

## 2 Preliminaries

### Score-based generative modeling

Let \(q_{\star}\) denote the data distribution, _i.e._, the distribution from which we wish to sample. In score-based generative modeling, we define a forward process \((q_{t}^{\rightarrow})_{t\geq 0}\) with \(q_{0}^{\rightarrow}=q_{\star}\), which transforms our data distribution into noise. In this paper, we focus on the canonical choice of the Ornstein-Uhlenbeck(OU) process,

\[\mathrm{d}x_{t}^{\rightarrow}=-x_{t}^{\rightarrow}\,\mathrm{d}t+\sqrt{2}\, \mathrm{d}B_{t}\,,\qquad x_{0}^{\rightarrow}\sim q_{\star}\,,\qquad q_{t}^{ \rightarrow}\coloneqq\mathrm{law}(x_{t}^{\rightarrow})\,,\] (1)

where \(\left(B_{t}\right)_{t\geq 0}\) is a standard Brownian motion in \(\mathbb{R}^{d}\). It is well-known that the OU process mixes rapidly (exponentially fast) to its stationary distribution, the standard Gaussian distribution \(\gamma^{d}\).

Once we fix a time horizon \(T>0\), the time reversal of the SDE defined in (1) over \([0,T]\) is given by

\[\mathrm{d}x_{t}^{\leftarrow}=(x_{t}^{\leftarrow}+2\,\nabla\ln q_{t}^{ \leftarrow}(x_{t}^{\leftarrow}))\,\mathrm{d}t+\sqrt{2}\,\mathrm{d}B_{t}\,,\] (2)

where \(q_{t}^{\leftarrow}\coloneqq q_{T-t}^{\rightarrow}\), and the reverse SDE is a generative model: when initialized at \(x_{0}^{\leftarrow}\sim q_{0}^{\leftarrow}\), then \(x_{T}^{\leftarrow}\sim q\). Since \(q_{0}^{\leftarrow}=q_{T}^{\rightarrow}\approx\gamma^{d}\), the reverse SDE transforms samples from \(\gamma^{d}\) (i.e., pure noise) into approximate samples from \(q_{\star}\). In order to implement the reverse SDE, however, one needs to estimate the score functions \(\nabla\ln q_{t}^{\leftarrow}\) for \(t\in[0,T]\) using the technique of score matching [11, 12]. In practice, the score estimates are produced via a deep neural network, and our main assumption is that these score estimates are accurate in an \(L^{2}\) sense (see Assumption 4). This gives rise to the denoising diffusion probabilistic modeling (DDPM) algorithm.

Notation.Since the reverse process is the primary object of interest, we drop the arrow \(\leftarrow\) from the notation for simplicity; thus, \(q_{t}\coloneqq q_{t}^{\leftarrow}\). We will always denote the forward process with the arrow \(\rightarrow\).

For each \(t\in[0,T]\), let \(s_{t}\) denote the estimate for the score \(\nabla\ln q_{t}=\nabla\ln q_{t}^{\leftarrow}\).

### Probability flow ODE (predictor steps)

Instead of running the reverse SDE (2), there is in fact an alternative process \(\left(x_{t}\right)_{t\in[0,T]}\) which evolves according to an ODE (and hence evolves deterministically), and yet has the same marginals as (2). This alternative process, called the _probability flow ODE_, can also be used for generative modeling.

One particularly illuminating way of deriving the probability flow ODE is to invoke the celebrated theorem, due to [1], that the OU process is the Wasserstein gradient flow of the KL divergence functional (i.e. relative entropy) \(\mathsf{KL}(\cdot\,\|\,\gamma^{d})\). From the general theory of Wasserstein gradient flows (see [1, 1]), the Wasserstein gradient flow \(\left(\mu_{t}\right)_{t\geq 0}\) of a functional \(\mathcal{F}\) can be implemented via the dynamics

\[\dot{z}_{t}=-[\nabla_{W_{2}}\mathcal{F}(\mu_{t})](z_{t})\,,\qquad z_{0}\sim \mu_{0}\,,\]

in that \(z_{t}\sim\mu_{t}\) for all \(t\geq 0\). Applying this to \(\mathcal{F}\coloneqq\mathsf{KL}(\cdot\,\|\,\gamma^{d})\), we arrive at the forward process

\[\dot{x}_{t}^{\rightarrow}=-\nabla\ln\Bigl{(}\frac{q_{t}^{\rightarrow}}{\gamma ^{d}}\Bigr{)}(x_{t}^{\rightarrow})=-x_{t}^{\rightarrow}-\nabla\ln q_{t}^{ \rightarrow}(x_{t}^{\rightarrow})\,.\] (3)

Setting \(x_{t}\coloneqq x_{T-t}^{\rightarrow}\), it is easily seen that the time reversal of (3) is

\[\dot{x}_{t}=x_{t}+\nabla\ln q_{t}(x_{t})\,,\quad\textit{i.e.,}\quad\dot{x}_{t }=x_{t}+\nabla\ln q_{T-t}^{\rightarrow}(x_{t})\,,\] (4)

which is called the probability flow ODE. In this paper, the interpretation of the probability flow ODE as a reverse Wasserstein gradient flow is only introduced for interpretability, and the reader who is unfamiliar with Wasserstein calculus can take (4) to be the definition of the probability flow ODE. Crucially, it has the property that if \(x_{0}\sim q_{0}\), then \(x_{t}\sim q_{t}\) for all \(t\in[0,T]\).

We can discretize the ODE (4). Fixing a step size \(h>0\), replacing the score function \(\nabla\ln q_{t}\) with the estimated score given by \(s_{t}\), and applying the exponential integrator to the ODE (i.e., exactly integrating the linear part), we arrive at the discretized process

\[x_{t+h}=x_{t}+\int_{0}^{h}x_{t+u}\,\mathrm{d}u+h\,s_{t}(x_{t})=\exp(h)\,x_{t}+ \left(\exp(h)-1\right)s_{t}(x_{t})\,.\] (5)

### Corrector steps

Let \(q\) be a distribution over \(\mathbb{R}^{d}\), and write \(U\) as a shorthand for the potential \(-\ln q\).

Overdamped Langevin.The _overdamped Langevin diffusion_ with potential \(U\) is a stochastic process \((x_{t})_{t\geq 0}\) over \(\mathbb{R}^{d}\) given by

\[\mathrm{d}x_{t}=-\nabla U(x_{t})\,\mathrm{d}t+\sqrt{2}\,\mathrm{d}B_{t}\,.\]

The stationary distribution of this diffusion is \(q\propto\exp(-U)\).

We also consider the following discretized process where \(-\nabla U\) is replaced by a _score estimate_\(s\). Fix a step size \(h>0\) and let \((\widehat{x}_{t})_{t\geq 0}\) over \(\mathbb{R}^{d}\) be given by

\[\mathrm{d}\widehat{x}_{t}=s(\widehat{x}_{\lfloor t/h\rfloor\,h})\,\mathrm{d}t +\sqrt{2}\,\mathrm{d}B_{t}\,.\]

Underdamped Langevin.Given a friction parameter \(\gamma>0\), the corresponding _underdamped Langevin diffusion_ is a stochastic process \((z_{t},v_{t})_{t\geq 0}\) over \(\mathbb{R}^{d}\times\mathbb{R}^{d}\) given by

\[\mathrm{d}z_{t} =v_{t}\,\mathrm{d}t\,,\] \[\mathrm{d}v_{t} =-(\nabla U(z_{t})+\gamma v_{t})\,\mathrm{d}t+\sqrt{2\gamma}\, \mathrm{d}B_{t}\,.\]

The stationary distribution of this diffusion is \(q\otimes\gamma^{d}\).

We also consider the following discretized process, where \(-\nabla U\) is replaced by a score estimate \(s\). Let \((\widehat{z}_{t},\widehat{v}_{t})_{t\geq 0}\) over \(\mathbb{R}^{d}\times\mathbb{R}^{d}\) be given by

\[\mathrm{d}\widehat{z}_{t} =\widehat{v}_{t}\,\mathrm{d}t\,,\] (6) \[\mathrm{d}\widehat{v}_{t} =(s(\widehat{z}_{\lfloor t/h\rfloor\,h})-\gamma\widehat{v}_{t}) \,\mathrm{d}t+\sqrt{2\gamma}\,\mathrm{d}B_{t}\,.\]

Diffusions as corrector steps.At time \(t\), the law of the ideal reverse process (4) initialized at \(q_{0}\) is \(q_{t}\). However, errors are accumulated through the course of the algorithm: the error from initializing at \(\gamma^{d}\) rather than at \(q_{0}\); errors arising from discretization of (4); and errors in estimating the score function. That's why the law of the algorithm's iterate will not be exactly \(q_{t}\). We propose to use either the overdamped or the underdamped Langevin diffusion with stationary distribution \(q_{t}\) and estimated score as a corrector, in order to bring the law of the algorithm iterate closer to \(q_{t}\). In the case of the underdamped Langevin diffusion, this is done by drawing an independent Gaussian random variable \(\widehat{v}_{0}\sim\gamma^{d}\), running the system (6) starting from \((\widehat{z}_{0},\widehat{v}_{0})\) (where \(\widehat{z}_{0}\) is the current algorithm iterate) for some time \(t\), and then keeping \(\widehat{z}_{t}\). In our theoretical analysis, the use of corrector steps boosts the accuracy and efficiency of the SGM.

## 3 Results

### Assumptions

We make the following mild assumptions on the data distribution \(q_{*}\) and on the score estimate \(s\).

**Assumption 1** (second moment bound).: _We assume that \(\mathfrak{m}_{2}^{2}:=\mathbb{E}_{q_{*}}[\|\cdot\|^{2}]<\infty\)._

**Assumption 2** (Lipschitz score).: _For all \(t\in[0,T]\), the score \(\nabla\ln q_{t}\) is \(L\)-Lipschitz, for some \(L\geq 1\)._

**Assumption 3** (Lipschitz score estimate).: _For all \(t\) for which we need to estimate the score function in our algorithms, the score estimate \(s_{t}\) is \(L\)-Lipschitz._

**Assumption 4** (score estimation error).: _For all \(t\) for which we need to estimate the score function in our algorithms,_

\[\mathbb{E}_{q_{*}}[\|s_{t}-\nabla\ln q_{t}\|^{2}]\leq\varepsilon_{\mathbf{sc} }^{2}\,.\]

Assumptions 1, 2, and 4 are standard and were shown in [11, 12, 13] to suffice for obtaining polynomial-time convergence guarantees for DDPMs. The new condition that we require in our analysis is Assumption 3, which was used in [13] but ultimately shown to be unnecessary for DDPMs. We leave it as an open question whether this can be lifted in the ODE setting.

_Remark 1_.: As observed in [11, 13, 13], Assumption 2 can be removed via early stopping, at the cost of polynomially larger iteration complexity. The idea is that if \(q_{*}\) has compact support but does not necessarily satisfy Assumption 2 (_e.g._, if \(q_{*}\) is supported on a compact and lower-dimensional manifold), then \(q_{\delta}^{*}\) will satisfy Assumption 2 if \(\delta>0\). By applying our analysis up to time \(T-\delta\) instead of time \(T\), one can show that a suitable projection of the output distribution is close in Wasserstein distance to \(q_{*}\) (see [13, Corollary 2.4] or [11, Corollary 5]). For brevity, we do not consider this extension of our results here.

### Algorithms

We provide the pseudocode for the two algorithms we consider, _Diffusion Predictor + Overdamped Modeling_ (DPOM) and _Diffusion Predictor + Underdamped Modeling_ (DPUM), in Algorithms 1 and 2 respectively. The only difference between the two algorithms is in the corrector step, which we highlight in Algorithm 2. For simplicity, we take the total amount of time \(T\) to be equal to \(N_{0}/L+h_{\mathsf{pred}}\) for an integer \(N_{0}\geq 1\), and we assume that \(1/L\) is a multiple of \(h_{\mathsf{pred}}\) and that \(h_{\mathsf{pred}}\) is a multiple of \(\delta=\Theta\big{(}\frac{\varepsilon^{2}}{L^{2}(d\sqrt{m_{2}^{2}})}\big{)}\).

We consider two stages: in the first stage, which lasts until time \(N_{0}/L=T-h_{\mathsf{pred}}\), we intersperse predictor epochs (run for time \(1/L\), discretized with step size \(h_{\mathsf{pred}}\)) and corrector epochs (run for time \(\Theta(1/L)\) for the overdamped corrector or for time \(\Theta(1/\sqrt{L})\) for the underdamped corrector, and discretized with step size \(h_{\mathsf{corr}}\)). The second stage lasts from time \(T-h_{\mathsf{pred}}\) to time \(T-\delta\), and we incorporate geometrically decreasing step sizes for the predictor. Note that this implies that our algorithm uses _early stopping_.

``` Input: Total time \(T\), predictor step size \(h_{\mathsf{pred}}\), corrector step size \(h_{\mathsf{corr}}\), score estimates \(s\) Output: Approximate sample from the data distribution \(q_{\star}\)
1 Draw \(\widehat{x}_{0}\sim\gamma^{d}\).
2for\(n=0,1,\ldots,N_{0}-1\)do
3Predictor: Starting from \(\widehat{x}_{n/L}\), run the discretized probability flow ODE (5) from time \(\frac{n}{L}\) to \(\frac{n+1}{L}\) with step size \(h_{\mathsf{pred}}\) and estimated scores to obtain \(\widehat{x}^{\prime}_{(n+1)/L}\).
4Corrector: Starting from \(\widehat{x}^{\prime}_{(n+1)/L}\), run overdamped Langevin Monte Carlo for total time \(\Theta(1/L)\) with step size \(h_{\mathsf{corr}}\) and score estimate \(s_{(n+1)/L}\) to obtain \(\widehat{x}_{(n+1)/L}\).
5Predictor: Starting from \(\widehat{x}_{T-h_{\mathsf{pred}}}\), run the discretized probability flow ODE (5) with step sizes \(h_{\mathsf{pred}}/2,h_{\mathsf{pred}}/4,h_{\mathsf{pred}}/8,\ldots,\delta\) and estimated scores to obtain \(\widehat{x}^{\prime}_{T-\delta}\).
6Corrector: Starting from \(\widehat{x}^{\prime}_{T-\delta}\), run overdamped Langevin Monte Carlo for total time \(\Theta(1/L)\) with step size \(h_{\mathsf{corr}}\) and score estimate \(s_{T-\delta}\) to obtain \(\widehat{x}_{T-\delta}\). return\(\widehat{x}_{T-\delta}\) ```

**Algorithm 1**DPOM(\(T,h_{\mathsf{pred}},h_{\mathsf{corr}},s\))

### Convergence guarantees

Our main results are the following convergence guarantees for the two predictor-corrector schemes described in SS3.2:

**Theorem 2** (Dpm).: _Suppose that Assumptions 1-4 hold. If \(\widehat{q}\) denotes the output of DPOM (Algorithm 1) with \(\delta\asymp\frac{\varepsilon^{2}}{L^{2}\left(d\sqrt{\mathfrak{m}_{2}}\right)}\), then_

\[\mathsf{TV}(\widehat{q},q_{\star})\lesssim(\sqrt{d}\vee\mathfrak{m}_{2})\exp( -T)+L^{2}Td^{1/2}h_{\mathsf{pred}}+L^{3/2}Td^{1/2}h_{\mathsf{corr}}+L^{1/2}T \varepsilon_{\mathsf{sc}}+\varepsilon\,.\] (7)

_In particular, if we set \(T=\Theta\bigl{(}\ln(\frac{d\mathsf{V}\mathfrak{m}_{2}^{2}}{\varepsilon^{2}}) \bigr{)}\), \(h_{\mathsf{pred}}=\widetilde{\Theta}(\frac{\varepsilon}{L^{2}d^{1/2}})\), \(h_{\mathsf{corr}}=\widetilde{\Theta}(\frac{\varepsilon^{2}}{L^{3/2}})\), and if the score estimation error satisfies \(\varepsilon_{\mathsf{sc}}\leq\widetilde{O}(\frac{\varepsilon}{\sqrt{L}})\), then we can obtain TV error \(\varepsilon\) with a total iteration complexity of \(\widetilde{\Theta}(\frac{L^{3}d}{\varepsilon^{2}})\) steps._

The five terms in the bound (7) correspond, respectively, to: the convergence of the forward (OU) process; the discretization error from the predictor steps; the discretization error from the corrector steps; the score estimation error; and the early stopping error.

Theorem 2 recovers nearly the same guarantees as the one in [1, 2, 3], but for the probability flow ODE with overdamped Langevin corrector instead of the reverse SDE without corrector. Recall also from Remark 1 that our results can easily be extended to compactly supported data distributions without smooth score functions. This covers essentially all distributions encountered in practice. Therefore, our result provides compelling theoretical justification complementing the empirical efficacy of the probability flow ODE, which was hitherto absent from the literature.

However, in Theorem 2, the iteration complexity is dominated by the corrector steps. Next, we show that by replacing the overdamped LMC with underdamped LMC, we can achieve a quadratic improvement in the number of steps, considering the dependence on \(d\). As discussed in the Introduction, this highlights the potential benefits of the ODE framework over the SDE.

**Theorem 3** (Dpm).: _Suppose that Assumptions 1-4 hold. If \(\widehat{q}\) denotes the output of DPUM (Algorithm 2) with \(\delta\asymp\frac{\varepsilon^{2}}{L^{2}\left(d\sqrt{\mathfrak{m}_{2}}\right)}\), then_

\[\mathsf{TV}(\widehat{q},q_{\star})\lesssim(\sqrt{d}\vee\mathfrak{m}_{2})\exp (-T)+L^{2}Td^{1/2}h_{\mathsf{pred}}+L^{3/2}Td^{1/2}h_{\mathsf{corr}}+L^{1/2} T\varepsilon_{\mathsf{sc}}+\varepsilon\,.\]

_In particular, if we set \(T=\Theta\bigl{(}\ln(\frac{d\mathsf{V}\mathfrak{m}_{2}^{2}}{\varepsilon^{2}}) \bigr{)}\), \(h_{\mathsf{pred}}=\widetilde{\Theta}(\frac{\varepsilon}{L^{2}d^{1/2}})\), \(h_{\mathsf{corr}}=\widetilde{\Theta}(\frac{\varepsilon}{L^{3/2}d^{1/2}})\), and if the score estimation error satisfies \(\varepsilon_{\mathsf{sc}}\leq\widetilde{O}(\frac{\varepsilon}{\sqrt{L}})\), then we can obtain TV error \(\varepsilon\) with a total iteration complexity of \(\widetilde{\Theta}(\frac{L^{2}d^{1/2}}{\varepsilon})\) steps._

## 4 Proof overview

Here we give a detailed technical overview for the proof of our main results, Theorems 2 and 3. As in [1, 3, 3], the three sources of error that we need to keep track of are (1) estimation of the score function; (2) discretization of time when implementing the probability flow ODE and corrector steps; and (3) initialization of the algorithm at \(\gamma^{d}\) instead of the true law of the end of the forward process, \(q_{0}=q_{T}^{-}\). It turns out that (1) is not so difficult to manage as soon as we can control (2) and (3). Furthermore, as in prior work, we can easily control (3) via the data-processing inequality: the total variation distance between the output of the algorithm initialized at \(q_{0}\) versus at \(\gamma^{d}\) is at most \(\mathsf{TV}(q_{T}^{-},\gamma^{d})\), which is exponentially small in \(T\) by rapid mixing of the OU process. So henceforth in this overview, let us assume that both the algorithm and the true process are initialized at \(q_{0}\). It remains to control (2).

Failure of existing approaches.In the SDE implementation of diffusion models, prior works handled (2) by directly bounding a strictly larger quantity, namely the KL divergence between the laws of the _trajectories_ of the algorithm and the true process; by Girsanov's theorem, this has a clean formulation as an integrated difference of drifts. Unfortunately, in the ODE implementation, this KL divergence is infinite: in the absence of stochasticity in the reverse process, these laws over trajectories are not even absolutely continuous with respect to each other.

In search of an alternative approach, one might try a Wasserstein analysis. As a first attempt, we could couple the initialization of both processes and look at how the distance between them changes over time. If \((\widehat{x}_{t})_{0\leq t\leq T}\) and \((x_{t})_{0\leq t\leq T}\) denote the algorithm and true process, then smoothness of the score function allows us to naively bound \(\partial_{t}\operatorname{\mathbb{E}}[\|\widehat{x}_{t}-x_{t}\|^{2}]\) by \(O(L)\operatorname{\mathbb{E}}[\|\widehat{x}_{t}-x_{t}\|^{2}]\). While this ensures that the processes are close if run for time \(\ll 1/L\), it does not rule out the possibility that they drift apart exponentially quickly after time \(1/L\).

Restarting the coupling--first attempt.What we would like is some way of "restarting" this coupling before the processes drift too far apart, to avoid this exponential compounding. We now motivate how to achieve this by giving an argument that is incorrect but nevertheless captures the intuition for our approach. Namely, let \(p_{t}\coloneqq\mathrm{law}(\widehat{x}_{t})\) denote the law of the algorithm, let \(P^{t_{0},h}_{\text{ODE}}\) denote the result of running the ideal probability flow ODE for time \(h\) starting from time \(t_{0}\), and let \(\widehat{P}^{t_{0},h}_{\text{ODE}}\) denote the same but for the discretized probability flow ODE with estimated score. For \(h\lesssim 1/L\), consider the law of the two processes at time \(2h\), i.e.,

\[p_{2h}=q_{0}\widehat{P}^{0,2h}_{\text{ODE}}\qquad\text{and}\qquad q_{2h}=q_{0} P^{0,2h}_{\text{ODE}}\,.\] (8)

The discussion above implies that \(q_{0}P^{0,h}_{\text{ODE}}\) and \(q_{0}\widehat{P}^{0,h}_{\text{ODE}}\) are close in 2-Wasserstein distance, so by the data-processing inequality, this implies that \(q_{0}P^{0,h}_{\text{ODE}}\widehat{P}^{h,h}_{\text{ODE}}\) and \(q_{0}\widehat{P}^{0,h}_{\text{ODE}}\widehat{P}^{h,h}_{\text{ODE}}\) are also close. To show that \(p_{2h}\) and \(q_{2h}\) in Eq. (8) are close, it thus suffices to show that \(q_{0}P^{0,2h}_{\text{ODE}}\) and \(q_{0}P^{0,h}_{\text{ODE}}\widehat{P}^{h,h}_{\text{ODE}}\) are close. But these two distributions are given by running the algorithm and the true process for time \(h\), both starting from \(q_{0}P^{0,h}_{\text{ODE}}\). So if we "restart" the coupling by coupling the processes based on their locations at time \(h\), rather than time \(0\), of the reverse process, we can again apply the naive Wasserstein analysis.

At this juncture, it would seem that we have miraculously sidestepped the exponential blowup and shown that the expected distance between the processes only increases linearly over time! The issue of course is in the application of the "data-processing inequality," which simply does not hold for the Wasserstein distance.

Restarting the coupling with a corrector step.This is where the corrector comes in. The idea is to use _short-time regularization_: if we apply a small amount of noise to two distributions which are already close in Wasserstein, then they become close in KL divergence, for which a data-processing inequality holds. The upshot is that if the noise doesn't change the distributions too much, then we can legitimately restart the coupling as above and prove that the distance between the processes, now defined by interleaving the probability flow ODE and its discretization with periodic injections of noise, increases only linearly in time.

It turns out that naive injection of noise, e.g., convolution with a Gaussian of small variance, is somewhat wasteful as it fails to preserve the true process and leads to poor polynomial dependence in the dimension. On the other hand, if we instead run the overdamped Langevin diffusion with potential chosen so that the law of the true process is stationary, then we can recover the linear in \(d\) dependence of Theorem 2. Then by replacing overdamped Langevin diffusion with its underdamped counterpart, which has the advantage of much smoother trajectories, we can obtain the desired quadratic speedup in dimension dependence in Theorem 3.

Score perturbation lemma.In addition to the switch from SDE to ODE and the use of the underdamped corrector, a third ingredient is essential to our improved dimension dependence. The former two ensure that the trajectory of our algorithm is smoother than that of DDPMs, so that even over time windows that scale with \(1/\sqrt{d}\), the process does not change too much. By extension, as the score functions are Lipschitz, this means that any fixed score function evaluated over iterates in such a window does not change much. This amounts to controlling discretization error in _space_.

It is also necessary to control discretization error in _time_, i.e., proving what some prior works referred to as a _score perturbation lemma_[14]. That is, for any fixed _iterate_\(x\), we want to show that the score function \(\nabla\ln q_{t}(x)\) does not change too much as \(t\) varies over a small window. Unfortunately, prior works were only able to establish this over windows of length \(1/d\). In this work, we improve this to windows of length \(1/\sqrt{d}\) (see Lemma 3 and Corollary 1).

In our proof, we bound the squared \(L^{2}\) norm of the derivative of the score along the trajectory of the ODE. The score function evaluated at \(y\) can be expressed as \(\mathbb{E}_{P_{0|t}(\cdot|y)}[\nabla U]\); here, the posterior distribution \(P_{0|t}(\cdot\mid y)\) is essentially the prior \(q_{*}\) tilted by a Gaussian of variance \(O(t)\). Hence we need to bound the change in the expectation when we change the distribution from \(P_{0|t}\) to \(P_{0|t+\Delta t}\); because \(\nabla U\) is \(L\)-Lipschitz, we can bound this by the Wasserstein distance between the distributions. For small enough \(t\), \(P_{0|t}\) is strongly log-concave, and a transport cost inequality bounds this in terms of KL divergence, which is more easily bounded. Indeed, we can bound it with the KL divergence between the joint distributions \(P_{0,t}\) and \(P_{0,t+\Delta t}\), which reduces to bounding the KL divergence between Gaussians of unequal variance.

However, since our score perturbation lemma degrades near the beginning of the forward process, we require better control of the discretization error during this part of the algorithm, hence leading to our choice of geometrically decreasing step sizes. Alternatively, we could use a two-stage step size schedule, see Remark 4.

## 5 Conclusion

In this work, we have provided the first polynomial-time guarantees for the probability flow ODE implementation of SGMs with corrector steps and exhibited improved dimension dependence of the ODE framework over prior results for DDPMs (_i.e.,_ the SDE framework). Our analysis raises questions relevant for practice, of which we list a few.

* Although we need the corrector steps for our proof, are they in fact necessary for the algorithm to work efficiently in practice?
* Is it possible to obtain even better dimension dependence, perhaps using higher-order solvers and stronger smoothness assumptions?
* Can we obtain improved dimension dependence even in the non-smooth setting, compared to the result of [1]?

We also list several limitations of our work, namely:

* Our analysis only covers the probability flow ODE corresponding to the OU forward process. We leave the study of more general dynamics for future study.
* Our guarantees require the score function to be learned to \(L^{2}\) accuracy \(\widetilde{O}(\varepsilon/\sqrt{L})\), which is more stringent than the prior works [1, 1, 2] and may be an technical artefact of our proof.
* We have not validated our theoretical findings with large-scale experiments. In particular, it is still unclear whether flow-based methods can outperform the standard DDPM algorithm in practical, high dimensional settings.

## 6 Acknowledgments

We want to thank Yin Tat Lee for his valuable comments, shaping the direction of this research project in its early stages. SC was supported by NSF Award 2103300 for part of this work.

## References

* [ABV23] M. S. Albergo, N. M. Boffi, and E. Vanden-Eijnden. "Stochastic interpolants: a unifying framework for flows and diffusions". In: _arXiv preprint 2303.08797_ (2023).
* [AGS08] L. Ambrosio, N. Gigli, and G. Savare. _Gradient flows in metric spaces and in the space of probability measures_. Second. Lectures in Mathematics ETH Zurich. Birkhauser Verlag, Basel, 2008, pp. x+334.
* [Aus+21] J. Austin, D. D. Johnson, J. Ho, D. Tarlow, and R. van den Berg. "Structured denoising diffusion models in discrete state-spaces". In: _Advances in Neural Information Processing Systems_. Ed. by M. Ranzato, A. Beygelzimer, Y. Dauphin, P. Liang, and J. W. Vaughan. Vol. 34. Curran Associates, Inc., 2021, pp. 17981-17993.
* [BDD23] J. Benton, G. Deligiannidis, and A. Doucet. "Error bounds for flow matching methods". In: _arXiv preprint 2305.16860_ (2023).
* [BGL01] S. G. Bobkov, I. Gentil, and M. Ledoux. "Hypercontractivity of Hamilton-Jacobi equations". In: _Journal de Mathematiques Pures et Appliquees_ 80.7 (2001), pp. 669-696.
* [BMR22] A. Block, Y. Mroueh, and A. Rakhlin. "Generative modeling with denoising auto-encoders and Langevin sampling". In: _arXiv preprint 2002.00107_ (2022).
* [BV23] N. M. Boffi and E. Vanden-Eijnden. "Probability flow solution of the Fokker-Planck equation". In: _Machine Learning: Science and Technology_ 4.3 (July 2023), p. 035012.

* [CDD23] S. Chen, G. Daras, and A. Dimakis. "Restoration-degradation beyond linear diffusions: a non-asymptotic analysis for DDIM-type samplers". In: _Proceedings of the 40th International Conference on Machine Learning_. Ed. by A. Krause, E. Brunskill, K. Cho, B. Engelhardt, S. Sabato, and J. Scarlett. Vol. 202. Proceedings of Machine Learning Research. PMLR, July 2023, pp. 4462-4484.
* [CE22] Y. Chen and R. Eldan. "Localization schemes: a framework for proving mixing bounds for Markov chains". In: _arXiv preprint 2203.04163_ (2022).
* [Che+22] Y. Chen, S. Chewi, A. Salim, and A. Wibisono. "Improved analysis for a proximal algorithm for sampling". In: _Proceedings of Thirty Fifth Conference on Learning Theory_. Ed. by P.-L. Loh and M. Raginsky. Vol. 178. Proceedings of Machine Learning Research. PMLR, July 2022, pp. 2984-3014.
* [Che+23a] S. Chen, S. Chewi, J. Li, Y. Li, A. Salim, and A. R. Zhang. "Sampling is as easy as learning the score: theory for diffusion models with minimal data assumptions". In: _The Eleventh International Conference on Learning Representations_. 2023.
* [Che+23b] Y. Chen, W. Deng, S. Fang, F. Li, N. T. Yang, Y. Zhang, K. Rasul, S. Zhe, A. Schneider, and Y. Nevmyvaka. "Provably convergent Schrodinger bridge with applications to probabilistic time series imputation". In: _Proceedings of the 40th International Conference on Machine Learning_. Ed. by A. Krause, E. Brunskill, K. Cho, B. Engelhardt, S. Sabato, and J. Scarlett. Vol. 202. Proceedings of Machine Learning Research. PMLR, July 2023, pp. 4485-4513.
* [Che22] S. Chewi. _Log-concave sampling_. Book draft available at https://chewisinho.github.io/. 2022.
* [CLL23] H. Chen, H. Lee, and J. Lu. "Improved analysis of score-based generative modeling: user-friendly bounds under minimal smoothness assumptions". In: _Proceedings of the 40th International Conference on Machine Learning_. Ed. by A. Krause, E. Brunskill, K. Cho, B. Engelhardt, S. Sabato, and J. Scarlett. Vol. 202. Proceedings of Machine Learning Research. PMLR, July 2023, pp. 4735-4763.
* [CSY22] H. Chung, B. Sim, and J. Ye. "Come-closer-diffuse-faster: accelerating conditional diffusion models for inverse problems through stochastic contraction". In: _2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)_. Los Alamitos, CA, USA: IEEE Computer Society, June 2022, pp. 12403-12412.
* [De +21] V. De Bortoli, J. Thornton, J. Heng, and A. Doucet. "Diffusion Schrodinger bridge with applications to score-based generative modeling". In: _Advances in Neural Information Processing Systems_. Ed. by M. Ranzato, A. Beygelzimer, Y. Dauphin, P. Liang, and J. W. Vaughan. Vol. 34. Curran Associates, Inc., 2021, pp. 17695-17709.
* [De 22] V. De Bortoli. "Convergence of denoising diffusion models under the manifold hypothesis". In: _Transactions on Machine Learning Research_ (2022).
* [DN21] P. Dhariwal and A. Nichol. "Diffusion models beat GANs on image synthesis". In: _Advances in Neural Information Processing Systems_. Ed. by M. Ranzato, A. Beygelzimer, Y. Dauphin, P. Liang, and J. W. Vaughan. Vol. 34. Curran Associates, Inc., 2021, pp. 8780-8794.
* [EMS22] A. El Alaoui, A. Montanari, and M. Sellke. "Sampling from the Sherrington-Kirkpatrick Gibbs measure via algorithmic stochastic localization". In: _2022 IEEE 63rd Annual Symposium on Foundations of Computer Science--FOCS 2022_. IEEE Computer Soc., Los Alamitos, CA, 2022, pp. 323-334.
* [FYC23] J. Fan, B. Yuan, and Y. Chen. "Improved dimension dependence of a proximal algorithm for sampling". In: _Proceedings of Thirty Sixth Conference on Learning Theory_. Ed. by G. Neu and L. Rosasco. Vol. 195. Proceedings of Machine Learning Research. PMLR, July 2023, pp. 1473-1521.
* [Gna+22] D. Gnaneshwar, B. Ramsundar, D. Gandhi, R. Kurchin, and V. Viswanathan. "Score-based generative models for molecule generation". In: _arXiv preprint 2203.04698_ (2022).
* [GW12] A. Guillin and F.-Y. Wang. "Degenerate Fokker-Planck equations: Bismut formula, gradient estimate and Harnack inequality". In: _Journal of Differential Equations 253.1_ (2012), pp. 20-40.
* [HJA20] J. Ho, A. Jain, and P. Abbeel. "Denoising diffusion probabilistic models". In: _Advances in Neural Information Processing Systems_ 33 (2020), pp. 6840-6851.

* [Hyv05] A. Hyvarinen. "Estimation of non-normalized statistical models by score matching". In: _J. Mach. Learn. Res._ 6 (2005), pp. 695-709.
* [JKO98] R. Jordan, D. Kinderlehrer, and F. Otto. "The variational formulation of the Fokker-Planck equation". In: _SIAM J. Math. Anal._ 29.1 (1998), pp. 1-17.
* [JP22] A. Jain and B. Poole. "Journey to the BAOAB-limit: finding effective MCMC samplers for score-based models". In: _NeurIPS 2022 Workshop on Score-Based Methods_. 2022.
* [Kin+21] D. Kingma, T. Salimans, B. Poole, and J. Ho. "Variational diffusion models". In: _Advances in Neural Information Processing Systems_. Ed. by M. Ranzato, A. Beygelzimer, Y. Dauphin, P. Liang, and J. W. Vaughan. Vol. 34. Curran Associates, Inc., 2021, pp. 21696-21707.
* [LC22] J. Liang and Y. Chen. "A proximal algorithm for sampling from non-smooth potentials". In: _arXiv preprint 2110.04597_ (2022).
* [LC23] J. Liang and Y. Chen. "A proximal algorithm for sampling". In: _Transactions on Machine Learning Research_ (2023).
* [Li+23] G. Li, Y. Wei, Y. Chen, and Y. Chi. "Towards faster non-asymptotic convergence for diffusion-based generative models". In: _arXiv preprint 2306.09251_ (2023).
* [Liu+22] X. Liu, L. Wu, M. Ye, and Q. Liu. "Let us build bridges: understanding and extending diffusion generative models". In: _arXiv preprint arXiv:2208.14699_ (2022).
* [LLT22] H. Lee, J. Lu, and Y. Tan. "Convergence for score-based generative modeling with polynomial complexity". In: _Advances in Neural Information Processing Systems_. Ed. by A. H. Oh, A. Agarwal, D. Belgrave, and K. Cho. 2022.
* [LLT23] H. Lee, J. Lu, and Y. Tan. "Convergence of score-based generative modeling for general data distributions". In: _Proceedings of the 34th International Conference on Algorithmic Learning Theory_. Ed. by S. Agrawal and F. Orabona. Vol. 201. Proceedings of Machine Learning Research. PMLR, Feb. 2023, pp. 946-985.
* [LST21] Y. T. Lee, R. Shen, and K. Tian. "Structured logconcave sampling with a restricted Gaussian oracle". In: _Proceedings of Thirty Fourth Conference on Learning Theory_. Ed. by M. Belkin and S. Kpotufe. Vol. 134. Proceedings of Machine Learning Research. PMLR, Aug. 2021, pp. 2993-3050.
* [Lu+22] C. Lu, Y. Zhou, F. Bao, J. Chen, C. Li, and J. Zhu. "DPM-Solver: a fast ODE solver for diffusion probabilistic model sampling in around 10 steps". In: _Advances in Neural Information Processing Systems_. Ed. by S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh. Vol. 35. Curran Associates, Inc., 2022, pp. 5775-5787.
* [MW23] A. Montanari and Y. Wu. "Posterior sampling from the spiked models via diffusion processes". In: _arXiv preprint 2304.11449_ (2023).
* [Pid22] J. Pidstrigach. "Score-based generative models detect manifolds". In: _Advances in Neural Information Processing Systems_. Ed. by S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh. Vol. 35. Curran Associates, Inc., 2022, pp. 35852-35865.
* [PMM23] F. Pedrotti, J. Maas, and M. Mondelli. "Improved convergence of score-based diffusion models via prediction-correction". In: _arXiv preprint 2305.14164_ (2023).
* [Ram+22] A. Ramesh, P. Dhariwal, A. Nichol, C. Chu, and M. Chen. "Hierarchical text-conditional image generation with CLIP latents". In: _arXiv preprint arXiv:2204.06125_ (2022).
* [Rom+22] R. Rombach, A. Blattmann, D. Lorenz, P. Esser, and B. Ommer. "High-resolution image synthesis with latent diffusion models". In: _2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)_. Los Alamitos, CA, USA: IEEE Computer Society, June 2022, pp. 10674-10685.
* [San15] F. Santambrogio. _Optimal transport for applied mathematicians_. Vol. 87. Progress in Nonlinear Differential Equations and their Applications. Calculus of variations, PDEs, and modeling. Birkhauser/Springer, Cham, 2015, pp. xxvii+353.
* [SE19] Y. Song and S. Ermon. "Generative modeling by estimating gradients of the data distribution". In: _Advances in Neural Information Processing Systems_. Ed. by H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alche-Buc, E. Fox, and R. Garnett. Vol. 32. Curran Associates, Inc., 2019.

* [Shi+21] C. Shi, S. Luo, M. Xu, and J. Tang. "Learning gradient fields for molecular conformation generation". In: _Proceedings of the 38th International Conference on Machine Learning_. Ed. by M. Meila and T. Zhang. Vol. 139. Proceedings of Machine Learning Research. PMLR, July 2021, pp. 9558-9568.
* [Soh+15] J. Sohl-Dickstein, E. Weiss, N. Maheswaranathan, and S. Ganguli. "Deep unsupervised learning using nonequilibrium thermodynamics". In: _Proceedings of the 32nd International Conference on Machine Learning_. Ed. by F. Bach and D. Blei. Vol. 37. Proceedings of Machine Learning Research. Lille, France: PMLR, July 2015, pp. 2256-2265.
* [Son+21a] Y. Song, C. Durkan, I. Murray, and S. Ermon. "Maximum likelihood training of score-based diffusion models". In: _Advances in Neural Information Processing Systems_. Ed. by M. Ranzato, A. Beygelzimer, Y. Dauphin, P. Liang, and J. W. Vaughan. Vol. 34. Curran Associates, Inc., 2021, pp. 1415-1428.
* [Son+21b] Y. Song, J. Sohl-Dickstein, D. P. Kingma, A. Kumar, S. Ermon, and B. Poole. "Score-based generative modeling through stochastic differential equations". In: _International Conference on Learning Representations_. 2021.
* [Son+22] Y. Song, L. Shen, L. Xing, and S. Ermon. "Solving inverse problems in medical imaging with score-based generative models". In: _International Conference on Learning Representations_. 2022.
* [TP18] M. K. Titsias and O. Papaspiliopoulos. "Auxiliary gradient-based sampling algorithms". In: _J. R. Stat. Soc. Ser. B. Stat. Methodol._ 80.4 (2018), pp. 749-767.
* [Vin11] P. Vincent. "A connection between score matching and denoising autoencoders". In: _Neural Comput._ 23.7 (2011), pp. 1661-1674.
* [VKK21] A. Vahdat, K. Kreis, and J. Kautz. "Score-based generative modeling in latent space". In: _Advances in Neural Information Processing Systems_. Ed. by M. Ranzato, A. Beygelzimer, Y. Dauphin, P. Liang, and J. W. Vaughan. Vol. 34. Curran Associates, Inc., 2021, pp. 11287-11302.
* [WHZ23] Z. Wang, J. J. Hunt, and M. Zhou. "Diffusion policies as an expressive policy class for offline reinforcement learning". In: _The Eleventh International Conference on Learning Representations_. 2023.
* [WY22] A. Wibisono and K. Y. Yang. "Convergence in KL divergence of the inexact Langevin algorithm with application to score-based generative models". In: _arXiv preprint 2211.01512_ (2022).
* [ZC23] Q. Zhang and Y. Chen. "Fast sampling of diffusion models with exponential integrator". In: _The Eleventh International Conference on Learning Representations_. 2023.

Notation and overview

In this section, we collect together the notation used throughout the proofs and provide a road map for the end-to-end analysis in SSE.

Throughout the analysis, Assumptions 1-4 are in full force.

We will reserve \(q\) for the law of the reverse process (and denote the forward process by \(q^{\rightarrow}\) when needed). In SSE, the law of the algorithm is denoted by \(p\).

We use the following Markov kernels:

1. \(P_{\mathsf{ODE}}^{t,h}\) is the output of running the ODE for time \(h\), starting at (reverse) time \(t\).
2. \(P_{\mathsf{LD}}\) (resp. \(P_{\mathsf{ULD}}\)) is the output of running the continuous-time overdamped (resp. underdamped) Langevin diffusion for time \(h\). In this notation, we have suppressed mention of the stationary distributions of the diffusion, which will be provided by context.
3. \(\widehat{P}_{\mathsf{ODE}}^{t,h}\) and \(\widehat{P}_{\mathsf{LMC}}\) (resp. \(\widehat{P}_{\mathsf{ULMC}}\)) are the corresponding processes once discretized and using the estimated score.

For the ODE, we are more precise with the notation because even within a single epoch of predictor steps, the kernel for the probability flow ODE depends on time (as opposed to the kernels for the diffusions, which are constant within any epoch of corrector steps); moreover, for our analysis in SSE, we also need to take time-varying step sizes for the predictor steps. We will omit the dependencies on \(t\) and \(h\) when clear from context. When \(P=P_{\mathsf{ODE}}\) or \(\widehat{P}_{\mathsf{ODE}}\), we use \(P^{t,h_{1},\ldots,h_{N}}\) to denote \(P^{t,h_{1}}P^{t+h_{1},h_{2}}\ldots P^{t+h_{1}+\cdots+h_{N-1},h_{N}}\) (we compose kernels on the right).

We refer to SS4 for a high-level description of the proof strategy. We begin in SSB with our improved score perturbation lemma (Corollary 1); this is the only section of the analysis which is indexed by _forward_ time (instead of reverse time). In Lemma 5 in SSC, we establish our main result for the predictor steps, which combines together standard ODE discretization analysis with the score perturbation lemma of SSB. Since Corollary 1 degrades near the end of the reverse process (or equivalently, near the start of the forward process, when the regularization has not yet kicked in), our analysis requires a geometrically decreasing step size schedule, which leads to the two-stage Algorithms 1 and 2.

In SSD, we prove our main regularization results for the overdamped corrector (Theorem 4) and the underdamped corrector (Theorem 5). Finally, we put together the various constituent results in the end-to-end analysis in SSE.

## Appendix B Score perturbation

In this section, we prove a score perturbation lemma which refines that of [11]. This improved lemma is necessary in order to obtain \(O(\sqrt{d})\) dependence for the probability flow ODE.

**Lemma 1** (Score perturbation).: _Suppose \(p_{t}=p_{0}*\mathcal{N}(0,tI)\) and \(x_{0}\sim p_{0}\), \(\dot{x}_{t}=-\frac{1}{2}\,\nabla\ln p_{t}(x_{t})\). Suppose that \(\|\nabla^{2}\ln p_{(t-\frac{1}{2L})\lor 0}(x)\|_{\mathsf{op}}\leq L\) for all \(x\). Then_

\[\mathbb{E}[\|\partial_{t}\nabla\ln p_{t}(x_{t})\|^{2}]\leq L^{2}d\left(L+ \frac{1}{t}\right).\]

Proof.: Without loss of generality, we may assume \(t\leq\frac{1}{2L}\), as otherwise, noting that \(p_{t}=p_{t-\frac{1}{2L}}*N(0,\frac{1}{2L}I)\), we may replace \(p_{0}\) with \(p_{t-\frac{1}{2L}}\) and \(t\) with \(\frac{1}{2L}\). Suppose \(p_{0}(x)=e^{-V(x)}\). Let \(P_{0,t}\) denote the joint distribution of \((X_{0},X_{t})\) where \(X_{t}=X_{0}+\sqrt{t}\,Z\) with \(Z\sim\mathcal{N}(0,I)\) independent of \(X_{0}\), and let \(P_{0|t}(\cdot\mid x_{t})\) denote the conditional distribution of \(X_{0}\) given \(X_{t}=x_{t}\). We first note that since

\[\ln p_{t}(y)=\ln\int\exp\bigl{(}-V(x)-\frac{1}{2t}\,\|y-x\|^{2}\bigr{)}\, \mathrm{d}x\,,\]

we have the following calculations:

\[\nabla\ln p_{t}(y)=-\frac{1}{t}\,\mathbb{E}_{P_{0|t}(\cdot\mid y)}(y-\cdot)=- \,\mathbb{E}_{P_{0|t}(\cdot\mid y)}(\nabla V)\,,\]\[\nabla^{2}\ln p_{t}(y)=\operatorname{Cov}_{P_{0|t}(\cdot|y)}(\nabla V)-\mathbb{E}_{P _{0|t}(\cdot|y)}(\nabla^{2}V)\,.\]

Using \(\dot{x}_{t}=-\frac{1}{2}\,\nabla\ln p_{t}(x_{t})\), we calculate

\[\partial_{t}\nabla\ln p_{t}(x_{t})=[\partial_{t}\nabla\ln p_{t}(y)]|_{y=x_{t}} -\frac{1}{2}\,\nabla^{2}\ln p_{t}(x_{t})\,\nabla\ln p_{t}(x_{t})\,.\] (9)

We bound each term above separately. For the first term, a quick calculation shows that \(\partial_{t}\nabla\ln p_{t}(y)=-\operatorname{Cov}_{P_{0|t}(\cdot|y)}\bigl{(} \frac{\|y-\cdot\|^{2}}{2t^{2}},\nabla V\bigr{)}\) is finite a.s.: by Cauchy-Schwarz, it suffices to show \(\mathbb{E}_{P_{0|t}(\cdot|y)}[\|y-\cdot\|^{4}]\) and \(\mathbb{E}_{P_{0|t}(\cdot|y)}[\|\nabla V\|^{2}]\) are finite for all \(y\), and this follows because for \(t\leq\frac{1}{2L}\) the measure \(P_{0|t}(\cdot\mid y)\) is strongly log-concave and \(\|\nabla V\|^{2}\) can be bounded by a quadratic. Because \(\nabla V\) is \(L\)-Lipschitz,

\[\|[\partial_{t}\nabla\ln p_{t}(y)]|_{y=x_{t}}\|^{2} =\|[\partial_{t}\,\mathbb{E}_{P_{0|t}(\cdot|y)}(\nabla V)]|_{y=x_ {t}}\|^{2}\] \[=\Bigl{\|}\lim_{\Delta t\to 0}\frac{1}{\Delta t}\,\bigl{[} \mathbb{E}_{P_{0|t+\Delta t}(\cdot|y)}[\nabla V]-\mathbb{E}_{P_{0|t}(\cdot|y) }[\nabla V]\bigr{]}\bigr{|}_{y=x_{t}}\Bigr{\|}^{2}\] \[\leq L^{2}\liminf_{\Delta t\to 0}\frac{1}{(\Delta t)^{2}}\,W_{1}^{ 2}\bigl{(}P_{0|t+\Delta t}(\cdot\mid x_{t}),P_{0|t}(\cdot\mid x_{t})\bigr{)}\,.\] (10)

Now \(P_{0|t}(\cdot\mid y)\) has density \(p_{0|t}(x\mid y)\propto p_{0}(x)\,e^{-\frac{1-x-y\|^{2}}{2t}}\) so if \(\|\nabla^{2}\ln p_{0}\|_{\mathsf{op}}\leq L\) and \(t\leq\frac{1}{2L}\), then \(P_{0|t}\) is \(\frac{1}{2t}\)-strongly log-concave. By Talagrand's transport cost inequality,

\[W_{1}^{2}\bigl{(}P_{0|t+\Delta t}(\cdot\mid x_{t}),P_{0|t}(\cdot\mid x_{t}) \bigr{)}\leq 4t\,\mathsf{KL}\bigl{(}P_{0|t+\Delta t}(\cdot\mid x_{t})\,\bigr{\|} \,P_{0|t}(\cdot\mid x_{t})\bigr{)}\,.\]

Plugging this back in (10) and using Fatou's lemma and the chain rule for KL,

\[\mathbb{E}[\|[\partial_{t}\nabla\ln p_{t}(y)]|_{y=x_{t}}\|^{2}] \leq L^{2}\,\mathbb{E}\liminf_{\Delta t\to 0}\frac{1}{(\Delta t)^{2}} \,4t\,\mathsf{KL}\bigl{(}P_{0|t+\Delta t}(\cdot\mid x_{t})\,\bigr{\|}\,P_{0|t }(\cdot\mid x_{t})\bigr{)}\] \[\leq L^{2}\liminf_{\Delta t\to 0}\frac{1}{(\Delta t)^{2}} \,4t\,\mathsf{KL}\bigl{(}P_{0|t+\Delta t}(\cdot\mid x_{t})\,\bigr{\|}\,P_{0|t }(\cdot\mid x_{t})\bigr{)}\] \[\leq L^{2}\liminf_{\Delta t\to 0}\frac{1}{(\Delta t)^{2}} \,4t\,\mathsf{KL}(P_{0,t+\Delta t}\,\|\,P_{0,t})\,.\] (11)

Now

\[\mathsf{KL}(P_{0,t+\Delta t}\,\|\,P_{0,t}) =\mathbb{E}_{x\sim P_{0}}\,\mathsf{KL}\bigl{(}P_{t+\Delta t|0}( \cdot\mid x),P_{t|0}(\cdot\mid x)\bigr{)}=\mathsf{KL}\bigl{(}\mathcal{N}(0,(t+ \Delta t)I)\,\big{\|}\,\mathcal{N}(0,tI)\bigr{)}\] \[=\frac{d}{2}\,\Bigl{(}-\ln\frac{t+\Delta t}{t}+\frac{t+\Delta t}{ t}-1\Bigr{)}=\frac{d}{4}\,\bigl{(}\frac{\Delta t}{t}\bigr{)}^{2}+O\Bigl{(} \bigl{(}\frac{\Delta t}{t}\bigr{)}^{3}\Bigr{)}\,.\]

Plugging into (11) gives

\[\mathbb{E}[\|[\partial_{t}\nabla\ln p_{t}(y)]|_{y=x_{t}}\|^{2}]\leq\frac{L^{2} d}{t}\,.\] (12)

For the second term, by assumption we have \(\|\nabla^{2}\ln p_{t}\|_{\mathsf{op}}\leq L\). Then, since \(x_{t}\sim p_{t}\),

\[\mathbb{E}[\|\nabla^{2}\ln p_{t}(x_{t})\,\nabla\ln p_{t}(x_{t})\|^{2}]\leq L^{ 2}\,\mathbb{E}_{p_{t}}[\|\nabla\ln p_{t}\|^{2}]\leq L^{3}d\] (13)

using the fact \(\mathbb{E}_{\mu}[\|\nabla\ln\mu\|^{2}]\leq Ld\) for any measure \(\mu\) such that \(\ln\mu\) is \(L\)-smooth, which follows from integration by parts. From (9), (12), and (13), and the elementary inequality \(\langle a,b\rangle\leq\|a\|^{2}+4\,\|b\|^{2}\), we get

\[\mathbb{E}[\|\partial_{t}\nabla\ln p_{t}(x_{t})\|^{2}] \leq\mathbb{E}[\|[\partial_{t}\nabla\ln p_{t}(y)]|_{y=x_{t}}\|^{2}] +\mathbb{E}[\|\nabla^{2}\ln p_{t}(x_{t})\,\nabla\ln p_{t}(x_{t})\|^{2}]\] \[\leq L^{2}d\,\bigl{(}L+\frac{1}{t}\bigr{)}\,.\qed\]

The above result holds for the dynamics \(\dot{x}_{t}=-\frac{1}{2}\,\nabla\ln p_{t}(x_{t})\) for which \(\left(p_{t}\right)_{t\geq 0}\) follows the heat flow; this corresponds to the variance-exploding SGM. In this paper, since we wish to consider the SGM based on the variance-conserving Ornstein-Uhlenbeck (OU) process, we can apply the following reparameterization lemma.

**Lemma 2** (Reparameterization).: _Suppose that \(\left(x_{t}\right)_{t\geq 0}\) satisfies the probability flow ODE for Brownian motion starting at \(p_{0}\); that is, letting \(p_{t}=p_{0}*\mathcal{N}(0,tI)\), we have \(x_{0}\sim p_{0}\), \(\dot{x}_{t}=-\frac{1}{2}\,\nabla\ln p_{t}(x_{t})\). Then, if we set_

\[y_{t}=e^{-t}\,x_{e^{2t}-1}\,,\]

_then \(\left(y_{t}\right)_{t\geq 0}\) satisfies the probability flow ODE for the OU process starting at \(p_{0}\); that is, letting \(q_{t}^{\rightarrow}\) be the density of the OU process at time \(t\), we have \(y_{0}\sim p_{0}=q_{0}^{\rightarrow}\), \(\dot{y}_{t}=-y_{t}-\nabla\ln q_{t}^{\rightarrow}(y_{t})\)._

Proof.: By direct calculation, one can check that for any \(y\in\mathbb{R}^{d}\), it holds that \(q_{t}^{\rightarrow}(y)\propto p_{e^{2t}-1}(e^{t}y)\). The claim follows from the chain rule. 

**Lemma 3** (Score perturbation for OU).: _Suppose \(q_{t}^{\rightarrow}\) is the density of the OU process at time \(t\), started at \(q_{0}^{\rightarrow}\), and \(y_{0}\sim q_{0}^{\rightarrow}\), \(\dot{y}_{t}=-y_{t}-\nabla\ln q_{t}^{\rightarrow}(y_{t})\). Suppose for all \(t\) and all \(x\) that \(\|\nabla^{2}\ln q_{t}^{\rightarrow}(x)\|_{\mathsf{op}}\leq L\), where \(L\geq 1\). Then,_

\[\mathbb{E}[\|\partial_{t}\nabla\ln q_{t}^{\rightarrow}(y_{t})\|^{2}]\lesssim L ^{2}d\left(L\vee\frac{1}{t}\right).\]

Proof.: Using the relationship \(q_{t}^{\rightarrow}(y)\propto p_{e^{2t}-1}(e^{t}y)\),

\[\nabla\ln q_{t}^{\rightarrow}(y) =e^{t}\,\nabla\ln p_{e^{2t}-1}(e^{t}y)\,,\] \[\partial_{t}\nabla\ln q_{t}^{\rightarrow}(y_{t}) =\underbrace{e^{t}\,\nabla\ln p_{e^{2t}-1}(x_{e^{2t}-1})}_{=:A}+ \underbrace{e^{t}\,\partial_{s}\nabla\ln p_{s}(x_{s})|_{s=e^{2t}-1}\cdot 2e^{2t }}_{=:B}\,.\]

If \(\|\nabla^{2}\ln q_{t}^{\rightarrow}\|_{\mathsf{op}}\leq L\), then \(\|\nabla^{2}\ln p_{e^{2t}-1}\|_{\mathsf{op}}\leq e^{-2t}L\). By Lemma 1,

\[\mathbb{E}[\|\partial_{s}\nabla\ln p_{s}(x_{s})|_{s=e^{2t}-1}\|^{2}]\lesssim e ^{-4t}L^{2}d\left(e^{-2t}L\vee\frac{1}{e^{2t}-1}\right).\]

Hence

\[\mathbb{E}[B^{2}]\lesssim L^{2}d\left(L\vee\frac{1}{t}\right).\]

Next,

\[\mathbb{E}[A^{2}]\leq e^{2t}\,\mathbb{E}[\|\nabla\ln p_{e^{2t}-1}(x_{e^{2t}-1 })\|^{2}]\leq e^{2t}\,e^{-2t}Ld\leq Ld\,.\]

The result follows. 

Finally, we use Lemma 3 to derive a bound on how much the score changes along the trajectory of the probability flow ODE.

**Corollary 1**.: _Consider the setting of Lemma 3, and suppose \(0<s<t\), \(h=t-s\)._

1. _If_ \(s,t\gtrsim 1/L\)_, then_ \[\mathbb{E}\big{[}\|\nabla\ln q_{t}^{\rightarrow}(x_{t})-\nabla\ln q_{s}^{ \rightarrow}(x_{s})\|^{2}\big{]}\lesssim L^{3}dh^{2}\,.\]
2. _If_ \(\frac{t}{2}\leq s\leq t\lesssim\frac{1}{L}\)_, then_ \[\mathbb{E}\big{[}\|\nabla\ln q_{t}^{\rightarrow}(x_{t})-\nabla\ln q_{s}^{ \rightarrow}(x_{s})\|^{2}\big{]}\lesssim\frac{L^{2}dh^{2}}{t}\,.\]

Proof.: By Lemma 3,

\[\mathbb{E}\big{[}\|\nabla\ln q_{t}^{\rightarrow}(x_{t})-\nabla \ln q_{s}^{\rightarrow}(x_{s})\|^{2}\big{]} =\mathbb{E}\Big{[}\Big{\|}\int_{s}^{t}\partial_{u}\nabla\ln q_{u} ^{\rightarrow}(x_{u})\,\mathrm{d}u\Big{\|}^{2}\Big{]}\] \[\leq(t-s)\int_{s}^{t}\mathbb{E}[\|\partial_{u}\nabla\ln q_{u}^{ \rightarrow}(x_{u})\|^{2}]\,\mathrm{d}u\] \[\lesssim h\int_{s}^{t}L^{2}d\max\bigl{\{}L,\frac{1}{u}\bigr{\}} \,\mathrm{d}u\,.\]

In the first case, this is bounded by \(O(L^{3}dh^{2})\). In the second case, this is bounded by \(O(L^{2}dh\int_{s}^{t}\frac{1}{u}\,\mathrm{d}u)=O(L^{2}dh\ln(t/s))=O(L^{2}dh^{2}/t)\)Predictor step

Next, we need an ODE discretization analysis.

**Lemma 4**.: _Suppose the score function satisfies Assumption 2. Assume that \(L\geq 1\), \(h\lesssim 1/L\), and \(T-(t_{0}+h)\geq\frac{T-t_{0}}{2}\). Then_

\[W_{2}(qP_{\mathsf{ODE}}^{t_{0},h},q\widehat{P}_{\mathsf{ODE}}^{t_{0},h}) \lesssim Ld^{1/2}h^{2}\left(L^{1/2}\vee\frac{1}{\left(T-t_{0}\right)^{1/2}} \right)+h\varepsilon_{\mathbf{sc}}\,.\]

Proof.: We have the ODEs

\[\dot{x}_{t} =x_{t}+\nabla\ln q_{t}(x_{t})\,,\] \[\dot{\widehat{x}}_{t} =\widehat{x}_{t}+s_{t_{0}}(\widehat{x}_{t_{0}})\,,\]

for \(t_{0}\leq t\leq t_{0}+h\), with \(x_{t_{0}}=\widehat{x}_{t_{0}}\sim q\), \(x_{t_{0}+h}\sim qP_{\mathsf{ODE}}\), and \(\widehat{x}_{t_{0}+h}\sim q\widehat{P}_{\mathsf{ODE}}\). Then,

\[\partial_{t}\|x_{t}-\widehat{x}_{t}\|^{2} =2\left\langle x_{t}-\widehat{x}_{t},\dot{x}_{t}-\dot{\widehat{x }}_{t}\right\rangle\] \[=2\left(\|x_{t}-\widehat{x}_{t}\|^{2}+\langle x_{t}-\widehat{x}_ {t},\nabla\ln q_{t}(x_{t})+s_{t_{0}}(\widehat{x}_{t_{0}})\rangle\right)\] \[\leq\left(2+\frac{1}{h}\right)\|x_{t}-\widehat{x}_{t}\|^{2}+h\, \|\nabla\ln q_{t}(x_{t})-s_{t_{0}}(\widehat{x}_{t_{0}})\|^{2}\,.\]

By Gronwall's inequality, noting that \(h=O(1)\),

\[\mathbb{E}[\|x_{t_{0}+h}-\widehat{x}_{t_{0}+h}\|^{2}] \leq\exp\bigl{(}\bigl{(}2+\frac{1}{h}\bigr{)}\,h\bigr{)}\int_{t_ {0}}^{t_{0}+h}h\,\mathbb{E}[\|\nabla\ln q_{t}(x_{t})-s_{t_{0}}(\widehat{x}_{t _{0}})\|^{2}]\,\mathrm{d}t\] \[\lesssim h\int_{t_{0}}^{t_{0}+h}\mathbb{E}[\|\nabla\ln q_{t}(x_{t })-s_{t_{0}}(\widehat{x}_{t_{0}})\|^{2}]\,\mathrm{d}t\,.\] (14)

We split up the error term as

\[\|\nabla\ln q_{t}(x_{t})-s_{t_{0}}(\widehat{x}_{t_{0}})\|^{2} \lesssim\|\nabla\ln q_{t}(x_{t})-\nabla\ln q_{t_{0}}(x_{t_{0}})\|^{2}+\| \nabla\ln q_{t_{0}}(x_{t_{0}})-s_{t_{0}}(\widehat{x}_{t_{0}})\|^{2}\,.\]

By Corollary 1, the expectation of the first term is bounded by

\[\mathbb{E}[\|\nabla\ln q_{t}(x_{t})-\nabla\ln q_{t_{0}}(x_{t_{0}})\|^{2}] \lesssim L^{2}dh^{2}\left(L\vee\frac{1}{T-t_{0}}\right).\]

The second term is bounded in expectation by \(\varepsilon_{\mathbf{sc}}^{2}\). Plugging back into (14) gives

\[\mathbb{E}[\|x_{t_{0}+h}-\widehat{x}_{t_{0}+h}\|^{2}] \lesssim h^{2}\left(L^{2}dh^{2}\left(L\vee\frac{1}{T-t_{0}}\right)+ \varepsilon_{\mathbf{sc}}^{2}\right).\]

The Wasserstein distance is bounded by the square root of this quantity, and the lemma follows. 

Lemma 4 suggests that focusing on the dependence on \(d\), we will be able to take \(h\asymp d^{-1/2}\) (we need to keep one factor of \(h\) in the bound, as we need to sum up the bound over \(1/h\) iterations).

_Remark 2_.: Our improved score perturbation lemma is necessary to obtain this \(d^{1/2}\) dependence. The original score perturbation lemma [11, Lemma C.11-12] combined with a space discretization bound gives a bound of

\[\mathbb{E}\bigl{[}\|\nabla\ln q_{t}^{\rightarrow}(x_{t})-\nabla\ln q_{s}^{ \rightarrow}(x_{s})\|^{2}\bigr{]}\lesssim L^{2}dh\]

in place of Corollary 1. Note this is a \(\frac{1}{2}\)-Holder continuity bound rather than a Lipschitz bound. The bound in Lemma 4 then becomes

\[W_{2}(qP_{\mathsf{ODE}}^{t_{0},h},q\widehat{P}_{\mathsf{ODE}}^{t_{0},h}) \lesssim Ld^{1/2}h^{3/2}+h\varepsilon_{\mathbf{sc}}\,,\]

and we would only be able to take \(h\asymp d^{-1}\). We also note that our bound has an extra factor of \(\max\{L^{1/2},(T-t_{0})^{-1/2}\}\); we do not know if this extra factor is necessary.

We now iterate Lemma 4 to obtain the following result. Note that we now need to also assume that the score estimate is \(L\)-Lipschitz.

**Lemma 5**.: _Suppose that both Assumptions 2 and 3 hold. Let \(h_{1},\dots,h_{N}>0\) be a sequence such that letting \(t_{N}=h_{1}+\dots+h_{N}\), we have \(t_{N}\leq 1/L\). Let \(h_{\max}=\max_{1\leq n\leq N}h_{n}\)._

1. _If_ \(T-(t_{0}+t_{N})\gtrsim 1/L\)_, then_ \[W_{2}(qP_{\mathsf{ODE}}^{t_{0},h_{1},\dots,h_{N}},q\widehat{P}_{ \mathsf{ODE}}^{t_{0},h_{1},\dots,h_{N}})\lesssim L^{3/2}d^{1/2}h_{\max}t_{N}+ \varepsilon_{\mathbf{sc}}t_{N}\leq L^{1/2}d^{1/2}h_{\max}+\frac{\varepsilon_{ \mathbf{sc}}}{L}\,.\]
2. _If_ \(T-t_{0}\lesssim 1/L\) _and_ \(h_{n+1}\leq\frac{T-t_{0}-t_{n}}{2}\) _for each_ \(n\)_, then_ \[W_{2}(qP_{\mathsf{ODE}}^{t_{0},h_{1},\dots,h_{N}},q\widehat{P}_{ \mathsf{ODE}}^{t_{0},h_{1},\dots,h_{N}})\lesssim L^{1/2}d^{1/2}h_{\max}+ \varepsilon_{\mathbf{sc}}t_{N}\leq L^{1/2}d^{1/2}h_{\max}+\frac{\varepsilon_ {\mathbf{sc}}}{L}\,.\]

Proof.: We abbreviate \(P_{\mathsf{ODE}}^{N}\coloneqq P_{\mathsf{ODE}}^{t_{0},h_{1},\dots,h_{N}}\) and \(\widehat{P}_{\mathsf{ODE}}^{N}\coloneqq\widehat{P}_{\mathsf{ODE}}^{t_{0},h_{ 1},\dots,h_{N}}\). Using the triangle inequality,

\[W_{2}(qP_{\mathsf{ODE}}^{N},q\widehat{P}_{\mathsf{ODE}}^{N}) \leq W_{2}(qP_{\mathsf{ODE}}^{N},qP_{\mathsf{ODE}}^{N-1}\widehat{ P}_{\mathsf{ODE}})+W_{2}(qP_{\mathsf{ODE}}^{N-1}\widehat{P}_{\mathsf{ODE}},q \widehat{P}_{\mathsf{ODE}}^{N})\] \[\leq O(Ld^{1/2}h_{N}^{2}\max\{L^{1/2},(T-t_{0}-t_{N})^{-1/2}\}+h_ {N}\varepsilon_{\mathbf{sc}})\] \[\quad+\exp(O(Lh_{N}))\,W_{2}(qP_{\mathsf{ODE}}^{N-1},q\widehat{ P}_{\mathsf{ODE}}^{N-1})\]

where the bound on the first term is by Lemma 4. By induction,

\[W_{2}(qP_{\mathsf{ODE}}^{N},q\widehat{P}_{\mathsf{ODE}}^{N}) \lesssim\sum_{n=1}^{N}\bigl{(}Ld^{1/2}h_{n}^{2}\max\{L^{1/2},(T-t_{0}-t_{n}) ^{-1/2}\}+h_{n}\varepsilon_{\mathbf{sc}}\bigr{)}\] \[\qquad\qquad\qquad\times\exp(O(L\,(h_{n+1}+\dots+h_{N})))\,.\]

By assumption, \(h_{n+1}+\dots+h_{N}\leq t_{N}\leq 1/L\). In the first case, we get

\[W_{2}(qP_{\mathsf{ODE}}^{N},q\widehat{P}_{\mathsf{ODE}}^{N}) \lesssim L^{3/2}d^{1/2}h_{\max}t_{N}+\varepsilon_{\mathbf{sc}}t_{N}\,.\]

In the second case we get

\[W_{2}(qP_{\mathsf{ODE}}^{N},q\widehat{P}_{\mathsf{ODE}}^{N}) \lesssim Ld^{1/2}h_{\max}\sum_{n=1}^{N}\frac{h_{n}}{\bigl{(}T-t_{0}-t_{n} \bigr{)}^{1/2}}+\varepsilon_{\mathbf{sc}}t_{N}\lesssim L^{1/2}d^{1/2}h_{\max }+\varepsilon_{\mathbf{sc}}t_{N}\]

by interpreting the summation as a Riemann sum, and noting that the condition \(h_{n+1}\leq\frac{T-t_{0}-t_{n}}{2}\) implies that this is a constant-factor approximation of the integral \(\int_{T-t_{0}-t_{N}}^{T-t_{0}}\frac{1}{t^{1/2}}\,\mathrm{d}t\lesssim\sqrt{T-t _{0}}\). 

Choice of step sizes.In the first case, we can take all the step sizes to be equal, but in the second case, we may need to take decreasing step sizes. Given a target time \(T-t_{0}-t_{N}=\delta\), by taking \(h_{1}=h_{\max}\) and then

\[h_{n}=\min\Bigl{\{}\delta,\,h_{\max},\,\frac{T-t_{0}-t_{n-1}}{2}\Bigr{\}}\,,\]

we can reach the target time in

\[N=O\Bigl{(}\frac{1}{Lh_{\max}}+\ln\frac{h_{\max}}{\delta}\Bigr{)}\quad\text{ steps}\,.\]

## Appendix D Corrector step

In SSD.1 (resp. SSD.2), we will show that if \(p\), \(q\) are close in Wasserstein distance, then running the corrector step based on the overdamped (resp. underdamped) Langevin diffusion starting from \(p\) and from \(q\) for some amount of time results in distributions which are close in _total variation_ distance. In the end-to-end analysis in SSE, we combine this "total variation to Wasserstein" regularization with the Wasserstein discretization analysis of the predictor step in SSC in order to establish our final results.

### Corrector via overdamped Langevin

We will take the potential and score estimate defining the Markov kernels \(P_{\mathsf{LD}}\) and \(\widehat{P}_{\mathsf{LMC}}\) from SS2.3 to be \(U\) and \(s\) respectively. Recall that these correspond respectively to running the overdamped Langevin diffusion with stationary distribution \(q\propto\exp(-U)\) and running the discretized diffusion with score estimate \(s\), both for time \(h\).

The main result of this section is to show that \(p\widehat{P}_{\mathsf{LMC}}^{N}\) and \(q\) are close in total variation if \(p\) and \(q\) are close in Wasserstein.

**Theorem 4** (Overdamped corrector).: _For any \(T_{\mathsf{corr}}\coloneqq Nh\lesssim 1/L\),_

\[\mathsf{TV}(p\widehat{P}_{\mathsf{LMC}}^{N},q)\lesssim W_{2}(p,q)/\sqrt{T_{ \mathsf{corr}}}+\varepsilon_{\mathsf{sc}}\sqrt{T_{\mathsf{corr}}}+L\sqrt{dhT _{\mathsf{corr}}}\,.\]

_In particular, for \(T_{\mathsf{corr}}\asymp 1/L\),_

\[\mathsf{TV}(p\widehat{P}_{\mathsf{LMC}}^{N},q)\lesssim\sqrt{L}\,W_{2}(p,q)+ \varepsilon_{\mathsf{sc}}/\sqrt{L}+\sqrt{Ldh}\,.\]

We will bound \(\mathsf{TV}(pP_{\mathsf{LD}}^{N},q)\) and \(\mathsf{TV}(p\widehat{P}_{\mathsf{LMC}}^{N},pP_{\mathsf{LD}}^{N})\) separately. For the former, we use the following short-time regularization result:

**Lemma 6** ([1, Lemma 4.2]).: _If \(T_{\mathsf{corr}}\lesssim 1/L\), then_

\[\mathsf{TV}(pP_{\mathsf{LD}}^{N},q)\lesssim\sqrt{\mathsf{KL}(pP_{\mathsf{LD}}^ {N}\,\|\,q)}\lesssim W_{2}(p,q)/\sqrt{T_{\mathsf{corr}}}\,.\]

Proof.: The first inequality is Pinsker's inequality. The second inequality is a consequence of [1, Lemma 4.2], which gives a bound \(\mathsf{KL}(pP_{\mathsf{LD}}^{N}\,\|\,q)\lesssim L\,(1+1/\big{(}e^{2LT_{ \mathsf{corr}}}-1))\,W_{2}^{2}(p,q).\) The claim then follows from simplifying by using \(T_{\mathsf{corr}}\lesssim 1/L\). 

For the latter term, we introduce notation for two stochastic processes.

\[\mathrm{d}x_{t}^{\circ} =-\nabla U(x_{t}^{\circ})\,\mathrm{d}t+\sqrt{2}\,\mathrm{d}B_{t}\,, x_{0}^{\circ} \sim q\,,\] \[\mathrm{d}x_{t} =-\nabla U(x_{t})\,\mathrm{d}t+\sqrt{2}\,\mathrm{d}B_{t}\,, x_{0} \sim p\,.\]

Note that for any integer \(k\geq 0\),

\[x_{kh}^{\circ}\sim qP_{\mathsf{LD}}^{k}\,,\qquad x_{kh}\sim pP_{\mathsf{LD}}^{ k}\,.\]

Observe that marginally, \(qP_{\mathsf{LD}}^{k}=q\) for any \(k\geq 0\) because \(q\) is the stationary distribution of the Langevin diffusion. The three processes are coupled by using the same Brownian motion and by coupling \(x_{0}=\widehat{x}_{0}\sim p\) and \(x_{0}^{\circ}\sim q\) optimally.

Before we proceed to bound \(\mathsf{TV}(pP_{\mathsf{LD}}^{N},p\widehat{P}_{\mathsf{LMC}}^{N})\), we need the following simple lemma.

**Lemma 7**.: _If \(T_{\mathsf{corr}}\lesssim 1/L\), then_

\[\mathbb{E}[\|x_{t}-x_{t}^{\circ}\|^{2}]\lesssim W_{2}^{2}(p,q)\]

_for all \(0\leq t\leq T_{\mathsf{corr}}\)._

Proof.: By Ito's formula,

\[\mathrm{d}(\|x_{t}-x_{t}^{\circ}\|^{2})=-2\left\langle x_{t}-x_{t}^{\circ}, \nabla U(x_{t})-\nabla U(x_{t}^{\circ})\right\rangle\leq 2L\,\|x_{t}-x_{t}^{ \circ}\|^{2}\,.\]

By Gronwall's inequality,

\[\|x_{t}-x_{t}^{\circ}\|^{2}\leq e^{2Lt}\,\|x_{0}-x_{0}^{\circ}\|^{2}\,,\]

so that if we couple the two processes by coupling \(x_{0}\) and \(x_{0}^{\circ}\) optimally, we conclude that

\[\mathbb{E}[\|x_{t}-x_{t}^{\circ}\|^{2}]\leq e^{2Lt}\,\mathbb{E}[\|x_{0}-x_{0}^ {\circ}\|^{2}]=e^{2Lt}\,W_{2}^{2}(p,q)\lesssim W_{2}^{2}(p,q)\,,\]

recalling that \(t\leq T_{\mathsf{corr}}\lesssim 1/L\) by hypothesis. 

It remains to bound \(\mathsf{TV}(p\widehat{P}_{\mathsf{LMC}}^{N},pP_{\mathsf{LD}}^{N})\).

**Lemma 8**.: _If \(T_{\mathsf{corr}}\lesssim 1/L\), then_

\[\mathsf{TV}(p\widehat{P}^{N}_{\mathsf{LMC}},pP^{N}_{\mathsf{LD}})\lesssim \sqrt{\mathsf{KL}(pP^{N}_{\mathsf{LD}}\,\|\,p\widehat{P}^{N}_{\mathsf{LMC}})} \lesssim L\sqrt{T_{\mathsf{corr}}}\,W_{2}(p,q)+\varepsilon_{\mathsf{sc}}\sqrt {T_{\mathsf{corr}}}+L\sqrt{dhT_{\mathsf{corr}}}\,.\]

Proof.: As \(x\) and \(\widehat{x}\) are driven by the same Brownian motion, by Girsanov's theorem8 and the data processing inequality we have

Footnote 8: Although the validity of Girsanovs theorem typically requires Novikovs condition to be satisfied, this can be avoided via an approximation argument as in [3].

\[\mathsf{KL}(pP^{N}_{\mathsf{LD}}\,\|\,p\widehat{P}^{N}_{\mathsf{LMC}})\lesssim \sum_{k=0}^{N-1}\,\int_{kh}^{(k+1)h}\mathbb{E}[\|s(x_{kh})-\nabla U(x_{u})\|^{ 2}]\,\mathrm{d}u\,.\]

We can decompose the integrand as follows:

\[\mathbb{E}[\|s(x_{kh})-\nabla U(x_{u})\|^{2}] \lesssim\mathbb{E}\big{[}\|s(x_{kh})-s(x^{\circ}_{kh})\|^{2}+\| s(x^{\circ}_{kh})-\nabla U(x^{\circ}_{kh})\|^{2}\] \[\qquad\qquad+\|\nabla U(x^{\circ}_{kh})-\nabla U(x^{\circ}_{u}) \|^{2}+\|\nabla U(x^{\circ}_{u})-\nabla U(x_{u})\|^{2}\big{]}\] \[\leq L^{2}\,\mathbb{E}[\|x_{kh}-x^{\circ}_{kh}\|^{2}]+\varepsilon _{\mathsf{sc}}^{2}+L^{2}\,\mathbb{E}[\|x^{\circ}_{kh}-x^{\circ}_{u}\|^{2}]+L^ {2}\,\mathbb{E}[\|x^{\circ}_{u}-x_{u}\|^{2}]\] \[\lesssim L^{2}\,W_{2}^{2}(p,q)+\varepsilon_{\mathsf{sc}}^{2}+L^{ 2}\,\mathbb{E}[\|x^{\circ}_{kh}-x^{\circ}_{u}\|^{2}]\] (15)

where we used Lemma 7 to bound \(\mathbb{E}[\|x^{\circ}_{u}-x_{u}\|^{2}]\).

It remains to bound \(\mathbb{E}[\|x^{\circ}_{kh}-x^{\circ}_{u}\|^{2}]\). Note that

\[\mathbb{E}[\|x^{\circ}_{kh}-x^{\circ}_{u}\|^{2}] =\mathbb{E}\Big{[}\Big{\|}\int_{kh}^{u}-\nabla U(x^{\circ}_{u}) \,\mathrm{d}s+\sqrt{2}\,(B_{u}-B_{kh})\Big{\|}^{2}\Big{]}\lesssim h\int_{kh}^ {u}\mathbb{E}[\|\nabla U(x^{\circ}_{s})\|^{2}]\,\mathrm{d}s+dh\] \[\leq Ldh^{2}+dh\lesssim dh\,,\]

where in the last step we used that \(\mathbb{E}[\|\nabla U(x^{\circ}_{u})\|^{2}]\leq Ld\). Substituting this into (15), we obtain

\[\mathsf{KL}(pP^{N}_{\mathsf{LD}}\,\|\,p\widehat{P}^{N}_{\mathsf{LMC}}) \lesssim L^{2}T_{\mathsf{corr}}\,W_{2}^{2}(p,q)+\varepsilon_{\mathsf{sc}}^{2} T_{\mathsf{corr}}+L^{2}dhT_{\mathsf{corr}}\,.\]

The claimed bound on \(\mathsf{TV}(pP^{N}_{\mathsf{LD}},p\widehat{P}^{N}_{\mathsf{LMC}})\) follows by Pinsker's inequality. 

Proof of Theorem 4.: This is immediate from Lemma 6 and Lemma 8, recalling that \(T_{\mathsf{corr}}\lesssim 1/L\) so that the bound in Lemma 6 dominates the \(W_{2}(p,q)\) term in Lemma 8. 

### Corrector via underdamped Langevin

Throughout, we set the friction parameter to

\[\gamma\asymp\sqrt{L}\,.\]

We will take the potential and score estimate defining the Markov kernels \(P_{\mathsf{ULD}}\) and \(\widehat{P}_{\mathsf{ULMC}}\) from SS2.3 to be \(U\) and \(s\) respectively. Recall that these correspond respectively to running the underdamped Langevin diffusion with stationary distribution \(q\) and running the discretized diffusion with score estimate \(s\), both for time \(h\).

Given probability measures \(p\) and \(q\), we write \(\bm{p}\coloneqq p\otimes\gamma_{d}\) and \(\bm{q}\coloneqq q\otimes\gamma_{d}\), where \(\gamma_{d}\) is the standard Gaussian measure in \(\mathbb{R}^{d}\).

The main result of this section is to show that \(\bm{p}\widehat{P}^{N}_{\mathsf{ULMC}}\) and \(\bm{q}\) are close in total variation if \(p\) and \(q\) are close in Wasserstein. Compared to SSD.1, the discretization error for the underdamped Langevin diffusion is smaller.

**Theorem 5** (Underdamped corrector).: _For \(T_{\mathsf{corr}}\lesssim 1/\sqrt{L}\),_

\[\mathsf{TV}(\bm{p}\widehat{P}^{N}_{\mathsf{ULMC}},\bm{q})\lesssim\frac{W_{2}(p, q)}{L^{1/4}T_{\mathsf{corr}}^{3/2}}+\frac{\varepsilon_{\mathsf{sc}}T_{ \mathsf{corr}}^{1/2}}{L^{1/4}}+L^{3/4}T_{\mathsf{corr}}^{1/2}d^{1/2}h\,.\]

_In particular, if we take \(T_{\mathsf{corr}}\asymp 1/\sqrt{L}\), then_

\[\mathsf{TV}(\bm{p}\widehat{P}^{N}_{\mathsf{ULMC}},\bm{q})\lesssim\sqrt{L}\,W_{2 }(p,q)+\varepsilon_{\mathsf{sc}}/\sqrt{L}+\sqrt{Ld}\,h\,.\]We will bound \(\mathsf{TV}(\bm{p}P_{\mathsf{ULD}}^{N},\bm{q})\) and \(\mathsf{TV}(\bm{p}\widehat{P}_{\mathsf{ULD}}^{N},\bm{p}P_{\mathsf{ULD}}^{N})\) separately. For the former, we use the short-time regularization result of [13]:

**Lemma 9**.: _If \(T_{\mathsf{corr}}\lesssim 1/\sqrt{L}\), then_

\[\mathsf{TV}(\bm{p}P_{\mathsf{ULD}}^{N},\bm{q})\lesssim\sqrt{\mathsf{KL}(\bm{p }P_{\mathsf{ULD}}^{N}\parallel\bm{q})}\lesssim\frac{W_{2}(p,q)}{L^{1/4}T_{ \mathsf{corr}}^{3/2}}\,.\]

Proof.: This is a consequence of [13, Corollary 4.7 (1)]. The condition to check therein is their Eq. (3.6), which in our setting is satisfied by the constants \(K_{1}=L\) and \(K_{2}=\upgamma\). The Corollary then states that for the cost function

\[c_{T_{\mathsf{corr}}}((z,v),(z^{\prime},v^{\prime}))\coloneqq\inf_{t\in(0,T_{ \mathsf{corr}}]}\frac{t}{2\upgamma}\left\{\left(\frac{6}{t^{2}}+L+\frac{3 \upgamma}{2t}\right)\|z-z^{\prime}\|+\left(\frac{4}{t}+\frac{4Lt}{27}+\upgamma \right)\|v-v^{\prime}\|\right\}^{2},\]

we have \(\mathsf{KL}(\bm{p}P_{\mathsf{ULD}}^{N}\parallel\bm{q})\leq W_{c_{T_{\mathsf{ corr}}}}(p\otimes\gamma_{d},q\otimes\gamma_{d})\). For \(v=v^{\prime}\) and \(T_{\mathsf{corr}}\lesssim 1/\sqrt{L}\), note that

\[c_{T_{\mathsf{corr}}}((z,v),(z^{\prime},v))\lesssim\frac{1}{L^{1/2}T_{ \mathsf{corr}}^{3}}\,\|z-z^{\prime}\|^{2}\,,\]

so the claim follows by Pinsker's inequality. 

Next, we define the following processes: \(\mathrm{d}z_{t}^{\circ}=v_{t}^{\circ}\,\mathrm{d}t\), \(\mathrm{d}z_{t}=v_{t}\,\mathrm{d}t\),

\[\mathrm{d}v_{t}^{\circ} =-\up v_{t}^{\circ}\,\mathrm{d}t-\nabla U(z_{t}^{\circ})\,\mathrm{ d}t+\sqrt{2\upgamma}\,\mathrm{d}B_{t}\,, (z_{0}^{\circ},v_{0}^{\circ})\sim\bm{q}\,,\] \[\mathrm{d}v_{t} =-\up v_{t}\,\mathrm{d}t-\nabla U(z_{t})\,\mathrm{d}t+\sqrt{2 \upgamma}\,\mathrm{d}B_{t}\,, (z_{0},v_{0})\sim\bm{p}\,.\]

It follows that for any integer \(k\geq 0\),

\[(z_{kh}^{\circ},v_{kh}^{\circ})\sim\bm{q}P_{\mathsf{ULD}}^{k}=\bm{q}\,,\qquad( z_{kh},v_{kh})\sim\bm{p}P_{\mathsf{ULD}}^{k}\,.\]

We couple these processes by using the same Brownian motion and coupling \(q\otimes\gamma_{d}\) and \(p\otimes\gamma_{d}\) optimally (in particular, \(v_{0}=v_{0}^{\circ}\)).

Before we proceed to bound \(\mathsf{TV}(pP_{\mathsf{ULD}}^{N},p\widehat{P}_{\mathsf{ULD}}^{N})\), we start with the following lemma.

**Lemma 10**.: _If \(T_{\mathsf{corr}}\lesssim 1/\sqrt{L}\), then for all \(0\leq t\leq T_{\mathsf{corr}}\),_

\[\mathbb{E}[\|z_{t}-z_{t}^{\circ}\|^{2}]\lesssim W_{2}^{2}(p,q)\,.\]

Proof.: We have

\[\nabla U(z_{t})-\nabla U(z_{t}^{\circ})=\left(\int_{0}^{1}\nabla^{2}U(z_{t}+u \,(z_{t}^{\circ}-z_{t}))\,\mathrm{d}u\right)(z_{t}-z_{t}^{\circ})\coloneqq \mathcal{H}_{t}(z_{t}-z_{t}^{\circ})\,,\]

and the operator \(\mathcal{H}_{t}\) satisfies

\[\|\mathcal{H}_{t}\|_{\bm{\infty}}\leq L\,.\]

Let \(\alpha\coloneqq 2/\upgamma\). For the vectors \(\delta_{t}\coloneqq(z_{t}+\alpha v_{t})-(z_{t}^{\circ}+\alpha v_{t}^{\circ})\) and \(\eta_{t}\coloneqq z_{t}-z_{t}^{\circ}\), we have

\[\frac{1}{2}\,\mathrm{d}(\|\delta_{t}\|^{2}+\|\eta_{t}\|^{2}) =-(\delta_{t},\eta_{t})^{\intercal}\begin{bmatrix}(\upgamma-\frac{1}{ \alpha})\,I_{d}&\frac{1}{2}\,(\alpha\mathcal{H}_{t}-\upgamma\,I_{d})\\ \frac{1}{2}\,(\alpha\mathcal{H}_{t}-\upgamma\,I_{d})&\frac{1}{\alpha}\,I_{d} \end{bmatrix}(\delta_{t},\eta_{t})\] \[\lesssim\sqrt{L}\,(\|\delta_{t}\|^{2}+\|\eta_{t}\|^{2})\,.\]

By Gronwall's inequality,

\[\|\delta_{t}\|^{2}+\|\eta_{t}\|^{2}\leq e^{O(\sqrt{L}t)}\,(\|\delta_{0}\|^{2}+ \|\eta_{0}\|^{2})\,,\]

so if we couple the two processes by coupling \(z_{0}\) and \(z_{0}^{\circ}\) optimally and taking \(v_{0}=v_{0}^{\circ}\), we obtain

\[\mathbb{E}[\|z_{t}-z_{t}^{\circ}\|^{2}]\lesssim\mathbb{E}[\|\delta_{t}\|^{2}+ \|\eta_{t}\|^{2}]\leq e^{O(\sqrt{L}t)}\,\mathbb{E}[\|\delta_{0}\|^{2}+\|\eta_{0} \|^{2}]\lesssim e^{O(\sqrt{L}t)}\,W_{2}^{2}(p,q)\lesssim W_{2}^{2}(p,q)\,,\]

recalling that \(t\leq T_{\mathsf{corr}}\lesssim 1/\sqrt{L}\) by hypothesis. 

It remains to bound \(\mathsf{TV}(\bm{p}\widehat{P}_{\mathsf{ULD}}^{N},\bm{p}P_{\mathsf{ULD}}^{N})\).

**Lemma 11**.: _If \(T_{\mathsf{corr}}\lesssim 1/\sqrt{L}\), then_

\[\mathsf{TV}(\bm{p}\widehat{P}^{N}_{\mathsf{ULMC}},\bm{p}P^{N}_{ \mathsf{ULMC}}) \lesssim\sqrt{\mathsf{KL}(\bm{p}P^{N}_{\mathsf{ULMC}}\parallel\bm{p }\widehat{P}^{N}_{\mathsf{ULMC}})}\] \[\lesssim L^{3/4}T_{\mathsf{corr}}^{1/2}\,W_{2}(p,q)+L^{-1/4}T_{ \mathsf{corr}}^{1/2}\varepsilon_{\mathsf{sc}}+L^{3/4}T_{\mathsf{corr}}^{1/2} d^{1/2}h\,.\]

Proof.: As \((z,v)\) and \((z^{\circ},v^{\circ})\) are driven by the same Brownian motion, by Girsanov's theorem9 and the data processing inequality we have

Footnote 9: Again, we can avoid checking Novikovs condition using the approximation argument of [Che+23a].

\[\mathsf{KL}(\bm{p}P^{N}_{\mathsf{ULMC}}\parallel\bm{p}\widehat{P}^{N}_{ \mathsf{ULMC}})\lesssim\frac{1}{\gamma}\sum_{k=0}^{N-1}\int_{kh}^{(k+1)h} \mathbb{E}[\|s(z_{kh})-\nabla U(z_{u})\|^{2}]\,\mathrm{d}u\,.\]

We can decompose the integrand as follows:

\[\mathbb{E}[\|s(z_{kh})-\nabla U(z_{u})\|^{2}] \lesssim\mathbb{E}\big{[}\|s(z_{kh})-s(z_{kh}^{\circ})\|^{2}+\| s(z_{kh}^{\circ})-\nabla U(z_{kh}^{\circ})\|^{2}\] \[\qquad\qquad+\|\nabla U(z_{kh}^{\circ})-\nabla U(z_{u}^{\circ})\| ^{2}+\|\nabla U(z_{u}^{\circ})-\nabla U(z_{u})\|^{2}\big{]}\] \[\leq L^{2}\,\mathbb{E}[\|z_{kh}-z_{kh}^{\circ}\|^{2}]+\varepsilon _{\mathsf{sc}}^{2}+L^{2}\,\mathbb{E}[\|z_{kh}^{\circ}-z_{u}^{\circ}\|^{2}]+L^ {2}\,\mathbb{E}[\|z_{u}^{\circ}-z_{u}\|^{2}]\] \[\lesssim L^{2}\,W_{2}^{2}(p,q)+\varepsilon_{\mathsf{sc}}^{2}+L^{2 }\,\mathbb{E}[\|z_{kh}^{\circ}-z_{u}^{\circ}\|^{2}]\,,\] (16)

where we applied Lemma 10.

It remains to bound \(\mathbb{E}[\|z_{kh}^{\circ}-z_{u}^{\circ}\|^{2}]\). Note that

\[\mathbb{E}[\|z_{kh}^{\circ}-z_{u}^{\circ}\|^{2}]=\mathbb{E}\Big{[}\Big{\|} \int_{kh}^{u}v_{s}^{\circ}\,\mathrm{d}s\Big{\|}^{2}\Big{]}\leq h\int_{kh}^{u} \mathbb{E}[\|v_{s}^{\circ}\|^{2}]\,\mathrm{d}s\leq dh^{2}\,,\]

where in the last step we used the fact that \(v_{s}^{\circ}\sim\gamma_{d}\). Substituting this into (16), we conclude that

\[\mathsf{KL}(\bm{p}P^{N}_{\mathsf{ULMC}}\parallel\bm{p}\widehat{P}^{N}_{ \mathsf{ULMC}})\lesssim L^{3/2}T_{\mathsf{corr}}\,W_{2}^{2}(p,q)+L^{-1/2}T_{ \mathsf{corr}}\varepsilon_{\mathsf{sc}}^{2}+L^{3/2}dh^{2}T_{\mathsf{corr}}\,.\]

The claimed bound on \(\mathsf{TV}(\bm{p}P^{N}_{\mathsf{ULMC}},\bm{p}\widehat{P}^{N}_{\mathsf{ULMC}})\) follows by Pinsker's inequality. 

Proof of Theorem 5.: This is immediate from Lemma 9 and Lemma 11, recalling that \(T_{\mathsf{corr}}\lesssim 1/\sqrt{L}\) so that the bound in Lemma 9 dominates the \(W_{2}(p,q)\) term in Lemma 11. 

_Remark 3_.: In all other sections of this paper, we abuse notation as follows. Given a distribution \(p\) on \(\mathbb{R}^{d}\), we write \(p\widehat{P}_{\mathsf{ULMC}}\) to denote the projection onto the \(z\)-coordinate of \(\bm{p}\widehat{P}_{\mathsf{ULMC}}\), i.e., we view \(\widehat{P}_{\mathsf{ULMC}}\) as a Markov kernel on \(\mathbb{R}^{d}\) rather than on \(\mathbb{R}^{d}\times\mathbb{R}^{d}\) (and similarly for \(P_{\mathsf{ULD}}\)).

## Appendix E End-to-end analysis

**Lemma 12** (TV error after one round of predictor and corrector).: _Choose predictor step sizes \(h_{1},\ldots,h_{N_{\mathsf{pred}}}\) as in Lemma 5 with \(T_{\mathsf{pred}}=h_{1}+\cdots+h_{N_{\mathsf{pred}}}\leq 1/L\). That is, if \(T-t_{0}-T_{\mathsf{pred}}\lesssim 1/L\), then we ensure that \(h_{n+1}\leq\frac{T-t_{0}-h_{1}-\cdots-h_{n}}{2}\) for all \(n\), and if \(T-t_{0}\gtrsim 1/L\), then we can take \(h_{1}=\cdots=h_{N}\). Let \(h_{\mathsf{pred}}:=\max_{1\leq n\leq N_{\mathsf{pred}}}h_{n}\) and abbreviate \(P^{(N_{\mathsf{pred}})}_{\mathsf{ODE}}\coloneqq P^{t_{0},h_{1},\ldots,h_{N_{ \mathsf{pred}}}}_{\mathsf{ODE}}\) (and similarly for \(\widehat{P}_{\mathsf{ODE}}\))._

1. _Consider running the overdamped Langevin corrector for time_ \(T_{\mathsf{corr}}\asymp 1/L\)_, step size_ \(h_{\mathsf{corr}}\)_, and stationary distribution_ \(q_{t_{0}}P^{(N_{\mathsf{pred}})}_{\mathsf{ODE}}=q_{t_{0}+T_{\mathsf{pred}}}\)_; set_ \(N_{\mathsf{corr}}=T_{\mathsf{corr}}/h_{\mathsf{corr}}\)_. Then,_ \[\mathsf{TV}(p\widehat{P}^{(N_{\mathsf{pred}})}_{\mathsf{ODE}}\widehat{P}^{N_{ \mathsf{corr}}}_{\mathsf{ULMC}},\,q_{t_{0}+T_{\mathsf{pred}}})\leq\mathsf{TV}(p,q _{t_{0}})+O\Big{(}L\sqrt{d}\,h_{\mathsf{pred}}+\sqrt{Ldh_{\mathsf{corr}}}+\frac{ \varepsilon_{\mathsf{sc}}}{\sqrt{L}}\Big{)}\,.\]
2. _Consider running the underdamped Langevin corrector for time_ \(T_{\mathsf{corr}}\asymp 1/\sqrt{L}\)_, step size_ \(h_{\mathsf{corr}}\)_, and stationary distribution_ \(q_{t_{0}}P^{(N_{\mathsf{pred}})}_{\mathsf{ODE}}=q_{t_{0}+T_{\mathsf{pred}}}\)_; set_ \(N_{\mathsf{corr}}=T_{\mathsf{corr}}/h_{\mathsf{corr}}\)_. Then,_ \[\mathsf{TV}(p\widehat{P}^{(N_{\mathsf{pred}})}_{\mathsf{ODE}}\widehat{P}^{N_{ \mathsf{corr}}}_{\mathsf{ULMC}},\,q_{t_{0}+T_{\mathsf{pred}}})\leq\mathsf{TV}(p,q _{t_{0}})+O\Big{(}L\sqrt{d}\,h_{\mathsf{pred}}+\sqrt{Ld}\,h_{\mathsf{corr}}+ \frac{\varepsilon_{\mathsf{sc}}}{\sqrt{L}}\Big{)}\,.\]Proof.: By the triangle inequality and the data-processing inequality,

\[\mathsf{TV}(p\widehat{P}_{\mathsf{ODE}}^{(N_{\mathsf{pred}})}\widehat {P}_{\mathsf{LMC}}^{N_{\mathsf{corr}}},\,q_{t_{0}+T_{\mathsf{pred}}})\] \[\quad\leq\mathsf{TV}(p\widehat{P}_{\mathsf{ODE}}^{(N_{\mathsf{pred }})}\widehat{P}_{\mathsf{LMC}}^{N_{\mathsf{corr}}},\,q_{t_{0}}\widehat{P}_{ \mathsf{ODE}}^{(N_{\mathsf{pred}})}\widehat{P}_{\mathsf{LMC}}^{N_{\mathsf{ corr}}})+\mathsf{TV}(q_{t_{0}}\widehat{P}_{\mathsf{ODE}}^{(N_{\mathsf{pred}})} \widehat{P}_{\mathsf{LMC}}^{N_{\mathsf{corr}}},\,q_{t_{0}+T_{\mathsf{pred}}})\] \[\quad\leq\mathsf{TV}(p,q_{t_{0}})+\mathsf{TV}(q_{t_{0}}\widehat{P }_{\mathsf{ODE}}^{(N_{\mathsf{pred}})}\widehat{P}_{\mathsf{LMC}}^{N_{\mathsf{ corr}}},\,q_{t_{0}+T_{\mathsf{pred}}})\,.\]

For overdamped Langevin, applying Theorem 4,

\[\mathsf{TV}(q_{t_{0}}\widehat{P}_{\mathsf{ODE}}^{(N_{\mathsf{pred}})}\widehat {P}_{\mathsf{LMC}}^{N_{\mathsf{corr}}},\,q_{t_{0}+T_{\mathsf{pred}}})\lesssim \sqrt{L}\,W_{2}(q\widehat{P}_{\mathsf{ODE}}^{(N_{\mathsf{pred}})},\,q_{t_{0}+ T_{\mathsf{pred}}})+\varepsilon_{\mathbf{sc}}/\sqrt{L}+\sqrt{Ldh_{\mathsf{corr}}}\,.\] (17)

For the Wasserstein term, Lemma 5 yields

\[W_{2}(q_{t_{0}}\widehat{P}_{\mathsf{ODE}}^{(N_{\mathsf{pred}})},q_{t_{0}+T_{ \mathsf{pred}}})=W_{2}(q_{t_{0}}\widehat{P}_{\mathsf{ODE}}^{(N_{\mathsf{pred}} )},q_{t_{0}}P_{\mathsf{ODE}}^{(N_{\mathsf{pred}})})\lesssim\sqrt{Ld}\,h_{ \mathsf{pred}}+\frac{\varepsilon_{\mathbf{sc}}}{L}\,.\]

Combining these bounds yields the result for the overdamped corrector. For the underdamped corrector, we modify (17) by replacing the use of Theorem 4 with Theorem 5. 

We also need the following lemma on the convergence of the OU process.

**Lemma 13**.: _Let \((q_{t}^{\rightarrow})_{t\geq 0}\) denote the marginal law of the OU process started at \(q_{0}^{\rightarrow}=q_{\star}\). Then, for all \(T\gtrsim 1\), it holds that_

\[\mathsf{TV}(q_{T}^{\rightarrow},\gamma^{d})\lesssim(\sqrt{d}+\mathfrak{m}_{2 })\exp(-T)\,.\]

Proof.: This follows from [1, Lemma C.4]. Alternatively, using the short-time regularization result of [1, Lemma 4.2] for time \(t_{0}\asymp 1\) and the Wasserstein contraction of the OU process,

\[\mathsf{TV}(q_{T}^{\rightarrow},\gamma^{d})\lesssim\sqrt{\mathsf{KL}(q_{T}^{ \rightarrow}\parallel\gamma^{d})}\lesssim\frac{W_{2}(q_{T-t_{0}}^{\rightarrow},\gamma^{d})}{\sqrt{t_{0}}}\leq\exp(-(T-t_{0}))\,W_{2}(q_{\star},\gamma^{d})\,.\]

The result follows from \(W_{2}(q_{\star},\gamma^{d})\leq W_{2}(q_{\star},\delta_{0})+W_{2}(\delta_{0}, \gamma^{d})\leq\mathfrak{m}_{2}+\sqrt{d}\). 

We now prove our main theorems.

Proof of Theorems 2 and 3.: For \(t\in[0,T]\), let \(p_{t}\coloneqq\mathrm{law}(\widehat{x}_{t})\). From Lemma 13,

\[\mathsf{TV}(p_{0},q_{0})=\mathsf{TV}(q_{T}^{\rightarrow},\gamma^{d}) \lesssim(\sqrt{d}+\mathfrak{m}_{2})\exp(-T)\,.\]

We divide our analysis according to the two stages of the algorithm. In the first stage, after iterating Lemma 12 for \(N_{0}\asymp LT\) steps,

\[\mathsf{TV}(p_{T-h_{\mathsf{pred}}},q_{T-h_{\mathsf{pred}}}) \leq\mathsf{TV}(p_{0},q_{0})+O\Big{(}L\sqrt{d}\,h_{\mathsf{pred}} +\sqrt{Ld}\,h_{\mathsf{corr}}^{\mathsf{p}}+\frac{\varepsilon_{\mathbf{sc}}}{ \sqrt{L}}\Big{)}\times N_{0}\] \[\lesssim(\sqrt{d}+\mathfrak{m}_{2})\exp(-T)+L^{2}Td^{1/2}h_{ \mathsf{pred}}+L^{3/2}Td^{1/2}h_{\mathsf{corr}}^{\mathsf{p}}+L^{1/2}T \varepsilon_{\mathbf{sc}}\]

where \(\mathsf{p}=\frac{1}{2}\) if we use the overdamped corrector and \(\mathsf{p}=1\) if we use the underdamped corrector. Applying the second part of Lemma 12 for the second stage of the algorithm, we then conclude that

\[\mathsf{TV}(p_{T-\delta},q_{T-\delta})\lesssim(\sqrt{d}+\mathfrak{m}_{2})\exp (-T)+L^{2}Td^{1/2}h_{\mathsf{pred}}+L^{3/2}Td^{1/2}h_{\mathsf{corr}}^{ \mathsf{p}}+L^{1/2}T\varepsilon_{\mathbf{sc}}\,.\]

Finally, we note that if we take \(\delta\asymp\frac{\varepsilon^{2}}{L^{2}\,(d\mathsf{TV}\mathfrak{m}_{2}^{2})}\), then by [1, Lemma 6.4], \(\mathsf{TV}(q_{T-\delta},q_{T})\leq\varepsilon\); a triangle inequality thus finishes the proof. 

_Remark 4_.: Alternatively, instead of taking geometrically decreasing step sizes and employing early stopping, we could split the algorithm into two stages: for time \(t<T-h_{\mathsf{pred}}\), we take constant step size \(h_{\mathsf{pred}}\), and for time \(t>T-h_{\mathsf{pred}}\), we use a smaller constant step size \(h^{\prime}\) as required if working with the original score perturbation lemma (see Remark 2).

[MISSING_PAGE_FAIL:23]

Figure 2: A realization of DPUM for another mixture of Gaussians.