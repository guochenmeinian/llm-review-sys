# Optimal Time Complexities of

Parallel Stochastic Optimization Methods

Under a Fixed Computation Model

Alexander Tyurin

KAUST

Saudi Arabia

alexandertiurin@gmail.com

&Peter Richtarik

KAUST

Saudi Arabia

richtarik@gmail.com

###### Abstract

Parallelization is a popular strategy for improving the performance of iterative algorithms. Optimization methods are no exception: design of efficient parallel optimization methods and tight analysis of their theoretical properties are important research endeavors. While the minimax complexities are well known for sequential optimization methods, the theory of parallel optimization methods is less explored. In this paper, we propose a new protocol that generalizes the classical oracle framework approach. Using this protocol, we establish _minimax complexities for parallel optimization methods_ that have access to an unbiased stochastic gradient oracle with bounded variance. We consider a fixed computation model characterized by each worker requiring a fixed but worker-dependent time to calculate stochastic gradient. We prove lower bounds and develop optimal algorithms that attain them. Our results have surprising consequences for the literature of _asynchronous_ optimization methods.

## 1 Introduction

We consider the nonconvex optimization problem

\[\min_{x\in Q}\Big{\{}f(x):=\mathbb{E}_{\xi\sim\mathcal{D}}\left[f(x;\xi) \right]\Big{\}}, \tag{1}\]

where \(f\,:\,\mathbb{R}^{d}\times\mathbb{S}_{\xi}\to\mathbb{R}\), \(Q\subseteq\mathbb{R}^{d}\), and \(\xi\) is a random variable with some distribution \(\mathcal{D}\) on \(\mathbb{S}_{\xi}\). In machine learning, \(\mathbb{S}_{\xi}\) could be the space of all possible data, \(\mathcal{D}\) is the distribution of the training dataset, and \(f(\cdot,\xi)\) is the loss of a data sample \(\xi\). In this paper we address the following natural setup:

1. \(n\) workers are available to work in parallel,
2. the \(i^{\text{th}}\) worker requires \(\tau_{i}\) seconds1 to calculate a stochastic gradient of \(f\). Footnote 1: Or any other unit of time.

The function \(f\) is \(L\)-smooth and lower-bounded (see Assumptions 7.1-7.2), and stochastic gradients are unbiased and \(\sigma^{2}\)-variance-bounded (see Assumption 7.3).

### Classical theory

In the nonconvex setting, gradient descent (GD) is an optimal method with respect to the number of gradient (\(\nabla f\)) calls (Lan, 2020; Nesterov, 2018; Carmon et al., 2020) for finding an approximately stationary point of \(f\). Obviously, a key issue with GD is that it requires access to the exact gradients\(\nabla f\) of the function \(f.\) However, in many practical applications, it can be infeasible to calculate the gradient of \(\mathbb{E}\left[f(\cdot;\xi)\right]\) analytically. Moreover, even if this is possible, e.g., if the distribution \(\mathcal{D}\) is described by \(m\) possible samples, so that \(\mathbb{E}_{\xi\sim\mathcal{D}}\left[f(\cdot;\xi)\right]=(\nicefrac{{1}}{{m}}) \sum_{i=1}^{m}\bar{f}(\cdot;\xi_{i}),\,m\) can be huge (Krizhevsky et al., 2017), and gradient evaluation can be arbitrarily expensive.

**Stochastic Gradient Descent.** Due to the above-mentioned problem, machine learning literature is preoccupied with the study of algorithms that can work with stochastic gradients instead (Lan, 2020; Ghadimi and Lan, 2013). For all \(x\in\mathbb{R}^{d},\) we assume that the \(n\) workers have access to independent, unbiased, and \(\sigma^{2}\)-variance-bounded stochastic gradients \(\widehat{\nabla}f(x,\xi)\) (see Assumption 7.3), where \(\xi\) is a random sample from \(\mathcal{D}\). Under such assumptions, **with one worker**, stochastic gradient descent (SGD), i.e., the method \(x^{k+1}=x^{k}-\gamma\widehat{\nabla}f(x^{k};\xi^{k}),\) where \(\xi^{k}\) are i.i.d. random samples from \(\mathcal{D}\), is known to be optimal with respect to the number of stochastic gradient calls (Ghadimi and Lan, 2013; Arjevani et al., 2022). SGD guarantees convergence to an \(\varepsilon\)-stationary point in expectation after \(\mathrm{O}\left(\nicefrac{{L\Delta}}{{\varepsilon}}+\nicefrac{{\sigma^{2}L \Delta}}{{\varepsilon^{2}}}\right)\) stochastic gradient evaluations, where \(\Delta:=f(x^{0})-f^{*}\) and \(x^{0}\in\mathbb{R}^{d}\) is a starting point.

### Parallel optimization methods

Using the bounds from Section 1.1, one can easily _estimate_ the performance of these algorithms in real systems. For instance, if it takes \(\tau_{1}\)_seconds_ to calculate a stochastic gradient **with one worker**, then SGD guarantees to return a solution after

\[\mathrm{O}\left(\tau_{1}\left(\frac{L\Delta}{\varepsilon}+\frac{\sigma^{2}L \Delta}{\varepsilon^{2}}\right)\right)\]

seconds. If instead of a single worker we can access \(n\) workers that can calculate stochastic gradients in parallel, we can consider the following classical parallel methods:

**Minibatch SGD.** The minibatch SGD method (Minibatch SGD), i.e., the iterative process

\[x^{k+1}=x^{k}-\gamma\frac{1}{n}\sum_{i=1}^{n}\widehat{\nabla}f(x^{k};\xi_{i}^ {k}),\]

where \(\gamma\) is a stepsize, \(\xi_{i}^{k}\) are i.i.d. samples from \(\mathcal{D}\), and the gradients \(\widehat{\nabla}f(x^{k};\xi_{i}^{k})\) are calculated in parallel. This method converges after \(\mathrm{O}\left(\nicefrac{{L\Delta}}{{\varepsilon}}+\nicefrac{{\sigma^{2}L \Delta}}{{n\varepsilon^{2}}}\right)\) iterations (Cotter et al., 2011; Goyal et al., 2017; Gower et al., 2019) and after

\[\mathrm{O}\left(\tau_{\max}\left(\frac{L\Delta}{\varepsilon}+\frac{\sigma^{2}L \Delta}{n\varepsilon^{2}}\right)\right) \tag{2}\]

seconds, where \(\tau_{\max}:=\max_{i\in[n]}\tau_{i}\) is the processing time associated with the _slowest_ machine2.

Footnote 2: Further, we assume that the last \(n^{\text{th}}\) worker is the slowest one: \(\tau_{n}=\tau_{\max}.\)

Although the time complexity (2) of Minibatch SGD improves with the number of workers \(n\), in general, this does _not_ guarantee better performance due to the delay \(\tau_{\max}\). In real systems, parallel computations can be very chaotic, e.g., they can be slow due to inconsistent network communications, or GPU computation delays (Dutta et al., 2018; Chen et al., 2016).

**Asynchronous SGD.** We now consider the asynchronous SGD method (Asynchronous SGD) (Recht et al., 2011; Nguyen et al., 2018; Arjevani et al., 2020; Feyzmahdavian et al., 2016) described by

1. Receive \(\widehat{\nabla}f(x^{k-\delta_{k}};\xi^{k-\delta_{k}})\) from a worker,
2. \(x^{k+1}=x^{k}-\gamma^{k}\widehat{\nabla}f(x^{k-\delta_{k}};\xi^{k-\delta_{k}}),\)
3. Ask the worker to calculate \(\widehat{\nabla}f(x^{k+1};\xi^{k+1}),\)

where \(\xi^{k}\) are i.i.d. samples from \(\mathcal{D}\), and \(\delta_{k}\) are gradient iteration delays. This is an _asynchronous_ method: the workers work independently, finish calculations of stochastic gradients with potentially large and chaotic delays \(\delta_{k}\), and the result of their computation is applied as soon as it is ready, without having to wait for other workers. Asynchronous SGD was also considered in the heterogeneous setting (see details in Section A.2).

Cohen et al. (2021); Mishchenko et al. (2022); Koloskova et al. (2022) provide the current state-of-the-art analysis of Asynchronous SGD. In particular, they prove that Asynchronous SGD converges after \(\mathrm{O}\left(\nicefrac{{nL\Delta}}{{\varepsilon}}+\nicefrac{{\sigma^{2}L \Delta}}{{\varepsilon^{2}}}\right)\) iterations. To show the superiority of Asynchronous SGD, Mishchenko et al. (2022) consider the following _fixed computation model_: the \(i^{\text{th}}\) worker requires \(\tau_{i}\) seconds to calculate stochastic gradients. In this setting, Asynchronous SGD converges after

\[\mathrm{O}\left(\left(\frac{1}{n}\sum_{i=1}^{n}\frac{1}{\tau_{i}}\right)^{-1} \left(\frac{L\Delta}{\varepsilon}+\frac{\sigma^{2}L\Delta}{n\varepsilon^{2}} \right)\right) \tag{3}\]

seconds (we reprove this fact in Section L). Thus, Asynchronous SGD can be \(\nicefrac{{1}}{{n}}\sum_{i=1}^{n}\nicefrac{{\tau_{\text{max}}}}{{\tau_{i}}}\) times faster than Minibatch SGD.

Besides Asynchronous SGD, many other strategies utilize parallelization (Dutta et al., 2018; Woodworth et al., 2020; Wu et al., 2022), and can potentially improve over Minibatch SGD.

## 2 Problem and Contribution

In this paper, we seek to find the optimal time complexity in the setting from Section 1: our goal is to provide a lower bound and a method that attains it. Our main contributions are:

1. **Lower bound.** In Sections 4 & 5, we define new Protocols 2 & 3, and a new complexity measure \(\mathsf{m}_{\text{time}}\) (see (6)), which we believe are more appropriate for the analysis of parallel optimization algorithms. In Section 6, we prove the time complexity lower bound for (nonconvex) functions and algorithms that work with parallel asynchronous oracles.
2. **Optimal method.** In Section 7, we develop a minimax optimal method--Rennala3 SGD--that attains this lower bound.

Footnote 3: [https://elaboring.wiki.faturallio.com/Rennala=Questor+the-Full-Noon](https://elaboring.wiki.faturallio.com/Rennala=Questor+the-Full-Noon): Rennala, Queen of the Full Moon is a Legend Boss in Elden Ring. Though not a demiged, Rennala is one of the sharbeness who resides in the Academy of Raya Lavaria. Rennala is a powerful success, head of the Carian Royal family, and extensible leader of the Academy.

In addition, we investigate several other related questions. As an independent result, in Section 8 we prove that all methods which synchronize workers in each iteration (e.g., Minibatch SGD) have _provably_ worse time complexity than asynchronous methods (e.g., Rennala SGD (see Method 4), Asynchronous SGD). In Section A, we extend our theory to the _heterogeneous_ case, in which the workers have access to different distributions (datasets), and provide a lower bound and a new method that attains it. In Section B, we provide the optimal time complexities in the _convex_ setting.

\begin{table}
\begin{tabular}{c c} \hline \hline \multicolumn{2}{c}{**Homogeneous Case**} \\ \hline \multicolumn{1}{c}{**Method**} & \multicolumn{1}{c}{**Time Complexity**} \\ \hline Minibatch SGD & \(\tau_{n}\left(\frac{L\Delta}{\varepsilon}+\frac{\sigma^{2}L\Delta}{n\varepsilon^ {2}}\right)\) \\ \hline Asynchronous SGD (Cohen et al., 2021) & \(\left(\frac{1}{n}\sum\limits_{i=1}^{n}\frac{1}{\tau_{i}}\right)^{-1}\left( \frac{L\Delta}{\varepsilon}+\frac{\sigma^{2}L\Delta}{n\varepsilon^{2}}\right)\) \\ (Mishchenko et al., 2022) & \(\left(\frac{1}{n}\sum\limits_{i=1}^{n}\frac{1}{\tau_{i}}\right)^{-1}\left( \frac{L\Delta}{\varepsilon}+\frac{\sigma^{2}L\Delta}{n\varepsilon^{2}}\right)\) \\ \hline 
\begin{tabular}{c} Rennala SGD (Theorem 7.5) \\ \end{tabular} & \(\min\limits_{m\in[n]}\left[\left(\frac{1}{n}\sum\limits_{i=1}^{n}\frac{1}{ \tau_{i}}\right)^{-1}\left(\frac{L\Delta}{\varepsilon}+\frac{2^{2}L\Delta}{n \varepsilon^{2}}\right)\right]\) \\ \hline \hline Lower Bound (Theorem 6.4) & \(\min\limits_{m\in[n]}\left[\left(\frac{1}{n}\sum\limits_{i=1}^{n}\frac{1}{\tau_ {i}}\right)^{-1}\left(\frac{L\Delta}{\varepsilon}+\frac{2^{2}L\Delta}{n \varepsilon^{2}}\right)\right]\) \\ \hline \hline \end{tabular}
\end{table}
Table 1: **Homogeneous and Heterogeneous Case.** The required time to get an \(\varepsilon\)-stationary point (\(\mathbb{E}[\left\|\nabla f(\widehat{x})\right\|^{2}]\leq\varepsilon\)) in the nonconvex setting, where \(i^{\text{th}}\) worker requires \(\tau_{i}\) seconds to calculate a stochastic gradient. We assume that \(0<\tau_{1}\leq\cdots\leq\tau_{n}\).

Classical Oracle Protocol

Let us recall the classical approach to obtaining lower bounds for optimization algorithms. We need to define a _function class_\(\mathcal{F}\), an _oracle class_\(\mathcal{O}\), and an _algorithm class_\(\mathcal{A}\). We then analyze the complexity of an algorithm \(A=\{A^{k}\}_{k=0}^{\infty}\in\mathcal{A}\), using the following protocol:

```
1:Input: function \(f\in\mathcal{F}\), oracle and distribution \((O,\mathcal{D})\in\mathcal{O}(f)\), algorithm \(A\in\mathcal{A}\)
2:for\(k=0,\ldots,\infty\)do
3:\(x^{k}=A^{k}(g^{1},\ldots,g^{k})\)\(\rhd\)\(x^{0}=A^{0}\) for \(k=0\).
4:\(g^{k+1}=O(x^{k},\xi^{k+1}),\quad\xi^{k+1}\sim\mathcal{D}\)
5:endfor
```

**Protocol 1** Classical Oracle Protocol

More formally, in first-order stochastic optimization, the oracle class \(\mathcal{O}\) returns a random mapping \(O\ :\ \mathbb{R}^{d}\times\mathbb{S}_{\xi}\to\mathbb{R}^{d}\) based on a function \(f\in\mathcal{F}\) and a distribution \(\mathcal{D}\); we use the notation \((O,\mathcal{D})\in\mathcal{O}(f)\). An algorithm \(A=\{A^{k}\}_{k=0}^{\infty}\in\mathcal{A}\) is a sequence such that

\[A^{k}\,:\,\underbrace{\mathbb{R}^{d}\times\cdots\times\mathbb{R}^{d}}_{\text{$k $ times}}\to\mathbb{R}^{d}\ \ \forall k\geq 1,\text{ and }A^{0}\in\mathbb{R}^{d}. \tag{4}\]

Typically, an oracle \(O\) returns an unbiased stochastic gradient that satisfies Assumption 7.3: \(O(x,\xi)=\widehat{\nabla}f(x;\xi)\) for all \(x\in\mathbb{R}^{d}\) and \(\xi\in\mathbb{S}_{\xi}\). Let us fix an oracle class \(\mathcal{O}\). Then, in the nonconvex first-order stochastic setting, we analyze the complexity measure

\[\mathfrak{m}_{\text{oracle}}\left(\mathcal{A},\mathcal{F}\right):=\inf_{A\in \mathcal{A}}\sup_{f\in\mathcal{F}}\sup_{(O,\mathcal{D})\in\mathcal{O}(f)}\inf \left\{k\in\mathbb{N}\,\Big{|}\,\mathbb{E}\left[\left\|\nabla f(x^{k})\right\|^ {2}\right]\leq\varepsilon\right\}, \tag{5}\]

where the sequence \(\{x^{k}\}_{k}\) is generated by Protocol 1. Virtually all previous works are concerned with lower bounds of optimization problems using Protocol 1 and the complexity measure (5) (Nemirovskij and Yudin, 1983; Carmon et al., 2020; Arjevani et al., 2022; Nesterov, 2018).

## 4 Time Oracle Protocol

In the previous sections, we discuss the classical approach to estimating the complexities of algorithms. Briefly, these approaches seek to quantify the worst-case number of iterations or oracle calls that are required to find a solution (see (5)), which is very natural for _sequential_ methods. However, and this is a key observation of our work, this approach is not convenient if we want to analyze _parallel_ methods. We now propose an alternative protocol that can be more helpful in this situation:

```
1:Input: functions \(f\in\mathcal{F}\), oracle and distribution \((O,\mathcal{D})\in\mathcal{O}(f)\), algorithm \(A\in\mathcal{A}\)
2:\(s^{0}=0\)
3:for\(k=0,\ldots,\infty\)do
4:\((t^{k+1},x^{k})=A^{k}(g^{1},\ldots,g^{k})\), \(\rhd t^{k+1}\geq t^{k}\)
5:\((s^{k+1},g^{k+1})=O(t^{k+1},x^{k},s^{k},\xi^{k+1}),\quad\xi^{k+1}\sim\mathcal{D}\)
6:endfor
```

**Protocol 2** Time Oracle Protocol

Protocol 2 is almost identical to Protocol 1 except for one key detail: Protocol 2 requires the algorithms to return a sequence \(\{t^{k+1}\}_{k=1}^{\infty}\) such that \(t^{k+1}\geq t^{k}\geq 0\) for all \(k\geq 0\). We assume that \(t^{0}=0\). We also assume that the oracles take to the input the states \(s^{k}\) and output them (the role of these states will be made clear later). In this case, we provide the following definition of an algorithm.

**Definition 4.1**.: An algorithm \(A=\{A^{k}\}_{k=0}^{\infty}\) is a sequence such that

\[A^{k}\,:\,\underbrace{\mathbb{R}^{d}\times\cdots\times\mathbb{R}^{d}}_{\text{$k $ times}}\to\mathbb{R}_{\geq 0}\times\mathbb{R}^{d}\quad\forall k\geq 1,A^{0} \in\mathbb{R}_{\geq 0}\times\mathbb{R}^{d},\]and, for all \(k\geq 1\) and \(g^{1},\ldots,g^{k}\in\mathbb{R}^{d}\), \(t^{k+1}\geq t^{k},\) where \(t^{k+1}\) and \(t^{k}\) are defined as \((t^{k+1},\cdot)=A^{k}(g^{1},\ldots,g^{k})\) and \((t^{k},\cdot)=A^{k-1}(g^{1},\ldots,g^{k-1}).\)

Let us explain the role of the sequence \(\{t^{k}\}_{k}\). In Protocol 1, an algorithm outputs a point \(x^{k}\) and then asks the oracle: _Provide me a gradient at the point \(x^{k}\)_. In contrast, in Protocol 2 an algorithm outputs a point \(x^{k}\) and a time \(t^{k+1}\), and asks the oracle: _Start calculating a gradient at the point \(x^{k}\) at a time \(t^{k+1}\)_. We have a constraint that \(t^{k+1}\geq t^{k}\) for all \(k\geq 0,\) which means that the algorithm is not allowed to travel into the past.

Using Protocol 2, we propose to use another complexity measure instead of (5):

\[\begin{split}&\mathfrak{m}_{\text{time}}\left(\mathcal{A}, \mathcal{F}\right):=\inf_{A\in\mathcal{A}}\sup_{f\in\mathcal{F}}\sup_{( \mathcal{O},\mathcal{D})\in\mathcal{O}(f)}\inf\left\{t\geq 0\left|\,\mathbb{E} \left[\inf_{k\in S_{t}}\left\|\nabla f(x^{k})\right\|^{2}\right]\leq\varepsilon \right.\right\},\\ & S_{t}:=\left\{k\in\mathbb{N}_{0}\big{|}t^{k}\leq t\right\}, \end{split} \tag{6}\]

where the sequences \(t^{k}\) and \(x^{k}\) are generated by Protocol 2. In (5), we seek to find the _worst-case number of iterations_\(k\) required to get \(\mathbb{E}\left[\left\|\nabla f(x^{k})\right\|^{2}\right]\leq\varepsilon\) for any \(A\in\mathcal{A}.\) In (6), we seek to find the _worst-case case time_\(t\) required to find an \(\varepsilon\)-stationary point for any \(A\in\mathcal{A}.\)

We now provide an example, considering an oracle that calculates a stochastic gradient in \(\tau\) seconds. Let us define the appropriate oracle for this problem:

\[O_{\tau}^{\nabla f}\,:\,\underbrace{\mathbb{R}_{\geq 0}}_{\text{time}}\times \underbrace{\mathbb{R}^{d}}_{\text{point}}\times\underbrace{(\mathbb{R}_{\geq 0} \times\mathbb{R}^{d}\times\{0,1\})}_{\text{input state}}\times\mathbb{S}_{ \xi}\rightarrow\underbrace{(\mathbb{R}_{\geq 0}\times\mathbb{R}^{d}\times\{0,1\})}_{ \text{output state}}\times\mathbb{R}^{d}\]

\[\text{such that }O_{\tau}^{\nabla f}(t,x,(s_{t},s_{x},s_{q}),\xi)=\begin{cases}((t,x,1),& 0),&s_{q}=0,\\ ((s_{t},s_{x},1),&0),&s_{q}=1\text{ and }t<s_{t}+\tau,\\ ((0,0,0),&\widehat{\nabla}f(s_{x};\xi)),&s_{q}=1\text{ and }t\geq s_{t}+\tau, \end{cases} \tag{7}\]

and \(\widehat{\nabla}f\) is a mapping such that \(\widehat{\nabla}f\,:\,\mathbb{R}^{d}\times\mathbb{S}_{\xi}\rightarrow\mathbb{ R}^{d}.\) Further, we additionally assume that \(\widehat{\nabla}f\) is an unbiased \(\sigma^{2}\)-variance-bounded stochastic gradient (see Assumption 7.3).

Note that the oracle \(O_{\tau}^{\nabla f}\) emulates the behavior of a real worker. Indeed, the oracle can return three different outputs. If \(s_{q}=0,\) it means that the oracle has been idle, then "starts the calculation" of the gradient at the point \(x,\) and changes the state \(s_{q}\) to \(1.\) Also, using the state, it remembers the time moment \(t\) when the calculation began and the point \(x.\) Next, if \(s_{q}=1\) and \(t<s_{t}+\tau,\) it means the oracle is still calculating the gradient, so if an algorithm sends time \(t\) such that \(t<s_{t}+\tau,\) then it receives the zero vector. Finally, if \(s_{q}=1,\) as soon as an algorithm sends time \(t\) such that \(t\geq s_{t}+\tau,\) then the oracle will be ready to provide the gradient. Note that the oracle provides the gradient calculated at the point \(x\) that was requested when the oracle was idle. Thus, the time between the request of an algorithm to get the gradient and the time when the algorithm gets the gradient is at least \(\tau\) seconds.

In Protocol 2, we have a game between an algorithm \(A\in\mathcal{A}\) and an oracle class \(\mathcal{O},\) where algorithms can decide the sequence of times \(t^{k}.\) Thus, an algorithm wants to find enough information from an oracle as soon as possible to obtain \(\varepsilon\)-stationary point.

Let us consider an example. For the oracle class \(\mathcal{O}\) that generates the oracle from (7), we can define the SGD method in the following way. We take any starting point \(x^{0}\in\mathbb{R}^{d},\) a step size \(\gamma=\min\left\{\nicefrac{{1}}{{L}},\nicefrac{{\varepsilon}}{{2L\sigma^{2}}}\right\}\) (see Theorem D.8) and define \(A^{k}\,:\,\underbrace{(\mathbb{R}^{d}\times\cdots\times\mathbb{R}^{d})}_{k\text{ times}}\rightarrow\mathbb{R}_{\geq 0}\times\mathbb{R}^{d}\) such that

\[A^{k}(g^{1},\ldots,g^{k})=\begin{cases}\Big{(}\tau\left\lfloor k/2\right\rfloor,x ^{0}-\gamma\sum_{j=1}^{k}g^{k}\Big{)},&k\,\,(\mathrm{mod}\,2)=0,\\ \Big{(}\tau\left(\left\lfloor k/2\right\rfloor+1\right),0\Big{)},&k\,\,(\mathrm{ mod}\,2)=1,\end{cases} \tag{8}\]

for all \(k\geq 1,\) and \(A^{0}=(0,x^{0}).\) Let us explain the behavior of the algorithm. In the first step of Protocol 2, when \(k=0,\) the algorithm requests the gradient at the point \(x^{0}\) at the time \(t^{1}=0\) since \(A^{0}=(0,x^{0})\). The oracle \(O\) changes the state from \(s^{0}_{q}=0\) to \(s^{1}_{q}=1\) and remembers the point \(x^{0}\) in the state \(s^{1}_{x}\). In the second step of the protocol, when \(k=1\), the algorithm calls the oracle at the time \(\tau\left(\left\lfloor\nicefrac{{k}}{{2}}\right\rfloor+1\right)=\tau\). In the oracle, the condition \(t^{2}\geq s^{1}_{t}+\tau\Leftrightarrow\tau\geq 0+\tau\) is satisfied, and it returns the gradient at the point \(x^{0}\). Note that this can only happen if an algorithm does the second call at a time that is greater or equal to \(\tau\).

One can see that after \(\tau K\) seconds, the algorithm returns the point \(x^{2K}=x^{0}-\gamma\sum_{j=0}^{K-1}\widehat{\nabla}f(x^{2j};\xi^{2j+1})\), where \(\xi^{j}\sim\mathcal{D}\) are i.i.d. random variables. The algorithm is equivalent to the SGD method that converges after \(K=\mathrm{O}\left(\nicefrac{{L\Delta}}{{\varepsilon}}+\nicefrac{{\sigma^{2}L \Delta}}{{\varepsilon^{2}}}\right)\) steps for the function class \(\mathcal{F}_{\Delta,L}\) (see Definition 6.1) for \(x^{0}=0\). Thus, the complexity \(\mathfrak{m}_{\text{time}}\left(\{A\},\mathcal{F}_{\Delta,L}\right)\) equals \(\mathrm{O}\left(\tau\times\left(\nicefrac{{L\Delta}}{{\varepsilon}}+\nicefrac{ {\sigma^{2}L\Delta}}{{\varepsilon^{2}}}\right)\right).\)

Actually, any algorithm that was designed for Protocol 1 can be used in Protocol 2 with the oracle (7). Assuming that we have mappings \(A^{k}:\,\mathbb{R}^{d}\times\cdots\times\mathbb{R}^{d}\rightarrow\mathbb{R}^{d}\) for all \(k\geq 1\), we can define mappings \(\widehat{A}^{k}:\,\mathbb{R}^{d}\times\cdots\times\mathbb{R}^{d}\rightarrow \mathbb{R}_{\geq 0}\times\mathbb{R}^{d}\) via

\[\widehat{A}^{k}(g^{1},\ldots,g^{k})=\begin{cases}\Big{(}\tau\left\lfloor k/2 \right\rfloor,A^{\lfloor k/2\rfloor}(g^{2},g^{4},\ldots,g^{2k})\Big{)},&k\ ( \mathrm{mod}\ 2)=0,\\ \Big{(}\tau\left(\left\lfloor k/2\right\rfloor+1\right),0\Big{)},&k\ ( \mathrm{mod}\ 2)=1.\end{cases}\]

For \(k=0\), we define \(\widehat{A}^{0}=(0,A^{0})\).

## 5 Time Multiple Oracles Protocol

The protocol framework from the previous section does not seem to be very powerful because one can easily find the time complexity (6) by knowing (5) and the amount of time that oracle needs to calculate a gradient. In fact, we provide Protocol 2 for simplicity only. We now consider a protocol that works with multiple oracles:

```
1:Input: function(s) \(f\in\mathcal{F}\), oracles and distributions \(\left((O_{1},...,O_{n}),(\mathcal{D}_{1},...,\mathcal{D}_{n})\right)\in \mathcal{O}(f)\), algorithm \(A\in\mathcal{A}\)
2:\(s^{0}_{i}=0\) for all \(i\in[n]\)
3:for\(k=0,\ldots,\infty\)do
4:\((t^{k+1},\nicefrac{{i^{k+1}}}{{x^{k}}})=A^{k}(g^{1},\ldots,g^{k})\), \(\triangleright\)\(t^{k+1}\geq t^{k}\)
5:\((s^{k+1}_{\nicefrac{{i^{k+1}}}{{i}}},g^{k+1})=O_{\nicefrac{{i^{k+1}}}{{i}}}(t^{ k+1},x^{k},s^{k}_{\nicefrac{{i^{k+1}}}{{i}}},\xi^{k+1}),\quad\xi^{k+1}\sim \mathcal{D}_{\nicefrac{{i^{k+1}}}{{i}}}\quad\triangleright\)\(s^{k+1}_{j}=s^{k}_{j}\quad\forall j\neq\nicefrac{{i^{k+1}}}{{i}}\)
6:endfor
```

**Protocol 3** Time Multiple Oracles Protocol

Compared to Protocol 2, Protocol 3 works with multiple oracles, and algorithms return the indices \(i^{k+1}\) of the oracle they want to call. This minor add-on to the protocol enables the possibility of analyzing parallel optimization methods. Also, each oracle \(O_{i}\) can have its own distribution \(\mathcal{D}_{i}\).

Let us consider an example with two oracles \(O_{1}=O_{\tau_{1}}^{\overline{v}f}\) and \(O_{2}=O_{\tau_{2}}^{\overline{v}f}\) from (7). One can see that a "wise" algorithm will first call the oracle \(O_{1}\) with the time \(t^{0}=0\), and then, in the second step, it will call the oracle \(O_{2}\) also with the time \(t^{1}=0\). Note that it is impossible to do the following steps: in the first step an algorithm calls the oracle \(O_{1}\) with the time \(t^{0}=0\), in the second step, the algorithm calls the oracle \(O_{1}\) with the time \(t^{1}=\tau_{1}\) and receives the gradient, in the third step, the algorithm calls the oracle \(O_{2}\) with the time \(t^{2}=0\). Indeed, this can't happen because \(t^{2}<t^{1}\).

An example of a "non-wise" algorithm is an algorithm that, in the first step, calls the oracle \(O_{1}\) with the time \(t^{0}=0\). In the second step, the algorithm calls the oracle \(O_{1}\) with the time \(t^{1}=\tau_{1}\) and receives the gradient. In the third step, the algorithm calls the oracle \(O_{2}\) with the time \(t^{2}=\tau_{1}\). It would mean that the "non-wise" algorithm did not use the oracle \(O_{2}\) for \(\tau_{1}\) seconds. Consequently, the "wise" algorithm can receive two gradients after \(\max\{\tau_{1},\tau_{2}\}\) seconds, while the "non-wise" algorithm can only receive two gradients after \(\tau_{1}+\tau_{2}\) seconds.

We believe that Protocol 3 and the complexity (6) is a better choice for analyzing the complexities of parallel methods than the classical Protocol 1. In the next section, we will use Protocol 3 to obtain lower bounds for parallel optimization methods.

Lower Bound for Parallel Optimization Methods

Considering Protocol 3, we define a special function class \(\mathcal{F}\), oracle class \(\mathcal{O}\), and algorithm class \(\mathcal{A}\). We consider the same function class as Nesterov (2018); Arjevani et al. (2022); Carmon et al. (2020):

**Definition 6.1** (Function Class \(\mathcal{F}_{\Delta,L}\)).: We assume that function \(f:\mathbb{R}^{d}\rightarrow\mathbb{R}\) is differentiable, \(L\)-smooth, i.e., \(\left\|\nabla f(x)-\nabla f(y)\right\|\leq L\left\|x-y\right\|\quad\forall x, y\in\mathbb{R}^{d},\) and \(\Delta\)-bounded, i.e., \(f(0)-\inf_{x\in\mathbb{R}^{d}}f(x)\leq\Delta\). A set of all functions with such properties we denote by \(\mathcal{F}_{\Delta,L}\).

In this paper, we analyze the class of "zero-respecting" algorithms, defined next.

**Definition 6.2** (Algorithm Class \(\mathcal{A}_{\text{ar}}\)).: Let us consider Protocol 3. We say that an algorithm \(A\) from Definition 4.1 is a zero-respecting algorithm, if \(\text{supp}\left(x^{k}\right)\subseteq\bigcup_{j=1}^{k}\text{supp}\left(g^{j }\right)\) for all \(k\in\mathbb{N}_{0},\) where \(\text{supp}(x):=\{i\in[d]\,|\,x_{i}\neq 0\}\). A set of all algorithms with this property we define as \(\mathcal{A}_{\text{ar}}\).

A zero-respecting algorithm does not try to change the coordinates for which no information was received from oracles. This family is considered by Arjevani et al. (2022); Carmon et al. (2020), and includes SGD, Minibatch and Asynchronous SGD, and Adam (Kingma and Ba, 2014).

**Definition 6.3** (Oracle Class \(\mathcal{O}_{\tau_{1},\ldots,\tau_{n}}^{\sigma^{2}}\)).: Let us consider an oracle class such that, for any \(f\in\mathcal{F}_{\Delta,L}\), it returns oracles \(O_{i}=O_{\tau_{i}}^{\nabla f}\) and distributions \(\mathcal{D}_{i}\) for all \(i\in[n],\) where \(\widehat{\nabla}f\) is an unbiased \(\sigma^{2}\)-variance-bounded mapping (see Assumption 7.3). The oracles \(O_{\tau_{i}}^{\nabla f}\) are defined in (7). We define such oracle class as \(\mathcal{O}_{\tau_{1},\ldots,\tau_{n}}^{\sigma^{2}}\). Without loss of generality, we assume that \(0<\tau_{1}\leq\cdots\leq\tau_{n}\).

We take \(\mathcal{O}_{\tau_{1},\ldots,\tau_{n}}^{\sigma^{2}}\) because it emulates the behavior of workers in real systems, where workers can have different processing times (delays) \(\tau_{i}\). Note that \(\mathcal{O}_{\tau_{1},\ldots,\tau_{n}}^{\sigma^{2}}\) has the freedom to choose a mapping \(\widehat{\nabla}f\). We only assume that the mapping is unbiased and \(\sigma^{2}\)-variance-bounded. We are now ready to present our first result; a lower bound:

**Theorem 6.4**.: _Let us consider the oracle class \(\mathcal{O}_{\tau_{1},\ldots,\tau_{n}}^{\sigma^{2}}\) for some \(\sigma^{2}>0\) and \(0<\tau_{1}\leq\cdots\leq\tau_{n}\). We fix any \(L,\Delta>0\) and \(0<\varepsilon\leq c^{\prime}L\Delta\). In view Protocol 3, for any algorithm \(A\in\mathcal{A}_{\text{ar}}\), there exists a function \(f\in\mathcal{F}_{\Delta,L}\) and oracles and distributions \(\left(\left(O_{1},\ldots,O_{n}\right),\left(\mathcal{D}_{1},\ldots,\mathcal{D }_{n}\right)\right)\in\mathcal{O}_{\tau_{1},\ldots,\tau_{n}}^{\sigma^{2}}(f)\) such that \(\mathbb{E}\left[\inf_{k\in S_{t}}\left\|\nabla f(x^{k})\right\|^{2}\right]>\varepsilon,\) where \(S_{t}:=\left\{k\in\mathbb{N}_{0}\big{|}t^{k}\leq t\right\},\) and_

\[t=c\times\min_{m\in[n]}\left[\left(\frac{1}{m}\sum_{i=1}^{m}\frac{1}{\tau_{i}} \right)^{-1}\left(\frac{L\Delta}{\varepsilon}+\frac{\sigma^{2}L\Delta}{m \varepsilon^{2}}\right)\right].\]

_The quantities \(c^{\prime}\) and \(c\) are universal constants._

Theorem 6.4 states that

\[\mathfrak{m}_{\text{time}}\left(\mathcal{A}_{\text{ar}},\mathcal{F}_{\Delta,L} \right)=\Omega\left(\min_{m\in[n]}\left[\left(\frac{1}{m}\sum_{i=1}^{m}\frac{1} {\tau_{i}}\right)^{-1}\left(\frac{L\Delta}{\varepsilon}+\frac{\sigma^{2}L \Delta}{m\varepsilon^{2}}\right)\right]\right). \tag{9}\]

The interpretation behind this complexity will be discussed later in Section 7.3. No algorithms known to us attain (9). For instance, Asynchronous SGD has the time complexity (3). Let us assume that \(\nicefrac{{\sigma^{2}}}{{\varepsilon}}\leq p\) and \(p\in[n]\). Then (lower bound from (9)) \(=\text{O}\left(\left(\frac{1}{p}\sum_{i=1}^{p}\frac{1}{\tau_{i}}\right)^{-1} \left(\frac{L\Delta}{\varepsilon}\right)\right)\). In this case, the lower bound in (9) will be at least \(\left(\frac{1}{n}\sum_{i=1}^{n}\frac{1}{\tau_{i}}\right)^{-1}/\left(\frac{1}{p} \sum_{i=1}^{p}\frac{1}{\tau_{i}}\right)^{-1}\) times smaller. It means that either the obtained lower bound is not tight, or Asynchronous SGD is a suboptimal method. In the following section we provide a method that attains the lower bound. The obtained lower bound is valid even if an algorithm has the freedom to interrupt oracles. See details in Section F.

### Related work

For convex problems, Woodworth et al. (2018) proposed the graph oracle, which generalizes the classical gradient oracle (Nemirovskij and Yudin, 1983; Nesterov, 2018), and provided lower boundsfor a rather general family of parallel methods. Arjevani et al. (2020) analyzed the delayed gradient descent method, which is Asynchronous SGD when all iteration delays \(\delta_{k}=\delta\) are a constant.

As far as we know, Woodworth et al. (2018) provide the most suitable and tightest prior framework for analyzing lower bound complexities for problem (1). However, as we shall see, our framework us more powerful. Moreover, they only consider the convex case. In Section M, we use the framework of Woodworth et al. (2018) and analyze the fixed computation model, where \(i^{\text{th}}\) worker requires \(\tau_{i}\) seconds to calculate stochastic gradients. In Section B, we consider the convex setting and show that the lower bound obtained by their framework is not tight and can be improved. While the graph oracle framework by Woodworth et al. (2018) is related to the classical oracle protocol (Section 3) and also calculates the number of oracle calls in order to get lower bounds, our approach directly estimates the required time. For more details, see Section B and the discussion in Section B.1.1.

```
1:Input: starting point \(x^{0}\), stepsize \(\gamma\), batch size \(S\)
2:Run Method 5 in all workers
3:for\(k=0,1,\ldots,K-1\)do
4: Init \(g^{k}=0\) and \(s=1\)
5:while\(s\leq S\)do
6: Wait for the next worker
7: Receive gradient and iteration index \((g,k^{\prime})\)
8:if\(k^{\prime}=k\)then
9:\(g^{k}=g^{k}+\frac{1}{S}g\); \(s=s+1\)
10:endif
11: Send \((x^{k},k)\) to the worker
12:endwhile
13:\(x^{k+1}=x^{k}-\gamma g^{k}\)
14:endfor
```

**Method 4** Rennala SGD

## 7 Minimax Optimal Method

We now propose and analyze a new method: Rennala SGD (see Method 4). Methods with a similar structure were proposed previously (e.g., (Dutta et al., 2018)), but we are not aware of any method with precisely the same parameters and structure. For us, in this paper, the theoretical bounds are more important than the method itself.

Let us briefly describe the structure of the method. At the start, Method 4 asks all workers to run Method 5. Method 5 is a standard routine: the workers receive points \(x^{k}\) from the server, calculate stochastic gradients, and send them back to the server. Besides that, the workers receive and send the iteration counter \(k\) of the received points \(x^{k}\). At the server's side, in each iteration \(k\), Method 4 calculates \(g^{k}\) and performs the standard gradient-type step \(x^{k+1}=x^{k}-\gamma g^{k}\). The calculation of \(g^{k}\) is done in a loop. The server waits for the workers to receive a stochastic gradient and an iteration index. The most important part of the method is that the server ignores a stochastic gradient if its iteration index is not equal to the current iteration index. In fact, this means that \(g^{k}=(1/s)\sum_{i=1}^{S}\widehat{\nabla}f(x^{k};\xi_{i}),\) where \(\xi_{i}\) are i.i.d. samples. In other words, the server ignores all stochastic gradients that were calculated at the points \(x^{0},\cdots,x^{k-1}\).

It may seem that Method 4 does not fully use the information due to ignoring some stochastic gradients. That contradicts the philosophy of Asynchronous SGD, which tries to use all stochastic gradients calculated in the previous points. Nevertheless, we show that Rennala SGD has _better time complexity_ than Asynchronous SGD, and this complexity matches the lower bound from Theorem 6.4. The fact that Rennala SGD ignores the previous iterates is motivated by the proof of the lower bound in Section 6. In the proof, any algorithm, on the constructed "worst case" function, does not progress to a stationary point if it calculates a stochastic gradient at a non-relevant point. This suggested to us to construct a method that would focus all workers on the last iterate.

### Assumptions

Let us consider the following assumptions.

**Assumption 7.1**.: \(f\) is differentiable & \(L\)-smooth, i.e., \(\left\|\nabla f(x)-\nabla f(y)\right\|\leq L\left\|x-y\right\|,\forall x,y\in \mathbb{R}^{d}\).

**Assumption 7.2**.: There exist \(f^{*}\in\mathbb{R}\) such that \(f(x)\geq f^{*}\) for all \(x\in\mathbb{R}^{d}\).

**Assumption 7.3**.: For all \(x\in\mathbb{R}^{d}\), stochastic gradients \(\widehat{\nabla}f(x;\xi)\) are unbiased and \(\sigma^{2}\)-variance-bounded, i.e., \(\mathbb{E}_{\xi}\left[\widehat{\nabla}f(x;\xi)\right]=\nabla f(x)\) and \(\mathbb{E}_{\xi}\left[\left\|\widehat{\nabla}f(x;\xi)-\nabla f(x)\right\|^{2 }\right]\leq\sigma^{2},\) where \(\sigma^{2}\geq 0\).

### Analysis of Rennala SGD

**Theorem 7.4**.: _Assume that Assumptions 7.1, 7.2 and 7.3 hold. Let us take the batch size \(S=\max\left\{\left|\left.\sigma^{2}/\varepsilon\right|,1\right\},\text{ and }\gamma=\min\left\{\frac{1}{L},\frac{\varepsilon S}{2L\sigma^{2}}\right\}= \Theta\left(\nicefrac{{1}}{{L}}\right)\text{ in Method 4}\). Then after_

\[K\geq\frac{24\Delta L}{\varepsilon}\]

_iterations, the method guarantees that \(\frac{1}{K}\sum_{k=0}^{K-1}\mathbb{E}\left[\left\|\nabla f(x^{k})\right\|^{2} \right]\leq\varepsilon\)._

In the following theorem, we provide the time complexity of Method 4.

**Theorem 7.5**.: _Consider Theorem 7.4. We assume that \(i^{\text{th}}\) worker returns a stochastic gradient every \(\tau_{i}\) seconds for all \(i\in[n]\). Without loss of generality, we assume that \(0<\tau_{1}\leq\cdots\leq\tau_{n}\). Then after_

\[96\times\min_{m\in[n]}\left[\left(\frac{1}{m}\sum_{i=1}^{m}\frac{1}{\tau_{i}} \right)^{-1}\left(\frac{L\Delta}{\varepsilon}+\frac{\sigma^{2}L\Delta}{m \varepsilon^{2}}\right)\right] \tag{10}\]

_seconds, Method 4 guarantees to find an \(\varepsilon\)-stationary point._

This result with Theorem 6.4 state that

\[\mathfrak{m}_{\text{time}}\left(\mathcal{A}_{\text{zr}},\mathcal{F}_{\Delta,L} \right)=\Theta\left(\min_{m\in[n]}\left[\left(\frac{1}{m}\sum_{i=1}^{m}\frac{1 }{\tau_{i}}\right)^{-1}\left(\frac{L\Delta}{\varepsilon}+\frac{\sigma^{2}L \Delta}{m\varepsilon^{2}}\right)\right]\right) \tag{11}\]

for Protocol 3 and and the oracle class \(\mathcal{O}_{\tau_{1},\ldots,\tau_{n}}^{\sigma^{2}}\) from Definition 6.3.

### Discussion

Theorem 7.5 and Theorem 6.4 state that Method 4 is _minimax optimal_ under the assumption that the delays of the workers are fixed and equal to \(\tau_{i}\). Note that this assumption is required only in Theorem 7.5, and Theorem 7.4 holds without it.

In the same setup, the previous works (Cohen et al., 2021; Mishchenko et al., 2022; Koloskova et al., 2022) obtained the weaker time complexity (3). We do not rule out that it might be possible for the analysis, the parameters or the structure of Asynchronous SGD to be improved and obtain the optimal time complexity (10). We leave this to future work. However, instead, we developed Method 4 that has not only the optimal time complexity, but also a very simple structure and analysis (see Section D.4.1). Our claims are supported by experiments in Section J.

The reader can see that we provide the complexity in a nonconstructive way, as the minimization over the parameter \(m\in[n]\). Note that Method 4 _automatically finds the optimal \(m\)_ in (7.5), and it does not require the knowledge of the delays \(\tau_{i}\) to do so! Let us explain the intuition behind the complexity (10). Let \(m^{*}\) be the optimal parameter of (10) with the smallest index. In Section D.4.3, we show that all workers with the delays \(\tau_{i}\) for all \(i>m^{*}\) can be simply ignored since their delays are too large, and their inclusion would only harm the convergence time of the method. So, the method _automatically_ ignores them! However, in Asynchronous SGD, these harmful workers can contribute to the optimization process, which can be the reason for the suboptimality of Asynchronous SGD.

In general, there are two important regimes: \(\nicefrac{{\sigma^{2}}}{{\varepsilon}}\ll n\) ("low noise/large # of workers") and \(\nicefrac{{\sigma^{2}}}{{\varepsilon}}\gg n\) ("high noise/small # of workers"). Intuitively, in the "high noise/small # of workers" regime, (11) is minimized when \(m\) is close to \(n\). However, in the "low noise/large # of workers", the optimal \(m\) can be much smaller than \(n\).

Synchronized Start of Workers

In the previous sections, we obtain the time complexities for the case when the workers asynchronously compute stochastic gradients. It is important that the complexities are obtained assuming that the workers _can start_ their calculations asynchronously. However, in practice, it is common to train machine learning models with multiple workers/GPUs, so that all workers are _synchronized_ after each stochastic gradient calculation (Goyal et al., 2017; Sergeev and Balso, 2018). The simplest example of such a strategy is Minibatch SGD (see Section 1.2). We want to find an answer to the question: what is the best time complexity we can get if we assume that the workers start simultaneously? In Section G, we formalize this setting, and show that the time complexity equals to

\[\mathfrak{m}_{\text{time}}\left(\mathcal{A}_{\text{rr}},\mathcal{F}_{\Delta,L} \right)=\Theta\left(\min_{m\in[n]}\left[\tau_{m}\left(\frac{L\Delta}{\varepsilon }+\frac{\sigma^{2}L\Delta}{m\varepsilon^{2}}\right)\right]\right) \tag{12}\]

for Protocol 2 and the oracle class \(\mathcal{O}_{\tau_{1},\ldots,\tau_{n}}^{\sigma^{2},\text{sync}}\) from Definition G.1. Comparing (11) and (12), one can see that _methods that start the calculations of workers simultaneously are provably worse than methods that allow workers to start the calculations asynchronously_.

## 9 Future Work

In this work, we consider the setup where the times \(\tau_{i}\) are fixed. In future work, one can consider natural, important, and more general scenarios where they can be random, follow some distribution, and/or depend on the random variables \(\xi\) from Assumption 7.3 (be correlated with stochastic gradients).

### Acknowledgements

This work of P. Richtarik and A. Tyurin was supported by the KAUST Baseline Research Scheme (KAUST BRF) and the KAUST Extreme Computing Research Center (KAUST ECRC), and the work of P. Richtarik was supported by the SDAIA-KAUST Center of Excellence in Data Science and Artificial Intelligence (SDAIA-KAUST AI).

## References

* Y. Arjevani, Y. Carmon, J. C. Duchi, D. J. Foster, N. Srebro, and B. Woodworth (2022)Lower bounds for non-convex stochastic optimization. Mathematical Programming, pp. 1-50. Cited by: SS1.
* Y. Arjevani, O. Shamir, and N. Srebro (2020)A tight convergence analysis for stochastic gradient descent with delayed updates. In Algorithmic Learning Theory, pp. 111-132. Cited by: SS1.
* A. Aytekin, H. R. Feyzmahdavian, and M. Johansson (2016)Analysis and implementation of an asynchronous optimization algorithm for the parameter server. arXiv preprint arXiv:1610.05507. Cited by: SS1.
* Y. Carmon, J. C. Duchi, O. Hinder, and A. Sidford (2020)Lower bounds for finding stationary points i. Mathematical Programming184 (1), pp. 71-120. Cited by: SS1.
* J. Chen, X. Pan, R. Monga, S. Bengio, and R. Jozefowicz (2016)Revisiting distributed synchronous sgd. arXiv preprint arXiv:1604.00981. Cited by: SS1.
* A. Cohen, A. Daniely, Y. Drori, T. Koren, and M. Schain (2021)Asynchronous stochastic optimization robust to arbitrary delays. Advances in Neural Information Processing Systems34, pp. 9024-9035. Cited by: SS1.
* A. Cotter, O. Shamir, N. Srebro, and K. Sridharan (2011)Better mini-batch algorithms via accelerated gradient methods. Advances in Neural Information Processing Systems24. Cited by: SS1.
* S. Dutta, G. Joshi, S. Ghosh, P. Dube, and P. Nagpurkar (2018)Slow and stale gradients can win the race: error-runtime trade-offs in distributed SGD. In International Conference on Artificial Intelligence and Statistics, pp. 803-812. Cited by: SS1.

Feyzmahdavian, H. R., Aytekin, A., and Johansson, M. (2016). An asynchronous mini-batch algorithm for regularized stochastic optimization. _IEEE Transactions on Automatic Control_, 61(12):3740-3754.
* Ghadimi and Lan (2013) Ghadimi, S. and Lan, G. (2013). Stochastic first-and zeroth-order methods for nonconvex stochastic programming. _SIAM Journal on Optimization_, 23(4):2341-2368.
* Gower et al. (2019) Gower, R. M., Loizou, N., Qian, X., Sailanbayev, A., Shulgin, E., and Richtarik, P. (2019). SGD: General analysis and improved rates. In _International Conference on Machine Learning_, pages 5200-5209. PMLR.
* Goyal et al. (2017) Goyal, P., Dollar, P., Girshick, R., Noordhuis, P., Wesolowski, L., Kyrola, A., Tulloch, A., Jia, Y., and He, K. (2017). Accurate, large minibatch SGD: Training imagenet in 1 hour. _arXiv preprint arXiv:1706.02677_.
* Khaled and Richtarik (2020) Khaled, A. and Richtarik, P. (2020). Better theory for SGD in the nonconvex world. _arXiv preprint arXiv:2002.03329_.
* Kingma and Ba (2014) Kingma, D. P. and Ba, J. (2014). Adam: A method for stochastic optimization. _arXiv preprint arXiv:1412.6980_.
* Koloskova et al. (2022) Koloskova, A., Stich, S. U., and Jaggi, M. (2022). Sharper convergence guarantees for asynchronous SGD for distributed and federated learning. _arXiv preprint arXiv:2206.08307_.
* Konecny et al. (2016) Konecny, J., McMahan, H. B., Yu, F. X., Richtarik, P., Suresh, A. T., and Bacon, D. (2016). Federated learning: Strategies for improving communication efficiency. _arXiv preprint arXiv:1610.05492_.
* Krizhevsky et al. (2017) Krizhevsky, A., Sutskever, I., and Hinton, G. E. (2017). Imagenet classification with deep convolutional neural networks. _Communications of the ACM_, 60(6):84-90.
* Lan (2020) Lan, G. (2020). _First-order and stochastic optimization methods for machine learning_. Springer.
* LeCun et al. (2010) LeCun, Y., Cortes, C., and Burges, C. (2010). Mnist handwritten digit database. _ATT Labs [Online]. Available: [http://yann.lecun.com/exdb/mnist_](http://yann.lecun.com/exdb/mnist_), 2.
* Mishchenko et al. (2022) Mishchenko, K., Bach, F., Even, M., and Woodworth, B. (2022). Asynchronous SGD beats minibatch SGD under arbitrary delays. _arXiv preprint arXiv:2206.07638_.
* Mishchenko et al. (2018) Mishchenko, K., Iutzeler, F., Malick, J., and Amini, M.-R. (2018). A delay-tolerant proximal-gradient algorithm for distributed learning. In _International Conference on Machine Learning_, pages 3587-3595. PMLR.
* Nemirovskij and Yudin (1983) Nemirovskij, A. S. and Yudin, D. B. (1983). Problem complexity and method efficiency in optimization.
* Nesterov (2018) Nesterov, Y. (2018). _Lectures on convex optimization_, volume 137. Springer.
* Nguyen et al. (2022) Nguyen, J., Malik, K., Zhan, H., Yousefpour, A., Rabbat, M., Malek, M., and Huba, D. (2022). Federated learning with buffered asynchronous aggregation. In _International Conference on Artificial Intelligence and Statistics_, pages 3581-3607. PMLR.
* Nguyen et al. (2018) Nguyen, L., Nguyen, P. H., Dijk, M., Richtarik, P., Scheinberg, K., and Takac, M. (2018). SGD and hogwild! convergence without the bounded gradients assumption. In _International Conference on Machine Learning_, pages 3750-3758. PMLR.
* Recht et al. (2011) Recht, B., Re, C., Wright, S., and Niu, F. (2011). Hogwild!: A lock-free approach to parallelizing stochastic gradient descent. _Advances in Neural Information Processing Systems_, 24.
* Sergeev and Balso (2018) Sergeev, A. and Balso, M. D. (2018). Horovod: Fast and easy distributed deep learning in TensorFlow. _arXiv preprint arXiv:1802.05799_.
* Woodworth et al. (2020) Woodworth, B., Patel, K. K., Stich, S., Dai, Z., Bullins, B., Mcmahan, B., Shamir, O., and Srebro, N. (2020). Is local SGD better than minibatch SGD? In _International Conference on Machine Learning_, pages 10334-10343. PMLR.
* Woodworth et al. (2018)Woodworth, B. E., Wang, J., Smith, A., McMahan, B., and Srebro, N. (2018). Graph oracle models, lower bounds, and gaps for parallel stochastic optimization. _Advances in Neural Information Processing Systems_, 31.
* Wu et al. (2022) Wu, X., Magnusson, S., Feyzmahdavian, H. R., and Johansson, M. (2022). Delay-adaptive step-sizes for asynchronous learning. _arXiv preprint arXiv:2202.08550_.

###### Contents

* 1 Introduction
	* 1.1 Classical theory
	* 1.2 Parallel optimization methods
* 2 Problem and Contribution
* 3 Classical Oracle Protocol
* 4 Time Oracle Protocol
* 5 Time Multiple Oracles Protocol
* 6 Lower Bound for Parallel Optimization Methods
	* 6.1 Related work
* 7 Minimax Optimal Method
	* 7.1 Assumptions
	* 7.2 Analysis of Rennala SGD
	* 7.3 Discussion
* 8 Synchronized Start of Workers
* 9 Future Work
* A Heterogeneous Regime
* A.1 Lower bound
* A.2 Related work and discussion
* A.3 Minimax optimal method
* A.4 Discussion
* B Convex Case
* B.1 Lower Bound
* B.1.1 Discussion
* B.2 Minimax optimal method
* B.2.1 Assumptions
* B.2.2 Analysis of Rennala SGD and Accelerated Rennala SGD in convex case
* C Table of Notations
* D Proofs for Homogeneous Regime
* D.1 The "worst case" function
* D.2 Proof of Theorem 6.4
* D.3 Auxiliary lemmas

[MISSING_PAGE_FAIL:14]

* M Analysis of Fixed-Computation Model Using Graph Oracle Models
* M.1 Example when the lower bound from (Woodworth et al., 2018) is not tight

[MISSING_PAGE_FAIL:16]

### Related work and discussion

The optimization problem (13) is well-investigated by many papers, including (Aytekin et al., 2016; Mishchenko et al., 2018; Nguyen et al., 2022; Wu et al., 2022; Koloskova et al., 2022; Mishchenko et al., 2022). There were attempts to analyze Asynchronous SGD in the heterogeneous regime. For instance, Mishchenko et al. (2022) proved the convergence to a neighborhood of a solution only. In general, it is quite challenging to get good rates for Asynchronous SGD without additional assumptions about the similarity of the functions \(f_{i}\)(Koloskova et al., 2022; Mishchenko et al., 2022).

In the non-stochastic case, when \(\sigma^{2}=0\), Wu et al. (2022) analyzed the PIAG method in the non-stochastic heterogeneous regime and showed convergence. Although the performance of PIAG can be good in practice, in the worst case PIAG requires \(\mathrm{O}\left(\tau_{n}\widehat{L}\Delta/\varepsilon\right)\) seconds to converge, where \(\tau_{n}\) is the time delay of the slowest worker, \(\widehat{L}:=\sqrt{\sum_{i=1}^{n}L_{i}^{2}}\), and \(L_{i}\) is a Lipschitz constant of \(\nabla f_{i}\). Note that the synchronous Minibatch SGD (see Section 1.2) method has the complexity \(\mathrm{O}\left(\tau_{n}L\Delta/\varepsilon\right),\) which is always better.4

Footnote 4: In the nonconvex case, \(\widehat{L}\) can be arbitrarily larger than \(L\).

Our lower bound in Theorem A.2 does not leave hope of breaking the dependence on the worst straggler in the heterogeneous case. In the stochastic case, the lower bound is slightly more optimistic in the regimes when the statistical term (the second term in (14)) is large. If the stragglers do not have too large delays, then their contributions to the _arithmetic_ mean can be small. Note that in Theorem 6.4 in the homogeneous case, we have the _harmonic_ mean of the delays instead.

### Minimax optimal method

In this section, we provide Malenia5 SGD (see Method 6) that is slightly different from Rennala SGD (Method 4). There are two main differences: the first one is that Method 6 has different gradients estimators \(g_{i}^{k}\) for each worker, and the second one is the constraint \(\left(\frac{1}{n}\sum_{i=1}^{n}\nicefrac{{1}}{{B_{i}}}\right)^{-1}<\nicefrac{{ S}}{{n}}\) in the inner loop6. The more gradients we get from the workers, the larger the term \(\left(\frac{1}{n}\sum_{i=1}^{n}\nicefrac{{1}}{{B_{i}}}\right)^{-1}.\)

Footnote 5: [https://aletuning.wiki.f.certraffic.com/malenia=glada60-of-sixiotta11](https://aletuning.wiki.f.certraffic.com/malenia=glada60-of-sixiotta11): Malenia, Blade of Miquella and Malenia, Goddess of Rot is two-phase a Dumpied Boss in Elda Ring. Side’s the twin of Miquella, the most powerful of the Empyeans, and gained renown for her legendary battle against Stanscoring Radha during the Stantering, in which she unfused the power of the Scarlet Rot and reduced Cavlid to mins.

Footnote 6: We assume that \(\left(\frac{1}{n}\sum_{i=1}^{n}\nicefrac{{1}}{{B_{i}}}\right)^{-1}=0\) if exists \(i\in[n]\) such that \(B_{i}=0\).

**Method 6** Malenia SGD

As in Section 7.2, we can provide the convergence theorems.

**Theorem A.3**.: _Assume that Assumptions 7.1 and 7.2 hold for the function \(f\). Assumption 7.3 holds for the function \(f_{i}\) for all \(i\in[n]\). Let us take the parameter \(S=\max\left\{\left\lceil\nicefrac{{\sigma^{2}}}{{\varepsilon}}\right\rceil,n \right\},\) and\(\gamma=\min\left\{\frac{1}{L},\frac{\varepsilon S}{2L\sigma^{2}}\right\}=\Theta\left( \nicefrac{{1}}{{L}}\right)\) in Method 6, then after \(K\geq\nicefrac{{24\Delta L}}{{\varepsilon}}\) iterations the method guarantees that \(\frac{1}{K}\sum_{k=0}^{K-1}\mathbb{E}\left[\left\|\nabla f(x^{k})\right\|^{2} \right]\leq\varepsilon\)._

**Theorem A.4**.: _Let us consider Theorem A.3. We assume that \(i^{\text{th}}\) worker returns a stochastic gradient every \(\tau_{i}\) seconds for all \(i\in[n]\). Without loss of generality, we assume that \(0<\tau_{1}\leq\cdots\leq\tau_{n}\). Then after_

\[96\left(\tau_{n}\frac{L\Delta}{\varepsilon}+\left(\frac{1}{n}\sum_{i=1}^{n} \tau_{i}\right)\frac{\sigma^{2}L\Delta}{n\varepsilon^{2}}\right) \tag{15}\]

_seconds, Method 6 guarantees to find an \(\varepsilon\)-stationary point._

Comparing Theorem A.2 and Theorem A.4, one can see that the complexity (15) is optimal. Note that Theorem A.3 holds without assumptions that the delays \(\tau_{i}\) are fixed.

### Discussion

Unlike Asynchronous SGD and PIAG, Malenia SGD ignores all stochastic gradients that were calculated in the previous iterations, which appears to be counterproductive. Nevertheless, we show that Malenia SGD converges, and the time complexity is optimal with respect to all parameters. Note that Malenia SGD does not require the Lipschitz smoothness of the local functions \(f_{i}\), does not depend on the time delays \(\tau_{i}\), does not need any similarity assumptions about the functions \(f_{i}\), and can be applied to problems where the function is not Lipschitz (does not have bounded gradients). The analysis of the method is elementary and does not go far away from the theory of the classical SGD method. When the ratio \(\nicefrac{{\sigma^{2}}}{{\varepsilon}}\) is large, Malenia SGD is better than Minibatch SGD (see (2)) by \(\Theta\left(\tau_{n}/\left(\frac{1}{n}\sum_{i=1}^{n}\tau_{i}\right)\right)\) times.

## Appendix B Convex Case

### Lower Bound

Let us consider the optimization problem (1) in the case when the function \(f\) is convex. For the convex case, using Protocol 2, we propose to use another complexity measure instead of (6):

\[\mathfrak{m}_{\text{time}}\left(\mathcal{A},\mathcal{F}\right):=\inf_{A\in \mathcal{A}}\sup_{f\in\mathcal{F}}\sup_{(O,\mathcal{D})\in\mathcal{O}(f)}\inf \left\{t\geq 0\left|\,\mathbb{E}\left[\inf_{k\in S_{t}}f(x^{k})\right]-\inf_{x \in Q}f(x)\leq\varepsilon\right.\right\}, \tag{16}\]

where the sequences \(t^{k}\) and \(x^{k}\) are generated by Protocol 2. Let us consider the following class of convex functions:

**Definition B.1** (Function Class \(\mathcal{F}^{\text{conv}}_{R,M,L}\)).:

Let us define \(B_{2}(0,R):=\left\{x\in\mathbb{R}^{d}\mid\|x\|\leq R\right\}.\) We assume that a function \(f\,:\,\mathbb{R}^{d}\rightarrow\mathbb{R}\) is convex, differentiable, \(L\)-smooth on the set \(B_{2}(0,R)\), i.e.,

\[\|\nabla f(x)-\nabla f(y)\|\leq L\left\|x-y\right\|\quad\forall x,y\in B_{2}( 0,R),\]

and \(M\)-Lipschitz on the set \(B_{2}(0,R)\), i.e.,

\[|f(x)-f(y)|\leq M\left\|x-y\right\|\quad\forall x,y\in B_{2}(0,R).\]

A set of all functions with such properties we define as \(\mathcal{F}^{\text{conv}}_{R,M,L}\).

For the convex case, we analyze the following class of algorithms:

**Definition B.2** (Algorithm Class \(\mathcal{A}_{\pi}^{R}\)).: Let us consider Protocol 3. We say that an algorithm \(A\) from Definition 4.1 belongs to a class \(\mathcal{A}_{\pi}^{R}\) iff \(A\in\mathcal{A}_{\pi}\) and \(x^{k}\in B_{2}(0,R)\) for all \(k\geq 0\).

We also define an oracle class:

**Definition B.3** (Oracle Class \(\mathcal{O}_{\tau_{1},\ldots,\tau_{n}}^{\text{conv},\sigma_{1}^{2}}\)).: Let us consider an oracle class such that, for any \(f\in\mathcal{F}_{R,M,L}^{\text{conv}}\), it returns oracles \(O_{i}=O_{\tau_{i}}^{\overline{\varsigma}f}\) and distributions \(\mathcal{D}_{i}\) for all \(i\in[n]\), where \(\widehat{\nabla}f\) is an unbiased \(\sigma^{2}\)-variance-bounded mapping on the set \(B_{2}(0,R)\). The oracles \(O_{\tau_{i}}^{\overline{\varsigma}f}\) are defined in (7). We define such oracle class as \(\mathcal{O}_{\tau_{1},\ldots,\tau_{n}}^{\text{conv},\sigma^{2}}\). Without loss of generality, we assume that \(0<\tau_{1}\leq\cdots\leq\tau_{n}\).

For this setup, we provide the lower bound for the class of convex functions in the next theorem.

**Theorem B.4**.: _Let us consider the oracle class \(\mathcal{O}_{\tau_{1},\ldots,\tau_{n}}^{\text{conv},\sigma^{2}}\) for some \(\sigma^{2}>0\) and \(0<\tau_{1}\leq\cdots\leq\tau_{n}\). We fix any \(R,L,M,\varepsilon>0\) such that \(\sqrt{L}R>c_{1}\sqrt{\varepsilon}>0\) and \(M^{2}R^{2}>c_{2}\varepsilon^{2}\). In the view Protocol 3, for any algorithm \(A\in\mathcal{A}_{\pi}^{R},\) there exists a function \(f\in\mathcal{F}_{R,M,L}^{\text{conv}}\) and oracles and distributions \(((O_{1},\ldots,O_{n}),(\mathcal{D}_{1},\ldots,\mathcal{D}_{n}))\in\mathcal{O}_ {\tau_{1},\ldots,\tau_{n}}^{\text{conv},\sigma^{2}}(f)\) such that_

\[\mathbb{E}\left[\inf_{k\in S_{t}}f(x^{k})\right]-\inf_{x\in B_{2}(0,R)}f(x)>\varepsilon,\]

_where \(S_{t}:=\left\{k\in\mathbb{N}_{0}\big{|}t^{k}\leq t\right\},\) and_

\[t=c\times\min_{m\in[n]}\left[\left(\frac{1}{m}\sum_{i=1}^{m}\frac{1}{\tau_{i}} \right)^{-1}\left(\min\left\{\frac{\sqrt{L}R}{\sqrt{\varepsilon}},\frac{M^{2} R^{2}}{\varepsilon^{2}}\right\}+\frac{\sigma^{2}R^{2}}{m\varepsilon^{2}}\right) \right].\]

_The quantities \(c_{1},\)\(c_{2}\) and \(c\) are universal constants._

#### b.1.1 Discussion

We improve the lower bound obtained by (Woodworth et al., 2018) (see Table 3). Woodworth et al. (2018) try to reduce any optimization problem to an oracle graph. Then, they get a lower bound using the depth and the number of nodes in a graph. Our approach is different, as we directly estimate the required time and avoid the reduction to an oracle graph. One can think that our "oracle graph" is always linear in Protocol 3, but every node in an "oracle graph" is associated with a timestamp and an index. Unlike the oracle in (Woodworth et al., 2018), which always returns a stochastic gradient, our oracle (7) returns a stochastic gradient only if the conditions are satisfied. Also, Woodworth et al. (2018) construct different "worst case" functions and oracles for the "optimization" and "statistical" terms. While our construction consists only of one function and one oracle.

\begin{table}
\begin{tabular}{c c} \hline \hline
**Method** & **Time Complexity** \\ \hline Minibatch SGD & \(\tau_{n}\left(\min\left\{\frac{\sqrt{L}R}{\sqrt{\varepsilon}},\frac{M^{2}R^{2} }{\varepsilon^{2}}\right\}+\frac{\sigma^{2}R^{2}}{n\varepsilon^{2}}\right)\) \\ \hline Asynchronous SGD & \(\left(\frac{1}{n}\sum_{i=1}^{n}\frac{1}{\tau_{i}}\right)^{-1}\left(\frac{RR^{2} }{\varepsilon}+\frac{\sigma^{2}R^{2}}{n\varepsilon^{2}}\right)\) \\ \hline (Accelerated) Remala SGD (Theorems B.9 and B.11) & \(\min\limits_{m\in[n]}\left[\left(\frac{1}{n}\sum_{i=1}^{n}\frac{1}{\tau_{i}} \right)^{-1}\left(\min\left\{\frac{\sqrt{L}R}{\sqrt{\varepsilon}},\frac{M^{2} R^{2}}{\varepsilon^{2}}\right\}+\frac{\sigma^{2}R^{2}}{m\varepsilon^{2}}\right)\right]\) \\ \hline \hline Lower Bound (Theorem B.4) & \(\min\limits_{m\in[n]}\left[\left(\frac{1}{n}\sum_{i=1}^{n}\frac{1}{\tau_{i}} \right)^{-1}\left(\min\left\{\frac{\sqrt{L}R}{\sqrt{\varepsilon}},\frac{M^{2} R^{2}}{\varepsilon^{2}}\right\}+\frac{\sigma^{2}R^{2}}{m\varepsilon^{2}}\right)\right]\) \\ \hline Lower Bound (Section M) (Woodworth et al., 2018) & \(\tau_{1}\min\left\{\frac{\sqrt{L}R}{\sqrt{\varepsilon}},\frac{M^{2}R^{2}R^{2} }{\varepsilon^{2}}\right\}+\left(\frac{1}{n}\sum_{i=1}^{n}\frac{1}{\tau_{i}} \right)^{-1}\frac{\sigma^{2}R^{2}}{n\varepsilon^{2}}\) \\ \hline \hline \end{tabular}
\end{table}
Table 3: **Convex Homogeneous Case.** The required time to get an \(\varepsilon\)-solution in the convex setting, where \(i^{\text{th}}\) worker requires \(\tau_{i}\) seconds to calculate a stochastic gradient. We assume that \(0<\tau_{1}\leq\cdots\leq\tau_{n}\).

### Minimax optimal method

#### b.2.1 Assumptions

Additionally to some assumptions from Section 7.1, we use the following assumptions in the convex case.

**Assumption B.5**.: The function \(f\) is convex and attains the minimum at some point \(x^{*}\in\mathbb{R}^{d}\).

**Assumption B.6**.: The function \(f\) is \(M\)-Lipschitz, i.e.,

\[\left|f(x)-f(y)\right|\leq M\left\|x-y\right\|,\quad\forall x,y\in\mathbb{R}^{ d}.\]

**Assumption B.7**.: For all \(x\in\mathbb{R}^{d}\), stochastic gradients \(\widehat{\nabla}f(x;\xi)\) are unbiased and have \(\sigma^{2}\)-variance-bounded, i.e., \(\mathbb{E}_{\xi\sim\mathcal{D}}\left[\widehat{\nabla}f(x;\xi)\right]\in \partial f(x)\) and \(\mathbb{E}_{\xi\sim\mathcal{D}}\left[\left\|\widehat{\nabla}f(x;\xi)-\mathbb{ E}\left[\widehat{\nabla}f(x;\xi)\right]\right\|^{2}\right]\leq\sigma^{2},\) where \(\sigma^{2}\geq 0\).

#### b.2.2 Analysis of Rennala SGD and Accelerated Rennala SGD in convex case

**Theorem B.8**.: _Assume that Assumptions B.5, B.6 and B.7 hold. Let us take the batch size \(S=\max\left\{\left\lceil\sigma^{2}/M^{2}\right\rceil,1\right\},\) and \(\gamma=\frac{\varepsilon}{M^{2}+\sigma^{2}/S}=\Theta(\nicefrac{{\varepsilon}} {{M^{2}}})\) in Method 4, then after \(K\geq\nicefrac{{2M^{2}R^{2}}}{{\varepsilon^{2}}}\) iterations the method guarantees that \(\mathbb{E}\left[\left(\widehat{x}^{K}\right)\right]-f(x^{*})\leq\varepsilon,\) where \(\widehat{x}^{K}=\frac{1}{K}\sum_{k=0}^{K-1}x^{k}\) and \(R=\left\|x^{*}-x^{0}\right\|.\)_

**Theorem B.9**.: _Let us consider Theorem B.8. We assume that \(i^{\text{th}}\) worker returns a stochastic gradient every \(\tau_{i}\) seconds for all \(i\in[n]\). Without loss of generality, we assume that \(0<\tau_{1}\leq\cdots\leq\tau_{n}.\) Then after_

\[8\min_{m\in[n]}\left[\left(\frac{1}{m}\sum_{i=1}^{m}\frac{1}{\tau_{i}}\right)^ {-1}\left(\frac{M^{2}R^{2}}{\varepsilon^{2}}+\frac{\sigma^{2}R^{2}}{m \varepsilon^{2}}\right)\right] \tag{17}\]

_seconds Method 4 guarantees to find an \(\varepsilon\)-solution._

Let us provide the theorems in the _smooth_ convex case. We consider the accelerated version of Rennala SGD. In particular, we assume that instead of Line 13 in Method 4, we have

\[\gamma_{k+1} =\gamma(k+1),\quad\alpha_{k+1}=2/(k+2) \tag{18}\] \[y^{k+1} =(1-\alpha_{k+1})x^{k}+\alpha_{k+1}u^{k},\qquad(u^{0}=x^{0})\] \[u^{k+1} =u^{k}-\gamma_{k+1}g_{k},\] \[x^{k+1} =(1-\alpha_{k+1})x^{k}+\alpha_{k+1}u^{k+1}.\]

We refer to such method as Accelerated Method 4 or Accelerated Rennala SGD. The acceleration technique is based on (Lan, 2020).

**Theorem B.10**.: _Assume that Assumptions B.5, 7.1 and 7.3 hold. Let us take the batch size \(S=\max\left\{\left[(\sigma^{2}R)/(\varepsilon^{3/2}\sqrt{L})\right],1\right\},\) and \(\gamma=\min\left\{\frac{1}{4L},\left[\frac{3R^{2}S}{4\sigma^{2}(K+1)(K+2)^{2} }\right]^{1/2}\right\}\) in Accelerated Method 4, then after \(K\geq\frac{8\sqrt{L}R}{\sqrt{\varepsilon}}\) iterations the method guarantees that \(\mathbb{E}\left[\left.f(x^{K})\right]-f(x^{*})\leq\varepsilon,\) where \(R\geq\left\|x^{*}-x^{0}\right\|.\)_

**Theorem B.11**.: _Let us consider Theorem B.10. We assume that \(i^{\text{th}}\) worker returns a stochastic gradient every \(\tau_{i}\) seconds for all \(i\in[n]\). Without loss of generality, we assume that \(0<\tau_{1}\leq\cdots\leq\tau_{n}.\) Then after_

\[32\min_{m\in[n]}\left[\left(\frac{1}{m}\sum_{i=1}^{m}\frac{1}{\tau_{i}}\right) ^{-1}\left(\frac{\sqrt{L}R}{\sqrt{\varepsilon}}+\frac{\sigma^{2}R^{2}}{m \varepsilon^{2}}\right)\right]\]

_seconds Accelerated Method 4 guarantees to find an \(\varepsilon\)-solution._

## Appendix C Table of Notations

## Appendix D Proofs for Homogeneous Regime

### The "worst case" function

In this section, we recall the "worst case" function that we use to prove our lower bounds. This is the standard function that is used in nonconvex optimization. Let us define

\[\text{prog}(x):=\max\{i\geq 0\,|\,x_{i}\neq 0\}\quad(x_{0}\equiv 1).\]

In our proofs, we use the construction from (Carmon et al., 2020; Arjevani et al., 2022). For any \(T\in\mathbb{N},\) the authors define

\[F_{T}(x):=-\Psi(1)\Phi(x_{1})+\sum_{i=2}^{T}\left[\Psi(-x_{i-1})\Phi(-x_{i})- \Psi(x_{i-1})\Phi(x_{i})\right], \tag{19}\]

where

\[\Psi(x)=\begin{cases}0,&x\leq 1/2,\\ \exp\left(1-\frac{1}{(2x-1)^{2}}\right),&x\geq 1/2,\end{cases}\quad\text{and}\quad\Phi(x)=\sqrt{e}\int_{-\infty}^{x}e ^{-\frac{1}{2}t^{2}}dt.\]

The main property of the function \(F_{T}(x)\) is that its gradients are large unless \(\text{prog}(x)\geq T.\)

**Lemma D.1** (Carmon et al. (2020); Arjevani et al. (2022)).: _The function \(F_{T}\) satisfies:_

1. \(F_{T}(0)-\inf_{x\in\mathbb{R}^{T}}F_{T}(x)\leq\Delta^{0}T,\) _where_ \(\Delta^{0}=12.\)__
2. _The function_ \(F_{T}\) _is_ \(l_{1}\)_-smooth, where_ \(l_{1}=152.\)__
3. _For all_ \(x\in\mathbb{R}^{T},\)__\(\|\nabla F_{T}(x)\|_{\infty}\leq\gamma_{\infty},\) _where_ \(\gamma_{\infty}=23.\)__
4. _For all_ \(x\in\mathbb{R}^{T},\)__\(\text{prog}(\nabla F_{T}(x))\leq\text{prog}(x)+1.\)__
5. _For all_ \(x\in\mathbb{R}^{T},\) _if_ \(\text{prog}(x)<T,\) _then_ \(\|\nabla F_{T}(x)\|>1.\)__

We use these properties in the proofs.

### Proof of Theorem 6.4

**Theorem 6.4**.: _Let us consider the oracle class \(\mathcal{O}_{\tau_{1},\ldots,\tau_{n}}^{\sigma^{2}}\) for some \(\sigma^{2}>0\) and \(0<\tau_{1}\leq\cdots\leq\tau_{n}.\) We fix any \(L,\Delta>0\) and \(0<\varepsilon\leq c^{\prime}L\Delta.\) In view Protocol 3, for any algorithm \(A\in\mathcal{A}_{\text{tr}},\) there exists a function \(f\in\mathcal{F}_{\Delta,L}\) and oracles and distributions \(\left((O_{1},\ldots,O_{n}),(\mathcal{D}_{1},\ldots,\mathcal{D}_{n})\right) \in\mathcal{O}_{\tau_{1},\ldots,\tau_{n}}^{\sigma^{2}}(f)\) such that \(\mathbb{E}\left[\inf_{k\in S_{t}}\left\|\nabla f(x^{k})\right\|^{2}\right]>\varepsilon,\) where \(S_{t}:=\left\{k\in\mathbb{N}_{0}\big{|}t^{k}\leq t\right\},\) and_

\[t=c\times\min_{m\in[n]}\left[\left(\frac{1}{m}\sum_{i=1}^{m}\frac{1}{\tau_{i} }\right)^{-1}\left(\frac{L\Delta}{\varepsilon}+\frac{\sigma^{2}L\Delta}{m \varepsilon^{2}}\right)\right].\]

_The quantities \(c^{\prime}\) and \(c\) are universal constants._Before we prove the theorem, let us briefly explain the idea. In Steps 1 and 2 of the proof, we construct the appropriate scaled function and stochastic oracles using the function (19). These steps are almost the same as in (Carmon et al., 2020; Arjevani et al., 2022).

In Step 3, we use the zero-chain property of the function (19) and the zero-respecting property of algorithms that would guarantee us that unless oracles send us a non-zero coordinate, an algorithm would not be able to progress to a new coordinate. The oracles send a non-zero coordinate with some probability \(p\). We have \(n\) parallel oracles that flip random coins _in parallel_. With a large probability, we show that will _not_ get a new coordinate earlier than

\[\approx\min_{m\in[n]}\left[\left(\sum_{i=1}^{m}\frac{1}{\tau_{i}}\right)^{-1} \left(\frac{1}{p}+m\right)\right]\]

seconds, where \(\tau_{i}\) are the delays of the oracles. So, with a large probability, we will not be able to solve the optimization earlier than

\[\approx T\times\min_{m\in[n]}\left[\left(\sum_{i=1}^{m}\frac{1}{\tau_{i}} \right)^{-1}\left(\frac{1}{p}+m\right)\right],\]

where \(T\) is the dimension of the problem.

Proof.: (**Step 1**: \(f\in\mathcal{F}_{\Delta,L}\))

Let us fix \(\lambda>0\) and take a function \(f(x):=L\lambda^{2}/l_{1}F_{T}\left(\frac{x}{\lambda}\right),\) where the function \(F_{T}\) is defined in Section D.1. Note that the function \(f\) is \(L\)-smooth:

\[\left\|\nabla f(x)-\nabla f(y)\right\|=L\lambda/l_{1}\left\|F_{T}\left(\frac{x }{\lambda}\right)-F_{T}\left(\frac{y}{\lambda}\right)\right\|\leq L\lambda \left\|\frac{x}{\lambda}-\frac{y}{\lambda}\right\|=L\left\|x-y\right\|\quad \forall x,y\in\mathbb{R}^{d}.\]

Let us take

\[T=\left\lfloor\frac{\Delta l_{1}}{L\lambda^{2}\Delta^{0}}\right\rfloor,\]

then

\[f(0)-\inf_{x\in\mathbb{R}^{T}}f(x)=\frac{L\lambda^{2}}{l_{1}}(F_{T}\left(0 \right)-\inf_{x\in\mathbb{R}^{T}}F_{T}(x))\leq\frac{L\lambda^{2}\Delta^{0}T}{ l_{1}}\leq\Delta.\]

We showed that the function \(f\in\mathcal{F}_{\Delta,L}\).

(**Step 2**: Oracle Class)

In the oracles \(O_{i},\) we have the freedom to choose a mapping \(\widehat{\nabla}f(\cdot;\cdot)\) (see (7)). Let us take

\[[\widehat{\nabla}f(x;\xi)]_{j}:=\nabla_{j}f(x)\left(1+1\left[j>\text{prog}(x) \right]\left(\frac{\xi}{p}-1\right)\right)\quad\forall x\in\mathbb{R}^{T},\]

and \(\mathcal{D}_{i}=\text{Bernouilli}(p)\) for all \(i\in[n],\) where \(p\in(0,1].\) We denote \([x]_{j}\) as the \(j^{\text{th}}\) index of a vector \(x\in\mathbb{R}^{T}.\) It is left to show this mapping is unbiased and \(\sigma^{2}\)-variance-bounded. Indeed,

\[\mathbb{E}\left[\left[\widehat{\nabla}f(x,\xi)\right]_{i}\right]=\nabla_{i}f(x )\left(1+1\left[i>\text{prog}(x)\right]\left(\frac{\mathbb{E}\left[\xi\right] }{p}-1\right)\right)=\nabla_{i}f(x)\]

for all \(i\in[T],\) and

\[\mathbb{E}\left[\left\|\widehat{\nabla}f(x;\xi)-\nabla f(x)\right\|^{2} \right]\leq\max_{j\in[T]}\left|\nabla_{j}f(x)\right|^{2}\mathbb{E}\left[\left( \frac{\xi}{p}-1\right)^{2}\right]\]

because the difference is non-zero only in one coordinate. Thus

\[\mathbb{E}\left[\left\|\widehat{\nabla}f(x,\xi)-\nabla f(x)\right\| ^{2}\right] \leq\frac{\left\|\nabla f(x)\right\|_{\infty}^{2}\left(1-p\right) }{p}=\frac{L^{2}\lambda^{2}\left\|F_{T}\left(\frac{x}{\lambda}\right)\right\|_ {\infty}^{2}\left(1-p\right)}{l_{1}^{2}p}\] \[\leq\frac{L^{2}\lambda^{2}\gamma_{\infty}^{2}(1-p)}{l_{1}^{2}p} \leq\sigma^{2},\]where we take

\[p=\min\left\{\frac{L^{2}\lambda^{2}\gamma_{\infty}^{2}}{\sigma^{2}l_{1}^{2}},1 \right\}.\]

(**Step 3**: Analysis of Protocol)

We choose

\[\lambda=\frac{\sqrt{2\varepsilon}l_{1}}{L}\]

to ensure that \(\left\|\nabla f(x)\right\|^{2}=\frac{L^{2}\lambda^{2}}{l_{1}^{2}}\left\| \nabla F_{T}(\frac{x}{\lambda})\right\|^{2}>2\varepsilon 1\) [prog\((x)<T\)] for all \(x\in\mathbb{R}^{T},\) where we use Lemma D.1. Thus

\[T=\left\lfloor\frac{\Delta L}{2\varepsilon l_{1}\Delta^{\mathbb{O}}}\right\rfloor\]

and

\[p=\min\left\{\frac{2\varepsilon\gamma_{\infty}^{2}}{\sigma^{2}},1\right\}.\]

Protocol 3 generates a sequence \(\{x^{k}\}_{k=0}^{\infty}.\) We have

\[\inf_{k\in S_{t}}\left\|\nabla f(x^{k})\right\|^{2}>2\varepsilon\inf_{k\in S_ {t}}\mathbb{1}\left[\text{prog}(x^{k})<T\right]. \tag{20}\]

Using Lemma D.2 with \(\delta=1/2\) and (20), we obtain

\[\mathbb{E}\left[\inf_{k\in S_{t}}\left\|\nabla f(x^{k})\right\|^{2}\right] \geq 2\varepsilon\mathbb{P}\left(\inf_{k\in S_{t}}\mathbb{1}\left[\text{prog }(x^{k})<T\right]\geq 1\right)>\varepsilon\]

for

\[t=\frac{1}{24}\min_{m\in[n]}\left[\left(\sum_{i=1}^{m}\frac{1}{\tau_{i}}\right) ^{-1}\left(\frac{\sigma^{2}}{2\varepsilon\gamma_{\infty}^{2}}+m\right)\right] \left(\frac{\Delta L}{2\varepsilon l_{1}\Delta^{\mathbb{O}}}-2\right).\]

### Auxillary lemmas

#### d.3.1 Proof of Lemma d.2

**Lemma D.2**.: _Let us fix \(T,T^{\prime}\in\mathbb{N}\) such that \(T\leq T^{\prime},\) consider Protocol 3 with a differentiable function \(f:\,\mathbb{R}^{T^{\prime}}\rightarrow\mathbb{R}\) such that \(\text{prog}(\nabla f(x))\leq\text{prog}(x)+1\) for all \(x\in\text{domain}(f),\) delays \(0<\tau_{1}\leq\cdots\leq\tau_{n},\) distributions \(\mathcal{D}_{i}=\text{Bernouilli}(p)\) and oracles \(O_{i}=O_{\tau_{i}}^{\nabla f}\) for all \(i\in[n],\) mappings_

\[[\widehat{\nabla}f(x;\xi)]_{j}=\nabla_{j}f(x)\left(1+1\left[j>\text{prog}(x) \right]\left(\frac{\xi}{p}-1\right)\right)\quad\forall x\in\mathbb{R}^{T^{ \prime}},\forall\xi\in\{0,1\},\forall j\in[T], \tag{21}\]

_and an algorithm \(A\in\mathcal{A}_{\text{ar}}.\) With probability not less than \(1-\delta,\)_

\[\inf_{k\in S_{t}}\mathbb{1}\left[\text{prog}(x^{k})<T\right]\geq 1\]

_for_

\[t\leq\frac{1}{24}\min_{m\in[n]}\left[\left(\sum_{i=1}^{m}\frac{1}{\tau_{i}} \right)^{-1}\left(\frac{1}{p}+m\right)\right]\left(\frac{T}{2}+\log\delta \right),\]

_where the iterates \(x^{k}\) are defined in Protocol 3._Proof.: **(Part 1):** _Comment: in this part, we formally show that if \(\inf_{k\in S_{t}}\mathbbm{1}\left[\operatorname{prog}(x^{k})<T\right]<1\) holds, then we have the inequality \(\sum_{i=1}^{T}\widehat{t}_{n_{i}}\leq t\), where \(\widehat{t}_{n_{i}}\) are random variables with some known "good" distributions. If \(\inf_{k\in S_{t}}\mathbbm{1}\left[\operatorname{prog}(x^{k})<T\right]<1,\) then it means that exists \(k\) such that \(\operatorname{prog}(x^{k})=T.\) Note that the algorithm is zero-respecting, so it can not progress to \(T^{\text{th}}\) coordinate unless the oracles generate stochastic gradients with non-zero \(1^{\text{st}}\), \(2^{\text{nd}}\),..., \(T^{\text{th}}\) coordinates. The oracles flip coins in parallel, so the algorithm should wait for the moment when the oracles flip a success. At the same time, it takes time to generate a coin (calculate a stochastic gradient), and the oracles can not flip more than \(k\) coins before some time \(\widehat{t}_{k}\). So if the \(\eta_{i}\) is an index of the first success to generate a non-zero \(i^{\text{th}}\) coordinate, then the algorithm should wait at least \(\widehat{t}_{\eta_{i}}\) seconds. Next, we give a formal proof._

Let us fix \(t\geq 0\) and define the smallest index \(k(i)\) of the sequence when the progress \(\operatorname{prog}(x^{k(i)})\) equals \(i:\)

\[k(i):=\inf\big{\{}k\in\mathbb{N}_{0}\,|\,i=\operatorname{prog}(x^{k})\big{\}} \in\mathbb{N}_{0}\cup\{\infty\}.\]

If \(\inf_{k\in S_{t}}\mathbbm{1}\left[\operatorname{prog}(x^{k})<T\right]<1\) holds, then exists \(k\in S_{t}\) such that \(\operatorname{prog}(x^{k})=T,\) thus, by the definition of \(k(T)\), \(t^{k(T)}\leq t^{k}\leq t,\) and \(k(T)<\infty.\) Note that \(t^{k(T)}\) is the smallest time when we make progress to the \(T^{\text{th}}\) coordinate.

Since \(x^{0}=0\) and \(A\) is a zero-respecting algorithm, the algorithm can return a vector \(x^{k}\) with the non-zero first coordinate only if some of returned by the oracles stochastic gradients have the first coordinate not equal to zero. The oracles \(O_{i}\) are constructed in such a way (see (21) and (7)) that they zero out a coordinate based on i.i.d. Bernoulli trials.

**Definition D.3** (Sequence \(k_{j}^{\xi}\)).: Let us consider a set

\[\{k\in\mathbb{N}\,|\,s_{i^{k},q}^{k-1}=1\text{ and }t^{k}\geq s_{i^{k},t}^{k-1}+ \tau_{i^{k}}\},\quad s_{i^{k}}^{k-1}\equiv(s_{i^{k},t}^{k-1},s_{i^{k},q}^{k-1 },s_{i^{k},x}^{k-1}).\]

We order this set and define the result sequence as \(\{k_{j}^{\xi}\}_{j=1}^{m},\) where \(m\in[0,\infty]\) is the size of the sequence. The sequence \(k_{i}^{\xi}\) is a subsequence of iterations where the oracles use the generated Bernouilli random variables in the third output of (7). The sequence \(s_{i^{k}}^{k-1}\) is defined in Protocol 3.

Let \(k_{\text{success}}\) be the _first_ iteration index when the oracles use a draw \(\xi=1,\) i.e.,

\[k_{\text{success}}:=\inf\{k\,|\,\xi^{k}=1\text{ and }k\in\{k_{j}^{\xi}\}_{j=1}^{m }\}\in\mathbb{N}\cup\{\infty\}.\]

Since the algorithm \(A\) is a zero-respecting and the function \(f\) is a zero-chain function, i.e., \(\operatorname{prog}(\nabla f(x))\leq\operatorname{prog}(x)+1\) for all \(x\in\operatorname{domain}(f),\) then \(\operatorname{prog}(g^{k})=\operatorname{prog}(x^{k})=0\) for all \(k<k_{\text{success}}.\) If \(\inf_{k\in S_{t}}\mathbbm{1}\left[\operatorname{prog}(x^{k})<T\right]<1\) holds, then \(k_{\text{success}}<\infty,\) and \(t^{k_{\text{success}}}\leq t^{k(1)}.\)

The oracles use the generated Bernoulli random variables \(\{\xi^{k}\,|\,k\in\{k_{j}^{\xi}\}_{j=1}^{m}\}\). Let us denote the index of the first successful trial as \(\eta_{1}\), i.e.,

\[\eta_{1}:=\inf\{i\,|\,\xi^{k_{i}^{\xi}}=1\text{ and }i\in[1,m]\}\in\mathbb{N} \cup\{\infty\}.\]

The \(i^{\text{th}}\) worker can generate the first Bernoulli random variable not earlier than after \(\tau_{i}\) seconds, the second Bernoulli random variable not earlier than after \(2\tau_{i}\) seconds, and so forth.

**Definition D.4** (Sequence \(\widehat{t}_{k}\)).: Let us consider a _multi-set_ of times

\[\{j\tau_{i}\,|\,j\geq 1,i\in[n]\}\equiv\{\tau_{1},2\tau_{1},\dots\}\uplus \dots\uplus\{\tau_{n},2\tau_{n},\dots\}.\]

We order this multi-set and define the result sequence as \(\{\widehat{t}_{k}\}_{k=1}^{\infty},\) and \(\widehat{t}_{\infty}:=\lim_{k\rightarrow\infty}\widehat{t}_{k}=\infty.\)

Then \(\eta_{1}{}^{\text{th}}\) Bernoulli random variable can not be generated earlier than \(\widehat{t}_{\eta_{1}}\) because \(\widehat{t}_{\eta_{1}}\) is the earliest time when the oracles can generate \(\eta_{1}\) random variables. Therefore, if \(\inf_{k\in S_{t}}\mathbbm{1}\left[\operatorname{prog}(x^{k})<T\right]<1\) holds, then \(\widehat{t}_{\eta_{1}}\leq t^{k_{\text{success}}}\leq t^{k(1)}.\)

Using the same reasoning, \(t^{k(j+1)}\geq t^{k(j)}+\widehat{t}_{\eta_{j+1}},\) where \(\eta_{j+1}\) is the index of the first successful trial of Bernouilli random variables when \(\operatorname{prog}(\cdot)=j\) in the sequence \(x^{k}.\) More formally:

**Definition D.5** (Sequence \(k_{j,i}^{\xi}\)).: Let us consider a set

\[\{k\in\mathbb{N}\,|\,s_{i^{k},q}^{k-1}=1\text{ and }t^{k}\geq s_{i^{k},t}^{k-1}+ \tau_{i^{k}}\text{ and }\text{prog}(s_{i^{k},x}^{k-1})=j\}.\]

We order this set and define the result sequence as \(\{k_{j,i}^{\xi}\}_{i=1}^{m_{j+1}},\) where \(m_{j+1}\in[0,\infty]\) is the size of the sequence. The sequence \(k_{j,i}^{\xi}\) is a subsequence of iterations where the oracles use the generated Bernouilli random variables in (7) when \(\text{prog}(s_{x})=j\).

Then

\[\eta_{j+1}:=\inf\{i\,\big{|}\,\xi^{k_{j,i}^{\xi}}=1\text{ and }i\in[1,m_{j+1}] \}\in\mathbb{N}\cup\{\infty\}\quad\forall j\in\{0,\ldots,T-1\}. \tag{22}\]

By the definition of \(k(j),\)\(x^{k(j)}\) is the first vector of the sequence, that contains a non-zero \(j\)th coordinate. Thus the oracles will start returning stochastic gradients that potentially have a non-zero \(j+1^{\text{th}}\) coordinate starting only from the iteration \(k(j)\). Therefore,

\[t^{k(T)}\geq t^{k(T-1)}+\widehat{t}_{\eta_{T}}\geq\sum_{i=1}^{T}\widehat{t}_{ \eta_{i}}.\]

Combining the observations, if \(\inf_{k\in S_{t}}\mathbbm{1}\left[\text{prog}(x^{k})<T\right]<1\) holds, then \(\sum_{i=1}^{T}\widehat{t}_{\eta_{i}}\leq t^{k(T)}\leq t.\) Thus

\[\mathbb{P}\left(\inf_{k\in S_{t}}\mathbbm{1}\left[\text{prog}(x^{k})<T\right]< 1\right)\leq\mathbb{P}\left(\sum_{i=1}^{T}\widehat{t}_{\eta_{i}}\leq t\right) \quad\forall t\geq 0.\]

In Section D.3.2, we prove the following inequality that we use in Part 2 of the proof.

**Lemma D.6**.: _Let us take \(l_{j+1}\in\mathbb{N}\). Then_

\[\mathbb{P}\left(\eta_{j+1}=l_{j+1}|\eta_{j},\ldots,\eta_{1}\right)\leq(1-p)^{ l_{j+1}-1}p\]

_for all \(j\in\{0,\ldots,T-1\}\)._

**(Part 2):** _Comment: in this part, we use the standard technique to bound the large deviations of the sum \(\sum_{i=1}^{T}\widehat{t}_{\eta_{i}}\)._

Let us fix \(t^{\prime}\geq 0.\) Recall Definition D.4 of \(\{\widehat{t}_{k}\}_{k=1}^{\infty}.\) If the number of workers \(n=1,\) then \(\widehat{t}_{k}=k\tau_{1}\) for all \(k\geq 1.\) For \(n>1,\) the sequence \(\{\widehat{t}_{k}\}_{k=1}^{\infty}\) has more complicated structure and depends on the delays \(\tau_{1},\ldots,\tau_{n}.\)

For any \(k\geq 1,\) if \(\widehat{t}_{k}\leq t^{\prime},\) then \(k\leq\sum_{i=1}^{n}\lfloor\frac{t^{\prime}}{\tau_{i}}\rfloor.\) Indeed, let us assume that \(k>\sum_{i=1}^{n}\lfloor\frac{t^{\prime}}{\tau_{i}}\rfloor.\) The sequence \(\widehat{t}_{k}\) is constructed by the ordering the multi-set \(\{j\tau_{i}\,|\,j\geq 1,i\in[n]\}.\) The number of elements, which are less or equal to \(t^{\prime},\) equals \(\sum_{i=1}^{n}\lfloor\frac{t^{\prime}}{\tau_{i}}\rfloor.\) Thus, we get a contradiction.

It means that

\[\mathbb{P}\left(\widehat{t}_{\eta_{j+1}}\leq t^{\prime}|\eta_{j},\ldots,\eta_{ 1}\right)\leq\mathbb{P}\left(\eta_{j+1}\leq\sum_{i=1}^{n}\left\lfloor\frac{t^ {\prime}}{\tau_{i}}\right\rfloor\Bigg{|}\eta_{j},\ldots,\eta_{1}\right).\]

Using Lemma D.6, we have

\[\mathbb{P}\left(\widehat{t}_{\eta_{j+1}}\leq t^{\prime}|\eta_{j},\ldots,\eta_ {1}\right)\leq\sum_{j=1}^{\sum_{i=1}^{n}\lfloor\frac{t^{\prime}}{\tau_{i}} \rfloor}(1-p)^{j-1}p.\]

If \(0\leq t^{\prime}<\tau_{1},\) then \(\sum_{i=1}^{n}\lfloor\nicefrac{{t^{\prime}}}{{\tau_{i}}}\rfloor=0,\) and

\[\mathbb{P}\left(\widehat{t}_{\eta_{j+1}}\leq t^{\prime}|\eta_{j},\ldots,\eta_ {1}\right)=0.\]

[MISSING_PAGE_FAIL:26]

[MISSING_PAGE_EMPTY:27]

[MISSING_PAGE_EMPTY:28]

\[\leq\sum_{k_{1}<\cdots<k_{l_{j+1}}=1}^{\infty}\mathbb{P}\left(\bigcap_{i=1}^{l_{j+1 }-1}\{\xi^{k_{i}}=0\},\xi^{k_{l_{j+1}}}=1,\bigcap_{i=1}^{l_{j+1}}\left(\{k_{j,i }^{\xi}=k_{i}\}\bigcap A_{k_{i}}\right)\left|\bigcap_{i=1}^{j}\{\eta_{i}=l_{i} \}\right.\right).\]

Let us define \(\sigma(\xi^{1},\ldots,\xi^{k_{l_{j+1}-1}})\) as a sigma-algebra generated by \(\xi^{1},\ldots,\xi^{k_{l_{j+1}-1}}\). Note that, for all \(i\in[l_{j+1}-1],\) the event \(\{\xi^{k_{i}}=0\}\in\sigma(\xi^{1},\ldots,\xi^{k_{l_{j+1}-1}}).\) Also, for all \(i\in[l_{j+1}],\) the event \(\{k_{j,i}^{\xi}=k_{i}\}\bigcap A_{k_{i}}\in\sigma(\xi^{1},\ldots,\xi^{k_{j+1} -1}).\) Finally, since \(k_{i-1,l_{i}}^{\xi}<k_{j,l_{j+1}}^{\xi},\) the event

\[A_{k_{l_{j+1}}}\bigcap\{k_{j,l_{j+1}}^{\xi}=k_{l_{j+1}}\}\bigcap\{\eta_{i}=l_{ i}\}\subseteq\sigma(\xi^{1},\ldots,\xi^{k_{l_{j+1}-1}})\]

for all \(i\in[j].\) Therefore, the event \(\{\xi^{k_{l_{j+1}}}=1\}\) is independent of the event

\[\bigcap_{i=1}^{l_{j+1}-1}\{\xi^{k_{i}}=0\}\bigcap_{i=1}^{l_{j+1}}\left(\{k_{j, i}^{\xi}=k_{i}\}\bigcap A_{k_{i}}\right)\bigcap_{i=1}^{j}\{\eta_{i}=l_{i}\}\in \sigma(\xi^{1},\ldots,\xi^{k_{l_{j+1}-1}})\]

because \(\xi^{k}\) are i.i.d. random variables. Using the independence and the equality \(\mathbb{P}\left(\xi^{k_{l_{j+1}}}=1\right)=p,\) we have

\[\mathbb{P}\left(\eta_{j+1}=l_{j+1}\middle|\bigcap_{i=1}^{j}\{\eta _{i}=l_{i}\}\right)\] \[\leq p\sum_{k_{1}<\cdots<k_{l_{j+1}}=1}^{\infty}\mathbb{P}\left( \bigcap_{i=1}^{l_{j+1}-1}\{\xi^{k_{i}}=0\},\bigcap_{i=1}^{l_{j+1}}\left(\{k_{ j,i}^{\xi}=k_{i}\}\bigcap A_{k_{i}}\right)\middle|\bigcap_{i=1}^{j}\{\eta_{i}=l_{i} \}\right).\]

Since the events \(\{k_{j,l_{j+1}}^{\xi}=k_{l_{j+1}}\}\bigcap A_{k_{l_{j+1}}}\) do not intersect, we can use the additivity of the probability. If \(l_{j+1}=1,\) we get

\[\mathbb{P}\left(\eta_{j+1}=l_{j+1}\middle|\bigcap_{i=1}^{j}\{\eta_{i}=l_{i}\} \right)\leq p\mathbb{P}\left(\bigcup_{i=1}^{\infty}\left(\{k_{j,l_{j+1}}^{\xi}= i\}\bigcap A_{i}\right)\middle|\bigcap_{i=1}^{j}\{\eta_{i}=l_{i}\}\right)\leq p,\]

and prove the lemma for \(l_{j+1}=1.\) Otherwise, if \(l_{j+1}>1,\) we obtain

\[\mathbb{P}\left(\eta_{j+1}=l_{j+1}\middle|\bigcap_{i=1}^{j}\{\eta _{i}=l_{i}\}\right)\] \[\leq p\sum_{k_{1}<\cdots<k_{l_{j+1}-1}=1}^{\infty}\mathbb{P}\left( \bigcap_{i=1}^{l_{j+1}-1}\{\xi^{k_{i}}=0\},\bigcap_{i=1}^{l_{j+1}-1}\left(\{k_{ j,i}^{\xi}=k_{i}\}\bigcap A_{k_{i}}\right),\right.\] \[\left.\bigcup_{i=k_{j+1}-1+1}^{\infty}\left(\{k_{j,l_{j+1}}^{\xi}= i\}\bigcap A_{i}\right)\middle|\bigcap_{i=1}^{j}\{\eta_{i}=l_{i}\}\right).\]

For any events \(A\) and \(B,\) we have \(\mathbb{P}\left(A,B\right)\leq\mathbb{P}\left(A\right),\) thus

\[\mathbb{P}\left(\eta_{j+1}=l_{j+1}\middle|\bigcap_{i=1}^{j}\{\eta _{i}=l_{i}\}\right)\] \[\leq p\sum_{k_{1}<\cdots<k_{l_{j+1}-1}=1}^{\infty}\mathbb{P} \left(\bigcap_{i=1}^{l_{j+1}-1}\{\xi^{k_{i}}=0\},\bigcap_{i=1}^{l_{j+1}-1} \left(\{k_{j,i}^{\xi}=k_{i}\}\bigcap A_{k_{i}}\right)\middle|\bigcap_{i=1}^{j} \{\eta_{i}=l_{i}\}\right).\]

Let us continue for \(l_{j+1}>1\) and rewrite the last inequality:

\[\mathbb{P}\left(\eta_{j+1}=l_{j+1}\middle|\bigcap_{i=1}^{j}\{\eta_{i}=l_{i}\}\right)\]\[\leq p\sum_{k_{1}<\cdots<k_{j+1-1}=1}^{\infty}\mathbb{P}\left(\bigcap_{i=1}^{l_{j+1 }-2}\{\xi^{k_{i}}=0\},\xi^{k_{l_{j+1}-1}}=0,\bigcap_{i=1}^{l_{j+1}-1}\left(\{k_ {j,i}^{\xi}=k_{i}\}\bigcap A_{k_{i}}\right)\right|\bigcap_{i=1}^{j}\{\eta_{i}=l _{i}\}\right).\]

Note that, for all \(i\in[l_{j+1}-2]\), the event \(\{\xi^{k_{i}}=0\}\in\sigma(\xi^{1},\ldots,\xi^{k_{l_{j+1}-2}})\). Also, for all \(i\in[l_{j+1}-1],\) the event \(\{k_{j,i}^{\xi}=k_{i}\}\bigcap A_{k_{i}}\in\sigma(\xi^{1},\ldots,\xi^{k_{j+1}- 2})\). Finally, since \(k_{i-1,l_{i}}^{\xi}<k_{j,l_{j+1}-1}^{\xi},\) the event

\[A_{k_{l_{j+1}-1}}\bigcap\{k_{j,l_{j+1}-1}^{\xi}=k_{l_{j+1}-1}\}\bigcap\{\eta_{ i}=l_{i}\}\subseteq\sigma(\xi^{1},\ldots,\xi^{k_{l_{j+1}-2}})\]

for all \(i\in[j]\). Therefore, the event \(\{\xi^{k_{l_{j+1}-1}}=0\}\) is independent of the event

\[\bigcap_{i=1}^{l_{j+1}-2}\{\xi^{k_{i}}=0\}\bigcap_{i=1}^{l_{j+1}-1}\left(\{k_ {j,i}^{\xi}=k_{i}\}\bigcap A_{k_{i}}\right)\bigcap_{i=1}^{j}\{\eta_{i}=l_{i}\}.\]

Thus, we have

\[\mathbb{P}\left(\eta_{j+1}=l_{j+1}\middle|\bigcap_{i=1}^{j}\{\eta _{i}=l_{i}\}\right)\] \[\leq p(1-p)\sum_{k_{1}<\cdots<k_{j+1-1}=1}^{\infty}\mathbb{P} \left(\bigcap_{i=1}^{l_{j+1}-2}\{\xi^{k_{i}}=0\},\bigcap_{i=1}^{l_{j+1}-1} \left(\{k_{j,i}^{\xi}=k_{i}\}\bigcap A_{k_{i}}\right)\middle|\bigcap_{i=1}^{j }\{\eta_{i}=l_{i}\}\right).\]

Since the events \(\{k_{j,l_{j+1}-1}^{\xi}=k_{l_{j+1}-1}\}\bigcap A_{k_{l_{j+1}-1}}\) do not intersect, we use the additivity of the probability. If \(l_{j+1}=2,\) we get

\[\mathbb{P}\left(\eta_{j+1}=l_{j+1}\middle|\bigcap_{i=1}^{j}\{\eta _{i}=l_{i}\}\right) \leq p(1-p)\mathbb{P}\left(\bigcup_{i=1}^{\infty}\left(\{k_{j,l _{j+1}-1}^{\xi}=i\}\bigcap A_{i}\right)\middle|\bigcap_{i=1}^{j}\{\eta_{i}=l_ {i}\}\right)\] \[\leq p(1-p),\]

and prove the lemma for \(l_{j+1}=2.\) Otherwise, if \(l_{j+1}>2,\) we obtain

\[\mathbb{P}\left(\eta_{j+1}=l_{j+1}\middle|\bigcap_{i=1}^{j}\{\eta _{i}=l_{i}\}\right)\] \[\leq p(1-p)\sum_{k_{1}<\cdots<k_{j+1-2}=1}^{\infty}\mathbb{P} \left(\bigcap_{i=1}^{l_{j+1}-2}\{\xi^{k_{i}}=0\},\bigcap_{i=1}^{l_{j+1}-2} \left(\{k_{j,i}^{\xi}=k_{i}\}\bigcap A_{k_{i}}\right),\right.\] \[\left.\bigcup_{i=k_{j+1}-2+1}^{\infty}\left(\{k_{j,l_{j+1}-1}^{ \xi}=i\}\bigcap A_{i}\right)\middle|\bigcap_{i=1}^{j}\{\eta_{i}=l_{i}\}\right)\] \[\leq p(1-p)\sum_{k_{1}<\cdots<k_{j+1-2}=1}^{\infty}\mathbb{P} \left(\bigcap_{i=1}^{l_{j+1}-2}\{\xi^{k_{i}}=0\},\bigcap_{i=1}^{l_{j+1}-2} \left(\{k_{j,i}^{\xi}=k_{i}\}\bigcap A_{k_{i}}\right)\middle|\bigcap_{i=1}^{j }\{\eta_{i}=l_{i}\}\right),\]

where we use \(\mathbb{P}\left(A,B\right)\leq\mathbb{P}\left(A\right)\) for any events \(A\) and \(B\). Using mathematical induction, we can continue and get that

\[\mathbb{P}\left(\eta_{j+1}=l_{j+1}\middle|\bigcap_{i=1}^{j}\{\eta_{i}=l_{i}\} \right)\leq p(1-p)^{l_{j+1}-1}.\]

#### d.3.3 Lemma d.7

This is a technical lemma that we use in the proof of Lemma D.2.

[MISSING_PAGE_EMPTY:31]

Assume that \(j_{1}^{*}>S+1.\) Since the harmonic mean of a sequence less or equal to the maximum, we have

\[S\left(\sum_{i=1}^{j_{1}^{*}-1}\frac{1}{\tau_{i}}\right)^{-1}<(j_{1}^{*}-1)\left( \sum_{i=1}^{j_{1}^{*}-1}\frac{1}{\tau_{i}}\right)^{-1}\leq\tau_{j_{1}^{*}-1} \leq\tau_{j_{1}^{*}}.\]

This inequality contradicts the definition of \(j_{1}^{*}.\) It means that \(j_{1}^{*}\leq S+1\) and

\[t_{2}\leq\left(\sum_{i=1}^{j_{1}^{*}}\frac{1}{\tau_{i}}\right)^{-1}(S+j_{1}^{*} )\leq\left(\sum_{i=1}^{j_{1}^{*}}\frac{1}{\tau_{i}}\right)^{-1}(2S+1)\leq\left( \sum_{i=1}^{j_{1}^{*}}\frac{1}{\tau_{i}}\right)^{-1}(6S)\leq 6t_{1}.\]

### Proof of Theorems 7.4 and 7.5

#### d.4.1 Proof of Theorems 7.4

**Theorem 7.4**.: _Assume that Assumptions 7.1, 7.2 and 7.3 hold. Let us take the batch size \(S=\max\left\{\left\lceil\nicefrac{{\sigma^{2}}}{{\varepsilon}}\right\rceil,1 \right\},\) and \(\gamma=\min\left\{\frac{1}{L},\frac{\varepsilon S}{2L\sigma^{2}}\right\}= \Theta\left(\nicefrac{{1}}{{L}}\right)\) in Method 4. Then after iterations, the method guarantees that \(\frac{1}{K}\sum_{k=0}^{K-1}\mathbb{E}\left[\left\|\nabla f(x^{k})\right\|^{2} \right]\leq\varepsilon.\)_

Proof.: Note that Method 4 is just the stochastic gradient method with the batch size \(S.\) Method 4 can be rewritten as \(x^{k+1}=x^{k}-\gamma\frac{1}{S}\sum_{i=1}^{S}\widehat{\nabla}f(x^{k};\xi_{i}),\) where the \(\xi_{i}\) are independent random samples. It means that we can use the classical SGD result (see Theorem D.8). For a stepsize

\[\gamma=\min\left\{\frac{1}{L},\frac{\varepsilon S}{2L\sigma^{2}}\right\},\]

we have

\[\frac{1}{K}\sum_{k=0}^{K-1}\mathbb{E}\left[\left\|\nabla f(x^{k})\right\|^{2} \right]\leq\varepsilon,\]

if

\[K\geq\frac{12\Delta L}{\varepsilon}+\frac{12\Delta L\sigma^{2}}{\varepsilon^{2 }S}.\]

Using the choice of \(S,\) we showed that Method 4 converges after

\[K\geq\frac{24\Delta L}{\varepsilon}\]

steps with

\[\gamma=\min\left\{\frac{1}{L},\frac{\varepsilon S}{2L\sigma^{2}}\right\}\geq \frac{1}{2L}.\]

#### d.4.2 The classical SGD theorem

We reprove the classical SGD result (Ghadimi and Lan, 2013; Khaled and Richtarik, 2020).

**Theorem D.8**.: _Assume that Assumptions 7.1 and 7.2 hold. We consider the SGD method:_

\[x^{k+1}=x^{k}-\gamma g(x^{k}),\]

_where_

\[\gamma=\min\left\{\frac{1}{L},\frac{\varepsilon}{2L\sigma^{2}}\right\}\]_For a fixed \(x\in\mathbb{R}^{d}\), \(g(x)\) is a random vector such that \(\mathbb{E}\left[g(x)\right]=\nabla f(x)\),_

\[\mathbb{E}\left[\left\|g(x)-\nabla f(x)\right\|^{2}\right]\leq \sigma^{2}, \tag{26}\]

_and \(g(x^{k})\) are independent vectors for all \(k\geq 0\). Then_

\[\frac{1}{K}\sum_{k=0}^{K-1}\mathbb{E}\left[\left\|\nabla f(x^{k})\right\|^{2} \right]\leq\varepsilon\]

_for_

\[K\geq\frac{4\Delta L}{\varepsilon}+\frac{8\Delta L\sigma^{2}}{ \varepsilon^{2}}.\]

Proof.: From Assumption 7.1, we have

\[f(x^{k+1}) \leq f(x^{k})+\left\langle\nabla f(x^{k}),x^{k+1}-x^{k}\right\rangle +\frac{L}{2}\left\|x^{k+1}-x^{k}\right\|^{2}\] \[=f(x^{k})-\gamma\left\langle\nabla f(x^{k}),g(x^{k})\right\rangle +\frac{L\gamma^{2}}{2}\left\|g(x^{k})\right\|^{2}.\]

We denote \(\mathcal{G}^{k}\) as a sigma-algebra generated by \(g(x^{0}),\ldots,g(x^{k-1})\). Using unbiasedness and (26), we obtain

\[\mathbb{E}\left[\left.f(x^{k+1})\right|\mathcal{G}^{k}\right] \leq f(x^{k})-\gamma\left(1-\frac{L\gamma}{2}\right)\left\|\nabla f (x^{k})\right\|^{2}+\frac{L\gamma^{2}}{2}\mathbb{E}\left[\left.\left\|g^{k}- \nabla f(x^{k})\right\|^{2}\right|\mathcal{G}^{k}\right]\] \[\leq f(x^{k})-\gamma\left(1-\frac{L\gamma}{2}\right)\left\|\nabla f (x^{k})\right\|^{2}+\frac{L\gamma^{2}\sigma^{2}}{2}.\]

Since \(\gamma\leq\nicefrac{{1}}{{L}}\), we get

\[\mathbb{E}\left[\left.f(x^{k+1})\right|\mathcal{G}^{k}\right]\leq f (x^{k})-\frac{\gamma}{2}\left\|\nabla f(x^{k})\right\|^{2}+\frac{L\gamma^{2} \sigma^{2}}{2}.\]

We subtract \(f^{*}\) and take the full expectation to obtain

\[\mathbb{E}\left[f(x^{k+1})-f^{*}\right]\leq\mathbb{E}\left[f(x^{k})-f^{*} \right]-\frac{\gamma}{2}\mathbb{E}\left[\left\|\nabla f(x^{k})\right\|^{2} \right]+\frac{L\gamma^{2}\sigma^{2}}{2}.\]

Next, we sum the inequality for \(k\in\{0,\ldots,K-1\}\):

\[\mathbb{E}\left[\left.f(x^{K})-f^{*}\right] \leq f(x^{0})-f^{*}-\sum_{k=0}^{K-1}\frac{\gamma}{2}\mathbb{E} \left[\left\|\nabla f(x^{k})\right\|^{2}\right]+\frac{KL\gamma^{2}\sigma^{2}} {2}\] \[=\Delta-\sum_{k=0}^{K-1}\frac{\gamma}{2}\mathbb{E}\left[\left\| \nabla f(x^{k})\right\|^{2}\right]+\frac{KL\gamma^{2}\sigma^{2}}{2}.\]

Finally, we rearrange the terms and use that \(\mathbb{E}\left[f(x^{K})-f^{*}\right]\geq 0\):

\[\frac{1}{K}\sum_{k=0}^{K-1}\mathbb{E}\left[\left\|\nabla f(x^{k})\right\|^{2} \right]\leq\frac{2\Delta}{\gamma K}+L\gamma\sigma^{2}.\]

The choice of \(\gamma\) and \(K\) ensures that

\[\frac{1}{K}\sum_{k=0}^{K-1}\mathbb{E}\left[\left\|\nabla f(x^{k})\right\|^{2} \right]\leq\varepsilon.\]

#### d.4.3 Proof of Theorems 7.5

**Theorem 7.5**.: _Consider Theorem 7.4. We assume that \(i^{\text{th}}\) worker returns a stochastic gradient every \(\tau_{i}\) seconds for all \(i\in[n]\). Without loss of generality, we assume that \(0<\tau_{1}\leq\cdots\leq\tau_{n}.\) Then after_

\[96\times\min_{m\in[n]}\left[\left(\frac{1}{m}\sum_{i=1}^{m}\frac{1}{\tau_{i}} \right)^{-1}\left(\frac{L\Delta}{\varepsilon}+\frac{\sigma^{2}L\Delta}{m \varepsilon^{2}}\right)\right] \tag{10}\]

_seconds, Method 4 guarantees to find an \(\varepsilon\)-stationary point._

Proof.: In this setup, the method converges after \(K\times\{\text{time required to collect a batch of the size }S\}\). Without loss of generality, we assume that \(\tau_{1}\leq\cdots\leq\tau_{n}.\)

Let us define time that is enough to collect a batch of the size \(S\) as \(t^{\prime}\). Obviously, one can always take \(t^{\prime}=3\tau_{n}\left\lceil\frac{S}{n}\right\rceil\) and guarantees that every worker calculates at least \(\left\lceil\frac{S}{n}\right\rceil\) stochastic gradients, but we will provide a tighter \(t^{\prime}\).

We define \(B_{i}\) as the number of received gradients with an iteration index equals to \(k\).7 For each worker, there are two options: either the \(i^{\text{th}}\) worker does not send a gradient with an iteration index \(k\) and \(B_{i}=0,\) or it sends at least once and \(B_{i}>0.\)

Footnote 7: Note that a worker may send a gradient from the previous iterations that we ignore in the method.

In the worst case, for \(i^{\text{th}}\) worker, the time required to calculate \(B_{i}\) gradients equals

\[t_{i}:=\begin{cases}\tau_{i}\left(1+B_{i}\right)&B_{i}>0\\ 0&B_{i}=0\end{cases}\]

because either \(B_{i}>0\) and, in the worst case, a worker finishes the calculation of a gradient from the previous iteration (that we ignore) and only then starts the calculation of a gradient of the current iteration \(k,\) or \(B_{i}=0\) and the server does not receive any gradients from a worker.

Note that all workers work in parallel, so our goal is to find feasible points \(t^{\prime}\in\mathbb{R}\) and \(B_{1},\cdots,B_{n}\in\mathbb{N}_{0}\) such that

\[t^{\prime}\geq\max_{i\in[n]}t_{i} \tag{27}\] \[B_{1},\cdots,B_{n}\in\mathbb{N}_{0}\] \[\sum_{i=1}^{n}B_{i}\geq S\]

First, we relax an assumption that \(B_{i}\in\mathbb{N}_{0}\) and assume that \(B_{i}\in\mathbb{R}\) for all \(i\in[n]:\)

\[t^{\prime}\geq\max_{i\in[n]}t_{i} \tag{28}\] \[B_{1},\cdots,B_{n}\in\mathbb{R}\] \[B_{1},\cdots,B_{n}\geq 0\] \[\sum_{i=1}^{n}B_{i}\geq S\]

If \(B_{i}\in\mathbb{R}\) are feasible points of (28), then

\[\max_{i\in[n]}t_{i}=\max_{B_{i}>0}\tau_{i}\left(1+B_{i}\right) \leq\max_{B_{i}>0}\tau_{i}\left(1+\left\lceil B_{i}\right\rceil\right)\] \[\leq\max_{B_{i}>0}\tau_{i}\left(2+B_{i}\right)\leq 2\max_{B_{i}>0 }\tau_{i}\left(1+B_{i}\right)=2\max_{i\in[n]}t_{i}.\]

It means that if \(t^{\prime}\in\mathbb{R}\) and \(B_{1},\cdots,B_{n}\) are feasible points of (28), then \(2t^{\prime}\) and \(\left\lceil B_{1}\right\rceil,\cdots,\left\lceil B_{n}\right\rceil\) are feasible points of (27).

Let us define

\[t^{\prime}(j):=\left(\sum_{i=1}^{j}\frac{1}{\tau_{i}}\right)^{-1}(S+j)\quad \forall j\in[n],\]and take \(j^{*}=\arg\min_{j\in[n]}t^{\prime}(j),\)\(j^{*}\) is the smallest index from all minimizers of \(t^{\prime}(j).\) Let us show that \(t^{\prime}(j^{*})\) and

\[B_{i}=\begin{cases}\frac{t^{\prime}(j^{*})}{\tau_{i}}-1,&i\leq j^{*}\\ 0,&i>j^{*}\end{cases}\]

are feasible points of (28). First, we have

\[\sum_{i=1}^{n}B_{i}=\sum_{i=1}^{j^{*}}\left(\frac{t^{\prime}(j^{*})}{\tau_{i}}- 1\right)=\left(\sum_{i=1}^{j^{*}}\frac{1}{\tau_{i}}\right)^{-1}(S+j^{*})\left( \sum_{i=1}^{j^{*}}\frac{1}{\tau_{i}}\right)-j^{*}=S.\]

Next, we show that \(B_{i}>0\) for all \(i\leq j^{*}.\) If \(j^{*}=1,\) then \(t^{\prime}(1)=\tau_{1}(S+1),\) thus \(B_{1}=S>0.\) If \(j^{*}>1,\) then, by its definition, we have \(t^{\prime}(j^{*})<t^{\prime}(j^{*}-1),\) thus

\[\left(\sum_{i=1}^{j^{*}}\frac{1}{\tau_{i}}\right)^{-1}(S+j^{*})<\left(\sum_{i= 1}^{j^{*}-1}\frac{1}{\tau_{i}}\right)^{-1}(S+j^{*}-1)\,.\]

From this inequality, we get

\[\left(\sum_{i=1}^{j^{*}-1}\frac{1}{\tau_{i}}\right)(S+j^{*})<\left(\sum_{i=1}^{ j^{*}}\frac{1}{\tau_{i}}\right)(S+j^{*}-1)\]

and

\[\left(\sum_{i=1}^{j^{*}}\frac{1}{\tau_{i}}\right)<\frac{1}{\tau_{j^{*}}}\left( S+j^{*}\right).\]

From the last inequality, we get that \(\tau_{j^{*}}<t^{\prime}(j^{*}),\) thus \(B_{i}\geq B_{j^{*}}>0\) for all \(i\leq j^{*}.\) It is left to show that

\[\max_{i\in[n]}t_{i}=\max_{i\leq j^{*}}\tau_{i}\left(B_{i}+1\right)=t^{\prime}( j^{*}).\]

Finally, we can conclude that Method 4 returns a solution after

\[K\times 2t^{\prime}(j^{*})=\frac{48\Delta L}{\varepsilon}\min_{j\in[n]} \left[\left(\sum_{i=1}^{j}\frac{1}{\tau_{i}}\right)^{-1}(S+j)\right]\]

seconds. 

## Appendix E Proofs for Heterogeneous Regime

### Proof of Theorem a.2

**Theorem A.2**.: _Let us consider the oracle class \(\mathcal{O}_{\tau_{1},\ldots,\tau_{n}}^{\sigma^{2},\text{heteg}}\) for some \(\sigma^{2}>0\) and \(0<\tau_{1}\leq\cdots\leq\tau_{n}.\) We fix any \(L,\Delta>0\) and \(0<\varepsilon\leq c^{\prime}L\Delta.\) In the view Protocol 3, for any algorithm \(A\in\mathcal{A}_{\text{ar}},\) there exists a function \(f=\frac{1}{n}\sum_{i=1}^{n}f_{i}\in\mathcal{F}_{\Delta,L}\) and oracles and distributions \(((O_{1},\ldots,O_{n}),(\mathcal{D}_{1},\ldots,\mathcal{D}_{n}))\in\mathcal{O} _{\tau_{1},\ldots,\tau_{n}}^{\sigma^{2},\text{heteg}}(f_{1},\ldots,f_{n})\) such that \(\mathbb{E}\left[\inf_{k\in S_{t}}\left\|\nabla f(x^{k})\right\|^{2}\right]>\varepsilon,\) where \(S_{t}:=\left\{k\in\mathbb{N}_{0}|t^{k}\leq t\right\},\) and_

\[t=c\times\left(\tau_{n}\frac{L\Delta}{\varepsilon}+\left(\frac{1}{n}\sum_{i=1 }^{n}\tau_{i}\right)\frac{\sigma^{2}L\Delta}{n\varepsilon^{2}}\right). \tag{14}\]

_The quantity \(c^{\prime}\) and \(c\) are universal constants._

The structure of the following proof is similar to the proof of Theorem 6.4. In the heterogeneous regime, the main difference is that we have more freedom to choose the functions \(f_{i}.\)Proof.: In (14), we have the sum of two terms. We split the proof in two parts for each of the terms.

**(Part 1)**

**(Step 1**: \(f\in\mathcal{F}_{\Delta,L}\))

Let us fix \(\lambda>0\). We consider the following functions \(f_{i}:\)

\[f_{i}(x):=\begin{cases}0,&i<n,\\ \frac{nL\lambda^{2}}{l_{1}}F_{T}\left(\frac{x}{\lambda}\right),&i=n.\end{cases}\]

Let us show that the function \(f\) is \(L\)-smooth:

\[\left\|\nabla f(x)-\nabla f(y)\right\|=\frac{1}{n}\left\|\sum_{i=1}^{n}\left( \nabla f_{i}(x)-\nabla f_{i}(y)\right)\right\|=\frac{L\lambda}{l_{1}}\left\| \nabla F_{T}\left(\frac{x}{\lambda}\right)-\nabla F_{T}\left(\frac{y}{\lambda }\right)\right\|\leq L\left\|x-y\right\|.\]

Let us take

\[T=\left\lfloor\frac{\Delta l_{1}}{L\lambda^{2}\Delta^{0}}\right\rfloor,\]

then

\[f(0)-\inf_{x\in\mathbb{R}^{T}}f(x)=\frac{1}{n}\frac{nL\lambda^{2}}{l_{1}}(F_{T }\left(0\right)-\inf_{x\in\mathbb{R}^{T}}F_{T}(x))\leq\frac{L\lambda^{2}\Delta ^{0}T}{l_{1}}\leq\Delta.\]

We showed that the function \(f\in\mathcal{F}_{\Delta,L}\).

**(Step 2**: Oracle Class)

In the oracles \(O_{i}\), we have the freedom to choose a mapping \(\widehat{\nabla}f_{i}(\cdot;\cdot)\) (see (7)). In this part of the proof, we simply take non-stochastic mappings \(\widehat{\nabla}f_{i}(x;\xi):=\nabla f_{i}(x)\) that are, obviously, unbiased and \(\sigma^{2}\)-variance-bounded. We can take an arbitrary distribution, for instance, let us take \(\mathcal{D}_{i}=\)Bernouilli(1) for all \(i\in[n]\).

**(Step 3**: Analysis of Protocol)

We take

\[\lambda=\frac{l_{1}\sqrt{\varepsilon}}{L}\]

to ensure that

\[\left\|\nabla f(x)\right\|^{2}=\frac{1}{n^{2}}\left\|\nabla f_{n}(x)\right\|^ {2}=\frac{L^{2}\lambda^{2}}{l_{1}^{2}}\left\|\nabla F_{T}\left(\frac{x}{\lambda }\right)\right\|^{2}>\frac{L^{2}\lambda^{2}}{l_{1}^{2}}=\varepsilon\]

for all \(x\in\mathbb{R}^{T}\) such that \(\text{prog}(x)<T\). Thus

\[T=\left\lfloor\frac{\Delta L}{l_{1}\varepsilon\Delta^{0}}\right\rfloor.\]

Only the \(n^{\text{th}}\) worker contains a nonzero function and can provide a gradient every \(\tau_{n}\) seconds. Since \(A\) is a zero-respecting algorithm and the function \(f_{n}\) is a zero-chain function, for all \(k\geq 0\) such that

\[t^{k}<\tau_{n}T,\]

we have

\[\left\|\nabla f(x^{k})\right\|>\varepsilon\]

because we need at least \(T\) oracle calls to obtain \(\text{prog}(x^{k})\geq T\). It means that

\[\inf_{k\in S_{t}}\left\|\nabla f(x^{k})\right\|^{2}>\varepsilon\]

for

\[t=\tau_{n}\left(\frac{\Delta L}{l_{1}\varepsilon\Delta^{0}}-1\right).\]

We now prove the second part of the lower bound.

**(Part 2)**

**(Step 1**: \(f\in\mathcal{F}_{\Delta,L}\))Let us fix \(\lambda>0\). We assume that \(x=[x_{1},\ldots,x_{n}]\in\mathbb{R}^{nT}\). We define \(x_{i}\in\mathbb{R}^{T}\) as the \(i^{\text{th}}\) block of a vector \(x=[x_{1},\ldots,x_{n}]\in\mathbb{R}^{nT}\). We consider the following functions \(f_{i}\) :

\[f_{i}(x):=\frac{nL\lambda_{i}^{2}}{l_{1}}F_{T}\left(\frac{x_{i}}{\lambda_{i}} \right).\]

The function \(f_{i}\) depends only on a subset of variables \(x_{i}\) from \(x\). Let us show that the function \(f\) is \(L\)-smooth. Indeed, we have

\[\left\|\nabla f_{i}(x)-\nabla f_{i}(y)\right\|=\frac{nL\lambda_{i}}{l_{1}} \left\|\nabla F_{T}\left(\frac{x_{i}}{\lambda_{i}}\right)-\nabla F_{T}\left( \frac{y_{i}}{\lambda_{i}}\right)\right\|\leq nL\left\|x_{i}-y_{i}\right\|\quad \forall i\in[n],\]

and

\[\left\|\nabla f(x)-\nabla f(y)\right\|^{2} =\frac{1}{n^{2}}\left\|\sum_{i=1}^{n}\left(\nabla f_{i}(x)-\nabla f _{i}(y)\right)\right\|^{2}=\frac{1}{n^{2}}\sum_{i=1}^{n}\left\|\nabla f_{i}(x )-\nabla f_{i}(y)\right\|^{2}\] \[\leq\frac{1}{n^{2}}\sum_{i=1}^{n}n^{2}L^{2}\left\|x_{i}-y_{i} \right\|^{2}=L^{2}\left\|x-y\right\|^{2}.\]

Let us take

\[T=\left\lfloor\frac{\Delta l_{1}}{L\sum_{j=1}^{n}\lambda_{j}^{2}\Delta^{0}} \right\rfloor\quad,\]

then

\[f(0)-\inf_{x\in\mathbb{R}^{T}}f(x)=\frac{1}{n}\sum_{i=1}^{n}\frac{nL\lambda_{i} ^{2}}{l_{1}}(F_{T}\left(0\right)-\inf_{x\in\mathbb{R}^{T}}F_{T}(x))\leq\sum_{i= 1}^{n}\frac{L\lambda_{i}^{2}\Delta^{0}T}{l_{1}}\leq\Delta.\]

We showed that the function \(f\in\mathcal{F}_{\Delta,L}\).

**(Step 2**: Oracle Class)

In the oracles \(O_{i}\), we have the freedom to choose a mapping \(\widehat{\nabla}f_{i}(\cdot;\cdot)\) (see (7)). Let us take

\[[\widehat{\nabla}f_{i}(x;\xi)]_{j}:=\nabla_{j}f_{i}(x)\left(1+1\left[j>(i-1)T +\text{prog}(x_{i})\right]\left(\frac{\xi}{p_{i}}-1\right)\right)\quad\forall x \in\mathbb{R}^{nT},\]

\(\mathcal{D}_{i}=\text{Bernouilli}(p_{i})\), and \(p_{i}\in(0,1]\) for all \(i\in[n]\). Let us show it is unbiased and \(\sigma^{2}\)-variance-bounded:

\[\mathbb{E}\left[[\widehat{\nabla}f_{i}(x;\xi)]_{j}\right]=\nabla_{j}f_{i}(x) \left(1+1\left[j>(i-1)T+\text{prog}(x_{i})\right]\left(\frac{\mathbb{E}\left[ \xi\right]}{p_{i}}-1\right)\right)=\nabla_{j}f_{i}(x)\]

for all \(j\in nT\), and

\[\mathbb{E}\left[\left\|\widehat{\nabla}f_{i}(x;\xi)-\nabla f_{i}(x)\right\|^{ 2}\right]\leq\left\|\nabla f_{i}(x)\right\|_{\infty}^{2}\mathbb{E}\left[\left( \frac{\mathbb{E}\left[\xi\right]}{p_{i}}-1\right)^{2}\right]\]

because the difference is non-zero only in one coordinate. Thus

\[\mathbb{E}\left[\left\|\widehat{\nabla}f_{i}(x;\xi)-\nabla f_{i} (x)\right\|^{2}\right] \leq\frac{\left\|\nabla f_{i}(x)\right\|_{\infty}^{2}(1-p_{i})}{p _{i}}=\frac{n^{2}L^{2}\lambda_{i}^{2}\left\|F_{T}\left(\frac{x_{i}}{\lambda_{i }}\right)\right\|_{\infty}^{2}(1-p_{i})}{l_{1}^{2}p_{i}}\] \[\leq\frac{n^{2}L^{2}\lambda_{i}^{2}\gamma_{\infty}^{2}(1-p_{i})} {l_{1}^{2}p_{i}}\leq\sigma^{2},\]

where we take

\[p_{i}=\min\left\{\frac{n^{2}L^{2}\lambda_{i}^{2}\gamma_{\infty}^{2}}{\sigma^{2} l_{1}^{2}},1\right\}.\]

**(Step 3**We fix \(\eta>0\) and choose

\[\lambda_{i}=\frac{l_{1}\sqrt{\eta\varepsilon\tau_{i}}}{L\sqrt{\sum_{i=1}^{n}\tau_{ i}}}\]

to ensure that

\[\left\|\nabla f(x)\right\|^{2} =\frac{1}{n^{2}}\sum_{i=1}^{n}\left\|\nabla f_{i}(x)\right\|^{2}= \sum_{i=1}^{n}\frac{L^{2}\lambda_{i}^{2}}{l_{1}^{2}}\left\|\nabla F_{T_{i}} \left(\frac{x_{i}}{\lambda_{i}}\right)\right\|^{2}\] \[=\sum_{i=1}^{n}\frac{\eta\varepsilon\tau_{i}}{\sum_{i=1}^{n}\tau_ {i}}\left\|\nabla F_{T_{i}}\left(\frac{x_{i}}{\lambda_{i}}\right)\right\|^{2} >\sum_{i=1}^{n}\frac{\eta\varepsilon\tau_{i}}{\sum_{i=1}^{n}\tau_{i}}\mathbbm{ \left[\text{prog}(x_{i})<T\right]} \tag{29}\]

for all \(x=[x_{1},\ldots,x_{n}]\in\mathbb{R}^{T}\). Thus

\[T=\left\lfloor\frac{\Delta L}{\eta\varepsilon l_{1}\Delta^{0}}\right\rfloor\]

and

\[p_{i}=\min\left\{\frac{n^{2}\gamma_{\infty}^{2}\eta\varepsilon\tau_{i}}{ \sigma^{2}\sum_{i=1}^{n}\tau_{i}},1\right\}\quad\forall i\in[n]. \tag{30}\]

Protocol 3 generates the sequence \(\{x^{k}\}_{k=0}^{\infty}\equiv\{[x_{1}^{k},\ldots,x_{n}^{k}]\}_{k=0}^{\infty}\). From (29), we have

\[\inf_{k\in S_{t}}\left\|\nabla f(x^{k})\right\|^{2} >\inf_{k\in S_{t}}\sum_{i=1}^{n}\frac{\eta\varepsilon\tau_{i}}{\sum_{i=1}^{n} \tau_{i}}\mathbbm{1}\left[\text{prog}(x_{i}^{k})<T\right]\geq\sum_{i=1}^{n} \frac{\eta\varepsilon\tau_{i}}{\sum_{i=1}^{n}\tau_{i}}\inf_{k\in S_{t}} \mathbbm{1}\left[\text{prog}(x_{i}^{k})<T\right]. \tag{31}\]

Further, we require the following auxillary lemma. See the proof in Section E.2.

**Lemma E.1**.: _For \(\eta=4,\) with probability not less than \(1/2,\)_

\[\sum_{i=1}^{n}\frac{\eta\varepsilon\tau_{i}}{\sum_{i=1}^{n}\tau_{i}}\inf_{k \in S_{t}}\mathbbm{1}\left[\text{prog}(x_{i}^{k})<T\right]>2\varepsilon\]

_for_

\[t\leq\frac{1}{24}\left(\frac{\sigma^{2}\sum_{i=1}^{n}\tau_{i}}{n^{2}\gamma_{ \infty}^{2}\eta\varepsilon}\right)\left(\frac{T}{2}-1\right).\]

Using Lemma E.1 and (31), we have

\[\mathbb{E}\left[\inf_{k\in S_{t}}\left\|\nabla f(x^{k})\right\|^{2}\right]>\varepsilon\]

for

\[t=\frac{1}{24}\left(\frac{\sigma^{2}\sum_{i=1}^{n}\tau_{i}}{4n^{2}\gamma_{ \infty}^{2}\varepsilon}\right)\left(\frac{\Delta L}{8\varepsilon l_{1}\Delta ^{0}}-2\right).\]

This finishes the proof of Part 2.

### Proof of Lemma e.1

In the following lemma, we use notations from the proof of Theorem A.2.

**Lemma E.1**.: _For \(\eta=4,\) with probability not less than \(1/2,\)_

\[\sum_{i=1}^{n}\frac{\eta\varepsilon\tau_{i}}{\sum_{i=1}^{n}\tau_{i}}\inf_{k \in S_{t}}\mathbbm{1}\left[\text{prog}(x_{i}^{k})<T\right]>2\varepsilon\]

_for_

\[t\leq\frac{1}{24}\left(\frac{\sigma^{2}\sum_{i=1}^{n}\tau_{i}}{n^{2}\gamma_{ \infty}^{2}\eta\varepsilon}\right)\left(\frac{T}{2}-1\right).\]Proof.: Let us fix \(t\geq 0\). Our goal is to show that the probability of an inequality

\[\sum_{i=1}^{n}\frac{\eta\varepsilon\tau_{i}}{\sum_{i=1}^{n}\tau_{i}}\inf_{k\in S_ {t}}\mathbb{1}[\text{prog}(x_{i}^{k})<T]\leq 2\varepsilon \tag{32}\]

is small.

We now use the same reasoning as in Lemma D.2. We use a notation \(\left\{x\right\}_{i}\) is \(i^{\text{th}}\) block of the vector \(x\). Let us fix a worker's index \(i\in[n]\).

**Definition E.2** (Sequence \(k_{i,j,l}^{\xi}\)).: Let us consider a set

\[\left\{k\in\mathbb{N}\,|\,s_{i^{\text{k}},q}^{k-1}=1,t^{k}\geq s_{i^{\text{k}},t}^{k-1}+\tau_{i^{\text{k}}},\text{prog}\left(\left\{s_{i^{\text{k}},x}^{k-1 }\right\}_{i}\right)=j,i^{k}=i\right\},\quad s_{i^{\text{k}}}^{k-1}\equiv(s_{ i^{\text{k}},t}^{k-1},s_{i^{\text{k}},q}^{k-1},s_{i^{\text{k}},x}^{k-1}).\]

We order this set and define the result sequence as \(\left\{k_{i,j,l}^{\xi}\right\}_{i=1}^{m_{i,j+1}},\) where \(m_{i,j+1}\in[0,\infty]\) is the size of the sequence. The sequence \(k_{i,j,l}^{\xi}\) is a subsequence of iterations where the \(i^{\text{th}}\) oracle use the generated Bernouilli random variables in (7) when \(\text{prog}\left(\left\{s_{x}\right\}_{i}\right)=j\). The sequence \(s_{i^{\text{k}}}^{k-1}\) is defined in Protocol 3.

Then

\[\eta_{i,j+1}:=\inf\{l\,|\,\xi^{k_{i,j,l}^{\xi}}=1\text{ and }l\in[1,m_{i,j+1} ]\}\in\mathbb{N}\cup\{\infty\}.\]

The quantity \(\eta_{i,j+1}\) is the index of the first successful trial, when \(\text{prog}(\cdot)=j\) in the \(i^{\text{th}}\) block of the sequence \(x^{k}\). Since the algorithm \(A\) is a zero-respecting algorithm, for all \(k<k_{i,j,\eta_{i,j+1}}^{\xi},\) the progress \(\text{prog}(x_{i}^{k})<j+1\).

As in Lemma D.2 (we skip the proof since the idea is the same. It is only required to use the different notations: \(x^{k}\to x_{i}^{k},\widehat{t}_{\eta_{j}}\to\widehat{t}_{i,\eta_{i,j}}\)), for all \(i\in[n]\), one can show that if \(\inf_{k\in S_{t}}\mathbb{1}\,[\text{prog}(x_{i}^{k})<T]<1\) holds, then \(\sum_{j=1}^{T}\widehat{t}_{i,\eta_{i,j}}\leq t,\) where \(\widehat{t}_{i,k}:=k\tau_{i}\) for all \(k\geq 1\). The time \(\widehat{t}_{i,k}\) is the smallest possible time when the \(i^{\text{th}}\) oracle can return the \(k^{\text{th}}\) stochastic gradient. Thus

\[\mathbb{P}\left(\sum_{i=1}^{n}\frac{\eta\varepsilon\tau_{i}}{\sum_{i=1}^{n} \tau_{i}}\inf_{k\in S_{t}}\mathbb{1}[\text{prog}(x_{i}^{k})<T]\leq 2 \varepsilon\right)\leq\mathbb{P}\left(\sum_{i=1}^{n}\frac{\eta\varepsilon \tau_{i}}{\sum_{i=1}^{n}\tau_{i}}\mathbb{1}\left[\sum_{j=1}^{T}\widehat{t}_{i, \eta_{i,j}}\leq t\right]\leq 2\varepsilon\right).\]

Using (25) with \(n=1\) (and the different notations \(p\to p_{i},\tau_{1}\to\tau_{i},\) and \(\widehat{t}_{\eta_{j}}\to\widehat{t}_{i,\eta_{i,j}}\)), we have

\[\mathbb{P}\left(\sum_{j=1}^{T}\widehat{t}_{i,\eta_{i,j}}\leq t\right)\leq \delta\quad\forall t\leq\frac{\tau_{i}}{24p_{i}}\left(\frac{T}{2}+\log\delta \right). \tag{33}\]

We now rearrange the terms and use Markov's inequality to obtain

\[\mathbb{P}\left(\sum_{i=1}^{n}\frac{\eta\varepsilon\tau_{i}}{\sum _{i=1}^{n}\tau_{i}}\mathbb{1}\left[\sum_{j=1}^{T}\widehat{t}_{i,\eta_{i,j}}>t \right]\leq 2\varepsilon\right)\] \[=\mathbb{P}\left(\sum_{i=1}^{n}\tau_{i}\mathbb{1}\left[\sum_{j=1 }^{T}\widehat{t}_{i,\eta_{i,j}}\leq t\right]\geq\left(1-\frac{2}{\eta}\right) \sum_{i=1}^{n}\tau_{i}\right)\] \[\leq\left(1-\frac{2}{\eta}\right)^{-1}\left(\sum_{i=1}^{n}\tau_{ i}\right)^{-1}\mathbb{E}\left[\sum_{i=1}^{n}\tau_{i}\mathbb{1}\left[\sum_{j=1}^{ T}\widehat{t}_{i,\eta_{i,j}}\leq t\right]\right]\] \[=\left(1-\frac{2}{\eta}\right)^{-1}\left(\sum_{i=1}^{n}\tau_{i} \right)^{-1}\sum_{i=1}^{n}\tau_{i}\mathbb{P}\left(\sum_{j=1}^{T}\widehat{t}_{i,\eta_{i,j}}\leq t\right),\]

for \(\eta>2\). Using the choice of \(p_{i}\) in (30), we have

\[\frac{\tau_{i}}{p_{i}}\geq\frac{\sigma^{2}\sum_{i=1}^{n}\tau_{i}}{n^{2}\gamma_{ \infty}^{2}\eta\varepsilon}\]for all \(i\in[n]\). The last term does not depend on \(i\). Therefore, we can use (33) with

\[t\leq\frac{1}{24}\left(\frac{\sigma^{2}\sum_{i=1}^{n}\tau_{i}}{n^{2}\gamma_{\infty }^{2}\eta\varepsilon}\right)\left(\frac{T}{2}+\log\delta\right)\]

to get

\[\mathbb{P}\left(\sum_{i=1}^{n}\frac{\eta\varepsilon\tau_{i}}{\sum_{i=1}^{n} \tau_{i}}\mathbb{1}\left[\sum_{j=1}^{T}\widehat{t}_{i,\eta_{i,j}}>t\right]\leq 2 \varepsilon\right)\leq\left(1-\frac{2}{\eta}\right)^{-1}\left(\sum_{i=1}^{n} \tau_{i}\right)^{-1}\left(\sum_{i=1}^{n}\tau_{i}\right)\delta=\left(1-\frac{2}{ \eta}\right)^{-1}\delta.\]

Finally, for \(\eta=4\) and \(\delta=1/4,\) we have

\[\mathbb{P}\left(\sum_{i=1}^{n}\frac{\eta\varepsilon\tau_{i}}{\sum_{i=1}^{n} \tau_{i}}\inf_{k\in S_{t}}\mathbb{1}[\text{prog}(x_{i}^{k})<T]\leq 2 \varepsilon\right)\leq\frac{1}{2}.\]

### Proof of Theorem a.3

**Theorem A.3**.: _Assume that Assumptions 7.1 and 7.2 hold for the function \(f\). Assumption 7.3 holds for the function \(f_{i}\) for all \(i\in[n].\) Let us take the parameter \(S=\max\left\{\left\lceil\sigma^{2}/\varepsilon\right\rceil,n\right\},\) and \(\gamma=\min\left\{\frac{1}{L},\frac{\varepsilon S}{2L\sigma_{\varepsilon}^{2} }\right\}=\Theta\left(\nicefrac{{1}}{{L}}\right)\) in Method 6, then after \(K\geq\nicefrac{{24\Delta L}}{{\varepsilon}}\) iterations the method guarantees that \(\frac{1}{K}\sum_{k=0}^{K-1}\mathbb{E}\left[\left\|\nabla f(x^{k})\right\|^{2} \right]\leq\varepsilon.\)_

Proof.: Note that Method 6 can be rewritten as \(x^{k+1}=x^{k}-\gamma\frac{1}{n}\sum_{i=1}^{n}\frac{1}{B_{i}}\sum_{j=1}^{B_{i} }\widehat{\nabla}f_{i}(x^{k};\xi_{i,j}),\) where the \(\xi_{i,j}\) are independent random samples. The variance of the gradient estimator equals

\[\mathbb{E}\left[\left\|\frac{1}{n}\sum_{i=1}^{n}\frac{1}{B_{i}} \sum_{j=1}^{B_{i}}\widehat{\nabla}f_{i}(x^{k};\xi_{i,j})-\nabla f(x^{k}) \right\|^{2}\right]\] \[=\frac{1}{n^{2}}\sum_{i=1}^{n}\mathbb{E}\left[\left\|\frac{1}{B_ {i}}\sum_{j=1}^{B_{i}}\widehat{\nabla}f_{i}(x^{k};\xi_{i,j})-\nabla f_{i}(x^{ k})\right\|^{2}\right]\] \[=\frac{1}{n^{2}}\sum_{i=1}^{n}\frac{1}{B_{i}^{2}}\sum_{j=1}^{B_{i }}\mathbb{E}\left[\left\|\widehat{\nabla}f_{i}(x^{k};\xi_{i,j})-\nabla f_{i}( x^{k})\right\|^{2}\right]\leq\frac{1}{n^{2}}\sum_{i=1}^{n}\frac{\sigma^{2}}{B_{i}}= \left(\frac{1}{n}\sum_{i=1}^{n}\frac{1}{B_{i}}\right)\frac{\sigma^{2}}{n}\leq \frac{\sigma^{2}}{S},\]

where we use the inequality \(\left(\frac{1}{n}\sum_{i=1}^{n}\frac{1}{B_{i}}\right)^{-1}\geq\frac{S}{n},\) We can use the classical SGD result (see Theorem D.8). For a stepsize

\[\gamma=\min\left\{\frac{1}{L},\frac{\varepsilon S}{2L\sigma^{2}}\right\},\]

we have

\[\frac{1}{K}\sum_{k=0}^{K-1}\mathbb{E}\left[\left\|\nabla f(x^{k})\right\|^{2} \right]\leq\varepsilon,\]

if

\[K\geq\frac{12\Delta L}{\varepsilon}+\frac{12\Delta L\sigma^{2}}{\varepsilon^{ 2}S}.\]

Using the choice of \(S,\) we obtain that Method 6 converges after

\[K\geq\frac{24\Delta L}{\varepsilon}\]

steps.

### Proof of Theorem a.4

**Theorem A.4**.: _Let us consider Theorem A.3. We assume that \(i^{\text{th}}\) worker returns a stochastic gradient every \(\tau_{i}\) seconds for all \(i\in[n]\). Without loss of generality, we assume that \(0<\tau_{1}\leq\cdots\leq\tau_{n}.\) Then after_

\[96\left(\tau_{n}\frac{L\Delta}{\varepsilon}+\left(\frac{1}{n}\sum_{i=1}^{n}\tau _{i}\right)\frac{\sigma^{2}L\Delta}{n\varepsilon^{2}}\right) \tag{15}\]

_seconds, Method 6 guarantees to find an \(\varepsilon\)-stationary point._

Proof.: The method converges after \(K\times\)[_time required to collect batches with the sizes \(B_{i}\) such that \(\left(\frac{1}{n}\sum_{i=1}^{n}\nicefrac{{1}}{{B_{i}}}\right)^{-1}\geq\frac{S }{n}\) holds_}.

In the worst case, for \(i^{\text{th}}\) worker, the time required to calculate \(B_{i}\) gradients equals

\[t_{i}:=\tau_{i}\left(1+B_{i}\right)\]

because it is possible that a worker finishes the calculation of a gradient from the previous iteration (that we ignore) and only then starts the calculation of a gradient of the current iteration.

Our goal is to find feasible points \(t^{\prime}\in\mathbb{R}\) and \(B_{1},\cdots,B_{n}\in\mathbb{N}\) such that

\[\begin{split}& t^{\prime}\geq\max_{i\in[n]}t_{i},\\ & B_{1},\cdots,B_{n}\in\mathbb{N},\\ &\left(\frac{1}{n}\sum_{i=1}^{n}\frac{1}{B_{i}}\right)^{-1}\geq \frac{S}{n}.\end{split} \tag{34}\]

Using the same reasoning as in Theorem 7.5, we relax the assumption that \(B_{i}\in\mathbb{N}\) and assume that \(B_{i}\in\mathbb{R}\) for all \(i\in[n]\) :

\[\begin{split}& t^{\prime}\geq\max_{i\in[n]}t_{i}\\ & B_{1},\cdots,B_{n}\in\mathbb{R}\\ & B_{1},\cdots,B_{n}>0\\ &\left(\frac{1}{n}\sum_{i=1}^{n}\frac{1}{B_{i}}\right)^{-1}\geq \frac{S}{n},\end{split} \tag{35}\]

If \(t^{\prime}\in\mathbb{R}\) and \(B_{1},\cdots,B_{n}\) are feasible points of (35), then \(2t^{\prime}\) and \(\left[B_{1}\right],\cdots,\left[B_{n}\right]\) are feasible points of (34). Let us show that \(t^{\prime}=2\left(\tau_{n}+\left(\frac{1}{n}\sum_{i=1}^{n}\tau_{i}\right) \frac{S}{n}\right)\) and \(B_{i}=\frac{t^{\prime}}{\tau_{i}}-1\) are feasible points. Indeed, for all \(i\in[n],\)

\[B_{i}=\frac{t^{\prime}}{\tau_{i}}-1\geq\frac{2\tau_{n}}{\tau_{i}}-1\geq 1.\]

Next, we have

\[\max_{i\in[n]}t_{i}=\max_{i\in[n]}\tau_{i}\left(B_{i}+1\right)=t^{\prime}\]

and

\[\left(\frac{1}{n}\sum_{i=1}^{n}\frac{1}{B_{i}}\right)^{-1}=\left(\frac{1}{n} \sum_{i=1}^{n}\frac{\tau_{i}}{t^{\prime}-\tau_{i}}\right)^{-1}\geq\left(\frac {1}{n}\sum_{i=1}^{n}\frac{2\tau_{i}}{t^{\prime}}\right)^{-1}=\frac{t^{\prime}} {2}\left(\frac{1}{n}\sum_{i=1}^{n}\tau_{i}\right)^{-1}\geq\frac{S}{n},\]

where we use \(t^{\prime}-\tau_{i}\geq t^{\prime}/2+\tau_{i}-\tau_{i}=t^{\prime}/2\) for all \(i\in[n]\). Finally, it means that Method 6 returns a solution after

\[K\times 2t^{\prime}=\frac{96\Delta L}{\varepsilon}\left(\tau_{n}+\left(\frac{1 }{n}\sum_{i=1}^{n}\tau_{i}\right)\frac{S}{n}\right)\]

seconds.

Interrupt Oracle Calculations

Let us define a protocol and an oracle where an algorithm can stop the oracle anytime. If an algorithm stops the oracle, its current calculations are canceled and discarded.

```
1:Input: functions \(f\in\mathcal{F}\), oracles and distributions \(((O_{1},\ldots,O_{n}),(\mathcal{D}_{1},\ldots,\mathcal{D}_{n}))\in\mathcal{O}(f)\), algorithm \(A\in\mathcal{A}\)
2:\(s_{i}^{0}=0\) for all \(i\in[n]\)
3:for\(k=0,\ldots,\infty\)do
4:\((t^{k+1},i^{k+1},\nicefrac{{c^{k}}}{{x^{k}}})=A^{k}(g^{1},\ldots,g^{k})\), \(\triangleright\)\(t^{k+1}\geq t^{k}\)
5:\((s_{i^{k+1}}^{k+1},g^{k+1})=O_{i^{k+1}}(t^{k+1},x^{k},\nicefrac{{c^{k}}}{{s_{i^ {k+1}}^{k}}},\xi^{k+1}),\quad\xi^{k+1}\sim\mathcal{D}\)\(\triangleright\)\(s_{j}^{k+1}=s_{j}^{k}\quad\forall j\neq i^{k+1}\)
6:endfor
```

**Protocol 8** Time Multiple Oracles Protocol With Control

In Protocol 8, we allow algorithms to output the control variables \(c^{k}\) that can be used in the following oracle.

We take an oracle

\[O_{\tau}^{\overline{\psi}f}\,:\,\mathbb{R}_{\geq 0}\times\mathbb{R}^{d}\times \underbrace{(\mathbb{R}_{\geq 0}\times\mathbb{R}^{d}\times\{0,1\})}_{\text{input state}}\times\underbrace{\{0,1\}}_{\text{control}}\times \mathbb{S}_{\xi}\rightarrow\underbrace{(\mathbb{R}_{\geq 0}\times\mathbb{R}^{d}\times\{0,1\})}_{\text{output state}}\times\mathbb{R}^{d}\]

such that

\[O_{\tau}^{\overline{\psi}f}(t,x,(s_{t},s_{x},s_{q}),c,\xi)=\begin{cases}((t,x,1), \qquad\qquad\qquad 0),&c=0\text{ and }s_{q}=0,\\ ((s_{t},s_{x},1),\qquad\qquad\qquad 0),&c=0\text{ and }s_{q}=1\text{ and }t<s_{t}+\tau,\\ ((0,0,0),\qquad\widehat{\nabla}f(s_{x};\xi)),&c=0\text{ and }s_{q}=1\text{ and }t\geq s_{t}+\tau,\\ ((0,0,0),\qquad\qquad\qquad 0),&c=1,\end{cases} \tag{36}\]

and \(\widehat{\nabla}f\) is a mapping such that

\[\widehat{\nabla}f\,:\,\mathbb{R}^{d}\times\mathbb{S}_{\xi}\rightarrow\mathbb{R }^{d}.\]

The oracle (36) generalizes the oracle (7) since an algorithm can send a signal \(c\) to the oracle (36) and interrupt the calculations. Note that if \(c=1\), then (36) has the same behavior as (7). But, if \(c=0\), then the oracle (36) discards all previous information in the state, and changes \(s_{q}\) to \(0\).

Let us define an oracle class:

**Definition F.1** (Oracle Class \(\mathcal{O}_{\tau_{1},\ldots,\tau_{n}}^{\sigma^{2},\text{stop}}\)).:

Let us consider an oracle class such that, for any \(f\in\mathcal{F}_{\Delta,L}\), it returns oracles \(O_{i}=O_{\tau_{i}}^{\overline{\psi}f}\) and distributions \(\mathcal{D}_{i}\) for all \(i\in[n]\), where \(\widehat{\nabla}f\) is an unbiased \(\sigma^{2}\)-variance-bounded mapping (see Assumption 7.3). The oracles \(O_{\tau_{i}}^{\overline{\psi}f}\) are defined in (36). We define such oracle class as \(\mathcal{O}_{\tau_{1},\ldots,\tau_{n}}^{\sigma^{2},\text{stop}}\). Without loss of generality, we assume that \(0<\tau_{1}\leq\cdots\leq\tau_{n}\).

For the oracle class \(\mathcal{O}_{\tau_{1},\ldots,\tau_{n}}^{\sigma^{2},\text{stop}}\), we state that

\[\mathfrak{m}_{\text{time}}\left(\mathcal{A}_{\text{ar}},\mathcal{F}_{\Delta,L} \right)=\Omega\left(\min_{m\in[n]}\left[\left(\frac{1}{m}\sum_{i=1}^{m}\frac{ 1}{\tau_{i}}\right)^{-1}\left(\frac{L\Delta}{\varepsilon}+\frac{\sigma^{2}L \Delta}{m\varepsilon^{2}}\right)\right]\right).\]

The lower bound is the same as for the oracle class from Definition 6.3. We do not provide a formal proof, but a close investigation can reveal that the proof is the same as in Theorem 6.4.

Indeed, in Part 1 of the proof of Lemma D.2, we reduce the the inequality \(\inf_{k\in S_{t}}\mathbb{1}\left[\text{prog}(x^{k})<T\right]<1\) to the inequality \(\sum_{i=1}^{T}\widehat{t}_{\eta_{i}}\leq t\), where \(\widehat{t}_{\eta_{i}}\) is the shortest time when the oracles can draw a successful Bernoulli random variable. The fact that an algorithm can interrupt the oracles can not change the quantity \(\widehat{t}_{\eta_{i}}\).

Time Complexity with Synchronized Start

In this section, we continue and fill up the discussion in Section 8.

Let us design an oracle for the synchronized start setting. We take an oracle

\[O_{\tau_{1},\ldots,\tau_{n}}^{\overline{\psi}f}\,:\,\mathbb{R}_{ \geq 0}\times\mathbb{R}^{d}\times\underbrace{(\mathbb{R}_{\geq 0}\times\mathbb{R}^{d} \times\{0,1\})}_{\text{input state}}\times\underbrace{(\mathbb{S}_{\xi} \times\cdots\times\mathbb{S}_{\xi})}_{n\text{ times}}\rightarrow\underbrace{( \mathbb{R}_{\geq 0}\times\mathbb{R}^{d}\times\{0,1\})}_{\text{output state}}\times \mathbb{R}^{d}\]

such that

\[O_{\tau_{1},\ldots,\tau_{n}}^{\overline{\psi}f}(t,x,(s_{t},s_{x}, s_{q}),(\xi_{1},\ldots,\xi_{n}))=\] \[\begin{cases}((t,x,1),&0),\quad\quad s_{q}=0,\\ ((0,0,0),&0),\quad\quad s_{q}=1\text{ and }t\in[0,s_{t}+\tau_{1}),\\ ((0,0,0),&\widehat{\nabla}f(s_{x};\xi_{1})),\quad\quad s_{q}=1\text{ and }t\in[s_{t}+\tau_{1},s_{t}+\tau_{2}),\\ ((0,0,0),&\sum_{i=1}^{2}\widehat{\nabla}f(s_{x};\xi_{i})),\quad\quad s_{q}=1 \text{ and }t\in[s_{t}+\tau_{2},s_{t}+\tau_{3}),\\ \ldots\\ ((0,0,0),&\sum_{i=1}^{n}\widehat{\nabla}f(s_{x};\xi_{i})),\quad\quad s_{q}=1 \text{ and }t\in[s_{t}+\tau_{n},\infty),\end{cases} \tag{37}\]

and \(\widehat{\nabla}f\) is a mapping such that

\[\widehat{\nabla}f\,:\,\mathbb{R}^{d}\times\mathbb{S}_{\xi}\rightarrow\mathbb{ R}^{d}.\]

We assume that \(\xi^{k+1}\) is a tuple in Protocol 2: \(\xi^{k+1}\equiv(\xi_{1}^{k+1},\ldots,\xi_{n}^{k+1})\sim\mathcal{D}\).

The oracle (37) with Protocol 2 emulates the behavior of a setting where we broadcast an iterate \(x\) to all workers, and they start calculations simultaneously. The workers have different time delays, hence some finish earlier than others. An algorithm can stop the procedure earlier and get calculated stochastic gradients, but other non-calculated ones will be discarded.

For this oracle, we define an oracle class:

**Definition G.1** (Oracle Class \(\mathcal{O}_{\tau_{1},\ldots,\tau_{n}}^{\sigma^{2},\text{sync}}\)).: Let us consider an oracle class such that, for any \(f\in\mathcal{F}_{\Delta,L}\), it return an oracle \(O=\mathcal{O}_{\tau_{1},\ldots,\tau_{n}}^{\overline{\psi}f}\) and a distribution \(\mathcal{D},\) where \(\widehat{\nabla}f\) is an unbiased \(\sigma^{2}\)-variance-bounded mapping (see Assumption 7.3). The oracle \(O_{\tau_{1},\ldots,\tau_{n}}^{\overline{\psi}f}\) is defined in (37). We define such oracle class as \(\mathcal{O}_{\tau_{1},\ldots,\tau_{n}}^{\sigma^{2},\text{sync}}\). Without loss of generality, we assume that \(0<\tau_{1}\leq\cdots\leq\tau_{n}\).

We now provide the lower bound for Protocol 2 and the oracle class \(\mathcal{O}_{\tau_{1},\ldots,\tau_{n}}^{\sigma^{2},\text{sync}}\).

**Theorem G.2**.: _Let us consider the oracle class \(\mathcal{O}_{\tau_{1},\ldots,\tau_{n}}^{\sigma^{2},\text{sync}}\) for some \(\sigma^{2}>0\) and \(0<\tau_{1}\leq\cdots\leq\tau_{n}\). We fix any \(L,\Delta>0\) and \(0<\varepsilon\leq c^{\prime}L\Delta\). In the view Protocol 2, for any algorithm \(A\in\mathcal{A}_{\text{ar}}\), there exists a function \(f\in\mathcal{F}_{\Delta,L}\) and an oracle and a distribution \((O,\mathcal{D})\in\mathcal{O}_{\tau_{1},\ldots,\tau_{n}}^{\sigma^{2},\text{ sync}}(f)\) such that \(\mathbb{E}\left[\inf_{k\in S_{t}}\left\|\nabla f(x^{k})\right\|^{2}\right]>\varepsilon,\) where \(S_{t}:=\left\{k\in\mathbb{N}_{0}\middle|t^{k}\leq t\right\},\) and_

\[t=c\times\min_{m\in[n]}\left[\tau_{m}\left(\frac{L\Delta}{\varepsilon}+\frac{ \sigma^{2}L\Delta}{m\varepsilon^{2}}\right)\right].\]

_The quantity \(c^{\prime}\) and \(c\) are universal constants._

### Minimax optimal method

In this section, we analyze the \(m\)-Minibatch SGD method (see Method 9). This method generalizes the Minibatch SGD method from Section 1.2. Unlike Minibatch SGD, the \(m\)-Minibatch SGD method only asks for stochastic gradients from the first \(m\in[n]\) (fastest) workers. Later, we show that optimal \(m\) is determined by (38). And with this parameter, \(m\)-Minibatch SGD method is minimax optimal under the setting from Sections 8 and G. Note that \(m\)-Minibatch SGD is Minibatch SGD if \(m=n\).

We now provide the convergence rate and the time complexity.

**Theorem G.3**.: _Assume that Assumptions 7.1, 7.2 and 7.3 hold. Let us take the step size_

\[\gamma=\min\left\{\frac{1}{L},\frac{\varepsilon m}{2L\sigma^{2}}\right\}\]

_in Method 9, then after_

\[K\geq\frac{12\Delta L}{\varepsilon}+\frac{12\Delta L\sigma^{2}}{\varepsilon^{ 2}m}\]

_iterations the method guarantees that \(\frac{1}{K}\sum_{k=0}^{K-1}\mathbb{E}\left[\left\|\nabla f(x^{k})\right\|^{2} \right]\leq\varepsilon\)._

**Theorem G.4**.: _Let us consider Theorem G.3. We assume that \(i^{\text{th}}\) worker returns a stochastic gradient every \(\tau_{i}\) seconds for all \(i\in[n]\). Without loss of generality, we assume that \(0<\tau_{1}\leq\cdots\leq\tau_{n}\). Let us take_

\[m=\operatorname*{arg\,min}_{m^{\prime}\in[n]}\tau_{m^{\prime}} \left(1+\frac{\sigma^{2}}{m^{\prime}\varepsilon}\right). \tag{38}\]

_Then after_

\[12\min_{m\in[n]}\tau_{m}\left(\frac{L\Delta}{\varepsilon}+ \frac{\sigma^{2}L\Delta}{m\varepsilon^{2}}\right) \tag{39}\]

_seconds Method 9 guarantees to find an \(\varepsilon\)-stationary point._

Despite the triviality of the \(m\)-Minibatch SGD and it analysis, we provide it to show that the lower bound in Theorem G.2 is tight.

### Proof of Theorem g.2

**Theorem G.2**.: _Let us consider the oracle class \(\mathcal{O}_{\tau_{1},\dots,\tau_{n}}^{\sigma^{2},\text{sync}}\) for some \(\sigma^{2}>0\) and \(0<\tau_{1}\leq\cdots\leq\tau_{n}\). We fix any \(L,\Delta>0\) and \(0<\varepsilon\leq c^{\prime}L\Delta\). In the view Protocol 2, for any algorithm \(A\in\mathcal{A}_{x},\) there exists a function \(f\in\mathcal{F}_{\Delta,L}\) and an oracle and a distribution \((O,\mathcal{D})\in\mathcal{O}_{\tau_{1},\dots,\tau_{n}}^{\sigma^{2},\text{sync }}(f)\) such that \(\mathbb{E}\left[\inf_{k\in S_{t}}\left\|\nabla f(x^{k})\right\|^{2}\right]>\varepsilon,\) where \(S_{t}:=\left\{k\in\mathbb{N}_{0}\big{|}t^{k}\leq t\right\},\) and_

\[t=c\times\min_{m\in[n]}\left[\tau_{m}\left(\frac{L\Delta}{ \varepsilon}+\frac{\sigma^{2}L\Delta}{m\varepsilon^{2}}\right)\right].\]

_The quantity \(c^{\prime}\) and \(c\) are universal constants._

Step 1 and Step 2 mirrors the corresponding steps from the proof of Theorem G.2.

Proof.: (**Step 1**: \(f\in\mathcal{F}_{\Delta,L}\))

Let us fix \(\lambda>0\). We take the same function \(f\in\mathcal{F}_{\Delta,L}\) as in the proof of Theorem 6.4. We define

\[f(x):=\frac{L\lambda^{2}}{l_{1}}F_{T}\left(\frac{x}{\lambda}\right)\]with

\[T=\left\lfloor\frac{\Delta l_{1}}{L\lambda^{2}\Delta^{0}}\right\rfloor.\]

(**Step 2**: Oracle Class)

Following the proof of Theorem 6.4, in the oracle \(O,\) we take the following stochastic estimator

\[[\widehat{\nabla}f(x;\xi)]_{j}:=\nabla_{j}f(x)\left(1+1\left[j>\text{prog}(x) \right]\left(\frac{\xi}{p}-1\right)\right)\quad\forall x\in\mathbb{R}^{T}, \tag{40}\]

and \(\mathcal{D}=\underbrace{(\text{Bernouilli}(p),\ldots,\text{Bernouilli}(p))}_{ \text{$n$ times}},\) where \(p\in(0,1].\) The stochastic gradient is unbiased and \(\sigma^{2}\)-variance-bounded if

\[p=\min\left\{\frac{L^{2}\lambda^{2}\gamma_{\infty}^{2}}{\sigma^{2}l_{1}^{2}},1 \right\}.\]

(**Step 3**: Analysis of Protocol)

We choose

\[\lambda=\frac{\sqrt{2\varepsilon}l_{1}}{L}\]

to ensure that \(\left\|\nabla f(x)\right\|^{2}=\frac{L^{2}\lambda^{2}}{l_{1}^{2}}\left\| \nabla F_{T}(\frac{\pi}{\lambda})\right\|^{2}>2\varepsilon 1\) [prog\((x)<T\)] for all \(x\in\mathbb{R}^{T},\) where we use Lemma D.1. Thus

\[T=\left\lfloor\frac{\Delta L}{2\varepsilon l_{1}\Delta^{0}}\right\rfloor\]

and

\[p=\min\left\{\frac{2\varepsilon\gamma_{\infty}^{2}}{\sigma^{2}},1\right\}.\]

Protocol 2 generates a sequence \(\{x^{k}\}_{k=0}^{\infty}.\) We have

\[\inf_{k\in S_{t}}\left\|\nabla f(x^{k})\right\|^{2}>2\varepsilon\inf_{k\in S_{ t}}\mathbb{1}\left[\text{prog}(x^{k})<T\right]. \tag{41}\]

Further, we require the following auxillary lemma. See the proof in Section D.3.

**Lemma G.5**.: _With probability not less than \(1-\delta,\)_

\[\inf_{k\in S_{t}}\mathbb{1}\left[\text{prog}(x^{k})<T\right]\geq 1\]

_for_

\[t\leq\frac{1}{2}\min_{m\in[n]}\tau_{m}\left(1+\frac{1}{4pm}\right)\left(\frac{ T}{2}+\log\delta\right).\]

Using Lemma G.5 with \(\delta=1/2\) and (41), we obtain

\[\mathbb{E}\left[\inf_{k\in S_{t}}\left\|\nabla f(x^{k})\right\|^{2}\right] \geq 2\varepsilon\mathbb{P}\left(\inf_{k\in S_{t}}\mathbb{1}\left[\text{prog} (x^{k})<T\right]\right)>\varepsilon\]

for

\[t=\frac{1}{2}\min_{m\in[n]}\tau_{m}\left(1+\frac{\sigma^{2}}{8\gamma_{\infty}^ {2}m\varepsilon}\right)\left(\frac{\Delta L}{2\varepsilon l_{1}\Delta^{0}}-2 \right).\]

#### g.2.1 Proof of Lemma g.5

**Lemma G.5**.: _With probability not less than \(1-\delta,\)_

\[\inf_{k\in S_{t}}\mathbb{1}\left[\text{\rm prog}(x^{k})<T\right]\geq 1\]

_for_

\[t\leq\frac{1}{2}\min_{m\in[n]}\tau_{m}\left(1+\frac{1}{4pm}\right)\left(\frac{T }{2}+\log\delta\right).\]

Proof.: **(Part 1):** _Comment: in this part, we mirror the proof of Lemma D.2. We also show that if \(\inf_{k\in S_{t}}\mathbb{1}\left[\text{\rm prog}(x^{k})<T\right]<1\) holds, then we have the inequality \(\sum_{i=1}^{T}\widehat{t}_{\eta_{i}}\leq t,\) where \(\widehat{t}_{\eta_{i}}\) are random variables with some known "good" distributions. However, in this lemma the quantities \(\widehat{t}_{\eta_{i}}\) are different._

In Protocol 2, the algorithm \(A\) consequently calls the oracle \(O.\) If \(\inf_{k\in S_{t}}\mathbb{1}\left[\text{\rm prog}(x^{k})<T\right]<1\) holds, then exists \(k\in S_{t}\) such that \(\text{\rm prog}(x^{k})=T.\) Since the algorithm \(A\) is zero-respecting, the mappings \(A^{k}\) will not output a non-zero vector (a vector with a non-zero first coordinate) unless the oracle returns a non-zero vector.

Let us define the smallest index \(k(i)\) of the sequence when the progress \(\text{\rm prog}(x^{k(i)})\) equals \(i:\)

\[k(i):=\inf\left\{k\in\mathbb{N}_{0}\left|\,i=\text{\rm prog}(x^{k})\right\} \in\mathbb{N}_{0}\cup\{\infty\}.\right.\]

**Definition G.6** (Sequence \((k_{p}^{\xi},i_{p}^{\xi})\)).: Let us consider a set

\[\{(k,i)\in\mathbb{N}\times[n]\,|\,s_{q}^{k-1}=1\text{ and }t^{k}\geq s_{t}^{k-1} +\tau_{i}\},\quad s^{k-1}\equiv(s_{t}^{k-1},s_{q}^{k-1},s_{x}^{k-1}).\]

We order this set lexicographically and define the result sequence as \(\{(k_{p}^{\xi},i_{p}^{\xi})\}_{p=1}^{m},\) where \(m\in[0,\infty]\) is the size of the sequence. The sequence \(s^{k-1}\) is defined in Protocol 2.

Note that the algorithm \(A\) is only depends on the random samples \(\left\{\begin{matrix}k_{p}^{\xi_{p}^{\xi}}\\ s_{p}^{\xi}\end{matrix}\right\}_{p=1}^{m}\) since the sequence \(\{(k_{p}^{\xi},i_{p}^{\xi})\}_{p=1}^{m}\) are the indices of the random samples that are used in the oracle (37).

Let us denote the index of the first successful trial as \(\eta_{1},\) i.e.,

\[\eta_{1}:=\inf\left\{i\left|\,\xi_{p}^{\xi_{p}^{\xi}}=1\text{ and }p\in[1,m] \right.\right\}\in\mathbb{N}\cup\{\infty\}.\]

If \(\inf_{k\in S_{t}}\mathbb{1}\left[\text{\rm prog}(x^{k})<T\right]<1\) holds, then \(\eta_{1}<\infty.\) Using the times \(t^{k},\) the algorithm \(A\) consequently requests the gradient estimators from the oracle (37).

In each round of the oracle's calculation, the algorithm can get the vector \(\widehat{\nabla}f(s_{x};\xi_{1})\) in not less than \(\tau_{1}\) seconds, the vector \(\sum_{i=1}^{2}\widehat{\nabla}f(s_{x};\xi_{i})\) in less than \(\tau_{2}\) seconds, and so forth (see (37)). The algorithm can repeat any number of these rounds sequentially.

The algorithm \(A\) one by one requests \(m_{1},\ldots,m_{i},\cdots\in\{0,\ldots,n\}\) gradient estimators from the oracle (37). It takes at least \(\tau_{m_{i}}\) seconds (\(\tau_{0}\equiv 0\)) to get a vector \(\sum_{i=1}^{m_{i}}\widehat{\nabla}f(s_{x};\xi_{i}).\) Let us consider that \(k\in\mathbb{N}\) is the _first_ index of gradient estimators such that is depends on some \(\xi_{i}=1.\) Necessarily, we have \(\sum_{j=1}^{k}m_{j}\geq\eta_{1}.\) Also, since the \(A\) is zero-respecting, we have \(\sum_{j=1}^{k}\tau_{m_{j}}\leq t^{k(1)}.\) Note that \(k,\) and \(m_{1},\ldots,m_{k}.\) depend on the algorithm's strategy. Let us find "the best possible" quantities \(k,\) and \(m_{1},\ldots,m_{k}\) that are independent of an algorithm.

Let us assume that \(k^{*},\) and \(m_{1}^{*},\ldots m_{k}^{*}\) minimize the quantity

\[\min_{k,m_{1},\ldots,m_{k}}\sum_{j=1}^{k}\tau_{m_{j}},\] (42) s.t. \[k\in\mathbb{N},\] \[m_{1},\ldots m_{k}\in\{0,\ldots,n\},\] \[\sum_{j=1}^{k}m_{j}\geq\eta_{1}.\]Then, we have

\[t^{k(1)}\geq\sum_{j=1}^{k^{*}}\tau_{m_{j}^{*}}.\]

Note that if exists \(j\in[k^{*}]\) such that \(m_{j}^{*}>\eta_{1},\) then \(k^{*},\) and \(m_{1}^{*},\ldots,m_{j-1}^{*},\eta_{1},m_{j+1}^{*}\ldots,m_{k}^{*}\) are also minimizers of (42) since the sequence \(\tau_{k}\) is not decreasing. Therefore, (42) is equivalent to

\[\min_{k,m_{1},\ldots,m_{k}}\sum_{j=1}^{k}\tau_{m_{j}},\] (43) s.t. \[k\in\mathbb{N},\] \[m_{1},\ldots m_{k}\in\{0,\ldots,\eta_{1}\},\] \[\sum_{j=1}^{k}m_{j}\geq\eta_{1}.\]

Then, using the simple algebra, we have

\[t^{k(1)} \geq\sum_{j=1}^{k^{*}}\tau_{m_{j}^{*}}=\sum_{j\,:\,m_{j}^{*}\neq 0 }\tau_{m_{j}^{*}}=\sum_{j\,:\,m_{j}^{*}\neq 0}m_{j}^{*}\frac{\tau_{m_{j}^{*}}} {m_{j}^{*}}\geq\sum_{j\,:\,m_{j}^{*}\neq 0}m_{j}^{*}\min_{m\in[\eta_{1}]} \frac{\tau_{m}}{m}\] \[=\sum_{j=1}^{k^{*}}m_{j}^{*}\min_{m\in[\eta_{1}]}\frac{\tau_{m}}{ m}\geq\eta_{1}\min_{m\in[\eta_{1}]}\frac{\tau_{m}}{m}.\]

In the first inequality, we use that \(m_{j}^{*}\in\{0,\ldots,\eta_{1}\}\) for all \(j\in[k^{*}]\). Next, using Lemma G.9, we get

\[t^{k(1)}\geq\frac{1}{2}\min_{m\in[\eta]}\tau_{m}\left(1+\frac{\eta_{1}}{m} \right).\]

Using the same reasoning, for \(j\in\{0,\ldots,T-1\}\),

\[t^{k(j+1)}\geq t^{k(j)}+\frac{1}{2}\min_{m\in[\eta]}\tau_{m}\left(1+\frac{\eta_ {j+1}}{m}\right),\]

where \(\eta_{j+1}\) is the index of the first successful trial of Bernouilli random variables when \(\text{prog}(\cdot)=j\). More formally, for all \(j\in\{0,\ldots,T-1\}\):

**Definition G.7** (Sequence \((k_{j,p}^{\xi},i_{j,p}^{\xi})\)).: Let us consider a set

\[\{(k,i)\in\mathbb{N}\times[n]\,|\,s_{q}^{k-1}=1\text{ and }t^{k}\geq s_{t}^{k-1} +\tau_{i}\text{ and }\text{prog}(s_{x}^{k-1})=j\},\quad s^{k-1}\equiv(s_{t}^{k-1},s_{q}^{k-1},s_{ x}^{k-1}).\]

We order this set lexicographically and define the result sequence as \(\{(k_{j,p}^{\xi},i_{j,p}^{\xi})\}_{p=1}^{m_{j+1}},\) where \(m_{j+1}\in[0,\infty]\) is the size of the sequence. The sequence \(s^{k-1}\) is defined in Protocol 2.

Then,

\[\eta_{j+1}:=\inf\left\{i\,\bigg{|}\,\xi_{i_{j,p}^{\xi}}^{k_{j,p}^{\xi}}=1\text { and }p\in[1,m_{j+1}]\right\}\in\mathbb{N}\cup\{\infty\}.\]

By the definition of \(k(j)\), \(x^{k(j)}\) is the first iterate such that \(\text{prog}(\cdot)=j\). Therefore, the oracle can potentially start returning gradient estimators with the non-zero \(j+1^{\text{th}}\) coordinate from the \(k(j)^{\text{th}}\) iteration.

Thus, if \(\inf_{k\in S_{t}}\mathbb{1}\left[\text{prog}(x^{k})<T\right]<1\) holds, then

\[\frac{1}{2}\sum_{i=1}^{T}\min_{m\in[n]}\tau_{m}\left(1+\frac{\eta_{i}}{m} \right)\leq t^{k(T)}\leq t.\]

Finally, we can conclude that

\[\mathbb{P}\left(\inf_{k\in S_{t}}\mathbb{1}\left[\text{prog}(x^{k})<T\right]< 1\right)\leq\mathbb{P}\left(\frac{1}{2}\sum_{i=1}^{T}\min_{m\in[n]}\tau_{m} \left(1+\frac{\eta_{i}}{m}\right)\leq t\right)\quad\forall t\geq 0. \tag{44}\]

As in Lemma D.6, we show that 

**Lemma G.8**.: _Let us take \(l_{j+1}\in\mathbb{N}\). Then_

\[\mathbb{P}\left(\eta_{j+1}=l_{j+1}|\eta_{j},\ldots,\eta_{1}\right)\leq(1-p)^{l_{j +1}-1}p \tag{45}\]

_for all \(j\in\{0,\ldots,T-1\}\)._

See the proof in Section G.2.3. Intuitively, the algorithm \(A\) can not increase the probability of getting a successful Bernouilli random variable earlier with its decisions.

Let us temporally define

\[\widehat{t}_{\eta_{i}}:=\frac{1}{2}\min_{m\in[n]}\tau_{m}\left(1+\frac{\eta_{i} }{m}\right)\]

for all \(i\in[T]\).

**(Part 2):**_Comment: in this part, we use the standard technique to bound the large deviations of the sum \(\sum_{i=1}^{T}\widehat{t}_{\eta_{i}}\)._

Note that a function \(g:\,\mathbb{R}\rightarrow\mathbb{R}\) such that \(g(x):=\frac{1}{2}\min_{m\in[n]}\tau_{m}\left(1+\frac{x}{m}\right)\) is continuous, strongly-monotone and invertible. For \(t^{\prime}\geq 0\), we have

\[\mathbb{P}\left(\widehat{t}_{\eta_{j+1}}\leq t^{\prime}\big{|}\eta_{j},\ldots, \eta_{1}\right)=\mathbb{P}\left(g(\eta_{j+1})\leq t^{\prime}|\eta_{j},\ldots, \eta_{1}\right)=\mathbb{P}\left(\eta_{j+1}\leq g^{-1}(t^{\prime})\big{|}\eta_{ j},\ldots,\eta_{1}\right).\]

Using (45), we obtain

\[\mathbb{P}\left(\widehat{t}_{\eta_{j+1}}\leq t^{\prime}\big{|}\eta_{j},\ldots, \eta_{1}\right)\leq\sum_{j=1}^{\left\lfloor g^{-1}(t^{\prime})\right\rfloor}(1 -p)^{j-1}p\leq p\left\lfloor g^{-1}(t^{\prime})\right\rfloor.\]

Let us define

\[p^{\prime}:=p\left\lfloor g^{-1}(t^{\prime})\right\rfloor,\]

then

\[\mathbb{P}\left(\widehat{t}_{\eta_{j+1}}\leq t^{\prime}\big{|}\eta_{j},\ldots, \eta_{1}\right)\leq p^{\prime}.\]

Using the Chernoff method, as in Lemma D.2, one can get

\[\mathbb{P}\left(\sum_{i=1}^{T}\widehat{t}_{\eta_{i}}\leq\widehat{t}\right) \leq e^{\widehat{t}/t^{\prime}-T+2p^{\prime}T}.\]

Let us take

\[t^{\prime}=g\left(\frac{1}{4p}\right)=\frac{1}{2}\min_{m\in[n]}\tau_{m}\left( 1+\frac{1}{4pm}\right),\]

then

\[p^{\prime}=p\left\lfloor g^{-1}\left(g\left(\frac{1}{4p}\right)\right)\right \rfloor=p\left\lfloor\frac{1}{4p}\right\rfloor\leq\frac{1}{4}.\]

Therefore,

\[\mathbb{P}\left(\sum_{i=1}^{T}\widehat{t}_{\eta_{i}}\leq\widehat{t}\right) \leq e^{\widehat{t}/t^{\prime}-\frac{T}{2}}.\]

Using (44), for

\[t\leq\frac{1}{2}\min_{m\in[n]}\tau_{m}\left(1+\frac{1}{4pm}\right)\left(\frac {T}{2}+\log\delta\right),\]

we have

\[\mathbb{P}\left(\inf_{k\in S_{t}}\mathbb{1}\left[\text{prog}(x^{k})<T\right]<1 \right)\leq\mathbb{P}\left(\sum_{i=1}^{T}\widehat{t}_{\eta_{i}}\leq t\right) \leq\delta.\]

The last inequality concludes the proof.

#### g.2.2 Lemma g.9

**Lemma G.9**.: _Let us consider a sorted sequence \(0<\tau_{1}\leq\cdots\leq\tau_{n}\) and a constant \(\eta\in\mathbb{N}\). We define_

\[t_{1}:=\eta\min_{m\in[n]}\frac{\tau_{m}}{m},\]

_and_

\[t_{2}:=\min_{m\in[n]}\tau_{m}\left(1+\frac{\eta}{m}\right).\]

_Then_

\[t_{1}\leq t_{2}\leq 2t_{1}.\]

Proof.: Additionally, let us define

\[m_{1}:=\operatorname*{arg\,min}_{m\in[n]}\frac{\tau_{m}}{m}\]

and

\[m_{2}:=\operatorname*{arg\,min}_{m\in[n]}\tau_{m}\left(1+\frac{\eta}{m}\right).\]

Then, using \(m_{1}\leq\eta\), we have

\[t_{2}=\min_{m\in[n]}\tau_{m}\left(1+\frac{\eta}{m}\right)\leq\tau_{m_{1}}\left( 1+\frac{\eta}{m_{1}}\right)\leq 2\tau_{m_{1}}\frac{\eta}{m_{1}}=2t_{1}.\]

If \(m_{2}\leq\eta,\) then

\[t_{1}=\eta\min_{m\in[n]}\frac{\tau_{m}}{m}\leq\eta\frac{\tau_{m_{2}}}{m_{2}} \leq\tau_{m_{2}}\left(1+\frac{\eta}{m_{2}}\right)=t_{2}.\]

Otherwise, if \(m_{2}>\eta,\)

\[t_{1}=\eta\min_{m\in[n]}\frac{\tau_{m}}{m}\leq\eta\frac{\tau_{\eta}}{\eta}=\tau _{\eta}\leq\tau_{m_{2}}\leq\tau_{m_{2}}\left(1+\frac{\eta}{m_{2}}\right)=t_{2}.\]

#### g.2.3 Proof of Lemma g.8

In the following lemma, we use notations from Part 1 of the proof of Lemma G.5.

**Lemma G.8**.: _Let us take \(l_{j+1}\in\mathbb{N}\). Then_

\[\mathbb{P}\left(\eta_{j+1}=l_{j+1}|\eta_{j},\ldots,\eta_{1}\right)\leq(1-p)^{l _{j+1}-1}p \tag{45}\]

_for all \(j\in\{0,\ldots,T-1\}.\)_

The idea of the following proof repeats the proof of Lemma G.8. But Protocol 2 with the oracle (37) differ, so we present the proof for completeness.

Proof.: We prove that

\[\mathbb{P}\left(\eta_{j+1}=l_{j+1}\middle|\bigcap_{i=1}^{j}\{\eta_{i}=l_{i}\} \right)\leq(1-p)^{l_{j+1}-1}p.\]

for all \(l_{1},\ldots,l_{j}\in\mathbb{N}\cup\{\infty\}\) such that \(\mathbb{P}\left(\bigcap_{i=1}^{j}\{\eta_{i}=l_{i}\}\right)>0.\)

If exists \(i\in[j]\) such that \(l_{i}=\infty,\) then

\[\mathbb{P}\left(\eta_{j+1}=l_{j+1}\middle|\bigcap_{i=1}^{j}\{\eta_{i}=l_{i}\} \right)=0\]

[MISSING_PAGE_EMPTY:50]

since, for all \(p\in[l_{j+1}],\) the event \(A_{(k_{p},i_{p})}\) is only determined by \(s^{k_{p}-1}\) and \(t^{k_{p}}\) that _do not_ depend on \(\{\xi^{j}\}_{j=k_{l_{j+1}}}^{\infty}\). And, for all \(p\in[l_{j+1}],\) the fact that \((k_{j,p}^{\xi},i_{j,p}^{\xi})=(k_{p},i_{p})\)_does not_ depend on \(\{\xi^{j}\}_{j=k_{l_{j+1}}}^{\infty}\). Note that \(k_{i-1,l_{i}}^{\xi}<k_{j,l_{j+1}}^{\xi}\) (a.s.) for all \(i\in[j]\). Thus

\[A_{(k_{j+1},i_{l_{j+1}})}\bigcap\{(k_{j,l_{j+1}}^{\xi},i_{j,l_{j+1}}^{\xi})=(k_ {l_{j+1}},i_{l_{j+1}})\}\bigcap_{i=1}^{j}\{\eta_{i}=l_{i}\}\in\sigma_{n}^{k_{l _{j+1}}-1}\]

since, for all \(i\in[j],\) this event implies that \(k_{i-1,l_{i}}^{\xi}<k_{l_{j+1}}\). All in all, we have that

\[\bigcap_{p=1}^{l_{j+1}-1}\{\xi_{i_{p}}^{k_{p}}=0\}\bigcap_{p=1}^{l_{j+1}}\left( \{(k_{j,p}^{\xi},i_{j,p}^{\xi})=(k_{p},i_{p})\}\bigcap A_{(k_{p},i_{p})}\right) \bigcap_{i=1}^{j}\{\eta_{i}=l_{i}\}\in\sigma_{n}^{k_{l_{j+1}}-1}\bigcup\sigma_ {i_{l_{j+1}}-1}^{k_{l_{j+1}}-1}.\]

Since \(\{\xi_{i_{l_{j+1}}}^{k_{l_{j+1}}}=1\}\) is independent of \(\sigma_{n}^{k_{l_{j+1}}-1}\bigcup\sigma_{i_{l_{j+1}}-1}^{k_{l_{j+1}}-1}\),8 we get

Footnote 8: For all \(i,j\geq 0\) and \(l,p\in\{0,\ldots,n\}\), the union of \(\sigma_{l}^{i}\) and \(\sigma_{p}^{j}\) is a sigma-algebra since either \(\sigma_{l}^{i}\subseteq\sigma_{p}^{j}\), or \(\sigma_{p}^{j}\subseteq\sigma_{l}^{i}\).

\[\mathbb{P}\left(\eta_{j+1}=l_{j+1}\middle|\bigcap_{i=1}^{j}\{\eta_{i}=l_{i}\}\right)\]

If \(l_{j+1}=1,\) observe that the events \(\{(k_{j,l_{j+1}}^{\xi},i_{j,l_{j+1}}^{\xi})=(k_{l_{j+1}},i_{l_{j+1}})\}\bigcap A _{(k_{l_{j+1}},i_{l_{j+1}})}\) do not intersect for all \((k_{l_{j+1}},i_{l_{j+1}})\in\mathbb{N}\times[n]\). Thus, we can use the additivity of the probability, and obtain

\[\mathbb{P}\left(\eta_{j+1}=l_{j+1}\middle|\bigcap_{i=1}^{j}\{\eta_{i}=l_{i}\}\right)\]

Otherwise, if \(l_{j+1}>1,\) we also use the fact that the events do not intersect and get

\[\mathbb{P}\left(\eta_{j+1}=l_{j+1}\middle|\bigcap_{i=1}^{j}\{\eta _{i}=l_{i}\}\right)\] \[\leq p\sum_{S_{l_{j+1}-1}}\mathbb{P}\left(\bigcap_{p=1}^{l_{j+1}- 1}\{\xi_{i_{p}}^{k_{p}}=0\},\bigcap_{p=1}^{l_{j+1}-1}\left(\{(k_{j,p}^{\xi},i _{j,p}^{\xi})=(k_{p},i_{p})\}\bigcap A_{(k_{p},i_{p})}\right),\right.\] \[\bigcup_{(k,i)>(k_{l_{j+1}-1},i_{l_{j+1}-1})}\left(\{(k_{j,l_{j+1 }}^{\xi},i_{j,l_{j+1}}^{\xi})=(k,i)\}\bigcap A_{(k,i)}\right)\middle|\bigcap_{ i=1}^{j}\{\eta_{i}=l_{i}\}\right)\] \[\leq p\sum_{S_{l_{j+1}-1}}\mathbb{P}\left(\bigcap_{p=1}^{l_{j+1}- 1}\{\xi_{i_{p}}^{k_{p}}=0\},\bigcap_{p=1}^{l_{j+1}-1}\left(\{(k_{j,p}^{\xi},i _{j,p}^{\xi})=(k_{p},i_{p})\}\bigcap A_{(k_{p},i_{p})}\right)\middle|\bigcap_{ i=1}^{j}\{\eta_{i}=l_{i}\}\right),\]

where we used an inequality \(\mathbb{P}\left(A,B\right)\leq\mathbb{P}\left(A\right)\) for any events \(A\) and \(B\). We take the sum over all \(((k_{1},i_{1}),\ldots,(k_{l_{j+1}-1},i_{l_{j+1}-1}))\in S_{l_{j+1}-1},\) where

\[S_{l_{j+1}-1}=\{((k_{1},i_{1}),\ldots,(k_{l_{j+1}-1},i_{l_{j+1}-1}))\in(\mathbb{ N}\times[n])^{l_{j+1}-1}\,|\,\forall p<j\in[l_{j+1}-1]:(k_{p},i_{p})<(k_{j},i_{j})\}.\]

Using the same reasoning, one can continue and get that

\[\mathbb{P}\left(\eta_{j+1}=l_{j+1}\middle|\bigcap_{i=1}^{j}\{\eta_{i}=l_{i}\} \right)\leq p(1-p)^{l_{j+1}-1}.\]

### Proof of Theorem g.3

**Theorem G.3**.: _Assume that Assumptions 7.1, 7.2 and 7.3 hold. Let us take the step size_

\[\gamma=\min\left\{\frac{1}{L},\frac{\varepsilon m}{2L\sigma^{2}}\right\}\]

_in Method 9, then after_

\[K\geq\frac{12\Delta L}{\varepsilon}+\frac{12\Delta L\sigma^{2}}{\varepsilon^{2 }m}\]

_iterations the method guarantees that \(\frac{1}{K}\sum_{k=0}^{K-1}\mathbb{E}\left[\left\|\nabla f(x^{k})\right\|^{2} \right]\leq\varepsilon\)._

Proof.: Note that

\[x^{k+1}=x^{k}-\gamma\frac{1}{m}\sum_{i=1}^{m}\widehat{\nabla}f(x^{k},\xi_{i}),\]

where the stochastic gradients are i.i.d. Therefore, we can use the classical SGD result (see Theorem D.8). For a stepsize

\[\gamma=\min\left\{\frac{1}{L},\frac{\varepsilon m}{2L\sigma^{2}}\right\},\]

we have

\[\frac{1}{K}\sum_{k=0}^{K-1}\mathbb{E}\left[\left\|\nabla f(x^{k})\right\|^{2} \right]\leq\varepsilon,\]

if

\[K\geq\frac{12\Delta L}{\varepsilon}+\frac{12\Delta L\sigma^{2}}{\varepsilon^{2 }m}.\]

### Proof of Theorem g.4

**Theorem G.4**.: _Let us consider Theorem G.3. We assume that \(i^{\text{th}}\) worker returns a stochastic gradient every \(\tau_{i}\) seconds for all \(i\in[n]\). Without loss of generality, we assume that \(0<\tau_{1}\leq\cdots\leq\tau_{n}\). Let us take_

\[m=\operatorname*{arg\,min}_{m^{\prime}\in[n]}\tau_{m^{\prime}}\left(1+\frac{ \sigma^{2}}{m^{\prime}\varepsilon}\right). \tag{38}\]

_Then after_

\[12\min_{m\in[n]}\tau_{m}\left(\frac{L\Delta}{\varepsilon}+\frac{\sigma^{2}L \Delta}{m\varepsilon^{2}}\right) \tag{39}\]

_seconds Method 9 guarantees to find an \(\varepsilon\)-stationary point._

Proof.: In this setup, the method converges after \(K\times\tau_{m}\) seconds because the delay of each iteration is determined by the slowest worker. Thus, the time complexity equals

\[\tau_{m}\left(\frac{12\Delta L}{\varepsilon}+\frac{12\Delta L\sigma^{2}}{ \varepsilon^{2}m}\right)=\frac{12\Delta L}{\varepsilon}\tau_{m}\left(1+\frac {\sigma^{2}}{\varepsilon m}\right)=\frac{12\Delta L}{\varepsilon}\min_{m^{ \prime}\in[n]}\tau_{m}\left(1+\frac{\sigma^{2}}{m^{\prime}\varepsilon}\right),\]

where we use the choice of the number of workers \(m\)Proofs for Convex Case

### The "worst case" function in convex case

In this proof, we use the construction from (Woodworth et al., 2018). Let us define \(B_{2}(0,R):=\left\{x\in\mathbb{R}^{T+1}\,:\,\left\|x\right\|\leq R\right\}.\)

Let us take functions \(f_{l,\eta}\,:\,\mathbb{R}^{T+1}\to\mathbb{R}\) and \(\widetilde{f}_{l,\eta}\,:\,\mathbb{R}^{T+1}\to\mathbb{R}\) such that

\[f_{l,\eta}(x):=\min_{y\in\mathbb{R}^{T+1}}\left\{\widetilde{f}_{l,\eta}(y)+\frac{\eta}{2}\left\|y-x\right\|^{2}\right\}\]

and

\[\widetilde{f}_{l,\eta}(x):=\max_{1\leq r\leq T+1}\left(lx_{r}- \frac{5l^{2}(r-1)}{\eta}\right),\]

where \(l,\eta>0\) are free parameters. Let us define

\[y(x):=\operatorname*{arg\,min}_{y\in\mathbb{R}^{T+1}}\left\{ \widetilde{f}_{l,\eta}(y)+\frac{\eta}{2}\left\|y-x\right\|^{2}\right\}.\]

For ths function \(f_{l,\eta}\), we have the following properties:

**Lemma H.1** (Woodworth et al. (2018)).: _The function \(f_{l,\eta}\) satisfies:_

1. _(Lemma_ 4_) The function_ \(f_{l,\eta}\) _is convex,_ \(l\)_-Lipschitz, and_ \(\eta\)_-smooth._
2. _(eq._ 75_)_ \[\min_{x\in B_{2}(0,1)}f_{l,\eta}(x)\leq-\frac{l}{\sqrt{T+1}}.\]
3. _(Lemma_ 6_) For all_ \(x\in B_{2}(0,1),\)__\(\text{prog}(\nabla f_{l,\eta}(x))\leq\text{prog}(x)+1\) _and_ \(\text{prog}(y(x))\leq\text{prog}(x)+1\)_._

### Proof of Theorem b.4

**Theorem B.4**.: _Let us consider the oracle class \(\mathcal{O}_{\tau_{1},\ldots,\tau_{n}}^{\text{conv},\sigma^{2}}\) for some \(\sigma^{2}>0\) and \(0<\tau_{1}\leq\cdots\leq\tau_{n}.\) We fix any \(R,L,M,\varepsilon>0\) such that \(\sqrt{L}R>c_{1}\sqrt{\varepsilon}>0\) and \(M^{2}R^{2}>c_{2}\varepsilon^{2}.\) In the view Protocol 3, for any algorithm \(A\in\mathcal{A}_{n}^{R},\) there exists a function \(f\in\mathcal{F}_{R,M,L}^{\text{conv}}\) and oracles and distributions \(((O_{1},\ldots,O_{n}),(\mathcal{D}_{1},\ldots,\mathcal{D}_{n}))\in\mathcal{O} _{\tau_{1},\ldots,\tau_{n}}^{\text{conv},\sigma^{2}}(f)\) such that_

\[\mathbb{E}\left[\inf_{k\in S_{t}}f(x^{k})\right]-\inf_{x\in B_{2} (0,R)}f(x)>\varepsilon,\]

_where \(S_{t}:=\left\{k\in\mathbb{N}_{0}\big{|}t^{k}\leq t\right\},\) and_

\[t=c\times\min_{m\in[n]}\left[\left(\frac{1}{m}\sum_{i=1}^{m}\frac {1}{\tau_{i}}\right)^{-1}\left(\min\left\{\frac{\sqrt{L}R}{\sqrt{\varepsilon} },\frac{M^{2}R^{2}}{\varepsilon^{2}}\right\}+\frac{\sigma^{2}R^{2}}{m \varepsilon^{2}}\right)\right].\]

_The quantities \(c_{1},\)\(c_{2}\) and \(c\) are universal constants._

In Step 1, we almost repeat the proof from Woodworth et al. (2018). Steps 2 and 3 are very close to Steps 2 and 3 of the proofs for the nonconvex case.

Proof.: (**Step 1**: \(f\in\mathcal{F}_{R,M,L}^{\text{conv}}\)) Following Woodworth et al. (2018), we assume that \(R=1.\) Otherwise, one can rescale the parameters of the construction. Let us take the function \(f_{l,\eta}\) from Section H.1 with parameters

\[l=\min\left\{M,\frac{L}{10(T+1)^{3/2}}\right\}\text{ and }\eta=10(T+1)^{3/2}l.\]

[MISSING_PAGE_EMPTY:54]

\[\mathbb{E}\left[f(\widehat{x}^{K})\right]-f(x^{*})\leq\varepsilon\]

if

\[K\geq\frac{2M^{2}\left\|x^{*}-x^{0}\right\|^{2}}{\varepsilon^{2}}\geq\frac{ \left(M^{2}+\frac{\sigma^{2}}{S}\right)\left\|x^{*}-x^{0}\right\|^{2}}{ \varepsilon^{2}}.\]

#### h.3.1 The classical SGD theorem in convex optimization

We reprove the classical SGD result (see, for instance, (Lan, 2020)) for convex functions.

**Theorem H.2**.: _Assume that Assumptions B.5 and B.6 hold. We consider the SGD method:_

\[x^{k+1}=x^{k}-\gamma g(x^{k}),\]

_where_

\[\gamma=\frac{\varepsilon}{M^{2}+\sigma^{2}}\]

_For a fixed \(x\in\mathbb{R}^{d}\), \(g(x)\) is a random vector such that \(\mathbb{E}\left[g(x)\right]\in\partial f(x)\) (\(\partial f(x)\) is the subdifferential of the function \(f\) at the point \(x\)),_

\[\mathbb{E}\left[\left\|g(x)-\mathbb{E}\left[g(x)\right]\right\|^{2}\right]\leq \sigma^{2},\]_and \(g(x^{k})\) are independent vectors for all \(k\geq 0\). Then_

\[\mathbb{E}\left[f\left(\frac{1}{K}\sum_{k=0}^{K-1}x^{k}\right) \right]-f(x^{*})\leq\varepsilon \tag{47}\]

_for_

\[K\geq\frac{(M^{2}+\sigma^{2})\left\|x^{*}-x^{0}\right\|^{2}}{ \varepsilon^{2}}.\]

Proof.: We denote \(\mathcal{G}^{k}\) as a sigma-algebra generated by \(g(x^{0}),\ldots,g(x^{k-1})\). Using the convexity, for all \(x\in\mathbb{R}^{d}\), we have

Note that

\[\left\langle g(x^{k}),x-x^{k}\right\rangle =\left\langle g(x^{k}),x^{k+1}-x^{k}\right\rangle+\left\langle g(x ^{k}),x-x^{k+1}\right\rangle\] \[=-\gamma\left\|g(x^{k})\right\|^{2}+\frac{1}{\gamma}\left\langle x ^{k}-x^{k+1},x-x^{k+1}\right\rangle\] \[=-\gamma\left\|g(x^{k})\right\|^{2}+\frac{1}{2\gamma}\left\|x^{k }-x^{k+1}\right\|^{2}+\frac{1}{2\gamma}\left\|x-x^{k+1}\right\|^{2}-\frac{1}{ 2\gamma}\left\|x-x^{k}\right\|^{2}\] \[=-\frac{\gamma}{2}\left\|g(x^{k})\right\|^{2}+\frac{1}{2\gamma} \left\|x-x^{k+1}\right\|^{2}-\frac{1}{2\gamma}\left\|x-x^{k}\right\|^{2}\]

and

\[\mathbb{E}\left[\left\|g(x^{k})\right\|^{2}\right|\mathcal{G}^{k} \right]=\mathbb{E}\left[\left\|g(x^{k})-\mathbb{E}\left[\left.g(x^{k})\right| \mathcal{G}^{k}\right]\right\|^{2}\right|\mathcal{G}^{k}\right]+\left\|\mathbb{ E}\left[\left.g(x^{k})\right|\mathcal{G}^{k}\right]\right\|^{2}\leq\sigma^{2}+M^{2}.\]

Therefore, we get

\[f(x^{k}) \leq f(x)+\mathbb{E}\left[\left\langle g(x^{k}),x^{k}-x\right\rangle \right|\mathcal{G}^{k}\right]\] \[=f(x)+\frac{\gamma}{2}\mathbb{E}\left[\left\|g(x^{k})\right\|^{2 }\right|\mathcal{G}^{k}\right]+\frac{1}{2\gamma}\left\|x-x^{k}\right\|^{2}- \frac{1}{2\gamma}\mathbb{E}\left[\left\|x-x^{k+1}\right\|^{2}\right|\mathcal{G }^{k}\right]\] \[\leq f(x)+\frac{\gamma}{2}\left(M^{2}+\sigma^{2}\right)+\frac{1}{ 2\gamma}\left\|x-x^{k}\right\|^{2}-\frac{1}{2\gamma}\mathbb{E}\left[\left\|x-x ^{k+1}\right\|^{2}\right|\mathcal{G}^{k}\right].\]

By taking the full expectation and summing the last inequality for \(t\) from \(0\) to \(K-1\), we obtain

\[\mathbb{E}\left[\sum_{k=0}^{K-1}f(x^{k})\right] \leq Kf(x)+\frac{K\gamma}{2}\left(M^{2}+\sigma^{2}\right)+\frac{1 }{2\gamma}\left\|x-x^{0}\right\|^{2}-\frac{1}{2\gamma}\mathbb{E}\left[\left\|x -x^{K}\right\|^{2}\right]\] \[\leq Kf(x)+\frac{K\gamma}{2}\left(M^{2}+\sigma^{2}\right)+\frac{1 }{2\gamma}\left\|x-x^{0}\right\|^{2}.\]

Let divide the last inequality by \(K,\) take \(x=x^{*},\) and use the convexity:

\[\mathbb{E}\left[f\left(\frac{1}{K}\sum_{k=0}^{K-1}x^{k}\right) \right]-f(x^{*})\leq\frac{\gamma}{2}\left(M^{2}+\sigma^{2}\right)+\frac{1}{2 \gamma K}\left\|x^{*}-x^{0}\right\|^{2}.\]

The choices of \(\gamma\) and \(K\) ensure that (47) holds. 

### Proof of Theorem b.9

**Theorem b.9**.: _Let us consider Theorem b.8. We assume that \(i^{\text{th}}\) worker returns a stochastic gradient every \(\tau_{i}\) seconds for all \(i\in[n]\). Without loss of generality, we assume that \(0<\tau_{1}\leq\cdots\leq\tau_{n}\). Then after_

\[8\min_{m\in[n]}\left[\left(\frac{1}{m}\sum_{i=1}^{m}\frac{1}{ \tau_{i}}\right)^{-1}\left(\frac{M^{2}R^{2}}{\varepsilon^{2}}+\frac{\sigma^{2} R^{2}}{m\varepsilon^{2}}\right)\right] \tag{17}\]

_seconds Method 4 guarantees to find an \(\varepsilon\)-solution._Proof.: The proof is the same as in Theorem 7.5. It is only required to estimate the time that is required to collect a batch of size \(S\). Method 4 returns a solution after

\[K\times 2t^{\prime}(j^{*})=\frac{4M^{2}\left\|x^{*}-x^{0}\right\|^{2}}{\varepsilon ^{2}}\min_{j\in[n]}\left[\left(\sum_{i=1}^{j}\frac{1}{\tau_{i}}\right)^{-1}(S+ j)\right]\]

seconds. 

### Proof of Theorem b.10

**Theorem B.10**.: _Assume that Assumptions B.5, 7.1 and 7.3 hold. Let us take the batch size \(S=\max\left\{\left[\left(\sigma^{2}R\right)/(\varepsilon^{3/2}\sqrt{L})\right],1\right\},\) and \(\gamma=\min\left\{\frac{1}{4L},\left[\frac{3R^{2}S}{4\sigma^{2}(K+1)(K+2)^{2}} \right]^{1/2}\right\}\) in Accelerated Method 4, then after \(K\geq\frac{8\sqrt{L}R}{\sqrt{\varepsilon}}\) iterations the method guarantees that \(\mathbb{E}\left[f(x^{K})\right]-f(x^{*})\leq\varepsilon,\) where \(R\geq\left\|x^{*}-x^{0}\right\|.\)_

Proof.: One can see that Accelerated Method 4 is just the accelerated stochastic gradient method with the batch size \(S.\) It means that we can use the classical SGD result (Proposition 4.4 in Lan (2020)). For a stepsize

\[\gamma=\min\left\{\frac{1}{4L},\left[\frac{3R^{2}S}{4\sigma^{2}(K+1)(K+2)^{2}} \right]^{1/2}\right\},\]

we have

\[\mathbb{E}\left[f(x^{K})\right]-f(x^{*})\leq\frac{4LR^{2}}{K^{2}}+\frac{4\sqrt{ \sigma^{2}R^{2}}}{\sqrt{SK}}.\]

Therefore,

\[\mathbb{E}\left[f(x^{K})\right]-f(x^{*})\leq\varepsilon\]

if

\[K\geq\frac{8\sqrt{L}R}{\sqrt{\varepsilon}}\geq 8\max\left\{\frac{\sqrt{L}R}{ \sqrt{\varepsilon}},\frac{\sigma^{2}R^{2}}{\varepsilon^{2}S}\right\},\]

where we use the choice of \(S.\) 

### Proof of Theorem b.11

**Theorem B.11**.: _Let us consider Theorem B.10. We assume that \(i^{\text{th}}\) worker returns a stochastic gradient every \(\tau_{i}\) seconds for all \(i\in[n]\). Without loss of generality, we assume that \(0<\tau_{1}\leq\cdots\leq\tau_{n}.\) Then after_

\[32\min_{m\in[n]}\left[\left(\frac{1}{m}\sum_{i=1}^{m}\frac{1}{\tau_{i}}\right) ^{-1}\left(\frac{\sqrt{L}R}{\sqrt{\varepsilon}}+\frac{\sigma^{2}R^{2}}{m \varepsilon^{2}}\right)\right]\]

_seconds Accelerated Method 4 guarantees to find an \(\varepsilon\)-solution._

Proof.: The proof is the same as in Theorem 7.5. It is only required to estimate the time that is required to collect a batch of size \(S\). Accelerated Method 4 returns a solution after

\[K\times 2t^{\prime}(j^{*})=\frac{16\sqrt{L}R}{\sqrt{\varepsilon}}\min_{j\in[n]} \left[\left(\sum_{i=1}^{j}\frac{1}{\tau_{i}}\right)^{-1}(S+j)\right]\]

seconds.

Construction of Algorithm for Rennala SGD

In this section, we provide the formal construction of the algorithm from Definition 4.1 for Rennala SGD. We consider the fixed computation model, where \(i^{\text{th}}\) worker requires \(\tau_{i}\) seconds to calculate stochastic gradients. We now define the corresponding sequence \(\{A^{k}\}_{k=0}^{\infty}\). Let us fix a starting point \(x^{0}\in\mathbb{R}^{d}\), a stepsize \(\gamma\geq 0\), and a batch size \(S\in\mathbb{N}\).

First, let us consider the sequence \(\{\widehat{t}_{k}\}_{k=1}^{\infty}\) from Definition D.4 that represents the times when the workers would be ready to provide stochastic gradients. Additionally, let us define \(\widehat{t}_{0}:=0\) and a sequence of the workers' indices \(\{\widehat{i}_{k}\}_{k=1}^{\infty}\) that are corresponding to the times \(\{\widehat{t}_{k}\}_{k=1}^{\infty}\). We can define

\[A^{k}(g^{1},\ldots,g^{k})=\begin{cases}\Big{(}\widehat{t}_{(\lfloor k/2\rfloor )},\widehat{t}_{(\lfloor k/2\rfloor+1)},x^{0}-\frac{\gamma}{S}\sum_{j=1}^{2S \times\lfloor k/(2S)\rfloor}g^{j}\Big{)},&k\;(\bmod\;2)=0,\\ \Big{(}\widehat{t}_{(\lfloor k/2\rfloor+1)},\widehat{t}_{(\lfloor k/2\rfloor+1 )},0\Big{)},&k\;(\bmod\;2)=1,\end{cases} \tag{48}\]

for all \(k\geq 1\), and \(A^{0}=(\widehat{t}_{0},\widehat{i}_{1},x^{0})\). For the fixed computation model, one can use this algorithm in Protocol 3 with the oracle (7) to get an equivalent procedure to Method 4.

Experiments

In this section, we compare Rennala SGD with Asynchronous SGD and Minibatch SGD on quadratic optimization tasks with stochastic gradients. The experiments were implemented in Python 3.7.9. The distributed environment was emulated on machines with Intel(R) Xeon(R) Gold 6248 CPU @ 2.50GHz.

### Setup

We consider the homogeneous optimization problem (1) with the convex quadratic function

\[f(x)=\frac{1}{2}x^{\top}\mathbf{A}x-b^{\top}x\quad\forall x\in\mathbb{R}^{d}.\]

We take \(d=1000\),

\[\mathbf{A}=\frac{1}{4}\left(\begin{array}{ccccc}2&-1&&0\\ -1&\ddots&\ddots&\\ &\ddots&\ddots&-1\\ 0&&-1&2\end{array}\right)\in\mathbb{R}^{d\times d}\quad\text{and}\quad\ b= \frac{1}{4}\left[\begin{array}{c}-1\\ 0\\ \vdots\\ 0\end{array}\right]\in\mathbb{R}^{d}.\]

Assume that all \(n\) workers has access to the following unbiased stochastic gradients:

\[[\widehat{\nabla}f(x;\xi)]_{j}:=\nabla_{j}f(x)\left(1+1\left[j>\text{prog}(x) \right]\left(\frac{\xi}{p}-1\right)\right)\quad\forall x\in\mathbb{R}^{d},\]

where \(\xi\sim\mathcal{D}_{i}=\text{Bernouilli}(p)\) for all \(i\in[n]\), where \(p\in(0,1]\). We denote \([x]_{j}\) as the \(j\)th index of a vector \(x\in\mathbb{R}^{d}\). In our experiments, we take \(p=0.01\) and the starting point \(x^{0}=[\sqrt{d},0,\dots,0]^{\top}\). We emulate our setup by considering that the \(i\)th worker requires \(\sqrt{i}\) seconds to calculate a stochastic gradient. In all methods, we fine-tune step sizes from a set \(\{2^{i}\,|\,i\in[-20,20]\}\). In Rennala SGD, we fine-tune the batch size \(S\in\{1,5,10,20,40,80,100,200,500,1000\}\).

### Results

In Figures 1, 2, and 3, we present experiments with different number of workers \(n\in\{100,1000,10000\}\). When the number of workers \(n=100\), Rennala SGD with Asynchronous SGD converge to the minimum at almost the same rate. However, when we start increasing the number of workers \(n\), one can see that Asynchronous SGD9 starts converging slower. This is an expected behavior since the maximum theoretical step size in Asynchronous SGD decreases as the number of workers \(n\) increases (Koloskova et al., 2022; Mishchenko et al., 2022).

Footnote 9: We implemented Asynchronous SGD with delay-adaptive stepsizes from (Koloskova et al., 2022)

## Appendix K Experiment with Small-Scale Machine Learning Task

We also consider the methods in a more practical scenario. We solve a logistic regression problem with the _MNIST_ dataset (LeCun et al., 2010). We take \(n=1000\) workers that hold the _same_ subset of _MNIST_ of the size \(3000\). Each worker samples stochastic gradients of size \(4\). In Figures 4 and 5, we provide convergence rates and a histogram of the time delays from the experiment. As in (Mishchenko et al., 2018), we can observe that asynchronous methods converge faster than Minibatch SGD. Unlike Section J where Rennala SGD converges faster than Asynchronous SGD, these methods have almost the same performance in this particular experiment.

Figure 1: # of workers \(n=100\).

Figure 3: # of workers \(n=10000\).

Figure 2: # of workers \(n=1000\).

## Appendix L Time Complexity of Asynchronous SGD

The works (Mishchenko et al., 2022; Koloskova et al., 2022) state that Asynchronous SGD convereges after

\[\mathrm{O}\left(\frac{nL\Delta}{\varepsilon}+\frac{\sigma^{2}L\Delta}{ \varepsilon^{2}}\right)\]

iterations. This result directly does not reveal the time complexity of Asynchronous SGD. Let us provide the time complexity for the case when the workers require exactly \(\tau_{i}\) seconds to compute stochastic gradients. Let us fix a time \(t\geq 0\). Then the workers will calculate at most

\[\sum_{i=1}^{n}\left\lfloor\frac{t}{\tau_{i}}\right\rfloor\]

stochastic gradients. To get \(\varepsilon\)-stationary point, we have to find the minimal \(t\) such that

\[c\times\left(\frac{nL\Delta}{\varepsilon}+\frac{\sigma^{2}L\Delta}{\varepsilon ^{2}}\right)\leq\sum_{i=1}^{n}\left\lfloor\frac{t}{\tau_{i}}\right\rfloor, \tag{49}\]

Figure 4: Logistic regression experiment

Figure 5: Histogram of time delays

[MISSING_PAGE_FAIL:62]

[MISSING_PAGE_EMPTY:63]