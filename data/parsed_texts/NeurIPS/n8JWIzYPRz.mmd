# Environment-Aware Dynamic Graph Learning for Out-of-Distribution Generalization

 Haonan Yuan\({}^{1,2}\), Qingyun Sun\({}^{1,2,}\), Xingcheng Fu\({}^{3}\), Ziwei Zhang\({}^{4}\), Cheng Ji\({}^{1,2}\),

Hao Peng\({}^{1}\), Jianxin Li\({}^{1,2}\)

\({}^{1}\)Beijing Advanced Innovation Center for Big Data and Brain Computing, Beihang University

\({}^{2}\)School of Computer Science and Engineering, Beihang University

\({}^{3}\)Key Lab of Education Blockchain and Intelligent Technology, Guangxi Normal University

\({}^{4}\)Department of Computer Science and Technology, Tsinghua University

{yuanhn,sunqy,jicheng,penghao,lijx}@buaa.edu.cn

fuxc@gxnu.edu.cn, zwzhang@tsinghua.edu.cn

Corresponding author

###### Abstract

Dynamic graph neural networks (DGNNs) are increasingly pervasive in exploiting spatio-temporal patterns on dynamic graphs. However, existing works fail to generalize under distribution shifts, which are common in real-world scenarios. As the generation of dynamic graphs is heavily influenced by latent environments, investigating their impacts on the out-of-distribution (OOD) generalization is critical. However, it remains unexplored with the following two major challenges: **(1)** How to properly model and infer the complex environments on dynamic graphs with distribution shifts? **(2)** How to discover invariant patterns given inferred spatio-temporal environments? To solve these challenges, we propose a novel **E**nvironment-**A**ware dynamic **G**raph **LE**arning (**E**agle)** framework for OOD generalization by modeling complex coupled environments and exploiting spatio-temporal invariant patterns. Specifically, we first design the environment-aware EA-DGNN to model environments by multi-channel environments disentangling. Then, we propose an environment instantiation mechanism for environment diversification with inferred distributions. Finally, we discriminate spatio-temporal invariant patterns for out-of-distribution prediction by the invariant pattern recognition mechanism and perform fine-grained causal interventions node-wisely with a mixture of instantiated environment samples. Experiments on real-world and synthetic dynamic graph datasets demonstrate the superiority of our method against state-of-the-art baselines under distribution shifts. To the best of our knowledge, we are the first to study OOD generalization on dynamic graphs from the environment learning perspective.

## 1 Introduction

Dynamic graphs are ubiquitous in the real world, like social networks [6; 25], financial transaction networks [61; 93], traffic networks [47; 97; 96], _etc._, where the graph topology evolves as time passes. Due to their complexity in both spatial and temporal correlation patterns, wide-ranging applications such as relation prediction [39; 68], anomaly detection [10; 69], _etc._ are rather challenging. With excellent expressive power, dynamic graph neural networks (DGNNs) achieve outstanding performance in dynamic graph representation learning by combining the merits of graph neural network (GNN) based models and sequential-based models.

Despite the popularity, most existing works are based on the widely accepted I.I.D. hypothesis, _i.e._, the training and testing data both follow the independent and identical distribution, which fails to generalize well [77] under the out-of-distribution (OOD) shifts in dynamic scenarios. Figure 1(a) illustrates a toy example demonstrating the OOD shifts on a dynamic graph. The failure lies in: (1) the exploited predictive patterns have changed for in-the-wild extrapolations, causing spurious correlations to be captured [94] and even strengthened with spatio-temporal convolutions. (2) performing causal intervention and inference without considering the impact of environments, introducing external bias of label shifting [91]. These can be explained by SCM model [64, 65, 66] in Figure 1(b).

As the generation of dynamic graphs is influenced by complicated interactions of multiple varying latent environment factors [86, 71, 8, 24, 3, 79, 78, 53], like heterogeneous neighbor relations, multi-community affiliations, _etc._, investigating the roles environments play in OOD generalization is of paramount importance. To tackle the issues above, we study the problem of generalized representation learning under OOD shifts on dynamic graphs in an environment view by carefully exploiting spatio-temporal invariant patterns. However, this problem is highly challenging in:

* How to understand and model the way latent environments behave on dynamic graphs over time?
* How to infer the distribution of underlying environments with the observed instances?
* How to recognize the spatio-temporal invariant patterns over changing surrounding environments?

To address these challenges, we propose a novel **E**nvironment-**A**ware dynamic **G**raph **LE**arning (**E**agle) framework for OOD generalization, which handles OOD generalization problem by exploiting spatio-temporal invariant patterns, thus filtering out spurious correlations via causal interventions over time. Our **E**agle solves the aforementioned challenges and achieves the OOD generalization target as follows. **Firstly**, to shed light on environments, we design the environment-aware EA-DGNN to model environments by multi-channel environments disentangling. It can be considered as learning the disentangled representations under multiple spatio-temporal correlated environments, which makes it possible to infer environment distributions and exploit invariant patterns. **Then**, we propose an environment instantiation mechanism for environment diversification with inferred environment distributions by applying the multi-label variational inference. This endows our **E**agle with higher generalizing power of potential environments. **Lastly**, we propose a novel invariant pattern recognition mechanism for out-of-distribution prediction that satisfies the Invariance Property and Sufficient Condition with theoretical guarantees. We then perform fine-grained causal interventions with a mixture of observed and generated environment instances to minimize the empirical and invariant risks. We optimize the whole framework by training with the adapted min-max strategy, encouraging **E**agle to generalize to diverse environments while learning on the spatio-temporal invariant patterns. Contributions of this paper are summarized as follows:

Figure 1: (a) shows the “user-item” interactions with heavy distribution shifts when the underlying environments change (_e.g._, seasons). A model could mistakenly predict that users would purchase an Iced Americano instead of a Hot Latte if it fails to capture spatio-temporal invariant patterns among spurious correlations. (b) analyzes the underlying cause of distribution shifts on dynamic graphs. It is broadly convinced [64, 67] that the spurious correlations of \(C\) (coffee) \(\leftrightarrow S\) (cold drink) within and between graph snapshots lead to poor OOD generalization under distribution shifts, which need to be filtered out via carefully investigating the impact of latent \(\mathbf{e}\). (Detailed discussions in Appendix F.1)

* We propose a novel framework named Eagle for OOD generalization by exploiting spatio-temporal invariant patterns with respect to environments. To the best of our knowledge, this is the first trial to explore the impact of environments on dynamic graphs under OOD shifts.
* We design the Environment "Modeling-Inferring-Discriminating-Generalizing" paradigm to endow Eagle with higher extrapolation power for future potential environments. Eagle can carefully model and infer underlying environments, thus recognizing the spatio-temporal invariant patterns and performing fine-grained causal intervention node-wisely with a mixture of observed and generated environment instances, which generalize well to diverse OOD environments.
* Extensive experiments on both real-world and synthetic datasets demonstrate the superiority of our method against state-of-the-art baselines for the future link prediction task.

## 2 Problem Formulation

In this section, we formulate the OOD generalization problem on dynamic graphs. Random variables are denoted as **bold** symbols while their realizations are denoted as \(italic\) letters. Notation with its description can be found in Appendix A.

**Dynamic Graph Learning.** Denote a dynamic graph as a set of discrete graphs snapshots \(\mathbf{D}\mathbf{G}=\{\mathcal{G}\}_{t=1}^{T}\), where \(T\) is the time length [94, 57], \(\mathcal{G}^{t}=(\mathcal{V}^{t},\mathcal{E}^{t})\) is the graph snapshot at time \(t\), \(\mathcal{V}^{t}\) is the node set and \(\mathcal{E}^{t}\) is the edge set. Let \(\mathbf{A}^{t}\in\{0,1\}^{N\times N}\) be the adjacency matrix and \(\mathbf{X}^{t}\in\mathbb{R}^{N\times d}\) be the matrix of node features, where \(N=|\mathcal{V}^{t}|\) denotes the number of nodes and \(d\) denotes the dimensionality. As the most challenging task on dynamic graphs, future link prediction task aims to train a predictor \(f_{\boldsymbol{\theta}}:\mathcal{V}\times\mathcal{V}\mapsto\{0,1\}^{N\times N}\) that predicts the existence of edges at time \(T+1\) given historical graphs \(\mathcal{G}^{1:T}\). Concretely, \(f_{\boldsymbol{\theta}}=w\circ g\) is compound of a DGNN \(w(\cdot)\) for learning node representations and a link predictor \(g(\cdot)\) for predicting links, _i.e._, \(\mathbf{Z}^{1:T}=w(\mathcal{G}^{1:T})\) and \(\hat{Y}^{T}=g(\mathbf{Z}^{1:T})\)

Figure 2: The framework of Eagle. Our proposed method jointly optimizes the following modules: (1) For a given dynamic graph generated under latent environments, the EA-DGNN first models environment by multi-channel environments disentangling. (2) The environment instantiation mechanism then infers the latent environments, followed by environment diversification with inferred distributions. (3) The invariant pattern recognition mechanism discriminates the spatio-temporal invariant patterns for OOD prediction. (4) Finally, Eagle generalizes to diverse environments by performing fine-grained causal interventions node-wisely with a mixture of environment instances. The Environment “Modeling-Inferring-Discriminating-Generalizing” paradigm endows Eagle with higher generalizing power for future potential environments.

The widely adopted Empirical Risk Minimization (ERM) [82] learns the optimal \(f^{\star}_{\bm{\theta}}\) as follows:

\[\min_{\bm{\theta}}\mathbb{E}_{(\mathcal{G}^{1:T},Y^{T})\sim p(\mathbf{G}^{1:T}, \mathbf{Y}^{T})}\left[\ell\left(f_{\bm{\theta}}\left(\mathcal{G}^{1:T}\right),Y ^{T}\right)\right].\] (1)

**OOD Generalization with Environments.** The predictor \(f^{\star}_{\bm{\theta}}\) learned in Eq. (1) may not generalize well to the testing set when there exist distribution shifts, _i.e._, \(p_{\mathrm{test}}(\mathbf{G}^{1:T},\mathbf{Y}^{T})\neq p_{\mathrm{train}}( \mathbf{G}^{1:T},\mathbf{Y}^{T})\). A broadly accepted assumption is that the distribution shifts on graphs are caused by multiple latent environments \(\mathbf{e}\)[86; 71; 8; 24; 3], which influence the generation of graph data, _i.e._, \(p(\mathbf{G}^{1:T},\mathbf{Y}^{T}\mid\mathbf{e})=p(\mathbf{G}^{1:T}\mid \mathbf{e})p(\mathbf{Y}^{T}\mid\mathbf{G}^{1:T},\mathbf{e})\). Denoting \(\mathbf{E}\) as the support of environments across \(T\) time slices, the optimization objective of OOD generalization can be reformulated as:

\[\min_{\bm{\theta}}\max_{\mathbf{e}\in\mathbf{E}}\mathbb{E}_{(\mathcal{G}^{1:T },Y^{T})\sim p(\mathbf{G}^{1:T},\mathbf{Y}^{T}|\mathbf{e})}\left[\ell\left(f_ {\bm{\theta}}\left(\mathcal{G}^{1:T}\right),Y^{T}\right)\mid\mathbf{e}\right],\] (2)

where the min-max strategy minimizes ERM under the worst possible environment. However, directly optimizing Eq. (2) is infeasible as the environment \(\mathbf{e}\) cannot be observed in the data. In addition, the training environments may not cover all the potential environments in practice, _i.e._, \(\mathbf{E}_{\mathrm{train}}\subseteq\mathbf{E}_{\mathrm{test}}\).

## 3 Method

In this section, we introduce **E**agle, an **E**nvironment-**A**ware dynamic **G**raph **L**E**arning framework, to solve the OOD generalization problem. The overall architecture of **E**agle is shown in Figure 2, following the **Environment "Modeling-Inferring-Discriminating-Generalizing"** paradigm.

### Environments Modeling with Environment-aware DGNN

To optimize the objectives of OOD generalization, we first need to infer the environments of dynamic graphs. In practice, the formation of real-world dynamic graphs typically follows a complex process under the impact of underlying environments [56; 51]. For example, the relationships in social networks are usually multi-attribute (_e.g._, colleagues, classmates, _etc._) and are changing over time (_e.g._, past classmates, current colleagues). Consequently, the patterns of message passing and aggregation in both spatial and temporal dimensions should be diversified in different environments, while the existing holistic approaches [94; 52] fail to distinguish them. To model spatio-temporal environments, we propose an **E**nvironment-**A**ware **D**ynamic **G**raph **N**eural **N**etwork (**EA-DGNN**) to exploit environment patterns by multi-channel environments disentangling.

**Environment-aware Convolution Layer (EAConv).** We perform convolutions following the "spatial first, temporal second" paradigm as most DGNNs do [54]. We consider that the occurrence of links is decided by \(K\) underlying environments \(\mathbf{e}_{v}=\{\mathbf{e}_{k}\}_{k=1}^{K}\) of the central node \(v\), which can be revealed by the features and structures of local neighbors. To obtain representations under multiple underlying environments, EAConv firstly projects the node features \(\mathbf{x}^{t}_{v}\) into \(K\) subspaces corresponding to different environments. Specifically, the environment-aware representation of node \(v\) with respect to the \(k\)-th environment \(\mathbf{e}_{k}\) at time \(t\) is calculated as:

\[\mathbf{z}^{t}_{v,k}=\sigma\left(\mathbf{W}^{\top}_{k}\left(\mathbf{x}^{t}_{v }\oplus\mathrm{RTE}(t)\right)+\mathbf{b}_{k}\right),\] (3)

where \(\mathbf{W}_{k}\in\mathbb{R}^{d\times d^{\prime}}\) and \(\mathbf{b}_{k}\in\mathbb{R}^{d^{\prime}}\) are learnable parameters, \(\mathrm{RTE}(\cdot)\) is the relative time encoding function, \(d^{\prime}\) is the dimension of \(\mathbf{z}^{t}_{v,k}\), \(\sigma(\cdot)\) is the activation function (_e.g._, the Sigmoid function), and \(\oplus\) is the element-wise addition.

To reflect the varying importance of environment patterns under \(K\) embedding spaces, we perform multi-channel convolutions with spatio-temporal aggregation reweighting for each \(\mathbf{e}_{k}\). Let \(\mathbf{A}^{t}_{(u,v),k}\) be the weight of edge \((u,v)\) under \(\mathbf{e}_{k}\) at time \(t\). The spatial convolutions of one EAConv layer are formulated as (note that we omit the layer superscript for brevity):

\[\dot{\mathbf{z}}^{t}_{v,k} =\mathbf{z}^{t}_{v,k}+\sum_{u\in\mathcal{N}^{t}(v)}\mathbf{A}^{t} _{(u,v),k}\mathbf{z}^{t}_{u,k},\] (4) \[\mathbf{A}^{t}_{(u,v),k} =\frac{\exp((\mathbf{z}^{t}_{u,k})^{\top}\mathbf{z}^{t}_{v,k})}{ \sum_{k^{\prime}=1}^{K}\exp((\mathbf{z}^{t}_{u,k^{\prime}})^{\top}\mathbf{z}^{t }_{v,k^{\prime}})},\] (5)where \(\mathcal{N}^{t}(v)\) is the neighbors of node \(v\) at time \(t\) and \(\hat{\mathbf{z}}\) denotes the updated node embedding. We then concatenate \(K\) embeddings from different environments as the final node representation \(\hat{\mathbf{z}}_{v}^{\mathbf{e},t}=\|k_{k=1}^{K}\hat{\mathbf{z}}_{v,k}^{\mathbf{ e}}\in\mathbb{R}^{K\times d^{\prime}}\), where \(\|\cdot\) means concatenation. After that, we conduct temporal convolutions holistically here for graph snapshots at time \(t\) and before:

\[\mathbf{z}_{v}^{\mathbf{e},t}=\frac{1}{t}\sum_{\tau=1}^{t}\hat{\mathbf{z}}_{v}^ {\mathbf{e},\tau}\in\mathbb{R}^{K\times d^{\prime}},\quad\text{where}\quad\hat {\mathbf{z}}_{v}^{\mathbf{e},\tau}=\left[\hat{\mathbf{z}}_{v,1}^{\tau}\|\hat{ \mathbf{z}}_{v,2}^{\tau}\|\cdots\|\hat{\mathbf{z}}_{v,K}^{\tau}\right].\] (6)

Note that, the temporal convolutions can be easily extended to other sequential convolution models or compounded with any attention/reweighting mechanisms.

**EA-DGNN Architecture.** The overall architecture of EA-DGNN is similar to general GNNs by stacking \(L\) layers of EAConv. In a global view, we exploit the patterns of environments by reweighting the multi-attribute link features with \(K\) channels. In the view of an individual node, multiple attributes in the link with neighbors can be disentangled to different attention when carrying out convolutions on both spatial and temporal dimensions. We further model the environment-aware representations by combining node representations at each time snapshot \(\mathbf{z}_{v}^{\mathbf{e}}=\bigcup_{t=1}^{T}\{\mathbf{z}_{v}^{\mathbf{e},t} \}\in\mathbb{R}^{T\times(K\times d^{\prime})}\).

### Environments Inferring with Environment Instantiation Mechanism

To infer environments with the environmental patterns, we propose an environment instantiation mechanism with multi-label variational inference, which can generate environment instances given multi-labels of time \(t\) and environment index \(k\).

**Environment Instantiation Mechanism** is a type of data augmentation to help OOD generalization. We regard the learned node embeddings \(\mathbf{z}_{v,k}^{t}\) as environment samples drawn from the ground-truth distribution of latent environment \(\mathbf{e}\). Particularly, we optimize a multi-label **E**nvironment-aware **C**onditional **V**ariational **A**utoEncoder (**ECVAE**) to infer the distribution of \(\mathbf{e}\sim q_{\phi}(\mathbf{e}\mid\mathbf{z},\mathbf{y})\) across \(T\). We have the following proposition. Proof for Proposition 1 can be found in Appendix C.1.

**Proposition 1**.: Given observed environment samples from the dynamic graph \(\mathcal{G}^{1:T}\) denoted as

\[\mathbf{z}=\bigcup_{v\in V}\bigcup_{k=1}^{K}\bigcup_{t=1}^{T}\{\mathbf{z}_{v, k}^{t}\}\in\mathbb{R}^{(|\mathcal{V}|\times K\times T)\times d^{\prime}} \xlongeqed{\mathrm{def}}\mathcal{S}_{\mathrm{ob}}\] (7)

with their corresponding one-hot multi-labels \(\mathbf{y}\), the environment variable \(\mathbf{e}\) is drawn from the prior distribution \(p_{\omega}(\mathbf{e}\mid\mathbf{y})\) across \(T\) time slices, and \(\mathbf{z}\) is generated from the distribution \(p_{\omega}(\mathbf{z}\mid\mathbf{y},\mathbf{e})\). Maximizing the conditional log-likelihood \(\log p_{\omega}(\mathbf{z}\mid\mathbf{y})\) leads to an optimal ECVAE by minimizing:

\[\mathcal{L}_{\mathrm{ECVAE}}=\mathrm{KL}[q_{\phi}(\mathbf{e}\mid\mathbf{z}, \mathbf{y})\|p_{\omega}(\mathbf{e}\mid\mathbf{y})]-\frac{1}{|\mathbf{z}|}\sum_ {i=1}^{|\mathbf{z}|}\log p_{\omega}(\mathbf{z}\mid\mathbf{y},\mathbf{e}^{(i)}),\] (8)

where \(\mathrm{KL}[\cdot\|\cdot]\) is the Kullback-Leibler (KL) divergence [37], \(|\mathbf{z}|\) is the number of observed environment samples, \(\mathbf{e}^{(i)}\) is the \(i\)-th sampling by the reparameterization trick.

**Sampling and Generating.** Proposition 1 demonstrates the training objectives of the proposed ECVAE. We realize ECVAE using fully connected layers, including an environment recognition network \(q_{\phi}(\mathbf{e}\mid\mathbf{z},\mathbf{y})\) as the encoder, a conditional prior network \(p_{\omega}(\mathbf{e}\mid\mathbf{y})\) as observed environment instantiations, and an environment sample generation network \(p_{\omega}(\mathbf{z}\mid\mathbf{y},\mathbf{e})\) as the decoder. By explicitly sampling latent \(\mathbf{e}_{i}\) from \(p_{\omega}(\mathbf{e})\), we can instantiate environments by generating samples \(\mathbf{z}_{k_{i}}^{t_{i}}\) from the the inferred distribution \(p_{\omega}(\mathbf{z}\mid\mathbf{y}_{i},\mathbf{e}_{i})\) with any given one-hot multi-label \(\mathbf{y}_{i}\) mixed up with the environment index \(k_{i}\) and time index \(t_{i}\). We denote the generated samples as \(\mathcal{S}_{\mathrm{ge}}\), which can greatly expand the diversity of the observed environments \(\mathcal{S}_{\mathrm{ob}}\) in Eq. (7).

### Environments Discriminating with Invariant Pattern Recognition

Inspired by the Independent Causal Mechanism (ICM) assumption [64; 65; 67], we next propose to learn the spatio-temporal invariant patterns utilizing our inferred and instantiated environments.

**Invariant Pattern Recognition Mechanism.** To encourage the model to rely on the invariant correlation that can generalize under distribution shifts, we propose an invariant pattern recognition mechanism to exploit spatio-temporal invariant patterns. We make the following assumption.

**Assumption 1** (Invariant and Sufficient).: Given the dynamic graph \(\mathcal{G}^{1:T}\), each node is associated with \(K\) surrounding environments. There exist spatio-temporal invariant patterns that can lead to generalized out-of-distribution prediction across all time slices. The function \(\mathbb{I}^{*}(\cdot)\) can recognize the spatio-temporal invariant patterns \(\mathcal{P}^{I}_{\mathbf{e}}\) and variant patterns \(\mathcal{P}^{V}_{\mathbf{e}}\) node-wisely, satisfying:

**(a) Invariance Property**: \(\forall\mathbf{e}\in\mathbf{E}\), \(\mathbb{I}^{*}(\mathbf{Z}^{1:T})\models\mathcal{P}^{I}_{\mathbf{e}}\), _s.t._\(p(\mathbf{Y}^{T}\mid\mathcal{P}^{I}_{\mathbf{e}},\mathbf{e})=p(\mathbf{Y}^ {T}\mid\mathcal{P}^{I}_{\mathbf{e}})\);

**(b) Sufficient Condition**: \(\mathbf{Y}^{T}=g(\mathbf{Z}^{1:T}_{I})+\epsilon\), _i.e._, \(\mathbf{Y}^{T}\perp\!\!\!\perp\mathcal{P}^{V}_{\mathbf{e}}\mid\mathcal{P}^{I}_ {\mathbf{e}}\), where \(\mathbf{Z}^{1:T}_{I}\) denotes representations under \(\mathcal{P}^{I}_{\mathbf{e}}\) over time, \(g(\cdot)\) is the link predictor, \(\epsilon\) is an independent noise.

Assumption 1 indicates that the modeled environment-aware representations of nodes under \(\mathcal{P}^{I}_{\mathbf{e}}\) contain a portion of spatio-temporal invariant causal features that contribute to generalized OOD prediction over time. Invariance Property guarantees for any environment \(\mathbf{e}\), function \(\mathbb{I}^{*}(\cdot)\) can always recognize the invariant patterns \(\mathcal{P}^{I}_{\mathbf{e}}\) with the observation of \(\mathbf{Z}^{1:T}\), and Sufficient Condition ensures the information contained in \(\mathbf{Z}^{1}_{\mathbf{j}}\):\(T\) is adequate for the link predictor to make correct predictions.

Next, we show that \(\mathbb{I}^{*}(\cdot)\) in Proposition 2 can be instantiated with the following proposition.

**Proposition 2** (A Solution for \(\mathbb{I}^{*}(\cdot)\)).: Denote \(\mathbf{z}^{\mathbf{e}\prime}_{v}=[\mathbf{z}^{\prime}_{v,1},\mathbf{z}^{ \prime}_{v,2},\cdots,\mathbf{z}^{\prime}_{v,K}]\), where \(\mathbf{z}^{\prime}_{v,k}=\bigcup_{t=1}^{T}\mathbf{z}^{t}_{v,k}\). Let \(\mathrm{Var}(\mathbf{z}^{\mathbf{e}\prime}_{v})\in\mathbb{R}^{K}\) represents the variance of \(K\) environment-aware representations. The Boolean function \(\mathbb{I}(\cdot)\) is a solution for \(\mathbb{I}^{*}(\cdot)\) with the following state update equation:

\[\mathbb{I}(i,j)=\begin{cases}\mathbb{I}(i-1,j)\vee\mathbb{I}(i-1,j-\mathrm{ Var}(\mathbf{z}^{\mathbf{e}\prime}_{v})[i-1]),&j\geq\mathrm{Var}(\mathbf{z}^{ \mathbf{e}\prime}_{v})[i-1]\\ \mathbb{I}(i-1,j),&\text{otherwise}\end{cases},\] (9)

\(\mathbb{I}(i,j)\) indicates whether it is feasible to select from the first \(i\) elements in \(\mathrm{Var}(\mathbf{z}^{\mathbf{e}\prime}_{v})\) so that their sum is \(j\). Traversing \(j\) in reverse order from \(\lfloor\sum\mathrm{Var}(\mathbf{z}^{\mathbf{e}\prime}_{v})/2\rfloor\) until satisfying \(\mathbb{I}(K,j)\) is True, we reach:

\[\delta_{v}=\sum\mathrm{Var}(\mathbf{z}^{\mathbf{e}\prime}_{v})-2j,\] (10) \[\mathcal{P}^{I}_{\mathbf{e}}(v)=\left\{\mathbf{e}_{k}\mid\mathrm{ Var}(\mathbf{z}^{\mathbf{e}\prime}_{v})[k]\leq\frac{1}{K}\sum\mathrm{Var}( \mathbf{z}^{\mathbf{e}\prime}_{v})-\frac{\delta_{v}}{2}\right\},\quad\mathcal{ P}^{V}_{\mathbf{e}}(v)=\overline{\mathcal{P}^{I}_{\mathbf{e}}(v)},\] (11)

where \(\delta_{v}\) is the optimal spatio-temporal invariance threshold of node \(v\).

Proposition 2 solves a dynamic programming problem to obtain the optimal \(\mathbb{I}^{*}(\cdot)\), whose target is to find a partition dividing all patterns into variant/invariant set with the maximum difference between the variance means that reveals the current invariance status, providing an ideal optimizing start point. The proof can be found in Appendix C.2.

With the theoretical support of Assumption 1 and Proposition 2, we can recognize the spatio-temporal invariant/variant patterns \(\mathcal{P}^{I}_{\mathbf{e}}=\bigcup_{v\in\mathcal{V}}\mathcal{P}^{I}_{ \mathbf{e}}(v)\) and \(\mathcal{P}^{V}_{\mathbf{e}}=\bigcup_{v\in\mathcal{V}}\mathcal{P}^{V}_{ \mathbf{e}}(v)\) with respect to the underlying environments for each node over a period of time by applying \(\mathbb{I}(\cdot)\).

### Environments Generalizing with Causal Intervention

**Generalization Optimization Objective.** Eq. (2) clarifies the training objective of OOD generalization. However, directly optimizing Eq. (2) is not impracticable. Based on the inferred and generated environments in Section 3.2 and spatio-temporal invariant patterns learned in Section 3.3, we further modify Eq. (2) to improve the model's OOD generalization ability by applying the intervention mechanism node-wisely with causal inference. Specifically, we have the following objectives:

\[\min_{\boldsymbol{\theta}}\mathcal{L}_{\mathrm{task}}+\alpha \mathcal{L}_{\mathrm{risk}},\] (12) \[\mathcal{L}_{\mathrm{task}}=\mathbb{E}_{\mathbf{e}\sim q_{\phi}( \mathbf{e}),(\mathcal{G}^{1:T},Y^{T})\sim p(\mathbf{G}^{1:T},\mathbf{Y}^{T}| \mathbf{e})}\left[\ell\left(g(\mathbf{Z}^{1:T}_{I}),Y^{T}\right)\right],\] (13) \[\mathcal{L}_{\mathrm{risk}}=\mathrm{Var}_{s\in\mathcal{S}}\left\{ \mathbb{E}_{\mathbf{e}\sim q_{\phi}(\mathbf{e}),(\mathcal{G}^{1:T},Y^{T})\sim p (\mathbf{G}^{1:T},\mathbf{Y}^{T}|\mathbf{e})}\left[\ell\left(f_{\boldsymbol{ \theta}}\left(\mathcal{G}^{1:T}\right),Y^{T}\mid\mathrm{do}(\mathbf{Z}^{1:T}_{ V}=s)\right)\right]\right\},\] (14)

where \(q_{\phi}(\mathbf{e})\) is the environment distribution in Section 3.2, \(\mathrm{do}(\cdot)\) is the \(do\)-calculus that intervenes the variant patterns, \(\mathcal{S}=\mathcal{S}_{\mathrm{ob}}\cup\mathcal{S}_{\mathrm{ge}}\) is the observed and generated environment instances for interventions, and \(\alpha\) is a hyperparameter. We show the optimality of Eq. (12) with the following propositions:

**Proposition 3** (Achievable Assumption).: Minimizing Eq. (12) can encourage the model to satisfy the Invariance Property and Sufficient Condition in Assumption 1.

[MISSING_PAGE_FAIL:7]

Though dynamic GNNs are designed to capture spatio-temporal features, they even underperform static GNNs in several settings, mainly because the predictive patterns they exploited are variant with spurious correlations. Conventional OOD generalization baselines have limited improvements as they rely on the environment labels to generalize, which are inaccessible on dynamic graphs. As the most related work, DIDA [94] achieves further progress by learning invariant patterns. However, it is limited by the lack of in-depth analysis into the environments, causing the label shift phenomenon [91] that damages its generalization ability. With the critical investigation of latent environments and theoretical guarantees, our Eagle consistently outperforms the baselines and achieves the best performance in all _w/ OOD_ settings and two _w/o OOD_ settings. Especially even on the most challenging COLLAB, where the time span is extremely long (1990 to 2006) and its link attributes difference is huge.

#### 4.1.2 Distribution Shifts of Node Features

**Setting.** We further introduce settings of node feature shifts on COLLAB. We respectively sample \(p(t)|\mathcal{E}^{t+1}|\) positive links and \((1-p(t))|\mathcal{E}^{t+1}|\) negative links, which are then factorized into shifted features \(\mathbf{X}^{t\prime}\in\mathbb{R}^{|\mathcal{V}|\times d}\) while preserving structural property. The sampling probability \(p(t)=\bar{p}+\sigma\cos(t)\), where \(\mathbf{X}^{t\prime}\) with higher \(p(t)\) will have stronger spurious correlations with future underlying environments. We set \(\bar{p}\) to be 0.4, 0.6 and 0.8 for training and 0.1 for testing. In this way, training data are relatively higher spuriously correlated than the testing data. We omit results on static GNNs as they cannot support dynamic node features. Detailed settings are in Appendix D.3.

**Results.** Results are reported in Table 2. We can observe a similar trend as Table 1, _i.e._, our method better handles distribution shifts of node features on dynamic graphs than the baselines. Though some baselines can report reasonably high performance on the training set, their performance drops drastically in the testing stage. In comparison, our method reports considerably smaller gaps. In particular, our Eagle surpasses the best-performed baseline by approximately 3%/5%/10% of AUC in the testing set under different shifting levels. Interestingly, as severer distribution shifts will lead to more significant performance degradation where the spurious correlations are strengthened, our method gains better task performance with a higher shifting degree. This demonstrates Eagle is more capable of eliminating spatio-temporal spurious correlations in severer OOD environments.

### Investigation on Invariant Pattern Recognition Mechanism

**Settings.** We generate synthetic datasets by manipulating environments to investigate the effect of the invariant pattern recognition mechanism. We set \(K=5\) and let \(\sigma_{\mathbf{e}}\) represent the proportion of the environments in which the invariant patterns are learned, where higher \(\sigma_{\mathbf{e}}\) means more reliable invariant patterns. Node features are drawn from multivariate normal distributions, and features under the invariant patterns related \(\mathbf{e}_{k}\) will be perturbed slightly and vice versa. We construct graph structures and filter out links built under a certain \(\mathbf{e}_{k}\) as the same in Section 4.1.1. We compare Eagle with the most related and strongest baseline DIDA [94]. Detailed settings are in Appendix D.3.

**Results.** Results are shown in Figure 3. \(\mathds{I}_{\mathrm{ACC}}\) denotes the prediction accuracy of the invariant patterns by \(\mathbb{I}(\cdot)\). We observe that, as \(\sigma_{\mathbf{e}}\) increases, the performance of Eagle shows a significant increase from 54.26% to 65.09% while narrowing the gap between _w/o OOD_ and _w/ OOD_ scenarios.

\begin{table}
\begin{tabular}{c|c c|c c|c c} \hline \hline
**Dataset** & \multicolumn{2}{c|}{**COLLAB**} & \multicolumn{2}{c|}{**Yelp**} & \multicolumn{2}{c}{**ACT**} \\ \hline
**Model** & _w/o OOD_ & _w/OOD_ & _w/o OOD_ & _w/o OOD_ & _w/ OOD_ \\ \hline GAE [42] & 77.15±0.50 & 74.04±0.75 & 70.67±1.11 & 64.45±5.02 & 72.31±0.53 & 60.27±0.41 \\ VGAE [42] & 86.47±0.04 & 74.95±1.25 & 76.54±0.50 & 65.33±1.43 & 79.18±0.47 & 66.29±1.33 \\ GCRN [76] & 82.78±0.54 & 69.72±0.46 & 68.95±1.05 & 68.64±5.97 & 76.28±0.51 & 64.35±1.24 \\ EvoleyGN [62] & 86.62±0.95 & 76.15±0.91 & 78.21±0.03 & 53.82±2.06 & 74.5±0.33 & 63.17±1.05 \\ DySAT [75] & 88.77±0.23 & 76.59±0.20 & 78.87±0.57 & 66.09±1.42 & 78.52±0.40 & 66.55±1.21 \\ IRM [3] & 87.96±0.90 & 75.42±0.87 & 66.49±10.78 & 56.02±16.08 & 80.02±0.57 & 69.19±1.35 \\ V-REx [44] & 88.13±0.32 & 76.24±0.77 & 79.04±0.16 & 66.41±1.87 & 83.11±0.29 & 70.15±1.09 \\ GroupDRO [74] & 88.76±0.12 & 76.33±0.29 & **79.38±0.42** & 66.97±0.61 & 85.19±0.53 & 74.35±1.62 \\ DIDA [94] & 91.97±0.05 & 81.87±0.40 & 78.22±0.40 & 75.92±0.90 & 89.84±0.82 & 78.64±0.97 \\ \hline
**Eagle** & **92.45±0.21** & **84.41±0.87** & 78.97±0.31 & **77.26±0.74** & **92.37±0.53** & **82.70±0.72** \\ \hline \hline \end{tabular}
\end{table}
Table 1: AUC score (% \(\pm\) standard deviation) of future link prediction task on real-world datasets with OOD shifts of link attributes. The best results are shown in **bold** and the runner-ups are underlined.

Though DIDA [94] also shows an upward trend, its growth rate is more gradual. This indicates that, as DIDA [94] is incapable of modeling the environments, it is difficult to perceive changes in the underlying environments caused by different \(\sigma_{\text{e}}\), thus cannot achieve satisfying generalization performance. In comparison, our Eagle can exploit more reliable invariant patterns, thus performing high-quality invariant learning and efficient causal interventions, and achieving better generalization ability. In addition, we also observe a positive correlation between \(\mathbb{I}_{\mathrm{ACC}}\) and the AUC, indicating the improvements is attributed to the accurate recognition of the invariant patterns by \(\mathbb{I}(\cdot)\). Additional results are in Appendix D.7.

### Ablation Study

In this section, we conduct ablation studies to analyze the effectiveness of three main mechanisms:

* **Eagle (w/o EI).** We remove the **E**nvironment **I**nstantiation mechanism in Section 3.2, and carrying out causal interventions in Eq. (15) with only observed environment samples.
* **Eagle (w/o IPR).** We remove the **I**nvariant **P**attern **R**ecognition mechanism in Section 3.3, and determining the spatio-temporal invariant patterns \(\mathcal{P}_{\text{e}}^{I}\) by randomly generating \(\delta_{v}\) for each node.
* **Eagle (w/o Interv).** We remove the spatio-temporal causal **Interv**ention mechanism in Section 3.4 and directly optimize the model by Eq. (16) without the second \(\mathcal{L}_{\mathrm{risk}}\) term.

**Results.** Results are demonstrated in Figure 4. Overall, Eagle consistently outperforms the other three variants on all datasets. The ablation studies provide insights into the effectiveness of the proposed mechanisms and demonstrate their importance in achieving better performance for OOD generalization on dynamic graphs.

### Visualization

We visualize snapshots in COLLAB using NetworkX [27] as shown in Figure 5, where colors reflect latent environments, numbers denote edge weights, solid lines implicate spatio-temporal invariant patterns dependencies, and dashed lines implicate variant patterns dependencies. Eagle can gradually exploit the optimal invariant patterns and strengthen reliance, making generalized predictions.

\begin{table}
\begin{tabular}{c|c c|c c|c c} \hline \hline
**Dataset** & \multicolumn{2}{c}{**COLLAB (\(\bm{\beta=0.4}\))**} & \multicolumn{2}{c|}{**COLLAB (\(\bm{\beta=0.6}\))**} & \multicolumn{2}{c}{**COLLAB (\(\bm{\beta=0.8}\))**} \\ \hline
**Model** & Train & Test & Train & Test & Train & Test \\ \hline GCRN [76] & 69.60±1.14 & 72.57±0.72 & 74.71±0.17 & 72.29±0.47 & 75.69±0.07 & 67.26±0.22 \\ EvolveGCN [62] & 78.82±1.40 & 69.00±0.53 & 79.47±1.68 & 62.70±1.14 & 81.07±1.40 & 60.13±0.89 \\ DySxf [75] & 84.71±0.80 & 70.24±1.26 & 89.77±0.32 & 64.01±10.19 & 94.02±1.29 & 62.19±0.39 \\ IRM [3] & 85.20±0.07 & 69.40±0.09 & 89.48±0.22 & 63.97±0.37 & **95.02±0.09** & 62.66±0.33 \\ V-REx [44] & 84.77±0.84 & 70.44±1.08 & 89.81±0.21 & 63.99±0.21 & 94.06±1.30 & 62.21±0.40 \\ GroupDRO [74] & 84.78±0.85 & 70.30±1.23 & 89.90±0.11 & 64.05±0.21 & 94.08±1.33 & 62.13±0.35 \\ DIDA [94] & 87.92±0.92 & 85.0±0.84 & 91.22±0.59 & 82.89±0.23 & 92.72±2.16 & 72.59±3.31 \\ \hline
**Eagle** & **92.97±0.88** & **88.32±0.61** & **94.52±0.42** & **87.29±0.71** & 94.11±1.03 & **82.30±0.75** \\ \hline \hline \end{tabular}
\end{table}
Table 2: AUC score (% ± standard deviation) of future link prediction task on real-world datasets with OOD shifts of node features. The best results are shown in bold and the runner-ups are underlined.

## 5 Related Work

**Dynamic Graph Learning.** Extensive researches [70; 4; 38; 90; 85; 35] address the challenges of dynamic graph learning. Dynamic graph neural networks (DGNNs) are intrinsically utilized to model both spatial and temporal patterns [88; 76; 84; 73; 62; 75; 80; 21] by combining vanilla GNNs and sequential-based models [58; 31; 28]. However, most existing works fail to generalize under distribution shifts. DIDA [94] is the sole prior work that tackles distribution shifts on dynamic graphs, but it neglects to model the complex environments, which is crucial in identifying invariant patterns.

**Out-of-Distribution Generalization.** Most machine learning methods are built on the I.I.D. hypothesis, which can hardly be satisfied in real-world scenarios [77; 71; 3]. Out-of-distribution (OOD) generalization has been extensively studied in both academia and industry areas [77; 92; 30] and we mainly focus on graphs. Most works concentrate on static graphs for node-level or graph-level tasks [98; 18; 49; 86; 52; 12; 87], supporting by invariant learning method [14; 46; 95] with disentangled learning [5; 55] and causal inference theories [65; 66; 64]. However, there lack of further research on dynamic graphs with more complicated shift patterns caused by spatio-temporal varying latent environments, which is our main concern.

**Invariant Learning.** Invariant learning aims to exploit the fewer variant patterns that lead to informative and discriminative representations for stable prediction [14; 46; 95]. Supporting by disentangled learning theories and causal learning theories, invariant learning tackles the OOD generalization problem from a more theoretical perspective, revealing a promising power. Disentangle-based methods [5; 55] learn representations by separating semantic factors of variations in data, making it easier to distinguish invariant factors and establish reliable correlations. Causal-based methods [22; 3; 72; 87; 11; 2; 60] utilize Structural Causal Model (SCM) [64] to filter out spurious correlations by intervention or counterfactual with \(do\)-calculus [65; 66] and strengthen the invariant causal patterns. However, the invariant learning method of node-level tasks on dynamic graphs is underexplored, mainly due to its complexity in analyzing both spatial and temporal invariant patterns.

## 6 Conclusion

In this paper, we propose a novel framework **E**agle for out-of-distribution (OOD) generalization on dynamic graphs by modeling complex dynamic environments for the first time and further exploiting spatio-temporal invariant patterns. **E**agle first models environment by an environment-aware DGNN, and then diversifies the observed environment samples with the environment instantiation mechanism, and finally learns OOD generalized spatio-temporal invariant patterns by the invariant pattern recognition mechanism and performs fine-grained causal interventions node-wisely. Experiment results on both real-world and synthetic datasets demonstrate that **E**agle greatly outperforms existing methods under distribution shifts. One limitation is that we mainly consider the node-level tasks, and leave extending our method to the graph-level OOD generalization for future explorations.

## Acknowledgements

The corresponding author is Qingyun Sun. The authors of this paper are supported by the National Natural Science Foundation of China through grants No.62225202, No.62302023, and No.62206149. We owe sincere thanks to all authors for their valuable efforts and contributions. We also acknowledge the support of MindSpore, CANN (Compute Architecture for Neural Networks) and Ascend AI Processor used for this research.

Figure 5: Visualization of snapshots in COLLAB.

## References

* [1]A. Fred Agarap (2018) Deep learning using rectified linear units (ReLU). arXiv preprint arXiv:1803.08375. Cited by: SS1.
* [2]K. Ahuja, K. Shanmugam, K. R. Varshney, and A. Dhurandhar (2020) Invariant risk minimization games. In Proceedings of the 37th International Conference on Machine Learning, Proceedings of Machine Learning Research, pp. 145-155. Cited by: SS1.
* [3]M. Arjovsky, L. Bottou, I. Gulrajani, and D. Lopez-Paz (2019) Invariant risk minimization. arXiv preprint arXiv:1907.02893. Cited by: SS1.
* [4]G. Atluri, A. Karpatne, and V. Kumar (2018) Spatio-temporal data mining: a survey of problems and methods. ACM Computing Surveys51 (4), pp. 1-41. Cited by: SS1.
* [5]Y. Bengio, A. Courville, and P. Vincent (2013) Representation learning: a review and new perspectives. IEEE Transactions on Pattern Analysis and Machine Intelligence35 (8), pp. 1798-1828. Cited by: SS1.
* [6]T. J. Berger-Wolf and J. Saia (2006) A framework for analysis of dynamic social networks. In Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 523-528. Cited by: SS1.
* [7]A. P. Bradley (1997) The use of the area under the ROC curve in the evaluation of machine learning algorithms. Pattern Recognition30 (7), pp. 1145-1159. Cited by: SS1.
* [8]P. Buhlmann (2018) Invariance, causality and robustness. arXiv preprint arXiv:1812.08233. Cited by: SS1.
* [9]R. Cadene, C. Dancette, M. Cord, D. Parikh, et al. (2019) Rubin: reducing unimodal biases for visual question answering. Advances in Neural Information Processing Systems32. Cited by: SS1.
* [10]L. Cai, Z. Chen, C. Luo, J. Gui, J. Ni, D. Li, and H. Chen (2021) Structural temporal graph neural networks for anomaly detection in dynamic graphs. In Proceedings of the 30th ACM International Conference on Information and Knowledge Management, pp. 3747-3756. Cited by: SS1.
* [11]S. Chang, Y. Zhang, M. Yu, and T. S. Jaakkola (2020) Invariant rationalization. In Proceedings of the 37th International Conference on Machine Learning, Proceedings of Machine Learning Research, pp. 1448-1458. Cited by: SS1.
* [12]Y. Chen, Y. Zhang, Y. Bian, H. Yang, M. Kaili, B. Xie, T. Liu, B. Han, and J. Cheng (2022) Learning causally invariant representations for out-of-distribution generalization on graphs. Advances in Neural Information Processing Systems35, pp. 22131-22148. Cited by: SS1.
* [13]K. Cho, B. van Merrienboer, C. Gulcehre, D. Bahdanau, F. Bougares, H. Schwenk, and Y. Bengio (2014) Learning phrase representations using RNN encoder-decoder for statistical machine translation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, pp. 1724-1734. Cited by: SS1.
* [14]E. Creager, J. Jacobsen, and R. S. Zemel (2021) Environment inference for invariant learning. In Proceedings of the 38th International Conference on Machine Learning, Proceedings of Machine Learning Research, pp. 2189-2200. Cited by: SS1.
* [15]D. Dai and L. V. Gool (2018) Dark model adaptation: semantic image segmentation from daytime to nighttime. In International Conference on Intelligent Transportation Systems, pp. 3819-3824. Cited by: SS1.
* [16]P. De Boer, D. P. Kroese, S. Mannor, and R. Y. Rubinstein (2005) A tutorial on the cross-entropy method. Annals of Operations Research134, pp. 67. Cited by: SS1.
* [17]M. Ding, K. Kong, J. Chen, J. Kirchenbauer, M. Goldblum, D. Wipf, F. Huang, and T. Goldstein (2021) A closer look at distribution shifts and out-of-distribution generalization on graphs. In NeurIPS 2021 Workshop on Distribution Shifts: Connecting Methods and Applications, Cited by: SS1.
* [18]S. Fan, X. Wang, C. Shi, P. Cui, and B. Wang (2021) Generalizing graph neural networks on out-of-distribution graphs. arXiv preprint arXiv:2111.10657. Cited by: SS1.

[MISSING_PAGE_POST]

* [21] Xingcheng Fu, Yuecen Wei, Qingyun Sun, Haonan Yuan, Jia Wu, Hao Peng, and Jianxin Li. Hyperbolic geometric graph representation learning for hierarchy-imbalance node classification. In _Proceedings of the ACM Web Conference_, pages 460-468, 2023.
* [22] Jean-Christophe Gagnon-Audet, Kartik Ahuja, Mohammad-Javad Darvishi-Bayazi, Guillaume Dumas, and Irina Rish. WOODS: Benchmarks for out-of-distribution generalization in time series tasks. _arXiv preprint arXiv:2203.09978_, 2022.
* [23] Walter R Gilks, Sylvia Richardson, and David Spiegelhalter. _Markov chain Monte Carlo in practice_. CRC press, 1995.
* [24] Mingming Gong, Kun Zhang, Tongliang Liu, Dacheng Tao, Clark Glymour, and Bernhard Scholkopf. Domain adaptation with conditional transferable components. In _Proceedings of the 33nd International Conference on Machine Learning_, volume 48 of _JMLR Workshop and Conference Proceedings_, pages 2839-2848. JMLR.org, 2016.
* [25] Derek Greene, Donal Doyle, and Padraig Cunningham. Tracking the evolution of communities in dynamic social networks. In _2010 International Conference on Advances in Social Networks Analysis and Mining_, pages 176-183. IEEE, 2010.
* [26] Shurui Gui, Xiner Li, Limei Wang, and Shuiwang Ji. GOOD: A graph out-of-distribution benchmark. _Advances in Neural Information Processing Systems_, 35:2059-2073, 2022.
* [27] Aric Hagberg, Pieter Swart, and Daniel S Chult. Exploring network structure, dynamics, and function using networkx. Technical report, Los Alamos National Lab.(LANL), Los Alamos, NM (United States), 2008.
* [28] Ehsan Hajiramezanali, Arman Hasanzadeh, Krishna Narayanan, Nick Duffield, Mingyuan Zhou, and Xiaoning Qian. Variational graph recurrent neural networks. _Advances in Neural Information Processing Systems_, 32, 2019.
* [29] John A Hartigan and Manchek A Wong. Algorithm as 136: A K-means clustering algorithm. _Journal of the Royal Statistical Society. Series C (Applied Statistics)_, 28(1):100-108, 1979.
* [30] Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, et al. The many faces of robustness: A critical analysis of out-of-distribution generalization. In _Proceedings of the IEEE/CVF International Conference on Computer Vision_, pages 8340-8349, 2021.
* [31] Sepp Hochreiter and Jurgen Schmidhuber. Long short-term memory. _Neural Computation_, 9(8):1735-1780, 1997.
* [32] Ziniu Hu, Yuxiao Dong, Kuansan Wang, and Yizhou Sun. Heterogeneous graph transformer. In _Proceedings of the Web Conference_, pages 2704-2710, 2020.
* [33] Huawei. Mindspore. https://www.mindspore.cn/, 2020.
* [34] Johan Ludwig William Valdemar Jensen. Sur les fonctions convexes et les inegalites entre les valeurs moyennes. _Acta Mathematica_, 30(1):175-193, 1906.
* [35] Cheng Ji, Tao Zhao, Qingyun Sun, Xingcheng Fu, and Jianxin Li. Higher-order memory guided temporal random walk for dynamic heterogeneous network embedding. _Pattern Recognition_, page 109766, 2023.
* [36] Yuanfeng Ji, Lu Zhang, Jiaxiang Wu, Bingzhe Wu, Long-Kai Huang, Tingyang Xu, Yu Rong, Lanqing Li, Jie Ren, Ding Xue, et al. DrugOOD: Out-of-distribution (OOD) dataset curator and benchmark for ai-aided drug discovery-a focus on affinity prediction problems with noise annotations. _arXiv preprint arXiv:2201.09637_, 2022.
* [37] James M Joyce. Kullback-leibler divergence. In _International Encyclopedia of Statistical Science_, pages 720-722. Springer, 2011.
* [38] Amol Kapoor, Xue Ben, Luyang Liu, Bryan Perozzi, Matt Barnes, Martin Blais, and Shawn O'Banion. Examining covid-19 forecasting using spatio-temporal graph neural networks. _arXiv preprint arXiv:2007.03113_, 2020.
* [39] Seyed Mehran Kazemi, Rishab Goel, Kshitij Jain, Ivan Kobyzev, Akshay Sethi, Peter Forsyth, and Pascal Poupart. Representation learning for dynamic graphs: A survey. _The Journal of Machine Learning Research_, 21(1):2648-2720, 2020.

* [40] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In _3rd International Conference on Learning Representations_, 2015.
* [41] Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. _arXiv preprint arXiv:1609.02907_, 2016.
* [42] Thomas N Kipf and Max Welling. Variational graph auto-encoders. _arXiv preprint arXiv:1611.07308_, 2016.
* [43] Alexander Kraskov, Harald Stogbauer, and Peter Grassberger. Estimating mutual information. _Physical Review E_, 69(6):066138, 2004.
* [44] David Krueger, Ethan Caballero, Jorn-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai Zhang, Remi Le Priol, and Aaron C. Courville. Out-of-distribution generalization via risk extrapolation (rex). In _Proceedings of the 38th International Conference on Machine Learning_, volume 139 of _Proceedings of Machine Learning Research_, pages 5815-5826. PMLR, 2021.
* [45] Srijan Kumar, Xikun Zhang, and Jure Leskovec. Predicting dynamic embedding trajectory in temporal interaction networks. In _Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining_, pages 1269-1278. ACM, 2019.
* [46] Bo Li, Yezhen Wang, Shanghang Zhang, Dongsheng Li, Kurt Keutzer, Trevor Darrell, and Han Zhao. Learning invariant representations and risks for semi-supervised domain adaptation. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pages 1104-1113, 2021.
* [47] Fuxian Li, Jie Feng, Huan Yan, Guangyin Jin, Fan Yang, Funing Sun, Depeng Jin, and Yong Li. Dynamic graph convolutional recurrent network for traffic prediction: Benchmark and solution. _ACM Transactions on Knowledge Discovery from Data_, 17(1):1-21, 2023.
* [48] Haoyang Li, Xin Wang, Ziwei Zhang, Zehuan Yuan, Hang Li, and Wenwu Zhu. Disentangled contrastive learning on graphs. _Advances in Neural Information Processing Systems_, 34:21872-21884, 2021.
* [49] Haoyang Li, Xin Wang, Ziwei Zhang, and Wenwu Zhu. OOD-GNN: Out-of-distribution generalized graph neural network. _IEEE Transactions on Knowledge and Data Engineering_, 2022.
* [50] Haoyang Li, Xin Wang, Ziwei Zhang, and Wenwu Zhu. Out-of-distribution generalization on graphs: A survey. _arXiv preprint arXiv:2202.07987_, 2022.
* [51] Haoyang Li, Ziwei Zhang, Xin Wang, and Wenwu Zhu. Disentangled graph contrastive learning with independence promotion. _IEEE Transactions on Knowledge and Data Engineering_, 2022.
* [52] Haoyang Li, Ziwei Zhang, Xin Wang, and Wenwu Zhu. Learning invariant graph representations for out-of-distribution generalization. In _Advances in Neural Information Processing Systems_, 2022.
* [53] Jianxin Li, Qingyun Sun, Hao Peng, Beining Yang, Jia Wu, and S Yu Phillp. Adaptive subgraph neural network with reinforced critical structure mining. _IEEE Transactions on Pattern Analysis and Machine Intelligence_, 2023.
* [54] Jianxin Li, Shuai Zhang, Hui Xiong, and Haoyi Zhou. Autost: Towards the universal modeling of spatio-temporal sequences. In _Advances in Neural Information Processing Systems_, volume 35, pages 20498-20510, 2022.
* [55] Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar Ratsch, Sylvain Gelly, Bernhard Scholkopf, and Olivier Bachem. Challenging common assumptions in the unsupervised learning of disentangled representations. In _Proceedings of the 36th International Conference on Machine Learning_, volume 97 of _Proceedings of Machine Learning Research_, pages 4114-4124. PMLR, 2019.
* [56] Jianxin Ma, Peng Cui, Kun Kuang, Xin Wang, and Wenwu Zhu. Disentangled graph convolutional networks. In _Proceedings of the 36th International Conference on Machine Learning_, volume 97 of _Proceedings of Machine Learning Research_, pages 4212-4221. PMLR, 2019.
* [57] Franco Manessi, Alessandro Rozza, and Mario Manzo. Dynamic graph convolutional networks. _Pattern Recognition_, 97:107000, 2020.
* [58] Larry R Medsker and LC Jain. Recurrent neural networks. _Design and Applications_, 5:64-67, 2001.
* [59] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word representations in vector space. In _1st International Conference on Learning Representations_, 2013.

* [60] Jovana Mitrovic, Brian McWilliams, Jacob C. Walker, Lars Holger Buesing, and Charles Blundell. Representation learning via invariant causal mechanisms. In _9th International Conference on Learning Representations_. OpenReview.net, 2021.
* [61] Diego C Nascimento, Bruno A Pimentel, Renata MCR Souza, Lilia Costa, Sandro Goncalves, and Francisco Louzada. Dynamic graph in a symbolic data framework: An account of the causal relation using covid-19 reports and some reflections on the financial world. _Chaos, Solitons & Fractals_, 153:111440, 2021.
* [62] Aldo Pareja, Giacomo Domeniconi, Jie Chen, Tengfei Ma, Toyotaro Suzumura, Hiroki Kanezashi, Tim Kaler, Tao B. Schardl, and Charles E. Leiserson. Evolvegcn: Evolving graph convolutional networks for dynamic graphs. In _The Thirty-Fourth AAAI Conference on Artificial Intelligence_, pages 5363-5370. AAAI Press, 2020.
* [63] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. _Advances in Neural Information Processing Systems_, 32, 2019.
* [64] Pearl and Judea. Causal inference in statistics: An overview. _Statistics Surveys_, 3:96-146, 2009.
* [65] Judea Pearl. Causal inference. _Causality: Objectives and Assessment_, pages 39-58, 2010.
* [66] Judea Pearl and Dana Mackenzie. _The Book of Why: the New Science of Cause and Effect_. Basic books, 2018.
* [67] Jonas Peters, Dominik Janzing, and Bernhard Scholkopf. _Elements of causal inference: foundations and learning algorithms_. The MIT Press, 2017.
* [68] Anton V Proskurnikov and Roberto Tempo. A tutorial on modeling and analysis of dynamic social networks. part i. _Annual Reviews in Control_, 43:65-79, 2017.
* [69] Stephen Ranshous, Shitian Shen, Danai Koutra, Steve Harenberg, Christos Faloutsos, and Nagiza F Samatova. Anomaly detection in dynamic networks: a survey. _Wiley Interdisciplinary Reviews: Computational Statistics_, 7(3):223-247, 2015.
* [70] John F Roddick and Myra Spiliopoulou. A bibliography of temporal, spatial and spatio-temporal data mining research. _ACM SIGKDD Explorations Newsletter_, 1(1):34-38, 1999.
* [71] Mateo Rojas-Carulla, Bernhard Scholkopf, Richard Turner, and Jonas Peters. Invariant models for causal transfer learning. _The Journal of Machine Learning Research_, 19(1):1309-1342, 2018.
* [72] Elan Rosenfeld, Pradeep Kumar Ravikumar, and Andrej Risteski. The risks of invariant risk minimization. In _9th International Conference on Learning Representations_. OpenReview.net, 2021.
* [73] Emanuele Rossi, Ben Chamberlain, Fabrizio Frasca, Davide Eynard, Federico Monti, and Michael Bronstein. Temporal graph networks for deep learning on dynamic graphs. _arXiv preprint arXiv:2006.10637_, 2020.
* [74] Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization. _arXiv preprint arXiv:1911.08731_, 2019.
* [75] Aravind Sankar, Yanhong Wu, Liang Gou, Wei Zhang, and Hao Yang. Dysat: Deep neural representation learning on dynamic graphs via self-attention networks. In _Proceedings of the 13th International Conference on Web Search and Aata Mining_, pages 519-527, 2020.
* [76] Youngjoo Seo, Michael Defferrard, Pierre Vandergheynst, and Xavier Bresson. Structured sequence modeling with graph convolutional recurrent networks. In _Neural Information Processing: 25th International Conference, ICONIP 2018, Siem Reap, Cambodia, December 13-16, 2018, Proceedings, Part I 25_, pages 362-373. Springer, 2018.
* [77] Zheyan Shen, Jiashuo Liu, Yue He, Xingxuan Zhang, Renzhe Xu, Han Yu, and Peng Cui. Towards out-of-distribution generalization: A survey. _arXiv preprint arXiv:2108.13624_, 2021.
* [78] Qingyun Sun, Jianxin Li, Hao Peng, Jia Wu, Xingcheng Fu, Cheng Ji, and Philip S. Yu. Graph structure learning with variational information bottleneck. In _Thirty-Sixth AAAI Conference on Artificial Intelligence_, pages 4165-4174. AAAI Press, 2022.
* [79] Qingyun Sun, Jianxin Li, Hao Peng, Jia Wu, Yuanxing Ning, Philip S Yu, and Lifang He. SUGAR: Subgraph neural network with reinforcement pooling and self-supervised mutual information mechanism. In _Proceedings of the ACM Web Conference_, pages 2081-2091, 2021.

* [80] Qingyun Sun, Jianxin Li, Haonan Yuan, Xingcheng Fu, Hao Peng, Cheng Ji, Qian Li, and Philip S Yu. Position-aware structure learning for graph topology-imbalance by relieving under-reaching and over-squashing. In _Proceedings of the 31st ACM International Conference on Information and Knowledge Management_, pages 1848-1857, 2022.
* [81] Jie Tang, Sen Wu, Jimeng Sun, and Hang Su. Cross-domain collaboration recommendation. In _Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining_, pages 1285-1293, 2012.
* [82] Vladimir N Vapnik. An overview of statistical learning theory. _IEEE transactions on neural networks_, 10(5):988-999, 1999.
* [83] Xin Wang, Hong Chen, Yuwei Zhou, Jianxin Ma, and Wenwu Zhu. Disentangled representation learning for recommendation. _IEEE Trans. Pattern Anal. Mach. Intell._, 45(1):408-424, 2023.
* [84] Yanbang Wang, Yen-Yu Chang, Yunyu Liu, Jure Leskovec, and Pan Li. Inductive representation learning in temporal networks via causal anonymous walks. In _9th International Conference on Learning Representations_. OpenReview.net, 2021.
* [85] Yanbang Wang, Pan Li, Chongyang Bai, and Jure Leskovec. Tedic: Neural modeling of behavioral patterns in dynamic social interaction networks. In _Proceedings of the ACM Web Conference_, pages 693-705, 2021.
* [86] Qitian Wu, Hengrui Zhang, Junchi Yan, and David Wipf. Handling distribution shifts on graphs: An invariance perspective. In _The Tenth International Conference on Learning Representations_. OpenReview.net, 2022.
* [87] Yingxin Wu, Xiang Wang, An Zhang, Xiangnan He, and Tat-Seng Chua. Discovering invariant rationales for graph neural networks. In _The Tenth International Conference on Learning Representations_. OpenReview.net, 2022.
* [88] Menglin Yang, Min Zhou, Marcus Kalander, Zengfeng Huang, and Irwin King. Discrete-time temporal network embedding via implicit hierarchical learning in hyperbolic space. In _The 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining_, pages 1975-1985. ACM, 2021.
* [89] Yiding Yang, Zunlei Feng, Mingli Song, and Xinchao Wang. Factorizable graph convolutional networks. _Advances in Neural Information Processing Systems_, 33:20286-20296, 2020.
* [90] Jiaxuan You, Yichen Wang, Aditya Pal, Pong Eksombatchai, Chuck Rosenberg, and Jure Leskovec. Hierarchical temporal convolutional networks for dynamic recommender systems. In _Proceedings of the ACM Web Conference_, pages 2236-2246. ACM, 2019.
* [91] Junchi Yu, Jian Liang, and Ran He. Mind the label shift of augmentation-based graph OOD generalization. In _IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pages 11620-11630. IEEE, 2023.
* [92] Lingxiao Yuan, Harold S Park, and Emma Lejeune. Towards out of distribution generalization for problems in mechanics. _Computer Methods in Applied Mechanics and Engineering_, 400:115569, 2022.
* [93] Shilei Zhang, Toyotaro Suzumura, and Li Zhang. Dynagphtrans: Dynamic graph embedding via modified universal transformer networks for financial transaction data. In _2021 IEEE International Conference on Smart Data Services_, pages 184-191. IEEE, 2021.
* [94] Zeyang Zhang, Xin Wang, Ziwei Zhang, Haoyang Li, Zhou Qin, and Wenwu Zhu. Dynamic graph neural networks under spatio-temporal distribution shift. In _Advances in Neural Information Processing Systems_, 2022.
* [95] Han Zhao, Remi Tachet des Combes, Kun Zhang, and Geoffrey J. Gordon. On learning invariant representations for domain adaptation. In _Proceedings of the 36th International Conference on Machine Learning_, volume 97 of _Proceedings of Machine Learning Research_, pages 7523-7532. PMLR, 2019.
* [96] Zhengyang Zhou, Yang Wang, Xike Xie, Lianliang Chen, and Hengchang Liu. RiskOracle: A minute-level citywide traffic accident forecasting framework. In _The Thirty-Fourth AAAI Conference on Artificial Intelligence_, pages 1258-1265. AAAI Press, 2020.
* [97] Zhengyang Zhou, Yang Wang, Xike Xie, Lianliang Chen, and Chaochao Zhu. Foresee urban sparse traffic accidents: A spatiotemporal multi-granularity perspective. _IEEE Transactions on Knowledge and Data Engineering_, 34(8):3786-3799, 2020.
* [98] Qi Zhu, Natalia Ponomareva, Jiawei Han, and Bryan Perozzi. Shift-robust GNNs: Overcoming the limitations of localized graph training data. _Advances in Neural Information Processing Systems_, 34:27965-27977, 2021.

[MISSING_PAGE_EMPTY:16]

**Computational Complexity Analysis.** We analyze the computational complexity of each part in Eagle as follows. Denote \(|\mathcal{V}|\) and \(|\mathcal{E}|\) as the total number of nodes and edges in each graph snapshot.

In Section 3.1, operations of the EAConv layer in EA-DGNN can be parallelized across all nodes, which is highly efficient. Thus, the computation complexity of EA-DGNN is:

\[\mathcal{O}\left(|\mathcal{E}|\sum_{l=0}^{L}d^{(l)}+\mathcal{V}\left(\sum_{l=1 }^{L}d^{(l-1)}d^{(l)}+(d^{(L)})^{2}\right)\right),\] (B.1)

where \(d^{(l)}\) denotes the dimension of the \(l\)-th layer. As \(L\) is a small number, and \(d^{(l)}\) is a constant, the Eq. (B.1) can be rewritten as \(\mathcal{O}(|\mathcal{E}|d+|\mathcal{V}|d^{2})\), where \(d\) is the universal notation of all \(d^{(l)}\).

In Section 3.2, the computation complexity of the ECVAE is a compound of the encoder and decoder, with the same computation complexity as \(\mathcal{O}(|\mathbf{z}|L^{\prime}d)\), where \(|\mathbf{z}|\) is the number of the observed environment samples, \(L^{\prime}\) is the number of layers in the encoder and decoder. Also, as \(L^{\prime}\) is a small number, we omit it for brevity. Thus, the computation complexity of ECVAE is \(\mathcal{O}(|\mathbf{z}|d)\).

In Section 3.3, we recognize the invariant/variant patterns for all nodes by the function \(\mathbb{I}(\cdot)\) in parallel, with the computation complexity \(\mathcal{O}(K\log|\mathcal{V}|)\).

In Section 3.4, we perform sampling and replacing as an implementation of causal interventions. Denote \(|\mathcal{E}|_{p}\) as the number of edges to predict and \(|\mathcal{S}|\) as the size of the intervention set, which is usually set as a small constant. The spatio-temporal causal intervention mechanism owns a computation complexity compounding of sampling and replacing as \(\mathcal{O}(|\mathcal{S}|d)+\mathcal{O}(|\mathcal{E}_{p}||\mathcal{S}|d)\) in training, and no extra computation complexity in the inference stage.

Therefore, the overall computation complexity of Eagle is:

\[\mathcal{O}(|\mathcal{E}|d+|\mathcal{V}|d^{2})+\mathcal{O}(|\mathbf{z}|d)+ \mathcal{O}(K\log|\mathcal{V}|)+\mathcal{O}(|\mathcal{S}|d)+\mathcal{O}(| \mathcal{E}_{p}||\mathcal{S}|d).\] (B.2)

In summary, Eagle has a linear computation complexity with respect to the number of nodes and edges, which is on par with DIDA [94] and other existing dynamic GNNs. We believe that the computational complexity bottleneck of Eagle lies in the spatio-temporal causal intervention mechanism. We further analyze the intervention efficiency in Appendix D.5.

**Space Complexity Analysis.** We analyze the space complexity of each part in Eagle as follows. Denote \(|\mathcal{V}|\) and \(|\mathcal{E}|\) as the number of nodes and edges, respectively, \(K\) as the number of environments, \(T\) as the number of time slices, \(L\) as the number of layers in EA-DGNN, \(L^{\prime}\) as the number of layers in ECVAE, \(d\) as the dimension of input node features, \(d^{\prime}=Kd\) as the hidden dimension of EAConv layers in EA-DGNN, \(d^{\prime\prime}\) as the hidden dimension of the encoder and decoder networks layer of ECVAE, \(\sum_{v\in\mathcal{V}}\mathrm{Var}(\mathbf{z}_{v}^{\prime\prime})\) as the variance of \(K\) environment-aware representations.

Here we provide a rough analysis of Eagle's space complexity. Note that, as the space complexity analysis of deep learning models is complicated, we omit some less important terms, such as intermediate activations, _etc._

* storing the dynamic graph: \(\mathcal{O}(KT(|\mathcal{V}|+|\mathcal{E}|))\).
* storing the node input features: \(\mathcal{O}(|\mathcal{V}|KTd)\).
* the EAConv layer: \(\mathcal{O}(Ld^{\prime 2})\).
* the encoder and decoder networks of ECVAE: \(\mathcal{O}(L^{\prime}d^{\prime\prime})\).
* storing generated environment samples (the number set to be the same with the observed ones): \(\mathcal{O}(|\mathcal{V}|KTd^{\prime\prime})\).
* storing the states for function \(\mathbb{I}(\cdot,\cdot)\): \(\mathcal{O}(K\sum_{v\in\mathcal{V}}\mathrm{Var}(\mathbf{z}_{v}^{\mathbf{e} \prime}))\).

Then the overall space complexity of Eagle can be roughly calculated as:

\[\mathcal{O}(KT(|\mathcal{V}|+|\mathcal{E}|))+\mathcal{O}(|\mathcal{V}|KTd)+ \mathcal{O}(Ld^{\prime 2})+\mathcal{O}(L^{\prime}d^{\prime\prime})+\mathcal{O}(| \mathcal{V}|KTd^{\prime\prime})+\mathcal{O}(K\sum_{v\in\mathcal{V}}\mathrm{ Var}(\mathbf{z}_{v}^{\mathbf{e}\prime})).\] (B.3)

However, it is hard to intuitively draw conclusions about memory requirements from the space complexity analysis. Based on our experiments experience, Eagle can be trained and tested under the hardware configurations (including memory requirements) listed in Appendix E.3, which is on par with the related works' requirements.

Proofs

### Proof of Proposition 1

**Proposition 1**.: Given observed environment samples from the dynamic graph \(\mathcal{G}^{1:T}\) denoted as

\[\mathbf{z}=\bigcup_{v\in\mathcal{V}}\bigcup_{k=1}^{K}\bigcup_{t=1}^{T}\{ \mathbf{z}_{v,k}^{t}\}\in\mathbb{R}^{(|\mathcal{V}|\times K\times T)\times d^{ \prime}}\xlongeqed{\mathrm{def}}\ \mathcal{S}_{\mathrm{ob}}\] (C.1)

with their corresponding one-hot multi-labels \(\mathbf{y}\), the environment variable \(\mathbf{e}\) is drawn from the prior distribution \(p_{\omega}(\mathbf{e}\mid\mathbf{y})\) across \(T\) time slices, and \(\mathbf{z}\) is generated from the distribution \(p_{\omega}(\mathbf{z}\mid\mathbf{y},\mathbf{e})\). Maximizing the conditional log-likelihood \(\log p_{\omega}(\mathbf{z}\mid\mathbf{y})\) leads to an optimal ECVAE by minimizing:

\[\mathcal{L}_{\mathrm{ECVAE}}=\mathrm{KL}[q_{\phi}(\mathbf{e}\mid\mathbf{z}, \mathbf{y})\|p_{\omega}(\mathbf{e}\mid\mathbf{y})]-\frac{1}{|\mathbf{z}|}\sum _{i=1}^{|\mathbf{z}|}\log p_{\omega}(\mathbf{z}\mid\mathbf{y},\mathbf{e}^{(i) }),\] (C.2)

where \(\mathrm{KL}[\cdot\|\cdot]\) is the Kullback-Leibler (KL) divergence [37], \(|\mathbf{z}|\) is the number of observed environment samples, \(\mathbf{e}^{(i)}\) is the \(i\)-th sampling by the reparameterization trick.

Proof.: The distribution distance between \(q_{\phi}(\mathbf{e}\mid\mathbf{z},\mathbf{y})\) and \(p_{\omega}(\mathbf{e}\mid\mathbf{z},\mathbf{y})\) can be calculated by the KL-divergence:

\[\mathrm{KL}[q_{\phi}(\mathbf{e}\mid\mathbf{z},\mathbf{y})\|p_{ \omega}(\mathbf{e}\mid\mathbf{z},\mathbf{y})] =\int q_{\phi}(\mathbf{e}\mid\mathbf{z},\mathbf{y})\log\frac{q_{ \phi}(\mathbf{e}\mid\mathbf{z},\mathbf{y})}{p_{\omega}(\mathbf{e}\mid\mathbf{ z},\mathbf{y})}\,\mathrm{d}\phi\] \[=\int q_{\phi}(\mathbf{e}\mid\mathbf{z},\mathbf{y})\log\frac{q_{ \phi}(\mathbf{e}\mid\mathbf{z},\mathbf{y})p_{\omega}(\mathbf{z}\mid\mathbf{y}) p_{\omega}(\mathbf{y})}{p_{\omega}(\mathbf{e},\mathbf{z},\mathbf{y})}\, \mathrm{d}\phi\] \[=\int q_{\phi}(\mathbf{e}\mid\mathbf{z},\mathbf{y})\log q_{\phi} (\mathbf{e}\mid\mathbf{z},\mathbf{y})\,\mathrm{d}\phi+\underbrace{\int q_{ \phi}(\mathbf{e}\mid\mathbf{z},\mathbf{y})\log p_{\omega}(\mathbf{z}\mid \mathbf{y})\,\mathrm{d}\phi}_{\log p_{\omega}(\mathbf{z}\mid\mathbf{y})}\, \mathrm{d}\phi\] \[\quad+\int q_{\phi}(\mathbf{e}\mid\mathbf{z},\mathbf{y})\log p_{ \omega}(\mathbf{y})\,\mathrm{d}\phi-\int q_{\phi}(\mathbf{e}\mid\mathbf{z}, \mathbf{y})\log p_{\omega}(\mathbf{e},\mathbf{z},\mathbf{y})\,\mathrm{d}\phi\] \[=\log p_{\omega}(\mathbf{z}\mid\mathbf{y})+\int q_{\phi}( \mathbf{e}\mid\mathbf{z},\mathbf{y})\log\frac{q_{\phi}(\mathbf{e}\mid\mathbf{ z},\mathbf{y})}{p_{\omega}(\mathbf{z}\mid\mathbf{y},\mathbf{e})p_{\omega}( \mathbf{e}\mid\mathbf{y})}\,\mathrm{d}\phi\] \[=\log p_{\omega}(\mathbf{z}\mid\mathbf{y})+\mathbb{E}_{q_{\phi}( \mathbf{e}\mid\mathbf{z},\mathbf{y})}[\log q_{\phi}(\mathbf{e}\mid\mathbf{z}, \mathbf{y})-\log p_{\omega}(\mathbf{e},\mathbf{z}\mid\mathbf{y})]\] \[=\log p_{\omega}(\mathbf{z}\mid\mathbf{y})-\mathbb{E}_{q_{\phi}( \mathbf{e}\mid\mathbf{z},\mathbf{y})}[-\log q_{\phi}(\mathbf{e}\mid\mathbf{z },\mathbf{y})+\log p_{\omega}(\mathbf{e},\mathbf{z}\mid\mathbf{y})].\] (C.3)

Thus the conditional log-likelihood \(\log p_{\omega}(\mathbf{z}\mid\mathbf{y})\) can be rewritten as:

\[\log p_{\omega}(\mathbf{z}\mid\mathbf{y})=\mathrm{KL}[q_{\phi}(\mathbf{e} \mid\mathbf{z},\mathbf{y})\|p_{\omega}(\mathbf{e}\mid\mathbf{z},\mathbf{y})] +\mathbb{E}_{q_{\phi}(\mathbf{e}\mid\mathbf{z},\mathbf{y})}[-\log q_{\phi}( \mathbf{e}\mid\mathbf{z},\mathbf{y})+\log p_{\omega}(\mathbf{e},\mathbf{z}\mid \mathbf{y})].\] (C.4)

Since this KL-divergence is non-negative, we then provide an Evidence Lower Bound (ELBO) for \(\log p_{\omega}(\mathbf{y}\mid\mathbf{z})\):

\[\log p_{\omega}(\mathbf{z}\mid\mathbf{y}) \geq\mathbb{E}_{q_{\phi}(\mathbf{e}\mid\mathbf{z},\mathbf{y})}[- \log q_{\phi}(\mathbf{e}\mid\mathbf{z},\mathbf{y})+\log p_{\omega}(\mathbf{e},\mathbf{z}\mid\mathbf{y})]\] \[=\mathbb{E}_{q_{\phi}(\mathbf{e}\mid\mathbf{z},\mathbf{y})}[- \log q_{\phi}(\mathbf{e}\mid\mathbf{z},\mathbf{y})+\log p_{\omega}(\mathbf{e} \mid\mathbf{y})]+\mathbb{E}_{q_{\phi}(\mathbf{e}\mid\mathbf{z},\mathbf{y})}[ \log p_{\omega}(\mathbf{z}\mid\mathbf{y},\mathbf{e})]\] (C.5) \[=-\mathrm{KL}[q_{\phi}(\mathbf{e}\mid\mathbf{z},\mathbf{y})\|p_{ \omega}(\mathbf{e}\mid\mathbf{y})]+\mathbb{E}_{q_{\phi}(\mathbf{e}\mid \mathbf{z},\mathbf{y})}[\log p_{\omega}(\mathbf{z}\mid\mathbf{y},\mathbf{e})].\]

We can maximize \(\log p_{\omega}(\mathbf{z}\mid\mathbf{y})\) by maximizing the ELBO, or minimizing:

\[\mathcal{L}_{\mathrm{ECVAE}}=-\mathrm{ELBO}=\mathrm{KL}[q_{\phi}(\mathbf{e} \mid\mathbf{z},\mathbf{y})\|p_{\omega}(\mathbf{e}\mid\mathbf{y})]-\mathbb{E}_{q_{ \phi}(\mathbf{e}\mid\mathbf{z},\mathbf{y})}[\log p_{\omega}(\mathbf{z}\mid \mathbf{y},\mathbf{e})].\] (C.6)

While the second term in \(\mathcal{L}_{\mathrm{ECVAE}}\) is the maximum likelihood estimation, which is infeasible to calculate directly under the expectation of the latent environment variable \(\mathbf{e}\sim p_{\phi}(\mathbf{e}\mid\mathbf{z},\mathbf{y})\) across \(T\) time slices. Inspired by Markov Chain Monte Carlo (MCMC) sampling [23], it can be estimated as:

\[\mathcal{L}_{\mathrm{ECVAE}}=\mathrm{KL}[q_{\phi}(\mathbf{e}\mid\mathbf{z}, \mathbf{y})\|p_{\omega}(\mathbf{e}\mid\mathbf{y})]-\frac{1}{|\mathbf{z}|}\sum_{i=1 }^{|\mathbf{z}|}\log p_{\omega}(\mathbf{z}\mid\mathbf{y},\mathbf{e}^{(i)}).\] (C.7)In implementations, we assume \(q_{\phi}(\mathbf{e}\mid\mathbf{z},\mathbf{y})\) and \(p_{\omega}(\mathbf{e}\mid\mathbf{y})\) follow the multivariate normal distribution \(\mathcal{N}(\bm{\mu};\bm{\sigma})\) parameterized by \(\bm{\mu}\) and \(\bm{\sigma}\), so that the KL-divergence can be easily calculated. In order to optimize the ECVAE by back-propagation, we utilize a reparameterization trick: \(\mathbf{e}^{(i)}=e_{\omega}(\mathbf{z},\mathbf{y},\epsilon^{(i)})\), where \(\epsilon^{(i)}\sim\mathcal{N}(\mathbf{0};\mathbf{I})\). Here \(e_{\omega}(\cdot,\cdot,\cdot)\) is some vector-valued functions parameterized by \(\phi\). 

### Proof of Proposition 2

**Proposition 2** (A Solution for \(\mathbb{I}^{\star}(\cdot)\)).: Denote \(\mathbf{z}_{v}^{\bm{\sigma}}=[\mathbf{z}_{v,1}^{\prime},\mathbf{z}_{v,2}^{ \prime},\cdots,\mathbf{z}_{v,K}^{\prime}]\), where \(\mathbf{z}_{v,k}^{\prime}=\bigcup_{t=1}^{T}\mathbf{z}_{v,k}^{\prime}\). Let \(\mathrm{Var}(\mathbf{z}_{v}^{\bm{\sigma}})\in\mathbb{R}^{K}\) represents the variance of \(K\) environment-aware representations. The Boolean function \(\mathbb{I}(\cdot)\) is a solution for \(\mathbb{I}^{\star}(\cdot)\) with the following state update equation:

\[\mathbb{I}(i,j)=\begin{cases}\mathbb{I}(i-1,j)\vee\mathbb{I}(i-1,j-\mathrm{ Var}(\mathbf{z}_{v}^{\bm{\sigma}\prime})[i-1]),&j\geq\mathrm{Var}(\mathbf{z}_{v}^{ \bm{\sigma}\prime})[i-1]\\ \mathbb{I}(i-1,j),&\text{otherwise}\end{cases},\] (C.8)

\(\mathbb{I}(i,j)\) indicates whether it is feasible to select from the first \(i\) elements in \(\mathrm{Var}(\mathbf{z}_{v}^{\bm{\sigma}\prime})\) so that their sum is \(j\). Traversing \(j\) in reverse order from \(\lfloor\sum\mathrm{Var}(\mathbf{z}_{v}^{\bm{\sigma}\prime})/2\rfloor\) until satisfying \(\mathbb{I}(K,j)\) is True, we reach:

\[\delta_{v}=\sum\mathrm{Var}(\mathbf{z}_{v}^{\bm{\sigma}\prime})-2j,\] (C.9)

\[\mathcal{P}_{\mathbf{e}}^{I}(v)=\left\{\mathbf{e}_{k}\mid\mathrm{Var}(\mathbf{ z}_{v}^{\bm{\sigma}\prime})[k]\leq\frac{1}{K}\sum\mathrm{Var}(\mathbf{z}_{v}^{ \bm{\sigma}\prime})-\frac{\delta_{v}}{2}\right\},\quad\mathcal{P}_{\mathbf{e} }^{V}(v)=\overline{\mathcal{P}_{\mathbf{e}}^{I}(v)},\] (C.10)

where \(\delta_{v}\) is the optimal spatio-temporal invariance threshold of node \(v\).

Proof.: In order to prove the boolean function \(\mathbb{I}(\cdot)\) is a solution for \(\mathbb{I}^{\star}(\cdot)\) in Assumption 1, the problem \(\mathbb{I}(\cdot)\) solves should satisfies: **(a) Optimal substructure; (b) Non-aftereffect property; (c) Overlapping sub-problems**.

Next, we prove the above three conditions are valid.

**(a) Optimal substructure.** It is said that the problem has the optimal substructure property when the optimal solution of the problem covers the optimal solutions of its subproblems. Now we prove the optimal solution of determining the spatio-temporal invariant patterns \(\mathcal{P}_{\mathbf{e}}^{I}(v)\) for node \(v\) is constructed from the optimal solutions of the sub-problems with the bottom-up approach by using the optimal substructure property of the problem.

As \(\mathbb{I}(i,j)\) indicates whether it is feasible to select some elements from the first \(i\) elements in \(\mathrm{Var}(\mathbf{z}_{v}^{\bm{\sigma}\prime})\) so that their sum is \(j\), \(\sum\mathrm{Var}(\mathbf{z}_{v}^{\bm{\sigma}\prime})\) means the sum of elements in \(\mathrm{Var}(\mathbf{z}_{v}^{\bm{\sigma}\prime})\), the target of the problem is to find \(\delta_{v}\) that denotes the optimal threshold for invariance of node \(v\). We reduce this problem by dividing \(\mathrm{Var}(\mathbf{z}_{v}^{\bm{\sigma}\prime})\) into two subsets \(\mathrm{Var}(\mathbf{z}_{v}^{\bm{\sigma}\prime})_{I}\) and \(\mathrm{Var}(\mathbf{z}_{v}^{\bm{\sigma}\prime})_{V}\), where \(\delta_{v}\) represents the value when the difference between the sum of two subsets is the smallest, _i.e._,

\[\delta_{v}=\min\left(\sum\mathrm{Var}(\mathbf{z}_{v}^{\bm{\sigma}\prime})-2j \right),\quad\text{where}\quad\mathbb{I}(K,j)==\mathrm{True}.\] (C.11)

Let \(\mathbb{I}_{I}(i,j)\) and \(\mathbb{I}_{V}(i,j)\) represent whether it is feasible to select some elements from the first \(i\) elements in \(\mathrm{Var}(\mathbf{z}_{v}^{\bm{\sigma}\prime})_{I}\) and \(\mathrm{Var}(\mathbf{z}_{v}^{\bm{\sigma}\prime})_{V}\) respectively, so that their sum is \(j\). Suppose the sum of \(\mathrm{Var}(\mathbf{z}_{v}^{\bm{\sigma}\prime})_{I}\) and \(\mathrm{Var}(\mathbf{z}_{v}^{\bm{\sigma}\prime})_{V}\) are \(\sum(\mathrm{Var}(\mathbf{z}_{v}^{\bm{\sigma}\prime})_{I})\) and \(\sum(\mathrm{Var}(\mathbf{z}_{v}^{\bm{\sigma}\prime})_{V})\), we have:

\[\sum(\mathrm{Var}(\mathbf{z}_{v}^{\bm{\sigma}\prime})_{I})+\sum(\mathrm{Var}( \mathbf{z}_{v}^{\bm{\sigma}\prime})_{V})=\sum\mathrm{Var}(\mathbf{z}_{v}^{\bm{ \sigma}\prime}).\] (C.12)

Then, the target of the original problem is transformed into finding an optimal solution for \(i\) and \(j\), satisfying:

\[\mathbb{I}_{I}(i,j)==\mathrm{True},\] (C.13) \[\text{\it s.t. }\min\left(\sum(\mathrm{Var}(\mathbf{z}_{v}^{\bm{ \sigma}\prime})_{I})-j-\left(\sum(\mathrm{Var}(\mathbf{z}_{v}^{\bm{\sigma}\prime}) _{V})-\left(\sum(\mathrm{Var}(\mathbf{z}_{v}^{\bm{\sigma}\prime})_{I})-j\right) \right)\right).\] (C.14)

According to the definition of \(\mathbb{I}(i,j)\), we can draw a conclusion the \(\mathbb{I}_{I}(i,j)\) and \(\mathbb{I}_{V}(i,j)\) both are the subproblems of the original problem, which similarly target at figuring out whether it is feasible to select some elements from the first \(i\) elements that satisfy their sum is \(j\). So, function \(\mathbb{I}_{I}(i,j)\) and \(\mathbb{I}_{V}(i,j)\) is the same with \(\mathbb{I}(i,j)\) in Eq. (C.8). Assuming that when the difference in the subsets is maximized, \(\mathbb{I}_{I}(i,j)\) and \(\mathbb{I}_{V}(i,j)\) return \(j_{I}\) and \(j_{V}\), respectively, that satisfy:

\[\begin{cases}\mathbb{I}_{I}(i,j_{I})==\mathrm{True},\\ \mathbb{I}_{V}(K-i,j_{V})==\mathrm{True}.\end{cases}\] (C.15)

We have:

\[\begin{cases}\sum(\mathrm{Var}(\mathbf{z}_{v}^{\mathbf{e}\prime})_{I})-j_{I}= \delta_{I},&\mathbb{I}_{I}(i,j_{I})==\mathrm{True},\\ \sum(\mathrm{Var}(\mathbf{z}_{v}^{\mathbf{e}\prime})_{V})-j_{V}=\delta_{V},& \mathbb{I}_{V}(K-i,\sum(\mathrm{Var}(\mathbf{z}_{v}^{\mathbf{e}\prime})_{I}) -j_{I})==\mathrm{True}.\end{cases}\] (C.16)

As \(\mathbb{I}_{I}(i,j_{I})\) and \(\mathbb{I}_{V}(K-i,\sum(\mathrm{Var}(\mathbf{z}_{v}^{\mathbf{e}\prime})_{I}) -j_{I})\) are both the optimal solutions, so we reach:

\[|\delta_{I}-\delta_{V}|=\left|\sum(\mathrm{Var}(\mathbf{z}_{v}^{\mathbf{e} \prime})_{I})-j_{I}-\left(\sum(\mathrm{Var}(\mathbf{z}_{v}^{\mathbf{e}\prime} )_{V})-j_{V}\right)\right|\leq\delta_{v}.\] (C.17)

The optimal substructure property is proven.

**(b) Non-aftereffect property.** This property implies that once the state of a certain stage is determined by \(\mathbb{I}(\cdot)\), it is not affected by future decision-making. In other words, the subsequent process will not affect the previous state, but only be related to the current state. Eq. (C.8) implies that, when \(j\geq\mathrm{Var}(\mathbf{z}_{v}^{\mathbf{e}\prime})[i-1]\), the state is decided by previous state \(\mathbb{I}(i-1,j)\) or \(\mathbb{I}(i-1,j-\mathrm{Var}(\mathbf{z}_{v}^{\mathbf{e}\prime})[i-1])\); accordingly, when \(j<\mathrm{Var}(\mathbf{z}_{v}^{\mathbf{e}\prime})[i-1]\), the state is solely decided by previous state \(\mathbb{I}(i-1,j)\). All state transition processes are based on historical states and executed in a one-way transition mode, meeting the requirements of the non-aftereffect property. Generally speaking, the non-aftereffect property is a relaxation condition, that is, as long as the properties of the optimal substructure property are satisfied, the non-aftereffect property will be basically satisfied.

**(c) Overlapping sub-problems.**\(\mathbb{I}(\cdot)\) solve the problem from top to bottom in a recursive way, each sub-problem is not always a new problem, but a large number of repeated sub-problems, that is, when different decision sequences reach a certain stage, they will generate duplicate problems. When figuring out \(\mathbb{I}(\cdot)\), we consider two situations:

* Not select the \(i\)-th element in \(\mathrm{Var}(\mathbf{z}_{v}^{\mathbf{e}\prime})\), _i.e._, \(\mathbb{I}(i,j)=\mathbb{I}(i-1,j)\);
* Select the \(i\)-th element in \(\mathrm{Var}(\mathbf{z}_{v}^{\mathbf{e}\prime})\), _i.e._, \(\mathbb{I}(i,j)=\mathbb{I}(i-1,j-\mathrm{Var}(\mathbf{z}_{v}^{\mathbf{e}\prime} )[i-1])\).

As we can observe, we need the solution of the sub-problem \(\mathbb{I}(i-1,j)\) and \(\mathbb{I}(i-1,j-\mathrm{Var}(\mathbf{z}_{v}^{\mathbf{e}\prime})[i-1])\) when figuring out \(\mathbb{I}(i,j)\), which are already calculated by \(\mathbb{I}(i-1,\cdot)\). So we can prove that the problem \(\mathbb{I}(\cdot)\) solved has overlapping sub-problems.

We then have proven the function \(\mathbb{I}(\cdot)\) is a solution for the function \(\mathbb{I}^{\star}(\cdot)\) in Assumption 1, from which we can obtain the optimal spatio-temporal invariance threshold \(\delta_{v}\) of node \(v\). Then the spatio-temporal invariant/variant patterns for node \(v\) can be exploited by Eq. (C.10), and their unions constitute the overall \(\mathcal{P}_{\mathbf{e}}^{I}\) and \(\mathcal{P}_{\mathbf{e}}^{V}\). We conclude the proof for Proposition 2. 

### Proof of Proposition 3

**Proposition 3** (Achievable Assumption).: Minimizing Eq. (12) can encourage the model to satisfy the Invariance Property and Sufficient Condition in Assumption 1.

Proof.: We first propose the following lemma to rewrite the Sufficient Condition and the Invariance Property in Assumption 1 using the information theory [43].

**Lemma 1** (Mutual Information Equivalence).: The Invariance Property and Sufficient Condition in Assumption 1 can be equivalently represented with the Mutual Information \(I(\cdot;\cdot)\):

**(a) Invariance Property:**: \(p(\mathbf{Y}^{T}\mid\mathcal{P}_{\mathbf{e}}^{I},\mathbf{e})=p(\mathbf{Y}^{T} \mid\mathcal{P}_{\mathbf{e}}^{I})\Leftrightarrow I(\mathbf{Y}^{T};\mathbf{e} \mid\mathcal{P}_{\mathbf{e}}^{I})=0\);
**(b) Sufficient Condition:**: \(\mathbf{Y}^{T}\perp\!\!\!\perp\mathcal{P}_{\mathbf{e}}^{V}\mid\mathcal{P}_{ \mathbf{e}}^{I}\Leftrightarrow I(\mathbf{Y}^{T};\mathcal{P}_{\mathbf{e}}^{I})\) is maximized.

Proof.: We prove Lemma 1 by respectively proving the above two conditions are valid.

**(a) Invariance Property.** According to the definition of the Mutual Information, we can easily get the following equation:

\[I(\mathbf{Y}^{T};\mathbf{e}\mid\mathcal{P}^{I}_{\mathbf{e}})=\mathrm{KL}\left[p( \mathbf{Y}^{T}\mid\mathbf{e},\mathcal{P}^{I}_{\mathbf{e}})\parallel p(\mathbf{Y }^{T}\mid\mathcal{P}^{I}_{\mathbf{e}})\right]=0,\] (C.18)

where \(\mathrm{KL}[\cdot\|\cdot]\) is the Kullback-Leibler (KL) divergence [37]. Thus we have proved the equivalence in Invariance Property.

**(b) Sufficient Condition.** We demonstrate sufficiency and necessity through the following two steps.

**First**, we prove that for \(\mathbf{Y}^{T}\), \(\mathcal{P}^{I}_{\mathbf{e}}\) and \(\epsilon\) satisfying \(\mathbf{Y}^{T}=g(\mathbf{Z}^{1:T}_{I})+\epsilon\) would also satisfy \(\mathcal{P}^{I}_{\mathbf{e}}=\operatorname*{arg\,max}_{\mathcal{P}^{I}_{ \mathbf{e}}}I(\mathbf{Y}^{T};\mathcal{P}^{I}_{\mathbf{e}})\). We perform proving by contradiction. Suppose \(\mathcal{P}^{I}_{\mathbf{e}}\neq\operatorname*{arg\,max}_{\mathcal{P}^{I}_{ \mathbf{e}}}I(\mathbf{Y}^{T};\mathcal{P}^{I}_{\mathbf{e}})\) and there exists \(\mathcal{P}^{I\prime}_{\mathbf{e}}=\operatorname*{arg\,max}_{\mathcal{P}^{I}_ {\mathbf{e}}}\) where \(\mathcal{P}^{I\prime}_{\mathbf{e}}\neq\mathcal{P}^{I}_{\mathbf{e}}\). We can always find a mapping function \(\mathcal{M}\) so that \(\mathcal{P}^{I\prime}_{\mathbf{e}}=\mathcal{M}(\mathcal{P}^{I}_{\mathbf{e}},\pi)\) where \(\pi\) is a random variable. Then we reach:

\[I(\mathbf{Y}^{T};\mathcal{P}^{I\prime}_{\mathbf{e}})=I(\mathbf{Y}^{T}; \mathcal{P}^{I}_{\mathbf{e}},\pi)=I(g(\mathbf{Z}^{1:T}_{I});\mathcal{P}^{I}_ {\mathbf{e}},\pi)=I(g(\mathbf{Z}^{1:T}_{I});\mathcal{P}^{I}_{\mathbf{e}})=I( \mathbf{Y}^{T};\mathcal{P}^{I}_{\mathbf{e}}),\] (C.19)

which leads to a contradiction.

**Next**, we prove that for \(\mathbf{Y}^{T}\), \(\mathcal{P}^{I}_{\mathbf{e}}\) and \(\epsilon\) satisfying \(\mathcal{P}^{I}_{\mathbf{e}}=\operatorname*{arg\,max}_{\mathcal{P}^{I}_{ \mathbf{e}}}I(\mathbf{Y}^{T};\mathcal{P}^{I}_{\mathbf{e}})\) would also satisfy \(\mathbf{Y}^{T}=g(\mathbf{Z}^{1:T}_{I})+\epsilon\). We also perform proving by contradiction. Suppose that \(\mathbf{Y}^{T}\neq g(\mathbf{Z}^{1:T}_{I})+\epsilon\) and \(\mathbf{Y}^{T}=g(\mathbf{Z}^{1:T}_{I})+\epsilon\) where \(\mathcal{P}^{I\prime}_{\mathbf{e}}\neq\mathcal{P}^{I}_{\mathbf{e}}\). We then have the following inequality:

\[I(g(\mathbf{Z}^{1:T}_{I});\mathcal{P}^{I}_{\mathbf{e}})\leq I(g(\mathbf{Z}^{1 :T}_{I});\mathcal{P}^{I\prime}_{\mathbf{e}}),\] (C.20)

from which we can obtain that \(\mathcal{P}^{I\prime}_{\mathbf{e}}=\operatorname*{arg\,max}_{\mathcal{P}^{I}_ {\mathbf{e}}}I(\mathbf{Y}^{T};\mathcal{P}^{I}_{\mathbf{e}})\), leading to a contradiction. 

Now, we prove Proposition 3 in the following two perspectives.

**First**, we prove that minimizing the expectation term (\(\mathcal{L}_{\mathrm{task}}\)) in Eq. (12) can enforce the model to satisfy the Sufficient Condition in Assumption 1 (note that we omit the subscript \(\mathcal{P}^{I}_{\mathbf{e}}\) in \(\mathbf{Z}^{1:T}_{I}\) for brevity in the rest of this subsection if there are no special declarations).

From the SCM model in Figure 1(b), we can analyze that \(\max_{q(\mathbf{Z}^{1:T}|\mathbf{G}^{1:T})}I(\mathbf{Y}^{T};\mathbf{Z}^{1:T})\) is equivalent to \(\min_{q(\mathbf{Z}^{1:T}|\mathbf{G}^{1:T})}I(\mathbf{Y}^{T};\mathbf{G}^{1:T} \mid\mathbf{Z}^{1:T})\), as we filter out the spurious correlations that contain in the dependencies between \(\mathbf{Y}^{T}\) and \(\mathbf{G}^{1:T}\). Treating \(q(\mathbf{Z}^{1:T}\mid\mathbf{G}^{1:T})\) as the variational distribution, we have the following upper bound:

\[I(\mathbf{Y}^{T};\mathbf{G}^{1:T}\mid\mathbf{Z}^{1:T}) =\mathrm{KL}\left[p(\mathbf{Y}^{T}\mid\mathbf{G}^{1:T},\mathbf{e })\parallel p(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T},\mathbf{e})\right]\] (C.21) \[=\mathrm{KL}\left[p(\mathbf{Y}^{T}\mid\mathbf{G}^{1:T},\mathbf{e })\parallel q(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T})\right]\] \[\quad-\mathrm{KL}\left[p(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T}, \mathbf{e})\parallel q(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T})\right]\] \[\leq\mathrm{KL}\left[p(\mathbf{Y}^{T}\mid\mathbf{G}^{1:T}, \mathbf{e})\parallel q(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T})\right]\] \[\leq\min_{q(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T})}\mathrm{KL} \left[p(\mathbf{Y}^{T}\mid\mathbf{G}^{1:T},\mathbf{e})\parallel q(\mathbf{Y}^{T }\mid\mathbf{Z}^{1:T})\right].\]

In addition, we have:

\[\mathrm{KL}\left[p(\mathbf{Y}^{T}\mid\mathbf{G}^{1:T},\mathbf{e}) \parallel q(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T})\right]\] (C.22) \[=\mathbb{E}_{\mathbf{e}}\mathbb{E}_{(\mathcal{G}^{1:T},Y)\sim p( \mathbf{G}^{1:T},\mathbf{Y}^{T}\mid\mathbf{e})}\mathbb{E}_{\mathbf{Z}^{1:T}\sim q (\mathbf{Z}^{1:T}|\mathbf{G}^{1:T}=\mathcal{G}^{1:T})}\left[\log\frac{p( \mathbf{Y}^{T}=Y^{T}\mid\mathbf{G}^{1:T}=\mathcal{G}^{1:T},\mathbf{e})}{q( \mathbf{Y}^{T}=Y^{T}\mid\mathbf{Z}^{1:T})}\right]\] \[\leq\mathbb{E}_{\mathbf{e}}\mathbb{E}_{(\mathcal{G}^{1:T},Y^{T})\sim p (\mathbf{G}^{1:T},\mathbf{Y}^{T}\mid\mathbf{e})}\left[\log\frac{(\mathbf{Y}^{T} =Y^{T}\mid\mathbf{G}^{1:T}=\mathcal{G}^{1:T},\mathbf{e})}{\mathbb{E}_{\mathbf{Z}^{1:T }\sim q(\mathbf{Z}^{1:T}|\mathbf{G}^{1:T}=\mathcal{G}^{1:T})}\left[q(\mathbf{Y} ^{T}=Y^{T}\mid\mathbf{Z}^{1:T})\right]}\right].\]

The inequality in Eq. (C.22) is derived from Jensen's Inequality [34] and [86], while the EA-DGNN \(w(\cdot)\) ensures \(q(\mathbf{Z}^{1:T}\mid\mathbf{G}^{1:T})\) is a Dirac delta distribution (\(\delta\)-distribution). Then we reach:

\[\min_{q(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T})}\mathrm{KL}\left[p( \mathbf{Y}^{T}\mid\mathbf{G}^{1:T},\mathbf{e})\parallel q(\mathbf{Y}^{T}\mid \mathbf{Z}^{1:T})\right]\] (C.23) \[\Leftrightarrow\min_{\boldsymbol{\theta}}\mathbb{E}_{\mathbf{e}\sim q _{\mathbf{e}}(\mathbf{e}),(\mathcal{G}^{1:T},Y^{T})\sim p(\mathbf{G}^{1:T}, \mathbf{Y}^{T}\mid\mathbf{e})}\left[\ell\left(g(\mathbf{Z}^{1:T}_{I}),Y^{T} \right)\rightWe thus have proven that, minimizing the expectation term (\(\mathcal{L}_{\mathrm{task}}\)) in Eq. (12) is to minimize the upper bound of \(I(\mathbf{Y}^{T};\mathbf{G}^{1:T}\mid\mathbf{Z}^{1:T})\) (maximize the lower bound of \(\max_{q(\mathbf{Z}^{1:T}\mid\mathbf{G}^{1:T})}I(\mathbf{Y}^{T};\mathbf{Z}^{1:T})\)), which leads to maximizing \(I(\mathbf{Y}^{T};\mathcal{P}^{I}_{\mathbf{e}})\). This helps enforce the model to satisfy the Sufficient Condition.

**Then**, we prove that minimizing the variance term (\(\mathcal{L}_{\mathrm{risk}}\)) in Eq. (12) can enforce the model to satisfy the Invariance Property in Assumption 1.

We have:

\[\begin{split} I(\mathbf{Y}^{T};\mathbf{e}\mid\mathbf{Z}^{1:T})& =\mathrm{KL}\left[p(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T},\mathbf{e}) \parallel p(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T})\right]\\ &=\mathrm{KL}\left[p(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T},\mathbf{ e})\parallel\mathbb{E}_{\mathbf{e}}\left[p(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T}, \mathbf{e})\right]\right]\\ &=\mathrm{KL}\left[q(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T}) \parallel\mathbb{E}_{\mathbf{e}}q(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T})\right] \\ &\quad-\mathrm{KL}\left[q(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T}) \parallel p(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T},\mathbf{e})\right]\\ &\quad-\mathrm{KL}\left[\mathbb{E}_{\mathbf{e}}\left[p(\mathbf{Y} ^{T}\mid\mathbf{Z}^{1:T},\mathbf{e})\right]\parallel\mathbb{E}_{\mathbf{e}} \left[q(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T})\right]\right]\\ &\leq\mathrm{KL}\left[q(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T}) \parallel\mathbb{E}_{\mathbf{e}}q(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T})\right]\\ &\leq\min_{q(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T})}\mathrm{KL} \left[q(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T})\parallel\mathbb{E}_{\mathbf{e}}q( \mathbf{Y}^{T}\mid\mathbf{Z}^{1:T})\right].\end{split}\] (C.24)

In addition, we have:

\[\begin{split}&\mathrm{KL}\left[q(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T}) \parallel\mathbb{E}_{\mathbf{e}}q(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T})\right] \\ &=\mathbb{E}_{\mathbf{e}}\mathbb{E}_{(\mathcal{G}^{1:T},Y^{T}) \sim p(\mathbf{G}^{1:T},\mathbf{Y}^{T}|\mathbf{e})}\mathbb{E}_{\mathbf{Z}^{1: T}\sim q(\mathbf{Z}^{1:T}|\mathbf{G}^{1:T}=\mathcal{G}^{1:T})}\left[\log\frac{q( \mathbf{Y}^{T}=Y^{T}\mid\mathbf{Z}^{1:T})}{\mathbb{E}_{\mathbf{e}}q(\mathbf{Y }^{T}=Y^{T}\mid\mathbf{Z}^{1:T})}\right].\end{split}\] (C.25)

Derived from Jensen's Inequality, the upper bound for \(\mathrm{KL}\left[q(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T})\parallel\mathbb{E}_{ \mathbf{e}}q(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T})\right]\) is:

\[\begin{split}&\mathrm{KL}\left[q(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T })\parallel\mathbb{E}_{\mathbf{e}}q(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T})\right] \\ &\leq\mathbb{E}_{\mathbf{e}}\left[\left|\ell\left(f_{\bm{\theta}} \left(\mathcal{G}^{1:T}\right),Y^{T}\right)-\mathbb{E}_{\mathbf{e}}\left[\ell \left(f_{\bm{\theta}}\left(\mathcal{G}^{1:T}\right),Y^{T}\right)\right]\right| \right].\end{split}\] (C.26)

Finally, we reach:

\[\begin{split}&\min_{q(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T})} \mathrm{KL}\left[q(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T})\parallel\mathbb{E}_{ \mathbf{e}}q(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T})\right]\\ &\Leftrightarrow\min_{\bm{\theta}}\mathrm{Var}_{s\in\mathcal{S}} \left\{\mathbb{E}_{\mathbf{e}\sim q_{\phi}(\mathbf{e}),(\mathcal{G}^{1:T},Y^{T })\sim p(\mathbf{G}^{1:T},\mathbf{Y}^{T}|\mathbf{e})}\left[\ell\left(f_{\bm{ \theta}}\left(\mathcal{G}^{1:T}\right),Y^{T}\mid\mathrm{do}(\mathbf{Z}^{1:T}_ {V}=s)\right)\right]\right\}.\end{split}\] (C.27)

We thus have proven that, minimizing the variance term (\(\mathcal{L}_{\mathrm{risk}}\)) in Eq. (12) is to minimize the upper bound of \(I(\mathbf{Y}^{T};\mathbf{e}\mid\mathbf{Z}^{1:T})\), which leads to minimizing \(I(\mathbf{Y}^{T};\mathbf{e}\mid\mathcal{P}^{I}_{\mathbf{e}})\). This helps enforce the model to satisfy the Invariance Property.

We conclude the proof for Proposition 3. 

### Proof of Proposition 4

**Proposition 4** (Equivalent Optimization).: Optimizing Eq. (12) is equivalent to minimizing the upper bound of the OOD generalization error in Eq. (2).

Proof.: As we defined in Eq. (2), the generation of dynamic graph data \((\mathcal{G}^{1:T},Y^{T})\) is drawn from the distribution \(p(\mathbf{G}^{1:T},\mathbf{Y}^{T}\mid\mathbf{e})\), while the difference of \(\mathbf{e}\) during training and testing causes the out-of-distribution shifts. Let \(q(\mathbf{Y}^{T}\mid\mathbf{G}^{1:T})\) be the inferred variational distribution of the ground-truth distribution \(p(\mathbf{Y}^{T}\mid\mathbf{G}^{1:T},\mathbf{e})\), then the OOD generalization error can be measured by the KL-divergence of the two distributions:

\[\begin{split}&\mathrm{KL}\left[p(\mathbf{Y}^{T}\mid\mathbf{G}^{1:T}, \mathbf{e})\parallel q(\mathbf{Y}^{T}\mid\mathbf{G}^{1:T})\right]\\ &=\mathbb{E}_{\mathbf{e}}\mathbb{E}_{(\mathcal{G}^{1:T},Y^{T}) \sim p(\mathbf{G}^{1:T},\mathbf{Y}^{T}|\mathbf{e})}\left[\log\frac{p(\mathbf{Y} ^{T}=Y^{T}\mid\mathbf{G}^{1:T}=\mathcal{G}^{1:T},\mathbf{e})}{q(\mathbf{Y}^{T}=Y ^{T}\mid\mathbf{G}^{1:T}=\mathcal{G}^{1:T})}\right].\end{split}\] (C.28)

Inspired by [19, 86], we apply an information-theoretic approach to our scenarios. First, we propose the following lemma in order to rewrite the OOD generalization error.

**Lemma 2** (OOD Generalization Upper Bound).: The OOD generalization error is upper bounded by:

\[\mathrm{KL}\left[p(\mathbf{Y}^{T}\mid\mathbf{G}^{1:T},\mathbf{e})\parallel q( \mathbf{Y}^{T}\mid\mathbf{G}^{1:T})\right]\leq\mathrm{KL}\left[p(\mathbf{Y}^{T }\mid\mathbf{G}^{1:T},\mathbf{e})\parallel q(\mathbf{Y}^{T}\mid\mathbf{Z}^{1: T})\right],\] (C.29)

where \(q(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T})\) can be seen as the inferred variational distribution of the edge predictor.

Proof.: We prove Lemma 2 by continue investigating on Eq. (C.28):

\[\mathrm{KL}\left[p(\mathbf{Y}^{T}\mid\mathbf{G}^{1:T},\mathbf{e} )\parallel q(\mathbf{Y}^{T}\mid\mathbf{G}^{1:T})\right]\] (C.30) \[=\mathbb{E}_{\mathbf{e}}\mathbb{E}_{(\mathcal{G}^{1:T},Y^{T}) \sim p(\mathbf{G}^{1:T},\mathbf{Y}^{T}|\mathbf{e})}\left[\log\frac{p( \mathbf{Y}^{T}=Y^{T}\mid\mathbf{G}^{1:T}=\mathcal{G}^{1:T},\mathbf{e})}{q( \mathbf{Y}^{T}=Y^{T}\mid\mathbf{G}^{1:T})}\right]\] \[=\mathbb{E}_{\mathbf{e}}\mathbb{E}_{(\mathcal{G}^{1:T},Y^{T}) \sim p(\mathbf{G}^{1:T},\mathbf{Y}^{T}|\mathbf{e})}\left[\log\frac{p( \mathbf{Y}^{T}=Y^{T}\mid\mathbf{G}^{1:T}=\mathcal{G}^{1:T})}{\mathbb{E}_{ \mathbf{Z}^{1:T}\sim q(\mathbf{Z}^{1:T}|\mathbf{G}^{1:T}=\mathcal{G}^{1:T})} \left[q(\mathbf{Y}^{T}=Y^{T}\mid\mathbf{Z}^{1:T})\right]}\right]\] \[\leq\mathbb{E}_{\mathbf{e}}\mathbb{E}_{(\mathcal{G}^{1:T},Y^{T}) \sim p(\mathbf{G}^{1:T},\mathbf{Y}^{T}|\mathbf{e})}\mathbb{E}_{\mathbf{Z}^{1: T}\sim q(\mathbf{Z}^{1:T}|\mathbf{G}^{1:T}=\mathcal{G}^{1:T})}\left[\log\frac{p( \mathbf{Y}^{T}=Y^{T}\mid\mathbf{G}^{1:T}=\mathcal{G}^{1:T},\mathbf{e})}{q( \mathbf{Y}^{T}=Y^{T}\mid\mathbf{Z}^{1:T})}\right]\] \[=\mathrm{KL}\left[p(\mathbf{Y}^{T}\mid\mathbf{G}^{1:T},\mathbf{e} )\parallel q(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T})\right].\quad\text{(upper bound for OOD generalization error)}\]

Again, the inequality in Eq. (C.22) is derived from Jensen's Inequality, while the EA-DGNN \(w(\cdot)\) ensures \(q(\mathbf{Z}^{1:T}\mid\mathbf{G}^{1:T})\) is a Dirac delta distribution (\(\delta\)-distribution). 

Based on Lemma 1, we can adapt the Eq. (12) as:

\[\min_{q(\mathbf{Z}^{1:T}|\mathbf{G}^{1:T}),q(\mathbf{Y}^{T},\mathbf{Z}^{1:T})} \mathrm{KL}\left[p(\mathbf{Y}^{T}\mid\mathbf{G}^{1:T},\mathbf{e})\parallel q( \mathbf{Y}^{T}\mid\mathbf{Z}^{1:T})\right]+I(\mathbf{Y}^{T};\mathbf{e}\mid \mathbf{Z}^{1:T}).\] (C.31)

Thus, based on Lemma 2, we validate that minimizing Eq. (12) is equivalent to minimizing the upper bound of the OOD generalization error in Eq. (2), _i.e._,

\[\min_{\boldsymbol{\theta}}\mathcal{L}_{\mathrm{task}}+\alpha \mathcal{L}_{\mathrm{risk}} \Leftrightarrow\min_{q(\mathbf{Z}^{1:T}|\mathbf{G}^{1:T}),q( \mathbf{Y}^{T},\mathbf{Z}^{1:T})}\mathrm{KL}\left[p(\mathbf{Y}^{T}\mid \mathbf{G}^{1:T},\mathbf{e})\parallel q(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T})\right]\] (C.32) \[\qquad\qquad\qquad\qquad\qquad+I(\mathbf{Y}^{T};\mathbf{e}\mid \mathbf{Z}^{1:T})\] \[\geq\min_{q(\mathbf{Z}^{1:T}|\mathbf{G}^{1:T}),q(\mathbf{Y}^{T}, \mathbf{Z}^{1:T})}\mathrm{KL}\left[p(\mathbf{Y}^{T}\mid\mathbf{G}^{1:T}, \mathbf{e})\parallel q(\mathbf{Y}^{T}\mid\mathbf{Z}^{1:T})\right]\] \[\geq\mathrm{KL}\left[p(\mathbf{Y}^{T}\mid\mathbf{G}^{1:T}, \mathbf{e})\parallel q(\mathbf{Y}^{T}\mid\mathbf{G}^{1:T})\right].(I(\mathbf{Y} ^{T};\mathbf{e}\mid\mathbf{Z}^{1:T})\text{ is non-negative})\]

We conclude the proof for Proposition 4. 

## Appendix D Experiment Details and Additional Results

### Datasets Details

We use three real-world datasets to evaluate Eagle on the challenging future link prediction task.

* **COLLAB1**[81] is an academic collaboration dataset with papers that were published during 1990-2006 (16 graph snapshots). Nodes and edges represent authors and co-authorship, respectively. Based on the co-authored publication, there are five attributes in edges, including "Data Mining", "Database", "Medical Informatics", "Theory" and "Visualization". We pick "Data Mining" as the shifted attribute. We apply word2vec [59] to extract 32-dimensional node features from paper abstracts. We use 10/1/5 chronological graph snapshots for training, validation, and testing, respectively. The dataset includes 23,035 nodes and 151,790 links in total. Footnote 1: https://www.aminer.cn/collaboration
* **Yelp2**[75] contains customer reviews on business. Nodes and edges represent customer/business and review behaviors, respectively. Considering categories of business, there are five attributes in edges, including "Pizza", "American (New) Food", "Coffee & Tea", "Sushi Bars" and "Fast Food" from January 2019 to December 2020 (24 graph snapshots). We pick "Pizza" as the shifted attribute. We apply word2vec [59] to extract 32-dimensional node features from reviews. We use 15/1/8 chronological graph snapshots for training, validation, and testing, respectively. The dataset includes 13,095 nodes and 65,375 links in total. Footnote 2: https://www.yelp.com/dataset* **ACT3**[45] describes student actions on a MOOC platform within a month (30 graph snapshots). Nodes represent students or targets of actions, edges represent actions. Considering the attributes of different actions, we apply K-Means [29] to cluster the action features into five categories and randomly select a certain category (the 5th cluster) of edges as the shifted attribute. We assign the features of actions to each student or target and expand the original 4-dimensional features to 32 dimensions by a linear function. We use 20/2/8 chronological graph snapshots for training, validation, and testing, respectively. The dataset includes 20,408 nodes and 202,339 links in total.

Footnote 3: https://snap.stanford.edu/data/act-mooc.html

Statistics of the three datasets are concluded in Table D.1. These three datasets have different time spans and temporal granularity (16 years, 24 months, and 30 days), covering most real-world scenarios. The most challenging dataset for the future link prediction task is the COLLAB. In addition to having the longest time span and the coarsest temporal granularity, it also has the largest difference in the properties of its links.

We visualize the distribution shifts in the three real-world dataset with respect to the average neighbor degree (Figure D.1) and the number of interactions (Figure D.2) in training and testing sets. We observe that, there exists a huge difference in terms of the values, trends, _etc._, between the training set and the testing set, which demonstrates the distribution shifts are heavy. Interestingly, COLLAB has less testing data than its training data, which is common in real-world scenarios, such as not all the co-authorship was established from the beginning. In addition, we notice a drastic drop in Yelp after January 2019 when the COVID-19 outbreak. The sudden change in predictive patterns increases the difficulty of the task. A similar abnormal steep upward trend can also be witnessed in ACT after Day 20, which may be caused by an unknown out-of-distribution event.

### Baseline Details

We compare Eagle with representative GNNs and OOD generalization methods.

* **Static GNNs: GAE**[42] is a representative static GNN as the GCN [41] based graph autoencoder; **VGAE**[42] further introduces variational variables into GAE, possessing better generative ability.
* **Dynamic GNNs: GCRN**[76] is a representative dynamic GNN following "spatial first, temporal second" convolution mechanism, which firstly adopts GCNs to obtain node embeddings and then a GRU [13] to capture temporal relations; **EvolveGCN**[62] applies an LSTM [31] or GRU

\begin{table}
\begin{tabular}{c c c c c c c} \hline \hline
**Dataset** & **\# Nodes** & **\# Links** & \begin{tabular}{c} **\# Graph** \\ **Snapshots** \\ \end{tabular} & \begin{tabular}{c} **Temporal** \\ **Granularity** \\ \end{tabular} & \begin{tabular}{c} **In-distribution Attributes** \\ \end{tabular} & \begin{tabular}{c} **Shifted** \\ **Attribute** \\ \end{tabular} \\ \hline COLLAB & 23,035 & 151,790 & 16 & year & \begin{tabular}{c} Database, Medical Informatics, \\ Theory, Visualization \\ \end{tabular} & Data Mining \\ Yelp & 13,095 & 65,375 & 24 & month & 
\begin{tabular}{c} American (New) Food, Fast Food \\ Sush Bars, Coffee \& Tea \\ Attributes 1-4 \\ \end{tabular} & Pizza \\ ACT & 20,408 & 202,339 & 30 & day & Attributes 1-4 & Attribute 5 \\ \hline \hline \end{tabular}
\end{table}
Table D.1: Statistics of the real-world datasets.

Figure D.1: Visualizations of the average neighbor degree in each graph snapshot.

to flexibly evolve the parameters of GCNs instead of modeling the dynamics after deriving node embeddings; **DySAT**[75] models dynamic graph through self-attentions in both structural neighborhoods and temporal dynamics.
* **OOD generalization methods**: **IRM**[3] minimizes the empirical risk to learn an optimal invariant predictor under potential environments; **V-REx**[44] extends the IRM by reweighting the empirical risk to emphasize more on training samples with larger errors; **GroupDRO**[74] reduces the empirical risk gap across training distributions to enhance the robustness when encountering heavy OOD shifts; **DIDA**[94] tackles OOD generalization problem on dynamic graphs for the first time by discovering and utilizing invariant patterns. It is worth noting that, DIDA [94] is the most relative work as our main baseline for comparison.

### Experiment Setting Details

**Detailed Settings for Section 4.1.1.** Each of the three real-world datasets can be split into several partial dynamic graphs based on their link properties, which demonstrates the multi-attribute relations under the impact of their surrounding environments. We filter out one certain attribute links as the variables under the future shifted environment as the OOD data, and the left links are further divided into training, validation, and testing sets chronologically. The shifted attribute links will only be accessible during the OOD testing stage, which is more practical and challenging in real-world scenarios as the model cannot capture any information about the filtered links during training and validation. Note that, all attribute-related features have been removed after the above operations before feeding to Eagle. Take the COLLAB dataset for example. There are five attribute links in COLLAB as summarized in Table D.1. We filter out all the links with the attribute "Data Mining", and split the rest of the links into training, validation, and testing sets by positive and negative edge sampling. Then we add the "Data Mining" links into testing sets to make the distribution shifts. Finally, we remove all link attribute information to avoid data leakage.

**Detailed Settings for Section 4.1.2.** Denote original node features and structures as \(\mathbf{X}^{t}\in\mathbb{R}^{N\times d}\) and \(\mathbf{A}^{t}\in\{0,1\}^{N\times N}\). For each time \(t\), we uniformly sample \(p(t)|\mathcal{E}^{t+1}|\) positive links and \((1-p(t))|\mathcal{E}^{t+1}|\) negative links, which are then factorized into shifted features \(\mathbf{X}^{t\prime}\in\mathbb{R}^{N\times d}\) while preserving structural property. Original node features and synthesized node features are concatenated as \([\mathbf{X}^{t}||\mathbf{X}^{t\prime}]\) as the input. In details, \(\mathbf{X}^{t\prime}\) is obtained by training the embeddings with reconstruction loss \(\ell(\mathbf{X}^{t\prime}\mathbf{X}^{t\prime\top},\mathbf{A}^{t+1})\), where \(\ell(\cdot)\) refers to the cross-entropy loss function [16]. In this way, we find that the link predictor can achieve satisfying results by using \(\mathbf{X}^{t\prime}\) to predict the links in \(\mathbf{A}^{t+1}\), which demonstrates that the generated node features have strong correlations with the future underlying environments. The sampling probability \(p(t)=\bar{p}+\sigma\cos(t)\), where \(\mathbf{X}^{t\prime}\) with higher \(p(t)\) will have stronger spurious correlations with future underlying environments. Note that, we apply the \(\mathrm{clip}(\cdot)\) function to limit the probability to between 0 and 1. We set \(\bar{p}\) to be 0.4, 0.6, and 0.8 for training and 0.1 for testing; set \(\sigma=0.05\) in training and \(\sigma=0\) in testing.

**Detailed Settings for Section 4.2.** We set the number of nodes \(N=\) 2,000 with 10 graph snapshots, where 6/2/2 chronological snapshots are used for training, validation, and testing, respectively. We set \(K=5\) and let \(\sigma_{\mathbf{e}}\) represent the proportion of the environments in which the invariant patterns are learned, where higher \(\sigma_{\mathbf{e}}\) means more reliable invariant patterns. Node features with respect to different environments are drawn from five multivariate normal distributions \(\mathcal{N}(\bm{\mu}_{k};\bm{\sigma}_{k})\). Features

Figure D.2: Visualizations of the number of interactions in each graph snapshot.

[MISSING_PAGE_EMPTY:26]

### Intervention Efficiency Analysis

From the results of complexity analysis in Appendix B, we believe the computational complexity bottleneck of Eagle lies in the spatio-temporal causal intervention mechanism. In this case, we analyze the intervention efficiency in the following two aspects.

**Intervention Ratio.** We perform node-wisely causal interventions as in Eq. (15). However, executing interventions for all nodes in each epoch is time-consuming. Thus, we propose randomly selecting nodes and performing interventions according to a certain ratio. Let the intervention ratio represent the ratio of the number of intervened nodes to the total number of nodes \(|\mathcal{V}|\). Figure D.5 shows the changes in task performance (AUC %) and the training time as the intervention ratio increases. We observe the AUC increases, proving that the spatio-temporal causal intervention mechanism is more effective in solving the OOD generalization problem with more intervened nodes. In addition, we notice a jump in the growth rate of AUC on three datasets at the ratio of 0.6, which indicates the most suitable intervention ratio while maintaining an acceptable training time cost.

**Mixing Ratio.** The intervention set \(\mathbf{s}_{v}\) is sampled from \(\mathcal{S}_{\mathrm{ob}}\cup\mathcal{S}_{\mathrm{ge}}\). While \(\mathcal{S}_{\mathrm{ob}}\) has been already prepared after we model the environments in Section 3.1, the \(\mathcal{S}_{\mathrm{ge}}\) requires instantly generating, which may be a burden on the intervention efficiency. Let the maxing ratio represent the ratio of the number of observed environment samples to the number of generated environment samples. Figure D.6 shows the changes in task performance (AUC %) and the training time as the mixing ratio increases. Different from the trend in Figure D.5, AUC reached the maximum value at different ratios on the three datasets, and when the ratio is too large or small, the model performs poorly, indicating that different datasets have varying preferences for mixing ratio settings. In addition, we observe the variation in training time is not significant, verifying that although \(\mathcal{S}_{\mathrm{ob}}\) needs to be generated instantly, its time cost is acceptable still, and we should pay more attention on the optimal mixing ratio.

### Additional Analysis of Section 4.1

We visualize Table 1 and Table 2 in Section 4.1 to provide additional analysis. We have concluded in Section 4.1 that the baselines own a strong fitting ability but weak generalization ability between the distribution shifts settings. In addition to visualizing the task performance (AUC %), Figure D.7

Figure D.6: Intervention efficiency analysis on the mixing ratio. The vertical dashed line indicates the ratio when AUC reaches the maximum value.

Figure D.5: Intervention efficiency analysis on the intervention ratio. The vertical dashed line indicates the most suitable intervention ratio while maintaining an acceptable training time cost.

annotates the decrease of AUC under each baseline method, where the horizontal dashed line represents the AUC decrease of our Eagle. The smaller the decrease, the stronger the control ability under the impact of out-of-distribution shifts. We can observe that on the vast majority of datasets, our method can improve task performance in both _w/o OOD_ and _w/ OOD_ scenarios while minimizing AUC decrease. Our control over AUC decrease exceeds the baseline except for GAE and GCRN in the vast majority of cases. For the above two baseline methods, although they have better control ability over AUC decrease than our method, the premise is that their task performance is inherently poor. In addition, our method achieves the most excellent task performance on the ACT dataset, which can explain the unsatisfying but acceptable AUC decrease control. In summary, in addition to evaluating the advantages of our Eagle in terms of task performance and generalization ability, which is the most topic-relative and common, our Eagle also maintains the ability to reduce the impact of OOD on task performance.

### Additional Results of Section 4.2

Section 4.2 reports the results when \(\bar{q}=0.8\). Here we report the additional results when \(\bar{q}=0.4\) and 0.6 in Figure D.8. All detailed results are summarized in Table D.2. A similar trend can be observed as we report in Section 4.2 that as \(\sigma_{\mathbf{e}}\) increases, the performance of Eagle shows a significant increase while narrowing the gap between _w/o OOD_ and _w/ OOD_ scenarios. Although DIDA [94] also shows an upward trend, its growth rate is much more gradual, which indicates that DIDA [94] is difficult to perceive changes in the underlying environments caused by different \(\sigma_{\mathbf{e}}\) as it is incapable of modeling the environments, thus cannot achieve satisfying generalization performance. In addition, we also notice a positive correlation between \(\mathbb{I}_{\mathrm{ACC}}\) and the AUC, which verifies the improvements are attributed to the proper recognition of the invariant patterns by \(\mathbb{I}(\cdot)\). In conclusion, our Eagle can exploit more reliable invariant patterns, thus performing high-quality invariant learning and efficient causal interventions, and achieving better generalization ability.

## Appendix E Implementation Details

### Training and Evaluation

**Training Settings.** The number of training epochs for optimizing our proposed method and all baselines is set to 1000. We adopt the early stopping strategy, _i.e._, stop training if the performance

Figure D.7: Additional analysis of the performance on future link prediction.

on the validation set does not improve for 50 epochs. For our Eagle, the hyperparameter \(\alpha\) is chosen from \(\{10^{-3},10^{-2},10^{-1},10^{0},10^{1}\}\), and \(\beta\) is chosen from \(\{10^{-6},10^{-5},10^{-4},10^{-3},10^{-2}\}\). The intervention ratio and the mixing ratio are carefully tuned for each dataset. For other parameters, we adopt the Adam optimizer [40] with an appropriate learning rate and weight decay for each dataset and adopt the grid search for the best performance using the validation split. All parameters are randomly initiated, which is especially important for \(\mathbf{W}_{k}\) in Eq. (3) that ensures the difference in each environment embedding space. The \(K\) channels will still remain orthogonal during training as we conduct discrete environment disentangling iteratively. This helps the recognition of invariant/variant patterns mainly because we guarantee there is no overlap between environments.

**Evaluation.** According to respective experiment settings, we randomly split the dynamic datasets into training, validation, and testing chronological sets. We sample negative links from nodes that do not have links, and the negative links for validation and testing sets are kept the same for all baseline methods and ours. We set the number of positive links to the same as the negative links. We use the Area under the ROC Curve (AUC) [7] as the evaluation metric. As we focus on the future link prediction task, we use the inner product of a pair of learned node representations to predict the occurrence of links, _i.e._, we implement the link predictor \(g(\cdot)\) as the inner product of hidden embeddings, which is commonly applied in classic future link prediction tasks. The biased training technique is adopted following [9]. We use the cross-entropy loss as the loss function \(\ell(\cdot)\). The activation function is LeakyReLU [1]. We randomly run all the experiments five times, and report the average results with standard deviations.

### Baseline Implementation Details

We provide the baseline methods implementations with respective licenses as follows.

\begin{table}
\begin{tabular}{c|c|c|c c|c c|c c} \hline \multicolumn{2}{c|}{**Shift Degree**} & \multicolumn{1}{c|}{—} & \multicolumn{3}{c|}{\(\bar{q}=\mathbf{0.4}\)} & \multicolumn{3}{c|}{\(\bar{q}=\mathbf{0.6}\)} & \multicolumn{3}{c}{\(\bar{q}=\mathbf{0.8}\)} \\ \hline \(\sigma_{\text{e}}\) & **Model** & _w/o OOD_ & _w/ OOD_ & \(\mathrm{I}_{\text{ACC}}\) & _w/ OOD_ & \(\mathrm{I}_{\text{ACC}}\) & _w/ OOD_ & \(\mathrm{I}_{\text{ACC}}\) \\ \hline \multirow{3}{*}{**0.2**} & DIDA [94] & 63.29\(\pm\)0.35 & 54.62\(\pm\)0.92 & — & 53.33\(\pm\)1.01 & — & 52.87\(\pm\)1.28 & — \\  & **EAGLE** & 67.10\(\pm\)0.23 & 59.91\(\pm\)1.18 & 69.28\(\pm\)1.59 & 54.71\(\pm\)1.29 & 63.36\(\pm\)1.74 & 54.26\(\pm\)1.31 & 59.79\(\pm\)1.37 \\ \hline \multirow{3}{*}{**0.4**} & DIDA [94] & 64.31\(\pm\)0.34 & 56.36\(\pm\)0.98 & — & 56.04\(\pm\)1.13 & — & 55.89\(\pm\)1.24 & — \\  & **EAGLE** & 70.32\(\pm\)0.27 & 63.97\(\pm\)0.82 & 72.04\(\pm\)1.34 & 61.08\(\pm\)1.02 & 69.95\(\pm\)1.30 & 58.40\(\pm\)1.12 & 63.88\(\pm\)1.36 \\ \hline \multirow{3}{*}{**0.6**} & DIDA [94] & 65.27\(\pm\)0.41 & 59.37\(\pm\)0.87 & — & 58.79\(\pm\)0.97 & — & 57.35\(\pm\)1.19 & — \\  & **EAGLE** & 71.77\(\pm\)0.38 & 66.01\(\pm\)0.74 & 80.31\(\pm\)1.52 & 63.26\(\pm\)0.64 & 73.62\(\pm\)1.41 & 63.11\(\pm\)0.78 & 69.30\(\pm\)1.50 \\ \hline \multirow{3}{*}{**0.8**} & DIDA [94] & 66.56\(\pm\)0.39 & 60.07\(\pm\)0.89 & — & 59.82\(\pm\)1.05 & — & 59.20\(\pm\)1.03 & — \\  & **EAGLE** & 74.33\(\pm\)0.29 & 68.41\(\pm\)0.72 & 83.95\(\pm\)1.66 & 66.15\(\pm\)0.69 & 77.08\(\pm\)1.73 & 65.82\(\pm\)0.81 & 72.59\(\pm\)1.46 \\ \hline \multirow{3}{*}{**1.0**} & DIDA [94] & 66.93\(\pm\)0.18 & 62.55\(\pm\)0.85 & — & 61.05\(\pm\)0.93 & — & 60.33\(\pm\)1.17 & — \\  & **EAGLE** & **75.58\(\pm\)0.40** & **70.12\(\pm\)0.91** & **85.83\(\pm\)1.54** & **69.83\(\pm\)0.93** & **79.56\(\pm\)1.65** & **68.09\(\pm\)0.97** & **74.16\(\pm\)1.21** \\ \hline \end{tabular}
\end{table}
Table 2: AUC score (% \(\pm\) standard deviation) of future link prediction task on synthetic datasets. _w/o OOD_ and _w/ OOD_ denote testing without and with distribution shifts. \(\mathrm{I}_{\text{ACC}}\) is reported in the accuracy score). The best results are shown in **bold** and the runner-ups are underlined.

Figure 8: Additional results on the effects of invariant pattern recognition.

* GAE [42]: https://github.com/DaehanKim/vgae_pytorch with MIT License.
* VGAE [42]: https://github.com/DaehanKim/vgae_pytorch with MIT License.
* GCRN [76]: https://github.com/youngjoo-epfl/gconvRNN with MIT License.
* EvolveGCN [62]: https://github.com/IBM/EvolveGCN with Apache-2.0 License.
* DySAT [75]: https://github.com/FeiGSSS/DySAT_pytorch with license unspecified.
* IRM [3]: https://github.com/facebookresearch/InvariantRiskMinimization with CC BY-NC 4.0 License.
* V-REx [44]: https://github.com/capybaralet/REx_code_release with license unspecified.
* GroupDRO [74]: https://github.com/kohpangwei/group_DRO with MIT License.
* DIDA [94]: https://github.com/wondergo2017/DIDA with license unspecified.

The parameters of baseline methods are set as the suggested value in their papers or carefully tuned for fairness.

### Configurations

We conduct the experiments with:

* Operating System: Ubuntu 20.04 LTS.
* CPU: Intel(R) Xeon(R) Platinum 8358 CPU@2.60GHz with 1TB DDR4 of Memory.
* GPU: NVIDIA Tesla A100 SMX4 with 40GB of Memory.
* Software: CUDA 10.1, Python 3.8.12, PyTorch [63] 1.9.1, PyTorch Geometric [20] 2.0.1.

## Appendix F Further Discussions

### Further Analysis on SCM Model

We provide further analysis of the intrinsic cause of the out-of-distribution shifts. From the causal-based theories [64, 65, 66], we formulate the generation process of static graphs and dynamic graphs with the Structural Causal Model (SCM) [64] in Figure F.1, where the arrow between variables denotes causal dependencies. It is widely accepted in the OOD generalization works [22, 3, 72, 87, 11, 2, 60] that the correlations between labels and certain parts of the latent features are invariant across data distributions in training and testing, while the other parts of the features are variant. The invariant part is also called the causal part (\(C\)) and the variant part is also called the spurious part (\(S\)).

**Qualitative Analysis.** In the SCM model on static graphs, \(C\rightarrow\mathbf{G}\gets S\) demonstrates that the invariant part and variant part jointly decide the generation of the graphs, while \(C\rightarrow\mathbf{Y}\) denotes the label is solely determined by the causal part. However, there exists the spurious correlation \(C^{*}\mathbin{\raisebox{-1.0pt}{\scalebox{1.0}{$\sim$}}}S\) in certain distributions that would lead to a backdoor causal path \(S^{-}\mathbin{\raisebox{-1.0pt}{\scalebox{1.0}{$\sim$}}}C\rightarrow\mathbf{Y}\) so that the variant part and the label are correlated statistically. As the variant part changes in the testing distributions caused by different environments \(\mathbf{e}\), the predictive patterns built on the spurious correlations expired. For the same reason, similar spurious correlation \(C^{t_{\mathbf{e}}\mathbin{\raisebox{-1.0pt}{\scalebox{1.0}{$\sim$}}}}S^{t}\) exists on dynamic graphs within a single graph snapshot, which opens the backdoor causal path \(S^{t}\mathbin{\raisebox{-1.0pt}{\scalebox{1.0}{$\sim$}}}C^{t}\rightarrow \mathbf{Y}^{t}\). Especially, as we have captured the temporal dynamics between each graph snapshot, the variant part in the previous time slice may also establish spurious correlations with the invariant part at present time, _i.e._, \(C^{t-1_{\mathbf{e}}\mathbin{\raisebox{-1.0pt}{\scalebox{1.0}{$\sim$}}}}S^{t}\), leading to \(S^{t-1}\mathbin{\raisebox{-1.0pt}{\scalebox{1.0}{$\sim$}}}C^{t}\rightarrow \mathbf{Y}^{t}\), which is a unique phenomenon in the dynamic scenarios. Hence, we propose to get rid of the spurious correlations within and between graph snapshots by investigating the latent environment variable \(\mathbf{e}\), encouraging the model to rely on the spatio-temporal invariant patterns to make predictions, and thus handle the distribution shifts.

**Further Analysis of Assumption 1.** The causal inference theories [64, 65, 66] propose to get rid of the spurious correlations by blocking the backdoor path with \(do\)-calculus, which would remove all causal dependencies on the intervened variables. Particularly, we intervene in the variant parts on all graph snapshots, _i.e._, \(\mathrm{do}(S^{t})\), and thus the spurious correlations within and between graph snapshots can be filtered out. This encourages the two conditions in Assumption 1 to be satisfied: the InvarianceProperty will be satisfied if the spurious correlations \(S^{t-1}\)*\(\times\)\(\sim\)\(C^{t}\)*\(\times\)\(\sim\)\(S^{t}\) are removed and the label will be solely decided by the invariant part \(C^{t}\rightarrow\mathbf{Y}^{t}\), which also satisfies the Sufficient Condition. In this case, we can minimize the variance of the empirical risks under diverse potential environments, while encouraging the model to make predictions of the spatio-temporal invariant patterns.

**Further Explanations of the Toy Example.** From the above analysis, we can further explain the toy example in Figure 1(a). The prediction model has captured the spurious correlations between "coffee" and the "cold drink", which caused the false prediction of buying an Iced Americano in the winter. By applying our environment-ware Eagle, the prediction model can perceive the environments of seasons through the neighbors around the central node, _i.e._, perceiving the winter season by learning the observed interactions between the user and the thick clothing. Thus encouraging the model to rely on the exploited spatio-temporal invariant patterns, _i.e._, "the user buys coffee", to make the correct prediction on the Hot Latte by considering underlying environments.

### Further Understanding of Environments

Environments on dynamic graphs are latent factors, where there are no accessible ground-truth environment labels in the real world, leading to the lack of explainability. In order to improve the explainability of the environment, and patterns the EA-DGNN learns, we have provided some real-world examples to make explanations (Section 3.1). The key insight lies that, the formation of real-world dynamic graphs typically follows a complex process under the impact of latent environments, causing the relationships to be multi-attribute. To model diverse spatio-temporal environments, the ego-graphs of each node need to be disentangled and processed in different embedding spaces.

**An Easy-to-Understand Example: the Social Networks.** The relationships between the central node and its neighbor nodes, which may be classmates, colleagues, _etc._, are formed under the influence of different surrounding environments. For example, the relationship between classmates is formed in the "school" environment, which is a compound of "classmates", "teachers", "staff", _etc._, and the relationship between colleagues is formed in the "working" environment, _etc._ Multiple relationships are compounded into a single edge and change over time. In order to model such multiple environments, we propose multi-channel environments disentangling to represent different semantic relationships in \(K\) embedding spaces. For example, the 1-st embedding represents the "classmate" relationship, and the 2-nd embedding space represents the "colleague" relationship, _etc._ Thus, EA-DGNN realizes the perception of multiple surrounding environments and encodes spatio-temporal environment information into node representations.

### Further Understanding of the Multi-Label

**Understanding.** We do not require ground-truth environment labels in our Eagle. The environments on dynamic graphs are latent factors, where there are no accessible ground-truth environment labels that have practical meanings in the real world. This is also why conventional OOD generalization baselines on images, text, _etc._ have poor performance (Section 4.1) in graphs as they must rely on the ground-truth environment labels to generalize. In our work, the multi-label \(\mathbf{y}\) in Section 3.2 is mixed up with time index \(t\) and environment index \(k\), indicating which environment index under which time index \(\mathbf{z}\) belongs. It can be seen as our inferred label of environments.

Figure 1: The SCM model on static graphs and dynamic graphs.

**Example.** If there exist \(K\) environments and \(T\) graph snapshots, we first initialize a zero matrix of the shape \(K\times T\). Then we mark the value in position \((k,t)\) to be 1 and reshape the matrix into the 1-dimension vector \(\mathbf{y}\), indicating the multi-label of \(\mathbf{z}\) for the \(k\)-th environment at time \(t\).

**Role.** The multi-labels are used with \(\mathbf{z}\) to infer environments by ECVAE, where the multi-label is concatenated with its corresponding \(\mathbf{z}\) to realize conditional variational inference. We can then instantiate environments by generating samples from the inferred distribution with a given one-hot multi-label. This can be regarded as the data augmentation of the environment samples under the guidance of the inferred prior distribution \(q_{\phi}(\mathbf{e}\mid\mathbf{z},\mathbf{y})\), which helps improve the generalization ability.

### Further Understanding of Proposition 2

**Targets and Principles.** Proposition 2 provides a solution to obtain the optimal \(\mathbb{I}^{*}(\cdot)\) in Assumption 1 with theoretical proof in Appendix C.2. In fact, Proposition 2 solves a dynamic programming problem by optimizing the state transition equation \(\mathbb{I}(i,j)\). Given \(\mathrm{Var}(\mathbf{z}_{v}^{\mathbf{\mathbf{\mathbf{\mathbf{\mathbf{\mathbf{ \mathbf{\mathbf{\mathbf{\mathbf{\mathbf{\mathbf{\mathbf{\mathbf{\mathbf{\mathbf{  \mathbf{  }}}}}}}}}}}}})\in \mathbb{R}^{K}\) as the representation variance of node \(v\) in each environment across times, the target is to find a partition dividing all environment patterns into invariant and variant types, so as to maximize the difference between the variance means.

**A Conceptual Example.** If \(\mathrm{Var}(\mathbf{z}_{v}^{\mathbf{\mathbf{\mathbf{\mathbf{\mathbf{\mathbf{ \mathbf{\mathbf{\mathbf{\mathbf{\mathbf{\mathbf{\mathbf{\mathbf{\mathbf{ \mathbf{ \mathbf{  \mathbf{   }}}}}}}}}}}}})\) of node \(v\) is [0.1, 0.2, 0.3, 0.4, 0.9], then the optimal partition is [0.1, 0.2, 0.3] and [0.4, 0.9]. An optimal partition can always be found for each node, which greatly helps the patterns discrimination and fine-grained causal interventions, improving the generalization ability, and is one of our main advantages compared with DIDA [94].

Proposition 2 intuitively illustrates a feasible implementation for the optimal \(\mathbb{I}^{*}(\cdot)\), providing an ideal optimizing start point. Note that, Proposition 2 itself cannot fully guarantee the global accuracy of identifying the \(\mathbb{I}^{*}(\cdot)\), but should optimize along with the \(\mathcal{L}_{\mathrm{risk}}\) loss (Eq.(14)), which provides theoretical ensure.

### Further Discussions Compared with DIDA

The difference between our Eagleand DIDA [94], and Eagle's main advantages are:

* **Modeling Environments.** Eagle is the first to explicitly model latent environments on dynamic graphs by variational inference. DIDA [94] neglects to model complex environments, which weakens its ability to identify invariant patterns.
* **Representation Learning.** Eagle learns node embeddings by \(K\)-channel environments disentangling and spatio-temporal convolutions, which helps better understand multi-attribute relations. DIDA [94] learns with single channel convolutions with an attention mechanism.
* **Invariant Learning.** Eagle discriminates spatio-temporal invariant patterns by the theoretically supported \(\mathbb{I}^{*}(\cdot)\) for each node individually, leading to better removal of spurious correlations. DIDA [94] divides invariant/variant parts heuristicly with a minus operation for all nodes.
* **Causal Intervention.** Eagle performs fine-grained causal interventions with both observed and generated environment samples, better minimizing the variance of extrapolation risks, and generalizing to unseen distributions better. DIDA [94] intervenes coarse-grainedly with only observed samples.

### Further Related Work

**Dynamic Graph Learning.** Extensive research [70, 4] address the challenges of learning on dynamic graphs, which consist of multiple graph snapshots at different times. Dynamic graph neural networks (DGNNs) are widely adopted to learn dynamic graphs by intrinsically modeling both spatial and temporal patterns, which can be divided into two main categories: spatial-first methods and temporal-first methods. The spatial-first methods [88, 28, 76] first adopt vanilla GNNs to model spatial patterns for each graph snapshot, followed by sequential-based models like RNNs [58] or LSTMs [31], to capture temporal relations. In comparison, temporal-first DGNNs [84, 73] model dynamics in advance with temporal encoding mechanisms [32], and then conduct convolutions of message-passing and aggregating on each single graph with GNNs. Dynamic graph learning has been widely utilized for prediction tasks like disease transmission prediction [38], dynamic recommender system [90],social relation prediction [85], _etc._ However, most existing works fail to generalize under distribution shifts. DIDA [94] is the sole prior work that addresses distribution shifts on dynamic graphs with an intervention mechanism. But DIDA [94] neglects to model the complex environments on dynamic graphs, which is crucial in tackling distribution shifts. We also experimentally validate the advantage of our method compared with DIDA [94].

**Out-of-Distribution Generalization.** Most machine learning methods are built on the I.I.D. hypothesis, _i.e._, training and testing data follow the independent and identical distribution, which can hardly be satisfied in real-world scenarios [77], as the generation and collection process of data are affected by many latent factors [71, 3]. The non-I.I.D. distribution results in a significant decline of model performance, highlighting the urgency to investigate generalized learning methods for out-of-distribution (OOD) shifts, especially for high-stake downstream applications, like autonomous driving [15], financial system [62], _etc._ OOD generalization has been extensively studied in both academia and industry covering various areas [77, 92, 30] and we mainly focus on OOD generalization on graphs [50]. Most graph-targeted works concentrate on node-level or graph-level tasks on static graphs [98, 18, 49, 86, 52, 12, 87], targeting at solving the problems of graph OOD generalization for drugs, molecules, _etc._, which is identified as one key challenge in AI for science (AI4Science). Another main category of works elaborates systematic benchmarks for graph OOD generalization evaluation [26, 17, 36]. However, there lack of further research on dynamic graphs with more complicated shift patterns caused by spatio-temporal varying latent environments, which is our main concern.

**Invariant Learning.** Deep learning models tend to capture predictive correlations behind observed samples, while the learned patterns are not always consistent with in-the-wild extrapolation. Invariant learning aims to exploit the less variant patterns that lead to informative and discriminative representations for stable prediction [14, 46, 95]. Supporting by disentangled learning theories and causal learning theories, invariant learning tackles the OOD generalization problem from a more theoretical perspective, revealing a promising power. Disentangle-based methods [5, 55] learn representations by separating semantic factors of variations in data, making it easier to distinguish invariant factors and establish reliable correlations. Causal-based methods [22, 3, 72, 87, 11, 2, 60] utilize Structural Causal Model (SCM) [64] to filter out spurious correlations by intervention or counterfactual with \(do\)-calculus [65, 66] and strengthen the invariant causal patterns. However, the invariant learning method of node-level tasks on dynamic graphs is underexplored, mainly due to its complexity in analyzing both spatial and temporal invariant patterns.

**Disentangled Representation Learning.** Disentangled Representation Learning (DRL) is a paradigm that inspires a model with the capability to discriminate and disentangle latent factors intrinsic to the observable data. The fundamental objective of DRL is to separate latent factors of variation into distinct variables endowed with semantic significance. This helps to improve the generalization capacity, explainability, and robustness, _etc._ in a wide range of scenarios. Following [83], we categorize existing DRL works into traditional statistical approaches, VAE-based approaches, GAN-based approaches, hierarchical approaches, and other methods. Specifically, applying DRL to graphs results in benefits and advantages in graph tasks. DisenGCN [56], FactorGCN [89], DGCL [48], _etc._ decompose the input graph into segments for disentangled representations, which inspire our work on environment disentangling.