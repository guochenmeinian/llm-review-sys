# Embedding-Aligned Language Models

Guy Tennenholtz\({}^{\dagger}\), Yinlam Chow\({}^{\dagger}\), Chih-Wei Hsu\({}^{\dagger}\), Lior Shani\({}^{\dagger}\), Ethan Liang\({}^{\ddagger}\), Craig Boutilier\({}^{\dagger}\)

\({\dagger}\) Google Research, \(\ddagger\) Google Deepmind

Correspondence to: guytenn@gmail.com

###### Abstract

We propose a novel approach for training large language models (LLMs) to adhere to objectives defined within a latent embedding space. Our method leverages reinforcement learning (RL), treating a pre-trained LLM as an environment. Our _embedding-aligned guided language_ (EAGLE) agent is trained to iteratively steer the LLM's generation towards optimal regions of the latent embedding space, w.r.t. some predefined criterion. We demonstrate the effectiveness of the EAGLE agent using the MovieLens 25M and Amazon Review datasets to surface content gaps that satisfy latent user demand. We also demonstrate the benefit of using an optimal design of a state-dependent action set to improve EAGLE's efficiency. Our work paves the way for controlled and grounded text generation using LLMs, ensuring consistency with domain-specific knowledge and data representations.

## 1 Introduction

Large language models (LLMs) such as Gemini (Team et al., 2023) and GPT (Achiam et al., 2023) have revolutionized the field of natural language processing, achieving remarkable success in text generation, translation, comprehension, as well as expert-level performance on challenging tasks (e.g., exams, coding). However, effectively applying (or fine-tuning) LLMs to _domain-specific_ tasks often requires considerable domain knowledge and labeled human data (Jeong et al., 2023; Ouyang et al., 2022; Ziegler et al., 2019). Fortunately, in many cases, domain knowledge is already captured and encoded within _latent embedding spaces_.

Latent embeddings are continuous vectors, ubiquitous in fields such as recommender systems (Hansen et al., 2020), reinforcement learning (RL) (Nabati et al., 2023; Pertsch et al., 2021), and image classification (Girdhar et al., 2023; Radford et al., 2021). They offer a powerful means to represent entities, concepts, and relationships within a specific domain. For example, in recommender systems, embeddings of items and users encapsulate information about preferences and behavior (Zhao et al., 2023), embeddings of images can capture their content and style (Radford et al., 2021), while embeddings of scientific articles can represent their research area and findings (Taher Harikandeh et al., 2023). The utility of a latent embedding lies in its underlying compact representation of entities, concepts or relationships, and the associated metrics, allowing one to construct simpler, more efficient models or induce control over various processes (Arvanitidis et al., 2018, 2021; Radford et al., 2021; Tennenholtz and Mannor, 2022). Importantly, latent embeddings are often pre-computed, and can thus serve as a readily available rich source of domain knowledge.

This leads to the key question: **can we leverage latent embeddings to better control and guide LLM generation?** In this paper, we present a novel framework which accomplishes this by exploiting latent embedding spaces to define an objective function for an LLM in an iterative RL-driven process.

As an example, consider the challenge of assisting content creators in generating valuable content within a recommender ecosystem (e.g., YouTube, Reddit, Spotify) (Boutilier et al., 2024). Animportant aspect of this problem includes identifying and surfacing of _content gaps_, i.e., identifying hypothetical content which could potentially drive value for users, and subsequently, describing it to creators. Latent embeddings offer an effective way of defining a content gap. Informally, a content gap is a hypothetical (i.e., non-existing) content item, corresponding to some point in a latent embedding space for which: (1) no content currently exists, implying an unexplored area within the existing content landscape, and (2) adding this content would improve overall system welfare (i.e., drive net positive value for both users and creators). While the latent embedding representation facilitates identification of content gaps, describing or _surfacing_ this hypothetical continuous vector to its potential creator requires that we move beyond the latent representation. The content gap embedding must be translated into a description that communicates its essence to a creator in a clear and actionable manner, requiring some way of interpreting the latent embedding.

In this paper, we address the general problem of _aligning LLMs with latent embedding spaces_. We address this by working directly with both the embedding space and the generated outputs of an LLM. We formulate an RL-driven framework which iteratively steers an LLM towards regions of an embedding space deemed optimal according to some predefined criterion (e.g., a content gap). To do so, we use a language-based agent to guide the LLM by modifying a textual representation of an entity. We then embed the resulting description into the latent embedding space to assess its quality w.r.t. our predefined criterion. Finally, we use this feedback to guide the LLM's next modification, steering it closer to optimal regions of the latent space.

Our contributions are as follows: (1) We propose an Embedding-Aligned Guided LanguageE (EAGLE) agent, which aligns an LLM with a latent embedding space; (2) We provide a comprehensive framework for novel content creation using LLMs, formulating a new technique for designing exploratory and high quality action sets by leveraging the power of LLMs, latent embeddings, and _G-optimal design_(Zhu et al., 2022); (3) We validate the effectiveness of our approach on the MovieLens 25M dataset (Harper and Konstan, 2015), aligning creation to behavioral movie and user embeddings. Our results are evaluated by human raters demonstrating EAGLE's ability to guide an LLM to generate text that is both creative and consistent with the domain's data representations.2

Footnote 2: Further experiments on the Amazon review dataset (Ni et al., 2019) are provided in Appendix I.

## 2 Preliminaries and Related Work

**Large Language Models (LLMs).** An LLM \(\mathcal{L}:\mathcal{S}\mapsto\Delta_{\mathcal{S}}\) maps sequence of tokens to probabilities over sequences of tokens. Transformers (Vaswani et al., 2017) are often used to train such LLMs over vast amounts of data, predicting the next token \(x_{t}\) in a sequence given the preceding tokens (\(x_{1},x_{2},\ldots,x_{t-1}\)), by minimizing the cross-entropy loss. Pre-trained LLMs often vary in size, with larger models having greater capabilities (Achiam et al., 2023; Team et al., 2023; Touvron et al., 2023); e.g., Llama 2 (Touvron et al., 2023) models have 7B, \(13\)B, and \(70\)B parameter variants.

**Embedding Language Models (ELMs).** An _embedding language model (ELM)_(Tennenholtz et al., 2024) combines textual prompts with vector representations of domain knowledge. It uses adapter layers to connect embedding inputs to a text-only pre-trained LLM. By training the model on these combined inputs, ELM generates language that reflects the information contained in the domain embedding vectors, even for hypothetical entities (Tennenholtz et al., 2024).

**Reinforcement Learning (RL).** A _Markov decision process (MDP)_ is a tuple \((\mathcal{S},\mathcal{A},P,r,H,\gamma)\), where \(\mathcal{S}\) is the state space, \(\mathcal{A}\) is the action space, \(P:\mathcal{S}\times\mathcal{A}\mapsto\Delta_{\mathcal{S}}\) is the transition function, \(r:\mathcal{S}\times\mathcal{A}\mapsto\mathbb{R}\) is the reward function, \(H\) is the horizon, and \(\gamma\in[0,1]\) is the discount factor. An _agent_\(\pi:\mathcal{S}\mapsto\Delta_{\mathcal{A}}\) is a stationary stochastic policy mapping states to a distribution over actions.3 Its value at state \(s\), \(V^{\pi}(s)=\mathbb{E}_{P,\pi}\Big{[}\sum_{t=0}^{H-1}\gamma^{t}(s_{t},a_{t})\, \Big{|}\,s_{0}=s\,\Big{]}\), is its expected discounted return starting at \(s\). The objective in RL is to compute an _optimal policy_, which maximizes value over some initial state distribution \(\nu_{0}\), i.e., \(\pi^{*}\in\arg\max_{\pi}\mathbb{E}_{s_{0}\sim\nu_{0}}[V^{\pi}(s_{0})]\).

Footnote 3: We limit ourselves to stationary policies for simplicity.

_Policy gradient (PG)_ methods are a class of RL algorithms that directly optimize the policy to maximize expected return (Schulman et al., 2017; Sutton et al., 1999). In LLM tasks, PG often uses a reference policy \(\pi_{\text{ref}}\) as an anchor to regularize the RL task (e.g., stay close to \(\pi_{\text{ref}}\)). This is the prevalent approach in _reinforcement learning from human feedback_(RLHF, Ouyang et al. (2022)). Inthis work we achieve this using a KL-divergence loss over policy outputs; i.e.,

\[\text{loss}(\pi)=\text{PG-loss}(\pi)-\alpha D_{KL}(\pi||\pi_{\text{ref}}).\] (1)

**Related Work.** Generative models are powerful tools for creative generation of text, images, and more (Achiam et al., 2023; Ho et al., 2020, 2022; Team et al., 2023). Embedding representations (Arvanitidis et al., 2018, 2021; Oord et al., 2018; Yang et al., 2017) have been applied in many fields, including recommender systems (Liang et al., 2018), healthcare (Rampasek et al., 2019), neuroscience (Keshtkaran and Pandarinath, 2019), genetics (Frazer et al., 2021), astronomy (Ravanbakhsh et al., 2017), and more (Gomez-Bombarelli et al., 2018; Kingma et al., 2014; Thadani et al., 2023).

Aligning LLM generation with embedding spaces holds great potential. Our work constrains the generation process to work with a predefined utility over an embedding space. Other methods have been proposed to align language models to knowledge graphs (Bao et al., 2016), safety constraints (Ji et al., 2024; Yang et al., 2021), and human preferences (Bakker et al., 2022; Ouyang et al., 2022; Wang et al., 2024). Our approach can be generalized to such tasks with a suitable latent embedding space and utility specification.

The use of RL with human and AI feedback for LLM fine-tuning has been shown to induce significant improvement in LLM capabilities (Lee et al., 2023; Ouyang et al., 2022). Embedding-driven guidance is an additional form of feedback that can further improve creative LLM generation, and potentially reduce hallucination (Dhuliawala et al., 2023; Gunjal et al., 2024; Li et al., 2023).

## 3 Problem Setup

We assume an _ambient entity space_\(\mathcal{X}\), which represents the space of all possible entities (e.g., all movie plots, or all animal photos). Since our setup is agnostic to the modality of the space \(\mathcal{X}\), we do not emphasize language entities in this section. We assume \(\mathcal{X}\) is equipped with a metric \(d:\mathcal{X}\times\mathcal{X}\mapsto\mathbb{R}_{+}\), which may not be known. We also assume access to a _latent embedding_\(E_{D}:\mathcal{X}\mapsto\mathcal{Z}\), which maps entities in \(\mathcal{X}\) to a latent embedding space \(\mathcal{Z}\subseteq\mathbb{R}^{n}\). If \(E_{D}\) is injective, it induces a metric \(d_{\mathcal{Z}}(z,w)=d(E_{D}^{-1}(z),E_{D}^{-1}(w))\) over \(\mathcal{Z}\). Otherwise, we define the metric \(d_{\mathcal{Z}}(z,w)=\sup_{x\in E_{D}^{-1}(z),y\in E_{D}^{-1}(w)}d(x,y)\) for \(z\neq w\), and \(d_{\mathcal{Z}}(z,z)=0\).4 Let \((\mathcal{Z},d_{\mathcal{Z}})\) be the embedding manifold. Though \(d_{\mathcal{Z}}\) is not known, various methods exist to estimate the underlying metric (e.g., see Appendix B on the use of Riemannian manifolds and pullback metrics of generative models to estimate \(d\)(Arvanitidis et al., 2018, 2021)).

Footnote 4: Other metric definitions are possible; we use this definition for illustration only.

Given a fixed set of entities \(\mathcal{D}=\left\{x_{i}\in\mathcal{X}\right\}_{i=1}^{N}\) of size \(N\) (i.e., a dataset), we define a utility function \(U:\mathcal{Z}\times\mathcal{D}\mapsto\mathbb{R}\) over embeddings on the manifold \((\mathcal{Z},d_{\mathcal{Z}})\). Below we illustrate an example of a utility function for quantifying the quality of a _content gap_.

**Example: Content Gaps.** Consider a utility function \(U\) measuring if a hypothetical point \(z\in\mathcal{Z}\) is a content gap in a recommender ecosystem (Boutilier et al., 2024). We might define \(U\) as:

\[U(z;\mathcal{D})=\underbrace{\sum_{\text{user}}U_{\text{user}}(z;\mathcal{D} )}_{\text{Users' Utility}}+\underbrace{\sum_{\text{creator}}U_{\text{creator}}(z; \mathcal{D})}_{\text{Creators' Utility}}+\underbrace{\sum_{x\in\mathcal{D}}U_{d}(d_{ \mathcal{Z}}(E_{D}(x),z))}_{\text{Distance from existing content}}.\] (2)

Here \(\mathcal{D}\) is the set of _existing_ content items, and \(U_{\text{user}},U_{\text{creator}},U_{d}\) are the utility functions for users, creators, and distance, defined over the latent embedding space. That is, a content gap \(z\) should bring high utility to users and creators, while also meeting some latent demand (i.e., non-existing content). In Sec. 5 we explicitly formulate this utility for a behavioral latent embedding space trained over movie and user data.

\begin{table}
\begin{tabular}{l|l|l|l} \hline \hline \(\mathcal{X}\) & Ambient space (e.g., descriptions of movies) & \(d:\mathcal{X}\times\mathcal{X}\mapsto\mathbb{R}_{+}\) & Ambient metric \\ \(\mathcal{Z}\) & Latent embedding space & \(d_{\mathcal{Z}}:\mathcal{Z}\times\mathcal{Z}\mapsto\mathbb{R}_{+}\) & Latent metric \\ \(\mathcal{A}\) & Action space (e.g., changes to a movie plot) & \(U:\mathcal{Z}\times\mathcal{D}\mapsto\mathbb{R}_{+}\) & Utility function \\ \(n\) & Latent dimension & \(E_{D}:\mathcal{X}\mapsto\mathcal{Z}\) & Latent encoder \\ \(\mathcal{D}\) & Dataset of entities & \(\pi_{\text{ref}}:\mathcal{X}\mapsto\Delta_{\mathcal{A}}\) & Reference policy \\ \(H\) & Horizon & \(q:\mathcal{X}\mapsto\Delta_{\mathcal{A}}\) & reference policy distribution \\ \hline \hline \end{tabular}
\end{table}
Table 1: GlossaryOptimality Criterion.Given the dataset of entities \(\mathcal{D}=\left\{x_{i}\in\mathcal{X}\right\}_{i=1}^{N}\), embedding manifold \((\mathcal{Z},d_{\mathcal{Z}})\), a corresponding embedding function \(E_{D}:\mathcal{X}\mapsto\mathcal{Z}\), and a utility function \(U:\mathcal{Z}\times\mathcal{D}\mapsto\mathbb{R}\), our goal is to find a novel entity \(x^{*}\in\mathcal{X}\backslash\mathcal{D}\) such that

\[x^{*}\in\arg\max_{x\in\mathcal{X},x\notin\mathcal{D}}U(E_{D}(x);\mathcal{D}).\] (3)

We emphasize that, while optimality is defined in the _latent embedding_ space, our goal is to identify a novel entity \(x^{*}\) in the _ambient_ space \(\mathcal{X}\) (e.g., an image or description of the hypothetical). As such, it is not enough to search for an optimal point in \(\mathcal{Z}\). Moreover, the solution is not necessarily unique.

## 4 Surfacing Optimal Entities Using LLMs

We now turn to generation of novel entities in language space; that is, we assume \(\mathcal{X}\subseteq\mathcal{S}\) is a subset of the space of all language sequences (e.g., plots of movies, or descriptions of clothes). Nevertheless, our methods are applicable more broadly to other modalities including images, videos, audio, or even RL policies. In what follows we describe two methods of finding an optimal entity \(x^{*}\) in Eq. (3), using either ELMs or RL. A high-level illustration of these methods is shown in Fig. 1.

### Embedding Language Models (ELMs) as Decoders

ELMs (Sec. 2) offer an explicit method of finding an optimal entity \(x^{*}\in\mathcal{X}\). Indeed, if one can train a decoder \(f:\mathcal{Z}\mapsto\mathcal{X}\) which satisfies \(E_{D}(f(z))=z\), then \(x^{*}\) can be determined by maximizing \(z^{*}\in\arg\max_{z\in\mathcal{Z}}U(z;\mathcal{D})\) (i.e., identifying an optimal latent embedding w.r.t. \(U\)) and returning \(x^{*}=f(z^{*})\) (i.e., some entity corresponding to \(z^{*}\)). Such a decoder \(f\) can be trained using a fixed dataset and an ELM architecture (Tennenholtz et al., 2024).

However, this approach has major limitations. First, learning an ELM decoder \(f\) requires training an LLM to interpret embeddings, a costly process which may negatively impact the expressive power of the LLM. Second, the manifold \((\mathcal{Z},d_{\mathcal{Z}})\) can be highly complex and non-linear. Moreover, the latent space metric \(d_{\mathcal{Z}}\) may not be known. As such, a latent embedding \(z^{*}\) deemed optimal in latent

Figure 1: An illustration comparing the creation of descriptions of novel entities using ELM (Tennenholtz et al., 2024) vs. EAGLE (ours). The latent embedding space \(\mathcal{Z}\) is illustrated as a complex surface on the right. Red points on the surface are illustrated as latent embeddings of existing entities. Black points are used to illustrate hypothetical (i.e., non-existing) entities. In ELM, a utility is maximized _in latent embedding space_ to identify an optimal point. This hypothetical embedding is then decoded back to ambient space \(\mathcal{X}\) to form a description of the hypothetical entity. Conversely, the EAGLE agent utilizes a highly capable pre-trained LLM as an environment to search for novel entities in ambient space \(\mathcal{X}\). EAGLE does not use a decoder, but rather only requires an encoder \(E_{D}:\mathcal{X}\mapsto\mathcal{Z}\). More specifically, the EAGLE agent uses action prompts to change an existing entity using the environment LLM. Every new changed entity is then mapped back to the latent embedding space using the encoder \(E_{D}\). The utility function is optimized by the EAGLE agent through a reward signal to stir the changes to areas of high utility in the latent embedding space. A final description is then returned after \(H\) steps.

space, may be "off-manifold", and therefore not mapped to a valid entity \(x\in\mathcal{X}\). To mitigate this, one can choose to stay close to points in the data, using Euclidean distance to approximate \(d\)(Chen et al., 2019), or employing a pullback metric defined by a Riemannian manifold (Arvanitidis et al., 2018, 2021) (see Appendix B for further discussion). Finally, the embedding space \(\mathcal{Z}\) may not contain enough semantic information to ensure that \(f\) generalizes well (e.g., embeddings trained over behavioral interactions with items). Training a new embedding, e.g., using Variational Auto-Encoders (VAEs) (Yang et al., 2017) can mitigate this problem; yet, this would require training a new latent embedding, a challenging problem in its own right (Vahdat and Kautz, 2020). Furthermore, training a new latent representation may not be feasible (e.g., due to limited data). As such, using ELMs to train a decoder LLM over the embedding space may be impractical in many domains.

### A Reinforcement Learning Perspective

As an alternative to ELMs, we formulate the optimization directly in the ambient space \(\mathcal{X}\) (i.e., language space) using RL. Specifically, we leverage a highly capable pre-trained LLM (e.g., Gemini-Ultra (Team et al., 2023), or GPT-4 (Achiam et al., 2023)) to act as an _environment_ for our RL formulation. The environment LLM remains fixed, and is only used to generate new entities in \(\mathcal{X}\).

We formulate the problem using an MDP \((\mathcal{X},\mathcal{A},P,r,H)\), where \(\mathcal{X}\subseteq\mathcal{S}\) is the state space comprising of all possible entities (in language), \(\mathcal{A}\subset\mathcal{S}\) is an action space, defined by language prompts for a pre-trained environment LLM.5 The action prompts are used to modify or _steer_ an entity \(x\in\mathcal{X}\). We elaborate on these actions later in this section. The transition function, \(P:\mathcal{X}\times\mathcal{A}\mapsto\Delta_{\mathcal{X}}\) is induced by the environment LLM. Finally, the reward function is defined using the utility \(U\) such that \(r_{t}(x)=0\) for all \(t<H-1\), and \(r_{H-1}(x)=U(E_{D}(x);\mathcal{D})\).6 While we do not define it explicitly, the MDP can also be endowed with contextual information such as information about nearby entities, or a user for whom we wish to personalize creation.

Footnote 5: We use the term pre-trained LLM to refer to an already trained LLM such as a capable Gemini or GPT model. We do not refer here to the specific stage in LLM training known as “pre-training”.

Footnote 6: More generally, intermediate rewards can be provided at every iteration. We do not use such rewards here as we focus only on the final generated outcome.

At time \(t=0\) the process is initialized at an existing entity \(x_{i}\in\mathcal{D}\). For every \(t<H\), the agent sees state \(x_{t}\in\mathcal{X}\) and selects an action \(a_{t}\in\mathcal{A}\). The action is provided to the environment LLM as a language prompt, the environment LLM generates the next state \(x_{t+1}\in\mathcal{X}\), and the agent receives a reward \(r(x_{t})\). We assume the environment LLM generates states in \(\mathcal{X}\) (i.e., feasible states).

### Designing a State-Dependent Action Space

Designing an action space for an RL problem can be challenging (Guss et al., 2019; Kanervisto et al., 2020; Tennenholtz and Mannor, 2019). In our setting, actions are prompts used to change entities in \(\mathcal{X}\). As such, a good set of actions should be diverse and induce high utility states (entities).

**LLMs for Action Creation.** We exploit the generative power of LLMs to construct an exploratory set of actions for each state. Specifically, for each \(x\in\mathcal{X}\), an LLM is used to construct a set \(\mathcal{A}(x)\) of \(K\) actions. For example, we might prompt an LLM to generate \(100\) ways to change a plot of a movie, or the specification of an designed product. This ensures each existing \(x\in\mathcal{D}\) is associated with a diverse set of actions that can modify it. To ensure coverage, \(K\) must be large enough to adequately search the state space (see Sec. 7 and appendix C further discussion).

**Reference Policy and G-Optimal Design.** We use the (possibly large) set of actions to learn a reference policy for a PG algorithm (see Sec. 2), trained via supervised learning. Specifically, given the action space, we define a _reference_ policy \(\pi_{\text{ref}}(a|x)=q_{a}\) where \(q\in\Delta(\mathcal{A}(x))\).

We consider three choices for distribution \(q\): (1) uniform, i.e., \(q_{a}=\frac{1}{K}\); (2) myopic best next-step action, i.e., \(q_{a}=\mathds{1}\big{\{}a\in\operatorname*{arg\,max}\mathbb{E}_{x^{\prime} \sim P(\cdot|x,a)}[U(x^{\prime})]\big{\}}\); and (3) myopic _G-optimal design_, which is a distribution over actions that minimizes a form of worse-case variance (Atwood, 1969; Kiefer and Wolfowitz, 1960). We define it formally as follows.

**Definition 1** (G-optimal design).: _Let \(\mathcal{A}(x)\subseteq\mathcal{A}\) be given. Denote \(z_{a}(x)=\mathbb{E}_{x^{\prime}\sim P(\cdot|x,a)}[E_{D}(x^{\prime})]\). A distribution \(q(x)\in\Delta(\mathcal{A}(x))\) is a myopic G-optimal design with approximation factor \(C\geq 1\) if_

\[\sup_{a\in\mathcal{A}(x)}\left\|z_{a}(x)\right\|_{\Sigma(q(x))^{-1}}^{2}\leq Cn,\] (4)

_where \(\Sigma(q(x))=\mathbb{E}_{a\sim q(x)}\big{[}z_{a}(x)z_{a}^{T}(x)\big{]}\), and \(n\) is the dimension of the latent embedding space \(\mathcal{Z}\)._G-optimal designs have proven useful for contextual bandits with large action spaces, allowing one to achieve efficient regret guarantees with minimal assumptions (Zhu et al., 2022). Notably, an optimal design as a uniform \(\epsilon\)-exploration strategy has been shown to produce an efficient algorithm. We implement such exploration using a G-optimal design-based reference policy. A G-optimal design always exists whenever \(\left\{z_{a}(x)\right\}_{a\in A(x)}\) is compact, and \(C=1\)(Kiefer and Wolfowitz, 1960; Zhu et al., 2022). While it is generally NP-hard to compute (Grotschel et al., 2012), an approximate optimal design can be computed efficiently (Zhu et al., 2022) (see Appendix C for specific implementation details in our setup using uniform sampling).

### Embedding-Aligned Guided LanguageE (EAGLE) Agent

We are now ready to describe our approach, the Embedding-Aligned Guided LanguageE (EAGLE) agent, which is detailed in Algorithm 1. An illustration comparing EAGLE to ELM is depicted in Fig. 1. The EAGLE agent is trained using the pre-trained environment LLM. We first generate \(K\) actions using the dataset of existing entities \(\mathcal{D}\) and the pre-trained LLM. Then, using the encoder \(E_{D}:\mathcal{X}\mapsto\mathcal{Z}\), we create an approximate myopic G-optimal design \(q\) over these actions. We use the G-optimal design to train an initial reference policy \(\pi_{\text{ref}}\) to match the action distribution \(q\). Finally, we use \(\pi_{\text{ref}}\) as a reference policy for a PG algorithm, regularizing the loss as in Eq. (1). The PG algorithm is trained using the environment LLM and the encoder \(E_{D}\) to optimize a utility \(U\).

```
1:Input: Environment LLM, dataset \(\mathcal{D}\), reward function \(r\), encoder \(E_{D}\), PG algorithm PG-ALG
2: Generate \(K\) candidate actions using pre-trained environment LLM for every \(x\in\mathcal{D}\).
3: Compute an approximate myopic G-optimal design \(q(x)\) for every \(\mathcal{A}(x),x\in\mathcal{D}\) (Definition 1).
4: Train reference policy \(\pi_{\text{ref}}(\cdot|x)=q(x)\) over candidate action data and G-optimal design.
5: Train PG-ALG with reference policy \(\pi_{\text{ref}}\), pre-trained environment LLM, encoder \(E_{D}\), and reward \(r\). ```

**Algorithm 1** Embedding-Aligned Guided LanguageE (EAGLE) Agent

## 5 Experiment Design

We detail our experiment design; specifically, the data generation process, the training process, and our evaluation methods. Our work uses the MovieLens 25M dataset (Harper and Konstan, 2015), which contains 25 million ratings (1 to 5) of 62,423 movies and 162,541 users. We also conduct experiments on the Amazon review dataset (Ni et al., 2019), whose results are provided in Appendix I.

### Data Generation

**Latent Embeddings.** We create embeddings for both users and movies in the MovieLens dataset. We consider _behavioral embeddings_, trained solely using user ratings (i.e., no explicit semantic information) via _matrix factorization_ using _weighted alternating least squares_(Hu et al., 2008). A user \(u\)'s predicted rating for movie \(m\) is given by the dot product \(\left\langle z_{u},z_{m}\right\rangle\) of their embeddings.7

Footnote 7: Other collaborative filtering methods could be used, e.g., dual encoders (Yang et al., 2020; Yi et al., 2019), but our approach is agnostic to the precise method used to generate behavioral embeddings.

**State Space.** We generate textual descriptions of movies and users in the MovieLens dataset using Gemini Ultra (Team et al., 2023). For movies, we prompt Gemini to generate a plot for the movie, list five reasons someone might like the movie, and list five reasons they might dislike it (we refer to these as the _description_ of a movie). To describe a user \(u\), we provide Gemini with the list of movies \(u\) rated with their ratings, and prompt Gemini to create a textual _user profile_ describing the user's preferences using a structured template with the following categories: general, genre, director, and aesthetic preferences. Examples of generated movie descriptions, user profiles, and prompts are provided in Appendices D, F and H. To test the consistency of the generated profile for a user \(u\), we train an encoder to map it to \(u\)'s behavioral embedding (see Appendix D).

**Action Space.** We generate 100 candidate actions for each movie in the dataset. Specifically, we generate 50 generic actions and 50 personalized actions for every movie. We do this by prompting Gemini Ultra with the plot of the movie, and the list of reasons someone might like or dislike it,and ask it to generate 50 actionable ways in which to change the movie. Similarly, to generate personalized actions, we also provide Gemini with a textual user profile, and ask it to generate 50 changes that are personalized to that user. To increase action set diversity, we prompt the model to output actions in five categories: plot changes, character enhancements, visual and storytelling improvements, thematic exploration, and audience appeal adjustments. See Appendices C, F and H for the precise prompts and sample outputs.

Notice that we rely on an LLM's ability (in our case, Gemini Ultra) to generate diverse actions that suffice to explore the ambient space of movies. Other domains may require further considerations to ensure action space diversity (see further discussion of this limitation in Appendix B).

### Training

**Training Task.** We consider a specialized content gap task described in Sec. 3. We simplify somewhat by not accounting for creator utility, and only considering "local" content gaps around anchor items and specified users. We compute user utility for items in behavioral embedding space using dot products of user and movie embeddings, \(\langle z_{u},z_{m}\rangle\). We ensure the generated movie is, in fact, a content gap by also accounting for distance to existing movies; specifically, \(\ell_{2}\) distance (in embedding space) of the generated movie to its three nearest neighbors. Formally, given user \(u\) with embedding \(z_{u}\), and a target movie \(m\in\mathcal{D}\) with embedding \(z_{m}=E_{D}(m)\), our utility is defined by

\[U(z_{m};\mathcal{D}) =\langle z_{u},z_{m}\rangle+\lambda\sum_{m^{\prime}\in\text{NN}( m)}\left\|z_{m}-z_{m^{\prime}}\right\|,\] (Content Gap Utility)

where NN\((m)\) is the set of three nearest neighbors to \(m\) in \(\mathcal{D}\) (w.r.t. \(\ell_{2}\) distance in \(\mathcal{Z}\)), and \(\lambda>0\).

**Encoder.** We fine-tune a Gemini Nano-2 LLM (3.25B parameters) [Team et al., 2023] to serve as a movie encoder \(E_{D}\). We train it using \(\ell_{2}\) regression loss to map movie descriptions (plot, reasons to like, and reasons to dislike) to their behavioral embeddings. We use \(E_{D}\) to compute the utility \(U\).

**Reference Policy.** We use Gemini Nano-2 to initialize a reference policy \(\pi_{\text{ref}}\). We fine-tune the model using next-token prediction (cross-entropy loss) of actions as targets. We create three reference policies: _(a) Uniform:_ We use the full set of 100 generated actions for each movie as targets. _(b) Best next-step action:_ We first create transitions for each action in the dataset. Specifically, we use Gemini Ultra to act as an environment, and prompt it with each action to generate a new movie (plot and reasons to like or dislike). The new movie is then encoded using \(E_{D}\), and its utility computed. Finally, we create a dataset of the "best" actions based on the computed scores. _(c) Approximate G-optimal design:_ We calculate the next step embeddings for each action, as before. We then select ten actions which are a solution to Eq. (4). The new dataset consists of ten "exploratory" actions per movie, which we use to train a reference policy via supervised learning, as before. We refer to Appendix C for details on computing the optimal design.

**RL Training.** We use Gemini Ultra as our environment LLM. It is prompted to generate a transition given the current movie description and the agent action (see Appendix F for a review of all prompts). We inject randomness by increasing the sampling temperature of the agent model and the environment LLM. Specific hyperparameters are given in Appendix E.

### Evaluation Methods

We employ two evaluation methods; namely, raw utility scores and human feedback, comparing EAGLE-generated outputs with their initial anchors. We use a pool of 124 human raters to provide feedback on our generated results.8 Raters are shown a textual user profile together with descriptions of two movies: a ground truth (real) movie, and a variant generated using \(H=5\) steps of agent changes. Importantly, the two descriptions are ordered randomly, and raters do not know which is the original or generated variant.

Footnote 8: Raters were paid contractors. They received their standard contracted wage, which is above the living wage in their country of employment.

We quantify each rater's personal preferences by having them rate 10-20 movies from a set of 600 popular movies, and ask them to write a textual profile of their own preferences. To increase confidence in our human evaluation, raters evaluate each algorithm twice, once w.r.t. a textual user profile of a user _from the MovieLens dataset_, and again w.r.t. _their own_ preference profile. Each rater is asked a series of questions to quantify: (1) _User Utility_, the quality of the generated movie w.r.t. a user profile; (2) _Rater Utility_, its quality w.r.t. their personal preferences; and (3) _Distance Score_, the distance of the generated movie from the anchor (i.e., the rater scores how different the two movies are). We express our results as the percentage of raters who preferred the generated result to the original (values in \([0,1]\)). See Appendix G for a complete overview of rater questions.

## 6 Experiments

Table 2 compares results of ELM, supervised training (i.e., the reference policy), and EAGLE (ours) using the three reference action distributions (see Secs. 4.3 and 5.2). Specific hyperparameters are detailed in Appendix E. We train ELM to map behavioral embeddings of existing movies to their descriptions. Given an input movie embedding, we search for a nearby embedding point with optimal utility, and use ELM as a decoder to produce its description. We see that EAGLE outperforms ELM by a large margin w.r.t. both user and rater utility. This suggests a limitation in the generalization capability of ELM, and a fundamental problem of moving "out of manifold" when searching for an optimal point in embedding space. We discuss this further in Appendix B. Despite this, raters judge ELM to generate movie descriptions that are further from (more different than) the anchor.

The reference policy performs best with optimistic actions (i.e., max next-step utility). Interestingly, even the randomized policies--uniform and G-optimal design--perform well. We believe this is due to the choice of action space, which includes many personalized actions, providing a strong initialization for the randomized policies. Moreover, EAGLE performs better with a G-optimal design baseline than with the uniform or optimistic action baselines. This suggests that G-optimal design helps search the state space more efficiently. This is also evident in the distance score, which increases with the use of G-optimal design.

**Environment Transfer.** Table 3 compares results for different training/inference setups to test transfer effectiveness. Specifically, we compare training with Gemini-Pro or Gemini-Ultra models, and testing (i.e., inference) with Gemini-Ultra or GPT-4 models. All results use EAGLE with a G-optimal design baseline. Our results suggest that a Gemini-Pro training environment suffices to obtain high-quality inference results, as training with Gemini-Ultra did not improve performance.

\begin{table}
\begin{tabular}{l|c|c c c} \hline \hline \multirow{2}{*}{Experiment} & \multicolumn{1}{c|}{Utility} & \multicolumn{3}{c}{Human Rater Evaluation} \\ \cline{2-5}  & \(U(z)\) & \begin{tabular}{c} User \\ Utility \\ \end{tabular} & \begin{tabular}{c} Rater \\ Utility \\ \end{tabular} & \begin{tabular}{c} Distance \\ Score \\ \end{tabular} \\ \hline ELM [2024] & 0.57 & 0.31 & 0.37 & **0.52** \\ \cline{2-5}  & \begin{tabular}{c} Uniform \\ Optimistic Action \\ G-Optimal Design \\ \end{tabular} & 0.49 \(\pm\) 0.02 & 0.59 & 0.62 & 0.44 \\ \cline{2-5}  & \begin{tabular}{c} Optimistic Action \\ G-Optimal Design \\ \end{tabular} & 0.58 \(\pm\) 0.02 & 0.62 & 0.6 & 0.34 \\ \cline{2-5}  & \begin{tabular}{c} Optimistic Action \\ G-Optimal Design \\ \end{tabular} & 0.51 \(\pm\) 0.02 & 0.51 & 0.67 & 0.45 \\ \cline{2-5}  & \begin{tabular}{c} Uniform \\ Optimistic Action \\ G-Optimal Design \\ \end{tabular} & 0.65 \(\pm\) 0.03 & 0.69 & 0.64 & 0.43 \\ \cline{2-5}  & \begin{tabular}{c} Optimistic Action \\ G-Optimal Design \\ \end{tabular} & 0.69 \(\pm\) 0.04 & 0.71 & 0.69 & 0.25 \\ \cline{2-5}  & 
\begin{tabular}{c} Optimistic Action \\ G-Optimal Design \\ \end{tabular} & 0.74 \(\pm\) 0.03 & **0.76** & **0.74** & 0.47 \\ \hline \hline \end{tabular}
\end{table}
Table 2: Comparison of ELM, supervised training, and EAGLE. We test three distribution of reference policies: uniform (i.e., random), optimistic (i.e., next-step best action), and G-optimal design (Definition 1).

\begin{table}
\begin{tabular}{l|c|c c c} \hline \hline \multirow{2}{*}{Experiment} & \multicolumn{1}{c|}{Utility} & \multicolumn{3}{c}{Human Rater Evaluation} \\ \cline{2-5}  & \(U(z)\) & \begin{tabular}{c} User \\ Utility \\ \end{tabular} & \begin{tabular}{c} Rater \\ Utility \\ \end{tabular} & 
\begin{tabular}{c} Distance \\ Score \\ \end{tabular} \\ \hline Gemini Pro \(\rightarrow\) Ultra & 0.75 \(\pm\) 0.03 & 0.76 & 0.74 & **0.47** \\ Gemini Ultra \(\rightarrow\) Ultra & **0.8 \(\pm\) 0.02** & 0.74 & 0.66 & **0.47** \\ Gemini Pro \(\rightarrow\) GPT-4 & 0.65 \(\pm\) 0.02 & **0.86** & **0.78** & **0.45** \\ \hline \hline \end{tabular}
\end{table}
Table 3: For \(\mathtt{EnvTrain}\in\{\text{Gemini Pro, Gemini Ultra}\}\) and \(\mathtt{EnvTest}\in\{\text{Gemini Ultra},\text{GPT-4}\}\), the experiment \(\mathtt{EnvTrain}\)\(\rightarrow\)EnvTest shows results for training EAGLE on \(\mathtt{EnvTrain}\) and testing it on \(\mathtt{EnvTest}\). All experiments use an EAGLE based on Gemini-Nano and a G-optimal design baseline.

Interestingly, a trained EAGLE agent tested on a fixed GPT-4 environment maintains (and sometimes increases) its level of performance, suggesting that EAGLE is robust to the LLM environment on which it acts. More broadly, it seems that one can train an EAGLE agent using any suitably capable LLM, and then apply it successfully in environments defined by different LLMs.

**Action Space.** We test the effect of changing the resolution and personalization of the action space on an EAGLE agent with a G-optimal design baseline in Table 4. We first test the effect of making personalized actions unavailable. As expected, we see significant degradation in performance, suggesting personalized actions are critical to performance.

Second, we construct a _macro-action space_ comprising tuples \((a_{1},a_{2},a_{3},a_{4},a_{5})\) of five consecutive actions. Thus, instead of making a single change to a movie at each step, the environment LLM makes five changes at once (i.e., \(H=1\)). We evaluate the macro action space by executing the five actions chosen by the trained EAGLE agent on the default action space, at once. We also construct a _combined action space_, that _adds_ macro-actions to the original action space (rather than replacing it). We see that macro-actions degrade performance w.r.t. the original finer-grained changes, suggesting the LLM performs better when making smaller changes. We also find the combined action space significantly outperforms other baselines, suggesting value to equipping the agent with both low and high resolution actions in a sequential setup.

**EAGLE on Highly Rated Movies.** Finally, we assess the conditional performance of the EAGLE agent over movies that are originally rated high. We find that, while EAGLE improves overall scores of anchor movies that are originally rated poorly (i.e., scores \(1,2,3\)), it does not perform as well on movies that are rated highly (e.g., scores \(4,5\)), sometimes even decreasing user utility. Specifically, conditioned on poorly rated movies, EAGLE achieves an average utility of \(0.7\pm 0.04\) (an approximate \(30\%\) increase), whereas for highly rated movies, it achieves an average utility of \(0.83\pm 0.03\) (an approximate \(5\%\) decrease). This result is expected as MovieLens rating data is limited to ratings between \(1\) and \(5\), where a rating of \(5\) is (perhaps, incorrectly) assumed to be optimal for the user. To address this, we might only suggest or create a new entity if it has a higher utility than its anchor.

## 7 Creative Generation: Discussion and Limitations

ELM vs. EAGLE.Our work reveals two distinct methodologies for generating novel entities that adhere to an underlying embedding space: using ELMs as decoders and our proposed EAGLE agent. While ELM offers efficient optimization within the embedding space and, in theory, can reach an unconstrained optimal point, it faces challenges related to the computational cost of fine-tuning the decoder, unknown generalization errors, and difficulties in constraining optimization due to the unknown manifold metric. Conversely, EAGLE leverages the existing textual capabilities of LLMs, enabling more interpretable optimization and potentially requiring a smaller agent model. However, EAGLE's coverage is inherently limited by the defined action space, and training can be computationally expensive due to its reliance on LLM environment queries. We refer the reader to Appendix B for further discussion on these tradeoffs.

Action Space Design.A principal building block of EAGLE is defining and / or designing an action space to change entities in \(\mathcal{X}\). Designing a good action space is critical to ensure reachability

\begin{table}
\begin{tabular}{l|c|c c c} \hline \hline \multirow{2}{*}{Experiment} & Utility & \multicolumn{3}{c}{Human Rater Evaluation} \\ \cline{2-5}  & \(U(z)\) & User Utility & Rater Utility & Distance Score \\ \hline Default Actions & **0.75 \(\pm\) 0.03** & 0.76 & 0.74 & **0.47** \\ Without Personalized & 0.56 \(\pm\) 0.02 & 0.54 & 0.59 & **0.45** \\ Macro Actions & 0.71 \(\pm\) 0.02 & 0.67 & 0.7 & 0.32 \\ Combined Actions & **0.74 \(\pm\) 0.04** & **0.88** & **0.92** & 0.4 \\ \hline \hline \end{tabular}
\end{table}
Table 4: The effect of changing the action space on EAGLE, showing (1) the default action space as described in Sec. 5, (2) the default action space with personalized actions removed, (3) only macro actions (i.e., taking three actions at once), and (4) a combined action space, with both the default actions as well as macro actions. All experiments use a G-optimal design strategy as reference policy.

of an optimal novel entity. In this work we define a methodology for designing such an action space using LLMs and G-optimal design (Definition 1).

Fig. 2 illustrates three examples of potential action spaces and their inherent bias in embedding space. Informally, an action space may allow for "better" coverage if it can induce changes in all direction on the embedding manifold \(\mathcal{Z}\). More generally, an action space should allow one to reach any point on the embedding manifold (up to some ball of radius \(\epsilon\)) in at most \(H\) iterations, starting from any point \(z=E_{D}(x)\) such that \(x\in\mathcal{D}\). Indeed, as we illustrate in Fig. 2, our action space may be constrained to certain directions, thereby limiting our ability to cover the full span of possible entities.

To increase the overall coverage of an action space one can take one of several measures, including: (1) generating a large amount of candidate actions, (2) using experts to enhance the action space with additional missing actions, or (3) changing the methods used to generate those actions (e.g., using different prompting strategies). While all of these methods could potentially increase the coverage of the action space, none of them would guarantee coverage of the embedding space. In fact, it may be that _no action exists_ that would allow one to move in any direction of the embedding space. That is, the environment LLM is incapable of moving in a specific embedding direction (i.e., an embedding direction cannot be mapped into an actionable text prompt). This is a particular disadvantage of EAGLE, and an advantage of ELM, as ELM is not constrained by movements in embedding space (see Appendix B).

Apart from the coverage challenge of designing an action space, we also consider the bias of such an action space. If an action space is biased, then a randomized policy executing those actions uniformly would be biased as well. To mitigate this bias effect we use a G-optimal design. The G-optimal design allows us to identify a set of \(k\) actions that would be best for exploring the action space in terms of overall utility, thereby mitigating the inherent bias for exploration.

## 8 Conclusion

This paper introduces EAGLE, a novel framework that leverages RL to align LLM generation with domain-specific objectives encoded in latent embedding spaces. Treating a pre-trained LLM as an environment, EAGLE iteratively steers its output towards optimal regions of the embedding space based on a predefined criterion. Our experiments on the MovieLens 25M dataset demonstrate the effectiveness of EAGLE in surfacing content gaps, hypothetical content items that satisfy latent user demand. The results highlight the benefit of incorporating a state-dependent action set based on G-optimal design for enhanced efficiency. EAGLE's capacity to leverage the power of large pre-trained LLMs without requiring explicit decoders opens up new possibilities for controlled and grounded text generation, ensuring consistency with domain knowledge and data representations.

Further research directions include: exploring different action space design methodologies beyond G-optimal design, generalizing EAGLE to diverse modalities like images, audio, and video, and applying EAGLE to other applications that require aligning LLM generation with specific domain knowledge or constraints. EAGLE's flexible framework holds promise for various tasks, including personalized content creation, targeted advertising, and controlled dialogue generation.

Figure 2: An illustration of different forms of coverage and bias of an action space. As actions are textual prompts, their corresponding embedding directions may either provide good coverage, or partial coverage of the underlying embedding manifold (e.g., there may be directions that are not covered by the generated actions). Moreover, actions may be uniformly biased toward specific directions. We accommodate for this using a G-optimal design which reduces this bias through a set of exploratory actions in embedding space.

## References

* Achiam et al. (2023) Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. _arXiv preprint arXiv:2303.08774_, 2023.
* Arvanitidis et al. (2018) Georgios Arvanitidis, Lars Kai Hansen, and Soren Hauberg. Latent space oddity: on the curvature of deep generative models. In _International Conference on Learning Representations_, 2018.
* Arvanitidis et al. (2021) Georgios Arvanitidis, Soren Hauberg, and Bernhard Scholkopf. Geometrically enriched latent spaces. In _International Conference on Artificial Intelligence and Statistics_, pages 631-639. PMLR, 2021.
* Atwood (1969) Corwin L Atwood. Optimal and efficient designs of experiments. _The Annals of Mathematical Statistics_, pages 1570-1602, 1969.
* Bakker et al. (2022) Michiel Bakker, Martin Chadwick, Hannah Sheahan, Michael Tessler, Lucy Campbell-Gillingham, Jan Balaguer, Nat McAleese, Amelia Glaese, John Aslanides, Matt Botvinick, et al. Fine-tuning language models to find agreement among humans with diverse preferences. _Advances in Neural Information Processing Systems_, 35:38176-38189, 2022.
* Bao et al. (2016) Junwei Bao, Nan Duan, Zhao Yan, Ming Zhou, and Tiejun Zhao. Constraint-based question answering with knowledge graph. In _Proceedings of COLING 2016, the 26th international conference on computational linguistics: technical papers_, pages 2503-2514, 2016.
* Boutilier et al. (2024) Craig Boutilier, Martin Mladenov, and Guy Tennenholtz. Recommender ecosystems: A mechanism design perspective on holistic modeling and optimization. _Proceedings of the AAAI Conference on Artificial Intelligence_, 38(20):22575-22583, Mar. 2024. doi: 10.1609/aaai.v38i20.30266. URL https://ojs.aaai.org/index.php/AAAI/article/view/30266.
* Chen et al. (2019) Nutan Chen, Francesco Ferroni, Alexej Klushyn, Alexandros Paraschos, Justin Bayer, and Patrick van der Smagt. Fast approximate geodesics for deep generative models. In _International Conference on Artificial Neural Networks_, pages 554-566, 2019.
* Dhuliawala et al. (2023) Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu, Roberta Raileanu, Xian Li, Asli Celikyilmaz, and Jason Weston. Chain-of-verification reduces hallucination in large language models. _arXiv preprint arXiv:2309.11495_, 2023.
* Frazer et al. (2021) Jonathan Frazer, Pascal Notin, Mafalda Dias, Aidan Gomez, Joseph K Min, Kelly Brock, Yarin Gal, and Debora S Marks. Disease variant prediction with deep generative models of evolutionary data. _Nature_, 599(7883):91-95, 2021.
* Girdhar et al. (2023) Rohit Girdhar, Alaaeldin El-Nouby, Zhuang Liu, Mannat Singh, Kalyan Vasudev Alwala, Armand Joulin, and Ishan Misra. Imagebind: One embedding space to bind them all. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pages 15180-15190, 2023.
* Gomez-Bombarelli et al. (2018) Rafael Gomez-Bombarelli, Jennifer N Wei, David Duvenaud, Jose Miguel Hernandez-Lobato, Benjamin Sanchez-Lengeling, Dennis Sheberla, Jorge Aguilera-Iparraguirre, Timothy D Hirzel, Ryan P Adams, and Alan Aspuru-Guzik. Automatic chemical design using a data-driven continuous representation of molecules. _ACS central science_, 4(2):268-276, 2018.
* Grotschel et al. (2012) Martin Grotschel, Laszlo Lovasz, and Alexander Schrijver. _Geometric algorithms and combinatorial optimization_, volume 2. Springer Science & Business Media, 2012.
* Gunjal et al. (2024) Anisha Gunjal, Jihan Yin, and Erhan Bas. Detecting and preventing hallucinations in large vision language models. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 38, pages 18135-18143, 2024.
* Guss et al. (2019) William H Guss, Brandon Houghton, Nicholay Topin, Phillip Wang, Cayden Codel, Manuela Veloso, and Ruslan Salakhutdinov. Minerl: A large-scale dataset of minecraft demonstrations. _arXiv preprint arXiv:1907.13440_, 2019.
* Hansen et al. (2020) Casper Hansen, Christian Hansen, Lucas Maystre, Rishabh Mehrotra, Brian Brost, Federico Tomasi, and Mounia Lalmas. Contextual and sequential user embeddings for large-scale music recommendation. In _Proceedings of the 14th ACM Conference on Recommender Systems_, pages 53-62, 2020.
* Hovy et al. (2019)F Maxwell Harper and Joseph A Konstan. The movielens datasets: History and context. _Acm transactions on interactive intelligent systems (tiis)_, 5(4):1-19, 2015.
* Ho et al. (2020) Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. _Advances in neural information processing systems_, 33:6840-6851, 2020.
* Ho et al. (2022) Jonathan Ho, Tim Salimans, Alexey Gritsenko, William Chan, Mohammad Norouzi, and David J Fleet. Video diffusion models. _Advances in Neural Information Processing Systems_, 35:8633-8646, 2022.
* Hu et al. (2008) Yifan Hu, Yehuda Koren, and Chris Volinsky. Collaborative filtering for implicit feedback datasets. In _Proceedings of the 8th IEEE International Conference on Data Mining (ICDM 2008), December 15-19, 2008, Pisa, Italy_, pages 263-272, 2008.
* Jeong et al. (2023) Jihwan Jeong, Yinlam Chow, Guy Tennenholtz, Chih-Wei Hsu, Azamat Tulepbergenov, Mohammad Ghavamzadeh, and Craig Boutilier. Factual and personalized recommendations using language models and reinforcement learning. _arXiv preprint arXiv:2310.06176_, 2023.
* Ji et al. (2024) Jiaming Ji, Mickel Liu, Josef Dai, Xuehai Pan, Chi Zhang, Ce Bian, Boyuan Chen, Ruiyang Sun, Yizhou Wang, and Yaodong Yang. Beavertails: Towards improved safety alignment of llm via a human-preference dataset. _Advances in Neural Information Processing Systems_, 36, 2024.
* Kanervisto et al. (2020) Anssi Kanervisto, Christian Scheller, and Ville Hautamaki. Action space shaping in deep reinforcement learning. In _2020 IEEE conference on games (CoG)_, pages 479-486. IEEE, 2020.
* Keshtkaran and Pandarinath (2019) Mohammad Reza Keshtkaran and Chethan Pandarinath. Enabling hyperparameter optimization in sequential autoencoders for spiking neural data. _Advances in neural information processing systems_, 32, 2019.
* Kiefer and Wolfowitz (1960) Jack Kiefer and Jacob Wolfowitz. The equivalence of two extremum problems. _Canadian Journal of Mathematics_, 12:363-366, 1960.
* Kingma et al. (2014) Durk P Kingma, Shakir Mohamed, Danilo Jimenez Rezende, and Max Welling. Semi-supervised learning with deep generative models. _Advances in neural information processing systems_, 27, 2014.
* Lee et al. (2023) Harrison Lee, Samrat Phatale, Hassan Mansoor, Kellie Lu, Thomas Mesnard, Colton Bishop, Victor Carbune, and Abhinav Rastogi. Rlaf: Scaling reinforcement learning from human feedback with ai feedback. _arXiv preprint arXiv:2309.00267_, 2023.
* Li et al. (2023) Junyi Li, Xiaoxue Cheng, Wayne Xin Zhao, Jian-Yun Nie, and Ji-Rong Wen. Halueval: A large-scale hallucination evaluation benchmark for large language models. In _Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing_, pages 6449-6464, 2023.
* Liang et al. (2018) Dawen Liang, Rahul G Krishnan, Matthew D Hoffman, and Tony Jebara. Variational autoencoders for collaborative filtering. In _Proceedings of the 2018 world wide web conference_, pages 689-698, 2018.
* Nabati et al. (2023) Ofir Nabati, Guy Tennenholtz, and Shie Mannor. Representation-driven reinforcement learning. In _International Conference on Machine Learning_, pages 25588-25603. PMLR, 2023.
* Ni et al. (2019) Jianmo Ni, Jiacheng Li, and Julian McAuley. Justifying recommendations using distantly-labeled reviews and fine-grained aspects. In _Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019_, pages 188-197, 2019.
* Oord et al. (2018) Aaron van den Oord, Yazhe Li, and Oriol Vinyals. Representation learning with contrastive predictive coding. _arXiv preprint arXiv:1807.03748_, 2018.
* Ouyang et al. (2022) Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with human feedback. _Advances in neural information processing systems_, 35:27730-27744, 2022.
* Ouyang et al. (2019)Karl Pertsch, Youngwoon Lee, and Joseph Lim. Accelerating reinforcement learning with learned skill priors. In _Conference on robot learning_, pages 188-204. PMLR, 2021.
* Radford et al. (2021) Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In _International conference on machine learning_, pages 8748-8763. PMLR, 2021.
* Rampasek et al. (2019) Ladislav Rampasek, Daniel Hidru, Petr Smirnov, Benjamin Haibe-Kains, and Anna Goldenberg. Dr. vae: improving drug response prediction via modeling of drug perturbation effects. _Bioinformatics_, 35(19):3743-3751, 2019.
* Ravanbakhsh et al. (2017) Siamak Ravanbakhsh, Francois Lanusse, Rachel Mandelbaum, Jeff Schneider, and Barnabas Poczos. Enabling dark energy science with deep generative models of galaxy images. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 31, 2017.
* Schulman et al. (2017) John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy optimization algorithms. _arXiv preprint arXiv:1707.06347_, 2017.
* Sutton et al. (1999) Richard S Sutton, David McAllester, Satinder Singh, and Yishay Mansour. Policy gradient methods for reinforcement learning with function approximation. _Advances in neural information processing systems_, 12, 1999.
* Harikandeh et al. (2023) Seyyed Reza Taher Harikandeh, Sadegh Aliakbary, and Sorous Taheri. An embedding approach for analyzing the evolution of research topics with a case study on computer science subdomains. _Scientometrics_, 128(3):1567-1582, 2023.
* Team et al. (2023) Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, et al. Gemini: a family of highly capable multimodal models. _arXiv preprint arXiv:2312.11805_, 2023.
* Tennenholtz and Mannor (2019) Guy Tennenholtz and Shie Mannor. The natural language of actions. In _International Conference on Machine Learning_, pages 6196-6205. PMLR, 2019.
* Tennenholtz and Mannor (2022) Guy Tennenholtz and Shie Mannor. Uncertainty estimation using riemannian model dynamics for offline reinforcement learning. _Advances in Neural Information Processing Systems_, 35:19008-19021, 2022.
* Tennenholtz et al. (2024) Guy Tennenholtz, Yinlam Chow, ChihWei Hsu, Jihwan Jeong, Lior Shani, Azamat Tulepbergenov, Deepak Ramachandran, Martin Mladenov, and Craig Boutilier. Demystifying embedding spaces using large language models. In _The Twelfth International Conference on Learning Representations_, 2024. URL https://openreview.net/forum?id=qqYogk1Pz.
* Thadani et al. (2023) Nicole N Thadani, Sarah Gurev, Pascal Notin, Noor Youssef, Nathan J Rollins, Daniel Ritter, Chris Sander, Yarin Gal, and Debora S Marks. Learning from prepandemic data to forecast viral escape. _Nature_, 622(7984):818-825, 2023.
* Touvron et al. (2023) Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. _arXiv preprint arXiv:2307.09288_, 2023.
* Vahdat and Kautz (2020) Arash Vahdat and Jan Kautz. Nvae: a deep hierarchical variational autoencoder. In _Proceedings of the 34th International Conference on Neural Information Processing Systems_, pages 19667-19679, 2020.
* Vaswani et al. (2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. _Advances in neural information processing systems_, 30, 2017.
* Wang et al. (2024) Jiashuo Wang, Haozhao Wang, Shichao Sun, and Wenjie Li. Aligning language models with human preferences via a bayesian approach. _Advances in Neural Information Processing Systems_, 36, 2024.
* Wang et al. (2018)Ji Yang, Xinyang Yi, Derek Zhiyuan Cheng, Lichan Hong, Yang Li, Simon Xiaoming Wang, Taibai Xu, and Ed H Chi. Mixed negative sampling for learning two-tower neural networks in recommendations. In _Proceedings of the Web Conference (WWW-20)_, pages 441-447, Taipei, 2020.
* Yang et al. (2021) Tsung-Yen Yang, Michael Y Hu, Yinlam Chow, Peter J Ramadge, and Karthik Narasimhan. Safe reinforcement learning with natural language constraints. _Advances in Neural Information Processing Systems_, 34:13794-13808, 2021.
* Yang et al. (2017) Zichao Yang, Zhiting Hu, Ruslan Salakhutdinov, and Taylor Berg-Kirkpatrick. Improved variational autoencoders for text modeling using dilated convolutions. In _International conference on machine learning_, pages 3881-3890. PMLR, 2017.
* Yi et al. (2019) Xinyang Yi, Ji Yang, Lichan Hong, Derek Zhiyuan Cheng, Lukasz Heldt, Aditee Kumthekar, Zhe Zhao, Li Wei, and Ed Chi. Sampling-bias-corrected neural modeling for large corpus item recommendations. In _Proceedings of the Thirteenth ACM Conference on Recommender Systems (RecSys19)_, pages 269-277, Copenhagen, 2019.
* Zhao et al. (2023) Xiangyu Zhao, Maolin Wang, Xinjian Zhao, Jiansheng Li, Shucheng Zhou, Dawei Yin, Qing Li, Jiliang Tang, and Ruocheng Guo. Embedding in recommender systems: A survey. _arXiv preprint arXiv:2310.18608_, 2023.
* Zhu et al. (2022) Yinglun Zhu, Dylan J Foster, John Langford, and Paul Mineiro. Contextual bandits with large action spaces: Made practical. In _International Conference on Machine Learning_, pages 27428-27453. PMLR, 2022.
* Ziegler et al. (2019) Daniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B Brown, Alec Radford, Dario Amodei, Paul Christiano, and Geoffrey Irving. Fine-tuning language models from human preferences. _arXiv preprint arXiv:1909.08593_, 2019.

Societal Impact

EAGLE, a tool capable of creating new content based on latent preferences, presents several societal implications. On one hand, EAGLE can enhance creativity and innovation by assisting content creators in exploring new ideas and generating novel content tailored to specific audiences. This can stimulate creative industries and lead to the development of more diverse and engaging content. Additionally, by identifying and surfacing content gaps, EAGLE can help address unmet needs and preferences within online platforms, leading to a more inclusive and satisfying user experience. Furthermore, EAGLE facilitates the generation of personalized content tailored to individual users, potentially improving engagement and satisfaction.

However, the technology also carries potential risks. If trained on biased data, EAGLE could amplify existing societal biases and reinforce echo chambers, limiting exposure to diverse perspectives. The ability to tailor content to latent preferences could also be misused to manipulate user behavior, leading to unintended consequences.

Mitigating these risks requires a multi-faceted approach. Ensuring data diversity and fairness during training is crucial to mitigate bias and promote inclusivity. Developing methods to make EAGLE's decision-making process transparent can help address concerns about manipulation and promote user trust. Finally, integrating fact-checking mechanisms and robust content moderation strategies can help prevent the spread of misinformation.

Developing and deploying EAGLE demands careful consideration of its potential societal impacts. Proactive measures to mitigate risks and promote responsible use are crucial to harnessing its potential benefits while minimizing potential harm.

## Appendix B ELM or EAGLE: Trade-Offs and Limitations

As discussed in Sec. 4, ELM and EAGLE can be viewed as alternative approaches for solving similar problems involving embedding spaces. Particularly, when we care about generating entities which adhere to some underlying embedding space. While ELM assumes the existence of a decoder \(f:\mathcal{Z}\mapsto\mathcal{X}\), EAGLE only requires access to an encoder \(E_{D}\) to assess the quality of any \(x\in\mathcal{X}\). Nevertheless, as we ultimately care about generating non-existing entities \(x\notin\mathcal{D}\), we must ask ourselves - how do we find an optimal \(x\) in a generalizable and robust manner. Below, we enumerate several of the trade-offs of using ELMs and EAGLE to solve this problem, focusing on three points: computational efficiency, realizability, and coverage. We summarize these trade-offs in Appendix B.

**Computational Efficiency.** When considering computational efficiency of ELM compared to EAGLE we account for training efficiency, inference efficiency, as well as the computational requirement to retrain the model over time (due to e.g., evolving data and metrics).

We find that ELM generally requires fine-tuning a much larger model than the EAGLE agent. Particularly, ELM should be capable of generating a full description of any embedding point in \(\mathcal{Z}\). This would potentially require training / fine-tuning a high capacity model. On the other hand, EAGLE requires generating action prompts, which are shorter in nature, and, as we find, can use much smaller models. Still, during training, EAGLE requires querying an environment LLM, which potentially uses many computational resources. Moreover, in our work we use 16 environment LLMs simultaneously to train the EAGLE agent, requiring extensive compute during training. That said, the environment LLM can in practice be an API call to a service which, unlike ELM, does not require serving an LLM in-house.

Finally, we note that ELM is more sensitive to changes in the dataset and metrics. As we see in Table 3, EAGLE is robust to changes in the environment LLM. More broadly, as EAGLE uses action prompts to change existing entities, much of the underlying "ground work" is done by the environment LLM. Therefore, if the dataset and metric were to change, e.g., one would want to also personalize outputs to specific creators, add more context to the generation, or perhaps generate other attributes of the hypothetical entities, then EAGLE would merely need to change the prompt of the environment LLM, whereas ELM would require retraining the model over new data to account for these changes.

The computational aspect of using ELM vs. EAGLE thus depends on the use case, the availability of resources to train LLMs (or using API calls), and the evolution of the underlying dataset and metrics.

**Realizability.** A critical aspect when comparing ELM to EAGLE is the realizability of the underlying embedding manifold. Even if ELM manages to learn a perfect decoder \(f:\mathcal{Z}\mapsto\mathcal{X}\), there remains the question of identifying an optimal point \(z\in\mathcal{Z}\) to decode. As we only have embedding points of real entities \(x\in\mathcal{D}\), extrapolating to non-existing entities requires moving on the embedding manifold \(\mathcal{Z}\), which is generally unknown. If we were to simply search for a point \(z\in\mathcal{R}^{n}\) which maximizes utility, we may return a point that does not correspond to a real entity, and thus decoding would not be feasible. Moreover, when as decoder is trained on existing entity data \(\mathcal{D}\), one must also account for generalization errors when attempting to move out of distribution.

v We propose two solution to account for this problem when using ELMs. The first, is to constrain the search in embedding space to be close to points in the data, that is, balls of radius epsilon around all embedding points in \(\mathcal{D}\):

\[\bigcup_{x\in\mathcal{D}}B_{\epsilon}(E_{D}(x)).\]

This solution allows one to confidently remain on manifold, with good generalization capabilities, while still optimizing for better content. Nevertheless, it may still be limited, as certain areas of the embedding space may be easier to decode than others.

Another approach to search over the manifold \((\mathcal{Z},d_{\mathcal{Z}})\) is to use the geometry of a generative model (Arvanitidis et al., 2018, 2021) and estimate the metric \(d_{\mathcal{Z}}\). Particularly, assuming the embedding space was trained by a stochastic generative model (such as a VAE), one can use the pull-back metric (defined by the decoder Jacobian) to define the geometry of the latent space. Specifically, for VAEs with a decoder of the form \(f(z)=\mu(z)+\sigma(z)\cdot\epsilon\), such that \(\mu:\mathcal{Z}\mapsto\mathcal{X},\sigma:\mathcal{Z}\mapsto\mathbb{R}_{+}^{ \mathcal{X}},\epsilon\sim\mathcal{N}(0,I)\), this induces a Reimannian sub-manifold, with an expected metric

\[\mathbb{E}[M_{z}]=\Big{(}J_{z}^{(\mu)}\Big{)}^{T}\Big{(}J_{z}^{(\mu)}\Big{)}+ \Big{(}J_{z}^{(\sigma)}\Big{)}^{T}\Big{(}J_{z}^{(\sigma)}\Big{)}.\]

This has been shown to produce improved interpolations of embeddings, which better align with the underlying geodesics of the manifold (Arvanitidis et al., 2018, 2021). Still, this approach is computationally expensive, as it requires computing the Jacobian of the decoder, which, in our case, consists of an LLM.

EAGLE achieves realizability of the embedding by construction. Assuming the environment LLM generate feasible descriptions in \(\mathcal{X}\), any such point readily maps to a feasible embedding point. Moreover, training an encoder \(E_{D}\) is often a significantly easier task than training a decoder. Indeed, we find our encoder generalizes well on the test set of movie descriptions. More importantly, using the encoder to map to the embedding manifold we ensure any generated point is realizable, overcoming this problem by "moving" in ambient space \(\mathcal{X}\) instead of latent embedding space \(\mathcal{Z}\). This, however, comes with a significant limitation, i.e., coverage, as we discuss next.

**Coverage.** One of the major limitations of working in ambient space \(\mathcal{X}\), as opposed to directly optimizing the embedding space \(\mathcal{Z}\) is the inherent coverage of actions in \(\mathcal{X}\). Particularly, EAGLE requires using action prompts to change an entity's description. This approach has several disadvantages as (1) one must define the set of actions, (2) it is unclear the full embedding space can be

\begin{table}
\begin{tabular}{|p{56.9pt}|p{113.8pt}|p{113.8pt}|} \hline
**Method** & **Advantages** & **Disadvantages** \\ \hline
**ELM** & \(\bullet\) Efficient optimization in embedding space. & \(\bullet\) Computational efficiency of fine-tuning an ELM. \\  & \(\bullet\) Not constrained - can theoretically reach optimal point in embedding space. & \(\bullet\) Unknown generalization error / manifold metric for constraining optimization. \\ \hline
**EAGLE** & \(\bullet\) Leverages textual proficiency of existing LLMs. & \(\bullet\) Coverage is constrained by action space. \\  & \(\bullet\) Interpretable optimization & \(\bullet\) Computational efficiency during training: must use LLM environment. \\  & \(\bullet\) Computational efficiency: agent can be implemented using a smaller model. & \\ \hline \end{tabular}
\end{table}
Table 5: Trade-offs between EAGLE and ELM

[MISSING_PAGE_FAIL:17]

[MISSING_PAGE_FAIL:18]

[MISSING_PAGE_FAIL:19]

## Appendix E Implementation Details

We explain training details of the reference policies and EAGLE agent, and provide hyperparameters used in training. EAGLE was trained on a Gemini Nano-2 language model (3.25B), which can be trained using an equivalent of one A100 GPU. In our work, we train EAGLE in a parallelized manner, on an equivalent of 16 A100 GPUs. We use Gemini Ultra API for the environment calls, which did not require local compute, though can be time consuming due to the long context length and decoding length of movie descriptions. Every instantiating of EAGLE was trained for 5-7 days.

### Reference Policy Training

We used Gemini Nano-2 LLM (3.25B parameters) [Team et al., 2023] to train our reference policy. We train the reference policy using supervised learning, via cross entropy loss with predicting the next token in the sequence.

Given the dataset of all 100 action candidates (per movie), we create three dataset variants:

1. Uniform: this dataset uses all 100 action candidates as targets. Training the reference policy over these generates a uniform distribution over all actions.
2. Optimistic: For each action in the dataset we use the environment prompt (see Appendix F) and a Gemini Ultra to generate a next movie description. We then encode this next movie description to the movie embedding space and predict its rating for a specified user. We do this for every action. We then select the action in the dataset that achieves the maximal rating prediction and create a filtered dataset of only "best" actions. We use these actions as targets in the same way as before to create the optimistic reference policy.
3. G-Optimal Design: As described in Appendix C, we use the embeddings generated before (i.e., next state representation) as each action representation. We then randomly sample a subsets of \(k=10\) actions (without replacement) and calculate the matrix norm in Definition 1. We continue sampling until we find a value that satisfies the condition in Definition 1 with \(C=1\). We use the filtered dataset of 10 actions per movie as targets and train a reference policy in the same way as above.

We provide hyperparameter details used for training the reference policy in Table 6 below:

### EAGLE Training

EAGLE was trained with each one of the reference policies. We use REINFORCE with a value baseline to train EAGLE, with Generalized Advantage Estimation (GAE). Specific hyperparameters are given Table 7 below. All our experiments (except for one in Table 3) are trained using a Gemini-Pro as environment. We generate test results using Gemini-Ultra. To ensure stochasticity we applied temperature sampling to the agent and the environment.

\begin{table}
\begin{tabular}{l c} \hline \hline  & value \\ \hline Training Steps & 20000 \\ Batch Size & 1024 \\ Learning Rate & 2e-6 \\ Dropout Probability & 0.1 \\ \hline \hline \end{tabular}
\end{table}
Table 6: Training hyperparameters for reference policy.

\begin{table}
\begin{tabular}{l c} \hline \hline  & value \\ \hline Training steps & 30000 \\ Reference policy KL regularization (\(\alpha\)) & 0.1 \\ Policy learning rate & 1e-5 \\ Value learning rate & 5e-6 \\ Policy (agent) temperate & 0.5 \\ Environment temperature & 0.5 \\ Horizon \(H\) & 5 \\ Discount \(\gamma\) & 1 \\ \hline \hline \end{tabular}
\end{table}
Table 7: Training hyperparameters for EAGLE.

[MISSING_PAGE_EMPTY:22]

Rater Evaluation

Below we provide the format of the form provided to human raters. In the following section we provide particular qualitative results that were also presented to raters in this form.

```
*Below are two MOVE FLOTS, and SOME CHARACTERTS of THOSE MOVELS READ THIOUCH THE DESCRIPTION OF THE TWO MOVELS CARESULTYOU will THEN BE PRESENTED WITH a ROPELE OF a USE's REFERENCES. You will be ASKED (QUESTIONS ABOUT THE TWO MOVELS AND THE REFERENCES OF THAT USER."
*THE FIRST MOVE FLOOT (MOVE A).**
*( ( plot of first movie ))
*REASONS WHY SOMEONE MIGHT LIKE IT.**
*( ( reasons to like first movie ))
*REASONS WHY SOMEONE MIGHT DISLIKE IT.**
*( ( reasons to dislike first movie ))
*"THE SECOND MOVE FLOOT MOVE B).**
*( ( plot of second movie ))
*"REASONS WHY SOMEONE MIGHT LIKE IT.**
*( ( reasons to like second movie ))
*"REASONS WHY SOMEONE MIGHT DISLIKE IT.**
*( ( reasons to dislike second movie ))
*"RELOW IS A PROFILE OF A USE.**
*( ( user profile ))

QUESTIONS:

1. Which movie would the user prefer to watch? (A, B)
2. Which movie matches more of the user's preferences? (A, B)
3. The user were movie A score between 1 to 5. What score do you think they gave the movie? (1 - lowest rating, 2, 3, 4, 5 - highest rating)
4. The user gave movie B a score between 1 to 5. What score do you think they gave the movie? (1 - lowest rating, 2, 3, 4, 5 - highest rating)
5. The two movies are different from each other (strongly disagree, disagree, neutral, agree, strongly agree)
6. I would watch movie A (agree, disagree)
7. I would watch movie B (agree, disagree)
8. If you had to choose one of the movies, which movie would you personally prefer to watch? (A, B)
9. Movie A is an existing real movie (agree, disagree)
10. Movie B is an existing real movie (agree, disagrees)
11. Which movie would be liked by a wider audience? (A, B) ```

We use eleven questions to evaluate our human raters. Many of the questions were used to validate the quality of the responses. For example, questions 1, 2, 3, 4 evaluate the same question (i.e., user utility) in different ways. In our results we report average scores of question 1 for "user utility", average scores of question 5 for "distance score", and average scores average scores of question 8 for "rater utility".

When scoring rater utility we use the human rater's profile. The textual rater profile is constructed by the rater themselves, for which we generate a personalized EAGLE output.

[MISSING_PAGE_FAIL:24]

[MISSING_PAGE_FAIL:25]

[MISSING_PAGE_EMPTY:26]

## Appendix H Final Generated Movie Flows

### Forrest Gump (1994)

Forrest Gump is a heartwarming tide of a simple-minded man from Alabama who witnesses and participates in some of the most significant events in American history. From his childhood as a boy with leg braces to his adulthood as a war hero, football star, and successful businessman, Ferenst's extraordinary life unfolds against the backdrop of the Vietnam War, the Civil Rights Movement, and the Watergate scandal.

[MISSING_PAGE_EMPTY:28]

*Unlessubed: The Bertysal Wihirun*

Jack Swift, a former special forces operative, is struggling to cope with the aftermath of a violent mission that left him tunnatized. Hautted by nightplanes and flashbacks, he isolates himself from society, seeking solace in alcohol and self-destruction.

One day, Jack's former candidate, Sam, reaches out him. Sam informs Jack that Ethan, another member of their team, has gone rugate and is involved in a dangerous criminal enterprise. Ethan's actions have put innocent lives at risk, and Sam believes Jack is the only one who can stop him.

Rebucturally, Jack agrees to help. He teams up with Anaya, a skilled hacker who has also been affected by Ethan's violence. Together, they embark on a mission to track down Ethan and confront the consequences of their shared past.

As Jack derives deeper into the investigation, be is forced to confront his own inner donors. The violence he witnessed and perpetrated during the mission has left an indelink mark on his soul. He struggles with guilt, anger, and a deep sense of loss.

Along the way, Jack and Anaya encounter victims of Ethan's buality. They witness frashand the devastating impact that violence has on individuals and relationships. Families are more apart, lives are shattered, and the cycle of violence continues to perpetrature.

As they close in on Ethan, Jack and Aaya must navigate a complex web of lies and deception. Ethan's actions have not only caused physical harm but have also poisoned their once-close bond. The trust they shared has been shattered, leaving behind a huer taste of betrayal.

In the climactic showdown, Jack forces Ethan, his former friend now turned enemy. The confrontation is not only physical but also emotional. Jack must confront the consequences of the violence they both participated in and the ways it has destroyed their lives.

As the dust settles, Jack emerges from the conflict forever changed. He has witnessed the devastating toll that violence takes on individuals and relationships, and he is determined to break the cycle. With the help of Anaya and Sam, he owes to dedicate his life to healing the wounds of the past and preventing further poisoned.

The film ends with a message of hope and redemption. While the scars of violence may never fully heal, it is possible to find a path forward. By acknowledging the consequences of our actions and working together to create a more peaceful world, we can break free from the chains of the past.

*Final Constructed Muroic: Reasons to Ethan

*Through-Prowking Thems** The film explores the complex and devastating consequences of violence, examining its impact on individuals, relationships, and society.
*Reliable Characteristics** Jack's struggle with trauma and guilt is relatable to anyone who has experienced or witnessed violence, making the film emotionally resonant.
*Compelling Narrative** The plot builds in a compelling and superneeful manner, keeping audiences invested in the characters and their journey.
*Reliable Depiction of Violence** The film does not glorify violence but instead depicts it in a realistic and unlinking way, highlighting its destructive nature.
*Message of Hope and Redemption** Despite the darkness of the subject matter, the film ultimately offers a message of hope and redemption, showing that it is possible to break the cycle of violence and find healing.

*Final Constructed Muroic: Reasons to Ethan

*Hierarch Subject Matter** The film's focus on the consequences of violence could be too heavy or depressing for some viewers.
*Synto Facing** The film's emphasis on character development and emotional exploration may result in a slow pace that some viewers find unsturifying.
*Lack of Actone** While the film does continue some action sequences, it is primarily a character-driven story, which may disappoint viewers expecting a more action-packet experience.
*Predicide Pote* Some views may find the plot predictable or formulaic, lacking the element of surprise or originality.
*Unstifying Resolution** The film's message of hope and redemption may feel too holistic or unrealistic to some viewers, leaving them feeling unresolved or disappointed.

### Ice Age (2002)

*Original Muroic: Prior
* Ice Age follows the adventures of a group of prehistoric animals during the beginning of the Ice Age. Many, a vocibly mammoth, Sid, a sabtu, and Diego, a shuter-adshed tiger, form an unlikely no at they journey to return a human baby to its tribe. Along the way, they encounter various challenges and dangers, including a group of vengeful dodo birds, a rereborrous ice curve, and a rock of hungry wolves.

* Original Muroic: Reasons to Life

* Family-Friendly Entertainment: The film is suitable for audiences of all ages, with its skuptick humor and heartwarming themes.
* Lovishe Characters: Many, Sid, and Diego are instantly likable and memorable characters that appeal to both children and adults.
* Suming Arithmetic: The film's animals is impressive for for its, bringing the predicted world to life in vivid detail.
* Primary Dialogue: The dialogue is witty and entertaining, featuring mentorable one-liners and posthibenments.
* Educational Value: The film touches upon themes of friendship, cooperation, and the importance of family.

* **Original Movie Reasons to Dislike**

* **Prodictable Part: The story follows a fairly formalistic structure, with few surprises or unexpected twists.**
* **Shallow Characters: While the main trio isivable, the supporting characters are underdeveloped and lack depth.**
* **Overlineance on Slapstick: Some viewers may find the film's reliance on physical comedy excessive and repetitive.**
* **Dust Automation: Compared to modern animated films, the animation in Ice Age may appear dated and less impressive.**
* **Lad of Emotional Resonance: The film's focus on humor and action may prevent it from connecting with audiences on a deeper emotional level.**

* **Textual Error Traffic**

* **Overall Percentors**

* **High-budget, effects-driven action and science fiction films**
* **Flims with strong storyling and character development**
* **Flims that are thought-peroking and/or emotionally resonant**
* **Gene Percentors**

* **Science fiction, particularly those with a focus on technology, space exploration, and philosophical themes**
* **Action, especially films with well-choreographed fight sequences and impressive special effects**
* **Sapapette films, particularly those that explore the complexities of heroism and maudity**
* **Cime delivers, with intricate plots and supensuroll passing**
* **Animated films, both feature-length and short-form**
* **Director Percentors**

* **No discernible preferences for specific directors**
* **Aesthetic Preferences**

* **Visually stanning films with impressive special effects and cinematography**
* **Flims with a dark and atmospheric tone**
* **Flims that use music effectively to enhance the emotional impact**
* **Other Preferences**

* **Flims that explore themes of ideality, maudily, and the human condition**
* **Flims with a strong sense of humor, particularly dark comeries of satistical films**
* **Flims that feature strong female characters**

* **RACLE Actions**

* **Touch upon the theme of survival in a harsh and unergishing environment, showcasing the characters' resilience and adaptability.**
* **Touch upon the theme of the search for meaning and purpose in a world that is constantly changing and unpredictable.**
* **Enploy a more dynamic camera style to capture the energy and struggle of the characters in the cold and unergifying environment.**
* **Inoperative slow-motion and time-lapse effects to highlight the passage of time and the technical nature of the cold.**
* **Incorporate more dynamic camera angles and editing techniques to enhance the sense of movement and danger.**

* **Final Featureized Movie Part**

* **Anid the decolate waveland of the Arctic Circle, a group of interpod exploreers embracts on a perilous expedition in search of a lost civilization.**
* **Low-angle shots capture the tueruing icebers that loom over the exploreers, dwarfing them amidst the unregoiving widerness. As they traverse the tuerachroress terrain, handheld cameras follow their every move, conveying the constant sense of danger and instability.**
* **During a sudden sowowaction, rapid-life editing and extreme close-ups capture the disorientation and panic that ensues. The camera spins and blurs, immersing the audience in the chorus struggle to bebilder.**
* **As they approach a towering glacier, a wide-angle shot reveals the sheet scale of the icy monolith. A time-lapse sequence captures the slow but redientes movement of the glacier, highlighting the ever-present threat of walanches.**
* **When a member of the team falls into a creasease, a low-angle shot from below captures their desperate struggle to escape. The camera tilts and rotates, conveying the claustrophobia and terror of their predicament.**
* **Through the use of dynamic camera angles and editing techniques, the film immerses the audience in the exploreers' periodizes journey. The constant sense of movement and danger keeps viewers on the edge of their seats, as they witness the raw power of nature and the indinutable spirit of those who dore to challenge it.**

* **Final Featureized Movie Reasons to Dislike**

* **Imretive Experience: The dynamic camera angles and editing techniques transport viewers into the heart of the Arctic sculpteness, creating an immersive and thrilling experience.**
* **-Heightened Danger: The use of low-angle shots, handheld cameras, and rapid-life editing intensities the sense of danger and peril faced by the exploreers.**
* **Visual Storyling: The innovative use of camera work and editing enhances the narrative, conveying the challenges and truimbs of the expedition in a visually engaging way.**
* **-Adrenaling Routh: The constant movement and supensens created by the dynamic visuals keep viewers on the edge of their seats, providing an adrenaline-fucked cinematice experience.**
* **-Apprecisation of Nature: The film's stunting portrayed of the Arctic landscape through wide-angle shots and time-lapse sequences fosters an appreciation for the raw beauty and unregoiving power of nature.*** **Clinical Clinical Matrix:** Restors to DIS/RIs

* **Excessive Visual Effects:** The constant use of dynamic camera angles and editing techniques could be perceived as overwhelming or distracting, detracting from the narrative flow.

* **Reduced Emotional Impact:** The focus on visual spectacle may overshadow the emotional depth of the characters and their journey, potentially dilating their relabitsky.

* **Motion Sickness:** The rapid camera movements and editing could induce motion sickness in some viewers, making the film an unpleasant experience.

* **Latch of Suddev:** The heavy-handed use of these cinematic techniques may feel forced or manipulate, undermining the authenticity of the narrative.

* **Reduced Dimension:** While the visual effects aim to enhance immersion, they could also create a sense of detachment if they become too intrusive or overwhelming.

### Despicable Me (2010)

* **Original Movie:** Top

* **Despicable Me follows the story of Gru, a supervillian who plans to steal the moon. However, his plans are thwarted when he encounters three orphaned girls, Margo, Edith, and Agnes, who he adopts as part of his scheme. As Gru spends time with the girls, he begins to widen and question his villinous ways. Eventually, he must choose between his ambition and the lore he has found with his new family.**

* **Original Movie:** Restors to DIS/RIs

* **Herwarming Story:** The film's central theme of redemption and the power of love is both heartwarming and relatable.

* **Homeous Characters:** Gru and his minions provide plenty of hapls with their guilty personalities and alspatied humor.

* **Adronic Minors:** The small, yellow, sithersonia-speaking minions are a highlight of the film and have become become iconic characters in their own right.

* **Family-friendly Entertainment:** The film is suitable for audiences of all ages, making it great choice for family movie nights.

* **Strong Voice Acting:** Steve Carell and Jule Andrews deliver remarkable performances as Gru and Gru's mother, respectively.

* **Original Movie:** Restors to DIS/RIs

* **Proticable:** The film's point follows a fairly predictable formula, which may not appeal to viewers looking for something more original.

* **Over-the-Top Hame:** Some may find the film's humor to be too silly or overtone.

* **Latch of Depth:** The film is primarily focused on entertainment and does not explore any deep or complex themes.

* **Derivative Characters:** Gru's character is reminiscent of other animated villinats, such as Megamand and Syndrome.

* **Weak Villain:** Vector, the film's antagonist, is not particularly threatening or memorable.

* **Textual User/Trendo**

* **Overall Preferences**

* **High-budger, effects-driven action and science fiction films**
* **Fims with strong suceptibility and character development**
* **Fims that are thought-pervolving and/or emotionally resonant**
* **Gener References**

* **Science fiction, particularly those with a focus on technology, space exploration, and philosophical themes**
* **Action, especially films with well-choreographed fight sequences and impressive special effects**
* **Sportence films, particularly those that explore the complexities of heroism and murality**
* **Cime delivers, with intricate plots and supensecult parsing**
* **Animated films, both feature-length and short-form**
* **Director Preferences**

* **No discernible preferences for specific directors**
* **Aesthetic Preferences**

* **Visually stumning films with impressive special effects and cinematography**
* **Fims with a dark and atmospheric tone**
* **Fims that use music effectively to enhance the emotional impact**
* **Other Preferences**

* **Fims that explore themes of identity, murality, and the human condition**
* **Fims with a strong sense of humor, particularly dark concepts or sutifical films**
* **Fims that feature strong female characters**

* **RACLE Settings**

* **Introduce a message about the importance of accepting and embracing one's true self.**
* **Use montage sequences to show the passage of time and the development of Gru's relationship with the girls, making the film more engaging.**
* **Use flashboxes or dream sequences to provide insights into Gru's past and motivations, making his character more relatable.**
* **Use flashboxes and dream sequences more sparingly, focusing on developing the present-day relationships and conflicts to keep the narrative engaging.**
* **Introduce a new character who is a rival to Gru, but who also has a hidden connection to the girls, creating a more complex and unpredictable dynamic.**

## Appendix H Final Generated Movie Plots

Dopedicable Me follows the present-day journey of Gru, a supervellin struggeling to balance his villainous ambitions with his newfound role as a father figure.

As Gru plans to steel the moon, he encounters a formidable rival named Dr. Neftario, a brilliant but eccentric scientist who also harbors a secret connection to Margo, Edith, and Agnes. Unbaknowments to Gru, Dr. Neftario was once the girls' guardian, having raised them in a secret laboratory before they were adopted by Gru.

Dr. Neftario's rivalty with Gru stems not only from their competing ambitions but also from his desire to reclaim his bond with the girls. His knowledge of their past and his genuine affection for then create a complex and unpredictable dynamic.

As Gru and De. Neftario engage in a battle of with and gadgets, the girls find themselves ten between their loyalty to Gru and their growing curiosity about their former guardian. Dr. Neftario's attempts to reconnect with them force Gru to confront his own feelings of inadequacy and question his true motivations.

Meanwhile, the girls' memories of their past begin to reurface, triggered by subtle cues and interactions with Dr. Neftario. As they piece together fragments of their childhood, they must decide who they can trust and where their true home lies.

The climax of the film involves a confrontation between Gru, Dr. Neftario, and the girls. Gru must not only overcome his rival but also confront the truth about his own past and the impact it has had on his present. Ultimately, the choice lies with the girls as they decide who will be their true protector and guide.

In the end, the film explores themes of identity, family, and the power of redemption. Gru's transformation is not only about abandoning his villainous ways but also about embracing his true self and finding fulfillment in the love and acceptance of others.

## Appendix H Final Generated Movie: Reasons to Disks

- Complex Characters: The introduction of Dr. Neftario creates a more complex and unpredictable dynamic, adding depth to both Gru and the girls' characters.

- Intriguing Plee: The hidden connection between Dr. Neftario and the girls adds an intriguing layer to the plot, keeping viewers engaged and pressing.

- Emotional Depth: Dr. Neftario's genuine affection for the girls and their resurfacing memories provide additional emotional depth to the story.

- Unperdeckable Outcome: The girls' ultimate chance between Gru and Dr. Neftario creates an unpredictable outcome, highlighting the superpose and excitement.

- Exploration of Identity: The film explores the themes of identity and self-discovery as Gru confronts his past and the girls search for their true home.

## Appendix H Final Generated Movie: Reasons to Disks

- Controlled Plot: The hidden connection between Dr. Neftario and the girls could be seen as contrived or forced.

- Underexveloped Characters: The focus on the complex dynamic between Gru, Dr. Neftario, and the girls could potentially lead to other characters being underdeveloped.

- Lack of Emotional Impact: The reduced reliance on flashbacks and dream sequences could limit the emotional impact of Gru's past and his transformation.

- Predictable Conflict: The trauly between Gru and Dr. Neftario may feel predictable or repetitive, despite the added complexity of their connection to the girls.

- Unresolved Questionnaire: The film may leave some questions about the girls' past and Dr. Neftario's motivations unanswered, leading to a sense of incompleteness.

## Appendix H.6 Amazing Spider-Man, The (2012)

### Original Movie: Reasons to Life

- Relatable Protagonist: Peter Parker is a valuable and Ihable character who audiences can easily root for.

- Exciting Action Sequences: The film features thrilling and well-choreographed action scenes that showcase Spider-Man's abilities.

- Strong Villar: The Lazard is a mechanism and formidable antagonist who provides a significant challenge for Spider-Man.

- Love Interest: Gruen says, Peter's love interest, i.e. charming and strong female character who adds an emotional layer to the story.

- Andrew Gurfield's Performance: Garfield delivers a nuanced and charmatic performance as Peter Parker/Spider-Man.
* *Overall Preferences*
* High-budget, effects-driven action and science friction films
* Finn with strong upwelling and character development
* Films that are thought perwooking and/or emotionally resonant
* Gene Preferences*
* Science fiction, particularly those with a focus on technology, space exploration, and philosophical themes
* Action, especially limits with well-chiorographed fight sequences and impressive special effects
* Spiepberne (dims, particularly those that explore the complexities of heroism and mortality
* Crime themselves with intricate plots and supensecraft)
* Animated films, both feature-length and short-form *
* Director Preferences*
* No discernible preferences for specific directors
* Aesthetic Preferences*
* Visually stunning films with impressive special effects and cinematography
* Films with a dark and atmospheric tone
* Films that use music effectively to enhance the emotional impact
* Other Preferences*
* Films that explore themes of identity, mortality, and the human condition
* Films with a strong sense of humor, particularly dark comedies or satistical films
* Films that feature strong female characters
* MCLB Actions*
* Add a musical score that complements the film's fast-paced and comecid tone. Create a marketing campaign that emphasizes the film's unique blend of action, comedy, and emotional depth, appealing to a wide range of viewers. Create a marketing campaign that emphasizes the film's unique blend of action, comedy, and emotional depth, appealing to viewers who value both entertainment and thought-perwoking content. Incorporate a twist where Alex discovers that his true desity lies in a different field than simply fighting aikens, challenging his proconceived notions. Develop the supporting characters by giving them unique personalities, quarts, and motivations that contribute to the overall ensemble.
* **Ascenance: A Chemantic Odyssey of Action, Comedy, and Unexpected Destiny**

Prepare yourself for an unforgetable cinematic experience with "Ascenance," a film that seamlessly waves together heart-pounding action, side-splitting comedy, and profound emotional depth.

Meter Alex, an ordinary college student whose life is forever changed when he witnesses a mysterious maneuver crash. As he investigates the crash site, Alex is exposed to an unknown energy that grants him superhuman abilities. The film's musical score captures the _ave_ and _wonder_ of Alex's transformation with an emigmatic and _ave-imping_ theme.

Joining Alex on his extraordinary journey are a diverse cast of supporting characters, each with their unique personalities, quits, and motivations.

* **Mia** ** Alex's best friend and confidence, Mia is a billiard and resourceful hacker who provides invaluable technical support and witty bautre. Her unweering loyalty to Alex is matched by her sarcastic humor, helping the mood in tense situations.

* **Dr. Emily Carter-A renowned audiologist, Dr. Carter becomes Alex's inventor and guide. Her scientific curiosity and composition drive her to help false understand his abilities and the potential implications of the dither threat.

* **Jake** ** A skeptical and pragmatic government agent, Jake initially views Alex with suspicion. However, as the evidence of an alien invasion mounts, he refortently learns up with Alex, helping his tactical expertise and answering determination.

* **Zia** ** An emigmatic union for a distant planet, Zara arrives on Earth with a mission to protect humanity from a common enemy. Her static denamator and formidable fighting skills and a new dimension to the conflict.

At first, Alex reeds in his newfound powers, using them for perhaps and personal ammement. However, his carrerere attitude takes a dramatic turn when a formalizable alien there emerges from the shadows. The score intensities, transitioning to a pulsating rhythm that underscores the thilling action sequences as Alex and his slime face of agent these extraterrestrial investors.

Anmidat the spectacle and adrenalite-pumping action, "Ascenance" deldly behaves in moments of lvity. Mia's witty remarks, Jake's dry home, and the abound situation they find themselves in provide a welcome balance, ensuring that the film remains both enlistization and entertaining. The score sensibly incorporates comedic elements, highlighting the film's unique blend of action and humor.

As the snakes rise, Alex grapgles with the weight of his abilities and the responsibility he bears to protect humanity. The score becomes more introspective and emotionally charged, mirroring his inner turnoll and the profound impact his choices have on his life and those around him.

Through their interactions with Alex and each other, the supporting characters contribute to the overall ensemble and enrich the narrative. Mia's unweering support helps Alex's argument, while Dr. Carter's scientific insights provide a rational perspective on the extraordinary events unfolding. Jake's skeptic challenges Alex's assumptions and forces him to confront the consequences of his actions. Zara's alien perspective offers a unique understanding of the conflict and the potential for injury between different species.

In a pivotal moment, Alex uncovers a hidden aptitude for diplancy and negotiation. Through his interactions with the alien invaders, he realizes that there is more to their presence than meets the eye. The score shifts to a more contemporhip and hopeful tone, hitting at the unexpected twist that awaits.

As the conflict intensifies, Alex faces a profound revelation. His true destiny lies not solely in unquestioning the alien threat but in bridging the gap between humanity and the extraterrestrial visitors. The score swells with a sense of purpose and determination, underscoring Alex's newfound understanding of his role.

Through a series of heart-stopping confrontations and thongk-provoking moments, "Ascenance" explores themes of identity, sacrifice, and the search for meaning in a chaotic world. The film's musical score serves as an integral guide, enhancing the emotional resonance of every scene.

In a climactic showdown that will leave audiences breathless. Alex utilizes both his superhuman abilities and his diplomatic skills to forge an unprecedented alliance betwen humanity and the alters. The score reaches an epic crescendo, capturing the triumph of hope, unity, and the unexpected density that Alex and his allees embrace.

"Ascenance" is a cinematic tour de force that will expretaure viewers with its unique blend of action, comedy, and emotional depth. It is a film that will not only entertain but also provide thought and ignite conversations long after the credits will.

**Marketing Campaign.**

The marketing campaign for "Ascenance" will emphasize the film's unexpected twist and its exploration of unconventional densities. Additionally, it will highlight the diverse cast of supporting characters and their unique contributions to the overall ensemble.

* **Type Audience** ** Webers who value both high-butcine action and thought-provoking content that challenges expectations.

* **System** **+** **Prepare for an Odyssey of Action, Comedy, and the Unexpected!-

* **Tailers and Posters** **+** **Highlight the film's thilling action sequences, witty humote, and the diverse

* **Tailers** **+** **Highlight the film's thilling action sequences, witty humote, and the diverse

** **Predictable Plot** **Some viewers may find the film's pick to be formulas or predictable, lacking the element of surprise.** **-** **Over-the-Top Action**.**++ **The action sequences may be too intense or over-the-top for audiences who prefer a more grounded approach.** **-** **Jarjune Tail Shifts** **The transitions between action, comedy, and emotional scenes may feel abrupt or jarjune in some views.** **-** **Uninspired Dialogues** **The film's dialogue may be considered clicked or lacking in depth, detecting from the overall impact.** **-** **Sablow Supporting Characters**.**++ **The supporting characters may not be fully developed or reliable, making it difficult for audiences to connect with them on an emotional level.** **-** **Decorative Themers** **The film's explanation of identity and sacrifice may feel derivative or unoriginal to some viewers.** **-** **Controlled Twist**++ **The revelation of Alex's true destiny may feel continuity or forced, undermining the credibility of the story.** **-** **Unsatisfying Resolution**.**++ **The film's ending may not provide a satisfying resolution to the conflicts and themes raised throughout the story.**

### Dumb & Dumber (Dumb and Dumber) (1994)

* **Optimal Movie Flow**

* **Dumb and Dumber follows the misadventures of two dim-vinted friends, Lloyd Christmas and Harry Drune. After losing their jobs, they embark on a cross-country road trip to Agent, Colorado, to return a briefcase full of money to its rightful owner, Mary Swanson. Along the way, they encounter a series of midups, including accidentally killing a man, getting kidnoped, and being pursued by a pair of criminals.**

* **Original Movie Flow** to Like

* **Slapistic Control: The film is filled with over-the-top physical comedy that will appeal to fans of the genre.** **-** **Quotable Lines: Dumb and Dumber is known for its memorable and quotable dialogue, such as "So you've telling me there's a chance?" **-** **Jim Carrey and Jeff Daniels**. The performances of Jim Carrey and Jeff Daniels as Lloyd and Harry are habitous and iconic.** **-** **Simple and Fan. The film has a simple premise that is easy to follow and enjoy.** **-** **Nosuliggic Value: For those who grow up in the 1990b, Dumb and Dumber holds a special place in their hearts.**

* **Original Movie Flow** to Like

* **Crade Itramer: The film's humor is often crude and may defend some viewers.** **-** **Predictable Plot: The plot is fairly predictable and lacks any real surpeties.** **-** **One-Dimensional Characters: Lloyd and Harry are essentially one-code characters who never really drevelop.** **-** **Last of Dumb. The film is purely comedy and does not explain any degree themes or ideas.** **-** **Repetitive Roles: Some of the jokes in Dumb and Dumber can become repetitive and gating.**

* **Textual User Profile**

* **Overall Preferences**
* **Perters popular and mainstream movies, particularly from the 1990s,** **Enjoys a wide range of genres, but shows a preference towards comedies and action films.** **-** **Tends to favor movies that are entertaining, crowd-pleasing, and offer an escape from reality.** **-** **Gore Preferences**
* **Epipsy comedies, particularly sluggist, gross-out, and romantic comedies.** **-** **Apprecticeations anxious with strong thrills, suspense, and special effects.** **-** **Epipsy coming theillness and mysteries the feature intriguing plots and twists.** **-** **Has a donhes for family-friendly films, including animated features and live-action comedies.** **-** **Shows interest in science fiction and fantasy movies, particularly those with epic storylines and impressive visual effects.** **-** **Direct Preferences**
* **Docs not been to have strong preferences for specific directors.** **-** **Enjoys wecks by directors who have helmed successful commercial films, such as Tim Buxton, Joel Schumacher, and Peter Farrelly.** **-** **Apprecticeations who can balance entertainment value with emotional depth.** **-** **Aesthetic Preferences**
* **Perters movies with a bright and colorful visual style.** **-** **Enjoys movies with a strong sense of spectacle and visual effects.** **-** **Apprectice movies with cathy soundtracks and upbeat music.** **-** **Other Preferences**
* **Enjoys movies that feature a blend of humor, action, and romance.** **-** **Valapse movies that offer excision and a sense of fun.** **-** **Apprectice movies that have a notable quality, reminding them of films from their childhood or adolescence.** **-** **Apprecticeations who can balance entertainment value,** **-** **Enjoys movies that feature strong characters and relatable storylines.** **-** **BACLE XRIMES**

[MISSING_PAGE_FAIL:36]

## Original Movie Reasons to Life

* Heartwarming Story: Dumbo's journey from contact to celebrated hero is both uplifting and emotionally resonant.
* Charming Animals: The film's classic Disney animation is visually appealing and brings the characters to life.
* Memorable Characters: Dumbo, Timothy, and the other circos animals are rendering and unforgettable.
* Timeseries The film explores themes of acceptance, self-confidence, and the importance of family.
* Nosalicylic Value: Dumbo holds a special place in the hearts of generations who grew up with it.

## Original Movie Reasons to Distifies

* Short Runtime: At only 64 minutes, Dumbo may feel too brief for some viewers.
* Oudatined Sensibilities: Some of the film's depications of race and animal treatment may be considered offensive by modern audiences.
* Lack of Complexity: The plot and characters are relatively simple, which may not appeal to viewers looking for a more sophisticated story.
* Sentiment Ending: The film's hype ending may be seen as overly saccharine or unrealistic.
* Limited Aimation: Compared to later Dinuy films, Dumbo's animation is more limited and may not be as visually impressive.

## Textup User Profile

* Overall Preferences**
* Preferences**
* Engways wide variety of genres, but shows a particular affinity for action and comedy.
* Trends to fawe movie with mainstream appeal and mass entertainment value.
* Appreciance films that are both entertaining and thought-provoking.
* Gene Preferences**
* Engways action movies featuring high-octane thrills, explosions, and fight sequences.
* Appreciance molecules that are highlighted, amusing, and sometimes sattical.
* Lakes crime thinks with complex plots, suggestingful twists, and enigmatic characters.
* Enjoys science fiction films that explore imaginative concepts and technological advancements.
* Appreciance family-friendly films, particularly those that feature animated characters and harentwarming stories.
* Director Preferences**
* The user's list does not indicate any strong preferences for particular directors.
* Aesthetic Preferences**
* Enjoys films with visually impressive special effects and action sequences.
* Appreciance movies that feature memoachic characters and equitable dialogue.
* Prefers films with a fast-posed and engaging narrative that keeps the audience entertained.
* Other Preferences**
* Enjoys films that combine elements of different genres, such as action-comedics or science fiction-drillers.
* Values films that feature strong and dynamicist lead performances.
* Appreciance movies that explore themes of heroin, loyalty, and reemption.
* Has a soft spot for notsialize films from their childhood, particularly animated features and family comedies.

## Appendix A Celine Actions

Introduce a female elephant character who becomes Dumbo's friend and helps him overcome adversity.

Towth upon the themes of residence, hope, and the power of redefinition.

Give Dumbo a mere acute role in his own relongens, showing his residence and determination in overcoming his challenge.

Male the tremendous more complex and multifaceted, showing their own smuggles and motorizations for instructing Dumbo.

Include more shoptical and physical comedy to enhance the entertainment value for younger audiences.

## Appendix H Third Generated Matrix Plots

Dumbo, the young citrus elephant with unusually large cars, faces reclentless comment from a group of fellow performers. However, unlike before, these temperatures are not simply cored and heartless. Instead, they are driven by their own insecticides and struggles, which are now amplified by a series of dispatch mixings.

The ringelader, Rec, is a once-remounced clow who has lost his spark. As be attempts to subedge Dumbo's performances, he finds himself trying over his own oversized shoes, tumbling into buckets of water, and getting caught in a net. His desperation for validation becomes even more comil as his pitfalls draw together from the audience.

The sturogram, Bruno, tries to intimidate Dumbo with his impressive physique, but his attempts are thwarted by a malfunctioning weightfuling bar that sends him flying across the ring. His fear of being overshadowed by Dumbo's strength is overshadowed by the spectacle of his own clumstiness.

The artrobos, Arya, Boris, and Cyril, are determined to prove their superiority over Dumbo. However, their elaborate status are constantly disrupted by instinct flips, slippery tapages, and a rogue myocyte. Their recruitment towards Dumbo transforms into a chaotic and hitarious competition of who can make the biggest blunder.

Amaidt this slasptick chaos, Ella, a fellow outcast, extends a hand of friendship to Dumbo. Together, they devise a plan to expose the underlying reasons behind the investment while also incorporating the termoters' misclosures into the show.

Through a series of carefully established performances, Dumbo and Ella turn the tomicto's 'patfalls into a source of entertainment. Rec's clumpy attempts to passide become a juggling act with flying pres, Brem's weightfuling might become a human camonball stunt, and the aerobus' mishops become a gravity-defying comedy routine.

In a climatic confrontation, Dumbo confronts his tencentors with a water balloon fight. As they chose each other around the ring, slipping and sliding in a freney of foam and water, their insecurities and vulnerabilities are washed away in a torrent of lungher.

One by one, the tencentors begin to realize the abusive of their behavior. Rec's fectiveness his joy in making people laugh, Bruno learns to embrace his owngoins, and the aerobus f fied new ways to showcase their talents while enhancing the unexpected.

Together, they create a more inclusive and supportive environment for all, where differences are celebrated and lungher is the best medicine. In the end, Dumbo's journey becomes a testament to the transformative power of empathy, the importance of embracing our imperfections, and the bounfless _py_ that can be found in the most unexpected of places.

## Appendix H Third Generated Matrix Results for Mike

- Enhanced Entertainment Value: The addition of dispatch and physical comedy provides a constant source of lungher and amsement, making the film highly entertaining for younger audiences.

- Reliable Characteristics: The ternometers' incentivies and struggles become even more relatable when paired with their conical misclosures.

- Humboons Redemption Arc: The ternometers' redemption are is made more lighthearted and enjoyable by the sliptick elements, while still conveying a meaningful message.

- Balanced Storyling: The sliptick comedy is seamlessly integrated into the plot, enhancing the entertainment value without deraterating from the emotional depth of the story.

- Family-friendly Fun: The combination of hertwarning themes and sliptick humore makes the film suitable for audiences of all ages, providing a shared experience for families.

## Appendix H Third Generated Matrix Results for Disk

- Oversliance on Slaptick: Some viewers may find the excessive use of sliptick and physical comedy to be distracting or overwhelming.

- Reduced Emotional Impact: The focus on comedy may dilute the emotional impact of the torrent Dumbo faces.

- Trivialization of Bullying: The sliptick elements may trviliate the seriousness of bullying and undermine the message of empathy.

- Famioioio Comedy: The sliptick routines may feel repetitive or formualize, reducing the overall entertainment value.

- Departure from Classic Story: Punits may object to the significant departure from the classic table, particularly the inclusion of sliptick and physical comedy.

## Appendix H.9 Scream 2 (1997)

### Original Market Plan

Two years after the events of Scream, Sidney Prescott is now a college student at Windsor College. However, the nightmare returns when a new killer, wearing the iconic Obsttic mask, begins targeting students on campus. As the body count rises, Sidney and her friends must race against time to uncover the identity of the killer and stop them before it's no late.

## Appendix H Additional Movie Results to Life

- *Nostalgia Factor ** For fans of the original Scream, this sequel offers a continuation of the beloved franchise.

- *Covert Kota-Commentary* The film directly references and satisfies the conventions of hour capsule.

- *Sutong Female Characteristics* Sidney Prescott remains a strong and resourced pedestrian, joined by other memorable female characters like Gale Webbers.

- *Influence Supreme** The film maintains a high level of supense throughout, keeping audiences on the edge of their seats.

- *Sarpasing Trusts** Like its predecessor, Scream 2 features unexpected twists and turns that keep viewers guessing.

* **Predictable Plot++** Same viewers may find the plot too similar to the original film, lacking originally.
* **Executive Gaze++** The film features a significant amount of violence and gone, which may be off-puting to some.
* **Work Supporting Characters++** While Sidney and Gale are well-developed, some of the supporting characters fed underdeveloped or disposable.
* **Over-the-Top Performances++** Some of the performances, particularly those of the killer, can be seen as overrated or canopy.
* **Lak of Scares++** Compared to the original Scream, this sequel may not be an effective at delivering genuine scores.

* **Textural Lkore Traffic**

* **Overall Procedures**
* **Perics contemporary films, with a focus on those released in the 1993s.
* **Enjoys a wide variety of genres, but shows a particular affinity for action and comedy.
* **Tools to favor movies with mainstream appeal and mass entertainment value.
* **Apprecedes ations that are both entertaining and thought-provoking.
* **Gene Preferences**
* **Enjoys action movies featuring high-octane thills, explosions, and fight sequences.
* **Apprecedes correlates that are highlighted, amusing and sometimes satitical.
* **Lkse crime thinks with complex plots, unsupervised twists, and enigmatic characters.
* **Enjoys science fiction films that explore imaginative concepts and technological advancements.
* **Apprecedes family-friendly films, particularly those that feature animated characters and heartwarming stories.
* **Director Preferences**
* **The user's list does not indicate any strong preferences for particular directors.
* **Aeahtica Preferences**
* **Enjoys films with visually impressive special effects and action sequences.
* **Apprecedes movies that feature memorable characters and qurobable dialogue.
* **Perics films with a fast-paced and engaging narrative that keeps the audience entertained.
* **Other Preferences**
* **Enjoys films that combine elements of different genres, such as action-comedics or science fiction-thrilers.
* **Values films that require strong and chrisamic lead performances.
* **Apprecedes movies that explore themes of herosion, loyalty, and reemption.
* **Has a soft spot for notable films from their childhood, particularly animated features and family comedies.

## 10 Machine Actions

Create a semantic subtlete between Sidney and a fellow student, adding an element of light/herotheness and emotional depth.

Set the film in a different location, such as a occluded island or an isolated eclipse campus.

Host special screening or events that cater to fans of the 1990s and early 2000s, highlighting the film's notable appeal.

Include a romantic subplot between Arya and Lian, adding an element of love and emotional connection to the narrative.

Add a comnck subdisk character who provides moments of heroly and entertainment amidst the supenselfth events.

### Final Centrotical Movie Trial

On the remote and enigmatic Shadow Island, a group of former students from the now-defunct Blackwood College remuite for a nonstlagic weekend gesture. Among them is Arya, a successful businessman who has long since buried her troubled past at the college, and Lian, a writer who has always harnessed feelings for her. Joining them is their cosmetic and perpetually optimistic friend, Max, who provides much-needed comic relief amidst the growing tension.

As they arrive at the isolated lodge nestled amidst tuering trees and the sound of crashing waves, Arya and Lian feel a spark of rekinded connection. Ambit the lagger and reminiting of their college days, Max's infectious humor keeps the mood light, even as the group begins to spend more time together, sharing secrets and confining in each other.

However, their reunion takes a sniuster turn when a masked killer known only as "The Shadow" emerges from the darkness, targeting them one by one. Pnic and/chous ensure as the group reduces they are trapped on the island with a rubbies narrower who seems to be connected to their past. Max, despite his initial four, manages to find humor in even the motor directing, lightening the mood and providing a glimmer of hope.

As the body court rests, Arya and Lian find themselves down together, seeking sobue and support in each other's presence. Ambit the fear and bloodst, their bloodst and deepens in a passionate be that bring them speech to face the unknown. Max, with its unsurvering loyaly and quick wit, becomes their unlikely ally, using his humor to attract the killer and provide much-needed moments of reguide.

Working together, Arya, Lian, and Max delve into the island's sinister history and uncover a chilling connection between the present killing and a dark tugely in that occurred during their college years. As they uncover the truth, their love for each other and Max's unwavering humor become because of hope in the face of overwhelming darkness.

In a climactic confrontation on the windowed cliffs, Arya, Lian, and Max confront their past, the true nature of the killer, and the guik they have carried for years. Armed with new/found strength, the unsurvering support of their love, and Max's ability to find luughter even in the face of danger, they light back against the darkness that threatens to consume them all.

As the sun rises over Shadow Island, the night/name ends, leaving behind a tale of realliscence, redemption, and the realization that even in the face of adversity, the power of love and luughter can cooperate all.

* **Nonstapic Appe.**\({}^{*}\) The film evolves a sense of outslgia for fans of the 1990s and early 2000s, with its references to popular culture and the tension of characters from a beloved institution.
* **Unique Setting.**\({}^{*}\) The scheduled island Launie creates a management of isolation and vulnerability, enhancing the suspension and terror.
* **Unique Change.**\({}^{*}\) Aray and Laun's compete parts and their developing live story add depth and intrigue to the narrative. Max's cemotic presence provides a welcome balance to the suspense and borrow.
* **Anmospheric Superne.**\({}^{*}\) The film effectively builds suspense through the use of shadows, create sounds, and the deadline landscape of the island.
* **Unique Legend.**\({}^{*}\) The incorporation of an island based ads in a supernment cleaner to the horore, creating a sense of unease and mystery.
* **Unique Legend.**\({}^{*}\) The film keeps venering with unexpected twists and revolutes about the killer's identity and motives.
* **Unique Female Propagation.**\({}^{*}\) Aray journey of self-discovery and resilience proxies a powerful and reliable female character.
* **Conomic Subject.**\({}^{*}\) The love story between Aray and Llam adds an emotional dimension to the horore, providing a sense of hope and connection amid the darkness.
* **Conomic Reidel.**\({}^{**}\) Data's infections humor provides much-needed moments of levity, lightening the mood and making the suspense more bearable.
* **Satisfying Resolution.**\({}^{**}\) The climate contraction on the cells offs a satisfying resolution that ties together the past and present, leaving audiences with a sense of closure and the turunch of love,ughter, and resilience over advertisity.

### Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)

* **Original Monte Plan**

* **Model and Exchanging.** The film creates a explaining world of magic and wonder that appeals to audiences of all ages.
* **Fairful Adaptation.** The movie closely follows the beloved book, satisfying fans of the original story.
* **Charming Charters: Harry, Ron, and Hermoine are reliable and encloring characters that audiences can't help but not for.
* **Summing Visual.** The special effects and we design during the magical world of Hogerstra to life in a visually impressive way.
* **Family-Friendly Entertainment.** The film is suitable for children and adults alike, providing a shared experience for families.

## Original Monte Results to Dislike

* **Proticable Pote: The story follows a fairly straightforward bare's journey, which some views may find tangential.
* **Childish Toac: The film's target audience is primarily children, which may make it less appealing to some older viewers.
* **Slow Pacing The early scenes at Hogerstra can feel slow-peared and lacking in action.
* **Overly Long Runtime: A152 minutes, the film may feel drawn out for some viewers.
* **Cherey Dialogue: Some of the dialogue, particularly between the younger characters, can come across as cheesy or forced.

[MISSING_PAGE_EMPTY:41]

[MISSING_PAGE_EMPTY:42]

## Appendix I Additional Experiments on Amazon Reviews

We complement our MovieLens experiments by demonstrating EAGLE on the public Amazon dataset [Ni et al., 2019], which consists of 9.35M products with textual descriptions, 20.9M users, 233.1M product reviews, and 82.83M ratings. We focus specifically on a subset of this dataset comprising the category "Clothing, Shoes and Jewelry," which consists of 5.7M reviews for 1.5M products.

We use the same textual user profiles, user embeddings, and product embeddings used in Tennenholtz et al. [2024]. Similar to MovieLens, we create five action categories from which the EAGLE agent can choose, namely: (1) design & aesthetics, (2) functionality & fit, (3) material & sustainability, (4) marketing & branding, and (5) features & details.

We employ a tree-search variant of EAGLE on the Amazon dataset. Specifically, we sample a tree of depth \(H=5\) and select the best leaf based on the overall utility. The tree is created using a G-optimal design, as described in Sec. 5.

Appendix I show results comparing EAGLE with G-optimal design (based on tree search) to the baseline reference policy. We use AI-feedback to simulate a rater feedback, using a Gemini model. We use the same question format as presented to human raters to query Gemini (effectively treating the LLM as a simulated rater). We find that EAGLE manages to substantially increase utility. This LLM/AI-rater evaluation also shows that EAGLE substantially improves user utility, while allowing for improved distance.

We observed that EAGLE is particularly sensitive to the quality of the textual user profiles, especially those that do not describe the full extent of as user's preferences or utility. Future work should consider improving user profiles based on such datasets to enable better evaluation and training of personalized models.

In the remainder of this appendix, we provide some qualitative results of EAGLE generations on the Amazon dataset (analogous to those above for MovieLens 25M).

[MISSING_PAGE_FAIL:44]

## Appendix I Additional Experiments

1. Review the marketing materials to emphasize the delicate details and littering silhouette of the Nine West Women's Daystream Dress Pump, highlighting its sophisticated and understated elegance instead of focusing solely on trendy aspects.
2. Add a subtle, consecutive element to the side of the pump, such as a small, elegant custom or a delicate embellishment, to enhance its visual appeal without overwhelming its undersorted elegance.
3. Offer the Nine West Women's Daystream Dress Pump in a rich, deep black color instead of faded black to enhance its luxurious appearance and appeal to customers who prefer a classic, sophisticated load.
4. Ensure the Nine West Women's Daystream Dress Pump is designed with a comfortable, non-restrictive fit to avoid discomfort and enhance the overall user experience.
5. Refine the marketing copy to emphasize the pump's affordability while maintaining its image of understated luxury, appealing to the user's preference for inexpensive yet high-quality items.

## Appendix II New Product Description

### Lookin Fine Ladies Leggings

Brightly colored luggings are a huge fashion DO this year! Go casual and could during the day, or dress them up for a girls night on its style. Controllable, thin, and nearly invisible underneath clothes. You could wear these leggings underneath any skirt, music, or dress any day of the work, to almost any occasional! These durable, versatile, and fashionable legging are almost yours, and quantities are limited? This style comes in many color options: Aqua, Black, Brown, Charoland Gray, Wee Red, Hot Park, Line Green, Navy Blue, Neon Lime Green, Neon Orange, Neon Pink, Neon Yellow, Purple, Red, Turugoue, White and Yellow. Future is composed of 2060 most likely. Hard work in cold water and lung to dry, or for best results dry clean. If this is not the style of Ladies leggings you were looking for today, then please continue browsing our other listings for additional styles and colors available.

### Lookin Fine Ladies Leggings

Brightly colored luggings are a huge fashion DO this year! Go casual and could during the day, or dress them up for a girls night on its style. Controllable, thin, and nearly invisible underneath clothes. You could wear these leggings underneath any skirt, music, or dress any day of the work, to almost any occasional! These durable, versatile, and fashionable leggings are almost yours, and quantities are limited? This style comes in many color options: Aqua, Black, Brown, Charoland Gray, Wee Red, Hot Park, Line Green, Navy Blue, Neon Lime Green, Neon Orange, Neon Pink, Neon Yellow, Purple, Red, Turugoue, White and Yellow. Future is composed of 2060 most likely. Hard work in cold water and lung to dry, or for best results dry clean. If this is not the style of Ladies leggings you were looking for today, then please continue browsing our other listings for additional styles and colors available.

### Lookin Fine Ladies Leggings

Brightly colored luggings are a huge fashion DO this year! Go casual and could during the day, or dress them up for a girls night on its style. Controllable and luxurious, these leggings are nearly invisible underneath clothes. You could wear these leggings underneath any skirt, music, or dress any day of the work, to almost any occasion! These durable, versatile, and fashionable leggings are almost yours, and quantities are limited? This style comes in a sophisticated range of colors, including rich jused themes, normal earth tones, and a few classic bright options: Black, Brown, Charoland Gray, Fire Red, Navy Blue, Purple, Red, Turugoue, Emerald Green, Soyphire Blue, and Row Gold. Fabric is composed of a luxurious blend of substantially scored pima cotton and silk. Features a higher-quality waistband with reinforced stacking for enhanced durability and comfort, these leggings offer superior quality and lasting over. Available in a wider range of sizes to accommodate diverse body types, these leggings cause a perfect fit for every woman. Bobby embellished with an elegant logo tag on the waistband, these leggings evade understated luxury. Hand wash in cold water and lung to dry, or for best results dry clean. If this is so the style of Ladies leggings you were looking for today, then please continue browsing our other listings for additional styles and colors available.

[MISSING_PAGE_EMPTY:46]

[MISSING_PAGE_FAIL:47]

## Appendix A.1 Additional results

1. Add individual product photos showing the exact print and color combinations of each stir in the 3-piece pack, to manage customer expectations and reduce disappointment from receiving a random assortment.
2. Rename the product to highlight the unique, handcrafted nature of the stirts, such as "Pack of 3 Unique Handcrafted Reversible Art Silk Sari Wirp Shirts".
3. Add a detailed description of the suit fabrics used, specifying the type of silk and any embelliments, to emphasize quality and car/community.
4. Highlights the versatility of the skirts by suggesting styling options and aortic combinations in the product description.
5. Specify the source of the suit fabrics and mention any ethical or sustainable scenario practices, if applicable, to appeal to conscious consumers.

## Appendix A.2 Additional results

1. Add individual product photos showing the exact print and color combinations of each stir in the 3-piece pack, to manage customer expectations and reduce disappointment from receiving a random assortment.
2. Rename the product to highlight the unique, handcrafted nature of the stirts, such as "Pack of 3 Unique Handcrafted Reversible Art Silk Sari Wirp Shirts".
3. Add a detailed description of the suit fabrics used, specifying the type of silk and any embelliments, to emphasize quality and car/community.
4. Highlights the versatility of the skirts by suggesting styling options and aortic combinations in the product description.
5. Specify the source of the suit fabrics and mention any ethical or sustainable scenario practices, if applicable, to appeal to conscious consumers.

## Appendix A.3 Additional results

1. Add individual product photos showing the exact print and color combinations of each stir in the 3-piece pack, to manage customer expectations and reduce disappointment from receiving a random assortment.
2. Rename the product to highlight the unique, handcrafted nature of the stirts, such as "Pack of 3 Unique Handcrafted Reversible Art Silk Sari Wirp Shirts".
3. Add a detailed description of the suit fabrics used, specifying the type of silk and any embelliments, to emphasize quality and car/community.
4. Highlights the versatility of the skirts by suggesting styling options and aortic combinations in the product description.
5. Specify the source of the suit fabrics and mention any ethical or sustainable scenario practices, if applicable, to appeal to conscious consumers.

## Appendix A.4 Additional results

1. Add individual product photos showing the exact print and color combinations of each stir in the 3-piece pack, to manage customer expectations and reduce disappointment from receiving a random assortment.
2. Rename the product to highlight the unique, handcrafted nature of the stirts, such as "Pack of 3 Unique Handcrafted Reversible Art Silk Sari Wirp Shirts".
3. Add a detailed description of the suit fabrics used, specifying the type of silk and any embelliments, to emphasize quality and car/community.
4. Highlights the versatility of the skirts by suggesting styling options and aortic combinations in the product description.
5. Specify the source of the suit fabrics and mention any ethical or sustainable scenario practices, if applicable, to appeal to conscious consumers.

## Appendix A.5 Additional results

1. Add individual product photos showing the exact print and color combinations of each stir in the 3-piece pack, to manage customer expectations and reduce disappointment from receiving a random assortment.
2. Rename the product to highlight the unique, handcrafted nature of the stirts, such as "Pack of 3 Unique Handcrafted Reversible Art Silk Sari Wirp Shirts".
3. Add a detailed description of the suit fabrics used, specifying the type of silk and any embelliments, to emphasize quality and car/community.
4. Highlights the versatility of the skirts by suggesting styling options and aortic combinations in the product description.
5. Specify the source of the suit fabrics and mention any ethical or sustainable scenario practices, if applicable, to appeal to conscious consumers.

## Appendix A.6 Additional results

1. Add individual product photos showing the exact print and color combinations of each stir in the 3-piece pack, to manage customer expectations and reduce disappointment from receiving a random assortment.
2. Rename the product to highlight the unique, handcrafted nature of the stirts, such as "Pack of 3 Unique Handcrafted Reversible Art Silk Sari Wirp Shirts".
3. Add a detailed description of the suit fabrics used, specifying the type of silk and any embelliments, to emphasize quality and car/community.
4. Highlights the versatility of the skirts by suggesting styling options and aortic combinations in the product description.
5. Specify the source of the suit fabrics and mention any ethical or sustainable scenario practices, if applicable, to appeal to conscious consumers.

## Appendix A.7 Additional results

1. Add individual product photos showing the exact print and color combinations of each stir in the 3-piece pack, to manage customer expectations and reduce disappointment from receiving a random assortment.
2. Rename the product to highlight the unique, handcrafted nature of the stirts, such as "Pack of 3 Unique Handcrafted Reversible Art Silk Sari Wirp Shirts".
3. Add a detailed description of the suit fabrics used, specifying the type of silk and any embelliments, to emphasize quality and car/community.
4. Highlights the versatility of the skirts by suggesting styling options and aortic combinations in the product description.
5. Specify the source of the suit fabrics and mention any ethical or sustainable scenario practices, if applicable, to appeal to conscious consumers.

## Appendix A.8 Additional results

1. Add individual product photos showing the exact print and color combinations of each stir in the 3-piece pack, to manage customer expectations and reduce disappointment from receiving a random assortment.
2. Rename the product to highlight the unique, handcrafted nature of the stirts, such as "Pack of 3 Unique Handcrafted Reversible Art Silk Sari Wirp Shirts".
3. Add a detailed description of the suit fabrics used, specifying the type of silk and any embelliments, to emphasize quality and car/community.
4. Highlights the versatility of the skirts by suggesting styling options and aortic combinations in the product description.
5. Specify the source of the suit fabrics and mention any ethical or sustainable scenario practices, if applicable, to appeal to conscious consumers.

## Appendix A.9 Additional results

1. Add individual product photos showing the exact print and color combinations of each stir in the 3-piece pack, to manage customer expectations and reduce disappointment from receiving a random assortment.
2. Rename the product to highlight the unique, handcrafted nature of the stirts, such as "Pack of 3 Unique Handcrafted Reversible Art Silk Sari Wirp Shirts".
3. Add a detailed description of the suit fabrics used, specifying the type of silk and any embelliments, to emphasize quality and car/community.
4. Highlights the versatility of the skirts by suggesting styling options and aortic combinations in the product description.
5. Specify the source of the suit fabrics and mention any ethical or sustainable scenario practices, if applicable, to appeal to conscious consumers.

## Appendix A.10 Additional results

1. Add individual product photos showing the exact print and color combinations of each stir in the 3-piece pack, to manage customer expectations and reduce disappointment from receiving a random assortment.
2. Rename the product to highlight the unique, handcrafted nature of the stirts, such as "Pack of 3 Unique Handcrafted Reversible Art Silk Sari Wirp Shirts".
3. Add a detailed description of the suit fabrics used, specifying the type of silk and any embelliments, to emphasize quality and car/community.
4. Highlights the versatility of the skirts by suggesting styling options and aortic combinations in the product description.
5. Specify the source of the suit fabrics and mention any ethical or sustainable scenario practices, if applicable, to appeal to conscious consumers.

## Appendix A.11 Additional results

1. Add individual product photos showing the exact print and color combinations of each stir in the 3-piece pack, to manage customer expectations and reduce disappointment from receiving a random assortment.
2. Rename the product to highlight the unique, handcrafted nature of the stirts, such as "Pack of 3 Unique Handcrafted Reversible Art Silk Sari Wirp Shirts".
3. Add a detailed description of the suit fabrics used, specifying the type of silk and any embelliments, to emphasize quality and car/community.
4. Highlights the versatility of the skirts by suggesting styling options and aortic combinations in the product description.
5. Specify the source of the suit fabrics and mention any ethical or sustainable scenario practices, if applicable, to appeal to conscious consumers.

## Appendix A.11 Additional results

1. Add individual product photos showing the exact print and color combinations of each stir in the 3-piece pack, to manage customer expectations and reduce disappointment from receiving a random assortment.
2. Rename the product to highlight the unique, handcrafted nature of the stirts, such as "Pack of 3 Unique Handcrafted Reversible Art Silk Sari Wirp Shirts".
3. Add a detailed description of the suit fabrics used, specifying the type of silk and any embelliments, to emphasize quality and car/community.
4. Highlights the versatility of the skirts by suggesting styling options and aortic combinations in the product description.
5. Specify the source of the suit fabrics and mention any ethical or sustainable scenario practices, if applicable, to appeal to conscious consumers.

## Appendix A.1 Additional results

1. Add individual product photos showing the exact print and color combinations of each stir in the 3-piece pack, to manage customer expectations and reduce disappointment from receiving a random assortment.
2. Rename the product to highlight the unique, handcrafted nature of the stirts, such as "Pack of 3 Unique Handcrafted Reversible Art Silk Sari Wirp Shirts".
3. Add a detailed description of the suit fabrics used, specifying the type of silk and any embelliments, to emphasize quality and car/community.
4. Highlights the versatility of the skirts by suggesting styling options and aortic combinations in the product description.
5. Specify the source of the suit fabrics and mention any ethical or sustainable scenario practices, if applicable, to appeal to conscious consumers.

## Appendix A.11 Additional results

1. Add individual product photos showing the exact print and color combinations of each stir in the 3-piece pack, to manage customer expectations and reduce disappointment from receiving a random assortment.
2. Rename the product to highlight the unique, handcrafted nature of the stirts, such as "Pack of 3 Unique Handcrafted Reversible Art Silk Sari Wirp Shirts".
3. Add a detailed description of the suit fabrics used, specifying the type of silk and any embelliments, to emphasize quality and car/community.
4. Highlights the versatility of the skirts by suggesting styling options and aortic combinations in the product description.
5. Specify the source of the suit fabrics and mention any ethical or sustainable scenario practices, if applicable, to appeal to conscious consumers.

## Appendix A.11 Additional results

1. Add individual product photos showing the exact print and color combinations of each stir in the 3-piece pack, to manage customer expectations and reduce disappointment from receiving a random assortment.
2. Rename the product to highlight the unique, handcrafted nature of the stirts, such as "Pack of 3 Unique Handcrafted Reversible Art Silk Sari Wirp Shirts".
3. Add a detailed description of the suit fabrics used, specifying the type of silk and any embelliments, to emphasize quality and car/community.
4. Highlights the versatility of the skirts by suggesting styling options and aortic combinations in the product description.
5. Specify the source of the suit fabrics and mention any ethical or sustainable scenario practices, if applicable, to appeal to conscious consumers.

## Appendix A.11 Additional results

1. Add individual product photos showing the exact print and color combinations of each stir in the 3-piece pack, to manage customer expectations and reduce disappointment from receiving a random assortment.
2. Rename the product to highlight the unique, handcrafted nature of the stirts, such as "Pack of 3 Unique Handcrafted Reversible Art Silk Sari Wirp Shirts".
3. Add a detailed description of the suit fabrics used, specifying the type of silk and any embelliments, to emphasize quality and car/community.
4. Highlights the versatility of the skirts by suggesting styling options and aortic combinations in the product description.
5. Specify the source of the suit fabrics and mention any ethical or sustainable scenario practices, if applicable, to appeal to conscious consumers.

## Appendix A.1 Additional results

1. Add individual product photos showing the exact print and color combinations of each stir in the 3-piece pack, to manage customer expectations and reduce disappointment from receiving a random assortment.
2. Rename the product to highlight the unique, handcrafted nature of the stirts, such as "Pack of 3 Unique Handcrafted Reversible Art Silk Sari Wirp Shirts".
3. Add a detailed description of the suit fabrics used, specifying the type of silk and any embelliments, to emphasize quality and car/community.
4. Highlights the versatility of the skirts by suggesting styling options and aortic combinations in the product description.
5. Specify the source of the suit fabrics and mention any ethical or sustainable scenario practices, if applicable, to appeal to conscious consumers.

## Appendix A.1 Additional results

1. Add individual product photos showing the exact print and color combinations of each stir in the 3-piece pack, to manage customer expectations and reduce disappointment from receiving a random assortment.
2. Rename the product to highlight the unique, handcrafted nature of the stirts, such as "Pack of 3 Unique Handcrafted Reversible Art Silk Sari Wirp Shirts".
3. Add a detailed description of the suit fabrics used, specifying the type of silk and any embelliments, to emphasize quality and car/community.
4. Highlights the versatility of the skirts by suggesting styling options and aortic combinations in the product description.
5. Specify the source of the suit fabrics and mention any ethical or sustainable scenario practices, if applicable, to appeal to conscious consumers.

## Appendix A.2 Additional results

1. Add individual product photos showing the exact print and color combinations of each stir in the 3-piece pack, to manage customer expectations and reduce disappointment from receiving a random assortment.
2. Rename the product to highlight the unique, handcrafted nature of the stirts, such as "Pack of 3 Unique Handcrafted Reversible Art Silk Sari Wirp Shirts".
3. Add a detailed description of the suit fabrics used, specifying the type of silk and any embelliments, to emphasize quality and car/community.
4. Highlights the versatility of the skirts by suggesting styling options and aortic combinations in the product description.
5. Specify the source of the suit fabrics and mention any ethical or sustainable scenario practices, if applicable, to appeal to conscious consumers.

## Appendix A.3 Additional results

1. Add individual product photos showing the exact print and color combinations of each stir in the 3-piece pack, to manage customer expectations and reduce disappointment from receiving a random assortment.
2. Rename the product to highlight the unique, handcrafted nature of the stirts, such as "Pack of 3 Unique Handcrafted Reversible Art Silk Sari Wirp Shirts".
3. Add a detailed description of the suit fabrics used, specifying the type of silk and any embelliments, to emphasize quality and car/community.
4. Highlights the versatility of the skirts by suggesting styling options and aortic combinations in the product description.
5. Specify the source of the suit fabrics and mention any ethical or sustainable scenario practices, if applicable, to appeal to conscious

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: Limitations are discussed throughout the paper, but particularly, we discuss many of the limitations in Appendix B. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [NA]Justification:

Guidelines:

* The answer NA means that the paper does not include theoretical results.
* All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
* All assumptions should be clearly stated or referenced in the statement of any theorems.
* The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.
* Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.
* Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: See Appendix E Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?Answer: [No] Justification: The dataset can be regenerated using the provided prompts and the available Gemini model API. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: Details are provided in Secs. 5 and 6 and appendix E. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors).

* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: See Appendix E Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: See Appendix A Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.

* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pre-trained language models, image generators, or scraped datasets)? Answer: [NA] Justification: Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licensees for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.

* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [Yes] Justification: See footnote 5 on Page 7, and also Appendix G. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.