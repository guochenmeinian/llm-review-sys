# Discrete-Smoothness in

Online Algorithms with Predictions

 Yossi Azar

Tel Aviv University

azar@tau.ac.il &Debmalya Panigrahi

Duke University

debmalya@cs.duke.edu &Noam Touitou

Amazon

noamtux@gmail.com

This paper does not relate to the author's work at Amazon.

###### Abstract

In recent years, there has been an increasing focus on designing online algorithms with (machine-learned) predictions. The ideal learning-augmented algorithm is comparable to the optimum when given perfect predictions (_consistency_), to the best online approximation for arbitrary predictions (_robustness_), and should interpolate between these extremes as a smooth function of the prediction error. In this paper, we quantify these guarantees in terms of a general property that we call _discrete-smoothness_ and achieve discrete-smooth algorithms for online covering, specifically the facility location and set cover problems. For set cover, our work improves the results of Bamas, Maggiori, and Svensson (2020) by augmenting consistency and robustness with smoothness guarantees. For facility location, our work improves on prior work by Almanza et al. (2021) by generalizing to nonuniform costs and also providing smoothness guarantees by augmenting consistency and robustness.

## 1 Introduction

The field of _learning-augmented online algorithms_ has gained rapid prominence in recent years. The basic premise is to provide an online algorithm with additional (machine-learned) predictions about the future to help bypass worst-case lower bounds. Since machine-learned predictions can be noisy in general, a key desideratum of the model is that the _competitive ratio_ of the online algorithm should degrade gracefully with prediction error. In particular, the cost of the algorithm should be bounded against that of the predicted solution (called _consistency_) or that of an online algorithm without predictions (called _robustness_) and should smoothly interpolate between the two with increase in prediction error (called _smoothness_). (The terms consistency and robustness were originally coined by Purohit, Svitkina, and Kumar [38].) While robustness and consistency are problem-independent notions, smoothness depends on prediction error which has been defined in a problem-specific manner. In this paper, we introduce a novel, problem-independent notion of smoothness called _discrete-smoothness_ that applies to any combinatorial problem. As illustrative applications of this new framework, we design discrete-smooth (learning-augmented) algorithms for two classic problems, _facility location_ and _set cover_, which improve and generalize previous results for these problems due to Almanza et al. (NeurIPS '21 [1]) and Bamas et al. (NeurIPS '20 [11]).

First, we introduce discrete-smoothness. Suppose we are given a problem instance of size \(n\). Let OPT be a solution for this instance. (The reader may think of OPT as an optimal solution, although our guarantees will hold for any feasible solution.) Let the predicted solution be \(S\). Ideally, \(S=\text{OPT}\); therefore, in general, OPT comprises two parts: the predicted part \(\text{OPT}|_{S}:=\text{OPT}\cap S\) and the unpredicted part \(\text{OPT}|_{\overline{S}}:=\text{OPT}\setminus S\). On the predicted part \(\text{OPT}|_{S}\), the algorithm has a meaningful signal from the prediction but the noise in the signal is given by the overprediction \(s_{\Delta}:=|S\setminus\text{OPT}|\). Naturally, the competitive ratio of the algorithm on this part will degrade with increase in this noise. On the unpredicted part \(\text{OPT}|_{\overline{S}}\), the algorithm does not have any signal from the prediction andcannot hope for a better competitive ratio than that of an online algorithm without prediction. Slightly abusing notation, we use \(\mathrm{OPT}|_{S},\mathrm{OPT}|_{\overline{S}}\) to denote both the aforementioned sets of items and their total cost; putting the two together, a learning-augmented algorithm ALG should satisfy

\[\mathrm{ALG}\leq O(f(s_{\Delta}))\cdot\mathrm{OPT}|_{S}+O(f(n))\cdot\mathrm{ OPT}|_{\overline{S}},\] (1)

where \(O(f(\cdot))\) is the competitive ratio without prediction. We call the property of Equation (1) _discrete-smoothness_.

Let us first argue that Equation (1) recovers consistency and robustness. Consistency follows from setting \(S=\mathrm{OPT}\); then, Equation (1) demands a constant approximation to \(\mathrm{OPT}\). Similarly, robustness follows from the fact that for any \(S\), the right hand side of Equation (1) is at most \(O(f(n))\cdot\mathrm{OPT}\).

Next, we show that the two terms \(f(s_{\Delta})\) and \(f(n)\) in Equation (1) are the best possible. For the first term, consider a prediction \(S\) comprising the entire instance (of size \(n\)); in this case, we cannot hope for the better than \(f(n)\)-competitive algorithm; thus, \(f(s_{\Delta})\) is necessary in the first term. And, for the second term, consider an empty prediction \(S=\emptyset\), in which case we again cannot hope for a better than \(f(n)\)-competitive algorithm; thus, \(f(n)\) is necessary in the second term. Note that the asymmetry between these two terms is necessary: specifically, \(f(n)\) cannot be replaced by \(f(|\mathrm{OPT}\setminus S|)\) since that would imply an \(f(\mathrm{OPT})\)-competitive online algorithm when \(S=\emptyset\). This is impossible, e.g., for the set cover problem.

A technical subtlety of the definition of discrete-smoothness (Equation (1)) is that given a fixed prediction \(S\), the minimum value of the right hand side might actually be a solution \(\mathrm{OPT}\) that is different from an optimal solution to the problem instance. So, although the solution \(\mathrm{OPT}\) is intuitively an optimal solution, we require that a discrete-smooth algorithm satisfy Equation (1) for _all_ feasible solutions \(\mathrm{OPT}\), and not just optimal solutions.

### Our Results

We apply discrete-smoothness to the classic problems of online facility location and set cover. For these problems, we obtain results that improve on prior work. We describe these next.

Online Facility Location with Predictions.In the online facility location problem, we are given offline a metric space \((X,\delta)\) of \(m:=|X|\) points, where each point \(v\in X\) has an associated facility opening cost \(o_{v}\geq 0\). On receiving an online request for a client at some location \(x\in X\), the online algorithm must connect the client to an open facility at some location \(v\in X\) incurring connection cost \(\delta(x,v)\). At any time, the algorithm is also allowed to open a facility at any location \(v\in X\) by incurring the opening cost \(o_{v}\). (Note that a client cannot update her connection even if a closer facility is opened later.) The total cost of the algorithm is the sum of opening costs of opened facilities and connection costs of clients.

The first result for the online facility location problem is due to Meyerson [33] who obtained a randomized algorithm with a competitive ratio of \(O(\log n)\) for \(n\) requests. This result was first derandomized [18], and later the competitive ratio slightly improved to \(O\left(\frac{\log n}{\log\log n}\right)\)[19], by Fotakis. This latter bound is asymptotically tight. More recently, the online facility location problem has been considered in the context of machine-learned _predictions_ (OFLP) by several papers [20; 1; 22]. Of these, the work of Almanza et al. [1] is the closest to our work (the other papers use metric error measures that are incomparable to our results). In [1], the offline input additionally contains a predicted solution of facilities \(S\subseteq X\), where we denote \(|S|=s\). By restricting the available facilities to the predicted set, they obtained an \(O(\log s)\)-competitive algorithm for uniform facility opening costs, under the condition that \(\mathrm{OPT}\subseteq S\).

We improve and generalize the Almanza et al. work by giving a discrete-smooth algorithm for the OFLP problem, i.e., an algorithm ALG that satisfies Equation (1):

**Theorem 1.1**.: _There is an algorithm ALG for online (nonuniform) facility location with a predicted solution \(S\) that satisfies for every solution \(\mathrm{OPT}\)_

\[\mathrm{ALG}\leq O(\log s_{\Delta})\cdot\mathrm{OPT}|_{S}+O(\log n)\cdot \mathrm{OPT}|_{\overline{S}},\] (2)

_where \(s_{\Delta}\) is the number of facilities in \(S\backslash\mathrm{OPT}\) and \(n\) is the number of online requests. Here, \(\mathrm{OPT}|_{S}\) (resp., \(\mathrm{OPT}|_{\overline{S}}\)) represents the sum of opening costs of facilities in \(\mathrm{OPT}\cap S\) (resp., \(\mathrm{OPT}\setminus S\)) and connection costs of all clients connecting to facilities in \(\mathrm{OPT}\cap S\) (resp., \(\mathrm{OPT}\setminus S\))._This generalizes and improves the Almanza et al. result in three ways:

* The result is generalized from uniform facility opening costs to arbitrary (nonuniform) costs. In fact, even for the online facility location problem (without prediction), we get an \(O\left(\log m\right)\)-competitive algorithm for arbitrary (nonuniform) facility opening costs -- previously, Almanza et al. only established this for uniform costs.
* The assumption that \(\mathrm{OPT}\subseteq S\), i.e., the prediction contains the entire solution, is no longer required.
* If \(\mathrm{OPT}\subseteq S\) (i.e., under the assumption of the Almanza et al. result), the competitive ratio improves from \(O\left(\log s\right)\) to \(O\left(\log s_{\Delta}\right)\). That is, the dependence is only on the prediction error and not the entire prediction.

In some situations, the length of the request sequence \(n\) can exceed the size of the metric space \(m\). To address this situation, we show that \(n\) can be replaced by \(m\) in the above result:

**Theorem 1.2**.: _There is an algorithm \(\mathrm{ALG}\) for online (nonuniform) facility location with a predicted solution \(S\) that satisfies for every solution \(\mathrm{OPT}\)_

\[\mathrm{ALG}\leq O\left(\log s_{\Delta}\right)\cdot\mathrm{OPT}|_{S}+O\left( \log m\right)\cdot\mathrm{OPT}|_{\overline{S}},\] (3)

_where \(m\) is the number of facilities in the metric space overall._

Online Set Cover with Predictions.In the online set cover problem, we are given offline a universe of elements \(E\) and \(m\) sets defined on them \(U\subseteq 2^{E}\) with nonnegative costs. In each online step, we get a new element \(e\in E\). If \(e\) is not already covered by the current solution, then the algorithm must add a new set from \(U\) that contains \(e\) to its solution. The total cost of the algorithm is the sum of costs of all sets in its solution.

Alon et al. [3] gave the first algorithm for the online set cover problem by introducing the online primal dual method, and obtained a competitive ratio of \(O\left(\log m\log n\right)\) where \(n\) denotes the number of requests. They also proved an almost matching lower bound of \(\Omega\left(\frac{\log m\log n}{\log\log m\log\log n}\right)\). Bamas, Maggiori, and Svensson [11] extended their work to online set cover _with predictions_ (OSCP), where the offline input additionally contains a predicted solution of sets \(S\subseteq U\). They established consistency and robustness bounds for this problem by adapting the online primal dual method to use the predicted solution. The cost of their algorithm is bounded by the minimum of \(O\left(\log n\right)\) times the cost of the prediction and \(O\left(\log m\log n\right)\) times the optimal cost. However, one cannot achieve smoothness through their work without choosing a trust parameter correctly in advance of the input.

We obtain a discrete-smooth algorithm for the OSCP problem, thereby giving the first algorithm for OSCP that goes beyond only consistency and robustness and achieves a smoothness guarantee:

**Theorem 1.3**.: _There is an algorithm \(\mathrm{ALG}\) for online set cover with a predicted solution \(S\) that satisfies for every solution \(\mathrm{OPT}\)_

\[\mathrm{ALG}\leq O\left(\log s_{\Delta}\log n\right)\cdot\mathrm{OPT}|_{S}+O \left(\log m\log n\right)\cdot\mathrm{OPT}|_{\overline{S}},\] (4)

_where \(s_{\Delta}\) is the number of sets in \(S\backslash\mathrm{OPT}\). Here, \(\mathrm{OPT}|_{S}\) (resp., \(\mathrm{OPT}|_{\overline{S}}\)) represents the sum of costs of sets in \(\mathrm{OPT}\cap S\) (resp., \(\mathrm{OPT}\setminus\overline{S}\))._

### Our Techniques: A Framework for Discrete-Smooth Algorithms

At a high level, our framework merges two online algorithms to obtain a discrete-smooth algorithm. The algorithms differ in the guarantees they provide. The first algorithm \(\mathrm{ALG}_{1}\) gets a sharper competitive ratio of \(O\left(f(s)\right)\) but against the optimal solution restricted to the prediction \(S\). The second algorithm \(\mathrm{ALG}_{2}\) has the standard competitive ratio of \(O\left(f(n)\right)\) but against the unconstrained optimum \(\mathrm{OPT}\). The main challenge in the combiner algorithm (call it \(\mathrm{ALG}\)) is to decide how to route online requests to the two algorithms. The natural choice would be to decide this based on whether \(\mathrm{OPT}|_{S}\) or \(\mathrm{OPT}_{\overline{S}}\) serves the request in \(\mathrm{OPT}\): in the first case, the request should be routed to \(\mathrm{ALG}_{1}\) and in the second case, it should be routed to \(\mathrm{ALG}_{2}\). But, of course, we do not know \(\mathrm{OPT}\) and therefore don't know \(\mathrm{OPT}|_{S}\) and \(\mathrm{OPT}|_{\overline{S}}\).

Before we describe the combiner strategy, consider the properties that these algorithms need to satisfy.

* First, consider the _subset_ of requests served by \(\mathrm{OPT}|_{S}\). Intuitively, \(\mathrm{ALG}_{1}\) should be competitive on these requests, which means that we need a stronger property from \(\mathrm{ALG}_{1}\) that its cost on any subset of requests is competitive against the optimal solution for this subset. We call this property _subset competitiveness_.2 Symmetrically, subset competitiveness of \(\mathrm{ALG}_{2}\) ensures that it is competitive on the requests in \(\mathrm{OPT}|_{\overline{S}}\). Footnote 2: Our subset-competitiveness property is similar to [9].
* Next, we need a guarantee on the cost of \(\mathrm{ALG}_{1}\) on \(\mathrm{OPT}|_{\overline{S}}\), and symmetrically, of \(\mathrm{ALG}_{2}\) on \(\mathrm{OPT}|_{S}\). For this, we first augment \(\mathrm{ALG}_{1},\mathrm{ALG}_{2}\) to address the _prize-collecting_ version of the original problem, where each online request can be ignored at a _penalty cost_. (Note that this is more general than the original problem where every online request must be served, since the latter can be recovered by setting the penalties to be infinitely large.) Setting the penalties appropriately, we ensure that the total penalty of the requests in \(\mathrm{OPT}|_{S}\) is bounded against the cost of \(\mathrm{ALG}_{1}\) on those requests (similarly for \(\mathrm{OPT}|_{\overline{S}}\)).
* Finally, we require that the cost of \(\mathrm{ALG}_{1},\mathrm{ALG}_{2}\) on any set of requests is bounded against the total penalty of the requests. We call this strengthened competitiveness w.r.t. penalties the _Lagrangian property_3. Note that this ensures that the cost of \(\mathrm{ALG}_{1},\mathrm{ALG}_{2}\) on \(\mathrm{OPT}|_{\overline{S}},\mathrm{OPT}|_{S}\) are respectively bounded. Footnote 3: Our Lagrangian competitiveness is similar to the Lagrangian multiplier preserving property in approximation algorithms for prize-collecting problems, e.g., [37, 26].

Now, we give the formal definition of Lagrangian subset-competitiveness that we motivated above. We use \(\mathrm{ALG}(Q^{\prime}|Q)\) to refer to the total cost of \(\mathrm{ALG}\) incurred when addressing a subset \(Q^{\prime}\subseteq Q\) as part of running on an input \(Q\). For any prize collecting solution SOL for input \(Q\), we separate its total cost into \(\mathrm{SOL}^{b}(Q)\) (buying cost) and \(\mathrm{SOL}^{p}(Q)\) (penalty cost). We formalize the Lagrangian subset-competitiveness property below:

**Definition 1.4** (Lagrangian subset-competitive algorithm).: Let \(\mathrm{ALG}\) be a randomized prize-collecting algorithm running on an input \(Q\). For any competitive ratio \(\beta\), we say that \(\mathrm{ALG}\) is Lagrangian \(\beta\)-subset-competitive if for every subset \(Q^{\prime}\subseteq Q\) we have

\[\mathbb{E}[\mathrm{ALG}(Q^{\prime}|Q)]\leq\beta\cdot\mathrm{OPT}^{b}(Q^{\prime })+O(1)\cdot\mathrm{OPT}^{p}(Q^{\prime})\] (5)

If in the equation above we replace the unconstrained optimum (OPT) by the optimal solution that can only use the prediction \(S\), we say that \(\mathrm{ALG}\) is Lagrangian \(\beta\)-subset-competitive w.r.t. \(S\).

We now give the combiner algorithm:

```
1 Let \(\mathrm{ALG}_{1},\mathrm{ALG}_{2}\) be two prize-collecting Lagrangian subset-competitive algorithms.
2Event Function\(\textsc{UponRequest}(q)\)
3 Let \(\alpha\) be the minimum penalty such that releasing \((q,\alpha)\) to \(\mathrm{ALG}_{1},\mathrm{ALG}_{2}\) would result in the request being served in either \(\mathrm{ALG}_{1}\) or \(\mathrm{ALG}_{2}\). (The value of \(\alpha\) can be determined by a standard "guess-and-double".)
4 Release \((q,\alpha)\) to both \(\mathrm{ALG}_{1}\) and \(\mathrm{ALG}_{2}\). Buy the items bought by \(\mathrm{ALG}_{1},\mathrm{ALG}_{2}\) as a result of this step. ```

**Algorithm 1** Smooth merging framework (The combiner algorithm)

The algorithm is simple: for a new online request \(q\), the framework chooses the minimum penalty \(\alpha\) which ensures that at least one of the two constituent algorithms \(\mathrm{ALG}_{1},\mathrm{ALG}_{2}\) would actually serve \(q\) (instead of paying the penalty). \((q,\alpha)\) is then presented as a (prize-collecting) request to both algorithms. (Recall that the combined algorithm is for the non-prize-collecting problem, but the individual algorithms \(\mathrm{ALG}_{1},\mathrm{ALG}_{2}\) are for the prize-collecting problem.) At this stage, one of the algorithms serves the request (due to the choice of \(\alpha\)) while the other may choose to pay the penalty. The combiner algorithm now simply buys all items bought by either algorithm.

Finally, we state the guarantees of the combiner algorithm informally. (For a formal description, see Appendix C.)

**Theorem 1.5**.: _(Informal) If \(\mathrm{ALG}_{1},\mathrm{ALG}_{2}\) are Lagrangian \(\beta\)-subset-competitive algorithms for \(\beta=f(s)\), \(f(n)\) respectively, then Algorithm 1 satisfies the discrete-smoothness property (Equation (1)._

**Applications of Theorem 1.5:** Section 3 and Appendix B give Lagrangian subset-competitive algorithms for facility location, and Section 4 gives a Lagrangian subset-competitive algorithm for set cover. Given these constituent algorithms, we use Theorem 1.5 to prove Theorem 1.1 and Theorem 1.2 for facility location and Theorem 1.3 for set cover. These proofs are given in Appendix D.

Related Work.There is a growing body of work in online algorithms with predictions in the last few years (see, e.g., the surveys [35; 36]). This model was introduced by Lykouris and Vassilvitskii for the caching problem [32] and has since been studied for a variety of problem classes: rent or buy [27; 25; 21; 41; 5; 39], covering [11], scheduling [27; 41; 10; 28; 34; 30; 8], caching [31; 40; 24; 13], matching [29; 16; 7; 23], graph problems [6; 22; 1; 14; 4; 20; 9], and so on. Prior works on online facility location with predictions either do not consider prediction error [1] or use continuous notions of error [22; 20], such as functions of the distances between predicted and optimal facilities. Our discrete notion of error refers only to whether an optimal item is predicted. Similarly, prior work on online set cover with predictions [11; 4] also does not consider prediction error. Finally, we note that discrete prediction error (similar to this paper) as well as hybrids between discrete and continuous error have also been considered [42; 9; 14] but the prediction here is on the input rather than the solution.

## 2 The Framework

We now describe some of the concepts of the framework in more detail.

**Reduction from \(s_{\delta}\) to \(s\).** Recall that we seek discrete-smooth algorithms, i.e., satisfying Equation (1). Our first step is to give a generic reduction that allows us to slightly weaken the guarantee to the following:

\[\mathrm{ALG}\leq O(f(s))\cdot\mathrm{OPT}|_{S}+O(f(n))\cdot\mathrm{OPT}|_{ \widetilde{S}},\] (6)

where \(O(f(\cdot))\) is the competitive ratio without predictions. We give a reduction from an algorithm that satisfies Equation (6) to one that satisfies Equation (1):

**Theorem 2.1**.: _Given an algorithm \(\mathrm{ALG}^{\prime}\) such that \(\mathrm{ALG}^{\prime}\leq O(f(s))\cdot\mathrm{OPT}|_{S}+O(g)\cdot\mathrm{OPT}| _{\widetilde{S}}\), there exists an algorithm \(\mathrm{ALG}\) such that \(\mathrm{ALG}\leq O(f(s_{\Delta}))\cdot\mathrm{OPT}|_{S}+O(g)\cdot\mathrm{OPT }|_{S}\)._

The proof of this theorem, in Appendix E, is roughly the following: for every integer \(i\), once the cost of the algorithm exceeds \(2^{i}\), we buy the cheapest predicted items of total cost at most \(2^{i}\), and then remove them from the prediction. While \(2^{i}<\mathrm{OPT}\), the total cost is \(O(1)\cdot\mathrm{OPT}\); once \(2^{i}\) exceeds OPT, the size of the prediction is at most \(s_{\Delta}\), and Equation (6) implies Equation (1).

**Monotonicity.** An additional, natural property that we demand from a constituent algorithm in our smooth combination framework is that increasing the penalty of input requests does not decrease the cost incurred by the algorithm. This is stated formally in the following definition.

**Definition 2.2**.: We say that a prize-collecting algorithm \(\mathrm{ALG}\) is _monotone_ if, fixing the input request prefix \(((q_{i},\pi_{i}))_{i=1}^{k-1}\) and current request \((q_{k},\pi_{k})\), then increasing \(\pi_{k}\) does not decrease \(\mathrm{ALG}(q_{k},\pi_{k})\).

**Online amortization.** Our framework extends to the case where Lagrangian subset-competitiveness and monotonicity are satisfied by _amortized_ costs instead of actual costs. This is important because for some problems, the actual cost expressly prohibits subset competitiveness. For example, consider facility location: given an input of multiple, identical requests with very small penalty, the algorithm should eventually stop paying penalties and open a facility. However, for the specific request upon which the facility is opened, the cost of the algorithm is much larger than the penalty for that request, the latter being optimal for just that request. To overcome this complication, we allow the cost for a request to be amortized over previous requests, and call this _online amortization_.

First, we define online amortization of costs, and define a "monotone" online amortization which can be used in our framework.

**Definition 2.3** (online amortization).: Let \(Q=((q_{1},\pi_{1}),\cdots,(q_{n},\pi_{n}))\) be an online input given to \(\mathrm{ALG}\). An _online amortization_ or \(\mathrm{OA}\) is a number sequence \((\mathrm{OA}(q,\pi))_{(q,\pi)\in Q}\) such that:

1. \(\mathrm{ALG}(Q)\leq\sum_{(q,\pi)\in Q}\mathrm{OA}(q,\pi)\).
2. \(\mathrm{OA}(q_{i},\pi_{i})\) is only a function of \((q_{1},\pi_{1}),\cdots,(q_{i},\pi_{i})\), and can thus be calculated online.

When considering the amortized cost of an algorithm, we use similar notation to the actual cost: on an input \(Q\), we use \(\textsc{oa}(Q)\) to denote the total amortized cost. We also use \(\textsc{oa}(Q^{\prime}|Q)\) to denote the total amortized cost incurred on a request subset \(Q^{\prime}\subseteq Q\). In addition, for a request \((q,\pi)\) in the input \(Q\), we use \(\textsc{oa}(q,\pi)\) to refer to the amortized cost of \((q,\pi)\); here the input \(Q\) is clear from context.

**Definition 2.4** (monotone online amortization).: We call an online amortization \(\textsc{oa}\)_monotone_ if **(a)** fixing previous requests, increasing the penalty of request \((q,\pi)\) never decreases \(\textsc{oa}(q,\pi)\), and **(b)** when the algorithm pays penalty for \((q,\pi)\) then \(\textsc{oa}(q,\pi)\geq\pi\).

The Main TheoremWe are now ready to state the main theorem of our algorithmic framework. We use \(\beta_{1}\) and \(\beta_{2}\) to denote the competitive ratios of \(\textsc{ALG}_{1}\) and \(\textsc{ALG}_{2}\); the reader should think of \(\beta_{1}\) as \(O(f(s))\) and \(\beta_{2}\) as \(O(f(n))\), i.e., \(\beta_{2}\gg\beta_{1}\).

**Theorem 2.5**.: _Consider any online covering problem with predictions \(\mathcal{P}\). Let \(\textsc{ALG}_{1},\textsc{ALG}_{2}\) be two algorithms for the prize-collecting version of \(\mathcal{P}\) with monotone (online amortized) costs \(\textsc{oa}_{1},\textsc{oa}_{2}\) respectively such that **(a)**\(\textsc{ALG}_{1}\) is Lagrangian \(\beta_{1}\)-subset-competitive using \(\textsc{oa}_{1}\) w.r.t. the prediction \(S\), and **(b)**\(\textsc{ALG}_{2}\) is Lagrangian \(\beta_{2}\)-subset-competitive using \(\textsc{oa}_{2}\) (against general \(\mathrm{OPT}\))._

_Then there exists \(\textsc{ALG}\) for \(\mathcal{P}\) such that for every partition of the input \(Q\) into \(Q_{1},Q_{2}\) we have_

\[\textsc{ALG}(Q)\leq O(\beta_{1})\cdot\mathrm{OPT}_{S}(Q_{1})+O(\beta_{2})\cdot \mathrm{OPT}(Q_{2})\]

We later show that Theorem 2.5 implies Equation (6) for facility location and set cover.

## 3 Online Facility Location

In this section, we consider metric, nonuniform facility location with predictions and present a novel prize-collecting algorithm TreeProxy. This algorithm is Lagrangian \(O(\log|S|)\)-subset-competitive w.r.t. the prediction \(S\) of possible facilities; thus, it is used in our framework to prove Theorems D.2 and D.3, which in turn imply Theorems 1.1 and 1.2, respectively. In addition, TreeProxy is a result independent of our framework/predictions: the competitiveness guarantee shown for TreeProxy also achieves \(O(\log m)\) competitiveness where \(m=|X|\) is the size of the metric space. We prove the following theorem:

**Theorem 3.1**.: _For facility location with predictions, there exists a randomized prize-collecting algorithm \(\textsc{ALG}\) with a monotone online amortization \(\textsc{oa}\) which is Lagrangian \(O(\log|S|)\)-subset competitive using \(\textsc{oa}\) w.r.t. \(S\)._

### The Algorithm

**Weighted hierarchically-separated trees (HSTs).** The algorithm starts by embedding the metric space into the leaves of a weighted \(3\)-HST, a metric space in which edge weights decrease at least exponentially as one descends from the root.

**Definition 3.2**.: For \(\gamma>1\), a rooted tree with weights \(c\) to the edges is a _weighted \(\gamma\)-HST_ if for every two edges \(e_{1},e_{2}\) such that \(e_{2}\) is a parent edge of \(e_{1}\), it holds that \(c(e_{2})\geq\gamma c(e_{1})\).

The following result is often used for embedding general metric spaces into weighted HSTs; it involves composing the embeddings of Fakcharoenphol et al. [17] and Bansal et al. [12].

**Theorem 3.3** (Due to [17] and [12]).: _For every metric space \((X,\delta)\) and constant \(\gamma\), there exists a distribution \(\mathcal{D}\) over weighted \(\gamma\)-HSTs of depth \(O(\log|X|)\) in which the points in \(X\) are the leaves of the HST, such that for every two points \(x_{1},x_{2}\in X\) we have:_

1. \(\delta(x_{1},x_{2})\leq\delta_{T}(x_{1},x_{2})\) _for every_ \(T\) _in the support of_ \(\mathcal{D}\)_._
2. \(\mathbb{E}_{T\sim\mathcal{D}}\left[\delta_{T}(x_{1},x_{2})\right]\leq O(\log|X| )\cdot\delta(x_{1},x_{2})\)_._

The algorithm starts by embedding the induced metric space of \(S\) into a weighted HST using Theorem 3.3; \(T\) denotes the resulting tree, and \(r\) denotes its root. For each edge \(e\in T\), we denote by \(c(e)\) the cost of the edge \(e\). Denote the set of leaves in the subtree rooted at \(v\) by \(L(v)\); note that \(L(r)=S\). Denote the distance between two nodes \(u,v\) in the tree by \(\delta_{T}(u,v)\). For every point \(u\in X\), define \(p(u):=\arg\min_{u^{\prime}\in S}\delta(u,u^{\prime})\); that is, \(p(u)\) is the closest predicted point to \(u\) (abusing notation, we similarly define \(p(q)\) for request \(q\)).

**Proxy list.** After embedding \(S\) into the leaves of a tree, the algorithm must open facilities on those leaves to serve requests. Intuitively, at any point the algorithm considers some (possibly internal) node \(v\in T\), and considers connecting the current request through \(v\) to a facility in \(L(v)\). Choosing from \(L(v)\) introduces a tradeoff between the cost of opening the facility and its distance from \(v\). For every \(v\), we identify the leaves in \(L(v)\) which offer the best points in this tradeoff (i.e., a Pareto frontier), and only allow the algorithm to choose from these leaves. This subset is called the _proxy list_ of \(v\), and denoted \(P(v)\subseteq L(v)\).

We now define the proxy list \(P(v)\). For ease of notation, define the logarithmic class operator \(\ell(x):=\lfloor\log x\rfloor\). For node \(v\in T\), we construct the proxy list \(P(v)\subseteq L(v)\) as follows:

1. Start with \(V\gets L(v)\).
2. While there exist distinct \(v_{1},v_{2}\in V\) such that \(\ell(o_{v_{1}})\geq\ell(o_{v_{2}})\) and \(\ell(\delta_{T}(v,v_{1}))\geq\ell(\delta_{T}(v,v_{2}))\), remove \(v_{1}\) from \(V\).
3. Output \(V\) as \(P(v)\).

We denote by \(k(v)\) the size of the proxy list \(P(v)\). We order the proxy list of \(v\) by increasing facility cost, thus writing \(P(v)=(s_{1}^{v},\cdots,s_{k(v)}^{v})\). For every \(v,i\), we use the shorthands \(o_{i}^{v}:=o_{s_{i}^{v}}\) and \(\delta_{i}^{v}:=\delta_{T}(v,s_{i}^{v})\). Slightly abusing notation, for every node \(v\in T\) we define \(c(v):=c(e_{v})\) where \(e_{v}\) is the edge connecting \(v\) to its parent node (for \(r\), we define \(c(r)=\infty\)). For a more streamlined notation, for every node \(v\in T\) we define \(\delta_{0}^{v}:=c(v)\) and \(o_{k(v)+1}^{v}:=\infty\).

**Observation 3.4**.: _For every node \(v\in T\), the proxy list \(P(v)\) satisfies:_

1. _For every_ \(u\in L(v)\)_, there exists index_ \(i\) _such that_ \(\ell(o_{i}^{v})\leq\ell(o_{u})\) _and_ \(\ell(\delta_{t}^{v})\leq\ell(\delta_{T}(v,u))\)_._
2. _For every distinct_ \(1\leq i<j\leq k(v)+1\)_, it holds that_ \(\ell(o_{i}^{v})<\ell(o_{j}^{v})\)_._
3. _For every distinct_ \(0\leq i<j\leq k(v)\)_, it holds that_ \(\ell(\delta_{i}^{v})>\ell(\delta_{j}^{v})\)_._

When \(i=0\), the third item in Observation 3.4 uses the fact that \(T\) is a weighted \(3\)-HST; thus, the cost of an edge is at least twice the distance from the child node of that edge to any descendant leaf.

**Counters.** For every node \(v\) and every \(i\in\{1,\cdots k(v)+1\}\), we define a counter \(\lambda(v,i)\) of size \(o_{i}^{v}\).

**Algorithm description.** The algorithm for facility location with predictions is given in Algorithm 2. Initially, the algorithm embeds the metric space induced by \(S\) into a weighted \(3\)-HST \(T\), using Theorem 3.3; upon each node in this \(T\) the proxy lists are computed, and the corresponding counters are assigned. Upon the release of a request \((q,\pi)\), the function UponRequest is triggered. Upon receiving \((q,\pi)\), it maps the request to the closest point \(p(q)\) in \(S\) (that is, a leaf of the HST). Then, the algorithm attempts to solve the request on the HST through a process of increasing counters, which we soon describe. (While the described algorithm raises these counters continuously, the process can easily be discretized, replacing the continuous growth with jumping discretely to the next event.) The algorithm keeps track of (some measure of) the cost involved; if during UponRequest that amount exceeds the penalty \(\pi\), the algorithm pays the penalty instead (see Line 9).

When solving the request on \(u=p(q)\), the algorithm climbs up the branch of \(u\), until a facility is found (or opened) to connect \(u\). At each ancestor \(v\) of \(u\), the algorithm invests a growing amount \(\tau_{v}\) in advancing the proxy list of \(v\) (i.e., buying a facility in \(P(v)\) closer to \(v\)). It raises the counter for the next item on the proxy list until full, at which point the relevant proxy facility is opened, and the next counter in the proxy list begins to increase. (Note that the same facility can be "opened" more than once due to being on multiple proxy lists.) Once \(\tau_{v}\) reaches the cost of connecting \(v\) to an open proxy, the algorithm stops increasing counters and makes the connection. When no proxy in \(P(v)\) is open, it could be that \(\tau_{v}\) exceeds the cost of moving from \(v\) to its parent \(p(v)\); in this case, we ascend the branch and explore proxies for \(p(v)\). Note that the function UponRequest of Algorithm 2 also returns a value; this return value is the online amortization cost of the request, to be used in the analysis of the algorithm. (See Figure 1 for an example.)

The analysis of Algorithm 2, and the proof of Theorem 3.1, appear in Appendix A.

## 4 Online Set Cover

In this section, we present and analyze an algorithm for prize-collecting fractional set cover which uses the well-known multiplicative updates method, and show that it is Lagrangian subset-competitive. Using this algorithm together with Algorithm 1 yields Theorem 1.3 (the proof appears in Appendix C).

Preliminaries.In prize-collecting fractional set cover, we are given a universe with elements \(E\) and sets \(U\); we define \(m:=|U|\). A solution may fractionally buy sets, according to a cost function \(c\). Requests then arrive online, where each request is for covering some element \(e\in E\), which is contained in some subfamily of sets from \(U\). To cover an element, an algorithm must hold fractions of sets containing \(e\) which sum to at least 1. Observe that fractional set cover with predictions conforms to the definition of an online covering problem with predictions; in this problem, the items are the sets. For prize-collecting fractional set cover, we prove the following theorem.

**Theorem 4.1**.: _There exists a deterministic algorithm \(\mathrm{ALG}\) for prize-collecting fractional set cover that \(\mathrm{ALG}\) is Lagrangian \(O(\log m)\)-subset-competitive_

Theorem 4.1 implies that, in the framework of Algorithm 1, our algorithm can be used as the general component, independent of the prediction. But, given a prediction \(S\subseteq U\), we can simply restrict the

Figure 1: A possible state of Algorithm 2, immediately before connecting a request \(q\). Here, \(q\) has been mapped to \(u\), which is the closest point in \(S\). The variable \(v\), an ancestor of \(u\), is shown, as is its proxy list \(s_{1}^{v},s_{2}^{v},s_{3}^{v}\). The counters of the proxy list are also shown: \(\hat{\lambda}(v,1)\) is full (and a facility thus exists in \(s_{1}^{v}\)), and \(\lambda(v,2)\) is partial (the last counter to be raised handling \(q\)). At some point, the growth in the counters of \(v\) exceeded the distance from \(v\) to \(s_{1}^{v}\), and thus the connection of \(q\) to \(s_{1}^{v}\) is made.

family of sets used by the algorithm to the given prediction, yields an algorithm competitive against \(\textsc{OPT}_{S}\). Thus, Theorem 4.1 immediately yields the following corollary.

**Corollary 4.2**.: _There exists a deterministic algorithm \(\mathrm{ALG}\) for prize-collecting fractional set cover such that \(\mathrm{ALG}\) is Lagrangian \(O(\log m^{\prime})\)-subset-competitive w.r.t. prediction \(S\subseteq U\), where \(|S|=m^{\prime}\)._

The Algorithm.The algorithm for prize-collecting set cover is given in Algorithm 3. The algorithm follows the standard multiplicative updates method: while the pending request is uncovered, sets containing that request are bought at an exponential rate (see [2, 15]). However, in this prize-collecting version, the algorithm never lets its cost for a specific request exceed its penalty. For ease of notation, define \(U(q)\) to be the collection of sets containing \(q\); that is, \(U(q):=\{s\in U|q\in s\}\).

**Analysis.** Where the input \(Q\) is fixed, and for \((q,\pi)\in Q\), we use \(\mathrm{ALG}(q,\pi)\) as a shorthand for \(\mathrm{ALG}(\{(q,\pi)\}|Q)\); i.e., the cost of \(\mathrm{ALG}\) when handling the request \((q,\pi)\) as part of \(Q\). We prove the two following lemmas:

**Lemma 4.3**.: _For every \((q,\pi)\in Q\), it holds that \(\mathrm{ALG}(q,\pi)\leq 3\pi\)._

**Lemma 4.4**.: _For every subset \(Q^{\prime}\subseteq Q\), we have \(\mathrm{ALG}(Q^{\prime}|Q)\leq O(\log m)\cdot\mathrm{OPT}(\overline{Q^{\prime }})\), where \(\overline{Q^{\prime}}\) is the non-prize-collecting input formed from \(Q^{\prime}\)._

These two lemmas imply _penalty-robust subset competitiveness_, a property shown in Proposition C.2 to be equivalent to Lagrangian subset-competitiveness. Thus, we focus on proving these lemmas; note that the proof of Lemma 4.4 appears in Appendix F.

**Proposition 4.5**.: _In every iteration of \(\textsc{UponRequest}(q,\pi)\), it holds that the total buying cost is at most \(2y_{q}\), where \(y_{q}\) is the final value of the variable of the same name._

Proof.: Consider each time \(y_{q}\) is incremented. The total cost of buying sets is the following.

\[\sum_{s\in U(q)}c_{s}\cdot\left(x_{s}\cdot\frac{1}{c_{s}}+\frac{1}{|U(q)|c_{s} }\right)=1+\sum_{s\in U(q)}x_{s}\leq 2\]

where the inequality is due to the fact that \(\sum_{s\in U(q)}x_{s}\leq 1\). Thus, each time \(y_{q}\) is incremented by \(1\), the cost of buying sets is at most \(2\), completing the proof. 

Proof of Lemma 4.3.: Consider \(\textsc{UponRequest}(q,\pi)\). If it returned through Line 11, it holds that \(y_{q}\leq\pi\); Proposition 4.5 shows that the total buying cost was thus at most \(2\pi\), and this cost is also \(\mathrm{ALG}(q,\pi)\). Otherwise, the function returned through Line 8; in this case, since \(y_{q}\) was incremented immediately before comparing \(y_{q}\) to \(\pi\), the argument from the proof of Proposition 4.5 implies that the total buying cost is at most \(2(y_{q}-1)\) (using the final value of \(y_{q}\)). In turn, this is at most \(2\pi\). In addition, the algorithm paid the penalty of \(\pi\); overall, \(\mathrm{ALG}(q,\pi)\leq 3\pi\). 

Proof of Theorem 4.1.: Lemma 4.3 and Lemma 4.4 show that the algorithm is \(O(\log m)\)-PRSC; Proposition C.2 then yields that the algorithm is Lagrangian \(O(\log m)\)-subset-competitive. 

## 5 Experiments

Input Generation.Our set cover instances contain \(100\) elements. (The number of sets will vary in the experiments.) Every set contains every element with some constant probability \(\alpha\) (we choose \(\alpha=0.02\)); that is, the input is represented by a random bipartite graph in which each edge manifests independently. Since this may not cover every element, we also add singleton sets for all elements. We generate random costs for the sets, independently drawn from a log-normal distribution (\(\mu=0,\sigma=1.6\)). For a given input, we generate a prediction in the following way:

1. Using an LP solver, we obtain an optimal fractional solution to the problem instance.
2. We randomly round the solution, such that every set appears in the prediction with probability proportional to its value in the fractional solution.
3. We apply noise to the prediction, of two types: false-positive noise, in which every set is added to the prediction with some probability \(p\); and false-negative noise, in which every set is removed from the prediction with some probability \(q\). (The reader should think of \(p\) and \(q\) as the classification error where the predictions were generated using a classifier.)4. Finally, we add the singleton sets to the prediction, to ensure that the prediction covers all elements.

Baselines and evaluation.We evaluate our algorithm described in Section 4, denoted SmoothMerge, against three baselines: the standard online algorithm without predictions, denoted On; the online algorithm restricted to predicted sets, denoted PredOn; and the standard merging BaseMerge of those two algorithms, which alternates between On and PredOn whenever the overall cost doubles. For every choice of parameters, we measure the costs of the four algorithms; these costs are then averaged over 300 different random inputs. We then measure the expected competitive ratio of each algorithm. Our experiments were run on an AWS EC2 r5.16xlarge machine.

We ran the following experiments: (a) we vary the false-positive rate \(p\) and the false-negative rate \(q\) keeping the number of sets fixed at 10000 (Table 1), and (b) we vary the number of sets in the input, fixing \(p=0.005,q=0.15\) (Figure 2).

Experimental Results.We ran two sets of experiments. In the first experiment, we varied the false-positive rate \(p\) and the false-negative rate \(q\) keeping the number of sets fixed at 10000. The results are reported in Table 1. We note that our algorithm SmoothMerge outperforms the standard merging algorithm BaseMerge and the online algorithm without predictions On consistently across all values of \(p,q\). SmoothMerge also outperforms PredOn, the online algorithm restricted to the prediction, except when there are no false negatives, i.e., \(q=0\). This is to be expected because \(q=0\) implies that there is a good solution contained in the prediction. When \(q>0\), PredOn fails miserably and our algorithm SmoothMerge obtains a competitive ratio that is an order of magnitude better than PredOn. This demonstrates the lack of robustness of PredOn because it is specifically tuned to correct predictions.

In the second set of experiments, we varied the number of sets in the input fixing the noise rates \(p=0.005,q=0.15\). The results are reported in Figure 2. Our algorithm SmoothMerge consistently outperforms all the baseline algorithms. In particular, it is able to utilize predictions to outperform On, which the standard merging BaseMerge is unable to achieve. Moreover, as the number of sets in the input grows, the gap between the two merging solutions increases.

## 6 Discussion

In this paper, we presented a novel framework for smooth interpolation between robustness and consistency guarantees in learning-augmented online algorithms, and applied it to set cover and facility location. More broadly, predictions for online algorithms are of two forms: prediction of the input and that of the solution. The notion of discrete-smoothness applies to any online combinatorial problem in the latter category, i.e., where a solution is provided in the form of a prediction to the algorithm. Many problems have been considered in this model including rent or buy problems, scheduling, matching, graph problems, etc. For all of these problems, the discrete-smoothness framework alleviates the need for problem-specific notions of prediction error and instead gives a common framework for arguing about the gradual degradation of solution quality with increase in prediction error. We hope that the current work will streamline the desiderata for learning-augmented online algorithms by adding this problem-independent notion of smoothness to the established (and also problem-independent) properties of consistency and robustness.

## Acknowledgments

YA was supported in part by the Israel Science Foundation (grant No. 2304/20). DP was supported in part by NSF awards CCF-1750140 (CAREER) and CCF-1955703.

## References

* [1] Matteo Almanza, Flavio Chierichetti, Silvio Lattanzi, Alessandro Panconesi, and Giuseppe Re. Online facility location with multiple advice. In Marc'Aurelio Ranzato, Alina Beygelzimer, Yann N. Dauphin, Percy Liang, and Jennifer Wortman Vaughan, editors, _Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual_, pages 4661-4673, 2021.
* [2] Noga Alon, Baruch Awerbuch, Yossi Azar, Niv Buchbinder, and Joseph Naor. The online set cover problem. In Lawrence L. Larmore and Michel X. Goemans, editors, _Proceedings of the 35th Annual ACM Symposium on Theory of Computing, June 9-11, 2003, San Diego, CA, USA_, pages 100-105. ACM, 2003.
* [3] Noga Alon, Baruch Awerbuch, Yossi Azar, Niv Buchbinder, and Joseph Naor. The online set cover problem. _SIAM J. Comput._, 39(2):361-370, 2009.
* [4] Keerti Anand, Rong Ge, Amit Kumar, and Debmalya Panigrahi. Online algorithms with multiple predictions. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato, editors, _International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland, USA_, volume 162 of _Proceedings of Machine Learning Research_, pages 582-598. PMLR, 2022.
* [5] Keerti Anand, Rong Ge, and Debmalya Panigrahi. Customizing ML predictions for online algorithms. In _Proceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event_, volume 119 of _Proceedings of Machine Learning Research_, pages 303-313. PMLR, 2020.
* [6] Antonios Antoniadis, Christian Coester, Marek Elias, Adam Polak, and Bertrand Simon. Online metric algorithms with untrusted predictions. In _Proceedings of the 37th International Conference on Machine Learning,ICML 2020_, 2020.
* [7] Antonios Antoniadis, Themis Gouleakis, Pieter Kleer, and Pavel Kolev. Secretary and online matching problems with machine learned advice. In Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin, editors, _Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual_, 2020.
* [8] Yossi Azar, Stefano Leonardi, and Noam Touitou. Flow time scheduling with uncertain processing time. In Samir Khuller and Virginia Vassilevska Williams, editors, _STOC '21: 53rd Annual ACM SIGACT Symposium on Theory of Computing, Virtual Event, Italy, June 21-25, 2021_, pages 1070-1080. ACM, 2021.
* 12, 2022_, pages 35-66. SIAM, 2022.
* [10] Etienne Bamas, Andreas Maggiori, Lars Rohwedder, and Ola Svensson. Learning augmented energy minimization via speed scaling. In Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin, editors, _Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual_, 2020.
* [11] Etienne Bamas, Andreas Maggiori, and Ola Svensson. The primal-dual method for learning augmented algorithms. In Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin, editors, _Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual_, 2020.

* [12] Nikhil Bansal, Niv Buchbinder, Aleksander Madry, and Joseph Naor. A polylogarithmic-competitive algorithm for the k-server problem. In Rafail Ostrovsky, editor, _IEEE 52nd Annual Symposium on Foundations of Computer Science, FOCS 2011, Palm Springs, CA, USA, October 22-25, 2011_, pages 267-276. IEEE Computer Society, 2011.
* [13] Nikhil Bansal, Christian Coester, Ravi Kumar, Manish Purohit, and Erik Vee. Scale-free allocation, amortized convexity, and myopic weighted paging. _CoRR_, abs/2011.09076, 2020.
* [14] Giulia Bernardini, Alexander Lindermayr, Alberto Marchetti-Spaccamela, Nicole Megow, Leen Stougie, and Michelle Swereing. A universal error measure for input predictions applied to online graph problems. In _NeurIPS_, 2022.
* [15] Niv Buchbinder and Joseph Naor. The design of competitive online algorithms via a primal-dual approach. _Found. Trends Theor. Comput. Sci._, 3(2-3):93-263, 2009.
* [16] Paul Dutting, Silvio Lattanzi, Renato Paes Leme, and Sergei Vassilvitskii. Secretaries with advice. In Peter Biro, Shuchi Chawla, and Federico Echenique, editors, _EC '21: The 22nd ACM Conference on Economics and Computation, Budapest, Hungary, July 18-23, 2021_, pages 409-429. ACM, 2021.
* [17] Jittat Fakcharoenphol, Satish Rao, and Kunal Talwar. A tight bound on approximating arbitrary metrics by tree metrics. _Journal of Computer and System Sciences_, 69(3):485-497, 2004. Special Issue on STOC 2003.
* [18] Dimitris Fotakis. A primal-dual algorithm for online non-uniform facility location. _J. Discrete Algorithms_, 5(1):141-148, 2007.
* [19] Dimitris Fotakis. On the competitive ratio for online facility location. _Algorithmica_, 50(1):1-57, 2008.
* [20] Dimitris Fotakis, Evangelia Gergatsouli, Themis Gouleakis, and Nikolas Patris. Learning augmented online facility location. _CoRR_, abs/2107.08277, 2021.
* [21] Sreenivas Gollapudi and Debmalya Panigrahi. Online algorithms for rent-or-buy with expert advice. In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, _Proceedings of the 36th International Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA_, volume 97 of _Proceedings of Machine Learning Research_, pages 2319-2327. PMLR, 2019.
* [22] Shaofeng H.-C. Jiang, Erzhi Liu, You Lyu, Zhihao Gavin Tang, and Yubo Zhang. Online facility location with predictions. In _The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022_. OpenReview.net, 2022.
* [23] Zhihao Jiang, Pinyan Lu, Zhihao Gavin Tang, and Yuhao Zhang. Online selection problems against constrained adversary. In Marina Meila and Tong Zhang, editors, _Proceedings of the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event_, volume 139 of _Proceedings of Machine Learning Research_, pages 5002-5012. PMLR, 2021.
* [24] Zhihao Jiang, Debmalya Panigrahi, and Kevin Sun. Online algorithms for weighted caching with predictions. In _47th International Colloquium on Automata, Languages, and Programming, ICALP 2020_, 2020.
* [25] Ali Khanafer, Murali Kodialam, and Krishna P. N. Puttaswamy. The constrained ski-rental problem and its application to online cloud cost optimization. In _Proceedings of the INFOCOM_, pages 1492-1500, 2013.
* [26] Jochen Konemann, Sina Sadeghian Sadeghabad, and Laura Sanita. An LMP o(log n)-approximation algorithm for node weighted prize collecting steiner tree. In _54th Annual IEEE Symposium on Foundations of Computer Science, FOCS 2013, 26-29 October, 2013, Berkeley, CA, USA_, pages 568-577. IEEE Computer Society, 2013.

* [27] Ravi Kumar, Manish Purohit, and Zoya Svitkina. Improving online algorithms via ML predictions. In Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicolo Cesa-Bianchi, and Roman Garnett, editors, _Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montreal, Canada_, pages 9684-9693, 2018.
* [28] Silvio Lattanzi, Thomas Lavastida, Benjamin Moseley, and Sergei Vassilvitskii. Online scheduling via learned weights. In Shuchi Chawla, editor, _Proceedings of the 2020 ACM-SIAM Symposium on Discrete Algorithms, SODA 2020, Salt Lake City, UT, USA, January 5-8, 2020_, pages 1859-1877. SIAM, 2020.
* Leibniz-Zentrum fur Informatik, 2021.
* 2 July, 2021_, pages 107-123. ACM, 2021.
* [31] Thodoris Lykouris and Sergei Vassilvitskii. Competitive caching with machine learned advice. In Jennifer G. Dy and Andreas Krause, editors, _Proceedings of the 35th International Conference on Machine Learning, ICML 2018, Stockholmsmassan, Stockholm, Sweden, July 10-15, 2018_, volume 80 of _Proceedings of Machine Learning Research_, pages 3302-3311. PMLR, 2018.
* [32] Thodoris Lykouris and Sergei Vassilvitskii. Competitive caching with machine learned advice. _J. ACM_, 68(4):24:1-24:25, 2021.
* [33] Adam Meyerson. Online facility location. In _42nd Annual Symposium on Foundations of Computer Science, FOCS 2001, 14-17 October 2001, Las Vegas, Nevada, USA_, pages 426-431, 2001.
* Leibniz-Zentrum fur Informatik, 2020.
* [35] Michael Mitzenmacher and Sergei Vassilvitskii. Algorithms with predictions. In Tim Roughgarden, editor, _Beyond the Worst-Case Analysis of Algorithms_, pages 646-662. Cambridge University Press, 2020.
* [36] Michael Mitzenmacher and Sergei Vassilvitskii. Algorithms with predictions. _Commun. ACM_, 65(7):33-35, 2022.
* [37] Anna Moss and Yuval Rabani. Approximation algorithms for constrained node weighted steiner tree problems. _SIAM J. Comput._, 37(2):460-481, 2007.
* [38] Manish Purohit, Zoya Svitkina, and Ravi Kumar. Improving online algorithms via ML predictions. In Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicolo Cesa-Bianchi, and Roman Garnett, editors, _Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montreal, Canada_, pages 9684-9693, 2018.
* [39] Shufan Wang, Jian Li, and Shiqiang Wang. Online algorithms for multi-shop ski rental with machine learned advice. In Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin, editors, _Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual_, 2020.

- Leibniz-Zentrum fur Informatik, 2020.
* [41] Alexander Wei and Fred Zhang. Optimal robustness-consistency trade-offs for learning-augmented online algorithms. In Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin, editors, _Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual_, 2020.
* March 1, 2022_, pages 8744-8752. AAAI Press, 2022.
Analysis of Algorithm 2

For this analysis section, we fix any input \(Q=((q_{1},\pi_{1}),\cdots,(q_{n},\pi_{n}))\). For both ALG and \(\textsc{OPT}_{S}\) we use the superscript \(\mathrm{f}\) to refer only to facility opening costs and \(\mathrm{c}\) to refer only to connection costs. We denote by \(\textsc{oa}(q,\pi)\) the value returned by UponRequest in Algorithm 2 upon receiving the pair \((q,\pi)\); we choose \((\textsc{oa}(q,\pi))\) as the online amortization of Algorithm 2.

**Online Amortization.** First, we show that the cost of the algorithm is bounded by the online amortization:

**Lemma A.1**.: _It holds that \(\textsc{ALG}(Q)\leq\textsc{oa}(Q)\)._

Proof.: We use the subscript \(q\) to refer to the final value of a variable in UponRequest\((q,\pi)\). The cost of the algorithm has the following three components:

1. Penalties paid.
2. Opening costs for facilities in \(S\).
3. Connection costs for facilities in \(S\).

Let \(Q^{\prime}\subseteq Q\) be the set of requests served by the algorithm (i.e., no penalty was paid).

**Penalties for requests in \(Q\backslash Q^{\prime}\).** Consider that whenever a penalty \(\pi\) is paid for a request in Line 10, the additive term \(\pi\) appears in the amortized cost of that request. We charge the penalty cost to that term.

**Opening cost.** Note that a facility \(s_{i}^{v}\) is only opened (at cost \(o_{i}^{v}\)) when the counter \(\lambda(v,i)\) reaches \(o_{i}^{v}\), and that counter is never used again; thus, the total opening cost can be charged to the sum over request \(q\) of the amount by which request \(q\) raises counters, which is \(\tau_{q}\). We charge this to the term \(\tau_{q}\) in \(\textsc{oa}(q,\pi)\).

**Connection cost for requests in \(Q^{\prime}\).** Suppose a request \((q,\pi)\in Q^{\prime}\) is connected to some point \(w\in S\). There exists an index \(i\) such that \(w=s_{i}^{v_{q}}\). It holds that

\[\delta(q,w)\leq\delta\big{(}q,u_{q}\big{)}+\delta\big{(}u_{q},w\big{)}\leq \delta(q,S)+\delta_{T}\big{(}u_{q},w\big{)}\leq\delta(q,S)+\delta_{T}\big{(}u_ {q},v_{q}\big{)}+\delta_{T}\big{(}v_{q},w\big{)}.\] (7)

where the first and third inequalities are due to the triangle inequality, and the second inequality is due to the definition of \(u_{q}\) and Theorem 3.3. Now, note that \(\delta_{T}\big{(}v_{q},w\big{)}=\delta_{i}^{v_{q}}\leq\tau_{q}^{v_{q}}\) from the condition of Line 16.

Enumerate the path in the tree between \(u_{q}\) and \(v_{q}\) as \(u_{q}=w_{0},w_{1},\cdots,w_{k}=v_{q}\), and note that \(\delta_{T}\big{(}u_{q},v_{q}\big{)}=\sum_{j=0}^{k-1}c\big{(}w_{j}\big{)}\). Now, note that the variable \(v\) advanced from \(w_{j}\) to \(w_{j+1}\) due to \(\tau_{q}^{w_{j}}\geq c\big{(}w_{j}\big{)}\); thus, \(\delta_{T}\big{(}u_{q},v_{q}\big{)}=\sum_{j=0}^{k-1}\tau_{q}^{w_{j}}\). Finally, note that \(\sum_{j=0}^{k}\tau_{q}^{w_{j}}=\tau_{q}\); combining, we get

\[\delta_{T}\big{(}u_{q},v_{q}\big{)}+\delta_{T}\big{(}v_{q},w\big{)}\leq\sum_ {j=0}^{k}\tau^{w_{j}}=\tau_{q}\]

Plugging the above into Equation (7), we get \(\delta(q,w)\leq\tau_{q}+\delta(q,S)\). We thus charge the connection cost of requests from \(Q^{\prime}\) to the \((\tau_{q}+\delta(q,S))\) term in \(\textsc{oa}(q,\pi)\).

This completes the proof of the lemma. 

**Observation A.2**.: _The online amortization oa of Algorithm 2 is monotone._

**Bounding Amortized Costs.** Having shown that the online amortization is valid and monotone, it remains to bound the amortized cost of the algorithm. To show that the algorithm is Lagrangian subset-competitive, it is enough to show that it is PRSC; see Proposition C.2. We thus focus on showing that the algorithm is PRSC using oa w.r.t. \(S\).

From this point on, for every node \(v\in T\) and index \(i\in[k(v)+1]\), we slightly abuse notation and use \(\lambda(v,i)\) to refer to both the counter itself, and its value at the end of the algorithm.

**Proposition A.3** (Penalty Robustness).: _For every \((q,\pi)\in Q\), it holds that \(\textsc{oa}(q,\pi)\leq 2\pi\)._Proof.: If \(\textsc{UponRequest}(q,\pi)\) returns in Line 22, then it must be that the condition in Line 9 has failed, and thus \(\tau+\delta(u,q)\leq\pi\); thus, \(\textsc{oa}(q,\pi)=\tau+(\tau+\delta(u,q))\leq 2\pi\).

Otherwise, \(\textsc{UponRequest}(q,\pi)\) returned on Line 11, in which case note that since \(\tau\) is raised continuously from \(0\), Line 11 ensures that \(\tau\leq\pi\) at all times. Thus, \(\textsc{oa}(q,\pi)=\tau+\pi\leq 2\pi\), completing the proof. 

It remains to show subset competitiveness for the algorithm. Henceforth, fix any subset of the input \(Q^{\prime}\subseteq Q\).

**Proposition A.4**.: _For every request \(q\) and \(v\in T\), \(\tau_{q}^{v}\leq c(v)\)._

Proof.: Observe that \(\tau_{q}^{v}\) cannot exceed \(\delta_{t(v)}^{v}\), for some current value of \(t(v)\), or else the request is connected (or escalated to a parent node). The fact that \(\delta_{0}^{v}=c(v)\), together with the fact that \(\delta_{l}^{v}\) is a decreasing sequence in \(i\) (Observation 3.4) complete the proof. 

We now begin to bound the (amortized) costs of the algorithm. Recall that \(\overline{Q^{\prime}}\) is the input \(Q^{\prime}\) with the penalties set to infinity; that is, the prize-collecting input converted to the standard setting. We would like to prove the following lemma.

**Lemma A.5**.: \(\mathbb{E}[\textsc{oa}(Q^{\prime}|Q)]\leq O(\log(|S|))\cdot\textsc{OPT}_{S} \Big{(}\overline{Q^{\prime}}\Big{)}\)_._

When the input consists of requests that are also from \(S\), both the clients and facilities are from \(S\), and thus on the leaves of the tree \(T\). In this case, we define \(\textsc{OPT}_{T}\) to be any solution for the input under the metric space induced by the weighted HST \(T\). To prove Lemma A.5, we first bound the cost of the algorithm against \(\textsc{OPT}_{T}\) on a set of clients mapped to their closest neighbors in \(S\).

**Lemma A.6**.: _Let \(Q^{\prime}_{S}\) be the input formed from \(Q^{\prime}\) by mapping each request \((q,\pi)\in Q^{\prime}\) to the request \((p(q),\pi)\). It holds that_

\[\textsc{oa}(Q^{\prime}|Q)\leq\sum_{(q,\pi)\in Q^{\prime}}\delta(q,S)+O(D) \cdot\textsc{OPT}_{T}^{f}\Big{(}\overline{Q^{\prime}_{S}}\Big{)}+O(1)\cdot \textsc{OPT}_{T}^{c}\Big{(}\overline{Q^{\prime}_{S}}\Big{)}\]

Proof.: First, observe both **return** statements in Algorithm 2 and note that for every request \((q,\pi)\in Q\) it holds that

\[\textsc{oa}(q,\pi)\leq 2\tau_{q}+\delta(q,S).\] (8)

We now focus on bounding \(\sum_{(q,\pi)\in Q^{\prime}}\tau_{q}\), i.e., total amount by which counters are raised when handling \(Q^{\prime}\). Let \(w\) be a facility opened in \(\textsc{OPT}_{T}(\overline{Q^{\prime}_{S}})\). Let \(R\subseteq Q^{\prime}\) be the set of requests such that their corresponding requests in \(\overline{Q^{\prime}_{S}}\) are connected by \(\textsc{OPT}_{T}\) to the facility \(w\). Using Observation 3.4, for every ancestor tree node \(v\) of \(w\), we define \(i_{v}\) to be the minimal index such that \(\ell(o^{v}_{i_{v}})\leq\ell(o_{w})\) and \(\ell(\delta^{v}_{i_{v}})\leq\ell(\delta_{T}(v,w))\).

Let \(P(w)=(v_{0}=w,v_{1},\cdots,v_{k}=r)\) be the path from \(w\) to the root. The sum \(\sum_{(q,\pi)\in Q^{\prime}}\tau_{q}\) can be divided as follows:

1. Raising counters \(\lambda(v,i)\) for \(v\in P(w)\), \(i\leq i_{v}\). The total amount here is at most \[\sum_{v\in P(w)}\sum_{i=1}^{i_{v}}\lambda(v,i) \leq\sum_{v\in P(w)}\sum_{i=1}^{i_{v}}o^{v}_{i}\leq\sum_{i=1}^{i_ {v}}2^{\ell(o^{v}_{i})+1}\leq\sum_{v\in P(w)}2^{\ell(o^{v}_{i_{v}})+2}\] \[\leq\sum_{v\in P(w)}2^{\ell(o_{w})+2}\leq\sum_{v\in P(w)}4o_{w} \leq 4Do_{w}.\]
2. Raising counters \(\lambda(v,i)\) for \(v\notin P(w)\). Consider a request \(q\in R\), and define \(u:=p(q)=u\) and \(v\) to be the lowest common ancestor of \(u\) and \(w\). The only nodes not in \(P(w)\) in which counters are raised when handling \(q\) are on the path from \(u\) (inclusive) to \(v\) (non-inclusive). Using Proposition A.4, the total increase in counters for these nodes is at most \(\delta_{T}(u,v)\).

3. Raising counters \(\lambda(v,i)\) for \(v\in P(w)\) and \(i>i_{v}\). Suppose that a request \(q\) raises such a counter \(\lambda(v_{j},i)\) for some node \(v_{j}\in P(w)\). When such a counter is raised, the proxy \(s_{v_{j}}^{v_{j}}\) is already open, and thus the total raising of counters of index greater than \(i_{v_{j}}\) for \(v_{j}\) by \(q\) is at most \(\delta_{v_{j}}^{v_{j}}\leq 2\delta_{w}^{v_{j}}=2\delta_{T}\big{(}v_{j},v\big{)}+2 \delta_{T}(v,w)\), where \(v\) is the lowest common ancestor of \(u\) and \(w\). (Note that other proxies of \(v_{j}\) of larger index could be open, but they can only be closer to \(v_{j}\), thus limiting the raising of counters even further.) Of those two costs, we would like to charge \(q\) only for \(2\delta_{T}(v,w)\), and charge \(2\delta_{T}\big{(}v_{j},v\big{)}\) in aggregate over all \(q\). To do so, observe that the counters for nodes in \(P(w)\backslash\{v_{j}\}\) that were raised upon request \(q\) must be of the form \(\lambda(v_{l},1)\) for \(v_{l}\in\big{\{}v_{0},\cdots,v_{j-1}\big{\}}\). As the request \(q\) was repeatedly escalated from \(v\) to \(v_{j}\), the total increase in those counters must be at least \(\delta_{T}\big{(}v,v_{j}\big{)}\), and thus \(2\delta_{T}\big{(}v,v_{j}\big{)}\) is upper bounded by twice the increase in those counters. However, as seen in Item 1, over all requests, these increases sum to at most \(4Do_{w}\) over all \(q\in R\); thus, the term \(2\delta_{T}(v_{j},v)\) sums in aggregate to at most \(8Do_{w}\).

Overall, denoting by \(w^{q}\) the lowest common ancestor of \(p(q)\) and \(w\), we get:

\[\sum_{(q,\pi)\in R}\tau(q,\pi) \leq 4Do_{w}+\sum_{(q,\pi)\in R}\delta_{T}(p(q),w^{q})+\left(8Do_{w }+\sum_{(q,\pi)\in R}\delta_{T}(w^{q},w)\right)\] \[\leq 12Do_{w}+2\delta_{T}(p(q),w).\]

Summing over all \(w\), we get

\[\sum_{(q,\pi)\in Q^{\prime}}\tau(q,\pi)\leq 12D\cdot\mathrm{OPT}_{T}^{f}\Big{(} \overline{Q^{\prime}_{S}}\Big{)}+2\cdot\mathrm{OPT}_{T}^{c}\Big{(}\overline{ Q^{\prime}_{S}}\Big{)}.\]

Combining with Equation (8), we get

\[\textsc{oa}(Q^{\prime}|Q)\leq\sum_{(q,\pi)\in Q^{\prime}}\delta(q,S)+24D\cdot \mathrm{OPT}_{T}^{f}\Big{(}\overline{Q^{\prime}_{S}}\Big{)}+4\cdot\mathrm{ OPT}_{T}^{c}\Big{(}\overline{Q^{\prime}_{S}}\Big{)}.\qed\]

Having bounded the costs of the algorithm against \(\mathrm{OPT}_{T}\), we can now prove Lemma A.5.

Proof of Lemma a.5.: Using Lemma A.6, we get the following.

\[\mathbb{E}[\textsc{oa}(Q^{\prime}|Q)]\leq\sum_{(q,\pi)\in Q^{\prime}}\delta( q,S)+\mathbb{E}\Big{[}O\left(\log(|S|)\right)\cdot\mathrm{OPT}_{T}^{f}\Big{(} \overline{Q^{\prime}_{S}}\Big{)}+O(1)\cdot\mathrm{OPT}_{T}^{c}\Big{(}\overline {Q^{\prime}_{S}}\Big{)}\Big{]}\]

Now, note that every solution \(\mathrm{OPT}_{S}(\overline{Q^{\prime}_{S}})\) induces a solution for \(\overline{Q^{\prime}_{S}}\) on \(T\), which opens the same facilities and makes the same connections (through the tree); the new tree solution has the same facility opening costs, and connection costs which are, in expectation, at most \(O(\log(|S|))\)-times greater (see Theorem 3.3). Thus, we have

\[\mathbb{E}[\textsc{oa}(Q^{\prime}|Q)]\leq\sum_{(q,\pi)\in Q^{\prime}}\delta( q,S)+O\left(\log(|S|)\right)\cdot\mathrm{OPT}_{S}\Big{(}\overline{Q^{\prime}_{S}} \Big{)}\]

Now, note that any solution \(\mathrm{OPT}_{S}\Big{(}\overline{Q^{\prime}}\Big{)}\) induces a solution for \(\overline{Q^{\prime}_{S}}\) of cost \(\sum_{(q,\pi)\in Q^{\prime}}\delta(q,S)+\mathrm{OPT}_{S}\Big{(}\overline{Q^{ \prime}}\Big{)}\), and also note that \(\sum_{(q,\pi)\in Q^{\prime}}\delta(q,S)\) is a lower bound for \(\mathrm{OPT}_{S}\Big{(}\overline{Q^{\prime}}\Big{)}\). Plugging into the displayed equation above completes the proof of the lemma. 

Proof of Theorem 3.1.: Lemma A.1 and Observation A.2 show that the online amortization oa is valid and monotone. Proposition A.3 shows penalty robustness, while Lemma A.5 shows subset competitiveness; thus, the algorithm is \(O(\log|S|)\)-PRSC using oa w.r.t. \(S\). Using Proposition C.2, the algorithm is Lagrangian \(O(\log|S|)\)-subset-competitive using oa w.r.t. \(S\).

## Appendix B Online Facility Location: The \(O(\log n)\)-Competitive Algorithm

In this section, we present and analyze a prize-collecting algorithm for facility location with predictions whose competitive ratio on the number of requests \(n=|Q|\). As is required for using Algorithm 1, this algorithm is Lagrangian subset-competitive. This algorithm is based on the work of Fotakis [18] for the non-prize-collecting setting. Specifically, we prove the following theorem.

**Theorem B.1**.: _For facility location with predictions, there exists a deterministic prize-collecting algorithm ALG with a monotone online amortization oa which is Lagrangian \(O(\log n)\)-subset-competitive using oa._

### The Algorithm

**Algorithm's description.** This algorithm follows the main principles of Fotakis [18]. Each point in the metric space has an associated potential, such that when that potential exceeds the cost of opening a facility at that point, the facility is opened. This potential roughly translates to the amount by which the cost of the offline solution for known requests would decrease by opening a facility at that location. Observing each request, consider the ball centered at that request such that the closest open facility lies on the sphere of that ball; the request imposes a potential increase for every point inside that ball. However, as the requests now have penalties, these penalties cap the radius of the ball, i.e., limit the potential imposed by the requests.

Specifically, the algorithm assigns each request a cost \(\tau_{q}\), which intuitively is the minimum cost of handling the current request. This cost could be the penalty cost, the cost of connecting to an open facility, or the cost of opening a facility (beyond the current potential budget) and then connecting to it. The algorithm spends an amortized cost of \(\tau_{q}\) to serve \(q\), but a potential ball of radius \(\tau_{q}\) is also created to serve future requests (at an future cost of at most \(\tau_{q}\)).

For every \(x\), we use \(x^{+}\) as a shorthand for \(\max\{0,x\}\). The prize-collecting algorithm based on [18] is given in Algorithm 4.

```
1Initialization Let \(Q\leftarrow\emptyset\).
2 Let \(F\leftarrow\emptyset\).
3 For every \(v\in X\), let \(p(v)\gets 0\).
4Event FunctionUponRequest(\(q,\pi\)) // Upon the next request \(q\) in the sequence on point \(u\in X\)
5 Set \(Q\gets Q\cup\{q\}\).
6 Denote \(v_{v}\gets 0\) the closest open facility to \(q\).
7 Define \(\tau_{q}\leftarrow\min\{\pi,\delta(q,F),\min_{v\in X}\{o_{v}-p(v)+\delta(q,v)\}\}\)
8if\(\tau_{q}=\delta(q,F)\)then
9 Connect \(q\) to the closest facility in \(F\).
10
11elseif\(\tau_{q}=o_{v}-p(v)+\delta(q,v)\) for some \(v\in X\)then
12 Open a facility at \(v\).
13 Connect \(q\) to \(v\).
14
15else
16 Pay the penalty \(\pi\) for \(q\).
17 ComputePotentials() return\(2\tau_{q}\) // return amortized cost
18FunctionComputePotentials() For every \(q\in Q\), define \(\lambda_{q}=\min\{\delta(q,F),\tau_{q}\}\)
19 For every location \(v\in X\), set \(p(v)\leftarrow\sum_{q\in Q}\{\lambda_{q}-\delta(q,v)\}^{+}\). ```

**Algorithm 4**A Variant of Fotakis' Algorithm for Prize-Collecting OFLP

#### b.1.1 Analysis

We now analyze Algorithm 4 and show that it proves Theorem B.1. For this analysis, we fix the prize-collecting input \(Q\). Next, we define the online amortization oa such that oa\((q,\pi)\) is the value returned by UponRequest in Theorem B.1 upon release of \((q,\pi)\in Q\).

#### Online Amortization

We first prove that oa is valid and monotone.

**Lemma B.2**.: _The online amortization oa for Algorithm 4 is valid, i.e., \(\operatorname{ALG}(Q)\leq\operatorname{oa}(Q)\)._

Proof.: For each request, observe the variable \(\tau_{q}\), and note that:

* If the penalty \(\pi\) is paid for \(q\), then \(\tau_{q}=\pi\).
* If \(q\) is connected to some facility, the connection cost of \(q\) does not exceed \(\tau_{q}\).

It remains to bound the opening costs of the algorithm. Observe the evolution of the potential function \(\sum_{q\in Q}\min\bigl{\{}\delta(q,F),\tau_{q}\bigr{\}}\) as \(Q\) and \(F\) grow over time. This function is nonnegative, and grows by exactly \(\tau_{q}\) upon the release of \((q,\pi)\) (after Line 8). Moreover, whenever a facility at \(v\) is opened (thus joining \(F\)), it decreases this amount by exactly \(o_{v}\). Thus, the total opening cost can be bounded by \(\sum_{q\in Q}\tau_{q}\).

Overall, we bounded the cost of the algorithm by \(\sum_{(q,\pi)\in Q}2\tau_{q}=\sum_{(q,\pi)\in Q}\operatorname{oa}(q,\pi)\). 

**Observation B.3**.: _The online amortization oa given for Algorithm 4 is a monotone online amortization._

### Bounding Amortized Costs

Having shown the necessary properties for the online amortization, we proceed to show that Algorithm 4 is Lagrangian subset-competitive using this amortization. As in Section 3, we first show that the algorithm is PRSC (see Proposition C.2); we begin by observing the penalty robustness of the algorithm.

**Observation B.4**.: _For every \((q,\pi)\in Q\), it holds that \(\operatorname{oa}(q,\pi)\leq 2\pi\)._

We now fix the subset \(Q^{\prime}\subseteq Q\) for the sake of proving subset competitiveness. Recall that \(\overline{Q^{\prime}}\) is the standard input formed from the prize-collecting input \(Q^{\prime}\) (by setting penalties to infinity).

Before proving subset-competitiveness, we need to prove the following simple lemma.

**Lemma B.5** (Min trace lemma).: _Let \((a_{1},\cdots,a_{k})\), \((b_{1},\cdots,b_{k})\) be two sequences of non-negative numbers, and define \(c_{i,j}=\min(a_{i},b_{j})\). Then if there exists \(z\) such that for every \(i\) it holds that \(\sum_{j=1}^{i}c_{i,j}\leq z\), then it holds that \(\sum_{i=1}^{k}c_{i,i}=O(\log k)\cdot z\)._

Proof.: We prove that \(\sum_{i=1}^{k}c_{i,i}\leq H_{k}\cdot z\) by induction on \(k\), where \(H_{k}=\sum_{i=1}^{k}\frac{1}{i}\) is the \(k\)-th harmonic number. Note that the base case, in which \(k=1\), holds as \(c_{1,1}\leq z\).

Now, for the general case, note that if we can find \(i\) such that \(c_{i,i}\leq\frac{z}{k}\), then we can complete the proof by induction on the sequences \((a_{1},\cdots,a_{i-1},a_{i+1},\cdots,a_{k})\) and \((b_{1},\cdots,b_{i-1},b_{i+1},\cdots,b_{k})\). (Note that the constraints required for this inductive instance are implied by the original constraints.) This induction would imply that \(\sum_{i^{\prime}\neq i}c_{i^{\prime},i^{\prime}}\leq H_{k-1}\cdot z\), to which adding \(c_{i,i}\) would complete the proof.

It remains to find \(i\) such \(c_{i,i}\leq\frac{z}{k}\). We consider the constraint \(\sum_{j=1}^{k}c_{k,j}\leq z\), and observe the following cases.

**Case 1**: \(c_{k,j}\) are equal for all \(j\). In this case, all \(c_{k,j}\) are at most \(\frac{z}{k}\). In particular, this is true for \(c_{k,k}\); thus, choosing \(i=k\) completes the proof.

**Case 2**: \(c_{k,j}\) are not all equal. In this case, observe \(j\) that minimizes \(c_{k,j}\), and note that \(c_{k,j}\leq\frac{z}{k}\). There exists \(j^{\prime}\) such that \(c_{k,j}<c_{k,j^{\prime}}\), which implies \(c_{k,j}<a_{k}\), and thus \(c_{k,j}=b_{j}\), yielding \(b_{j}\leq\frac{z}{k}\). But this implies \(c_{j,j}\leq b_{j}\leq\frac{z}{k}\), and thus choosing \(i=j\) completes the proof. 

We can now prove subset-competitiveness, as stated in Lemma B.6.

**Lemma B.6**.: \(\operatorname{oa}(Q^{\prime}|Q)\leq O(\log|Q^{\prime}|)\cdot\operatorname{ OPT}\Bigl{(}\overline{Q^{\prime}}\Bigr{)}\).

Proof.: Let \(w\) be some facility opened by \(\operatorname{OPT}\!\left(\overline{Q^{\prime}}\right)\), and denote by \(R\subseteq\overline{Q^{\prime}}\) the set of requests connected to that facility in \(\operatorname{OPT}\!\left(\overline{Q^{\prime}}\right)\). Define \(C_{w}:=\sum_{(q,\pi)\in R}\delta(w,q)\) the total connection cost incurred by \(\operatorname{OPT}\!\left(\overline{Q^{\prime}}\right)\) on the facility \(w\). Enumerate these requests as \(((q_{1},\pi_{1}),\cdots,(q_{k},\pi_{k}))\), where \(k=|R|\). For \(1\leq i\leq k\), denote by \(F_{i}\) the set of facilities which were open immediately before the release of \((q_{i},\pi_{i})\). As a shorthand, we also define \(\tau_{i}=\tau_{q_{i}}\). Consider that the total potential of the facility \(w\) can never exceed its cost \(o_{w}\); moreover, upon release of \((q_{i},\pi_{i})\), the choice of \(\tau_{i}\) ensures that

\[o_{w} \geq\tau_{i}-\delta(q_{i},w)+\sum_{j=1}^{i-1}\min(\tau_{j},( \delta\big{(}q_{j},F_{i}\big{)}-\delta\big{(}q_{j},w\big{)})^{+})\] \[\geq\tau_{i}-\delta(q_{i},w)+\sum_{j=1}^{i-1}\min(\tau_{j},\delta \big{(}q_{i},F_{i}\big{)}-\delta\big{(}q_{i},w\big{)}-\delta\big{(}q_{j},w \big{)}-\delta\big{(}q_{j},w\big{)})\] \[\geq\tau_{i}-\delta(q_{i},w)+\sum_{j=1}^{i-1}\min(\tau_{j},\tau_{ i}-\delta(q_{i},w))-2\sum_{j=1}^{i-1}\delta\big{(}q_{j},w\big{)}\] \[\geq\tau_{i}-\delta(q_{i},w)+\sum_{j=1}^{i-1}\min(\tau_{j},\tau_{ i}-\delta(q_{i},w))-2C_{w}\] \[\geq\sum_{j=1}^{i}\min(\tau_{j},\tau_{i}-\delta(q_{i},w))-2C_{w}\] (9)

where the second inequality uses the triangle inequality and the third inequality uses the definition of \(\tau_{i}\).

From Equation (9), we have that for every \(1\leq i\leq k\) it holds that

\[\sum_{j=1}^{i}\min(\tau_{j},\tau_{i}-\delta(q_{i},w))\leq o_{w}+2C_{w}.\]

Using Lemma B.5, this yields

\[\sum_{i=1}^{k}\min(\tau_{i},\tau_{i}-\delta(q_{i},w))\leq O(\log k)\cdot(o_{w }+2C_{w})\]

Since \(\tau_{i}-\delta(q_{i},w)=\min(\tau_{i},\tau_{i}-\delta(q_{i},w))\), and since \(\sum_{i=1}^{k}\delta(q_{i},w)=C_{w}\), we have

\[\sum_{i=1}^{k}\tau_{i}\leq O(\log k)\cdot(o_{w}+C_{w})\leq O(\log|Q^{\prime}| )\cdot(o_{w}+C_{w})\]

Finally, summing over all facilities \(w\) in \(\operatorname{OPT}\!\left(\overline{Q^{\prime}}\right)\) yields

\[\sum_{(q,\pi)\in Q^{\prime}}\tau_{q}\leq O(\log|Q^{\prime}|)\operatorname{OPT} \!\left(\overline{Q^{\prime}}\right).\qed\]

Proof of Theorem b.1.: Through Lemma B.2 and Observation B.3, we have that oa is a valid and monotone amortization for Algorithm 4. Lemma B.6 and Observation B.4 then yield that the algorithm is \(O(\log Q)\)-PRSC using oa. Using Proposition C.2 yields that the algorithm is Lagrangian \(O(\log Q)\)-subset-competitive using oa, which completes the proof of the theorem. 

## Appendix C The Smooth Combination Framework

### Proof of Theorem 2.5

Proof of Theorem 2.5.: Consider the framework in Algorithm 1 applied to algorithms \(\operatorname{ALG}_{1},\operatorname{ALG}_{2}\). The framework ensures that all requests are satisfied, as at least one of the constituent algorithmsserves each request. Denote by \(\alpha(q)\) the final value assigned to the variable \(\alpha\) upon request \(q\); the prize-collecting input given to both constituent algorithms is \(Q^{*}=\left((q,\alpha(q))\right)_{q\in Q}\). We define \(Q^{*}_{1},Q^{*}_{2}\) be the partition of \(Q^{*}\) induced by the partition of \(Q\) into \(Q_{1},Q_{2}\). As the algorithm only buys items bought by one of the constituent algorithms, its cost can thus be bounded by \(\mathrm{ALG}_{1}(Q^{*})+\mathrm{ALG}_{2}(Q^{*})\). We now bound \(\mathrm{ALG}_{1}(Q^{*})\); bounding \(\mathrm{ALG}_{2}(Q^{*})\) is identical.

First, consider the prize-collecting solution which serves \(Q^{*}_{1}\) optimally subject to using items from \(S\), but pays the penalty for requests from \(Q^{*}_{2}\); using the Lagrangian subset-competitiveness of \(\mathrm{ALG}_{1}\) against this solution yields

\[\mathbb{E}[\mathrm{ALG}_{1}(Q^{*})]\leq O(\beta_{1})\cdot\mathrm{OPT}_{S}(Q_ {1})+\mathbb{E}\Bigg{[}O(1)\cdot\sum_{q\in Q_{2}}\alpha(q)\Bigg{]}\] (10)

Now, observe that using the definition of \(\alpha\) and the fact that \(\mathrm{ALG}_{2}\) is monotone, we have that \(\alpha(q)\leq\mathrm{ALG}_{2}(q,\alpha(q))\); summing over requests in \(Q_{2}\) we get that \(\sum_{q\in Q_{2}}\alpha(q)\leq\mathrm{ALG}_{2}\big{(}Q^{*}_{2}|Q^{*}\big{)}\). Plugging into Equation (10), we get

\[\mathbb{E}[\mathrm{ALG}_{1}(Q^{*})] \leq O(\beta_{1})\cdot\mathrm{OPT}_{S}(Q_{1})+\mathbb{E}\big{[} O(1)\cdot\mathrm{ALG}_{2}\big{(}Q^{*}_{2}|Q^{*}\big{)}\big{)}\big{]}\] \[\leq O(\beta_{1})\cdot\mathrm{OPT}_{S}(Q_{1})+O(\beta_{2})\cdot \mathrm{OPT}(Q_{2})\]

where the second inequality uses the fact that \(\mathrm{ALG}_{2}\) is subset competitive to bound its cost on the subset \(Q^{*}_{2}\) against the solution which serves those requests optimally. This completes the bounding of costs for \(\mathrm{ALG}_{1}\); we can bound \(\mathbb{E}[\mathrm{ALG}_{2}(Q^{*})]\) in the same way. Summing the bounds for \(\mathrm{ALG}_{1}\) and \(\mathrm{ALG}_{2}\), we get

\[\mathrm{ALG}(Q)\leq O(\beta_{1})\cdot\mathrm{OPT}_{S}(Q_{1})+O(\beta_{2}) \cdot\mathrm{OPT}(Q_{2})\]

which completes the proof. 

### Penalty-Robust Subset-Competitive Algorithms

In proving that a prize-collecting algorithm is Lagrangian subset-competitive (for use in our framework), we sometimes find it easier to prove that it is _penalty-robust subset competitive_. As we now prove, this latter property is sufficient to prove the former. (In fact, it is easy to see that both properties are in fact equivalent.)

**Definition C.1** (PRSC algorithm using online amortization).: Let \(\mathrm{ALG}\) be a randomized prize-collecting algorithm equipped with an online amortization oa running on an input \(Q\). We say that \(\mathrm{ALG}\) is \(\beta\) penalty-robust subset competitive (PRSC) using oa if both following conditions hold:

1. For every \((q,\pi)\in Q\) we have \(\textsc{oa}(q,\pi)\leq O(1)\cdot\pi\).
2. For every subset \(Q^{\prime}\subseteq Q\), we have \(\mathbb{E}[\textsc{oa}(Q^{\prime}|Q)]\leq\beta\cdot\mathrm{OPT}(\overline{Q^{ \prime}})\). (where \(\overline{Q^{\prime}}\) is the input formed from \(Q^{\prime}\) by forcing service, i.e., setting penalties to infinity.)

If in the second condition of PRSC we replace \(\mathrm{OPT}\Big{(}\overline{Q^{\prime}}\Big{)}\) by \(\mathrm{OPT}_{S}\Big{(}\overline{Q^{\prime}}\Big{)}\), we say that \(\mathrm{ALG}\) is \(\beta\)-PRSC using oa w.r.t. \(S\).

**Proposition C.2**.: _A \(\beta\)-PRSC algorithm using oa (w.r.t. \(S\)) is also Lagrangian \(\beta\)-subset-competitive using oa (w.r.t. \(S\))._

Proof.: We prove this for a general solution, restricting to \(S\) is identical. Consider prize-collecting input \(Q\), and any subset \(Q^{\prime}\subseteq Q\). Let \(\mathrm{SOL}\) be the optimal solution for \(Q^{\prime}\), which pays penalties for \(Q^{\prime}_{p}\) and serves \(Q^{\prime}_{b}=Q^{\prime}\backslash Q^{\prime}_{p}\) optimally. Then it holds that

\[\mathbb{E}[\textsc{oa}(Q^{\prime}|Q)] =\mathbb{E}\big{[}\textsc{oa}(Q^{\prime}_{b}|Q)\big{]}+\mathbb{E }\Big{[}\textsc{oa}\Big{(}Q^{\prime}_{p}|Q\Big{)}\Big{]}\] \[\leq\beta\cdot\mathrm{OPT}\Big{(}\overline{Q^{\prime}_{b}}\Big{)} +O(1)\cdot\sum_{(q,\pi)\in Q^{\prime}_{p}}\pi\] \[=\beta\cdot\mathrm{SOL}^{b}(Q^{\prime})+O(1)\cdot\mathrm{SOL}^{p}( Q^{\prime})\]

where the inequality uses both properties of PRSC.

Proofs of Theorems 1.1, 1.2 and 1.3

We establish these theorems in three steps. First, we combine various constituent prize-collecting algorithms using Theorem 2.5 and explicitly state the guarantees for the resulting algorithms. Then, we use these guarantees to derive the discrete-smoothness property for the individual problems with respect to the size of the prediction (i.e., Equation (6)). Finally, we use Theorem 2.1 to make the competitive ratio depend on \(|S\backslash\mathrm{OPT}|\) rather than on \(|S|\).

Before proceeding further, we need to precisely define the intersection/difference of a solution with a prediction to make Theorem 1.1, Theorem 1.2, and Theorem 1.3 completely formal.

**Definition D.1** (restriction of solution with prediction).: Consider an online covering problem with items \(\mathcal{E}\), let \(S\subseteq\mathcal{E}\) be some prediction. For every solution \(A\) which buys some items from \(\mathcal{E}\):

* Define \(A|_{S}\) to be the solution which only buys items from \(S\), to the same amount as \(A\).
* Define \(A|_{\overline{S}}\) to be the solution which only buys items outside \(S\), to the same amount as \(A\).

**Facility Location with Predictions.** In order to describe facility location as a covering problem, we must describe the set of items. Here, the set of items comprises an opening item \(b_{v}\) for each facility and a connection item \(c_{v,q}\) for each (request, facility) pair. When we informally write that \(S\) is a set of possible facilities, this can be formalized to the set of items \(b_{v}\) for \(v\in S\), plus the connection items \(c_{v,q}\) for all \(q\) in the input and \(v\in S\).

Due to Theorem 3.1 and Theorem B.1, we have that both Algorithm 2 and Algorithm 4 can serve as constituent algorithms in our framework. Combining both algorithms using Theorem 2.5 thus implies the following theorem.

**Theorem D.2**.: _For facility location with predictions, there exists a randomized algorithm \(\mathrm{ALG}\) such that for every input \(Q\), and for every partition of \(Q\) into \(Q_{1},Q_{2}\), we have_

\[\mathbb{E}[\mathrm{ALG}(Q)]\leq O(\log\lvert S\backslash\mathrm{OPT}\rvert) \cdot\mathrm{OPT}_{S}(Q_{1})+O(\log\lvert Q_{2}\rvert)\cdot\mathrm{OPT}(Q_{2}).\]

We obtain an additional result, which is useful for small metric spaces, from combining two instances of Algorithm 2, one for the entire metric space \(X\) and one for the predictions \(S\).

**Theorem D.3**.: _For facility location with predictions, there exists a randomized algorithm \(\mathrm{ALG}\) such that for every input \(Q\), and for every partition of \(Q\) into \(Q_{1},Q_{2}\), we have_

\[\mathbb{E}[\mathrm{ALG}(Q)]\leq O(\log\lvert S\backslash\mathrm{OPT}\rvert) \cdot\mathrm{OPT}_{S}(Q_{1})+O(\log\lvert X\rvert)\cdot\mathrm{OPT}(Q_{2}).\]

Proof of Theorem 1.1.: Consider a solution \(\mathrm{OPT}\) to facility location on a set of requests \(Q\). Partition \(Q\) into \(Q_{1},Q_{2}\) such that \(Q_{1}\) contains all requests from \(Q\) that are connected to a facility in \(\mathrm{OPT}|_{S}\) (and \(Q_{2}\) is complementary). Using the algorithm \(\mathrm{ALG}\) from Theorem D.2, we have

\[\mathrm{ALG}(Q)\leq O(\log\lvert S\rvert)\cdot\mathrm{OPT}_{S}(Q_{1})+O(\log \lvert Q_{2}\rvert)\cdot\mathrm{OPT}(Q_{2}).\] (11)

Now note that \(\mathrm{OPT}|_{S}\) is a solution to \(Q_{1}\) that only uses facility and connection items from \(S\), and thus \(\mathrm{OPT}_{S}(Q_{1})\leq\mathrm{OPT}|_{S}\). Moreover, \(\mathrm{OPT}|_{\overline{S}}\) is a solution to \(Q_{2}\), and thus \(\mathrm{OPT}_{S}(Q_{2})\leq\mathrm{OPT}|_{\overline{S}}\). Plugging into Equation (12), and noting that \(\lvert Q_{2}\rvert\leq\lvert Q\rvert\), we get

\[\mathrm{ALG}(Q)\leq O(\log\lvert S\rvert)\cdot\mathrm{OPT}|_{S}+O(\log\lvert Q \rvert)\cdot\mathrm{OPT}|_{\overline{S}}.\]

We now plug the above equation into Theorem 2.1, thus replacing the dependence on \(|S|\) with dependence on \(|S\backslash\mathrm{OPT}|\). 

Proof of Theorem 1.2.: Identical to the proof of Theorem 1.1, but using Theorem D.3. 

**Set Cover with Predictions.** Theorem 4.1 implies that Algorithm 3 is Lagrangian subset-competitive. In addition, it is easy to see that Algorithm 3 is monotone, as defined in Definition 2.2. Thus, the algorithm can serve as a constituent algorithm in our framework. From combining two instances of Algorithm 3, Theorem 2.5 thus implies the following theorem.

**Theorem D.4**.: _For fractional set cover with predictions, with universe \((E,U)\) and a prediction \(S\subseteq U\), there exists a deterministic algorithm \(\mathrm{ALG}\) such that for every input \(Q\), and for every partition of \(Q\) into \(Q_{1},Q_{2}\), we have_

\[\mathrm{ALG}(Q)\leq O(\log\lvert S\rvert)\cdot\mathrm{OPT}_{S}(Q_{1})+O(\log \lvert U\rvert)\cdot\mathrm{OPT}(Q_{2}).\]Using standard rounding techniques (see [3, 15]) for online set cover, we can round the fractional solution online at a loss of \(O(\log\lvert Q\rvert)\). In addition, we can then apply Theorem 2.1 to replace \(\lvert S\rvert\) with \(\lvert S\backslash\mathrm{OPT}\rvert\). Thus, Theorem D.4 yields the following corollary.

**Corollary D.5**.: _For (integral) set cover with predictions, with universe \((E,U)\) and a prediction \(S\subseteq U\), there exists a randomized algorithm \(\mathrm{ALG}\) such that for every input \(Q\), and for every partition of \(Q\) into \(Q_{1},Q_{2}\), we have_

\[\mathbb{E}[\mathrm{ALG}(Q)]\leq O(\log\lvert Q\rvert\log\lvert S\backslash \mathrm{OPT}\rvert)\cdot\mathrm{OPT}_{S}(Q_{1})+O(\log\lvert Q\rvert\log\lvert U \rvert)\cdot\mathrm{OPT}(Q_{2}).\]

Proof of Theorem 1.3.: Consider a solution \(\mathrm{OPT}\) to set cover on a set of requests \(Q\). Partition \(Q\) into \(Q_{1},Q_{2}\) such that \(Q_{1}\) contains all requests from \(Q\) that belong to a set in \(\mathrm{OPT}\lvert_{S}\) (and \(Q_{2}\) is complementary). Using the randomized algorithm \(\mathrm{ALG}\) from Corollary D.5, we have

\[\mathrm{ALG}(Q)\leq O(\log\lvert Q\rvert\log\lvert S\rvert)\cdot\mathrm{OPT} _{S}(Q_{1})+O(\log\lvert Q\rvert\log\lvert U\rvert)\cdot\mathrm{OPT}(Q_{2}).\] (12)

Now note that \(\mathrm{OPT}\lvert_{S}\) is a solution to \(Q_{1}\) that only uses sets from \(S\), and thus \(\mathrm{OPT}_{S}(Q_{1})\leq\mathrm{OPT}\lvert_{S}\). Moreover, \(\mathrm{OPT}\lvert_{\overline{S}}\) is a solution to \(Q_{2}\), and thus \(\mathrm{OPT}_{S}(Q_{2})\leq\mathrm{OPT}\lvert_{\overline{S}}\). Plugging into Equation (12), we get

\[\mathrm{ALG}(Q)\leq O(\log\lvert Q\rvert\log\lvert S\rvert)\cdot\mathrm{OPT} _{S}+O(\log\lvert Q\rvert\log\lvert U\rvert)\cdot\mathrm{OPT}\lvert_{ \overline{S}}.\]

## Appendix E Proof of Theorem 2.1: Reduction from Equation (6) to Equation (1)

In this section, we give the proof of Theorem 2.1 whose goal is to give a reduction from Equation (6) to Equation (1). This replaces \(s\) in the bound of Equation (6) with the term \(s_{\delta}\), where \(s_{\delta}\coloneqq|S\backslash\mathrm{OPT}|\), in order to obtain Equation (1).

Proof of Theorem 2.1.: Assume, without loss of generality, that the cheapest item in \(\mathcal{E}\) costs 1. Consider the following construction of the algorithm \(\mathrm{ALG}\) using the algorithm \(\mathrm{ALG}^{\prime}\):

```
1Initialize \(i\gets 0\), \(S^{\prime}\gets S\), \(B\gets 0\), and define the item cost function \(c^{\prime}\gets c\).
2Let \(A\) be an instance of \(\mathrm{ALG}^{\prime}\) with prediction set \(S^{\prime}\), and cost function \(c^{\prime}\).
3for incoming request \(q\)do
4while\(T\tau\)ue do
5Simulate sending \(q\) to \(A\), and let \(c\) be the resulting cost.
6if\(B+c<2^{i}\)thenbreak
7Spend \(2^{i}\) budget in buying the cheapest items in \(S^{\prime}\), let the bought subset of items be \(T\).
8Set \(S^{\prime}\gets S^{\prime}\backslash T\), \(B\gets 0\), \(i\gets i+1\).
9For every \(e\in T\), set \(c^{\prime}(e)\gets 0\).
10Reset \(A\) to be a new instance of \(\mathrm{ALG}^{\prime}\), given \(S^{\prime}\) as prediction, and using the (modified) cost function \(c^{\prime}\).
11Send \(q\) to \(A\), and set \(B\gets B+c\). ```

**Algorithm 1** \(\mathrm{ALG}^{\prime}\) with prediction set \(S^{\prime}\), and cost function \(c^{\prime}\).

For integer \(\ell\), define _phase_\(\ell\) to be the subsequence of requests in which variable \(i\) takes value \(\ell\). The cost of the algorithm can be charged to a constant times \(2^{j}\), where \(j\) is the penultimate value of \(i\) in the algorithm. If \(2^{j-1}<\mathrm{OPT}\), then the cost of the algorithm is at most \(O(1)\cdot\mathrm{OPT}\) and we are done. Henceforth, suppose \(\mathrm{OPT}\leq 2^{j-1}\). Define \(S^{\prime}_{j},A_{j},c^{\prime}_{j}\) to be the values of the variables \(S^{\prime}\), \(A\) and \(c^{\prime}\) during phase \(j\). When considering the cost of a solution relative to a cost function, we place that cost function as superscript (e.g., \(\mathrm{OPT}^{c^{\prime}}\)). Before the beginning of phase \(j\), the algorithm spent at least \(\mathrm{OPT}\) budget on buying the cheapest items in the (remaining) prediction; it thus holds that \(\left\lvert S^{\prime}_{j}\right\rvert\leq\lvert S\backslash\mathrm{OPT}\rvert\). Let \(q_{1},\cdots,q_{k}\) be the requests of phase \(j\); moreover, let \(q_{k+1}\) be the request upon which the variable \(i\) was incremented to \(j+1\). From the definition of \(q_{k+1}\), it holds that the cost of the instance of \(A\) in phase \(j\) on \((q_{1},\cdots,q_{k},q_{k+1})\) is at least \(2^{j}\); thus, the total cost of the algorithm can be charged to this cost, which we denote by \(\alpha\). But, through Equation (6), and from the fact that OPT is a solution which serves \((q_{1},\cdots,q_{k+1})\), we have

\[\alpha \leq O(f(|S\backslash\mathrm{OPT}|))\cdot\mathrm{OPT}^{c^{\prime}_{j }}|_{S^{\prime}_{j}}+O(g)\cdot\mathrm{OPT}^{c^{\prime}_{j}}|_{\overline{S^{ \prime}_{j}}}\] \[\leq O(f(|S\backslash\mathrm{OPT}|))\cdot\mathrm{OPT}|_{S^{\prime}_ {j}}+O(g)\cdot\left(\mathrm{OPT}^{c^{\prime}_{j}}|_{\overline{S}}+\mathrm{OPT} ^{c^{\prime}_{j}}|_{S\backslash S^{\prime}_{j}}\right)\] \[\leq O(f(|S\backslash\mathrm{OPT}|))\cdot\mathrm{OPT}|_{S}+O(g) \cdot\mathrm{OPT}|_{\overline{S}}\qed\]

## Appendix F Proof of Lemma 4.4

Proof of Lemma 4.4.: First, note that \(\mathrm{ALG}(q,\pi)\leq 3y_{q}\), where \(y_{q}\) is the final value of the variable of that name: Proposition 4.5 implies that the buying cost is at most \(2y_{q}\), while a penalty of \(\pi\) is paid only if \(\pi\leq y_{q}\). We show that \(\sum_{(q,\pi)\in Q^{\prime}}y_{q}\leq O(\log m)\cdot\mathrm{OPT}(\overline{Q ^{\prime}})\); since \(\mathrm{ALG}(q,\pi)\leq 3\cdot y_{q}\), this would complete the proof of the lemma. Consider the (standard) primal and dual LPs for fractional set cover of \(Q^{\prime}\) without penalties (i.e. solving \(\overline{Q^{\prime}}\)). The primal LP is given by:

\[\min\sum_{s\in U}x_{s}\cdot c\left(s\right)\text{ such that }\forall q\in Q^{ \prime}:\sum_{s|q\in s}x_{s}\geq 1\text{ and }\forall s\in U:x_{s}\geq 0.\]

and the dual LP is given by:

\[\max\sum_{q\in Q^{\prime}}y_{q}\text{ such that }\forall s\in U:\sum_{q|q\in s }y_{q}\leq c\left(s\right)\text{ and }\forall q\in Q^{\prime}:y_{q}\geq 0.\]

We claim that the dual solution \(\left\{y_{q}\right\}_{q\in Q^{\prime}}\) violates dual constraints by at most \(O(\log m)\); thus, scaling it down by that factor yields a feasible dual solution, and a lower bound to \(\mathrm{OPT}\!\left(\overline{Q^{\prime}}\right)\).

Consider the dual constraint corresponding to the set \(s\); we want to bound the term \(\sum_{q\in Q^{\prime}|q\in s}y_{q}\). Through induction on \(k\), we can prove that once \(\sum_{q\in Q^{\prime}|q\in s}y_{q}=k\) for some integer \(k\), it holds that \(x_{s}\geq\frac{1}{m}\left(\left(1+\frac{1}{c_{s}}\right)^{k}-1\right)\). Thus, once \(k=\Theta(c_{s}\log m)\) we have \(x_{s}\geq 1\), and \(\sum_{q\in s}y_{q}\) would increase no more. This implies that scaling down \(\left\{y_{q}\right\}_{q\in Q^{\prime}}\) by \(\Theta(\log m)\) yields a feasible dual solution, which lower bounds \(\mathrm{OPT}\!\left(\overline{Q^{\prime}}\right)\), and completes the proof.

It remains to prove the inductive claim. For the base case where \(k=0\), the claim holds trivially. Now, assume that the claim holds for \(k-1\), and consider point in which \(\sum_{q\in Q^{\prime}|q\in s}y_{q}\) is incremented from \(k-1\) to \(k\); let \(x,x^{\prime}\) be the old and new amounts by which \(s\) is held in the algorithm. We have

\[x^{\prime}=x\cdot\left(1+\frac{1}{c\left(s\right)}\right)+\frac{1}{U(q)c\left( s\right)}\geq\frac{1}{m}\left(\left(1+\frac{1}{c\left(s\right)}\right)^{k}-1- \frac{1}{c\left(s\right)}\right)+\frac{1}{mc\left(s\right)}\geq\frac{1}{m} \left(\left(1+\frac{1}{c\left(s\right)}\right)^{k}-1\right)\] (13)

where the inequality uses the inductive hypothesis as well as the fact that \(|U(q)|\leq m\).