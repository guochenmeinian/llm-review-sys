# Online Estimation via Offline Estimation:

An Information-Theoretic Framework

 Dylan J. Foster

dylanfoster@microsoft.com

Yanjun Han

yanjunhan@nyu.edu

Jian Qian

jianqian@mit.edu

Alexander Rakhlin

rakhlin@mit.edu

###### Abstract

The classical theory of statistical estimation aims to estimate a parameter of interest under data generated from a fixed design ("offline estimation"), while the contemporary theory of online learning provides algorithms for estimation under adaptively chosen covariates ("online estimation"). Motivated by connections between estimation and interactive decision making, we ask: _is it possible to convert offline estimation algorithms into online estimation algorithms in a black-box fashion?_ We investigate this question from an information-theoretic perspective by introducing a new framework, _Oracle-Efficient Online Estimation_ (OEOE), where the learner can only interact with the data stream indirectly through a sequence of _offline estimators_ produced by a black-box algorithm operating on the stream. Our main results settle the statistical and computational complexity of online estimation in this framework.

1. _Statistical complexity._ We show that information-theoretically, there exist algorithms that achieve near-optimal online estimation error via black-box offline estimation oracles, and give a nearly-tight characterization for minimax rates in the OEOE framework.
2. _Computational complexity._ We show that the guarantees above cannot be achieved in a computationally efficient fashion in general, but give a refined characterization for the special case of conditional density estimation: computationally efficient online estimation via black-box offline estimation is possible whenever it is possible via unrestricted algorithms.

Finally, we apply our results to give offline oracle-efficient algorithms for interactive decision making.

## 1 Introduction

Consider a general framework for statistical estimation specified by a tuple \((\mathcal{X},\mathcal{Y},\mathcal{Z},\mathcal{K},\mathcal{F})\), which we will show encompasses classification, regression, and conditional density estimation. The learner is given a parameter space \(\mathcal{F}\) (typically a function class), where each parameter \(f\in\mathcal{F}\) is a map from the space of _covariates_\(\mathcal{X}\) to the space of _values_\(\mathcal{Z}\). For an integer \(T\geq 1\), the learner is given a dataset \((x^{\imath},y^{\imath}),\ldots,(x^{\tau},y^{\tau})\), where \(x^{\imath},\ldots,x^{\tau}\) are _covariates_ and \(y^{\imath},\ldots,y^{\tau}\) are _outcomes_ generated via \(y^{\imath}\sim\mathcal{K}(\cdot\mid f^{\star}(x^{\imath}))\), where \(f^{\star}\in\mathcal{F}\) is an unknown target parameter that the learner wishes to estimate; here \(\mathcal{K}\) is a probability kernel that assigns to each value \(z\in\mathcal{Z}\) a distribution \(\mathcal{K}(\cdot\mid z)\) on the space of outcomes \(\mathcal{Y}\). We adopt the shorthand \(\mathcal{K}(z)=\mathcal{K}(\cdot\mid z)\) throughout.

The classical theory of statistical estimation typically assumes that the _covariates_\(x^{\imath},\ldots,x^{\tau}\) are an arbitrary fixed design, and is concerned with estimating the target parameter \(f^{\star}\in\mathcal{F}\) well _in-distribution_[64, 40, 62]. Formally, for a _loss function_\(\mathsf{D}:\mathcal{Z}\times\mathcal{Z}\to\mathbb{R}_{\geq 0}\) on the space of values \(\mathcal{Z}\), the goal of the learner is to output an estimator \(\widehat{f}\) based on \((x^{\imath},y^{\imath}),\ldots,(x^{\tau},y^{\tau})\) such that the in-distribution error

\[\mathbf{Est}_{\mathsf{D}}^{\text{Off}}(T):=\sum\nolimits_{t=1}^{T}\mathsf{D} \big{(}\widehat{f}(x^{\imath}),f^{\star}(x^{\imath})\big{)}\] (1)

is small; we refer to this as an _offline estimation_ guarantee. Canonical examples include:* Classification (i.e., distribution-free PAC learning [38; 63]), where \(\mathcal{Z}=\mathcal{Y}=\{0,1\}\), \(\mathcal{K}(f^{\star}(x))=\mathbb{1}_{f^{\star}(x)}\),1 and \(\mathsf{D}_{0/1}\big{(}\widehat{f}(x),f^{\star}(x)\big{)}=1\{\widehat{f}(x) \neq f^{\star}(x)\}\) is the \(0/1\)-loss.
* Regression with a well-specified model [62; 66], where \(\mathcal{Z}=\mathcal{Y}=\mathbb{R}\), \(\mathcal{K}(f^{\star}(x))=\mathcal{N}(f^{\star}(x),\sigma^{2})\), and \(\mathsf{D}_{\mathbf{sq}}\big{(}\widehat{f}(x),f^{\star}(x)\big{)}=(\widehat{ f}(x)-f^{\star}(x))^{2}\) is the square loss.
* Conditional density estimation [12], where \(\mathcal{Y}\) is an arbitrary alphabet, \(\mathcal{Z}=\Delta(\mathcal{Y})\), \(\mathcal{K}(f^{\star}(x))=f^{\star}(x)\), and \(\mathsf{D}_{\mathsf{H}}^{2}(\cdot,\cdot)\) is squared Hellinger distance; see Appendix C for details.

Footnote 1: We use \(\mathbb{1}_{y}\) to indicate the delta distribution that places probability mass \(1\) on \(y\).

In parallel to statistical estimation, the contemporary theory of online learning [17; 49] provides estimation error algorithms that support _adaptively chosen_ sequences of covariates, a meaningful form of _out-of-distribution_ guarantee. Here, the examples \((x^{\iota},y^{\iota})\) arrive one at a time. For each step \(t\in[T]\), the learner produces an estimator \(\widehat{f}^{\iota}:\mathcal{X}\to\mathcal{Z}\) based on the data \((x^{\iota},y^{\iota}),\ldots,(x^{\iota-1},y^{\iota-1})\) observed so far. The covariate \(x^{\iota}\) is then chosen in an arbitrary fashion, and the outcome is generated via \(y^{\iota}\sim\mathcal{K}(f^{\star}(x^{\iota}))\) and revealed to the learner. The quality of the estimators is measured via2

Footnote 2: For technical reasons, it is also common to consider randomized estimators where \(\widehat{f}^{\iota}\sim\mu^{\iota}\), and measure error by \(\mathbf{Est}_{\mathsf{D}}^{\mathsf{on}}(T):=\sum_{t=1}^{T}\mathbb{E}_{\widehat {f}^{\iota}\sim\mu^{\iota}}\big{[}\mathsf{D}\big{(}\widehat{f}^{\iota}(x^{ \iota}),f^{\star}(x^{\iota})\big{)}\big{]}\).

\[\mathbf{Est}_{\mathsf{D}}^{\mathsf{on}}(T):=\sum\nolimits_{t=1}^{T}\mathsf{ D}\big{(}\widehat{f}^{\iota}(x^{\iota}),f^{\star}(x^{\iota})\big{)}.\] (2)

We refer to this as an _online estimation_ guarantee; classical examples include online classification in the mistake-bound model [41], online regression [51], and online conditional density estimation [11]. Online estimation provides a non-trivial out-of-distribution guarantee, as it requires (on average) that the learner achieves non-trivial estimation performance on covariates \(x^{\iota}\) that can be arbitrarily far from the previous examples \(x^{1},\ldots,x^{\iota-1}\). This property has many applications in algorithm design, notably in the context of _interactive decision making_, where it has recently found extensive use for problems including contextual bandits [25; 58; 24], reinforcement learning [27; 28], and imitation learning [56; 55].

In this paper, we investigate the relative power of online and offline estimation through a new information-theoretic perspective. It is well known that any algorithm for online estimation can be used _as-is_ to solve offline estimation through _online-to-batch conversion_, a standard technique in learning theory and statistics [3; 9; 16; 61; 36; 8]. The converse is less apparent, as online estimation requires non-trivial algorithm design techniques that go well beyond classical estimators like least-squares or maximum likelihood [17]. In the case of regression with a finite class \(\mathcal{F}\), least squares achieves optimal offline estimation error \(\mathbf{Est}_{\mathsf{D}}^{\mathsf{Off}}(T)\leq O(\log[\mathcal{F}])\),3 and while it is possible to achieve a similar rate \(\mathbf{Est}_{\mathsf{D}}^{\mathsf{on}}(T)\leq O(\log[\mathcal{F}])\) for online estimation, this requires Vovk's aggregating algorithm or exponential weights [65]; directly applying least squares or other standard offline estimators leads to vacuous guarantees. This leads us to ask: _Is it possible to convert offline estimation algorithms into online estimation algorithms in a black-box fashion?_

Footnote 3: We consider _unnormalized_ estimation error in Eq. (1), following the convention of online learning. For normalized estimation error, we have \(\frac{1}{T}\mathbf{Est}_{\mathsf{D}}^{\mathsf{Off}}(T)\leq\frac{\log[\mathcal{ F}]}{T}\), following the convention of statistical estimation.

Computationally speaking, this question has practical significance, since online estimation algorithms are typically far less efficient than their offline counterparts (the classical exponential weights algorithm maintains a separate weight for every \(f\in\mathcal{F}\), which is exponentially less memory-efficient than empirical risk minimization). In fact, at first glance this seems like a _purely_ computational question: if the learner has access to an offline estimator, nothing is stopping them (information-theoretically) from throwing the estimator away and using the data to run an online estimation algorithm.4 Yet, for aforementioned applications in interactive decision making [25; 58; 24; 27; 28; 56; 55], estimation algorithms--particularly online estimators--play a deeper information-theoretic role, and can be viewed as compressing the data stream into a succinct, operational representation that directly informs downstream decision making. With these applications in mind, the first contribution of this paper is to introduce a new protocol, _Oracle-Efficient Online Estimation_, which provides an _information-theoretic_ abstraction of the role of online versus offline estimation, analogous to the framework of information-based complexity in optimization [43; 60; 48; 2] and statistical query complexity in theoretical computer science [13; 37; 21; 22].

### Our protocol: oracle-efficient online estimation

In the Oracle-Efficient Online Estimation (OEOE) framework, the aim is to perform _online_ estimation in the sense of Eq. (2), with the twist that the learner does not directly observe the outcomes \(y^{\texttt{i}},\ldots,y^{\texttt{r}}\); rather, they interact with the environment _indirectly_ through a sequence of _offline_ estimators produced by a black-box algorithm operating on the historical data. We formalize this black-box algorithm as an _estimation oracle_\(\mathbf{Alg}_{\mathsf{Off}}=\left\{\mathbf{Alg}_{\mathsf{Off}}^{\texttt{i}} \right\}_{t=1}^{T}\) (e.g., Foster and Rakhlin [26]), which is a mapping from histories to estimators that enjoy bounded offline estimation error.

**Definition 1.1** (Offline estimation oracle).: _An offline estimation oracle\(\mathbf{Alg}_{\mathsf{Off}}=\left\{\mathbf{Alg}_{\mathsf{Off}}^{\texttt{i}} \right\}_{t=1}^{T}\) for a statistical estimation instance \((\mathcal{X},\mathcal{Y},\mathcal{Z},\mathcal{K},\mathcal{F})\) and loss \(\mathsf{D}\) is a mapping \(\mathbf{Alg}_{\mathsf{Off}}^{\texttt{i}}:(\mathcal{X}\times\mathcal{Y})^{t-1} \rightarrow(\mathcal{X}\rightarrow\mathcal{Z})\) such that for any sequence \((x^{\texttt{i}},y^{\texttt{i}}),\ldots,(x^{\texttt{r}},y^{\texttt{r}})\) with \(y^{\texttt{i}}\sim\mathcal{K}(f^{\star}(x^{\texttt{r}}))\), the sequence of estimators \(\widehat{f}^{\texttt{i}}=\mathbf{Alg}_{\mathsf{Off}}(x^{\texttt{i}},\ldots,x ^{\texttt{r}-1},y^{\texttt{i}},\ldots,y^{\texttt{r}-1})\) satisfies \(\mathbf{Est}_{\mathsf{D}}^{\texttt{Off}}(t):=\sum_{s=1}^{t-1}\mathsf{D}\big{(} \widehat{f}^{\texttt{i}}(x^{\texttt{r}}),f^{\star}(x^{\texttt{r}})\big{)} \leq\beta_{\mathsf{Off}}\) for all \(t\in[T]\) almost surely; we allow \(x^{\texttt{r}}\) to be selected adaptively based on \(y^{\texttt{i}},\ldots,y^{\texttt{r}-1}\) and \(\widehat{f}^{\texttt{i}},\ldots,\widehat{f}^{\texttt{i}-1}\). We refer to \(\beta_{\mathsf{Off}}\geq 0\) as the offline estimation parameter._

This definition simply asserts that the estimators \(\widehat{f}^{\texttt{i}}\) produced by the offline estimation oracle satisfy the guarantee in Eq. (1), even when the covariates are selected adaptively. Examples include standard algorithms like least-squares for regression and maximum likelihood for conditional density estimation, which guarantee \(\beta_{\mathsf{Off}}\leq O(\log|\mathcal{F}|)\) with high probability whenever \(\mathcal{F}\) is a finite class; see Appendix C.1 for further background.5 Throughout the paper, we assume for simplicity that \(\beta_{\mathsf{Off}}>0\) is known in advance.

Footnote 5: Most algorithms only ensure that the guarantee in Definition 1.1 holds with high probability. We assume an almost sure bound to simplify exposition, but our results trivially extend. Likewise, our results immediately extend to handle the case in which \(\beta_{\mathsf{Off}}\) is allowed to grow as a (sublinear) function of \(t\).

With this definition, we present the Oracle-Efficient Online Estimation protocol in Protocol 1. In the protocol, a learner aims to perform online estimation, but at each step \(t\), the only information available is the covariates \(x^{\texttt{i}},\ldots,x^{\texttt{r}-1}\) and the estimators \(\widehat{f}^{\texttt{i}},\ldots,\widehat{f}^{\texttt{i}}\) generated by an offline estimation oracle satisfying Definition 1.1; the outcomes \(y^{\texttt{i}},\ldots,y^{\texttt{r}}\) are not directly observed. Based on this information, the learner produces a new estimator \(\widehat{f}^{\texttt{i}}\) such that the online estimation error \(\mathbf{Est}_{\mathsf{D}}^{\mathsf{On}}(T)=\sum_{t=1}^{T}\mathbb{E}_{\widehat{f }\sim\mu^{\texttt{i}}}\big{[}\mathsf{D}\big{(}\bar{f}(x^{\texttt{r}}),f^{ \star}(x^{\texttt{i}})\big{)}\big{]}\) in Eq. (2) is minimized.6 An algorithm is termed _oracle-efficient_ if it attains low online estimation error (2) in the OEOE framework. Note that while the learner cannot directly observe the outcomes \(y^{\texttt{i}},\ldots,y^{\texttt{r}}\), the covariates \(x^{\texttt{i}},\ldots,x^{\texttt{r}}\) are observed; we prove that without this ability, it is impossible to achieve non-trivial estimation performance (Section 3).

Footnote 6: For technical reasons, we allow the learner to randomize the estimator \(\bar{f}^{\texttt{i}}\) via a distribution \(\mu^{\texttt{i}}\).

The OEOE framework abstracts away the property that oracle-efficient algorithms implicitly interact with the environment through a compressed, potentially lossy channel (the estimation oracle \(\mathbf{Alg}_{\mathsf{Est}}\)). We believe this property merits deeper investigation: it is shared by essentially all algorithms from recent research that reduces interactive decision making and reinforcement learning to estimation oracles [25, 58, 27, 28, 56, 55], yet the relative power of offline oracles and analogously defined online oracles is poorly understood in this context. By providing an information-theoretic abstraction to study oracle-efficiency, the OEOE framework plays a role similar to information-based complexity in optimization [43, 60, 48, 2] and statistical query complexity in theoretical computer science [13, 37, 21, 22], both of which provide rich frameworks for designing and evaluating iterative algorithms that interact with the environment in a structured fashion. We expect that this abstraction will find broader use for more complex domains (e.g., decision making and active learning) as a means to guide algorithm design and prove lower bounds against natural classes of algorithms.

Let us first build some intuition. Familiar readers may recognize that the classical _halving algorithm_ for binary classification (e.g., Cesa-Bianchi and Lugosi [17]) can be viewed as oracle-efficient in our framework. Specifically, for binary classification with \(\mathcal{Y}=\mathcal{Z}=\{0,1\}\) and loss function \(\mathsf{D}_{0/1}\big{(}\widehat{f}(x),f^{\star}(x)\big{)}=1\big{\{}\widehat{f}( x)\neq f^{\star}(x)\big{\}}\), the halving algorithm can use any offline oracle with \(\beta_{\text{Off}}=0\) to achieve \(\mathbf{Est}_{\text{D}}^{\text{On}}(T)=O(\log|\mathcal{F}|)\), which is optimal. However, little is known for noisy oracles with \(\beta_{\text{Off}}>0\), or more general outcome spaces and loss functions (e.g., regression or density estimation). In addition, the halving algorithm--while oracle-efficient--is computationally inefficient, as it requires maintaining an explicit version space. This leads us to restate our central question formally, in two parts:

1. _Can we design oracle-efficient algorithms with near-optimal online estimation error (2), up to polynomial factors (for general instances \((\mathcal{X},\mathcal{Y},\mathcal{Z},\mathcal{K},\mathcal{F})\) and \(\beta_{\text{Off}}>0\))?_
2. _Can we do so in a computationally efficient fashion?_

### Contributions

For a general class of losses \(\mathsf{D}\), referred to as _metric-like_, we settle the statistical and computational complexity of performing online estimation via black-box offline estimation oracles up to mild gaps, answering questions (1) and (2) above.

Statistical complexity.Our first result concerning statistical complexity focuses on finite classes \(\mathcal{F}\), where the optimal rates for offline and online estimation with standard losses \(\mathsf{D}(\cdot,\cdot)\) both scale as \(\Theta(\log|\mathcal{F}|)\). For this setting, we show (Theorem 3.1) that there exists an oracle-efficient online estimation algorithm that achieves \(\mathbf{Est}_{\text{D}}^{\text{On}}(T)=O((\beta_{\text{Off}}+1)\min\{\log| \mathcal{F}|,|\mathcal{X}|\})\) in the OEOE framework, and that this is optimal (Theorem 3.2). This provides an affirmative answer to question (1), and characterizes the statistical complexity of oracle-efficient online estimation with finite classes \(\mathcal{F}\).

In the general OEOE framework, the learner can use the entire history of offline estimators \(\widehat{f}^{1},\dots,\widehat{f}^{t}\) and covariates \(x^{1},\dots,x^{t-1}\) to produce the online estimator \(\bar{f}^{t}\) for step \(t\). As a secondary result, we study a restricted class of _memoryless_ oracle-efficient algorithms that choose \(\bar{f}^{t}\) only based on the most recent offline estimator \(\widehat{f}^{t}\), and show (Theorem 3.3) that it is impossible for such algorithms to achieve low online estimation error.

Lastly, we give a more general approach to deriving oracle-efficient reductions (Theorem D.1) that is based on _delayed online learning_[67, 42, 35, 47]. Using this result, we give a characterization of learnability with _infinite classes_ for binary classification in the OEOE framework (Theorem D.2), proving that finite Littlestone dimension is necessary and sufficient for oracle-efficient learnability.

Computational complexity.On the computational side, we provide a negative answer to question (2), showing (Theorem 4.1) that under standard conjectures in computational complexity, there do not exist polynomial-time algorithms with non-trivial online estimation error in OEOE framework. In spite of this negative result, we provide a fine-grained perspective for the statistical problem of _conditional density estimation_, a general task that subsumes classification and regression and has immediate applications to reinforcement learning and interactive decision making [27, 28]. Here we show, perhaps surprisingly (Theorem 4.2), that online estimation in the OEOE framework is no harder computationally than online estimation with arbitrary, unrestricted algorithms. This result is salient in light of the applications we discuss below.

Implications for interactive decision making.As the preceding discussion has alluded to, our interest in studying oracle-efficient online estimation is largely motivated by a connection to the problem of _interactive decision making_. Foster et al. [27, 28], Foster and Rakhlin [26] propose a general framework for interactive decision making called _Decision Making with Structured Observations_ (DMSO), which subsumes contextual bandits, bandit problems with structured rewards, and reinforcement learning with general function approximation. They show that for any decision making problem in the DMSO framework, there exists an algorithm that, given access to an online estimation algorithm (or, "oracle") for conditional density estimation for an appropriate class \(\mathcal{F}\), it is possible to achieve _near-optimal regret_. The results above critically make use of _online estimation_ oracles, as they require achieving low estimation error for adaptively chosen sequences of covariates, and it is natural to ask whether similar guarantees can be achieved using only offline estimation oracles. However, positive results are only known for certain special cases [18, 19, 20, 58], with scant results for reinforcement learning in particular. In this context, our results have the following implication (Corollary E.1): _Information-theoretically, it is possible to achieve near-optimal regret for any interactive decision making problem using an algorithm that accesses the data stream only through offline estimation oracles._

Additional results._Due to space constraints, the following results are deferred to the appendix: (i) detailed examples for our statistical estimation framework (Appendix C); (ii) additional results concerning statistical complexity of the OEOE framework (Appendix D); and (iii) detailed results for our application to interactive decision making (Appendix E)._

## 2 Preliminaries

Unless otherwise stated, our results assume the loss function \(\mathsf{D}\) has _metric-like_ structure.

**Definition 2.1** (Metric-like loss).: _A loss function \(\mathsf{D}:\mathcal{Z}\times\mathcal{Z}\to[0,1]\) is metric-like on the set \(\mathcal{Z}\) if it is symmetric and satisfies (i) \(\mathsf{D}(z_{1},z_{2})\geq 0\) for any \(z_{1},z_{2}\in\mathcal{Z}\) and \(\mathsf{D}(z,z)=0\) for all \(z\in\mathcal{Z}\); and (ii) \(\mathsf{D}(z_{1},z_{2})\leq C_{\mathsf{D}}\cdot(\mathsf{D}(z_{1},z_{3})+ \mathsf{D}(z_{3},z_{2}))\) for all \(z_{1},z_{2},z_{3}\in\mathcal{Z}\), for an absolute constant \(C_{\mathsf{D}}\geq 1\)._

Throughout the paper, we focus on three canonical applications, outlined in the introduction: Classification with the indicator loss \(\mathsf{D}_{0/1}\) (\(C_{\mathsf{D}}=1\)), regression with the square loss \(\mathsf{D}_{\mathsf{sq}}\) (\(C_{\mathsf{D}}=2\)), and conditional density estimation with squared Hellinger distance \(\mathsf{D}_{\mathsf{H}}^{2}\) (\(C_{\mathsf{D}}=2\)). See Appendix C for detailed examples and discussion. (omitted for space).

Finite versus infinite classes.The majority of our results focus on finite classes \(\mathcal{F}\). We believe this captures the essential difficulty of the problem, but we expect that most of our sample complexity results (which typically scale with \(\log|\mathcal{F}|\)) can be extended to infinite classes by combining our techniques with appropriate notions of complexity for the function class (Littlestone dimension for classification, sequential Rademacher complexity, and sequential covering numbers [50; 41; 52]). For the canonical settings of classification, regression, and conditional density estimation, there exist algorithms that achieve \(\mathbf{Est}_{\mathsf{D}}^{\mathsf{Off}}(T)=O(\log|\mathcal{F}|)\) and \(\mathbf{Est}_{\mathsf{D}}^{\mathsf{On}}(T)=O(\log|\mathcal{F}|)\) for arbitrary finite classes; see Appendix C for details.

We defer additional notation and related work to Appendices A and B

## 3 Statistical complexity of oracle-efficient online estimation

This section presents our main results concerning the statistical complexity of oracle-efficient online estimation. In Section 3.1, we focus on finite classes \(\mathcal{F}\) and present an oracle-efficient algorithm that achieves near-optimal online estimation error (Theorem 3.1). We then provide a lower bound that shows that our reduction is near optimal (Theorem 3.2). In Section 3.2, we turn our attention to memoryless oracle-efficient algorithms, proving strong impossibility results (Theorem 3.3).

### Minimax sample complexity for oracle-efficient algorithms

In this section, we present our main statistical conclusion for the OEOE framework: _For any finite class \(\mathcal{F}\), it is possible to transform any black-box offline estimation algorithm into an online estimation algorithm with near-optimal error_ (up to a logarithmic factor that we show is unavoidable).

Algorithm and minimax upper bound.Our results are achieved through a new algorithm, _Version Space Averaging_, described in Algorithm 1. At each round \(t\), the algorithm uses estimators \(\widehat{f}^{\ast},\ldots,\widehat{f}^{\ast}\) produced by an offline estimation oracle \(\mathbf{Alg}_{\mathsf{Off}}\), along with the previous covariates \(x^{1},\ldots,x^{t-1}\), to construct a _version space_\(\mathcal{F}_{t}\subseteq\mathcal{F}\) in Eq. (3). Informally, \(\mathcal{F}_{t}\) consists of all \(f\in\mathcal{F}\) that are _consistent_ with the estimators \(\widehat{f}^{1},\ldots,\widehat{f}^{\ast}\) in the sense that for all \(s\in[t]\), the offline estimation error relative to \(\widehat{f}^{\ast}\) is small; as long as the offline estimation oracle \(\mathbf{Alg}_{\mathsf{Off}}\) has offline estimation error \(\beta_{\mathsf{Off}}\) (Definition 1.1), it follows immediately that the construction in Eq. (3) satisfies \(f^{\ast}\in\mathcal{F}_{t}\). Given the version space \(\mathcal{F}_{t}\), Algorithm 1 predicts by uniformly sampling: \(\bar{f}^{\ast}\sim\mu^{\ast}:=\mathrm{Unif}(\mathcal{F}_{t})\), then proceeds to the next round.7 The main guarantee for Algorithm 1 is stated in Theorem 3.1.

**Theorem 3.1** (Main upper bound for OEOE).: _For any instance \((\mathcal{X},\mathcal{Y},\mathcal{Z},\mathcal{K},\mathcal{F})\), any metric-like loss \(\mathsf{D}\), and any offline estimator \(\mathbf{Alg}_{\mathsf{Off}}\) with parameter \(\beta_{\mathsf{Off}}\geq 0\), Algorithm 1 is oracle-efficient and achieves_

\[\mathbf{Est}_{\mathsf{D}}^{\mathsf{On}}(T)\leq O(C_{\mathsf{D}}\cdot(\beta_{ \mathsf{Off}}+1)\cdot\min\left\{\log|\mathcal{F}|,|\mathcal{X}|\log T\right\}).\]

Most notably, Algorithm 1 achieves \(\mathbf{Est}_{\mathsf{D}}^{\mathsf{On}}(T)\leq O(C_{\mathsf{D}}\cdot(\beta_{ \mathsf{Off}}+1)\cdot\log|\mathcal{F}|)\); that is, up to a \(O(\log|\mathcal{F}|)\) factor, the reduction achieves online estimation rates in the OEOE framework that are no worse than the minimax rate for offline estimation. For classification, regression, and density estimation with generic finite classes \(\mathcal{F}\) (Appendix C), the best possible offline estimation error rate is \(\beta_{\mathsf{Off}}=O(\log|\mathcal{F}|)\), so this shows that price of oracle-efficiency is at most quadratic.

Minimax lower bound.Next, we show that the upper bound in Theorem 3.1 is nearly tight, giving a lower bound that matches up to logarithmic factors.

**Theorem 3.2** (Main lower bound for OEOE).: _Consider the binary classification setting with \(\mathcal{Z}=\mathcal{Y}=\{0,1\}\) and loss \(\mathsf{D}_{0/1}(\cdot,\cdot)\). For any \(N\in\mathbb{N}\) and \(\beta_{\mathsf{Off}}>0\), there exists an instance \((\mathcal{X},\mathcal{Y},\mathcal{Z},\mathcal{K},\mathcal{F})\) with \(\log|\mathcal{F}|=|\mathcal{X}|=N\) such that for any oracle-efficient algorithm, there is a sequence of covariates \((x^{1},\ldots,x^{r})\) and offline oracle with parameter \(\beta_{\mathsf{Off}}\) such that \(\mathbb{E}\big{[}\mathbf{Est}_{\mathsf{D}}^{\mathsf{On}}(T)\big{]}\geq\Omega( \min\left\{(\beta_{\mathsf{Off}}+1)N,T\right\})\)._

This result states that for a generic finite class \(\mathcal{F}\) and offline estimation oracle \(\mathbf{Alg}_{\mathsf{Off}}\), any oracle-efficient online estimator must have

\[\mathbb{E}\big{[}\mathbf{Est}_{\mathsf{D}}^{\mathsf{On}}(T)\big{]}\geq\Omega (\min\left\{(\beta_{\mathsf{Off}}+1)\log|\mathcal{F}|,(\beta_{\mathsf{Off}}+1) |\mathcal{X}|,T\right\})\]

in the worst case. This implies that the \(\log|\mathcal{F}|\) factor we pay for offline to online conversion is unavoidable, and that Theorem 3.1 is optimal up to a \(\log T\) factor, giving a near-optimal characterization for the minimax rate for online estimation in the OEOE framework. We conclude with two remarks: (i) The \((\beta_{\mathsf{Off}}+1)\) scaling (as opposed to say, \(\beta_{\mathsf{Off}}\)) in Theorem 3.1 is unavoidable, as witnessed by the optimality of the halving algorithm for noiseless binary classification [17]; (ii) if the space \(\mathcal{Z}\) and the loss \(\mathsf{D}\) are convex, then we can change Algorithm 1 to output a deterministic prediction by using the average of all parameters in \(\mathcal{F}_{t}\) rather than the uniform distribution on \(\mathcal{F}_{t}\). See Lemma G.1 for details.

General reductions and infinite classes.Algorithm 1 is somewhat specialized to finite classes. In Appendix D (deferred to the appendix for space), we provide a more general approach to designing oracle-efficient algorithms based on _delayed online learning_ (Theorem D.1), and use it to derive a characterization of oracle-efficient learnability for classification with infinite classes \(\mathcal{F}\) (Theorem D.2).

Full memory vs. finite memory.Algorithm 1 requires full memory of all past offline estimators. The more general approach proposed in Appendix D can use \(N\) most recent offline estimators to obtain an estimation error bound of \(O(C_{\mathsf{D}}(N+\beta_{\mathsf{Off}}T/N)+N\cdot\log|\mathcal{F}|)\) (Corollary D.1) for any integer \(N>0\).

### Impossibility of memoryless oracle-efficient algorithms

In the general OEOE framework, the learner can use the entire history of estimators \(\widehat{f}^{1},\ldots,\widehat{f}^{i}\) and covariates \(x^{1},\ldots,x^{r-1}\) to produce the online estimator \(\widehat{f}^{i}\) for step \(t\); notably the Version Space Averaging algorithm with which our upper bounds in the prequel are derived uses the entire history. In this section, we show that for _memoryless_ oracle-efficient algorithms (Definition 3.1) that select the estimator \(\widehat{f}^{i}\) only as a function of the most recent offline estimator \(\widehat{f}^{i}\), similar guarantees are impossible.

**Definition 3.1** (Memoryless algorithm).: _An online estimation algorithm is memoryless if there exists a map \(F^{\iota}(\cdot)\) such that we can write \(\mu^{\iota}=F^{\iota}(\widehat{f}^{\iota})\), where \(\widehat{f}^{\iota}=\mathbf{Alg}_{\mathsf{Off}}^{\iota}(x^{1},\ldots,x^{\iota-1},y^{1},\ldots,y^{\iota-1})\) and \(\mu^{\iota}\) is the randomization distribution for the online estimator \(\widehat{f}^{\iota}\).8_

Footnote 8: There are many natural variants of this protocol. For example, algorithms could select \(\mu^{\iota}\) based on \(\widehat{f}^{\iota}\) and \(B\) bits of auxiliary memory. We hope future work will explore these variants.

Memoryless algorithms are more practical than arbitrary algorithms, since they do not require storing past estimators or covariates in memory. Our motivation for studying memoryless algorithms arises from recent work in interactive decision making [25; 27], which shows that there exist near-optimal algorithms for contextual bandits and reinforcement learning that use estimation oracles in memoryless fashion. We show that unfortunately, it is not possible to convert offline estimators into memoryless online estimation algorithms with non-trivial error.

**Theorem 3.3** (Impossibility of memoryless algorithms for OEOE).: _Consider the binary classification setting with \(\mathcal{Z}=\mathcal{Y}=\{0,1\}\) and loss \(\mathsf{D}_{0/1}(\cdot,\cdot)\). For any \(N\in\mathbb{N}\) and \(\beta_{\mathsf{Off}}\geq 0\), there exists an instance \((\mathcal{X},\mathcal{Y},\mathcal{Z},\mathcal{K},\mathcal{F})\) with \(|\mathcal{F}|=|\mathcal{X}|=N\) such that for any memoryless oracle-efficient algorithm, there exists a sequence of covariates \((x^{1},\ldots,x^{r})\) and a (potentially improper) offline oracle \(\mathbf{Alg}_{\mathsf{Off}}\) with parameter \(\beta_{\mathsf{Off}}\) such that \(\mathbb{E}\left[\mathbf{Est}_{\mathsf{D}}^{\mathsf{On}}(T)\right]\geq\Omega( \min\left\{N(\beta_{\mathsf{Off}}+1),T\right\})\). This conclusion still holds when the online estimation algorithm remembers \(\widehat{f}^{1},\ldots,\widehat{f}^{\iota-1}\) but not \(x^{1},\ldots,x^{\iota-1}\)._

This result shows that in the worst case, any memoryless oracle-efficient algorithm must have

\[\mathbb{E}\big{[}\mathbf{Est}_{\mathsf{D}}^{\mathsf{On}}(T)\big{]}\geq\Omega ((\beta_{\mathsf{Off}}+1)\min\{|\mathcal{X}|,|\mathcal{F}|\}).\]

This precludes an online estimation error bound scaling with \((\beta_{\mathsf{Off}}+1)\log|\mathcal{F}|\) as in Theorem 3.1, and shows that the gap between general and memoryless oracle-efficient algorithms can be exponential.

Interestingly, the lower bound in Theorem 3.3 holds even if the online estimation algorithm is allowed to remember \(\widehat{f}^{1},\ldots,\widehat{f}^{\iota-1}\), but not \(x^{1},\ldots,x^{\iota-1}\). The intuition here is that without covariate information, it is not possible to aggregate the predictions of previous estimators or otherwise use them to reduce uncertainty. This provides post-hoc motivation for our decision to incorporate covariate memory into the OEOE protocol in Section 1.1.

The proof of Theorem 3.3 uses that the estimators \(\widehat{f}^{\iota}\) produced by the offline estimation oracle may be _improper_ (i.e., \(\widehat{f}^{\iota}\notin\mathcal{F}\)). We defer a variant of the result that holds even if the estimation oracle is _proper_ under additional assumptions as well as the complementary upper bound to Appendix D.2

## 4 Computational complexity of oracle-efficient online estimation

In this section, we turn our attention to the computational complexity of oracle-efficient online estimation in the OEOE framework. In Section 4.1, we show (Theorem 4.1) that in general, it is not possible to transform black-box offline estimation algorithms into online estimation algorithms in a computationally efficient fashion. Then, in Section 4.2, we provide a more fine-grained perspective, showing (Theorem 4.2) that for conditional density estimation, online estimation in the OEOE framework is no harder computationally than online estimation with unrestricted algorithms.

### Computational hardness of oracle-efficient estimation

Our main upper bounds (Section 3.1) show that online estimation error \(\mathbf{Est}_{\mathsf{D}}^{\mathsf{On}}(T)\leq O((\beta_{\mathsf{Off}}+1) \log|\mathcal{F}|)\) can be achieved in an oracle-efficient fashion for any finite class \(\mathcal{F}\), but the algorithm (Algorithm 1) is not computationally efficient. We now show that this is fundamental: There exist classes \(\mathcal{F}\) for which offline estimation can be performed in polynomial time, yet no oracle-efficient algorithm running in polynomial-time algorithm can achieve sublinear online estimation error.

Computational model.To present our results, we must formalize a computational model for oracle-efficient online estimation, and in particular, define a notion of _input length_ for oracle-efficient online algorithms. To do so, we restrict our attention to noiseless binary classification, and consider a sequence of classification instances indexed by \(n\in\mathbb{N}\), with \(\mathcal{Z}=\mathcal{Y}=\{0,1\}\), \(\mathcal{X}_{n}:=\{0,1\}^{n}\), \(\mathcal{K}(z)=\mathbbm{1}_{z}\), and indicator loss \(\mathsf{D}_{0/1}(\cdot,\cdot)\). We consider a sequence of classes \(\mathcal{F}_{n}\) that have polynomial description length.e. \(\log|\mathcal{F}_{n}|\) is polynomial in \(n\), so that \(f\in\mathcal{F}_{n}\) can be described in \(\operatorname{poly}(n)\) bits. In particular, we assume that \(f\in\mathcal{F}_{n}\) is represented as a Boolean circuit of size \(\operatorname{poly}(n)\) so that \(f(x)\) can be computed in \(\operatorname{poly}(n)\) time for \(x\in\mathcal{X}_{n}\); we refer to such sequences as _polynomially computable_.

To allow for offline estimators that are improper, we assume that for all \(t\) and all sequences \((x^{i},y^{i}),\ldots,(x^{r},y^{r})\), the output \(\widehat{f}^{i}:\{0,1\}^{n}\to\{0,1\}\) returned by \(\mathbf{Alg}_{\text{Off}}^{\text{c}}(x^{1},\ldots,x^{t-1},y^{1},\ldots,y^{t-1})\) is a Boolean circuit of size \(\operatorname{poly}(n)\); we refer to such oracles as having \(\operatorname{poly}(n)\)-_output description length_.9 Likewise, to allow the online estimation algorithm itself to be improper and randomized, we restrict to algorithms for which computing \(\bar{f}^{i}(x)\) for \(\bar{f}^{i}\sim\mu^{i}\) can be implemented as \(\bar{f}^{i}(x,r)\) for a random bit string \(r\sim\operatorname{Unif}(\{0,1\}^{B})\), where \(B=\operatorname{poly}(n)\); we refer to the online estimator as having \(\operatorname{poly}(n)\)-output description length if \(\bar{f}^{i}(\cdot,\cdot)\) is itself a Boolean circuit of size \(\operatorname{poly}(n)\). We refer to the online estimation algorithm _polynomial time_ if it runs in time \(\operatorname{poly}(n)\) for any sequence of inputs \(t\), \(x^{1},\ldots,x^{t-1}\), and \(\widehat{f}^{1},\ldots,\widehat{f}^{t-1}\), and has \(\operatorname{poly}(n)\)-output description length.10

Footnote 9: See, e.g., Arora and Barak [6], Definition 6.1

Footnote 10: The precise computational model for runtime under consideration (e.g., Turing machines or Boolean circuits) does not change the nature of our results.

Main lower bound.Our main computational lower bound is as follows.

**Theorem 4.1** (Computational lower bound for OEOE).: _Assume the existence of one-way functions.11 There exists a sequence of polynomially computable classes \((\mathcal{F}_{1},\mathcal{F}_{2},\ldots,\mathcal{F}_{n},\ldots)\), along with a sequence of \(\operatorname{poly}(n)\)-output description length offline oracles with \(\beta_{\text{Off}}=0\) associated with each \(\mathcal{F}_{n}\), such that for any fixed polynomials \(p,q:\mathbb{N}\to\mathbb{N}\) and all \(n\in\mathbb{N}\) sufficiently large, any oracle-efficient online estimation algorithm with runtime bounded by \(p(n)\) must have \(\mathbb{E}[\mathbf{Est}_{\mathsf{D}}^{\mathsf{O}n}(T)]\geq T/4\) for all \(1\leq T\leq q(n)\). At the same time, there exists an inefficient algorithm that achieves \(\mathbb{E}[\mathbf{Est}_{\mathsf{D}}^{\mathsf{O}n}(T)]\leq O(\sqrt{n})\) for all \(T\in\mathbb{N}\)._

Footnote 11: Existence of one-way functions is a standard and widely believed complexity-theoretic assumptions, which forms the basis of modern cryptography [30].

Informally, Theorem 4.1 shows that there exist a class \(\mathcal{F}\) and offline estimation oracles \(\mathbf{Alg}_{\text{Off}}\) for which no oracle-efficient online estimation algorithm that runs in time

\[\operatorname{poly}(\mathsf{len}(\mathcal{X}),\mathsf{len}(\mathcal{F}),\max _{t}\mathsf{len}(\widehat{f}^{i}),T)\]

can achieve sublinear estimation error, where \(\mathsf{len}(\mathcal{X})\) and \(\mathsf{len}(\mathcal{F})\) denote the number of bits required to describe \(x\in\mathcal{X}\) and \(f\in\mathcal{F}\), and \(\mathsf{len}(\widehat{f}^{i})\) denotes the size of the circuit required to compute \(\widehat{f}^{i}(x)\). Yet, low online estimation error _can_ be achieved by an inefficient algorithm, and there exist efficient offline estimators with \(\beta_{\text{Off}}=0\) as well. The result is essentially a corollary of Blum [14]; we refer to Appendix H.1 for the detailed proof. We mention in passing that Hazan and Koren [33] also give lower bounds against reducing online learning to offline oracles, but in a somewhat different computational model; see Appendix B for detailed discussion.

Theorem 4.1 is slightly disappointing, since one of the main motivations for studying oracle-efficiency is to leverage offline estimators as a computational primitive. Combined with our results in Section 3, Theorem 4.1 shows that even though it is possible to be oracle-efficient information-theoretically, it is not possible to achieve this computationally. Nonetheless, we are optimistic that our abstraction can (i) aid in designing computationally efficient algorithms for learning settings beyond online estimation, and (ii) continue to serve as a tool to formalize lower bounds against natural classes of algorithms, as we have done here; see Section 5 for further discussion.

**Remark 4.1**.: _Theorem 4.1 relies on the fact that the offline estimator may be improper (i.e., \(\widehat{f}^{i}\notin\mathcal{F}\)). An interesting open problem is whether one can attain \(\operatorname{poly}(\log|\mathcal{F}_{n}|)\cdot o(T)\) online estimation error with runtime \(\operatorname{poly}(\log|\mathcal{F}_{n}|)\) given a proper offline estimation oracle with parameter \(\beta_{\text{Off}}=0\). \(\triangleleft\)_

### Conditional density estimation: computationally efficient algorithms

In spite of the negative result in the prequel, which shows that efficient computation in the OEOE framework is not possible in general, we can provide a more fine-grained perspective on the computational complexity of oracle-efficient estimation for the problem _conditional density estimation_, a general task which subsumes classification and regression, and has immediate applications to reinforcement learning and interactive decision making [27; 28].

Conditional density estimation.Recall that conditional density estimation [71; 12] is the special case of the online estimation framework in Section 1 in which \(\mathcal{X}\) and \(\mathcal{Y}\) are arbitrary, \(\mathcal{Z}=\Delta(\mathcal{Y})\), and the kernel is \(\mathcal{K}(z)=z\); that is sampling \(y\sim\mathcal{K}(f^{\star}(x))\) is equivalent to sampling \(y\sim f^{\star}(x)\). For the loss, we use squared Hellinger distance: \(\mathsf{D}_{\mathsf{H}}^{2}\big{(}f(x),f^{\star}(x)\big{)}=\frac{1}{2}\int\bigl{(} \sqrt{f(y\mid x)}-\sqrt{f^{\star}(y\mid x)}\bigr{)}^{2}\); with online estimation error given by \(\operatorname{\mathbf{Est}}_{\mathsf{H}}^{\mathsf{On}}(T)=\sum_{t=1}^{T} \mathsf{D}_{\mathsf{H}}^{2}\big{(}\widehat{f}^{\prime}(x^{t}),f^{\star}(x^{t}) \big{)}\).

**Base algorithm.** Our result is based on a reduction. We assume access to a base algorithm \(\mathcal{A}_{\mathsf{CDE}}\) for online estimation in the Conditional Density Estimation (CDE) framework, which is _unrestricted_ in the sense that it is not necessarily oracle-efficient. That is, \(\mathcal{A}_{\mathsf{CDE}}\) can directly use the full data stream \((x^{\downarrow},y^{\downarrow}),\dots,(x^{\downarrow-1},y^{\downarrow-1})\) at step \(t\). For parameters \(R_{\mathsf{CDE}}(T)\) and \(C_{\mathcal{F}}\geq 1\), we assume that for any \(f^{\star}\in\mathcal{F}\), the base algorithm \(\mathcal{A}_{\mathsf{CDE}}\) ensures that for all \(\delta\in(0,e^{-1})\), with probability at least \(1-\delta\),

\[\operatorname{\mathbf{Est}}_{\mathsf{H}}^{\mathsf{On}}(T)\leq R_{\mathsf{CDE }}(T)+C_{\mathcal{F}}\cdot\log(1/\delta).\] (4)

We define the total runtime for \(\mathcal{A}_{\mathsf{CDE}}\) across all rounds as \(\mathsf{Time}(\mathcal{F},T)\).

Main result.Our main result shows that any algorithm \(\mathcal{A}_{\mathsf{CDE}}\) satisfying the guarantee above can be transformed into an oracle-efficient algorithm with only polynomial blowup in runtime. For technical reasons, we assume that \(V:=e\ \vee\ \sup_{f,f^{\prime}\in\mathcal{F},x\in\mathcal{X},y\in\mathcal{Y}} \frac{f(y\mid x)}{f^{\prime}(y\mid x)}\) is bounded; our sample complexity bounds scale only logarithmically with respect to this parameter. In addition, we assume that all \(f\in\mathcal{F}\) and \(x\in\mathcal{X}\) have \(O(1)\) description length, and that one can sample \(y\sim f(x)\) in \(O(1)\) time.

**Theorem 4.2**.: _Let \(\mathcal{A}_{\mathsf{CDE}}\) be an arbitrary (unrestricted) online estimation algorithm that satisfies Eq. (4) and has runtime \(\mathsf{Time}(\mathcal{F},T)\). Then for any \(N\in\mathbb{N}\), there exists an oracle-efficient online estimation algorithm that achieves estimation error_

\[\mathbb{E}\bigl{[}\operatorname{\mathbf{Est}}_{\mathsf{H}}^{\mathsf{On}}(T) \bigr{]}\leq\widetilde{O}(C_{\mathcal{F}}\log V\cdot\beta_{\mathsf{Off}}T/N+N \cdot(R_{\mathsf{CDE}}(T)+C_{\mathcal{F}}\log V))\]

_with runtime \(\operatorname{poly}(\mathsf{Time}(\mathcal{F},T),\log|\mathcal{F}|,\log| \mathcal{X}|,T)\), where \(\beta_{\mathsf{Off}}\geq 0\) is the offline estimation parameter. The distributions \(\mu^{1},\dots,\mu^{T}\) produced by the algorithm have support size \(\operatorname{poly}(\log|\mathcal{F}|,\log|\mathcal{X}|,T)\). As a special case, if the online estimation guarantee for the base algorithm holds with \(R_{\mathsf{CDE}}(T)\leq C_{\mathcal{F}}^{\prime}\log T\) for some problem-dependent constant \(C_{\mathcal{F}}^{\prime}\geq 1\), then by choosing \(N\) appropriately, we achieve \(\mathbb{E}\bigl{[}\operatorname{\mathbf{Est}}_{\mathsf{H}}^{\mathsf{On}}(T) \bigr{]}\leq\widetilde{O}\bigl{(}(C_{\mathcal{F}}(C_{\mathcal{F}}+C_{\mathcal{ F}}^{\prime})\beta_{\mathsf{Off}})^{1/2}\log V\cdot T^{1/2}+(C_{\mathcal{F}}+C_{ \mathcal{F}}^{\prime})\log V\bigr{)}\)._

Note that the estimation error bound in Theorem 4.2 is sublinear whenever the rate \(R_{\mathsf{CDE}}(T)\) is. This implies that for squared Hellinger distance, online estimation in the OEOE framework is no harder computationally than online estimation with arbitrary, unrestricted algorithms.

The proof of Theorem 4.2 is algorithmic, and is based on several layers of reductions. The main reason why the result is specialized to conditional density estimation is as follows: If we have an estimator \(\widehat{f}\) for which \(\mathsf{D}_{\mathsf{H}}^{2}\big{(}\widehat{f}(x),f^{\star}(x)\big{)}\) is small for some \(x\), we can simulate \(y\sim f^{\star}(x)\) up to low statistical error by sampling \(y\sim\widehat{f}(x)\) instead, as \(\widehat{f}\) and \(f^{\star}\) are close in distribution. This allows us to implement a scheme based on simulating outcomes and feeding them to the base algorithm.

## 5 Discussion

Our work introduces the Oracle-Efficient Online Estimation protocol as an information-theoretic framework to study the relative power of online and offline estimators and gives a nearly complete characterization of the statistical and computational complexity of learning in this framework. In what follows, we discuss broader implications for our information-abstraction of oracle-efficiency.

Oracle-efficient learning as a general framework for analysis of algorithms.One of the most important contributions of this work is to formalize oracle-efficient algorithms as mappings that act upon a sequence of estimators but do not directly act on historical outcomes. While the computational lower bounds we provide for oracle-efficient learning are somewhat disappointing, we are optimistic that--similar to statistical query complexity in TCS and information-based complexity in optimization--our abstraction can (i) aid in designing computationally efficient algorithms for learning settings beyond online estimation, and (ii) continue to serve as a tool to formalize lower bounds against natural classes of algorithms, for estimation and beyond. That is, we envision _oracle-efficient learning_ as a more general framework to study oracle-based algorithms in any type of interactive learning problem. We remark that one need not restrict to offline oracles; it is natural to study oracle-efficient algorithms based on online estimation oracles or other types of oracles through our information-theoretic abstraction as well. For concreteness, let us mention a couple of natural settings where our information-theoretic abstraction can be applied.

_Oracle-efficient interactive decision making_. For interactive decision making problems like bandits and reinforcement learning (more broadly, the DMSO framework described in Appendix E.1), it is natural to formalize _oracle-efficient_ algorithms as algorithms that do not directly observe rewards (bandits) or trajectories (reinforcement learning), and instead must select their decision based on an (online or offline) estimator (e.g., regression for bandits or conditional density estimation for RL). Foster and Rakhlin (2015) and Foster et al. (2017) et seq. provide algorithms with this property for contextual bandits and RL, respectively, but the power of offline oracles in this context is not well understood.

_Oracle-efficient active learning_. For active learning, it is natural to consider algorithms that decide whether to query the label for a point in an oracle-efficient fashion (e.g., Krishnamurthy et al. (2018)). For concreteness, consider pool-based active learning (Krishnamurthy et al., 2018). Suppose the learner is given a pool \(\mathcal{P}=\{x_{1},...,x_{n}\}\) of covariates and a parameter space \(\mathcal{F}\). The learner can repeatedly choose \(x^{t}\in\mathcal{P}\) and call the offline oracle to obtain an estimator \(\widehat{f}^{i}\) such \(\mathbf{Est}_{\text{D}}^{\text{Off}}(t):=\sum_{i<t}\text{D}\left(\widehat{f} ^{i}(x^{i}),f^{\star}(x^{i})\right)\leq\beta_{\text{Off}}\) (in contrast to an unrestricted algorithm that observes \(y^{t}=f^{\star}(x^{t})\)). The aim is to learn a hypothesis with low classification error using the smallest number of queries possible. Can we design oracle-efficient algorithms that do so with near-optimal label complexity?

### Further Directions

We close with some additional directions for future research.

Refined notions of estimation oracles.This work considers generic offline estimation algorithms that satisfy the statistical guarantee in Definition 1.1 but can otherwise be arbitrary. Understanding the power of offline estimators that satisfy more refined (e.g., problem-dependent) guarantees is an interesting direction for future research.

Open questions for proper versus improper learning.Our results leave some interesting gaps in the power of proper versus improper oracles. First, the computational lower bounds in Section 4.1, leave open the possibility of attaining \(\operatorname{poly}(\log|\mathcal{M}_{n}|)\cdot o(T)\) online estimation error with runtime \(\operatorname{poly}(\log|\mathcal{M}_{n}|)\) given access to a _proper_ offline estimation oracle with parameter \(\beta_{\text{Off}}=0\). Second, our results in Section 3.2 leave open the possibility of bypassing the \(\Omega(|\mathcal{X}|(\beta_{\text{Off}}+1))\) lower bound for memoryless algorithms under the assumption that the offline oracle is proper.

### Acknowledgments and Disclosure of Funding

We acknowledge support from the ARO through award W911NF-21-1-0328 and from the Simons Foundation and the NSF through award DMS-2031883.

## References

* [1] Anders Aamand, Justin Y Chen, Huy Le Nguyen, and Sandeep Silwal. Improved space bounds for learning with experts. _arXiv preprint arXiv:2303.01453_, 2023.
* [2] Alekh Agarwal, Peter L Bartlett, Pradeep Ravikumar, and Martin J Wainwright. Information-theoretic lower bounds on the oracle complexity of stochastic convex optimization. _IEEE Transactions on Information Theory_, 5(58):3235-3249, 2012.
* [3] Aizerman, Braverman, and Rozonoer. Theoretical foundations of the potential function method in pattern recognition learning. _Automation and remote control_, 25:821-837, 1964.
* [4] Philip Amortila, Dylan J Foster, Nan Jiang, Ayush Sekhari, and Tengyang Xie. Harnessing density ratios for online reinforcement learning. _International Conference on Learning Representations (ICLR)_, 2024.
* [5] Yossi Arjevani, Yair Carmon, John C Duchi, Dylan J Foster, Nathan Srebro, and Blake Woodworth. Lower bounds for non-convex stochastic optimization. _Mathematical Programming_, 199 (1-2):165-214, 2023.
* [6] Sanjeev Arora and Boaz Barak. _Computational complexity: a modern approach_. Cambridge University Press, 2009.
* [7] Idan Attias, Steve Hanneke, Alkis Kalavasis, Amin Karbasi, and Grigoris Velegkas. Optimal learners for realizable regression: Pac learning and online learning. _arXiv preprint arXiv:2307.03848_, 2023.

* [8] Jean-Yves Audibert. Fast learning rates in statistical inference through aggregation. _The Annals of Statistics_, 37(4):1591-1646, 2009.
* [9] Andrew R Barron. Are bayes rules consistent in information? In _Open problems in communication and computation_, pages 85-91. Springer, 1987.
* [10] Shai Ben-David, David Pal, and Shai Shalev-Shwartz. Agnostic online learning. In _COLT_, volume 3, page 1, 2009.
* [11] Blair Bilodeau, Dylan J Foster, and Daniel Roy. Tight bounds on minimax regret under logarithmic loss via self-concordance. In _International Conference on Machine Learning_, 2020.
* [12] Blair Bilodeau, Dylan J Foster, and Daniel M Roy. Minimax rates for conditional density estimation via empirical entropy. _The Annals of Statistics_, 51(2):762-790, 2023.
* [13] Avrim Blum, Merrick Furst, Jeffrey Jackson, Michael Kearns, Yishay Mansour, and Steven Rudich. Weakly learning dnf and characterizing statistical query learning using fourier analysis. In _Proceedings of the twenty-sixth annual ACM symposium on Theory of computing_, pages 253-262, 1994.
* [14] Avrim L Blum. Separating distribution-free and mistake-bound learning models over the boolean domain. _SIAM Journal on Computing_, 23(5):990-1000, 1994.
* [15] Mark Bun. A computational separation between private learning and online learning. _Advances in Neural Information Processing Systems_, 33:20732-20743, 2020.
* [16] Olivier Catoni. The mixture approach to universal model selection. 1997.
* [17] Nicolo Cesa-Bianchi and Gabor Lugosi. _Prediction, learning, and games_. Cambridge university press, 2006.
* [18] Nicolo Cesa-Bianchi, Alex Conconi, and Claudio Gentile. On the generalization ability of on-line learning algorithms. _IEEE Transactions on Information Theory_, 50(9):2050-2057, 2004.
* [19] Constantinos Daskalakis and Vasilis Syrgkanis. Learning in auctions: Regret is hard, envy is easy. In _2016 ieee 57th annual symposium on foundations of computer science (focs)_, pages 219-228. IEEE, 2016.
* [20] Miroslav Dudik, Nika Haghtalab, Haipeng Luo, Robert E Schapire, Vasilis Syrgkanis, and Jennifer Wortman Vaughan. Oracle-efficient online learning and auction design. _Journal of the ACM (JACM)_, 67(5):1-57, 2020.
* [21] Vitaly Feldman. A complete characterization of statistical query learning with applications to evolvability. _Journal of Computer and System Sciences_, 78(5):1444-1459, 2012.
* [22] Vitaly Feldman. A general characterization of the statistical query complexity. In _Conference on Learning Theory_, pages 785-830. PMLR, 2017.
* [23] Vitaly Feldman, Cristobal Guzman, and Santosh Vempala. Statistical query algorithms for mean vector estimation and stochastic convex optimization. In _Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on Discrete Algorithms_, pages 1265-1277. SIAM, 2017.
* [24] Dylan J Foster and Akshay Krishnamurthy. Efficient first-order contextual bandits: Prediction, allocation, and triangular discrimination. _Neural Information Processing Systems (NeurIPS)_, 2021.
* [25] Dylan J Foster and Alexander Rakhlin. Beyond UCB: Optimal and efficient contextual bandits with regression oracles. _International Conference on Machine Learning (ICML)_, 2020.
* [26] Dylan J Foster and Alexander Rakhlin. Foundations of reinforcement learning and interactive decision making. _arXiv preprint arXiv:2312.16730_, 2023.
* [27] Dylan J Foster, Sham M Kakade, Jian Qian, and Alexander Rakhlin. The statistical complexity of interactive decision making. _arXiv preprint arXiv:2112.13487_, 2021.

* [28] Dylan J Foster, Noah Golowich, and Yanjun Han. Tight guarantees for interactive decision making with the decision-estimation coefficient. _Conference on Learning Theory (COLT)_, 2023.
* [29] Dylan J Foster, Noah Golowich, Jian Qian, Alexander Rakhlin, and Ayush Sekhari. Model-free reinforcement learning with the decision-estimation coefficient. In _Thirty-seventh Conference on Neural Information Processing Systems_, 2023.
* [30] Oded Goldreich et al. Foundations of cryptography-a primer. _Foundations and Trends(r) in Theoretical Computer Science_, 1(1):1-116, 2005.
* [31] Alon Gonen, Elad Hazan, and Shay Moran. Private learning implies online learning: An efficient reduction. _Advances in Neural Information Processing Systems_, 32, 2019.
* [32] Steve Hanneke. Theory of disagreement-based active learning. _Foundations and Trends(r) in Machine Learning_, 7(2-3):131-309, 2014.
* [33] Elad Hazan and Tomer Koren. The computational power of optimization in online learning. In _Proceedings of the forty-eighth annual ACM symposium on Theory of Computing_, pages 128-141, 2016.
* [34] TS Jayram. Hellinger strikes back: A note on the multi-party information complexity of and. In _International Workshop on Approximation Algorithms for Combinatorial Optimization_, pages 562-573. Springer, 2009.
* [35] Pooria Joulani, Andras Gyorgy, and Csaba Szepesvari. Online learning under delayed feedback. In _International Conference on Machine Learning_, pages 1453-1461. PMLR, 2013.
* [36] Anatoli Juditsky, Philippe Rigollet, and Alexandre B Tsybakov. Learning by mirror averaging. _The Annals of Statistics_, 36(5):2183-2206, 2008.
* [37] Michael Kearns. Efficient noise-tolerant learning from statistical queries. _Journal of the ACM (JACM)_, 45(6):983-1006, 1998.
* [38] Michael Kearns, Ming Li, Leonard Pitt, and Leslie Valiant. On the learnability of boolean formulae. In _Proceedings of the nineteenth annual ACM symposium on Theory of computing_, pages 285-295, 1987.
* [39] Akshay Krishnamurthy, Alekh Agarwal, Tzu-Kuo Huang, Hal Daume III, and John Langford. Active learning for cost-sensitive classification. In _International Conference on Machine Learning_, pages 1915-1924, 2017.
* [40] Erich L Lehmann and George Casella. _Theory of point estimation_. Springer Science & Business Media, 2006.
* [41] Nick Littlestone. Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm. _Machine learning_, 2(4):285-318, 1988.
* [42] Jon Christian Mesterharm. _Improving on-line learning_. Rutgers The State University of New Jersey, School of Graduate Studies, 2007.
* [43] Arkadii Nemirovski, David Borisovich Yudin, and Edgar Ronald Dawson. Problem complexity and method efficiency in optimization. 1983.
* [44] Binghui Peng and Aviad Rubinstein. Near optimal memory-regret tradeoff for online learning. _arXiv preprint arXiv:2303.01673_, 2023.
* [45] Binghui Peng and Fred Zhang. Online prediction in sub-linear space. In _Proceedings of the 2023 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)_, pages 1611-1634. SIAM, 2023.
* [46] Yury Polyanskiy and Yihong Wu. Lecture notes on information theory. 2014.
* [47] Kent Quanrud and Daniel Khashabi. Online learning with adversarial delays. _Advances in neural information processing systems_, 28, 2015.

* [48] Maxim Raginsky and Alexander Rakhlin. Information-based complexity, feedback and dynamics in convex programming. _IEEE Transactions on Information Theory_, 57(10):7036-7056, 2011.
* [49] Alexander Rakhlin and Karthik Sridharan. Statistical learning and sequential prediction, 2012. Available at http://www.mit.edu/~rakhlin/courses/stat928/stat928_notes.pdf.
* [50] Alexander Rakhlin and Karthik Sridharan. Statistical learning theory and sequential prediction. _Lecture Notes in University of Pennsylvania_, 44, 2012.
* [51] Alexander Rakhlin and Karthik Sridharan. Online nonparametric regression. In _Conference on Learning Theory_, 2014.
* [52] Alexander Rakhlin and Karthik Sridharan. Online nonparametric regression with general loss functions. _arXiv preprint arXiv:1501.06598_, 2015.
* [53] Alexander Rakhlin, Karthik Sridharan, and Ambuj Tewari. Online learning: Random averages, combinatorial parameters, and learnability. _Advances in Neural Information Processing Systems 23_, pages 1984-1992, 2010.
* [54] Alexander Rakhlin, Karthik Sridharan, and Ambuj Tewari. Online learning via sequential complexities. _Journal of Machine Learning Research_, 2014.
* [55] Stephane Ross and J Andrew Bagnell. Reinforcement and imitation learning via interactive no-regret learning. _arXiv preprint arXiv:1406.5979_, 2014.
* [56] Stephane Ross, Geoffrey Gordon, and Drew Bagnell. A reduction of imitation learning and structured prediction to no-regret online learning. In _Proceedings of the fourteenth international conference on artificial intelligence and statistics_, pages 627-635. JMLR Workshop and Conference Proceedings, 2011.
* [57] Shai Shalev-Shwartz and Shai Ben-David. _Understanding machine learning: From theory to algorithms_. Cambridge university press, 2014.
* [58] David Simchi-Levi and Yunzong Xu. Bypassing the monster: A faster and simpler optimal algorithm for contextual bandits under realizability. _Mathematics of Operations Research_, 2021.
* [59] Vaidehi Srinivas, David P Woodruff, Ziyu Xu, and Samson Zhou. Memory bounds for the experts problem. In _Proceedings of the 54th Annual ACM SIGACT Symposium on Theory of Computing_, pages 1158-1171, 2022.
* [60] Joseph F Traub, Grzegorz W Wasilkowski, and Henryk Wozniakowski. Information-based complexity. 1988.
* [61] Alexandre B Tsybakov. Optimal rates of aggregation. In _Learning Theory and Kernel Machines_, pages 303-313. Springer, 2003.
* [62] Alexandre B Tsybakov. _Introduction to Nonparametric Estimation_. Springer Publishing Company, Incorporated, 2008.
* [63] Leslie G Valiant. A theory of the learnable. _Communications of the ACM_, 27(11):1134-1142, 1984.
* [64] S. A. van de Geer. _Empirical Processes in M-Estimation_. Cambridge University Press, 2000.
* [65] Vladimir Vovk. Competitive on-line linear regression. In _NIPS '97: Proceedings of the 1997 conference on Advances in neural information processing systems 10_, pages 364-370, Cambridge, MA, USA, 1998. MIT Press.
* [66] Martin J Wainwright. _High-dimensional statistics: A non-asymptotic viewpoint_, volume 48. Cambridge University Press, 2019.
* [67] Marcelo J Weinberger and Erik Ordentlich. On delayed prediction of individual sequences. _IEEE Transactions on Information Theory_, 48(7):1959-1976, 2002.

* [68] David P Woodruff, Fred Zhang, and Samson Zhou. Streaming algorithms for learning with experts: Deterministic versus robust. _arXiv preprint arXiv:2303.01709_, 2023.
* [69] Tengyang Xie, Dylan J Foster, Yu Bai, Nan Jiang, and Sham M Kakade. The role of coverage in online reinforcement learning. _International Conference on Learning Representations (ICLR)_, 2023.
* [70] Yunbei Xu and Assaf Zeevi. Upper counterfactual confidence bounds: a new optimism principle for contextual bandits. _arXiv preprint arXiv:2007.07876_, 2020.
* [71] Yuhong Yang and Andrew Barron. Information-theoretic determination of minimax rates of convergence. _Annals of Statistics_, pages 1564-1599, 1999.

###### Contents of Appendix

* I Additional discussion and examples
* A Additional notation
* B Additional related work
* C Examples of estimation problems and loss functions
* C.1 Examples of offline oracles
* II Omitted results
* D General reductions for oracle-efficient online estimation
* D.1 Characterization of oracle-efficient learnability for classification
* D.2 Additional lower and upper bounds for memoryless oracle-efficient algorithms
* E Application to interactive decision making
* E.1 Offline oracle-efficient algorithms for interactive decision making
* E.2 Bypassing impossibility of memoryless algorithms via coverability

## Part I Additional discussion and examples

### Appendix A Additional notation

We denote \(\mathbb{R}_{\geq 0}=[0,\infty)\). For any \(a,b\in\mathbb{R}\), \(a\wedge b:=\min\left\{a,b\right\}\) and \(a\lor b:=\max\left\{a,b\right\}\). For any integer \(N>0\), \([N]=\left\{1,\ldots,N\right\}\). For any set \(\mathcal{X}\), \(\Delta(\mathcal{X})\) is the space of all distributions on \(\mathcal{X}\). For any integer \(T\), the notation \(x^{i:\tau}\) will be the shorthand notation for the sequence \(x^{i},\ldots,x^{T}\). For any real number \(x\in\mathbb{R}\), denote by \(\left\lfloor x\right\rfloor\) the largest integer that is smaller than or equal to \(x\) and by \(\left\lceil x\right\rceil\) the smallest integer that is greater than or equal to \(x\). The indicator function is denoted by \(\mathbbm{1}(\cdot)\). We define \(O(\cdot)\), \(\Omega(\cdot)\), \(o(\cdot)\), \(\Theta(\cdot)\), \(\widetilde{O}(\cdot)\), \(\widetilde{\Omega}(\cdot)\), \(\widetilde{\Theta}(\cdot)\) following standard non-asymptotic big-oh notation. We use the binary relation \(x\lesssim y\) to indicate that \(x\leq O(y)\).

### Appendix B Additional related work

In this section we discuss related work not already covered in detail.

Computational lower bounds for online learning.Beyond Blum [14], another work that considers computational lower bounds for online learning is Hazan and Koren [33]. This work proves lower bounds for online learning in a model where the learner has access to an ERM oracle that can minimize the training loss for an arbitrary dataset \((x^{1},y^{1}),\ldots,(x^{T},y^{T})\). Their lower bound does not fit in our computational model due to details around the way description length is formalized. In particular, the main focus of [33] is to obtain a lower bound on the _number of oracle calls_ any online learning algorithm must make to an ERM oracle.

Similar to the setup for Theorem 4.1, Hazan and Koren [33] consider a sequence of classification instances with \(\mathcal{X}_{n}=\left\{0,1\right\}^{n}\) and classes \(\mathcal{F}_{n}\) of the size of \(\Omega(2^{\sqrt{|\mathcal{X}_{n}|}})\), and show that any online learning algorithm requires \(\Omega(\sqrt{|\mathcal{X}_{n}|})\) oracle calls to achieve low regret for this class. However, the estimators \(f\in\mathcal{F}_{n}\) returned by the oracle in their construction have \(\Omega(\sqrt{|\mathcal{X}_{n}|})\) description length themselves, meaning that they do not satisfy the \(\mathrm{poly}(n)\)-description length required by the model described in Section 4.1 (in other words, the result is not meaningful as a lower bound on runtime, because simply reading in the output of the offline oracle takes exponential time). For completeness, we restate the example proposed by Hazan and Koren [33, Theorem 22] in our framework below.

_Hard case from [33]._ For any integer \(n\geq 1\), consider a binary classification problem with \(\mathcal{X}_{2n}=\left\{0,1\right\}^{2n}\), \(\mathcal{Z}=\mathcal{Y}=\left\{0,1\right\}\), \(\mathsf{D}=\mathsf{D}_{0/1}\) and \(\mathcal{K}(z)=\mathbbm{1}_{z}\). Let \(N:=2^{2n}\), and let \(\mathcal{S}\) be the collection of all sets \(S=\left\{s_{1},\ldots,s_{2^{n}}\right\}\subset\left\{0,1\right\}^{2n}\) where \(\left\{0,1\right\}^{2n}\) is also treated as the integer set of \(\left\{0,\ldots,2^{2n}-1\right\}\) in left-to-right order and \(s_{i}\in\left\{2^{n}(i-1),\ldots,2^{n}i-1\right\}\) for each \(i=1,\ldots,2^{n}\). We define a class \(\mathcal{F}_{2n}=\left\{f_{S,\tau}:S\in\mathcal{S},\tau\leq 2^{n}\right\}\), where

\[f_{S,\tau}(x)=\begin{cases}0&\text{if $x\in S$ and $x\geq s_{\tau}$},\\ 1&\text{otherwise}.\end{cases}\]

For this class, we reduce back to the Theorem 22 of Hazan and Koren [33] which states that any algorithm with runtime \(o(\sqrt{N})\) has to suffer online estimation error at least \(t/2\) for all \(1\leq t\leq 2^{n}\). The issue with this example for our computation model is that \(|\mathcal{F}_{2n}|=\Omega(2^{\sqrt{|\mathcal{X}_{2n}|}})\). Any sufficient description for this parameter space in bit strings (or, e.g., boolean circuits) will scale with \(\Omega(\sqrt{|\mathcal{X}_{2n}|})\). Thus, the description length required to return \(\widehat{f}^{\prime}\) is too large (already larger than the lower bound obtained).

Online learning with memory constraints.A number of recent works focus on memory-regret tradeoffs in online learning [59, 45, 44, 1, 68]. Here, the learner can observe the full data stream \((x^{i},y^{1}),\ldots,(x^{T},y^{T})\), but is constrained to \(B\) bits of memory. This framework is incomparable to the OEOE framework, but it would be interesting to explore whether there are deeper connections (e.g., any memoryless OEOE algorithm inherently has memory no larger than that of the offline oracle).

Gaps between offline and online.A long line of work aims to characterize the optimal regret for online learning, developing complexity measures (Littlestone dimension, sequential Rademacher complexity) that parallel classical complexity measures like VC dimension and Rademacher complexity for offline learning and estimation [10, 53, 54, 7]. It is well known that in general, the optimal rates for online learning can be significantly worse than those for offline learning. Our work primarily focuses on finite classes \(\mathcal{F}\), where there is no gap, but for infinite classes, any conversion from offline to online estimation will inevitably lead to a loss in the estimation error rate that scales with appropriate complexity measures for online learning (cf. Appendix D.1).

Other restricted computational models.Our information-theoretic formulation of oracle-efficiency is inspired by statistical query complexity in theoretical computer science and information complexity in optimization, both of which can be viewed as restricted computational models with an information-theoretic flavor. The statistical query model is a framework in which the learner can only access the environment through an oracle that outputs noise estimates ("statistical queries") for a target parameter of interest [13, 37, 21, 22, 23]. Information complexity in optimization is a model in which algorithms can only access the parameter of interest through (potentially noisy) local queries to gradients or other information [43, 60, 48, 2, 5].

## Appendix C Examples of estimation problems and loss functions

In what follows, we give detailed background on three canonical examples of the general estimation framework discussed in Section 1: Binary classification, square loss regression, and conditional density estimation.

Classification [38, 63].For binary classification, we take \(\mathcal{Z}=\mathcal{Y}=\{0,1\}\) with the binary loss \(\mathsf{D}_{0/1}(z_{1},z_{2})=\mathbbm{1}(z_{1}\neq z_{2})\) for \(z_{1},z_{2}\in\mathcal{Z}\) and kernel \(\mathcal{K}(z)=\mathbbm{1}_{z}\), which is noiseless. The binary loss is metric-like with \(C_{\mathsf{D}}=1\).

For offline estimation, observe that with covariates \(x^{1},\ldots,x^{T}\) and outcomes \(y^{\iota}=f^{\star}(x^{\iota})\) for all \(t\in\{1,\ldots,T\}\), any empirical risk minimizer \(\widehat{f}\) that sets \(\widehat{f}(x^{\iota})=y^{\iota}\) obtains

\[\sum_{t=1}^{T}\mathsf{D}_{0/1}\Big{(}\widehat{f}(x^{\iota}),f^{\star}(x^{ \iota})\Big{)}=0.\] (5)

For online estimation, the halving algorithm [17] achieves

\[\mathbf{Est}_{0/1}^{\mathsf{On}}(T)=\sum_{t=1}^{T}\mathsf{D}_{0/1}\Big{(} \widehat{f}^{\iota}(x^{\iota}),f^{\star}(x^{\iota})\Big{)}\leq\log(|\mathcal{ F}|).\] (6)

We mention in passing that another natural classification setting we do not explore in detail in this paper is _noisy classification_, where the setting is as above, except that we set \(\mathcal{Z}=[0,1]\), \(\mathcal{K}(f^{\star}(x))=\mathrm{Ber}(f^{\star}(x))\), and take \(\mathsf{D}_{\mathsf{abs}}(z_{1},z_{2})=|z_{1}-z_{2}|\) as the absolute loss for all \(z_{1},z_{2}\in\mathcal{Z}\).

Square loss regression [62, 66].For real-valued regression, we take \(\mathcal{Z}=\mathcal{Y}=\mathbb{R}\) with the square loss \(\mathsf{D}_{\mathsf{sq}}(z_{1},z_{2})=(z_{1}-z_{2})^{2}\) for \(z_{1},z_{2}\in\mathcal{Z}\) and the kernel \(\mathcal{K}(f^{\star}(x))=\mathcal{N}(f^{\star}(x),1)\) or another subGaussian distribution. Note that the square loss is a metric-like loss with \(C_{\mathsf{D}}=2\).

For offline estimation, with covariates \(x^{1},\ldots,x^{T}\) and outcomes \(y^{\iota}\sim f^{\star}(x^{\iota})+\varepsilon^{\iota}\) for all \(t\in\{1,\ldots,T\}\), the classical Empirical Risk Minimization (ERM) \(\widehat{f}:=\arg\min_{f\in\mathcal{F}}\sum_{t=1}^{T}(f(x^{\iota})-y^{\iota})^ {2}\) gives

\[\mathbf{Est}_{\mathsf{sq}}^{\mathsf{Off}}(T)=\sum_{t=1}^{T}\mathsf{D}_{\mathsf{ sq}}\Big{(}\widehat{f}(x^{\iota}),f^{\star}(x^{\iota})\Big{)}\leq\log(| \mathcal{F}|\delta^{-1}),\] (7)

with probability at least \(1-\delta\) (cf. Lemma C.1below).

For online estimation, the exponential weights algorithm [17], with decision space \(\mathcal{F}\) and the loss at each round chosen to be \(\ell^{\iota}(f)=(f(x^{\iota})-y^{\iota})^{2}\), achieves

\[\mathbf{Est}_{\mathsf{sq}}^{\mathsf{On}}(T)=\sum_{t=1}^{T}\mathsf{D}_{\mathsf{ sq}}\Big{(}\widehat{f}^{\iota}(x^{\iota}),f^{\star}(x^{\iota})\Big{)}\leq \log(|\mathcal{F}|\delta^{-1}),\] (8)

with probability at least \(1-\delta\) (cf. Foster and Rakhlin [25] for a proof).

[MISSING_PAGE_FAIL:18]

Plug the above inequality back into Eq. (12) and reorganize, we obtain the desired bound of

\[\sum_{t=1}^{T}(\widehat{f}(x^{\prime})-f^{\star}(x^{\prime}))^{2} \leq 8\log(|\mathcal{F}|/\delta).\]

Maximum likelihood estimation for conditional density estimation.For any conditional density estimation instance \((\mathcal{X},\mathcal{Y},\mathcal{Z},\mathcal{K},\mathcal{F})\) defined as in Appendix C. The Maximum Likelihood Estimator (\(\mathrm{MLE}\)) \(\widehat{f}\) is defined as

\[\widehat{f}=\operatorname*{arg\,max}_{f\in\mathcal{F}}\sum_{t=1} ^{T}\log f(y^{\prime}\mid x^{\prime}).\]

We have the following bounds on the offline estimation error for squared Hellinger distance.

**Lemma C.2**.: _For any target parameter \(f^{\star}\in\mathcal{F}\), with probability at least \(1-\delta\), we have,_

\[\sum_{t=1}^{T}\mathrm{D}_{\mathsf{H}}^{2}\Big{(}\widehat{f}(x^{ \prime}),f^{\star}(x^{\prime})\Big{)} \leq\log(|\mathcal{F}|/\delta).\]

Proof of Lemma C.2.: For any parameter \(f\in\mathcal{F}\), define

\[Z_{t}=-\frac{1}{2}(\log f^{\star}(y^{\prime}\mid x^{\prime})- \log f(y^{\prime}\mid x^{\prime})).\]

Then for any \(f\in\mathcal{F}\), by Lemma A.4 of Foster et al. [27], with probability at least \(1-\delta/|\mathcal{F}|\), we have,

\[\sum_{t=1}^{T}-\frac{1}{2}(\log f^{\star}(y^{\prime}\mid x^{ \prime})-\log f(y^{\prime}\mid x^{\prime})) \leq\sum_{t=1}^{T}\log\Biggl{(}\mathbb{E}\Biggl{[}\sqrt{\frac{f(y^{\prime} \mid x^{\prime})}{f^{\star}(y^{\prime}\mid x^{\prime})}}\Biggr{]}\Biggr{)}+ \log(|\mathcal{F}|/\delta).\]

We further have by the inequality of \(\log(1+x)\leq x\) that

\[\log\Biggl{(}\mathbb{E}\Biggl{[}\sqrt{\frac{f(y^{\prime}\mid x^{ \prime})}{f^{\star}(y^{\prime}\mid x^{\prime})}}\Biggr{]}\Biggr{)} \leq\mathbb{E}\Biggl{[}\sqrt{\frac{f(y^{\prime}\mid x^{ \prime})}{f^{\star}(y^{\prime}\mid x^{\prime})}}-1\Biggr{]}.\]

Since \(y^{\prime}\sim f^{\star}(x^{\prime})\), we have by standard calculus and the definition of the squared Hellinger distance that

\[\mathbb{E}\Biggl{[}\sqrt{\frac{f(y^{\prime}\mid x^{\prime})}{f^{ \star}(y^{\prime}\mid x^{\prime})}}-1\Biggr{]}=-\mathsf{D}_{\mathsf{H}}^{2}(f ^{\star}(x^{\prime}),f(x^{\prime})).\]

Altogether, we have obtained for any \(f\in\mathcal{F}\), with probability at least \(1-\delta/|\mathcal{F}|\)

\[\sum_{t=1}^{T}-\frac{1}{2}(\log f^{\star}(y^{\prime}\mid x^{ \prime})-\log f(y^{\prime}\mid x^{\prime})) \leq-\sum_{t=1}^{T}\mathsf{D}_{\mathsf{H}}^{2}(f^{\star}(x^{\prime}),f(x^{ \prime}))+\log(|\mathcal{F}|/\delta).\]

Thus, by union bound, the above inequality holds for all \(f\in\mathcal{F}\) with probability at least \(1-\delta\). Thus the MLE \(\widehat{f}\) satisfies

\[\sum_{t=1}^{T}\mathsf{D}_{\mathsf{H}}^{2}\Big{(}f^{\star}(x^{ \prime}),\widehat{f}(x^{\prime})\Big{)} \leq\sum_{t=1}^{T}\frac{1}{2}(\log f^{\star}(y^{\prime}\mid x^{ \prime})-\log\widehat{f}(y^{\prime}\mid x^{\prime}))+\log(|\mathcal{F}|/\delta)\] \[\leq\log(|\mathcal{F}|/\delta),\]

where the second inequality is by the defintion of MLE.

```
1:input: Offline estimation oracle \(\mathbf{Alg}_{\mathsf{Off}}\) with parameter \(\beta_{\mathsf{Off}}\geq 0\), delay parameter \(N\in\mathbb{N}\), delayed online learning algorithm \(\mathcal{A}_{\mathsf{OOL}}\) for class \(\mathcal{F}\).
2:for\(t=1,2,\ldots,T\)do
3: Receive \(\widehat{f}^{t}=\mathbf{Alg}^{t}_{\mathsf{Off}}(x^{1},\ldots,x^{t-1},y^{1}, \ldots,y^{t-1})\).
4:if\(t>N\)then
5: Let \(\tilde{f}^{t-N}:=\frac{1}{N}\sum\limits_{i=t-N+1}^{t}\widehat{f}^{i}\).
6: Let \(\ell^{t-N}(f):=\mathsf{D}\Big{(}\tilde{f}^{t-N}(x^{t-N}),f(x^{t-N})\Big{)}\) and pass \(\ell^{t-N}(\cdot)\) to \(\mathcal{A}_{\mathsf{OOL}}\) as the delayed feedback.
7: Let \(\mu^{t}=\mathcal{A}^{t}_{\mathsf{OOL}}(\ell^{1},..,\ell^{t-N})\) be the delayed online learner's prediction distribution.
8: Predict with \(\bar{f}^{t}\sim\mu^{t}\) and receive \(x^{t}\). ```

**Algorithm 2** Reduction from OEOE to Online Learning with Delayed Feedback

## Part II Omitted results

### General reductions for oracle-efficient online estimation

The oracle-efficient online estimation algorithm in Section 3.1, Algorithm 1, is somewhat specialized to finite classes. In this section, we provide a more general approach to designing oracle-efficient algorithms based on _delayed online learning_, and use it to derive a characterization of oracle-efficient learnability for classification with infinite classes \(\mathcal{F}\).

For the results in this section, we assume that \(\mathcal{Z}\) and \(\mathsf{D}\) are convex, which covers regression and conditional density estimation; variants of our result for classification are given in Appendix G.3.

Online learning with delayed feedback.Before introducing our algorithm, we first introduce an abstract _delayed online learning_ framework [67, 42, 35, 47]. In our framework, the learner is given a class \(\mathcal{F}\subseteq\mathcal{Z}^{\mathcal{X}}\). Their goal is to choose a sequence of parameters \(\tilde{f}^{1},\ldots,\tilde{f}^{T}\) that minimizes regret against the class \(\mathcal{F}\) for an adversarially chosen sequence of loss functions \(\ell^{1},\ldots,\ell^{T}\), with the twist being that the loss \(\ell^{t}\) is not revealed immediately at step \(t\), and instead becomes available at step \(t+N\) for a _delay_ parameter \(N\in\mathbb{N}\).

In more detail, the interaction between the learner and the environment proceeds as follows:

* For \(t=1,\ldots,T\):
* The learner picks \(\bar{f}^{i}\sim\mu^{t}\in\Delta(\mathcal{Z}^{\mathcal{X}})\).
* Learner incurs loss \(\ell^{t}(\bar{f}^{i})\) and adversary reveals loss function \(\ell^{t-N}:\mathcal{Z}^{\mathcal{X}}\to[0,1]\) for round \(t-N\) (if \(t<N+1\), nothing is revealed).

The goal of the learner is to minimize regret in the sense that

\[R_{\mathsf{OOL}}(T,N,\gamma):=\sum\limits_{t=1}^{T}\mathbb{E}_{\bar{f}^{t} \sim\mu^{t}}\big{[}\ell^{t}(\bar{f}^{t})\big{]}-\gamma\cdot\min\limits_{f\in \mathcal{F}}\sum\limits_{t=1}^{T}\ell^{t}(f)\]

is small, where \(\gamma\geq 1\) is a parameter. For \(\gamma=1\), this definition coincides with the standard notion of regret in online learning (e.g., Cesa-Bianchi and Lugosi [17]), but allowing for \(\gamma>1\) will prove useful for our technical results.

Algorithm and online estimation error bound.Algorithm 2 describes our reduction from oracle-efficient online estimation to delayed online learning. In addition to an offline oracle \(\mathbf{Alg}_{\mathsf{Off}}\), the algorithm takes as input a _delay parameter_\(N\in\mathbb{N}\) and a delayed online learning algorithm \(\mathcal{A}_{\mathsf{OOL}}\) for the class \(\mathcal{F}\) (Algorithm 2 does not explicitly take the class \(\mathcal{F}\) as an argument, as the algorithm only implicitly makes use of \(\mathcal{F}\) through \(\mathcal{A}_{\mathsf{OOL}}\)).

The basic premise behind Algorithm 2 is that for any sequence of consistent offline estimators, we can average to improve the predictions. Consider a step \(t\in[T]\). Suppose \(\widehat{f}^{1},\ldots,\widehat{f}^{T}\) are produced by an offline oracle \(\mathbf{Alg}_{\mathsf{Off}}\) with parameter \(\beta_{\mathsf{Off}}\geq 0\), where we augment the sequence by setting \(\widehat{f}^{r+s}=\widehat{f}^{r}\) for all \(s\in\mathbb{N}\). Then we can use an argument based on convexity (cf. proof of Theorem D.1) to show that for any \(N\in\mathbb{N}\), the averaged parameters

\[\tilde{f}^{\iota}:=\frac{1}{N}\sum_{i=t+1}^{t+N}\widehat{f}^{i}\] (13)

satisfies

\[\sum_{t=1}^{T}\mathsf{D}\Big{(}\tilde{f}^{\iota}(x^{\iota}),f^{ \star}(x^{\iota})\Big{)} \leq N+\frac{1}{N}\sum_{t=1}^{T-N}\sum_{i=t+1}^{t+N}\mathsf{D}\Big{(} \widehat{f}^{\iota}(x^{\iota}),f^{\star}(x^{\iota})\Big{)}\] \[=N+\frac{1}{N}\sum_{t=2}^{T}\sum_{i<t}\mathsf{D}\Big{(}\widehat{f }^{\iota}(x^{\iota}),f^{\star}(x^{\iota})\Big{)}\leq N+\beta_{\mathsf{Off}}T/N.\]

In particular, as we increase \(N\), the quality of the predictions increases, and we achieve sublinear estimation error as soon as \(N=\omega(T)\). Of course, the catch here is that \(\tilde{f}^{\iota}\) depends on the predictions of future estimators, and cannot be computed at step \(t\). However, \(\tilde{f}^{\iota}\)_can_ be computed at step \(t+N+1\), with a delay of \(N\). This leads us to appeal to delayed online learning. In particular, at each step \(t\geq N+1\), Algorithm 2 proceeds as follows. Using the new offline estimator \(\widehat{f}^{\iota}\) from \(\mathbf{Alg}_{\mathsf{Off}}\), the algorithm computes the averaged estimator \(\tilde{f}^{\iota-N}:=\frac{1}{N}\sum\limits_{i=t-N+1}^{t}\widehat{f}^{i}\) corresponding to the estimator in Eq. (13) for step \(t-N\). The algorithm then defines a loss function

\[\ell^{t-N}(f):=\mathsf{D}\Big{(}\tilde{f}^{\iota-N}(x^{\iota-N}),f(x^{\iota-N })\Big{)}\]

and feeds it into the delayed online learning algorithm \(\mathcal{A}_{\mathsf{DOL}}\) as the feedback for step \(t-N\). Finally, Algorithm 2 uses the prediction distribution \(\mu^{\iota}\) produced by \(\mathcal{A}_{\mathsf{OOL}}\) to sample the final estimator \(\tilde{f}^{\iota}\), then proceeds to the next step. Our main theorem shows that as long \(\mathcal{A}_{\mathsf{OOL}}\) achieves low regret for delayed online learning, this strategy leads to low online estimation error.

**Theorem D.1** (Reduction from oracle-efficient online estimation to delayed online learning).: _Let \(\mathsf{D}\) be any convex, metric-like loss. Suppose we run Algorithm 2 with delay parameter \(N\in\mathbb{N}\) and a delayed online learning algorithm \(\mathcal{A}_{\mathsf{OOL}}\) for the class \(\mathcal{F}\). Then for all \(\gamma\geq 1\), Algorithm 2 ensures that_

\[\mathbb{E}\big{[}\mathbf{Est}_{\mathsf{D}}^{\mathsf{On}}(T)\big{]}\leq O(C_{ \mathsf{D}}\gamma(N+\beta_{\mathsf{Off}}T/N)+R_{\mathsf{OOL}}(T,N,\gamma)),\] (14)

_with any offline oracle \(\mathbf{Alg}_{\mathsf{Off}}\) with parameter \(\beta_{\mathsf{Off}}\geq 0\), where_

\[R_{\mathsf{OOL}}(T,N,\gamma):=\sum_{t=1}^{T}\mathbb{E}_{\tilde{f}^{\iota}\sim \mu^{\iota}}\big{[}\ell^{\iota}(\bar{f}^{\iota})\big{]}-\gamma\cdot\min_{f\in \mathcal{F}}\sum_{t=1}^{T}\ell^{\iota}(f)\] (15)

_is the regret of \(\mathcal{A}_{\mathsf{OOL}}\) for the sequence of losses constructed in Algorithm 2._

The parameter \(N\) controls a sort of bias-variance tradeoff in Theorem D.1. The first term in Eq. (14) (corresponding to the bias of the averaged estimators) decreases with the delay \(N\), while the second term (corresponding to the regret of \(\mathcal{A}_{\mathsf{OOL}}\)) increases; the optimal choice for \(N\) will balance these terms. To make this concrete, we revisit finite classes as a warmup.

Example: Finite classes.Delayed online learning is well-studied, and optimal algorithms are known for many classes of interest [67, 42, 35, 47]. The following standard result (a proof is given in Appendix G.3 for completeness) gives a delayed regret bound for arbitrary finite classes.

**Lemma D.1**.: _Consider the delayed online learning setting with a delay parameter \(N\). There exists an algorithm that achieves_

\[R_{\mathsf{OOL}}(T,N,2)=\sum_{t=1}^{T}\mathbb{E}_{\tilde{f}^{\iota}\sim\mu^{ \iota}}\big{[}\ell^{\iota}(\bar{f}^{\iota})\big{]}-2\cdot\min_{f\in\mathcal{F} }\sum_{t=1}^{T}\ell^{\iota}(f)\leq 2N\cdot\log|\mathcal{F}|\]

_for any sequences of losses \(\ell^{\iota},\ldots,\ell^{r}\in[0,1]\)._Combining Theorem D.1 with Lemma D.1, we can obtain the following upper bound for oracle-efficient online estimation.

**Corollary D.1** (Oracle-efficient online estimation for finite classes via delayed online learning).: _Consider an arbitrary instance \((\mathcal{X},\mathcal{Y},\mathcal{Z},\mathcal{K},\mathcal{F})\) and metric-like loss \(\mathsf{D}\), and assume \(\mathcal{Z}\) is convex. By choosing \(\mathcal{A}_{\mathsf{DOL}}\) as in Lemma D.1, Algorithm 2 ensures that for any \(N\geq 1\),_

\[\mathbb{E}\big{[}\mathbf{Est}_{\mathsf{D}}^{\mathsf{On}}(T)\big{]}\leq O(C_{ \mathsf{D}}(N+\beta_{\mathsf{Off}}T/N)+N\cdot\log|\mathcal{F}|).\]

_with any offline oracle \(\mathbf{Alg}_{\mathsf{Off}}\) with parameter \(\beta_{\mathsf{Off}}\)._

By choosing \(N=\sqrt{\frac{C_{\mathsf{D}}\beta_{\mathsf{Off}}\cdot T}{C_{\mathsf{D}}+\log| \mathcal{F}|}}\lor 1\), Corollary D.1 gives an upper bound of \(O\Big{(}\sqrt{C_{\mathsf{D}}\beta_{\mathsf{Off}}(C_{\mathsf{D}}+\log| \mathcal{F}|)\cdot T}+\log|\mathcal{F}|\Big{)}\). While the rate in Corollary D.1, is worse than Theorem 3.1 in terms of dependence on \(T\), the reduction has two advantages: (1) It does require a-priori knowledge of the offline estimation parameter \(\beta_{\mathsf{Off}}\): If we choose \(N=\sqrt{\frac{C_{\mathsf{D}}\cdot T}{C_{\mathsf{D}}+\log|\mathcal{F}|}}\lor 1\), Corollary D.1 obtains \(O((\beta_{\mathsf{Off}}+1)(\sqrt{C_{\mathsf{D}}(C_{\mathsf{D}}+\log|\mathcal{ F}|)\cdot T}+C_{\mathsf{D}}+\log|\mathcal{F}|))\); (2) The reduction by Algorithm 2 is more flexible, and allows for guarantees beyond finite classes, as we now illustrate.

### Characterization of oracle-efficient learnability for classification

As an application of Algorithm 2 and Theorem D.1, we give a characterization for oracle-efficient learnability in the OEOE framework. To state the result, we define \(\operatorname{Ldim}(\mathcal{F})\) as the Littlestone dimension for a binary function class \(\mathcal{F}\) (e.g., Ben-David et al. [10]).

**Theorem D.2** (Characterization of oracle-efficient learnability for binary classification).: _Consider a binary classification instance \((\mathcal{X},\mathcal{Y},\mathcal{Z},\mathcal{K},\mathcal{F})\) with \(\mathcal{Z}=\mathcal{Y}=\{0,1\}\), \(\mathsf{D}=\mathsf{D}_{0/1}\) and \(\mathcal{K}(z)=\mathbb{1}_{z}\). For any class \(\mathcal{F}\) and \(\beta_{\mathsf{Off}}\geq 0\), there exists an oracle-efficient algorithm that achieves online estimation error \(O(\sqrt{\beta_{\mathsf{Off}}\operatorname{Ldim}(\mathcal{F})\cdot T\log T}+ \operatorname{Ldim}(\mathcal{F})\log T)\). On the other hand, in the worst-case any algorithm must suffer at least \(\Omega(\operatorname{Ldim}(\mathcal{F}))\) online estimation error._

The main idea behind this result is to show that we can create a delayed online learner for the reduction in Algorithm 2 that achieves low regret for Littlestone classes.13

Footnote 13: Formally, to handle the fact that \(\mathcal{Z}=\{0,1\}\) is not convex, this result requires a slight modification to Line 4 in Algorithm 2 that replaces the average with a majority vote. See the proof for details.

### Additional lower and upper bounds for memoryless oracle-efficient algorithms

The proof of Theorem 3.3 uses that the estimators \(\widehat{f}^{\iota}\) produced by the offline estimation oracle may be _improper_ (i.e., \(\widehat{f}^{\iota}\notin\mathcal{F}\)). We next provide a variant of the result that holds even if the estimation oracle is _proper_, under the additional assumptions that (i) the learner is itself proper in the sense that \(\mu^{\iota}\in\Delta(\mathcal{F})\), and (ii) the learner is _time-invariant_ (i.e., the learner sets \(\mu^{\iota}=F(\widehat{f}^{\iota})\) for all \(\iota\)).

**Theorem 3.3**\({}^{\prime}\) (Impossibility of memoryless algorithms for OEOE; proper variant).: _Consider the binary classification setting with \(\mathcal{Z}=\mathcal{Y}=\{0,1\}\) and loss \(\mathsf{D}_{0/1}(\cdot,\cdot)\). For any \(N\in\mathbb{N}\) and \(\beta_{\mathsf{Off}}\geq 0\), there exists an instance \((\mathcal{X},\mathcal{Y},\mathcal{Z},\mathcal{K},\mathcal{F})\) with \(|\mathcal{F}|=|\mathcal{X}|=N\) such that for any memoryless oracle-efficient algorithm that is (i) **proper**, and (ii) **time-invariant**, there exists a sequence of covariates \((x^{\downarrow},\dots,x^{T})\) and a **proper** offline oracle \(\mathbf{Alg}_{\mathsf{Off}}\) with parameter \(\beta_{\mathsf{Off}}\) such that \(\mathbb{E}\big{[}\mathbf{Est}_{\mathsf{D}}^{\mathsf{On}}(T)\big{]}\geq\Omega (\min\{N(\beta_{\mathsf{Off}}+1),T\})\)._

A complementary upper bound.For completeness, we conclude by showing that the (large) lower bound in Theorem 3.3 can be achieved with a memoryless oracle-efficient algorithm. We consider the "trivial" algorithm that outputs the estimators produced by the offline oracle as-is.

**Proposition D.1** (Upper bound for memoryless OEOE).: _For any instance \((\mathcal{X},\mathcal{Y},\mathcal{Z},\mathcal{K},\mathcal{F})\), metric-like loss \(\mathsf{D}\), and offline oracle \(\mathbf{Alg}_{\mathsf{Off}}\) with parameter \(\beta_{\mathsf{Off}}\), the algorithm that returns \(\bar{f}^{\iota}=\widehat{f}^{\iota}:=\mathbf{Alg}_{\mathsf{Off}}^{\prime}(x^{ \downarrow},\dots,x^{\iota-1},y^{\downarrow},\dots,y^{\iota-1})\) has online estimation error \(\mathbf{Est}_{\mathsf{D}}^{\mathsf{On}}(T)\leq O((\beta_{\mathsf{Off}}+1)| \mathcal{X}|\log T)\)._Application to interactive decision making

In this section, we apply our techniques for oracle-efficient online estimation to the _Decision Making with Structured Observations_ (DMSO) framework for interactive decision making introduced by [27]. First, in Appendix E.1, we use our reductions to provide offline oracle-efficient algorithms for interactive decision making. Then, in Appendix E.2, we focus on reinforcement learning and show that it is possible to bypass the impossibility results for memoryless oracle-efficient algorithms (Theorem 3.3) for instances \((\mathcal{X},\mathcal{Y},\mathcal{Z},\mathcal{K},\mathcal{F})\) corresponding to Markov decision processes that satisfy a structural property known as coverability.

### Offline oracle-efficient algorithms for interactive decision making

In this section, we introduce the setting of Decision Making with Structured Observations (DMSO) and the applications of our results to this setting.

Decision Making with Structured Observations (DMSO).The DMSO framework [27] captures a large class of interactive decision making problems (e.g. contextual bandits and reinforcement learning). In this framework, the learner is given access to a _model class_\(\mathcal{M}\) that contains an unknown true model \(M^{\star}:\Pi\to\Delta(\mathcal{R}\times\mathcal{O})\), where \(\Pi\) is the _decision space_, \(\mathcal{R}\subseteq\mathbb{R}\) is the _reward space_ and \(\mathcal{O}\) is the _observation space_. Then the interaction between the learner and the environment proceeds in \(T\) rounds, where for each round \(t=1,\ldots,T\):

1. The learner selects a _decision_\(\pi^{\iota}\in\Pi\).
2. Nature selects a _reward_\(r^{\iota}\in\mathcal{R}\) and _observation_\(o^{\iota}\in\mathcal{O}\) based on the decision, where the pair \((r^{\iota},o^{\iota})\) is drawn independently from the unknown distribution \(M^{\star}(\pi^{\iota})\). The reward and observation is then observed by the learner.

Let \(g^{\mathit{st}}(\pi):=\ \mathbb{E}^{\mathit{M},\pi}[r]\) denote the mean reward function and \(\pi_{\mathit{M}}:=\ \arg\max_{\pi\in\Pi}g^{\mathit{M}}(\pi)\) denote the decision with the greatest expected reward for \(M\). The learner's performance is evaluated in terms of _regret_ to the optimal decision for \(M^{\star}\):

\[\mathbf{Reg}_{\mathsf{DM}}(T):=\sum_{t=1}^{T}\mathbb{E}_{\pi^{\iota}\sim p^{ \iota}}\big{[}g^{\mathit{M}^{\star}}(\pi_{\mathit{M}^{\star}})-g^{\mathit{M}^ {\star}}(\pi^{\iota})\big{]},\] (16)

where \(p^{\iota}\in\Delta(\Pi)\) is the learner's distribution over decisions at round \(t\).

Background: Reducing DMSO to online estimation.Any DMSO class \((\mathcal{M},\Pi,\mathcal{O})\) induces an instance \((\mathcal{X},\mathcal{Y},\mathcal{Z},\mathcal{K},\mathcal{F})\) of the estimation framework in Section 1 as follows. We associate \(\mathcal{F}=\mathcal{M}\), \(\mathcal{X}=\Pi\), \(\mathcal{Y}=\mathcal{O}\times\mathcal{R}\), \(\mathcal{Z}=\Delta(\mathcal{O}\times\mathcal{R})\), and \(\mathcal{K}(M^{\star}(\pi))=M^{\star}(\pi)\). That is, we have a conditional density estimation problem in which the covariates are decisions \(\pi\in\Pi\) and the outcomes are observation-reward pairs drawn from the underlying model \(M^{\star}(\pi)\). In particular for a sequence of decisions \(\pi^{1},\ldots,\pi^{\mathit{T}}\) and a sequence of estimators \(\widehat{M}^{1},\ldots,\widehat{M}^{\mathit{T}}\), we define the online estimation error for a loss D as

\[\mathbf{Est}_{\mathsf{D}}^{\mathsf{On}}(T)=\sum_{t=1}^{T}\mathsf{D}\big{(} \widehat{M}^{\mathit{t}}(\pi^{\iota}),M^{\star}(\pi^{\iota})\big{)}.\] (17)

We refer to any algorithm \(\mathbf{Alg}_{\mathsf{On}}\) that ensures that \(\mathbf{Est}_{\mathsf{D}}^{\mathsf{On}}(T)\leq\beta_{\mathsf{On}}\) almost surely given access to \(\{(\pi^{\iota},o^{\iota},r^{\iota})\}_{t=1}^{T}\) with \((o^{\iota},r^{\iota})\sim M^{\star}(\pi^{\iota})\) as an _online estimation oracle_ with parameter \(\beta_{\mathsf{On}}\).

Foster et al. [27, 28] give an algorithm, _Estimation-to-Decisions_ (E2D), that provides bounds on the regret in Eq. (16) given access to an online estimation oracle \(\mathbf{Alg}_{\mathsf{On}}\). The algorithm is (online) oracle-efficient and memoryless, in the sense that the decision \(\pi^{\iota}\) at each step \(t\) is a measurable function of the oracle's output \(\widehat{M}^{\iota}\). To restate their result, we define the _Decision-Estimation Coefficient_ for the class \(\mathcal{M}\) as

\[\mathsf{dec}_{\gamma}^{\mathsf{D}}(\mathcal{M},\overline{M})=\inf_{p\in \Delta(\Pi)}\sup_{M\in\mathcal{M}}\mathbb{E}_{\pi\sim p}\bigg{[}g^{\mathit{M}} (\pi_{\mathit{M}})-g^{\mathit{M}}(\pi)-\gamma\cdot\mathsf{D}\big{(}M(\pi), \overline{M}(\pi)\big{)}\bigg{]}\] (18)

for a reference model \(\overline{M}\) and any losses D. We further define \(\mathsf{dec}_{\gamma}^{\mathsf{D}}(\mathcal{M})=\sup_{\overline{M}\in \mathcal{M}}\mathsf{dec}_{\gamma}^{\mathsf{D}}(\mathcal{M},\overline{M})\). With this notation, the main regret bound for E2D is as follows.

**Proposition E.1** (Theorem 4.3 of [27]).: _For any model class \((\mathcal{M},\Pi,\mathcal{O})\) and metric-like loss \(\mathsf{D}\), any \(\gamma>0\), and any online estimation oracle \(\mathbf{Alg}_{\mathsf{O}\mathsf{n}}\) with parameter \(\beta_{\mathsf{O}\mathsf{n}}>0\), the E2D algorithm ensures that_

\[\mathbf{Reg}_{\mathsf{DM}}(T)\lesssim\sup_{\mu\in\Delta(\mathcal{M})} \mathsf{dec}_{\gamma}^{\mathsf{D}}(\mathcal{M},\mu)\cdot T+\gamma\cdot\beta_{ \mathsf{O}\mathsf{n}}.\] (19)

For the case of squared Hellinger distance where \(\mathsf{D}=\mathsf{D}_{\mathsf{H}}^{2}\), the Decision-Estimation Coefficient \(\mathsf{dec}_{\gamma}^{\mathsf{D}}(\mathcal{M})\) was shown to be a _lower bound_ on the minimax optimal regret for any class \(\mathcal{M}\). Hence, Proposition E.1 shows that it is possible to achieve near-optimal regret for any interactive decision making problems whenever an online estimation oracle is available. However, it was unclear whether similar results could be achieved based on offline estimation oracles.

Making E2D offline oracle-efficient.Algorithm 3 (E2D.Off) invokes the E2D algorithm of Foster et al. [27] with any oracle-efficient online estimation algorithm \(\mathbf{Alg}_{\mathsf{O}\mathsf{E}\mathsf{O}\mathsf{E}}\) (which can be any of the algorithms we provide, e.g. Theorems 3.1 and 4.2), along with an offline estimation oracle \(\mathbf{Alg}_{\mathsf{O}\mathsf{H}}\), to provide offline oracle-efficient guarantees for interactive decision making. Invoking the algorithm with Version Space Averaging (via Theorem 3.1) leads to the following corollary.

**Corollary E.1**.: _Consider any DMSO class \((\mathcal{M},\Pi,\mathcal{O})\) and metric-like loss \(\mathsf{D}\). Algorithm 3, with exploration parameter \(\gamma>0\) and \(\mathbf{Alg}_{\mathsf{O}\mathsf{E}\mathsf{O}\mathsf{E}}\) chosen to be Algorithm 1, ensures that_

\[\mathbb{E}[\mathbf{Reg}_{\mathsf{DM}}]\leq O(\log T)\cdot\max\biggl{\{} \mathsf{dec}_{\gamma}^{\mathsf{D}}(\mathcal{M})\cdot T,\ \gamma\cdot(\beta_{\mathsf{O}\mathsf{H}}+1)\log|\mathcal{M}|\biggr{\}},\]

_for any offline estimation oracle \(\mathbf{Alg}_{\mathsf{O}\mathsf{H}}\) with parameter \(\beta_{\mathsf{O}\mathsf{H}}\)._

This result shows that information-theoretically, it is possible to achieve low regret in the DMSO framework with offline oracles, though the result is not computationally efficient.

As an example, in the case of square loss regression (Appendix C) which is used for contextual bandits, an offline guarantee of \(\beta_{\mathsf{O}\mathsf{H}}=O(\log|\mathcal{M}|)\) is achievable. Meanwhile, it is known that \(\mathsf{dec}_{\gamma}^{\mathsf{D}_{\mathsf{n}}}(\mathcal{M})\lesssim| \mathcal{A}|/\gamma\)[27]. Thus Corollary E.1 achieves a bound of \(\widetilde{O}(\sqrt{|\mathcal{A}|T}\cdot\log|\mathcal{M}|)\) with an appropriate choice of \(\gamma\). The best know regret guarantee for contextual bandit is \(\widetilde{O}(\sqrt{|\mathcal{A}|T\log|\mathcal{M}|})\)[58, 70]. The bound from Corollary E.1 matches the state-of-the-art result up to a factor \(\widetilde{O}(\sqrt{\log|\mathcal{M}|})\). How to remove this suboptimality is an interesting direction for future work.

Naturally, the other reductions for oracle-efficient online estimation developed in this paper can be combined with Algorithm 3 as well. In particular, by combining with Theorem 4.2 we derive the following corollary for squared Hellinger distance.

**Corollary (Informal).**_Whenever online conditional density estimation can be performed efficiently with access to the full history, and whenever the minimax problem in Eq. (18) can be solved efficiently, there exists a computationally efficient and offline oracle-efficient algorithm with near-optimal regret in the DMSO framework._

### Bypassing impossibility of memoryless algorithms via coverability

Recall that our results in Section 3.2 show that in general, it is impossible to obtain low online estimation error through memoryless oracle-efficient algorithms. In this section, we revisit memoryless algorithms for the _Markov decision processes_ a particular type of class \((\mathcal{M},\Pi,\mathcal{O})\) (or equivalently, \((\mathcal{X},\mathcal{Y},\mathcal{Z},\mathcal{K},\mathcal{F})\)). We prove that for any class of Markov decision processes for which a structural parameter called _coverability_[69] is small, any offline estimator can be directly converted into an online estimator.

Markov decision processes.We consider classes \((\mathcal{M},\Pi,\mathcal{O})\) that correspond to an episodic finite-horizon reinforcement learning setting, following Foster et al. [27]. With \(H\in\mathbb{N}\) denoting the horizon, each model \(M\in\mathcal{M}\) specifies a non-stationary Markov decision process as a tuple \(M=\big{\{}\{\mathcal{S}_{h}\}_{h=1}^{H},\mathcal{A},\{P_{h}^{M}\}_{h=1}^{H}, \{R_{h}^{M}\}_{h=1}^{H},d_{1}\big{\}}\), where \(\mathcal{S}_{h}\) is the state space for layer \(h\), \(\mathcal{A}\) is the action space, \(P_{h}^{M}:\mathcal{S}_{h}\times\mathcal{A}\to\Delta(\mathcal{S}_{h+1})\) is the probability transition kernel for layer \(h\), \(R_{h}^{M}:\mathcal{S}_{h}\times\mathcal{A}\to\Delta(\mathbb{R})\) is the reward distribution for layer \(h\), and \(d_{1}\in\Delta(\mathcal{S}_{1})\) is the initial state distribution. We allow the reward distribution and transition kernel to vary across models in \(\mathcal{M}\) and assume that the initial state distribution is fixed.

We set \(\Pi\subset\Pi_{\mathrm{RNS}}\), which denotes the set of all randomized, non-stationary policies \(\pi=(\pi_{1},\ldots,\pi_{H})\in\Pi_{\mathrm{RNS}}\), where \(\pi_{h}:\mathcal{S}_{h}\to\Delta(\mathcal{A})\). For a fixed MDP \(M\in\mathcal{M}\) and \(\pi\in\Pi\), the observation \(o\sim M(\pi)\) is a trajectory \((s_{1},a_{1},r_{1}),\ldots,(s_{H},a_{H},r_{H})\) that is generated through the following process, beginning from \(s_{1}\sim d_{1}\). For \(h=1,\ldots,H\):

* \(a_{h}\sim\pi_{h}(s_{h})\).
* \(r_{h}\sim R_{h}^{M}(s_{h},a_{h})\) and \(s_{h+1}\sim P_{h}^{M}(\cdot\mid s_{h},a_{h})\).

So the observation space \(\mathcal{O}=\mathcal{S}_{1}\times\mathcal{A}\times\mathbb{R}\times\cdots\times \mathcal{S}_{H}\times\mathcal{A}\times\mathbb{R}\). For notational convenience, we take \(s_{H+1}\) to be a deterministic terminal state. We use \(\mathbb{P}^{M,\pi}\) and \(\mathbb{E}^{M,\pi}[\cdot]\) to denote the probability law and expectation over trajectories induced by \(M(\pi)\). In addition, we define \(\overline{P}_{h}^{M}(\cdot\mid s_{h},a_{h})\) as the conditional distribution on \(s_{h+1},r_{h}\) given \(s_{h},a_{h}\) under \(M\) for \(h\in[H]\).

The guarantees we provide apply to any loss that has a particular _layer-wise_ structure tailored to reinforcement learning.

**Definition E.1** (Layer-wise loss).: _For any sequence of losses \(\{\mathsf{D}_{h}\}_{h\in[H]}\) bounded by \([0,1]\), where \(\mathsf{D}_{h}:\Delta(\mathcal{S}_{h}\times\mathbb{R})\times\Delta(\mathcal{ S}_{h}\times\mathbb{R})\to[0,1]\) for all \(h\in[H]\), we define the layer-wise loss \(\mathsf{D}^{\mathsf{RL}}\) on \(\Delta(\mathcal{O})\) as 14_

Footnote 14: The ordering of \(M\) and \(M^{\prime}\) on the right-hand side of the definition is due to the following technical reason: Theorem E.1 only works when the expectation on the right-hand side to be taken with respect to \(M^{\ast}(\pi)\), which shows up as the second argument in the offline oracle guarantee (17).

\[\mathsf{D}^{\mathsf{RL}}(M(\pi)\|M^{\prime}(\pi))=\sum_{h=1}^{H}\mathbb{E}^{M^ {\prime},\pi}\Big{[}\mathsf{D}_{h}\Big{(}\overline{P}^{M^{\prime}}(\cdot\mid s _{h},a_{h})\|\overline{P}^{M}(\cdot\mid s_{h},a_{h})\Big{)}\Big{]},\]

_for any pair of MDPs \(M,M^{\prime}\in\mathcal{M}\) and policy \(\pi\in\Pi\).15_

Footnote 15: For the results in this section, it will be useful to work with asymmetric losses, and in this case we use the notation \(\mathsf{D}(\cdot\parallel\cdot)\) instead of \(\mathsf{D}(\cdot,\cdot)\).

Examples of the layer-wise loss are scaled reverse KL-divergence (which is bounded by \([0,1]\) whenever the density ratios under consideration are upper and lower bounded with an appropriate scaling) [27] and the squared Bellman error [29]. Another useful example is the the sum of layer-wise squared Hellinger distances given by

\[\mathsf{D}^{\mathsf{RL}}_{\mathsf{H}}(M(\pi)\|M^{\prime}(\pi))=\sum_{h=1}^{H} \mathbb{E}^{M^{\prime},\pi}\Big{[}\mathsf{D}^{2}_{\mathsf{H}}\Big{(}\overline{ P}^{M}(\cdot\mid s_{h},a_{h}),\overline{P}^{M^{\prime}}(\cdot\mid s_{h},a_{h}) \Big{)}\Big{]}.\] (21)

This loss coincides with the global squared Hellinger distance \(\mathsf{D}^{2}_{\mathsf{H}}(M(\pi),M^{\prime}(\pi))\) up to an \(O(H)\) factor.

Coverability.We provide memoryless oracle-efficient algorithms for online estimation for any layer-wise loss \(\mathsf{D}^{\mathsf{RL}}\) when the underlying MDP \(M^{\star}\) has bounded _coverability_[69].

**Definition E.2** (Coverability).: _For an MDP \(M^{\star}\) and a policy \(\pi\), we define \(d_{h}^{\pi}(s,a)\equiv\mathbb{E}^{M^{\star},\pi}[\mathbbm{1}(s_{h},a_{h}=s,a)]\). The coverability coefficient \(C_{\mathsf{cov}}\) for a policy class \(\Pi\) for the MDP \(M^{\star}\) is given by_

\[C_{\mathsf{cov}}(M^{\star}):=\inf_{\nu_{1},\ldots,\nu_{H}\in\Delta(\mathcal{S }\times\mathcal{A})}\sup_{\pi\in\Pi,h\in[H]}\biggl{\|}\frac{d_{h}^{\pi}}{\nu_{h }}\biggr{\|}_{\infty}.\]

It is immediate to see that \(C_{\mathsf{cov}}\leq|\Pi|\), but in general it can be much smaller. Examples of MDP classes with low coverability include Block MDPs, Low-Rank MDPs, and exogenous block MDPs [69, 4].

Offline-to-online conversion under coverability.Our main result shows that under coverability, the outputs of any offline estimation oracle \(\mathbf{Alg}_{\mathsf{Off}}\) satisfy an online estimation guarantee _as-is_.

**Theorem E.1** (Offline-to-online conversion under coverability).: _For any layer-wise loss \(\mathsf{D}^{\mathsf{RL}}\) and MDP class \((\mathcal{M},\Pi,\mathcal{O})\) and \(M^{\star}\in\mathcal{M}\), the sequence of estimators \((\widehat{M}^{1},\ldots,\widehat{M}^{T})\) produced by any offline estimation oracle \(\mathbf{Alg}_{\mathsf{Off}}\) for \(\mathsf{D}^{\mathsf{RL}}\) with parameter \(\beta_{\mathsf{Off}}\) satisfy_

\[\sum_{t=1}^{T}\mathsf{D}^{\mathsf{RL}}\Bigl{(}\widehat{M}^{t}(\pi^{t})\|M^{ \star}(\pi^{t})\Bigr{)}\leq O\Bigl{(}\sqrt{HC_{\mathsf{cov}}(M^{\star})\beta_{ \mathsf{Off}}T\log T}+HC_{\mathsf{cov}}(M^{\star})\Bigr{)}.\]

This result is based on a variant of the proof technique in Theorem 1 of Xie et al. [69]. An important application of the result, which can be applied in tandem with the guarantees in Foster et al. [27], concerns squared Hellinger distance.

**Corollary E.2**.: _For any MDP class \((\mathcal{M},\Pi,\mathcal{O})\) and \(M^{\star}\in\mathcal{M}\), the sequence of estimators \((\widehat{M}^{1},\ldots,\widehat{M}^{T})\) produced by any offline estimation oracle \(\mathbf{Alg}_{\mathsf{Off}}\) for squared Hellinger distance \(\mathsf{D}_{\mathsf{H}}^{2}\) with parameter \(\beta_{\mathsf{Off}}\) satisfy_

\[\mathbf{Est}_{\mathsf{H}}^{\mathsf{On}}(T)=\sum_{t=1}^{T}\mathsf{D}_{\mathsf{ H}}^{2}\Bigl{(}\widehat{M}^{t}(\pi^{t}),M^{\star}(\pi^{t})\Bigr{)}\leq O \Bigl{(}H\sqrt{C_{\mathsf{cov}}(M^{\star})\beta_{\mathsf{Off}}T\log T}+H^{2}C_ {\mathsf{cov}}(M^{\star})\Bigr{)}\]

This result follows by using that the layer-wise squared Hellinger distance in Eq. (21) is equivalent to \(\mathsf{D}_{\mathsf{H}}^{2}(M(\pi),M^{\prime}(\pi))\) up to \(O(H)\) factors.

Application to interactive decision making.We apply Theorem E.1 to decision making via Algorithm 3.

**Corollary E.3**.: _Consider any layer-wise loss \(\mathsf{D}=\mathsf{D}^{\mathsf{RL}}\) and MDP class \((\mathcal{M},\Pi,\mathcal{O})\), and let \(C_{\mathsf{cov}}:=\sup_{M\in\mathcal{M}}C_{\mathsf{cov}}(M)\). Algorithm 3 with exploration parameter \(\gamma>0\) and \(\mathbf{Alg}_{\mathsf{OEOE}}\) chosen to be the identity map ensures that_

\[\mathbb{E}[\mathbf{Reg}_{\mathsf{DM}}]\leq O(\log T)\cdot\max\biggl{\{}\sup_{ \mu\in\Delta(\mathcal{M})}\mathsf{dec}_{\gamma}^{\mathsf{D}}(\mathcal{M},\mu) \cdot T,\ \gamma\cdot\Bigl{(}\sqrt{HC_{\mathsf{cov}}\beta_{\mathsf{Off}}T\log T}+HC_{ \mathsf{cov}}\Bigr{)}\biggr{\}},\]

_for any offline estimation oracle \(\mathbf{Alg}_{\mathsf{Off}}\) with parameter \(\beta_{\mathsf{Off}}\)._

Contextual bandits and optimality of offline-to-online conversion.Another implication for Theorem E.1 concerns the special case of contextual bandits (that is, MDPs with horizon one). For the contextual bandit setting we abbreviate \(\mathcal{S}=\mathcal{S}_{1}\), and refer to \(d_{1}\in\Delta(\mathcal{S})\) as the _context distribution_. We define \(g^{{}_{M}}(s,a)=\mathbb{E}_{r\sim R_{1}^{M}(s,a)}[r]\) as the expected reward function under a model \(M\), and following Foster and Rakhlin [25], use the squared error between mean reward functions as our divergence:

\[\mathsf{D}_{\mathsf{CB}}(M(\pi),M^{\prime}(\pi)):=\mathbb{E}_{s\sim d_{1},a\sim \pi(s)}\bigl{[}\mathsf{D}_{\mathsf{sq}}\bigl{(}g^{{}_{M}}(s,a),g^{{}^{M^{ \prime}}(s,a)}\bigr{)}\bigr{]}.\] (22)

For this setting, the coverability coefficient \(C_{\mathsf{cov}}\) is always bounded by the number of actions \(|\mathcal{A}|\), which leads to the following corollary.

**Corollary E.4**.: _For any contextual bandit class \((\mathcal{M},\Pi,\mathcal{O})\) and \(M^{\star}\in\mathcal{M}\), the sequence of estimators \((\widehat{M}^{1},\ldots,\widehat{M}^{T})\) produced by any offline estimation oracle \(\mathbf{Alg}_{\mathsf{Off}}\) for \(\mathsf{D}_{\mathsf{CB}}\) with parameter \(\beta_{\mathsf{Off}}\) satisfy_

\[\mathbf{Est}_{\mathsf{D}}^{\mathsf{On}}(T)=\sum_{t=1}^{T}\mathsf{D}_{\mathsf{ CB}}\Big{(}\widehat{M}^{i}(\pi^{t}),M^{\star}(\pi^{t})\Big{)}\leq O\big{(} \sqrt{|\mathcal{A}|T\beta_{\mathsf{Off}}\log T}+|\mathcal{A}|\big{)},\]

Recall that Foster and Rakhlin [25] show that any algorithm for online estimation with the divergence in Eq. (22) with \(\mathbf{Est}_{\mathsf{D}}^{\mathsf{On}}(T)\leq\beta_{\mathsf{On}}\) can be lifted to a contextual bandit algorithm with regret \(O\big{(}\sqrt{|\mathcal{A}|T\cdot\beta_{\mathsf{On}}}\big{)}\) via the _inverse gap weighting strategy_, even if contexts are chosen adversarially. Subsequent work of Simchi-Levi and Xu [58] shows that for stochastic contexts, the inverse gap weighting strategy also yields regret \(O\big{(}\sqrt{|\mathcal{A}|T\cdot\beta_{\mathsf{Off}}}\big{)}\) given access to an offline oracle with parameter \(\beta_{\mathsf{Off}}\). On the other hand, combining Corollary E.4 with the guarantee from Foster and Rakhlin [25] gives regret \(O\big{(}|\mathcal{A}|^{1/4}T^{3/4}\beta_{\mathsf{Off}}{}^{1/4}\big{)}\). This does not recover the result from Simchi-Levi and Xu [58], but nonetheless gives an alternative proof that sublinear offline estimation error suffices for sublinear regret.

The guarantee in Theorem E.1 leads to a degradation in rate from \(\beta_{\mathsf{Off}}\) to \(\sqrt{T\beta_{\mathsf{Off}}}\) (suppressing problem-dependent parameters). Our next result shows that this is tight in general.

**Proposition E.2** (Tightness of offline-to-online conversion).: _For any integer \(T\geq 1\) and \(\beta_{\mathsf{Off}}>0\), there exists a contextual bandit class \((\mathcal{M},\Pi=\mathcal{A}^{\mathcal{S}},\mathcal{O})\) with \(|\mathcal{A}|=2\), a distribution \(d_{1}\in\Delta(\mathcal{S})\), a sequence \((\pi^{1},\ldots,\pi^{T})\) and an offline oracle \(\mathbf{Alg}_{\mathsf{Off}}\) for \(\mathsf{D}_{\mathsf{CB}}\) with parameter \(\beta_{\mathsf{Off}}\) such that the oracle's outputs \((\widehat{M}^{1},\ldots,\widehat{M}^{T})\) satisfy_

\[\mathbf{Est}_{\mathsf{D}}^{\mathsf{On}}(T)=\sum_{t=1}^{T}\mathsf{D}_{\mathsf{ CB}}\Big{(}\widehat{M}^{i}(\pi^{t}),M^{\star}(\pi^{t})\Big{)}\geq\Omega\Big{(} \sqrt{T\beta_{\mathsf{Off}}}\Big{)}.\]

## Part III Proofs

### Technical tools

**Lemma F.1**.: _For any non-increasing sequence \(x_{1}\geq x_{2}\geq\cdots\geq x_{T+1}\geq 1\),_

\[\sum_{t=1}^{T}\frac{x_{t}-x_{t+1}}{x_{t}}\leq\log(x_{1}).\]

Proof of Lemma F.1.: Since \(\log(1+a)\leq a\) for all \(a>-1\), for any \(t\in[T]\), we have

\[-\log(x_{t}/x_{t+1})=\log\biggl{(}1+\biggl{(}\frac{x_{t+1}}{x_{t}}-1\biggr{)} \biggr{)}\leq\biggl{(}\frac{x_{t+1}}{x_{t}}-1\biggr{)}.\]

Summing up over \(t\in[T]\), we obtain

\[\sum_{t=1}^{T}\frac{x_{t}-x_{t+1}}{x_{t}}=\sum_{t=1}^{T}1-\frac{x_{t+1}}{x_{t} }\leq\,\sum_{t=1}^{T}\log(x_{t}/x_{t+1})=\log(x_{1}/x_{T+1})\leq\log(x_{1}).\]

The following lemma gives an improvement to Lemma A.13 of Foster et al. [27] that removes a logarithmic factor. This shows that up to an absolute constant, squared Hellinger distance obeys a one-sided version of the chain rule for KL divergence.

**Lemma F.2** (Subadditivity for squared Hellinger distance).: _Let \((\mathcal{X}_{1},\mathscr{F}_{1}),\ldots,(\mathcal{X}_{n},\mathscr{F}_{n})\) be a sequence of measurable spaces, and let \(\mathcal{X}^{i}=\prod_{i=t}^{i}\mathcal{X}_{t}\) and \(\mathscr{F}^{i}=\bigotimes_{t=1}^{i}\mathscr{F}_{t}\). For each \(i\), let \(\mathbb{P}^{i}(\cdot\mid\cdot)\) and \(\mathbb{Q}^{i}(\cdot\mid\cdot)\) be probability kernels from \((\mathcal{X}^{i-1},\mathscr{F}^{i-1})\) to \((\mathcal{X}_{i},\mathscr{F}_{i})\). Let \(\mathbb{P}\) and \(\mathbb{Q}\) be the laws of \(X_{1},\ldots,X_{n}\) under \(X_{i}\sim\mathbb{P}^{i}(\cdot\mid X_{1:i-1})\) and \(X_{i}\sim\mathbb{Q}^{i}(\cdot\mid X_{1:i-1})\) respectively. Then it holds that_

\[\mathsf{D}_{\mathsf{H}}^{2}(\mathbb{P},\mathbb{Q})\leq 7\cdot\mathbb{E}_{ \mathbb{P}}\Biggl{[}\sum_{i=1}^{n}\mathsf{D}_{\mathsf{H}}^{2}(\mathbb{P}^{i}( \cdot\mid X_{1:i-1}),\mathbb{Q}^{i}(\cdot\mid X_{1:i-1}))\Biggr{]}.\]

Proof of Lemma F.2.: We appeal to the _cut-and-paste property_ of [34], defining a collection of distributions indexed by a hypercube \(\{0,1\}^{n}\) with the property that the vertices \((0,\ldots,0)\) and \((1,\ldots,1)\) correspond to the distribution \(\mathbb{P}\) and \(\mathbb{Q}\). Concretely, for any vertex \(v\in\{0,1\}^{n}\) of the hypercube, we define a probability distribution

\[\mathfrak{P}_{v}:=\prod_{i\in[n]}R_{v_{i}}(\cdot\mid X_{1:i-1}),\qquad\text{ where }R_{v_{i}}(\cdot\mid X_{1:i-1})=\begin{cases}\mathbb{P}^{i}(\cdot\mid X_{1:i-1})& \text{if }v_{i}=0,\\ \mathbb{Q}^{i}(\cdot\mid X_{1:i-1})&\text{if }v_{i}=1.\end{cases}\]

Observe that \(\mathfrak{P}_{(0,\ldots,0)}=\mathbb{P}\) and \(\mathfrak{P}_{(1,\ldots,1)}=\mathbb{Q}\). Now, consider any four vertices \(a,b,c,d\in\{0,1\}^{n}\) with the property that \(\{a_{i},b_{i}\}=\{c_{i},d_{i}\}\) for each \(i\in[n]\) (with \(\{\cdot\}\) interpreted as a multi-set). Then for any measure \(\nu:=\prod_{i=1}^{n}\nu_{i}(\cdot|X_{1:i-1})\), where \(\nu_{i}(\cdot|X_{1:i-1})\) is any common dominating conditional measure16 for \(\mathbb{P}^{i}(\cdot|X_{1:i-1})\) and \(\mathbb{Q}^{i}(\cdot|X_{1:i-1})\), by the definition of squared Hellinger distance we have

Footnote 16: For example, we can take \(\nu_{i}(\cdot|X_{1:i})=(\mathbb{P}^{i}(\cdot|X_{1:i-1})+\mathbb{Q}^{i}(\cdot|X_ {1:i-1}))/2\). for \(\mathbb{P}^{i}\) and \(\mathbb{Q}^{i}\). The result is independent of the choice of \(\nu\).

\[\mathsf{D}_{\mathsf{H}}^{2}(\mathfrak{P}_{a},\mathfrak{P}_{b}) =1-\int\sqrt{\prod_{i=1}^{n}\frac{dR_{a_{i}}(\cdot\mid X_{1:i-1}) }{d\nu_{i}}\frac{dR_{b_{i}}(\cdot\mid X_{1:i-1})}{d\nu_{i}}}d\nu\] \[=1-\int\sqrt{\prod_{i=1}^{n}\frac{dR_{c_{i}}(\cdot\mid X_{1:i-1} )}{d\nu_{i}}\frac{dR_{d_{i}}(\cdot\mid X_{1:i-1})}{d\nu_{i}}}d\nu\] \[=\mathsf{D}_{\mathsf{H}}^{2}(\mathfrak{P}_{c},\mathfrak{P}_{d}).\] (23)Let \(k\) be the maximum integer such that \(2^{k}\leq n\). Then since Eq. (23) holds, by Theorem 7 of Jayram [34] applied with the pairwise disjoint collection \(A_{j}=\big{\{}i\leq n\mid i\mod 2^{k}=j\big{\}}\) for all \(j\in[2^{k}]\) where \(|A_{j}|\leq 2\) for all \(j\), we have

\[\mathsf{D}_{\mathsf{H}}^{2}(\mathbb{P},\mathbb{Q})\cdot\prod_{i=1 }^{n}(1-1/2^{i}) \leq\sum_{j=1}^{2^{k}}\mathsf{D}_{\mathsf{H}}^{2}\Bigg{(}\mathbb{P}, \prod_{l\in A_{j}}\mathbb{Q}^{l}(\cdot\mid X_{1:l-1})\prod_{l^{\prime}\notin A_ {j}}\mathbb{P}^{l^{\prime}}(\cdot\mid X_{1:l^{\prime}-1})\Bigg{)}\] \[\leq 2\,\mathbb{E}_{\mathbb{P}}\Bigg{[}\sum_{i=1}^{n}\mathsf{D}_{ \mathsf{H}}^{2}(\mathbb{P}^{i}(\cdot\mid X_{1:i-1}),\mathbb{Q}^{i}(\cdot\mid X _{1:i-1}))\Bigg{]}.\]

To conclude, we note that \(\prod_{i=1}^{n}(1-1/2^{i})>2/7\).

## Appendix G Proofs from Section 3

### Proofs from Section 3.1

**Theorem 3.1** (Main upper bound for OEOE).: _For any instance \((\mathcal{X},\mathcal{Y},\mathcal{Z},\mathcal{K},\mathcal{F})\), any metric-like loss \(\mathsf{D}\), and any offline estimator \(\mathbf{Alg}_{\mathsf{Off}}\) with parameter \(\beta_{\mathsf{Off}}\geq 0\), Algorithm 1 is oracle-efficient and achieves_

\[\mathbf{Est}_{\mathsf{D}}^{\mathsf{On}}(T)\leq O(C_{\mathsf{D}}\cdot(\beta_{ \mathsf{Off}}+1)\cdot\min\{\log|\mathcal{F}|,|\mathcal{X}|\log T\}).\]

Proof of Theorem 3.1.: Our main technical result is the following lemma, which is proven in the sequel.

**Lemma G.1**.: _Consider any instance \((\mathcal{X},\mathcal{Y},\mathcal{Z},\mathcal{K},\mathcal{F})\) and a metric-like loss17 Don \(\mathcal{Z}\). Let \(f^{\star}\in\mathcal{F}\) be the target parameter, and consider a sequence of sets \(\mathcal{F}=\mathcal{F}_{1}\supseteq\mathcal{F}_{2}\supseteq\cdots\supseteq \mathcal{F}_{T}\supseteq\{f^{\star}\}\) and sequence of covariates \(x^{1},\ldots,x^{T}\in\mathcal{X}\) with the property that for all \(t\in\mathcal{T}\), all \(f\in\mathcal{F}_{t}\) satisfy the following offline estimation guarantee:_

Footnote 17: For this lemma, \(\mathsf{D}\) need not be a metric-like loss; it suffices that \(\mathsf{D}\) is bounded and has \(\mathsf{D}(z,z)=0\) for all \(z\in\mathcal{Z}\).

\[\sum_{s=1}^{t-1}\mathsf{D}(f(x^{\iota}),f^{\star}(x^{\iota}))\leq\beta_{ \mathsf{Off}}.\] (24)

_Then, by defining \(\mu^{\iota}=\mathrm{Unif}(\mathcal{F}_{t})\), we have that_

\[\sum_{t=1}^{T}\mathbb{E}_{f\sim\mu^{\iota}}[\mathsf{D}(f(x^{\iota}),f^{\star}( x^{\iota}))]\leq O((\beta_{\mathsf{Off}}+1)\cdot\min\{\log|\mathcal{F}|,| \mathcal{X}|\log T\}).\]

To invoke Lemma G.1, we observe that the version space construction in Algorithm 1 ensures that for all \(t\in[T]\), all \(f\in\mathcal{F}_{t}\) satisfy

\[\sum_{s=1}^{t-1}\mathsf{D}(f(x^{\iota}),f^{\star}(x^{\iota}))\leq\sum_{s=1}^{t -1}C_{\mathsf{D}}\Big{(}\mathsf{D}\Big{(}f(x^{\iota}),\widehat{f}^{\iota}(x^ {\iota})\Big{)}\Big{)}+\mathsf{D}\Big{(}\widehat{f}^{\iota}(x^{\iota}),f^{ \star}(x^{\iota})\Big{)}\leq 2C_{\mathsf{D}}\beta_{\mathsf{Off}}.\]

In addition, it is immediate to see that \(\mathcal{F}=\mathcal{F}_{1}\supseteq\mathcal{F}_{2}\supseteq\cdots\supseteq \mathcal{F}_{T}\). Thus, by invoking Lemma G.1 with parameter \(\beta_{\mathsf{Off}}{}^{\prime}=2C_{\mathsf{D}}\beta_{\mathsf{Off}}\), we have that

\[\mathbf{Est}_{\mathsf{D}}^{\mathsf{On}}(T)=\sum_{t=1}^{T}\mathbb{E}_{f\sim\mu ^{\iota}}[\mathsf{D}(f(x^{\iota}),f^{\star}(x^{\iota}))]\leq O((C_{\mathsf{D} }\beta_{\mathsf{Off}}+1)\cdot\min\{\log|\mathcal{F}|,|\mathcal{X}|\log T\}).\]

To simplify, we note that \((C_{\mathsf{D}}\beta_{\mathsf{Off}}+1)\leq C_{\mathsf{D}}(\beta_{\mathsf{Off}} +1)\), since \(C_{\mathsf{D}}\geq 1\).

Proof of Lemma G.1.We begin by proving that \(\mathbf{Est}_{\mathsf{D}}^{\mathsf{On}}(T)\leq O(C_{\mathsf{D}}\cdot(\beta_{ \mathsf{Off}}+1)\cdot\log|\mathcal{F}|)\). Let us adopt the convention that \(\mathcal{F}_{T+1}=\{f^{\star}\}\), so that \(\mathcal{F}_{T+1}\subseteq\mathcal{F}_{T}\subseteq\cdots\subseteq\mathcal{F}_ {1}\). For any parameter \(f\in\mathcal{F}\setminus\{f^{\star}\}\), define \(t_{f}:=\min\{t:f\notin\mathcal{F}_{t+1}\}\). It is immediate to see that for all \(f\in\mathcal{F}\setminus\{f^{\star}\}\), \(1\leq t_{f}\leq T\) and for all \(t\in[T]\), \(|\{f:t_{f}=t\}|=|\mathcal{F}_{t}\setminus\mathcal{F}_{t+1}|\). Using that \(\mathsf{D}(f^{\star}(x),f^{\star}(x))=0\) for all \(x\in\mathcal{X}\), we re-write the online estimation error as

\[\sum_{t=1}^{T}\mathbb{E}_{f\sim\mu^{t}}[\mathsf{D}(f(x^{\prime}), f^{\star}(x^{\prime}))]=\sum_{t=1}^{T}\frac{1}{|\mathcal{F}_{t}|}\sum_{f\in \mathcal{F}_{t}}\mathsf{D}(f(x^{\prime}),f^{\star}(x^{\prime})) =\sum_{t=1}^{T}\frac{1}{|\mathcal{F}_{t}|}\sum_{f\in\mathcal{F}_{ t},f\neq f^{\star}}\mathsf{D}(f(x^{\prime}),f^{\star}(x^{\prime}))\] \[=\sum_{t=1}^{T}\sum_{f:t_{f}=t}\sum_{s\leq t}\frac{1}{|\mathcal{F }_{s}|}\mathsf{D}(f(x^{\prime}),f^{\star}(x^{\prime}))\]

Using that \(\mathcal{F}_{T}\subseteq\mathcal{F}_{T-1}\subseteq\cdots\subseteq\mathcal{F}_ {1}\), we can upper bound this quantity by

\[\sum_{t=1}^{T}\sum_{f:t_{f}=t}\sum_{s\leq t}\frac{1}{|\mathcal{F} _{s}|}\mathsf{D}(f(x^{\prime}),f^{\star}(x^{\prime}))\leq\sum_{t=1}^{T}\sum_{f: t_{f}=t}\frac{1}{|\mathcal{F}_{t}|}\sum_{s\leq t}\mathsf{D}(f(x^{*}),f^{\star}(x^{ \prime})).\]

To proceed, observe that for any function \(f\in\mathcal{F}\), if \(t_{f}=t\), then \(f\in\mathcal{F}_{t}\). It follows from the assumed bound in Eq. (24) that if \(t_{f}=t\), then

\[\sum_{s\leq t}\mathsf{D}(f(x^{\prime}),f^{\star}(x^{\prime})) =\mathsf{D}(f(x^{\prime}),f^{\star}(x^{\prime}))+\sum_{s\leq t-1} \mathsf{D}(f(x^{\prime}),f^{\star}(x^{*}))\] \[\leq 1+\beta_{\mathsf{Off}},\]

where we have used the fact that the loss \(\mathsf{D}\) is bounded by \(1\). Using this fact, and recalling that for all \(t\in[T]\), \(|\{f:t_{f}=t\}|=|\mathcal{F}_{t}\setminus\mathcal{F}_{t+1}|\), we bound

\[\sum_{t=1}^{T}\sum_{f:t_{f}=t}\frac{1}{|\mathcal{F}_{t}|}\sum_{s \leq t}\mathsf{D}(f(x^{*}),f^{\star}(x^{*}))\leq(\beta_{\mathsf{Off}}+1)\sum_{ t=1}^{T}\sum_{f:t_{f}=t}\frac{1}{|\mathcal{F}_{t}|}\leq(\beta_{\mathsf{Off}}+1) \sum_{t=1}^{T}\frac{|\mathcal{F}_{t}\setminus\mathcal{F}_{t+1}|}{|\mathcal{F}_ {t}|}.\]

Finally, by Lemma F.1, we have that

\[\sum_{t=1}^{T}\frac{|\mathcal{F}_{t}\setminus\mathcal{F}_{t+1}|}{|\mathcal{F} _{t}|}=\sum_{t=1}^{T}\frac{|\mathcal{F}_{t}|-|\mathcal{F}_{t+1}|}{|\mathcal{F} _{t}|}\leq\log|\mathcal{F}_{1}|=\log|\mathcal{F}|.\]

We conclude that

\[\sum_{t=1}^{T}\mathbb{E}_{f\sim\mu^{t}}[\mathsf{D}(f(x^{\prime}), f^{\star}(x^{\prime}))]\leq(\beta_{\mathsf{Off}}+1)\log|\mathcal{F}|.\]

We now prove the bound \(\mathbf{Est}_{\mathsf{D}}^{\mathsf{On}}(T)\leq O(C_{\mathsf{D}}\cdot(\beta_{ \mathsf{Off}}+1)\cdot|\mathcal{X}|\log T)\). For each \(x\in\mathcal{X}\), define \(N_{t-1}(x)=\sum\limits_{s=1}^{t-1}\mathbbm{1}(x^{*}=x)\). Then we can write the online estimation error as

\[\sum_{t=1}^{T}\mathbb{E}_{f\sim\mu^{t}}[\mathsf{D}(f(x^{\prime}), f^{\star}(x^{\prime}))]=\sum_{t=1}^{T}\sum_{x\in\mathcal{X}}\frac{1(x=x^{ \prime})}{N_{t-1}(x)\lor 1}\cdot\mathbb{E}_{f\sim\mu^{t}}[(N_{t-1}(x)\lor 1) \mathsf{D}(f(x),f^{\star}(x))].\]

From the definition of \(\mu^{t}\), we have that

\[\mathbb{E}_{f\sim\mu^{t}}[(N_{t-1}(x)\lor 1)\mathsf{D}(f(x),f^{ \star}(x))] =\frac{1}{|\mathcal{F}_{t}|}\sum_{f\in\mathcal{F}_{t}}(N_{t-1}(x) \lor 1)\mathsf{D}(f(x),f^{\star}(x))\] \[\leq\frac{1}{|\mathcal{F}_{t}|}\sum_{f\in\mathcal{F}_{t}}(N_{t-1}( x)+1)\mathsf{D}(f(x),f^{\star}(x)).\]

Now, from the offline guarantee assumed in Eq. (24), we have for all \(x\in\mathcal{X}\) and \(f\in\mathcal{F}_{t}\),

\[(N_{t-1}(x)+1)\mathsf{D}(f(x),f^{\star}(x))\leq\sum_{s\leq t-1} \mathsf{D}(f(x^{*}),f^{\star}(x^{*}))+\mathsf{D}(f(x),f^{\star}(x))\leq\beta_{ \mathsf{Off}}+1.\]Combining these observations, we have

\[\sum_{t=1}^{T}\mathbb{E}_{f\sim\mu^{t}}[\mathsf{D}(f(x^{t}),f^{\star}(x^{t}))]\leq (\beta_{\mathsf{Off}}+1)\sum_{t=1}^{T}\sum_{x\in\mathcal{X}}\frac{1(x=x^{t})}{N _{t-1}(x)\lor 1}.\]

Now, for each \(x\in\mathcal{X}\), define \(t_{x}=\min\left\{t\leq T:x^{t}=x\right\}\) if this set is not empty, and set \(t_{x}=T\) otherwise. From this definition and the fact that \(1+1/2+\cdots+1/T\leq 1+\log T\), we have that

\[\sum_{x\in\mathcal{X}}\sum_{t=1}^{T}\frac{\mathbbm{1}(x=x^{t})}{N _{t-1}(x)\lor 1} =\sum_{x\in\mathcal{X}}\Biggl{(}\sum_{t=1}^{t_{x}}\frac{\mathbbm{1 }(x=x^{t})}{N_{t-1}(x)\lor 1}+\sum_{t=t_{x}+1}^{T}\frac{\mathbbm{1}(x=x^{t})}{N _{t-1}(x)\lor 1}\Biggr{)}\] \[\leq\sum_{x\in\mathcal{X}}\Biggl{(}1+\sum_{i=1}^{N_{T-1}(x)} \frac{1}{i}\Biggr{)}\] \[\leq 2|\mathcal{X}|+|\mathcal{X}|\log T\leq 3|\mathcal{X}|\log T.\]

We conclude that

\[\sum_{t=1}^{T}\mathbb{E}_{f\sim\mu^{t}}[\mathsf{D}(f(x^{t}),f^{\star}(x^{t}))] \leq 3(\beta_{\mathsf{Off}}+1)\cdot|\mathcal{X}|\log T.\]

**Theorem 3.2** (Main lower bound for OEOE).: _Consider the binary classification setting with \(\mathcal{Z}=\mathcal{Y}=\{0,1\}\) and loss \(\mathsf{D}_{0/1}(\cdot,\cdot)\). For any \(N\in\mathbb{N}\) and \(\beta_{\mathsf{Off}}>0\), there exists an instance \((\mathcal{X},\mathcal{Y},\mathcal{Z},\mathcal{K},\mathcal{F})\) with \(\log|\mathcal{F}|=|\mathcal{X}|=N\) such that for any oracle-efficient algorithm, there is a sequence of covariates \((x^{1},\ldots,x^{r})\) and offline oracle with parameter \(\beta_{\mathsf{Off}}\) such that \(\mathbb{E}\bigl{[}\mathbf{Est}_{\mathsf{Off}}^{\mathsf{On}}(T)\bigr{]}\geq \Omega(\min\left\{(\beta_{\mathsf{Off}}+1)N,T\right\})\)._

Proof of Theorem 3.2.: Let \(N\geq 1\) be given, a consider the model class where \(\mathcal{X}=\{x_{1},\ldots,x_{N}\}\) is an arbitrary discrete set, \(\mathcal{Z}=\mathcal{Y}=\{0,1\}\), \(\mathcal{F}=\{0,1\}^{\mathcal{X}}\), \(\mathsf{D}(z_{1},z_{2})=\mathsf{D}_{0/1}(z_{1},z_{2})=\mathbbm{1}\{z_{1}\neq z _{2}\}\), and \(\mathcal{K}(z)=\mathbbm{1}_{z}\).

We first specify the offline estimation oracle, then specify an adversarially chosen covariate sequence. Fix \(T\in\mathbb{N}\), and for any \(1\leq t\leq T\) and sequence of covariates \(x^{1},\ldots,x^{t}\) define \(N_{t}(x):=\sum_{s=1}^{t}\mathbbm{1}(x^{s}=x)\). For any target parameter \(f^{\star}\in\mathcal{F}\) and offline estimation parameter \(\beta_{\mathsf{Off}}>0\), we consider the oracle \(\mathbf{Alg}_{\mathsf{Off}}^{\prime}(\cdot;f^{\star})\) for the sequence \(x^{1},\ldots,x^{t}\) that returns

\[\widehat{f}^{\dagger}(x)=\begin{cases}0&\text{if }N_{t-1}(x)<\beta_{\mathsf{Off}}, \\ f^{\star}(x)&\text{otherwise.}\end{cases}\]

To complete the construction, we consider sequence \((x^{1},\ldots,x^{r})\) in which

\[x^{t}=x_{\min\{\lceil t/\lceil\beta_{\mathsf{Off}}\rceil\rceil,N\}}.\]

Equivalently, and perhaps more intuitively, we set

\[(x^{1},\ldots,x^{T})=\underbrace{(x_{1},\ldots,x_{1})}_{\lceil\beta_{\mathsf{ off}}\rceil},\underbrace{x_{2},\ldots,x_{2}}_{\lceil\beta_{\mathsf{Off}}\rceil}, \ldots,\underbrace{x_{N},\ldots,x_{N}}_{\lceil\beta_{\mathsf{Off}}\rceil},x_ {N},x_{N},\ldots),\]

stopping earlier if \(T\leq N\lceil\beta_{\mathsf{Off}}\rceil\).

For any \(f^{\star}\), we now show that \(\mathbf{Alg}_{\mathsf{Off}}^{\prime}(\cdot;f^{\star})\) is an offline oracle with parameter \(\beta_{\mathsf{Off}}\) on the sequence \(x^{1},\ldots,x^{r}\). This is because for any \(i<\min\left\{\lceil t/\lceil\beta_{\mathsf{Off}}\rceil\right\rceil,N\right\}\), the covariate \(x_{i}\) is repeated \(\lceil\beta_{\mathsf{Off}}\rceil\geq\beta_{\mathsf{Off}}\) times. Thus \(\widehat{f}^{i}(x_{i})=f^{\star}(x_{i})\). This implies for \(t\leq N\cdot\lceil\beta_{\mathsf{Off}}\rceil\) that

\[\sum_{s=1}^{t-1}\mathsf{D}_{0/1}\Bigl{(}\widehat{f}^{i}(x^{s}),f^{\star}(x^{s} )\Bigr{)}=\sum_{s=t-\lceil t/\lceil\beta_{\mathsf{Off}}\rceil\rceil\cdot \lceil\beta_{\mathsf{Off}}\rceil}^{t-1}\mathsf{D}_{0/1}\Bigl{(}\widehat{f}^{i}(x ^{s}),f^{\star}(x^{s})\Bigr{)}\leq\lceil\beta_{\mathsf{Off}}\rceil-1\leq\beta_ {\mathsf{Off}}.\]If \(t>N\cdot\lceil\beta_{\mathsf{Off}}\rceil\), then all the covariates are repeated for more than \(\lceil\beta_{\mathsf{Off}}\rceil\) times, thus \(\widehat{f}^{t}=f^{\star}\). Overall, we have shown that \(\mathbf{Alg}^{\prime}_{\mathsf{Off}}(\cdot;f^{\star})\) is an offline oracle with parameter \(\beta_{\mathsf{Off}}\).

Now, fix any oracle-efficient online estimation algorithm, and consider the expected regret under \(f^{\star}\sim\mathrm{Unif}(\mathcal{F})\) (with \(\mathbf{Alg}^{\prime}_{\mathsf{Off}}(\cdot;f^{\star})\) as the oracle). If \(T\geq N\lceil\beta_{\mathsf{Off}}\rceil\), then regardless of how the algorithm chooses \(\mu^{t}\), since for any block of \(x_{i}\), \(f^{\star}(x_{i})\) is independent of \(\mu^{t}(x_{i})\), the expected regret is lower bounded as

\[\sum_{t=1}^{T}\mathbb{E}_{f^{\star}\sim\mathrm{Unif}(\mathcal{F}) }\,\mathbb{E}_{\widehat{f}^{\prime}\sim\mu^{t}}\big{[}\mathsf{D}_{0/1}\big{(} \bar{f}(x^{\star}),f^{\star}(x^{\star})\big{)}\big{]}\] \[\geq\sum_{i=1}^{N}\sum_{j=1}^{\lceil\beta_{\mathsf{Off}}\rceil} \mathbb{E}_{f^{\star}\sim\mathrm{Unif}(\mathcal{F})}\,\mathbb{E}_{\widehat{f} \sim\mu^{t\lceil\beta_{\mathsf{Off}}\rceil+j}}\big{[}\mathsf{D}_{0/1}\big{(} \bar{f}(x_{i}),f^{\star}(x_{i})\big{)}\big{]}\] \[=\frac{1}{2}N\lceil\beta_{\mathsf{Off}}\rceil\geq\Omega(N(\beta_ {\mathsf{Off}}+1))=\Omega(\min\left\{(\beta_{\mathsf{Off}}+1)\log|\mathcal{F}|, (\beta_{\mathsf{Off}}+1)|\mathcal{X}|\right\}).\]

### Proofs from Section 3.2

**Theorem 3.3** (Impossibility of memoryless algorithms for OEOE).: _Consider the binary classification setting with \(\mathcal{Z}=\mathcal{Y}=\{0,1\}\) and loss \(\mathsf{D}_{0/1}(\cdot,\cdot)\). For any \(N\in\mathbb{N}\) and \(\beta_{\mathsf{Off}}\geq 0\), there exists an instance \((\mathcal{X},\mathcal{Y},\mathcal{Z},\mathcal{K},\mathcal{F})\) with \(|\mathcal{F}|=|\mathcal{X}|=N\) such that for any memoryless oracle-efficient algorithm, there exists a sequence of covariates \((x^{1},\ldots,x^{T})\) and a (potentially improper) offline oracle \(\mathbf{Alg}_{\mathsf{Off}}\) with parameter \(\beta_{\mathsf{Off}}\) such that \(\mathbb{E}\big{[}\mathbf{Est}^{\mathsf{On}}_{0}(T)\big{]}\geq\Omega(\min\left\{ N(\beta_{\mathsf{Off}}+1),T\right\})\). This conclusion still holds when the online estimation algorithm remembers \(\widehat{f}^{1},\ldots,\widehat{f}^{t-1}\) but not \(x^{1},\ldots,x^{t-1}\)._

Proof of Theorem 3.3.: Given a parameter \(\beta_{\mathsf{Off}}>0\) and an integer \(N\), assume without loss of generality that \(K:=T/(\lfloor\beta_{\mathsf{Off}}\rfloor+1)\) is an integer. Consider the instance \((\mathcal{X},\mathcal{Y},\mathcal{Z},\mathcal{K},\mathcal{F})\) with \(\mathcal{X}=[N]\), \(\mathcal{Z}=\mathcal{Y}=\{0,1\}\), \(\mathsf{D}=\mathsf{D}_{0/1}\), \(\mathcal{K}(z)=\mathbbm{1}_{z}\), and parameter space \(\mathcal{F}=\{f_{i}\}_{i\in[N]}\) is defined as

\[f_{i}(x)=\mathbbm{1}\{x=i\}.\]

We consider a sequence of covariates \((x^{1},\ldots,x^{T})\) divided into \(K\) blocks, each with length \(\lfloor\beta_{\mathsf{Off}}\rfloor+1\). In each block, the covariates will be chosen to be the same, i.e., \(x^{1}=\cdots=x^{\lfloor\beta_{\mathsf{Off}}\rfloor+1}\), \(x^{\lfloor\beta_{\mathsf{Off}}\rfloor+2}=\cdots=x^{\lfloor\beta_{\mathsf{Off}} \rfloor+2}\). We define \(\tau_{t}=\lceil t/(\lfloor\beta_{\mathsf{Off}}\rfloor+1)\rceil\) as the index of the block the step \(t\) belongs to, and we adopt the convention that \(x_{\tau}\in\mathcal{X}\) is value of the covariates for block \(\tau\), i.e., \(x^{i}=x_{\tau_{t}}\) for all \(t\). We leave the precise choice for \(x_{1},\ldots,x_{K}\) as a free parameter for now.

Fix any memoryless oracle-efficient online estimation algorithm defined by a sequence of maps \(\{F^{\star}\}_{t\in[T]}\) (cf. Definition 3.1). We set the true target parameter to be \(f^{\star}=f_{i^{\star}}\), where the index \(i^{\star}\in[N]\) will be chosen later in the proof (in an adversarial fashion based on the algorithm under consideration); for now, we leave \(i^{\star}\in[N]\) as a free parameter.

We first specify the offline estimation oracle under \(f_{i^{\star}}\). For each block index \(\tau=1,\ldots,K\), define

\[\mathcal{X}^{\tau}=\mathcal{X}\setminus(\{x^{\star}\}_{s\leq(\tau-1)(\lfloor \beta_{\mathsf{Off}}\rfloor+1)}\cup\{i^{\star}\})\]

as the set of covariates in \(\mathcal{X}\setminus\{i^{\star}\}\) that have not been observed before block \(\tau\), and let \(\overline{\mathcal{X}}^{\tau}:=\mathcal{X}^{\tau}\cup\{i^{\star}\}\). We define

\[\widehat{f}^{i}(x)=\mathbbm{1}\{x\in\overline{\mathcal{X}}^{\tau_{t}}\}\]

as the estimator returned by the oracle at round \(t\). It is immediate from this construction that regardless of how \(x^{1},\ldots,x^{T}\) are chosen, the offline estimation error is bounded by

\[\forall t\in[T],\ \sum_{s<t}\mathsf{D}_{0/1}\Big{(}f^{\star}(x^{\star}),\widehat{f }^{i}(x^{\star})\Big{)}\leq\sum_{s=(\tau_{t}-1)(\lfloor\beta_{\mathsf{Off}} \rfloor+1)+1}^{t-1}\mathsf{D}_{0/1}\Big{(}f^{\star}(x^{\star}),\widehat{f}^{i}(x ^{\star})\Big{)}\leq\lfloor\beta_{\mathsf{Off}}\rfloor\leq\beta_{\mathsf{Off}},\]

since the value of \(\widehat{f}^{i}\) differs from \(f_{i^{\star}}\) only for covariates that have not been observed before block \(\tau_{t}\).

It remains to lower bound the algorithm's online estimation error. To start, note that \(\mathsf{D}_{0/1}\) coincides with \(\mathsf{D}_{\mathsf{sq}}\) on the set \(\{0,1\}\) and \(\mathsf{D}_{\mathsf{sq}}\) is convex. Hence, by Jensen's inequality, it suffices to lower bound

\[\sum_{t=1}^{T}(f^{\iota}(x^{\iota})-f_{i^{\star}}(x^{\iota}))^{2},\]

where \(f^{\iota}(x^{\iota})\) is the mean under \(\bar{f}^{\iota}(x^{\iota})\) where \(\bar{f}^{\iota}\sim\mu^{\iota}=F^{\iota}(\widehat{f}^{\downarrow},\ldots, \widehat{f}^{\downarrow-1},\widehat{f}^{\iota})\).

To proceed, we specify the sequence \(x^{\downarrow},\ldots,x^{\tau}\), choosing \(x^{\iota}\) as a measurable function of \(\overline{\mathcal{X}}^{\iota}\) and \(i^{\star}\) (recall that \(i^{\star}\) itself has yet to be chosen). Fix a round \(t\), and suppose that \(\mathcal{X}^{\iota}\neq\varnothing\). We choose \(x^{\iota}\) to lower bound the estimation error by considering two cases. In the process, we will also define a function \(\widehat{j}^{\tau}:(2^{[N]})^{\otimes\tau}\to[N]\cup\{\bot\}\) for each \(\tau\in[K]\), where \((2^{[N]})^{\otimes\tau}=\underbrace{2^{[N]}\times\cdots\times 2^{[N]}}_{\tau\text{ copies}}\). Let \(\tau\in[K]\) be fixed.

* If \(\sum\limits_{p=1}^{\lfloor\beta_{\mathsf{0Inf}}\rfloor+1}\mathbbm{1}(f^{\tau( \lfloor\beta_{\mathsf{0Inf}}\rfloor+1)+p}(x)\leq 1/2)\geq\frac{\lfloor\beta_{ \mathsf{0Inf}}\rfloor+1}{2}\) for all \(x\in\overline{\mathcal{X}}^{\tau}\), we set \(x_{\tau}=i^{\star}\) (equivalently, \(x^{\tau(\lfloor\beta_{\mathsf{0Inf}}\rfloor+1)+p}=i^{\star}\) for \(p=1,\ldots,\lfloor\beta_{\mathsf{0Inf}}\rfloor+1\)), so that \[\sum_{t=\tau(\lfloor\beta_{\mathsf{0Inf}}\rfloor+1)+1}^{(\tau+1)(\lfloor\beta_{ \mathsf{0Inf}}\rfloor+1)}\max_{x^{\iota}}(f^{\iota}(x^{\iota})-f_{i^{\star}}( x^{\iota}))^{2}\geq\frac{\lfloor\beta_{\mathsf{0Inf}}\rfloor+1}{8}.\] In this case, we define \(\widehat{j}^{\tau}(\overline{\mathcal{X}}^{\tau},\ldots,\overline{\mathcal{ X}}^{\tau})=\bot\).
* If there exists \(j\in\overline{\mathcal{X}}^{\tau}\) such that \(\sum\limits_{p=1}^{\lfloor\beta_{\mathsf{0Inf}}\rfloor+1}\mathbbm{1}(f^{\tau( \lfloor\beta_{\mathsf{0Inf}}\rfloor+1)+p}(j)\leq 1/2)<\frac{\lfloor\beta_{ \mathsf{0Inf}}\rfloor+1}{2}\), we set \(x_{\tau}=j\) (equivalently, \(x^{\tau(\lfloor\beta_{\mathsf{0Inf}}\rfloor+1)+p}=j\) for \(p=1,\ldots,\lfloor\beta_{\mathsf{0Inf}}\rfloor+1\)) for the least such \(j\), so that \[\sum_{t=\tau(\lfloor\beta_{\mathsf{0Inf}}\rfloor+1)+1}^{(\tau+1)(\lfloor\beta_ {\mathsf{0Inf}}\rfloor+1)}\max_{x^{\iota}}(f^{\iota}(x^{\iota})-f_{i^{\star}}( x^{\iota}))^{2}\geq\frac{\lfloor\beta_{\mathsf{0Inf}}\rfloor+1}{8}\mathbbm{1} \{i^{\star}\neq j\}.\] In this case, we define \(\widehat{j}^{\tau}(\overline{\mathcal{X}}^{\tau},\ldots,\overline{\mathcal{ X}}^{\tau})=j\) as well.

Note that since \(f^{\iota}\) is a measurable function of \(\overline{\mathcal{X}}^{\rceil}\), \(\widehat{j}^{\uparrow}\),...,\(\overline{\mathcal{X}}^{\tau_{\iota}}\), \(\widehat{j}^{\uparrow_{\iota}}\) is well-defined.

Combining these cases, it follows that for any choice of \(i^{\star}\), choosing \(x_{1},\ldots,x_{K}\) in the fashion described above ensures that

\[\sum_{t=1}^{T}(f^{\iota}(x^{\iota})-f_{i^{\star}}(x^{\iota}))^{2}\geq\frac{ \lfloor\beta_{\mathsf{0Inf}}\rfloor+1}{8}\sum_{\tau=1}^{K}\mathbbm{1}\Big{\{} \widehat{j}^{\tau}(\overline{\mathcal{X}}^{\rceil},\ldots,\overline{\mathcal{ X}}^{\tau})\neq i^{\star}\Big{\}}.\]

We now state and prove the following technical lemma, which asserts that there exists a choice of \(i^{\star}\) for which the right-hand side above is large.

**Lemma G.2**.: _For any algorithm, there exists a choice for \(i^{\star}\in[N]\) such that_

\[\min\Bigl{\{}\tau:\widehat{j}^{\tau}(\overline{\mathcal{X}}^{\rceil},\ldots, \overline{\mathcal{X}}^{\tau})=i^{\star}\Bigr{\}}\geq\Omega(N).\]

Proof of Lemma G.2.: Consider a more abstract process, which we claim captures the evolution of \(\overline{\mathcal{X}}^{\tau}\). Let \(i^{\star}\in[N]\), and let \(A^{\downarrow}=[N]\). We consider a sequence of sets \(\{A^{\uparrow}\}_{\tau\geq 1}\) evolving according to the following process, parameterized by a sequence of functions \(\bigl{\{}g^{\tau}:(2^{[N]})^{\otimes\tau}\to[N]\cup\{\bot\}\bigr{\}}_{\tau\geq 1}\) and index \(i^{\star}\in[N]\).

For \(\tau\geq 1\):

* If \(g^{\tau}(A^{\downarrow},\ldots,A^{\tau})=\bot\), \(A^{\tau+1}\gets A^{\tau}\).
* If \(g^{\tau}(A^{\downarrow},\ldots,A^{\tau})\neq\bot\), let \(A^{\tau+1}=A^{\tau}\setminus\{g^{\tau}(A^{\downarrow},\ldots,A^{\tau})\}\) if \(g^{\tau}(A^{\downarrow},\ldots,A^{\tau})\neq i^{\star}\), and let \(A^{\tau+1}\gets A^{\tau}\) otherwise.

We claim that there exists \(i^{\star}\in[N]\) such that \(g^{*}(A^{1},\ldots,A^{*})\neq i^{\star}\) for all \(s<N\) under this process. To see this define a set \(X^{\tau}\) inductively: Starting from \(X^{1}=[N]\), set \(X^{\tau+1}\gets X^{\tau}\setminus g^{\tau}(X^{1},\ldots,X^{\tau})\) if \(g^{\tau}(X^{1},\ldots,X^{\tau})\neq\perp\), and set \(X^{\tau+1}\gets X^{\tau}\) otherwise; note that this process does not depend on the choice \(i^{\star}\), since \(g^{\tau}\) itself does not depend on \(i^{\star}\).

For any \(\tau\), observe that for any \(i\in X^{\tau}\), if we set \(i^{\star}=i\), then \(g^{\tau}(A^{1},\ldots,A^{\cdot})\neq i^{\star}\) for all \(s<\tau\), and so \(A^{\tau}=X^{\tau}\). It follows that as long as \(X^{\tau}\neq\varnothing\), we can choose \(i^{\star}\) such that \(g^{*}(A^{1},\ldots,A^{\cdot})\neq i^{\star}\) for all \(s<\tau\). Since \(X^{\tau}\) shrinks by at most one element per iteration, it follows that this is possible for all \(\tau<N\).

It follows immediately from Lemma G.2 that by choosing \(i^{\star}\) as guaranteed by the lemma, we have

\[\sum_{t=1}^{T}(f^{\prime}(x^{\iota})-f_{i^{\star}}(x^{\iota}))^{2} \geq\frac{\left\lfloor\beta_{\text{Off}}\right\rfloor+1}{8}\cdot \Omega(\min\left\{N,K\right\})\] \[\geq\Omega(\min\left\{N(\beta_{\text{Off}}+1),T\right\}).\]

**Theorem 3.3\({}^{\prime}\)** (Impossibility of memoryless algorithms for OEOE; proper variant).: _Consider the binary classification setting with \(\mathcal{Z}=\mathcal{Y}=\{0,1\}\) and loss \(\mathsf{D}_{0/1}(\cdot,\cdot)\). For any \(N\in\mathbb{N}\) and \(\beta_{\text{Off}}\geq 0\), there exists an instance \((\mathcal{X},\mathcal{Y},\mathcal{Z},\mathcal{K},\mathcal{F})\) with \(\left|\mathcal{F}\right|=\left|\mathcal{X}\right|=N\) such that for any memoryless oracle-efficient algorithm that is (i) **proper**, and (ii) **time-invariant**, there exists a sequence of covariates \((x^{1},\ldots,x^{T})\) and a **proper** offline oracle \(\mathbf{Alg}_{\text{Off}}\) with parameter \(\beta_{\text{Off}}\) such that \(\mathbb{E}\big{[}\mathbf{Est}_{\mathsf{D}}^{\text{On}}(T)\big{]}\geq\Omega( \min\left\{N(\beta_{\text{Off}}+1),T\right\})\)._

**Proof of Theorem 3.3\({}^{\prime}\).** Given a parameter \(N\in\mathbb{N}\), we consider the instance \((\mathcal{X},\mathcal{Y},\mathcal{Z},\mathcal{K},\mathcal{F})\) given by \(\mathcal{X}=\left\{x_{i}\right\}_{i\in[N]}\), \(\mathcal{Z}=\mathcal{Y}=\{0,1\}\), \(\mathsf{D}=\mathsf{D}_{0/1}\) and \(\mathcal{K}(z)=\mathbbm{1}_{z}\), with parameter space \(\mathcal{F}:=\left\{f_{i}\right\}_{i\in[N]}\) given by

\[f_{i}(x_{j})=\mathbbm{1}(j\geq i).\]

Let any memoryless oracle-efficient algorithm defined by prediction map \(F^{{}^{1}}=\cdots=F^{{}^{T}}=F\) be given. We lower bound the algorithm's online estimation error by considering two cases.

**Case 1:**_There exists a parameter \(f_{i}\) such that the distribution \(\mu_{i}=F(f_{i})\) satisfies \(\mu_{i}(f_{i})<1/2\)._ We consider two sub-cases of Case 1. The first subcase is where \(\mu_{i}(\{f_{j}:j>i\})>1/4\). In this case, we choose the sequence of covariates as \(x^{1}=\cdots=x^{T}=x_{i}\), set \(f^{\star}=f_{i}\), and choose \(\mathbf{Alg}_{\text{Off}}\) to be the offline estimation oracle that sets \(\widehat{f}^{1}=\cdots=\widehat{f}^{T}=f_{i}\). With this choice, the offline estimation error for the oracle satisfies

\[\forall t\in[T],\ \sum_{s<t}\mathsf{D}_{0/1}\!\left(f^{\star}(x^{ \iota}),\widehat{f}^{\iota}(x^{\iota})\right)=\sum_{s<t}\mathsf{D}_{0/1}\! \left(f_{i}(x^{\iota}),f_{i}(x^{\iota})\right)=0.\]

However, the online estimation error satisfies

\[\sum_{t=1}^{T}\mathbb{E}_{\bar{f}\sim\mu^{\iota}}\big{[}\mathsf{ D}_{0/1}\!\left(f^{\star}(x^{\iota}),\bar{f}(x^{\iota})\right)\big{]} =\sum_{t=1}^{T}\mathbb{E}_{\bar{f}\sim\mu_{i}}\big{[}\mathsf{D}_{ 0/1}\!\left(f_{i}(x_{i}),\bar{f}(x_{i})\right)\big{]}\] \[\geq\sum_{t=1}^{T}\sum_{j>i}\mu_{i}(f_{j})\mathsf{D}_{0/1}\!\left( f_{i}(x_{i}),f_{j}(x_{i})\right)\] \[=\sum_{t=1}^{T}\sum_{j>i}\mu_{i}(f_{j})\mathsf{D}_{0/1}\!\left(f_{ i}(x_{i}),f_{i+1}(x_{i})\right)\] \[\geq\frac{1}{4}\sum_{t=1}^{T}\mathsf{D}_{0/1}\!\left(f_{i}(x_{i}), f_{i+1}(x_{i})\right)=T/4.\]The second sub-case of Case 1 is where \(\mu_{i}(\{f_{j}:j>i\})\leq 1/4\). This, combined with the fact that \(\mu_{i}(f_{i})<1/2\), gives \(\mu_{i}(\{f_{j}:j<i\})>1/4\). In this sub-case, we choose the sequence of covariates as \(x^{1}=\cdots=x^{\tau}=x_{i-1}\), set \(f^{\star}=f_{i}\), and choose \(\mathbf{Alg}_{\mathsf{Off}}\) to be the offline estimation oracle that sets \(f^{1}=\cdots=f^{\tau}=f_{i}\). In this case, the offline estimation error is zero:

\[\forall t\in[T],\ \sum_{s<t}\mathsf{D}_{0/1}\Big{(}f^{\star}(x^{\ast}), \widehat{f}^{t}(x^{\ast})\Big{)}=\sum_{s<t}\mathsf{D}_{0/1}(f_{i}(x^{\ast}),f_{ i}(x^{\ast}))=0.\]

In addition, the online estimation error is lower bounded by

\[\sum_{t=1}^{T}\mathbb{E}_{\widehat{f}\sim\mu^{t}}\big{[}\mathsf{ D}_{0/1}\big{(}f^{\star}(x^{\ast}),\bar{f}(x^{\ast})\big{)}\big{]} =\sum_{t=1}^{T}\mathbb{E}_{\widehat{f}\sim\mu_{i}}\big{[}\mathsf{ D}_{0/1}\big{(}f_{i}(x_{i-1}),\bar{f}(x_{i-1})\big{)}\big{]}\] \[\geq\sum_{t=1}^{T}\sum_{j<i}\mu_{i}(f_{j})\mathsf{D}_{0/1}\big{(} f_{i}(x_{i-1}),f_{j}(x_{i-1})\big{)}\] \[=\sum_{t=1}^{T}\sum_{j<i}\mu_{i}(f_{j})\mathsf{D}_{0/1}\big{(}f_{ i}(x_{i-1}),f_{i-1}(x_{i-1})\big{)}\] \[\geq\frac{1}{4}\sum_{t=1}^{T}\mathsf{D}_{0/1}\big{(}f_{i}(x_{i-1} ),f_{i-1}(x_{i-1})\big{)}=T/4.\]

**Case 2:**_For all parameter \(f_{i}\in\mathcal{F}\), the distribution \(\mu_{i}=F(f_{i})\) has \(\mu_{i}(f_{i})\geq 1/2\)._

In this case, we choose \(x^{1},\ldots,x^{\tau}\) by repeating each of the covariates \(\lfloor\beta_{\mathsf{Off}}\rfloor+1\) number of times in increasing order by their index, and choose the offline estimation oracle \(\mathbf{Alg}_{\mathsf{Off}}\) to return \(f_{1},\ldots,f_{N}\) in the same block-wise but with the index offset by \(1\).

Formally, let \(\tau_{t}=\lceil t/(\lfloor\beta_{\mathsf{Off}}\rfloor+1)\rceil\) denote the index of the block that round \(t\) belongs to, so that \(\tau_{1}=\cdots=\tau_{\lfloor\beta_{\mathsf{Off}}\rfloor+1}=1\), \(\tau_{\lfloor\beta_{\mathsf{Off}}\rfloor+2}=\cdots=\tau_{\lfloor\beta_{\mathsf{ off}}\rfloor+2}=2\) and so on. We choose \(x^{i}=x_{\min\{\tau_{t},N\}}\), and choose the offline oracle \(\mathbf{Alg}_{\mathsf{Off}}\) to set \(\widehat{f}^{i}=f_{\min\{\tau_{t},N\}}\). Finally, we set \(f^{\star}=f_{N}\).

We have that for all \(t\), the offline estimation error of the oracle is bounded as.

\[\sum_{s<t}\mathsf{D}_{0/1}\Big{(}\widehat{f}^{i}(x^{\ast}),f^{ \star}(x^{\ast})\Big{)} =\sum_{s<t}\mathsf{D}_{0/1}\big{(}f_{N}(x_{\min\{\tau_{s},N\}}),f _{\min\{\tau_{t},N\}}(x_{\min\{\tau_{s},k\}})\big{)}\] \[=\sum_{s<t,\tau_{s}=\tau_{t}}1\leq\lfloor\beta_{\mathsf{Off}} \rfloor\leq\beta_{\mathsf{Off}}.\]

However, the online estimation error is lower bounded by

\[\sum_{t=1}^{T}\mathbb{E}_{\widehat{f}\sim\mu^{t}}\big{[}\mathsf{ D}_{0/1}\big{(}f^{\star}(x^{\ast}),\bar{f}(x^{\prime})\big{)}\big{]} \geq\frac{1}{2}\sum_{t=1}^{T}\mathsf{D}_{0/1}\big{(}f_{N}(x_{\min \{\tau_{t},N\}}),f_{\min\{\tau_{t},N\}}(x_{\min\{\tau_{t},N\}})\big{)}\] \[\geq\Omega(\min\{T,N(\beta_{\mathsf{Off}}+1)\}).\]

**Proposition D.1** (Upper bound for memoryless OEOE).: _For any instance \((\mathcal{X},\mathcal{Y},\mathcal{Z},\mathcal{K},\mathcal{F})\), metric-like loss \(\mathsf{D}\), and offline oracle \(\mathbf{Alg}_{\mathsf{Off}}\) with parameter \(\beta_{\mathsf{Off}}\), the algorithm that returns \(\bar{f}^{t}=\widehat{f}^{t}:=\mathbf{Alg}_{\mathsf{Off}}^{\ast}(x^{1},\ldots,x ^{\epsilon-1},y^{1},\ldots,y^{\epsilon-1})\) has online estimation error \(\mathbf{Est}_{\mathsf{D}}^{\mathsf{On}}(T)\leq O((\beta_{\mathsf{Off}}+1)| \mathcal{X}|\log T)\)._

**Proof of Proposition D.1.** The proof is very similar to the second part of the proof of Lemma G.1. For each \(x\in\mathcal{X}\), define \(N_{t-1}(x)=\sum\limits_{s=1}^{t-1}\mathbbm{1}(x^{\ast}=x)\). Then we can write the online estimation error as

\[\sum_{t=1}^{T}\mathsf{D}\Big{(}\widehat{f}^{t}(x^{\prime}),f^{ \star}(x^{\prime})\Big{)}=\sum_{t=1}^{T}\sum_{x\in\mathcal{X}}\frac{\mathbbm{1} (x=x^{\prime})}{N_{t-1}(x)\lor 1}\cdot(N_{t-1}(x)\lor 1)\cdot\mathsf{D}\Big{(} \widehat{f}^{t}(x),f^{\star}(x)\Big{)},\]As a consequence of the offline estimation guarantee for \(\widehat{f}^{\prime}\), we have that

\[(N_{t-1}(x)\lor 1)\mathsf{D}\Big{(}\widehat{f}^{\prime}(x),f^{ \star}(x)\Big{)}\leq\left(\sum_{s=1}^{t-1}\mathsf{D}\Big{(}\widehat{f}^{\prime} (x^{\ast}),f^{\star}(x^{\ast})\Big{)}\right)\lor 1\leq\beta_{\mathsf{Off}}+1.\]

Combining this with the preceding inequality gives

\[\sum_{t=1}^{T}\mathsf{D}\Big{(}\widehat{f}^{\prime}(x^{\epsilon} ),f^{\star}(x^{\epsilon})\Big{)}\leq(\beta_{\mathsf{Off}}+1)\sum_{t=1}^{T}\sum_ {x\in\mathcal{X}}\frac{1(x=x^{\epsilon})}{N_{t-1}(x)\lor 1}.\]

Now, for any \(x\in\mathcal{X}\), define \(t_{x}:=\min\left\{t\leq T:x^{\epsilon}=x\right\}\) if this set is not empty, and let \(t_{x}=T\) otherwise. From this definition and the fact that \(1+1/2+\cdots+1/T\leq 1+\log T\), we have that

\[\sum_{x\in\mathcal{X}}\sum_{t=1}^{T}\frac{1(x=x^{\epsilon})}{N_ {t-1}(x)\lor 1} =\sum_{x\in\mathcal{X}}\Biggl{(}\sum_{t=1}^{t_{x}}\frac{1(x=x^{ \epsilon})}{N_{t-1}(x)\lor 1}+\sum_{t=t_{x}+1}^{T}\frac{1(x=x^{\epsilon})}{N_{t-1}(x) \lor 1}\Biggr{)}\] \[\leq\sum_{x\in\mathcal{X}}\left(1+\sum_{i=1}^{N_{T-1}(x)}\frac{1 }{i}\right)\] \[\leq 2|\mathcal{X}|+|\mathcal{X}|\log T\leq 3|\mathcal{X}|\log T.\]

We conclude that

\[\sum_{t=1}^{T}\mathsf{D}\Big{(}f^{\star}(x^{\epsilon}),\widehat{ f}^{\prime}(x^{\epsilon})\Big{)}\leq 3(\beta_{\mathsf{Off}}+1)\cdot|\mathcal{X}| \log T.\]

### Proofs from Appendix D

**Theorem D.1** (Reduction from oracle-efficient online estimation to delayed online learning).: _Let \(\mathsf{D}\) be any convex, metric-like loss. Suppose we run Algorithm 2 with delay parameter \(N\in\mathbb{N}\) and a delayed online learning algorithm \(\mathcal{A}_{\mathsf{OOL}}\) for the class \(\mathcal{F}\). Then for all \(\gamma\geq 1\), Algorithm 2 ensures that_

\[\mathbb{E}\bigl{[}\mathbf{Est}_{\mathsf{D}}^{\mathsf{On}}(T) \bigr{]}\leq O(C_{\mathsf{D}}\gamma(N+\beta_{\mathsf{Off}}T/N)+R_{\mathsf{OOL }}(T,N,\gamma)),\] (14)

_with any offline oracle \(\mathbf{Alg}_{\mathsf{Off}}\) with parameter \(\beta_{\mathsf{Off}}\geq 0\), where_

\[R_{\mathsf{OOL}}(T,N,\gamma):=\,\sum_{t=1}^{T}\mathbb{E}_{f^{ \star}\sim\mu^{t}}\bigl{[}\ell^{t}(\bar{f}^{\prime})\bigr{]}-\gamma\cdot\min_ {f\in\mathcal{F}}\sum_{t=1}^{T}\ell^{t}(f)\] (15)

_is the regret of \(\mathcal{A}_{\mathsf{OOL}}\) for the sequence of losses constructed in Algorithm 2._

Proof of Theorem D.1.: Using the metric-like loss property, we can bound the online estimation error of Algorithm 2 by

\[\sum_{t=1}^{T}\mathbb{E}_{f\sim\mu^{t}}\bigl{[}\mathsf{D}\big{(} \bar{f}(x^{\epsilon}),f^{\star}(x^{\epsilon})\big{)}\bigr{]}\] \[\leq C_{\mathsf{D}}\cdot\sum_{t=1}^{T}\mathbb{E}_{\bar{f}\sim\mu^ {t}}\Bigl{[}\mathsf{D}\Big{(}\bar{f}(x^{\epsilon}),\tilde{f}^{\prime}(x^{ \epsilon})\Big{)}\Bigr{]}+C_{\mathsf{D}}\cdot\sum_{t=1}^{T}\mathsf{D}\Big{(} \tilde{f}^{\prime}(x^{\epsilon}),f^{\star}(x^{\epsilon})\Big{)}.\]

By the regret guarantee for the delayed online learning algorithm \(\mathcal{A}_{\mathsf{OOL}}\), we have

\[\sum_{t=1}^{T}\mathbb{E}_{\bar{f}\sim\mu^{t}}\Bigl{[}\mathsf{D} \Big{(}\bar{f}(x^{\epsilon}),\tilde{f}^{\prime}(x^{\epsilon})\Big{)}\Bigr{]} \leq\gamma\cdot\sum_{t=1}^{T}\mathsf{D}\Big{(}\tilde{f}^{\prime}(x^{ \epsilon}),f^{\star}(x^{\epsilon})\Big{)}+R_{\mathsf{OOL}}(T,N,\gamma)\]since \(f^{\star}\in\mathcal{F}\). Combining these observations, we have that

\[\sum_{t=1}^{T}\mathbb{E}_{\tilde{f}\sim\mu^{\iota}}\big{[}\mathsf{D} \big{(}\bar{f}(x^{\iota}),f^{\star}(x^{\iota})\big{)}\big{]}\leq C_{\mathsf{D} }(\gamma+1)\sum_{t=1}^{T}\mathsf{D}\Big{(}\bar{f}^{\iota}(x^{\iota}),f^{\star}( x^{\iota})\Big{)}+R_{\mathsf{ODL}}(T,N,\gamma).\]

Finally, from the definition of \(\tilde{f}^{\iota}\) and the convexity of the loss \(\mathsf{D}\), we have

\[\sum_{t=1}^{T}\mathsf{D}\Big{(}\bar{f}^{\iota}(x^{\iota}),f^{ \star}(x^{\iota})\Big{)} \leq N+\frac{1}{N}\sum_{t=1}^{T-N}\sum_{i=t+1}^{t+N}\mathsf{D} \Big{(}\widehat{f}^{\iota}(x^{\iota}),f^{\star}(x^{\iota})\Big{)}\] \[=N+\frac{1}{N}\sum_{t=2}^{T}\sum_{i<t}\mathsf{D}\Big{(}\widehat{f }^{\iota}(x^{\iota}),f^{\star}(x^{\iota})\Big{)}\] \[\leq N+\frac{\beta_{\mathsf{Off}}T}{N},\]

where the final line uses the offline estimation guarantee for \(\mathbf{Alg}_{\mathsf{Off}}\). This completes the proof.

**Lemma D.1**.: _Consider the delayed online learning setting with a delay parameter \(N\). There exists an algorithm that achieves_

\[R_{\mathsf{ODL}}(T,N,2)=\sum_{t=1}^{T}\mathbb{E}_{\tilde{f}_{t}\sim\mu^{\iota} }\big{[}\ell^{\iota}(\bar{f}^{\iota})\big{]}-2\cdot\min_{f\in\mathcal{F}}\sum_ {t=1}^{T}\ell^{\iota}(f)\leq 2N\cdot\log|\mathcal{F}|\]

_for any sequences of losses \(\ell^{\iota},\ldots,\ell^{\tau}\in[0,1]\)._

**Proof of Lemma D.1.** This result follows using Lemma G.3 with \(\gamma=2\), choosing \(\mathcal{A}_{\mathsf{OL}}\) to be the exponential weights algorithm described in Corollary 2.3 of Cesa-Bianchi and Lugosi [17], which has

\[R_{\mathsf{OL}}(T,\gamma)\leq O(\log|\mathcal{F}|)\]

for all \(T\in\mathbb{N}\) and \(\gamma\geq 1\).

**Theorem D.2** (Characterization of oracle-efficient learnability for binary classification).: _Consider a binary classification instance \((\mathcal{X},\mathcal{Y},\mathcal{Z},\mathcal{K},\mathcal{F})\) with \(\mathcal{Z}=\mathcal{Y}=\{0,1\}\), \(\mathsf{D}=\mathsf{D}_{0/1}\) and \(\mathcal{K}(z)=\mathbb{1}_{z}\). For any class \(\mathcal{F}\) and \(\beta_{\mathsf{Off}}\geq 0\), there exists an oracle-efficient algorithm that achieves online estimation error \(O(\sqrt{\beta_{\mathsf{Off}}\mathrm{Ldim}(\mathcal{F})}\cdot T\log T+ \mathrm{Ldim}(\mathcal{F})\log T)\). On the other hand, in the worst-case any algorithm must suffer at least \(\Omega(\mathrm{Ldim}(\mathcal{F}))\) online estimation error._

**Proof of Theorem D.2.** For the lower bound we recall that for \(\beta_{\mathsf{Off}}=0\), Lemma 21.6 of [57] states that any algorithm (oracle-efficient or not) has to suffer \(\Omega(\mathrm{Ldim}(\mathcal{F}))\) online estimation error in the worst case.

For the remainder of the proof, we focus on establishing the upper bound. For any set of parameters \(\mathcal{F}:\mathcal{X}\to\Delta(\{0,1\})\), define the majority vote function \(\mathrm{Majority}(\mathcal{F})\) for a class \(\mathcal{F}\) via

\[\mathrm{Majority}(\mathcal{F})(x)=\mathbb{1}\Bigg{\{}\sum_{f\in\mathcal{F}}f( 1\mid x)\geq\sum_{f\in\mathcal{F}}f(0\mid x)\Bigg{\}}\]

for all \(x\in\mathcal{X}\). We will show that Algorithm 4 (a variant of Algorithm 2 that replaces averaging with a majority vote), with a properly chosen delayed online learning algorithm \(\mathcal{A}_{\mathsf{ODL}}\), can obtain

\[O\Big{(}\sqrt{\beta_{\mathsf{Off}}\mathrm{Ldim}(\mathcal{F})\cdot T\log T}+ \mathrm{Ldim}(\mathcal{F})\log T\Big{)}\]

online estimation error.

Let \(\gamma\geq 1\) be fixed, and consider any delayed online learning algorithm \(\mathcal{A}_{\mathsf{OOL}}\) that achieves

\[\sum_{t=1}^{T}\mathbb{E}_{\tilde{f}^{t}\sim\mu^{t}}\big{[}\ell^{t}(\tilde{f}^{t}) \big{]}-\gamma\cdot\min_{f\in\mathcal{F}}\sum_{t=1}^{T}\ell^{t}(f)\leq R_{ \mathsf{OOL}}(T,N,\gamma).\]

for any sequence of losses in the delayed online learning setting with delay \(N\) (i.e., where we receive loss \(\ell^{i}\) at time \(t+N\) for some \(N\geq 0\)).

We proceed to bound the regret of Algorithm 4. Since the loss \(\mathsf{D}_{0/1}\) is metric-like, the online estimation error is upper bounded by

\[\sum_{t=1}^{T}\mathbb{E}_{\tilde{f}\sim\mu^{t}}\big{[}\mathsf{D}_{0/1}\big{(} \bar{f}(x^{t}),f^{\star}(x^{t})\big{)}\big{]}\leq\sum_{t=1}^{T}\mathbb{E}_{ \tilde{f}\sim\mu^{t}}\Big{[}\mathsf{D}_{0/1}\Big{(}\bar{f}(x^{t}),\tilde{f}^{t }(x^{t})\Big{)}\Big{]}+\sum_{t=1}^{T}\mathsf{D}_{0/1}\Big{(}\bar{f}^{i}(x^{t} ),f^{\star}(x^{t})\Big{)}.\]

Next, the guarantee of \(\mathcal{A}_{\mathsf{OOL}}\) ensures that

\[\sum_{t=1}^{T}\mathbb{E}_{\tilde{f}\sim\mu^{t}}\big{[}\mathsf{D}_{0/1}\Big{(} \bar{f}(x^{t}),\tilde{f}^{i}(x^{t})\Big{)}\Big{]}\leq\gamma\sum_{t=1}^{T} \mathsf{D}_{0/1}\Big{(}\tilde{f}^{i}(x^{t}),f^{\star}(x^{t})\Big{)}+R_{\mathsf{ OOL}}(T,N,\gamma),\]

since \(f^{\star}\in\mathcal{F}\). Combining these observations, we have that

\[\sum_{t=1}^{T}\mathbb{E}_{\tilde{f}\sim\mu^{t}}\big{[}\mathsf{D}_{0/1}\big{(} \bar{f}(x^{t}),f^{\star}(x^{t})\big{)}\big{]}\leq(\gamma+1)\sum_{t=1}^{T} \mathsf{D}_{0/1}\Big{(}\tilde{f}^{i}(x^{t}),f^{\star}(x^{t})\Big{)}+R_{\mathsf{ OOL}}(T,N,\gamma).\]

Finally, we observe that for each step \(t\), if \(\mathsf{D}_{0/1}\Big{(}\tilde{f}^{i}(x^{t}),f^{\star}(x^{t})\Big{)}=1\), it means that least \(N/2\) of the predictors \(\widehat{f}^{i+1},\ldots,\widehat{f}^{i+N}\) must have predicted \(f^{\star}(x^{t})\) incorrectly. This implies that

\[\mathsf{D}_{0/1}\Big{(}\tilde{f}^{i}(x^{t}),f^{\star}(x^{t})\Big{)}\leq\frac {2}{N}\sum_{i=t+1}^{t+N}\mathsf{D}_{0/1}\Big{(}\widehat{f}^{i}(x^{t}),f^{\star }(x^{t})\Big{)}.\]

But since the offline estimation assumption states that

\[\sum_{i<t}\mathsf{D}_{0/1}\Big{(}\widehat{f}^{i}(x^{i}),f^{\star}(x^{i})\Big{)} \leq\beta_{\mathsf{Off}},\]

this implies that

\[\sum_{t=1}^{T}\mathsf{D}_{0/1}\Big{(}\tilde{f}^{i}(x^{t}),f^{ \star}(x^{t})\Big{)} \leq N+\frac{2}{N}\sum_{t=1}^{T-N}\sum_{i=t+1}^{t+N}\mathsf{D}_{0/ 1}\Big{(}\widehat{f}^{i}(x^{t}),f^{\star}(x^{t})\Big{)}\] \[=N+\frac{2}{N}\sum_{t=2}^{T}\sum_{i<t}\mathsf{D}_{0/1}\Big{(} \widehat{f}^{i}(x^{i}),f^{\star}(x^{t})\Big{)}\] \[\leq N+\frac{2\beta_{\mathsf{Off}}T}{N}.\]We conclude that

\[\sum_{t=1}^{T}\mathbb{E}_{\bar{f}^{t}\sim\mu^{t}}\big{[}\mathsf{D}_{0/1}\big{(} \bar{f}^{i}(x^{i}),f^{\star}(x^{i})\big{)}\big{]}\leq O(\gamma(N+\beta_{\mathsf{ O}\#}T/N)+R_{\mathsf{DOL}}(T,N,\gamma)).\]

To complete the proof, we set \(\gamma=2\) and choose \(\mathcal{A}_{\mathsf{OL}}\) to be the algorithm described in Theorem 21.10 of Shalev-Shwartz and Ben-David [57], which (by incorporating the same technique18 as Corollary 2.3 of Cesa-Bianchi and Lugosi [17]), ensures that

Footnote 18: The algorithm described in Theorem 21.10 of Shalev-Shwartz and Ben-David [57] applies the exponential weights algorithm to a specialized class of experts, and the guarantee obtained is for \(R_{\mathsf{OL}}(T,1)\). The analysis from Corollary 2.3 of Cesa-Bianchi and Lugosi [17] shows that for \(\gamma>e/(e-1)\), the same algorithm obtains \(R_{\mathsf{OL}}(T,2)\) scaling with \(O(\operatorname{Ldim}(\mathcal{F})\log T)\). We omit the details here since it is a standard argument.

\[R_{\mathsf{OL}}(T/N,2)\leq O(\operatorname{Ldim}(\mathcal{F})\log T).\]

Then by Lemma G.3 with \(\gamma=2\), we have

\[R_{\mathsf{DOL}}(T,N,2)\leq O(N\cdot\operatorname{Ldim}(\mathcal{F})\log T).\]

Setting \(N=\sqrt{\beta_{\mathsf{O}\#}T/(\operatorname{Ldim}(\mathcal{F})\log T)}\lor 1\), this yields

\[\sum_{t=1}^{T}\mathbb{E}_{\bar{f}^{t}\sim\mu^{t}}\big{[}\mathsf{D}\big{(}\bar {f}^{i}(x^{i}),f^{\star}(x^{i})\big{)}\big{]}\leq O\Big{(}\sqrt{\beta_{\mathsf{ O}\#}\operatorname{Ldim}(\mathcal{F})\cdot T\log T}+\operatorname{Ldim}( \mathcal{F})\log T\Big{)}.\]

#### g.3.1 Supporting Lemmas

```
1:input: Delay parameter \(N\in\mathbb{N}\), base online learning algorithm \(\mathcal{A}_{\mathsf{OL}}\).
2: Initialize \(N\) copies \(\mathcal{A}_{\mathsf{OL}}^{1},\dots,\mathcal{A}_{\mathsf{OL}}^{N}\) of the base algorithm.
3:for\(t=1,\dots,T\)do
4:if\(t\leq N\)then
5: Let \(\mu^{i}=\mathcal{A}_{\mathsf{OL}}^{t}(\varnothing)\).
6:else
7: Let \(i\equiv t\mod N\) where \(i\in[N]\).
8: Receive loss \(\ell^{t-N}\).
9: Feed \(\ell^{t-N}\) to \(\mathcal{A}_{\mathsf{OL}}^{i}\).
10: Let \(\mu^{i}=\mathcal{A}_{\mathsf{OL}}^{i}(\ell^{\ell},\ell^{t+N},\dots,\ell^{t-N})\).
11: Play \(\bar{f}^{i}\sim\mu^{i}\). ```

**Algorithm 5** Reduction from delayed online learning to non-delayed online learning

The following lemma is a standard result [67, 42, 35, 47] which shows that the delayed online learning problem setting in Appendix D can be generically reduced to non-delayed online learning. The idea behind the reduction, which is displayed in Algorithm 5, is as follows. Given a delay parameter \(N\in\mathbb{N}\), we run \(N\) copies \(\mathcal{A}_{\mathsf{OL}}^{1},\dots,\mathcal{A}_{\mathsf{OL}}^{N}\) of a given "base" online learning algorithm \(\mathcal{A}_{\mathsf{OL}}\) for a class \(\mathcal{F}\) over disjoint subsequences of rounds. The following lemma gives a guarantee for this reduction

**Lemma G.3** (Delayed online learning reduction).: _Let \(\mathcal{A}_{\mathsf{OL}}\) be a base online learning algorithm for the class \(\mathcal{F}\) with the property that for any sequence of losses \(\ell^{1},\dots,\ell^{T}\) in the non-delayed online learning setting and any \(\gamma\geq 1\),_

\[\sum_{t=1}^{T}\mathbb{E}_{\bar{f}^{t}\sim\mu^{t}}\big{[}\ell^{t}(\bar{f}^{i}) \big{]}-\gamma\cdot\min_{f\in\mathcal{F}}\sum_{t=1}^{T}\ell^{i}(f)\leq R_{ \mathsf{OL}}(T,\gamma).\]

_If we run Algorithm 5 with delay parameter \(N\in\mathbb{N}\), then for all \(\gamma\geq 1\), the algorithm ensures that_

\[R_{\mathsf{DOL}}(T,N,\gamma) \leq\sum_{i=1}^{N}\left(\sum_{j=1}^{T/N}\mathbb{E}_{\bar{f}^{i+N \cdot j}\sim\mu^{i+N\cdot j}}\big{[}\ell^{i+N\cdot j}(\bar{f}^{i+N\cdot j}) \big{]}-\gamma\cdot\min_{f\in\mathcal{F}}\sum_{j=1}^{T/N}\ell^{i+N\cdot j}(f)\right)\] \[\leq N\cdot R_{\mathsf{OL}}(T/N,\gamma)\]

_for online learning with delay \(N\)._Proof of Lemma 6.3.: By the guarantee of \(\mathcal{A}_{\mathsf{OL}}\), we have that for all \(i\in[N]\),

\[\sum_{j=1}^{T/N}\mathbb{E}_{\bar{f}^{i+N\cdot j}\sim\mu^{i+N\cdot j}}\left[\ell^{ i+N\cdot j}(\bar{f}^{i+N\cdot j})\right]-\gamma\cdot\min_{f\in\mathcal{F}}\sum_{j=1}^ {T/N}\ell^{i+N\cdot j}(f)\leq R_{\mathsf{OL}}(T/N,\gamma).\]

Summing up over all \(i\in[N]\), we obtain

\[N\cdot R_{\mathsf{OL}}(T/N,\gamma) =\sum_{i=1}^{N}\sum_{j=1}^{T/N}\mathbb{E}_{\bar{f}^{i+N\cdot j} \sim\mu^{i+N\cdot j}}\left[\ell^{i+N\cdot j}(\bar{f}^{i+N\cdot j})\right]- \gamma\cdot\sum_{i=1}^{N}\min_{f\in\mathcal{F}}\sum_{j=1}^{T/N}\ell^{i+N\cdot j} (f)\] \[\geq\sum_{i=1}^{N}\sum_{j=1}^{T/N}\mathbb{E}_{\bar{f}^{i+N\cdot j} \sim\mu^{i+N\cdot j}}\left[\ell^{i+N\cdot j}(\bar{f}^{i+N\cdot j})\right]- \gamma\cdot\min_{f\in\mathcal{F}}\sum_{i=1}^{N}\sum_{j=1}^{T/N}\ell^{i+N\cdot j} (f)\] \[=\sum_{t=1}^{T}\mathbb{E}_{\bar{f}^{t}\sim\mu^{t}}\left[\ell^{t}( \bar{f}^{i})\right]-\gamma\cdot\min_{f\in\mathcal{F}}\sum_{t=1}^{T}\ell^{t}(f).\]

## Appendix H Proofs from Section 4

### Proofs from Section 4.1

**Theorem 4.1** (Computational lower bound for OEOE).: _Assume the existence of one-way functions.19 There exists a sequence of polynomially computable classes \((\mathcal{F}_{1},\mathcal{F}_{2},\dots,\mathcal{F}_{n},\dots)\), along with a sequence of \(\mathrm{poly}(n)\)-output description length offline oracles with \(\beta_{\mathsf{Off}}=0\) associated with each \(\mathcal{F}_{n}\), such that for any fixed polynomials \(p,q:\mathbb{N}\to\mathbb{N}\) and all \(n\in\mathbb{N}\) sufficiently large, any oracle-efficient online estimation algorithm with runtime bounded by \(p(n)\) must have \(\mathbb{E}[\mathbf{Est}_{\mathsf{D}}^{\mathsf{On}}(T)]\geq T/4\) for all \(1\leq T\leq q(n)\). At the same time, there exists an inefficient algorithm that achieves \(\mathbb{E}[\mathbf{Est}_{\mathsf{D}}^{\mathsf{On}}(T)]\leq O(\sqrt{n})\) for all \(T\in\mathbb{N}\)._

Footnote 19: Existence of one-way functions is a standard and widely believed complexity-theoretic assumptions, which forms the basis of modern cryptography [30].

Proof of Theorem 4.1.: We frame the example proposed by Blum [14] in their Theorem 3.2 (see also Bun [15]) in our setting. For any integer \(n\geq 1\), let the covariate space \(\mathcal{X}_{n}\) be \(\mathcal{X}_{n}=\left\{0,1\right\}^{n}\), and set \(\mathcal{Z}=\mathcal{Y}=\left\{0,1\right\}\) and \(\mathcal{K}(z)=\mathbb{1}_{z}\). We define a class \(\mathcal{F}_{n}=\left\{f_{s}:s\in\left\{0,1\right\}^{\sqrt{n}}\right\}\) with

\[f_{s}(x):=\begin{cases}1&\text{if }x\in c_{s},\\ 0&\text{otherwise},\end{cases}\]

for a certain collection of subsets \(\left\{c_{s}\in\mathcal{X}_{n}\right\}_{s\in\left\{0,1\right\}^{\sqrt{n}}}\) defined in Definition 2 of Blum [14], which is constructed based on cryptographic functions using the assumption of existence of one-way functions. The precise definition will not be important. The properties we will use are:

1. The value \(f_{s}(x)\) can be computed in \(\mathrm{poly}(n)\) time for any \(x\in\mathcal{X}_{n}\).
2. For any polynomials \(p(n),q(n)\), any (possibly randomized) online estimation algorithm (oracle-efficient or not) which runs in time \(p(n)\), and any time step \(T\leq q(n)\), for sufficiently large \(n\) where \(q(n)\ll 2^{\sqrt{n}}\),20 there exists \(s\in\left\{0,1\right\}^{\sqrt{n}}\) and a sequence \(x_{s}^{1},\dots,x_{s}^{2^{\sqrt{n}-1}},x_{s}^{2^{\sqrt{n}}}\) (the specific definition of this sequence can be found in Blum [14]) such that the online estimation error under this sequence when \(f^{\star}=f_{s}\) is at least \(T/4\) in expectation. Our lower bound construction for any oracle efficient online estimation algorithm with runtime bounded by \(p(n)\) in time step bounded by \(1\leq T\leq q(n)\) will choose the aforementioned covariate sequence as the covariates revealed with the aforementioned function as the true parameter, i.e., \(x^{r}=x_{s}^{r}\) for \(\tau\in[T]\) and \(f^{\star}=f_{s}\).

It is straightforward to see that the sequence \((\mathcal{F}_{1},\mathcal{F}_{2}...,\mathcal{F}_{n},...)\) admits polynomial description length as claimed, since \(\log|\mathcal{F}_{n}|=\sqrt{n}\). We are left to verify that there is an offline oracle that achieves \(\beta_{\mathsf{Off}}=0\) with \(\operatorname{poly}(n)\)-output description length, yet does not provide any information not already available to the learner in the setting of Blum [14] (recall that in the protocol of Blum [14], the learner gets to see the covariates \(x^{!}\),...,\(x^{!}\) and the true labels \(y^{!}\),...,\(y^{!-1}\) at time step \(t\) before making their prediction, but does not receive any other feedback).

Consider the following offlines oracle \(\mathbf{Alg}^{\prime}_{\mathsf{Off}}(x^{!},\ldots,x^{!-1},y^{!},\ldots,y^{!-1})\). The oracle output \(\widehat{f}^{\prime}\) is a circuit that, on input \(x\), compares \(x\) sequentially with \(x^{!},\ldots,x^{!}\). If \(x\) is ever equal to \(x^{?}\) for some \(\tau\in[t-1]\), the circuit will output \(y^{?}\). If \(x\) is not equal to any \(x^{?}\) for \(\tau\in[t-1]\), the circuit outputs \(0\). Such a Boolean circuit can be constructed with polynomial size in \(n\) because each \(x^{?}\) has length \(n\) for \(\tau\in[t-1]\) and \(t\leq T\leq q(n)\) by assumption. It is easy to see that this oracle achieves \(\beta_{\mathsf{Off}}=0\), yet does not provide any additional information about target parameter \(f^{\star}\) beyond what is available in the model of Blum [14]. Combining all the above, we complete our lower bound proof.

Lastly, we observe that since the setting we consider is an instance of noiseless binary classification, the classical halving algorithm achieves an online estimation error bound of \(O(\log|\mathcal{F}_{n}|)=O(\sqrt{n})\)[17].

### Proofs from Section 4.2

In this section, we prove Theorem 4.2 through four layers of reductions through different variants of the online estimation setting. In Appendix H.2.1, we first introduce the relevant settings and the describe reductions through them. We then combine these reductions to prove Theorem 4.2. Finally, in Appendix H.2.2, we prove each of the four reduction results.

#### h.2.1 Proof of Theorem 4.2

**Theorem 4.2**.: _Let \(\mathcal{A}_{\mathsf{CDE}}\) be an arbitrary (unrestricted) online estimation algorithm that satisfies Eq. (4) and has runtime \(\mathsf{Time}(\mathcal{F},T)\). Then for any \(N\in\mathbb{N}\), there exists an oracle-efficient online estimation algorithm that achieves estimation error_

\[\mathbb{E}\big{[}\mathbf{Est}^{\mathsf{On}}_{\mathsf{H}}(T)\big{]}\leq \widetilde{O}(C_{\mathcal{F}}\log V\cdot\beta_{\mathsf{Off}}T/N+N\cdot(R_{ \mathsf{CDE}}(T)+C_{\mathcal{F}}\log V))\]

_with runtime \(\operatorname{poly}(\mathsf{Time}(\mathcal{F},T),\log|\mathcal{F}|,\log| \mathcal{X}|,T)\), where \(\beta_{\mathsf{Off}}\geq 0\) is the offline estimation parameter. The distributions \(\mu^{1},\ldots,\mu^{r}\) produced by the algorithm have support size \(\operatorname{poly}(\log|\mathcal{F}|,\log|\mathcal{X}|,T)\). As a special case, if the online estimation guarantee for the base algorithm holds with \(R_{\mathsf{CDE}}(T)\leq C_{\mathcal{F}}^{\prime}\log T\) for some problem-dependent constant \(C_{\mathcal{F}}^{\prime}\geq 1\), then by choosing \(N\) appropriately, we achieve \(\mathbb{E}\big{[}\mathbf{Est}^{\mathsf{On}}_{\mathsf{H}}(T)\big{]}\leq \widetilde{O}\big{(}(C_{\mathcal{F}}(C_{\mathcal{F}}+C_{\mathcal{F}}^{\prime })\beta_{\mathsf{Off}})^{1/2}\log V\cdot T^{1/2}+(C_{\mathcal{F}}+C_{\mathcal{F }}^{\prime})\log V\big{)}\)._

Proof of Theorem 4.2.: The proof of Theorem 4.2 is algorithmic, and is based on several layers of reductions.

* First, using the scheme in Appendix D, we reduce the problem of oracle-efficient online estimation to delayed online learning with the loss function \(\ell^{t-N}(f)=\mathsf{D}\big{(}\tilde{f}^{t-N}(x^{t-N}),f(x^{t-N})\big{)}\) defined in Algorithm 2, where \(\tilde{f}^{t-N}=\frac{1}{N}\sum_{i=t-N+1}^{t}\widehat{f}^{i}\) is an average of offline estimators and \(N\in\mathbb{N}\) is a delay parameter.
* Then, using a standard reduction [67; 42; 35; 47], we reduce the delayed online learning problem above to a sequence of \(N\) non-delayed online learning problems, with the same sequence of loss functions; both this and the preceding step are computationally efficient.
* To complete the reduction, we argue that the base algorithm can be used to solve the online learning problem above in an oracle-efficient fashion. To do this, we simulate interaction with the environment by sampling fictitious outcomes \(y^{t}\sim\tilde{f}^{i}(x^{t})\) from the averaged offline estimators and passing them into the base algorithm. We argue that the fictitious outcomes approximate the true outcomes well through a change-of-measure argument.

Combining the above, we conclude that given any base algorithm that efficiently performs online estimation with outcomes sampled from the target parameter \(f^{\star}\), we can efficiently construct a computationally efficient and oracle-efficient algorithm. In more detail, we introduce four layers of reduction in reverse order from CDE to OEOE.

Conditional Density Estimation with Reference Outcomes (CDEwRO).The bottom-most reduction we consider is from a setting we refer to as _Conditional Density Estimation with Reference Outcomes (CDEwRO)_ to the (realizable) CDE setting. CDEwRO is similar to CDE, but with the following difference. Instead of receiving outcomes \(y^{1},\ldots,y^{r}\) sampled from the true model \(f^{\star}(x^{t})\) directly, in CDEwRO, the outcome is sampled from a _reference parameter_\(\tilde{f}^{\prime}(x^{t})\) which is guaranteed to be close to \(f^{\star}\) in a certain sense. Moreover, the covariates and the reference parameters \(\tilde{f}^{1},\ldots,\tilde{f}^{r}\) are selected obliviously (i.e. the entire sequence is chosen by the adversary before the online learning protocol begins).

```
1:input: Time \(T\in\mathbb{N}\), base algorithm \(\mathcal{A}_{\text{CDE}}\).
2:Nature selects \(T\) covariates \(x^{1},\ldots,x^{T}\) along with the reference parameters \(\tilde{f}^{1},\ldots,\tilde{f}^{r}\).
3:for\(t=1,\ldots,T\)do
4:Learner predicts \(\tilde{f}^{i}\sim\mu^{i}=\mathcal{A}_{\text{CDE}}(x^{1},\ldots,x^{i\sim i},y^ {1},\ldots,y^{i\sim i})\).
5: Outcome \(y^{i}\sim\tilde{f}^{i}(x^{i})\) is sampled and revealed to the learner with the covariate \(x^{i}\). ```

**Algorithm 6** Reduction from CDEwRO to CDE

Our reduction from CDEwRO to CDE is given in Algorithm 6. The main guarantee for this reduction is as follows.

**Lemma H.1**.: _For any fixed \(\zeta\geq 0\), suppose \(\sum\limits_{t=1}^{T}\mathsf{D}_{\mathsf{H}}^{2}\Big{(}\tilde{f}^{i}(x^{t}),f^ {\star}(x^{t})\Big{)}\leq\zeta\). Let_

\[R_{\text{CDEwRO}}(T,\zeta):=3C_{\mathcal{F}}\log V\cdot\zeta+R_{\text{CDE}}(T)+ 2C_{\mathcal{F}}\cdot\log(C_{\mathcal{F}}T),\] (25)

_where \(R_{\text{CDE}}(T)\) is defined as in Eq. (4) by the assumption on \(\mathcal{A}_{\text{CDE}}\). Then Algorithm 6 achieves an expected online estimation error upper bound of_

\[\sum\limits_{t=1}^{T}\mathbb{E}\big{[}\mathsf{D}_{\mathsf{H}}^{2}\Big{(} \tilde{f}^{i}(x^{t}),f^{\star}(x^{t})\big{)}\big{]}\leq R_{\text{CDEwRO}}(T,\zeta)\]

_in the CDEwRO setting, and has runtime \(\operatorname{poly}(\mathsf{Time}(\mathcal{F},T),T)\)._

The key technique in the proof of this lemma is a change of measure argument based on Donsker-Varadhan [46].

Conditional Density Estimation with Reference Parameters (CDEwRP).The next reduction in our stack is from a setting we refer to as _Conditional Density Estimation with Reference Parameters (CDEwRP)_ to the CDEwRO setting above. CDEwRP is identical to CDEwRO, except that in the former setting, the learner directly observes the reference parameter \(\tilde{f}^{i}\) instead of observing \(y^{t}\sim\tilde{f}^{i}(x^{t})\) as in CDEwRO.

A second difference is that we allow the adversary in the CDEwRP setting to be adaptive, while our definition of the CDEwRO setting only allows for oblivious adversaries. Thus, the reduction we consider serves two purposes:

* Simulating the CDEwRO feedback model through sampling.
* Reducing the adaptive adversary to an oblivious one.

The reduction from adaptive adversaries to oblivious follows and improves upon the result from [31], and may be of independent interest.

Our reduction from CDEwRP to CDEwRO is displayed in Algorithm 6, and takes as input an algorithm \(\mathcal{A}_{\text{CDEwRO}}(\cdot;\cdot)\) for the CDEwRO setting, where \(\mathcal{A}_{\text{CDEwRO}}^{\text{}}(T;\cdot)\) denotes the algorithm's output at round \(t\leq T\) as a function of the history. The main guarantee for the algorithm is as follows.

**Lemma H.2**.: _For any fixed \(\zeta\geq 0\), suppose \(\sum\limits_{t=1}^{T}\mathsf{D}_{\mathsf{H}}^{2}\Big{(}\tilde{f}^{i}(x^{t}),f^{\star}(x^{t})\Big{)}\leq\zeta\). Let_

\[R_{\text{CDEwRP}}(T,\zeta,\varepsilon):=2R_{\text{CDEwRO}}(T,\zeta)+\varepsilon,\] (26)_where \(R_{\mathsf{CDEwRPO}}(T,\zeta)\) is defined as in Eq. (25). Then Algorithm 7 with parameter \(\varepsilon>0\) achieves an expected online estimation error upper bound of_

\[\sum\limits_{t=1}^{T}\mathbb{E}\big{[}\mathsf{D}_{\mathsf{H}}^{2}\big{(}\bar{f}^ {i}(x^{\iota}),f^{\star}(x^{\iota})\big{)}\big{]}\leq R_{\mathsf{CDEwRP}}(T, \zeta,\varepsilon)\]

_in the CDEwRP setting, and runs in time \(\mathrm{poly}(\mathsf{Time}(\mathcal{F},T),T,\log|\mathcal{F}|,\log|\mathcal{ X}|,1/\varepsilon)\). The distributions \(\mu^{1},\ldots,\mu^{T}\) produced by the algorithm have support size \(\mathrm{poly}\big{(}\log|\mathcal{F}|,\log|\mathcal{X}|,T,1/\varepsilon)\)._

**Conditional Density Estimation with Delayed Reference Parameters (CDEwDRP).** Our next reduction is from a setting we refer to as _Conditional Density Estimation with Delayed Reference Parameters (CDEwDRP)_ to the CDEwRP setting. CDEwDRP is identical to CDEwRP, except that the reference function \(\bar{f}^{i}\) is revealed only at round \(t+N\) instead of at round \(t\), for a delay parameter \(N\in\mathbb{N}\).

```
1:input: Time \(T\in\mathbb{N}\), delay time \(N\in\mathbb{N}\), algorithm \(\mathcal{A}_{\mathsf{CDEwRP}}\).
2: Initialize \(N\) copies of the algorithm \(\mathcal{A}_{\mathsf{CDEwRP}}\) as \(\mathcal{A}_{\mathsf{CDEwRP}}^{\star},\ldots,\mathcal{A}_{\mathsf{CDEwRP}}^{N}\).
3:for\(t=1,\ldots,T\)do
4: Learner predicts \(\bar{f}^{i}\sim\mu^{\iota}=\mathcal{A}_{\mathsf{CDEwRP}}^{i}(T/N,1/N;x^{i},x ^{i+N},\ldots,x^{\iota-N},\bar{f}^{i},\bar{f}^{i+N},\ldots,\bar{f}^{i-N})\) where \(i\equiv t\mod N\).
5: Nature selects and reveals the covariate \(x^{\iota}\) and the reference parameter \(\bar{f}^{i-N}\) based on \(\mu^{\iota}\). ```

**Algorithm 8** Reduction from CDEwDRP to CDEwRP

Our reduction from CDEwDRP to CDEwRP is displayed in Algorithm 7, and takes as input an algorithm \(\mathcal{A}_{\mathsf{CDEwRP}}(\cdot;\cdot)\) for the CDEwRP setting, where \(\mathcal{A}_{\mathsf{CDEwRP}}^{\star}(T,\varepsilon;\cdot)\) denotes the algorithm's output at round \(t\leq T\) with accuracy parameter \(\varepsilon>0\) (cf. Algorithm 7), as a function of the history. The main guarantee for the algorithm is as follows.

**Lemma H.3**.: _For any fixed \(\zeta\geq 0\), suppose \(\sum\limits_{t=1}^{T}\mathsf{D}_{\mathsf{H}}^{2}\Big{(}\bar{f}^{i}(x^{\iota}),f^{\star}(x^{\iota})\Big{)}\leq\zeta\). Let_

\[R_{\mathsf{CDEwDRP}}(T,N,\zeta):=\sup\limits_{\zeta_{1},\ldots,\zeta_{N}\geq 0,\sum\limits_{i=1}^{N}\zeta_{i}\leq\zeta}\sum\limits_{i=1}^{N}R_{\mathsf{CDEwRP }}(T/N,\zeta_{i},1/N),\] (27)

_where \(R_{\mathsf{CDEwRP}}(T/N,\zeta_{i},1/N)\) is defined as in Eq. (26). Then Algorithm 8 achieves an expected online estimation error upper bound of_

\[\sum\limits_{t=1}^{T}\mathbb{E}\big{[}\mathsf{D}_{\mathsf{H}}^{2}\big{(}\bar{ f}^{i}(x^{\iota}),f^{\star}(x^{\iota})\big{)}\big{]}\leq R_{\mathsf{CDEwDRP}}(T,N,\zeta)\]

_in the CDEwDRP setting, and has runtime \(\mathrm{poly}(\mathsf{Time}(\mathcal{F},T),T,\log|\mathcal{F}|,\log|\mathcal{ X}|)\). The distributions \(\mu^{1},\ldots,\mu^{T}\) produced by the algorithm have support size \(\mathrm{poly}\big{(}\log|\mathcal{F}|,\log|\mathcal{X}|,T)\)._```
1:input: Time \(T\in\mathbb{N}\), offline estimation oracle \(\mathbf{Alg}_{\mathsf{Off}}\) with parameter \(\beta_{\mathsf{Off}}\geq 0\), delay parameter \(N\in\mathbb{N}\), CDEwDRP algorithm \(\mathcal{A}_{\mathsf{ODEwDRP}}\).
2:for\(t=1,\ldots,T\)do
3: Receive \(\widehat{f}^{i}=\mathbf{Alg}^{i}_{\mathsf{Off}}(x^{1},\ldots,x^{t-1},y^{1}, \ldots,y^{t-1})\).
4: Learner computes reference parameter \(\tilde{f}^{i-N}=\frac{1}{N}\sum\limits_{i=t-N+1}^{t}\widehat{f}^{i}\).
5: Learner predicts \(\tilde{f}^{i}\sim\mu^{i}=\mathcal{A}_{\mathsf{ODEwDRP}}(T,N;x^{1},x^{2}, \ldots,x^{t},\tilde{f}^{1},\tilde{f}^{2},\ldots,\tilde{f}^{t-N})\).
6: Nature selects and reveals the covariate \(x^{\prime}\) based on \(\mu^{\prime}\). ```

**Algorithm 9** Reduction from OEOE to CDEwDRP

Oracle-Efficient Online Estimation (OEOE).Our final reduction reduces the Oracle-Efficient Online Estimation setting (OEOE) to the CDEwDRP setting described above. This reduction, which is displayed in Algorithm 8, is a variant of the approach used in Theorem D.1. The reduction takes as input a CDEwDRP algorithm \(\mathcal{A}_{\mathsf{ODEwDRP}}(\cdot;\cdot)\), where \(\mathcal{A}^{i}_{\mathsf{ODEwDRP}}(T,N;\cdot)\) denotes the algorithm's output at round \(t\leq T\) with delay parameter \(N\), as a function of the history.

**Lemma H.4**.: _Algorithm 9 achieves an expected online estimation error upper bound of_

\[\sum\limits_{t=1}^{T}\mathbb{E}\big{[}\mathsf{D}^{2}_{\mathsf{H}} \big{(}\bar{f}^{i}(x^{\prime}),f^{\star}(x^{\prime})\big{)}\big{]}\leq R_{ \mathsf{CDEwDRP}}(T,N,N+\beta_{\mathsf{Off}}T/N)\]

_in the OEOE setting, and has runtime \(\mathrm{poly}(\mathsf{Time}(\mathcal{F},T),T,\log|\mathcal{F}|,\log| \mathcal{X}|)\). The distributions \(\mu^{1},\ldots,\mu^{\tau}\) produced by the algorithm have support size \(\mathrm{poly}(\log|\mathcal{F}|,\log|\mathcal{X}|,T)\)._

Completing the proof of Theorem 4.2.To prove Theorem 4.2, we compose all of the preceding reductions, with \(N\) left as a free parameter temporarily. We first apply Lemma H.4 to reduce from the OEOE setting to the CDEwDRP setting, with the guarantee that

\[\sum\limits_{t=1}^{T}\mathbb{E}\big{[}\mathsf{D}^{2}_{\mathsf{H}} \big{(}\bar{f}^{i}(x^{\prime}),f^{\star}(x^{\prime})\big{)}\big{]}\leq R_{ \mathsf{CDEwDRP}}(T,N,N+\beta_{\mathsf{Off}}T/N).\]

Then by Lemma H.3, we can reduce the CDEwDRP setting to the CDEwRP setting, with the guarantee by Eq. (27) that

\[R_{\mathsf{CDEwDRP}}(T,N,N+\beta_{\mathsf{Off}}T/N)=\sup\limits_{ \sum\limits_{i=1}^{N}\zeta_{i}\leq N+\beta_{\mathsf{Off}}T/N}\sum\limits_{i=1} ^{N}R_{\mathsf{CDEwRP}}(T/N,\zeta_{i},1/N).\]

Then apply Lemma H.2\(N\) times with \(T\), \(\zeta\), and \(\varepsilon\) in the Lemma chosen to be \(T/N\), \(\zeta_{i}\), and \(1/N\) respectively for each \(i\in[N]\), we can reduce the CDEwRP setting to the CDEwRO setting with guarantee by Eq. (26) that

\[\sup\limits_{\sum\limits_{i=1}^{N}\zeta_{i}\leq N+\beta_{\mathsf{Off}}T/N} \sum\limits_{i=1}^{N}R_{\mathsf{CDEwRP}}(T/N,\zeta_{i},1/N)=1+\sup\limits_{ \sum\limits_{i=1}^{N}\zeta_{i}\leq N+\beta_{\mathsf{Off}}T/N}2\sum\limits_{i= 1}^{N}R_{\mathsf{CDEwRO}}(T/N,\zeta_{i}).\]Consequently, apply Lemma H.1\(N\) times with \(T\) and \(\zeta\) in the Lemma chosen to be \(T/N\) and \(\zeta_{i}\) for each \(i\in[N]\), we can reduce the CDEwRO setting to the CDE setting with guarantee by Eq. (25) that

\[\sup_{\sum\limits_{i=1}^{N}\zeta_{i}\leq N+\beta_{\mathsf{Off}}T/N} \sum\limits_{i=1}^{N}R_{\mathsf{CDEwRO}}(T/N,\zeta_{i})\] \[\qquad\qquad\leq\sup_{\sum\limits_{i=1}^{N}\zeta_{i}\leq N+\beta_ {\mathsf{Off}}T/N}\sum\limits_{i=1}^{N}(3C_{\mathcal{F}}\log V\cdot\zeta_{i}+R_ {\mathsf{CDE}}(T)+2C_{\mathcal{F}}\cdot\log(C_{\mathcal{F}}T))\] \[\qquad\qquad\qquad\qquad\lesssim C_{\mathcal{F}}\log V\cdot \left(N+\frac{\beta_{\mathsf{Off}}T}{N}\right)+N\cdot(R_{\mathsf{CDE}}(T)+C_{ \mathcal{F}}\cdot\log(C_{\mathcal{F}}T))\] \[\qquad\qquad\qquad\qquad\qquad\qquad=C_{\mathcal{F}}\log V\cdot \frac{\beta_{\mathsf{Off}}T}{N}+N\cdot(R_{\mathsf{CDE}}(T)+C_{\mathcal{F}} \cdot\log(VC_{\mathcal{F}}T)).\] (28)

By choosing \(N=\sqrt{\frac{C_{\mathcal{F}}\beta_{\mathsf{Off}}T\cdot\log V}{R_{\mathsf{ CDE}}(T)+C_{\mathcal{F}}\cdot\log(VC_{\mathcal{F}}T)}}\lor 1\), we can bound the expression in (28) as

\[\mathbb{E}[\mathbf{Est_{H}}(T,\beta_{\mathsf{Off}})] \lesssim\sqrt{C_{\mathcal{F}}\beta_{\mathsf{Off}}T(R_{\mathsf{ CDE}}(T)+C_{\mathcal{F}}\cdot\log(VC_{\mathcal{F}}T))\log V}+R_{\mathsf{CDE}}(T)+C_{ \mathcal{F}}\cdot\log(VC_{\mathcal{F}}T)\] \[\leq\sqrt{C_{\mathcal{F}}\beta_{\mathsf{Off}}TR_{\mathsf{CDE}}(T )\log V}+C_{\mathcal{F}}\sqrt{\beta_{\mathsf{Off}}T\log(VC_{\mathcal{F}}T) \log V}\] \[\qquad\qquad\qquad+R_{\mathsf{CDE}}(T)+C_{\mathcal{F}}\cdot\log(VC _{\mathcal{F}}T).\]

Finally, under the assumption that \(R_{\mathsf{CDE}}(T)\leq C_{\mathcal{F}}^{\prime}\log T\), the bound above can be further simplified as

\[\mathbb{E}[\mathbf{Est_{H}}(T,\beta_{\mathsf{Off}})] \lesssim(C_{\mathcal{F}}(C_{\mathcal{F}}+C_{\mathcal{F}}^{\prime})\beta_{ \mathsf{Off}}\log V\log(VC_{\mathcal{F}}T))^{1/2}T^{1/2}+(C_{\mathcal{F}}+C_{ \mathcal{F}}^{\prime})\log(VC_{\mathcal{F}}T).\]

#### h.2.2 Proofs for supporting lemmas

**Proof of Lemma H.1.** For Algorithm 6, denote the randomness of the sequence \((y^{{}_{1:T}},\mu^{{}_{1:T}})\) under \(f^{\star}\in\mathcal{F}\) and \((\check{f}^{{}_{1:T}})\) by \(\mathbb{P}^{f^{\star}}\) and \(\mathbb{P}^{f^{{}_{1:T}}}\) respectively. The data generating process for \((x^{{}_{1:T}},y^{{}_{1:T}})\) in the CDEwRO setting implies that

\[\mathbb{E}_{\mathbb{P}^{f^{{}_{1:T}}}}\Bigg{[}\sum\limits_{t=1}^{T}\mathbb{E}_ {\check{f}^{{}_{t}}\sim\mu^{t}}\big{[}\mathsf{D}_{\mathsf{H}}^{2}\big{(} \check{f}^{{}_{t}}(x^{{}_{t}}),f^{\star}(x^{{}_{t}})\big{)}\big{]}\Bigg{]}= \mathbb{E}\Bigg{[}\sum\limits_{t=1}^{T}\mathbb{E}_{\check{f}^{{}_{t}}\sim\mu^{ t}}\big{[}\mathsf{D}_{\mathsf{H}}^{2}\big{(}\check{f}^{{}_{t}}(x^{{}_{t}}),f^{ \star}(x^{{}_{t}})\big{)}\big{]}\Bigg{]}.\]

By Donsker-Varadhan [46], we have that for all \(\eta>0\)

\[\frac{1}{\eta}\mathsf{D}_{\mathsf{KL}}\Big{(}\mathbb{P}^{\check{ f}^{{}_{1:T}}}\,\|\,\mathbb{P}^{f^{\star}}\Big{)}\geq\mathbb{E}_{\mathbb{P}^{f^{{}_{1:T}}}} \Bigg{[}\sum\limits_{t=1}^{T}\mathbb{E}_{\check{f}^{{}_{t}}\sim\mu^{t}}\big{[} \mathsf{D}_{\mathsf{H}}^{2}\big{(}\check{f}^{{}_{t}}(x^{{}_{t}}),f^{\star}(x^{{ }_{t}})\big{)}\big{]}\Bigg{]}\] \[\qquad\qquad\qquad\qquad-\frac{1}{\eta}\log\mathbb{E}_{\mathbb{P }^{f^{\star}}}\exp\Bigg{\{}\eta\sum\limits_{t=1}^{T}\mathbb{E}_{\check{f}^{{}_{t} }\sim\mu^{t}}\big{[}\mathsf{D}_{\mathsf{H}}^{2}\big{(}\check{f}^{{}_{t}}(x^{ {}_{t}}),f^{\star}(x^{{}_{t}})\big{)}\big{]}\Bigg{\}}.\] (29)

For any random variables \(X,Y,Z\), we denote by \(\mathsf{D}_{\mathsf{KL}}(\mathbb{P}_{X}\,\|\,\mathbb{P}_{Y}\mid Z)=\mathbb{E}_ {Z}[\mathsf{D}_{\mathsf{KL}}\big{(}\mathbb{P}_{X\mid Z}\,\|\,\mathbb{P}_{Y\mid Z }\big{)}]\). We further note that by the chain rule for KL divergence,

\[\mathsf{D}_{\mathsf{KL}}\Big{(}\mathbb{P}^{\check{f}^{{}_{1:T}}} \,\|\,\mathbb{P}^{f^{\star}}\Big{)} =\sum\limits_{t=1}^{T}\mathbb{E}_{\mathbb{P}^{f^{{}_{1:T}}}} \Big{[}\mathsf{D}_{\mathsf{KL}}\Big{(}\mathbb{P}_{(x^{{}_{t}},y^{{}_{t}})}^{ \check{f}^{{}_{1:T}}}\,\|\,\mathbb{P}_{(x^{{}_{t}},y^{{}_{t}})}^{\check{f}^{{} _{*}}}\mid x^{{}_{1:t-1}},y^{{}_{1:t-1}}\Big{)}\Big{]}\] \[=\sum\limits_{t=1}^{T}\mathsf{D}_{\mathsf{KL}}\Big{(}\check{f}^{{} _{t}}(x^{{}_{t}})\,\|\,f^{\star}(x^{{}_{t}})\Big{)},\]

where the second equality holds because \(y^{{}_{t}}\) follows \(\check{f}^{{}_{t}}(x^{{}_{t}})\) and \(f^{\star}(x^{{}_{t}})\) respectively, and because the conditional distribution of \(x^{{}_{t}}\) is identical under both laws due to the oblivious assumption of the covariates in the setting of CDEwRO. Then by the relation between KL and Hellinger (Lemma A.10 of [27]) and that \(1\leq\log V\), we have

\[\sum_{t=1}^{T}\mathsf{D}_{\mathsf{KL}}\left(\tilde{f}^{i}(x^{\iota})\,\|\,f^{ \star}(x^{\iota})\right)\leq(2+\log V)\cdot\sum_{t=1}^{T}\mathsf{D}_{\mathsf{ H}}^{2}\Big{(}\tilde{f}^{i}(x^{\iota}),f^{\star}(x^{\iota})\Big{)}\leq 3 \log V\cdot\sum_{t=1}^{T}\mathsf{D}_{\mathsf{H}}^{2}\Big{(}\tilde{f}^{i}(x^{ \iota}),f^{\star}(x^{\iota})\Big{)},\]

where the last inequality is by \(V\geq e\). Combining all of the results so far and using (29), we have

\[\mathbb{E}\Bigg{[}\sum_{t=1}^{T}\mathbb{E}_{\tilde{f}^{\iota}\sim \mu^{t}}\big{[}\mathsf{D}_{\mathsf{H}}^{2}\big{(}\tilde{f}^{i}(x^{\iota}),f^{ \star}(x^{\iota})\big{)}\big{]}\Bigg{]} \leq\frac{3\log V}{\eta}\cdot\sum_{t=1}^{T}\mathsf{D}_{\mathsf{ H}}^{2}\Big{(}\tilde{f}^{i}(x^{\iota}),f^{\star}(x^{\iota})\Big{)}\]

To proceed, using that for any positive random variable \(X\), \(\mathbb{E}[X]=\int_{0}^{\infty}\mathbb{P}(X\geq t)\mathrm{d}t\), we have

\[\frac{1}{\eta}\log\mathbb{E}_{\tilde{f}^{\prime}} \exp\Bigg{\{}\eta\sum_{t=1}^{T}\mathbb{E}_{\tilde{f}^{\iota}\sim \mu^{t}}\big{[}\mathsf{D}_{\mathsf{H}}^{2}\big{(}\tilde{f}^{i}(x^{\iota}),f^{ \star}(x^{\iota})\big{)}\big{]}\Bigg{\}}\] \[=R_{\mathsf{CDE}}(T)+\frac{1}{\eta}\log\mathbb{E}_{\tilde{f}^{ \prime}}\,\exp\Bigg{\{}\eta\Bigg{(}\sum_{t=1}^{T}\mathbb{E}_{\tilde{f}^{\iota} \sim\mu^{t}}\big{[}\mathsf{D}_{\mathsf{H}}^{2}\big{(}\tilde{f}^{i}(x^{\iota}), f^{\star}(x^{\iota})\big{)}\big{]}-R_{\mathsf{CDE}}(T)\Bigg{)}_{+}\Bigg{\}}\] \[=R_{\mathsf{CDE}}(T)+\frac{1}{\eta}\log\int_{0}^{\infty}\mathbb{P }^{f^{\star}}\Bigg{(}\Bigg{(}\sum_{t=1}^{T}\mathbb{E}_{\tilde{f}^{\iota}\sim \mu^{t}}\big{[}\mathsf{D}_{\mathsf{H}}^{2}\big{(}\tilde{f}^{i}(x^{\iota}),f^{ \star}(x^{\iota})\big{)}\big{]}-R_{\mathsf{CDE}}(T)\Bigg{)}_{+}\geq\frac{1}{ \eta}\log t\Bigg{)}\mathrm{d}t.\]

Recall the assumption \(\sum\limits_{t=1}^{T}\mathsf{D}_{\mathsf{H}}^{2}\Big{(}\tilde{f}^{i}(x^{\iota}),f^{\star}(x^{\iota})\Big{)}\leq\zeta\) and let \(\eta=\frac{1}{C_{\mathcal{F}}}\). We have

\[\frac{3\log V}{\eta}\cdot\sum_{t=1}^{T}\mathsf{D}_{\mathsf{H}}^{ 2}\Big{(}\tilde{f}^{i}(x^{\iota}),f^{\star}(x^{\iota})\Big{)}+\frac{1}{\eta} \log\mathbb{E}_{\tilde{f}^{\prime}}\,\exp\Bigg{\{}\eta\sum_{t=1}^{T}\mathbb{E }_{\tilde{f}^{\iota}\sim\mu^{t}}\big{[}\mathsf{D}_{\mathsf{H}}^{2}\big{(} \tilde{f}^{i}(x^{\iota}),f^{\star}(x^{\iota})\big{)}\big{]}\Bigg{\}}\] \[\leq\frac{3\log V}{\eta}\cdot\zeta+R_{\mathsf{CDE}}(T)\] \[\leq 3C_{\mathcal{F}}\log V\cdot\zeta+R_{\mathsf{CDE}}(T)+C_{ \mathcal{F}}\log\!\left(1+\int_{1}^{e^{C_{\mathcal{F}}\cdot T}}\frac{1}{t} \mathrm{d}t\right)\] \[\leq 3C_{\mathcal{F}}\log V\cdot\zeta+R_{\mathsf{CDE}}(T)+2C_{ \mathcal{F}}\cdot\log(C_{\mathcal{F}}T).\]

where the second inequality uses the assumption Eq. (4) on the algorithm.

Proof of Lemma H.2.: Our result improves uses the proof technique from the adversarial-to-oblivious reduction in Lemma 11 of Gonen et al. [31], but improves the result by a \(O(\log T)\) factor.

Consider the CDEwRP setting. Let \(\mathbb{E}^{t}[\cdot]:=\mathbb{E}[\cdot\mid x^{\iota\cdot t-1},\tilde{f}^{ \,\,\,\,i\cdot t-1}]\). Let \(\mu^{\iota,\iota}:=\mathbb{E}^{t}[\mathcal{A}_{\mathsf{CDEwRO}}(y_{1}^{\iota, \iota},\ldots,y_{1}^{\iota-1,\iota},x_{1}^{\iota,\iota},\ldots,x_{1}^{\iota-1, \iota})]\) for all \(1\leq s\leq t\leq T\) where the expectation is taken over all the random variables \(y_{1}^{\iota,\,\,\,i},\ldots,y_{1}^{\iota-1,\iota},x_{1}^{\iota,\,\,i},\ldots,x_ {1}^{\iota-1,\iota}\).

Then by Bernstein's concentration inequality applied to \(\mu^{\iota}\) (interpreted as an empirical approximation to \(\mu^{\iota,\iota}\)), conditioned on \(x^{\iota\cdot t-1},\tilde{f}^{\,\,\,i\cdot t-1}\), we have with probability at least \(1-\frac{\varepsilon}{2T}\), for all \(x^{\prime}\in\mathcal{X}\) and \(f^{\prime}\in\mathcal{F}\),

\[\mathbb{E}^{t}_{f\sim\mu^{t}}\big{[}\mathsf{D}_{\mathsf{H}}^{2}(f(x),f^{\prime}( x))\big{]}\leq 2\,\mathbb{E}^{t}_{f\sim\mu^{t,t}}\big{[}\mathsf{D}_{\mathsf{H}}^{2}(f(x),f^{ \prime}(x))\big{]}+\varepsilon/(2T).\] (30)For any fixed \(t\in[T]\) and all \(t^{\prime}\) such that \(t\leq t^{\prime}\leq T\), the different trajectories \(x_{1}^{\texttt{t}^{\prime}},\ldots,x_{1}^{\texttt{t}^{\prime}-1,t^{\prime}},y_{1 }^{\texttt{t}^{\prime}},\ldots,y_{1}^{\texttt{t}^{\prime}-1,t^{\prime}}\) are i.i.d. conditioned on \(x^{\texttt{t}^{\texttt{t}^{\prime}-1}},\tilde{f}^{\texttt{t}^{\texttt{t}^{ \prime}-1}}\). Thus, we have

\[\mathbb{E}\big{[}\mathbb{E}_{f\sim\mu^{\texttt{t},t}}^{\texttt{ t}^{\prime}}\big{[}\mathsf{D}_{\mathsf{H}}^{2}(f(x^{\texttt{t}}),f^{\star}(x^{ \texttt{t}}))\big{]}\big{]} =\mathbb{E}\Big{[}\mathbb{E}_{f\sim\mu^{\texttt{t},t+1}}^{t+1} \big{[}\mathsf{D}_{\mathsf{H}}^{2}\big{(}f(x^{\texttt{t}}),f^{\star}(x^{ \texttt{t}})\big{)}\big{]}\Big{]}\] (31) \[=\ldots\] (32) \[=\mathbb{E}\Big{[}\mathbb{E}_{f\sim\mu^{\texttt{t},T}}^{T}\big{[} \mathsf{D}_{\mathsf{H}}^{2}(f(x^{\texttt{t}}),f^{\star}(x^{\texttt{t}}))\big{]} \Big{]}.\] (33)

Finally, for Algorithm 7, we have by the guarantee of \(\mathcal{A}_{\mathsf{CDEwRO}}\),

\[\sum\limits_{t=1}^{T}\mathbb{E}\Big{[}\mathbb{E}_{f\sim\mu^{ \texttt{t}^{\prime},T}}^{T}\big{[}\mathsf{D}_{\mathsf{H}}^{2}(f(x^{\texttt{t} }),f^{\star}(x^{\texttt{t}}))\big{]}\Big{]}\leq R_{\mathsf{CDEwRO}}(T,\zeta).\]

Combining the three results above, we have

\[\sum\limits_{t=1}^{T}\mathbb{E}\big{[}\mathbb{E}_{f\sim\mu^{ \texttt{t}^{\prime}}}^{t}\big{[}\mathsf{D}_{\mathsf{H}}^{2}(f(x^{\texttt{t}}), f(x^{\texttt{t}}))\big{]}\big{]} \leq 2\sum\limits_{t=1}^{T}\mathbb{E}\big{[}\mathbb{E}_{f\sim\mu^{ \texttt{t},t}}^{\texttt{\prime}}\big{[}\mathsf{D}_{\mathsf{H}}^{2}(f(x^{ \texttt{t}}),f^{\star}(x^{\texttt{t}}))\big{]}\big{]}+\varepsilon\] \[\leq 2R_{\mathsf{CDEwRO}}(T,\zeta)+\varepsilon,\]

where the first equality is by Eq. (30), the second equality is from Eq. (31), and the final inequality is by the guarantee of \(\mathcal{A}_{\mathsf{CDEwRO}}\).

**Proof of Lemma H.3.** Note that Algorithm 8 is a variant of the reduction in Lemma G.3, specialized to squared Hellinger distance, and the proof here will use the same idea as Lemma G.3.

For each \(i\in[N]\), let \(\zeta_{i}=\sum\nolimits_{j=1}^{T/N}\mathsf{D}_{\mathsf{H}}^{2}\Big{(}\tilde{f} ^{\texttt{t}^{\texttt{t}+N\texttt{.}j}}(x^{\texttt{t}^{\texttt{t}+N\texttt {.}j}}),f^{\star}(x^{\texttt{t}^{\texttt{t}+N\texttt{.}j}})\Big{)}\). Then by the guarantee of \(\mathcal{A}_{\mathsf{CDEwRP}}\), we that for all \(i\in[N]\),

Summing up over all \(i\in[N]\), we obtain

\[\sum\limits_{t=1}^{T}\mathbb{E}_{\tilde{f}\sim\mu^{\texttt{t}}} \big{[}\mathsf{D}_{\mathsf{H}}^{2}\big{(}\tilde{f}(x^{\texttt{t}}),f^{\star}( x^{\texttt{t}})\big{)}\big{]} =\sum\limits_{i=1}^{N}\sum\limits_{j=1}^{T/N}\mathbb{E}_{\tilde{f} \sim\mu^{\texttt{t}+N\texttt{.}j}}\big{[}\mathsf{D}_{\mathsf{H}}^{2}\big{(} \tilde{f}(x^{\texttt{t}+N\texttt{.}j}),f^{\star}(x^{\texttt{t}+N\texttt{.}j}) \big{)}\big{]}\] \[\leq\sum\limits_{i=1}^{N}R_{\mathsf{CDEwRP}}(T/N,\zeta_{i},1/N).\]

By the assumption on \(\sum\limits_{t=1}^{T}\mathsf{D}_{\mathsf{H}}^{2}\Big{(}\tilde{f}^{\texttt{t}}( x^{\texttt{t}}),f^{\star}(x^{\texttt{t}})\Big{)}\), we have

\[\sum\limits_{i=1}^{N}\zeta_{i}=\sum\limits_{i=1}^{N}\sum\limits_{j=1}^{T/N} \mathsf{D}_{\mathsf{H}}^{2}\Big{(}\tilde{f}^{\texttt{t}+N\texttt{.}j}(x^{ \texttt{t}+N\texttt{.}j}),f^{\star}(x^{\texttt{t}+N\texttt{.}j})\Big{)}=\sum \limits_{t=1}^{T}\mathsf{D}_{\mathsf{H}}^{2}\Big{(}\tilde{f}^{\texttt{t}}(x^{ \texttt{t}}),f^{\star}(x^{\texttt{t}})\Big{)}\leq\zeta.\]

Finally, we conclude

\[\sum\limits_{t=1}^{T}\mathbb{E}_{\tilde{f}\sim\mu^{\texttt{t}}} \big{[}\mathsf{D}_{\mathsf{H}}^{2}\big{(}\tilde{f}(x^{\texttt{t}}),f^{\star}( x^{\texttt{t}})\big{)}\big{]}\leq\sup\limits_{\sum\limits_{i=1}^{N}\zeta_{i}\leq\zeta} \sum\limits_{i=1}^{N}R_{\mathsf{CDEwRP}}(T/N,\zeta_{i},1/N).\]Proof of Lemma H.4.: This reduction is arguably the most interesting one. This reduction is by noticing that averaging across the outputs of the offline oracle will generate reference parameters (although delayed) with small online estimation errors as shown later in Eq. (34). By the guarantee of \(\mathcal{A}_{\mathsf{ODEwDRP}}\), we have

\[\sum_{t=1}^{T}\mathbb{E}_{\tilde{f}\sim\mu^{t}}\big{[}\mathsf{D}_{\mathsf{H}}^{ 2}(\bar{f}(x^{\iota}),f^{\star}(x^{\iota}))\big{]}\leq R_{\mathsf{CDEwDRP}}(T,N,\zeta),\]

where \(\zeta\) can be chosen to be any upper bound of \(\sum\limits_{t=1}^{T}\mathsf{D}_{\mathsf{H}}^{2}\Big{(}\tilde{f}^{\iota}(x^{ \iota}),f^{\star}(x^{\iota})\Big{)}\) since it is unknown to the learner in the setup where we augment the sequence of \(\widehat{f}^{\iota}\),...,\(\widehat{f}^{\iota}\) by setting \(\widehat{f}^{\iota_{+}}=\widehat{f}^{\iota}\) for all \(s\in\mathbb{N}\) and define \(\tilde{f}^{\iota}:=\frac{1}{N}\sum_{i=t+1}^{t+N}\widehat{f}^{\iota}\) for \(t=T-N,T-N+1,\ldots,T\). Furthermore, by the definition of \(\tilde{f}^{\iota}\), we can obtain

\[\sum_{t=1}^{T}\mathsf{D}_{\mathsf{H}}^{2}\Big{(}\tilde{f}^{\iota }(x^{\iota}),f^{\star}(x^{\iota})\Big{)} =N+\frac{1}{N}\sum_{t=1}^{T-N}\sum_{i=t+1}^{t+N}\mathsf{D}_{\mathsf {H}}^{2}\big{(}\bar{f}^{\iota}(x^{\iota}),f^{\star}(x^{\iota})\big{)}\] \[=N+\frac{1}{N}\sum_{t=2}^{T}\sum_{i<t}\mathsf{D}_{\mathsf{H}}^{2} \big{(}\bar{f}^{\iota}(x^{\iota}),f^{\star}(x^{\iota})\big{)}\] \[\leq N+\frac{\beta_{\mathsf{Off}}T}{N}.\] (34)

Thus, we conclude Algorithm 9 obtains

\[\sum_{t=1}^{T}\mathbb{E}_{\tilde{f}\sim\mu^{t}}\big{[}\mathsf{D}_{\mathsf{H}}^ {2}\big{(}\bar{f}(x^{\iota}),f^{\star}(x^{\iota})\big{)}\big{]}\leq R_{\mathsf{ CDEwDRP}}(T,N,N+\beta_{\mathsf{Off}}T/N).\]

## Appendix I Proofs from Appendix E

**Theorem E.1** (Offline-to-online conversion under coverability).: _For any layer-wise loss \(\mathsf{D}^{\mathsf{RL}}\) and MDP class \((\mathcal{M},\Pi,\mathcal{O})\) and \(M^{\star}\in\mathcal{M}\), the sequence of estimators \((\widehat{M}^{\iota},\ldots,\widehat{M}^{\iota})\) produced by any offline estimation oracle \(\mathbf{Alg}_{\mathsf{Off}}\) for \(\mathsf{D}^{\mathsf{RL}}\) with parameter \(\beta_{\mathsf{Off}}\) satisfy_

\[\sum_{t=1}^{T}\mathsf{D}^{\mathsf{RL}}\Big{(}\widehat{M}^{\iota}(\pi^{t})\|M^ {\star}(\pi^{\iota})\Big{)}\leq O\Big{(}\sqrt{HC_{\mathsf{cov}}(M^{\star}) \beta_{\mathsf{Off}}T\log T}+HC_{\mathsf{cov}}(M^{\star})\Big{)}.\]

Proof of Theorem E.1.: This proof closely follows the proof of Theorem 1 in Xie et al. [69]. Define the shorthand \(d_{h}^{\iota}(s,a)\equiv d_{h}^{\pi^{t}}(s,a)\) and \(C_{\mathsf{cov}}=C_{\mathsf{cov}}(M^{\star})\), and define

\[\widetilde{d}_{h}^{\iota}(s,a):=\sum_{\tau=1}^{t-1}d_{h}^{\iota}(s,a),\quad \text{and}\quad\mu_{h}^{\star}:=\operatorname*{arg\,min}_{\mu_{h}\in\Delta( \mathcal{S}\times\mathcal{A})}\sup_{\pi\in\Pi}\norm{\frac{d_{h}^{\pi}}{\mu_{h} }}_{\infty}.\]

From the definition of the layer-wise loss, we have

\[\sum_{t=1}^{T}\mathsf{D}^{\mathsf{RL}}\Big{(}\widehat{M}^{\iota}(\pi^{\iota}) \|M^{\star}(\pi^{\iota})\Big{)}=\sum_{h=1}^{H}\sum_{t=1}^{T}\sum_{(s,a)\in \mathcal{S}\times\mathcal{A}}d_{h}^{\iota}(s,a)\mathsf{D}_{h}\Big{(}\overline {P}_{h}^{{}^{M^{\star}}}(s,a)\|\overline{P}_{h}^{{}^{\widehat{M}^{t}}}(s,a) \Big{)}.\]

We define a "burn-in" phase for each state-action pair \((s,a)\in\mathcal{S}\times\mathcal{A}\) by defining

\[\tau_{h}(s,a)=\min\left\{t\mid\widetilde{d}_{h}^{\iota}(s,a)\geq C_{\mathsf{ cov}}\cdot\mu_{h}^{\star}(s,a)\right\}.\]Let \(h\in[H]\) be With this definition, for we can write

\[\sum_{t=1}^{T}\sum_{(s,a)\in\mathcal{S}\times\mathcal{A}}d_{h}^{t}(s,a)\mathsf{D}_{h}\Big{(}\overline{P}_{h}^{{}^{M^{\star}}}(s,a)\|\overline{P}_{h} ^{{}^{\bar{\Omega}}t}(s,a)\Big{)}\] \[=\sum_{(s,a)\in\mathcal{S}\times\mathcal{A}}\sum_{t<\tau_{h}(s,a)} d_{h}^{t}(s,a)\mathsf{D}_{h}\Big{(}\overline{P}_{h}^{{}^{M^{\star}}}(s,a)\| \overline{P}_{h}^{{}^{\bar{\Omega}}t}(s,a)\Big{)}+\sum_{(s,a)\in\mathcal{S} \times\mathcal{A}}\sum_{t\geq\tau_{h}(s,a)}d_{h}^{t}(s,a)\mathsf{D}_{h}\Big{(} \overline{P}_{h}^{{}^{M^{\star}}}(s,a)\|\overline{P}_{h}^{{}^{\bar{\Omega}}t}( s,a)\Big{)}\]

For the first term above, we have

\[\sum_{(s,a)\in\mathcal{S}\times\mathcal{A}}\sum_{t<\tau_{h}(s,a)}d_{h}^{t}(s,a )\mathsf{D}_{h}\Big{(}\overline{P}_{h}^{{}^{M^{\star}}}(s,a)\|\overline{P}_{h} ^{{}^{\bar{\Omega}}t}(s,a)\Big{)}\leq\sum_{(s,a)\in\mathcal{S}\times\mathcal{A }}\widetilde{d}_{h}^{\tau_{h}(s,a)}(s,a)\leq 2C_{\mathsf{cov}}\sum_{(s,a)\in \mathcal{S}\times\mathcal{A}}\mu_{h}^{\star}(s,a)=2C_{\mathsf{cov}},\]

where the last inequality holds because

\[\sum_{(s,a)\in\mathcal{S}\times\mathcal{A}}\widetilde{d}_{h}^{\tau_{h}(s,a)}( s,a)=\sum_{(s,a)\in\mathcal{S}\times\mathcal{A}}\widetilde{d}_{h}^{\tau_{h}(s,a) -1}(s,a)+d_{h}^{\tau_{h}(s,a)}(s,a)\leq 2C_{\mathsf{cov}}\cdot\mu_{h}^{\star}(s,a).\]

The remaining term is

\[\sum_{h=1}^{H}\sum_{(s,a)\in\mathcal{S}\times\mathcal{A}}\sum_{t \geq\tau_{h}(s,a)}d_{h}^{t}(s,a)\mathsf{D}_{h}\Big{(}\overline{P}_{h}^{{}^{M^ {\star}}}(s,a)\|\overline{P}_{h}^{{}^{\bar{\Omega}}t}(s,a)\Big{)}\] \[=\sum_{h=1}^{H}\sum_{t=1}^{T}\sum_{(s,a)\in\mathcal{S}\times \mathcal{A}}d_{h}^{t}(s,a)\Bigg{(}\frac{\widetilde{d}_{h}^{t}(s,a)}{\widetilde {d}_{h}^{t}(s,a)}\Bigg{)}^{1/2}\mathbbm{1}\{t\geq\tau_{h}(s,a)\}\mathsf{D}_{h} \Big{(}\overline{P}_{h}^{{}^{M^{\star}}}(s,a)\|\overline{P}_{h}^{{}^{\bar{ \Omega}}t}(s,a)\Big{)}\] \[\leq\sqrt{\sum_{h=1}^{H}\sum_{t=1}^{T}\sum_{(s,a)\in\mathcal{S} \times\mathcal{A}}\frac{(\mathbbm{1}(t\geq\tau_{h}(s,a))d_{h}^{t}(s,a))^{2}}{ \widetilde{d}_{h}^{t}(s,a)}}\cdot\sqrt{\sum_{h=1}^{H}\sum_{t=1}^{T}\sum_{(s,a )\in\mathcal{S}\times\mathcal{A}}\widetilde{d}_{h}^{t}(s,a)\mathsf{D}_{h} \Big{(}\overline{P}_{h}^{{}^{M^{\star}}}(s,a)\|\overline{P}_{h}^{{}^{\bar{ \Omega}}t}(s,a)\Big{)}}.\]

Following the derivation in Theorem 1 of Xie et al. [69], we have

\[\sum_{t=1}^{T}\sum_{(s,a)\in\mathcal{S}\times\mathcal{A}}\frac{( \mathbbm{1}(t\geq\tau_{h}(s,a))d_{h}^{t}(s,a))^{2}}{\widetilde{d}_{h}^{t}(s,a)} \leq 2\sum_{t=1}^{T}\sum_{(s,a)\in\mathcal{S}\times\mathcal{A}} \frac{d_{h}^{t}(s,a)\cdot d_{h}^{t}(s,a)}{\widetilde{d}_{h}^{t}(s,a)+C_{ \mathsf{cov}}\cdot\mu_{h}^{\star}(s,a)}\] \[\leq 2\sum_{t=1}^{T}\sum_{(s,a)\in\mathcal{S}\times\mathcal{A}} \max_{t^{\prime}\in[T]}d_{h}^{t^{\prime}}(s,a)\cdot\frac{d_{h}^{t}(s,a)}{ \widetilde{d}_{h}^{t}(s,a)+C_{\mathsf{cov}}\cdot\mu_{h}^{\star}(s,a)}\] \[\leq 2\Bigg{(}\max_{s,a}\sum_{t=1}^{T}\frac{d_{h}^{t}(s,a)}{ \widetilde{d}_{h}^{t}(s,a)+C_{\mathsf{cov}}\cdot\mu_{h}^{\star}(s,a)}\Bigg{)} \cdot\Bigg{(}\sum_{(s,a)\in\mathcal{S}\times\mathcal{A}}\max_{t\in[T]}d_{h}^{t }(s,a)\Bigg{)}\] \[\lesssim C_{\mathsf{cov}}\log T,\]

where the last inequality follows from Lemmas 3 and 4 of Xie et al. [69]. For the second term, as a consequence of the offline estimation assumption, we have that for all \(t\in[T]\),

\[\sum_{h=1}^{H}\sum_{(s,a)\in\mathcal{S}\times\mathcal{A}}\widetilde{d}_{h}^{t}(s,a)\mathsf{D}_{h}\Big{(}\overline{P}_{h}^{{}^{M^{\star}}}(s,a)\|\overline{P}_{h}^ {{}^{\bar{\Omega}}t}(s,a)\Big{)}=\sum_{s=1}^{t-1}\mathsf{D}^{\mathsf{RL}} \Big{(}\widehat{M}^{t}(\pi^{\star})\|M^{\star}(\pi^{\star})\Big{)}\leq\beta_{ \mathsf{Off}}.\]

Altogether, we conclude that

\[\sum_{t=1}^{T}\mathsf{D}^{\mathsf{RL}}\Big{(}\widehat{M}^{t}(\pi^{\star})\|M^{ \star}(\pi^{\star})\Big{)}\leq O\Big{(}\sqrt{HC_{\mathsf{cov}}\beta_{ \mathsf{Off}}T\log T}+HC_{\mathsf{cov}}\Big{)}.\]

**Corollary E.2**.: _For any MDP class \((\mathcal{M},\Pi,\mathcal{O})\) and \(M^{\star}\in\mathcal{M}\), the sequence of estimators \((\widehat{M}^{1},\ldots,\widehat{M}^{T})\) produced by any offline estimation oracle \(\mathbf{Alg}_{\mathsf{Off}}\) for squared Hellinger distance \(\mathsf{D}^{2}_{\mathsf{H}}\) with parameter \(\beta_{\mathsf{Off}}\) satisfy_

\[\mathbf{Est}^{\mathsf{On}}_{\mathsf{H}}(T)=\sum_{t=1}^{T}\mathsf{D}^{2}_{ \mathsf{H}}\Big{(}\widehat{M}^{t}(\pi^{t}),M^{\star}(\pi^{t})\Big{)}\leq O\Big{(} H\sqrt{C_{\mathsf{cov}}(M^{\star})\beta_{\mathsf{Off}}T\log T}+H^{2}C_{ \mathsf{cov}}(M^{\star})\Big{)}\]

**Proof of Corollary E.2.** By Lemma F.2, for any two MDP models \(M\) and \(M^{\prime}\) and any \(\pi\in\Delta(\Pi_{\mathrm{RNS}})\), we have

\[\mathsf{D}^{2}_{\mathsf{H}}(M(\pi),M^{\prime}(\pi))=\mathsf{D}^{2}_{\mathsf{H }}(M^{\prime}(\pi),M(\pi))\leq 7\cdot\sum_{h=1}^{H}\mathbb{E}^{M^{\prime}, \pi}\Big{[}\mathsf{D}^{2}_{\mathsf{H}}\Big{(}\overline{P}^{M^{\prime}}_{h}(s_ {h},a_{h}),\overline{P}^{M}_{h}(s_{h},a_{h})\Big{)}\Big{]}.\] (35)

On the other hand, for any \(h\in[H]\), we have from Lemma A.9 of Foster et al. [27] that

\[\mathbb{E}^{M^{\prime},\pi}\Big{[}\mathsf{D}^{2}_{\mathsf{H}}\Big{(}\overline {P}^{M^{\prime}}_{h}(s_{h},a_{h}),\overline{P}^{M}_{h}(s_{h},a_{h})\Big{)} \Big{]}\leq 4\mathsf{D}^{2}_{\mathsf{H}}(M(\pi),M^{\prime}(\pi)),\]

by choosing \(X=(s_{h},a_{h})\) and \(Y=(r_{h},s_{h+1})\) in the aforementioned lemma. Summing up over \(h\), we conclude that

\[\sum_{h=1}^{H}\mathbb{E}^{M^{\prime},\pi}\Big{[}\mathsf{D}^{2}_{\mathsf{H}} \Big{(}\overline{P}^{M^{\prime}}_{h}(s_{h},a_{h}),\overline{P}^{M}_{h}(s_{h}, a_{h})\Big{)}\Big{]}\leq 4H\cdot\mathsf{D}^{2}_{\mathsf{H}}(M(\pi),M^{\prime}(\pi)).\] (36)

Consider any sequence of policies \(\pi^{1},\ldots,\pi^{T}\) and outputs \(\widehat{M}^{1},\ldots,\widehat{M}^{T}\) from an offline oracle with parameter \(\beta_{\mathsf{Off}}\) for squared Hellinger distance. By Eq. (36), we have that for all \(t\in[T]\),

\[\sum_{\tau=1}^{t-1}\sum_{h=1}^{H}\mathbb{E}^{M^{\star},\pi^{\tau}}\Big{[} \mathsf{D}^{2}_{\mathsf{H}}\Big{(}\overline{P}^{M^{\star}}_{h}(s,a), \overline{P}^{\widehat{M}^{t}}_{h}(s,a)\Big{)}\Big{]}\leq 4H\sum_{\tau=1}^{t-1} \mathsf{D}^{2}_{\mathsf{H}}\Big{(}\widehat{M}^{\tau}(\pi^{\tau}),M^{\star}( \pi^{\tau})\Big{)}\leq 4\beta_{\mathsf{Off}}H.\]

Theorem E.1 thus implies that

\[\sum_{t=1}^{T}\sum_{h=1}^{H}\mathbb{E}^{M^{\star},\pi^{t}}\Big{[}\mathsf{D}^{2} _{\mathsf{H}}\Big{(}\overline{P}^{M^{\star}}_{h}(s,a),\overline{P}^{\widehat{ M}^{t}}_{h}(s,a)\Big{)}\Big{]}\lesssim H\sqrt{C_{\mathsf{cov}}\beta_{\mathsf{Off}}T\log T}+H^{2}C_{ \mathsf{cov}}.\]

Finally, using Eq. (35), we can convert the inequality above into a bound on the square Hellinger distance:

\[\sum_{t=1}^{T}\mathsf{D}^{2}_{\mathsf{H}}\Big{(}\widehat{M}^{t} (\pi^{t}),M^{\star}(\pi^{t})\Big{)} \lesssim\sum_{t=1}^{T}\sum_{h=1}^{H}\mathbb{E}^{M^{\star},\pi^{t} }\Big{[}\mathsf{D}^{2}_{\mathsf{H}}\Big{(}\overline{P}^{M^{\star}}_{h}(s,a), \overline{P}^{\widehat{M}^{t}}_{h}(s,a)\Big{)}\Big{]}\] \[\lesssim H\sqrt{C_{\mathsf{cov}}\beta_{\mathsf{Off}}T\log T}+H^{2}C _{\mathsf{cov}}.\]

\(\square\)

**Proposition E.2** (Tightness of offline-to-online conversion).: _For any integer \(T\geq 1\) and \(\beta_{\mathsf{Off}}>0\), there exists a contextual bandit class \((\mathcal{M},\Pi=\mathcal{A}^{\mathcal{S}},\mathcal{O})\) with \(|\mathcal{A}|=2\), a distribution \(d_{1}\in\Delta(\mathcal{S})\), a sequence \((\pi^{1},\ldots,\pi^{T})\) and an offline oracle \(\mathbf{Alg}_{\mathsf{Off}}\) for \(\mathsf{D}_{\mathsf{CB}}\) with parameter \(\beta_{\mathsf{Off}}\) such that the oracle's outputs \((\widehat{M}^{1},\ldots,\widehat{M}^{T})\) satisfy_

\[\mathbf{Est}^{\mathsf{On}}_{\mathsf{D}}(T)=\sum_{t=1}^{T}\mathsf{D}_{\mathsf{CB}} \Big{(}\widehat{M}^{i}(\pi^{t}),M^{\star}(\pi^{t})\Big{)}\geq\Omega\Big{(} \sqrt{T\beta_{\mathsf{Off}}}\Big{)}.\]

**Proof of Proposition E.2.** Let \(\beta_{\mathsf{Off}}>0\) and \(T\) be given, and let \(N\in\mathbb{N}\) be chosen such that \(T=N\cdot\lfloor N\beta_{\mathsf{Off}}\rfloor\); we assume without loss of generality that \(N\) is large enough such that \(N\beta_{\mathsf{Off}}>1\), which implies that \(\lfloor N\beta_{\mathsf{Off}}\rfloor\geq N\beta_{\mathsf{Off}}/2\)). Define \(\mathcal{A}=\{a_{0},a_{1}\}\), \(\mathcal{S}=\{s_{0},\ldots,s_{N-1}\}\), and \(g^{M^{\star}}(s,a)\equiv 0\)for all \(s\in\mathcal{S},a\in\mathcal{A}\). Let \(d_{1}=\operatorname{Unif}(\mathcal{S})\) be the context distribution. For any \(t\in\{1,\dots,T\}\), consider the deterministic policy \(\pi^{\iota}:\mathcal{S}\to\mathcal{A}\) and the offline estimator \(\widehat{M}^{\iota}\) defined via

\[\pi^{\iota}(s_{n})=\begin{cases}a_{1},&\text{if }n=\lfloor t/\lfloor N\beta_{ \mathsf{Off}}\rfloor\rfloor,\\ a_{0},&\text{otherwise.}\end{cases}\quad\text{ and }\,g^{\beta^{t}}(s,a)= \begin{cases}1,&\text{if }s=s_{\lfloor t/\lfloor N\beta_{\mathsf{Off}}\rfloor \rfloor},a=a_{1},\\ 0,&\text{otherwise.}\end{cases}\]

We first verify that \(\widehat{M}^{\iota},\dots,\widehat{M}^{T}\) satisfy the offline oracle requirement. For any \(t\in\{1,\dots,T\}\), we have

\[\sum_{\tau=1}^{t-1}\mathbb{E}_{s\sim d_{1}}\big{[}\mathsf{D}_{ \mathsf{sq}}\big{(}g^{{}_{M}}(s,\pi^{\tau}(s)),g^{\beta^{t}\tau}(s,\pi^{\tau}(s ))\big{)}\big{]}\] \[=\frac{1}{N}\sum_{\tau=1}^{t-1}\mathbbm{1}\big{\{}\pi^{\tau}(s_{ \lfloor t/N\rfloor})=a_{1}\big{\}}\] \[=\frac{1}{N}\cdot(t-\lfloor t/\lfloor N\beta_{\mathsf{Off}} \rfloor]\cdot\lfloor N\beta_{\mathsf{Off}}\rfloor)\leq\beta_{\mathsf{Off}}.\]

However, the online error is

\[\sum_{t=1}^{T}\mathbb{E}_{s\sim d_{1}}\big{[}\mathsf{D}_{\mathsf{sq}}\big{(}g^ {{}_{M}}(s,\pi^{t}(s)),g^{\beta^{t}\iota}(s,\pi^{t}(s))\big{)}\big{]}=\sum_{t =1}^{T}\frac{1}{N}=\lfloor N\beta_{\mathsf{Off}}\rfloor\geq\frac{1}{2}\sqrt{ T\beta_{\mathsf{Off}}}.\]

### NeurIPS Paper Checklist

The checklist is designed to encourage best practices for responsible machine learning research, addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove the checklist: **The papers not including the checklist will be desk rejected.** The checklist should follow the references and follow the (optional) supplemental material. The checklist does NOT count towards the page limit.

Please read the checklist guidelines carefully for information on how to answer these questions. For each question in the checklist:

* You should answer [Yes], [No], or [NA].
* [NA] means either that the question is Not Applicable for that particular paper or the relevant information is Not Available.
* Please provide a short (1-2 sentence) justification right after your answer (even for NA).

**The checklist answers are an integral part of your paper submission.** They are visible to the reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it (after eventual revisions) with the final version of your paper, and its final version will be published with the paper.

The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation. While "[Yes] " is generally preferable to "[No] ", it is perfectly acceptable to answer "[No] " provided a proper justification is given (e.g., "error bars are not reported because it would be too computationally expensive" or "we were unable to find the license for the dataset we used"). In general, answering "[No] " or "[NA] " is not grounds for rejection. While the questions are phrased in a binary way, we acknowledge that the true answer is often more nuanced, so please just use your best judgment and write a justification to elaborate. All supporting evidence can appear either in the main paper or the supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification please point to the section(s) where related material for the question can be found.

IMPORTANT, please:

* **Delete this instruction block, but keep the section heading "NeurIPS paper checklist"**,
* **Keep the checklist subsection headings, questions/answers and guidelines below.**
* **Do not modify the questions and only use the provided macros for your answers**.

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes]. Justification: The main claims made in the abstract and introduction accurately reflect the paper's contributions and scope. The claims are validated by detailed proofs. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors?Answer: [Yes]. Justification: See Section 1.2. Guidelines:

* The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.
* The authors are encouraged to create a separate "Limitations" section in their paper.
* The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.
* The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.
* The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.
* The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.
* If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.
* While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes]. Justification: The paper provides detailed assumptions and proofs. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility**Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [NA]. Justification: This paper does not include experiments. Guidelines:

* The answer NA means that the paper does not include experiments.
* If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.
* If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.
* Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.
* While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [NA] Justification: This paper does not include experiments. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [NA]. Justification: This paper does not include experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [NA]. Justification: This paper does not include experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors). * It should be clear whether the error bar is the standard deviation or the standard error of the mean.

* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [NA]. Justification: This paper does not include experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes]. Justification: The research conducted in the paper conforms, in every respect, with the NeurIPS Code of Ethics Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: This is a theoretical work. There is no societal impact on the work performed. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.

* Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.
* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).

11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA]. Justification: The paper poses no such risks. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.

12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [NA]. Justification: This paper does not use existing assets. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset.

* For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.
* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA]. Justification: This paper does not release new assets. Guidelines: * The answer NA means that the paper does not release new assets. * Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. * The paper should discuss whether and how consent was obtained from people whose asset is used. * At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA]. Justification: This paper does not involve crowdsourcing or research with human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. * According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA]. Justification: This paper does not involve crowdsourcing or research with human subjects.

Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.