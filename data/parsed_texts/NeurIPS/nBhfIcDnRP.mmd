# Efficient Graph Matching

for Correlated Stochastic Block Models

 Shuwen Chai

Northwestern University

Evanston, IL 60208

shuwenchai2027@u.northwestern.edu

&Miklos Z. Racz

Northwestern University

Evanston, IL 60208

miklos.racz@northwestern.edu

###### Abstract

We study learning problems on correlated stochastic block models with two balanced communities. Our main result gives the first efficient algorithm for graph matching in this setting. In the most interesting regime where the average degree is logarithmic in the number of vertices, this algorithm correctly matches all but a vanishing fraction of vertices with high probability, whenever the edge correlation parameter \(s\) satisfies \(s^{2}>\alpha\approx 0.338\), where \(\alpha\) is Otter's tree-counting constant. Moreover, we extend this to an efficient algorithm for exact graph matching whenever this is information-theoretically possible, positively resolving an open problem of Racz and Sridhar (NeurIPS 2021). Our algorithm generalizes the recent breakthrough work of Mao, Wu, Xu, and Yu (STOC 2023), which is based on centered subgraph counts of a large family of trees termed chandeliers. A major technical challenge that we overcome is dealing with the additional estimation errors that are necessarily present due to the fact that, in relevant parameter regimes, the latent community partition cannot be exactly recovered from a single graph. As an application of our results, we give an efficient algorithm for exact community recovery using multiple correlated graphs in parameter regimes where it is information-theoretically impossible to do so using just a single graph.

## 1 Introduction

The proliferation of network data has highlighted the ubiquity and importance of _graph matching_ in machine learning, with applications in a variety of domains, including social networks [51, 56], computational biology [61], and computer vision [13, 36]. While the graph matching task--recovering the latent node alignment between two networks--is known to be NP-hard to solve or even approximate in general [38, 52], in practice it is often possible to solve it well, such as in the works cited above. This has motivated an exciting recent line of work studying average-case graph matching [14, 15, 65, 16, 23, 27, 24, 49, 5, 21, 22, 39, 40, 41, 17, 20, 18], focusing on correlated Erdos-Renyi random graphs [56]. These papers culminated in recent breakthrough works which developed efficient graph matching algorithms in the constant noise regime [40, 41].

However, real-world networks are not modeled well by Erdos-Renyi random graphs, which in turn has motivated a growing line of recent work studying graph matching beyond Erdos-Renyi [8, 32, 11, 54, 58, 70, 57, 25, 63, 59, 19, 67, 66, 60, 10]. In particular, an important problem in this vein is to study graph matching in _correlated stochastic block models (correlated SBMs)_[35, 54, 34] (see Section 2 for definitions), since community structure is prevalent in many networks and the community recovery problem is a fundamental inference task that is often a starting point for deeper analyses. Recent work of Racz and Sridhar [57] determined the fundamental information-theoretic limits for exact graph matching in correlated SBMs; however, the underlying algorithm used to achieve this limit is inefficient (that is, not polynomial time). Racz and Sridhar [57] posed the open problem of finding an _efficient_ algorithm for (exact) graph matching whenever this is information-theoretically feasible.

Our main contribution positively resolves this open problem of Racz and Sridhar [57], giving the first efficient algorithm for graph matching for correlated SBMs with two balanced communities, under a condition on the correlation strength that is conjectured to be necessary. Specifically, we give an efficient algorithm that, in the most interesting regime where the average degree is logarithmic in the number of vertices, achieves almost exact recovery of the latent matching, whenever the edge correlation parameter \(s\) satisfies \(s^{2}>\alpha\approx 0.338\), where \(\alpha\) is Otter's tree-counting constant. Moreover, we extend this to an efficient algorithm for exact graph matching whenever this is information-theoretically possible. See Section 3 and Theorem 1 for details.

In addition, our results on graph matching directly imply novel efficient algorithms and results for community recovery. Specifically, combining--in a black-box fashion--our (exact) graph matching algorithm with existing community recovery algorithms, we give an efficient algorithm for exact community recovery using multiple correlated graphs in parameter regimes where it is information-theoretically impossible to do so using just a single graph. See Section 3 and Theorem 2 for details.

Our algorithm generalizes the recent breakthrough work of Mao, Wu, Xu, and Yu [41], which is based on centered subgraph counts of a large family of trees termed chandeliers, to the setting of correlated SBMs. A major technical challenge that we overcome is dealing with the additional estimation errors that are necessarily present due to the fact that, in relevant parameter regimes, the latent community partition cannot be exactly recovered from a single graph, and thus the edge-indicator variables in the centered subgraph counts cannot be precisely centered. Our technical contributions highlight the interplay between graph matching and community recovery in ways that are complementary to the recent work of Gaudio, Racz, and Sridhar [25].

## 2 Models and problems

In this section we describe the setting of the paper by introducing the stochastic block model (SBM), correlated SBMs, and the community recovery and graph matching tasks.

The **stochastic block model (SBM)** is the canonical probabilistic generative model for a network with latent community structure. The SBM was first introduced by Holland, Laskey, and Leinhardt [29] and has been widely studied over the past decades [1]. In general, an SBM may consist of a number of communities, with distinct vertices connected randomly with a probability that depends on their community memberships.

In this work, we focus on the simplest setting of the balanced two-community SBM. Given \(n\in\mathbb{Z}_{+}\) and \(p,q\in[0,1]\), we construct \(G\sim\mathrm{SBM}(n,p,q)\) as follows. The graph \(G\) has \(n\) vertices, with vertex labels given by \(V=[n]:=\{1,2,\ldots,n\}\). Let \(\boldsymbol{\sigma}_{*}=\{\boldsymbol{\sigma}_{*}(i)\}_{i=1}^{n}\) be the vector of community labels, where each entry \(\boldsymbol{\sigma}_{*}(i)\in\{-1,+1\}\) is drawn independently and uniformly at random. Then, given the community labels \(\boldsymbol{\sigma}_{*}\), for any pair of vertices \(i\neq j\in[n]\), edge \((i,j)\) is in \(G\) with probability \(p\mathbf{1}_{\{\boldsymbol{\sigma}_{*}(i)=\boldsymbol{\sigma}_{*}(j)\}}+q \mathbf{1}_{\{\boldsymbol{\sigma}_{*}(i)\neq\boldsymbol{\sigma}_{*}(j)\}}\). That is, two different vertices are connected with probability \(p\) if they are from the same community and connected with probability \(q\) otherwise.

**Correlated SBMs** are multiple SBMs where the corresponding edge variables are correlated [35; 54; 34]. Specifically, we construct two correlated SBMs \((G_{1},G_{2})\sim\mathrm{CSBM}(n,p,q,s)\) using a natural subsampling procedure as follows. Let \(G\sim\mathrm{SBM}(n,p,q)\) be a parent graph with community labels \(\boldsymbol{\sigma}_{*}\). Next, given \(G\), we construct \(G_{1}\) by random sampling of the edges: each edge of \(G\) is included in \(G_{1}\) with probability \(s\), independently of everything else, and non-edges of \(G\) remain non-edges of \(G_{1}\). We then do the edge sampling independently again to obtain \(G_{2}^{\prime}\) in the same way. The child graphs \(G_{1}\) and \(G_{2}^{\prime}\) inherit both the vertex labels (given by \([n]\)) and the community labels \(\boldsymbol{\sigma}_{*}\) from the parent graph \(G\). Finally, let \(\pi_{*}\) be a uniformly random permutation of \([n]:=\{1,2,\ldots,n\}\) and generate \(G_{2}\) by relabeling the vertices of \(G_{2}^{\prime}\) according to \(\pi_{*}\) (e.g., vertex \(i\) in \(G_{2}^{\prime}\) is relabeled as \(\pi_{*}(i)\) in \(G_{2}\)). This last step reflects the fact that in practice often the correspondence between the two vertex sets is unknown. We denote the adjacency matrices of \(G_{1}\) and \(G_{2}\) as \(A\) and \(B\), respectively, and note that the community labels of the two graphs are \(\boldsymbol{\sigma}_{*}^{A}:=\boldsymbol{\sigma}_{*}\) and \(\boldsymbol{\sigma}_{*}^{B}:=\boldsymbol{\sigma}_{*}\circ\pi_{*}^{-1}\), respectively. See Figure 1 for an illustration.

Marginally, \(G_{1}\) and \(G_{2}\) are identically distributed SBMs: we have \(G_{1},G_{2}\sim\mathrm{SBM}(n,ps,qs)\). Moreover, \(G_{1}\) and \(G_{2}\) are _correlated_. Specifically, for every pair of distinct vertices \(\{i,j\}\), the edge-indicator random variables \(A_{i,j}\) and \(B_{\pi_{*}(i),\pi_{*}(j)}\) are correlated Bernoulli random variables. A simple calculation shows that if \(\boldsymbol{\sigma}_{*}(i)=\boldsymbol{\sigma}_{*}(j)\), then the correlation coefficient of \(A_{i,j}\) and \(B_{\pi_{*}(i),\pi_{*}(j)}\) is equal to \(\rho_{+}:=s\frac{1-p}{1-ps}\), whereas if \(\bm{\sigma}_{*}(i)\neq\bm{\sigma}_{*}(j)\), then this correlation coefficient is \(\rho_{-}:=s\frac{1-q}{1-qs}\). Our focus will be on the sparse setting where \(p,q=o(1)\) (as \(n\to\infty\)), in which case both \(\rho_{+}\) and \(\rho_{-}\) are asymptotically \((1-o(1))s\), and hence we can regard \(s\) as the _edge correlation parameter_.

**Community recovery.** The goal of community recovery is to recover the latent community labels \(\bm{\sigma}_{*}\) given some (graph) data, such as an SBM \(G\) or correlated SBMs \((G_{1},G_{2})\). There are various notions of community recovery, depending on how close an estimate is to the ground truth \(\bm{\sigma}_{*}\). In this work, we focus on _exact community recovery_, defined as follows: an estimator \(\widehat{\bm{\sigma}}\) achieves exact community recovery if \(\lim_{n\to\infty}\mathbb{P}(|\frac{1}{n}\sum_{i=1}^{n}\widehat{\bm{\sigma}}(i) \bm{\sigma}_{*}(i)|=1)=1\). The absolute value is present in the previous expression since we can only hope to recover the community labels up to a global sign flip; in other words, our goal is to recover the partition of the graph into two communities. A slightly weaker notion, which also appears throughout our work, is _almost exact community recovery_, which holds if \(\lim_{n\to\infty}\mathbb{P}(|\frac{1}{n}\sum_{i=1}^{n}\widehat{\bm{\sigma}}(i )\bm{\sigma}_{*}(i)|=1-o(1))=1\); in other words, this notion tolerates a vanishing fraction of errors. Further weaker notions include partial recovery and weak recovery; since these are not the focus here, we refer to [1] for details.

Different parameter regimes give rise to different challenges and different notions of recovery become most relevant. In the constant average degree regime, that is, when \(p=\frac{a}{n}\) and \(q=\frac{b}{n}\) for some constants \(a\) and \(b\), it is impossible to recovery the communities exactly. Prior works [46, 48, 43] have characterized the information-theoretic threshold and developed efficient algorithms for partial recovery in this regime. On the other hand, if the vertices have polynomially growing degrees, that is, when \(p=n^{-a+o(1)}\) and \(q=n^{-b+o(1)}\) for some constants \(a,b\in[0,1)\), then community recovery is easy as long as \(\liminf_{n\to\infty}|p_{n}/q_{n}-1|>0\) (see [47]).

In this work, we focus on the "bottleneck regime" of logarithmic average degree, which is the bare minimum for the graph to be connected, and which is when exact community recovery is most interesting. In most of the paper we assume that \(p=a\frac{\log n}{n}\) and \(q=b\frac{\log n}{n}\) for some positive constants \(a,b\). For an SBM with two balanced communities and these parameters, there is a sharp information-theoretic threshold for exact community recovery, which is given by \(D_{+}(a,b)=1\), where \(D_{+}(a,b):=(\sqrt{a}-\sqrt{b})^{2}/2\) (see [47, 2, 4, 1]). This quantity is known as the _Chernoff-Hellinger divergence_ in the general \(k\)-community SBM setting with linear size communities [4] and simplifies to the above form in our setting. In other words, when \(D_{+}(a,b)>1\), there exists an estimator \(\widehat{\bm{\sigma}}\) that is computable in polynomial-time and which achieves exact community recovery with high probability. On the other hand, when \(D_{+}(a,b)<1\), exact community recovery is impossible, in the sense that for all estimators \(\widehat{\bm{\sigma}}\) we have that \(\lim_{n\to\infty}\mathbb{P}(|\frac{1}{n}\sum_{i=1}^{n}\widehat{\bm{\sigma}}(i )\bm{\sigma}_{*}(i)|=1)=0\). Moreover, when it is possible to achieve exact community recovery on a single graph, several polynomial-time algorithms have been studied by previous works (e.g., [47, 2]).

**Community recovery and graph matching.** What are the information-theoretic limits for exact community recovery given two correlated SBMs \((G_{1},G_{2})\sim\mathrm{CSBM}(n,a\frac{\log n}{n},b\frac{\log n}{n},s)\)? This question was initiated and partially solved by Racz and Sridhar [57], and subsequently fully solved by Gaudio, Racz, and Sridhar [25]. Without yet going into the details, these works highlight the importance of _graph matching_, that is, the task of recovering the latent matching \(\pi_{*}\) given the two correlated graphs \((G_{1},G_{2})\). In brief, when \(\pi_{*}\) can be perfectly recovered from \((G_{1},G_{2})\), then one can take the union graph \(G_{1}\vee_{\pi_{*}}G_{2}\) of \(G_{1}\) and \(G_{2}\), which is also an SBM, but with a larger edge density,

Figure 1: Schematic illustrating two-community correlated SBMs; see the text for details. (Figure reproduced from [57] with permission.)

which makes community recovery easier. This shows that exact community recovery is possible from \((G_{1},G_{2})\) even in parameter regimes where this is impossible from just a single graph \(G_{1}\) (see [57]).

**Graph matching.** Motivated by the above discussion, we now discuss average-case graph matching and notions of recovery. In general, suppose that \((G_{1},G_{2})\) are two correlated random graphs with \(n\) vertices each and that \(\pi_{*}\) is the underlying latent vertex matching. The goal of graph matching is to output an estimator \(\widehat{\pi}=\widehat{\pi}(G_{1},G_{2})\) that is close to \(\pi_{*}\). There are various notions of recovery depending on how close \(\widehat{\pi}\) is to \(\pi_{*}\); the two most relevant notions are the following. We say that an estimator \(\widehat{\pi}\) achieves _exact graph matching_ if \(\lim_{n\to\infty}\mathbb{P}(\widehat{\pi}=\pi_{*})=1\). We say that an estimator achieves _almost exact graph matching_ if with high probability there exists a subset \(I\subseteq[n]\) with \(|I|=(1-o(1))n\) such that \(\widehat{\pi}|_{I}=\pi_{*}|_{I}\), where \(\pi|_{I}\) denotes the restriction of \(\pi\) to \(I\). In words, almost exact graph matching allows the estimator to make a vanishing fraction of errors.

The graph matching problem has been widely studied, with applications to computer vision [13; 36], computational biology [61], and social networks [56]. In particular, de-anonymizing social networks is possible with graph matching algorithms, which implies that anonymity is not equivalent to privacy [51]. That said, studying the limits of graph matching algorithms--including potential information-computation gaps, as we shall discuss--can help guide data regulators on when to take more actions with regards to data protection, in addition to anonymity.

As discussed in the introductory paragraphs, there has been a large body of recent work on average-case graph matching, both studying correlated Erdos-Renyi random graphs [56; 14; 15; 65; 16; 23; 27; 24; 49; 5; 21; 22; 39; 40; 41; 17; 20; 18] and more general models of correlated random graphs [8; 32; 11; 54; 58; 70; 57; 25; 63; 59; 19; 67; 66; 60; 10]. In particular, Racz and Sridhar [57] determined the fundamental information-theoretic limits for exact graph matching in correlated SBMs: in the logarithmic average degree regime discussed above, this threshold is \(s^{2}\frac{a+b}{2}=1\). However, this result is information-theoretic, and the authors posed the open problem of finding an _efficient_ algorithm for exact graph matching, whenever this is information-theoretically possible.

Our main contribution positively resolves this open problem, giving the first efficient algorithm for graph matching for correlated SBMs with two balanced communities. Our algorithm generalizes the recent breakthrough work of Mao, Wu, Xu, and Yu [41] that developed an efficient graph matching algorithm for correlated Erdos-Renyi graphs. As an application, our results imply novel efficient algorithms and results for community recovery. We now turn to describing our results.

## 3 Main results: Graph matching

Our main theorem for graph matching on correlated SBMs is that there exists a polynomial-time algorithm that can achieve exact matching if \(s^{2}>\alpha\), where \(\alpha\) is Otter's tree counting constant1[55].

Footnote 1: This constant captures the base of the exponential growth of unlabeled rooted trees: the total number of unlabeled rooted trees with \(N\) vertices is \((\alpha+o(1))^{-N}\).

**Theorem 1**.: _Fix constants \(a\neq b>0\) and \(s\in[0,1]\). Let \((G_{1},G_{2})\sim\mathrm{CSBM}(n,a\frac{\log n}{n},b\frac{\log n}{n},s)\). For any \(\varepsilon>0\), if \(s^{2}\geq\alpha+\varepsilon\), then the following holds._

1. _(Almost exact matching)_ _There exists a polynomial-time algorithm that outputs a subset_ \(I\in[n]\) _and a mapping_ \(\widehat{\pi}:I\to[n]\) _such that_ \(\widehat{\pi}=\pi_{*}|_{I}\) _and_ \(|I|=(1-o(1))n\) _with high probability._
2. _(Exact matching)_ _If, in addition,_ \(s^{2}(a+b)/2>1\)_, then there exists a polynomial-time algorithm that outputs a mapping_ \(\widehat{\pi}\) _such that_ \(\lim_{n\to\infty}\mathbb{P}(\widehat{\pi}=\pi_{*})=1\)_._

Several remarks are now in order about the tightness of the main result, an overview of the chandelier counting algorithm when \(a=b\), and the main challenge of our analysis.

**Tightness.** This result is tight whenever \(s^{2}>\alpha\), because \(s^{2}(a+b)/2=1\) is the information-theoretic threshold of exact graph matching given two correlated SBMs \((G_{1},G_{2})\)[57]. When \(s^{2}<\alpha\), it is conjectured that an information-computation gap exists for the correlated Erdos-Renyi graphs [41]. Specifically, by assuming that \(a=b\), it is information-theoretically possible to match correlated Erdos-Renyi graphs exactly if \(s^{2}a>1\)[14; 15; 65]. However, it is believed hard to find a polynomial-time algorithm to do this. In our model with SBMs, which is an extension from Erdos-Renyi graphs, it is also likely hard to find a polynomial-time algorithm when \(s^{2}<\alpha\).

**Signed chandelier counts.** Our theorem extends from the main theorem in Mao et al. [41], which proposed a polynomial-time algorithm that matches the correlated Erdos-Renyi graphs exactly. The algorithm has two main steps: First, construct signature vectors \(\bm{s}_{i}\) and \(\bm{t}_{j}\) for vertices \(i\in[n]\) in \(G_{1}\) and \(j\in[n]\) in \(G_{2}\) by the _signed subgraph counts_ of a specially designed graph class--termed _Chandeliers_--and calculate the weighted inner product of pairs of signature vectors \(\langle\bm{s}_{i},\bm{t}_{j}\rangle\) and match vertices if the inner product value is large enough; Second, use a seeded graph matching algorithm to boost the almost exact graph matching algorithm to exact graph matching. It is natural to adapt this algorithm from correlated Erdos-Renyi graphs to correlated SBMs but the details present non-trivial challenges, as we explain below.

**Main challenge.** The main challenge on correlated SBMs is that signed subgraph counts is no longer a free lunch. Signed subgraph counts is counting the subgraphs on a centralized adjacency matrix, which is first proposed by Bubeck et al. [9] and later commonly used to control the variance of counting statistics. The success of the chandelier counting method relies on the sufficient separation of the two inner product distributions of true and false vertex correspondence. We want to find a way that keeps doing the adjacency matrices centralization possible. Recall that we explore the graph matching motivated by community recovery. Interestingly, the solution to this centralization problem is now the other way around--using a rough community label estimate to help the graph matching. Our main technical contributions are first showing that when there are no error occurs in the community label estimate, the signed chandelier counting can be generalized to correlated SBMs and then show that when the exact community recovery is not possible, the errors introduced in the community label estimation, which is polynomial in \(n\), are actually tolerable for the whole algorithm.

The analysis falls in two cases. If \(sD_{+}(a,b)>1\), then we can achieve exact community recovery on each of the graphs by applying the community recovery algorithm from [47]. In addition, if \(s^{2}\frac{a}{2}>1\), 2 then it suffices to look at each community individually. This is easy and follows in a black-box fashion from [41] (See Section 7). However, on the other side, \(s^{2}\frac{a}{2}<1\), one still needs to use information the community information. Therefore, we need to go through the whole algorithm analysis again in this case. Note that the analysis would work for both regimes with no constraint on \(s^{2}\frac{a}{2}<1\). We plot the black-box regime in _black_ and the non-black-box regime in _green_ in Figure 2.

Footnote 2: For a \(\mathrm{SBM}(n,\frac{a\log n}{n},\frac{b\log n}{n})\), each community, conditioned on its size \(N\approx n/2\), is an Erdős–Renyi graph \(\mathcal{G}(N,\frac{a\log n}{n})\approx\mathcal{G}(N,\frac{a\log n}{2N})\).

The second case is even trickier. If \(sD_{+}(a,b)<1\), by the same algorithm, we can only obtain almost exact correct community labels \(\widehat{\bm{\sigma}}_{A}\) and \(\widehat{\bm{\sigma}}_{B}\) on graph \(G_{1}\) and \(G_{2}\), respectively. We perform adjacency matrix centralization based on \(\widehat{\bm{\sigma}}_{A}\) and \(\widehat{\bm{\sigma}}_{B}\) and show that the error introduced in this step is negligible

Figure 2: Phase diagram for graph matching on \((G_{1},G_{2})\sim\mathrm{CSBM}(n,\frac{a\log n}{n},\frac{b\log n}{n},s)\). The red diagonal line depicts \(a=b\), which is an Erdős–Rényi graph. _Black regions_: exact graph matching is possible and can be done efficiently for each community separately by applying the graph matching algorithm for correlated Erdős–Rényi graphs; _Green regions_: exact graph matching is possible and can be done efficiently; _Light green regions_: exact graph matching is impossible, but almost exact graph matching is possible and can be done efficiently; _Cyan regions_: exact graph matching is possible and can be done efficiently by first recovering the community labels almost exactly; _Yellow regions_: exact graph matching is impossible but almost exact graph matching can be done efficiently by first recovering the community labels almost exactly.

in the sense that the inner-product scores remains sufficiently distinguishable between true pairs (\(j=\pi_{*}(i)\)) and fake pairs (\(j\neq\pi_{*}(i)\)).

## 4 Application: Community recovery

Once matching up the vertices on two correlated graphs, we can combine the information of them onto a union graph and then immediately have an application on community recovery. Our result for community detection is that there exists a polynomial-time algorithm for exact community recovery on correlated SBMs when the squared edge correlation parameter satisfies \(s^{2}>\alpha\).

**Theorem 2**.: _Fix constants \(a\neq b>0\) and \(s\in[0,1]\). Let \((G_{1},G_{2})\sim\mathrm{CSBM}(n,a\frac{\log n}{n},b\frac{\log n}{n},s)\). For any \(\varepsilon>0\), if_

\[s^{2}\geq\alpha+\varepsilon,\quad s^{2}(\frac{a+b}{2})>1,\quad\text{ and}\quad(1-(1-s)^{2})D_{+}(a,b)>1,\]

_then, there exists an estimator \(\widehat{\bm{\sigma}}=\widehat{\bm{\sigma}}(G_{1},G_{2})\) that can be computed in polynomial-time such that \(\lim_{n\to\infty}\mathbb{P}(|\frac{1}{n}\sum_{i=1}^{n}\widehat{\bm{\sigma}}(i) \bm{\sigma}_{*}(i)|=1)=1\)._

Theorem 2 is a direct application of our Theorem 1. The proof mainly follows the Theorem 3.3 in [57], which gives exact community recovery on the union graph of \(G_{1}\) and \(G_{2}\) regarding to the permutation \(\widehat{\pi}\), \(G_{1}\vee_{\widehat{\pi}}G_{2}\). The key difference is that we substitute the maximum a posterior estimator used in the first step with the \(\widehat{\pi}(G_{1},G_{2})\) output by the algorithm used to prove Theorem 1. Figure 3 is a summary of the phase diagram for community recovery determined by this work along with previous works [57; 25], focusing on the exact community recovery and efficiency.

**Remark 1**.: _Consider a more general correlated SBMs with \(K\) correlated graphs \((G_{1},G_{2},\dots,G_{K})\sim\mathrm{CSBM}(n,a\frac{\log n}{n},b\frac{\log n}{ n},s,K)\). Theorem 1 also implies an efficient algorithm for exact community recovery above the exact graph matching threshold for \(K\) correlated SBMs when \(D_{+}(a,b)>\frac{1}{1-(1-s)^{K}}\) (Theorem 3.6 in [57])._

## 5 Algorithm and the overview of the proofs

In this section, we define a few key concepts, give a brief overview of the algorithm, and briefly discuss the proof of Theorem 1 and challenges. See Appendix C for a full version.

**Chandelier.** An \((L,M,K,R,D)\)-chandelier is a rooted tree with \(L\) branches, each of which consists of a path with \(M\) edges (\(M\)-wire), followed by a rooted tree with \(K\) edges (\(K\)-bulb); the \(K\)-bulbs are

Figure 3: Phase diagram for exact community recovery with fixed \(s\) on correlated SBMs. _Green regions_: exact community recovery is possible from \(G_{1}\) alone and can be done efficiently; _Lightgreen regions_: exact community recovery is possible from \((G_{1},G_{2})\) but impossible from \(G_{1}\) alone, exact graph matching can be done efficiently and therefore exact community recovery can be done efficiently; _Violet regions_: exact community recovery is impossible from \(G_{1}\) alone, impossible from \((G_{1},G_{2})\) if \(s^{2}(\frac{a+b}{2})+s(1-s)D_{+}(a,b)<1\) and possible if \(s^{2}(\frac{a+b}{2})+s(1-s)D_{+}(a,b)>1\)[25]. It is unknown whether there exists an efficient algorithm for exact community recovery in this regime.

non-isomorphic to each other, each of them has at most \(R\) automorphisms, and the maximum degree is at most \(D\). For each chandelier \(H\), let \(\mathcal{K}(H)\) denote the set of bulbs of \(H\).

For a rooted tree \(T\), let \(\mathrm{aut}(H)\) denote the number of rooted automorphisms of \(T\) throughout this paper. We abbreviate rooted automorphism as automorphism when it is clear that we are applying it to a chandelier. The number of automorphisms of \(H\) is determined by the automorphisms of its bulbs.

Let \(\mathcal{T}\) denote the family of non-isomorphic \((L,M,K,R,D)\)-chandelier. The family size of chandelier is \(|\mathcal{T}|=\binom{|\mathcal{J}|}{L}\), where \(\mathcal{J}\equiv\mathcal{J}(K,R,D)\) denotes the collection of unlabeled rooted trees with \(K\) edges, at most \(R\) automorphisms, and maximum degree \(D\). Otter [55] showed that the number of unlabeled rooted trees with \(K\) edges (and no constraint on the automorphisms and vertex degrees) is \(|\mathcal{J}(K,\infty,\infty)|=(\alpha+o(1))^{-K}\), where \(\alpha\approx 0.338\). We show that under proper choices of \(R\) and \(D\), we have \(|\mathcal{J}(K,R,D)|=(\alpha+o(1))^{-K}\) in Section C.

**Algorithm overview.** Given \((G_{1},G_{2})\sim\mathrm{CSBM}(n,p,q,s)\). Our algorithm contains mainly three steps. Firstly, we apply the Algorithm 3 (discussed in Section D.3) by Mossel, Neeman, and Sly [47] to obtain almost exact community label estimates for each single graph. Secondly, we calculate the signed chandelier counting [41] based similarity score to give an almost exact graph matching (Algorithm 1 and Algorithm 4). Lastly, we boost the almost exact matching to exact matching by extending the seeded graph matching algorithm [41] on Erdos-Renyi graphs to SBMs (Algorithm 2).

**Subgraph counts.** For an arbitrary weighted adjacency matrix \(M\) of some adjacency matrix \(A\), vertex \(i\in[n]\), and a rooted graph \(H\), we define the _weighted subgraph counts_ on \(M\) as

\[W_{i,H}(M):=\sum_{S(i)\cong H}M_{S},\text{ where }M_{S}:=\prod_{e\in E(S)}M_{e},\]

and \(S(i)\) enumerates subgraphs of the complete graph \(K_{n}\), rooted at \(i\), that are isomorphic to \(H\).

When \(M\) is the adjacency matrix itself, \(W_{i,H}(M)\) is the usual subgraph count, representing the number of subgraphs rooted at \(i\) in \(M\) that are isomorphic to \(H\). When \(M\) is the centralized adjacency matrix \(\overline{A}:=A-\mathbb{E}[A]\), we call \(W_{i,H}(M)\) a signed subgraph count following [9]. However, we do not have access to \(\mathbb{E}[A]\) in many cases. Specifically for SBM, we can estimate \(\mathbb{E}[A]\) through estimating the community labels. We define the _approximately centralized adjacency matrix_ regarding to community label estimate \(\widehat{\bm{\sigma}}\), denoted as \(\overline{A}^{\widehat{\bm{\sigma}}}\), entry-wise as \(\overline{A}^{\widehat{\bm{\sigma}}}_{i,j}=A_{i,j}-p\mathbf{1}_{\widehat{ \bm{\sigma}}[i]=\widehat{\bm{\sigma}}[j]}-q\mathbf{1}_{\widehat{\bm{\sigma}} [i]\neq\widehat{\bm{\sigma}}[j]}\).

Given a family \(\mathcal{H}\) of non-isomorphic rooted graphs, we define the _subgraph count signature_ of vertex \(i\) as \(W_{i}^{\mathcal{H}}(M):=(W_{i,H}(M))_{H\in\mathcal{H}}\).

**Similarity score.** Given a pair of correlated SBMs (\(G_{1},G_{2}\)), we define the similarity score between vertex \(i\) on graph \(G_{1}\) and vertex \(j\) on graph \(G_{2}\) as a weighted inner product between two signatures:

\[\Phi_{ij}:=\langle W_{i}^{\mathcal{T}}(\overline{A}),W_{j}^{\mathcal{T}}( \overline{B})\rangle:=\sum_{H\in\mathcal{T}}\mathrm{aut}(H)W_{i,H}(\overline {A})W_{j,H}(\overline{B}).\]

When we do not have access to \(\overline{A}\) and \(\overline{B}\), we use the approximately centralized adjacency matrices \(\overline{A}^{\widehat{\bm{\sigma}}}\) and \(\overline{B}^{\widehat{\bm{\sigma}}}\). We define the similarity score in a slightly different notation:

\[\Phi^{\widehat{\bm{\sigma}}}_{ij}:=\langle W_{i}^{\mathcal{T}}(\overline{A}^ {\widehat{\bm{\sigma}}_{A}}),W_{j}^{\mathcal{T}}(\overline{B}^{\widehat{\bm{ \sigma}}_{B}})\rangle=\sum_{H\in\mathcal{T}}\mathrm{aut}(H)W_{i,H}(\overline{A} ^{\widehat{\bm{\sigma}}_{A}})W_{j,H}(\overline{B}^{\widehat{\bm{\sigma}}_{B}}).\]

**Almost exact graph matching.** The first part in the analysis is to show that by calculating this similarity score, with an appropriate thresholding strategy, we can match up \((1-o(1))n\) vertices correctly (Theorem 3). The high-level idea is to show that the similarity score distributions are well-separated between true pairs and fake pairs. We expect the similarity score having the following properties, under event \(\mathcal{H}:=\{\frac{n}{2}-n^{\frac{3}{4}}\leq|V^{+}|,|V^{-}|\leq\frac{n}{2}+n ^{\frac{3}{4}}\}\) (to be discussed in Section D.2):

* For true pairs \(j=\pi(i):\) \[\mathbb{E}[\Phi^{\widehat{\bm{\sigma}}}_{i\pi_{\pi}(i)}\mathbf{1}_{\mathcal{H}} ]>0,\quad\mathrm{Var}[\Phi^{\widehat{\bm{\sigma}}}_{ij}\mathbf{1}_{\mathcal{H} }]=o\left(\mathbb{E}[\Phi^{\widehat{\bm{\sigma}}}_{i\pi_{\pi}(i)}\mathbf{1}_ {\mathcal{H}}]^{2}\right),\] (1)
* For fake pairs \(j\neq\pi(i):\) \[\mathbb{E}[\Phi^{\widehat{\bm{\sigma}}}_{ij}\mathbf{1}_{\mathcal{H}}]=o\left( \mathbb{E}[\Phi^{\widehat{\bm{\sigma}}}_{i\pi_{\pi}(i)}\mathbf{1}_{\mathcal{H}} ]\right),\quad\mathrm{Var}[\Phi^{\widehat{\bm{\sigma}}}_{ij}\mathbf{1}_{ \mathcal{H}}]=o\left(\frac{\mathbb{E}[\Phi^{\widehat{\bm{\sigma}}}_{i\pi_{\pi}(i )}\mathbf{1}_{\mathcal{H}}]^{2}}{n^{2}}\right).\] (2)Precisely forming bounds for these moments constitutes the main bulk of the paper. We provide results from Proposition 1 to Proposition 6. Followed by these moment bounds, we have Theorem 3.

**Theorem 3**.: _Fix \(a\neq b>0\) and \(s\in[0,1]\). Let \(p=a\frac{\log n}{n},q=b\frac{\log n}{n}\) and \((G_{1},G_{2})\sim\mathrm{CSBM}(n,p,q,s)\). For any \(\varepsilon>0\), suppose \(s^{2}\geq\alpha+\varepsilon\). There exists positive constants \(C_{1},C_{2},C_{3},C_{4},C_{5}>0\) such that the following holds. Pick \(K,M,L,N,D\) as_

\[L=\frac{C_{1}}{\varepsilon},\quad K=C_{2}\log n,\quad M=\frac{C_{3}K}{\log(ns( p\wedge q))},\quad R=\exp(C_{4}K),\quad D=C_{5}\frac{\log n}{(\log\log n)^{2}}.\] (3)

_Pick an arbitrary \(c\in(0,1)\) and set \(\mu=|\mathcal{T}|n^{N}\rho^{N}\sigma_{\mathrm{eff}}^{2N}\), where \(\sigma_{\mathrm{eff}}^{2}:=(\frac{\sigma_{+}^{2}+\sigma_{-}^{2}}{2})\). Then, Algorithm 1 outputs a set \(I\) with size \((1-o(1))n\) and a mapping \(\widetilde{\pi}\) such that \(\widetilde{\pi}|_{I}=\widetilde{\pi}_{*}|_{I}\) with high probability._

**Proof challenge.** In regime \(sD_{+}(a,b)>1\), the probability of existing one vertex being classified incorrectly is vanishing for Algorithm 3. Therefore, with high probability, \(\widetilde{A}^{\widehat{\boldsymbol{\sigma}}_{A}}=\overline{A}\). If \(sD_{+}(a,b)<1\), then the recovered \(\widehat{\boldsymbol{\sigma}}\) contains errors (polynomial in \(n\)), which will cause some edges being centralized incorrectly and thereby affect the moments calculation.

This phenomenon poses a challenge to the algorithm analysis. We highlight some key points in the context of second moment calculation. For simplicity, we ignore event \(\mathcal{H}\) here. From definition,

\[\mathrm{Var}[\Phi_{ij}^{\widehat{\boldsymbol{\sigma}}}] =\sum_{H,I\in\mathcal{T}}\mathrm{aut}(H)\mathrm{aut}(I)\sum_{S_{ 1}(i),S_{2}(j)\cong H}\sum_{T_{1}(i),T_{2}(j)\cong I}\bigg{(}\mathbb{E}_{ \boldsymbol{\sigma}_{*}}\left[\mathbb{E}[\overline{A}_{S_{1}}^{\widehat{ \boldsymbol{\sigma}}_{A}}\overline{B}_{S_{2}}^{\widehat{\boldsymbol{\sigma} }_{B}}\overline{A}_{T_{1}}^{\widehat{\boldsymbol{\sigma}}_{A}}\overline{B}_{T _{2}}^{\widehat{\boldsymbol{\sigma}}_{B}}\mid\boldsymbol{\sigma}_{*}]\right]\] \[\quad-\mathbb{E}_{\boldsymbol{\sigma}_{*}}\left[\mathbb{E}[ \overline{A}_{S_{1}}^{\widehat{\boldsymbol{\sigma}}_{A}}\overline{B}_{S_{2}}^{ \widehat{\boldsymbol{\sigma}}_{B}}\mid\boldsymbol{\sigma}_{*}]\right]\mathbb{ E}_{\boldsymbol{\sigma}_{*}}\left[\mathbb{E}[\overline{A}_{T_{1}}^{\widehat{ \boldsymbol{\sigma}}_{A}}\overline{B}_{T_{2}}^{\widehat{\boldsymbol{\sigma}}_{ B}}\mid\boldsymbol{\sigma}_{*}]\right]\bigg{)}.\]

Let us define the union graph \(U:=S_{1}\cup S_{2}\cup T_{1}\cup T_{1}\)3. If \(sD_{+}(a,b)>1\), we view \(\overline{A}^{\widehat{\boldsymbol{\sigma}}}\) and \(\overline{B}^{\widehat{\boldsymbol{\sigma}}}\) as \(\overline{A}\) and \(\overline{B}\), respectively. \(\mathbb{E}[\overline{A}_{S_{1}}^{\widehat{\boldsymbol{\sigma}}_{1}}\overline{ B}_{S_{2}}\overline{A}_{T_{1}}\overline{A}_{T_{2}}\mid\boldsymbol{\sigma}_{*}]\neq 0\) only if there exists no edge \(e\in E(U)\) such that it occurs only once among \((S_{1},S_{2},T_{1},T_{2})\). This is because different edges are independent and centralized conditioned on \(\boldsymbol{\sigma}_{*}\).

Footnote 3: Note that \(S_{1}\) and \(T_{1}\) are rooted at \(i\), while \(S_{2}\) and \(T_{2}\) are rooted at \(j\). For \(e=(u,v)\in E(S_{1})\), we say it occurs in \(T_{1}\) if \(e\in E(T_{1})\) and it occurs in \(S_{2}\) (resp. \(T_{2}\)) if \((\boldsymbol{\sigma}_{*}(u),\boldsymbol{\sigma}_{*}(v))\in E(S_{2})\) (resp. \(T_{2}\)).

However, in regime \(sD_{+}(a,b)<1\), \(\mathbb{E}[\overline{A}_{S_{1}}^{\widehat{\boldsymbol{\sigma}}_{A}}\overline {B}_{S_{2}}^{\widehat{\boldsymbol{\sigma}}_{B}}\overline{A}_{T_{1}}^{\widehat{ \boldsymbol{\sigma}}_{A}}\overline{B}_{T_{2}}^{\widehat{\boldsymbol{\sigma}}_{ B}}\mid\boldsymbol{\sigma}_{*}]\neq 0\) even when edges are not occurring multiple times as we have the expectation of \(\overline{A}_{e}^{\widehat{\boldsymbol{\sigma}}_{A}}\) can be non-zero when conditioning on \(\boldsymbol{\sigma}_{*}\) and an estimate \(\widehat{\boldsymbol{\sigma}}_{A}\) that disagrees with \(\boldsymbol{\sigma}_{*}\) on the edge type (i.e., for \(e=(u,v),\boldsymbol{\sigma}_{*}(u)\boldsymbol{\sigma}_{*}(v)\neq\widehat{ \boldsymbol{\sigma}}_{A}(u)\widehat{\boldsymbol{\sigma}}_{A}(v)\)). This not only causes this cross-moments calculation being more complicated, but significantly increasing the possibility of the combinations between \(S_{1},S_{2},T_{1}\), and \(T_{2}\).

The most important high-level idea to properly bound the moments is: the cross-moment conditioning on a specific \(\widehat{\boldsymbol{\sigma}}=(\widehat{\boldsymbol{\sigma}}_{A},\widehat{ \boldsymbol{\sigma}}_{B})\) would be non-trivial if and only if _all edges occurring only once are centralized incorrectly_. Assuming there are \(z\) edges occurring once, we show that the probability that \(\widehat{\boldsymbol{\sigma}}\) satisfying this property is no greater than \(n^{-\frac{z(sD_{+}(a,b)-\varepsilon\log(a/b)/2)}{D}}\) for any \(\varepsilon>0\), by using the definition of \(\mathcal{T}\) and Lemma 8 later in Section K and Section L. It turns out that we require \(n^{-\frac{z(sD_{+}(a,b)-\varepsilon\log(a/b)/2)}{D}}\) to be \(o(\frac{1}{\log^{C}n})\) for some positive constant \(C\) so that (1) and (2) are satisfied.

**Efficient algorithm.** Calculating \(\Phi_{ij}^{\widehat{\boldsymbol{\sigma}}}\) exactly (Algorithm 1) takes quasi-polynomial time as searching for all \(S\cong H\) has time complexity \(n^{\Theta(N)}\). Algorithm 4 in Section F computes an approximated score in polynomial time. Specifically, we follow the color-coding-based similarity score approximation from [41]. The basic idea is coloring the stochastic block model using \(N+1\) colors uniformly at random. Then, we only do signed counts on vertex sets that are colorful with \(N+1\) distinct colors. We show that this is an unbiased estimator of \(\Phi_{ij}^{\widehat{\boldsymbol{\sigma}}}\) and only potentially increase the variance by an additional constant factor in Section F. The result is stated as in Theorem 4.

**Theorem 4**.: _Theorem 3 continues to hold with the color-coding sampled estimation \(\widetilde{\Phi}_{ij}^{\widehat{\boldsymbol{\sigma}}}\) in place of \(\Phi_{ij}^{\widehat{\boldsymbol{\sigma}}}\). Moreover, by Algorithm 4, \(\{\widetilde{\Phi}_{ij}^{\widehat{\boldsymbol{\sigma}}}\}_{i,j\in[n]}\) can be computed in \(O(n^{C})\) for some constant \(C\equiv C(\varepsilon)\) depending only on \(\varepsilon\), where \(\varepsilon\) is from (3)._

**Exact graph matching.** The final step of the algorithm is boosting the almost exact matching to a exact matching. The key idea is exploring the number of common neighbors.

Denote \(\mathrm{N}_{\pi}(i,j)\) as the number of common neighbors of \(i\) and \(j\) under correspondence \(\pi\). The high-level idea is that if \(i\) and \(j\) form a true correspondence, then for a correct partial matching \(\widetilde{\pi}\) on \((1-o(1))n\) vertices, with high probability, \(\mathrm{N}_{\widetilde{\pi}}(i,j)\gtrsim\frac{p^{2}+q^{2}}{2}s^{2}(n+2n^{ \frac{3}{4}})\) under the nice event \(\mathcal{H}\). Therefore, we match up \(i\) and \(j\) if they have more common neighbors than this threshold. Define \(h(x)=x\log x-x+1\). We give the following guarantee.

**Theorem 5**.: _Fix \(a\neq b>0\) and \(s\in[0,1]\). Let \(p=a\frac{\log n}{n},q=b\frac{\log n}{n}\) and \((G_{1},G_{2})\sim\mathrm{CSBM}(n,p,q,s)\). Suppose \(s^{2}(\frac{a+b}{2})\geq 1+\varepsilon\) and \(s^{2}\geq\alpha+\varepsilon\), for some \(\varepsilon>0\). Let \(\gamma\) be the unique solution in \((1,\infty)\) to \(h(\gamma)=\frac{3\log n}{(n-2)pqs^{2}}\). Then, the seeded matching Algorithm 2 with input \(\widehat{\pi}\) and an index set \(I\subset[n],|I|=(1-o(1))n\geq(1-\varepsilon/16)n\) such that \(\widehat{\pi}|_{I}=\pi_{*}\) outputs an exact matching \(\widehat{\pi}=\pi_{*}\) in \(O(n^{3}(p+q)^{2})\) time with probability \(1-o(1)\)._

**Putting these pieces together implies Theorem 1.** From Theorem 4, we know that for \((G_{1},G_{2})\sim\mathrm{CSBM}(n,a\frac{\log n}{n},b\frac{\log n}{n},s)\), \(a\neq b\), if \(s^{2}\geq\alpha+\varepsilon\) for some \(\varepsilon>0\) then there we can match \((1-o(1))n\) vertices correctly and efficiently with high probability. Take the returned \(\widehat{\pi}\) from Algorithm 4 as input of Algorithm 2, then Theorem 5 guarantees that the final output \(\widetilde{\pi}=\pi_{*}\) with high probability.

## 6 Related work

Graph Matching.Correlated Erdos-Renyi graphs were first studied in [56] for social network de-anonymization. The information-theoretic threshold for partial matching was determined by [24; 27] and the information-theoretic threshold for exact graph matching was determined by [14; 15; 65].

Mao et al. [40] proposed the first efficient algorithm that achieves exact graph matching for correlated Erdos-Renyi graphs with average degree \((1+\varepsilon)\log n\leq nq\leq n^{\frac{1}{60}(\log\log n)}\) and constant noise. This algorithm only requires a constant edge correlation (sufficiently close to \(1\)) rather than converging to \(1\), which represents a perfect correlation. Mao et al. [41] followed up with an improved efficient algorithm that achieves exact graph matching for any correlation \(\rho\) satisfying \(\rho^{2}>\alpha\) when \(nq(q+\rho(1-q))\geq(1+\varepsilon)\log n\). It is conjectured that for random graphs of logarithmic average degree, \(\rho^{2}=\alpha\) is the computational threshold [41]. Muratori and Semerjian [50] added a small constant constraint on the maximum vertex degree of a chandelier to improve the runtime, at the expense of having a slightly larger constant \(\widehat{\alpha}\) as the minimum squared correlation requirement.

In the denser regime where \(p=n^{-a+o(1)}\), \(a\in(0,1]\), Ding and Du [17] established a sharp information-theoretic threshold for matching a positive fraction of vertices. Ding and Li [20] also developed an efficient algorithm for exact graph matching whenever the edge correlation is non-vanishing, which goes beyond the Otter's tree counting constant.

Several recent works also go beyond correlated Erdos-Renyi graphs. Wang et al. [64] studied the exact graph matching with additional attribute information on vanishing edge correlation.

Closely related to our work, Yang et al. [67] adopted the binary tree counting algorithm [40] to give an efficient graph matching algorithm for correlated SBMs. However, [67] makes several significant assumptions (which we do not). For one, the algorithm in [67] assumes that the community labels are known. This is a strong assumption which may be unrealistic in practice; moreover, this precludes using graph matching as a tool for improved community recovery. In contrast, we do not assume that community labels are known; in fact, a significant part of our technical work is devoted to dealing with the errors arising from estimating the community labels. Moreover, our graph matching algorithm can be directly applied to improve community recovery, as discussed in Theorem 2 and Section 3. In addition, [67] makes strong assumptions on the parameters, assuming that (1) the average degree is at least \((\log n)^{1.1}\), (2) the SBM has at least \(3\) communities, and (3) the correlation parameter satisfies \(s>1-\varepsilon_{0}\) for some unspecified (small) \(\varepsilon_{0}\). In contrast, our results hold in the most interesting regime of logarithmic average degree and the most natural setting of two balanced communities; moreover, our assumption on \(s\) is also weaker.

Community recovery with side informationBeyond correlated SBMs, there are some other models utilizing side information, from multiple networks [28; 62; 33; 30; 68; 71], additional covariates[7], or both [44, 37]. Multi-layer SBM is first mentioned in [29], which is generated as following: first, generate the community labels for all vertices and fix them for all layers; second, form edges on each layer based on the community labels. Typically, different layers in a multi-layer SBM are conditionally independent given the shared community labels. In addition, several works [44, 37] also encode community membership correlated covariates onto each node. Aside from the multi-layer SBM, Braun and Sugiyama [7] recently studied community detection on a novel variation of SBM whose edges are attached with vectorial covariates.

## 7 Discussion and future work

Our main contribution in this paper is to give the first efficient algorithm for exact graph matching for correlated SBMs with two balanced communities, as well as a rigorous proof of its correctness (Theorem 1). We also discuss novel applications to community recovery (Theorem 2). At the same time, our work raises many interesting questions for future research, which we discuss here.

**Optimal runtime.** While our graph matching algorithm is efficient, it would be desirable to understand the optimal running time that can be achieved. Mao, Rudelson, and Tikhomirov [40] gave an efficient algorithm for matching correlated Erdos-Renyi graphs with runtime \(n^{2+o(1)}\); the main drawback is that this algorithm requires the correlation parameter to satisfy \(s>1-\varepsilon_{0}\) for some unspecified (small) \(\varepsilon_{0}>0\). Nonetheless, it would be interesting to generalize this algorithm to correlated SBMs and the techniques developed in our work may be useful to do so. In very recent (and concurrent) work, Muratori and Semerjian [50] gave faster algorithms for matching correlated Erdos-Renyi graphs by introducing a constraint on the maximum degree of a chandelier, at the expense of strengthening the condition \(s^{2}>\alpha\) to \(s^{2}>\widehat{\alpha}\) for some \(\widehat{\alpha}>\alpha\). Exploring the connections between our work and theirs, and generalizing their ideas to correlated SBMs, are of interest.

**Information-computation gap.** An important assumption throughout this work is that the correlation parameter satisfies \(s^{2}>\alpha\). We believe that this is inherently necessary and that there is no efficient algorithm (in the logarithmic average degree regime) when \(s^{2}<\alpha\). At the same time, exact graph matching is information-theoretically possible whenever \(s^{2}(a+b)/2>1\), so there is a conjectured information-computation gap. This mirrors the conjecture in [41] for Erdos-Renyi graphs; see also [18] for the low-degree hardness results on the correlation detection and [10] for the very recent low-degree hardness results on testing a pair of correlated stochastic block models against a pair of independent Erdos-Renyi graphs.

**Efficient exact community recovery when exact graph matching is not possible.** Gaudio, Racz, and Sridhar [25] determined the information-theoretic threshold for exact community recovery on correlated SBMs, in particular showing that there is a regime when this is possible even though (1) this is impossible with a single graph and also (2) exact graph matching is impossible. It remains unknown whether this can be done efficiently in this regime. We believe that this is possible, and our work is an important starting point for this question, yet additional ideas are needed to understand the subtle interplay between graph matching and community recovery in this regime.

**Sparser and denser regimes.** Our work focuses on the most interesting regime where the average degree is logarithmic in \(n\); it is worth understanding other regimes too. In particular, the chandelier counting algorithm by Mao et al. [41] gives almost exact graph matching whenever the average degree diverges. In our Theorem 1 we require that the average degree diverges logarithmically for the corresponding result, so that the error rate for community recovery estimate is polynomially small in \(n\). It would be interesting to overcome this technical barrier and extend the analysis to this sparser regime. Denser regimes are easier to understand. A close inspection of our analysis shows that it also works when the average degree diverges as a (small) polynomial in \(n\); in even denser regimes, the community partition can be recovered exactly and efficiently whenever \(\liminf_{n\to\infty}|p_{n}/q_{n}-1|>0\) (see [47]) and then the graph matching algorithm in [41] can be applied in a black-box fashion.

**General block models.** We focused here on the simplest case of SBMs with two balanced communities. It is of great interest to develop efficient graph matching algorithms in the general block model with \(k\) communities, whenever this is possible. Recently, Yang and Chung [66] determined the information-theoretic threshold for exact graph matching in the \(k\)-community symmetric SBM, extending the results of Racz and Sridhar [57]. We conjecture that substituting the community recovery algorithm used in our work with the degree-profiling algorithm by Abbe and Sandon [4] gives an efficient algorithm for graph matching in this more general setting, assuming again that \(s^{2}>\alpha\).

## Acknowledgements

We thank Julia Gaudio, Anirudh Sridhar, Yihong Wu, and Jiaming Xu for helpful discussions. We also thank anonymous reviewers for constructive feedback. S.C. was supported in part by the Institute for Data, Econometrics, Algorithms, and Learning (IDEAL), funded through the National Science Foundation TRIPODS Phase II program (NSF grant ECCS 2216970).

## References

* [1] Emmanuel Abbe. Community Detection and Stochastic Block Models: Recent Developments. _Journal of Machine Learning Research_, 18(177):1-86, 2018.
* [2] Emmanuel Abbe, Afonso S. Bandeira, and Georgina Hall. Exact Recovery in the Stochastic Block Model. _IEEE Transactions on Information Theory_, 62(1):471-487, 2016.
* [3] Emmanuel Abbe, Jianqing Fan, Kaizheng Wang, and Yiqiao Zhong. Entrywise eigenvector analysis of random matrices with low expected rank. _The Annals of Statistics_, 48(3):1452-1474, 2020.
* [4] Emmanuel Abbe and Colin Sandon. Community detection in general stochastic block models: Fundamental limits and efficient algorithms for recovery. In _2015 IEEE 56th Annual Symposium on Foundations of Computer Science (FOCS)_, pages 670-688. IEEE, 2015.
* [5] Boaz Barak, Chi-Ning Chou, Zhixian Lei, Tselil Schramm, and Yueqi Sheng. (Nearly) Efficient Algorithms for the Graph Matching Problem on Correlated Random Graphs. In _Advances in Neural Information Processing Systems (NeurIPS)_, volume 32, pages 9190-9198, 2019.
* [6] Terry Beyer and Sandra Mitchell Hedetniemi. Constant Time Generation of Rooted Trees. _SIAM Journal on Computing_, 9(4):706-712, 1980.
* [7] Guillaume Braun and Masashi Sugiyama. Vec-sbm: Optimal community detection with vectorial edges covariates. In _Proceedings of The 27th International Conference on Artificial Intelligence and Statistics (AISTATS)_, volume 238 of _Proceedings of Machine Learning Research (PMLR)_, pages 532-540, 2024.
* [8] Karl Bringmann, Tobias Friedrich, and Anton Krohmer. De-anonymization of heterogeneous random graphs in quasilinear time. In _Proceedings of the 22nd Annual European Symposium on Algorithms (ESA)_, pages 197-208, 2014.
* [9] Sebastien Bubeck, Jian Ding, Ronen Eldan, and Miklos Z Racz. Testing for high-dimensional geometry in random graphs. _Random Structures & Algorithms_, 49(3):503-532, 2016.
* [10] Guanyi Chen, Jian Ding, Shuyang Gong, and Zhangsong Li. A computational transition for detecting correlated stochastic block models by low-degree polynomials. Preprint available at https://arxiv.org/abs/2409.00966, 2024.
* [11] Carla-Fabiana Chiasserini, Michele Garetto, and Emilio Leonardi. Social Network De-Anonymization Under Scale-Free User Relations. _IEEE/ACM Transactions on Networking_, 24(6):3756-3769, 2016.
* [12] Charles J. Colbourn and Kellogg S. Booth. Linear Time Automorphism Algorithms for Trees, Interval Graphs, and Planar Graphs. _SIAM Journal on Computing_, 10(1):203-225, 1981.
* [13] Donatello Conte, Pasquale Foggia, Carlo Sansone, and Mario Vento. Thirty years of graph matching in pattern recognition. _International Journal of Pattern Recognition and Artificial Intelligence_, 18(03):265-298, 2004.
* [14] Daniel Cullina and Negar Kiyavash. Improved Achievability and Converse Bounds for Erdos-Renyi Graph Matching. In _ACM SIGMETRICS_, volume 44, pages 63-72, 2016.
* [15] Daniel Cullina and Negar Kiyavash. Exact alignment recovery for correlated Erdos-Renyi graphs. Preprint available at https://arxiv.org/abs/1711.06783, 2018.

* [16] Daniel Cullina, Negar Kiyavash, Prateek Mittal, and H. Vincent Poor. Partial Recovery of Erdos-Renyi Graph Alignment via \(k\)-Core Alignment. In _ACM SIGMETRICS Performance Evaluation Review_, volume 48, pages 99-100. ACM, 2020.
* [17] Jian Ding and Hang Du. Matching recovery threshold for correlated random graphs. _The Annals of Statistics_, 51(4):1718-1743, 2023.
* [18] Jian Ding, Hang Du, and Zhangsong Li. Low-Degree Hardness of Detection for Correlated Erdos-Renyi Graphs. Preprint available at https://arxiv.org/abs/2311.15931, 2023.
* [19] Jian Ding, Yumou Fei, and Yuanzheng Wang. Efficiently matching random inhomogeneous graphs via degree profiles. Preprint available at https://arxiv.org/abs/2310.10441, 2023.
* [20] Jian Ding and Zhangsong Li. A polynomial-time iterative algorithm for random graph matching with non-vanishing correlation. Preprint available at https://arxiv.org/abs/2306.00266, 2023.
* [21] Jian Ding, Zongming Ma, Yihong Wu, and Jiaming Xu. Efficient random graph matching via degree profiles. _Probability Theory and Related Fields_, 179(1):29-115, 2021.
* [22] Zhou Fan, Cheng Mao, Yihong Wu, and Jiaming Xu. Spectral graph matching and regularized quadratic relaxations: Algorithm and theory. In _Proceedings of the 37th International Conference on Machine Learning (ICML)_, volume 119 of _Proceedings of Machine Learning Research (PMLR)_, pages 2985-2995, 2020.
* [23] Luca Ganassali and Laurent Massoulie. From tree matching to sparse graph alignment. In _Proceedings of the 33rd Conference on Learning Theory (COLT)_, volume 125 of _Proceedings of Machine Learning Research (PMLR)_, pages 1633-1665, 2020.
* [24] Luca Ganassali, Laurent Massoulie, and Marc Lelarge. Impossibility of Partial Recovery in the Graph Alignment Problem. In _Proceedings of the 34th Conference on Learning Theory (COLT)_, volume 134 of _Proceedings of Machine Learning Research (PMLR)_, pages 2080-2102, 2021.
* [25] Julia Gaudio, Miklos Z. Racz, and Anirudh Sridhar. Exact community recovery in correlated stochastic block models. In _Proceedings of Thirty Fifth Conference on Learning Theory (COLT)_, volume 178 of _Proceedings of Machine Learning Research_, pages 2183-2241. PMLR, 02-05 Jul 2022.
* [26] William M.Y. Goh and Eric Schmutz. Unlabeled Trees: Distribution of the Maximum Degree. _Random Structures & Algorithms_, 5(3):411-440, 1994.
* [27] Georgina Hall and Laurent Massoulie. Partial recovery in the graph alignment problem. _Operations Research_, 71(1):259-272, 2023.
* [28] Qiuyi Han, Kevin Xu, and Edoardo Airoldi. Consistent estimation of dynamic and multi-layer block models. In _International Conference on Machine Learning (ICML)_, volume 37 of _Proceedings of Machine Learning Research (PMLR)_, pages 1511-1520, 2015.
* [29] Paul W. Holland, Kathryn Blackmond Laskey, and Samuel Leinhardt. Stochastic blockmodels: First steps. _Social Networks_, 5(2):109-137, 1983.
* [30] Yaofang Hu and Wanjie Wang. Network-adjusted covariates for community detection. _Biometrika_, page asae011, 2024.
* [31] Svante Janson, Tomasz Luczak, and Andrzej Rucinski. _Random Graphs_. John Wiley & Sons, 2000.
* [32] Nitish Korula and Silvio Lattanzi. An efficient reconciliation algorithm for social networks. _Proceedings of the VLDB Endowment_, 7(5):377-388, 2014.
* [33] Jing Lei, Kehui Chen, and Brian Lynch. Consistent community detection in multi-layer network data. _Biometrika_, 107(1):61-73, 2020.

* [34] Vince Lyzinski. Information recovery in shuffled graphs via graph matching. _IEEE Transactions on Information Theory_, 64(5):3254-3273, 2018.
* [35] Vince Lyzinski, Daniel L. Sussman, Donniell E. Fishkind, Henry Pao, Li Chen, Joshua T. Vogelstein, Youngser Park, and Carey E. Priebe. Spectral clustering for divide-and-conquer graph matching. _Parallel Computing_, 47:70-87, 2015.
* [36] Jiayi Ma, Xingyu Jiang, Aoxiang Fan, Junjun Jiang, and Junchi Yan. Image matching from handcrafted to deep features: A survey. _International Journal of Computer Vision_, 129:23-79, 2021.
* [37] Zongming Ma and Sagnik Nandy. Community detection with contextual multilayer networks. _IEEE Transactions on Information Theory_, 69(5):3203-3239, 2023.
* [38] Konstantin Makarychev, Rajsekar Manokaran, and Maxim Sviridenko. Maximum quadratic assignment problem: Reduction from maximum label cover and lp-based approximation algorithm. In _International Colloquium on Automata, Languages, and Programming (ICALP)_, pages 594-604. Springer, 2010.
* [39] Cheng Mao, Mark Rudelson, and Konstantin Tikhomirov. Random Graph Matching with Improved Noise Robustness. In _Proceedings of the 34th Conference on Learning Theory (COLT)_, volume 134 of _Proceedings of Machine Learning Research (PMLR)_, pages 3296-3329, 2021.
* [40] Cheng Mao, Mark Rudelson, and Konstantin Tikhomirov. Exact matching of random graphs with constant correlation. _Probability Theory and Related Fields_, 186:327-389, 2023.
* [41] Cheng Mao, Yihong Wu, Jiaming Xu, and Sophie H. Yu. Random Graph Matching at Otter's Threshold via Counting Chandeliers. In _Proceedings of the 55th Annual ACM Symposium on Theory of Computing (STOC)_, pages 1345-1356, 2023.
* [42] Cheng Mao, Yihong Wu, Jiaming Xu, and Sophie H. Yu. Testing network correlation efficiently via counting trees. _The Annals of Statistics_, to appear, 2024+.
* [43] Laurent Massoulie. Community detection thresholds and the weak Ramanujan property. In _Proceedings of the 46th Annual ACM Symposium on Theory of Computing (STOC)_, pages 694-703. ACM, 2014.
* [44] Vaishakhi Mayya and Galen Reeves. Mutual information in community detection with covariate information and correlated networks. In _2019 57th Annual Allerton Conference on Communication, Control, and Computing (Allerton)_, pages 602-607. IEEE, 2019.
* [45] Michael Mitzenmacher and Eli Upfal. _Probability and Computing: Randomized Algorithms and Probabilistic Analysis_. Cambridge University Press, 2005.
* [46] Elchanan Mossel, Joe Neeman, and Allan Sly. Stochastic block models and reconstruction. _arXiv preprint arXiv:1202.1499_, 2012.
* [47] Elchanan Mossel, Joe Neeman, and Allan Sly. Consistency thresholds for the planted bisection model. In _Proceedings of the forty-seventh annual ACM symposium on Theory of computing_, pages 69-75, 2015.
* [48] Elchanan Mossel, Joe Neeman, and Allan Sly. A proof of the block model threshold conjecture. _Combinatorica_, 38(3):665-708, 2018.
* [49] Elchanan Mossel and Jiaming Xu. Seeded graph matching via large neighborhood statistics. _Random Structures & Algorithms_, 57(3):570-611, 2020.
* [50] Andrea Muratori and Guilhem Semerjian. Faster algorithms for the alignment of sparse correlated Erdos-Renyi random graphs. Preprint available at https://arxiv.org/abs/2405.08421, 2024.
* [51] Arvind Narayanan and Vitaly Shmatikov. De-anonymizing social networks. In _Proceedings of the 30th IEEE Symposium on Security and Privacy_, pages 173-187. IEEE Computer Society, 2009.

* [52] Ryan O'Donnell, John Wright, Chenggang Wu, and Yuan Zhou. Hardness of robust graph isomorphism, lasserre gaps, and asymmetry of random graphs. In _Proceedings of the Twenty-Fifth Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)_, pages 1659-1677. SIAM, 2014.
* [53] Christoffer Olsson and Stephan Wagner. Automorphisms of Random Trees. In _33rd International Conference on Probabilistic, Combinatorial and Asymptotic Methods for the Analysis of Algorithms (AofA 2022)_, volume 225 of _Leibniz International Proceedings in Informatics (LIPIcs)_, pages 16:1-16:16. Schloss Dagstuhl-Leibniz-Zentrum fur Informatik, 2022.
* [54] Efe Onaran, Siddharth Garg, and Elza Erkip. Optimal de-anonymization in random graphs with community structure. In _2016 50th Asilomar Conference on Signals, Systems and Computers_, pages 709-713. IEEE, 2016.
* [55] Richard Otter. The Number of Trees. _Annals of Mathematics_, 49(3):583-599, 1948.
* [56] Pedram Pedarsani and Matthias Grossglauser. On the privacy of anonymized networks. In _Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)_, pages 1235-1243, 2011.
* [57] Miklos Z. Racz and Anirudh Sridhar. Correlated Stochastic Block Models: Exact Graph Matching with Applications to Recovering Communities. In _Advances in Neural Information Processing Systems (NeurIPS)_, volume 34, pages 22259-22273, 2021.
* [58] Miklos Z. Racz and Anirudh Sridhar. Correlated randomly growing graphs. _The Annals of Applied Probability_, 32(2):1058-1111, 2022.
* [59] Miklos Z. Racz and Anirudh Sridhar. Matching Correlated Inhomogeneous Random Graphs using the \(k\)-core Estimator. In _2023 IEEE International Symposium on Information Theory (ISIT)_, pages 2499-2504, 2023.
* [60] Miklos Z. Racz and Jifan Zhang. Harnessing Multiple Correlated Networks for Exact Community Recovery. In _Advances in Neural Information Processing Systems (NeurIPS)_, volume 38, 2024.
* [61] Rohit Singh, Jinbo Xu, and Bonnie Berger. Global alignment of multiple protein interaction networks with application to functional orthology detection. _Proceedings of the National Academy of Sciences_, 105(35):12763-12768, 2008.
* [62] Toni Valles-Catala, Francesco A. Massucci, Roger Guimera, and Marta Sales-Pardo. Multilayer Stochastic Block Models Reveal the Multilayer Structure of Complex Networks. _Physical Review X_, 6(1):011036, 2016.
* [63] Haoyu Wang, Yihong Wu, Jiaming Xu, and Israel Yolou. Random Graph Matching in Geometric Models: the Case of Complete Graphs. In _Proceedings of the 35th Conference on Learning Theory (COLT)_, volume 178 of _Proceedings of Machine Learning Research (PMLR)_, pages 3441-3488, 2022.
* [64] Ziao Wang, Weina Wang, and Lele Wang. Efficient Algorithms for Attributed Graph Alignment with Vanishing Edge Correlation. In _Proceedings of the 37th Conference on Learning Theory (COLT)_, volume 247 of _Proceedings of Machine Learning Research (PMLR)_, pages 4889-4890, 2024.
* [65] Yihong Wu, Jiaming Xu, and Sophie H. Yu. Settling the Sharp Reconstruction Thresholds of Random Graph Matching. _IEEE Transactions on Information Theory_, 68(8):5391-5417, 2022.
* [66] Joonhyuk Yang and Hye Won Chung. Graph matching in correlated stochastic block models for improved graph clustering. In _Proceedings of the 2023 59th Annual Allerton Conference on Communication, Control, and Computing (Allerton)_, pages 1-8. IEEE, 2023.
* [67] Joonhyuk Yang, Dongpil Shin, and Hye Won Chung. Efficient Algorithms for Exact Graph Matching on Correlated Stochastic Block Models with Constant Correlation. In _Proceedings of the 40th International Conference on Machine Learning (ICML)_, volume 202 of _Proceedings of Machine Learning Research (PMLR)_, pages 39416-39452, 2023.

* [68] Xiaodong Yang, Buyu Lin, and Subhabrata Sen. Fundamental limits of community detection from multi-view data: multi-layer, dynamic and partially labeled block models. Preprint available at https://arxiv.org/abs/2401.08167, 2024.
* [69] Lyudmila Yartseva and Matthias Grossglauser. On the Performance of Percolation Graph Matching. In _Proceedings of the First ACM Conference on Online Social Networks (COSN)_, pages 119-130, 2013.
* [70] Liren Yu, Jiaming Xu, and Xiaojun Lin. The Power of \(D\)-hops in Matching Power-Law Graphs. _Proceedings of the ACM on Measurement and Analysis of Computing Systems_, 5(2):1-43, 2021.
* [71] Jingnan Zhang, Junhui Wang, and Xueqin Wang. Consistent community detection in inter-layer dependent multi-layer networks. _Journal of the American Statistical Association_, pages 1-11, 2024.

Organization

The rest of this paper is organized as follows. In Section B, we give some notations used throughout. In Section C, we define the similarity score of a pair of vertices and give the formal proof of Theorem 1 based on Theorem 3 (Almost exact graph matching), Theorem 4 (Efficient algorithm for almost exact graph matching), and Theorem 5 (Exact graph matching by seeded graph matching). In Section D, we talk about some preliminaries: tail bounds, nice events, a tree node assigning sub-problem, an automorphism inequality for trees, and the calculation for cross-moments. These results will be repeatedly used in the following sections. In Section E, Section F, and Section G, we present the proofs for Theorem 3, Theorem 4, and Theorem 5, respectively. Section F and Section G are self-contained, while Section E contains several propositions whose proofs are deferred and which make up the remainder of the paper.

In Section E, we introduce six additional Propositions to show that under two different cases--namely, \(sD_{+}(a,b)\geq 1\) and \(sD_{+}(a.b)<1\)--the mean and variance of the similarity score are properly controlled. Specifically, if \(sD_{+}(a,b)\geq 1\), then Proposition 1 gives the mean calculation of the similarity score, while Proposition 2 and Proposition 3 are about the variance calculation of the similarity score for true pairs and fake pairs of vertices. If \(sD_{+}(a,b)<1\), then Proposition 4 gives the mean calculation of the similarity score, while Proposition 5 and Proposition 6 are about the variance calculation of the similarity score for true pairs and fake pairs of vertices. The proofs of Proposition 1, Proposition 2, Proposition 3, Proposition 4, Proposition 5, and Proposition 6 are presented in Section H, Section I, Section J, Section K, Section L, and Section M, respectively.

## Appendix B Notation

For any graph \(G=(V,E)\), we denote \(E(G)\) as the edge set and \(V(G)\) as the vertex set. We let \(e(G):=|E(G)|\) denote the number of edges of graph \(G\) and \(v(G):=|V(G)|\) denote the number of vertices in graph \(G\). We define the excess of graph \(G\) as \(e(G)-v(G)\), the difference between the number of edges and the number of vertices of \(G\).

Consider an arbitrary graph where vertices are equipped with two possible community labels \(\{+1,-1\}\), we denote \(V^{+}\) as the set of vertices with community label \(+1\), \(V^{-}\) as the set of vertices with community label \(-1\), \(\mathcal{N}(v)\) as the set vertices that are neighbors of \(v\).

Let \(\pi\) be a permutation on \([n]\), \((G_{1},G_{2})\sim\mathrm{CSBM}(n,p,q,s)\). Let \(A\) (resp. \(B\)) be the adjacency matrix of \(G_{1}\) (resp. \(G_{2}\)). Let \(\overline{A}:=A-\mathbb{E}[A]\) (resp. \(\overline{B}\)) be the centralized adjacency matrix. We further define the approximately centralized adjacency matrix with respect to community label estimate \(\widehat{\bm{\sigma}}\) as \(\overline{A}^{\widehat{\bm{\sigma}}_{A}}:=A-E_{A}\), where \(E_{A}\) is an \(n\times n\) matrix whose \((i,j)\)-th entry is \(p\) if \(\widehat{\bm{\sigma}}(i)=\widehat{\bm{\sigma}}(j)\) and \(q\) otherwise.4

Footnote 4: See Section K for illustrations and more discussions on approximately centralized adjacency matrices.

We denote \(G_{1}\vee_{\pi}G_{2}\) as the union graph with respect to \(\pi\), such that \((i,j)\in E(G_{1}\vee_{\pi}G_{2})\) if and only if \((i,j)\in E(G_{1})\) or \((\pi(i),\pi(j))\in E(G_{2})\). We denote \(G_{1}\wedge_{\pi}G_{2}\) as the intersection graph with respect to \(\pi\), such that \((i,j)\in E(G_{1}\wedge_{\pi}G_{2})\) if and only if \((i,j)\in E(G_{1})\) and \((\pi(i),\pi(j))\in E(G_{2})\).

We denote the variance of in-community edges \(\sigma_{+}^{2}:=sp(1-sp)\) and the variance of cross-community edges as \(\sigma_{-}^{2}:=sq(1-sq)\). Denote the correlation for in-community edges and cross-community edges as \(\rho_{+}\) and \(\rho_{-}\), respectively. In addition, we define \(\rho:=\frac{\rho_{+}+\rho_{-}}{2}\). Consider the average degree being logarithmic in the number of vertices, then for some constants \(a,b>0\), \(p=\frac{a\log n}{n}\), \(q=\frac{b\log n}{n}\), \(\rho=(1+\Theta(\frac{\log n}{n}))\rho_{+}=(1+\Theta(\frac{\log n}{n}))\rho_{-} =(1+\Theta(\frac{\log n}{n}))s\).5

Footnote 5: For arbitrarily small constant \(\varepsilon>0\), there exists \(n\) large enough, such that \(\rho^{2}\geq\alpha+\varepsilon\) if and only if \(s^{2}\geq\alpha+\varepsilon\).

Throughout the paper, we use standard asymptotic notation \(O(\cdot),\Omega(\cdot),\Theta(\cdot),o(\cdot),\omega(\cdot)\). Any limitation is for \(n\to\infty\) without special explanations. For real numbers \(x,y\), we define \(x\lor y:=\max\{x,y\}\) and \(x\wedge y:=\min\{x,y\}\). In this paper, \(\log\) is natural logarithmic function (with base \(e\)). Further notation is introduced in the following section which details the algorithms.

Proof overview and proof of Theorem 1

### Chandelier

A line of works convert the graph matching problem from quadratic assumption to linear assignment by creating a signature vector \(\bm{s}_{i}\) for each vertex \(i\in[n]\), followed by calculating the similarity score \(\Phi_{ij}=\langle\bm{s}_{i}^{(1)},\bm{s}_{j}^{(2)}\rangle\) of all possible pairs of signatures on two graphs. Recently, Mao et al. [41] proposed a special tree family \(\mathcal{T}\), Chandelier, that shows a result of efficient graph matching under constant correlation.

**Definition 1** (\((L,M,K,R)\)-chandelier[41]).: _An \((L,M,K,R)\)-chandelier is a rooted tree with \(L\) branches, each of which consists of a path with \(M\) edges (\(M\)-wire), followed by a rooted tree with \(K\) edges (\(K\)-bulb); the \(K\)-bulbs are non-isomorphic to each other and each of them has at most \(R\) automorphisms._

In this paper, we give an alternative definition of chandelier with five tuple. The first four parameters remain the same as \((L,M,K,R)\)-chandelier. The last parameter \(D\) stands for the maximum degree of vertices on this chandelier. We explain the necessity of controlling \(D\) in the proof challenge.

**Definition 2** (\((L,M,K,R,D)\)-chandelier).: _An \((L,M,K,R,D)\)-chandelier is a rooted tree with \(L\) branches, each of which consists of a path with \(M\) edges (\(M\)-wire), followed by a rooted tree with \(K\) edges (\(K\)-bulb); the \(K\)-bulbs are non-isomorphic to each other, each of them has at most \(R\) automorphisms, and the degree of each vertex is at most \(D\)._

For each chandelier \(H\), let \(\mathcal{K}(H)\) denote the set of bulbs of \(H\). For a rooted tree \(T\), let \(\mathrm{aut}(H)\) denote the number of rooted automorphisms of \(T\) throughout this paper. We abbreviate rooted automorphism as automorphism when it is clear that we are applying it to a chandelier. The number of automorphisms of \(H\) is determined by the automorphisms of its bulbs. Because all bulbs are non-isomorphic to each other,

\[\mathrm{aut}(H)=\prod_{\mathcal{B}\in\mathcal{K}(H)}\mathrm{aut}(\mathcal{B}).\] (4)

Let \(\mathcal{T}\) denote the family of non-isomorphic \((L,M,K,R,D)\)-chandelier. The family size of chandelier is \(|\mathcal{T}|=\binom{|\mathcal{T}|}{L}\), where \(\mathcal{J}\equiv\mathcal{J}(K,R,D)\) denotes the collection of unlabeled rooted trees with \(K\) edges, at most \(R\) automorphisms, and maximum degree \(D\).

Otter [55] showed that the number of unlabeled rooted trees with \(K\) edges (and no constraint on the automorphisms and vertex degrees) is \(|\mathcal{J}(K,\infty,\infty)|=(\alpha+o(1))^{-K}\), where \(\alpha\approx 0.338\). We show that under proper choices of \(R\) and \(D\), we have \(|\mathcal{J}(K,R,D)|=(\alpha+o(1))^{-K}\) through the following two Lemmas.

**Lemma 1**.: _Let \(K\) be the number of vertices on a unlabeled rooted tree, \(C^{\prime}>\frac{1}{\log(1/\alpha)}\approx 0.9227\), \(D\geq C^{\prime}\log K\). As \(K\to\infty\),_

\[\frac{|\mathcal{J}(K,\infty,D)|}{|\mathcal{J}(K,\infty,\infty)|}=1-o(1).\] (5)

Proof.: Otter [55] characterized that \(\frac{|\mathcal{J}(K,\infty,D)|}{|\mathcal{J}(K,\infty,\infty)|}\asymp\frac{ \alpha_{D}^{-n}}{\alpha^{-n}}\), where \(\alpha_{D}\) is the radius of convergence for the generating function of the number of unlabeled rooted trees whose maximum vertex degree less than or equal to \(D\). Goh and Schumutz [26] (Theorem 7) showed the following property: as \(D\to\infty\), for some constant \(C>0\), \(\alpha_{D}=\alpha+C\alpha^{D}+o(\alpha^{D})\). Immediately we can see that \(\frac{|\mathcal{J}(K,\infty,D)|}{|\mathcal{J}(K,\infty,\infty)|}=(1+O(\alpha^ {D}))^{-K}=1-o(1)\) if \(K\alpha^{D}\to 0\). Let \(C^{\prime}>\frac{1}{\log(1/\alpha)}\), choosing \(D\geq C^{\prime}\log K\) satisfies \(K\alpha^{D}\to 0\). 

**Lemma 2**.: _Let \(K\) be the number of vertices on a unlabeled rooted tree, \(C\) be a constant and choose \(R=\exp(CK)\). For sufficiently large \(C\) and \(K\to\infty\),_

\[\frac{|\mathcal{J}(K,R,\infty)|}{|\mathcal{J}(K,\infty,\infty)|}=1-o(1).\] (6)Proof.: Olsson and Wagner [53] (Theorem 2) showed a central limit theorem result for the number of automorphism on unlabeled rooted trees: \(\frac{1}{\sqrt{K}}(\log\operatorname{aut}(H_{K})-\mu K)\to\mathcal{N}(0,\sigma^{2})\) as \(K\to\infty\), where \(H_{K}\) is a uniform random unlabeled rooted tree with \(K\) edges and \(\mu\approx 0.137,\sigma^{2}\approx 0.197\). This implies that for some constant \(C>\mu\) and \(R=\exp(CK)\), \(\operatorname{aut}(H_{K})<R\) with high probability. 

Putting together Lemma 1 and Lemma 2, and choosing \(R\) and \(D\) as specified, we have that \(|\mathcal{J}(K,R,D)|=(1-o(1))|\mathcal{J}(K,\infty,\infty)|=(\alpha+o(1))^{-K}\). Let \(\beta\) denote a universal constant such that \(|\mathcal{J}|\leq\beta^{K}\). We take \(\beta=\alpha^{-1}\).

### Algorithm overview

Given \((G_{1},G_{2})\sim\operatorname{CSBM}(n,p,q,s)\). Our algorithm contains mainly three steps. Firstly, we apply the algorithm by Mossel, Neeman, and Sly [47] to obtain almost exact community label estimates for each single graph. Secondly, we calculate the signed chandelier counting [41] based similarity score to give an almost exact graph matching. Lastly, we boost the almost exact matching to exact matching by extending the seeded graph matching algorithm [41] on Erdos-Renyi graphs to stochastic block models.

**Almost exact community recovery.** Obtaining community label estimates for both graph \(G_{1}\) and \(G_{2}\) is the first step of our algorithm. This is necessary for centralizing the adjacency matrices for the signed subgraph counts afterwards. We expect the following properties from the community recovery algorithm:

1. gives almost exact recovery (down to the information-theoretic threshold, which is \(s^{2}(a+b)=1\) in the correlated SBMs with two balanced communities [57]);
2. gives an error rate for each vertex of inverse-polynomial;
3. gives error rates on different vertices that are approximately independent.

The community recovery algorithm in [47] (described as Algorithm 3) has been shown with property (a) by [47] and property (b) by [25] with an error rate of \(n^{-sD_{+}(a,b)}\). In this paper, we show that property (c) is satisfied (See Lemma 8).

**Subgraph counts.** For an arbitrary weighted adjacency matrix \(M\) of some adjacency matrix \(A\), vertex \(i\in[n]\), and a rooted graph \(H\), we define the _weighted subgraph counts_ on \(M\) as

\[W_{i,H}(M):=\sum_{S(i)\cong H}M_{S},\text{ where }M_{S}:=\prod_{e\in E(S)}M_{e},\] (7)

and \(S(i)\) enumerates subgraphs of the complete graph \(K_{n}\), rooted at \(i\), that are isomorphic to \(H\).

When \(M\) is the adjacency matrix itself, \(W_{i,H}(M)\) is the usual subgraph count, representing the number of subgraphs rooted at \(i\) in \(M\) that are isomorphic to \(H\). When \(M\) is the centralized adjacency matrix \(\overline{A}:=A-\mathbb{E}[A]\), we call \(W_{i,H}(M)\) a signed subgraph count following [9]. However, we do not have access to \(\mathbb{E}[A]\) in many cases. Specifically for SBM, we can estimate \(\mathbb{E}[A]\) through estimating the community labels. We define the _approximately centralized adjacency matrix_ regarding to community label estimate \(\widehat{\bm{\sigma}}\), denoted as \(\overline{A}^{\widehat{\bm{\sigma}}}\), entry-wise as \(\overline{A}^{\widehat{\bm{\sigma}}}_{i,j}=A_{i,j}-p\mathbf{1}_{\widehat{\bm{ \sigma}}[i]=\widehat{\bm{\sigma}}[j]}-q\mathbf{1}_{\widehat{\bm{\sigma}}[i] \neq\widehat{\bm{\sigma}}[j]}\).

Figure 4: A chandelier.

Using \(\overline{A}^{\widehat{\bm{\sigma}}}\) in (7) yields the weighted subgraph counts for approximately centralized adjacency matrix. We also refer to this as a signed subgraph count, though errors may exist.

Given a family \(\mathcal{H}\) of non-isomorphic rooted graphs, we define the _subgraph count signature_ of vertex \(i\) as

\[W_{i}^{\mathcal{H}}(M):=(W_{i,H}(M))_{H\in\mathcal{H}}.\] (8)

**Similarity score.** Given a pair of correlated SBMs (\(G_{1},G_{2}\)), we define the similarity score between vertex \(i\) on graph \(G_{1}\) and vertex \(j\) on graph \(G_{2}\) as a weighted inner product between two signatures:

\[\Phi_{ij}:=\langle W_{i}^{\mathcal{T}}(\overline{A}),W_{j}^{\mathcal{T}}( \overline{B})\rangle:=\sum_{H\in\mathcal{T}}\mathrm{aut}(H)W_{i,H}(\overline{A })W_{j,H}(\overline{B}),\] (9)

where \(\mathcal{T}\) is the family of chandelier.

When we do not have access to the centralized adjacency matrices \(\overline{A}\) and \(\overline{B}\), we use community label estimates \(\widehat{\bm{\sigma}}_{A}\) and \(\widehat{\bm{\sigma}}_{B}\) for \(G_{1}\) and \(G_{2}\) correspondingly. We define the similarity score with a slightly different notation:

\[\Phi_{ij}^{\widehat{\bm{\sigma}}}:=\langle W_{i}^{\mathcal{T}}(\overline{A}^ {\widehat{\bm{\sigma}}_{A}}),W_{j}^{\mathcal{T}}(\overline{B}^{\widehat{\bm{ \sigma}}_{B}})\rangle=\sum_{H\in\mathcal{T}}\mathrm{aut}(H)W_{i,H}(\overline{A }^{\widehat{\bm{\sigma}}_{A}})W_{j,H}(\overline{B}^{\widehat{\bm{\sigma}}_{B }}).\] (10)

**Almost exact graph matching.** The first part in the analysis is to show that by calculating this similarity score, with an appropriate thresholding strategy, we can match up \((1-o(1))n\) vertices correctly (Theorem 3). The high-level idea is to show that the similarity score distributions are well-separated between true pairs and fake pairs. We expect the similarity score having the following properties, under event \(\mathcal{H}\):

* For true pairs \(j=\pi(i)\) : \[\mathbb{E}[\Phi_{i\pi_{*}(i)}^{\widehat{\bm{\sigma}}}\mathbf{1}_{\mathcal{H}} ]>0,\quad\mathrm{Var}[\Phi_{ij}^{\widehat{\bm{\sigma}}}\mathbf{1}_{\mathcal{H }}]=o\left(\mathbb{E}[\Phi_{i\pi_{*}(i)}^{\widehat{\bm{\sigma}}}\mathbf{1}_{ \mathcal{H}}]^{2}\right),\]
* For fake pairs \(j\neq\pi(i)\) : \[\mathbb{E}[\Phi_{ij}^{\widehat{\bm{\sigma}}}\mathbf{1}_{\mathcal{H}}]=o\left( \mathbb{E}[\Phi_{i\pi_{*}(i)}^{\widehat{\bm{\sigma}}}\mathbf{1}_{\mathcal{H}} ]\right),\quad\mathrm{Var}[\Phi_{ij}^{\widehat{\bm{\sigma}}}\mathbf{1}_{ \mathcal{H}}]=o\left(\frac{\mathbb{E}[\Phi_{i\pi_{*}(i)}^{\widehat{\bm{\sigma} }}\mathbf{1}_{\mathcal{H}}]^{2}}{n^{2}}\right).\]

Precisely forming bounds for these moments constitutes the main bulk of the paper. Aside from proving the desired properties of the first and second order moments, we follow the color-coding-based similarity score estimation idea from [41] to analyze an efficient algorithm. The basic idea is to color the vertices of SBMs using \(N+1\) colors uniformly at random. Then, we only do signed counts on vertex sets that are colorful with \(N+1\) colors. We show that this is an unbiased estimator and only potentially increase the variance by an additional constant factor in Section F. The result is stated formally as in Theorem 4.

**Input:** Adjacency matrices \(A\) and \(B\) for \((G_{1},G_{2})\sim\mathrm{CSBM}(n,a^{\frac{\log n}{n}},b^{\frac{\log n}{n}},s)\), a constant \(c\), and mean value \(\mu\).

**Output:** A mapping \(\widehat{\pi}:I\rightarrow[n]\).

```
1: Run community recovery Algorithm 3[47] on \(A\) and \(B\) separately and get label vector \(\widehat{\bm{\sigma}}_{A},\widehat{\bm{\sigma}}_{B}\).
2: For each pair of vertex \(i\) in \(\overline{A}^{\widehat{\bm{\sigma}}_{A}}\) and vertex \(j\) in \(\overline{B}^{\widehat{\bm{\sigma}}_{B}}\), compute their similarity score as in [41]: \[\Phi_{ij}^{\widehat{\bm{\sigma}}}=\langle W_{i}^{\mathcal{T}}(\overline{A}^{ \widehat{\bm{\sigma}}_{A}}),W_{j}^{\mathcal{T}}(\overline{B}^{\widehat{\bm{ \sigma}}_{B}})\rangle=\sum_{H\in\mathcal{T}}\mathrm{aut}(H)W_{i,H}(\overline{A }^{\widehat{\bm{\sigma}}_{A}})W_{j,H}(\overline{B}^{\widehat{\bm{\sigma}}_{B }}).\] (11)
3: Let \(\tau=c\mu\), output \(I:=\{i|i\in[n],\exists j\in[n],\text{s.t. }\Phi_{ij}^{\mathcal{T}}\geq\tau,\text{ and }\forall k \in[n]\setminus\{j\},\Phi_{ik}^{\mathcal{T}}<\tau\}\). ```

**Algorithm 1** Almost Exact Graph Matching for CSBM

**Proof challenge.** In regime \(sD_{+}(a,b)>1\), the probability of existing one vertex being classified incorrectly is vanishing. Therefore, with high probability, \(\overline{A}^{\widehat{\bm{\sigma}}_{A}}=\overline{A}\). If \(sD_{+}(a,b)<1\), then the recovered \(\widehat{\bm{\sigma}}\) contains errors (polynomial in \(n\)), which will cause some edges being centralized incorrectly and thereby affect the moments calculation. For example, let \(i,j\in[n]\) be two vertices on \(G_{1}\) who has the same community label \(\bm{\sigma}_{*}(i)=\bm{\sigma}_{*}(j)\). If only one of \(i,j\) is labeled incorrectly by Algorithm 3, then the expectation of \(\overline{A}_{i,j}^{\widehat{\bm{\sigma}}_{A}}\) conditioned on \(\bm{\sigma}_{*}\) and \(\widehat{\bm{\sigma}}\) is \(p-q\).

This phenomenon poses a challenge to the algorithm analysis. We highlight some key points in the context of second moment calculation. For simplicity, we ignore event \(\mathcal{H}\) here.

\[\mathrm{Var}[\Phi_{ij}^{\widehat{\bm{\sigma}}}] =\sum_{H,I\in\mathcal{T}}\mathrm{aut}(H)\mathrm{aut}(I)\sum_{S_{ 1}(s_{1}),S_{2}(j)\cong H}\sum_{T_{1}(i),T_{2}(j)\cong I}\left(\mathbb{E}_{ \bm{\sigma}_{*}}\left[\mathbb{E}[\overline{A}_{S_{1}}^{\widehat{\bm{\sigma}}_{ A}}\overline{B}_{S_{2}}^{\widehat{\bm{\sigma}}_{B}}\overline{A}_{T_{1}}^{ \widehat{\bm{\sigma}}_{A}}\overline{B}_{T_{2}}^{\widehat{\bm{\sigma}}_{B}} \mid\bm{\sigma}_{*}]\right]\right.\] \[\left.-\mathbb{E}_{\bm{\sigma}_{*}}\left[\mathbb{E}[\overline{A }_{S_{1}}^{\widehat{\bm{\sigma}}_{A}}\overline{B}_{S_{2}}^{\widehat{\bm{\sigma} }_{B}}\mid\bm{\sigma}_{*}]\right]\mathbb{E}_{\bm{\sigma}_{*}}\left[\mathbb{E }[\overline{A}_{T_{1}}^{\widehat{\bm{\sigma}}_{A}}\overline{B}_{T_{2}}^{ \widehat{\bm{\sigma}}_{B}}\mid\bm{\sigma}_{*}]\right]\right)\right).\]

Let us define the union graph \(U:=S_{1}\cup S_{2}\cup T_{1}\cup T_{1}\)6. If \(sD_{+}(a,b)>1\), we view \(\overline{A}^{\widehat{\bm{\sigma}}}\) and \(\overline{B}^{\widehat{\bm{\sigma}}}\) as \(\overline{A}\) and \(\overline{B}\), respectively. \(\mathbb{E}[\overline{A}_{S_{1}}\overline{B}_{S_{2}}\overline{A}_{T_{1}} \overline{A}_{T_{2}}\mid\bm{\sigma}_{*}]\neq 0\) only if there exists no edge \(e\in E(U)\) such that it occurs only once among \((S_{1},S_{2},T_{1},T_{2})\). This is because different edges are independent and centralized conditioned on \(\bm{\sigma}_{*}\). Without loss of generality, we assume there exists an edge \(e\in E(A)\) occur only on \(S_{1}\), thus \(\mathbb{E}[\overline{A}_{e}\mid\bm{\sigma}_{*}]=0\) and also \(\mathbb{E}[\overline{A}_{S_{1}}\overline{B}_{S_{2}}\overline{A}_{T_{1}} \overline{A}_{T_{2}}\mid\bm{\sigma}_{*}]=0\).

Footnote 6: Note that \(S_{1}\) and \(T_{1}\) are rooted at \(i\), while \(S_{2}\) and \(T_{2}\) are rooted at \(j\). For \(e=(u,v)\in E(S_{1})\), we say it occurs in \(T_{1}\) if \(e\in E(T_{1})\) and it occurs in \(S_{2}\) (resp. \(T_{2}\)) if \((\bm{\sigma}_{*}(u),\bm{\sigma}_{*}(v))\in E(S_{2})\) (resp. \(T_{2}\)).

However, in regime \(sD_{+}(a,b)<1\), \(\mathbb{E}[\overline{A}_{S_{1}}^{\widehat{\bm{\sigma}}_{A}}\overline{B}_{S_{2 }}^{\widehat{\bm{\sigma}}_{B}}\overline{A}_{T_{1}}^{\widehat{\bm{\sigma}}_{A}} \overline{B}_{T_{2}}^{\widehat{\bm{\sigma}}_{B}}\mid\bm{\sigma}_{*}]\neq 0\) even when edges are not occurring multiple times as we have the expectation of \(\overline{A}_{e}^{\widehat{\bm{\sigma}}_{A}}\) can be non-zero when conditioning on \(\bm{\sigma}_{*}\) and an estimate \(\widehat{\bm{\sigma}}_{A}\) that disagrees with \(\bm{\sigma}_{*}\) on the edge type (i.e., for \(e=(u,v),\bm{\sigma}_{*}(u)\bm{\sigma}_{*}(v)\neq\widehat{\bm{\sigma}}_{A}(u) \widehat{\bm{\sigma}}_{A}(v)\)). This not only causes this cross-moments calculation being more complicated, but significantly increasing the possibility of the combinations between \(S_{1},S_{2},T_{1}\), and \(T_{2}\). The maximum vertex in the union graph grows from \(2N\) to \(4N\), squaring up the trivial bound on the number of subgraphs on the complete graph \(K_{n}\) that is isomorphic to \(U\).

The most important high-level idea to properly bound the moments is: the cross-moment conditioning on a specific \(\widehat{\bm{\sigma}}=(\widehat{\bm{\sigma}}_{A},\widehat{\bm{\sigma}}_{B})\) would be non-trivial if and only if _all edges occurring only once are centralized incorrectly_. This is because, conditioning on \(\widehat{\bm{\sigma}}\) satisfying the above property, the expectation of \(\overline{A}_{e}\) takes either \(p-q\) or \(q-p\) for all \(e\in E(U)\) that occurs only once. Assuming there are \(z\) edges occurring once, we show that the probability that \(\widehat{\bm{\sigma}}\) satisfying this property is no greater than \(n^{-\frac{z(sD_{+}(a,b)-e\log(a/b)/2)}{D}}\) for any \(\varepsilon>0\). Intuitively, this is saying that to incorrectly centralize \(z\) edges at the same time, we expect the Algorithm 3 to label at least \(\lceil\frac{z}{D}\rceil\) vertices incorrectly. It turns out that we require \(n^{-\frac{z(sD_{+}(a,b)-e\log(a/b)/2)}{D}}\) to be \(o(\frac{1}{\log^{C}n})\) for some positive constant \(C\) so that (1) and (2) are satisfied.

**Theorem 3**.: _Fix \(a\neq b>0\) and \(s\in[0,1]\). Let \(p=a\frac{\log n}{n},q=b\frac{\log n}{n}\) and \((G_{1},G_{2})\sim\mathrm{CSBM}(n,p,q,s)\). For any \(\varepsilon>0\), suppose \(s^{2}\geq\alpha+\varepsilon\). There exists positive constants \(C_{1},C_{2},C_{3},C_{4},C_{5}>0\) such that the following holds. Pick \(K,M,L,N,D\) as_

\[L=\frac{C_{1}}{\varepsilon},\quad K=C_{2}\log n,\quad M=\frac{C_{3}K}{\log(ns(p \wedge q))},\quad R=\exp(C_{4}K),\quad D=C_{5}\frac{\log n}{(\log\log n)^{2}}.\] (12)

_Pick an arbitrary \(c\in(0,1)\) and set \(\mu=|\mathcal{T}|n^{N}\rho^{N}\sigma_{\mathrm{eff}}^{2N}\), where \(\sigma_{\mathrm{eff}}^{2}:=\left(\frac{\sigma_{+}^{2}+\sigma_{-}^{2}}{n}\right)\). Then, Algorithm 1 outputs a set \(I\) with size \((1-o(1))n\) and a mapping \(\widetilde{\pi}\) such that \(\widetilde{\pi}|_{I}=\widehat{\pi}_{*}|_{I}\) with high probability._

Algorithm 1 takes quasi-polynomial time. Algorithm 4 in Section F computes an approximated score in polynomial time and satisfies the following Theorem.

**Theorem 4**.: _Theorem 3 continues to hold with the color-coding sampled estimation \(\widetilde{\Phi}_{ij}^{\widehat{\bm{\sigma}}}\) in place of \(\Phi_{ij}^{\widehat{\bm{\sigma}}}\). Moreover, by Algorithm 4, \(\{\widetilde{\Phi}_{ij}^{\widehat{\bm{\sigma}}}\}_{i,j,\in[n]}\) can be computed in \(O(n^{C})\) for some constant \(C\equiv C(\varepsilon)\) depending only on \(\varepsilon\), where \(\varepsilon\) is from (3)._

**Exact graph matching.** The final step of the algorithm is boosting the almost exact matching to a exact matching. The key idea is exploring the number of common neighbors for two unmatched vertices with regard to the current matching.

Denote \(\mathrm{N}_{\pi}(i,j)\) as the number of common neighbors of \(i\) and \(j\) under correspondence \(\pi\). In another word, \(\mathrm{N}_{\pi}(i,j)\) is the number of vertex \(v\in I\) such that \(v\) is a neighbor of \(i\) in \(G_{1}\) and \(\pi(v)\) is a neighbor of \(j\) in \(G_{2}\). The high-level idea is that if \(i\) and \(j\) form a true correspondence, then for a correct partial matching \(\widetilde{\pi}\) on \((1-o(1))n\) vertices, with high probability, \(\mathrm{N}_{\widetilde{\pi}}(i,j)\gtrsim\frac{p^{2}+q^{2}}{2}s^{2}(n+2n^{\frac {3}{4}})\) under the nice event \(\mathcal{H}\). Therefore, we match up \(i\) and \(j\) if they have more common neighbors than this threshold. In addition, we can show that all the remaining vertices will be matched up with high probability. Formally, define \(h(x)=x\log x-x+1\), we summarize the algorithm as Algorithm 2 and the guarantee as Theorem 5.

**Theorem 5**.: _Fix \(a\neq b>0\) and \(s\in[0,1]\). Let \(p=a\frac{\log n}{n},q=b\frac{\log n}{n}\) and \((G_{1},G_{2})\sim\mathrm{CSBM}(n,p,q,s)\). Suppose_

\[s^{2}(\frac{a+b}{2})\geq 1+\varepsilon\quad\text{and}\quad s^{2}\geq\alpha+\varepsilon,\]

_for some \(\varepsilon>0\). Let \(\gamma\) be the unique solution in \((1,\infty)\) to \(h(\gamma)=\frac{3\log n}{(n-2)pqs^{2}}\). Then, the seeded matching Algorithm 2 with input \(\widehat{\pi}\) and an index set \(I\subset[n],|I|=(1-o(1))n\geq(1-\varepsilon/16)n\) such that \(\widehat{\pi}|_{I}=\pi_{*}\) outputs an exact matching \(\widetilde{\pi}=\pi_{*}\) in \(O(n^{3}(p+q)^{2})\) time with probability \(1-o(1)\)._

```
0: Adjacency matrices \(A\) and \(B\) for \((G_{1},G_{2})\sim\mathrm{CSBM}(n,p,q,s),p=a\frac{\log n}{n},q=b\frac{\log n}{n}\) for some \(a>0,b>0\). A mapping \(\widehat{\pi}:I\to[n]\) with \(|I|=(1-o(1))n\), parameters \(p,q,s\), and \(\gamma\in(1,\infty)\) such that \(h(\gamma)=\frac{3\log n}{(n-2)pqs^{2}}\).
1: Let \(J=I\), and \(\widetilde{\pi}=\widehat{\pi}\).
2:while there exists \(i\notin J\) and \(j\notin\widetilde{\pi}(J)\) such that \(\mathrm{N}_{\widetilde{\pi}}(i,j)\geq\gamma\frac{p^{2}+q^{2}}{2}s^{2}(n+2n^{ \frac{3}{4}})\)do
3: Add \(i\) to \(J\) and let \(\widetilde{\pi}(i)=j\).
4:endwhile
5:\(\widetilde{\pi}\). ```

**Algorithm 2** Seeded Graph Matching [41]

### Putting things together: Proof of Theorem 1

The proof of Theorem 1 follows from Theorem 4 and Theorem 5.

Proof of Theorem 1.: From Theorem 4, we know that for \((G_{1},G_{2})\sim\mathrm{CSBM}(n,a\frac{\log n}{n},b\frac{\log n}{n},s)\), \(a\neq b\), if \(s^{2}\geq\alpha+\varepsilon\) for some \(\varepsilon>0\) then there we can match \((1-o(1))n\) vertices correctly and efficiently with high probability.

Take the returned \(\widehat{\pi}\) from Algorithm 4 as input of Algorithm 2, then Theorem 5 guarantees that the final output \(\widetilde{\pi}=\pi_{*}\) with probability \(1-o(1)\). This completes the proof of Theorem 1. 

## Appendix D Preliminaries

### Tail bounds

**Lemma 3** (Chernoff Bound, Theorem 2.1 of [31]).: _Let \(X\sim\mathrm{Binom}(n,p)\) be a binomial random variable. Then, for all \(t\geq 0\),_

\[\mathbb{P}(X\geq\mathbb{E}X+t) \leq\exp\left(-\frac{t^{2}}{2(\mathbb{E}X+t/3)}\right),\] \[\mathbb{P}(X\leq\mathbb{E}X-t) \leq\exp\left(-\frac{t^{2}}{2\mathbb{E}X}\right).\]

**Lemma 4** (Multiplicative Chernoff Bound, Theorem 4.4 and Theorem 4.5 of [45]).: _Let \(X\sim\mathrm{Binom}(n,p)\) be a binomial random variable, denote \(\mu=np\) as the mean. Let \(h(x)=x\log x-x+1\). Then, for all \(\gamma\in(1,\infty)\),_

\[\mathbb{P}(X\geq\gamma\mu)\leq\exp(-\mu h(\gamma)).\]_For \(\gamma\in(0,1)\),_

\[\mathbb{P}(X\leq\gamma\mu)\leq\exp(-\mu h(\gamma)).\]

**Lemma 5**.: _[_47; 25_]_ _Suppose that \(a<b\). Let \(Y\sim\mathrm{Binom}(m_{+},\frac{a\log n}{n})\) and \(Z\sim\mathrm{Binom}(m_{-},\frac{b\log n}{n})\) be independent. If \(m_{+}=(1+o(1))\frac{n}{2}\), \(m_{-}=(1+o(1))\frac{n}{2}\), then,_

\[\mathbb{P}(Y<Z)=n^{-D_{+}(a,b)+o(1)}.\]

_For any \(\varepsilon>0\),_

\[\mathbb{P}(Y-Z\leq\varepsilon\log n)\leq n^{-(D_{+}(a,b)-\frac{\varepsilon\log (a/b)}{2})+o(1)}.\]

This result has been proved in Lemma 8 in [3] and Lemma 3.3 in [25].

### Nice events

When \((G_{1},G_{2})\sim\mathrm{CSBM}(n,\frac{a\log n}{n},\frac{b\log n}{n},s)\), there are some events that happen with high probability and our following analysis intuitively relies on the happening of these nice events.

* **(Balanced Communities)** We denote \(\mathcal{H}:=\{\frac{n}{2}-n^{\frac{3}{4}}\leq|V^{+}|,|V^{-}|\leq\frac{n}{2}+ n^{\frac{3}{4}}\}\). We observe that \(|V^{+}|\sim\mathrm{Binom}(n,\frac{1}{2})\) and \(|V^{-}|=n-|V^{+}|\). By Chernoff bound, \[\mathbb{P}(\mathcal{H}^{c})=\mathbb{P}(|V^{+}|\geq\frac{n}{2}+n^{\frac{3}{4}} )-\mathbb{P}(|V^{+}|\leq\frac{n}{2}-n^{\frac{3}{4}})\leq\frac{1}{e^{(1-o(1)) \sqrt{n}}}.\]
* **(Reasonable Large Neighborhood)** Let \(\gamma=\max(a,b)\), we also denote that \[\mathcal{F}=\{\forall v\in[n],|\mathcal{N}(v)|\leq 100\max(1,\gamma)\log^{3}n\}.\]

**Lemma 6**.: _As \(n\to\infty\), we have_

\[\mathbb{P}(\mathcal{F})\geq 1-n^{-O(\log^{2}n)}.\]

Proof.: Let \(X\sim\mathrm{Binom}(n,\gamma\frac{\log n}{n})\). Fix \(i\in[n]\), conditioned on any \(\boldsymbol{\sigma}_{*}\), \(|\mathcal{N}(i)|\) is stochastically dominated by \(X\). Therefore,

\[\mathbb{P}(|\mathcal{N}(i)|\geq\gamma\log^{3}n\mid\boldsymbol{ \sigma}_{*}) \leq\mathbb{P}(X\geq\gamma\log^{3}n)\leq\exp\left(-\frac{(\gamma \log^{3}n)^{2}}{2\gamma\log n+2/3\gamma\log^{3}n}\right)\] \[\leq\exp(-\gamma\log^{3}n)=n^{-\gamma\log^{2}n},\]

where the second line uses Bernstein's inequality and the third line holds for any \(n\) such that \(\log^{2}n>6\). From an union bound, we have

\[\mathbb{P}(\mathcal{F})=\mathbb{E}[\mathbb{P}(\mathcal{F}|\boldsymbol{\sigma} _{*})]\geq 1-n^{-O(\log^{2}n)}.\qed\]

### Community recovery

We make a slight change on the choice of the partition number of the community detection algorithm proposed by Mossel, Neeman, and Sly [47]. This algorithm gives almost exact recovery with \(n^{1-sD_{+}(a,b)+\varepsilon\left\lfloor\log(a/b)\right\rfloor}\) vertices labeled incorrectly. After community recovery, we need to match the two communities in \(G_{1}\) and \(G_{2}\) by applying the community matching Algorithm 3.

Consider \(G\sim\mathrm{SBM}(n,\frac{a\log n}{n},\frac{b\log n}{n})\). Define \(\gamma=\max\{a,b\}\). For any vertex \(v\in[n]\), we define the signed neighbor counts of \(v\) in \(G\) as

\[\mathrm{maj}_{G}(v)=\boldsymbol{\sigma}_{*}(v)\sum_{u\in\mathcal{N}(v)} \boldsymbol{\sigma}_{*}(u).\]

For any \(\varepsilon>0\), define a set of vertices:

\[I_{\varepsilon}(G):=\{v\in[n]:\mathrm{maj}_{G}(v)\leq\varepsilon\log n\text{ or }|\mathcal{N}(v)|\geq\gamma\log^{3}n\}.\]

Previous results (Lemma 5.1 [25], Proposition 4.3 [47]) have shown that Algorithm 3's correctness on \([n]\setminus I_{\varepsilon}(G)\) with a different choice of \(m\) and the lower bound of \(|\mathcal{N}(v)|\) in the bad vertices set \(I_{\varepsilon}(G)\). In our work, we first demonstrates that Algorithm 3 on input \((G,a,b,\varepsilon)\) correctly classifies all vertices in \([n]\setminus I_{\varepsilon}(G)\).

**Lemma 7**.: _Algorithm 3 on input \((n,a,b,s)\) classifies all vertices in \([n]\setminus I_{\varepsilon}(G)\) correctly with high probability._

The proof directly follows from the proof of Proposition \(5.1\) in [25], with two remarks. First, although the maximum size of neighbors \(|\mathcal{N}(i)|\) we consider here is enlarged from \(100\max\{1,\gamma\}\log n\) to \(\gamma\log^{3}n\), we adjust the condition of \(m\) accordingly such that the tail bound holds. Secondly, we need to justify that with high probability, all partitions done by the spectral method are still almost exactly correct under the new choice of \(m\), which is no longer a constant independent of \(n\). Theorem \(3.2\) of [3] showed that the vanilla spectral method achieved optimal error rate, in the sense that \(\mathbb{E}[\frac{1}{n}\sum_{i=1}^{n}1_{\{\bm{\sigma}_{*}(i)\neq\widehat{\bm{ \sigma}}(i)\}}]\leq n^{-(1+o(1))D_{+}(a,b)}\). This implies that with probability \(1-n^{-(1+o(1))D_{+}(a,b)}\), the spectral method labels all but \(o(n)\) vertices correctly. Furthermore, for all \(i\in[n]\), \(U_{i,+}\) matches with \(V^{+}\setminus U_{i}\) and \(U_{i,-}\) matches with \(V^{-}\setminus U_{i}\) on all but \(o(n)\) vertices after step (5) with high probability.

In this work, we further determine the probability of a set of vertices being in the set \(I_{\varepsilon}(G)\), which is a generalization of the result on the \(\mathbb{P}(v\in I_{\varepsilon})\) for an arbitrary \(v\in[n]\) (Lemma \(5.3\) of [25]).

**Lemma 8**.: _Given a random graph \(G\sim\mathrm{SBM}(n,\frac{sa\log n}{n},\frac{sb\log n}{n})\) and a fixed subgraph induced by vertex set \(S\in[n]\)._

_If \(|S|=O(\log n)\), then for any \(\varepsilon>0,\delta>0\),_

\[\mathbb{P}(\{\forall i\in S,i\in I_{\varepsilon}\}\cap\mathcal{H})=O(n^{-|S| (sD_{+}(a,b)-\varepsilon(1+\delta)|\log(a/b)|)}+n^{-\varepsilon\delta(1-o(1)) \log n}).\]

_If \(|S|=o(\log n)\), then for any \(\varepsilon>0,\delta>0\),_

\[\mathbb{P}(\{\forall i\in S,i\in I_{\varepsilon}\}\cap\mathcal{H})=O(n^{-|S| (sD_{+}(a,b)-\varepsilon(1+\delta)|\log(a/b)|)}).\]

Proof.: The main idea is considering the intersection of the interested event \(\{\forall i\in S,i\in I_{\varepsilon}\}\cap\mathcal{H}\) with \(\mathcal{G}=\{\forall i\in S,|\mathcal{N}_{S}(i)|\leq\varepsilon\delta\log n\}\), where \(\mathcal{N}_{S}(v)\) denotes the set of neighbors of \(v\) restricted on the vertex set \(S\).

\[\mathbb{P}(\{\forall i\in S,i\in I_{\varepsilon}\}\cap\mathcal{H})\leq \mathbb{P}(\{\forall i\in S,i\in I_{\varepsilon}\}\cap\mathcal{H}\cap \mathcal{F}\cap\mathcal{G})+\mathbb{P}(\mathcal{G}^{c})+\mathbb{P}(\mathcal{F }^{c}).\] (13)

Firstly, we give the upper bound of \(\mathbb{P}(\mathcal{G}^{c}\mid\bm{\sigma}_{*})\bm{1}_{\mathcal{H}}\). Assume that \(|S|\geq\varepsilon\delta\log n\) without loss of generality. By using an union bound,

\[\mathbb{P}(\mathcal{G}) \leq|S|\times\mathbb{E}[\mathbb{P}(|\mathcal{N}_{S}(i)|> \varepsilon\delta\log n\mid\bm{\sigma}_{*})]\] \[=|S|\times\sum_{k=\delta\log n}^{|S|}\binom{|S|}{\varepsilon \delta\log n}(\frac{a\log n}{n})^{\varepsilon\delta\log n}(1-\frac{b\log n}{n })^{|S|-\varepsilon\delta\log n}\] \[=n^{\frac{\log\log n}{\log n}}(\frac{Ca\log^{2}n}{n})^{ \varepsilon\delta\log n}=O(n^{-\varepsilon\delta(1-o(1))\log n}),\] (14)where the second equation holds from the assumption of \(|S|=O(\log n)\).

Secondly, we study this event \(E=\{\forall i\in S,i\in I_{\varepsilon}\}\cap\mathcal{H}\cap\mathcal{F}\).

\[\mathbb{P}(E) =\mathbb{E}[\mathbb{P}(\{\forall v\in S,\mathrm{maj}_{G}(v)\leq \varepsilon\log n\}\mid\boldsymbol{\sigma}_{*})\boldsymbol{1}_{\mathcal{H}}]\] \[=\mathbb{E}[\mathbb{P}(\{\forall v\in S,\mathrm{maj}_{G[[n] \setminus S]}(v)+\mathrm{maj}_{G[S]}(v)\leq\varepsilon\log n\}\mid\boldsymbol{ \sigma}_{*})\boldsymbol{1}_{\mathcal{H}}]\] \[\leq\mathbb{E}[\mathbb{P}(\{\forall v\in S,\mathrm{maj}_{G[[n] \setminus S]}(v)\leq\varepsilon(1+\delta)\log n\}\mid\boldsymbol{\sigma}_{*}) \boldsymbol{1}_{\mathcal{H}}].\]

For any \(v\in S\), \(\mathrm{maj}_{G[[n]\setminus S]}(v)\) is the difference of two independent binomial random variables \(Y_{v}\) and \(Z_{v}\), where \(Y_{v}\sim\mathrm{Binom}(|V^{\boldsymbol{\sigma}_{*}(v)}_{G[[n]\setminus S]}|, sa\frac{\log n}{n}),Z_{v}\sim\mathrm{Binom}(|V^{-\boldsymbol{\sigma}_{*}(v)}_{G[[n] \setminus S]}|,sb\frac{\log n}{n})\). With \(\mathcal{H}\) happening, we have \(|V^{\boldsymbol{\sigma}_{*}(v)}_{G[[n]\setminus S]}|=(1-o(1))\frac{n}{2},|V^{ -\boldsymbol{\sigma}_{*}(v)}_{G[[n]\setminus S]}|=(1-o(1))\frac{n}{2}\). Since \(Y_{v}\) and \(Z_{v}\) do not take into account \(v\in S\), they are independent for all \(v\in S\). Therefore,

\[\mathbb{P}(E) =\mathbb{E}[\Pi_{v\in S}\mathbb{P}(\{Y_{v}-Z_{v}\leq\varepsilon( 1+\delta)\log n\}\mid\boldsymbol{\sigma}_{*})\boldsymbol{1}_{\mathcal{H}}]\] \[\leq(n^{-(sD_{+}(a,b)-\frac{s(1+\delta)\log(a/b)}{2})+o(1)})|S|\] \[\leq n^{-|S|(sD_{+}(a,b)-\varepsilon(1+\delta)|\log(a/b)|)},\] (15)

where the second line holds by Lemma 5 and the last line holds for sufficiently large \(n\). We conclude with by Lemma 6, Inequality (14), and Inequality (15) into Inequality (13). 

**Remark 2**.: _For arbitrary \(\varepsilon>0\), we can find \(\varepsilon^{\prime}>0\) and \(\delta>0\) such that \(\varepsilon^{\prime}(1+\delta)=\varepsilon\). For the sake of convenience, we also denote \(D_{+}(a,b,s,\varepsilon)\) as \(sD_{+}(a,b)-\varepsilon|\log(a/b)|\) and this is equivalent as the \((\varepsilon,\delta)\)-parameterization in Lemma 8. We mainly use the \(sD_{+}(a,b,s,\varepsilon)\) notation in the analysis throughout this paper._

### Tree node assigning

Before getting to the first moment calculation of the similarity score, we introduce a sub-problem, named _in-community edge counting for node assignment on trees_.

Assume that we have a random graph \(G\) with \(n\) vertices, which are labeled by a community label vector \(\boldsymbol{\sigma}\). We are also given a rooted tree \(T(i)\) with \(N\) vertices other than the root, where \(i\) specifies the root node of \(T\) on \(G\). Planting \(T(i)\) onto \(G\) has at least \(\binom{n}{N}\) possible positions. If \(G\) is a stochastic block model, different planted positions of \(T\) would contain different numbers of in-community edges. We are interested in the distribution of the number of in-community edges when planting \(T(i)\) onto \(G\) uniformly at random.

**Lemma 9**.: _Let \(K_{n}\) be the complete graph of a stochastic block model \(G\) on \(n\) vertices. Let \(\boldsymbol{\sigma}_{*}=\{\boldsymbol{\sigma}_{*}(i)\}_{i=1}^{n},\boldsymbol{ \sigma}_{*}(i)\in\{-1,+1\}\) drawn independently and uniformly at random as the vector of community labels. Let \(v\in[n]\) be an arbitrary node of \(K_{n}\). Let \(T\) be an arbitrary rooted tree with \(N\) vertices other than the root. Consider a uniformly random injective function \(\tau:V(T)\to V(K_{n})\) such that root \(r(T)\) is mapped to \(v\) in \(V(K_{n})\). Define \(X\) as the random variable representing the number of in-community edges in the tree \(T\) under random \(\tau\). Then,_

\[\text{Bin}(N,\frac{1}{2}-2n^{-\frac{1}{4}})\preccurlyeq X\mid\mathcal{H} \preccurlyeq\text{Bin}(N,\frac{1}{2}+2n^{-\frac{1}{4}}).\]

Proof.: There are \(N\) edges on the tree \(T\). For any \((u,v)\in V(K_{n})\times V(K_{n})\), we denote \(X_{(u,v)}\) as the indicator random variable of event \(\mathcal{E}=\{u\text{ and }v\text{ are from the same community}\}\). Since \(\frac{1}{2}-2n^{-\frac{1}{4}}\leq\mathbb{P}(\mathcal{E}\mid\mathcal{H})\leq \frac{1}{2}+2n^{-\frac{1}{4}}\), \(X_{(u,v)}\mid\mathcal{H}\) stochastically dominates \(\text{Bernoulli}(\frac{1}{2}-2n^{-\frac{1}{4}})\) and is stochastically dominated by \(\text{Bernoulli}(\frac{1}{2}+2n^{-\frac{1}{4}})\). Thus, the summation over all edges on tree \(T\), \(X\mid\mathcal{H}=\sum_{(u,v)\in E(T)}X_{(u,v)}\mid\mathcal{H}\), stochastically dominates \(\mathrm{Binom}(n,\frac{1}{2}-2n^{-\frac{1}{4}})\) and is stochastically dominated by \(\mathrm{Binom}(n,\frac{1}{2}+2n^{-\frac{1}{4}})\). 

**Remark 3**.: _If \(N=o(n^{\frac{1}{4}})\), Lemma 9 implies that with some non-negative integer \(N_{1}\leq N\), \(\mathbb{P}(\{X=N_{1}\}\cap\mathcal{H})=(1+o(1))\binom{N}{N_{1}}(\frac{1}{2})^{N}\). Because \(\mathbb{P}(\{X=N_{1}\}\cap\mathcal{H})=(1-o(1))\mathbb{P}(X=N_{1}\mid\mathcal{H})\), it _suffices to show both the upper and lower bound on \(\mathbb{P}(X=N_{1}\mid\mathcal{H})\)._

\[\mathbb{P}(X=N_{1}\mid\mathcal{H})=\mathbb{P}(X\geq N_{1}\mid \mathcal{H})-\mathbb{P}(X\geq N_{1}+1\mid\mathcal{H})\] \[\quad\leq\sum_{t\geq N_{1}}\binom{N}{t}(\frac{1}{2}+2n^{-\frac{1} {4}})^{t}(\frac{1}{2}-2n^{-\frac{1}{4}})^{N-t}-\sum_{t\geq N_{1}+1}\binom{N}{t }(\frac{1}{2}-2n^{-\frac{1}{4}})^{t}(\frac{1}{2}+2n^{-\frac{1}{4}})^{N-t}\] \[\quad\leq(1+o(1))\binom{N}{N_{1}}(\frac{1}{2})^{N}+\sum_{t\geq(N-N _{1})\vee(N_{1}+1)}\binom{N}{t}(\frac{1}{2})^{N}f(n,N,t),\]

_where \(f(n,N,t)=(1+4n^{-\frac{1}{4}})^{t}(1-4n^{-\frac{1}{4}})^{N-t}-(1-4n^{-\frac{1} {4}})^{t}(1+4n^{-\frac{1}{4}})^{N-t}\). The first inequality holds because of the stochastic dominance in Lemma 9. The second inequality holds because \(\binom{N}{N-t}f(n,N,N-t)=\binom{N}{t}f(n,N,t)\) and thus cancels out every term in the summation indexed from \(t=N_{1}+1\) to \(t=N-(N_{1}+1)\). For \(t\geq(N-N_{1})\vee(N_{1}+1)\), we know that \(\binom{N}{t}<\binom{N}{N_{1}}\). Also, \(f(n,N,t)\leq(1+4n^{-\frac{1}{4}})^{N}-(1-4n^{-\frac{1}{4}})^{N}<O(n^{-\frac{1} {4}}N)=o(\frac{1}{N})\) from our assumption on \(N\). Therefore, summing over \(t\geq(N-N_{1})\wedge(N_{1}+1)\), we have_

\[\mathbb{P}(X=N_{1}\mid\mathcal{H})\leq(1+o(1))\binom{N}{N_{1}}(\frac{1}{2})^{ N}.\]

_From the other direction of stochastic dominance, we have \(\mathbb{P}(X=N_{1}\mid\mathcal{H})=\mathbb{P}(X\geq N_{1}\mid\mathcal{H})- \mathbb{P}(X\geq N_{1}+1\mid\mathcal{H})\geq(1-o(1))\binom{N}{N_{1}}(\frac{1} {2})^{N}\)._

**Lemma 10**.: _Let \(K_{n}\) be the complete graph of a stochastic block model \(G\) on \(n\) vertices. Let \(\boldsymbol{\sigma}_{*}=\{\boldsymbol{\sigma}_{*}(i)\}_{i=1}^{n},\boldsymbol {\sigma}_{*}(i)\in\{-1,+1\}\) drawn independently and uniformly at random as the vector of community labels. Let \(v\in[n]\) be an arbitrary node of \(G\). Let \(\{T\}_{i=1}^{t}\) be a sequence of arbitrary rooted tree with \(N\) vertices other than the root. Consider a uniformly random injective function \(\tau:V(T)\to V(K_{n})\) such that root \(r(T_{1})\) of the first tree is mapped to \(v\) in \(V(K_{n})\). Also, the root of \(i\)-th tree is mapped to \(\tau(r(T_{i}))=\tau(u)\) for a fixed vertex on previous trees \(u\in\cup_{t=1}^{i-1}V(T_{t})\) or a fixed vertex on \(K_{n}\). Define \(X\) as the random variable representing the number of in-community edges in all the trees under random \(\tau\). Then,_

\[\text{Bin}(N,\frac{1}{2}-2n^{-\frac{1}{4}})\preccurlyeq X\mid\mathcal{H} \preccurlyeq\text{Bin}(N,\frac{1}{2}+2n^{-\frac{1}{4}}).\]

Proof.: Define \(X_{i}\) as the random variable for number of in-community edges on Tree \(T_{i}\) with random embedding \(\tau\). The following holds immediately from Lemma 9,

\[\text{Bin}(N_{T_{i}},\frac{1}{2}-2n^{-\frac{1}{4}})\preccurlyeq X_{i}\mid \mathcal{H}\preccurlyeq\text{Bin}(N_{T_{i}},\frac{1}{2}+2n^{-\frac{1}{4}}).\]

Since \(X\mid\mathcal{H}=\sum_{i}X_{i}\mid\mathcal{H}\),

\[\text{Bin}(N,\frac{1}{2}-2n^{-\frac{1}{4}})\preccurlyeq X\mid\mathcal{H} \preccurlyeq\text{Bin}(N,\frac{1}{2}+2n^{-\frac{1}{4}}).\qed\]

To present the following Lemma 11, we need to introduce a few more definitions: _decorated union graph_ and _decorated edges_, which will be explained in more details in the context of chandelier in Section I.

**Decorated union graph.** Let \(S_{1},S_{2},T_{1},T_{2}\) be four rooted graphs. The union graph is defined as \(U:=S_{1}\cup S_{2}\cup T_{1}\cup T_{2}\). We define the decorated union graph as a two-tuple \(\dot{U}:=(U,D_{U})\), which is \(U\) associating with a decoration set. For each edge,

\[D_{U}(e)=\begin{cases}\text{The subset of }\{S_{1},S_{2},T_{1},T_{2}\}\text{ where }e \text{occurs},&\text{if }e\in E(U),\\ \emptyset,&\text{otherwise}.\end{cases}\]

We call an edge \(e\in E(U)\) is \(t\)-decorated if \(|D_{U}(e)|=t\) for \(t\in\{0,1,2,3,4\}\). Decorated union graph \(\dot{U}\) has one-to-one correspondence with \((S_{1},S_{2},T_{1},T_{2})\) as we can uniquely determine \(\dot{U}\) given \((S_{1},S_{2},T_{1},T_{2})\) and uniquely recover \((S_{1},S_{2},T_{1},T_{2})\) given \(\dot{U}\).

**Lemma 11** (Asymptotic independence of the counts of \(i\)-decorated in-community edges).: _Let \(K_{n}\) be the complete graph of a stochastic block model \(G\) on \(n\) vertices. Consider a connected decorated union graph \(\dot{U}_{P}\) with \(d_{1}\)\(1\)-decorated edges, \(d_{2}\)\(2\)-decorated edges, \(d_{3}\)\(3\)-decorated edges, and \(d_{4}\)\(4\)-decorated edges, rooted at \(v\) on the complete graph \(K_{n}\). Consider a uniformly random injective function \(\tau:V(T)\to V(K_{n})\) such that root \(r(T)\) is mapped to \(v\) in \(V(K_{n})\). Define \(X^{(i)}\) as the random variable representing the number of \(i\)-decorated in-community edges in \(\dot{U}_{P}\). Assume that \(|V(\dot{U}_{P})|=O(\log n)\) and \(\dot{U}_{P}\) has excess \(k\). If \(k=-1\), then,_

\[\mathbb{P}(X^{(1)}=M_{1},X^{(2)}=M_{2},X^{(3)}=M_{3},X^{(4)}=M_{4} \mid\mathcal{H})\] \[\quad=(1\pm o(1))\mathbb{P}(X^{(1)}=M_{1}\mid\mathcal{H}) \mathbb{P}(X^{(2)}=M_{2}\mid\mathcal{H})\mathbb{P}(X^{(3)}=M_{3}\mid\mathcal{ H})\mathbb{P}(X^{(4)}=M_{4}\mid\mathcal{H})\] \[\quad=(1+o(1))\binom{d_{1}}{M_{1}}\binom{d_{2}}{M_{2}}\binom{d_{3 }}{M_{3}}\binom{d_{4}}{M_{4}}\frac{1}{2^{d_{1}+d_{2}+d_{3}+d_{4}}}.\]

Proof.: From the assumption \(k=-1\) we have \(\dot{U}_{P}\) is a tree. We can decompose \(U_{P}\) to a sequence of trees as follows: Traverse \(U_{P}\) in BFS order and include each maximal connected component with all edges \(i\)-decorated as a subtree.

In addition, we break this sequence of tree into four sequences based on the decoration number: \(\{T_{j}^{(1)}\}_{j=1}^{c},\{T_{j}^{(2)}\}_{j=1}^{d},\{T_{j}^{(3)}\}_{j=1}^{c}, \{T_{j}^{(4)}\}_{j=1}^{f}\). In the random mapping, the root of each tree should be mapped to either \(v\) or a non-root vertex on the other tree. Let \(X_{j}^{(i)}\) be the random variable for the number of in-community edges for the \(j\)-th tree of \(i\)-decoration. \(X_{j}^{(i)}\mid\mathcal{H}\) satisfies the following stochastic dominance:

\[\text{Bin}(|V(T_{j}^{(i)})|,\frac{1}{2}-2n^{-\frac{1}{4}})\preccurlyeq X_{j}^ {(i)}\mid\mathcal{H}\preccurlyeq\text{Bin}(|V(T_{j}^{(i)})|,\frac{1}{2}+2n^{- \frac{1}{4}}).\]

Thus, their summation satisfies the following stochastic dominance:

\[\text{Bin}(d_{i},\frac{1}{2}-2n^{-\frac{1}{4}})\preccurlyeq X^{(i)}\mid \mathcal{H}\preccurlyeq\text{Bin}(d_{i},\frac{1}{2}+2n^{-\frac{1}{4}}),i=1,2,3,4.\]

As each of the series of trees occupy \(O(\log n)\) vertices, every \(X^{(i)}\) conditioned on other \(X^{(i^{\prime})},i^{\prime}\neq i\) still satisfies the stochastic dominance:

\[\text{Bin}(d_{i},\frac{1}{2}-2n^{-\frac{1}{4}})\preccurlyeq X^{(i)}|X^{(i^{ \prime})},\mathcal{H}\preccurlyeq\text{Bin}(d_{i},\frac{1}{2}+2n^{-\frac{1}{4} }).\]

Specifically, following Remark 3, \(\mathbb{P}(X^{(4)}=M_{4}\mid\mathcal{H})=(1+o(1))\binom{d_{4}}{M_{4}}\frac{1} {2^{d_{4}}},\mathbb{P}(X^{(3)}=M_{3}|X^{(4)}=M_{4},\mathcal{H})=(1+o(1))\binom{ d_{3}}{M_{3}}\frac{1}{2^{d_{3}}},\mathbb{P}(X^{(2)}=M_{2}|X^{(3)}=M_{3},X^{(4)}=M_{4}, \mathcal{H})=(1+o(1))\binom{d_{2}}{M_{2}}\frac{1}{2^{d_{2}}},\) and \(\mathbb{P}(X^{(1)}=M_{1}|X^{(2)}=M_{2},X^{(3)}=M_{3},X^{(4)}=M_{4},\mathcal{H} )=(1+o(1))\binom{d_{1}}{M_{1}}\frac{1}{2^{d_{1}}}\). Collectively, these form the asymptotic independence of \(X^{(i)}\):

\[\mathbb{P}(X^{(1)}=M_{1},X^{(2)}=M_{2},X^{(3)}=M_{3},X^{(4)}=M_{4 }\mid\mathcal{H})\\ =(1+o(1))\binom{d_{1}}{M_{1}}\binom{d_{2}}{M_{2}}\binom{d_{3}}{M_ {3}}\binom{d_{4}}{M_{4}}\frac{1}{2^{d_{1}+d_{2}+d_{3}+d_{4}}}.\qed\]

Lemma 11 discusses the case of \(k=-1\). We do not expect the same property holds for \(k\geq 0\) but we have an auxiliary result as in the following Corollary 1.

**Corollary 1**.: _(If \(k\geq 0\), then \(\dot{U}_{P}\) contains cycles.) By definition, \(\dot{U}_{P}\) can be decomposed into a tree \(T_{P}\) with \(v_{P}\) vertices other than the root and additional \(k+1\) distinct edges \(E_{k+1}=\{(u_{j},v_{j})\}_{i=j}^{k+1}\) fixed. By edges' decorations, \(E_{k+1}=E^{(1)}\cup E^{(2)}\cup E^{(3)}\cup E^{(4)}\). Let \(X^{(i)}\) still be the random variable representing the number of \(i\)-decorated in-community edges on \(\dot{U}_{N}\). If \(k\geq 0\), let \(X^{(i,a)}\) be the counts of \(i\)-decorated in-community edges on \(T_{N}\) and \(X^{(i,b)}\) be the counts of \(i\)-decorated in-community edges on \(\{e_{i}\}_{i=1}^{k+1}\). From construction, we know \(X^{(i)}=X^{(i,a)}+X^{(i,b)}\). Correspondingly, there are \(A_{i}\)\(i\)-decorated edges on tree, \(B_{i}=|E^{(i)}|\), and \(d_{i}=A_{i}+B_{i}\), which are all fixed from \(\dot{U}_{P}\)._

_Then, \(\mathbb{P}(X^{(1,a)}=a_{1},X^{(2,a)}=a_{2},X^{(3,a)}=a_{3},X^{(4,a)}=a_{4},X^{(2,b )}=b_{2},X^{(1,b)}=b_{1},X^{(3,b)}=b_{3},X^{(4,b)}=b_{4}\mid\mathcal{H})\leq(1+o(1 ))\binom{A_{1}}{a_{1}}\binom{A_{2}}{a_{2}}\binom{A_{3}}{a_{3}}\binom{A_{4}}{a_{ 4}}\frac{1}{2^{A_{1}+A_{2}+A_{3}+A_{4}}}.\)_

The proof follows straightforwardly from the proof of Lemma 11.

### Inequalities concerning automorphisms

In this subsection, we study how adding edges can change the number of rooted automorphisms of a rooted tree. With a slight abuse of notation, we denote by \(\operatorname{aut}(T)\) the number of rooted automorphisms (i.e., automorphisms which fix the root) of a rooted tree \(T\). We start by quantifying the effect of adding an additional edge.

**Lemma 12**.: _Let \(T=(V,E,r)\) be a rooted tree with root \(r\). Let \(T^{\prime}:=(V\cup\{u\},E\cup\{(u,v)\},r)\) be the rooted tree obtained from \(T\) by adding a vertex \(u\) and the edge \((u,v)\), where \(v\in V\). The following bounds hold:_

\[\operatorname{aut}(T)\times\frac{1}{|V|-1}\leq\operatorname{aut}(T^{\prime}) \leq\operatorname{aut}(T)\times|V|,\] (16)

_where \(|V|\) is the number of vertices in \(T\)._

Proof.: Since \(T\) is a rooted tree, there is a natural notion of a _parent_ vertex for every vertex other than the root. Namely, the parent of a vertex \(v\neq r\) is the neighbor of \(v\) which is closest to the root \(r\). We also define the _subtree rooted at \(v\)_ to be the subtree of \(T\) induced by all vertices whose shortest path to \(r\) goes through \(v\), rooted at \(v\).

We partition \(V\) into equivalence classes according to the following rule: \(v_{1}\) and \(v_{2}\) are in the same equivalence class if and only if they share the same parent and the subtrees rooted at \(v_{1}\) and \(v_{2}\) are isomorphic. We denote the resulting partition as \(\{V_{i}\}_{i\in\mathcal{I}}\) and refer to the equivalence classes as orbits. Note that the root \(r\) is always in a single-element orbit and thus the size of each orbit is at most \(|V|-1\).

Observe that a permutation of the vertices is a rooted automorphism precisely when it maps each vertex to a vertex in its orbit. Thus we have that

\[\operatorname{aut}(T)=\prod_{i\in\mathcal{I}}|V_{i}|!.\] (17)

Now consider \(T^{\prime}\), which adds a new vertex \(u\) to \(T\) with an edge connecting \(u\) to a vertex in \(T\). By (17), in order to understand \(\operatorname{aut}(T^{\prime})\), we need to understand how the orbits and their sizes change due to the addition of the new vertex and edge. The new vertex \(u\) will either join an existing orbit or form its own one. The parent of \(u\) may change orbits, so might the parent of its parent, etc. In other words, the vertices on the path from \(u\) to the root \(r\) might change their orbit, but vertices not on this path will not. In the following, we argue iteratively based on the depth of \(u\) in \(T^{\prime}\) (i.e., its distance from the root). When considering the upper bound, we will ignore the possible size decrease of orbits. When considering the lower bound, we will ignore the possible size increase of orbits.

Figure 5: Decomposition of a decorated tree into three sequences of trees. Edges that are 2, 3, \(4\)-decorated are painted as red, green, and blue color correspondingly. Roots of each subtree is marked by larger node and annotated as \(r(T_{j}^{(i)})\), where \(i\) is the decoration counts and \(j\) is the order in its sequence.

Assume first that the new vertex \(u\) is attached to the root \(r\). If there are no leaves except for \(u\) connecting to \(r\), then \(u\) forms a new orbit \(V_{|\mathcal{I}|+1}\) whose size is \(1\), which does not change the number of rooted automorphisms. Otherwise, without loss of generality, assume that orbit \(V_{1}\) is the set that contains all leaves connected to \(r\). Then \(u\) will join this orbit, so the set of orbits of \(T^{\prime}\) is given by \(V_{1}\cup\{u\}\) and \(\{V_{i}\}_{i=2}^{|\mathcal{I}|}\). Thus, we have that \(\operatorname{aut}(T^{\prime})=\operatorname{aut}(T)(|V_{1}|+1)\), so in particular

\[\operatorname{aut}(T)\leq\operatorname{aut}(T^{\prime})=\operatorname{aut}(T) (|V_{1}|+1)\leq\operatorname{aut}(T)\times|V|.\]

Now suppose that \(u\) has depth \(2\) in \(T^{\prime}\), and let \(v^{(1)}\) denote the parent of \(u\) in \(T^{\prime}\). Without loss of generality, assume that \(v^{(1)}\in V_{1}\). There are again two cases depending on whether or not there are leaves attached to \(v^{(1)}\) in \(T\). Suppose first that there are not any leaves attached to \(v^{(1)}\) in \(T\). Then \(u\) has its own orbit (of size \(1\)) in \(T^{\prime}\). The orbit of \(v^{(1)}\) changes from \(V_{1}\) in \(T\) to either a new orbit or some existing orbit \(V_{j_{1}}\) in \(T^{\prime}\) (for some \(2\leq j_{1}\leq|\mathcal{I}|\)). In the former case we have that \(\operatorname{aut}(T^{\prime})=\operatorname{aut}(T)/|V_{1}|\), while in the latter case we have that

\[\operatorname{aut}(T^{\prime})=\operatorname{aut}(T)\times\frac{|V_{j_{1}}|+1 }{|V_{1}|}.\]

The desired inequalities thus follow since each orbit has size at most \(|V|-1\). Now suppose that there are leaves attached to \(v^{(1)}\) in \(T\) and let \(V_{2}\) denote the equivalence class of these vertices. Then, \(u\) joins the orbit \(V_{2}\) in \(T^{\prime}\). The orbit of \(v^{(1)}\) again changes from \(V_{1}\) in \(T\) to either a new orbit or some existing orbit \(V_{j_{1}}\) in \(T^{\prime}\) (for some \(3\leq j_{1}\leq|\mathcal{I}|\)). In the former case we have that \(\operatorname{aut}(T^{\prime})=\operatorname{aut}(T)\times(|V_{2}|+1)/|V_{1}|\), while in the latter case we have that

\[\operatorname{aut}(T^{\prime})=\operatorname{aut}(T)\times\frac{(|V_{2}|+1)(| V_{j_{1}}|+1)}{|V_{1}|}.\]

The lower bound follows since \(|V_{1}|\leq|V|-1\). For the upper bound in the latter case, note that by the definition of orbits, in \(T^{\prime}\) there are \(|V_{j_{1}}|+1\) nodes at depth \(1\) who each have \(|V_{2}|+1\) children that are leaves. This implies that \(T^{\prime}\) has at least \((|V_{2}|+1)(|V_{j_{1}}|+1)\) non-root vertices, so \((|V_{2}|+1)(|V_{j_{1}}|+1)\leq(|V|+1)-1=|V|\).

The general case when \(u\) has depth \(\ell\) in \(T^{\prime}\) is analogous. Let \(v^{(\ell-1)}\) denote the parent of \(u\) in \(T^{\prime}\), let \(v^{(\ell-2)}\) denote the parent of \(v^{(\ell-1)}\), etc. Without loss of generality, let \(V_{i}\) denote the orbit of \(v^{(i)}\) in \(T\), for \(i\in[\ell-1]\). Suppose that \(v^{(\ell-1)}\) has children that are leaves in \(T\) (the other case, when it does not, is similar and simpler), and let \(V_{\ell}\) denote the equivalence class of these vertices. Then, using similar observations as above, we obtain the following upper and lower bounds on \(\operatorname{aut}(T^{\prime})\):

\[\operatorname{aut}(T)\times\frac{1}{\prod_{i=1}^{\ell-1}|V_{i}|}\leq \operatorname{aut}(T^{\prime})\leq\operatorname{aut}(T)\times(|V_{\ell}|+1) \times\prod_{i=1}^{\ell-1}\left(|V_{j_{i}}|+1\right).\]

Here, for every \(i\in[\ell-1]\), either \(j_{i}\in[\ell+1,|\mathcal{I}|]\) (which corresponds to \(v^{(i)}\) changing from \(V_{i}\) in \(T\) to some existing orbit \(V_{j_{i}}\) in \(T^{\prime}\)) or \(|V_{j_{i}}|=0\) (which corresponds to \(v^{(i)}\) changing from \(V_{i}\) in \(T\) to a new orbit in \(T^{\prime}\)). To conclude the lower bound, observe (using the definition of orbits) that \(T\) contains a subtree consisting of the root and \(\prod_{i=1}^{\ell-1}|V_{i}|\) additional vertices, so \(\prod_{i=1}^{\ell-1}|V_{i}|\leq|V|-1\). For the upper bound, observe similarly that \(T^{\prime}\) contains a subtree consisting of the root and \((|V_{\ell}|+1)\times\prod_{i=1}^{\ell-1}\left(|V_{j_{i}}|+1\right)\) additional vertices, so \((|V_{\ell}|+1)\times\prod_{i=1}^{\ell-1}\left(|V_{j_{i}}|+1\right)\leq|V|\). 

**Lemma 12 is tight.** Let \(T\) be a star rooted at its center (i.e., a tree where all vertices except the root are connected to the root). Then all permutations of the vertices that fix the root are rooted automorphisms, so \(\operatorname{aut}(T)=(|V(T)|-1)!\). Now let \(T^{\prime}\) be a tree obtained from \(T\) by adding an additional child to the root (see Figure 6, tree in the middle). Then \(\operatorname{aut}(T^{\prime})=(|V(T)|)!=\operatorname{aut}(T)\times|V(T)|\). This shows that the upper bound in Lemma 12 is tight. Now let \(T^{\prime\prime}\) be a tree obtained from \(T\) by adding a child to one of the leaves of \(T\) (see Figure 6, tree on the right). The rooted automorphisms of \(T^{\prime\prime}\) are precisely the permutations of the vertices that permute the neighbors of the root which are leaves, so \(\operatorname{aut}(T^{\prime\prime})=(|V(T)|-2)!=\operatorname{aut}(T)/(|V(T)|-1)\). This shows that the lower bound in Lemma 12 is tight.

From Lemma 12, we can derive the following corollary by an iterative argument.

**Corollary 2**.: _Let \(T_{1}=(V_{1},E_{1},r)\) and \(T_{2}=(V_{2},E_{2},r)\) be two trees rooted at the same vertex \(r\). Define the union \(T_{1}\cup T_{2}:=(V_{1}\cup V_{2},E_{1}\cup E_{2},r)\) by taking the union of the two vertex sets (both of which contain \(r\)) and the union of the two edge sets, with multiple edges ignored (i.e., if an edge appears in both \(E_{1}\) and \(E_{2}\), then it appears in \(E_{1}\cup E_{2}\) exactly once). Suppose that \(T_{1}\cup T_{2}\) is also a tree. Let \(d:=|E_{1}\triangle E_{2}|\) denote the size of the symmetric difference of the edge sets. Then_

\[\sqrt{\mathrm{aut}(T_{1})\mathrm{aut}(T_{2})}\leq\mathrm{aut}(T_{1}\cup T_{2}) \times(2\max\{|V_{1}|,|V_{2}|\})^{d}.\] (18)

Proof.: By the assumptions on \(T_{1}\) and \(T_{2}\), the union \(T_{1}\cup T_{2}\) has \((|V_{1}|+|V_{2}|+d)/2-1\) edges. There are two natural ways that we can think of \(T_{1}\cup T_{2}\). First, we can start from \(T_{1}\) and add \((|V_{2}|-|V_{1}|+d)/2\) new vertices--those that are in \(V_{2}\) but not in \(V_{1}\)--one at a time, together with a new edge for each new added vertex, connecting it to an existing vertex, to obtain \(T_{1}\cup T_{2}\). With this perspective, applying the lower bound in (16) from Lemma 12 across each of the \((|V_{2}|-|V_{1}|+d)/2\) steps, we obtain that

\[\mathrm{aut}(T_{1})\leq\mathrm{aut}(T_{1}\cup T_{2})\prod_{k=|V_{1}|-1}^{(|V_ {1}|+|V_{2}|+d)/2-2}k.\] (19)

On the other hand, we can equally well start from \(T_{2}\) and add \((|V_{1}|-|V_{2}|+d)/2\) new edges and vertices to obtain \(T_{1}\cup T_{2}\). Thus, analogously, (19) also holds with \(\mathrm{aut}(T_{1})\) on the left hand side replaced with \(\mathrm{aut}(T_{2})\), and \(|V_{1}|-1\) on the right hand side (the minimum value of \(k\) in the product) replaced with \(|V_{2}|-1\).

Combining these two inequalities, we obtain that

\[\sqrt{\mathrm{aut}(T_{1})\mathrm{aut}(T_{2})}\leq\mathrm{aut}(T_{1}\cup T_{2} )\times\prod_{k=\min\{|V_{1}|,|V_{2}|\}-1}^{(|V_{1}|+|V_{2}|+d)/2-2}k.\]

Since \(d\leq 2(\max\{|V_{1},V_{2}|\}-1)\), it follows that \((|V_{1}|+|V_{2}|+d)/2-2\leq 2\max\{|V_{1}|,|V_{2}|\}\), so all factors in the product above are at most \(2\max\{|V_{1}|,|V_{2}|\}\). Note also that \(d\geq\max\{|V_{1},V_{2}|\}-\min\{|V_{1},V_{2}|\}\), so the number of factors in the product above is \((\max\{|V_{1},V_{2}|\}-\min\{|V_{1},V_{2}|\}+d)/2\leq d\). Putting these observations together we see that (18) holds. 

**Remark 4**.: _The leftmost example in Figure 6 provides an example showing that the right hand side of (18) would no longer be an upper bound without the factor \((2\max\{|V_{1}|,|V_{2}|\})^{d}\)._

### Auxiliary result: Bounds on the cross-moments

In this section, we summarize the upper bound on cross-moments. In Lemma 13, we work on the regime \(sD_{+}(a,b)>1\) where we can recover the community label exactly first. In Lemma 14, we work on the regime \(sD_{+}(a,b)<1\) where we we have a inverse polynomial fraction of vertices being labeled incorrectly.

Figure 6: _Left_: The simplest example of two rooted trees \(T_{1}\) and \(T_{2}\) satisfying \(\sqrt{\mathrm{aut}(T_{1})\mathrm{aut}(T_{2})}>\mathrm{aut}(T_{1}\cup T_{2})\); here \(T_{1}\) is induced by the blue and green edges, \(T_{2}\) is induced by the blue and red edges, and both trees are rooted at the vertex at the top. _Middle_: Example that shows that the upper bound in Lemma 12 is tight, where blue lines and black vertices represent \(T\), and the red vertex is additionally added with an edge attaching it to the root. _Right_: Example that shows that the lower bound in Lemma 12 is tight.

**Lemma 13**.: _Let \((G_{1},G_{2})\sim\mathrm{CSBM}(n,p,q,s),p=\frac{a\log n}{n},q=\frac{b\log n}{n}\). Denote \(\overline{A},\overline{B}\) as the centralized adjacency matrices of \(G_{1}\) and \(G_{2}\) correspondingly. Let \(e:=(u,v)\in[n]\times[n]\) be an arbitrary edge. Define the edge type indicator \(c(e)=+\) if \(e\) is an in-community edge and \(c(e)=-\) if \(e\) is a cross-community edge under \(\bm{\sigma}_{*}\). The following holds for \(0\leq\ell,m\leq 2,2\leq\ell+m\leq 4\), and any \(\bm{\sigma}_{*}\),_

\[\beta_{\ell,m}(e):=\sigma_{c(e)}^{-(\ell+m)}\mathbb{E}[\overline{A}_{e}^{\ell }\overline{B}_{e}^{m}\mid\bm{\sigma}_{*}]\leq\begin{cases}1&(\ell,m)=(2,0),(0,2 )\\ (1+\Theta(\frac{\log n}{n}))\rho&(\ell,m)=(1,1)\\ \frac{1}{\sqrt{s(p\wedge q)}}&(\ell,m)=(2,1),(1,2)\\ \frac{1}{s(p\wedge q)}&(\ell,m)=(2,2).\end{cases}\]

Proof.: Conditioning on a specific true community label vector that satisfies the balanced community event \(\mathcal{H}\), we can apply Lemma 5 from [42] for each case of \(c(e)=+\) and \(c(e)=-\). Then, the upper bound are different in terms of \(p,q\) and \(\rho_{+},\rho_{-}\). When \((\ell,m)=(1,1)\), \(\beta_{\ell,m}\leq\max\{|\rho_{+}|,|\rho_{-}|\}\leq(1+\Theta(\frac{\log n}{n}))\rho\). When \((\ell,m)=(2,1)\) or \((1,2)\), if \(c(e)=+\), then we have \(\beta_{\ell,m}\leq\frac{1}{\sqrt{sp}}\), else we have \(\beta_{\ell,m}\leq\frac{1}{\sqrt{sq}}\). Therefore, \(\beta_{\ell,m}\leq\frac{1}{\sqrt{s(p\wedge q)}}\). The same argument holds for the case when \((\ell,m)=(2,2)\). 

**Lemma 14**.: _Let \((G_{1},G_{2})\sim\mathrm{CSBM}(n,p,q,s),p=\frac{a\log n}{n},q=\frac{b\log n}{n}\). Denote \(\overline{A}^{\widehat{\bm{\sigma}}_{A}},\overline{B}^{\widehat{\bm{\sigma}}_ {B}}\) as the approximately centralized adjacency matrices of \(G_{1}\) and \(G_{2}\) correspondingly. Let \(e:=(u,v)\in[n]\times[n]\) be an arbitrary edge. Define the edge type indicator \(c(e)=+\) if \(e\) is an in-community edge and \(c(e)=-\) if \(e\) is a cross-community edge under \(\bm{\sigma}_{*}\). Define \(\Delta:=|sp-sq|\). The following holds for \(0\leq\ell,m\leq 2,1\leq\ell+m\leq 4\), and any \(\bm{\sigma}_{*},\widehat{\bm{\sigma}}=(\widehat{\bm{\sigma}}_{A},\widehat{ \bm{\sigma}}_{B})\),_

\[\eta_{\ell,m}(e):=\sigma_{c(e)}^{-(\ell+m)}\mathbb{E}[\overline{A}_{e}^{ \widehat{\bm{\sigma}}_{A},\ell}\overline{B}_{e}^{\widehat{\bm{\sigma}}_{B},m} \mid\bm{\sigma}_{*},\widehat{\bm{\sigma}}]\leq\begin{cases}\Theta(\sqrt{ \Delta})&(\ell,m)=(0,1),(1,0)\\ 1+\Theta(\frac{\log n}{n})&(\ell,m)=(2,0),(0,2)\\ \rho(1+\Theta(\frac{\log n}{n}))&(\ell,m)=(1,1)\\ \frac{1}{\sqrt{\frac{\Theta(p\wedge q)}{n}}}(1+\Theta(\frac{\log n}{n}))&( \ell,m)=(2,1),(1,2)\\ \frac{1}{s(p\wedge q)}(1+\Theta(\frac{\log n}{n}))&(\ell,m)=(2,2).\end{cases}\]

Proof.: Denote the two vertices on \(e\) as \(u\) and \(v\). We denote \(p^{\prime}:=sp\) and \(q^{\prime}:=sq\).

**(a)**\(\ell+m=1\). Without loss of generality, we consider \(\ell=1\) and \(m=0\).

\[\mathbb{E}[\overline{A}_{e}^{\widehat{\bm{\sigma}}_{A},1}\mid\bm{\sigma}_{*}, \widehat{\bm{\sigma}}]=\begin{cases}0,&\bm{\sigma}_{*}(u)\bm{\sigma}_{*}(v)= \widehat{\bm{\sigma}}_{A}(u)\widehat{\bm{\sigma}}_{A}(v),\\ \pm\Delta,&\bm{\sigma}_{*}(u)\bm{\sigma}_{*}(v)\neq\widehat{\bm{\sigma}}_{A}(u) \widehat{\bm{\sigma}}_{A}(v).\end{cases}\]

When \(\mathbb{E}[\overline{A}_{e}^{\widehat{\bm{\sigma}}_{A},1}\mid\bm{\sigma}_{*}, \widehat{\bm{\sigma}}]\) is non-zero, \(\sigma_{c(e)}^{-1}\mathbb{E}[\overline{A}_{e}^{\widehat{\bm{\sigma}}_{A},1} \mid\bm{\sigma}_{*},\widehat{\bm{\sigma}}]=\Theta(\sqrt{\Delta})\).

**(b)**\(\ell+m=2\). We first consider the case of \(\ell=2\) or \(m=2\).

We explicitly calculate the expectation on the following two cases. If \(\bm{\sigma}_{*}(u)\bm{\sigma}_{*}(v)=\widehat{\bm{\sigma}}(u)\widehat{\bm{ \sigma}}(v)\), then \(\mathbb{E}[\overline{A}_{e}^{\widehat{\bm{\sigma}}_{A},2}\mid\bm{\sigma}_{*}, \widehat{\bm{\sigma}}]=p^{\prime}(1-p^{\prime})=\sigma_{c(e)}^{2}\). If \(\bm{\sigma}_{*}(u)\bm{\sigma}_{*}(v)\neq\widehat{\bm{\sigma}}(u)\widehat{\bm{ \sigma}}(v)\), then \(\mathbb{E}[\overline{A}_{e}^{\widehat{\bm{\sigma}}_{A},2}\mid\bm{\sigma}_{*}, \widehat{\bm{\sigma}}]=p^{\prime}-2p^{\prime}q^{\prime}+q^{\prime 2}=\sigma_{c(e)}^{2}+\Delta^{2}\).

In summary, we have

\[\mathbb{E}[\overline{A}_{e}^{\widehat{\bm{\sigma}}_{A},2}\mid\bm{\sigma}_{*}, \widehat{\bm{\sigma}}]=\mathbb{E}[\overline{B}_{e}^{\widehat{\bm{\sigma}}_{B},2} \mid\bm{\sigma}_{*},\widehat{\bm{\sigma}}]\leq\sigma_{c(e)}^{2}+\Delta^{2}= \sigma_{c(e)}^{2}(1+\Theta(\frac{\log n}{n})).\]

We next consider the case of \(\ell=m=1\). If \(\bm{\sigma}_{*}(u)\bm{\sigma}_{*}(v)=\widehat{\bm{\sigma}}(u)\widehat{\bm{ \sigma}}(v)\), then \(\mathbb{E}[\overline{A}_{e}^{\widehat{\bm{\sigma}}_{A},1}\overline{B}_{e}^{ \widehat{\bm{\sigma}}_{B},1}\mid\bm{\sigma}_{*},\widehat{\bm{\sigma}}]=\rho_{c(e )}\sigma_{c(e)}^{2}\). If \(\bm{\sigma}_{*}(u)\bm{\sigma}_{*}(v)\neq\widehat{\bm{\sigma}}(u)\widehat{\bm{ \sigma}}(v)\), then \(\mathbb{E}[\overline{A}_{e}^{\widehat{\bm{\sigma}}_{A},1}\overline{B}_{e}^{ \widehat{\bm{\sigma}}_{B},1}\mid\bm{\sigma}_{*},\widehat{\bm{\sigma}}]=\rho_{c( e)}\sigma_{c(e)}^{2}+\Delta^{2}\).

In summary, we have

\[\mathbb{E}[\overline{A}_{e}^{\widehat{\bm{\sigma}}_{A},1}\overline{B}_{e}^{ \widehat{\bm{\sigma}}_{B},1}\mid\bm{\sigma}_{*},\widehat{\bm{\sigma}}]\leq\rho_{c( e)}\sigma_{c(e)}^{2}+\Delta^{2}=\rho\sigma_{c(e)}^{2}(1+\Theta(\frac{\log n}{n}))\]

**(c)**\(\ell+m=3\)**. With loss of generality, we assume that this edge connects two vertices from different communities. Conditioned on correct centralization, we can compute

\[\mathbb{E}[\overline{A}_{e}^{\widehat{\bm{\sigma}}_{A},2}\overline{B}_{e}^{ \widehat{\bm{\sigma}}_{B},1}\mid\bm{\sigma}_{*},\widehat{\bm{\sigma}}]=\mathbb{ E}[\overline{A}_{e}^{2}\overline{B}_{e}\mid\bm{\sigma}_{*}]=qs^{2}(1-q)(1-2qs)= \sigma_{-}^{3}\frac{\rho_{-}(1-2q^{\prime})}{\sqrt{q^{\prime}(1-q^{\prime})}} \leq\sigma_{-}^{3}\frac{1}{\sqrt{q^{\prime}}},\]

which is the same as in Lemma 13. If the centralization is incorrect for both graphs, the expectation changes to the following:

\[\mathbb{E}[\overline{A}_{e}^{\widehat{\bm{\sigma}}_{A},2}\overline{B}_{e}^{ \widehat{\bm{\sigma}}_{B},1}\mid\bm{\sigma}_{*},\widehat{\bm{\sigma}}]=q^{ \prime}s-p^{\prime}q^{\prime}-2p^{\prime}q^{\prime}s+3p^{\prime 2}q^{\prime}-p^{ \prime 3}.\]

From observation, we see that the dominant part in both cases are the same, which is \(q^{\prime}s=\Theta(\frac{\log n}{n})\). Then, we can show that the difference between two quantities are minor:

\[\frac{\mathbb{E}[\overline{A}_{e}^{\widehat{\bm{\sigma}}_{A},2} \overline{B}_{e}^{\widehat{\bm{\sigma}}_{B},1}\mid\bm{\sigma}_{*},\widehat{ \bm{\sigma}}]-\mathbb{E}[\overline{A}_{e}^{2}\overline{B}_{e}\mid\bm{\sigma}_ {*}]}{\sigma_{-}^{3}}=\frac{(p^{\prime}-q^{\prime})(p^{\prime 2}-2p^{\prime}q^{ \prime}-2q^{\prime 2}+q^{\prime}+2q^{\prime}s)}{q^{\prime}(1-q^{\prime})\sqrt{q^{ \prime}(1-q^{\prime})}}=\Theta(\sqrt{q^{\prime}}).\] (20)

The above (20) also holds for the case when \(e\) is classified correctly in \(A\) or \(B\) only.

By also considering the other case, that is, this edge is connects two vertices from the same community but wrongly centralized according to \(\widehat{\bm{\sigma}}\), we conclude with

\[\mathbb{E}[\overline{A}_{e}^{\widehat{\bm{\sigma}}_{A},2}\overline{B}_{e}^{ \widehat{\bm{\sigma}}_{B},1}\mid\bm{\sigma}_{*},\widehat{\bm{\sigma}}]\leq \sigma_{c(e)}^{3}\frac{1}{\sqrt{s(p\wedge q)}}(1+\Theta(s(p\wedge q)))=\sigma _{c(e)}^{3}\frac{1}{\sqrt{s(p\wedge q)}}(1+\Theta(\frac{\log n}{n}))\]

**(d)**\(\ell+m=4\)**. With loss of generality, we assume that this edge connects two vertices from different communities. For the correct centralization, the moment stays the same as in Lemma 13,

\[\mathbb{E}[\overline{A}_{e}^{2}\overline{B}_{e}^{2}\mid\bm{\sigma}_{*}]=q^{ \prime}s-4q^{\prime 2}s+4q^{\prime 3}s+2q^{\prime 3}-3q^{\prime 4}=q^{\prime 2}(1-q^{ \prime})^{2}+q^{\prime}(1-q^{\prime})\rho_{-}(1-2q^{\prime})^{2}\leq\sigma_{- }^{4}\frac{1}{q^{\prime}}.\]

If the centralization is incorrect for both graphs, we have

\[\mathbb{E}[\overline{A}_{e}^{\widehat{\bm{\sigma}}_{A},2}\overline{B}_{e}^{ \widehat{\bm{\sigma}}_{B},2}\mid\bm{\sigma}_{*},\widehat{\bm{\sigma}}]=q^{ \prime}s-4p^{\prime}q^{\prime}s+4p^{\prime 2}q^{\prime}s+2p^{\prime 2}q^{ \prime}-4p^{\prime 3}q^{\prime}+p^{\prime 4},\]

and we can show that the error has the following order

\[\mathbb{E}[\overline{A}_{e}^{\widehat{\bm{\sigma}}_{A},2}\overline{B}_{e}^{ \widehat{\bm{\sigma}}_{B},2}\mid\bm{\sigma}_{*},\widehat{\bm{\sigma}}]- \mathbb{E}[\overline{A}_{e}^{\widehat{\bm{\sigma}}_{A},2}\overline{B}_{e}^{ \widehat{\bm{\sigma}}_{B},2}\mid\bm{\sigma}_{*}]\leq\Theta((\frac{\log n}{n}) ^{2})=\Theta(\sigma_{c(e)}^{4}).\] (21)

When the centralization is incorrect for only one graph, (21) still holds.

By also considering the other case, that is, this edge is connects two vertices from the same community but wrongly centralized according to \(\widehat{\bm{\sigma}}\), we conclude with

\[\mathbb{E}[\overline{A}_{e}^{\widehat{\bm{\sigma}}_{A},2}\overline{B}_{e}^{ \widehat{\bm{\sigma}}_{B},2}\mid\bm{\sigma}_{*},\widehat{\bm{\sigma}}]\leq \Theta(\sigma_{c(e)}^{4})+\sigma_{c(e)}^{4}\frac{1}{s(p\wedge q)}\leq\sigma_{ c(e)}^{4}\frac{1}{s(p\wedge q)}(1+\Theta(\frac{\log n}{n})).\qed\]

## Appendix E Proof of Theorem 3: Almost exact graph matching

Fix constants \(a\neq b>0,s\in[0,1]\). Throughout the paper, we refer to \(sD_{+}(a,b)>1\) as Regime I and \(sD_{+}(a,b)<1\) as Regime II. We define \(\mu:=|\mathcal{T}|n^{N}\rho^{N}\sigma_{\text{eff}}^{2N}\), where \(\sigma_{\text{eff}}^{2}=\frac{\sigma_{+}^{2}+\sigma_{-}^{2}}{2}\). Depending on the different parameter regimes, the analysis is different. We first present the first and second moment bounds for both regimes and then prove Theorem 3.

### Regime I: Exact community recovery is possible for a single graph

**Proposition 1** (Mean calculation, \(sD_{+}(a,b)\geq 1\)).: _Given \((G_{1},G_{2})\sim\mathrm{CSBM}(n,\frac{a\log n}{n},\frac{b\log n}{n},s)\), the similarity score satisfies,_

\[\mathbb{E}[\Phi_{ij}\bm{1}_{\mathcal{H}}]=\begin{cases}(1+o(1))\mu,&\text{if } \pi_{*}(i)=j,\\ 0,&\text{if }\pi_{*}(i)\neq j.\end{cases}\]

**Proposition 2** (Variance calculation-True pairs, \(sD_{+}(a,b)>1\)).: _Suppose that \(j=\pi_{*}(i)\), that \(sD_{+}(a,b)>1\), and that_

\[\frac{14L^{2}}{\rho^{2(K+M)}(|\mathcal{J}|)}\leq\frac{1}{2}, \quad\frac{22R^{4}(2N+1)(11\beta)^{2(K+M)}}{n}\leq\frac{1}{2},\] \[\frac{4R^{\frac{M}{M}}(11\beta)^{\frac{4K+4M}{M}}}{ns(p\wedge q)} \leq\frac{1}{2},\quad\frac{1+2L^{2}}{ns(p\wedge q)}\leq\frac{1}{4}.\] (22)

_Then, for any \(i\in[n]\), we have_

\[\frac{\mathrm{Var}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}]}{\mathbb{E}[\Phi_{i\pi_{ *}(i)}\mathbf{1}_{\mathcal{H}}]^{2}}=O\left(\frac{L^{2}}{\rho^{2}ns(p\wedge q)} +\frac{L^{2}}{\rho^{2(K+M)}|\mathcal{J}|}\right).\]

**Proposition 3** (Variance calculation-Fake pairs, \(sD_{+}(a,b)>1\)).: _Suppose that \(j\neq\pi_{*}(i)\), that \(sD_{+}(a,b)>1\), and that_

\[4^{L+4}L^{2L\wedge(4K+2)}(11\beta)^{8(K+M)}R^{4}(2N+1)^{3}\leq\frac{n}{2}, \quad\frac{4R^{\frac{2}{M}}(11\beta)^{\frac{4(K+M)}{M}}}{ns(p\wedge q)}\leq \frac{1}{2}.\] (23)

_Then, for any \(i\in[n]\), we have_

\[\frac{\mathrm{Var}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}]}{\mathbb{E}[\Phi_{i\pi_{ *}(i)}\mathbf{1}_{\mathcal{H}}]^{2}}=O(\frac{1}{|\mathcal{T}|\rho^{2N}}).\]

### Regime II: Exact community recovery is impossible for a single graph

Before getting into the details of proof, let us first give more intuition on the approximately centralized adjacency matrix.

In this regime, for each element in the adjacency matrix, there are four cases: (1) Correct centralization for in-community edges; (2) Incorrect centralization for in-community edges; (3) Correct centralization for cross-community edges; (4) Incorrect centralization for cross-community edges. Figure 7 gives an example of how the graphon for balanced 2-community SBM changes under community label misclassifications.

**Proposition 4** (Mean calculation, \(sD_{+}(a,b)<1\)).: _Let \((G_{1},G_{2})\sim\mathrm{CSBM}(n,\frac{a\log n}{n},\frac{b\log n}{n},s)\). Given \((K,L,M,R,D)\)-Chandelier class \(\mathcal{T}\). Assume that \(D=o(\frac{\log n}{\log\log n})\)._

_For all \(i\in[n]\) with \(j=\pi_{*}(i)\), we have_

\[\mathbb{E}[\Phi_{i\pi_{*}(i)}^{\widehat{\boldsymbol{\sigma}}}\mathbf{1}_{ \mathcal{H}}]=(1+o(1))\mu.\]

Figure 7: Illustration on the impact of incorrect community labels on adjacency matrix centralization with \(G\sim\mathrm{SBM}(n,0.3,0.1)\). Centralized adjacency matrix \(\overline{A}^{\widehat{\boldsymbol{\sigma}}_{A}}=A-\mathbb{E}[A]\), where matrix \(\mathbb{E}[A]\) takes the value of discretized graphon as above.

_For all \(i\in[n]\) with \(j\neq\pi_{*}(i)\), we have_

\[\mathbb{E}[\Phi_{ij}^{\widehat{\bm{\rho}}}\mathbf{1}_{\mathcal{H}}]=o(\mu).\]

**Proposition 5** (Variance calculation-True pairs, \(sD_{+}(a,b)<1\)).: _Suppose that \(j=\pi_{*}(i)\), \(sD_{+}(a,b)<1\), \(L=o(n)\), and that for some \(c>0\),_

\[\frac{4R^{\frac{2}{M}}(15\beta)^{2\frac{K+M}{M}}}{ns(p\wedge q)} \leq\frac{1}{2},\quad\frac{30R^{4}(2N+1)^{2}(15\beta)^{4(K+M)}}{n}\leq\frac{1} {2},\] \[\frac{sD_{+}(a,b)}{D}\geq\frac{(\log\log n)^{2}}{\log n},\quad 2NL(4 LM)^{6L}\leq\log^{c}n.\] (24)

_Then, for any \(i\in[n]\), we have_

\[\frac{\mathrm{Var}[\Phi_{ij}^{\widehat{\bm{\rho}}}\mathbf{1}_{ \mathcal{H}}]}{\mathbb{E}[\Phi_{i\pi_{*}(i)}^{\widehat{\bm{\rho}}}\mathbf{1}_ {\mathcal{H}}]^{2}}=O\left(\frac{L^{2}}{\rho^{2}ns(p\wedge q)}+\frac{L^{2}}{ \rho^{2(K+M)}|\mathcal{J}|}\right).\]

**Proposition 6** (Variance calculation-Fake pairs, \(sD_{+}(a,b)<1\)).: _Suppose that \(j\neq\pi_{*}(i)\), \(sD_{+}(a,b)<1\), \(N=\Theta(\log n)\), \(D=o(\frac{\log n}{\log\log n})\), and that_

\[\frac{4R^{\frac{2}{M}}(15\beta)^{2\frac{K+M}{M}}}{ns(p\wedge q)} \leq\frac{1}{2},\quad\frac{sD_{+}(a,b)}{D}\geq\frac{(\log\log n)^{2}}{\log n},\] \[\left(\frac{(15\beta)^{2(K+M)}30R^{4}(4n+1)^{2}}{n}\right)(2 \beta)^{8(K+M)}(4LM)^{4L}(4L)!\leq\frac{1}{2},\] (25)

_Then, for any \(i\in[n]\), we have_

\[\frac{\mathrm{Var}[\Phi_{ij}^{\widehat{\bm{\rho}}}\mathbf{1}_{ \mathcal{H}}]}{\mathbb{E}[\Phi_{i\pi_{*}(i)}^{\widehat{\bm{\rho}}}\mathbf{1}_ {\mathcal{H}}]}=O(\frac{1}{|\mathcal{T}|\rho^{2N}}).\]

### Putting things together: Proof of Theorem 3

Proof of Proposition 3.: Firstly, the following conditions imply (22), (23), (24), and (25):

\[L\leq\frac{c_{1}\log n}{\log\log n}\wedge c_{6}\sqrt{ns(p\wedge q )},\quad\frac{c_{2}}{\log(ns(p\wedge q))}\leq\frac{M}{K}\leq\frac{\log\frac{ \rho^{2}}{\alpha}}{2\log\frac{1}{\rho^{2}}},\quad KL\geq\frac{c_{3}\log n}{ \log\frac{\rho^{2}}{\alpha}},\] \[K+M\leq c_{4}\log n,\quad R=\exp(c_{5}K),\quad D\leq c_{7}\frac{ \log n}{(\log\log n)^{2}}.\] (26)

for some absolute constants \(c_{1},c_{2},\ldots,c_{7}>0\).

Furthermore, with growing \(ns(p\wedge q)\), we have for \(j=\pi_{*}(i)\), \(\frac{\mathrm{Var}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}]}{\mathbb{E}[\Phi_{i\pi_ {*}(i)}^{\widehat{\bm{\rho}}}\mathbf{1}_{\mathcal{H}}]^{2}}=o(1)\) when \(sD_{+}(a,b)>1\) and \(\frac{\mathrm{Var}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}]}{\mathbb{E}[\Phi_{i\pi_ {*}(i)}\mathbf{1}_{\mathcal{H}}]^{2}}=o(1)\) when \(sD_{+}(a,b)<1\). For any \(\varepsilon>0\) there exists \(\varepsilon^{\prime}>0\) such that \(s^{2}\geq\alpha+\varepsilon\Leftrightarrow\rho^{2}\geq\alpha+\varepsilon^{\prime}\). We have for \(j\neq\pi_{*}(i)\), \(\frac{\mathrm{Var}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}]}{\mathbb{E}[\Phi_{i\pi_ {*}(i)}\mathbf{1}_{\mathcal{H}}]^{2}}=o(\frac{1}{n^{2}})\) when \(sD_{+}(a,b)>1\) and \(\frac{\mathrm{Var}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}]}{\mathbb{E}[\Phi_{i\pi_ {*}(i)}\mathbf{1}_{\mathcal{H}}]^{2}}=o(\frac{1}{n^{2}})\) when \(sD_{+}(a,b)<1\).

**Next, we claim that almost exact recovery is achievable by counting challengers.** Let \(\tau=c\mu\), for arbitrary \(c\in(0,1)\), where \(\mu=\mathbb{E}[\Phi_{i\pi_{*}(i)}\mathbf{1}_{\mathcal{H}}]\). By Chebyshev's inequality, the probability that the similarity score of a fake pair (\(j\neq\pi_{*}(i)\)) of vertices exceeding \(\tau\), is upper bounded as

\[\mathbb{P}(\Phi_{ij}\mathbf{1}_{\mathcal{H}}\geq\tau)\leq\mathbb{ P}\left(|\Phi_{ij}\mathbf{1}_{\mathcal{H}}-\mathbb{E}[\Phi_{ij}\mathbf{1}_{ \mathcal{H}}]|\geq c\mathbb{E}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}]\right) \leq\frac{\mathrm{Var}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}]}{c^{2} \mathbb{E}[\Phi_{ii}\mathbf{1}_{\mathcal{H}}]^{2}}\] \[=O\left(\frac{1}{|\mathcal{T}|\rho^{2N}}\right)=o(\frac{1}{n^{2}}).\]

Next, by the definition of \(\mathcal{H}\), we have

\[\mathbb{P}(\Phi_{ij}\geq\tau)\leq\mathbb{P}(\Phi_{ij}\mathbf{1}_{ \mathcal{H}}\leq c)+\mathbb{P}(\mathcal{H}^{c})=o(\frac{1}{n^{2}}).\]Applying union bound over all \(i\neq j\in[n]\), we have \(\mathbb{P}\{\exists i\neq j,\Phi_{ij}\geq\tau\}=o(1)\). Thus, for all possible pairs of vertices \((i,j)\in[n]\times[n]\), \(\Phi_{ij}<\tau\) with high probability.

We next study the probability that the similarity score of a true pair of vertices falling below the threshold \(\tau\). We even consider a larger set containing \(F:=\{i\in[n]:\Phi_{i\pi_{*}(i)}<\tau\}\),

\[\mathbb{P}(|\Phi_{i\pi_{*}(i)}\mathbf{1}_{\mathcal{H}}-\mu|>(1-c )\mu) \leq\frac{\operatorname{Var}[\Phi_{i\pi_{*}(i)}\mathbf{1}_{ \mathcal{H}}]}{(1-c)^{2}\mathbb{E}[\Phi_{i\pi_{*}(i)}\mathbf{1}_{\mathcal{H}}] ^{2}}\] \[=O\left(\frac{L^{2}}{\rho^{2}ns(p\wedge q)}+\frac{L^{2}}{\rho^{2( K+M)}|\mathcal{J}|}\right)=:\gamma=o(1).\]

Therefore, \(\mathbb{E}[|F|]\leq n\gamma\). Denote \(I\in[n]\) the vertex set this algorithm matches. For every vertex not in the set \(F\), it is guaranteed to be matched up correctly, so

\[\mathbb{E}[|I|]\geq n-\mathbb{E}[|F|]=n(1-\gamma).\]

By Markov's inequality,

\[\mathbb{P}(|F|>=\sqrt{\gamma}n)\leq\frac{\gamma n}{\sqrt{\gamma}n}=\sqrt{ \gamma}=o(1).\]

Therefore, Algorithm 1 matches \(|I|\geq(1-\sqrt{\gamma})n\) vertices correctly with high probability.

In Regime II, with Proposition 4, Proposition 5, and Proposition 6, the same argument follows. These two regimes together complete the proof. 

## Appendix F Proof of Theorem 4: Efficient algorithm for almost exact graph matching

### Color-coding-based similarity score estimation

In this section, we re-state and modify the efficient graph matching algorithm for correlated Erdos-Renyi graphs discussed in Section 5 of [41], and then analyze it for correlated SBMs.

Let \((G_{1},G_{2})\) be a pair of correlated SBMs with adjacency matrices \(A\) and \(B\). Let \(H\) be a rooted connected graph with \(N+1\) vertices. We now want to approximately count the signed subgraphs rooted at \(i\in[n]\) on the centralized adjacency matrices. In general, we do not have access to the centralized adjacency matrices \(\overline{A}\) and \(\overline{B}\), we would use community label estimates \(\widehat{\bm{\sigma}}_{A}\) and \(\widehat{\bm{\sigma}}_{B}\) from Algorithm 3 to approximately centralize the adjacency matrices as \(\overline{A}^{\widehat{\bm{\sigma}}_{A}}\) and \(\overline{B}^{\widehat{\bm{\sigma}}_{B}}\).

First, we generate a random coloring \(\mu:[n]\rightarrow[N+1]\), which is assigning every node on \(\overline{A}\) to one of \(N+1\)--the same as the number of vertices on a chandelier--colors independently and uniformly at random. For any vertex set \(V\subset[n]\), we define \(\chi_{\mu}(V)=\mathbf{1}_{\{\forall x,y\in V,x\neq y:\mu(x)\neq\mu(y)\}}\). We call the vertex set \(V\) being colorful if \(\chi_{\mu}(V)=1\). We denote \(r:=\mathbb{P}(\chi_{\mu}(V)=1)=\frac{(N+1)!}{(N+1)^{N+1}}\). We define the **approximate signed rooted subgraph count** as

\[X_{i,H}(\overline{A}^{\widehat{\bm{\sigma}}_{A}},\mu):=\sum_{S(i)\cong H}\chi _{\mu}(V(S))\Pi_{e\in E(S)}\overline{A}_{e}^{\widehat{\bm{\sigma}}_{A}}.\] (27)

Observe that \(\mathbb{E}[X_{i,H}(\overline{A}^{\widehat{\bm{\sigma}}_{A}},\mu)]=rW_{i,H}( \overline{A}^{\widehat{\bm{\sigma}}_{A}})\), where \(W_{i,H}(\overline{A}^{\widehat{\bm{\sigma}}_{A}})\) is the ground truth of signed counts as defined in Section C. In another word, \(X_{i,H}(\overline{A}^{\widehat{\bm{\sigma}}_{A}},\mu)/r\) is an unbiased estimator of \(W_{i,H}(\overline{A}^{\widehat{\bm{\sigma}}_{A}})\).

Let \(t:=\lceil 1/r\rceil\), we repeat the random coloring for \(t\) times and then average over the estimates before taking the inner product of two signed counts vectors. Formally, we generate \(2t\) independent colorings independently and uniformly at random, denoted as \(\{\mu_{a}\}_{a=1}^{t}\) and \(\{\nu_{b}\}_{b=1}^{t}\). For vertex \(i\) in \(G_{1}\) and vertex \(j\) in \(G_{2}\), we define the **approximate similarity score** as follows

\[\widetilde{\Phi}_{ij}^{\widehat{\bm{\sigma}}_{B}}:=\frac{1}{r^{2}}\sum_{H\in \mathcal{T}}\operatorname{aut}(H)\left(\frac{1}{t}\sum_{a=1}^{t}X_{i,H}( \overline{A}^{\widehat{\bm{\sigma}}_{A}},\mu_{a})\right)\left(\frac{1}{t} \sum_{b=1}^{t}X_{j,H}(\overline{B}^{\widehat{\bm{\sigma}}_{B}},\nu_{b})\right).\]We have \(\mathbb{E}[\widetilde{\Phi}_{ij}^{\widehat{\bm{\sigma}}}|\overline{A}^{\widehat{\bm{ \sigma}}^{A}},\overline{B}^{\widehat{\bm{\sigma}}^{B}}]=\Phi_{ij}^{\widehat{ \bm{\sigma}}}\) and also \(\mathbb{E}[\widetilde{\Phi}_{ij}^{\widehat{\bm{\sigma}}}\bm{1}_{\mathcal{H}}| \overline{A}^{\widehat{\bm{\sigma}}_{A}},\overline{B}^{\widehat{\bm{\sigma}}_ {B}},\bm{\sigma}_{*}]=\Phi_{ij}^{\widehat{\bm{\sigma}}}\bm{1}_{\mathcal{H}}\) also holds as \(\bm{1}_{\mathcal{H}}\) is a deterministic function on \(\bm{\sigma}_{*}\). We summarize the algorithm as Algorithm 4. There are two additional steps than Algorithm 2 in [41]: First, in the construction of the chandelier class in this work, we need to filter out instances with maximum degree greater than a threshold \(D\), which takes \(O(K)\) time for each tree; Second, we need to obtain the community label estimates before estimating the signed subgraph counts.

```
0: Adjacency matrices \(A\) and \(B\) on \(n\) vertices for correlated stochastic block models \((G_{1},G_{2})\). Step 1 - Construct the chandelier class
1: (Rooted tree generation [6]) List all non-isomorphic rooted trees with \(K\) edges.
2: (Automorphism constraint [12]) Compute \(\mathrm{aut}(H)\) for each rooted tree using the automorphism algorithm for trees.
3: (Maximum degree constraint) Compute the maximum degree of vertices.
4: (Chandelier class) Return \(\mathcal{J}\) as the subset of rooted trees whose number of automorphisms is at most \(R\) and maximum degree is at most \(D\). Construct \((K,L,M,R,D)\)-Chandelier class \(\mathcal{T}\). Step 2 - Estimation of the similarity score (Random Coloring) Generate i.i.d. uniformly random colorings \(\{\mu_{a}\}_{a=1}^{t}\) and \(\{\nu_{b}\}_{b=1}^{t}\), each maps from \([n]\) to \([N+1]\). (Community recovery) Obtaining \(\widehat{\bm{\sigma}}_{A}\) and \(\widehat{\bm{\sigma}}_{B}\) for \(A\) and \(B\) independently by Algorithm 3. for all \((i,j)\in[n]\times[n]\)do for all \(H\in\mathcal{T}\)do (Signed counts estimation [42]) Compute \(\{X_{i,H}(\overline{A}^{\widehat{\bm{\sigma}}_{A}},\mu_{a})\}_{a=1}^{t}\) and \(\{X_{j,H}(\overline{B}^{\widehat{\bm{\sigma}}_{B}},\nu_{b})\}_{b=1}^{t}\). endfor endfor Output: The approximate similarity scores \(\{\widetilde{\Phi}_{ij}\}_{i,j\in[n]}\). ```

**Algorithm 4** Efficient Almost Exact Graph Matching Algorithm

When we can obtain the correct centralized adjacency matrices \(\overline{A}\) and \(\overline{B}\), we replace \(\overline{A}^{\widehat{\bm{\sigma}}_{A}}\) (resp. \(\overline{B}^{\widehat{\bm{\sigma}}_{B}}\)) with \(\overline{A}\) (resp. \(\overline{B}\)), and everything defined above is still valid. In that case, we denote the approximate similarity score as \(\widetilde{\Phi}\) rather than \(\widetilde{\Phi}^{\widehat{\bm{\sigma}}}\).

### Analysis

The analysis is similar to that in Section \(5.1\) of [41], while we split the analysis into two regimes.

Under Regime I (\(sD_{+}(a,b)>1\)), we can recover the community labels on \(G_{1}\) and \(G_{2}\) exactly correct with high probability. We define \(\Gamma_{ij}\) as an upper bound of \(\mathrm{Var}[\Phi_{ij}]\) as follows:

\[\mathrm{Var}[\Phi_{ij}\bm{1}_{\mathcal{H}}]\leq\sum_{H,I\in \mathcal{T}}\mathrm{aut}(H)\mathrm{aut}(I)\sum_{S_{1}(i),S_{2}(j)\cong H}\sum_{ T_{1}(i),T_{2}(j)\cong I}|\mathbb{E}[\overline{A}_{S_{1}}\overline{B}_{S_{2}} \overline{A}_{T_{1}}\overline{B}_{T_{2}}\bm{1}_{\mathcal{H}}]|\\ \bm{1}_{\{S_{1}\neq S_{2}\;\bm{\sigma}\;T_{1}\neq T_{2}\;\bm{ \sigma}\;V(S_{1})\cap V(T_{1})\neq\{i\}\}}\bm{1}_{\{S_{1}\subseteq T_{1}\subset S _{2}\cup T_{2},S_{2}\subseteq T_{2}\subset S_{1}\cup T_{1}\}}=:\Gamma_{ij}.\] (28)

If \(\bm{1}_{\{S_{1}\subseteq T_{1}\subset S_{2}\cup T_{2},S_{2}\subseteq T_{2} \subset S_{1}\cup T_{1}\}}=0\), then there exists some edge occurring only once among \(S_{1}\), \(S_{2}\), \(T_{1}\), and \(T_{2}\), and so \(|\mathbb{E}[\overline{A}_{S_{1}}\overline{B}_{S_{2}}\overline{A}_{T_{1}} \overline{B}_{T_{2}}\bm{1}_{\mathcal{H}}]|=0\). Therefore, we only look at the cases where every edge occurs at least two times among these four chandeliers. If \(\bm{1}_{\{S_{1}\neq S_{2}\;\bm{\sigma}\;T_{1}\neq T_{2}\;\bm{\sigma}\;V(S_{1}) \cap V(T_{1})\neq\{i\}\}}=0\), then \(S_{1}=S_{2}\), \(T_{1}=T_{2}\), and \(S_{1}\) has no common vertex with \(T_{1}\) except for the root. In this case, \(S_{1}\) and \(T_{1}\), and \(S_{2}\) and \(T_{2}\) have no common edges, so the covariance between \(\overline{A}_{S_{1}}\overline{B}_{T_{1}}\) and \(\overline{A}_{S_{2}}\overline{B}_{T_{2}}\) is always zero.

For Regime II (\(sD_{+}(a,b)<1\)), where we cannot recover the correct centralized adjacency matrices with high probability. Alternatively, we define \(\Gamma_{ij}^{\prime}\) as:

\[\Gamma_{ij}^{\prime}:=\sum_{H,I\in\mathcal{T}}\mathrm{aut}(H)\mathrm{aut}(I) \sum_{S_{1},S_{2}\cong H,T_{1},T_{2}\cong I}\mathbb{E}[\overline{A}_{S_{1}}^{ \widehat{\bm{\sigma}}_{A}}\overline{B}_{S_{2}}^{\widehat{\bm{\sigma}}_{B}} \overline{A}_{T_{1}}^{\widehat{\bm{\sigma}}_{A}}\overline{B}_{T_{2}}^{\widehat{ \bm{\sigma}}_{B}}\bm{1}_{\mathcal{H}}].\] (29)

From the definition of variance,

\[\mathrm{Var}[\Phi_{ij}^{\widehat{\bm{\sigma}}}\bm{1}_{\mathcal{H}}]\leq\Gamma_{ ij}^{\prime}.\]

**Lemma 15**.: _Fix constants \(a\neq b>0,s\in[0,1]\). Let \((G_{1},G_{2})\sim\mathrm{CSBM}(n,\frac{a\log n}{n},\frac{b\log n}{n},s)\). The variance of estimation error has the following upper bound:_

\[\mathrm{Var}[(\widetilde{\Phi}_{ij}-\Phi_{ij})\mathbf{1}_{\mathcal{H}}]\leq 3 \Gamma_{ij}\qquad\text{and}\qquad\mathrm{Var}[(\widetilde{\Phi}_{ij}^{\widehat {\boldsymbol{\sigma}}}-\Phi_{ij}^{\widehat{\boldsymbol{\sigma}}})\mathbf{1}_{ \mathcal{H}}]\leq 3\Gamma_{ij}^{\prime},\]

_where \(\Gamma_{ij}\) is defined in (28) and \(\Gamma_{ij}^{\prime}\) is defined in (29)._

Proof.: **Regime I: \(sD_{+}(a,b)>1\).** Define

\[Y_{ij}(\mu,\nu):=\sum_{H\in\mathcal{T}}\mathrm{aut}(H)X_{i,H}(\overline{A}, \mu)X_{j,H}(\overline{B},\nu),\]

where \(\mu,\nu\) are two \((N+1)\)-coloring of the vertices in \([n]\). Then, we can represent the approximate similarity score as

\[\widetilde{\Phi}_{ij}=\frac{1}{r^{2}t^{2}}\sum_{c=1}^{t}\sum_{d=1}^{t}Y_{ij}( \mu_{c},\nu_{d}).\] (30)

For any \(\mu_{c},\nu_{d}\), \(1\leq c,d\leq t\), \(Y_{ij}(\mu_{c},\nu_{d})/r^{2}\) is an unbiased estimator of \(\Phi_{ij}\) given \(\overline{A},\overline{B}\) as

\[\mathbb{E}[Y_{ij}(\mu_{c},\nu_{d})\mathbf{1}_{\mathcal{H}}|\overline{A}, \overline{B},\boldsymbol{\sigma}_{\star}]=r^{2}\sum_{H\in\mathcal{T}}\mathrm{ aut}(H)W_{i,H}(\overline{A})W_{j,H}(\overline{B})\mathbf{1}_{\mathcal{H}}=r^{2} \Phi_{ij}\mathbf{1}_{\mathcal{H}}.\]

Note that \(X_{i,H}(\overline{A},\mu)\) and \(X_{j,H}(\overline{B},\nu)\) are independent conditioned on \(\overline{A},\overline{B}\). Moreover, note that \(\{Y_{ij}(\mu_{c},\nu_{d})\}_{1\leq c,d\leq t}\) are identically distributed. Hence, we have

\[\mathbb{E}[\widetilde{\Phi}_{ij}\mathbf{1}_{\mathcal{H}}]=\mathbb{E}[\mathbb{ E}_{\mu,\nu}[\frac{1}{r^{2}t^{2}}\sum_{c=1}^{t}\sum_{d=1}^{t}Y_{ij}(\mu_{c}, \nu_{d})\mathbf{1}_{\mathcal{H}}|\overline{A},\overline{B},\boldsymbol{\sigma }_{\star}]]=\mathbb{E}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}].\]

Next, we bound the variance of \(\widetilde{\Phi}_{ij}\). In particular, we can get

\[\mathrm{Var}[(\widetilde{\Phi}_{ij}-\Phi_{ij})\mathbf{1}_{\mathcal{H}}] =\mathrm{Var}(\mathbb{E}[(\widetilde{\Phi}_{ij}-\Phi_{ij})\mathbf{1}_ {\mathcal{H}}|\overline{A},\overline{B},\boldsymbol{\sigma}_{\star}])+ \mathbb{E}[\mathrm{Var}((\widetilde{\Phi}_{ij}-\Phi_{ij})\mathbf{1}_{ \mathcal{H}}|\overline{A},\overline{B},\boldsymbol{\sigma}_{\star})]\] \[=\mathbb{E}[\mathrm{Var}(\widetilde{\Phi}_{ij}|\overline{A}, \overline{B},\boldsymbol{\sigma}_{\star})\mathbf{1}_{\mathcal{H}}],\]

because \(\Phi_{ij}\) and \(\mathbf{1}_{\mathcal{H}}\) are fixed conditional on \(\overline{A},\overline{B},\boldsymbol{\sigma}_{\star}\). Furthermore, conditioned on \(\overline{A}\) and \(\overline{B}\), for any \(1\leq c,d,e,f\leq t\), \(Y_{ij}(\mu_{c},\nu_{d})\) are independent with \(Y_{ij}(\mu_{c},\nu_{f})\) if and only if \(c\neq e\) and \(d\neq f\).

\[\mathrm{Var}[(\widetilde{\Phi}_{ij}-\Phi_{ij})\mathbf{1}_{\mathcal{H}}]\leq \frac{1}{r^{4}t^{4}}\sum_{c=1}^{t}\sum_{d=1}^{t}\sum_{e=1}^{t}\sum_{f=1}^{t} \mathbb{E}[\mathrm{Cov}(Y_{ij}(\mu_{c},\nu_{d}),Y_{ij}(\mu_{e},\nu_{f}))| \overline{A},\overline{B},\boldsymbol{\sigma}_{\star})\mathbf{1}_{\mathcal{H}}].\]

Applying Lemma 16, we have

\[\mathrm{Var}[(\widetilde{\Phi}_{ij}-\Phi_{ij})\mathbf{1}_{\mathcal{ H}}] \leq\frac{1}{r^{4}t^{4}}\sum_{c=1}^{t}\sum_{d=1}^{t}\sum_{c=1}^{t} \sum_{f=1}^{t}(r^{2+1_{(c\neq e)}+1_{(d\neq f)}}-r^{4})\Gamma_{ij}\] \[=\frac{1}{r^{2}t^{2}}\left(t^{2}r^{2}+2t^{3}r^{3}-(t^{2}+2t^{3}) r^{4}\right)\Gamma_{ij}\] \[\leq 3\Gamma_{ij},\]

where the last inequality holds because \(t=\lceil 1/r\rceil,tr\geq 1\).

**Regime II: \(sD_{+}(a,b)<1\).** With community label estimates \(\widehat{\boldsymbol{\sigma}}_{A}\) and \(\widehat{\boldsymbol{\sigma}}_{B}\), we define

\[Y_{ij}^{\widehat{\boldsymbol{\sigma}}}(\mu,\nu):=\sum_{H\in\mathcal{T}}\mathrm{ aut}(H)X_{i,H}(\overline{A}^{\widehat{\boldsymbol{\sigma}}_{A}},\mu)X_{j,H}( \overline{B}^{\widehat{\boldsymbol{\sigma}}_{B}},\nu),\] (31)

where \(\mu,\nu\) are two \((N+1)\)-coloring of the vertices in \([n]\). The proof for Regime I still holds in this case by replacing \(\overline{A},\overline{B},Y_{ij},\Phi_{ij},\widetilde{\Phi}_{ij}\) and \(\Gamma_{ij}\) with \(\overline{A}^{\widehat{\boldsymbol{\sigma}}_{A}},\overline{B}^{\widehat{ \boldsymbol{\sigma}}_{B}},Y_{ij}^{\widehat{\boldsymbol{\sigma}}_{B}},\Phi_{ij}^{ \widehat{\boldsymbol{\sigma}}},\widetilde{\Phi}_{ij}^{\widehat{\boldsymbol{ \sigma}}}\) and \(\Gamma_{ij}^{\prime}\) correspondingly.

**Lemma 16** (Extension of Lemma 12 in [41] to correlated SBMs).: _Fix constants \(a\neq b>0,s\in[0,1]\). Let \((G_{1},G_{2})\sim\mathrm{CSBM}(n,a\frac{\log n}{n},b\frac{\log n}{n},s)\). Fix any \(1\leq c,d,e,f\leq t\), and \(i,j\in[n]\). If \(sD_{+}(a,b)>1\), then_

\[\mathbb{E}[\mathrm{Cov}(Y_{ij}(\mu_{c},\nu_{d}),Y_{ij}(\mu_{e},\nu_{f})| \overline{A},\overline{B},\bm{\sigma}_{*})\mathbf{1}_{\mathcal{H}}]\leq(r^{2 +\mathbf{1}_{\{d\neq f\}}+\mathbf{1}_{\{c\neq c\}}}-r^{4})\Gamma_{ij}.\] (32)

_If \(sD_{+}(a,b)<1\), then_

\[\mathbb{E}[\mathrm{Cov}(Y_{ij}(\mu_{c},\nu_{d}),Y_{ij}(\mu_{e},\nu_{f})| \overline{A}^{\widehat{\bm{\sigma}}_{A}},\overline{B}^{\widehat{\bm{\sigma}}_ {B}},\bm{\sigma}_{*})\mathbf{1}_{\mathcal{H}}]\leq(r^{2+\mathbf{1}_{\{d\neq f \}}+\mathbf{1}_{\{c\neq c\}}}-r^{4})\Gamma^{\prime}_{ij}.\] (33)

Proof.: We first prove (33) and then explain why it implies (32).

For two independent \((N+1)\)-colorings \(\mu\) and \(\nu\) of the vertices in \([n]\). From the definition of \(Y^{\widehat{\bm{\sigma}}}_{ij}(\mu,\nu)\) (31), \(\mathbb{E}[Y^{\widehat{\bm{\sigma}}}_{ij}(\mu,\nu)|\overline{A}^{\widehat{\bm {\sigma}}_{A}},\overline{B}^{\widehat{\bm{\sigma}}_{B}},\bm{\sigma}_{*}]=r^{2} \Phi^{\widehat{\bm{\sigma}}}_{ij}\). Then,

\[\mathrm{Cov}(Y^{\widehat{\bm{\sigma}}}_{ij}(\mu_{c},\nu_{d}),Y^{ \widehat{\bm{\sigma}}}_{ij}(\mu_{e},\nu_{f})|\overline{A}^{\widehat{\bm{\sigma }}_{A}},\overline{B}^{\widehat{\bm{\sigma}}_{B}},\bm{\sigma}_{*})\] \[=\mathbb{E}[Y^{\widehat{\bm{\sigma}}}_{ij}(\mu_{c},\nu_{d})Y^{ \widehat{\bm{\sigma}}}_{ij}(\mu_{e},\nu_{f})|\overline{A}^{\widehat{\bm{\sigma }}_{A}},\overline{B}^{\widehat{\bm{\sigma}}_{B}},\bm{\sigma}_{*}]-r^{4}(\Phi^{ \widehat{\bm{\sigma}}}_{ij})^{2}.\] (34)

From the definition of \(Y^{\widehat{\bm{\sigma}}}_{ij}(\mu,\nu)\) in (31) again,

\[\mathbb{E}[Y_{ij}(\mu_{c},\nu_{d})Y_{ij}(\mu_{e},\nu_{f})| \overline{A}^{\widehat{\bm{\sigma}}_{A}},\overline{B}^{\widehat{\bm{\sigma}}_ {B}},\bm{\sigma}_{*}]\] \[=\mathbb{E}[\sum_{H\in\mathcal{T}}\mathrm{aut}(H)X_{i,H}( \overline{A}^{\widehat{\bm{\sigma}}_{A}},\mu_{c})X_{j,H}(\overline{B}^{ \widehat{\bm{\sigma}}},\nu_{d})\] \[\quad\times\sum_{I\in\mathcal{T}}\mathrm{aut}(H)X_{i,I}( \overline{A}^{\widehat{\bm{\sigma}}_{A}},\mu_{e})X_{j,I}(\overline{B}^{ \widehat{\bm{\sigma}}_{B}},\nu_{f})|\overline{A}^{\widehat{\bm{\sigma}}_{A}},\overline{B}^{\widehat{\bm{\sigma}}_{B}},\bm{\sigma}_{*}].\]

From (27) and the independence of colorings,

\[\mathbb{E}[Y_{ij}(\mu_{c},\nu_{d})Y_{ij}(\mu_{e},\nu_{f})| \overline{A}^{\widehat{\bm{\sigma}}_{A}},\overline{B}^{\widehat{\bm{\sigma}}_ {B}},\bm{\sigma}_{*}]\] \[=\mathbb{E}\bigg{[}\sum_{H,I\in\mathcal{T}}\mathrm{aut}(H) \mathrm{aut}(I)\sum_{S_{1}(i),S_{2}(j)\cong H}\sum_{T_{1}(i),T_{2}(j)\cong I} \chi_{\mu_{c}}(V(S_{1}))\overline{A}^{\widehat{\bm{\sigma}}_{A}}_{S_{1}}\] \[\quad\times\chi_{\nu_{d}}(V(S_{2}))\overline{B}^{\widehat{\bm{\sigma }}_{B}}_{S_{2}}\times\chi_{\mu_{c}}(V(T_{1}))\overline{A}^{\widehat{\bm{\sigma} }_{A}}_{T_{1}}\times\chi_{\nu_{f}}(V(T_{2}))\overline{B}^{\widehat{\bm{\sigma}} _{B}}_{T_{2}}|\overline{A}^{\widehat{\bm{\sigma}}_{A}},\overline{B}^{\widehat{ \bm{\sigma}}_{B}},\bm{\sigma}_{*}\bigg{]}\] \[=\sum_{H,I\in\mathcal{T}}\mathrm{aut}(H)\mathrm{aut}(I)\sum_{S_{ 1}(i),S_{2}(j)\cong H}\sum_{T_{1}(i),T_{2}(j)\cong I}\mathbb{E}[\chi_{\mu_{c}}( V(S_{1}))\chi_{\mu_{e}}(V(T_{1}))]\] \[\quad\times\mathbb{E}[\chi_{\nu_{d}}(V(S_{2}))\chi_{\nu_{f}}(V(T_ {2}))]\overline{A}^{\widehat{\bm{\sigma}}_{A}}_{S_{1}}\overline{B}^{\widehat{ \bm{\sigma}}_{B}}_{S_{2}}\overline{A}^{\widehat{\bm{\sigma}}_{A}}_{T_{1}} \overline{B}^{\widehat{\bm{\sigma}}_{B}}_{T_{2}}.\] (35)

From (34), (35), and (10),

\[\mathbb{E}[\mathrm{Cov}(Y_{ij}(\mu_{c},\nu_{d}),Y_{ij}(\mu_{e},\nu_ {f})|\overline{A}^{\widehat{\bm{\sigma}}_{A}},\overline{B}^{\widehat{\bm{ \sigma}}_{B}},\bm{\sigma}_{*})\mathbf{1}_{\mathcal{H}}]\] \[=\sum_{H,I\in\mathcal{T}}\mathrm{aut}(H)\mathrm{aut}(I)\sum_{S_{ 1}(i),S_{2}(j)\cong H}\sum_{T_{1}(i),T_{2}(j)\cong I}\mathbb{E}[\overline{A}^{ \widehat{\bm{\sigma}}_{A}}_{S_{1}}\overline{B}^{\widehat{\bm{\sigma}}_{B}}_{S_{2}} \overline{A}^{\widehat{\bm{\sigma}}_{A}}_{T_{1}}\overline{B}^{\widehat{\bm{\sigma}}_ {B}}_{T_{2}}\mathbf{1}_{\mathcal{H}}]\] \[\quad\times\bigg{(}\mathbb{E}[\chi_{\mu_{c}}(V(S_{1}))\chi_{\mu_{c} }(V(T_{1}))]\mathbb{E}[\chi_{\nu_{d}}(V(S_{2}))\chi_{\nu_{f}}(V(T_{2}))]-r^{4} \bigg{)}.\]

Observe that \(\mathbb{E}[\chi_{\mu_{c}}(V(S_{1}))\chi_{\mu_{c}}(V(T_{1}))]\leq r^{1+1_{\{c \neq c\}}}\) and \(\mathbb{E}[\chi_{\nu_{d}}(V(S_{2}))\chi_{\nu_{f}}(V(T_{2}))]\leq r^{1+1_{\{d\neq f\}}}\),

\[\mathbb{E}[\mathrm{Cov}(Y_{ij}(\mu_{c},\nu_{d}),Y_{ij}(\mu_{e},\nu_ {f})|\overline{A}^{\widehat{\bm{\sigma}}_{A}},\overline{B}^{\widehat{\bm{\sigma}}_ {B}},\bm{\sigma}_{*})\mathbf{1}_{\mathcal{H}}]\] \[\leq\sum_{H,I\in\mathcal{T}}\mathrm{aut}(H)\mathrm{aut}(I)\sum_{S_{ 1}(i),S_{2}(j)\cong H}\sum_{T_{1}(i),T_{2}(j)\cong I}\mathbb{E}[\overline{A}^{ \widehat{\bm{\sigma}}_{A}}_{S_{1}}\overline{B}^{\widehat{\bm{\sigma}}_{B}}_{S_{2}} \overline{A}^{\widehat{\bm{\sigma}}_{A}}_{T_{1}}\overline{B}^{\widehat{\bm{\sigma}}_ {B}}_{T_{2}}\mathbf{1}_{\mathcal{H}}](r^{2+\mathbf{1}_{\{d\neq f\}}+1_{\{c\neq c\}}}-r^{4})\] \[=\Gamma^{\prime}_{ij}(r^{2+\mathbf{1}_{\{d\neq f\}}+1_{\{c\neq c \}}}-r^{4}),\]and this completes the proof for Regime II.

In Regime I, \(\mathbb{E}[\overline{A}_{S_{1}}\overline{B}_{S_{2}}\overline{A}_{T_{2}}\overline{B }_{T_{2}}\mathbf{1}_{\mathcal{H}}]\neq 0\) only if \(\{S_{1}\bigtriangleup T_{1}\subset S_{2}\cup T_{2},S_{2}\bigtriangleup T_{2} \subset S_{1}\cup T_{1}\}\) happens. In addition, if \(S_{1}=S_{2}\), \(T_{1}=T_{2}\), and \(V(S_{1})\cap V(T_{1})=\{i\}\), then \(\mathbb{E}[\chi_{\mu_{c}}(V(S_{1}))\chi_{\mu_{c}}(V(T_{1}))]=\mathbb{E}[\chi_{ \nu_{d}}(V(S_{2}))\chi_{\nu_{f}}(V(T_{2}))]=r^{2}\), because \(S_{1}\) (resp. \(S_{2}\)) shares no common edges with \(T_{1}\) (resp. \(T_{2}\)) Therefore,

\[\mathbb{E}[\mathrm{Cov}(Y_{ij}(\mu_{c},\nu_{d}),Y_{ij}(\mu_{e},\nu _{f})|\overline{A},\overline{B},\boldsymbol{\sigma}_{*})\mathbf{1}_{\mathcal{H}}] \leq\sum_{H,I\in\mathcal{T}}\mathrm{aut}(H)\mathrm{aut}(I)\sum_{S_{1}(i),S_{2} (j)\cong H}\sum_{T_{1}(i),T_{2}(j)\cong I}\mathbb{E}[\overline{A}_{S_{1}} \overline{B}_{S_{2}}\overline{A}_{T_{1}}\overline{B}_{T_{2}}\mathbf{1}_{ \mathcal{H}}](r^{2+\mathbf{1}_{\{d\neq f\}}+\mathbf{1}_{\{c\neq e\}}}-r^{4})\] \[=\sum_{H,I\in\mathcal{T}}\mathrm{aut}(H)\mathrm{aut}(I)\sum_{S_{1 }(i),S_{2}(j)\cong H}\sum_{T_{1}(i),T_{2}(j)\cong I}\mathbb{E}[\overline{A}_{ S_{1}}\overline{B}_{S_{2}}\overline{A}_{T_{1}}\overline{B}_{T_{2}}\mathbf{1}_{ \mathcal{H}}](r^{2+\mathbf{1}_{\{d\neq f\}}+\mathbf{1}_{\{c\neq e\}}}-r^{4})\] \[\quad\times\mathbf{1}_{\{S_{1}\neq S_{2}\;\boldsymbol{\sigma}\;T_ {1}\neq T_{2}\;\boldsymbol{\sigma}\;V(S_{1})\cap V(T_{1})\neq\{i\}\}}\mathbf{1} _{\{S_{1}\bigtriangleup T_{1}\subset S_{2}\cup T_{2},S_{2}\bigtriangleup T_{2} \subset S_{1}\cup T_{1}\}}\] \[=\Gamma_{ij}(r^{2+\mathbf{1}_{\{d\neq f\}}+\mathbf{1}_{\{c\neq e\} }}-r^{4}),\]

where the first line follows from the proof in Regime II and the last line applies the definition of \(\Gamma_{ij}\) (28). 

Now, we are ready to prove Theorem 4.

**Proof of Theorem 4:**_For the first part of this proof_, our goal is to show that the estimated score preserves the asymptotic upper bound on \(\frac{\mathrm{Var}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}]}{\mathbb{E}[\Phi_{i\pi_{* }(i)}\mathbf{1}_{\mathcal{H}}]^{2}}\) for Regime I and \(\frac{\mathrm{Var}[\widetilde{\Phi}_{ij}^{\widehat{\boldsymbol{\sigma}}} \mathbf{1}_{\mathcal{H}}]}{\mathbb{E}[\Phi_{i\pi_{*}(i)}^{\widehat{\boldsymbol{ \sigma}}}\mathbf{1}_{\mathcal{H}}]^{2}}\) for Regime II. For Regime I (\(sD_{+}(a,b)>1\)), we have

\[\frac{\mathrm{Var}[\widetilde{\Phi}_{ij}\mathbf{1}_{\mathcal{H}} ]}{\mathbb{E}[\widetilde{\Phi}_{i\pi_{*}(i)}\mathbf{1}_{\mathcal{H}}]^{2}}= \frac{\mathrm{Var}[\widetilde{\Phi}_{ij}\mathbf{1}_{\mathcal{H}}]}{\mathbb{E} [\Phi_{i\pi_{*}(i)}\mathbf{1}_{\mathcal{H}}]^{2}}\] \[\quad=\frac{1}{\mathbb{E}[\Phi_{i\pi_{*}(i)}\mathbf{1}_{\mathcal{ H}}]^{2}}\Big{[}\mathrm{Var}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}]+\mathrm{Var}[( \widetilde{\Phi}_{ij}-\Phi_{ij})\mathbf{1}_{\mathcal{H}}]+2\,\mathrm{Cov}(( \widetilde{\Phi}_{ij}-\Phi_{ij})\mathbf{1}_{\mathcal{H}},\Phi_{ij}\mathbf{1}_{ \mathcal{H}})\Big{]}\,,\]

where the first equality is from the fact that \(\widetilde{\Phi}_{ij}\mathbf{1}_{\mathcal{H}}\) is an unbiased estimator of \(\Phi_{ij}\mathbf{1}_{\mathcal{H}}\) conditioned on \(\overline{A},\overline{B}\), and \(\boldsymbol{\sigma}_{*}\). Further,

\[\frac{\mathrm{Var}[\widetilde{\Phi}_{ij}\mathbf{1}_{\mathcal{H}}]}{\mathbb{E} [\widetilde{\Phi}_{i\pi_{*}(i)}\mathbf{1}_{\mathcal{H}}]^{2}}\leq\frac{1}{ \mathbb{E}[\Phi_{i\pi_{*}(i)}\mathbf{1}_{\mathcal{H}}]^{2}}\left[\Gamma_{ij}+3 \Gamma_{ij}+2\mathbb{E}[(\widetilde{\Phi}_{ij}-\Phi_{ij})\Phi_{ij}\mathbf{1}_{ \mathcal{H}}]\right]\leq 4\frac{\Gamma_{ij}}{\mathbb{E}[\Phi_{i\pi_{*}(i)}\mathbf{1}_{ \mathcal{H}}]^{2}},\]

where the first inequality holds from (28), Lemma 15, and \(\mathbb{E}[(\widetilde{\Phi}_{ij}-\Phi_{ij})\mathbf{1}_{\mathcal{H}}]=0\), and the second inequality holds because \(\mathbb{E}[((\widetilde{\Phi}_{ij}-\Phi_{ij})\Phi_{ij}\mathbf{1}_{\mathcal{H}}) ]=\mathbb{E}[\mathbb{E}[(\widetilde{\Phi}_{ij}-\Phi_{ij})|\overline{A}, \overline{B},\boldsymbol{\sigma}_{*}]\Phi_{ij}\mathbf{1}_{\mathcal{H}}]=0\).

The proof of Proposition 2 and Proposition 3 are based on analyzing \(\Gamma_{ij}\) and thus the upper bounds on \(\frac{\mathrm{Var}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}]}{\mathbb{E}[\widetilde{ \Phi}_{i\pi_{*}(i)}\mathbf{1}_{\mathcal{H}}]^{2}}\) all hold for \(\frac{\Gamma_{ij}}{\mathbb{E}[\Phi_{i\pi_{*}(i)}\mathbf{1}_{\mathcal{H}}]^{2}}\). Therefore, we conclude that for all \(i\in[n]\), if (22) holds, then

\[\frac{\mathrm{Var}[\widetilde{\Phi}_{i\pi_{*}(i)}\mathbf{1}_{\mathcal{H}}]}{ \mathbb{E}[\widetilde{\Phi}_{i\pi_{*}(i)}\mathbf{1}_{\mathcal{H}}]^{2}}=O\left( \frac{L^{2}}{\rho^{2}ns(p\wedge q)}+\frac{L^{2}}{\rho^{2(K+M)}|\mathcal{J}|} \right);\]

and that for all \(i,j\in[n]\), \(j\neq\pi_{*}(i)\), if (23) holds, then

\[\frac{\mathrm{Var}[\widetilde{\Phi}_{ij}\mathbf{1}_{\mathcal{H}}]}{\mathbb{E}[ \widetilde{\Phi}_{i\pi_{*}(i)}\mathbf{1}_{\mathcal{H}}]^{2}}=O\left(\frac{1}{| \mathcal{T}|\rho^{2N}}\right).\]

For Regime II (\(sD_{+}(a,b)<1\)), from (29) and Lemma 15,

\[\frac{\mathrm{Var}[\widetilde{\Phi}_{ij}^{\widehat{\boldsymbol{\sigma}}} \mathbf{1}_{\mathcal{H}}]}{\mathbb{E}[\widetilde{\Phi}_{ij}^{\widehat{ \boldsymbol{\sigma}}}\mathbf{1}_{\mathcal{H}}]^{2}}\leq\frac{1}{\mathbb{E}[ \Phi_{i\pi_{*}(i)}^{\widehat{\boldsymbol{\sigma}}}\mathbf{1}_{\mathcal{H}}]^{2}} \left[\Gamma_{ij}^{\prime}+3\Gamma_{ij}^{\prime}+2\mathbb{E}[(\widetilde{\Phi}_{ ij}^{\widehat{\boldsymbol{\sigma}}}-\Phi_{ij}^{\widehat{\boldsymbol{\sigma}}})\Phi_{ij}^{\widehat{ \boldsymbol{\sigma}}}\mathbf{1}_{\mathcal{H}}])\right]\leq 4\frac{\Gamma_{ij}^{\prime}}{\mathbb{E}[\Phi_{i\pi_{*}(i)}^{ \widehat{\boldsymbol{\sigma}}}\mathbf{1}_{\mathcal{H}}]^{2}},\]The proof of Proposition 5 and Proposition 6 are based on analyzing \(\Gamma^{\prime}_{ij}\) and thus the upper bounds on \(\frac{\mathrm{Var}[\widehat{\Phi}^{\widehat{\sigma}}_{ij}\mathbf{1}_{\mathcal{H}}] }{\mathbb{E}[\widehat{\Phi}^{\widehat{\sigma}}_{i\pi_{*}(i)}\mathbf{1}_{\mathcal{ H}}]^{2}}\) all hold for \(\frac{\Gamma^{\prime}_{ij}}{\mathbb{E}[\widehat{\Phi}^{\widehat{\sigma}}_{i\pi_{*}( i)}\mathbf{1}_{\mathcal{H}}]^{2}}\). Therefore, we conclude that for all \(i\in[n]\), if (24) holds, then

\[\frac{\mathrm{Var}[\widehat{\Phi}^{\widehat{\sigma}}_{i\pi_{*}(i)}\mathbf{1}_{ \mathcal{H}}]}{\mathbb{E}[\widehat{\Phi}^{\widehat{\sigma}}_{i\pi_{*}(i)} \mathbf{1}_{\mathcal{H}}]^{2}}=O\left(\frac{L^{2}}{\rho^{2}ns(p\wedge q)}+ \frac{L^{2}}{\rho^{2(K+M)}|\mathcal{J}|}\right);\]

and that for all \(i,j\in[n]\), \(j\neq\pi_{*}(i)\), if (25) holds, then

\[\frac{\mathrm{Var}[\widehat{\Phi}^{\widehat{\sigma}}_{ij}\mathbf{1}_{\mathcal{ H}}]}{\mathbb{E}[\widehat{\Phi}^{\widehat{\sigma}}_{i\pi_{*}(i)}\mathbf{1}_{ \mathcal{H}}]^{2}}=O\left(\frac{1}{|\mathcal{T}|\rho^{2N}}\right).\]

_For the second part of this proof, we are going to show the time complexity of Algorithm 4._

First, we know that step 1-1 costs time \(O(\beta^{K})\) by the algorithm in [6], step 1-2 takes time \(O(K)\) by the algorithm in [12], and step 1-3 takes time \(O(K)\) by enumerating through all edges. In summary, he total time complexity to generate \(\mathcal{J}\) is \(O(K^{2}\alpha^{K})\). Afterwards, it takes \(O(|\mathcal{T}|)\) time to complete step 1-4, the generation of chandelier class.

The signed counts estimation step takes \(O(|\mathcal{T}|N3^{N}n^{2})\) times as shown in the proof of Proposition 5 in [41]. Then, the total time complexity is

\[O\left(K^{2}\beta^{K}+|\mathcal{T}|(1+N(3\mathrm{e})^{N}n^{2})\right) =O\left(\binom{|\mathcal{J}|}{L}N(3\mathrm{e})^{N}n^{2}\right)\] \[=O\left(\beta^{KL}(3\mathrm{e})^{N}n^{2}\right)=O\left((3\mathrm{ e}\beta)^{N}n^{2}\right).\]

Under condition (3) and for large enough \(\log(ns(p\wedge q))\geq\log(2)\), we have

\[N=(K+M)L=\frac{C^{\prime}\log n}{\varepsilon}(1+\frac{C^{\prime\prime}}{\log( ns(p\wedge q))})\leq\frac{C^{\prime}(1+\frac{C^{\prime\prime}}{\log 2})}{ \varepsilon}\log n,\]

for some constants \(C^{\prime}\) and \(C^{\prime\prime}\). Hence, there exists some constant \(C\) depending only on \(\varepsilon\) such that the total time complexity of Algorithm 4 is \(O(n^{C})\).

## Appendix G Proof of Theorem 5: Exact graph matching by seeded graph matching

For a pair of correlated SBMs \((G_{1},G_{2})\sim\mathrm{CSBM}(n,p,q,s)\), where \(p=\frac{a\log n}{n}\) and \(q=\frac{b\log n}{n}\). Algorithm 4 efficiently matches \((1-o(1))n\) vertices correctly with high probability. Our next step is to finish the matching on those remaining vertices.

To do this, we use the seeded graph matching algorithm7 (Algorithm 2): Starting with an initial partial matching on at least \((1-\varepsilon/16)n\) vertices which is correct on whatever it matches, we form new matches between vertex \(i\) in \(G_{1}\) and vertex \(j\) in \(G_{2}\) if the common neighbors of those two vertices under the current partial matching sufficiently large. We then update the partial matching and repeat this rule until we get a complete matching, which will be shown happens with high probability. Define \(h(x)=x\log x-x+1\). The sufficiently large common neighbors threshold is set as \(\gamma\frac{p^{2}+q^{2}}{2}s^{2}(n+2n^{\frac{3}{4}})\), where \(\gamma\in(1,\infty)\) such that \(h(\gamma)=\frac{3\log n}{(n-2)pqs^{2}}\).

Footnote 7: Relevant seeded graph matching algorithms also occur in [69, 5, 40].

Denote \(\mathrm{N}_{\pi}(i,j)\) as the number of common neighbors of \(i\) and \(j\) under correspondence \(\pi\). In another word, \(\mathrm{N}_{\pi}(i,j)\) is the number of vertex \(v\in I\) such that \(v\) is a neighbor of \(i\) in \(A\) and \(\pi(v)\) is a neighbor of \(j\) in \(B\). If \(\pi=\pi_{*}\), we also write it as \(\mathrm{N}(i,j)\).

The following lemma for SBM is an analogy to Lemma \(13\) in [41], which studied the property of Erdos-Renyi graph.

**Lemma 17**.: _Fix \(\varepsilon>0\) and \(a,b>0\) such that \(\frac{a+b}{2}\geq 1+\varepsilon\). Let \(p=a\frac{\log n}{n},q=b\frac{\log n}{n}\) and \(G\sim\mathrm{SBM}(n,p,q)\). Let \(I\subset[n]\) be a subset of vertices, \(e_{G}(I,I^{c})\) denotes the number of edges between vertices in \(I\) and vertices in \(I^{c}=[n]\setminus I\). With probability \(1-n^{-\frac{5}{4}}\), for any \(I\) such that \(|I|\leq\frac{c}{16}n\), \(e_{G}(I,I^{c})\geq\eta|I||I^{c}|p\wedge q\), where \(\eta\) is the unique solution in \((0,1)\) such that \(h(\eta)=\frac{(1+\frac{c}{8})\log n}{(p+q)(\frac{n}{2}-n^{3/4}-\frac{c}{16}n)}\). In particular,_

\[\eta\geq 1-\sqrt{\frac{1+\frac{c}{8}}{(1+\varepsilon)(1-\frac{c}{7})}}.\]

Proof.: If \(I=\emptyset\), \(e_{G}(I,I^{c})\geq\eta|I||I^{c}|\frac{p+q}{2}\) holds trivially. Let \(I\) be an non-empty set with \(1\leq|I|\leq\frac{c}{16}n\). We denote \(k\) as \(|I|\). The number of edges between \(I\) and \(I^{c}\) is the summation of \(k(n-k)\) independent Bernoulli trails. For arbitrary vertex \(i\in I\) and vertex \(j\in I^{c}\), if they have the same community label, then the Bernoulli trail between them has mean \(p\). Otherwise,t he Bernoulli trail has mean \(q\). We assume that there are \(N_{1}\) trails with mean \(p\) and \(N_{2}\) trails with mean \(q\), where \(N_{1}+N_{2}=k(n-k)\). We can write out the distribution as \(e_{G}(I,I^{c})\sim\mathrm{Binom}(N_{1},p)+\mathrm{Binom}(N_{2},q)\).

Under the balanced community event \(\mathcal{H}\), \(\frac{n}{2}-n^{3/4}\leq|V^{+}|,|V^{-}|\leq\frac{n}{2}+n^{3/4}\). Assume that there are \(k_{+}\) vertices in \(I\) with label \(+1\) and the remaining \(k_{-}\) vertices with label \(-1\).

\[\frac{N_{1}}{k} =\frac{1}{k}\Big{(}k_{+}(|V^{+}|-k_{+})+k_{-}(|V^{-}|-k_{-})\Big{)} \geq\frac{n}{2}-n^{3/4}-\frac{k_{+}^{2}+k_{-}^{2}}{k}\geq\frac{n}{2}-n^{3/4}- \frac{\varepsilon}{16}n,\] (36) \[\frac{N_{2}}{k} =\frac{1}{k}\Big{(}k_{-}(|V^{+}|-k_{+})+k_{+}(|V^{-}|-k_{-})\Big{)} \geq\frac{n}{2}-n^{3/4}-\frac{2k_{1}k_{2}}{k}\geq\frac{n}{2}-n^{3/4}-\frac{ \varepsilon}{32}n.\] (37)

We are interested in the probability of \(e_{G}(I,I^{c})\) being less than \(n|I||I^{c}|p\wedge q\):

\[\mathbb{P}(e_{G}(I,I^{c})\leq\eta k(n-k)p\wedge q)\leq\mathbb{P}(e_{G}(I,I^{c} )\leq\eta(N_{1}p+N_{2}q))\leq\exp(-(N_{1}p+N_{2}q)h(\eta)),\]

where the first inequality holds because \(N_{1}+N_{2}=k(n-k)\) and \(p\wedge q\leq p,q\) and the second inequality holds because of the multiplicative Chernoff bound (Lemma 4).

Let \(h(\eta)=\frac{(1+\frac{c}{8})\log n}{(p+q)(\frac{n}{2}-n^{3/4}-\frac{c}{16}n)}\), we can show that

\[\frac{k(1+\frac{c}{8})\log n}{N_{1}p+N_{2}q}<\frac{(1+\frac{c}{8})\log n}{(p+q )(\frac{n}{2}-n^{3/4}-\frac{c}{16}n)}\leq\frac{1+\frac{c}{8}}{(1+\varepsilon)( 1-2n^{-1/4}-\frac{c}{8})}<\frac{1+\frac{c}{8}}{(1+\varepsilon)(1-\frac{c}{7})}<1,\] (38)

where the first inequality holds because of (36) and (37), the second inequality holds because \(\frac{a+b}{2}\geq 1+\varepsilon\) and the third inequality holds for sufficiently large \(n\). Since \(h(\eta)\in(0,1)\), there is an unique solution of \(\eta\in(0,1)\) due to the monotocity (decreasing) of the function \(h(\cdot)\).

Applying the fact that \((N_{1}p+N_{2}q)h(\eta)>(1+\frac{c}{8})\log n\) (38) and using an union bound over all subsets \(I\subset[n]\) with size \(1\leq|I|\leq\frac{c}{16}\), we have

\[\mathbb{P}(\exists I\subset[n]\text{ s.t. }1\leq|I|\leq\frac{ \varepsilon}{16},e_{G}(I,I^{c})\leq\eta|I|(n-|I|)p\wedge q)\\ \leq\sum_{k=1}^{\frac{c}{6}}n^{k}\mathbb{P}(e_{G}(I,I^{c})\leq \eta k(n-k)p\wedge q)\leq\sum_{k=1}^{\frac{c}{6}}n^{k-k(1+\frac{c}{8})}=O(n^{- \frac{c}{8}}).\]

Because \(h(x)\geq\frac{(x-1)^{2}}{2}\) for \(x\in(0,1)\), we have \(\eta\geq 1-\sqrt{2h(\eta)}>1-\sqrt{\frac{1+\frac{c}{8}}{(1+\varepsilon)(1-\frac{c}{ 7})}}\). 

Now, we are ready to prove Theorem 5.

Proof of Theorem 5.: **Firstly, we study the size of common neighbors.** For an arbitrary vertex \(u\in[n]\) in \(G_{1}\) and \(v\in[n]\) in \(G_{2}\) such that \(v\) is not the true correspondence of \(u\), we study the number of common neighbors \(\mathrm{N}(u,v)\) in the intersection graph corresponding to the true permutation.

_Case a: These two vertices come from different communities._ If \(v\neq\pi_{*}(u),\boldsymbol{\sigma}(u)\boldsymbol{\sigma}(v)=-1\), then we have \(\mathrm{N}(u,v)\sim\mathrm{Binom}(n-2,pqs^{2})\). By the multiplicative Chernoff bound (Lemma 4) for Binomial distributions, for \(\gamma\in(1,\infty)\), we have

\[\mathbb{P}(\mathrm{N}(u,v)\geq\gamma\frac{p^{2}+q^{2}}{2}s^{2}(n+2n^{\frac{3} {4}}))<\mathbb{P}(\mathrm{N}(u,v)\geq\gamma(n-2)pqs^{2})\leq e^{-(n-2)pqs^{2}h( \gamma)}=n^{-3},\]where \(h(\gamma)=\frac{3\log n}{(n-2)pqs^{2}}>1,\gamma\in(1,\infty)\). The first inequality holds because \(\frac{p^{2}+q^{2}}{2}(n+2n^{\frac{3}{4}})>(n-2)pq\).

By a union bound over all \(u,v\) such that \(v\neq\pi_{*}(u),\boldsymbol{\sigma}(u)\boldsymbol{\sigma}(v)=-1\), we have

\[\mathbb{P}\{\exists v\neq\pi_{*}(u),\boldsymbol{\sigma}(u) \boldsymbol{\sigma}(v)=-1,\text{ s.t. }\mathrm{N}(u,v)\geq\gamma\frac{p^{2}+q^{2}}{2}s^{2}n(1+2n^{-\frac{1}{4}})\}= O(\frac{1}{n}).\]

_Case b: These two vertices come from the same community._ If \(v\neq\pi_{*}(u),\boldsymbol{\sigma}(u)\boldsymbol{\sigma}(v)=1\), then we have \(\mathrm{N}(u,v)\sim\mathrm{Binom}(|V^{\boldsymbol{\sigma}(v)}|-2,p^{2}s^{2}) +\mathrm{Binom}(|V^{-\boldsymbol{\sigma}(v)}|,q^{2}s^{2})\) because there are \(|V^{\boldsymbol{\sigma}(v)}|-2\) vertices left from the same community as \(u,v\) and \(|V^{-\boldsymbol{\sigma}(v)}|\) vertices from the different community. Denote \(n_{1}\) as \(|V^{\boldsymbol{\sigma}(v)}|-2\) and \(n_{2}\) as \(|V^{-\boldsymbol{\sigma}(v)}|\), \(n_{1}+n_{2}=n-2\).

\[\mathbb{P}\{\mathrm{N}(u,v)\geq\gamma\frac{p^{2}+q^{2}}{2}s^{2}(n +2n^{\frac{3}{4}})\} <\mathbb{P}\{\mathrm{N}(u,v)\geq\gamma(n_{1}p^{2}+n_{2}q^{2})s^{2}\}\] \[\leq\exp(-(n_{1}p^{2}+n_{2}q^{2})s^{2}h(\gamma))<n^{-3}.\]

The first inequality holds because \(\frac{p^{2}+q^{2}}{2}(n+2n^{\frac{3}{4}})>n_{1}p^{2}+n_{2}q^{2}\). The last inequality holds because \(\frac{3\log n}{(n-2)pq}>\frac{3\log n}{\frac{p^{2}+q^{2}}{2}n(1-2n^{-\frac{1}{4 }})}>\frac{3\log n}{n_{1}p^{2}+n_{2}q^{2}}\) for sufficiently large \(n\).

Then, with an union bound over all \(u,v\) such that \(v\neq\pi_{*}(u),\boldsymbol{\sigma}(u)\boldsymbol{\sigma}(v)=1\), we have

\[\mathbb{P}\{\exists v\neq\pi_{*}(u),\boldsymbol{\sigma}(u) \boldsymbol{\sigma}(v)=1,\text{ s.t. }\mathrm{N}(u,v)\geq\gamma\frac{p^{2}+q^{2}}{2}s^{2}n(1+2n^{-\frac{1}{4}})\}= O(\frac{1}{n}).\]

Combining the above two cases, we have

\[\mathbb{P}\{\exists v\neq\pi_{*}(u),\mathrm{N}(u,v)\geq\gamma \frac{p^{2}+q^{2}}{2}s^{2}n(1+2n^{-\frac{1}{4}})\}=o(1).\] (39)

**Secondly, we show that the algorithm is working properly.** From (39), we assume that for all \(v\neq\pi_{*}(u)\), \(\mathrm{N}(u,v)<\gamma\frac{p^{2}+q^{2}}{2}s^{2}(n+2n^{\frac{3}{4}})\). We want to show \(\widetilde{\pi}=\pi_{*}|_{J}\) in every step of Algorithm 2 by induction. This is true for the initialization of \(\widetilde{\pi}\) as a base case, from our assumption for Theorem 5. Suppose that this is true for \(t\)-th round of the algorithm, then at the \((t+1)\)-th round, we have that for all \(v\neq\pi_{*}(u)\),

\[\mathrm{N}_{\widetilde{\pi}}(u,v)\leq\mathrm{N}(u,v)<\gamma\frac{p^{2}+q^{2}} {2}s^{2}(n+2n^{\frac{3}{4}}).\]

Therefore, as the \((t+1)\)-th round, the algorithm will still not add an fake correspondence. Either the algorithm terminates, or a new vertex \(i\) is added to \(J\) such that \(\widetilde{\pi}(i)=i\), which preserves the property \(\widetilde{\pi}=\pi_{*}|_{J}\).

Next, we show that Algorithm 2 always ends with \(J=[n]\) by contradiction. Assume that the algorithm terminates with \(|J|<n\), then \(J^{c}\neq\emptyset\). Then, by definition, for al \(i\in J^{c}\), \(\mathrm{N}_{\widetilde{\pi}}(i,\pi_{*}(i))<\gamma\frac{p^{2}+q^{2}}{2}(n+2n^{ \frac{3}{4}})\). Therefore,

\[e_{G_{1}\wedge_{\pi_{*}}G_{2}}(J,J^{c})=\sum_{i\in J^{c}}\mathrm{N }_{\widetilde{\pi}(i,\pi_{*}(i))}\leq|J^{c}|\gamma\frac{p^{2}+q^{2}}{2}s^{2}( n+2n^{\frac{3}{4}}).\] (40)

On the other side, \(G_{1}\wedge_{\pi_{*}}G_{2}\sim\mathrm{SBM}(n,s^{2}p,s^{2}q)\). If \(s^{2}\frac{p+q}{2}\geq(1+\varepsilon)\frac{\log n}{n}\), then from Lemma 17 (in view of \(J^{c}\) as \(I\)), with probability of \(1-O(n^{-\frac{\varepsilon}{8}})\),

\[e_{G_{1}\wedge_{\pi_{*}}G_{2}}(J,J^{c})\geq\eta|J||J^{c}|s^{2} \frac{p+q}{2}\geq\eta(1-\frac{\varepsilon}{16})n|J^{c}|s^{2}(p\wedge q).\] (41)

To reach a contradiction between (40) and (41), the remaining is to prove that

\[\gamma\leq\frac{\eta(1-\frac{\varepsilon}{16})ns(p\wedge q)}{\frac{p^{2}+q^{2} }{2}(n+2n^{\frac{3}{4}})}.\] (42)We observe that \(h(\gamma)=\frac{3\log n}{(n-2)pqs^{2}}=\Theta(1)\), while \(\frac{\eta(1-\frac{1}{2}s_{G})ns(p\wedge q)}{\frac{p^{2}+3^{2}}{2}(n+2n^{\frac{ 3}{2}})}=\Theta(\frac{n}{\log n})\). Therefore (42) holds for sufficiently large \(n\).

**Finally, we analyze the time complexity of Algorithm 2.** For each \(u\in[n]\) to be added into the seeded set \(I\), we update the number of common neighbors \(\mathrm{N}_{\widetilde{\pi}}(i,j)\) for all \(i,j\in I\). This step takes \(O(\deg_{G_{1}}(u)\deg_{G_{2}}(u))\), where \(\deg_{G}(u)\) denotes the degree of \(u\) in graph \(G\). With probability \(1-o(\frac{1}{n^{2}})\), \(\deg_{G_{1}}(u)=O(n(p+q))\). By summing up for all possible \(u\) to be added, the time complexity of Algorithm 2 is \(O(n^{3}(p+q)^{2})\). 

## Appendix H Proof of Proposition 1

In this section, we calculate the expectation of similarity score for correlated SBM. Recall that we have defined \(\sigma_{+}^{2}:=sp(1-sp),\sigma_{-}^{2}:=sq(1-sq)\) and that \(\sigma_{\mathrm{eff}}^{2}:=(\frac{\sigma_{+}^{2}+\sigma_{-}^{2}}{2})\) throughout this paper.

Proof of Proposition 1.: By definition of the similarity score,

\[\mathbb{E}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}]=\sum_{H\in\mathcal{T}}\mathrm{ aut}(H)\sum_{S(i)\cong H}\sum_{S(j)\cong H}\mathbb{E}\left[\overline{A}_{S(i)} \overline{B}_{S(j)}\mathbf{1}_{\mathcal{H}}\right].\]

The expectation is zero if \(S(i)=S(j)\), which implies considering \(\pi_{*}(i)=j\) suffices:

\[\mathbb{E}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}]=(1+o(1))\sum_{H\in\mathcal{T}} \mathrm{aut}(H)\sum_{S(i)\cong H}\mathbb{E}\left[\overline{A}_{S(i)} \overline{B}_{S(\pi_{*}(i))}\mid\mathcal{H}\right].\]

Define \(X_{1}\) as the random variable for the number of in-community edges of \(S(i)\), which takes possible value from \(0\) to \(N\). Define \(|\{S(i):S(i)\cong H\}|\) as the total number of \(S\) rooted at \(i\) and isomorphic to \(H\), we have

\[\mathbb{E}[\Phi_{i\pi_{*}(i)}\mathbf{1}_{\mathcal{H}}] =(1+o(1))\sum_{H\in\mathcal{T}}\mathrm{aut}(H)|\{S(i):S(i)\cong H \}|\mathbb{E}\bigg{[}\mathbb{E}\left[\overline{A}_{S(i)}\overline{B}_{S(\pi_{ *}(i))}\mid X_{1},\mathcal{H}\right]\bigg{]}\] \[\leq(1+o(1))\sum_{H\in\mathcal{T}}n^{N}\sum_{N_{1}=0}^{N}\mathbb{ P}(X_{1}=N_{1}\mid\mathcal{H})\rho^{N}\sigma_{+}^{2N_{1}}\sigma_{-}^{2N-2N_{1}}.\]

The second inequality holds by \(|\{S(i):S(i)\cong H\}|=\frac{\binom{n}{N}N!}{\mathrm{aut}(H)}=(1+o(1))\frac{n^ {N}}{\mathrm{aut}(H)}\) since \(\binom{n}{N}N!\) is the number of possible vertex embedding of the chandelier onto the random graph and also \(\mathbb{E}\left[\overline{A}_{S(i)}\overline{B}_{S(\pi_{*}(i))}|\{X_{1}=N_{1} \}\cap\mathcal{H}\right]=\rho_{+}^{N_{1}}\rho_{-}^{N-N_{1}}\sigma_{+}^{2N_{1} }\sigma_{-}^{2(N-N_{1})}=(1+o(1))\rho^{N}\sigma_{+}^{2N_{1}}\sigma_{-}^{2(N-N_ {1})}\).

Then, according to Lemma 9 and the binomial theorem, we have \(\mathbb{P}(X_{1}=N_{1}\mid\mathcal{H})=(1+o(1))\binom{N}{N_{1}}2^{-N}\). Therefore,

\[\mathbb{E}[\Phi_{i\pi_{*}(i)}\mathbf{1}_{\mathcal{H}}] =(1+o(1))|\mathcal{T}|n^{N}\rho^{N}\sum_{N_{1}=0}^{N}\binom{N}{N_{1 }}\frac{1}{2^{N}}\sigma_{+}^{2N_{1}}\sigma_{-}^{2N-2N_{1}}\] \[=(1+o(1))|\mathcal{T}|n^{N}\rho^{N}(\frac{\sigma_{+}^{2}+\sigma_{- }^{2}}{2})^{N}=(1+o(1))|\mathcal{T}|n^{N}\rho^{N}\sigma_{\mathrm{eff}}^{2N}.\qed\]

## Appendix I Proof of Proposition 2

### Decorated union graph and union graph partition

The analysis of the first moment involves two chandeliers, while the second moment analysis requires four chandeliers. Before delving into the analysis, we introduce the notation for the decorated union graph and establish a rule for union graph partition. We adopt some notations and definitions from [41] and further introduce concepts that are particularly useful for correlated stochastic block models.

* **(Decorated graph)** For any graph \(G\), define \(\dot{G}\) as a decorated graph \(\dot{G}:=(G,D_{G})\), where \(D_{G}\) is a decoration mapping from the edge set to a decoration set. Define the edge set of decorated graph \(E(\dot{G}):=E(G)\) and the vertex set of decorated graph \(V(\dot{G}):=V(G)\).
* **(Decorated union graph)** For any pair of chandeliers \(H,I\in\mathcal{T}\), let \(S_{1}(i),S_{2}(j)\cong H\) and \(T_{1}(i),T_{2}(j)\cong I\). The union graph is defined as \(U=S_{1}\cup S_{2}\cup T_{1}\cup T_{2}\). Now, let us define the proper decoration for \(\dot{U}\): \[D_{U}(e)=\begin{cases}\text{The subset of }\{S_{1},S_{2},T_{1},T_{2}\}\text{ where $e$ occurs},&\text{if $e\in E(U)$},\\ \emptyset,&\text{if $e\notin E(U)$}.\end{cases}\] (43) We call an edge \(e\in E(U)\)\(t\)-decorated if \(|D_{U}(e)|=t\), \(t\in\{0,1,2,3,4\}\).
* **(Decorated set operation)*
* Assume that \(\dot{U}=(U,D_{U})\) and \(\dot{U}^{\prime}=(U^{\prime},D_{U^{\prime}})\) are two decorated graphs. We define the union, intersection, and difference operations, from which the complement and symmetric difference naturally follow.
* Union. \(\dot{U}\cup\dot{U}^{\prime}:=(U\cup U^{\prime},D_{U^{\prime\prime}}:D_{U^{ \prime\prime}}(e)=D_{U}(e)\cup D_{U^{\prime}}(e))\).
* Intersection. \(\dot{U}\cap U^{\prime}:=(U\cap U^{\prime},D_{U^{\prime\prime}}:D_{U^{\prime \prime}}(e)=D_{U}(e)\cap D_{U^{\prime}}(e))\).
* Difference. \(\dot{U}\setminus\dot{U}^{\prime}:=(U\setminus U^{\prime},D_{U^{\prime\prime}} :D_{U^{\prime\prime}}(e)=D_{U}(e)\setminus D_{U^{\prime}}(e))\).
* **(Union graph partition)** Assume that \(i\) is the root of union graph. Consider the graph \(U\) with edge \((i,a)\) removed for all neighbors \(a\) of \(i\). Let \(\dot{\mathcal{C}}(i,a)\) be the connected component therein that contains \(a\). Let \(\dot{\mathcal{G}}(i,a)\) be the graph union of \(\dot{\mathcal{C}}(i,a)\) and the edge \((i,a)\). Then, we divide the set of root neighbors \(\mathcal{N}(i)\) into the following sets depending on whether \(\dot{\mathcal{G}}(i,a)\) is a tree: \(\mathcal{N}_{T}=\{a:(i,a)\in E(U),\dot{\mathcal{G}}(i,a)\text{ is a tree}\}, \mathcal{N}_{N}=\{a:(i,a)\in E(\dot{U})\}\setminus\mathcal{N}_{T}\). Furthermore, we breakdown \(\mathcal{N}_{T}\) into two sets depending on whether there are at least \(M\) edges \(3\)-decorated: \(\mathcal{N}_{M}=\{a\in\mathcal{N}_{T},|\{e\in E(\dot{\mathcal{G}}(i,a)):|D_{U} (e)|\geq 3\}|\geq M\}\), \(\mathcal{N}_{L}=\mathcal{N}_{T}\setminus\mathcal{N}_{M}\),. Next, we define the decomposition of decorated union graph \(\dot{U}\): \[\dot{U}_{L}:=\bigcup_{a\in\mathcal{N}_{L}}\dot{\mathcal{G}}(i,a),\quad\dot{U} _{M}:=\bigcup_{a\in\mathcal{N}_{M}}\dot{\mathcal{G}}(i,a),\quad\dot{U}_{N}:= \dot{U}\setminus(\dot{U}_{L}\cup\dot{U}_{M}).\] (44) If any of these become an empty set, we define it as the graph consisting of the single vertex \(i\). To provide an intuitive understanding: \(\dot{U}_{N}\) contains those chandelier branches that form cycles in the union graph, while \(\dot{U}_{L}\) and \(\dot{U}_{M}\) are the collection of those chandelier branches that do not tangle with other branches from bottom and remain a part of tree rooted at \(i\) (or \(j\)) in the union graph. As a characteristic of trees, the decorations on edges within \(\dot{U}_{M}\) and \(\dot{U}_{N}\) are monotonically decreasing, meaning that the decoration set of an edge at depth \(d\geq 1\) is always a subset of the decoration set of the preceding edge at depth \(d-1\) that connects to it. For each node \(v\in\dot{U}_{M}\) that is connected to the root, the connected component \(\dot{\mathcal{G}}(i,a)\) should have at list \(M\) vertices that are at least \(3\)-decorated. \(\dot{U}_{L}\) is the union of all connected components remained that are trees. The definition of \(\dot{U}_{L}\) implies that the branches cannot be fully \(3\)-decorated, otherwise this branch would fall in \(\dot{U}_{M}\).

For every union graph, we can decompose the decorated union graph based on its decoration sets. Specifically, we want to keep track of how many times each vertex appears on the chandeliers that are rooted at \(i\) and the chandeliers that are rooted at \(j\). We present the definition as follows.

**Definition 3** (Decorated union graph decomposition by decorations).: \[K_{\ell m}:=(V(U),\{e\in E(U):\ell=\mathbf{1}_{\{e\in S_{1}\}}+\mathbf{1}_{\{e \in T_{1}\}},k=\mathbf{1}_{\{e\in S_{2}\}}+\mathbf{1}_{\{e\in T_{2}\}}\}).\] (45)

**Definition 4** (Edge counts on \(3\) and \(4\)-decorated edges).: _Based on the definition of union graph partition and \(K_{\ell m}\), we further define_

\[e_{L}:=\frac{1}{2}[e((K_{22}\cup K_{21})\cap U_{L})+e((K_{22}\cup K_{12})\cap U _{L})],\] (46)

\[e_{M}:=\frac{1}{2}[e((K_{22}\cup K_{21})\cap U_{M})+e((K_{22}\cup K_{12})\cap U _{M})],\] (47)

\[e_{N}:=\frac{1}{2}[e((K_{22}\cup K_{21})\cap U_{N})+e((K_{22}\cup K_{12})\cap U _{N})],\] (48)_where \(2e_{L}\) (resp. \(2e_{M}\), \(2e_{N}\)) is the counts of \(3\)-decorated edges and two times the \(4\)-decorated edges on \(U_{L}\) (resp. \(U_{M}\), \(U_{N}\))._

We use \(\mathcal{U}_{L}(v_{L},e_{L},\ell)\) to denote the collection of all possible \(\dot{U}_{L}\) with \(v_{L}\) vertices except for \(i\) and \(j\), \(e_{L}\) counts of special edges as defined, and \(\ell\) edges in \(K_{11}\cap\dot{U}_{L}\). \(\mathcal{U}_{M}(v_{M},e_{M})\) denotes the family of all possible \(\dot{U}_{M}\) with \(v_{M}\) vertices except for \(i\) and \(j\) and \(e_{L}\) counts of special edges as defined. \(\mathcal{U}_{N}(v_{N},e_{N},k)\) denotes the family of all possible \(\dot{U}_{N}\) with \(v_{N}\) vertices except for \(i\) and \(j\), \(e_{N}\) counts of special edges as defined, and excess \(k\).

We further define the weights for of decorated graphs \(\dot{U}_{L}\), \(\dot{U}_{M}\), and \(\dot{U}_{N}\).

**Definition 5**.: _Let \(\dot{G}\) be an arbitrary \(\dot{U}_{L}\), \(\dot{U}_{M}\), or \(\dot{U}_{N}\), we define the weight of \(\dot{G}\) with regard to a chandelier \(S\) as_

\[w_{S}(\dot{G}):=\prod_{\mathcal{B}\in\mathcal{K}(S),\mathcal{B}\subset G} \operatorname{aut}(\mathcal{B})^{\frac{1}{2}}.\] (49)

_We set \(w_{S}(\dot{G})=1\) if \(\dot{G}\) contains no bulbs in \(\mathcal{K}(S)\). We define the weight of \(\dot{G}\) as the multiplication of its weights over \(S_{1},S_{2},T_{1},T_{2}\):_

\[w(\dot{G}):=w_{S_{1}}(\dot{G})w_{S_{2}}(\dot{G})w_{T_{1}}(\dot{G})w_{T_{2}}( \dot{G}).\] (50)

We have the following observation with regard to the concepts introduced above:

* **(Counting edges)**\(2(v_{L}+v_{M}+v_{N}+k+1+\mathbf{1}_{\{i\neq j\}})+2(e_{L}+e_{M}+e_{N})=4N\). This holds because \(2(v_{L}+v_{M}+v_{N}+k+1+\mathbf{1}_{\{i\neq j\}})\) counts all the edges on union graph twice and \(2(e_{L}+e_{M}+e_{N})\) makes up for an additional count for \(3\)-decorated edges and two counts for \(4\)-decorated edges.
* **(Automorphism as decorated graph weights)** From the definition of \(\operatorname{aut}(\cdot)\) and chandelier, \[(\operatorname{aut}(S_{1})\operatorname{aut}(S_{2})\operatorname{aut}(T_{1}) \operatorname{aut}(T_{2}))^{\frac{1}{2}}=w(\dot{U}_{L})w(\dot{U}_{M})w(\dot{U}_ {N}).\] (51)
* **(Trivial upper bound on the decorated graph weights)** Since \(\operatorname{aut}(\mathcal{B})\) is upper bounded by \(R\) for arbitrary bulb \(\mathcal{B}\), this inequality follows from the definition of decorated union graph weights \[w(\dot{U}_{L})\leq(\sqrt{R}^{|\mathcal{N}_{L}|})^{4}=R^{2|\mathcal{N}_{L}|}.\] (52) The same holds for \(\dot{U}_{M}\) and \(\dot{U}_{N}\).

Specific to the moment calculation for correlated stochastic block models, we present the following two definitions.

**Definition 6** (\(g_{\dot{U}}(\sigma_{+},\sigma_{-})\)).: _Fix chandeliers \((S_{1},S_{2},T_{1},T_{2})\) on the complete graph, conditioned on the ground-truth labels of correlated SBMs, we define a function as follows:_

\[g_{\dot{U}}(\sigma_{+},\sigma_{-}):=\sigma_{+}^{h(S_{1})+h(S_{2})+h(T_{1})+h(T _{2})}\sigma_{-}^{\overline{h}(S_{1})+\overline{h}(S_{2})+\overline{h}(T_{1}) +\overline{h}(T_{2})},\]

_where \(h(\cdot)\) is the counts of edges connecting two points from the same community, \(\overline{h}(\cdot)\) is the counts of edges connecting two points from different communities on the complete graph \(K_{n}\)._

**Definition 7** (Extension of \(\sigma_{\text{eff}}^{2}\)).: _We define \(\gamma_{2}:=\left(\frac{\sigma_{+}^{4}+\sigma_{-}^{4}}{2}\right)/\sigma_{\text {eff}}^{4}\) and \(\gamma_{1}:=\left(\frac{\sigma_{+}^{3}+\sigma_{-}^{3}}{2}\right)/\sigma_{\text {eff}}^{3}\). Thus, \(\left(\frac{\sigma_{+}^{4}+\sigma_{-}^{4}}{2}\right)^{k}=(1+o(1))\left(\frac{ \sigma_{+}^{2}+\sigma_{-}^{2}}{2}\right)^{2k}\gamma_{2}^{k}\) and \(\left(\frac{\sigma_{+}^{3}+\sigma_{-}^{3}}{2}\right)^{k}=(1+o(1))\left(\frac{ \sigma_{+}^{2}+\sigma_{-}^{2}}{2}\right)^{\frac{3k}{2}}\gamma_{1}^{k}\)._

**Remark 5**.: _We observe that \(\gamma_{2}<2\) and \(\gamma_{1}\leq\gamma_{2}\). The first holds simply because \(\sigma_{+}^{4}+\sigma_{-}^{4}\geq 2\sigma_{+}^{2}\sigma_{-}^{2}\). By Cauchy-Schwarz inequality, for an arbitrary random variable \(X\), \(\mathbb{E}[X^{3}]\mathbb{E}[X^{2}]^{2}\leq\mathbb{E}[X^{4}]\mathbb{E}[X^{2}] ^{3/2}\). Let \(X\) takes \(\sigma_{+}^{2}\) and \(\sigma_{-}^{2}\) uniformly at random, then \(\frac{\mathbb{E}[X^{3}]}{\mathbb{E}[X^{2}]^{3/2}}\leq\frac{\mathbb{E}[X^{4}]}{ \mathbb{E}[X^{2}]^{3}}\) and thus \(\gamma_{1}\leq\gamma_{2}\) is implied._

### Proof of the Proposition

In regime \(sD_{+}(a,b)>1,\) we can recover the correct community label with high probability [2, 47, 1]. Therefore we can effectively work on the correct centralized adjacency matrices. Recall that \(\mathcal{H}=\{\frac{n}{2}-n^{\frac{3}{4}}\leq|V^{+}|,|V^{-}|\leq\frac{n}{2}+n^{ \frac{3}{4}}\}\), as defined in Section D.

Proof of Proposition 2.: From the definition of variance,

\[\mathrm{Var}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}]=\sum_{H,I\in\mathcal{T}} \mathrm{aut}(H)\mathrm{aut}(I)\sum_{S_{1},S_{2}\cong H,T_{1},T_{2}\cong I} \mathrm{Cov}(\overline{A}_{S_{1}}\overline{B}_{S_{2}}\mathbf{1}_{\mathcal{H}}, \overline{A}_{T_{1}}\overline{B}_{T_{2}}\mathbf{1}_{\mathcal{H}}).\]

If \(S_{1}=S_{2}\), \(T_{1}=T_{2}\), and \(V(S_{1})\cap V(T_{1})=\{i\}\), the covariance becomes zero. Also, we know from Proposition 1 that \(\mathbb{E}[\overline{A}_{S_{1}}\overline{B}_{S_{2}}]\mathbb{E}[\overline{A}_ {T_{1}}\overline{B}_{T_{2}}]\) is either \(0\) or \((1+o(1))(\rho\sigma_{\text{eff}})^{2N}\). Thus,

\[\mathrm{Var}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}]\leq\sum_{H,I\in\mathcal{T}} \mathrm{aut}(H)\mathrm{aut}(I)\sum_{S_{1},S_{2}\cong H,T_{1},T_{2}\cong I} \mathbb{E}[\overline{A}_{S_{1}}\overline{B}_{S_{2}}\overline{A}_{T_{1}} \overline{B}_{T_{2}}\mathbf{1}_{\mathcal{H}}].\]

\(\mathbb{E}[\overline{A}_{S_{1}}\overline{B}_{S_{2}}\overline{A}_{T_{1}} \overline{B}_{T_{2}}]\) is non-zero if and only if each edge \(e\in U\) is at least \(2\)-decorated. Let \(\mathcal{W}_{ij}\) denote the collection of decorated union graph \(U_{D}\), where \(S_{1}(i),S_{2}(j)\cong H,T_{1}(i),T_{2}(j)\cong I\) for some \(H,I\in\mathcal{T}\), such that each edge is at least \(2\)-decorated and satisfies \(S_{1}\neq S_{2}\) or \(T_{1}\neq T_{2}\) or \(V(S_{1})\cap V(T_{1})\neq\{i\}\).

\[\mathrm{Var}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}]\leq\sum_{U\in\mathcal{W}_{ij }}(\mathrm{aut}(S_{1})\mathrm{aut}(S_{2})\mathrm{aut}(T_{1})\mathrm{aut}(T_{2} ))^{\frac{1}{2}}\mathbb{E}[\overline{A}_{S_{1}}\overline{B}_{S_{2}}\overline{A }_{T_{1}}\overline{B}_{T_{2}}\mathbf{1}_{\mathcal{H}}].\] (53)

Conditioned on the ground-truth labeling \(\boldsymbol{\sigma}_{*}\),

\[g_{\bar{U}}(\sigma_{+},\sigma_{-})=\prod_{2\leq\ell+m\leq 4}\prod_{(u,v)\in K_{\ell m }}\sigma_{c(u,v)}^{(\ell+m)},\]

where \(c(u,v)=+\) if \(\boldsymbol{\sigma}_{*}(u)=\boldsymbol{\sigma}_{*}(v)\) and \(c(u,v)=-\) if \(\boldsymbol{\sigma}_{*}(u)\neq\boldsymbol{\sigma}_{*}(v)\).

Conditioned on \(\boldsymbol{\sigma}_{*}\), \(\mathcal{H}\) is determined,

\[\mathbb{E}[\overline{A}_{S_{1}}\overline{B}_{S_{2}}\overline{A}_{T_{1}} \overline{B}_{T_{2}}\mathbf{1}_{\mathcal{H}}]=\mathbb{E}\left[\mathbb{E}[ \overline{A}_{S_{1}}\overline{B}_{S_{2}}\overline{A}_{T_{1}}\overline{B}_{T_{ 2}}\mid\boldsymbol{\sigma}_{*}]\mathbf{1}_{\mathcal{H}}\right].\] (54)

Conditioned on \(\boldsymbol{\sigma}_{*}\), \(g_{\bar{U}}(\sigma_{+},\sigma_{-})\) is fixed, so as \(g_{\bar{U}}^{-1}(\sigma_{+},\sigma_{-})\).

\[g_{\bar{U}}(\sigma_{+},\sigma_{-})^{-1}\mathbb{E}[\overline{A}_{S_{1}} \overline{B}_{S_{2}}\overline{A}_{T_{1}}\overline{B}_{T_{2}}\mid\boldsymbol{ \sigma}_{*}]=\prod_{2\leq\ell+m\leq 4}\prod_{(u,v)\in K_{\ell m}}\sigma_{c(u,v)}^{-(\ell+m)} \mathbb{E}[\overline{A}_{uv}^{\ell}\overline{B}_{uv}^{m}\mid\boldsymbol{ \sigma}_{*}].\]

We define \(\beta_{\ell m}(e)\) as \(\sigma_{c(u,v)}^{-(\ell+m)}\mathbb{E}[\overline{A}_{uv}^{\ell}\overline{B}_{ uv}^{m}\mid\boldsymbol{\sigma}_{*}]\), for \(e=(u,v)\in K_{\ell,m}\). Thus,

\[g_{\bar{U}}(\sigma_{+},\sigma_{-})^{-1}\mathbb{E}[\overline{A}_{S_{1}} \overline{B}_{S_{2}}\overline{A}_{T_{1}}\overline{B}_{T_{2}}\mid\boldsymbol{ \sigma}_{*}]=g_{\bar{U}}(\sigma_{+},\sigma_{-})^{-1}\prod_{2\leq\ell+m\leq 4}\prod_{(u,v)\in K_{\ell m}}\beta_{\ell m}(e).\]

Then, we apply Lemma 13 to bound each \(\beta_{\ell m}(e)\). Since the upper bound of \(\beta_{\ell m}(e)\) only depends on \(\ell\) and \(m\), we have the following:

\[g_{\bar{U}}(\sigma_{+},\sigma_{-})^{-1}\mathbb{E}[\overline{A}_{S _{1}}\overline{B}_{S_{2}}\overline{A}_{T_{1}}\overline{B}_{T_{2}}\mid \boldsymbol{\sigma}_{*}]\leq |\max\{\rho_{+},\rho_{-}\}|^{e(K_{11})}\frac{(sp\wedge sq)^{-e(K_{22} )}}{\sqrt{(sp\wedge sq)}^{(e(K_{12})+e(K_{12}))}}\] \[= (1+o(1))\rho^{e(K_{11})}(sp\wedge sq)^{-2N+e(U)},\] (55)

where the last equality holds because \(2\left[\frac{1}{2}(e(K_{12})+e(K_{21}))+e(K_{22})\right]=(2-2)e(K_{20})+(2-2)e(K_ {02})+(3-2)e(K_{12})+(3-2)e(K_{12})+(4-2)e(K_{22})=4N-e(U)\). From (54) and (55), and the fact that \(\mathcal{H}\) happens with high probability, we have

\[\mathbb{E}[\overline{A}_{S_{1}}\overline{B}_{S_{2}}\overline{A}_{T_{1}} \overline{B}_{T_{2}}\mathbf{1}_{\mathcal{H}}]=(1+o(1))\rho^{e(K_{11})}(sp\wedge sq )^{-2N+e(U)}\mathbb{E}\left[g_{\bar{U}}(\sigma_{+},\sigma_{-})\mid\mathcal{H} \right].\] (56)It remains to compute \(\mathbb{E}\left[g_{\hat{U}}(\sigma_{+},\sigma_{-})\mid\mathcal{H}\right]\). Here, \(\hat{U}\) is fixed and we assume that there are \(d_{2}\)\(2\)-decorated edges, \(d_{3}\)\(3\)-decorated edges, and \(d_{4}\)\(4\)-decorated edges without loss of generality. Let \(X^{(2)},X^{(3)},\) and \(X^{(4)}\) be the number of in-community edges for \(2,3\), and \(4\)-decorated edges on the complete graph respectively. In \(\hat{U}\) is a tree, we can apply Lemma 10 to determine the distribution of \(X^{(2)},X^{(3)},\) and \(X^{(4)}\).

Generally, \(\hat{U}\) contains cycles. \(\hat{U}\) can be decomposed into a tree with an additional set of edges connecting vertices on the tree. We assume that there are \(A_{i}\)\(i\)-decorated edges on the tree and \(B_{i}\)\(i\)-decorated edges in the additional edge set of size \(e(\hat{U})-v(\hat{U})+1\), for \(i\in\{2,3,4\}\). We apply the Corollary 1 and have that \(\mathbb{P}(X^{(2,a)}=a_{2},X^{(3,a)}=a_{3},X^{(4,a)}=a_{4},X^{(2,b)}=b_{2},X^{ (3,b)}=b_{3},X^{(4,b)}=b_{4}\mid\mathcal{H})\leq(1+o(1))\binom{A_{2}}{a_{2}} \binom{A_{3}}{a_{3}}\binom{A_{4}}{a_{4}}\frac{1}{2^{A_{2}+A_{3}+A_{4}}}\), where \(X^{(i,a)}\) is the number of \(i\)-decorated in-community edges on the tree-part of \(\hat{U}\) and \(X^{(i,b)}\) is the number of \(i\)-decorated in-community edges among the additional edge set.

\(A_{i}\) and \(B_{i}\) are fixed but summed up to \(d_{i}\) for each \(\hat{U}\). \(a_{i}\) (\(b_{i}\)) takes possible values from \(0\) to \(A_{i}\) (\(B_{i}\)), for \(i\in[4]\). The number of \(i\)-decorated in-community edges is \(a_{i}+b_{i}\), and the number of \(i\)-decorated cross-community edges is \(d_{i}-a_{i}-b_{i}=(A_{i}-a_{i})+(B_{i}-b_{i})\).

\[\mathbb{E}\left[g_{\hat{U}}(\sigma_{+},\sigma_{-})\mid\mathcal{H}\right] =\sum_{a_{2}}^{A_{2}}\sum_{a_{3}}^{A_{3}}\sum_{a_{4}}^{A_{4}}\sum _{b_{2}}^{B_{2}}\sum_{b_{3}}^{B_{3}}\sum_{b_{4}}^{B_{4}}\sigma_{+}^{2(a_{2}+b _{2})}\sigma_{-}^{2(d_{2}-a_{2}-b_{2})}\sigma_{+}^{3(a_{3}+b_{3})}\sigma_{-}^ {3(d_{3}-a_{3}-b_{3})}\] \[\quad\times\sigma_{+}^{4(a_{4}+b_{4})}\sigma_{-}^{4(d_{4}-a_{4}-b _{4})}\binom{A_{2}}{a_{2}}\binom{A_{3}}{a_{3}}\binom{A_{4}}{a_{4}}\frac{1}{2^{ A_{2}+A_{3}+A_{4}}}\] \[=\left(\frac{\sigma_{+}^{2}+\sigma_{-}^{2}}{2}\right)^{A_{2}} \left(\frac{\sigma_{+}^{3}+\sigma_{-}^{3}}{2}\right)^{A_{3}}\left(\frac{ \sigma_{+}^{4}+\sigma_{-}^{4}}{2}\right)^{A_{4}}\] \[\quad\times\sum_{b_{2}=0}^{B_{2}}\sigma_{+}^{2b_{2}}\sigma_{-}^{ 2(B_{2}-b_{2})}\sum_{b_{3}=0}^{B_{3}}\sigma_{+}^{3b_{3}}\sigma_{-}^{3(B_{3}-b_{ 3})}\sum_{b_{4}=0}^{B_{4}}\sigma_{+}^{4b_{4}}\sigma_{-}^{4(B_{4}-b_{4})}\] \[\leq\left(\frac{\sigma_{+}^{2}+\sigma_{-}^{2}}{2}\right)^{d_{2}} \left(\frac{\sigma_{+}^{3}+\sigma_{-}^{3}}{2}\right)^{d_{3}}\left(\frac{\sigma_ {+}^{4}+\sigma_{-}^{4}}{2}\right)^{d_{4}}2^{k+1},\] (57)

where the last inequality holds because we can upper bound by multiplying a binomial coefficient \(\binom{B_{2}}{b_{2}}\binom{B_{3}}{b_{3}}\binom{B_{4}}{b_{4}}\) and that \(B_{2}+B_{3}+B_{4}=k+1\). By the definition of \(\gamma_{2}\) and \(\gamma_{1}\),

\[\mathbb{E}\left[g_{\hat{U}}(\sigma_{+},\sigma_{-})\mid\mathcal{H}\right]\leq \sigma_{\mathrm{eff}}^{2d_{2}+3d_{3}+4d_{4}}\gamma_{1}^{d_{3}}\gamma_{2}^{d_{2} }2^{k+1}\leq\sigma_{\mathrm{eff}}^{4N}\gamma_{2}^{2(e_{L}+e_{M}+e_{N})}2^{k+1}.\] (58)

The last inequality holds because \(\gamma_{1}<\gamma_{2}\) and \(d_{3}+d_{4}=e(K_{12})+e(K_{21})+e(K_{22})\leq 2(e_{L}+e_{M}+e_{N})\).

Denote \(\mathcal{W}_{ij}(v,k)\) as the subset of \(\mathcal{W}_{ij}\) that contains all the elements that have exactly \(v\) vertices except for \(i\) and \(j\) and excess \(k\). By applying the definition of union graph partitions, decorated graph weights, and (53),

\[\mathrm{Var}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}] \leq(1+o(1))\sum_{k\geq-1}\sum_{v}(sp\wedge sq)^{-2N+v+k+1}\sum_{ \hat{U}\in\mathcal{W}_{ij}(v,k)}\rho^{e(K_{11})}w(\hat{U}_{L})w(\hat{U}_{M})w( \hat{U}_{N})\] \[\quad\times\sigma_{\mathrm{eff}}^{4N}\gamma_{2}^{2(e_{L}+e_{M}+e_{ L})}2^{k+1},\] (59)

For the \(\dot{U}_{L},\dot{U}_{M},\dot{U}_{N}\) partition, we define

\[P_{L}(v_{L},e_{L},\ell) :=\sum_{\dot{U}_{L}\in\mathcal{U}_{L}(v_{L},e_{L},\ell)}w(\dot{U}_ {L}),\] (60) \[P_{M}(v_{M},e_{M}) :=\sum_{\dot{U}_{M}\in\mathcal{U}_{L}(v_{M},e_{M})}w(\dot{U}_{M}),\] (61) \[P_{N}(v_{N},e_{N},k) :=\sum_{\dot{U}_{N}\in\mathcal{U}_{N}(v_{N},e_{N})}w(\dot{U}_{N}).\] (62)Then, we can write out the upper bound as

\[\mathrm{Var}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}] \lesssim\sum_{k}\sum_{v}(sp\wedge sq)^{-2N+v+k+1}\sum_{v_{L},v_{M},v_ {N}\geq 0}\sum_{e_{L},e_{M},e_{N},\ell\geq 0}\sigma_{\mathbb{F}}^{4N}\gamma_{2}^{ 2(e_{L}+e_{M}+e_{L})}2^{k+1}\] \[\quad\times\rho^{\ell}P_{L}(v_{L},e_{L},\ell)P_{M}(v_{M},e_{M})P_{ N}(v_{N},e_{N},k).\]

Applying Proposition 1, Lemma 18, Lemma 19, and Lemma 20, we can upper bound the variance by:

\[\mathrm{Var}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}] \lesssim\sum_{k}\sum_{v}(sp\wedge sq)^{-2N+v+k+1}\sum_{v_{j}\geq 0} \sum_{e_{i},\ell\geq 0}\rho^{\ell}(11\beta n)^{v_{M}}R^{\frac{4e_{M}}{M}}\mathbf{1}_{ \{v_{M}\leq e_{M}\frac{4K+4M}{M}\}}\] \[\quad\times\sigma_{\mathrm{eff}}^{4N}\gamma_{2}^{2(e_{L}+e_{M}+e_ {L})}\times 2n^{v_{L}}(1+2L^{2})^{e_{L}}f_{\overline{v}_{\ell}}\mathbf{1}_{\{K+M |e_{L}+v_{L}\leq 2N\}}\] \[\quad\times n^{v_{N}}(11\beta)^{v_{N}}(22R^{4}(v_{N}+1)^{2})^{k+1 }\mathbf{1}_{\{v_{N}\leq 2(K+M)(k+1)\}}\]

Note that \(v_{M}\leq e_{M}\frac{4K+4M}{M}\), we have \(\sum_{v_{M}\geq 0}(11\beta)^{v_{M}}\leq 2(11\beta)^{e_{M}\frac{4K+4M}{M}}\). Also, we know that \(v_{N}\leq 2N,v_{N}\leq 2(K+M)(k+1)\). Then, \(\sum_{v_{N}\geq 0}(11\beta)^{v_{M}}\leq 2(11\beta)^{2(K+M)(k+1)}\). Thus,

\[\mathrm{Var}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}] \lesssim\sum_{k,v}(sp\wedge sq)^{-2N+v+k+1}\sum_{e_{L}+e_{M}+e_{N} =2N-(v+k+1)}2^{3}n^{v}\left(R^{\frac{4}{M}}(11\beta)^{\frac{4K+4M}{M}}\right) ^{e_{M}}\] \[\quad\times(22R^{4}(2N+1)(11\beta)^{2(K+M)})^{k+1}(1+2L^{2})^{e_{ L}}\sigma_{\mathrm{eff}}^{4N}\gamma_{2}^{2(e_{L}+e_{M}+e_{L})}\] \[\quad\times\sum_{v_{L}\geq 0,l\geq 0}\left(\rho^{\ell}f_{ \overline{v}_{\ell}}\mathbf{1}_{\{K+M|e_{L}+v_{L}\}}\mathbf{1}_{\{v_{L}+e_{L} \leq 2N\}}\right).\]

Regarding to the Lemma 4 in [41], if \(\frac{12L^{2}}{\rho^{2(K+M)(|\mathcal{J}|-2L)}}\leq\frac{1}{2}\), then

\[\mathrm{Var}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}] \lesssim\sum_{k,v}(sp\wedge sq)^{-2N+v+k+1}\sum_{v_{L}+v_{M}+e_{ L}+e_{M}+e_{N}=2N}2^{3}n^{v}\left(R^{\frac{4}{M}}(11\beta)^{\frac{4K+4M}{M}} \right)^{e_{M}}\] \[\quad(22R^{4}(2N+1)(11\beta)^{2(K+M)})^{k+1}(1+2L^{2})^{e_{L}} \sigma_{\mathrm{eff}}^{4N}\gamma_{2}^{2(e_{L}+e_{M}+e_{N})}\] \[\quad 8\rho^{2N}\left(\rho^{-2e_{L}}\mathbf{1}_{e_{L}\neq 0}+ \frac{12L^{2}}{\rho^{2(K+M)|\mathcal{J}|}}\mathbf{1}_{e_{L}=0}\right)|\mathcal{ T}|^{2}.\]

Note that \(\frac{12L^{2}}{\rho^{2(K+M)}(|\mathcal{J}|-2L)}\leq\frac{1}{2}\) is guaranteed by the first condition in (22) \(\frac{14L^{2}}{\rho^{2(K+M)}(|\mathcal{J}|)}\leq\frac{1}{2}\) for large enough \(n\).

In the following step, we divide \(\mathrm{Var}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}]\) by \(\mathbb{E}[\Phi_{i\pi_{*}(i)}\mathbf{1}_{\mathcal{H}}]^{2}\) and use the fact that \(e_{N}=2N-(v+k+1+e_{L}+e_{M})\):

\[\frac{\mathrm{Var}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}]}{\mathbb{E }[\Phi_{i\pi_{*}(i)}\mathbf{1}_{\mathcal{H}}]^{2}} \leq(1+o(1))2^{6}\sigma_{\mathrm{eff}}^{4N-4N}\sum_{k\geq-1} \left(\frac{22R^{4}(2N+1)(11\beta)^{2(K+M)}}{n}\right)^{k+1}\] \[\quad\sum_{e_{M}\geq 0}\left(\gamma_{2}^{2}\frac{R^{\frac{4}{M}}(11 \beta)^{\frac{4K+4M}{M}}}{ns(p\wedge q)}\right)^{e_{M}}\] \[\quad\sum_{e_{L}\geq 0}\left(\gamma_{2}^{2}\frac{1+2L^{2}}{ns(p \wedge q)}\right)^{e_{L}}\left(\rho^{-2e_{L}}\mathbf{1}_{\{e_{L}>0\}}+\frac{12 L^{2}}{\rho^{2(K+M)}|\mathcal{J}|}\mathbf{1}_{\{e_{L}=0\}}\right)\] \[\quad\sum_{e_{M}\geq 0}^{2N}\left(\gamma_{2}^{2}(\frac{n}{sp \wedge sq})\right)^{2N-(v+k+1+e_{L}+e_{M})}\mathbf{1}_{\{e_{L}+e_{M}\leq 2N-(v+k+1)\}}\]

In view of \(\gamma_{2}<2\), the last three conditions in (22) guarantee that

\[\sum_{k\geq-1}\left(\frac{22R^{4}(2N+1)(11\beta)^{2(K+M)}}{n} \right)^{k+1}\leq 2,\] \[\sum_{e_{M}\geq 0}\left(\gamma_{2}^{2}\frac{R^{\frac{4}{M}}(11 \beta)^{\frac{4K+4M}{M}}}{ns(p\wedge q)}\right)^{e_{M}}\leq 2,\quad\sum_{e_{L}\geq 0} \left(\gamma_{2}^{2}\frac{1+2L^{2}}{ns(p\wedge q)}\right)^{e_{L}}\leq 2.\]Also, for sufficiently large \(n\), \(\frac{\gamma_{2}^{2}}{ns(p\wedge q)}\leq\frac{1}{2}\), such that

\[\sum_{v=0}^{2N-k-1}(\frac{\gamma_{2}^{2}}{ns(p\wedge q)})^{2N-(v+k+1+e_{L}+e_{M })}\leq 2.\]

In conclusion,

\[\frac{\operatorname{Var}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}]}{\mathbb{E}[\Phi_{ i\pi_{*}(i)}\mathbf{1}_{\mathcal{H}}]^{2}}\leq O\left(\frac{\gamma_{2}^{2}(2+4L^{2})}{ \rho^{2}ns(p\wedge q)}+\frac{12L^{2}}{\rho^{2(K+M)}|\mathcal{J}|}\right)=O \left(\frac{L^{2}}{\rho^{2}ns(p\wedge q)}+\frac{L^{2}}{\rho^{2(K+M)}|\mathcal{J }|}\right).\qed\]

### Proof of auxiliary Lemmas

To complete the proof of Proposition 2, it remains to prove Lemma 18, Lemma 19, and Lemma 20. In this case, those upper bounds have been shown in [41]. We briefly re-state the proof idea.

**Lemma 18** (Upper bound of \(P_{L}(v_{L},e_{L},\ell)\) (True pairs: \(j=\pi_{*}(i)\), \(sD_{+}(a,b)>1\)).: \[P_{L}(v_{L},e_{L},\ell)\leq(1+o(1))2n^{v_{L}}(1+2L^{2})^{e_{L}}f_{\widetilde {t},t}\mathbf{1}_{\{K+M|e_{L}+v_{L}\}}\mathbf{1}_{\{v_{L}+e_{L}\leq 2N\}}.\]

Proof of Lemma 18.: Firstly, we define unlabeled union graph class \(\widetilde{\mathcal{U}}(v_{L},e_{L},\ell)\) and set of labeled union graphs isomorphic to \(\dot{U}_{L}\in\widetilde{\mathcal{U}}(v_{L},e_{L},\ell)\) as \(H(\dot{U}_{L})\).

\[P_{L}(v_{L},e_{L},\ell)=\sum_{\dot{U}_{L}\in\mathcal{U}_{L}(v_{L},e_{L},\ell)} w(\dot{U}_{L})=\sum_{\dot{U}_{L}\in\widetilde{\mathcal{U}}_{L}(v_{L},e_{L}, \ell)}w(\dot{U}_{L})|H(\dot{U}_{L})|.\]

The number of ways to label \(\dot{U}_{L}\) is \(|H(\dot{U}_{L})|\leq\binom{n}{v_{L}!}\frac{v_{L}!}{\operatorname{aut}(\dot{ U}_{L})}\leq\frac{n^{v_{L}}}{\operatorname{aut}(\dot{U}_{L})}\), \(\binom{n}{v_{L}!}v_{L}!\leq n^{v_{L}}\). In addition, \(w(\dot{U}_{L})\leq\operatorname{aut}(\dot{U}_{L})\). This is true because every bulbs are exactly \(2\)-decorated so for the union graph, the automorphism number coming from the orbits in this bulb is the same as the weights of this bulb. However, there can be other orbits outside the bulbs, for example, some bulbs are isomorphic so the vertices on the wires can be in the same orbit, thereby increasing the automorphism number.

From Lemma 7 in [41], we know that

\[|\widetilde{\mathcal{U}}_{L}(v_{L},e_{L},l)|\leq 2(1+2L^{2})^{e_{L}}f_{\widetilde {t},t}\mathbf{1}_{\{K+M|e_{L}+v_{L}\}}\mathbf{1}_{\{v_{L}+e_{L}\leq 2N\}},\]

where \(f_{\widetilde{t},t}\) counts the possible structures of chandeliers before merging edges to form a union graph and \(\widetilde{t}\) is depending on \(\ell\).

Combining these pieces together, we derived the upper bound:

\[P_{L}(v_{L},e_{L},\ell)\leq 2n^{v_{L}}(1+2L^{2})^{e_{L}}f_{\widetilde{t},t} \mathbf{1}_{\{K+M|e_{L}+v_{L}\}}\mathbf{1}_{\{v_{L}+e_{L}\leq 2N\}}.\]

See Lemma 3 in [41] for more detailed discussion on \(t,\widetilde{t}\) and \(f_{\widetilde{t},t}\). 

**Lemma 19** (Upper bound of \(P_{M}(v_{M},e_{M})\) (True pairs: \(j=\pi_{*}(i)\), \(sD_{+}(a,b)>1\))).: \[P_{M}(v_{M},e_{M})\leq(11\beta n)^{v_{M}}R^{\frac{4e_{M}}{M}}\sigma_{\rm eff }^{2v_{M}+2e_{M}}\gamma_{2}^{e_{M}}\mathbf{1}_{\{v_{M}\leq e_{M}\frac{4K+4M}{M }\}}.\]

Proof.: We have \(|\mathcal{N}_{M}|M\leq 2e_{M}\) because each connected component \(\dot{\mathcal{G}}(i,a)\) contains at least \(M\) edges that are 3 or 4-decorated and \(\mathcal{N}_{M}\) is the number of neighbors \(a\) in this set. This gives the constraint on \(v_{M}\leq\frac{2e_{M}}{M}(2K+2M)\) and from the definition of \(w(\cdot)\), \(w(\dot{U}_{M})\leq R^{2|\mathcal{N}_{M}|}\leq R^{\frac{4e_{M}}{M}}\). Define \(\widetilde{\mathcal{U}}_{M}(v_{M},e_{M})\) as the unlabeled union graph class and \(H(\dot{U}_{M})\) as the set of labeled \(\dot{U}_{M}\) for \(\dot{U}_{M}\in\widetilde{\mathcal{U}}_{M}(v_{M},e_{M})\).

\[P_{M}(v_{M},e_{M})=\sum_{\dot{U}_{M}\in\mathcal{U}_{M}(v_{M},e_{M})}w(\dot{U}_ {M})\leq R^{\frac{4e_{M}}{M}}\sum_{\dot{U}_{M}\in\widetilde{\mathcal{U}}_{M}(v_ {M},e_{M})}|H(\dot{U}_{M})|.\] (63)

We have \(|H(\dot{U}_{M})|\leq(n)^{v_{M}}\). There are at most \(\beta^{v_{M}}\) rooted unlabeled undercoated trees, where \(\beta=\frac{1}{(1+o(1))\alpha}\)[55] and at most \(11^{v_{M}}\) decorations for each tree. Thus, \(|\widetilde{\mathcal{U}}_{M}(v_{M},e_{M})|\leq(11\beta)^{v_{M}}\). Finally, we obtain that

\[P_{M}(v_{M},e_{M})\leq(11\beta n)^{v_{M}}R^{\frac{4e_{M}}{M}}\mathbf{1}_{\{v_{M }\leq(2K+2M)\frac{2e_{M}}{M}\}}.\qed\]

**Lemma 20** (Upper bound of \(P_{N}(v_{N},e_{N},k)\) (True pairs: \(j=\pi_{*}(i)\), \(sD_{+}(a,b)>1\))).: \[P_{N}(v_{N},e_{N},k)\leq n^{v_{N}}(11\beta)^{v_{N}}(11R^{4}(v_{N}+1)^{2})^{k+1} \mathbf{1}_{\{v_{N}\leq 2(K+M)(2k+2)\}}.\]

Proof.: From Lemma 2 in [41], we know that \(|\mathcal{N}_{N}|\leq 2k+2\) and thus \(w(\dot{U}_{N})\leq R^{|\mathcal{N}_{N}|}\leq R^{4(K+1)}\). Briefly, this is because the excess is \(k\) and whenever two branches tangle with each other, the excess of this graph increases by one. To maximally involving branches in this \(k+1\) times of branch tangles, we never re-tangle a branch after it has tangled with the other branch. In this way, we see that there are at most \(2(k+1)\) branches in \(\dot{U}_{N}\). This immediately gives the condition of \(v_{N}\leq(2k+2)(M+K)\). Define \(\tilde{\mathcal{U}}_{N}(v_{N},e_{N},k)\) as the unlabeled union graph class and \(H(\dot{U}_{N})\) as the set of labeled \(\dot{U}_{N}\) for \(\dot{U}_{N}\in\tilde{\mathcal{U}}_{N}(v_{N},e_{N},k)\).

\[P_{N}(v_{N},e_{N},k)=\sum_{\dot{U}_{N}\in\tilde{\mathcal{U}}_{N}(v_{N},e_{N},k )}w(\dot{U}_{N})\leq R^{4(k+1)}\sum_{\dot{U}_{N}\in\tilde{\mathcal{U}}_{N}(v_{ N},e_{N},k)}|H(\dot{U}_{N})|.\]

\(\dot{U}_{L}\) consists of a tree with \(v_{N}\) vertices and additional \(k+1\) edges connecting vertices on the tree. What's more, each edge can be associated with at most \(11\) possible decoration sets.

\[|\tilde{\mathcal{U}}_{N}(v_{N},e_{N},k)|\leq\beta^{v_{N}}\binom{\binom{v_{N}+1 }{2}}{k+1}1^{v_{N}+k+1}\leq(11\beta)^{v_{N}}(11(v_{N}+1)^{2})^{(k+1)}.\]

Therefore,

\[P_{N}(v_{N},e_{N},k)\leq n^{v_{N}}(11\beta)^{v_{N}}(11R^{4}(v_{N}+1)^{2})^{k+1 }\mathbf{1}_{\{v_{N}\leq 2(K+M)(2k+2)\}}.\qed\]

## Appendix J Proof of Proposition 3

In this section, we show the Proposition 3 to complete the analysis on variance of similarity score. In this case, as \(j\neq\pi_{*}(i)\), the decorated union graph structure is different from the case when \(j=\pi_{*}(i)\) because the roots of \(S_{1}\) and \(S_{2}\) are different on the complete graph.

### Graph partition

The definitions in Section I still apply, except that we need to re-define the union graph partition.

* **(Union graph partition)** We first decompose \(\dot{U}\) into three edge-disjoint subgraphs. Specifically, for any neighbor \(a\) of \(i\) in \(\dot{U}\), consider the graph \(\dot{U}\) with the edge \((i,a)\) removed and let \(\dot{\mathcal{C}}(i,a)\) be the connected component that contains \(a\). Denote \(\dot{\mathcal{G}}(i,a)\) as the union of \(\dot{\mathcal{C}}(i,a)\) and the edge \((i,a)\). Let \[\mathcal{N}_{T}(i) =\{a:D_{U}((i,a))\cap\{S_{1},T_{1}\}\neq\emptyset,\dot{\mathcal{ G}}(i,a)\text{ is a tree not containing }j\},\] \[\mathcal{N}_{N}(i) =\{a:D_{U}((i,a))\cap\{S_{1},T_{1}\}\neq\emptyset\}\setminus \mathcal{N}_{T}(i).\] Symmetrically, let \[\mathcal{N}_{T}(j) =\{a:D_{U}((j,a))\cap\{S_{2},T_{2}\}\neq\emptyset,\dot{\mathcal{ G}}(j,a)\text{ is a tree not containing }i\},\] \[\mathcal{N}_{N}(j) =\{a:D_{U}((j,a))\cap\{S_{2},T_{2}\}\neq\emptyset\}\setminus \mathcal{N}_{T}(j).\] Next, we further decompose \(\dot{U}_{T}(i)\) into two edge-disjoint subtrees and similarly for \(\dot{U}_{T}(j)\). In particular, define \[\mathcal{N}_{M}(i) =\{a\in\mathcal{N}_{T}(i):|\{e\in E(\dot{\mathcal{G}}(i,a)):|D_{e} |\geq 3\}|\geq M\},\] \[\mathcal{N}_{L}(i) =\mathcal{N}_{T}(i)\setminus\mathcal{N}_{M}(i).\] Then, we decompose \(\dot{U}\) according to the node set \(\mathcal{N}\) into two tree-parts on root \(i\) (resp. \(j\)): \[\dot{U}_{L}(i):=\bigcup_{a\in\mathcal{N}_{L}(i)}\dot{\mathcal{G}}(i,a),\quad \dot{U}_{M}(i):=\bigcup_{a\in\mathcal{N}_{M}(i)}\dot{\mathcal{G}}(i,a).\]and the non-tree part \[\dot{U}_{N}:=\dot{U}\setminus(\dot{U}_{L}(i)\cup\dot{U}_{M}(i)\cup\dot{U}_{L}(j) \cup\dot{U}_{M}(j)).\] (64) For convenience, we denote \[\dot{U}_{L}:=\dot{U}_{L}(i)\cup\dot{U}_{L}(j),\quad\dot{U}_{M}:=\dot{U}_{M}(i) \cup\dot{U}_{M}(j).\] (65)

We again assign weights to each of these decorated union graph partitions.

\[w(\dot{U}_{L}) :=w_{S_{1}}(\dot{U}_{L}(i))w_{T_{1}}(\dot{U}_{L}(i))w_{S_{2}}( \dot{U}_{L}(j))w_{T_{2}}(\dot{U}_{L}(j)),\] (66) \[w(\dot{U}_{M}) :=w_{S_{1}}(\dot{U}_{M}(i))w_{T_{1}}(\dot{U}_{M}(i))w_{S_{2}}( \dot{U}_{M}(j))w_{T_{2}}(\dot{U}_{M}(j)),\] (67) \[w(\dot{U}_{N}) :=w_{S_{1}}(\dot{U}\setminus\dot{U}_{T}(i))w_{T_{1}}(\dot{U} \setminus\dot{U}_{T}(i))w_{S_{2}}(\dot{U}\setminus\dot{U}_{T}(j))w_{T_{2}}( \dot{U}\setminus\dot{U}_{T}(j)).\] (68)

### Proof of the Proposition

Proof of Proposition 3.: In the case of \(j\neq\pi_{*}(i)\), the excess \(k\) of the union graph starts from \(-2\). This is because the minimum number of edges of a decorated union graph for \(j\neq\pi_{*}(i)\) with \(v\) vertices except for \(i\) and \(j\) is \(v\), when \(S_{1},T_{1}\) and \(S_{2},T_{2}\) form two disjoint trees rooted at \(i\) and \(j\) respectively. Therefore, \(k\geq v-v(\dot{U})=-2\).

The proof of Proposition 2 in Section I holds for \(j\neq\pi_{*}(i)\) until (59), which holds with placing \(k+1\) with \(k+2\). This is because the decorated union graph can be viewed as two disjoint trees with \(v+2\) vertices plus \(k+2\) edges connecting vertices on these two trees. We have,

\[\mathrm{Var}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}] \leq(1+o(1))\sum_{k\geq-2}\sum_{v=0}^{2N-k-2}(sp\wedge sq)^{-2N+v +k+2}\sum_{\dot{U}\in\mathcal{W}_{ij}(v,k)}\rho^{e(K_{11})}\mathrm{aut}(H) \mathrm{aut}(I)\] \[\quad\times\sigma_{\mathrm{eff}}^{4N}\gamma_{2}^{e(K_{12})+e(K_{ 21})+e(K_{22})}2^{k+2}.\]

We define \(P_{ij}(v,k):=\sum_{\dot{U}\in\mathcal{W}_{ij}(v,k)}\rho^{e(K_{11})}\mathrm{ aut}(H)\mathrm{aut}(I)\gamma_{2}^{e(K_{12})+e(K_{21})+e(K_{22})}\).

\[\mathrm{Var}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}] \leq(1+o(1))\sum_{k\geq-2}\sum_{v=0}^{2N-k-2}(sp\wedge sq)^{-2N+v+k+2} \sigma_{\mathrm{eff}}^{4N}2^{k+2}P_{ij}(v,k)\]

Case a: \(k=-2\).We first consider the special case when \(k=-2\). When \(k=-2\), there are two disjoint trees in the decorated union graph. Then, it must be the case of \(S_{1}=T_{1}\), \(S_{2}=T_{2}\), \(v=2N\), and \(H=I\). Therefore, \(e(K_{12})=e(K_{21})=e(K_{22})=0\). We have,

\[P_{ij}(2N,-2)\leq\sum_{H\in\mathcal{T}}\mathrm{aut}(H)^{2}|S_{1}(i):S_{1}\cong H ||S_{2}(j):S_{2}\cong H|=|\mathcal{T}|n^{2N}.\]

Under this parameterization, \(-2N+v+k+2\) is also zero, we have

\[\mathrm{Var}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}] \leq(1+o(1))\left(|\mathcal{T}|n^{2N}\sigma_{\mathrm{eff}}^{4N}+ \sum_{k>-2}\sum_{v=0}^{2N-k-2}(sp\wedge sq)^{-2N+v+k+2}\sigma_{\mathrm{eff}}^{4 N}2^{k+2}P_{ij}(v,k)\right).\]

It turns out that the summation over \(k>-2\) would have the same order as the first special case.

Case b: \(k>-2\).We enumerate through three parts of the union graph. Recall that \(e(K_{12})+e(K_{21})+e(K_{22})\leq 2(e_{L}+e_{M}+e_{N})=4N-2(v+k+2)\), therefore

\[P_{ij}(v,k) \leq\sum_{e_{M}}\sum_{v_{L},v_{M},v_{N}}\sum_{\dot{U}\in\mathcal{ W}(v,k)}w(\dot{U}_{L})w(\dot{U}_{M})w(\dot{U}_{N})\gamma_{2}^{e(K_{12})+e(K_{21})+e(K_{ 22})}\] \[\leq\sum_{e_{M}}\gamma_{2}^{4N-2(v+k+2)}\sum_{v_{L},v_{M},v_{N}}P_ {L}(v_{L})P_{M}(v_{M},e_{M})P_{N}(v_{N},k),\] (69)

where \(P_{M}(v_{M},e_{M})\) is defined as before, while we let \(P_{L}(v_{L})\) and \(P_{N}(v_{N},k)\) have no constraints on the number of \(3\) and \(4\)-decorated edges for \(\dot{U}_{L}\) and \(\dot{U}_{N}\).

We can plug those upper bounds from Lemma 21, Lemma 22, and Lemma 23 into (69):

\[P_{ij}(v,k) \leq\sum_{e_{M}}R^{2\frac{e_{M}}{M}}n^{v}|\mathcal{T}|4^{L}L^{2L \wedge(4K+2)}(6\beta)^{4(K+M)-2}\mathbf{1}_{\{e_{M}\leq 2N-(v+k+2)\}}\] \[\quad\times\sum_{v_{L}+v_{M}+v_{N}=v}v_{M}(11\beta)^{v_{M}}\beta( 11\beta)^{v_{N}}(22R^{4}(v_{N}+2)^{2})^{k+2}\sigma_{\mathrm{eff}}^{4N}\gamma_{ 2}^{4N-2(v+k+2)}\] \[\quad\times\mathbf{1}_{\{v_{M}\leq 2(K+M)\frac{2e_{M}}{M}\}} \mathbf{1}_{\{v_{N}\leq 4(K+M)(k+2)\}}.\]

Note that \(v_{M},v_{N}\leq v\leq 2N-k-2\leq 2N+1\) as \(k\geq-1\). Therefore \(v_{M}(v_{N}+2)^{2(k+2)}\leq(2N+1)^{3(k+2)}\). Applying \(e_{M}\leq 2N-(v+k+2)\), \(v_{N}\leq 4(K+M)(k+2)\) and \(v_{M}\leq 2(K+M)\frac{e_{M}}{M}\) we can get the following upper bound:

\[\frac{\mathrm{Var}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}]}{\mathbb{E }[\Phi_{i\pi_{*}(i)}\mathbf{1}_{\mathcal{H}}]^{2}} \leq(1+o(1))\frac{1}{|\mathcal{T}|\rho^{2N}}+(1+o(1))\frac{1}{| \mathcal{T}|\rho^{2N}}\Bigg{\{}4^{L}L^{2L\wedge(4K+2)}(6\beta)^{4K+4M}\] \[\quad\times\sum_{k\geq-1}\left(\frac{(11\beta)^{4(K+M)}22R^{4}(2 N+1)^{3}}{n}\right)^{k+2}\] \[\quad\times\sum_{v=0}^{2N-k-2}\left(\gamma_{2}^{2}\frac{R^{\frac{ 2}{M}}(11\beta)^{\frac{4(K+M)}{M}}}{ns(p\wedge q)}\right)^{2N-(v+k+2)}\Bigg{\}}.\]

From the first condition in (23), because \(\gamma_{2}<2\), we have

\[\sum_{v=0}^{2N-k-2}\left(\gamma_{2}^{2}\frac{R^{\frac{2}{M}}(11\beta)^{\frac{ 4(K+M)}{M}}}{ns(p\wedge q)}\right)^{2N-(v+k+2)}\leq 2.\]

From the second condition in (23), we have \(\frac{(11\beta)^{4(K+M)}22R^{4}(2N+1)^{3}}{n}\leq\frac{1}{2}\), therefore,

\[\sum_{k\geq-1}\left(\frac{(11\beta)^{4(K+M)}22R^{4}(2N+1)^{3}}{n}\right)^{k+2 }\leq 2\left(\frac{(11\beta)^{4(K+M)}22R^{4}(2N+1)^{3}}{n}\right).\]

From the second condition in (23), we know that

\[4^{L}L^{2L\wedge(4K+2)}(6\beta)^{4K+4M}2^{2}\left(\frac{(11\beta)^{4(K+M)}22R ^{4}(2N+1)^{3}}{n}\right)\leq\frac{1}{2}.\]

In summary,

\[\frac{\mathrm{Var}[\Phi_{ij}\mathbf{1}_{\mathcal{H}}]}{\mathbb{E}[\Phi_{i\pi_ {*}(i)}\mathbf{1}_{\mathcal{H}}]^{2}}=O(\frac{1}{|\mathcal{T}|\rho^{2N}}).\qed\]

### Proof of auxiliary Lemmas

The following Lemma 21, Lemma 22, and Lemma 23, have been shown by Mao et al. [41]. We briefly re-state those results for completeness.

**Lemma 21** (Upper bound of \(P_{L}(v_{L})\) (Fake pairs: \(j\neq\pi_{*}(i),sD_{+}(a,b)>1\))).: \[P_{L}(v_{L})\leq n^{v_{L}}|\mathcal{T}|4^{L}L^{2L\wedge(4K+2)}(6\beta)^{4(K+ M)-2}.\]

Proof.: Firstly, we introduce unlabeled union graph sets \(\widetilde{\mathcal{U}}(v_{L},e_{L})\) and the set of labeled isomorphic members as \(H(\dot{U}_{L})\), for \(\dot{U}_{L}\in\mathcal{U}(v_{L},e_{L},l)\). From definition (60),

\[P_{L}(v_{L})=\sum_{\dot{U}_{L}\in\mathcal{U}_{L}(v_{L})}w(\dot{U}_{L})=\sum_{ \dot{U}_{L}\in\widetilde{\mathcal{U}}_{L}(v_{L})}w(\dot{U}_{L})|H(\dot{U}_{L})|.\]

As we have repeatedly seen, \(|H(\dot{U}_{L})|\leq\frac{n^{v_{L}}}{\mathrm{aut}(\dot{U}_{L})}\). From the Lemma 10 and Claim 5-(v) in [41] we have the following takeaways: (1) \(|\widetilde{\mathcal{U}}_{L}(v_{L})|\leq|\mathcal{T}|4^{L}L^{2L\wedge(4K+2)}(6 \beta)^{4(K+M)-2}\); (2) \(w(\dot{U}_{L})\leq\mathrm{aut}(\dot{U}_{L}(i))\mathrm{aut}(\dot{U}_{L}(j))= \mathrm{aut}(\dot{U}_{L})\). Putting pieces together, we complete the proof.

[MISSING_PAGE_FAIL:52]

Proof of Proposition 4

In this section, we prove Proposition 4, which extends the Proposition 1 to the case when we can only perform almost exact community recovery with a single graph. We denote \(\widehat{\bm{\sigma}}:=(\widehat{\bm{\sigma}}_{A},\widehat{\bm{\sigma}}_{B})\), which is the combination of the community label estimates for both graphs.

Proof of Proposition 4.: By definition of the similarity score and \(\mathcal{H}\),

\[\mathbb{E}[\Phi_{ij}^{\widehat{\bm{\sigma}}}\bm{1}_{\mathcal{H}}] =\sum_{H\in\mathcal{T}}\operatorname{aut}(H)\sum_{S(i)\cong H} \sum_{T(j)\cong H}\mathbb{E}[\overline{A}_{S}^{\widehat{\bm{\sigma}}_{A}} \overline{B}_{T}^{\widehat{\bm{\sigma}}_{B}}\bm{1}_{\mathcal{H}}]\] \[=(1+o(1))\sum_{H\in\mathcal{T}}\operatorname{aut}(H)\sum_{S(i) \cong H}\sum_{T(j)\cong H}\mathbb{E}\left[\mathbb{E}[\overline{A}_{S}^{ \widehat{\bm{\sigma}}_{A}}\overline{B}_{T}^{\widehat{\bm{\sigma}}_{B}}\mid \bm{\sigma}_{*},\widehat{\bm{\sigma}}]\bm{1}_{\mathcal{H}}\right].\]

Define \(\mathcal{C}\) as the edge collection of the intersection graph of \(S\) and \(T\): \(\mathcal{C}:=E(S)\cap E(T)\).

\[\mathbb{E}[\Phi_{ij}^{\widehat{\bm{\sigma}}}\bm{1}_{\mathcal{H}}]\] \[\sim\sum_{H\in\mathcal{T}}\operatorname{aut}(H)\sum_{S(i)\cong H} \sum_{T(j)\cong H}\mathbb{E}\left[\mathbb{E}[\prod_{e\in\mathcal{C}}\overline {A}_{e}^{\widehat{\bm{\sigma}}_{A}}\overline{B}_{e}^{\widehat{\bm{\sigma}}_{B}} \mid\bm{\sigma}_{*},\widehat{\bm{\sigma}}]\prod_{e^{\prime}\in E(S)\setminus \mathcal{C}}\overline{A}_{e^{\prime}}^{\widehat{\bm{\sigma}}_{A}}\prod_{e^{ \prime\prime}\in E(T)\setminus\mathcal{C}}\overline{B}_{e^{\prime}}^{\widehat {\bm{\sigma}}_{B}}\mid\bm{\sigma}_{*},\widehat{\bm{\sigma}}]\bm{1}_{ \mathcal{H}}\right]\] \[\sim\sum_{H\in\mathcal{T}}\operatorname{aut}(H)\sum_{S(i)\cong H} \sum_{T(j)\cong H}\mathbb{E}\bigg{[}\prod_{e\in\mathcal{C}}\mathbb{E}[ \overline{A}_{e}^{\widehat{\bm{\sigma}}_{A}}\overline{B}_{e}^{\widehat{\bm{ \sigma}}_{B}}\mid\bm{\sigma}_{*},\widehat{\bm{\sigma}}]\prod_{e^{\prime}\in E (S)\setminus\mathcal{C}}\mathbb{E}[\overline{A}_{e^{\prime}}^{\widehat{\bm{ \sigma}}_{A}}\mid\bm{\sigma}_{*},\widehat{\bm{\sigma}}]\] \[\quad\times\prod_{e^{\prime\prime}\in E(T)\setminus\mathcal{C}} \mathbb{E}[\overline{B}_{e^{\prime}}^{\widehat{\bm{\sigma}}_{B}}\mid\bm{\sigma }_{*},\widehat{\bm{\sigma}}]\bm{1}_{\mathcal{H}}\bigg{]}.\]

We perform case studies for \(\mathbb{E}[\Phi_{ij}^{\widehat{\bm{\sigma}}}\bm{1}_{\mathcal{H}}]\) based on the structure of \(S,T\) as a union graph and then later sum each case up.

(a) \(S=T\), that is, all edges appear in pairs (this case is only possible for \(i=j\)).There are \((1+o(1))n^{N}/\operatorname{aut}(H)\) labeled union graphs of \(S_{1}\) and \(T_{1}\) satisfying this condition. In this case, every edge is \(2\)-decorated and it no longer matters whether \(\widehat{\bm{\sigma}}\) gives a correct output or not, as we can show the following upper bound.

\[\mathbb{E}[\Phi_{ij}^{\widehat{\bm{\sigma}}}\bm{1}_{\mathcal{H}}] ^{(A)} =(1+o(1))\sum_{H\in\mathcal{T}}\operatorname{aut}(H)\frac{n^{N}}{ \operatorname{aut}(H)}\mathbb{E}\left[\prod_{e\in\mathcal{C}}\mathbb{E}[ \overline{A}_{e}^{\widehat{\bm{\sigma}}_{A}}\overline{B}_{e}^{\widehat{\bm{ \sigma}}_{B}}\mid\bm{\sigma}_{*},\widehat{\bm{\sigma}}]\bm{1}_{\mathcal{H}}\right]\] \[\leq(1+o(1))|\mathcal{T}|n^{N}\sum_{N_{+}}\mathbb{P}(\zeta=N_{+}) \sum_{N^{\prime}}\mathbb{P}(\eta_{c+}=N_{c+},\eta_{c-}=N_{c-}|\zeta=N_{+})\] \[\quad\times(\rho_{+}\sigma_{+}^{2})^{N_{c+}}(\rho_{-}\sigma_{-}^{ 2})^{N_{c-}}(\rho_{+}\sigma_{+}^{2}+\Delta^{2})^{N_{+}-N_{c+}}(\rho_{-}\sigma_ {-}^{2}+\Delta^{2})^{N-N_{+}-N_{c-}}\] \[\leq(1+o(1))|\mathcal{T}|n^{N}\sum_{N_{+}=0}^{N}\binom{N}{N-1} \frac{1}{2^{N}}(\rho\sigma_{+}^{2}+\Delta^{2})^{N_{+}}(\rho\sigma_{-}^{2}+ \Delta^{2})^{N-N_{+}}\] \[=(1+o(1))|\mathcal{T}|n^{N}(\rho\sigma_{\mathrm{eff}}^{2}+\Delta^{ 2})^{N},\]

where \(\zeta\) is the number of in-community edges out of the \(N\) edges in \(S\), \(\eta_{c+}\) is the number of in-community edges that are centralized incorrectly, \(\eta_{c-}\) is the number of cross-community edges that are centralized incorrectly, and \(\Delta:=|p-q|\). (i) The first equality holds by definition and counting cases. (ii) The second inequality holds because there are \(N_{c+}(N_{c-})\) in(cross)-community edges centralized correctly, each of which contributes the same as \(\mathbb{E}[\overline{A}_{e}\overline{B}_{e}\mid\bm{\sigma}_{*}]=(1+o(1))\rho_{+} \sigma_{+}^{2}(\rho_{-}\sigma_{-}^{2})\) (Lemma 13). For the remaining edges, \(N_{+}-N_{c+}\) (\(N-N_{+}-N_{c-}\)) of them has \(\mathbb{E}[\overline{A}_{e}^{\widehat{\bm{\sigma}}_{A}}\overline{B}_{e}^{ \widehat{\bm{\sigma}}_{B}}\mid\bm{\sigma}_{*},\widehat{\bm{\sigma}}]=(1+o(1))( \rho_{+}\sigma_{+}^{2})+\mathbb{E}[\overline{A}_{e}^{\widehat{\bm{\sigma}}_{A}} \mid\bm{\sigma}_{*},\widehat{\bm{\sigma}}]\mathbb{E}[\overline{B}_{e}^{\widehat {\bm{\sigma}}_{B}}\mid\bm{\sigma}_{*},\widehat{\bm{\sigma}}]\leq(1+o(1))( \rho_{+}\sigma_{+}^{2}+\Delta^{2})\). (iii) The third inequality holds because \(\Delta^{2}>0\), Lemma 9 gives the distribution of \(\zeta\), and \(\rho=(1+\Theta(\frac{\log n}{n}))\rho_{+},\rho=(1+\Theta(\frac{\log n}{n})) \rho_{-}\). (iv) The last equality holds from the binomial theorem.

Observe that \(\Delta^{2}=(1+\Theta(\frac{\log n}{n}))(\rho\sigma_{\mathrm{eff}}^{2})\). Assume that \(N=O(\log n)\),

\[\mathbb{E}[\Phi_{ij}^{\widehat{\bm{\sigma}}}\bm{1}_{\mathcal{H}}]^{(A)}=(1+o(1))| \mathcal{T}|n^{N}(\rho\sigma_{\mathrm{eff}})^{N}.\](b) \(S\) and \(T\) have no common edges, that is, \(E(S)\cap E(T)=\emptyset\).We can use the trivial bound on the labeled \(S\) and \(T\) as \(\frac{n^{2N}}{\operatorname{aut}(H)^{2}}\).

\[\mathbb{E}[\Phi_{ij}^{\widehat{\boldsymbol{\sigma}}}\boldsymbol{1 }_{\mathcal{H}}]^{(B)}\] \[\sim\sum_{H\in\mathcal{T}}\operatorname{aut}(H)\sum_{S(i) \equiv H}\sum_{T(j)\cong H:\mathcal{C}=\emptyset}\mathbb{E}\left[\prod_{e^{ \prime}\in E(S)}\mathbb{E}[\overline{A}_{e^{\prime}}^{\widehat{\boldsymbol{ \sigma}}_{A}}\mid\boldsymbol{\sigma}_{*},\widehat{\boldsymbol{\sigma}}]\prod_{e ^{\prime\prime}\in E(T)}\mathbb{E}[\overline{B}_{e^{\prime}}^{\widehat{ \boldsymbol{\sigma}}_{B}}\mid\boldsymbol{\sigma}_{*},\widehat{\boldsymbol{ \sigma}}]\boldsymbol{1}_{\mathcal{H}}\right]\] \[\lesssim|\mathcal{T}|\frac{n^{2N}}{\operatorname{aut}(H)} \mathbb{P}(E)\Delta^{2N},\] (70)

where \(E\) denotes the event \(\{\widehat{\boldsymbol{\sigma}}:\prod_{e\in E(S)}\mathbb{E}[\overline{A}_{e} ^{\widehat{\boldsymbol{\sigma}}_{A}}]\prod_{e\in E(T)}\mathbb{E}[\overline{B} _{e}^{\widehat{\boldsymbol{\sigma}}_{B}}]=\Theta(\Delta^{e(S)+e(T)})\}\cap \mathcal{H}\), that is, every edge is centralized correctly and \(\mathcal{H}\) happens. This inequality is true because conditioned on \(\mathcal{H}\) and \(\widehat{\boldsymbol{\sigma}}\) being correct, \(\mathbb{E}[\overline{A}_{e}^{\widehat{\boldsymbol{\sigma}}_{A}}\mid \boldsymbol{\sigma}_{*},\widehat{\boldsymbol{\sigma}}]\boldsymbol{1}_{ \mathcal{H}}=o(n^{-D_{+}(a,b,s,\varepsilon)})\), the upper bound of the probability that one vertex on this edge being labeled incorrectly.

We further denote \(E^{\prime}\) as \(\{\widehat{\boldsymbol{\sigma}}_{A}:\prod_{e\in E(S)}\mathbb{E}[\overline{A} _{e}^{\widehat{\boldsymbol{\sigma}}_{A}}]=\Theta(\Delta^{e(S)})\}\cap \mathcal{H}\). It is obvious that \(\mathbb{P}(E)\leq\mathbb{P}(E^{\prime})\). Then, we need to upper bound the probability of \(\widehat{\boldsymbol{\sigma}}_{A}\) giving incorrect centralization for all edges in \(S\cup T\).

We observe that _there are only two situations_, that is, no vertices in \(S\) that has a neighbor with the same label correctness as itself. See Figure 8 for an illustration. We denote those two possible outcomes constraint on \(S\cup T\) as \(\widehat{\boldsymbol{\sigma}}_{1}\) and \(\widehat{\boldsymbol{\sigma}}_{2}\). \(\mathbb{P}(E^{\prime})=\mathbb{P}(\{\widehat{\boldsymbol{\sigma}}_{A}= \widehat{\boldsymbol{\sigma}}_{1}\}\cap\mathcal{H})+\mathbb{P}(\{\widehat{ \boldsymbol{\sigma}}_{A}=\widehat{\boldsymbol{\sigma}}_{2}\}\cap\mathcal{H})\).

By the label correctness, we separate \(V(S)\) into two disjoint sets: \(V(S)_{c}^{\widehat{\boldsymbol{\sigma}}}\) for the correctly labeled vertices and \(V(S)_{ic}^{\widehat{\boldsymbol{\sigma}}_{i}}\) for the incorrectly labeled vertices. The deterministic relationship between \(\widehat{\boldsymbol{\sigma}}_{1}\) and \(\widehat{\boldsymbol{\sigma}}_{2}\) is: \(V(S)_{c}^{\widehat{\boldsymbol{\sigma}}_{1}}=V(S)_{c}^{\widehat{\boldsymbol{ \sigma}}_{2}}\). without loss of generality, we assume \(|V(S)_{c}^{\widehat{\boldsymbol{\sigma}}_{1}}|>|V(S)_{ic}^{\widehat{\boldsymbol {\sigma}}_{1}}|\). Observe that event \(\{\boldsymbol{\sigma}_{A}=\widehat{\boldsymbol{\sigma}}_{1}\}\) (resp. \(\{\widehat{\boldsymbol{\sigma}}_{A}=\widehat{\boldsymbol{\sigma}}_{2}\}\)) is equivalent as saying the set of vertices on odd (resp. even) levels are labeled incorrectly (falling in the bad vertex set \(I_{\varepsilon}\) as defined in Section D).

Denote \(p_{a,b,s,\varepsilon,\delta,V}:=n^{-V\times D_{+}(a,b,s,\varepsilon)}+n^{- \varepsilon\delta(1-o(1))\log n}\). We can apply Lemma 8,

\[\mathbb{P}(\{\widehat{\boldsymbol{\sigma}}_{A}=\widehat{ \boldsymbol{\sigma}}_{1}\}\cap\mathcal{H}) \leq(1-p_{a,b,s,\varepsilon,\delta,|V(S)_{ic}^{\widehat{\boldsymbol{ \sigma}}_{1}}})(p_{a,b,s,\varepsilon,\delta,|V(S)_{ic}^{\widehat{\boldsymbol{ \sigma}}_{1}}}),\] \[\mathbb{P}(\{\widehat{\boldsymbol{\sigma}}_{A}=\widehat{ \boldsymbol{\sigma}}_{2}\}\cap\mathcal{H}) \leq(1-p_{a,b,s,\varepsilon,\delta,|V(S)_{ic}^{\widehat{\boldsymbol{ \sigma}}_{1}}})(p_{a,b,s,\varepsilon,\delta,|V(S)_{c}^{\widehat{\boldsymbol{ \sigma}}_{1}}}),\] \[\mathbb{P}(E^{\prime}) \leq 2(1-p_{a,b,s,\varepsilon,\delta,|V(S)_{c}^{\widehat{\boldsymbol {\sigma}}_{1}}})(p_{a,b,s,\varepsilon,\delta,|V(S)_{ic}^{\widehat{ \boldsymbol{\sigma}}_{1}}}).\]

Consider each chandelier has \(L\) branches and each has a \(M\)-wire (assume that \(M=\Theta(\frac{\log n}{\log long})\) as in condition (3)). Even if we don't know the structure of bulbs, we have a coarse lower bound \(|V(S)_{ic}^{\widehat{\boldsymbol{\sigma}}_{1}}|=\Omega(\frac{\log n}{\log \log n})\), because at least half of the vertices on wires should be labeled incorrectly.

For some constant \(c_{1}>0\) such that \(|V(S)_{ic}^{\widehat{\boldsymbol{\sigma}}_{1}}|\geq c_{1}\frac{\log n}{\log \log n}\),

\[\mathbb{P}(E)\leq\mathbb{P}(E^{\prime})\leq O(p_{a,b,s,\varepsilon,\delta,|V(S )_{ic}^{\widehat{\boldsymbol{\sigma}}_{1}}})\leq O(n^{-D_{+}(a,b,s,\varepsilon )c_{1}\frac{\log n}{\log\log n}}).\]

Figure 8: _Left_: One possible labeling such that all edges are centralized incorrectly, with the colored vertices indicating those that are labeled incorrectly and the black vertices indicating those that are labeled correctly. _Right_: Another possible labeling such that all edges are centralized incorrectly.

By substituting \(\mathbb{P}(E)\) and \(\Delta^{2N}\) into (70), we have

\[\mathbb{E}[\Phi^{\widehat{\bm{\sigma}}}_{ij}\mathbf{1}_{\mathcal{H}}]^{(B)}\leq O \left(|\mathcal{T}|\frac{n^{2N}}{\mathrm{aut}(H)}n^{-[D_{+}(a,b,s,\varepsilon) ]c_{1}\frac{\log n}{\log\log n}}(\rho\sigma^{2}_{\mathrm{eff}})^{2N}(\nu)^{2N }\right).\]

Recall that \(\mu=|\mathcal{T}|n^{N}(\rho\sigma^{2}_{\mathrm{eff}})^{N}\). Denote \(\nu^{2}=\frac{\Delta^{2}}{(\rho\sigma^{2}_{\mathrm{eff}})^{2}}(=(1+o(1))\frac {2(a-b)}{\rho(a+b)})\). For some constant \(c_{2}>0\) such that \(\rho\sigma^{2}_{\mathrm{eff}}\leq c_{2}\frac{\log n}{n}\),

\[\mathbb{E}[\Phi^{\widehat{\bm{\sigma}}}_{ij}\mathbf{1}_{\mathcal{H}}]^{(B)} \leq O\left(\mu c_{2}^{N}\nu^{2N}(\frac{\log n}{n})^{N}n^{N} \frac{n^{-D_{+}(a,b,s,\varepsilon)c_{1}\frac{\log n}{\log\log n}}}{\log\log n}\right)\]

\[=O\left(\mu c_{2}^{N}\nu^{2N}\frac{(\log n)^{N}}{n^{c_{1}D_{+}(a,b,s, \varepsilon)\frac{\log n}{\log\log n}}}\right).\]

For some constant \(c_{3}>0\) such that \(N=c_{3}\log n\), as in assumption (3),

\[=O\left(\mu(\frac{(c_{2}\nu^{2}\log n)^{c_{3}\log\log n}}{n^{c_{1} D_{+}(a,b,s,\varepsilon)}})^{\frac{\log n}{\log\log n}}\right)\] \[=o(\mu/n^{2}).\]

(c) \(S\) and \(T\) have some common edges, that is, \(E(S)\cap E(T)\neq\emptyset\).There are at most \([n^{2N}-n^{N}(n-N)^{N}]/\mathrm{aut}(H)^{2}=o(n^{N})n^{N}/\mathrm{aut}(H)^{2}\) cases in the enumeration of \(S\) and \(T\).

\[\mathbb{E}[\Phi^{\widehat{\bm{\sigma}}}_{ij}\mathbf{1}_{\mathcal{H}}]^{(C)} \lesssim\sum_{H\in\mathcal{T}}\mathrm{aut}(H)\sum_{M=1}^{N-1}\sum_{S(i)\cong H,T(j)\cong H:C\neq\emptyset,X_{d}=M}(\rho\sigma^{2}_{\mathrm{eff}}+\Delta^{2} )^{N-M}\Delta^{2M}\mathbb{P}(E^{\prime\prime}),\]

where we denote by \(E^{\prime\prime}\) the event

\[\{\widehat{\bm{\sigma}}:\prod_{e^{\prime}\in E(S)\setminus\mathcal{C}} \mathbb{E}[\widetilde{A}^{\widehat{\bm{\sigma}}_{e^{\prime}}}_{e^{\prime\prime }}]\prod_{e^{\prime\prime}\in E(T)\setminus\mathcal{C}}\mathbb{E}[\widetilde{ B}^{\widehat{\bm{\sigma}}_{e^{\prime}}}_{e^{\prime}}]=\Theta(\Delta)^{|E(S) \setminus\mathcal{C}|+|E(T)\setminus\mathcal{C}|}\}\cap\mathcal{H}.\]

Let \(X_{d}\) denote the number of different edges between \(S\) and \(T\) under the true permutation. The structures of \(S\) and \(T\) such that \(\{X_{d}=M\}\) happens, \(\sum_{S(i)\cong H}\sum_{T(j)\cong H}\mathbf{1}_{\{X_{d}=M\}}\), is upper bounded by \(\frac{n^{N}}{\mathrm{aut}(H)}\times\frac{n^{M}}{\mathrm{aut}(H)}\) as changing \(M\) edges from \(S\) to \(T\) allows changing at most \(M\) vertices for a tree. Then, we have

\[\mathbb{E}[\Phi^{\widehat{\bm{\sigma}}}_{ij}\mathbf{1}_{\mathcal{H }}]^{(C)} \lesssim|\mathcal{T}|n^{N}\sum_{M=1}^{N-1}(\rho\sigma^{2}_{\mathrm{ eff}}+\Delta^{2})^{N-M}n^{M}\Delta^{2M}\mathbb{P}(E^{\prime\prime})\] \[\lesssim|\mathcal{T}|n^{N}\sum_{M=1}^{N-1}(\rho\sigma^{2}_{ \mathrm{eff}})^{N-M}n^{M}(\rho\sigma^{2}_{\mathrm{eff}})^{2M}(\frac{2(a-b)}{ \rho(a+b)})^{2M}\mathbb{P}(E^{\prime\prime})\] \[=(1+o(1))\mu\sum_{M=1}^{N-1}(n\rho\sigma^{2}_{\mathrm{eff}})^{M} \nu^{2M}\mathbb{P}(E^{\prime\prime}).\] (71)

We observe the following:

\[\mathbb{P}(E^{\prime\prime})\leq n^{-D_{+}(a,b,s,\varepsilon)(2M/2D)}.\]

This inequality holds because there are \(2M\) edges centralized incorrectly (required from event \(E^{\prime\prime}\)) in \(S\) and \(T\) and each incorrect labeling of a vertex can lead to incorrect centralization on at most \(D\) edges. Therefore, at least \(2M/2D\) vertices should be wrongly labeled for \(E^{\prime\prime}\) to happen.

Substitute \(\mathbb{P}(E^{\prime\prime})\) into (71). Assuming that \(D=o(\frac{\log n}{\log\log n})\) (3),

\[\mathbb{E}[\Phi^{\widehat{\bm{\sigma}}}_{ij}\mathbf{1}_{\mathcal{H}}]^{(C)} \lesssim\mu\sum_{M=1}^{N-1}(\frac{n\rho\sigma^{2}_{\mathrm{eff}}\nu^{2}}{n^{ \frac{1}{D}D_{+}(a,b,s,\varepsilon)}})^{M}\lesssim\mu\sum_{M=1}^{N-1}(\frac{ \nu^{2}c_{1}\log n}{n^{\frac{1}{D}D_{+}(a,b,s,\varepsilon)}})^{M}=o(\mu).\]

In summary,

\[\mathbb{E}[\Phi^{\widehat{\bm{\sigma}}}_{ij}\mathbf{1}_{\mathcal{H}}]=\begin{cases} \mathbb{E}[\Phi^{\widehat{\bm{\sigma}}}_{ij}\mathbf{1}_{\mathcal{H}}]^{(A)}+ \mathbb{E}[\Phi^{\widehat{\bm{\sigma}}}_{ij}\mathbf{1}_{\mathcal{H}}]^{(B)}+ \mathbb{E}[\Phi^{\widehat{\bm{\sigma}}}_{ij}\mathbf{1}_{\mathcal{H}}]^{(C)}=(1+o (1))\mu&\text{if }j=\pi_{*}(i),\\ \mathbb{E}[\Phi^{\widehat{\bm{\sigma}}}_{ij}\mathbf{1}_{\mathcal{H}}]^{(B)}+ \mathbb{E}[\Phi^{\widehat{\bm{\sigma}}}_{ij}\mathbf{1}_{\mathcal{H}}]^{(C)}=o( \mu)&\text{if }j\neq\pi_{*}(i).\end{cases}\]

**Remark 6**.: _(Denser regime) If we are not restricting the sparse regime \(p=\frac{a\log n}{n}\) and \(q=\frac{b\log n}{n}\), we are interested in what general \(p,q\) conditions are for Lemma 4 to hold. Assume that \(p\lor q=O(n^{-c(n)})\), then the geometric series \(\sum_{M=1}^{N-1}\frac{n\rho\sigma_{\text{alt}}^{2}\nu^{2}}{n^{\frac{1}{D}}D_{+ (a,b,s,t)}}\) converges if and only if \(c(n)>1-\frac{D_{+}(a,b,s,\varepsilon)}{D}\)._

## Appendix L Proof of Proposition 5

### Proof of the Proposition

In this section, we analyze the second moment of similarity score. We expect the variance of \(\Phi_{ij}\) to be infinitely small in comparison with the squared expectation of true pair's similarity score.

Proof of Proposition 5.: Recall that \(S_{1},T_{1}\) are rooted on \(i\) and \(S_{2},T_{2}\) are rooted on \(j\).

\[\operatorname{Var}[\Phi_{ij}^{\widehat{\sigma}}\mathbf{1}_{\mathcal{H}}] =\sum_{H,I\in\mathcal{T}}\operatorname{aut}(H)\text{aut}(I)\sum_ {S_{1},S_{2}\cong H,T_{1},T_{2}\cong I}\operatorname{Cov}(\overline{A}_{S_{1} }^{\widehat{\sigma}_{A}}\overline{B}_{S_{2}}^{\widehat{\sigma}_{B}}\mathbf{1} _{\mathcal{H}},\overline{A}_{T_{1}}^{\widehat{\sigma}_{A}}\overline{B}_{T_{2} }^{\widehat{\sigma}_{B}}\mathbf{1}_{\mathcal{H}})\] (72) \[=\underbrace{\sum_{H,I\in\mathcal{T}}\operatorname{aut}(H) \text{aut}(I)}_{S_{1},S_{2}\cong H,T_{1},T_{2}\cong I}\mathbb{E}[\overline{A} _{S_{1}}^{\widehat{\sigma}_{A}}\overline{B}_{S_{2}}^{\widehat{\sigma}_{B}} \overline{A}_{T_{1}}^{\widehat{\sigma}_{A}}\overline{B}_{T_{2}}^{\widehat{ \sigma}_{B}}\mathbf{1}_{\mathcal{H}}]-\] \[\underbrace{\sum_{H,I\in\mathcal{T}}\operatorname{aut}(H) \text{aut}(I)}_{S_{1},S_{2}\cong H,T_{1},T_{2}\cong I}\mathbb{E}[\overline{A} _{S_{1}}^{\widehat{\sigma}_{A}}\overline{B}_{S_{2}}^{\widehat{\sigma}_{B}} \mathbf{1}_{\mathcal{H}}]\mathbb{E}[\overline{A}_{T_{1}}^{\widehat{\sigma}_{ A}}\overline{B}_{T_{2}}^{\widehat{\sigma}_{B}}\mathbf{1}_{\mathcal{H}}]\]

(a) Analyzing \(V_{2}\).We first give the upper bound of the latter part. When analyzing with correct centralization, we ignore this part as it is non-negative in the correct centralization case. However, in this case, it is possible to be negative because there can be odd number of edges occurring once and also being incorrectly centralized.

After factorizing \(V_{2}\),

\[V_{2}=\left(\sum_{H\in\mathcal{T}}\operatorname{aut}(H)\sum_{S_{1},S_{2}\cong H }\mathbb{E}[\overline{A}_{S_{1}}^{\widehat{\sigma}_{A}}\overline{B}_{S_{2}}^ {\widehat{\sigma}_{B}}\mathbf{1}_{\mathcal{H}}]\right)\left(\sum_{I\in \mathcal{T}}\operatorname{aut}(I)\sum_{T_{1},T_{2}\cong I}\mathbb{E}[\overline {A}_{T_{1}}^{\widehat{\sigma}_{A}}\overline{B}_{T_{2}}^{\widehat{\sigma}_{B}} \mathbf{1}_{\mathcal{H}}]\right),\]

we can see that \(V_{2}\geq 0\), and thus we have \(\operatorname{Var}[\Phi_{ij}^{\widehat{\sigma}}\mathbf{1}_{\mathcal{H}}]\leq V _{1}\) for \(j=\pi_{*}(i)\).

(b) Analyzing \(V_{11}\).The main challenge here is that we do not have the condition that every edge occurs at least twice in the union graph as in the analysis of Regime I. However, we can put union graphs into two categories based on whether every edge is at least \(2\)-decorated or not. We keep the notation of \(\mathcal{W}_{ij}\) as the collection of decorated union graphs \(\hat{U}\) that are at least \(2\)-decorated and we decompose (72) as follows

\[V_{1} =\sum_{H,I\in\mathcal{T}}\operatorname{aut}(H)\text{aut}(I)\sum_ {S_{1},S_{2}\cong H,T_{1},T_{2}\cong I}\mathbb{E}[\overline{A}_{S_{1}}^{ \widehat{\sigma}_{A}}\overline{B}_{S_{2}}^{\widehat{\sigma}_{B}}\overline{A}_ {T_{1}}^{\widehat{\sigma}_{A}}\overline{B}_{T_{2}}^{\widehat{\sigma}_{B}} \mathbf{1}_{\mathcal{H}}]\] \[=\underbrace{\sum_{U\in\mathcal{W}_{ij}}(\operatorname{aut}(S_{1} )\text{aut}(S_{2})\text{aut}(T_{1})\text{aut}(T_{2}))^{\frac{1}{2}}\mathbb{E} [\overline{A}_{S_{1}}^{\widehat{\sigma}_{A}}\overline{B}_{S_{2}}^{\widehat{ \sigma}_{B}}\overline{A}_{T_{1}}^{\widehat{\sigma}_{A}}\overline{B}_{T_{2}}^{ \widehat{\sigma}_{B}}\mathbf{1}_{\mathcal{H}}]}_{V_{11}}+\] \[\quad+\underbrace{\sum_{\dot{U}\not\in\mathcal{W}_{ij}}( \operatorname{aut}(S_{1})\text{aut}(S_{2})\text{aut}(T_{1})\text{aut}(T_{2}))^ {\frac{1}{2}}\mathbb{E}[\overline{A}_{S_{1}}^{\widehat{\sigma}_{A}}\overline{B }_{S_{2}}^{\widehat{\sigma}_{B}}\overline{A}_{T_{1}}^{\widehat{\sigma}_{A}} \overline{B}_{T_{2}}^{\widehat{\sigma}_{B}}\mathbf{1}_{\mathcal{H}}]}_{V_{12}}.\]

We first show that \(V_{11}/\mu^{2}=O\left(\frac{L^{2}}{\rho^{2}ns(p\wedge q)}+\frac{L^{2}}{\rho^{2 (k+M)}|\mathcal{J}|}\right)\).

The incorrect centralization affects the upper bound of moments as the following:

\[\mathbb{E}[\overline{A}_{S_{1}}^{\widehat{\bm{\sigma}}_{A}}\overline{B }_{S_{2}}^{\widehat{\bm{\sigma}}_{B}}\overline{A}_{T_{1}}^{\widehat{\bm{\sigma}} _{A}}\overline{B}_{T_{2}}^{\widehat{\bm{\sigma}}_{B}}\mathbf{1}_{\mathcal{H}}]\] \[\qquad=\mathbb{E}\left[g_{\hat{U}}(\sigma_{+},\sigma_{-})\prod_{2 \leq\ell+m\leq 4}\prod_{(u,v)\in K_{\ell m}}\sigma_{c(u,v)}^{-(\ell+m)} \mathbb{E}[\overline{A}_{uv}^{\widehat{\bm{\sigma}}_{A},\ell}\overline{B}_{uv}^ {\widehat{\bm{\sigma}}_{B},m}\mid\bm{\sigma}_{*},\widehat{\bm{\sigma}}] \mathbf{1}_{\mathcal{H}}\right]\] \[\qquad=\mathbb{E}\left[g_{\hat{U}}(\sigma_{+},\sigma_{-})\prod_{2 \leq\ell+m\leq 4}\beta_{l,m}^{e(K_{\ell m})}\mathbf{1}_{\mathcal{H}}\right]\] \[\qquad\leq\rho^{e(K_{11})}(sp\wedge sq)^{-2N+e(U)}\sigma_{\text{ eff}}^{4N}(1+O(\frac{\log n}{n}))^{e(U)}\] \[\qquad\leq\rho^{e(K_{11})}(sp\wedge sq)^{-2N+e(U)}\sigma_{\text{ eff}}^{4N}(1+O(\frac{\log n}{n}))^{4N}.\] (73)

The first two equalities follow from definitions. The third inequality holds because of the upper bounds of \(\beta_{\ell,m}^{e(K_{\ell m})}\) from Lemma 14 holds for all \(\widehat{\bm{\sigma}}\).

Then, the structures of the union graph, alone with the assigned weights are bounded the same as in Section I. This implies that \(\frac{V_{11}}{\mathbb{E}[\Phi_{i\pi_{*}(i)}\mathbf{1}_{\mathcal{H}}]^{2}}\leq O \left(\frac{L^{2}}{\rho^{2}ns(p\wedge q)}+\frac{L^{2}}{\rho^{2(K+M)}|\mathcal{ J}|}\right)\) under the same condition as (22).

(c) Analyzing \(V_{12}\).To conclude \(\frac{\operatorname{Var}[\widehat{\Phi}_{i\pi_{*}(i)}^{\widehat{\bm{\sigma}}_{ B}}\mathbf{1}_{\mathcal{H}}]^{2}}{\mathbb{E}[\Phi_{i\pi_{*}(i)}\mathbf{1}_{ \mathcal{H}}]^{2}}\leq\frac{V_{11}+V_{12}+V_{2}}{\mathbb{E}[\Phi_{i\pi_{*}(i)} \mathbf{1}_{\mathcal{H}}]^{2}}=O\left(\frac{L^{2}}{\rho^{2}ns(p\wedge q)}+ \frac{L^{2}}{\rho^{2(K+M)}|\mathcal{J}|}\right)\), it remains to show \(V_{12}=o\left(\frac{L^{2}}{\rho^{2}ns(p\wedge q)}+\frac{L^{2}}{\rho^{2(K+M)}| \mathcal{J}|}\right)\). Lemma 24 gives a even stronger result, because as assumed in Proposition 5, \(L=o(\log n))\), giving \(\frac{L^{2}}{\rho^{2}ns(p\wedge q)}+\frac{L^{2}}{\rho^{2(K+M)}|\mathcal{J}|}\gg n ^{-\varepsilon^{\prime}}\) for all \(\varepsilon^{\prime}>0\). 

**Lemma 24**.: _Under the same conditions as Proposition 5, for some \(\varepsilon^{\prime}>0\),_

\[\frac{V_{12}}{\mathbb{E}[\Phi_{i\pi_{*}(i)}\mathbf{1}_{\mathcal{H}}]^{2}}=o( n^{-\varepsilon^{\prime}}).\]

Proof.: For the expectation inside \(V_{1}\) part, it can be separated as eight sets \(K_{\ell m}\):

\[\mathbb{E}[\overline{A}_{S_{1}}^{\widehat{\bm{\sigma}}_{A}}\overline{B}_{S_{2} }^{\widehat{\bm{\sigma}}_{B}}\overline{A}_{T_{1}}^{\widehat{\bm{\sigma}}_{A}} \overline{B}_{T_{2}}^{\widehat{\bm{\sigma}}_{B}}\mathbf{1}_{\mathcal{H}}]= \mathbb{E}\left[g_{\hat{U}}g_{\hat{U}}^{-1}\mathbb{E}[\prod_{\ell\in[2],m\in[2 ],\ell+m\geq 1}\prod_{e\in K_{\ell m}}\overline{A}_{e}^{\widehat{\bm{\sigma}}_{ A},\ell}\overline{B}_{e}^{\widehat{\bm{\sigma}}_{B},m}\mid\bm{\sigma}_{*}, \widehat{\bm{\sigma}}]\mathbf{1}_{\mathcal{H}}\right],\]

where \(g_{\hat{U}}\) is the abbreviation for \(g_{\hat{U}}(\sigma_{+},\sigma_{-})\).

Conditioned on \(\bm{\sigma}\) and \(\widehat{\bm{\sigma}}\), approximately centered edges are still independent with each other,

\[\mathbb{E}[\overline{A}_{S_{1}}^{\widehat{\bm{\sigma}}_{A}}\overline{B}_{S_{2} }^{\widehat{\bm{\sigma}}_{B}}\overline{A}_{T_{1}}^{\widehat{\bm{\sigma}}_{A}} \overline{B}_{T_{2}}^{\widehat{\bm{\sigma}}_{B}}\mathbf{1}_{\mathcal{H}}]= \mathbb{E}\left[g_{\hat{U}}g_{\hat{U}}^{-1}\prod_{\ell\in[2],m\in[2],\ell+m \geq 1}\prod_{e\in K_{\ell m}}\mathbb{E}[\overline{A}_{e}^{\widehat{\bm{\sigma}}_{ A},\ell}\overline{B}_{e}^{\widehat{\bm{\sigma}}_{B},m}\mid\bm{\sigma}_{*}, \widehat{\bm{\sigma}}]\mathbf{1}_{\mathcal{H}}\right],\]

Lemma 14 gives the upper bound over \(\eta_{\ell,m}:=\sigma_{c(e)}^{-(\ell+m)}\mathbb{E}[\overline{A}_{e}^{\widehat{ \bm{\sigma}}_{A},\ell}\overline{B}_{e}^{\widehat{\bm{\sigma}}_{B},m}\mid\bm{ \sigma}_{*},\widehat{\bm{\sigma}}]\) and thus by enumerating through the products, we have

\[g_{\hat{U}}^{-1}\prod_{\ell\in[2],m\in[2],\ell+m\geq 1}\prod_{e\in K_{ \ell m}}\mathbb{E}[\overline{A}_{e}^{\widehat{\bm{\sigma}}_{A},\ell}\overline{B}_ {e}^{\widehat{\bm{\sigma}}_{B},m}\mid\bm{\sigma}_{*},\widehat{\bm{\sigma}}]\] \[\qquad\qquad\qquad\leq(1+\Theta(\frac{\log n}{n}))^{4N}\rho^{e(K_{ 11})}(sp\wedge sq)^{-\frac{1}{2}(e(K_{12})+e(K_{21}))-e(K_{22})}\mathbb{P}( \mathcal{E})\Delta^{z/2},\] \[\qquad\qquad\qquad\qquad\leq(1+o(1))\rho^{e(K_{11})}(sp\wedge sq)^{ v+k+1-2N}\mathbb{P}(\mathcal{E})(\frac{|a-b|}{a\wedge b})^{z/2},\]where \(\mathcal{E}:=\{\text{Every 1-decorated edges are centralized incorrectly}\}\cap\mathcal{H}\) and \(z\) is the number of \(1\)-decorated edges, namely, \(z:=e(K_{01})+e(K_{10})\). The second inequality holds because \(-\frac{1}{2}(e(K_{12})+e(K_{21}))-e(K_{22})=(v+k+1)-2N-z/2\).

According to Lemma 8 and condition (24), we have that for any \(\varepsilon>0\),

\[\mathbb{P}(\mathcal{E})\leq n^{-D_{+}(a,b,s,\varepsilon)\frac{\varepsilon}{B }}.\]

Putting things together,

\[\mathbb{E}[\bar{A}_{S_{1}}^{\bar{\boldsymbol{\sigma}}_{A}}\bar{\boldsymbol{ \sigma}}_{B_{2}}^{\bar{\boldsymbol{\sigma}}_{B}}\bar{A}_{T_{1}}^{\bar{ \boldsymbol{\sigma}}_{A}}\bar{B}_{T_{2}}^{\bar{\boldsymbol{\sigma}}_{B}} \boldsymbol{1}_{\mathcal{H}}]\leq(1+o(1))n^{-D_{+}(a,b,s,\varepsilon)\frac{ \varepsilon}{B}}(sp\wedge sq)^{v+k+1-2N}\rho^{e(K_{11})}\mathbb{E}[g_{\hat{U}}( \sigma_{+},\sigma_{-})\mid\mathcal{H}].\]

It remains to calculate \(\mathbb{E}[g_{\hat{U}}(\sigma_{+},\sigma_{-})\mid\mathcal{H}]\).

Similar as in the calculation in Section I, where we only consider \(\hat{U}\) being at least \(2\)-decorated. Here, we need to generalize it into the case when \(\hat{U}\) has \(1\)-decorated edges. \(\hat{U}\) can be decomposed into a tree with an additional set of edges connecting vertices on the tree. We assume that there are \(A_{i}\)\(i\)-decorated edges on the tree and \(B_{i}\)\(i\)-decorated edges in the additional edge set of size \(e(\hat{U})-v(\hat{U})+1\), for \(i\in[4]\). We apply the Corollary 1 and have that \(\mathbb{P}(X^{(1,a)}=a_{1},X^{(2,a)}=a_{2},X^{(3,a)}=a_{3},X^{(4,a)}=a_{4},X^{( 1,b)}=b_{1},X^{(2,b)}=b_{2},X^{(3,b)}=b_{3},X^{(4,b)}=b_{4}\mid\mathcal{H}) \leq(1+o(1))\binom{A_{1}}{a_{1}}\binom{A_{2}}{a_{2}}\binom{A_{3}}{a_{3}}\binom{ A_{4}}{a_{4}}\frac{1}{2^{A_{1}+A_{2}+A_{3}+A_{4}}},\) where \(X^{(i,a)}\) is the number of \(i\)-decorated in-community edges on the tree-part of \(\hat{U}\) and \(X^{(i,b)}\) is the number of \(i\)-decorated in-community edges among the additional edge set.

\(A_{i}\) and \(B_{i}\) are fixed but summed up to \(d_{i}\) for each \(\hat{U}\). \(a_{i}\) (\(b_{i}\)) takes possible values from \(0\) to \(A_{i}\) (\(B_{i}\)), for \(i\in[4]\). The number of \(i\)-decorated in-community edges is \(a_{i}+b_{i}\), and the number of \(i\)-decorated cross-community edges is \(d_{i}-a_{i}-b_{i}=(A_{i}-a_{i})+(B_{i}-b_{i})\).

\[\mathbb{E}\left[g_{\hat{U}}(\sigma_{+},\sigma_{-})\mid\mathcal{H}\right]\] \[\leq(1+o(1))\sum_{a_{1}}^{A_{1}}\sum_{a_{2}}^{A_{2}}\sum_{a_{3}}^{A _{3}}\sum_{a_{4}}^{A_{4}}\sum_{b_{1}}^{B_{1}}\sum_{b_{2}}^{B_{2}}\sum_{b_{3}} ^{B_{3}}\sum_{b_{4}}^{B_{4}}\sigma_{+}^{(a_{1}+b_{1})}\sigma_{+}^{2(a_{2}+b_{ 2})}\sigma_{-}^{2(d_{2}-a_{2}-b_{2})}\sigma_{+}^{3(a_{3}+b_{3})}\sigma_{-}^{3( d_{3}-a_{3}-b_{3})}\] \[\quad\times\sigma_{+}^{4(a_{4}+b_{4})}\sigma_{-}^{4(d_{4}-a_{4}-b _{4})}\binom{A_{1}}{a_{1}}\binom{A_{2}}{a_{2}}\binom{A_{3}}{a_{3}}\binom{A_{4} }{a_{4}}\frac{1}{2^{A_{1}+A_{2}+A_{3}+A_{4}}}\] \[=(1+o(1))\left(\frac{\sigma_{+}+\sigma_{-}}{2}\right)^{A_{1}} \left(\frac{\sigma_{+}^{2}+\sigma_{-}^{2}}{2}\right)^{A_{2}}\left(\frac{\sigma_ {+}^{3}+\sigma_{-}^{3}}{2}\right)^{A_{3}}\left(\frac{\sigma_{+}^{4}+\sigma_{-} ^{4}}{2}\right)^{A_{4}}\] \[\quad\times\sum_{b_{1}=0}^{B_{1}}\sigma_{+}^{b_{1}}\sigma_{-}^{(B_ {1}-b_{1})}\sum_{b_{2}=0}^{B_{2}}\sigma_{+}^{2b_{2}}\sigma_{-}^{2(B_{2}-b_{2})} \sum_{b_{3}=0}^{B_{3}}\sigma_{+}^{3b_{3}}\sigma_{-}^{3(B_{3}-b_{3})}\sum_{b_{4 }=0}^{B_{4}}\sigma_{+}^{4b_{4}}\sigma_{-}^{4(B_{4}-b_{4})}\] \[\leq(1+o(1))\left(\frac{\sigma_{+}+\sigma_{-}}{2}\right)^{d_{1}} \left(\frac{\sigma_{+}^{2}+\sigma_{-}^{2}}{2}\right)^{d_{2}}\left(\frac{\sigma_ {+}^{3}+\sigma_{-}^{3}}{2}\right)^{d_{3}}\left(\frac{\sigma_{+}^{4}+\sigma_{-} ^{4}}{2}\right)^{d_{4}}2^{k+1},\]

where the last inequality holds because the upper bound holds with multiplying a binomial coefficient \(\binom{B_{1}}{b_{1}}\binom{B_{2}}{b_{2}}\binom{B_{3}}{b_{3}}\binom{B_{4}}{b_{4}}\) and that \(\sum_{i}B_{i}=k+1\). By the definition of \(\gamma_{2}\) and \(\gamma_{1}\),

\[\mathbb{E}\left[g_{\hat{U}}(\sigma_{+},\sigma_{-})\mid\mathcal{H}\right]\leq(1+o(1 ))\left(\frac{\sigma_{+}+\sigma_{-}}{2}\right)^{d_{1}}\sigma_{\text{eff}}^{2d_{2 }+3d_{3}+4d_{4}}\gamma_{1}^{d_{3}}\gamma_{2}^{d_{4}}2^{k+1}.\]

Define \(\gamma_{0}:=(\frac{\sigma_{+}+\sigma_{-}}{2})/\sigma_{\text{eff}}\) and we can see that \(\gamma_{0}<1\). So, we can upper bound \((\frac{\sigma_{+}+\sigma_{-}}{2})^{d_{1}}\) as \(\sigma_{\text{eff}}^{d_{1}}\). Because \(\gamma_{1}<\gamma_{2}\) and \(d_{3}+d_{4}=e(K_{12})+e(K_{21})+e(K_{22})\),

\[\mathbb{E}\left[g_{\hat{U}}(\sigma_{+},\sigma_{-})\mid\mathcal{H}\right]\leq(1+o(1 ))\sigma_{\text{eff}}^{4N}\gamma_{2}^{e(K_{12})+e(K_{21})+e(K_{22})}2^{k+1}.\]

In summary,

\[\mathbb{E}[\overline{A}_{S_{1}}\overline{B}_{S_{2}}\overline{A}_{T_ {1}}\overline{B}_{T_{2}}\boldsymbol{1}_{\mathcal{H}}] \leq(1+o(1))n^{-D_{+}(a,b,s,\varepsilon)\frac{\varepsilon}{B}}(sp \wedge sq)^{v+k+1-2N}\rho^{e(K_{11})}\] \[\quad\times\sigma_{\text{eff}}^{4N}\gamma_{2}^{e(K_{12})+e(K_{21 })+e(K_{22})}2^{k+1}.\] (74)After plugging the upper bound on cross-moments to the ratio, it remains to bound the number of different union graph structures and their corresponding weights. In parallel to \(\mathcal{W}_{ij}\), we define \(\mathcal{S}_{ij}\) as the collection of decorated union graphs that have at least one \(1\)-decorated edge. \(\mathcal{S}_{ij}(v,k)\) denotes those with \(v+1+\mathbf{1}_{j\neq\pi,i}\) vertices and excess \(k\).

\[\frac{V_{12}}{\mathbb{E}[\Phi_{i\pi,(i}\mathbf{1}_{\mathcal{H}}]^{ 2}}\] \[\leq\frac{\sum_{v+k+1=0}^{4N}\sum_{\hat{U}\in\mathcal{S}_{ij}(v,k) }\mathrm{aut}(H)\mathrm{aut}(I)\rho^{e(K_{11})}(sp\wedge sq)^{v+k+1-2N}\gamma_{ 2}^{e(K_{12})+e(K_{21})+e(K_{22})}2k^{+1}}{(1+o(1))n^{2N}\rho^{2N}|\mathcal{T}| ^{2}n^{zD_{+}(a,b,s,\varepsilon)/D}}\]

We define the \((\dot{U}_{L},\dot{U}_{M},\dot{U}_{N})\) partition of decorated union graph as (44) in Section I. We define \(\mathcal{U}_{L}(v_{L},z,\ell)\) as the collection of \(\dot{U}_{L}\) that has \(v_{L}\) vertices, \(\ell\) edges belonging to set \(e(K_{11})\), and no more than \(z\)\(1\)-decorated edges. We define \(\mathcal{U}_{M}(v_{M})\) as the collection of \(\dot{U}_{M}\) that has \(v_{M}\) vertices. We define \(\mathcal{U}_{N}(v_{N},k)\) as the collection of \(\dot{U}_{N}\) that has \(v_{N}\) vertices and excess \(k\). We also keep the notation of \(\widetilde{\mathcal{U}}\) as the corresponding unlabeled decorated union graph sets. In addition,

\[P_{L}(v_{L},z,\ell) :=\sum_{\dot{U}_{L}\in\mathcal{U}_{L}(v_{L},z,\ell)}w(\dot{U}_{L}),\] (75) \[P_{M}(v_{M}) :=\sum_{\dot{U}_{L}\in\mathcal{U}_{L}(v_{M})}w(\dot{U}_{M}),\] (76) \[P_{N}(v_{N},k) :=\sum_{\dot{U}_{L}\in\mathcal{U}_{L}(v_{N},k)}w(\dot{U}_{N}).\] (77)

From the above partition,

\[\frac{V_{12}}{\mathbb{E}[\Phi_{i\pi,(i)}\mathbf{1}_{\mathcal{H}} ]^{2}}\] \[\leq\frac{\sum_{v=N}^{4N}\sum_{k+1=0}^{4N-v}(sp\wedge sq)^{v+k+1-2 N}2^{k+1}\sum_{z}\sum_{v_{L},v_{M},v_{N}}\sum_{\ell}\rho^{\ell}P_{L}(v_{L},z, \ell)P_{M}(v_{M})P_{L}(v_{N},k)}{(1+o(1))n^{2N}\rho^{2N}|\mathcal{T}|^{2}n^{zD_ {+}(a,b,s,\varepsilon)}/\gamma_{2}^{2(v+k+2)-4N}}.\]

We show upper bounds for \(P_{L}(v_{L},z,\ell)\) in Lemma 25, which is

\[\sum_{\ell=0}^{2N}\rho^{\ell}P_{L}(v_{L},z,\ell)\leq(4N)^{2z+1}n^{v_{L}}L(4LM) ^{6L}|\mathcal{T}|^{2}\rho^{2N}\rho^{-\frac{z}{2}}.\]

The upper bounds for \(P_{M}\) and \(P_{N}\) trivially follows from Lemma 19 and Lemma 20, with a replacement of \(11\) to \(15\) as the possible decorations of each vertex increase by \(4\) for \(1\)-decoration and a different maximum value of \(e_{M}\), parameterized by \(v,k,z\).

\[P_{M}(v_{M}) \leq R^{\frac{2\varepsilon_{M}}{M}}n^{v_{M}}(15\beta)^{(K+M)\frac {2\varepsilon_{M}}{M}}\mathbf{1}_{\{e_{M}\leq 2N-(v+k+2)+z/2\}}\] \[P_{N}(v_{N},k) \leq n^{v_{N}}(15\beta)^{v_{N}}(15R^{4}(v_{N}+1)^{2})^{k+1} \mathbf{1}_{\{v_{N}\leq 2(K+M)(2k+2)\}}.\]

Putting all the pieces together, we have

\[\frac{V_{12}}{\mathbb{E}[\Phi_{i\pi_{*}(i)}\mathbf{1}_{\mathcal{H} }]^{2}} \leq\sum_{k\geq-1}\left(\frac{30R^{4}(2N+1)^{2}(15\beta)^{4(K+M)}}{n} \right)^{k+1}\] \[\quad\times\sum_{v=N}^{4N-k-1}\left(\frac{R^{\frac{2}{M}}(15 \beta)^{2\frac{K+M}{M}}}{ns(p\wedge q)}\gamma_{2}^{2}\right)^{2N-v-k-1}\] \[\quad\times\sum_{z=1\vee(2(v+k+1)-4N)}^{4N}\left(\frac{(4N)^{2}R^ {\frac{1}{M}}(15\beta)^{\frac{K+M}{M}}}{\sqrt{\rho}n^{\frac{D_{+}(a,b,s, \varepsilon)}{D}}}\right)^{z}\times 2NL(4LM)^{6L}.\]From condition (24), \(2NL(4LM)^{6L}\leq\log^{3}n\). Also, since with (24) and \(\gamma_{2}<2\),

\[\frac{R^{\frac{2}{M}}(15\beta)^{2}\frac{K+M}{N}}{ns(p\wedge q)}\gamma_{2}^{2} \leq\frac{1}{2},\quad\frac{15R^{4}(2N+1)^{2}(15\beta)^{4(K+M)}}{n}\leq\frac{1}{ 2}.\]

For \(v\leq 2N-k-1\), we have

\[\sum_{v=N}^{2N-k-1}\left(\frac{R^{\frac{2}{M}}(15\beta)^{2}\frac{K+M}{N}}{ns(p \wedge q)}\gamma_{2}^{2}\right)^{2N-v-k-1}\leq 2.\]

For the first summation, we always have

\[\sum_{k\geq-1}\left(\frac{30R^{4}(2N+1)^{2}(15\beta)^{4(K+M)}}{n}\right)^{k+1} \leq 2.\]

For the last summation with those additional terms, from condition (24), we have

\[\sum_{z=1}^{4N}\left(\frac{(4N)^{2}R^{\frac{1}{M}}(15\beta)^{\frac{K+M}{M}}}{ \sqrt{\rho n^{\frac{D+(a,b,s,\varepsilon)}{D}}}}\right)^{z}\times 2NL(4 LM)^{6L}=o(n^{-\varepsilon^{\prime}}),\]

for some \(\varepsilon^{\prime}>0\) because \(n^{D_{+}(a,b,s,\varepsilon)/D}\) is the only term being polynomial.

If \(v>2N-k-1\), then we know that \(z>2(v+k+1-2N)\). The summation over \(v\) and \(z\) together is upper bounded by

\[\sum_{v=2N-k}^{4N-k-1}\left(\frac{R^{\frac{2}{M}}(15\beta)^{2}\frac{K+M}{M}}{ ns(p\wedge q)}\gamma_{2}^{2}\times\frac{(4N)^{2}R^{\frac{1}{M}}(15\beta)^{\frac{K+M}{M}}}{ \sqrt{\rho}n^{\frac{D+(a,b,s,\varepsilon)}{D}}}\right)^{v+k+1-2N}2NL(4LM)^{6L} =o(n^{-\varepsilon^{\prime}}),\]

because, again \(n^{D_{+}(a,b,s,\varepsilon)/D}\) is the only term being polynomial.

In summary, we have \(\frac{V_{12}}{[\mathds{C}_{i\pi\pi\epsilon(i)}\mathds{1}_{k}]^{2}}=o(n^{- \varepsilon^{\prime}})\) for some \(\varepsilon^{\prime}>0\), which completes the proof. 

### Proof of auxiliary Lemmas

**Lemma 25**.: _For true pairs,_

\[\sum_{\ell=0}^{2N}\rho^{\ell}P_{L}(v_{L},z,\ell)\leq(4N)^{2z+1}n^{v_{L}}L(4 LM)^{6L}|\mathcal{T}|^{2}\rho^{2N}\rho^{-\frac{z}{2}}.\]

Proof.: We define the unlabeled union graph sets corresponding to \(\mathcal{U}(v_{L},z,\ell)\) as \(\widetilde{\mathcal{U}}(v_{L},z,\ell)\). From definition (60),

From the definition (75) and Claim 1,

\[\sum_{\ell=0}^{2N}\rho^{\ell}P_{L}(v_{L},z,\ell)\leq\sum_{\ell=0}^{2N}\rho^{ \ell}\sum_{\hat{U}_{L}\in\widetilde{\mathcal{U}}_{L}(v_{L},z,\ell)}\frac{n^{v _{L}}w(\hat{U}_{L})}{\mathrm{aut}(\hat{U}_{L})}\leq\sum_{\ell=0}^{2N}n^{v_{L}} \rho^{\ell}|\widetilde{\mathcal{U}}_{L}(v_{L},z,\ell)|(2K)^{z}.\] (78)

Recall that \(e_{L}=\frac{1}{2}(e(K_{12}\cup K_{22}\cap\hat{U}_{L})+e(K_{21}\cup K_{22}\cap \hat{U}_{L}))\). The total number of edges on \(S_{1},T_{1},S_{2}\) and \(T_{2}\) involved in \(\hat{U}_{L}\) is \((2(v_{L}+e_{L})-z)\) and thus the total number of bulbs on \(S_{1},T_{1},S_{2}\) and \(T_{2}\) involved in \(\hat{U}_{L}\) is \(b:=\frac{2(v_{L}+e_{L})-z}{K+M}<4L\). Those \(b\) bulbs can be partly or fully overlapped (namely, _tangled_) with another stay on their own. From the definition of \(\hat{U}_{L}\) (44), it is impossible to have three or more bulbs tangling with each other. If two bulbs are tangling with each other, we put them into a pair. If a bunch of bulbs are all not tangling with any other bulbs, we pair them up arbitrarily. We denote \(t_{1}\) as the number of pairs of bulbs that have decorations being a subset of \(\{S_{1},S_{2}\}\) or \(\{T_{1},T_{2}\}\). For all \(2\)-decorated edges among these pairs, they are in \(K_{11}\). Since \(\hat{U}_{L}\) has at most \(z\)\(1\)-decorated edges, we have

\[\ell\geq t_{1}K-z/2.\] (79)Next, we introduce three types of bulbs. The first type is called _effective non-isomorphic_ bulbs, which is a selection of bulbs that are not isomorphic to each other and always pair with a bulb that are not of the same type. The selection is not unique and we take the largest possible set of bulbs satisfying those rules as the set of effective non-isomorphic bulbs. Fixed the effective bulb set, for bulbs that are isomorphic to those effective non-isomorphic bulbs, we name them as _shadow effective bulbs_. For the remaining bulbs, we name them as _non-effective bulbs_. We have the following Claim 2:

\[\frac{t_{1}}{2}\leq a\leq L+\frac{t_{1}}{2}.\] (80)

From definition, there is at most one non-effective bulb and at most one effective non-isomorphic bulb in each pair of bulbs, while two shadow bulbs can pair up.

We call those effective non-isomorphic bulbs as effective because when enumerating through the chandelier structures, we let them having the priority of taking any possible structure from \(\mathcal{J}\) and serving the base of that pair. Shadow effective bulbs are named so because they mirror the structure of effective non-isomorphic bulbs and thus will not increase the union graph richness too much. For non-effective bulbs, we let them take any possible structures with the constrain that there are at most \(z\)\(1\)-decorated edges in \(\dot{U}_{L}\).

We denote the number of effective non-isomorphic bulbs as \(a\). For all pairs, we upper bound the number of different non-isomorphic tangled bulbs as following combinatorial factor

\[\binom{|\mathcal{J}|}{a}\binom{b}{a}\binom{2N}{z/2}(4N)^{\frac{z}{2}},\]

where \(\binom{|\mathcal{J}|}{a}\) comes from the structure of \(a\) effective non-isomorphic bulbs, \(\binom{b}{a}\) is the upper bound of choosing \(a\) effective non-isomorphic bulbs from \(b\) bulbs, \(\binom{2N}{z/2}\) is the upper bound on the selection of which edges on effective non-isomorphic bulbs and shadow effective bulbs are overlapped as there are at most \(2K\) (\(<2N\)) \(2\)-decorated edges on bulbs if all bulbs are perfectly overlapping with one another, and \((4N)^{\frac{z}{2}}\) bounds the placement of those remaining \(1\)-decorated edges from the non-effective bulbs as each of them has at most \(4N\) possible vertices to attach to on the union graph.

Since wires cannot tangle with bulbs (otherwise, it is not a tree), we bound the possible structures separately. There can be at most \(4\) wires tangling with each other, from top to bottom. We apply a very loose bound even without using this fact, which is \((b-1)!M^{b-1}\). This is because there are at most \(b\) wires and we determine the structure of wires on the union graph one by one. When the \(t\)-th wire comes in, it can determine which of the \(t-1\) wires to tangle with and the length of overlap, from \(0\) to \(M\).

Putting together (79) and (80) with the combinatorial observations, we have

\[\rho^{\ell}|\widetilde{\mathcal{U}}_{L}(v_{L},z,\ell)| \leq\sum_{a=0}^{2L}\sum_{b=2a}^{4L}\sum_{t_{1}=0}^{a}\rho^{t_{1} K-\frac{z}{2}}\mathbf{1}_{\{a\leq L+\frac{t_{1}}{2}\}}|\mathcal{J}|^{a} \binom{b}{a}(2N)^{3z/2}(b-1)!M\] \[\leq|\mathcal{T}|(4N)^{z}\rho^{-\frac{z}{2}}\sum_{t_{1}=0}^{2L}(| \mathcal{J}|^{\frac{t_{1}}{2}}\rho^{t_{1}K})\sum_{a=0}^{2L}\sum_{b=2a}^{4L} \binom{b}{a}(b-1)!M^{b-1}\] \[\leq(4LM)^{6L}|\mathcal{T}|(4N)^{z}\rho^{-\frac{z}{2}}\sum_{t_{1} =0}^{2L}(|\mathcal{J}|\rho^{2K})^{\frac{t_{1}}{2}}\] \[\leq L(4LM)^{6L}|\mathcal{T}|^{2}\rho^{2N}(4N)^{z}\rho^{-\frac{z} {2}}.\] (81)

In the second inequality, we loose the upper bound of \(t_{1}\) from \(a\) to \(2L\) and change the order of summation. In the third inequality, we bound the summation over \(a\) and \(b\). Lastly, \(\sum_{t_{1}=0}^{2L}(|\mathcal{J}|\rho^{2K})^{\frac{t_{1}}{2}}\leq L(|\mathcal{ J}|\rho^{2K})^{L}=L|\mathcal{T}|\rho^{2N}\).

Plugging (81) back to (78), after a summation over \(\ell\), we complete the proof. 

**Claim 1**.: _Assume that \(j=\pi_{*}(i)\). For any arbitrary \(\dot{U}_{L}\in\mathcal{U}_{L}(v_{L},z,\ell)\), we have_

\[w(\dot{U}_{L})\leq\operatorname{aut}(\dot{U}_{L})(2K)^{z}.\]Proof.: Denote all bulbs contained in \(\dot{U}_{L}\) as \(\mathcal{B}_{1},\mathcal{B}_{2},\ldots,\mathcal{B}_{w}\). (1) Some of them can be fully overlapped to form a \(2\)-decorated bulbs in the union graph. (2) Some of them can be partly overlapped. (3) And the remaining of them are fully \(1\)-decorated. There cannot be three or more bulbs overlapping with each other thanks to the definition of \(\dot{U}_{L}\) (65).

Each bulb \(\mathcal{B}_{i}\) contributes to the \(w(\dot{U}_{L})\) by \(\mathrm{aut}(\mathcal{B}_{i})\) independently from definition (66) and (50). For any vertex on the bulbs, it will not be at the same orbit as any vertex on the wire, so studying the automorphism of the overlapped bulbs gives a lower bound on the automorphism of the whole decorated graph. Since each bulb occurs in at most one overlapped bulb, to prove the claim, it suffices to examine the relationship between weights and automorphism for each of the three cases aforementioned.

For \(i,j\in[w]\), if bulbs \(\mathcal{B}_{i}\) is partly overlapping with \(\mathcal{B}_{j}\). From Corollary 2, \(\sqrt{\mathrm{aut}(\mathcal{B}_{i})\mathrm{aut}(\mathcal{B}_{j})}\leq\mathrm{ aut}(\mathcal{B}_{i}\cup\mathcal{B}_{j})(2K)^{|E(\mathcal{B}_{i})\triangle E( \mathcal{B}_{j})|}\). If \(\mathcal{B}_{i}\) is fully overlapping with \(\mathcal{B}_{j}\), then \(\sqrt{\mathrm{aut}(\mathcal{B}_{i})\mathrm{aut}(\mathcal{B}_{j})}=\mathrm{ aut}(\mathcal{B}_{i}\cup\mathcal{B}_{j})\). If \(\mathcal{B}_{i}\) is fully \(1\)-decorated, then \(\sqrt{\mathrm{aut}(\mathcal{B}_{i})}\leq\mathrm{aut}(\mathcal{B}_{i})\).

Denote \(I_{1}\) and \(I_{2}\) as the collections of index pairs that the corresponding bulbs fall in case (1) or (2). Denote \(I_{3}\) as the collection of indices corresponding to the bulbs falling in case (3). Therefore,

\[w(\dot{U}_{L}) \leq\prod_{(i,j)\in I_{1}}\mathrm{aut}(\mathcal{B}_{i}\cup \mathcal{B}_{j})(2K)^{|E(\mathcal{B}_{i})\triangle E(\mathcal{B}_{j})|}\prod_{ (i,j)\in I_{2}}\mathrm{aut}(\mathcal{B}_{i}\cup\mathcal{B}_{j})\prod_{i\in I_{ 3}}\mathrm{aut}(\mathcal{B}_{i})\] \[\leq\mathrm{aut}(\dot{U}_{L})(2K)^{\sum_{(i,j)\in I}|E(\mathcal{B }_{i})\triangle E(\mathcal{B}_{j})|}.\] (82)

The union graph has at least \(2\times\sum_{(i,j)\in I}|E(\mathcal{B}_{i})\triangle E(\mathcal{B}_{j})|\)\(1\)-decorated edges and we know that \(\dot{U}_{L}\) has at most \(z\)\(1\)-decorated edges. Therefore, \(\sum_{(i,j)\in I}|E(\mathcal{B}_{i})\triangle E(\mathcal{B}_{j})|\leq z\). Substituting this into (82) completes the proof. 

**Claim 2**.: _Let \(a\) be the number of effective non-isomorphic bulbs and \(t_{1}\) be the number of pairs of tangled bulbs that are decorated by a subset of either \(\{S_{1},S_{2}\}\) or \(\{T_{1},T_{2}\}\). We have_

\[\frac{t_{1}}{2}\leq a\leq L+\frac{t_{1}}{2}.\] (83)

Proof.: For an arbitrary bulb, it occurs at most one time in \(S_{1},S_{2},T_{1},T_{2}\) each and they are paired up into two sets, \(a\geq\frac{t_{1}}{2}\). Assume that there are \(t^{\prime}\) non-isomorphic bulbs among the \(t_{1}\) pairs, they can all be assigned as effective non-isomorphic bulbs. Then, without loss of generality, \(S_{1},S_{2}\) have at most \(L-\frac{t^{\prime}}{2}\) bulbs unspecified. By assumption, they cannot pair up with each other, so every one bulb from \(S_{1},S_{2}\) remaining will pair up with another bulb from \(T_{1},T_{2}\). Therefore, the remaining bulbs have at most \(L-\frac{t^{\prime}}{2}\) effective non-isomorphic bulbs.

Together, we have \(a\leq t^{\prime}+(L-\frac{t^{\prime}}{2})\leq L+\frac{t_{1}}{2}\), as \(t^{\prime}\leq t_{1}\). 

## Appendix M Proof of Proposition 6

### Proof of the Proposition

Proof of Proposition 6.: Recall that \(S_{1}\) and \(T_{1}\) are rooted on \(i\), \(S_{2}\) and \(T_{2}\) are rooted on \(j\). The minimum value of \(k\) is \(-2\) when the union graph consists of two disconnected trees, \(S_{1}\cup T_{1}\) and \(S_{2}\cup T_{2}\). We use the same notation for different parts of the variance as in Section L.

\[\mathrm{Var}[\Phi_{ij}^{\widehat{\bm{\sigma}}_{A}}\bm{1}_{\mathcal{H}}] =\sum_{H,I\in\mathcal{T}}\mathrm{aut}(H)\mathrm{aut}(I)\sum_{S_{1}( i),S_{2}(i)\otimes H,T_{1}(j),T_{2}(j)\otimes I}\mathrm{Cov}(\overline{A}_{S_{1}}^{ \widehat{\bm{\sigma}}_{A}}\overline{B}_{S_{2}}^{\widehat{\bm{\sigma}}_{B}}\bm{ 1}_{\mathcal{H}},\overline{A}_{T_{1}}^{\widehat{\bm{\sigma}}_{A}}\overline{B }_{T_{2}}^{\widehat{\bm{\sigma}}_{B}}\bm{1}_{\mathcal{H}})\] \[=\underbrace{\sum_{U\in\mathcal{W}_{ij}}(\mathrm{aut}(S_{1}) \mathrm{aut}(S_{2})\mathrm{aut}(T_{1})\mathrm{aut}(T_{2}))^{\frac{1}{2}} \mathbb{E}[\overline{A}_{S_{1}}^{\widehat{\bm{\sigma}}_{A}}\overline{B}_{S_{2} }^{\widehat{\bm{\sigma}}_{B}}\overline{A}_{T_{1}}^{\widehat{\bm{\sigma}}_{A} }\overline{B}_{T_{2}}^{\widehat{\bm{\sigma}}_{B}}\bm{1}_{\mathcal{H}}]}_{V_{ 11}}\] \[+\underbrace{\sum_{U\notin\mathcal{W}_{ij}}(\mathrm{aut}(S_{1}) \mathrm{aut}(S_{2})\mathrm{aut}(T_{1})\mathrm{aut}(T_{2}))^{\frac{1}{2}} \mathbb{E}[\overline{A}_{S_{1}}^{\widehat{\bm{\sigma}}_{A}}\overline{B}_{S_{2 }}^{\widehat{\bm{\sigma}}_{B}}\overline{A}_{T_{1}}^{\widehat{\bm{\sigma}}_{A} }\overline{B}_{T_{2}}^{\widehat{\bm{\sigma}}_{B}}\bm{1}_{\mathcal{H}}]}_{V_{ 12}}-\] \[\underbrace{\sum_{H,I\in\mathcal{T}}\mathrm{aut}(H)\mathrm{aut}(I) \sum_{S_{1},S_{2}\cong H,T_{1},T_{2}\cong I}\mathbb{E}[\overline{A}_{S_{1}}^{ \widehat{\bm{\sigma}}_{A}}\overline{B}_{S_{2}}^{\widehat{\bm{\sigma}}_{B}}\bm {1}_{\mathcal{H}}]\mathbb{E}[\overline{A}_{T_{1}}^{\widehat{\bm{\sigma}}_{A}} \overline{B}_{T_{2}}^{\widehat{\bm{\sigma}}_{B}}\bm{1}_{\mathcal{H}}]}_{V_{ 2}}.\] (84)

Since \(V_{2}\geq 0\), it suffices to bound the first two summations. The same argument in Section L to bound the \(V_{11}\) for true pairs works for this case with an additional fluctuation coming from using Lemma 14 to bound the cross moments rather than Lemma 13. We have

\[V_{11}/\mu^{2}\leq(1+\Theta(\frac{\log n}{n}))^{4N}\frac{\mathrm{Var}[\Phi_{ ij}^{\widehat{\bm{\sigma}}_{A}}\bm{1}_{\mathcal{H}}]}{\mu^{2}}|_{sD_{+}(a,b)>1}=O( \frac{1}{|\mathcal{T}|\rho^{2N}})\]

under conditions (23). The additional fluctuation comes from the cross moment bounds.

Lemma 26 shows that \(V_{12}/\mu^{2}=o(\frac{1}{|\mathcal{T}|\rho^{2N}})\). In summary, we have \(\frac{\mathrm{Var}[\Phi_{ij}^{\widehat{\bm{\sigma}}_{A}}\bm{1}_{\mathcal{H}}]} {\mathbb{E}[\Phi_{i\pi_{(}i)\bm{1}_{\mathcal{H}}}]}=O(\frac{1}{|\mathcal{T}| \rho^{2N}})\). 

**Lemma 26**.: _Under the same conditions as Proposition 6,_

\[\frac{V_{12}}{\mu^{2}}=o(\frac{1}{|\mathcal{T}|\rho^{2N}}).\]

Proof.: First, we apply the upper bound on \(\mathbb{E}[\overline{A}_{S_{1}}^{\widehat{\bm{\sigma}}_{A}}\overline{B}_{S_{2} }^{\widehat{\bm{\sigma}}_{B}}\overline{A}_{T_{1}}^{\widehat{\bm{\sigma}}_{A} }\overline{B}_{T_{2}}^{\widehat{\bm{\sigma}}_{B}}\bm{1}_{\mathcal{H}}]\) as derived in (74), with replacing \(k+1\) to \(k+2\) everywhere as from definition \(v\) is the number of vertices except for \(i\) and \(j\). When \(j\neq\pi_{*}(i)\), the minimum value of \(j\) starts from \(-2\) when the union graph consists of two disjoint trees.

\[\mathbb{E}[\overline{A}_{S_{1}}^{\widehat{\bm{\sigma}}_{A}}\overline {B}_{S_{2}}^{\widehat{\bm{\sigma}}_{B}}\overline{A}_{T_{1}}^{\widehat{\bm{ \sigma}}_{A}}\overline{B}_{T_{2}}^{\widehat{\bm{\sigma}}_{B}}\bm{1}_{\mathcal{H}}] \leq(1+o(1))n^{-D_{+}(a,b,s,e)\frac{k}{D}}(sp\wedge sq)^{v+k+2-2N} \rho^{e(K_{11})}\] \[\times\sigma_{\mathrm{eff}}^{4N}\gamma_{2}^{e(K_{12})+e(K_{21}) +e(K_{22})}2^{k+2}.\] (85)

After plugging the upper bound on cross-moments to the ratio, it remains to bound the number of different union graph structures and their corresponding weights.

\[\frac{V_{12}}{\mathbb{E}[\Phi_{i\pi_{*}(i)}\bm{1}_{\mathcal{H}}]^ {2}}\] \[\leq\frac{\sum_{v+k+2=0}^{4N}\sum_{\dot{U}\in\mathcal{S}_{i_{j}}(v,k)}\mathrm{aut}(H)\mathrm{aut}(I)\rho^{e(K_{11})}(sp\wedge sq)^{v+k+2-2N} \gamma_{2}^{e(K_{12})+e(K_{21})+e(K_{22})}2^{k+2}}{(1+o(1))n^{2N}\rho^{2N}| \mathcal{T}|^{2}n^{E_{+}D_{+}(a,b,s,e)/D}}.\]

(a) Case \(k=-2\).We first consider the special case when \(k=-2\). When \(k=-2\), there are two disjoint trees in the decorated union graph and all edges are decorated by a subset of either \(\{S_{1},T_{1}\}\) or \(\{S_{2},T_{2}\}\). Then, \(e(K_{11})=e(K_{12})=e(K_{21})=e(K_{22})=0\). Also \(v\geq 2N\),

\[V_{12}=\sigma_{\mathrm{eff}}^{4N}\sum_{\dot{U}\in\mathcal{S}_{i_{j}}(v\geq 2N)} \mathrm{aut}(H)\mathrm{aut}(I)n^{-\frac{sD_{+}(a,b,s,e)}{D}}\leq 2\sigma_{\mathrm{ eff}}^{4N}F_{ij},\]

where

\[F_{ij}:=\sum_{H\in\mathcal{T}}\sum_{I\in\mathcal{T}:\mathrm{aut}(I)\leq \mathrm{aut}(H)}\mathrm{aut}(H)^{2}\sum_{\dot{U}\in\mathcal{S}_{ij}(v\geq 2N,H,I)}n^{- \frac{sD_{+}(a,b,s,e)}{D}},\]and \(\mathcal{S}_{ij}(v\geq 2N,H,I)\) is the collection of decorated union graphs that have at least \(2N+2\) vertices, excess \(-2\), at least \(1\) edge \(1\)-decorated, and that \(S_{1},S_{2}\cong H,T_{1},T_{2}\cong I\).

For a specific decorated graph \(\dot{U}\), we denote \(t_{1}\) (resp. \(t_{2}\)) as the number of different edges vetween \(S_{1}\) and \(T_{2}\) (resp. \(S_{2}\) and \(T_{2}\)). There are \(z=2(t_{1}+t_{2})\)\(1\)-decorated edges and the remaining edges are in set \(K_{02}\) or \(K_{20}\). We write out \(F_{ij}\) under the summation over \(t_{1}\) and \(t_{2}\).

\[F_{ij} =\sum_{H\in\mathcal{T}}\sum_{S_{1},S_{2}\cong H}\sum_{\exists I \in\mathcal{T},\mathrm{aut}(H)>\mathrm{aut}(I),T_{1},T_{2}\cong I}\sum_{t_{1} =0}^{N}\sum_{t_{2}=0}^{N}n^{-\frac{zD_{+}(a,b,s,s)}{D}}\mathbf{1}_{\{t_{1}+t_{2 }\geq 1\}}\] \[=\sum_{t_{1}+t_{2}\geq 1}\sum_{H\in\mathcal{T}}|\mathcal{S}(v\geq 2 N,H,t_{1},t_{2})|n^{-\frac{zD_{+}(a,b,s,s)}{D}},\]

where \(\mathcal{S}(v\geq 2N,H,t_{1},t_{2})\) collects all the possible decorated union graph that have \(S_{1},S_{2}\cong H\), \(T_{1},T_{2}\cong I\) for some \(I\in\mathcal{T}\) such that \(\mathrm{aut}(I)<\mathrm{aut}(H)\), and \(S_{1}\) (resp. \(S_{2}\)) differ in \(t_{1}\) (resp. \(t_{2}\)) edges with \(T_{1}\) (resp. \(T_{2}\)).

Next, we bound \(|\mathcal{S}(v\geq 2N,H,t_{1},t_{2})|\) by the following way: First, enumerate through all \(S_{1},S_{2}\cong H\) on the complete graph with all possible structure, this gives \(\frac{n^{2N}}{\mathrm{aut}(H)^{2}}\). Then, we choose which edges that are overlapped with \(T_{1}\) on \(S_{1}\) (resp. overlapped with \(T_{2}\) on \(S_{2}\)). This is at most \(\binom{N}{t_{1}}\binom{N}{t_{2}}\leq N^{t_{1}+t_{2}}\). After this, we draw \(t_{1}+t_{2}\) new vertices for \(T_{1}\) and \(T_{2}\) and allow them arbitrarily connecting edges among those \(N\) vertices on its chandelier, which is upper bounded by \(\binom{N}{2}^{t_{1}+t_{2}}\) (ignoring the constraint that \(T_{1}\cong T_{2}\cong I\) for some chandelier \(I\) having less automorphism number than \(H\)). Altogether,

\[|\mathcal{S}_{ij}(v\geq 2N,H,I)|\leq\frac{n^{2N}}{\mathrm{aut}(H)^{2}} \left(\frac{N^{3}}{n^{2D_{+}(a,b,s,c)/D}}\right)^{t_{1}+t_{2}}.\]

Therefore,

\[F_{ij}=n^{2N}|\mathcal{T}|\sum_{t_{1}+t_{2}\geq 1}\left(\frac{N^{3}}{n^{2D_{ +}(a,b,s,c)/D}}\right)^{t_{1}+t_{2}}.\]

As assumed in Proposition 6, \(N=\Theta(\log n)\) and \(D=o(\frac{\log n}{\log\log n})\). Therefore,

\[V_{12}/\mu^{2}=o(\frac{1}{|\mathcal{T}|\rho^{2N}}).\]

(b) Case \(k>-2\).In general, we define \(\dot{U}_{L},\dot{U}_{M}\), and \(\dot{U}_{N}\) partition the same as (64) and (65). We also define the weights of each part the same as (66), (67), and (68). We define \(P_{L}(v_{L},z)=\sum_{\dot{U}\in\mathcal{U}_{L}(v_{L},z)}w(\dot{U})\). The definition of \(P_{M}(v_{M})\) and \(P_{N}(v_{N},k)\) follow. All union graph class should not have more than \(z\)\(1\)-decorated edges, but specifically we only need this constraint for \(\dot{U}_{L}\).

Note that \(e(K_{12})+e(K_{21})+e(K_{22})\leq 4N-2(v+k+1)+z\),

\[V_{12}|_{k>-2} \leq\sigma_{\mathrm{eff}}^{4N}\sum_{v=N}^{4N}\sum_{k+2=1}^{4N-v} \sum_{z=1}^{4N}\gamma_{2}^{4N-2(v+k+2)}2^{k+2}(sp\wedge sq)^{v-2N+k+2}\] \[\quad\times\sum_{v_{L},v_{M},v_{N}}P_{L}(v_{L},z)P_{M}(v_{M})P_{L }(v_{N},k)\left(\frac{\gamma_{2}}{n^{D_{+}(a,b,s,c)/D}}\right)^{z}.\]

We show the upper bound for \(\dot{U}_{L}\) part in Lemma 27. The upper bound for \(P_{M}\) and \(P_{N}\) trivially follows from Lemma 22 and Lemma 23 as they do not use any assumption on edges are all at least \(2\)-decorated, except for the number \(11\), the possible ways of decoration. So, we change \(11\) to \(15\) and then every thing follows. When \(z\neq 0\), \(e_{M}\) as defined before in an arbitrary \(\dot{U}_{M}\) has maximum value \(2N-(v+k+2)-z/2\) (same holds for \(e_{N},e_{L}\) but we do not need to use them in our bound). Insummary,

\[P_{L}(v_{L},z) \leq n^{v_{L}}|\mathcal{T}|\beta^{4K}(4LM)^{4L}(4L)!(2\beta)^{4(K+M)} \left((4N)^{2}\beta^{\frac{K}{K+M}}\right)^{z}\] \[P_{M}(v_{M}) \leq R^{\frac{2\varepsilon M}{M}}n^{v_{M}}(15\beta)^{(K+M)\frac{2 \varepsilon M}{M}}\mathbf{1}_{[\varepsilon_{M}\leq 2N-(v+k+2)+z/2)}\] \[\leq n^{v_{M}}\left(R^{\frac{2}{M}}(15\beta)^{\frac{2(K+M)}{M}} \right)^{2N-v-k-2}\left(R^{\frac{1}{M}}(15\beta)^{\frac{K+M}{M}}\right)^{z}\] \[P_{N}(v_{N},k) \leq n^{v_{N}}\beta(15\beta)^{(K+M)2(k+2)}(15R^{4}(v_{N}+2)^{2})^{ k+2}\] \[\leq n^{v_{N}}\beta\left((15\beta)^{2(K+M)}15R^{4}(4N+1)^{2} \right)^{k+2}.\]

The last inequality holds because \(v_{N}\leq v\leq 4N-(k+2)\) and \(k\geq-1\).

Putting every pieces together,

\[\frac{V_{12}|_{k>-2}}{\mu^{2}} \leq\sum_{k\geq-1}\left(\frac{(15\beta)^{2(K+M)}30R^{4}(4n+1)^{2} }{n}\right)^{k+2}\sum_{v=N}^{4N-k-2}\left(\frac{\gamma_{2}^{2}(15\beta)^{2\frac {K+M}{M}}R^{\frac{2}{M}}}{ns(p\wedge q)}\right)^{2N-v-k-2}\] \[\quad\times\sum_{z=1\lor(2N-v-k-2)}^{4N}\left(\frac{\gamma_{2}(4N) ^{2}R^{\frac{1}{M}}(15\beta)^{\frac{K+M}{M}}\beta^{\frac{K}{K+M}}}{n^{\frac{D _{+}(a,b,s,r)}{D}}}\right)^{z}\] \[\quad\times\frac{\beta^{4K+1}(2\beta)^{4(K+M)}(4LM)^{4L}(4L)!}{| \mathcal{T}|\rho^{2N}}.\]

From the second condition in (25), we first look at the summation of \(v\) from \(N\) to \(2N-k-2\),

\[\sum_{z=1}^{4N}\left(\frac{\gamma_{2}(4N)^{2}R^{\frac{1}{M}}(15\beta)^{\frac{ K+M}{M}}\beta^{\frac{K}{K+M}}}{n^{\frac{D_{+}(a,b,s,r)}{D}}}\right)^{z}=o(1).\]

From the first condition in (25),

\[\sum_{v=N}^{2N-k-2}\left(\frac{\gamma_{2}^{2}(15\beta)^{2\frac{K+M}{M}}R^{ \frac{2}{M}}}{ns(p\wedge q)}\right)^{2N-v-k-2}\leq 2.\]

When \(v>2N-k-2\), the power \(2N-v-k-2<0\). Observe that \(z\geq 2(v+k+2)-4N=z-e(K_{12})-e(K_{21})-2e(K_{22})\), we have the product of two summations upper bounded by

\[\sum_{v=2N-k-1}^{4N-k-2}\left(\frac{ns(p\wedge q)}{\gamma_{2}^{2}(15\beta)^{2 \frac{K+M}{M}}R^{\frac{2}{M}}}\times\frac{\gamma_{2}(4N)^{2}R^{\frac{1}{M}}(1 5\beta)^{\frac{K+M}{M}}\beta^{\frac{K}{K+M}}}{n^{\frac{D_{+}(a,b,s,s)}{D}}} \right)^{v+k+2-2N}.\]

This is clearly \(o(1)\) because \(N=\Theta(\log n)\) and from the first and second condition (25), \(n^{D_{+}(a,b,s,e)/D}\) is the only term being \(\log^{\omega(1)}n\).

From the third condition in (25),

\[\sum_{k\geq-1}\left(\frac{(15\beta)^{2(K+M)}30R^{4}(4n+1)^{2}}{n} \right)^{k+2}\beta^{4K+1}(2\beta)^{4(K+M)}(4LM)^{4L}(4L)!\\ \leq 2\left(\frac{(15\beta)^{2(K+M)}30R^{4}(4n+1)^{2}}{n}\right) \beta^{4K+1}(2\beta)^{4(K+M)}(4LM)^{4L}(4L)!\leq 1.\]

Therefore, \(V_{12}/\mu^{2}=o(\frac{1}{|\mathcal{T}|\rho^{2N}})\). 

### Proof of auxiliary Lemmas

**Lemma 27**.: _For \(j\neq\pi_{*}(i)\),_

\[P_{L}(v_{L},z)\leq n^{v_{L}}|\mathcal{T}|\beta^{4K}(4LM)^{4L}(4L)!(2\beta)^{4(K +M)}\left((4N)^{2}\beta^{\frac{K}{K+M}}\right)^{z}.\]Proof.: We define the unlabeled union graph sets corresponding to \(\mathcal{U}(v_{L},z)\) as \(\widetilde{\mathcal{U}}(v_{L},z)\). From the definition (75) and Claim 3,

\[P_{L}(v_{L},z)\leq\sum_{\hat{U}_{L}\in\widetilde{\mathcal{U}}_{L}(v_{L},z)}\frac {n^{v_{L}}w(\hat{U}_{L})}{\mathrm{aut}(\hat{U}_{L})}\leq(2K)^{z}n^{v_{L}}| \widetilde{\mathcal{U}}_{L}(v_{L},z)|.\] (86)

Recall that \(\hat{U}_{L}\) consists of two disjoint trees, one rooted at \(i\) and the other one rooted at \(j\). We consider the branches of chandeliers without overlapping with each other.

Then, we specify two categories of branches. A branch is called an invader if it is rooted at \(i\) (resp. \(j\)) but in \(\hat{U}_{L}(j)\) (resp. \(\hat{U}_{L}(i)\)). A branch that is not an invader is called a residence. We observe that there are at most \(L+\lfloor\frac{z}{K+M}\rfloor+4\) effective non-isomorphic bulbs among residents (defined in Section L, the proof of Proposition 5) because of the followings: 1) If branches are perfectly matched and overlapped, there are at most \(L\) pairs of them rooted at \(i\) and another \(L\) pairs rooted at \(j\). We define effective non-isomorphic bulbs the same as in Lemma 25. Here we have \(L\) effective non-isomorphic bulbs because \(S_{1}\cong S_{2},T_{1}\cong T_{2}\). 2) \(\lfloor\frac{z}{K+M}\rfloor\) is the maximum number of fully \(1\)-decorated branches in allowed \(\hat{U}_{L}\), and 3) There are at most \(4\) invading branches, each of which can at most fully overlapping with one resident bulb, due to the fact that there cannot be two branches on the same chandelier passing through the same vertex.

The remaining is to bound \(|\widetilde{U}_{L}(v_{L},z)|\). We observe that there are at most \(4(K+M-1)\) edges from invading branches, which might be attaching to at most \(4(K+M-1)\) resident branches. This is because an invader rooted at \(j\) may only have its bulb overlapping with \(\hat{U}_{L}(i)\). In this case, one invader can overlap with multiple resident branches in \(\hat{U}_{L}(i)\).

\[|\widetilde{U}_{L}(v_{L},z)|\leq\binom{|\mathcal{J}|}{L+\lfloor\frac{z}{K+M} \rfloor+4}\binom{2N}{z/2}(4N)^{\frac{z}{2}}(4LM)^{4L}(2\beta)^{4(K+M-1)}(4L)!,\] (87)

where \(\binom{|\mathcal{J}|}{L+\lfloor\frac{z}{K+M}\rfloor+4}\) is the structures of all resident branches, \(\binom{2N}{z/2}\) is the upper bound of choosing which edges to be not overlapped on bulbs assume starting from perfect overlapped bulbs, \((4N)^{\frac{z}{2}}\) is the bound for placing the remaining \(z/2\)\(1\)-decorated vertices, \((4LM)^{4L}\) is a trivial bound on how resident branches have their wires tangling with each other, \((\beta)^{4(K+M-1)}\) is the structure of invading edges, and lastly \(2^{(K+M-1)}(4L)!\) bounds the different interactions between invading edges and the resident branches. To understand the quantity \(2^{(K+M-1)}(4L)!\), this comes from the fact that each invading edge connected to the root can choose one out of at most \(4L\) resident branch to attach, and that the following invading edges can choose to stay overlapping with the current resident branch or leave.

Plugging (87) back into (86) with basic binomial bounds and \(|\mathcal{J}|\leq\beta^{K}\), we complete the proof. 

**Claim 3**.: _Assume that \(j\neq\pi_{*}(i)\). For any \(\hat{U}_{L}\in\mathcal{U}_{L}(v_{L},z)\),_

\[w(\hat{U}_{L})\leq\mathrm{aut}(\hat{U}_{L})(2K)^{z}.\] (88)

Proof.: Denote all bulbs contained in \(\hat{U}_{L}(i)\) (resp., \(j\)) and are attached to wires rooted at \(i\) (resp., \(j\)) as \(\mathcal{B}_{1},\mathcal{B}_{2},\ldots,\mathcal{B}_{w}\). Denote all bulbs contained in \(\hat{U}_{L}(i)\) (resp., \(j\)) and are attached to wires rooted at \(j\) (resp., \(i\)) as \(T_{1},T_{2},\ldots,T_{m}\). For those branches rooted at \(i\) (resp., \(j\)) but connect to \(j\) (resp., \(i\)), although they can have their bulbs in \(\hat{U}_{L}(j)\) (resp., \(\hat{U}_{L}(i)\)), they contribute to the weight of non-tree part \(\hat{U}_{N}\) from definitions (66) and (68).

For an arbitrary bulb \(\mathcal{B}_{t}\) in \(\hat{U}_{L}(i)\cup\hat{U}_{L}(j)\), we discuss the following three cases. Without loss of generality, we assume that \(\mathcal{B}_{t}\) is attached to a wire rooted at \(i\).

Firstly, if there exists another bulb \(\mathcal{B}_{r}\) such that \(\mathcal{B}_{r}\) and \(\mathcal{B}_{t}\) be two bulbs with wires rooted both at \(i\) and overlapping with each other. Then, from Corollary 2, we have that \(\sqrt{\mathrm{aut}(\mathcal{B}_{r})\mathrm{aut}(\mathcal{B}_{t})}\leq\mathrm{ aut}(\mathcal{B}_{r}\cup\mathcal{B}_{t})(2K)^{\frac{E(\mathcal{B}_{r})\wedge E( \mathcal{B}_{t})}{2}}\), because each bulb has size \(K\) and the difference between two edge set is at most \(K\). Secondly, if \(\mathcal{B}_{r}\) is full \(1\)-decorated, then it contributes to \(\sqrt{\mathrm{aut}(\mathcal{B}_{r})}\) to \(w(\hat{U}_{L})\) and \(\mathrm{aut}(\mathcal{B}_{t})\) to \(\mathrm{aut}(\hat{U}_{L})\). Thirdly, assume that there is another bulb \(\mathcal{B}_{t}\) attached to a wire rooted at \(j\) partly overlapping with \(\mathcal{B}_{t}\), then \(\sqrt{\mathrm{aut}(\mathcal{B}_{t})\mathrm{aut}(T_{r})}\leq\mathrm{aut}(\mathcal{ B}_{t}\cup T_{r})(2K)^{|E(\mathcal{B}_{4})\triangle E(T_{r})|}\) from Corollary 2. Note that in this case, full overlap is not possible because this invader branch spends at least one edge connecting from \(j\) to \(i\). The third case can be considered as a generalized version of the first case.

By a product over all overlapping bulbs, we have \(w(\dot{U}_{L})\leq\mathrm{aut}(\dot{U}_{L})(2K)^{z}\) because the total number of edges in the difference sets of overlapping bulbs are upper bounded by \(z\), the number of \(1\)-decorated edges, and the automorphism number of \(\dot{U}_{L}\) is greater than the product of automorphism number of all bulbs.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: As stated in the abstract and introduction, the main contribution of the paper is to give the first efficient algorithm for graph matching in the setting of correlated stochastic block models with two balanced communities. This is exactly the content of Theorem 1 in Section 3. The paper also claims, as an application, an efficient algorithm for exact community recovery given correlated stochastic block models. This is exactly the content of Theorem 2 in Section 4. These results, and their underlying assumptions, are discussed in detail in Sections 2, 3, 4, and 7. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: We discuss the limitations of our work, and possible future work that may address these, in Section 7. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.

3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: We clearly define the model and questions that we study in Section 2, and we fully state our main theoretical results, including all assumptions, in Theorem 1 and Theorem 2. Theorem 2 follows directly from Theorem 1 and prior work, as explained in the main text. For Theorem 1, we provide a brief overview of the proof in Section 5, and we give the full proof in the Appendix. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [NA] Justification: This paper does not include experimental results. Our main contribution is the theoretical analysis of a novel efficient graph matching algorithm for correlated SBMs. The algorithm itself is fully described and hence implementable. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset).

* We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
* **Open access to data and code*
* Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [NA] Justification: This paper does not include experiments. Guidelines:
* The answer NA means that paper does not include experiments requiring code.
* Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
* **Experimental Setting/Details*
* Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results?s Answer: [NA] Justification: This paper does not include experiments. Guidelines:
* The answer NA means that the paper does not include experiments.
* The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them.
* The full details can be provided either with the code, in appendix, or as supplemental material.
* **Experiment Statistical Significance*
* Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [NA] Justification: This paper does not include experiments. Guidelines:
* The answer NA means that the paper does not include experiments.
* The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.
* The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).
* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [NA] Justification: This paper does not include experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: This research conforms with the NeurIPS Code of Ethics in every respect. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: We discuss both the potential positive and negative societal impacts of this work, especially graph matching, in Section 2.

Guidelines:

* The answer NA means that there is no societal impact of the work performed.
* If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.
* Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.
* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).

11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: The paper does not involve any data or models that have a high risk for misuse. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: Relevant prior work on models (all theoretical) is cited and discussed in detail throughout the paper, following the norms of the research literature. No code or data is used. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset.

* For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.
* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: The paper does not release any new assets. Guidelines: * The answer NA means that the paper does not release new assets. * Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. * The paper should discuss whether and how consent was obtained from people whose asset is used. * At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: This paper is a theoretical work and does not involve crowdsourcing nor research with human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. * According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: This paper is a theoretical work and does not involve crowdsourcing nor research with human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.

* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.