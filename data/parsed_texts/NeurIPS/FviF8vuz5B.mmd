# On Differentially Private Sampling from Gaussian and Product Distributions

 Badih Ghazi

Google Research

Mountain View, CA, US

badihghazi@gmail.com

&Xiao Hu

University of Waterloo

Waterloo, Canada

xiaohu@uwaterloo.ca

&Ravi Kumar

Google Research

Mountain View, CA, US

ravi.k53@gmail.com

This work was done while the author was visiting Google Research.

Pasin Manurangsi

Google Research

Bangkok, Thailand

pasin@google.com

###### Abstract

Given a dataset of \(n\) i.i.d. samples from an unknown distribution \(P\), we consider the problem of generating a sample from a distribution that is close to \(P\) in total variation distance, under the constraint of differential privacy (DP). We study the problem when \(P\) is a multi-dimensional Gaussian distribution, under different assumptions on the information available to the DP mechanism: known covariance, unknown bounded covariance, and unknown unbounded covariance. We present new DP sampling algorithms, and show that they achieve near-optimal sample complexity in the first two settings. Moreover, when \(P\) is a product distribution on the binary hypercube, we obtain a pure-DP algorithm whereas only an approximate-DP algorithm (with slightly worse sample complexity) was previously known.

## 1 Introduction

Differential privacy (DP) [18, 16] is a strong and rigorous notion of privacy that has been increasingly studied and deployed as protection against the leakage of personal data used to train ML models.

A basic setting widely studied in ML is _distribution learning_, where given samples drawn i.i.d. from an unknown distribution \(P\), we seek to output a distribution \(Q\) that is as close to \(P\) as possible (formal definitions are given in Section 1.1). Recent works [27, 2, 29, 4] have studied DP distribution _learning_, whereby the output distribution is guaranteed to stay roughly the same when a single input sample is changed. A closely related setting is DP mean and covariance estimation studied by [38, 21, 36, 30, 7, 8, 11, 15, 28, 25, 9, 26]. Motivated by the fact that tasks often require much fewer samples than full-fledged learning, the very recent work of [35] studied the task of DP _distribution sampling_, where the goal is to generate a sample from a distribution \(Q\) that is as close as possible to the distribution \(P\) from which the input samples are drawn i.i.d. (In the non-private setting, variants of the sampling task have also been studied, e.g., in the work on sample amplification by [5].)

In this work, we study DP distribution sampling, and the quantitative gap with respect to the _a priori_ more challenging task of DP distribution learning. For the case of multi-dimensional Gaussians, we consider three natural settings: known covariance, unknown bounded covariance, and unknown unbounded covariance; for the first two, we obtain near-tight bounds. This answers an open question of [35]. Moreover, we obtain near-tight bounds on sampling in the case of product distributions on \(\{0,1\}^{d}\) with pure-DP, also improving upon previous work.

**Motivation.** There are many natural settings where a sample from the underlying distribution would be sufficient (as an alternative to the possibly more expensive task of learning the distribution).

For example, if one is implementing an algorithm that would run on sensitive user data, then, as part of the usual software development cycle, unit tests [24] are important. Writing unit tests on real data can violate users' privacy (e.g., if the unit test code is public). On the other hand, (privately) learning the distribution of the user data could be a significant overkill for this application. A private sample of the underlying distribution would provide a sufficiently representative input for the unit testing algorithm, and this input could be revealed publicly without compromising the privacy of the users.

A second motivation arises in distributed settings. Consider the situation where algorithms are being developed on medical data provided by multiple hospitals. The algorithm designer would like a synthetic dataset that would work well for the algorithm development process. Such a dataset could be obtained if each hospital provides a few (private) samples from its underlying distribution.

Finally, we describe another distributed setting motivation where a central curator wishes to build a synthetic dataset from multiple users, each contributing multiple items, under the constraint of item-level DP (as opposed to user-level DP). A simple approach for generating such a synthetic dataset is to let each user send to the curator a private sample (satisfying item-level DP).

### Formulation

Let \(\mathcal{D}\) be a class of distributions on some domain \(\mathcal{X}\). We consider a setting where there is an unknown distribution \(D\in\mathcal{D}\) and an algorithm has sample access to \(D\). There are two natural problems that can be posed in this setting. In the _sampling problem_, the goal is to design an algorithm that uses samples from \(D\) (which is unknown) and outputs an element in \(\mathcal{X}\). We say that an algorithm \(\mathcal{A}\) is an \(\alpha\)-_accurate sampler for \(\mathcal{D}\)_ iff \(d_{\mathrm{tv}}(D,Q_{\mathcal{A},D})\leq\alpha\) for all \(D\in\mathcal{D}\), where \(Q_{\mathcal{A},D}\) denotes the distribution of \(\mathcal{A}(\mathbf{X})\) where \(\mathbf{X}\sim D^{n}\) and \(d_{\mathrm{tv}}(\cdot,\cdot)\) denotes the total variation distance. Here \(n\) is said to be the sample complexity of the sampler. In the _learning problem_, the goal is to design an algorithm that outputs a distribution \(D^{\prime}\in\mathcal{D}\). We say that an algorithm \(\mathcal{A}\) is an \((\alpha,\beta)\)-_accurate learner for \(\mathcal{D}\)_ if \(\Pr_{\mathbf{X}\sim D^{n},D^{\prime}\sim\mathcal{A}(\mathbf{X})}[d_{\mathrm{tv }}(D^{\prime},D)\leq\alpha]\geq 1-\beta\) for all \(D\in\mathcal{D}\); as before, \(n\) is the sample complexity of the learner.

The DP version of the learning problem is well studied, e.g., [27, 4]; in this work we study the DP version of the sampling problem. First, we recall the definition of DP. We consider the _substitution_ notion, i.e., two datasets are _neighbors_ iff they have the same number of samples and we can transform one to the other by changing a single sample.

**Definition 1.1** (Differential Privacy [18, 16]).: An algorithm \(M:\mathcal{Y}\rightarrow\mathcal{O}\) is said to be \((\epsilon,\delta)\)-_differentially private_ (\((\epsilon,\delta)\)-DP) for \(\epsilon>0\), \(\delta\geq 0\) iff, for every \(S\subseteq\mathcal{O}\) and every neighboring datasets \(Y,Y^{\prime}\in\mathcal{Y}\), we have \(\Pr[\mathcal{M}(Y)\in S]\leq e^{\epsilon}\cdot\Pr[\mathcal{M}(Y^{\prime})\in S ]+\delta\).

We abbreviate \((\epsilon,0)\)-DP by \(\epsilon\)-DP, aka, _pure-DP_; the \(\delta\neq 0\) case is _approximate-DP_. We assume that the privacy parameters satisfy \(\epsilon\leq 1\), \(\delta\leq 1/2\), and the accuracy parameter satisfies \(0<\alpha\leq 1/2\).

### Our Results for Gaussian Distributions in \(\mathbb{R}^{d}\)

We focus on the \(d\)-dimensional Gaussian distribution, i.e., \(D=\mathsf{N}(\mu,\Sigma)\) with \(\mu\in\mathbb{R}^{d},\Sigma\in\mathbb{R}^{d\times d}\). Recall that \(\mathsf{N}(\mu,\Sigma)\) is supported on \(\mathbb{R}^{d}\) with \(f_{\mathsf{N}(\mu,\Sigma)}(x)\propto\exp\left(-\frac{1}{2}(x-\mu)^{T}\Sigma^ {-1}(x-\mu)\right)\). We study three cases that have been considered in the literature:

* _Known Covariance:_\(\Sigma\) is known, but \(\mu\) is not. More formally, the class of distributions is \(\mathcal{D}^{\mathsf{N}}_{\Sigma}:=\{\mathsf{N}(\mu,\Sigma)\mid\mu\in\mathbb{R }^{d}\}\).
* _Unknown Bounded Covariance:_ Both \(\mu,\Sigma\) are unknown but with a promise that \(I\preceq\Sigma\preceq\kappa\cdot I\) for a known constant \(\kappa>0\), i.e., the class of distributions is \(\mathcal{D}^{\mathsf{N}}_{\kappa}:=\{\mathsf{N}(\mu,\Sigma)\mid\mu\in\mathbb{R }^{d},\Sigma\in\mathbb{R}^{d\times d}\text{ s.t. }I\preceq\Sigma\preceq\kappa\cdot I\}\).2

Footnote 2: We write \(A\preceq B\) to denote that \(B-A\) is positive semi-definite, for matrices \(A\) and \(B\).
* _Unknown Unbounded Covariance:_ Both \(\mu,\Sigma\) are unknown, i.e., the class of distributions is \(\mathcal{D}^{\mathsf{N}}:=\{\mathsf{N}(\mu,\Sigma)\mid\mu\in\mathbb{R}^{d}, \Sigma\in\mathbb{R}^{d\times d}\}\).

A summary of our DP sampling results along with a comparison to known DP learning results is in Table 1. Before we describe our results in more detail, we highlight the following. (i) In all cases,the dependence of our algorithms on the accuracy parameter \(\alpha\) is only polylogarithmic, whereas for DP learning algorithms, this dependence is polynomial. (ii) In the case of known covariance and unbounded known covariance, we obtain improvements over DP learning in terms of the dependence on the dimension \(d\). (iii) All of our algorithms run in polynomial time, although we do not explicitly state the running time in the formal statements.

**Known Covariance.** While any DP learning algorithm requires \(\tilde{\Theta}\left(\frac{d}{\alpha^{2}}+\frac{d}{\alpha\epsilon}\right)\) samples in this setting [27], we show that, surprisingly, only \(\tilde{O}\left(\sqrt{d}/\epsilon\right)\) samples suffice for DP sampling.

**Theorem 1.2**.: _There is an \(\alpha\)-accurate \((\epsilon,\delta)\)-DP sampler for Gaussian distributions with known covariance with sample complexity \(O\left(\frac{\sqrt{d}}{\epsilon}\cdot\mathrm{polylog}\left(\frac{d}{\delta \epsilon\alpha}\right)\right).\)_

We also show that the \(\sqrt{d}\) dependence is necessary, i.e., that our algorithm's sample complexity is tight up to polylogarithmic factors.

**Theorem 1.3**.: _Any 0.1-accurate \((\epsilon,\delta)\)-DP sampler for Gaussian distributions with known covariance must have sample complexity \(\Omega(\sqrt{d}/\epsilon)\)._

**Unknown Bounded Covariance.** In this setting, we obtain an algorithm with sample complexity of \(\tilde{O}_{\kappa}\left(\frac{d}{\epsilon}\right)\); in contrast, the best known DP learning algorithm requires \(\tilde{\Theta}_{\kappa}\left(\frac{d^{2}}{\alpha^{2}}+\frac{d^{2}}{\alpha \epsilon}\right)\) samples [27, 29].

**Theorem 1.4**.: _There is an \(\alpha\)-accurate \((\epsilon,\delta)\)-DP sampler for Gaussian distributions with unknown covariance, under the assumption \(I\preceq\Sigma\preceq\kappa\cdot I\), with sample complexity \(O\left(\frac{d}{\epsilon}\cdot\kappa^{2}\cdot\mathrm{polylog}\left(\frac{d}{ \delta\epsilon\alpha}\right)\right).\)_

Similar to before, we can show that the sample complexity dependence on \(d,\epsilon\) is near-optimal:

**Theorem 1.5**.: _Let \(\alpha>0\) be a sufficiently small constant, and \(\epsilon,\delta\) be such that \(\delta\leq O\left(\frac{1}{nd^{2}}\right)\). Then, any \(\alpha\)-accurate \((\epsilon,\delta)\)-DP sampler for Gaussian distributions with unknown covariance, under the assumption \(I\preceq\Sigma\preceq 2I\), must have sample complexity \(n=\Omega\left(\frac{d}{\epsilon\sqrt{\log d}}\right)\)._

**Unknown Unbounded Covariance.** In this setting, the best known DP learning algorithm uses \(\tilde{\Theta}\left(\frac{d^{2}}{\alpha^{2}}+\frac{d^{2}}{\alpha\epsilon}\right)\) samples [4, 29, 28]. For DP sampling, we show that we can reduce the dependence on \(\alpha\) to polylogarithmic and the dependence on \(d\) to \(d^{1.5}\).

**Theorem 1.6**.: _There exists an \(\alpha\)-accurate \((\epsilon,\delta)\)-DP sampler for Gaussian distributions (without any assumption) with sample complexity \(O\left(\frac{d^{1.5}}{\epsilon}\operatorname{polylog}\left(\frac{d}{\alpha \epsilon\delta}\right)\right)\)._

### Our Results for Product Distributions on \(\{0,1\}^{d}\)

For \(p\in[0,1]\), let \(\mathsf{Ber}(p)\) be the _Bernoulli_ distribution supported on \(\{0,1\}\) with probability mass function \(f_{\mathsf{Ber}(p)}(0)=1-p\) and \(f_{\mathsf{Ber}(p)}(1)=p\). We consider product distributions \(\mathsf{Ber}(p_{1})\otimes\cdots\otimes\mathsf{Ber}(p_{d})\) where \(p_{1},\ldots,p_{d}\in[0,1]\) are unknown. (In other words, the class of distributions is \(\mathcal{D}^{\mathrm{prod}}:=\{\mathsf{Ber}(p_{1})\otimes\cdots\otimes\mathsf{ Ber}(p_{d})\mid p_{1},\ldots,p_{d}\in[0,1]\}\).)

\begin{table}
\begin{tabular}{|c|c|c|c|} \hline  & Known Covariance & Bounded Covariance & Unbounded Covariance \\ \hline Non-Private Learning (Folklore) & \(\Theta\left(\frac{d}{\alpha^{2}}\right)\) & \(\Theta\left(\frac{d^{2}}{\alpha^{2}}\right)\) & \(\Theta\left(\frac{d^{2}}{\alpha^{2}}\right)\) \\ \hline \((\epsilon,\delta)\)-DP Learning & \(\tilde{\Theta}\left(\frac{d}{\alpha^{2}}+\frac{d}{\alpha\epsilon}\right)\) & \(\tilde{\Theta}\left(\frac{d^{2}}{\alpha^{2}}+\frac{d^{2}}{\alpha\epsilon}\right)\) & \(\tilde{\Theta}\left(\frac{d^{2}}{\alpha^{2}}+\frac{d^{2}}{\alpha\epsilon}\right)\) \\  & [27] & [27, 28] & [4, 28] \\ \hline \((\epsilon,\delta)\)-DP Sampling (Our results) & \(\tilde{\Theta}\left(\frac{\sqrt{d}}{\epsilon}\right)\) Theorems 1.2,1.3 Theorems 1.4, 1.5 Theorem 1.6 \\ \hline \end{tabular}
\end{table}
Table 1: Sample complexity of private learning and sampling for Gaussian distributions. Here, \(\tilde{O},\tilde{\Theta}\) hide factors that are polylogarithmic in \(d,1/\epsilon,1/\delta,1/\alpha\) (and \(1/\beta\) in the case of learning).

We give a pure-DP sampler with sample complexity \(\tilde{O}\left(\frac{d}{\alpha\epsilon}\right)\). Previously, only approximate-DP sampler with similar sample complexity was known from [35], which also provided a matching lower bound. In comparison, DP learning uses \(\tilde{\Theta}\left(\frac{d}{\alpha^{2}}+\frac{d}{\alpha\epsilon}\right)\) samples [27; 10].

**Theorem 1.7**.: _There exists an \(\alpha\)-accurate \(\epsilon\)-DP sampler for product distributions on \(\{0,1\}^{d}\) with sample complexity \(O\left(\frac{d\log\left(\frac{d}{\alpha}\right)}{\alpha\epsilon}+\frac{d\log^ {2}\left(\frac{d}{\alpha}\right)}{\epsilon}\right).\)_

We also note that our result above improves upon even the approximate-DP sampler in [35] by logarithmic factors. Specifically, for \(\alpha\leq 1/\log d\), our sample complexity is \(O\left(\frac{d\log(d/\alpha)}{\alpha\epsilon}\right)\) whereas theirs is \(O\left(\frac{d\sqrt{\log(1/\delta)}}{\alpha\epsilon}\left(\log^{9/4}d+\log^{ 5/4}(1/\alpha)\right)\right)\).

## 2 Technical Overview

### Gaussian Distributions: Algorithms

**Known Covariance.** When \(\Sigma\) is known, we may assume w.l.o.g. that \(\Sigma=I\); otherwise, we can transform each sample \(X\) into \(\Sigma^{-1/2}X\). We start by using known algorithms [23; 40; 33] to find a "rough" estimate for the mean. In particular, we find an estimate \(\hat{\mu}\) such that \(\|\hat{\mu}-\mu\|_{2}\leq R=\tilde{O}(\sqrt{d}/\epsilon)\) using \(n=\tilde{O}(\sqrt{d}/\epsilon)\) samples. By appropriately shifting the subsequent samples, this is equivalent to assuming that \(\|\mu\|_{2}\leq R\). We then focus on designing a DP sampler for this bounded mean case. It turns out, surprisingly, that the Gaussian mechanism suffices here. Specifically, for a parameter \(B>0\) (chosen later), we truncate each sample so that its \(\ell_{2}\)-norm is at most \(B\). We then output their average with a (spherical) Gaussian noise \(\mathsf{N}(0,\sigma^{2}I)\) added. The description is given in Algorithm 1.

``` Parameters:\(B,\sigma>0\), and \(n\in\mathbb{N}\). Sample \(X_{1},\ldots,X_{n}\sim D\) for\(i=1,\ldots,n\)do \(X_{i}^{\text{trunc}}=\text{trunc}_{B}^{2}(X_{i})\)\(\triangleright\) see (1) Sample \(Z\sim\mathsf{N}(0,\sigma^{2}I)\) return\(Z+\frac{1}{n}\sum_{i\in[n]}X_{i}^{\text{trunc}}\) ```

**Algorithm 1** SphericalGaussianSampler

The analysis of the Gaussian mechanism [e.g., 20, Appendix A] shows that the algorithm is \((\epsilon,\delta)\)-DP as long as we pick \(\sigma\geq\tilde{O}\left(\frac{B}{n\epsilon}\right)\).

As for the accuracy, observe that if there were no truncation, then the output is exactly distributed as \(\mathsf{N}(\mu,(\sigma^{2}+1/n)I)\), which is precisely \(\mathsf{N}(\mu,I)\) if we set \(\sigma^{2}=(n-1)/n\). Therefore, by setting \(B=R+O(\sqrt{d+\log(1/\alpha)})\) so that the truncation does _not_ occur with probability \(1-\alpha\), we ensure that the sampler is \(\alpha\)-accurate. The constraint that \(\sigma\geq\tilde{O}\left(\frac{B}{n\epsilon}\right)\) from privacy implies that we need \(n\geq\tilde{O}(\sqrt{d}/\epsilon)\) and hence yielding the sample complexity in Theorem 1.2.

**Unknown Bounded Covariance.** Recall that in this setting we know that \(I\preceq\Sigma\preceq\kappa\cdot I\). While it might be tempting to use the above Gaussian mechanism for this setting as well, it turns out that this approach results in sample complexity that depends _polynomially_ on \(1/\alpha\).3

Footnote 3: See Appendix C for a proof sketch of the sample complexity from such an approach.

To circumvent this, we first consider the case where \(\mu=0\) (i.e., "centered" Gaussians). In this case, our algorithm originates from the following attempt: output \(\sum_{i\in[n]}a[i]\cdot X_{i}\), where \((a[1],\ldots,a[n])\sim\text{Un}_{n}^{\mathbb{S}}\), the uniform distribution over points on the unit sphere in \(\mathbb{R}^{n}\). It follows from the \(2\)-stability of the Gaussian distribution [41] that, when \(X_{1},\ldots,X_{n}\sim\mathsf{N}(0,\Sigma)\), this results4 in an output that is distributed exactly as \(\mathsf{N}(0,\Sigma)\).

Footnote 4: Note that this holds even for any fixed unit vector \(a\in\mathbb{R}^{d}\).

Unfortunately, this algorithm is not DP: if \(X_{1}=\cdots=X_{n-1}=0\), then the output will reveal the direction of \(X_{n}\) in the clear. To remedy this, we build on the intuition that, if \(X_{1},\ldots,X_{n}\) "sufficiently span all directions", then there should be "enough noise" to make this algorithm DP. In particular, using the bounded covariance property, we can show that if all the eigenvalues of \(\sum_{i\in[n]}X_{i}X_{i}^{T}\)

\begin{table}
\begin{tabular}{|c|c|} \hline Non-Private Learning & \(\Theta\left(\frac{d}{\alpha^{2}}\right)\) \\ \hline \(\epsilon\)-DP Learning & \(\tilde{\Theta}\left(\frac{d}{\alpha^{2}}+\frac{d}{\alpha\epsilon}\right)\)[29; 27] \\ \hline \((\epsilon,\delta)\)-DP Sampling & \(\tilde{\Theta}\left(\frac{d}{\alpha\epsilon}\right)\)[35] \\ \hline \(\epsilon\)-DP Sampling & \(\tilde{\Theta}\left(\frac{d}{\alpha\epsilon}\right)\) Theorem 1.7 \\ (Our result) & \(\tilde{\Theta}\left(\frac{d}{\alpha\epsilon}\right)\) Theorem 1.7 \\ \hline \end{tabular}
\end{table}
Table 2: Sample complexity for private learning and sampling for product distributions on \(\{0,1\}^{d}\). Here, \(\tilde{\Theta}\) hides factors that are polylogarithmic in \(d,1/\alpha\) (and \(1/\beta\) in the case of learning).

are sufficiently large (and each \(X_{i}\) is truncated appropriately), then this algorithm is indeed "DP". This is perhaps the most technically challenging part of our work, as the noise is data-dependent and therefore poses significant hurdles in the privacy analysis (Section 4.2). Note that this is also the reason we need \(n\geq\Omega(d)\), as otherwise \(X_{1},\ldots,X_{n}\) cannot "sufficiently span all directions" in \(\mathbb{R}^{d}\).

With the above, the last ingredient is a testing step (in the "propose-test-release" paradigm of [17]) that checks this eigenvalue condition. When this condition fails, we return \(\bot\); otherwise \(\sum_{i\in[n]}a[i]\cdot X_{i}\).

To handle the case where \(\mu\neq 0\), we take an output to be the sum of the average of \(n_{1}\) samples and \(\sqrt{1-\frac{1}{n_{1}}}\cdot(\sum_{i\in[n_{2}]}a[i]\cdot U_{i})\), where each \(U_{i}\) is the difference between two fresh independent samples divided by \(\sqrt{2}\) and \((a[1],\ldots,a[n_{2}])\sim\mathsf{Uni}_{n_{2}}^{\mathbb{S}}\). Notice here that each \(U_{i}\sim\mathsf{N}(0,\Sigma)\), while the average over \(n_{1}\) samples is \(\sim\mathsf{N}(\mu,\frac{1}{n_{1}}\cdot\Sigma)\); thus, the sum is \(\sim\mathsf{N}(\mu,\Sigma)\) as desired. The full description is presented in Algorithm 2; the parameter setting and analysis can be found in Appendix B.4.

**Unknown Unbounded Covariance.**

We proceed by reducing this case to the previous setting. We do so by first applying the known DP "preconditioner" algorithm for Gaussians (with unknown unbounded covariance) from the work of [9] in order to obtain rough estimates \(\hat{\mu},\hat{\Sigma}\) of \(\mu,\Sigma\) respectively. This allows us to transform any subsequent sample \(X\) into \(\hat{\Sigma}^{-1/2}(X-\hat{\mu})\). This reduces us back to DP sampling for \(\mathsf{N}(\hat{\Sigma}^{-1/2}(\mu-\hat{\mu}),\hat{\Sigma}^{1/2}\Sigma^{-1} \hat{\Sigma}^{1/2})\). The guarantee of the DP preconditioner ensures that this Gaussian actually has bounded covariance. Therefore, we can apply our previous algorithm. Note that a significant part of the sample complexity is due to the DP preconditioner of the Gaussian; it turns out that the sample complexity of this task is only \(\tilde{O}_{\epsilon,\alpha}(d^{3/2})\) (compared to \(\tilde{\Theta}_{\epsilon,\alpha}(d^{2})\) for learning). Furthermore, since we only need the preconditioner to be a rough estimate, we can set the accuracy parameter for the learning to be \(\Theta(1)\) and thus avoid the polynomial dependence on \(1/\alpha\). (Note that private preconditioner is a standard ingredient in the recipe for DP learning [e.g., 27].)

### Gaussian Distributions: Lower Bounds

**Known Covariance.** Our lower bound in this setting builds on the following insight: if we take a constant number of samples from \(\mathsf{N}(\mu,I)\) (using the DP sampler) and use them to estimate \(\mu\), then we incur an expected \(\ell_{2}^{2}\)-error that is \(O(d)\). It turns out that known lower bounds for DP mean estimation of Gaussians with known covariance [27] hold for this setting and give a lower bound of \(\Omega\left(\frac{d}{\gamma\epsilon}\right)\), where \(\gamma^{2}\) is the \(\ell_{2}^{2}\)-error. Plugging in \(\gamma=\sqrt{d}\) in our setting gives the desired lower bound of \(\Omega(\sqrt{d}/\epsilon)\). In the actual proof, one complication stems from the fact that our DP sampler does not output a sample exactly from \(\mathsf{N}(\mu,I)\). Nonetheless, we can quantify this in terms of the accuracy \(\alpha\).

**Unknown Bounded Covariance.** In this setting, we reduce from a lower bound on DP covariance estimation [28]--rather than DP mean estimation earlier--of centered Gaussians. The challenge is that \(\Theta(1)\) samples from \(\mathsf{N}(0,\Sigma)\) do _not_ provide a sufficiently high accuracy estimate for \(\Sigma\) so that we can apply the known lower bound5. Therefore, the above approach does not work directly.

Footnote 5: This high accuracy requirement is inherent in the known DP covariance estimation lower bound; see [28, Remark 4.4] for more details.

To overcome this, we will have to use many samples to estimate the covariance. Recall that the sample complexity lower bound of \(\Omega(d^{2}/\epsilon)\) for covariance estimation requires the accuracy in the Frobenius distance (or the Mahalanobis distance) to be constant [28]. Due to this accuracy requirement, we need to use our DP sampler to generate \(L=\Omega(d^{2})\) samples \(Y_{1},\ldots,Y_{L}\) to achieve such an accuracy. We can draw a fresh batch \(X_{1}^{i},\ldots,X_{n}^{i}\) of samples from the underlying distribution to generate each \(Y_{i}\). However, since \(L=\Omega(d^{2})\), this would use \(Ln\) samples in total. The covariance estimation lower bound would then yield \(Ln\geq\Omega(d^{2}/\epsilon)\), implying \(n\geq\Omega(1/\epsilon)\)--even weaker than the mean estimation lower bound!

Fortunately, it turns out this can be overcome by using advanced composition of DP [19]. In particular, we may run our sampler \(L\) times on the _same_\(n\) samples to produce \(Y_{1},\ldots,Y_{L}\). In this case, the final covariance estimation algorithm has privacy loss parameter \(\tilde{O}(\sqrt{L}\cdot\epsilon)=\tilde{O}(d\cdot\epsilon)\) due to advanced composition (Theorem A.5). Therefore, we get a lower bound of \(\tilde{\Omega}(d^{2}/(d\cdot\epsilon))=\tilde{\Omega}(d/\epsilon)\) as desired.

While the above overview seems intuitively plausible, there are certain difficulties that we need to overcome. First, the samples \(Y_{i}\) that our algorithm produces are not exactly drawn from \(\mathbb{N}(0,\Sigma)\); to fix this, we run an agnostic learner for Gaussians [e.g., 3] to recover the estimate of \(\Sigma\). Second, since we run our DP sampler on the same \(n\) samples, the produced \(Y_{1},\ldots,Y_{L}\) are not independent. We fix this by first drawing a larger number \(N\) of samples, and then produce each \(Y_{i}\) using \(n\)-out-of-\(N\) random samples; this reduces the correlation across the \(Y_{i}\)'s. Furthermore, using amplification-by-sampling of DP [6] gives us the desired privacy-vs-sample complexity lower bound guarantee.

### Product Distributions: Algorithm

Our sampler follows the framework of [35], which is built upon the preconditioning procedure proposed by [27] for DP learning.

We start with a private preconditioner, which obtains a crude estimate of each \(p_{j}\) (up to a constant multiplicative factor). This is similar to that of [27], except that we use Laplace noise instead of Gaussian noise; this ensures that the resulting algorithm is pure-DP6. By suitably partitioning \([0,1]\) into geometrically decreasing buckets in terms of \(d/\alpha\), the goal then is to estimate \(p_{j}\) by placing it in one of these buckets. This can be done by an appropriate thresholding and the Laplace mechanism.

Footnote 6: We remark that a similar analysis has also been done by [37], who uses such a pure-DP preconditioner to give pure-DP algorithms for _learning_ product distributions.

The next step is to obtain a refined estimate of the \(p_{i}\)'s using a fresh batch of samples. The algorithm then returns a sample randomly drawn from the product distribution given by these estimates. The earlier crude estimates are helpful in truncating and clipping the samples to make the produced sample DP, without adding any noise to the refined estimate.

## 3 Preliminaries

For convenience, we use the notation \(\text{trunc}_{B}^{p}(X)\) for "truncation" for all \(X\in\mathbb{R}^{d},B>0,p\geq 1\):

\[\text{trunc}_{B}^{p}(X):=\begin{cases}X&\text{ if }\|X\|_{p}\leq B,\\ X\cdot B/\|X\|_{p}&\text{ if }\|X\|_{p}>B.\end{cases}\] (1)

Let \([k]\) denote \(\{1,\ldots,k\}\). For any \(X\in\mathbb{R}^{d}\), we use \(X[j]\) to denote the value of its \(j\)th coordinate.

### Distributions and Tail Bounds

For a discrete distribution \(D\), we use \(f_{D}\) to denote its probability mass function (PMF); for a continuous distribution \(D\), we use \(f_{D}\) to denote its probability density function (PDF). Let \(\operatorname{supp}(D)\) denote the support of \(D\). We let \(Z\sim D\) denote that the random variable \(Z\) is distributed according to \(D\); throughout, we may write the random variable in place of the distribution and vice versa when convenient. Finally, when \(D_{1},\ldots,D_{d}\) are distributions, we use \(D_{1}\otimes\cdots\otimes D_{d}\) as the product distribution, i.e., the distribution of \((Z_{1},\ldots,Z_{d})\) where \(Z_{1}\sim D_{1},\ldots,Z_{d}\sim D_{d}\) are independent.

For a distribution \(D\) on \(\mathbb{R}^{d}\) and \(v\in\mathbb{R}^{d}\), we write \(D+v\) as a shorthand for the distribution of \(X+v\) where \(X\sim D\). Furthermore, for a distribution \(D\) and a (possibly randomized) function \(h\), we write \(h(D)\) to denote the distribution of \(h(X)\) where \(X\sim D\).

We will list a few distributions that will be useful for us.

(i) _Shifted Truncated Discrete Laplace Distribution:_ For \(\Delta>0\), let \(s(\epsilon,\delta)=\lceil\Delta(1+\log(1/\delta)/\epsilon)\rceil\). We define \(\mathsf{STlap}(\epsilon,\delta,\Delta)\) to be the discrete distribution supported on \([-2s(\epsilon,\delta),0]\) such that \(f_{\mathsf{STlap}(\epsilon,\delta,\Delta)}(x)\propto\exp{(-\epsilon\,|x+s( \epsilon,\delta)|)}\).

It is known that adding \(\mathsf{STlap}\) noise to a low-sensitivity function results in a DP estimate [e.g., 22].

**Lemma 3.1**.: _If \(g\) is a function with sensitivity \(\leq\Delta\), then the algorithm that outputs \(g(\mathsf{X})+\mathsf{STlap}(\epsilon,\delta,\Delta)\) is \((\epsilon,\delta)\)-DP._

(ii) _Beta Distribution:_ For \(\alpha,\beta>0\), \(\mathsf{Beta}(\alpha,\beta)\) has the PDF \(f_{\mathsf{Beta}(\alpha,\beta)}(x)\propto x^{\alpha-1}(1-x)^{\beta-1}\).

(iii) _Uniform Distribution over Unit Sphere:_ For \(d\in\mathbb{N}\), let \(\mathsf{Un}_{d}^{\mathbb{S}}\) denote the distribution of a random unit vector in \(\mathbb{R}^{d}\).

(iv) _Projection of Uniform Distribution over Unit Sphere:_ For any \(d\in\mathbb{N}\) and \(i\in[d]\) and \(z\in\mathbb{R}^{d}\), let \(\Pi_{\leq i}(z)\) denote \((z_{1},\ldots,z_{i})\). Then, let \(\mathsf{Un}_{d,i}^{\mathbb{S}}\) denote the distribution of \(\Pi_{\leq i}(Z)\) where \(Z\sim\mathsf{Un}_{d}^{\mathbb{S}}\). This distribution has the PDF (see, e.g., [34, Theorem 2]) given below.

\[f_{\mathsf{Un}_{d,i}^{\mathbb{S}}}(z)\propto\begin{cases}(1-\|z\|^{2})^{\frac{ d-i}{2}-1}&\text{ if }\|z\|^{2}<1\\ 0&\text{otherwise.}\end{cases}\] (2)

We need a tail bound on the \(\ell_{2}\)-norm of a Gaussian-distributed vector:

**Lemma 3.2** ([42, Theorem 6.2]).: _There exists a constant \(c\geq 1\) such that, for any \(\mu\in\mathbb{R}^{d}\), \(\Sigma\in\mathbb{R}^{d\times d}\) where \(\Sigma\preceq\kappa\cdot I\) and any \(\beta\in(0,\frac{1}{2})\), \(\Pr_{X\sim\mathsf{N}(\mu,\Sigma)}\left[\|X-\mu\|_{2}>c\sqrt{\kappa}\left(\sqrt {d}+\sqrt{\log(1/\beta)}\right)\right]\leq\beta\)._

We also need a tail bound for the beta distribution:

**Lemma 3.3** ([43], Theorem 8).: _There exists a constant \(c\in(0,1)\) such that, for any \(0<\alpha<\beta\) and any \(x\geq 0\), we have \(\Pr_{Z\sim\mathsf{Beta}(\alpha,\beta)}\left[Z\geq\frac{\alpha}{\alpha+\beta}+ x\right]\leq 2e^{-c\cdot\min\left\{\frac{\beta^{2}x^{2}}{\alpha},\beta x\right\}}\)._

The following concentration bound on the empirical covariance will also be helpful.

**Lemma 3.4** ([27, Fact 3.4]).: _There exists a constant \(c\geq 1\) such that for any \(\Sigma\succeq I\), let \(U_{1},\ldots,U_{n}\sim\mathsf{N}(0,\Sigma)\) and \(\hat{\Sigma}=\frac{1}{n}\sum_{i\in[n]}U_{i}U_{i}^{T}\), we have \(\Pr\left[\hat{\Sigma}\succeq\left(1-c\sqrt{\frac{d+\log(1/\beta)}{n}}\right) \cdot I\right]\geq 1-\beta\)._

### Differential Privacy

**Hockey Stick Divergence.** We also recall the definition of \(\epsilon\)_-hockey stick divergence_ between two distributions \(P,Q\): \(d_{\epsilon}(P\mid\mid Q):=\int_{y\in\operatorname{supp}(P)}[f_{P}(y)-e^{ \epsilon}f_{Q}(y)]_{+}dy,\) where \([a]_{+}:=\max\{a,0\}\).

The following standard fact about the hockey stick divergence is often useful in proving DP guarantees of algorithms [39, 31].

**Lemma 3.5**.: _For any \(\epsilon\geq 0\) and distributions \(P,Q\), \(d_{\epsilon}(P\mid\mid Q)\leq\Pr_{y\sim P}[f_{P}(y)>e^{\epsilon}f_{Q}(y)]\)._

It will be also useful to keep in mind the "post-processing" property of DP:

**Lemma 3.6**.: _For any distributions \(P,Q\) and any function \(h\), we have \(d_{\epsilon}(h(P)\mid\mid h(Q))\leq d_{\epsilon}(P\mid\mid Q)\)._

**DP under Condition.** Since we will use a "propose-test-release"-style algorithm [17], it will be convenient to use the notion of "DP under condition" together with its composition properties. The particular definition we use below is from [32]; similar notions have been used earlier, e.g., in [17].

**Definition 3.7** (DP under Condition, [32]).: Let \(\Psi:\mathcal{Y}\to\{0,1\}\) be a predicate. An algorithm \(M:\mathcal{Y}\to\mathcal{O}\) is \((\epsilon,\delta)\)_-DP under condition \(\Psi\)_ for \(\epsilon,\delta>0\) iff, for every \(S\subseteq\mathcal{O}\) and every neighboring datasets \(Y,Y^{\prime}\in\mathcal{Y}\) both satisfying \(\Psi\), we have \(\Pr[\mathcal{M}(Y)\in S]\leq e^{\epsilon}\cdot\Pr[\mathcal{M}(Y^{\prime})\in S ]+\delta\).

**Lemma 3.8** (Composition for Algorithm with Halting, [32]).: _Let \(\mathcal{M}_{1}:\mathcal{Y}\to\mathcal{O}_{1}\cup\{\bot\},\mathcal{M}_{2}: \mathcal{O}_{1}\times\mathcal{Y}\to\mathcal{O}_{2}\) be algorithms. Furthermore, let \(\mathcal{M}\) denote the following algorithm: Let \(o_{1}=\mathcal{M}_{1}(Y)\) and, if \(o_{1}=\bot\), then halt and output \(\bot\) or else, output \(o_{2}=\mathcal{M}_{2}(o_{1},Y)\)._

_Let \(\Psi\) be any condition such that, if \(Y\) does not satisfy \(\Psi\), then \(\mathcal{M}_{1}(Y)\) always returns \(\bot\). Suppose that \(\mathcal{M}_{1}\) is \((\epsilon_{1},\delta_{1})\)-DP and \(\mathcal{M}_{2}\) is \((\epsilon_{2},\delta_{2})\)-DP under condition \(\Psi\). Then, \(\mathcal{M}\) is \((\epsilon_{1}+\epsilon_{2},\delta_{1}+\delta_{2})\)-DP._Gaussian Distribution: Algorithms

**Reduction to the Bounded Mean Case.** As stated earlier, for the cases of known covariance and bounded covariance, we will need a preprocessing step that computes a rough private estimate for the mean. The properties of the reduction are stated below.

**Lemma 4.1**.: _Suppose that there is an \(\alpha\)-accurate \((\epsilon,\delta)\)-DP sampler for Gaussian distributions under the assumption that \(I\preceq\Sigma\preceq\kappa\cdot I,\|\mu\|\leq R\) with sample complexity \(n_{\mathrm{bm\cdotsampler}}(\alpha,R,\epsilon,\delta)\). Then, there exists an \(\alpha\)-accurate \((\epsilon,\delta)\)-DP sampler for Gaussian distributions under the assumption that \(I\preceq\Sigma\preceq\kappa\cdot I\) with sample complexity \(\tilde{O}\left(\frac{\sqrt{d}}{\epsilon}\right)+n_{\mathrm{bm\cdotsampler} }(\alpha/2,O(\kappa\sqrt{d}),\epsilon/2,\delta/2)\)._

### Known Covariance

With the reduction in Lemma 4.1, we may assume that \(\|\Sigma^{-1/2}\mu\|\leq R\). When the covariance is known, we give an algorithm with the following guarantees.

**Theorem 4.2**.: _Assuming \(\Sigma\) is known and \(\|\Sigma^{-1/2}\mu\|\leq R\), there is an \(\alpha\)-accurate \((\epsilon,\delta)\)-DP sampler for Gaussian distributions with sample complexity \(O\left(\left(R+\sqrt{d+\log\left(\frac{\log(1/\delta)}{\alpha\epsilon}\right) }\right)\sqrt{\frac{\log(1/\delta)}{\epsilon}}\right)\)._

We assume w.l.o.g. that \(\Sigma=I\); otherwise, we can consider \(X_{i}^{\prime}=\Sigma^{-1/2}X_{i}\). Before we describe the algorithm, note that Theorem 4.2 together with Lemma 4.1 implies Theorem 1.2. As stated earlier, the algorithm (Algorithm 1) is simple: take the average of the truncated input samples and add to it (spherical) Gaussian noise.

Proof.: Let \(C\geq 1\) be the constant from Lemma 3.2, \(B=R+10^{4}C\sqrt{d+\log\left(\frac{2\log(2/\delta)}{\alpha\epsilon}\right)}\), and \(n=1+\lceil 10B\sqrt{\log(2/\delta)}/\epsilon\rceil\). Let \(\mathcal{A}\) be Algorithm 1 with \(B,n\) as specified and \(\sigma=\sqrt{(n-1)/n}\).

**Privacy Analysis.**\(\mathcal{A}\) is the Gaussian mechanism with noise multiplier \(n\sigma/B\geq 10\sqrt{\log(2/\delta)}/\epsilon\); therefore, \(\mathcal{A}\) is \((\epsilon,\delta)\)-DP, using (20, Appendix A).

**Accuracy Analysis.** Let \(D=\mathsf{N}(\mu,I)\) for some unknown \(\mu\). Consider the algorithm \(\mathcal{A}^{\prime}\) where there is no truncation, i.e., \(\mathcal{A}^{\prime}\) simply outputs \(Y:=Z+\frac{1}{n}\sum_{i\in[n]}X_{i}\). Via Lemma 3.2 and a union bound, the truncation is not applied anyway in \(\mathcal{A}\) (i.e., \(X_{i}=X_{i}^{\text{trunc}},\forall i\in[n]\)) with probability at least \(1-\alpha\). Therefore, \(d_{\mathsf{tv}}(Q_{\mathcal{A},D},Q_{\mathcal{A}^{\prime},D})\leq\alpha\). Note that \(\mathcal{A}^{\prime}\) just outputs \(Y:=Z+\frac{1}{n}\sum_{i\in[n]}X_{i}\), so we have \(Y\sim\mathsf{N}(\mu,I)=D\), i.e., \(Q_{\mathcal{A}^{\prime},D}=D\). Combining these bounds yields \(d_{\mathsf{tv}}(Q_{\mathcal{A},D},D)\leq\alpha\). 

### Unknown Bounded Covariance

We now move on to the case where both \(\mu,\Sigma\) are unknown but under the assumption \(I\preceq\Sigma\preceq\kappa\cdot I\). The main result of this section is stated below7. Again, note that Theorem 4.3 and Lemma 4.1 immediately yield Theorem 1.4.

Footnote 7: The dependence on \(\kappa\) can be reduced to \(\text{polylog}(1/\kappa)\) by applying the private preconditioning in (27), although this will increase the dependence on \(d\) to \(d^{1.5}\); it is an interesting question if this increase in the dependence on \(d\) can be avoided.

**Theorem 4.3**.: _Assuming \(I\preceq\Sigma\preceq\kappa\cdot I\) for some \(\kappa>0\) and \(\|\mu\|\leq R\), there is an \(\alpha\)-accurate \((\epsilon,\delta)\)-DP sampler for Gaussian distributions with sample complexity \(O\left(\left(R^{2}+\kappa^{2}\left(d+\log\left(\frac{\log(1/\delta)}{\alpha \epsilon}\right)\right)\right)\cdot\frac{\log(1/\delta)}{\epsilon}\right).\)_

As stated in the overview, the main challenge lies in the privacy analysis. It will be proved in three steps. First, in Section 4.2.1, we will show that if we add noise that is drawn from projection of random unit vector to the first \(M\) coordinates to a low-(\(\ell_{2}\)-)sensitivity function, then it is DP. Then, in Section 4.2.2, we use this to show that adding noise of the form \(\sum_{i\in[n]}a[i]\cdot w_{i}\) (where \(a\sim\mathsf{Un}_{n}^{\mathbb{S}}\)) to a low-sensitivity function also suffices for privacy as long as the smallest eigenvalue of \(\sum_{i\in[n]}w_{i}w_{i}^{T}\) is sufficiently large. Here \(w_{1},\ldots,w_{n}\) are assumed to be fixed vectors given beforehand. Note that the noises discussed so far are input _independent_. Finally, in Appendix B.4, we relate this to the 

[MISSING_PAGE_FAIL:9]

**Acknowledgment.** We thank Shyam Narayanan for pointing us to [9], which improves dependency on \(d\) in the sample complexity for sampling Gaussians with unknown (unbounded) covariance from \(d^{2}\) to \(d^{1.5}\).

## References

* Abadi et al. [2016] Martin Abadi, Andy Chu, Ian J. Goodfellow, H. Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. Deep learning with differential privacy. In _CCS_, pages 308-318, 2016.
* Aden-Ali et al. [2021] Ishaq Aden-Ali, Hassan Ashtiani, and Gautam Kamath. On the sample complexity of privately learning unbounded high-dimensional Gaussians. In _ALT_, pages 185-216, 2021.
* Ashtiani et al. [2018] Hassan Ashtiani, Shai Ben-David, and Abbas Mehrabian. Sample-efficient learning of mixtures. In _AAAI_, pages 2679-2686, 2018.
* Ashtiani and Liaw [2022] Hassan Ashtiani and Christopher Liaw. Private and polynomial time algorithms for learning Gaussians and beyond. In _COLT_, pages 1075-1076, 2022.
* Axelrod et al. [2020] Brian Axelrod, Shivam Garg, Vatsal Sharan, and Gregory Valiant. Sample amplification: Increasing dataset size even when learning is impossible. In _ICML_, pages 442-451, 2020.
* Balle et al. [2018] Borja Balle, Gilles Barthe, and Marco Gaboardi. Privacy amplification by subsampling: Tight analyses via couplings and divergences. In _NeurIPS_, pages 6280-6290, 2018.
* Biswas et al. [2020] Sourav Biswas, Yihe Dong, Gautam Kamath, and Jonathan R. Ullman. Coinpress: Practical private mean and covariance estimation. In _NeurIPS_, 2020.
* Brown et al. [2021] Gavin Brown, Marco Gaboardi, Adam D. Smith, Jonathan R. Ullman, and Lydia Zakymithou. Covariance-aware private mean estimation without private covariance estimation. In _NeurIPS_, pages 7950-7964, 2021.
* Brown et al. [2023] Gavin Brown, Samuel Hopkins, and Adam Smith. Fast, sample-efficient, affine-invariant private mean and covariance estimation for subgaussian distributions. In _COLT_, pages 5578-5579, 2023.
* Bun et al. [2021] Mark Bun, Gautam Kamath, Thomas Steinke, and Zhiwei Steven Wu. Private hypothesis selection. _IEEE Trans. Inf. Theory_, 67(3):1981-2000, 2021.
* Cai et al. [2021] T. Tony Cai, Yichen Wang, and Linjun Zhang. The cost of privacy: Optimal rates of convergence for parameter estimation with differential privacy. _Ann. Stat._, 49(5):2825-2850, 2021.
* Desfontaines et al. [2022] Damien Desfontaines, James Voss, Bryant Gipson, and Chinmoy Mandayam. Differentially private partition selection. _PETS_, 2022(1):339-352, 2022.
* Devroye et al. [2018] Luc Devroye, Abbas Mehrabian, and Tommy Reddad. The total variation distance between high-dimensional Gaussians with the same mean. _arXiv:1810.08693_, 2018.
* Diakonikolas et al. [2019] Ilias Diakonikolas, Gautam Kamath, Daniel Kane, Jerry Li, Ankur Moitra, and Alistair Stewart. Robust estimators in high-dimensions without the computational intractability. _SIAM J. Comput._, 48(2):742-864, 2019.
* Dong et al. [2022] Wei Dong, Yuting Liang, and Ke Yi. Differentially private covariance revisited. In _NeurIPS_, 2022.
* Dwork et al. [2006] Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya Mironov, and Moni Naor. Our data, ourselves: Privacy via distributed noise generation. In _EUROCRYPT_, pages 486-503, 2006.
* Dwork and Lei [2009] Cynthia Dwork and Jing Lei. Differential privacy and robust statistics. In _STOC_, pages 371-380, 2009.
* Dwork et al. [2006] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in private data analysis. In _TCC_, pages 265-284, 2006.

* [19] Cynthia Dwork, Moni Naor, and Salil P. Vadhan. The privacy of the analyst and the power of the state. In _FOCS_, pages 400-409, 2012.
* [20] Cynthia Dwork and Aaron Roth. The algorithmic foundations of differential privacy. _Found. Trends Theor. Comput. Sci._, 9(3-4):211-407, 2014.
* [21] Cynthia Dwork, Kunal Talwar, Abhradeep Thakurta, and Li Zhang. Analyze gauss: Optimal bounds for privacy-preserving principal component analysis. In _STOC_, pages 11-20, 2014.
* [22] Badih Ghazi, Neel Kamal, Ravi Kumar, Pasin Manurangsi, and Annika Zhang. Private aggregation of trajectories. _PETS_, 2022(4):626-644, 2022.
* [23] Badih Ghazi, Ravi Kumar, and Pasin Manurangsi. Differentially private clustering: Tight approximation ratios. In _NeurIPS_, 2020.
* [24] Paul Hamill. _Unit Test Frameworks: Tools for High-Quality Software Development_. " O'Reilly Media, Inc.", 2004.
* [25] Samuel B. Hopkins, Gautam Kamath, and Mahbod Majid. Efficient mean estimation with pure differential privacy via a sum-of-squares exponential mechanism. In _STOC_, pages 1406-1417, 2022.
* [26] Samuel B. Hopkins, Gautam Kamath, Mahbod Majid, and Shyam Narayanan. Robustness implies privacy in statistical estimation. In _STOC_, pages 497-506, 2023.
* [27] Gautam Kamath, Jerry Li, Vikrant Singhal, and Jonathan R. Ullman. Privately learning high-dimensional distributions. In _COLT_, pages 1853-1902, 2019.
* [28] Gautam Kamath, Argyris Mouzakis, and Vikrant Singhal. New lower bounds for private estimation and a generalized fingerprinting lemma. In _NeurIPS_, 2022.
* [29] Gautam Kamath, Argyris Mouzakis, Vikrant Singhal, Thomas Steinke, and Jonathan R. Ullman. A private and computationally-efficient estimator for unbounded Gaussians. In _COLT_, pages 544-572, 2022.
* [30] Vishesh Karwa and Salil P. Vadhan. Finite sample differentially private confidence intervals. In _ITCS_, pages 44:1-44:9, 2018.
* [31] Antti Koskela, Joonas Jalko, and Antti Honkela. Computing tight differential privacy guarantees using FFT. In _AISTATS_, pages 2560-2569, 2020.
* [32] Pravesh Kothari, Pasin Manurangsi, and Ameya Velingker. Private robust estimation by stabilizing convex relaxations. In _COLT_, pages 723-777, 2022.
* [33] Shyam Narayanan, Vahab S. Mirrokni, and Hossein Esfandiari. Tight and robust private mean estimation with few users. In _ICML_, pages 16383-16412, 2022.
* [34] Hedvika Ranosova. Spherically Symmetric Measures. Bachelor's thesis, Department of Probability and Mathematical Statistics, Charles University, 2021.
* [35] Sofya Raskhodnikova, Satchit Sivakumar, Adam Smith, and Marika Swanberg. Differentially private sampling from distributions. In _NeurIPS_, pages 28983-28994, 2021.
* [36] Or Sheffet. Differentially private ordinary least squares. In _ICML_, pages 3105-3114, 2017.
* [37] Vikrant Singhal. A polynomial time, pure differentially private estimator for binary product distributions. _CoRR_, abs/2304.06787, 2023.
* [38] Adam Smith. Privacy-preserving statistical estimation with optimal convergence rates. In _STOC_, pages 813-822, 2011.
* [39] David M. Sommer, Sebastian Meiser, and Esfandiar Mohammadi. Privacy loss classes: The central limit theorem in differential privacy. _PETS_, 2019(2):245-269, 2019.
* [40] Eliad Tsfadia, Edith Cohen, Haim Kaplan, Yishay Mansour, and Uri Stemmer. Friendlycore: Practical differentially private aggregation. In _ICML_, pages 21828-21863, 2022.

* [41] Vladimir V. Uchaikin and Vladimir M. Zolotarev. _Chance and Stability_. De Gruyter, Berlin, Boston, 1999.
* [42] Roman Vershynin. _High-Dimensional Probability: An Introduction with Applications in Data Science_. Cambridge University Press, 2018.
* [43] Anru R. Zhang and Yuchen Zhou. On the non-asymptotic and sharp lower tail bounds of random variables. _Stat_, 9(1):e314, 2020.

## Appendix A Additional Preliminaries

We consider a generalization of the truncation (1) where there is a weight vector \(w\in\mathbb{R}_{\geq 0}^{d}\), and the truncation is w.r.t. \(w\):

\[\text{trunc}_{B,w}^{p}(X):=\begin{cases}X&\text{if }\|X\circ w\|_{p}\leq B,\\ X\cdot B/\|X\circ w\|_{p}&\text{if }\|X\circ w\|_{p}>B,\end{cases}\]

where \(\circ\) denotes the element-wise product. Clearly \(\text{trunc}_{B}^{p}=\text{trunc}_{B,w}^{p}\) when \(w\) is the all-ones vector. For \(a,b\in\mathbb{R}\) where \(a\leq b\), we also use \(\text{clip}_{(a,b)}:\mathbb{R}\to\mathbb{R}\) to denote the function:

\[\text{clip}_{(a,b)}(x)=\max\{a,\min\{b,x\}\}.\]

### Total Variation Distance between Gaussians

For our proofs, it will be useful to state the total variation distance bounds for Gaussian distributions. We will use the following notation:

**Definition A.1**.: For any matrix \(A\in\mathbb{R}^{d\times d}\) and positive semi-definite matrix \(\Sigma\in\mathbb{R}^{d\times d}\), we write \(\|A\|_{\Sigma}:=\|\Sigma^{-1/2}A\Sigma^{-1/2}\|_{F}\), where \(\|\cdot\|_{F}\) denotes the Frobenius norm.

It is well known that when \(\|\Sigma-\hat{\Sigma}\|_{\Sigma}\leq O(1)\), the total variation distance between Gaussian with covariance matrices \(\Sigma\) and \(\hat{\Sigma}\) and the same mean is \(\Theta(\|\Sigma-\hat{\Sigma}\|_{\Sigma})\), as stated more formally below.

**Lemma A.2** ([13]).: _There exists a constant \(C\geq 1\) such that the following holds. For any \(\Sigma,\hat{\Sigma}\), if \(d_{\mathrm{tv}}(\mathsf{N}(0,\Sigma),\mathsf{N}(0,\hat{\Sigma}))\leq 0.001\), then \(\|\Sigma-\hat{\Sigma}\|_{\Sigma}\leq C\cdot d_{\mathrm{tv}}(\mathsf{N}(0, \Sigma),\mathsf{N}(0,\hat{\Sigma}))\)._

**Lemma A.3** (e.g., [14]).: _There exists a constant \(C>0\) such that the following holds. For any \(\Sigma,\hat{\Sigma}\in\mathbb{R}^{d\times d}\), we have \(d_{\mathrm{tv}}(\mathsf{N}(0,\Sigma),\mathsf{N}(0,\hat{\Sigma}))\leq C\cdot \|\Sigma-\hat{\Sigma}\|_{\Sigma}\)._

### Differential Privacy

#### a.2.1 Amplification by Subsampling

Suppose that we have as an input \(N\) samples, and we draw \(n<N\) subsamples (without replacement) randomly from these \(N\) samples and run an \((\epsilon,\delta)\)-DP algorithm on these \(n\) subsamples. Then, it is known that this results in an \((\epsilon^{\prime},\delta^{\prime})\)-DP algorithm for \(\epsilon^{\prime}<\epsilon,\delta^{\prime}<\delta\). Such a phenomenon is called _amplification by subsampling_ and is often used in DP learning [e.g., 1]. We will use the following version of this for our lower bound proof.

**Theorem A.4** (Amplification by Subsampling, [6]).: _Suppose that \(\mathcal{A}\) is an \((\epsilon,\delta)\)-DP algorithm that takes in \(n\) samples. Then, the algorithm that draws \(n\) subsamples randomly without replacement out of \(N\) samples and runs \(\mathcal{A}\) on the \(n\) subsamples is \((\epsilon^{\prime},\delta^{\prime})\)-DP where_

\[\epsilon^{\prime}=\ln(1+(n/N)(e^{\epsilon}-1)),\qquad\delta^{\prime}=(n/N) \cdot\delta.\]

### Advanced Composition

We will also use the following _advanced composition_ of DP.

**Theorem A.5** (Advanced Composition, [19]).: _Let \(\epsilon_{0}>0\) and \(\delta_{0},\delta_{1}\in(0,1/2]\), and \(\mathcal{A}\) be any \((\epsilon_{0},\delta_{0})\)-DP algorithm. Then, the algorithm that runs \(\mathcal{A}\) a total of \(k\) times is \((\epsilon_{1},k\delta_{0}+\delta_{1})\)-DP where_

\[\epsilon_{1}=\left(\sqrt{2k\ln(1/\delta_{1})}+k(e^{\epsilon_{0}}-1)\right) \epsilon_{0}.\]

### Lower Bounds for Mean and Covariance Estimations

As stated in our proof overview (Section 2), our lower bounds for Gaussian samplers (Theorems 1.3 and 1.5) are via reductions from previously known lower bounds for mean and covariance estimations. We state them below, starting with the mean estimation lower bound (aka "fingerprinting for Gaussian") result due to [27]

**Theorem A.6** ([27]).: _For any \(\epsilon,\delta\in(0,1]\) such that \(\delta\leq O\left(\frac{\sqrt{d}}{n\sqrt{\log(n/d)}}\right)\), if an \((\epsilon,\delta)\)-DP algorithm \(\mathcal{M}\) that can take in \(N\) samples from \(D=\mathsf{N}(\mu,I)\) where8\(-1\leq\mu\leq 1\) and output an estimate \(\hat{\mu}\in\mathbb{R}^{d}\) that satisfies_

Footnote 8: We write \(-1\leq\mu\leq 1\) as a shorthand for \(-1\leq\mu[j]\leq 1\) for all \(j\in[d]\).

\[\mathbb{E}_{\mathbf{X}\sim D^{N},\hat{\mu}\sim\mathcal{M}(\mathbf{X})}[\|\hat {\mu}-\hat{\mu}\|_{2}^{2}]\leq\gamma^{2}\leq d/6,\]

_then \(N\geq\Omega\left(\frac{d}{\gamma\epsilon}\right)\)._

Next is a similar lower bound but for covariance estimation. Notice that the lower bound on the sample complexity below is \(\Omega(d^{2}/\epsilon^{2})\) whereas the lower bound above is only \(\Omega(d/\epsilon)\) (for constant accuracy parameter \(\gamma\)).

**Theorem A.7** ([28]).: _There exists a small constant \(\xi>0\) such that the following holds: for any \(\epsilon,\delta\in(0,1]\) such that \(\delta\leq O\left(\min\left\{1/n,d^{2}/(n\log n)\right\}\right)\), if an \((\epsilon,\delta)\)-DP algorithm \(\mathcal{M}\) that can take in \(N\) samples from \(D=\mathsf{N}(0,\Sigma)\) where \(I\preceq\Sigma\preceq 2I\) and output an estimate \(\hat{\Sigma}\in\mathbb{R}^{d\times d}\) that satisfies_

\[\mathbb{E}_{\mathbf{X}\sim D^{N},\hat{\Sigma}\sim\mathcal{M}(\mathbf{X})}[\| \hat{\Sigma}-\Sigma\|_{\Sigma}^{2}]\leq\xi^{2},\]

_then \(N\geq\Omega\left(d^{2}/\epsilon\right)\)._

### Agnostic Learner

In the main body of the paper, we considered the learner where the samples are drawn from \(D\) which belongs to a certain class \(\mathcal{D}\). For our lower bound proofs, it will be convenient to consider the _agnostic_ setting where \(D\) is not assumed to be from \(\mathcal{D}\). The definition and accuracy guarantee of agnostic learner is given below. We remark that the definition coincides with the learner definition given earlier if we assume that \(D\in\mathcal{D}\). (Note that the constant 3 is required for Theorem A.8.)

**Agnostic Learning.** Let \(\mathcal{D}\) be a class of distribution. An algorithm \(\mathcal{A}\), which takes in \(n\) samples and output a distribution \(\hat{P}\in\mathcal{D}\), is said to be an \((\alpha,\beta)\)_-accurate agnostic learner_ for a class \(\mathcal{D}\) of distributions iff, for any distribution \(P\), we have

\[\Pr_{\mathbf{X}\sim P^{n},\hat{P}\leftarrow\mathcal{A}(\mathbf{X})}\left[d_{ \mathrm{tv}}(\hat{P},P)\leq 3\cdot\min_{P\in\mathcal{D}}d_{\mathrm{tv}}(D,P)+ \alpha\right]\geq 1-\beta.\]

We will use the following (well-known) result that the class of centered9 Gaussian distributions can be learned with sample complexity \(O(d^{2}/\gamma^{2})\). For a full proof, see e.g., [3].

Footnote 9: Recall that centered simply means that \(\mu=0\).

**Theorem A.8**.: _For any \(\gamma,\beta\in(0,1/2]\), there exists a \((\gamma,\beta)\)-accurate agnostic learner for centered Gaussian distributions in \(d\) dimensions with sample complexity_

\[O\left(\frac{d^{2}+\sqrt{\log(1/\beta)}}{\gamma^{2}}\right).\]

## Appendix B Proofs for Section 4

### Reduction to the Bounded Mean Case

The reduction will be done by applying a so-called "densest ball" algorithm; this is an algorithm that, when there is a ball of radius \(r\) that contains the majority of the input, can find a ball of radius \(O(r)\) containing the majority of the input. There are many algorithms known for this problem [23, 40, 33] that give similar guarantees10. We state such a guarantee below.

**Theorem B.1** (e.g., [23]).: _For \(n_{\mathrm{dens}}(d,\beta,\epsilon,\delta)=\tilde{\Theta}\left(\frac{\sqrt{d}}{ \epsilon}\right)\), there exists an \((\epsilon,\delta)\)-DP algorithm \(\mathcal{A}_{\mathrm{dens}}\) that takes in \(X_{1},\ldots,X_{n}\in\mathbb{R}^{d}\) together with a radius parameter \(r>0\) such that: if there is an \(r\)-radius ball containing at least \(2/3\) fraction of the input points, then with probability \(1-\beta\), it outputs a ball of radius \(O(r)\) that contains at least half of the input points._

We can now give a reduction of an arbitrary mean case to the bounded mean case by first using Theorem B.1 to obtain a rough estimate of the mean and then shifting the remaining samples accordingly.

Proof.: The new sampler works as follows:

* Let \(n_{1}:=\max\{n_{\mathrm{dens}}(d,\alpha/4,\epsilon/2,\delta/2),100\log(4/ \alpha)\},r=10C\kappa\sqrt{d}\) where \(C\) is the constant from Lemma 3.2, and \(n_{2}:=n_{\mathrm{bm-sampler}}(\alpha/2,r,\epsilon/2,\delta/2)\).
* _Rough Mean Estimator Stage:_
* Run \((\epsilon/2,\delta/2)\)-DP \(\mathcal{A}_{\mathrm{dens}}\) from Theorem B.1 on \(n_{1}\) samples (with \(r\) as specified above) to get a ball centered at \(c\in\mathbb{R}^{d}\).
* _Sampling Stage:_
* Draw \(n_{2}\) additional samples \(X_{1},\ldots,X_{n_{2}}\).
* Run \((\epsilon/2,\delta/2)\)-DP \((\alpha/2)\)-accurate \(\mathcal{A}_{\mathrm{bm-sampler}}\) with \(R=r\) on \((X_{1}-c),\ldots,(X_{n_{2}}-c)\); let \(Y\) be its output.
* Output \(Y+c\).

**Privacy Analysis.** Basic composition implies that the sampler is \((\epsilon,\delta)\)-DP as desired.

**Accuracy Analysis.** Since \(\Sigma\preceq\kappa I\), Lemma 3.2 implies that \(\Pr_{X\sim\mathsf{N}(\mu,\Sigma)}\|X-\mu\|_{2}\geq r]\leq 0.1\). Thus, using standard concentration inequality (e.g., Theorem E.1) and since \(n_{1}\geq 100\log(4/\alpha)\), the probability that at least \(2/3\) of the \(n_{1}\) points sampled in the first stage contains in the ball \(B(\mu,r)\) is at least \(1-\alpha/4\). The guarantee of the densest ball algorithm then implies that with probability \(1-\alpha/2\), we have \(\|\mu-c\|_{2}\leq r\).

Let us consider a fixed \(c\) and consider the output distribution \(\mathcal{D}_{Y}^{c}\) of \(Y\) in the sampling stage and \(\mathcal{D}_{Y+c}^{c}\) of the final output \(Y+c\). Notice that \((X_{1}-c),\ldots,(X_{n_{2}}-c)\sim\mathsf{N}(\mu-c,\Sigma)\). Consequently, when \(\|\mu-c\|_{2}\leq r\), we may apply the guarantee of \(\mathcal{A}_{\mathrm{bm-sampler}}\) to yield

\[\alpha/2\geq d_{\mathrm{tv}}(\mathcal{D}_{Y}^{c},\mathsf{N}(\mu-c,\Sigma))=d _{\mathrm{tv}}(\mathcal{D}_{Y+c}^{c},\mathsf{N}(\mu,\Sigma)).\]

Combining these arguments, the sampler is \(\alpha\)-accurate as desired. 

### Unknown Bounded Covariance

Proof of Lemma 4.4.: From Lemma 3.5, we have

\[d_{\epsilon}(\mathsf{Un}_{M,N}^{\mathbb{S}}\mid\mid\mathsf{Un}_{M,N}^{ \mathbb{S}}+v)\leq\Pr_{z\sim\mathsf{Un}_{M,N}^{\mathbb{S}}}[f_{\mathsf{Un}_{ M,N}^{\mathbb{S}}}(z)>e^{\epsilon}\cdot f_{\mathsf{Un}_{M,N}^{\mathbb{S}}}(z-v)].\]

For convenience, let us also define \(\eta=\tau\cdot\left(10\sqrt{\frac{\log(10/\delta)}{cM}}\right)\). Note that \(\eta\leq 0.01\).

For \(z\) such that \(\|z\|\leq 0.9,|\left<z,v\right>|\leq\eta\), we also have \(\|z-v\|^{2}\leq 0.9^{2}+0.02+0.0001<0.9\) and thus

\[\ln\frac{\mathsf{Un}_{M,N}^{\mathbb{S}}(z)}{\mathsf{Un}_{M,N}^{ \mathbb{S}}(z-v)}\overset{\eqref{eq:d_varvar}}{=} \left(\frac{M-N}{2}-1\right)\ln\left(\frac{1-\|z\|^{2}}{1-\|z-v \|^{2}}\right)\] \[\leq\left(\frac{M-N}{2}-1\right)\left(\frac{1-\|z\|^{2}}{1-\|z-v \|^{2}}-1\right)\] \[\leq\left(\frac{M-N}{2}-1\right)\left(\frac{\|v\|^{2}-2\left<z,v \right>}{1-\|z-v\|^{2}}\right)\] \[\leq M\left(10(\tau^{2}+2\eta)\right)\] \[\leq\epsilon,\]where the last inequality follows from our choice of parameters (i.e., \(M\geq\frac{10^{4}\log(10/\delta)}{ce}\)).

Combining the previous two bounds, we have

\[d_{\epsilon}(\mathsf{Un}_{M,N}^{\mathbb{S}}\mid\mid\mathsf{Un}_{M,N}^{\mathbb{S}}+v) \leq\Pr_{z\sim\mathsf{Un}_{M,N}^{\mathbb{S}}}[\|z\|>0.9\ \vee\ \langle z,v\rangle>\eta]\] \[\leq\Pr_{z\sim\mathsf{Un}_{M,N}^{\mathbb{S}}}[\|z\|>0.9]+\Pr_{z \sim\mathsf{Un}_{M,N}^{\mathbb{S}}}[\langle z,v\rangle>\eta]\] \[\leq\Pr_{z\sim\mathsf{Un}_{M,N}^{\mathbb{S}}}[\|z\|>0.9]+\Pr_{z \sim\mathsf{Un}_{M,N}^{\mathbb{S}}}\left[\left\langle z,\frac{v}{\|v\|}\right\rangle >10\sqrt{\frac{\log(10/\delta)}{cM}}\right].\]

Next, recall that when \(z\sim\mathsf{Un}_{M,N}^{\mathbb{S}}\), \(\|z\|^{2}\sim\mathsf{Beta}(N/2,(M-N)/2)\).11 Thus, applying Lemma 3.3 and using the assumption that \(N\leq M/2\), we can conclude that

Footnote 11: See, e.g., https://en.wikipedia.org/wiki/Beta_distribution

\[\Pr_{z\sim\mathsf{Un}_{M,N}^{\mathbb{S}}}[\|z\|>0.9]=\Pr_{Z\sim\mathsf{Beta} (N/2,(M-N)/2)}[Z^{2}>0.81]\leq 2\exp(-c\cdot 0.01M)\leq\delta/2,\]

where the first inequality is from Lemma 3.3 and the last inequality follows from our assumption that \(M\geq 100c\log(10/\delta)\).

Recall also that when \(z\sim\mathsf{Un}_{M,N}^{\mathbb{S}}\), \(\left|\left\langle z,\frac{v}{\|v\|}\right\rangle\right|^{2}\sim\mathsf{Beta} (1/2,(M-1)/2)\). Again, applying Lemma 3.3 yields

\[\Pr_{z\sim\mathsf{Un}_{M,N}^{\mathbb{S}}}\left[\left\langle z,\frac{v}{\|v\|} \right\rangle>10\sqrt{\frac{\log(10/\delta)}{cM}}\right]\leq\Pr_{Z\sim\mathsf{ Beta}(1/2,(M-1)/2)}\left[Z^{2}>\frac{100\log(10/\delta)}{cM}\right]\leq\delta/2,\]

where the last inequality again follows from our choice of parameters.

Combining the three preceding inequalities, we can conclude that \(d_{\epsilon}(\mathsf{Un}_{M,N}^{\mathbb{S}}\mid\mid\mathsf{Un}_{M,N}^{ \mathbb{S}}+v)\leq\delta\) as desired. 

### Unknown Covariance

Throughout this section, we assume the standard assumption that the covariance matrix \(\Sigma\) is full rank. It is simple to extend the result to the more general case using an algorithm of [4], which can identify the span of \(\Sigma\) with probability one, using \(O(d\log(1/\delta)/\epsilon)\) samples.

As stated earlier, we will use DP preconditioner from [9]. We say that an algorithm is an \((\alpha,\beta)\)-_accurate preconditioner for Gaussian distributions_ iff, when the input \(\mathbf{X}\) is drawn i.i.d. from \(\mathsf{N}(\mu,\Sigma)\) (for any \(\mu\in\mathcal{R}^{d},\Sigma\in\mathcal{R}^{d\times d}\)), the algorithm outputs \(\hat{\mu},\hat{\Sigma}\) that satisfies the following with probability at least \(1-\beta\): \(\|\hat{\Sigma}^{-1}(\hat{\mu}-\mu)\|_{2}\leq\alpha\) and12\(\|\Sigma^{-1/2}\hat{\Sigma}\Sigma^{-1/2}-I\|_{2}\leq\alpha\). Below we provide a generic reduction from the unbounded covariance case to the bounded covariance case using preconditioner.

Footnote 12: The guarantee here is in the spectral norm, not Frobenius norm. However, this suffices for our purposes.

**Lemma B.2**.: _Suppose that the following hold:_

* _There exists an_ \((\alpha,\beta)\)_-accurate_ \((\epsilon,\delta)\)_-DP preconditioner for Gaussian distributions with sample complexity_ \(n_{\mathrm{precnd}}(\alpha,\beta,\epsilon,\delta)\)_._
* _There exists an_ \(\alpha\)_-accurate_ \((\epsilon,\delta)\)_-DP sampler_ \(\mathcal{A}_{\mathrm{bc-sampler}}\) _for Gaussian distributions with_ \(I\preceq\Sigma\preceq\kappa\cdot I\) _with sample complexity_ \(n_{\mathrm{bc-sampler}}(\kappa,\alpha,\epsilon,\delta)\)_._

_Then, there exists an \(\alpha\)-accurate \((\epsilon,\delta)\)-DP sampler for Gaussian (without any assumption) with sample complexity_

\[n_{\mathrm{precnd}}(0.001,\alpha/2,\epsilon/2,\delta/2)+n_{\mathrm{bc-sampler}}(4, \alpha/2,\epsilon/2,\delta/2).\]

Proof of Lemma b.2.: The sampler is as follows:

* Let \(n_{1}:=n_{\mathrm{precnd}}(0.001,\alpha/2,\epsilon/2,\delta/2)\) and \(n_{2}:=n_{\mathrm{bc-sampler}}(4,\alpha/2,\epsilon/2,\delta/2)\).
* _Estimation Stage:_* Run \((\epsilon/2,\delta/2)\)-DP \((0.001,\alpha/2)\)-accurate \(\mathcal{A}_{\rm precnd}\) on \(n_{1}\) samples to get \(\hat{\mu},\hat{\Sigma}\).
* _Sampling Stage:_
* Draw \(n_{2}\) additional samples \(X_{1},\ldots,X_{n_{2}}\).
* Run \((\epsilon/2,\delta/2)\)-DP \((\alpha/2)\)-accurate \(\mathcal{A}_{\rm bc-sampler}\) on \(2\hat{\Sigma}^{-1/2}(X_{1}-\hat{\mu}),\ldots,2\hat{\Sigma}^{-1/2}(X_{n_{2}}- \hat{\mu})\); let \(Y\) be its output.
* Output \(0.5\hat{\Sigma}^{1/2}Y+\hat{\mu}\).

Basic composition implies that the sampler is \((\epsilon,\delta)\)-DP.

To see the accuracy guarantee, the guarantee of the learner implies that with probability \(1-\alpha/2\), we have \(\|\hat{\Sigma}^{-1}(\hat{\mu}-\mu)\|_{2}\leq 0.001\) and \(\|\Sigma^{-1/2}\hat{\Sigma}\Sigma^{-1/2}-I\|_{2}\leq 0.001\). The latter implies that all eigenvalues of \(\hat{\Sigma}^{1/2}\Sigma^{-1/2}\) lie in [0.998, 1.002]; in turn, this implies that the eigenvalues of \(\hat{\Sigma}^{-1/2}\Sigma^{1/2}\) all lie in \([0.996,1.004]\). Finally, this implies that \(\|\Sigma^{1/2}\hat{\Sigma}^{-1}\Sigma^{1/2}-I\|_{2}\leq 0.01\).

Let us consider a fixed \(\hat{\Sigma},\hat{\mu}\) and consider the output distribution of the sampling stage. When the above inequalities hold, the guarantee of \(\mathcal{A}_{\rm bc-sampler}\) implies that

\[\alpha/2\geq d_{\rm tv}(Y,\mathsf{N}(2\hat{\Sigma}^{-1/2}(\mu-\hat{\mu}),4 \Sigma^{1/2}\hat{\Sigma}^{-1/2}))=d_{\rm tv}(0.5\hat{\Sigma}^{1/2}Y+\hat{\mu},\mathsf{N}(\mu,\Sigma)).\]

Combining the above arguments, the sampler is \(\alpha\)-accurate as desired. 

Combining the above reduction (Lemma B.2) together with a known result on DP preconditioner of Gaussians (Theorem B.3 below), we immediately arrive at Theorem 1.6.

**Theorem B.3** ([8]).: _There is an \((\alpha,\beta)\)-accurate \((\epsilon,\delta)\)-DP preconditioner for Gaussian distributions with sample complexity \(O\left(\frac{d}{\alpha^{2}}+\frac{d^{3/2}}{\alpha\epsilon}\cdot\mathrm{polylog }\left(\frac{d}{\alpha\beta\epsilon\delta}\right)\right)\)._

### Proof of Theorem 4.3

We use Algorithm 2 with the following parameters: \(B=R+10^{4}\kappa\sqrt{d+\log\left(\frac{2\log(2/\delta)}{\alpha\epsilon} \right)}\), \(\Delta=2B^{2}\), and \(n_{1}=n_{2}=\left\lceil 10^{4}C^{2}\left(B^{2}\cdot\frac{\log(10/\delta)}{c \epsilon}\right)\right\rceil\), where \(c,C\) are the constants from Lemmas 3.3 and 3.4.

**Privacy Analysis.** To analyze the privacy constraint, we first notice that the sensitivity of \(\lambda_{\min}\left(\sum_{i\in[n_{2}]}U_{i}U_{i}^{T}\right)\) is at most \(\Delta=(\sqrt{2}\cdot B)^{2}\) and Lemma 3.1 ensures that the check, which only uses \(\lambda_{\min}\left(\sum_{i\in[n_{2}]}U_{i}U_{i}^{T}\right)+r\), is \((\epsilon/2,\delta/2)\)-DP. Passing this check ensures that

\[\lambda_{\min}\cdot\left(\sum_{i\in[n_{2}]}U_{i}U_{i}^{T}\right)\geq 0.75n_{2}.\] (3)

From Lemma 3.8, it suffices to show that the output of the algorithm is DP, under (3). Let \(\mathbf{X}=X_{1},\ldots,X_{n_{1}+2n_{2}}\).

To do this, it will be more convenient to define \(V_{i}=\sqrt{1-\frac{1}{n_{1}}}\cdot U_{i}\). Condition (3) implies that

\[\lambda_{\min}\left(\sum_{i\in[n_{2}]}V_{i}V_{i}^{T}\right)\geq 0.5n_{2}+\Delta.\] (4)

Let \(\mathcal{M}(\mathbf{X})=\frac{1}{n_{1}}\left(\sum_{i\in[n_{1}]}X_{i}^{\text{ trunc}}\right)+\left(\sum_{i\in[n_{2}]}a[i]\cdot V_{i}\right)\). Consider any neighboring inputs \(\mathbf{X}\) and \(\tilde{\mathbf{X}}\) that satisfy the condition. There are two cases, based on where they differ.

(i) _Case I:_\(\mathbf{X},\tilde{\mathbf{X}}\) differ on the first \(n_{1}\) samples. Let \(v=\frac{1}{n_{1}}\sum_{i\in[n_{1}]}(\tilde{X}_{i}^{\text{trunc}}-X_{i})\); notice that \(\|v\|\leq\frac{2B}{n_{1}}\). Furthermore, (4) implies that \(\frac{1}{n_{2}}\left(\sum_{i\in[n_{2}]}V_{i}V_{i}^{T}\right)\succeq 0.5I\). Letting \(W\) denote the matrix whose columns are \(V_{1},\ldots,V_{n_{2}}\), \(d_{\frac{\epsilon}{2}}\left(\mathcal{M}(\mathbf{X})\parallel\mathcal{M}(\tilde{ \mathbf{X}})\right)=d_{\frac{\epsilon}{2}}\left(\mathsf{Uni}_{W}^{\mathbb{S}} \parallel\mathsf{Uni}_{W}^{\mathbb{S}}+v\right)\leq\delta/2\), where the inequality follows from Lemma 4.5.

(ii) _Case II:_\(\mathbf{X},\tilde{\mathbf{X}}\) differ on the last \(n_{2}\) samples; assume w.l.o.g. \(X_{n_{1}+2n_{2}}\neq\tilde{X}_{n_{1}+2n_{2}}\). Let \(w=V_{n_{2}}^{\prime}-V_{n_{2}}\) and \(W\) denote the matrix whose columns are \(V_{1},\ldots,V_{n_{2}-1}\). Furthermore, let \(a,a^{\prime}\) be independent samples from \(\mathsf{Un}_{q}^{\mathbb{S}}\).

\[d_{\frac{\varepsilon}{2}}\left(\mathcal{M}(\mathbf{X})\;||\; \mathcal{M}(\tilde{\mathbf{X}})\right) =d_{\frac{\varepsilon}{2}}\left(a[n_{2}]\cdot V_{n_{2}}+\sum_{i \in[n_{2}-1]}a[i]\cdot V_{i}\;\middle|\;a^{\prime}[n_{2}]\cdot V_{n_{2}}^{ \prime}+\sum_{i\in[n_{2}-1]}a^{\prime}[i]\cdot V_{i}\right)\] \[\leq\int_{y}d_{\frac{\varepsilon}{2}}\left(\mathsf{Un}_{W}^{ \mathbb{S}}\;\middle|\;\middle|\;\frac{y\cdot w}{\sqrt{1-y^{2}}}+\mathsf{Un}_{ W}^{\mathbb{S}}\right)\mathsf{Un}_{n_{2},1}^{\mathbb{S}}(y)dy,\] (5)

where the inequality follows from the coupling \(a[n_{2}]=a^{\prime}[n_{2}]=y\), \(a[n_{2}]\sim\mathsf{Un}_{n_{2},1}^{\mathbb{S}}\) and the observation that \(\left(\frac{a[1]}{\sqrt{1-y^{2}}},\ldots,\frac{a[n_{2}-1]}{\sqrt{1-y^{2}}}\right)\) and \(\left(\frac{a^{\prime}[1]}{\sqrt{1-y^{2}}},\ldots,\frac{a^{\prime}[n_{2}-1]}{ \sqrt{1-y^{2}}}\right)\) are independently distributed as \(\mathsf{Un}_{n_{2}-1}^{\mathbb{S}}\).

When \(|y|\leq\sqrt{\frac{10\log(10/\delta)}{cn_{2}}}\), we have \(\left\|\frac{y\cdot w}{\sqrt{1-y^{2}}}\right\|\leq\sqrt{\frac{20\log(10/\delta )}{cn_{2}}}\cdot\sqrt{2}\cdot B\leq 20\sqrt{\frac{\log(10/\delta)}{c}}\). Furthermore, (4) implies that \(\frac{1}{n_{2}}\left(\sum_{i\in[n_{2}-1]}V_{i}V_{i}^{T}\right)\succeq 0.5I\). Thus, Lemma 4.5 implies

\[d_{\epsilon/2}\left(\mathsf{Un}_{W}^{\mathbb{S}}\;\middle|\;\middle|\;\frac{y \cdot w}{\sqrt{1-y^{2}}}+\mathsf{Un}_{W}^{\mathbb{S}}\right)\leq\delta/4.\]

Combining this with (5), we arrive at \(d_{\epsilon/2}\left(\mathcal{M}(\mathbf{X})\;||\;\mathcal{M}(\tilde{\mathbf{X }})\right)\leq\delta/4+\Pr_{y\sim\mathsf{Un}_{n_{2},1}^{\mathbb{S}}}\left[|y|> \sqrt{\frac{10\log(10/\delta)}{cn_{2}}}\right].\) Since \(y^{2}\sim\mathsf{Beta}(1/2,(n_{2}-1)/2)\), we may apply the tail bound (Lemma 3.3) to get

\[\Pr\left[y^{2}>\frac{10\log(10/\delta)}{cn_{2}}\right]\leq\delta/4.\]

Thus, \(d_{\epsilon/2}\left(\mathcal{M}(\mathbf{X})\;||\;\mathcal{M}(\tilde{\mathbf{ X}})\right)\leq\delta/4+\delta/4=\delta/2\).

In both cases, we have \(d_{\epsilon/2}\left(\mathcal{M}(\mathbf{X})\;||\;\mathcal{M}(\tilde{\mathbf{ X}})\right)\leq\delta/2\) under (3). This concludes our privacy proof.

**Accuracy Analysis.** Let \(D=\mathsf{N}(\mu,\Sigma)\) for some unknown \(\mu,\Sigma\). Consider the algorithm \(\mathcal{A}^{\prime}\) where there is no truncation and no halting. Since \(I\preceq\Sigma\preceq\kappa\cdot I\), standard concentration bounds (Lemmas 3.2 and 3.4) imply that the truncation and halting are not applied in \(\mathcal{A}\) with probability at least \(1-\alpha/2\). Therefore, we have \(d_{\mathrm{tv}}(Q_{\mathcal{A},D},Q_{\mathcal{A}^{\prime},D})\leq\alpha/2\).

Now, notice that the algorithm \(\mathcal{A}^{\prime}\) just outputs \(Y:=\frac{1}{n_{1}}\left(\sum_{i\in[n_{1}]}X_{i}\right)+\sqrt{1-\frac{1}{n_{1}} }\cdot\left(\sum_{i\in[n_{2}]}a_{i}U_{i}\right)\); this output \(Y\sim\mathsf{N}(\mu,\Sigma)\). In other words, we have \(Q_{\mathcal{A}^{\prime},D}=\mathsf{N}(\mu,\Sigma)\). Combining these, we can conclude that \(\mathcal{A}\) is \(\alpha\)-accurate.

## Appendix C A Simpler but Worse Algorithm for Unknown Bounded Covariance

In this section, we give a simpler algorithm for the unknown bounded covariance setting. Its sample complexity bound of \(\tilde{O}\left(\frac{d^{3/2}}{\alpha\epsilon^{2}}\right)\) is worse than the one in Algorithm 2 and Theorem 4.3, but is still better than \(\Omega\left(\frac{d^{2}}{\alpha^{2}}+\frac{d^{2}}{\alpha\epsilon}\right)\) for DP learning [27] for constant \(\epsilon>0\).

The simpler sampler is given in Algorithm 3 and its guarantee is given in the theorem below. Note that this algorithm is once again just a form of (scaled) Gaussian mechanism, whereas the algorithm in the main body (Algorithm 2) adds noise that is input dependent.

**Theorem C.1**.: _Assume that \(I\preceq\Sigma\preceq\kappa\cdot I\) for some \(\kappa>0\) and that \(\|\mu\|\leq R\), there is an \(\alpha\)-accurate \((\epsilon,\delta)\)-DP sampler with sample complexity_

\[n=O\left(\left(R^{2}+\kappa^{2}d\left(\log\left(\frac{d}{\alpha\epsilon}\right)+ \log\log(1/\delta)\right)\right)\cdot\frac{d^{1/2}}{\alpha}\cdot\frac{\log(1/ \delta)}{\epsilon^{2}}\right).\]

``` Parameters:\(B,\sigma>0\), and \(n_{1},n_{2}\in\mathbb{N}\).  Sample \(X_{1},\ldots,X_{n_{1}},X_{n_{1}+1},\ldots,X_{n_{1}+2n_{2}}\sim D\) for\(i=1,\ldots,n_{1}+2n_{2}\)do \(X_{i}=\text{trunc}_{B}^{2}(X_{i})\)  Sample \(Z\sim\mathsf{N}(0,\sigma^{2}I)\) return\(\frac{1}{n_{1}}\left(\sum_{i\in[n_{1}]}X_{i}\right)+\sqrt{\frac{1-1/n_{1}}{2n_{2}}} \left(\sum_{i\in[n_{2}]}(X_{n_{1}+2i-1}-X_{n_{1}+2i})\right)+Z\) ```

**Algorithm 3**BoundedCovarianceGaussianSampler

Proof Sketch of Theorem c.1.: Let \(B=R+10^{4}\kappa\sqrt{d\left(\log\left(\frac{2d}{\alpha\epsilon}\right)+\log \log(2/\delta)\right)},\sigma=\frac{\sqrt{\alpha}}{2d^{1/4}}\) and \(n_{1},n_{2}\) be such that \(n_{1}=n_{2}\geq\frac{100B^{2}\log(2/\delta)}{\sigma^{2}\epsilon^{2}}\). Let \(\mathcal{A}\) denote Algorithm 3 with parameters \(B,n,\sigma\) as specified.

**Privacy Analysis.**\(\mathcal{A}\) is the Gaussian mechanism with noise multiplier \(\frac{\sigma}{B\cdot\sqrt{\frac{1-1/n_{1}}{2n_{2}}}}\geq 10\sqrt{\log(2/\delta)}/\epsilon\) by the setting of our parameters; therefore, \(\mathcal{A}\) is \((\epsilon,\delta)\)-DP.

**Accuracy Analysis.** To understand the accuracy guarantee, let \(D=\mathsf{N}(\mu,\Sigma)\) for some unknown \(\mu,\Sigma\) where \(I\preceq\Sigma\preceq\kappa\cdot I\). Let us consider the algorithm \(\mathcal{A}^{\prime}\) where there is no truncation. Again, a standard concentration bound implies that the truncation is not applied anyway in \(\mathcal{A}\) with probability at least \(1-\alpha/2\). Therefore, we have

\[d_{\text{tv}}(Q_{\mathcal{A},P},Q_{\mathcal{A}^{\prime},P})\leq\alpha/2.\]

Now, notice that in algorithm \(\mathcal{A}^{\prime}\), we just output

\[Y:=\frac{1}{n_{1}}\left(\sum_{i\in[n_{1}]}X_{i}\right)+\sqrt{\frac{1-1/n_{1}} {2n_{2}}}\left(\sum_{i\in[n_{2}]}(X_{n_{1}+2i-1}-X_{n_{1}+2i})\right)+Z.\]

Without truncation, this output \(Y\) has identical distribution as \(\mathsf{N}(\mu,\Sigma+\sigma^{2}I)\). In other words, we have

\[d_{\text{tv}}(Q_{\mathcal{A}^{\prime},P},\mathsf{N}(\mu,\Sigma))=d_{\text{tv} }(\mathsf{N}(\mu,\Sigma+\sigma^{2}I),\mathsf{N}(\mu,\Sigma))\leq\|\sigma^{2} I\|_{\Sigma}\leq\|\sigma^{2}I\|_{F}=\sigma^{2}\cdot\sqrt{d}\leq\alpha/2,\]

where the first inequality follows from Lemma A.3 and the last inequality follows from our parameter selection. Combining the above two inequalities, we can conclude that the sampler is \(\alpha\)-accurate as desired. 

## Appendix D Gaussian Distributions: Lower Bounds

### Known Covariance

In this section, we prove a lower bound of \(\Omega(\sqrt{d}/\epsilon)\) that holds even for the simplest case of known covariance (Theorem 1.3), showing that the dependence on \(d\) in our sampler (Theorem 4.2) is nearly optimal.

We prove this by using a DP sampler to draw a large, but constant, number of samples and the use them to perform mean estimation; the lower bound for mean estimation (Theorem A.6) then gives the desired lower bound for the sample complexity of DP sampler.

Proof of Theorem 1.3.: Given an \(\alpha\)-accurate \((\epsilon,\delta)\)-DP sampler \(\mathcal{A}\), we construct an algorithm \(\mathcal{M}\) for mean estimation as follows:* For \(i=1,\ldots,10^{6}\):
* Run \(\mathcal{A}\) on \(n\) fresh samples from \(D\) to get \(Y_{i}\).
* Output \(\hat{\mu}\in\mathbb{R}^{d}\) with \(\hat{\mu}[j]:=\text{clip}_{-1,1}(\text{median}(Y_{1}[j],\ldots,Y_{10^{6}}[j]))\)

Since \(\mathcal{A}\) is \(\alpha\)-accurate, each \(Y_{i}\) is sampled from a distribution \(D^{\prime}\) that is \(\alpha\)-close (in total variation distance) to \(D=\mathsf{N}(\mu,I)\). For \(\alpha=0.1\), this means that

\[\Pr[Y_{i}(j)\leq\mu-0.3]\leq\Phi(-0.3)+\alpha\leq 0.49,\]

and similarly,

\[\Pr[Y_{i}(j)\geq\mu+0.3]\leq(1-\Phi(0.3))+\alpha\leq 0.49.\]

As a result, standard concentration bounds (e.g., Theorem E.1) imply that

\[\Pr[\text{median}(Y_{1}(j),\ldots,Y_{10^{6}}(j))\in[\mu-0.3,\mu+0.3]]>0.99.\]

This in turn implies that

\[\mathbb{E}_{\mathbf{X}\sim D^{N},\hat{\mu}\sim\mathsf{M}(\mathbf{X})}[\|\hat{ \mu}-\mu\|_{2}^{2}]\leq d\cdot\left(0.01\cdot 2^{2}+0.99\cdot 0.3^{2}\right) \leq d/6.\]

Applying Theorem A.6 with \(\gamma=\sqrt{d/6}\), we can conclude that the sample complexity of \(\mathcal{M}\) (which is equal to \(10^{6}n\)) must be at least \(\Omega\left(\frac{d}{\epsilon\sqrt{d/6}}\right)=\Omega(\sqrt{d}/\epsilon)\). Thus, we must have \(n\geq\Omega(\sqrt{d}/\epsilon)\) as claimed. 

### Unknown Bounded Covariance

Next, we will prove the lower bound for the unknown bounded covariance case (Theorem 1.5).

#### d.2.1 Reduction to Covariance Estimation

**Parameters:**\(N,n,L\in\mathbb{N}\), sampler \(\mathcal{A}_{\mathrm{sampler}}\), agnostic learner \(\mathcal{A}_{\mathrm{learner}}\) for centered Gaussians

Sample \(X_{1},\ldots,X_{N}\sim P\)

**for**\(\ell=1,\ldots,L\)**do**

Randomly draw \(n\) subsamples \(X_{i_{1}^{\ell}},\ldots,X_{i_{n}^{\ell}}\) without replacement from \(X_{1},\ldots,X_{N}\)

\(Y_{\ell}\leftarrow\mathcal{A}_{\mathrm{sampler}}(X_{i_{1}^{\ell}},\ldots,X_{i_{n }^{\ell}})\)

\(\mathsf{N}(0,\hat{\Sigma})\leftarrow\mathcal{A}_{\mathrm{learner}}(Y_{1}, \ldots,Y_{L})\)

**if**\(0.5I\preceq\hat{\Sigma}\preceq 2.5I\)**then**

\(\hat{\Sigma}^{\prime}\leftarrow\hat{\Sigma}\)

**else**

\(\hat{\Sigma}^{\prime}\gets I\)

**return**\(\hat{\Sigma}^{\prime}\)

**Algorithm 4** CovarianceEstimator

As stated earlier in Section 2, we will prove this lower bound by reducing to covariance estimation (Theorem A.7). This is done by first taking \(N\gg n\) samples, and then generating each \(Y_{\ell}\) by subsampling the input to \(n\) samples and running our DP sampler. These \(Y_{\ell}\)'s are then feed into the agnostic learner to produce an estimate \(\hat{\Sigma}\) for \(\Sigma\). The full reduction is given in Algorithm 4. Note that here \(\mathcal{A}_{\mathrm{sampler}}\) will be the \((\epsilon,\delta)\)-DP sampler and \(\mathcal{A}_{\mathrm{learner}}\) will be the learner from Theorem A.8.

**Privacy Analysis.** The privacy guarantee of Algorithm 4 follows easily from the amplification by subsampling and advanced composition of DP. This is formalized below.

**Lemma D.1**.: _For any \(\epsilon^{*}\in(0,1],\delta^{*}\in(0,1)\), if \(\mathcal{A}_{\mathrm{sampler}}\) is \((\epsilon,\delta)\)-DP for \(\epsilon\leq\min\left\{1,\frac{\epsilon^{*}N}{4n\sqrt{L\ln(2/\delta^{*})}} \right\},\delta\leq\left(\frac{0.5N}{Ln}\right)\delta^{*}\), then Algorithm 4 is \((\epsilon^{*},\delta^{*})\)-DP._

Proof.: First, we apply Theorem A.4 which means that computing a single \(Y_{\ell}\) is \((\epsilon^{\prime},\delta^{\prime})\)-DP where

\[\epsilon^{\prime} =\ln(1+(n/N)(e^{\epsilon}-1)), \delta^{\prime} =(n/N)\cdot\delta.\]Then, applying Theorem A.5 with \(\delta_{1}=0.5\delta^{*}\) implies that all \((Y_{1},\dots,Y_{L})\) together is \((\epsilon_{1},L\delta^{\prime}+\delta_{1})\)-DP where

\[\epsilon_{1}=\left(\sqrt{2L\ln(1/\delta_{1})}+L(e^{\epsilon^{\prime}}-1) \right)\epsilon^{\prime}.\]

Combining the above expressions, we have

\[\epsilon_{1} =\left(\sqrt{2L\ln(2/\delta^{*})}+L(n/N)(e^{\epsilon}-1)\right) \ln(1+(n/N)(e^{\epsilon}-1))\] \[(\text{from }\epsilon\leq 1) \leq\left(\sqrt{2L\ln(2/\delta^{*})}+L(n/N)(2\epsilon)\right) \ln(1+(n/N)(2\epsilon))\] \[\leq\left(\sqrt{2L\ln(2/\delta^{*})}+L(n/N)(2\epsilon)\right) \cdot((n/N)(2\epsilon))\] \[\left(\text{from }\epsilon\leq\frac{\epsilon^{*}N}{4n\sqrt{L\ln(2/ \delta^{*})}}\right) \leq\epsilon^{*},\]

and \(L\delta^{\prime}+\delta_{1}\leq\delta^{*}/2+\delta^{*}/2\leq\delta^{*}\). In other words, \((Y_{1},\dots,Y_{L})\) together is \((\epsilon^{*},\delta^{*})\)-DP. Finally, applying \(\mathcal{A}_{\text{learner}}\) on \((Y_{1},\dots,Y_{L})\) is simply a post-processing step. Thus, the entire algorithm is \((\epsilon^{*},\delta^{*})\)-DP as desired. 

#### d.2.2 Accuracy Analysis

Next, we argue that the accuracy of the covariance estimation algorithm, assuming the accuracy of the sampler and the agnostic learner.

**Lemma D.2**.: _Let \(\xi\in(0,0.01]\) and \(n,N,L\in\mathbb{N}\) be such that \(N\geq\left(\frac{10nLd}{\xi}\right)^{2}\), and suppose that \(I\preceq\Sigma\preceq 2I\). Furthermore, suppose that_

* \(\mathcal{A}_{\mathrm{sampler}}\) _is an_ \(\left(\frac{\xi}{10C}\right)\)_-accurate sampler for the class of Gaussians under the assumption_ \(I\preceq\Sigma\preceq 2I\)_, and_
* \(\mathcal{A}_{\mathrm{learner}}\) _is an_ \(\left(\frac{\xi}{10C},\frac{\xi^{2}}{200d^{2}}\right)\)_-accurate agnostic learner for the class of centered Gaussians,_

_where \(C\) is the constant in Lemma A.2. Then, \(\mathbb{E}[\|\hat{\Sigma}^{\prime}-\Sigma\|_{\Sigma}^{2}]\leq\xi^{2}\) where \(\hat{\Sigma}^{\prime}\) denotes the output of Algorithm 3._

Proof.: Let \(D=\mathsf{N}(0,\Sigma)\) denote the underlying distribution and for notational convenience, let \(\zeta:=\left(\frac{\xi}{10C}\right)\). Let \(\mathcal{E}_{\mathrm{disjoint}}\) denote the event that \(i_{1}^{1},\dots,i_{n}^{L}\) are all different. Note that we have

\[\Pr[\neg\mathcal{E}_{\mathrm{disjoint}}]\leq\sum_{\ell\neq\ell^{\prime}\in[ L],j,j^{\prime}\in[n]}\Pr[i_{j}^{\ell}=i_{j^{\prime}}^{\ell^{\prime}}]=\sum_{ \ell\neq\ell^{\prime}\in[L],j,j^{\prime}\in[n]}\frac{1}{N^{2}}\leq\frac{L^{2} n^{2}}{2N}\leq\frac{\xi^{2}}{200d^{2}},\]

where the last inequality follows from our choice of parameters.

Next, suppose that \(\mathcal{E}_{\mathrm{disjoint}}\) holds. Then, we have that \(Y_{1},\dots,Y_{L}\) are independently sampled from \(Q_{\mathcal{A}_{\mathrm{sampler}},D}\). Applying the agnostic learning guarantee of \(\mathcal{A}_{\mathrm{learner}}\), with probability \(1-\frac{\xi^{2}}{200d^{2}}\), we get

\[d_{\mathrm{tv}}(\mathsf{N}(0,\hat{\Sigma}),Q_{\mathcal{A}_{\mathrm{sampler}},D})\leq 3\cdot d_{\mathrm{tv}}(\mathsf{N}(0,\Sigma),Q_{\mathcal{A}_{\mathrm{sampler}},D})+\zeta.\]

Recall also from the accuracy guarantee of the sampler that \(d_{\mathrm{tv}}(\mathsf{N}(0,\Sigma),Q_{\mathcal{A}_{\mathrm{sampler}},D})\leq\zeta\).

Combining all of these together we have

\[\Pr[d_{\mathrm{tv}}(\mathsf{N}(0,\hat{\Sigma}),Q_{\mathcal{A}_{\mathrm{sampler }},D})>4\zeta]\leq 1-\frac{\xi^{2}}{100d^{2}}.\]

Applying Lemma A.2, we get

\[\Pr[\|\hat{\Sigma}-\Sigma\|_{\Sigma}>\xi/2]\leq 1-\frac{\xi^{2}}{100d^{2}}.\]

Notice that if \(\|\hat{\Sigma}-\Sigma\|_{\Sigma}\leq\xi/2\), then we have \(\hat{\Sigma}^{\prime}=\hat{\Sigma}\). Furthermore, \(I\preceq\Sigma\preceq 2I\) and \(0.5I\preceq\hat{\Sigma}^{\prime}\preceq 2.5I\) imply that \(\|\hat{\Sigma}^{\prime}-\Sigma\|_{\Sigma}\leq 6d\). Thus, we have

\[\mathbb{E}[\|\hat{\Sigma}^{\prime}-\Sigma\|_{\Sigma}^{2}]\leq(\xi/2)^{2}+(6d)^ {2}\cdot\Pr[\|\hat{\Sigma}-\Sigma\|_{\Sigma}>\xi/2]\leq(\xi/2)^{2}+(6d)^{2} \cdot\frac{\xi^{2}}{100d^{2}}\leq\xi^{2}.\qed\]

#### d.2.3 Putting Things Together

Combing the privacy and accuracy guarantees and plugging in the appropriate parameters immediately yields Theorem 1.5.

Proof of Theorem 1.5.: Let \(\alpha=\xi/(10C)\) where \(\xi\) is as in Theorem A.7 and \(C\) is as in Lemma A.2. Suppose for the sake of contradiction that there exists an \((\epsilon,\delta)\)-DP \(\alpha\)-accurate sampler with sample complexity \(n=o\left(\frac{d}{\epsilon\sqrt{\log d}}\right)\) under the assumption \(I\preceq\Sigma\preceq 2I\). Then, let us select the parameters as follows:

* \(L\leq O\left(d^{2}\right)\) denote the sample complexity of the \(\left(\frac{\xi}{10C},\frac{\xi^{2}}{200d^{2}}\right)\)-accurate agnostic learner for the class of centered Gaussians as given by Theorem A.8.
* \(N=\left\lceil\left(\frac{10nLd}{\xi}\right)^{2}\right\rceil\leq O\left(n^{2}d^ {2}\log d\right)\).
* \(\delta^{*}=O\left(\min\left\{1/N,d^{2}/(N\log N)\right\}\right)\). Note that, when the constant in big-O notation is sufficiently large, our choice of parameters implies that \(\delta\leq\left(\frac{0.5N}{Ln}\right)\delta^{*}\).
* \(\epsilon^{*}=\frac{4ne\sqrt{L\ln(2/\delta^{*})}}{N}=o(d^{2}/N)\).

By Lemma D.2, we have that \(\mathbb{E}[\|\hat{\Sigma}^{\prime}-\Sigma\|_{\Sigma}^{2}]\leq\xi^{2}\). Furthermore, by Lemma D.1, we have that the algorithm CovarianceEstimator is \((\epsilon^{*},\delta^{*})\)-DP. However, we also have \(N=o(d^{2}/\epsilon^{*})\), which contradicts Theorem A.7. 

## Appendix E Product Distributions on \(\{0,1\}^{d}\)

In this section, we describe and analyze our sampler for product distributions on \(\{0,1\}^{d}\) (Theorem 1.7). We may assume w.l.o.g. that \(p_{1},\ldots,p_{d}\leq 3/4\). (Otherwise, we first privately estimate \(p_{i}\) using, e.g., the Laplace mechanism, and flip the \(i\)th bit in all samples if the estimate is more than \(3/4\).)

Given a dataset element \(X_{i}\in\{0,1\}^{d}\), we use \(X_{i}[j]\) to denote its \(j\)th coordinate, and \(X_{i}[S]=(X_{i}[j])_{j\in S}\) to denote the vector \(X_{i}\) restricted to the subset \(S\subseteq[d]\) of coordinates.

### Additional Preliminaries

Here we list a few concentration inequalities that are useful. We start with the following version of the Bernstein inequality (see, e.g., 42, Theorem 2.8.4):

**Theorem E.1** (Bernstein's inequality).: _Let \(Y_{1},\ldots,Y_{n}\) be independent real-valued random variables such that, with probability 1, \(Y_{i}\in[0,C]\) for all \(i\in[n]\). Let \(V=\sum_{i\in[n]}\mathrm{var}(Y_{i})\). Then, for any \(\Delta\geq 0\), we have_

\[\Pr\left[\left|\sum_{i\in[n]}Y_{i}-\sum_{i\in[n]}\mathbb{E}[Y_{i}]\right|> \Delta\right]\leq 2\exp\left(\frac{-\Delta^{2}}{2V+C\Delta}\right).\]

We now list a couple of versions of this inequality, which will be more useful in our setting.

**Corollary E.2**.: _Let \(P\) be a product distribution on \(\{0,1\}^{d}\). For any \(\beta,\gamma\in(0,\frac{1}{2})\), let \(n>\frac{50}{\gamma}\log\frac{d}{\beta}\) and \(X_{1},\ldots,X_{n}\sim P\). Let \(\overline{X}:=\frac{1}{n}\sum_{i\in[n]}X_{i}\). Then, we have_

\[\Pr\left[\forall j\in[d],\overline{X}[j]\in[0.9p_{j}-\gamma,1.1p_{j}+\gamma] \right]\geq 1-\beta.\]

Proof.: For each \(j\in[d]\), applying Theorem E.1 with \(\Delta=\max\{\gamma,0.1p_{j}\}\cdot n\) and using \(p_{j}\leq 3/4\), we obtain

\[\Pr\left[|\overline{X}[j]-p_{j}|\leq\max\{\gamma,0.1p_{j}\}\right]\leq 2\exp \left(\frac{-\Delta^{2}}{2np_{j}+\Delta}\right)\leq 2\exp\left(-\frac{\Delta}{21} \right)\leq\frac{\beta}{d}.\]

Taking a union bound over all \(j\in[d]\) completes the proof.

**Corollary E.3**.: _Let \(P\) be a product distribution on \(\{0,1\}^{d}\). For any \(\beta,\gamma\in(0,\frac{1}{2})\), let \(n>\frac{50}{\gamma}\log\frac{d}{\beta}\) and \(X_{1},\ldots,X_{n}\sim P\). Then, we have_

\[\Pr\left[\forall i\in[n],\sum_{j\in[d]}\frac{X_{i}[j]}{\max\{p_{j},\gamma\}} \leq 3d+\frac{4}{\gamma}\log\frac{n}{\beta}\right]\geq 1-\beta.\]

Proof.: Denote \(Y_{j}=X_{i}[j]/\max\{p_{j},\gamma\}\) for all \(j\in[d]\). Here we have \(\mathbb{E}[Y_{j}]=p_{j}/\max\{p_{j},\gamma\}\leq 1\) and \(\operatorname{var}(Y_{j})\leq p_{j}/\max\{p_{j},\gamma\}^{2}\leq 1/\gamma\). Moreover, with probability 1, we have \(Y_{j}\leq 1/\gamma\). As a result, we can apply Theorem E.1 with \(\Delta=2d+4\log(n/\beta)/\gamma\), which gives

\[\Pr\left[\left|\sum_{j\in[d]}\frac{X_{i}[j]}{\max\{p_{j},\gamma\}}-d\right|> \Delta\right]\leq 2\exp\left(\frac{-t^{2}}{2d/\gamma+t/\gamma}\right)\leq 2 \exp(-0.5\Delta\gamma)\leq\frac{\beta}{n}.\]

Taking a union bound over all \(i\in[n]\) completes the proof. 

### Private Preconditioner

We start with the following private preconditioner, which estimates each \(p_{j}\) up to a constant factor. This preconditioner is similar to that of [27], except that we add noise from the Laplace distribution13 (instead of Gaussian noise) to achieve pure-DP and that we are looking for a coarser guarantee compared to [27].

Footnote 13: The _Laplace distribution_\(\mathsf{Lap}(b)\) is given by the PDF \(f_{\mathsf{Lap}(b)}(x)\propto\exp(-|x|/b)\).

**Lemma E.4**.: _There exists an \(\epsilon\)-DP algorithm that takes_

\[O\left(\left(d\log\left(\frac{d}{\alpha}\right)+\frac{d}{\alpha}\right)\frac {\log\left(\frac{d}{\alpha\beta}\right)}{\epsilon}\right),\]

_samples as input and output integers \(\ell_{1},\ldots,\ell_{d}\in\{0,\ldots,\lceil\log(\frac{2d}{\alpha})\rceil\}\) such that, with probability \(1-\beta\), the following hold for all \(j\in[d]\):_

* _if_ \(\ell_{j}\neq\lceil\log(\frac{2d}{\alpha})\rceil\)_, then_ \(p_{j}\in\lceil\nicefrac{{1}}{{4}}\cdot 2^{-\ell_{j}},\nicefrac{{3}}{{4}}\cdot 2^{- \ell_{j}}\rceil\)_, and_
* _if_ \(\ell_{j}=\lceil\log(\frac{2d}{\alpha})\rceil\)_, then_ \(p_{j}\leq\alpha/2d\)_._

In the remaining of this section, we will focus on the proof of Lemma E.4 and Algorithm 5.

**Sample Complexity.** From Algorithm 5, the total sample complexity can be bounded by

\[\sum_{\ell\in[L]}n_{\ell}=O\left(\sum_{\ell\in[L]}\left(d+2^{\ell}\right)\frac {\log\left(\frac{d}{\alpha\beta}\right)}{\epsilon}\right)=O\left(\left(d\log \left(\frac{d}{\alpha}\right)+\frac{d}{\alpha}\right)\frac{\log\left(\frac{d}{ \alpha\beta}\right)}{\epsilon}\right),\]

as desired.

**Privacy Analysis.** In each iteration \(\ell\in[L]\), the samples \(X_{1}^{\ell},\ldots,X_{n_{\ell}}^{\ell}\), after truncation, are noised with a Laplace distribution; by the privacy guarantee of the Laplace mechanism, each iteration is thus \(\epsilon\)-DP. Furthermore, since each iteration uses a fresh set of samples, by the parallel composition property of DP, the entire algorithm is \(\epsilon\)-DP as desired.

**Accuracy Analysis.** We will prove this by induction. Specifically, let \(S_{\ell}^{\uparrow}:=\{j\in[d]\mid p_{j}\leq\nicefrac{{3}}{{4}}\cdot 2^{- \ell}\}\) and \(S_{\ell}^{\downarrow}:=\{j\in[d]\mid p_{j}\leq\nicefrac{{1}}{{4}}\cdot 2^{- \ell}\}\). We will show that

\[\Pr\left[\forall\ell\in\{0,\ldots,t\},S_{\ell-1}^{\downarrow}\subseteq S_{\ell} \subseteq S_{\ell}^{\uparrow}\right]\geq 1-\frac{t\beta}{L},\] (6)

for all \(t\in[L]\) by an induction on \(t\). Observe that this statement implies the desired accuracy claim in the lemma because \(j\) gets assigned \(\ell_{j}=\ell\) if and only if \(j\in S_{\ell}\setminus S_{\ell+1}\). (Here we use the convention that \(S_{L+1}=\emptyset\).)

**Input:** An unknown product distribution \(P\) over \(\{0,1\}^{d}\), privacy parameter \(\epsilon\), accuracy parameter \(\alpha\), failure probability parameter \(\beta\)

**Output:**\(\ell_{1},\ldots,\ell_{d}\in\{0,1,\ldots,\lceil\log(\frac{2d}{\alpha})\rceil\}\)

\(L\leftarrow\lceil\log(\frac{2d}{\alpha})\rceil\)

\(\ell_{j}\gets 0\) for every \(j\in[d]\)

\(S_{0}\leftarrow[d]\)

**foreach**\(\ell=0,1,\ldots,L-1\)**do**

\(B_{\ell}\gets 1000(d\cdot 2^{-\ell}+1)\)

\(n_{\ell}\leftarrow\frac{1000}{\epsilon}\cdot B_{\ell}\cdot 2^{\ell}\cdot \log\left(\frac{d}{\alpha\beta}\right)\)

Sample \(X_{1}^{\ell},\ldots,X_{n_{\ell}}^{\ell}\sim P\)

\(S_{\ell+1}\leftarrow\emptyset\)

\(q_{\ell}[S_{\ell}]\leftarrow\frac{1}{n_{\ell}}\left(\mathsf{ Lap}\left(\frac{B_{\ell}}{\epsilon}\right)+\sum_{i\in[n_{\ell}]}\text{ trunc}_{B_{\ell}}^{1}(X_{i}^{\ell}[S_{\ell}])\right)\)

**foreach**\(j\in S_{\ell}\)**do**

**if**\(q_{\ell}[j]\leq 0.57\cdot 2^{-\ell}\) **then**

Add \(j\) to \(S_{\ell+1}\)

**else**

\(\ell_{j}\leftarrow\ell\)

**foreach**\(j\in S_{L}\)**do**

\(\ell_{j}\gets L\)

**return**\(\ell_{1},\ldots,\ell_{d}\)

**Algorithm 5** PreconditionerProductDist

**Base Case.** (2) trivially holds for \(t=0\) as \(S_{0}^{\uparrow}=S_{0}=[d]\).

**Inductive Step.** Suppose that (6) holds for \(t-1\) for some \(t\in\mathbb{N}\). We will also show that it also holds for \(t\). From a union bound, it suffices to show

\[\Pr\left[S_{t-1}^{\downarrow}\subseteq S_{t}\subseteq S_{t}^{\uparrow}\mid S _{t-1}\subseteq S_{t-1}^{\uparrow}\right]\geq 1-\frac{\beta}{L}.\]

To show this, we need the following claim:

_Claim 1_.: Assume \(S_{t-1}\subseteq S_{t-1}^{\uparrow}\). For each \(j\in S_{t}\), with probability \(1-\frac{0.5\beta}{Ld}\), we have

\[\frac{1}{n_{t}}\left(\sum_{i\in[n_{t}]}\text{trunc}_{B_{\ell}}^{1}(X_{i}^{t}[ S_{t}])\right)_{j}\in\left[0.8p_{j}-0.01\cdot 2^{-t},1.1p_{j}+0.01\cdot 2^{-t} \right].\]

Before we prove Claim 1, let us see how to use it to finish the proof. Let \(Z^{t}\sim\mathsf{Lap}\left(B_{t}/\epsilon\right)\) be the Laplace noise added. First, by a standard concentration bound for the Laplace distribution, we have

\[\Pr\left[|Z_{j}^{t}|<\frac{B_{t}}{\epsilon}\log\left(\frac{4Ld}{\beta}\right) \right]\geq 1-\frac{0.5\beta}{Ld}.\]

Note also that by our choice of parameters, we have \(B_{t}/\epsilon\cdot\log\left(4Ld/\beta\right)\leq 0.01\cdot 2^{-t}\cdot n_{t}\).

Hence, by a union bound, we have that with probability \(1-\beta/L\) for all \(j\in S_{t}\),

\[q_{t}[j]\in[0.8p_{j}-0.02\cdot 2^{-t},1.1p_{j}+0.02\cdot 2^{-t}].\]

Consider any \(j\in S_{t}\setminus S_{t}^{\uparrow}\). Since \(p_{j}\geq 0.75\cdot 2^{-t}\), we have \(q_{t}[j]\geq 0.58\cdot 2^{-t}>\tau_{t}\). Hence, \(j\) will not be included in \(S_{t}\), coming to a contradiction. In other words, \(S_{t}\setminus S_{t}^{\uparrow}=\emptyset\), i.e., \(S_{t}\subseteq S_{t}^{\uparrow}\). Similarly, consider any \(j\in S_{t-1}^{\downarrow}\). Since \(p_{j}\leq 0.25\cdot 2^{-t+1}\), we have \(q_{t}[j]\leq 0.57\cdot 2^{-t}=\tau_{t}\). By Algorithm 5, \(j\) will be included in \(S_{t}\). Hence, \(S_{t-1}^{\downarrow}\subseteq S_{t}\). These conclude the inductive step.

We are now left to prove Claim 1.

Proof of Claim 1.: Let \(Y_{i}=\left(\text{trunc}^{1}_{B_{t}}(X_{i}^{t}[S_{t}])\right)_{j}\).

First note that \(\sum_{i\in[n_{t}]}Y_{i}\leq\sum_{i\in[n_{t}]}X_{i}^{t}[j]\). Therefore, we may apply Corollary E.2, which gives

\[\Pr\left[\frac{1}{n_{t}}\cdot\sum_{i\in[n_{t}]}Y_{i}\leq 1.1p_{j}+0.01\cdot 2^{-t} \right]>1-\frac{0.25\beta}{Ld}.\]

Next, to give a lower bound on \(Y_{i}\), we also observe that

\[\Pr[Y_{i}=1] =\Pr\left[X_{i}^{t}[j]=1\text{ and }\|X_{i}^{\ell}[S_{t}]\|_{1}\leq B _{t}\right]\] \[\geq\Pr[X_{i}^{t}[j]=1\text{ and }\|X_{i}^{t}[S_{t}\setminus\{j \}]\|_{1}\leq B_{t}-1]\] \[=\Pr[X_{i}^{t}[j]=1]\cdot\Pr[\|X_{i}^{t}[S_{t}\setminus\{j\}]\|_ {1}\leq B_{t}-1]\] \[=p_{j}\cdot\Pr[\|X_{i}^{t}[S_{t}\setminus\{j\}]\|_{1}\leq B_{t}-1],\]

and

\[\mathbb{E}[\|X_{i}^{t}[S_{t}\setminus\{j\}]\|_{1}]=\sum_{j^{\prime}\in S_{t} \setminus\{j\}}p_{j^{\prime}}.\]

We note that \(S_{t}\subseteq S_{t-1}\) holds by Algorithm 5 and \(S_{t-1}\subseteq S_{t-1}^{\uparrow}\) follows the assumption. Hence, \(p_{j^{\prime}}<0.75\cdot 2^{-(t-1)}\) for every \(j^{\prime}\in S_{t-1}^{\uparrow}\). Moreover, \(|S_{t-1}^{\uparrow}|\leq d\). Putting everything together, we can further bound

\[\mathbb{E}[\|X_{i}^{t}[S_{t}\setminus\{j\}]\|_{1}]=\sum_{j^{\prime}\in S_{t} \setminus\{j\}}p_{j^{\prime}}\leq\sum_{j^{\prime}\in S_{t-1}^{\uparrow}}p_{j ^{\prime}}\leq d\cdot 0.75\cdot 2^{-(t-1)}\leq 0.1(B_{t}-1).\]

Therefore, by Markov's inequality, we have

\[\Pr[\|X_{i}^{t}[S_{t}\setminus\{j\}]\|_{1}\leq B_{t}-1]\geq 0.9.\]

Combining with the above, we have \(\Pr[Y_{i}=1]\geq 0.9p_{j}\). Notice also that \(Y_{1},\ldots,Y_{n_{t}}\) are i.i.d. and always lie between \([0,1]\). Thus, we can apply Theorem E.1 with \(\Delta=(0.1p_{j}+0.01\cdot 2^{-t})n_{t}\) to obtain

\[\Pr\left[\frac{1}{n_{t}}\cdot\sum_{i\in[n_{t}]}Y_{i}<0.8p_{j}-0.01\cdot 2^{-t }\right]\leq 2\exp\left(\frac{\Delta^{2}}{2p_{j}n_{t}+\Delta}\right)\leq 2\exp \left(\frac{\Delta^{2}}{21\Delta}\right)\leq\frac{0.25\beta}{Ld}.\]

Applying a union bound then yields the claim. 

### Sampler

Next, we give a DP sampler for an unknown product distribution, assuming that a rough estimate of each \(p_{j}\) is already computed via the private preconditioner in Section E.2. The exact guarantee is given below; combining this with Lemma E.4, we immediately arrive at Theorem 1.7.

**Lemma E.5**.: _Suppose that \(\ell_{1},\ldots,\ell_{d}\) satisfy the conditions in Lemma E.4. Then, there is an \(\epsilon\)-DP algorithm taking \(\ell_{1},\ldots,\ell_{d}\) as input, that is an \(\alpha\)-accurate sampler and has a sample complexity of_

\[O\left(\frac{d\log(d/\alpha)}{\alpha\epsilon}\right).\]In the following, we will focus on the proof of Lemma E.5 with Algorithm 6.

**Privacy Analysis.** Consider any pair \(\mathbf{X},\mathbf{X}^{\prime}\) of neighboring datasets. We may assume w.l.o.g. that the two datasets agree except for \(X_{n}\) and \(X^{\prime}_{n}\). We write \(q^{\prime},\tilde{p}^{\prime}\) to denote the values of \(q,\tilde{p}\) computed for \(\mathbf{X}^{\prime}\). Now, consider any possible output \(y\in\{0,1\}^{d}\). For each \(j\in[d]\), we claim that

\[\frac{\Pr[\mathcal{A}(\mathbf{X}^{\prime})_{j}=y_{j}]}{\Pr[\mathcal{A}( \mathbf{X})_{j}=y_{j}]}\leq 1+8w_{j}|\tilde{p}^{\prime}_{j}-\tilde{p}_{j}|.\] (7)

To show this, we first mention two facts:

* \(\frac{\Pr[\mathcal{A}(\mathbf{X}^{\prime})_{j}=0]}{\Pr[\mathcal{A}( \mathbf{X})_{j}=0]}=\frac{1-\tilde{p}^{\prime}_{j}}{1-\tilde{p}_{j}}\leq 1+ \frac{|\tilde{p}^{\prime}_{j}-\tilde{p}_{j}|}{1-\tilde{p}_{j}}\);
* \(\frac{\Pr[\mathcal{A}(\mathbf{X}^{\prime})_{j}=1]}{\Pr[\mathcal{A}(\mathbf{X} )_{j}=1]}=\frac{\tilde{p}^{\prime}_{j}}{\tilde{p}_{j}}\leq 1+\frac{|\tilde{p}^{ \prime}_{j}-\tilde{p}_{j}|}{\tilde{p}_{j}}\).

It suffices to show \(1/(8w_{j})\leq\tilde{p}_{j}\leq 1-1/(8w_{j})\) to prove (7). This follows since \(w_{j}>1\) and \(1/(8w_{j})\leq\tilde{p}_{j}\leq 7/(8w_{j})\) due to clipping.

We also note the following useful property:

\[\|w\circ(q^{\prime}-q)\|_{1}= \frac{1}{n}\cdot\|w\circ(\text{trunc}^{1}_{B,w}(X^{\prime}_{n})- \text{trunc}^{1}_{B,w}(X_{n}))\|_{1}\] \[\leq \frac{1}{n}\cdot\|w\circ(\text{trunc}^{1}_{B,w}(X^{\prime}_{n})+ \text{trunc}^{1}_{B,w}(X_{n}))\|_{1}\leq\frac{2B}{n}.\] (8)

Finally, we are ready to prove the privacy guarantee:

\[\frac{\Pr[\mathcal{A}(\mathbf{X}^{\prime})=y]}{\Pr[\mathcal{A}( \mathbf{X})=y]} =\prod_{j\in[d]}\frac{\Pr[\mathcal{A}(\mathbf{X}^{\prime})_{j}=y_ {j}]}{\Pr[\mathcal{A}(\mathbf{X})_{j}=y_{j}]}\leq\prod_{j\in[d]}\big{(}1+8w_{j }\cdot|\tilde{p}^{\prime}_{j}-\tilde{p}_{j}|\big{)}\] \[\leq \prod_{j\in[d]}\exp\big{(}8w_{j}\cdot|\tilde{p}^{\prime}_{j}- \tilde{p}_{j}|\big{)}=\exp\left(8w\circ|\tilde{p}^{\prime}-\tilde{p}|\right)\] \[\leq \exp\left(8w\circ|q^{\prime}-q|\right)\leq\exp\left(\frac{16B}{ n}\right)=\exp(\epsilon),\]

where the third inequality is due to clipping, the penultimate step follows (8), and the last step follows from our choice of parameters. Thus, the algorithm is \(\epsilon\)-DP as claimed.

**Accuracy Analysis.** Let \(S=\{j\in[d]\mid p_{j}<2^{-L}\}\). We first consider the version of \(\mathcal{A}\) (Algorithm 6), where there is no truncation at all and there is no clipping for any \(j\notin S\), denoted as \(\mathcal{A}^{\prime}\). Let \(Q_{\mathcal{A}^{\prime},P}=\mathsf{Ber}(p^{*}_{1})\otimes\cdots\otimes\mathsf{ Ber}(p^{*}_{d})\). Fix \(\beta=\alpha/12d<\alpha/4\). We define the event \(\mathcal{E}\) as "no \(X_{i}\) is truncated for any \(i\in[n]\) and no \(p_{j}\) is clipped for any \(j\notin S\) by Algorithm 6". By concentration results (Corollaries E.2 and E.3 with \(\gamma=2^{-L-1}\)) and our selection of parameters, we can conclude that \(\mathcal{E}\) happens with probability at least \(1-\beta\), and therefore

\[d_{\mathrm{tv}}(Q_{\mathcal{A}^{\prime},P},Q_{\mathcal{A},P})=d_{\mathrm{tv}}( Q_{\mathcal{A}^{\prime},P},Q_{\mathcal{A},P}\mid\mathcal{E})\cdot\Pr[\mathcal{E}]+d_{ \mathrm{tv}}(Q_{\mathcal{A}^{\prime},P},Q_{\mathcal{A},P}\mid\bar{\mathcal{E}} )\cdot\Pr[\bar{\mathcal{E}}]\]\[=0\cdot(1-\beta)+1\cdot\beta\leq\alpha/2.\]

Furthermore, we can see that \(\mathbb{E}[p_{j}^{*}]=p_{j}\) if \(j\notin S\). For \(j\in S\), clipping ensures us that \(p_{j}^{*}\leq 2^{-L}\), hence \(\mathbb{E}[p_{j}^{*}]\leq 2^{-L}\). Together, we have

\[d_{\mathrm{tv}}(Q_{\mathcal{A}^{\prime},P},P)=\sum_{j\in[d]}|\mathbb{E}[p_{j}^ {*}]-p_{j}|=\sum_{j\in S}|\mathbb{E}[p_{j}^{*}]-p_{j}|\leq\sum_{j\in S}2^{-L} \leq d\cdot 2^{-L}\leq\alpha/2.\]

Combining the above two inequalities yields the \(\alpha\)-accuracy guarantee of \(\mathcal{A}\):

\[d_{\mathrm{tv}}(Q_{\mathcal{A},P},P)\leq d_{\mathrm{tv}}(Q_{\mathcal{A},P},Q_ {\mathcal{A}^{\prime},P})+d_{\mathrm{tv}}(Q_{\mathcal{A}^{\prime},P},P)\leq \alpha/2+\alpha/2=\alpha.\]

Proof of Theorem 1.7.: Finally, we are ready to prove Theorem 1.7. For simplicity, let \(\alpha^{\prime}\) be the target accuracy parameter. Set \(\alpha=\alpha^{\prime}/2\) and \(\beta=\alpha/12d<\alpha^{\prime}/2\). We define the event \(\mathcal{E}\) as "Algorithm 5 returns \(\ell_{1},\ldots,\ell_{d}\) satisfying the properties in Lemma E.4". If \(\mathcal{E}\) holds, then the error of our sampler is at most \(\alpha^{\prime}/2\), which is implied by Lemma E.5. If \(\mathcal{E}\) fails, the error is at most \(1\), but this event happens with probability at most \(\beta<\alpha^{\prime}/2\). Together, the error of our sampler is

\[\alpha^{\prime}/2\cdot(1-\beta)+1\cdot\beta<\alpha^{\prime}/2+\alpha^{\prime}/ 2=\alpha^{\prime},\]

and the sampling complexity is (with \(\beta=\alpha^{\prime}/24d\))

\[O\left(\left(d\log\left(\frac{d}{\alpha^{\prime}}\right)+\frac{d}{\alpha^{ \prime}}\right)\frac{\log\left(\frac{d}{\alpha^{\prime}\beta}\right)}{\epsilon }+\frac{d}{\alpha^{\prime}\epsilon}\log\left(\frac{d}{\alpha^{\prime}}\right) \right)=O\left(\frac{d}{\epsilon}\log^{2}\left(\frac{d}{\alpha^{\prime}} \right)+\frac{d}{\alpha^{\prime}\epsilon}\log\left(\frac{d}{\alpha^{\prime}} \right)\right),\]

as desired.