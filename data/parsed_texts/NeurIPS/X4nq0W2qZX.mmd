# MmCows: A Multimodal Dataset for Dairy Cattle Monitoring

 Hien Vu

Purdue University

hienvu@purdue.edu

&Omkar Prabhune

Purdue University

oprabhun@purdue.edu

&Unmesh Raskar

University of Wisconsin-Madison

uraskar@wisc.edu

&Dimuth Panditharatne

University of Wisconsin-Madison

panditharatn@wisc.edu

&Hanwook Chung

Iowa State University

hwchung@iastate.edu

&Christopher Y. Choi

University of Wisconsin-Madison

cchoi22@wisc.edu

&Younghyun Kim

Purdue University

younghyun@purdue.edu

###### Abstract

Precision livestock farming (PLF) has been transformed by machine learning (ML), enabling more precise and timely interventions that enhance overall farm productivity, animal welfare, and environmental sustainability. However, despite the availability of various sensing technologies, few datasets leverage multiple modalities, which are crucial for developing more accurate and efficient monitoring devices and ML models. To address this gap, we present MmCows, a multimodal dataset for dairy cattle monitoring. This dataset comprises a large amount of synchronized, high-quality measurement data on behavioral, physiological, and environmental factors. It includes two weeks of data collected using wearable and implantable sensors deployed on ten milking Holstein cows, such as ultra-wideband (UWB) sensors, inertial sensors, and body temperature sensors. In addition, it features 4.8 million frames of high-resolution image sequences from four isometric view cameras, as well as temperature and humidity data from environmental sensors. We also gathered milk yield data and outdoor weather conditions. One full day's worth of image data is annotated as ground truth, totaling 20,000 frames with 213,000 bounding boxes of 16 cows, along with their 3D locations and

Figure 1: Sample 3D visualization of the MmCows multimodal sensing and four camera views.

behavior labels. An extensive analysis of MnCows is provided to evaluate the modalities individually and their complementary benefits. The release of MnCows and its benchmarks will facilitate research on multimodal monitoring of dairy cattle, thereby promoting sustainable dairy farming. The dataset and the code for benchmarks are available at https://github.com/neis-lab/mmcows.

## 1 Introduction

The dairy industry around the world is under strong sustainability pressure--environmentally, socially, and economically. Environmentally, massive consumption of clean water and energy and the waste produced by cattle threaten the environmental sustainability of the industry [1]. At the same time, strong social pressure is placed on farmers to raise cattle in a more humane way [2]. However, due to the low economic margin of the dairy industry, dairy farms tend to house more cows in large-scale facilities often with inadequate living conditions [3], making it even more challenging to carry out environment- and animal-friendly farming. These compounded problems also result in significant production losses which have been estimated at several billions of US dollars annually, along with excessive costs in energy and water usage, that increasingly and negatively affect dairy producers worldwide [4; 5; 6]. In short, the sustainability of the dairy industry depends on the maintenance of larger herds at minimal labor costs with low water and energy consumption, while keeping them healthy and stress-free.

Precision agriculture, or precision livestock farming (PLF) more specifically, has emerged as an effective solution to address these sustainability challenges in dairy farming [4]. Powered by advances in sensing, computing, and communication technologies [7], PLF enables the monitoring of individual animals' behavior, physiology, and their social interaction in real time to quickly detect health problems and better track their diet, growth, and productivity [8; 5], allowing fine-grained monitoring and control of facilities [9]. More recently, similar to many other application domains, PLF has seen a remarkable transformation with the advent of machine learning (ML) techniques [10; 11]. Combined with various sensing and computer vision techniques, several ML approaches have been proposed to monitor livestock animals. Examples include computer vision-based measurement of cow body weight [12] and detection of bovine respiratory diseases using wearable inertial measurement units (IMUs) [13].

With the rapid rise in the popularity of ML approaches and enabled by the increasing availability of low-cost high-quality sensors, a number of datasets of dairy cattle have been introduced. Each modality has different pros and cons in terms of accuracy, cost, animal friendliness, etc., and to determine the optimal modality or complementary modalities for a target application, a high-quality multimodal dataset is crucial. Unfortunately, existing dairy cattle datasets with only one or two sensing modalities do not meet the needs of recent ML research.

In this work, we present the MnCows dataset that leverages the complementary benefits of synchronized data from multiple modalities for accurate and efficient monitoring of dairy cattle. The dataset was collected from Holstein cows, which is the dominant breed of dairy cattle worldwide [14]. MnCows also includes data related to the environment and milk yield, which can be used to provide a comprehensive understanding of behavior and physiological changes of the cattle over time. The contributions and unique aspects of the MnCows dataset are as follows:

* **Multiple sensing modalities:** MnCows is a large-scale fine-grained dataset of dairy cattle collected over a two-week period featuring multiple sensing modalities. The variety of modalities ranges from physiological and behavioral sensing to visual, environmental, and milk yield data. As ground truth, MnCows contains one day's worth of annotated visual data of 16 cows, including 20,000 isometric-view images with IDs and behavior labels.
* **Real-world data:** The data was collected from actual milking cows housed in the Agricultural Research Station at the University of Wisconsin-Madison. The deployment was carefully planned and executed without disrupting the cows' daily routine or negatively affecting their comfort to obtain physiological and behavioral data that is as natural as possible, similar to what can be observed at commercial dairy farms.
* **Comprehensive data and extensive benchmarks:** MnCows not only contains primary measurement data, but also various secondary processed data derived from it. We also present a comprehensive set of benchmarks that utilize both primary and secondary data for various applications of cattle monitoring.

## 2 Related Work

In this section, we discuss advanced sensing technologies that enable the collection of various data required for PLF, and the lack of suitable multimodal datasets required for ML research.

### Health monitoring of dairy cattle

Behavioral and physiological responses in dairy cattle are widely utilized in both research and practice for detecting health issues, and the monitoring of such responses is critical for the timely detection of various health conditions including heat stress, lameness, ketosis, mastitis, estrus, and calving.

Heat stress occurs when a cow's core body temperature exceeds the upper critical threshold of the thermal neutral zone, leading to behavioral changes [15]. Cows experiencing heat stress tend to stand more to increase surface area for better cooling through convection [16; 17; 18]. They also reduce the number of meals per day to lower metabolic heat production [19; 20; 21; 22], and their milk production decreases as a result [23; 24; 25]. Additionally, cows under heat stress drink more frequently but in smaller amounts [26].

Lameness in dairy cattle is characterized by abnormal gait or movement due to pain or injury in the limbs or feet that significantly impacts well-being and productivity [27]. Lame cows typically exhibit reduced daily feeding time and fewer feeding visits, coupled with an increased feeding rate [28; 29]. Accurate prediction of lameness was achieved by combining data on neck acceleration and milk production [30].

Ketosis is a metabolic disorder where energy demands exceed intake, that results in a negative energy balance, leading to rapid reductions in daily milk yield, feeding time, and feeding rate in affected cows [28; 31].

Mastitis, an inflammatory condition of the udder, is one of the most economically significant diseases in dairy cattle. Cows with mastitis show decreased feeding and ruminating time, alongside increased idle standing time [32].

Estrus and calving can be detected early through behavioral monitoring. Indicators of estrus include standing heat, intense physical activity, and mounting behaviors [33; 34]. Before calving, cows typically increase their daily step count and reduce lying and feeding time within the 24 hours leading up to calving [35; 36].

### Behavioral and physiological sensing of dairy cattle

Behavioral and physiological responses of dairy cattle have been widely used to detect health issues in research and practice. For behavior monitoring, the most common methods involve measuring cows' movements and locations. An accelerometer mounted on the neck or ankle provides useful information about a cow's body movements and postures [37; 38; 39; 40]. While this approach allows for accurate behavior inference, wearable devices can be relatively costly to deploy and maintain at scale. Cow location data also offers insights into their activities (such as feeding and drinking) and social interactions, typically using UWB or GPS for localization [41; 42; 43]. UWB provides precise locations but requires an infrastructure of stationary anchor devices, whereas GPS functions without such infrastructure but has relatively low accuracy, especially indoors. High-power consumption and the need for wearable sensors are drawbacks of both localization methods.

An increasingly popular solution for tracking cattle movement and location is ML-based vision processing. Various vision models have been proposed to identify individual cows [44; 45; 46] and to recognize behavior and posture [47]. Vision models can also be applied for localization [48]. The primary advantage of vision-based approaches is that they eliminate the need for wearable devices, which simplifies deployment and improves animal comfort. However, these methods are susceptible to changes in lighting conditions and physical obstructions.

One of the most critical physiological data is core body temperature (CBT) due to its relevance to animal behavior and health conditions, particularly heat stress [17; 49; 8; 50]. CBT can be measured using commercial temperature sensors inserted in the vagina or rectum, which is considered the conventional "gold standard" method [51; 52]. However, the insertion and retrieval process is very costly and stressful for both farmers and cows, and due to the depth of implantation, real-time measurement is not feasible. Ingestible boluses have been used to measure the reticulum temperature [53], but their measurement results can be affected by water and feed intake, making them unsuitable for precise CBT measurement. More recent studies have shown that subcutaneously injected temperature sensors can be used for real-time CBT measurement [54; 55; 56; 57], though they are not yet commercially available.

### Related datasets

As seen in Section 2.2, each sensing modality has different pros and cons in terms of accuracy, cost, animal friendliness, etc. To develop cattle monitoring devices and ML models that are accurate, cost-effective, and animal-friendly, a careful evaluation of different modalities or combinations of modalities must be performed, which requires an appropriate dataset. Table 1 compares various datasets developed for animal (cattle or swine) and human subjects.

For the monitoring of human subjects, which have been relatively well studied, several datasets are available for multimodal ML, including [58; 59; 60]. In these datasets, RGB images are the most common, and IMUs are also widely used to record joint movements. Other sensing modalities found in human datasets include heart rate, audio, depth, mmWave, etc. [58; 60; 61].

On the other hand, although many animal datasets are available for ML research, none of them were developed mainly for multimodal ML. As shown in Table 1, most datasets consist of RGB images, usually close-up top-view images that are useful for identification of the animals [65; 48; 66; 14; 68; 69; 62; 63; 64]. Other datasets contain IMU data for motion detection and behavior classification [67; 70] or UWB data for localization [42], but not both. Only one dataset [64] includes an additional modality, depth images, alongside traditional RGB images; however, both fall into the category of image sensing. As a result, these datasets are only suitable for developing and evaluating ML models for a certain modality and do not provide a way to compare different modalities and their combinations.

\begin{table}
\begin{tabular}{l l c c c c c c c c c c} \hline \hline  & Datasets & \# of & Main modalities & \# of & \# of & Dura- & \# of & Annotation classes \\  & & modal. & UWB & IMU & RGB & cams. & frames & tion & subj. & ID & Behavior \\ \hline \multirow{4}{*}{\begin{tabular}{} \end{tabular} } & Stanford-ECM [58] & 3 & - & ✓ & ✓ & 1 & - & - & 31h & 10 & - & 24 \\  & ActionSense [59] & 8 & - & ✓ & ✓ & 7 & 512k & 13h & 10 & - & 20 \\  & mRI [60] & 4 & - & ✓ & ✓ & 1 & 160k & 0.3h & 20 & - & 12 \\  & SALSA [61] & 5 & - & - & ✓ & 4 & - & 1h & 18 & - & - \\ \hline \multirow{6}{*}{
\begin{tabular}{} \end{tabular} } & PBVD-5 [62] & 1 & - & - & ✓ & 1 & - & 8d & 9 & 9 & 5 \\  & Zhang et al. [63] & 1 & - & - & ✓ & 1 & - & 1.5h & 12 & - & 5 \\  & Bergamini et al. [64] & 2 & - & - & ✓ & 1 & 3.4M & 23d & 8 & 8 & 5 \\  & FriesianCattle2015 [65] & 1 & - & - & ✓ & 1 & 764 & - & 92 & - & - \\  & FriesianCattle2017 [48] & 1 & - & - & ✓ & 1 & 940 & 2h & 89 & - & - \\  & AerialCattle2017 [48] & 1 & - & - & ✓ & 1 & 16k & 0.2h & 23 & 23 & - \\  & Ter-Sarkisov et al. [66] & 1 & - & - & ✓ & - & - & 14d & 10 & - & - \\  & DSCOW [42] & 1 & ✓ & - & - & - & - & 123d & 190 & - & - \\  & Rodriguez et al. [67] & 1 & - & ✓ & - & - & - & 28d & 20 & - & 7 \\  & OpenCows2020 [14] & 1 & - & - & ✓ & 1 & 3.7k & - & 46 & - & - \\  & Cows2021 [68] & 1 & - & - & ✓ & 1 & 10k & - & 186 & - & - \\  & Koskela et al. [69] & 1 & - & - & ✓ & 1 & 1.7M & 19h & - & - & 7 \\  & CowScreeningDB [70] & 1 & - & ✓ & - & - & - & 7h & 43 & - & - \\ \hline \multicolumn{2}{c}{**MMCows** (ours)} & 9 & ✓ & ✓ & ✓ & 4 & 4.8M & 14d & 16 & 16 & 7 \\ \hline \hline \end{tabular}
\end{table}
Table 1: Comparison of related datasets.

[MISSING_PAGE_EMPTY:5]

Holstein cows, ten of which are equipped with wearable sensors, described next. The cattle stay in the pen most of the time except for milking twice per day for approximately 30 minutes each time. All procedures were performed with the approval of the Institutional Animal Care and Use Committee (IACUC) of the University of Wisconsin-Madison (Protocol #A006606).

**Neck-mount tag (uwb, immu, pressure).** We designed a wearable neck-mount tag to measure individual cows' locations and behavior. Figure 3 shows the tag's PCB and how it is mounted on the cow. The tag consists of (1) the Qorvo DW3000 UWB module for measuring distances from the tag to eight stationary UWB anchors, which are used to derive 3D neck location of the cow, (2) the TDK ICM-20984 IMMU that measures acceleration and magnetic field, and (3) the Bosch BMP390 air pressure sensor for measuring elevation. To minimize measurement noise, the UWB, the accelerometer inside the IMMU, and the pressure sensor are configured to perform oversampling at rates of 5x, 16x, and 8x, respectively. Refer to Table 2 for the sampling configurations. The tag, along with a 1.9-Ah lithium battery, is enclosed in a water-proof casing with an air-permeable hole for air pressure measurement. As shown in Figure 4, eight UWB anchors are installed at a height of 5 m to enable 3D spatial measurements. Ten of these tags are attached to ten cows (Cow 1 through Cow 10) out of a group of 16. Two additional tags are mounted in stationary positions around the pen to record data as reference points.

**Vaginal temperature sensor (cbt).** Each of the same ten cows is equipped with an Onset HOBO U12-15 temperature logger, inserted in their vagina to measure the vaginal temperature, which is considered the CBT of the cows.

**Ankle sensor (ankle).** As a common approach to detecting lying behavior, we attached an Onset HOBO Pendant G ankle sensor to the left hind leg of the same cows. This sensor measures the direction of gravity, which allows us to infer the orientation of the leg.

**Cameras (rgb).** Four GoPro HERO11 Black cameras are mounted at four corners of the pen, directed toward the center, as shown in Figure 4. The cameras record 4480\(\times\)2800 (4.5K) videos at 1 fps, providing isometric views of the pen instead of top views, which are more common in many datasets. Detection and identification tasks become much more challenging with isometric-view images, but

Figure 4: Top-view map of the pen with installation locations of the UWB anchors, cameras, and microclimate sensors.

Figure 3: (a) Top and (b) bottom view of the wearable neck-mount tag with UWB, IMMU, and pressure sensor. (c) Water-proof enclosure with a battery. (d) The tag is mounted at the top of the neck using a neck halter.

this setup is more common in commercial barns as it provides wider visibility. We do not add any additional lighting to reduce motion blur, in order to maintain the same barn environment.

**Indoor microclimate (thi) and outdoor weather (weather).** The ambient temperature and relative humidity (RH) are used to infer the Temperature-Humidity Index (THI) [71], and are measured by six Onset HOBO Pro v2 temperature/RH loggers deployed as shown in Figure 4. The outdoor weather conditions are recorded every 5 minutes by a weather station located 950 m northeast of the experimental site, which includes dew point, precipitation, sunlight intensity, wind speed and direction, etc.

**Milk yield record (milk).** The dataset also contains the daily milk yield in kg and the health checkup records of all 16 cows prior to and after the experiment, which are recorded by the barn staff.

**Secondary data.** We generate secondary data based on the collected primary data. Secondary data in MmCows includes head direction (hd) from IMMU, and lying/non-lying classification (lnl) using the ankle sensor data. The processing pipeline for secondary data generation is illustrated in Figure 5. Note that this pipeline is only an example used in this paper, and the dataset can be used in different processing pipelines for various applications.

**Sensor calibration.** Ten UWB modules in the tags and eight UWB anchors are pairwise calibrated from 0 to 18 m using a linear calibration model. The accelerometer in the IMMU is also separately calibrated using linear offset, and the magnetometer is calibrated for hard and soft iron biases [72]. The MCU stores the calibration parameters and corrects the measurements of the IMMU in real time, while the pressure sensor is programmed to perform self-calibration upon powering on.

**Sensor synchronization.** Each neck tag is equipped with the Analog Devices DS3231 real-time clock to maintain its local time. The local time of all neck-mounted tags is synchronized with Internet time every 30 minutes through a stationary hub using UWB communication. The hub contains a Raspberry Pi 4 connected to the Internet to retrieve and retain the Internet time. In other words, the timestamps of all data collected by different sensors in the tags are synchronized with Internet time. Every 15 seconds, the tags synchronously perform distance measurements one by one in succession to prevent packet collisions when using the same wireless channel.

### Ground truth

#### 3.2.1 Ground truth for cow identification and behavior classification

The ground truth of cow IDs and behaviors is manually created using the vision data. The UWB-synced RGB frames from July 25(tm) are used for the annotation. We manually annotated 20,000 images to produce 213,000 bounding boxes for all 16 cows. When the cows are lying in the stalls, their bodies are often heavily occluded by one another, making identification more challenging. Thus, we separate the bounding box labels of cows into three sets: lying, non-lying, and combined labels. The annotators were trained to follow our comprehensive annotation rules to ensure consistency.

Figure 5: The data processing and benchmarking pipeline of MmCows in this paper. MmCows can be used in different processing pipelines for different applications.

The correctness of cow ID annotation was automatically verified using visual localization, which is elaborated in Section 3.2.2, and was also manually verified during the process of behavior labeling. Details of the annotation rules are provided on the dataset website.

We manually created the behavior ground truth of 16 cows at the granularity of one-second intervals, where each behavior label of the cow is associated with a timestamp. The synchronization of RGB frames from four cameras ensures that for each given timestamp, each cow performs the same behavior in all camera views. We use seven behaviors of individual cows, including walking, standing, feeding head up, feeding head down, licking, drinking, and lying, which are commonly used in various cattle behavior monitoring studies discussed in Section 2.1. Details of behavior definitions and visual examples are available in the supplementary document.

#### 3.2.2 Visual localization and location ground truth

To provide reliable ground truth for cows' locations, we propose a new optimization-based approach to calculate body location using the annotated bounding boxes from multiple views. We first project the bounding box centers of the same cow across multiple views into the world coordinate system as 3D lines that inherently converge in space. We then apply AdaGrad [73] to find the optimal location that is nearest to the lines, which serves as the cow's location in 3D. This location can be used as ground truth for developing vision-based localization models. More details are provided in the supplementary document.

As an additional step to ensure the correctness of the ID annotation process, for each location, we calculate the distance from that location to its corresponding projection lines. Any line that is irregularly far from the visual location is flagged as an outlier, indicating that the cow's ID has been incorrectly annotated, which is subsequently corrected until all projection lines converge.

## 4 Evaluation and Benchmarks

For the evaluation of MaCows, we conduct a two-stage benchmarking process. In the first stage, to show how the multimodal dataset can be used for system design, we compare different modalities for the behavior classification task. In the second stage, we perform a high-level behavior analysis to show how MaCows can be used for automated dairy barn management. As this section only briefly introduces the results, we discuss them in more detail in the supplementary document.

### Modality comparison for behavior classification

**Setting.** To avoid data leakage, we consider two data split settings: object-wise split (OS) and temporal split (TS). The OS setting evaluates cross-cow generalization, while the TS setting assesses robustness on unseen data. For uwb and immu, data from ten cows with tags is used, and both OS and TS settings are applied. For rgb, data from all 16 cows is used, and only the TS setting is applied since data from all cows is required to train the identification models.

In the OS setting, we use 5-fold cross-validation to train models, with the ratio of cows for training, validation, and testing set to [6:2:2]. The selection of cows is rotated so that each cow appears in the test set exactly once.

In the TS setting, data from each modality is separated into two groups based on the lighting conditions. The first group contains data with artificial light, recorded between 3am-6am and 6pm-12am. The second group contains data with natural light, recorded between 6am-6pm. Each group is divided equally and temporally into five segments, resulting in ten segments. We apply 5-fold cross-validation, where from each group, the ratio of segments for training, validation, and testing is set to [3:1:1]. The two groups are concatenated in the configuration [6:2:2]. Validation is performed until each segment has been tested once.

**Metric.** Cows often spend substantial amounts of time lying, feeding, and standing, but only seldom engaging in walking, drinking, or licking. Since the behavior classes are heavily imbalanced and the minority classes are also important, we use the F1 score to evaluate the results. An average F1 score is reported for each setting.

**Methods.** We perform behavior classification using uwb, immu, rgb, and some combinations of them with hd and ankle. We selected three specific combinations of modalities to demonstrate the benefits

[MISSING_PAGE_FAIL:9]

classification over 13 days with respect to THI (excluding the first and last days that are shorter than 24 hours).

**Metric.** We use the Pearson correlation coefficient (\(r\)), \(p\)-value, and \(R^{2}\) to evaluate the relationship between variables. The \(r\) value helps to identify the strength and direction of the relationship; the \(p\)-value determines the statistical significance, and \(R^{2}\) indicates the proportion of variability explained by the THI.

**Method.** We use UWB+HD+Akl to perform inference on 2-week-long data to extract seven behaviors of ten cows. Feeding head up and head down behaviors are combined as feeding. To obtain an accurate number of bouts for each behavior, we use a custom filter to remove momentary switching between classes.

**Results and discussion.** We confirm significant correlations between the cows' behavior and THI as reported in Table 4. All behaviors are strongly affected by THI, indicated by the very small \(p\)-values and high \(R^{2}\) values. The results agree with previous studies on THI-dependent changes in cattle behavior [16; 17; 18; 76; 77; 78; 79]. The results show the effectiveness of behavior monitoring in assessing cattle health status, such as heat stress.

## 5 Conclusion

MnCows is the first multimodal dataset for dairy cattle monitoring, comprising nine modalities and records. It integrates wearable, implantable, visual, and environmental data collected from 16 milking Holstein cows in a real-world barn over two weeks. This paper describes the creation of this dataset and demonstrates its potential benefits for developing monitoring devices and ML models. The true potential of MnCows lies in the numerous combinations of modalities that have yet to be explored, which can contribute to designing high-accuracy, low-cost, and animal-friendly monitoring systems. We envision MnCows being leveraged for a variety of future endeavors, to promote environmentally, socially, and economically sustainable dairy farming.

## Acknowledgements

The authors thank the anonymous reviewers for their valuable feedback. This work was supported by the USDA National Institute of Food and Agriculture grant 2021-67021-34036 and the National Science Foundation grant 2435327.

## References

* [1] D. O'Brien, J. L. Capper, P. C. Garnsworthy, C. Grainger, and L. Shalloo. A case study of the carbon footprint of milk from high-performing confinement and grass-based dairy farms. _Journal of Dairy Science_, 97(3):1835-1851, 2014.
* [2] Clarissa S. Cardoso, Maria Jose Hotzel, Daniel M. Weary, Jesse A. Robbins, and Marina A.G. von Keyserlingk. Imagining the ideal dairy farm. _Journal of Dairy Science_, 99(2):1663-1671, 2016.
* [3] H. W. Barkema, M. A. G. von Keyserlingk, J. P. Kastelic, T. J. G. M. Lam, C. Luby, J. P. Roy, S. J. LeBlanc, G. P. Keefe, and D. F. Kelton. Invited review: Changes in the dairy industry affecting dairy cattle health and welfare. _Journal of Dairy Science_, 98(11):7426-7445, 2015.

\begin{table}
\begin{tabular}{l c c c} \hline \hline Behavior & \((|r|>0)\uparrow\) & \(p\)-value \(\downarrow\) & \(R^{2}\uparrow\) \\ \hline Standing & [\(-.470\), \(\mathbf{.726}\), \(\mathbf{.678}\)] & [\(.105\), \(\mathbf{.005}\), \(\mathbf{.011}\)] & [\(.221\), \(\mathbf{.527}\), \(\mathbf{.459}\)] \\ Lying & [ \(.476\), \(\mathbf{-.744}\), \(\mathbf{-.696}\)] & [\(.158\), \(\mathbf{.004}\), \(\mathbf{.008}\)] & [\(.173\), \(\mathbf{.553}\), \(\mathbf{.484}\)] \\ Feeding & [ \(.502\), \(-.581\), \(-.424\)] & [\(.080\), \(\mathbf{.037}\), \(.149\)] & [\(.252\), \(.338\), \(.180\)] \\ Drinking & [ \(.802\), \(.196\), \(.476\)] & [\(.001\), \(.521\), \(.100\)] & [\(\mathbf{.643}\), \(.038\), \(.227\)] \\ \hline \hline \end{tabular}
\end{table}
Table 4: Correlations between daily [frequency of bouts, mean duration of bouts, total duration] of cows’ behaviors versus the THI for 13 days.

* [4] Daniela Lovarelli, Jacopo Bacchetti, and Marcella Guarino. A review on dairy cattle farming: Is precision livestock farming the compromise for an environmental, economic and social sustainable production? _Journal of Cleaner Production_, 262:121409, 2020.
* [5] Emanuela Tullo, Alberto Finzi, and Marcella Guarino. Review: Environmental impact of livestock farming and precision livestock farming as a mitigation strategy. _Science of The Total Environment_, 650:2751-2760, 2019.
* [6] Philip Thornton, Gerald Nelson, Dianne Mayberry, and Mario Herrero. Impacts of heat stress on global cattle production during the 21st century: A modelling study. _The Lancet Planetary Health_, 6(3):e192-e201, 2022.
* [7] Suresh Neethirajan and Bas Kemp. Digital livestock farming. _Sensing and Bio-Sensing Research_, 32:100408, 2021.
* [8] Jiangjing Liu, Lanqi Li, Xiaoli Chen, Yongqiang Lu, and Dong Wang. Effects of heat stress on body temperature, milk production, and reproduction in dairy cows: A novel idea for monitoring and evaluation of heat stress--A review. _Asian-Australasian Journal of Animal Sciences_, 32(9):1332, 2019.
* [9] Sebastien Fournel, Alain N. Rousseau, and Benoit Laberge. Rethinking environment control strategy of confined animal housing systems through precision livestock farming. _Biosystems Engineering_, 155:96-123, 2017.
* [10] Rodrigo Garcia, Jose Aguilar, Mauricio Toro, Angel Pinto, and Paul Rodriguez. A systematic literature review on the use of machine learning in precision livestock farming. _Computers and Electronics in Agriculture_, 179:105826, 2020.
* [11] Md Sultan Mahmud, Azlan Zahid, Anup Kumar Das, Muhammad Muzammil, and Muhammad Usman Khan. A systematic literature review on deep learning applications for precision cattle farming. _Computers and Electronics in Agriculture_, 187:106313, 2021.
* [12] A. Cominotte, A. F. A. Fernandes, J. R. R. Dorea, G. J. M. Rosa, M. M. Ladeira, E. H. C. B. van Cleef, G. L. Pereira, W. A. Baldassini, and O. R. Machado Neto. Automated computer vision system to predict body weight and average daily gain in beef cattle during growing and finishing phases. _Livestock Science_, 232:103904, 2020.
* [13] Yigit Tuncel, Toygun Basaklar, Mackenzie Smithyman, Joao Dorea, Vinicius Nunes De Gouvea, Younghyun Kim, and Umit Ogras. Advancing cattle welfare: Ultra low-power health monitoring at the edge. In _IEEE Biomedical Circuits and Systems Conference (BioCAS)_, pages 1-5, 2023.
* [14] William Andrew, Jing Gao, Siobhan Mullan, Neill Campbell, Andrew W Dowsey, and Tilo Burghardt. Visual identification of individual holstein-friesian cattle via deep metric learning. _Computers and Electronics in Agriculture_, 185:106133, 2021.
* [15] C. A. Becker, R. J. Collier, and A. E. Stone. Invited review: Physiological and behavioral effects of heat stress in dairy cows. _Journal of Dairy Science_, 103(8):6751-6770, 2020.
* [16] N. B. Cook, R. L. Mentink, T. B. Bennett, and K. Burgi. The effect of heat stress and lameness on time budgets of lactating dairy cows. _Journal of Dairy Science_, 90(4):1674-1682, 2007.
* [17] J. D. Allen, L. W. Hall, R. J. Collier, and J. F. Smith. Effect of core body temperature, time of day, and climate conditions on behavioral patterns of lactating dairy cows experiencing mild to moderate heat stress. _Journal of Dairy Science_, 98(1):118-127, 2015.
* [18] Grazyne Tresoldi, Karin E. Schutz, and Cassandra B. Tucker. Cooling cows with sprinklers: Effects of soaker flow rate and timing on behavioral and physiological responses to heat load and production. _Journal of Dairy Science_, 102(1):528-538, 2019.
* [19] Abdul Sammad, Ya Jing Wang, Saqib Umer, Hu Lirong, Imran Khan, Adnan Khan, Baseer Ahmad, and Yachun Wang. Nutritional physiology and biochemistry of dairy cattle under the influence of heat stress: Consequences and opportunities. _Animals_, 10(5):793, 2020.

* [20] Charles T. Kadzere, Michael R. Murphy, Nissim Silanikove, and Elliot Maltz. Heat stress in lactating dairy cows: A review. _Livestock Production Science_, 77(1):59-91, 2002.
* [21] R. J. Collier, B. J. Renquist, and Y. Xiao. A 100-year review: Stress physiology including heat stress. _Journal of Dairy Science_, 100(12):10367-10380, 2017.
* [22] P. R. Hut, J. Scheurwater, M. Nielen, J. Van Den Broek, and M. M. Hostens. Heat stress in a temperate climate leads to adapted sensor-based behavioral patterns of dairy cows. _Journal of Dairy Science_, 105(8):6909-6922, 2022.
* [23] Jessica B. Wheelock, Robert P. Rhoads, Matthew J. VanBaale, Susan R. Sanders, and Lance H. Baumgard. Effects of heat stress on energetic metabolism in lactating holstein cows. _Journal of Dairy Science_, 93(2):644-655, 2010.
* [24] G. Andre, B. Engel, P. B. M. Berentsen, Th. V. Vellinga, and A. G. J. M. Oude Lansink. Quantifying the effect of heat stress on daily milk yield and monitoring dynamic changes using an adaptive dynamic model. _Journal of Dairy Science_, 94(9):4502-4513, 2011.
* [25] A. E. Stone, B. W. Jones, C. A. Becker, and J. M. Bewley. Influence of breed, milk yield, and temperature-humidity index on dairy cow lying time, neck activity, reticulorumen temperature, and rumination behavior. _Journal of Dairy Science_, 100(3):2395-2403, 2017.
* [26] Elena Galan, Pol Llonch, Arantxa Villagra, Harel Levit, Severino Pinto, and Agustin Del Prado. A systematic review of non-productivity-related animal-based indicators of heat stress resilience in dairy cattle. _PloS One_, 13(11):e0206520, 2018.
* [27] Nigel B. Cook and Kenneth V. Nordlund. The influence of the environment on dairy cow behavior, claw health and herd lameness dynamics. _The Veterinary Journal_, 179(3):360-369, 2009.
* [28] L. A. Gonzalez, B. J. Tolkamp, M. P. Coffey, A. Ferret, and I. Kyriazakis. Changes in feeding behavior as possible indicators for the automatic monitoring of health disorders in dairy cows. _Journal of Dairy Science_, 91(3):1017-1028, 2008.
* [29] Vivi M. Thorup, Birte L. Nielsen, Pierre-Emmanuel Robert, Sylvie Giger-Reverdin, Jakub Konka, Craig Michie, and Nicolas C. Friggens. Lameness affects cow feeding but not rumination behavior as characterized from sensor data. _Frontiers in Veterinary Science_, 3:37, 2016.
* [30] G. M. Borghart, L. E. O'Grady, and J. R. Somers. Prediction of lameness using automatically recorded activity, behavior and production data in post-parturient irish dairy cows. _Irish Veterinary Journal_, 74:1-10, 2021.
* [31] Nathalie Bareille, F. Beaudeau, Stephanie Billon, A. Robert, and Philippe Faverdin. Effects of health disorders on feed intake and milk production in dairy cows. _Livestock Production Science_, 83(1):53-62, 2003.
* [32] Katrine Kop Fogsgaard, Christine Maria Rontved, Peter Sorensen, and Mette S Herskin. Sickness behavior in dairy cows during escherichia coli mastitisti. _Journal of Dairy Science_, 95(2):630-638, 2012.
* [33] P. Lovendahl and M. G. G. Chagunda. On the use of physical activity monitoring for extras detection in dairy cows. _Journal of Dairy Science_, 93(1):249-259, 2010.
* [34] Said Benaissa, Frank Andre Maurice Tuyttens, David Plets, Jens Trogh, Luc Martens, Leen Vandaele, Wout Joseph, and Bart Sonck. Calving and estrus detection in dairy cattle using a combination of indoor localization and accelerometer sensors. _Computers and Electronics in Agriculture_, 168:105153, 2020.
* [35] Ephraim Maltz and Aharon Antler. A practical way to detect approaching calving of the dairy cow by a behaviour sensor. In _Precision Livestock Farming_, pages 141-146. 2007.
* [36] K. Schirmann, N. Chapinal, D. M. Weary, L. Vickers, and M. A. G. Von Keyserlingk. Rumination and feeding behavior before and after calving in dairy cows. _Journal of Dairy Science_, 96(11):7088-7092, 2013.

* [37] L. N. Grinter, M. R. Campler, and J. H. C. Costa. Validation of a behavior-monitoring collar's precision and accuracy to measure rumination, feeding, and resting time of lactating dairy cows. _Journal of Dairy Science_, 102(4):3487-3494, 2019.
* [38] Weizheng Shen, Fei Cheng, Yu Zhang, Xiaoli Wei, Qiang Fu, and Yonggen Zhang. Automatic recognition of ingestive-related behaviors of dairy cows based on triaxial acceleration. _Information Processing in Agriculture_, 7(3):427-443, 2020.
* A review. _Behavioural Processes_, 181:104262, 2020.
* [40] Kim Margarette Corpuz Nogoy, Sun-il Chon, Ji-hwan Park, Saraswathi Sivamani, Dong-Hoon Lee, and Seong Ho Choi. High precision classification of resting and eating behaviors of cattle by using a collar-fitted triaxial accelerometer sensor. _Sensors_, 22(16):5961, 2022.
* [41] B. Wolfger, B. W. Jones, K. Orsel, and J. M. Bewley. Evaluation of an ear-attached real-time location monitoring system. _Journal of Dairy Science_, 100(3):2219-2224, 2017.
* [42] Bruno Meunier, Philippe Pradel, Karen H. Sloth, Carole Cirie, Eric Delval, Marie M. Mialon, and Isabelle Veissier. Image analysis to refine measurements of dairy cow behaviour from a real-time location system. _Biosystems Engineering_, 173:32-44, 2018.
* [43] E. M. Homer, Y. Gao, X. Meng, A. Dodson, R. Webb, and P. C. Garnsworthy. A novel approach to the detection of estrus in dairy cows using ultra-wideband technology. _Journal of Dairy Science_, 96(10):6529-6534, 2013.
* [44] Keni Ren, Gun Bernes, Marten Hetta, and Johannes Karlsson. Tracking and analysing social interactions in dairy cattle with real-time locating system and machine learning. _Journal of Systems Architecture_, 116:102139, 2021.
* [45] Hai Wang, Abraham O. Fapojuwo, and Robert J. Davies. A wireless sensor network for feedlot animal health monitoring. _IEEE Sensors Journal_, 16(16):6433-6446, 2016.
* [46] Brahim Achour, Malika Belkadi, Idir Filali, Mourad Laghrouche, and Mourad Lahdir. Image analysis for individual identification and feeding behaviour monitoring of dairy cows based on Convolutional Neural Networks (CNN). _Biosystems Engineering_, 198:31-49, 2020.
* [47] Hang Shu, Jerome Bindelle, Leifeng Guo, and Xianhong Gu. Determining the onset of heat stress in a dairy herd based on automated behaviour recognition. _Biosystems Engineering_, 226:238-251, 2023.
* [48] William Andrew, Colin Greatwood, and Tilo Burghardt. Visual localisation and individual identification of holstein friesian cattle via deep learning. In _Proceedings of the IEEE International Conference on Computer Vision Workshops (ICCV)_, pages 2850-2859, 2017.
* [49] Ramendra Das, Lalrengpuii Sailo, Nishant Verma, Pranay Bharti, Jnyanashree Saikia, and Rakesh Kumar. Impact of heat stress on health and performance of dairy animals: A review. _Veterinary World_, 9(3):260, 2016.
* [50] Ian K. Atkins, Nigel B. Cook, Mario R. Mondaca, and Christopher Y. Choi. Continuous respiration rate measurement of heat-stressed dairy cows and relation to environment, body temperature, and lying time. _Transactions of the American Society of Agricultural and Biological Engineers (ASABE)_, 61(5):1475-1485, 2018.
* [51] Musadiq Idris, Jashim Uddin, Megan Sullivan, David M. McNeill, and Clive J. C. Phillips. Non-invasive physiological indicators of heat stress in cattle. _Animals_, 11(1):71, 2021.
* [52] Soraia F. Neves, Monica C. F. Silva, Joao M. Miranda, George Stilwell, and Paulo P. Cortez. Predictive models of dairy cow thermal state: A review from a technological perspective. _Veterinary Sciences_, 9(8):416, 2022.
* [53] smaxtec. smaxtec: Early detection for dairy cows with bolus technology. Last accessed: October 30th, 2024. URL: https://smaxtec.com/us/.

* [54] Hien Vu, Hanwook Chung, Christopher Choi, and Younghyun Kim. eTag: An energy-neutral ear tag for real-time body temperature monitoring of dairy cattle. In _Proceedings of the International Conference on Mobile Computing and Networking (MobiCom)_, pages 1-15, 2023.
* [55] Hanwook Chung, Hien Vu, Younghyun Kim, and Christopher Y. Choi. Subcutaneous temperature monitoring through ear tag for heat stress detection in dairy cows. _Biosystems Engineering_, 235:202-214, 2023.
* [56] Hanwook Chung, Jingjie Li, Younghyun Kim, Jennifer M. C. Van Os, Sabrina H. Brounts, and Christopher Y. Choi. Using implantable biosensors and wearable scanners to monitor dairy cattle's core body temperature in real-time. _Computers and Electronics in Agriculture_, 174:105453, 2020.
* [57] Hanwook Chung, Jingjie Li, Younghyun Kim, and Christopher Y. Choi. Continuous and wireless skin contact and ear implant temperature measurements and relations to the core body temperature of heat stressed dairy cows. In _Proceedings of the International Livestock Environment Symposium (ILES X)_, page 1, 2018.
* [58] Katsuyuki Nakamura, Serena Yeung, Alexandre Alahi, and Li Fei-Fei. Jointly learning energy expenditures and activities using egocentric multimodal signals. In _Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)_, pages 1868-1877, 2017.
* [59] Joseph DelPreto, Chao Liu, Yiyue Luo, Michael Foshey, Yunzhu Li, Antonio Torralba, Wojciech Matusik, and Daniela Rus. Actionsense: A multimodal dataset and recording framework for human activities using wearable sensors in a kitchen environment. In _Advances in Neural Information Processing Systems (NeurIPS)_, volume 35, pages 13800-13813, 2022.
* [60] Sizhe An, Yin Li, and Umit Ogras. mri: Multi-modal 3d human pose estimation dataset using mmwave, rgb-d, and inertial sensors. In _Advances in Neural Information Processing Systems (NeurIPS)_, volume 35, pages 27414-27426, 2022.
* [61] Xavier Alameda-Pineda, Jacopo Staiano, Ramanathan Subramanian, Ligia Batrinca, Elisa Ricci, Bruno Lepri, Oswald Lanz, and Nicu Sebe. Salsa: A novel dataset for multimodal group behavior analysis. _IEEE Transactions on Pattern Analysis and Machine Intelligence_, 38(8):1707-1720, 2015.
* [62] Dan Li, Kaifeng Zhang, Zhenbo Li, and Yifei Chen. A spatiotemporal convolutional network for multi-behavior recognition of pigs. _Sensors_, 20(8):2381, 2020.
* [63] Kaifeng Zhang, Dan Li, Jiayun Huang, and Yifei Chen. Automated video behavior recognition of pigs using two-stream convolutional networks. _Sensors_, 20(4):1085, 2020.
* [64] Luca Bergamini, Stefano Pini, Alessandro Simoni, Roberto Vezzani, Simone Calderara, Rick B. D. Eath, and Robert B. Fisher. Extracting accurate long-term behavior changes from a large pig dataset. In _International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications (VISIGAPP)_, pages 524-533, 2021.
* [65] William Andrew, Sion Hannuna, Neill Campbell, and Tilo Burghardt. Automatic individual holstein freiseian cattle identification via selective local coat pattern matching in rgb-d imagery. In _IEEE International Conference on Image Processing (ICIP)_, pages 484-488, 2016.
* [66] Aram Ter-Sarkisov, Robert Ross, and John Kelleher. Bootstrapping labelled dataset construction for cow tracking and behavior analysis. In _Conference on Computer and Robot Vision (CRV)_, pages 277-284, 2017.
* [67] Domingo S. Rodriguez-Baena, Francisco A. Gomez-Vela, Miguel Garcia-Torres, Federico Divina, Carlos D. Barranco, Norberto Daz-Diaz, Manuel Jimenez, and Gema Montalvo. Identifying livestock behavior patterns based on accelerometer dataset. _Journal of Computational Science_, 41:101076, 2020.
* [68] Jing Gao, Tilo Burghardt, William Andrew, Andrew W. Dowsey, and Neill W. Campbell. Towards self-supervision for video identification of individual holstein-friesian cattle: The cows2021 dataset. _arXiv Preprint arXiv:2105.01938_, 2021.

* [69] Olli Koskela, Leonardo Santiago Benitez Pereira, Ilpo Polonen, Ilmo Aronen, and Iivari Kunttu. Deep learning image recognition of cow behavior and an open data set acquired near an automatic milking robot. _Agricultural and Food Science_, 31(2):89-103, 2022.
* [70] Shahid Ismail, Moises Diaz, Cristina Carmona-Duarte, Jose Manuel Vilar, and Miguel A. Ferrer. Cowscreeningdb: A public benchmark database for lameness detection in dairy cows. _Computers and Electronics in Agriculture_, 216:108500, 2024.
* [71] S. Dikmen and P. J. Hansen. Is the temperature-humidity index the best indicator of heat stress in lactating dairy cows in a subtropical environment? _Journal of Dairy Science_, 92(1):109-116, 2009.
* [72] MathWorks. Magnetometer calibration. Last accessed: October 30th, 2024. URL: https://www.mathworks.com/help/nav/ug/magnetometer-calibration.html.
* [73] John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and stochastic optimization. _Journal of Machine Learning Research_, 12(7), 2011.
* [74] Glenn Jocher, Ayush Chaurasia, and Jing Qiu. Ultralytics yolov8, 2023. Last accessed: October 30th, 2024. URL: https://github.com/ultralytics/ultralytics.
* [75] Mingxing Tan and Quoc Le. Efficientnet: Rethinking model scaling for convolutional neural networks. In _International Conference on Machine Learning_, pages 6105-6114, 2019.
* [76] A. Gomez and N. B. Cook. Time budgets of lactating dairy cattle in commercial freestall herds. _Journal of Dairy Science_, 93(12):5772-5781, 2010.
* [77] Lisette M. C. Leliveld, Elisabetta Riva, Gabriele Mattachini, Alberto Finzi, Daniela Lovarelli, and Giorgio Provolo. Dairy cow behavior is affected by period, time of day and housing. _Animals_, 12(4):512, 2022.
* [78] J. Chang-Fung-Martel, M. T. Harrison, J. N. Brown, Richard Rawnsley, A. P. Smith, and Holger Meinke. Negative relationship between dry matter intake and the temperature-humidity index with increasing heat stress in cattle: A global meta-analysis. _International Journal of Biometeorology_, 65(12):2099-2109, 2021.
* [79] Yu-Chi Tsai, Jih-Tay Hsu, Shih-Torng Ding, Dan Jeric Arcega Rustia, and Ta-Te Lin. Assessment of dairy cow heat stress by monitoring drinking behaviour using an embedded imaging system. _Biosystems Engineering_, 199:97-108, 2020.

## Paper Checklist

1. For all authors: 1. Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? [Yes] 2. Have you read the ethics review guidelines and ensured that your paper conforms to them? [Yes] 3. Did you discuss any potential negative societal impacts of your work? [Yes], we discuss this in the supplementary material. 4. Did you describe the limitations of your work? [Yes], the reported models and results are baseline that gives room for improvement in future studies. Please refer to the supplementary document for the limitations of the dataset.

2. If you are including theoretical results:

1. Did you state the full set of assumptions of all theoretical results? [N/A] 2. Did you include complete proofs of all theoretical results? [N/A]

3. If you ran experiments:

1. Did you include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)? [Yes], the code and instructions are provided in our project page. 2. Did you specify all the training details (e.g., data splits, hyperparameters, how they were chosen)? [Yes], we discuss that in Section 4 and the supplementary document. 3. Did you report error bars (e.g., with respect to the random seed after running experiments multiple times)? [Yes], that is in Section 4. 4. Did you include the amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)? [Yes], we included that in the supplementary document.

4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets:

1. If your work uses existing assets, did you cite the creators? [Yes]
2. Did you mention the license of the assets? [Yes] All materials published are made available under the following Creative Commons license: Attribution-NonCommercial 4.0 International (CC BY-NC 4.0). This is mentioned in the supplementary material. 3. Did you include any new assets either in the supplemental material or as a URL? [Yes] 4. Did you discuss whether and how consent was obtained from people whose data you're using/curating? [Yes], we explained in details the goals and usage of the data to the annotators and obtained their consent during the recruitment. We also discuss others' algorithms that were used in Section 4 and the supplementary material. 5. Did you discuss whether the data you are using/curating contains personally identifiable information or offensive content? [Yes], the dataset does not contain any personal information and the annotators' information is not disclosed in any form.

5. If you used crowdsourcing or conducted research with human subjects:

1. Did you include the full text of instructions given to participants and screenshots, if applicable? [Yes], we constructed a detailed guideline on the annotation and labeling process that was provided to the annotators to ease any confusion and ensure the consistency and the quality of the dataset. This guideline will be made available on the dataset website.
2. Did you describe any potential participant risks, with links to Institutional Review Board (IRB) approvals, if applicable? [Yes], the annotators were fully informed of the content they would be working on during the recruitment. We discussed any potential risk with the annotators and obtained their consent at the beginning of the work. Prior to the experiment, we obtained the approval of the Institutional Animal Care and Use Committee (IACUC) of the University of Wisconsin-Madison (Protocol #A006606).

3. Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation? [Yes], the total amount spent on participant compensation is $6991.50. There are three tasks: non-lying cows annotation, lying cows annotation, and behavior labeling, where we paid $3645.50, $2133.00, and $1213.00, respectively. The annotators are paid at $15/hour according to our Department's hiring policy. We gave the annotators a reasonable amount of time to work on the task and they are free to choose the amount of work according to their satisfactory with the wage.