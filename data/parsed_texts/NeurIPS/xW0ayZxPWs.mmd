# Fair Graph Distillation

Qizhang Feng\({}^{1}\), Zhimeng Jiang\({}^{1}\), Ruiquan Li\({}^{2}\), Yicheng Wang\({}^{1}\), Na Zou\({}^{1}\), Jiang Bian\({}^{3}\), Xia Hu\({}^{4}\)

\({}^{1}\)Texas A&M University, \({}^{2}\)University of Science and Technology of China,

\({}^{3}\)University of Florida, \({}^{3}\)Rice University

###### Abstract

As graph neural networks (GNNs) struggle with large-scale graphs due to high computational demands, graph data distillation promises to alleviate this issue by distilling a large real graph into a smaller distilled graph while maintaining comparable prediction performance for GNNs trained on both graphs. However, we observe that GNNs trained on distilled graphs may exhibit more severe group fairness issues than GNNs trained on real graphs for vanilla and fair GNNs training. Motivated by these observations, we propose _fair graph distillation_ (FGD), an advanced graph distillation approach to generate fair distilled graphs. The challenge lies in the deficiency of sensitive attributes for nodes in the distilled graph, making most debiasing methods (e.g., regularization and adversarial debiasing) intractable for distilled graphs. We develop a simple yet effective bias metric, named coherence, for distilled graphs. Based on the proposed coherence metric, we introduce a framework for fair graph distillation using a bi-level optimization algorithm. Extensive experiments demonstrate that the proposed algorithm can achieve better prediction performance-fairness trade-offs across various datasets and GNN architectures.

## 1 Introduction

Real-world data, like chemical molecules, social networks, and transportation networks, can be represented as graphs [14, 15, 16, 17, 18, 19]. Graph neural networks (GNNs) excel at capturing structural information but struggle with large-scale graphs due to memory consumption and computational expense caused by the neighborhood explosion problem[14, 15]. This cost becomes unaffordable in situations requiring repeated GNN training, such as neural architecture search and continual learning [13, 15, 16, 17]. Dataset distillation is a promising solution to address computation challenges by generating small, informative distilled data for neural network training in downstream tasks [14, 15, 16, 17]. Techniques like dataset condensation [15, 16] can significantly reduce training data size without major performance degradation in the image and graph domains. However, focusing solely on prediction performance may introduce fairness issues, as sensitive information can be condensed into distilled data for prediction. A natural question is raised: _Is the model trained on the distilled graph fair, and if not, how can we achieve fair graph distillation?_

In this work, we focus on the group fairness1 for node classification tasks under binary sensitive attribute setting. We discover that GNNs trained on distilled small graphs exhibit more severe group fairness issues than those on real graphs. In other words, graph distillation can even _amplify_ graphdata bias, which challenges the applicability of graph distillation in high-stake applications (Mehrabi et al., 2021; Suresh and Guttag, 2019). To this end, we propose a fair graph distillation framework to offer a significantly reduced graph size and also better utility-fairness trade-off while maintaining predictive performance.

Many debias methods explicitly use sensitive attributes, but these are inherently missing in distilled graphs because they are excluded from the data attributes and the meaning of the attributes may change during the optimization process. In this paper, we point out the relationship between the space of real graphs and the space of distilled graphs and develop a simple estimator of sensitive attributes and introduce a bias measurement called consistency. We then propose a bi-level optimization algorithm for fair graph distillation: the outer loop generates a fair and informative distilled graph using gradient matching and coherence loss, while GNNs train on distilled graphs in the inner loop. In a nutshell, the contributions can be summarized as follows:

* To our knowledge, this is the first paper to identify group fairness issues in conventional graph distillation methods with binary sensitive attributes, motivating the formulation of a fair graph distillation problem in node classification tasks.
* We discover the relationship between the space of real graphs and the space of distilled graphs. We develop a bias metric called coherence for distilled graphs and propose a bi-level optimization framework using this metric to achieve fair graph distillation.
* We perform extensive experiments on various real-world datasets and GNN architectures to validate the effectiveness of the proposed FGD algorithm. Results demonstrate that FGD achieves a better accuracy-fairness trade-off compared to vanilla graph distillation methods and numerous baselines.

## 2 Preliminaries

### Notations

We consider node classification tasks given a graph dataset \(\mathcal{G}=\{\bm{A},\bm{X},\bm{Y},\bm{S}\}\) with \(N\) nodes. Here, \(\bm{A}\in\{0,1\}^{N\times N}\) is the adjacency matrix, and \(A_{ij}=1\) represents there exists an edge between node \(i\) and \(j\). \(\bm{X}\in\mathbb{R}^{N\times D}\) is the node feature matrix, where \(D\) is non-sensitive feature dimension for each node. \(\bm{Y}\in\{0,1,\cdots,C-1\}^{N}\) denotes the node labels over \(C\) classes. For simplicity, we consider a binary sensitive attribute2\(\bm{S}\in\{0,1\}^{N}\). \(\bm{\Pi}^{s}\) is the sensitive membership diagonal matrix. \(\bm{\Pi}^{s}_{ii}=1\) if and only if \(i\)-th node belongs to sensitive group \(s\). The distilled small graph dataset is marked as \(\mathcal{G}^{\prime}=\{\bm{A}^{\prime},\bm{X}^{\prime},\bm{Y}^{\prime}\}\) which contains \(N^{\prime}\) nodes and \(N^{\prime}\ll N\). Note that elements of the distilled adjacency matrix satisfy \(\bm{A}^{\prime}_{ij}\in[0,1]\) and no sensitive attributes exist in \(\mathcal{G}^{\prime}\). The latent node representation of real graph is \(\bm{Z}\), and the span space of it is \(\text{span}(\bm{Z})\coloneqq\big{\{}\sum_{i=1}^{N}w_{i}\bm{z}_{i}|1\leq i\leq N,w_{i}\in\mathbf{R}\big{\}}\). Similar definition of \(\bm{Z}^{\prime}\) and \(\text{span}(\bm{Z}^{\prime})\) for distilled graph.

Footnote 2: The sensitive attribute \(S\) represents the attribute that the respondents do not want to be disclosed, such as gender or age. Sensitive attribute \(S\) is not included in the normal features \(X\).

### Graph Distillation via Gradient Matching

The purpose of graph distillation is to generate a _distilled_ graph \(\mathcal{G}^{\prime}\) such that the GNN model, denoted as \(\text{GNN}_{\theta}\) with parameters \(\theta\), trained on distilled graph performs _comparably_ to the model trained on the real graph \(\mathcal{G}\). The objective can be formulated as the following bi-level optimization problem:

\[\min_{\mathcal{G}^{\prime}}\mathcal{L}\left(\text{GNN}_{\theta^{\mathcal{G}^{ \prime}}}\left(\bm{A},\bm{X}\right),\bm{Y}\right)\ \ \text{s.t}\ \ \ \theta^{\mathcal{G}^{\prime}}=\underset{\theta}{\arg\min}\mathcal{L}\left( \text{GNN}_{\theta}\left(\bm{A}^{\prime},\bm{X}^{\prime}\right),\bm{Y}^{\prime}\right)\] (1)

where \(\theta^{\mathcal{G}^{\prime}}\) denotes the optimal parameter trained on distilled small graph \(\mathcal{G}^{\prime}\), and \(\mathcal{L}(\cdot,\cdot)\) denotes the loss function. To tackle the above optimization problem, the gradient matching method Zhao et al.

Figure 1: AUC and \(\Delta_{DP}\) of the GNN trained on real graph data and distilled graph data. Both utility and fairness performance deteriorates after vanilla graph distillation.

[2021a] is proposed. The intuition is to let the GNN parameters \(\theta^{\mathcal{G}^{\prime}}\) trained on distilled graph follow a similar path to the GNN parameters \(\theta^{\mathcal{G}}\) trained on the real graph during model optimization. The gradient of the GNN parameters is forced to be the same over the real and distilled graphs:

\[\min_{\mathcal{G}^{\prime}}\left[\sum_{t=0}^{T-1}D\left(\nabla_{\theta}\mathcal{ L}(\mathcal{G}),\nabla_{\theta}\mathcal{L}(\mathcal{G}^{\prime})\right)\right],\] (2)

where \(D(\cdot,\cdot)\) is a distance function, \(T\) is the number of steps of model parameters trajectory, and \(\theta_{t}^{\mathcal{G}},\theta_{t}^{\mathcal{G}^{\prime}}\) denotes the model parameters trained on \(\mathcal{G}\) and \(\mathcal{G}^{\prime}\) at time step \(t\), respectively. The gradient calculated on \(\mathcal{G}\) and \(\mathcal{G}^{\prime}\) is denoted as \(\nabla_{\theta}\mathcal{L}(\mathcal{G})\coloneqq\nabla_{\theta}\mathcal{L} \left(\text{GNN}_{\theta_{t}}\left(\bm{A},\bm{X}\right),\bm{Y}\right)\) and \(\nabla_{\theta}\mathcal{L}(\mathcal{G}^{\prime})\coloneqq\nabla_{\theta} \mathcal{L}\left(\text{GNN}_{\theta_{t}}\left(\bm{A}^{\prime},\bm{X}^{\prime} \right),\bm{Y}^{\prime}\right)\), respectively.

## 3 Bias Measurement for Distilled Graph

In this section, we empirically demonstrate the fairness issue in the distilled graph. Motivated by this, we pursue fair graph distillation. Although distilled graphs lack sensitive attributes \(\bm{S}^{\prime}\), we observe that between the node representations of the real and distilled graphs: their barycenter remain consistent, and their spaces are also consistent. We leverage this phenomenon to develop a simple, effective bias measurement for distilled graphs.

### Is Graph Distillation Really Fair?

Our empirical investigation assesses the fairness of graph distillation across various datasets and architectures. We compare the utility (AUC) and fairness (demographic parity (\(\Delta_{DP}\)) [Beutel et al., 2017]) of GNNs trained on real graphs and those trained on distilled graphs created by the vanilla graph distillation method. The utility and fairness performance are shown in Figure 1. We can find that: For datasets like Pokec-n, German, and Credit, distilled graph-based GNNs have higher \(\Delta_{DP}\) and lower AUC performance, suggesting a compromise in fairness and prediction performance. We also notice that, for Pokec-z and Recidivism datasets, these GNNs exhibit lower \(\Delta_{DP}\) and significantly lower AUC performance (shown in Table 1), indicating a trade-off between improved fairness and reduced prediction performance. We observe similar results when using other fair GNN models. More details can be found in Appendix E. Motivated by these observations, we aim to find a better prediction performance and fairness trade-off via chasing the fair graph distillation method.

### Geometric Connections in Data Distillation

The distilled data can be generated via minimizing gradient distance in Equation 2. To simplify the analysis, we consider \(D(\cdot,\cdot)\) as Euclidean distance and those model parameters during optimization trajectory satisfying \(\theta\sim\mathcal{P}_{\theta}\), where \(\mathcal{P}_{\theta}\) is certain but unknown parameters' distribution. Therefore, the objective can be transformed as

\[\min_{\mathcal{G}^{\prime}}\mathbb{E}_{\theta\sim\mathcal{P}_{\theta}}\big{[} ||\nabla_{\theta}\mathcal{L}(\mathcal{G})-\nabla_{\theta}\mathcal{L}( \mathcal{G}^{\prime})||^{2}\big{]}.\] (3)

We consider three assumptions of the model parameters' distribution and the convergence for loss minimization.

**Assumption 3.1** (Model parameters' distribution).: We assume that each model parameter in the last softmax layer satisfies the same distribution.

**Assumption 3.2** (Loss minimization).: We assume that exists at least one distilled dataset that minimizes Equation 3.

**Theorem 3.3** (Consistent Span Space).: _We empirically show that \(\text{span}(\bm{Z}^{\prime})\approx\text{span}(\bm{Z})\) via calculating the principle angles between them. We also provides the rigorous proof of \(\bm{z}^{\prime}\in\text{span}(\bm{Z})\) under distribution matching in Appendix D._

**Theorem 3.4** (Consistent Geometric Barycenters).: _Under Assumptions 3.1 and 3.2, the barycenter of the last representation for the optimal distilled graph and the real graphs are consistent, i.e. \(\frac{1}{N}\sum_{i=1}^{N}\bm{z}_{i}=\frac{1}{N^{\prime}}\sum_{i=1}^{N^{\prime}} \bm{z}_{i}^{\prime}\). Please see proof in Appendix B._

Figure 2: Geometric intuition of sensitive attribute estimation. The projection distance indicates the extent to which the node belongs to the sensitive group. (a) Unfair node representations have a large coherence bias. (b) Fair node representations have a small coherence bias.

### Sensitive Attribute Estimation

The consistent span space and geometric barycenter suggest that we can estimate sensitive attributes from the representations of both distilled and real graphs. We frame sensitive attribute estimation as a classification problem: Given a data representation \(\bm{z}^{\prime}\in\bm{Z}^{\prime}\), what is the probability that \(\bm{z}^{\prime}\) belongs to the sensitive group?

Ridge regression for distance measurement.Notice that the representation of each sensitive group for the real graph is known, we define \(\bm{Z}_{0}\) and \(\bm{Z}_{1}\) as the representation matrix for sensitive group \(s=0\) and \(s=1\). To measure the probability that \(\bm{z}^{\prime}\) belongs to these two sensitive groups, we first find the closest vector \(\bm{z}^{\prime}_{proj}=\bm{Z}^{\top}_{s}\bm{q}\in\text{Span}(Z_{s})\) to approximate the representation \(\bm{z}^{\prime}\), and then use the norm of \(\bm{z}^{\prime}-\bm{z}^{\prime}_{proj}\) to measure the distance between \(\bm{z}^{\prime}\) and sensitive group \(\bm{Z}_{s}\). Specifically, we adopt ridge regression to find the optimal coefficient vector \(\bm{q}_{*}\), which can be formulated as

\[Dist(\bm{z}^{\prime},\bm{Z}_{s})=\|\bm{z}^{\prime}-\bm{Z}^{\top}_ {s}\bm{q}^{*}\|_{2}\] (4) \[\text{s.t }\bm{q}^{*}=\operatorname*{arg\,min}_{\bm{q}}\gamma\| \bm{z}^{\prime}-\bm{Z}^{\top}_{s}\bm{q}\|_{2}^{2}+\|\bm{q}\|_{2}^{2},\] (5)

where \(\gamma\) is the hyperparameter for ridge regression. For the optimal \(q^{*}\), we have

\[\bm{p}^{s}=\bm{z}^{\prime}-\bm{Z}^{\top}_{s}\bm{q}^{*}=\bm{z}^{\prime}-\gamma \bm{Z}^{\top}_{s}(\bm{I}+\gamma\bm{Z}_{s}\bm{Z}^{\top}_{s})^{-1}\bm{Z}_{s}\bm{z }^{\prime},\] (6)

where \(\top\) represents matrix transpose, \(\bm{p}^{s}\) is approximately the projection onto the orthogonal complement of the subspace \(\text{span}(\bm{Z}_{s})\). The proof is in Appendix C.

Sensitive attribute soft estimation.Since \(\bm{p}^{s}=\bm{z}^{\prime}-\gamma\bm{Z}^{\top}_{s}(\bm{I}+\gamma\bm{Z}_{s} \bm{Z}^{\top}_{s})^{-1}\bm{Z}_{s}\bm{z}^{\prime}\) can be viewed as approximately the projection of \(\bm{z}\) onto the orthogonal complement of sensitive group \(\bm{Z}_{s}\), \(\|\bm{p}^{s}\|_{2}\) is small if \(\bm{z}\) is in sensitive group \(\bm{Z}_{s}\) and large otherwise. The probability of the given data representation \(\bm{z}\) belongs to the sensitive group \(\bm{Z}_{s}\) can further be inferred via a softmax function:

\[\pi^{s}(\bm{z}^{\prime})=\frac{\exp{(-\lambda\,\|\bm{p}^{s}\|_{2})}}{\sum_{s= 0}^{1}\exp{(-\lambda\,\|\bm{p}^{s}\|_{2})}}\,\in[0,1],\] (7)

where \(\lambda\) is the temperature hyperparameter. The sensitive attribute probability of \(\bm{z}^{\prime}\) for distilled graph can be estimated as probability distribution \([\pi^{s=0}(\bm{z}^{\prime}),\pi^{s=1}(\bm{z}^{\prime})]\), where \(\pi^{s=0}(\bm{z}^{\prime})+\pi^{s=1}(\bm{z}^{\prime})=1\).

### Bias Measurement

Given the estimated sensitive attribute probability for \(\bm{z}^{\prime}\) of each distilled node, how can we measure the bias for them? For a fair representation, we can not distinguish which representation is more likely to be a specific sensitive group. Therefore, we adopt a simple surrogate bias measurement, named coherence, the variance of the estimated sensitive group membership. Given the whole distilled data representation \(\bm{Z}^{\prime}=[\bm{z}_{1}...,\bm{z}_{N^{\prime}}]^{\top}\), the bias can be defined as:

\[Coh^{s}(\bm{Z}^{\prime})=\widehat{Var}\left(\bm{\pi}^{s}(\bm{Z}^{\prime}) \right)=\frac{1}{N^{\prime}}\sum_{n=1}^{N^{\prime}}\left(\bm{\pi}^{s}(\bm{z}^ {\prime}_{n})-\frac{1}{N^{\prime}}\sum_{n=1}^{N^{\prime}}\bm{\pi}^{s}(\bm{z}^ {\prime}_{n})\right)\]

Note that \(Coh^{s=0}(\bm{Z}^{\prime})=Coh^{s=1}(\bm{Z}^{\prime})\), and we adopt abbreviation \(Coh(\bm{Z}^{\prime})\)3.

Footnote 3: For multiple-value sensitive attribute, we can use average coherence \(Coh(\bm{Z}^{\prime})\) across all sensitive groups.

Geometric intuition.The intuition of sensitive attribute estimation, as illustrated in Figure 2, can be grasped from a geometric standpoint. In a toy example with a two-dimensional data representation, \(\bm{z}^{\prime}\in\mathbb{R}^{2}\), we consider two demographic groups for a binary sensitive attribute. The subspace spanned by the data representations from these groups is denoted by \(\mathcal{S}^{0}\) and \(\mathcal{S}^{1}\). Data representations to be estimated are \(\bm{z}^{\prime}_{0}\) and \(\bm{z}^{\prime}_{1}\). \(\bm{p}^{0}_{0}\), \(\bm{p}^{0}_{1}\) and \(\bm{p}^{1}_{0}\), \(\bm{p}^{1}_{1}\) is the projection of \(\bm{z}^{\prime}_{0}\) and \(\bm{z}^{\prime}_{1}\) onto the orthogonal complement of \(\mathcal{S}^{0}\) and \(\mathcal{S}^{1}\). As for fair data representation, zero coherent encourages all representations aligned with a "line" so that all representations are with the same normalized similarity with sensitive groups. Figure 2 (a) shows the case in which the data representation is biased where \(\bm{z}^{\prime}_{0}\) and \(\bm{z}^{\prime}_{1}\) can be easily distinguished. Figure 2 (b) shows that fairer data representation as they are less separable.

## 4 Methodology

### Problem Statement

Based on the proposed coherence metric, we argue that if \(Coh(\bm{Z}^{\prime})\) is reduced, bias in the distilled graph can be mitigated. As a result, if GNNs are trained on such distilled graphs, the bias issues in downstream tasks could also be alleviated. The problem is formally defined as: Given an undirected attributed network \(\mathcal{G}=\{\bm{A},\bm{X},\bm{Y},\bm{S}\}\), our goal is to obtain an debiased distilled graph \(\mathcal{G}^{\prime}=\{\bm{A}^{\prime},\bm{X}^{\prime},\bm{Y}^{\prime}\}\) via reducing \(Coh\), so that the fairness issues of GNNs trained on \(\mathcal{G}^{\prime}\) is mitigated. Hence the overall objective goal for generating a fair and condensed graph is:

\[\min_{\mathcal{G}^{\prime}}\mathcal{L}_{GM}+\alpha\mathcal{L}_{Coh }\left(\text{GNN}_{\theta^{\mathcal{G}^{\prime}}}\left(\bm{A}^{\prime},\bm{X }^{\prime}\right),\text{GNN}_{\theta^{\mathcal{G}^{\prime}}}\left(\bm{A},\bm {X}\right)\right)\] \[\text{s.t }\theta^{\mathcal{G}^{\prime}}=\operatorname*{arg\,min}_{ \theta}\mathcal{L}_{CE}\left(\text{GNN}_{\theta}\left(\bm{A}^{\prime},\bm{X }^{\prime}\right),\bm{Y}^{\prime}\right)\] (8)

### Fair Graph Distillation Loss

Gradient Matching Loss.We adopt gradient matching, as shown in equation (2), for graph distillation to distill useful information for node classification tasks. However, treating both \(\bm{X}^{\prime}\) and \(\bm{A}^{\prime}\) as learnable parameter 4 and directly optimizing \(\bm{A}^{\prime}\) is unaffordable due to \(O(N^{2})\) computation complexity. Following previous work Jin et al. (2021), we parameterize \(\bm{A}^{\prime}\) as a function of \(\bm{X}^{\prime}\):

Footnote 4: The distilled label \(\bm{Y}^{\prime}\) is sampled from real label \(\bm{Y}\) with the same class probability, and it is fixed.

\[\bm{A}^{\prime}_{i,j}=\text{Sigmoid}\left(\frac{\text{MLP}_{\phi}([\bm{x}^{ \prime}_{i};\bm{x}^{\prime}_{j}])+\text{MLP}_{\phi}([\bm{x}^{\prime}_{j};\bm{ x}^{\prime}_{i}])}{2}\right),\] (9)

where \(\bm{A}^{\prime}_{i,j}\) is \(i\)-th row, \(j\)-th column of \(\bm{A}^{\prime}\), \(\text{MLP}_{\phi}\) is a multi-layer neural network parameterized with \(\phi\) and \([\cdot;\cdot]\) denotes concatenation. Note that \(\bm{A}^{\prime}\) is controlled to be symmetric since \(\bm{A}^{\prime}_{i,j}=\bm{A}^{\prime}_{j,i}\). Sigmoid function pushes \(\bm{A}^{\prime}\) close to \(0\) or \(1\) to encourage its sparsity. For simplicity, we denote the parameterized adjacency matrix as \(\bm{A}^{\prime}_{\phi}\). In this way, we can reduce the complexity to \(O(N)\).

The distance metric \(D\) measures the similarity of gradients over the real graph and distilled graph. We adopt the summation of the gradient distance over all layers as the final gradient distance:

\[D\left(\nabla_{\theta}\mathcal{L}(\mathcal{G}),\nabla_{\theta}\mathcal{L}( \mathcal{G})^{\prime}\right)=\sum_{i}\left(1-\frac{\nabla_{\theta}\mathcal{L} (\mathcal{G})_{i}\cdot\nabla_{\theta}\mathcal{L}(\mathcal{G})^{\prime}_{i}}{ \|\nabla_{\theta}\mathcal{L}(\mathcal{G})_{i}\|\|\nabla_{\theta}\mathcal{L}( \mathcal{G})^{\prime}_{i}\|}\right)\] (10)

Figure 3: An overview of the proposed framework. The synthesizer generates the attribute matrix and adjacency matrix of the distilled small graph \(\mathcal{G}^{\prime}\). The Cross-Entropy loss \(\mathscr{L}_{CE}\) guides the update of GNNs model during the inner optimization loop. Gradient matching loss \(\mathscr{L}_{GM}\) and coherence loss \(\mathscr{L}_{Coh}\) guide the update of the synthesizer during the outer optimization loop for utility and fairness.

where \(\nabla_{\theta}\mathcal{L}(\mathcal{G})_{i}\) is the i-th column vectors of the gradient matrices. Hence the loss objective for the graph distillation module is given by:

\[\mathscr{L}_{GM}=\mathbf{E}_{\theta\sim P_{0}}\left[\sum_{t=0}^{T-1}D\left( \nabla_{\theta}\mathcal{L}(\mathcal{G}),\nabla_{\theta}\mathcal{L}(\mathcal{G} ^{\prime})\right)\right]\] (11)

where \(\mathcal{G}^{\prime}=\{\bm{X}^{\prime},\bm{A}^{\prime},\bm{Y}^{\prime}\}\), \(t\) is the training epoch, and \(\theta_{t}\) is well-trained GNNs model parameters. To reduce the impact of parameter initialization, the initial model parameters \(\theta_{0}\) are sampled from a distribution of random initialization.

Coherence loss.In Section 3.4, we introduce coherence as a bias metric for distilled data. To mitigate bias, we use coherence bias as a regularization for fair synthesis. This calculation employs real graph node attribute \(\bm{X}\) and distilled node attribute \(\bm{X}^{\prime}\) to estimate sensitive group memberships but overlooks structural bias in graph data. Given the GNN propagation mechanism, bias can exist in both node attributes and graph structure Dong et al. (2022). Even without attribute bias, node representation may still be biased if structural bias is present.

Work by Dong et al. (2022) suggests that structural bias can be measured through graph representation bias. Leveraging this, we aim for low coherence in node attributes and representations to fully remove bias from our distilled graph. Specifically, we introduce attribute and structural coherence to decrease attribute and structural bias, respectively, by minimizing the variance in sensitive group membership estimation for node attributes and representations. Given a real graph data \(\mathcal{G}=\{\bm{A},\bm{X},\bm{Y},\bm{S}\}\) and a distilled graph \(\mathcal{G}^{\prime}=\{\bm{A}^{\prime},\bm{X}^{\prime},\bm{Y}^{\prime}\}\), we feed them into a \(L\)-layer GNN, where the \(l\)-th layer latent representation in the GNN is denoted as \(\bm{Z}_{l}\). The latent representation for node attribute after \(l\)-hop propagation contains both attribute bias as well as structural bias. Note the node attribute \(\bm{X}\) and \(\bm{X}^{\prime}\) before propagation as \(\bm{Z}_{0}\) and \(\bm{Z}_{0}^{\prime}\), we get a set of latent presentation \(\{\bm{Z}_{0},\bm{Z}_{1},...,\bm{Z}_{L}\}\) for \(\mathcal{G}\) and \(\{\bm{Z}_{0}^{\prime},\bm{Z}_{1}^{\prime},...,\bm{Z}_{L}^{\prime}\}\) for \(\mathcal{G}^{\prime}\). The objective to measure bias of \(\bm{Z}_{l}^{\prime}\) is:

\[Coh(\bm{Z}_{l}^{\prime})=\widehat{Var}\left(\bm{\pi}^{j}(\bm{Z}_{l}^{\prime}) \right)=\widehat{Var}\left(\frac{\exp\left(-\lambda\left\|\bm{C}^{j}\bm{Z}_{l }^{\prime}\right\|_{2}\right)}{\sum_{j}\exp\left(-\lambda\left\|\bm{C}^{j} \bm{Z}_{l}^{\prime}\right\|_{2}\right)}\right),\] (12)

where \(\bm{C}^{j}=\gamma_{j}\left(\bm{I}+\gamma_{j}\bm{Z}_{l}\bm{\Pi}^{j}\bm{Z}_{l}^ {T}\right)^{-1}\). \(\bm{\Pi}^{j}\) is introduced in Sec 4.1. Since we consider the binary sensitive attribute, \(j\) is set as \(0\) without losing generality and is omitted in the notations as \(\bm{\pi}^{j}(\cdot):=\bm{\pi}(\cdot)\). After considering all the latent representations, the coherence loss objective is defined as the summation of all coherence over all layers, i.e.,

\[\mathscr{L}_{Coh}=\sum_{l=0}^{L}Coh(\bm{Z}_{l}^{\prime})=\sum_{l=0}^{L} \widehat{Var}\left(\bm{\pi}(\bm{Z}_{l}^{\prime})\right).\] (13)

Prediction loss for GNN training.The GNNs model is trained on distilled graph \(\mathcal{G}^{\prime}=\{\bm{A}^{\prime},\bm{X}^{\prime},\bm{Y}^{\prime}\}\) with prediction loss. We adopt \(L\)-layer GNNs model, where \(\theta\) is the parameter of the GNN. We also adopt cross-entropy loss by default:

\[\mathscr{L}_{CE}=\mathcal{L}\left(\text{GNN}_{\theta}\left(\bm{A}^{\prime}, \bm{X}^{\prime}\right),\bm{Y}^{\prime}\right),\] (14)

### Final Objective and Training Algorithm

Outer loop optimization.In the outer loop, we optimize the fair graph synthesizer with gradient matching loss and coherence loss:

\[\min_{\bm{X}^{\prime},\bm{A}^{\prime}}\mathscr{L}_{GM}+\alpha\mathscr{L}_{Coh},\] (15)

where \(\alpha\) is a hyperparameter to regularize the debiasing intensity. The distilled node attribute \(\bm{X}^{\prime}\) and the distilled node label \(\bm{Y}^{\prime}\) are initialized with the nodes uniformly sampling from real graph data \(\mathcal{G}\).

Inner loop optimization.The GNN parameter \(\theta\) is optimized in the inner loop:

\[\min_{\theta}\mathscr{L}_{CE}\left(\text{GNN}_{\theta}\left(\bm{A}^{\prime}, \bm{X}^{\prime}\right),\bm{Y}^{\prime}\right).\] (16)

Instead of using the real graph data \(\mathcal{G}\) to calculate the loss, we use the distilled graph \(\mathcal{G}^{\prime}\). It empirically shows good performance and better efficiency. But the adversarial training baseline uses \(\mathcal{G}\) as it needs the sensitive attribute for discriminator training.

[MISSING_PAGE_FAIL:7]

### Debiasing distilled Graph

In response to **RQ.1**, we assess FGD's bias mitigation and prediction performance across various GNN architectures and datasets, as shown in Table 1. We compare the \(\Delta_{DP}\) and \(\Delta_{EO}\) values of GNNs trained on real graphs (_Real_), vanilla distilled graphs (_Vanilla_), and debiased distilled graphs via FGD (_FGD_). Key findings include: (1) Models trained on _Real_ graphs consistently outperform _Vanilla_ and _FGD_ in utility, though _FGD_'s utility matches or surpasses _Vanilla_. (2) FGD consistently yields lower bias than _Vanilla_, and outperforms _Real_ on 4 out of 5 datasets, excluding Poken-n.

We compare the coherence bias of distilled graphs generated by _Vanilla_ and _FGD_ methods across five real-world datasets with the GCN architecture (Table 2). Our analysis reveals that FGD reduces unfairness, reflected in lower coherence bias in the distilled graphs. This consistency confirms the effectiveness of coherence bias as a measure of distilled graph bias.

### Trade-Off Comparison

In response to **RQ.2**, we compare the trade-off between model utility and bias mitigation against other baselines using the GCN architecture. We utilize the Pareto frontier Ishizaka and Nemeny (2013) to evaluate our approach's utility-fairness trade-off, using different hyperparameters. The Pareto frontier graphically represents optimal trade-offs in multi-objective optimization. We use AUC as the utility metric and \(\Delta_{DP}\) and \(\Delta_{EO}\) as fairness metrics. Higher AUC and lower \(\Delta_{DP}\)/\(\Delta_{EO}\) are preferred, so models with Pareto frontier curves closer to the bottom right corner (AUC on the horizontal axis and \(\Delta_{DP}\)/\(\Delta_{EO}\) on the vertical) have better trade-off performance.

Figure 4 shows the results for models trained on the real graph, the distilled graph debiased by baseline methods (vanilla graph distillation, FairGNN, and EDITS5) and the distilled graph debiased by FGD. We can observe: (1) From a model utility perspective, FGD performs comparably to other baselines, like vanilla graph distillation, FairGNN, and EDITS 6, suggesting it preserves sufficient information for node classification. (2) In terms of bias mitigation, all baselines show effectiveness, with FGD exhibiting the best results. (3) When considering the utility-fairness trade-off, FGD's Pareto front curve lies at the bottom right corner of all baselines, signifying it offers the best balance. Thus, FGD outperforms other baselines in balancing model utility and bias mitigation.

Footnote 5: EDITS publishes fair graph for German, Credit and Recidivism dataset on Github

Footnote 6: Out of memory (OOM) issue appears when running EDITS on Pokec-z and Pokec-n datasets.

### Add-on Module

\begin{table}
\begin{tabular}{c c c} \hline  & Vanilla & FGD \\ \hline Pokec-z & 0.009468 & \(\textbf{0.002123}-77.57\%\) \\ \hline Pokec-n & 0.004464 & \(\textbf{0.000432}-90.32\%\) \\ \hline German & 0.012772 & \(\textbf{0.003489}-72.68\%\) \\ \hline Credit & 0.011864 & \(\textbf{0.002866}-75.84\%\) \\ \hline Recidivism & 0.000098 & \(\textbf{0.000038}-61.22\%\) \\ \hline \end{tabular}
\end{table}
Table 2: Coherence bias comparison between vanilla distilled graph (denoted as Vanilla) and fair distilled graph (denoted as FGD). The lower, the better. The best ones are marked in bold. The architecture model is GCN.

Figure 4: Trade-off comparison between FGDand other baselines for five real-world graph datasets.

In addition to its superior trade-off performance, our method, FGD, can enhance other debiasing baselines like FairGNN and EDITS by acting as an add-on debias module. This compatibility is due to the fact that these baselines can replace the cross-entropy loss in the GNN training module. To answer **RQ.3**, we conducted experiments on the Credit dataset comparing FairGNN/EDITS performance with and without FGD. As shown in Figure 5, FairGNN/EDITS coupled with FGD delivers better utility-fairness trade-off, demonstrating FGD's potential to boost other debias methods.

## 6 Related Work

Dataset Distillation \(\&\) Knowledge Distillation.Dataset Distillation (DD) and Knowledge Distillation (KD) are methods to improve the efficiency of training deep neural networks. DD synthesizes a small dataset encapsulating the knowledge of a larger one, achieving comparable model performance [22, 23, 24, 25, 26]. It employs a bi-level optimization approach, with dataset condensation (DC) speeding up the process via gradient matching of model parameters. DD also helps with repeated training or privacy applications like continual learning, neural architecture search, and privacy-preserving scenarios. Meanwhile, graph data condensation methods have been developed for node and graph classification tasks [12]. KD, on the other hand, enhances computational efficiency through model compression and acceleration. It trains a compact student model using the knowledge from a larger teacher model Gou et al. [2021]To address the scarcity and high complexity of labeled data in GNNs, knowledge distillation (KD) was introduced to enhance existing GNNs Liu et al. [2023], Wang et al. [2023], also for fairness problem Dong et al. [2023]. While KD focuses on model compression, DD targets data compression, each improving efficiency from model-centric and data-centric perspectives.

Fair Graph Learning.Fairness in machine learning has attracted many research efforts[13, 24, 25, 26, 27, 28]. Many technologies are introduced in graph neural networks to achieve fair graph learning in node classification tasks, including optimization with regularization [24, 25], rebalancing [26], adversarial learning [22, 27] and graph rewiring [28, 29]. For link prediction, dyadic fairness and corresponding graph rewiring solutions are also developed in [10]. Another line of work focuses on solving the individual fairness problem on the graph data Song et al. [2022], Dong et al. [2021], Kang et al. [2020].

## 7 Conclusion

Despite the ability of graph distillation to condense valuable graph data, this study finds that the vanilla method can worsen fairness issues. Therefore, we introduce a fair graph distillation process to generate fair distilled graph data. As the distilled graph lacks the nodes' sensitive attributes, conventional fair methods cannot be directly applied. However, we identify a consistent geometric phenomenon in graph distillation to estimate these sensitive attributes. We also introduce a new bias metric, coherence, and propose a bi-level optimization framework, FGD, for fair graph distillation. Experimental results validate FGD's effectiveness in mitigating bias while maintaining model utility across various GNN architectures and datasets. Future work will focus on addressing individual fairness issues and non-binary sensitive attribute conditions, among other aspects, as discussed in Appendix H.

## Acknowledgements

We are deeply grateful to the National Science Foundation for their unwavering support. This research was substantially facilitated by the funding from grants IIS-1939716 and IIS-1900990.

Figure 5: Trade-off comparison between FairGNN, EDITS and FairGNN+FGD, EDITS+FGD on Credit dataset.

## References

* Agarwal et al. (2021) C. Agarwal, H. Lakkaraju, and M. Zitnik. Towards a unified framework for fair and stable graph representation learning. In _Uncertainty in Artificial Intelligence_, pages 2114-2124. PMLR, 2021.
* Beutel et al. (2017) A. Beutel, J. Chen, Z. Zhao, and E. H. Chi. Data decisions and theoretical implications when adversarially learning fair representations. _arXiv preprint arXiv:1707.00075_, 2017.
* Bose and Hamilton (2019) A. Bose and W. Hamilton. Compositional fairness constraints for graph embeddings. In _International Conference on Machine Learning_, pages 715-724. PMLR, 2019.
* Chuang and Mroueh (2020) C.-Y. Chuang and Y. Mroueh. Fair mixup: Fairness via interpolation. In _International Conference on Learning Representations_, 2020.
* Dai and Wang (2021) E. Dai and S. Wang. Say no to the discrimination: Learning fair graph neural networks with limited sensitive attribute information. In _Proceedings of the 14th ACM International Conference on Web Search and Data Mining_, pages 680-688, 2021.
* Dong et al. (2021) Y. Dong, J. Kang, H. Tong, and J. Li. Individual fairness for graph neural networks: A ranking based approach. In _Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining_, pages 300-310, 2021.
* Dong et al. (2022) Y. Dong, N. Liu, B. Jalaian, and J. Li. Edits: Modeling and mitigating data bias for graph neural networks. In _Proceedings of the ACM Web Conference 2022_, pages 1259-1269, 2022.
* Dong et al. (2023) Y. Dong, B. Zhang, Y. Yuan, N. Zou, Q. Wang, and J. Li. Reliant: Fair knowledge distillation for graph neural networks. In _Proceedings of the 2023 SIAM International Conference on Data Mining (SDM)_, pages 154-162. SIAM, 2023.
* Du et al. (2021) M. Du, S. Mukherjee, G. Wang, R. Tang, A. H. Awadallah, and X. Hu. Fairness via representation neutralization. _arXiv preprint arXiv:2106.12674_, 2021.
* Fisher et al. (2020) J. Fisher, A. Mittal, D. Palfrey, and C. Christodoulopoulos. Debiasing knowledge graph embeddings. In _Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)_, pages 7332-7345, 2020.
* Gou et al. (2021) J. Gou, B. Yu, S. J. Maybank, and D. Tao. Knowledge distillation: A survey. _International Journal of Computer Vision_, 129:1789-1819, 2021.
* Hamilton et al. (2017) W. Hamilton, Z. Ying, and J. Leskovec. Inductive representation learning on large graphs. _Advances in neural information processing systems_, 30, 2017.
* Han et al. (2022a) X. Han, Z. Jiang, N. Liu, and X. Hu. G-mixup: Graph data augmentation for graph classification. _arXiv preprint arXiv:2202.07179_, 2022a.
* Han et al. (2022b) X. Han, Z. Jiang, N. Liu, Q. Song, J. Li, and X. Hu. Geometric graph representation learning via maximizing rate reduction. In _Proceedings of the ACM Web Conference 2022_, pages 1226-1237, 2022b.
* Han et al. (2023) X. Han, Z. Jiang, H. Jin, Z. Liu, N. Zou, Q. Wang, and X. Hu. Retiring $delta text{DP}$: New distribution-level metrics for demographic parity. _Transactions on Machine Learning Research_, 2023. ISSN 2835-8856. URL https://openreview.net/forum?id=LJDFIWWVa.
* Ishizaka and Nemeny (2013) A. Ishizaka and P. Nemeny. _Multi-criteria decision analysis: methods and software_. John Wiley & Sons, 2013.
* Jiang et al. (2022a) Z. Jiang, X. Han, C. Fan, Z. Liu, N. Zou, A. Mostafavi, and X. Hu. Fmp: Toward fair graph message passing against topology bias. _arXiv preprint arXiv:2202.04187_, 2022a.
* Jiang et al. (2022b) Z. Jiang, X. Han, C. Fan, F. Yang, A. Mostafavi, and X. Hu. Generalized demographic parity for group fairness. In _International Conference on Learning Representations_, 2022b.
* Jiang et al. (2023) Z. Jiang, X. Han, H. Jin, G. Wang, R. Chen, N. Zou, and X. Hu. Chasing fairness under distribution shift: a model weight perturbation approach. 2023.
* Jiang et al. (2023)W. Jin, L. Zhao, S. Zhang, Y. Liu, J. Tang, and N. Shah (2021)Graph condensation for graph neural networks. arXiv preprint arXiv:2110.07580. Cited by: SS1.
* W. Jin, X. Tang, H. Jiang, Z. Li, D. Zhang, J. Tang, and B. Yin (2022)Condensing graphs via one-step gradient matching. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pp. 720-730. Cited by: SS1.
* J. Kang, J. He, R. Maciejewski, and H. Tong (2020)Inform: individual fairness on graph mining. In Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery & data mining, pp. 379-389. Cited by: SS1.
* J. Kim, J. Kim, S. J. Oh, S. Yun, H. Song, J. Jeong, J. Ha, and H. O. Song (2022)Dataset condensation via efficient synthetic-data parameterization. In International Conference on Machine Learning, pp. 11102-11118. Cited by: SS1.
* T. N. Kipf and M. Welling (2016)Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907. Cited by: SS1.
* O. D. Kose and Y. Shen (2021)Fairness-aware node representation learning. arXiv preprint arXiv:2106.05391. Cited by: SS1.
* S. Lee, S. Chun, S. Jung, S. Yun, and S. Yoon (2022)Dataset condensation with contrastive signals. In International Conference on Machine Learning, pp. 12352-12364. Cited by: SS1.
* P. Li, Y. Wang, H. Zhao, P. Hong, and H. Liu (2021)On dyadic fairness: exploring and mitigating bias in graph connections. In International Conference on Learning Representations, Cited by: SS1.
* Z. Li and D. Hoiem (2017)Learning without forgetting. IEEE transactions on pattern analysis and machine intelligence40 (12), pp. 2935-2947. Cited by: SS1.
* H. Ling, Z. Jiang, Y. Luo, S. Ji, and N. Zou (2023)Learning fair graph representations via automated data augmentations. In International Conference on Learning Representations, Cited by: SS1.
* H. Liu, K. Simonyan, and Y. Yang (2018)Darts: differentiable architecture search. arXiv preprint arXiv:1806.09055. Cited by: SS1.
* J. Liu, T. Zheng, G. Zhang, and Q. Hao (2023)Graph-based knowledge distillation: a survey and experimental evaluation. arXiv preprint arXiv:2302.14643. Cited by: SS1.
* Z. Liu, Z. Jiang, S. Zhong, K. Zhou, L. Li, R. Chen, S. Choi, and X. Hu (2023)Editable graph neural network for node classifications. arXiv preprint arXiv:2305.15529. Cited by: SS1.
* Z. Liu, K. Zhou, Z. Jiang, L. Li, R. Chen, S. Choi, and X. Hu (2023)DSpar: an embarrassingly simple strategy for efficient GNN training and inference via degree-based sparsification. Transactions on Machine Learning Research2023c. ISSN 2835-8856. External Links: Link, Document Cited by: SS1.
* C. Louizos, K. Swersky, Y. Li, M. Welling, and R. Zemel (2015)The variational fair autoencoder. arXiv preprint arXiv:1511.00830. Cited by: SS1.
* N. Mehrabi, F. Morstatter, N. Saxena, K. Lerman, and A. Galstyan (2021)A survey on bias and fairness in machine learning. ACM Computing Surveys (CSUR)54 (6), pp. 1-35. Cited by: SS1.
* T. Nguyen, R. Novak, L. Xiao, and J. Lee (2021)Dataset distillation with infinitely wide convolutional networks. Advances in Neural Information Processing Systems34, pp. 5186-5198. Cited by: SS1.
* W. Song, Y. Dong, N. Liu, and J. Li (2022)Guide: group equality informed individual fairness in graph neural networks. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pp. 1625-1634. Cited by: SS1.
* H. Suresh and J. V. Guttag (2019)A framework for understanding unintended consequences of machine learning. arXiv preprint arXiv:1901.10002. Cited by: SS1.
*L. Takac and M. Zabovsky. Data analysis in public social networks. In _International scientific conference and international workshop present day trends of innovations_, volume 1. Present Day Trends of Innovations Lamza Poland, 2012.
* Tong et al. (2020) A. Tong, J. Huang, G. Wolf, D. Van Dijk, and S. Krishnaswamy. Trajectorynet: A dynamic optimal transport network for modeling cellular dynamics. In _International conference on machine learning_, pages 9526-9536. PMLR, 2020.
* Wang et al. (2018) T. Wang, J.-Y. Zhu, A. Torralba, and A. A. Efros. Dataset distillation. _arXiv preprint arXiv:1811.10959_, 2018.
* Wang et al. (2023) Y. Wang, B. Hooi, Y. Liu, and N. Shah. Graph explicit neural networks: Explicitly encoding graphs for efficient and accurate inference. In _Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining_, pages 348-356, 2023.
* Wu et al. (2019) F. Wu, A. Souza, T. Zhang, C. Fifty, T. Yu, and K. Weinberger. Simplifying graph convolutional networks. In _International conference on machine learning_, pages 6861-6871. PMLR, 2019.
* Yang et al. (2022) S. Yang, Z. Xie, H. Peng, M. Xu, M. Sun, and P. Li. Dataset pruning: Reducing training data by examining generalization influence. _arXiv preprint arXiv:2205.09329_, 2022.
* Ying et al. (2018) R. Ying, R. He, K. Chen, P. Eksombatchai, W. L. Hamilton, and J. Leskovec. Graph convolutional neural networks for web-scale recommender systems. In _Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining_, pages 974-983, 2018.
* Zeng et al. (2021) Z. Zeng, R. Islam, K. N. Keya, J. Foulds, Y. Song, and S. Pan. Fair representation learning for heterogeneous information networks. In _Proceedings of the International AAAI Conference on Web and Social Media_, volume 15, pages 877-887, 2021.
* Zhang et al. (2018) B. H. Zhang, B. Lemoine, and M. Mitchell. Mitigating unwanted biases with adversarial learning. In _Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society_, pages 335-340, 2018.
* Zhao et al. (2021a) B. Zhao, K. R. Mopuri, and H. Bilen. Dataset condensation with gradient matching. _ICLR_, 1(2):3, 2021a.
* Zhao et al. (2021b) B. Zhao, K. R. Mopuri, and H. Bilen. Dataset condensation with gradient matching. _ICLR_, 1(2):3, 2021b.
* Zhou et al. (2019) K. Zhou, Q. Song, X. Huang, and X. Hu. Auto-gnn: Neural architecture search of graph neural networks. _arXiv preprint arXiv:1909.03184_, 2019.

Training Algorithm

The training algorithm for fair graph distillation is shown in Algorithm 1.

``` Input: Training graph data \(\mathcal{G}=\{\bm{X},\bm{A},\bm{S},\bm{Y}\}\), hyperparameters \(\alpha\), temperature \(\gamma\), number of alternative optimization step \(T_{alt}\), distilled label \(\bm{Y}^{\prime}\).  Initialize \(\bm{X}^{\prime}\) based on real attributes, synthesizer model \(\phi\), and GNNs model \(\theta\). for t = 1 to \(T_{alt}\)do  1. Train GNNs model using distilled graph \(\mathcal{G}^{\prime}_{t}\) and Equation (15) to obtain \(GNN_{\theta_{t}}\).  2. Given GNNs model \(GNN_{\theta_{t}}\), calculate the gradient distance \(D\big{(}\nabla_{\theta}\mathcal{L}(\mathcal{G}),\nabla_{\theta}\mathcal{L}( \mathcal{G}^{\prime}_{t})\big{)}\) over the real graph \(\mathcal{G}\) and distilled graph \(\mathcal{G}^{\prime}_{t}\).  3. Calculate coherence loss based on GNNs model \(GNN_{\theta_{t}}\), real graph \(\mathcal{G}\) and distilled graph \(\mathcal{G}^{\prime}_{t}\).  4. Train synthesizer model using prediction loss as Equation (16). endfor Output: The fair distilled graph \(\mathcal{G}^{\prime}=\{\bm{A}^{\prime},\bm{X}^{\prime},\bm{Y}^{\prime}\}\). ```

**Algorithm 1** Fair Graph Distillation

## Appendix B Proof of Theorem 3.4

We consider GNNs model to learn node presentation \(\bm{z}_{i}\) in the real graph \(\mathcal{G}\) and then followed a linear classifier \(\bm{W}=[\bm{w}_{0},\cdots,\bm{w}_{C-1}]\) and softmax layer, where \(\bm{w}_{j}\) is the weight vector connected to the \(j\)-tj output neuron. We first focus on the relation between the latent representation and the gradient of the linear classification layer. It is easy to obtain the cross-entropy loss \(J_{i}\) (\(J^{\prime}_{i}\)) for \(i\)-th node with label \(y_{i}\) in real graph \(\mathcal{G}\) (distilled graph \(\mathcal{G}^{\prime}\)) as follows:

\[J_{i}=-\log\frac{\exp(\bm{w}_{y_{i}}^{\top}\cdot\bm{z}_{i})}{\sum_{k}\exp(\bm {w}_{k}^{\top}\cdot\bm{z}_{i})},\] (17)

Then we define gradient over weight vector as \(\bm{g}_{i,j}=\frac{\partial J_{i}}{\partial\bm{w}_{j}}\) and \(\bm{g}^{\prime}_{i,j}=\frac{\partial J^{\prime}_{i}}{\partial\bm{w}_{j}}\) in the real and distilled graph. If \(j=y_{i}\), we can obtain

\[\bm{g}_{i,y_{i}} =-\frac{\sum_{k}\exp(\bm{w}_{k}^{\top}\cdot\bm{z}_{i})}{\exp(\bm {w}_{y_{i}}^{\top}\cdot\bm{z}_{i})}\] \[\cdot\frac{\exp(\bm{w}_{y_{i}}^{\top}\cdot\bm{z}_{i})\sum_{k}\exp (\bm{w}_{k}^{\top}\cdot\bm{z}_{i})-\exp^{2}(\bm{w}_{y_{i}}^{\top}\cdot\bm{z}_ {i})}{\big{(}\sum_{k}\exp(\bm{w}_{k}^{\top}\cdot\bm{z}_{i})\big{)}^{2}}\cdot \bm{z}_{i}\] \[=-\bm{z}_{i}+\frac{\exp(\bm{w}_{y_{i}}^{\top}\cdot\bm{z}_{i})}{ \sum_{k}\exp(\bm{w}_{k}^{\top}\cdot\bm{z}_{i})}\cdot\bm{z}_{i},\] (18)

Similarly, for \(j\neq y\), we have

\[\bm{g}_{i,j}=\frac{\exp(\bm{w}_{y_{i}}^{\top}\cdot\bm{z}_{i})}{\sum_{k}\exp( \bm{w}_{k}^{\top}\cdot\bm{z}_{i})}\cdot\bm{z}_{i},\] (19)

In other words, the gradient of the loss for \(i\)-th node with label \(y_{i}\) with respect to the weight vector connected to the \(j\)-th output neuron is given by

\[\bm{g}_{i,j}=\frac{\exp(\bm{w}_{y_{i}}^{\top}\cdot\bm{z}_{i})}{\sum_{k}\exp( \bm{w}_{k}^{\top}\cdot\bm{z}_{i})}\cdot\bm{z}_{i}-\mathbb{I}_{j=y_{i}}\bm{z}_ {i}.\] (20)

Based on Assumption 3.1, each model parameter in the last softmax layer satisfies the same distribution. In other words, the expectation of all predictions are the same, i.e.,

\[\mathbb{E}_{\mathcal{P}_{\theta}}\Big{[}\frac{\exp(\bm{w}_{0}^{\top}\cdot\bm{z} _{i})}{\sum_{k}\exp(\bm{w}_{k}^{\top}\cdot\bm{z}_{i})}\Big{]}=\cdots=\mathbb{E }_{\mathcal{P}_{\theta}}\Big{[}\frac{\exp(\bm{w}_{C-1}^{\top}\cdot\bm{z}_{i})}{ \sum_{k}\exp(\bm{w}_{k}^{\top}\cdot\bm{z}_{i})}\Big{]}.\] (21)Note that the gradient calculation is based on backpropagation, the gradient for the last linear classification layer is quite critical for the gradient of other layers. Hence we consider the gradient of the last linear classification layer in the real graph, shown by

\[\mathbb{E}_{\theta\sim\mathcal{P}_{\theta}}\big{[}\nabla_{\bm{w}_{j} }\mathcal{L}(\mathcal{G})\big{]} =\mathbb{E}_{\theta\sim\mathcal{P}_{\theta}}\big{[}\frac{1}{N} \sum_{i=1}^{N}\bm{g}_{i,j}\big{]}\] \[=\frac{1}{NC}\sum_{i=1}^{N}\bm{z}_{i}-\frac{1}{N}\sum_{\{i:y_{i}= j\}}\bm{z}_{i},\] (22)

Similarly, we have the gradient of the last linear classification layer in the distilled graph as follows:

\[\mathbb{E}_{\theta\sim\mathcal{P}_{\theta}}\big{[}\nabla_{\bm{w}_ {j}}\mathcal{L}(\mathcal{G}^{\prime})\big{]} =\mathbb{E}_{\theta\sim\mathcal{P}_{\theta}}\big{[}\frac{1}{N^{ \prime}}\sum_{i=1}^{N}\bm{g}^{\prime}_{i,j}\big{]}\] \[=\frac{1}{N^{\prime}C}\sum_{i=1}^{N^{\prime}}\bm{z}^{\prime}_{i}- \frac{1}{N^{\prime}}\sum_{\{i:y^{\prime}_{i}=j\}}\bm{z}^{\prime}_{i},\] (23)

Under assumption 3.2, it is easy to know that the optimal solution to minimizing the objective \(\min_{\mathcal{G}^{\prime}}\mathbb{E}_{\theta\sim\mathcal{P}_{\bm{W}}}\big{[} ||\nabla_{\bm{W}}\mathcal{L}(\mathcal{G})-\nabla_{\bm{W}}\mathcal{L}( \mathcal{G}^{\prime})||^{2}\big{]}\) satisfy \(\nabla_{\bm{W}}\mathcal{L}(\mathcal{G})=\nabla_{\bm{W}}\mathcal{L}(\mathcal{ G}^{\prime})\). Since the distilled label is sampling to keep class label probability, we have \(\frac{|\{i:y^{\prime}=j\}|}{N^{\prime}}=\frac{|\{i:y_{i}=j\}|}{N}\) for any class index \(i\). Therefore, based on Equations (22) and (23), we have the optimal distilled graph satisfy

\[\frac{1}{N}\sum_{i=1}^{N}\bm{z}_{i}=\frac{1}{N^{\prime}}\sum_{i=1}^{N^{\prime} }\bm{z}^{\prime}_{i}.\] (24)

## Appendix C Proof of Ridge Regression

Define objective function \(J=\gamma\|\bm{z}^{\prime}-\bm{Z}^{\top}_{s}\bm{q}\|_{2}^{2}+\|\bm{q}\|_{2}^{2}\), it is easy to obtain

\[\frac{\partial J}{\partial\bm{q}}=-2\gamma\bm{Z}_{s}\big{(}\bm{z}^{\prime}- \bm{Z}^{\top}_{s}\bm{q}\big{)}+2\bm{q}=0\] (25)

Therefore, the optimal \(\bm{q}^{*}=\gamma(\bm{I}+\gamma\bm{Z}_{s}\bm{Z}^{\top}_{s})^{-1}\bm{Z}_{s}\bm {z}^{\prime}\). Therefore, the projection of representation \(\bm{z}^{\prime}\) in the complement space of sensitive group \(\bm{Z}_{s}\) is given by

\[\bm{z}^{\prime}-\bm{Z}^{\top}_{s}\bm{q}^{*}=\bm{z}^{\prime}-\gamma\bm{Z}^{ \top}_{s}(\bm{I}+\gamma\bm{Z}_{s}\bm{Z}^{\top}_{s})^{-1}\bm{Z}_{s}\bm{z}^{\prime}\] (26)

## Appendix D More Results on Consistent Span Space

We conduct experiments to measure the distance between \(span(Z)\) and \(span(Z^{\prime})\) using principle angles between subspaces and emperically shows that \(span(Z)\approx span(Z^{\prime})\) in the real dataset.

The concept of principal angle is used in linear algebra to measure the similarity between two subspaces of a vector space. It helps quantify how close or far apart these subspaces are. Given subspace, \(\mathbf{L},\mathbf{M}\subseteq\mathbb{R}^{n}\), with \(\dim\mathbf{L}=l\geq\dim\mathbf{M}=m\), there are m principal angles between L and M denoted as \(0\leq\theta_{1}\leq\theta_{2}\leq\cdots\leq\theta_{m}\leq\frac{\pi}{2}\) between L and M are recursively defined, where

\[\cos\left(\theta_{i}\right):=\min\left\{\frac{\langle\mathbf{x},\mathbf{y}>}{ \|\mathbf{x}\|\|\mathbf{y}\|}\mid\mathbf{x}\in\mathbf{L},\mathbf{y}\in \mathbf{M},\mathbf{x}\perp\mathbf{x}_{k},\mathbf{y}\perp\mathbf{y}_{k},k=1, \cdots,i-1\right\}.\] (27)

Notably, when the two subspaces are aligned, the principal angels are close to 0. We report the average principal angles of \(span(Z)\) and \(span(Z^{\prime})\) on all datasets as following:

* Pokec-z: \(1.08\times 10^{-6}\)
* Pokec-n: \(1.03\times 10^{-6}\)
* German: \(4.84\times 10^{-7}\)* Credit: \(2.57\times 10^{-7}\)
* Recidivism: \(3.87\times 10^{-7}\)

In the experiments, the principal angles of \(span(Z)\) and \(span(Z^{\prime})\) on all dataset are nearly 0. This indicates that the distance between space \(span(Z^{\prime})\) and space \(span(Z)\) are quite small in practice.

Additionally, we would like to mention that [1] provides the rigorous proof of \(z^{\prime}\in span(Z)\) for distribution matching under several assumptions (although we can not prove it under gradient matching setting). According to formulas 21 from [1], it is assumed that (1) the **linear extractor**\(\psi_{\bm{\theta}}:\mathbb{R}^{d}\rightarrow\mathbb{R}^{k}\) such that \(k<d,\bm{\theta}=[\theta_{i,j}]\in\mathbb{R}^{k\times d}\), \(\theta_{i,j}\overset{iid}{\sim}\mathcal{N}(0,1)\) and for an input \(\mathbf{z}\), \(\psi_{\bm{\theta}}(\mathbf{x})=\bm{\theta}\mathbf{z}\). When using distribution match method for data condensation, we have:

\[\frac{\partial L}{\partial\mathbf{z}^{\prime}_{i}}=\frac{\partial E_{\theta}|| d||^{2}}{\partial\mathbf{z}^{\prime}_{i}}=-\frac{2}{|N^{\prime}|}\left(\frac{1}{N} \sum_{j=1}^{N}\mathbf{z}_{j}-\frac{1}{N^{\prime}}\sum_{j=1}^{N^{\prime}} \mathbf{z}^{\prime}_{j}\right)^{T}\cdot E[\bm{\theta}^{t}\bm{\theta}]\]

where \(d:=\theta\left(\frac{1}{N}\sum_{j=1}^{N}\mathbf{z}_{j}-\frac{1}{N^{\prime}} \sum_{j=1}^{N^{\prime}}\mathbf{z}^{\prime}_{j}\right)\), \(\mathbb{E}\left[\bm{\theta}^{\top}\bm{\theta}\right]=k\mathbf{I}_{d}\) by definition of \(\bm{\theta}\), and \(\mathbf{I}_{d}\) is the identity matrix of \(\mathbb{R}^{d}\). the projection components of \(\mathrm{span}(Z)^{\perp}\) remain zero throughout the optimization process of DM. And we use \(\mathbf{z}_{i}\) to initialize \(\mathbf{z}^{\prime}_{i}\), thus \(\mathbf{z}^{\prime}\in span(Z)\). However, in the implementation we use gradient matching instead of distribution matching.

## Appendix E Preliminary Motivation

We have added experiments comparing the fairness performance of various fair GNNs trained on synthetic and real graph data. Specifically, we report the results (using demographic parity (DP), equal opportunity (EO), and individual unfairness (IND) Song et al. (2022) as metrics) with EDITS Dong et al. (2022), FairGNN Dai and Wang (2021), InFoRM Kang et al. (2020), and REDBESS Dong et al. (2021) on five datasets in our paper. EDITS is a pre-processing debiasing method, FairGNN is an in-processing debiasing method, and InFoRM and REDBESS focus on individual fairness. We encountered out-of-memory (OOM) issues when implementing GUIDE and REDBESS on an NVIDIA GeForce RTX A5000 (24GB GPU memory), so we used InFoRM as the baseline. Due to the extensive training time required for REDBESS, we only report results on the German dataset for REDBESS. We use demographic parity (DP), equal opportunity (EO), and individual unfairness (IND) as metrics.Table 4 demonstrates the result. From Table 4, we can see that in terms of the group fairness metrics (DP, EO), the fairness problem becomes uniformly worse on the Credit, German, and Pokecn datasets for all debiasing methods. For the Recidivism dataset, the distilled graph shows fewer fairness issues (lower DP or EO), especially for the EDITS method. This may result from the drop in utility of the model trained on the distilled graph (AUC is too low). As shown in Figure 4 of our paper, FGD can achieve a better performance-fairness trade-off compared to the baselines.

## Appendix F Dataset Statistics

Pokec.The Pokec dataset consists of millions of anonymized user profiles from Slovakia's most popular social network in 2012, with information such as gender, age, hobbies, interests, education, and working field. The dataset was sampled into Pokec-z and Pokec-n based on user province, with region as the sensitive attribute. The task is to predict user working field.

\begin{table}
\begin{tabular}{c|c c c c c c} \hline \hline Dataset & \# Nodes & \# Attributes & \# Edges & Avg. degree & Sens & Label \\ \hline Pokec-n & 6,185 & 59 & 21,844 & 7.06 & Region & Working field \\ \hline Pokec-z & 7,659 & 59 & 29,476 & 7.70 & Region & Working field \\ \hline German & 1,000 & 27 & 21,242 & 44.50 & Gender & Credit status \\ \hline Credit & 30,000 & 13 & 1,436,858 & 95.80 & Age & Future default \\ \hline Recidivism & 18,876 & 18 & 321,308 & 34.00 & Race & Bail decision \\ \hline \hline \end{tabular}
\end{table}
Table 3: Statistical Information on DatasetsGerman.The German Graph credit dataset has 1,000 client records with attributes like Gender and LoanAmount, used to classify individuals as good or bad credit risks. The similarity between node attributes is calculated using Minkowski distance and nodes are connected if the similarity is 80% of the maximum similarity.

Credit.Credit dataset, consisting of 30,000 individuals with features such as education, credit history, age, and derived spending and payment patterns. The similarity between two node attributes is calculated using Minkowski distance as the similarity measure and the credit defaulter graph network is constructed by connecting nodes with a similarity of 70% of the maximum similarity between all nodes.

Recidivism.The US state court bail outcome dataset (1990-2009) contains 18,876 defendant records with past criminal records, demographic attributes, etc. The similarity between node attributes is calculated using Minkowski distance and nodes are connected if the similarity is 60% of the maximum similarity.

## Appendix G More Experimental Details

### Parameter Study

Here we aim to study the sensitivity of FGD w.r.t. hyper-parameters. Specifically, we show the parameter study of \(\alpha\) on Recidivism dataset. Here \(\alpha\) controls the intensity to regularize the coherence bias of the distilled small graph. The results in Table 5 indicate that \(\alpha\) can control the debiasing and utility performance of the distilled small graph.

### Implementation Details

Synthesizer training.We adopt Adam optimizer for synthesizer training with \(0.0002\) learning rate. MLP\({}_{\phi}\) consists of 3 linear layer with 128 hidden dimension. The outer loop number is 16 while the inner loop is 4 for each epoch. For each experiment, we train with a maximum of 1200 epochs and 3 independent runs. The temperature parameter \(\gamma\) is set to 10. \(\bm{X}^{\prime}\) and \(\phi\) are optimized alternatively.

GNN training.We adopt Adam optimizer for GNN training with \(0.005\) learning rate. All GNN models are 2 layers with 256 hidden dimensions. For Pokec-z, Pokec-n, German, Credit, and Recidivism the training epochs are \(1500\), \(1500\), \(4000\), \(1000\), and \(1000\) respectively.

\begin{table}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|} \hline  & & Recidivism & Credit & German & \multicolumn{2}{c|}{Pokeen} & \multicolumn{2}{c|}{Pokeen} \\ \hline  & & Real & Distilleded & Real & Distilleded & Real & Distilleded & Real & Distilleded \\ \hline \multirow{4}{*}{EDITS} & AUC1 & 0.971 & 0.658 & 0.740 & 0.704 & 0.668 & 0.506 & OOM & OOM & OOM & OOM \\ \cline{2-11}  & DP1 & 0.067 & 0.005 & 0.027 & **0.045** & 0.009 & **0.034** & OOM & OOM & OOM \\ \cline{2-11}  & FO1 & 0.038 & 0.011 & 0.018 & **0.028** & 0.008 & OOM & OOM & OOM & OOM \\ \hline \multirow{4}{*}{FairGNN} & AUC1 & 0.977 & 0.788 & 0.759 & 0.720 & 0.742 & 0.645 & 0.782 & 0.676 & 0.784 & 0.723 \\ \cline{2-11}  & DP1 & 0.065 & 0.046 & 0.062 & **0.123** & 0.010 & **0.013** & 0.005 & **0.044** & 0.042 & **0.037** \\ \cline{2-11}  & EO1 & 0.037 & 0.046 & 0.037 & **0.091** & **0.001** & **0.001** & **0.006** & **0.062** & 0.051 & **0.038** \\ \hline \multirow{4}{*}{InfCoRM} & AUC1 & 0.906 & 0.708 & 0.741 & 0.717 & 0.642 & 0.538 & 0.743 & 0.644 & 0.751 & 0.708 \\ \cline{2-11}  & DP1 & 0.011 & 0.118 & 0.004 & **0.174** & 0.085 & 0.018 & 0.009 & 0.009 & 0.020 & **0.048** \\ \cline{2-11}  & EO1 & 0.024 & 0.092 & 0.030 & **0.135** & 0.153 & 0.017 & 0.013 & 0.015 & 0.018 & **0.038** \\ \cline{2-11}  & IND1 & **0.018** & **0.036** & **0.032** & **0.0318** & **0.460** & **0.2888** & **0.646** & **272013** & 6.628 & **19983** \\ \hline \multirow{4}{*}{REDRESS} & AUC1 & OOM & OOM & OOM & OOM & O719 & 0.483 & OOM & OOM & OOM & OOM \\ \cline{2-11}  & DP1 & OOM & OOM & OOM & OOM & OOM & **0.035** & OOM & OOM & OOM & OOM \\ \cline{1-1} \cline{2-11}  & EO1 & OOM & OOM & OOM & OOM & 0.010 & **0.073** & OOM & OOM & OOM & OOM \\ \cline{1-1} \cline{2-11}  & IND1 & OOM & OOM & OOM & OOM & 9728 & **180366** & OOM & OOM & OOM & OOM \\ \hline \end{tabular}
\end{table}
Table 4: Utility and group fairness comparison between real graph and distilled graph with various debias method. **Bold** value indicates worse fairness performance.

\begin{table}
\begin{tabular}{c|c c c c} \hline \hline \(\alpha\) & AUC & \(\Delta_{DP}\) & \(\Delta_{EO}\) & Bias \\ \hline
0.04 & 74.75 & 0.84 & 0.88 & 0.19 \\
0.5 & 69.42 & 0.66 & 0.43 & 0.15 \\
0.6 & 69.37 & 0.58 & 0.16 & 0.14 \\
1.0 & 65.35 & 0.00 & 0.00 & 0.11 \\ \hline \hline \end{tabular}
\end{table}
Table 5: Parameter study of \(\alpha\). All the value is in scale of \(\times 10^{2}\).

### More Visualization

We also visualize the node representation using PCA. We could observe that the barycenter of node from real graph and distilled graph is very close. And The distribution of node representation after being normalized to the circumference is consistent with the geometric intuition shown in Figure 6.

## Appendix H Limitations and Future Work

### Non-binary Sensitive Attribute

For categorical sensitive attributes, if only one sensitive membership group's embeddings are far away from others, then the mean embeddings will still be close to the majority embeddings, especially for many categories, resulting in low variance (coherence). We argue that only this group with distant embedding (a small portion of samples) can have their sensitive attribute detected using embedding distributions. From a metric perspective, if we adopt the maximized \(\Delta_{DP}\) over any sensitive attribute group pair, the bias should be large due to considering the worst case. The proposed coherence may not work well in this scenario, and an advanced coherence can be developed for this case, e.g., the maximized variance over any sensitive group pair. We leave the advanced coherence development for categorical, multiple, or even continuous sensitive attributes in future work.

### Individual Fairness

From Table 4, we find that all datasets suffer from a surprisingly more severe individual fairness problem (much higher IND score) when the model is trained on the distilled graph, even if we use InFoRM or REDFESS. This could be an interesting direction for future work, and we will add discussion with references in the related work section.

### Other Tasks

Our paper mainly focuses node classification tasks and it is possible to extend our method to other tasks or other group fairness problems. For instance, FGD may alleviate group fairness issues in link prediction tasks by reducing the coherence bias among different link groups. Exploring other tasks (e.g., recommendation, graph classification) or other fairness metrics (e.g., individual fairness, rank fairness) could be interesting for future work.

Figure 6: (a) shows the visualization of node representations from real graph and distilled graph, as well as their barycenter, on Credit dataset, after PCA. (b) shows the visualization of geometric intuition of node from real graph and distilled graph on Credit dataset.