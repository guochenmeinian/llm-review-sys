Relative Entropic Optimal Transport: a (Prior-aware) Matching Perspective to (Unbalanced) Classification

 Liangliang Shi, Haoyu Zhen, Gu Zhang, Junchi Yan

Dept. of Computer Science and Engineering & MoE Key Lab of AI, Shanghai Jiao Tong University

{shiliangliang, anye_zhen, blake-nash, yanjunchi}@sjtu.edu.cn

PyTorch Code: https://github.com/LiangliangShi/RE-OT

Correspondence author. This work was partly supported by NSFC (62222607, 61972250, U19B2035) and Shanghai Municipal Science and Technology Major Project (2021SHZDZX0102).

###### Abstract

Classification is a fundamental problem in machine learning, and considerable efforts have been recently devoted to the demanding long-tailed setting due to its prevalence in nature. Departure from the Bayesian framework, this paper rethinks classification from a matching perspective by studying the matching probability between samples and labels with optimal transport (OT) formulation. Specifically, we first propose a new variant of optimal transport, called Relative Entropic Optimal Transport (RE-OT), which guides the coupling solution to a known prior information matrix. We gives some theoretical results and their proof for RE-OT and surprisingly find RE-OT can help to deblur for barycenter images. Then we adopt inverse RE-OT for training long-tailed data and find that the loss derived from RE-OT has a similar form to Softmax-based cross-entropy loss, indicating a close connection between optimal transport and classification and the potential for transferring concepts between these two academic fields, such as barycentric projection in OT, which can map the labels back to the feature space. We further derive an epoch-varying RE-OT loss, and do the experiments on unbalanced image classification, molecule classification, instance segmentation and representation learning. Experimental results show its effectiveness.

## 1 Introduction

Long-tailed label distribution or unbalanced classification in training given more balanced testing set has been a challenge for existing neural models [42, 3, 62]. Various approaches have been developed, such as Class Re-balancing [3, 25, 35, 8, 45, 52], Information Augmentation [36, 7], and Module Improvement [65, 16, 62]. However, the problem is still far from being solved.

Most existing methods on (long-tailed) classification study the conditional probability function \(p(y|x)\) or their joint distribution given the label \(y\) and sample \(x\), almost taking it for granted. For instance, [45] shows that in the long-tailed case, according to Bayes' theorem, the vanilla Softmax classification is affected by the label distribution shift, which makes the classifier more inclined to consider the samples as belonging to the majority class. To address this issue, the work explicitly considers the label distribution shift and re-derives the Softmax function. [22] argues that the conditional distribution \(p(y|x)\) is not the same between training and testing data, which can result in target-shift. To enhance class-unbalanced learning, the authors propose to relax the assumption that the source and target domains share the same conditional distribution \(p(x|y)\). Despite the de-facto Bayesian perspective for understanding classification, in this paper, we take a matching view and demonstrate how new insights and approaches can be derived, especially for the challenging long-tail cases.

From the matching perspective, the problem becomes matching samples to labels. During training, the goal is to learn the distances between the features of samples and labels. During testing, matching results can be obtained by calculating the distances between the features of testing samples and their labels. We formulate this matching using the theory of Optimal Transport (OT), where training precisely involves learning the Inverse OT [12, 33, 51], and testing involves optimizing the transportation results. In the commonly studied long-tailed setting [35], the labels of training samples follow a long-tail distribution, while the labels are uniformly distributed for testing data. With our OT formulation, we demonstrate that these two different priors (i.e. long-tailed and uniform) can effectively reduce the difference between training and testing, thereby increasing the accuracy of the matching probability.

To incorporate the prior information e.g. the aforementioned typical long-tailed setting, we introduce the smoothing-guided prior matrix \(\mathbf{Q}\) to vanilla entropic OT and call the resulting formulation relative entropic OT (RE-OT). To this new variant of OT, we provide convergence analysis, its corresponding static Schrodinger form, Sinkhorn algorithm for solving the problem as well as the dual formulation of RE-OT, which are mostly similar to those for the vanilla entropic OT. We find our RE-OT can help to deblur for barycenter images by setting specific smoothing prior \(\mathbf{Q}\).

Specifically, we develop the inverse RE-OT (as our relative entropy OT's counterpart to inverse OT) to learn the cost matrix or equivalently, the sample features for training data. And then we use the RE-OT to optimize the transportation to get the matching results (i.e. predictions for testing data). It is uncovered that many Softmax-based cross-entropy losses (e.g. Balanced Softmax, A-softmax and etc) are special cases of our derived new loss under half constraints of OT by specifying different forms of the cost matrix, supervision matrix in IOT and the smoothing-guided prior matrix \(\mathbf{Q}\). In other words, we can generalize the cross-entropy loss by specifying different cost matrix, smoothing-guided matrix, or other settings in the framework of inverse OT. We also find that when the regularization coefficient \(\epsilon\to 0\), the loss of inverse RE-OT equals triplet loss in metric learning fields. Additionally, our matching perspective reveals interesting connections between OT and classification tasks. For example, we discover the equivalence between the coefficient of entropic regularization in OT and the temperature in Softmax. We also find that the concept of barycentric projection in OT can be used in classification to calculate the class barycenters in hidden feature space. We believe that the connection between these two fields will inspire further algorithmic development for both sides. **This paper contributes in the following ways:**

1) We propose a matching perspective to revisit and provide new understanding to the classification problem with OT formulation. The matching perspective provide a clear interpretation to the challenge of long-tailed classification, which lies in the inconsistency of the utilized prior information between the matches learned from the training set and those from the testing set.

2) We propose a new variant of entropic optimal transport, called relative entropic OT (RE-OT), for learning matching with a specified prior. We provide theoretical results on various aspects of RE-OT, including its solution properties, Sinkhorn algorithm, barycenter calculation, and its dual form. As a side product of our study, we find that RE-OT can help to deblur barycenter images by setting a specific smoothing prior \(\mathbf{Q}\), which entropic OT alone cannot achieve.

3) We further develop Inverse RE-OT to link our results to classification, and show that Softmax and its variants are special cases of our derived loss based on Inverse RE-OT. This finding inspires a simple yet effective technique in practice for long-tailed classification: we let the smoothing-guided matrix \(\mathbf{Q}\) to be epoch-varying, which gradually provides prior information and improves the performance.

4) Our study has revealed a significant link between Optimal Transport (OT) and existing classification tasks, such as the relationship between the regularization coefficient in OT and the temperature in Softmax. This suggests that OT concepts can be applied to classification tasks, and vice versa. For instance, the barycentric projection concept in OT can be utilized in classification tasks to calculate the class barycenters in the hidden feature space. We anticipate that this connection between the two fields will lead to further algorithmic development for both OT and classification.

5) Our method performs competitively and often outperforms baselines on various long-tailed benchmarks ranging from image classification, to molecule property prediction, and instance segmentation. Source code will be made publicly available.

Preliminaries and Related Work

**Optimal Transport.** Known as Wasserstein distance or Earth Mover's distance, Optimal transport (OT) [26], has gained significant attention in various fields including domain adaption [11], generative models [15; 34; 49], and image registration [14]. We begin by briefly introducing discrete Optimal Transport (OT), which provides a framework for viewing the (long-tailed) classification problem from a matching perspective. For a more detailed introduction to OT, readers are directed to [43].

Consider two histograms \(\mathbf{a}\in\Sigma_{n}\) and \(\mathbf{b}\in\Sigma_{m}\), where the simplex \(\Sigma_{d}=\{x\in\mathbb{R}_{+}^{d}|x^{\top}1_{d}=1\}\). We can represent the transportation polytope \(U(\mathbf{a},\mathbf{b})\), which is the polyhedral set of \(n\times m\) matrices:

\[U(\mathbf{a},\mathbf{b})=\{\mathbf{P}\in\mathbb{R}_{+}^{n\times m}|\mathbf{P} \mathbf{1}_{m}=\mathbf{a},\mathbf{P}^{\top}\mathbf{1}_{n}=\mathbf{b}\},\] (1)

where \(\mathbf{1}_{n}\) and \(\mathbf{1}_{m}\) are \(n\) and \(m\) dimensional vectors of ones. \(U(\mathbf{a},\mathbf{b})\) contains all \(n\times m\) nonnegative probabilistic matrices with row and column sums \(\mathbf{a}\) and \(\mathbf{b}\). Then the Kantorovich's optimal transport problem can be defined as [26]:

\[\min_{\mathbf{P}\in U(\mathbf{a},\mathbf{b})}<\mathbf{C},\mathbf{P}>=\sum_{i,j }\mathbf{C}_{ij}\mathbf{P}_{ij},\] (2)

where \(\mathbf{C}\in\mathbb{R}_{+}^{n\times m}\) is the cost matrix for the distance between sample \(\{\mathbf{x}_{i}\}_{i=1}^{n}\) and \(\{\mathbf{y}_{j}\}_{j=1}^{m}\). The above minimization is a linear program and the optimal solution \(\mathbf{P}^{*}\) can be obtained with the network simplex [54] or other off-the-shelf techniques e.g. [40], which require significant time overhead. For its cost-effectiveness, the entropic regularization [57] is more popular and it gets an approximation:

\[\min_{\mathbf{P}\in U(\mathbf{a},\mathbf{b})}\mathcal{L}^{\epsilon}=<\mathbf{ C},\mathbf{P}>-\epsilon H(\mathbf{P}),\] (3)

where the regularizer is specified as \(H(\mathbf{P})=\sum_{ij}-\mathbf{P}_{ij}(\log(\mathbf{P}_{ij})-1)\). It can be proved that [43] when \(\epsilon\to 0\), the unique solution of Eq. 3 converges to the optimal \(\mathbf{P}^{*}\) of original problem. And when \(\epsilon\rightarrow+\infty\), we can get

\[\mathbf{P}_{\epsilon}\stackrel{{\epsilon\rightarrow+\infty}}{{ \longrightarrow}}\mathbf{a}\otimes\mathbf{b},\] (4)

where \(\mathbf{a}\otimes\mathbf{b}=\mathbf{a}^{\top}\mathbf{b}\in U(\mathbf{a}, \mathbf{b})\). So we can find the entropic regularization \(H(\mathbf{P})\) exactly do a smoothing to the solution towards \(\mathbf{a}\otimes\mathbf{b}\). Recently, Inverse Optimal Transport (IOT) start to be studied [12; 33; 51; 50] which assumes that the cost \(\mathbf{C}\) is unknown for learning, given the established coupling. The inverse of entropic OT problem can be formulated as:

\[\min_{\theta}KL(\mathbf{\tilde{P}}|\mathbf{P}^{\theta}),\quad\text{where} \quad\mathbf{P}^{\theta}=\arg\min_{\mathbf{P}\in U(\mathbf{a},\mathbf{b})}< \mathbf{C}^{\theta},\mathbf{P}>-\epsilon H(\mathbf{P}).\] (5)

Specifically, [51] proposes a principled approach to infer the unknown costs and [6] develops the mathematical theory for IOT. [33] shows that by IOT, one can also modify and improve the raw matching prediction by the cost, which is learned by the raw matching as noise supervision.

In this paper, we develop an IOT-based formulation to learn the cost between samples and their labels, which further allows one to learn the feature extractor of the training samples. Then with the features exacted from testing data, we match them with target labels and achieve the goal of classification.

**Long-tailed recognition.** Long-tailed recognition has been a standing problem with wide attention in vision and learning [64; 19; 35]. One common approach [45; 41] is to re-balance the class distribution in the training set. For example, some works employ re-sampling [25] or re-weighting [8] techniques to let the model pay more attention to the minority classes in the training set. Data augmentation is also adopted to synthesize more samples for the underrepresented classes [28]. While in [9], transfer learning is used, which leverages knowledge learned from a source domain with sufficient data to improve the performance on a target domain with imbalanced data. This line of research includes techniques such as fine-tuning [63], domain adaptation [53], and meta-learning [56]. Recently, some works have proposed to explicitly model the long-tailed distribution, such as by adjusting the loss or designing specialized network architectures. Examples include focal loss [35], class-balanced loss [8], balanced Softmax loss [45]. In this paper, we view classification from a matching perspective. Our method does not predict the label or class directly but learns the features in training and calculates the matching probability instead. With the aid of OT, we formulate it with relative entropic as proposed in the next section, which adopts different prior for training and testing.

## 3 Relative Entropy Regularization for Optimal Transport

**Motivation of introducing prior into OT.** As introduced in Eq. 3, entropic regularization (ER) is an effective method [10] for approximating the Kantorovich OT solution. It pushes the original linear programming solution away from the hard boundary and obtains a smoother solution by minimizing a \(\epsilon-\)strongly convex function. With the increase of the penalty coefficient, the solution progressively approaches a more'smooth' solution, ultimately converging to \(\mathbf{a}^{\top}\mathbf{b}\) as illustrated by Eq. 4. However, a question is raised: is such a smoothing direction \(\mathbf{a}^{\top}\mathbf{b}\) appropriate for all practical situations, e.g. the long-tailed problems? Can we freely choose a more suitable (smoothing) direction to achieve more effective results tailored to the problem or dataset at hand? In this section, we will develop relative entropic OT (RE-OT), a more general formulation than traditional entropic OT [57].

**Formulation.** Given a cost matrix \(\mathbf{C}\in\mathbb{R}_{+}^{n\times m}\) and two margins \(\mathbf{a}\in\Sigma_{n}\) and \(\mathbf{b}\in\Sigma_{m}\), where \(\Sigma_{n}\) and \(\Sigma_{m}\) represent the probability simplex with \(n\) and \(m\) bins, respectively, we introduce the positive smoothing-guidance matrix \(\mathbf{Q}\) as a manually-specified constant prior to guide the smoothing. We use the relative entropy regularizer \(H_{\mathbf{Q}}(\mathbf{P})\) in place of the traditional entropy in Eq. 3 to achieve this ability, defined as \(H_{\mathbf{Q}}(\mathbf{P})=-\sum_{ij}\mathbf{P}_{ij}\left(\log\frac{\mathbf{P }_{ij}}{\mathbf{Q}_{ij}}-1\right)\). Then we have:

\[\min_{\mathbf{P}\in U(\mathbf{a},\mathbf{b})}\mathcal{L}_{\mathbf{Q}}^{ \epsilon}=<\mathbf{C},\mathbf{P}>-\epsilon H_{\mathbf{Q}}(\mathbf{P}).\] (6)

The relative entropy \(H_{\mathbf{Q}}(\mathbf{P})\) can increase the probability of transportation for the element \(\mathbf{P}_{ij}\) if \(\mathbf{Q}_{ij}\) is larger. Consequently, if the prior in the form of \(\mathbf{Q}\) is available, the use of relative entropy regularization can improve the efficiency of learning the transportation solution. Therefore, for long-tailed tasks, we can assign a large \(\mathbf{Q}\) element to the majority classes and a low element of \(\mathbf{Q}\) to the tailed classes to enhance training. We will discuss this in detail in the next section.

For Eq. 6, we further study its properties. Firstly, we show the relation between RE-OT and the entropic OT by Eq. 3 as follows. The proof is given in Table A.

**Proposition 1** (**Solution Propriety.**).: _Assume \(\mathbf{P}_{Q}^{\epsilon},\mathbf{P}^{\epsilon}\) and are the optimal solution of RE-OT and entropic regularized OT, respectively. Then we can get:_

_(1) When_ \(\epsilon\rightarrow+\infty\)_, the optimal RE-OT's solution_ \(\mathbf{P}_{Q}^{\epsilon}\) _will converge to_ \(\widetilde{\mathbf{Q}}\) _where_ \(\widetilde{\mathbf{Q}}\) _takes the form_ \(\widetilde{\mathbf{Q}}=diag(\mathbf{u})\mathbf{Q}diag(\mathbf{v})\) _with two uniquely defined non-negative vectors_ \(\mathbf{u}\) _and_ \(\mathbf{v}\)_._

_(2) With the prior_ \(\mathbf{Q}\) _and its corresponding_ \(\widetilde{\mathbf{Q}}\) _as defined in (_1_), we have_ \(\mathbf{P}_{\widetilde{\mathbf{Q}}}^{\epsilon}=\mathbf{P}_{\widetilde{ \mathbf{Q}}}^{\epsilon}\)_. And when_ \(\widetilde{\mathbf{Q}}=\mathbf{a}\otimes\mathbf{b}\)_, we have the equality_ \(\mathbf{P}^{\epsilon}=\mathbf{P}_{\widetilde{\mathbf{Q}}}^{\epsilon}\)_._

Proposition 1 shows the relation between RE-OT and entropic OT, and we can find RE-OT is a more general formulation. Note \(\widetilde{\mathbf{Q}}\) is defined by \(\mathbf{Q}\) and can be obtained by iteratively normalizing row/column sums of \(\mathbf{Q}\). Fig. 1 shows the results of \(\mathbf{P}_{\widetilde{\mathbf{Q}}}^{\epsilon}\) by varying \(\epsilon\). As \(\epsilon\) increases, the optimal coupling becomes more dense, but \(\mathbf{P}^{\epsilon}\) becomes more uniform while \(\mathbf{P}_{Q}^{\epsilon}\) converges to \(\widetilde{\mathbf{Q}}\).

Besides, similar to the standard entropic regularized OT, our RE-OT in Eq. 6 can also be reformulated to the "static Schrodinger problem" form [31], which exactly leans a projection under KL divergence.

**Proposition 2** (**static Schrodinger form**).: _Redefine a general KL divergence as_

\[\widetilde{KL}(\mathbf{P}|\mathbf{K})=\sum_{ij}\mathbf{P}_{ij}\log \frac{\mathbf{P}_{ij}}{\mathbf{K}_{ij}}-\mathbf{P}_{ij}+\mathbf{K}_{ij},\] (7)

_The optimization in Eq. 6 is equivalent to the following minimization, where \(\mathbf{K}_{ij}=\mathbf{Q}_{ij}e^{-\mathbf{C}_{ij}/\epsilon}:\)_

\[\mathbf{P}_{Q}^{\epsilon}=\operatorname*{arg\,min}_{\mathbf{P} \in U(\mathbf{a},\mathbf{b})}\widetilde{KL}(\mathbf{P}|\mathbf{K}).\] (8)

The proof is in Appendix B. Prop. 2 shows the optimal solution \(\mathbf{P}_{Q}^{\epsilon}\) is exactly the KL projection of \(\mathbf{K}\) onto \(U(\mathbf{a},\mathbf{b})\). In fact, \(\mathbf{K}\) can be set as \(\mathbf{K}_{ij}=\widetilde{\mathbf{Q}}_{ij}e^{-\mathbf{C}_{ij}/\epsilon}\) due to the equivalence between \(\mathbf{P}_{\mathbf{Q}}^{\epsilon}\) and \(\mathbf{P}_{\widetilde{\mathbf{Q}}}^{\epsilon}\). Expect for the different form of \(\mathbf{K}\), RE-OT and entropic OT share the same static Schrodinger formulation, which means that many methods in entropic OT can be applied to RE-OT, such as iterative Bregman projections [2].

**The Sinkhorn algorithm and barycenters for RE-OT.** The optimal solution for RE-OT can be estimated using the Sinkhorn algorithm, as its counterpart has already been well-developed for solving entropic OT [10]. The algorithm for RE-OT shares the same form as that for entropic OT, given \(\mathbf{K}_{ij}=\widetilde{\mathbf{Q}}_{ij}e^{-\mathbf{C}_{ij}/\epsilon}\). Specifically, with two non-negative vectors \(\mathbf{u}^{\prime}\) and \(\mathbf{v}^{\prime}\) uniquely defined up to a multiplicative factor, the optimal solution has the form \(\mathbf{P}_{Q}^{\epsilon}=\operatorname{diag}(\mathbf{u}^{\prime})\mathbf{K} \operatorname{diag}(\mathbf{v}^{\prime})\), which can be efficiently computed by iterating \(\mathbf{u}^{\prime},\mathbf{v}^{\prime}\leftarrow\mathbf{a}/\mathbf{K}\mathbf{ v}^{\prime},\mathbf{b},/\mathbf{K}^{\top}\mathbf{u}^{\prime}\). The proof and algorithm are presented in Appendix C. In addition, the barycenter between distributions is a natural extension of OT [1, 2], and with the matrix \(\mathbf{K}\), [2] defined it with a weighted KL projection problem:

\[\min_{\{\mathbf{P}_{s}\},\mathbf{a}}\sum_{s}\epsilon\cdot\lambda_{s} \widetilde{KL}(\mathbf{P}_{s}|\mathbf{K})\text{ s.t. }\mathbf{P}_{s}^{\top}\mathbf{1}_{n}=\mathbf{b}_{s},\mathbf{P}_{1}\mathbf{1}_{ m}=\mathbf{P}_{2}\mathbf{1}_{m}=\cdots=\mathbf{P}_{S}\mathbf{1}_{m}= \mathbf{a},\] (9)

where \(\{\lambda_{s}\}_{s=1}^{S}\) are the weights, \(\mathbf{b}_{s}\) are known histograms representing images, and \(\mathbf{a}\) is the barycenter histogram to be calculated. Though easier to calculate compared with the regularized formulation in [1], a drawback of this entropic-based method is that it can lead to blurred barycenters, and methods have been proposed to address this issue [23]. By calculating barycenters between noise and an image (i.e. \(S=2\) here), we show that the blurred problem can be simply solved by setting \(\lambda\) where \(\lambda_{1}=\lambda,\lambda_{2}=1-\lambda\) and the prior matrix \(\mathbf{Q}:\)

\[\mathbf{Q}=(1-\lambda)(\mathbf{P}^{\epsilon})^{\top}+\lambda \mathbf{P}^{\epsilon},\] (10)

where \(\mathbf{P}^{\epsilon}\) is the optimal solution of entropic OT from image \(\mathbf{b}_{1}\) to \(\mathbf{b}_{2}\). Fig. 2 illustrates the effect of different choices of \(\mathbf{Q}\) when computing barycenters between noise and an image. Without using \(\mathbf{Q}\), the resulting barycenters are very blurry. When we set \(\mathbf{Q}\) to be \(\mathbf{P}^{\epsilon}\), the barycenters display the shape of the leopard clearly, but fail to transition smoothly from noise to leopard image as \(\lambda\) changes. To address this issue, we set \(\mathbf{Q}\) as shown in Eq. 10, which can blur the image while transitioning smoothly with the gradient.

**Proposition 3** (**Dual formulation**).: _From the optimization in Eq. 6, we can get its dual formulation:_

\[L_{\mathbf{Q}}^{\epsilon}=<\mathbf{f},\mathbf{a}>+<\mathbf{g}, \mathbf{b}>-\epsilon<e^{\mathbf{f}/\epsilon},\mathbf{K}e^{\mathbf{g}/\epsilon}>\] (11)

_where \(\mathbf{f}\in\mathbb{R}^{n}\) and \(\mathbf{g}\in\mathbb{R}^{m}\) are the corresponding dual variables._

The proof is given in Appendix D. Exactly \(\mathbf{f}\), \(\mathbf{g}\) are linked to \(\mathbf{u}\), \(\mathbf{v}\) appearing in Sinkhorn algorithm by \(\mathbf{u}=\exp{(\mathbf{f}/\epsilon)}\) and \(\mathbf{v}=\exp{(\mathbf{g}/\epsilon)}\), and thus Sinkhorn algorithm can be done in log-domain [47].

**Setting \(\mathbf{Q}\) with the Optimal Solution Iteratively.** The intuition for the prior is to iteratively update the solution \(P_{\mathbf{Q}}^{\epsilon}\) as a new \(\mathbf{Q}\), i.e., \(\mathbf{Q}^{(t)}=\mathbf{P}_{\mathbf{Q}^{(t-1)}}^{\epsilon}\), where \(\mathbf{Q}^{(t)}\) represents the solution obtained after the \(n\)-th iteration. The question then arises as to how \(\mathbf{Q}^{(t)}\) changes over time. We find that this problem is equivalent to a proximal point algorithm:

\[\mathbf{Q}^{(t)}=\operatorname*{arg\,min}_{\mathbf{Q}}KL(\mathbf{Q}|\mathbf{Q} ^{(t-1)})+\frac{1}{\epsilon}F(\mathbf{Q}).\] (12)

Here \(F(\mathbf{Q})=<C,\mathbf{Q}>+l_{U(\mathbf{a},\mathbf{b})}(\mathbf{Q})\), where \(l_{U(\mathbf{a},\mathbf{b})}(\mathbf{Q})\) is defined such that \(l_{U(\mathbf{a},\mathbf{b})}(\mathbf{Q})=0\) if \(\mathbf{Q}\in U(\mathbf{a},\mathbf{b})\), and \(l_{U(\mathbf{a},\mathbf{b})}(\mathbf{Q})=+\infty\) otherwise. We find this problem is discussed by [29, 43],which aims to get the optimal solution of the non-regularized OT. As discussed in Sinkhorn of RE-OT, we have the optimal solution form:

\[\begin{split}\mathbf{Q}^{(t)}&=\operatorname{diag}( \mathbf{u}^{(t-1)})\mathbf{Q}^{(t-1)}\odot e^{-C/\epsilon}\operatorname{diag}( \mathbf{v}^{(t-1)})\\ &=\operatorname{diag}(\mathbf{u}^{(t-1)}\odot...\odot\mathbf{u}^ {(0)})\mathbf{Q}^{(0)}\odot e^{-\frac{(t+1)C}{\epsilon}}\operatorname{diag}( \mathbf{v}^{(0)}\odot...\mathbf{v}^{(t-1)}).\end{split}\] (13)

When we set \(\mathbf{Q}^{(0)}=\mathbf{1}_{n\times m}\), the optimization is equivalent to applying Sinkhorn's algorithm iteratively with a kernel \(e^{-\frac{(t+1)C}{\epsilon}}\), i.e., with a decaying regularization coefficient \(\frac{\epsilon}{t+1}\). This observation further emphasizes the importance of selecting an appropriate \(\mathbf{Q}\) for RE-OT.

## 4 RE-OT for Long-tailed Recognition

We now discuss the application of inverse RE-OT to address the long-tailed classification task (including the contrastive learning setting). Unlike previous works that study this problem using conditional probability, our approach aims to learn features by matching samples with their labels using Inverse OT. Specifically, given the mini-batch pair set \(\{(\mathbf{x}_{i},\mathbf{y}_{i})\}_{i=1}^{n}\) where \(\mathbf{x}_{i}\) is training sample and \(\mathbf{y}_{i}\) is the \(m-\)dimensional one-hot label of \(\mathbf{x}_{i}\). We can set the the cost \(\mathbf{C}_{ij}^{\theta}\) between sample \(\mathbf{x}_{i}\) and another one-hot label given the neural network \(f_{\theta}\). Without loss of generality, we can set \(\mathbf{C}_{ij}^{\theta}=c-l_{ij}\) where \(l_{ij}=(f_{\theta}(\mathbf{x}_{i}))_{j}\) is the \(j-\)th component of logits \(f_{\theta}(\mathbf{x}_{i})\) for sample \(\mathbf{x}_{i}\). Then we can learn the matching between features and labels with inverse OT via a bi-level optimization:

\[\min_{\theta}KL(\widetilde{\mathbf{P}}|\mathbf{P}^{\theta})\quad s.t.\quad \mathbf{P}^{\theta}=\operatorname*{arg\,min}_{\mathbf{P}\in U}<\mathbf{C}^{ \theta},\mathbf{P}>-\epsilon H_{\mathbf{Q}}(\mathbf{P}),\] (14)

where \(\widetilde{\mathbf{P}}\) is the supervision given the label \(\{\mathbf{y}_{i}\}\). For example, we can set \(\widetilde{\mathbf{P}}_{ij}=\mathbf{y}_{ij}\) when \(\mathbf{y}_{ij}\) is the \(j\)-th component of \(\mathbf{y}_{i}\). Here \(U\) refer to the constraints for the coupling \(\mathbf{P}\). We can set \(U=U(\mathbf{a},\mathbf{b})\) with the full matching constraints or its relaxation e.g. \(U=U(\mathbf{a})=\{\mathbf{P}|\mathbf{P}\mathbf{1}_{m}=\mathbf{a}\}\).

For our designed smoothing guidance \(\mathbf{Q}\), a simple idea is to set it with the long-tailed ratio i.e. the training sample ratio of class labels which are readily available from the training set, which equals to

Figure 3: RE-OT for unbalanced classification.

Figure 2: The barycenter results between noise and a leopard image. It is very blurry without the use of \(\mathbf{Q}\). However, when we set \(\mathbf{Q}=\mathbf{P}^{\epsilon}\), the resulting barycenters clearly display the shape of the leopard, but fail to transition smoothly from noise to leopard image as \(\lambda\) changes. To address this, we set \(\mathbf{Q}\) as shown in Eq. 10, which blurs the image while transitioning with the increase of \(\lambda\).

the Balanced Softmax method proposed in [45]. In this paper, motivated by Eq. 10 having a good efficiency in OT and other works [60] which adopt two stages for learning, we let it vary over epochs:

\[\mathbf{Q}=(1-\lambda(t))\operatorname{Uniform}+\lambda(t)\mathbf{r},\] (15)

where \(t\) is the training epoch and \(\mathbf{r}\) is the prior probability matrix e.g. the balanced ratio in [45], teacher-based prior predictions or the sample-class-wise setting discussed in Appendix E. \(\lambda(t)\) is an epoch varying weight. When \(t\) is small, \(\lambda(t)\) is close to 0, and \(\mathbf{Q}\) is more likely to be a uniform distribution, which gives the model less prior information. As \(t\) approaches the final training epoch number \(T\), \(\lambda(t)\to 1\) and \(\mathbf{Q}\rightarrow\mathbf{r}\), which means the model is given the full prior information. This gradual process of introducing prior information can be helpful for training the inverse OT. We provide a specific setting for \(\lambda(t)\) and \(\mathbf{r}\) in Appendix E. During the inference process, the problem reduces to the inner optimization in Eq. 6, which takes the form of traditional unsupervised OT. We use this optimization to obtain the matching between the sample features and labels, which corresponds to classification for the testing data. We do not adopt the long-tailed setting of \(\mathbf{Q}\) during inference because the testing data is assumed to be uniform.

### Generalization to a Family of Losses in Form of Softmax-based Cross-Entropy

We find our new formulation with inverse OT is a more general form if we set \(U=U(\mathbf{a})\) where \(\mathbf{a}_{i}=1/n\) and many Softmax-based cross-entropy losses can be our special case by varying the form of \(\widetilde{\mathbf{P}},\mathbf{C}^{\theta}\) and \(\mathbf{Q}\). Specifically, with \(U=U(\mathbf{a})\), Eq.14 equals to

\[\min_{\theta}L=\sum_{i,j}\widetilde{\mathbf{P}}_{ij}\log\frac{\mathbf{Q}_{ij }e^{-\mathbf{C}_{ij}^{\theta}/\epsilon}}{n\sum_{k=1}^{m}\mathbf{Q}_{ik}e^{- \mathbf{C}_{ik}^{\theta}/\epsilon}}.\] (16)

The proof is given in Appendix F. We can find the form in Eq. 16 is similar with the Softmax cross-entropy loss. In particular, if we set \(\widetilde{\mathbf{P}}\), \(\mathbf{C}^{\theta}\), \(\mathbf{Q}\) and \(\epsilon\) in different forms as shown in Tab. 1, many classification loss can be the special cases of our formulation, as discussed in detail as follows.

**Special cases by varying \(\mathbf{C}^{\theta}\).** For a matching problem, it is quite important to define a distance among samples. We first set \(\mathbf{C}_{ij}^{\theta}=c-l_{ij}\) where \(c\) is a large enough value. In this case, Eq. 16 reduces to a normal softmax-based cross-entropy loss when \(\mathbf{Q}\) is in the uniformly distributed. Alternatively, we can set \(\mathbf{C}^{\theta}\) differently to suit specific tasks. For example, in learning in the hypersphere space, the Vanilla Softmax will be converted to A-softmax [37] to enforce angular margin constraints for improved face recognition performance.

**Deriving more losses by varying \(\mathbf{Q}\).** By varying the setting of \(\mathbf{Q}\), we can derive many Softmax-based losses as special cases of the RE-OT-based loss. For example, the Balanced Softmax can be obtained by setting \(\mathbf{Q}_{ij}=n_{j}\), where \(n_{j}\) is the frequency of label \(j\) in the training set. This choice of \(\mathbf{Q}\) encourages the model to assign equal weights to each class during training, which helps to mitigate the impact of class imbalance.

**Discussion on \(\widetilde{\mathbf{P}}\).** Re-weighting the example is a common way to improve the Long-tailed learning, including the empirical Re-weighting methods (e.g. focal loss [35]) and automatic Re-weighting ways (e.g. L2RW [46]). In the view of IOT, the supervision of the coupling \(\widetilde{\mathbf{P}}\) is self adapting and may depend on \(\mathbf{P}^{\theta}\), which may be helpful in IOT application fields such as deep graph matching.

\begin{table}
\begin{tabular}{c|c|c|c|c} \hline \hline \multirow{2}{*}{**Methods**} & \multicolumn{4}{c}{**Formulation**} \\ \cline{2-5}  & Ground Truth \(\widetilde{\mathbf{P}}_{ij}\) & Cost \(\mathbf{C}_{ij}\) & Prior \(\mathbf{Q}_{ij}\) & penalty coefficient \(\epsilon\) \\ \hline Vanilla Softmax & \(\widetilde{\mathbf{P}}_{ij}=\psi_{ij}\) & \(\mathbf{C}_{ij}=c-l_{ij}\) & \(Q_{ij}=1\) & \(\epsilon=\tau\) \\ \hline Focal Loss [35] & \(\widetilde{\mathbf{P}}_{ij}=\psi_{ji}\) (\(1-\mathbf{P}_{ij}\))\({}^{\ast}\) & \(\mathbf{C}_{ij}=c-l_{ij}\) & \(Q_{ij}=1\) & \(\epsilon=\tau\) \\ \hline A-softmax [37] & \(\widetilde{\mathbf{P}}_{ij}=\psi_{ij}\) & \(\mathbf{C}_{ij}=c-\|\psi_{ij}\|(\psi_{ij,\epsilon})\) & \(Q_{ij}=1\) & \(\epsilon=\tau\) \\ \hline Triplet [48] & \(\widetilde{\mathbf{P}}_{ij}=\psi_{ij}\) & \(\mathbf{C}_{ij}=\|f(x_{i})-f(x_{j})\|^{2}\) & \(Q_{ij}=1\) & \(\epsilon\to 0^{\ast}\) \\ \hline Class-Balanced Loss [3] & \(\widetilde{\mathbf{P}}_{ij}=(1-\beta)/\left(1-\beta_{\infty}^{\ast}\right)\) & \(\mathbf{C}_{ij}=c-l_{ij}\) & \(Q_{ij}=1\) & \(\epsilon=\tau\) \\ \hline LDAM Loss [3] & \(\widetilde{\mathbf{P}}_{ij}=\psi_{ij}\) & \(\mathbf{C}_{ij}=c-l_{ij}\) & \(Q_{ij}=c^{-l(\tau)\cdot\mathbf{C}/\epsilon}\) & \(\epsilon=\tau\) \\ \hline BalancedSoftmax [45] & \(\widetilde{\mathbf{P}}_{ij}=\psi_{ij}\) & \(\mathbf{C}_{ij}=c-l_{ij}\) & \(Q_{ij}=n_{j}\) & \(\epsilon=\tau\) \\ \hline Our Setting & \(\widetilde{\mathbf{P}}_{ij}=\psi_{ij}\) & \(\mathbf{C}_{ij}=c-l_{ij}\) & \(Q=(1-\lambda(t))\operatorname{Uniform}+\lambda(t)\mathbf{r}\) & \(\epsilon\rightarrow\tau\) \\ \hline \hline \end{tabular}
\end{table}
Table 1: Previous works in the view of inverse RE-OT by setting different ground truth \(\widetilde{\mathbf{P}}_{ij}\), cost \(\mathbf{C}_{ij}\), prior \(\mathbf{Q}_{ij}\) and coefficient \(\epsilon\) under the constraints \(U(\mathbf{a})\).

**Triplet loss for \(\epsilon\to 0^{+}\).** Though Eq. 16 has a very different form compared to triplet loss, the equivalence can also be established when the temperature \(\epsilon\to 0^{+}\). Note that the idea of the relation between triplet loss and our loss is motivated by the work [55] which gives the proof of the equivalence between triplet loss and InfoNCE. We give the proof in Appendix G.

**Representation Learning with our Formulation** Our matching perspective can be applied not only to unbalanced classification but also to unbalanced representation learning, in which we only need to modify the original one-hot label to the augmentation's features. In Sec. 5, we conducted experiments on long-tailed contrastive learning and verified that by selecting an appropriate \(\mathbf{Q}\), we can improve the effectiveness of representation learning on long-tailed datasets.

### Bridging Regularized OT to Classification

We have shown the classification can be viewed as a matching problem and if we formulate the matching with optimal transport, we can get the equivalence between Softmax (as well as its variants) and RE-OT under the setting of \(U(\mathbf{a})\). We can observe that there are some interconnected concepts between OT and classification, which can shed lights on a deeper understanding of OT and in turn the classification problem with different forms. One notable example is the entropy regularization coefficient \(\epsilon\) in OT and the temperature coefficient \(\tau\) in Softmax. There have been numerous works [24; 61] exploring the role of the temperature hyperparameter in Softmax. We can understand it easier from the view of OT, where \(\epsilon\) serves as a relaxation hyperparameter for couplings yielding smoother predictions. In fact, there are other concepts, such as barycentic projection in OT [13], which may help us understand more about classification. We give its definition here:

**Definition 1** (**Barycentric Projection**).: _Consider the setting of Eq. 6 in which we use entropic regularization to approximate OT between discrete measures. One can define the so-called barycentric projection map with the coupling \(\mathbf{P}\)_

\[T:x_{i}\in X\rightarrow\frac{1}{\mathbf{a}_{i}}\sum\nolimits_{j}\mathbf{P}_{ ij}y_{j}\in Y,\] (17)

_where \(\{x_{i}\}\subset X\) is the set of locations corresponding to simplex \(\mathbf{a}\) and \(\{y_{j}\}\) is the set of locations in the \(Y\) space corponding to simplex \(\mathbf{b}\)._

From the classification view, exactly \(T(x_{i})\) is probability confidences of samples \(x_{i}\) which can be understand as the feature in the one-hot label space. Besides, motivated by this barycentric projection in OT, we can exactly define the mapping for the feature of one-hot label in hidden feature space:

\[T^{\prime}:y_{j}\in Y\rightarrow\frac{1}{\sum\nolimits_{i}\mathbf{P}_{ij}} \sum\nolimits_{i}\mathbf{P}_{ij}\mathbf{f}_{i}\in\mathcal{F},\] (18)

where \(\mathbf{f}_{i}\) is the feature of \(x_{i}\) extracting from the neural networks and \(\mathcal{F}\) is the feature space. Eq. 18 maps the (one-hot) label to the feature space, which means no need to learn the centroid features

Figure 4: t-SNE for training and testing sample features and class barycenters. The class barycenters are calculated by Eq. 18 with features of training data. It can be observed that in the training data, the class barycenters are mainly on the feature centers of corresponding category samples, which proves the effectiveness of the barycentric projection map defined in Eq. 18. At the same time, we also find that barycenters calculated by features of training samples may not necessarily be centered in the test data. Additionally, the head class occupies a significantly larger space than the tail class in the 2D feature space, which may be one of the reasons for the poor accuracy of the tail class.

as done in oneline clustering methods [4; 32] but calculate it statically with Eq. 18 if the coupling is known. As shown in Fig. 4, we first train the models using vanilla softmax, focal loss, and our loss on the Cifar10-LT dataset. We consider the logits as the sample features and save the logits from the three head and three tailed classes, along with the corresponding predicted couplings, as matrices. Then, we calculate the barycenters of the labels using Eq. 18, which effectively computes the weighted average of the features. We concat the logits and barycenters as a new matrix and use it to calculate t-SNE results for training data, as shown in the first row of Fig. 4. For testing data, we concat the testing logits with the barycenters calculated from the training data and use t-SNE dimensional reduction, as shown in the second row in Fig. 4. By comparing the first row and the second row of Fig. 4, we can observe the differences in the positions of the barycenters, which are actually caused by shift in the feature distributions.

**Further Discussions between OT and classification.** Note that many theoretical aspects and variations of OT can be incorporated into the field of classification. Here are a few advantages unique to the OT perspective that can be achieved but are not possible in the traditional Bayesian view: **1) Variable** constraints instead of \(\{\mathbf{P}:\mathbf{P}\mathbf{1}=\mathbf{a}\}\), such as (modified) Optimal Partial Transport (OPT) with \(\{\mathbf{P}:\mathbf{P}\mathbf{1}\leq\mathbf{a},\mathbf{1}^{\top}\mathbf{P} \mathbf{1}=s\}\) where \(s\) is the number requiring to predict. This allows for distributions that are not just one-vs-all and enables rejection of classification if the model determines that a sample cannot be classified into any of the candidate labels; **2) Generalization** of softmax. The current softmax formulation is essentially based on Entropic Regularization of OT. However, OT regularization goes beyond just the entropic regularization and includes other regularizations such as L2, Tsallis entropies, or divergence-based ones. This opens up possibilities for generalizing softmax; **3) Classification** cross-representation models. From the OT perspective, classification between the features of samples and labels, based on Gromov-Wasserstein Distance, can be performed in different feature spaces. For example, the sample features may be in 100 dimensions while the label features are in 20 dimensions. This can be helpful for preserving privacy as Gromov-Wasserstein Distance [44] only requires similarity between samples and labels. Due to the various variants and theories within OT, considering classification as OT naturally allows us to incorporate existing OT knowledge into the field of classification, which is the ongoing work we are conducting.

## 5 Experiments

We evaluate our proposed approach for both image and molecule datasets. As the primary focus of this paper is the impact of loss functions on model learning, we do not adopt additional specialized techniques to improve performance, such as transfer learning or resampling. This is to control variables and thus all the baselines used in this study represent only the loss functions proposed by them. Additional experimental settings and details can be found in Appendix H.

**Experiments on long-tailed image classification.** The long-tailed image classification datasets analyzed in this study include CIFAR10-LT, CIFAR100-LT [30], and Imagenet-LT [38]. To evaluate the performance of the models, we use the corresponding balanced test dataset and report top-1 accuracy. Specifically, for CIFAR-10, we report accuracy on two sets of classes: Many-shot (more than 100 images) and Few-shot (less than 100 images). For CIFAR-100 and Imagenet, we report accuracy on three sets: Many-shot (more than 100 images), Medium-shot (20 \(\sim\) 100 images), and Few-shot (less than 20 images). The experiments for unbalanced image classification are all conducted with an imbalanced factor of less than 200, which is defined as the ratio of the number of training instances in the largest class to the smallest [45]. The results for long-tailed classification are presented in Table 3. Note that in our approach, the teacher-based method involves setting the prior matrix \(\mathbf{r}\) in Eq. 15 using a vanilla softmax trained teacher model. On the other hand, the ratio-based method refers to setting \(\mathbf{r}\) as the long-tailed ratio. From a comprehensive perspective, at least one of our approaches achieves the best average accuracy across the entire dataset.

**Experiments on unbalanced molecule classification.** We further examine the application of our proposed method in the context of molecular representation learning task, which holds significant implications for healthcare [59] and drug discovery [17; 58]. Specifically, we perform the experiments on two unbalanced molecule classification datasets, i.e. OGBG-MOLBBBP and OGBG-MOLBACE, from the Open Graph Benchmark (OGB) [21]. We use the default train/val/test split with ratio 8:1:1. Given the presence of class imbalance within the two datasets, we have chosen to adhere to the precedent set by prior studies, also employing the ROC-AUC as the metric for performance evaluation. As the experimental results are easily influenced by initialization, we conducted five repetitions of the experiment and reported the mean accuracy and its standard deviation in the Tab. 2, which show the effectiveness of our method.

**Experiments on Long-Tailed Instance Segmentation.** We do experiments on long-tailed instance segmentation with LVIS v1.0 datasets [18], as one of the most challenging datasets in vision with a much higher imbalance factor compared to the rest. We use the official splits and evaluation is conducted on validation set. The setting mainly follows the experiments in [45], whose details are given in Appendix H. AP\({}_{m}\), AP\({}_{r}\), AP\({}_{c}\), AP\({}_{f}\) are reported in Tab. 2. AP\({}_{m}\) denotes Average Precision of masks, AP\({}_{r}\), AP\({}_{c}\), AP\({}_{f}\) denote Average Precision of masks on rare classes, common classes and frequent classes. As shown in Tab. 2, we can find that our method achieves the best AP\({}_{m}\) on the entire set and perform competitively for other evaluations.

**More Experiments.** We also perform experiments on Long-Tailed contrastive representation learning on CIFAR10-LT, CIFAR100-LT with 100 imbalanced factor. We compare our methods with the methods in [5, 27]. The settings and results are given in Appendix H.5. Besides, to further demonstrate the usefulness of viewing classification as OT, a new inference method is proposed for testing. we replaced the softmax (i.e. constraints within \(U(\mathbf{a})\)) with Sinkhorn algorithm (i.e. constraints within \(U(\mathbf{a},\mathbf{b})\)), where \(\mathbf{b}\) represents the assumed ratio in the testing data (e.g., long-tailed, uniform, or reverse long-tailed distribution). Details are given in Appendix H.6.

## 6 Conclusion

We have provided a matching perspective to provide new understanding to classification. Under our matching-based framework, we show that the inherent challenge of long-tailed classification lies in the inconsistency of the prior information used for training and testing under the matching formulation. We then develop inverse relative entropic OT approach to revisit the classification problem, and especially for the long-tailed case, we develop a simple yet effective technique based on our theoretical insights. Experimental results verify the effectiveness of our methods.

**Broader impacts.** Our work establishes a theoretical framework for understanding and solving (self-)supervised problems using OT theory. This not only broadens the range of applications for OT in generative models, such as WGAN and its variants, but also provides a new perspective for redefining, understanding, and solving (self-)supervised problems. Furthermore, the theory and concepts of OT can facilitate the discovery of interesting relationships and insights for supervised problems, such as the connection between open set recognition and unbalanced OT. **Limitations.** It assumes known prior label distribution testing data, which is often unknown in real-world scenarios.

\begin{table}
\begin{tabular}{l||c c c c||c|c} \hline \hline \multirow{2}{*}{**Method**} & \multicolumn{3}{c||}{**LVIS (instance seg.)**} & \multicolumn{3}{c}{**OGBG-MOLBBBP**} & \multicolumn{1}{c}{**OGBG-MOLBACE**} \\ \cline{2-7}  & AP\({}_{m}\) & AP\({}_{r}\) & AP\({}_{r}\) & AP\({}_{f}\) & ROC-AUC & ROC-AUC \\ \hline Vanilla & 20.62 & 9.66 & 19.11 & 27.11 & 69.21 \(\pm\) 0.34 & 79.40 \(\pm\) 1.20 \\ Focal Loss [35] & 19.69 & 8.75 & 17.74 & 26.68 & 68.15 \(\pm\) 1.29 & 80.65 \(\pm\) 1.50 \\ LDAM [3] & 15.53 & 7.14 & 13.23 & 20.89 & 65.99 \(\pm\) 0.94 & 79.20 \(\pm\) 2.00 \\ LogitAdjust [39] & 22.41 & 17.10 & 21.18 & **28.48** & 69.05 \(\pm\) 1.59 & 81.25 \(\pm\) 0.33 \\ CB-CE [8] & 20.38 & 9.58 & 18.72 & 26.98 & 69.19 \(\pm\) 1.18 & 79.39 \(\pm\) 1.16 \\ CB-FC [8] & 21.41 & **15.67** & 20.34 & 25.25 & 69.51 \(\pm\) 1.18 & 80.24 \(\pm\) 1.45 \\ Balanced Softmax & 22.60 & 12.88 & 21.20 & 28.44 & 68.13 \(\pm\) 0.87 & 80.26 \(\pm\) 2.28 \\ Ours(ratio-based) & **22.64** & 13.15 & **21.26** & 28.34 & **70.48 \(\pm\) 0.73** & **82.48 \(\pm\) 1.59** \\ \hline \hline \end{tabular}
\end{table}
Table 2: Test on instance segmentation and molecule classification.

\begin{table}
\begin{tabular}{l||c c c||c c c c||c c c} \hline \hline \multirow{2}{*}{**Method**} & \multicolumn{3}{c||}{**CIFAR10-LT**} & \multicolumn{3}{c||}{**CIFAR100-LT**} & \multicolumn{3}{c}{**ImageNet-LT**} \\ \cline{2-13}  & Many & Few & All & Many & Medium & Few & All & Many & Medium & Few & All \\ \hline Vanilla Softmax & 77.4 & 68.9 & 74.9 & 75.8 & 48.2 & 11.0 & 42.0 & 57.3 & 26.2 & 3.1 & 35.0 \\ Focal Loss [35] & 79.6 & 58.4 & 73.3 & **76.1** & 46.9 & 11.1 & 41.7 & 57.3 & 27.6 & 4.4 & 35.9 \\ LDAM [3] & 80.5 & 65.2 & 75.9 & 75.7 & 50.6 & 11.5 & 42.9 & **57.3** & 27.6 & 4.4 & 35.9 \\ LogitAdjust [39] & 80.0 & 35.3 & 66.6 & 75.7 & 39.2 & 4.1 & 36.5 & 54.2 & 14.0 & 0.4 & 27.6 \\ CB-CE [8] & 76.6 & 70.7 & 74.8 & 53.2 & 48.8 & 13.3 & 36.3 & 35.3 & 32.1 & 21.2 & 31.9 \\ Balanced Softmax [45] & 82.2 & 71.6 & 79.0 & 70.3 & 50.4 & 26.5 & 47.0 & 52.5 & 38.6 & 17.8 & 41.1 \\ Ours(teacher-based) & **84.4** & 63.7 & 78.2 & 69.7 & **55.6** & 24.9 & **47.9** & 41.5 & 37.6 & **31.1** & 38.2 \\ Ours(ratio-based) & 81.5 & **74.6** & **79.4** & 70.4 & 53.0 & **26.6** & **47.9** & 53.5 & **39.0** & 17.4 & **41.6** \\ \hline \hline \end{tabular}
\end{table}
Table 3: Top-1 accuracy (%) for long-tailed image classification with 200 imbalanced factor.

## References

* [1]M. Agueh and G. Carlier (2011) Barycenters in the wasserstein space. SIAM Journal on Mathematical Analysis43 (2), pp. 904-924. Cited by: SS1.
* [2]J. Benamou, G. Carlier, M. Cuturi, L. Nenna, and G. Peyre (2015) Iterative bregman projections for regularized transportation problems. SIAM Journal on Scientific Computing37 (2), pp. A1111-A1138. Cited by: SS1.
* [3]K. Cao, C. Wei, A. Gaidon, N. Arechiga, and T. Ma (2019) Learning imbalanced datasets with label-distribution-aware margin loss. Advances in neural information processing systems32. Cited by: SS1.
* [4]M. Caron, I. Misra, J. Mairal, P. Goyal, P. Bojanowski, and A. Joulin (2020) Unsupervised learning of visual features by contrasting cluster assignments. Advances in neural information processing systems33, pp. 9912-9924. Cited by: SS1.
* [5]T. Chen, S. Kornblith, M. Norouzi, and G. Hinton (2020) A simple framework for contrastive learning of visual representations. In International conference on machine learning, pp. 1597-1607. Cited by: SS1.
* [6]W. Chiu, P. Wang, and P. Shafto (2022) Discrete probabilistic inverse optimal transport. In International Conference on Machine Learning, pp. 3925-3946. Cited by: SS1.
* [7]J. Cui, Z. Zhong, S. Liu, B. Yu, and J. Jia (2021) Parametric contrastive learning. In Proceedings of the IEEE/CVF international conference on computer vision, pp. 715-724. Cited by: SS1.
* [8]Y. Cui, M. Jia, T. Lin, Y. Song, and S. Belongie (2019) Class-balanced loss based on effective number of samples. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 9268-9277. Cited by: SS1.
* [9]Y. Cui, Y. Song, C. Sun, A. Howard, and S. Belongie (2018) Large scale fine-grained categorization and domain-specific transfer learning. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 4109-4118. Cited by: SS1.
* [10]M. Cuturi (2013) Sinkhorn distances: lightspeed computation of optimal transport. Advances in neural information processing systems26. Cited by: SS1.
* [11]B. B. Damodaran, B. Kellenberger, R. Flamary, D. Tuia, and N. Courty (2018) DeepJOT: deep joint distribution optimal transport for unsupervised domain adaptation. In Proceedings of the European conference on computer vision (ECCV), pp. 447-463. Cited by: SS1.
* [12]A. Dupuy, A. Galichon, and Y. Sun (2016) Estimating matching affinity matrix under low-rank constraints. arXiv preprint arXiv:1612.09585. Cited by: SS1.
* [13]S. Ferradans, N. Papadakis, G. Peyre, and J. Aujol (2014) Regularized discrete optimal transport. SIAM Journal on Imaging Sciences7 (3), pp. 1853-1882. Cited by: SS1.
* [14]J. Feydy, B. Charlier, F. Vialard, and G. Peyre (2017) Optimal transport for diffeomorphic registration. In Medical Image Computing and Computer Assisted Intervention- MICCAI 2017: 20th International Conference, Quebec City, QC, Canada, September 11-13, 2017, Proceedings, Part I 20, pp. 291-299. Cited by: SS1.
* [15]I. Gulrajani, F. Ahmed, M. Arjovsky, V. Dumoulin, and A. Courville (2017) Improved training of wasserstein gans. In NIPS, Cited by: SS1.
* [16]H. Guo and S. Wang (2021) Long-tailed multi-label visual recognition by collaborative training on uniform and re-balanced samplings. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 15089-15098. Cited by: SS1.
* [17]Z. Guo, W. Yu, C. Zhang, M. Jiang, and N. V. Chawla (2020) Graseq: graph and sequence fusion learning for molecular property prediction. In Proceedings of the 29th ACM international conference on information & knowledge management, pp. 435-443. Cited by: SS1.

* [18] A. Gupta, P. Dollar, and R. Girshick. Lvis: A dataset for large vocabulary instance segmentation. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pages 5356-5364, 2019.
* [19] H. He and E. A. Garcia. Learning from imbalanced data. _IEEE Transactions on knowledge and data engineering_, 21(9):1263-1284, 2009.
* [20] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In _Proceedings of the IEEE conference on computer vision and pattern recognition_, pages 770-778, 2016.
* [21] W. Hu, M. Fey, M. Zitnik, Y. Dong, H. Ren, B. Liu, M. Catasta, and J. Leskovec. Open graph benchmark: Datasets for machine learning on graphs. _Advances in neural information processing systems_, 33:22118-22133, 2020.
* [22] M. A. Jamal, M. Brown, M.-H. Yang, L. Wang, and B. Gong. Rethinking class-balanced methods for long-tailed visual recognition from a domain adaptation perspective. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pages 7610-7619, 2020.
* [23] H. Janati, M. Cuturi, and A. Gramfort. Debiased sinkhorn barycenters. In _International Conference on Machine Learning_, pages 4692-4701. PMLR, 2020.
* [24] E. Jang, S. Gu, and B. Poole. Categorical reparameterization with gumbel-softmax. _arXiv preprint arXiv:1611.01144_, 2016.
* [25] B. Kang, S. Xie, M. Rohrbach, Z. Yan, A. Gordo, J. Feng, and Y. Kalantidis. Decoupling representation and classifier for long-tailed recognition. _arXiv preprint arXiv:1910.09217_, 2019.
* [26] L. Kantorovich. On the transfer of masses (in russian). In _Doklady Akademii Nauk_, volume 37, pages 227-229, 1942.
* [27] P. Khosla, P. Teterwak, C. Wang, A. Sarna, Y. Tian, P. Isola, A. Maschinot, C. Liu, and D. Krishnan. Supervised contrastive learning. _Advances in neural information processing systems_, 33:18661-18673, 2020.
* [28] J. Kim, J. Jeong, and J. Shin. M2m: Imbalanced classification via major-to-minor translation. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pages 13896-13905, 2020.
* [29] J. J. Kosowsky and A. L. Yuille. The invisible hand algorithm: Solving the assignment problem with statistical physics. _Neural networks_, 7(3):477-490, 1994.
* [30] A. Krizhevsky, G. Hinton, et al. Learning multiple layers of features from tiny images. 2009.
* [31] C. Leonard. From the schrodinger problem to the monge-kantorovich problem. _Journal of Functional Analysis_, 262(4):1879-1920, 2012.
* [32] J. Li, P. Zhou, C. Xiong, and S. C. Hoi. Prototypical contrastive learning of unsupervised representations. _arXiv preprint arXiv:2005.04966_, 2020.
* [33] R. Li, X. Ye, H. Zhou, and H. Zha. Learning to match via inverse optimal transport. _Journal of machine learning research_, 20, 2019.
* [34] Y. Li, Y. Mo, L. Shi, and J. Yan. Improving generative adversarial networks via adversarial learning in latent space. _Advances in Neural Information Processing Systems_, 35:8868-8881, 2022.
* [35] T.-Y. Lin, P. Goyal, R. Girshick, K. He, and P. Dollar. Focal loss for dense object detection. In _Proceedings of the IEEE international conference on computer vision_, pages 2980-2988, 2017.
* [36] J. Liu, Y. Sun, C. Han, Z. Dou, and W. Li. Deep representation learning on long-tailed data: A learnable embedding augmentation perspective. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pages 2970-2979, 2020.

* [37] W. Liu, Y. Wen, Z. Yu, M. Li, B. Raj, and L. Song. Sphereface: Deep hypersphere embedding for face recognition. In _Proceedings of the IEEE conference on computer vision and pattern recognition_, pages 212-220, 2017.
* [38] Z. Liu, Z. Miao, X. Zhan, J. Wang, B. Gong, and S. X. Yu. Large-scale long-tailed recognition in an open world. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pages 2537-2546, 2019.
* [39] A. K. Menon, S. Jayasumana, A. S. Rawat, H. Jain, A. Veit, and S. Kumar. Long-tail learning via logit adjustment. _arXiv preprint arXiv:2007.07314_, 2020.
* [40] J. Orlin. A faster strongly polynomial minimum cost flow algorithm. In _Proceedings of the Twentieth annual ACM symposium on Theory of Computing_, pages 377-387, 1988.
* [41] S. Park, J. Lim, Y. Jeon, and J. Y. Choi. Influence-balanced loss for imbalanced visual classification. In _Proceedings of the IEEE/CVF International Conference on Computer Vision_, pages 735-744, 2021.
* [42] H. Peng, M. Sun, and P. Li. Optimal transport for long-tailed recognition with learnable cost matrix. In _International Conference on Learning Representations_, 2022.
* [43] G. Peyre and M. Cuturi. Computational optimal transport. _Foundations and Trends in Machine Learning_, 11(5-6):355-607, 2019.
* [44] G. Peyre, M. Cuturi, and J. Solomon. Gromov-wasserstein averaging of kernel and distance matrices. In _International conference on machine learning_, pages 2664-2672. PMLR, 2016.
* [45] J. Ren, C. Yu, X. Ma, H. Zhao, S. Yi, et al. Balanced meta-softmax for long-tailed visual recognition. _Advances in neural information processing systems_, 33:4175-4186, 2020.
* [46] M. Ren, W. Zeng, B. Yang, and R. Urtasun. Learning to reweight examples for robust deep learning. In _International conference on machine learning_, pages 4334-4343. PMLR, 2018.
* [47] B. Schmitzer. Stabilized sparse scaling algorithms for entropy regularized transport problems. _SIAM Journal on Scientific Computing_, 41(3):A1443-A1481, 2019.
* [48] F. Schroff, D. Kalenichenko, and J. Philbin. Facenet: A unified embedding for face recognition and clustering. In _Proceedings of the IEEE conference on computer vision and pattern recognition_, pages 815-823, 2015.
* [49] L. Shi, Y. Li, and J. Yan. lid-gan: an iid sampling perspective for regularizing mode collapse. _arXiv preprint arXiv:2106.00563_, 2021.
* [50] L. Shi, G. Zhang, H. Zhen, J. Fan, and J. Yan. Understanding and generalizing contrastive learning from the inverse optimal transport perspective. _International conference on machine learning_, 2023.
* [51] A. M. Stuart and M.-T. Wolfram. Inverse optimal transport. _SIAM Journal on Applied Mathematics_, 80(1):599-619, 2020.
* [52] J. Tan, C. Wang, B. Li, Q. Li, W. Ouyang, C. Yin, and J. Yan. Equalization loss for long-tailed object recognition. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pages 11662-11671, 2020.
* [53] E. Tzeng, J. Hoffman, K. Saenko, and T. Darrell. Adversarial discriminative domain adaptation. In _Proceedings of the IEEE conference on computer vision and pattern recognition_, pages 7167-7176, 2017.
* [54] G. R. Waissi. Network flows: Theory, algorithms, and applications, 1994.
* [55] F. Wang and H. Liu. Understanding the behaviour of contrastive loss. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pages 2495-2504, 2021.
* [56] Y.-X. Wang, D. Ramanan, and M. Hebert. Learning to model the tail. _Advances in neural information processing systems_, 30, 2017.

* [57] A. G. Wilson. The use of entropy maximising models, in the theory of trip distribution, mode split and route split. _Journal of transport economics and policy_, pages 108-126, 1969.
* [58] N. Yang, K. Zeng, Q. Wu, X. Jia, and J. Yan. Learning substructure invariance for out-of-distribution molecular representations. In _Advances in Neural Information Processing Systems_, 2022.
* [59] N. Yang, K. Zeng, Q. Wu, and J. Yan. Molerec: Combinatorial drug recommendation with substructure-aware molecular representation learning. In _Proceedings of the ACM Web Conference 2023_, pages 4075-4085, 2023.
* [60] S. Zhang, Z. Li, S. Yan, X. He, and J. Sun. Distribution alignment: A unified framework for long-tail visual recognition. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pages 2361-2370, 2021.
* [61] X. Zhang, F. X. Yu, S. Karaman, W. Zhang, and S.-F. Chang. Heated-up softmax embedding. _arXiv preprint arXiv:1809.04157_, 2018.
* [62] Y. Zhang, B. Hooi, L. Hong, and J. Feng. Self-supervised aggregation of diverse experts for test-agnostic long-tailed recognition. _arXiv preprint arXiv:2107.09249_, 2021.
* [63] Y. Zhang, B. Hooi, D. Hu, J. Liang, and J. Feng. Unleashing the power of contrastive self-supervised visual models via contrast-regularized fine-tuning. _Advances in Neural Information Processing Systems_, 34:29848-29860, 2021.
* [64] Y. Zhang, B. Kang, B. Hooi, S. Yan, and J. Feng. Deep long-tailed learning: A survey. _IEEE Transactions on Pattern Analysis and Machine Intelligence_, 2023.
* [65] B. Zhou, Q. Cui, X.-S. Wei, and Z.-M. Chen. Bbn: Bilateral-branch network with cumulative learning for long-tailed visual recognition. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pages 9719-9728, 2020.