# Stochastic Approximation Algorithms

for Systems of Interacting Particles

 Mohammad Reza Karimi

ETH Zurich

mkarimi@inf.ethz.ch &Ya-Ping Hsieh

ETH Zurich

yaping.hsieh@inf.ethz.ch &Andreas Krause

ETH Zurich

krausea@ethz.ch

###### Abstract

Interacting particle systems have proven highly successful in various machine learning tasks, including approximate Bayesian inference and neural network optimization. However, the analysis of these systems often relies on the simplifying assumption of the _mean-field_ limit, where particle numbers approach infinity and infinitesimal step sizes are used. In practice, discrete time steps, finite particle numbers, and complex integration schemes are employed, creating a theoretical gap between continuous-time and discrete-time processes. In this paper, we present a novel framework that establishes a precise connection between these discrete-time schemes and their corresponding mean-field limits in terms of convergence properties and asymptotic behavior. By adopting a dynamical system perspective, our framework seamlessly integrates various numerical schemes that are typically analyzed independently. For example, our framework provides a unified treatment of optimizing an infinite-width two-layer neural network and sampling via Stein Variational Gradient descent, which were previously studied in isolation.

## 1 Introduction

Dynamics of interacting particle systems are central to many challenges in modern machine learning. These range from algorithm design for approximate Bayesian inference, to the study of equilibria in games [26, 31, 34]. Moreover, researchers have gained valuable insights by interpreting the training process of over-parametrized two-layer neural networks as a system of interacting particles, thereby advancing our intuition in this domain [11, 12, 36, 37, 38, 46, 51].

Analyzing the behavior of such systems poses a significant challenge. To simplify the analysis, researchers often turn to the concept of the _mean-field limit_. In this approach, the number of particles is increased to infinity, the step-size of the algorithm shrinks to zero, and results are deduced from this continuous limit. Specifically, an initial probability distribution is assigned to the infinitely many particles, and a continuous-time evolution is derived for this distribution. The resulting evolutionary equation serves as a powerful tool for gaining insights into the system's asymptotic behavior, significantly aiding in the comprehension of systems with a large number of interacting particles [1, 5, 22, 26, 47].

Although the mean-field limit has offered valuable insights into the aforementioned problems, its rigorous justification necessitates examining systems with both a _finite_ number of particles and the _discrete-time algorithms_ commonly used in practice. Unfortunately, to the best of our knowledge, while a substantial body of work exists on finite-particle systems (see, e.g., the review papers [8, 9] and references therein), these studies are confined to analyzing continuous-time dynamics. As a result, a gap between theory and practice has emerged, and a precise link between continuous and discrete-time schemes is still largely lacking.

SS Contributions.Our paper aims to bridge this gap by rigorously establishing the convergence of discrete-time algorithms to their continuous-time counterparts in terms of long-term behavior.

To accomplish this, we draw inspiration from the field of _dynamical system_ theory, which traces its origins back to early developments in statistics [42] and has recently found success in various domains of machine learning, including optimization theory, games, and sampling [21; 23; 24].

This dynamical system framework offers two significant advantages. Firstly, it provides a flexible framework capable of accommodating a wide range of practical schemes commonly employed in real-world scenarios. Secondly, this framework enables a unified treatment of various machine learning tasks that were previously studied in isolation. Notably, it allows us to address tasks such as training neural networks and approximate Bayesian inference using techniques like Stein variational gradient descent in a coherent and unified manner.

In summary, our paper makes the following contributions:

1. We introduce a comprehensive framework for analyzing a broad class of algorithms called _stochastic approximation schemes_. These schemes are widely utilized in simulating systems of interacting particles, and our framework provides a unified approach to analyze their behavior.
2. Under mild assumptions on the discrete-time schemes and the mean-field dynamics, we prove the convergence of these schemes towards their respective mean-field limits. The convergence is established in terms of the _2-Wasserstein distance_, a metric commonly used to measure the dissimilarity between probability distributions.
3. Since our framework is specifically tailored to address a wide range of fields, we instantiate our main theorem and provide novel guarantees to a diverse array of interacting particle systems across domains such as the Stein variational gradient descent, the training of wide two-layer neural networks, and the examination of game equilibria.

## 2 Illustration: Training Two-Layer Neural Networks via Noisy SGD

To illustrate the particle system under study and its corresponding mean-field limit, let us consider the example of training a two-layer neural network with \(N\) neurons and squared loss using the noisy SGD algorithm. The network takes an input \(z\in\mathbb{R}^{d-1}\) and computes function:

\[h_{\bm{\theta}}(z)\coloneqq\frac{1}{N}\sum_{i=1}^{N}\varphi(\theta^{i},z), \quad\text{with}\quad\theta^{i}=(a^{i},b^{i})\in\mathbb{R}^{d-1}\times\mathbb{ R}\quad\text{and}\quad\varphi(\theta^{i},z)=b^{i}\,\kappa(\langle a^{i},z \rangle).\]

Here, \(\bm{\theta}=(\theta^{1},\dots,\theta^{N})\) denotes the collection of neurons' parameters, and \(\kappa\) is an activation function (such as sigmoid or tanh). To train this network, one ideally minimizes the regularized risk \(L(\bm{\theta})\coloneqq\mathbb{E}_{(y,z)\sim\mathcal{D}}\frac{1}{2}(y-h_{\bm {\theta}}(z))^{2}+\lambda\,U(\bm{\theta})\), where \(\mathcal{D}\) is the data distribution, and \(U(\bm{\theta})=\frac{1}{N}\sum_{i}U(\theta^{i})\) is a regularizer, such as \(U(\theta)=\frac{1}{2}|\theta|^{2}\). Applying the noisy gradient descent algorithm to the regularized risk then results in the update rule:

\[\theta^{i}_{k+1}=\theta^{i}_{k}-\gamma_{k+1}\nabla_{\theta^{i}}L(\bm{\theta} _{k})+\sigma\sqrt{2\gamma_{k+1}}\,\xi^{i}_{k+1},\qquad i=1,\dots,N,\] (SGD \[{}_{\sigma}\] )

where \(\gamma_{k+1}\) is the step-size, \(\sigma\geq 0\) is the noise level, and \(\{\xi^{i}_{k+1}\}\) is a collection of i.i.d. standard Gaussians. To cast this algorithm as a system of interacting particles, we define the _interaction kernel_\(W\) and the _potential_\(V\) as

\[W(\theta,\theta^{\prime})=\mathbb{E}_{z\sim\mathcal{D}}\left[\varphi(\theta,z) \varphi(\theta^{\prime},z)\right]\quad\text{and}\quad V(\theta)=\mathbb{E}_{( y,z)\sim\mathcal{D}}\left[y\,\varphi(\theta,z)\right]+\lambda\,U(\theta).\] (1)

It is then easily seen (cf. (36, Eqn. 4)) that the update rule (SGD\({}_{\sigma}\)) can be rewritten as

\[\theta^{i}_{k+1}=\theta^{i}_{k}-\gamma_{k+1}\Big{(}\frac{1}{N}\sum_{j=1}^{N} \nabla_{\theta}W(\theta^{i}_{k},\theta^{j}_{k})+\nabla V(\theta^{i}_{k}) \Big{)}+\sigma\sqrt{2\gamma_{k+1}}\,\xi^{i}_{k+1},\quad i=1,\dots,N.\] (2)

By considering neurons as particles, the equation (2) reveals that the training dynamics of each particle is influenced by the potential \(V\) and the interaction energy \(W\) with other particles. This interpretation highlights that (SGD\({}_{\sigma}\)) represents the evolution of a system of interacting particles. In a broader context, one may consider more sophisticated algorithms, several of which (see Section 4 for examples) can be formulated as

\[\theta^{i}_{k+1}=\theta^{i}_{k}-\gamma_{k+1}\big{(}\nabla_{\theta^{i}}L(\bm{ \theta}_{k})+P^{i}_{k+1}\big{)}+\sigma\sqrt{2\gamma_{k+1}}\,\xi^{i}_{k+1}, \qquad i=1,\dots,N\] (3)

where \(P^{i}_{k+1}\) is the (random or deterministic) perturbation in evaluating the gradient. These algorithms are usually called _stochastic approximation algorithms_. For example, Noisy SGD corresponds to setting \(P^{i}_{k+1}=\nabla_{\theta^{i}}\widetilde{L}(\bm{\theta}_{k})-\nabla_{\theta ^{i}}L(\bm{\theta}_{k})\), where \(\widetilde{L}\) is the loss of a random batch of data.

S Continuous-time limit and the mean-field approximation.We now go from the discrete-time algorithm (3) to a continuous-time process and then derive the mean-field approximation. First, observe that the risk \(L(\bm{\theta})\) depends on \((\theta^{1},\ldots,\theta^{N})\) only through their _empirical measure_\(\widetilde{\mu}=\frac{1}{N}\sum_{i}\delta_{\theta^{i}}\). For example,

\[\tfrac{1}{N}\sum_{j=1}^{N}\nabla_{\theta}W(\theta,\theta^{j})+\nabla V(\theta) =\int\nabla_{\theta}W(\theta,\theta^{\prime})\;\widetilde{\mu}(d\theta^{ \prime})+\nabla V(\theta)\eqqcolon b(\theta,\widetilde{\mu}),\] (4)

where we have introduced the _drift_ function \(b\). To simplify the analysis, previous studies then consider the idealized setting where an infinitesimal step-size is employed, thereby further reducing (3) to the following system of stochastic differential equations (SDEs):

\[d\theta^{i}_{t}=b(\theta^{i}_{t},\widetilde{\mu}_{t})\;dt+\sigma\sqrt{2}\,dW^ {i}_{t},\qquad i=1,\ldots,N,\] (5)

where \(\widetilde{\mu}_{t}=\frac{1}{N}\sum_{i}\delta_{\theta^{i}_{t}}\) is the empirical measure of the particles at time \(t\), and \(\{W^{i}_{\cdot}\}\) is a collection of i.i.d. standard Brownian motions. In the over-parametrized regime where the number of particles \(N\) becomes very large, one can approximate the initial setting of the particles \(\widetilde{\mu}_{0}\) with a probability density \(\rho_{0}\), and consider the following _mean-field_ approximation defined over \(\mathbb{R}^{d}\) as

\[d\theta_{t}=b(\theta_{t},\rho_{t})\;dt+\sigma\sqrt{2}\,dW_{t},\quad\rho_{t}= \operatorname{density}(\theta_{t}).\] (6)

This dynamics captures the behavior of an individual particle \(\theta\) within a density of particles distributed according to \(\rho\). The analysis of (6) turns out to be considerably simpler compared to the system of SDEs in (5), e.g., via studying the evolutionary PDE \(\partial_{t}\rho_{t}=\nabla\cdot(\rho_{t}\,b(\cdot,\rho_{t}))+\sigma^{2} \Delta\rho_{t}\). As a result, it has attracted significant interest in the field of deep learning theory [36, 37, 38, 12, 11, 38].

In conclusion, the mean-field dynamics (6) offers a powerful and elegant framework, but its validity rests on two simplifying assumptions: an infinite number of particles and a step-size approaching zero. A rigorous justification of these two steps is by no means trivial. While the existing literature has made progress in addressing the infinite particle issue, the second assumption has received comparatively less attention. Bridging this gap is one of the primary objectives of our paper. Specifically, we aim to establish the Wasserstein convergence of the discrete-time dynamics (3) to the same limit sets1 as the continuous-time particle dynamics (5), under mild conditions on the drift \(b\) and perturbations \(\{P^{i}_{k+1}\}\), as well as the step-size rule \(\gamma_{k+1}\).

Footnote 1: The _limit set_ of a curve \((c(t))_{t\geq 0}\) in a metric space is \(\cap_{t\geq 0}\operatorname{cl}(c(\{t,\infty\}))\), that is, the set of all limits of convergent sequences \(\{c(t_{k}),\,t_{k}\to\infty\}\).

## 3 Dynamics of Systems of Interacting Particles

This section presents the fundamental master theorem that forms the basis for all the applications discussed in Section 4. Our objectives are two-fold. Firstly, we aim to provide a set of assumptions for the discrete-time scheme that can be easily verified by practical algorithms. Secondly, we establish a set of assumptions on the _mean-field_ dynamics, which, as demonstrated in Section 4, are readily implied by the standard assumptions in the _finite particle_ regime. The key result of our paper asserts that, under these assumptions, any discrete-time scheme converges to its continuous counterpart, thus closing the existing theoretical gap.

### The algorithmic template

In this paper, we study the _stochastic approximation algorithms_ for simulating systems of interacting particles of the form:

\[x^{i}_{k+1}=x^{i}_{k}+\gamma_{k+1}\big{\{}b(x^{i}_{k},\widetilde{\mu}_{k})+P^ {i}_{k+1}\big{\}}+\sqrt{\gamma_{k+1}}\sigma(x^{i}_{k},\widetilde{\mu}_{k})\; \xi^{i}_{k+1},\qquad i=1,\ldots,N,\] (SAA)

where \(b:\mathbb{R}^{d}\times\mathcal{P}_{2}(\mathbb{R}^{d})\to\mathbb{R}^{d}\) is the (non-local) drift,2\(\sigma:\mathbb{R}^{d}\times\mathcal{P}_{2}(\mathbb{R}^{d})\to\mathbb{R}^{d \times d}\) is the (state-dependent and non-local) diffusion coefficient, \(P^{i}_{k+1}\) is the noise and bias in evaluating the drift, and \(\widetilde{\mu}_{k}\) is the empirical measure of the particles at iteration \(k\). The system (SAA) can be written in a more succinct way by stacking all the variables in a larger vector. That is, define \(x\coloneqq(x^{i})_{i\in[N]}\in(\mathbb{R}^{d})^{\otimes N}\), and let \(\mu_{x}\) be the empirical distribution corresponding to the \(N\) vectors in \(x\), and define the _aggregated drift and diffusion terms_ as

Footnote 2: \(\mathcal{P}_{2}(\mathbb{R}^{d})\) is the space of probability measures on \(\mathbb{R}^{d}\) with bounded second moments.

\[\bm{b}(x)\coloneqq(b(x^{i},\mu_{x}))_{i\in[N]}\in(\mathbb{R}^{d})^{\otimes N}, \quad\bm{\sigma}(x)\coloneqq\operatorname{diag}((\sigma(x^{i},\mu_{x}))_{i\in[ N]}).\] (7)

Define \(\{P_{k+1}\}\) and \(\{\xi_{k+1}\}\) analogously. We can then rewrite (SAA) as:

\[x_{k+1}=x_{k}+\gamma_{k+1}\{\bm{b}(x_{k})+P_{k+1}\}+\sqrt{\gamma_{k+1}}\,\bm{ \sigma}(x_{k})\,\xi_{k+1}.\] (PSAA)

### Dynamical system theory

By considering infinitesimal step-sizes and neglecting the perturbations \(P^{i}_{k+1}\), we can derive a system of corresponding SDEs as follows:

\[dX^{i}_{t}=b(X^{i}_{t},\widehat{\mu}_{t})\;dt+\sigma(X^{i}_{t},\widehat{\mu}_{t} )\;dW^{i}_{t},\quad i=1,\ldots,N,\quad\widehat{\mu}_{t}=\tfrac{1}{N}\sum_{i} \delta_{X^{i}_{t}},\] (Sys-SDE)

with the corresponding aggregated version

\[dX_{t}=\boldsymbol{b}(X_{t})\;dt+\boldsymbol{\sigma}(X_{t})\;dW_{t}.\] (PSDE)

It is important to emphasize that even though we have rearranged the particles into a unified vector and introduced the concepts of aggregated drift and diffusion, the original process retains its _exchangeability_. This property implies that the distribution of \(X^{i}_{t}\) in (Sys-SDE) remains invariant under permutations of the particles (for further details, refer to [8, Def. 2.1]).

The primary objective of our paper is to rigorously establish the convergence of the stochastic approximation scheme (PSAA) to its continuous-time counterpart (PSDE). To accomplish this, we employ the _dynamical system_ theory introduced by Benaim and Hirsch [4]. First, we construct a continuous-time _interpolated process_ associated with the discrete-time algorithm (PSAA):

\[X_{t}=x_{k}+(t-\tau_{k})(\boldsymbol{b}(x_{k})+\mathbb{E}[P_{k+1}\mid\mathcal{ F}_{t}])+\boldsymbol{\sigma}(x_{k})(W_{t}-W_{\tau_{k}}),\quad\tau_{k}\leq t< \tau_{k+1}.\] (Int)

Here, \(\tau_{k}=\sum_{j=1}^{k}\gamma_{j}\) represents the cumulative time until step \(k\). It is worth noting that we construct (Int) in such a way that it is adapted to the same filtration \((\mathcal{F}_{t})\) as the Brownian motion.

To compare (PSAA) with (PSDE), we integrate (PSDE) using the following approach: For a fixed \(t\geq 0\), we define \(W^{(t)}_{s}=W_{t+s}-W_{t}\) and denote the solution of (PSDE) as the _flow_:

\[\Phi^{(t)}_{s}=X_{t}+\int_{0}^{s}\boldsymbol{b}(\Phi^{(t)}_{u})\;du+\int_{0}^ {s}\boldsymbol{\sigma}(\Phi^{(t)}_{u})\;dW^{(t)}_{u}.\] (Flow)

It is important to observe that the flow _starts at \(X_{t}\)_ and continues according to the true SDE.

We now introduce the central concept in our paper, which is the _asymptotic pseudotrajectory_ theory of Benaim and Hirsch [4].

**Definition 1** (Wasserstein asymptotic pseudotrajectory).: We say the stochastic process \((X_{t})_{t\geq 0}\) is a _Wasserstein asymptotic pseudotrajectory_ (WAPT) of the flow \(\Phi\) if for any fixed \(T>0\),

\[\lim_{t\to\infty}\sup_{0\leq s\leq T}\mathcal{W}_{2}(X_{t+s},\Phi^{(t)}_{s})=0,\] (8)

where \(\mathcal{W}_{2}(\cdot,\cdot)\) denotes the 2-Wasserstein distance between two distributions.

The notion of WAPT provides a measure of "asymptotic closeness" between two stochastic processes. In particular, (8) requires that \((X_{t})_{t\geq 0}\) closely tracks the flow \(\Phi^{(t)}_{s}\) over arbitrarily long time intervals \(T\) with arbitrary precision. The key aspect of the WAPT is that it serves as a tool specifically designed to establish the convergence of a stochastic approximation scheme to its continuous-time counterparts. In particular, it is known that proving the convergence of a stochastic approximation algorithm (PSAA) to its continuous-time counterparts (PSDE) can be accomplished by demonstrating the following two conditions [3, 4]:

* The interpolation (Int) satisfies the WAPT condition with respect to the corresponding flow.
* The iterates \(\{x_{k}\}_{k}\)'s in (PSAA) have bounded second moments.

Below, we present a set of general conditions that are straightforward to verify and ensure the satisfaction of the above two conditions.

_Remark_.: There are two major reasons for choosing \(\mathcal{W}_{2}\) as the distance in (8): Firstly, the 2-Wasserstein space is a _metric space_ on which McKean-Vlasov equations can be seen as a _flow_, both aspects indispensable for invoking the dynamical system theory of Benaim and Hirsch [3, 4]. Secondly, it is a popular metric in the propagation of chaos literature. This allows a seamless transition from convergence guarantees for stochastic approximation schemes to their mean-field limit counterparts via combining our results with the propagation of chaos results in the literature, see (13).

### Technical Assumptions

We proceed to present our technical assumptions and discuss their generality.

SS On the mean-field dynamics.We begin by introducing three assumptions that pertain to the drift and diffusion coefficients of the continuous-time dynamics (Sys-SDE):

**Assumption 1** (Lipschitzness of drift and diffusion).: _There is some \(L>0\) such that for all \(x,y\in\mathbb{R}^{d}\) and all \(\mu,\nu\in\mathcal{P}_{2}(\mathbb{R}^{d})\),_

\[|b(x,\mu)-b(y,\nu)|+\|\sigma(x,\mu)-\sigma(y,\nu)\|_{F}\leq L(|x-y|+\mathcal{W }_{2}(\mu,\nu)).\]

**Assumption 2** (Drift growth condition).: _For all \(\mu\in\mathcal{P}_{2}(\mathbb{R}^{d})\), there is some \(C_{\nu}>0\) such that_

\[\int\left\langle x,b(x,\mu)\right\rangle\mu(dx)\leq C_{\nu}\int\left(|x|+1 \right)\mu(dx).\]

**Assumption 3** (Boundedness of the diffusion).: _There is some \(K>0\) such that for all \(x\in\mathbb{R}^{d}\) and all \(\mu\in\mathcal{P}_{2}(\mathbb{R}^{d})\), \(\|\sigma(x,\mu)\|_{F}\leq K\)._

We note that the first assumption is standard and is commonly used to prove existence of strong solutions for the mean-field equation (see (26, Thm. 3.3)). The other two assumptions are exceedingly weak and are satisfied by all the applications we consider.

SS On the stochastic approximation schemes.The following assumptions concern the time-discretization scheme and the induced noise and bias.

**Assumption 4** (Noise and bias).: _The perturbation \(P_{k+1}\) decomposes into noise and bias as \(P_{k+1}=U_{k+1}+\varepsilon_{k+1}\), where the noises \(\{U_{k+1}\}\) form a martingale difference sequence, i.e., \(\mathbb{E}[U_{k+1}\,|\,U_{k}]=0\), and have second moments uniformly bounded by \(M_{U}\). In addition, the bias terms satisfy \(\varepsilon_{k}\in\mathcal{F}_{\tau_{k}}\) and_

\[\mathbb{E}[|\varepsilon_{k+1}|^{2}\,|\,\mathcal{F}_{\tau_{k}}]=\mathcal{O}( \gamma_{k+1}^{2}|\bm{b}(x_{k})|^{2}+\gamma_{k+1}).\] (9)

**Assumption 5** (Step-sizes).: _The step-sizes are decreasing and satisfy the Robbins-Monro summability conditions_

\[\sum_{k}\gamma_{k+1}=\infty\quad\text{and}\quad\sum_{k}\gamma_{k+1}^{2}<\infty.\] (10)

_Moreover, we require, for some constant \(P>0\),_

\[\gamma_{k+1}/\gamma_{k}+P\gamma_{k}\gamma_{k+1}\leq 1-\gamma_{k+1}.\] (11)

The condition specified in equation (9) is algorithm-dependent, and as we will prove in Section 4, it is satisfied by numerous practical schemes. In Assumption 5, equation (10) is a commonly used condition in the literature [42], while (11) imposes a mild growth condition on the step size, which remains satisfied even for slowly-decreasing step-sizes such as \(\gamma_{k+1}\sim(\sqrt{k}\,\log k)^{-1}\). Therefore, this condition is not overly restrictive and accommodates a wide range of scenarios.

SS On dissipativity.In the context of dynamical system theory, it is important to ensure that the iterates of stochastic approximation schemes have bounded second moments. In the literature, this requirement is often met by imposing _dissipativity_-type conditions. Building upon this concept, we introduce the following definition:

**Definition 2** (Average Dissipativity).: We call the drift \(b\) to be _\((\alpha,\beta)\)-dissipative on average_ for some \(\alpha>0\) and \(\beta\in\mathbb{R}\), if for all probability measures \(\mu\in\mathcal{P}_{2}(\mathbb{R}^{d})\), it holds

\[\int\left\langle x,b(x,\mu)\right\rangle\mu(dx)\leq-\alpha\int|x|^{2}\,\mu(dx) +\beta.\]

The concept of average dissipativity, as introduced in Definition 2, provides a novel formulation specifically designed to capture the dissipativity property of a drift function that depends on _measures_, as in equation (Sys-SDE). In contrast to the traditional notion of dissipativity [19], which focuses on the dissipative behavior of _individual_ particles in isolation, this formulation allows for a more fine-grained control over the _collective_ behavior exhibited by \(N\) particles, each running in parallel with the same stochastic approximation scheme. In Section 4, we will provide concrete examples from the applications of machine learning to demonstrate the satisfaction of average dissipativity.

### Main Results

We are now ready to state our main theorem, whose proof can be found in Appendix B.

**Theorem 1**.: _Consider the algorithm (SAA), where the drift \(b\) and diffusion \(\sigma\) satisfy Assumptions 1-3, and the step-sizes \(\{\gamma_{k+1}\}\) and the perturbations \(\{P^{i}_{k+1}\}\) satisfy Assumptions 4 and 5. Then the following holds:_

* _The interpolation (_Int_) of iterates of the algorithm is a WAPT of the flow in (_Flow_)._
* _Moreover, if the drift_ \(b\) _is dissipative on average (see Definition_ 2_), the iterates of (_PSAA_) are bounded in second moments, and their limit set is included in that of the original SDE (_PSDE_)._

Proof sketch.: The main step of the proof is the construction of the _Picard process_, which is inspired by [23] and defined as follows:

\[\Pi_{s}^{(t)}=X_{t}+\int_{0}^{s}\bm{b}(X_{t+u})\,du+\int_{0}^{s}\sigma(X_{t+u}) \,dW_{u}^{(t)}\,.\] (Picard)

The proof is completed in four steps: first, we prove that the Picard process closely tracks the flow (Flow), and then we bound the distance between the Picard process and the interpolation (Int). By using martingale convergence arguments, employing our assumption on bias Assumption 4, and Gronwall inequality, we conclude the proof of the WAPT property. Lastly, we show that dissipativity on average ensures a uniform bound on the second moments of the iterates. The convergence is then implied by invoking [23, Theorem 3]. 

In summary, according to Theorem 1, the convergence of the stochastic approximation scheme in (SAA) can be reduced to its continuous-time counterpart in (Sys-SDE) when the assumptions stated in Section 3.3 are satisfied.

Our Theorem 1 can be combined with existing results in the finite particle regime to establish the overall convergence towards the desired mean-field limit. To see this, let \(M_{t}^{i,N}\) be \(N\) independent processes, synchronously coupled with (Sys-SDE), each starting from \(X_{0}^{i}\) and following

\[dM_{t}^{i,N}=b(M_{t}^{i,N},\mu_{t})\,dt+\sigma(M_{t}^{i,N},\mu_{t})\,dW_{t}^{i,N}\,,\]

where \(\mu_{t}\) is the _mean-field solution_. A common phenomenon in the study of interacting particle systems, known as _uniform propagation of chaos_[8, 22, 27, 47], implies the existence of a constant \(C\) such that for every \(N\):

\[\sup_{t\geq 0}\tfrac{1}{N}\sum_{i=1}^{N}\mathcal{W}_{2}^{2}(X_{t}^{i,N},M_{t}^ {i,N})\leq\tfrac{C}{N},\] (12)

where \(X_{t}^{i,N}\) represents the particles following the continuous-time dynamics in (Sys-SDE). Letting \(\mu_{\infty}\) represent the limit of the mean-field equation, a straightforward application of the triangle inequality argument, which we defer to Appendix B.2, yields:

\[\lim_{k\to\infty}\tfrac{1}{N}\sum_{i=1}^{N}\mathcal{W}_{2}^{2}(x_{k}^{i},\mu_ {\infty})\leq\tfrac{C}{N}\to 0\quad\text{as}\quad N\to\infty.\] (13)

In other words, as the number of particles approaches infinity, the law of the empirical distribution of the particles following the discrete-time algorithm (SAA) also converges to the mean-field solution.

SS A note on the literature.The rich body of literature on McKean-Vlasov SDEs and interacting particle systems offers considerable insights on the convergence of Euler-Maruyama and Milstein type numerical schemes to their limiting mean-field equations, e.g., [2, 28, 41]. However, it is noteworthy that our study diverges in several key respects: Firstly, our work emphasizes on generic _stochastic_ and _biased_ drift oracles. This contrasts with the deterministic and unbiased drift oracles considered in the aforementioned studies, making our algorithmic approach broader in scope. Secondly, while those studies present strong finite-time error bounds, our convergence results focus on providing asymptotic guarantees. Lastly, we incorporate different underlying assumptions. For instance, we need global Lipschitz drifts to ensure globally integrable flows, while one-sided Lipschitz drifts are allowed in the works by [2, 41, 28]. However, our growth condition in Assumption 2 requires control on average, whereas the works mentioned assume stronger pointwise controls.

In the light of these distinctions, we believe that our work complements this body of literature.

Applications

The goal of this section is to demonstrate the wide-ranging applicability of our framework across diverse domains such as machine learning, game theory, and physics, which were previously analyzed in isolation. In each of these applications, we demonstrate that standard assumptions in their respective domains meet the necessary conditions to invoke Theorem 1. All proofs are deferred to Appendix C.

### Two-Layer Neural Networks and Mean-Field Langevin

Our first application is providing a rigorous guarantee for the training dynamics of wide two-layer neural networks as alluded to in Section 2. To begin, let us quickly recall the notations therein: The noisy SGD iterates in (SGD\({}_{\sigma}\)) for wide two-layer neural networks can be viewed as approximations of the mean-field dynamics (6) through the discrete-time system (SAA), whose drift term \(b(\cdot,\cdot)\) is defined in (1). The corresponding continuous-time and finite-particle dynamics is (5), which has been extensively studied in recent years; see [11; 12; 36; 37; 38; 46; 51] and references therein. Under the standard assumptions as in [11; 12; 37], a simple application of Theorem 1 then yields the convergence of (SGD\({}_{\sigma}\)):

**Corollary 1**.: _Let \(\kappa(\cdot)\) denote the activation function. Assume that (1) \(\kappa\) and \(\kappa^{\prime}\) are Lipschitz and bounded, (2) the data has bounded support, and (3) \(|a\,\kappa^{\prime}(a)|\) is bounded. Then the discrete-time scheme (SGD\({}_{\sigma}\)) converges in \(\mathcal{W}_{2}\) to the same limit sets as the continuous-time (5)._

The mean-field dynamics for two-layer neural networks converges to a stationary point in Wasserstein space due to its gradient flow structure [12]. In addition, it is known that under fairly mild assumptions, the resulting limit becomes a unique _global_ risk minimizer [12]. By employing uniform propagation of chaos for neural networks [46], it is observed that the limit sets of the continuous-time \(N\)-particle dynamics exhibit similar generalization error to the global minimizer. Remarkably, Corollary 1 validates that noisy SGD and other discretizations following template (SAA) eventually converge to this limit set, providing justification for the observed generalization behavior in neural networks.

SS Comparison to prior work.Our result above cannot be directly compared to the existing analysis conducted on the discrete-time scheme (SGD\({}_{\sigma}\)), namely [37], due to the assumption A1 therein, which excludes step-size rules of the form \(\gamma_{k+1}\sim k^{-\beta}\) where \(\beta\in(1/2,1]\). Conversely, the bounds provided in [37] for a _constant_ step-size are non-asymptotic (albeit doubly-exponential), resulting in stronger conclusions compared to our asymptotic results. Therefore, these two analyses complement each other and contribute to a more comprehensive understanding of the training dynamics exhibited by neural networks.

### Stein Variational Gradient Descent

Sampling from a distribution \(\pi\propto e^{-V}\) is a crucial task in various machine learning applications. An effective method that has demonstrated practical success in this regard is the _Stein variational gradient descent_ (SVGD) [29; 30]. Intuitively, this method emulates the steepest descent for the KL divergence in _continuous-time_ with a _continuous probability measure_. In practice, the algorithm is implemented as an interacting particle system as follows (see [33] for a derivation). Let \(K:\mathbb{R}^{d}\times\mathbb{R}^{d}\to\mathbb{R}\) be a _positive definite kernel_. The SVGD algorithm updates the set of \(N\) particles as

\[x_{k+1}^{i}=x_{k}^{i}-\tfrac{\gamma_{k+1}}{N}\sum_{j=1}^{N}\left(K(x_{k}^{i},x _{k}^{j})\nabla V(x_{k}^{j})-\nabla_{2}K(x_{k}^{i},x_{k}^{j})\right),\qquad i =1,\ldots,N,\] (SVGD \[{}_{k}\] )

where \(\nabla_{2}K\) is the gradient of \(K\) with respect to its second input. The corresponding continuous-time dynamics is then:

\[\tfrac{d}{dt}X_{t}^{i}=\tfrac{1}{N}\sum_{j}\nabla_{2}K(X_{t}^{i},X_{t}^{j})- \tfrac{1}{N}\sum_{j}K(X_{t}^{i},X_{t}^{j})\nabla V(X_{t}^{j}),\qquad i=1, \ldots,N,\] (SVGD \[{}_{t}\] )

which is a special case of (Sys-SDE) with \(b(x,\mu)=(\nabla_{2}K*\mu)(x)-(K*(\mu\nabla V))(x)\) and \(\sigma\equiv 0\) (no diffusion), where \(*\) denotes the convolution operator. We now prove:

**Corollary 2**.: _Suppose that (1) \(\nabla V(x)\) is Lipschitz, (2) \(V\) is dissipative,3 (3) for some \(C>0\), \(|\nabla V(x)|\leq C(1+|x|^{2})\), (4) \(\|K\|_{\infty},\|\nabla_{2}K\|_{\infty},\|\nabla^{2}K\|_{\infty}<\infty\), (5) \(|\nabla_{2}K(x,y)|\leq\eta/|x-y|\), and (6) \(K(x,y)\leq\eta/|x-y|^{2}\) for some \(\eta>0\). Then the iterates in (SVGD\({}_{k}\)) converge in \(\mathcal{W}_{2}\) to the same limit sets as the continuous-time process (SVGD\({}_{t}\))._

Footnote 3: That is, \(\exists\,m>0\), \(m^{\prime}\in\mathbb{R}\) such that \(\langle x,\nabla V(x)\rangle\geq m|x|^{2}-m^{\prime}\).

Similar to neural networks training discussed in Section 4.1, the mean-field SVGD also exhibits a gradient flow structure, and in this case, the target distribution \(\pi\) serves as the only limit set for the mean-field SVGD [29]. Combining Corollary 2 with a uniform propagation of chaos argument for SVGD then confirms that the iterates of (SVGD\({}_{k}\)), or any discretization of (SVGD\({}_{t}\)) that satisfies Assumption 4, effectively converge to a distribution that closely approximates \(\pi\) in terms of \(\mathcal{W}_{2}\). This outcome underscores the effectiveness of these algorithms in sampling.

SS Comparison to prior work.While there has been extensive theoretical work on the convergence of SVGD, most of it focuses on either the _population limit_ (i.e., when \(N\to\infty\) in (SVGD\({}_{k}\))) or the _vanishing step-size_ (which directly examines the properties of (SVGD\({}_{t}\))) [10; 14; 25; 29; 43; 45]. However, the convergence behavior of the discrete iterates (SVGD\({}_{k}\)) remains a challenging task with limited success. To the best of our knowledge, the only existing work in this direction is [44], but its result is not directly comparable to ours. Although our assumptions on the bounded derivatives of \(V\) and \(W\) are similar to those in [44], the difference lies in the requirement imposed on the target distribution \(e^{-V}\). Specifically, Shi and Mackey [44] assume a T1-inequality on \(e^{-V}\)[50], whereas our work requires \(V\) to be dissipative. Notably, our approach holds a significant advantage over [44] in terms of simplicity: The result of [44] is only applicable to a highly specific and fairly complicated step-size rule (see [44, Cor 2]), whereas our sole requirement on \(\gamma_{k+1}\) is the standard Assumption 5. However, it should be noted that the bounds in [44] are _non-asymptotic_ (albeit doubly-exponential in \(N\) and exponential in \(k\)), while we can only handle asymptotic convergence.

_Remark_.: It is worth mentioning that Corollary 2 can be straightforwardly extended to the _Stochastic Particle-Optimization Sampling_ algorithm of Zhang et al. [53], which is identical to SVGD but includes a constant diffusion term \(\sigma>0\). Since the analysis remains the same, we omit the details.

### Two-Player Zero-sum Continuous Games

Min-max learning appears in several important machine learning tasks such as Generative Adversarial Networks [18] and adversarial training [35]. These learning problems can be formulated as a continuous zero-sum game between a min-player and a max-player. The min-player selects strategies from the set \(\mathcal{X}\subset\mathbb{R}^{d}\), while the max-player selects strategies from the set \(\mathcal{Y}\subset\mathbb{R}^{d}\), with the goal of finding a saddle point of a function \(K(x,y)\):

\[\min_{x\in\mathcal{X}}\max_{y\in\mathcal{Y}}K(x,y).\] (14)

However, solving (14) becomes challenging and sometimes impossible when \(K\) is non-convex in \(x\) and non-concave in \(y\), as a solution to (14) may not even exist. To address this issue, _mixed Nash equilibriums_ (MNEs) are introduced, where the pure strategies are replaced by probability distributions over the sets of strategies, which exist under mild assumptions on \(K\)[13; 17].

Specifically, an MNE is represented by a pair of measures \((\mu^{\star},\nu^{\star})\in\mathcal{P}_{2}(\mathcal{X})\times\mathcal{P}_{2} (\mathcal{Y})\), forming a saddle point of the functional \(E(\mu,\nu)\coloneqq\iint\limits K(x,y)\mu(dx)\nu(dy)\). The quest for efficient solutions to the MNE problem in machine learning has led to the development of particle-based methods that offer approximate solutions [13; 20; 34]. However, the existing studies have primarily focused on analyzing the _continuous-time_ dynamics of these methods. Below, we shift our focus to the more practical setting of the _discrete-time_ system of interacting particles in these work:

\[\begin{cases}x^{i}_{k+1}=x^{i}_{k}-\gamma_{k+1}\frac{1}{N}\sum_{j}\nabla_{x}K (x^{i}_{k},y^{j}_{k})+\sqrt{2\tau\gamma_{k+1}}\xi^{i}_{k+1}\\ y^{j}_{k+1}=y^{j}_{k}+\alpha\gamma_{k+1}\frac{1}{N}\sum_{j}\nabla_{y}K(x^{j}_{ k},y^{j}_{k})+\sqrt{2\alpha\tau\gamma_{k+1}}\,\zeta^{i}_{k+1}\end{cases},\] (GDA \[{}_{k}\] )

where \(\xi^{i}_{k+1}\) and \(\zeta^{i}_{k+1}\) are independent standard Gaussians, \(\tau>0\) is a hyperparameter chosen by the user, and \(\alpha\) is the _scale_ difference between the two players [34]. We will additionally consider the _optimistic_ version of (GDA\({}_{k}\)) in [20], which has shown empirical benefits over (GDA\({}_{k}\)):

\[\begin{cases}x^{i}_{k+1}=x^{i}_{k}-\gamma_{k+1}\frac{1}{N}\sum_{j}\left(2 \nabla_{x}K(x^{i}_{k},y^{j}_{k})-\nabla_{x}K(x^{i}_{k-1},y^{j}_{k-1})\right)+ \sqrt{2\tau\gamma_{k+1}}\,\xi^{i}_{k+1}\\ y^{j}_{k+1}=y^{j}_{k}+\alpha\gamma_{k+1}\frac{1}{N}\sum_{j}\left(2\nabla_{y}K( x^{j}_{k},y^{j}_{k})-\nabla_{y}K(x^{j}_{k-1},y^{j}_{k-1})\right)+\sqrt{2\alpha\tau \gamma_{k+1}}\,\zeta^{i}_{k+1}.\end{cases}\] (OGDA \[{}_{k}\] )

At first glance, it may seem that (GDA\({}_{k}\)) and (OGDA\({}_{k}\)) are distinct algorithms that cannot be analyzed together. However, our subsequent corollary reveals that these systems actually converge to the _same_continuous-time dynamics:

\[\begin{cases}dX_{t}^{i}=-\frac{1}{N}\,\sum_{j}\nabla_{x}K(X_{t}^{i},Y_{t}^{j})\,dt+ \sqrt{2\tau}dW_{t}^{i}\\ \par M_{t}^{j}=\frac{\alpha}{N}\sum_{j}\nabla_{y}K(X_{t}^{j},Y_{t}^{j})\,dt+ \sqrt{2\alpha\tau}dB_{t}^{i}\end{cases},\] (GDA \[{}_{t}\] )

where \(W_{t}^{i}\) and \(B_{t}^{j}\) are collections of i.i.d. Brownian motions. The key enabling factor for this unified treatment is to allow for a _non-zero bias_ in the algorithmic template (SAA).

To facilitate the analysis, we introduce a pairing of players' particles by setting \(Q_{t}^{i}\coloneqq(X_{t}^{i},Y_{t}^{i})\in\mathbb{R}^{2d}\), and define the drift \(b:\mathbb{R}^{2d}\times\mathcal{P}_{2}(\mathbb{R}^{2d})\to\mathbb{R}^{2d}\) as

\[b(q,\mu)\coloneqq\int\begin{pmatrix}-\nabla_{x}K(q_{1},q_{2}^{\prime})\\ \alpha\,\nabla_{y}K(q_{1}^{\prime},q_{2})\end{pmatrix}\,\mu(dq^{\prime}), \quad q=(q_{1},q_{2}),\]

and the diffusion \(\sigma(q,\mu)\coloneqq\sqrt{2\tau}\operatorname{diag}(I_{d\times d},\sqrt{ \alpha}\,I_{d\times d})\). By doing so, we can then cast (GDA\({}_{t}\)) in template of (Sys-SDE).

**Corollary 3**.: _Assume that (1) \(\nabla_{x}K\) and \(\nabla_{y}K\) are Lipschitz, and (2) \(\nabla_{x}K\) and \(-\nabla_{y}K\) are dissipative, or (2') the domains \(\mathcal{X}\) and \(\mathcal{Y}\) are bounded. Then the algorithms (GDA\({}_{k}\)) and (OGDA\({}_{k}\)) converge in \(\mathcal{W}_{2}\) to the same limits of (GDA\({}_{t}\))._

We note that the assumptions in (3) are mild and are even required for analysing the _continuous-time_ dynamics; see e.g., [34]. Consequently, our Corollary 3 provides a rigorous foundation for the consideration of continuous-time dynamics in existing studies such as [13; 20; 34].

_Remark_.: The schemes (GDA\({}_{k}\)) and (OGDA\({}_{k}\)) above rely on _simultaneous_ updates, i.e., from \((x_{k},y_{k})\), one obtains \((x_{k+1},y_{k+1})\). However, empirical evidence suggests that _alternating_ updates i.e., following \((x_{k},y_{k})\to(x_{k+1},y_{k})\to(x_{k+1},y_{k+1})\), often preforms better. Our framework allows for this flexibility, as it is easy to cast the alternating (GDA\({}_{k}\)) and (OGDA\({}_{k}\)) as stochastic approximation schemes satisfying Assumption 4, see [24, Proposition 4] for an example of this argument.

### Kinetic Equations

In this section, we study the _kinetic equations_ defined on the space of probability measures. Initially emerging from the physics community, these equations have recently gained attention in the machine learning community due to their connection to _Wasserstein gradient flows_[15; 32; 39; 40; 48; 49; 52]. Here, we denote \(\rho\) as a probability density, and we examine three distinct "energy" functionals: an internal energy \(\mathcal{U}\), a potential energy \(\mathcal{V}\), and an interaction energy \(\mathcal{W}\). These functionals are defined as follows:

\[\mathcal{U}(\rho)=\int U(\rho(x))\,dx,\quad\mathcal{V}(\rho)=\int\mathcal{V}(x )\,\rho(dx),\quad\mathcal{W}(\rho)=\tfrac{1}{2}\iint W(x-y)\,\rho(dx)\rho(dy).\] (15)

The most interesting scenario is when \(U(s)=s\log s\) represents the _entropy_, in which case the Wasserstein gradient flow with finite particles becomes [5; 7]:

\[dX_{t}^{i}=-\nabla V(X_{t}^{i})\,dt-\tfrac{1}{N}\,\sum_{j=1}^{N}\nabla W(X_{t} ^{i}-X_{t}^{j})\,dt+\sqrt{2}\,dW_{t}^{i},\quad i=1,\ldots,N.\] (Kin-SDE)

By setting \(b(x,\mu)\coloneqq-\nabla V(x)-(\nabla W*\mu)(x)\) and \(\sigma(x,\mu)\equiv\sqrt{2}\), we again see that (Kin-SDE) is a special case of (Sys-SDE).

In the physics community, the equation is commonly simulated using a system of interacting particles through the _proximal point method_[6; 48]:

\[x_{k+1}^{i}=x_{k}^{i}-\gamma_{k+1}\Big{(}\nabla V(x_{k+1}^{i})+\tfrac{1}{N}\, \sum_{j=1}^{N}\nabla W(x_{k+1}^{i}-x_{k}^{j})\Big{)}+\sqrt{2\gamma_{k+1}}\, \xi_{k+1}^{i}.\] (Kin-Prox)

Note that the right-hand side of (Kin-Prox) involves the next iterates \(x_{k+1}^{i}\) so that, as opposed to the simple Euler discretization, it is an _implicit_ rule. The key factor that enables the application of our framework to these implicit schemes is the observation that (Kin-Prox) can be formulated as a stochastic approximation scheme in (SAA) by incorporating a _non-zero bias_ term; see Appendix C. Our next result provides a rigorous guarantee for these methods:

**Corollary 4**.: _Assume that (1) \(V\) is dissipative and \(\nabla V\) is \(L\)-Lipschitz, (2) \(W\) is symmetric and \(\nabla W\) is \(L\)-Lipschitz, (3) There exists some \(M_{W}\geq 0\) such that for all \(x,y\in\mathbb{R}^{d}\), \(\langle\nabla W(x)-\nabla W(y),x-y\rangle\geq-M_{W}\). Then, the iterates (Kin-Prox) converge in \(\mathcal{W}_{2}\) to the same limit sets as (Kin-SDE)._We remark that the convergence of (Kin-Prox) under these standard assumptions is known [15; 48]. However,we emphasize that the aforementioned results only apply to _deterministic_ updates, while our proof is robust enough to accommodate updates with _finite-variance noise_. This flexibility sets our approach apart, allowing for a broader range of practical applications.

## 5 Conclusion and Future Directions

In conclusion, our work has successfully bridged the gap between continuous- and discrete-time schemes by establishing the convergence of discrete-time algorithms to their continuous-time counterparts, drawing inspiration from dynamical system theory. This achievement offers a flexible framework that can accommodate practical schemes and unify tasks from various domains, including machine learning, game theory, and physics. By introducing a comprehensive framework for analyzing stochastic approximation schemes, providing convergence proofs, and presenting easily verifiable conditions at the finite particle level, our contributions enhance the understanding and application of stochastic approximation schemes for simulating interacting particle systems.

In our future works, we will explore the exciting possibilities offered by the dynamical system theory of [4] to derive convergence rates through \(\lambda\)-pseudotrajectories. This avenue of research will allow us to establish exponential convergence for dynamics using smaller step-sizes after a "burn-in" time, thereby sharpening our understanding for the long-term behavior of these practical schemes.

Additionally, we aim to relax the Lipschitzness assumption on the drift and expand the scope of guaranteed algorithms, such as the Ensemble Kalman Sampler [16]. We also aim to explore further applications in natural sciences, including stochastic mean-field FitzHugh-Nagumo models and networks of Hodgkin-Huxley neurons [1]. These models are important because they provide a mathematical description of neuronal dynamics, contribute to our understanding of neurological disorders, and inform the development of brain-computer interfaces. By leveraging our novel framework, we hope to offer rigorous guarantees for the algorithms employed in these domains while also designing new, efficient approaches that can support computational neuroscience research.

## Acknowledgments and Disclosure of Funding

This work was supported by the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation program grant agreement No 815943. YPH acknowledges funding through an ETH Foundations of Data Science (ETH-FDS) postdoctoral fellowship.

## References

* [1] Javier Baladron, Diego Fasoli, Olivier Faugeras, and Jonathan Touboul. Mean Field description of and propagation of chaos in recurrent multipopulation networks of Hodgkin-Huxley and Fitzhugh-Nagumo neurons, October 2011.
* [2] Jianhai Bao, Christoph Reisinger, Panpan Ren, and Wolfgang Stockinger. First-order convergence of milstein schemes for McKean-vlasov equations and interacting particle systems. _Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences_, 477 (2245), January 2021. doi: 10.1098/rspa.2020.0258. URL https://doi.org/10.1098/rspa.2020.0258.
* [3] Michel Benaim. Dynamics of stochastic approximation algorithms. In _Seminaire de probabilites XXXIII_, pages 1-68. Springer, 2006.
* [4] Michel Benaim and Morris W Hirsch. Asymptotic pseudotrajectories and chain recurrent flows, with applications. _Journal of Dynamics and Differential Equations_, 8(1):141-176, 1996.
* [5] Dario Benedetto, Emanuelle Caglioti, Jose A Carrillo, and Mario Pulvirenti. A non-maxwellian steady distribution for one-dimensional granular media. _Journal of statistical physics_, 91:979-990, 1998.
* [6] Lev M Bregman. The relaxation method of finding the common point of convex sets and its application to the solution of problems in convex programming. _USSR computational mathematics and mathematical physics_, 7(3):200-217, 1967.

* Cattiaux et al. [2006] Patrick Cattiaux, Guillin Arnaud, and Malrieu Florent. Probabilistic approach for granular media equations in the non uniformly convex case, March 2006.
* Chaintron and Diez [2022] Louis-Pierre Chaintron and Antoine Diez. Propagation of chaos: a review of models, methods and applications. i. models and methods. _Kinetic and Related Models_, 2022. doi: 10.3934/krm.2022017.
* Chaintron and Diez [2022] Louis-Pierre Chaintron and Antoine Diez. Propagation of chaos: A review of models, methods and applications. II. Applications. _Kinetic and Related Models_, 15(6):1017, 2022. ISSN 1937-5093, 1937-5077. doi: 10.3934/krm.2022018.
* Chewi et al. [2020] Sinho Chewi, Thibaut Le Gouic, Chen Lu, Tyler Maunu, and Philippe Rigollet. Svgd as a kernelized wasserstein gradient flow of the chi-squared divergence. _Advances in Neural Information Processing Systems_, 33:2098-2109, 2020.
* Chizat [2022] Lenaic Chizat. Mean-field langevin dynamics: Exponential convergence and annealing. _Transactions on Machine Learning Research_, 2022.
* Chizat and Bach [2018] Lenaic Chizat and Francis Bach. On the Global Convergence of Gradient Descent for Over-parameterized Models using Optimal Transport. In _Advances in Neural Information Processing Systems_, volume 31. Curran Associates, Inc., 2018.
* Domingo-Enrich et al. [2021] Carles Domingo-Enrich, Samy Jelassi, Arthur Mensch, Grant Rotskoff, and Joan Bruna. A mean-field analysis of two-player zero-sum games, May 2021.
* Duncan et al. [2019] Andrew Duncan, Nikolas Nusken, and Lukasz Szpruch. On the geometry of stein variational gradient descent. _arXiv preprint arXiv:1912.00894_, 2019.
* Durmus et al. [2020] Alain Durmus, Andreas Eberle, Arnaud Guillin, and Raphael Zimmer. An elementary approach to uniform in time propagation of chaos. _Proceedings of the American Mathematical Society_, 148(12):5387-5398, 2020.
* Garbuno-Inigo et al. [2020] Alfredo Garbuno-Inigo, Franca Hoffmann, Wuchen Li, and Andrew M Stuart. Interacting langevin diffusions: Gradient structure and ensemble kalman sampler. _SIAM Journal on Applied Dynamical Systems_, 19(1):412-441, 2020.
* Glicksberg [1952] Irving L Glicksberg. A further generalization of the kakutani fixed theorem, with application to nash equilibrium points. _Proceedings of the American Mathematical Society_, 3(1):170-174, 1952.
* Goodfellow et al. [2020] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial networks. _Communications of the ACM_, 63(11):139-144, 2020.
* Hale [1988] Jack K. Hale. _Asymptotic Behavior of Dissipative Systems_. American Mathematical Society, 1988.
* Hsieh et al. [2019] Ya-Ping Hsieh, Chen Liu, and Volkan Cevher. Finding mixed nash equilibria of generative adversarial networks. In _International Conference on Machine Learning_, pages 2810-2819, 2019.
* Hsieh et al. [2021] Ya-Ping Hsieh, Panayotis Mertikopoulos, and Volkan Cevher. The limits of min-max optimization algorithms: Convergence to spurious non-critical sets. In _International Conference on Machine Learning_, pages 4337-4348. PMLR, 2021.
* Kac [1956] M. Kac. Foundations of Kinetic Theory. In _Proceedings of the Third Berkeley Symposium on Mathematical Statistics and Probability, Volume 3: Contributions to Astronomy and Physics_, volume 3.3, pages 171-198. University of California Press, January 1956.
* Karimi et al. [2022] Mohammad Reza Karimi, Ya-Ping Hsieh, and Andreas Krause. A dynamical system view of langevin-based non-convex sampling. _arXiv preprint arXiv:2210.13867_, 2022.
* Karimi et al. [2022] Mohammad Reza Karimi, Ya-Ping Hsieh, Panayotis Mertikopoulos, and Andreas Krause. The dynamics of Riemannian Robbins-Monro algorithms. In _COLT 2022-35th Annual Conference on Learning Theory_, pages 1-31, 2022.

* Korba et al. [2020] Anna Korba, Adil Salim, Michael Arbel, Giulia Luise, and Arthur Gretton. A non-asymptotic analysis for stein variational gradient descent. _Advances in Neural Information Processing Systems_, 33:4672-4682, 2020.
* Lacker [2018] Daniel Lacker. Mean field games and interacting particle systems. _preprint_, 2018.
* Lacker and Flem [2023] Daniel Lacker and Luc Le Flem. Sharp uniform-in-time propagation of chaos. _Probability Theory and Related Fields_, February 2023. ISSN 1432-2064. doi: 10.1007/s00440-023-01192-x.
* Leobacher et al. [2022] Gunther Leobacher, Christoph Reisinger, and Wolfgang Stockinger. Well-posedness and numerical schemes for one-dimensional McKean-vlasov equations and interacting particle systems with discontinuous drift. _BIT Numerical Mathematics_, 62(4):1505-1549, May 2022. doi: 10.1007/s10543-022-00920-4. URL https://doi.org/10.1007/s10543-022-00920-4.
* Liu [2017] Qiang Liu. Stein Variational Gradient Descent as Gradient Flow, November 2017.
* Liu and Wang [2016] Qiang Liu and Dilin Wang. Stein variational gradient descent: A general purpose bayesian inference algorithm. _Advances in neural information processing systems_, 29, 2016.
* Liu and Wang [2019] Qiang Liu and Dilin Wang. Stein Variational Gradient Descent: A General Purpose Bayesian Inference Algorithm, September 2019.
* Liu et al. [2021] Wei Liu, Liming Wu, and Chaoen Zhang. Long-Time Behaviors of Mean-Field Interacting Particle Systems Related to McKean-Vlasov Equations. _Communications in Mathematical Physics_, 387(1):179-214, October 2021. ISSN 1432-0916. doi: 10.1007/s00220-021-04198-5.
* Lu et al. [2019] Jianfeng Lu, Yulong Lu, and James Nolen. Scaling limit of the stein variational gradient descent: The mean field regime. _SIAM Journal on Mathematical Analysis_, 51(2):648-671, 2019.
* Lu [2023] Yulong Lu. Two-Scale Gradient Descent Ascent Dynamics Finds Mixed Nash Equilibria of Continuous Games: A Mean-Field Perspective, January 2023.
* Madry et al. [2017] Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. Towards deep learning models resistant to adversarial attacks. _arXiv preprint arXiv:1706.06083_, 2017.
* Mei et al. [2018] Song Mei, Andrea Montanari, and Phan-Minh Nguyen. A mean field view of the landscape of two-layer neural networks. _Proceedings of the National Academy of Sciences_, 115(33):E7665-E7671, 2018.
* Mei et al. [2019] Song Mei, Theodor Misiakiewicz, and Andrea Montanari. Mean-field theory of two-layers neural networks: Dimension-free bounds and kernel limit, February 2019.
* Nitanda et al. [2022] Atsushi Nitanda, Denny Wu, and Taiji Suzuki. Convex Analysis of the Mean Field Langevin Dynamics. In _Proceedings of The 25th International Conference on Artificial Intelligence and Statistics_, pages 9741-9757. PMLR, May 2022.
* Otto [2001] Felix Otto. The geometry of dissipative evolution equations: the porous medium equation. _Communications in Partial Differential Equations_, 26(1-2):101-174, 2001. doi: 10.1081/PDE-100002243.
* Peyre et al. [2019] Gabriel Peyre, Marco Cuturi, et al. Computational optimal transport: With applications to data science. _Foundations and Trends(r) in Machine Learning_, 11(5-6):355-607, 2019.
* Reisinger and Stockinger [2022] Christoph Reisinger and Wolfgang Stockinger. An adaptive euler-maruyama scheme for McKean-vlasov SDEs with super-linear growth and application to the mean-field FitzHugh-nagumo model. _Journal of Computational and Applied Mathematics_, 400:113725, January 2022. doi: 10.1016/j.cam.2021.113725. URL https://doi.org/10.1016/j.cam.2021.113725.
* Robbins and Monro [1951] Herbert Robbins and Sutton Monro. A stochastic approximation method. _The annals of mathematical statistics_, pages 400-407, 1951.
* Salim et al. [2022] Adil Salim, Lukang Sun, and Peter Richtarik. A convergence theory for svgd in the population limit under talagrand's inequality t1. In _International Conference on Machine Learning_, pages 19139-19152. PMLR, 2022.

* Shi and Mackey [2022] Jiaxin Shi and Lester Mackey. A finite-particle convergence rate for stein variational gradient descent. _CoRR_, abs/2211.09721, 2022. doi: 10.48550/arXiv.2211.09721. URL https://doi.org/10.48550/arXiv.2211.09721.
* Sun et al. [2023] Lukang Sun, Avetik Karagulyan, and Peter Richtarik. Convergence of stein variational gradient descent under a weaker smoothness condition. In _International Conference on Artificial Intelligence and Statistics_, pages 3693-3717. PMLR, 2023.
* Suzuki et al. [2023] Taiji Suzuki, Atsushi Nitanda, and Denny Wu. Uniform-in-time propagation of chaos for the mean-field gradient Langevin dynamics. In _ICLR_, 2023.
* Sznitman [1991] Alain-Sol Sznitman. Topics in propagation of chaos. In Donald L. Burkholder, Etienne Pardoux, Alain-Sol Sznitman, and Paul-Louis Hennequin, editors, _Ecole d'Ete de Probabilites de Saint-Flour XIX -- 1989_, Lecture Notes in Mathematics, pages 165-251, Berlin, Heidelberg, 1991. Springer. ISBN 978-3-540-46319-1. doi: 10.1007/BFb0085169.
* Vazquez [2007] Juan Luis Vazquez. _The porous medium equation: mathematical theory_. Oxford University Press on Demand, 2007.
* Villani [2003] Cedric Villani. _Topics in optimal transportation_. Number 58. American Mathematical Soc., 2003.
* Villani [2008] Cedric Villani. _Optimal transport: old and new_, volume 338. Springer Science & Business Media, 2008.
* Woodworth et al. [2020] Blake Woodworth, Suriya Gunasekar, Jason D Lee, Edward Moroshko, Pedro Savarese, Itay Golan, Daniel Soudry, and Nathan Srebro. Kernel and rich regimes in overparametrized models. In _Conference on Learning Theory_, pages 3635-3673. PMLR, 2020.
* Yao et al. [2022] Rentian Yao, Xiaohui Chen, and Yun Yang. Mean-field nonparametric estimation of interacting particle systems. In _Conference on Learning Theory_, pages 2242-2275. PMLR, 2022.
* Zhang et al. [2020] Jianyi Zhang, Ruiyi Zhang, Lawrence Carin, and Changyou Chen. Stochastic Particle-Optimization Sampling and the Non-Asymptotic Convergence Theory. In _Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics_, pages 1877-1887. PMLR, June 2020.
* Zhang et al. [2020] Kelvin Shuangjian Zhang, Gabriel Peyre, Jalal Fadili, and Marcelo Pereyra. Wasserstein Control of Mirror Langevin Monte Carlo. _arXiv:2002.04363 [cs, math, stat]_, February 2020.

Properties of Mean-field Transfer to Particle System

**Lemma A.1**.: _The Assumptions 1-3 transfer seamlessly to the aggregated notions of drift and diffusion given in (7):_

1. _If_ \(b(\cdot,\cdot)\) _and_ \(\sigma(\cdot,\cdot)\) _satisfy Assumption_ 1_, then_ \(\bm{b}(\cdot)\) _and_ \(\bm{\sigma}(\cdot)\) _are_ \(L(\sqrt{N}+1)\)_-Lipschitz._
2. _If_ \(b(\cdot,\cdot)\) _satisfies Assumption_ 2_, then_ \(\bm{b}(\cdot)\) _satisfies the same condition with the constant_ \(\sqrt{N}C_{v}\)_._
3. _If_ \(\sigma(\cdot,\cdot)\) _satisfies Assumption_ 3_, then the same holds for_ \(\bm{\sigma}(\cdot)\) _with constant_ \(\sqrt{N}K\)_._

Proof.: We prove these statements separately:

**1.** Let \(x,y\in(\mathbb{R}^{d})^{\otimes N}\) and define \(a_{i}=|x^{i}-y^{i}|\). First, notice that \(\mathcal{W}_{2}^{2}(\mu_{x},\mu_{y})\leq\frac{1}{N}\sum a_{i}^{2}\), as the average on the right-hand-side corresponds to the specific coupling of \(x_{i}\leftrightarrow y_{i}\). Now, observe that

\[|\bm{b}(x)-\bm{b}(y)|^{2} =\sum_{i}|b(x^{i},\mu_{x})-b(y^{i},\mu_{y})|^{2}\] \[\leq L^{2}\sum_{i}(a_{i}+\mathcal{W}_{2}(\mu_{x},\mu_{y}))^{2}\] \[\leq L^{2}\sum_{i}\Bigl{(}a_{i}+\sqrt{\frac{1}{N}\sum_{j}a_{j}^{2 }}\Bigr{)}^{2}.\]

Let \(\bm{a}=(a_{1},\ldots,a_{N})\), and notice that the last quantity above is equal to

\[L^{2}\biggl{|}\bm{a}+\sqrt{\frac{1}{N}}\,|\bm{a}|\cdot\bm{1}\biggr{|}^{2}=L^{2 }|\bm{a}|^{2}\biggl{|}\frac{\bm{a}}{|\bm{a}|}+\sqrt{\frac{1}{N}}\cdot\bm{1} \biggr{|}^{2}\leq L^{2}|\bm{a}|^{2}N\biggl{(}1+\sqrt{\frac{1}{N}}\biggr{)}^{2}.\]

This means that

\[|\bm{b}(x)-\bm{b}(y)|\leq L(\sqrt{N}+1)|x-y|.\]

For the diffusion, it suffices to notice that

\[\|\bm{\sigma}(x)-\sigma(y)\|_{\mathrm{F}}^{2}=\sum_{i}\|\sigma(x^{i},\mu_{x}) -\sigma(y^{i},\mu_{y})\|_{\mathrm{F}}^{2}.\]

The rest of the proof is similar to the one for the drift.

**2.** We have

\[\frac{1}{N}\langle x,\bm{b}(x)\rangle=\frac{1}{N}\sum_{i=1}^{N}\langle x^{i},b(x^{i},\mu_{x})\rangle\leq C_{v}(\frac{1}{N}\sum\lvert x^{i}\rvert+1)\leq C _{v}(\frac{1}{\sqrt{N}}\sqrt{\sum\lvert x^{i}\rvert^{2}}+1),\]

where in the last inequality, we used Cauchy-Schwarz. This implies \(\langle x,\bm{b}(x)\rangle\leq C_{v}\sqrt{N}(\lvert x\rvert+1)\).

**3.** It is easy to see that

\[\|\bm{\sigma}(x)\|_{F}^{2}=\operatorname{tr}(\bm{\sigma}(x)^{\top}\bm{\sigma} (x))=\sum_{i=1}^{N}\operatorname{tr}(\sigma(x^{i},\mu_{x})^{\top}\sigma(x^{i},\mu_{x}))\leq NK^{2}.\qed\]

**Lemma A.2**.: _If \(b(\cdot,\cdot)\) is \((\alpha,\beta)\)-dissipative on average, then \(\bm{b}(\cdot)\) is \((\alpha,N\beta)\)-dissipative in the usual sense, that is, for all \(x\in(\mathbb{R}^{d})^{\otimes N}\), \(\langle x,\bm{b}(x)\rangle\leq-\alpha\lvert x\rvert^{2}+N\beta\)._

Proof.: Observe that for \(x\in(\mathbb{R}^{d})^{\otimes N}\) we have

\[\frac{1}{N}\langle x,\bm{b}(x)\rangle =\frac{1}{N}\sum_{i=1}^{N}\langle x^{i},b(x^{i},\mu_{x})\rangle= \operatorname{\mathbb{E}}_{\mu_{x}}\bigl{\{}y,b(y,\mu_{x})\bigr{\}}\leq-\alpha \operatorname{\mathbb{E}}_{\mu_{x}}\lvert y\rvert^{2}+\beta\] \[=-\alpha\frac{1}{N}\sum_{i=1}^{N}\lvert x^{i}\rvert^{2}+\beta=- \alpha\frac{1}{N}\lvert x\rvert^{2}+\beta.\]

This means that \(\langle x,\bm{b}(x)\rangle\leq-\alpha\lvert x\rvert^{2}+N\beta\).

The Main Theorem

### Proof of Theorem 1

Recall the _Picard process_ (Picard):

\[\Pi_{s}^{(t)}=X_{t}+\int_{0}^{s}\bm{b}\left(X_{t+u}\right)du+\int_{0}^{s}\bm{ \sigma}(X_{t+u})\ dW_{u}^{(t)}.\]

We break down the proof into four steps: first, we prove that the Picard process is close to the flow (Flow), and then we bound the distance between the Picard process and the interpolation (Int). We then conclude the proof of the WAPT property. Lastly, we prove that stability is implied by dissipativity.

## SS Distance of Picard from Flow.

\[\mathbb{E}|\Pi_{s}^{(t)}-\Phi_{s}^{(t)}|^{2} \leq 2\,\mathbb{E}\!\left|\!\!\int_{0}^{s}\bm{b}\left(X_{t+u} \right)-\bm{b}\left(\Phi_{u}^{(t)}\right)du\!\right|^{2}+2\,\mathbb{E}\!\left| \!\int_{0}^{s}\bm{\sigma}(X_{t+u})-\bm{\sigma}(\Phi_{u}^{(t)})\ dW_{u}^{(t)} \right|^{2}\] \[\leq 2(T+1)L^{2}\int_{0}^{s}\mathbb{E}|\Phi_{u}^{(t)}-X_{t+u}|^{2}\]

where we used Lipschitzness of \(\bm{b}\) and \(\bm{\sigma}\) (implied by Assumption 1 and Lemma A.1), Ito's isometry (see, e.g., (54, Lemma 3.4)), and Lemma A.1.

## SS Distance of Picard to Interpolation.

We place a bar above a symbol to denotes its piecewise constant interpolation.

\[\mathbb{E}|\Pi_{s}^{(t)}-X_{t+s}|^{2} =\mathbb{E}\!\left|\!\int_{t}^{t+s}\bm{b}\left(X_{u}\right)-\bm{b} \left(\overline{X_{u}}\right)du+\int_{t}^{t+s}\bm{\sigma}(X_{u})-\bm{\sigma}( \overline{X_{u}})\ dW_{u}^{(t)}+\Delta_{P}(t,s)\right|^{2}\] \[\leq 3(T+1)L^{2}\int_{t}^{t+s}\mathbb{E}|X_{u}-\overline{X_{u}}|^ {2}\ du+3\,\mathbb{E}\!\left|\Delta_{P}(t,s)\right|^{2},\]

where \(\Delta_{P}(t,s)\) is the accumulated noise and bias from time \(t\) to time \(t+s\), which is equal to

\[\Delta_{P}(t,s)\coloneqq\sum_{i=k}^{n-1}\gamma_{i+1}P_{i+1}+(t+s-\tau_{n}) \,\mathbb{E}\!\left[P_{n+1}\mid\mathcal{F}_{t+s}\right]-(t-\tau_{k})\, \mathbb{E}\!\left[P_{k+1}\mid\mathcal{F}_{t}\right],\] (B.1)

with \(n=m(t+s)\) and \(k=m(t)\). It is shown in [23] that \(\lim_{t\to\infty}\mathbb{E}\!\left|\Delta_{P}(t,s)\right|^{2}=0\), a.s.

Continuing to bound the inside of the integral, we have

\[\mathbb{E}|X_{t}-x_{k}|^{2}\leq 3(t-\tau_{k})^{2}(\mathbb{E}|\bm{b}(x_{k})|^ {2}+\mathbb{E}|P_{k+1}|^{2})+3(t-\tau_{k})\,\mathbb{E}\operatorname{tr}(\bm{ \sigma}(x_{k})^{\top}\bm{\sigma}(x_{k}))\]

where we used the fact that conditional expectation is a contraction in \(L^{2}\), and

\[\mathbb{E}|\bm{\sigma}(x_{k})\,\xi_{k+1}|^{2} =\mathbb{E}\operatorname{tr}\!\left(\xi_{k+1}^{\top}\bm{\sigma}(x _{k})^{\top}\bm{\sigma}(x_{k})\,\xi_{k+1}\right)\] \[=\mathbb{E}\operatorname{tr}\!\left(\bm{\sigma}(x_{k})^{\top}\bm {\sigma}(x_{k})\,\xi_{k+1}\xi_{k+1}^{\top}\right)\] \[=\mathbb{E}\operatorname{tr}\!\left(\bm{\sigma}(x_{k})^{\top}\bm {\sigma}(x_{k})\,\mathbb{E}\!\left[\xi_{k+1}\xi_{k+1}^{\top}\mid\mathcal{F}_{ \tau_{k}}\right]\right)\] \[=\mathbb{E}\operatorname{tr}\!\left(\bm{\sigma}(x_{k})^{\top}\bm {\sigma}(x_{k})\right).\]

Moreover, by Assumption 3 we have \(\mathbb{E}\operatorname{tr}(\bm{\sigma}(x_{k})^{\top}\bm{\sigma}(x_{k}))=\mathcal{ O}(1)\). We thus get by Lemma B.1

\[\mathbb{E}|X_{t}-x_{k}|^{2}\leq 3C\gamma_{k+1}^{2}(1/\gamma_{k+1}+1)+3C\gamma_{k+1 }=\mathcal{O}(\gamma_{k+1}).\]

This implies

\[\sup_{s\in[0,T]}\mathbb{E}|\Pi_{s}^{(t)}-X_{t+s}|^{2}\leq CT^{2}L^{2}\sup_{t \leq u\leq t+T}\overline{\gamma_{u}}+3\,\mathbb{E}\!\left|\Delta_{P}(t,T) \right|^{2}\eqqcolon A_{t},\]

with \(A_{t}\to 0\) as \(t\to\infty\), a.s.

\(\lx@sectionsign\) Concluding the proof of APT.By Gronwall inequality,

\[\mathbb{E}|X_{t+s}-\Phi_{s}^{(t)}|^{2}\leq C\int_{0}^{s}\mathbb{E}|X_{t+u}-\Phi_ {t}^{(t)}|^{2}+A_{t}\leq A_{t}\exp(sC)\leq A_{t}\exp(TC)\to 0\]

as \(t\to\infty\). Since

\[\mathcal{W}_{2}^{2}(\mathrm{law}(X_{t+s}),\mathrm{law}(\Phi_{s}^{(t)}))\leq \mathbb{E}|X_{t+s}-\Phi_{s}^{(t)}|^{2},\]

we get the desired result.

\(\lx@sectionsign\) Stability.Lemma A.2 implies that under dissipativity on average, the iterates are stable, and as in [23, Theorem 3], we get the desired convergence result.

### On Propagation of Chaos

Theorem 1 shows that the law \(\mu_{k}\) of \(x_{k}\in(\mathbb{R}^{d})^{\otimes N}\) converges in the Wasserstein space to the limit-set (or the _internally chain-transitive_ (ICT) set) \(S\subset\mathcal{P}_{2}((\mathbb{R}^{d})^{\otimes N})\) of the corresponding flow:

\[\lim_{k\to\infty}\inf_{\mu\in S}\mathcal{W}_{2}(\mu_{k},\mu)=0.\]

By looking only at the first particle of \(x_{k}\), namely, \(x_{k}^{1}\), and given that the dynamics is exchangeable, it follows that

\[\mathcal{W}_{2}^{2}(\mu_{k},\mu) =\inf_{\pi}\int|x-y|^{2}\,\pi(dx,\,dy)\] \[=\inf_{\pi}(\int|x^{1}-y^{1}|^{2}\,\pi^{1}(dx^{1},dy^{1})+\cdots+ \int|x^{N}-y^{N}|^{2}\,\pi^{N}(dx^{N},dy^{N}))\] \[\geq\inf_{\pi^{1}}\int|x^{1}-y^{1}|^{2}\,\pi^{1}(dx^{1},dy^{1})\] \[=\mathcal{W}_{2}^{2}(\mathrm{law}(x_{k}^{1}),\mathrm{marginal}_ {1}(\mu)),\]

where \(\pi^{1}(dx^{1},dy^{1})=\int\pi(x,y)\,dx^{2}dy^{2}\cdots dx^{N}dy^{N}\), and we used the exchangability in deducing that the law of \(y^{i}\) are the same as the first marginal of \(\mu\), for all \(i=1,\ldots,N\). Hence, as the limit-set \(S^{\prime}\) of the first component of the SDE \(X_{t}^{1}\) is a subset of the marginal of \(S\),

\[\lim_{k\to\infty}\inf_{\nu\in S^{\prime}}\mathcal{W}_{2}(\mathrm{law}(x_{k}^{ 1}),\nu)\leq\lim_{k\to\infty}\inf_{\nu\in\mathrm{marginal}_{1}(S)}\mathcal{W} _{2}(\mathrm{law}(x_{k}^{1}),\nu)=0.\]

This means that the first particle converges in law to the ICT sets of the corresponding SDE. Assuming a uniform propagation of chaos, we also know that the law of \(X_{t}^{1}\) has a distance of \(O(1/N)\) from the mean-field equation, and hence, we get that the law of the particles following the discrete algorithm have controllable distance from the mean-field dynamics.

### Supporting Lemmas

**Lemma B.1**.: _Suppose Assumptions 1-5 hold. One has \(\mathbb{E}|\bm{b}(x_{k})|^{2}=\mathcal{O}(1/\gamma_{k+1})\), \(\mathbb{E}|\varepsilon_{k+1}|^{2}=\mathcal{O}(\gamma_{k+1})\), and \(\mathbb{E}|P_{k+1}|^{2}=\mathcal{O}(1)\)._

Proof.: We repeatedly use the fact that \(\mathbb{E}|\bm{b}(x_{k})|^{2}\leq 2L^{2}\,\mathbb{E}|x_{k}|^{2}+\mathbb{E}|\bm{b }(x_{0})|^{2}\eqqcolon 2L^{2}\,\mathbb{E}|x_{k}|^{2}+C_{0}\). By Assumption 4, \(\mathbb{E}|\varepsilon_{k+1}|^{2}\leq\mathcal{O}(\gamma_{k+1}^{2})a_{k}+ \mathcal{O}(\gamma_{k+1})\), and we have

\[\mathbb{E}|P_{k+1}|^{2}\leq 2\,\mathbb{E}|\varepsilon_{k+1}|^{2}+2\,\mathbb{E}|U _{k+1}|^{2}=\mathcal{O}(\gamma_{k+1}^{2})a_{k}+\mathcal{O}(1).\] (B.2)

Moreover, as \(\sqrt{p+q}\leq\sqrt{p}+\sqrt{q}\), we have

\[\sqrt{\mathbb{E}|P_{k+1}|^{2}}\leq\mathcal{O}(\gamma_{k+1})\sqrt{a_{k}}+ \mathcal{O}(1).\] (B.3)

Assumption 3 also implies that \(\mathbb{E}|\bm{\sigma}(x_{k})\xi_{k+1}|^{2}\leq C_{\sigma}\).

Define \(a_{k}\coloneqq\mathsf{E}|x_{k}|^{2}\). Then,

\[a_{k+1}-a_{k} =\gamma_{k+1}^{2}\,\mathsf{E}|\bm{b}(x_{k})+P_{k+1}|^{2}+\gamma_{k+ 1}\,\mathsf{E}|\bm{\sigma}(x_{k})\xi_{k+1}|^{2}+2\gamma_{k+1}\,\mathsf{E}\langle x _{k},\bm{b}(x_{k})+P_{k+1}\rangle\] \[\qquad\quad+2\gamma_{k+1}^{1/2}\,\mathsf{E}\langle x_{k},\bm{ \sigma}(x_{k})\xi_{k+1}\rangle+2\gamma_{k+1}^{3/2}\,\mathsf{E}\langle\bm{b}(x _{k})+P_{k+1},\bm{\sigma}(x_{k})\xi_{k+1}\rangle\] \[\leq 2L^{2}\gamma_{k+1}^{2}a_{k}+\gamma_{k+1}^{2}C_{0}+2\gamma_{k+ 1}^{2}\,\mathsf{E}|P_{k+1}|^{2}+\gamma_{k+1}C_{\sigma}+2\gamma_{k+1}C_{v}( \sqrt{a_{k}}+1)\] \[\qquad\quad+2\gamma_{k+1}\sqrt{a_{k}}\sqrt{\mathsf{E}|P_{k+1}|^{ 2}}+2\gamma_{k+1}^{3/2}\sqrt{C_{\sigma}}\sqrt{\mathsf{E}|P_{k+1}|^{2}}\] (B.4)

Plugging the bounds from (B.2) and (B.3) into (B.4) gives

\[a_{k+1}-a_{k} \leq\mathcal{O}(\gamma_{k+1}^{2})a_{k}+\mathcal{O}(\gamma_{k+1}) \sqrt{a_{k}}+\mathcal{O}(\gamma_{k+1})\] \[\coloneqq:P\gamma_{k+1}^{2}a_{k}+\mathcal{O}\gamma_{k+1}\sqrt{a_{ k}}+R\gamma_{k+1},\]

for some \(P,Q,R>0\) that do not depend on \(k\).

We now prove \(a_{k}\leq M/\gamma_{k+1}\) for some fixed \(M>0\) via induction. Suppose this is the case for \(k\). For \(k+1\) we have

\[a_{k+1} \leq(P\gamma_{k+1}^{2}+1)a_{k}+Q\gamma_{k+1}\sqrt{a_{k}}+R\gamma_ {k+1}\] \[\leq M(P\gamma_{k+1}+1/\gamma_{k+1})+\sqrt{M}Q\sqrt{\gamma_{k+1}} +R\gamma_{k+1}\] \[\stackrel{{!}}{{\leq}}M/\gamma_{k+2}.\]

The last inequality is equivalent to the fact that the following quadratic equation (in \(\sqrt{M}\)) has a bounded largest root (and the bound shall not depend on \(k\)):

\[M(P\gamma_{k+1}+1/\gamma_{k+1}-1/\gamma_{k+2})+\sqrt{M}Q\sqrt{\gamma_{k+1}}+R \gamma_{k+1}\]

Notice that by Assumption 5, the leading coefficient is negative, and the larger root is computed as

\[\frac{Q\sqrt{\gamma_{k+1}}+Q\sqrt{\gamma_{k+1}}+\sqrt{4R(\gamma_ {k+1}/\gamma_{k+2}-P\gamma_{k+1}^{2}-1)}}{2(1/\gamma_{k+2}-P\gamma_{k+1}-1/ \gamma_{k+1})}\] \[\leq\frac{2Q\sqrt{\gamma_{k+1}}+2\sqrt{R}\sqrt{\gamma_{k+1}/ \gamma_{k+2}}}{2\gamma_{k+1}/\gamma_{k+2}}\leq 2Q\sqrt{\gamma_{k+2}}+\sqrt{R} \sqrt{\gamma_{k+2}/\gamma_{k+1}}<2Q+\sqrt{R}\eqqcolon M.\]

The claim for \(\bm{b}\) follows by Lipschitzness, from which the claim for the bias and perturbation follows directly. 

## Appendix C Proofs of Results for Applications

### Two-Layer Neural Networks and Mean-field Langevin

Proof of Corollary 1.: **Smoothness of drift:** We start by showing Lipschitzness with respect to the measure parameter of the drift. First, observe that \(\nabla_{\theta}W(\theta,\cdot)\) is Lipschitz:

\[|\nabla_{\theta}W(\theta,\theta^{\prime})-\nabla_{\theta}W( \theta,\theta^{\prime\prime})| =|\mathsf{E}_{z\sim\mathcal{D}}[(\varphi(z,\theta^{\prime})- \varphi(z,\theta^{\prime\prime}))\,\nabla_{\theta}\varphi(z,\theta)]|\] \[=|\mathsf{E}_{z\sim\mathcal{D}}[(\kappa(\langle z,\theta^{\prime} \rangle)-\kappa(\langle z,\theta^{\prime\prime}\rangle))\,\kappa^{\prime}( \langle z,\theta\rangle)\,z]|\] \[\leq C|\theta^{\prime}-\theta^{\prime\prime}|,\]

due to the boundedness of \(\kappa^{\prime}\) and \(z\), and Lipschitzness of \(\kappa\).

Now, consider \(\mu,\nu\in\mathcal{P}_{2}(\mathbb{R}^{d})\) and let \(\pi\) be the optimal coupling (in \(\mathcal{W}_{2}\) sense) between them. Then, for a fixed \(\theta\in\mathbb{R}^{d}\),

\[|b(\theta,\mu)-b(\theta,\nu)|^{2} =\left|\int\nabla_{\theta}W(\theta,p)-\nabla_{\theta}W(\theta,q)\, \pi(dp,dq)\right|^{2}\] \[\leq\int|\nabla_{\theta}W(\theta,p)-\nabla_{\theta}W(\theta,q)|^ {2}\,\pi(dp,dq)\] \[\leq\int\,C^{2}|p-q|^{2}\,\pi(dp,dq)\] \[=C^{2}W_{2}^{2}(\mu,\nu).\]Next, we show for a fixed measure \(\mu\in\mathcal{P}_{2}(\mathbb{R}^{d})\), \(b(\cdot,\mu)\) is Lipschitz in the first input.

\[|b(\theta,\mu)-b(\theta^{\prime},\mu)|\leq\left|\int\nabla_{\theta}W(\theta,p)- \nabla_{\theta}W(\theta^{\prime},p)\,\mu(dp)\right|+|\nabla V(\theta)-\nabla V( \theta^{\prime})|.\]

Let us treat each term separately. We have

\[|\nabla_{\theta}W(\theta,p)-\nabla_{\theta}W(\theta^{\prime},p)| =|\mathbb{E}_{z\sim\mathcal{D}}[\varphi(z,p)(\nabla_{\theta} \varphi(z,\theta)-\nabla_{\theta}\varphi(z,\theta^{\prime}))]|\] \[=|\mathbb{E}_{z\sim\mathcal{D}}[\kappa(\langle p,z\rangle)( \kappa^{\prime}(\langle z,\theta\rangle)-\kappa^{\prime}(\langle z,\theta^{ \prime}\rangle))\,z]|\] \[\leq C\,\mathbb{E}_{z\sim\mathcal{D}}[|z||\theta-\theta^{\prime}| \,z]\] \[\leq C|\theta-\theta^{\prime}|.\]

Similarly,

\[|\nabla V(\theta)-\nabla V(\theta^{\prime})|=\left|\mathbb{E}_{(y,z)- \mathcal{D}}[yz(\kappa^{\prime}(\langle\theta,z\rangle)-\kappa^{\prime}( \langle\theta^{\prime},z\rangle))\,\mathcal{D}(dy,dz)]\right|\leq C|\theta- \theta^{\prime}|.\]

Thus,

\[|b(\theta,\mu)-b(\theta^{\prime},\nu)|\leq|b(\theta,\mu)-b(\theta,\nu)|+|b( \theta,\nu)-b(\theta^{\prime},\nu)|\leq L(|\theta-\theta^{\prime}|+\mathcal{W }_{2}(\mu,\nu)),\]

showing \(b\) satisfies Assumption 1.

**Growth control:** First, let us calculate

\[\int\left\langle\theta,b(\theta,\mu)\right\rangle\mu(d\theta) =\iint\varphi(z,\theta^{\prime})\langle\theta,\nabla_{\theta} \varphi(z,\theta)\rangle\,\mathcal{D}(dz)\mu(d\theta^{\prime})\mu(d\theta)\] \[\qquad-\iint y\left\langle\theta,\nabla_{\theta}\varphi(z,\theta )\right\rangle\,\mathcal{D}(dy,dz)\mu(d\theta)\] \[\qquad-\lambda\int|\theta|^{2}\,\mu(d\theta)\] \[=\iint\varphi(z,\theta^{\prime})\kappa^{\prime}(\langle z, \theta\rangle)\langle\theta,z\rangle\,\mathcal{D}(dz)\mu(d\theta^{\prime})\mu (d\theta)\] \[\qquad-\iint y\,\kappa^{\prime}(\langle z,\theta\rangle)\langle \theta,z\rangle\,\mathcal{D}(dy,dz)\mu(d\theta)\] \[\qquad-\lambda\int|\theta|^{2}\,\mu(d\theta).\]

As \(\varphi\), \(\kappa^{\prime}\), and \(\operatorname{supp}(\mathcal{D})\) are bounded, we can see that

\[\left|\int\left\langle\theta,b(\theta,\mu)\right\rangle\mu(d\theta)\right| \leq C\iint|\theta||z|\,\mathcal{D}(dz)\mu(d\theta)+C^{\prime}\int|\theta||z| \,\mathcal{D}(dz)\mu(d\theta)\leq C\int|\theta|\,\mu(d\theta),\]

thus, satisfying Assumption 2.

**Dissipativity on average:** Here we use the extra assumption that \(|a\,\kappa^{\prime}(a)|\) is bounded. We directly bound the terms \(\kappa^{\prime}(\langle\theta,z\rangle)\langle\theta,z\rangle\) above and obtain

\[\int\left\langle\theta,b(\theta,\mu)\right\rangle\mu(d\theta)\leq-\lambda\int |\theta|^{2}\,\mu(d\theta)+C.\qed\]

### Stein Variational Gradient Descent

Proof of Corollary 2.: While the first term in the drift is standard to work with (see Section 4.4), it is the second term in the drift that makes it difficult to analyze. Specifically, we prove the dissipativity on average only for empirical measures. While this would be enough for our purposes (and Theorem 1 goes through), it is an interesting future direction to see when does dissipativity hold in a more general setup. Moreover, for simplicity, we only consider the case where the kernel \(K\) is of the form \(K(x,y)=h(x-y)\), for some function \(h\).

Below, we first prove that \(b\) is dissipative on average, which implies that the law of the iterates will be in a compact subset of \(\mathcal{P}_{2}(\mathbb{R}^{d})\). Then, we show that \(b\) is smooth on this compact subset.

**Dissipativity on average:** Due to \(K\) being symmetric, \(\nabla_{2}K(x,y)=-\nabla_{2}K(y,x)\). We thus have

\[\iint\left\langle x-y,\nabla_{2}K(x,y)\right\rangle\mu(dx)\mu(dy)\] \[=\iint\left\langle x,\nabla_{2}K(x,y)\right\rangle\mu(dx)\mu(dy)- \iint\left\langle y,\nabla_{2}K(x,y)\right\rangle\mu(dx)\mu(dy)\] \[=\iint\left\langle x,\nabla_{2}K(x,y)\right\rangle\mu(dx)\mu(dy)+ \iint\left\langle y,\nabla_{2}K(y,x)\right\rangle\mu(dx)\mu(dy)\] \[=2\iint\left\langle x,\nabla_{2}K(x,y)\right\rangle\mu(dx)\mu(dy).\]

Thus,

\[\iint\left\langle x,\nabla_{2}K(x,y)\right\rangle\mu(dx)\mu(dy)=\frac{1}{2} \iint\left\langle x-y,\nabla_{2}K(x,y)\right\rangle\mu(dx)\mu(dy)\leq\eta\]

by Cauchy-Schwarz and the assumption that \(|\nabla_{2}K(x,y)|\leq\eta/|x-y|\). With similar arguments, and using dissipativity of \(V\), we have

\[\iint\left\langle x,\nabla V(y)\right\rangle K(x,y)\,\mu(dx)\mu(dy)\] \[=\iint\left\langle x,\nabla V(x)\right\rangle K(x,y)\,\mu(dx)\mu (dy)-\frac{1}{2}\iint\left\langle x-y,\nabla V(x)-\nabla V(y)\right\rangle K( x,y)\,\mu(dx)\mu(dy)\] \[\geq\alpha\iint|x|^{2}K(x,y)\,\mu(dx)\mu(dy)-\beta\|K\|_{\infty}\] \[\quad-\frac{1}{2}L\iint|x-y|^{2}K(x,y)\,\mu(dx)\mu(dy)\] \[\geq\alpha\iint|x|^{2}K(x,y)\,\mu(dx)\mu(dy)-\beta\|K\|_{\infty}+ \frac{L\eta}{2}.\]

As \(K(x,x)=h(0)\) and \(K(x,y)>0\) for all \(x,y\), and that \(\mu\) is an empirical measure \(\mu=\frac{1}{N}\sum_{i=1}^{N}\delta_{x_{i}}\), the last quantity is equal to

\[\frac{1}{N^{2}}\sum_{i}|x_{i}|^{2}\sum_{j}K(x_{i},x_{j})\geq\frac{1}{N^{2}} \sum_{i}|x_{i}|^{2}K(x_{i},x_{i})\geq\frac{h(0)}{N}\int|x|^{2}\,\mu(dx).\]

In total, we derive that \(b\) is dissipative on average.

**Smoothness of the drift:** We have, for \(\mu\) in a compact set of \(\mathcal{P}_{2}(\mathbb{R}^{d})\)

\[|b\left(x,\mu\right)-b(x^{\prime},\mu)|\] \[\leq\left|\int\nabla_{2}K(x,y)-\nabla_{2}K(x^{\prime},y)\,\mu(dy )\right|+\left|\int\left(K(x,y)-K(x^{\prime},y)\right)\nabla V(y)\,\mu(dy)\right|\] \[\leq L|x-x^{\prime}|\left(1+\int|\nabla V(y)|\,\mu(dy)\right)\] \[\leq L|x-x^{\prime}|\left(1+C\int\left(1+|y|^{2}\right)\mu(dy) \right)<L^{\prime}|x-x^{\prime}|.\]

Moreover, take \(\mu,\nu\) in the same compact set, and let \(\pi\) be the optimal coupling (in \(\mathcal{W}_{2}\) sense). Then,

\[|b\left(x,\mu\right)-b\left(x,\nu\right)|^{2}\] \[\leq 2\left|\int\nabla_{2}K(x,y)-\nabla_{2}K(x,z)\,\pi(dy,dz) \right|^{2}\] \[\qquad+2\left|\int K(x,y)\nabla V(y)-K(x,z)\nabla V(z)\,\pi(dy, dz)\right|^{2}\] \[\leq 2L^{2}\mathcal{W}_{2}^{2}(\mu,\nu)\] \[\qquad+2\left|\int K(x,y)\nabla V(y)-K(x,z)\nabla V(y)+K(x,z) \nabla V(y)-K(x,z)\nabla V(z)\,\pi(dy,dz)\right|^{2}\] \[\leq 2L^{2}\mathcal{W}_{2}^{2}(\mu,\nu)+4(L^{2}+L^{2})\mathcal{W}_ {2}^{2}(\mu,\nu).\]

### Two-player Zero-sum Continuous Games

Proof of Corollary 3.: Recall that

\[b(q,\mu)\coloneqq\int\begin{pmatrix}-\nabla_{x}K(q_{1},q_{2}^{\prime})\\ \alpha\,\nabla_{y}K(q_{1}^{\prime},q_{2})\end{pmatrix}\,\mu(dq^{\prime}),\quad q =(q_{1},q_{2}).\]

**Smoothness of drift:** For a fixed \(\mu\in\mathcal{P}_{2}(\mathbb{R}^{d})\mathbb{R}^{2d}\) and \(q,r\in\mathbb{R}^{2d}\) we have

\[|b(q,\mu)-b(r,\mu)|^{2} \leq\int\left|\begin{pmatrix}-\nabla_{x}K(q_{1},q_{2}^{\prime})\\ \alpha\,\nabla_{y}K(q_{1}^{\prime},q_{2})\end{pmatrix}-\begin{pmatrix}- \nabla_{x}K(r_{1},q_{2}^{\prime})\\ \alpha\,\nabla_{y}K(q_{1}^{\prime},r_{2})\end{pmatrix}\right|^{2}\mu(dq^{ \prime})\] \[\leq L^{2}|q_{1}-r_{1}|^{2}+\alpha^{2}L^{2}|q_{2}-r_{2}|^{2}\] \[\leq L^{2}|q-r|^{2},\]

where we used \(L\)-Lipschitzness of \(\nabla_{x}K\) and \(\nabla_{y}K\).

Now, for a fixed \(q\in\mathbb{R}^{2d}\), and \(\mu,\nu\in\mathcal{P}_{2}(\mathbb{R}^{d})\mathbb{R}^{2d}\) with optimal coupling \(\pi\), we have

\[|b(q,\mu)-b(q,\nu)|^{2} \leq\iint\left|\begin{pmatrix}-\nabla_{x}K(q_{1},r_{2})\\ \alpha\,\nabla_{y}K(r_{1},q_{2})\end{pmatrix}-\begin{pmatrix}-\nabla_{x}K(q_{1 },r_{2}^{\prime})\\ \alpha\,\nabla_{y}K(r_{1}^{\prime},q_{2})\end{pmatrix}\right|^{2}\pi(dr,dr^{ \prime})\] \[\leq L^{2}\iint|r_{2}-r_{2}^{\prime}|^{2}+|r_{1}-r_{1}^{\prime}| ^{2}\,\pi(dr,dr^{\prime})\] \[=L^{2}\mathcal{W}_{2}^{2}(\mu,\nu).\]

**Average dissipativity of drift:** Suppose \(\nabla_{x}K\) and \(-\nabla_{y}K\) are \((a,\beta)\)-dissipative. Then

\[\int\left\langle q,b(q,\mu)\right\rangle\mu(dq) =\iint\left\langle q_{1},-\nabla_{x}K(q_{1},q_{2}^{\prime}) \right\rangle+\alpha\langle q_{2},\nabla_{y}K(q_{1}^{\prime},q_{2})\rangle\, \mu(dq^{\prime})\mu(dq)\] \[\leq\int\,-a\alpha(|q_{1}|^{2}+|q_{2}|^{2})\,\mu(dq)+2\beta,\]

implying that \(b(\cdot,\cdot)\) is \((a\alpha,2\beta)\)-dissipative on average.

If, on the other hand, the domains \(\mathcal{X}\) and \(\mathcal{Y}\) are bounded, observe that by Cauchy-Schwarz

\[\left|\int\left\langle q,b(q,\mu)\right\rangle\mu(dq)\right|\leq\iint|q_{1}|| \nabla_{x}K(q_{1},q_{2}^{\prime})|+\alpha|q_{2}||\nabla_{y}K(q_{1}^{\prime},q_ {2})|\,\mu(dq^{\prime})\mu(dq)\leq M,\]

where \(M=\sup_{q_{1}\in\mathcal{X},q_{2}\in\mathcal{Y}}|q_{1}||\nabla_{x}K(q_{1},q_{ 2}^{\prime})|+\alpha|q_{2}||\nabla_{y}K(q_{1}^{\prime},q_{2})|\). Also denoting by \(R=\sup_{q\in\mathcal{X}\times\mathcal{Y}}|q|^{2}\), we see that for any \(\alpha>0\), \(b(\cdot,\cdot)\) is \((\alpha,M+\alpha N)\)-dissipative on average, as

\[\int\left\langle q,b(q,\mu)\right\rangle\mu(dq)+\alpha\int|q|^{2}\,\mu(dq)\leq M +\alpha N.\]

**Optimistic algorithm fits Assumption 4**: Recall the iterates

\[q_{k+1}^{i}=q_{k}^{i}+\gamma_{k+1}\big{(}2b(q_{k}^{i},\widetilde{\mu}_{k})-b( q_{k-1}^{i},\widetilde{\mu}_{k-1})\big{)}+\sqrt{2\gamma_{k+1}}\,\sigma\,\Xi_{k+1}^{i},\]

where \(\Xi_{k+1}^{i}=(\xi_{k+1}^{i},\zeta_{k+1}^{i})\). Notice that the bias of this iteration is

\[\varepsilon_{k+1}^{i}=b(q_{k}^{i},\widetilde{\mu}_{k})-b(q_{k-1}^{i}, \widetilde{\mu}_{k-1}).\]

For brevity, let us write \(\mathcal{F}_{k}\coloneqq\mathcal{F}_{\tau_{k}}\). We have

\[\mathbb{E}[|\varepsilon_{k+1}^{i}|^{2}\,|\,\mathcal{F}_{k}] =\mathbb{E}[|q_{k+1}^{i}-q_{k}^{i}-\gamma_{k+1}b(q_{k}^{i}, \widetilde{\mu}_{k})-\sqrt{2\gamma_{k+1}}\,\sigma\,\Xi_{k+1}^{i}|^{2}\,|\, \mathcal{F}_{k}]\] \[\leq 3\,\mathbb{E}[|q_{k+1}^{i}-q_{k}^{i}|^{2}\,|\,\mathcal{F}_{k}] +3\gamma_{k+1}^{2}\,\mathbb{E}[|b(q_{k}^{i},\widetilde{\mu}_{k})|^{2}\,|\, \mathcal{F}_{k}]+6\gamma_{k+1}\tau(1+\alpha)d.\]

Moreover, we have

\[\mathbb{E}[|q_{k+1}^{i}-q_{k}^{i}|^{2}\,|\,\mathcal{F}_{k}] \leq 2\gamma_{k+1}^{2}\,\mathbb{E}[|2b(q_{k}^{i},\widetilde{\mu}_{k })-b(q_{k-1}^{i},\widetilde{\mu}_{k-1})|^{2}\,|\,\mathcal{F}_{k}]+2\gamma_{k+1} \tau(1+\alpha)d\] \[=2\gamma_{k+1}^{2}\,\mathbb{E}[|b(q_{k}^{i},\widetilde{\mu}_{k})+ \varepsilon_{k+1}^{i}|^{2}\,|\,\mathcal{F}_{k}]+2\gamma_{k+1}\tau(1+\alpha)d\] \[\leq 4\gamma_{k+1}^{2}\,\mathbb{E}[|b(q_{k}^{i},\widetilde{\mu}_{k}) |^{2}\,|\,\mathcal{F}_{k}]+4\gamma_{k+1}^{2}\,\mathbb{E}[|\varepsilon_{k+1}^{i }|^{2}\,|\,\mathcal{F}_{k}]+2\gamma_{k+1}\tau(1+\alpha)d\]Combining the last two inequalities, we have

\[\mathbb{E}[|e_{k+1}^{i}|^{2}\,|\,\mathscr{F}_{k}] \leq 3\Big{(}4\gamma_{k+1}^{2}\,\mathbb{E}[|b(q_{k}^{i},\widetilde{ \mu}_{k})|^{2}\,|\,\mathscr{F}_{k}]+4\gamma_{k+1}^{2}\,\mathbb{E}[|e_{k+1}^{i}|^ {2}\,|\,\mathscr{F}_{k}]+2\gamma_{k+1}\tau(1+\alpha)d\Big{)}\] \[+3\gamma_{k+1}^{2}\,\mathbb{E}[|b(q_{k}^{i},\widetilde{\mu}_{k})| ^{2}\,|\,\mathscr{F}_{k}]+6\gamma_{k+1}\tau(1+\alpha)d\] \[=12\gamma_{k+1}^{2}\,\mathbb{E}[|e_{k+1}^{i}|^{2}\,|\,\mathscr{F} _{k}]+15\gamma_{k+1}^{2}\,\mathbb{E}[|b(q_{k}^{i},\widetilde{\mu}_{k})|^{2}\,| \,\mathscr{F}_{k}]+12\gamma_{k+1}\tau(1+\alpha)d\]

Since \(\gamma_{k+1}\to 0\), we can assume that \(12\gamma_{k+1}^{2}\leq 1/2\), which implies

\[\mathbb{E}[|e_{k+1}^{i}|^{2}\,|\,\mathscr{F}_{k}]\leq 30\gamma_{k+1}^{2}\, \mathbb{E}[|b(q_{k}^{i},\widetilde{\mu}_{k})|^{2}\,|\,\mathscr{F}_{k}]+24 \gamma_{k+1}\tau(1+\alpha)d,\]

which is exactly what we are after. 

### Kinetic Equations

Proof of Corollary 4.: **Smoothness of the drift:** Let \(x,y\in\mathbb{R}^{d}\) and \(\mu,\nu\in\mathscr{P}_{2}(\mathbb{R}^{d})\) and set \(\pi\) be an optimal coupling between \(\mu\) and \(\nu\) (in \(W_{1}\) sense). Then

\[|b(x,\mu)-b(y,\nu)|\leq|\nabla V(x)-\nabla V(y)|+\left|\int\nabla W(x-z)\,\mu( dz)-\int\nabla W(y-z)\,\nu(dz)\right|.\]

By \(L\)-Lipschitzness of \(\nabla V\), the first term is bounded by \(L|x-y|\). For the second term, using the coupling, we can write it as

\[\left|\iint\nabla W(x-z_{1})-\nabla W(y-z_{2})\,\pi(dz_{1},dz_{2})\right| \leq\iint|\nabla W(x-z_{1})-\nabla W(y-z_{2})|\,\pi(dz_{1},dz_{2})\] \[\leq L\iint|x-y+z_{2}-z_{1}|\,\pi(dz_{1},dz_{2})\] \[\leq L\iint|x-y|+|z_{2}-z_{1}|\,\pi(dz_{1},dz_{2})\] \[\leq L|x-y|+LW_{1}(\mu,\nu)\] \[\leq L|x-y|+LW_{2}(\mu,\nu).\]

Putting these together we get

\[|b(x,\mu)-b(y,\nu)|\leq 2L(|x-y|+\mathcal{W}_{2}(\mu,\nu)).\]

**Average dissipativity of the drift:** First we show that for \(x\in\mathbb{R}^{d}\) and a probability measure \(\mu\), we have

\[\iint\left\langle x,\nabla W(x-y)\right\rangle\mu(dx)\mu(dy)\geq-M_{W}/2.\] (C.1)

This holds, since

\[\iint\left\langle x,\nabla W(x-y)\right\rangle\mu(dx)\mu(dy)\] \[\qquad=\iint\left\langle x-y+y,\nabla W(x-y)\right\rangle\mu(dx) \mu(dy)\] \[\qquad=\iint\left\langle x-y,\nabla W(x-y)\right\rangle\mu(dx) \mu(dy)+\iint\left\langle y,\nabla W(x-y)\right\rangle\mu(dx)\mu(dy)\] \[\qquad\geq-M_{W}+\iint\left\langle y,\nabla W(x-y)\right\rangle \mu(dx)\mu(dy)\] \[\qquad\geq-M_{W}-\iint\left\langle x,\nabla W(x-y)\right\rangle \mu(dx)\mu(dy),\]

where in the penultimate inequality we used the assumption (which implies \(\left\langle\nabla W(x),x\right\rangle\geq-M_{W}\)), and in the last one, we used the that \(W\) is symmetric (which implies \(\nabla W(-z)=-\nabla W(z)\)), and used Fubini's theorem to exchange integrals. Bringing the last term to the left and dividing by \(2\) shows (C.1).

To show average dissipativity, it suffices to observe

\[-\int\left\langle x,b(x,\mu)\right\rangle\mu(dx) =\int\left\langle x,\nabla V(x)\right\rangle\mu(dx)+\iint\left\langle x,\nabla W(x-y)\right\rangle\mu(dy)\mu(dx)\] \[\geq\alpha\int\left|x\right|^{2}\mu(dx)-\beta-M_{W}/2.\]

**Proximal algorithm fits Assumption 4**: Note that this implicit algorithm corresponds to the following proximal step

\[x_{k+1}^{i}=\operatorname*{arg\,min}_{x}\left\{V(x)+\frac{1}{N}\sum_{j=1}^{N}W (x-x_{k}^{j})+\frac{1}{2\gamma_{k+1}}\Big{|}x-(x_{k}^{i}+\sqrt{2\gamma_{k+1}} \,\xi_{k+1}^{i})\Big{|}^{2}\right\}.\]

By defining the perturbation as

\[P_{k+1}^{i}=\varepsilon_{k+1}^{i}=\nabla V(x_{k+1}^{i})-\nabla V(x_{k}^{i})+ \frac{1}{N}\sum_{j=1}^{N}(\nabla W(x_{k+1}^{i}-x_{k}^{j})-\nabla W(x_{k}^{i}- x_{k}^{j})),\]

we see that the algorithm (Kin-Prox) fits the template (SAA). For brevity, let us write \(\mathcal{F}_{k}\coloneqq\mathcal{F}_{r_{k}}\). We only have to show that

\[\mathbb{E}[\left|\varepsilon_{k+1}\right|^{2}\left|\mathcal{F}_{k}\right|= \sum_{i=1}^{N}\mathbb{E}[\left|\varepsilon_{k+1}^{i}\right|^{2}\left|\mathcal{ F}_{k}\right|=\mathcal{O}(\gamma_{k+1}^{2}|\bm{b}(x_{k})|^{2}+\gamma_{k+1}).\]

We have

\[\left|\varepsilon_{k+1}^{i}\right|^{2} =\left|\nabla V(x_{k+1}^{i})-\nabla V(x_{k}^{i})+\frac{1}{N}\sum _{j=1}^{N}(\nabla W(x_{k+1}^{i}-x_{k}^{j})-\nabla W(x_{k}^{i}-x_{k}^{j})) \right|^{2}\] \[\leq 2\big{|}\nabla V(x_{k+1}^{i})-\nabla V(x_{k}^{i})\big{|}^{2} +\frac{2}{N}\sum_{j=1}^{N}\Big{|}\nabla W(x_{k+1}^{i}-x_{k}^{j})-\nabla W(x_{k }^{i}-x_{k}^{j})\Big{|}^{2}\] \[\leq 2L^{2}\big{|}x_{k+1}^{i}-x_{k}^{i}\big{|}^{2}+\frac{2L^{2}}{ N}\sum_{j=1}^{N}\!\big{|}x_{k+1}^{i}-x_{k}^{i}\big{|}^{2}\] \[=4L^{2}\big{|}x_{k+1}^{i}-x_{k}^{i}\big{|}^{2}.\]

For brevity, let

\[f(x)=\nabla V(x)+\frac{1}{N}\sum_{j=1}^{N}\nabla W(x-x_{k}^{j}),\]

noticing that \(\varepsilon_{k+1}^{i}=f(x_{k+1}^{i})-f(x_{k}^{i})\). By the update rule (Kin-Prox)

\[\mathbb{E}[\left|x_{k+1}^{i}-x_{k}^{i}\right|^{2}\left|\mathcal{F}_{k}\right| \leq 2\gamma_{k+1}^{2}\mathbb{E}[|f(x_{k+1}^{i})|^{2}\left|\mathcal{F}_{k }\right|+4\gamma_{k+1}d.\]

Moreover, we have that \(|f(x_{k+1}^{i})|^{2}\leq 2|f(x_{k+1}^{i})-f(x_{k}^{i})|^{2}+2|f(x_{k}^{i})|^{2}\). Since \(\gamma_{k+1}\to 0\), we can assume that \(16L^{2}\gamma_{k+1}^{2}<\frac{1}{2}\). All in all, this gives

\[\mathbb{E}[\left|\varepsilon_{k+1}^{i}\right|^{2}\left|\mathcal{ F}_{k}\right| \leq 4L^{2}\mathbb{E}[\left|x_{k+1}^{i}-x_{k}^{i}\right|^{2}\left| \mathcal{F}_{k}\right|\] \[\leq 8L^{2}\gamma_{k+1}^{2}\mathbb{E}[|f(x_{k+1}^{i})|^{2}\left| \mathcal{F}_{k}\right|+16L^{2}\gamma_{k+1}d\] \[\leq 16L^{2}\gamma_{k+1}^{2}\mathbb{E}[\left|f(x_{k+1}^{i})-f(x_{k }^{i})\right|^{2}\left|\mathcal{F}_{k}\right|+16L^{2}\gamma_{k+1}^{2}]f(x_{k} ^{i})|^{2}+16L^{2}\gamma_{k+1}d\] \[\leq 16L^{2}\gamma_{k+1}^{2}\mathbb{E}[\left|\varepsilon_{k+1}^{i} \right|^{2}\left|\mathcal{F}_{k}\right|+16L^{2}\gamma_{k+1}^{2}|f(x_{k}^{i})|^ {2}+16L^{2}\gamma_{k+1}d\] \[\leq\frac{1}{2}\mathbb{E}[\left|\varepsilon_{k+1}^{i}\right|^{2} \left|\mathcal{F}_{k}\right|+16L^{2}\gamma_{k+1}^{2}|f(x_{k}^{i})|^{2}+16L^{2} \gamma_{k+1}d.\]

This implies that

\[\mathbb{E}[\left|\varepsilon_{k+1}^{i}\right|^{2}\left|\mathcal{F}_{k}\right| \leq 32L^{2}\gamma_{k+1}^{2}|f(x_{k}^{i})|^{2}+32L^{2}\gamma_{k+1}d.\]

Summing over \(i\) and observing that \(\sum\lvert f(x_{k}^{i})\rvert^{2}=|\bm{b}(x_{k})|^{2}\) concludes the proof.