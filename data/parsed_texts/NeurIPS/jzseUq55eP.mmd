# Metropolis Sampling for Constrained Diffusion Models

 Nic Fishman

University of Oxford

&Leo Klarner

University of Oxford

&Emile Mathieu

University of Cambridge

&Michael Hutchinson

University of Oxford

&Valentin De Bortoli

ENS Ulm

{njwfish,leojklarner}@gmail.com

###### Abstract

Denoising diffusion models have recently emerged as the predominant paradigm for generative modelling on image domains. In addition, their extension to Riemannian manifolds has facilitated a range of applications across the natural sciences. While many of these problems stand to benefit from the ability to specify arbitrary, domain-informed constraints, this setting is not covered by the existing (Riemannian) diffusion model methodology. Recent work has attempted to address this issue by constructing novel noising processes based on the reflected Brownian motion and logarithmic barrier methods. However, the associated samplers are either computationally burdensome or only apply to convex subsets of Euclidean space. In this paper, we introduce an alternative, simple noising scheme based on Metropolis sampling that affords substantial gains in computational efficiency and empirical performance compared to the earlier samplers. Of independent interest, we prove that this new process corresponds to a valid discretisation of the reflected Brownian motion. We demonstrate the scalability and flexibility of our approach on a range of problem settings with convex and non-convex constraints, including applications from geospatial modelling, robotics and protein design.

## 1 Introduction

In recent years, denoising diffusion models (Sohl-Dickstein et al., 2015; Song et al., 2019; Song et al., 2021; Ho et al., 2020) have emerged as a powerful paradigm for generative modelling, achieving state-of-the-art performance across a range of domains. They work by progressively adding noise to data following a Stochastic Differential Equation (SDE)--the forward _noising_ process--until it is close to the invariant distribution of the SDE. The generative model is then given by an approximation of the associated time-reversed _denoising_ process, which is also an SDE whose drift depends on the gradient of the logarithmic densities of the forward process, referred to as the _Stein score_. Building on the success of diffusion models for image generation tasks, De Bortoli et al. (2022) and Huang et al. (2022) have recently extended this framework to a wide range of Riemannian manifolds, enabling the specification of inherent structural properties of the modelled domain. This has broadened the applicability of diffusion models to problems in the natural and engineering sciences, including the conformational modelling of small molecules (Jing et al., 2022; Corso et al., 2022), proteins (Trippe et al., 2022; Watson et al., 2022; Yim et al., 2023) and robotic platforms (Urain et al., 2022).

However, in many data-scarce or safety-critical settings, researchers may want to restrict the modelled domain even further by specifying problem-informed constraints to make maximal use of limited experimental data or prevent unwanted behaviour (Morris, 2002; Han et al., 2006; Thiele et al., 2013; Lukens et al., 2020). As illustrated in Figure 1, such domain-informed constraints can be naturally represented as a _Riemannian manifold with boundary_. Training diffusion models on such constrained manifolds is thus an important problem that requires principled noising processes--and corresponding discretisations--that stay within the constrained set.

Recent work by Fishman et al. (2023) has attempted to derive such processes and extend the applicability of diffusion models to inequality-constrained manifolds by investigating the generative modelling applications of classic sampling schemes based on log-barrier methods (Kannan et al., 2009; Lee et al., 2017; Noble et al., 2022; Kook et al., 2022; Gatmiry et al., 2022; Lee et al., 2018) and the reflected Brownian motion (Williams, 1987; Petit, 1997; Shkolnikov et al., 2013). While empirically promising, the proposed algorithms can be computationally and numerically burdensome, and require bespoke implementations for different manifolds and constraints. Concurrently, Lou et al. (2023) have investigated the use of reflected diffusion models for image applications. They focus on the high-dimensional hypercube, as this setting admits a theoretically grounded treatment of the _static thresholding_ method which is widely used in image models such as Saharia et al. (2022). More recently, Liu et al. (2023) have investigated the use of log-barrier-based mirror maps to transform a constrained domain into an unconstrained dual space for applications in image watermarking. While both methods exhibit robust scaling properties and impressive results, they only consider convex subsets of Euclidean space and do not extend to more general manifolds.

Here, we propose a new method for generative modelling on constrained manifolds based on a Metropolis-based discretisation of the reflected Brownian motion. The Metropolised process' chief advantage is that it is lightweight: the only additional requirement over those outlined in De Bortoli et al. (2022) that is needed to implement a constrained diffusion model is an efficient binary function that indicates whether any given point is within the constrained set. This Metropolised approximation of the reflected Brownian motion is substantially easier to implement, faster to compute and more numerically stable than the previously considered sampling schemes. Our core theoretical contribution is to show that this new discretisation converges to the reflected SDE by using the invariance principle for SDEs with boundary (Stroock et al., 1971). To the best of our knowledge, this is the first time that such a process has been investigated. We demonstrate that our method attains improved empirical results on diverse manifolds with convex and non-convex constraints by applying it to a range of problems from geospatial modelling, robotics and protein design.

## 2 Background

Riemannian manifolds.A Riemannian manifold is defined as a tuple \((\mathcal{M},\mathfrak{g})\) with \(\mathcal{M}\) a smooth manifold and \(\mathfrak{g}\) a metric defining an inner product on tangent spaces. In this work, we will use the exponential map \(\exp_{x}:\mathrm{T}_{x}\mathcal{M}\to\mathcal{M}\), as well as the extension of the gradient \(\nabla\), divergence \(\mathrm{div}\) and Laplace \(\Delta\) operators to \(\mathcal{M}\). All of these quantities can be defined in local coordinates in terms of the metric. The extension of the Laplace operator to \(\mathcal{M}\) is called the Laplace-Beltrami operator, also denoted \(\Delta\) when there is no ambiguity. Using \(\Delta\), we can define a Brownian motion on \(\mathcal{M}\), denoted \((\mathbf{B}_{t})_{t\geq 0}\) and with density w.r.t. the volume form of \(\mathcal{M}\) denoted \(p_{t}\) for any \(t>0\). We refer to Appendix B for a more detailed exposition, to Lee (2013) for a thorough treatment of Riemannian manifolds and to Hsu (2002) for details on stochastic analysis on manifolds. In the following, we consider a constrained manifold \(\mathcal{M}\) defined by

\[\mathcal{M}=\{x\in\mathcal{N}\,:\,\,f_{i}(x)<0,\,\,i\in\mathcal{I}\},\] (1)

Figure 1: When operating in data-scarce settings, it may often be beneficial to specify as much prior knowledge of the modelled domain as possible. Consider a distribution over a subset \(\mathcal{M}\) of the unit sphere \(\mathcal{S}^{2}\subset\mathbb{R}^{3}\). While a Euclidean diffusion model can approximate the distribution in \(\mathbb{R}^{3}\) (a), directly modelling it on \(\mathcal{S}^{2}\) can make learning significantly easier (b). Restricting the problem space even further by only constructing a diffusion model on \(\mathcal{M}\) can lead to even better performance (c).

where \((\mathcal{N},\mathfrak{g})\) is a Riemannian manifold, \(\mathcal{I}\) is an arbitrary finite indexing family and for any \(i\in\mathcal{I}\), \(f_{i}\in\mathrm{C}(\mathcal{N},\mathbb{R})\). Since \(\mathcal{I}\) is finite and \(f_{i}\) continuous for any \(i\in\mathcal{I}\), \(\mathcal{M}\) is an open set of \(\mathcal{N}\) and inherits its metric \(\mathfrak{g}\). This captures simple Euclidean polytopes and complex constrained spaces like Figure 1.

Denoising diffusion models.Denoising diffusion models (Song et al., 2019; Ho et al., 2020; Song et al., 2021) work as follows: let \((\mathbf{X}_{t})_{t\in[0,T]}\) be a _noising process_ that corrupts the original data distribution \(p_{0}\). We assume that \((\mathbf{X}_{t})_{t\geq 0}\) converges to \(\mathrm{N}(0,\sigma^{2}\operatorname{Id})\), with \(\sigma>0\). Several such processes exist, but in practice we consider the Ornstein-Uhlenbeck (OU) process, also referred to as VP-SDE, which is defined by the following Stochastic Differential Equation (SDE)

\[\mathrm{d}\mathbf{X}_{t}=-\tfrac{1}{2}\mathbf{X}_{t}\mathrm{d}t+\sigma \mathrm{d}\mathbf{B}_{t},\qquad\mathbf{X}_{0}\sim p_{0}.\] (2)

Under conditions on \(p_{0}\), for any \(T>0\), \((\mathbf{Y}_{t})_{t\in[0,T]}=(\mathbf{X}_{T-t})_{t\in[0,T]}\) is also the (weak) solution to a SDE (Anderson, 1982; Haussmann et al., 1986; Cattiaux et al., 2021)

\[\mathrm{d}\mathbf{Y}_{t}=\{\tfrac{1}{2}\mathbf{Y}_{t}+\sigma^{2}\nabla\log p_ {T-t}(\mathbf{Y}_{t})\}\mathrm{d}t+\sigma\mathrm{d}\mathbf{B}_{t},\ \mathbf{Y}_{0}\sim p_{T},\] (3)

where \(p_{t}\) denotes the density of \(\mathbf{X}_{t}\). In practice, \(\nabla\log p_{t}\) is approximated with a score network \((t,x)\mapsto s_{\theta}(t,x)\) trained by minimising either a denoising score matching (\(\mathrm{dsm}\)) loss or an implicit score matching (\(\mathrm{issm}\)) loss (Vincent, 2011)

\[\ell(\theta)=\mathbb{E}_{t\sim\mathcal{U}([0,T]),(\mathbf{X}_{a},\mathbf{X}_ {t})}[\lambda_{t}(\tfrac{1}{2}\|s_{\theta}(t,\mathbf{X}_{t})\|^{2}+\mathrm{ div}(s_{\theta})(t,\mathbf{X}_{t}))],\] (4)

where \(\lambda_{t}>0\). For a flexible score network, the global minimiser \(\theta^{\star}=\operatorname*{argmin}_{\theta}\mathcal{L}(\theta)\) satisfies \(s_{\theta^{\star}}(t,\cdot)=\nabla\log p_{t}\). De Bortoli et al. (2022) and Huang et al. (2022) have extended denoising diffusion models to the Riemannian setting. The time-reversal formula (3) remains the same, replacing the Euclidean gradient with its Riemannian equivalent. The \(\mathrm{ism}\) loss can still be computed in that setting. However, the samplers used in the Riemannian setting differ from the classical Euler-Maruyama discretisation used in the Euclidean framework. De Bortoli et al. (2022) use Geodesic Random Walks (Jorgensen, 1975), which ensure that the samples remain on the manifold at every step. In this paper, we propose a sampler with similar properties in the case of _constrained_ manifolds.

Reflected SDE.We conclude this section by recalling the framework for studying reflected SDEs, which is introduced via the notion of the _Skorokhod problem_. For simplicity, we focus on Euclidean space \(\mathbb{R}^{d}\) here, but note that reflected processes can be defined on arbitrary smooth manifolds \(\mathcal{N}\). In the case of the Brownian motion, a solution to the Skorokhod problem is a process of the form \((\bar{\mathbf{B}}_{t},\mathbf{k}_{t})_{t\geq 0}\). Locally, \((\bar{\mathbf{B}}_{t})_{t\geq 0}\) can be seen as a regular Brownian motion \((\mathbf{B}_{t})_{t\geq 0}\) while \((\mathbf{k}_{t})_{t\geq 0}\) forces \((\bar{\mathbf{B}}_{t})_{t\geq 0}\) to remain in \(\mathcal{M}\). Under mild additional regularity conditions on \(\mathcal{M}\) and \((\bar{\mathbf{B}}_{t},\mathbf{k}_{t})_{t\geq 0}\), see Skorokhod (1961), \((\bar{\mathbf{B}}_{t},\mathbf{k}_{t})_{t\geq 0}\) is a solution to the _Skorokhod problem_ if for any \(t\geq 0\)

\[\bar{\mathbf{B}}_{t}=\bar{\mathbf{B}}_{0}+\mathbf{B}_{t}-\mathbf{k}_{t}\in \mathcal{M},\] (5)

\(\left|\mathbf{k}\right|_{t}=\int_{0}^{t}\mathbf{1}_{\bar{\mathbf{B}}_{t}\in \partial\mathcal{M}}\mathrm{d}\left|\mathbf{k}\right|_{s}\) and \(\mathbf{k}_{t}=\int_{0}^{t}\mathbf{n}(\bar{\mathbf{B}}_{s})\mathrm{d}\left| \mathbf{k}\right|_{s},\) where \((\left|\mathbf{k}\right|_{t})_{t\geq 0}\) is the total variation of \((\mathbf{k}_{t})_{t\geq 0}\)1. Let us provide some intuition on this definition. When \((\bar{\mathbf{B}}_{t})_{t\geq 0}\) hits the boundary \(\partial\mathcal{M}\), \(-\mathbf{k}_{t}\) pushes the process back into \(\mathcal{M}\) along the inward normal \(-\mathbf{n}(\bar{\mathbf{B}}_{t})\), according to \(\mathbf{k}_{t}=\int_{0}^{t}\mathbf{n}(\bar{\mathbf{B}}_{s})\mathrm{d}\left| \mathbf{k}\right|_{s}\).

Footnote 1: In this case \((\mathbf{k}_{t})_{t\geq 0}\) is not regular enough, but if it were in the class \(\mathrm{C}^{1}\), its total variation would be given by \(\int_{0}^{t}\lvert\partial_{t}\mathbf{k}_{t}\rvert\mathrm{d}s\) in the one-dimensional case.

Figure 2: Visual comparison of a discretisation of the unconstrained Brownian motion (blue) and two discretisations of the reflected Brownian motion: one based on a reflection scheme (green) and the other based on our Metropolis sampler (red). The Metropolised trajectory is very close to that of the reflected one while being significantly easier to implement and cheaper to compute.

The condition \(|\mathbf{k}|_{t}=\int_{0}^{t}\mathbf{1}_{\bar{\mathbf{B}}_{s}\in\partial\mathcal{M }}\mathrm{d}|\mathbf{k}|_{s}\) is more technical and can be seen as imposing that \(\mathbf{k}_{t}\) remains constant so long as \((\bar{\mathbf{B}}_{t})_{t\geq 0}\) does not hit \(\partial\mathcal{M}\). We refer to Fishman et al. (2023) and Lou et al. (2023) for a more thorough introduction of these concepts in the context of diffusion models.

## 3 Diffusion models for constrained manifolds via Metropolis sampling

In Section 3.1, we highlight the practical limitations of existing constrained diffusion models and propose an alternative Metropolis sampling-based approach. In Section 3.2, we outline our proof that this process corresponds to a valid discretisation of the reflected Brownian motion, justifying its use in diffusion models. An overview of the samplers we cover in this section is presented in Table 1.

### Practical limitations of existing constrained diffusion models

Barrier methods.In the barrier approach, a constrained manifold is transformed into an unconstrained space via a barrier metric. This metric is defined by \(\nabla^{2}\phi(x)\) with \(\phi(x)=\sum_{i\in T}\phi_{i}(d(x,f_{i}))\) where \(d(x,f_{i})\) is the minimum distance from the point \(x\) to the set defined by \(f_{i}(x)=0\) and \(\phi_{i}\) is a monotonically decreasing function such that \(\lim_{z\to 0}\phi_{i}(z)=\infty\). Under additional regularity assumptions, \(\phi\) is called a _barrier function_ (see Nesterov et al. (1994)). This definition ensures that the barrier function induces a well-defined exponential map on the manifold, making the Riemannian diffusion model frameworks of De Bortoli et al. (2022) and Huang et al. (2022) applicable. In the log-barrier method of Fishman et al. (2023), evaluating \(\phi\) requires computing \(d(x,\partial\mathcal{M})\) (and its derivatives), which can be prohibitively expensive. Furthermore, since the exponential map under the induced manifold is difficult to compute, it is approximated by projecting the exponential map on the original manifold back onto the constraint set, incurring an additional bias. Liu et al. (2023) propose a more tractable method by constructing a mirror map that transforms a constrained domain into an unconstrained dual space, in which one can train a standard Euclidean diffusion model. However, this approach is only applicable to convex subsets of \(\mathbb{R}^{d}\) and does not extend to arbitrary Riemannian manifolds. More generally, warping the geometry of the modelled domain can adversely impact the interpolative performance of log-barrier-based diffusion models, as the space between data points expands rapidly when approaching the boundary.

Reflected stochastic processes.Fishman et al. (2023) and Lou et al. (2023) introduce diffusion models based on the _reflected Brownian motion_ (RBM). In Fishman et al. (2023), the reflected SDE is discretised by (i) considering a classical step of the Euler-Maruyama discretization (or the Geodesic Random Walk in the Riemannian setting) and (ii) reflecting this step according to the boundary defined by \(\partial\mathcal{M}\). To compute the reflection, one must check whether the step crosses the boundary. If it does, the point of intersection needs to be calculated in order to reflect the ray and continue the step in the reflected direction. This can require an arbitrarily large number of reflections depending on the step size, the geodesic on the manifold, and the geometry of the bounded region within the manifold. We refer to Appendix C for the pseudocode of the reflection step and additional comments. An alternative approach to discretising a reflected SDE is to replace the reflection with a projection (Slominski, 1994). However, the projection requires the most expensive part of the reflection algorithm: computing the intersection of the geodesic with the boundary. Lou et al. (2023) propose a more tractable approach that exploits the product structure of the unit hypercube to afford simulation-free sampling but does not extend to arbitrary Riemannian manifolds. Additionally, specifying convex constraints in their framework requires a bijection onto the hypercube, distorting the modelled geometry and incurring the same issues as outlined above.

Figure 3: Evolution of the density of the reflected Brownian motion and its Metropolis sampling-based approximation on the unit interval starting from a delta mass.

Metropolis approximation.Existing approaches to constrained (Riemannian) diffusion models either only apply to convex subsets of \(\mathbb{R}^{d}\) or require manifold- and constraint-specific implementations that become computationally intractable as the complexity of the modelled geometry increases. This limits their practicality even for relatively simple manifolds with well-defined exponential maps and linear inequality constraints such as for example polytopes. In the following, we introduce a method that aims to solve both of these problems. The sampler we propose is similar to a classical Euler-Maruyama discretisation of the Brownian motion, except that, whenever a step would carry the Brownian motion out of the constrained region, we reject it (see Algorithm 1). This is a _Metropolised_ version of the usual discretisation and is trivial to implement compared to the existing barrier, reflection and projection methods. Hence, this method enables the principled extension of diffusion models to arbitrarily constrained manifolds at virtually _no added implementational complexity or computational expense_.

### Relating the Metropolis sampler to the reflected Brownian motion

In this section, we prove that the proposed Metropolis sampling-based process (Algorithm 1) corresponds to a valid discretisation of the reflected process, justifying its use in diffusion models. Here we focus on a concise presentation of the core concepts and the main results. A full proof can be found in Appendix D. For simplicity, we restrict ourselves to the Euclidean setting. All of our results require particular assumptions on \(\mathcal{M}\), which we discuss at the end of this section. We begin with a definition of the Metropolis approximation of RBM.

**Definition 1**.: _For any \(\gamma>0\) and \(k\in\mathbb{N}\), let \(X_{0}^{\gamma}\in\mathcal{M}\) and \(X_{k+1}^{\gamma}=X_{k}^{\gamma}+\sqrt{\gamma}Z_{k}^{\gamma}\) if \(X_{k}^{\gamma}+\sqrt{\gamma}Z_{k}^{\gamma}\in\mathcal{M}\) and \(X_{k}^{\gamma}\) otherwise. The sequence \((X_{k}^{\gamma})_{k\in\mathbb{N}}\) is called the Metropolis approximation of RBM._

For any \(\gamma>0\), we consider \((\mathbf{X}_{t}^{\gamma})_{t\geq 0}\), the linear interpolation of \((X_{k}^{\gamma})_{k\in\mathbb{N}}\) such that for any \(k\in\mathbb{N}\), \(\mathbf{X}_{k\gamma}^{\gamma}=X_{k}^{\gamma}\). The following result is the main theoretical contribution of our paper.

**Theorem 2**.: _Under assumptions on \(\mathcal{M}\), for any \(T\geq 0\), \((\mathbf{X}_{t}^{\gamma})_{t\in[0,T]}\) weakly converges to the RBM \((\tilde{\mathbf{B}}_{t})_{t\in[0,T]}\) as \(\gamma\to 0\)._

The rest of the section is devoted to a high level presentation of the proof of Theorem 2. It is theoretically impractical to work directly with the Metropolis approximation of RBM. Instead, we introduce an auxiliary process, show this converges to the RBM, and finally prove that the convergence of the auxiliary process implies the convergence of our Metropolis discretisation.

**Definition 3**.: _For any \(\gamma>0\) and \(k\in\mathbb{N}\), let \(\hat{X}_{0}^{\gamma}=x\in\mathcal{M}\) and \(\hat{X}_{k+1}^{\gamma}=\hat{X}_{k}^{\gamma}+\sqrt{\gamma}Z_{k}^{\gamma}\) with \(Z_{k}^{\gamma}\) a Gaussian random variable conditioned on \(\hat{X}_{k}^{\gamma}+\sqrt{\gamma}Z_{k}^{\gamma}\in\mathcal{M}\). The sequence \((\hat{X}_{k}^{\gamma})_{k\in\mathbb{N}}\) is called the Rejection approximation of RBM._

\begin{table}
\begin{tabular}{l c c c c} \hline \hline \multirow{2}{*}{**Diffusion Model**} & \multicolumn{2}{c}{Broth required for fast DSM loss} & \multirow{2}{*}{\begin{tabular}{c} Modelling \\ domain \\ \end{tabular} } & \multirow{2}{*}{
\begin{tabular}{c} Preserves \\ metric of \(\mathcal{M}\) \\ \end{tabular} } \\ \hline Reflected Diffusions & & & & \\ Lou et al. (2023) & ✓ & ✓ & convex \(\subset\mathbb{R}^{d}\) & ✗ \\ Fishman et al. (2023) & ✗ & \(\mathcal{O}(d^{2})\) & Any \(\mathcal{M}\) & ✓ \\ Metropolis (ours) & ✗ & \(\mathcal{O}(d)\) & Any \(\mathcal{M}\) & ✓ \\ \hline Barrier Diffusions & & & & \\ Fishman et al. (2023) & ✗ & ✗ & convex \(\subset\) any \(\mathcal{M}\) & ✗ \\ Liu et al. (2023) & ✓ & ✓ & convex \(\subset\mathbb{R}^{d}\) & ✗ \\ \hline \hline \end{tabular}
\end{table}
Table 1: Comparison of the advantages and disadvantages of the different constrained (Riemannian) diffusion models covered in Section 3.1.

We call this process _Rejection approximation of RBM_ since in practice, \(Z_{k}^{\gamma}\) is sampled using rejection sampling, see Algorithm 2. For any \(\gamma>0\), we also consider \((\hat{\mathbf{X}}_{t}^{\gamma})_{t\geq 0}\), the linear interpolation of \((\hat{X}_{k}^{\gamma})_{k\in\mathbb{N}}\) such that for any \(k\in\mathbb{N}\), \(\hat{\mathbf{X}}_{k\gamma}^{\gamma}=\hat{X}_{k}^{\gamma}\). In Appendix D, we prove the following result.

**Theorem 4**.: _Under assumptions on \(\mathcal{M}\), for any \(T\geq 0\), \((\hat{\mathbf{X}}_{t}^{\gamma})_{t\in[0,T]}\) weakly converges to the Reflected Brownian Motion \((\tilde{\mathbf{B}}_{t})_{t\in[0,T]}\) as \(\gamma\to 0\)._

Proof.: Here we give some elements of the proof. Details and full derivations are postponed to Appendix D. Our approach is based on the invariance principle of Stroock et al. (1971). More precisely, we show that we can compute an equivalent 'drift' and 'diffusion matrix' for the discretised process and that, as \(\gamma\to 0\), the drift converges to zero and the diffusion matrix converges to \(\mathrm{Id}\). In the Euclidean setting, this result, accompanied by mild regularity and growth assumptions, ensures that the discretization weakly converges to the original SDE. However, the case with boundary is much more complicated, primarily because the approximate drift might explode near the boundary, thus we need to verify exactly how the drift behaves as \(\gamma\to 0\) and as the process approaches the boundary. We show that the _normalised_ drift converges to the inward normal near the boundary. This ensures that (a) in the interior of \(\mathcal{M}\) the drift converges to zero, i.e. locally in the interior of \(\mathcal{M}\) the Brownian motion and the Reflected Brownian Motion coincide, (b) on the boundary, the drift pushes the samples inside the manifold according to the inward normal, mimicking \((\mathbf{k}_{t})_{t\geq 0}\) in (5). Finally, with results from Stroock et al. (1971) and Kang et al. (2017), we show the convergence to the RBM. 

Our next step is to show that the approximate drift and diffusion matrix of the Metropolised process are upper and lower bounded by their counterparts in the rejection process. While the upper-bound is easy to derive, the lower-bound requires the following result.

**Proposition 5**.: _Under assumptions on \(\mathcal{M}\), \(\forall\;\varepsilon>0\), \(\exists\;\bar{\gamma}>0\) such that for any \(\gamma\in(0,\bar{\gamma})\) and for any \(x\in\mathcal{M}\), \(\gamma\in(0,\bar{\gamma})\) and \(Z\sim\mathrm{N}(0,\mathrm{Id})\) we have \(\mathbb{P}(x+\sqrt{\gamma}Z\in\mathcal{M})\geq 1/2-\varepsilon\), with \(Z\sim\mathrm{N}(0,\mathrm{Id})\)._

Proposition 5 tells us that _locally_ the boundary looks like a half-space when integrating w.r.t. a Gaussian measure. A corollary is that, for \(\gamma>0\) small enough and for any \(k\in\mathbb{N}\), the probability that \(X_{k+1}^{\gamma}=X_{k}^{\gamma}\) is upper bounded _uniformly_ w.r.t. \(X_{k}^{\gamma}\in\mathcal{M}\). The proof of Proposition 5 uses Theorem 7 in Appendix D, whose proof relies on the concept of _tubular neighborhoods_(Lee et al., 2012).

Having established the lower and upper bound, we can conclude the proof by noting that the approximate drift and the diffusion matrix in the rejection and Metropolis case coincide as \(\gamma\to 0\). This is enough to apply the same results as before, giving the desired convergence.

Assumptions on \(\mathcal{M}\).Before concluding this section, we detail the assumptions we make on \(\mathcal{M}\). For Theorem 2 to hold, we assume that \(\mathcal{M}=\{x\in\mathbb{R}^{d}\;:\;\Phi(x)>0\}\) is bounded, with \(\Phi\in\mathrm{C}^{2}(\mathbb{R}^{d},\mathbb{R})\) concave. We have that \(\partial\mathcal{M}=\{x\in\mathbb{R}^{d}\;:\;\Phi(x)=0\}\). In addition, we assume that for any \(x\in\partial\mathcal{M}\), \(\|\nabla\Phi(x)\|=1\). These assumptions match those Stroock et al. (1971) use for their study of the existence of solutions to the RBM. While it seems possible to relax the _global_ existence of \(\Phi\) to a _local_ one, the regularity assumption of the domain is key. This regularity is essential to establish Proposition 5 and the associated geometrical result on tubular neighbourhoods. We also emphasize that the smoothness of the domain is central in the results of Kang et al. (2017) on the equivalence of two definitions of RBMs which we rely on.

```
0:\(p\in\mathcal{M}\), \(\{f_{i}\}_{i\in\mathcal{I}}\) Sample \(\bm{v}\sim\mathrm{N}(0,\mathrm{Id})\in\mathrm{T}_{p}\mathcal{M}\)\(p^{\prime}\leftarrow\exp_{p}(\bm{v})\) while\(f_{i}(p^{\prime})\geq 0\) for any \(i\)do  Sample \(\bm{v}\sim\mathrm{Id}(0,1)\in\mathrm{T}_{p}\mathcal{M}\)\(p^{\prime}\leftarrow\exp_{p}(\bm{v})\) endwhile return\(p^{\prime}\) ```

**Algorithm 2**_Rejection approx. of RBM_

## 4 Related work on approximations of reflected SDEs

Several schemes have been introduced to approximately sample from reflected Stochastic Differential Equations. They can be interpreted as modifications of classical Euler-Maruyama schemes used to discretise SDEs without boundary. One of the most common approaches is to use the Euler-Maruyama discretisation and project the solution onto the boundary if it escapes from the domain \(\mathcal{M}\).

In this case, mean-square error rates of order _almost_\(1/2\) have been proven under various conditions (Liu, 1995; Chitashvili et al., 1981; Pettersson, 1995; Slominski, 1994). Concretely this means that \(\mathbb{E}[\|\mathbf{\dot{B}}_{t}-X_{n}^{t/n}\|^{2}]=O(n^{-1+\varepsilon})\) with \(\varepsilon>0\) arbitrary small and where \((X_{k}^{\gamma})_{k\in\mathbb{N}}\) is the projection scheme. The rate \(1/2\) is tight (Pacchiarotti et al., 1998). It is possible to use the Euler-Peano method to get slight improvements for a mean-square error rate of order of \(1/2\), but this is impractical as it assumes that one can solve a (simplified) Skorokhod problem, which is usually intractable. Liu (1993) introduced a _penalised_ method which pushes the solution away from the boundary and shows a mean-square error of order \(1/4\), see also Pettersson (1997). Weak errors of order \(1\) have been obtained in Bossy et al. (2004) and Gobet (2001) by introducing a reflection component in the discretisation or using some local approximation of the domain to a half-space. We refer to Pilipenko (2014) for an introduction to the discretisation of reflected SDEs. Closer to our work, Burdzy et al. (2008) consider three different methods to approximate reflected Brownian motions on general domains (two based on discrete methods and one based on killed diffusions). Only qualitative results are provided. To the best of our knowledge, no previous work in the probability literature has investigated the _Metropolised_ scheme we propose. Our Metropolis scheme is also related to the ball walk (Applegate et al., 1991), which replaces the Gaussian random variable with a uniform over the ball (or the Dikin ellipsoid). Applegate et al. (1991) and Lovasz et al. (2007) have studied the asymptotic convergence rate of the ball walk, but, to the best of our knowledge, its limiting behaviour when the step size goes to zero has not been investigated.

\begin{table}
\begin{tabular}{c c c c c c} \hline \hline \multirow{2}{*}{Manifold} & \multirow{2}{*}{Dimension} & \multicolumn{2}{c}{Reflected} & \multicolumn{2}{c}{Metropolis} \\  & & log-likelihood & runtime & log-likelihood & runtime \\ \hline \multirow{3}{*}{\([-1,1]^{d}\)} & 2 & \(2.25_{\pm.01}\) & \(8.95\) & \(\mathbf{2.32}_{\pm.05}\) & \(\mathbf{0.72}\) \\  & 3 & \(3.77_{\pm.13}\) & \(8.97\) & \(\mathbf{4.15}_{\pm.15}\) & \(\mathbf{0.71}\) \\  & 10 & \(7.42_{\pm.77}\) & \(10.1\) & \(\mathbf{10.80}_{\pm.34}\) & \(\mathbf{0.90}\) \\ \hline \multirow{3}{*}{\(\Delta^{d}\)} & 2 & \(1.01_{\pm.01}\) & \(9.17\) & \(\mathbf{1.06}_{\pm.02}\) & \(\mathbf{0.82}\) \\  & 3 & \(2.64_{\pm.01}\) & \(9.43\) & \(\mathbf{3.23}_{\pm.17}\) & \(\mathbf{0.78}\) \\ \cline{1-1}  & 10 & \(7.00_{\pm.13}\) & \(10.5\) & \(\mathbf{7.81}_{\pm.20}\) & \(\mathbf{0.97}\) \\ \hline \hline \end{tabular}
\end{table}
Table 2: Log-likelihood (\(\uparrow\)) of a held-out test set from a synthetic bimodal distribution over convex subsets of \(\mathbb{R}^{d}\) bounded by the hypercube \([-1,1]^{d}\) and unit simplex \(\Delta^{d}\). Means and standard deviations are computed over 3 different runs. Average training time is provided in hours.

Figure 4: Convergence time of the Reflected (green) and Metropolis (red) forward noising processes to the uniform distribution on the hypercube \([-1,1]^{d}\) and unit simplex \(\Delta^{d}\). The lines indicate functions fit with the PySR symbolic regression package (Cranmer, 2023) and correspond to empirical runtime complexities of \(\mathcal{O}(d^{2})\) and \(\mathcal{O}(d)\), respectively, matching the superimposed scaling law isocontours.

## 5 Experimental results

To demonstrate the practical utility and empirical performance of the proposed Metropolis diffusion models, we conduct a comprehensive evaluation on a range of synthetic and real-world tasks. In Section 5.1, we assess the scalability of our method by applying it to synthetic distributions on hypercubes and simplices of increasing dimensionality. In Section 5.2, we extend the evaluation to real-world tasks on manifolds with convex constraints by applying our method to the robotics and protein design datasets presented in Fishman et al. (2023). In Section 5.3, we additionally demonstrate that our method extends to constrained manifolds with highly _non-convex_ boundaries--a setting that is intractable with existing approaches.

As we found--in line with Fishman et al. (2023)--that log-barrier diffusion models perform strictly worse than reflected approaches across all experimental settings, we focus on a more detailed comparison with the latter here and postpone additional empirical results to Appendix F.1. These include additional performance metrics and a comparison to an unconstrained Euclidean diffusion model on the synthetic datasets presented in Section 5.1.

For all experiments, we use a simple 6-layer MLP with sine activations and a score rescaling function to ensure that the score reaches zero at the boundary, scaling linearly into the interior of the constrained set as in Liu et al. (2022) and Fishman et al. (2023). We set \(T=1\), \(\beta_{0}=1\times 10^{-3}\) and tune \(\beta_{1}\) to ensure that the forward process reaches the invariant distribution with a linear \(\beta\)-schedule. We use a learning rate of \(2\times 10^{-4}\) with a cosine learning rate schedule and an \(\mathrm{ism}\) loss with a modified loss weighting function of \((1+t)\), a batch size of 1024 and 8 repeats per batch. All models were trained on a single NVIDIA GeForce GTX 1080 GPU. Additional details are provided in Appendix F.2.

All source code that is needed to reproduce the results presented below is made available under https://github.com/oxcsml/score-sde/tree/metropolis, which requires a supporting package to handle the different geometries that is available under https://github.com/oxcsml/geomstats/tree/polytope.

### Synthetic distributions on simple polytopes

In this section, we investigate the scalability of the proposed Metropolis diffusion models by applying them to synthetic bimodal distributions over the \(d\)-dimensional hypercube \([-1,1]^{d}\) and unit simplex \(\Delta^{d}\). A quantitative comparison of the log-likelihood of a held-out test set is presented in Table 2, while a visual comparison is postponed to Appendix F.3. We find that our Metropolis models outperform reflected approaches across all dimensions and constraint geometries by a substantial and statistically significant margin while training in one tenth of the time. The degree of improvement seems to scale with the dimensionality of the problem: the larger the dimension of the experiment, the larger the gain in performance from using our proposed Metropolis scheme.

We observe a similar difference in the scaling properties of reflected and Metropolis models when measuring the convergence times of the respective forward noising processes to the uniform distribution on hypercubes \([-1,1]^{d}\) and simplices \(\Delta^{d}\) of increasing dimensionality. The results are presented in Section 4 and show that the convergence time of the Metropolis process scales linearly in the dimension, while the reflected process scales quadratically.

Figure 5: A qualitative visual comparison of \(10^{6}\) samples from the data distribution, our Metropolis diffusion model, a reflected diffusion model and the uniform distribution for the constrained configurational modelling of robotic arms on \(\mathcal{S}^{2}_{++}\times\mathbb{R}^{2}\).

### Modelling proteins and robotic arms under convex constraints

In addition to illustrating our method's scalability on high-dimensional synthetic tasks, we follow the experimental setup from Fishman et al. (2023) to additionally demonstrate its practical utility and favourable empirical performance on two real-world problems from robotics and protein design.

Constrained configurational modelling of robotic arms.The problem of modelling the configurations and trajectories of a robotic arm can be formulated as learning a distribution over the locations and manipulability ellipsoids of its joints, parameterised on \(\mathbb{R}^{d}\times\mathcal{S}^{d}_{++}\), where \(\mathcal{S}^{d}_{++}\) is the manifold of symmetric positive-definite (SPD) \(d\times d\) matrices (Yoshikawa, 1985; Jaquier et al., 2021). For practical robotics applications, it may be desirable to restrict the maximal velocity with which a robotic arm can move or the maximum force it can exert. This manifests in a trace constraint \(C>0\) on \(\mathcal{S}^{d}_{++}\), resulting in a constrained manifold \(\{M\in\mathcal{S}^{d}_{++}:\sum_{i=1}^{d}M_{ii}<C\}\). Following Fishman et al. (2023), we parametrise this constraint via the Cholesky decomposition (Lin, 2019) and use the resulting setup to model the dataset presented in Jaquier et al. (2021).

Conformational modelling of protein backbones.Modelling the conformational ensembles of proteins is a data-scarce problem with a range of important applications in biotechnology and drug discovery (Lane, 2023). In many practical settings, it may often be unnecessary to model the structural ensembles of an entire protein, as researchers are primarily interested in specific functional sites that are embedded in a structurally conserved scaffold (Huang et al., 2016). Modelling the conformational ensembles of such substructural elements requires positional constraints on their endpoints to ensure that they can be accommodated by the remaining protein. Using the parametrisation and dataset presented in Fishman et al. (2023), we formulate the problem of modelling the backbone conformations of a cyclic peptide of length \(N=6\) as learning a distribution over the product of a polytope \(\mathbb{P}\subset\mathbb{R}^{3}\) and the hypertorus \(\mathbb{T}^{4}\).

We quantify the empirical performance of different methods by evaluating the log-likelihood of a held-out test set and present the resulting performance metrics in Table 3. Again, we find that our Metropolis model outperforms the reflected approach by a statistically significant margin while training 7-8 times as fast. Qualitative visual comparisons of samples from the true distribution, the trained diffusion models and the uniform distribution are presented in Figures 5 and 6, with full univariate marginal and pairwise bivariate correlation plots postponed to Appendices F.4 and F.5.

\begin{table}
\begin{tabular}{c c c c c c} \hline \hline Dataset & Domain & \multicolumn{2}{c}{Reflected} & \multicolumn{2}{c}{Metropolis} \\  & & log-likelihood & runtime & log-likelihood & runtime \\ \hline Robotics & \(\mathcal{S}^{2}_{++}\times\mathbb{R}^{2}\) & \(8.39_{\pm.06}\) & \(9.52\) & \(\mathbf{9.13_{\pm.03}}\) & \(\mathbf{1.36}\) \\ Proteins & \(\mathbb{P}\subset\mathbb{R}^{3}\times\mathbb{T}^{4}\) & \(15.20_{\pm.06}\) & 24.80 & \(\mathbf{15.33_{\pm.02}}\) & \(\mathbf{3.12}\) \\ \hline \hline \end{tabular}
\end{table}
Table 3: Log-likelihood (\(\uparrow\)) of a held-out test set for the robotics and protein applications. Means and standard deviations are computed over 3 different runs. Average training time is provided in hours.

Figure 6: A qualitative comparison of \(10^{5}\) samples from the data distribution, our Metropolis diffusion model, a reflected diffusion model and the uniform distribution for the constrained conformational modelling of cyclic peptide backbones. For visual clarity, the figures only show the constrained planar projections encoded by \(\mathbb{P}\subset\mathbb{R}^{3}\).

### Modelling geospatial data within non-convex country borders

Motivated by the strong empirical performance of our approach on tasks with challenging convex constraints, we investigated its ability to model distributions whose support is restricted to manifolds with highly non-convex boundaries--a setting that is intractable with existing approaches. To this end, we derived a geospatial dataset based on wildfire incidence rates within the continental United States (see Appendix E for full details) and trained a Metropolis diffusion model constrained by the corresponding country borders on the sphere \(\mathcal{S}^{2}\). A qualitative visual comparison of samples from the true distribution, our model, and the uniform distribution is presented in Figures 6(a) to 6(c) and a quantitative comparison to a Riemannian diffusion model on \(\mathcal{S}^{2}\)(De Bortoli et al., 2022) is given in Table 4. Both demonstrate that our approach is able to successfully capture challenging multimodal and sparse distributions on constrained manifolds with highly non-convex boundaries.

## 6 Conclusion

Accurately modelling distributions on constrained Riemannian manifolds is a challenging problem with a range of impactful practical applications. In this work, we have proposed a mathematically principled and computationally tractable extension of existing diffusion model methodology to this setting. Based on a _Metropolisation_ of random walks in Euclidean spaces and on Riemannian manifolds, we have shown that our approach corresponds to a valid discretisation of the reflected Brownian motion, justifying its use in diffusion models. To demonstrate the practical utility of our method, we have performed an extensive empirical evaluation, showing that it outperforms existing constrained diffusion models on a range of synthetic and real-world tasks defined on manifolds with convex boundaries, including applications from robotics and protein design. Leveraging the flexibility and simplicity of our method, we have also demonstrated that it extends beyond convex constraints and is able to successfully model distributions on manifolds with highly non-convex boundaries. While we found our method to perform well across the synthetic and real-world applications we considered, we expect it to perform poorly on certain constraint geometries. For instance, the current implementation relies on an isotropic noise distribution which could impede its performance on exceedingly narrow constraint geometries, even with correspondingly small step sizes. In this context, an important direction of future research would be to investigate whether we can instead sample from more suitable distributions, e.g. a Dikin ellipsoid, while maintaining the simplicity and efficiency of the Metropolis approach.

\begin{table}
\begin{tabular}{c c c c c} \hline \hline Model & Domain & MMD & runtime & \% in boundary \\ \hline Unconstrained & \(\mathcal{S}^{2}\) & \(0.1567\pm 0.013\) & \(\mathbf{0.81}\) & \(63.3\) \\ Metropolis & \(\mathbb{P}\subset\mathcal{S}^{2}\) & \(\mathbf{0.1388\pm 0.015}\) & \(3.86\) & \(\mathbf{100.0}\) \\ \hline \hline \end{tabular}
\end{table}
Table 4: MMD (\(\downarrow\)) of a held-out test set for the geospatial modelling dataset. Means and standard deviations are computed over 3 different runs. Average training time is provided in hours.

Figure 7: Orthographic projection of \(10^{5}\) samples from (a) the data distribution, (b) our Metropolis diffusion model, and (c) the uniform distribution, for geospatial data (wildfire incidence rates) within a non-convex boundary (the continental United States). The projections are aligned with the geometric centre of the boundary and zoomed in ten-fold for visual clarity.

## Acknowledgements

NF thanks the Rhodes Trust for supporting their studies at Oxford and this work. LK acknowledges support from the University of Oxford's Clarendon Fund.

## References

* Anderson (1982) B. D. Anderson. Reverse-time diffusion equation models. _Stochastic Processes and their Applications_, 12(3):313-326, 1982. Cited on page 3.
* Applegate and Kannan (1991) Sampling and integration of near log-concave functions. In Proceedings of the twenty-third annual ACM symposium on Theory of computing, pp. 156-163. Cited on page 3.
* Bednar et al. (2023) J. A. Bednar, J. Crail, J. Crist-Harif, P. Rudiger, G. Brener, I. Thomas, C. B, J. Mease, J. Signell, M. Liquet, J. Stevens, B. Collins, A. Thorve, Uuydotm, S. H. Hansen, esc, kbowen, N. Abdennur, O. Smirnov, maihde, A. Hawley, A. Oriekhov, A. Ahmadia, B. A. B. Jr, C. H. Brandt, C. Tolboom, E. G., E. Welch, J. Bourbeau, and J. J. Schmidt. Holoviz/datashader: version 0.14.4, version v0.14.4, Feb. 2023. External Links: 10.5281/zenodo.7599872, Link Cited by: SS1.
* Bevis and Chatelain (1989) Locating a point on a spherical surface relative to a spherical polygon of arbitrary shape. Mathematical geology21, pp. 811-828. Cited by: SS1.
* Bossy, Egobet, and Talay (2004) A symmetrized euler scheme for an efficient approximation of reflected diffusions. Journal of applied probability41 (3), pp. 877-889. Cited by: SS1.
* Burdzy and Chen (2008) Discrete approximations to reflected brownian motion. Cited by: SS1.
* Cattiaux, Conforti, I. Gentil, and C. Leonard (2021) Time reversal of diffusion processes under a finite entropy condition. arXiv preprint arXiv:2104.07708. Cited by: SS1.
* Chitashvili and Lazrieva (1981) Strong solutions of stochastic differential equations with boundary conditions. Stochastics: an international journal of probability and stochastic processes5 (4), pp. 255-309. Cited by: SS1.
* Corso, Stark, Bing, and Barzilay (2022) DiffDock: diffusion steps, twists, and turns for molecular docking. External Links: Link Cited by: SS1.
* Cranmer (2023) Interpretable machine learning for science with psr and symbolicregression. jl. arXiv preprint arXiv:2305.01582. Cited by: SS1.
* De Bortoli, Mathieu, Hutchinson, J. Thornton, Y. W. Teh, and A. Doucet (2022) Riemannian score-based generative modeling. External Links: 2202.02763, Link Cited by: SS1.
* Fishman, L. Klarner, V. De Bortoli, E. Mathieu, and M. Hutchinson (2023) Diffusion models for constrained domains. arXiv preprint arXiv:2304.05364. Cited by: SS1.
* Gatmiry and Vempala (2022) Convergence of the riemannian langevin algorithm. arXiv preprint arXiv:2204.10818. Cited by: SS1.
* E. Gobet (2001) Euler schemes and half-space approximation for the simulation of diffusion in a domain. ESAIM: Probability and Statistics5, pp. 261-297. Cited by: SS1.
* A. Gretton, K. M. Borgwardt, M. J. Rasch, B. Scholkopf, and A. Smola (2012) A kernel two-sample test. Journal of Machine Learning Research13 (null), pp. 723-773. External Links: ISSN 1532-4435, Link, Document Cited by: SS1.
* L. Han and L. Rudolph (2006) Inverse kinematics for a serial chain with joints under distance constraints. In Robotics: Science and systems, Vol., Cited by: SS1.

U. G. Haussmann and E. Pardoux. Time reversal of diffusions. _The Annals of Probability_:1188-1205, 1986. Cited on page 3.
* Ho et al. (2020)J. Ho, A. Jain, and P. Abbeel. Denoising diffusion probabilistic models. _Advances in Neural Information Processing Systems_, 2020. Cited on pages 1, 3.
* Hsu (2002)E. P. Hsu. _Stochastic analysis on manifolds_, number 38. American Mathematical Soc., 2002. Cited on page 2.
* Huang et al. (2022)C. Huang, M. Aghajohari, A. J. Bose, P. Panangaden, and A. Courville. Riemannian Diffusion Models, Aug. 2022. doi: 10.48550/arXiv.2208.07949. Cited on pages 1, 3.
* Huang et al. (2016)P. Huang, S. E. Boyken, and D. Baker. The coming of age of de novo protein design. _Nature_, 537(7620):320-327, 2016. Cited on page 9.
* Jaquier et al. (2021)N. Jaquier, L. Rozo, D. G. Caldwell, and S. Calinon. Geometry-aware manipulability learning, tracking, and transfer. _The International Journal of Robotics Research_, 40(2-3):624-650, 2021. Cited on page 9.
* Jing et al. (2022)B. Jing, G. Corso, J. Chang, R. Barzilay, and T. Jaakkola. Torsional Diffusion for Molecular Conformer Generation, June 2022. url: http://arxiv.org/abs/2206.01729. Cited on page 1.
* Jorgensen (1975)E. Jorgensen. The central limit problem for geodesic random walks. _Zeitschrift fur Wahrscheinlichkeitstheorie und verwandte Gebiete_, 32(1-2):1-64, 1975. Cited on page 3.
* Kang and Ramanan (2017)W. Kang and K. Ramanan. On the submartingale problem for reflected diffusions in domains with piecewise smooth boundaries, 2017. Cited on pages 6, 4.
* Kannan and Narayanan (2009)Ramond walks on polytopes and an affine interior point method for linear programming. In _Proceedings of the Forty-First Annual ACM Symposium on Theory of Computing_, STOC '09, Bethesda, MD, USA. Association for Computing Machinery, 2009. ISBN: 9781605585062. doi: 10.1145/1536414.1536491. url: https ://doi.org/10.1145/1536414.1536491. Cited on page 2.
* Ketzner et al. (2022)R. Ketzner, V. Ravindra, and M. Bramble. A robust, fast, and accurate algorithm for point in spherical polygon classification with applications in geoscience and remote sensing. _Computers & Geosciences_, 167:105185, 2022. Cited on pages 15, 16.
* Kook et al. (2022)Y. Kook, Y. T. Lee, R. Shen, and S. S. Vempala. Sampling with riemannian hamiltonian monte carlo in a constrained space. _arXiv preprint arXiv:2202.01908_, 2022. Cited on page 2.
* Lane (2023)T. J. Lane. Protein structure prediction has reached the single-structure frontier. _Nature Methods_:1-4, 2023. Cited on page 9.
* Laurent and Massart (2000)B. Laurent and P. Massart. Adaptive estimation of a quadratic functional by model selection. _Annals of Statistics_:1302-1338, 2000. Cited on page 6.
* Lee (2013)J. M. Lee. Smooth manifolds. In _Introduction to Smooth Manifolds_, pages 1-31. Springer, 2013. Cited on pages 2.
* Lee and Lee (2012)J. M. Lee. _Smooth manifolds_. Springer, 2012. Cited on pages 6, 4.
* Lee and Vempala (2018)Y. T. Lee and S. S. Vempala. Convergence rate of riemannian hamiltonian monte carlo and faster polytope volume computation. In _Proceedings of the 50th Annual ACM SIGACT Symposium on Theory of Computing_, pages 1115-1121, 2018. Cited on page 2.
* Lee and Vempala (2017)Y. T. Lee and S. S. Vempala. Geodesic walks in polytopes. In _Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing_, Montreal Canada. ACM, June 2017. ISBN: 978-1-4503-4528-6. doi: 10.1145/3055399.3055416. Cited on page 2.
* Lin (2019)Z. Lin. Riemannian geometry of symmetric positive definite matrices via cholesky decomposition. _SIAM Journal on Matrix Analysis and Applications_, 40(4):1353-1370, 2019. Cited on pages 9, 2.
* Liu et al. (2023)G. Liu, T. Chen, E. A. Theodorou, and M. Tao. Mirror diffusion models for constrained and watermarked generation. _arXiv preprint arXiv:2310.01236_, 2023. Cited on pages 2.

[MISSING_PAGE_FAIL:13]

A. V. Skorokhod. Stochastic equations for diffusion processes in a bounded region. _Theory of Probability & Its Applications_, 6(3):264-274, 1961. Cited on page 3.
* S. M. A. Rubin and J. A. Rubin (1992)A stochastic model for diffusion processes with applications to diffusion processes. In 1992 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1993)A stochastic model for diffusion processes with applications to diffusion processes. In 2003 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1994)A stochastic model for diffusion processes with applications to diffusion processes. In 2004 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1995)A stochastic model for diffusion processes with applications to diffusion processes. In 2005 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1996)A stochastic model for diffusion processes with applications to diffusion processes. In 2006 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1997)A stochastic model for diffusion processes with applications to diffusion processes. In 2007 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1998)A stochastic model for diffusion processes with applications to diffusion processes. In 2008 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes with applications to diffusion processes with applications to diffusion processes with applications to diffusion processes with applications to diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes with applications to diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin, and J. A. Rubin (1999)A stochastic model for diffusion processes with applications to diffusion processes with applications to diffusion processes with applications to diffusion processes with applications to diffusion processes with applications to diffusion processes with applications to diffusion processes with applications to diffusion processes with applications to diffusion processes with applications to diffusion processes. In 2009 IEEE International Conference on Decision and Control (CDC), Vol. 1, pp. 1-10. Cited by: SS1.
* J. A. Rubin, D. J. A. Rubin,

**Supplementary to:**

**Metropolis Sampling for Constrained Diffusion Models**

## Appendix A Overview

In Appendix B, we recall some basic concepts of Riemannian geometry which are key to defining discretisations of the reflected Brownian motion. In Appendix C, we give some details on the reflection step in reflected discretizations. In Appendix D, we prove the convergence of the rejection and Metropolis discretizations to the true reflected Brownian Motion. The geospatial dataset with non-convex constraints based on wildfire incidence rates in the continental United States is presented Appendix E. All supplementary experimental details and empirical results are gathered in Appendix F.

## Appendix B Manifold concepts

In the following, we aim to introduce key concepts that underpin diffusion models on Riemannian manifolds, with a particular focus on notions relevant to the reflected Brownian motion that we build on in Appendix C. For a more thorough treatment with reference to reflected diffusion models, we refer to (Fishman et al., 2023). For a detailed presentation of smooth manifolds, see Lee (2013).

A Riemannian manifold is a tuple \((\mathcal{M},\mathfrak{g})\) with \(\mathcal{M}\) a smooth manifold and \(\mathfrak{g}\) a metric that imbues the manifold with a notion of distance and curvature and is defined as a smooth positive-definite inner product on each of the tangent spaces of the manifold:

\[\mathfrak{g}(p):\mathrm{T}_{p}\mathcal{M}\times\mathrm{T}_{p}\mathcal{M} \rightarrow\mathbb{R}.\]

The tangent space \(\mathrm{T}_{p}\) of a point \(p\) on a manifold is an extension of the notion of tangent planes and can be thought of as the space of derivatives of scalar functions on the manifold at that point.

To establish how different tangent spaces relate to one another, we need to additionally introduce the concept of a _connection_. This is a map that takes two vector fields and produces a derivative of the first with respect to the second, typically written as \(\nabla(X,Y)=\nabla_{X}Y\). While there are infinitely many connections on any given manifold, the _Levi-Cevita_ emerges as a natural choice if we impose the following two conditions:

1. \(X\cdot(\mathfrak{g}(Y,Z))=\mathfrak{g}(\nabla_{X}Y,Z)+\mathfrak{g}(Y,\nabla_ {X}Z)\),
2. \([X,Y]=\nabla_{X}Y-\nabla_{Y}X\),

where \([\cdot,\cdot]\) is the Lie bracket. These conditions ensure that the connection is (i) metric-preserving and (ii) torsion-free, with the latter guaranteeing a unique connection and integrability on the manifold.

Using the metric and Levi-Cevita connection, we can define a number of key concepts:

Geodesic._Geodesics_ extend the Euclidean notion of'straight lines' to manifolds. They are defined as the unique path \(\gamma:(0,1)\rightarrow\mathcal{M}\) such that \(\nabla_{\gamma^{\prime}}\gamma^{\prime}=0\) and are the shortest path between two points on a manifold, in the sense that \(L(\gamma)=\int_{0}^{1}\sqrt{\mathfrak{g}(\gamma(t))(\gamma^{\prime}(t),\gamma (t))}\mathrm{d}t\) is minimal.

Exponential map.The _exponential map_ on a manifold is given by the mapping between an element \(\bm{v}\in T_{p}\mathcal{M}\) of the tangent space at point \(p\) and the endpoint of the unique geodesic \(\gamma\) with \(\gamma(0)=p\) and \(\gamma^{\prime}(0)=\bm{v}\).

Intersection.The _intersection_ along a geodesic is the first point at which the geodesic intersects the boundary. We recall that the boundary is defined by \(f=0\). We can define this via an optimisation problem: compute the minimum \(t>0\) such that we have that \(\exp_{\mathfrak{g}}(x,tz)\) is a root of \(f\): \(f(\exp_{\mathfrak{g}}(x,tz))=0\). We will say that \(\exp_{\mathfrak{g}}(x,tz)=\operatorname{intersect}_{\mathfrak{g}}(x,z;f)\) and that \(t=\operatorname{arg\,intersect}_{\mathfrak{g}}(x,z;f)\).

[MISSING_PAGE_FAIL:16]

``` Require:\(T,N,X_{0}^{\gamma},\{f_{i}\}_{i\in\mathcal{I}}\) \(\gamma=T/N\) for\(k\in\{0,\ldots,N-1\}\)do \(Z_{k+1}\sim\mathrm{N}(0,\mathrm{Id})\) \(X_{k+1}^{\gamma}=\text{ReflectedStep}[X_{k}^{\gamma},\sqrt{\gamma}Z_{k+1},\{f_{i} \}_{i\in\mathcal{I}}]\) endfor return\(\{X_{k}^{\gamma}\}_{k=0}^{N}\) ```

**Algorithm 4**_Reflected Random Walk_. Discretisation of the SDE \(\mathrm{d}\mathbf{X}_{t}=b(t,\mathbf{X}_{t})\mathrm{d}t+\mathrm{d}\mathbf{B}_{t }-\mathrm{d}\mathbf{k}_{t}\).

Convergence to the reflected process

In this note, we assume that \(\mathcal{M}=\{x\in\mathbb{R}^{d}\,:\ \Phi(x)>0\}\) is compact, with \(\Phi\in\mathrm{C}^{2}(\mathbb{R}^{d},\mathbb{R})\). We have that \(\partial\mathcal{M}=\{x\in\mathbb{R}^{d}\,:\ \Phi(x)=0\}\). In addition, we assume that for any \(x\in\partial\mathcal{M}\), \(\|\nabla\Phi(x)\|=1\) and that \(\Phi\) is concave. The closure of \(\mathcal{M}\) is denoted \(\overline{\mathcal{M}}\). The assumption that \(\Phi\) is concave is only used in Theorem 7-(d) and can be dropped. We consider it for simplicity.

Let \((\hat{X}_{k}^{\gamma})_{k\in\mathbb{N}}\) given for any \(\gamma>0\) and \(k\in\mathbb{N}\) by \(\hat{X}_{0}^{\gamma}=x\in\overline{\mathcal{M}}\) and for \(\hat{X}_{k+1}^{\gamma}=\hat{X}_{k}^{\gamma}+\sqrt{\gamma}Z_{k}^{\gamma}\) with \(Z_{k}^{\gamma}\) a Gaussian random variable conditioned on \(\hat{X}_{k}^{\gamma}+\sqrt{\gamma}Z_{k}^{\gamma}\in\overline{\mathcal{M}}\). In practice, \(Z_{k}^{\gamma}\) is sampled using rejection sampling. We define \(\hat{\mathbf{X}}^{\gamma}:\mathbb{R}_{+}\to\overline{\mathcal{M}}\) given for any \(k\in\mathbb{N}\) by \(\hat{\mathbf{X}}_{k\gamma}^{\gamma}=\hat{X}_{k}^{\gamma}\) and for any \(t\in[k\gamma,(k+1)\gamma)\), \(\hat{\mathbf{X}}_{t}^{\gamma}=\hat{X}_{k}^{\gamma}\). Note that \((\mathbf{X}_{t})_{t\in[0,T]}\) is a \(\mathrm{D}([0,T]\,,\overline{\mathcal{M}})\) valued random variable, where \(\mathrm{D}([0,T]\,,\overline{\mathcal{M}})\) is the space of right-continuous with left-limit processes which take values in \(\overline{\mathcal{M}}\). We denote \(\hat{\mathbb{P}}^{\gamma}\) the distribution of \((\hat{\mathbf{X}}_{t}^{\gamma})_{t\in[0,T]}\) on \(\mathrm{D}([0,T]\,,\overline{\mathcal{M}})\).

Our goal is to show the following theorem.

**Theorem 6**.: _For any \(T\geq 0\), \((\hat{\mathbf{X}}_{t}^{\gamma})_{t\in[0,T]}\) weakly converges to \((\mathbf{X}_{t})_{t\in[0,T]}\) such that for any \(t\in[0,T]\)_

\[\mathbf{X}_{t}=x+\mathbf{B}_{t}-\mathbf{k}_{t},\qquad|\mathbf{k}|_{t}=\int_{0} ^{t}\mathbbm{1}_{\mathbf{X}_{s}\in\partial\mathcal{M}}\mathrm{d}|\mathbf{k}|_{ s},\qquad\mathbf{k}_{t}=\int_{0}^{t}\mathbf{n}(\mathbf{X}_{s})\mathrm{d}| \mathbf{k}|_{s}.\] (6)

Proof.: In order to prove the result, we prove that the distribution of the Markov chain seen as an element of \(\mathrm{D}([0,T]\,,\overline{\mathcal{M}})\) converges to a solution of the Skorokhod problem (6). In particular, we first show that the limiting distribution satisfies a submartingale problem following (Storock et al., 1971, Theorem 6.3). The transition from a solution of a submartingale problem to a weak solution of the Skorokhod problem is given by (Kang et al., 2017, Theorem 1, Proposition 2.12) and (Ramanan, 2006, Corollary 2.10). In order to apply (Storock et al., 1971, Theorem 6.3), we define an intermediate drift and diffusion matrix, see (55) and (51). To prove the theorem one needs to control the drift and diffusion matrix inside \(\mathcal{M}\) and show that it converges to \(0\) and \(\mathrm{Id}\) respectively. The technical part of the proof comes from the control of the drift coefficient near the boundary. In particular, we show that if the intermediate drift is large then we are close to the boundary and the intermediate drift is pointing inward. To investigate the local properties of the drift near the boundary we rely on the notion of tubular neighborhood, see (Lee et al., 2012, Theorem 6.24). 

Some key properties of the tubular neighborhood are stated in Appendix D.1. We then establish a few technical lemmas about the tail probability of some distributions in Appendix D.2. Controls on the diffusion matrix and lower bounds on the probability of belonging in \(\mathcal{M}\) are given in Appendix D.3. Properties of large drift terms are given in Appendix D.4. The convergence of the drift and diffusion matrix on compact sets is given in Appendix D.5. The convergence of the boundary terms is investigated in Appendix D.6. Finally, we conclude the proof in Appendix D.7.

### Properties of the tubular neighborhood

Using the results of (Lee et al., 2012), we establish the existence of an open set of \(\overline{\mathcal{M}}\) (for the induced topology of \(\mathbb{R}^{d}\)) satisfying several important properties.

**Theorem 7**.: _There exist \(\mathsf{U}\subset\overline{\mathcal{M}}\) open and \(C\geq 1,\bar{r}>0\) such that for any \(\gamma\in(0,\bar{\gamma})\) with \(\bar{\gamma}=1\) the following properties hold:_

1. _For any_ \(x\in\mathsf{U}\)_, there exist a unique_ \(\bar{x}\in\partial\mathcal{M}\) _and_ \(\bar{\alpha}>0\) _such that_ \(x=\bar{x}+\bar{\alpha}\nabla\Phi(\bar{x})\)_._
2. _For any_ \(\bar{\alpha}\in[0,\bar{r}]\) _and_ \(\bar{x}\in\partial\mathcal{M}\) _such that_ \(\bar{x}+\bar{\alpha}\nabla\Phi(\bar{x})\in\overline{\mathcal{M}}\)_, let_ \(x=\bar{x}+\bar{\alpha}\nabla\Phi(\bar{x})\) _and_ \(\mathsf{C}(x,\gamma)\) _such that_ \(x+\sqrt{\gamma}z\in\mathsf{C}(x,\gamma)\) _if_ \[-\bar{\alpha}\gamma^{-1/2}\leq\alpha<\bar{r}\gamma^{-1/2},\qquad\|v\|^{2}\leq( \alpha\gamma^{1/2}+\bar{\alpha})/(C\gamma),\] (7) _with_ \(z=\alpha\nabla\Phi(\bar{x})+v\)_, with_ \(v\perp\nabla\Phi(\bar{x})\)_. Then_ \(\mathsf{C}(x,\gamma)\subset\overline{\mathcal{M}}\)_._
3. \(\mathsf{V}=\{\bar{x}+\alpha\nabla\Phi(\bar{x})\,:\ \bar{x}\in\partial\mathcal{M},\ \alpha\in[0,\bar{r})\}\) _is open in_ \(\overline{\mathcal{M}}\)_._
4. _For any_ \(x\in\mathsf{U}\)_,_ \(x+\sqrt{\gamma}z\in\overline{\mathcal{M}}\cap\mathsf{C}(x,\gamma)^{c}\) _then_ \(\alpha\geq\bar{r}\gamma^{-1/2}\) _or_ \(\|v\|^{2}\geq(\alpha\gamma^{1/2}+\bar{\alpha})/(C\gamma)\) _and_ \(\alpha\gamma^{1/2}+\bar{\alpha}\geq 0\)_, with_ \(z=\alpha\nabla\Phi(\bar{x})+v\)_, with_ \(\bar{x}\) _given in (a) and_ \(v\perp\nabla\Phi(\bar{x})\)_._.__._
* _There exists_ \(R>0\) _such that_ \(\{x\in\overline{\mathcal{M}}\,:\ d(x,\partial\mathcal{M})\leq 2R\}\subset\mathsf{V}\)_._

Proof.: Let \(\gamma\in(0,\bar{\gamma})\) with \(\bar{\gamma}=1\). First, note that for any \(\bar{x}\in\partial\mathcal{M}\), the normal space is given by \(\{\alpha\nabla\Phi(\bar{x})\,:\ \alpha\in\mathbb{R}\}\). Using this result and (Lee et al., 2012, Theorem 6.24) there exists \(\tilde{r}_{0}>0\) such that \(\mathsf{U}_{0}=\{\bar{x}+\alpha\nabla\Phi(\bar{x})\,:\ \bar{x}\in\partial\mathcal{M},\ \alpha\in(-\tilde{r}_{0}, \tilde{r}_{0})\}\subset\mathbb{R}^{d}\) is open2. We have that for any \(\alpha\in[-r_{0},0)\) and \(\bar{x}\in\partial\mathcal{M}\)

Footnote 2: This is the tubular neighborhood theorem which is key to the rest of the proof.

\[\Phi(\bar{x}+\alpha\nabla\Phi(\bar{x})) =\Phi(\bar{x})+\alpha\|\nabla\Phi(\bar{x})\|^{2}+\int_{0}^{1} \nabla^{2}\Phi(\bar{x}+t\alpha\nabla\Phi(\bar{x}))(\alpha\nabla\Phi(\bar{x})) ^{\otimes 2}\mathrm{d}t\] (8) \[\leq\alpha+\tilde{C}_{0}\alpha^{2}<0,\] (9)

with \(r_{0}=\min(\tilde{r}_{0},1/(2\tilde{C}_{0}))\), where we have used that \(\Phi(\bar{x})=0\), \(\|\nabla\Phi(\bar{x})\|=1\) and defined \(\tilde{C}_{0}=\sup\{\|\nabla^{2}\Phi(\bar{x}+\alpha\nabla\Phi(\bar{x}))\|\,: \ \bar{x}\in\partial\mathcal{M},\ \alpha\in[-\tilde{r}_{0},\tilde{r}_{0}]\}\). Reciprocally, we have for any \(\alpha\in[0,r_{0})\) and \(\bar{x}\in\partial\mathcal{M}\)

\[\Phi(\bar{x}+\alpha\nabla\Phi(\bar{x}))=\Phi(\bar{x})+\alpha\| \nabla\Phi(\bar{x})\|^{2}+\int_{0}^{1}\nabla^{2}\Phi(\bar{x}+t\alpha\nabla\Phi (\bar{x}))(\alpha\nabla\Phi(\bar{x}))^{\otimes 2}\mathrm{d}t\geq\alpha-C_{0} \alpha^{2},\] (10)

where we have used that \(\Phi(\bar{x})=0\), \(\|\nabla\Phi(\bar{x})\|=1\) and defined \(C_{0}=\sup\{\|\nabla^{2}\Phi(\bar{x}+\alpha\nabla\Phi(\bar{x}))\|\,:\ \bar{x}\in\partial \mathcal{M},\ \alpha\in[-r_{0},r_{0}]\}\). Let \(r_{1}=\min(r_{0},1/(2C_{0}))\). Then, \(\mathsf{U}_{1}=\{\bar{x}+\alpha\nabla\Phi(\bar{x})\,:\ \bar{x}\in\partial \mathcal{M},\ \alpha\in(-r_{1},r_{1})\}\subset\mathbb{R}^{d}\) is open and

\[\mathsf{U}_{1}\cap\overline{\mathcal{M}}=\{\bar{x}+\alpha\nabla \Phi(\bar{x})\,:\ \bar{x}\in\partial\mathcal{M},\ \alpha\in[0,r_{1})\}.\] (11)

In what follows, we define \(\mathsf{U}=\mathsf{U}_{1}\cap\overline{\mathcal{M}}\). Note that \(\mathsf{U}\) is open for the induced topology and that \(\partial\mathcal{M}\subset\mathsf{U}\). In particular, \(\partial\mathcal{M}\) is compact, \(\mathsf{U}^{\rm c}\) is closed and \(\partial\mathcal{M}\cap\mathsf{U}^{\rm c}=\varnothing\). Hence, there exists \(r>0\) such that \(d(\partial\mathcal{M},\mathsf{U}^{\rm c})\geq 4r\). Without loss of generality we can assume that \(r\leq 1/2\). We also have \(\{x\in\overline{\mathcal{M}}\,:\ d(x,\partial\mathcal{M})\leq 2r\}\subset\mathsf{U}\). The proof of (a) follows from the definition of \(\mathsf{U}_{0}\). In the rest of the proof, we define

\[C^{1/2}=2\max(1,\sup\{\|\nabla^{2}\Phi(\bar{x}+u)\|\,:\ \bar{x}\in\partial \mathcal{M},\,\|u\|^{2}\leq r(r+1)\}),\quad\bar{r}=\min(1/(2C^{1/2}),r/2).\] (12)

Let us prove (b). Consider \(x+\sqrt{\bar{\gamma}}z\in\mathsf{C}(x,\gamma)\) with \(\mathsf{C}(x,\gamma)\) given by (7) and \(x=\bar{x}+\bar{\alpha}\nabla\Phi(\bar{x})\) and \(z=\alpha\nabla\Phi(\bar{x})+v\) with \(v\perp\nabla\Phi(\bar{x})\). In particular, we recall that we have

\[-\bar{\alpha}\gamma^{-1/2}\leq\alpha<\bar{r}\gamma^{-1/2},\qquad\|v\|^{2}\leq( \alpha\gamma^{1/2}+\bar{\alpha})/(C\gamma).\] (13)

This implies that

\[\bar{\alpha}+\sqrt{\bar{\gamma}}\alpha\leq 2\bar{r},\qquad\gamma\|v\|^{2}\leq 2 \bar{r}/C.\] (14)

First, using that \(C\geq 1\), \(\|\nabla\Phi(\bar{x})\|=1\), (14) and (12), we have

\[\|x+\sqrt{\bar{\gamma}}z-\bar{x}\|^{2}=(\bar{\alpha}+\sqrt{\bar{ \gamma}}\alpha)^{2}+\gamma\|v\|^{2}\leq r^{2}+r/C\leq r(r+1).\] (15)

Then, we have that

\[\Phi(x+\sqrt{\bar{\gamma}}z) =\Phi(\bar{x})+\bar{\alpha}+\sqrt{\bar{\gamma}}\alpha+\int_{0}^{1} \nabla^{2}\Phi(\bar{x}+t(x+\sqrt{\bar{\gamma}}z-\bar{x}))(x+\sqrt{\bar{\gamma} }z-\bar{x})^{\otimes 2}\mathrm{d}t\] (16) \[\geq\bar{\alpha}+\sqrt{\bar{\gamma}}\alpha-(C^{1/2}/2)((\bar{ \alpha}+\sqrt{\bar{\gamma}}\alpha)^{2}+\gamma\|v\|^{2}),\] (17)

where we recall that

\[C^{1/2}=2\max(1,\sup\{\|\nabla^{2}\Phi(\bar{x}+u)\|\,:\ \bar{x}\in\partial \mathcal{M},\,\|u\|^{2}\leq r(r+1)\}),\qquad\bar{r}=\min(1/(2C^{1/2}),r/2).\] (18)

First, using that \(r\leq 1/2\) and (14), we have \(\bar{\alpha}+\sqrt{\bar{\gamma}}\alpha\leq 2r\leq 1\). Since, \(\|v\|^{2}\leq(\bar{\alpha}+\sqrt{\bar{\gamma}}\alpha)/(C\gamma)\) and we have that \(\|v\|^{2}<1/(C\gamma)\). Let \(P(X)=X-(C^{1/2}/2)X^{2}-(C^{1/2}/2)\gamma\|v\|^{2}\). We have that \(P(x)\geq 0\) if and only if \(x\in[x_{\min},x_{\max}]\) with

\[x_{\min}=(1-(1-C\gamma\|v\|^{2})^{1/2})/C^{1/2},\qquad x_{\max}=(1+(1-C\gamma\|v \|^{2})^{1/2})/C^{1/2}.\] (19)

Using that for any \(t\in(0,1)\), \((1-t)^{1/2}\geq 1-t\) we have that

\[x_{\min}\leq\gamma C\|v\|^{2}/2,\qquad x_{\max}\geq 1/C^{1/2}.\] (20)Since \(\|v\|^{2}\leq(\sqrt{\gamma}\alpha+\bar{\alpha})/(\gamma C)\), we have that \(\bar{\alpha}+\sqrt{\gamma}\alpha\geq x_{\min}\). In addition, using that \(\bar{\alpha}+\sqrt{\gamma}\alpha\leq 2\bar{r}\leq 1/C^{1/2}\leq x_{\max}\), we get that \(P(\bar{\alpha}+\sqrt{\gamma}\alpha)\geq 0\) and therefore \(x+\sqrt{\gamma}z\in\overline{\mathcal{M}}\) since \(\Phi(x+\sqrt{\gamma}z)\geq 0\). This concludes the proof of (b). Note that the condition \(\alpha\geq-\gamma^{-1/2}\bar{\alpha}\) is implied by the condition \(\|v\|^{2}\leq(\sqrt{\gamma}\alpha+\bar{\alpha})/(\gamma C)\). Using that \(\mathsf{V}\subset\{x\in\overline{\mathcal{M}}\,:\,d(x,\partial\mathcal{M}) \leq 2r\}\subset\mathsf{U}\), (c) is a direct consequence of (Lee et al., 2012, Theorem 6.24)]. Next, we prove (d). Let \(x+\sqrt{\gamma}z\in\overline{\mathcal{M}}\cap\mathsf{C}(x,\gamma)^{c}\). If \(\alpha<-\bar{\alpha}\gamma^{-1/2}\) then since \(\Phi\) is concave, we have

\[\Phi(x+\sqrt{\gamma}z)=\Phi(\bar{x})+\bar{\alpha}+\sqrt{\gamma} \alpha+\int_{0}^{1}\nabla^{2}\Phi(\bar{x}+t(x+\sqrt{\gamma}z-\bar{x}))(x+ \sqrt{\gamma}z-\bar{x})^{\otimes 2}\mathrm{d}t<0,\] (21)

where we have used that \(\Phi(\bar{x})=0\). This is absurd, hence either \(\alpha\geq\bar{r}\gamma^{-1/2}\) or \(\|v\|^{2}\geq(\alpha\gamma^{1/2}+\bar{\alpha})/(C\gamma)\) and \(\alpha\gamma^{1/2}+\bar{\alpha}\geq 0\), which concludes the proof. The proof of (e) is similar to the proof that \(\{x\in\overline{\mathcal{M}}\,:\,\,d(x,\partial\mathcal{M})\leq 2r\}\subset \mathsf{U}\). 

The main message of Theorem 7 is that using Theorem 7-(d), if we move in the direction of \(\nabla\Phi(\bar{x})\) (the inward normal) with magnitude \(\alpha\) then we are allowed to move in the orthonormal direction with magnitude \(\alpha^{1/2}\). In the next paragraph, we discuss this fact in details and shows it is necessary for the rest of our study.

The necessity of Theorem 7-(b).At first sight one can wonder if the statement of Theorem 7-(b) could be simplify. In particular, it would be simpler to replace this statement with: for any \(\bar{\alpha}\in[0,\bar{r}]\) and \(\bar{x}\in\partial\mathcal{M}\) such that \(\bar{x}+\bar{\alpha}\nabla\Phi(\bar{x})\in\overline{\mathcal{M}}\), let \(x=\bar{x}+\bar{\alpha}\nabla\Phi(\bar{x})\) and \(\mathsf{C}(x,\gamma)\) such that \(x+\sqrt{\gamma}z\in\mathsf{C}(x,\gamma)\) if

\[-\bar{\alpha}\gamma^{-1/2}\leq\alpha<\bar{r}\gamma^{-1/2},\qquad\|v\|^{2}\leq( \alpha\gamma^{1/2}+\bar{\alpha})^{2}/(C\gamma),\] (22)

with \(z=\alpha\nabla\Phi(\bar{x})+v\), with \(v\perp\nabla\Phi(\bar{x})\). Then \(\mathsf{C}(x,\gamma)\subset\overline{\mathcal{M}}\). Note that \(\|v\|^{2}\leq(\alpha\gamma^{1/2}+\bar{\alpha})/(C\gamma)\) is replaced by \(\|v\|^{2}\leq(\alpha\gamma^{1/2}+\bar{\alpha})^{2}/(C\gamma)\), see Figure 8 for an illustration. However, in that case Theorem 7-(d) becomes: in addition, if \(x+\sqrt{\gamma}z\in\overline{\mathcal{M}}\cap\mathsf{C}(x,\gamma)^{c}\) then \(\alpha\geq r\gamma^{-1/2}\) or \(\|v\|^{2}\geq(\alpha\gamma^{1/2}+\bar{\alpha})^{2}/(C\gamma)\) and \(\alpha\gamma^{1/2}+\bar{\alpha}\geq 0\).

In what follows, when controlling the properties of large drift, see the proof of Proposition 18 and the proof of Proposition 21, we need to control quantities of the form \(\mathbb{P}(x+\sqrt{\gamma}Z\in\mathsf{C}(x,\gamma)^{c}\cap\overline{\mathcal{ M}})/\sqrt{\gamma}\)3 Using the original Theorem 7-(d) it is possible to show that this quantity is bounded. However, if one uses the updated version of Theorem 7-(d) then one needs to show that there exists \(M\geq 0\) and \(\bar{\gamma}>0\) such that for any \(\gamma\in(0,\bar{\gamma})\) (here we have assumed that \(\bar{\alpha}=0\), i.e. \(x\in\partial\mathcal{M}\) for simplicity)

Footnote 3: The division by \(\sqrt{\gamma}\) comes from the definition of the intermediate drift (55).

\[\int_{0}^{r/\gamma^{-1/2}}\int_{\nabla\Phi(\bar{x})^{\perp}}\mathbbm{1}_{\|v \|^{2}\geq\alpha^{2}}\varphi(v)\varphi(\alpha)\mathrm{d}v\mathrm{d}\alpha\leq M \sqrt{\gamma},\] (23)

which is absurd.

### Technical lemmas

We start with a few technical lemmas which will allow us to control some Gaussian probabilities outside of a compact set. We denote \(\Psi:\mathbb{R}_{+}\times\mathbb{N}\to[0,1]\) such that for any \(k\in\mathbb{N}\), \(\Psi(\cdot,k)\) is the tail probability of a \(\chi\)-squared random variable with parameter \(k\), i.e. for any \(k\in\mathbb{N}\) and \(t\geq 0\) we have

\[\Psi(t,k)=\mathbb{P}(\|Z\|^{2}\geq t),\] (24)

with \(Z\) a Gaussian random variable in \(\mathbb{R}^{k}\) with zero mean and identity covariance matrix. We will make extensive use of the following lemma which is a direct consequence of (Laurent et al., 2000, Section 4, Lemma 1).

**Lemma 8**.: _For any \(k\in\mathbb{N}\) and \(t\in\mathbb{R}_{+}\) with \(t\geq 5k\), \(\Psi(t,k)\leq\exp[-t/5]\)._

Proof.: Let \(k\in\mathbb{N}\). First, note that for any \(x\geq k\), we have that \(k+2(kx)^{1/2}+2x\leq 5x\). Combining this result and (Laurent et al., 2000, Section 4, Lemma 1, Equation (4.3)), we have that for any \(x\geq k\)

\[\mathbb{P}(\|X\|^{2}\geq 5x)\leq\exp[-x],\] (25)

with \(X\) a \(\mathbb{R}^{k}\)-valued Gaussian random variable with zero mean and identity covariance matrix. This concludes the proof upon letting \(t=5x\)Let \(\varphi:\ \mathbb{R}^{p}\rightarrow\mathbb{R}_{+}\) given for any \(u\in\mathbb{R}\) by \(\varphi(u)=(2\uppi)^{-p/2}\exp[-\|u\|^{2}/2]\)4, i.e. the density of a real Gaussian random variable with zero mean and unit variance. While Lemma 9 appears technical, it will be central to provide quantitative upper bounds on the _rejection_ probability, see Lemma 12 for instance.

Footnote 4: In the rest of the supplementary, we never precise the dimension \(p\in\mathbb{N}\) which can be deduced from the variable.

**Lemma 9**.: _For any \(k\in\mathbb{N}\), \(\alpha_{0}>0\), \(\beta_{0}\in(0,1]\) and \(\delta>0\) we have_

\[\psi(\delta)=\sup\{\int_{0}^{+\infty}\Psi(\alpha_{0}t/\delta,k)^{\beta_{0}} \varphi(t-t_{0}/\delta)\mathrm{d}t\,:\ t_{0}\geq 0\}\leq C_{0}\delta,\] (26)

_with \(C_{0}=5(2\uppi)^{-1/2}(k+1)/(\alpha_{0}\beta_{0})\)._

Proof.: Let \(k\in\mathbb{N}\), \(\alpha_{0}>0\), \(\beta_{0}\in(0,1]\) and \(\delta>0\). Let \(t_{\delta}=5k\delta/\alpha_{0}\). Note that if \(t\geq t_{\delta}\) then, \(\alpha_{0}t/\delta\geq 5k\). In addition, we have

\[\int_{0}^{+\infty}\Psi(\alpha_{0}t/\delta,k)^{\beta_{0}}\varphi(t -t_{0}/\delta)\mathrm{d}t \leq(2\uppi)^{-1/2}\int_{0}^{+\infty}\Psi(\alpha_{0}t/\delta,k)^{ \beta_{0}}\mathrm{d}t\] (27) \[\leq(2\uppi)^{-1/2}\int_{0}^{t_{\delta}}\Psi(\alpha_{0}t/\delta,k)^{\beta_{0}}\mathrm{d}t+(2\uppi)^{-1/2}\int_{t_{\delta}}^{+\infty}\Psi( \alpha_{0}t/\delta,k)^{\beta_{0}}\mathrm{d}t.\] (28)

Using that for any \(w>0\), \(\int_{0}^{+\infty}\exp[-wt]\mathrm{d}t\leq(1/w)\), that for any \(u\geq 0\), \(\Psi(u,k)\leq 1\) and that if \(u\geq 5k\), \(\Psi(u,k)\leq\exp[-u/5]\), we get for any \(t_{0}\geq 0\)

\[\int_{0}^{+\infty}\Psi(\alpha_{0}t/\delta,k)\varphi(t-t_{0}/\delta)\leq(2 \uppi)^{-1/2}[5k\delta/\alpha_{0}+5\delta/(\alpha_{0}\beta_{0})]\leq(5(2\uppi )^{-1/2}(k+1)/(\alpha_{0}\beta_{0}))\delta,\] (29)

which concludes the proof. 

Finally, we have the following lemma, which is similar to Lemma 8 but will be used to control quantities related to the norm.

**Lemma 10**.: _For any \(k\in\mathbb{N}\), \(\alpha_{0}>0\), \(\beta_{0}\in(0,1]\) and \(\delta>0\) we have_

\[\psi(\delta)=\int_{0}^{+\infty}\Psi(\alpha_{0}t/\delta,k)^{\beta_{0}}t\varphi( t)\mathrm{d}t\leq C_{0}\delta^{2},\] (30)

_with \(C_{0}=25(2\uppi)^{-1}(k^{2}+1)/(\alpha_{0}\beta_{0})^{2}\)._

Proof.: Let \(k\in\mathbb{N}\), \(\alpha_{0}>0\), \(\beta_{0}\in(0,1]\) and \(\delta>0\). Let \(t_{\delta}=5k\delta/\alpha_{0}\). Note that if \(t\geq t_{\delta}\) then, \(\alpha_{0}t/\delta\geq 5k\). In addition, we have

\[\int_{0}^{+\infty}\Psi(\alpha_{0}t/\delta,k)^{\beta_{0}}t\varphi( t)\mathrm{d}t\leq(2\uppi)^{-1}\int_{0}^{t_{\delta}}\Psi(\alpha_{0}t/\delta,k)^{ \beta_{0}}\mathrm{d}t+(2\uppi)^{-1}\int_{t_{\delta}}^{+\infty}\Psi(\alpha_{0} t/\delta,k)^{\beta_{0}}t\mathrm{d}t.\] (31)In addition, using that if \(u\geq 5k\) then \(\Psi(u,k)\leq\exp[-u/5]\), we get

\[(2\pi)^{-1}\int_{t_{\delta}}^{+\infty}\Psi(\alpha_{0}t/\delta,k)^{\beta_{0}}t \mathrm{d}t\leq(2\pi)^{-1}\int_{0}^{+\infty}\exp[-\alpha_{0}\beta_{0}t/(5\delta )]t\mathrm{d}t\leq(2\pi)^{-1}25\delta^{2}/(\alpha_{0}\beta_{0})^{2}.\] (32)

Finally, using that for any \(u\geq 0\), \(\Psi(u,k)\leq 1\), we have

\[(2\pi)^{-1}\!\int_{0}^{t_{\delta}}\Psi(\alpha_{0}t/\delta,k)^{\beta_{0}}t \mathrm{d}t\leq(2\pi)^{-1}25k^{2}\delta^{2}/\alpha_{0}^{2},\] (33)

which concludes the proof. 

### Lower bound on the inside probability and control of moments of order two and higher

Lower bound on the inside probability.We begin with the following lemma which controls the expectation of \(1+\|Z\|\)_outside_ of \(\mathsf{C}(x,\gamma)\). We recall that \(\mathsf{V}\) is defined in Theorem 7-(c).

**Lemma 11**.: _Let \(\bar{\gamma}=1\). Let \(x\in\mathsf{V}\), \(Z\in\sim\mathrm{N}(0,\mathrm{Id})\) and \(\gamma\in(0,\bar{\gamma})\) then we have_

\[\max(\mathbb{E}[\mathbb{1}_{x+\sqrt{\gamma}Z\in\overline{\mathcal{M}}\cap \mathsf{C}(x,\gamma)^{c}}],\mathbb{E}[\langle Z,\nabla\Phi(\bar{x})\rangle \mathbb{1}_{x+\sqrt{\gamma}Z\in\overline{\mathcal{M}}\cap\mathsf{C}(x,\gamma)^ {c}}])\leq\psi(\gamma),\] (34)

_with \(\psi:\ \mathbb{R}_{+}\to\mathbb{R}_{+}\) such that \(\limsup_{t\to 0}\psi(t)/t^{1/2}<+\infty\)._

Proof.: Let \(\bar{r}>0\) given by Theorem 7. First, we have that

\[\int_{\mathbb{R}}\int_{\mathbb{R}^{d-1}}(1+|\alpha|+\|v\|)\mathbb{ 1}_{\alpha\geq\bar{r}/\gamma^{1/2}}\varphi(\alpha)\varphi(v)\mathrm{d}\alpha \mathrm{d}v\] (35) \[\leq d\int_{\mathbb{R}}(1+|\alpha|)\mathbb{1}_{\alpha\geq\bar{r} /\gamma^{1/2}}\varphi(\alpha)\mathrm{d}\alpha\leq d(\Psi(\bar{r}^{2}/\gamma,1 )+\exp[-\bar{r}^{2}/(2\gamma)]).\] (36)

Second, using Lemma 9, we have that

\[\int_{\mathbb{R}}\int_{\mathbb{R}^{d-1}}1_{\|v\|^{2}\geq(\bar{ \alpha}+\sqrt{\gamma}\alpha)/(C\gamma)}\mathbb{1}_{\bar{\alpha}+\sqrt{\gamma} \alpha\geq 0}\varphi(\alpha)\varphi(v)\mathrm{d}\alpha\mathrm{d}v\] (37) \[\leq\int_{\mathbb{R}}\mathbb{1}_{\bar{\alpha}+\sqrt{\gamma}\alpha \geq 0}\Psi((\bar{\alpha}+\sqrt{\gamma}\alpha)/(C\gamma),d-1)\varphi(\alpha) \mathrm{d}\alpha\] (38) \[\leq\int_{0}^{+\infty}\Psi(\alpha/C\gamma^{1/2},d-1)\varphi(\alpha -\bar{\alpha}/\gamma^{1/2})\mathrm{d}\alpha\leq\Psi_{1}(\gamma^{1/2}).\] (39)

Second, using Lemma 10, we have that

\[\int_{\mathbb{R}}\int_{\mathbb{R}^{d-1}}\alpha\mathbb{1}_{\|v\|^ {2}\geq(\bar{\alpha}+\sqrt{\gamma}\alpha)/(C\gamma)}\mathbb{1}_{\bar{\alpha}+ \sqrt{\gamma}\alpha\geq 0}\varphi(\alpha)\varphi(v)\mathrm{d}\alpha\mathrm{d}v\] (40) \[=\int_{\mathbb{R}}\alpha\Psi((\bar{\alpha}+\sqrt{\gamma}\alpha)/(C \gamma),d-1)\mathbb{1}_{\bar{\alpha}+\sqrt{\gamma}\alpha\geq 0}\varphi(\alpha) \mathrm{d}\alpha\] (41) \[\leq\int_{0}^{+\infty}\Psi(\alpha/C\gamma^{1/2},d-1)\alpha\varphi( \alpha)\mathrm{d}\alpha\leq\Psi_{2}(\gamma^{1/2}).\] (42)

Note that we have \(\limsup_{\gamma\to 0}\Psi_{2}(\gamma^{1/2})+\Psi_{1}(\gamma^{1/2})<+\infty\). We conclude upon combining (36), (39) and (42) with Theorem 7-(d) and the fact that \(\|\Phi(\bar{x})\|=1\). 

The following lemma allow us to give a lower bound to the quantity \(\mathbb{E}[\mathbb{1}_{x+\sqrt{\gamma}Z\in\overline{\mathcal{M}}}]\) uniformly w.r.t \(x\in\overline{\mathcal{M}}\).

**Lemma 12**.: _There exists \(\bar{\gamma}>0\) such that for any \(\gamma\in(0,\bar{\gamma})\) and for any \(x\in\overline{\mathcal{M}}\), \(\gamma\in(0,\bar{\gamma})\) and \(Z\sim\mathrm{N}(0,\mathrm{Id})\) we have_

\[\mathbb{E}[\mathbb{1}_{x+\sqrt{\gamma}Z\in\overline{\mathcal{M}}}]\geq 1/4\.\] (43)

Proof.: Let \(\gamma\in(0,\bar{\gamma})\). If \(x\not\in\mathsf{V}\) then \(\mathrm{B}(x,2R)\subset\mathcal{M}\) using Theorem 7-(e) and therefore \(\mathbb{E}[\mathbb{1}_{x+\sqrt{\gamma}Z\in\overline{\mathcal{M}}}]\geq 1/4\) for \(\bar{\gamma}>0\) small enough. Now, assume that \(x\in\mathsf{V}\). Using Lemma 11, we have that \(\mathbb{E}[\mathbb{1}_{x+\sqrt{\gamma}Z\in\overline{\mathcal{M}}\cap\mathsf{C }(x,\gamma)^{c}}]\leq\psi(\gamma)\). In addition, using Theorem 7-(b), we have that for any \(\gamma>0\)

\[\mathbb{E}[\mathbb{1}_{x+\sqrt{\gamma}Z\in\overline{\mathcal{M}}}] \geq\mathbb{E}[\mathbb{1}_{x+\sqrt{\gamma}Z\in\mathsf{C}(x,\gamma)}]\] (44) \[\geq\int_{-\bar{\alpha}\gamma^{-1/2}}^{r\gamma^{-1/2}}\int_{ \nabla\Phi(\bar{x})^{\perp}}\mathbb{1}_{\|v\|^{2}\leq(\bar{\alpha}+\gamma^{1/ 2}\alpha)/(C\gamma)}\varphi(\alpha)\varphi(v)\mathrm{d}\alpha\mathrm{d}v\] (45) \[\geq\int_{-\bar{\alpha}\gamma^{-1/2}}^{r\gamma^{-1/2}}(1-\Psi(( \bar{\alpha}+\gamma^{1/2}\alpha)/(C\gamma),d-1))\varphi(\alpha)\mathrm{d}\alpha\] (46) \[\geq(1/2)-\Psi(r^{2}/\gamma,1)-\int_{-\bar{\alpha}\gamma^{-1/2}}^{+ \infty}\Psi((\bar{\alpha}+\gamma^{1/2}\alpha)/(C\gamma),d-1)\varphi(\alpha) \mathrm{d}\alpha.\] (47)

Hence, using Lemma 8 and Lemma 9, there exists \(\bar{\gamma}>0\) such that for any \(\gamma\in(0,\bar{\gamma})\), \(\Psi(r^{2}/\gamma,1)+\int_{0}^{+\infty}\Psi(\alpha/(C\gamma^{1/2}),d)\varphi( \alpha-\gamma^{1/2}\bar{\alpha})\mathrm{d}\alpha\leq 1/4\), which concludes the proof.

Note that the result of Lemma 12 can be improved to \(1/2-\varepsilon\) for any \(\varepsilon>0\). In particular this result tells us that for \(\gamma>0\) small enough, \(\overline{\mathcal{M}}\) looks like the _hyperplane_ from the point of view of the Gaussian with variance \(\gamma\) centered on \(\partial\mathcal{M}\).

Bound on moments of order two and higher.In what follows, we define for any \(\gamma>0\), \(\Delta^{\gamma}:\overline{\mathcal{M}}\to\mathbb{R}_{+}\) given for any \(x\in\overline{\mathcal{M}}\) by

\[\Delta^{\gamma}(x)=(1/\gamma)\int_{\mathbb{R}^{d}}\mathbbm{1}_{x+\sqrt{\gamma }z\in\mathcal{M}}\|\sqrt{\gamma}z\|^{4}\varphi(z)\mathrm{d}z/\int_{\mathbb{R} ^{d}}\mathbbm{1}_{x+\sqrt{\gamma}z\in\mathcal{M}}\varphi(z)\mathrm{d}z.\] (48)

**Proposition 13**.: _We have \(\lim_{\gamma\to 0}\sup\{\Delta^{\gamma}(x)\,:\,x\in\overline{\mathcal{M}}\}=0\)._

Proof.: Let \(\bar{\gamma}>0\) given by Lemma 12. Let \(x\in\overline{\mathcal{M}}\) and \(\gamma\in(0,\bar{\gamma})\). We have using Lemma 12

\[\int_{\mathbb{R}^{d}}\mathbbm{1}_{x+\sqrt{\gamma}z\in\mathcal{M}}\varphi(z) \mathrm{d}z\geq 1/4.\] (49)

We also have that

\[(1/\gamma)\int_{\mathbb{R}^{d}}\mathbbm{1}_{x+\sqrt{\gamma}z\in\mathcal{M}}\| \sqrt{\gamma}z\|^{4}\varphi(z)\mathrm{d}z\leq 3\gamma d^{2}.\] (50)

Therefore, we get that for any \(\gamma\in(0,\bar{\gamma})\), \(\Delta^{\gamma}(x)\leq 12\gamma d^{2}\), which concludes the proof. 

In what follows, we define for any \(\gamma>0\), \(\hat{\Sigma}^{\gamma}:\ \overline{\mathcal{M}}\to\mathbb{S}_{d}^{+}(\mathbb{R})\) given for any \(x\in\overline{\mathcal{M}}\) by

\[\hat{\Sigma}^{\gamma}(x)=\int_{\mathbb{R}^{d}}\mathbbm{1}_{x+\sqrt{\gamma}z\in \mathcal{M}}z\otimes z\varphi(z)\mathrm{d}z/\int_{\mathbb{R}^{d}}\mathbbm{1}_{ x+\sqrt{\gamma}z\in\mathcal{M}}\varphi(z)\mathrm{d}z.\] (51)

**Proposition 14**.: _There exists \(\bar{\gamma}>0\) such that for any \(x\in\overline{\mathcal{M}}\) and \(\gamma\in(0,\bar{\gamma})\) we have_

\[\|\hat{\Sigma}^{\gamma}(x)\|\leq 4d.\] (52)

Proof.: Let \(x\in\overline{\mathcal{M}}\) and \(\bar{\gamma}>0\) given by Lemma 12. For any \(\gamma\in(0,\bar{\gamma})\), we have using Lemma 12

\[\int_{\mathbb{R}^{d}}\mathbbm{1}_{x+\sqrt{\bar{\gamma}}z\in\mathcal{M}}\varphi (z)\mathrm{d}z\geq 1/4.\] (53)

We also have that

\[\int_{\mathbb{R}^{d}}\mathbbm{1}_{x+\sqrt{\bar{\gamma}}z\in\mathcal{M}}\|z\|^ {2}\varphi(z)\mathrm{d}z\leq d,\] (54)

which concludes the proof. 

### Properties of large drift terms

Finally, we define for any \(\gamma>0\), \(\hat{b}^{\gamma}:\ \overline{\mathcal{M}}\to\mathbb{R}^{d}\) given for any \(x\in\overline{\mathcal{M}}\) by

\[\hat{b}^{\gamma}(x)=\gamma^{-1/2}\int_{\mathbb{R}^{d}}\mathbbm{1}_{x+\sqrt{ \bar{\gamma}}z\in\mathcal{M}}z\varphi(z)\mathrm{d}z/\int_{\mathbb{R}^{d}} \mathbbm{1}_{x+\sqrt{\bar{\gamma}}z\in\mathcal{M}}\varphi(z)\mathrm{d}z.\] (55)

First, we show away from the boundary the drift \(\hat{b}^{\gamma}\) converges to zero.

**Proposition 15**.: _There exists \(\bar{\gamma}>0\) such that for any \(\gamma\in(0,\bar{\gamma})\), \(r>0\) and \(x\in\overline{\mathcal{M}}\) such that \(d(x,\partial\mathcal{M})\geq r\) we have \(\|\hat{b}^{\gamma}(x)\|\leq 2d\Psi(r/\gamma,d)^{1/2}/\gamma^{1/2}\)._

Proof.: Let \(x\in\overline{\mathcal{M}}\) and \(\bar{\gamma}>0\) given by Lemma 12. For any \(\gamma\in(0,\bar{\gamma})\) we have using Lemma 12

\[\int_{\mathbb{R}^{d}}\mathbbm{1}_{x+\sqrt{\bar{\gamma}}z\in\mathcal{M}}\varphi (z)\mathrm{d}z\geq 1/4.\] (56)

We also have that

\[\|\int_{\mathbb{R}^{d}}\mathbbm{1}_{x+\sqrt{\bar{\gamma}}z\in \mathcal{M}}z\varphi(z)\mathrm{d}z\| \leq\|\int_{\mathbb{R}^{d}}\mathbbm{1}_{\|z\|\leq r/\gamma^{1/2}}z \varphi(z)\mathrm{d}z\|+\int_{\mathbb{R}^{d}}\mathbbm{1}_{\|z\|\geq r/\gamma^{ 1/2}}\|z\|\varphi(z)\mathrm{d}z\] (57) \[\leq 2\int_{\mathbb{R}^{d}}\mathbbm{1}_{\|z\|\geq r/\gamma^{1/2}}\|z \|\varphi(z)\mathrm{d}z\leq 2d\Psi(r/\gamma,d)^{1/2}/\gamma^{1/2},\] (58)

which concludes the proof. 

We have the following corollary.

**Corollary 16**.: _There exists \(\bar{\gamma}>0\) such that for any \(\delta>0\) there exists \(M_{\delta}>0\) such that for any \(\gamma\in(0,\bar{\gamma})\) and \(x\in\overline{\mathcal{M}}\), \(\|\hat{b}^{\gamma}(x)\|\geq M_{\delta}\), then \(\Phi(x)\leq\delta\)._Proof.: Let \(\bar{\gamma}>0\) given by Lemma 12. Let \(f:\ \mathbb{R}_{+}\to\mathbb{R}_{+}\) given for any \(r>0\) by \(f(r)=\sup\{\gamma>0\ :\ \Psi(r/\gamma,1)^{1/2}/\gamma^{1/2}\}\). We have that \(f\) is non-increasing and \(\lim_{r\to 0}f(r)=+\infty\). Let \(\delta>0\) and \(M_{\delta}=2df(\delta/C)\) with \(C=\sup\{\|\nabla\Phi(x)\|\ :\ x\in\overline{\mathcal{M}}\}\). Let \(\gamma\in(0,\bar{\gamma})\) and \(x\in\overline{\mathcal{M}}\) such that \(\|\hat{b}^{\gamma}(x)\|\geq M_{\delta}\) then using Proposition 15 we have that \(d(x,\partial\mathcal{M})\leq\delta/C\). Let \(\bar{x}\in\partial\mathcal{M}\) such that \(\|x-\bar{x}\|=d(x,\partial\mathcal{M})\). We have

\[\Phi(x)\leq\Phi(\bar{x})+\int_{0}^{1}\langle\nabla\Phi(\bar{x}+t(x-\bar{x})),x -\bar{x}\rangle\mathrm{d}t\leq\delta,\] (59)

which concludes the proof. 

For ease of notation, for any \(\gamma>0\), we define \(\bar{b}^{\gamma}=\gamma^{1/2}\hat{b}^{\gamma}\), the _renormalized_ version of the drift. First, we have the following result which will ensure that the drift projected on the normal component does not vanish.

**Lemma 17**.: _There exists \(\bar{\gamma}>0\) such that for any \(\gamma\in(0,\bar{\gamma})\) and \(x\in\mathsf{V}\) we have_

\[\langle\bar{b}^{\gamma}(x),\nabla\Phi(\bar{x})\rangle\geq\|\bar{b}^{\gamma}(x )\|-\psi(\gamma),\] (60)

_with \(\psi:\ \mathbb{R}_{+}\to\mathbb{R}_{+}\) such that \(\limsup_{\gamma\to 0}\psi(\gamma)/\sqrt{\gamma}<+\infty\)._

Proof.: Let \(x\in\overline{\mathcal{M}}\) and \(\bar{\gamma}>0\) given by Lemma 12. For any \(\gamma\in(0,\bar{\gamma})\) we have using Lemma 12

\[\int_{\mathbb{R}^{d}}\mathbb{1}_{x+\sqrt{\bar{\gamma}}z\in\mathcal{M}}\varphi( z)\mathrm{d}z\geq 1/4.\] (61)

In addition, we have

\[\int_{\mathbb{R}^{d}}\mathbb{1}_{x+\sqrt{\bar{\gamma}}z\in \mathcal{M}}\langle z,\nabla\Phi(\bar{x})\rangle\varphi(z)\mathrm{d}z \geq\int_{\mathbb{R}^{d}}\mathbb{1}_{x+\sqrt{\bar{\gamma}}z\in\mathsf{C}(x, \gamma)}\langle z,\nabla\Phi(\bar{x})\rangle\varphi(z)\mathrm{d}z\] (62) \[-\int_{\mathbb{R}^{d}}\mathbb{1}_{x+\sqrt{\bar{\gamma}}z\in \mathcal{M}\cap\mathsf{C}(x,\gamma)^{c}}\langle z,\nabla\Phi(\bar{x})\rangle \varphi(z).\] (63)

Using Lemma 11, we get that

\[\int_{\mathbb{R}^{d}}\mathbb{1}_{x+\sqrt{\bar{\gamma}}z\in \mathcal{M}}\langle z,\nabla\Phi(\bar{x})\rangle\varphi(z)\mathrm{d}z\geq\int _{\mathbb{R}^{d}}\mathbb{1}_{x+\sqrt{\bar{\gamma}}z\in\mathsf{C}(x,\gamma)} \langle z,\nabla\Phi(\bar{x})\rangle\varphi(z)\mathrm{d}z-\psi(\gamma).\] (64)

Let \(\{e_{i}\}_{i=1}^{d-1}\) a basis of \(\nabla\Phi(\bar{x})^{\perp}\). Using Theorem 7-(b), we have that for any \(i\in\{1,\ldots,d-1\}\)

\[\int_{\mathbb{R}^{d}}\mathbb{1}_{x+\sqrt{\bar{\gamma}}z\in\mathsf{C}(x, \gamma)}\langle z,e_{i}\rangle\varphi(z)\mathrm{d}z =\int_{-\bar{\alpha}/\gamma^{1/2}}^{r/\gamma^{1/2}}\int_{\nabla\Phi(\bar{x})^{ \perp}}\mathbb{1}_{\|v\|^{2}\leq(\gamma^{1/2}\alpha+\bar{\alpha})/\gamma} \langle v,e_{i}\rangle\varphi(v)\varphi(\alpha)\mathrm{d}v\mathrm{d}\alpha.\] (65)

Hence, combining this result and the Cauchy-Schwarz inequality we have for any \(i\in\{1,\ldots,d-1\}\)

\[(\int_{\mathbb{R}^{d}}\mathbb{1}_{x+\sqrt{\bar{\gamma}}z\in \mathsf{C}(x,\gamma)}\langle z,e_{i}\rangle\varphi(z)\mathrm{d}z)^{2}=(\int_ {-\bar{\alpha}/\gamma^{1/2}}^{r/\gamma^{1/2}}\int_{\nabla\Phi(\bar{x})^{\perp }}\mathbb{1}_{\|v\|^{2}\geq(\gamma^{1/2}\alpha+\bar{\alpha})/\gamma}\langle v, e_{i}\rangle\varphi(v)\varphi(\alpha)\mathrm{d}v\mathrm{d}\alpha)^{2}\] (66) \[\leq(\int_{-\bar{\alpha}/\gamma^{1/2}}^{r/\gamma^{1/2}}\Psi((\bar {\alpha}+\alpha\gamma^{1/2})/\gamma,d-1)^{1/2}\varphi(\alpha)\mathrm{d} \alpha)^{2}.\] (67)

Hence, using Lemma 9, we get that

\[\sum_{i=1}^{d-1}(\int_{\mathbb{R}^{d}}\mathbb{1}_{x+\sqrt{\bar{\gamma}}z\in \mathsf{C}(x,\gamma)}\langle z,e_{i}\rangle\varphi(z)\mathrm{d}z)^{2}\leq(d-1 )\psi^{2}(\gamma),\] (69)

with \(\psi\) given by Lemma 9 with \(\beta_{0}=1/2\). Therefore, we get that

\[(\int_{\mathbb{R}^{d}}\mathbb{1}_{x+\sqrt{\bar{\gamma}}z\in \mathsf{C}(x,\gamma)}\langle z,\nabla\Phi(\bar{z})\rangle\varphi(z)\mathrm{d}z)^ {2}\] (70) \[=(\int_{\mathbb{R}^{d}}\mathbb{1}_{x+\sqrt{\bar{\gamma}}z\in \mathcal{M}}\varphi(z)\mathrm{d}z)^{2}\|\bar{b}^{\gamma}(x)\|^{2}-\sum_{i=1}^{d -1}(\int_{\mathbb{R}^{d}}\mathbb{1}_{x+\sqrt{\bar{\gamma}}z\in\mathsf{C}(x, \gamma)}\langle z,e_{i}\rangle\varphi(z)\mathrm{d}z)^{2}\] (71) \[\geq(\int_{\mathbb{R}^{d}}\mathbb{1}_{x+\sqrt{\bar{\gamma}}z\in \mathcal{M}}\varphi(z)\mathrm{d}z)^{2}\|\bar{b}^{\gamma}(x)\|^{2}-\psi(\gamma)^{ 2}.\] (72)

We conclude the proof upon using that for any \(a,b\geq 0\), \((a+b)^{1/2}\leq a^{1/2}+b^{1/2}\) and (61). 

We are now ready to state the following lower bound on the drift.

**Proposition 18**.: _There exist \(\bar{\gamma}>0\), \(M\geq 0\) and \(c>0\) such that for any \(x\in\overline{\mathcal{M}}\) and \(\gamma\in(0,\bar{\gamma})\) if \(\|\hat{b}^{\gamma}(x)\|\geq M\) then \(x\in\mathsf{V}\) and_

\[\min((\hat{b}^{\gamma}(x),\nabla\Phi(x)),\langle\hat{b}^{\gamma}(x),\nabla\Phi (\bar{x})\rangle)\geq c\|\hat{b}^{\gamma}(x)\|.\] (73)

Proof.: Let \(\bar{\gamma}>0\) given by Lemma 12 and \(M_{0}=4\sup\{\psi(\gamma)/\gamma^{1/2}\,:\,\,\gamma\in(0,\bar{\gamma}]\}\). In addition, let \(c=1/4\). Using Proposition 15 and Theorem 7-(e), there exists \(M_{1}\geq 0\) such that for any any \(x\in\overline{\mathcal{M}}\), if \(\|\hat{b}^{\gamma}(x)\|\geq M_{1}\) then \(x\in\mathsf{V}\) and \(x=\bar{x}+\alpha\nabla\Phi(\bar{x})\) with \(\alpha\leq 1/(4C)\) and \(C=\sup\{\|\nabla^{2}\Phi(x)\|\,:\,x\in\overline{\mathcal{M}}\}\). We denote \(M=\max(M_{0},M_{1})\). Let \(\gamma\in(0,\bar{\gamma})\) and \(x\in\overline{\mathcal{M}}\) such that \(\|\hat{b}^{\gamma}(x)\|\geq M\). Using Lemma 17, we have that

\[\langle\hat{b}^{\gamma}(x),\nabla\Phi(\bar{x})\rangle\geq\|\hat{b}^{\gamma}(x )\|-\psi(\gamma)/\gamma^{1/2}.\] (74)

Using that \(\psi(\gamma)/\gamma^{1/2}\leq M/2\leq\|\hat{b}^{\gamma}(x)\|/2\), we have

\[\langle\hat{b}^{\gamma}(x),\nabla\Phi(\bar{x})\rangle\geq(1/2)\|\hat{b}^{ \gamma}(x)\|.\] (75)

Since \(\|x-\bar{x}\|\leq\alpha\leq 1/(4C)\) we have \(\langle\hat{b}^{\gamma}(x),\nabla\Phi(x)\rangle\geq(1/2-C\alpha)\|\hat{b}^{ \gamma}(x)\|\geq\|\hat{b}^{\gamma}(x)\|/4\), which concludes the proof. 

### Convergence on compact sets

In this section, we show the convergence of the drift and diffusion matrix on compact sets. We recall that \(\mathcal{M}\) does _not_ include its boundary \(\partial\mathcal{M}\).

**Proposition 19**.: _For any compact set \(\mathsf{K}\subset\mathcal{M}\) and \(\varepsilon>0\), there exists \(\bar{\gamma}>0\) such that for any \(\gamma\in(0,\bar{\gamma})\) we have for any \(x\in\mathsf{K}\)_

\[\|\hat{b}^{\gamma}(x)\|\leq\varepsilon,\qquad\|\hat{\Sigma}^{\gamma}(x)- \operatorname{Id}\|\leq\varepsilon.\] (76)

Proof.: Let \(\mathsf{K}\subset\mathcal{M}\) be a compact set and \(\gamma>0\). Since \(\mathsf{K}\cap\partial\mathcal{M}=\varnothing\), there exists \(r>0\) such that for any \(x\in\mathsf{K}\), \(d(x,\partial\mathcal{M})>r\). Therefore, we have that for any \(x\in\mathsf{K}\)

\[\|\hat{b}^{\gamma}(x)\|=\gamma^{-1/2}\|\int_{x+\sqrt{\bar{\gamma}}z\in \mathcal{M}}z\varphi(z)\mathrm{d}z\|/\int_{x+\sqrt{\bar{\gamma}}z\in\mathcal{M }}\varphi(z)\mathrm{d}z.\] (77)

In addition, using the Cauchy-Schwarz inequality we have

\[\|\int_{x+\sqrt{\bar{\gamma}}z\in\mathcal{M}}z\varphi(z)\mathrm{ d}z\| \leq\|\int_{\mathbb{R}^{d}}z\varphi(z)\mathrm{d}z\|+\int_{\mathcal{M}^{ \mathsf{K}}}\|z\|\varphi(z)\mathrm{d}z\] (78) \[\leq\int_{\mathbb{R}^{d}}\mathbbm{1}_{\|z\|\geq r/\gamma^{1/2}} \|z\|\varphi(z)\mathrm{d}z\leq\sqrt{d}\Psi(r^{2}/\gamma,d)^{1/2}.\] (79)

Using Lemma 8 and Lemma 12, there exists \(\bar{\gamma}_{0}>0\) such that for any \(\gamma\in(0,\bar{\gamma}_{0})\) we have that for any \(x\in\mathsf{K}\)

\[\|\hat{b}^{\gamma}(x)\|\leq 4d\Psi(r^{2}/\gamma,1)^{1/2}/\gamma^{1/2}\leq\varepsilon,\] (80)

which concludes the first part of the proof. Similarly, we have that for any \(x\in\mathsf{K}\)

\[\|\int_{x+\sqrt{\bar{\gamma}}z\in\mathcal{M}}(z\otimes z- \operatorname{Id})\varphi(z)\mathrm{d}z\| \leq\|\int_{\mathbb{R}^{d}}(z\otimes z-\operatorname{Id})\varphi(z )\mathrm{d}z\|+\int_{\mathcal{M}^{\mathsf{K}}}\|z\|\varphi(z)\mathrm{d}z\] (81) \[\leq\int_{\mathbb{R}^{d}}\mathbbm{1}_{\|z\|\geq r/\gamma^{1/2}}\| z\otimes z-\operatorname{Id}\|\varphi(z)\mathrm{d}z\] (82) \[\leq\sqrt{2}(1+3d^{2})^{1/2}\Psi(r^{2}/\gamma,d)^{1/2}.\] (83)

Using Lemma 8 and Lemma 12, there exists \(\bar{\gamma}_{1}>0\) such that for any \(\gamma\in(0,\bar{\gamma}_{1})\), we have that for any \(x\in\mathsf{K}\)

\[\|\hat{\Sigma}^{\gamma}(x)-\operatorname{Id}\|\leq 4\sqrt{2}(1+3d^{2})^{1/2} \Psi(r^{2}/\gamma,1)^{1/2}\leq\varepsilon,\] (84)

which concludes the proof upon letting \(\bar{\gamma}=\min(\bar{\gamma}_{0},\bar{\gamma}_{1})\)

### Convergence on the boundary

Finally, we investigate the behavior at the boundary of the diffusion matrix and the drift. First, we show that there is a lower bound to the diffusion matrix near the boundary. Second, we show that the renormalized drift converges to the outward normal.

**Proposition 20**.: _There exist \(c>0\) and \(\bar{\gamma}>0\) such that for any \(\gamma\in(0,\bar{\gamma})\), \(u\in\mathbb{R}^{d}\) and \(x\in\mathsf{V}\) we have_

\[\langle u,\hat{\Sigma}^{\gamma}(x)u\rangle\geq c\|u\|^{2}.\] (85)

_In particular, there exist \(r,\varepsilon>0\) such that for any \(\gamma\in(0,\bar{\gamma})\) and \(x\in\overline{\mathcal{M}}\) with \(d(x,\partial\mathcal{M})\leq r\)_

\[\langle\nabla\Phi(x),\hat{\Sigma}^{\gamma}(x)\nabla\Phi(x)\rangle\geq\varepsilon.\] (86)

Proof.: First, we show (85). Let \(x\in\mathsf{V}\). We have for any \(u\in\mathbb{R}^{d}\)

\[\langle u,\hat{\Sigma}^{\gamma}(x)u\rangle =\int_{\mathbb{R}^{d}}1_{x+\sqrt{\bar{\gamma}}z\in\mathcal{M}} \langle z,u\rangle^{2}\varphi(z)\mathrm{d}z/\int_{\mathbb{R}^{d}}1_{x+\sqrt{ \bar{\gamma}}z\in\mathcal{M}}\mathrm{d}z\] (87) \[\geq\int_{\mathbb{R}^{d}}1_{x+\sqrt{\bar{\gamma}}z\in\mathcal{C}( x,\gamma)}\langle z,u\rangle^{2}\varphi(z)\mathrm{d}z.\] (88)

For any \(u\in\mathbb{R}^{d}\), let \(\alpha_{u}=\langle u,\nabla\Phi(\bar{x})\rangle\). Using Theorem 7-(b) we have for any \(u\in\mathbb{R}^{d}\)

\[\int_{\mathbb{R}^{d}}1_{x+\sqrt{\bar{\gamma}}z\in\mathcal{C}(x, \gamma)}\langle z,u\rangle^{2}\varphi(z)\mathrm{d}z\] (89) \[\quad=\int_{-\bar{\alpha}/\gamma^{1/2}}^{r/\gamma^{1/2}}\int_{ \nabla\Phi(\bar{x})\perp}(\langle u,v\rangle+\alpha\alpha_{u})^{2}1_{\|v\|^{2} \leq(\alpha\gamma^{1/2}+\bar{\alpha})/\gamma}\varphi(v)\varphi(\alpha)\mathrm{ d}v\mathrm{d}\alpha\] (90) \[\quad\geq\int_{0}^{r/\gamma^{1/2}}\int_{\nabla\Phi(\bar{x})\perp} (\langle u,v\rangle^{2}+\alpha^{2}\alpha_{u}^{2})1_{\|v\|^{2}\leq(\alpha\gamma^ {1/2}+\bar{\alpha})/\gamma}\varphi(v)\varphi(\alpha)\mathrm{d}v\mathrm{d}\alpha\] (91) \[\quad\geq\alpha_{u}^{2}\int_{0}^{r/\gamma^{1/2}}\alpha^{2}\varphi (\alpha)\mathrm{d}\alpha+\int_{-\bar{\alpha}/\gamma^{1/2}}^{r/\gamma^{1/2}} \int_{\nabla\Phi(\bar{x})\perp}\langle u,v\rangle^{2}1_{\|v\|^{2}\leq(\alpha \gamma^{1/2}+\bar{\alpha})/\gamma}\varphi(v)\varphi(\alpha)\mathrm{d}v\mathrm{ d}\alpha.\] (92)

Using Cauchy-Schwarz inequality, we have

\[\int_{0}^{r/\gamma^{1/2}}\alpha^{2}\varphi(\alpha)\mathrm{d}\alpha=(1/2)-\int _{r/\gamma^{1/2}}^{+\infty}\alpha^{2}\varphi(\alpha)\mathrm{d}\alpha\geq(1/2) -3\Phi(r^{2}/\gamma,1)^{1/2}.\] (93)

In addition, using the Cauchy-Schwarz inequality, we have that

\[\int_{-\bar{\alpha}/\gamma^{1/2}}^{r/\gamma^{1/2}}\int_{\nabla \Phi(\bar{x})\perp}\langle u,v\rangle^{2}1_{\|v\|^{2}\leq(\alpha\gamma^{1/2}+ \bar{\alpha})/\gamma}\varphi(v)\varphi(\alpha)\mathrm{d}v\mathrm{d}\alpha\] (94) \[\quad=\int_{\nabla\Phi(\bar{x})\perp}\langle u,v\rangle^{2} \varphi(v)\mathrm{d}v\int_{-\bar{\alpha}/\gamma^{1/2}}^{r/\gamma^{1/2}} \varphi(\alpha)\mathrm{d}\alpha\] (95) \[\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad-\int_{- \bar{\alpha}/\gamma^{1/2}}^{r/\gamma^{1/2}}\int_{\nabla\Phi(\bar{x})\perp} \langle u,v\rangle^{2}1_{\|v\|^{2}\geq(\alpha\gamma^{1/2}+\bar{\alpha})/\gamma} \varphi(v)\varphi(\alpha)\mathrm{d}v\mathrm{d}\alpha\] (96) \[\quad\geq(\|u\|^{2}-\alpha_{u}^{2})((1/2)-\Phi(r^{2}/\gamma,1))\] (97) \[\quad\quad\quad-\sqrt{3}(d-1)\|u\|^{2}\int_{0}^{+\infty}\Phi( \alpha/\gamma^{1/2},d-1)^{1/2}\varphi(\alpha-\bar{\alpha}/\gamma^{1/2})\mathrm{ d}\alpha.\] (98)

Combining this result, (93), (92) and Lemma 9 there exists \(\bar{\gamma}>0\) such that for any \(\gamma\in(0,\bar{\gamma}]\) and \(u\in\mathbb{R}^{d}\)

\[\int_{\mathbb{R}^{d}}1_{x+\sqrt{\bar{\gamma}}z\in\mathcal{C}(x,\gamma)}\langle z,u\rangle^{2}\varphi(z)\mathrm{d}z\geq(1/4)\|u\|^{2},\] (99)

which concludes the proof of (85). Finally, using Theorem 7-(e), we have that for any \(x\in\overline{\mathcal{M}}\) if \(d(x,\partial\mathcal{M})\leq R\) then \(x\in\mathsf{V}\). Let \(r=\min(R,1/(2C))\) with \(C=\sup\{\|\nabla^{2}\Phi(x)\|\ :\ x\in\overline{\mathcal{M}}\}\). We have that for any \(x\in\overline{\mathcal{M}}\) such that \(d(x,\partial\mathcal{M})\leq r\)

\[\|\nabla\Phi(x)\|\geq\|\nabla\Phi(\bar{x}_{0})\|-Cr\geq 1/2,\] (100)

where \(\bar{x}_{0}\) is such that \(\|x-\bar{x}_{0}\|\leq r\) and \(\bar{x}_{0}\in\partial\mathcal{M}\). Combining this result and (99) concludes the proof upon letting \(\varepsilon=1/16\). 

Finally, we investigate the behavior of the normalized drift near the boundary.

**Proposition 21**.: _For any \(\bar{x}_{0}\in\partial\mathcal{M}\) and \(\varepsilon>0\), there exist \(\bar{\gamma},r,M>0\) such that for any \(x\in\overline{\mathcal{M}}\) and \(\gamma\in(0,\bar{\gamma})\) with \(\|x-\bar{x}_{0}\|\leq r\) and \(\|\hat{b}^{\gamma}(x)\|\geq M\)_

\[\|\hat{b}^{\gamma}(x)/\langle\hat{b}^{\gamma}(x),\nabla\Phi(x)\rangle-\nabla\Phi( \bar{x}_{0})\|\leq\varepsilon.\] (101)Proof.: Let \(\bar{\gamma}\) be given by Proposition 18. Let \(\psi\) given by Lemma 9 and \(M_{0}=\sup\{\psi(\gamma)/\gamma^{1/2}:\gamma\in(0,\bar{\gamma})\}<+\infty\). Let \(M=16M_{0}/(c\varepsilon^{1/2})\) with \(c\) given in Proposition 18. Let \(R>0\) given by Theorem 7-(e) such that for any \(x\in\overline{\mathcal{M}}\) with \(d(x,\partial\mathcal{M})\) there exist \(\bar{x}\in\partial\mathcal{M}\) and \(\alpha\in[0,c\varepsilon/(4C)]\) such that \(x=\bar{x}+\alpha\nabla\Phi(\bar{x})\) with \(C=\sup\{\|\nabla^{2}\Phi(x)\|:\ x\in\overline{\mathcal{M}}\}\) and \(c\) given in Proposition 18. Let \(r=\min(\bar{r},c\varepsilon/4,R)\) and \(x\in\overline{M}\) with \(\|x-\bar{x}_{0}\|\leq r\). First, since \(d(x,\partial\mathcal{M})\leq R\), there exist \(\bar{x}\in\partial\mathcal{M}\) and \(\alpha\in[0,\varepsilon/(4C)]\) such that \(x=\bar{x}+\alpha\nabla\Phi(\bar{x})\). Therefore, we get that \(\|\bar{x}-\bar{x}_{0}\|\leq\varepsilon/(2C)\) and therefore \(\|\nabla\Phi(\bar{x}_{0})-\nabla\Phi(\bar{x})\|\leq\varepsilon/2\). In addition, we have that

\[\|\hat{b}^{\gamma}(x)/\langle\hat{b}^{\gamma}(x),\nabla\Phi(x) \rangle-\hat{b}^{\gamma}(x)/\langle\hat{b}^{\gamma}(x),\nabla\Phi(\bar{x})\rangle\|\] (102) \[\leq\|\hat{b}^{\gamma}(x)\|^{2}\|\nabla\Phi(x)-\nabla\Phi(\bar{x} )\|/\langle(\hat{b}^{\gamma}(x),\nabla\Phi(x)\rangle\langle\hat{b}^{\gamma}(x),\nabla\Phi(\bar{x})\rangle).\] (103)

Using Proposition 18, we get that

\[\|\hat{b}^{\gamma}(x)/\langle\hat{b}^{\gamma}(x),\nabla\Phi(x) \rangle-\hat{b}^{\gamma}(x)/\langle\hat{b}^{\gamma}(x),\nabla\Phi(\bar{x}) \rangle\|\leq\varepsilon/4.\] (104)

In what follows, we show that

\[\|\hat{b}^{\gamma}(x)/\langle\hat{b}^{\gamma}(x),\nabla\Phi(\bar{x})\rangle- \nabla\Phi(\bar{x})\|^{2}\leq\varepsilon/2.\] (105)

In particular, we show that for any \(u\in\nabla\Phi(\bar{x})^{\perp}\) with \(\|u\|=1\),

\[\langle\hat{b}^{\gamma}(x),u\rangle^{2}\leq(\varepsilon/16)\langle\hat{b}^{ \gamma}(x),\nabla\Phi(\bar{x})\rangle^{2}.\] (106)

Assuming (106), letting \(u=(\hat{b}^{\gamma}(x)-\langle\hat{b}^{\gamma}(x),\nabla\Phi(\bar{x})\rangle)/( \|\hat{b}^{\gamma}(x)\|^{2}-\langle\hat{b}^{\gamma}(x),\nabla\Phi(\bar{x})^{2 }\rangle^{1/2}\) and using that \(\hat{b}^{\gamma}(x)=\langle\hat{b}^{\gamma}(x),u\rangle u+\langle\hat{b}^{ \gamma}(x),\nabla\Phi(\bar{x})\rangle\nabla\Phi(\bar{x})\) we have

\[\|\hat{b}^{\gamma}(x)/\langle\hat{b}^{\gamma}(x),\nabla\Phi(x) \rangle-\nabla\Phi(\bar{x})\|\leq\|\hat{b}^{\gamma}(x)/\langle\hat{b}^{\gamma }(x),\nabla\Phi(\bar{x})\rangle-\nabla\Phi(\bar{x})\|\] (107) \[\qquad\qquad\qquad\qquad\qquad\qquad+\|\hat{b}^{\gamma}(x)/\langle \hat{b}^{\gamma}(x),\nabla\Phi(x)\rangle-\hat{b}^{\gamma}(x)/\langle\hat{b}^{ \gamma}(x),\nabla\Phi(\bar{x})\rangle\|\] (108) \[\leq|\langle\hat{b}^{\gamma}(x),u\rangle/\langle\hat{b}^{\gamma} (x),\nabla\Phi(\bar{x})\rangle|+\varepsilon/4\leq\varepsilon/2,\] (109)

which concludes the proof. Let \(u\in\nabla\Phi(\bar{x})^{\perp}\) with \(\|u\|=1\) and \(\{e_{i}\}_{i=1}^{d-1}\) an orthonormal basis of \(\nabla\Phi(\bar{x})^{\perp}\). There exist \(\{a_{i}\}_{i=1}^{d-1}\) such that \(\sum_{i=1}^{d-1}a_{i}^{2}=1\) and \(u=\sum_{i=1}^{d-1}a_{i}e_{i}\). Using Theorem 7-(b), we have that for any \(i\in\{1,\ldots,d-1\}\)

\[\int_{\mathbb{R}^{d}}\mathbbm{1}_{x+\sqrt{\gamma}z\in\mathsf{C}(x,\gamma)}\langle z,e_{i}\rangle\varphi(z)\mathrm{d}z =\int_{-\bar{\alpha}/\gamma^{1/2}}^{r/\gamma^{1/2}}\int_{\nabla \Phi(\bar{x})^{\perp}}\mathbbm{1}_{\|v\|^{2}\leq(\gamma^{1/2}\alpha+\bar{ \alpha})/\gamma}\langle v,e_{i}\rangle\varphi(v)\varphi(\alpha)\varphi(\alpha) \varphi\mathrm{d}v\mathrm{d}\alpha\] (110) \[=\int_{-\bar{\alpha}/\gamma^{1/2}}^{r/\gamma^{1/2}}\int_{\nabla \Phi(\bar{x})^{\perp}}\mathbbm{1}_{\|v\|^{2}\geq(\gamma^{1/2}\alpha+\bar{ \alpha})/\gamma}\langle v,e_{i}\rangle\varphi(v)\varphi(\alpha)\mathrm{d}v \mathrm{d}\alpha\] (111)

Hence, combining this result and the Cauchy-Schwarz inequality we have for any \(i\in\{1,\ldots,d-1\}\)

\[(\int_{\mathbb{R}^{d}}\mathbbm{1}_{x+\sqrt{\gamma}z\in\mathsf{C}(x,\gamma)} \langle z,e_{i}\rangle\varphi(z)\mathrm{d}z)^{2}=(\int_{-\bar{\alpha}/\gamma^{1 /2}}^{r/\gamma^{1/2}}\int_{\nabla\Phi(\bar{x})^{\perp}}\mathbbm{1}_{\|v\|^{2} \geq(\gamma^{1/2}\alpha+\bar{\alpha})/\gamma}\langle v,e_{i}\rangle\varphi(v) \varphi(\alpha)\mathrm{d}v\mathrm{d}\alpha)^{2}\] (112)

\[\leq\int_{\nabla\Phi(\bar{x})^{\perp}}\langle v,e_{i}\rangle^{2}\varphi(v) \mathrm{d}v(\int_{-\bar{\alpha}/\gamma^{1/2}}^{r/\gamma^{1/2}}\Psi((\bar{ \alpha}+\alpha\gamma^{1/2})/\gamma,d-1)^{1/2}\varphi(\alpha)\mathrm{d}\alpha)^ {2}.\] (113)

Hence, we get that

\[\sum_{i=1}^{d-1}a_{i}^{2}(\int_{\mathbb{R}^{d}}\mathbbm{1}_{x+\sqrt{\gamma}z\in \mathsf{C}(x,\gamma)}\langle z,e_{i}\rangle\varphi(z)\mathrm{d}z)^{2}\leq\|u\|^{2} \psi^{2}(\gamma),\] (114)

with \(\psi\) given by Lemma 9. Recalling that \(\|\hat{b}^{\gamma}(x)\|\geq M\) we have

\[\langle\hat{b}^{\gamma}(x),u\rangle^{2}\leq 16\psi(\gamma)^{2}/\gamma\leq c^{2}( \varepsilon/16)M^{2}\leq(\varepsilon/16)\langle\hat{b}^{\gamma}(x),\nabla\Phi (\bar{x})\rangle^{2},\] (115)

which concludes the proof.

### Submartingale problem and weak solution

We are now ready to conclude the proof.

**Theorem 22**.: _There exists \(\mathbb{P}^{\star}\) a distribution on \(\mathrm{D}([0,T]\,,\overline{\mathcal{M}})\) such that \(\lim_{\gamma\to 0}\hat{\mathbb{P}}^{\gamma}=\mathbb{P}^{\star}\). In addition, for any \(f\in\mathrm{C}^{1,2}([0,T]\times\overline{\mathcal{M}},\mathbb{R})\) with \(\langle\nabla\Phi(\bar{x}),\nabla f(x)\rangle\geq 0\) for any \(t\in[0,T]\) and \(x\in\partial\mathcal{M}\), we have that the process \((f(t,\omega(t)))_{t\in[0,T]}\) given for any \(t\in[0,T]\)_

\[f(t,\omega(t))-\int_{0}^{t}(\partial_{s}f(s,\omega(s)+\tfrac{1}{2}\Delta f(s, \omega(s)))\mathbbm{1}_{\mathcal{M}}(\omega(s))\mathrm{d}s,\] (116)

_is a \(\mathbb{P}\) submartingale._

Proof.: Condition (A) (Stroock et al., 1971, p.197) is a consequence of Proposition 13. Condition (B) (Stroock et al., 1971, p.197) is a consequence of Proposition 18. Condition (C) (Stroock et al., 1971, p.198) is a consequence of Corollary 16. Condition (D) (Stroock et al., 1971, p.198) is a consequence of Proposition 14. We fix \(\rho=0\) and condition (1) (Stroock et al., 1971, p.203) is a consequence of Proposition 19. Condition (2)-(iii) (Stroock et al., 1971, p.203) is a consequence of Proposition 20. Condition (2)-(iv) (Stroock et al., 1971, p.203) is a consequence of Proposition 21. We conclude upon using (Stroock et al., 1971, Theorem 6.3) and (Stroock et al., 1971, Theorem 5.8). 

We finally conclude the proof of Theorem 6 upon using the results of (Kang et al., 2017) which establish the link between a weak solution to the reflected SDE and the solution to a submartingale problem.

**Theorem 23**.: _For any \(T\geq 0\), \((\hat{\mathbf{X}}_{t}^{\gamma})_{t\in[0,T]}\) weakly converges to \((\mathbf{X}_{t})_{t\in[0,T]}\) such that for any \(t\in[0,T]\)_

\[\mathbf{X}_{t}=x+\mathbf{B}_{t}-\mathbf{k}_{t},\qquad|\mathbf{k}|_{t}=\int_{0 }^{t}\mathbbm{1}_{\mathbf{X}_{s}\in\partial\mathcal{M}}\mathrm{d}|\mathbf{k}| _{s},\qquad\mathbf{k}_{t}=\int_{0}^{t}\mathbf{n}(\mathbf{X}_{s})\mathrm{d}| \mathbf{k}|_{s}.\] (117)

Proof.: Using Theorem 22 and (Kang et al., 2017, Theorem 1, Proposition 2.12), we have that \(\mathbb{P}\) in Theorem 22is associated with a solution to the extended Skorokhod problem. We conclude that a solution to the extended Skorokhod problem is a solution to the Skorokhod problem using (Ramanan, 2006, Corollary 2.10). 

### Extension to the Metropolis process

We recall that the Metropolis process is defined as follows. Let \((X_{k}^{\gamma})_{k\in\mathbb{N}}\) given for any \(\gamma>0\) and \(k\in\mathbb{N}\) by \(X_{0}^{\gamma}=x\in\overline{\mathcal{M}}\) and for \(X_{k+1}^{\gamma}=X_{k}^{\gamma}+\sqrt{\gamma}Z_{k}\) if \(X_{k}^{\gamma}+\sqrt{\gamma}Z_{k}^{\gamma}\in\overline{\mathcal{M}}\) and \(X_{k}^{\gamma}\) otherwise, \(Z_{k}\sim\mathrm{N}(0,\mathrm{Id})\). We recall that \(\hat{b}^{\gamma}\), \(\hat{\Sigma}^{\gamma}\) and \(\hat{\Delta}^{\gamma}\) are given by (48), (51) and (55). In particular, denoting \(\hat{\mathrm{K}}^{\gamma}\) the Markov kernel associated with \((\hat{X}_{k}^{\gamma})_{k\in\mathbb{N}}\), i.e. \(\hat{\mathrm{K}}^{\gamma}:\ \mathcal{M}\times\mathcal{B}(\mathcal{M})\to[0,1]\) such that for any \(x\in\mathcal{M}\), \(\hat{\mathrm{K}}^{\gamma}(x,\cdot)\) is a probability measure, for any \(\mathsf{A}\in\mathcal{B}(\mathcal{M})\), \(\hat{\mathrm{K}}^{\gamma}(\cdot,\mathsf{A})\) is a measurable function and \(\mathbb{E}[\mathbbm{1}_{\mathsf{A}}(\hat{X}_{1}^{\gamma})\mid\hat{X}_{0}^{ \gamma}=x]=\hat{\mathrm{K}}^{\gamma}(x,\mathsf{A})\). We have that for any \(\gamma>0\) and \(x\in\mathcal{M}\)

\[\hat{b}^{\gamma}(x)=(1/\gamma)\int_{\mathcal{M}}(y-x)\hat{\mathrm{ K}}^{\gamma}(x,\mathrm{d}y),\] (118) \[\hat{\Sigma}^{\gamma}(x)=(1/\gamma)\int_{\mathcal{M}}(y-x)^{ \otimes 2}\hat{\mathrm{K}}^{\gamma}(x,\mathrm{d}y),\] (119) \[\hat{\Delta}^{\gamma}(x)=(1/\gamma)\int_{\mathcal{M}}\|y-x\|^{4} \hat{\mathrm{K}}^{\gamma}(x,\mathrm{d}y).\] (120)

In what follows, we denote \(a^{\gamma}(x)=\mathbb{E}[\mathbbm{1}_{x+\sqrt{\gamma}Z_{0}\in\mathcal{M}}]\). Denote \(\mathrm{K}^{\gamma}\) the kernel associated with \((X_{k}^{\gamma})_{k\in\mathbb{N}}\). We have that for any \(\mathsf{A}\in\mathcal{B}(\mathcal{M})\), \(\gamma>0\) and \(x\in\mathcal{M}\)

\[\mathrm{K}^{\gamma}(x,\mathsf{A}) =\mathbb{E}[\mathbbm{1}_{X_{k+1}^{\gamma}\in\mathsf{A}}\mathbbm{1 }_{x+\sqrt{\gamma}Z_{k+1}\in\mathcal{M}}]+(1-a^{\gamma}(x))\mathbbm{1}_{ \mathsf{A}}(x)\] (121) \[=a^{\gamma}(x)\hat{\mathrm{K}}^{\gamma}(x,\mathsf{A})+(1-a^{ \gamma}(x))\mathbbm{1}_{\mathsf{A}}(x).\] (122)

We define for any \(\gamma>0\) and \(x\in\mathcal{M}\)

\[b^{\gamma}(x)=(1/\gamma)\int_{\mathcal{M}}(y-x)\mathrm{K}^Using (122), we get that for any \(\gamma>0\) and \(x\in\mathcal{M}\)

\[b^{\gamma}(x)=a^{\gamma}(x)\hat{b}^{\gamma}(x),\qquad\Sigma^{\gamma}(x)=a^{ \gamma}(x)\hat{\Sigma}^{\gamma}(x),\qquad\Delta^{\gamma}(x)=a^{\gamma}(x)\hat{ \Delta}^{\gamma}(x).\] (126)

Using Lemma 12, we have that for any \(\gamma\in(0,\bar{\gamma})\) and \(x\in\mathcal{M}\), \(a^{\gamma}(x)\geq 1/4\).

In order to conclude for the convergence of the Metropolis process we adapt Theorem 22 and Theorem 23. We define \(\mathbf{X}^{\gamma}:\mathbb{R}_{+}\to\overline{\mathcal{M}}\) given for any \(k\in\mathbb{N}\) by \(\mathbf{X}^{\gamma}_{k\gamma}=X^{\gamma}_{k}\) and for any \(t\in\left[k\gamma,\left(k+1\right)\gamma\right)\), \(\mathbf{X}^{\gamma}_{t}=X^{\gamma}_{k}\). Note that \((\mathbf{X}_{t})_{t\in[0,T]}\) is a \(\mathrm{D}(\left[0,T\right],\overline{\mathcal{M}})\) valued random variable, where \(\mathrm{D}(\left[0,T\right],\overline{\mathcal{M}})\) is the space of right-continuous with left-limit processes which take values in \(\overline{\mathcal{M}}\). We denote \(\mathbb{P}^{\gamma}\) the distribution of \((\mathbf{X}_{t})_{t\in[0,T]}\) on \(\mathrm{D}(\left[0,T\right],\overline{\mathcal{M}})\).

**Theorem 24**.: _There exists \(\mathbb{P}^{\star}\) a distribution on \(\mathrm{D}(\left[0,T\right],\overline{\mathcal{M}})\) such that \(\lim_{\gamma\to 0}\mathbb{P}^{\gamma}=\mathbb{P}^{\star}\). In addition, for any \(f\in\mathrm{C}^{1,2}(\left[0,T\right]\times\overline{\mathcal{M}},\mathbb{R})\) with \(\langle\nabla\Phi(\bar{x}),\nabla f(x)\rangle\geq 0\) for any \(t\in\left[0,T\right]\) and \(x\in\partial\mathcal{M}\), we have that the process \((f(t,\omega(t)))_{t\in[0,T]}\) given for any \(t\in\left[0,T\right]\)_

\[f(t,\omega(t))-\int_{0}^{t}(\partial_{s}f(s,\omega(s)+\tfrac{1}{2}\Delta f(s, \omega(s)))\mathbbm{1}_{\mathcal{M}}(\omega(s))\mathrm{d}s,\] (127)

_is a \(\mathbb{P}\) submartingale._

Proof.: Condition (A) (Stroock et al., 1971, p.197) is a consequence of Proposition 13 and (126). Condition (B) (Stroock et al., 1971, p.197) is a consequence of Proposition 18 and (126). Condition (C) (Stroock et al., 1971, p.198) is a consequence of Corollary 16 and (126). Condition (D) (Stroock et al., 1971, p.198) is a consequence of Proposition 14 and (126). We fix \(\rho=0\) and condition (1) (Stroock et al., 1971, p.203) is a consequence of Proposition 19 and that \(\lim_{\gamma\to 0}a^{\gamma}=1\) uniformly on compact subsets \(\mathsf{K}\subset\mathcal{M}\). Condition (2)-(iii) (Stroock et al., 1971, p.203) is a consequence of Proposition 20 and (126). Condition (2)-(iv) (Stroock et al., 1971, p.203) is a consequence of Proposition 21 and (126). We conclude upon using (Stroock et al., 1971, Theorem 6.3) and (Stroock et al., 1971, Theorem 5.8). 

**Theorem 25**.: _For any \(T\geq 0\), \((\mathbf{X}^{\gamma}_{t})_{t\in[0,T]}\) weakly converges to \((\mathbf{X}_{t})_{t\in[0,T]}\) such that for any \(t\in[0,T]\)_

\[\mathbf{X}_{t}=x+\mathbf{B}_{t}-\mathbf{k}_{t},\qquad|\mathbf{k}_{t}=\int_{0} ^{t}\mathbbm{1}_{\mathbf{X}_{s}\in\partial\mathcal{M}}\mathrm{d}|\mathbf{k} |_{s},\qquad\mathbf{k}_{t}=\int_{0}^{t}\mathbf{n}(\mathbf{X}_{s})\mathrm{d}| \mathbf{k}|_{s}.\] (128)

Proof.: The proof is identical to Theorem 23. 

## Appendix E Modelling geospatial data within non-convex boundaries

To demonstrate the ability of the proposed method to model distributions whose support is restricted to manifolds with highly non-convex boundaries, we derived a geospatial dataset based on the historical wildfire incidence rate within the continental United States (described in in Appendix E.1) and, using the corresponding country borders, trained a constrained diffusion model by adapting the point-in-spherical-polytope conditions outlined in (Ketzner et al., 2022) (described in Appendix E.2).

### Derivation of bounded geospatial dataset

Specifically, we retrieved the rasterised version of the wildfire data provided by Welty et al. (2020), converted it to a spherical geodetic coordinate system using the Cartopy library (Met Office, 2010 - 2015), and drew a weighted subsample of size \(1\times 10^{6}\). We then retrieved the country borders of the continental United States from (Natural Earth, 2023) and mapped them to the same geodetic reference frame as the wildfire data. A visualization of the resulting dataset is presented in Figure 9.

### Point-in-spherical-polytope algorithms

The support of the data-generating distribution we aim to approximate is thus restricted to a highly non-convex spherical polytope \(\mathbb{P}\in\mathcal{S}^{2}\) given by the country borders of the continental United States. To determine whether a query point \(q\in\mathcal{S}^{2}\) is within \(\mathbb{P}\), we adapt an efficient reformulation of the point-in-spherical-polygon algorithm (Bevis et al., 1989) presented in (Ketzner et al., 2022). The algorithm requires the provision of a reference point \(r\in\mathcal{S}^{2}\) known to be located in \(\mathbb{P}\) and determineswhether \(q\) is inside or outside the polygon by checking whether the geodesic between \(r\) and \(q\) crosses the polygon an even or odd number of times. Letting \(\hat{x}\in\mathbb{R}^{3}\) denote the Cartesian coordinates of a point \(x\in\mathcal{S}^{2}\), (Ketzner et al., 2022) rely on a Cartesian reference coordinate system \(\hat{Q}\) (with its \(z\)-axis given by \(\hat{r}\)) and the corresponding spherical coordinate system \(Q\) to decompose the edge-crossing condition of Bevis et al. (1989) into two efficiently computable parts. That is, the geodesic between \(q\) and \(r\) crosses an edge \(e_{i}=(v_{i},v_{j})\) of the polygon if:

1. the longitude of \(q\) in \(Q\) is bounded by the longitudes of \(v_{i}\) and \(v_{j}\) in \(Q\), i.e. \[\phi_{Q}(q)\in[\min(\phi_{Q}(v_{i}),\phi_{Q}(v_{j})),\max(\phi_{Q}(v_{i}),\phi _{Q}(v_{j}))],\]
2. the plane specified by the normal vector \(\hat{p}_{i}=\hat{v}_{i}\times\hat{v}_{j}\) represents an equator that separates \(q\) and \(r\) into two different hemispheres, i.e. \[\mathrm{sign}(\langle\hat{p}_{i},\hat{r}\rangle\cdot\langle\hat{p}_{i},\hat{q }\rangle)=-1.\]

Especially when \(\mathbb{P}\) is fixed and the corresponding coordinate transformations and normal vectors can be precomputed for each edge, this algorithm affords an efficient and parallelisable approach to determining whether any given point on \(\mathcal{S}^{2}\) is contained by a spherical polytope.

## Appendix F Supplementary Experimental Results

### Evaluating log-barrier and Euclidean models

Following (Fishman et al., 2023), we approached the empirical evaluation of our Metropolis model by computing the maximum mean discrepancy (MMD) (Gretton et al., 2012) between samples from the true distribution and the trained diffusion models. The MMD is a statistic that quantifies the similarity of two samples by computing the distance of their respective mean embeddings in a reproducing kernel Hilbert space. For this, we use an RBF kernel with the same length scales as the standard deviations of the normal distributions used to generate the synthetic distribution. We sum these RBF kernels by the weights of the corresponding components of the synthetic Gaussian mixture model.

This is essential to be able to include the log-barrier in the comparison since the log-barrier methods suffer severe instabilities around the boundary, as the space is stretched to more and more. These instabilities cause the problems in fitting the log-barrier model and in computing the likelihood using the log-barrier model.

Figure 9: Orthographic projection of the wildfire dataset described in Appendix E. The projection is aligned with the centroid of the continental United States and zoomed in ten-fold for visual clarity. All visualisations of geospatial data were generated using the GeoViews(Rudiger et al., 2023) and DataShader(Bednar et al., 2023) libraries.

From the results in Table 5, it is clear that the log-barrier approach performs significantly worse than the Reflected model and the Metropolis models across all settings. This, in conjunction with numerical instabilities we encountered when attempting to evaluate sample likelihoods with the log-barrier models as presented in (Fishman et al., 2023), motivated us to focus on the Reflected and Metropolis models in the main text.

Additionally, we note that the unconstrained Euclidean models outperform the constrained methods on both the simplex and the hypercube as the dimensionality of the problem space increases. Especially on the simplex, we attribute this performance primarily to the fact that the synthetic distribution is simply a standard Normal with only a small portion close to the boundary. The amount of reflection needed to model the distribution decreases in higher dimensions, as the mass of the Normal distribution gets increasingly concentrated--which Euclidean diffusion models will fit well. This same dynamic is partially responsible for the hypercube performance.

### Implementational details

All source code that is needed to reproduce the results presented below is made available under https://github.com/oxcsml/score-sde/tree/metropolis, which requires a supporting package to handle the different geometries that is available under https://github.com/oxcsml/geomstats/tree/polytope.

We use the same architecture in all of our experiments: a 6-layer MLP with 512 hidden units and sine activation functions, except in the output layer, which uses a linear activation function. Following (Fishman et al., 2023), we implement a simple linear function that scales the score by the distance to the boundary, approaching zero within \(\epsilon=0.01\) of the boundary. This ensures the score obeys the Neumann boundary conditions required by the reflected Brownian Motion. For the geospatial dataset within non-convex country borders, we do not use distance rescaling. Instead, we substitute

\begin{table}
\begin{tabular}{c c c c c c} \hline \hline \multirow{2}{*}{Manifold} & \multirow{2}{*}{Dimension} & \multirow{2}{*}{Process} & \multicolumn{2}{c}{MMD} & \multicolumn{1}{c}{\% in Manifold} \\  & & & mean & std & mean \\ \hline \multirow{8}{*}{\(\Delta^{d}\)} & \multirow{8}{*}{2} & Euclidean & 0.027 & 0.011 & 0.969 \\  & & Log-Barrier & 0.050 & 0.012. & 1.000 \\  & & Reflected & 0.041 & 0.008 & 1.000 \\  & & Rejection & 0.030 & 0.002 & 1.000 \\ \cline{2-6}  & \multirow{8}{*}{3} & Euclidean & 0.032 & 0.015 & 0.969 \\  & & Log-Barrier & 0.238 & 0.009 & 1.000 \\  & & Reflected & 0.179 & 0.013 & 1.000 \\  & & Rejection & 0.111 & 0.002 & 1.000 \\ \cline{2-6}  & \multirow{8}{*}{10} & Euclidean & 0.028 & 0.001 & 0.946 \\  & & Log-Barrier & 0.275 & 0.0015 & 1.000 \\  & & Reflected & 0.233 & 0.004 & 1.000 \\  & & Rejection & 0.226 & 0.005 & 1.000 \\ \hline \multirow{8}{*}{\([0,1]^{d}\)} & \multirow{8}{*}{2} & Euclidean & 0.069 & 0.004 & 0.992 \\  & & Log-Barrier & 0.66 & 0.006 & 1.000 \\  & & Reflected & 0.048 & 0.012 & 1.000 \\  & & Rejection & 0.025 & 0.005 & 1.000 \\ \cline{2-6}  & \multirow{8}{*}{3} & Euclidean & 0.074 & 0.004 & 0.991 \\  & & Log-Barrier & 0.209 & 0.0077 & 1.000 \\ \cline{1-1}  & & Reflected & 0.085 & 0.006 & 1.000 \\ \cline{1-1}  & & Rejection & 0.049 & 0.006 & 1.000 \\ \cline{1-1} \cline{2-6}  & \multirow{8}{*}{10} & Euclidean & 0.086 & 0.007 & 0.968 \\ \cline{1-1}  & & Log-Barrier & 0.330 & 0.004 & 1.000 \\ \cline{1-1}  & & Reflected & 0.314 & 0.049 & 1.000 \\ \cline{1-1}  & & Rejection & 0.138 & 0.007 & 1.000 \\ \hline \hline \end{tabular}
\end{table}
Table 5: Maximum mean discrepancy (MMD) (\(\downarrow\)) of a held-out test set from a synthetic bimodal distribution over convex subsets of \(\mathbb{R}^{d}\) bounded by the hypercube \([-1,1]^{d}\) and unit simplex \(\Delta^{d}\). Means and standard deviations are computed over 3 different runs.

it with a series of step functions to rescale the score. This is a proof-of-concept to show that even when computing the distance is hard, simple and efficient approximations suffice. When constructing Riemannian diffusion models on the torus and sphere for the protein and geospatial datasets, we follow (De Bortoli et al., 2022) and include an additional preconditioner for the score on the manifold. We _do not_ use the residual trick or the standard deviation trick, which are both common score-rescaling functions in image model architectures; in our setting, we find that they adversely affect model training.

For the forward/reverse process we always set \(T=1\), \(\beta_{0}=1\times 10^{-3}\) and then tune \(\beta_{1}\) to ensure that the forward process just reaches the invariant distribution with a linear \(\beta\)-schedule. At sampling time we use \(N=100\) steps of the discretised process. We discretise the training process by selecting a random \(N\) between 0 and 100 for each example, rolling out to that time point. This lets us cheaply implement a simple variance reduction technique: we take multiple samples from this trajectory by selecting multiple random \(N\) to save for each example. This technique was originally described in (Fishman et al., 2023) and we find it is also helpful for our Metropolis models. For all experiments, we use the \(\mathrm{ism}\) loss with a modified weighting function of \((1+t)\), which we found to be essential to model training. All experiments use a batch size of 256 with 8 repeats per batch. For training, we use a learning rate of \(2\times 10^{-4}\) with a cosine learning rate schedule. We trained for 100,000 batches on the synthetic examples and 300,000 batches on the real-world examples (robotics, proteins, wildfires).

We selected these hyperparameters from a systematic search over learning rates (\(6\times 10^{-4}\), \(2\times 10^{-4}\), \(6\times 10^{-5}\), \(2\times 10^{-5}\)), learning rate schedules (cosine, log-linear), and batch sizes (128, 256, 512, 1024) on synthetic examples for the reflected and log-barrier models. Similar parameters worked well for both, and we used those for our Metropolis models to allow a straightforward comparison. We tried \(N=100,1000\) for several synthetic examples but found that very large rollout times actually hurt performance for the Metropolis model, though the log-barrier performed a bit better with longer rollouts and the reflected was the same.

All models were trained on a single NVIDIA GeForce GTX 1080 GPU. All of the Metropolis models presented here can easily be trained on this hardware in under 4 hours. The runtime for the log-barrier and reflected models is considerably longer.

### Synthetic Distributions on Constrained Manifolds of Increasing Dimensionality

Figure 11: Qualitiative comparison of samples from the data distribution, our Metropolis model, a Reflected model and the uniform distribution for a synthetic bimodal distribution on \(\Delta^{2}\).

Figure 10: Qualitiative comparison of samples from the data distribution, our Metropolis model, a Reflected model and the uniform distribution for a synthetic bimodal distribution on \([-1,1]^{2}\).

### Constrained Configurational Modelling of Robotic Arms

The following univariate marginal and pairwise bivariate plots visualise the distribution of different samples in

1. the three dimensions needed to describe an ellipsoid \(M=\begin{bmatrix}l_{1}&l_{2}\\ l_{2}&l_{3}\end{bmatrix}\in\mathcal{S}^{2}_{++}\) and
2. the two dimensions needed to describe a location in \(\mathbb{R}^{2}\).

#### f.4.1 Visualisation of samples from the data distribution

#### f.4.2 Visualisation of samples from our Metropolis sampling-based diffusion model

Figure 12: Visualisation of the data distribution in \(\mathcal{S}^{2}_{++}\times\mathbb{R}^{2}\) using univariate marginal and pairwise bivariate plots.

Figure 13: Visualisation of the distribution learned by our Metropolis sampling-based diffusion model in \(\mathcal{S}^{2}_{++}\times\mathbb{R}^{2}\) using univariate marginal and pairwise bivariate plots.

#### f.4.3 Visualisation of samples from a reflected Brownian motion-based diffusion model

#### f.4.4 Visualisation of samples from the uniform distribution

### Conformational Modelling of Protein Backbones

The following univariate marginal and pairwise bivariate plots visualise the distribution of different samples in (i) the polytope \(\mathbb{P}\subset\mathbb{R}^{3}\) and (ii) the torus \(\mathbb{T}^{4}\) used to parametrise the conformations of a polypeptide chain of length \(N=6\) with coinciding endpoints. We refer to (Han et al., 2006) for full detail on the reparametrisation and to (Fishman et al., 2023) for a full description of the dataset.

Figure 14: Visualisation of the distribution learned by a reflected Brownian motion-based diffusion model in \(\mathcal{S}^{2}_{++}\times\mathbb{R}^{2}\) using univariate marginal and pairwise bivariate plots.

#### e.5.1 Visualisation of samples from the data distribution

#### e.5.2 Visualisation of samples from our Metropolis sampling-based diffusion model

Figure 16: Visualisation of the data distribution in \(\mathbb{P}\subset\mathbb{R}^{3}\times\mathbb{T}^{4}\) using univariate marginal and pairwise bivariate plots.

Figure 17: Visualisation of the distribution learned by our Metropolis model in \(\mathbb{P}\subset\mathbb{R}^{3}\times\mathbb{T}^{4}\) using univariate marginal and pairwise bivariate plots.

#### f.5.3 Visualisation of samples from a reflected Brownian motion-based diffusion model

#### f.5.4 Visualisation of samples from the uniform distribution

Figure 19: Visualisation of the uniform distribution in \(\mathbb{P}\subset\mathbb{R}^{3}\times\mathbb{T}^{4}\) using univariate marginal and pairwise bivariate plots.

Figure 18: Visualisation of the distribution learned by a reflected Brownian motion-based diffusion model in \(\mathbb{P}\subset\mathbb{R}^{3}\times\mathbb{T}^{4}\) using univariate marginal and pairwise bivariate plots.