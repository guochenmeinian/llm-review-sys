# Flipped Classroom: Aligning Teacher Attention with Student in Generalized Category Discovery

 Haonan Lin\({}^{1}\)   Wenbin An\({}^{2}\)   Jiahao Wang\({}^{1}\)   Yan Chen\({}^{1}\)   Feng Tian\({}^{1}\)

&Mengmeng Wang\({}^{3,4}\)   Guang Dai\({}^{4}\)   Qianying Wang\({}^{5}\)   Jingdong Wang\({}^{6}\)

\({}^{1}\) School of Comp. Science & Technology, MOEKLINNS Lab, Xi'an Jiaotong University

\({}^{2}\) School of Auto. Science & Engineering, MOEKLINNS Lab, Xi'an Jiaotong University

\({}^{3}\) College of Comp. Science & Technology, Zhejiang University of Technology

\({}^{4}\) SGIT AI Lab, State Grid Corporation of China

\({}^{5}\) Lenovo Research   Baidu Inc

Corresponding Authors.

Equal contribution.

This work was partly completed during the internship at SGIT AI Lab, State Grid Corporation of China.

###### Abstract

Recent advancements have shown promise in applying traditional Semi-Supervised Learning strategies to the task of Generalized Category Discovery (GCD). Typically, this involves a teacher-student framework in which the teacher imparts knowledge to the student to classify categories, even in the absence of explicit labels. Nevertheless, GCD presents unique challenges, particularly the absence of priors for new classes, which can lead to the teacher's misguidance and unsynchronized learning with the student, culminating in suboptimal outcomes. In our work, we delve into why traditional teacher-student designs falter in open-world generalized category discovery as compared to their success in closed-world semi-supervised learning. We identify inconsistent pattern learning across attention layers as the crux of this issue and introduce FlipClass--a method that dynamically updates the teacher to align with the student's attention, instead of maintaining a static teacher reference. Our teacher-student attention alignment strategy refines the teacher's focus based on student feedback from an energy perspective, promoting consistent pattern recognition and synchronized learning across old and new classes. Extensive experiments on a spectrum of benchmarks affirm that FlipClass significantly surpasses contemporary GCD methods, establishing new standards for the field.

## 1 Introduction

Teacher-Student architecture has proved its effectiveness in Semi-Supervised Learning (SSL) [66, 32, 53], which aims to take advantage of a large collection of unlabeled data, reducing the expensive costs of annotation [57, 90, 89] . Previous approaches tend to model \(p\)(student[teacher], where the teacher typically acts as a fixed point of reference, providing a form of "supervision prior" to guide the student [25, 42, 60]. This supervision comes from labeled data and is asymmetrical: while the teacher has robust prior knowledge and provides a stable learning signal, the student's knowledge is incomplete and evolving. The student learns from both the teacher's supervision and the data it is exposed to, trying to emulate the teacher by aligning its predictions with those of the teacher.

Teacher-Student designs traditionally rely on a closed-world assumption, where it is expected that the teachers have supervision prior to all classes they will face while instructing students [61; 3]. However, real-world applications often involve dynamic and open environments, where instances belonging to new classes may appear [84; 30; 31; 41]. In such cases, discovering novelties could enable models to adapt new information and evolve continually as biological systems do [14; 49]. Recently, Generalized Category Discovery (GCD) [69] stands out by challenging models to categorize unlabeled data containing both old and new classes using only partial labels for training. Although recent GCD methods have adapted closed-world Teacher-Student strategies with notable success [75; 50], the transition is not seamless and presents several challenges.

**Challenge I: Learning gap.** Fig. 1 top left illustrates the learning evolution of student and teacher. The previous teacher-student models result in unsynchronized learning and a significant learning gap in new classes. The ideal learning dynamic between the teacher and student should be cohesive, which requires teaching students in accordance with their aptitude.

**Challenge II: Discrepancies in features.** The learning gap arises from the teacher's fast pace, leading to large discrepancies in representations between weakly-augmented data (teacher) and strongly-augmented data (student), especially for new classes (Fig. 1 middle). This causes significant prediction differences, making consistency loss optimization difficult and hindering effective student learning. Over time, the iterative learning process exacerbates this misalignment.

**Challenge III: Attention inconsistency.** Inadequate supervision for new classes leads to inaccurate instructions from the teacher, causing the student to focus on different parts than the teacher (Fig. 1 right). Imagine a classroom transitioning to a new subject. Without proper guidance, students' attention diverges from the teacher's, resulting in confusion and ineffective learning.

To sum up, the challenges of previous teacher-student models arise from inadequate supervision on new classes and the gap between weakly and strongly augmented data. This results in attention inconsistency (Chall. III), which leads to discrepancies in predictions and representations (Chall. II), ultimately causing a significant performance gap (Chall. I). Addressing these challenges requires developing teacher-student dynamics that align the evolving knowledge of both teacher and student (Fig. 1, bottom left). These findings lay the foundation for our approach, _FlipClass_, which models the teacher's posterior \(p\)(teacher|student) from the energy perspective of attention, building an adaptive teacher to bridge the learning gap. _FlipClass_ offers a plug-and-play solution to foster an interactive learning environment where the student can influence the teacher's guidance in real-time, allowing teachers to tailor their instructions based on students' current attention [7; 1]. By aligning attention, _FlipClass_ ensures that the learning pace of the teacher and student is in sync, leading to improvement on both old and new classes. Our contributions are summarized as:

Figure 1: Left: Learning effects of traditional Teacher-Student Consistency Model (TSCM, _e.g._, SimGCD [75]) and our Flipped Classroom Consistency Model (_FlipClass_) on Stanford Cars [33]. Middle: Model comparison between TSCM and our FlipClass, where \(\mathbb{D}^{\text{new}}\) refers to data belonging to new classes. Right: Illustration of the inner feedback mechanism in FlipClass, where teacher attention is adapted to the student, leading to the alignment of attention.

**(1) Empirical analysis**: We highlight the challenge of applying the closed-world Teacher-Student paradigm to the open-world scenario of GCD. Our in-depth analysis identifies attention misalignment between teacher and student as the key issue hindering synchronized learning between them.

**(2) Methodology**: Based on these analyses, we propose a flexible and effective method, _FlipClass_, which enables teachers to adapt and respond to student feedback to synchronize their learning progress, thereby leading to an overall improvement in teaching outcomes.

**(3) Superiority**: _FlipClass_ consistently outperforms state-of-the-art generalized category discovery methods on both coarse-grained and fine-grained datasets.

## 2 Background

We first provide some background on semi-supervised learning and generalized category discovery to better contextualize our analysis. Let us consider a data set \(\mathbb{D}\) consisting of labeled data \(\mathbb{D}_{L}=\left\{(\mathbf{x}_{i}^{\ell},y_{i})\right\}_{i=1}^{N_{L}}\) from \(|\mathbb{C}_{K}|\) old classes and unlabeled data \(\mathbb{D}_{U}=\{\mathbf{x}_{j}^{u}\}_{j=1}^{N_{U}}\) that may contain instances from both old classes \(\mathbb{C}_{K}\) and new classes \(\mathbb{C}_{N}\), with \(\mathbb{C}=\mathbb{C}_{K}\cup\mathbb{C}_{N}\). For a data instance \(\mathbf{x}\), let \(p_{\text{m}}(y\mid f_{\theta}(\mathbf{x}))\) denote the predicted class distribution produced by the model \(f\).

### Integrating SSL Techniques into a Consistency Loss Framework

In semi-supervised learning (SSL), the goal is to enhance model performance by leveraging unlabeled data, traditionally drawn from the same class spectrum as the labeled data [90]. The goal of SSL can be formalized by integrating three fundamental techniques: _(1) Consistency regularization_ ensures that the model outputs consistent predictions for augmented versions of the same instance. This technique utilizes different transformations to test the robustness of the model's predictions, promoting stability across variations in the input data [8; 59; 36]. _(2) Pseudo-labeling_ utilizes the model to generate artificial labels for unlabeled data by adopting "hard" labels (that is, the argmax of the model output) and keeping only the labels where the highest class probability exceeds a predefined threshold [62; 47; 57; 37; 23]. _(3) Teacher-Student model_ incorporates a structured learning relationship where the **teacher** model, typically trained on weakly-augmented instances, generates high-quality pseudo labels. These pseudo labels are then used to guide the training of the **student** model, which processes strongly-augmented instances. This approach helps improve the generalization capabilities of the student model by learning from the refined knowledge and stable supervision signals provided by the teacher [66; 43; 77; 12; 53]. Several methods integrate some of these techniques and achieve advanced performance in SSL [63; 83; 78; 87]. We unify these SSL techniques into one consistency loss:

\[\mathcal{L}_{\text{cons}}=\frac{1}{|\mathbb{D}_{U}|}\sum_{\mathbf{x}\in \mathbb{D}_{U}}H\Big{(}p_{\text{m}}\big{(}y\mid f_{\theta}(\alpha(\mathbf{x}) )\big{)},\,p_{\text{m}}\big{(}y\mid f_{\theta}(\mathcal{A}(\mathbf{x})) \big{)}\Big{)},\] (1)

Figure 2: Exploring prior gaps between SSL and GCD on SCars and CUB datasets. Left: Accuracy of sorted pseudo labels for old and new classes. Middle: Consistency loss trends over epochs, illustrating challenges in optimization and slower convergence for new classes. Right: Categorize errors [75], where “True Old” refers to predicting an ‘Old’ class sample to another ‘Old’ class, while ‘False Old” indicates predicting an ‘Old’ class sample as some ‘New’ class.

where cross-entropy \(H(\cdot,\cdot)\) measures _consistency for regularization_, while the prediction \(p_{\mathsf{m}}(y\mid f_{\theta}(\mathbf{x}))\) serves as a _pseudo label_. This setup captures a _teacher-student dynamic_, where \(\alpha(\mathbf{x})\) and \(\mathcal{A}(\mathbf{x})\) represent the **teacher** (weakly-augmented) and **student** (strongly-augmented) instances, respectively.

### Class Prior Gap between SSL and GCD

The GCD task pushes the boundaries of SSL by questioning the closed-world assumption that all classes in the unlabeled dataset \(\mathbb{D}_{U}\) are previously known [69]. Instead, GCD incorporates new classes \(\mathbb{C}_{N}\) into the unlabeled dataset, demanding that the model learn to recognize and then correctly classify them [4; 21; 80; 5]. In this open-world setting, SSL methods face obstacles with new classes due to the lack of supervision [24; 56], resulting in significantly lower quality of pseudo-labels for these new classes than for the old ones (Fig. 2 left). This gap exacerbates the complexity of optimizing the consistency loss Eq. 1 for new classes, leading to learning instability and slow convergence (Fig. 2, middle). Such optimization issues lead to severe prediction bias, resulting in new classes' performance lagging behind that of old classes (Fig. 2, right), underlining the limitations of existing SSL techniques in GCD scenarios. More empirical analysis can be found in _Appendix_B.2.

## 3 How Consistency Loss Goes Awry: Unraveling the Pitfalls

Acknowledging challenges presented by the absence of prior knowledge for new classes in traditional semi-supervised learning (SSL) methods is the first step toward addressing the complexities of open-world tasks. We further identify that the 'prior gap' manifests as issues in learning synchronization and representation discrepancy (Sec. 3.1). Our analysis targets the minimization of the energy function between teacher and student representations to bridge the 'prior gap'. We find that aligning their attention on similar patterns reduces energy, indicating effective alignment and learning (Sec. 3.2). This key understanding paves the way for the development of our proposed methods, aiming to synchronize teacher-student attentions for improved model learning dynamics (Sec. 4).

### What to Bridge the Class Prior

The challenge of optimizing consistency loss leads to a learning gap between the student and the teacher, particularly evident when dealing with new classes (Fig. 1 top left). This gap causes the student to plateau, as it cannot keep pace with the teacher's more advanced understanding, which in turn restricts the teacher's progress in new classes Moreover, this learning gap also manifests itself in the divergent representations between teacher and student (Fig. 1 middle), specifically for new classes. Based on these observations, we revisit consistency loss (Eq. 1) in the closed-world setting.

**Insight 3.1**.: _The large discrepancy between \(f_{\theta}(\alpha(x))\) and \(f_{\theta}(\mathcal{A}(x))\) complicates maintaining consistency across the model predictions. To narrow this divide, an intuitive idea is to align \(f_{\theta}(\alpha(\mathbf{x}))\) more closely with \(f_{\theta}(\mathcal{A}(\mathbf{x}))\), simplifying the optimization of \(\mathcal{L}_{cons}\):_

\[\mathcal{L}_{\mathrm{cons}}=\frac{1}{|\mathbb{D}_{U}|}\sum_{\mathbf{x}\in \mathbb{D}_{U}}d\Big{(}p_{\mathsf{m}}\big{(}y\mid f_{\theta}(\alpha(\mathbf{ x}))-\Delta\Re\big{)},p_{\mathsf{m}}\big{(}y\mid f_{\theta}(\mathcal{A}( \mathbf{x}))\big{)}\Big{)},\] (2)

_where \(\Delta\Re\) aims to pull \(f_{\theta}(\alpha(\mathbf{x}))\) closer to \(f_{\theta}(\mathcal{A}(\mathbf{x}))\). Ideally, \(\Delta\Re\) would be adaptive, scaling with the discrepancy between \(f_{\theta}(\mathcal{A}(x))\) and \(f_{\theta}(\alpha(x))\), while avoiding make them too similar, which enables model to find a shortcut of \(\mathcal{L}_{cons}\)._

To design it, we delve into the vision transformer, a representation encoder that has significantly advanced the performance of the GCD task. We found that the self-attention mechanism excels at capturing critical image patterns: as depicted in Fig. 3 left, deeper features (after the 8th layer) reveal semantic, high-level commonalities (_e.g._, car shell) across all images; and the shallow features are more attuned to high-frequency, low-level details (_e.g._, color and texture).

### Inconsistent Patterns Spoil the Whole Barrel

Inconsistent patterns can disrupt learning, making it crucial to align stored and queried patterns effectively. To address this, we draw inspiration from the Hopfield Network [2] -- an associative memory model known for its energy-based mechanism that naturally pulls similar patterns together (see _Appendix_ A.1 for details). We follow Ramsauer et al. to define the energy function for a state pattern (query) \(\bm{\xi}\in\mathbb{R}^{d}\), parameterized by \(N\) stored (key) patterns \(\mathbf{X}=[\mathbf{x}_{1},\cdots,\mathbf{x}_{N}]\in\mathbb{R}^{d\times N}\):

\[E(\bm{\xi};\mathbf{X})=\frac{1}{2}\bm{\xi}^{\top}\bm{\xi}-\text{\rm{lse}}( \mathbf{X}^{\top}\bm{\xi},\bm{\beta})+c,\quad\text{with }\text{\rm{lse}}(\mathbf{v},\bm{\beta}):=\beta^{-1}\log\left(\sum_{i=1}^{N} \exp(\mathbf{v}_{i})\right).\] (3)

Minimizing \(E(\bm{\xi};\mathbf{X})\) resembles retrieving stored pattern \(\mathbf{x}_{i}\) that is most similar to the query \(\bm{\xi}\), and _log-sum-exp_ (\(\text{\rm{lse}}\)) function is parameterized by \(\beta>0\) and \(c\) is a preset constant. Particularly, the first term ensures the finiteness of the query, while the second term measures the alignment of the query with each stored pattern. The update rule for a state pattern \(\bm{\xi}\) is equivalent to a gradient descent update of minimizing the energy \(E\) with step size \(\eta=1\)[54], ensures that the query moves closer to the most similar stored pattern:

\[\bm{\xi}\leftarrow\bm{\xi}-\eta\nabla_{\bm{\xi}}E(\bm{\xi};\mathbf{X})=\bm{ \xi}-\text{\rm{sm}}(\beta\bm{\xi}^{\top}\mathbf{X})\mathbf{X}^{\top}.\] (4)

Moreover, the energy function is closely related to the Transformer's self-attention mechanism [67] (_Appendix_ A.1.2). By extending the energy model from self-attention to cross-attention, we model the dynamics between student and teacher learning patterns. Taking the student representations \(\mathbf{f}_{s}=f(\mathcal{A}(\mathbf{x}))\) as examples, we have \(\mathbf{Q}_{s}=\mathbf{f}_{s}\mathbf{W}_{Q}\) and \(\mathbf{K}_{s}=\mathbf{f}_{s}\mathbf{W}_{K}\). By applying Eq. 3 to key and query matrices, we set energy functions to track the teacher-student relationship:

\[E(\mathbf{Q}_{s};\mathbf{K}_{t})=\frac{\alpha}{2}\text{diag}( \mathbf{K}_{t}\mathbf{K}_{t}^{T})-\sum_{i=1}^{N}\text{\rm{lse}}(\mathbf{Q}_{ s}\mathbf{k}_{t,i}^{T},\beta)+c,\] (5a) \[E(\mathbf{K}_{t})=\text{\rm{lse}}\left(\frac{1}{2}\text{diag}( \mathbf{K}_{t}\mathbf{K}_{t}^{T}),1\right)=\log\sum_{i=1}^{N}\exp\left(\frac{ 1}{2}\mathbf{k}_{t,i}\mathbf{k}_{t,i}^{T}\right)+c,\] (5b)

where \(E(\mathbf{Q}_{s};\mathbf{K}_{t})\) indicates the alignment in learning patterns of the student and teacher; \(\mathbf{k}_{t,i}\) denotes the \(i\)-th row vector of \(\mathbf{K}_{t}\) and \(\alpha\geq 0\). Intuitively, \(\text{\rm{lse}}(\mathbf{Q}_{s}\mathbf{k}_{t,i}^{T},\beta)\) captures the smooth maximum alignment between student queries \(\mathbf{q}_{s,i}\) and teacher keys \(\mathbf{k}_{t,i}\). Specifically, it nudges each teacher key \(\mathbf{k}_{t,j}\) towards a semantic alignment with its most corresponding student query \(\mathbf{q}_{s,j}\). The regularization term \(\text{diag}(\mathbf{K}_{t}\mathbf{K}_{t}^{T})\) acts as a constraint on the energy levels of teacher's representation \(\mathbf{k}_{t,i}\), guarding against any disproportionate increase during the maximization of \(\text{\rm{lse}}(\mathbf{Q}_{s}\mathbf{k}_{t,i}^{T},\beta)\). This ensures that no individual teacher representation becomes too closely mirrored in the student's representation, maintaining a diverse learning trajectory.

**Insight 3.2**.: _When applying closed-world consistency regularization to the GCD task, it becomes difficult to gradually reduce the energy \(E(\mathbf{Q}_{s};\mathbf{K}_{t})\) as training progresses (Fig. 3 right). The sustained high energy demonstrated a flaw in the previous methods: teachers and students focused on identifying patterns that were inconsistent, leading to divergent learning paths. Specifically, when teachers and students focus on similar patterns (e.g., taillights), energy is reduced, indicating better prediction consistency and effective learning. In contrast, when their attention is distracted, the energy rises, leading to severe inconsistencies in predictions and making the optimization of \(\mathcal{L}_{cons}\) more difficult._

Figure 3: Left: Attention heatmaps for teacher and student across attention layers. Right: Energy trend over epochs, with lower energy indicating less discrepancy in pattern recognition between teacher and student.

FlipClass: Teacher-Student Attention Alignment

### Teacher Attention Update Rule

Based on Insights 3.1 and 3.2, our objective is to minimize the energy function \(E(\mathbf{Q}_{s};\mathbf{K}_{t})\) between teacher and student representations, thereby easing the optimization of \(\mathcal{L}_{\text{cons}}\).

**Theorem 4.1**.: _The minimization can be formulated as obtaining a maximum a posteriori probability (MAP) estimate of teacher keys \(\mathbf{K}_{t}\) given a set of observed student queries \(\mathbf{Q}_{s}\):_

\[p(\mathbf{K}_{t}|\mathbf{Q}_{s})=\frac{p(\mathbf{Q}_{s}|\mathbf{K}_{t})p( \mathbf{K}_{t})}{p(\mathbf{Q}_{s})},\] (6)

_where \(p(\mathbf{Q}_{s}|\mathbf{K}_{t})\) and \(p(\mathbf{K}_{t})\) are modeled by energy functions Eq. 5a and 5b, respectively. We approximate the posterior inference by the gradient of the log posterior, estimated as:_

\[\begin{split}\nabla_{\mathbf{K}_{t}}\log p(\mathbf{K}_{t}| \mathbf{Q}_{s})&=-\left(\nabla_{\mathbf{K}_{t}}E(\mathbf{Q}_{s}; \mathbf{K}_{t})+\nabla_{\mathbf{K}_{t}}E(\mathbf{K}_{t})\right)\\ &=sm\left(\beta\mathbf{Q}_{s}\mathbf{K}_{t}{}^{T}\right)\mathbf{ Q}_{s}-\left(\alpha\mathbf{I}+\mathcal{D}\left(sm\left(\frac{1}{2}\text{diag}( \mathbf{K}_{t}\mathbf{K}_{t}{}^{T})\right)\right)\right)\mathbf{K}_{t},\end{split}\] (7)

_where \(sm(\mathbf{v}):=\exp\left(\mathbf{v}-\text{lse}(\mathbf{v},1)\right)\) and \(\mathcal{D}(\cdot)\) is a vector-to-diagonal-matrix operator. Incorporating Eq. 4, the update rule of teacher keys \(\mathbf{K}_{t}\) is derived as follows:_

\[\mathbf{K}_{t}^{update}=\mathbf{K}_{t}+\gamma_{update}\left[\,\left(sm\left( \beta\mathbf{K}\bm{Q}^{T}\right)\bm{Q}\bm{W}_{K}^{T}\right)-\gamma_{\text{reg }}\left(\alpha\mathbf{I}+\mathcal{D}\left(sm\left(\frac{1}{2}\text{diag} \left(\bm{K}\bm{K}^{T}\right)\right)\right)\bm{K}\bm{W}_{K}^{T}\right)\right],\] (8)

_where \(\alpha\), \(\gamma_{update}\) and \(\gamma_{\text{reg}}\) are hyper-parameters._

For a proof, refer to _Appendix_ A.2. The teacher-attention update rule in Theorem 4.1 minimizes an implicit energy function determined by student queries and teacher keys. It serves as using the student queries to search for the most similar teacher patterns in the stored set. As illustrated in Fig. 4, the update rule adjusts the teacher's attention in the direction of student attention, facilitating the retrieval of related patterns and improving semantic alignment. This design establishes a bidirectional information flow: the teacher not only imparts advanced knowledge to the student, but also adjusts guidance based on the student's learning effects, achieving a more cohesive learning dynamic.

### Representation Learning and Parametric Classification

Contrastive learning plus consistency regularization under the parametric paradigm has been demonstrated effective in GCD task [75]. Formally, given two views (random augmentations \(\mathbf{x}_{i}\) and \(\mathbf{x}_{i}^{\prime}\)) of the same image in a mini-batch \(\mathbb{B}\), the supervised and self-supervised contrastive loss is written as:

\[\mathcal{L}_{\text{rep}}^{s}=\frac{1}{|\mathbb{B}^{\prime}|}\sum_{i\in \mathbb{B}^{\prime}}\frac{1}{|\mathbb{N}_{i}|}\sum_{q\in\mathbb{N}_{i}}-\log \frac{\exp(\mathbf{z}_{i}^{T}z_{q}^{\prime}/\tau_{c})}{\sum_{i^{\prime}\neq i }\exp(\mathbf{z}_{i}^{T}z_{i^{\prime}}^{\prime}/\tau_{c})},\] \[\mathcal{L}_{\text{rep}}^{u}=\frac{1}{|\mathbb{B}|}\sum_{i\in \mathbb{B}}-\log\frac{\exp(\mathbf{z}_{i}^{T}\mathbf{z}_{i}^{\prime}/\tau_{u} )}{\sum_{i^{\prime}\neq i}\exp(\mathbf{z}_{i}^{T}z_{i^{\prime}}^{\prime}/\tau_ {u})},\]

where the feature \(\mathbf{z}_{i}=f(\mathbf{x}_{i})\) and is \(\ell_{2}\)-normalised, and \(\tau_{u}\), \(\tau_{c}\) are temperature values. For \(\mathcal{L}_{\text{rep}}^{s}\), \(\mathbb{N}_{i}\) indexes all other images in the same batch that hold the same label as \(\mathbf{x}_{i}\). The representation learning loss is balanced with \(\lambda\): \(L_{\text{rep}}=(1-\lambda)L_{\text{rep}}^{u}+\lambda L_{\text{rep}}^{s}\), where \(\mathbb{B}^{\prime}\) corresponds to the labeled subset of \(\mathbb{B}\).

Figure 4: **Framework of _FlipClass_ demonstrating teacher-student interaction, where teacher’s and student’s attention is aligned by teacher’s updating (Eq. 8). Then \(\mathcal{L}_{\text{rep}}\) and \(\mathcal{L}_{\text{cons}}\) are combined for optimization.

The consistency regularization objectives (Eq. 1) are then simply cross-entropy loss \(\ell(q^{\prime},p)=-\sum_{k}q^{\prime}(k)\log p(k)\) between the predictions and pseudo-labels or ground-truth labels:

\[\mathcal{L}_{\text{cons}}=\begin{cases}\frac{1}{|\mathbb{B}|}\sum_{i\in\mathbb{B }}\ell(q^{\prime}_{i},p_{i})-\varepsilon H(\bar{p})&\text{for unlabeled,}\\ \frac{1}{|\mathbb{B}|}\sum_{i\in\mathbb{B}^{\prime}}\ell(y_{i},p_{i})&\text{ for labeled.}\end{cases}\]

The one-hot labels \(y_{i}\) correspond to \(\mathbf{x}_{i}\), and the soft pseudo-label \(q^{\prime}_{i}\) is produced by the teacher instance \(\alpha(\mathbf{x})_{i}\). Moreover, a mean-entropy regularizer [6], \(H(\bar{p})=-\sum_{k}\bar{p}(k)\log\bar{p}(k)\), is included to encourage diverse predictions. The combined classification loss, \(\mathcal{L}_{\text{cons}}\), balances unsupervised and supervised terms with a parameter \(\lambda\). And the overall training objective is \(\mathcal{L}_{\text{rep}}+\mathcal{L}_{\text{cons}}\).

## 5 Experiments

### Experimental Settings

**Datasets.** We evaluate the effectiveness of _FlipClass_ on three generic image recognition datasets (_i.e._, CIFAR-10/100 [34] and ImageNet-100 [20]), three fine-grained datasets [68] (_i.e._, CUB [71], Stanford Cars [33], and FGVC-Aircraft [46]) contained in Semantic Shift Benchmark (SSB) [68], and the challenging datasets Herbarium-19 [65], ImageNet-1k [20]. For each dataset, we first subsample \(|\mathcal{C}_{l}|\) seen (labeled) classes from all classes. Following GCD [69], we subsample 80% samples in CIFAR-100 and 50% samples in all other datasets from the seen classes to construct \(\mathbb{D}_{l}\), while the remaining images are treated as \(\mathbb{D}_{u}\) (refer to Table 9).

**Evaluation Protocols.** The performance was evaluated by measuring accuracy between the model's cluster assignments and ground-truth labels on the test set, with three aspects: all instances (All), instances from old categories (Old), and instances from new categories (New). The number of categories in the unlabeled dataset (\(|\mathcal{C}_{u}|\)) is often unknown. Following previous studies [64; 85], we set \(K\) (cluster number) equal to \(|\mathcal{C}_{u}|\), as approximate cluster estimation is usually feasible in the real world. The estimation of the number of categories in unlabeled datasets can be found in the _Appendix_ C.4. Further implementation details can be found in Appendix D.1.

\begin{table}
\begin{tabular}{l l c c c|c c c|c c c|c} \hline \multirow{2}{*}{Methods} & \multirow{2}{*}{Backbone} & \multicolumn{3}{c}{CUB} & \multicolumn{3}{c}{Stanford Cars} & \multicolumn{3}{c}{Aircraft} \\ \cline{3-11}  & & All & Old & New & All & Old & New & All & Old & New & Avg. \\ \hline GCD [2022] & DINO & 51.3 & 56.6 & 48.7 & 39.0 & 57.6 & 29.9 & 45.0 & 41.1 & 46.9 & 45.1 \\ XCon [2022] & DINO & 52.1 & 54.3 & 51.0 & 40.5 & 58.8 & 31.7 & 47.7 & 44.4 & 49.4 & 46.8 \\ CIPR [203] & DINO & 57.1 & 58.7 & 55.6 & 47.0 & 61.5 & 40.1 & - & - & - & - & - \\ PCAL [2023] & DINO & 62.9 & 64.4 & 62.1 & 50.2 & 70.1 & 40.6 & 52.2 & 52.2 & 52.3 & 55.1 \\ SimGCD [2023] & DINO & 60.3 & 65.6 & 57.7 & 53.8 & 71.9 & 45.0 & 54.2 & 59.1 & 51.8 & 56.1 \\ AdaptGCD [2024] & DINO & 66.6 & 66.5 & 66.7 & 48.4 & 57.7 & 39.3 & 53.7 & 51.1 & 56.0 & 56.2 \\ AMEND [2024] & DINO & 64.9 & 75.6 & 59.6 & 56.4 & 73.3 & 48.2 & 52.8 & 61.8 & 48.3 & 58.0 \\ GCA [2024] & DINO & 68.8 & 73.4 & 66.6 & 54.4 & 72.1 & 45.8 & 52.0 & 57.1 & 49.5 & 58.4 \\ TIDA [2024] & DINO & - & - & - & 54.7 & 72.3 & 46.2 & 54.6 & 61.3 & 52.1 & - \\ _uGCD_ [2024] & DINO & 65.7 & 68.0 & 64.6 & 56.5 & 68.1 & 50.9 & 53.8 & 55.4 & 53.0 & 58.7 \\ CMS [2024] & DINO & 68.2 & 76.5 & 64.0 & 56.9 & 76.1 & 47.6 & 56.0 & 63.4 & 52.3 & 60.4 \\ InfoSieve [2024] & DINO & 69.4 & **77.9** & 65.1 & 55.7 & 74.8 & 46.4 & 56.3 & 63.7 & 52.5 & 60.5 \\ SPTNet [2024] & DINO & 65.8 & 68.8 & 65.1 & 59.0 & 79.2 & 49.3 & **59.3** & 61.8 & **58.1** & 61.4 \\ \hline FlipClass (Ours) & DINO & **71.3** & 71.3 & **71.3** & **63.1** & **81.7** & **53.8** & **59.3** & **66.9** & 55.4 & **64.6** \\ Improvement & DINO & +5.5 & +2.5 & +6.2 & +4.1 & +2.5 & +4.5 & +0.0 & +5.1 & -2.7 & +3.2 \\ \hline \hline GCD [2022] & DINOv2 & 71.9 & 71.2 & 72.3 & 65.7 & 67.8 & 64.7 & 55.4 & 47.9 & 59.2 & 64.3 \\ SimGCD [2023] & DINOv2 & 71.5 & 78.1 & 68.3 & 71.5 & 81.9 & 64.6 & 49.9 & 60.9 & 60.0 & 63.0 \\ \(\mu\)GCD [2024] & DINOv2 & 74.0 & 75.9 & 73.1 & 76.1 & **91.0** & 68.9 & 66.3 & 68.7 & 65.1 & 72.1 \\ \hline FlipClass (Ours) & DINOv2 & **79.3** & **80.7** & **78.5** & **78.0** & 88.0 & **73.2** & **71.1** & **75.1** & **69.1** & **76.1** \\ Improvement & DINOv2 & +5.3 & +4.8 & +5.4 & +1.9 & -3.0 & +4.3 & +4.8 & +6.4 & +4.0 & +4.0 \\ \hline \end{tabular}
\end{table}
Table 1: Evaluation on the Semantic Shift Benchmark (SSB). Bold values represent the best results, while underlined values represent the second-best results.

### Experimental Results

We compare SOTA methods with ours in GCD using features from both DINO [15] and DINOv2 [51]. Our approach shows significant performance improvement, particularly in the recognition of 'New' classes across both the SSB fine-grained benchmark (Tab. 1) and generic image recognition datasets (Tab. 2), consistently surpassing existing SOTA methods. Moreover, in fine-grained image classification (Tab. 1), recognizing subtle differences between closely related categories is crucial, which is in contrast to coarse-grained datasets where the visual differences between classes are more obvious. In fine-grained settings, the risk of the model generating incorrect pseudo labels is higher, which makes consistency regularization counterproductive (Sec. 2.2). However, the results across these datasets demonstrate our model's capability to effectively adapt consistency regularization strategies from closed-world settings to more complex open-world scenarios. Moreover, the balanced accuracy between new and old classes on the CUB dataset (Tab. 1), also observed with methods like PCAL, CiPR, and AdaptGCD, can be attributed to the dataset's small size (6,000 images) and large class split (200). This limited data reduces the likelihood of overfitting to old classes, promoting more uniform performance across both categories. Additional results on Herbarium 19 and ImageNet-1k are detailed in the _Appendix_ C.2.

### Analysis and Discussion

**Ablation Studies.** Our ablation study, shown in Fig. 5, underscores the significance of our design choices. First, we replace the student's augmentations with the teacher's, _i.e._, using only weak augmentations, the performance on 'New' classes significantly declines (2nd set of bars). This underscores the importance of **strong augmentations** for the student, which are essential to bolster generalizability. Then we validate the importance of attention alignment in Eq. 8 (3rd set of bars), we see performance drop across both 'Old' and 'New' classes, affirming that our attention alignment strategy is crucial for maintaining a consistent learning pace between the teacher and student, leading to sustained performance gains. Finally, the 4th set of bars verifies the role of **regularization** during

\begin{table}
\begin{tabular}{l l c c c|c c c|c c c} \hline \multirow{2}{*}{Methods} & \multirow{2}{*}{Backbone} & \multicolumn{3}{c}{CIFAR10} & \multicolumn{3}{c}{CIFAR100} & \multicolumn{3}{c}{ImageNet-100} \\ \cline{3-11}  & & All & Old & New & All & Old & New & All & Old & New & Avg. \\ \hline GCD [2022] & DINO & 91.5 & **97.9** & 88.2 & 73.0 & 76.2 & 65.5 & 74.1 & 89.8 & 66.3 & 79.5 \\ AdaptGCD [2024] & DINO & 93.2 & 94.6 & 92.8 & 71.3 & 75.7 & 66.8 & 83.3 & 90.2 & 76.5 & 82.6 \\ InfoSieve [2024] & DINO & 94.8 & 97.2 & 93.7 & 76.9 & 78.4 & 73.9 & 80.5 & 92.8 & 74.4 & 84.1 \\ CiPR [2023] & DINO & 97.7 & 97.5 & 97.7 & 81.5 & 82.4 & 79.7 & 80.5 & 84.9 & 78.3 & 86.6 \\ SimGCD [2023] & DINO & 97.1 & 95.1 & 98.1 & 80.1 & 81.2 & 77.8 & 83.0 & 93.1 & 77.9 & 86.7 \\ GCA [2024] & DINO & 95.5 & 95.9 & 95.2 & 82.4 & 85.6 & 75.9 & 82.8 & 94.1 & 77.1 & 86.9 \\ TIDA [2024] & DINO & 98.2 & **97.9** & 98.5 & 82.3 & 83.8 & 80.7 & - & - & - & - \\ CMS [2024] & DINO & - & - & - & 82.3 & **85.7** & 75.5 & 84.7 & **95.6** & 79.2 & - \\ AMEND [2024] & DINO & 96.8 & 94.6 & 97.8 & 81.0 & 79.9 & 83.8 & 83.2 & 92.9 & 78.3 & 87.0 \\ SPTNet [2024] & DINO & 97.3 & 95.0 & 98.6 & 81.3 & 84.3 & 75.6 & 85.4 & 93.2 & 81.4 & 88.0 \\ \hline FlipClass (Ours) & DINO & **98.5** & 97.6 & **99.0** & **85.2** & 84.9 & **85.8** & **86.7** & 94.3 & **82.9** & **90.1** \\ Improvement & DINO & +1.2 & +2.6 & +0.4 & +3.9 & +0.6 & +10.2 & +1.3 & +1.1 & +1.5 & +2.1 \\ \hline \hline \(*\) GCD [2022] & DINOv2 & 95.2 & 97.8 & 93.9 & 77.3 & 82.8 & 66.1 & 81.3 & 94.3 & 74.8 & 84.6 \\ \(*\) AMEND [2024] & DINOv2 & 97.7 & 96.6 & 98.3 & 83.5 & 83.0 & 84.5 & 87.3 & 95.1 & 83.4 & 89.5 \\ \hline FlipClass (Ours) & DINOv2 & **99.0** & **98.2** & **99.4** & **91.7** & **90.4** & **94.2** & **91.0** & **96.3** & **88.3** & **93.9** \\ Improvement & DINOv2 & +1.3 & +1.6 & +1.1 & +8.2 & +7.4 & +9.7 & +3.7 & +1.2 & +4.9 & +4.3 \\ \hline \end{tabular}
\end{table}
Table 2: Evaluation on three generic image recognition datasets.

Figure 5: Ablation study results for FlipClass, indicate the critical role of strong augmentations, attention alignment, and regularization in model performance across multiple datasets.

the attention update, which integrates the prior energy of the teacher, preventing any single student pattern from overly influencing the teacher's attention.

**Enhanced Consistency through Attention Alignment.** To validate our assumption on modeling \(\Reamond\) in Eq. 2, we showcase how distribution-based strategies (distribution alignment [11], FixMatch [63]) and our representation-based method, attention alignment, achieve consistency on new classes from CUB dataset (Fig. 6). Our method stands out by significantly reducing the discrepancy between the representations of teacher (weakly-augmented) and student (strongly-augmented) data. This representation-based alignment leads to a more consistent learning process and is evidenced by the superior accuracies we achieve for both 'Old' and 'New' classes.

**Design Choice of Attention Alignment.** We experimented with various techniques to model \(\Reamond\) in Eq. 2, including scheduled data augmentation (SDA), increasing similarity between \(\mathbf{Q}_{s}\) and \(\mathbf{K}_{t}\) via \(\ell_{2}\) norm, Kullback-Leibler divergence (KLD) or CORrelation ALignment (CORAL) loss (see details in _Appendix_ D.1). As shown in Fig. 6(a), our teacher-attention update strategy outperforms these alternatives on both CUB and SCars datasets.

**FlipClass mitigates prediction bias.** We verify the effectiveness and robustness of _FlipClass_, by diagnosing the model's classification errors under four different (\(\gamma_{\text{update}}\)) as defined in Eq. 8. As depicted in Fig. 6(b), both "False New" and "False Old" errors are consistently mitigated--where 'Old' class samples are mistakenly labeled as 'New' and vice-versa. Moreover, as illustrated in Fig.7(b) bottom, _FlipClass_ outperforms leading methods [55] by moving closer to the true class distribution, yielding higher and less biased accuracies across all classes.

**Does the improved energy dynamic make for performance gains?** Fig. 7(a) top shows that aligning attention in these deeper (9-10) layers yields the highest performance on SCars dataset. And Fig. 7(a) bottom displays a greater reduction of energy \(E(\mathbf{Q}_{s};\mathbf{K}_{t})\) in deeper layers. Moreover, this trend highlights that attention alignment constantly maintains lower energy levels than without, indicating improved alignment of student patterns with teacher updating.

**How does FlipClass change the representations?** Fig. 7(b) showcases representation enhancements with _FlipClass_ against the leading method, InfoSieve [55], using the same t-SNE and PCA components to ensure consistent projection space and scale. FlipClass forms clusters with higher compactness and purity, demonstrating enhanced feature discrimination and less inter-class confusion. The zoom-in comparison on CUB dataset is provided in Fig. 9, which showcases that FlipClass achieves more distinct and well-separated clusters. Further, we assess prediction bias and class

Figure 6: Accuracy and representation alignment with different strategies: (1) initial state, (2) distribution alignment, (3) FixMatch, and (4) our teacher-attention update. Performance on ‘New’ and ‘Old’ classes are shown, alongside alignment of teacher (red) and student (blue) representation.

Figure 7: Attention alignment methods comparison and categorize errors with different update rates.

specific accuracies. Unlike InfoSieve's skewed predictions, _FlipClass_ aligns better with true class distributions, and significantly improves over the tail classes in CUB dataset (More experiments in _Appendix_ C.3).

## 6 Conclusion

This paper introduces _FlipClass_, a dynamic teacher-student attention alignment strategy for improving learning synchronization, providing a new view on applying closed-world models to open-world task of GCD. By aligning the attention of teacher and student, _FlipClass_ bridges the learning gap between them, resulting in performance improvement on both old and new classes. Extensive experiments and analysis demonstrate that _FlipClass_ outperforms existing state-of-the-art methods across diverse datasets by a large margin.

## 7 Acknowledgement

This work was supported by National Science and Technology Major Project (2022ZD0117102), National Natural Science Foundation of China (62293551, 62377038,62177038,62277042). Project of China Knowledge Centre for Engineering Science and Technology, Project of Chinese academy of engineering "The Online and Offline Mixed Educational Service System for 'The Belt and Road' Training in MOOC China". "LENOVO-XJTU" Intelligent Industry Joint Laboratory Project.

## References

* [1] Gokce Akcayir and Murat Akcayir. The flipped classroom: A review of its advantages and challenges. _Computers & Education_, 126:334-345, 2018.
* [2] S-I Amari. Learning patterns and pattern sequences by self-organizing nets of threshold elements. _IEEE Transactions on computers_, 100(11):1197-1206, 1972.

Figure 8: Attention alignment improves energy dynamic and brings performance gains.

Figure 9: Zoom-in comparison of InfoSieve and FlipClass on the CUB dataset using t-SNE and PCA. FlipClass shows improved cluster separation and compactness.

* [3] Wenbin An, Wenkai Shi, Feng Tian, Haonan Lin, QianYing Wang, Yaqiang Wu, Mingxiang Cai, Luyan Wang, Yan Chen, Haiping Zhu, et al. Generalized category discovery with large language models in the loop. _arXiv preprint arXiv:2312.10897_, 2023.
* [4] Wenbin An, Feng Tian, Qinghua Zheng, Wei Ding, QianYing Wang, and Ping Chen. Generalized category discovery with decoupled prototypical network. In _Proceedings of the AAAI Conference on Artificial Intelligence_, number 11, pages 12527-12535, 2023.
* [5] Wenbin An, Feng Tian, Wenkai Shi, Yan Chen, Yaqiang Wu, Qianying Wang, and Ping Chen. Transfer and alignment network for generalized category discovery. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 38, pages 10856-10864, 2024.
* [6] Mahmoud Assran, Mathilde Caron, Ishan Misra, Piotr Bojanowski, Florian Bordes, Pascal Vincent, Armand Joulin, Mike Rabbat, and Nicolas Ballas. Masked siamese networks for label-efficient learning. In _European Conference on Computer Vision_, pages 456-473. Springer, 2022.
* [7] Isaiah T Awidi and Mark Paynter. The impact of a flipped classroom approach on student learning experience. _Computers & education_, 128:269-283, 2019.
* [8] Philip Bachman, Ouais Alsharif, and Doina Precup. Learning with pseudo-ensembles. _Advances in neural information processing systems_, 27, 2014.
* [9] Jianhong Bai, Zuozhu Liu, Hualiang Wang, Ruizhe Chen, Lianrui Mu, Xiaomeng Li, Joey Tianyi Zhou, Yang Feng, Jian Wu, and Haoji Hu. Towards distribution-agnostic generalized category discovery. _Advances in Neural Information Processing Systems_, 36, 2024.
* [10] Anwesha Banerjee, Liyana Sahir Kallooriyakath, and Soma Biswas. Amend: Adaptive margin and expanded neighborhood for efficient generalized category discovery. In _Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision_, pages 2101-2110, 2024.
* [11] David Berthelot, Nicholas Carlini, Ekin D Cubuk, Alex Kurakin, Kihyuk Sohn, Han Zhang, and Colin Raffel. Remixmatch: Semi-supervised learning with distribution alignment and augmentation anchoring. In _International conference on learning representations_, 2020.
* [12] Zhaowei Cai, Avinash Ravichandran, Subhransu Maji, Charless Fowlkes, Zhuowen Tu, and Stefano Soatto. Exponential moving average normalization for self-supervised and semi-supervised learning. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pages 194-203, 2021.
* [13] Kaidi Cao, Maria Brbic, and Jure Leskovec. Open-world semi-supervised learning. _arXiv preprint arXiv:2102.03526_, 2021.
* [14] Susan Carey. The origin of concepts. _Journal of Cognition and Development_, 1(1):37-41, 2000.
* [15] Mathilde Caron, Hugo Touvron, Ishan Misra, Herve Jegou, Julien Mairal, Piotr Bojanowski, and Armand Joulin. Emerging properties in self-supervised vision transformers. In _Proceedings of the IEEE/CVF international conference on computer vision_, pages 9650-9660, 2021.
* [16] Florent Chiaroni, Jose Dolz, Ziko Imtiaz Masud, Amar Mitiche, and Ismail Ben Ayed. Mutual information-based generalized category discovery. _arXiv preprint arXiv:2212.00334_, 2, 2022.
* [17] Sua Choi, Dahyun Kang, and Minsu Cho. Contrastive mean-shift learning for generalized category discovery. _arXiv preprint arXiv:2404.09451_, 2024.
* [18] Ekin D Cubuk, Barret Zoph, Jonathon Shlens, and Quoc V Le. Randaugment: Practical automated data augmentation with a reduced search space. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops_, pages 702-703, 2020.
* 299, 2017. URL https://api.semanticscholar.org/CorpusID:119317128.
* Deng et al. [2009] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In _2009 IEEE conference on computer vision and pattern recognition_, pages 248-255. Ieee, 2009.
* Fei et al. [2022] Yixin Fei, Zhongkai Zhao, Siwei Yang, and Bingchen Zhao. Xcon: Learning with experts for fine-grained category discovery. _arXiv preprint arXiv:2208.01898_, 2022.
* Fini et al. [2021] Enrico Fini, Enver Sangineto, Stephane Lathuiliere, Zhun Zhong, Moin Nabi, and Elisa Ricci. A unified objective for novel class discovery. In _Proceedings of the IEEE/CVF International Conference on Computer Vision_, pages 9284-9292, 2021.
* Grandvalet and Bengio [2004] Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. _Advances in neural information processing systems_, 17, 2004.
* Guo et al. [2022] Lan-Zhe Guo, Yi-Ge Zhang, Zhi-Fan Wu, Jie-Jing Shao, and Yu-Feng Li. Robust semi-supervised learning when not all classes have labels. _Advances in Neural Information Processing Systems_, 35:3305-3317, 2022.
* Han et al. [2018] Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang, and Masashi Sugiyama. Co-teaching: Robust training of deep neural networks with extremely noisy labels. _Advances in neural information processing systems_, 31, 2018.
* Han et al. [2019] Kai Han, Andrea Vedaldi, and Andrew Zisserman. Learning to discover novel visual categories via deep transfer clustering. In _Proceedings of the IEEE/CVF International Conference on Computer Vision_, pages 8401-8409, 2019.
* Han et al. [2020] Kai Han, Sylvestre-Alvise Rebuffi, Sebastien Ehrhardt, Andrea Vedaldi, and Andrew Zisserman. Automatically discovering and learning new visual categories with ranking statistics. In _International conference on learning representations_, 2020.
* Hao et al. [2023] Shaozhe Hao, Kai Han, and Kwan-Yee K Wong. Cipr: An efficient framework with cross-instance positive relations for generalized category discovery. _arXiv preprint arXiv:2304.06928_, 2023.
* Hendrycks et al. [2019] Dan Hendrycks, Norman Mu, Ekin D Cubuk, Barret Zoph, Justin Gilmer, and Balaji Lakshminarayanan. Augmix: A simple data processing method to improve robustness and uncertainty. _arXiv preprint arXiv:1912.02781_, 2019.
* Hsu et al. [2018] Yen-Chang Hsu, Zhaoyang Lv, and Zsolt Kira. Learning to cluster in order to transfer across domains and tasks. In _International conference on learning representations_, 2018.
* Hsu et al. [2019] Yen-Chang Hsu, Zhaoyang Lv, Joel Schlosser, Phillip Odom, and Zsolt Kira. Multi-class classification without multi-class labels. In _International conference on learning representations_, 2019.
* Ke et al. [2019] Zhanghan Ke, Daoye Wang, Qiong Yan, Jimmy Ren, and Rynson WH Lau. Dual student: Breaking the limits of the teacher in semi-supervised learning. In _Proceedings of the IEEE/CVF international conference on computer vision_, pages 6728-6736, 2019.
* Krause et al. [2013] Jonathan Krause, Michael Stark, and Li Fei-Fei. 3d object representations for fine-grained categorization. In _Proceedings of the IEEE international conference on computer vision workshops_, pages 554-561, 2013.
* Krizhevsky and Hinton [2009] Alex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images. Technical Report 0, University of Toronto, Toronto, Ontario, 2009. URL https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf.
* Krizhevsky et al. [2012] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. _Advances in neural information processing systems_, 25, 2012.
* Laine and Aila [2017] Samuli Laine and Timo Aila. Temporal ensembling for semi-supervised learning. In _International conference on learning representations_, 2017.

* Lee et al. [2013] Dong-Hyun Lee et al. Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks. _Workshop on challenges in representation learning, ICML_, 3(2):896, 2013.
* Li et al. [2023] Wenbin Li, Zhichen Fan, Jing Huo, and Yang Gao. Modeling inter-class and intra-class constraints in novel class discovery. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pages 3449-3458, 2023.
* Lin et al. [2024] Haonan Lin, Wenbin An, Yan Chen, Feng Tian, Wei Ding, QianYing Wang, Ping Chen, Yaqiang Wu, mingxiang cai, and Guang Dai. Semantic-enhanced prototypical network for universal novel category discovery, 2024. URL https://openreview.net/forum?id=UoaHvbjpbG.
* Lin et al. [2024] Haonan Lin, Wenbin An, Yan Chen, Feng Tian, Yuzhe Yao, Wei Ding, Qianying Wang, and Ping Chen. A tri-branch network with prototype-aware matching for universal category discovery. In _2024 IEEE International Conference on Multimedia and Expo (ICME)_, pages 1-6. IEEE, 2024.
* Liu et al. [2020] Weitang Liu, Xiaoyun Wang, John Owens, and Yixuan Li. Energy-based out-of-distribution detection. _Advances in neural information processing systems_, 33:21464-21475, 2020.
* Loureiro et al. [2021] Bruno Loureiro, Cedric Gerbelot, Hugo Cui, Sebastian Goldt, Florent Krzakala, Marc Mezard, and Lenka Zdeborova. Learning curves of generic features maps for realistic datasets with a teacher-student model. _Advances in Neural Information Processing Systems_, 34:18137-18151, 2021.
* Luo et al. [2018] Yucen Luo, Jun Zhu, Mengxi Li, Yong Ren, and Bo Zhang. Smooth neighbors on teacher graphs for semi-supervised learning. In _Proceedings of the IEEE conference on computer vision and pattern recognition_, pages 8896-8905, 2018.
* Ma et al. [2024] Shijie Ma, Fei Zhu, Zhun Zhong, Xu-Yao Zhang, and Cheng-Lin Liu. Active generalized category discovery. _arXiv preprint arXiv:2403.04272_, 2024.
* MacQueen et al. [1967] James MacQueen et al. Some methods for classification and analysis of multivariate observations. _Proceedings of the fifth Berkeley symposium on mathematical statistics and probability_, 1(14):281-297, 1967.
* Maji et al. [2013] Subhransu Maji, Esa Rahtu, Juho Kannala, Matthew Blaschko, and Andrea Vedaldi. Fine-grained visual classification of aircraft. _arXiv preprint arXiv:1306.5151_, 2013.
* McLachlan [1975] Geoffrey J McLachlan. Iterative reclassification procedure for constructing an asymptotically optimal rule of allocation in discriminant analysis. _Journal of the American Statistical Association_, 70(350):365-369, 1975.
* Miyato et al. [2018] Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. Virtual adversarial training: a regularization method for supervised and semi-supervised learning. _IEEE transactions on pattern analysis and machine intelligence_, 41(8):1979-1993, 2018.
* Murphy [2004] Gregory Murphy. _The big book of concepts_. MIT press, 2004.
* Noroozi and Favaro [2016] Mehdi Noroozi and Paolo Favaro. Unsupervised learning of visual representations by solving jigsaw puzzles. In _European conference on computer vision_, pages 69-84. Springer, 2016.
* Oquab et al. [2023] Maxime Oquab, Timothee Darcet, Theo Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, et al. Dinov2: Learning robust visual features without supervision. _arXiv preprint arXiv:2304.07193_, 2023.
* Otholt et al. [2024] Jona Otholt, Christoph Meinel, and Haojin Yang. Guided cluster aggregation: A hierarchical approach to generalized category discovery. In _Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision_, pages 2618-2627, 2024.
* Pham et al. [2021] Hieu Pham, Zihang Dai, Qizhe Xie, and Quoc V Le. Meta pseudo labels. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pages 11557-11568, 2021.
* Ramsauer et al. [2021] Hubert Ramsauer, Bernhard Schafl, Johannes Lehner, Philipp Seidl, Michael Widrich, Thomas Adler, Lukas Gruber, Markus Holzleitner, Milena Pavlovic, Geir Kjetil Sandve, et al. Hopfield networks is all you need. In _International conference on learning representations_, 2021.

* Rastegar et al. [2024] Sarah Rastegar, Hazel Doughty, and Cees Snoek. Learn to categorize or categorize to learn? self-coding for generalized category discovery. _Advances in Neural Information Processing Systems_, 36, 2024.
* Rizve et al. [2022] Mamshad Nayeem Rizve, Navid Kardan, and Mubarak Shah. Towards realistic semi-supervised learning. In _European Conference on Computer Vision_, pages 437-455. Springer, 2022.
* Rosenberg et al. [2005] Chuck Rosenberg, Martial Hebert, and Henry Schneiderman. _Semi-supervised self-training of object detection models_. Carnegie Mellon University, 2005.
* Russakovsky et al. [2015] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, and Li Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. _International Journal of Computer Vision (IJCV)_, 115(3):211-252, 2015. doi: 10.1007/s11263-015-0816-y.
* Sajjadi et al. [2016] Mehdi Sajjadi, Mehran Javanmardi, and Tolga Tasdizen. Regularization with stochastic transformations and perturbations for deep semi-supervised learning. _Advances in neural information processing systems_, 29, 2016.
* Sarnthein et al. [2023] Felix Sarnthein, Gregor Bachmann, Sotiris Anagnostidis, and Thomas Hofmann. Random teachers are good teachers. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors, _Proceedings of the 40th International Conference on Machine Learning_, volume 202 of _Proceedings of Machine Learning Research_, pages 30022-30041. PMLR, 23-29 Jul 2023. URL https://proceedings.mlr.press/v202/sarnthein23a.html.
* Scheirer et al. [2012] Walter J Scheirer, Anderson de Rezende Rocha, Archana Sapkota, and Terrance E Boult. Toward open set recognition. _IEEE transactions on pattern analysis and machine intelligence_, 35(7):1757-1772, 2012.
* Scudder [1965] Henry Scudder. Probability of error of some adaptive pattern-recognition machines. _IEEE Transactions on Information Theory_, 11(3):363-371, 1965.
* Sohn et al. [2020] Kihyuk Sohn, David Berthelot, Nicholas Carlini, Zizhao Zhang, Han Zhang, Colin A Raffel, Ekin Dogus Cubuk, Alexey Kurakin, and Chun-Liang Li. Fixmatch: Simplifying semi-supervised learning with consistency and confidence. _Advances in neural information processing systems_, 33:596-608, 2020.
* Sun and Li [2022] Yiyou Sun and Yixuan Li. Opencon: Open-world contrastive learning. _Transactions on Machine Learning Research_, 2022.
* Tan et al. [2019] Kiat Chuan Tan, Yulong Liu, Barbara Ambrose, Melissa Tulig, and Serge Belongie. The herbarium challenge 2019 dataset. _arXiv preprint arXiv:1906.05372_, 2019.
* Tarvainen and Valpola [2017] Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. _Advances in neural information processing systems_, 30, 2017.
* Vaswani et al. [2017] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. _Advances in neural information processing systems_, 30, 2017.
* Vaze et al. [2022] Sagar Vaze, Kai Han, Andrea Vedaldi, and Andrew Zisserman. Open-set recognition: A good closed-set classifier is all you need? In _International conference on learning representations_, 2022.
* Vaze et al. [2022] Sagar Vaze, Kai Han, Andrea Vedaldi, and Andrew Zisserman. Generalized category discovery. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pages 7492-7501, 2022.
* Vaze et al. [2024] Sagar Vaze, Andrea Vedaldi, and Andrew Zisserman. No representation rules them all in category discovery. _Advances in Neural Information Processing Systems_, 36, 2024.

* [71] Catherine Wah, Steve Branson, Peter Welinder, Pietro Perona, and Serge Belongie. The caltech-ucsd birds-200-2011 dataset. Technical report, California Institute of Technology, 2011.
* [72] Hongjun Wang, Sagar Vaze, and Kai Han. SPTNet: An efficient alternative framework for generalized category discovery with spatial prompt tuning. In _The Twelfth International Conference on Learning Representations_, 2024. URL https://openreview.net/forum?id=3QLkwU40EE.
* [73] Ye Wang, Yaxiong Wang, Yujiao Wu, Bingchen Zhao, and Xueming Qian. Beyond known clusters: Probe new prototypes for efficient generalized class discovery. _arXiv preprint arXiv:2404.08995_, 2024.
* [74] Yu Wang, Zhun Zhong, Pengchong Qiao, Xuxin Cheng, Xiawu Zheng, Chang Liu, Nicu Sebe, Rongrong Ji, and Jie Chen. Discover and align taxonomic context priors for open-world semi-supervised learning. _Advances in Neural Information Processing Systems_, 36, 2024.
* [75] Xin Wen, Bingchen Zhao, and Xiaojuan Qi. Parametric classification for generalized category discovery: A baseline study. In _Proceedings of the IEEE/CVF International Conference on Computer Vision_, pages 16590-16600, 2023.
* [76] Qizhe Xie, Zihang Dai, Eduard Hovy, Thang Luong, and Quoc Le. Unsupervised data augmentation for consistency training. _Advances in neural information processing systems_, 33:6256-6268, 2020.
* [77] Qizhe Xie, Minh-Thang Luong, Eduard Hovy, and Quoc V Le. Self-training with noisy student improves imagenet classification. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pages 10687-10698, 2020.
* [78] Yi Xu, Lei Shang, Jinxing Ye, Qi Qian, Yu-Feng Li, Baigui Sun, Hao Li, and Rong Jin. Dash: Semi-supervised learning with dynamic thresholding. In _International Conference on Machine Learning_, pages 11525-11536. PMLR, 2021.
* [79] Muli Yang, Yuehua Zhu, Jiaping Yu, Aming Wu, and Cheng Deng. Divide and conquer: Compositional experts for generalized novel class discovery. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pages 14268-14277, 2022.
* [80] Qing Yu, Daiki Ikami, Go Irie, and Kiyoharu Aizawa. Self-labeling framework for novel category discovery over domains. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 36, pages 3161-3169, 2022.
* [81] Alan L Yuille and Anand Rangarajan. The concave-convex procedure (cccp). _Advances in neural information processing systems_, 14, 2001.
* [82] Sangdoo Yun, Dongyoon Han, Seong Joon Oh, Sanghyuk Chun, Junsuk Choe, and Youngjoon Yoo. Cutmix: Regularization strategy to train strong classifiers with localizable features. In _Proceedings of the IEEE/CVF international conference on computer vision_, pages 6023-6032, 2019.
* [83] Bowen Zhang, Yidong Wang, Wenxin Hou, Hao Wu, Jindong Wang, Manabu Okumura, and Takahiro Shinozaki. Flexmatch: Boosting semi-supervised learning with curriculum pseudo labeling. _Advances in Neural Information Processing Systems_, 34:18408-18419, 2021.
* [84] He Zhang and Vishal M Patel. Sparse representation-based open set recognition. _IEEE transactions on pattern analysis and machine intelligence_, 39(8):1690-1696, 2016.
* [85] Sheng Zhang, Salman Khan, Zhiqiang Shen, Muzammal Naseer, Guangyi Chen, and Fahad Shahbaz Khan. Promptcal: Contrastive affinity learning via auxiliary prompts for generalized novel category discovery. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pages 3479-3488, 2023.
* [86] Bingchen Zhao and Kai Han. Novel visual category discovery with dual ranking statistics and mutual knowledge distillation. _Advances in Neural Information Processing Systems_, 34:22982-22994, 2021.

* [87] Mingkai Zheng, Shan You, Lang Huang, Fei Wang, Chen Qian, and Chang Xu. Simmatch: Semi-supervised learning with similarity matching. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pages 14471-14481, 2022.
* [88] Zhun Zhong, Enrico Fini, Subhankar Roy, Zhiming Luo, Elisa Ricci, and Nicu Sebe. Neighborhood contrastive learning for novel class discovery. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pages 10867-10875, 2021.
* [89] Zhi-Hua Zhou. A brief introduction to weakly supervised learning. _National science review_, 5(1):44-53, 2018.
* [90] Xiaojin Jerry Zhu. _Semi-supervised learning literature survey_. University of Wisconsin-Madison Department of Computer Sciences, 2005.

## Appendix

### Table of Contents

* A Theory Assumptions and Proofs
* A.1 Preliminaries: Hopfield Network Energy Function
* A.2 Derivation of The Teacher Attention Update Rule
* B Extended Experimental Analysis of Attention Alignment
* B.1 Representation Discrepancy of Old and New Classes
* B.2 Enhanced Consistency Loss Optimization
* B.3 Attention Alignment Bridges Prior Gap and Benefits Synchronized Learning
* B.4 Attention Specialization in Deep Network Layers
* B.5 Attention Alignment in Layer Selection
* B.6 Time Efficiency of Attention Alignment
* C More Experimental Results
* C.1 Main Results with Error Bars
* C.2 Results on Complex Datasets
* C.3 Clustering and Per-class Prediction Distribution
* C.4 Robustness to Number of Classes
* C.5 Results with Varying Proportion of Old Classes
* D Experimental Settings
* D.1 Implementation Details
* D.2 Design of Data Augmentation
* D.3 Datasets
* D.4 Other Alignment Strategies
* E Related Works
* E.1 Consistency Regularization
* E.2 Novel Category Discovery
* E.3 Generalized Category Discovery
* F Limitations and Future Work
* G Broader ImpactsTheory Assumptions and Proofs

### Preliminaries: Hopfield Network Energy Function

#### a.1.1 Global Convergence of Hopfield Network Energy Function

We first provide the formulation of Hopfield network energy function, and present its convergence, which build the fundamental of our one-step Teacher-Attention Update Strategy. Ramsauer et al. proposed a new energy function that is a modification of the energy of modern Hopfield networks [19], and a new update rule which can be proven to converge to stationary points of the energy.

Given \(N\) stored (key) patterns \(\mathbf{x}_{i}\in\mathbb{R}^{d}\) represented by the matrix \(\mathbf{X}=(\mathbf{x}_{1},\dots,\mathbf{x}_{N})\) with the state (query) pattern \(\bm{\xi}\in\mathbb{R}^{d}\), the energy function \(E\) of the modern Hopfield networks can be expressed:

\[E=\exp(\text{lse}(1,\mathbf{X}^{T}\bm{\xi})),\]

where \(\text{lse}(\beta,x)=\beta^{-1}\log\left(\sum_{i=1}^{N}\exp(\beta\mathbf{x}_{i })\right)\) is the log-sum-exp function (lse) for \(0<\beta\). Ramsauer et al. then proposed to take the logarithm of the negative energy of modern Hopfield networks and add a quadratic term of the current state to ensure that the norm of the state vector \(\bm{\xi}\) remains finite and the energy is bounded, reads:

\[E=-\text{lse}(\beta,\mathbf{X}^{T}\bm{\xi})+\frac{1}{2}\bm{\xi}^{T}\bm{\xi}+ \beta^{-1}\log N+\frac{1}{2}M^{2}.\] (9)

Using \(p=\text{softmax}(\beta\mathbf{X}^{T}\bm{\xi})\), the update rule is defined as:

\[\bm{\xi}^{\text{new}}=f(\bm{\xi})=\mathbf{X}p=\mathbf{X}\text{softmax}(\beta \mathbf{X}^{T}\bm{\xi}),\] (10)

which is the Concave-Convex Procedure (CCCP) for minimizing the energy \(E\) and can be proven as converging globally.

**Theorem A.1** (Global Convergence (Zangwill): Energy).: _The update rule Eq. 10 converges globally: For \(\bm{\xi}^{t+1}=f(\bm{\xi}^{t})\), the energy \(E(\bm{\xi}^{t})\to E(\bm{\xi}^{*})\) for \(t\to\infty\) and a fixed point \(\bm{\xi}^{*}\)._

Proof.: The Concave-Convex Procedure (CCCP) [81] minimizes a function that is the sum of a concave function and a convex function. And since \(1se\) is a convex, \(-\)lse a concave function. Therefore, the energy function \(E(\bm{\xi})\) is the sum of the convex function \(E_{1}(\bm{\xi})=\frac{1}{2}\bm{\xi}^{T}\bm{\xi}+C_{1}\) and the concave function \(E_{2}(\bm{\xi})=-\)lse:

\[E(\bm{\xi})=E_{1}(\bm{\xi})+E_{2}(\bm{\xi}),\] (11) \[E_{1}(\bm{\xi})=\frac{1}{2}\bm{\xi}^{T}\bm{\xi}+\beta^{-1}\ln N+ \frac{1}{2}M^{2}=\frac{1}{2}\bm{\xi}^{T}\bm{\xi}+C_{1},\] \[E_{2}(\bm{\xi})=-\text{lse}(\beta,\mathbf{X}^{T}\bm{\xi}),\]

where \(C_{1}\) does not depend on \(\bm{\xi}\).

The Concave-Convex Procedure (CCCP) applied to \(E\) is

\[\nabla_{\bm{\xi}}E_{1}(\bm{\xi}^{t+1})=-\nabla_{\bm{\xi}}E_{2}(\bm{\xi}^{t}),\] (12)

which results in the update rule:

\[\bm{\xi}^{t+1}=\mathbf{X}p^{t}=X\text{softmax}(\beta\mathbf{X}^{T}\bm{\xi}^{t})\] (13)

where \(p^{t}=\text{softmax}(\beta\mathbf{X}^{T}\bm{\xi}^{t})\). This is the update rule in Eq. 10. 

#### a.1.2 Hopfield Update Rule is Attention of The Transformer

The Hopfield network update rule is the attention mechanism used in transformer. Assume \(N\) stored (key) patterns \(\mathbf{x}_{i}\) and \(S\) state (query) patterns \(\mathbf{r}_{i}\) with dimension \(d_{k}\), we can have \(\mathbf{X}=(\mathbf{x}_{1},\dots,\mathbf{x}_{N})^{T}\) and \(\mathbf{R}=(\mathbf{r}_{1},\dots,\mathbf{r}_{S})^{T}\) combine the \(\mathbf{x}_{i}\) and \(\mathbf{r}_{i}\) as row vectors. Define the key as \(\mathbf{k}_{i}=\mathbf{W}_{K}^{T}\mathbf{x}_{i}\), \(\mathbf{q}_{i}=\mathbf{W}_{Q}^{T}\mathbf{r}_{i}\), and multiply the result of the update rule (Eq. 10) with \(\mathbf{W}_{V}\). By defining the matrices \(\mathbf{K}=(\mathbf{X}\mathbf{W}_{K})^{T}\), \(\mathbf{Q}=(\mathbf{R}\mathbf{W}_{Q})^{T}\), and \(\mathbf{V}=\mathbf{X}\mathbf{W}_{K}\mathbf{W}_{V}=\mathbf{K}^{T}\mathbf{W}_{V}\), where \(\mathbf{W}_{K}\in\mathbb{R}^{d_{x}\times d_{k}}\), \(\mathbf{W}_{Q}\in\mathbb{R}^{d_{r}\times d_{k}}\), \(\mathbf{W}_{V}\in\mathbb{R}^{d_{k}\times d_{o}}\). If \(\beta=1/\sqrt{d_{k}}\) and \(\mathrm{softmax}\in\mathbb{R}^{N}\) is changed to a row vector, there is:

\[\mathrm{softmax}\left(\frac{1}{\sqrt{d_{k}}}\mathbf{Q}\mathbf{K}^{T}\right) \mathbf{V}=\mathrm{softmax}\left(\beta\mathbf{R}\mathbf{W}_{Q}\mathbf{W}_{K}^{ T}\mathbf{X}^{T}\right)\mathbf{X}\mathbf{W}_{K}\mathbf{W}_{V},\] (14)

where the left part is the transformer attention, while the right part is the update rule Eq. 4 multiplied by \(\mathbf{W}_{V}\).

### Derivation of The Teacher Attention Update Rule

We first provide several lemmas for the derivation of the teacher-attention update rule (Eq. 8).

**Lemma A.2**.: _For a given column vector \(\mathbf{x}\in\mathbb{R}^{N}\), we have:_

\[\frac{\partial\log\sum\exp(\beta\mathbf{x})}{\partial\mathbf{x}}=\mathrm{ softmax}(\beta\mathbf{x})\] (15)

Proof.: Consider \(S=\sum_{i=1}^{N}\exp(\beta\mathbf{x}_{i})\) and \(f(\mathbf{x})=\log S\), \(\frac{\partial f(\mathbf{x})}{\partial\mathbf{x}}\) can be computed as:

\[\frac{\partial f(\mathbf{x})}{\partial\mathbf{x}_{j}}=\frac{\partial}{ \partial\mathbf{x}_{j}}\log S=\frac{1}{S}\cdot\frac{\partial S}{\partial \mathbf{x}_{j}}\]

The partial derivative \(\frac{\partial S}{\partial\mathbf{x}_{j}}\) is:

\[\frac{\partial S}{\partial\mathbf{x}_{j}}=\frac{\partial}{\partial\mathbf{x} _{j}}\sum_{i=1}^{N}\exp(\beta\mathbf{x}_{i})=\sum_{i=1}^{N}\frac{\partial}{ \partial\mathbf{x}_{j}}\exp(\beta\mathbf{x}_{i})=\sum_{i=1}^{N}\beta\exp( \beta\mathbf{x}_{i})\delta_{ij}=\beta\exp(\beta\mathbf{x}_{j})\]

where \(\delta_{ij}\) is the Kronecker delta.

Substitute \(\frac{\partial S}{\partial\mathbf{x}_{j}}\) back into the expression for \(\frac{\partial f(\mathbf{x})}{\partial\mathbf{x}_{j}}\):

\[\frac{\partial f(\mathbf{x})}{\partial\mathbf{x}_{j}}=\frac{1}{S}\cdot\beta \exp(\beta\mathbf{x}_{j})=\beta\cdot\frac{\exp(\beta\mathbf{x}_{j})}{S}\]

Recognize that \(\frac{\exp(\beta\mathbf{x}_{j})}{S}\) is the \(j\)-th component of the softmax function applied to \(\beta\mathbf{x}\):

\[\mathrm{softmax}(\beta\mathbf{x})_{j}=\frac{\exp(\beta\mathbf{x}_{j})}{\sum_{i =1}^{N}\exp(\beta\mathbf{x}_{i})}=\frac{\exp(\beta\mathbf{x}_{j})}{S}\]

Therefore, we have:

\[\frac{\partial\log\sum_{i=1}^{N}\exp(\beta\mathbf{x}_{i})}{\partial\mathbf{x}_ {j}}=\beta\cdot\mathrm{softmax}(\beta\mathbf{x})_{j}\]

Putting it back into vector notation:

\[\frac{\partial\log\sum_{i=1}^{N}\exp(\beta\mathbf{x}_{i})}{\partial\mathbf{x}}= \beta\cdot\mathrm{softmax}(\beta\mathbf{x})\]

Since \(\frac{\partial\log\sum\exp(\beta\mathbf{x})}{\partial\mathbf{x}}=\beta^{-1} \frac{\partial\log\sum_{i=1}^{N}\exp(\beta\mathbf{x}_{i})}{\partial\mathbf{x}}\), we can have:

\[\frac{\partial\log\sum\exp(\beta\mathbf{x}_{i})}{\partial\mathbf{x}}=\mathrm{ softmax}(\beta\mathbf{x})\]

This confirms the lemma. 

**Lemma A.3**.: _Let \(\mathbf{k}_{i}\) denote the \(i\)-th row vector of \(\mathbf{K}\in\mathbb{R}^{N\times d}\). Then, we have:_

\[\frac{\partial\mathbf{k}_{i}\mathbf{k}_{i}^{T}}{\partial\mathbf{K}}=2\mathbf{e} _{i}^{N}(\mathbf{e}_{i}^{N})^{T}\mathbf{K},\] (16)

_where \(\mathbf{e}_{i}^{N}\) represents an \(N\)-dimensional column vector where only the \(i\)-th entry is 1, with all other entries set to zero._Proof.: First, note that the expression \(\mathbf{k}_{i}\mathbf{k}_{i}^{T}\) can be equivalently rewritten as \(\mathbf{e}_{i}^{N}\mathbf{k}_{i}\mathbf{k}_{i}^{T}(\mathbf{e}_{i}^{N})^{T}\).

To find the derivative of \(\mathbf{k}_{i}\mathbf{k}_{i}^{T}\) with respect to \(\mathbf{K}\), we need to consider the individual elements of \(\mathbf{K}\). Let \(\mathbf{K}=[\mathbf{k}_{1}^{T};\mathbf{k}_{2}^{T};\cdots;\mathbf{k}_{N}^{T}]\). Therefore, \(\mathbf{k}_{i}^{T}\) is the \(i\)-th row of \(\mathbf{K}\), and we denote this as \(\mathbf{k}_{i}^{T}=\mathbf{K}_{i,:}\).

The differential of \(\mathbf{k}_{i}\mathbf{k}_{i}^{T}\) is given by:

\[d(\mathbf{k}_{i}\mathbf{k}_{i}^{T})=d(\mathbf{K}_{i,:}^{T}\mathbf{K}_{i,:})=d (\mathbf{K}_{i,:}^{T})\mathbf{K}_{i,:}+\mathbf{K}_{i,:}^{T}d(\mathbf{K}_{i,:}).\]

Since \(\mathbf{K}_{i,:}^{T}d(\mathbf{K}_{i,:})=\mathbf{e}_{i}^{N}(\mathbf{e}_{i}^{N })^{T}d\mathbf{K}\mathbf{K}_{i,:}=(\mathbf{e}_{i}^{N}(\mathbf{e}_{i}^{N})^{T} d\mathbf{K})\mathbf{K}\) and similarly for the transpose term, we get:

\[d(\mathbf{k}_{i}\mathbf{k}_{i}^{T})=\mathbf{e}_{i}^{N}(\mathbf{e}_{i}^{N})^{T }d\mathbf{K}\mathbf{K}_{i,:}+\mathbf{K}_{i,:}^{T}(\mathbf{e}_{i}^{N}(\mathbf{ e}_{i}^{N})^{T}d\mathbf{K}).\]

Thus, we can summarize the derivative as:

\[\frac{\partial\mathbf{k}_{i}\mathbf{k}_{i}^{T}}{\partial\mathbf{K}}=2\mathbf{ e}_{i}^{N}(\mathbf{e}_{i}^{N})^{T}\mathbf{K},\]

which matches Eq. 16

**Lemma A.4**.: \[\nabla_{\mathbf{K}}\mathrm{lse}(\mathbf{Q}\mathbf{k}_{i}^{T},\beta)=\mathrm{ softmax}(\beta\mathbf{Q}\mathbf{k}_{i}^{T})\cdot\mathbf{Q}\] (17)

Proof.: Define \(\mathbf{z}=\mathbf{Q}\mathbf{k}_{i}^{T}\), we can rewrite \(\mathrm{lse}(\mathbf{Q}\mathbf{k}_{i}^{T},\beta)\) as:

\[\mathrm{lse}(\mathbf{z},\beta)=\beta^{-1}\log\left(\sum_{j=1}^{N}\exp(\beta z _{j})\right)\]

Using Lemma A.3, we have:

\[\nabla_{\mathbf{z}}\mathrm{lse}(\mathbf{z},\beta)=\mathrm{softmax}(\beta \mathbf{z})\] (18)

Substitute \(\mathbf{z}=\mathbf{Q}\mathbf{k}_{i}^{T}\) back to the expression, we have:

\[\nabla_{\mathbf{K}}\mathrm{lse}(\mathbf{Q}\mathbf{k}_{i}^{T},\beta)=\nabla_{ \mathbf{z}}\mathrm{lse}(\mathbf{z},\beta)\cdot\frac{\partial\mathbf{z}}{ \partial\mathbf{K}}\]

With \(\frac{\partial z_{j}}{\partial\mathbf{k}_{i}}=\mathbf{Q}_{j,:}\) and Eq. 18, we have:

\[\nabla_{\mathbf{K}}\mathrm{lse}(\mathbf{Q}\mathbf{k}_{i}^{T},\beta)=\mathrm{ softmax}(\beta\mathbf{Q}\mathbf{k}_{i}^{T})\cdot\mathbf{Q}\]

Thus, the lemma is proved. 

**Lemma A.5**.: \[\frac{\partial\mathrm{diag}(\mathbf{K}\mathbf{K}^{T})}{\partial\mathbf{K}}=2 \mathbf{K}\] (19)

_where \(\mathrm{diag}(\mathbf{A})\) denotes the trace of \(\mathbf{A}\)._

Proof.: Let us construct a column vector \(\mathbf{x}\) whose \(i\)-th element is given by \(\mathbf{x}_{i}:=\mathbf{k}_{i}\mathbf{k}_{i}^{T}/2\). Then, using Lemmas A.2 and A.3 and the chain rule, we have:

\[\frac{\partial\mathrm{diag}(\mathbf{K}\mathbf{K}^{T})}{\partial \mathbf{K}} =\frac{\partial\log\sum_{i=1}^{N}\exp\left(\frac{1}{2}\mathbf{k}_{i} \mathbf{k}_{i}^{T}\right)}{\partial\mathbf{K}}\] \[=\sum_{i}\frac{\partial\mathbf{x}_{i}}{\partial\mathbf{K}}\frac{ \partial\mathrm{lse}(\mathbf{x},1)}{\partial\mathbf{x}_{i}}\] \[=\sum_{i}\mathbf{e}_{i}^{N}(\mathbf{e}_{i}^{N})^{T}\mathbf{K}[ \mathrm{softmax}(x)]_{i}\qquad\text{Because of Lemma A.2 and A.3}\] \[=\sum_{i}\mathbf{e}_{i}^{N}\mathbf{k}_{i}[\mathrm{softmax}( \mathbf{x})]_{i}=2\mathbf{K}\]

This proves the lemma.

Derivation of Eq. 7.Now we proof that we can approximate the posterior inference of \(p(\mathbf{K}_{t}\mid\mathbf{Q}_{s})\) by the gradient of the log posterior, estimated as:

\[\nabla_{\mathbf{K}_{t}}\log p(\mathbf{K}_{t}\mid\mathbf{Q}_{s}) =-\left(\nabla_{\mathbf{K}_{t}}E(\mathbf{Q}_{s};\mathbf{K}_{t})+ \nabla_{\mathbf{K}_{t}}E(\mathbf{K}_{t})\right)\] \[=\mathrm{sm}\left(\beta\mathbf{Q}_{s}\mathbf{K}_{t}{}^{T} \right)\mathbf{Q}_{s}-\left(\alpha\mathbf{I}+\mathcal{D}\left(\mathrm{sm} \left(\frac{1}{2}\mathrm{diag}(\mathbf{K}_{t}\mathbf{K}_{t}{}^{T})\right) \right)\right)\mathbf{K}_{t},\]

where \(\mathrm{sm}(\mathbf{v})=\mathrm{softmax}(\mathbf{v}):=\exp\left(\mathbf{v}- \mathrm{lse}(\mathbf{v},1)\right)\) and \(\mathcal{D}(\cdot)\) is a vector-to-diagonal-matrix operator. Moreover, recall Eq. 5a and 5b, the energy \(E(\mathbf{Q}_{s};\mathbf{K}_{t})\) and \(E(\mathbf{K}_{t})\) are denoted as:

\[E(\mathbf{Q}_{s};\mathbf{K}_{t})=\frac{\alpha}{2}\mathrm{diag}( \mathbf{K}_{t}\mathbf{K}_{t}{}^{T})-\sum_{i=1}^{N}\mathrm{lse}(\mathbf{Q}_{s} \mathbf{k}_{t,i}^{T},\beta)+c,\] \[E(\mathbf{K}_{t})=\mathrm{lse}\left(\frac{1}{2}\mathrm{diag}( \mathbf{K}_{t}\mathbf{K}_{t}{}^{T}),1\right)=\log\sum_{i=1}^{N}\exp\left( \frac{1}{2}\mathbf{k}_{t,i}\mathbf{k}_{t,i}^{T}\right)+c,\]

Proof.: Using Lemmas A.4 and A.5, we have:

\[\nabla_{\mathbf{K}_{t}}E(\mathbf{Q}_{s};\mathbf{K}_{t})=\alpha\mathbf{K}_{t}- \mathrm{sm}(\beta\mathbf{Q}_{s}\mathbf{K}_{t}^{T})\cdot\mathbf{Q}\]

Since \(\mathbf{K}_{t}\) can be expressed as \(\mathrm{lse}(\frac{1}{2}\mathbf{k}_{t}\mathbf{k}_{t}^{T})\), incorporating Lemma A.5, we have:

\[\nabla_{\mathbf{K}_{t}}E(\mathbf{K}_{t})=\mathcal{D}\left(\mathrm{sm}\left( \frac{1}{2}\mathrm{diag}(\mathbf{K}_{t}\mathbf{K}_{t}{}^{T})\right)\right) \mathbf{K}_{t}\]

Put them together, we have:

\[\nabla_{\mathbf{K}_{t}}\log p(\mathbf{K}_{t}\mid\mathbf{Q}_{s})=\mathrm{sm} \left(\beta\mathbf{Q}_{s}\mathbf{K}_{t}{}^{T}\right)\mathbf{Q}_{s}-\left( \alpha\mathbf{I}+\mathcal{D}\left(\mathrm{sm}\left(\frac{1}{2}\mathrm{diag}( \mathbf{K}_{t}\mathbf{K}_{t}{}^{T})\right)\right)\right)\mathbf{K}_{t},\]

This matches Eq. 7. 

## Appendix B Extended Experimental Analysis of Attention Alignment

In this section, we begin by examining the representation discrepancy between old and new classes, highlighting alignment issues (B.1). Enhanced consistency loss optimization is then detailed, showing improvements in learning stability (B.2). We discuss how attention alignment bridges the prior gap and benefits synchronized learning, enhancing overall performance (B.3). The focus then shifts to attention specialization in deep network layers (B.4), and the performance impact of layer selection for attention alignment on different dataset (B.5). Finally, we represent the negligible impact on computational cost of the Attention Alignment strategy (B.6), thereby proving its practical viability.

### Representation Discrepancy of Old and New Classes

In GCD, directly applying consistency regularization leads to challenges, especially for new classes. Due to the lack of prior knowledge, the teacher struggles to guide the student, resulting in representation discrepancies between the teacher (weakly-augmented) and student (strongly-augmented). This is evident in Fig. 10 (left), where new classes show poor alignment between teacher and student representations compared to known classes.

This discrepancy causes unsynchronized learning, as shown in Fig. 10 (right). The two main phenomena observed are the _learning gap_ and _learning regression_. The _learning gap_ indicates that the student struggles to reach the teacher's level of understanding, particularly for new classes, leading to stagnation. _Learning regression_ affects the teacher, hampering improvement for new classes and causing regression in known classes due to the alignment efforts with the student.

### Enhanced Consistency Loss Optimization

Building on the previous discussion on the representation discrepancy of old and new classes, we address the challenges in optimizing consistency loss (Sec. 2.2) that contribute to the learning gap. Toverify how _FlipClass_ improves this process, we track the consistency loss \(\mathcal{L}_{\text{cons}}\) on new classes. As shown in Fig. 10(a), FlipClass with various update rates (\(\gamma_{\text{update}}\)) demonstrates faster and more stable convergence compared to the SimGCD baseline. Specifically, the experiments on SCars and CUB datasets reveal that FlipClass streamlines the optimization process of consistency loss, leading to more rapid and stable convergence.

### Attention Alignment Bridges Prior Gap and Benefits Synchronized Learning

The enhanced consistency loss optimization further aids in achieving consistency between the student and the teacher, reflecting in two main aspects. Firstly, it **mitigates the effects of prior gap**, as shown in Fig. 10(b). Compared to the categorize errors of SimGCD (Fig. 2), _FlipClass_ reduces the 'False New' error (where the model incorrectly predicts new classes as old classes). This indicates that _FlipClass_ can mitigate overfitting on old classes due to the lack of prior knowledge about new classes. Secondly, as shown in Fig. 12, compared to the traditional teacher-student model used in generalized category discovery (e.g., SimGCD), which suffers from a learning gap, _FlipClass_ successfully **bridges the learning gap**. It achieves better teacher-student learning effects, ensuring more synchronized and stable learning outcomes.

Figure 11: Attention alignment bridges the prior gap with better-converged consistency loss and leads to less biased predictions.

Figure 10: Left: Comparison of representation discrepancy with respect to old and new classes before and after training, showing the misalignment of student (blue) and teacher (red). Right: Learning unsynchronization between teacher and student with trends of _learning regression_ and _learning gap_ for old and new classes.

### Attention Specialization in Deep Network Layers

Moreover, on the SCars dataset, the model shows a greater energy reduction in deeper layers, suggesting a focus on local semantics over general ones. This is illustrated in Fig. 13, where deeper layers emphasize local semantic parts, and earlier ones are associated with general semantics (e.g., texture, color). This local semantic concentration enhances transferability across 'Old' and 'New' classes, with attention alignment in deeper layers (9-10) yielding the highest performance. We observe that different heads attend to disjoint regions of the image, focusing on important parts. After training with our method, attention heads become more specialized to semantic parts, displaying more concentrated and local attention. Our model learns to specialize attention heads (shown as columns) to different semantically meaningful parts, improving transferability between labeled and unlabeled categories.

### Attention Alignment in Layer Selection

Furthermore, we provide the performance of layer selection for attention alignment on CUB and Cifar-10. In this context, "2 layers" means performing attention alignment in the two layers depicted in the Fig. 14. As shown, Cifar-10 (coarse-grained) tends to achieve higher performance when alignment is performed in the middle layers (4-5), while CUB (fine-grained) achieves higher performance with alignment in deeper layers, which aligns with the trend of SCars (Fig. 13). The difference stems from

Figure 12: **Learning curves for SCars and CUB datasets.**_FlipClass_ achieves better synchronized and stable learning effects compared to the traditional teacher-student model.

Figure 13: **Attention heatmap accuracy per layer on SCars dataset**, with deeper layers focused on local semantic features and earlier layers on general features, indicating better transfer learning for old and new classes with attention alignment in deeper network layers.

the dataset nature. CIFAR-10 benefits from middle-layer alignment, capturing general features like shapes and textures, which suffice for its simpler categories. Conversely, CUB requires deeper layer alignment for detailed features needed to distinguish similar bird species. Deeper layers provide the refined features critical for complex tasks.

### Time Efficiency of Attention Alignment

A potential concern is whether attention alignment increases the time cost. Since we perform the alignment in a one-loop manner, the additional time overhead is negligible. This is demonstrated in Table 3, showing that the training and inference times for FlipClass are comparable to those of SimGCD.

We further analyze the potential extra overhead of our attention update strategy compared to a conventional self-attention block:

* **Overall Training Cost**: For a Vision Transformer (ViT) with \(L\) layers, the training cost includes (1) _self-attention cost_, \(O(L\cdot N\cdot d_{k}^{2})\); (2) _feed-forward network (FFN) cost_, \(O(L\cdot N\cdot d_{k}\cdot d_{m})\). Here, \(N\) is the sequence length, \(d_{k}\) is the feature dimension, and \(d_{m}\) is the hidden dimension in the FFN.
* **Attention Update Cost**: Our update strategy applies only to 2-3 layers (see Appendix B.5), with each update having the same cost as one FFN operation per layer.

In sum, we add **2-3 extra FFN-like operations** during the forward pass. And there is no impact on the backward pass, as only the last block is updated without introducing extra parameters for optimization. Therefore, the additional overhead is minimal, with only a slight increase in training time, as shown in Table 4.

Figure 14: Layer selection performance for attention alignment on Cifar-10 and CUB datasets. Higher performance is observed in middle layers for Cifar-10 and deeper layers for CUB, indicating the need to tailor attention alignment to the nature of the data.

\begin{table}
\begin{tabular}{l|c c c c} \hline \hline \multirow{2}{*}{**Method**} & \multicolumn{3}{c}{**ImageNet-100**} & \multicolumn{2}{c}{**AirCraft**} \\  & Training time (Min) Infer. time (Sec) Training time (Min) Infer. time (Sec) \\ \hline SimGCD [75] & 1639 & 591 & 224 & 17 \\ \hline
**FlipClass (Ours)** & 1648 & 591 & 229 & 17 \\ \hline \hline \end{tabular}
\end{table}
Table 3: Comparison of training and inference times for SImGCD on ImageNet-100 and AirCraft datasets, with 200 epochsIn summary, the attention update operation introduces a small extra overhead equivalent to **2-3 additional FFN operations**, which remains insignificant relative to the overall training cost, especially given the performance improvements achieved by FlipClass.

## Appendix C More Experimental Results

We detail our experimental results, including main outcomes with error bars for statistical significance (C.1). We evaluate performance on complex datasets (C.2), analyze clustering and per-class prediction distributions (C.3). Additionally, we examine robustness to varying numbers of old and new classes (C.4), and investigate how different proportions of old classes affect performance (C.5), demonstrating our method's stability and adaptability.

### Main Results with Error Bars

Table 5 reports error bars to provide a clear understanding of the statistical significance and variability of the main results in our experiments. Specifically, we include both the mean and standard deviation (std) values for the performance of our _FlipClass_ across different datasets and class types (All, Old, New). The standard deviations are calculated from five independent runs with random seeds, offering insight into the consistency of our method's performance.

### Results on Complex Datasets

Here, we discuss the performance of various methods on challenging datasets, specifically Herbraium19 [65] and ImageNet-1K [35]. Herbraium19, a long-tailed dataset, poses significant challenges due to the varying frequencies of different categories, leading to unbalanced cluster sizes. Table 6 demonstrates the robustness of our proposed _FlipClass_, in handling such frequency imbalances and its ability to accurately distinguish categories even with few examples. Table 7 showcases the performance on ImageNet-1K, a large-scale generic classification dataset, in evaluating the model's capability in real-world applications of generalized category discovery. The results demonstrate the robustness of _FlipClass_ for tasks involving both familiar and unfamiliar data in complex, real-world scenarios.

### Clustering and Per-class Prediction Distribution

**Clustering Analysis.** Fig. 15 presents a visual comparison of the clustering results obtained with _FlipClass_ against the existing state-of-the-art method, InfoSieve [55], on Cifar-10 and Cifar-100 datasets. On Cifar-10, FlipClass forms clusters that exhibit higher compactness and purity, indicating

\begin{table}
\begin{tabular}{l c c} \hline \hline Setting & CUB & SCars \\ \hline w/o Attention Updating & 65s & 93s \\ w/ Attention Updating (2 layers) & 71s & 101s \\ w/ Attention Updating (3 layers) & 76s & 109s \\ \hline \hline \end{tabular}
\end{table}
Table 4: Time cost (seconds) per forward pass on CUB and Stanford Cars.

\begin{table}
\begin{tabular}{l|c c|c c|c c} \hline \hline \multirow{2}{*}{**Dataset**} & \multicolumn{2}{c|}{**All**} & \multicolumn{2}{c|}{**Old**} & \multicolumn{2}{c}{**New**} \\  & Mean & Std & Mean & Std & Mean & Std \\ \hline CIFAR10 & 98.5 & \(\pm\) 0.1 & 97.6 & \(\pm\) 0.2 & 99.0 & \(\pm\) 0.4 \\ CIFAR100 & 85.2 & \(\pm\) 0.3 & 84.9 & \(\pm\) 0.5 & 85.8 & \(\pm\) 1.2 \\ ImageNet-100 & 86.7 & \(\pm\) 0.5 & 94.3 & \(\pm\) 1.2 & 82.9 & \(\pm\) 0.9 \\ CUB & 71.3 & \(\pm\) 1.4 & 71.3 & \(\pm\) 3.2 & 71.3 & \(\pm\) 2.0 \\ Stanford Cars & 63.1 & \(\pm\) 0.7 & 81.7 & \(\pm\) 1.8 & 53.8 & \(\pm\) 1.7 \\ FGVC-Aircraft & 59.3 & \(\pm\) 1.98 & 66.9 & \(\pm\) 3.66 & 55.4 & \(\pm\) 4.20 \\ \hline \hline \end{tabular}
\end{table}
Table 5: Complete results of _FlipClass_ in have five independent runs with random seeds.

enhanced feature discrimination and reduced interclass confusion. In contrast, on Cifar-100, although InfoSieve forms visually more compact clusters, these clusters show less purity, with a higher incidence of false class predictions.

**Prediction Distribution and Class-specific Accuracies.** Fig. 16 evaluates the prediction distribution and class-specific accuracies of _FlipClass_ compared to InfoSieve [55]. _FlipClass_ demonstrates a better fit to the true distribution, whereas InfoSieve shows skewed predictions. Moreover, _FlipClass_ significantly outperforms InfoSieve in recognizing tail classes on the CUB and Stanford Cars datasets, improving accuracy and reducing prediction bias.

### Robustness to Number of Classes

**Varying Number of Classes during Clustering.** In the main experiments (Section 5), the class number, \(K\), is assumed as a known prior following prior works [69, 64, 75, 70], however, this setting has been questioned as impractical [9, 74, 73]. In Fig. 17, we conduct experiments when this assumption is removed, evaluating results with different numbers of classes, where the ratio changes from 80% to 200% compared to the ground truth number of classes. During clustering (e.g., KMeans [45]), a predefined class number lower than the ground truth significantly limits the ability to discover new classes, causing the model to focus more on old classes. Conversely, increasing the class number results in less harm to the generic image recognition datasets (e.g., Cifar-100) and can even be beneficial for some fine-grained, long-tailed datasets (e.g., CUB). This phenomenon occurs because overestimating the number of classes allows the model to maintain higher flexibility and adaptability in recognizing new classes in these fine-grained, challenging datasets. For fine-grained, class-distribution biased datasets like CUB, overestimating the class number helps capture subtle differences between closely related categories, thereby improving class separation and reducing prediction bias. However, for generic datasets like Cifar-100, the visual differences between classes are more pronounced, and overestimating the class number can introduce unnecessary complexity, leading to overfitting and decreased performance.

**Estimation of Number of Classes.** Additionally, to further validate the robustness of our model, we trained FlipClass using an estimated number of classes in the dataset, where the number of classes

\begin{table}
\begin{tabular}{l c c c c} \hline \hline \multirow{2}{*}{**Methods**} & \multirow{2}{*}{**Pretraining**} & \multicolumn{3}{c}{Herbarium19} \\  & & **All** & **Known** & **Novel** \\ \hline k-means [1967] & DINO & 13.0 & 12.2 & 13.4 \\ ORCA [2021] & DINO & 20.9 & 30.9 & 15.5 \\ RS+ [2020] & DINO & 27.9 & 55.8 & 12.8 \\ UNO+ [2021] & DINO & 28.3 & 53.7 & 12.8 \\ GCD [2022] & DINO & 35.4 & 51.0 & 27.0 \\ CMS [2024] & DINO & 36.4 & 54.9 & 26.4 \\ OpenCon [2022] & DINO & 39.3 & 58.9 & 28.6 \\ InfoSieve [2024] & DINO & 41.0 & 55.4 & 33.2 \\ MIB [2022] & DINO & 42.3 & 56.1 & 34.8 \\ PCAL [2023] & DINO & 37.0 & 52.0 & 28.9 \\ SimGCD [2023] & DINO & 44.0 & 58.0 & 36.4 \\ AMEND [2024] & DINO & 44.2 & 60.5 & 35.4 \\ \(\mu\)GCD [2024] & DINO & 45.8 & **61.9** & 37.2 \\ \hline FlipClass (Ours) & DINO & **46.3** & 60.2 & **40.7** \\ \hline \hline \end{tabular}
\end{table}
Table 6: Performance comparison of different methods on the Herbarium19 dataset.

\begin{table}
\begin{tabular}{l c c c c} \hline \hline \multirow{2}{*}{**Methods**} & \multirow{2}{*}{**Pretraining**} & \multicolumn{3}{c}{**ImageNet-1K**} \\  & & **All** & **Known** & **Novel** \\ \hline GCD [69] & DINO & 52.5 & 72.5 & 42.2 \\ SimGCD [2023] & DINO & 57.1 & 77.3 & 46.9 \\ \hline FlipClass (Ours) & DINO & **59.2** & **78.9** & **49.5** \\ \hline \hline \end{tabular}
\end{table}
Table 7: Performance comparison of different methods on the ImageNet-1K dataset.

is predicted using the over-clustering method from GCD [69]. We obtained a similar predicted number of classes as SimGCD. As expected, our method performs worse on Cifar-100 when using an estimated number of classes due to the mismatch between the estimated and actual class distribution. Interestingly, the performance of SimGCD (traditional teacher-student model) improves on CUB with both new and old classes, while our FlipClass makes improvements on old classes but sees a decrease in new classes.

### Results with Varying Proportion of Old Classes

In the primary experiments, we fix the number of the old classes \(|\mathcal{C}_{\ell}|\) (details in _Appendix_ D.3). Here, we experiment with our method by changing the class split setting. Specifically, on Cifar-100 (\(|\mathcal{C}_{\ell}|=80\)) and CUB (\(|\mathcal{C}_{\ell}|=100\)) datasets, we test with fewer old classes, as shown in Fig. 18. For Cifar-100 and CUB, as the number of old classes decreases, the accuracy for both old and new classes slightly declines but remains stable. This demonstrates _FlipClass_'s effectiveness in leveraging additional old class information and robustness in handling varying numbers of known classes.

Figure 16: **Prediction distribution and class-specific accuracies** of InfoSieve and _FlipClass_ on Cifar-10, CUB, and Stanford Cars datasets.

Figure 15: **Comparison of clustering results on Cifar-10 and Cifar-100 datasets using GCD, InfoSieve, and our _FlipClass_.**

## Appendix D Experimental Settings

### Implementation Details

We develop our FlipClass upon the SimGCD [75] baseline on the pre-trained ViT-B/16 DINO2[15]. Specifically, we take the final feature corresponding to the \(\mathsf{CLS}\) token from the backbone as the image feature, which has a dimension of 768. For the feature extractor \(\mathbb{F}\), we only fine-tune the last block. We set the balancing factor \(\lambda\) to 0.35 and the temperature values \(\tau_{u}\) and \(\tau_{c}\) to 0.07 and 1.0, respectively, following SimGCD. For the temperature values \(\tau_{t}\) and \(\tau_{s}\) in the classification losses, we also set them to 0.07 and 0.1. For update rule (Eq. 8), we set \(\alpha=0\), \(\beta=1\), \(\gamma_{\text{update}}=0.1\) and \(\gamma_{\text{reg}}=0.5\). All experiments are conducted using a single NVIDIA A100 GPU with 200 epochs, which we find sufficient for the losses to plateau.

Footnote 2: https://huggingface.co/facebook/dino-vitb16

### Design of Data Augmentation

In this experimental setup, we design both weak and strong augmentations for the teacher and student networks. For weak augmentation, we use common techniques such as RandomHorizontalFlip and RandomCrop for all datasets, aiming to pass less perturbed versions of the input images to the teacher network. For the strong augmentation that is applied to the images fed to the student, we incorporate more aggressive transformations to expose the student to a wider range of variations. Specifically, we add RandomResizedCrop with a scale range of 0.3 to 1.0, which allows for more aggressive cropping and resizing. Additionally, we include Gaussian blurring to simulate different levels of image blurriness. For datasets that are used for generic recognition tasks, we further enhance the strong augmentation by including ColorJitter with probability 0.8 and RandomGrayscale with probability 0.2. Solarization inverts pixel values above a threshold, simulating the effect of solarizing an image, while Grayscale converts the image to black and white, reducing color information. These additional augmentations help expose the student network to even more diverse image variations, improving its robustness and generalization capabilities.

Figure 17: **Results with varying numbers of classes during clustering, where the ratio changes from 80% to 200% of the ground truth number of classes.**

\begin{table}
\begin{tabular}{l c|c c c|c c c} \hline \hline \multirow{2}{*}{**Method**} & \multirow{2}{*}{\(|C_{\text{all}}|/|C_{\ell}|\)} & \multicolumn{3}{c}{**CUB**} & \multicolumn{3}{c}{**Cifar100**} \\  & & **All** & **Old** & **New** & **All** & **Old** & **New** \\ \hline SimGCD [75] & GT (200/100) & 60.3 & 65.6 & 57.7 & 80.1 & 81.2 & 77.8 \\ FlipClass (Ours) & GT (200/100) & **71.3** & 71.3 & **71.3** & **85.2** & **84.9** & **85.8** \\ \hline SimGCD [75] & Est. (231/109) & 61.0 & 66.0 & 58.6 & 81.1 & 90.9 & 76.1 \\ FlipClass (Ours) & Est. (299/108) & 70.5 & **72.7** & 69.4 & 84.2 & 84.3 & 84.1 \\ \hline \hline \end{tabular}
\end{table}
Table 8: Performance of FlipClass and the baseline method SimGCD with an estimated number of categories on CUB and Cifar100. Bold values represent the best results.

### Datasets

We follow the dataset settings from earlier works [75; 70] to subsample the training dataset. Specifically, 50% of known categories and all samples of unknown categories are used for training. For all datasets except Cifar-100, 50% of the categories are considered known during training, whereas for Cifar-100, 80% of the categories are known during training. Detailed statistics are displayed in Table 9. Below is a summary of the datasets and how their combination supports experiments in generalized category discovery:

_Cifar-10/1003_[34] are coarse-grained datasets consisting of general categories with low-resolution images and even class distribution.

Footnote 3: https://www.cs.toronto.edu/~kriz/cifar.html

_ImageNet-100/1K4_ is a subset of 100/1K categories from the coarse-grained ImageNet5[35; 58] dataset. It includes a large scale of high-resolution real-world images with evenly distributed classes.

Footnote 4: https://www.kaggle.com/c/imagenet-object-localization-challenge/overview/description

_CUB_ (Caltech-UCSD Birds-200-2011)6[71] is widely used for fine-grained image recognition, containing different bird species distinguished by subtle details.

Footnote 5: https://www.image-net.org/download.php

_Stanford Cars7[33]_ is a fine-grained dataset of various car brands, providing multi-view objects for class detection and scene understanding, challenging real-world applications in distinguishing subtle appearance differences.

Footnote 7: https://www.vision.caltech.edu/datasets/cub_200_2011/

_FGVC-Aircraft_ (Fine-Grained Visual Classification of Aircraft)8[46] is a fine-grained dataset organized in a three-level hierarchy. At the finer level, differences between models are subtle but visually measurable. Unlike animals, aircraft are rigid and less deformable, presenting variations in purpose, size, designation, structure, historical style, and branding.

Footnote 7: https://www.kaggle.com/datasets/jessicali9530/stanford-cars-dataset

Figure 18: Results with varying the number of old classes \(|\mathcal{C}_{\ell}|\).

\begin{table}
\begin{tabular}{l c c c c c c c} \hline \hline  & CIFAR10 & CIFAR100 & ImageNet100 & CUB200 & Stanford Cars & Aircraft & Herbarium 19 \\ \hline \(|\mathcal{Y}^{l}|\) & 5 & 80 & 50 & 100 & 98 & 50 & 341 \\ \(|\mathcal{Y}^{u}|\) & 10 & 100 & 100 & 200 & 196 & 100 & 683 \\ \(|\mathcal{D}^{l}|\) & 12.5k & 20k & 31.9k & 1.5k & 2.0k & 1.7k & 8.9k \\ \(|\mathcal{D}^{u}|\) & 37.5k & 30k & 95.3k & 4.5k & 6.1k & 5.0k & 25.4k \\ \hline \hline \end{tabular}
\end{table}
Table 9: Statistics of the datasets used in our experiments.

_Herbarium 19_ (FGVC 2019 Herbarium Challenge)9[65] provides a curated dataset of over 46,000 herbarium specimens across 680 species, presenting a long-tailed distribution and challenges for species recognition.

Footnote 9: https://www.kaggle.com/c/herbarium-2019-fgvc6

### Other Alignment Strategies

In the ablation studies (Section 5.3), we apply different strategies such as distribution alignment [11], FixMatch [63] and CORAL. These strategies are employed to encourage the consistency between the teacher and student, therefore modeling \(\mathbf{\Re}\) in Eq. 2. We briefly provide the main idea of these alignment strategies below.

**Distribution alignment** is designed by maintaining a running average of the model's predictions on unlabeled data \(\tilde{p}(y)\). Given the model's prediction \(q=p_{\text{model}}(y\mid\mathbf{x}_{u})\) on an unlabeled example \(\mathbf{x}_{u}\), \(q\) is scaled by the ratio \(p(y)/\tilde{p}(y)\) and then renormalize the result to form a valid probability distribution: \(\tilde{q}=\text{Normalize}(q\times p(y)/\tilde{p}(y))\).

**FixMatch** is a semi-supervised learning method that combines consistency regularization and pseudo-labeling. It works by first generating pseudo-labels for unlabeled images using the model's predictions on weakly enhanced versions of those images, retaining only high-confidence predictions as following:

\[\ell_{u}=\frac{1}{\mu B}\sum_{b=1}^{\mu B}\mathbbm{1}\left(\max\left(q_{b} \right)\geq\tau\right)\mathrm{H}\left(\hat{q}_{b},p_{\text{m}}\left(y\mid \mathcal{A}\left(u_{b}\right)\right)\right),\]

where \(\tau\) is a scalar hyperparameter denoting the threshold above which a pseudo-label should be retained. Then, the model is trained to predict these pseudo-labels using strongly enhanced versions of the same images. The loss function consists of two cross-entropy terms: a supervised loss for labeled data and an unsupervised loss for unlabeled data, where the unsupervised loss utilizes the pseudo-labels calculated from weakly enhanced images and the model's predictions on strongly enhanced images.

**CORAL** (CORrelation ALignment) aligns the second-order statistics (covariances) of two spaces. Specifically, CORAL minimizes the difference in covariance matrices between the student and teacher representations (\(\mathbf{S}\) and \(\mathbf{T}\)). The goal of CORAL is to find a transformation for \(\mathbf{S}\) that minimizes the Frobenius norm of the difference between the covariance matrices of \(\mathbf{S}\) and \(\mathbf{T}\), denoting \(\mathbf{C}_{S}\) and \(\mathbf{C}_{T}\), respectively. CORAL minimizes the following objective:

\[\min_{S^{\prime}}\|\mathbf{C}_{S^{\prime}}-\mathbf{C}_{T}\|_{F}^{2},\]

where \(\mathbf{C}_{S^{\prime}}\) is the covariance matrix of the transformed student representations \(\mathbf{S}^{\prime}\), and \(\|.\|_{F}\) denotes the Frobenius norm.

## Appendix E Related Works

### Consistency Regularization

In semi-supervised learning (SSL), the goal is to enhance model performance by leveraging unlabeled data, traditionally drawn from the same class spectrum as the labeled data [90]. A key strategy in SSL, consistency regularization [36], in recent years, centers on promoting model stability by ensuring that the teacher instance (weakly-augmented instance) and the student instance (strongly-augmented instance) yield coherent predictions[11, 63, 78, 87, 83]. Building on the \(\Pi\)-Model's teacher-student framework, several approaches have advanced its capabilities [66, 43, 77, 12, 53]. MeanTeacher [66] deploys an exponential moving average of the model parameters to stablize the teacher's output. NoisyStudent [77] employs a self-training strategy that incorporates noise into the student model's training, cycling the improved student back into the teacher role. Previous methods in SSL have largely concentrated on promoting the teacher's performance, often overlooking whether the student can keep pace, and neglecting the harmony of interaction. Our approach pivots to synchronizing the teacher's and student's attention, a shift that's especially pivotal in GCD, where consistency is challenged by the introduction of new classes. This strategy ensures a balanced teacher-student dynamic, crucial for effective consistency regularization in the open-world setting.

### Novel Category Discovery

Novel category discovery (NCD) is first formalized as cross-task transfer in [30], which aims to discover unseen categories from unlabeled data that have nonoverlapped classes with the labeled ones. Earlier works [31, 26, 86, 79, 38] mostly maintain two networks for learning from labeled and unlabeled data respectively. AutoNovel [27] introduces a three-stage framework. Specifically, the model is firstly trained with the whole dataset in a self-supervised manner and then fine-tuned only with the fully-supervised labeled set to capture the semantic knowledge for the final joint-learning stage. UNO [22] addresses the problem by jointly modeling the labeled and unlabeled sets to prevent the model from overfitting to labeled categories. Similarly, NCL [88] generates pairwise pseudo labels for unlabeled data and mixes samples in the feature space to construct hard negative pairs.

### Generalized Category Discovery

Generalized Category Discovery (GCD) extends NCD by categorizing unlabeled images from both seen and unseen categories [69], which tackles this issue by tuning the representation of the pre-trained ViT model with DINO ([15], [51]) with contrastive learning, followed by semi-supervised k-means clustering. ORCA [13] considers the problem from a semi-supervised learning perspective and introduces an adaptive margin loss for better intra-class separability for both seen and unseen classes. CiPR [28] introduces a method for more effective contrastive learning and a hierarchical clustering method for GCD without requiring the category number in the unlabeled data to be known a priori. SimGCD [75] proposes a parametric method with entropy regularization to improve performance. TIDA [74] discovers multi-granularity semantic concepts and then leverages them to enhance representation learning and improve the quality of pseudo labels. Moreover, \(\mu\)GCD [70] take a leap forward by extending the MeanTeacher paradigm to the GCD task. Instead of managing dual models as in \(\mu\)GCD, our approach achieves teacher-student consistency more effectively within a single-model structure, streamlining computational demands. Crucially, we found that the learning discrepancy between teachers and students in the open-world context is the reason why consistency is difficult to achieve, and solved this problem by synchronizing the attention of teachers and students.

## Appendix F Limitations and Future Work

**Catastrophic Forgetting.** While our method achieves significant improvement on new classes, the performance on old classes, particularly on CUB, lacks compared to the state-of-the-art methods. We attribute this to a phenomenon akin to catastrophic forgetting, where the model forgets previously learned concepts. Addressing these issues is essential for enhancing the robustness and effectiveness of the proposed methods.

**Sub-optimal \(K\) Estimation.** As shown in Appendix C.4, for fine-grained, class-distribution biased datasets like CUB, overestimating the class number helps capture subtle differences between closely related categories, thereby improving class separation and reducing prediction bias. However, for coarse-grained datasets like CIFAR-100, overestimating the class number can introduce unnecessary complexity, leading to overfitting and decreased performance. Some works have delved into this path and show promising performance [73, 74, 9], highlighting the potential of tailored \(K\) estimation strategies to balance complexity and performance across different types of datasets.

**Data Augmentation to Enhance Teacher-Student Consistency**. Effective data augmentation techniques has been investigated a lot in semi-supervised learning [18, 82, 48, 76, 29], the techniques for generalized category discovery are still lacking, which affects the consistency between the teacher and student models. The strength of data augmentation for new classes needs careful control to avoid ineffective learning due to excessive noise or insufficient variability. Additionally, preventing data leakage during augmentation is critical, as pretrained diffusion models can compromise evaluation integrity by leaking training data. Addressing these issues is essential for enhancing the robustness and effectiveness of the proposed methods.

## Appendix G Broader Impacts

Our study extends the capability of AI systems from the closed world to the open world, fostering AI systems capable of categorizing and organizing open-world data automatically. While GeneralizedCategory Discovery (GCD) has many real-world applications, it can be unreliable and must be applied with caution. Currently, supervised learning with extensive fine annotations is the mainstream solution for many computer vision tasks, but the cost and difficulty of obtaining these annotations can be prohibitive. Our work addresses this issue by advancing an open-set semi-supervised learning paradigm, significantly reducing the need for precise annotations and promoting the application of AI models in areas where annotations are difficult to obtain.

This work provides a new idea for open-set semi-supervised learning. Specifically, while conventional approaches apply closed-world semi-supervised learning techniques to generalized category discovery, they rarely consider the attention alignment gap between teacher and student models. We point out that bridging this gap can significantly improve learning efficiency and accuracy. We hope that this methodology can be generalized to more relevant label-efficient tasks, promoting broader applications of AI in scenarios with limited labeled data.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: The main claims made in the abstract and introduction (Section 1) accurately reflect the paper's contributions and scope. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: The limitations of the work are discussed in _Appendix_ F. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes]Justification: Concerning the proposition 4.1, _Appendix_ A.1 and A provide its corresponding proofs, with a short proof sketch to provide intuition. Guidelines:

* The answer NA means that the paper does not include theoretical results.
* All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
* All assumptions should be clearly stated or referenced in the statement of any theorems.
* The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.
* Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.
* Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: Refer to _Appendix_ D.1 for implementation details, the provided code in the supplementary materials ensure the reproducibility as well. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code**Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: Refer to provided code in the supplementary materials. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: Table 9 specifies all the training and test detail. _Appendix_ D.1 provides the employed hyperparameters. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: _Appendix_ C.1 provides the statistical significance of the experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).

* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: _Appendix_ D.1 and B.6 provide sufficient information on the computer resources and the related costs. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: The authors have reviewed and understand the NeurIPS Code of Ethics, and confirm that their research conforms to it in every respect. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: Potential societal impacts of the work are discussed in _Appendix_ G. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.

* Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.
* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).

11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: The paper poses no such risks. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.

12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: The original papers of assets, and the corresponding versions are provided in Section 5, _References_ and _Appendix_ D.1. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.

* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [Yes] Justification: We will well document the assets when we officially release our code. Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: The paper does not describe potential risks incurred by study participants. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.