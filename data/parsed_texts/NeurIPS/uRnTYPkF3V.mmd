Sequential Probability Assignment with Contexts: Minimax Regret, Contextual Shtarkov Sums, and Contextual Normalized Maximum Likelihood

 Ziyi Liu

University of Toronto & Vector Institute

kevind.liu@mail.utoronto.ca &Idan Attias

Ben-Gurion University & Vector Institute

idanatti@post.bgu.ac.il &Daniel M. Roy

University of Toronto & Vector Institute

daniel.roy@utoronto.ca

###### Abstract

We study the fundamental problem of sequential probability assignment, also known as online learning with logarithmic loss, with respect to an arbitrary, possibly nonparametric hypothesis class. Our goal is to obtain a complexity measure for the hypothesis class that characterizes the minimax regret and to determine a general, minimax optimal algorithm. Notably, the sequential \(\ell_{\infty}\) entropy, extensively studied in the literature (Rakhlin and Sridharan, 2015, Bilodeau et al., 2020, Wu et al., 2023), was shown to not characterize minimax regret in general. Inspired by the seminal work of Shtarkov (1987) and Rakhlin, Sridharan, and Tewari (2010), we introduce a novel complexity measure, the _contextual Shtarkov sum_, corresponding to the Shtarkov sum after projection onto a multiary context tree, and show that the worst case log contextual Shtarkov sum equals the minimax regret. Using the contextual Shtarkov sum, we derive the minimax optimal strategy, dubbed _contextual Normalized Maximum Likelihood_ (cNML). Our results hold for sequential experts, beyond binary labels, which are settings rarely considered in prior work. To illustrate the utility of this characterization, we provide a short proof of a new regret upper bound in terms of sequential \(\ell_{\infty}\) entropy, unifying and sharpening state-of-the-art bounds by Bilodeau et al. (2020) and Wu et al. (2023).

## 1 Introduction

Sequential probability assignment is a fundamental problem with connections to information theory (Ris84; MF98; XB00), machine learning (CL06; Vov95; RST15; FKLMS18; Sha20), and portfolio optimization (Ke15; Cov74; Cov91; CO96; Fed91). In the original non-contextual setup, the learner aims to assign probabilities to a series of labels, which are revealed sequentially. The goal is to offer probabilistic forecasts over the label set such that the probability assigned to any observed sequence is comparable to that assigned by the best model in any fixed class of models.

The celebrated work of Shtarkov (Sht87) characterized minimax regret for context-free sequential probability assignment in terms of what is now known as the _Shtarkov sum_, and subsequently described the minimax algorithm, _Normalized Maximum Likelihood_ (NML). NML represents the ideal probabilistic forecast in the sense of minimax regret, providing a benchmark for universal coding and prediction strategies. While often not used directly due to its computational complexity, NML has guided the design of practical algorithms and informed the development of efficient approxima

[MISSING_PAGE_FAIL:2]

A long line of work has focused on controlling minimax regret for rich classes in terms of covering numbers. [1, 1] upper bounded the regret in terms of the (non-sequential) uniform covering number of the class. However, this complexity measure proved to be insufficient for obtaining optimal rates. [15] improved regret upper bounds by proposing a sequential covering measure. Thereafter, by utilizing the self-concordance property and the curvature of the log loss, [1] further improved the upper bound in terms of the sequential covering number for nonparametric Lipschitz classes, through a non-constructive proof. [20] proposed a Bayesian algorithmic approach in order to upper bound the regret using a global notion of sequential covering. Notably, both the global and local sequential covering numbers do not fully characterize the regret, and the algorithm in [20] is not minimax optimal. By relaxing the worst-case analysis, [1] studied this problem within the smoothed analysis framework, where nature is not fully adversarial but constrained.

Online learning with respect to arbitrary hypothesis classes and the zero-one loss, in the realizable case, is known to be characterized by the Littestone dimension [14]. The agnostic case was addressed by [1, 1]. Understanding sequential complexities in online learning with Lipschitz losses was extensively studied by [1, 15, 16, 17]. Note that the logarithmic loss is neither Lipschitz nor bounded. Recently, [1] characterized online regression in the realizable case, for any approximate pseudo-metric, such as the \(\ell_{p}\) loss.

## 2 Preliminaries

Notation.For a positive integer \(K\), let \([K]:=\{1,2,\ldots,K\}\). For a finite set \(\mathcal{K}\) with \(|\mathcal{K}|=K\), we use \(\Delta(\mathcal{K})\) to denote the set of all distributions on \(\mathcal{K}\). We may identify \(\mathcal{K}\) with \([K]\) (under arbitrary enumeration of elements in \(\mathcal{K}\)) and treat elements of \(\Delta(\mathcal{K})\) as vectors in \(\mathbb{R}^{K}\). For a vector \(p\in\mathbb{R}^{K}\) and \(i\in[K]\), let \(p(i)\) be the \(i\)-th coordinate of \(p\). Let \(\Delta^{+}(\mathcal{K})=\{p\in\Delta(\mathcal{K}):p(k)>0,\forall k\in\mathcal{K}\}\). For a general finite sequence \((a_{i})_{i=1}^{N}\), we will use \(a_{n:m}\) to denote the sub-sequence \((a_{n},\ldots,a_{m})\) for any \(n\leq m\) and the empty sequence for \(n>m\). For any set \(\mathcal{A}\), let \(\mathcal{A}^{*}=\cup_{k\geq 0}\mathcal{A}^{k}\) be the set of all finite length sequences over \(\mathcal{A}\).

Sequential probability assignment and minimax regret.Let \(\mathcal{X}\) be the context space and \(\mathcal{Y}\) be the finite label space. In each round \(t\in[T]\) during the game of sequential probability assignment, the learner receives a context \(x_{t}\in\mathcal{X}\) from nature and assigns a probability distribution \(\hat{p}_{t}\in\Delta(\mathcal{Y})\) to the possible labels. Then nature reveals the true label \(y_{t}\in\mathcal{Y}\) and the learner incurs a loss \(\ell(\hat{p}_{t},y_{t})=-\log(\hat{p}_{t}(y_{t}))\). Throughout, the learner is required to predict nearly as well as the best expert from an expert class, which is modeled as an arbitrary hypothesis class \(\mathcal{F}\subseteq\{(\mathcal{X}\times\mathcal{Y})^{*}\times\mathcal{X} \rightarrow\Delta(\mathcal{Y})\}\). More formally, the goal of the learner is make their _regret_ with respect to \(\mathcal{F}\),

\[\mathcal{R}_{T}(\mathcal{F};\hat{p}_{1:T},x_{1:T},y_{1:T})=\sum_{t=1}^{T}\ell (\hat{p}_{t},y_{t})-\inf_{f\in\mathcal{F}}\sum_{t=1}^{T}\ell(f(x_{1:t},y_{1:t- 1}),y_{t}),\]

as small as possible for all sequences \(\mathbf{x}\) and \(\mathbf{y}\) generated by nature, possibly in an adversarial manner. Here \(f(x_{1:t},y_{1:t-1})\in\Delta(\mathcal{Y})\) can be understood as the prediction made by expert \(f\) at round \(t\) using past observations \((x_{1:t-1},y_{1:t-1})\) as well as the fresh context \(x_{t}\). The main focus is to study the _minimax regret_\(\mathcal{R}_{T}(\mathcal{F})\), which can be written as the following extensive form

\[\mathcal{R}_{T}(\mathcal{F})=\sup_{x_{t}}\inf_{\hat{p}_{1}}\sup_{y_{1}}\cdots \sup_{x_{T}}\inf_{\hat{p}_{T}}\sup_{y_{T}}\mathcal{R}_{T}(\mathcal{F};\hat{p} _{1:T},x_{1:T},y_{1:T}),\]

where \(x_{t}\in\mathcal{X},\hat{p}_{t}\in\Delta(\mathcal{Y})\) and \(y_{t}\in\mathcal{Y},\forall t\in[T]\). In light of this formulation, we can see that the minimax regret concerns both the learner and the nature to be _adaptive_, meaning that their actions can rely on the revealed history so far.

**Remark 2.1** (Sequential vs non-sequential experts): Experts \(f\) as mappings from \((\mathcal{X}\times\mathcal{Y})^{*}\times\mathcal{X}\) to \(\Delta(\mathcal{Y})\) are sometimes called _fully sequential_ experts [20] due to their ability to predict based on the past history. However, the literature (e.g. [15, 1, 16]) often considers the more limited notion of _non-sequential_ experts, modeled as \(\mathcal{F}\subseteq\{\mathcal{X}\rightarrow\Delta(\mathcal{Y})\}\), reflecting the fact that prediction made by each expert \(f\) is simply \(f(x_{t})\) in each round \(t\). In contrast, our results are more general as our novel techniques can be applied to the more flexible sequential experts.

Multiary trees.The complexity of online learning problems stems from the sequential and adaptive nature of the adversary, which we can capture with _multiary trees_. Formally, for a general space \(\mathcal{A}\) and a finite set \(\mathcal{K}\), an \(\mathcal{A}\)-valued \(\mathcal{K}\)-ary tree \(\mathbf{v}\) of depth \(d\) is a sequence of mappings \(\mathbf{v}_{t}:\mathcal{K}^{t-1}\to\mathcal{A}\) for \(t\in[d]\). A _path_ in a depth-\(d\) tree is a sequence \(\boldsymbol{\varepsilon}=(\varepsilon_{1},\ldots,\varepsilon_{d})\in\mathcal{ K}^{d}\). We use the notation \(\mathbf{v}_{t}(\boldsymbol{\varepsilon})\) to denote \(\mathbf{v}_{t}(\varepsilon_{1},\ldots,\varepsilon_{t-1})\) for \(t\in[d]\) and the boldface notation \(\mathbf{v}(\boldsymbol{\varepsilon})\) to denote \((\mathbf{v}_{1}(\boldsymbol{\varepsilon}),\ldots,\mathbf{v}_{d}(\boldsymbol {\varepsilon}))\in\mathcal{A}^{d}\). Throughout we will only consider \(\mathcal{Y}\)-ary trees valued in either \(\mathcal{X}\) or \(\Delta(\mathcal{Y})\), where the paths are denoted by the boldface \(\mathbf{y}\). We refer to \(\mathcal{X}\)-valued trees as _context trees_ and \(\Delta(\mathcal{Y})\)-valued trees as _probabilistic trees_.

Time-varying context sets.So far we consider the context set \(\mathcal{X}\) to be constant over time. But all of our results can be extended easily to allow for time-varying context spaces. Details of this generalization can be found in Appendix C.

### Prior work: the Shtarkov sum in context-free and fixed designs

Before introducing our complexity measure that characterizes \(\mathcal{R}_{T}(\mathcal{F})\), we review some prior settings where the minimax regret can be characterized by the well-studied _Shtarkov sum_. First we introduce the notion of likelihood of a hypothesis \(f\) with respect to a context and label sequence, which plays a key role in defining complexity measures and optimal algorithms.

**Definition 2.2** (Likelihood): For \(f:(\mathcal{X}\times\mathcal{Y})^{*}\times\mathcal{X}\to\Delta(\mathcal{Y})\) and length\(-d\) sequences \(x_{1:d}\in\mathcal{X}^{d},y_{1:d}\in\mathcal{Y}^{d}\), the likelihood \(P_{f}(y_{1:d}|x_{1:d})\) is defined as

\[P_{f}(y_{1:d}|x_{1:d})=\prod_{t=1}^{d}f(x_{1:t},y_{1:t-1})(y_{t}),\]

where we use the compact notation \(f(x_{1:t},y_{1:t-1})\) for \(f(x_{1},y_{1},\ldots,x_{t-1},y_{t-1},x_{t})\).

In the classical context-free setting where \(\mathcal{X}\) can be thought of as a singleton, any sequential expert \(f\) degenerates to a joint distribution over label sequences. Indeed, given any label sequence \(y_{1:t-1}\), \(f(y_{1:t-1})\in\Delta(\mathcal{Y})\) can be interpreted as the conditional distribution \(f\) assigns to the next label \(y_{t}\). We use \(P_{f}(y_{1:d})=\prod_{t=1}^{d}f(y_{1:t-1})(y_{t})\) to denote this distribution. Similarly, the learner's strategy is also specified by a joint distribution that is decomposed to a sequence of conditional distributions \(\hat{p}_{t}=\hat{p}_{t}(\cdot|y_{1:t-1})\in\Delta(\mathcal{Y})\). In this setup the minimax regret \(\mathcal{R}_{T}(\mathcal{F})\) is characterized by the Shtarkov sum [14].

**Proposition 2.3** ([14]): _In the context-free setting, for any hypothesis class \(\mathcal{F}\) and horizon \(T\), the Shtarkov sum \(S_{T}(\mathcal{F})\) is defined as_

\[S_{T}(\mathcal{F})=\sum_{y_{1:T}\in\mathcal{Y}^{T}}\sup_{f\in\mathcal{F}}P_{f} (y_{1:T}).\]

_Moreover, the minimax regret is given by \(\mathcal{R}_{T}(\mathcal{F})=\log S_{T}(\mathcal{F})\), and the unique minimax optimal strategy is the normalized maximum likelihood (NML) distribution given by_

\[p_{nml}(y_{1:T})=\frac{\sup_{f\in\mathcal{F}}P_{f}(y_{1:T})}{\sum_{y^{\prime}_{ 1:T}\in\mathcal{Y}^{T}}\sup_{f\in\mathcal{F}}P_{f}(y^{\prime}_{1:T})},\qquad \forall y_{1:T}\in\mathcal{Y}^{T}.\]

To go beyond this classical context-agnostic setting and incorporate contextual information, prior work (e.g. [10]) also considered an easier problem than the aforementioned sequential probability assignment, by forcing nature to reveal the context sequence \(x_{1:T}\) to the learner at the start of the game. This is known as the _fixed design_ setting or _transductive online learning_[23], where the goal is to characterize the so-called _fixed design maximal_ minimax regret

\[\mathcal{R}_{T}^{\mathrm{FD}}(\mathcal{F}):=\sup_{x_{1:T}\in\mathcal{X}^{T}} \inf_{\hat{p}_{1}}\sup_{y_{1}}\cdots\inf_{\hat{p}_{T}}\sup_{y_{T}}\mathcal{R}_ {T}(\mathcal{F};\hat{p}_{1:T},x_{1:T},y_{1:T}).\]

It is straightforward to see that after projecting on \(x_{1:T}\), the hypothesis class \(\mathcal{F}\) again collapses to a set of joint distributions over \(\mathcal{Y}^{T}\) specified by the likelihood function in Definition 2.2. Moreover, this set of distributions can be accessed by the learner from the start, so the fixed design setting can be essentially reduced to the context-free setting. To be more specific, for any \(f\in\mathcal{F}\), it induces an expert in the context-free setting after being projected on \(x_{1:T}\), which is denoted by \(f|_{x_{1:T}}\) and

\[f|_{x_{1:T}}(y_{1:t-1}):=f(x_{1:t},y_{1:t-1})\in\Delta(\mathcal{Y}),\forall t \in[T],y_{1:t-1}\in\mathcal{Y}^{t-1},\]

and let \(\mathcal{F}|_{x_{1:T}}:=\{f|_{x_{1:T}}:f\in\mathcal{F}\}\). Then given any predetermined \(x_{1:T}\), the learner is equivalently competing with \(\mathcal{F}|_{x_{1:T}}\) in the context-free setting. With the following natural variant of the Shtarkov sum, we can easily characterize \(\mathcal{R}_{T}^{\mathrm{FD}}(\mathcal{F})\).

**Definition 2.4** (Conditional Shtarkov sum): Given a context sequence \(x_{1:T}\in\mathcal{X}^{T}\), the Shtarkov sum of \(\mathcal{F}\) conditioned on \(x_{1:T}\) is

\[S_{T}(\mathcal{F}|x_{1:T}):=\sum_{y_{1:T}\in\mathcal{Y}^{T}}\sup_{f\in \mathcal{F}}P_{f}(y_{1:T}|x_{1:T}).\]

In fact, \(S_{T}(\mathcal{F}|x_{1:T})\) is just the Shtarkov sum of the projected class \(\mathcal{F}|_{x_{1:T}}\) in the context-free setting. The following result characterizes the fixed-design setting:

**Proposition 2.5** (Minimax regret, fixed design [1]): _In the fixed design setting, for any hypothesis class \(\mathcal{F}\) and horizon \(T\), the fixed design maximal minimax regret is_

\[\mathcal{R}_{T}^{\mathrm{FD}}(\mathcal{F})=\sup_{x_{1:T}\in\mathcal{X}^{T}} \log S_{T}(\mathcal{F}|x_{1:T}),\]

_and, given any context sequence \(x_{1:T}\), the minimax optimal response is NML with respect to \(\mathcal{F}|_{x_{1:T}}\)._

## 3 Minimax regret via contextual Shtarkov sum

Now we state one of our main results about the characterization of the minimax regret of sequential probability assignment. First we introduce the key concept of _contextual Shtarkov sum_, which is a natural generalization of Shtarkov sum in the context-free setting.

**Definition 3.1** (Contextual Shtarkov sum): The _contextual Shtarkov sum_\(S_{T}(\mathcal{F}|\mathbf{x})\) of a hypothesis class \(\mathcal{F}\) on a given context tree \(\mathbf{x}\) of depth \(T\) is defined as

\[S_{T}(\mathcal{F}|\mathbf{x}):=\sum_{\mathbf{y}\in\mathcal{Y}^{T}}\sup_{f\in \mathcal{F}}P_{f}(\mathbf{y}|\mathbf{x}(\mathbf{y})).\]

Just like the conditional Shtarkov sum, the contextual Shtarkov sum \(S_{T}(\mathcal{F}|\mathbf{x})\) can be interpreted as the Shtarkov sum of the projected class \(\mathcal{F}|_{\mathbf{x}}:=\{f|_{\mathbf{x}}:f\in\mathcal{F}\}\) where \(f|_{\mathbf{x}}\) is the induced context-free expert specified by

\[f|_{\mathbf{x}}(y_{1:t-1}):=f(\mathbf{x}(y_{1:t-1}),y_{1:t-1})\in\Delta( \mathcal{Y}),\forall t\in[T],y_{1:t-1}\in\mathcal{Y}^{t-1},\]

where we have slightly abused the notation to use \(\mathbf{x}(y_{1:t-1})\) to denote the length-\(t\) context sequence obtained by tracing tree \(\mathbf{x}\) through the (partial) path \(y_{1:t-1}\). Next we show that the minimax regret \(\mathcal{R}_{T}(\mathcal{F})\) is characterized by the worst-case contextual Shtarkov sum:

**Theorem 3.2** (Main result: minimax regret): _For any hypothesis class \(\mathcal{F}\subseteq\{(\mathcal{X}\times\mathcal{Y})^{*}\times\mathcal{X} \rightarrow\Delta(\mathcal{Y})\}\) and horizon \(T\),_

\[\mathcal{R}_{T}(\mathcal{F})=\sup_{\mathbf{x}}\log S_{T}(\mathcal{F}|\mathbf{x }),\]

_where the supremum is taken over all \(\mathcal{X}\)-valued context trees \(\mathbf{x}\) of depth \(T\)._

Since any context sequence \(x_{1:T}\) can be thought as a special context tree \(\mathbf{x}\) that is constant in each level \(t\in[T]\) (i.e., \(\mathbf{x}_{t}(\mathbf{y})=x_{t},\forall\mathbf{y}\)), we can find that the supremum over context trees in Theorem 3.2 strictly subsumes the supremum over context sequences in Proposition 2.5. Thus we can see the separation between \(\mathcal{R}_{T}(\mathcal{F})\) and \(\mathcal{R}_{T}^{\mathrm{FD}}(\mathcal{F})\) is clearly exhibited.

The full proof of Theorem 3.2 as well as an overview are provided in Appendix A.

### Applications: an improved regret upper bound in terms of sequential entropy

To illustrate the utility of our characterization in Theorem 3.2, we walk through some examples where we are able to recover and _sharpen_ existing regret upper bounds with relatively short proofs via contextual Shtarkov sum. As a start, we provide a short proof in Appendix A.6 of the classical regret bound for a finite hypothesis class.

**Proposition 3.3** (Finite classes): _For any \(\mathcal{F}\subseteq[0,1]^{\mathcal{X}}\) and horizon \(T\), \(\mathcal{R}_{T}(\mathcal{F})\leq\log|\mathcal{F}|\)._

Let us go back to the binary label setting with non-sequential experts, that is, \(\mathcal{Y}=\{0,1\}\) and \(\mathcal{F}\subseteq[0,1]^{\mathcal{X}}\), and \(f(x)\in[0,1]\) is interpreted as the probability assigned to label \(1\) by this expert \(f\). We will show a regret bound that _outperforms_ the state-of-the-art ones in [1, 2] with a surprisingly simple proof. To proceed, we need the following notation. Given a context tree \(\mathbf{x}\) of depth \(T\), let \(\mathcal{F}\circ\mathbf{x}=\{f\circ\mathbf{x}:f\in\mathcal{F}\}\), where \(f\circ\mathbf{x}\) is the \([0,1]\)-valued tree such that

\[(f\circ\mathbf{x})_{t}(\mathbf{y})=f(\mathbf{x}_{t}(\mathbf{y})),\forall \mathbf{y}\in\mathcal{Y}^{T}.\]

Next we introduce the definitions of sequential \(\ell_{\infty}\) covers and entropy.

**Definition 3.4** (Sequential \(\ell_{\infty}\) cover and entropy): Given a hypothesis class \(\mathcal{F}\subseteq[0,1]^{\mathcal{X}}\) and a context tree \(\mathbf{x}\) of depth \(T\), we say a collection of \(\mathbb{R}\)-valued trees \(V_{\mathbf{x},\alpha}\) is a sequential cover of \(\mathcal{F}\circ\mathbf{x}\) at scale \(\alpha>0\) if for any \(f\in\mathcal{F},\mathbf{y}\in\mathcal{Y}^{T}\), there exists some \(v\in V_{\mathbf{x},\alpha}\) such that

\[|f(\mathbf{x}_{t}(\mathbf{y}))-v_{t}(\mathbf{y})|\leq\alpha,\forall t\in[T].\]

Let the sequential \(\ell_{\infty}\) covering number \(\mathcal{N}_{\infty}(\mathcal{F}\circ\mathbf{x},\alpha,T)\) be the size of the smallest such cover. The sequential \(\ell_{\infty}\) entropy of \(\mathcal{F}\) at scale \(\alpha\) and depth \(T\) is defined as the logarithm of the worst-case sequential covering number: \(\mathcal{H}_{\infty}(\mathcal{F},\alpha,T):=\sup_{\mathbf{x}}\log\mathcal{N}_ {\infty}(\mathcal{F}\circ\mathbf{x},\alpha,T)\).

**Definition 3.5** (Global sequential \(\ell_{\infty}\) cover and entropy): Given a hypothesis class \(\mathcal{F}\subseteq[0,1]^{\mathcal{X}}\), we say a collection of mappings \(\mathcal{G}_{\alpha}\subseteq[0,1]^{\mathcal{X}_{*}}\) is a _global_ sequential cover of \(\mathcal{F}\) at scale \(\alpha>0\) and depth \(T\) if for any \(f\in\mathcal{F},x_{1:T}\in\mathcal{X}^{T}\), there exists some \(g\in\mathcal{G}_{\alpha}\) such that

\[|f(x_{t})-g(x_{1:t})|\leq\alpha,\forall t\in[T].\]

Let the _global_ sequential \(\ell_{\infty}\) covering number \(\mathcal{N}_{G}(\mathcal{F},\alpha,T)\) be the size of the smallest such cover. The _global_ sequential \(\ell_{\infty}\) entropy of \(\mathcal{F}\) at scale \(\alpha\) and depth \(T\) is defined as

\[\mathcal{H}_{G}(\mathcal{F},\alpha,T):=\log\mathcal{N}_{G}(\mathcal{F},\alpha, T).\]

**Proposition 3.6** ([1, 2]): _For any \(\mathcal{F}\subseteq[0,1]^{\mathcal{X}}\) and horizon \(T\),_

\[\mathcal{R}_{T}(\mathcal{F})\leq\min\bigg{\{}\underbrace{\inf_{\alpha>0}\{4T \alpha+c\mathcal{H}_{\infty}(\mathcal{F},\alpha,T)\}}_{\text{\@@cite[cite]{[ \@@bibref{}{BFR20}{}{}]}}},\underbrace{\inf_{\alpha>0}\{T\log(1+2\alpha)+ \mathcal{H}_{G}(\mathcal{F},\alpha,T)\}}_{\text{\@@cite[cite]{[\@@bibref{} {WHG82}{}{}]}}}\bigg{\}},\]

_where \(c=\frac{2-\log(2)}{\log(3)-\log(2)}\in(3,4)\)._

It is easy to show that \(\mathcal{H}_{\infty}(\mathcal{F},\alpha,T)\leq\mathcal{H}_{G}(\mathcal{F}, \alpha,T)\), but, in general, the two bounds in Proposition 3.6 are incomparable due to constants and different dependence on \(\alpha\) (more discussions on these bounds are deferred to Appendix C). Starting from the contextual Shtarkov sum, we are able to derive a bound that combines the best of these two bounds:

**Theorem 3.7** (Main result: sequential entropy bound): _For any \(\mathcal{F}\subseteq[0,1]^{\mathcal{X}}\) and horizon \(T\),_

\[\mathcal{R}_{T}(\mathcal{F})\leq\inf_{\alpha>0}\Big{\{}T\log(1+2\alpha)+ \mathcal{H}_{\infty}(\mathcal{F},\alpha,T)\Big{\}}.\]Proof.: For any scale \(\alpha>0\) and depth-\(T\) context tree \(\mathbf{x}\), let \(V_{\mathbf{x},\alpha}\) be a sequential cover of \(\mathcal{F}\circ\mathbf{x}\) at scale \(\alpha\) with size \(\mathcal{N}_{\infty}(\mathcal{F}\circ\mathbf{x},\alpha,T)\). We can always assume \(V_{\mathbf{x},\alpha}\) to be \([0,1]\)-valued without loss of generality because otherwise we can just truncate it without violating its coverage guarantee. Define the smoothed covering set \(\tilde{V}_{\mathbf{x},\alpha}=\left\{\tilde{v}:\forall t\in[T],\tilde{v}_{t}( \cdot)=\frac{v_{t}(\cdot)+\alpha}{1+2\alpha},v\in V_{\mathbf{x},\alpha}\right\}\), inspired by [1, 1]. Then for any \(f\in\mathcal{F},\mathbf{y}\in\mathcal{Y}^{T}\), there exists some \(v\in V_{\mathbf{x},\alpha}\) such that \(|f(\mathbf{x}_{t}(\mathbf{y}))-v_{t}(\mathbf{y})|\leq\alpha,\forall t\in[T]\) and hence \(\tilde{v}\) satisfies

\[\frac{f(\mathbf{x}_{t}(\mathbf{y}))}{\tilde{v}_{t}(\mathbf{y})}\leq 1+2\alpha, \quad\frac{1-f(\mathbf{x}_{t}(\mathbf{y}))}{1-\tilde{v}_{t}(\mathbf{y})}\leq 1 +2\alpha.\]

Hence

\[P_{f}(\mathbf{y}|\mathbf{x}(\mathbf{y}))=\prod_{t=1}^{T}f(\mathbf{x}_{t}( \mathbf{y}))^{y_{t}}(1-f(\mathbf{x}_{t}(\mathbf{y})))^{1-y_{t}}\leq(1+2\alpha) ^{T}\prod_{t=1}^{T}\tilde{v}_{t}(\mathbf{y})^{y_{t}}(1-\tilde{v}_{t}(\mathbf{y }))^{1-y_{t}},\]

and

\[\sum_{\mathbf{y}}\sup_{f\in\mathcal{F}}P_{f}(\mathbf{y}|\mathbf{x }(\mathbf{y})) \leq(1+2\alpha)^{T}\sum_{\mathbf{y}}\sup_{\tilde{v}\in\tilde{V}_ {\mathbf{x},\alpha}}\prod_{t=1}^{T}\tilde{v}_{t}(\mathbf{y})^{y_{t}}(1-\tilde{ v}_{t}(\mathbf{y}))^{1-y_{t}}\] \[\leq(1+2\alpha)^{T}\sum_{\tilde{v}\in\tilde{V}_{\mathbf{x},\alpha }}\sum_{\mathbf{y}}\prod_{t=1}^{T}\tilde{v}_{t}(\mathbf{y})^{y_{t}}(1-\tilde{ v}_{t}(\mathbf{y}))^{1-y_{t}}=(1+2\alpha)^{T}|\tilde{V}_{\mathbf{x},\alpha}|,\]

where the last equality follows from Lemma D.1, treating \(\tilde{v}\) as sequential experts. Finally,

\[\mathcal{R}_{T}(\mathcal{F}) =\sup_{\mathbf{x}}\log\Biggl{(}\sum_{\mathbf{y}}\sup_{f\in \mathcal{F}}P_{f}(\mathbf{y}|\mathbf{x}(\mathbf{y}))\Biggr{)}\] \[\leq\sup_{\mathbf{x}}\log\Bigl{(}(1+2\alpha)^{T}|\tilde{V}_{ \mathbf{x},\alpha}|\Bigr{)}=T\log(1+2\alpha)+\mathcal{H}_{\infty}(\mathcal{F}, \alpha,T).\]

Since our choice of \(\alpha\) is arbitrary, the result follows. 

### The inadequacy of sequential \(\ell_{\infty}\) covering number

We conclude this section with a discussion on the suboptimality of regret bounds based on sequential covering numbers as in Proposition 3.6 and Theorem 3.7. Let us consider the binary label setting and the following hypothesis classes over the unit Hilbert ball \(\mathcal{X}=\mathbb{B}_{2}\):

\[\mathcal{F}^{\mathrm{Lin}}:=\left\{x\mapsto\frac{\langle w,x\rangle+1}{2}:w \in\mathbb{B}_{2}\right\},\quad\mathcal{F}^{\mathrm{AbsLin}}:=\left\{x\mapsto |\langle w,x\rangle|:w\in\mathbb{B}_{2}\right\}.\] (1)

We can see that the sequential \(\ell_{\infty}\) covering numbers of \(\mathcal{F}^{\mathrm{Lin}}\) and \(\mathcal{F}^{\mathrm{AbsLin}}\) are of the same order for all scales, thus the aforementioned results will yield the same regret bound for these two classes. However, we have \(\mathcal{R}_{T}(\mathcal{F}^{\mathrm{Lin}})=\tilde{O}(\sqrt{T})\) while \(\mathcal{R}_{T}(\mathcal{F}^{\mathrm{AbsLin}})=\tilde{O}(T^{2/3})\)[1, 1], which implies that the sequential \(\ell_{\infty}\) covering number, in its current form within the regret bound, cannot characterize the minimax regret.

It is worth mentioning that an \(\tilde{\Omega}(\sqrt{T})\) lower bound on \(\mathcal{R}_{T}(\mathcal{F}^{\mathrm{Lin}})\) is achievable, via an \(\tilde{\Omega}(1/\alpha^{2})\) lower bound on the sequential fat-shattering dimension \(\mathrm{sfat}_{\alpha}(\mathcal{F}^{\mathrm{Lin}})\) combined with Proposition 2 in [1]. The same lower bound also holds in the finite-dimensional case, where \(\mathbb{B}_{2}\) is a unit \(d\)-dimensional Euclidean ball with \(d\geq\sqrt{T}\)[1, 1]. Our proof (Appendix A.7) of the next result works in both the infinite and finite dimensional (with \(d\geq T\)) cases.

**Lemma 3.8** (\(\Omega(\sqrt{T})\)**lover bound for the linear class \(\mathcal{F}^{\mathrm{Lin}}\)): _For \(\mathcal{F}^{\mathrm{Lin}}\) defined as in Eq. (1) with \(\mathbb{B}_{2}\) being the unit Hilbert ball or the unit \(d\)-dimensional Euclidean ball with \(d\geq T\), then_

\[\mathcal{R}_{T}(\mathcal{F}^{\mathrm{Lin}})\geq\mathcal{R}_{T}^{\mathrm{ED}}( \mathcal{F}^{\mathrm{Lin}})\geq\sqrt{T}/4.\]

The proof of Lemma 3.8 is based on lower bounding the conditional Shtarkov sums (and hence the contextual Shtarkov sums) of \(\mathcal{F}^{\mathrm{Lin}}\). From Theorem 3.2 we know that the \(\tilde{O}(\sqrt{T})\) upper bound holds for the log of contextual Shtarkov sums as well but we do not have a direct proof of this fact so far.

**Input:** Hypothesis class \(\mathcal{F}\), horizon \(T\)

**For \(t=1,2,...,T\)do**

1. Observe context \(x_{t}\in\mathcal{X}\)
2. If \(\sup_{f\in\mathcal{F}}P_{f}(y_{1:t-1}|x_{1:t-1})>0\), predict \(\hat{p}_{t}\in\Delta(\mathcal{Y})\) with \[\hat{p}_{t}(y)=\frac{\sup_{\mathbf{x}}S_{T}^{x_{1:t},(y_{1:t-1},y)}(\mathcal{ F}|\mathbf{x})}{\sum_{y^{\prime}\in\mathcal{Y}}\sup_{\mathbf{x}}S_{T}^{x_{1:t},(y_{1: t-1},y^{\prime})}(\mathcal{F}|\mathbf{x})},\forall y\in\mathcal{Y},\] (2) and otherwise set \(\hat{p}_{t}\) to be an arbitrary member of \(\Delta^{+}(\mathcal{Y})\)
3. Receive label \(y_{t}\in\mathcal{Y}\)

**End for**

**Algorithm 1** Contextual Normalized Maximum Likelihood (cNML)

## 4 Contextual NML, the minimax optimal algorithm

So far we have settled the minimax regret of sequential probability assignment in a nonconstructive way. Now we switch to the algorithmic lens to study the optimal strategy that achieves the minimax regret. Remarkably, we show that the minimax optimal algorithm can be described by a data-dependent variant of the contextual Shtarkov sum, which is named contextual Shtarkov sum _with prefix_.

**Definition 4.1** (Contextual Shtarkov sum with prefix): Given sequences \(x_{1:t}\in\mathcal{X}^{t},y_{1:t}\in\mathcal{Y}^{t},t\in[T]\) and a context tree \(\mathbf{x}\) of depth \(T-t\), the contextual Shtarkov sum \(S_{T}^{x_{1:t},y_{1:t}}(\mathcal{F}|\mathbf{x})\) of \(\mathcal{F}\) on \(\mathbf{x}\) with prefix \(x_{1:t},y_{1:t}\) is defined as

\[S_{T}^{x_{1:t},y_{1:t}}(\mathcal{F}|\mathbf{x})=\sum_{\mathbf{y}\in\mathcal{Y }^{T-t}}\sup_{f\in\mathcal{F}}P_{f}(y_{1:t},\mathbf{y}|x_{1:t},\mathbf{x}( \mathbf{y})).\]

Now we present our prediction strategy, _contextual normalized maximum likelihood_ (cNML), which is summarized in Algorithm 1. In each round \(t\), with \(x_{1:t},y_{1:t-1}\) as past observations, the learner first checks whether \(\sup_{f\in\mathcal{F}}P_{f}(y_{1:t-1}|x_{1:t-1})>0\) since if that is not the case and \(\sup_{f\in\mathcal{F}}P_{f}(y_{1:t-1}|x_{1:t-1})=0\), the cumulative losses of all experts in \(\mathcal{F}\) have already blown up to \(+\infty\) and the learner only needs to predict any \(\hat{p}\in\Delta^{+}(\mathcal{Y})\) in all remaining rounds. On the other hand, if \(\sup_{f\in\mathcal{F}}P_{f}(y_{1:t-1}|x_{1:t-1})>0\), then

\[\max_{y\in\mathcal{Y}}\sup_{\mathbf{x}}S_{T}^{x_{1:t},(y_{1:t-1},y)}(\mathcal{ F}|\mathbf{x})>0\]

and the \(\hat{p}_{t}\) given by Eq. (2) is indeed a valid member of \(\Delta(\mathcal{Y})\) (shown in Appendix B) and is used as the learner's prediction. The following theorem shows that cNML is the minimax optimal algorithm, with proof deferred to Appendix B.

**Theorem 4.2** (Main result: optimal algorithm): _The contextual normalized maximum likelihood strategy (Algorithm 1) is minimax optimal._

To see that cNML is reduced to NML in the context-free setting, it suffices to consider the case where \(\sup_{f\in\mathcal{F}}P_{f}(y_{1:T})>0\) since otherwise NML will simply assign \(0\) probability on this sequence \(y_{1:T}\) and during the actual round-wise implementation of NML, it also predicts an arbitrary element from \(\Delta^{+}(\mathcal{Y})\) in those rounds \(t\) where \(\sup_{f}P_{f}(y_{1:t-1})=0\). Now for any \(y_{1:T}\) such that \(\sup_{f\in\mathcal{F}}P_{f}(y_{1:T})>0\), the prediction by cNML in each round \(t\) is

\[\hat{p}_{t}(y)=\frac{\sum_{\mathbf{y}\in\mathcal{Y}^{T-t}}\sup_{f\in\mathcal{ F}}P_{f}(y_{1:t-1},y,\mathbf{y})}{\sum_{\mathbf{y}^{\prime}\in\mathcal{Y}^{T-t+1}} \sup_{f\in\mathcal{F}}P_{f}(y_{1:t-1},\mathbf{y}^{\prime})},\forall y\in \mathcal{Y}\]

which can be summarized into a joint density over \(y_{1:T}\) by

\[\hat{p}(y_{1:T})=\frac{\sup_{f\in\mathcal{F}}P_{f}(y_{1:T})}{\sum_{\mathbf{y}^{ \prime}_{1:T}\in\mathcal{Y}^{T}}\sup_{f\in\mathcal{F}}P_{f}(y^{\prime}_{1:T})}.\]

Recall that this is exactly the NML prediction \(p_{nml}(y_{1:T})\).

**Remark 4.3** (Relaxations and efficient algorithms): One may wonder if more efficient algorithms are available when it is not easy to compute contextual Shtarkov sums with prefix. One solution is to apply the framework of admissible relaxation in [12], which provides a systematic way of constructing efficient algorithms at the cost of worse regret guarantees. Notice that the worst-case log contextual Shtarkov sums with prefix constitute a trivially "admissible relaxation" since they are the exact conditional game values.

## 5 Perspectives on contextual Shtarkov sums

In this section, we provide further insight into contextual Shtarkov sums, defined in Sections 3 and 4.

### Contextual Shtarkov sums through martingales

We can relate our characterization of the minimax regret to the more extensively studied _sequential Rademacher complexity_, which arises in online learning problems with hypothesis class \(\mathcal{F}\subseteq[0,1]^{\mathcal{X}}\) and bounded convex losses like absolute loss. Specifically, the (conditional) sequential Rademacher complexity [12] is defined by

\[\mathfrak{R}_{T}(\mathcal{F};\mathbf{x}):=\mathbb{E}_{\boldsymbol{\varepsilon }}\Big{[}\sup_{f\in\mathcal{F}}\sum_{t=1}^{T}\varepsilon_{t}f(\mathbf{x}_{t}( \boldsymbol{\varepsilon}))\Big{]},\]

where \(\mathbf{x}\) is a depth-\(T\) binary context tree and \(\boldsymbol{\varepsilon}=(\varepsilon_{1},\ldots,\varepsilon_{T})\in\{\pm 1 \}^{T}\) is a sequence of i.i.d. Rademacher random variables. A notable feature of \(\mathfrak{R}_{T}(\mathcal{F};\mathbf{x})\) is that it is the expected supremum of the sum of a martingale differences, i.e., for any \(f,\mathbb{E}[\varepsilon_{t}f(\mathbf{x}_{t}(\boldsymbol{\varepsilon}))| \varepsilon_{1},\ldots,\varepsilon_{t-1}]=0\). Likewise, \(S_{T}(\mathcal{F}|\mathbf{x})\) also admits a martingale interpretation. To see this, let \(\mathcal{F}\subseteq\{(\mathcal{X}\times\mathcal{Y})^{*}\times\mathcal{X} \rightarrow\Delta(\mathcal{Y})\}\) and rewrite \(S_{T}(\mathcal{F}|\mathbf{x})\) for any context tree \(\mathbf{x}\):

\[S_{T}(\mathcal{F}|\mathbf{x})=\sum_{\mathbf{y}\in\mathcal{Y}^{T}}\sup_{f\in \mathcal{F}}P_{f}(\mathbf{y}|\mathbf{x}(\mathbf{y}))=\mathbb{E}_{\mathbf{y}} \Big{[}\sup_{f\in\mathcal{F}}\prod_{t=1}^{T}\Bigl{(}|\mathcal{Y}|\cdot f( \mathbf{x}_{1:t}(\mathbf{y}),y_{1:t-1})(y_{t})\Bigr{)}\Big{]},\]

where \(\mathbf{y}=(y_{1},\ldots,y_{T})\) is a sequence of i.i.d. variables following the uniform distribution over \(\mathcal{Y}\). It is easy to check that \(\mathbb{E}[|\mathcal{Y}|\cdot f(\mathbf{x}_{1:t}(\mathbf{y}),y_{1:t-1})(y_{t} )|y_{1},\ldots,y_{t-1}]=1\), and thus

\[\Big{\{}\prod_{s=1}^{t}\Bigl{(}|\mathcal{Y}|\cdot f(\mathbf{x}_{1:s}(\mathbf{ y}),y_{1:s-1})(y_{s})\Bigr{)}\Big{\}}_{t\in[T]}\]

is a martingale with respect to filtration \(\mathcal{F}_{t}=\sigma(y_{1},\ldots,y_{t}),t\in[T]\). It would be of independent interest to study the contextual Shtarkov sums more quantitatively by developing new tools for such product-type martingales.

### General Shtarkov sums

We can also interpret contextual Shtarkov sums as an instance of _general Shtarkov sums_, which are defined over sub-probability measures.

**Definition 5.1** (Sub-probability measure): A set \(\mathcal{P}=\{p:\mathcal{K}\rightarrow[0,1]\}\) is a class of sub-probability measures over a finite set \(\mathcal{K}\) if

\[\sum_{k\in\mathcal{K}}p(k)\leq 1,\forall p\in\mathcal{P}.\]

Due to Lemma D.1, it is easy to see that for any hypothesis class \(\mathcal{F}\subseteq\{(\mathcal{X}\times\mathcal{Y})^{*}\times\mathcal{X} \rightarrow\Delta(\mathcal{Y})\}\) and depth-\(T\) context tree \(\mathbf{x}\), they induce a class

\[\mathcal{P}_{\mathcal{F}|\mathbf{x}}:=\{P_{f}(\cdot|\mathbf{x}(\cdot)):f\in \mathcal{F}\}\]

that is a class of sub-probability measures over \(\mathcal{Y}^{T}\). Moreover, for any \(\mathcal{F}\), depth-\((T-t)\) context tree \(\mathbf{x}\) and sequences \(x_{1:t}\in\mathcal{X}^{t},y_{1:t}\in\mathcal{Y}^{t}\), the induced

\[\mathcal{P}_{\mathcal{F}^{x_{1:t},y_{1:t}}|\mathbf{x}}:=\{P_{f}(y_{1:t},\cdot|x_ {1:t},\mathbf{x}(\cdot)):f\in\mathcal{F}\}\]is a class of sub-probability measure over \(\mathcal{Y}^{T-t}\) since

\[\sum_{\mathbf{y}\in\mathcal{Y}^{T-t}}P_{f}(y_{1:t},\mathbf{y}|x_{1:t},\mathbf{x }(\mathbf{y}))=P_{f}(y_{1:t}|x_{1:t})\leq 1.\]

Next we introduce the notion of general Shtarkov sum over classes of sub-probability measures.

**Definition 5.2** (General Shtarkov sum): Given any class \(\mathcal{P}\) of sub-probability measures over \(\mathcal{K}\), the general Shtarkov sum of \(\mathcal{P}\) is defined as

\[S(\mathcal{P})=\sum_{k\in\mathcal{K}}\sup_{p\in\mathcal{P}}p(k).\]

With the notion of general Shtarkov sum, it is not hard to verify that the contextual Shtarkov sums with & without prefix can be interpreted as instances of general Shtarkov sums:

**Proposition 5.3**: _For any horizon \(T,t\in[T]\), data sequence \(x_{1:t}\in\mathcal{X}^{t},y_{1:t}\in\mathcal{Y}^{t}\), and context trees \(\mathbf{x},\mathbf{x}^{\prime}\) of depth \(T,T-t\) respectively, we have_

\[S_{T}(\mathcal{F}|\mathbf{x})=S(\mathcal{P}_{\mathcal{F}|\mathbf{x}}),\quad S _{T}^{x_{1:t},y_{1:t}}(\mathcal{F}|\mathbf{x}^{\prime})=S(\mathcal{P}_{ \mathcal{F}^{x_{1:t},y_{1:t}}|\mathbf{x}^{\prime}}).\]

It would be interesting to find out other instances of general Shtarkov sums that capture the complexities of other online learning problems with log loss.

## 6 Discussions

In this paper, we characterize the minimax regret and the optimal prediction strategy for sequential probability assignment, generalizing the classical results in the context-free setting. Moreover, our results are general enough to subsume the setting of multiary labels and sequential hypothesis classes, which has not been sufficiently explored before. Remarkably, our characterization holds for arbitrary hypothesis classes that may not admit the regularity assumptions implicitly required by prior works (e.g. [1, 1]).

For future works, it would be interesting to study the minimax regret of specific classes more quantitatively using our contextual Shtarkov sums. It is also intriguing to consider the setting of infinite labels. Although most of our arguments would go through under sufficient regularity conditions, a more systematic study is needed. On the practical side, it is important to develop algorithms that are more computationally efficient than cNML and with provable guarantees.

## Acknowledgements

We are grateful to Changlong Wu for telling us about Proposition C.2 and to Zeyu Jia for insights leading to Lemma 3.8. We would also like to thank Blair Bilodeau and Sasha Voitovych for helpful discussions and comments on earlier drafts of this work. ZL is supported by the Vector Research Grant at the Vector Institute. IA is supported by the Vatat Scholarship from the Israeli Council for Higher Education. DMR is supported by an NSERC Discovery Grant and funding through his Canada CIFAR AI Chair at the Vector Institute.

## References

* [ABDMNY21] N. Alon, O. Ben-Eliezer, Y. Dagan, S. Moran, M. Naor, and E. Yogev. "Adversarial laws of large numbers and optimal regret in online classification". In: _Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing_. 2021, pp. 447-455 (cit. on p. 3).
* [AHKKV23] I. Attias, S. Hanneke, A. Kalavasis, A. Karbasi, and G. Velegkas. "Optimal Learners for Realizable Regression: PAC Learning and Online Learning". In: _Thirty-seventh Conference on Neural Information Processing Systems_. 2023 (cit. on p. 3).
* [BRY98] A. Barron, J. Rissanen, and B. Yu. "The minimum description length principle in coding and modeling". In: _IEEE transactions on information theory_ 44.6 (1998), pp. 2743-2760 (cit. on p. 2).

* [BPS09] S. Ben-David, D. Pal, and S. Shalev-Shwartz. "Agnostic Online Learning." In: _COLT_. Vol. 3. 2009, p. 1 (cit. on p. 3).
* [BHS23] A. Bhatt, N. Haghtalab, and A. Shetty. "Smoothed Analysis of Sequential Probability Assignment". In: _Thirty-seventh Conference on Neural Information Processing Systems_. 2023 (cit. on p. 3).
* [BFR20] B. Bilodeau, D. Foster, and D. Roy. "Tight bounds on minimax regret under logarithmic loss via self-concordance". In: _International Conference on Machine Learning_. PMLR. 2020, pp. 919-929 (cit. on pp. 2, 3, 6, 10, 14, 15, 25).
* [BFR23] B. Bilodeau, D. J. Foster, and D. M. Roy. "Minimax rates for conditional density estimation via empirical entropy". In: _The Annals of Statistics_ 51.2 (2023), pp. 762-790 (cit. on pp. 7, 15).
* [CL06] N. Cesa-Bianchi and G. Lugosi. _Prediction, learning, and games_. Cambridge university press, 2006 (cit. on pp. 1, 2).
* [CL99] N. Cesa-Bianchi and G. Lugosi. "Minimax regret under log loss for general classes of experts". In: _Proceedings of the Twelfth annual conference on computational learning theory_. 1999, pp. 12-18 (cit. on p. 3).
* [Cov74] T. M. Cover. "Universal gambling schemes and the complexity measures of Kolmogorov and Chaitin". In: _Technical Report, no. 12_ (1974) (cit. on pp. 1, 2).
* [Cov91] T. M. Cover. "Universal portfolios". In: _Mathematical finance_ 1.1 (1991), pp. 1-29 (cit. on pp. 1, 2).
* [CO96] T. M. Cover and E. Ordentlich. "Universal portfolios with side information". In: _IEEE Transactions on Information Theory_ 42.2 (1996), pp. 348-363 (cit. on pp. 1, 2).
* [Dav73] L. D. Davisson. "Universal noiseless coding". In: _IEEE Trans. Inf. Theory_ 19 (1973), pp. 783-795 (cit. on p. 2).
* [DS04] M. Drmota and W. Szpankowski. "Precise minimax redundancy and regret". In: _IEEE Transactions on Information Theory_ 50.11 (2004), pp. 2686-2707 (cit. on p. 2).
* [Fed91] M. Feder. "Gambling using a finite state machine". In: _IEEE Transactions on Information Theory_ 37.5 (1991), pp. 1459-1465 (cit. on pp. 1, 2).
* [FMG92] M. Feder, N. Merhav, and M. Gutman. "Universal prediction of individual sequences". In: _IEEE transactions on Information Theory_ 38.4 (1992), pp. 1258-1270 (cit. on p. 2).
* [Fit66] B. Fitingof. "Optimal encoding with unknown and variable message statistics". In: _Probl. Inform. Transm._ 2 (1966), pp. 3-11 (cit. on p. 2).
* [FKLMS18] D. J. Foster, S. Kale, H. Luo, M. Mohri, and K. Sridharan. "Logistic regression: The importance of being improper". In: _Conference on learning theory_. PMLR. 2018, pp. 167-208 (cit. on p. 1).
* [Fre96] Y. Freund. "Predicting a binary sequence almost as well as the optimal biased coin". In: _Proceedings of the ninth annual conference on Computational learning theory_. 1996, pp. 89-98 (cit. on p. 2).
* [Gru05] P. Grunwald. "Minimum description length tutorial". In: (2005) (cit. on p. 2).
* [HY01] M. H. Hansen and B. Yu. "Model selection and the principle of minimum description length". In: _Journal of the American Statistical Association_ 96.454 (2001), pp. 746-774 (cit. on p. 2).
* [JSS21] P. Jacquet, G. Shamir, and W. Szpankowski. "Precise minimax regret for logistic regression with categorical feature values". In: _Algorithmic Learning Theory_. PMLR. 2021, pp. 755-771 (cit. on pp. 2, 4, 5).
* [Kel56] J. L. Kelly. "A new interpretation of information rate". In: _the bell system technical journal_ 35.4 (1956), pp. 917-926 (cit. on pp. 1, 2).
* [Kol65] A. N. Kolmogorov. "Three approaches to the definition of the concept "quantity of information"". In: _Problemy peredachi informatsii_ 1.1 (1965), pp. 3-11 (cit. on p. 2).
* [Lit88] N. Littlestone. "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm". In: _Machine learning_ 2 (1988), pp. 285-318 (cit. on p. 3).

* [MF98] N. Merhav and M. Feder. "Universal prediction". In: _IEEE Transactions on Information Theory_ 44.6 (1998), pp. 2124-2147 (cit. on pp. 1, 2).
* [MG22] J. Mourtada and S. Gaiffas. "An improper estimator with optimal excess risk in misspecified density estimation and logistic regression". In: _Journal of Machine Learning Research_ 23.31 (2022), pp. 1-49 (cit. on p. 22).
* [OH99] M. Opper and D. Haussler. "Worst case prediction over sequences under log loss". In: _The Mathematics of Information Coding, Extraction and Distribution_. Springer, 1999, pp. 81-90 (cit. on p. 3).
* [OS04] A. Orlitsky and N. P. Santhanam. "Speaking of infinity [iid strings]". In: _IEEE Transactions on Information Theory_ 50.10 (2004), pp. 2215-2230 (cit. on p. 2).
* [RS14a] A. Rakhlin and K. Sridharan. "Online non-parametric regression". In: _Conference on Learning Theory_. PMLR. 2014, pp. 1232-1264 (cit. on pp. 2, 3).
* [RS14b] A. Rakhlin and K. Sridharan. "Statistical Learning and Sequential Prediction". In: 2014 (cit. on p. 3).
* [RS15] A. Rakhlin and K. Sridharan. "Sequential probability assignment with binary alphabets and large classes of experts". In: _arXiv preprint arXiv:1501.07340_ (2015) (cit. on pp. 2, 3, 7, 14, 25).
* [RST10] A. Rakhlin, K. Sridharan, and A. Tewari. "Online learning: Random averages, combinatorial parameters, and learnability". In: _Advances in Neural Information Processing Systems_ 23 (2010) (cit. on pp. 2, 3).
* [RST15] A. Rakhlin, K. Sridharan, and A. Tewari. "Sequential complexities and uniform martingale laws of large numbers". In: _Probability theory and related fields_ 161 (2015), pp. 111-153 (cit. on pp. 1-3, 9, 10, 14).
* [RSS12] S. Rakhlin, O. Shamir, and K. Sridharan. "Relax and randomize: From value to algorithms". In: _Advances in Neural Information Processing Systems_ 25 (2012) (cit. on p. 9).
* [Ris78] J. Rissanen. "Modeling by shortest data description". In: _Automatica_ 14.5 (1978), pp. 465-471 (cit. on p. 2).
* [Ris84] J. Rissanen. "Universal coding, information, prediction, and estimation". In: _IEEE Transactions on Information theory_ 30.4 (1984), pp. 629-636 (cit. on pp. 1, 2).
* [Ris86] J. Rissanen. "Complexity of strings in the class of Markov sources". In: _IEEE Transactions on Information Theory_ 32.4 (1986), pp. 526-532 (cit. on p. 2).
* [Ris87] J. Rissanen. "Stochastic complexity". In: _Journal of the Royal Statistical Society: Series B (Methodological)_ 49.3 (1987), pp. 223-239 (cit. on p. 2).
* [RL81] J. Rissanen and G. Langdon. "Universal modeling and coding". In: _IEEE Transactions on Information Theory_ 27.1 (1981), pp. 12-23 (cit. on p. 2).
* [Ris76] J. J. Rissanen. "Generalized Kraft inequality and arithmetic coding". In: _IBM Journal of research and development_ 20.3 (1976), pp. 198-203 (cit. on p. 2).
* [Ris96] J. J. Rissanen. "Fisher information and stochastic complexity". In: _IEEE transactions on information theory_ 42.1 (1996), pp. 40-47 (cit. on p. 2).
* [Sha06] G. I. Shamir. "On the MDL principle for iid sources with large alphabets". In: _IEEE transactions on information theory_ 52.5 (2006), pp. 1939-1955 (cit. on p. 2).
* [Sha20] G. I. Shamir. "Logistic regression regret: What's the catch?" In: _Conference on Learning Theory_. PMLR. 2020, pp. 3296-3319 (cit. on p. 1).
* [Sht87] Y. M. Shtarkov. "Universal Sequential Coding of Single Messages". In: _Problems of Information Transmission_ 23 (3 1987), pp. 3-17 (cit. on pp. 1, 2, 4).
* [Sio58] M. Sion. "On general minimax theorems". In: _Pacific Journal of Mathematics_ 8 (1958), pp. 171-176 (cit. on p. 15).
* [Sol64] R. Solmonoff. "A formal theory of inductive inference. I". In: _II Information and Control_ 7 (1964), pp. 224-254 (cit. on p. 2).
* [Szp98] W. Szpankowski. "On asymptotics of certain recurrences arising in universal coding". In: _PROBLEMS OF INFORMATION TRANSMISSION C/C OF PROBLEMY PEREDACHI INFORMATSII_ 34 (1998), pp. 142-146 (cit. on p. 2).

* [Vov95] V. G. Vovk. "A game of prediction with expert advice". In: _Proceedings of the eighth annual conference on Computational learning theory_. 1995, pp. 51-60 (cit. on p. 1).
* [WHGS23] C. Wu, M. Heidari, A. Grama, and W. Szpankowski. "Regret Bounds for Log-loss via Bayesian Algorithms". In: _IEEE Transactions on Information Theory_ (2023) (cit. on pp. 2-4, 6, 7, 15, 25, 26).
* [XB97] Q. Xie and A. R. Barron. "Minimax redundancy for the class of memoryless sources". In: _IEEE Transactions on Information Theory_ 43.2 (1997), pp. 646-657 (cit. on p. 2).
* [XB00] Q. Xie and A. R. Barron. "Asymptotic minimax regret for data compression, gambling, and prediction". In: _IEEE Transactions on Information Theory_ 46.2 (2000), pp. 431-445 (cit. on p. 1).
* [ZL77] J. Ziv and A. Lempel. "A universal algorithm for sequential data compression". In: _IEEE Transactions on information theory_ 23.3 (1977), pp. 337-343 (cit. on p. 2).
* [ZL78] J. Ziv and A. Lempel. "Compression of individual sequences via variable-rate coding". In: _IEEE transactions on Information Theory_ 24.5 (1978), pp. 530-536 (cit. on p. 2).

Proofs for Section 3

Notations.When the context and label sequences \(x_{1:T},y_{1:T}\) are clear from the context, we may use \(f_{t}\) to denote the probability vector \(f(x_{1:t},y_{1:t-1})\in\Delta(\mathcal{Y})\) produced by hypothesis \(f\) at time \(t\) for notational convenience. We also adopt the notation for repeated operators in [11, 12], denoting \(\operatorname{Opt}_{1}\cdots\operatorname{Opt}_{T}[\cdots]\) by \(\left\langle\!\left\langle\operatorname{Opt}_{t}\right\rangle\!\right\rangle_{t =1}^{T}\left[\cdots\right]\). For any discrete distribution \(P\) and discrete random variables \(X,Y\), let \(H(P)\) be the entropy of \(P\) and \(H(X|Y)\) be the conditional entropy of \(X\) given \(Y\).

### Proof overview of Theorem 3.2

Before presenting the proof of Theorem 3.2 in full details in Appendices A.2 to A.4, we give a high-level overview here.

The proof starts from swapping the pairs of \(\inf\) and \(\sup\) (after randomizing the labels revealed by the nature) in the extensive formulation of \(\mathcal{R}_{T}(\mathcal{F})\) to move to the _dual game_, where the learner predicts _after_ seeing the action of the nature. Trivially the value of this swapped game is a lower bound for \(\mathcal{R}_{T}(\mathcal{F})\), and after rearranging we get that

\[\text{the value of the swapped game}=\sup_{\mathbf{x},\mathbf{p}}\mathbb{E}_{ \mathbf{y}\sim\mathbf{p}}[\mathcal{R}_{T}(\mathcal{F};\mathbf{p}(\mathbf{y}), \mathbf{x}(\mathbf{y}),\mathbf{y})]\leq\mathcal{R}_{T}(\mathcal{F}),\]

where the supremum is taken over all context trees \(\mathbf{x}\) and probabilistic trees \(\mathbf{p}\), of depth \(T\). Also \(\mathbb{E}_{\mathbf{y}\sim\mathbf{p}}\) means the nested conditional expectations \(\mathbb{E}_{y_{1}\sim\mathbf{p}_{1}(\mathbf{y})}\,\mathbb{E}_{y_{2}\sim \mathbf{p}_{2}(\mathbf{y})}\cdots\mathbb{E}_{y_{T}\sim\mathbf{p}_{T}(\mathbf{ y})}\).

Similar to the proof of Lemma 6 in [12] for the binary label setting, we apply the minimax theorem with a tweak that we devise to handle multiary labels to derive that

\[\mathcal{R}_{T}(\mathcal{F})=\sup_{\mathbf{x},\mathbf{p}}\mathbb{E}_{\mathbf{ y}\sim\mathbf{p}}[\mathcal{R}_{T}(\mathcal{F};\mathbf{p}(\mathbf{y}),\mathbf{x}( \mathbf{y}),\mathbf{y})]\] (3)

under some mild regularity condition for \(\mathcal{F}\). A key observation is that the supremum over depth-\(T\) probabilistic trees \(\mathbf{p}\) is equivalent to the supremum over joint distributions \(P\) over \(\mathcal{Y}^{T}\). Based on this observation and some algebra, for a fixed context tree \(\mathbf{x}\), the supremum over \(p\) in Eq. (3) is

\[\sup_{P\in\Delta(\mathcal{Y}^{T})}H(P)+\mathbb{E}_{\mathbf{y}\sim P}\big{[} \sup_{f\in\mathcal{F}}\log P_{f}(\mathbf{y}|\mathbf{x}(\mathbf{y}))\big{]}.\]

The value of this maximization problem can be easily computed to be

\[\log\!\left(\sum_{\mathbf{y}}\sup_{f\in\mathcal{F}}P_{f}(\mathbf{y}|\mathbf{x }(\mathbf{y}))\right)=\log S_{T}(\mathcal{F}|\mathbf{x}).\]

Thus,

\[\mathcal{R}_{T}(\mathcal{F}) =\sup_{\mathbf{x},\mathbf{p}}\mathbb{E}_{\mathbf{y}\sim\mathbf{p }}[\mathcal{R}_{T}(\mathcal{F};\mathbf{p}(\mathbf{y}),\mathbf{x}(\mathbf{y}), \mathbf{y})]\] \[=\sup_{\mathbf{x}}\sup_{P\in\Delta(\mathcal{Y}^{T})}H(P)+ \mathbb{E}_{\mathbf{y}\sim P}\big{[}\sup_{f\in\mathcal{F}}\log P_{f}(\mathbf{ y}|\mathbf{x}(\mathbf{y}))\big{]}=\sup_{\mathbf{x}}\log S_{T}(\mathcal{F}|\mathbf{x}).\]

However, Eq. (3) is not guaranteed when there is no assumed regularity condition for \(\mathcal{F}\). To get away from this, prior works have assumed a particular hypothesis is included in \(\mathcal{F}\) such that the enlarged class allows for the minimax swap [11, 12]. Nevertheless, even adding a mere hypothesis may lead to suboptimal analysis for some classes \(\mathcal{F}\), say when \(\mathcal{R}_{T}(\mathcal{F})\) is of constant order. To completely get rid of any regularity assumption and obtain a unified characterization of the minimax regret for arbitrary class \(\mathcal{F}\), we provide a novel argument as follows. For an arbitrary class \(\mathcal{F}\), we study a smooth truncated version of it, denoted by \(\mathcal{F}^{\delta}\) for any level \(\delta\in(0,1/2)\), such that \(\mathcal{F}^{\delta}\) always validates the use of the minimax theorem and hence \(\mathcal{R}_{T}(\mathcal{F}^{\delta})=\sup_{\mathbf{x}}\log S_{T}(\mathcal{F}^ {\delta}|\mathbf{x})\). Then we give a series of refined analysis comparing the minimax regrets and contextual Shtarkov sums of \(\mathcal{F}\) and \(\mathcal{F}^{\delta}\) that yields

\[\mathcal{R}_{T}(\mathcal{F})\leq\mathcal{R}_{T}(\mathcal{F}^{ \delta})+T\log(1+|\mathcal{Y}|\delta) =\sup_{\mathbf{x}}\log S_{T}(\mathcal{F}^{\delta}|\mathbf{x})+T \log(1+|\mathcal{Y}|\delta)\] \[\leq\log\!\Big{(}\sup_{\mathbf{x}}S_{T}(\mathcal{F}|\mathbf{x})+ \delta\cdot C(T,|\mathcal{Y}|)\Big{)}+T\log(1+|\mathcal{Y}|\delta),\]

where \(C(T,|\mathcal{Y}|)<\infty\) is a positive constant that only depends on \(T\) and \(|\mathcal{Y}|\). Sending \(\delta\to 0^{+}\) will conclude that \(\mathcal{R}_{T}(\mathcal{F})\leq\sup_{\mathbf{x}}\log S_{T}(\mathcal{F}| \mathbf{x})\), which finishes the whole proof as we already have \(\mathcal{R}_{T}(\mathcal{F})\geq\sup_{\mathbf{x}}\log S_{T}(\mathcal{F}| \mathbf{x})\) from the start.

### Minimax swap

As standard in online learning literature, we will first move to a dual game after applying a minimax swap at each round of the game. Under mild assumptions, the value of the original game coincides with the that of the swapped game. More specifically, we have:

**Lemma A.1**: _Whenever \(\mathcal{F}\) satisfies that for every sequence \(x_{1:T}\in\mathcal{X}^{T},y_{1:T}\in\mathcal{Y}^{T}\),_

\[\inf_{f\in\mathcal{F}}\sum_{t=1}^{T}\ell(f(x_{1:t},y_{1:t-1}),y_{t})<\infty,\] (4)

_we have that_

\[\mathcal{R}_{T}(\mathcal{F})=\sup_{\mathbf{x},\mathbf{p}}\mathbb{E}_{\mathbf{ y}\sim\mathbf{p}}[\mathcal{R}_{T}(\mathcal{F};\mathbf{p}(\mathbf{y}),\mathbf{x}( \mathbf{y}),\mathbf{y})],\] (5)

_where the supremum is taken over all \(\mathcal{X}\)-valued \(\mathcal{Y}\)-ary trees \(\mathbf{x}\) and \(\Delta(\mathcal{Y})\)-valued \(\mathcal{Y}\)-ary trees \(\mathbf{p}\), of depth \(T\). Also \(\mathbb{E}_{\mathbf{y}\sim\mathbf{p}}\) means the nested conditional expectations \(\mathbb{E}_{y_{1}\sim\mathbf{p}_{1}(\mathbf{y})}\,\mathbb{E}_{y_{2}\sim \mathbf{p}_{2}(\mathbf{y})}\cdots\mathbb{E}_{y_{T}\sim\mathbf{p}_{T}( \mathbf{y})}\)._

To deal with the unboundedness of log loss in the proof, we introduce the following truncation method inspired by [3, 1], generalizing the one in [3] which was specific to binary labels.

**Definition A.2** (Smooth truncation): The general smooth truncation map \(\tau_{\delta}:\Delta(\mathcal{Y})\to\Delta(\mathcal{Y})\) is defined such that for all \(p\in\Delta(\mathcal{Y})\) and \(y\in\mathcal{Y}\),

\[\tau_{\delta}(p)(y)=\frac{p(y)+\delta}{1+|\mathcal{Y}|\delta},\]

given threshold \(\delta\in(0,1/2)\).

It is easy to check that \(\tau_{\delta}(p)\) is indeed a valid member in \(\Delta(\mathcal{Y})\) and \(\tau_{\delta}(p)(y)\in[\delta/(1+|\mathcal{Y}|\delta),(1+\delta)/(1+|\mathcal{ Y}|\delta)]\). Moreover, it is not hard to verify that \(\tau_{\delta}(\Delta(\mathcal{Y}))=\{p\in\Delta(\mathcal{Y}):p(y)\in[\delta/(1+| \mathcal{Y}|\delta),(1+\delta)/(1+|\mathcal{Y}|\delta)],\forall y\in\mathcal{Y}\}\). We will use \(\Delta^{\delta}(\mathcal{Y})\) to denote this image set \(\tau_{\delta}(\Delta(\mathcal{Y}))\).

**Proof of Lemma A.1**: Fix \(\delta\in(0,1/2)\). By restricting the learner's prediction \(\hat{p}_{t}\) to \(\Delta^{\delta}(\mathcal{Y})\), we get an upper bound on \(\mathcal{R}_{T}(\mathcal{F})\):

\[\mathcal{R}_{T}(\mathcal{F}) \leq\left\langle\!\left\langle\sup_{x_{t}}\inf_{\hat{p}_{t}\in \Delta^{\delta}(\mathcal{Y})}\sup_{y_{t}}\right\rangle\!\!\right\rangle_{t=1}^ {T}\Big{[}\sum_{t=1}^{T}\ell(\hat{p}_{t},y_{t})-\inf_{f\in\mathcal{F}}\sum_{t=1 }^{T}\ell(f_{t},y_{t})\Big{]}\] \[=\left\langle\!\left\langle\sup_{x_{t}}\inf_{\hat{p}_{t}\in \Delta^{\delta}(\mathcal{Y})}\sup_{y_{t}}\right\rangle\!\!\right\rangle_{t=1}^ {T-1}\sup_{x_{T}}\inf_{\hat{p}_{T}\in\Delta^{\delta}(\mathcal{Y})}\sup_{p_{T}} \mathbb{E}_{y_{T}\sim p_{T}}\Big{[}\sum_{t=1}^{T}\ell(\hat{p}_{t},y_{t})-\inf _{f\in\mathcal{F}}\sum_{t=1}^{T}\ell(f_{t},y_{t})\Big{]}.\]

Now we can apply Sion's minimax theorem [11] to the function

\[A(\hat{p}_{T},p_{T})=\mathbb{E}_{y_{T}\sim p_{T}}\Big{[}\sum_{t=1}^{T}\ell( \hat{p}_{t},y_{t})-\inf_{f\in\mathcal{F}}\sum_{t=1}^{T}\ell(f_{t},y_{t})\Big{]}\]

to derive that

\[\inf_{\hat{p}_{T}\in\Delta^{\delta}(\mathcal{Y})}\sup_{p_{T}\in\Delta(\mathcal{ Y})}A(\hat{p}_{T},p_{T})=\sup_{p_{T}\in\Delta(\mathcal{Y})}\inf_{\hat{p}_{T}\in \Delta^{\delta}(\mathcal{Y})}A(\hat{p}_{T},p_{T}).\]

This is because:

1. \(A(\hat{p}_{T},p_{T})\) is convex and continuous in \(\hat{p}_{T}\) over the compact \(\Delta^{\delta}(\mathcal{Y})\) and
2. \(A(\hat{p}_{T},p_{T})\) is concave and continuous in \(p_{T}\) over the compact \(\Delta(\mathcal{Y})\), which is further due to that \(A(\hat{p}_{T},p_{T})\) is linear in \(p_{T}\) and is bounded given Eq. (4).

Hence

\[\mathcal{R}_{T}(\mathcal{F}) \leq\left\langle\!\!\left\langle\sup_{x_{t}}\inf_{\hat{p}_{t}\in \Delta^{\delta}(\mathcal{Y})}\sup_{y_{t}}\right\rangle\!\!\right\rangle_{t=1}^ {T-1}\sup_{x_{T}}\sup_{p_{T}}\inf_{\hat{p}_{T}\in\Delta^{\delta}(\mathcal{Y})} \mathbb{E}_{y_{T}\sim p_{T}}\Big{[}\sum_{t=1}^{T}\ell(\hat{p}_{t},y_{t})-\inf_{ f\in\mathcal{F}}\sum_{t=1}^{T}\ell(f_{t},y_{t})\Big{]}\] \[=\left\langle\!\!\left\langle\sup_{x_{t}}\inf_{\hat{p}_{t}\in \Delta^{\delta}(\mathcal{Y})}\sup_{y_{t}}\right\rangle\!\!\right\rangle_{t=1}^ {T-2}\sup_{x_{T-1}\,\hat{p}_{T-1}\in\Delta^{\delta}(\mathcal{Y})}\sup_{p_{T-1} \sim p_{T-1}}\mathbb{E}_{y_{T-1}\sim p_{T-1}}\] \[\Big{[}\sum_{t=1}^{T-1}\ell(\hat{p}_{t},y_{t})+\sup_{x_{T}}\sup_ {p_{T}}\big{[}\inf_{\hat{p}_{T}\in\Delta^{\delta}(\mathcal{Y})}\mathbb{E}_{y_ {T}\sim p_{T}}\,\ell(\hat{p}_{T},y_{T})-\mathbb{E}_{y_{T}\sim p_{T}}\inf_{f\in \mathcal{F}}\sum_{t=1}^{T}\ell(f_{t},y_{t})\big{]}\Big{]}.\]

Again the order of \(\inf_{\hat{p}_{T-1}\in\Delta^{\delta}(\mathcal{Y})}\) and \(\sup_{p_{T-1}\in\Delta(\mathcal{Y})}\) with respect to

\[B(\hat{p}_{T-1},p_{T-1})=\mathbb{E}_{y_{T-1}\sim p_{T-1}}\Big{[}\sum_{t=1}^{T- 1}\ell(\hat{p}_{t},y_{t})+\sup_{x_{T}}\sup_{p_{T}}\big{[}\inf_{\hat{p}_{T}\in \Delta^{\delta}(\mathcal{Y})}\mathbb{E}_{y_{T}\sim p_{T}}\,\ell(\hat{p}_{T},y_ {T})-\mathbb{E}_{y_{T}\sim p_{T}}\inf_{f\in\mathcal{F}}\sum_{t=1}^{T}\ell(f_{t },y_{t})\big{]}\Big{]}\]

can be swapped due to the same reason as above, leading to

\[\mathcal{R}_{T}(\mathcal{F}) \leq\left\langle\!\!\left\langle\sup_{x_{t}}\inf_{\hat{p}_{t}\in \Delta^{\delta}(\mathcal{Y})}\sup_{y_{t}}\right\rangle\!\!\right\rangle_{t=1}^ {T-2}\sup_{x_{T-1}\,p_{T-1}}\inf_{\hat{p}_{T-1}\in\Delta^{\delta}(\mathcal{Y})} \mathbb{E}_{y_{T-1}\sim p_{T-1}}\] \[\Big{[}\sum_{t=1}^{T-1}\ell(\hat{p}_{t},y_{t})+\sup_{x_{T}}\sup_{ p_{T}}\!\big{[}\inf_{\hat{p}_{T}\in\Delta^{\delta}(\mathcal{Y})}\mathbb{E}_{y_{T} \sim p_{T}}\,\ell(\hat{p}_{T},y_{T})-\mathbb{E}_{y_{T}\sim p_{T}}\inf_{f\in \mathcal{F}}\sum_{t=1}^{T}\ell(f_{t},y_{t})\big{]}\Big{]}\] \[=\left\langle\!\!\left\langle\sup_{x_{t}}\inf_{\hat{p}_{t}\in \Delta^{\delta}(\mathcal{Y})}\sup_{y_{t}}\right\rangle\!\!\right\rangle_{t=1}^ {T-3}\sup_{x_{T-2}\,\hat{p}_{T-2}\in\Delta^{\delta}(\mathcal{Y})}\sup_{p_{T-2 }}\mathbb{E}_{y_{T-2}\sim p_{T-2}}\] \[\Big{\{}\sum_{t=1}^{T-2}\ell(\hat{p}_{t},y_{t})+\sup_{x_{T-1}} \sup_{p_{T-1}}\Big{[}\inf_{\hat{p}_{T-1}\in\Delta^{\delta}(\mathcal{Y})} \mathbb{E}_{y_{T-1}\sim p_{T-1}}\,\ell(\hat{p}_{T-1},y_{T-1})\] \[+\mathbb{E}_{y_{T-1}\sim p_{T-1}}\sup_{x_{T}}\sup_{p_{T}}\Big{[} \inf_{\hat{p}_{T}\in\Delta^{\delta}(\mathcal{Y})}\mathbb{E}_{y_{T}\sim p_{T}}\, \ell(\hat{p}_{T},y_{T})-\mathbb{E}_{y_{T}\sim p_{T}}\inf_{f\in\mathcal{F}}\sum_{t =1}^{T}\ell(f_{t},y_{t})\Big{]}\Big{]}\Big{\}}.\]

Repeating this procedure through all \(T\) rounds yields

\[\mathcal{R}_{T}(\mathcal{F})\]

By Lemma A.7, we know that we do not lose too much by restricting learner's prediction to \(\Delta^{\delta}(\mathcal{Y})\):

\[\mathcal{R}_{T}(\mathcal{F})\]

Sending \(\delta\to 0^{+}\) on the RHS of the above inequality, we get

\[\mathcal{R}_{T}(\mathcal{F})\]

It is easy to see that on the RHS of the above inequality, the inner infimum over \(\hat{p}_{t}\in\Delta(\mathcal{Y})\) is achieved at \(\hat{p}_{t}=p_{t}\) due to the nature of log loss. So

\[\mathcal{R}_{T}(\mathcal{F}) \leq\left\langle\!\!\left\langle\sup_{x_{t}}\sup_{p_{t}}\mathbb{E} _{y_{t}\sim p_{t}}\right\rangle\!\right\rangle_{t=1}^{T}\sup_{f\in\mathcal{F}} \Bigl{[}\sum_{t=1}^{T}\mathbb{E}_{y_{t}\sim p_{t}}[\ell(p_{t},y_{t})]-\ell(f_{t},y _{t})\Bigr{]}\] \[=\sup_{\mathbf{x},\mathbf{p}}\mathbb{E}_{\mathbf{y}\sim\mathbf{p}}[ \mathcal{R}_{T}(\mathcal{F};\mathbf{p}(\mathbf{y}),\mathbf{x}(\mathbf{y}), \mathbf{y})],\]

where in the last equality we use the compact notation of trees to further simplify our expression and this concludes the proof.

**Lemma A.3**: _For any hypothesis class \(\mathcal{F}\) and horizon \(T\),_

\[\sup_{\mathbf{x},\mathbf{p}}\mathbb{E}_{\mathbf{y}\sim\mathbf{p}}[\mathcal{R}_{ T}(\mathcal{F};\mathbf{p}(\mathbf{y}),\mathbf{x}(\mathbf{y}),\mathbf{y})]=\sup_{ \mathbf{x}}\log S_{T}(\mathcal{F}|\mathbf{x}).\] (6)

_It is implied that whenever \(\mathcal{F}\) satisfies Eq. (5), we have_

\[\mathcal{R}_{T}(\mathcal{F})=\sup_{\mathbf{x}}\log S_{T}(\mathcal{F}|\mathbf{ x}).\]

**Proof of Lemma a.3** First we can see that the outcome sequence \(y_{1:T}\) generated under any tree \(\mathbf{p}\) is the same thing as \(y_{1:T}\) generated by its associated joint distribution over \(\mathcal{Y}^{T}\), and vice versa. So we can replace the supremum over trees \(\mathbf{p}\) in the LHS of Eq. (6) by the supremum over joint distributions \(P\) over \(\mathcal{Y}^{T}\). Hence,

\[\sup_{\mathbf{x},\mathbf{p}}\mathbb{E}_{\mathbf{y}\sim\mathbf{p} }[\mathcal{R}_{T}(\mathcal{F};\mathbf{p}(\mathbf{y}),\mathbf{x}(\mathbf{y}), \mathbf{y})] =\sup_{\mathbf{x},P}\mathbb{E}_{\mathbf{y}\sim P}[\mathcal{R}_{ T}(\mathcal{F};\mathbf{p}(\mathbf{y}),\mathbf{x}(\mathbf{y}),\mathbf{y})]\] \[=\sup_{\mathbf{x},P}\mathbb{E}_{\mathbf{y}\sim P}\Big{[}\sum_{t =1}^{T}\ell(P_{t},y_{t})-\inf_{f\in\mathcal{F}}\sum_{t=1}^{T}\ell(f_{t},y_{t}) \Big{]},\]

where \(P_{t}\) denotes the conditional distribution \(P_{t}(\cdot|y_{1:t-1})\in\Delta(\mathcal{Y})\) of \(y_{t}\) under \(P\) given \(y_{1:t-1}\).

Now fix the context tree \(\mathbf{x}\) and distribution \(P\). Then we can see that \(\mathbb{E}_{\mathbf{y}\sim P}[\ell(P_{t},y_{t})]=H(y_{t}|y_{1:t-1})\). So \(\mathbb{E}_{\mathbf{y}\sim P}[\sum_{t=1}^{T}\ell(P_{t},y_{t})]=\sum_{t=1}^{T}H (y_{t}|y_{1:t-1})=H(P)\). Further notice that

\[\inf_{f\in\mathcal{F}}\sum_{t=1}^{T}\ell(f_{t},y_{t})=\inf_{f\in\mathcal{F}}(- \log P_{f}(y_{1:T}|x_{1:T}))=-\sup_{f\in\mathcal{F}}\log P_{f}(y_{1:T}|x_{1:T}).\]

So naturally we define the map \(F_{\mathbf{x}}:\mathcal{Y}^{T}\to\mathbb{R}\cup\{-\infty\}\) by

\[F_{\mathbf{x}}(\mathbf{y})=\sup_{f\in\mathcal{F}}\log P_{f}(\mathbf{y}| \mathbf{x}(\mathbf{y})),\]

and then we see that

\[\mathbb{E}_{\mathbf{y}\sim P}\Big{[}\sum_{t=1}^{T}\ell(P_{t},y_{t})-\inf_{f \in\mathcal{F}}\sum_{t=1}^{T}\ell((f(x_{t}(\mathbf{y})),y_{t})\Big{]}=H(P)+ \mathbb{E}_{\mathbf{y}\sim P}[F_{\mathbf{x}}(\mathbf{y})].\]

For any given tree \(\mathbf{x}\), notice that the optimization problem

\[\sup_{P\in\Delta(\mathcal{Y}^{T})}H(P)+\mathbb{E}_{\mathbf{y}\sim P}[F_{ \mathbf{x}}(\mathbf{y})]\]

is actually a maximization problem in the form of \(\max_{P\in\Delta(\mathcal{Y}^{T})}H(P)+\langle P,v\rangle\), where \(v\) is some \(|\mathcal{Y}|^{T}-\)dimensional vector. According to the conjugacy between negative entropy function and log-sum-exp function, the optimal \(P^{*}\) is given by

\[P^{*}(\mathbf{y})=\frac{\exp(F_{\mathbf{x}}(\mathbf{y}))}{\sum_{\mathbf{y}^{ \prime}}\exp(F_{\mathbf{x}}(\mathbf{y}^{\prime}))}=\frac{\sup_{f\in\mathcal{F}} P_{f}(\mathbf{y}|\mathbf{x}(\mathbf{y}))}{\sum_{\mathbf{y}^{\prime}}\sup_{f\in \mathcal{F}}P_{f}(\mathbf{y}^{\prime}|\mathbf{x}(\mathbf{y}^{\prime}))},\forall \mathbf{y}\in\mathcal{Y}^{T}.\]

Note that the above formula for \(P^{*}\) is also valid when \(F_{\mathbf{x}}(\mathbf{y})=-\infty\) for some \(\mathbf{y}\), since \(P^{*}\) should be supported on \(\{\mathbf{y}\in\mathcal{Y}^{T}:F_{\mathbf{x}}(\mathbf{y})>-\infty\}\), and \(F_{\mathbf{x}}(\mathbf{y})\) cannot be \(-\infty\) for all \(\mathbf{y}\) due to Lemma D.1. The associated value of this maximization problem is

\[\log\!\left(\sum_{\mathbf{y}}\exp(F_{\mathbf{x}}(\mathbf{y}))\right)=\log\! \left(\sum_{\mathbf{y}}\sup_{f\in\mathcal{F}}P_{f}(\mathbf{y}|\mathbf{x}( \mathbf{y}))\right).\]

Therefore,

\[\sup_{\mathbf{x},\mathbf{p}}\mathbb{E}_{\mathbf{y}\sim\mathbf{p}}[ \mathcal{R}_{T}(\mathcal{F};\mathbf{p}(\mathbf{y}),\mathbf{x}(\mathbf{y}), \mathbf{y})] =\sup_{\mathbf{x},P}\mathbb{E}_{\mathbf{y}\sim P}\Big{[}\sum_{t=1} ^{T}\ell(P_{t},y_{t})-\inf_{f\in\mathcal{F}}\sum_{t=1}^{T}\ell(f_{t},y_{t}) \Big{]}\] \[=\sup_{\mathbf{x}}\sup_{P}\!\left\{H(P)+\mathbb{E}_{\mathbf{y} \sim P}[F_{\mathbf{x}}(\mathbf{y})]\right\}\] \[=\sup_{\mathbf{x}}\log\!\left(\sum_{\mathbf{y}}\sup_{f\in \mathcal{F}}P_{f}(\mathbf{y}|\mathbf{x}(\mathbf{y}))\right)\] \[=\sup_{\mathbf{x}}\log S_{T}(\mathcal{F}|\mathbf{x}).\]In the proof of Lemma A.1, if we do not restrict the learner's prediction and simply swap the order of inf and sup to produce an inequality at each time \(t\), we will reach the following folklore result.

**Lemma A.4**: _For any hypothesis class \(\mathcal{F}\) and horizon \(T\),_

\[\mathcal{R}_{T}(\mathcal{F})\geq\sup_{\mathbf{x},\mathbf{p}}\mathbb{E}_{ \mathbf{y}\sim\mathbf{p}}[\mathcal{R}_{T}(\mathcal{F};\mathbf{p}(\mathbf{y}), \mathbf{x}(\mathbf{y}),\mathbf{y})].\] (7)

**Proof of Lemma A.4** To get Eq. (7), we simply need to reverse the order of sup and inf at each time in the extensive formulation of minimax regret and produce an inequality:

\[\mathcal{R}_{T}(\mathcal{F}) =\sup_{x_{1}}\inf_{\tilde{p}_{1}}\sup_{y_{1}}\cdots\sup_{x_{T}} \inf_{\tilde{p}_{T}}\sup_{y_{T}}\mathcal{R}_{T}(\mathcal{F};\hat{p}_{1:T},x_{ 1:T},y_{1:T})\] \[=\] \[\geq\] \[= \left\langle\left\langle\sup_{x_{t}}\inf_{\tilde{p}_{t}}\sup_{y_{ t}}\right\rangle\right|_{t=1}^{T-1}\left[\sum_{t=1}^{T-1}\ell(\hat{p}_{t},y_{t})+ \sup_{x_{T}}\sup_{p_{T}}\big{[}\inf_{\tilde{p}_{T}}\mathbb{E}_{y_{T}\sim p_{T} }\ell(\hat{p}_{T},y_{T})-\mathbb{E}_{y_{T}\sim p_{T}}\inf_{f\in\mathcal{F}} \sum_{t=1}^{T}\ell(f_{t},y_{t})\big{]}\right]\]

Iterating the argument and rearranging terms as above, we will get that

\[\mathcal{R}_{T}(\mathcal{F}) \geq\] \[=\] \[=\] \[= \sup_{\mathbf{x},\mathbf{p}}\mathbb{E}_{\mathbf{y}\sim\mathbf{p}}[ \mathcal{R}_{T}(\mathcal{F};\mathbf{p}(\mathbf{y}),\mathbf{x}(\mathbf{y}), \mathbf{y})].\]

\(\blacksquare\)

### Smooth truncated hypothesis class

To remove the reliance on Eq. (4), we introduce a smooth truncated version of \(\mathcal{F}\) that always satisfies Eq. (4) and study its minimax regret as well as contextual Shtarkov sums, compared to those of the untruncated class \(\mathcal{F}\). To be more specific, we will apply the smooth truncation map to hypotheses: for any \(\delta\in(0,1/2)\) and \(f:(\mathcal{X}\times\mathcal{Y})^{*}\times\mathcal{X}\to\Delta(\mathcal{Y})\), we use \(f^{\delta}\) to denote its smooth truncated counterpart \(\tau_{\delta}\circ f\); for any hypothesis class \(\mathcal{F}\), we use \(\mathcal{F}^{\delta}\) to denote the corresponding smooth truncated class \(\tau_{\delta}\circ\mathcal{F}=\{\tau_{\delta}\circ f:f\in\mathcal{F}\}\). It is easy to verify that any smooth truncated class \(\mathcal{F}^{\delta}\) satisfies Eq. (4) and hence

\[\mathcal{R}_{T}(\mathcal{F}^{\delta})=\sup_{\mathbf{x}}\log S_{T}(\mathcal{F} ^{\delta}|\mathbf{x}).\]

Next we control the effect of truncation on the minimax regret.

**Lemma A.5**: _For any \(\mathcal{F},T\) and \(\delta\in(0,1/2)\),_

\[\mathcal{R}_{T}(\mathcal{F})\leq\mathcal{R}_{T}(\mathcal{F}^{\delta})+T\cdot \log(1+|\mathcal{Y}|\delta).\]

**Proof of Lemma A.5** Fix threshold \(\delta\in(0,1/2)\) and hypothesis \(f\). By Lemma A.7, for any given sequences \(x_{1:T},y_{1:T}\), there is

\[\sum_{t=1}^{T}\ell(f^{\delta}(x_{1:t},y_{1:t-1}),y_{t})-\sum_{t=1}^{T}\ell(f(x_{ 1:t},y_{1:t-1}),y_{t})\leq T\cdot\log(1+|\mathcal{Y}|\delta).\] (8)

Then, for any sequence of predictions \(\hat{p}_{1:T}\),

\[\mathcal{R}_{T}(\mathcal{F};\hat{p}_{1:T},x_{1:T},y_{1:T}) =\sum_{t=1}^{T}\ell(\hat{p}_{t},y_{t})-\inf_{f\in\mathcal{F}}\sum _{t=1}^{T}\ell(f_{t},y_{t})\] \[\leq\sum_{t=1}^{T}\ell(\hat{p}_{t},y_{t})-\inf_{f^{\delta}\in \mathcal{F}^{s}}\sum_{t=1}^{T}\ell(f_{t}^{\delta},y_{t})+T\cdot\log(1+| \mathcal{Y}|\delta)\] \[=\mathcal{R}_{T}(\mathcal{F}^{\delta};\hat{p}_{1:T},x_{1:T},y_{1 :T})+T\cdot\log(1+|\mathcal{Y}|\delta),\]

which concludes the proof. \(\blacksquare\)

**Lemma A.6**: _There exists a constant \(M(T)<\infty\) that only depends on \(T\) such that for any \(f,x_{1:T}\in\mathcal{X}^{T},y_{1:T}\in\mathcal{Y}^{T}\) and \(\delta\in(0,1/2)\),_

\[P_{f^{\delta}}(y_{1:T}|x_{1:T})\leq P_{f}(y_{1:T}|x_{1:T})+\delta\cdot M(T).\]

**Proof of Lemma A.6** Fix threshold \(\delta\in(0,1/2)\), hypothesis \(f\) and sequences \(x_{1:T},y_{1:T}\). Then

\[P_{f^{\delta}}(y_{1:T}|x_{1:T})=\prod_{t=1}^{T}f_{t}^{\delta}(y_{ t}) =\prod_{t}\biggl{(}\frac{f_{t}(y_{t})+\delta}{1+|\mathcal{Y}|\delta }\biggr{)}\] \[\leq\prod_{t}(f_{t}(y_{t})+\delta)\] \[=\prod_{t}f_{t}(y_{t})+\delta\cdot\sum_{t}\prod_{t^{\prime}\neq t }f_{t^{\prime}}(y_{t^{\prime}})+\cdots+\delta^{T}\] \[\leq\prod_{t}f_{t}(y_{t})+\delta\cdot M(T)\] \[=P_{f}(y_{1:T}|y_{1:T})+\delta\cdot M(T),\]

where we can set \(M(T)=T+{T\choose 2}+{T\choose 3}+\cdots+{T\choose T}\) since \(f_{t}(y_{t})\)'s are bounded by \(1\). \(\blacksquare\)

### Putting together

Now we are fully prepared to finish the proof of Theorem 3.2, our main result in Section 3.

**Proof of Theorem 3.2** By Lemma A.6, we have that for any context tree \(\mathbf{x}\) of depth \(T\),

\[\sum_{\mathbf{y}\in\mathcal{Y}^{T}}\sup_{f^{\delta}\in\mathcal{F}^{\delta}}P_ {f^{\delta}}(\mathbf{y}|\mathbf{x}(\mathbf{y}))\leq\sum_{\mathbf{y}\in \mathcal{Y}^{T}}\sup_{f\in\mathcal{F}}P_{f}(\mathbf{y}|\mathbf{x}(\mathbf{y})) +\delta\cdot M(T)\cdot|\mathcal{Y}|^{T}.\]

Thus

\[\mathcal{R}_{T}(\mathcal{F}^{\delta}) =\sup_{\mathbf{x}}\log S_{T}(\mathcal{F}^{\delta}|\mathbf{x})\] \[=\sup_{\mathbf{x}}\log\Biggl{(}\sum_{\mathbf{y}\in\mathcal{Y}^{T} }\sup_{f^{\delta}\in\mathcal{F}^{\delta}}P_{f^{\delta}}(\mathbf{y}|\mathbf{x} (\mathbf{y}))\Biggr{)}\] \[\leq\sup_{\mathbf{x}}\log\Biggl{(}\sum_{\mathbf{y}\in\mathcal{Y} ^{T}}\sup_{f\in\mathcal{F}}P_{f}(\mathbf{y}|\mathbf{x}(\mathbf{y}))+\delta \cdot M(T)\cdot|\mathcal{Y}|^{T}\Biggr{)}\] \[=\log\Biggl{(}\sup_{\mathbf{x}}\sum_{\mathbf{y}\in\mathcal{Y}^{T} }\sup_{f\in\mathcal{F}}P_{f}(\mathbf{y}|\mathbf{x}(\mathbf{y}))+\delta\cdot M( T)\cdot|\mathcal{Y}|^{T}\Biggr{)}.\]Together with Lemma A.5, we get that for any \(\delta\in(0,1/2)\),

\[\mathcal{R}_{T}(\mathcal{F})\leq\log\Biggl{(}\sup_{\mathbf{x}}\sum_{\mathbf{y} \in\mathcal{Y}^{T}}\sup_{f\in\mathcal{F}}P_{f}(\mathbf{y}|\mathbf{x}(\mathbf{y }))+\delta\cdot M(T)\cdot|\mathcal{Y}|^{T}\Biggr{)}+T\cdot\log(1+|\mathcal{Y}| \delta).\] (9)

After sending \(\delta\to 0^{+}\) on the RHS of Eq.9,

\[\mathcal{R}_{T}(\mathcal{F})\leq\log\Biggl{(}\sup_{\mathbf{x}}\sum_{\mathbf{y} \in\mathcal{Y}^{T}}\sup_{f\in\mathcal{F}}P_{f}(\mathbf{y}|\mathbf{x}(\mathbf{y }))\Biggr{)}=\sup_{\mathbf{x}}\log S_{T}(\mathcal{F}|\mathbf{x}).\]

Recall that we have \(\mathcal{R}_{T}(\mathcal{F})\geq\sup_{\mathbf{x}}\log S_{T}(\mathcal{F}| \mathbf{x})\) from Lemma A.4 and Lemma A.3. So finally,

\[\mathcal{R}_{T}(\mathcal{F})=\sup_{\mathbf{x}}\log S_{T}(\mathcal{F}| \mathbf{x}).\]

### Additional proofs

**Lemma A.7**: _For any \(p\in\Delta(\mathcal{Y})\) and \(\delta\in(0,1/2)\),_

\[\ell(\tau_{\delta}(p),y)\leq\ell(p,y)+\log(1+|\mathcal{Y}|\delta)\leq\ell(p,y )+|\mathcal{Y}|\delta,\forall y\in\mathcal{Y}.\]

**Proof of Lemma A.7** By direct computation, for any \(y\in\mathcal{Y}\),

\[\ell(\tau_{\delta}(p),y)-\ell(p,y) =\log\Bigl{(}\frac{p(y)}{p(y)+\delta}\cdot(1+|\mathcal{Y}|\delta) \Bigr{)}\] \[\leq\log(1+|\mathcal{Y}|\delta)\] \[\leq|\mathcal{Y}|\delta.\]

### Proof of Proposition3.3

Starting from Theorem3.2 that \(\mathcal{R}_{T}(\mathcal{F})=\sup_{\mathbf{x}}\log S_{T}(\mathcal{F}| \mathbf{x})\), we have

\[\mathcal{R}_{T}(\mathcal{F}) =\sup_{\mathbf{x}}\log\Biggl{(}\sum_{\mathbf{y}}\sup_{f\in \mathcal{F}}P_{f}(\mathbf{y}|\mathbf{x}(\mathbf{y}))\Biggr{)}\] \[\leq\sup_{\mathbf{x}}\log\Biggl{(}\sum_{\mathbf{y}}\sum_{f\in \mathcal{F}}P_{f}(\mathbf{y}|\mathbf{x}(\mathbf{y}))\Biggr{)}\] \[=\sup_{\mathbf{x}}\log\Biggl{(}\sum_{f\in\mathcal{F}}\sum_{ \mathbf{y}}P_{f}(\mathbf{y}|\mathbf{x}(\mathbf{y}))\Biggr{)}=\log|\mathcal{F}|,\]

where the last equality is due to LemmaD.1.

### Proof of Lemma3.8

It suffices to show that \(\mathcal{R}_{T}^{\mathrm{FD}}(\mathcal{F}^{\mathrm{Lin}})\geq\sqrt{T}/4\). In particular, we only need to find some context sequence \(x_{1:T}\) such that \(\log S_{T}(\mathcal{F}^{\mathrm{Lin}}|x_{1:T})\geq\sqrt{T}/4\) due to Proposition2.5. Here we pick \(x_{1:T}\) such that \(x_{t}\) are unit vectors and \(x_{t}\perp x_{t^{\prime}}\) whenever \(t\neq t^{\prime}\). Such sequence exists because the dimension of \(\mathbb{B}_{2}\) is no smaller than \(T\). In this way, for each possible label sequence \(y_{1:T}\in\{0,1\}^{T}\), we can see that the \(f_{w}\in\mathcal{F}^{\mathrm{Lin}}\) that is indexed by

\[w=\sum_{t=1}^{T}\frac{2y_{t}-1}{\sqrt{T}}x_{t}\]

achieves likelihood \(P_{f_{w}}(y_{1:T}|x_{1:T})=(\frac{1+1/\sqrt{T}}{2})^{T}\). Therefore,

\[S_{T}(\mathcal{F}^{\mathrm{Lin}}|x_{1:T})=\sum_{y_{1:T}\in\{0,1\}^{T}}\sup_{f \in\mathcal{F}^{\mathrm{Lin}}}P_{f}(y_{1:T}|x_{1:T})\geq\sum_{y_{1:T}\in\{0,1 \}^{T}}\Biggl{(}\frac{1+1/\sqrt{T}}{2}\Biggr{)}^{T}=\left(1+1/\sqrt{T}\right)^ {T},\]

which implies that \(\mathcal{R}_{T}^{\mathrm{FD}}(\mathcal{F}^{\mathrm{Lin}})=\log S_{T}(\mathcal{ F}^{\mathrm{Lin}}|x_{1:T})\geq T\log(1+1/\sqrt{T})\geq\sqrt{T}/4\) for all \(T\geq 1\).

## Appendix B Proofs for Section 4

Notations.Again we may use \(f_{t}\) to denote the probability vector \(f(x_{1:t},y_{1:t-1})\in\Delta(\mathcal{Y})\) produced by hypothesis \(f\) at time \(t\) when the context and label sequences \(x_{1:T},y_{1:T}\) are clear from the context. For a context tree \(\mathbf{x}\) of depth \(T-t\) and a path \(\mathbf{y}\in\mathcal{Y}^{T-t}\), we re-index \(\mathbf{x}(\mathbf{y})\) as \((\mathbf{x}_{t+1}(\mathbf{y}),\ldots,\mathbf{x}_{T}(\mathbf{y}))\) whenever it takes the last \(T-t\) entries of the entire context sequence. And we do the same for the probabilistic tree \(\mathbf{p}\) as well. That is, whenever \(\mathbf{y}=(y_{t+1},\ldots,y_{T})\in\mathcal{Y}^{T-t}\) takes the last \(T-t\) entries of the whole label sequence and \(\mathbf{y}\sim\mathbf{p}\), then we will denote this label generating process by \(y_{t+1}\sim\mathbf{p}_{t+1}(\mathbf{y}),\ldots,y_{T}\sim\mathbf{p}_{T}(\mathbf{ y})\).

### Proof of Theorem 4.2

Recall that the minimax regret is

\[\mathcal{R}_{T}(\mathcal{F})=\left\langle\!\left\langle\sup_{x_{t}}\inf_{ \hat{p}_{t}}\sup_{y_{t}}\right\rangle\!\!\right\rangle_{t=1}^{T}\Big{[}\sum_ {t=1}^{T}\ell(\hat{p}_{t},y_{t})-\inf_{f\in\mathcal{F}}\sum_{t=1}^{T}\ell(f(x_ {1:t},y_{1:t-1}),y_{t})\Big{]}.\]

Through this extensive form of the minimax regret, we know that given \(x_{1:t},y_{1:t-1}\), the minimax prediction \(\hat{p}_{t}^{*}\) at round \(t\) is the one that minimizes the following expression over all \(\hat{p}_{t}\in\Delta(\mathcal{Y})\):

\[\sup_{y_{t}}\left\langle\!\left\langle\sup_{x_{s}}\inf_{\hat{p}_{s}}\sup_{y_{ s}}\right\rangle\!\!\right\rangle_{s=t+1}^{T}\Big{[}\sum_{s=t}^{T}\ell(\hat{p}_{s},y _{s})-\inf_{f\in\mathcal{F}}\sum_{s=1}^{T}\ell(f(x_{1:s},y_{1:s-1}),y_{s})\Big{]}.\] (10)

Define

\[G(\mathcal{F},x_{1:t},y_{1:t})=\left\langle\!\left\langle\sup_{x_{s}}\inf_{ \hat{p}_{s}}\sup_{y_{s}}\right\rangle\!\!\right\rangle_{s=t+1}^{T}\Big{[}\sum _{s=t+1}^{T}\ell(\hat{p}_{s},y_{s})-\inf_{f\in\mathcal{F}}\sum_{s=1}^{T}\ell(f (x_{1:s},y_{1:s-1}),y_{s})\Big{]},\]

and now

\[\tilde{p}_{t}^{*}=\operatorname*{argmin}_{\hat{p}_{t}\in\Delta(\mathcal{Y})} \sup_{y_{t}}\Bigl{\{}\ell(\hat{p}_{t},y_{t})+G(\mathcal{F},x_{1:t},y_{1:t}) \Bigr{\}}.\]

The crux of the proof is to show the following:

**Lemma B.1**: _For any hypothesis class \(\mathcal{F}\) and sequences \(x_{1:t}\in\mathcal{X}^{t},y_{1:t}\in\mathcal{Y}^{t}\),_

\[G(\mathcal{F},x_{1:t},y_{1:t})=\sup_{\mathbf{x}}\log S_{T}^{x_{1:t},y_{1:t}}( \mathcal{F}|\mathbf{x}).\]

The proof of Lemma B.1 is done by essentially following the same strategy in Appendix A since \(G(\mathcal{F},x_{1:t},y_{1:t})\) admits a similar extensive form with the minimax regret \(\mathcal{R}_{T}(\mathcal{F})\). For completeness we provide its proof in Appendix B.2. Given Lemma B.1, we have

\[\tilde{p}_{t}^{*} =\operatorname*{argmin}_{\hat{p}_{t}\in\Delta(\mathcal{Y})}\sup_{y_ {t}}\Bigl{\{}\ell(\hat{p}_{t},y_{t})+\sup_{\mathbf{x}}\log S_{T}^{x_{1:t},y_{1: t}}(\mathcal{F}|\mathbf{x})\Bigr{\}}\] \[=\operatorname*{argmin}_{\hat{p}_{t}\in\Delta(\mathcal{Y})}\sup_{y_ {t}}\log\Bigl{(}\frac{\sup_{\mathbf{x}}S_{T}^{x_{1:t},y_{1:t}}(\mathcal{F}| \mathbf{x})}{\hat{p}_{t}(y_{t})}\Bigr{)}.\]

We apply the following result to solve the above program:

**Lemma B.2**: _[_14_, Lemma 15]_ _Let \(g:\mathcal{Y}\to[0,+\infty]\) be a measurable function such that \(\int_{\mathcal{Y}}g(y)d\mu\in(0,+\infty)\). Then,_

\[\inf_{p}\sup_{y\in\mathcal{Y}}\log\frac{g(y)}{p(y)}=\log\Bigl{(}\int_{\mathcal{ Y}}g(y)\mu(dy)\Bigr{)},\] (11)

_where the infimum in Eq. (11) spans over all probability densities \(p:\mathcal{Y}\to[0,+\infty)\) with respect to \(\mu\), and the infimum is reached at_

\[p^{*}=\frac{g}{\int_{\mathcal{Y}}g(y)d\mu}.\]

Letting \(g(y)=\sup_{\mathbf{x}}S_{T}^{x_{1:t},(y_{1:t-1},y)}(\mathcal{F}|\mathbf{x}) \in[0,1]\) and \(\mu\) be the counting measure on the finite space \(\mathcal{Y}\), we can apply Lemma B.2 whenever not all \(g(y)\)'s are \(0\). In this case, we solve that

\[\hat{p}_{t}^{*}(y)=\frac{g(y)}{\sum_{y^{\prime}\in\mathcal{Y}}g(y^{\prime})}= \frac{\sup_{\mathbf{x}}S_{T}^{x_{1:t},(y_{1:t-1},y)}(\mathcal{F}|\mathbf{x}) }{\sum_{y^{\prime}\in\mathcal{Y}}\sup_{\mathbf{x}}S_{T}^{x_{1:t},(y_{1:t-1},y ^{\prime})}(\mathcal{F}|\mathbf{x})},\forall y\in\mathcal{Y}.\]

On the other hand, if \(g(y)=0,\forall y\in\mathcal{Y}\), then any \(\hat{p}_{t}\) such that \(\hat{p}_{t}(y)>0,\forall y\in\mathcal{Y}\), is an minimax optimal prediction. Moreover, it implies that \(P_{f}(y_{1:t-1}|x_{1:t-1})=0,\forall f\in\mathcal{F}\). This is because for arbitrary context tree \(\mathbf{x}\),

\[0 =\sum_{y_{s}}\sum_{\mathbf{y}\in\mathcal{Y}^{T-t}}P_{f}(y_{1:t}, \mathbf{y}|x_{1:t},\mathbf{x}(\mathbf{y}))\] \[=\sum_{y_{t}}P_{f}(y_{1:t}|x_{1:t})\] \[=P_{f}(y_{1:t-1}|x_{1:t-1}).\]

So the cumulative loss for each expert \(f\) up to round \(t-1\) already blows up to \(+\infty\) and the learner only needs to predict an arbitrary \(\hat{p}\in\Delta^{+}(\mathcal{Y})\) in all remaining rounds to achieve \(\mathcal{R}_{T}(\mathcal{F};\hat{p}_{1:T},x_{1:T},y_{1:T})=-\infty\).

Overall, we can see that the minimax optimal prediction \(\hat{p}_{t}^{*}\in\Delta(\mathcal{Y})\) at round \(t\) given \(x_{1:t},y_{1:t-1}\) is

\[\hat{p}_{t}^{*}(y)=\frac{\sup_{\mathbf{x}}S_{T}^{x_{1:t},(y_{1:t-1},y)}( \mathcal{F}|\mathbf{x})}{\sum_{y^{\prime}\in\mathcal{Y}}\sup_{\mathbf{x}}S_{T }^{x_{1:t},(y_{1:t-1},y^{\prime})}(\mathcal{F}|\mathbf{x})},\forall y\in \mathcal{Y},\]

if there exists \(y\in\mathcal{Y}\) such that \(\sup_{\mathbf{x}}S_{T}^{x_{1:t},(y_{1:t-1},y)}(\mathcal{F}|\mathbf{x})>0\). Otherwise, select \(\hat{p}_{t}^{*}\) to be an arbitrary element in \(\Delta^{+}(\mathcal{Y})\) (and so do all remaining rounds).

### Auxiliary lemmas

Recall that for any hypothesis class \(\mathcal{F}\) and sequences \(x_{1:t}\in\mathcal{X}^{t},y_{1:t}\in\mathcal{Y}^{t}\),

\[G(\mathcal{F},x_{1:t},y_{1:t})\] \[=\]

To prove Lemma B.1, we need the following lemmas.

**Lemma B.3**: _For any hypothesis class \(\mathcal{F}\) and sequences \(x_{1:t}\in\mathcal{X}^{t},y_{1:t}\in\mathcal{Y}^{t}\),_

\[G(\mathcal{F},x_{1:t},y_{1:t})\geq\sup_{\mathbf{x},\mathbf{p}}\mathbb{E}_{ \mathbf{y}\sim\mathbf{p}}\Bigl{[}\sum_{s=t+1}^{T}\mathbb{E}_{y_{s}\sim\mathbf{ p},(\mathbf{y})}[\ell(\mathbf{p}_{s}(\mathbf{y}),y_{s})]-\inf_{f\in\mathcal{F}} \sum_{s=1}^{T}\ell(f_{s},y_{s})\Bigr{]}.\] (12)

_And whenever for every \(x_{t+1:T}\in\mathcal{X}^{T-t},y_{t+1:T}\in\mathcal{Y}^{T-t}\), it holds_

\[\inf_{f\in\mathcal{F}}\sum_{s=1}^{T}\ell(f(x_{1:s},y_{1:s-1}),y_{s})<\infty,\] (13)_then_

\[G(\mathcal{F},x_{1:t},y_{1:t})=\sup_{\mathbf{x},\mathbf{p}}\mathbb{E}_{\mathbf{y} \sim\mathbf{p}}\Big{[}\sum_{s=t+1}^{T}\mathbb{E}_{y_{s}\sim\mathbf{p}_{s}( \mathbf{y})}[\ell(\mathbf{p}_{s}(\mathbf{y}),y_{s})]-\inf_{f\in\mathcal{F}}\sum _{s=1}^{T}\ell(f_{s},y_{s})\Big{]}.\] (14)

**Proof of Lemma B.3** First we see that similar to the proof of Lemma A.4, we can reverse every pair of sup over \(p_{s}\) and inf over \(\hat{p}_{s}\) in the extensive formulation of \(G(\mathcal{F},x_{1:t},y_{1:t})\) and rearrange terms to obtain

\[G(\mathcal{F},x_{1:t},y_{1:t})\geq\left\langle\!\!\left\langle\sup_{x_{s}} \sup_{p_{s}}\mathbb{E}_{y_{s}\sim p_{s}}\right\rangle\!\!\right\rangle_{s=t+1} ^{T}\Big{[}\sum_{s=t+1}^{T}\inf_{\hat{p}_{s}}\mathbb{E}_{y_{s}\sim p_{s}}[ \ell(\hat{p}_{s},y_{s})]-\inf_{f\in\mathcal{F}}\sum_{s=1}^{T}\ell(f_{s},y_{s} )\Big{]},\]

and again due to the nature of log loss,

\[G(\mathcal{F},x_{1:t},y_{1:t}) \geq\left\langle\!\!\left\langle\sup_{x_{s}}\sup_{p_{s}}\mathbb{E }_{y_{s}\sim p_{s}}\right\rangle\!\!\right\rangle_{s=t+1}^{T}\Big{[}\sum_{s=t +1}^{T}\mathbb{E}_{y_{s}\sim p_{s}}[\ell(p_{s},y_{s})]-\inf_{f\in\mathcal{F}} \sum_{s=1}^{T}\ell(f_{s},y_{s})\Big{]}\] \[=\sup_{\mathbf{x},\mathbf{p}}\mathbb{E}_{\mathbf{y}\sim\mathbf{p} }\Big{[}\sum_{s=t+1}^{T}\mathbb{E}_{y_{s}\sim\mathbf{p}_{s}(\mathbf{y})}[\ell (\mathbf{p}_{s}(\mathbf{y}),y_{s})]-\inf_{f\in\mathcal{F}}\sum_{s=1}^{T}\ell( f_{s},y_{s})\Big{]},\]

where in the last step we compress the expression using trees (of depth \(T-t\)) and Eq. (12) is proved.

To show that the minimax swap is valid under Eq. (13), we follow the same strategy as in the proof of Lemma A.1 by restricting the learner's prediction \(\hat{p}_{s}\) to \(\Delta^{\delta}(\mathcal{Y})\) for any threshold \(\delta\in(0,1/2)\) which yields

\[G(\mathcal{F},x_{1:t},y_{1:t})\] \[\leq\left\langle\!\!\left\langle\sup_{x_{s}}\sup_{p_{s}}\mathbb{ E}_{y_{s}\sim p_{s}}\right\rangle\!\!\right\rangle_{s=t+1}^{T}\Big{[}\sum_{s=t+1} ^{T}\inf_{\hat{p}_{s}}\mathbb{E}_{y_{s}\sim p_{s}}[\ell(\hat{p}_{s},y_{s})]- \inf_{f\in\mathcal{F}}\sum_{s=1}^{T}\ell(f_{s},y_{s})\Big{]}+|\mathcal{Y}|\delta T.\]

So Eq. (14) is proved by sending \(\delta\to 0^{+}\) on the RHS of the last inequality and the established Eq. (12). \(\blacksquare\)

**Lemma B.4**: _For any hypothesis class \(\mathcal{F}\) and sequences \(x_{1:t}\in\mathcal{X}^{t},y_{1:t}\in\mathcal{Y}^{t}\),_

\[\sup_{\mathbf{x},\mathbf{p}}\mathbb{E}_{\mathbf{y}\sim\mathbf{p}}\Big{[}\sum_ {s=t+1}^{T}\mathbb{E}_{y_{s}\sim\mathbf{p}_{s}(\mathbf{y})}[\ell(\mathbf{p}_{s} (\mathbf{y}),y_{s})]-\inf_{f\in\mathcal{F}}\sum_{s=1}^{T}\ell(f_{s},y_{s}) \Big{]}=\sup_{\mathbf{x}}\log S_{T}^{x_{1:t},y_{1:t}}(\mathcal{F}|\mathbf{x}).\]

**Proof of Lemma B.4** The proof follows that of Lemma A.3. By replacing the probabilistic tree \(\mathbf{p}\) by the joint distribution \(P\in\Delta(\mathcal{Y}^{T-t})\), we get

\[\sup_{\mathbf{x},\mathbf{p}}\mathbb{E}_{\mathbf{y}\sim\mathbf{p} }\Big{[}\sum_{s=t+1}^{T}\mathbb{E}_{y_{s}\sim\mathbf{p}_{s}(\mathbf{y})}[\ell( \mathbf{p}_{s}(\mathbf{y}),y_{s})]-\inf_{f\in\mathcal{F}}\sum_{s=1}^{T}\ell(f_{s },y_{s})\Big{]}\] \[= \sup_{\mathbf{x},P}\mathbb{E}_{\mathbf{y}\sim P}\Big{[}\sum_{s=t+1 }^{T}\ell(P_{s},y_{s})-\inf_{f\in\mathcal{F}}\sum_{s=1}^{T}\ell(f_{s},y_{s}) \Big{]}\] \[= \sup_{\mathbf{x}}\sup_{P\in\Delta(\mathcal{Y}^{T-t})}H(P)+\mathbb{ E}_{\mathbf{y}\sim P}\Big{[}\sup_{f\in\mathcal{F}}\log P_{f}(y_{1:t},\mathbf{y}|x_{1:t}, \mathbf{x}(\mathbf{y}))\Big{]}.\]

Similarly, for any fixed \(\mathbf{x}\), define the map \(F_{\mathbf{x}}^{x_{1:t},y_{1:t}}:\mathcal{Y}^{T-t}\to\mathbb{R}\cup\{-\infty\}\) by

\[F_{\mathbf{x}}^{x_{1:t},y_{1:t}}(\mathbf{y})=\sup_{f\in\mathcal{F}}\log P_{f}(y_ {1:t},\mathbf{y}|x_{1:t},\mathbf{x}(\mathbf{y})),\]and now we solve

\[\sup_{P\in\Delta(\mathcal{Y}^{T-t})}H(P)+\mathbb{E}_{\mathbf{y}\sim P}[F_{\mathbf{ x}}^{x_{1:t},y_{1:t}}(\mathbf{y})].\]

If there exists some \(\mathbf{y}\in\mathcal{Y}^{T-t}\) such that \(F_{\mathbf{x}}^{x_{1:t},y_{1:t}}(\mathbf{y})>-\infty\), then the optimal \(P^{*}\) is given by

\[P^{*}(\mathbf{y})=\frac{\exp(F_{\mathbf{x}}^{x_{1:t},y_{1:t}}(\mathbf{y}))}{ \sum_{\mathbf{y}^{\prime}}\exp(F_{\mathbf{x}}^{x_{1:t},y_{1:t}}(\mathbf{y}^{ \prime}))}=\frac{\sup_{f\in\mathcal{F}}P_{f}(y_{1:t},\mathbf{y}|x_{1:t}, \mathbf{x}(\mathbf{y}))}{\sum_{\mathbf{y}^{\prime}}\sup_{f\in\mathcal{F}}P_{f} (y_{1:t},\mathbf{y}^{\prime}|x_{1:t},\mathbf{x}(\mathbf{y}^{\prime}))},\forall \mathbf{y}\in\mathcal{Y}^{T-t},\]

and then

\[\sup_{\mathbf{x},\mathbf{p}}\mathbb{E}_{\mathbf{y}\sim\mathbf{p}} \Big{[}\sum_{s=t+1}^{T}\mathbb{E}_{y_{s}\sim\mathbf{p}_{s}(\mathbf{y})}[\ell( \mathbf{p}_{s}(\mathbf{y}),y_{s})]-\inf_{f\in\mathcal{F}}\sum_{s=1}^{T}\ell(f _{s},y_{s})\Big{]}\] \[= \sup_{\mathbf{x}}\sup_{P\in\Delta(\mathcal{Y}^{T-t})}H(P)+ \mathbb{E}_{\mathbf{y}\sim P}[F_{\mathbf{x}}^{x_{1:t},y_{1:t}}(\mathbf{y})]\] \[= \sup_{\mathbf{x}}\log\Big{(}\sum_{\mathbf{y}}\sup_{f\in\mathcal{ F}}P_{f}(y_{1:t},\mathbf{y}|x_{1:t},\mathbf{x}(\mathbf{y}))\Big{)}\] \[= \sup_{\mathbf{x}}\log S_{T}^{x_{1:t},y_{1:t}}(\mathcal{F}|\mathbf{ x}).\]

However, if \(F_{\mathbf{x}}^{x_{1:t},y_{1:t}}(\mathbf{y})=-\infty\) for all \(\mathbf{y}\), then it implies that for any context tree \(\mathbf{x}\), path \(\mathbf{y}\), and \(f\in\mathcal{F}\), \(P_{f}(y_{1:t},\mathbf{y}|x_{1:t},\mathbf{x}(\mathbf{y}))=0\) and hence,

\[\sup_{\mathbf{x},\mathbf{p}}\mathbb{E}_{\mathbf{y}\sim\mathbf{p} }\Big{[}\sum_{s=t+1}^{T}\mathbb{E}_{y_{s}\sim\mathbf{p}_{s}(\mathbf{y})}[\ell( \mathbf{p}_{s}(\mathbf{y}),y_{s})]-\inf_{f\in\mathcal{F}}\sum_{s=1}^{T}\ell(f _{s},y_{s})\Big{]}\] \[= \sup_{\mathbf{x}}\sup_{P\in\Delta(\mathcal{Y}^{T-t})}H(P)+ \mathbb{E}_{\mathbf{y}\sim P}[F_{\mathbf{x}}^{x_{1:t},y_{1:t}}(\mathbf{y})]\] \[= -\infty\] \[= \sup_{\mathbf{x}}\log\Big{(}\sum_{\mathbf{y}}\sup_{f\in\mathcal{ F}}P_{f}(y_{1:t},\mathbf{y}|x_{1:t},\mathbf{x}(\mathbf{y}))\Big{)}\] \[= \sup_{\mathbf{x}}\log S_{T}^{x_{1:t},y_{1:t}}(\mathcal{F}| \mathbf{x}),\]

which finishes our proof. 

Now we are able to prove the key result Lemma B.1.

Proof of Lemma b.1.: Fix any hypothesis class \(\mathcal{F}\) and sequences \(x_{1:t}\in\mathcal{X}^{t},y_{1:t}\in\mathcal{Y}^{t}\). First we know

\[G(\mathcal{F},x_{1:t},y_{1:t})\geq\sup_{\mathbf{x}}\log S_{T}^{x_{1:t},y_{1:t} }(\mathcal{F}|\mathbf{x})\]

due to Eq. (12) and Lemma B.4. For the other direction, let us fix any threshold value \(\delta\in(0,1/2)\) and then

\[G(\mathcal{F},x_{1:t},y_{1:t}) \leq G(\mathcal{F}^{\delta},x_{1:t},y_{1:t})+T\cdot\log(1+|\mathcal{ Y}|\delta)\] \[=\sup_{\mathbf{x}}\log S_{T}^{x_{1:t},y_{1:t}}(\mathcal{F}^{ \delta}|\mathbf{x})+T\cdot\log(1+|\mathcal{Y}|\delta)\] \[=\sup_{\mathbf{x}}\log\Big{(}\sum_{\mathbf{y}\in\mathcal{Y}^{T-t} }\sup_{f\in\mathcal{F}^{\delta}}P_{f^{\delta}}(y_{1:t},\mathbf{y}|x_{1:t}, \mathbf{x}(\mathbf{y}))\Big{)}+T\cdot\log(1+|\mathcal{Y}|\delta)\] \[\leq\sup_{\mathbf{x}}\log\Big{(}\sum_{\mathbf{y}\in\mathcal{Y}^{T- t}}\sup_{f\in\mathcal{F}}P_{f}(y_{1:t},\mathbf{y}|x_{1:t},\mathbf{x}(\mathbf{y}))+ \delta\cdot M(T)\cdot|\mathcal{Y}|^{T}\Big{)}+T\cdot\log(1+|\mathcal{Y}|\delta)\] \[=\log\Big{(}\sup_{\mathbf{x}}\sum_{\mathbf{y}\in\mathcal{Y}^{T-t} }\sup_{f\in\mathcal{F}}P_{f}(y_{1:t},\mathbf{y}|x_{1:t},\mathbf{x}(\mathbf{y}))+ \delta\cdot M(T)\cdot|\mathcal{Y}|^{T}\Big{)}+T\cdot\log(1+|\mathcal{Y}|\delta),\]

where we have applied Lemma A.7, Lemma B.3, Lemma B.4, and Lemma A.6 accordingly. Similarly, we send \(\delta\to 0^{+}\) on the RHS of the last inequality and get

\[G(\mathcal{F},x_{1:t},y_{1:t})\leq\sup_{\mathbf{x}}\log\Big{(}\sum_{\mathbf{y} \in\mathcal{Y}^{T-t}}\sup_{f\in\mathcal{F}}P_{f}(y_{1:t},\mathbf{y}|x_{1:t}, \mathbf{x}(\mathbf{y}))\Big{)}=\sup_{\mathbf{x}}\log S_{T}^{x_{1:t},y_{1:t}}( \mathcal{F}|\mathbf{x}),\]

which concludes the proof. 
Additional discussions

### On the time-variant context space

In this section we generalize our analysis to the setting where the context space can evolve over time. We model time-varying context sets by a sequence of maps \(\mathcal{X}_{t}:\mathcal{X}^{t-1}\times\mathcal{Y}^{t-1}\to 2^{\mathcal{X}},t \in[T]\) as in [14, 15]. In each round \(t\), instead of picking any context from \(\mathcal{X}\), the nature is now required to only choose \(x_{t}\) from \(\mathcal{X}_{t}(x_{1:t-1},y_{1:t-1})\subseteq\mathcal{X}\). Then the minimax regret with respect to \((\mathcal{X}_{t})_{t\in[T]}\) is rewritten as

\[\mathcal{R}_{T}(\mathcal{F})=\left\|\sup_{x_{t}\in\mathcal{X}_{t}(x_{1:t-1},y_ {1:t-1})}\inf_{\hat{p}_{t}}\sup_{y_{t}}\right\|_{t=1}^{T}\,\mathcal{R}_{T}( \mathcal{F};\hat{p}_{1:T},x_{1:T},y_{1:T}).\]

A context tree \(\mathbf{x}\) is _consistent_ with respect to \((\mathcal{X}_{t})_{t\in[T]}\) if for all \(t\in[T]\) and \(\mathbf{y}\in\mathcal{Y}^{T}\), \(\mathbf{x}_{t}(\mathbf{y})\in\mathcal{X}_{t}(x_{1:t-1},y_{1:t-1})\). Then our results in Section 3 and Section 4 can be generalized simply by replacing the supremum over all context trees (of depth \(T\)) by the supremum over all consistent context trees. For example, we will have

\[\mathcal{R}_{T}(\mathcal{F})=\sup_{\mathbf{x}:\mathbf{x}\text{ is consistent}}\log S_{T}(\mathcal{F}|\mathbf{x}).\]

### On the global and non-global sequential cover

Now we go back to consider the usual setting of binary label and constant experts, i.e., \(\mathcal{Y}=\{0,1\}\) and \(\mathcal{F}\subseteq[0,1]^{\mathcal{X}}\). As mentioned in Section 3, previous works [15, 16] provided regret upper bounds based on \(\ell_{\infty}\) sequential entropy. More specifically, both of their bounds are in the form of \(O(\inf_{\alpha>0}\{\alpha T+\mathcal{H}(\mathcal{F},\alpha,T)\})\), with \(\mathcal{H}(\mathcal{F},\alpha,T)\) being either the non-global entropy \(\mathcal{H}_{\infty}(\mathcal{F},\alpha,T)\) or the global entropy \(\mathcal{H}_{G}(\mathcal{F},\alpha,T)\). It is then natural to ask which one of these two bounds is tighter. It is straightforward to prove that \(\mathcal{H}_{\infty}(\mathcal{F},\alpha,T)\) is no larger than \(\mathcal{H}_{G}(\mathcal{F},\alpha,T)\). In fact, the gap between them is at most a polylog factor, as we state and prove below.1 The proof of \(\mathcal{H}_{\infty}(\mathcal{F},\alpha,T)\leq\mathcal{H}_{G}(\mathcal{F}, \alpha,T)\) is also included for completeness. Before stating the results, we introduce the definition of sequential fat-shattering dimension.

Footnote 1: This result and its detailed proof sketch were communicated to the first author by Changlong Wu. The argument here differs only in minor details that we introduced, perhaps unnecessarily, to arrive at a rigorous proof.

**Definition C.1**: We say an \(\mathcal{X}\)-valued binary tree \(\mathbf{x}\) of depth \(d\) is \(\alpha\)-shattered by a class \(\mathcal{F}\subseteq[0,1]^{\mathcal{X}}\) for some \(\alpha>0\), if there exists a \([0,1]\)-valued binary tree \(\mathbf{s}\) of depth \(d\) such that

\[\forall\mathbf{y}\in\{0,1\}^{d},\exists f\in\mathcal{F},\text{ s.t. }(2y_{t}-1)\cdot(f(\mathbf{x}_{t}(\mathbf{y}))-\mathbf{s}_{t}(\mathbf{y})) \geq\frac{\alpha}{2},\forall t\in[d].\]

In this case, \(\mathbf{s}\) is called the witness of the shattering. The sequential fat-shattering dimension of \(\mathcal{F}\) at scale \(\alpha\), denoted by \(\text{sfat}_{\alpha}(\mathcal{F})\), is the largest \(d\) such that some depth-\(d\) context tree is \(\alpha\)-shattered by \(\mathcal{F}\).

**Proposition C.2**: _For any scale \(\alpha>0\), we have_

\[\mathcal{H}_{\infty}(\mathcal{F},\alpha,T)\geq\min\{T,\sup_{\alpha^{\prime}> \alpha}\text{sfat}_{2\alpha^{\prime}}(\mathcal{F})\}\cdot\log(2).\]

_Therefore, together with \(\mathcal{H}_{\infty}(\mathcal{F},\alpha,T)\leq\mathcal{H}_{G}(\mathcal{F}, \alpha,T)\) and the folklore \(\mathcal{H}_{G}(\mathcal{F},\alpha,T)\leq O(\text{sfat}_{\alpha}(\mathcal{F}) \log(T/\alpha))\), we conclude that the regret upper bounds \(O(\inf_{\alpha>0}\{\alpha T+\mathcal{H}(\mathcal{F},\alpha,T)\}),\mathcal{H} \in\{\mathcal{H}_{\infty},\mathcal{H}_{G}\}\), differ by at most a polylog factor._

**Proof of Proposition C.2**: Fix any \(\alpha^{\prime}>\alpha>0\) and let \(d_{\alpha^{\prime}}\) denote \(\min\{T,\text{sfat}_{2\alpha^{\prime}}(\mathcal{F})\}\). Then there exists a context tree \(\mathbf{x}\) and a witness tree \(\mathbf{s}\), both of depth \(d_{\alpha^{\prime}}\), such that for any path \(\mathbf{y}\in\{0,1\}^{d_{\alpha^{\prime}}}\), there exists an \(f\in\mathcal{F}\) such that

\[\forall t\in[d_{\alpha^{\prime}}],(2y_{t}-1)\cdot(f(x_{t}(\mathbf{y}))-s_{t}( \mathbf{y}))\geq\alpha^{\prime}>\alpha.\] (15)Let \(V_{\mathbf{x},\alpha}\) be an arbitrary sequential \(\ell_{\infty}\) covering of \(\mathcal{F}\) on \(\mathbf{x}\). Now we select a path \(\mathbf{y}\) and a sequence of subsets \(V_{\mathbf{x},\alpha}^{(t)}\subseteq V_{\mathbf{x},\alpha},t\in[d_{\alpha^{ \prime}}]\) in the following recursive way. Define \(V_{\mathbf{x},\alpha}^{(0)}=V_{\mathbf{x},\alpha}\). For each \(t\in[d_{\alpha^{\prime}}]\), choose \(y_{t}\in\{0,1\}\) such that \(2y_{t}-1\in\{-1,+1\}\) is the minority among all \(\mathrm{sgn}(v_{t}(y_{1:t-1})-s_{t}(y_{1:t-1})),v\in V_{\mathbf{x},\alpha}^{(t- 1)}\) (ignoring those of \(0\)'s). Finally update \(V_{\mathbf{x},\alpha}^{(t)}=\{v\in V_{\mathbf{x},\alpha}^{(t-1)}:\mathrm{sgn}( v_{t}(y_{1:t-1})-s_{t}(y_{1:t-1}))=2y_{t}-1\}\).

First we argue that, if there is any time \(t^{\prime}\in[d_{\alpha^{\prime}}]\) such that \(V_{\mathbf{x},\alpha}^{(t^{\prime}-1)}\neq\emptyset,V_{\mathbf{x},\alpha}^{(t ^{\prime})}=\emptyset\), then \(V_{\mathbf{x},\alpha}\) is not a valid cover of \(\mathcal{F}\) on \(\mathbf{x}\). Otherwise, recall we have selected \(y_{1},\ldots,y_{t^{\prime}-1}\). Now pick an arbitrary \(y_{t^{\prime}}\in\{0,1\}\). By Eq. (15) we can find some \(f\in\mathcal{F}\) such that \((2y_{t}-1)\cdot(f(x_{t}(y_{1:t-1}))-s_{t}(y_{1:t-1}))>\alpha,\forall t\in[t^{ \prime}]\). Since \(V_{\mathbf{x},\alpha}\) is a covering at scale \(\alpha\), there is \(v\in V_{\mathbf{x},\alpha}\) such that \(|v_{t}(\mathbf{y})-f(x_{t}(\mathbf{y}))|\leq\alpha,\forall t\in[t^{\prime}]\). This implies that \(\mathrm{sgn}(f(x_{t}(\mathbf{y}))-s_{t}(\mathbf{y}))=\mathrm{sgn}(v_{t}( \mathbf{y})-s_{t}(\mathbf{y}))=2y_{t}-1,\forall t\in[t^{\prime}]\). So we can always find some member of \(V_{\mathbf{x},\alpha}^{(t^{\prime}-1)}\) to match the minority sign of \(v_{t^{\prime}}(y_{1:t^{\prime}-1})-s_{t^{\prime}}(y_{1:t^{\prime}-1}),v\in V_ {\mathbf{x},\alpha}^{(t^{\prime}-1)}\), which means that \(V_{\mathbf{x},\alpha}^{(t)}\neq\emptyset\) and yields a contradiction.

Now we know that \(|V_{\mathbf{x},\alpha}^{(t)}|\geq 1,\forall t\in[d_{\alpha^{\prime}}]\). By design \(|V_{\mathbf{x},\alpha}^{(t)}|\leq|V_{\mathbf{x},\alpha}^{(t-1)}|/2,\forall t \in[d_{\alpha^{\prime}}]\), so we must have \(|V_{\mathbf{x},\alpha}|=|V_{\mathbf{x},\alpha}^{(0)}|\geq 2^{d_{\alpha^{\prime}}}\). As the choice of covering is arbitrary, the covering number \(\mathcal{N}_{\infty}(\mathcal{F}\circ\mathbf{x},\alpha,d_{\alpha^{\prime}})\) is also lower bounded by \(2^{d_{\alpha^{\prime}}}\) and hence \(\mathcal{H}_{\infty}(\mathcal{F},\alpha,d_{\alpha^{\prime}})\geq d_{\alpha^{ \prime}}\cdot\log(2)\). If \(\sup_{\alpha^{\prime}>\alpha}\mathrm{stat}_{2\alpha^{\prime}}(\mathcal{F})\leq T\), then we get that

\[\mathcal{H}_{\infty}(\mathcal{F},\alpha,T)\geq\sup_{\alpha^{\prime}>\alpha} \mathcal{H}_{\infty}(\mathcal{F},\alpha,\mathrm{stat}_{2\alpha^{\prime}}( \mathcal{F}))\geq\sup_{\alpha^{\prime}>\alpha}\mathrm{stat}_{2\alpha^{\prime}}( \mathcal{F})\cdot\log(2).\]

If there is some \(\alpha^{\prime}>\alpha\) such that \(\mathrm{stat}_{2\alpha^{\prime}}(\mathcal{F})\geq T\), then

\[\mathcal{H}_{\infty}(\mathcal{F},\alpha,T)=\mathcal{H}_{\infty}(\mathcal{F}, \alpha,d_{\alpha^{\prime}})\geq T\cdot\log(2).\]

Combining these two cases together, we have

\[\mathcal{H}_{\infty}(\mathcal{F},\alpha,T)\geq\min\{T,\sup_{\alpha^{\prime}> \alpha}\mathrm{stat}_{2\alpha^{\prime}}(\mathcal{F})\}\cdot\log(2).\]

**Proposition C.3**: _Let \(\mathcal{G}_{\alpha}\) be a global sequential \(\alpha\)-covering of \(\mathcal{F}\) as defined in [10]. Then for any context tree \(\mathbf{x}\), there exists a sequential cover \(V_{\mathbf{x},\alpha}\) of \(\mathcal{F}\circ\mathbf{x}\) at scale \(\alpha\) with \(|V_{\mathbf{x},\alpha}|\leq|\mathcal{G}_{\alpha}|\). This implies that \(\mathcal{H}_{\infty}(\mathcal{F},\alpha,T)\leq\log|\mathcal{G}_{\alpha}|\)._

**Proof of Proposition C.3** Fix arbitrary context tree \(\mathbf{x}\). For any \(g\in\mathcal{G}_{\alpha}\), define the \([0,1]\)-valued tree \(v^{g}\) by \(v_{t}^{g}(\mathbf{y})=g(x_{1:t}(\mathbf{y})),\forall t\in[T],\mathbf{y}\in \mathcal{Y}^{T}\). Now let \(V_{\mathbf{x},\alpha}=\{v^{g}:g\in\mathcal{G}_{\alpha}\}\) and we will show that \(V_{\mathbf{x},\alpha}\) is indeed a sequential cover of \(\mathcal{F}\circ\mathbf{x}\) at scale \(\alpha\).

For any \(f\in\mathcal{F}\) and \(\mathbf{y}\in\mathcal{Y}^{T}\), tree \(\mathbf{x}\) yields a length\(-T\) sequence \(x_{1:T}(\mathbf{y})\) and by definition of the global sequential covering, there exists \(g\in\mathcal{G}_{\alpha}\) such that

\[|f(x_{t}(\mathbf{y}))-g(x_{1:t}(\mathbf{y}))|\leq\alpha,\forall t\in[T].\]

So by our construction of \(V_{\mathbf{x},\alpha}\), \(v^{g}\in V_{\mathbf{x},\alpha}\) holds

\[|f(x_{t}(\mathbf{y}))-v_{t}^{g}(\mathbf{y})|=|f(x_{t}(\mathbf{y}))-g(x_{1:t}( \mathbf{y}))|\leq\alpha,\forall t\in[T],\]

which yields our claim after observing \(|V_{\mathbf{x},\alpha}|\leq|\mathcal{G}_{\alpha}|\).

## Appendix D Additional proofs

**Lemma D.1**: _For any \(\mathcal{X}\)-valued \(\mathcal{Y}\)-ary context tree \(\mathbf{x}\) of depth \(T\), and \(f:(\mathcal{X}\times\mathcal{Y})^{*}\times\mathcal{X}\to\Delta(\mathcal{Y})\), we have_

\[\sum_{\mathbf{y}\in\mathcal{Y}^{T}}P_{f}(\mathbf{y}|\mathbf{x}(\mathbf{y}))=1,\] (16)

_where we recall that \(\mathbf{x}(\mathbf{y})\) denotes the context sequence \((\mathbf{x}_{1}(\mathbf{y}),\ldots,\mathbf{x}_{T}(\mathbf{y}))\)._

**Proof of Lemma D.1** This is done by induction on the depth \(T\). The key observation is that for any label sequence \(\mathbf{y}\), \(\mathbf{x}_{t}(\mathbf{y})=\mathbf{x}_{t}(y_{1},\ldots,y_{t-1})\) only depends on the first \(t-1\) labels. For \(T=1\), any context tree \(\mathbf{x}\) is represented by its root node \(\mathbf{x}_{1}(\cdot)=\mathbf{x}_{1}\in\mathcal{X}\) and hence

\[\sum_{y_{1}}P_{f}(y_{1}|\mathbf{x}_{1})=\sum_{y_{1}}f(\mathbf{x}_{1})(y_{1})=1.\]

Suppose Eq. (16) holds for all context trees \(\mathbf{x}\) of depth \(T\leq d\) and all sequential functions \(f\). Now given any context tree \(\mathbf{x}=(\mathbf{x}_{1},\ldots,\mathbf{x}_{d+1})\) of depth \(T=d+1\), we denote its depth \(d\) subtree \((\mathbf{x}_{1},\ldots,\mathbf{x}_{d})\) by \(\mathbf{x}_{[d]}\). Then

\[\sum_{\mathbf{y}\in\mathcal{Y}^{d+1}}P_{f}(\mathbf{y}|\mathbf{x }(\mathbf{y})) =\sum_{y_{1:d}}\sum_{y_{d+1}}P_{f}(y_{1:d+1}|\mathbf{x}_{1}, \mathbf{x}_{2}(y_{1}),\ldots,\mathbf{x}_{d+1}(y_{1:d}))\] \[=\sum_{y_{1:d}}\sum_{y_{d+1}}P_{f}(y_{1:d}|\mathbf{x}_{1},\ldots, \mathbf{x}_{d}(y_{1:d-1}))\cdot f(\mathbf{x}_{1},\ldots,\mathbf{x}_{d+1}(y_{1: d}),y_{1:d})(y_{d+1})\] \[=\sum_{y_{1:d}}P_{f}(y_{1:d}|\mathbf{x}_{1},\ldots,\mathbf{x}_{d}( y_{1:d-1}))\sum_{y_{d+1}}f(\mathbf{x}_{1},\ldots,\mathbf{x}_{d+1}(y_{1:d}),y_{1:d}) (y_{d+1})\] \[=\sum_{y_{1:d}}P_{f}(y_{1:d}|\mathbf{x}_{1},\ldots,\mathbf{x}_{d}( y_{1:d-1}))\] \[=\sum_{\mathbf{y}\in\mathcal{Y}^{d}}P_{f}(\mathbf{y}|\mathbf{x}_{ [d]}(\mathbf{y}))=1,\]

where the last step is due to induction. We are done.

### NeurIPS Paper Checklist

The checklist is designed to encourage best practices for responsible machine learning research, addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove the checklist: **The papers not including the checklist will be desk rejected.** The checklist should follow the references and precede the (optional) supplemental material. The checklist does NOT count towards the page limit.

Please read the checklist guidelines carefully for information on how to answer these questions. For each question in the checklist:

* You should answer [Yes], [No], or [NA]
* [NA] means either that the question is Not Applicable for that particular paper or the relevant information is Not Available.
* Please provide a short (1-2 sentence) justification right after your answer (even for NA).

**The checklist answers are an integral part of your paper submission.** They are visible to the reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it (after eventual revisions) with the final version of your paper, and its final version will be published with the paper.

The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation. While "[Yes] " is generally preferable to "[No] ", it is perfectly acceptable to answer "[No] " provided a proper justification is given (e.g., "error bars are not reported because it would be too computationally expensive" or "we were unable to find the license for the dataset we used"). In general, answering "[No] " or "[NA] " is not grounds for rejection. While the questions are phrased in a binary way, we acknowledge that the true answer is often more nuanced, so please just use your best judgment and write a justification to elaborate. All supporting evidence can appear either in the main paper or the supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification please point to the section(s) where related material for the question can be found.

IMPORTANT, please:

* **Delete this instruction block, but keep the section heading "NeurIPS paper checklist"**,
* **Keep the checklist subsection headings, questions/answers and guidelines below.**
* **Do not modify the questions and only use the provided macros for your answers**.

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: Abstract summarizes theorems we have proven. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes]Justification: We discuss limitations in the Discussion section. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: We don't see how to justify this without machine checkable proofs, which we have not provided. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [NA] Justification: There are no experiments.

Guidelines:

* The answer NA means that the paper does not include experiments.
* If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.
* If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.
* Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.
* While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [NA] Justification: There is no data or code. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.

* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [NA] Justification: There are no experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [NA] Justification: There are no experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors). * It should be clear whether the error bar is the standard deviation or the standard error of the mean. * It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified. * For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). * If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [NA] Justification: There are no experiments. Guidelines: * The answer NA means that the paper does not include experiments.

* The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.
* The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.
* The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: We have read the code and do not see any violation. Our work relates to the mathematical foundations of a basic task in ML. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: The paper presents a mathematical characterization of the limits of probabilistic forecasting, and a (meta)algorithm that achieves these limits. For any class of interest, there remains significant work to realize that algorithm in an efficient way. As such, our impact is most directly on the theoretical community, who might then have direct societal impact by producing an minimax optimal algorithm. As such, our societal impact may be great, but it will always be quite indirect. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. * If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards**Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: We are not releasing models or data. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licensees for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [NA] Justification: We use no such assets. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. * If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: No new assets are introduced. Guidelines: * The answer NA means that the paper does not release new assets. * Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. * The paper should discuss whether and how consent was obtained from people whose asset is used.

* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: No such experiments were performed. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. * According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: Paper does not involve crowdsourcing or research with human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper. * We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution. * For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.