# Weak Supervision Performance Evaluation

via Partial Identification

 Felipe Maia Polo

Department of Statistics

University of Michigan

&Subha Maity1

Department of Statistics and Actuarial Science

University of Waterloo

Mikhail Yurochkin

MIT-IBM Watson AI Lab

&Moulinath Banerjee

Department of Statistics

University of Michigan

&Yuekai Sun

Department of Statistics

University of Michigan

Equal contribution. Corresponding author: Felipe Maia Polo <felipemiaapolo@gmail.com>

###### Abstract

Programmatic Weak Supervision (PWS) enables supervised model training without direct access to ground truth labels, utilizing weak labels from heuristics, crowd-sourcing, or pre-trained models. However, the absence of ground truth complicates model evaluation, as traditional metrics such as accuracy, precision, and recall cannot be directly calculated. In this work, we present a novel method to address this challenge by framing model evaluation as a partial identification problem and estimating performance bounds using Frechet bounds. Our approach derives reliable bounds on key metrics without requiring labeled data, overcoming core limitations in current weak supervision evaluation techniques. Through scalable convex optimization, we obtain accurate and computationally efficient bounds for metrics including accuracy, precision, recall, and F1-score, even in high-dimensional settings. This framework offers a robust approach to assessing model quality without ground truth labels, enhancing the practicality of weakly supervised learning for real-world applications.2

Footnote 2: Our code can be found on https://github.com/felipemiaapolo/wsbounds

## 1 Introduction

Programmatic weak supervision (PWS) is a modern learning paradigm that allows practitioners to train their supervised models without the immediate need for ground truth labels \(Y\)[50, 48, 47, 49, 58, 64]. In PWS, practitioners first acquire cheap and abundant weak labels \(Z\) through heuristics, crowdsourcing, external APIs, and pretrained models, which serve as proxies for \(Y\). Then, they fit a _label model_, _i.e._, a graphical model for \(P_{Y,Z}\)[50, 49, 22, 17], which, under appropriate modeling assumptions, can be fitted without requiring \(Y\)'s. Finally, a predictor \(h:\mathcal{X}\rightarrow\mathcal{Y}\) is trained using samples \((X_{i},Z_{i})\)'s and a _noise-aware loss_ constructed using this fitted label model [50].

One major unsolved issue with the weak supervision approach is that even if we knew \(P_{Y,Z}\), evaluation metrics such as accuracy, recall, precision, or \(F_{1}\) cannot be estimated for model validation without any ground truth labels. In fact, these quantities are not identifiable (not uniquely determined) since we only have partial information about the joint distribution \(P_{X,Y}\) through the marginals \(P_{X,Z}\) and \(P_{Y,Z}\). As a consequence, any performance metric based on \(h\) cannot be estimated without making extra strong assumptions, _e.g._, \(X\perp\!\!\!\perp Y\mid Z\). Unfortunately, these conditions are unlikely to arise in many situations. A recent work [66] investigated the role and importance of ground truth labels on model evaluation in the weak supervision literature. They determined that, under the current situation,the _good performance and applicability of weakly supervised classifiers heavily rely on the presence of at least some high-quality labels, which undermines the purpose of using weak supervision_ since models can be directly fine-tuned on those labels and achieve similar performance. Therefore, in this work, we develop new evaluation methods that can be used without any ground truth labels and show that the performance of weakly supervised models can be accurately estimated in many cases, even permitting successful model selection. Our solution relies on partial identification by estimating Frechet bounds for bounding performance metrics such as accuracy, precision, recall, and \(F_{1}\) score of classifiers trained with weak supervision.

**Frechet bounds:** Consider a random vector \((X,Y,Z)\in\mathcal{X}\times\mathcal{Y}\times\mathcal{Z}\) is drawn from an unknown distribution \(P\). We assume \(\mathcal{X}\subset\mathbb{R}^{d}\) is arbitrary while \(\mathcal{Y}\) and \(\mathcal{Z}\) are finite. In this work, we develop and analyze the statistical properties of a method for estimating Frechet bounds [53; 54] of the form

\[L\triangleq\inf_{\pi\in\Pi}\mathbb{E}_{\pi}[g(X,Y,Z)]\text{ and }U\triangleq \sup_{\pi\in\Pi}\mathbb{E}_{\pi}[g(X,Y,Z)]\] (1.1)

when \(g\) is a fixed bounded function, with \(\Pi\) being the set of distributions \(\pi\) for \((X,Y,Z)\) such that the marginal \(\pi_{X,Z}\) (resp. \(\pi_{Y,Z}\)) is identical to the prescribed marginal \(P_{X,Z}\) (resp. \(P_{Y,Z}\)). Our proposed method can efficiently obtain estimates for the bounds by solving convex programs, with the significant advantage that the computational complexity of our algorithm does not scale with the dimensionality of \(X\), making it well-suited for applications dealing with high-dimensional data. In previous work, for example, Frechet bounds were studied in the financial context (_e.g._, see Ruschendorf [55], Bartl et al. [7]). However, our focus is on applying our methods of estimating Frechet bounds to the problem of assessing predictors trained using programmatic weak supervision (PWS). For example, the upper and lower bounds for the accuracy of a classifier \(h\) can be estimated using our method simply by letting \(g(x,y,z)=\mathds{1}[h(x)=y]\) in (1.1). At a high level, our method replaces \(P_{Y,Z}\) with the fitted label, and \(P_{X,Z}\) with its empirical version in the Frechet bounds in (1.1), and reformulates the problem in terms of a convex optimization problem.

**Contributions:** Our contributions are

1. Developing a practical algorithm for estimating the Frechet bounds in (1.1). Our algorithm can be summarized as solving convex programs and is scalable to high-dimensional distributions.
2. Quantifying the uncertainty in the computed bounds due to uncertainty in the prescribed marginals by deriving the asymptotic distribution for our estimators.
3. Applying our method to bounding the accuracy, precision, recall, and \(F_{1}\) score of classifiers trained with weak supervision. This enables practitioners to evaluate classifiers in weak supervision settings _without access to ground truth labels_.

### Related work

**Weak supervision:** With the emergence of data-hungry models, the lack of properly labeled datasets has become a major bottleneck in the development of supervised models. One approach to overcome this problem is using programmatic weak supervision (PWS) to train predictors in the absence of high-quality labels \(Y\)[50; 48; 47; 49; 58; 64]. PWS has shown the potential to solve a variety of tasks in different fields with satisfactory performance. For example, some works have applied weak supervision to named-entity recognition [32; 21; 57], video frame classification [22], bone and breast tumor classification [61]. More recently, Smith et al. [59] proposed a new approach to integrating weak supervision and pre-trained large language models (LLMs). Rather than applying LLMs in the usual zero/few-shot fashion, they treat those large models as weak labelers that can be used through prompting to obtain weak signals instead of using hand-crafted heuristics. Recently, Zhu et al. [66] showed that in many situations, the success of weakly supervised classifiers depends on the availability of ground truth validation samples, undermining the purpose of weak supervision. Then, we develop a new method for model evaluation that does not depend on the availability of any ground truth labels.

A relevant line of research within the realm of weak supervision that is closely related to this work is adversarial learning [4; 5; 42; 41]. Often, adversarial learning aims to learn predictors that perform well in worst-case scenarios. For example, Mazzetto et al. [41] develops a method to learn weakly supervised classifiers in the absence of a good label model. In their work, the authors use a small set of labeled data points to constrain the space of possible data distributions and then find a predictor that performs well in the worst-case scenario. Our work relates to this literature in the sense that we are interested in the worst and best-case scenarios over a set of distributions. However, we focus on developing an evaluation method instead of another adversarial learning strategy.

**Partial identification:** It is often the case that the distributions of interest cannot be fully observed, which is generally due to missing or noisy data [43, 23]. In cases where practitioners can only observe some aspects of those distributions, _e.g._, marginal distributions or moments, parameters of interest may not be identifiable without strong assumptions due to ambiguity in the observable data. Partial identification deals with the problem without imposing extra assumptions. This framework allows estimating a set of potential values for the parameters of interest (usually given by non-trivial bounds) and has been frequently considered in many areas such as microeconometrics [38, 39, 40, 43], causal inference [25, 23], algorithmic fairness [20, 46]. Our work is most related to Ruschendorf [53, 54, 55], Bartl et al. [7], which study bounds for the uncertainty of a quantity of interest for a joint distribution that is only partially identified through its marginals, _i.e._, Frechet bounds. Compared to the aforementioned works, the novelty of our contribution is proposing a convex optimization algorithm that accurately estimates the Frechet bounds with proven performance guarantees in a setup that is realized in numerous weak-supervision applications.

### Notation

We write \(\mathbb{E}_{Q}\) and \(\mathrm{Var}_{Q}\) for the expectation and variance of statistics computed using i.i.d. copies of a random vector \(W\sim Q\). Consequently, \(\mathbb{P}_{Q}(A)=\mathbb{E}_{Q}\mathds{1}_{A}\), where \(\mathds{1}_{A}\) is the indicator of an event \(A\). If the distribution is clear by the context, we omit the subscript. If \((a_{m})_{m\in\mathbb{N}}\) and \((b_{m})_{m\in\mathbb{N}}\) are sequences of scalars, then \(a_{m}=o(b_{m})\) is equivalent to \(a_{m}/b_{m}\to 0\) as \(m\to\infty\) and \(a_{m}=b_{m}+o(1)\) means \(a_{m}-b_{m}=o(1)\). If \((V^{(m)})_{m\in\mathbb{N}}\) is a sequence of random variables, then (i) \(V^{(m)}=o_{P}(1)\) means that for every \(\varepsilon>0\) we have \(\mathbb{P}(|V^{(m)}|>\varepsilon)\to 0\) as \(m\to\infty\), (ii) \(V^{(m)}=\mathcal{O}_{P}(1)\) means that for every \(\varepsilon>0\) there exists a \(M>0\) such that \(\sup_{m\in\mathbb{N}}\mathbb{P}(|V^{(m)}|>M)<\varepsilon\), (iii) \(V^{(m)}=a_{m}+o_{P}(1)\) means \(V^{(m)}-a_{m}=o_{P}(1)\), (iv) \(V^{(m)}=o_{P}(a_{m})\) means \(V^{(m)}/a_{m}=o_{P}(1)\), and (v) \(V^{(m)}=\mathcal{O}_{P}(a_{m})\) means \(V^{(m)}/a_{m}=\mathcal{O}_{P}(1)\).

## 2 Estimating Frechet bounds

A roadmap to our approach follows. We first reformulate the Frechet bounds in (1.1) into their dual problems, which we discuss in (2.1). Then, we replace the non-smooth dual problems with their appropriate smooth approximations, as discussed in (2.2). Finally, we propose estimators for the smooth approximations (2.3) and derive their asymptotic distributions in Theorem 2.5.

### Dual formulations of the bounds and their approximations

This section presents a result that allows us to efficiently solve the optimization problems in (1.1) by deriving their dual formulations as finite-dimensional convex programs. Before we dive into the result, let us define a family of matrices denoted by

\[\mathcal{A}\triangleq\big{\{}a\in\mathbb{R}^{|\mathcal{Y}|\times|\mathcal{Z }|}\ :\ \sum_{y\in\mathcal{Y}}a_{yz}=0\text{ for every }z\in\mathcal{Z}\big{\}}.\]

With this definition in place, we introduce the dual formulation in Theorem 2.1.

**Theorem 2.1**.: _Let \(g:\mathcal{X}\times\mathcal{Y}\times\mathcal{Z}\to\mathbb{R}\) be a bounded measurable function. Then,_

\[L=\sup_{a\in\mathcal{A}}\mathbb{E}[f_{l}(X,Z,a)]\text{ and }U=\inf_{a\in \mathcal{A}}\mathbb{E}[f_{u}(X,Z,a)]\] (2.1)

_where_

\[f_{l}(x,z,a)\triangleq \min_{\bar{y}\in\mathcal{Y}}\left[g(x,\bar{y},z)+a_{\bar{y}z} \right]-\mathbb{E}_{P_{Y|Z}}\left[a_{Yz}|Z=z\right]\] \[f_{u}(x,z,a)\triangleq \max_{\bar{y}\in\mathcal{Y}}\left[g(x,\bar{y},z)+a_{\bar{y}z} \right]-\mathbb{E}_{P_{Y|Z}}\left[a_{Yz}|Z=z\right].\]

_Moreover, \(L\) and \(U\) are attained by some optimizers in \(\mathcal{A}\)._

Theorem 2.1 remains valid if we maximize/minimize over \(\mathbb{R}^{|\mathcal{Y}|\times|\mathcal{Z}|}\) instead of \(\mathcal{A}\). However, this is not necessary because the values of \(f_{l}\) and \(f_{u}\) remain identical for the following shifts in \(a\): \(a_{\cdot z}\gets a_{\cdot z}+b_{z}\) where \(b_{z}\in\mathbb{R}\). By constraining the set of optimizers to \(\mathcal{A}\), we eliminate the possibility of having multiple optimal points. The proof of Theorem 2.1 is placed in Appendix B and is inspired by ideas from Optimal Transport; see Appendix A.

The computation of these bounds entails finding a minimum or maximum over a discrete set, meaning that straightforward application of their empirical versions could result in optimizing non-smooth functions, which is often challenging. To mitigate this, we consider a smooth approximation of the problem that is found to be useful in handling non-smooth optimization problems [3; 6]. We approximate the \(\max\) and \(\min\) operators with their "soft" counterparts:

\[\text{softmin}\{b_{1},\cdots,b_{K}\}\triangleq-\varepsilon\log[\tfrac{1}{K} \sum_{k}\exp(\tfrac{-b_{k}}{\varepsilon})],\ \ \text{softmax}\{b_{1},\cdots,b_{K}\}\triangleq \varepsilon\log[\tfrac{1}{K}\sum_{k}\exp(\tfrac{b_{k}}{\varepsilon})]\,,\]

where \(\varepsilon>0\) is a small constant that dictates the level of smoothness. As \(\varepsilon\) nears zero, these soft versions of \(\max\) and \(\min\) converge to their original non-smooth forms. Using these approximations, we reformulate our dual optimization in (2.1) into smooth optimization problems:

\[L_{\varepsilon}\triangleq\sup_{a\in\mathcal{A}}\mathbb{E}[f_{l,\varepsilon}( X,Z,a)]\text{ and }U_{\varepsilon}\triangleq\inf_{a\in\mathcal{A}}\mathbb{E}[f_{u,\varepsilon}(X,Z,a)]\] (2.2)

where

\[f_{l,\varepsilon}(x,z,a) \triangleq-\varepsilon\log\left[\tfrac{1}{|\mathcal{Y}|}\sum_{y \in\mathcal{Y}}\exp\left(\tfrac{g(x,y,z)+a_{yz}}{-\varepsilon}\right)\right] -\mathbb{E}_{P_{Y|Z}}\left[a_{Yz}\mid Z=z\right]\] \[f_{u,\varepsilon}(x,z,a) \triangleq\varepsilon\log\left[\tfrac{1}{|\mathcal{Y}|}\sum_{y \in\mathcal{Y}}\exp\left(\tfrac{g(x,y,z)+a_{yz}}{\varepsilon}\right)\right]- \mathbb{E}_{P_{Y|Z}}\left[a_{Yz}\mid Z=z\right]\]

and \(\varepsilon>0\) is kept fixed at an appropriate value. As a consequence of Lemma 5 of An et al. [3], we know that \(L_{\varepsilon}\) and \(U_{\varepsilon}\) are no more than \(\varepsilon\log|\mathcal{Y}|\) units from \(L\) and \(U\). Thus, that distance can be regulated by adjusting \(\varepsilon\). For example, if we are comfortable with an approximation error of \(10^{-2}\) units when \(|\mathcal{Y}|=2\), we will set \(\varepsilon=10^{-2}/\log(2)\approx.014\).

### Estimating the bounds

In practice, it is not usually possible to solve the optimization problems in (2.2), because we may not have direct access to the distributions \(P_{X,Z}\) and \(P_{Y|Z}\). We overcome this problem by assuming that we can estimate the distributions using an available dataset.

To this end, let us assume that we have a sample \(\{(X_{i},Z_{i})\}_{i=1}^{n}\stackrel{{\text{iid}}}{{\sim}}P_{X,Z}\), and thus we replace the relevant expectations with \(P_{X,Z}\) by its empirical version. Additionally, we have a sequence \(\{\hat{P}_{Y|Z}^{(m)},m\in\mathbb{N}\}\) that estimates \(P_{Y|Z}\) with greater precision as \(m\) increases. Here, \(m\) can be viewed as the size of a sample to estimate \(P_{Y|Z}\). Although the exact procedure for estimating the conditional distribution is not relevant to this section, we have discussed in our introductory section that this can be estimated using a _label model_[49; 22] in applications with weak supervision or in a variety of other ways for applications beyond weak supervision. Later in this section, we will formalize the precision required for the estimates. To simplify our notation, we omit the superscript \(m\) in \(\hat{P}_{Y|Z}^{(m)}\), whenever it is convenient to do so.

Thus, the Frechet bounds are estimated as

\[\hat{L}_{\varepsilon}=\sup_{a\in\mathcal{A}}\tfrac{1}{n}\sum_{i=1}^{n}\hat{f }_{l,\varepsilon}(X_{i},Z_{i},a)\ \ \text{and}\ \hat{U}_{\varepsilon}=\inf_{a\in\mathcal{A}}\tfrac{1}{n}\sum_{i=1}^{n}\hat{f} _{u,\varepsilon}(X_{i},Z_{i},a)\] (2.3)

where

\[\hat{f}_{l,\varepsilon}(x,z,a) \triangleq-\varepsilon\log\left[\tfrac{1}{|\mathcal{Y}|}\sum_{y \in\mathcal{Y}}\exp\left(\tfrac{g(x,y,z)+a_{yz}}{-\varepsilon}\right)\right]- \mathbb{E}_{\hat{P}_{Y|Z}}\left[a_{Yz}\mid Z=z\right]\] \[\hat{f}_{u,\varepsilon}(x,z,a) \triangleq\varepsilon\log\left[\tfrac{1}{|\mathcal{Y}|}\sum_{y \in\mathcal{Y}}\exp\left(\tfrac{g(x,y,z)+a_{yz}}{\varepsilon}\right)\right]- \mathbb{E}_{\hat{P}_{Y|Z}}\left[a_{Yz}\mid Z=z\right]\]

In our practical implementations we eliminate the constraint that \(\sum_{y}a_{yz}=0\) for all \(z\in\mathcal{Z}\) by adding a penalty term \(\sum_{z\in\mathcal{Z}}(\sum_{y\in\mathcal{Y}}a_{yz})^{2}\) to \(\hat{U}_{\varepsilon}\) (and its negative to \(\hat{L}_{\varepsilon}\)) and then solve unconstrained convex programs using the L-BFGS algorithm [33]. Since the penalty term vanishes only when \(\sum_{y}a_{yz}=0\) for all \(z\in\mathcal{Z}\), we guarantee that the optimal solution is in \(\mathcal{A}\).

### Asymptotic properties of the estimated bounds

In the following, we state the assumptions required for our asymptotic analysis of \(\hat{L}_{\varepsilon}\) and \(\hat{U}_{\varepsilon}\). We start with some regularity assumptions.

**Assumption 2.2**.: \(L_{\varepsilon}\) _and \(U_{\varepsilon}\) are attained by some optimizers in \(\mathcal{A}\) (2.2)._

**Assumption 2.3**.: _Let \(\hat{a}\) represent the optimizer for any problem in (2.3), which is assumed to exist. Suppose \(\left\|\hat{a}\right\|_{\infty}=\mathcal{O}_{P}(1)\) as \(m\to\infty\)._We show in Lemmas C.4, C.5, and C.6 that Assumptions 2.2 and 2.3 can be derived in the binary classification case (\(|\mathcal{Y}|=2\)) if \(\mathbb{P}(Y=y\mid Z=z)\) is bounded away from both zero and one, _i.e._\(\kappa<\mathbb{P}(Y=y\mid Z=z)<1-\kappa\) for some \(\kappa>0\) for every \(y\in\mathcal{Y}\) and \(z\in\mathcal{Z}\).

In our next assumption, we formalize the degree of precision for the sequence \(\{\hat{P}_{Y|Z}^{(m)},m\in\mathbb{N}\}\) of estimators that we require for desired performances of the bound estimates.

**Assumption 2.4**.: _Denote the total variation distance (TV) between probability measures as \(d_{\mathrm{TV}}\). For every \(z\in\mathcal{Z}\), for some \(\lambda>0\), we have that \(d_{\mathrm{TV}}\big{(}\hat{P}_{Y|Z=z}^{(m)},P_{Y|Z=z}\big{)}=\mathcal{O}_{P}( m^{-\lambda})\)._

From Ratner et al. [49]'s Theorem 2 and a Lipschitz property of the label model3, we can conclude \(\lambda=1/2\) for a popular label model used in the PWS literature. The asymptotic distributions for the estimated bounds follow.

Footnote 3: Ratner et al. [49] derive that in page 24 of their arXiv paper version.

**Theorem 2.5**.: _Assume 2.2, 2.3, and 2.4, and let \(n\) be a function of \(m\) such that \(n\to\infty\) and \(n=o(m^{2\lambda})\) when \(m\to\infty\). Then, as \(m\to\infty\)_

\[\sqrt{n}(\hat{L}_{\varepsilon}-L_{\varepsilon})\Rightarrow N(0,\sigma_{l, \varepsilon}^{2})\text{ and }\sqrt{n}(\hat{U}_{\varepsilon}-U_{\varepsilon}) \Rightarrow N(0,\sigma_{u,\varepsilon}^{2})\]

_where \(\sigma_{l,\varepsilon}^{2}\triangleq\mathrm{Var}f_{l,\varepsilon}(X,Z,a_{l, \varepsilon}^{*})\), \(\sigma_{u,\varepsilon}^{2}\triangleq\mathrm{Var}f_{u,\varepsilon}(X,Z,a_{u, \varepsilon}^{*})\), and \(a_{l,\varepsilon}^{*}\) and \(a_{u,\varepsilon}^{*}\) are the unique optimizers to attain \(L_{\varepsilon}\) and \(U_{\varepsilon}\) (2.2)._

Theorem 2.5 tells us that, if the label model is consistent (Assumption 2.4), under some mild regularity conditions (Assumption 2.2 and 2.3), our estimators and will be asymptotically Gaussian with means \(L_{\varepsilon}\) and \(U_{\varepsilon}\) and variances \(\sigma_{l,\varepsilon}^{2}/n\) and \(\sigma_{u,\varepsilon}^{2}/n\). The above theorem requires \(m^{2\lambda}\) to grow faster than \(n\) implying that, through assumption 2.4, \(P_{Y|Z}\) is estimated with a precision greater than the approximation error when we replace \(P_{X,Z}\) with \(\frac{1}{n}\sum_{i}\delta_{X_{i},Z_{i}}\). In the case which \(\lambda=1/2\), this condition translates to \(n/m\to 0\) as \(n\to\infty\). This allows us to derive the asymptotic distribution when combined with classical results from M-estimation (see proof in Appendix C).

**Construction of confidence bounds:** One interesting use of Theorem 2.5 is that we can construct an approximate confidence interval for the estimates of the bounds. For example, an approximate \(1-\gamma\) confidence interval for \(L_{\varepsilon}\) can is constructed as

\[\hat{I}=\Big{[}\hat{L}_{\varepsilon}-\frac{\tau_{\gamma}\hat{\sigma}_{l, \varepsilon}}{\sqrt{n}},\ \ \hat{L}_{\varepsilon}+\frac{\tau_{\gamma}\hat{\sigma}_{l, \varepsilon}}{\sqrt{n}}\Big{]},\]

where \(\tau_{\gamma}=\Phi^{-1}(1-\gamma/2)\) and \(\hat{\sigma}_{l,\varepsilon}\) is the empirical standard deviation of \(f_{l,\varepsilon}(X,Z,\cdot)\), substituting the estimate \(\hat{a}\) (solution for the problem in 2.3). For such interval, it holds \(\mathbb{P}\big{(}L_{\varepsilon}\in\hat{I}\big{)}\approx 1-\gamma\), _i.e._, with approximately \(1-\gamma\) confidence we can say that the true \(L_{\varepsilon}\) is in the interval above. An interval for \(U_{\varepsilon}\) can be constructed similarly.

## 3 Evaluation of model performance in weak supervision

In this section, we describe how to use the ideas presented in Section 2 to estimate non-trivial bounds for the evaluation metrics of a weakly supervised classifier \(h\) when no high-quality labels are available. In the standard weak supervision setup, only unlabeled data (\(X\)) is available, but the practitioner can extract weak labels (\(Z\)) from the available data. More specifically, we assume access to the dataset \(\{(X_{i},Z_{i})\}_{i=1}^{m}\), i.i.d. with distribution \(P_{X,Z}\), used in its entirety to estimate a label model \(\hat{P}_{Y|Z}\)[49; 22] and where part of it, _e.g._, a random subset of size \(n\), is used to estimate bounds4. To simplify the exposition, we assume the classifier \(h\) is fixed5.

Footnote 4: It is also possible to use distinct datasets for estimating the label model and the bounds as long as the dataset to estimate the label is much bigger. This is our approach in the experiments.

Footnote 5: In practice, it can be obtained using all the data not used to estimate bounds.

### Risk and accuracy

Let \(\ell\) be a generic classification loss function. The risk of a classifier \(h\) is defined as \(R(h)=\mathbb{E}[\ell(h(X),Y)]\), which cannot be promptly estimated in a weak supervision problem, where we do not observe any \(Y\). In this situation, we can make use of our bound estimators in Section 2.2, where we set \(g(x,y,z)=\ell(h(x),y)\) to obtain bounds for \(R(h)\). Furthermore, we can estimate an uncertainty set for the accuracy of the classification simply by letting \(g(x,y,z)=\mathds{1}[h(x)=y]\).

### Precision, recall, and \(F_{1}\) score

For a binary classification problem, where \(\mathcal{Y}=\{0,1\}\), the precision, recall, and \(F_{1}\) score of a classifier \(h\) are defined as

\[p\triangleq\mathbb{P}(Y=1\mid h(X)=1)=\tfrac{\mathbb{P}(h(X)=1,Y= 1)}{\mathbb{P}(h(X)=1)},\;\;r\triangleq\mathbb{P}(h(X)=1\mid Y=1)=\tfrac{ \mathbb{P}(h(X)=1,Y=1)}{\mathbb{P}(Y=1)},\] \[F\triangleq\tfrac{2}{r^{-1}+p^{-1}}=\tfrac{2\mathbb{P}(h(X)=1,Y= 1)}{\mathbb{P}(h(X)=1)+\mathbb{P}(Y=1)}\,.\]

The quantities \(\mathbb{P}(h(X)=1)\) and \(\mathbb{P}(Y=1)\) in the above definitions are identified, since the marginals \(P_{X,Z}\) and \(P_{Y,Z}\) are specified in the Frechet problem in (1.1). The \(\mathbb{P}(h(X)=1)\) can be estimated from the full dataset \(\{(X_{i},Z_{i})\}_{i=1}^{m}\) simply using \(\hat{\mathbb{P}}(h(X)=1)\triangleq\tfrac{1}{m}\sum_{i=1}^{m}\mathds{1}[h(X_{ i})=1]\). On the other hand, in most weak supervision applications, \(\mathbb{P}(Y=1)\) is assumed to be known from some prior knowledge or can be estimated from an auxiliary dataset, _e.g._, using the method described in the appendix of Ratner et al. [49]. Estimating or knowing \(\mathbb{P}(Y=1)\) is required to fit the label model [49, 22] in the first place, so it is beyond our scope of discussion. Then, we assume we have an accurate estimate \(\hat{\mathbb{P}}(Y=1)\).

The probability \(\mathbb{P}(h(X)=1,Y=1)\), which is the final ingredient in the definition of precision, recall, and F1 score is not identifiable as \(P_{X,Y}\) is unknown. The uncertainty bounds for this quantity can be estimated using our method simply by letting \(g(x,y,z)=\mathds{1}[h(x)=1\text{ and }y=1]\). Let \(\hat{L}_{\varepsilon}\) and \(\hat{U}_{\varepsilon}\) denote the estimated lower and upper bounds for \(\mathbb{P}(h(X)=1,Y=1)\) obtained using (2.3). Naturally, the lower bound estimators for precision, recall, and \(F_{1}\) score are

\[\hat{p}_{l,\varepsilon}\triangleq\tfrac{\hat{L}_{\varepsilon}}{\mathbb{P}(h(X )=1)},\;\hat{r}_{l,\varepsilon}\triangleq\tfrac{\hat{L}_{\varepsilon}}{ \mathbb{P}(Y=1)},\text{ and }\hat{F}_{l,\varepsilon}\triangleq\tfrac{2\hat{L}_{ \varepsilon}}{\mathbb{P}(h(X)=1)+\mathbb{P}(Y=1)}\,,\]

while the upper bound estimators \(\hat{p}_{u,\varepsilon}\), \(\hat{r}_{u,\varepsilon}\), and \(\hat{F}_{u,\varepsilon}\) are given by substituting \(\hat{L}_{\varepsilon}\) by \(\hat{U}_{\varepsilon}\) above. In the following corollary, we show that the bounds converge asymptotically to normal distributions, which we use for calculating their coverage bounds presented in our applications.

**Corollary 3.1**.: _Let \(n\) be a function of \(m\) such that \(n\to\infty\) and \(n=o\left(m^{(2\lambda)\wedge 1}\right)\) when \(m\to\infty\). Assume the conditions of Theorem 2.5 hold. Then as \(m\to\infty\)_

\[\circ\sqrt{n}\big{(}\hat{p}_{l,\varepsilon}-p_{l,\varepsilon}\big{)} \Rightarrow N(0,\sigma_{p,l,\varepsilon}^{2})\text{ with }p_{l,\varepsilon}=\tfrac{L_{\varepsilon}}{\mathbb{P}(h(X)=1)},\; \sigma_{p,l,\varepsilon}^{2}\triangleq\tfrac{\sigma_{l,\varepsilon}^{2}}{ \mathbb{P}(h(X)=1)^{2}},\] \[\circ\sqrt{n}\big{(}\hat{r}_{l,\varepsilon}-r_{l,\varepsilon} \big{)}\Rightarrow N(0,\sigma_{r,l,\varepsilon}^{2})\text{ with }r_{l,\varepsilon}=\tfrac{L_{\varepsilon}}{\mathbb{P}(Y=1)},\;\sigma_{r,l}^{2} \triangleq\tfrac{\sigma_{l,\varepsilon}^{2}}{\mathbb{P}(Y=1)^{2}},\] \[\circ\sqrt{n}\big{(}\hat{F}_{l,\varepsilon}-F_{l,\varepsilon} \big{)}\Rightarrow N(0,\sigma_{F,l,\varepsilon}^{2})\text{ with }F_{l,\varepsilon}=\tfrac{2L_{\varepsilon}}{\mathbb{P}(h(X)=1)+\mathbb{P}(Y=1)} \;\&\;\sigma_{F,l,\varepsilon}^{2}\triangleq\tfrac{4\sigma_{l,\varepsilon}^{2} }{[\mathbb{P}(h(X)=1)+\mathbb{P}(Y=1)]^{2}},\]

_where \(L_{\varepsilon}\), \(\sigma_{l,\varepsilon}^{2}\) are defined in Theorem 2.5. Asymptotic distributions for \(\sqrt{n}\big{(}\hat{p}_{u,\varepsilon}-p_{u,\varepsilon}\big{)}\), \(\sqrt{n}\big{(}\hat{r}_{u,\varepsilon}-r_{u,\varepsilon}\big{)}\), and \(\sqrt{n}\big{(}\hat{F}_{u,\varepsilon}-F_{u,\varepsilon}\big{)}\) are obtained in a similar way by changing \(L_{\varepsilon}\) to \(U_{\varepsilon}\) and \(\sigma_{l,\varepsilon}^{2}\) to \(\sigma_{u,\varepsilon}^{2}\)._

Reiterating our discussion in the final paragraph in Section 2.2, asymptotic distributions are important for constructing confidence intervals for the bounds, which can be done in a similar manner.

## 4 Experiments

All experiments are structured to emulate conditions where high-quality labels are inaccessible during training, validation, and testing phases, and all weakly-supervised classifiers are trained using the noise-aware loss [50]. To fit the label models, we assume \(P_{Y}\) is known (computed using the training set). Unless stated, we use \(l_{2}\)-regularized logistic regressors as classifiers, where the regularization strength is determined according to the validation noise-aware loss.

**Wrench datasets:** To carry out realistic experiments within the weak supervision setup and study accuracy/F1 score estimation, we utilize datasets incorporated in Wrench (**W**eak Supervision **B**enchmark) [63]. This standardized benchmark platform features real-world datasets and pre-generated weak labels for evaluating weak supervision methodologies. Most of Wrench's datasets are designed for classification tasks, encompassing diverse data types such as tabular, text, and image; all contain their pre-computed weak labels. Specifically, we utilize Census [27], YouTube [1], SMS [2], IMDB [37], Yelp [65], AGNews [65], TREC [31], Spouse [12], SemEval [24], CDR [14], ChemProt [29], Commercial [22], Tennis Rally [22], Basketball [22]. For text datasets, weemploy the paraphrase-MiniLM-L6-v2 model from the _sentence-transformers_6 library for feature extraction [51]. Features were extracted for the image datasets before their inclusion in Wrench.

Footnote 6: Accessible at https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L6-v2.

**Hate Speech Dataset [15]:** This dataset contains sentence-level annotations for hate speech in English, sourced from posts from white supremacy forums. It encompasses thousands of sentences classified into either Hate (1) or noHate (0) categories. This dataset provides an ideal ground for examining recall and precision estimation. Social media moderators aim to maximize the filtering of hate posts, _i.e._, increasing recall, while ensuring that non-hate content is rarely misclassified as offensive, maintaining high precision. Analogously to the Wrench text datasets, we utilize paraphrase-MiniLM-L6-v2 for feature extraction.

### Bounding the performance of weakly supervised classifiers

In this section, we conduct an empirical study using some of the Wrench and Hate Speech datasets to verify the validity and usefulness of our methodology. We compare results for which \(P_{Y|Z}\) is estimated using the true labels \(Y\) ("Oracle") and those derived using Snorkel's [48, 47] default label model with no hyperparameter tuning and a thousand epochs. Such a comparison facilitates an evaluation of our method's efficacy, especially in cases where the label model could be incorrectly specified. Results for other Wrench datasets and one extra label model (FlyingSquid, [22]) are presented in Appendix F.

In Figure 1, we demonstrate our approaches for bounding test metrics, such as accuracy and F1 score (shown in green), when no true labels are available to estimate performance at various classification thresholds for binary classification tasks on Wrench datasets. In the first row ("Oracle"), true labels are used to estimate the conditional distribution \(P_{Y|Z}\), representing a (close to) ideal scenario with a well-specified label model. In the second row ("Snorkel"), however, we use a label model to estimate \(P_{Y|Z}\) without relying on any true labels. Despite potential inaccuracies in Snorkel's label model, it achieves results close to those obtained using true labels to estimate \(P_{Y|Z}\), yielding approximate but useful bounds. This indicates that even if Snorkel's label model is imperfectly specified, its effectiveness in estimating bounds remains similar to that of the "Oracle" approach, underscoring the value of bounding metrics regardless of label model accuracy. Delving deeper into Figure 1, results for "youtube", "commercial", and "tennis" highlight that our uncertainty about out-of-sample performance is small, even without labeled samples. However, there is a noticeable increase in uncertainty for "imdb" and "cdr", making weakly supervised models de

\begin{table}
\begin{tabular}{c|c c c c} \hline \hline Dataset & Lab model & Lo. bound & Up. bound & Test acc \\ \hline \multirow{3}{*}{agnews} & Oracle & \(0.46_{\pm 0.01}\) & \(0.95_{\pm 0.01}\) & \(0.80_{\pm 0.01}\) \\  & Snorkel & \(0.42_{\pm 0.01}\) & \(0.9_{\pm 0.01}\) & \(0.76_{\pm 0.01}\) \\ \hline \multirow{3}{*}{sremoval} & Oracle & \(0.54_{\pm 0.04}\) & \(0.78_{\pm 0.03}\) & \(0.72_{\pm 0.04}\) \\  & Snorkel & \(0.36_{\pm 0.03}\) & \(0.70_{\pm 0.03}\) & \(0.56_{\pm 0.04}\) \\ \hline \hline \end{tabular}
\end{table}
Table 1: Bounding accuracy in multinomial classification.

Figure 1: We apply our method to bound test metrics such as accuracy and F1 score (in green) when no true labels are used to estimate performance. In the first row (“Oracle”), we use true labels to estimate the conditional distribution \(P_{Y|Z}\), thus approximating a scenario in which the label model is reasonably specified. On the second row (“Snorkel”), we use a label model to estimate \(P_{Y|Z}\) without access to any true labels. Despite potential misspecification in Snorkel’s label model, it performs comparably to using labels to estimate \(P_{Y|Z}\), giving approximate but meaningful bounds.

additional validation. Yet, the bounds retain their informative nature. For instance, for those willing to accept the risk, the "imdb" classifier's ideal threshold stands at \(.5\). This is deduced from the flat worst-case and peaking best-case accuracy at this threshold. Table 1 presents some results for "agnews" (4 classes) and "semeval" (9 classes). From Table 1, we can see that both "Oracle" and "Snorkel" approaches produce valid bounds.

Now, we present bounds on the classifiers' precision and recall across different classification thresholds for the hate speech dataset. This dataset did not provide weak labels, so we needed to generate them. We employed four distinct weak labelers. The initial weak labeler functions are based on keywords and terms. Should words or phrases match those identified as hate speech in the lexicon created by Davidson et al. [13], we categorize the sentence as \(1\); if not, it's designated \(0\). The second weak labeler is based on TextBlob's sentiment analyzer [36]: a negative text polarity results in a \(1\) classification, while other cases are labeled \(0\). Our final pair of weak labelers are language models, specifically BERT [16] and RoBERTa [34], that have undergone fine-tuning for detecting toxic language or hate speech [35; 28]. Figure 2 presents both recall and precision bounds and test estimates for the weakly-supervised hate speech classifier. Mirroring observations from Figure 1, Snorkel's standard label model gives valuable bounds analogous to scenarios where we employ labels to estimate \(P_{Y|Z}\). If used by practitioners, Figure 2 could help trade-off recall and precision by choosing an appropriate classification threshold in the absence of high-quality labels.

### Choosing a set of weak labels

In this experiment, we examine how our approach performs under the influence of highly informative weak labels as opposed to scenarios with less informative weak labels. Using the YouTube dataset provided by Wrench, we attempt to classify YouTube comments into categories of SPAM or HAM, leveraging Snorkel to estimate \(P_{Y|Z}\). Inspired by Smith et al. [59], we craft three few-shot weak labelers by prompting7 the large language model (LLM) Llama-2-13b-chat-hf[60]. For each dataset entry, we pose three distinct queries to the LLM. Initially, we inquire if the comment is SPAM or HAM. Next, we provide clear definitions of SPAM and HAM, then seek the classification from LLM. In the third prompt, leveraging in-context learning ideas [17], we provide five representative comments labeled as SPAM/HAM prior to requesting the LLM's verdict on the comment in question. In cases where LLM's response diverges from SPAM or HAM, we interpret it as LLM's abstention.

Footnote 7: More details regarding the prompts can be found in Appendix G.1.

After obtaining this triad of weak labels, we analyze two situations. Initially, we integrate the top five8 weak labels ("high-quality" labels) from Wrench. In the subsequent scenario, we synthetically generate weak labels ("low-quality" labels) that do not correlate with \(Y\). The first plot in Figure 3 depicts the bounds of our classifier based solely on weak few-shot labels, which unfortunately do not provide substantial insights. Enhancing the bounds requires the inclusion of additional weak labels. Yet, as indicated by the subsequent pair of plots, it becomes evident that only the incorporation of "high-quality" weak labels results in significant shrinkage and upward shift of the bounds. As confirmed by the test accuracy, if a practitioner had used our method to select the set of weak labels, that would have led to a significant boost in performance.

Footnote 8: The most informative weak labels are determined based on their alignment with the true label.

### Model selection strategies using the Frechet bounds

In Sections 4.1 and 4.2, we implicitly touched on the topic of model selection when discussing the classification threshold and weak label selection. Here, we explicitly discuss the use of our Frechet bounds for model selection purposes. Consider a set of possible models \(\mathcal{H}\triangleq\{h_{1},\cdots,h_{K}\}\) from which we wish to find the best model according to a specific metric, _e.g._, accuracy, or F1 score. We consider three approaches for model selection using the Frechet bounds: choosing the model with the best possible (i) lower bound, (ii) upper bound, and (iii) average of lower and upper bounds on the metric of interest. Strategy (i) works well for the worst-case scenario and can be seen as the

Figure 2: Precision and recall bounds for hate speech detection.

distributionally robust optimization (DRO) [9] solution when the uncertainty set is given by \(\Pi\) in (1.1), while (ii) is suitable for an optimistic scenario, and (iii) is suggested when one wants to balance between the worst- and best-case scenarios. Please check Appendix E for more details.

In this experiment, we select multilayer-perceptrons (MLPs). The considered MLPs have one hidden layer with a possible number of neurons in \(\{50,100\}\). Training is carried out with Adam [26], with possible learning rates in \(\{.1,.001\}\) and weight decay (\(l_{2}\) regularization parameter) in \(\{.1,.001\}\). For those datasets that use the F1 score as the evaluation metric, we also tune the classification threshold in \(\{.2,.4,.5,.6,.8\}\) (otherwise, they return the most probable class as a prediction). In total, \(\mathcal{H}\) is composed of \(8\) trained models when evaluating accuracy and \(40\) models when evaluating the F1 score. We also consider directly using the label model (Snorkel [47]) to select models. For example, when the metric considered is accuracy, _i.e._, we use select the model \(\arg\max_{h_{k}\in\mathcal{H}}\frac{1}{n}\sum_{i=1}^{n}\mathds{E}_{\hat{P}_{Y |Z}}\mathds{1}[h_{k}(X)=Y\mid Z=Z_{i}]\), which is a natural choice when \(X\perp\!\!\!\perp Y\mid Z\). As baselines, we consider having a few labeled samples.

In Table 2, we report a subset of our results (please check Appendix E for the full set of results). In this table, we report the average test scores of the chosen models over \(10\) repetitions for different random seeds (standard deviation report as subscript). We can extract some lessons from the table. First, using metrics derived from the Frechet bounds is most useful when our uncertainty about the model performance is low, _e.g._, "'commercial" and "tennis" in Figure 1. In those cases, using our metrics for model selection gives better results even when compared to a labeled validation set of size \(n=100\). Moreover, once the practitioner knows that the uncertainty is low, using the label model approach also does well.

## 5 Discussion

### Extensions

An extension we do not address in the main text is the evaluation of end-to-end weak supervision methods [62; 56; 52], where the separation between the label model and the final predictor is less clear than in our primary setting. Our approach remains compatible with these methods as long as we can fit a label model (_e.g._, Snorkel) separately and utilize it solely for the evaluation step. Another possible extension is the application of the ideas presented in this work in different fields of machine learning or statistics. One could consider applying our ideas to the problem of "statistical matching" (SM) [18; 10; 19; 30; 11], for example. The classic formulation of SM involves observing two distinct datasets that contain replications of \((X,Z)\) and \((Y,Z)\), but the triplet \((X,Y,Z)\) is never observed. The primary goal is to make inferences about the relationship between \(X\) and \(Y\). For instance, if our focus is on bounding \(\mathbb{P}((X,Y)\in B)=\mathbb{E}[\mathds{1}_{B}(X,Y)]\) for a certain event \(B\), we could define \(g(x,y,z)=\mathds{1}_{B}(x,y)\) and apply our method.

\begin{table}
\begin{tabular}{c c|c c c|c} \hline \hline  & metric & Lowr bound & Bounds avg & Label model & Label (\(n=100\)) \\ \hline apnews & acc & \(0.77_{\pm 0.00}\) & \(0.78_{\pm 0.00}\) & \(0.77_{\pm 0.00}\) & \(0.77_{\pm 0.00}\) \\ imdb & acc & \(0.72_{\pm 0.00}\) & \(0.73_{\pm 0.00}\) & \(0.73_{\pm 0.00}\) & \(0.72_{\pm 0.01}\) \\ \hline yely & acc & \(0.81_{\pm 0.00}\) & \(0.81_{\pm 0.00}\) & \(0.81_{\pm 0.00}\) & \(0.82_{\pm 0.01}\) \\ tennis & F1 & \(0.76_{\pm 0.01}\) & \(0.76_{\pm 0.01}\) & \(0.75_{\pm 0.01}\) & \(0.71_{\pm 0.02}\) \\ \hline commercial & F1 & \(0.96_{\pm 0.00}\) & \(0.96_{\pm 0.00}\) & \(0.96_{\pm 0.00}\) & \(0.91_{\pm 0.01}\) \\ \hline \hline \end{tabular}
\end{table}
Table 2: Performance of selected models

Figure 3: Performance bounds for classifiers on the YouTube dataset, initially relying solely on few-shot weak labels obtained via prompts to the LLM L1ama-2-13b-chat-hf. The progression of plots illustrates the comparative impact of integrating “high-quality” labels from Wrench versus synthetically generated “low-quality” labels. Evidently, the addition of “high-quality” labels significantly enhances the bounds, underscoring their superior utility over “low-quality” labels for optimal classification of SPAM and HAM comments.

### Limitations

We discuss some limitations of our methods. Firstly, our method and theoretical results are only applicable to cases where \(\mathcal{Y}\) and \(\mathcal{Z}\) are finite sets, such as in classification problems. Extending the dual formulation in Theorem 2.1 to general \(\mathcal{Y}\) and \(\mathcal{Z}\) is possible but would require optimizing over function spaces, which is computationally and theoretically challenging. Additionally, if \(|\mathcal{Z}|\) is large, convergence may be slow, necessitating a large unlabeled dataset for accurate bounds. Using a smaller, curated set of weak labels, may be more effective for bounds estimation and performance. We end this subsection with two other limitations related to misspecification in the label model and informativeness of the bounds. The proofs of the results introduced in this section are placed in Appendix D.

**Label model misspecification:** In our asymptotic results we assumed that the label models are well-specified, _i.e._, the estimates \(\{\hat{P}_{Y|Z}^{(m)},m\in\mathbb{N}\}\) converge to the true label model \(P_{Y|Z}\) at \(m\to\infty\). To understand the qualities of our bound when this assumption is violated, we introduce the misspecification: \(\hat{P}_{Y|Z}^{(m)}\to Q_{Y|Z}\) and \(Q_{Y|Z}\neq P_{Y|Z}\). In our investigation on the misspecification of the label model, we control the level of misspecification as \(d_{\mathrm{TV}}(Q_{Y|Z=z},P_{Y|Z=z})\leq\delta\) and then study the subsequent errors in our Frechet bounds. The following theorem formalizes the result.

**Theorem 5.1**.: _Recall from equation (2.2) that \(L_{\epsilon}\) and \(U_{\epsilon}\) are the smoothened upper and lower Frechet bounds with the true \(P_{Y|Z=z}\). Additionally, let us define similar \(\hat{L}_{\epsilon}\) and \(\hat{U}_{\epsilon}\) bounds, but with a misspecified \(Q_{Y|Z=z}\), i.e._

\[\begin{split}&\hat{L}_{\epsilon}\triangleq\sup_{\alpha\in \mathcal{A}}\mathbb{E}[\hat{f}_{l,\varepsilon}(X,Z,a)]\ \ \text{and}\ \ \hat{U}_{\epsilon}\triangleq\inf_{a\in\mathcal{A}}\mathbb{E}[\hat{f}_{u, \varepsilon}(X,Z,a)]\,,\\ &\hat{f}_{l,\varepsilon}(x,z,a)\triangleq-\varepsilon\log\left[ \frac{1}{|\mathcal{Y}|}\sum_{y\in\mathcal{Y}}\exp\left(\frac{g(x,y,z)+a_{yz}} {-\varepsilon}\right)\right]-\mathbb{E}_{Q_{Y|Z}}\left[a_{Yz}\mid Z=z\right] \\ &\hat{f}_{u,\varepsilon}(x,z,a)\triangleq\ \varepsilon\log\left[\frac{1}{| \mathcal{Y}|}\sum_{y\in\mathcal{Y}}\exp\left(\frac{g(x,y,z)+a_{yz}}{ \varepsilon}\right)\right]-\mathbb{E}_{Q_{Y|Z}}\left[a_{Yz}\mid Z=z\right] \end{split}\] (5.1)

_Assume \(Q_{Y|Z}\) is in a set of conditional distributions such that the optimizers for (5.1), which are assumed to exist, are uniformly bounded. If \(d_{\mathrm{TV}}\big{(}Q_{Y|Z=z},P_{Y|Z=z}\big{)}\leq\delta\), then for some \(C>0\) which is independent of \(\delta>0\), we have_

\[\max\big{(}|\hat{L}_{\epsilon}-L_{\epsilon}|,|\hat{U}_{\epsilon}-U_{\epsilon}| \big{)}\leq C\delta\,.\] (5.2)

The above theorem reveals how misspecification translates to the errors in subsequent Frechet bounds. In an ideal scenario, with access to an \(\{(Y_{i},Z_{i})\}_{i=1}^{m}\) sample we can consistently estimate \(P_{Y|Z}\), leading to \(\delta=0\). In situations when this \(\{(Y_{i},Z_{i})\}_{i=1}^{m}\) sample is not accessible and we have to rely on a label model, we require the misspecification in this model to be small.

**Informativeness of the bounds:** The bounds \(L\) and \(U\) are especially useful when their difference \(U-L\) is small because in that case, we obtain a tight bound for \(\mathbb{E}[g(X,Y,Z)]\) and narrow it down with high precision even if the joint random vector \((X,Y,Z)\) is never observed. But when is this bound small? In the next theorem, we provide an upper bound on this difference.

**Theorem 5.2**.: _Let \(L\) and \(U\) be defined as in equation (1.1). Then_

\[U-L\leq\sqrt{8\left\|g\right\|_{\infty}^{2}\min\{H(X\mid Z),H(Y\mid Z)\}}\]

_where \(H(X\mid Z)\) (resp. \(H(Y\mid Z)\)) denotes the conditional entropy of \(X\) (resp. \(Y\)) given \(Z\)._

To understand the result better, recall our setting: we do not observe the joint distribution \(P_{X,Y,Z}\) and only observe the marginals \(P_{Y,Z}\) and \(P_{X,Z}\). The only way we can infer about the joint distribution is by connecting these two marginals through \(Z\). So, readers can guess that it is more favorable when \(Z\) is informative for either \(X\) or \(Y\). For example, take the extreme case when \(Y=h(Z)\) for a function \(h:\mathcal{Y}\to\mathcal{Z}\). In this case the \(P_{X,Y,Z}=P_{X,g(Z),Z}\) is precisely known from the \(P_{X,Z}\) and we can exactly pinpoint the \(\mathbb{E}[g(X,Y,Z)]\) as \(\mathbb{E}[g(X,h(Z),Z)]\). In this case, \(H(Y\mid Z)=0\), leading to \(U-L=0\), _i.e._, its Frechet bounds can precisely pinpoint it as well; ideally at least one of the \(H(X\mid Z)\) and \(H(Y\mid Z)\) is small.

## 6 Acknowledgements

This paper is based upon work supported by the National Science Foundation (NSF) under grants no. 1916271, 2027737, 2113373, and 2113364.

## References

* [1] T.C. Alberto and J.V. Lochter (2015) YouTube Spam Collection. UCI Machine Learning Repository. Note: DOI: https://doi.org/10.24432/C58885 Cited by: SS1.
* [2]T. Almeida and J. Hidalgo (2011) SMS Spam Collection. UCI Machine Learning Repository. Note: DOI: https://doi.org/10.24432/C5CC84 Cited by: SS1.
* [3]D. An, N. Lei, X. Xu, and X. Gu (2022) Efficient optimal transport algorithm by accelerated gradient descent. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 36, pp. 10119-10128. Cited by: SS1.
* [4]C. Arachie and B. Huang (2019) Adversarial label learning. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33, pp. 3183-3190. Cited by: SS1.
* [5]C. Arachie and B. Huang (2021) A general framework for adversarial label learning. J. Mach. Learn. Res.22, pp. 118-1. Cited by: SS1.
* [6]A. Asl and M. L. Overton (2021) Behavior of limited memory bfgs when applied to nonsmooth functions and their nesterov smoothings. In Numerical Analysis and Optimization: NAO-V, Muscat, Oman, January 2020 V, pp. 25-55. Cited by: SS1.
* [7]D. Bartl, M. Kupper, T. Lux, A. Papapantoleon, and S. Eckstein (2022) Marginal and dependence uncertainty: bounds, optimal transport, and sharpness. SIAM Journal on Control and Optimization60 (1), pp. 410-434. Cited by: SS1.
* [8]M. Beiglbock and W. Schachermayer (2011) Duality for borel measurable cost functions. Transactions of the American Mathematical Society363 (8), pp. 4203-4224. Cited by: SS1.
* [9]R. Chen, I. Ch Paschalidis, et al. (2020) Distributionally robust learning. Foundations and Trends(r) in Optimization4 (1-2), pp. 1-243. Cited by: SS1.
* [10]P. Luigi Conti, D. Marella, and M. Scanu (2016) Statistical matching analysis for complex survey data with applications. Journal of the American Statistical Association111 (516), pp. 1715-1725. Cited by: SS1.
* [11]P. Luigi Conti, D. Marella, and M. Scanu (2019) An overview on uncertainty and estimation in statistical matching. Analysis of Integrated Data, pp. 73-100. Cited by: SS1.
* [12]D. PA Corney, D. Albakour, M. Martinez-Alvarez, and S. Moussa (2016) What do a million news articles look like?. In NewsIR@ ECIR, pp. 42-47. Cited by: SS1.
* [13]T. Davidson, D. Warmsley, M. Macy, and I. Weber (2017) Automated hate speech detection and the problem of offensive language. In Proceedings of the international AAAI conference on web and social media, Vol. 11, pp. 512-515. Cited by: SS1.
* [14]A. P. Davis, C. J. Grondin, R. J. Johnson, D. Sciaky, B. L. King, R. McMorran, J. Wiegers, T. C. Wiegers, and C. J. Mattingly (2017) The comparative toxicogenomics database: update 2017. Nucleic acids research45 (D1), pp. D972-D978. Cited by: SS1.
* [15]O. de Gibert, N. Perez, A. Garcia-Pablos, and M. Cuadros (2018-06) Hate Speech Dataset from a White Supremacy Forum. In Proceedings of the 2nd Workshop on Abusive Language Online (ALW2), Brussels, Belgium, October 2018, pp. 11-20. External Links: Link Cited by: SS1.
* [16]J. Devlin (2018) Bert: pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805. Cited by: SS1.
* [17]Q. Dong, L. Li, D. Dai, C. Zheng, Z. Wu, B. Chang, X. Sun, J. Xu, and Z. Sui (2022) A survey for in-context learning. arXiv preprint arXiv:2301.00234. Cited by: SS1.
* [18]M. D'Orazio, M. Di Zio, and M. Scanu (2006) Statistical matching: theory and practice. John Wiley & Sons. Cited by: SS1.
* [19]M. D. D'Orazio, M. Di Zio, and M. Scanu (2006) Statistical matching: theory and practice. John Wiley & Sons. Cited by: SS1.
* [20]M. D. D'Orazio, M. Di Zio, and M. Scanu (2006) Statistical matching: theory and practice. John Wiley & Sons. Cited by: SS1.
* [21]M. D. D'Orazio, M. Di Zio, and M. Scanu (2006) Statistical matching: theory and practice. John Wiley & Sons. Cited by: SS1.
* [22]M. D. D'Orazio, M. Di Zio, and M. Scanu (2006) Statistical matching: theory and practice. John Wiley & Sons. Cited by: SS1.
* [23]M. D. D'Orazio, M. Di Zio, and M. Scanu (2006) Statistical matching: theory and practice. John Wiley & Sons. Cited by: SS1.
* [24]M. D. D'Orazio, M. Di Zio, and M. Scanu (2006) Statistical matching: theory and practice. John Wiley & Sons. Cited by: SS1.
* [25]M. D. D'Orazio, M. Di Zio, and M. Scanu (2006) Statistical matching: theory and practice. John Wiley & Sons. Cited by: SS1.
* [26]M. D. D'Orazio, M. Di Zio, and M. Scanu (2006) Statistical matching: theory and practice. John Wiley & Sons. Cited by: SS1.
* [27]M. D. D'Orazio, M. Di Zio, and M. Scanu (2006) Statistical matching: theory and practice. John Wiley & Sons. Cited by: SS1.
* [28]M. D. D'Orazio, M. Di Zio, and M. Scanu (2006) Statistical matching: theory and practice. John Wiley & Sons. Cited by: SS1.
* [29]M. D. D'Orazio, M. Di Zio, and M. Scanu (2006) Statistical matching: theory and practice. John Wiley & Sons. Cited by: SS1.
* [30]M. D. D'Orazio, M. Di Zio, and M. Scanu (2006) Statistical matching: theory and practice. John Wiley & Sons. Cited by: SS1.
* [31]M. D. D'Orazio, M. Di Zio, and M. Scanu (2006) Statistical matching: theory and practice. John Wiley & Sons. Cited by: SS1.
* [32]M. D. D'Orazio, M. Di Zio, and M. Scanu (2006) Statistical matching: theory and practice. John Wiley & Sons. Cited by: SS1.
* [33]M. D. D'Orazio, M. D. D'Orazio, M. D. D'Orazio, M. D. D'Orazio, M.

* D'Orazio [2019] Marcello D'Orazio. Statistical learning in official statistics: the case of statistical matching. _Statistical Journal of the IAOS_, 35(3):435-441, 2019.
* Fogliato et al. [2020] Riccardo Fogliato, Alexandra Chouldechova, and Max G'Sell. Fairness evaluation in presence of biased noisy labels. In _International conference on artificial intelligence and statistics_, pages 2325-2336. PMLR, 2020.
* Fries et al. [2021] Jason A Fries, Ethan Steinberg, Saelig Khattar, Scott L Fleming, Jose Posada, Alison Callahan, and Nigam H Shah. Ontology-driven weak supervision for clinical entity classification in electronic health records. _Nature communications_, 12(1):2017, 2021.
* Fu et al. [2020] Daniel Fu, Mayee Chen, Frederic Sala, Sarah Hooper, Kayvon Fatahalian, and Christopher Re. Fast and three-rious: Speeding up weak supervision with triplet methods. In _International conference on machine learning_, pages 3280-3291. PMLR, 2020.
* Guo et al. [2022] Wenshuo Guo, Mingzhang Yin, Yixin Wang, and Michael Jordan. Partial identification with noisy covariates: A robust optimization approach. In _Conference on Causal Learning and Reasoning_, pages 318-335. PMLR, 2022.
* Hendrickx et al. [2010] Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva, Preslav Nakov, Diarmuid O Seaghdha, Sebastian Pado, Marco Pennacchiotti, Lorenza Romano, and Stan Szpakowicz. SemEval-2010 task 8: Multi-way classification of semantic relations between pairs of nominals. In Katrin Erk and Carlo Strapparava, editors, _Proceedings of the 5th International Workshop on Semantic Evaluation_, pages 33-38, Uppsala, Sweden, July 2010. Association for Computational Linguistics. URL https://aclanthology.org/S10-1006.
* Kallus [2022] Nathan Kallus. What's the harm? sharp bounds on the fraction negatively affected by treatment. _Advances in Neural Information Processing Systems_, 35:15996-16009, 2022.
* Kingma and Ba [2014] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. _arXiv preprint arXiv:1412.6980_, 2014.
* Kohavi [1996] Ron Kohavi. Census Income. UCI Machine Learning Repository, 1996. DOI: https://doi.org/10.24432/C5GP7S.
* Novak et al. [2022] Petra Kralj Novak, Teresa Scantamburlo, Andraz Pelicon, Matteo Cinelli, Igor Mozetic, and Fabiana Zollo. Handling disagreement in hate speech modelling. In _International Conference on Information Processing and Management of Uncertainty in Knowledge-Based Systems_, pages 681-695. Springer, 2022.
* Krallinger et al. [2017] Martin Krallinger, Obdulia Rabal, Saber A Akhondi, Martun Perez Perez, Jesus Santamaria, Gael Perez Rodriguez, Georgios Tsatsaronis, Ander Intxaurrondo, Jose Antonio Lopez, Umesh Nandal, et al. Overview of the biocreative vi chemical-protein interaction track. In _Proceedings of the sixth BioCreative challenge evaluation workshop_, volume 1, pages 141-146, 2017.
* Lewaa et al. [2021] Israa Lewaa, Mai Sherif Hafez, and Mohamed Ali Ismail. Data integration using statistical matching techniques: A review. _Statistical Journal of the IAOS_, 37(4):1391-1410, 2021.
* Li and Roth [2002] Xin Li and Dan Roth. Learning question classifiers. In _COLING 2002: The 19th International Conference on Computational Linguistics_, 2002.
* Lison et al. [2020] Pierre Lison, Aliaksandr Hubin, Jeremy Barnes, and Samia Touileb. Named entity recognition without labelled data: A weak supervision approach. _arXiv preprint arXiv:2004.14723_, 2020.
* Liu and Nocedal [1989] Dong C Liu and Jorge Nocedal. On the limited memory bfgs method for large scale optimization. _Mathematical programming_, 45(1-3):503-528, 1989.
* Liu [2019] Yinhan Liu. Roberta: A robustly optimized bert pretraining approach. _arXiv preprint arXiv:1907.11692_, 2019.
* Logacheva et al. [2022] Varvara Logacheva, Daryna Dementieva, Sergey Ustyantsev, Daniil Moskovskiy, David Dale, Irina Krotova, Nikita Semenov, and Alexander Panchenko. ParaDetox: Detoxification with parallel data. In _Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pages 6804-6818, Dublin, Ireland, May 2022. Association for Computational Linguistics. URL https://aclanthology.org/2022.acl-long.469.

* [36] Steven Loria et al. textblob documentation. _Release 0.15_, 2(8):269, 2018.
* Volume 1_, HLT '11, page 142-150, USA, 2011. Association for Computational Linguistics. ISBN 9781932432879.
* [38] Charles F Manski. Anatomy of the selection problem. _Journal of Human resources_, pages 343-360, 1989.
* [39] Charles F Manski. Nonparametric bounds on treatment effects. _The American Economic Review_, 80(2):319-323, 1990.
* [40] Charles F Manski. _Partial identification of probability distributions_, volume 5. Springer, 2003.
* [41] Alessio Mazzetto, Cyrus Cousins, Dylan Sam, Stephen H Bach, and Eli Upfal. Adversarial multi class learning under weak supervision with performance guarantees. In _International Conference on Machine Learning_, pages 7534-7543. PMLR, 2021.
* [42] Alessio Mazzetto, Dylan Sam, Andrew Park, Eli Upfal, and Stephen Bach. Semi-supervised aggregation of dependent weak supervision sources with performance guarantees. In _International Conference on Artificial Intelligence and Statistics_, pages 3196-3204. PMLR, 2021.
* [43] Francesca Molinari. Microeconometrics with partial identification. _Handbook of econometrics_, 7:355-486, 2020.
* [44] Wojciech Niemiro. Asymptotics for m-estimators defined by convex minimization. _The Annals of Statistics_, pages 1514-1533, 1992.
* [45] Gabriel Peyre, Marco Cuturi, et al. Computational optimal transport: With applications to data science. _Foundations and Trends(r) in Machine Learning_, 11(5-6):355-607, 2019.
* [46] Flavien Prost, Pranjal Awasthi, Nick Blumm, Aditee Kumthekar, Trevor Potter, Li Wei, Xuezhi Wang, Ed H Chi, Jilin Chen, and Alex Beutel. Measuring model fairness under noisy covariates: A theoretical perspective. In _Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society_, pages 873-883, 2021.
* [47] Alex Ratner, Braden Hancock, Jared Dunnmon, Roger Goldman, and Christopher Re. Snorkel metal: Weak supervision for multi-task learning. In _Proceedings of the Second Workshop on Data Management for End-To-End Machine Learning_, pages 1-4, 2018.
* [48] Alexander Ratner, Stephen H Bach, Henry Ehrenberg, Jason Fries, Sen Wu, and Christopher Re. Snorkel: Rapid training data creation with weak supervision. In _Proceedings of the VLDB Endowment. International Conference on Very Large Data Bases_, volume 11, page 269. NIH Public Access, 2017.
* [49] Alexander Ratner, Braden Hancock, Jared Dunnmon, Frederic Sala, Shreyash Pandey, and Christopher Re. Training complex models with multi-task weak supervision. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 33, pages 4763-4771, 2019.
* [50] Alexander J Ratner, Christopher M De Sa, Sen Wu, Daniel Selsam, and Christopher Re. Data programming: Creating large training sets, quickly. _Advances in neural information processing systems_, 29, 2016.
* [51] Nils Reimers and Iryna Gurevych. Sentence-bert: Sentence embeddings using siamese bert-networks. In _Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing_. Association for Computational Linguistics, 2019.
* [52] Salva Ruhling Cachay, Benedikt Boecking, and Artur Dubrawski. End-to-end weak supervision. _Advances in Neural Information Processing Systems_, 34:1845-1857, 2021.
* [53] Ludger Ruschendorf. Bounds for distributions with multivariate marginals. _Lecture Notes-Monograph Series_, pages 285-310, 1991.

* [54] Ludger Ruschendorf. Frechet-bounds and their applications. In _Advances in Probability Distributions with Given Marginals: beyond the copulas_, pages 151-187. Springer, 1991.
* [55] Ludger Ruschendorf. Risk bounds and partial dependence information. _From Statistics to Mathematical Finance: Festschrift in Honour of Winfried Stute_, pages 345-366, 2017.
* [56] Dylan Sam and J Zico Kolter. Losses over labels: Weakly supervised learning via direct loss construction. In _Proceedings of the AAAI conference on artificial intelligence_, volume 37, pages 9695-9703, 2023.
* [57] Agam Shah, Ruchit Vithani, Abhinav Gullapalli, and Sudheer Chava. Finer: Financial named entity recognition dataset and weak-supervision model. _arXiv preprint arXiv:2302.11157_, 2023.
* [58] Changho Shin, Winfred Li, Harit Vishwakarma, Nicholas Roberts, and Frederic Sala. Universalizing weak supervision. _arXiv preprint arXiv:2112.03865_, 2021.
* [59] Ryan Smith, Jason A Fries, Braden Hancock, and Stephen H Bach. Language models in the loop: Incorporating prompting into weak supervision. _arXiv preprint arXiv:2205.02318_, 2022.
* [60] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. _arXiv preprint arXiv:2307.09288_, 2023.
* [61] Paroma Varma, Bryan D He, Payal Bajaj, Nishith Khandwala, Imon Banerjee, Daniel Rubin, and Christopher Re. Inferring generative model structure with static analysis. _Advances in neural information processing systems_, 30, 2017.
* [62] Yue Yu, Simiao Zuo, Haoming Jiang, Wendi Ren, Tuo Zhao, and Chao Zhang. Fine-tuning pre-trained language model with weak supervision: A contrastive-regularized self-training approach. _arXiv preprint arXiv:2010.07835_, 2020.
* [63] Jieyu Zhang, Yue Yu, Yinghao Li, Yujing Wang, Yaming Yang, Mao Yang, and Alexander Ratner. Wrench: A comprehensive benchmark for weak supervision. _arXiv preprint arXiv:2109.11377_, 2021.
* [64] Jieyu Zhang, Cheng-Yu Hsieh, Yue Yu, Chao Zhang, and Alexander Ratner. A survey on programmatic weak supervision. _arXiv preprint arXiv:2202.05433_, 2022.
* [65] Xiang Zhang, Junbo Zhao, and Yann LeCun. Character-level convolutional networks for text classification. _Advances in neural information processing systems_, 28, 2015.
* [66] Dawei Zhu, Xiaoyu Shen, Marius Mosbach, Andreas Stephan, and Dietrich Klakow. Weaker than you think: A critical look atweakly supervised learning. _arXiv preprint arXiv:2305.17442_, 2023.

Connection to optimal transport

The optimizations in the Frechet bounds (1.1) can be connected to an optimization problem [45]. We only explain this connection for the lower bound, but the connection to the upper bound is quite similar. The optimization lower bound is

\[\inf_{\pi_{X,Z}=P_{X,z}}\mathbb{E}_{\pi_{Y|Z}=P_{Y|Z}}\mathbb{E}_{\pi }[g(X,Y,Z)]=\] \[=\inf_{\pi_{X,Z}=P_{X,z}}\sum_{z}\mathbb{P}(Z=z)\mathbb{E}_{\pi} [g(X,Y,Z)\mid Z=z]\] \[=\sum_{z}\mathbb{P}(Z=z)\left\{\inf_{\pi_{X|Z=z}=P_{X|Z=z}} \mathbb{E}_{\pi_{X,Y|Z=z}}[g(X,Y,z)]\right\}\]

where we notice that the inner minimization is an optimal transport problem between the probability distributions \(P_{X|Z=z}\) and \(P_{Y|Z=z}\) with the cost function \(d_{z}(x,y)=g(x,y,z)\).

A proof for the duality result

Proof of Theorem 2.1.: We start proving the result for \(L\). See that

\[L =\inf_{\pi\in\Pi}\mathbb{E}_{\pi}[g(X,Y,Z)]\] \[=\inf_{\{\pi_{z}\in\Pi_{z}\}_{z\in\mathcal{Z}}}\sum_{z\in\mathcal{ Z}}\mathbb{P}(Z=z)\cdot\mathbb{E}_{\pi_{z}}[g(X,Y,Z)\mid Z=z]\] \[=\sum_{z\in\mathcal{Z}}\mathbb{P}(Z=z)\cdot\inf_{\pi_{z}\in\Pi_{ z}}\mathbb{E}_{\pi_{z}}[g(X,Y,Z)\mid Z=z]\]

with \(\Pi_{z}\), is defined as

\[\Pi_{z}\triangleq\{\pi_{z}\in\Delta(\mathcal{X}\times\mathcal{Y}):\pi_{z} \circ\rho_{X}^{-1}=P_{X\mid Z=z}\text{ and }\pi_{z}\circ\rho_{Y}^{-1}=P_{Y\mid Z=z}\}\]

That is, for each \(z\in\mathcal{Z}\), \(\Pi_{z}\) represents the set of couplings such that marginals are given by \(P_{X\mid Z=z}\) and \(P_{Y\mid Z=z}\). We can represent the problem in this way since the marginal distribution of \(Z\) is fixed and, given that distribution, \(\{\Pi_{z}\}\) specifies the same set of distributions as \(\Pi\).

Realize that we have broken down our initial maximization problem in \(|\mathcal{Z}|\) smaller minimization problems. Each of those minimization problems can be treated as an optimal transportation problem. Consequently, by Beiglbock and Schachermayer [8, Theorem 1], for each \(z\in\mathcal{Z}\), we get the following duality result

\[\inf_{\pi_{z}\in\Pi_{z}}\mathbb{E}_{\pi_{z}}[g(X,Y,Z)\mid Z=z]=\sup_{(\beta_{z },\alpha_{z})\in\Psi_{z}}\mathbb{E}[\beta_{z}(X)+\alpha_{z}(Y)\mid Z=z]\]

with

\[\Psi_{z}\triangleq\left\{(\beta_{z},\alpha_{z}):\begin{array}{l}\beta_{z}:X \rightarrow[-\infty,\infty),\alpha_{z}:Y\rightarrow[-\infty,\infty)\\ \mathbb{E}[|\beta_{z}(X)|\mid Z=z]<\infty,\mathbb{E}[|\alpha_{z}(Y)|\mid Z=z] <\infty\\ \beta_{z}(x)+\alpha_{z}(y)\leq g(x,y,z)\text{ for all }(x,y)\in X\times Y \end{array}\right\}\]

Moreover, partially optimizing on \(\beta_{z}(x)\), we can set \(\beta_{z}^{*}(x)=\min_{y\in\mathcal{Y}}[g(x,y,z)-\alpha_{z}(y)]\) and then

\[\inf_{\pi_{z}\in\Pi_{z}}\mathbb{E}_{\pi_{z}}[g(X,Y,Z)\mid Z=z]=\] \[=\sup_{\alpha_{z}}\mathbb{E}\left[\min_{y\in\mathcal{Y}}[g(X,y,Z) +\alpha_{z}(y)]-\alpha_{z}(Y)\mid Z=z\right]\]

where \(\alpha_{z}\) is a simple function taking values in the real line.

Consequently,

\[L =\sum_{z\in\mathcal{Z}}\mathbb{P}(Z=z)\cdot\sup_{\alpha_{z}} \mathbb{E}\left[\min_{y\in\mathcal{Y}}[g(X,y,Z)+\alpha_{z}(y)]-\alpha_{z}(Y) \mid Z=z\right]\] \[=\sup_{\{\alpha_{z}\}_{z\in\mathcal{Z}}}\sum_{z\in\mathcal{Z}} \mathbb{P}(Z=z)\cdot\mathbb{E}\left[\min_{y\in\mathcal{Y}}[g(X,y,Z)+\alpha_{z} (y)]-\alpha_{z}(Y)\mid Z=z\right]\] \[=\sup_{\{\alpha_{z}\}_{z\in\mathcal{Z}}}\mathbb{E}\left[\min_{y \in\mathcal{Y}}[g(X,y,Z)+\alpha_{Z}(y)]-\alpha_{Z}(Y)\right]\]

Because each \(\alpha_{z}\) is a function assuming at most \(|\mathcal{Y}|\) values and we have \(|\mathcal{Z}|\) functions (one for each value of \(z\)), we can equivalently solve an optimization problem on \(\mathbb{R}^{|\mathcal{Y}|\times|\mathcal{Z}|}\). Adjusting the notation,

\[L=\sup_{a\in\mathbb{R}^{|\mathcal{Y}|\times|Z|}}\mathbb{E}\Big{[}\min_{\bar{y} \in\mathcal{Y}}[g(X,\bar{y},Z)+a_{\bar{y}Z}]\,\Big{]}-\mathbb{E}\left[a_{YZ}\right]\]

From Beiglbock and Schachermayer [8, Theorem 2], we know that the maximum is attained by some \(a^{*}\in\mathbb{R}^{|\mathcal{Y}|\times|\mathcal{Z}|}\). To show that there is a maximizer in \(\mathcal{A}\), we need to update the solution

\[a_{.z}^{*}\gets a_{.z}^{*}-\sum_{y\in\mathcal{Y}}a_{yz}^{*}\quad\text{( shift sub-vector by a constant)}\] (B.1)

for every \(z\in\mathcal{Z}\). The objective function is not affected by such translations.

To prove the result for \(U\), first realize that because \(g\) is bounded, with no loss of generality, we can assume its range is a subset of \([0,1]\). Define \(c(x,y,z)=1-g(x,y,z)\) and see that

\[U=\sup_{\pi\in\Pi}\mathbb{E}_{\pi}[1-c(X,Y,Z)]=1-\inf_{\pi\in\Pi}\mathbb{E}_{ \pi}[c(X,Y,Z)]\]

Proceeding as before, we can obtain the final result by finding the dual formulation for \(\inf_{\pi\in\Pi}\mathbb{E}_{\pi}[c(X,Y,Z)]\)Proofs for the estimation results

**We will analyze the estimator for \(U\) (results for the estimator of \(L\) can be obtained analogously).** For the next results, we define

\[\tilde{f}_{u,\varepsilon}(x,z,a)\triangleq f_{u,\varepsilon}(x,z,a)+\sum_{z^{ \prime}\in\mathcal{Z}}\left(\sum_{y\in\mathcal{Y}}a_{yz^{\prime}}\right)^{2}.\]

Proof of Theorem 2.5.: By Assumption 2.2 and Lemmas C.1 and C.2, we can guarantee that \(\mathbb{E}[\tilde{f}_{u,\varepsilon}(X,Z,a)]\) is minimized by a unique \(a^{*}_{u,\varepsilon}\) (equalling it to \(U_{\varepsilon}\)) and that \(\nabla^{2}_{a}\mathbb{E}[\tilde{f}_{u,\varepsilon}(X,Z,a^{*}_{u,\varepsilon})]\) is positive definite. Also, from the proof of Lemma C.2, we can see that \(\tilde{f}_{u,\varepsilon}\) is convex in \(a\) (because its Hessian is positive semidefinite). It is also true that the second moment of \(\tilde{f}_{u,\varepsilon}(X,Z,a)\) is well defined (exists and finite) for each \(a\) since \(g\) is bounded. Define

\[\tilde{U}_{\varepsilon}\triangleq\inf_{a\in\mathbb{R}^{|\mathcal{Y}|\times| \mathcal{Z}|}}\tfrac{1}{n}\sum_{i=1}^{n}\tilde{f}_{u,\varepsilon}(X_{i},Z_{i},a)\]

and let \(\tilde{a}_{\varepsilon}\) denote a value that attains that minimum; from Niemiro [44, Theorem 4] and the conditions discussed above, we know that \(\sqrt{n}(\tilde{a}_{\varepsilon}-a^{*}_{u,\varepsilon})=\mathcal{O}_{P}(1)\). The existence of \(\tilde{a}_{\varepsilon}\) is discussed by Niemiro [44]. Then

\[\begin{split}&\sqrt{n}(\tilde{U}_{\varepsilon}-U_{\varepsilon})\\ &=\frac{1}{\sqrt{n}}\left(\sum_{i}\tilde{f}_{u,\varepsilon}(X_{i},Z_{i},\tilde{a}_{\varepsilon})-\sum_{i}\tilde{f}_{u,\varepsilon}(X_{i},Z_{i}, a^{*}_{u,\varepsilon})\right)+\sqrt{n}\left(\frac{1}{n}\sum_{i}\tilde{f}_{u, \varepsilon}(X_{i},Z_{i},a^{*}_{u,\varepsilon})-U_{\varepsilon}\right)\\ &=\frac{1}{\sqrt{n}}\left([\sqrt{n}(\tilde{a}_{\varepsilon}-a^{*} _{u,\varepsilon})]^{\top}[\frac{1}{n}\sum_{i}\nabla^{2}_{a}\tilde{f}_{u, \varepsilon}(X_{i},Z_{i},\bar{a})][\sqrt{n}(\tilde{a}_{\varepsilon}-a^{*}_{u, \varepsilon})]\right)+\\ &\quad+\sqrt{n}\left(\frac{1}{n}\sum_{i}\tilde{f}_{u,\varepsilon }(X_{i},Z_{i},a^{*}_{u,\varepsilon})-U_{\varepsilon}\right)+o_{P}(1)\end{split}\] (C.1)

where the first term is obtained by a second-order Taylor expansion of the summing functions around \(\tilde{a}_{\varepsilon}\) (\(\bar{a}\) is some random vector). Also, from the standard central limit theorem, we know that

\[\sqrt{n}\left(\tfrac{1}{n}\sum_{i}\tilde{f}_{u,\varepsilon}(X_{i},Z_{i},a^{*} _{u,\varepsilon})-U_{\varepsilon}\right)\Rightarrow N(0,\mathrm{Var}\tilde{f} _{u,\varepsilon}(X,Z,a^{*}_{u,\varepsilon}))\]

Given that \(\sqrt{n}(\tilde{a}_{\varepsilon}-a^{*}_{u,\varepsilon})=\mathcal{O}_{P}(1)\) and that the Hessian has bounded entries (then \(\mathcal{O}_{P}(1)\) as well), the first term in C.1 is \(o_{P}(1)\). Because \(a^{*}_{u,\varepsilon}\in\mathcal{A}\), we have that \(f_{u,\varepsilon}(X,Z,a^{*}_{u,\varepsilon})=\tilde{f}_{u,\varepsilon}(X,Z,a^ {*}_{u,\varepsilon})\) and then

\[\sqrt{n}(\tilde{U}_{\varepsilon}-U_{\varepsilon})\Rightarrow N(0,\mathrm{ Var}f_{u,\varepsilon}(X,Z,a^{*}_{u,\varepsilon}))\]

by Slutsky's theorem. Since

\[\sqrt{n}(\hat{U}_{\varepsilon}-U)=\sqrt{n}(\hat{U}_{\varepsilon}-\tilde{U}_{ \varepsilon})+\sqrt{n}(\tilde{U}_{\varepsilon}-U_{\varepsilon}),\]

if we can show that

\[\sqrt{n}(\tilde{U}_{\varepsilon}-\hat{U}_{\varepsilon})=o_{P}(1)\]

we are done.

Let \(\hat{a}\) be solution for the problem in 2.3 and see that

\[|\tilde{U}_{\varepsilon}-\hat{U}_{\varepsilon}|=\] \[=\left|\tfrac{1}{n}\sum_{i=1}^{n}\tilde{f}_{u,\varepsilon}(X_{i},Z _{i},\tilde{a}_{\varepsilon})-\tfrac{1}{n}\sum_{i=1}^{n}\varepsilon\log\left[ \tfrac{1}{|\mathcal{Y}|}\sum_{y\in\mathcal{Y}}\exp\left(\tfrac{g(X_{i},y,Z_{i} )+\hat{a}_{yZ_{i}}}{\varepsilon}\right)\right]+\mathbb{E}_{\hat{P}_{Y|Z}}\left[ \hat{a}_{YZ}\mid Z=Z_{i}\right]\right|\] \[\leq\left|\tfrac{1}{n}\sum_{i=1}^{n}\tilde{f}_{u,\varepsilon}(X_{ i},Z_{i},\tilde{a}_{\varepsilon})-\tfrac{1}{n}\sum_{i=1}^{n}\tilde{f}_{u, \varepsilon}(X_{i},Z_{i},\hat{a})\right|+\] \[\quad+\left|\tfrac{1}{n}\sum_{i=1}^{n}\tilde{f}_{u,\varepsilon}( X_{i},Z_{i},\hat{a})-\tfrac{1}{n}\sum_{i=1}^{n}\varepsilon\log\left[\tfrac{1}{| \mathcal{Y}|}\sum_{y\in\mathcal{Y}}\exp\left(\tfrac{g(X_{i},y,Z_{i})+\hat{a}_{ yZ_{i}}}{\varepsilon}\right)\right]+\mathbb{E}_{\hat{P}_{Y|Z}}\left[\hat{a}_{YZ} \mid Z=Z_{i}\right]\right|\] \[=(\tfrac{1}{n}\sum_{i=1}^{n}\tilde{f}_{u,\varepsilon}(X_{i},Z_{i},\hat{a})-\tfrac{1}{n}\sum_{i=1}^{n}\tilde{f}_{u,\varepsilon}(X_{i},Z_{i},\tilde {a}_{\varepsilon}))+\] \[\quad+\left|\tfrac{1}{n}\sum_{i=1}^{n}\sum_{y}[\mathbb{P}(Y=y\mid Z =Z_{i})-\hat{\mathbb{P}}(Y=y\mid Z=Z_{i})]\hat{a}_{yZ_{i}}\right|\] \[\leq\left(\tfrac{1}{n}\sum_{i=1}^{n}\tilde{f}_{u,\varepsilon}(X_{ i},Z_{i},\hat{a})-\tfrac{1}{n}\sum_{i=1}^{n}\varepsilon\log\left[\tfrac{1}{| \mathcal{Y}|}\sum_{y\in\mathcal{Y}}\exp\left(\tfrac{g(X_{i},y,Z_{i})+\hat{a}_{ yZ_{i}}}{\varepsilon}\right)\right]+\mathbb{E}_{\hat{P}_{Y|Z}}\left[\hat{a}_{YZ} \mid Z=Z_{i}\right]\right)\] \[\quad+\left(\tfrac{1}{n}\sum_{i=1}^{n}\varepsilon\log\left[ \tfrac{1}{|\mathcal{Y}|}\sum_{y\in\mathcal{Y}}\exp\left(\tfrac{g(X_{i},y,Z_{i} )+\hat{a}_{yZ_{i}}}{\varepsilon}\right)\right]-\mathbb{E}_{\hat{P}_{Y|Z}} \left[\tilde{a}_{\varepsilon_{YZ}}\mid Z=Z_{i}\right]-\tfrac{1}{n}\sum_{i=1}^{ n}\tilde{f}_{u,\varepsilon}(X_{i},Z_{i},\tilde{a}_{\varepsilon})\right)\] \[\quad+\left|\tfrac{1}{n}\sum_{i=1}^{n}\sum_{y}[\mathbb{P}(Y=y \mid Z=Z_{i})-\hat{\mathbb{P}}(Y=y\mid Z=Z_{i})]\hat{a}_{yZ_{i}}\right|\] \[=\left(\tfrac{1}{n}\sum_{i=1}^{n}\sum_{y}[\hat{\mathbb{P}}(Y=y \mid Z=Z_{i})-\mathbb{P}(Y=y\mid Z=Z_{i})]\hat{a}_{yZ_{i}}\right)\] \[\quad+\left|\tfrac{1}{n}\sum_{i=1}^{n}\sum_{y}[\mathbb{P}(Y=y \mid Z=Z_{i})-\hat{\mathbb{P}}(Y=y\mid Z=Z_{i})]\hat{a}_{z_{yZ_{i}}}\right|\] \[\leq 2\left\|\hat{a}\right\|_{\infty}\tfrac{1}{n}\sum_{i=1}^{n} \sum_{y}|\mathbb{P}(Y=y\mid Z=Z_{i})-\hat{\mathbb{P}}(Y=y\mid Z=Z_{i})|+\] \[\quad+\left\|\tilde{a}_{\varepsilon}\right\|_{\infty}\tfrac{1}{n} \sum_{i=1}^{n}\sum_{y}|\mathbb{P}(Y=y\mid Z=Z_{i})-\hat{\mathbb{P}}(Y=y\mid Z =Z_{i})|\] \[\leq 2\left\|\hat{a}\right\|_{\infty}\sum_{z}\sum_{y}|\mathbb{P}(Y=y \mid Z=z)-\hat{\mathbb{P}}(Y=y\mid Z=z)|+\] \[\leq 4\left\|\hat{a}\right\|_{\infty}\sum_{z}d_{\text{TV}}\left( \hat{P}_{Y|Z=z},P_{Y|Z=z}\right)+2\left\|\tilde{a}_{\varepsilon}\right\|_{ \infty}\sum_{z}d_{\text{TV}}\left(\hat{P}_{Y|Z=z},P_{Y|Z=z}\right)\] \[=\mathcal{O}_{P}(m^{-\lambda})\]

where the last equality is obtained using Assumptions 2.3 and 2.4, and the fact that \(\left\|\tilde{a}_{\varepsilon}\right\|_{\infty}\) is tight (derived from \(\sqrt{n}(\tilde{a}_{\varepsilon}-a_{u,\varepsilon}^{*})=\mathcal{O}_{P}(1)\)). Consequently,

\[\sqrt{n}(\tilde{U}_{\varepsilon}-\hat{U}_{\varepsilon})=\sqrt{n} \mathcal{O}_{P}(m^{-\lambda})=o(m^{\lambda})\mathcal{O}_{P}(m^{-\lambda})=o_{P}(1)\]

Finally, using Slutsky's theorem,

\[\sqrt{n}(\hat{U}_{\varepsilon}-U)=\sqrt{n}(\hat{U}_{\varepsilon}- \tilde{U}_{\varepsilon})+\sqrt{n}(\tilde{U}_{\varepsilon}-U)\Rightarrow N(0, \operatorname{Var}f_{u,\varepsilon}(X,Z,a_{u,\varepsilon}^{*}))\]

Proof of Corollary 3.1.: We prove the asymptotic distribution of \(\sqrt{n}\big{(}\hat{p}_{u,\varepsilon}-p_{u,\varepsilon}\big{)}\). The result for the lower bound can be obtained analogously.

First, note that

\[\hat{\mathbb{P}}(h(X)=1)-\mathbb{P}(h(X)=1)=\mathcal{O}_{P}(m^{-1/2})\] (C.2)

by the standard central limit theorem.

Next, see that

\[\sqrt{n}\left(\hat{p}_{u,\varepsilon}-p_{u,\varepsilon}\right)=\] \[=\sqrt{n}\left(\frac{\hat{U}_{\varepsilon}}{\mathbb{P}(h(X)=1)}- \frac{U_{\varepsilon}}{\mathbb{P}(h(X)=1)}\right)\] \[=\frac{1}{\mathbb{P}(h(X)=1)}\sqrt{n}\left(\hat{U}_{\varepsilon} -\frac{\mathbb{P}(h(X)=1)}{\mathbb{P}(h(X)=1)}U_{\varepsilon}\right)\] \[=\frac{1}{\mathbb{P}(h(X)=1)}\sqrt{n}\left(\hat{U}_{\varepsilon} -U_{\varepsilon}\right)+\frac{1}{\mathbb{P}(h(X)=1)}\sqrt{n}\left(U_{ \varepsilon}-\frac{\hat{\mathbb{P}}(h(X)=1)}{\mathbb{P}(h(X)=1)}U_{\varepsilon}\right)\] \[=\frac{1}{\mathbb{P}(h(X)=1)}\sqrt{n}\left(\hat{U}_{\varepsilon} -U_{\varepsilon}\right)+U_{\varepsilon}\sqrt{n}\left(\frac{1}{\mathbb{P}(h(X) =1)}-\frac{1}{\mathbb{P}(h(X)=1)}\right)\] \[=\frac{1}{\mathbb{P}(h(X)=1)}\sqrt{n}\left(\hat{U}_{\varepsilon} -U_{\varepsilon}\right)+U_{\varepsilon}\sqrt{n}\left(\hat{\mathbb{P}}(h(X)=1) -\mathbb{P}(h(X)=1)\right)\left(\frac{-1}{\mathbb{P}(h(X)=1)^{2}}\right)+o_{ P}\left(m^{-1/2}\right)\] \[=\frac{1}{\mathbb{P}(h(X)=1)}\sqrt{n}\left(\hat{U}_{\varepsilon} -U_{\varepsilon}\right)+o_{P}\left(1\right)\] \[\Rightarrow N(0,\sigma_{p,u,\varepsilon}^{2})\]

where the (i) fifth and sixth lines equality is obtained using Taylor's theorem, (ii) sixth and seventh lines equality is obtained using observation C.2 and the fact that \(n=o(m^{(2\lambda)\wedge 1})\), and (iii) seventh to eighth lines equality is obtained using observation C.2, Theorem 2.5, and Slutsky's theorem.

We prove the asymptotic distribution of \(\sqrt{n}\big{(}\hat{r}_{u,\varepsilon}-r_{u,\varepsilon}\big{)}\). The result for the lower bound can be obtained analogously. From Lemma C.3, we know that there is an estimator \(\hat{\mathbb{P}}(Y=1)\) such that \(\hat{\mathbb{P}}(Y=1)-\mathbb{P}(Y=1)=\mathcal{O}_{P}(m^{-(\lambda\wedge 1/2)})\), _i.e._, it has enough precision. We use that estimator.

Next, see that

\[\sqrt{n}\left(\hat{r}_{u,\varepsilon}-r_{u,\varepsilon}\right)=\] \[=\sqrt{n}\left(\frac{\hat{U}_{\varepsilon}}{\mathbb{P}(Y=1)}- \frac{U_{\varepsilon}}{\mathbb{P}(Y=1)}\right)\] \[=\frac{1}{\mathbb{P}(Y=1)}\sqrt{n}\left(\hat{U}_{\varepsilon}- \frac{\mathbb{P}(Y=1)}{\mathbb{P}(Y=1)}U_{\varepsilon}\right)\] \[=\frac{1}{\mathbb{P}(Y=1)}\sqrt{n}\left(\hat{U}_{\varepsilon}-U_ {\varepsilon}\right)+\frac{1}{\mathbb{P}(Y=1)}\sqrt{n}\left(U_{\varepsilon} -\frac{\hat{\mathbb{P}}(Y=1)}{\mathbb{P}(Y=1)}U_{\varepsilon}\right)\] \[=\frac{1}{\mathbb{P}(Y=1)}\sqrt{n}\left(\hat{U}_{\varepsilon}-U_ {\varepsilon}\right)+U_{\varepsilon}\sqrt{n}\left(\frac{1}{\mathbb{P}(Y=1)}- \frac{1}{\mathbb{P}(Y=1)}\right)\] \[=\frac{1}{\mathbb{P}(Y=1)}\sqrt{n}\left(\hat{U}_{\varepsilon}-U_ {\varepsilon}\right)+o_{P}\left(1\right)\] \[\Rightarrow N(0,\sigma_{r,u,\varepsilon}^{2})\]

Finally, we prove the asymptotic distribution of \(\sqrt{n}\big{(}\hat{F}_{u,\varepsilon}-F_{u,\varepsilon}\big{)}\). The result for the lower bound can be obtained analogously. From the facts stated above, we know that

\[\hat{\mathbb{P}}(h(X)=1)+\hat{\mathbb{P}}(Y=1)-[\mathbb{P}(h(X)=1 )+\mathbb{P}(Y=1)]=\] \[=[\hat{\mathbb{P}}(h(X)=1)-\mathbb{P}(h(X)=1)]+[\hat{\mathbb{P}}( Y=1)-\mathbb{P}(Y=1)]=\] \[=\mathcal{O}_{P}(m^{-(\lambda\wedge 1/2)})\]Then,

\[\sqrt{n}\left(\hat{F}_{u,\varepsilon}-F_{u,\varepsilon}\right)=\] \[=\sqrt{n}\left(\tfrac{2\hat{U}_{\varepsilon}}{\left[\mathbb{P}(h(X) =1)+\mathbb{P}(Y=1)\right]}-\tfrac{2U_{\varepsilon}}{\left[\mathbb{P}(h(X)=1)+ \mathbb{P}(Y=1)\right]}\right)\] \[=\tfrac{2}{\left[\mathbb{P}(h(X)=1)+\mathbb{P}(Y=1)\right]}\sqrt{n }\left(\hat{U}_{\varepsilon}-\tfrac{\left[\mathbb{P}(h(X)=1)+\mathbb{P}(Y=1) \right]}{\left[\mathbb{P}(h(X)=1)+\mathbb{P}(Y=1)\right]}U_{\varepsilon}\right)\] \[=\tfrac{2}{\left[\mathbb{P}(h(X)=1)+\mathbb{P}(Y=1)\right]}\sqrt{ n}\left(\hat{U}_{\varepsilon}-U_{\varepsilon}\right)+\tfrac{1}{\left[ \mathbb{P}(h(X)=1)+\mathbb{P}(Y=1)\right]}\sqrt{n}\left(2U_{\varepsilon}- \tfrac{\left[\mathbb{P}(h(X)=1)+\mathbb{P}(Y=1)\right]}{\left[\mathbb{P}(h(X )=1)+\mathbb{P}(Y=1)\right]}2U_{\varepsilon}\right)\] \[=\tfrac{2}{\left[\mathbb{P}(h(X)=1)+\mathbb{P}(Y=1)\right]}\sqrt {n}\left(\hat{U}_{\varepsilon}-U_{\varepsilon}\right)+2U_{\varepsilon}\sqrt{n }\left(\tfrac{1}{\left[\mathbb{P}(h(X)=1)+\mathbb{P}(Y=1)\right]}-\tfrac{1}{ \left[\mathbb{P}(h(X)=1)+\mathbb{P}(Y=1)\right]}\right)\] \[=\tfrac{2}{\left[\mathbb{P}(h(X)=1)+\mathbb{P}(Y=1)\right]}\sqrt {n}\left(\hat{U}_{\varepsilon}-U_{\varepsilon}\right)+\] \[\Rightarrow N(0,\sigma_{F,u,\varepsilon}^{2})\]

where all the steps are justified as before.

\(\square\)

### Auxiliary lemmas

**Lemma C.1**.: _Define_

\[\tilde{f}_{u,\varepsilon}(x,z,a)\triangleq f_{u,\varepsilon}(x,z,a)+\sum_{z^{ \prime}\in\mathcal{Z}}\left(\sum_{y\in\mathcal{Y}}a_{yz^{\prime}}\right)^{2}\]

_Then_

\[\inf_{a\in\mathbb{R}^{|\mathcal{Y}|\times|Z|}}\mathbb{E}[\tilde{f}_{u, \varepsilon}(X,Z,a)]=\inf_{a\in\mathcal{A}}\mathbb{E}[f_{u,\varepsilon}(X,Z,a)]\]

Proof.: First, see that

\[\mathbb{E}[\tilde{f}_{u,\varepsilon}(X,Z,a)]\geq\mathbb{E}[f_{u,\varepsilon} (X,Z,a)]\]

From Assumption 2.2, we know that there exists some \(a^{*}_{u,\varepsilon}\in\mathbb{R}^{|\mathcal{Y}|\times|Z|}\) such that

\[\inf_{a\in\mathcal{A}}\mathbb{E}[f_{u,\varepsilon}(X,Z,a)]=\mathbb{E}[f_{u, \varepsilon}(X,Z,a^{*}_{u,\varepsilon})]\]

For that specific \(a^{*}_{u,\varepsilon}\), we have that

\[\mathbb{E}[\tilde{f}_{u,\varepsilon}(X,Z,a^{*}_{u,\varepsilon})]=\mathbb{E}[ f_{u,\varepsilon}(X,Z,a^{*}_{u,\varepsilon})]\]

Consequently,

\[\inf_{a\in\mathbb{R}^{|\mathcal{Y}|\times|Z|}}\mathbb{E}[\tilde{f}_{u, \varepsilon}(X,Z,a)]=\mathbb{E}[\tilde{f}_{u,\varepsilon}(X,Z,a^{*}_{u, \varepsilon})]=\mathbb{E}[f_{u,\varepsilon}(X,Z,a^{*}_{u,\varepsilon})]=\inf_ {a\in\mathcal{A}}\mathbb{E}[f_{u,\varepsilon}(X,Z,a)]\]

\(\square\)

**Lemma C.2**.: _The function of a given by \(\mathbb{E}[\tilde{f}_{u,\varepsilon}(X,Z,a)]\) has positive definite Hessian, i.e.,_

\[H_{\varepsilon}(a)=\nabla_{a}^{2}\mathbb{E}[\tilde{f}_{u,\varepsilon}(X,Z,a)]\succ 0\]

_and, consequently, it is strictly convex._

Proof.: See that

\[H_{\varepsilon}(a)=\nabla_{a}^{2}\mathbb{E}[f_{u,\varepsilon}(X,Z,a)]+\nabla _{a}^{2}\left[\sum_{z^{\prime}\in\mathcal{Z}}\left(\sum_{y\in\mathcal{Y}}a_{ yz^{\prime}}\right)^{2}\right]\]We start computing the first term in the sum.

First, for an arbitrary pair \((k,l)\in\mathcal{Y}\times\mathcal{Z}\), define

\[s_{kl}(x)\triangleq\frac{\exp\left(\frac{g(x,k,l)+s_{kl}}{\varepsilon}\right)}{ \sum_{y}\exp\left(\frac{g(x,y,l)+s_{kl}}{\varepsilon}\right)}\]

Now, see that

\[\tfrac{\partial}{\partial a_{kl}}f_{u,\varepsilon}(x,z,a)=\mathds{1}_{\{l\}}( z)\Bigg{[}s_{kl}(x)-\mathbb{P}(Y=k\mid Z=l)\Bigg{]}\]

and

\[\tfrac{\partial^{2}}{\partial a_{pl}\partial a_{kl}}f_{u,\varepsilon}(x,z,a) =\tfrac{1}{\varepsilon}\mathds{1}_{\{l\}}(z)\Bigg{[}\mathds{1}_{\{k\}}(p)s_{ kl}(x)-s_{kl}(x)s_{pl}(x)\Bigg{]}\]

See that \(\tfrac{\partial^{2}}{\partial a_{p\cup}\partial a_{kl}}f_{u,\varepsilon}(x,z,a )=0\) if \(b\neq l\). Consequently, the Hessian \(\nabla_{a}^{2}\)\(f_{u,\varepsilon}(x,z,a)\) is block diagonal.

Consequently, because the second derivatives are bounded, we can push them inside the expectations and get

\[\tfrac{\partial^{2}}{\partial a_{pl}\partial a_{kl}}\mathbb{E} \left[f_{u,\varepsilon}(X,Z,a)\right]=\] \[=\mathbb{E}\left[\tfrac{\partial^{2}}{\partial a_{pl}\partial a _{kl}}f_{u,\varepsilon}(X,Z,a)\right]\] \[=\tfrac{1}{\varepsilon}\mathbb{E}\left[\mathds{1}_{\{l\}}(Z) \Big{[}\mathds{1}_{\{k\}}(p)s_{kl}(X)-s_{kl}(X)s_{pl}(X)\Big{]}\right]\] \[=\tfrac{1}{\varepsilon}\mathds{1}_{\{k\}}(p)\cdot\mathbb{E} \left[\mathbb{P}(Z=l\mid X)s_{kl}(X)\right]-\tfrac{1}{\varepsilon}\mathbb{E} \left[\mathbb{P}(Z=l\mid X)s_{kl}(X)s_{pl}(X)\right]\]

Because \(\nabla_{a}^{2}\)\(f_{u,\varepsilon}(x,z,a)\) is block diagonal, we know that the Hessian

\[\nabla_{a}^{2}\,\mathbb{E}\left[f_{u,\varepsilon}(X,Z,a)\right]\]

is block diagonal (one block for each segment \(a_{\cdot z}\) of the vector \(a\)). Now, realize that

\[\nabla_{a}^{2}\left[\sum_{z^{\prime}\in\mathcal{Z}}\left(\sum_{y\in\mathcal{Y }}a_{yz^{\prime}}\right)^{2}\right]\]

is also block diagonal, with each block being matrices of ones. In this case, we also have one block for each segment \(a_{\cdot z}\) of the vector \(a\). Consequently, \(H_{\varepsilon}(a)\) is block diagonal, and it is positive definite if and only if all of its blocks are positive definite. Let us analyse an arbitrary block of \(H_{\varepsilon}(a)\), _e.g._, \(\nabla_{a_{\cdot l}}^{2}\,\mathbb{E}\left[\tilde{f}_{u,\varepsilon}(X,Z,a)\right]\). Let \(\mathbf{s}_{\cdot l}(x)\) be the vector composed of \(s_{kl}(x)\) for all \(k\). If \(\mathds{1}\in\mathbb{R}^{|\mathcal{Y}|}\) denotes a vector of ones, then,

\[\nabla_{a_{\cdot l}}^{2}\,\mathbb{E}\left[\tilde{f}_{u,\varepsilon }(X,Z,a)\right]=\] \[=\tfrac{1}{\varepsilon}\text{diag}\Big{(}\mathbb{E}\left[\mathbb{ P}(Z=l\mid X)\mathbf{s}_{\cdot l}(X)\right]\Big{)}-\tfrac{1}{\varepsilon} \mathbb{E}\left[\mathbb{P}(Z=l\mid X)\mathbf{s}_{\cdot l}(X)\mathbf{s}_{\cdot l }(X)^{\top}\right]+\mathds{1}\mathds{1}^{\top}\] \[=\mathbb{E}\Bigg{\{}\tfrac{1}{\varepsilon}\mathbb{P}(Z=l\mid X) \Big{[}\text{diag}\big{(}\mathbf{s}_{\cdot l}(X)\big{)}-\mathbf{s}_{\cdot l}( X)\mathbf{s}_{\cdot l}(X)^{\top}+\tfrac{\varepsilon}{\mathbb{P}(Z=l)} \mathds{1}\mathds{1}^{\top}\Big{]}\Bigg{\}}\] \[=\mathbb{E}\Bigg{\{}\tfrac{1}{\varepsilon}\mathbb{P}(Z=l\mid X) \Big{[}\text{diag}\big{(}\mathbf{s}_{\cdot l}(X)\big{)}-\mathbf{s}_{\cdot l}( X)\mathbf{s}_{\cdot l}(X)^{\top}+\tilde{\mathds{1}}\mathds{1}^{\top} \Big{]}\Bigg{\}}\]

where \(\tilde{\mathds{1}}=\sqrt{\frac{\varepsilon}{\mathbb{P}(Z=l)}\mathds{1}}\). See that \(\text{diag}\big{(}\mathbf{s}_{\cdot l}(x)\big{)}\) has rank \(|\mathcal{Y}|\) (full rank) while \(\mathbf{s}_{\cdot l}(x)\mathbf{s}_{\cdot l}(x)^{\top}\) is rank one for every \(x\in\mathbb{R}^{d_{X}}\). Consequently, the rank of the difference

\[D(x)=\text{diag}\big{(}\mathbf{s}_{\cdot l}(x)\big{)}-\mathbf{s}_{\cdot l}(x) \mathbf{s}_{\cdot l}(x)^{\top}\]is greater or equal \(|\mathcal{Y}|-1\). It is the case that \(\text{rank}(D(x))=|\mathcal{Y}|-1\) because \(\tilde{\mathds{1}}\) is in the null space of \(D\):

\[D(x)\tilde{\mathds{1}}=\left[\text{diag}\big{(}\mathbf{s}_{\cdot l}(x)\big{)}- \mathbf{s}_{\cdot l}(x)\mathbf{s}_{\cdot l}(x)^{\top}\right]\tilde{\mathds{1}} =\sqrt{\tfrac{\varepsilon}{\mathbb{P}(Z=l)}}(\mathbf{s}_{\cdot l}(x)- \mathbf{s}_{\cdot l}(x))=0\]

Moreover, the range of \(D(x)\) and \(\tilde{\mathds{1}}\tilde{\mathds{1}}^{\top}\) are orthogonal. For any two vectors \(\mathbf{v},\mathbf{u}\in\mathbb{R}^{|\mathcal{Y}|}\), we have that

\[(D(x)\mathbf{v})^{\top}(\tilde{\mathds{1}}\tilde{\mathds{1}}^{\top}\mathbf{u} )=\mathbf{v}^{\top}D(x)^{\top}\tilde{\mathds{1}}\tilde{\mathds{1}}^{\top} \mathbf{u}=\mathbf{v}^{\top}D(x)\tilde{\mathds{1}}\tilde{\mathds{1}}^{\top} \mathbf{u}=\mathbf{v}^{\top}0\tilde{\mathds{1}}^{\top}\mathbf{u}=0\]

That implies \(D(x)+\tilde{\mathds{1}}\tilde{\mathds{1}}^{\top}\) is full rank. To see that, let \(\mathbf{v}\in\mathbb{R}^{|\mathcal{Y}|}\) be arbitrary and see

\[(D(x)+\tilde{\mathds{1}}\tilde{\mathds{1}}^{\top})\mathbf{v}=0\Rightarrow D (x)\mathbf{v}=\tilde{\mathds{1}}\tilde{\mathds{1}}^{\top}\mathbf{v}=0\]

Because \(D(x)\mathbf{v}=0\), it means that \(\mathbf{v}=\theta\tilde{\mathds{1}}\) for some constant \(\theta\). If \(\theta\neq 0\), then \(\tilde{\mathds{1}}\tilde{\mathds{1}}^{\top}\mathbf{v}=\theta|\mathcal{Y}| \tilde{\mathds{1}}\neq 0\). Therefore, \(\theta=0\) and \(\mathbf{v}=0\).

Now, let \(\mathbf{u}\in\mathbb{R}^{|\mathcal{Y}|}\) be arbitrary non-null vector and see

\[\mathbf{u}^{\top}D(x)\mathbf{u} =\mathbf{u}^{\top}\text{diag}\big{(}\mathbf{s}_{\cdot l}(x) \mathbf{u}-\mathbf{u}^{\top}\mathbf{s}_{\cdot l}(x)\mathbf{s}_{\cdot l}(x)^{ \top}\mathbf{u}\] \[=\sum_{y}u_{y}^{2}s_{yl}(x)-\left(\sum_{y}u_{y}s_{yl}(x)\right)^{2}\] \[=\left(\sum_{y}s_{yl}(x)\right)\left(\sum_{y}u_{y}^{2}s_{yl}(x) \right)-\left(\sum_{y}u_{y}s_{yl}(x)\right)^{2}\] \[=\left(\sum_{y}\sqrt{s_{yl}(x)}\sqrt{s_{yl}(x)}\right)\left(\sum_ {y}\sqrt{u_{y}^{2}s_{yl}(x)}\sqrt{u_{y}^{2}s_{yl}(x)}\right)-\left(\sum_{y}u_ {y}s_{yl}(x)\right)^{2}\] \[\geq\left(\sum_{y}u_{y}s_{yl}(x)\right)^{2}-\left(\sum_{y}u_{y}s _{yl}(x)\right)^{2}=0\]

by the Cauchy-Schwarz inequality. Then, \(D(x)\) is positive semidefinite, and because \(\tilde{\mathds{1}}\tilde{\mathds{1}}^{\top}\) is also positive semidefinite, their sum needs to be positive definite for all \(x\) (that matrix is full rank). Each block of \(H_{\varepsilon}(a)\) is positive definite; consequently, \(H_{\varepsilon}(a)\) is positive definite. 

**Lemma C.3**.: _Assume Assumption 2.4 holds. Let_

\[\hat{\mathbb{P}}(Y=1)=\tfrac{1}{m}\sum_{i=1}^{m}\mathbb{E}_{\hat{P}_{Y|Z}}[Y\mid Z =Z_{i}]\]

_Then_

\[\hat{\mathbb{P}}(Y=1)-\mathbb{P}(Y=1)=\mathcal{O}_{P}(m^{-(\lambda\wedge 1/2)})\]

Proof.: To derive this result, see that

\[|\hat{\mathbb{P}}(Y=1)-\mathbb{P}(Y=1)|=\] \[=\Big{|}\tfrac{1}{m}\sum_{i=1}^{m}\mathbb{E}_{P_{Y|Z}}[Y\mid Z=Z_ {i}]-\mathbb{P}(Y=1)+\tfrac{1}{m}\sum_{i=1}^{m}\mathbb{E}_{\hat{P}_{Y|Z}}[Y \mid Z=Z_{i}]-\mathbb{E}_{P_{Y|Z}}[Y\mid Z=Z_{i}]\Big{|}\] \[\leq\big{|}\tfrac{1}{m}\sum_{i=1}^{m}\mathbb{E}_{P_{Y|Z}}[Y\mid Z =Z_{i}]-\mathbb{P}(Y=1)\big{|}+\tfrac{1}{m}\sum_{i=1}^{m}\Big{|}\mathbb{E}_{ \hat{P}_{Y|Z}}[Y\mid Z=Z_{i}]-\mathbb{E}_{P_{Y|Z}}[Y\mid Z=Z_{i}]\Big{|}\] \[=\mathcal{O}_{P}(m^{-1/2})+\tfrac{1}{m}\sum_{i=1}^{m}\Big{|} \mathbb{P}_{\hat{P}_{Y|Z}}[Y=1\mid Z=Z_{i}]-\mathbb{P}_{P_{Y|Z}}[Y=1\mid Z=Z_{ i}]\Big{|}\] \[\leq\mathcal{O}_{P}(m^{-1/2})+\sum_{z\in\mathcal{Z}}\Big{|}\mathbb{ P}_{\hat{P}_{Y|Z}}[Y=1\mid Z=z]-\mathbb{P}_{P_{Y|Z}}[Y=1\mid Z=z]\Big{|}\] \[\leq\mathcal{O}_{P}(m^{-1/2})+\sum_{y\in\{0,1\}}\sum_{z\in \mathcal{Z}}\Big{|}\mathbb{P}_{\hat{P}_{Y|Z}}[Y=y\mid Z=z]-\mathbb{P}_{P_{Y|Z}}[ Y=y\mid Z=z]\Big{|}\] \[=\mathcal{O}_{P}(m^{-1/2})+2\sum_{z\in\mathcal{Z}}d_{\text{TV}} \left(\hat{P}_{Y|Z=z},P_{Y|Z=z}\right)\] \[=\mathcal{O}_{P}(m^{-1/2})+\mathcal{O}_{P}(m^{-\lambda})\] \[=\mathcal{O}_{P}(m^{-(\lambda\wedge 1/2)})\]

where the standard central limit theorem obtains the third step, the sixth step is obtained by the formula of the total variation distance for discrete measures, and the seventh step is obtained by Assumption 2.4.

**Lemma C.4**.: _For some \(\kappa>0\) and any \(y\in\mathcal{Y}\) assume that \(\kappa\leq p_{y}\leq 1-\kappa\). Define \(\mathcal{A}=\{a_{y}\in\mathbb{R}:\sum_{y}a_{y}=0\}\). Then the optima of the following problems_

\[\begin{split}\inf_{a\in\mathcal{A}}f_{u}(a),& f_{u}(a)\triangleq\mathbb{E}\Big{[}\epsilon\log\Big{\{} \frac{1}{|\mathcal{Y}|}\sum_{y}\exp\bigl{(}\frac{g(X,y)+a_{y}}{\epsilon}\bigr{)} \Big{\}}\Big{]}-\sum_{y}p_{y}a_{y}\,,\\ \sup_{a\in\mathcal{A}}f_{l}(a),& f_{l}(a)\triangleq \mathbb{E}\Big{[}-\epsilon\log\Big{\{}\frac{1}{|\mathcal{Y}|}\sum_{y}\exp \bigl{(}\frac{g(X,y)+a_{y}}{-\epsilon}\bigr{)}\Big{\}}\Big{]}-\sum_{y}p_{y}a_ {y}\end{split}\] (C.3)

_are attained in a compact set \(K(\kappa,L)\subset\mathcal{A}\) where \(\|g\|_{\infty}\leq L\)._

Proof of lemma c.4.: We shall only prove this for the minimization problem. The conclusion for the maximization problem follows in a similar way.

Strict convexity:The second derivation of \(f_{u}\) is

\[\nabla_{a_{y},a_{y^{\prime}}}f_{u}(a)=\tfrac{1}{\epsilon}\mathbb{E}\big{[}p(X, y,a)\{\delta_{y,y^{\prime}}-p(X,y^{\prime},a)\}\big{]}\] (C.4)

where \(p(x,y,a)\triangleq\frac{\exp\bigl{(}\frac{g(X,y)+a_{y}}{\epsilon}\bigr{)}}{ \sum_{i\in\mathcal{Y}}\exp\bigl{(}\frac{g(X,i)+a_{i}}{\epsilon}\bigr{)}}\). For any \(u\in\mathbb{R}^{\mathcal{Y}}\) we have

\[\begin{split} u^{\top}\nabla^{2}f_{u}(a)u&=\sum_{i,j\in\mathcal{Y}}u_{i}u_{j}\nabla_{a_{i},a_{j}}f_{u}(a)\\ &=\tfrac{1}{\epsilon}\sum_{i,j\in\mathcal{Y}}u_{i}u_{j}\mathbb{E} \big{[}p(X,i,a)\{\delta_{i,j}-p(X,j,a)\}\big{]}\\ &=\tfrac{1}{\epsilon}\mathbb{E}\big{[}\sum_{i}u_{i}^{2}p(X,i,a)- \big{\{}\sum_{i}u_{i}p(X,i,a)\big{\}}^{2}\big{]}=\tfrac{1}{\epsilon}\mathbb{E} [\sigma^{2}(X,u,a)]\geq 0\end{split}\] (C.5)

where \(\sigma^{2}(x,u,a)\) is the variance of a categorical random variable taking the value \(u_{i}\) with probability \(p(x,i,a)\). This leads to the conclusion that the function is convex.

To establish strict convexity, we fix \(a\in\mathcal{A}\) and notice that \(0<p(x,y,a)<1\) (because \(\|g\|_{\infty}\leq L\)). Therefore, the \(\sigma^{2}(x,u,a)\) can be zero only when the \(u_{i}\)'s are all equal. Since \(\mathcal{A}=\{a\in\mathbb{R}^{\mathcal{Y}}:\sum_{y}a_{y}=0\}\), such \(u\) belongs to the space \(\mathcal{A}\) in the unique case \(u_{i}=0\). This leads to the conclusion that for any \(u\in\mathcal{A}\) and \(u\neq 0\)

\[u^{\top}\nabla^{2}f_{u}(a)u=\tfrac{1}{\epsilon}\mathbb{E}[\sigma^{2}(X,u,a)]>0\,.\]

Therefore, \(f_{u}\) is strictly convex and has a unique minimizer in \(\mathcal{A}\). In the remaining part of the proof, we focus on the first-order condition.

First order condition:The first-order condition is

\[h(a,y)=p_{y}\text{ for all }y\in\mathcal{Y},\text{ where }h(a,y)\triangleq\mathbb{E}[p(X,y,a)]\] (C.6)

To show that (C.6) has a solution in a compact ball \(K(\epsilon,\kappa,L)\triangleq\{a\in\mathcal{A}:\|a\|_{2}\leq M(\epsilon, \kappa,L)\}\) we construct an \(M(\epsilon,\kappa,L)>0\) such that \(\min_{y}h(a,y)<\kappa\) whenever \(\|a\|_{2}>M(\epsilon,\kappa,L)\). Since \(\kappa\leq p_{y}\leq 1-\kappa\) for all \(y\in\mathcal{Y}\) this concludes that the solution to (C.6) must be inside the \(K(\epsilon,\kappa,L)\).

Construction of the compact set:Let us define \(y_{\min}\triangleq\arg\min_{y}a_{y}\) and \(y_{\max}\triangleq\arg\max_{y}a_{y}\). To construct \(M(\kappa,L,\epsilon)\) (we shall write it simply as \(M\) whenever it is convenient to do so) we notice that

\[\begin{split} h(a,y_{\min})&=\mathbb{E}[p(X,y_{\min},a)]\\ &=\mathbb{E}\Big{[}\tfrac{\exp\bigl{(}\frac{g(X,1)+a_{y_{\min}}}{ \epsilon}\bigr{)}}{\sum_{i\in\mathcal{Y}}\exp\bigl{(}\frac{g(X,i)+a_{i}}{ \epsilon}\bigr{)}}\Big{]}\\ &\leq\tfrac{\exp\bigl{(}\frac{L+a_{i}\min}{\epsilon}\bigr{)}}{ \exp\bigl{(}\frac{L+a_{i}\min}{\epsilon}\bigr{)}+\sum_{i\geq 2}\exp\bigl{(}-\frac{L+a_{i} }{\epsilon}\bigr{)}}\\ &=\tfrac{\exp\bigl{(}\frac{2L}{\epsilon}\bigr{)}}{\exp\bigl{(} \frac{2L}{\epsilon}\bigr{)}+\sum_{i\geq 2}\exp\bigl{(}\frac{a_{i}-a_{i}\min}{ \epsilon}\bigr{)}}\\ &\leq\tfrac{\exp\bigl{(}\frac{2L}{\epsilon}\bigr{)}}{\exp\bigl{(} \frac{2L}{\epsilon}\bigr{)}+\exp\bigl{(}\frac{g_{\max}-a_{i}\min}{\epsilon} \bigr{)}}\leq\tfrac{\exp\bigl{(}\frac{2L}{\epsilon}\bigr{)}}{\exp\bigl{(} \frac{2L}{\epsilon}\bigr{)}+\exp\bigl{(}\frac{R}{\epsilon}\bigr{)}}\,,\end{split}\] (C.7)

where

\[R\triangleq\min\{\max_{y}a_{y}-\min_{y}a_{y}:\sum_{i}a_{i}=0,\sum_{i}a_{i}^{2}>M^{ 2}\}\,.\]We rewrite the constraints of the optimization as:

\[R\triangleq\min\big{\{}\max_{y}a_{y}-\min_{y}a_{y}:\text{mean}\{a_{i}\}=0,\text{ var}\{a_{i}\}>\frac{M^{2}}{|\mathcal{Y}|}\big{\}}\,.\]

where we use the Popoviciu's inequality on variance to obtain

\[\tfrac{M^{2}}{|\mathcal{Y}|}<\text{var}\{a_{i}\}\leq\tfrac{(\max_{y}a_{y}-\min_ {y}a_{y})^{2}}{4},\ \text{or}\ \max_{y}a_{y}-\min_{y}a_{y}>\tfrac{2M}{\sqrt{|\mathcal{Y}|}}\,,\]

Thus \(R\geq\tfrac{2M}{\sqrt{|\mathcal{Y}|}}\) whenever \(\|a\|_{2}>M\). We use this inequality in (C.7) and obtain

\[h(a,y_{\min})\leq\tfrac{\exp\left(\frac{2t_{L}}{\epsilon}\right)}{\exp\left( \frac{2t_{L}}{\epsilon}\right)+\exp\left(\frac{R}{\epsilon}\right)}\leq\tfrac {\exp\left(\frac{2t_{L}}{\epsilon}\right)}{\exp\left(\frac{2t_{L}}{\epsilon} \right)+\exp\left(\frac{2M}{\sqrt{|\mathcal{Y}|}}\right)}\,.\]

Finally, we choose \(M=M(\epsilon,\kappa,L)>0\) large enough such that

\[h(a,y_{\min})\leq\tfrac{\exp\left(\frac{2t_{L}}{\epsilon}\right)}{\exp\left( \frac{2t_{L}}{\epsilon}\right)+\exp\left(\frac{2M}{\epsilon\sqrt{|\mathcal{Y}| }}\right)}<\kappa\,.\]

For such an \(M\) we concludes that \(h(a,y_{\min})<\kappa\) whenever \(\|a\|_{2}>M\).

**Lemma C.5**.: \(L_{\varepsilon}\) _and \(U_{\varepsilon}\) are attained by some optimizers in a compact set \(K(\epsilon,\kappa_{z},z\in\mathcal{Z};L)\supset\mathcal{A}\) ((2.2)), where \(\kappa_{z}=\min\{p_{y|z},1-p_{y|z}:y\in\mathcal{Y}\}\)._

Proof of lemma c.5.: We shall only prove the case of the minimization problem. The proof for the maximization problem uses a similar argument.

A decomposition of the minimization problem according to the values of \(Z\) follows.

\[\min_{\alpha\in\mathcal{A}}\mathbb{E}\Big{[}\epsilon\log\Big{\{} \tfrac{1}{|\mathcal{Y}|}\sum_{y\in\mathcal{Y}}\exp\bigl{(}\tfrac{g(X,y,Z)+a_{Y,Z}}{\epsilon}\bigr{)}\Big{\}}-\mathbb{E}\left[a_{Y,Z}\mid Z\right]\Big{]}\] (C.8) \[=\sum_{z}p_{z}\left\{\min_{\begin{subarray}{c}a_{z,z}\in\mathbb{ R}^{Y}\\ \sum_{y}a_{y,z}=0\end{subarray}}\mathbb{E}\Big{[}\epsilon\log\Big{\{}\tfrac{1}{| \mathcal{Y}|}\sum_{y\in\mathcal{Y}}\exp\bigl{(}\tfrac{g(X,y,z)+a_{Y,z}}{ \epsilon}\bigr{)}\Big{\}}\mid Z=z\Big{]}-\mathbb{E}[a_{Y,z}\mid Z=z]\right\}\] \[=\sum_{z}p_{z}\left\{\min_{\begin{subarray}{c}a_{z,z}\in\mathbb{ R}^{Y}\\ \sum_{y}a_{y,z}=0\end{subarray}}\mathbb{E}\Big{[}\epsilon\log\Big{\{}\tfrac{1}{| \mathcal{Y}|}\sum_{y\in\mathcal{Y}}\exp\bigl{(}\tfrac{g(X,y,z)+a_{Y,z}}{ \epsilon}\bigr{)}\Big{\}}\mid Z=z\Big{]}-\sum_{y}a_{y,z}p_{y|z}\right\}\]

where \(p_{z}=P(Z=z)\) and \(p_{y|z}=P(Y=y\mid Z=z)\). We fix a \(z\) and consider the corresponding optimization problem in the decomposition. Then according to lemma C.4 the optimal point is in a compact set \(K(\epsilon,\kappa_{z},L)\). Thus the optimal point of the full problem is in the Cartesian product \(\prod_{z}K(\epsilon,\kappa_{z},L)\subset\mathcal{A}\), which a compact set. Thus we let \(K(\epsilon,\kappa_{z},z\in\mathcal{Z};L)=\prod_{z}K(\epsilon,\kappa_{z},L)\).

**Lemma C.6**.: _The optimizers for the problems in (2.3) are tight with respect to \(m,n\to\infty\)._

Proof of the lemma c.6.: Let \(p_{y|z}=P(Y=y\mid Z=z)\) and \(\hat{p}_{y|z}^{(m)}=\hat{P}_{Y|Z=z}^{(m)}(y)\). Since

\[\tfrac{1}{2}\sum_{y}|\hat{p}_{y|z}^{(m)}-p_{y|z}\big{|}=d_{\text{TV}}\left(\hat {P}_{Y|Z=z}^{(m)},P_{Y|Z=z}\right)=\mathcal{O}_{P}(m^{-\lambda})\]

according to the assumption 2.4, for sufficiently large \(m\) with high probability \(p(m)\) (\(p(m)\to 1\) as \(m\to\infty\)) \(\tfrac{\kappa_{z}}{\epsilon}\leq\hat{p}_{y|z}^{(m)}\leq 1-\tfrac{\kappa_{z}}{2}\) for all \(y\). Fix such an \(m\) and \(\hat{p}_{y|z}^{(m)}\). In lemma C.5 we replace \(P_{X,Z}\) with \(\sum_{i=1}^{n}\delta_{X_{i},Z_{i}}\) and \(p_{y|z}\) with \(\hat{p}_{y|z}^{(m)}\) to reach the conclusion that the optimizer is in the compact set \(K(\epsilon,\nicefrac{{\kappa_{z}}}{{2}},z\in\mathcal{Z};L)\). Thus, for sufficiently large \(m\) and any \(n\)

\[\mathbb{P}\big{(}\text{optimizer is in }K(\epsilon,\nicefrac{{\kappa_{z}}}{{2}},z \in\mathcal{Z};L)\big{)}\geq p(m)\,.\]

This establishes that the optimizers are tight.

[MISSING_PAGE_FAIL:25]

Let \(Q^{(1)}_{X,Y,Z}\) and \(Q^{(2)}_{X,Y,Z}\) be two distributions in \(\Pi\), _i.e._, with marginals \(P_{X,Z}\) and \(P_{Y,Z}\). Let the densities of \(Q^{(1)}_{X,Y,Z}\) and \(Q^{(2)}_{X,Y,Z}\) as \(q^{(1)}_{X,Y,Z}\) and \(q^{(2)}_{X,Y,Z}\). Then, see that

\[\left|\int g\mathrm{d}Q^{(1)}_{X,Y,Z}-\int g\mathrm{d}Q^{(2)}_{X, Y,Z}\right|=\] \[=\left|\int\sum_{y,z}g(x,y,z)(q^{(1)}_{X,Y,Z}(x,y,z)-q^{(2)}_{X,Y,Z}(x,y,z))\mathrm{d}x\right|\] \[\leq\int\sum_{y,z}|g(x,y,z)|\cdot|q^{(1)}_{X,Y,Z}(x,y,z)-q^{(2)}_{ X,Y,Z}(x,y,z)|\mathrm{d}x\] \[\leq 2\left\|g\right\|_{\infty}\sum_{z}p_{Z}(z)\tfrac{1}{2}\int \sum_{y}\cdot|q^{(1)}_{X,Y\mid Z}(x,y\mid z)-q^{(2)}_{X,Y\mid Z}(x,y\mid z)| \mathrm{d}x\] \[=2\left\|g\right\|_{\infty}\mathbb{E}\left[d_{\text{TV}}(Q^{(1)} _{X,Y\mid Z},Q^{(2)}_{X,Y\mid Z})\right]\] \[\leq 2\left\|g\right\|_{\infty}\left\{\mathbb{E}\left[d_{\text{ TV}}(Q^{(1)}_{X,Y\mid Z},P_{X\mid Z}P_{Y\mid Z})\right]+\mathbb{E}\left[d_{\text{TV}}(Q^{(2)} _{X,Y\mid Z},P_{X\mid Z}P_{Y\mid Z})\right]\right\}\] (D.9) \[\leq 2\left\|g\right\|_{\infty}\left\{\mathbb{E}\left[\sqrt{ \tfrac{1}{2}\mathbb{KL}(Q^{(1)}_{X,Y\mid Z}||P_{X\mid Z}P_{Y\mid Z})}\right] +\mathbb{E}\left[\sqrt{\tfrac{1}{2}\mathbb{KL}(Q^{(2)}_{X,Y\mid Z}||P_{X\mid Z }P_{Y\mid Z})}\right]\right\}\] (D.10) \[\leq 2\left\|g\right\|_{\infty}\left\{\sqrt{\tfrac{1}{2}\mathbb{E }\left[\mathbb{KL}(Q^{(1)}_{X,Y\mid Z}||P_{X\mid Z}P_{Y\mid Z})\right]}+\sqrt{ \tfrac{1}{2}\mathbb{E}\left[\mathbb{KL}(Q^{(2)}_{X,Y\mid Z}||P_{X\mid Z}P_{Y \mid Z})\right]\right\}\] (D.11) \[\leq 2\left\|g\right\|_{\infty}\left\{\sqrt{\tfrac{1}{2}H(X\mid Z) }+\sqrt{\tfrac{1}{2}H(X\mid Z)}\right\}\] (D.12) \[\leq\sqrt{8\left\|g\right\|_{\infty}^{2}H(X\mid Z)}\]

where step D.9 is justified by triangle inequality, step D.10 is justified by Pinsker's inequality, step D.11 is justified by Jensen's inequality, and step D.12 is justified by the fact that both expected KL terms are conditional mutual information terms, which can be bounded by the conditional entropy. Following the same idea, we can show that \(\left|\int g\mathrm{d}Q^{(1)}_{X,Y,Z}-\int g\mathrm{d}Q^{(2)}_{X,Y,Z}\right| \leq\sqrt{8\left\|g\right\|_{\infty}^{2}H(Y\mid Z)}\). Consequently,

\[\left|\int g\mathrm{d}Q^{(1)}_{X,Y,Z}-\int g\mathrm{d}Q^{(2)}_{X, Y,Z}\right| \leq\min\left(\sqrt{8\left\|g\right\|_{\infty}^{2}H(X\mid Z)}, \sqrt{8\left\|g\right\|_{\infty}^{2}H(Y\mid Z)}\right)\] \[=\sqrt{8\left\|g\right\|_{\infty}^{2}\min\left(H(X\mid Z),H(Y\mid Z )\right)}.\]

Because this statement is valid for any distributions \(Q^{(1)}_{X,Y,Z}\) and \(Q^{(2)}_{X,Y,Z}\) in \(\Pi\), we have that

\[U-L\leq\sqrt{8\left\|g\right\|_{\infty}^{2}\min\left(H(X\mid Z),H(Y\mid Z) \right)}\]Model selection using performance bounds

In this section, we propose and empirically evaluate three strategies for model selection using our estimated bounds in Equation 2.3.

#### e.0.1 Introducing model selection strategies

Assume, for example, \(g(x,y,z)=\mathds{1}[h(x)=y]\) for a given classifier \(h\), _i.e._, we conduct model selection based on accuracy, even though we can easily extend the same idea to different choices of metrics, such as F1 score. The model selection problem consists of choosing the best model from a set \(\mathcal{H}\triangleq\{h_{1},\cdots,h_{K}\}\) in order to maximize out-of-sample accuracy. Define \(\hat{L}_{\varepsilon}(h)\) and \(\hat{U}_{\varepsilon}(h)\) as the estimated accuracy lower and upper bounds for a certain model \(h\). The first strategy is to choose the model with _highest_ accuracy lower bound, _i.e._,

\[h^{*}_{\text{lower}}=\arg\max_{h_{k}\in\mathcal{H}}\hat{L}_{\varepsilon}(h_{k})\]

Maximizing the accuracy lower bound approximates the distributionally robust optimization (DRO) [9] solution when the uncertainty set is given by \(\Pi\) in 1.1. That is, we optimize for the worst-case distribution in the uncertainty set. Analogously, we can choose the model that optimizes the best-case scenario

\[h^{*}_{\text{upper}}=\arg\max_{h_{k}\in\mathcal{H}}\hat{U}_{\varepsilon}(h_{k }).\]

Moreover, if we want to guarantee that both worst and best-case scenarios are not bad, we can optimize the average of upper and lower bounds, _i.e._,

\[h^{*}_{\text{avg}}=\arg\max_{h_{k}\in\mathcal{H}}\frac{\hat{L}_{\varepsilon}( h_{k})+\hat{U}_{\varepsilon}(h_{k})}{2}.\]

#### e.0.2 Experiment setup

In this experiment, we select multilayer-perceptrons (MLPs). The considered MLPs have one hidden layer with a possible number of neurons in \(\{50,100\}\). Training is carried out with Adam [26], with possible learning rates in \(\{.1,.001\}\) and weight decay (\(l_{2}\) regularization parameter) in \(\{.1,.001\}\). For those datasets that use the F1 score as the evaluation metric, we also tune the classification threshold in \(\{.2,.4,.5,.6,.8\}\) (otherwise, they return the most probable class as a prediction). In total, \(\mathcal{H}\) is composed of \(8\) trained models when evaluating accuracy and \(40\) models when evaluating the F1 score. We also consider directly using the label model (Snorkel [47]) to select models. For example, when the metric considered is accuracy, _i.e._, we use

\[h^{*}_{\text{label\_model}}=\arg\max_{h_{k}\in\mathcal{H}}\tfrac{1}{n}\sum_{i= 1}^{n}\mathbb{E}_{\hat{P}_{Y|Z}}\mathds{1}[h_{k}(X)=Y\mid Z=Z_{i}],\]

which is a natural choice when \(X\perp\!\!\!\perp Y\mid Z\). As benchmarks, we consider having a few labeled samples.

In Table 3, we report the average test scores of the chosen models over \(10\) repetitions for different random seeds (standard deviation report as subscript). The main message here is that, for those datasets in which our uncertainty about the score (given by the different upper and lower bounds) is small, _e.g._, "'commercial" and "tennis", using our approaches leads to much better results when compared to using small sample sizes.

Now, we explore a different way of comparing models. Instead of making an explicit model selection, this experiment uses the proposed metrics, _i.e._, accuracy lower/upper bounds, bounds average, to rank MLP classifiers. We rank the models using both the test set accuracy/F1 score (depending on Zhang et al. [63]) and alternative metrics, _i.e._, accuracy/F1 score lower/upper bounds, bounds average, label model, and small labeled sample sizes. Then, we calculate a Pearson correlation between rankings and display numbers in Table 4. If the numbers are higher, it means that the proposed selection method is capable of distinguishing good from bad models. Table 4 shows that the bounds average and label model methods usually return the best results when no labels are used. Moreover, in some cases using a small labeled sample for model selection can relatively hurt performance (when the validation set is small, there is a chance all models will have the same or similar performances, leading to smaller or null rank correlations).

[MISSING_PAGE_EMPTY:28]

### Extra plots for the hate speech detection experiment

In Table 6, we can see the same results already in the main text plus the results for FlyingSquid.

## Appendix G Computing resources

All experiments were conducted using a virtual machine with 32 cores. The experiments are not computationally intensive and everything can be run within a few hours.

Figure 4: Bounds on classifier accuracies across classification thresholds for the Wrench datasets. Despite potential misspecification in Snorkel’s and FlyingSquid’s label model, it performs comparably to using labels to estimate \(P_{Y|Z}\), giving approximate but meaningful bounds..

Figure 5: Bounds on classifier accuracies and F1 scores across classification thresholds for the Wrench datasets (using the full set of weak labels). Despite potential misspecification in Snorkel’s and FlyingSquid’s label model, it performs comparably to using labels to estimate \(P_{Y|Z}\), giving approximate but meaningful bounds.

[MISSING_PAGE_FAIL:30]

**Definition of spam: spam is a term referencing a broad category of postings whichabuse web-based forms to postunsolicited advertisements as comments onforums, blogs, wikis and online guestbook.**

**Definition of ham: texts that arenots spam.**

Target sentence: if yourlikedrones, plzsubscribet to Kamal Tayara. He takes videos with hisdrones that are absolutely beautiful. -- Response:

**Prompt 3**

You should classify the target sentence as "spam" or "ham". If definitions or examples areintroduced, you should consider them when classifying sentences. Respond with "spam" or "ham".

Example 0: 860,000,000 lets make it first female to reach one billion!! Share it and replay it! -- Response: ham

Example 1: Waka waka eh -- Response: ham

Example 2: You guys should check out this EXTRAORDINARY website called ZONEPA.COM. You can make money online and start working from home today as I am! I am making over $3,000+ per month at ZONEPA.COM! Visit Zonepa.com and check it out! How doest the mother approvethe axiomatic insurance? Thefear appoints theroll. When does the spacep prepare the historical shame? -- Response: spam

Example 3: Checkout these Irishguys cover of Avicii&#39;s Wake Me Up! Justsearch.. &quot;wake mem up Fiddle Me Silly&quot; Worth a listen for the gorgeousfiddle player! -- Response: spam

Example 4: if you want towinn money athopmclick here <a href="https://www.paidverts.com/ref/sihaam01"> https://www.paidverts.com/ref/sihaam01</a> it&#39;s work 100/100 -- Response: spam

Target sentence: if yourlikedrones, plzsubscribet to Kamal Tayara. He takes videos with hisdrones that are absolutely beautiful. -- Response:

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: In the abstract and Introduction section, we summarize the contributions and the scope of the paper. Guidelines:
2. The answer NA means that the abstract and introduction do not include the claims made in the paper.
3. The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.
4. The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.
5. It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
6. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: We have included a section to discuss limitations in the conclusion. Guidelines:
7. The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.
8. The authors are encouraged to create a separate "Limitations" section in their paper.
9. The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.
10. The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.
11. The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.
12. The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.
13. If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.
14. While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
15. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: The assumptions are discussed in the statements of the theorems and the proofs are provided in the Appendix.

Guidelines:

* The answer NA means that the paper does not include theoretical results.
* All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
* All assumptions should be clearly stated or referenced in the statement of any theorems.
* The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.
* Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.
* Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: We provide a general setting of the experiments in the paper and details are provided in the code itself submitted as supplementary material. Guidelines:

* The answer NA means that the paper does not include experiments.
* If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.
* If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.
* Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.
* While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: We provide simulation settings that are accessible and reproducible through the submitted zip file.

Guidelines:

* The answer NA means that paper does not include experiments requiring code.
* Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: We do specify those parameters in the paper. Guidelines:
* The answer NA means that the paper does not include experiments.
* The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them.
* The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: We provide errorbars for the plots. Guidelines:
* The answer NA means that the paper does not include experiments.
* The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.
* The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).
* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).

* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: We include a section in the appendix about this. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: Yes, we followed the NeurIPS Code of Ethics Guidelines:
* The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
* If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.
* The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: Our work may have potential societal consequences, none of which we feel must be specifically highlighted here. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.

* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: The paper poses no such risks. Guidelines:

* The answer NA means that the paper poses no such risks.
* Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.
* Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.
* We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: We make citations when needed. Guidelines:

* The answer NA means that the paper does not use existing assets.
* The authors should cite the original paper that produced the code package or dataset.
* The authors should state which version of the asset is used and, if possible, include a URL.
* The name of the license (e.g., CC-BY 4.0) should be included for each asset.
* For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.
* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [Yes] Justification: The paper does not release new assets. Guidelines:

* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.

* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: The paper does not involve crowdsourcing or research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: The paper does not involve crowdsourcing or research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.