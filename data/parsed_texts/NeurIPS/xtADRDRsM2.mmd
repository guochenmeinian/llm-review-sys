# Adversarial Robustness in Graph Neural Networks:

A Hamiltonian Approach

 Kai Zhao

Nanyang Technological University

&Qiyu Kang1

Nanyang Technological University

&Yang Song

C3 AI, Singapore

&Rui She

Nanyang Technological University

&Sijie Wang

Nanyang Technological University

&Wee Peng Tay

Nanyang Technological University

Footnote 1: First three authors contributed equally to this work.

###### Abstract

Graph neural networks (GNNs) are vulnerable to adversarial perturbations, including those that affect both node features and graph topology. This paper investigates GNNs derived from diverse neural flows, concentrating on their connection to various stability notions such as BIBO stability, Lyapunov stability, structural stability, and conservative stability. We argue that Lyapunov stability, despite its common use, does not necessarily ensure adversarial robustness. Inspired by physics principles, we advocate for the use of conservative Hamiltonian neural flows to construct GNNs that are robust to adversarial attacks. The adversarial robustness of different neural flow GNNs is empirically compared on several benchmark datasets under a variety of adversarial attacks. Extensive numerical experiments demonstrate that GNNs leveraging conservative Hamiltonian flows with Lyapunov stability substantially improve robustness against adversarial perturbations. The implementation code of experiments is available at https://github.com/zknus/NeurIPS-2023-HANG-Robustness.

## 1 Introduction

Graph neural networks (GNNs) [1, 2, 3, 4, 5, 6, 7, 8] have achieved great success in inference tasks involving graph-structured data, including applications from social media networks, molecular chemistry, and mobility networks. However, GNNs are known to be vulnerable to adversarial attacks [9]. To fool a trained GNN, adversaries can either add new nodes to the graph during the inference phase or remove/add edges from/to the graph. The former is called an injection attack [10, 11, 12, 13], and the latter is called a modification attack [14, 15, 16]. In some works [9, 17], node feature perturbations are also considered to enable stronger modification attacks.

Neural ordinary differential equation (ODE) networks [18] have recently gained popularity due to their inherent robustness [19, 20, 21, 22, 23, 24]. Neural ODEs can be considered as a continuous analog of ResNet [25]. Many neural ODE networks have since been proposed, including but not limited to [19, 26, 27, 28, 20]. Using neural ODEs, we can constrain the input and output of a neural network to follow certain physics laws. Injecting physics constraints to black-box neural networks improves neural networks' explainability. More recently, neural ODEs have also been successfully applied to GNNs by modelingthe way nodes exchange information given the adjacency structure of the underlying graph. We call them _graph neural flows_ which enables the interpretation of GNNs as evolutionary dynamical systems. These system equations can be learned by instantiating them using neural ODEs [29, 30, 31, 32, 33, 34]. For instance, [29, 30] models the message-passing process, i.e., feature exchanges between nodes, as the heat diffusion, while [31, 32] model the message passing process as the Beltrami diffusion. The reference [35] models the graph nodes as coupled oscillators with a coupled oscillating ODE guiding the message-passing process.

Although adversarial robustness of GNNs has been investigated in various works, including [9, 13, 17], robustness study of graph neural flows is still in its fancy. To the best of our knowledge, only the recent paper [32] has started to formulate theoretical insights into why graph neural diffusion is generally more robust against topology perturbation than conventional GNNs. The concept of Lyapunov stability was used in [20, 21]. However, there are many different notions of stability in the dynamic system literature [36, 37]. In this paper, we focus on the study of different notions of stability for graph neural flows and investigate which notion is most strongly connected to adversarial robustness. We impose an energy conservation constraint on graph neural flows that lead to a Hamiltonian graph neural flow. We find that energy-conservative graph Hamiltonian flows endowed with Lyapunov stability improve the robustness the most as compared to other existing stable graph neural flows.

**Main contributions.** This research is centered on examining various stability notions within the realm of graph neural flows, especially as they relate to adversarial robustness. Our main contributions are summarized as follows:

1. We revisit the definitions of stability from the perspective of dynamical systems as applicable to graph neural flows. We argue that vanilla Lyapunov stability does not necessarily confer adversarial robustness and provide a rationale for this observation.
2. We propose Hamiltonian-inspired graph neural ODEs, noted for their energy-conservative nature. We perform comprehensive numerical experiments to verify their performance on standard benchmark datasets. Crucially, our results demonstrate that Hamiltonian flow GNNs present enhanced robustness against various adversarial perturbations. Moreover, it is found that the effectiveness of Lyapunov stability becomes pronounced when layered on top of Hamiltonian flow GNNs, thereby fortifying their adversarial robustness.

The rest of this paper is organized as follows. We introduce various stability notions from a dynamical system perspective in Section 2. A review of existing graph neural flows is presented in Section 3 with links to the stability notions defined in Section 2. We present a new type of graph neural flow inspired by the Hamiltonian system with energy conservation in Section 4. Two different variants of this model are proposed in Section 5. Section 6 details our extensive experimental outcomes. The supplementary section provides an overview of related studies, an exhaustive outline of the algorithm, further insights into model robustness, supplementary experimental data, and the proofs for the theoretical propositions made throughout the paper.

## 2 Stability in Dynamical Systems

It is well known that a small perturbation at the input of an unstable dynamical system will result in a large distortion in the system's output. In this section, we first introduce various types of stability in dynamical physical systems and then relate them to graph neural flows. We consider the evolution of a dynamical system that is described as the following autonomous nonlinear differential equation:

\[\frac{\mathrm{d}\mathbf{z}(t)}{\mathrm{d}t}=f_{\boldsymbol{\theta}}(\mathbf{z }(t)),\] (1)

where \(f_{\boldsymbol{\theta}}:\mathbb{R}^{n}\rightarrow\mathbb{R}^{n}\) denotes the system dynamics, which may be non-linear in general, \(\boldsymbol{\theta}\) denotes the system parameters, and \(\mathbf{z}:[0,\infty)\rightarrow\mathbb{R}^{n}\) represents the \(n\)-dimensional system state.

We first introduce the stability notions from a dynamical systems perspective that is related to the GNN robustness against _node feature perturbation_.

**Definition 1** (BIBO stability).: _The system is called BIBO (bounded input bounded output) stable if for any bounded input, there exists a constant \(M\) s.t. the output \(\|\mathbf{z}(t)\|<M,\forall\,t\geq 0\)._

Suppose \(f\) has an equilibrium at \(\mathbf{z}_{c}\) so that \(f_{\boldsymbol{\theta}}\left(\mathbf{z}_{c}\right)=0\). We can define the stability notion for \(\mathbf{z}_{c}\).

**Definition 2** (Lyapunov stability and asymptotically stable [38]).: _The equilibrium \(\mathbf{z}_{e}\) is Lyapunov stable if for every \(\epsilon>0\), there exists a \(\delta>0\) such that, if \(\|\mathbf{z}(0)-\mathbf{z}_{e}\|<\delta\), then for every \(t\geq 0\) we have \(\|\mathbf{z}(t)-\mathbf{z}_{e}\|<\epsilon\). Furthermore, the equilibrium point \(\mathbf{z}_{e}\) is said to be asymptotically stable if it is Lyapunov stable and there exists a \(\delta^{\prime}>0\) such that if \(\|\mathbf{z}(0)-\mathbf{z}_{e}\|<\delta^{\prime}\), then \(\lim_{t\to\infty}\|\mathbf{z}(t)-\mathbf{z}_{e}\|=0\)._

**Remark 1**.: _Lyapunov stability indicates that the solutions whose initial points are near an equilibrium point \(\mathbf{z}_{e}\) stay near \(\mathbf{z}_{e}\) forever. For the special linear time-invariant system \(\,\mathrm{d}\mathbf{z}(t)/\,\mathrm{d}t=\mathbf{A}\mathbf{z}(t)\) with a constant matrix \(\mathbf{A}\), it is Lyapunov stable if and only if all eigenvalues of \(\mathbf{A}\) have non-positive real parts and those with zero real parts are the simple roots of the minimal polynomial of \(\mathbf{A}\)[39, 40]. Asymptotically stable means that not only do trajectories stay near \(\mathbf{z}_{e}\) for all time (Lyapunov stability), but trajectories also converge to \(\mathbf{z}_{e}\) as time goes to infinity (asymptotic stability)._

We next introduce the concept of structural stability from dynamical systems theory, which is related to the robustness of GNNs against _graph topological perturbation_. It describes the sensitivity of the qualitative features of a solution to changes in parameters \(\boldsymbol{\theta}\). The definition of structural stability requires the introduction of a topology on the space of \(\mathbf{z}\) in (1), which we do not however present here rigorously due to space constraints and not to distract the reader with too much mathematical details. Instead, we provide a qualitative description of structural stability to elucidate how it can indicate the robustness of a graph neural flow against topology perturbations.

**Definition 3** (Structural stability).: _Unlike Lyapunov stability, which considers perturbations of initial conditions for a fixed \(f_{\boldsymbol{\theta}}\), structural stability deals with perturbations of the dynamic function \(f_{\boldsymbol{\theta}}\) by perturbing the parameter \(\boldsymbol{\theta}\). The qualitative behavior of the solution is unaffected by small perturbations of \(f_{\boldsymbol{\theta}}\) in the sense that there is a homeomorphism that globally maps the original solution to the solution under perturbation._

**Remark 2**.: _In the graph neural flows to be detailed in Section 3 and Section 4, the parameter \(\boldsymbol{\theta}\) includes the graph topology (i.e., the adjacency matrix) and learnable neural network weights. Unlike adversarial attacks on other deep learning neural networks where the attacker targets only the input \(\mathbf{z}\), it is worth noting that adversaries for GNNs can also attack the graph topology, which forms part of \(\boldsymbol{\theta}\). If there are different Lyapunov stable equilibrium points, one for each class of nodes, one intuitive example of breaking structural stability in graph neural flows is by perturbing the graph topology in such a way that there are strictly fewer equilibrium points than the number of classes._

In this study, we will propose GNNs drawing inspiration from Hamiltonian mechanics. In a Hamiltonian system, \(\mathbf{z}=(q,p)\in\mathbb{R}^{2n}\) refers to the generalized coordinates, with \(q\) and \(p\) corresponding to the generalized position and momentum, respectively. The dynamical system is characterized by the following nonlinear differential equation:

\[\frac{\,\mathrm{d}\mathbf{z}(t)}{\,\mathrm{d}t}=J\nabla H(\mathbf{z}(t)),\] (2)

where \(\nabla H(\mathbf{z})\) is the gradient of a scalar function \(H\) at \(\mathbf{z}\) and \(J=\left(\begin{array}{cc}0&I\\ -I&0\end{array}\right)\) is the \(2n\times 2n\) skew-symmetric matrix with \(I\) being the \(n\times n\) identity matrix.

We now turn our attention to the notion of conservative stability in dynamical systems. It is worth noting that a general dynamical system, as characterized in (1), might not consistently resonate with traditional perspectives on energy and conservation, especially when compared to physics-inspired neural networks, like (2).

**Definition 4** (Conservative stability).: _In a dynamical system inspired by physical principles, such as (2), a conserved quantity might be present. This quantity, which frequently embodies the notion of the system's energy, remains invariant along the system's evolution trajectory \(\mathbf{z}(t)\)._

Our focus in this work is on graph neural flows that can be described by either (1) or (2). Chamberlain et al. [29] postulate that many GNN architectures such as GAT can be construed as discrete versions of (1) via different choices of the function \(f_{\boldsymbol{\theta}}\) and discretization schemes. Therefore, the stability definitions provided above can offer additional insights into many popular GNNs. Most existing graph neural flows only scrutinize the BIBO/Lyapunov stability of their system. For instance, GRAND [29] proposes BIBO/Lyapunov stability against node feature perturbation over \(\mathbf{z}\). However, the more fundamental structural stability in graph neural flows, which is related to the robustness against graph topological changes, remains largely unexplored. Some models, such as GraphCON [29, 35], exhibit conservative stability under certain conditions. We direct the reader to Section 3 and Table 1 for a comprehensive discussion of the stability properties of each model.

## 3 Existing Graph Neural Flows and Stability

Consider an undirected, weighted graph \(\mathcal{G}=(\mathcal{V},\mathcal{E})\) where \(\mathcal{V}\) is a finite set of vertices and \(\mathcal{E}\subset\mathcal{V}\times\mathcal{V}\) denotes the set of edges. The adjacency matrix of the graph is denoted as \((\mathbf{W}[u,v])=\mathbf{W}([v,u])\) for all \([u,v]\in\mathcal{E}\). Let \(\mathbf{X}(t)\in\mathbb{R}^{|\mathcal{V}|\times r}\) represent the features associated with the vertices at time \(t\). The feature vector for the \(i\)-th node in \(\mathcal{V}\) at time \(t\) can be represented as the \(i\)-th row of \(\mathbf{X}(t)\), indicated by \(\mathbf{x}_{i}^{\intercal}(t)\). In this section, we introduce several graph neural flows on \(\mathcal{G}\), categorizing them according to the stability concepts outlined in Section 2.

**GRAND:** Inspired by the heat diffusion equation, GRAND [29] employs the following dynamical system:

\[\frac{\mathrm{d}\mathbf{X}(t)}{\mathrm{d}t}=\overline{\mathbf{A}}_{G}( \mathbf{X}(t))\mathbf{X}(t)\coloneqq(\mathbf{A}_{G}(\mathbf{X}(t))-\alpha \mathbf{I})\mathbf{X}(t),\] (3)

with the initial condition \(\mathbf{X}(0)\). Within this model, \(\mathbf{A}_{G}(\mathbf{X}(t))\) is either a time-invariant static matrix, represented as GRAND-l, or a trainable time-variant attention matrix \((a_{G}\left(\mathbf{x}_{i}(t),\mathbf{x}_{j}(t)\right))\), labeled as GRAND-nl, reflecting the graph's evolutionary features. The function \(a_{G}(\cdot)\) calculates similarity for pairs of vertices, and \(\mathbf{I}\) is an identity matrix with dimensions that fit the context. In [29], \(\alpha\) is set to be 1. Let \(\mathbf{D}\) be the diagonal node degree matrix where \(\mathbf{D}[u,u]=\sum_{v\in\mathcal{V}}\mathbf{W}[u,v]\).

**Theorem 1**.: _We can prove the following stability:_

1. _For GRAND-nl, if the attention matrix_ \(\mathbf{A}_{G}(\mathbf{X}(t))\) _is set as a doubly stochastic attention_ _[_41_]__, we have BIBO stability and Lyapunov stability for any_ \(\alpha\geq 1\)_. When_ \(\alpha>1\)_, it reaches global asymptotic stability under any perturbation._
2. _Within the GRAND-l setting, if_ \(\mathbf{A}_{G}\) _is set as a constant column- or row-stochastic matrix, such as the normalized adjacency matrices_ \(\mathbf{W}\mathbf{D}^{-1}\) _or_ \(\mathbf{D}^{-1}\mathbf{W}\)_, global asymptotic stability is achieved for_ \(\alpha>1\) _under any perturbation. If the graph is additionally assumed to be strongly connected_ _[_42_]__[_Sec.6.3]__, BIBO and Lyapunov stability are realized for_ \(\alpha=1\)_._
3. _Furthermore, when_ \(\mathbf{A}_{G}\) _is specifically a constant column-stochastic matrix like_ \(\mathbf{W}\mathbf{D}^{-1}\) _and_ \(\alpha=1\)_, GRAND conserves a quantity that can be interpreted as energy. Furthermore, in this setting, asymptotic stability is attained when the graph is aperiodic and strongly connected and the perturbations on_ \(\mathbf{X}(0)\) _ensure unaltered column summations._

**BLEND:**_In comparison to GRAND, BLEND [31] introduces the use of positional encodings. Following a similar line of reasoning to that used for GRAND, BLEND also exhibits BIBO/Lyapunov stability as stated in Theorem 1. Moreover, it is noteworthy that if positional features_ \(\mathbf{U}(t)\) _are eliminated, for instance by setting them as a constant, BLEND simplifies to the GRAND model._

**GraphCON:** Inspired by oscillator dynamical systems, GraphCON is a graph neural flow proposed in [35] and defined as

\[\left\{\begin{array}{l}\frac{\mathrm{d}\mathbf{Y}(t)}{\mathrm{d}t}=\sigma( \mathbf{F}_{\theta}(\mathbf{X}(t),t))-\gamma\mathbf{X}(t)-\alpha\mathbf{Y}(t), \\ \frac{\mathrm{d}\mathbf{X}(t)}{\mathrm{d}t}=\mathbf{Y}(t),\end{array}\right.\] (4)

where \(\mathbf{F}_{\theta}(\cdot)\) is a learnable \(1\)-neighborhood coupling function, \(\mathbf{Y}(t)\) is an auxiliary velocity variable, \(\sigma\) denotes an activation function, and \(\gamma\) and \(\alpha\) are tunable parameters.

_As described in [35, Proposition 3.1], under specific settings where \(\sigma\) is the identity function and \(\mathbf{F}_{\theta}(\mathbf{X}(t),t)=\mathbf{A}\mathbf{X}(t)\) with \(\mathbf{A}\) being a constant matrix, GraphCON conserves Dirichlet energy_ (11)_, thereby demonstrating conservative stability._

**GraphBel:** Generalizing the Beltrami flow, mean curvature flow and heat flow, a stable graph neural flow [32] is designed as

\[\frac{\mathrm{d}\mathbf{X}(t)}{\mathrm{d}t}=(\mathbf{A}_{\mathbf{S}}(\mathbf{X }(t))\odot\mathbf{B}_{\mathbf{S}}(\mathbf{X}(t))-\Psi(\mathbf{X}(t)))\mathbf{ X}(t),\] (5)

where \(\odot\) is the element-wise multiplication. \(\mathbf{A}_{\mathbf{S}}(\cdot)\) and \(\mathbf{B}_{\mathbf{S}}(\cdot)\) are learnable attention function and normalized vector map, respectively. \(\mathbf{\Psi}(\mathbf{X}(t))\) is a diagonal matrix in which \(\Psi(\mathbf{x}_{i},\mathbf{x}_{i})=\sum_{\mathbf{x}_{j}}(\mathbf{A}\odot \mathbf{B})(\mathbf{x}_{i},\mathbf{x}_{j})\).

_Analogous to BLEND, under certain conditions with \(\Psi(\mathbf{X}(t))=\mathbf{B}_{\mathbf{S}}(\mathbf{X}(t))=\mathbf{I}\), GraphBel simplifies to the GRAND model. Consequently, it exhibits BIBO/Lyapunov stability in certain scenarios._The incorporation of ODEs via graph neural flows may enhance the stability of graph feature representations. A summarized relationship between model stability and these graph neural flows can be found in Table 1.

### Lyapunov Stability vs. Node Classification Robustness:

At first glance, Lyapunov stability has a strong correlation with node classification robustness against feature perturbations. However, before diving into experimental evidence, we point out an important conclusion: **Lyapunov stability _by itself_ does not necessarily imply adversarial robustness.** Consider a scenario where a graph neural flow has only one equilibrium point \(\mathbf{z}_{e}\), while the node features are derived from more than one class. In a Lyapunov asymptotically stable graph neural flow, such as GRAND (as shown in Theorem 1), all node features across different classes would inevitably converge to a single point \(\mathbf{z}_{e}\) due to global contraction. We note that this is why the model in [20] requires a diversity-promoting layer to ensure that different classes converge to different Lyapunov-stable equilibrium points.

**Example 1**.: _We provide an example to demonstrate our claim. Consider the following Lyapunov stable ODE_

\[\dot{\mathbf{x}}(t)=\begin{pmatrix}-1&0\\ 0&-5\end{pmatrix}\mathbf{x}(t)\] (6)

_with initial condition \(\mathbf{x}(0)=\left[x_{1}(0),x_{2}(0)\right]^{\intercal}\). The solution to this ODE is given by \(\mathbf{x}(t)=x_{1}(0)e^{-t}[1,0]^{\intercal}+x_{2}(0)e^{-5t}[0,1]^{\intercal}\). For all initial points in \(\mathbb{R}^{2}\), we have \(\mathbf{x}(t)\rightarrow\mathbf{0}\) as \(t\rightarrow\infty\). Furthermore, as \(t\rightarrow\infty\), the trajectory \(\mathbf{x}(t)\) for any initial point is approximately parallel to the x-axis. We draw the phase plane in Fig. 0(a)._

_Assume that the points on the upper half y-axis belongs to class 1 while we have a linear classifier that seperates class 1 and class 2 as shown in Fig. 0(a). We observe that for the initial point \(A\) belonging to class 1, the solution from a small perturbed initial point \(A+\epsilon\) is misclassified as class 2 for a large enough \(t\) for any linear classifier. We see from this example that Lyapunov stability itself does not imply adversarial robustness in graph neural flow models._

_This example indicates that Lyapunov stability does not guarantee node classification robustness. Additionally, for a system exhibiting global contraction to a single equilibrium point, structural stability may also be ensured. For instance, in the case of GRAND, even if the edges are perturbed, the system maintains the same number of equilibrium points with global contraction._ We conclude that even an amalgamation of both Lyapunov stability and structural stability may not help the graph's adversarial robustness for node classification.

In the example shown in Fig. 1, we observe that in the case of GRAND when \(\alpha>1\), the node features from different classes tend to become closer to each other as time progresses. This phenomenon can potentially create more vulnerability to adversarial attacks.

Figure 1: (a): We plot the vector field and the system solution trajectories of Example 1. (b) and (c): In GRAND, the node features’ energy tends to converge towards each other. In HANG, we observe the node features’ energy remains relatively stable over time. Two nodes are from different classes.

## 4 Hamiltonian-Inspired Graph Neural Flow

Drawing inspiration from the principles of Hamiltonian classical mechanics, we introduce a novel graph neural flow paradigm, namely HamiltonianAN Graph diffusion (HANG). In Hamiltonian mechanics, the notation \((q,p)\) is traditionally used to represent the properties of nodes (position and momentum). Hence, in this section, we adopt this notation instead of \(\mathbf{X}\) (as used in Section 3) to denote node features.

### Physics Philosophy Behind HANG

In Hamiltonian mechanics, the state evolution of a multi-object physical system, such as an electromagnetic field, double pendulum, or spring network [43, 44], adheres to well-established physical laws. For instance, in a system of charged particles, each particle generates an electromagnetic field that influences other particles. The Hamiltonian for such a system includes terms representing the kinetic and potential energy of each particle, along with terms representing the interactions between particles via their electromagnetic fields. In this paper, we propose a novel concept of information propagation between graph nodes, where interactions follow a similar Hamiltonian style.

In a Hamiltonian system, the position \(q\) and momentum \(p\) together constitute the phase space \((q,p)\), which comprehensively characterizes the system's evolution. In our HANG model, we process the raw node features of the graph using a linear input layer, yielding \(2r\)-dimensional vectors. Following the methodologies introduced in the GNN work [31, 35], we split the \(2r\) dimensions into two equal halves, with the first half serving as the feature (position) vector and the second half as "momentum" vector that guides the system evolution. Concretely, each node \(k\) is associated with an \(r\)-dimensional feature vector \(\mathbf{q}_{k}(0)=(q_{k}^{1},\ldots,q_{k}^{r})\) and an \(r\)-dimensional momentum vector \(\mathbf{p}_{k}(0)=(p_{k}^{1},\ldots,p_{k}^{r})\). Subsequently, \(\mathbf{q}_{k}(t)\) and \(\mathbf{p}_{k}(t)\) will evolve along with the propagation of information between graph nodes, with \(\mathbf{q}_{k}(0)\) and \(\mathbf{p}_{k}(0)\) serving as the initial conditions.

Following the modeling conventions in physical systems, we concatenate the feature positions of all \(|\mathcal{V}|\) vertices into a single vector, treating it as the system's generalized coordinate within a \(r|\mathcal{V}|\)-dimensional manifold, a process that involves index relabeling3.

Footnote 3: In multilinear algebra and tensor computation, vector components employ upper indices, while covector components use lower indices. We adhere to this convention.

\[q(t)=\left(q^{1}(t),\ldots q^{r|\mathcal{V}|}(t)\right)=\left(\mathbf{q}_{1}(t ),\ldots,\mathbf{q}_{|\mathcal{V}|}(t)\right).\] (7)

This \(r|\mathcal{V}|\)-dimensional coordinate representation at each time instance provides a snapshot of the state of the graph system. Similarly, we concatenate all the "momentum" vectors at time \(t\) to construct an \(r|\mathcal{V}|\)-dimensional vector:

\[p(t)=\left(p_{1}(t),\ldots p_{r|\mathcal{V}|}(t)\right)=\left(\mathbf{p}_{1}(t ),\ldots,\mathbf{p}_{|\mathcal{V}|}(t)\right),\] (8)

Figure 2: The model architecture: each node is assigned a learnable “momentum” vector at time \(t=0\) which initializes the evolution of the system together with node features. The graph features evolve on following a _learnable_ law (10) derived from the \(H_{\mathrm{net}}\). At the time \(t=T\), we use \(q(T)\) as the final node feature. \(H_{\mathrm{net}}(q(t),p(t))\) is a learnable graph energy function.

which can be interpreted as a generalized momentum vector for the entire graph system.

In physics, the system evolves in accordance with fundamental physical laws, and a conserved quantity function \(H(q,p)\) remains constant along the system's evolution trajectory. This conserved quantity is typically interpreted as the "system energy". In our HANG model, instead of defining an explicit energy function \(H(p,q)\) from a fixed physical law, we utilize a learnable energy function \(H_{\mathrm{net}}:\mathcal{G}\rightarrow\mathbb{R}^{+}\) parameterized by a neural network, referred to as the _Hamiltonian energy function_:

\[H_{\mathrm{net}}:\mathcal{G}\rightarrow\mathbb{R}^{+}\] (9)

We allow the graph features to evolve according to a learnable Hamiltonian law analogous to basic physical laws. More specifically, we model the feature evolution trajectory as the following canonical Hamilton's equations, which is a restatement of (2):

\[\dot{q}(t)=\frac{\partial H_{\mathrm{net}}}{\partial p},\quad\dot{p}(t)=- \frac{\partial H_{\mathrm{net}}}{\partial q},\] (10)

with the initial features \((q(0),p(0))\in\mathbb{R}^{2r|\mathcal{V}|}\) at time \(t=0\) being the vectors after the raw node features transformation.

The neural ODE given by (10) can be trained and solved through integration to obtain the trajectory \((q(t),p(t))\). At the terminal time point \(t=T\), the system's solution is represented as \((q(T),p(T))\). We then apply the canonical projection map \(\pi\) to extract the nodes' concatenated feature vector \(q(T)\) as follows: \(\pi((q(T),p(T)))=q(T)\). This concatenated feature vector \(q(T)\) is subsequently decompressed into individual node features for utilization in downstream tasks. For this study, we employ backpropagation to minimize the cross-entropy in node classification tasks. The complete model architecture is depicted in Fig. 2, while a comprehensive summary of the full algorithm can be found in the Appendix G.

### Hamiltonian Energy Conservation

Referring to [45], it is known that the total Hamiltonian energy \(H_{\mathrm{net}}\) remains constant along the trajectory of its induced Hamiltonian flow. This principle is recognized as the law of energy conservation in a Hamiltonian system.

**Theorem 2**.: _If the graph system evolves in accordance with (10), the total energy \(H_{\mathrm{net}}(q(t),p(t))\) of the system remains constant. BIBO stability is achieved if \(H_{\mathrm{net}}\) remains bounded for all bounded inputs and, as \((q,p)\rightarrow\infty\), \(H_{\mathrm{net}}(q,p)\rightarrow\infty\)._

In light of Theorem 2, if our system evolves following (10), it adheres to the law of energy conservation. As a result, our model guarantees conservative stability. Compared to GraphCON, which conserves Dirichlet energy over time \(t\) under specific conditions, the notion of Hamiltonian energy conservation is broader in scope. Under the settings delineated in Section 3, GraphCON can be considered as a particular instance of HANG when \(H_{\mathrm{net}}\) is set to represent Dirichlet energy \(\mathcal{E}(q)\):

**Definition 5** (Dirichlet energy [35]).: _The Dirichlet energy is defined on node features \(q(t)\) at time \(t\) of an undirected graph \(\mathcal{G}\) as_

\[\mathcal{E}(q(t))=\frac{1}{|\mathcal{V}|}\sum_{i}\sum_{j\in\mathcal{N}(i)}\| \mathbf{q}_{i}(t)-\mathbf{q}_{j}(t)\|^{2},\] (11)

_where \(\mathcal{N}(i)=\{j:[i,j]\in\mathcal{E}\}\) is the set of neighbors adjacent to node \(i\) in the graph._

## 5 Different Hamiltonian Energy Functions

In physical systems, the system is often depicted as a graph where two neighboring vertices with mass are connected by a spring of given stiffness and length [44]. The system's energy is thus related to the graph's topology. Similarly, in our graph system, the energy function \(H_{\mathrm{net}}\) involves interactions between neighboring nodes, signifying the importance of the graph's topology. There exist multiple ways to learn the energy function, and we present two examples below.

### Vanilla HANG

We define \(H_{\mathrm{net}}\) as a composition of two graph convolutional layers:

\[H_{\mathrm{net}}=\left\|\left(g_{\mathrm{gcn_{2}}}\circ\tanh\circ g_{\mathrm{ gcn_{1}}}\right)\left(q,p\right)\right\|_{2},\] (12)

where \(g_{\mathrm{gcn_{1}}}:\mathbb{R}^{2r\times|\mathcal{V}|}\rightarrow\mathbb{R}^{d \times|\mathcal{V}|}\) and \(g_{\mathrm{gcn_{2}}}:\mathbb{R}^{d\times|\mathcal{V}|}\rightarrow\mathbb{R}^{| \mathcal{V}|}\) are two GCN [3] layers with different hidden dimensions. A \(\tanh\) activation function is applied between the two GCN layers, and \(\|\cdot\|_{2}\) denotes the \(\ell_{2}\) norm. We concatenate \(\mathbf{q}_{k}\) and \(\mathbf{p}_{k}\) for each node \(k\) at the input of the above composite function, resulting in an input dimension of \(2r\) per node. From Theorem 2, it follows that HANG exhibits BIBO stability. If \(\left(q(t),p(t)\right)\) were unbounded, the value of \(H_{\mathrm{net}}\) would also become unbounded, contradicting the energy conservation principle. In subsequent discussions, this invariant is referred to as HANG.

### Quadratic HANG (HANG-quad)

The general vanilla HANG with conservative stability does not possess Lyapunov stability. Other additional conditions may be required for Lyapunov stability. The following Lagrange-Dirichlet Theorem provides a sufficient condition.

**Theorem 3** (Lagrange-Dirichlet Theorem [46]).: _Let \(\mathbf{z}_{e}\) be a locally quadratic equilibrium of the natural Hamiltonian (2) with_

\[H=T(q,p)+U(q),\] (13)

_where \(T\) is a positive definite, quadratic function of \(p\). Then \(\mathbf{z}_{e}\) is Lyapunov stable if the position of it is a strict local minimum of \(U(q)\)._

Theorem 3 implies that we can design an energy function \(H_{\mathrm{net}}\) such that the induced graph neural flow is both Lyapunov stable and energy conservative. For instance, we can define \(T\) as

\[T(q,p)=\sum_{i}\mathbf{h}_{i}^{\intercal}\mathbf{h}_{i}+\lambda \mathbf{p}_{i}^{\intercal}\mathbf{p}_{i},\] (14)

where \(\mathbf{h}_{i}=\sum_{j\in\mathcal{N}(i)}a_{G}\left(\mathbf{q}_{i},\mathbf{q}_{ j}\right)\mathbf{p}_{j}\) is the aggregation of \(\mathbf{p}_{j}\) through the attention mechanism \(a_{G}\left(\mathbf{q}_{i},\mathbf{q}_{j}\right)\) calculated based on \(q\) (or we directly use adjacency matrix with \(a_{G}\left(\mathbf{q}_{i},\mathbf{q}_{j}\right)\equiv\mathbf{W}[i,j]\)). The term \(\lambda\) is a small positive number included to ensure the positive definiteness. If \(U(q)\) has only a single global minimum, such as \(U(q)=\|q\|\) with an \(\ell_{2}\) norm, this stability may not ensure adversarial robustness as discussed in Section 3.1. An alternative is setting \(U(q)=\|\sin(q)\|\), which fosters Lyapunov stability across multiple local equilibrium points. However, this choice considerably restricts the form that \(U\) can take and may consequently limit the model's capacity. In the implementation, we set the function \(U(q)\) in \(H\) to be a single GAT [6] layer \(g_{\mathrm{gat}}:\mathbb{R}^{r\times|\mathcal{V}|}\rightarrow\mathbb{R}^{r \times\mathcal{V}}\) with a \(\sin\) activation function followed by an \(\ell_{2}\) norm, i.e., \(U(q)=\left\|g_{\mathrm{gat}}(q)\right\|_{2}.\) The stability of HANG and HANG-quad is summarized in Table 1.

## 6 Experiments

In this section, we conduct a comprehensive evaluation of our theoretical findings and assess the robustness of two conservative stable models: HANG and HANG-Quad. We compare their performance against various benchmark GNN models, including GAT [47], GraphSAGE [48], GCN [3] and other prevalent graph neural flows. We incorporate different types of graph adversarial attacks as described in Section 6.1 and Section 6.3. These attacks are conducted in a black-box setting, where a surrogate model is trained to generate perturbed graphs or features. For more experiments, we direct readers to Appendix C.

\begin{table}
\begin{tabular}{c c c c c} \hline \hline Graph Neural Flows & BIBO stability & Lyapunov stability & Structural stability & Conservative stability \\ \hline GRAND & \(\measuredangle\) & \(\measuredangle\) & \(\measuredangle\) & \(\measuredangle\) \\ BLEND & \(\measuredangle\) & \(\measuredangle\) & \(\measuredangle\) & \(\measuredangle\) \\ GraphCON & \(\measuredangle\) & \(\measuredangle\) & \(\measuredangle\) & \(\measuredangle\) \\ GraphB & \(\measuredangle\) & \(\measuredangle\) & \(\measuredangle\) & \(\measuredangle\) \\ HANG-quad & \(\measuredangle\) & \(\measuredangle\) & \(\measuredangle\) & \(\measuredangle\) \\ \hline \hline \end{tabular}
\end{table}
Table 1: The stability summary for different graph neural flows where the \(\measuredangle\)denotes that stability is affirmed under additional conditions.

[MISSING_PAGE_FAIL:9]

### Performance Results Under GIAs

Upon examining the results in Table 2 and Table 3 pertaining to experiments conducted under GIA conditions, the robustness of our proposed HANG and HANG-quad, is notably prominent across different GIA scenarios. Interestingly, GRAND, despite its Lyapunov stability as analyzed in Theorem 1, does not significantly outperform GAT under certain attacks. In contrast, HANG consistently displays robustness against attacks. Notably, HANG-quad exhibits superior performance to HANG on the Pubmed dataset under GIA perturbations, underscoring the effectiveness of integrating both Lyapunov stability and Hamiltonian mechanics to boost robustness. Although other graph neural flows might demonstrate a range of improved performance compared to conventional GNN models under GIA, the degree of improvement is not consistently distinct. Despite the pronounced association between conservative stability in Hamiltonian systems and adversarial robustness, a clear relationship between adversarial robustness with the other stability of the graph neural flows outlined in Table 1 is not immediately discernible. The performance differential between HANG variants and other graph neural flows further underscores the potential of our proposed Hamiltonian models in enhancing robustness against GIA attacks.

### Graph Modification Attacks

To evaluate the robustness of our proposed conservative models, we conducted graph modification adversarial attacks using the Metattack method [17]. We followed the attack setting described in the Pro-GNN [55] and utilized the perturbed graph provided by the library [56] to ensure a fair comparison. The perturbation rate, which indicates the proportion of altered edges, was incrementally varied in 5% increments from 0% to 25%. For comparison, we also considered other defense models for GNNs, namely Pro-GNN [55], RGCN [57], and GCN-SVD [58]. We report the results of baseline models from [55].

### Performance Results Under Modification/Poisoning/Transductive Attacks

In the case of the Polblogs dataset [59], as shown in Table 4, our proposed HANG-quad model demonstrates superior performance compared to other methods, including existing defense models. This result indicates that incorporating Lyapunov stability indeed enhances HANG's robustness against graph modification and poisoning attacks. For the Pubmed dataset, we note that the impact of Meta-attacks of varying strengths on _all_ graph neural flows, including our proposed ones, is negligible. Conversely, traditional GNN models such as GAT, GCN, and RGCN are marginally affected as the attack strength escalates. This observation underlines the robustness of graph neural flows, including our proposed models, against Meta-attacks on this dataset.

### Combination with other defense mechanisms

It merits noting that our models, HANG and HANG-quad, can be readily integrated with additional defense mechanisms against adversarial attacks. These include Adversarial Training (AT) [60] and other preprocessing methods such as GNNGUARD [61]. This integration can further bolster the robustness of the HANG model. To validate this enhancement, extensive experiments are conducted, with results detailed in Appendix C.8 and Appendix C.9.

## 7 Conclusion

In this paper, we conducted a comprehensive study on stability notions in the context of graph neural flows and made significant findings. While Lyapunov stability is frequently employed, it alone may not suffice in guaranteeing robustness against adversarial attacks. With a grounding in foundational physics principles, we proposed a shift towards conservative Hamiltonian neural flows for crafting GNNs resilient against adversarial attacks. Our empirical comparisons across diverse neural flow GNNs, as tested on multiple benchmark datasets subjected to a range of adversarial attacks, have further corroborated this proposition. Notably, GNNs that amalgamate conservative Hamiltonian flows with Lyapunov stability exhibited marked enhancement in their robustness metrics. We are optimistic that our work will inspire further research into marrying physics principles with machine learning paradigms for enhanced security.

Acknowledgments and Disclosure of Funding

This research is supported by the Singapore Ministry of Education Academic Research Fund Tier 2 grant MOE-T2EP20220-0002, and the National Research Foundation, Singapore and Infocomm Media Development Authority under its Future Communications Research and Development Programme. To improve the readability, parts of this paper have been grammatically revised using ChatGPT [62].

## References

* [1] X. Yue, Z. Wang, J. Huang, S. Parthasarathy, S. Moosavinasab, Y. Huang, S. M. Lin, W. Zhang, P. Zhang, and H. Sun, "Graph embedding on biomedical networks: methods, applications and evaluations," _Bioinformatics_, vol. 36, no. 4, pp. 1241-1251, 2019.
* [2] H. Ashoor, X. Chen, W. Rosikiewicz, J. Wang, A. Cheng, P. Wang, Y. Ruan, and S. Li, "Graph embedding and unsupervised learning predict genomic sub-compartments from hic chromatin interaction data," _Nat. Commun._, vol. 11, 2020.
* [3] T. N. Kipf and M. Welling, "Semi-supervised classification with graph convolutional networks," in _Proc. Int. Conf. Learn. Representations_, 2017.
* [4] Z. Zhang, P. Cui, and W. Zhu, "Deep learning on graphs: A survey," _IEEE Trans. Knowl. Data Eng._, vol. 34, no. 1, pp. 249-270, Jan 2022.
* [5] Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang, and P. S. Yu, "A comprehensive survey on graph neural networks," _IEEE Trans. Neural Netw. Learn. Syst._, vol. 32, no. 1, pp. 4-24, 2021.
* [6] P. Velickovic, G. Cucurull, A. Casanova, A. Romero, P. Lio, and Y. Bengio, "Graph attention networks," in _Proc. Int. Conf. Learn. Representations_, 2018, pp. 1-12.
* [7] F. Ji, S. H. Lee, H. Meng, K. Zhao, J. Yang, and W. P. Tay, "Leveraging label non-uniformity for node classification in graph neural networks," in _Proc. Int. Conf. Mach. Learn._, vol. 202, Jul. 2023, pp. 14 869-14 885.
* [8] S. H. Lee, F. Ji, and W. P. Tay, "SGAT: Simplicial graph attention network," in _Proc. Inter. Joint Conf. Artificial Intell._, Jul. 2022.
* [9] D. Zugner, A. Akbarnejad, and S. Gunnemann, "Adversarial attacks on neural networks for graph data," in _Proc. Int. Conf. Knowl. Discovery Data Mining_, 2018.
* 27, 2020.
* [11] Q. Zheng, Y. Fei, Y. Li, Q. Liu, M. Hu, and Q. Sun. Kdd cup 2020 ml track 2 adversarial attacks and defense on academic graph 1st place solution. Accessed: May 1, 2022. [Online]. Available: https://github.com/Stanislas0/KDD_CUP_2020_MLTrack2_SPEIT
* [12] X. Zou, Q. Zheng, Y. Dong, X. Guan, E. Kharlamov, J. Lu, and J. Tang, "Tdgia: Effective injection attacks on graph neural networks," in _Proc. Int. Conf. Knowl. Discovery Data Mining_, 2021, p. 2461-2471.
* [13] H. Hussain, M. Cao, S. Sikdar, D. Helic, E. Lex, M. Strohmaier, and R. Kern, "Adversarial inter-group link injection degrades the fairness of graph neural networks," in _Prof. Int. Conf. Data Mining_, 2022, pp. 975-980.
* [14] J. Chen, Y. Wu, X. Xu, Y. Chen, H. Zheng, and Q. Xuan, "Fast gradient attack on network embedding," _arXiv preprint arXiv:1809.02797_, 2018.
* [15] M. Waniek, T. P. Michalak, M. J. Wooldridge, and T. Rahwan, "Hiding individuals and communities in a social network," _Nature Human Behaviour_, vol. 2, no. 1, pp. 139-147, 2018.
* [16] J. Du, S. Zhang, G. Wu, J. M. F. Moura, and S. Kar, "Topology adaptive graph convolutional networks," _ArXiv_, vol. abs/1710.10370, 2017.
* [17] D. Zugner and S. Gunnemann, "Adversarial attacks on graph neural networks via meta learning," in _Proc. Int. Conf. Learn. Representations_, 2019.
* [18] R. T. Chen, Y. Rubanova, J. Bettencourt, and D. Duvenaud, "Neural ordinary differential equations," in _Advances Neural Inf. Process. Syst._, 2018.
* [19] H. Yan, J. Du, V. Y. Tan, and J. Feng, "On robustness of neural ordinary differential equations," in _Advances Neural Inf. Process. Syst._, 2018, pp. 1-13.

* [20] Q. Kang, Y. Song, Q. Ding, and W. P. Tay, "Stable neural ODE with Lyapunov-stable equilibrium points for defending against adversarial attacks," in _Advances Neural Inf. Process. Syst._, 2021.
* [21] I. D. J. Rodriguez, A. Ames, and Y. Yue, "Lyanet: A lyapunov framework for training neural odes," in _Proc. Int. Conf. Mach. Learn._, 2022, pp. 18 687-18 703.
* [22] R. She, Q. Kang, S. Wang, Y.-R. Yang, K. Zhao, Y. Song, and W. P. Tay, "Robustmat: Neural diffusion for street landmark patch matching under challenging environments," _IEEE Trans. Image Process._, 2023.
* [23] S. Wang, Q. Kang, R. She, W. P. Tay, A. Hartmannsgruber, and D. N. Navarro, "RobustLoc: Robust camera pose regression in challenging driving environments," in _Proc. AAAI Conference on Artificial Intelligence_, Feb. 2023.
* [24] R. She, Q. Kang, S. Wang, W. P. Tay, Y. L. Guan, D. N. Navarro, and A. Hartmannsgruber, "Image patch-matching with graph-based learning in street scenes," _IEEE Trans. Image Process._, vol. 32, pp. 3465-3480, 2023.
* [25] K. He, X. Zhang, S. Ren, and J. Sun, "Deep residual learning for image recognition," in _Proc. IEEE Int. Conf. Comput. Vision_, 2016, pp. 770-778.
* [26] Y. D. Zhong, B. Dey, and A. Chakraborty, "Symplectic ode-net: Learning hamiltonian dynamics with control," in _Proc. Int. Conf. Learn. Representations_, 2020.
* [27] Y. Chen, T. Matsubara, and T. Yaguchi, "Neural symplectic form: Learning hamiltonian equations on general coordinate systems," in _Advances Neural Inf. Process. Syst._, 2021.
* [28] Y. Huang, Y. Yu, H. Zhang, Y. Ma, and Y. Yao, "Adversarial robustness of stabilized neural ode might be from obfuscated gradients," in _Proc. Math. Sci. Mach. Learn. Conf._, J. Bruna, J. Hesthaven, and L. Zdeborova, Eds., 2022, pp. 497-515.
* [29] B. P. Chamberlain, J. Rowbottom, M. Goronova, S. Webb, E. Rossi, and M. M. Bronstein, "Grand: Graph neural diffusion," in _Proc. Int. Conf. Mach. Learn._, 2021.
* [30] M. Thorpe, T. M. Nguyen, H. Xia, T. Strohmer, A. Bertozzi, S. Osher, and B. Wang, "Grand++: Graph neural diffusion with a source term," in _Proc. Int. Conf. Learn. Representations_, 2021.
* [31] B. P. Chamberlain, J. Rowbottom, D. Eynard, F. Di Giovanni, D. Xiaowen, and M. M. Bronstein, "Beltrami flow and neural diffusion on graphs," in _Advances Neural Inf. Process. Syst._, 2021.
* [32] Y. Song, Q. Kang, S. Wang, K. Zhao, and W. P. Tay, "On the robustness of graph neural diffusion to topology perturbations," in _Advances Neural Inf. Process. Syst._, New Orleans, USA, Nov. 2022.
* [33] K. Zhao, Q. Kang, Y. Song, R. She, S. Wang, and W. P. Tay, "Graph neural convection-diffusion with heterophily," in _Proc. Inter. Joint Conf. Artificial Intell._, Aug. 2023.
* [34] Q. Kang, K. Zhao, Y. Song, S. Wang, and W. P. Tay, "Node embedding from neural Hamiltonian orbits in graph neural networks," in _Proc. Int. Conf. Mach. Learn._, vol. 202, Jul. 2023, pp. 15 786-15 808.
* [35] T. K. Rusch, B. P. Chamberlain, J. Rowbottom, S. Mishra, and M. M. Bronstein, "Graph-coupled oscillator networks," in _Proc. Int. Conf. Mach. Learn._, 2022.
* [36] W. E. Boyce and R. C. a. DiPrima, _Elementary Differential Equations and Boundary Value Problems_. Wiley, New York, 1997, vol. 3.
* [37] M. W. Hirsch and S. Smale, _Differential Equations, Dynamical Systems and an Introduction to Chaos_. Academic Press/Elsevier, San Diego, 2004.
* [38] A. Katok and B. Hasselblatt, _Introduction to the modern theory of dynamical systems_. Cambridge University Press, 1995, no. 54.
* [39] C.-T. Chen and B. Shafai, _Linear system theory and design_. New York: Oxford university press New York, 1999.
* [40] D. Arrowsmith and C. M. Place, _Dynamical systems: differential equations, maps, and chaotic behaviour_. London: CRC Press, 1992.
* [41] M. E. Sander, P. Ablin, M. Blondel, and G. Peyre, "Sinkformers: Transformers with doubly stochastic attention," in _International Conference on Artificial Intelligence and Statistics_. PMLR, 2022, pp. 3515-3530.

* [42] R. A. Horn and C. R. Johnson, _Matrix analysis_. New York: Cambridge university press, 2012.
* [43] M. De Leon and P. R. Rodrigues, _Generalized Classical Mechanics and Field Theory: a geometrical approach of Lagrangian and Hamiltonian formalisms involving higher order derivatives_. Elsevier, 2011.
* [44] W. Curtin and H. Scher, "Mechanics modeling using a spring network," _J. Mater. Research_, vol. 5, no. 3, pp. 554-562, 1990.
* [45] A. C. Da Silva and A. C. Da Salva, _Lectures on symplectic geometry_. Springer, 2008, vol. 3575.
* [46] V. I. Arnold, V. V. Kozlov, and A. I. Neishtadt, _Mathematical aspects of classical and celestial mechanics_. Springer Science & Business Media, 2007, vol. 3.
* [47] P. Velickovic, G. Cucurull, A. Casanova, A. Romero, P. Lio, and Y. Bengio, "Graph attention networks," in _Proc. Int. Conf. Learn. Representations_, 2018, pp. 1-12.
* [48] W. L. Hamilton, R. Ying, and J. Leskovec, "Inductive representation learning on large graphs," in _Advances Neural Inf. Process. Syst._, 2017.
* [49] Y. Chen, H. Yang, Y. Zhang, K. Ma, T. Liu, B. Han, and J. Cheng, "Understanding and improving graph injection attack by promoting unnoticeability," in _Proc. Int. Conf. Learn. Representations_, 2022.
* [50] A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu, "Towards deep learning models resistant to adversarial attacks," in _Proc. Int. Conf. Learn. Representations_, 2018.
* [51] Z. Yang, W. Cohen, and R. Salakhudinov, "Revisiting semi-supervised learning with graph embeddings," in _Proc. Int. Conf. Mach. Learn._, 2016, pp. 40-48.
* [52] O. Shchur, M. Mumme, A. Bojchevski, and S. Gunnemann, "Pitfalls of graph neural network evaluation," _Relational Representation Learning Workshop, Advances Neural Inf. Process. Syst._, 2018.
* [53] W. Hu, M. Fey, M. Zitnik, Y. Dong, H. Ren, B. Liu, M. Catasta, and J. Leskovec, "Open graph benchmark: Datasets for machine learning on graphs," _Advances Neural Inf. Process. Syst._, vol. 33, pp. 22 118-22 133, 2020.
* [54] Q. Zheng, X. Zou, Y. Dong, Y. Cen, D. Yin, J. Xu, Y. Yang, and J. Tang, "Graph robustness benchmark: Benchmarking the adversarial robustness of graph machine learning," _Advances Neural Inf. Process. Syst. Track Datasets Benchmarks_, 2021.
* [55] W. Jin, Y. Ma, X. Liu, X. Tang, S. Wang, and J. Tang, "Graph structure learning for robust graph neural networks," in _Proc. Int. Conf. Knowl. Discovery Data Mining_, 2020, pp. 66-74.
* [56] Y. Li, W. Jin, H. Xu, and J. Tang, "Deeprobust: A pytorch library for adversarial attacks and defenses," _arXiv preprint arXiv:2005.06149_, 2020.
* [57] D. Zhu, Z. Zhang, P. Cui, and W. Zhu, "Robust graph convolutional networks against adversarial attacks," in _Proc. Int. Conf. Knowl. Discovery Data Mining_, 2019, pp. 1399-1407.
* [58] N. Entezari, S. A. Al-Sayouri, A. Darvishzadeh, and E. E. Papalexakis, "All you need is low (rank): Defending against adversarial attacks on graphs," in _Proc. Int. Conf. Web Search Data Mining_, 2020, p. 169-177.
* [59] L. A. Adamic and N. Glance, "The political blogosphere and the 2004 us election: divided they blog," in _Proc. Int. Workshop Link Discovery_, 2005, pp. 36-43.
* [60] A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu, "Towards deep learning models resistant to adversarial attacks," _arXiv preprint arXiv:1706.06083_, 2017.
* [61] X. Zhang and M. Zitnik, "Gnnguard: Defending graph neural networks against adversarial attacks," _Advances Neural Inf. Process. Syst._, vol. 33, pp. 9263-9275, 2020.
* [62] OpenAI, "Chatgpt-4," 2022, available at: https://www.openai.com (Accessed: 26 September 2023).
* [63] Y. Ma, S. Wang, T. Derr, L. Wu, and J. Tang, "Graph adversarial attack via rewiring," in _Proc. Int. Conf. Knowl. Discovery Data Mining_, 2021, p. 1161-1169.
* [64] Y. Sun, S. Wang, X. Tang, T.-Y. Hsieh, and V. Honavar, "Adversarial attacks on graph neural networks via node injections: A hierarchical reinforcement learning approach," in _Proc. Web Conf._, 2020, p. 673-683.

* [65] X. Wan, H. Kenlay, B. Ru, A. Blaas, M. A. Osborne, and X. Dong, "Adversarial attacks on graph classification via bayesian optimisation," _arXiv preprint arXiv:2111.02842_, 2021.
* [66] S. Geisler, T. Schmidt, H. Sirin, D. Zugner, A. Bojchevski, and S. Gunnemann, "Robustness of graph neural networks at scale," _Advances Neural Inf. Process. Syst._, vol. 34, pp. 7637-7649, 2021.
* [67] J. Ma, J. Deng, and Q. Mei, "Adversarial attack on graph neural networks as an influence maximization problem," in _Prof. Int. Conf. Web Search Data Mining_, 2022, pp. 675-685.
* [68] B. Finkelshtein, C. Baskin, E. Zheltnozhskii, and U. Alon, "Single-node attacks for fooling graph neural networks," _Neurocomputing_, vol. 513, pp. 1-12, 2022.
* [69] D. Zhu, Z. Zhang, P. Cui, and W. Zhu, "Robust graph convolutional networks against adversarial attacks," in _Proc. Int. Conf. Knowl. Discovery Data Mining_, 2019, p. 1399-1407.
* [70] W. Feng, J. Zhang, Y. Dong, Y. Han, H. Luan, Q. Xu, Q. Yang, E. Kharlamov, and J. Tang, "Graph random neural networks for semi-supervised learning on graphs," in _Proc. Advances Neural Inf. Process. Syst._, 2020.
* [71] W. Jin, Y. Ma, X. Liu, X. Tang, S. Wang, and J. Tang, "Graph structure learning for robust graph neural networks," in _Proc. Int. Conf. Knowl. Discovery Data Mining_, 2020, p. 66-74.
* [72] X. Gao, W. Hu, and Z. Guo, "Exploring structure-adaptive graph learning for robust semi-supervised classification," in _2020 IEEE International Conference on Multimedia and Expo (ICME)_. IEEE, 2020, pp. 1-6.
* [73] T. Zhao, Y. Liu, L. Neves, O. Woodford, M. Jiang, and N. Shah, "Data augmentation for graph neural networks," in _Proc. AAAI Conference on Artificial Intelligence_, vol. 35, no. 12, 2021, pp. 11 015-11 023.
* [74] K. Li, Y. Liu, X. Ao, J. Chi, J. Feng, H. Yang, and Q. He, "Reliable representations make a stronger defender: Unsupervised structure refinement for robust gnn," in _Proc. Int. Conf. Knowl. Discovery Data Mining_, 2022, pp. 925-935.
* [75] B. Runwal, S. Kumar _et al._, "Robust graph neural networks using weighted graph laplacian," _arXiv preprint arXiv:2208.01853_, 2022.
* [76] X. Zhang and M. Zitnik, "Gnnguard: Defending graph neural networks against adversarial attacks," in _Proc. Advances Neural Inf. Process. Syst._, 2020.
* [77] S. Greydanus, M. Dzamba, and J. Yosinski, "Hamiltonian neural networks," in _Advances Neural Inf. Process. Syst._, 2019.
* [78] Z. Chen, J. Zhang, M. Arjovsky, and L. Bottou, "Symplectic recurrent neural networks," in _Proc. Int. Conf. Learn. Representations_, 2020.
* [79] A. Choudhary, J. F. Lindner, E. G. Holliday, S. T. Miller, S. Sinha, and W. L. Ditto, "Physics-enhanced neural networks learn order and chaos," _Physical Review E_, vol. 101, no. 6, p. 062207, 2020.
* [80] E. Haber and L. Ruthotto, "Stable architectures for deep neural networks," _Inverse Problems_, vol. 34, no. 1, pp. 1-23, Dec. 2017.
* [81] J. Li, J. Peng, L. Chen, Z. Zheng, T. Liang, and Q. Ling, "Spectral adversarial training for robust graph neural network," _IEEE Transactions on Knowledge and Data Engineering_, 2022.
* [82] C. Deng, X. Li, Z. Feng, and Z. Zhang, "Garnet: Reduced-rank topology learning for robust and scalable graph neural networks," in _Learning on Graphs Conference_. PMLR, 2022, pp. 3-1.
* [83] V. Nikiforov, "Revisiting schur's bound on the largest singular value," _arXiv preprint math/0702722_, 2007.
* [84] H. K. Khalil, "Nonlinear control," 2015, available at: https://www.egr.msu.edu/~khalil/NonlinearControl/Slides-Short/Lecture_2.pdf (Accessed: 26 September 2023).
* [85] R. Durrett, _Probability: theory and examples_. Cambridge university press, 2019, vol. 49.

Summary of Supplement

In this supplement, we expand on material from the main paper, addressing each point as follows:

1. An in-depth comparison with related work is covered in Appendix B.
2. Appendix C presents the datasets and details of the attackers, and includes additional experimental results, inference time, and model size to reinforce our model's effectiveness.
3. Theoretical proofs supporting assertions made in the main paper are presented in Appendix E.
4. Further discussions on the robustness insights of our model are covered in Appendix D.
5. The complete summary of the algorithm can be found in Appendix G.
6. Lastly, we address the limitations of our work and discuss its broader impact.

## Appendix B Related Work

In what follows, we briefly review a few concepts closely related to our work.

**Graph Adversarial Attacks and Defenses.** In _modification attacks_, adversaries can perturb a graph's topology by adding or removing edges [14, 15, 63, 64, 65, 9, 16, 66, 67, 63]. To improve the modification attack performance, adversaries are also permitted to perturb node attributes [17, 68, 63, 64, 67, 9]. In _injection attacks_, adversaries can only inject malicious nodes into the original graph [10, 11, 12, 13] while the edges and nodes inside the original graph are not allowed to be perturbed. For _defense methods_ against adversarial attacks, multiple robust GNN models have been proposed. Examples include RobustGCN [69], GRAND [70], ProGNN [71], GLNN [72], GAUGM [73], STABLE [74] and RWL-GNN [75]. In addition, preprocessing-based defenders including GNN-SVD [58] and GNNGuard [76] may help to improve GNN robustness.

_In this paper, we use different attacks to test GNNs robustness. We compare graph neural flows with different stability settings with the above-mentioned defense methods as robustness benchmarks._

**Stable Graph Neural Flow Networks.** While traditional GNNs perform message passing on a simple, discrete and flat space, graph neural flows model the message passing as a continuous diffusion process that occurs on a smooth manifold. GRAND [29] and GRAND++ [30] use heat diffusion to achieve feature information exchange. BLEND [31] exploits the Beltrami diffusion where the nodes' positional information is updated along with their features. GraphCON [35] adopts the coupled oscillator model that preserves the graph's Dirichlet energy over time and thus mitigates the oversmoothing problem. In general, [32] shows that graph neural PDEs are Lyapunov stable and exhibit stronger robustness against graph topology perturbation than traditional GNNs.

_While most of the above-mentioned graph neural flows are Lyapunov stable, whether the notion of Lyapunov stability leads to better adversarial robustness is an open question. In this paper, we argue that Lyapunov stability does not necessarily imply adversarial robustness._

**Hamiltonian Neural Networks.** Hamiltonian equations have been applied to conserve an energy-like quantity in (graph) neural networks. The references [77, 26, 27] train a neural network to infer the Hamiltonian dynamics of a physical system, where Hamiltonian equations are solved using neural ODE solvers. In [78], the authors propose to learn a Hamiltonian function of the system by a neural network to capture the dynamics of physical systems from observed trajectories. They shows that the network performs well on noisy and complex systems such as a spring-chain system. To forecast dynamics, the work [79] use neural networks that incorporate Hamiltonian dynamics to efficiently learn phase space orbits and demonstrate the effectiveness of Hamiltonian neural networks on several dynamics benchmarks. The paper [80] builds a Hamiltonian-inspired neural ODE to stabilize the gradients so as to avoid gradient vanishing and gradient exploding.

_In this paper, inspired by existing Hamiltonian neural networks, we introduce several energy-conservative graph neural flows. We are neither simulating a physical system nor forecasting a forecast the dynamics for a physical problem. Instead, we combine the Hamiltonian mechanics concept with graph neural networks to develop a new robust GNN._More Experiments

### Data and Attackers

The datasets and attack budgets utilized in Table 2 and Table 3 are outlined in Table 5 and Table 6, respectively. These datasets span various domains and scales, thereby providing a diverse base for our study. The adopted attack budget aligns consistently with the specifications set out in the paper [49].

### Implementation Details

The raw node features are compressed to a fixed dimension, such as 64, using a fully connected (FC) layer to generate the initial features \(q(0)\) in (10). At time \(t=0\), \(p(0)\) and \(q(0)\) are initialized identically. For \(t>0\), both \(q(t)\) and \(p(t)\) undergo updates using a graph ODE. The ODE is solved using the solver from [18]. It is observed that different solvers deliver comparable performance in terms of clean accuracy. However, to mitigate computational expense, the Euler solver is employed in our experiments, with an ablation study on different solvers provided for further insight. The integral time \(T\) acts as a hyperparameter in our model. Interestingly, the performance of the model exhibits minimal sensitivity to this time \(T\). For all datasets, we establish the time \(T\) as 3 and maintain a fixed step size of 1. This setup aligns with a fair comparison to three-layer GNNs.

All the baseline models presented in Table 2 and Table 3 are implemented based on the original work of [49]. The baseline model results in Table 4 are directly extracted from the paper [55]. This is done as we employ the same clean and perturbed graph datasets provided in their research [55].

Our experiment code is developed based on the following repositories:

* https://github.com/tk-rusch/GraphCON
* https://github.com/twitter-research/graph-neural-pde
* https://github.com/LFhase/GIA-HAO
* https://github.com/ChandlerBang/Pro-GNN

### White-box Attack

In our main study, we utilized black-box attacks. Now, we extend our experiments to incorporate white-box, injection, and evasion attacks. In the context of white-box attacks, the adversaries have full access to the target model, enabling them to directly attack the target model to generate a perturbed graph. This represents a significantly more potent form of attack than the black-box variant. Moreover, we execute inductive learning tasks the same as Table 2, with the corresponding results reported in Table 7. We observe that, under white-box attack conditions, all other baseline models exhibit severely reduced performance, essentially collapsing across all datasets. The classification accuracy of the HANG model experiences a slight decline on the Cora, Citeseer, and Pubmed datasets. However, its performance remains substantially superior to other graph neural flow models or GNN models. Intriguingly, our HANG-quad model remains virtually unaffected by the white-box attacks, maintaining a performance level similar to that observed under black-box attacks. Such robustness of HANG-quad underscores the pivotal contribution of Lyapunov stability when combined with our Hamiltonian-driven design.

\begin{table}
\begin{tabular}{c c c} \hline \hline Dataset & max \# Nodes & max \# Edges \\ \hline Cora & 60 & 20 \\ \hline Citeseer & 90 & 10 \\ \hline PubMed & 200 & 100 \\ \hline Coauthor & 300 & 150 \\ \hline Ogbn-Azxiv\({}^{*}\) & 120 & 100 \\ \hline Computers\({}^{*}\) & 100 & 150 \\ \hline \hline \end{tabular}
\end{table}
Table 6: Attacks’ budgets for GIA. \({}^{*}\) refers to targeted GIA.

\begin{table}
\begin{tabular}{c c c c c} \hline \hline Dataset & \# Nodes & \# Edges & \# Features & \# Classes \\ \hline Cora & 2708 & 5429 & 1433 & 7 \\ \hline Citeseer & 3327 & 4732 & 3703 & 6 \\ \hline PubMed & 19717 & 44338 & 500 & 3 \\ \hline Coauthor & 18,333 & 81,894 & 6,805 & 15 \\ \hline Computers & 13,752 & 245,861 & 767 & 10 \\ \hline Ogbn-Azxiv\({}^{*}\) & 169343 & 1166243 & 128 & 40 \\ \hline \hline \end{tabular}
\end{table}
Table 5: Dataset Details

[MISSING_PAGE_FAIL:17]

### Nettack

We further evaluate the robustness of our model under the targeted poisoning attack, Nettack [9]. Adhering to the settings outlined in [55], we select nodes in the test set with a degree greater than 10 to be the target nodes. We then vary the number of perturbations applied to each targeted node from 1 to 5, incrementing in steps of 1. It is important to note that Nettack only involves feature perturbations. The test accuracy in Table 9 refer to the classification accuracy on the targeted nodes. As demonstrated in Table 9, our HANG-quad model exhibits exceptional resistance to Nettack, thereby underlining its superior robustness. This suggests that the combination of Lyapunov stability and conservative Hamiltonian design significantly enhances robustness in the face of graph poisoning attacks. On its own, Lyapunov stability has been recognized to defend against only slight feature perturbations in the input graph [32]. Furthermore, our HANG model also displays superior resilience compared to other graph neural flows, reinforcing the fact that the Hamiltonian principle contributes to its robustness.

### ODE solvers

The results from various ODE solvers are depicted in Table 10. We consider fixed-step Euler and RK4, along with adaptive-step Dopri5, from [18], and Symplectic-Euler from [35]. The Symplectic-Euler method, being inherently energy-conserving, is particularly suited for preserving the dynamic properties of Hamiltonian systems over long times. Our observations suggest that while the choice of solver slightly influences the clean accuracy for some models, their performance under attack conditions remains fairly consistent. Consequently, there was no specific optimization for solver selection during our experiments. For computational efficiency, we opted for the Euler ODE solver in all experiments presented in the main paper.

\begin{table}
\begin{tabular}{c c c c c c c} \hline \hline Attack & Soker & HANG & HANG-quad & GraphCON & GraphBd & GRAND \\ \hline \multirow{4}{*}{clean} & Euler & 74.11\(\pm\)1.56 & 72.85\(\pm\)0.83 & 74.84\(\pm\)0.49 & 69.62\(\pm\)0.56 & 74.98\(\pm\)0.45 \\  & rk4 & 73.71\(\pm\)1.58 & 72.62\(\pm\)0.56 & 75.80\(\pm\)0.38 & 74.46\(\pm\)0.68 & 75.32\(\pm\)0.78 \\  & symplectic & 71.35\(\pm\)1.91 & 72.80\(\pm\)0.64 & 75.43\(\pm\)0.62 & 69.87\(\pm\)0.78 & 75.70\(\pm\)0.71 \\  & dopri5 & 75.20\(\pm\)0.93 & – & 76.24\(\pm\)0.76 & 74.63\(\pm\)0.70 & 75.14\(\pm\)0.56 \\ \hline \multirow{4}{*}{FOD} & Euler & 72.31\(\pm\)1.16 & 71.07\(\pm\)0.41 & 40.80\(\pm\)36.50 & 56.57\(\pm\)5.35 & 36.68\(\pm\)105 \\  & rk4 & 71.85\(\pm\)2.04 & 72.38\(\pm\)0.52 & 41.46\(\pm\)0.89 & 41.51\(\pm\)1.76 & 41.21\(\pm\)1.57 \\  & symplectic & 70.57\(\pm\)1.74 & 72.46\(\pm\)0.53 & 40.87\(\pm\)2.62 & 40.99\(\pm\)1.82 & 39.72\(\pm\)1.54 \\  & dopri5 & 73.59\(\pm\)0.38 & – & 42.02\(\pm\)21.21 & 40.07\(\pm\)0.87 & 40.53\(\pm\)1.14 \\ \hline \multirow{4}{*}{TDGIA} & Euler & 72.12\(\pm\)0.52 & 71.69\(\pm\)0.40 & 36.67\(\pm\)1.25 & 34.17\(\pm\)4.68 & 36.67\(\pm\)1.25 \\  & rk4 & 71.03\(\pm\)1.64 & 72.85\(\pm\)0.78 & 36.19\(\pm\)2.03 & 37.90\(\pm\)1.70 & 34.21\(\pm\)1.63 \\  & symplectic & mixer & 71.92\(\pm\)2.03 & 73.31\(\pm\)0.58 & 35.32\(\pm\)1.78 & 28.00\(\pm\)9.11 & 35.21\(\pm\)1.62 \\  & dopri5 & 72.14\(\pm\)0.71 & – & 83.04\(\pm\)1.71 & 40.63\(\pm\)1.60 & 34.39\(\pm\)1.19 \\ \hline \multirow{4}{*}{MetaGIA} & Euler & 72.92\(\pm\)0.66 & 71.60\(\pm\)0.48 & 48.36\(\pm\)2.12 & 45.60\(\pm\)4.31 & 46.23\(\pm\)2.01 \\  & rk4 & 70.25\(\pm\)1.45 & 72.39\(\pm\)0.61 & 42.57\(\pm\)1.09 & 43.38\(\pm\)0.88 & 41.01\(\pm\)0.92 \\  & symplectic & mixer & 71.56\(\pm\)1.07 & 72.86\(\pm\)0.72 & 42.57\(\pm\)1.09 & 44.72\(\pm\)6.28 & 41.06\(\pm\)0.64 \\  & dopri5 & 71.83\(\pm\)1.26 & – & 42.61\(\pm\)0.57 & 42.93\(\pm\)0.61 & 41.74\(\pm\)0.69 \\ \hline \hline \end{tabular}
\end{table}
Table 10: Node classification accuracy (%) on graph **injection, evasion, non-targeted, black-box** attack in **inductive** learning of Citeseer dataset.

\begin{table}
\begin{tabular}{c c c c c c c c c c c} \hline \hline Dataset & Ph & HANG & HANG-quad & GripCON & GraphBd & GRAND & GAT & GCN & RGCN & GCN-SVD & Pro-GNN \\ \hline \multirow{4}{*}{Citeseer} & 1 & 75.54\(\pm\)3.10 & 76.99\(\pm\)3.16 & 73.25\(\pm\)3.91 & 63.73\(\pm\)2.25 & 80.12\(\pm\)8.1 & 76.04\(\pm\)2.08 & 75.96\(\pm\)1.02 & 76.52\(\pm\)1.71 & 77.23\(\pm\)8.2 & 84.18\(\pm\)1.66 \\  & 2 & 73.73\(\pm\)3.64 & 76.51\(\pm\)2.60 & 67.83\(\pm\)3.0 & 62.41\(\pm\)2.94 & 76.27\(\pm\)1.79 & 70.24\(\pm\)1.43 & 70.69\(\pm\)1.10 & 70.96\(\pm\)1.14 & 72.53\(\pm\)1.60 & 75.90\(\pm\)1.43 \\  & 3 & 68.43\(\pm\)4.23 & 73.13\(\pm\)2.35 & 68.19\(\pm\)2.10 & 61.20\(\pm\)3.08 & 70.48\(\pm\)3.74 & 65.54\(\pm\)1.34 & 67.95\(\pm\)1.72 & 66.51\(\pm\)1.60 & 66.75\(\pm\)1.54 & 70.12\(\pm\)1.93 \\  & 4 & 66.02\(\pm\)2.21 & 72.55\(\pm\)2.14 & 57.59\(\pm\)2.24 & 56.54\(\pm\)1.27 & 63.69\(\pm\)2.24 & 61.69\(\pm\)0.90 & 61.51\(\pm\)1.47 & 54.92\(\pm\)2.68 & 66.07\(\pm\)2.63 & 66.66\(\pm\)1.35 \\  & 5 & 60.01\(\pm\)3.63 & 68.00\(\pm\)2.35 & 68.50\(\pm\)4.77 & 51.93\(\pm\)2.77 & 59.52\(\pm\)2.38 & 58.11\(\pm\)2.35 & 58.41\(\pm\)1.66 & 55.30\(\pm\)1.66 & 57.11\(\pm\)1.82 & 64.44\(\pm\)1.72 \\ \hline \multirow{4}{*}{Citeseer} & 1 & 76.03\(\pm\)3.51 & 79.05\(\pm\)1.38 & 76.03\(\pm\)3.44 & 68.99\(\pm\)2.67 & 80.01\(\pm\)0.15 & 81.27\(\pm\)1.38 & 78.41\(\pm\)1.62 & 78.25\(\pm\)0.73 & 80.16\(\pm\)2.04 & 81.75\(\pm\)0.79 \\  & 2 & 74.76\(\pm\)2.50 & 79.

[MISSING_PAGE_FAIL:19]

### Combination with GNN defense mechanisms

We acknowledge the potential advantages of integrating defense mechanisms that operate through diverse strategies. In this context, we combine HANG with GNNGuard [61], a preprocessing-based defense renowned for its effectiveness in enhancing GNN robustness, and GARNET [82], another noteworthy defense mechanism.

We conduct experiments to assess the performance of HANG when amalgamated with GNNGuard and GARNET. The results in Table 14 and Table 15 clearly indicate that such integration effectively enhances the model's robustness. This outcome highlights the adaptability of our methodology with current defense strategies and sheds light on the potential for cooperative improvements in model defense.

## Appendix D More Insights about Model Robustness

For a clearer insight into the energy concept within HANG, consider the "time" in graph neural flows as analogous to the "layers" in standard GNNs (note that ODE solvers basically discretize the "time", which indeed approximately turns the model into a layered one). Here, the feature vector \(\mathbf{q}(t)\) and the momentum vector \(\mathbf{p}(t)\) evolve with time, bound tightly by equation (10). Given that \(\mathbf{q}(t)\) mirrors the node features at layer \(t,\mathbf{p}(t)\) can be understood as the variation in node features over time - essentially, the evolution of node features between successive layers. Thus, our defined energy interweaves both the node feature and its rate of change across adjacent layers. The constant \(H_{\mathrm{net}}\) implies inherent constraints on the node features and their alteration pace over layers. Because \(H_{\mathrm{net}}\) processes the whole graph data and yields a scalar, it serves as a constraint on the global graph feature and its variation, which we opine to be crucial in countering adversarial attacks.

From an adversarial perspective, the attacker modifies either the node features or the underlying graph topology. These modifications are propagated through multiple aggregation steps, such as layers in conventional GNNs or integrals in graph ODEs. While the Hamiltonian considers the energy of the entire graph, adversarial attacks often target localized regions of the graph. The inherent global energy perspective of the Hamiltonian system makes it resilient to such localized attacks, as local perturbations often get "absorbed" or "mitigated" when viewed from the perspective of the entire system. When adversarial perturbations are introduced, they might indeed tweak the instantaneous features of certain nodes. However, the challenge lies in modifying the trajectory (or evolution) of these nodes (positions \(p(t)\) and the variations \(q(t)\)) in the phase space in a manner that is aligned with the rest of the graph, all while upholding the energy conservation constraints. This feat is arduous,

\begin{table}
\begin{tabular}{l l l l l l l} \hline \hline Dataset & H\(\mathrm{b}\)-state & HANG & HANG-GARNET & HANG-quad & HANG-quad-GARNET & GCN & GCN-GARNET \\ \hline \multirow{4}{*}{Cora} & 1 & 75.54\(\pm\)3.0 & 82.41\(\pm\)0.80 & 76.99\(\pm\)1.36 & 83.01\(\pm\)0.84 & 70.06\(\pm\)0.81 & 79.75\(\pm\)2.35 \\  & 2 & 73.73\(\pm\)3.64 & 80.84\(\pm\)1.57 & 76.51\(\pm\)2.60 & 79.88\(\pm\)0.55 & 68.60\(\pm\)1.81 & 79.60\(\pm\)1.50 \\  & 3 & 68.43\(\pm\)4.23 & 80.48\(\pm\)1.69 & 73.13\(\pm\)2.85 & 79.76\(\pm\)0.72 & 65.04\(\pm\)3.31 & 74.42\(\pm\)2.06 \\  & 4 & 66.02\(\pm\)2.21 & 70.0\(\pm\)1.47 & 72.53\(\pm\)2.14 & 75.90\(\pm\)0.54 & 61.69\(\pm\)1.48 & 69.60\(\pm\)2.67 \\  & 5 & 60.12\(\pm\)3.63 & 67.83\(\pm\)1.87 & 68.80\(\pm\)2.55 & 69.28\(\pm\)1.34 & 55.66\(\pm\)1.95 & 67.04\(\pm\)2.05 \\ \hline \hline \end{tabular}
\end{table}
Table 15: Node classification accuracy (%) on graph **Netstack targeted** attack in **transductive** learning.

\begin{table}
\begin{tabular}{l l l l l l} \hline \hline Dataset & Attack & HANG & HANG-GURARD & HANG-quad & HANG-quad-GURARD \\ \hline \multirow{4}{*}{Cora} & _clean_ & 87.13\(\pm\)0.86 & 86.54\(\pm\)0.57 & 79.68\(\pm\)0.62 & 81.23\(\pm\)0.70 \\  & PCD & 78.37\(\pm\)1.84 & 86.23\(\pm\)0.55 & 79.65\(\pm\)0.42 & 80.91\(\pm\)0.67 \\  & TDIGA & 79.76\(\pm\)0.99 & 85.56\(\pm\)0.34 & 79.54\(\pm\)0.65 & 81.11\(\pm\)0.76 \\  & MetaGIA & 77.48\(\pm\)1.02 & 86.0\(\pm\)0.60 & 78.28\(\pm\)0.56 & 80.10\(\pm\)0.53 \\ \hline \multirow{4}{*}{Citeseer} & _clean_ & 74.11\(\pm\)0.62 & 75.95\(\pm\)0.66 & 71.85\(\pm\)0.48 & 73.15\(\pm\)0.61 \\  & PGD & 72.31\(\pm\)1.16 & 75.38\(\pm\)0.82 & 71.07\(\pm\)0.41 & 73.07\(\pm\)0.63 \\  & TDIGA & 72.12\(\pm\)0.52 & 75.44\(\pm\)0.69 & 71.69\(\pm\)0.40 & 73.04\(\pm\)0.52 \\  & MetaGIA & 72.92\(\pm\)0.66 & 75.22\(\pm\)0.66 & 71.60\(\pm\)0.48 & 73.11\(\pm\)0.45 \\ \hline \multirow{4}{*}{Pubanned} & _clean_ & 89.93\(\pm\)0.27 & 89.96\(\pm\)0.25 & 88.10\(\pm\)0.33 & 88.93\(\pm\)0.18 \\  & PCD & 81.81\(\pm\)1.94 & 87.27\(\pm\)0.89 & 87.69\(\pm\)0.57 & 88.99\(\pm\)0.11 \\  & TDIGA & 86.62\(\pm\)1.05 & 88.86\(\pm\)0.40 & 87.55\(\pm\)0.60 & 88.90\(\pm\)0.12 \\  & MetaGIA & 87.58\(\pm\)0.75 & 88.23\(\pm\)0.93 & 87.40\(\pm\)0.62 & 88.78\(\pm\)0.16 \\ \hline \hline \end{tabular}
\end{table}
Table 14: Node classification accuracy (%) on graph **injection, evasion, non-targeted** attack in **inductive** learning.

if not impossible, without creating detectable inconsistencies elsewhere. This property ensures that the energy of each node feature is preserved over time and multiple aggregation steps. As a result, the distances between features of different nodes are preserved if their norms differ initially before the adversarial attack. The robustness of HANG against topology perturbation may stem from the fact that adversarial topology perturbation has small influence on the node feature energy. This can be seen from Fig. 1. When using HANG, the node feature before and after adversarial attack are relatively stable and well separated between nodes from different classes.

## Appendix E Proof of Theorem 1

Recall that

\[\frac{\mathrm{d}\mathbf{X}(t)}{\mathrm{d}t}=\overline{\mathbf{A} }_{G}(\mathbf{X}(t))\mathbf{X}(t)=(\mathbf{A}_{G}(\mathbf{X}(t))-\alpha \mathbf{I})\mathbf{X}(t),\] (15)

Without loss of generality, we assume \(\mathbf{X}\in\mathbb{R}^{|\mathcal{V}|\times 1}\) since the results can be generalized to \(\mathbf{X}\in\mathbb{R}^{|\mathcal{V}|\times r}\) on a component-wise basis.

_Proof of 1)_.

Given our assumptions where \(\mathbf{A}_{G}(\mathbf{X}(t))\) is either column- or row-stochastic, the spectral radius of \(\mathbf{A}_{G}(\mathbf{X}(t))\) is 1, as established by [42][Theorem 8.1.22]. This implies that the modulus of its eigenvalues is as most 1.

We define a Lyapunov function as \(V(\mathbf{X}(t))=\mathbf{X}(t)^{\intercal}\mathbf{X}(t)=\|\mathbf{X}(t)\|_{2}^ {2}\) where \(\|\cdot\|_{2}\) is the \(\ell_{2}\) euclidean norm. Take the derivative of \(V\) with respect to time, we have

\[\dot{V}(\mathbf{X}(t))=\mathbf{X}^{\intercal}(t)\dot{\mathbf{X}}(t)+\dot{ \mathbf{X}}^{\intercal}(t)\mathbf{X}(t)=\mathbf{X}^{\intercal}(t)\left( \overline{\mathbf{A}}_{G}(\mathbf{X}(t))+\overline{\mathbf{A}}_{G}^{\intercal }(\mathbf{X}(t))\right)\mathbf{X}(t)\] (16)

We next prove that \(\dot{V}(\mathbf{X}(t))\leq 0\) when \(\mathbf{A}_{G}(\mathbf{X}(t))\) is a doubly stochastic attention matrix under the GRAND-nl setting.

\[\dot{V}(\mathbf{X}(t)) =\mathbf{X}^{\intercal}(t)\left(\overline{\mathbf{A}}_{G}( \mathbf{X}(t))+\overline{\mathbf{A}}_{G}^{\intercal}(\mathbf{X}(t))\right) \mathbf{X}(t)\] (17) \[=2\mathbf{X}^{\intercal}(t)\overline{\mathbf{A}}_{G}(\mathbf{X}( t))\mathbf{X}(t)\] \[=2\mathbf{X}^{\intercal}(t)\mathbf{A}_{G}(\mathbf{X}(t))\mathbf{ X}(t)-2\alpha\mathbf{X}^{\intercal}(t)\mathbf{X}(t)\]

Note that

\[|\mathbf{X}^{\intercal}(t)\mathbf{A}_{G}(\mathbf{X}(t))\mathbf{X}(t)|\leq\| \mathbf{X}\|_{2}\|\mathbf{A}_{G}(\mathbf{X}(t)\|_{2}\|\mathbf{X}\|_{2}\] (18)

where \(\|\cdot\|_{2}\) is the spectral matrix norm induced by \(\ell_{2}\) vector norm. The given inequality is a direct result of the Cauchy-Schwarz inequality and the properties of the induced norm. Drawing from [42][Theorem 5.6.9], we can currently establish that \(\|\mathbf{A}_{G}(\mathbf{X}(t)\|_{2}\geq 1\). Nevertheless, we intend to assert that this inequality is indeed an equality when \(\mathbf{A}_{G}(\mathbf{X}(t))\) is doubly stochastic, i.e., \(\|\mathbf{A}_{G}(\mathbf{X}(t)\|_{2}=1\). To see this, from Schur's bounds on the largest singular value [83][eq.(1)], we have

\[\|\mathbf{A}_{G}(\mathbf{X}(t)\|_{2}\leq\sqrt{\|\mathbf{A}_{G}( \mathbf{X}(t)\|_{\infty}\|\mathbf{A}_{G}(\mathbf{X}(t)\|_{1}}\]

where \(\|\cdot\|_{1}\) is the induced \(\ell_{1}\) norm and \(\|\cdot\|_{\infty}\) is the induced \(\ell_{\infty}\) norm. Given that \(\mathbf{A}_{G}(\mathbf{X}(t)\) is doubly stochastic, we observe that \(\|\mathbf{A}_{G}(\mathbf{X}(t)\|_{\infty}=\|\mathbf{A}_{G}(\mathbf{X}(t)\|_{1 }=1\). It now follows that \(\|\mathbf{A}_{G}(\mathbf{X}(t)\|_{2}\leq 1\), the equality is consequently confirmed. It follows from (18) that

\[|\mathbf{X}^{\intercal}(t)\mathbf{A}_{G}(\mathbf{X}(t))\mathbf{X}(t)|\leq\| \mathbf{X}\|_{2}^{2}=\mathbf{X}^{\intercal}(t)\mathbf{X}(t)\] (19)

From (17) and (19), it follows that

\[\dot{V}(\mathbf{X}(t))\leq 2(1-\alpha)\|\mathbf{X}\|_{2}^{2}\leq 0\] (20)

when \(\alpha\geq 1\). The observation that \(V(\mathbf{X}(t))\) does not increase over time ensures that \(\mathbf{X}(t)\) stays bounded. In effect, we also have proved Lyapunov stability concerning the equilibrium point \(0\).

To prove asymptotic stability for the equilibrium point \(0\) when \(\alpha>1\), we need to show that the system not only remains bounded but also approaches \(0\) as \(t\to\infty\). This is indicated by the fact that when \(\alpha>1\), \(V(\mathbf{X}(t))<0\) unless \(\mathbf{X}(t)=0\). This signifies that \(V(\mathbf{X}(t))\) strictly declines over time unless \(\mathbf{X}(t)=0\), thereby showing that the system will converge to \(0\) as \(t\rightarrow\infty\). Notably, we can infer global asymptotic stability since \(V\) is radially unbounded [84].

The proof for the GRAND-nl case is complete.

_Proof of 2)._

We next prove the claims under GRAND-l setting.

When \(\mathbf{A}_{G}\) is either column- or row-stochastic, the spectral radius of \(\mathbf{A}_{G}(\mathbf{X}(t))\) is 1, as established by [42][Theorem 8.1.22]. The modulus of its eigenvalues is as most 1. Consider the Jordan canonical form of \(\mathbf{A}_{G}\) represented as \(\mathbf{S}\mathbf{J}\mathbf{S}^{-1}\) where \(\mathbf{J}\) stands as the Jordan form.

Given that our equation system now represents a linear time-invariant ODE, the solution to (15) can be expressed as:

\[\mathbf{X}(t) =e^{\overline{\mathbf{A}}_{G}t}\mathbf{X}(0)\] \[=\mathbf{S}e^{\overline{\mathbf{J}}t}\mathbf{S}^{-1}\mathbf{X}(0)\] (21)

where \(\bar{\mathbf{J}}=\mathbf{J}-\alpha\mathbf{I}\). Citing [42][3.2.2. page 177, 4-th equation], for \(\alpha>1\), BIBO and Lyapunov stabilities are attained. Notably, for \(\alpha>1\), the system achieves global asymptotic stability around the equilibrium point 0 under any disturbances.

Further, by considering strong connectedness and referencing the Perron-Frobenius theorem [42][Theorem 8.4.4], it is deduced that \(1\) serves as the simple eigenvalue for \(\mathbf{A}_{G}\). In this case, when \(\alpha=1\), we still have BIBO stability and Lyapunov stability according to [42][3.2.2. page 177, 4-th equation].

_Proof of 3)._

We subsequently demonstrate that when \(\mathbf{A}_{G}\) is selected to be column-stochastic and \(\alpha=1\), GRAND conserves a certain quantity interpretable as energy. Specifically, this "energy" refers to the sum of the elements of \(\mathbf{X}(t)\), denoted as \(\mathbf{1}^{\intercal}\mathbf{X}(t)\), with \(\mathbf{1}\) representing an all-ones vector. From (15), this quantity remains conserved if

\[0=\frac{\mathrm{d}\mathbf{1}^{\intercal}\mathbf{X}(t)}{\mathrm{d}t}=\mathbf{1 }^{\intercal}\overline{\mathbf{A}}_{G}(\mathbf{X}(t))\mathbf{X}(t)\] (22)

Given that \(\mathbf{A}_{G}\) is column-stochastic, it follows directly that \(\mathbf{1}^{\intercal}\overline{\mathbf{A}}_{G}=\mathbf{0}^{\intercal}\), validating (22).

Finally, we aim to prove that GRAND is asymptotic stable concerning a specified equilibrium vector when \(\alpha=1\) and the graph is aperiodic and strongly connected. Based on [42][Theorem 3.2.5.2.,Theorem 8.5.3.] and [85][Theorem 5.6.6], we observe that \(\lim_{k\rightarrow\infty}(\mathbf{A}_{G})^{k}=\lim_{k\rightarrow\infty} \mathbf{S}\mathbf{J}^{k}\mathbf{S}^{-1}=\mathbf{S}\mathbf{A}\mathbf{S}^{-1}\), where \(\mathbf{\Lambda}\) is a diagonal matrix with the first element as \(1\) and all the others as \(0\):

\[\mathbf{\Lambda}=\left(\begin{array}{cccc}1&&&&\\ &0&&&\\ &&\ddots&\\ &&&0\end{array}\right)\]

Since \(\lim_{k\rightarrow\infty}(\mathbf{A}_{G})^{k}\) maintains its column stochasticity and the rank of \(\mathbf{S}\mathbf{\Lambda}\mathbf{S}^{-1}\) is 1, it follows that each column is the **same**. Due to the zeros in \(\mathbf{\Lambda}\), the limit is the outer product of the first column of \(\mathbf{S}\) and the first row of \(\mathbf{S}^{-1}\). Since we have the same column for the outer product, we deduce that the first row of \(\mathbf{S}^{-1}\) is \(a\mathbf{1}^{\intercal}\) with \(a\) being a scalar and \(\mathbf{1}\) an all-ones vector. We have \(\overline{\mathbf{A}}_{G}\) has an eigenvalue of 0, with the rest of the eigenvalues having _strictly negative real parts_. According to [42][3.2.2], it follows that

\[\lim_{t\to 0}\mathbf{X}(t)=\lim_{t\to 0}\mathbf{S}e^{ \overline{\mathbf{J}}t}\mathbf{S}^{-1}\mathbf{X}(0)=\mathbf{S}\mathbf{ \Lambda}\mathbf{S}^{-1}\mathbf{X}(0)\] (23)

If \(s\coloneqq\mathbf{1}^{\intercal}\mathbf{X}(0)\) remains constant for any perturbed \(\mathbf{X}(0)\), we have that \(\lim_{t\to 0}\mathbf{X}(t)=sa\mathbf{s}\) where \(\mathbf{s}\) is the first column of \(\mathbf{S}\). We thus conclude that if the perturbation on \(\mathbf{X}(0)\) maintains the column summations, i.e. the "energy", unchanged, the asymptotic convergence to the equilibrium vector \(sa\mathbf{s}\) remains unaffected.

The proof is now complete.

Proof of Theorem 2

The energy conservation of our system, represented as \(H_{\mathrm{net}}\) in (9), remains invariant over time. To understand this better, consider the following

\[\frac{\mathrm{d}H_{\mathrm{net}}}{\mathrm{d}t} =\sum_{i=1}^{n}\frac{\partial H_{\mathrm{net}}}{\partial q_{i}} \dot{q}_{i}+\sum_{i=1}^{n}\frac{\partial H_{\mathrm{net}}}{\partial p_{i}}\dot{ p}_{i}\] \[=\sum_{i=1}^{n}\frac{\partial H_{\mathrm{net}}}{\partial q_{i}} \frac{\partial H_{\mathrm{net}}}{\partial p_{i}}+\sum_{i=1}^{n}\frac{\partial H _{\mathrm{net}}}{\partial p_{i}}\left(-\frac{\partial H_{\mathrm{net}}}{ \partial q_{i}}\right)\] \[=0.\]

where the last equality follows from (10).

BIBO stability is inferred since, with an unbounded output, the energy conservation expressed by \(H_{\mathrm{net}}\) would be violated.

## Appendix G Complete Algorithm Summary

We present the complete algorithm of HANG in Algorithm 1, which unfortunately had been delayed in its inclusion within the main paper due to space constraints.

### Limitations

While our work on graph neural flows presents promising advancements in enhancing adversarial robustness of GNNs using Hamiltonian-inspired neural ODEs, it is not without limitations. As we demonstrated in the paper, the notions of stability borrowed from dynamical systems, such as BIBO stability and Lyapunov stability, do not always guarantee adversarial robustness. Our finding that energy-conservative Hamiltonian graph flows improve robustness is only one facet of the broader landscape of potential stability measures. It is possible that other notions of stability, not covered in this work, could yield additional insights into adversarial robustness. Our current Hamiltonian graph neural flows do not explicitly account for quasi-periodic motions in the graph dynamics. The Kolmogorov-Arnold-Moser (KAM) theory, a foundational theory in Hamiltonian dynamics, is renowned for its analysis of persistence of quasi-periodic motions under small perturbations in Hamiltonian dynamical systems. While the energy-conserving nature of our Hamiltonian-inspired model inherently offers some level of robustness to perturbations, an explicit incorporation of KAM theory could potentially further improve the robustness, particularly in the face of quasi-periodic adversarial attacks. However, this is a complex task due to the high dimensionality of typical graph datasets and the intricacies involved in approximating quasi-periodic dynamics.

### Broader Impact

This research, centered on enhancing adversarial robustness in graph neural networks (GNNs), carries implications for various sectors, such as social media networks, sensor networks, and chemistry. By improving the resilience of GNNs, we can boost the reliability of AI-driven systems, contributing to greater efficiency, productivity, and cost-effectiveness. The shift towards automation may displace certain jobs, raising ethical concerns about income disparity and job security. Moreover, while our models enhance robustness, potential system failures can still occur, with impacts varying based on the application. Lastly, the robustness conferred might be exploited maliciously. Our work underscores the importance of diligent oversight, equitable technology implementation, and continuous innovation in the development of AI technologies.

[MISSING_PAGE_EMPTY:24]