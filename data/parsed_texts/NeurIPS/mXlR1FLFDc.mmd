# A Compositional Atlas for Algebraic Circuits

 Benjie Wang

University of California, Los Angeles

benjiewang@ucla.edu

&Denis Deratani Maua

University of Sao Paulo

ddm@ime.usp.br

Guy Van den Broeck

University of California, Los Angeles

guyvdb@cs.ucla.edu

&YooJung Choi

Arizona State University

yj.choi@asu.edu

###### Abstract

Circuits based on sum-product structure have become a ubiquitous representation to compactly encode knowledge, from Boolean functions to probability distributions. By imposing constraints on the structure of such circuits, certain inference queries become tractable, such as model counting and most probable configuration. Recent works have explored analyzing probabilistic and causal inference queries as compositions of basic operators to derive tractability conditions. In this paper, we take an _algebraic_ perspective for _compositional inference_, and show that a large class of queries--including marginal MAP, probabilistic answer set programming inference, and causal backdoor adjustment--correspond to a combination of basic operators over semirings: aggregation, product, and elementwise mapping. Using this framework, we uncover simple and general sufficient conditions for tractable composition of these operators, in terms of circuit properties (e.g., marginal determinism, compatibility) and conditions on the elementwise mappings. Applying our analysis, we derive novel tractability conditions for many such compositional queries. Our results unify tractability conditions for existing problems on circuits, while providing a blueprint for analysing novel compositional inference queries.

## 1 Introduction

Circuit-based representations, such as Boolean circuits, decision diagrams, and arithmetic circuits, are of central importance in many areas of AI and machine learning. For example, a primary means of performing inference in many models, from Bayesian networks [16; 9] to probabilistic programs [20; 24; 26; 43], is to convert them into equivalent circuits; this is commonly known as _knowledge compilation_. Inference via knowledge compilation has also been used for many applications in neuro-symbolic AI, such as constrained generation [2; 54] and neural logic programming [34; 28]. Circuits can also be _learned_ as probabilistic generative models directly from data [25; 41; 40; 32], in which context they are known as probabilistic circuits [11]. Compared with neural generative models, probabilistic circuits enjoy tractable evaluation of inference queries such as marginal probabilities, which has been used for tasks such as fair machine learning [12] and causal reasoning [53; 50; 49].

The key feature of circuits is that they enable one to precisely characterize _tractability conditions_ (structural properties of the circuit) under which a given _inference query_ can be computed exactly and efficiently. One can then enforce these circuit properties when compiling or learning a model to enable tractable inference. For many basic inference queries, such as computing a marginal probability, tractability conditions are well understood [48; 8]. However, for more complex queries, the situation is less clear, and the exercise of deriving algorithms and tractability conditions for a given query has usually been carried out in an instance-specific manner requiring significant effort.

In Figure 1, we illustrate two such queries. The marginal MAP (MMAP) [13] query takes a probabilistic circuit \(p\) and some evidence \(\bm{e}\) and asks for the most likely assignment of a subset of variables. The success probability inference in probabilistic logic programming [6; 45] takes a circuit representation \(\phi\) of a logic program, a weight function \(\omega\) and some query \(\bm{q}\), and computes the probability of the query under the program's semantics (MaxEnt, in the example). At first glance, these seem like very different queries, involving different types of input circuits (logical and probabilistic), and different types of computations. However, they share similar _algebraic structure_: logical and probabilistic circuits can be interpreted as circuits defined over different _semirings_, while maximization and summation can be viewed as _aggregation_ over different semirings. In this paper, inspired by the compositional atlas for probabilistic circuits [48], we take a _compositional_ approach to algebraic inference problems, breaking them down into a series of basic operators: aggregation, product, and elementwise mapping. For example, the MMAP and probabilistic logic programming queries involve multiple interleaved aggregations and products, along with one elementwise mapping each. Given a circuit algorithm (and associated tractability condition) for each basic operator, we can reuse these algorithms to construct algorithms for arbitrary compositions. The key challenge is then to check if each intermediate circuit satisfies the requisite tractability conditions.

Our contributions can be summarized as follows. We introduce a compositional inference framework for _algebraic_ circuits (Section 3) over arbitrary semirings, generalizing existing results on logical [18] and probabilistic [48] circuits. In particular, we provide a language for specifying inference queries involving _different_ semirings as a composition of basic operators (Section 3.1). We then prove sufficient conditions for the tractability of each basic operator (Section 3.2) and novel conditions for composing such operators (Section 3.3). We apply our compositional framework to a number of inference problems (Section 4), showing how our compositional approach leads to more systematic derivation of tractability conditions and algorithms, and in some cases improved complexity analysis. In particular, we discover a tractability hierarchy for inference queries captured under the 2AMC framework [29], and reduce the complexity of causal backdoor/frontdoor adjustment on probabilistic circuits [38; 49] from quadratic/cubic to linear/quadratic respectively.

## 2 Preliminaries

NotationWe use capital letters (e.g., \(X,Y\)) to denote variables and lowercase for assignments (values) of those variables (e.g., \(x,y\)). We use boldface to denote sets of variables/assignments (e.g., \(\bm{X},\bm{y}\)) and write \(\text{Assign}(\bm{V})\) for the set of all assignments to \(\bm{V}\). Given a variable assignment \(\bm{v}\) of \(\bm{V}\), and a subset of variables \(\bm{W}\subseteq\bm{V}\), we write \(\bm{v_{W}}\) to denote the assignment of \(\bm{W}\) corresponding to \(\bm{v}\).

SemiringsIn this paper, we consider inference problems over commutative _semirings_. Semirings are sets closed w.r.t. operators of addition (\(\oplus\)) and multiplication (\(\otimes\)) that satisfy certain properties:

**Definition 1** (Commutative Semiring).: _A commutative semiring \(\mathcal{S}\) is a tuple \((S,\oplus,\otimes,0_{\mathcal{S}},1_{\mathcal{S}})\), where \(\oplus\) and \(\otimes\) are associative and commutative binary operators on a set \(S\) (called the domain) such that \(\otimes\) distributes over \(\oplus\) (i.e., \(a\otimes(b\oplus c)=(a\otimes b)\oplus(a\otimes c)\) for all \(a,b,c\in S\)); \(0_{\mathcal{S}}\in S\) is the additive identity (i.e., \(0_{\mathcal{S}}\oplus a=a\) for all \(a\in S\)) and annihilates \(S\) through multiplication (i.e., \(0_{\mathcal{S}}\otimes a=0\) for all \(a\in S\)); and \(1_{\mathcal{S}}\in S\) is the multiplicative identity (i.e., \(1_{\mathcal{S}}\otimes a=a\) for all \(a\in S\))._

For example, the probability semiring \(\mathcal{P}=(\mathbb{R}_{\geq 0},+,\cdot,0,1)\) employs standard addition and multiplication (\(\oplus=+\) and \(\otimes=\cdot\)) over the non-negative reals, the \((\max,\cdot)\) semiring \(\mathcal{M}=(\mathbb{R}_{\geq 0},\max,\cdot,0,1)\)

Figure 1: Example applications of our compositional inference framework for _(Left)_ MMAP and _(Right)_ Success Probability in Prob. Logic Programing under the Stable Model semantics (MaxEnt).

replaces addition with maximization, while the Boolean semiring \(\mathcal{B}=(\{\bot,\top\},\vee,\wedge,\bot,\top)\) employs disjunction and conjunction operators (\(\oplus=\vee\) and \(\otimes=\wedge\)) over truth values.

Algebraic CircuitsWe now define the concept of an algebraic circuit, which are computational graph-based representations of functions taking values in an arbitrary semiring.

**Definition 2** (Algebraic Circuit).: _Given a semiring \(\mathcal{S}=(S,\oplus,\otimes,0_{\mathcal{S}},1_{\mathcal{S}})\), an algebraic circuit \(C\) over variables \(\bm{V}\) is a rooted directed acyclic graph (DAG), whose nodes \(\alpha\) have the following syntax:_

\[\alpha::=l\mid+_{i=1}^{k}\alpha_{i}\mid\times_{i=1}^{k}\alpha_{i}\,,\]

_where \(\alpha_{i}\in C\) are circuit nodes, \(k\in\mathbb{N}^{>0}\) and \(l:\text{Assign}(\bm{W})\to S\) is a function over a (possibly empty) subset \(\bm{W}\subseteq\bm{V}\) of variables, called its scope. That is, each circuit node may be an input (\(l\)), sum (\(+\)), or a product (\(\times\)). The scope of any internal node is defined to be \(\text{vars}(\alpha):=\cup_{i=1}^{k}\text{vars}(\alpha_{i})\). Each node \(\alpha\) represents a function \(p_{\alpha}\) taking values in \(S\), defined recursively by: \(p_{\alpha}(\bm{w}):=l(\bm{w})\) if \(\alpha=l\), \(p_{\alpha}(\bm{w})::=\oplus_{i=1}^{k}p_{\alpha_{i}}(\bm{w})\) if \(\alpha=+_{i=1}^{k}\alpha_{i}\), and \(p_{\alpha}(\bm{w})::=\otimes_{i=1}^{k}p_{\alpha_{i}}(\bm{w})\) if \(\times_{i=1}^{k}\alpha_{i}\), where \(\bm{W}\) is the scope of \(\alpha\). The function \(p_{C}\) represented by the circuit is defined to be the function of the root node. The size \(|C|\) of a circuit is defined to be the number of edges in the DAG._

For simplicity, we will restrict to circuits with binary products (i.e. \(k=2\) for products); this can be enforced with at most a linear increase in size. Prominent examples of algebraic circuits include negation normal forms (NNF) and binary decision diagrams [4]--which are over the Boolean semiring and represent Boolean functions--and probabilistic circuits [11]--which are over the probabilistic semiring and represent probability distributions.1 By imposing simple restrictions on the circuit, which we call _circuit properties_, various inference queries that are computationally hard in general become tractable. In particular, smoothness and decomposability ensure tractable marginal inference:

Footnote 1: Probabilistic circuits are sometimes written with weights on the edges; this can easily be translated to our formalism by replacing the child of a weighted edge with a product of itself and an input function with empty scope corrresponding to the weight [44, 42].

**Definition 3** (Smoothness, Decomposability).: _A circuit is smooth if for every sum node \(\alpha=+_{i}\alpha_{i}\), its children have the same scope: \(\forall i,j,\ \text{vars}(\alpha_{i})=\text{vars}(\alpha_{j})\). A circuit is decomposable if for every product node \(\alpha=\alpha_{1}\times\alpha_{2}\), its children have disjoint scopes: \(\text{vars}(\alpha_{1})\cap\text{vars}(\alpha_{2})=\emptyset\)._

Aside from the scopes of circuit nodes, we can also specify properties relating to their _supports_[11]:

**Definition 4** (\(\bm{X}\)-Support).: _Given a partition \((\bm{X},\bm{Y})\) of variables \(\bm{V}\) and a node \(\alpha\) in circuit \(C\), the \(\bm{X}\)-support of \(\alpha\) is the projection of its support on \(\bm{X}\):_

\[\text{supp}_{\bm{X}}(\alpha)=\{\bm{x}\in\text{Assign}(\bm{X}\cap\text{vars} (\alpha)):\exists\bm{y}\in\text{Assign}(\text{vars}(\alpha)\setminus\bm{X}) \text{ s.t. }p_{\alpha}(\bm{x},\bm{y})\neq 0_{\mathcal{S}}\}.\]

**Definition 5** (\(\bm{X}\)-Determinism).: _Given a circuit \(C\) and a partition \((\bm{X},\bm{Y})\) of \(\bm{V}\), we say that \(C\) is \(\bm{X}\)-deterministic if for all sum nodes \(\alpha=+_{i=1}^{k}\alpha_{i}\), either: (i) \(\text{vars}(\alpha)\cap\bm{X}=\emptyset\); or (ii) \(\text{supp}_{\bm{X}}(\alpha_{i})\cap\text{supp}_{\bm{X}}(\alpha_{j})=\emptyset\) for all \(i\neq j\)._

\(\bm{X}\)-determinism refers to a family of properties indexed by sets \(\bm{X}\). In particular \(\bm{V}\)-determinism is usually referred to simply as determinism. Note that, as defined, scope and support, and thus these circuit properties, apply to any semiring: the scope only depends on the variable decomposition of the circuit, while the support only refers to scope and the semiring additive identity \(0_{\mathcal{S}}\). Figure 1(a) shows a simple example of a smooth, decomposable, and deterministic circuit that is not \(X\)-deterministic, while Figure 1(b) shows a smooth, decomposable, and \(\{X_{1},X_{2}\}\)-deterministic circuit.

Figure 2: Examples of Algebraic Circuits. We use \(\bm{\mathsf{O}},\bm{\mathsf{O}}\) to represent input, sum and product nodes respectively.

## 3 Compositional Inference: A Unifying Approach

Many inference problems can be written as _compositions of basic operators_, which take as input one or more functions and output another function. For example, the marginal MAP query on probability distributions \(\max_{\bm{x}}\sum_{\bm{y}}p(\bm{x},\bm{y})\) is a composition of the \(\sum\) and \(\max\) operators. Similarly, for Boolean functions \(\phi,\psi\), the query \(\sum_{\bm{x}}\exists\bm{y}.\,\phi(\bm{x},\bm{y})\wedge\psi(\bm{x},\bm{y})\) composes the \(\sum\), \(\exists\) and \(\wedge\) operators. Although these queries appear to involve four different operators, three of them \((\sum,\max,\exists)\) can be viewed as an _aggregation_ operation over _different_ semirings. Thus, we begin this section by consolidating to a simple set of three operators applicable to functions taking values in some semiring: namely, aggregation, product, and elementwise mapping (Section 3.1).

Equipped with this language for specifying compositional inference queries, we then move on to analyzing their tractability when the input functions are given as circuits. The thesis of this paper is that algebraic structure is often the right level of abstraction to derive useful sufficient (and sometimes necessary) conditions for tractability. We firstly show _tractability conditions_ of each of the basic operators (Section 3.2), before deriving _composability conditions_ showing how circuit properties are maintained through operators (Section 3.3). This enables us to systematically derive conditions for the input circuits that enable efficient computation of a compositional inference query. Algorithms and detailed proofs of all theorems can be found in Appendix A.

### Basic Operators

AggregationGiven a function \(f:\operatorname{Assign}(\bm{V})\to S\), _aggregating_\(f\) over \(\bm{W}\subseteq\bm{V}\) returns the function \(f^{\prime}:\operatorname{Assign}(\bm{Z})\to S\) for \(\bm{Z}=\bm{V}\setminus\bm{W}\) defined by \(f^{\prime}(\bm{z}):=\bigoplus_{\bm{w}}f(\bm{z},\bm{w})\).

For example, aggregation corresponds to forgetting variables \(\bm{W}\) in the Boolean semiring, marginalizing out \(\bm{W}\) in the probability semiring, and maximizing over assignments in the \((\max,\cdot)\) semiring. Next, some queries, such as divergence measures between probability distributions, take two functions as input, and many others involve combining two or more intermediate results, as is the case in probabilistic answer set programming inference and causal backdoor/frontdoor queries. We define the product operator to encapsulate such "combination" of functions in general.

ProductGiven two functions \(f:\operatorname{Assign}(\bm{W})\to S\) and \(f^{\prime}:\operatorname{Assign}(\bm{W}^{\prime})\to S\), the _product of \(f\) and \(f^{\prime}\)_ is a function \(f^{\prime\prime}:\operatorname{Assign}(\bm{V})\to S\), where \(\bm{V}=\bm{W}\cup\bm{W}^{\prime}\), defined by \(f^{\prime\prime}(\bm{v}):=f(\bm{v_{W}})\otimes f^{\prime}(\bm{v_{W^{\prime}}})\).

For example, a product corresponds to the conjoin operator \(\wedge\) in the Boolean semiring, and standard multiplication \(\cdot\) in the probability semiring. Lastly, we introduce the _elementwise mapping_ operator, defined by a mapping \(\tau\) from a semiring to a (possibly different) semiring. When applied to a function \(f\), it returns the function composition \(\tau\circ f\). This is the key piece that distinguishes our framework from prior analysis of sum-of-product queries over specific semirings, allowing us to express queries such as causal inference and probabilistic logic programming inference under the same framework.

Elementwise MappingGiven a function \(f:\operatorname{Assign}(\bm{V})\to S\) and a mapping \(\tau:S\to S^{\prime}\) from semiring \(\mathcal{S}\) to \(\mathcal{S}^{\prime}\) satisfying \(\tau(0_{\mathcal{S}})=0_{\mathcal{S}^{\prime}}\), an _elementwise mapping of \(f\) by \(\tau\)_ results in a function \(f^{\prime}:\operatorname{Assign}(\bm{V})\to S^{\prime}\) defined by \(f^{\prime}(\bm{v}):=\tau(f(\bm{v}))\).2

Footnote 2: In a slight abuse of notation, we will write \(\tau:\mathcal{S}\to\mathcal{S}^{\prime}\) to indicate that \(\tau\) maps between the respective sets.

In practice, we use elementwise mappings as an abstraction predominantly for two purposes. The first is for switching between semirings, while the second is to map between elements of the same semiring. For the former, one of the most important elementwise mappings we will consider is the _support mapping_, which maps between any two semirings as follows.

**Definition 6** (Support Mapping).: _Given a source semiring \(\mathcal{S}\) and a target semiring \(\mathcal{S}^{\prime}\), the support mapping \([\![\cdot]\!]_{\mathcal{S}\to\mathcal{S}^{\prime}}\) is defined as: \([\![a]\!]_{\mathcal{S}\to\mathcal{S}^{\prime}}=0_{\mathcal{S}^{\prime}}\) if \(a=0_{\mathcal{S}}\); \([\![a]\!]_{\mathcal{S}\to\mathcal{S}^{\prime}}=1_{\mathcal{S}^{\prime}}\) otherwise._

In particular we will often use the source semiring \(\mathcal{S}=\mathcal{B}\), in which case the support mapping maps \(\bot\) to the \(0_{\mathcal{S}^{\prime}}\) and \(\top\) to the \(1_{\mathcal{S}^{\prime}}\) in the target semiring. This is useful for encoding a logical function for inference in another semiring, e.g. probabilistic inference in the probabilistic semiring.

**Example 1** (Marginal MAP).: _Suppose that we are given a Boolean formula \(\phi(\bm{X},\bm{Y})\) and a weight function \(w:\text{Assign}(\bm{X}\cup\bm{Y})\to\mathbb{R}_{\geq 0}\). The marginal MAP query for variables \(\bm{X}\) is defined by_

\[\text{MMAP}(\phi,\omega)=\max_{\bm{x}}\sum_{\bm{y}}\phi(\bm{x},\bm{y})\cdot \omega(\bm{x},\bm{y})\,,\]

_where we interpret \(\top\) as \(1\) and \(\bot\) as 0. We can break this down into a compositional query as follows:_

\[\bigoplus_{\bm{x}}\tau_{id,\mathcal{P}\to\mathcal{M}}\left[\bigoplus_{\bm{y}} \llbracket\phi(\bm{x},\bm{y})\rrbracket_{\mathcal{B}\to\mathcal{P}}\otimes \omega(\bm{x},\bm{y})\right]\,.\]

_The support mapping ensures \(\phi\) and \(\omega\) are both functions over the probabilistic semiring, so that we can apply the product operation. Notice also the inclusion of an identity mapping \(\tau_{id,\mathcal{P}\to\mathcal{M}}\) from the probability to the \((\max,\cdot)\) semiring defined by \(\tau_{id,\mathcal{P}\to\mathcal{M}}(x)=x\) for all \(x\in\mathbb{R}_{\geq 0}\). While differentiating between semirings over the same domain may seem superfluous, the explicit identity operator will become important when we analyze the tractability of these compositions on circuits._

### Tractability Conditions for Basic Operators

We now consider the tractability of applying each basic operator to circuits: that is, computing a circuit whose function corresponds to the result of applying the operator to the functions given by the input circuit(s). First, it is well known that forgetting and marginalization of any subset of variables can be performed in polynomial time if the input circuits in the respective semirings (NNF and PC) are smooth and decomposable [18; 11]. This can be generalized to arbitrary semirings:

**Theorem 1** (Tractable Aggregation).: _Let \(C\) be a smooth and decomposable circuit representing a function \(p:\text{Assign}(\bm{V})\to S\). Then for any \(\bm{W}\subseteq\bm{V}\), it is possible to compute the aggregate as a smooth and decomposable circuit \(C^{\prime}\) (i.e., \(p_{C^{\prime}}(\bm{Z})=\bigoplus_{\bm{w}}p_{C}(\bm{Z},\bm{w})\)) in \(O(|C|)\) time and space._

Next, let us consider the product operator. In the Boolean circuits literature, it is well known that the conjoin operator can be applied tractably if the circuits both follow a common structure known as a _vtree_[17]. In [48] a more general property known as _compatibility_ was introduced that directly specifies conditions with respect to two (probabilistic) circuits, without reference to a vtree. We now define a generalization of this property (\(\bm{X}\)-compatibility) and also identify a new condition (\(\bm{X}\)-support-compatibility) that enables tractable products.

**Definition 7** (\(\bm{X}\)-Compatibility).: _Given two smooth and decomposable circuits \(C,C^{\prime}\) over variables \(\bm{V},\bm{V}^{\prime}\) respectively, and a variable set \(\bm{X}\subseteq\bm{V}\cap\bm{V^{\prime}}\), we say that \(C,C^{\prime}\) are \(\bm{X}\)-compatible if for every product node \(\alpha=\alpha_{1}\times\alpha_{2}\in C\) and \(\alpha^{\prime}=\alpha^{\prime}_{1}\times\alpha^{\prime}_{2}\in C^{\prime}\) such that \(\operatorname{vars}(\alpha)\cap\bm{X}=\operatorname{vars}(\alpha^{\prime}) \cap\bm{X}\), the scope is partitioned in the same way, i.e. \(\operatorname{vars}(\alpha_{1})\cap\bm{X}=\operatorname{vars}(\alpha^{ \prime}_{1})\cap\bm{X}\) and \(\operatorname{vars}(\alpha_{2})\cap\bm{X}=\operatorname{vars}(\alpha^{ \prime}_{2})\cap\bm{X}\). We say that \(C,C^{\prime}\) are compatible if they are \((\bm{V}\cap\bm{V}^{\prime})\)-compatible._

Intuitively, compatibility states that the scopes of the circuits decompose in the same way at product nodes. Compatibility of two circuits suffices to be able to tractably compute their product:

**Theorem 2** (Tractable Product - Compatibility).: _Let \(C,C^{\prime}\) be compatible circuits over variables \(\bm{V},\bm{V}^{\prime}\), respectively, and the same semiring. Then it is possible to compute their product as a circuit \(C\) compatible with them (i.e., \(p_{C^{\prime\prime}}(\bm{V}\cup\bm{V}^{\prime})=p_{C}(\bm{V})\otimes p_{C^{ \prime}}(\bm{V}^{\prime})\)) in \(O(|C||C^{\prime}|)\) time and space._

We remark that if we are given a fully factorized function \(f(\bm{V})=\bigotimes_{V_{i}\in\bm{V}}f_{i}(V_{i})\), this can be arranged as a circuit (series of binary products) compatible with any other decomposable circuit; thus, we say this type of function is _omni-compatible_. We also say that a circuit is _structured decomposable_ if it is compatible with itself. Now, our more general definition of \(\bm{X}\)-compatibility states that the scopes of the circuits _restricted to \(\bm{X}\)_ decompose in the same way at product nodes. This will be important when we consider composing products with other operators, such as aggregation. The following result shows that compatibility w.r.t. a subset is a weaker condition:

**Proposition 1** (Properties of \(\bm{X}\)-Compatibility).: _If two circuits \(C,C^{\prime}\) are \(\bm{X}\)-compatible, then they are \(\bm{X}^{\prime}\)-compatible for any subset \(\bm{X}^{\prime}\subseteq\bm{X}\)._

Compatibility is a sufficient but not necessary condition for tractable products. Some non-compatible circuits can be efficiently _restructured_ to be compatible, such that we can then apply Theorem 2; we refer readers to [55] for details. Alternatively, it is also known that deterministic circuits can be multiplied with themselves in linear time, even when they are not structured decomposable [48; 27]. We formalize this idea with a new property that we call _support-compatibility_.

**Definition 8** (\(X\)-Support Compatibility).: _Given two smooth and decomposable circuits \(C,C^{\prime}\) over variables \(\bm{V},\bm{V}^{\prime}\) respectively, and a set of variables \(\bm{X}\subseteq\bm{V}\cap\bm{V}^{\prime}\), let \(C[\bm{X}],C^{\prime}[\bm{X}]\) be the DAGs obtained by restricting to nodes with scope overlapping with \(\bm{X}\). We say that \(C,C^{\prime}\) are \(\bm{X}\)-support-compatible if there is an isomorphism \(\iota\) between \(C[\bm{X}],C^{\prime}[\bm{X}]\) such that: (i) for any node \(\alpha\in C[\bm{X}]\), \(\text{\rm{vars}}(\alpha)\cap\bm{X}=\text{\rm{vars}}(\iota(\alpha))\cap\bm{X}\); (ii) for any sum node \(\alpha\in C[\bm{X}]\), \(\text{\rm{supp}}_{\bm{X}}(\alpha_{i})\cap\text{\rm{supp}}_{\bm{X}}(\iota( \alpha_{j}))=\emptyset\) whenever \(i\neq j\). We say that \(C,C^{\prime}\) are support-compatible if they are \((\bm{V}\cap\bm{V}^{\prime})\)-support-compatible._

To unpack this definition, we note that any smooth, decomposable, and \(\bm{X}\)-deterministic circuit is \(\bm{X}\)-support-compatible with itself, with the obvious isomorphism. However, this property is more general in that it allows for circuits over different sets of variables and does not require that the nodes represent exactly the same function; merely that the sum nodes have "compatible" support decompositions. As we will later see, the significance of this property is that it can be often maintained through applications of operators, making it useful for compositions.

**Theorem 3** (Tractable Product - Support Compatibility).: _Let \(C,C^{\prime}\) be support-compatible circuits over variables \(\bm{V},\bm{V}^{\prime}\), respectively, and the same semiring. Then, given the isomorphism \(\iota\), it is possible to compute their product as a smooth and decomposable circuit \(C^{\prime\prime}\) support-compatible with them (i.e., \(p_{C^{\prime\prime}}(\bm{V}\cup\bm{V}^{\prime})=p_{C}(\bm{V})\otimes p_{C^{ \prime}}(\bm{V}^{\prime})\)) in \(O(\max(|C|,|C^{\prime}|))\) time and space._

We now examine the tractability of general elementwise mappings \(\tau:\mathcal{S}\to\mathcal{S}^{\prime}\) on a circuit \(C\). It is tempting here to simply construct a new circuit \(C^{\prime}\) over the semiring \(\mathcal{S}^{\prime}\) with the same structure as \(C\), and replace each input function \(l\) in the circuit with \(\tau(l)\). However, the resulting circuit \(p_{C^{\prime}}(\bm{V})\) is not guaranteed to correctly compute \(\tau(p_{C}(\bm{V}))\) in general. For example, consider the support mapping \(\llbracket\cdot\rrbracket_{\mathcal{B}\to\mathcal{S}}\)--which maps \(\bot\) to \(0_{\mathcal{S}}\) and \(\top\) to \(1_{\mathcal{S}}\)--for the probability semiring \(\mathcal{S}=(\mathbb{R}_{\geq 0},+,\cdot,0,1)\). Then the transformation of the smooth and decomposable circuit \(C=X\lor X\) produces \(C^{\prime}=\llbracket X\rrbracket+\llbracket X\rrbracket\), which evaluates to \(p_{C^{\prime}}(X=\top)=2\) whereas \(\tau(p_{C}(X=\top))=1\). In order for this simple algorithm to be correct, we need to impose certain conditions on the elementwise mapping \(\tau\) and/or the circuit \(C\) it is being applied to.

**Theorem 4** (Tractable Mapping).: _Let \(C\) be a smooth and decomposable circuit over semiring \(\mathcal{S}\), and \(\tau:\mathcal{S}\to\mathcal{S}^{\prime}\) a mapping such that \(\tau(0_{\mathcal{S}})=0_{\mathcal{S}^{\prime}}\). Then it is possible to compute the mapping of \(C\) by \(\tau\) as a smooth and decomposable circuit \(C^{\prime}\) (i.e., \(p_{C^{\prime}}(\bm{V})=\tau(p_{C}(\bm{V}))\)) in \(O(|C|)\) time and space if \(\tau\) distributes over sums and over products._

\(\tau\) distributes over sums _if: either **(Additive)**\(\tau\) is an additive homomorphism, i.e. \(\tau(a\oplus b)=\tau(a)\oplus\tau(b)\); or **(Det)**\(C\) is deterministic._

\(\tau\) distributes over products _if: either **(Multiplicative)**\(\tau\) is an multiplicative homomorphism, i.e. \(\tau(a\otimes b)=\tau(a)\otimes\tau(b)\); or **(Prod 0/1)**\(\tau(1_{\mathcal{S}})=1_{\mathcal{S}^{\prime}}\), and for all product nodes \(\alpha=\alpha_{1}\times\alpha_{2}\in C\), and for every value \(\bm{v}\in\text{\rm{Assign}}(\text{\rm{vars}}(\alpha)),\) either \(p_{\alpha_{1}}(\bm{v}_{\text{\rm{vars}}(\alpha_{1})})\in\{0_{\mathcal{S}},1_{ \mathcal{S}}\}\) or \(p_{\alpha_{2}}(\bm{v}_{\text{\rm{vars}}(\alpha_{2})})\in\{0_{\mathcal{S}},1_{ \mathcal{S}}\}\)._

We can apply Theorem 4 to immediately derive the following property of support mappings:

**Corollary 1** (Support Mapping).: _Given a circuit \(C\) over a semiring \(\mathcal{S}\) and any target semiring \(\mathcal{S}^{\prime}\), a circuit representing \(\llbracket p_{C}\rrbracket_{\mathcal{S}\to\mathcal{S}^{\prime}}\) can be computed tractably if (i) \(\mathcal{S}\) satisfies \(a\oplus b=0_{\mathcal{S}}\implies a=b=0_{\mathcal{S}}\) and \(\mathcal{S}^{\prime}\) is idempotent (i.e., \(1_{\mathcal{S}^{\prime}}\oplus 1_{\mathcal{S}^{\prime}}=1_{\mathcal{S}^{\prime}}\)), or (ii) \(C\) is deterministic._

Proof.: First note that \(\llbracket\cdot\rrbracket_{\mathcal{S}\to\mathcal{S}^{\prime}}\) satisfies (Multiplicative), and thus distributes over products. If (i) holds, consider \(\llbracket a\oplus b\rrbracket_{\mathcal{S}\to\mathcal{S}^{\prime}}\). If \(a=b=0_{\mathcal{S}}\), then this is equal to \(\llbracket 0_{\mathcal{S}}\rrbracket_{\mathcal{S}\to\mathcal{S}^{\prime}}= \llbracket a\rrbracket_{\mathcal{S}\to\mathcal{S}^{\prime}}+\llbracket b \rrbracket_{\mathcal{S}\to\mathcal{S}^{\prime}}=0_{\mathcal{S}^{\prime}}\); otherwise \(a,b,a\oplus b\neq 0_{\mathcal{S}}\) and \(\llbracket a\oplus b\rrbracket_{\mathcal{S}\to\mathcal{S}^{\prime}}= \llbracket a\rrbracket_{\mathcal{S}\to\mathcal{S}^{\prime}}\oplus \llbracket b\rrbracket_{\mathcal{S}\to\mathcal{S}^{\prime}}=1_{\mathcal{S}^{ \prime}}\) (by idempotence of \(\mathcal{S}^{\prime}\)). Thus \(\llbracket\cdot\rrbracket_{\mathcal{S}\to\mathcal{S}^{\prime}}\) satisfies (Additive). Alternatively, if (ii) holds, then (Det) holds. In either case \(\llbracket\cdot\rrbracket_{\mathcal{S}\to\mathcal{S}^{\prime}}\) distributes over sums in the circuit. 

The following examples illustrate the generality of elementwise mappings and Theorem 4:

**Example 2** (Partition Function and MAP).: _Given a probability distribution \(p(\bm{V})\), consider the task of computing the partition function \(\sum_{\bm{v}}p(\bm{v})\) and MAP \(\max_{\bm{v}}p(\bm{v})\). These can be viewed as aggregations over the probability and \((\max,\cdot)\) semirings respectively._

\(p\) _is often either a probabilistic circuit_ \(C_{prob}\)_, or a combination of a Boolean circuit_ \(C_{bool}\) _and weights_ \(w\) _(in weighted model counting). In the former case, the partition function is tractable because the circuit is already over the probability semiring, while in the latter case, MAP is tractable because the_ \(\mathcal{S}^{\prime}=(\max,\cdot)\) _semiring is idempotent so_ \(\llbracket C_{bool}\rrbracket_{\mathcal{B}\to\mathcal{S}^{\prime}}\) _is tractable. On the other hand, the partitionfunction for Boolean circuits and MAP for PCs require determinism for the conditions of Theorem 4 to hold; in fact, these problems are known to be NP-hard without determinism [18; 39]._

**Example 3** (Power Function in Probability Semiring).: _For the probability semiring \(\mathcal{S}=\mathcal{S}^{\prime}=(\mathbb{R}_{\geq 0},+,\cdot,0,1)\), consider the power function \(\tau_{\beta}(a):=\begin{cases}a^{\beta}&\text{if }a\neq 0\\ 0&\text{if }a=0\end{cases}\) for some \(\beta\in\mathbb{R}\). This mapping satisfies (Multiplicative), and is tractable if we enforce (Det) on the circuit._

It is worth noting that semiring homomorphisms (i.e. additive and multiplicative) are always tractable. In the case when \(\mathcal{S}=\mathcal{S}^{\prime}=\mathcal{P}\), it was shown in [48] that the only such mapping is the identity function. However this is not the case for other semirings: the power function \(\tau_{\beta}\) is an example in the \((\max,\cdot)\) semiring. To summarize, we have shown sufficient tractability conditions for aggregation, products, and elementwise mappings. Notice that the conditions for aggregation and products only depend on variable scopes and supports, and as such apply to any semiring; in contrast, for elementwise mappings, we take advantage of specific properties of the semiring(s) in question.

### Tractable Composition of Operators

We now analyze compositions of these basic operators. As such, we need to consider not only circuit properties that enable tractability, but how these properties are maintained through each operator, so that the output circuit can be used as input to another operator. We call these _composability conditions_. In all cases, the output circuit is smooth and decomposable. Thus, we focus on the properties of \(\bm{X}\)-determinism, \(\bm{X}\)-compatibility, and \(\bm{X}\)-support-compatibility. We emphasize that these are not singular properties, but rather families of properties indexed by a variable set \(\bm{X}\). We present the intuitive ideas behind our results below, while deferring full proofs to the Appendix.

**Theorem 5** (Composability Conditions).: _The results in Table 1 hold._

\(\bm{X}\)-determinismIntuitively, \(\bm{X}\)-determinism is maintained through products because the resulting sum nodes partition the \(\bm{X}\)-support in a "finer" way to the original circuits, and through elementwise mappings since they do not expand the support of any node (since \(\tau(0_{\mathcal{S}})=0_{\mathcal{S}^{\prime}}\)). For aggregation, the \(\bm{X}\)-support is maintained if aggregation does not occur over any of the variables in \(\bm{X}\).

\(\bm{X}\)-compatibilityHere, we are interested in the following question: if the input circuit(s) to some operator are \(\bm{X}\)-compatible with some other circuit \(C_{\text{other}}\) for any fixed \(\bm{X}\), is the same true of the output of the operator? \(\bm{X}\)-compatibility with \(C_{\text{other}}\) is maintained through aggregation because it weakens the condition (by Proposition 1) and through elementwise mapping as it does not change variable scopes. As for taking the product of circuits, the output circuit will maintain similar variable partitionings at products, such that it remains \(\bm{X}\)-compatible with \(C_{\text{other}}\). Notably, this result does _not_ hold for compatibility where the scope \(\bm{X}\) may be different for each pair of circuits under consideration; we show a counterexample in Example 4 in the Appendix.

\(\bm{X}\)-support-compatibility\(\bm{X}\)-support-compatibility is maintained through elementwise mappings and aggregation (except on \(\bm{X}\)) for similar reasons to \(\bm{X}\)-determinism. For products, the result retains a similar \(\bm{X}\)-support structure, so \(\bm{X}\)-support compatibility is maintained.

We conclude by remarking that, once we determine that a compositional query is tractable, then one immediately obtains a correct algorithm for computing the query by application of the generic

\begin{table}
\begin{tabular}{l l l l l l l} \hline \multirow{3}{*}{} & \multirow{3}{*}{**Conditions**} & \multicolumn{4}{c}{**If the Input Circuit(s) are...**} \\ \cline{3-6}  & & \(\bm{X}\)-Det & \(\bm{X}\)-Cmp w / \(C_{\text{other}}\) & \(\bm{X}\)-SCmp w / \(C_{\text{other}}\) & **Complexity** \\ \cline{3-6}  & & & **The Output Circuit is...** & (A.4) \\ \hline \multirow{2}{*}{**Aggr. (\(\bm{W}\))**} & \multirow{2}{*}{Sm, Dec} & \(\bm{X}\)-Det & \(\bm{X}\)-Cmp w / \(C_{\text{other}}\) & \(\bm{X}\)-SCmp w / \(C_{\text{other}}\) & \(O(|C|)\) (A.1) \\  & & if \(\bm{W}\cap\bm{X}=\emptyset\) & if \(\bm{W}\cap\bm{X}=\emptyset\) & if \(\bm{W}\cap\bm{X}=\emptyset\) & \(\bm{W}\cap\bm{X}=\emptyset\) & \(O(|C|)\) (A.1) \\ \hline \multirow{2}{*}{**Product**} & \multirow{2}{*}{Cmp} & \(\bm{X}\)-Det & \(\bm{X}\)-Cmp w / \(C_{\text{other}}\) & N/A & \(O(|C|C|^{\prime})\) (A.2.1) \\ \cline{2-6}  & & SCmp & \(\bm{X}\)-Det & \(\bm{X}\)-Cmp w / \(C_{\text{other}}\) & \(\bm{X}\)-SCmp w / \(C_{\text{other}}\) & \(O(\max(|C|,|C^{\prime}|))\) (A.2.2) \\ \hline \multirow{2}{*}{**Elem.**} & \multirow{2}{*}{Sm, Dec, (Add/Det), (Mult/Prod01)} & \multirow{2}{*}{\(\bm{X}\)-Det} & \multirow{2}{*}{\(\bm{X}\)-Cmp w / \(C_{\text{other}}\)} & \multirow{2}{*}{\(\bm{X}\)-SCmp w / \(C_{\text{other}}\)} & \multirow{2}{*}{\(O(|C|)\) (A.3)} \\ \cline{3-6}  & & & & & & \\ \hline \end{tabular}
\end{table}
Table 1: Tractability Conditions for Operations on Algebraic Circuits. Sm: Smoothness, Dec: Decomposability; \(\bm{X}\)-Det(erminism), \(\bm{X}\)-Cmp: \(\bm{X}\)-Compatibility, \(\bm{X}\)-SCmp: \(\bm{X}\)-Support-Compatibility.

algorithms for aggregation, product, and elementwise mapping (see Appendix A). An upper bound on the complexity (attained by the algorithm) is also given by considering the complexities of each individual operator; in particular, the algorithm is polytime for a bounded number of operators.

## 4 Case Studies

In this section, we apply our compositional framework to analyze the tractability of several different problems involving circuits found in the literature (Table 2). Some of the results are known, but can now be cast in a general framework (with often simpler proofs). We also present new results, deriving tractability conditions that are less restrictive than reported in existing literature.

**Theorem 6** (Tractability of Compositional Queries).: _The results in Table 2 hold._

### Algebraic Model Counting

In algebraic model counting [30] (a generalization of weighted model counting), one is given a Boolean function \(\phi(\bm{V})\), and a fully-factorized labeling function \(\omega(\bm{V})=\bigotimes_{V_{i}\in\bm{V}}\omega_{i}(V_{i})\) in some semiring \(\mathcal{S}\), and the goal is to aggregate these labels for all satisfying assignments of \(\phi\). This can be easily cast in our framework as \(\bigoplus_{\bm{v}}\big{(}\llbracket(\phi(\bm{v}))\rrbracket_{\mathcal{B} \rightarrow\mathcal{S}}\otimes\omega(\bm{v})\big{)}\). Here, the support mapping \(\llbracket\cdot\rrbracket_{\mathcal{B}\rightarrow\mathcal{S}}\) transfers the Boolean function to the semiring \(\mathcal{S}\) over which aggregation occurs. Assuming that \(\phi(\bm{V})\) is given as a smooth and decomposable Boolean circuit (DNNF), then by Corollary 1 AMC is tractable if \(\mathcal{S}\) is idempotent or if the circuit is additionally deterministic (note that \(\omega(\bm{V})\) is omni-compatible, so the product is tractable); this matches the results of [30].

2AmcA recent generalization of algebraic model counting is the 2AMC (second-level algebraic model counting) problem [29], which encompasses a number of important bilevel inference problems such as marginal MAP and inference in probabilistic answer set programs. Given a partition of the variables \(\bm{V}=(\bm{X},\bm{Y})\), a Boolean function \(\phi(\bm{X},\bm{Y})\), _outer_ and _inner_ semirings \(\mathcal{S}_{\bm{X}},\mathcal{S}_{\bm{Y}}\), labeling functions \(\omega_{\bm{Y}}(\bm{Y})=\bigotimes_{\bm{Y}_{i}\in\bm{Y}}\omega_{\bm{Y},i}(Y_{i})\) over \(\mathcal{S}_{\bm{Y}}\) and \(\omega_{\bm{X}}(\bm{X})=\bigotimes_{\bm{X}_{i}\in\bm{X}}\omega_{\bm{X},i}(X_{i})\) over \(\mathcal{S}_{\bm{X}}\), and an elementwise mapping \(\tau_{\mathcal{S}_{\bm{Y}}\rightarrow\mathcal{S}_{\bm{X}}}:\mathcal{S}_{\bm{Y }}\rightarrow\mathcal{S}_{\bm{X}}\), the 2AMC problem is given by:

\[\bigoplus_{\bm{x}}\!\!\left(\tau_{\mathcal{S}_{\bm{Y}}\rightarrow\mathcal{S}_ {\bm{X}}}\bigg{(}\bigoplus_{\bm{y}}\llbracket\phi(\bm{x},\bm{y})\rrbracket_{ \mathcal{B}\rightarrow\mathcal{S}_{\bm{Y}}}\otimes\omega(\bm{y})\bigg{)} \otimes\omega^{\prime}(\bm{x})\right)\] (1)

To tackle this type of bilevel inference problem, [29] identified a circuit property called \(\bm{X}\)-firstness.

**Definition 9** (\(\bm{X}\)-Firstness).: _Suppose \(C\) is a circuit over variables \(\bm{V}\) and \((\bm{X},\bm{Y})\) a partition of \(\bm{V}\). We say that a node \(\alpha\in C\) is \(\bm{X}\)-only if \(\text{vars}(\alpha)\subseteq\bm{X}\), \(\bm{Y}\)-only if \(\text{vars}(\alpha)\subseteq\bm{Y}\), and \(\text{mixed}\) otherwise. Then we say that \(C\) is \(\bm{X}\)-first if for all product nodes \(\alpha=\alpha_{1}\times\alpha_{2}\), we have that either: (i) each \(\alpha_{i}\) is \(\bm{X}\)-only or \(\bm{Y}\)-only; (ii) or exactly one \(\alpha_{i}\) is mixed, and the other is \(\bm{X}\)-only._

It was stated in [29] that smoothness, decomposability, determinism, and \(\bm{X}\)-firstness suffice to ensure tractable computation of 2AMC problems, by simply evaluating the circuit in the given semirings (caching values if necessary). We now show that this is neither sufficient nor necessary in general. To build intuition, consider the simple NNF circuit \(\phi(X,Y)=(X\wedge Y)\vee(X\wedge\neg Y)\). Note that \(\phi\) trivially satisfies \(X\)-firstness and is smooth, decomposable, and deterministic. Let

\begin{table}
\begin{tabular}{l l l l l} \hline \hline  & **Problem** & **Tractability Conditions** & **Complexity** \\ \hline \multirow{3}{*}{**2AMC**} & PASP (Max-Credal)\({}^{*}\) & Sm, Dec, \(\bm{X}\)-Det & \(O(|C|)\) \\  & PASP (MaxEnt)\({}^{*}\), MMAP & Sm, Dec, Det, \(\bm{X}\)-Det & \(O(|C|)\) \\  & SDP\({}^{*}\) & Sm, Dec, Det, \(\bm{X}\)-Det & \(\bm{X}\)-First & \(O(|C|)\) \\ \hline \multirow{3}{*}{**Causal Inference**} & Backdoor\({}^{*}\) & Sm, Dec, SD, \((\bm{X}\cup\bm{Z})\)-Det & \(O(|C|^{2})\) \\  & Rrontdoor\({}^{*}\) & Sm, Dec, \(\bm{Z}\)-Det, \((\bm{X}\cup\bm{Z})\)-Det & \(O(|C|^{2})\) \\ \hline \multirow{2}{*}{**Other**} & MFE\({}^{*}\) & Sm, Dec, \(\bm{H}\)-Det, \(\bm{I}^{*}\)â€“Det, \((\bm{H}\cup\bm{I}^{*})\)-Det & \(O(|C|)\) \\  & Reverse-MAP & Sm, Dec, \(\bm{X}\)-Det & \(O(|C|)\) \\ \hline \hline \end{tabular}
\end{table}
Table 2: Tractability Conditions and Complexity for Compositional Inference Problems. We denote new results with an asterisk.

be the probability semiring, \(\mathcal{S}^{\prime}\) be the \((\max,\cdot)\)-semiring, labeling functions be \(\omega(y)=\omega(\neg y)=1\), \(\omega^{\prime}(x)=\omega^{\prime}(\neg x)=1\), and the mapping function be the identity \(\tau(a)=a\). Then, noting that the labels are the multiplicative identity \(1\), the 2AMC value is \(\max_{X}\tau(\sum_{Y}[\![\phi(X,Y)]\!]_{\mathcal{B}\to\mathcal{S}})=\max\bigl{(} \tau\bigl{(}[\![\phi(x,y)]\!]_{\mathcal{B}\to\mathcal{S}}+[\![\phi(x,\neg y)]\!] _{\mathcal{B}\to\mathcal{S}}\bigr{)},\tau\bigl{(}[\![\phi(\neg x,y)]\!]_{ \mathcal{B}\to\mathcal{S}}+[\![\phi(\neg x,\neg y)]\!]_{\mathcal{B}\to \mathcal{S}}\bigr{)}=\max\bigl{(}\tau(1+1),\tau(0)\bigr{)}=2\). On the other hand, the algorithm of [29] returns the value 2AMC \(=1\), as shown in Figure 3. This is not just a flaw in the specific evaluation algorithm, but rather a provable intractability of the problem given these properties:

**Theorem 7** (Hardness of 2AMC with \(\bm{X}\)-firstness).: _2AMC is #P-hard, even for circuits that are smooth, decomposable, deterministic, and \(\bm{X}\)-first, and a constant-time elementwise mapping._

Analyzing using our compositional framework, the issue is that the tractability conditions for \(\tau\) do not hold; whilst the Boolean circuit is deterministic, this is not true once \(Y\) is aggregated. In fact, we show that also enforcing \(\bm{X}\)-determinism suffices to tractably compute arbitrary 2AMC instances.

**Theorem 8** (Tractability Conditions for 2AMC).: _Every 2AMC instance is tractable in \(O(|C|)\) time for Boolean circuits that are smooth, decomposable, deterministic, \(\bm{X}\)-first, and \(\bm{X}\)-deterministic._

Proof sketch.: The key point to notice is that the elementwise mapping relative to the transformation of inner to outer semiring operates over an aggregation of an \(\bm{X}\)-first and \(\bm{X}\)-deterministic circuit, obtained by the product of a Boolean function (mapped to the inner semiring by a support mapping) and a weight function of \(\bm{Y}\). Hence, it satisfies (Det) and (Prod 0/1): all of the \(\bm{X}\)-only children of a product node are 0/1 valued (in the inner semiring). 

For specific instances of 2AMC, depending on the semirings \(\mathcal{S},\mathcal{S}^{\prime}\) and mapping function \(\tau\), we also find that it is possible to remove the requirement of \(\bm{X}\)-firstness or (\(\bm{V}\))-determinism, as we summarize in Table 2. One might thus wonder if there is a difference in terms of compactness between requiring \(\bm{X}\)-determinism and \(\bm{X}\)-firstness, as opposed to \(\bm{X}\)-determinism alone. For example, for sentential decision diagrams (SDD) [17], a popular knowledge compilation target, these notions coincide: a SDD is \(\bm{X}\)-deterministic iff it is \(\bm{X}\)-first (in which context this property is known as \(\bm{X}\)-constrainedness [37; 22]). However, as shown in Figure 1(b), there exist \(\bm{X}\)-deterministic but not \(\bm{X}\)-first circuits. We now show that \(\bm{X}\)-deterministic circuits can be exponentially more succinct than \(\bm{X}\)-deterministic circuits that are additionally \(\bm{X}\)-first, as the size of \(\bm{X}\) grows.3

Footnote 3: If the size of \(\bm{X}\) is fixed, a circuit can always be rearranged to be \(\bm{X}\)-first with at most a \(2^{|\bm{X}|}\) blowup.

**Theorem 9** (Exponential Separation).: _Given sets of variables \(\bm{X}=\{X_{1},...,X_{n}\},\bm{Y}=\{Y_{1},...,Y_{n}\}\), there exists a smooth, decomposable and \(\bm{X}\)-deterministic circuit \(C\) of size \(poly(n)\) such that the smallest smooth, decomposable, and \(\bm{X}\)-first circuit \(C^{\prime}\) such that \(p_{C}\equiv p_{C^{\prime}}\) has size \(2^{\mathrm{d}(n)}\)._

Thus, to summarize, some instances of 2AMC can be solved efficiently when \(\phi\) is smooth, decomposable and \(\bm{X}\)-deterministic. A larger number of instances can be solved when additionally, \(\phi\) is deterministic; and all 2AMC problems are tractable if we also impose \(\bm{X}\)-firstness.

### Causal Inference

In causal inference, one is often interested in computing _interventional distributions_, denoted using the \(do(\cdot)\) operator, as a function of the observed distribution \(p\). This function depends on the causal graph linking the variables, and can be derived using the do-calculus [38]. For example, the well-known _backdoor_ and _frontdoor_ graphs induce the following formulae:

\[p(\bm{y}|do(\bm{x}))=\sum_{\bm{z}}p(\bm{z})p(\bm{y}|\bm{x},\bm{z}),\] (2)

Figure 3: Failure case of 2AMC algorithm on smooth, decomposable, X-first circuit.

\[p(\bm{y}|do(\bm{x}))=\sum_{\bm{z}}p(\bm{z}|\bm{x})\sum_{\bm{x}^{\prime}}p(\bm{x} ^{\prime})p(\bm{y}|\bm{x}^{\prime},\bm{z}).\] (3)

Assuming that the observed joint distribution \(p(\bm{X},\bm{Y},\bm{Z})\) is given as a probabilistic circuit \(C\), we consider the problem of obtaining a probabilistic circuit \(C^{\prime}\) over variables \(\bm{X}\cup\bm{Y}\) representing \(p(\bm{Y}|do(\bm{X}))\). Tractability conditions for the backdoor/frontdoor cases were derived by [49], with quadratic/cubic complexity respectively. However, we observe that in some cases we can avoid the requirement of structured decomposability and/or obtain reduced complexity relative to their findings.

In the backdoor case, it is known that structured decomposability and \((\bm{X}\cup\bm{Z})\)-determinism suffices for a quadratic time algorithm. This can be seen by decomposing into a compositional query:

\[\bigoplus_{\bm{z}}\Bigl{(}\Bigl{(}\bigoplus_{\bm{x},\bm{y}}p(\bm{v})\Bigr{)} \otimes p(\bm{v})\otimes\tau_{-1}\Bigl{(}\bigoplus_{\bm{y}}p(\bm{v})\Bigr{)} \Bigr{)}.\] (4)

where \(\bm{V}=(\bm{X},\bm{Y},\bm{Z})\), and \(\tau_{-1}(a)=\begin{cases}a^{-1}&\text{if }a\neq 0\\ 0&\text{if }a=0\end{cases}\). Assuming \((\bm{X}\cup\bm{Z})\)-determinism and structured decomposability, then \(\tau_{-1}\bigl{(}\bigoplus_{\bm{y}}p(\bm{V})\bigr{)}\) is tractable by (Det) and (Multiplicative), the product \(p(\bm{V})\otimes\tau_{-1}\bigl{(}\bigoplus_{\bm{y}}p(\bm{V})\bigr{)}\) by support-compatibility, and the final product by compatibility. However, if we additionally have \(\bm{Z}\)-determinism, then the final product becomes tractable by support compatibility. This has linear rather than quadratic complexity, and does not require the circuit to be structured decomposable. In the frontdoor case, [49] showed that \(\bm{X}\)-determinism, \((\bm{X}\cup\bm{Z})\)-determinism, and structured decomposability suffices for cubic complexity. However, we note that under such conditions, the inner product \(p(\bm{X}^{\prime})\otimes p(\bm{Y}|\bm{X}^{\prime},\bm{Z})\) is tractable by support-compatibility. As such, the complexity of this query is actually quadratic rather than cubic as previously shown. We summarize our findings in Table 2 and refer the reader to the Appendix for full proofs.

## 5 Related Work

Our work builds upon the observation that many inference problems can be characterized as a composition of basic operators. Prior works have considered compositional inference for circuits in the Boolean [18] and probabilistic semirings [48; 49], deriving tractability conditions for operators specific to these semirings. Aside from generalizing to arbitrary semirings, we also introduce extended composability conditions that enable interleaving of aggregation, products, and mappings. Meanwhile, algebraic model counting [30] deals (implicitly) with mappings from the Boolean semiring to an arbitrary semiring, but does not consider compositional queries. Closest to our work, [29] consider a generalization of algebraic model counting that allows for an additional semiring translation; however, this still assumes input Boolean circuits and has incomplete tractability characterizations. Our framework resolves these limitations, permitting arbitrary compositional queries over semirings.

Many works have considered (unbounded) sums-of-products queries on arbitrary semirings [21; 5; 1; 23], encompassing many important problems such as constraint satisfaction problems [7], graphical model inference [56], and database queries [52], which are often computationally hard in the worst-case. Algorithms for such queries often utilize compact intermediate representations and/or assume compact input representations, such as circuits [35; 17; 36; 3]. Our framework focuses on queries where the number of operators is bounded, and characterizes conditions under which inference is tractable in polynomial time. It also includes elementwise mappings as a key additional abstraction that can be used to express queries involving more than sums and products.

## 6 Conclusion

In summary, we have introduced a framework for analysing compositional inference problems on circuits, based on algebraic structure. In doing so, we were able to derive new tractability conditions and simplified algorithms for a number of existing problems, including 2AMC and causal inference. Our framework focuses on simple and composable _sufficient_ tractability conditions for aggregations, products and elementwise mappings operators; a limitation of this generality is these conditions may not be necessary for specific queries on specific semirings. Our work motivates the development of knowledge compilation and learning algorithms that target the requisite circuit properties, such as \(\bm{X}\)-determinism. Finally, while we focus on exact inference, for many problems (e.g. marginal MAP) approximate algorithms exist and are of significant interest; an interesting direction for future work is to investigate if these can be also be generalized using the compositional approach.

## Acknowledgements

We thank Antonio Vergari for helpful discussions, and acknowledge him for proposing an early version of support compatibility and Theorem 3, and for pointing out a potential reduction in complexity for the causal inference queries. This work was done in part while the authors were visiting the Simons Institute for the Theory of Computing. This work was funded in part by the DARPA ANSR program under award FA8750-23-2-0004, the DARPA PTG Program under award HR00112220005, and NSF grant #IIS-1943641. DM received generous support from the IBM Corporation, the Center for Artificial Intelligence at University of Sao Paulo (C4AI-USP), the Sao Paulo Research Foundation (FAPESP grants #2019/07665-4 and 2022/02937-9), the Brazilian National Research Council (CNPq grant no. 305136/2022-4) and CAPES (Finance Code 001). YC was partially supported by a gift from Cisco University Research Program.

## References

* Khamis et al. [2016] Mahmoud Abo Khamis, Hung Q Ngo, and Atri Rudra. Faq: questions asked frequently. In _Proceedings of the 35th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems_, pages 13-28, 2016.
* Ahmed et al. [2022] Kareem Ahmed, Stefano Teso, Kai-Wei Chang, Guy Van den Broeck, and Antonio Vergari. Semantic probabilistic layers for neuro-symbolic learning. In _Advances in Neural Information Processing Systems 35 (NeurIPS)_, dec 2022.
* Amarilli and Capelli [2024] Antoine Amarilli and Florent Capelli. Tractable circuits in database theory. _ACM SIGMOD Record_, 53(2):6-20, 2024.
* Amarilli et al. [2024] Antoine Amarilli, Marcelo Arenas, YooJung Choi, Mikael Monet, Guy Van den Broeck, and Benjie Wang. A circus of circuits: Connections between decision diagrams, circuits, and automata. _arXiv preprint arXiv:2404.09674_, 2024.
* Bacchus et al. [2009] Fahiem Bacchus, Shannon Dalmao, and Toniann Pitassi. Solving# sat and bayesian inference with backtracking search. _Journal of Artificial Intelligence Research_, 34:391-442, 2009.
* Baral et al. [2009] Chitta Baral, Michael Gelfond, and J. Nelson Rushton. Probabilistic reasoning with answer sets. _Theory and Practice of Logic Programming_, 9(1):57-144, 2009.
* Bistarelli et al. [1997] Stefano Bistarelli, Ugo Montanari, and Francesca Rossi. Semiring-based constraint satisfaction and optimization. _Journal of the ACM (JACM)_, 44(2):201-236, 1997.
* Broadrick et al. [2024] Oliver Broadrick, Honghua Zhang, and Guy Van den Broeck. Polynomial semantics of tractable probabilistic circuits. In _Proceedings of the 40th Conference on Uncertainty in Artificial Intelligence (UAI)_, july 2024.
* Chavira and Darwiche [2008] Mark Chavira and Adnan Darwiche. On probabilistic inference by weighted model counting. _Artificial Intelligence_, 172(6):772-799, 2008.
* Choi et al. [2012] Arthur Choi, Yexiang Xue, and Adnan Darwiche. Same-decision probability: A confidence measure for threshold-based decisions. _International Journal of Approximate Reasoning_, 53(9):1415-1428, 2012. ISSN 0888-613X. doi: https://doi.org/10.1016/j.ijar.2012.04.005. URL https://www.sciencedirect.com/science/article/pii/S0888613X12000485. Fifth European Workshop on Probabilistic Graphical Models (PGM-2010).
* Choi et al. [2020] YooJung Choi, Antonio Vergari, and Guy Van den Broeck. Probabilistic circuits: A unifying framework for tractable probabilistic models. arXiv preprint, 2020.
* Choi et al. [2021] YooJung Choi, Meihua Dang, and Guy Van den Broeck. Group fairness by probabilistic modeling with latent fair decisions. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 35, pages 12051-12059, 2021.
* Choi et al. [2022] YooJung Choi, Tal Friedman, and Guy Van den Broeck. Solving marginal map exactly by probabilistic circuit transformations. In _Proceedings of the 25th International Conference on Artificial Intelligence and Statistics (AISTATS)_, 2022.

* [14] Fabio Gagliardi Cozman and Denis Deratani Maua. On the semantics and complexity of probabilistic logic programs. _Journal of Artificial Intelligence Research_, 60:221-262, 2017.
* [15] Adnan Darwiche. On the tractable counting of theory models and its application to truth maintenance and belief revision. _Journal of Applied Non-Classical Logics_, 11(1-2):11-34, 2001. doi: 10.3166/jancl.11.11-34.
* [16] Adnan Darwiche. A differential approach to inference in bayesian networks. _Journal of the ACM (JACM)_, 50(3):280-305, 2003.
* [17] Adnan Darwiche. Sdd: A new canonical representation of propositional knowledge bases. In _Twenty-Second International Joint Conference on Artificial Intelligence_, 2011.
* [18] Adnan Darwiche and Pierre Marquis. A knowledge compilation map. _Journal of Artificial Intelligence Research_, 17:229-264, 2002.
* [19] Cassio P De Campos. New complexity results for map in bayesian networks. In _IJCAI_, volume 11, pages 2100-2106. Citeseer, 2011.
* [20] Luc De Raedt, Angelika Kimmig, and Hannu Toivonen. Problog: A probabilistic prolog and its application in link discovery. In _Proceedings of the International Joint Conference in Artificial Intelligence (IJCAI)_, volume 7, pages 2462-2467, 2007.
* [21] Rina Dechter. Bucket elimination: A unifying framework for reasoning. _Artificial Intelligence_, 113(1-2):41-85, 1999.
* [22] Vincent Derkinderen and Luc De Raedt. Algebraic circuits for decision theoretic inference and learning. In _ECAI 2020_, pages 2569-2576. IOS Press, 2020.
* [23] Thomas Eiter and Rafael Kiesel. On the complexity of sum-of-products problems over semirings. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 35, pages 6304-6311, 2021.
* [24] Daan Fierens, Guy Van den Broeck, Joris Renkens, Dimitar Shterionov, Bernd Gutmann, Ingo Thon, Gerda Janssens, and Luc De Raedt. Inference and learning in probabilistic logic programs using weighted boolean formulas. _Theory and Practice of Logic Programming_, 15(3):358-401, 2015.
* [25] Robert Gens and Domingos Pedro. Learning the structure of sum-product networks. In _International conference on machine learning_, pages 873-880. PMLR, 2013.
* [26] Steven Holtzen, Guy Van den Broeck, and Todd Millstein. Scaling exact inference for discrete probabilistic programs. _Proceedings of the ACM on Programming Languages_, 4(OOPSLA):1-31, 2020.
* [27] Haiying Huang and Adnan Darwiche. Causal unit selection using tractable arithmetic circuits. _arXiv preprint arXiv:2404.06681_, 2024.
* [28] Jiani Huang, Ziyang Li, Binghong Chen, Karan Samel, Mayur Naik, Le Song, and Xujie Si. Scallop: From probabilistic deductive databases to scalable differentiable reasoning. _Advances in Neural Information Processing Systems_, 34:25134-25145, 2021.
* [29] Rafael Kiesel, Pietro Totis, and Angelika Kimmig. Efficient knowledge compilation beyond weighted model counting. In _Proceedings of the 38th International Conference on Logic Programming (ICLP 2022)_, 2022.
* [30] Angelika Kimmig, Guy Van den Broeck, and Luc De Raedt. Algebraic model counting. _Journal of Applied Logic_, 22:42-62, 2017.
* [31] Johan Kwisthout. Most frugal explanations in bayesian networks. _Artificial Intelligence_, 218:56-73, 2015. ISSN 0004-3702. doi: https://doi.org/10.1016/j.artint.2014.10.001.
* [32] Anji Liu, Honghua Zhang, and Guy Van den Broeck. Scaling up probabilistic circuits by latent variable distillation. In _Proceedings of the International Conference on Learning Representations (ICLR)_, may 2023.

* [33] T. Lukasiewicz. Probabilistic description logic programs. _International Journal of Approximate Reasoning_, 45(2):288-307, 2007.
* [34] Robin Manhaeve, Sebastijan Dumancic, Angelika Kimmig, Thomas Demeester, and Luc De Raedt. Deepproblog: Neural probabilistic logic programming. _Advances in neural information processing systems_, 31, 2018.
* [35] Robert Mateescu, Rina Dechter, and Radu Marinescu. And/or multi-valued decision diagrams (aomdds) for graphical models. _Journal of Artificial Intelligence Research_, 33:465-519, 2008.
* [36] Dan Olteanu and Maximilian Schleich. Factorized databases. _ACM SIGMOD Record_, 45(2):5-16, 2016.
* [37] Umut Oztok, Arthur Choi, and Adnan Darwiche. Solving pp pp-complete problems using knowledge compilation. In _Fifteenth International Conference on the Principles of Knowledge Representation and Reasoning_, 2016.
* [38] Judea Pearl. Causal diagrams for empirical research. _Biometrika_, 82(4):669-688, 1995.
* [39] Robert Peharz, Robert Gens, Franz Pernkopf, and Pedro Domingos. On the latent variable interpretation in sum-product networks. _IEEE transactions on pattern analysis and machine intelligence_, 39(10):2030-2044, 2016.
* [40] Robert Peharz, Antonio Vergari, Karl Stelzner, Alejandro Molina, Xiaoting Shao, Martin Trapp, Kristian Kersting, and Zoubin Ghahramani. Random sum-product networks: A simple and effective approach to probabilistic deep learning. In _Uncertainty in Artificial Intelligence_, pages 334-344. PMLR, 2020.
* [41] Tahrima Rahman, Prasanna Kothalkar, and Vibhav Gogate. Cutset networks: A simple, tractable, and scalable approach for improving the accuracy of chow-liu trees. In _Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2014, Nancy, France, September 15-19, 2014. Proceedings, Part II 14_, pages 630-645. Springer, 2014.
* [42] Amirmohammad Rooshenas and Daniel Lowd. Learning sum-product networks with direct and indirect variable interactions. In _International Conference on Machine Learning_, pages 710-718. PMLR, 2014.
* [43] Feras A Saad, Martin C Rinard, and Vikash K Mansinghka. Sppl: probabilistic programming with fast exact symbolic inference. In _Proceedings of the 42nd acm sigplan international conference on programming language design and implementation_, pages 804-819, 2021.
* [44] Amir Shpilka, Amir Yehudayoff, et al. Arithmetic circuits: A survey of recent results and open questions. _Foundations and Trends(r) in Theoretical Computer Science_, 5(3-4):207-388, 2010.
* [45] Pietro Totis, Luc De Raedt, and Angelika Kimmig. smProbLog: Stable model semantics in problog for probabilistic argumentation. _Theory And Practice Of Logic Programming_, 23(6):1198-1247, 2023.
* [46] Leslie G Valiant. The complexity of enumeration and reliability problems. _SIAM Journal on Computing_, 8(3):410-421, 1979.
* [47] Guy Van den Broeck, Anton Lykov, Maximilian Schleich, and Dan Suciu. On the tractability of shap explanations. In _Proceedings of the 35th AAAI International Conference on Artificial Intelligence and Statistics (AAAI 2021)_, 2021.
* [48] Antonio Vergari, YooJung Choi, Anji Liu, Stefano Teso, and Guy den Broeck. A Compositional Atlas of Tractable Circuit Operations for Probabilistic Inference. In _Advances in Neural Information Processing Systems_, volume 34, pages 13189-13201, 2021.
* [49] Benjie Wang and Marta Kwiatkowska. Compositional probabilistic and causal inference using tractable circuit models. In _Proceedings of the 26th International Conference on Artificial Intelligence and Statistics (AISTATS)_, pages 9488-9498. PMLR, 2023.
* [50] Benjie Wang, Matthew R Wicker, and Marta Kwiatkowska. Tractable uncertainty for structure learning. In _International Conference on Machine Learning_, pages 23131-23150. PMLR, 2022.

* [51] Zhun Yang, Adam Ishay, and Joohyung Lee. NeurASP: Embracing neural networks into answer set programming. In _Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence (IJCAI)_, pages 1755-1762, 2020.
* [52] Mihalis Yannakakis. Algorithms for acyclic database schemes. In _VLDB_, volume 81, pages 82-94, 1981.
* [53] Matej Zecevic, Devendra Dhami, Athresh Karanam, Sriraam Natarajan, and Kristian Kersting. Interventional sum-product networks: Causal inference with tractable probabilistic models. _Advances in neural information processing systems_, 34:15019-15031, 2021.
* [54] Honghua Zhang, Meihua Dang, Nanyun Peng, and Guy Van den Broeck. Tractable control for autoregressive language generation. In _Proceedings of the 40th International Conference on Machine Learning (ICML)_, jul 2023.
* [55] Honghua Zhang, Benjie Wang, Marcelo Arenas, and Guy Van den Broeck. Restructuring tractable probabilistic circuits. _arXiv preprint arXiv:2411.12256_, 2024.
* [56] Nevin L Zhang and David Poole. A simple approach to bayesian network computations. In _Proc. of the Tenth Canadian Conference on Artificial Intelligence_, 1994.

``` Input: Smooth and decomposable algebraic circuit \(C(\bm{V})\); node \(\alpha\in C\); Subset of variables \(\bm{W}\subseteq\text{vars}(\alpha)\) Output: Node encoding \(\bigoplus_{\bm{W}}p_{\alpha}(\bm{V})\)
1if\(\alpha\) is input node then
2returnAGG-INPUT\((\alpha;\bm{W})\)
3elseif\(\alpha\) is product or sum node and \(\text{vars}(\alpha)=\bm{W}\)then
4returnNEWNODE\((\otimes_{i=1}^{k}p_{\texttt{AGG}(\alpha_{i};\bm{W}\cap\text{vars}(\alpha_{i}))})\) if\(\alpha\) is product elseNEWNODE\((\oplus_{i=1}^{k}p_{\texttt{AGG}(\alpha_{i};\bm{W})})\)
5elseif\(\alpha\) is product or sum node and \(\bm{W}\subset\text{vars}(\alpha)\)then
6return\(\times_{i=1}^{k}\texttt{AGG}(\alpha_{i};\bm{W}\cap\text{vars}(\alpha_{i}))\) if\(\alpha\) is product else\(+_{i=1}^{k}\texttt{AGG}(\alpha_{i};\bm{W})\) ```

**Algorithm 1**AGG

``` Input: Compatible algebraic circuits \(C(\bm{V}),C^{\prime}(\bm{V}^{\prime})\); nodes \(\alpha\in C,\alpha^{\prime}\in C^{\prime}\) s.t. \(\text{vars}(\alpha)\cap(\bm{V}\cap\bm{V}^{\prime})=\text{vars}(\alpha^{\prime}) \cap(\bm{V}\cap\bm{V}^{\prime})\) Output: Node encoding \(p_{C}(\bm{V})\otimes p_{C^{\prime}}(\bm{V}^{\prime})\)
1if\(\text{vars}(\alpha)\cap\text{vars}(\alpha^{\prime})=\emptyset\)then
2return\(\alpha\times\alpha^{\prime}\)
3elseif\(\alpha\) is a product or input node and \(\alpha^{\prime}=+_{j=1}^{k^{\prime}}\) is a sum node then
4return\(+_{j=1}^{k^{\prime}}\texttt{PROD-CMP}(\alpha,\alpha^{\prime}_{j})\)
5elseif\(\alpha,\alpha^{\prime}\) are input nodes then
6returnPROD-INPUT\((\alpha,\alpha^{\prime})\)
7elseif\(\alpha=\alpha_{1}\times\alpha_{2},\alpha^{\prime}=\alpha^{\prime}_{1}\times \alpha^{\prime}_{2}\) are product nodes then
8returnPROD-CMP\((\alpha_{1},\alpha^{\prime}_{1})\times\texttt{PROD-CMP}(\alpha_{2},\alpha^{ \prime}_{2})\)
9elseif\(\alpha=+_{i=1}^{k}\alpha_{i},\alpha^{\prime}=+_{j=1}^{k^{\prime}}\alpha^{ \prime}_{j}\) are sum nodes then
10return\(+_{i=1}^{k}+_{j=1}^{k^{\prime}}\texttt{PROD-CMP}(\alpha_{i},\alpha^{\prime}_{j})\) ```

**Algorithm 2**PROD-CMP

## Appendix A Algorithms and Proofs

In Algorithms 1-4 we present algorithms for the aggregation, product (with compatibility), product (with support-compatiblity), and elementwise mapping operators respectively (the initial call is to the root of the circuit(s)). In the following, we present proofs that the algorithms soundly compute smooth and decomposable output circuits for the respective operators.

### Tractable Aggregation

**Theorem 1** (Tractable Aggregation).: _Let \(C\) be a smooth and decomposable circuit representing a function \(p:\text{Assign}(\bm{V})\to S\). Then for any \(\bm{W}\subseteq\bm{V}\), it is possible to compute the aggregate as a smooth and decomposable circuit \(C^{\prime}\) (i.e., \(p_{C^{\prime}}(\bm{Z})=\bigoplus_{\bm{w}}p_{C}(\bm{Z},\bm{w})\)) in \(O(|C|)\) time and space._

Proof.: We prove this inductively, starting from the input nodes of the circuit. Our claim is that for each node \(\alpha\in C\), \(\texttt{AGG}(\alpha;\bm{W})\) (Algorithm 1) returns a node \(\alpha^{\prime}\) with scope \(\text{vars}(\alpha^{\prime})=\text{vars}(\alpha)\setminus\bm{W}\) such that \(p_{\alpha^{\prime}}(\text{vars}(\alpha^{\prime}))=\bigoplus_{\bm{w}}p_{\alpha} (\text{vars}(\alpha))\), and is decomposable (if product) and smooth (if sum).

If \(\alpha\) is an input node (Lines 1-2), then this is possible by assumption; we denote this with \(\texttt{AGG-INPUT}\) in the algorithm. Note that if \(\text{vars}(\alpha)=\bm{W}\), then this is just a scalar/constant (i.e. input node with empty scope).

``` Input: Support-compatible algebraic circuits \(C(\bm{V}),C^{\prime}(\bm{V}^{\prime})\); nodes \(\alpha\in C,\alpha^{\prime}\in C^{\prime}\) s.t. \(\iota(\alpha)=\alpha^{\prime}\) Output: Circuit encoding \(p_{C}(\bm{V})\otimes p_{C^{\prime}}(\bm{V}^{\prime})\)
1if\(\operatorname{vars}(\alpha)\cap\operatorname{vars}(\alpha^{\prime})=\emptyset\)then
2return\(\alpha\times\alpha^{\prime}\)
3elseif\(\alpha,\alpha^{\prime}\) are input nodes then
4returnPROD-INPUT(\(\alpha,\alpha^{\prime}\))
5elseif\(\alpha=\alpha_{1}\times\alpha_{2},\alpha^{\prime}=\alpha_{1}^{\prime}\times \alpha_{2}^{\prime}\) are product nodes then
6returnPROD-SCMP(\(\alpha_{1},\alpha_{1}^{\prime}\))\(\times\)PROD-SCMP(\(\alpha_{2},\alpha_{2}^{\prime}\))
7elseif\(\alpha=+_{i=1}^{k}\alpha_{i},\alpha^{\prime}=+_{i=1}^{k}\alpha_{i}^{\prime}\) are sum nodes then
8return\(+_{i=1}^{k}\texttt{PROD-SCMP}(\alpha_{i},\alpha_{i}^{\prime})\) ```

**Algorithm 4**MAPPING

``` Input: Smooth and decomposable algebraic circuit \(C(\bm{V})\) over semiring \(\mathcal{S}\); Node \(\alpha\in C\); Mapping function \(\tau:\mathcal{S}\rightarrow\mathcal{S}^{\prime}\) Output: Node encoding \(\tau(p_{C}(\bm{V}))\)
1if\(\alpha\) is input node then
2returnMAPPING-INPUT(\(\alpha;\tau\))
3elseif\(\alpha\) is product or sum node then
4return\(\otimes_{i=1}^{k}\texttt{MAPPING}(\alpha_{i};\tau)\) if\(\alpha\) is product else\(\oplus_{i=1}^{k}\texttt{MAPPING}(\alpha_{i};\tau)\) ```

**Algorithm 5**MAPPING

If \(\alpha\) is a product node \(\alpha_{1}\times\alpha_{2}\), then by decomposability, \(\bm{W}\cap\operatorname{vars}(\alpha_{1})\) and \(\bm{W}\cap\operatorname{vars}(\alpha_{2})\) partition \(\bm{W}\). Thus we have that:

\[\bigoplus_{\bm{w}}p_{\alpha}(\operatorname{vars}(\alpha)) =\bigoplus_{\bm{w}}\bigl{(}p_{\alpha_{1}}(\operatorname{vars}( \alpha_{1}))\otimes p_{\alpha_{2}}(\operatorname{vars}(\alpha_{2}))\bigr{)}\] \[=\bigoplus_{\bm{w}\cap\operatorname{vars}(\alpha_{1})}\bigoplus_{ \bm{w}\cap\operatorname{vars}(\alpha_{2})}\bigl{(}p_{\alpha_{1}}( \operatorname{vars}(\alpha_{1}))\otimes p_{\alpha_{2}}(\operatorname{vars}( \alpha_{2}))\bigr{)}\] \[=\left(\bigoplus_{\bm{w}\cap\operatorname{vars}(\alpha_{1})}p_{ \alpha_{1}}(\operatorname{vars}(\alpha_{1}))\right)\otimes\left(\bigoplus_{ \bm{w}\cap\operatorname{vars}(\alpha_{2})}p_{\alpha_{2}}(\operatorname{vars}( \alpha_{2}))\right)\] \[=p_{\texttt{AGG}(\alpha_{1};\bm{W}\cap\operatorname{vars}(\alpha_ {1}))}(\operatorname{vars}(\alpha_{1})\setminus\bm{W})\otimes p_{\texttt{AGG}( \alpha_{2};\bm{W}\cap\operatorname{vars}(\alpha_{2}))}(\operatorname{vars}( \alpha_{2})\setminus\bm{W})\]

The second equality follows by the partition (and associativity of the addition and multiplication), while the third follows by distributivity of multiplication over addition. In the case where \(\operatorname{vars}(\alpha)=\bm{W}\) (Lines 3-4), then \(p_{\texttt{AGG}(\alpha_{i};\bm{W}\cap\operatorname{vars}(\alpha_{i}))}( \operatorname{vars}(\alpha_{i}))\) is just a scalar for each \(i\), so we can directly perform this computation, returning a new scalar node \(\alpha^{\prime}\). Otherwise (Lines 5-6), we construct a new product node \(\alpha^{\prime}=\alpha_{1}^{\prime}\times\alpha_{2}^{\prime}=\texttt{AGG}( \alpha_{1};\bm{W}\cap\operatorname{vars}(\alpha_{1}))\times\texttt{AGG}( \alpha_{2};\bm{W}\cap\operatorname{vars}(\alpha_{2}))\). By the inductive hypothesis, \(\alpha_{i}^{\prime}\) has scope \(\operatorname{vars}(\alpha_{i}^{\prime})=\operatorname{vars}(\alpha_{i}) \setminus\bm{W}\), so \(\alpha^{\prime}\) is clearly decomposable and has scope \(\operatorname{vars}(\alpha^{\prime})=(\operatorname{vars}(\alpha_{1})\setminus \bm{W})\cup(\operatorname{vars}(\alpha_{2})\setminus\bm{W})=\operatorname{vars}( \alpha)\setminus\bm{W}\).

If \(\alpha=\iota_{i=1}^{k}\alpha_{i}\) is a sum node, then we note that by smoothness, \(\text{vars}(\alpha_{i})=\text{vars}(\alpha)\) for all \(i\). Thus we have that:

\[\bigoplus_{\bm{w}}p_{\alpha}(\text{vars}(\alpha)) =\bigoplus_{\bm{w}}\bigoplus_{i=1}^{k}p_{\alpha_{i}}(\text{vars}( \alpha))\] \[=\bigoplus_{i=1}^{k}\bigoplus_{\bm{w}}p_{\alpha_{i}}(\text{vars}( \alpha))\] \[=\bigoplus_{i=1}^{k}\bigoplus_{\bm{w}}p_{\alpha_{i}}(\text{vars}( \alpha_{i}))\] \[=\bigoplus_{i=1}^{k}p_{\mathtt{A0G}(\alpha_{i};\bm{W})}(\text{vars} (\alpha_{i}))\]

In the case where \(\text{vars}(\alpha)=\bm{W}\) (Lines 3-4), then \(p_{\mathtt{A0G}(\alpha_{i};\bm{W})}(\text{vars}(\alpha_{i}))\) is just a scalar, so we can directly perform this computation, returning a new scalar node \(\alpha^{\prime}\). Otherwise (Lines 5-6), we construct a new sum node \(\alpha^{\prime}=\iota_{i=1}^{k}\alpha_{i}^{\prime}=\iota_{i=1}^{k}\mathtt{ AGG}(\alpha_{i};\bm{W})\). By the inductive hypothesis, each \(\alpha_{i}^{\prime}\) has scope \(\text{vars}(\alpha_{i})\setminus\bm{W}=\text{vars}(\alpha)\setminus\bm{W}\), so \(\alpha^{\prime}\) is smooth and also has scope \(\text{vars}(\alpha)\setminus\bm{W}\). 

### Tractable Product

#### a.2.1 Tractable Product with Compatibility

**Theorem 2** (Tractable Product - Compatibility).: _Let \(C,C^{\prime}\) be compatible circuits over variables \(\bm{V}\), \(\bm{V}^{\prime}\), respectively, and the same semiring. Then it is possible to compute their product as a circuit \(C\) compatible with them (i.e., \(p_{C^{\prime\prime}}(\bm{V}\cup\bm{V}^{\prime})=p_{C}(\bm{V})\otimes p_{C^{ \prime}}(\bm{V}^{\prime})\)) in \(O(|C||C^{\prime}|)\) time and space._

Proof.: We prove this inductively bottom up, for nodes \(\alpha\in C,\alpha^{\prime}\in C\) such that \(\text{vars}(\alpha)\cap(\bm{V}\cap\bm{V}^{\prime})=\text{vars}(\alpha^{\prime })\cap(\bm{V}\cap\bm{V}^{\prime})\). Our claim is that \(\mathtt{PROD-SCMP}(\alpha,\alpha^{\prime})\) (Algorithm 2) returns a node \(\alpha^{\prime\prime}\) such that \(p_{\alpha^{\prime\prime}}=p_{\alpha}\otimes p_{\alpha^{\prime}}\), has scope \(\text{vars}(\alpha^{\prime\prime})=\text{vars}(\alpha)\cup\text{vars}(\alpha^ {\prime})\), and is decomposable (if product) and smooth (if sum).

If \(\text{vars}(\alpha)\cap\text{vars}(\alpha^{\prime})=\emptyset\) (i.e. \(\text{vars}(\alpha)\cap(\bm{V}\cap\bm{V}^{\prime})=\text{vars}(\alpha^{ \prime})\cap(\bm{V}\cap\bm{V}^{\prime})\) is empty), then the algorithm (Lines 1-2) simply constructs a new product node \(\alpha^{\prime\prime}=\alpha\times\alpha^{\prime}\). By definition, \(p_{\alpha^{\prime\prime}}=p_{\alpha}\otimes p_{\alpha^{\prime}}\), has scope \(\text{vars}(\alpha^{\prime\prime})=\text{vars}(\alpha)\cup\text{vars}(\alpha^ {\prime})\), and \(\alpha^{\prime\prime}\) is decomposable.

If \(\alpha,\alpha^{\prime}\) are input nodes, then we can construct a new input node \(\alpha^{\prime\prime}\) satisfying the requisite properties (Lines 5-6).

If \(\alpha\) is an input or product node and \(\alpha^{\prime}=\iota_{j=1}^{k^{\prime}}\alpha_{j}^{\prime}\) is a sum node, then the algorithm constructs a new sum node \(\alpha^{\prime\prime}=\iota_{j=1}^{k^{\prime}}\mathtt{PROD-CMP}(\alpha,\alpha_ {j}^{\prime})\). This computes the correct function as \(p_{\alpha^{\prime\prime}}=\oplus_{j=1}^{k^{\prime}}\left(p_{\alpha}\otimes p_{ \alpha_{j}^{\prime}}\right)=p_{\alpha}\otimes\left(\oplus_{j=1}^{k^{\prime}}p_{ \alpha_{j}^{\prime}}\right)=p_{\alpha}\otimes p_{\alpha^{\prime}}\). Each child has scope \(\text{vars}(\alpha)\cup\text{vars}(\alpha_{j}^{\prime})=\text{vars}(\alpha) \cup\text{vars}(\alpha^{\prime})\), so smoothness is retained.

If \(\alpha=\alpha_{1}\times\alpha_{2},\alpha^{\prime}=\alpha_{1}^{\prime}\times \alpha_{2}^{\prime}\) are product nodes such that \(\text{vars}(\alpha)\cap(\bm{V}\cap\bm{V}^{\prime})=\text{vars}(\alpha^{ \prime})\cap(\bm{V}\cap\bm{V}^{\prime})\) is non-empty, then writing \(\bm{X}:=\bm{V}\cap\bm{V}^{\prime}\), by compatibility we also have \(\text{vars}(\alpha_{1})\cap\bm{X}=\text{vars}(\alpha_{1}^{\prime})\cap\bm{X}\) and \(\text{vars}(\alpha_{2})\cap\bm{X}=\text{vars}(\alpha_{2}^{\prime})\cap\bm{X}\), so we can apply the inductive hypothesis for \(\mathtt{PROD-CMP}(\alpha_{1},\alpha_{1}^{\prime})\) and \(\mathtt{PROD-CMP}(\alpha_{2},\alpha_{2}^{\prime})\). Algorithm 2 constructs a new product node \(\alpha^{\prime\prime}=\mathtt{PROD-CMP}(\alpha_{1},\alpha_{1}^{\prime})\times \mathtt{PROD-CMP}(\alpha_{2},\alpha_{2}^{\prime})\). To show that this is decomposable, we need the following lemma:

**Lemma 1** (Decomposability of Product).: _Suppose \(\alpha\in C,\alpha^{\prime}\in C^{\prime}\) are decomposable product nodes which decompose in the same way over \(\bm{X}\), i.e. \(\text{vars}(\alpha_{1})\cap\bm{X}=\text{vars}(\alpha_{1}^{\prime})\cap\bm{X}\) and \(\text{vars}(\alpha_{2})\cap\bm{X}=\text{vars}(\alpha_{2}^{\prime})\cap\bm{X}\). Then \((\text{vars}(\alpha_{1})\cup\text{vars}(\alpha_{1}^{\prime}))\cap(\text{vars}( \alpha_{2})\cup\text{vars}(\alpha_{2}^{\prime}))=\emptyset\)._

Proof.: We have that:

\[(\text{vars}(\alpha_{1})\cup\text{vars}(\alpha_{1}^{\prime}))\cap( \text{vars}(\alpha_{2})\cup\text{vars}(\alpha_{2}^{\prime}))\] \[=(\text{vars}(\alpha_{1})\cap\text{vars}(\alpha_{2}))\cup(\text{vars}( \alpha_{1}^{\prime})\cap\text{vars}(\alpha_{2}^{\prime}))\cup(\text{vars}(\alpha_ {1})\cap\text{vars}(\alpha_{2}^{\prime}))\cup(\text{vars}(\alpha_{1})\cap \text{vars}(\alpha_{2}^{\prime}))\cup(\text{vars}(\alpha_{2})\cap\text{vars}( \alpha_{1}^{\prime}))\]Note that the first two intersections are empty due to decomposability of \(\alpha,\alpha^{\prime}\). For the third intersection \((\text{vars}(\alpha_{1})\cap\text{vars}(\alpha^{\prime}_{2}))\), any variable in this intersection must be in the common variables \(\bm{X}\). But we know that \(\text{vars}(\alpha^{\prime}_{2})\cap\bm{X}=\text{vars}(\alpha_{2})\cap\bm{X}\) in both cases above; by decomposability, \((\text{vars}(\alpha^{\prime}_{2})\cap\bm{X})\cap(\text{vars}(\alpha_{1})\cap \bm{X})=\emptyset\). Thus the third intersection is also empty; a similar argument applies for the fourth. 

Applying this Lemma, we see that \(\alpha^{\prime\prime}\) is decomposable as \(\text{vars}(\texttt{PROD-CMP}(\alpha_{1},\alpha^{\prime}_{1}))=(\text{vars}( \alpha_{1})\cup\text{vars}(\alpha^{\prime}_{1}))\) and \(\text{vars}(\texttt{PROD-CMP}(\alpha_{2},\alpha^{\prime}_{2}))=(\text{vars}( \alpha_{2})\cup\text{vars}(\alpha^{\prime}_{2}))\). We can also verify that \(p_{\alpha^{\prime\prime}}=p_{\texttt{PROD-CMP}(\alpha_{1},\alpha^{\prime}_{1} )}\otimes p_{\texttt{PROD-CMP}(\alpha_{2},\alpha^{\prime}_{2})}=p_{\alpha_{1} }\otimes p_{\alpha^{\prime}_{1}}\otimes p_{\alpha_{2}}\otimes p_{\alpha^{ \prime}_{2}}=p_{\alpha}\otimes p_{\alpha^{\prime}}\) by the inductive hypothesis, and associtivity of \(\otimes\).

If \(\alpha=+^{k}_{i=1}\alpha_{i}\), \(\alpha^{\prime}=+^{k^{\prime}}_{i=1}\alpha^{\prime}_{i}\) are sum nodes, then the algorithm produces a new sum node \(\alpha^{\prime\prime}=+^{k}_{i=1}\ast^{k^{\prime}}_{j=1}\texttt{PROD-CMP}( \alpha_{i},\alpha^{\prime}_{j})\) (Lines 7-8). This computes the correct function as \(p_{\alpha^{\prime\prime}}=\oplus^{k}_{i=1}\oplus^{k^{\prime}}_{j=1}\texttt{ PROD-CMP}(\alpha_{i},\alpha^{\prime}_{j})=\oplus^{k}_{i=1}\oplus^{k^{\prime}}_{j=1}p_{ \alpha_{i}}p_{\alpha^{\prime}_{j}}=(\oplus^{k}_{i=1}p_{\alpha_{i}})\otimes( \oplus^{k^{\prime}}_{j=1}p_{\alpha^{\prime}_{j}})=p_{\alpha}\otimes p_{\alpha^ {\prime}}\). It also retains smoothness.

The complexity of this algorithm is \(O(|C||C^{\prime}|)\) because we perform recursive calls for pairs of nodes in \(C\) and \(C^{\prime}\). 

#### a.2.2 Linear-time Product with Support Compatibility

**Theorem 3** (Tractable Product - Support Compatibility).: _Let \(C,C^{\prime}\) be support-compatible circuits over variables \(\bm{V},\bm{V}^{\prime}\), respectively, and the same semiring. Then, given the isomorphism \(\iota\), it is possible to compute their product as a smooth and decomposable circuit \(C^{\prime\prime}\) support-compatible with them (i.e., \(p_{C^{\prime\prime}}(\bm{V}\cup\bm{V}^{\prime})=p_{C}(\bm{V})\otimes p_{C^{ \prime}}(\bm{V}^{\prime})\)) in \(O(\max(|C|,|C^{\prime}|))\) time and space._

Proof.: We prove this inductively bottom up, for nodes \(\alpha\in C\) such that \(\alpha^{\prime}\in C\) either satisfies \(\alpha^{\prime}=\iota(\alpha)\) or \(\text{vars}(\alpha)\cap\text{vars}(\alpha^{\prime})=\emptyset\). Our claim is that \(\texttt{PROD-SCMP}(\alpha,\alpha^{\prime})\) (Algorithm 3) returns a node \(\alpha^{\prime\prime}\) such that \(p_{\alpha^{\prime\prime}}=p_{\alpha}\otimes p_{\alpha^{\prime}}\), has scope \(\text{vars}(\alpha^{\prime\prime})=\text{vars}(\alpha)\cup\text{vars}(\alpha^ {\prime})\), and is decomposable (if product) and smooth (if sum).

If \(\text{vars}(\alpha)\cap\text{vars}(\alpha^{\prime})=\emptyset\), then the algorithm (Lines 1-2) simply constructs a new product node \(\alpha^{\prime\prime}=\alpha\times\alpha^{\prime}\). By definition, \(p_{\alpha^{\prime\prime}}=p_{\alpha}\otimes p_{\alpha^{\prime}}\), has scope \(\text{vars}(\alpha^{\prime\prime})=\text{vars}(\alpha)\cup\text{vars}(\alpha^ {\prime})\), and \(\alpha^{\prime\prime}\) is decomposable.

If the \(\alpha,\alpha^{\prime}\) are input nodes, then we can construct a new input node \(\alpha^{\prime\prime}\) satisfying the requisite properties (Lines 3-4).

If \(\alpha=\alpha_{1}\times\alpha_{2},\alpha^{\prime}=\alpha^{\prime}_{1}\times \alpha^{\prime}_{2}\) are product nodes and \(\iota(\alpha)=\alpha^{\prime}\), then the Algorithm (Lines 5-6) constructs a product node \(\alpha^{\prime\prime}=\texttt{PROD-SCMP}(\alpha_{1},\alpha^{\prime}_{1})\times \texttt{PROD-SCMP}(\alpha_{2},\alpha^{\prime}_{2})\). Define \(\bm{X}=\bm{V}\cup\bm{V}^{\prime}\). By support compatibility (i.e. \(\bm{X}\)-support compatibility), \(\alpha,\alpha^{\prime}\) are part of the restricted circuits \(C[\bm{X}],C^{\prime}[\bm{X}]\) respectively and so \(\text{vars}(\alpha)\cap\bm{X}\neq\emptyset,\text{vars}(\alpha^{\prime})\cap\bm{ X}\neq\emptyset\). There are two cases to consider; we first show that in both of these cases, we can apply the inductive hypothesis to \(\texttt{PROD-SCMP}(\alpha_{1},\alpha^{\prime}_{1})\) and \(\texttt{PROD-SCMP}(\alpha_{2},\alpha^{\prime}_{2})\).

* Firstly, suppose that both \(\alpha_{1}\) and \(\alpha_{2}\) have scope overlapping with \(\bm{X}\). Then by the isomorphism, we have \(\alpha^{\prime}_{1}=\iota(\alpha_{1})\), \(\alpha^{\prime}_{2}=\iota(\alpha_{2})\). By the definition of support compatibility, this also means \(\text{vars}(\alpha_{1})\cap\bm{X}=\text{vars}(\alpha^{\prime}_{1})\cap\bm{X}\) and \(\text{vars}(\alpha_{2})\cap\bm{X}=\text{vars}(\alpha^{\prime}_{2})\cap\bm{X}\) and these are both non-empty; thus we can apply the inductive hypothesis for \(\texttt{PROD-SCMP}(\alpha_{1},\alpha^{\prime}_{1})\) and \(\texttt{PROD-SCMP}(\alpha_{2},\alpha^{\prime}_{2})\).
* Second, suppose instead that only \(\alpha_{1}\) has scope overlapping with \(\bm{X}\), and so \(\text{vars}(\alpha_{2})\cap\bm{X}=\emptyset\). Then \(\alpha^{\prime}_{1}=\iota(\alpha_{1})\) and \(\text{vars}(\alpha_{1})\cap\bm{X}=\text{vars}(\alpha^{\prime}_{1})\cap\bm{X}= \text{vars}(\alpha)\cap\bm{X}=\text{vars}(\alpha^{\prime})\cap\bm{X}\). Since \(\text{vars}(\alpha^{\prime}_{2})=\text{vars}(\alpha^{\prime})\setminus\text{vars} (\alpha^{\prime}_{1})\), it follows that \(\text{vars}(\alpha_{2})\cap\bm{X}=(\text{vars}(\alpha^{\prime})\cap\bm{X}) \setminus(\text{vars}(\alpha^{\prime}_{1})\cap\bm{X})=\emptyset\), i.e. \(\alpha^{\prime}_{2}\) also does not have scope overlapping with \(\bm{X}\). Since \(\bm{X}\) are the shared variables \(\bm{V},\bm{V}^{\prime}\), it follows that \(\text{vars}(\alpha_{2})\cap\text{vars}(\alpha^{\prime}_{2})=\emptyset\), and so we can apply the inductive hypothesis for \(\texttt{PROD-SCMP}(\alpha_{2},\alpha^{\prime}_{2})\) (and for \(\texttt{PROD-SCMP}(\alpha_{1},\alpha^{\prime}_{1})\)).

By the inductive hypothesis, \(\texttt{PROD-SCMP}(\alpha_{1},\alpha^{\prime}_{1})\) has scope \(\text{vars}(\alpha_{1})\cup\text{vars}(\alpha^{\prime}_{1})\) and \(\texttt{PROD-SCMP}(\alpha_{2},\alpha^{\prime}_{2})\) has scope \(\text{vars}(\alpha_{2})\cup\text{vars}(\alpha^{\prime}_{2})\). We can thus apply Lemma 1. Thus \(\texttt{PROD-SCMP}(\alpha_{1},\alpha^{\prime}_{1})\) and \(\texttt{PROD-SCMP}(\alpha_{2},\alpha^{\prime}_{2})\) have disjoint scopes and \(\alpha^{\prime\prime}\) is decomposable. Wecan also verify that \(p_{\alpha^{\prime\prime}}=p_{\texttt{PROD-SCMP}(\alpha_{1},\alpha_{1}^{\prime})} \otimes p_{\texttt{PROD-SCMP}(\alpha_{2},\alpha_{2}^{\prime})}=p_{\alpha_{1}} \otimes p_{\alpha_{1}^{\prime}}\otimes p_{\alpha_{2}}\otimes p_{\alpha_{2}^{ \prime}}=p_{\alpha}\otimes p_{\alpha^{\prime}}\) by the inductive hypothesis, and associativity of \(\otimes\).

If \(\alpha=+_{i=1}^{k}\alpha_{i}\), \(\alpha^{\prime}=+_{i=1}^{k^{\prime}}\alpha_{i}^{\prime}\) are sum nodes and \(\iota(\alpha)=\alpha^{\prime}\), then by smoothness, all of the children of \(\alpha\) have the same support and all the children of \(\alpha\) have the same support; thus all the children are in \(C[\bm{X}],C^{\prime}[\bm{X}]\) respectively, \(k=k^{\prime}\), and \(\iota(\alpha_{i})=\alpha_{i}^{\prime}\). By support compatibility, we also that (i) \(\text{vars}(\alpha_{i})\cap\bm{X}=\text{vars}(\alpha_{j}^{\prime})\cap\bm{X}\) for all \(i,j\); and (ii) that \(\text{supp}_{\bm{X}}(\alpha_{i})\cap\text{supp}_{\bm{X}}(\alpha_{j}^{\prime})\) for \(i\neq j\).

We claim that \(p_{\alpha_{i}}\otimes p_{\alpha_{j}^{\prime}}\equiv 0_{\mathcal{S}}\) whenever \(i\neq j\). To see this, recall the definition of \(\bm{X}\)-support: we have that:

\[\text{supp}_{\bm{X}}(\alpha_{i})=\{\bm{x}\in\text{Assign}(\bm{X} \cap\text{vars}(\alpha_{i})):\exists\bm{y}\in\text{Assign}(\text{vars}( \alpha_{i})\setminus\bm{X})\text{ s.t. }p_{\alpha_{i}}(\bm{x},\bm{y})\neq 0_{ \mathcal{S}}\}\] \[\text{supp}_{\bm{X}}(\alpha_{j}^{\prime})=\{\bm{x}\in\text{Assign }(\bm{X}\cap\text{vars}(\alpha_{j}^{\prime})):\exists\bm{y}\in\text{Assign}( \text{vars}(\alpha_{j}^{\prime})\setminus\bm{X})\text{ s.t. }p_{\alpha_{j}^{\prime}}(\bm{x},\bm{y})\neq 0_{ \mathcal{S}}\}\]

Since \(\bm{X}\cap\text{vars}(\alpha_{i})=\bm{X}\cap\text{vars}(\alpha_{j}^{\prime})\) and is nonempty, by (ii) we know that there is no assignment of \(\bm{X}\cap\text{vars}(\alpha_{i})\) such that \(p_{\alpha_{i}}\) and \(p_{\alpha_{j}^{\prime}}\) can be simultaneously not equal to \(0_{\mathcal{S}}\). Thus there is no assignment of \(\bm{X}\cap\text{vars}(\alpha_{i})\) such that \(p_{\alpha_{i}}\otimes p_{\alpha_{j}^{\prime}}\) is not \(0_{\mathcal{S}}\), since \(0_{\mathcal{S}}\) is the multiplicative annihilator.

Thus, the product function is given by:

\[p_{\alpha}\otimes p_{\alpha^{\prime}} =\bigoplus_{i=1}^{k}\bigoplus_{j=1}^{k}(p_{\alpha_{i}}\otimes p_{ \alpha_{j}^{\prime}})\] \[=\bigoplus_{i=1}^{k}(p_{\alpha_{i}}\otimes p_{\alpha_{i}^{\prime}})\] \[=\bigoplus_{i=1}^{k}\texttt{PROD-SCMP}(\alpha_{i},\alpha_{i}^{ \prime})\]

The second equality follows by the Lemma and the fact that \(0_{\mathcal{S}}\) is the additive identity, and the third equality by the inductive hypothesis. Thus \(\alpha^{\prime\prime}=+_{i=1}^{k}\texttt{PROD-SCMP}(\alpha_{i},\alpha_{i}^{ \prime})\) computes the correct function (Lines 7-8). We conclude by noting that \(\text{vars}(\alpha^{\prime\prime})=\bigcup_{i=1}^{k}(\text{vars}(\alpha_{i}) \cup\text{vars}(\alpha_{i}))=\bigcup_{i=1}^{k}\text{vars}(\alpha_{i})\cup \bigcup_{i=1}^{k}\text{vars}(\alpha_{i})=\text{vars}(\alpha)\cup\text{vars}( \alpha^{\prime})\).

The complexity of this procedure applied to the root nodes is \(O(\max(|C|,|C^{\prime}|)\), as we only perform recursive calls for (i) \(\alpha\in C[\bm{X}]\) and its corresponding node \(\alpha^{\prime}=\iota(\alpha)\) and (ii) nodes with non-overlapping scope, upon which the recursion ends; so the overall number of recursive calls is linear in the size of the circuits.

### Tractable Elementwise Mapping

**Theorem 4** (Tractable Mapping).: _Let \(C\) be a smooth and decomposable circuit over semiring \(\mathcal{S}\), and \(\tau:\mathcal{S}\rightarrow\mathcal{S}^{\prime}\) a mapping such that \(\tau(0_{\mathcal{S}})=0_{\mathcal{S}^{\prime}}\). Then it is possible to compute the mapping of \(C\) by \(\tau\) as a smooth and decomposable circuit \(C^{\prime}\) (i.e., \(p_{C^{\prime}}(\bm{V})=\tau(p_{C}(\bm{V}))\)) in \(O(|C|)\) time and space if \(\tau\) distributes over sums and over products._

\(\tau\) distributes over sums _if: either **(Additive)**_\(\tau\) is an additive homomorphism, i.e. \(\tau(a\oplus b)=\tau(a)\oplus\tau(b)\); or **(Det)**_\(C\) is deterministic._

\(\tau\) distributes over products _if: either **(Multiplicative)**_\(\tau\) is an multiplicative homomorphism, i.e. \(\tau(a\otimes b)=\tau(a)\otimes\tau(b)\); or **(Prod 0/1)**_\(\tau(1_{\mathcal{S}})=1_{\mathcal{S}^{\prime}}\), and for all product nodes \(\alpha=\alpha_{1}\times\alpha_{2}\in C\), and for every value \(\bm{v}\in\text{Assign}(\text{vars}(\alpha))\), either \(p_{\alpha_{1}}(\bm{v}_{\text{vars}(\alpha_{1})})\in\{0_{\mathcal{S}},1_{ \mathcal{S}}\}\) or \(p_{\alpha_{2}}(\bm{v}_{\text{vars}(\alpha_{2})})\in\{0_{\mathcal{S}},1_{ \mathcal{S}}\}\)._

Proof.: First, let us consider sum nodes. Given any sum node \(\alpha=+_{i=1}^{k}\alpha_{i}\in C\), we consider computing a circuit representing

\[\tau\big{(}p_{\alpha}(\text{vars}(\alpha))\big{)}\equiv\tau\Big{(}\bigoplus_{i=1 }^{k}p_{\alpha_{i}}(\text{vars}(\alpha))\Big{)}\] (5)If (Additive) holds, then we immediately have that \(\tau\big{(}\bigoplus_{i=1}^{k}p_{\alpha_{i}}(\text{vars}(\alpha))\big{)}\equiv \bigoplus_{i=1}^{k}\tau(p_{\alpha_{i}}(\text{vars}(\alpha)))\) by associativity of \(\oplus\). Alternatively, if (Det) holds, then given any \(\bm{v}\in\text{Assign}((\text{vars}(\alpha)))\), there is at most one child, say \(\alpha_{j}\), such that \(p_{\alpha_{j}}(\bm{v})\neq 0_{\mathcal{S}}\). Then we have that

\[\tau\big{(}\oplus_{i=1}^{k}p_{\alpha_{i}}(\bm{v})\big{)} =\tau\Big{(}p_{\alpha_{j}}(\bm{v})\oplus\Big{(}\bigoplus_{i=1,i \neq j}^{k}p_{\alpha_{i}}(\bm{v})\Big{)}\Big{)}\] \[=\tau\Big{(}p_{\alpha_{j}}(\bm{v})\oplus\Big{(}\bigoplus_{i=1,i \neq j}^{k}0_{\mathcal{S}}\Big{)}\Big{)}\] \[=\tau\big{(}p_{\alpha_{j}}(\bm{v})\big{)}\] \[=\tau\big{(}p_{\alpha_{j}}(\bm{v})\big{)}\oplus\Big{(}\bigoplus_{ i=1,i\neq j}^{k}0_{\mathcal{S}^{\prime}}\Big{)}\] \[=\tau\big{(}p_{\alpha_{j}}(\bm{v})\big{)}\oplus\Big{(}\bigoplus_{ i=1,i\neq j}^{k}\tau(p_{\alpha_{i}}(\bm{v}))\Big{)}\] \[=\bigoplus_{i=1}^{k}\tau(p_{\alpha_{i}}(\bm{v}))\]

and so again \(\tau\Big{(}\bigoplus_{i=1}^{k}p_{\alpha_{i}}(\bm{v})\Big{)}\equiv\bigoplus_{ i=1}^{k}\tau(p_{\alpha_{i}}(\bm{v}))\).

Second, let us consider product nodes. If (Multiplicative) holds, then we immediately have that \(\tau\Big{(}\bigotimes_{i=1}^{k}p_{\alpha_{i}}(\text{vars}(\alpha))\Big{)} \equiv\bigotimes_{i=1}^{k}\tau(p_{\alpha_{i}}(\text{vars}(\alpha)))\) by associativity of \(\otimes\). Otherwise, if (Prod 0/1) holds, then given any \(\bm{v}\in\text{Assign}(\text{vars}(\alpha))\), there is at most one child, say \(\alpha_{j}\), such that \(p_{\alpha_{j}}(\bm{v})\not\in\{0_{\mathcal{S}},1_{\mathcal{S}}\}\). Thus, we have that:

\[\tau\Big{(}\bigotimes_{i=1}^{k}p_{\alpha_{i}}(\bm{v})\Big{)} =\tau\Big{(}p_{\alpha_{j}}(\bm{v})\otimes\Big{(}\bigotimes_{i=1,i \neq j}^{k}p_{\alpha_{i}}(\bm{v})\Big{)}\Big{)}\] \[=\tau\big{(}p_{\alpha_{j}}(\bm{v})\big{)}\otimes\tau\Big{(} \bigotimes_{i=1,i\neq j}^{k}p_{\alpha_{i}}(\bm{v})\Big{)}\] \[=\bigotimes_{i=1}^{k}\tau(p_{\alpha_{i}}(\bm{v}))\]

The second equality follows because \(\Big{(}\bigotimes_{i=1,i\neq j}^{k}p_{\alpha_{i}}(\bm{v})\Big{)}\in\{0_{ \mathcal{S}},1_{\mathcal{S}}\}\), and we have that \(\tau(a\otimes 0_{\mathcal{S}})=0_{\mathcal{S}^{\prime}}=\tau(a)\otimes\tau(0_{ \mathcal{S}})\) and \(\tau(a\otimes 1_{\mathcal{S}})=1_{\mathcal{S}^{\prime}}=\tau(a)\otimes\tau(1_{ \mathcal{S}})\) for any \(a\in\mathcal{S}\). The third equality follows as both \(\tau\Big{(}\bigotimes_{i=1,i\neq j}^{k}p_{\alpha_{i}}(\bm{v})\Big{)}\) and \(\bigotimes_{i=1,i\neq j}^{k}\tau(p_{\alpha_{i}}(\bm{v}))\) are equal to \(1_{\mathcal{S}^{\prime}}\) iff no \(p_{\alpha_{i}}(\bm{v})\) is \(0_{\mathcal{S}}\). Thus, we have that \(\tau\Big{(}\bigotimes_{i=1}^{k}p_{\alpha_{i}}(\bm{v})\Big{)}\equiv\bigotimes_{ i=1}^{k}\tau(p_{\alpha_{i}}(\bm{v}))\).

By applying these identities recursively to sum and product nodes, and assuming that \(\tau\) can be applied tractably to input nodes, we obtain a circuit \(C^{\prime}\) such that \(p_{C^{\prime}}(\bm{V})\equiv\tau(p_{C}(\bm{V}))\). 

### Tractable Composition of operators

**Theorem 5** (Composability Conditions).: _The results in Table 1 hold._Proof.: We look at each property in turn, and show that they are maintained under the aggregation, product, and mapping operators as stated in the Table. For convenience, we reproduce the table in Table 3, with each result highlighted with a number that is referenced in the proof below.

X-determinismSuppose that circuit \(C\) is \(\bm{X}\)-deterministic; that is, for any sum node \(\alpha=+_{i=1}^{k}\alpha_{i}\in C\), either (i) \(\text{vars}(\alpha)\cap\bm{X}=\emptyset\), or else (ii) \(\text{supp}_{\bm{X}}(\alpha_{i})\cap\text{supp}_{\bm{X}}(\alpha_{j})=\emptyset\) for all \(i\neq j\).

**(5.1)** Consider aggregating with respect to a set of variables \(\bm{W}\) such that \(\bm{W}\cap\bm{X}=\emptyset\). According to Algorithm 1 and the proof of Theorem 1, this produces an output circuit where each node \(\alpha^{\prime}\) corresponds to some node \(\alpha\) in the original circuit, such that \(p_{\alpha^{\prime}}=\bigoplus_{\bm{w}\cap\text{vars}(\alpha)}p_{\alpha}\) and with scope \(\text{vars}(\alpha)\setminus\bm{W}\). In particular, for sum nodes \(\alpha=+_{i=1}^{k}\alpha_{i}\in C\), either \(\text{vars}(\alpha)\subseteq\bm{W}\), in which case \(\alpha^{\prime}\) is an input node (and \(\bm{X}\)-determinism is not applicable), or else \(\alpha^{\prime}=+_{i=1}^{k}\alpha_{i}^{\prime}\) is also a sum node, where each \(\alpha_{i}^{\prime}\) corresponds to \(\alpha_{i}\). If (i) \(\text{vars}(\alpha)\cap\bm{X}=\emptyset\), then \(\text{vars}(\alpha^{\prime})\cap\bm{X}=\emptyset\) also.

If (ii) \(\text{supp}_{\bm{X}}(\alpha_{i})\cap\text{supp}_{\bm{X}}(\alpha_{j})=\emptyset\) for all \(i\neq j\), we claim that \(\text{supp}_{\bm{X}}(\alpha_{i}^{\prime})\subseteq\text{supp}_{\bm{X}}(\alpha _{i})\) for all \(i\). To see this, first note that by smoothness, \(\text{vars}(\alpha_{i}^{\prime})=\text{vars}(\alpha_{j}^{\prime})=\text{vars} (\alpha^{\prime})\). Suppose that \(\bm{x}_{i}\in\text{Assign}(\bm{X}\cap\text{vars}(\alpha^{\prime}))\) satisfies \(\bm{x}\in\text{supp}_{\bm{X}}(\alpha_{i}^{\prime})\). Then there exists \(\bm{y}_{i}\in\text{Assign}(\text{vars}(\alpha^{\prime})\setminus\bm{X})\) such that \(p_{\alpha_{i}^{\prime}}(\bm{x}_{i},\bm{y}_{i})\neq 0_{\mathcal{S}}\). Since \(\alpha_{i}^{\prime}\) corresponds to \(\alpha_{i}\) in the original circuit, we have:

\[\bigoplus_{\bm{w}\in\text{Assign}(\bm{W})\cap\text{vars}(\alpha)}p_{\alpha_{ i}}(\bm{x}_{i},\bm{y}_{i},\bm{w}_{i})=p_{\alpha_{i}^{\prime}}(\bm{x},\bm{y})\neq 0_{ \mathcal{S}}\]

This means that there must be some \(\bm{w}_{i}\in\text{Assign}(\bm{W})\cap\text{vars}(\alpha)\) such that \(p_{\alpha_{i}}(\bm{x},\bm{y}_{i},\bm{w}_{i})\neq 0_{\mathcal{S}}\) (since \(0_{\mathcal{S}}\) is the additive identity); thus \(\bm{x}\in\text{supp}_{\bm{X}}(\alpha_{i})\). To finish the proof, note that \(\text{supp}_{\bm{X}}(\alpha_{i}^{\prime})\subseteq\text{supp}_{\bm{X}}(\alpha _{i})\) and \(\text{supp}_{\bm{X}}(\alpha_{i}^{\prime})\subseteq\text{supp}_{\bm{X}}(\alpha _{l})\) are disjoint unless \(i=l\) (by \(\bm{X}\)-determinism of \(\alpha\), i.e. \(\text{supp}_{\bm{X}}(\alpha_{i})\cap\text{supp}_{\bm{X}}(\alpha_{l})=\emptyset\) unless \(i=l\)). Thus (ii) holds for \(\alpha^{\prime}\). In either case, we have shown that \(\alpha^{\prime}\) is also \(\bm{X}\)-deterministic.

**(5.2)** Consider taking the product of two compatible circuits \(C,C^{\prime}\) over variables \(\bm{V},\bm{V^{\prime}}\), outputting a circuit \(C^{\prime\prime}\). According to Algorithm 2 and the proof of Theorem 2, every sum node \(\alpha^{\prime\prime}\in C^{\prime\prime}\) corresponds to either the product of (a) an input or product node \(\alpha\in C\) and a sum node \(\alpha^{\prime}=+_{j=1}^{k^{\prime}}\alpha_{j}^{\prime}\in C^{\prime}\), such that \(\alpha^{\prime\prime}=+_{j=1}^{k^{\prime}}\alpha_{j}^{\prime\prime}\) or (b) two sum nodes \(\alpha=+_{i=1}^{k}\alpha_{i}\in C\) and \(\alpha^{\prime}=+_{j=1}^{k^{\prime}}\alpha_{j}^{\prime}\in C^{\prime}\), such that \(\alpha^{\prime\prime}=+_{i=1}^{k^{\prime}}+_{j=1}^{k^{\prime}}\alpha_{ij}^{\prime\prime}\). Further, \(\alpha\) and \(\alpha^{\prime}\) have the same scope over the common variables \(\bm{V}\cap\bm{V}^{\prime}\), i.e. \(\text{vars}(\alpha)\cap(\bm{V}\cap\bm{V}^{\prime})=\text{vars}(\alpha^{\prime}) \cap(\bm{V}\cap\bm{V}^{\prime})\).

Assume that \(C\) and \(C^{\prime}\) are both \(\bm{X}\)-deterministic; then \(\bm{X}\subseteq\bm{V}\cap\bm{V}^{\prime}\). We note that since \(\alpha,\alpha^{\prime}\) have the same scope over the common variables, they also have the same scope over \(\bm{X}\), i.e. \(\text{vars}(\alpha)\cap\bm{X}=\text{vars}(\alpha^{\prime})\cap\bm{X}\).

In case (a), \(\bm{X}\)-determinism of \(\alpha^{\prime}\) means that either (i) \(\text{vars}(\alpha^{\prime})\cap\bm{X}=\emptyset\) or (ii) \(\text{supp}_{\bm{X}}(\alpha_{i}^{\prime})\cap\text{supp}_{\bm{X}}(\alpha_{j}^{ \prime})=\emptyset\) for all \(i\neq j\). If (i), then \(\text{vars}(\alpha^{\prime\prime})\cap\bm{X}=(\text{vars}(\alpha)\cup\text{vars}( \alpha^{\prime}))\cap\bm{X}=\emptyset\) also. If (ii), note that \(\text{supp}_{\bm{X}}(\alpha_{j}^{\prime\prime})\subseteq\text{supp}_{\bm{X}}( \alpha_{j}^{\prime})\) for all \(j\) as \(a\otimes 0_{\mathcal{S}}=0_{\mathcal{S}}\) for any semiring \(\mathcal{S}\) and \(a\in\mathcal{S}\). Thus \(\text{supp}_{\bm{X}}(\alpha_{i}^{\prime\prime})\cap\text{supp}_{\bm{X}}( \alpha_{j}^{\prime\prime})=\emptyset\) for all \(i\neq j\). Thus \(\alpha^{\prime\prime}\) is \(\bm{X}\)-deterministic.

In case (b), since \(\alpha,\alpha^{\prime}\) have the same scope over \(\bm{X}\), either (i) holds for both \(\alpha,\alpha^{\prime}\), or (ii) holds for both. If (i), then \(\text{vars}(\alpha^{\prime\prime})\cap\bm{X}=(\text{vars}(\alpha)\cup\text{vars}( \alpha^{\prime}))\cap\bm{X}=\emptyset\) also. If (ii), then for any \(i,j\), consider the restricted support \(\text{supp}_{\bm{X}}(\alpha_{ij}^{\prime\prime})\). Noting that \(\text{vars}(\alpha_{i})\cap\bm{X}=\text{vars}(\alpha_{j}^{\prime})\cap\bm{X}= \text{vars}(\alpha_{ij}^{\prime\prime})\cap\bm{X}=\text{vars}(\alpha_{ij}^{ \prime\prime})\cap\bm{X}=\emptyset\)

\begin{table}
\begin{tabular}{l l l l l l} \hline \hline  & & & & & & & \\ \hline \multirow{3}{*}{**Argeation (\(\bm{W}\))**} & \multirow{3}{*}{Sm AND Dec} & \multirow{3}{*}{\begin{tabular}{l} \(\bm{X}\)-Det \\ \(\bm{i}\) if \(\bm{W}\cap\bm{X}=\emptyset\) \\ (\(\bm{5}\).1) \\ \end{tabular} } & \multirow{3}{*}{\begin{tabular}{l} \(\bm{X}\)-Cmp w/ \(C_{\text{other}}\) \\ \(\bm{i}\) if \(\bm{W}\cap\bm{X}=\emptyset\) \\ (\(\bm{5}\).1) \\ \end{tabular} } & \multirow{3}{*}{\begin{tabular}{l} \(\bm{X}\)-Cmp w/ \(C_{\text{other}}\) \\ \(\bm{i}\) if \(\bm{W}\cap\bm{X}=\emptyset\) \\ (\(\bm{5}\).5) \\ \end{tabular} } & \multirow{3}{*}{
\begin{tabular}{l} \(\bm{X}\)-Cmp w/ \(C_{\text{other}}\) \\ \(\bm{i}\) if \(\bm{W}\\(\bm{X}\) by smoothness, we claim that \(\text{supp}_{\bm{X}}(\alpha^{\prime\prime}_{ij})\subseteq\text{supp}_{\bm{X}}( \alpha_{i})\cap\text{supp}_{\bm{X}}(\alpha^{\prime}_{j})\). Suppose that \(\bm{x}\in\text{supp}_{\bm{X}}(\alpha^{\prime\prime}_{ij})\). Then there exists some \(\bm{y}\in\text{vars}(\alpha^{\prime\prime}_{ij})\backslash\bm{X}\) such that \(p_{\alpha^{\prime\prime}_{ij}}(\bm{x},\bm{y})=p_{\alpha_{i}}(\bm{x},\bm{y}_{ \text{vars}(\alpha_{i})\backslash\bm{X}})\otimes p_{\alpha^{\prime}_{j}}(\bm{x },\bm{y}_{\text{vas}(\alpha^{\prime}_{j})\backslash\bm{X}})\neq 0_{\mathcal{S}}\). This means that both \(p_{\alpha_{i}}(\bm{x},\bm{y}_{\text{vas}(\alpha_{i})\backslash\bm{X}}),p_{ \alpha^{\prime}_{j}}(\bm{x},\bm{y}_{\text{vas}(\alpha^{\prime}_{j})\backslash \bm{X}})\) cannot be \(0_{\mathcal{S}}\), and so \(\bm{x}\in\text{supp}_{\bm{X}}(\alpha_{i})\) and \(\bm{x}\in\text{supp}_{\bm{X}}(\alpha^{\prime}_{j})\) also. To finish the proof, we note that \(\text{supp}_{\bm{X}}(\alpha^{\prime\prime}_{ij})\subseteq\text{supp}_{\bm{X} }(\alpha_{i})\cap\text{supp}_{\bm{X}}(\alpha^{\prime}_{j})\) and \(\text{supp}_{\bm{x}}(\alpha^{\prime\prime}_{lm})\subseteq\text{supp}_{\bm{X} }(\alpha_{l})\cap\text{supp}_{\bm{X}}(\alpha^{\prime}_{m})\) are disjoint unless \(i=l,j=m\) (by \(\bm{X}\)-determinism of \(\alpha\) and \(\alpha^{\prime}\)). Thus \(\alpha^{\prime\prime}\) is \(\bm{X}\)-deterministic by (ii).

**(5.3)** Consider taking the product of two support-compatible circuits \(C,C^{\prime}\) over variables \(\bm{V},\bm{V^{\prime}}\), outputting a circuit \(C^{\prime\prime}\). According to Algorithm 3 and the proof of Theorem 3, every sum node \(\alpha^{\prime\prime}=+_{i=1}^{k}\alpha^{\prime\prime}_{i}\in C^{\prime\prime}\) corresponds to some sum nodes \(\alpha=+_{i=1}^{k}\alpha_{i}\in C\) and \(\alpha^{\prime}=+_{i=1}^{k}\alpha^{\prime}_{i}\in C^{\prime}\) such that \(\alpha^{\prime}=\iota(\alpha)\), \(p_{\alpha^{\prime}_{i}}=p_{\alpha_{i}}\otimes p_{\alpha^{\prime}_{i}}\), and has scope \(\text{vars}(\alpha)\cup\text{vars}(\alpha^{\prime})\). Further, \(\alpha\) and \(\alpha^{\prime}\) have the same scope over the common variables \(\bm{V}\cap\bm{V^{\prime}}\), i.e. \(\text{vars}(\alpha)\cap(\bm{V}\cap\bm{V^{\prime}})=\text{vars}(\alpha^{ \prime})\cap(\bm{V}\cap\bm{V^{\prime}})\).

Assume that \(C\) and \(C^{\prime}\) are both \(\bm{X}\)-deterministic; then \(\bm{X}\subseteq\bm{V}\cap\bm{V^{\prime}}\). We note that since \(\alpha,\alpha^{\prime}\) have the same scope over the common variables, they also have the same scope over \(\bm{X}\), i.e. \(\text{vars}(\alpha)\cap\bm{X}=\text{vars}(\alpha^{\prime})\cap\bm{X}\). Thus, either (i) holds for both \(\alpha,\alpha^{\prime}\), or (ii) holds for both. If (i), then \(\text{vars}(\alpha^{\prime\prime})\cap\bm{X}=(\text{vars}(\alpha)\cup\text{vars }(\alpha^{\prime}))\cap\bm{X}=\emptyset\) also. If (ii), then for any \(i\), consider the restricted support \(\text{supp}_{\bm{X}}(\alpha^{\prime\prime}_{ij})\). Noting that \(\text{vars}(\alpha_{i})\cap\bm{X}=\text{vars}(\alpha^{\prime}_{j})\cap\bm{X }=\text{vars}(\alpha^{\prime\prime}_{i})\cap\bm{X}\) by smoothness, we claim that \(\text{supp}_{\bm{X}}(\alpha^{\prime\prime}_{ij})\subseteq\text{supp}_{\bm{X} }(\alpha_{i})\cap\text{supp}_{\bm{X}}(\alpha^{\prime}_{i})\). Suppose that \(\bm{x}\in\text{supp}_{\bm{X}}(\alpha^{\prime\prime}_{i})\). Then there exists some \(\bm{y}\in\text{vars}(\alpha^{\prime\prime}_{i})\setminus\bm{X}\) such that \(p_{\alpha^{\prime\prime}_{i}}(\bm{x},\bm{y})=p_{\alpha_{i}}(\bm{x},\bm{y}_{ \text{vars}(\alpha_{i})\backslash\bm{X}})\otimes p_{\alpha^{\prime}_{i}}(\bm{x },\bm{y}_{\text{vars}(\alpha^{\prime}_{i})\backslash\bm{X}})\neq 0_{\mathcal{S}}\). This means that both \(p_{\alpha_{i}}(\bm{x},\bm{y}_{\text{vas}(\alpha_{i})\backslash\bm{X}}),p_{ \alpha^{\prime}_{i}}(\bm{x},\bm{y}_{\text{vars}(\alpha^{\prime}_{i})\backslash \bm{X}})\) cannot be \(0_{\mathcal{S}}\), and so \(\bm{x}\in\text{supp}_{\bm{X}}(\alpha_{i})\) and \(\bm{x}\in\text{supp}_{\bm{X}}(\alpha^{\prime}_{i})\) also. To finish the proof, we note that \(\text{supp}_{\bm{X}}(\alpha^{\prime\prime}_{i})\subseteq\text{supp}_{\bm{X} }(\alpha_{i})\cap\text{supp}_{\bm{X}}(\alpha^{\prime}_{i})\) and \(\text{supp}_{\bm{x}}(\alpha^{\prime\prime}_{i})\subseteq\text{supp}_{\bm{X} }(\alpha_{l})\cap\text{supp}_{\bm{X}}(\alpha^{\prime}_{l})\) are disjoint unless \(i=l\) (by \(\bm{X}\)-determinism of \(\alpha\) and \(\text{supp}_{\bm{x}}(\alpha^{\prime\prime}_{l})\subseteq\text{supp}_{\bm{X} }(\alpha_{l})\cap\text{supp}_{\bm{X}}(\alpha^{\prime}_{l})\) are disjoint unless \(i=l\) (by \(\bm{X}\)-determinism of \(\alpha\) and \(\alpha^{\prime}\)). Thus \(\alpha^{\prime\prime}\) is \(\bm{X}\)-deterministic by (ii).

**(5.4)** Consider applying an elementwise mapping \(\tau\) to a circuit \(C\), outputting a circuit \(C^{\prime}\). According to Algorithm 4 and Theorem 4, every sum node \(\alpha^{\prime}=+_{i=1}^{k}\alpha^{\prime}_{i}\in C^{\prime}\) corresponds to some node \(\alpha=+_{i=1}^{k}\alpha_{i}\in C^{\prime}\), such that \(p_{\alpha^{\prime}}=\tau(p_{\alpha})\), and further \(p_{\alpha^{\prime}_{i}}=\tau(p_{\alpha_{i}})\) and \(\text{vars}(\alpha^{\prime}_{i})=\text{vars}(\alpha_{i})\) for each \(i\).

Assume that \(C\) is \(\bm{X}\)-deterministic. If (i) \(\text{vars}(\alpha)\cap\bm{X}=\emptyset\), then \(\text{vars}(\alpha^{\prime})\bm{X}=\emptyset\) also. Otherwise, (ii) \(\text{supp}_{\bm{X}}(\alpha_{i})\cap\text{supp}_{\bm{X}}(\alpha_{j})=\emptyset\) for all \(i\neq j\). We claim that \(\text{supp}_{\bm{X}}(\alpha^{\prime}_{i})\subseteq\text{supp}_{\bm{X}}(\alpha_{i})\) for each \(i\). To see this, recall that elementwise mappings satisfy \(\tau(0_{\mathcal{S}})=0_{\mathcal{S}}\). If \(\bm{x}\in\text{supp}_{\bm{X}}(\alpha^{\prime}_{i})\), then there exists \(\bm{y}\) s.t. \(p_{\alpha^{\prime}_{i}}(\bm{x},\bm{y})\neq 0_{\mathcal{S}^{\prime}}\). Since \(p_{\alpha^{\prime}_{i}}(\bm{x},\bm{y})=\tau(p_{\alpha_{i}}(\bm{x},\bm{y}))\), \(p_{\alpha_{i}}(\bm{x},\bm{y})\neq 0_{\mathcal{S}}\). So \(\bm{x}\in\text{supp}_{\bm{X}}(\alpha_{i})\). To finish the proof, note that \(\text{supp}_{\bm{x}}(\alpha^{\prime}_{i})\subseteq\text{supp}_{\bm{X}}(\alpha_{i})\) and \(\text{supp}_{\bm{x}}(\alpha^{\prime}_{i})\subseteq\text{supp}_{\bm{X}}(\alpha_{i})\) are disjoint unless \(i=l\) (by \(\bm{X}\)-determinism of \(\alpha\)). Thus \(\alpha^{\prime}\) is \(\bm{X}\)-deterministic by (ii).

X-compatibilityRecall that two smooth and decomposable circuits \(C,C_{\text{other}}\)\(\operatorname{vars}(\alpha^{\prime})\cap(\bm{V}\cap\bm{V^{\prime}})\) (and similarly for their children). Thus by \((\bm{V}\cup\bm{V^{\prime}})\)-compatibility of \(C,C^{\prime}\), \(\alpha\) and \(\alpha^{\prime}\) decompose the same way over \((\bm{V}\cup\bm{V^{\prime}})\), i.e. \(\operatorname{vars}(\alpha_{1})\cap(\bm{V}\cup\bm{V^{\prime}})=\operatorname{vars }(\alpha^{\prime}_{1})\cap(\bm{V}\cup\bm{V^{\prime}})\) and \(\operatorname{vars}(\alpha_{2})\cap(\bm{V}\cup\bm{V^{\prime}})=\operatorname{ vars}(\alpha^{\prime}_{2})\cap(\bm{V}\cup\bm{V^{\prime}})\). Since \(\bm{X}\subseteq\bm{V}\cap\bm{V^{\prime}}\) (by definition of compatibility), this also holds over \(\bm{X}\), i.e. \(\operatorname{vars}(\alpha_{1})\cap\bm{X}=\operatorname{vars}(\alpha^{ \prime}_{1})\cap\bm{X}\) and \(\operatorname{vars}(\alpha_{2})\cap\bm{X}=\operatorname{vars}(\alpha^{ \prime}_{2})\cap\bm{X}\).

Now, since \(\operatorname{vars}(\alpha^{\prime\prime}_{1})=\operatorname{vars}(\alpha_{1} )\cup\operatorname{vars}(\alpha^{\prime}_{1})\) and \(\operatorname{vars}(\alpha^{\prime\prime}_{2})=\operatorname{vars}(\alpha_{ 2})\cup\operatorname{vars}(\alpha^{\prime}_{2})\), we have that:

\[\operatorname{vars}(\alpha^{\prime\prime})\cap\bm{X} =(\operatorname{vars}(\alpha)\cap\bm{X})\cup(\operatorname{vars }(\alpha^{\prime})\cap\bm{X})=\operatorname{vars}(\alpha)\cap\bm{X}\] \[\operatorname{vars}(\alpha^{\prime\prime}_{1})\cap\bm{X} =(\operatorname{vars}(\alpha_{1})\cap\bm{X})\cup(\operatorname{vars }(\alpha^{\prime}_{1})\cap\bm{X})=\operatorname{vars}(\alpha_{1})\cap\bm{X}\] \[\operatorname{vars}(\alpha^{\prime\prime}_{2})\cap\bm{X} =(\operatorname{vars}(\alpha_{2})\cap\bm{X})\cup(\operatorname{vars }(\alpha^{\prime}_{2})\cap\bm{X})=\operatorname{vars}(\alpha_{2})\cap\bm{X}\]

By compatibility of \(C\), \(C_{\text{other}}\), we have that \(\operatorname{vars}(\alpha_{\text{other}})\cap\bm{X}=\operatorname{vars}( \alpha_{1})\cap\bm{X}\) and \(\operatorname{vars}(\alpha_{\text{other}_{2}})\cap\bm{X}=\operatorname{vars}( \alpha_{2})\cap\bm{X}\). Thus \(\operatorname{vars}(\alpha_{\text{other}_{1}})\cap\bm{X}=\operatorname{vars}( \alpha^{\prime\prime}_{1})\cap\bm{X}\) and \(\operatorname{vars}(\alpha_{\text{other}_{2}})\cap\bm{X}=\operatorname{vars}( \alpha^{\prime\prime}_{2})\cap\bm{X}\). This shows \(\bm{X}\)-compatibility of \(C^{\prime\prime},C_{\text{other}}\).

**Example 4** (Counterexample to (5.6) for Compatibility).: _While \(\bm{X}\)-compatibility is maintained through multiplying compatible circuits, the same is not true for compatibility, due to the different variable overlaps between the circuits. For example, suppose that \(C\) over variable sets \(\bm{A},\bm{B},\bm{C}\) has product nodes with scope decomposing as \(\alpha=\alpha_{1}(\bm{A})\times\alpha_{2}(\bm{B}\cup\bm{C})\), and \(C^{\prime}\) over variable sets \(\bm{A},\bm{B},\bm{D}\) has product nodes with scope decomposing as \(\alpha^{\prime}=\alpha^{\prime}_{1}(\bm{A})\times\alpha^{\prime}_{2}(\bm{B}\cup \bm{D})\). Then these circuits are compatible (i.e. \(\bm{A}\cup\bm{B}\)-compatible), and their product is a circuit with product nodes with scope decomposing as \(\alpha^{\prime\prime}=\alpha^{\prime}_{1}(\bm{A})\times\alpha^{\prime}_{2}(\bm{B }\cup\bm{C}\cup\bm{D})\). Now consider \(C_{\text{other}}\) with product nodes with scope decomposing as \(\alpha_{\text{other}}=\alpha_{\text{other}}(\bm{C})\times\alpha_{\text{other}}( \bm{D})\). This is compatible with \(\alpha\) and \(\alpha^{\prime}\), but not with \(\alpha^{\prime\prime}\)._

**(5.7)** This holds by the same argument as (5.6).

**(5.8)** The circuit \(C^{\prime}\) obtained by applying an elementwise mapping to \(C\) does not change the scopes of any node. Thus, if \(C\) is compatible with \(C_{\text{other}}\), then \(C^{\prime}\) is also compatible with \(C_{\text{other}}\).

X-support-compatibilityRecall that two smooth and decomposable circuits \(C\), \(C_{\text{other}}\) over variables \(\bm{V},\bm{V}_{\text{other}}\) are \(\bm{X}\)-support-compatible for \(\bm{X}\subseteq\bm{V}\cap\bm{V}_{\text{other}}\) if there is an isomorphism \(\iota\) between the nodes \(C[\bm{X}]\) and \(C_{\text{other}}[\bm{X}]\), such that:

* For any node \(\alpha\in C[\bm{X}]\), \(\operatorname{vars}(\alpha)\cap\bm{X}=\operatorname{vars}(\iota(\alpha))\cap \bm{X}\);
* For all sum nodes \(\alpha=+_{i=1}^{k}\alpha_{i}\in C[\bm{X}]\), we have that \(\operatorname{supp}_{\bm{X}}(\alpha_{i})\cap\operatorname{supp}_{\bm{X}}( \iota(\alpha_{j}))=\emptyset\) whenever \(i\neq j\).

**(5.9)** Suppose that \(C,C_{\text{other}}\) are \(\bm{X}\)-support-compatible; and let \(\iota_{C_{\text{other}},C}\) be the isomorphism from \(C_{\text{other}}[\bm{X}]\) to \(C[\bm{X}]\). We wish to show that \(C_{\text{other}},C^{\prime}\) are \(\bm{X}\)-support-compatible where \(C^{\prime}\) is the output circuit from Algorithm 1 that aggregates \(C\) over \(\bm{W}\), where \(\bm{W}\cap\bm{X}=\emptyset\).

We define the isomorphism as follows. Consider the set of nodes \(C^{\prime}[\bm{X}]\). Since \(\bm{W}\cap\bm{X}=\emptyset\), these nodes are not scalars and so are not propagated away by Lines 3-4. Moreover, since the algorithm retains the node types and connectivity of the circuit, there is an isomorphism \(\iota_{C,C^{\prime}}\) between \(C[\bm{X}]\) and \(C^{\prime}[\bm{X}]\). There is thus an isomorphism \(\iota_{C_{\text{other}},C^{\prime}}:=\iota_{C,C^{\prime}}\circ\iota_{C_{\text{other}},C}\) between \(C_{\text{other}}[\bm{X}]\) and \(C^{\prime}[\bm{X}]\). It remains to show the two conditions.

Given a node \(\alpha_{\text{other}}\in C_{\text{other}}\), let us write \(\alpha:=\iota_{C_{\text{other}},C}(\alpha_{\text{other}})\) and \(\alpha^{\prime}:=\iota_{C,C^{\prime}}(\alpha)\). By \(\bm{X}\)-support compatibility of \(C_{\text{other}},C\), we have that \(\operatorname{vars}(\alpha_{\text{other}})\cap\bm{X}=\operatorname{vars}(\alpha) \cap\bm{X}\). By the proof of Theorem 1, we know that \(\operatorname{vars}(\alpha^{\prime})=\operatorname{vars}(\alpha)\setminus\bm{W}\). Since \(\bm{W}\cap\bm{X}=\emptyset\), this implies that \(\operatorname{vars}(\alpha_{\text{other}})\cap\bm{X}=\operatorname{vars}(\alpha^{ \prime})\cap\bm{X}\) as required. For the second part, suppose that these are sum nodes, i.e. \(\alpha_{\text{other}}=+_{i=1}^{k}\alpha_{\text{other},i}\), \(\alpha=+_{i=1}^{k}\alpha_{i}\) and \(\alpha^{\prime}=+_{i=1}^{k}\alpha^{\prime}_{i}\). We know by \(\bm{X}\)-support-compatibility that \(\operatorname{supp}_{\bm{X}}(\alpha_{\text{other},i})\cap\operatorname{supp}_{\bm{X} }(\alpha_{j})=\emptyset\) whenever \(i\neq j\). By the same argument as in (5.1), we have that \(\operatorname{supp}_{\bm{X}}(\alpha_{i}^{\prime})\subseteq\operatorname{supp}_{\bm{X} }(\alpha_{i})\) for all \(i\). Thus we can conclude that \(\operatorname{supp}_{\bm{X}}(\alpha_{\text{other},i})\cap\operatorname{supp}_{\bm{X} }(\alpha_{j}^{\prime})=\emptyset\) whenever \(i\neq j\). So \(C_{\text{other}},C^{\prime}\) are \(\bm{X}\)-support-compatible.

**(5.10)** Suppose that \(C\) over \(\bm{V}\) and \(C^{\prime}\) over \(\bm{V}^{\prime}\) are both \(\bm{X}\)-support-compatible with \(C_{\text{other}}\); write \(\iota_{C_{\text{other}},C}\) for the isomorphism from \(C_{\text{other}}[\bm{X}]\) to \(C\), and \(\iota_{C_{\text{other}},C^{\prime}}\) for the isomorphism from \(C_{\text{other}}[\bm{X}]\) to \(C^{\prime}\). We wish to show that \from Algorithm 3 that computes the product of the two support-compatible (i.e. \((\bm{V}\cup\bm{V}^{\prime})\)-support-compatible) circuits \(C,C^{\prime}\).

We define the isomorphism as follows. Consider the set of nodes \(C^{\prime\prime}[\bm{X}]\). The algorithm for multiplying \(C,C^{\prime}\) makes use of the isomorphism \(\iota_{C,C^{\prime}}\) between \(C[\bm{V}\cap\bm{V}^{\prime}]\) and \(C^{\prime}[\bm{V}\cap\bm{V}^{\prime}]\), with \(C^{\prime\prime}[\bm{V}\cap\bm{V}^{\prime}]\) retaining the same connectivity and node types; thus there is an isomorphism \(\iota_{C,C^{\prime\prime}}\) from \(C[\bm{V}\cap\bm{V}^{\prime}]\) to \(C^{\prime\prime}[\bm{V}\cap\bm{V}^{\prime}]\), also. Since \(\bm{X}\subseteq(\bm{V}\cap\bm{V}^{\prime})\), this isomorphism also holds between the circuits restricted to \(\bm{X}\). Thus, we define the isomorphism \(\iota=\iota_{C,C^{\prime\prime}}\circ\iota_{C_{\text{other}},C}\) between \(C_{\text{other}}[\bm{X}]\) and \(C^{\prime\prime}[\bm{X}]\). It remains to show the two conditions.

Given a node \(\alpha_{\text{other}}\in C_{\text{other}}\), let us write \(\alpha:=\iota_{C_{\text{other}},C}(\alpha_{\text{other}})\), \(\alpha^{\prime}=\iota_{C,C^{\prime}}(\alpha)\) and \(\alpha^{\prime\prime}:=\iota_{C,C^{\prime\prime}}(\alpha)\). By \(\bm{X}\)-support-compatibility of \(C_{\text{other}},C\), we have that \(\text{vars}(\alpha_{\text{other}})\cap\bm{X}=\text{vars}(\alpha)\cap\bm{X}\). By support-compatibility of \(C,C^{\prime}\), we have that \(\text{vars}(\alpha)\cap(\bm{V}\cap\bm{V}^{\prime})=\text{vars}(\alpha^{ \prime})\cap(\bm{V}\cap\bm{V}^{\prime})\) and so \(\text{vars}(\alpha)\cap\bm{X}=\text{vars}(\alpha^{\prime})\cap\bm{X}\), and both are equal to \(\text{vars}(\alpha^{\prime\prime})\cap\bm{X}\) since \(\text{vars}(\alpha^{\prime\prime})=\text{vars}(\alpha)\cup\text{vars}(\alpha^ {\prime})\) (as in Theorem 3). Thus \(\text{vars}(\alpha_{\text{other}})\cap\bm{X}=\text{vars}(\alpha^{\prime\prime}) \cap\bm{X}\) as required. For the second part, suppose that these are sum nodes, i.e. \(\alpha_{\text{other}}=+_{i=1}^{k}\alpha_{\text{other},i}\), \(\alpha=+_{i=1}^{k}\alpha_{i}\), \(\alpha^{\prime}=+_{i=1}^{k}\alpha_{i}^{\prime}\) and \(\alpha^{\prime}=+_{i=1}^{k}\alpha_{i}^{\prime\prime}\). We know by \(\bm{X}\)-support-compatibility that \(\text{supp}_{\bm{X}}(\alpha_{\text{other},i})\cap\text{supp}_{\bm{X}}(\alpha_{ j})=\emptyset\) whenever \(i\neq j\). By the same argument as in (5.3), we have that \(\text{supp}_{\bm{X}}(\alpha^{\prime\prime})\subseteq\text{supp}_{\bm{X}}( \alpha)\cap\text{supp}_{\bm{X}}(\alpha^{\prime})\). Thus we can conclude that \(\text{supp}_{\bm{X}}(\alpha_{\text{other},i})\cap\text{supp}_{\bm{X}}(\alpha^ {\prime\prime})=\emptyset\). So \(C_{\text{other}},C^{\prime\prime}\) are \(\bm{X}\)-support-compatible.

**(5.11)** Suppose that \(C,C_{\text{other}}\) are \(\bm{X}\)-support-compatible; and let \(\iota_{C_{\text{other}},C}\) be the isomorphism from \(C_{\text{other}}[\bm{X}]\) to \(C[\bm{X}]\). We wish to show that \(C_{\text{other}},C^{\prime}\) are \(\bm{X}\)-support-compatible where \(C^{\prime}\) is the output circuit from Algorithm 4 that applies an elementwise mapping \(\tau\) to \(C\). Algorithm 4 maps each node \(\alpha\in C\) to another node \(\alpha^{\prime}\in C\), keeping the node type and connectivity; this defines an isomorphism \(\iota_{C,C^{\prime}}\) from \(C[\bm{X}]\) to \(C^{\prime}[\bm{X}]\). Thus we have an isomorphism \(\iota_{C_{\text{other}},C^{\prime}}:=\iota_{C,C^{\prime}}\circ\iota_{C_{\text{other }},C}\). It remains to show the two conditions.

Given a node \(\alpha_{\text{other}}\in C_{\text{other}}\), let us write \(\alpha:=\iota_{C0,C}(\alpha_{\text{other}})\) and \(\alpha^{\prime}:=\iota_{C,C^{\prime}}(\alpha)\). By \(\bm{X}\)-support-compatibility of \(C_{\text{other}},C\), we have that \(\text{vars}(\alpha_{\text{other}})\cap\bm{X}=\text{vars}(\alpha)\cap\bm{X}\). The mapping algorithm does not change the scope of the nodes, i.e. \(\text{vars}(\alpha^{\prime})=\text{vars}(\alpha)\), so we have that \(\text{vars}(\alpha_{\text{other}})\cap\bm{X}=\text{vars}(\alpha^{\prime})\cap \bm{X}\) as required. For the second part, suppose that these are sum nodes, i.e. \(\alpha_{\text{other}}=+_{i=1}^{k}\alpha_{\text{other},i}\), \(\alpha=+_{i=1}^{k}\alpha_{i}\) and \(\alpha^{\prime}=+_{i=1}^{k}\alpha_{i}^{\prime}\). We know by \(\bm{X}\)-support-compatibility that \(\text{supp}_{\bm{X}}(\alpha_{\text{other},i})\cap\text{supp}_{\bm{X}}(\alpha_{ j})=\emptyset\) whenever \(i\neq j\). We know by the same argument as in (5.4) that \(\text{supp}_{\bm{X}}(\alpha_{i}^{\prime})\subseteq\text{supp}_{\bm{X}}(\alpha_{ i})\) for all \(i\). Thus we can conclude that \(\text{supp}_{\bm{X}}(\alpha_{\text{other},i})\cap\text{supp}_{\bm{X}}(\alpha_{j}^{ \prime})=\emptyset\) whenever \(i\neq j\). So \(C_{\text{other}},C^{\prime}\) are \(\bm{X}\)-support-compatible. 

**Theorem 7** (Hardness of 2AMC with \(\bm{X}\)-firstness).: _2AMC is #P-hard, even for circuits that are smooth, decomposable, deterministic, and \(\bm{X}\)-first, and a constant-time elementwise mapping._

Proof.: Take a DNF \(\phi\) with terms \(\phi_{1},\dots,\phi_{m}\) over variables \(X_{1},\dots,X_{n}\). Let \(l=\lceil\log m\rceil+1\). Let us construct another DNF \(\phi^{\prime}\) with terms \(\phi_{1}^{\prime},\dots,\phi_{m}^{\prime}\) over variables \(X_{1}\dots,X_{n}\) and \(Y_{1},\dots,Y_{l+1}\) such that each \(\phi_{i}^{\prime}\) is the conjunction of \(\phi_{i}\), \(Y_{l+1}\) and a term over \(Y_{1},\dots,Y_{l}\) encoding a binary representation of \(i\). For example:

\[\phi_{5}^{\prime}=\phi_{5}\wedge Y_{1}\wedge-Y_{2}\wedge Y_{3}\wedge-Y_{4}\wedge \dots\wedge-Y_{l}\wedge Y_{l+1}.\]

Now, efficiently manipulate \(\phi^{\prime}\) to make it smooth [15]. The circuit \(\phi^{\prime}\) is thus smooth, decomposable, deterministic and trivially satisfies X-firstness (since the children to every \(\wedge\)-gate are literals). Take the probability semiring as \(\mathcal{S}_{\bm{X}}\), and \(\mathcal{S}_{\bm{Y}}=(\mathbb{N}^{2},+_{2},\times_{2},(0,0),(1,1))\) and \(\tau((n1,n2))=n1/n2\) (define \(0/0=0\)). Also, define \(\omega(x)=1\), and \(\omega^{\prime}(Y_{l+1}=0)=(0,1)\) and \(\omega^{\prime}(y)=1\) for all other literals. Then 2AMC counts the models of \(\phi\), which is #P-hard [46]:

\[2AMC=\sum_{\bm{x}}\frac{\sum_{\bm{y}:y_{l+1}=1}\phi^{\prime}(\bm{x},\bm{y})}{ \sum_{\bm{y}}\phi^{\prime}(\bm{x},\bm{y})}=\sum_{\bm{x}}\phi(\bm{x}),\]

where we assume \(0/0=0\). The last equality follows because the circuit is deterministic (hence \(\sum_{\bm{y}}\phi^{\prime}(\bm{x},\bm{y})=\max_{\bm{y}}\phi(\bm{x},\bm{y})\leq 1\)) and logically equivalent to \(\phi\) (i.e., \(\forall\bm{x}:\phi(\bm{x})=1\Leftrightarrow\exists\bm{y}:\phi^{\prime}(\bm{x}, \bm{y})=1\)). 

**Theorem 8** (Tractability Conditions for 2AMC).: _Every 2AMC instance is tractable in \(O(|C|)\) time for Boolean circuits that are smooth, decomposable, deterministic, \(\bm{X}\)-first, and \(\bm{X}\)-deterministic._Proof.: In Algorithm 5, we show the algorithm for 2AMC, which is simply a composition of aggregations, products, and elementwise mappings. To show tractability of 2AMC, we simply need to show that the input circuits to each of these operators satisfy the requisite tractability conditions.

We start with a smooth, decomposable, deterministic, \(\bm{X}\)-deterministic, and \(\bm{X}\)-first circuit \(C(\bm{X},\bm{Y})\).

* In line 1, we use the support mapping (Definition 6) from the Boolean to \(\mathcal{S}_{\bm{Y}}\) semiring; this is tractable by Corollary 1 due to determinism, and the output \(C_{\mathcal{S}_{\bm{Y}}}(\bm{X},\bm{Y})\) retains all the properties by Table 3.
* In line 2, we take the product of \(C_{\mathcal{S}_{\bm{Y}}}(\bm{X},\bm{Y})\) and \(\omega_{\bm{X}}(\bm{X})\). \(\omega_{\bm{X}}\) is omni-compatible, so we can apply PROD-CMP. This results in a circuit \(C_{\mathcal{S}_{\bm{Y}},\omega_{\bm{Y}}}(\bm{X},\bm{Y})\) that is smooth, decomposable and \(\bm{X}\)-first. \(\omega_{\bm{X}}(\bm{X})\) is both deterministic and \(\bm{X}\)-deterministic as it has no sum nodes, so this output circuit is also deterministic and \(\bm{X}\)-deterministic by (5.2).
* In line 3, we aggregate \(C_{\mathcal{S}_{\bm{Y}},\omega_{\bm{Y}}}(\bm{X},\bm{Y})\) over \(\bm{Y}\). The output circuit \(C_{\mathcal{S}_{\bm{Y}},\omega_{\bm{Y}}}(\bm{X})\) is smooth and decomposable. It is also \(\bm{X}\)-deterministic by (5.1), as \(\bm{Y}\cap\bm{X}=\emptyset\).

Figure 4: Illustration of PC computing hidden Markov model (HMM)

Since \(C_{\mathcal{S_{Y}},\omega_{Y}}(\bm{X},\bm{Y})\) satisfied \(\bm{X}\)-firstness, each product node \(\alpha=\alpha_{1}\times\alpha_{2}\) in that circuit had at most one child (say \(\alpha_{1}\)) with scope overlapping with \(\bm{Y}\). Then, in the product in the previous step, \(\alpha_{2}\) must have been produced through Lines 1-2 (otherwise it would contain some variable in \(\bm{Y}\)); thus it was produced by applying \([\cdot]\bm{g}_{\rightarrow\mathcal{S_{Y}}}\) to some node in \(C\). Thus, for any value \(\bm{v}\in\text{Assign}(\alpha_{2})\), \(p_{\alpha_{2}}\in\{0_{\mathcal{S_{Y}}},1_{\mathcal{S_{Y}}}\}\). So (Prod 0/1) is satisfied.
* In line 4, we apply the mapping \(\tau_{\mathcal{S_{Y}}\rightarrow\mathcal{S_{X}}}\) to \(C_{\mathcal{S_{Y}},\omega_{Y}}(\bm{X})\). This circuit is over \(\bm{X}\) and is \(\bm{X}\)-deterministic, i.e. deterministic and satisfies (Additive). As shown in the previous step, it also satisfies (Prod 0/1). Thus the mapping algorithm produces the correct result, producing a smooth, decomposable and determisitic circuit \(C_{\mathcal{S_{X}},\omega_{Y}}(\bm{X})\) as output.
* In line 5, we take the product of \(C_{\mathcal{S_{X}},\omega_{Y}}(\bm{X})\) with \(\omega_{\bm{X}}(\bm{X})\). \(\omega_{\bm{X}}\) is omni-compatible so we can apply PROD-CMP, producing a circuit \(C_{\mathcal{S_{X}},\omega_{Y},\omega_{\bm{X}}}\) that is smooth and decomposable (and also deterministic).
* Finally, we aggregate \(C_{\mathcal{S_{X}},\omega_{Y},\omega_{\bm{X}}}(\bm{X})\) over \(\bm{X}\), producing a scalar.

**Theorem 9** (Exponential Separation).: _Given sets of variables \(\bm{X}=\{X_{1},...,X_{n}\},\bm{Y}=\{Y_{1},...,Y_{n}\}\), there exists a smooth, decomposable and \(\bm{X}\)-deterministic circuit \(C\) of size \(poly(n)\) such that the smallest smooth, decomposable, and \(\bm{X}\)-first circuit \(C^{\prime}\) such that \(p_{C}\equiv p_{C^{\prime}}\) has size \(2^{\Omega(n)}\)._

Proof.: Consider representing the distribution given by a hidden Markov model (HMM) over (hidden) variables \(X_{\leq n}=\{X_{1},...,X_{n}\}\) and (observed) variables \(Y_{\leq n}=\{Y_{1},...,Y_{n}\}\), as depicted in Figure 3(a). Figure 3(b) shows a structured decomposable circuit that computes the hidden Markov model distribution, where the components \(C_{i}(j)\) have scope \(\{X_{i},Y_{i}\}\). The corresponding \(\text{tree/scope-decomposition}\) (with nodes notated using their scopes) is shown in Figure 3(c). It can easily be checked that the circuit is \(X_{\leq n}\)-deterministic, and that the circuit size is linear in \(n\).

It remains to show that the smallest \(X_{\leq n}\)-first and \(X_{\leq n}\)-deterministic circuit computing the HMM distribution is exponential in size. Explicitly, we will choose a HMM such that the emission distribution is given by \(p(Y_{i}|X_{i})=\mathds{1}_{Y_{i}=X_{i}}\). Then we have that \(p_{C^{\prime}}(x_{\leq n},Y_{\leq n})=p_{C^{\prime}}(x_{\leq n})p_{C^{\prime}} (Y_{\leq n}|x_{\leq n})=p_{C^{\prime}}(x_{\leq n})\mathds{1}_{Y_{\leq n}=x_{ \leq n}}\), for any circuit \(C^{\prime}\) that expresses the distribution of the HMM.

Consider any such circuit \(C^{\prime}\). Then, let \(\bm{\alpha}=\{\alpha_{1},...,\alpha_{K}\}\) be the set of nodes with scope \(Y_{\leq n}\) in the circuit. We will need the following lemma:

**Lemma 2**.: _For any value \(x_{\leq n}\) of \(X_{\leq n}\), there exists constants \(c_{1},..,c_{K}\in\mathbb{R}^{\geq 0}\) such that:_

\[p_{C^{\prime}}(x_{\leq n},Y_{\leq n})\equiv\sum_{k=1}^{K}c_{k}p_{\alpha_{k}}(Y _{\leq n})\] (6)

In other words, the output of the circuit is a linear function of the nodes with scope \(Y_{\leq n}\).

Proof.: We show this proof by bottom-up induction (child before parent), for the set of nodes whose scope _contains_\(Y_{\leq n}\):

* **Input node**: If the scope is \(Y_{\leq n}\), then it must be some node \(\alpha_{k}\in\bm{\alpha}\); then we take \(c_{k}=1\) and \(c_{k^{\prime}}=0\) for all \(k^{\prime}\neq k\).
* **Sum node**: By smoothness, all the children must have the same scope (containing \(Y_{\leq n}\)). The sum node is then just a linear combination of its children, so the result holds by the inductive hypothesis.
* **Product node**\(P\): Let \(P_{1},P_{2}\) be the children of \(P\). By \(X_{\leq n}\)-firstness, either both children are pure (have scope entirely contained in \(X_{\leq n}\) or \(Y_{\leq n}\)), or one of them is pure, and the scope of the other one (say \(P_{1}\)) contains \(Y_{\leq n}\). In the first case, if there is exactly one node (say \(P_{1}\)), with scope contained in \(Y_{\leq n}\), then it must have scope exactly \(Y_{\leq n}\). Then we have that: \[p_{P}(x_{\leq n},Y_{\leq n})=p_{P_{1}}(Y_{\leq n})p_{P_{2}}(x_{\leq n}\cap \text{vars}(P_{2}))\]\(p_{P_{2}}(x_{\leq n}\cap\text{vars}(P_{2}))\) here is a constant, so by the inductive hypothesis we are done. If both nodes have scope contained in \(Y_{\leq n}\), then \(P\) is in \(\bm{\alpha}\), say \(P=\alpha_{k}\). Then we set \(c_{k}=1\) and \(c_{k^{\prime}}=0\) for \(k^{\prime}\neq k\). In the second case, we have that: \[p_{P}(x_{\leq n},Y_{\leq n})=p_{P_{1}}(x_{\leq n}\cap\text{vars}(P_{1}),Y_{\leq n })p_{P_{2}}(x_{\leq n}\cap\text{vars}(P_{2}))\] Here \(p_{P_{2}}(x_{\leq n}\cap\text{vars}(P_{2}))\) is a constant, so by the inductive hypothesis we are done. Note that \(X_{\leq n}\)-firstness was crucial to avoid the case where a product has two mixed nodes (containing variables in \(X_{\leq n}\) and \(Y_{\leq n}\)) as children.

For any \(k=1,..,K\), define \(v_{k}\in\mathbb{R}^{2^{n}}_{\geq 0}\) to be the vector with entries \(v_{k,i}=\alpha_{k}(i)\) (where we interpret \(i\) as a value of \(Y_{\leq n}\)). Then we have the following Corollary:

**Corollary 2**.: _The set of vectors \(\{v_{1},...,v_{K}\}\) forms a spanning set for \(\mathbb{R}^{2^{n}}\)._

Proof.: By the Lemma and the fact that \(C^{\prime}\) expresses the HMM distribution, we have that for any \(x_{\leq n}\in\{0,1\}^{n}\), there exists \(c_{1},..,c_{k}\in\mathbb{R}^{\geq 0}\) such that:

\[p_{C^{\prime}}(x_{\leq n})\mathds{1}_{Y_{\leq n}=x_{\leq n}}\equiv\sum_{k=1}^{ K}c_{k}p_{\alpha_{k}}(Y_{\leq n})\]

Rearranging, and writing in vector form, we have:

\[e_{x_{\leq n}}=\sum_{k=1}^{K}\frac{c_{k}}{p_{C^{\prime}}(x_{\leq n})}v_{k}\]

where \(e_{x_{\leq n}}\in\mathbb{R}^{2^{n}}_{\geq 0}\) is the standard basis vector corresponding to the value \(x_{\leq n}\). Thus \(\{v_{1},...,v_{K}\}\) is a spanning set. 

Any spanning set for \(\mathbb{R}^{2^{n}}\) must contain at least \(2^{n}\) elements. Thus, \(K\geq 2^{n}\), and the circuit \(C^{\prime}\) must be exponentially sized. 

One might attempt to remedy the situation by replacing \(\bm{X}\)-firstness with \(\bm{X}\)-determinism. For the general case, that however is insufficient:

**Theorem 10** (Hardness of 2AMC with \(\bm{X}\)-determinism).: _2AMC is #P-hard even for decomposable, smooth, deterministic and \(\bm{X}\)-deterministic circuits, and a constant-time elementwise transformation function._

Proof.: By reduction from the counting version of number partitioning: Given positive integers \(k_{1},\ldots,k_{n}\), count the number of index sets \(S\subseteq\{1,\ldots,n\}\) such that \(\sum_{i\in S}k_{i}=\sum_{i\not\in S}k_{i}=c\). That problem is known to be #P-hard [47]. Define \(\phi=\bigwedge_{i=1}^{n}(X_{i}\Leftrightarrow Y_{i})\). Then \(\phi\) is a deterministic, \(\bm{X}\)-deterministic, decomposable and smooth circuit.4 Let the inner labeling function be \(\omega^{\prime}(y_{i})=k_{i}/c\) and \(\omega^{\prime}(\neg y_{i})=1\). Then for a fixed configuration \(x\) of the variables \(X=\{X_{1},\ldots,X_{n}\}\), we have exactly one model for \(\phi\), whose value is \(\otimes_{i:x_{i}=1}k_{i}/c\). If we select the inner semiring so that \(\otimes\) is addition (e.g., the max tropical semiring or log semiring), then the inner AMC problem returns \(\sum_{i:x_{i}=1}k_{i}/c\), which equals \(1\) iff \(S=\{i:x_{i}=1\}\) is a solution to the number partitioning instance. Now, define the outer labeling function to be \(\omega=1\), and let the transformation function be \(\tau(s)=1\) if \(s=1\) and \(\tau(s)=0\) otherwise. Then the 2AMC problem with the probability semiring as outer semiring counts the number of solutions of the number partitioning instance. 

Footnote 4: While this circuit is not \(\bm{X}\)-first, it does satisfy a property known as \(\bm{X}\)-firstness modulo definability [29]; thus that property is insufficient for 2AMC even together with \(\bm{X}\)-determinism.

## Appendix B Case Studies

In this section, we provide more details about the compositional inference problems in Table 2 (reproduced in Table 4) for convenience, and prove the tractability conditions for each (Theorem 6). For all of them, we assume that we are given a Boolean formula represented as a circuit. That would usually come from knowledge compilation from some source language such as Bayesian Networks [9] or probabilistic logic programs [24]; our results thus show what properties the compiled circuit must have in order a query of interest to be tractable. Note that the problems are generally computationally hard [19, 10] on the source language, which means there do not exist compact circuits satsifying the properties in the worst-case.

**Theorem 6** (Tractability of Compositional Queries).: _The results in Table 2 hold._

### 2AMC Queries

Firstly, we consider instances of 2AMC queries. Recall the general form of a 2AMC query. Given a partition of the variables \(\bm{V}=(\bm{X},\bm{Y})\), a Boolean function \(\phi(\bm{X},\bm{Y})\), _outer_ and _inner_ semirings \(\mathcal{S}_{\bm{X}},\mathcal{S}_{\bm{Y}}\), labeling functions \(\omega_{\bm{Y}}(\bm{Y})=\bigotimes_{Y_{i}\in\bm{Y}}\omega_{\bm{Y},i}(Y_{i})\) over \(\mathcal{S}\) and \(\omega_{\bm{X}}(\bm{X})=\bigotimes_{X_{i}\in\bm{X}}\omega_{\bm{X},i}(X_{i})\) over \(\mathcal{S}^{\prime}\), and an elementwise mapping \(\tau_{\mathcal{S}_{\bm{Y}}\to\mathcal{S}_{\bm{X}}}:\mathcal{S}_{\bm{Y}}\to \mathcal{S}_{\bm{X}}\), the 2AMC problem is given by:

\[\bigoplus_{\bm{x}}\biggl{(}\tau_{\mathcal{S}_{\bm{Y}}\to\mathcal{S}_{\bm{X}}} \biggl{(}\bigoplus_{\bm{y}}[\phi(\bm{x},\bm{y})]\|_{\mathcal{B}\to\mathcal{S}_ {\bm{Y}}}\otimes\omega(\bm{y})\biggr{)}\otimes\omega^{\prime}(\bm{x})\biggr{)}\] (1, revisited)

By Theorem 8, any 2AMC problem is tractable if \(\phi\) is given as a smooth, decomposable, deterministic, \(\bm{X}\)-deterministic, and \(\bm{X}\)-first circuit \(C\). However, in some instances, we can relax these conditions, as we show shortly.

#### b.1.1 Marginal MAP

In the _Marginal Maximum A Posteriori inference_ (MMAP), we are given a Boolean function \(\phi(\bm{V})\), a (unnormalized) fully factorized distribution \(p(\bm{V})=\prod_{i}p_{i}(V_{i})\), a partition \(\bm{X}\cup\bm{Y}=\bm{V}\) and some evidence \(\bm{e}\) on \(\bm{E}\subset\bm{V}\). The goal is to compute the probability of the maximum probability assignment of \(\bm{X}\) consistent with \(\bm{e}\):

\[\max_{\bm{x}}p(\bm{X}=\bm{x},\bm{E}=\bm{e})=\max_{\bm{x}}\sum_{\bm{y}|=\phi( \bm{x},\bm{Y})\wedge\bm{e}}\prod_{i}p_{i}(v_{i}).\]

To cast it as a 2AMC problem, take the inner semiring \(\mathcal{S}_{\bm{Y}}\) to be the probability semiring and define the inner labelling function to assign \(\omega_{\bm{Y}}(Y_{i})=0\) if \(Y_{i}\in\bm{E}\) and \(Y_{i}\) is _in_consistent with \(\bm{e}\) and \(\omega_{\bm{Y}}(Y_{i})=p_{i}(Y_{i})\) otherwise. The outer semiring is the \((\max,\cdot)\) semiring with labeling function \(\omega_{\bm{X}}(X_{i})=1\). The elementwise mapping function \(\tau_{\mathcal{S}_{\bm{Y}}\to\mathcal{S}_{\bm{X}}}(a)=a\) is the identity function.

The proof of the tractability conditions follows Theorem 8, except that we note that the mapping function \(\tau_{\mathcal{S}_{\bm{Y}}\to\mathcal{S}_{\bm{X}}}\) from the outer to inner semiring satsifies (Multiplicative). As such, we do not need the (Prod 0/1) circuit property, which was the reason we needed the \(\bm{X}\)-firstness condition.

\begin{table}
\begin{tabular}{l l l l} \hline \hline  & **Problem** & **Tractability Conditions** & **Complexity** \\ \hline \multirow{3}{*}{**2AMC**} & PASP (Max-Credal)\({}^{*}\) & Sm, Dec, \(\bm{X}\)-Det & \(O(|C|)\) \\  & PASP (MaxEnt)\({}^{*}\), MMAP & Sm, Dec, Det, \(\bm{X}\)-Det & \(O(|C|)\) \\  & SDP\({}^{*}\) & Sm, Dec, Det, \(\bm{X}\)-Det, \(\bm{X}\)-First & \(O(|C|)\) \\ \hline \multirow{3}{*}{**Causal Inference**} & Backdoor\({}^{*}\) & Sm, Dec, SD, \((\bm{X}\cup\bm{Z})\)-Det & \(O(|C|^{2})\) \\  & Backdoor\({}^{*}\) & Sm, Dec, \(\bm{Z}\)-Det, \((\bm{X}\cup\bm{Z})\)-Det & \(O(|C|)\) \\ \cline{2-4}  & Frontdoor\({}^{*}\) & Sm, Dec, SD, \(\bm{X}\)-Det, \((\bm{X}\cup\bm{Z})\)-Det & \(O(|C|^{2})\) \\ \hline \multirow{2}{*}{**Other**} & MFE\({}^{*}\) & Sm, Dec, \(\bm{H}\)-Det, \(\bm{I}^{*}\)â€“Det, \((\bm{H}\cup\bm{I}^{*})\)-Det & \(O(|C|)\) \\  & Reverse-MAP & Sm, Dec, \(\bm{X}\)-Det & \(O(|C|)\) \\ \hline \hline \end{tabular}
\end{table}
Table 4: Tractability Conditions and Complexity for Compositional Inference Problems. We denote new results with an asterisk.

#### b.1.2 Probabilistic Answer Set Programming (PASP)

The _Probabilistic Answer Set Programming Inference_ (PASP) query takes a Boolean formula \(\phi(\bm{V})\), a partition \(\bm{X}\cup\bm{Y}=\bm{V}\), a (unnormalized) fully factorized distribution \(p(\bm{X})=\prod_{i}p(X_{i})\), and query variable and value \(\{Q=q\}\), for some \(Q\in\bm{V}\). The goal is to compute:

\[p(Q=q)=\sum_{\bm{x}}\left(\prod_{i}p(X_{i})\right)\sum_{\bm{y}\models\phi(\bm{x },\bm{Y})\wedge q}p^{*}(\bm{y}|\bm{x}).\]

The function \(p^{*}(\bm{Y}|\bm{X})\) depends on the semantics adopted. Let \(\text{mod}(\bm{Y}|\bm{X}):=\{\bm{y}:\phi(\bm{X},\bm{y})\}\) be the set of assignments of \(\bm{Y}\) such that \(\phi(\bm{X},\cdot)\) is true. In the _Maximum Entropy Semantics_ (MaxEnt) [6, 51, 45], one distributes the probability mass \(p(\bm{X})\) uniformly over the models of \(\phi\) consistent with \(\bm{X}\), i.e. \(p^{*}(\bm{y}|\bm{X})=\frac{1}{\mid\text{mod}(\bm{Y}|\bm{X})\mid}\). On the other hand, in the _Credal Semantics_[33, 14] (Max-Credal), one places all probability mass \(p(\bm{X})\) on some assignment \(\bm{y}\) of \(\bm{Y}\) consistent with \(\bm{X}\) and \(q\). To obtain an upper bound on the query probability regardless of which \(\bm{y}\) is chosen, one sets \(p^{*}(\bm{y}|\bm{X}):=1\) for all \(\bm{y}\) if there exists an assignment \(\bm{Y}\models\phi(\bm{X},\bm{Y})\wedge q\), and \(p^{*}(\bm{Y}|\bm{X})=0\) otherwise.

The 2AMC formulation of the problem uses the probability semiring as outer semiring \(\mathcal{S}_{\bm{X}}\), with labeling function \(\omega_{\bm{X}}(X_{i})=p(X_{i})\) for \(X_{i}\in\bm{X}\).

* In the (MaxEnt) semantics, for the inner semiring, we take as the semiring of pairs of naturals \(\mathcal{S}_{\bm{Y}}=(\mathbb{N}^{2},+,\cdot,(0,0),(1,1))\), with coordinatewise addition and multiplication. The inner labeling function sets \(\omega_{\bm{Y}}(Q)=(\mathds{1}_{Q=q},1)\), and sets \(\omega_{\bm{Y}}(Y_{i})=(1,1)\) for all other variables \(Y_{i}\in\bm{Y}\). The mapping function is defined by \(\tau_{\mathcal{S}_{\bm{Y}}\to\mathcal{S}_{\bm{X}}}((a,b))=a/b\) (with \(0/0=0\)).
* In the (Max-Credal) semantics, we simply set the inner semiring to be the Boolean semiring \(\mathcal{S}_{\bm{Y}}=\mathcal{B}\). The inner labeling function sets \(\omega_{\bm{Y}}(Q)=\begin{cases}\top&\text{if }Q=q\\ \bot&\text{otherwise}\end{cases}\), and sets \(\omega_{\bm{Y}}(Y_{i})=\top\) for all other variables \(Y_{i}\in\bm{Y}\). The mapping function is defined by \(\tau_{\mathcal{S}_{\bm{Y}}\to\mathcal{S}_{\bm{X}}}(a)=\llbracket a\rrbracket_{ \mathcal{S}_{\bm{Y}}\to\mathcal{S}_{\bm{X}}}\).

As with marginal MAP, we can see that in both cases, the mapping function \(\tau_{\mathcal{S}_{\bm{Y}}\to\mathcal{S}_{\bm{X}}}\) satisfies \(\tau_{\mathcal{S}_{\bm{Y}}\to\mathcal{S}_{\bm{X}}}((a,b)\otimes(c,d))=\tau_{ \mathcal{S}_{\bm{Y}}\to\mathcal{S}_{\bm{X}}}((a\cdot c,b\cdot d))=\frac{a\cdot c }{b,d}=\frac{a}{b}\cdot\frac{c}{d}=\tau_{\mathcal{S}_{\bm{Y}}\to\mathcal{S}_{ \bm{X}}}(a,b)\cdot\tau_{\mathcal{S}_{\bm{Y}}\to\mathcal{S}_{\bm{X}}}(c,d)= \tau_{\mathcal{S}_{\bm{Y}}\to\mathcal{S}_{\bm{X}}}(a,b)\otimes\tau_{\mathcal{S} _{\bm{Y}}\to\mathcal{S}_{\bm{X}}}(c,d)\) (this holds also if \((a,b)=(0,0)\) and/or \((c,d)=(0,0)\)). Meanwhile, for (Max-Credal) we have \(\tau_{\mathcal{S}_{\bm{Y}}\to\mathcal{S}_{\bm{X}}}(a\otimes b)=\tau_{ \mathcal{S}_{\bm{Y}}\to\mathcal{S}_{\bm{X}}}(a\wedge b)=\llbracket a\wedge b \rrbracket_{\mathcal{S}_{\bm{Y}}\to\mathcal{S}_{\bm{X}}}=\llbracket a\rrbracket_ {\mathcal{S}_{\bm{Y}}\to\mathcal{S}_{\bm{X}}}\cdot\llbracket b\rrbracket_{ \mathcal{S}_{\bm{Y}}\to\mathcal{S}_{\bm{X}}}=\tau_{\mathcal{S}_{\bm{Y}}\to \mathcal{S}_{\bm{X}}}(a)\cdot\tau_{\mathcal{S}_{\bm{Y}}\to\mathcal{S}_{\bm{X}}}(b )=\tau_{\mathcal{S}_{\bm{Y}}\to\mathcal{S}_{\bm{X}}}(a)\otimes\tau_{\mathcal{S} _{\bm{Y}}\to\mathcal{S}_{\bm{X}}}(b)\).

For the (Max-Credal) semantics, we note additionally since \(\mathcal{S}_{\bm{Y}}\) is just the Boolean semiring, we do _not_ need determinism in Line 1 of Algorithm 5. So the only conditions required are smoothness, decomposability, and \(\bm{X}\)-determinism.

#### b.1.3 Same-Decision Probability

In the _Same Decision Probability_ (SDP) query [37], we are given a Boolean formula \(\phi(\bm{V})\), a fully factorized distribution \(p(\bm{V})=\prod_{i}p(V_{i})\), a partition \(\bm{X},\{Y\}\) of \(\bm{V}\), a query \(\{Y=y\}\), some evidence \(\bm{e}\) on a subset \(\bm{E}\subseteq\bm{X}\) of variables and a threshold value \(T\in(0,1]\). The goal is to compute a confidence measure on some threshold-based classification made with the underlying probabilistic model:

\[\sum_{\bm{x}}p(\bm{x}|\bm{e})\mathds{1}_{p(Y=y|\bm{x},\bm{e})\geq T},\]

To cast this as a 2AMC instance, we use the inner semiring \(\mathcal{S}^{\prime}=(\mathbb{R}^{2}_{\geq 0},+,\cdot,(0,0),(1,1))\), with coordinate-wise addition and multiplication. The inner labeling function assigns \(\omega_{\bm{Y}}(Y)=(p(Y)\mathds{1}_{Y=y},p(Y))\). The outer semiring is the probability semiring and the mapping \(\tau_{\mathcal{S}_{\bm{Y}}\to\mathcal{S}_{\bm{X}}}\) from inner to outer semirings is \(\tau_{\mathcal{S}_{\bm{Y}}\to\mathcal{S}_{\bm{X}}}((a,b))=\llbracket a\geq bT\rrbracket\). Last, the outer labeling function assigns \(\omega_{\bm{X}}(X_{i})=\mathds{1}_{X_{i}\models\bm{e}}\) if \(X_{i}\in\bm{E}\), and \(\omega_{\bm{X}}(X_{i})=p(X_{i})\) otherwise.

Unlike marginal MAP and PASP inference, there is no special structure in SDP that allows us to relax the general tractability conditions for 2AMC. However, it is still a 2AMC instance, and we have the tractability conditions from Theorem 8. In particular this justifies the use of \(\bm{X}\)-constrained sentential decision diagrams for this problem.

### Causal Inference

In Section 4.2, we discussed computing causal interventional distributions. In particular, in the backdoor and frontdoor cases, we had the following formulae:

\[p(\bm{y}|do(\bm{x}))=\sum_{\bm{z}}p(\bm{z})p(\bm{y}|\bm{x},\bm{z}),\] (2)

\[p(\bm{y}|do(\bm{x}))\!=\!\sum_{\bm{z}}p(\bm{z}|\bm{x})\sum_{\bm{x}^{\prime}}p( \bm{x}^{\prime})p(\bm{y}|\bm{x^{\prime}},\bm{z}).\] (3)

#### b.2.1 Backdoor query

The backdoor query can be written as a compositional query as follows:

\[\texttt{BACKDOOR}(p;\bm{x},\bm{y}):=\bigoplus_{\bm{z}}\Bigl{(}\Bigl{(}\bigoplus _{\bm{x},\bm{y}}p(\bm{v})\Bigr{)}\otimes p(\bm{v})\otimes\tau_{-1}\Bigl{(} \bigoplus_{\bm{y}}p(\bm{v})\Bigr{)}\Bigr{)}.\] (7)

where \(\bm{V}=(\bm{X},\bm{Y},\bm{Z})\), and \(\tau_{-1}(a)=\begin{cases}a^{-1}&\text{if }a\neq 0\\ 0&\text{if }a=0\end{cases}\). Note that \(\tau_{-1}\) satisfies (Multiplicative), and so for this mapping to be tractable we just need the circuit it is applied to to be deterministic.

Assume that \(p(\bm{V})\) is given as a smooth, structured decomposable, and \((\bm{X}\cup\bm{Z})\)-deterministic circuit (over the probabilistic semiring). We now show that this query is tractable, by showing that each operator in the composition is tractable. For readability, we label each circuit constructed with the function that it represents \(\boxed\).

* \(\boxed{p(\bm{X},\bm{Z})}\)\(C_{1}(\bm{X},\bm{Z}):=\texttt{AGG}(C,\bm{Y})\) is tractable by smoothness and decomposability. By (5.1) in Table 3, since \(\bm{Y}\cap(\bm{X}\cup\bm{Z})=\emptyset\), \(C_{1}\) is \((\bm{X}\cup\bm{Z})\)-deterministic (i.e. deterministic).
* \(\boxed{p(\bm{X},\bm{Z})}\)\(C_{2}(\bm{X},\bm{Z}):=\texttt{MAPPING}(C_{1},\tau_{-1})\) is tractable since \(C_{1}\) is deterministic.
* \(\boxed{p(\bm{Y}|\bm{X},\bm{Z})}\)\(C_{3}(\bm{X},\bm{Y},\bm{Z}):=\texttt{PROD-SCMP}(C(\bm{X},\bm{Y},\bm{Z}),C_{2}( \bm{X},\bm{Z}))\). \(C\) is \((\bm{X}\cup\bm{Z})\)-support-compatible with itself as it is \((\bm{X}\cup\bm{Z})\)-deterministic \(\implies\)\(C\) is also \((\bm{X}\cup\bm{Z})\)-support-compatible with \(C_{1}\) by (5.9) \(\implies\)\(C\) is also \((\bm{X}\cup\bm{Z})\)-support-compatible with \(C_{2}\) by (5.11). As \(C\) and \(C_{2}\) share variables \((\bm{X}\cup\bm{Z})\), this means they are support-compatible. Thus this product is tractable in linear time.
* \(\boxed{p(\bm{Z})}\)\(C_{4}(\bm{Z}):=\texttt{AGG}(C,\bm{X}\cup\bm{Y})\) is tractable by smoothness and decomposability.
* \(\boxed{p(\bm{Z})p(\bm{Y}|\bm{X},\bm{Z})}\)\(C_{5}(\bm{X},\bm{Y},\bm{Z}):=\texttt{PROD-CMP}(C_{4},C_{3})\). \(C\) is \(\bm{V}\)-compatible with itself (structured decomposable) \(\implies\)\(C\) is \(\bm{Z}\)-compatible with itself by Proposition 1\(\implies\)\(C\) is also \(\bm{Z}\)-compatible with \(C_{4}\) by (5.5) \(\implies\)\(C_{4}\) is \(\bm{Z}\)-compatible with \(C_{1}\) by (5.5) \(\implies\)\(C_{4}\) is \(\bm{Z}\)-compatible with \(C_{2}\) by (5.8) \(\implies\)\(C_{4}\) is \(\bm{Z}\)-compatible with \(C_{3}\) by (5.6). Since \(C_{4}\) and \(C_{3}\) share variables \(\bm{Z}\), this means they are compatible and so this product is tractable in quadratic time.
* \(\boxed{\sum_{\bm{z}}p(\bm{z})p(\bm{Y}|\bm{X},\bm{z})}\)\(C_{6}(\bm{X},\bm{Y})=\texttt{AGG}(C_{5},\bm{Z})\) is tractable by smoothness and decomposability.

Thus, we have recovered the tractability conditions derived by [49], with the same complexity of \(O(|C|^{2})\) (induced by the compatible product to construct \(C_{5}\)). However, we also have an alternative tractability condition. Suppose that \(C\) were additionally \(\bm{Z}\)-deterministic, but not necessarily structured decomposable. Then we could replace the derivation of \(C_{5}\) above with the following:

* \(\boxed{p(\bm{Z})p(\bm{Y}|\bm{X},\bm{Z})}\)\(C_{5}(\bm{X},\bm{Y},\bm{Z}):=\texttt{PROD-SCMP}(C_{4},C_{3})\). \(C\) is \(\bm{Z}\)-support-compatible with itself as it is \(\bm{Z}\)-deterministic \(\implies\)\(C\) is also \(\bm{Z}\)-support-compatible with \(C_{4}\) by (5.9) \(\implies\)\(C_{4}\) is \(\bm{Z}\)-support-compatible with \(C_{1}\) by (5.9) \(\implies\)\(C_{4}\) is \(\bm{Z}\)-compatible with \(C_{2}\) by (5.11) \(\implies\)\(C_{4}\) is \(\bm{Z}\)-compatible with \(C_{3}\) by (5.10). Since \(C_{4}\) and \(C_{3}\) share variables \(\bm{Z}\), this means they are compatible and so this product is tractable in linear time.

In this case, the overall complexity is also reduced to \(O(|C|)\).

#### b.2.2 Frontdoor query

Now, consider the frontdoor case. In this case, we have the following compositional query:

\[\texttt{FRONTDOOR}(p;\bm{x},\bm{y},\bm{z})=\bigoplus_{\bm{z}}\Bigl{(}\Bigl{(} \bigoplus_{\bm{y}}p(\bm{v})\Bigr{)}\otimes\tau_{-1}\Bigl{(}\bigoplus_{\bm{y}, \bm{z}}p(\bm{v})\Bigr{)}\otimes\texttt{BACKDOOR}(p;\bm{z},\bm{y})\Bigr{)}\] (8)

Assume that \(p(\bm{V})\) is given as a smooth, structured decomposable, \(\bm{X}\)-deterministic, and \((\bm{X}\cup\bm{Z})\)-deterministic circuit (over the probabilistic semiring). We continue the analysis from the backdoor case:

* \(p(\bm{X})\)\(C_{7}(\bm{X}):=\texttt{AGG}(C,\bm{Y}\cup\bm{Z})\) is tractable by smoothness and decomposability. By (5.1) in Table 3, since \((\bm{Y}\cup\bm{Z})\cap\bm{X}=\emptyset\), \(C_{7}\) is \(\bm{X}\)-deterministic (i.e. deterministic).
* \(\frac{1}{p(\bm{X})}\)\(C_{8}(\bm{X}):=\texttt{MAPPING}(C_{7},\tau_{-1})\) is tractable since \(C_{7}\) is deterministic.
* \(p(\bm{Z}|\bm{X})\)\(C_{9}(\bm{X},\bm{Z}):=\texttt{PROD-SCMP}(C_{8},C_{1})\). \(C\) is \(\bm{X}\)-support-compatible with itself as it is \(\bm{X}\)-deterministic \(\implies\)\(C\) is \(\bm{X}\)-support-compatible with \(C_{1}\) by (5.9) \(\implies\)\(C_{1}\) is \(\bm{X}\)-support-compatible with \(C_{7}\) by (5.9) \(\implies\)\(C_{1}\) is \(\bm{X}\)-support-compatible with \(C_{8}\) by (5.11). Thus this product is tractable in linear time.
* \(\left\lceil\sum_{\bm{x}}p(\bm{x})p(\bm{Y}|\bm{x},\bm{Z})\right\rceil C_{10}( \bm{Y},\bm{Z})\). This is just like \(C_{6}\), but with variables \(\bm{X}\) and \(\bm{Z}\) swapped. Thus it is tractable for a smooth, \(\bm{X}\)-deterministic and \((\bm{X}\cup\bm{Z})\)-deterministic circuit in linear time.
* \(p(\bm{Z}|\bm{X})\sum_{\bm{x}^{\prime}}p(\bm{x}^{\prime})p(\bm{Y}|\bm{x^{ \prime}},\bm{Z})\)\(C_{11}(\bm{X},\bm{Y},\bm{Z}):=\texttt{PROD-CMP}(C_{9},C_{10})\). We can chain applications of (5.5), (5.7) and (5.8) in a similar way to the other steps to show that \(C_{9},C_{10}\) are \(\bm{Z}\)-compatible (i.e. compatible), so this product is tractable in quadratic time.
* \(\left\lceil\sum_{\bm{z}}p(\bm{z}|\bm{X})\sum_{\bm{x}^{\prime}}p(\bm{x^{ \prime}})p(\bm{Y}|\bm{x^{\prime}},\bm{z})\right\rceil C_{12}(\bm{X},\bm{Y}):= \texttt{AGG}(C_{11};\bm{Z})\). This is tractable by smoothness and decomposability.

Thus, this algorithm has complexity \(O(|C|^{2})\), as opposed to the \(O(|C|^{3})\) complexity algorithm in [49]. The key difference is that we exploit support compatibility for a linear time product when constructing \(C_{10}\).

### Other Problems

#### b.3.1 Most Frugal Explanation

In [31], the most frugal explanation (MFE) query was introduced. Given a partition of variables \(\bm{V}\) into \((\bm{H},\bm{I}^{+},\bm{I}^{-},\bm{E})\), some evidence \(\bm{e}\in\text{Assign}(\bm{E})\), and a probability distribution \(p(\bm{V})\), the MFE query asks for the following:

\[\max_{\bm{h}}\sum_{\bm{i}^{-}}\mathds{1}[\bm{h}\in\arg\max_{\bm{h}^{\prime}}p (\bm{h}^{\prime},\bm{i}^{-},\bm{e})]\] (9)

In words, we want the explanation (assignment to \(\bm{H}\)) that is the most probable for the most number of assignments to \(\bm{I}^{-}\), when \(\bm{I}^{+}\) is marginalized out. We can rewrite as follows:

\[\max_{\bm{h}}\sum_{\bm{i}^{-}}\mathds{1}\left[\frac{p(\bm{h},\bm{i}^{-},\bm{e })}{\max_{\bm{h}^{\prime}}p(\bm{h}^{\prime},\bm{i}^{-},\bm{e})}=1\right]\] (10)

This can be written as a compositional query as follows.

\[\bigoplus_{\bm{h}}\tau_{\mathcal{S}^{\prime\prime\prime}\to\mathcal{S}^{ \prime}}\bigoplus_{i^{-}}\tau_{\mathcal{S}^{\prime\prime}\to\mathcal{S}^{ \prime\prime\prime}}\left(\tau_{-1}\left(\tau_{\mathcal{S}^{\prime}\to \mathcal{S}^{\prime\prime}}\left(\bigoplus_{\bm{h}^{\prime}}\tau_{\mathcal{S} \to\mathcal{S}^{\prime}}(p(\bm{h}^{\prime},\bm{i}^{-},\bm{e}))\right)\right) \otimes p(\bm{h},\bm{i}^{-},\bm{e})\right)\] (11)

where \(\mathcal{S}\) is the probability semiring, \(\mathcal{S}^{\prime}\) is the \((\max,\cdot)\)-semiring, \(\mathcal{S}^{\prime\prime}\) is \(([0,1],+,\cdot,0,1)\) (i.e. the probability semiring with domain \([0,1]\)), and \(\mathcal{S}^{\prime\prime\prime}\) is the counting semiring \((\mathbb{N},+,\cdot,0,1)\), and the mapping functions are defined as follows:* \(\tau_{S\to S^{\prime}}(a)=a\)
* \(\tau_{S^{\prime}\to S^{\prime\prime}}(a)=a\)
* \(\tau_{-1}(a)=\begin{cases}a^{-1}&\text{if }a\neq 0\\ 0&\text{if }a=0\end{cases}\)
* \(\tau_{S^{\prime\prime}\to S^{\prime\prime}}(a)=\mathds{1}_{a=1}\)
* \(\tau_{S^{\prime\prime\prime}\to S^{\prime}}(a)=a\)

Suppose we are given a probabilistic circuit representing \(p(\bm{H},\bm{I}^{-},\bm{e})\). While this query appears extremely intimidating at first glance, we note that the only operators we need to consider are the mappings and single product. Note that all of these mappings satisfy (Multiplicative) (\(\tau_{S^{\prime\prime}\to S^{\prime\prime\prime}}\) because the domain of \(\mathcal{S}^{\prime\prime}\) is \([0,1]\) so \(\tau_{S^{\prime\prime}\to S^{\prime\prime\prime}}(a\cdot b)=1\) iff \(a=b=1\)); thus the mappings are tractable if the input circuits are deterministic. By checking the scopes of the inputs to each mapping, we can see that \((\bm{H}\cup\bm{I}^{-})\)-determinism, \(\bm{I}^{-}\)-determinism, and \(\bm{H}\)-determinism suffices. This also enables tractability of the product in linear time by support compatibility.

No tractability conditions for exact inference for this query were previously known. While the motivation behind the MFE query is as a means of approximating marginal MAP, and so this exact algorithm is not practically useful in this case, this example illustrates the power of the compositional framework to tackle even very complex queries.

#### b.3.2 Reverse MAP

Recently, in [27], the reverse-MAP query was introduced, defined by:

\[\max_{\bm{X}}p(\bm{e}_{1}|\bm{X},\bm{e}_{2})\] (12)

where the variables are partitioned as \(\bm{V}=(\bm{E}_{1},\bm{E}_{2},\bm{X},\bm{H})\). In our compositional framework, this can be written as:

\[\bigoplus_{\bm{x}}\tau_{\mathcal{P}\to\mathcal{M}}\Big{(}\bigoplus_{\bm{h}}p( \bm{e}_{1},\bm{x},\bm{e}_{2},\bm{h})\otimes\tau_{-1}\big{(}\bigoplus_{\bm{h}, \bm{e}_{1}^{\prime}}p(\bm{e}_{1}^{\prime},\bm{x},\bm{e}_{2},\bm{h})\big{)} \Big{)}\] (13)

Here, the mapping \(\tau_{-1}\) is tractable if the circuit for \(p\) is \(\bm{X}\)-deterministic. Since \(p\) is \(\bm{X}\)-deterministic, it is \(\bm{X}\)-support-compatible with itself; chaining this with (5.9) and (5.11) in Table 3, the inputs to the product are \(\bm{X}\)-compatible; since they have scope \(\bm{X}\), this means the product is tractable by support-compatibility. The resulting circuit remains \(\bm{X}\)-deterministic (i.e. deterministic as the scope is \(\bm{X}\)), which means that the mapping \(\tau_{\mathcal{P}\to\mathcal{M}}\) from the probability to \((\max,\cdot)\) semiring is tractable. Thus, this query is tractable for smooth, decomposable and \(\bm{X}\)-deterministic circuits in linear time (same as derived by the authors).

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: The abstract and introduction reference the results in the rest of the paper. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: Yes, in the conclusion we discuss the fact that while our results provide simple and general sufficient tractability conditions, these are not necessary conditions. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes]Justification: Yes, assumptions are laid out in the statements of the results, and proofs are provided in the supplementary material. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [NA] Justification: This paper does not include experiments. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?Answer: [NA] Justification: This paper does not include experiments requiring code. Guidelines:

* The answer NA means that paper does not include experiments requiring code.
* Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [NA] Justification: This paper does not contain experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [NA] Justification: This paper does not contain experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors). * It should be clear whether the error bar is the standard deviation or the standard error of the mean. ** It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [NA] Justification: This paper does not contain experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: The paper does conform to the NeurIPS Code of Ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [No] Justification: This paper presents foundational research that is not tied to any particular application/deployment; there are no particular societal impacts that we feel need to be highlighted. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.

* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: The paper does not propose to release any data or models that would pose such a risk. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licensees for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [NA] Justification: This paper does not use existing assets. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.

* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: This paper does not release new assets. Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.