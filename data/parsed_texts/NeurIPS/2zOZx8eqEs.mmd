# Graph Agnostic Causal Bayesian Optimization

Sumantrak Mukherjee\({}^{1}\) Mengyan Zhang\({}^{2}\) Seth Flaxman\({}^{2}\) Sebastian Vollmer\({}^{1,3}\)

\({}^{1}\)Department of Data Science and its Applications, DFKI GmbH

\({}^{2}\)Department of Computer Science, University of Oxford

\({}^{3}\)Department of Computer Science, University of Kaiserslautern-Landau

Equal Contribution

###### Abstract

We study the problem of globally optimising a target variable of an _unknown_ causal graph on which a sequence of soft or hard interventions can be performed. The problem of optimising the target variable associated with a causal graph is formalised as Causal Bayesian Optimisation (CBO). We study the CBO problem under the _cumulative regret_ objective with unknown causal graphs for two settings, namely structural causal models with hard interventions and function networks with soft interventions. We propose Graph Agnostic Causal Bayesian Optimisation (GACBO), an algorithm that actively discovers the causal structure that contributes to achieving optimal rewards. GACBO seeks to balance exploiting the actions that give the best rewards against exploring the causal structures and functions. To the best of our knowledge, our work is the first to study causal Bayesian optimization with cumulative regret objectives in scenarios where the graph is unknown or partially known. We show our proposed algorithm outperforms baselines in simulated experiments and real-world applications.

## 1 Introduction

Bayesian Optimization (BO) is a robust technique for optimizing black-box functions, widely used in fields like drug discovery, robotics, and automated machine learning (Mockus, 1975; Garnett, 2023). Traditional BO methods (Srinivas et al., 2009; Garnett, 2023) often treat functions as black boxes, but real-world data usually exhibits structural patterns. Causal Bayesian Optimization (CBO) methods (Aglietti et al., 2020; Sussex et al., 2022) leverage these structures to improve sample efficiency. However, in many cases, causal graphs are either unknown or incorrectly specified. We address this by proposing a _Graph Agnostic Causal Bayesian Optimization_ (GACBO) method that works with unknown or partially known causal graphs. Unlike previous methods (Branchini et al., 2023; Alabed and Yoneki, 2022; Toth et al., 2022), which focus on hard interventions and simple regret, have a limited prior on graphs or target causal reasoning but not BO, GACBO handles

Figure 1: Graph Agnostic Causal Bayesian Optimisation (gacbo) workflow. _Top_: Select plausible graphs based on data collected so far, _Right_: Perform Causal Bayesian Optimisation on plausible graphs, _Bottom_: Select the action based on the highest reward among all plausible graphs, _Left_: Execute selected action, collect Data and repeat steps.

both soft and hard interventions and aims to maximize cumulative rewards while learning the causal structure as needed. Our approach balances exploitation (selecting actions with the highest potential outcomes) and exploration (uncertainty in function space or causal structure learning). Figure 1 illustrates our proposed method. We begin with a uniform prior over all possible acyclic graph structures, modeling surrogate functions for each target node's ancestors using Gaussian processes, with inputs being the node's parents and influencing actions. The Bayesian Score (Friedman and Nachman, 2013) models the probability of these graphs. At each iteration, we retain functions and graphs within high-probability confidence intervals, selecting interventions with a ucb-based acquisition function using the reparametrization trick (Sussex et al., 2022). Our **contributions** are as follows: **1)** We are the first to study causal Bayesian optimization with a cumulative objective in scenarios where the graph is unknown or partially known. **2)** We propose a novel algorithm, Graph Agnostic Causal Bayesian Optimization (gacbo), that handles both soft and hard interventions and includes all possible graphs in the prior, effectively sharing information across different experiments through a model-based approach. **3)** We introduce an _Upper Confidence Bound_-based acquisition function that integrates causal discovery as a subtask, engaging in it only when distinguishing between graphs improves outcomes, thereby balancing exploitation and exploration. **4)** We demonstrate on synthetic and real-world causal graphs that our algorithm performs competitively compared to existing baselines.

## 2 Problem Setup

Structural Causal ModelsAn scm(Pearl, 2009) is defined as a tuple \(\langle g,Y,\bm{V},\bm{f}_{g},\bm{\Omega}\rangle\), where \(g\) is a Directed Acyclic Graph (dag) describing the relations between observed random variables \(\bm{V}=\{V_{i}\}_{i=0}^{m-1}\), with each node \(i\in[m]\) belonging to a compact space \(\mathcal{V}_{i}\subset\mathbb{R}\). Here, \(Y=V_{m}\) is the reward variable, and \(\bm{f}_{g}=\{f_{i}^{g}\}_{i=0}^{m}\) represents the unknown functions associated with \(g\), with independent noise terms \(\bm{\Omega}=\{\Omega_{i}\}_{i=0}^{m}\) having zero mean and a known distribution. The parent nodes of any node \(i\) in \(g\) are denoted by \(pa_{g}(i)\subset[m]\), and \(\bm{Z}_{i}^{g}=\{V_{j}\}_{j\in pa_{g}(i)}\) represents the parents of node \(i\) in \(g\). Each node \(V_{i}\in\bm{V}\) is generated by the function \(f_{i}^{g}:\mathcal{Z}_{i,g}\rightarrow\mathcal{V}_{i}\), with the observed value \(v_{i}\) given by \(v_{i}=f_{i}^{g}(\bm{z}_{i}^{g})+\omega_{i}\). These functions are evaluated in topological order from the root to the leaf nodes according to \(g\). In this setting, not all observable variables are intervenable (Lee and Bareinboim, 2019). Let \(\mathcal{I}\subset\{0,\ldots,m-1\}\) denote the indices of intervenable variables. The set of observed variables \(\bm{V}\) is decomposed into intervenable variables \(\bm{X}=\{V_{j}\}_{j\in\mathcal{I}}\) and non-intervenable variables \(\bm{C}=\{V_{j}\}_{j\not\in\mathcal{I}}\), with the target variable \(Y=V_{m}\) assumed to be non-intervenable.

InterventionsWe use a _soft intervention_ model for noisy function networks (NFNs) (Eberhardt and Scheines, 2007), where controllable action variables \(\bm{a}=\{a_{j}\}_{j=0}^{n}\) are added as nodes in \(g\) and act as parents to nodes \(V_{i}\), making them inputs to \(f_{i}^{g}\). The subset \(\bm{a}_{i}^{g}\subset\bm{a}\) affects \(V_{i}\) based on \(g\), with the action space \(\mathcal{A}_{i}^{g}\subset\mathbb{R}^{|\bm{a}_{i}^{g}|}\) and total action space \(\mathcal{A}\). Since \(f_{i}^{g}:\mathcal{Z}_{i}^{g}\times\mathcal{A}_{i}^{g}\rightarrow\mathcal{V}_ {i}\) is unknown, the agent cannot predict the effect of \(\bm{a}_{i}^{g}\) on \(V_{i}\) in advance. Observations are modelled as a special case i.e., \(\{a_{j}=0\ \forall\ a_{j}\in\bm{a}_{i}^{g}\}\)

_Hard interventions_ are modelled as a subset of intervenable variables \(\bm{I}\in\mathcal{P}(\mathcal{I})\) being set to values \(\bm{a}_{\bm{I}}=\{a_{i}\}_{i\in\bm{I}}\) independent of their parents using the do operator s.t. \(\{do(x_{i}=a_{i})\ \forall i\in\bm{I},\,a_{i}\in\mathcal{A}_{i}\subset\mathbb{R}\}\) and values are evaluated for all nodes \(i\in[m]\), based on the topological ordering of \(g\)

\[v_{i}=\begin{cases}f_{i}^{g}(\bm{z}_{i}^{g})+\omega_{i}&\text{if }i\notin\bm{I}\\ a_{i}&\text{if }i\in\bm{I}\end{cases}\] (1)

Problem Statement and Performance MetricWe address the problem of an agent interacting with an SCM or NFN defined by \(\langle g^{*},Y,\bm{V},\bm{f}_{g^{*}},\bm{\Omega}\rangle\), where the graph \(g^{*}\) and functions \(\bm{f}_{g^{*}}\) are unknown but fixed. At each round \(t\), the agent selects soft intervention actions \(\bm{a}_{\cdot,t}=\{\bm{a}_{i,t}^{g}\}_{i=0}^{m}\), and for hard interventions, it chooses the nodes \(\bm{I}_{t}\) and the corresponding intervention values \(\bm{a}_{\bm{I}_{t}}\). The agent then collects data \(\bm{v}_{t}\), with the subscript \(t\) indicating the time step of the intervention and data collection. The objective is to design a sequence of actions \(\{\bm{a}_{\cdot,t}\}_{t=0}^{T}\) or \(\{\bm{I}_{t},\bm{a}_{\bm{I}_{t}}\}_{t=0}^{T}\) that maximizes the average expected reward for soft and hard interventions, respectively, which is equivalent to minimizing the expected cumulative regret (Sussex et al., 2022; Lattimore and Szepesvari, 2020):

\[R_{T}=\sum_{t=1}^{T}\left[\mathbb{E}[y|\bm{a}^{*}]-\mathbb{E}[y|\bm{a}_{\cdot,t} ]\right];\quad R_{T}=\sum_{t=1}^{T}\left[\mathbb{E}[y|\bm{a}^{*}]-\mathbb{E}[y| {d}(\bm{x}_{\bm{I}_{t}}=\bm{a}_{\bm{I}_{t}})]\right].\] (2)

[MISSING_PAGE_FAIL:3]

It is important to note that 6 is not suitable for standard optimization methods because it requires maximization over a set of functions with a bounded RKHS norm.

Therefore for a graph \(g\) within the plausible models, the reparametrisation trick introduced in Curi et al. (2020) and utilised for CBO in Sussex et al. (2022) can be used to write any function \(\tilde{f}_{i}^{g}\in\tilde{\bm{f}}_{g}\in\mathcal{M}_{t}^{g}\) using \(\eta_{i,g}:\mathcal{Z}_{i}^{g}\times\mathcal{A}_{i}^{g}\rightarrow[-1,1]\), as

\[\tilde{f}_{i,t}^{g}(\tilde{\bm{z}}_{i}^{g},\tilde{\bm{a}}_{i}^{g})=\mu_{i,t-1}^{ g}(\tilde{\bm{z}}_{i}^{g},\tilde{\bm{a}}_{i}^{g})+\beta_{t}\sigma_{i,t-1}^{g}( \tilde{\bm{z}}_{i}^{g},\tilde{\bm{a}}_{i}^{g})\eta_{i,g}(\tilde{\bm{z}}_{i}^{g },\tilde{\bm{a}}_{i}^{g}),\] (7)

The acquisition function can therefore be expressed in terms of \(\bm{\eta_{g}}:\mathcal{Z}^{g}\times\mathcal{A}^{g}\rightarrow[-1,1]^{|V(g)|}\), where \(|V(g)|\) is the number of nodes in the graph \(g\),

\[\arg\max_{\bm{a}\in\mathcal{A}}\max_{g\in G_{t}}\max_{\bm{\eta}_{g}(\cdot)} \mathbb{E}[y|\tilde{\bm{f}}_{g},\bm{a}].\] (8)

More details about the optimistic reparameterisation trick can be found in A.5. The data collected is used to update model posteriors and construct plausible models for next time step.

## 4 Results

We evaluate gacbo on synthetic environments (Dropwave, Alpine3, Rosenbrock, ToyGraph) and a real-world Epidemiology Graph from (Astudillo and Frazier, 2021; Branchini et al., 2023). The metric used is the average reward, inversely related to cumulative regret. We repeat each experiment 5 times with different seeds and report average rewards \(\pm\sigma/\sqrt{5}\), where \(\sigma\) is the standard deviation. We compare gacbo with: 1) mcbo(Sussex et al., 2022) using the true causal graph, 2) mcbo with incorrect graphs (missing or extra edges), 3) gp-ucb(Srinivas et al., 2009) for soft interventions.

SimulationsFigure 2 shows our results. For soft interventions, we use Dropwave, Alpine3, and Rosenbrock. For hard interventions, we use ToyGraph (Aglietti et al., 2020). mcbo with the true graph generally performs best, except in Rosenbrock, where gp-ucb excels due to the function's additive structure. mcbo struggles with incorrect graphs, particularly when extra edges increase dimensionality or missing edges misrepresent the function space. gacbo, initially hampered by lack of graph information, quickly learns the correct structure and matches mcbo's performance after about 100 rounds. Further information regarding performance in specific environments can be found in A.9.

Real-World Application: EpidemiologyWe test gacbo in an Epidemiology setting (Havercroft and Didelez, 2012; Branchini et al., 2023), aiming to minimize HIV viral load by choosing from interventions \(\mathcal{I}=\{\emptyset,\{T\},\{R\},\{T,R\}\}\). Despite the environment's complexity, gacbo quickly learns the correct causal structure and matches mcbo's performance with the true graph within 100 rounds, significantly outperforming mcbo with incorrect graphs.

Figure 3: Epidemiology application. Top left: true causal graph. Bottom left: incorrect causal structure for mcbo. Right: performance comparison.

Figure 2: Simulation results comparing gacbo with mcbo (true and incorrect graphs) and gp-ucb. gp-ucb is not applicable to ToyGraph due to hard interventions.

## References

* Ackley (2012) David Ackley. _A connectionist machine for genetic hillclimbing_, volume 28. Springer science & business media, 2012.
* Aglietti et al. (2020) Virginia Aglietti, Xiaoyu Lu, Andrei Paleyes, and Javier Gonzalez. Causal bayesian optimization. In _International Conference on Artificial Intelligence and Statistics_, pages 3155-3164. PMLR, 2020.
* Agrawal et al. (2019) Raj Agrawal, Chandler Squires, Karren Yang, Karthikeyan Shanmugam, and Caroline Uhler. Abstract strategy: Budgeted experimental design for targeted causal structure discovery. In _The 22nd International Conference on Artificial Intelligence and Statistics_, pages 3400-3409. PMLR, 2019.
* Alabed and Yoneki (2022a) Sami Alabed and Eiko Yoneki. BoGraph. In _Proceedings of the 2nd European Workshop on Machine Learning and Systems_. ACM, April 2022a. doi: 10.1145/3517207.3526977. URL https://doi.org/10.1145/3517207.3526977.
* Alabed and Yoneki (2022b) Sami Alabed and Eiko Yoneki. Bograph: structured bayesian optimization from logs for expensive systems with many parameters. In _Proceedings of the 2nd European Workshop on Machine Learning and Systems_, pages 45-53, 2022b.
* Andersson et al. (1997) Steen A Andersson, David Madigan, and Michael D Perlman. A characterization of markov equivalence classes for acyclic digraphs. _The Annals of Statistics_, 25(2):505-541, 1997.
* Astudillo and Frazier (2021) Raul Astudillo and Peter Frazier. Bayesian optimization of function networks. _Advances in neural information processing systems_, 34:14463-14475, 2021.
* Balandat et al. (2020) Maximilian Balandat, Brian Karrer, Daniel Jiang, Samuel Daulton, Ben Letham, Andrew G Wilson, and Eytan Bakshy. Botorch: A framework for efficient monte-carlo bayesian optimization. _Advances in neural information processing systems_, 33:21524-21538, 2020.
* Berkenkamp et al. (2019) Felix Berkenkamp, Angela P Schoellig, and Andreas Krause. No-regret bayesian optimization with unknown hyperparameters. _arXiv preprint arXiv:1901.03357_, 2019.
* Branchini et al. (2023) Nicola Branchini, Virginia Aglietti, Neil D hir, and Theodoros Damoulas. Causal entropy optimization. In _International Conference on Artificial Intelligence and Statistics_, pages 8586-8605. PMLR, 2023.
* Chickering (2002) David Maxwell Chickering. Optimal structure identification with greedy search. _Journal of machine learning research_, 3(Nov):507-554, 2002.
* Curi et al. (2020) Sebastian Curi, Felix Berkenkamp, and Andreas Krause. Efficient model-based reinforcement learning through optimistic policy search and planning. _Advances in Neural Information Processing Systems_, 33:14156-14170, 2020.
* De Kroon et al. (2022) Arnoud De Kroon, Joris Mooij, and Danielle Belgrave. Causal bandits without prior knowledge using separating sets. In _Conference on Causal Learning and Reasoning_, pages 407-427. PMLR, 2022.
* Eaton and Murphy (2007) Daniel Eaton and Kevin Murphy. Exact bayesian structure learning from uncertain interventions. In _Artificial intelligence and statistics_, pages 107-114. PMLR, 2007.
* Eberhardt and Scheines (2007) Frederick Eberhardt and Richard Scheines. Interventions and causal inference. _Philosophy of science_, 74(5):981-995, 2007.
* Faria et al. (2022) Goncalo Rui Alves Faria, Andre Martins, and Mario AT Figueiredo. Differentiable causal discovery under latent interventions. In _Conference on Causal Learning and Reasoning_, pages 253-274. PMLR, 2022.
* Friedman and Koller (2003) Nir Friedman and Daphne Koller. Being bayesian about network structure. a bayesian approach to structure discovery in bayesian networks. _Machine learning_, 50:95-125, 2003.
* Friedman and Nachman (2013) Nir Friedman and Iftach Nachman. Gaussian process networks. _arXiv preprint arXiv:1301.3857_, 2013.
* Garnett (2023) Roman Garnett. _Bayesian Optimization_. Cambridge University Press, 2023.
* Ghahramani et al. (2019)AmirEmad Ghassami, Saber Salehkaleybar, Negar Kiyavash, and Elias Bareinboim. Budgeted experiment design for causal structure learning. In _International Conference on Machine Learning_, pages 1724-1733. PMLR, 2018.
* Giudice et al. (2023) Enrico Giudice, Jack Kuipers, and Giusi Moffa. A bayesian take on gaussian process networks. _arXiv preprint arXiv:2306.11380_, 2023.
* Hauser and Buhlmann (2014) Alain Hauser and Peter Buhlmann. Two optimal strategies for active learning of causal models from interventional data. _International Journal of Approximate Reasoning_, 55(4):926-939, 2014.
* Havercroft and Didelez (2012) WG Havercroft and Vanessa Didelez. Simulating from marginal structural models with time-dependent confounding. _Statistics in medicine_, 31(30):4190-4206, 2012.
* Hoyer et al. (2008) Patrik Hoyer, Dominik Janzing, Joris M Mooij, Jonas Peters, and Bernhard Scholkopf. Nonlinear causal discovery with additive noise models. _Advances in neural information processing systems_, 21, 2008.
* Jamil and Yang (2013) Momin Jamil and Xin-She Yang. A literature survey of benchmark functions for global optimisation problems. _International Journal of Mathematical Modelling and Numerical Optimisation_, 4(2):150-194, 2013.
* Janzing et al. (2012) Dominik Janzing, Joris Mooij, Kun Zhang, Jan Lemeire, Jakob Zscheischler, Povilas Daniusis, Bastian Steudel, and Bernhard Scholkopf. Information-geometric approach to inferring causal directions. _Artificial Intelligence_, 182:1-31, 2012.
* Kocaoglu et al. (2017) Murat Kocaoglu, Alex Dimakis, and Sriram Vishwanath. Cost-optimal learning of causal graphs. In _International Conference on Machine Learning_, pages 1875-1884. PMLR, 2017.
* Konobeev et al. (2023) Mikhail Konobeev, Jalal Etesami, and Negar Kiyavash. Causal bandits without graph learning. _arXiv preprint arXiv:2301.11401_, 2023.
* Lattimore and Szepesvari (2020) Tor Lattimore and Csaba Szepesvari. _Bandit algorithms_. Cambridge University Press, 2020.
* Lee and Bareinboim (2018) Sanghack Lee and Elias Bareinboim. Structural causal bandits: Where to intervene? _Advances in neural information processing systems_, 31, 2018.
* Lee and Bareinboim (2019) Sanghack Lee and Elias Bareinboim. Structural causal bandits with non-manipulable variables. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 33, pages 4164-4172, 2019.
* Lorch et al. (2021) Lars Lorch, Jonas Rothfuss, Bernhard Scholkopf, and Andreas Krause. Dibs: Differentiable bayesian structure learning. _Advances in Neural Information Processing Systems_, 34:24111-24123, 2021.
* Lu et al. (2021) Yangyi Lu, Amirhossein Meisami, and Ambuj Tewari. Causal bandits with unknown graph structure. _Advances in Neural Information Processing Systems_, 34:24817-24828, 2021.
* Malek et al. (2023) Alan Malek, Virginia Aglietti, and Silvia Chiappa. Additive causal bandits with unknown graph. In _International Conference on Machine Learning_, pages 23574-23589. PMLR, 2023.
* Masegosa and Moral (2013) Andres R Masegosa and Serafin Moral. An interactive approach for bayesian network learning using domain/expert knowledge. _International Journal of Approximate Reasoning_, 54(8):1168-1181, 2013.
* Mockus (1975) Jonas Mockus. On bayesian methods for seeking the extremum. In _Optimization Techniques IFIP Technical Conference: Novosibirsk, July 1-7, 1974_, pages 400-404. Springer, 1975.
* Murphy (2001) Kevin P Murphy. Active learning of causal bayes net structure. Technical report, technical report, UC Berkeley, 2001.
* Ness et al. (2017) Robert Osazuwa Ness, Karen Sachs, Parag Mallick, and Olga Vitek. A bayesian active learning experimental design for inferring signaling networks. In _Research in Computational Molecular Biology: 21st Annual International Conference, RECOMB 2017, Hong Kong, China, May 3-7, 2017, Proceedings 21_, pages 134-156. Springer, 2017.
* Pearl (2009) Judea Pearl. _Causality_. Cambridge University Press, 2 edition, 2009. doi: 10.1017/CBO9780511803161.
* Pearl (2009)Shohei Shimizu, Patrik O Hoyer, Aapo Hyvarinen, Antti Kerminen, and Michael Jordan. A linear non-gaussian acyclic model for causal discovery. _Journal of Machine Learning Research_, 7(10), 2006.
* Spirtes et al. (2000) Pater Spirtes, Clark Glymour, Richard Scheines, Stuart Kauffman, Valerio Aimale, and Frank Wimberly. Constructing bayesian network models of gene expression networks from microarray data. 2000.
* Srinivas et al. (2009) Niranjan Srinivas, Andreas Krause, Sham M Kakade, and Matthias Seeger. Gaussian process optimization in the bandit setting: No regret and experimental design. _arXiv preprint arXiv:0912.3995_, 2009.
* Surjanovic and Bingham (2013) S Surjanovic and D Bingham. Drop-wave function. 2013.
* Sussex et al. (2022) Scott Sussex, Anastasia Makarova, and Andreas Krause. Model-based causal bayesian optimization. _arXiv preprint arXiv:2211.10257_, 2022.
* Tigas et al. (2022) Panagiotis Tigas, Yashas Annadani, Andrew Jesson, Bernhard Scholkopf, Yarin Gal, and Stefan Bauer. Interventions, where and how? experimental design for causal models at scale. _Advances in Neural Information Processing Systems_, 35:24130-24143, 2022.
* Tigas et al. (2023) Panagiotis Tigas, Yashas Annadani, Desi R Ivanova, Andrew Jesson, Yarin Gal, Adam Foster, and Stefan Bauer. Differentiable multi-target causal bayesian experimental design. In _International Conference on Machine Learning_, pages 34263-34279. PMLR, 2023.
* Tong and Koller (2001) Simon Tong and Daphne Koller. Active learning for structure in bayesian networks. In _International joint conference on artificial intelligence_, volume 17, pages 863-869. Citeseer, 2001.
* Toth et al. (2022) Christian Toth, Lars Lorch, Christian Knoll, Andreas Krause, Franz Pernkopf, Robert Peharz, and Julius Von Kugelgen. Active bayesian causal inference. _Advances in Neural Information Processing Systems_, 35:16261-16275, 2022.
* Verma and Pearl (2022) Thomas S Verma and Judea Pearl. Equivalence and synthesis of causal models. In _Probabilistic and causal inference: The works of Judea Pearl_, pages 221-236. 2022.
* von Kugelgen et al. (2019) Julius von Kugelgen, Paul K Rubenstein, Bernhard Scholkopf, and Adrian Weller. Optimal experimental design via bayesian optimization: active causal structure learning for gaussian process networks. _arXiv preprint arXiv:1910.03962_, 2019.
* Wang and Jegelka (2017) Zi Wang and Stefanie Jegelka. Max-value entropy search for efficient bayesian optimization. In _International Conference on Machine Learning_, pages 3627-3635. PMLR, 2017.
* Williams and Rasmussen (1995) Christopher Williams and Carl Rasmussen. Gaussian processes for regression. _Advances in neural information processing systems_, 8, 1995.
* Yang et al. (2018) Karren Yang, Abigail Katcoff, and Caroline Uhler. Characterizing and learning equivalence classes of causal dags under interventions. In _International Conference on Machine Learning_, pages 5541-5550. PMLR, 2018.

Appendix

### Nomenclature

Using standard notation, we use Capital letters to denote random variables and lowercase letters to denote the realization of said random variables. We use bold letters to denote sets of certain nodes. The support of a variable is given by curly letters. We use the subscript \(t\) to index data observed thus far, and the subscript \(i\) is used to index a particular node in a vector, the superscript \(g\) is used to refer to the input space

\begin{tabular}{l l} \hline \hline
**Symbol** & **Description** \\ \hline \(V_{j}\) & \(j^{\text{th}}\) observed variable \\ \(Y\) & Target variable we seek to optimize corresponds to \\  & \(V_{m}\) \\ \(\bm{V}\) & Set of all observed variables \\ \(\bm{X}\) & Set of intervenable variables \\ \(\bm{C}\) & Set of non intervenable variables \\ \(A_{i}\) & Action performed on node i \\ \(g^{*}\) & True latent causal graph \\ \(\bm{A}\) & Action vector composed of \(\{A_{i}\}_{i=0}^{m}\) \\ \(\bm{Z}_{i}^{g^{*}}\) & The parents of node \(i\) in graph \(g^{*}\) \\ \(f_{i}^{g^{*}}(\bm{z}_{i}^{g^{*}},\bm{a}_{i}^{g^{*}})\) & functions relating a node \(i\) with its parents and actions \\ \(\bm{f}^{g^{*}}(\bm{a})\) & The overall function with input action composed \\  & of functions \(\{f_{i}^{g^{*}}\}_{i=0}^{m}\) related by graph \(g^{*}\) \\ \(\bm{F}_{g^{*}}\) & the set of respective unknown functions associated \\  & with \(g^{*}\), i.e. \(\{f_{i}^{g^{*}}\}_{i=0}^{m}\) \\ \(\bm{\Omega}\) & a set of independent noises with zero mean and \\  & known distribution, i.e. \(\{\Omega_{i}\}_{i=0}^{m}\) \\ \(pa_{g^{*}}(i)\) & indices of parent nodes of any node, defined for \\  & the dag \(g^{*}\) \\ \(\{y_{t},\bm{v}_{t},\bm{a}_{t}\}\) & Observation of reward variable \(y_{t}\) and intermediate \\  & variables \(v_{t}\) for the corresponding action \(\bm{a}_{t}\) \\ \(\mathcal{D}_{t}\) & Observations for actions until time \(t\), is the set \\  & \(\{y_{j},\bm{v}_{j},\bm{a}_{j}\}_{j=0}^{t}\) \\ \(G_{t}\) & Posterior of the distribution over graphs at time \(t\) \\ \(g\) & Random DAG samples from \(G_{t}\) \\ \(k_{i}^{g}(\cdot,\cdot)\) & Kernel defined on input space implied by graph \(g\) \\  & for node \(i\), gives covariance between two points \\ \(\bm{k}_{i,t}^{g}(\cdot)\) & A vector of covariances of the current input to \\  & previous inputs \([k_{i}^{g}((z_{i,t}^{g},a_{i,t}^{g}),\cdot)]_{i=0}^{t}\) \\ \(\bm{K}_{i}^{g}\) & Covariance matrix based on previous \(\mathcal{D}_{t}\) \\ \(\mu_{i,t}^{g}(\cdot)\) & Mean function based on data \(\mathcal{D}_{t}\) and kernel \(k_{i}^{g}(\cdot,\cdot)\) \\ \(\sigma_{i,t}^{g}(\cdot)\) & Variance function based on data \(\mathcal{D}_{t}\) and kernel \\  & \(k_{i}^{g}(\cdot,\cdot)\) \\ \(GP(\mu_{i,t}^{g},\sigma_{i,t}^{g})\) & Gaussian Process \(\tilde{f}_{i}^{g}(\cdot)\sim\mathcal{N}(\mu_{i,t}^{g}(\cdot),\sigma_{i,t}^{ g}(\cdot))\) \\ \(\mathcal{H}_{k^{g}}\) & Hilbert Spaces of functions implied by kernel \(k_{i}^{g}\) \\ \(\tilde{f}_{i}^{g}\) & A function sampled from Gaussian Processes GP \\ \(\omega_{i}\) & Observational noise of node \(i\) \\ \(\mathcal{M}_{t}\) & Plausible models at time \(t\) based on confidence bounds \\ \hline \hline \end{tabular}

### Related Work

Causal Decision MakingThe first causal Bayesian optimisation setting was proposed in Aglietti et al. (2020), which focused on hard interventions and the best intervention identification setting.

Sussex et al. (2022) expanded their setting to include soft interventions and noisy environments. They proposed the Model-based Causal Bayesian Optimisation (mcbo) algorithm, which is the state-of-the-art method with a known graph. With unknown graphs for cumulative regret objective, Lu et al. (2021), De Kroon et al. (2022), Konobeev et al. (2023) considered causal multi-armed bandits. Lu et al. (2021) studied causal trees, causal forests and proper interval graphs, with regret analysis under a few causal assumptions. De Kroon et al. (2022) utilised an estimator based on separating sets, with no theoretical analysis on regret shown. Konobeev et al. (2023) proposed a Randomized Parent Search algorithm (RAPS) and showed conditional regret upper bounds. Malek et al. (2023) show that the unknown causal graph be exponentially hard in parents of the outcome and studies the problem under the additive assumption on the outcome. All the above work considered discrete arms (intervention values) and linear bandits, while our work addresses continuous intervention values, non-linear relations between nodes and a more general class of graphs.

Branchini et al. (2023) studied the cbo setting with an unknown graph for the best intervention identification setting. Their approaches are based on the entropy search criterion. However, directly applying their method to cumulative regret objective would lead to suboptimal performance since one needs to further balance the exploitation-exploration balance between picking actions that lead to the best rewards and learning causal structures. Alabed and Yoneki (2022) studied the cbo problem for unknown causal graph scenarios with a specific application to autotuners. To the best of our knowledge, we are the first to study the cbo with unknown graph and cumulative regret objectives.

Active Causal Discoveryvon Kugelgen et al. (2019) developed a Bayesian optimal experimental design framework to perform active causal discovery for Gaussian Process networks. Lorch et al. (2021), Giudice et al. (2023) addressed the problem of causal discovery for graphs with a larger number of nodes. Based on this, Tigas et al. (2022, 2023) performed active causal discovery for larger graphs. Toth et al. (2022) considered the active learning methods for unifying sequential causal discovery and causal reasoning.

The goals of active causal discovery and Bayesian optimisation are misaligned. While Bayesian optimisation tries to balance exploration and exploitation to minimise cumulative regret, the active causal discovery acquisition function might choose an intervention that has a low reward and does not help future steps of CBO but helps discover the true underlying Causal Graph. Therefore it is sub-optimal to first perform active causal discovery and then followed by causal Bayesian optimisation as separate steps. Our algorithm naturally unifies these two steps by making causal discovery a sub-task of causal Bayesian optimisation. See Appendix A.10 for a detailed discussion.

### Surrogate models

Surrogate models help us incorporate our prior beliefs into the modelling process and allow us to enact interventions without performing them in the real environment and also quantify the total uncertainty related to certain outcomes. Define surrogate model \(m_{t}\sim\mathcal{M}_{t}\) at time step \(t\) as a triple \(m_{t}=(g_{t},\tilde{\bm{f}}_{t}^{g},\bm{\omega}_{t}^{2})\). \(\mathcal{M}_{t}\) denotes the posterior of plausible models, \(g_{t}\sim G_{t}\) is one possible realisation of posterior \(G_{t}\) at time \(t\), \(\tilde{\bm{f}}_{t}^{g}=\{\tilde{f}_{t,i}^{g}\}_{i=0}^{m}\) where the surrogate function \(\tilde{f}_{t,i}^{g}\in\mathcal{H}_{k_{i}^{g}}\) belongs to the RKHS \(\mathcal{H}_{k_{i}^{g}}\) which is defined on the input space \(\mathcal{S}_{i}^{g}=\mathcal{Z}_{i}^{g}\times\mathcal{A}_{i}^{g}\) (and \(\mathcal{S}_{i}^{g}=\mathcal{Z}_{i}^{g}\) for hard interventions) for all nodes \(i\) as implied by kernel \(k_{i}^{g}:\mathcal{S}_{i}^{g}\times\mathcal{S}_{i}^{g}\rightarrow\mathbb{R}\). And we assume subgaussian observational noise of each node \(\bm{\omega}_{t}^{2}=\{\omega_{t,i}^{2}\}_{i=0}^{m}\).

Surrogate FunctionsWe model surrogate functions using Gaussian processes (gps). Posterior means \(\mu_{i,t}^{g}\) and variances \(\sigma_{i,t}^{g}\) for any function parameterising any possible graph \(g\) at a given point is calculated according to the gp posterior at time step \(t\). The posterior is calculated using gp update equations (Williams and Rasmussen, 1995).

\[\tilde{f}_{i,t}^{g}(\bm{z}_{i}^{g},\bm{a}_{i}^{g})\sim\mathcal{N}(\mu_{i,t}^{ g}(\bm{z}_{i}^{g},\bm{a}_{i}^{g}),\sigma_{i,t}^{g}(\bm{z}_{i}^{g},\bm{a}_{i}^{g})),\] (9)where

\[\begin{split}&\mu_{i,t}^{g}(\bm{z}_{i}^{g},\bm{a}_{i}^{g})=\bm{k}_{ i,t}^{g}(\bm{z}_{i}^{g},\bm{a}_{i}^{g})^{\top}(\bm{K}_{i}^{g}+\rho_{i}^{2}\bm{I})^{-1} \text{vec}(v_{i,1:t});\\ &\sigma_{i,t}^{g}(\bm{z}_{i}^{g},\bm{a}_{i}^{g})=k_{i}^{g}((\bm{z }_{i}^{g},\bm{a}_{i}^{g}),(\bm{z}_{i}^{g},\bm{a}_{i}^{g}))-\bm{k}_{i,t}^{g}(\bm {z}_{i}^{g},\bm{a}_{i}^{g})^{\top}(\bm{K}_{i}^{g}+\rho_{i}^{2}\bm{I})^{-1}\bm{ k}_{i,t}^{g}(\bm{z}_{i}^{g},\bm{a}_{i}^{g}),\end{split}\] (10)

where \(\bm{I}\) is used to define the identity matrix, \(\text{vec}(v_{i,1:t})=[v_{i,1}\dots v_{i,t}]^{\top}\), \(\bm{k}_{i,t}^{g}(\bm{z}_{i}^{g},\bm{a}_{i}^{g})=[k_{i}^{g}((\bm{z}_{i,1}^{g}, \bm{a}_{i,1}^{g}),(\bm{z}_{i}^{g},\bm{a}_{i}^{g})),\dots,k_{i}^{g}((\bm{z}_{i,t }^{g},\bm{a}_{i,t}^{g}),(\bm{z}_{i}^{g},\bm{a}_{i}^{g}))]\), \([\bm{K}_{i}^{g}]_{t_{1},t_{2}}=k_{i}^{g}((\bm{z}_{i,t_{1}}^{g},\bm{a}_{i,t_{ 1}}^{g}),(\bm{z}_{i,t_{2}}^{g},\bm{a}_{i,t_{2}}^{g}))\).

**Graph Likelihood** The _Markov Property_ of Bayesian networks allows for a compact factorisation of the joint distribution of all observed nodes \(\bm{V}=\{V_{1},\dots,V_{m}\}\) in the Bayesian Network,

\[p(\bm{V}|g)=\prod_{i=0}^{m}p(V_{i}|\bm{Z}_{i}^{g}).\] (11)

The joint distribution factorises into conditional distributions given its parents in the graph \(g\).

In the case of soft interventions any observed node \(V_{i}\) is affected by its parents \(\bm{Z}_{i}^{g}\) as well as the actions which appear as extra nodes in the scm, we use \(\bm{A}_{i}^{g}\) to denote the set of action nodes affecting node \(i\) therefore it is calculated as

\[p(\bm{V}|g)=\prod_{i=0}^{m}p(V_{i}|\bm{Z}_{i}^{g},\bm{A}_{i}^{g})\] (12)

The distribution factorises into conditional distributions for each variable, given its parents in the dag and the associated actions for the node.

gps admit a closed-form expression for the marginal likelihood of the \(t\) observations \(v_{i,1:t}\) of the node \(V_{i}\). \(p(v_{i,1:t}|g,\bm{\theta}_{i})\) can be calculated as below

\[(2\pi)^{-\frac{t}{2}}|\tilde{\bm{K}}_{i,\theta}^{g}|^{-\frac{1}{2}}\text{exp }\left(-\frac{1}{2}v_{i,1:t}^{\top}(\tilde{\bm{K}}_{i,\theta}^{g})^{-1}v_{i,1: t}\right)\] (13)

where \(\tilde{\bm{K}}_{i,\theta}^{g}=\bm{K}_{i,\theta}^{g}+\omega_{i}^{2}I\). The covariance matrix \(\bm{K}_{i,\theta}^{g}\) is given by the kernel \(k_{i,\theta}^{g}\) used and observations collected until time step \(t\) (\(\bm{z}_{i,1}^{g},\bm{a}_{i,1}^{g})\dots(\bm{z}_{i,t}^{g},\bm{a}_{i,t}^{g})\), (\(\bm{z}_{i,1}^{g})\dots(\bm{z}_{i,t}^{g}\)) for soft and hard interventions respectively. The input space of the functions and hence the kernel specified is dependent on the selected graph. The lengthscales \(\bm{\theta}_{i}=\{\theta_{i,j}\}_{i\in p\alpha_{g}(i)}\) chosen for different input nodes in the selected graph, determine the smoothness of the functions in the rkhs implied by the kernel. The lengthscales chosen for the kernel relate directly to the smoothness of the functions sampled from the gp (Berkenkamp et al., 2019). We define priors \(\bm{\theta}_{i}\sim\pi(\bm{\theta}_{i})\) over hyperparameters consistent with our smoothness assumptions.

### Bayesian Score

The _Score_ is defined as Friedman and Nachman (2013) as \(S\) and is calculated as follows. The score shows the probability of the observed values of node \(V_{i}\) is \(v_{i,1:t}\) given the graph \(g\) and dataset \(\mathcal{D}_{t-1}\), where graph \(g\) indicates the parents of node \(V_{i}\) is \(\bm{Z}_{i}^{g}\) and actions \(\bm{A}_{i}^{g}\).

\[S(V_{i},\bm{Z}_{i}^{g},\bm{A}_{i}^{g}|\mathcal{D}_{t})=\int p(v_{i,1:t}|g,\bm{ \theta}_{i})\pi(\bm{\theta}_{i}|g)d\bm{\theta}_{i},\] (14)

Therefore the probability of observing data \(\mathcal{D}_{t}\) given \(g\) is given as the product of observing the values of each node in \(i\in[m]\) given the values of its parents according to graph \(g\)

\[P(\mathcal{D}_{t}|g)=\prod_{i=0}^{m}S(V_{i},\bm{Z}_{i}^{g},\bm{A}_{i}^{g}| \mathcal{D}_{t}).\] (15)

The probability of the graph \(g\) given \(\mathcal{D}_{t}\) is directly proportional to the product of the probability of observing the data given graph \(P(\mathcal{D}_{t}|g)\) and prior probability of graph \(g\)\(p(g)\) using Bayes Rule,

\[P(g|\mathcal{D}_{t})\propto P(\mathcal{D}_{t}|g)p(g).\] (16)

### Optimistic Reparameterisation

Actions are evaluated based on the topological ordering of nodes in a graph \(g\). Finding the optimal value of the target node requires selecting the correct actions for all its ancestor nodes. This task is challenging due to two key factors. First, there is function uncertainty, meaning that for a given set of node values and a fixed action, the exact value of the affected node is not known but lies within a confidence interval. Second, the values of ancestor nodes, given actions up to node \(i\) in \(g\), can vary. The optimistic reparametrization approach involves choosing values for these ancestor nodes within their confidence intervals in a way that allows descendant nodes to take on values that optimize the target node.

For a graph \(g\) within the set of plausible models, the reparametrization trick from Curi et al. (2020) and used for CBO in Sussex et al. (2022) allows us to express any function \(\tilde{f}_{i}^{g}\in\tilde{\bm{f}}_{g}\in\mathcal{M}_{t}^{g}\) using \(\eta_{i,g}:\mathcal{Z}_{i}^{g}\times\mathcal{A}_{i}^{g}\to[-1,1]\) as

\[\tilde{f}_{i,t}^{g}(\tilde{\bm{z}}_{i}^{g},\tilde{\bm{a}}_{i}^{g})=\mu_{i,t-1} ^{g}(\tilde{\bm{z}}_{i}^{g},\tilde{\bm{a}}_{i}^{g})+\beta_{t}\sigma_{i,t-1}^{ g}(\tilde{\bm{z}}_{i}^{g},\tilde{\bm{a}}_{i}^{g})\eta_{i,g}(\tilde{\bm{z}}_{i}^{g}, \tilde{\bm{a}}_{i}^{g}).\]

The acquisition function can then be expressed in terms of \(\bm{\eta}_{g}:\mathcal{Z}^{g}\times\mathcal{A}^{g}\to[-1,1]^{|V(g)|}\), where \(|V(g)|\) is the number of nodes in graph \(g\):

\[\arg\max_{\bm{a}\in\mathcal{A}}\max_{g\in G_{t}}\max_{\bm{\eta}_{g}(\cdot)} \mathbb{E}[y|\tilde{\bm{f}}_{g},\bm{a}].\]

By selecting a sequence \(\bm{\eta}_{g}\) corresponding to actions \(\bm{a}_{:,t}\), we can choose optimistic but plausible functions that maximize the target node for a given action. The objective then becomes finding the right sequence \(\bm{\eta}_{g}\) and the optimal action \(\bm{a}_{:,t}\) to achieve the best possible outcome given the current function estimates.

In noiseless settings, instead of parameterizing each \(\eta_{i}\) as a neural network, it can be parameterized as a constant. Without noise, the inputs to \(\eta_{i,g}\) (\(z_{i}^{g}\) and \(a_{i}^{g}\)) are fixed given \(\bm{a}\), reducing the parameter space to optimize. This allows us to use the optimization procedure from EIFN by Astudillo and Frazier (2021), which is also implemented as an optimizer in the BoTorch package Balandat et al. (2020).

For noisy settings where each \(\eta_{i,g}:\mathcal{Z}_{i}^{g}\times\mathcal{A}_{i}^{g}\to\mathbb{R}\) is parameterized as a neural network, we use our own optimizer. For each initialization of \(\eta\) parameters, we perform stochastic gradient descent to optimize both the \(\eta_{i}\) parameters and the action \(a\), leveraging the differentiability of the acquisition function with respect to both \(a\) and the \(\eta_{i}\) parameters. After running stochastic gradient descent on many random initializations, we select the candidate with the highest acquisition function value. Since the acquisition function may be highly non-convex, we use a large number of random initializations. Alternative approaches, such as those in Curi et al. (2020) for model-based reinforcement learning, could also be adapted to optimize our acquisition function. When parameterizing each \(\eta_{i}\) with a neural network, we use a two-layer feed-forward network with a ReLU non-linearity, followed by an element-wise Sigmoid function to map the output into \([-1,1]\).

### Regularity Assumption

We operate under standard smoothness assumptions for any function relating any node to its parents \(f_{i}^{g^{*}}\to\mathcal{S}\times\mathcal{V}_{i}\) is defined over a compact domain \(\mathcal{S}\). For all nodes \(i\in[m]\), we assume \(f_{i}^{g^{*}}(\cdot)\) belongs to a reproducible Kernel Hilbert Space (RKHS) \(\mathcal{H}_{k_{i}^{g^{*}}}\), a space of smooth functions defined on the input space \(\mathcal{S}=\mathcal{Z}_{i}^{g^{*}}\times\mathcal{A}_{i}^{g^{*}}\) for fns and \(\mathcal{S}=\mathcal{Z}_{i}^{g^{*}}\) for cms. This means all functions \(f_{i}^{g^{*}}\in\mathcal{H}_{k_{i}^{g^{*}}}\) are induced by \(k_{i}^{g^{*}}:\mathcal{S}\times\mathcal{S}\to\mathbb{R}\). We also assume that \(k_{i}^{g^{*}}(s,s^{\prime})\leq 1\) for every \(s,s^{\prime}\in\mathcal{S}\). We enforce our smoothness assumptions by placing a bound on the RKHS norm of \(f_{i}^{g^{*}}(\cdot)\), \(\|f_{i}^{g^{*}}\|\leq\mathcal{B}_{i}\) for some fixed constant \(\mathcal{B}_{i}\geq 0\). To ensure the compactness of the domain \(\mathcal{Z}_{i}^{g^{*}}\) we assume that the noise \(\omega_{i}\) is either subgaussian or bounded i.e \(\omega_{i}\in[-1,1]\).

### Supplementary Algorithms

GACBO HardSimilar to the acquisition function defined in 6, we define an acquisition function for hard interventions, with the only difference being that hard interventions are performed instead ofsoft interventions. The observational uncertainty is propagated through the resulting mutilated graph, the reparameterisation trick is used to find optimistic upper confidence for all plausible graphs

\[\arg\max_{I,\bm{a}_{I}\in\mathcal{A}}\max_{g\in G_{t}}\max_{\bm{\eta}_{g}(\cdot )}\mathbb{E}[y|\tilde{\bm{f}}_{g},do(V_{I}=\bm{a}_{I})].\] (17)

This is slightly different as compared to soft interventions, because a hard intervention mutates the graph, making the node independent of all ancestor nodes and interventions performed on them, thus simplifying the problem. This induces the notion of Minimal Intervention Sets mis[11]. A mis for an scm\(\langle g,Y,\bm{V},\bm{f}_{g},\bm{\Omega}\rangle\) is defined as the set of variables \(\mathbf{X}_{\mathbf{s}}\in\mathcal{P}(\mathbf{X})\) such that there exists no such \(\mathbf{X}_{\mathbf{s}}^{{}^{\prime}}\subset\mathbf{X}_{\mathbf{s}}\) for which \(\mathbb{E}[Y\mid do(\mathbf{X}_{\mathbf{s}})]=\mathbb{E}[Y\mid\mathbf{do}( \mathbf{X}_{\mathbf{s}}^{\prime})]\). We denote the mis for graph \(g\) with target node \(y\) as \(\mathbb{M}_{g,y}\) however since the graph structure is not known to us a priori, we construct our _Plausible MIS_\(\mathbb{M}_{y,t}\), by taking the union over the mis of plausible graphs at time step \(t\), i.e. \(\mathbb{M}_{y,t}=\bigcup_{g\in G_{t}}\mathbb{M}_{g,y}\). For each plausible graph, we only compare interventions within the MIS of the given graph to find the intervention which maximises the surrogate model associated with that particular graph and then compare across all possible graphs to find the best plausible intervention.

``` Input:\(\bm{S}_{i}=\{S(V_{i},Z_{i},A_{i}|\mathcal{D}_{t}),\forall(Z_{i},A_{i})\in \mathcal{Z}_{i}\times\mathcal{A}_{i}\}\), where \(i\in[m]\), \(g_{t}=\{\}\), \(De(m)=\{\}\). functionFindSubgraph(\(g,i,\bm{S}_{i},De(i)\)) if\(i\in g\)then return\(g\) endif\(\bm{S}_{i}^{c}=\{S\in\bm{S}_{i}\mid Z_{i}\cap De(i)=\emptyset\}\),\(\tilde{\bm{S}}_{i}^{c}=\{\sum_{S\in\bm{S}_{i}^{c}}\forall S\in\bm{S}_{i}^{c}\}\), \((Z_{i}^{c},A_{i}^{c})\sim\text{Multinomial}(\tilde{\bm{S}}_{i}^{c})\) if\(Z_{i}^{c}=\emptyset\)then \(g=g\cup\{i:(Z_{i}^{c},A_{i}^{c})\}\) else \(g=\{g\cup\{i:(Z_{i}^{c},A_{i}^{c})\}\), \(Pa_{g}(i)\sim\text{Uniform}(\text{Permutations}(Z_{i}^{c}))\) for\(j\in Pa_{g}(i)\)do \(De(j)=De(j)\cup\{i\}\), \(g=\text{FindSubgraph}(g,j,\bm{S}_{j},De(j))\) endfor endif return\(\mathbf{g}\) endfunction Output:\(g_{t}=\text{FindSubgraph}(g_{t},m,\bm{S}_{m},De(m))\) ```

**Algorithm 2** Graph Agnostic Causal Bayesian Optimisation (Hard intervention) (gacbo-h)

Causal Subgraph DiscoveryOur causal Subgraph discovery algorithm is used in both versions of the GACBO algorithm to sample from the posterior over graphs. The Graph discovery algorithm only focuses on components that are possibly ancestors of the target variables. It recursively samples graph components based on scores of the graph components for any given node. The given nodes are those of already sampled components closer to the target variable. We ensure acyclicity by excluding components that form a cycle with one or more of the already sampled nodes. We randomly sample the ordering of the parents of a node to determine their respective graph components.

### Motivating Examples

We illustrate an example of how making use of causal structure in soft or hard intervention cases can improve the optimization in Figure 5. This example shows observing intermediate nodes is essential. Consider a modeller trying to optimize \(Y\) using \(A2\), while ignoring the values of \(X1,X2\), they would observe a lot of different values of \(y\) for the same action \(A2\) considering that \(X1\) can take on several different values, consequently affecting \(X2\) and \(Y\).

Consider an investigator trying to optimize her crop yield, the crop could be dependent on several variables such as hours of daylight, soil moisture content, soil nitrogen content, temperature, rainfall, pest control, fertilizer use, crop rotation, irrigation practices, planting density, soil pH, weed control, climate conditions, genetic factors and so on.

While she is aware of all the factors that are related to crop yield, the causal relations between these factors and the target variable are either unknown or partially known to her.

Some of these factors are not directly manipulable like rainfall, soil moisture content, soil pH, and soil nitrogen content. However, they can be manipulated using soft interventions such as changing irrigation frequency or adding pesticides. For example, soil moisture would be dependent on both rain and irrigation practices, so even though we cannot directly set soil moisture content to our desired level we can manipulate it by changing irrigation practices.

Adding pesticides could be treated as a soft intervention on both soil nitrogen content and soil pH level. Both these variables might have a nonlinear relation to the amount of pesticide used.

If by some mechanism we could set the soil pH to our desired value that would be equivalent to a hard intervention.

By experimentation, she can manipulate the values of these variables discover the causal relations between them, and consequently design a policy that maximizes crop yield.

### Simulation Details

#### a.9.1 Dropwave

Surjanovic and Bingham (2013), Astudillo and Frazier (2021), Sussex et al. (2022)

For our setting we consider \(A_{0}\in[-5.12,5.12]\) and \(A_{1}\in[-5.12,5.12]\), we set \(\beta=0.5\) and \(\epsilon_{i}=0.1\forall i\in[m]\)

Figure 4: Problem Settings and Causal Structures: (a) Bayesian optimisation; (b) Structural causal models and hard interventions; (c) Function networks and soft interventions; (c-w1) Incomplete graph for (c), missing X1; (c-w2) Incorrect graph for (c), reversing the order of X1 and X2. The blue circles \(X1\) and \(X2\) represent non-manipulative variables, the orange squares \(A1\) and \(A2\) represent actions that can be taken, and \(Y\) is the outcome of interest.

\[x_{0} =f_{0}(a_{0},a_{1})=\sqrt{a_{0}^{2}+a_{1}^{2}}+\epsilon_{0}\] (18) \[y=f_{y}(x_{0})=\frac{1+\cos(12x_{0})}{2+0.5x_{0}^{2}}+\epsilon_{y}\]

**Results** GACBO outperforms all cases other than MCBO when the graph is known as apriori. We see a dip in performance in the initial rounds as expected, which are spent on graph discovery, however after the 20th iteration on all seeds the posterior is concentrated around the true graph and the performance matches that of MCBO.

#### a.9.2 Rosenbrock

Jamil and Yang (2013); Astudillo and Frazier (2021); Sussex et al. (2022)

For our setting we use \(a_{i}\in[-2,2]\) for \(i\in[m]\), we use \(\beta=0.5\) and \(\epsilon_{i}=0.1\forall i\in[m]\)

Figure 5: Illustrative example based on Ackley (2012), \(X2=f_{2}(X1,A2),Y=f_{y}(X2)\). _Hard Interventions_: X2 can be manipulated therefore optimisation objective can directly be achieved by setting X2 to the correct value. _Soft Interventions_ : X2 cannot directly be modified but is a function of the value of X1 and action A2, hence by observing the value of X1 and appropriately choosing A2 (represented by plot on X1, A2 plane) the desired value of X2 can be achieved. This example shows observing intermediate nodes is essential. Consider a modeller trying to optimise \(Y\) using \(A2\), while ignoring the values of \(X1,X2\), they would observe a lot of different values of \(y\) for the same action \(A2\) considering that \(X1\) can take on several different values, consequently affecting X2 and Y.

Figure 6: Dropwave: True DAG structure, and Incorrect DAG structures used in Experiment

\[f_{0}(a_{0},a_{1}) =-100a_{1}-a_{0}^{2}2-(1-a_{0})^{2}+\epsilon_{0}\] (19) \[f_{k}(a_{k},a_{k+1},x_{k-1}) =-100a_{k+1}-a_{k}^{2}2-(1-a_{k})^{2}+x_{k-1}+\epsilon_{k}i=1,\ldots,m\]

**Results** GACBO matches the performance of other baselines in this environment. This behaviour is expected as Rosenbrock has an additive structure and causal graph knowledge does not help accelerate BO's performance. However as demonstrated in our experiments, MCBO with missing edges performs drastically worse as compared to all other methods demonstrating that utilising MCBO with a misspecified graph can result in bad performance.

#### a.9.3 Alpine3

[Jamil and Yang, 2013, Sussex et al., 2022, Astudillo and Frazier, 2021] For our experiments we consider \(a_{i}\in[0,10]\), for \(i\in m\), we consider \(\beta=0.5\) and \(\eta=0.1\)

\[f_{0}(x_{0}) =-\sqrt{x_{0}}\sin(x_{0})+\epsilon_{0}\] (20) \[f_{i}(a_{i},x_{i-1}) =\sqrt{a_{i}}\sin(a_{i})x_{i-1}+\epsilon_{i},i=1,\ldots,m\]

**Results** Similar to Dropwave, GACBO outperforms all methods except MCBO with a known graph. For Alpine, the non-linear relationships make knowing the graph structure crucial for faster identification of optimal actions, as shown by the empirical results.

#### a.9.4 ToyGraph

Aglietti et al. [2020]

\[X =\epsilon_{x}\] (21) \[Z =\exp(-X)+\epsilon_{z}\] \[Y =\cos(Z)-\exp(-Z/20)+\epsilon_{y}\]

**Results** GACBO significantly outperforms MCBO with the wrong graph in both cases (extra and missing edges). The ToyGraph environment is incredibly noisy when intervening on non-parent nodes and therefore knowledge of the graph structure boosts performance.

Figure 7: Rosenbrock: True DAG structure, and Incorrect DAG structures used in Experiment

#### a.9.5 Epidemiology

, Branchini et al. (2023), Havercroft and Didelez (2012)

In our settings, we consider the following input ranges for interventions \(T\in[0,4]\) and \(R\in[0,4]\), we use \(\beta=1\) and noise levels are specified according to the scm.

\[\begin{split} B&=\mathcal{U}[-1,1]\\ T&=\mathcal{U}[4,8]\\ L&=\text{expit}(0.5T+U)\\ R&=4+LT\\ Y&=0.5+\cos(4T)+\sin(-L+2R)+B+\epsilon\text{ with } \epsilon\sim\mathcal{N}(0,1)\end{split}\] (22)

Figure 8: Alpine3: True DAG structure, and Incorrect DAG structures used in Experiment

Figure 9: Toy Graph: True DAG structure, and Incorrect DAG structures used in Experiment

### Causal Discovery and Causal Bayesian Optimization

Causal discovery from observational data (Verma and Pearl, 2022; Andersson et al., 1997; Spirtes et al., 2000; Chickering, 2002; Friedman and Koller, 2003; Shimizu et al., 2006) can recover causal graphs up to Markov Equivalence Classes (mec). Friedman and Koller (2003); Janzing et al. (2012) go beyond mec from purely observational data based on information asymmetry. Tong and Koller (2001); Murphy (2001); Eaton and Murphy (2007); Hauser and Buhlmann (2014); Wang and Jegelka (2017); Ness et al. (2017); Yang et al. (2018); Ghassami et al. (2018); Agrawal et al. (2019); Faria et al. (2022) study the problem of learning graphs from observational and interventional data.

Active causal discovery aims to learn the scm efficiently. For example, von Kugelgen et al. (2019) studied causal structure learning actively using Bayesian Optimal Experimental Design (boed). The acquisition function used in their model seeks to select the intervention that is maximally informative about the underlying causal structure with respect to the current model.

Bayesian optimisation aims to learn the optimal point of unknown functions. Knowing the causal structure helps us reduce the causal intrinsic dimension of the optimisation problem for hard intervention. In the case of soft interventions, causal knowledge is useful for utilising the information from intermediate nodes and converting a high-dimension problem into \(n\) smaller dimensional optimisation problems (where \(n\) is the number of intermediate nodes).

However, learning the entire scm such as in active causal discovery (i.e., all the causal edges and mechanisms of all nodes in their entire domain) is not necessary for causal Bayesian optimisation. This is understood in two separate cases:

Hard InterventionA hard Intervention mutates the graph, making the intervened node independent of all its parents and ancestors. Lee and Bareinboim (2018) demonstrated that the optimal intervention lies within the parents when there are no unobserved confounders. In such a case learning the causal relation between the ancestors of the parents does not help the underlying goal of causal Bayesian optimisation. Consider the example of ToyGraph, in the true data-generating mechanism \(X_{1}\) is the parent of \(Y\), and on performing \(\text{do}(X_{1}=x_{1})\) the value of \(Y\) is not affected by the value of \(X_{0}\), hence for optimization knowing the causal direction or mechanism relating \(X_{0}\) and \(X_{1}\) is not required.

Soft InterventionA soft intervention does not mutate the graph, hence learning the causal relations of the ancestral nodes is still relevant to the downstream optimisation problem, however learning the entire causal structure might still be wasteful. If we have determined (specified by expert knowledge or during a certain step of our active causal discovery process) that a certain node is not an ancestor of the target node, then knowing the ancestors or descendants of the node does not contribute to causal Bayesian optimisation. Causal structure in the case of soft intervention utilises values of intermediate nodes to constrain the optimisation problem. Causal structure is only useful when the decomposed problem is simpler than the original problem. For example consider function \(f(x_{1},x_{2})=g(h(x_{1}),x_{2})\), knowing the intermediate value \(h(x_{1})\) is only useful if the composed function \(f\) is more difficult to optimise (because of non-linearity) than the individual functions \(g\) and \(h\). We observe in our experiments with the Rosenbrock graph in Section 4 that there is no significant advantage of causal structure when the intermediate functions are purely linear.

Our algorithm naturally unifies the two steps of causal discovery and causal Bayesian optimisation by making causal discovery a sub-task of causal Bayesian optimisation. If multiple causal graphs exist within our hypothesis space that explain the data collected up to time step \(t\), we only perform an intervention aimed at disambiguation between these graphs if it potentially leads to better rewards than the optimal value observed thus far. Our acquisition function (2) has three maximisations, for a given graph \(g\in G_{t}\) there are several plausible functions for each node \(\tilde{f}^{g}_{i,t}\) and all possible combinations of node functions define the function space for the graph \(g\). We use the optimistic reparameterisation trick to find the combination of functions and actions \(a_{g}\) which maximises the target node. We do this for all plausible graphs and compare the best possible value for each graph \(g\). We select the plausible graph \(g\) with the maximum possible value for the target node and the corresponding action \(a_{g}\) which maximises it. Consider a hypothetical scenario with two different graphs \(g_{1},g_{2}\) which disagree on the value of node \(i\) for intervention \(a\) but the action which maximises the value of target node \(y_{g_{1}},y_{g_{2}}\) in \(g_{1}\) and \(g_{2}\) is same \(a^{*}\), and the target node values also agree i.e., \(y^{*}_{g_{1}}=y^{*}_{g_{2}}\) for action \(a^{*}\), even though performing \(a\) would help identify the true graph our acquisition function is designed to choose \(a^{*}\). Because \(y_{g_{1}}\leq y^{*}_{g_{1}}\) or \(y_{g_{2}}\leq y^{*}_{g_{2}}\) for any action \(a\neq a^{*}\).

### Superexponential Scaling of DAGs and Scalability

The problem setting we addressed in this paper is challenging due to the super-exponential growth of the number of DAGs with the increase in the number of nodes. We only focus on small graphs where all the graphs can be enumerated to study the problem of CBO with unknown graphs in isolation. Our approach can be further improved to be more scalable, by MCMC-based sampling in the space of graphs Giudice et al. (2023), or Differential approaches like DiBS Lorch et al. (2021) in latent spaces or topological ordering of nodes. We leave it as a future work.

Our method in its current state computes the gp score of all possible graph components (all combinations of parents and actions for all observed nodes) and samples graphs based on the GP score and individually optimises and compares all sampled graphs. For larger graphs, the problem becomes intractable as the number of components for which the gp score needs to be calculated increases exponentially. In the initial rounds, the number of graphs that need to be optimised and the number of comparisons that need to be made also increases superexponentially. Causal Bayesian optimisation using the MCBO approach also takes longer for larger graphs.

### Discussion on Theoretical Analysis

Our approach suggests attaining a similar regret bound to MCBO but with an added constant term. However, our method holds the potential for a superior regret bound by simultaneously exploring the causal structure and exploiting rewards from the outset. Empirical results indicate that our algorithm, GACBO, exhibits a significantly faster increase in average rewards after initial rounds, underscoring its potential for improved regret. The lack of guarantees for the convergence of the posterior to the true graph in finite samples is a major obstacle. A potential theoretical proofing can be achieved by decomposing our regret into two parts:

* Constant term: For the first \(n\) samples before learning the true graph, we obtain the constant regret. This is due to the boundness assumption of function (See section 2.3 "Regularity Assumption") \(||f_{i}^{g^{*}}||\leq\mathcal{B}_{i}\). No matter what actions are selected, the upper bound of instant regret can be bounded by \(2\mathcal{B}_{i}\).
* MCBO regret: the second term is the same as the MCBO regret term since after \(n\) samples we've discovered the true graph.

Effect of Graph Knowledge on OptimisationTheorem 1 of Sussex et al. (2022) bounds the regret with high probability when the graph is known but functions are unknown in the case of soft intervention as \(R_{T}\leq\mathcal{O}(L_{f}^{N}L_{\sigma}^{N}\beta_{T}^{N}K^{N}m\sqrt{T\gamma_ {T}})\) where \(\gamma_{T}=\max_{i}\gamma_{i,T}\), and \(N\) denotes the maximum distance from a root node to \(V_{m}\), \(K=\max_{i}|pa_{\tilde{q}}^{*}(i)|\) as compared to Standard Bayesian Optimisation that makes no use of graph structure resulting in cumulative regret _exponential_ in \(m\). Assuming the use of the Squared Exponential Kernel for modelling all functions, \(\gamma_{T}=\mathcal{O}((K+q)(logT)^{K+q+1})\) scales exponentially with respect to \(K\) and \(q\) the length of each action vector. This results in an expression that scales exponentially in \(K,N\). The theorem demonstrates a potentially exponential improvement in the scaling of cumulative regret for possible actions \(m\geq K+N\).

For environments allowing hard interventions, the optimisation problem can be reduced to the Causal Intrinisic dimension (Aglietti et al., 2020) if interventions on parents are allowed, Lee and Bareinboim (2018) shows results that the optimal intervention is always found among parents. For environments which do not allow direct interventions on parents, the problem can be studied as a soft intervention for the mutilated graph, by treating the intervened nodes as action nodes and propagating uncertainty through the remaining nodes. For certain graphs, the depth \(N\) of the resulting graph can be reduced significantly, consider by figure 1 of Aglietti et al. (2020) with a slight modification where, intervention on the parent nodes \(\{X_{100},Z_{100}\}\) is not possible but we are allowed to intervene on \(\{X_{99},Z_{99}\}\), this allows us to reduce \(N=2\) from \(N=100\), resulting in an exponential improvement in performance.

Convergence to the True GraphAs the posterior mass on the graph distribution converges to the dirac delta distribution on the true graph \(p(g)\rightarrow\delta_{g=g^{*}}\)the cumulative regret converges to the cumulative regret accrued when the graph is known. For hard interventions the posterior convergence to the true graph is guaranteed under a few assumptions. For soft intervention models dags belongingto Markov Equivalence Classes are further distinguished under the assumptions underpinning the gpn models, considering the functions \(f_{i}\), are not generally invertible (Giudice et al., 2023), the gpn usually suggest higher scores to models admitting the true sem structure as confirmed in our numerical experiments. For cases where functions are invertible (Hoyer et al., 2008) guarantees identifiability by leveraging the asymmetry of residual noise distributions.

While asymptotic convergence to the true graph structure is guaranteed, there are no known results for finite samples. However, in our numerical experiments, we observe that the graph converges to the essential graph in a small number of samples and potentially observes exponentially less regret as compared to not knowing the graph henceforth. Several studies have considered the problem of learning the causal structure optimally, Murphy (2001); Tong and Koller (2001); Masegosa and Moral (2013); Hauser and Buhlmann (2014); Kocaoglu et al. (2017). Future work could look at more efficient techniques to learn the structure with finite time guarantees to place an upper bound on the cumulative regret for the case when the graph is unknown apriori.

### Experiment Details

All our experiments were performed on Google Colab without a GPU or TPU enabled, we used random seeds \(47,42,73,66,13\) for 5 repeats for all given algorithms and given environments.

We use the BoTorch library for both our surrogate models and acquisition functions, specifically implementing the acquisition function with the _qSimpleRegret_ module. For each node, we initialize the lengthscales using BoTorch's default prior and set a lower bound on the lengthscale using functionality provided by GPyTorch. Inputs to the individual functions are normalized to the \([0,1]^{d}\) range. To fit the hyperparameters, we maximize the marginal log-likelihood.

### Limitations and Future Work

In the current work we focus on the problem of causal Bayesian optimisation with unknown graphs, however we make several assumptions which may be violated in practice. We assume no unobserved confounders, this assumption is critical to our causal discovery algorithm and our model-based approach for causal Bayesian optimisation is also not resilient to unobserved confounders. We assume additive noise and known noise distribution for each node, this is a strong assumption in practice and needs to be relaxed in future work. Our regularity assumptions might also restrict the application of our method to problems where the relation between a node and its parents is not highly nonlinear. Our current method does not scale well to larger graphs, however, this can be addressed in future work as described in section A.11. We defer providing theoretical guarantees for our method to future work as discussed in A.12.