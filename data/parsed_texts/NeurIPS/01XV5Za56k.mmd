# Testing Calibration in Nearly-Linear Time

Lunjia Hu

Harvard University

lunjia@alumni.stanford.edu &Arun Jambulapati

University of Michigan

jmblpati@gmail.com &Kevin Tian

University of Texas at Austin

kjtian@cs.utexas.edu &Chutong Yang

University of Texas at Austin

cyang98@utexas.edu

###### Abstract

In the recent literature on machine learning and decision making, _calibration_ has emerged as a desirable and widely-studied statistical property of the outputs of binary prediction models. However, the algorithmic aspects of measuring model calibration have remained relatively less well-explored. Motivated by [1], which proposed a rigorous framework for measuring distances to calibration, we initiate the algorithmic study of calibration through the lens of property testing. We define the problem of _calibration testing_ from samples where given \(n\) draws from a distribution \(\mathcal{D}\) on (predictions, binary outcomes), our goal is to distinguish between the cases where \(\mathcal{D}\) is perfectly calibrated or \(\varepsilon\)-far from calibration. We make the simple observation that the empirical smooth calibration linear program can be reformulated as an instance of minimum-cost flow on a highly-structured graph, and design an exact dynamic programming-based solver for it which runs in time \(O(n\log^{2}(n))\), and solves the calibration testing problem information-theoretically optimally in the same time. This improves upon state-of-the-art black-box linear program solvers requiring \(\Omega(n^{\omega})\) time, where \(\omega>2\) is the exponent of matrix multiplication. We also develop algorithms for tolerant variants of our testing problem improving upon black-box linear program solvers, and give sample complexity lower bounds for alternative calibration measures to the one considered in this work. Finally, we present experiments showing the testing problem we define faithfully captures standard notions of calibration, and that our algorithms scale efficiently to accommodate large sample sizes.

## 1 Introduction

Probabilistic predictions are at the heart of modern data science. In domains as wide-ranging as forecasting (e.g. predicting the chance of rain from meteorological data [13, 14]), medicine (e.g. assessing the likelihood of disease [15]), computer vision (e.g. assigning confidence values for categorizing images [12]), and more (e.g. speech recognition [1] and recommender systems [16]), prediction models have by now become essential components of the decision-making pipeline. Particularly in the context of critical, high-risk use cases, the interpretability of prediction models is therefore paramount in downstream applications. That is, how do we assign meaning to the predictions our model gives us, especially when the model is uncertain?

We focus on perhaps the most ubiquitous form of prediction modeling: binary predictions, represented as tuples \((v,y)\) in \([0,1]\times\{0,1\}\) (where the \(v\) coordinate is our prediction of the likelihood of an event, and the \(y\) coordinate is the observed outcome). We model prediction-outcome pairs in the binary prediction setting by a joint distribution \(\mathcal{D}\) over \([0,1]\times\{0,1\}\), fixed in the following discussion. Inthis context, _calibration_ of a predictor has emerged as a basic desideratum. A prediction-outcome distribution \(\mathcal{D}\) is said to be calibrated if

\[\mathbb{E}_{(v,y)\sim\mathcal{D}}[y\mid v=t]=t\text{ for all }t\in[0,1]. \tag{1}\]

That is, calibration asks that the outcome is \(1\) exactly \(60\%\) of the time, when the model returns a prediction \(v=0.6\). While calibration (or approximate variants thereof) is a relatively weak requirement on a meaningful predictor, as it can be achieved by simple models,1 it can still be significantly violated in practice. For example, interest in calibration in the machine learning community was spurred by [13], which observed that many modern deep learning models are far from calibrated. Moreover, variants of calibration have been shown to have strong postprocessing properties for fairness constraints and loss minimization [14, 15, 16, 17], which has garnered renewed interest in calibration by the theoretical computer science and statistics communities.

Footnote 1: The predictor which ignores features and always return the population mean is calibrated, for example.

The question of measuring the calibration of a distribution is subtle; even a calibrated distribution incurs measurement error due to sampling. For example, consider the _expected calibration error_, used in e.g. [15, 13, 14, 15] as a ground-truth measure of calibration:

\[\mathsf{ECE}(\mathcal{D}):=\mathbb{E}_{(v,y)\sim\mathcal{D}}\left[\left| \mathbb{E}_{(v^{\prime},y)\sim\mathcal{D}}\left[y\mid v^{\prime}=v\right]-v \right|\right].\]

Unfortunately, the empirical \(\mathsf{ECE}\) is typically meaningless; if the marginal density of \(v\) is continuous, we will almost surely only observe a single sample with each \(v\) value. Further, [15] observed that \(\mathsf{ECE}\) is discontinuous in \(v\). In practice, binned variants of \(\mathsf{ECE}\) are often used as a proxy, where a range of \(v\) is lumped together in the conditioning event. However, hyperparameter choices (e.g. the number of bins) can significantly affect the quality of binned \(\mathsf{ECE}\) variants as a distance measure [15, 16, 15, 17].2 Moreover, as we explore in this paper, binned calibration measures inherently suffer from larger sample complexity-to-accuracy tradeoffs, and are less faithful to ground truth calibration notions in experiments than the calibration measures we consider.

Footnote 2: For example, [15] observed that, in their words, “dramatic differences in bin sensitivity” can occur “depending on properties of the (distribution) at hand,” a sentiment echoed by Section 5 of [17].

Recently, [15] undertook a systematic study of various measures of distance to calibration proposed in the literature. They proposed information-theoretic tractability in the _prediction-only access (PA) model_, where the calibration measure definition can only depend on the joint prediction-outcome distribution (rather than the features of training examples),3 as a desirable criterion for calibration measures. Correspondingly, [15] introduced Definition 1 as a ground-truth notion for measuring calibration in the PA model, which we also adopt in this work.4

Footnote 3: This access model is practically desirable because it abstracts away the feature space, which can lead to significant memory savings when our goal is only to test the calibration of model predictions. Moreover, this matches conventions in the machine learning literature, e.g. loss functions are typically defined in the PA model.

Footnote 4: We note that [15] introduced an _upper distance to calibration_, also defined in the PA model, which they showed is quadratically-related to the \(\mathsf{dCE}\) in Definition 1. However, the upper distance does not satisfy basic properties such as continuity, making it less amenable to estimation and algorithm design.

**Definition 1** (Lower distance to calibration).: _Let \(\mathcal{D}\) be a distribution over \([0,1]\times\{0,1\}\). The lower distance to calibration (LDTC) of \(\mathcal{D}\), denoted \(\underline{\mathsf{dCE}}(\mathcal{D})\), is defined by_

\[\underline{\mathsf{dCE}}(\mathcal{D}):=\inf_{\Pi\in\mathsf{ext}(\mathcal{D})} \mathbb{E}_{(u,v,y)\sim\Pi}\left|u-v\right|,\]

_where \(\mathsf{ext}(\mathcal{D})\) is all distributions \(\Pi\) over \((u,v,y)\in[0,1]\times[0,1]\times\{0,1\}\) satisfying the following._

* _The marginal distribution of_ \((v,y)\) _is_ \(\mathcal{D}\)_._
* _The marginal distribution_ \((u,y)\) _is perfectly calibrated, i.e._ \(\mathbb{E}_{\Pi}[y|u]=u\)_._

Definition 1 has various beneficial aspects: it is convex in \(v\), computable in the PA model, and (as shown by [15]) polynomially-related to various other calibration measures, including some which require feature access, e.g. the _distance to calibration_ (DTC, Eq. (1), [15]). Roughly, the DTC of a distribution is the tightest lower bound on the \(\ell_{1}\) distance between \(v\) and any calibrated function of the features, _after taking features into account_. The LDTC is the analog of this feature-aware measure of calibration when limited to the PA model, so it does not depend on features. We focus on Definition 1 as our ground-truth measure in the remainder of the paper.

### Our results

We initiate the algorithmic study of the _calibration testing_ problem, defined as follows.

**Definition 2** (Calibration testing).: _Let \(\varepsilon\in[0,1]\). We say algorithm \(\mathcal{A}\) solves the \(\varepsilon\)-calibration testing problem with \(n\) samples, if given \(n\) i.i.d. draws from a distribution \(\mathcal{D}\) over \([0,1]\times\{0,1\}\), \(\mathcal{A}\) returns either "yes" or "no" and satisfies the following with probability \(\geq\frac{2}{3}\).5_

Footnote 5: As is standard in property testing problems, the success probability of either a calibration tester or a tolerant calibration tester can be boosted to \(1-\delta\) for any \(\delta\in(0,1)\) at a \(k=O(\log(\frac{1}{2}))\) overhead in the sample complexity. This is because we can independently call \(k\) copies of the tester and output the majority vote, which succeeds with probability \(\geq 1-\delta\) by Chernoff bounds, so we focus on \(\delta=\frac{1}{3}\).

* \(\mathcal{A}\) _returns "no" if_ \(\underline{\mathsf{dCE}}(\mathcal{D})\geq\varepsilon\)_._
* \(\mathcal{A}\) _returns "yes" if_ \(\underline{\mathsf{dCE}}(\mathcal{D})=0\)_._

_In this case, we also call \(\mathcal{A}\) an \(\varepsilon\)-calibration tester._

To our knowledge, we are the first to formalize the calibration testing problem in Definition 2, which is natural from the perspective of _property testing_, an influential paradigm in statistical learning [14, 15, 16]. In particular, there is an \(\varepsilon_{n}=\Theta(n^{-1/2})\) so that it is information-theoretically impossible to solve the \(\varepsilon_{n}\)-calibration testing problem from \(n\) samples (see Lemma 5), so a variant of Definition 2 with an exact distinguishing threshold between "calibrated/uncalibrated" is not tractable. Hence, Definition 2 only requires distinguishing distributions \(\mathcal{D}\) which are "clearly uncalibrated" (parameterized by a threshold \(\varepsilon\)) from those which are perfectly calibrated.

We note that a variant of Definition 2 where \(\underline{\mathsf{dCE}}\) is replaced by variants of the \(\mathsf{ECE}\) was recently proposed by [10]. However, due to the aforementioned discontinuity and binning choice issues which plague the \(\mathsf{ECE}\), [10] posed as an explicit open question whether an alternative calibration metric makes for a more appropriate calibration testing problem, motivating our Definition 2. Indeed, Proposition 9 of [10] shows that without smoothness assumptions on the data distribution, it is impossible to solve the \(\mathsf{ECE}\) calibration testing problem from finite samples.6

Footnote 6: The work [10] considered \(k\)-class prediction tasks, extending our focus on binary classification (\(k=2\)), which we believe is an exciting future direction. However, their Proposition 9 holds even when \(k=2\).

Our first algorithmic contribution is a nearly-linear time algorithm for calibration testing.

**Theorem 1**.: _Let \(n\in\mathbb{N}\), and \(\varepsilon=\Omega(\varepsilon_{n})\), where \(\varepsilon_{n}=\Theta(n^{-1/2})\) is minimal such that it is information-theoretically possible to solve the \(\varepsilon_{n}\)-calibration testing problem (Definition 2) with \(n\) samples. There is an algorithm which solves the \(\varepsilon\)-calibration testing problem with \(n\) samples, running in time \(O(n\log^{2}(n))\)._

The lower bound on the acceptable range of \(\varepsilon_{n}\) in Theorem 1 is well-known, and recalled in Lemma 5 for completeness. Our main contribution is to prove the upper bound (i.e., achieving \(O(\varepsilon_{n})\)-calibration testing) in Theorem 1 by designing a new algorithm for computing \(\mathsf{smCE}(\widehat{\mathcal{D}}_{n})\), the _smooth calibration error_ (Definition 3), an alternative calibration measure, of an empirical distribution \(\widehat{\mathcal{D}}_{n}\).

**Definition 3** (Smooth calibration error).: _Let \(W\) be the set of Lipschitz functions \(w:[0,1]\to[-1,1]\). The smooth calibration error of distribution \(\mathcal{D}\) over \([0,1]\times\{0,1\}\), denoted \(\mathsf{smCE}(\mathcal{D})\), is_

\[\mathsf{smCE}(\mathcal{D})=\sup_{w\in W}\left|\mathbb{E}_{(v,y)\sim\mathcal{D }}[(y-v)w(v)]\right|.\]

It was shown in [1] that \(\mathsf{smCE}(\mathcal{D})\) is a constant-factor approximation to \(\underline{\mathsf{dCE}}(\mathcal{D})\) for all \(\mathcal{D}\) on \([0,1]\times\{0,1\}\) (see Lemma 4). Additionally, the empirical \(\mathsf{smCE}\) admits a representation as a linear program with an \(O(n)\times O(n)\)-sized constraint matrix encoding Lipschitz constraints.7 Thus, [1] proposed a simple procedure for estimating \(\mathsf{smCE}(\mathcal{D})\): draw \(n\) samples from \(\mathcal{D}\), and solve the associated linear program on the empirical distribution. While there have been significant recent runtime advances in the linear programming literature [13, 14, 15, 16], \(\mathsf{vBLLS20}\), \(\mathsf{vBLLL}^{+}21\)], all state-of-the-art black-box linear programming algorithms solve linear systems involving the constraint matrix, which takes \(\Omega(n^{\omega})\) time, where \(\omega>2.371\)[17] is the current exponent ofmatrix multiplication. Even under the best-possible assumption that \(\omega=2\), the strategy of exactly solving a linear program represents an \(\Omega(n^{2})\) quadratic runtime barrier for calibration testing.

We bypass this barrier by noting that the smCE linear program is highly-structured, and can be reformulated as minimum-cost flow on a planar graph. We believe this observation is already independently interesting, as it opens the door to using powerful software packages designed for efficiently solving flow problems to measure calibration in practice. Moreover, using recent theoretical breakthroughs in graph algorithms [3, 14, 15] as a black box, this observation readily implies an \(O(n\cdot\text{polylog}(n))\)-time algorithm for solving the smooth calibration linear program.

However, these aforementioned algorithms are quite complicated, and implementations in practice are not available, leaving their relevance to empirical calibration testing unclear at the moment. Motivated by this, in Section 2 we develop a custom solver for the minimum-cost flow reformulation of empirical smooth calibration, based on dynamic programming. Our theoretical runtime improvement upon [3, 14, 15] is by at least a large polylogarithmic factor, and moreover our algorithm is simple enough to implement in practice, where it attains faster runtimes than general-purpose commercial solvers on moderate or large dataset sizes, evaluated in Section 3.

We further define a _tolerant_ variant of Definition 2 (see Definition 4), where we allow for error thresholds in both the "yes" and "no" cases; "yes" is the required answer when \(\underline{\text{dCE}}(\mathcal{D})\leq\varepsilon_{2}\), and "no" is required when \(\underline{\text{dCE}}(\mathcal{D})\geq\varepsilon_{1}\). Our algorithm in Theorem 1 continues to serve as an efficient tolerant calibration tester when \(\varepsilon_{1}\geq 4\varepsilon_{2}\), formally stated in Theorem 3. This constant-factor loss comes from a similar loss in the relationship between smCE and dCE, see Lemma 4. We make the observation that a constant factor loss in the tolerant testing parameters is inherent following this strategy, via a lower bound in Lemma 13. Thus, even given infinite samples, computing the smooth calibration error cannot solve tolerant calibration testing all the way down to the information-theoretic threshold \(\varepsilon_{1}\geq\varepsilon_{2}\). To develop an improved tolerant calibration tester, we directly show how to approximate the LDTC of an empirical distribution, our second main algorithmic contribution.

**Theorem 2** (Informal, see Theorem 4, Corollary 3).: _Let \(n\in\mathbb{N}\), and let \(\varepsilon_{1}-\varepsilon_{2}=\Omega(\varepsilon_{n})\), where \(\varepsilon_{n}=\Theta(n^{-1/2})\) is minimal such that it is information-theoretically possible to solve the \(\varepsilon_{n}\)-calibration testing problem (Definition 4) with \(n\) samples. There is an algorithm which solves the \((\varepsilon_{1},\varepsilon_{2})\)-tolerant calibration testing problem with \(n\) samples, running in time \(O(\frac{n\log(n)}{(\varepsilon_{1}-\varepsilon_{2})^{2}})=O(n^{2}\log(n))\)._

While Theorem 2 is slower than Theorem 1, it directly approximates the LDTC, making it applicable to tolerant calibration testing. We mention that state-of-the-art black-box linear programming based solvers, while still applicable to (a discretizeation of) the empirical LDTC, require \(\Omega(n^{2.5})\) time [16], even if \(\omega=2\). This is because the constraint matrix for the \(\varepsilon\)-approximate empirical LDTC linear program has dimensions \(O(\frac{n}{\varepsilon})\times O(n)\), resulting in an \(\approx\frac{1}{\varepsilon}=\Omega(\sqrt{n})\) overhead in the dimension of the decision variable. We prove Theorem 2 in Appendix C, where we use recent advances in minimax optimization [16] and a custom combinatorial rounding procedure to develop a faster algorithm, improving state-of-the-art linear programming runtimes by an \(\Omega(\sqrt{n})\) factor.

In Appendix D, we complement our algorithmic results with lower bounds (Theorems 5, 6) on the sample complexity required to solve variants of the testing problem in Definition 2, when dCE is replaced with different calibration measures. For several widely-used distances in the machine learning literature, including binned and convolved variants of ECE[17, 18], we show that \(\widetilde{\Omega}(\varepsilon^{-2.5})\) samples are required to the associated \(\varepsilon\)-calibration testing problem. This demonstrates a statistical advantage of our focus on dCE as our ground-truth notion for calibration testing.

We corroborate our theoretical findings with experimental evidence on real and synthetic data in Section 3. First, on a simple Bernoulli example, we show that dCE and smCE testers are more reliable measures of calibration than a recently-proposed binned ECE variant. We then apply our smCE tester to postprocessed neural network predictions to test their calibration levels, validating against the findings in [16]. Finally, we implement our method from Theorem 1 on our Bernoulli dataset, showing that it scales to high dimensions and runs faster than both a linear program solver from CVXPY for computing the empirical smCE, as well as a commercial minimum-cost flow solver from Gurobi Optimization (combined with our reformulation in Lemma 2).8

Footnote 8: Our code is included in the supplementary material.

### Our techniques

Theorems 1 and 2 follow from designing custom algorithms for approximating empirical linear programs associated with the smCE and dCE of a sampled dataset \(\widehat{\mathcal{D}}_{n}:=\{(v_{i},y_{i})\}_{i\in[n]}\sim_{\text{i.i.d.}}\mathcal{D}\). In both cases, generalization bounds from [1] show it suffices to approximate the value of the empirical calibration measures to error \(\varepsilon=\Omega(n^{-1/2})\), though our solver in Theorem 1 will be exact.

We begin by explaining our strategy for estimating \(\mathsf{smCE}(\widehat{\mathcal{D}}_{n})\) (Definition 3). By definition, the smooth calibration error of \(\widehat{\mathcal{D}}_{n}\) can be formulated as a linear program,

\[\min_{x\in[-1,1]^{n}}\frac{1}{n}\sum_{i\in[n]}x_{i}(v_{i}-y_{i}),\text{ where }|x_{i}-x_{j}|\leq|v_{i}-v_{j}|\text{ for all }(i,j)\in[n]\times[n]. \tag{2}\]

Here, \(x_{i}\in[-1,1]\) corresponds to the weight on \(v_{i}\), and there are \(2\binom{n}{2}\) constraints on the decision variable \(x\), each of which corresponds to a Lipschitz constraint. We make the simple observation that every Lipschitz inequality constraint can be replaced by two constraints of the form \(x_{i}-x_{j}\leq|v_{j}-v_{i}|\) (with \(i,j\) swapped). Moreover, the box constraints \(x\in[-1,1]^{n}\) can be handled by introducing a dummy variable \(x_{n+1}\) and writing \(\max(x_{i}-x_{n+1},x_{n+1}-x_{i})\leq 1\), after penalizing \(x_{n+1}\) appropriately in the objective. Notably, this substitution makes every constraint the difference of two decision variables, which is enforceable using the edge-vertex incidence matrix of a graph. Finally, the triangle inequality implies that we only need to enforce Lipschitz constraints in (2) corresponding to adjacent \(i,j\). After making these simplifications, the result is the dual of a minimum-cost flow problem on a graph which is the union of a star and a path; this argument is carried out in Lemma 2.

Because of the sequential structure of the induced graph, we show in Appendix B.2 that a dynamic programming-based approach, which maintains the minimum-cost flow value after committing to the first \(i<n\) flow variables in the graph recursively, succeeds in computing the value (2). To implement each iteration of our dynamic program in polylogarithmic time, we rely on a generalization of the classical segment tree data structure that we develop in Appendix B.3; combining gives Theorem 1.

On the other hand, the linear program corresponding to the empirical dCE is more complex (with two types of constraints), and to our knowledge lacks the graphical structure to be compatible with the aforementioned approach. Moreover, it is not obvious how to use first-order methods, an alternative linear programming framework suitable when only approximate answers are needed, to solve this problem more quickly. This is because the empirical dCE linear program enforces hard constraints to a set that is difficult to project to under standard distance metrics. To develop our faster algorithm in Theorem 2, we instead follow an "augmented Lagrangian" method where we lift the constraints directly into the objective as a soft-constrained penalty term. To prove correctness of this lifting, we follow a line of results in combinatorial optimization [14, 15]. These works develop a "proof-by-rounding algorithm" framework to show that the hard-constrained and soft-constrained linear programs have equal values, summarized in Appendix C.1 (see Lemma 14).

To use this augmented Lagrangian framework, it remains to develop an appropriate rounding algorithm to the feasible polytope for the empirical dCE linear program, which enforces two types of constraints: marginal satisfaction of \((v,y)\), and calibration of \((u,y)\) (using notation from Definition 1). In Appendix C.3, we design a two-step rounding procedure, which first fixes the marginals on the \((v,y)\) coordinates, and then calibrates the \(u\) coordinates without affecting any \((v,y)\) marginal.

### Related work

The calibration performance of deep neural networks has been studied extensively in the literature (e.g. [17, 18, 19, 20, 21]). Measuring the calibration error in a meaningful way can be challenging, especially when the predictions are not naturally discretized (e.g. in neural networks). Recently, [1] addresses this challenge using the _distance to calibration_ as a central notion. They consider a calibration measure to be _consistent_ if it is polynomially-related to the distance to calibration. Consistent calibration measures include the smooth calibration error [13], Laplace kernel calibration error [16], interval calibration error [1], and convolved ECE [2].9On the algorithmic front, substantial observations were made by [1] on linear programming characterizations of calibration measures such as the LDTC and smooth calibration. While there have been significant advances on the runtime frontier of linear programming solvers, current runtimes for handling an \(n\times d\) linear program constraint matrix with \(n\geq d\) remain \(\Omega(\min(nd+d^{2.5},n^{\omega}))\)[13, vdBLL\({}^{+}\)21, JSWZ21]. Our constraint matrix is roughly-square and highly-sparse, so it is plausible that e.g. the recent research on sparse linear system solvers [20, 19] could apply to the relevant Newton's method subproblems and improve upon these rates. Moreover, while efficient estimation algorithms have been proposed by [1] for (surrogate) interval calibration error and by [14] for convolved ECE, these algorithms require suboptimal sample complexity for solving our testing task in Definition 2 (see Appendix D). To compute their respective distances to error \(\varepsilon\) from samples, these algorithms require \(\Omega(\varepsilon^{-5})\) and \(\Omega(\varepsilon^{-3})\) time. As comparison, under this parameterization Theorems 1 and 2 require \(\widetilde{O}(\varepsilon^{-2})\) and \(\widetilde{O}(\varepsilon^{-4})\) time, but can solve stronger testing problems with the same sample complexity, experimentally validated in Section 3.

Notation.Throughout, \(\mathcal{D}\) denotes a distribution over \([0,1]\times\{0,1\}\). When \(\mathcal{D}\) is clear from context, we let \(\widehat{\mathcal{D}}_{n}=\{(v_{i},y_{i})\}_{i\in[n]}\) denote a dataset of \(n\) independent samples from \(\mathcal{D}\) and, in a slight abuse of notation, the distribution with probability \(\frac{1}{n}\) for each \((v_{i},y_{i})\). We say \(\mathrm{d}\) is a _calibration measure_ if it takes distributions on \([0,1]\times\{0,1\}\) to the nonnegative reals \(\mathbb{R}_{\geq 0}\), so \(\mathsf{dCE}\) (Definition 1) and \(\mathsf{smCE}\) (Definition 3) are both calibration measures. We use \(\widetilde{O}\) and \(\widetilde{\Omega}\) to hide polylogarithmic factors in the argument. We denote \([n]:=\{i\in\mathbb{N}\mid i\leq n\}\). We denote matrices in boldface throughout. For any \(\mathbf{A}\in\mathbb{R}^{m\times n}\), we refer to its \(i^{\text{th}}\) row by \(\mathbf{A}_{i:}\) and its \(j^{\text{th}}\) column by \(\mathbf{A}_{:j}\). For a set \(S\) identified with rows of a matrix \(\mathbf{A}\), we let \(\mathbf{A}_{s:}\) denote the row indexed by \(s\in S\), and use similar notation for columns. For a directed graph \(G=(V,E)\), we define its edge-vertex incidence matrix \(\mathbf{B}\in\{-1,0,1\}^{E\times V}\) which has a row corresponding to each \(e=(u,v)\in E\) with \(\mathbf{B}_{eu}=1\) and \(\mathbf{B}_{ev}=-1\). When \(G\) is undirected, we similarly define \(\mathbf{B}\in\{-1,0,1\}^{E\times V}\) with arbitrary edge orientations.

## 2 Smooth calibration

In this section, we overview our main result on approximating the smooth calibration of a distribution on \([0,1]\times\{0,1\}\), deferring some aspects of the proof to Appendix B. We first show that the linear program corresponding to the smooth calibration of an empirical distribution can be reformulated as an instance of minimum-cost flow on a highly-structured graph. We then explain our dynamic programming approach to solving this minimum-cost flow problem and state a runtime guarantee. Finally, we give our main result on near-linear time calibration testing, Theorem 1.

Throughout this section, we fix a dataset under consideration, \(\widehat{\mathcal{D}}_{n}:=\{(v_{i},y_{i})\}_{i\in[n]}\subset[0,1]\times\{0,1\}\), and the corresponding empirical distribution (which, in an abuse of notation, we also denote \(\widehat{\mathcal{D}}_{n}\)), i.e. we use \((v,y)\sim\widehat{\mathcal{D}}_{n}\) to mean that \((v,y)=(v_{i},y_{i})\) with probability \(\frac{1}{n}\) for each \(i\in[n]\). We also assume without loss of generality that the \(\{v_{i}\}_{i\in[n]}\) are in sorted order, so \(0\leq v_{1}\leq\ldots\leq v_{n}\leq 1\). Recalling Definition 3, the associated empirical smooth calibration linear program is

\[\mathsf{smCE}(\widehat{\mathcal{D}}_{n}) :=\max_{x\in[-1,1]^{n}}b^{\top}x, \tag{3}\] \[\text{where }|x_{i}-x_{j}| \leq v_{j}-v_{i}\text{ for all }(i,j)\in[n]\times[n]\text{ with }i<j,\] \[\text{ and }b_{i} :=\frac{1}{n}(y_{i}-v_{i})\text{ for all }i\in[n].\]

We first make a simplifying observation, which shows that it suffices to replace the Lipschitz constraints in (3) with only the Lipschitz constraints corresponding to adjacent indices \((i,j)\).

**Lemma 1**.: _If \(x,v\in\mathbb{R}^{n}\), where \(v\) has monotonically nondecreasing coordinates, and \(|x_{i}-x_{i+1}|\leq v_{i+1}-v_{i}\) for all \(i\in[n-1]\), then \(|x_{i}-x_{j}|\leq v_{j}-v_{i}\) for all \((i,j)\in[n]\times[n]\) with \(i<j\)._

We now reformulate (3) as a (variant of a) minimum-cost flow problem.

**Lemma 2**.: _Consider an instance of (3). Let \(G=(V,E)\) be an undirected graph on \(n+1\) vertices labeled by \(V:=[n+1]\), and with \(2n-1\) directed edges \(E\) defined and with edge costs as follows._

* _For all_ \(i\in[n-1]\)_, there is an edge between vertices_ \((i,i+1)\) _with edge cost_ \(v_{i+1}-v_{i}\)* _For all_ \(i\in[n]\)_, there is an edge between vertices_ \((i,n+1)\) _with edge cost_ \(1\)_._

_Let \(c\in\mathbb{R}^{E}\) be the vector of all edge costs, let \(d\in\mathbb{R}^{n+1}\) be the demand vector which concatenates \(-b\) in (3) with a last coordinate set to \(\sum_{i\in[n]}b_{i}\), and let \(\mathbf{B}\in\{-1,0,1\}^{E\times V}\) be the edge-vertex incidence matrix of \(G\). Then the problem_

\[\min_{\begin{subarray}{c}f\in\mathbb{R}^{E}\\ \mathbf{B}^{\top}f=d\end{subarray}}c^{\top}|f|:=\sum_{e\in E}c_{e}|f_{e}| \tag{4}\]

_has the same value as the empirical smooth calibration linear program (3)._

Proof.: By Lemma 1, solving (3) is equivalent to solving

\[\min_{x\in[-1,1]^{n}}-b^{\top}x,\text{ where }|x_{i}-x_{i+1}|\leq v_{i+1}-v_{i }\text{ for all }i\in[n-1], \tag{5}\]

We create a dummy variable \(x_{n+1}\), and rewrite (5) as

\[\min_{x\in\mathbb{R}^{n+1}}\sum_{i\in[n]}-b_{i}(x_{i}-x_{n+1}), \text{ where }|x_{i}-x_{i+1}|\leq v_{i+1}-v_{i}\text{ for all }i\in[n-1], \tag{6}\] \[\text{ and }-1\leq x_{i}-x_{n+1}\leq 1\text{ for all }i\in[n].\]

Next, consider a directed graph \(\widetilde{G}=(V,\widetilde{E})\) with \(4n-2\) edges which duplicate the undirected edges described in the lemma statement in both directions. Let \(\widetilde{\mathbf{B}}\in\{-1,0,1\}^{\widetilde{E}\times V}\) be the edge-vertex incidence matrix of \(\widetilde{G}\), and let \(\tilde{c}\in\mathbb{R}^{\widetilde{E}}\) be the edge cost vector so that both edges in \(\widetilde{E}\) corresponding to \(e\in E\) have the same cost \(c_{e}\). Then (6) is equivalent to the linear program \(\max_{x\in\mathbb{R}^{n+1}}d^{\top}x\) such that \(\widetilde{\mathbf{B}}x\leq c\), where \(d\) is described as in the lemma statement. The dual of this linear program is

\[\min_{\begin{subarray}{c}f\in\mathbb{R}^{\widetilde{E}}_{o}\\ \widetilde{\mathbf{B}}^{\top}f=d\end{subarray}}\tilde{c}^{\top}f, \tag{7}\]

a minimum-cost flow problem on \(\widetilde{G}\). In particular, based on the way we defined \(\widetilde{\mathbf{B}}\), we can check that \(\widetilde{\mathbf{B}}^{\top}f\) encodes the net flow at each vertex of \(\widetilde{G}\), which is set according to the demand vector \(d\) in the above optimization problem. Next, for each pair of directed edges \((e^{\prime},e^{\prime\prime})\) in \(\widetilde{G}\) corresponding to some \(e\in E\), note that an optimal solution to (7) will only put nonzero flow on one of \(e^{\prime}\) or \(e^{\prime\prime}\), else we can achieve a smaller cost by canceling out redundant flow. Therefore, we can collapse each pair of directed edges into a single undirected edge, where we allow the flow variable \(f\) to be negative but charge its magnitude \(|f|\) in cost, proving equivalence of (7) and (4) as claimed. 

We believe this observation in Lemma 2 is already interesting, as it lets us to use specialized graph algorithms to achieve faster runtimes in both theory and practice for solving (3). By using the special structure of the graph (the union of a star and path), we show in Appendix B that we can develop a more efficient custom algorithm for this problem. Specifically, we show how to replace the constrained problem (4) with an unconstrained problem on only the path edges, of the form

\[\min_{f\in\mathbb{R}^{n-1}}A(f):=|d_{1}+f_{1}|+|d_{n}-f_{n-1}|+\sum_{i\in[n-2] }|f_{i}-f_{i+1}-d_{i+1}|+\sum_{i\in[n-1]}c_{i}|f_{i}|. \tag{8}\]

We prove the following result in Appendix B.2.

**Proposition 1**.: _There is an algorithm which computes a minimizer \(f\in\mathbb{R}^{n-1}\) to \(A\) in (8), as well as the minimizing value \(A(f)\), in time \(O(n\log^{2}(n))\)._

Figure 1: Example graph \(G\) for \(n=5\) with \(n+1=6\) vertices and \(2n-1=9\) edges.

Our algorithm for establishing Proposition 1 is based on dynamic programming, and recursively represents partial solutions to \(A\) as a piecewise-linear function. We implement updates to this representation via a _segment tree_ data structure in polylogarithmic time, giving our overall solution.

**Corollary 1**.: _There is an algorithm which computes the value of (3) in time \(O(n\log^{2}(n))\)._

Proof.: This is immediate from Lemma 2, the equivalence between the constrained problem (4) and the unconstrained problem (8) established in Appendix B.2, and Proposition 1. 

We now describe how to build upon Corollary 1 to give an algorithm for proving Theorem 1, using a result from [1] which bounds how well the smooth calibration of an empirical distribution approximates the smooth calibration of the population.

**Lemma 3** (Corollary 9.9, [1]).: _For \(\varepsilon\in(0,1)\), there is an \(n=O(\frac{1}{\varepsilon^{2}})\) such that if \(\widehat{\mathcal{D}}_{n}\) is the empirical distribution over \(n\) i.i.d. draws from \(\mathcal{D}\), with probability \(\geq\frac{2}{3}\), \(|\mathsf{smCE}(\mathcal{D})-\mathsf{smCE}(\widehat{\mathcal{D}}_{n})|\leq\varepsilon\)._

Further, we recall the smooth calibration error is constant-factor related to the LDTC.

**Lemma 4** (Theorem 7.3, [1]).: _For any distribution \(\mathcal{D}\) over \([0,1]\times\{0,1\}\), we have \(\frac{1}{2}\underline{\mathsf{dCE}}(\mathcal{D})\leq\mathsf{smCE}(\mathcal{D}) \leq 2\underline{\mathsf{dCE}}(\mathcal{D})\)._

Proof of Theorem 1.: We take \(n=O(\frac{1}{\varepsilon^{2}})\) samples so Lemma 3 ensures \(|\mathsf{smCE}(\mathcal{D})-\mathsf{smCE}(\widehat{\mathcal{D}}_{n})|\leq\frac {\varepsilon}{2}\) with probability \(\geq\frac{2}{3}\). We then compute \(\beta=\mathsf{smCE}(\widehat{\mathcal{D}}_{n})\) using Corollary 1, and return "yes" iff \(\beta\leq\frac{\varepsilon}{4}\), which distinguishes between the two cases in Definition 2 via Lemma 4. 

## 3 Experiments

In this section, we present experiments on synthetic data and CIFAR-100 supporting our argument that \(\underline{\mathsf{dCE}}\) and \(\mathsf{smCE}\) are reliable measures of calibration for use in defining a testing problem. We then evaluate our custom algorithms from Section 2 and Appendix B, showing promising results on their runtimes outperforming standard packages for linear programming and minimum-cost flow. The experiments in the first and third part of this section are run on a 2018 laptop with 2.2 GHz 6-Core Intel Core i7 processor. The experiments in the second part are run on a cluster using 2x AMD EPYC 7763 64-Core Processor and a single NVIDIA A100 PCIE 40GB.

Synthetic dataset.In our first experiment, we considered the ability of \(\varepsilon\)-d-testers (Definition 5) to detect the miscalibration of a synthetic dataset, for various levels of \(\varepsilon\in\{0.01,0.03,0.05,0.07,0.1\}\), and various choices of \(\mathsf{d}\in\{\mathsf{smCE},\underline{\mathsf{dCE}},\mathsf{ConvECE}\}\).10 The synthetic dataset we used is \(n\) independent draws from \(\mathcal{D}\), where a draw \((v,y)\sim\mathcal{D}\) first draws \(v\sim_{\text{unif.}}[0,1-\varepsilon^{\star}]\), and \(y\sim\mathsf{Bern}(v+\varepsilon^{\star})\), for \(\varepsilon^{\star}:=0.01\).11 Note that \(\underline{\mathsf{dCE}}(\mathcal{D})=\varepsilon^{\star}=0.01\), by the proof in Lemma 13. In Table 1, where the columns index \(n\) (the number of samples), for each choice of \(\mathsf{d}\) we report the smallest value of \(\varepsilon\) such that a majority of \(100\) runs of an \(\varepsilon\)-\(\mathsf{d}\)-tester report "yes." For \(\mathsf{d}=\mathsf{ConvECE}\), we implemented our tester by running code in [1] to compute \(\mathsf{ConvECE}\) and thresholding at \(\frac{\varepsilon}{2}\). For \(\mathsf{d}\in\{\mathsf{smCE},\underline{\mathsf{dCE}}\}\), we used the standard linear program solver from CVXPY [1, 1] and again thresholded at \(\frac{\varepsilon}{2}\). We remark that the CVXPY solver, when run on the \(\underline{\mathsf{dCE}}\) linear program, fails to produce stable results for \(n>2^{9}\) due to the size of the constraint matrix. As seen from Table 1, both \(\mathsf{smCE}\) and \(\underline{\mathsf{dCE}}\) testers are more reliable estimators of the ground truth calibration error \(\varepsilon^{\star}\) than \(\mathsf{ConvECE}\).

Footnote 10: We implemented \(\mathsf{ConvECE}\) using code from [1], which automatically conducts a search for \(\sigma\).

Footnote 11: This is a slight variation on the synthetic dataset used in [1].

\begin{table}
\begin{tabular}{|c|c c c c c c|} \hline \(n\) & \(2^{6}+1\) & \(2^{7}+1\) & \(2^{8}+1\) & \(2^{9}+1\) & \(2^{10}+1\) & \(2^{11}+1\) \\ \hline \(\mathsf{smCE}\) & \(0.07\) & \(0.05\) & \(0.03\) & \(0.03\) & \(0.01\) & \(0.01\) \\ \hline \(\underline{\mathsf{dCE}}\) & \(0.03\) & \(0.01\) & \(0.01\) & & & \\ \hline \(\underline{\mathsf{cECE}}\) & \(0.1\) & \(0.1\) & \(0.07\) & \(0.07\) & \(0.05\) & \(0In Figure 2, we plot the median error with error bars for each calibration measure, where the \(x\) axis denotes \(\log_{2}(n-1)\), and results are reported over \(100\) runs.

Postprocessed neural networks.In [14], which observed modern deep neural networks may be very miscalibrated, various strategies were proposed for postprocessing network predictions to calibrate them. We evaluate two of these strategies using our testing algorithms. We trained a DenseNet40 model [12] on the CIFAR-100 dataset [15], producing a distribution \(\mathcal{D}_{\text{base}}\), where a draw \((v,y)\sim\mathcal{D}_{\text{base}}\) selects a random example from the test dataset, sets \(y\) to be its label, and \(v\) to be the prediction of the neural network. We also learned calibrating postprocessing functions \(f_{\text{iso}}\) and \(f_{\text{temp}}\) from the training dataset, the former via isotonic regression and the latter via temperature scaling. These induce (ideally, calibrated) distributions \(\mathcal{D}_{\text{iso}}\), \(\mathcal{D}_{\text{temp}}\), where a draw from \(\mathcal{D}_{\text{iso}}\) samples \((v,y)\sim\mathcal{D}_{\text{base}}\) and returns \((f_{\text{iso}}(v),y)\), and \(\mathcal{D}_{\text{temp}}\) is defined analogously. The neural network and postprocessing functions were all trained by adapting code from [14].

We computed the median smooth calibration error of \(20\) runs of the following experiment. In each run, for each \(\mathcal{D}\in\{\mathcal{D}_{\text{base}},\mathcal{D}_{\text{iso}},\mathcal{D }_{\text{temp}}\}\), we drew \(256\) random examples from \(\mathcal{D}\), and computed the average smooth calibration error smCE of the empirical dataset using a linear program solver from CVXPY. We report our findings in Table 2. We also compared computing smCE using the CVXPY solver and a commercial minimum-cost flow solver from Gurobi Optimization [16] (on the objective from Lemma 2) in this setting. The absolute difference between outputs is smaller than \(10^{-5}\) in all cases, verifying that minimum-cost flow solvers accurately measure smooth calibration.

Qualitatively, our results (based on smCE) agree with findings in [14] (based on binned variants of ECE), in that temperature scaling appears to be the most effective postprocessing technique.

smCE tester.Finally, we evaluated the efficiency of our proposed approaches to computing the empirical smCE. Specifically, we measure the runtime of four solvers for computing (3): a linear program solver from CVXPY, a commercial minimum-cost flow solver from Gurobi Optimization, a naive implementation of our algorithm from Corollary 1 using Python, and a slightly-optimized implementation using the PyPy package [13]. We use the same experimental setup as in Table 1, i.e. measuring calibration of a uniform predictor on a miscalibrated synthetic dataset, with \(\epsilon^{*}=0.01\).12 In Table 3, we report the average runtimes for each trial (across \(10\) runs), varying the sample size. Again, the absolute difference between the outputs of all methods is negligible (\(\leq 10^{-9}\) in all cases). As seen in Table 3, our custom algorithm (optimized with PyPy) outperforms standard packages from CVXPY and Gurobi Optimization starting from moderate sample sizes. We believe that Table 3 demonstrates that our new algorithms are a scalable, reliable way of testing calibration, and that these performance gains may be significantly improvable by further optimizing our code.

Footnote 12: We found similar runtime trends when using our algorithms to test calibration on the postprocessed neural network dataset, but the runtime gains were not as drastic as the sample size \(n=2^{8}\) was smaller in that case.

\begin{table}
\begin{tabular}{|c|c c c|} \hline \(\mathcal{D}\) & \(\mathcal{D}_{\text{base}}\) & \(\mathcal{D}_{\text{iso}}\) & \(\mathcal{D}_{\text{temp}}\) \\ \hline Empirical smCE & \(0.2269\) & \(0.2150\) & \(0.1542\) \\ \hline \end{tabular}
\end{table}
Table 2: Empirical smCE on postprocessed DenseNet40 predictions (median over \(20\) runs)

Figure 2: The \(25\%\) quantile, median, and \(75\%\) quantile (over \(100\) runs) for smCE, dCE and cECE respectively. The \(x\)-axis is for dataset with size \(2^{x}+1\).

## Acknowledgements

We thank Edgar Dobriban for pointing us to the reference [13], and Yang P. Liu and Richard Peng for helpful discussions on the segment tree data structure in Section B.3. We also thank Yue Zhao for advice on running our experiments.

## References

* [AAA\({}^{+}\)16] Dario Amodei, Sundaram Ananthanarayanan, Rishita Anubhai, Jingliang Bai, Eric Battenberg, Carl Case, Jared Casper, Bryan Catanzaro, Jingdong Chen, Mike Chrzanowski, Adam Coates, Greg Diamos, Erich Elsen, Jesse H. Engel, Linxi Fan, Christopher Fougner, Awni Y. Hannun, Billy Jun, Tony Han, Patrick LeGresley, Xiangang Li, Libby Lin, Sharan Narang, Andrew Y. Ng, Sherjil Ozair, Ryan Prenger, Sheng Qian, Jonathan Raiman, Sanjeev Satheesh, David Seetapun, Shubho Sengupta, Chong Wang, Yi Wang, Zhiqian Wang, Bo Xiao, Yan Xie, Dani Yogatama, Jun Zhan, and Zhenyao Zhu. Deep speech 2 : End-to-end speech recognition in english and mandarin. In _Proceedings of the 33nd International Conference on Machine Learning, ICML 2016_, volume 48 of _JMLR Workshop and Conference Proceedings_, pages 173-182. JMLR.org, 2016.
* [AVDB18] Akshay Agrawal, Robin Verschueren, Steven Diamond, and Stephen Boyd. A rewriting system for convex optimization problems. _Journal of Control and Decision_, 5(1):42-60, 2018.
* [BGHN23a] Jaroslaw Blasiok, Parikshit Gopalan, Lunjia Hu, and Preetum Nakkiran. A unifying theory of distance from calibration. In _Proceedings of the 55th Annual ACM Symposium on Theory of Computing_, pages 1727-1740, 2023.
* [BGHN23b] Jaroslaw Blasiok, Parikshit Gopalan, Lunjia Hu, and Preetum Nakkiran. When does optimizing a proper loss yield calibration? _arXiv preprint arXiv:2305.18764_, 2023.
* [BN23] Jaroslaw Blasiok and Preetum Nakkiran. Smooth ECE: Principled reliability diagrams via kernel smoothing. _arXiv preprint arXiv:2309.12236_, 2023.
* [Can22] Clement L. Canonne. Topics and techniques in distribution testing: A biased but representative sample. _Foundations and Trends(r) in Communications and Information Theory_, 19(6):1032-1198, 2022.
* [CKL\({}^{+}\)22] Li Chen, Rasmus Kyng, Yang P Liu, Richard Peng, Maximilian Probst Gutenberg, and Sushant Sachdeva. Maximum flow and minimum-cost flow in almost-linear time. In _2022 IEEE 63rd Annual Symposium on Foundations of Computer Science (FOCS)_, pages 612-623. IEEE, 2022.
* [CLS21] Michael B. Cohen, Yin Tat Lee, and Zhao Song. Solving linear programs in the current matrix multiplication time. _J. ACM_, 68(1):3:1-3:39, 2021.
* Leibniz-Zentrum fur Informatik, 2021.
* [DB16] Steven Diamond and Stephen Boyd. CVXPY: A Python-embedded modeling language for convex optimization. _Journal of Machine Learning Research_, 17(83):1-5, 2016.

\begin{table}
\begin{tabular}{|c|c c c c c c|} \hline \(n\) & \(2^{10}\) & \(2^{11}\) & \(2^{12}\) & \(2^{13}\) & \(2^{14}\) & \(2^{15}\) \\ \hline CVXPY LP solver & \(0.105\) & \(0.370\) & \(1.58\) & \(6.51\) & \(45.7\) & \(245\) \\ \hline Gurobi minimum-cost flow solver & \(0.063\) & \(0.179\) & \(0.238\) & \(0.539\) & \(1.45\) & \(3.19\) \\ \hline Solver from Corollary 1 & \(0.177\) & \(0.389\) & \(0.899\) & \(2.01\) & \(4.66\) & \(10.6\) \\ \hline Solver from Corollary 1 with PyPy & \(0.079\) & \(0.115\) & \(0.176\) & \(0.307\) & \(0.621\) & \(2.05\) \\ \hline \end{tabular}
\end{table}
Table 3: Runtimes (in seconds) for computing the value of (3), using various solvers* [DGG\({}^{+}\)22] Sally Dong, Yu Gao, Gramoz Goranci, Yin Tat Lee, Richard Peng, Sushant Sachdeva, and Guanghao Ye. Nested dissection meets ipms: Planar min-cost flow in nearly-linear time. In _Proceedings of the 2022 ACM-SIAM Symposium on Discrete Algorithms, SODA 2022_, pages 124-153. SIAM, 2022.
* [DKR\({}^{+}\)21] Cynthia Dwork, Michael P. Kim, Omer Reingold, Guy N. Rothblum, and Gal Yona. Outcome indistinguishability. In _STOC '21: 53rd Annual ACM SIGACT Symposium on Theory of Computing, 2021_, pages 1095-1108. ACM, 2021.
* [Doi07] Kunio Doi. Computer-aided diagnosis in medical imaging: historical review, current status and future potential. _Computerized medical imaging and graphics_, 31(4-5):198-211, 2007.
* Leibniz-Zentrum fur Informatik, 2022.
* [Gol17] Oded Goldreich. _Introduction to Property Testing_. Cambridge University Press, 2017.
* [GPSW17] Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. On calibration of modern neural networks. In _International conference on machine learning_, pages 1321-1330. PMLR, 2017.
* [HKRR18] Ursula Hebert-Johnson, Michael P. Kim, Omer Reingold, and Guy N. Rothblum. Multicalibration: Calibration for the (computationally-identifiable) masses. In _Proceedings of the 35th International Conference on Machine Learning, ICML 2018_, volume 80 of _Proceedings of Machine Learning Research_, pages 1944-1953. PMLR, 2018.
* [HLvdMW17] Gao Huang, Zhuang Liu, Laurens van der Maaten, and Kilian Q. Weinberger. Densely connected convolutional networks. In _2017 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017_, pages 2261-2269. IEEE Computer Society, 2017.
* [IS03] Y. I. Ingster and I. A. Suslina. _Nonparametric Goodness-of-Fit Testing under Gaussian Models_, volume 169 of _Lecture Notes in Statistics_. Springer-Verlag, New York, 2003.
* [JST19] Arun Jambulapati, Aaron Sidford, and Kevin Tian. A direct \(\widetilde{O}(1/\varepsilon)\) iteration parallel algorithm for optimal transport. _Advances in Neural Information Processing Systems_, 32, 2019.
* [JSWZ21] Shunhua Jiang, Zhao Song, Omri Weinstein, and Hengjie Zhang. A faster algorithm for solving general lps. In _Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing_, pages 823-832, 2021.
* [JT23] Arun Jambulapati and Kevin Tian. Revisiting area convexity: Faster box-simplex games and spectrahedral generalizations. _arXiv preprint arXiv:2303.15627_, 2023.
* [KF04] Sham M. Kakade and Dean P. Foster. Deterministic calibration and nash equilibrium. In John Shawe-Taylor and Yoram Singer, editors, _Learning Theory_, pages 33-48, Berlin, Heidelberg, 2004. Springer Berlin Heidelberg.
* [KF08] Sham M. Kakade and Dean P. Foster. Deterministic calibration and nash equilibrium. _J. Comput. Syst. Sci._, 74(1):115-130, 2008.
* [KLM19] Ananya Kumar, Percy Liang, and Tengyu Ma. Verified uncertainty calibration. In _Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019_, pages 3787-3798, 2019.

* [Kri09] Alex Krizhevsky. Learning multiple layers of features from tiny images. [https://www.cs.toronto.edu/](https://www.cs.toronto.edu/) kriz/learning-features-2009-TR.pdf, 2009. Accessed: 2024-01-31.
* [KSJ18] Aviral Kumar, Sunita Sarawagi, and Ujjwal Jain. Trainable calibration measures for neural networks from kernel mean embeddings. In Jennifer Dy and Andreas Krause, editors, _Proceedings of the 35th International Conference on Machine Learning_, volume 80 of _Proceedings of Machine Learning Research_, pages 2805-2814. PMLR, 10-15 Jul 2018.
* [LHHD23] Donghwan Lee, Xinmeng Huang, Hamed Hassani, and Edgar Dobriban. T-cal: An optimal test for the calibration of predictive models. _Journal of Machine Learning Research_, 24:1-72, 2023.
* [LS14] Yin Tat Lee and Aaron Sidford. Path finding methods for linear programming: Solving linear programs in o(vrank) iterations and faster algorithms for maximum flow. In _55th IEEE Annual Symposium on Foundations of Computer Science, FOCS 2014_, pages 424-433. IEEE Computer Society, 2014.
* [MDR\({}^{+}\)21a] Matthias Minderer, Josip Djolonga, Rob Romijnders, Frances Hubis, Xiaohua Zhai, Neil Houlsby, Dustin Tran, and Mario Lucic. Revisiting the calibration of modern neural networks. In _Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021_, pages 15682-15694, 2021.
* [MDR\({}^{+}\)21b] Matthias Minderer, Josip Djolonga, Rob Romijnders, Frances Hubis, Xiaohua Zhai, Neil Houlsby, Dustin Tran, and Mario Lucic. Revisiting the calibration of modern neural networks. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang, and J. Wortman Vaughan, editors, _Advances in Neural Information Processing Systems_, volume 34, pages 15682-15694. Curran Associates, Inc., 2021.
* [Mur98] Allan H. Murphy. The early history of probability forecasts: Some extensions and clarifications. _Weather and forecasting_, 13(1):5-15, 1998.
* [MW84] Allan H. Murphy and Robert L. Winkler. Probability forecasting in meteorology. _Journal of the American Statistical Association_, 79(387):489-500, 1984.
* [NCH15] Mahdi Pakdaman Naeini, Gregory F. Cooper, and Milos Hauskrecht. Obtaining well calibrated probabilities using bayesian binning. In _Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence, January 25-30, 2015_, pages 2901-2907. AAAI Press, 2015.
* [NDZ\({}^{+}\)19] Jeremy Nixon, Michael W. Dusenberry, Linchuan Zhang, Ghassen Jerfel, and Dustin Tran. Measuring calibration in deep learning. In _IEEE Conference on Computer Vision and Pattern Recognition Workshops, CVPR Workshops 2019_, pages 38-41. Computer Vision Foundation / IEEE, 2019.
* [Nie22] Zipei Nie. Matrix anti-concentration inequalities with applications. In _STOC '22: 54th Annual ACM SIGACT Symposium on Theory of Computing_, pages 568-581. ACM, 2022.
* [Opt23] Gurobi Optimization. Minimum-cost flow. [https://gurobi-optimization-gurobi-optimods.readthedocs-hosted.com/en/latest/mods/min-cost-flow.html](https://gurobi-optimization-gurobi-optimods.readthedocs-hosted.com/en/latest/mods/min-cost-flow.html), 2023. Accessed: 2024-05-21.
* [PV21] Richard Peng and Santosh S. Vempala. Solving sparse linear systems faster than matrix multiplication. In _Proceedings of the 2021 ACM-SIAM Symposium on Discrete Algorithms, SODA 2021_, pages 504-521. SIAM, 2021.
* [PyP19] PyPy. Pypy. [https://www.pypy.org/](https://www.pypy.org/), 2019. Accessed: 2024-05-21.
* [QM22] Benjamin Qi and Dustin Miao. Segment tree beats. [https://usaco.guide/adv/segtree-beats?lang=cpp](https://usaco.guide/adv/segtree-beats?lang=cpp), 2022. Accessed: 2024-05-20.

* [Ron08] Dana Ron. Property testing: A learning theory perspective. _Found. Trends Mach. Learn._, 1(3):307-402, 2008.
* [Ron09] Dana Ron. Algorithmic and analysis techniques in property testing. _Found. Trends Theor. Comput. Sci._, 5(2):73-205, 2009.
* [RRSK11] Francesco Ricci, Lior Rokach, Bracha Shapira, and Paul B. Kantor. _Recommender Systems Handbook_. Springer New York, 2011.
* [Rt21a] Rahul Rahaman and alexandre thiery. Uncertainty quantification and deep ensembles. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang, and J. Wortman Vaughan, editors, _Advances in Neural Information Processing Systems_, volume 34, pages 20063-20075. Curran Associates, Inc., 2021.
* [RT21b] Rahul Rahaman and Alexandre H. Thiery. Uncertainty quantification and deep ensembles. In _Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021_, pages 20063-20075, 2021.
* [She13] Jonah Sherman. Nearly maximum flows in nearly linear time. In _54th Annual IEEE Symposium on Foundations of Computer Science, FOCS 2013_, pages 263-269. IEEE Computer Society, 2013.
* [She17] Jonah Sherman. Area-convexity, l\({}_{\infty}\) regularization, and undirected multicommodity flow. In Hamed Hatami, Pierre McKenzie, and Valerie King, editors, _Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing, STOC 2017_, pages 452-460. ACM, 2017.
* [vdBLL\({}^{+}\)21] Jan van den Brand, Yin Tat Lee, Yang P. Liu, Thatchaphol Saranurak, Aaron Sidford, Zhao Song, and Di Wang. Minimum cost flows, mdps, and \(\ell_{1}\)-regression in nearly linear time for dense instances. In _STOC '21: 53rd Annual ACM SIGACT Symposium on Theory of Computing, 2021_, pages 859-869. ACM, 2021.
* [vdBLSS20] Jan van den Brand, Yin Tat Lee, Aaron Sidford, and Zhao Song. Solving tall dense linear programs in nearly linear time. In _Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing, STOC 2020_, pages 775-788. ACM, 2020.
* [VDDP17] Athanasios Voulodimos, Nikolaos Doulamis, Anastasios Doulamis, and Effychios Protopapadakis. Deep learning for computer vision: A brief review. _Computational Intelligence and Neuroscience_, 2018, 2017.
* [WXXZ23] Virginia Vassilevska Williams, Yinzhan Xu, Zixuan Xu, and Renfei Zhou. New bounds for matrix multiplication: from alpha to omega. _CoRR_, abs/2307.07970, 2023.

Additional preliminaries

We first introduce some notation used in Appendices B, C, and D. When applied to a vector, we let \(\left\|\cdot\right\|_{p}\) denote the \(\ell_{p}\) norm for \(p\geq 1\). We let \(\mathbb{U}_{d}\) and \(\mathbb{1}_{d}\) denote the all-zeroes and all-ones vectors in dimension \(d\). We let \(\Delta^{d}:=\{x\in\mathbb{R}_{\geq 0}^{d}\mid\left\|x\right\|_{1}=1\}\) denote the probability simplex in dimension \(d\). The \(i^{\text{th}}\) coordinate basis vector is denoted \(e_{i}\). We say \(\tilde{x}\in\mathbb{R}\) is an \(\varepsilon\)-additive approximation of \(x\in\mathbb{R}\) if \(\left|\tilde{x}-x\right|\leq\varepsilon\). For a set \(S\subset\mathbb{R}\), we say another set \(T\subset\mathbb{R}\) is an \(\varepsilon\)-cover of \(S\) if for all \(s\in S\), there is \(t\in T\) with \(\left|s-t\right|\leq\varepsilon\). For \(a,b\in\mathbb{R}\) with \(a\leq b\), we let \(\text{clip}_{[a,b]}(t):=\min(b,\max(a,t))\) denote the result of projecting \(t\in\mathbb{R}\) onto \([a,b]\).

We next formally define our tolerant variant of the calibration testing problem in Definition 2.

**Definition 4** (Tolerant calibration testing).: _Let \(0\leq\varepsilon_{2}\leq\varepsilon_{1}\leq 1\). We say algorithm \(\mathcal{A}\) solves the \((\varepsilon_{1},\varepsilon_{2})\)-tolerant calibration testing problem with \(n\) samples, if given \(n\) i.i.d. draws from a distribution \(\mathcal{D}\) over \([0,1]\times\{0,1\}\), \(\mathcal{A}\) returns either "yes" or "no" and satisfies the following with probability \(\geq\frac{2}{3}\)._

* \(\mathcal{A}\) _returns "no" if_ \(\underline{\mathsf{dCE}}(\mathcal{D})\geq\varepsilon_{1}\)_._
* \(\mathcal{A}\) _returns "yes" if_ \(\underline{\mathsf{dCE}}(\mathcal{D})\leq\varepsilon_{2}\)_._

_In this case, we also call \(\mathcal{A}\) an \((\varepsilon_{1},\varepsilon_{2})\)-tolerant calibration tester._

Note that an algorithm which solves the \((\varepsilon_{1},\varepsilon_{2})\)-tolerant calibration testing problem with \(n\) samples also solves the \(\varepsilon_{1}\)-calibration testing problem with the same sample complexity. Moreover, we give a simple impossibility result on parameter ranges for calibration testing.

**Lemma 5**.: _Let \(0\leq\varepsilon_{2}\leq\varepsilon_{1}\leq\frac{1}{2}\) satisfy \(\varepsilon_{1}-\varepsilon_{2}=\varepsilon\). There is a universal constant \(C_{\text{coin}}\) such that, given \(n\leq\frac{C_{\text{coin}}}{\varepsilon^{2}}\) samples from a distribution on \([0,1]\times\{0,1\}\), it is information-theoretically impossible to solve the \((\varepsilon_{1},\varepsilon_{2})\)-tolerant calibration testing problem._

Proof.: Suppose \(\varepsilon\leq\frac{1}{10}\), else we can choose \(C_{\text{coin}}\) small enough such that \(n<1\). We consider two distributions over \([0,1]\times\{0,1\}\), \(\mathcal{D}\) and \(\mathcal{D}^{\prime}\), with \(\underline{\mathsf{dCE}}(\mathcal{D})\geq\varepsilon_{1}\) but \(\underline{\mathsf{dCE}}(\mathcal{D}^{\prime})\leq\varepsilon_{2}\), so if \(\mathcal{A}\) succeeds at tolerant calibration testing for both \(\mathcal{D}\) and \(\mathcal{D}^{\prime}\), we must have \(\mathrm{d}_{\mathrm{TV}}(\mathcal{D}^{\otimes n},(\mathcal{D}^{\prime})^{ \otimes n})\geq\frac{1}{3}\), where we denote the \(n\)-fold product of a distribution with \({}^{\otimes n}\). Else, \(\mathcal{A}\) cannot return different answers from \(n\) samples with probability \(\geq\frac{2}{3}\), as required by Definition 4. Specifically, we define \(\mathcal{D},\mathcal{D}^{\prime}\) as follows.

* To draw \((v,y)\sim\mathcal{D}\), let \(v=\frac{1}{2}+\varepsilon_{1}\) and \(y\sim\text{Bern}(\frac{1}{2})\).
* To draw \((v,y)\sim\mathcal{D}^{\prime}\), let \(v=\frac{1}{2}+\varepsilon_{1}\) and \(y\sim\text{Bern}(\frac{1}{2}+\varepsilon)\).

We claim that \(\underline{\mathsf{dCE}}(\mathcal{D})=\varepsilon_{1}\). To see this, let \(\Pi\in\text{ext}(\mathcal{D})\) and \((u,v,y)\sim\Pi\), so \(\mathbb{E}_{(u,v,y)\sim\Pi}[u]=\frac{1}{2}\) because \(u\) is calibrated. By Jensen's inequality, we have:

\[\mathbb{E}_{(u,v,y)\sim\Pi}\left[\left|u-v\right|\right]\geq\left|\mathbb{E}_{ (u,v,y)\sim\Pi}\left[u\right]-\left(\frac{1}{2}+\varepsilon_{1}\right)\right| =\varepsilon_{1}.\]

The equality case is realized when \(u=\frac{1}{2}\) with probability \(1\), proving the claim. Similarly, \(\underline{\mathsf{dCE}}(\mathcal{D}^{\prime})=\varepsilon_{2}\). Finally, let \(\pi:=\text{Bern}(\frac{1}{2})\), \(\pi^{\prime}:=\text{Bern}(\frac{1}{2}+\varepsilon)\), and \(\pi^{\otimes n},(\pi^{\prime})^{\otimes n}\) denote their \(n\)-fold product distributions. Pinsker's inequality shows that it suffices to show that \(d_{\text{KL}}(\pi^{\otimes n}\|(\pi^{\prime})^{\otimes n})\leq\frac{1}{5}\) to contradict our earlier claim \(\mathrm{d}_{\mathrm{TV}}((\mathcal{D})^{\otimes n},(\mathcal{D}^{\prime})^{ \otimes n})\geq\frac{1}{3}\). To this end, we have

\[d_{\text{KL}}(\pi^{\otimes n}\|(\pi^{\prime})^{\otimes n}) =n\cdot d_{\text{KL}}\left(\pi\|\pi^{\prime}\right)=\frac{n}{2} \left(\log\left(\frac{\frac{1}{2}}{\frac{1}{2}+\varepsilon}\right)+\log\left( \frac{\frac{1}{2}}{\frac{1}{2}-\varepsilon}\right)\right)\] \[=\frac{n}{2}\log\left(\frac{1}{1-4\varepsilon^{2}}\right)\leq \frac{n}{2}\cdot 5\varepsilon^{2}\leq\frac{1}{5},\]

where the first line used tensorization of \(d_{\text{KL}}\), and the last chose \(C_{\text{coin}}\) small enough. 

We also generalize Definitions 2 and 4 to apply to an arbitrary calibration measure.

**Definition 5** (d testing).: _Let \(\mathsf{d}\) be a calibration measure. For \(\varepsilon\in\mathbb{R}_{\geq 0}\), we say algorithm \(\mathcal{A}\) solves the \(\varepsilon\)-\(\mathsf{d}\)-testing problem (or, \(\mathcal{A}\) is an \(\varepsilon\)-\(\mathsf{d}\) tester) with \(n\) samples, if given \(n\) i.i.d. draws from a distribution \(\mathcal{D}\) over \([0,1]\times\{0,1\}\), \(\mathcal{A}\) returns either "yes" or "no" and satisfies the following with probability \(\geq\frac{2}{3}\)._

1. \(\mathcal{A}\) _returns "no" if_ \(\mathsf{d}(\mathcal{D})\geq\varepsilon\)_._
2. \(\mathcal{A}\) _returns "yes" if_ \(\mathsf{d}(\mathcal{D})=0\)_._

_For \(0\leq\varepsilon_{2}\leq\varepsilon_{1}\), we say algorithm \(\mathcal{A}\) solves the \((\varepsilon_{1},\varepsilon_{2})\)-tolerant \(\mathsf{d}\) testing problem (or, \(\mathcal{A}\) is an \((\varepsilon_{1},\varepsilon_{2})\)-tolerant \(\mathsf{d}\) tester) with \(n\) samples, if given \(n\) i.i.d. draws from a distribution \(\mathcal{D}\) over \([0,1]\times\{0,1\}\), \(\mathcal{A}\) returns either "yes" or "no" and satisfies the following with probability \(\geq\frac{2}{3}\)._

1. \(\mathcal{A}\) _returns "no" if_ \(\mathsf{d}(\mathcal{D})\geq\varepsilon_{1}\)_._
2. \(\mathcal{A}\) _returns "yes" if_ \(\mathsf{d}(\mathcal{D})\leq\varepsilon_{2}\)_._

## Appendix B Appendix for Section 2

### Deferred lemma proofs

Proof of Lemma 1.: This follows from the triangle inequality:

\[|x_{i}-x_{j}|\leq\sum_{k=i}^{j-1}|x_{k}-x_{k+1}|\leq\sum_{k=i}^{j-1}v_{k+1}-v _{k}=v_{j}-v_{i}.\]

### Dynamic programming

In this section, we give our dynamic programming approach to solving (4), which establishes Proposition 1. The graph \(G\) in (4) is the union of a path \(P\) on \(n\) vertices and a star \(S\) to the \((n+1)^{\mathsf{th}}\) vertex. Let us identify the edges in \(P\) with \([n-1]\) (where edge \(i\) corresponds to vertices \((i,i+1)\)), and the edges in \(S\) with \([2n-1]\setminus[n-1]\). We first make a simplifying observation, which is that given the coordinates of a flow variable \(f\in\mathbb{R}^{E}\) on the edges in the path \(P\), there is a unique way to set the values of \(f\) on the edges in the star \(S\) so that the demands \(\mathbf{B}^{\top}f=d\) are satisfied. Concretely, we require

\[f_{n-1+i} =d_{i}+f_{i}-f_{i-1}\text{ for all }2\leq i\leq n-1,\] \[f_{n} =d_{1}+f_{1},\text{ and }f_{2n-1}=d_{n}-f_{n-1}.\]

Hence, minimizing the constrained problem in (4) is equivalent to minimizing the following unconstrained problem on the first \(n-1\) flow variables, stated in (8) and reproduced here:

\[\min_{f\in\mathbb{R}^{n-1}}A(f):=|d_{1}+f_{1}|+|d_{n}-f_{n-1}|+\sum_{i\in[n-2] }|f_{i}-f_{i+1}-d_{i+1}|+\sum_{i\in[n-1]}c_{i}|f_{i}|.\]

We now solve (8). We first define a sequence of partial functions \(\{A_{j}:\mathbb{R}\rightarrow\mathbb{R}\}_{j\in[n-1]}\) by

\[A_{1}(z) :=|d_{1}+z|+c_{1}|z|, \tag{9}\] \[A_{j}(z) :=\min_{\begin{subarray}{c}f\in\mathbb{R}^{j}\\ f_{j}=z\end{subarray}}|d_{1}+f_{1}|+\sum_{i\in[j-1]}|f_{i}-f_{i+1}-d_{i+1}|+ \sum_{i\in[j-1]}c_{i}|f_{i}|\text{ for all }2\leq j\leq n-2,\] \[A_{n-1}(z) :=\min_{\begin{subarray}{c}f\in\mathbb{R}^{j}\\ f_{j}=z\end{subarray}}A(f).\]

In other words, \(A_{j}(z)\) asks to minimize the partial function in (8) over the first \(j\) flow variables \(\{f_{i}\}_{i\in[j]}\), corresponding to all terms in which these flow variables participate, subject to fixing \(f_{j}=z\). We make some preliminary observations about the partial functions \(\{A_{j}\}_{j\in[n-1]}\).

**Lemma 6**.: _For all \(j\in[n-2]\), \(A_{j}\) is a convex, continuous, piecewise linear function with at most \(j+2\) pieces, and \(A_{n-1}\) is a convex, continuous, piecewise linear function with at most \(n+2\) pieces._

Proof.: We first establish convexity by induction; the base case \(j=1\) is clear. We next observe that

\[A_{j}(z) =c_{j}|z|+\min_{w\in\mathbb{R}}|w-z-d_{j}|+A_{j-1}(w)\text{ for all }2\leq j\leq n-2, \tag{10}\] \[A_{n-1}(z) =|d_{n}-z|+c_{n-1}|z|+\min_{w\in\mathbb{R}}|w-z-d_{n-1}|+A_{n-2}(w).\]

In other words, each partial function \(A_{j}\) can be recursively defined by first minimizing the first \(j-2\) flow variables for a fixed value \(f_{j-1}=w\), and then taking the optimal choice of \(w\). Moreover, supposing inductively \(A_{j-1}\) is convex, \(A_{j}\) is the sum of a convex function and a partial minimization over a jointly convex function of \((w,z)\), so it is also convex, completing the induction.

To see that \(A_{j}\) is continuous (assuming continuity of \(A_{j-1}\) inductively), it suffices to note \(A_{j}\) is the sum of a continuous function and a partial minimization over a continuous function in two variables.

We now prove the claims about piecewise linearity, and the number of pieces. Clearly, \(A_{1}\) is continuous and piecewise linear with at most \(3\) pieces. Next, for some \(2\leq j\leq n-2\), suppose \(A_{j-1}\) is piecewise linear with vertices \(\{v_{i}\}_{i\in[j]}\) in nondecreasing order (possibly with repetition) and slopes \(\{t_{i}\}_{i=0}^{j}\), so \(t_{i}\) is the slope of the segment of \(A_{j-1}\) between \(v_{i}\) and \(v_{i+1}\), and \(t_{0}\) and \(t_{j}\) are the leftmost and rightmost slopes. For convenience we define \(v_{0}:=-\infty\) and \(v_{j+1}:=\infty\). Consider the function

\[\min_{w\in\mathbb{R}}|w-z-d_{j}|+A_{j-1}(w). \tag{11}\]

For all values \(z\) satisfying \(v_{i}\leq z+d_{j}\leq v_{i+1}\) where \(0\leq i\leq j\), the function \(|w-z-d_{j}|+A_{j-1}(w)\) is piecewise linear with vertices \(v_{1},\ldots,v_{i},z+d_{j},v_{i+1},\ldots,v_{j}\), and correspondingly ordered slopes \(t_{0}-1,t_{1}-1,\ldots,t_{i}-1,t_{i}+1,\ldots,t_{j}+1\). The minimizing \(w\) in (11) corresponds to any \(v\in\{v_{i}\}_{i\in[j]}\cup\{z+d_{j}\}\) where the slope switches from nonpositive to nonnegative, which is either a fixed vertex \(v=v_{k}\) for the entire range \(v_{i}\leq z+d_{j}\leq v_{i+1}\), or the new vertex \(z+d_{j}\) for this entire range.

In the former case, we have

\[\min_{w\in\mathbb{R}}|w-z-d_{j}|+A_{j-1}(w)=|v_{k}-z-d_{j}|+A_{j-1}(v_{k}), \tag{12}\]

which up to a constant additive shift is \(|z-(v_{k}-d_{j})|\), a linear function in \(z\) in the range \(v_{i}\leq z+d_{j}\leq v_{i+1}\) because the sign of \(z-(v_{k}-d_{j})\) does not change. In the latter case, we have

\[\min_{w\in\mathbb{R}}|w-z-d_{j}|+A_{j-1}(w)=A_{j-1}(z+d_{j}), \tag{13}\]

which again is a linear function in \(z\) in the range \(v_{i}\leq z+d_{j}\leq v_{i+1}\) by induction. In conclusion, (11) is linear in each range \(z\in[v_{i}-d_{j},v_{i+1}-d_{j}]\), so it is piecewise linear with at most \(j+1\) pieces; adding \(c_{j}|z|\), which introduces at most \(1\) more piece, completes the induction. An analogous argument holds for \(j=n-1\), but we potentially introduce two more pieces due to adding \(|d_{n}-z|+c_{n-1}|z|\).

For convenience, we now describe how to update the slopes and vertices going from the piecewise linear function \(A_{j-1}\) to \(A_{j}\). Also, as above suppose the vertices of \(A_{j-1}\) are \(\{v_{i}\}_{i\in[j]}\) and the corresponding slopes are \(\{t_{i}\}_{i=0}^{j}\). Then because we argued (11) is linear in each range \(z\in[v_{i}-d_{j},v_{i+1}-d_{j}]\), it has vertices \(\{v_{i}-d_{j}\}_{i\in[j]}\). If \(z\in[v_{i}-d_{j},v_{i+1}-d_{j}]\) and \(t_{i}\in[-1,1]\), then we are in the case of (13) and the corresponding slope in this range is \(t_{i}\). Otherwise, if \(t_{i}\leq-1\) we are in the case of (12) with slope \(-1\), and if \(t_{i}\geq 1\) the slope of the piece is similarly \(1\). We then add \(c_{j}|z|\) (and \(|d_{n}-z|\) if \(j=n-1\)). In summary, the new slopes and vertices are as follows.

* If \(j\leq n-2\), the new vertices are \(\{v_{i}-d_{j}\}_{i\in[j]}\cup\{0\}\). If \(v_{k}-d_{j}\leq 0\leq v_{k+1}-d_{j}\) for some \(0\leq k\leq j\), using our convention \(v_{0}=-\infty\) and \(v_{j+1}=\infty\), the new slopes are \[\{\text{clip}_{[-1,1]}(t_{i})-c_{j}\}_{0\leq i<k}\cup\{\text{clip}_{[-1,1]}(t_ {k})-c_{j}\}\] (14) \[\cup\{\text{clip}_{[-1,1]}(t_{k})+c_{j}\}\cup\{\text{clip}_{[-1,1] }(t_{i})+c_{j}\}_{k<i\leq j}.\]* If \(j=n-1\), the new vertices are \(\{v_{i}-d_{j}\}_{i\in[j]}\cup\{0\}\cup\{d_{n}\}\). If \(v_{k}-d_{j}\leq 0\leq v_{k+1}-d_{j}\) and \(v_{h}-d_{j}\leq d_{n}\leq v_{h+1}-d_{n}\) for some \(0\leq h,k\leq j\), the new slopes are \[\{\text{clip}_{[-1,1]}(t_{i})-c_{j}\iota_{v_{i+1}\leq d_{j}}+c_{j}\iota_{v_{i} \geq d_{j}}\}_{\begin{subarray}{c}0\leq i\leq j\\ i\notin\{h,k\}\end{subarray}}\] (15) \[\cup\left\{\text{clip}_{[-1,1]}(t_{k})-c_{j}\right\}\cup\left\{ \text{clip}_{[-1,1]}(t_{k})+c_{j}\right\}\] \[\cup\left\{\text{clip}_{[-1,1]}(t_{h})-1\right\}\cup\left\{\text{ clip}_{[-1,1]}(t_{h})+1\right\},\] where we let \(\iota_{\mathcal{E}}\) denote the \(0\)-\(1\) indicator variable of an event \(\mathcal{E}\).

The ordering of these vertices and their slopes are uniquely determined, because they are sorted similarly due to convexity, which implies nondecreasing slopes as \(z\) increases. Finally, we note that assuming the invariant that at least one \(\{t_{i}\}_{i=0}^{j}\) is nonnegative and at least one is nonpositive (which holds in the first iteration), in either of the cases (14) or (15) this invariant is preserved, since clipping preserves signs, the smallest slope decreases, and the largest slope increases. 

We require one additional property of the slope updates (14).

**Lemma 7**.: _For \(j\in[n-1]\), let \(\{t_{i}\}_{i=0}^{j}\) be the nondecreasing slopes of \(A_{j}\). Then \(t_{0}\leq-1\) and \(t_{j}\geq 1\)._

Proof.: By observation, the smallest and largest slopes of \(A_{1}\) (9) are \(-1-c_{1}\) and \(1+c_{1}\). Hence, assuming inductively the lemma statement is true for \(A_{j-1}\), the slope updates (14) result in smallest and largest slopes \(-1-c_{j}\) and \(-1+c_{j}\) in \(A_{j}\), completing the induction. 

We next observe that, by storing a constant amount of information in each iteration, we can work backwards from an optimal solution to \(A_{n-1}\) and recover all flow variables which realized this value.

**Lemma 8**.: _Let \(\{v_{i}\}_{i\in[j]}\) and \(\{t_{i}\}_{i=0}^{j}\) be the nondecreasing vertices and slopes of \(A_{j-1}\) for some \(2\leq j\leq n-1\). Suppose we know \(v_{\ell}\) and \(v_{r}\) for \(\ell,r\in[j]\), defined such that \(t_{\ell-1}\leq-1\) but \(t_{\ell}\geq-1\), and similarly \(t_{r-1}\leq 1\) but \(t_{r}\geq 1\). Then given a value of \(z\), we can compute in \(O(1)\) time_

\[\text{argmin}_{w\in\mathbb{R}}|w-z-d_{j}|+A_{j-1}(w).\]

Proof.: Note that existence of \(v_{\ell},v_{r}\) is guaranteed by Lemma 7. We consider three cases.

First, if \(z+d_{j}\in[v_{\ell},v_{r}]\), we claim \(w=z+d_{j}\). To see this, recall that if \(z+d_{j}\in[v_{i},v_{i+1}]\), we proved in Lemma 6 that the slopes of \(|w-z-d_{j}|+A_{j-1}(w)\) (in \(w\)) are \(t_{0}-1,t_{1}-1,\ldots,t_{i}-1,t_{i}+1,\ldots,t_{j}+1\). Hence, the assumptions imply \(t_{i}\in[-1,1]\), so a vertex of \(|w-z-d_{j}|+A_{j-1}(w)\) where the slope changes from nonpositive to nonnegative (i.e. the minimizing argument \(w\)) is \(w=z+d_{j}\), as claimed.

To handle the other two cases, if \(z+d_{j}\leq v_{\ell}\), then the above calculation shows the new optimal vertex is \(w=v_{\ell}\); similarly, if \(z+d_{j}\geq v_{r}\) the new optimal vertex is \(w=v_{r}\). 

We now describe an interface for a data structure that we use to efficiently implement the updates (14) and (15), whose existence we prove in the following Appendix B.3.

**Lemma 9**.: _There is a data structure, \(\mathsf{SegmentTree}\), which initializes a vector \(t\in\mathbb{R}^{n}\) to \(t\leftarrow\mathbb{0}_{n}\), and supports the following operations each in \(O(\log n)\) time._

* \(\mathsf{Query}(i)\)_: Return_ \(t_{i}\)_._
* \(\mathsf{Add}(\ell,r,c)\)_: Update_ \(t_{i}\gets t_{i}+c\) _for all_ \(\ell\leq i\leq r\)_._
* \(\mathsf{Set}(\ell,r,c)\)_: Update_ \(t_{i}\gets c\) _for all_ \(\ell\leq i\leq r\)_._

Given access to \(\mathsf{SegmentTree}\), we now describe how to solve (8) in nearly-linear time, proving Proposition 1.

Proof of Proposition 1.: We first describe how to compute all of the vertices and slopes \(\{v_{i}\}_{i\in[n-1]}\), \(\{t_{i}\}_{i=0}^{n-1}\) of \(A_{n-2}\) in time \(O(n\log^{2}(n))\). The proof of Lemma 6 shows that the vertices are

\[\left\{-\sum_{k=j+1}^{n-2}d_{k}\right\}_{j=0}^{n-2}, \tag{16}\]

where we treat the empty sum as \(0\). Moreover, the vertex \(-\sum_{k=j+1}^{n-2}d_{k}\) is the new vertex which was inserted (as \(0\)) when computing \(A_{j}\), and then advanced through the remaining iterations. We sort the vertices (16) into nondecreasing order, keeping track of the resulting permutation \(\pi:[n-2]\cup\{0\}\to[n-1]\), i.e. if the vertex \(-\sum_{k=j+1}^{n-2}d_{k}\) is the \(i^{\text{th}}\) smallest in (16), then \(\pi(j)=i\). This step takes time \(O(n\log n)\) and does not dominate.

We next initialize a SegmentTree (Lemma 9) with \(n\) vertices. We update it through the first \(n-2\) recursive computations of slopes, via (14), keeping track of a time counter \(j\), i.e. after we are done updating the slopes of \(A_{j}\) the time counter increments. The state of SegmentTree at the end of time \(j\) is as follows. For all \(k\in[j]\), letting \(\pi(h)\) be the next largest value after \(\pi(k)\) amongst \(\{\pi(k^{\prime})\}_{k^{\prime}\in[j]}\), we require that \(t_{i}\) equals the slope of the segment to the right of the vertex inserted at time \(k\) in \(A_{j}\), for all the coordinates \(\pi(k)+1\leq i\leq\pi(h)\). In other words, SegmentTree stores all of the slopes of \(A_{j}\) in its coordinates (with redundancies due to vertices which will be inserted after time \(j\)), and \(\pi\) maps the times vertices are inserted to their coordinate values in SegmentTree.

We next show how to maintain this state in \(O(\log^{2}(n))\) time per time increment. In iteration \(j\), the update (14) requires us to clip all previous slopes to the range \([-1,1]\), subtract \(c_{j}\) from all slopes in the range \([1,\pi(j)]\), and add \(c_{j}\) to all slopes in the range \([\pi(j)+1,n]\). We first use Query to perform binary searches for the values \(\ell,r\) as defined in Lemma 7. We then sequentially apply

\[\mathsf{Set}(1,\ell,-1),\ \mathsf{Set}(r+1,n,1),\ \mathsf{Add}(1,\pi(j),-c_{j} ),\ \mathsf{Add}(\pi(j)+1,n,c_{j}).\]

The dominant runtime term is the cost of \(O(\log(n))\) calls to Query to perform the binary search, giving the claimed \(O(\log^{2}(n))\) runtime per time increment. We can now call Query \(n\) times to compute all slopes and vertices of \(A_{n-2}\). We will also store the values of \(v_{\ell}\) and \(v_{r}\) at time \(j\), which takes \(O(1)\) time given \(\ell,r,\pi\), and partial sums which can be precomputed in time \(O(n)\).

Given these slopes and vertices, it is straightforward to apply (15) to compute all slopes and vertices of \(A_{n-1}\) in time \(O(n)\), at which point we can find \(z:=\text{argmin}_{z\in\mathbb{R}}A_{n-1}(z)\). Next, by using our stored values of \(v_{\ell}\) and \(v_{r}\) in every iteration, we can then use Lemma 8 to compute all the optimal flow values realizing \(A_{n-1}(z)\). Finally, we can compute the optimal value (8) in time \(O(n)\). 

### Implementation of SegmentTree

In this section, we develop a data structure known as a _segment tree_ which plays a vital role in our main algorithm. In particular, it allows us to prove Lemma 9. While this data structure is well-known folklore in the competitive programming community (see e.g. an overview of this technique in [13]), we provide a full description and proof for completeness.

For integers \(\ell\) and \(r\) satisfying \(\ell\leq r\), we use \([\ell:r]\) to denote the set \(\{\ell,\ell+1,\ldots,r\}\).

**Lemma 10** (Segment tree).: _Let \(G\) be a semigroup with an identity element \(e\), where the semigroup product of \(a,b\in G\) is denoted by \(a\cdot b\) or \(ab\) and is not necessarily commutative. Let \(v\) be an array of length \(n\), where each element of \(v\) is initialized to be the identity element \(e\) of \(G\). There is a data structure \(\mathcal{D}\), called a segment tree, that can perform each of the following operations in \(O(\log n)\) time (assuming a semigroup product can be computed in constant time)._

1. \(\mathsf{Access}(i)\)_: given_ \(i\in[1:n]\)_, return the_ \(i^{\text{th}}\) _element in_ \(v\)_._
2. \(\mathsf{Apply}(g,\ell,r)\)_: given_ \(\ell,r\in[1:n]\) _satisfying_ \(\ell\leq r\)_, and given a semigroup element_ \(g\in G\)_, for each index_ \(i\in[\ell:r]\)_, replace_ \(v[i]\) _with_ \(g\cdot v[i]\)_._

Before proving Lemma 10, we first use it to prove Lemma 9.

Proof of Lemma 9.: We apply the data structure in Lemma 10 to a specific semigroup \(G\) defined as follows. The elements of \(G\) are functions \(\tau:\mathbb{R}\to\mathbb{R}\), where the identity element \(e\) is the identity function \(e(u)=u\) for every \(u\in\mathbb{R}\), and the semigroup product is defined as function composition: \((a\cdot b)(u)=a(b(u))\) for every \(a,b\in G\) and \(u\in\mathbb{R}\). The semigroup \(G\) consists of the following functions: \(\mathsf{add}_{c}\) and \(\mathsf{set}_{c}\) for every \(c\in\mathbb{R}\). These functions are defined as follows:

\[\mathsf{add}_{c}(u)=u+c,\quad\mathsf{set}_{c}(u)=c,\quad\text{for every }u\in \mathbb{R}.\]

It is easy to check that these functions are closed under composition:

\[\mathsf{add}_{c}\cdot\mathsf{add}_{c^{\prime}} =\mathsf{add}_{c+c^{\prime}},\] \[\mathsf{set}_{c}\cdot\mathsf{set}_{c^{\prime}} =\mathsf{set}_{c},\] \[\mathsf{add}_{c}\cdot\mathsf{set}_{c^{\prime}} =\mathsf{set}_{c+c^{\prime}},\] \[\mathsf{set}_{c}\cdot\mathsf{add}_{c^{\prime}} =\mathsf{set}_{c}.\]

Therefore, \(G\) is a valid semigroup. We can now implement the operations \(\mathsf{Query},\mathsf{Add},\mathsf{Set}\) in Lemma 9 using the operations \(\mathsf{Access}\) and \(\mathsf{Apply}\) in Lemma 10 as follows.

To implement \(\mathsf{Query}(i)\), we run \(\mathsf{Access}(i)\) to obtain its output \(g=v[i]\in G\), and return \(g(0)\).

To implement \(\mathsf{Add}(\ell,r,c)\), we run \(\mathsf{Apply}(\mathsf{add}_{c},\ell,r)\).

To implement \(\mathsf{Set}(\ell,r,c)\), we run \(\mathsf{Apply}(\mathsf{set}_{c},\ell,r)\).

The correctness of this implementation can be shown inductively. At initialization, \(v[i]=e\), and thus \(\mathsf{Query}(i)\) returns \(e(0)=0\), which is the correct value of \(t_{i}\) at initialization. It remains to show inductively that after each \(\mathsf{Add}\) and \(\mathsf{Set}\) operation, the output of \(\mathsf{Query}(i)\), i.e., \(v[i](0)\), is the intended value of \(t_{i}\). Indeed, after an \(\mathsf{Add}\) operation, for any \(i\in[\ell:r]\), the element \(v[i]\) is updated to \(v[i]^{\prime}:=(\mathsf{add}_{c}\cdot v[i])\), and thus

\[v[i]^{\prime}(0)=(\mathsf{add}_{c}\cdot v[i])(0)=\mathsf{add}_{c}(v[i](0))=v[i] (0)+c=t_{i}+c,\]

which is the intended new value of \(t_{i}\). For \(i\notin[\ell:r]\), the element \(v[i]\) remains unchanged, and thus \(v[i](0)\) remains unchanged. This is as desired because the new value of \(t_{i}\) is intended to be the same as the old value. Combining these two cases, we have shown that the \(\mathsf{Add}\) operation maintains that \(v[i](0)\) is the intended value of \(t_{i}\) for every \(i\in[1:n]\). We can similarly show that the \(\mathsf{Set}\) operation also has this property, and thus our implementation is correct. The running time guarantee of the implementation follows directly from the running time guarantee in Lemma 10. 

We prove Lemma 10 by describing the construction of the segment tree data structure and analyzing its correctness (Lemma 11) and efficiency (Lemma 12). By appending to the array an appropriate number of auxiliary entries, we can assume without loss of generality that the array length \(n\) is a power of \(2\), i.e., \(n=2^{r}\) for a positive integer \(r\). The data structure is implemented using a complete binary tree \(T\) with depth \(r\), where the \(2^{r}\) leaves correspond to the \(n=2^{r}\) entries in the array.

More specifically, we use \(\mathsf{seg}(\tau)\subseteq[1:n]\) to denote the set of indices \(i\) that a node \(\tau\in T\) is associated with. For the root \(\tau_{0}\) of the tree \(T\), we set \(\mathsf{seg}(\tau_{0})=[1:n]=[1:2^{r}]\), and for its two children \(\tau_{1},\tau_{2}\) we set \(\mathsf{seg}(\tau_{1})=[1:n/2]=[1:2^{r-1}]\) and \(\mathsf{seg}(\tau_{2})=[n/2+1:n]=[2^{r-1}+1:2^{r}]\). In general, for any non-leaf node \(\tau\) and its two children \(\tau_{1},\tau_{2}\), we set \(\mathsf{seg}(\tau_{1})\) as the first half of \(\mathsf{seg}(\tau)\), and set \(\mathsf{seg}(\tau_{2})\) as the second half. In particular, for every leaf \(\tau\), \(\mathsf{seg}(\tau)\) is a singleton set consisting of a unique index \(i\in[1:n]\), and we say \(\tau\) is the (unique) leaf corresponding to index \(i\). See Figure 3 for an example with depth \(r=3\).

At every node \(\tau\) of the tree, we maintain a semigroup element \(g_{\tau}\in G\) initialized to be the identity element \(e\).

Figure 3: Example of segment tree with depth \(r=3\).

Access.We implement Access(\(i\)) as follows. Let \(\tau_{0}\rightarrow\cdots\rightarrow\tau_{r}\) be the directed path from the root \(\tau_{0}\) to the leaf \(\tau_{r}\) corresponding to index \(i\). Return the semigroup product \(g_{\tau_{0}}g_{\tau_{1}}\cdots g_{\tau_{r}}\).

Apply.We implement Apply(\(g,\ell,r\)) recursively. That is, we implement Apply(\(g,\ell,r,\tau\)) in Algorithm 1 which takes a node \(\tau\in T\) as an additional input. We then define Apply(\(g,\ell,r\)) to be Apply(\(g,\ell,r,\tau_{0}\)), where the additional input is set as the root \(\tau_{0}\) of the tree \(T\).

```
1:if\(\text{seg}(\tau)\cap[\ell:r]=\emptyset\)then
2:return
3:endif
4:if\(\text{seg}(\tau)\subseteq[\ell:r]\)then
5:\(g_{\tau}\gets g\cdot g_{\tau}\)
6:return
7:endif
8: Let \(\tau_{1},\tau_{2}\) be the two children of \(\tau\)
9:\(g_{\tau_{1}}\gets g_{\tau}\cdot g_{\tau_{1}}\)
10:\(g_{\tau_{2}}\gets g_{\tau}\cdot g_{\tau_{2}}\)
11:\(g_{\tau}\gets e\)
12:Apply(\(g,\ell,r,\tau_{1}\))
13:Apply(\(g,\ell,r,\tau_{2}\))
```

**Algorithm 1**Apply(\(g,\ell,r,\tau\))

Correctness.At initialization, each array element \(v[i]\) is initialized to be the identity element \(e\). The semigroup element \(g_{\tau}\) stored at each tree node \(\tau\) is also initialized to be \(e\), so Access(\(i\)) returns the correct value \(e\). It remains to show that Access(\(i\)) still returns the correct value of \(v[i]\) after each Apply operation. This is established in the following lemma:

**Lemma 11**.: _For \(i\in\{1,\ldots,n\}\), let \(\tau_{0}\rightarrow\cdots\rightarrow\tau_{r}\) be the directed path from the root \(\tau_{0}\) to the leaf \(\tau_{r}\) corresponding to index \(i\). Let \(\hat{g}_{\tau_{0}},\ldots,\hat{g}_{\tau_{r}}\in G\) denote the current states of the semigroup elements \(g_{\tau_{0}},\ldots,g_{\tau_{r}}\) stored in the data structure. Then after we call Apply(\(g,l,r\)), we have_

\[g_{\tau_{0}}\cdots g_{\tau_{r}}=\begin{cases}g\cdot\hat{g}_{\tau_{0}}\cdots \hat{g}_{\tau_{r}},&\text{if $i\in[\ell:r]$};\\ \hat{g}_{\tau_{0}}\cdots\hat{g}_{\tau_{r}},&\text{if $i\notin[\ell:r]$}.\end{cases}\]

Proof.: It is clear that \([1:n]=\text{seg}(\tau_{0})\supseteq\cdots\supseteq\text{seg}(\tau_{r})=\{i\}\). If \(i\in[\ell:r]\), let \(\tau_{j}\) be the first node among \(\tau_{0},\ldots,\tau_{r}\) such that \(\text{seg}(\tau_{j})\subseteq[\ell,r]\). We can inductively show that for every \(j^{\prime}=1,\ldots,j\), right before we make the recursive call to Apply(\(g,\ell,r,\tau_{j^{\prime}}\)), we have

\[g_{\tau_{i}}=\begin{cases}e,&\text{if $i<j^{\prime}$},\\ \hat{g}_{\tau_{0}}\cdots\hat{g}_{\tau_{j}},&\text{if $i=j^{\prime}$},\\ \hat{g}_{\tau_{i}},&\text{if $i>j^{\prime}$}.\end{cases}\]

When we call Apply(\(g,\ell,r,\tau_{j}\)), since \(\text{seg}(\tau_{j})\subseteq[\ell:r]\), Line 5 is executed and the function returns after that. Now we have

\[g_{\tau_{i}}=\begin{cases}e,&\text{if $i<j$},\\ g\cdot\hat{g}_{\tau_{0}}\cdots\hat{g}_{\tau_{j}},&\text{if $i=j$},\\ \hat{g}_{\tau_{i}},&\text{if $i>j$}.\end{cases}\]

This implies \(g_{\tau_{0}}\cdots g_{\tau_{r}}=g\cdot\hat{g}_{\tau_{0}}\cdots\hat{g}_{\tau_{r}}\), as desired.

Similarly, if \(i\notin[\ell,r]\), let \(\tau_{j}\) be the first node among \(\tau_{0},\ldots,\tau_{r}\) such that \(\text{seg}(\tau_{j})\cap[\ell:r]=\emptyset\). We can show that

\[g_{\tau_{i}}=\begin{cases}e,&\text{if $i<j$};\\ \hat{g}_{\tau_{0}}\cdots\hat{g}_{\tau_{j}},&\text{if $i=j$};\\ \hat{g}_{\tau_{i}},&\text{if $i>j$}.\end{cases}\]

This implies \(g_{\tau_{0}}\cdots g_{\tau_{r}}=\hat{g}_{\tau_{0}}\cdots\hat{g}_{\tau_{r}}\), as desired.

Efficiency.The following result establishes the running time guarantee in Lemma 10.

**Lemma 12**.: _Both Access and Apply run in \(O(\log n)\) time._

Proof.: It is clear that Access runs in time \(O(r)=O(\log n)\). When we run Apply(\(g,\ell,r,\tau\)), the recursive calls at Lines 12-13 are made only when \([\ell:r]\) intersects but does not contain \(\mathsf{seg}(\tau)\), i.e., \(\emptyset\subsetneq\mathsf{seg}(\tau)\cap[\ell:r]\subsetneq\mathsf{seg}(\tau)\). There are at most \(2\) such nodes \(\tau\) at each level of the binary tree, so the total number of such nodes \(\tau\) is \(O(\log n)\). This implies that Apply runs in time \(O(\log n)\). 

### Tolerant testing via smooth calibration

For completeness, we first make the simple (but to our knowledge, new) observation that, while the constants in Lemma 4 are not necessarily tight, there is a constant gap between \(\underline{\mathsf{dCE}}\) and \(\mathsf{smCE}\).

**Lemma 13**.: _Suppose for constants \(B\geq A>0\), it is the case that \(A\cdot\underline{\mathsf{dCE}}(\mathcal{D})\leq\mathsf{smCE}(\mathcal{D})\leq B \cdot\underline{\mathsf{dCE}}(\mathcal{D})\) for all distributions \(\mathcal{D}\) over \([0,1]\times\{0,1\}\). Then, \(\frac{B}{A}\geq\frac{3}{2}\)._

Proof.: First, we claim that \(A\leq 1\). To see this, let \((v,y)\sim\mathcal{D}\) be distributed where \(v=\frac{1}{2}\) with probability \(1\), and \(y\sim\mathsf{Bern}(\frac{1}{2}+\varepsilon)\) for some \(\varepsilon\in[0,\frac{1}{2}]\). Clearly, \(\mathsf{smCE}(\mathcal{D})=|\frac{1}{2}-(\frac{1}{2}+\varepsilon)|=\varepsilon\). Moreover, \(\underline{\mathsf{dCE}}(\mathcal{D})=\varepsilon\), which follows from the same Jensen's inequality argument as in Lemma 5, so this shows that \(A\leq 1\). Next, we claim that \(B\geq\frac{3}{2}\), concluding the proof. Consider the joint distribution over \((u,v,y)\) in Table 4, and let \(\mathcal{D}\) be the marginal of \((v,y)\). It is straightforward to check \((u,y)\) is calibrated and \(\mathbb{E}|u-v|=\frac{\varepsilon}{2}\), so \(\underline{\mathsf{dCE}}(\mathcal{D})\leq\frac{\varepsilon}{2}\). Moreover, \(\mathsf{smCE}(v,y)\geq\frac{3\varepsilon}{4}\), as witnessed by the Lipschitz weight function \(w(v)\) in Table 4, finishing our proof that \(B\geq\frac{3}{2}\):

\[\mathsf{smCE}(v,y)\geq\mathbb{E}[(y-v)w(v)]=\frac{1}{2}\left(\left(\frac{1}{2} +\varepsilon\right)\cdot 1\right)+\frac{1}{2}\left(\left(-\frac{1}{2}\right) \cdot(1-\varepsilon)\right)=\frac{3\varepsilon}{4}.\]

Using these claims, we now give our tolerant calibration tester in the regime \(\varepsilon_{1}>4\varepsilon_{2}\).

**Theorem 3**.: _Let \(0\leq\varepsilon_{2}\leq\varepsilon_{1}\leq 1\) satisfy \(\varepsilon_{1}>4\varepsilon_{2}\), and let \(n\geq C_{\mathsf{kt}}\cdot\frac{1}{(\varepsilon_{1}-4\varepsilon_{2})^{2}}\) for a universal constant \(C_{\mathsf{kt}}\). There is an algorithm \(\mathcal{A}\) which solves the \((\varepsilon_{1},\varepsilon_{2})\)-tolerant calibration testing problem with \(n\) samples, which runs in time_

\[O\left(n\log^{2}(n)\right).\]

Proof.: Throughout the proof, let \(\alpha:=\frac{\varepsilon_{1}}{2}-2\varepsilon_{2}>0\). Consider the following algorithm.

1. Sample \(n\geq\frac{C_{\mathsf{kt}}}{\alpha^{2}}\) samples to form an empirical distribution \(\widehat{\mathcal{D}}_{n}\), where \(C_{\mathsf{kt}}\) is chosen large enough so that Lemma 3 guarantees \(|\mathsf{smCE}(\mathcal{D})-\mathsf{smCE}(\widehat{\mathcal{D}}_{n})|\leq \frac{\alpha}{2}\) with probability \(\geq\frac{2}{3}\).
2. Call Corollary 1 to obtain \(\beta\), the value of \(\mathsf{smCE}(\widehat{\mathcal{D}}_{n})\).
3. Return "yes" if \(\beta\leq 2\varepsilon_{2}+\frac{\alpha}{2}\), and return "no" otherwise.

Conditioned on the event \(|\mathsf{smCE}(\mathcal{D})-\mathsf{smCE}(\widehat{\mathcal{D}}_{n})|\leq \frac{\alpha}{2}\), we show that the algorithm succeeds in tolerant calibration testing. First, if \(\underline{\mathsf{dCE}}(\mathcal{D})\leq\varepsilon_{2}\), then \(\mathsf{smCE}(\mathcal{D})\leq 2\varepsilon_{2}\) by Lemma 4, and therefore by the assumed success of Lemma 3, the algorithm will return "yes." Second, if \(\underline{\mathsf{dCE}}(\mathcal{D})\geq\varepsilon_{1}\), then \(\mathsf{smCE}(\mathcal{D})\geq\frac{\varepsilon_{1}}{2}\) by Lemma 4, and similarly the algorithm returns "no" in this case. Finally, the runtime is immediate from Corollary 1; all other steps take \(O(1)\) time.

Lower distance to calibration

In this section, we provide our main result on approximating the lower distance to calibration of a distribution on \([0,1]\times\{0,1\}\). We provide details on a framework for lifting constrained linear programs to equivalent unconstrained counterparts in Appendix C.1. In Appendix C.2, we next state preliminary definitions and results from [1] used in our algorithm. In Appendix C.3, we then develop a rounding procedure compatible with a linear program which closely approximates the empirical lower distance to calibration. Finally, in Appendix C.4, we use our rounding procedure to design an algorithm for calibration testing, which solves the problem for a larger range of parameters than Theorem 4 (i.e. the entire relevant parameter range), at a quadratic runtime overhead.

### Rounding linear programs

In this section, we give a general framework for approximately solving linear programs, following similar developments in the recent combinatorial optimization literature [20, 19]. Roughly speaking, this framework is a technique for losslessly converting a constrained convex program to an unconstrained one, provided we can show existence of a rounding procedure compatible with the constrained program in an appropriate sense. We begin with our definition of a rounding procedure.

**Definition 6** (Rounding procedure).: _Consider a convex program defined on the intersection of convex set \(\mathcal{X}\) with linear equality constraints \(\mathbf{A}x=b\):_

\[\min_{\begin{subarray}{c}\mathbf{A}\in\mathcal{X}\\ \mathbf{A}x=b\end{subarray}}c^{\top}x. \tag{17}\]

_We say \(\mathsf{Round}\) is a \((\widetilde{\mathbf{A}},\tilde{b},p)\)-equality rounding procedure for \((\mathbf{A},b,c,\mathcal{X})\) if \(p\geq 1\), and for any \(x\in\mathcal{X}\), there exists \(x^{\prime}:=\mathsf{Round}(x)\in\mathcal{X}\) such that \(\mathbf{A}x^{\prime}=b\), \(\widetilde{\mathbf{A}}x^{\prime}=\tilde{b}\), and_

\[c^{\top}x^{\prime}\leq c^{\top}x+\left\|\widetilde{\mathbf{A}}x-\tilde{b} \right\|_{p}. \tag{18}\]

Intuitively, rounding procedures replace the hard-constrained problem (17) with its soft-constrained variants, i.e. the soft equality-constrained

\[\min_{x\in\mathcal{X}}c^{\top}x+\left\|\widetilde{\mathbf{A}}x-\tilde{b} \right\|_{p}, \tag{19}\]

for some \((\widetilde{\mathbf{A}},\tilde{b},p)\) constructed from the corresponding hard-constrained problem instance (parameterized by \(\mathbf{A},b,c,\mathcal{X}\)). Leveraging the assumptions on our rounding procedure, we now show how to relate approximate solutions to these problems, generalizing Lemma 1 of [19].

**Lemma 14**.: _Let \(x\) be an \(\varepsilon\)-approximate minimizer to (19), and let \(\mathsf{Round}\) be a \((\widetilde{\mathbf{A}},\tilde{b},p)\)-equality rounding procedure for \((\mathbf{A},b,c,\mathcal{X})\). Then \(x^{\prime}:=\mathsf{Round}(x)\) is an \(\varepsilon\)-approximate minimizer to (17)._

Proof.: We first claim that a minimizing solution to (19) satisfies the constraints \(\mathbf{A}x=b\). To see this, given any \(x\in\mathcal{X}\), we can produce \(x^{\prime}\in\mathcal{X}\) with \(\mathbf{A}x^{\prime}=b\) and such that \(x^{\prime}\) has smaller objective value in (19). Indeed, letting \(x^{\prime}:=\mathsf{Round}(x^{\prime})\), (18) guarantees

\[c^{\top}x^{\prime}=c^{\top}x^{\prime}+\left\|\widetilde{\mathbf{A}}x^{\prime}- \tilde{b}\right\|_{p}\leq c^{\top}x+\left\|\widetilde{\mathbf{A}}x-\tilde{b} \right\|_{p},\]

as claimed. Now let \(x^{*}\in\mathcal{X}\) satisfying \(\mathbf{A}x^{*}=b\) minimize (19). Then, if \(x\) is an \(\varepsilon\)-approximate minimizer to (19) and \(x^{\prime}=\mathsf{Round}(x)\), we have the desired claim from \(\mathbf{A}x^{\prime}=b\), and

\[c^{\top}x^{\prime}=c^{\top}x^{\prime}+\left\|\widetilde{\mathbf{A}}x^{\prime}- \tilde{b}\right\|_{p}\leq c^{\top}x+\left\|\widetilde{\mathbf{A}}x-\tilde{b} \right\|_{p}\leq c^{\top}x^{*}+\left\|\widetilde{\mathbf{A}}x^{*}-\tilde{b} \right\|_{p}=c^{\top}x^{*}+\varepsilon.\]

In the remainder of the section, we apply our rounding framework to a hard-constrained linear program, in the \(p=1\) geometry. To aid in approximately solving the soft-constrained linear programs arising from our framework, we use the following procedure from [19], building upon the recent literature for solving box-simplex games at accelerated rates [20, 19, 18]. In the statement of Proposition 2, we use the notation

\[\left\lVert\mathbf{A}\right\rVert_{p\to q}:=\max_{x\in\mathbb{R}^{n}\left\lVert x \right\rVert_{p}\leq 1}\left\lVert\mathbf{A}x\right\rVert_{q}.\]

Notice that in particular, \(\left\lVert\mathbf{A}\right\rVert_{1\to 1}\) is the largest \(\ell_{1}\) norm of any column of \(\mathbf{A}\).

**Proposition 2** (Theorem 1, [19]).: _Let \(\mathbf{A}\in\mathbb{R}^{n\times d}\), \(b\in\mathbb{R}^{d}\), \(c\in\mathbb{R}^{n}\), and \(\varepsilon>0\). There is an algorithm which computes an \(\varepsilon\)-approximate saddle point to the box-simplex game_

\[\min_{x\in[-1,1]^{n}}\max_{y\in\Delta^{d}}x^{\top}\mathbf{A}y-b^{\top}y+c^{\top }x, \tag{20}\]

_in time_

\[O\left(\operatorname{nnz}(\mathbf{A})\cdot\frac{\left\lVert\mathbf{A}\right\rVert _{1\to 1}\log d}{\varepsilon}\right).\]

We also require a standard claim on converting minimax optimization error to error on an induced minimization objective. To introduce our notation, we say that \(x\in\mathcal{X}\) is an \(\varepsilon\)-approximate minimizer of \(f:\mathcal{X}\to\mathbb{R}\) if \(f(x)-\min_{x^{\prime}\in\mathcal{X}}f(x^{\prime})\leq\varepsilon\). We call \((x,y)\in\mathcal{X}\times\mathcal{Y}\) an \(\varepsilon\)-approximate saddle point to a convex-concave function \(f:\mathcal{X}\times\mathcal{Y}\to\mathbb{R}\) if its duality gap is at most \(\varepsilon\), i.e.

\[\max_{y^{\prime}\in\mathcal{Y}}f(x,y^{\prime})-\min_{x^{\prime}\in\mathcal{X}} f(x^{\prime},y)\leq\varepsilon.\]

**Lemma 15**.: _Let \(f:\mathcal{X}\times\mathcal{Y}\to\mathbb{R}\) be convex-concave for compact \(\mathcal{X},\mathcal{Y}\), and let \(g(x):=\max_{y\in\mathcal{Y}}f(x,y)\) for \(x\in\mathcal{X}\). If \((x,y)\) is an \(\varepsilon\)-approximate saddle point to \(f\), \(x\) is an \(\varepsilon\)-approximate minimizer to \(g\)._

Proof.: Let \(y^{\prime}:=\operatorname{argmax}_{y\in\mathcal{Y}}f(x,y)\) and \(x^{\prime}:=\operatorname{argmin}_{x^{\prime}\in\mathcal{X}}f(x^{\prime},y)\). The conclusion follows from

\[\min_{x^{*}\in\mathcal{X}}g(x^{*})=\min_{x^{*}\in\mathcal{X}}\max_{y^{*}\in \mathcal{Y}}f(x^{*},y^{*})=\max_{y^{*}\in\mathcal{Y}}\min_{x^{*}\in\mathcal{ X}}f(x^{*},y^{*})\geq\min_{x^{\prime}\in\mathcal{X}}f(x^{\prime},y),\]

where we used strong duality (via Sion's minimax theorem), so that

\[g(x)-\min_{x^{*}\in\mathcal{X}}g(x^{*})\leq g(x)-f(x^{\prime},y)=f(x,y^{\prime })-f(x^{\prime},y)\leq\varepsilon.\]

The following corollary of Proposition 2 will be particularly useful in our development, which is immediate using Lemma 15, upon negating the box-simplex game (20), exchanging the names of the variables \((x,y)\), \((b,c)\), and explicitly maximizing over \(y\in[-1,1]^{n}\), i.e.

\[\min_{x\in\Delta^{d}}\left\langle c,x\right\rangle+\left\lVert\mathbf{A}x-b \right\rVert_{1}=\min_{x\in\Delta^{d}}\max_{y\in[-1,1]^{n}}\left\langle c,x \right\rangle+y^{\top}(\mathbf{A}x-b).\]

**Corollary 2**.: _Let \(\mathbf{A}\in\mathbb{R}^{n\times d}\), \(b\in\mathbb{R}^{n}\), \(c\in\mathbb{R}^{d}\), and \(\varepsilon>0\). There is an algorithm which computes an \(\varepsilon\)-approximate minimizer to \(\min_{x\in\Delta^{d}}c^{\top}x+\left\lVert\mathbf{A}x-b\right\rVert_{1}\), in time_

\[O\left(\operatorname{nnz}(\mathbf{A})\cdot\frac{\left\lVert\mathbf{A}\right \rVert_{1\to 1}\log d}{\varepsilon}\right).\]

### LDTC preliminaries

In this section, we collect preliminaries for our testing algorithm based on estimating the LDTC. First, analogously to Lemma 3, we recall a bound from [1] on the deviation of the empirical estimate of \(\underline{\mathsf{dCE}}(\mathcal{D})\) from the population truth which holds with constant probability.

**Lemma 16** (Theorem 9.10, [1]).: _For any \(\varepsilon\in(0,1)\), there is an \(n=O(\frac{1}{\varepsilon^{2}})\) such that, if \(\widehat{\mathcal{D}}_{n}\) is the empirical distribution over \(n\) i.i.d. draws from \(\mathcal{D}\), with probability \(\geq\frac{2}{3}\),_

\[\left|\underline{\mathsf{dCE}}(\mathcal{D})-\underline{\mathsf{dCE}}(\widehat{ \mathcal{D}}_{n})\right|\leq\varepsilon.\]

Next, given a set \(U\subset[0,1]\), we provide an analog of Definition 1 which is restricted to \(U\).

**Definition 7** (\(U\)-Ldtc).: _Let \(U\subset[0,1]\), and let \(\mathcal{D}\) be a distribution over \([0,1]\times\{0,1\}\). Define \(\operatorname{ext}^{U}(\mathcal{D})\) to be all joint distributions \(\Pi\) over \((u,v,y)\in U\times[0,1]\times\{0,1\}\), with the following properties._

* _The marginal distribution of_ \((v,y)\) _is_ \(\mathcal{D}\)_._
* _The marginal distribution_ \((u,y)\) _is perfectly calibrated, i.e._ \(\mathbb{E}_{\Pi}[y|u]=u\)_._

_The \(U\)-lower distance to calibration (U-LDTC) of \(\mathcal{D}\), denoted \(\underline{\mathsf{dCE}}^{U}(\mathcal{D})\), is defined by_

\[\underline{\mathsf{dCE}}^{U}(\mathcal{D}):=\inf_{\Pi\in\operatorname{ext}^{U} (\mathcal{D})}\mathbb{E}_{(u,v,y)\sim\Pi}\left|u-v\right|.\]

Note that if we require \(\{0,1\}\subset U\), then \(\operatorname{ext}^{U}(\mathcal{D})\) is always nonempty, because we can let \(u=y\) with probability \(1\). We also state a helper claim from [1], which relates \(\underline{\mathsf{dCE}}^{U}\) to \(\underline{\mathsf{dCE}}\).

**Lemma 17** (Lemma 7.11, [1]).: _Let \(\mathcal{D}\) be a distribution over \([0,1]\times\{0,1\}\), and let \(U\) be a finite \(\frac{\epsilon}{2}\)-covering of \([0,1]\) satisfying \(\{0,1\}\subseteq U\). Then, \(\underline{\mathsf{dCE}}(\mathcal{D})\leq\underline{\mathsf{dCE}}^{U}( \mathcal{D})\leq\underline{\mathsf{dCE}}(\mathcal{D})+\varepsilon\)._

To this end, in the rest of the section we define, for any \(\varepsilon\in(0,1)\),

\[U_{\varepsilon}:=\{0,1\}\cup\left\{\frac{i\varepsilon}{2}\mid i\in\left[\left| \frac{2}{\varepsilon}\right|\right]\right\}, \tag{21}\]

which is an \(\frac{\epsilon}{2}\)-cover of \([0,1]\) satisfying \(|U_{\varepsilon}|=O(\frac{1}{\varepsilon})\). Finally, we state a linear program, derived in [1], whose value equals \(\underline{\mathsf{dCE}}^{U}(\mathcal{D})\), when the first marginal of \(\mathcal{D}\) is discretely supported.

**Lemma 18** (Lemma 7.6, [1]).: _Let \(U,V\subset[0,1]\) be discrete sets, where \(\{0,1\}\subset U\), and let \(\mathcal{D}\) be a distribution over \(V\times\{0,1\}\), where for \((v,y)\in V\times\{0,1\}\) we denote the probability of \((v,y)\sim\mathcal{D}\) by \(\mathcal{D}(v,y)\). The following linear program with \(2|U||V|\) variables \(\Pi(u,v,y)\) for all \((u,v,y)\in U\times V\times\{0,1\}\), is feasible, and its optimal value equals \(\underline{\mathsf{dCE}}^{U}(\mathcal{D})\):_

\[\min_{\Pi\in\mathbb{R}^{2|U||V|}_{\geq 0}}\sum_{(u,v,y)\in U\times V \times\{0,1\}}\left|u-v\right|\Pi(u,v,y)\] \[\text{such that }\sum_{u\in U}\Pi(u,v,y)=\mathcal{D}(v,y),\text{ for all }(v,y)\in V\times\{0,1\},\] \[\text{and }(1-u)\sum_{v\in V}\Pi(u,v,1)=u\sum_{v\in V}\Pi(u,v,0),\text{ for all }u\in U.\]

### Rounding for empirical \(U\)-Ldtc

In this section we fix a dataset under consideration,

\[\widehat{\mathcal{D}}_{n}:=\{(v_{i},y_{i})\}_{i\in[n]}\subset[0,1]\times\{0,1\},\]

and the corresponding empirical distribution, also denoted \(\widehat{\mathcal{D}}_{n}\), where \((v,y)\sim\widehat{\mathcal{D}}_{n}\) means \((v,y)=(v_{i},y_{i})\) with probability \(\frac{1}{n}\) for each \(i\in[n]\). We let \(V:=\{v_{i}\}_{i\in[n]}\) be identified with \([n]\) in the natural way. Moreover, for a fixed parameter \(\varepsilon\in(0,1)\) throughout, we let \(U:=U_{\varepsilon}\) defined in (21). Finally, we denote \(m:=|U|=O(\frac{1}{\varepsilon})\), and let \(\mathbf{U}\in[0,1]^{m\times m}\) be the diagonal matrix whose diagonal entries correspond to \(U\). We also identify elements of \(U\) with \(j\in[m]\) in an arbitrary but consistent way, writing \(u_{j}\in[0,1]\) to mean the \(j^{\text{th}}\) element of \(U\) according to this identification.

We next rewrite the linear program in Lemma 18 into a more convenient reformulation.

**Lemma 19**.: _The linear program in Lemma 18 can equivalently be written as:_

\[\underline{\mathsf{dCE}}^{U}(\widehat{\mathcal{D}}_{n}):=\min_{ \begin{subarray}{c}\underline{\mathsf{M}}_{n}\in\underline{\mathsf{L}}\\ \mathbf{U}\mathbf{B}_{0}x_{0}=(\mathbf{I}_{m}^{-}\mathbf{U})\mathbf{B}_{1}x_{1} \end{subarray}}c^{\top}x,\text{ where }\mathcal{X}:=\Delta^{2mn}\text{ and we denote }x=\begin{pmatrix}x_{0}\in\mathbb{R}^{mn}\\ x_{1}\in\mathbb{R}^{mn}\end{pmatrix}, \tag{22}\]_where we define \(c\in\mathbb{R}^{2mn}\), \(\mathbf{M}\in\mathbb{R}^{n\times 2mn}\), and \(\mathbf{B}_{0},\mathbf{B}_{1}\in\mathbb{R}^{m\times mn}\) by_

\[c_{(i,j,k)} :=|u_{j}-v_{i}|\;\text{ for all }(i,j,k)\in[n]\times[m]\times\{0,1\},\] \[\mathbf{M}_{i^{\prime},(i,j,k)} :=\begin{cases}1&y_{i}=k,\;i^{\prime}=i\\ 0&\text{else}\end{cases}\;\text{ for all }i^{\prime}\in[n],(i,j,k)\in[n]\times[m] \times\{0,1\},\] \[\text{and }\left[\mathbf{B}_{0}\right]_{j^{\prime},(i,j,k)} :=\begin{cases}1&j=j^{\prime},\;k=0\\ 0&\text{else}\end{cases}\;\text{ for all }j^{\prime}\in[m],(i,j,k)\in[n] \times[m]\times\{0,1\},\] \[\left[\mathbf{B}_{1}\right]_{j^{\prime},(i,j,k)} :=\begin{cases}1&j=j^{\prime},\;k=1\\ 0&\text{else}\end{cases}\;\text{ for all }j^{\prime}\in[m],(i,j,k)\in[n] \times[m]\times\{0,1\}.\]

Proof.: This is clear from observation, but we give a brief explanation of the notation. First, \(x\in\mathcal{X}\) represents the density function of our joint distribution \(\Pi\) over \(U\times V\times\{0,1\}\), and has \(2mn\) coordinates identified with elements \((i,j,k)\in V\times U\times\{0,1\}\equiv[n]\times[m]\times\{0,1\}\). We let the subset of coordinates with \(k=0\) be denoted \(x_{0}\in\mathbb{R}^{mn}\), defining \(x_{1}\) similarly. Recalling the definition of the linear program in Lemma 18, \(x_{(i,j,k)}\) is indeed reweighted by \(c_{(i,j,k)}=|u_{j}-v_{i}|\).

Next, \(\mathbf{M}\) represents the marginal constraints in Lemma 18, and enforcing \(\mathbf{M}x=\frac{1}{n}\mathbbm{1}_{n}\) is equivalent to the statement that, for each \(i^{\prime}\in[n]\), the sum of all entries \((i,j,k)\) of \(x\) with \(i=i^{\prime}\) and \(k=y_{i}\) is \(\frac{1}{n}\), since that is the probability density assigned to \((v_{i^{\prime}},y_{i^{\prime}})\) by the distribution \(\widehat{\mathcal{D}}_{n}\).

Lastly, the \(j^{\text{th}}\) calibration constraint in Lemma 18 is enforced by the \(j^{\text{th}}\) row of the equation \(\mathbf{UB}_{0}x_{0}=(\mathbf{I}_{m}-\mathbf{U})\mathbf{B}_{1}x_{1}\), which reads \(u_{j}\left\langle[\mathbf{B}_{0}]_{j:},x_{0}\right\rangle=(1-u_{j})\left\langle [\mathbf{B}_{1}]_{j:},x_{1}\right\rangle\). We can check by the definitions of \([\mathbf{B}_{0}]_{j:}\), \([\mathbf{B}_{1}]_{j:}\) that this is consistent with our earlier calibration constraints.

We give a convenient way of visualizing the marginal and calibration constraints described in Lemma 19. For convenience, we identify each \(x\in\Delta^{2mn}\) with an \(m\times 2n\) matrix

\[\text{mat}(x)=\mathbf{X}=\left(\mathbf{X}_{0}\in\mathbb{R}^{m\times n}\quad \mathbf{X}_{1}\in\mathbb{R}^{m\times n}\right), \tag{23}\]

where \(\mathbf{X}_{0}\) consists of entries of \(x_{0}\) arranged in a matrix fashion (with rows corresponding to \([m]\equiv U\) and columns corresponding to \([n]\equiv V\)), and similarly \(\mathbf{X}_{1}\) is a rearrangement of \(x_{1}\), recalling (22). When explaining how we design our rounding procedures to modify \(\mathbf{X}\) to satisfy constraints, it will be helpful to view entries of \(\mathbf{X}\) as denoting an amount of physical mass which we can move around.

There are \(2n\) columns in \(\mathbf{X}\), corresponding to pairs \((i,k)\in V\times\{0,1\}\); among these, we say \(n\) columns are "active," where column \((i,k)\) is active iff \(y_{i}=k\), and we say the other \(n\) columns are "inactive." Following notation (23), the marginal constraints \(\mathbf{X}=\frac{1}{n}\mathbbm{1}_{n}\) simply ask that the total amount of mass in each active column is \(\frac{1}{n}\), so there is no mass in any inactive column since \(x\in\Delta^{2mn}\).

Moreover, there are \(m\) rows in \(\mathbf{X}\), each corresponding to some \(j\in U\). If we let \(\ell_{j}\) denote the amount of mass on \([\mathbf{X}_{0}]_{j:}\) and \(r_{j}\) the amount of mass on \([\mathbf{X}_{1}]_{j:}\), the \(j^{\text{th}}\) calibration constraint simply asks that \(u_{j}\ell_{j}=(1-u_{j})r_{j}\), i.e. it enforces balance on the amount of mass in each row's two halves.

Finally, for consistency with Definition 6, the linear program in (22) can be concisely written as

\[\min_{\begin{subarray}{c}x\in\mathcal{X}\\ \mathcal{X}=b\end{subarray}}c^{\top}x,\text{ where }\mathbf{A}:=\begin{pmatrix} \mathbf{M}\\ \mathbf{B}\end{pmatrix},\;\mathbf{B}:=\left(\mathbf{UB}_{0}\quad-(\mathbf{I} _{m}-\mathbf{U})\mathbf{B}_{1}\right),\;b:=\left(\frac{\mathbbm{1}_{n} \mathbbm{1}_{n}}{0}\right) \tag{24}\]

and \(c\), \(\mathcal{X}\) are as defined in (22). In the rest of the section, following Definition 6, we develop an equality rounding procedure for the equality-constrained linear program in (24) in two steps.

1. In Lemma 20, we first show how to take \(x\in\mathcal{X}\) with \(\|\mathbf{M}x-\frac{1}{n}\mathbbm{1}_{n}\|_{1}=\Delta\), and produce \(x^{\prime}\in\mathcal{X}\) such that \(\mathbf{M}x^{\prime}=\frac{1}{n}\mathbbm{1}_{n}\) (i.e. \(x^{\prime}\) now satisfies the marginal constraints) and \(\|x-x^{\prime}\|_{1}=O(\Delta)\).
2. In Lemma 22, we then consider \(x\in\mathcal{X}\) such that, following the notation (22), \(\|\mathbf{UB}_{0}x_{0}-(\mathbf{I}_{m}-\mathbf{U})\mathbf{B}_{1}x_{1}\|_{1}=\Delta\). We show how to produce \(x^{\prime}\in\mathcal{X}\) such that \(\mathbf{M}x=\mathbf{M}x^{\prime}\) (i.e. the marginals of \(x^{\prime}\) are unchanged), \(\mathbf{UB}_{0}x^{\prime}_{0}=(\mathbf{I}_{m}-\mathbf{U})\mathbf{B}_{1}x^{ \prime}_{1}\) (i.e. \(x^{\prime}\) is calibrated), and \(\langle c,x^{\prime}-x\rangle=O(\Delta)\).

Our rounding procedure uses Lemma 20 to satisfy the marginal constraints in (22), and then applies Lemma 22 to the result to satisfy the calibration constraints in (22) without affecting the marginal constraints. By leveraging the stability guarantees on these steps, we can show this is indeed a valid rounding procedure in the sense of (18). We now give our first step for marginal satisfaction.

**Lemma 20** (Marginal satisfaction).: _Following notation in (22), let \(x\in\mathcal{X}\) satisfy \(\|\mathbf{M}x-\frac{1}{n}\mathbb{1}_{n}\|_{1}=\Delta\). There is an algorithm which runs in time \(O(mn)\), and returns \(x^{\prime}\) with_

\[\mathbf{M}x^{\prime}=\frac{1}{n}\mathbb{1}_{n},\ \|x-x^{\prime}\|_{1}\leq 2\Delta.\]

Proof.: Recall for \(i\in[n]\), we say column \(i\) of \(\mathbf{X}_{0}\) is active if \(y_{i}=0\), and similarly column \(i\) of \(\mathbf{X}_{1}\) is active if \(y_{i}=1\). We call \(I\) the set of \(n\) inactive columns, and partition \(A\), which we call the set of \(n\) active columns, into three sets \(A^{>}\), \(A^{=}\), and \(A^{<}\), where \(A^{>}\) are the columns whose sums are \(>\frac{1}{n}\), \(A^{<}\) are the columns whose sums are \(<\frac{1}{n}\), and \(A^{=}\) are the remaining columns. Hence, every column of \(\mathbf{X}\) belongs to \(I\), \(A^{>}\), \(A^{=}\), or \(A^{\leq}\). Note that until \(|A^{=}|=n\), we can never have \(A^{<}=\emptyset\), since this means all column sums in \(A\) are \(\geq\frac{1}{n}\) (with at least \(1\) strict inequality), contradicting \(x\in\mathcal{X}\).

We first take columns \(i\in A^{>}\) one at a time, and pair them with an arbitrary column in \(i^{\prime}\in A^{<}\), moving mass from column \(i\) arbitrarily to column \(i^{\prime}\) until either column \(i\) or column \(i^{\prime}\) enters \(A^{=}\). We charge this movement to the marginal constraints corresponding to \(i\) and \(i^{\prime}\), since the constraints were violated by the same amount as the mass being moved. After this process is complete, \(A^{>}\) is empty, and we only moved mass from columns originally in \(A^{>}\) to columns originally in \(A^{<}\).

Next, we take columns \(i\in I\) one at a time, and pair them with an arbitrary column \(i^{\prime}\in A^{<}\), moving mass until either column \(i\) is \(\mathbbold{0}_{m}\) or column \(i^{\prime}\) enters \(A^{=}\). We can charge half this movement to the marginal constraint corresponding to \(i^{\prime}\), since the sign of the marginal violation stays the same throughout. Hence, the overall movement is \(\leq 2\Delta\). After this is complete, all columns in \(I\) are \(\mathbbold{0}_{m}\) and all columns in \(A\) are in \(A^{=}\), so we can return \(x^{\prime}\in\Delta^{2mn}\) corresponding to the new matrix.

It is clear both steps of this marginal satisfaction procedure take \(O(mn)\) time, since we can sequentially process columns in \(A^{-}\) until they enter \(A^{=}\), and will never be considered again. 

We next describe a procedure which takes \(x\in\Delta^{2mn}\), and modifies it to satisfy the calibration constraints \(\mathbf{U}\mathbf{B}_{0}x=(\mathbf{I}_{m}-\mathbf{U})\mathbf{B}_{1}x\) without changing the marginals \(\mathbf{M}x\). We first provide a helper lemma used in our rounding procedure, which describes how to fix the \(j^{\text{th}}\) marginal constraint.

**Lemma 21**.: _Let \(x\in\Delta^{2mn}\) and \(\mathbf{X}:=\text{\rm mat}(x)\) as defined in (23). Let \(j\in[m]\) correspond to an element \(u_{j}\in U\), let \(\ell_{j}:=\|[\mathbf{X}_{0}]_{j}\|_{1}\), \(r_{j}:=\|[\mathbf{X}_{1}]_{j}\|_{1}\), and let \(\Delta_{j}:=|u_{j}\ell_{j}-(1-u_{j})r_{j}|\). There exists \(j^{\prime}\in[m]\) such that we can move mass from only \(\mathbf{X}_{j}\) to \(\mathbf{X}_{j^{\prime}}\), resulting in \(\mathbb{R}^{m\times 2n}\ni\mathbf{X}^{\prime}\equiv x^{\prime}\in\Delta^{2mn}\) such that \(\mathbf{M}x^{\prime}=\mathbf{M}x\), \(u_{j}\|[\mathbf{X}_{0}^{\prime}]_{j}\|_{1}=(1-u_{j})\|[\mathbf{X}_{1}^{\prime} ]_{j}\|_{1}\), and \(\langle c,x^{\prime}-x\rangle\leq\Delta_{j}\)._

Proof.: Without loss of generality, suppose that the row \(j=1\) corresponds to \(u_{j}=0\), and \(j=m\) corresponds to \(u_{j}=1\). We split the proof into two cases, depending on the sign of \(u_{j}\ell_{j}-(1-u_{j})r_{j}\).

_Case 1: \(u_{j}\ell_{j}>(1-u_{j})r_{j}\)._ We let \(j^{\prime}=1\), i.e. we only move mass from the \(j^{\text{th}}\) row to the first row. Specifically, we leave \([\mathbf{X}_{1}]_{j}\): unchanged, and move mass from \([\mathbf{X}_{0}]_{j}\): to \([\mathbf{X}_{0}]_{1}\), making sure to only move mass in the same column. The total amount of mass we must delete from \([\mathbf{X}_{0}]_{j}\): is

\[\ell_{j}-\frac{1-u_{j}}{u_{j}}\cdot r_{j}=\frac{u_{j}\ell_{j}-(1-u_{j})r_{j}}{ u_{j}}=\frac{\Delta_{j}}{u_{j}}.\]

Our strategy is to arbitrarily move mass within columns until we have deleted \(\frac{\Delta_{j}}{u_{j}}\) total mass. If we denote the mass moved in column \(i\in[n]\) as \(\delta_{ij}\), and let \(x^{\prime}\) be the result after the move,

\[\langle c,x^{\prime}-x\rangle\leq\sum_{i\in[n]}|c_{(i,1,0)}-c_{(i,j,0)}|\delta_ {ij}=\sum_{i\in[n]}||u_{j}-v_{i}|-|u_{1}-v_{i}||\,\delta_{ij}\leq\sum_{i\in[n] }u_{j}\delta_{ij}=\Delta_{j}.\]

Here, the first inequality was the triangle inequality, the first equality used the definition of \(c\) in (22), the second inequality used \(u_{1}=0\) and the triangle inequality, and the last used \(\sum_{i\in[n]}\delta_{ij}=\frac{\Delta_{j}}{u_{j}}\).

_Case 2: \(u_{j}\ell_{j}<(1-u_{j})r_{j}\)._ This case is entirely analogous; we move mass arbitrarily from row \(j\) to row \(m\), i.e. the last row with \(u_{m}=1\). The amount of mass we must move is

\[r_{j}-\frac{u_{j}}{1-u_{j}}\ell_{j}=\frac{(1-u_{j})r_{j}-u_{j}\ell_{j}}{1-u_{j} }=\frac{\Delta_{j}}{1-u_{j}}.\]

Again denoting the amount of mass moved from column \(i\in[n]\) as \(\delta_{ij}\), the claim follows:

\[\left\langle c,x^{\prime}-x\right\rangle\leq\sum_{i\in[n]}\left|\left|u_{j}-v_{i }\right|-\left|u_{m}-v_{i}\right|\right|\delta_{ij}\leq\sum_{i\in[n]}(1-u_{j}) \delta_{ij}=\Delta_{j}.\]

By iteratively applying Lemma 21, we have our marginal-preserving calibration procedure.

**Lemma 22** (Marginal-preserving calibration).: _Following the notation (24), given \(x\in\Delta^{2mn}\) with \(\left\|\mathbf{B}x\right\|_{1}=\Delta\), we can compute \(x^{\prime}\) with \(\mathbf{M}x^{\prime}=\mathbf{M}x\), \(\mathbf{B}x^{\prime}=0_{m}\), and \(\left\langle c,x^{\prime}-x\right\rangle\leq\Delta\) in \(O(mn)\) time._

Proof.: It suffices to apply Lemma 21 to each row \(i\in[m]\). All of the movement in the rows \(i\in[2,m-1]\) are independent of each other, and do not affect the imbalance in the rows \(i\in\{1,m\}\) when we have finished applying Lemma 21, since e.g. \(u_{1}\ell_{1}=0\) regardless of how much mass is moved to \([\mathbf{X}_{0}]_{1:}\), and a similar property holds for the \(m^{\text{th}}\) row. The total change in \(\left\langle c,x^{\prime}-x\right\rangle\) is thus boundable by \(\sum_{j\in[m]}\Delta_{j}\leq\Delta\), and applying Lemma 21 to each row takes \(O(n)\) time. Finally, \(\mathbf{M}x=\mathbf{M}x^{\prime}\) follows because we only move mass within the same column, so no marginal changes. 

By combining Lemma 20 with Lemma 22, we can complete our rounding procedure.

**Lemma 23**.: _Let \((\mathbf{A},b,c,\mathcal{X})\) be defined as in (22), (24), and let \((\widetilde{\mathbf{A}},\tilde{b}):=(4\mathbf{A},4b)\). There exists \(\text{Round}\), \(a\)\((\widetilde{\mathbf{A}},\tilde{b},1)\)-equality rounding procedure for \((\mathbf{A},b,c,\mathcal{X})\), running in \(O(mn)\) time._

Proof.: Throughout the proof, let \(\Delta_{\mathbf{M}}:=\left\|\mathbf{M}x-\frac{1}{n}\mathbb{1}_{n}\right\|_{1}\) and \(\Delta_{\mathbf{B}}:=\left\|\mathbf{B}x\right\|_{1}\), following the notation (24). We also denote the total violation by

\[\Delta:=\left\|\widetilde{\mathbf{A}}x-\tilde{b}\right\|_{1}=4\Delta_{ \mathbf{M}}+4\Delta_{\mathbf{B}}.\]

We first apply Lemma 20 to \(x\) to produce \(\tilde{x}\) satisfying \(\left\|x-\tilde{x}\right\|_{1}\leq 2\Delta_{\mathbf{M}}\) and \(\mathbf{M}\tilde{x}=\frac{1}{n}\mathbb{1}_{n}\), in \(O(mn)\) time. Note that, because \(\left\|\mathbf{B}\right\|_{1\to 1}\leq 1\) since all columns of \(\mathbf{B}\) are \(1\)-sparse, we have

\[\left\|\mathbf{B}\tilde{x}\right\|_{1}\leq\left\|\mathbf{B}x\right\|_{1}+ \left\|\mathbf{B}\right\|_{1\to 1}\left\|x-\tilde{x}\right\|_{1}\leq\Delta_{ \mathbf{B}}+2\Delta_{\mathbf{M}}.\]

Next, we apply Lemma 22 to \(\tilde{x}\), resulting in \(x^{\prime}\) with \(\mathbf{M}x^{\prime}=\frac{1}{n}\mathbb{1}_{n}\), \(\mathbf{B}x^{\prime}=0_{m}\), and \(\left\langle c,x^{\prime}-\tilde{x}\right\rangle\leq\Delta_{\mathbf{B}}+2 \Delta_{\mathbf{M}}\), in \(O(mn)\) time. Recalling the definition (19), we have the conclusion from \(\left\|c\right\|_{\infty}\leq 1\), so

\[c^{\top}(x^{\prime}-x) \leq c^{\top}(\tilde{x}-x)+c^{\top}(x^{\prime}-\tilde{x})\] \[\leq\left\|c\right\|_{\infty}\left\|\tilde{x}-x\right\|_{1}+c^{ \top}(x^{\prime}-\tilde{x})\leq 2\Delta_{\mathbf{M}}+\Delta_{\mathbf{B}}+2 \Delta_{\mathbf{M}}\leq\Delta.\]

We conclude by applying the solver from Corollary 2 to our resulting unconstrained linear program.

**Proposition 3**.: _Let \(\varepsilon\geq 0\). We can compute \(x\in\mathcal{X}\), \(an\)\(\varepsilon\)-approximate minimizer to (22), in time_

\[O\left(\frac{n\log(n)}{\varepsilon^{2}}\right).\]

_Further, the objective value of \(x\) in (22) is a \(2\varepsilon\)-additive approximation of \(\mathsf{dCE}(\widehat{\mathcal{D}}_{n})\)._

Proof.: Observe that for \(\widetilde{\mathbf{A}}=4\mathbf{A}\), we have \(\left\|\widetilde{\mathbf{A}}\right\|_{1\to 1}\leq 8\) and \(\mathsf{nnz}(\widetilde{\mathbf{A}})=O(mn)\), since no column is more than \(2\)-sparse and all entries of \(\mathbf{A}\) are in \([-1,1]\). Further, recalling the definition of \(U\) from (21), we have \(m=O(\frac{1}{\varepsilon})\). So, Corollary 2 shows we can compute an \(\varepsilon\)-approximate minimizer to

\[\min_{x\in\Delta^{2mn}}c^{\top}x+\left\|\widetilde{\mathbf{A}}x-\tilde{b} \right\|_{1}\]

within the stated runtime. The rest of the proof follows using Round from Lemma 23, where we recall \(\left|\mathsf{dCE}(\widehat{\mathcal{D}}_{n})-\mathsf{dCE}^{U}(\widehat{ \mathcal{D}}_{n})\right|\leq\varepsilon\) due to our definition of \(U\) and Lemma 17.

### Testing via LDTC

We now give analogs of Theorems 1 and 3, using our solver in Proposition 3.

**Theorem 4**.: _Let \(0\leq\varepsilon_{2}\leq\varepsilon_{1}\leq 1\) satisfy \(\varepsilon_{1}>\varepsilon_{2}\), and let \(n\geq C_{\textnormal{ct}}\cdot\frac{1}{(\varepsilon_{1}-\varepsilon_{2})^{2}}\) for a universal constant \(C_{\textnormal{ct}}\). There is an algorithm \(\mathcal{A}\) which solves the \((\varepsilon_{1},\varepsilon_{2})\)-tolerant calibration testing problem with \(n\) samples, which runs in time_

\[O\left(\frac{n\log(n)}{(\varepsilon_{1}-\varepsilon_{2})^{2}}\right).\]

Proof.: Throughout the proof, let \(\alpha:=\varepsilon_{1}-\varepsilon_{2}>0\). Consider the following algorithm.

1. For \(|U|=m\geq\frac{6}{\alpha}\), sample \(n\geq\frac{C_{\textnormal{ct}}}{\alpha^{2}}\) samples to form an empirical distribution \(\widehat{\mathcal{D}}_{n}\), where \(C_{\textnormal{ct}}\) is chosen so Lemma 3 guarantees \(|\underline{\textnormal{dCE}}(\mathcal{D})-\underline{\textnormal{dCE}}( \widehat{\mathcal{D}}_{n})|\leq\frac{\alpha}{6}\) with probability \(\geq\frac{2}{3}\).
2. Call Proposition 2 with \(\varepsilon\leftarrow\frac{\alpha}{6}\) to obtain \(\beta\), an \(\frac{\alpha}{3}\)-additive approximation to \(|\underline{\textnormal{dCE}}(\widehat{\mathcal{D}}_{n})|\).
3. Return "yes" if \(\beta\leq\varepsilon_{2}+\frac{\alpha}{2}\), and return "no" otherwise.

Conditioned on the event that \(|\underline{\textnormal{dCE}}(\mathcal{D})-\underline{\textnormal{dCE}}( \widehat{\mathcal{D}}_{n})|\leq\frac{\alpha}{6}\), we show that the algorithm succeeds. First, if \(\underline{\textnormal{dCE}}(\mathcal{D})\leq\varepsilon_{2}\), then \(\underline{\textnormal{dCE}}(\widehat{\mathcal{D}}_{n})\leq\varepsilon_{2}+ \frac{\alpha}{6}\) by assumption, and so \(\beta\leq\varepsilon_{2}+\frac{\alpha}{2}\) by Proposition 2, so the tester will return "yes." Second, if \(\underline{\textnormal{dCE}}(\mathcal{D})\geq\varepsilon_{1}\), then \(\underline{\textnormal{dCE}}(\widehat{\mathcal{D}}_{n})\geq\varepsilon_{1}- \frac{\alpha}{6}\) by assumption, so \(\beta\geq\varepsilon_{1}-\frac{\alpha}{2}\) by Proposition 2 and similarly the tester will return "no" in this case. Finally, the runtime is immediate from Proposition 3 and the definition of \(\alpha\). 

Theorem 4 has the following implication for (standard) calibration testing, by letting \(\varepsilon_{2}=0\).

**Corollary 3**.: _Let \(n\in\mathbb{N}\) and let \(\varepsilon_{n}\in(0,1)\) be minimal such that it is information-theoretically possible to solve the \(\varepsilon_{n}\)-calibration testing problem with \(n\) samples. For some \(\varepsilon=\Theta(\varepsilon_{n})\), there is an algorithm \(\mathcal{A}\) which solves the \(\varepsilon\)-calibration testing problem with \(n\) samples, which runs in time_

\[O\left(n^{2}\log(n)\right).\]

## Appendix D Sample complexity lower bounds for calibration measures

Recent works [1, 1] have introduced other calibration measures (e.g. the convolved ECE and interval CE), given efficient estimation algorithms for them, and showed that they are polynomially related to the lower distance to calibration \(\underline{\textnormal{dCE}}\). Therefore, an alternative approach to the (non-tolerant) testing problem for \(\underline{\textnormal{dCE}}\) is by reducing it to testing problems for these measures. The main result of this section is that this approach leads to suboptimal sample complexity: the testing problems for these measures cannot be solved given only \(O(\varepsilon^{-2})\) data points \(\{(v_{i},y_{i})\}_{i\in[n]}\).

To establish this sample complexity lower bound, we construct a perfectly calibrated distribution \(\mathcal{D}_{0}\) and a family of miscalibrated distributions \(\mathcal{D}_{\theta}\) parameterized by \(\theta\) belonging to a finite set. We use \(\mathcal{D}_{0}^{\otimes n}\) (and \(\mathcal{D}_{\theta}^{\otimes n}\)) to denote the joint distribution of \(n\) independent examples from \(\mathcal{D}_{0}\) (and \(\mathcal{D}_{\theta}\)). In Lemma 24, we show that the total variation distance between \(\mathcal{D}_{0}^{\otimes n}\) and the mixture \(\mathbb{E}[\mathcal{D}_{\theta}^{\otimes n}]\) of \(\mathcal{D}_{\theta}^{\otimes n}\) is small unless \(n\) is large, and thus distinguishing them requires large sample complexity. Consequently, the testing problem for a calibration measure has large sample complexity if it assigns every \(\mathcal{D}_{\theta}\) a large calibration error. Finally, we show every \(\mathcal{D}_{\theta}\) indeed has large convolved ECE and interval CE, establishing sample complexity lower bounds for these measures in Theorems 5 and 6.

To construct \(\mathcal{D}_{0}\) and \(\mathcal{D}_{\theta}\), we consider \(t\) values \(\{u_{i}\}_{i\in[t]}\in[\frac{1}{3},\frac{2}{3}]\) where \(u_{i}=\frac{1}{3}+\frac{i}{3t}\) for \(i\in[t]\). We will determine the value of \(t\in\mathbb{N}\) later. We also define the following distribution, a perfectly calibrated distribution which is related to the miscalibrated synthetic dataset used in Section 3.

**Definition 8**.: _The distribution \(\mathcal{D}_{0}\) of \((v,y)\in[0,1]\times\{0,1\}\) is defined such that the marginal distribution of \(v\) is uniform over \(\{u_{i}\}_{i\in[t]}\) and \(\mathbb{E}_{\mathcal{D}_{0}}[y|v]=v\)._

Fix \(\alpha\in(0,\frac{1}{3})\). For \(\theta\in\{-1,1\}^{t}\), we define distribution \(\mathcal{D}_{\theta}\) of \((v,y)\in[0,1]\times\{0,1\}\) such that the marginal distribution of \(v\) is uniform over \(\{u_{i}\}_{i\in[t]}\) and \(\mathbb{E}_{\mathcal{D}_{\theta}}[y|v=u_{i}]=u_{i}+\theta_{i}\alpha\). In other words,each conditional distribution given \(v\) is miscalibrated by \(\alpha\), but the bias takes a random direction. We now follow a standard approach by [13] to bound the total variation between our distributions.

**Lemma 24**.: _For any \(t\in\mathbb{N}\) and \(\alpha\in(0,\frac{1}{3})\),_

\[\mathrm{d}_{\mathrm{TV}}(\mathcal{D}_{0}^{\otimes n},\mathbb{E}_{\theta}[ \mathcal{D}_{\theta}^{\otimes n}])\leq\frac{1}{2}\sqrt{\exp\left(\frac{11 \alpha^{4}n^{2}}{t}\right)-1}.\]

_Here, to construct the mixture distribution \(\mathbb{E}_{\theta}[\mathcal{D}_{\theta}^{\otimes n}]\), we first draw \(\theta\sim_{\text{\rm unif.}}\{-1,1\}^{t}\), and then draw \(n\) independent examples from \(\mathcal{D}_{\theta}\). We denote the distribution of the \(n\) examples by \(\mathbb{E}_{\theta}[\mathcal{D}_{\theta}^{\otimes n}]\)._

Proof.: By a standard inequality between the total variation distance and the \(\chi^{2}\) distance, we have

\[\mathrm{d}_{\mathrm{TV}}(\mathcal{D}_{0}^{\otimes n},\mathbb{E}_{\theta}[ \mathcal{D}_{\theta}^{\otimes n}])\leq\frac{1}{2}\sqrt{\chi^{2}(\mathbb{E}_{ \theta}[\mathcal{D}_{\theta}^{\otimes n}]\|\mathcal{D}_{0}^{\otimes n})}. \tag{25}\]

By Ingster's method [13] (see also Section 3.1 of [14]),

\[\chi^{2}(\mathbb{E}_{\theta}[\mathcal{D}_{\theta}^{\otimes n}]\|\mathcal{D}_{ 0}^{\otimes n})=\mathbb{E}_{\theta,\theta^{\prime}}\left[\left(\sum_{i=1}^{t} \sum_{j\in\{0,1\}}\frac{\mathcal{D}_{\theta}(u_{i},j)\mathcal{D}_{\theta^{ \prime}}(u_{i},j)}{\mathcal{D}_{0}(u_{i},j)}\right)^{n}\right]-1, \tag{26}\]

where the expectation is over \(\theta,\theta^{\prime}\) drawn i.i.d. \(\sim_{\text{\rm unif.}}\{-1,1\}^{t}\). For every \(i\in[t]\), we have

\[\frac{\mathcal{D}_{\theta}(u_{i},1)\mathcal{D}_{\theta^{\prime}}(u_{i},1)}{ \mathcal{D}_{0}(u_{i},1)}=\frac{\left(\frac{u_{i}+\theta_{i}\alpha}{t}\right) \left(\frac{u_{i}+\theta_{i}^{\prime}\alpha}{t}\right)}{\frac{u_{i}}{t}}= \frac{u_{i}}{t}+\frac{(\theta_{i}+\theta_{i}^{\prime})\alpha}{t}+\frac{\theta_ {i}\theta_{i}^{\prime}\alpha^{2}}{u_{i}t},\]

and similarly

\[\frac{\mathcal{D}_{\theta}(u_{i},0)\mathcal{D}_{\theta^{\prime}}(u_{i},0)}{ \mathcal{D}_{0}(u_{i},0)}=\frac{\left(\frac{(1-u_{i}-\theta_{i}\alpha)}{t} \right)\left(\frac{(1-u_{i}-\theta_{i}^{\prime}(\alpha)}{t}\right)}{\frac{1-u _{i}}{t}}=\frac{1-u_{i}}{t}-\frac{(\theta_{i}-\theta_{i}^{\prime})}{t}+\frac{ \theta_{i}\theta_{i}^{\prime}\alpha^{2}}{(1-u_{i})t}.\]

Adding up the two equations, we get

\[\sum_{j\in\{0,1\}}\frac{\mathcal{D}_{\theta}(u_{i},j)\mathcal{D}_{\theta^{ \prime}}(u_{i},j)}{\mathcal{D}_{0}(u_{i},j)}=\frac{1}{t}+\frac{\theta_{i} \theta_{i}^{\prime}\alpha^{2}}{t}\left(\frac{1}{u_{i}}+\frac{1}{1-u_{i}} \right)\leq\frac{1}{t}+\frac{9\theta_{i}\theta_{i}^{\prime}\alpha^{2}}{2t},\]

where the last inequality uses the fact that \(u_{i}\in[\frac{1}{3},\frac{2}{3}]\). Plugging this into (26), we get

\[\chi^{2}(\mathbb{E}_{\theta}[\mathcal{D}_{\theta}^{\otimes n}]\| \mathcal{D}_{0}^{\otimes n}) \leq\mathbb{E}_{\theta,\theta^{\prime}}\left[\left(1+\frac{9 \alpha^{2}}{2t}\sum_{i=1}^{t}\theta_{i}\theta_{i}^{\prime}\right)^{n}\right]-1\] \[\leq\mathbb{E}_{\theta,\theta^{\prime}}\left[\exp\left(\frac{9 \alpha^{2}n}{2t}\sum_{i=1}^{t}\theta_{i}\theta_{i}^{\prime}\right)\right]-1\] \[=\prod_{i=1}^{t}\mathbb{E}_{\theta,\theta^{\prime}}\left[\exp \left(\frac{9\alpha^{2}n}{2t}\theta_{i}\theta_{i}^{\prime}\right)\right]-1\] \[\leq\prod_{i=1}^{t}\mathbb{E}_{\theta}\left[\exp\left(\frac{81 \alpha^{4}n^{2}}{8t^{2}}\theta_{i}^{2}\right)\right]-1\] (by Hoeffding's lemma) \[=\exp\left(\frac{81\alpha^{4}n^{2}}{8t}\right)-1.\]

Plugging this into (25) completes the proof. 

### Lower bound for convolved ECE

We now introduce the definition of convolved ECE from [1], and show that for every \(\theta\in\{-1,1\}^{t}\), \(\mathcal{D}_{\theta}\) has a large convolved ECE in Lemma 26. This allows us to prove our sample complexity lower bound for convolved ECE in Theorem 5, by applying Lemma 24.

**Definition 9** (Convolved ECE [18]).: _Let \(\pi_{R}:\mathbb{R}\to[0,1]\) be the periodic function with period \(2\) satisfying \(\pi_{R}(v)=v\) if \(v\in[0,1]\), and \(\pi_{R}(v)=2-v\) if \(v\in[1,2]\). Consider a distribution \(\mathcal{D}\) over \([0,1]\times\{0,1\}\). For \((v,y)\sim\mathcal{D}\), define random variable \(\hat{v}:=\pi_{R}(v+\eta)\), where \(\eta\) is drawn independently from \(\mathcal{N}(0,\sigma^{2})\) for a parameter \(\sigma\geq 0\). The \(\sigma\)-convolved ECE is defined as follows:_

\[\mathsf{cECE}_{\sigma}(\mathcal{D}):=\mathbb{E}|\mathbb{E}[(y-v)|\hat{v}]|,\]

_where the outer expectation is over the marginal distribution of \(\hat{v}\), and the inner expectation is over the conditional distribution of \((y,v)\) given \(\hat{v}\). It has been shown in [18] that \(\mathsf{cECE}_{\sigma}(\mathcal{D})\in[0,1]\) is a nonincreasing function of \(\sigma\geq 0\) and there exists a unique \(\sigma^{*}\geq 0\) satisfying \(\mathsf{cECE}_{\sigma^{*}}(\mathcal{D})=\sigma^{s}\). The convolved ECE \(\mathsf{cECE}(\mathcal{D})\) is defined to be \(\mathsf{cECE}_{\sigma^{*}}(\mathcal{D})\)._

We also mention that the following relationship is known between \(\mathsf{cECE}\) and \(\mathsf{dCE}\).

**Lemma 25** (Theorem 7, [18]).: _For any distribution \(\mathcal{D}\) over \([0,1]\times\{0,1\}\), it holds that_

\[\frac{1}{2}\mathsf{dCE}(\mathcal{D})\leq\mathsf{cECE}(\mathcal{D})\leq 2\sqrt{ \mathsf{dCE}(\mathcal{D})}.\]

We have the following lower bound on \(\mathsf{cECE}(\mathcal{D}_{\theta})\):

**Lemma 26**.: _For integer \(t\geq 3\), choose \(\alpha=\frac{1}{t\sqrt{\ln t}}\). Then for every \(\theta\in\{-1,1\}^{t}\),_

\[\mathsf{cECE}(\mathcal{D}_{\theta})\geq\frac{1}{100t\sqrt{\ln t}}.\]

Proof.: It suffices to show that \(\mathsf{cECE}_{\sigma}(\mathcal{D}_{\theta})\geq\frac{1}{100t\sqrt{\ln t}}\) whenever \(\sigma\leq\frac{1}{100t\sqrt{\ln t}}\).

Consider \((v,y)\sim\mathcal{D}\) and \(\hat{v}=\pi_{R}(v+\eta)\), where \(\eta\) is drawn independently from \(\mathcal{N}(0,\sigma^{2})\). By standard Gaussian tail bounds, we have

\[\Pr\left[|\eta|\geq\frac{1}{6t}\right]\leq\frac{1}{t^{2}}. \tag{27}\]

Next, consider a function \(\ell:[0,1]\to[t]\) such that \(\ell(\hat{v})\in\text{argmin}_{i\in[t]}|u_{i}-\hat{v}|\). Let \(\mathcal{E}\) denote the event that \(v=u_{\ell(\hat{v})}\). Let \(\mathbb{I}_{\mathcal{E}}\) and \(\mathbb{I}_{-\mathcal{E}}\) be the indicators of \(\mathcal{E}\) and its complement, respectively. We have

\[\mathbb{E}[(y-v)\mathbb{I}_{\mathcal{E}}\mid\hat{v},v] =\mathbb{I}_{\mathcal{E}}\mathbb{E}[y-v\mid\hat{v},v] \text{($\mathbb{I}_{E}$ is fully determined by $v$ and $\hat{v}$)}\] \[=\mathbb{I}_{\mathcal{E}}\mathbb{E}[y-v\mid v] \text{($y$ is independent of $\hat{v}$ given $v$)}\] \[=\mathbb{I}_{\mathcal{E}}\mathbb{E}[y-v\mid v=u_{\ell(\hat{v})}] =\mathbb{I}_{\mathcal{E}}\theta_{\ell(\hat{v})}\alpha.\]

Taking expectation over \(v\) conditioned on \(\hat{v}\), we have

\[|\mathbb{E}[(y-v)\mathbb{I}_{\mathcal{E}}\mid\hat{v}]|=|\Pr[\mathcal{E}\mid \hat{v}]\theta_{\ell(\hat{v})}\alpha|=\Pr[\mathcal{E}\mid\hat{v}]\alpha.\]

We also have

\[\left|\mathbb{E}\Big{[}(y-v)\mathbb{I}_{-\mathcal{E}}\mid\hat{v}\Big{]}\right| \leq\mathbb{E}\Big{[}[(y-v)\mathbb{I}_{-\mathcal{E}}\mid\hat{v}\Big{]}\leq \Pr[-\mathcal{E}\mid\hat{v}].\]

Therefore,

\[|\mathbb{E}[y-v\mid\hat{v}]|\geq\Pr[\mathcal{E}|\hat{v}]\alpha-\Pr[-\mathcal{ E}\mid\hat{v}].\]

Taking expectations over \(\hat{v}\), we have

\[\mathsf{cECE}_{\sigma}(\mathcal{D}_{\theta})=\mathbb{E}[|\mathbb{E}[y-v\mid \hat{v}]|]\geq\Pr[\mathcal{E}]\alpha-\Pr[-\mathcal{E}]. \tag{28}\]

Whenever \(\mathcal{E}\) does not occur, it must hold that \(|v-\hat{v}|\geq\frac{1}{6t}\), which can only hold when \(|\eta|\geq\frac{1}{6t}\). Therefore, by plugging (27) into (28), we get

\[\mathsf{cECE}_{\sigma}(\mathcal{D}_{\theta})\geq\left(1-\frac{1}{t^{2}}\right) \alpha-\frac{1}{t^{2}}\geq\frac{1}{100t\sqrt{\ln t}}.\qed\]

**Theorem 5**.: _If \(\mathcal{A}\) is an \(\varepsilon\)-\(\mathsf{cECE}\) tester with \(n\) samples (Definition 5), for \(\varepsilon\in(0,\frac{1}{3})\), then_

\[n=\Omega\left(\frac{1}{\varepsilon^{2.5}\ln^{0.25}(\frac{1}{\varepsilon})} \right).\]Proof.: Without loss of generality, assume that \(\varepsilon\leq 10^{-3}\). Let \(t\geq 3\) be the largest integer satisfying \(\varepsilon\leq\frac{1}{100t\sqrt{\ln t}}\). We choose \(\alpha=\frac{1}{t\sqrt{\ln t}}\).

By Lemma 26, we have \(\mathsf{cECE}(\mathcal{D}_{\theta})\geq\varepsilon\) for every \(\theta\in\{-1,1\}^{t}\). By the guarantee of the tester, we have

\[\mathrm{d}_{\mathrm{TV}}(\mathcal{D}_{0}^{\otimes n},\mathbb{E}_{\theta}[ \mathcal{D}_{\theta}^{\otimes n}])\geq\frac{1}{3}.\]

Combining this with Lemma 24, we get \(n=\Omega(\alpha^{-2}\sqrt{t})=\Omega(t^{2.5}\ln t)\), so the claim holds. 

### Lower bound for (surrogate) interval CE

The _interval calibration error_ was introduced in [1] as a modified version of the popular _binned ECE_ to obtain a polynomial relationship to the lower distance to calibration (\(\mathsf{dCE}\)). To give an efficient estimation algorithm, [1] considered a slight variant of the interval calibration error, called the _surrogate interval calibration error_, which preserves the polynomial relationship. Below we include the definition of the surrogate interval calibration error, and its polynomial relationship with \(\mathsf{dCE}\). We then establish our sample complexity lower bound (Theorem 6) for surrogate interval CE by showing that every \(\mathcal{D}_{\theta}\) has a large surrogate interval CE (Lemma 28).

**Definition 10** ([1]).: _For a distribution \(\mathcal{D}\) over \([0,1]\times\{0,1\}\) and an interval width parameter \(w>0\), the random interval calibration error is defined to be_

\[\mathsf{RintCE}(\mathcal{D},w):=\mathbb{E}_{r}\left[\sum_{j\in\mathcal{Z}}| \mathbb{E}_{(v,y)\sim\mathcal{D}}[(y-v)!(v\in I_{r,j}^{w})]|\right], \tag{29}\]

_where the outer expectation is over \(r\) drawn uniformly from \([0,w)\) and \(I_{r,j}^{w}\) is the interval \([r+j\varepsilon,r+(j+1)\varepsilon)\). Note that although the summation is over \(j\in\mathcal{Z}\), there are only finitely many \(j\) that can contribute to the sum (which are the \(j\) that satisfy \(I_{r,j}^{w}\cap[0,1]\neq\emptyset\)). The surrogate interval calibration error is defined as follows:_

\[\mathsf{SintCE}(\mathcal{D}):=\inf_{k\in\mathcal{Z}_{\geq 0}}\Big{(}\mathsf{ RintCE}(\mathcal{D},2^{-k})+2^{-k}\Big{)}.\]

**Lemma 27** (Theorem 6.11, [1]).: _For any distribution \(\mathcal{D}\) over \([0,1]\times\{0,1\}\), it holds that_

\[\mathsf{dCE}(\mathcal{D})\leq\mathsf{SintCE}(\mathcal{D})\leq 6\sqrt{\mathsf{dCE }(\mathcal{D})}.\]

**Lemma 28**.: _For \(t\in\mathbb{N}\), let \(\alpha=\frac{1}{3t}\). Then for every \(\theta\in\{-1,1\}^{t}\), it holds that \(\mathsf{SintCE}(\mathcal{D}_{\theta})\geq\frac{1}{3t}\)._

Proof.: It suffices to prove that \(\mathsf{RintCE}(\mathcal{D}_{\theta},w)\geq\frac{1}{3t}\) whenever \(w<\frac{1}{3t}\), where we recall the definition (29). Fix some \(r\in[0,1]\). Every \(u_{i}\) belongs to the interval \(I_{r,j_{i}}^{w}\) for a unique \(j_{i}\in\mathcal{Z}\). Since the interval width \(w\) is smaller than the gap between \(u_{i}\) and \(u_{i^{\prime}}\) for distinct \(i,i^{\prime}\), we have \(j_{i}\neq j_{i^{\prime}}\). Therefore,

\[\sum_{j\in\mathcal{Z}}|\mathbb{E}_{(v,y)\sim\mathcal{D}}[(y-v)!(v \in I_{r,j}^{w})]| \geq\sum_{i\in[t]}|\mathbb{E}_{(v,y)\sim\mathcal{D}}[(y-v)!(v\in I _{r,j_{i}}^{w})]|\] \[=\sum_{i\in[t]}|\mathbb{E}_{(v,y)\sim\mathcal{D}}[(y-v)!(v=u_{i})]|\] \[=\sum_{i\in[t]}\Pr[v=u_{i}]\mathbb{E}[y-v|v=u_{i}]\] \[=\frac{1}{3t}.\]

Plugging this into (29), we get \(\mathsf{RintCE}(\mathcal{D}_{\theta},w)\geq\frac{1}{3t}\). 

**Theorem 6**.: _If \(\mathcal{A}\) is an \(\varepsilon\)-\(\mathsf{SintCE}\) tester with \(n\) samples (Definition 5), for \(\varepsilon\in(0,\frac{1}{3})\), then_

\[n=\Omega\left(\frac{1}{\varepsilon^{2.5}}\right).\]Proof.: Choose \(t\geq 1\) to be the largest integer satisfying \(\frac{1}{3t}\geq\varepsilon\), and choose \(\alpha=\frac{1}{3t}\). By Lemma 28, \(\mathsf{SintCE}(\mathcal{D}_{\theta})\geq\varepsilon\) for every \(\theta\in\{-1,1\}^{t}\). By the guarantee of the tester, we have

\[\mathrm{d}_{\mathrm{TV}}(\mathcal{D}_{0}^{\otimes n},\mathbb{E}_{\theta}[ \mathcal{D}_{\theta}^{\otimes n}])\geq\frac{1}{3}.\]

Combining this with Lemma 24, we get \(n=\Omega(\alpha^{-2}\sqrt{t})=\Omega(\varepsilon^{-2.5})\).

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: We claimed a novel testing problem for measuring calibration, faster algorithms for solving it, and lower bounds for alternative measures. This is precisely what we provide. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: We explain that our basic tester does not solve the tolerant testing problem in all regimes, and that our more powerful tolerant tester has a slower runtimes. We also state that our practical implementation is preliminary and could be optimized. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof?Answer: [Yes]

Justification: We give full, detailed proofs of all theoretical claims.

Guidelines:

* The answer NA means that the paper does not include theoretical results.
* All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
* All assumptions should be clearly stated or referenced in the statement of any theorems.
* The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.
* Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.
* Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: We provide a complete description of our experimental setups, and all of the relevant code in the supplementary material for reproducibility. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code**Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: As previously mentioned, we give full descriptions and provide our code. Guidelines:

* The answer NA means that paper does not include experiments requiring code.
* Please see the NeurIPS code and data submission guidelines ([https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy)) for more details.
* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines ([https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy)) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: See above. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: We replicated our experiments across multiple runs and provide error bars. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: We describe all our computing environments and provide runtime metrics. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics [https://neurips.cc/public/EthicsGuidelines?](https://neurips.cc/public/EthicsGuidelines?) Answer: [Yes] Justification: We read the ethics guidelines and believe we meet them. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: We provide a new tool for assessing calibration, a measure of interpretability of models, which is not tied to any particular societal application, and do not foresee a pathway to use this tool for negative societal impact. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.

* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: We only use simple synthetic or public datasets for our experiments. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: We made sure to cite all relevant code and data used in our experiments. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.

* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: We do not release new assets. Guidelines: * The answer NA means that the paper does not release new assets. * Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. * The paper should discuss whether and how consent was obtained from people whose asset is used. * At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: Our paper does not involve crowdsourcing nor research with human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. * According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: Our paper does not involve crowdsourcing nor research with human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper. * We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution. * For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. *