# LORA-MOO: Learning Ordinal Relations and Angles for Expensive Many-Objective Optimization

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

Many-objective optimization (MOO) simultaneously optimizes many conflicting objectives to identify the Pareto front - a set of diverse solutions that represent different optimal balances between conflicting objectives. For expensive MOO problems, due to their costly function evaluations, computationally cheap surrogates have been widely used in MOO to save evaluation budget. However, as the number of objectives increases, the cost of learning and surrogation, as well as the difficulty of maintaining solution diversity, increases rapidly. In this paper, we propose LORA-MOO, a surrogate-assisted MOO algorithm that learns surrogates from spherical coordinates. This includes an ordinal-regression-based surrogate for convergence and \(M-1\) regression-based surrogates for diversity. \(M\) is the number of objectives. Such a surrogate modeling method makes it possible to use a single ordinal surrogate to do the surrogate-assisted search, and the remaining surrogates are used to select solution for expensive evaluations, which enhances the optimization efficiency. The ordinal regression surrogate is developed to predict ordinal relation values as radial coordinates, estimating how desirable the candidate solutions are in terms of convergence. The solution diversity is maintained via angles between solutions, which is a parameter-free. Experimental results show that LORA-MOO significantly outperforms other surrogate-assisted MOO methods on most MOO benchmark problems and real-world applications.

## 1 Introduction

Many-objective optimization problems (MOOPs) are widely exist in many real-world applications, such as production scheduling [26], traffic signal control [33], and water resource engineering [21]. These MOOPs have conflicting objectives to optimize, and thus all objectives cannot reach their optimum simultaneously. As a result the optimum of MOOPs is the _Pareto front (PF)_: A set of non-dominated solutions that represent different optimal balance between conflicting objectives. Multi-/many-objective optimization (MOO) 1 aims to find non-dominated solutions that are close to the PF and also well distributed along the PF, indicating that MOO should consider both convergence and diversity.

Footnote 1: Multi-objective optimization has 2 or 3 objectives, many-objective optimization has 4 or more objectives.

Various evolutionary optimization algorithms have been proposed to solve MOOPs [10]. These optimization algorithms usually require plenty of solution samplings and evaluations to find converged and diverse non-dominated solutions. However, in many real-world MOOPs, the evaluation of solution performance could be expensive [41]. In these expensive MOOPs, the evaluation budget only allows a limited number of solutions to be evaluated on the expensive objective functions. To address expensive MOOPs, evolutionary optimization algorithms are combined with computationally cheapsurrogates to enhance sampling efficiency and save evaluations, which are known as surrogate-assisted evolutionary algorithms (SAEAs).

Yet, it is a perennial challenge to use surrogates in a more effective and efficient way for SAEAs, especially when optimization problems have many objectives. For example, conventional SAEAs usually use regression-based surrogates to approximate each objective function separately [5; 34]. For MOOPs, many objectives indicate maintaining many surrogates for surrogate-assisted search and selection, which results in a low efficiency of SAEAs. In addition, it is difficult to maintain solution diversity in high-dimensional objective space. Some SAEAs [24; 43; 5] need to investigate proper parametric strategies to generate reference vectors or divide objective space into subspaces. Recently, a family of classification-based SAEAs [31; 17] attempted to use a single surrogate to learn pairwise dominance relations. However, the training with pairwise relations implies an exponential increase in the size of training dataset. Therefore, a natural question is that whether we can reduce the cost of maintaining many surrogates without increasing the cost of training a single surrogate. Furthermore, whether we can use an non-parametric diversity maintenance strategy to handle the objective space of MOOPs, instead of designing complex reference vectors or points?

In this paper, we propose a different way to implement surrogate-assisted evolutionary optimization for expensive MOOPs, named LORA-MOO, where a single surrogate is developed to learn ordinal relations for convergence purpose, and several angular surrogates are generated from spherical coordinates to maintain diversity. Our major contributions are summarized as follows:

* We develop a novel ordinal-regression-based model to approximate the ordinal landscape of expensive MOOPs. Our ordinal surrogate is able to handle many objectives simultaneously and assist MOO algorithms to complete the model-based search. Artificial ordinal relations are generated via a clustering method to improve the learning quality of ordinal relations for many objectives. Unlike the pairwise relations learned through classification, the ordinal relations would not increase the size of training dataset, hence high efficiency.
* We introduce the idea of spherical coordinates approximation into surrogate-assisted evolutionary optimization and proposed LORA-MOO to solve expensive MOOPs. Different from existing SAEAs which learn approximation models from Cartesian coordinates, we fit several regression-based surrogates to approximate angular coordinates, while our ordinal surrogate can be treated as a radial coordinate. An non-parametric approach is developed to select diverse solutions for expensive evaluations via our angular coordinate surrogates.
* Extensive experiments on benchmark and real-world optimization problems are conducted under a range of scales and numbers of objectives. Empirical results show that our LORA-MOO is effective. It is able to obtain a well-distributed solution set that outperforms the state-of-the-arts.

## 2 Related Work

### Multi-/Many-Objective Surrogate-Assisted Evolutionary Algorithms

**Regression-based SAEAs.** Regression-based SAEAs employ regression-based surrogates such as Kriging [36; 39] to approximate either the objective values of solutions or the objective functions of expensive problems [22]. To maintain solution diversity, ParEGO [24] employs a Kriging model to iteratively approximate an aggregate objective function which aggregates all objectives into one via a set of pre-defined scale vectors. In MOEA/D-EGO [43], plenty of scale vectors are generated uniformly to decompose the target MOOP into many single-objective subproblems. K-RVEA [5] also designs a set of scale vectors as reference vectors to maintain solution diversity. Similarity or density estimation is an alternative option for maintaining diversity. For instance, KTA2 [34] estimates the distribution status of non-dominated solutions by defining a similarity or density indicator.

**Classification-based SAEAs.** In model-based optimization, the optimization is guided by the relation between solutions rather than accurate objective values. Therefore, there is a tendency for recently proposed SAEAs to use classification-based surrogates to learn the relation between solutions directly. CSEA [31] trains a neural network to justify whether candidate solutions can be dominated by given reference points or not. \(\theta\)-DEA-DP [42] uses two neural networks to predict the Pareto dominance relation and \(\theta\)-dominance relation between two solutions, respectively. REMO [17] employs a neural network to fit a ternary classifier, which is able to learn the dominance relation between pairs of solutions. Compared with regression-based SAEAs, although classification-based SAEAs take advantage of learning solution relations directly, their drawbacks are also clear: The prediction of solution relations lacks the information of how solutions are distributed in the objective space, making it difficult for classification-based SAEAs to maintain solution diversity. In [31, 17], a radial projection selection approach is adapted to select diverse reference points. However, its effect on diversity maintenance is limited. In addition, although classification-based SAEAs maintain only one surrogate, the cost of learning pairwise relations from large datasets is inevitably increased.

**SAEAs based on Other Surrogates.** HSMEA [15] uses an ensemble of multiple surrogates in the optimization. In addition, a new category of surrogates, namely ordinal regression surrogate [40] or level-based classification surrogate [28], is proposed recently to combine regression-based surrogates with classification-based surrogates. However, the shortcoming remains the same as these surrogates lack the information of solution distribution, especially when the number of objectives is large.

### Multi-Objective Bayesian Optimization

**MOBO.** Bayesian Optimization (BO) [35, 18] is also a typical model-based optimization method for expensive optimization, while multi-objective BO (MOBO) methods are designed for expensive MOOPs [7, 8, 27, 1]. Some MOBO generalizes the acquisition functions such as upper confidence bound (UCB) [46], expected improvement (EI) [14], Thompson sampling [3], to solve expensive MOOPs. In addition, entropy search methods have also been employed in MOBO [2, 37]. To maintain solution diversity, the EI of a multi-objective performance indicator, Hypervolume (HV) [45], was used as the acquisition function in recent MOBO [6, 27]. Based on the Hypervolume improvement (HVI), PSL [27] proposes a learning method to approximate the whole Pareto set for MOBO, and PDBO [1] automatically selects the best acquisition function for objective functions in each iteration. However, the time complexity of computing HV increases exponentially with the number of objectives, which may limit the application of MOBO methods on optimization problems with many objectives.

**Connection to SAEAs.** Both SAEAs and MOBO are model-based optimization methods. A SAEA is also a MOBO if it uses probability models as surrogates, and a MOBO is also a SAEA if it searches candidate solutions with evolutionary search algorithms. Therefore, some model-based optimization methods belong to both SAEAs and MOBO [24, 14, 43].

## 3 LORA-MOO: Optimization via Learning Ordinal Relations and Angles

This section first introduces the LORA-MOO framework, followed by detailed algorithm descriptions.

### LORA-MOO Framework

The pseudocode of LORA-MOO is depicted in Alg. 1, it consists of four phases:

1. Initialization: An initial dataset of size \(11D\) - 1 (As suggested in the literature [24]) are sampled from the decision space using the Latin hypercube sampling (LHS) [30] (line 1), where \(D\) is the dimensionality of decision variables. The sampled solutions are evaluated on objective functions \(f\) and then saved in an archive \(S_{A}\) (line 2).
2. Surrogate modeling: For all solutions \(\mathbf{x}\in S_{A}\), quantify their ordinal values (line 4) and calculate their angular coordinates (line 9). The set of ordinal values \(S_{o}\) is used to train the ordinal surrogate \(h_{o}\) (line 5). The angular coordinates are used to fit \(M-1\) angular surrogates \(h_{ai}\) separately (line 10).
3. Sampling (Search and Selection): Run an optimizer on surrogate \(h_{o}\) to generate a population of candidate solutions \(P\) (line 6). Select optimal candidate solutions \(\mathbf{x}_{1}^{*}\), \(\mathbf{x}_{2}^{*}\) from \(P\) based on surrogates \(h_{o}\), \(h_{ai}\), respectively (lines 7 and 11).
4. Update: Evaluate new optimal candidate solutions \(\mathbf{x}_{1}^{*}\), \(\mathbf{x}_{2}^{*}\) on expensive objective functions \(f\), update archive \(S_{A}\) and the number of used function evaluations \(FE\) (lines 8 and 12). The algorithm will go to phase 2 until the evaluation budget \(FE_{max}\) has run out.

### Surrogate Modeling

The ordinal surrogate \(h_{o}\) is mainly trained on dominance-based ordinal relations, additional clustering-based artificial ordinal relations will be introduced for training if the number of objectives \(M\) is large. In addition, for an \(M\)-objective problem, \(M\)-1 angular surrogates \(h_{ai}\) are trained on angular coordinates. These surrogates are used in the selection procedure for solution diversity but are idle in the search procedure.

#### 3.2.1 Learning dominance-based ordinal relations.

In LORA-MOO, the concept of ordinal regression [40] is adapted to learn dominance-based ordinal relations. Clearly, the dominance-based ordinal relation between a set of reference points \(S_{RP}\) and a given solution \(\mathbf{x}\) is quantified as a relation value. Such a relation value is a numerical value that used for training the ordinal-regression surrogate \(h_{o}\). The quantification of relation values consists of two steps: The selection of reference points \(S_{RP}\) and the computation of relation values.

**Selection of Reference Points.** We propose the definition of \(\lambda\)-dominance relationship to simplify the selection of reference points.

**Definition 1**.: (\(\lambda\)-_Dominance Relationship_)__

_A solution \(\mathbf{x}^{1}\) is said to \(\lambda\)-dominate another solution \(\mathbf{x}^{2}\) (denoted by \(\mathbf{x}^{1}\prec_{\lambda}\mathbf{x}^{2}\)) if and only if:_

\[g_{\lambda}(\mathbf{x}^{1})\prec g_{\lambda}(\mathbf{x}^{2}), \tag{1}\]

_where \(\lambda\geq 0\) is the dominance coefficient and \(g_{\lambda}\) is a smooth objective function defined as:_

\[f_{in}(\mathbf{x})=\frac{f_{i}(\mathbf{x})-z_{i}^{*}}{|z_{i}^{nad}-z_{i}^{*}|}, \tag{2}\]

\[g_{\lambda,i}(\mathbf{x})=f_{in}(\mathbf{x})+\lambda max(f_{jn}(\mathbf{x})),j\in\{1, \ldots,M\}, \tag{3}\]

_where \(f_{in}\) denotes a normalized objective function, \(\mathbf{z}^{*}=\{z_{1}^{*},\ldots,z_{M}^{*}\},\mathbf{z}^{nad}=\{z_{1}^{nad},\ldots,z_{ M}^{nad}\}\) are ideal point and nadir point for the current non-dominated solutions, respectively._

More detailed definitions about the background of MOO are available in Appendix A. All non-\(\lambda\)-dominated solutions in \(S_{A}\) are selected as reference points \(S_{RP}\). There are two reasons to introduce the definition of \(\lambda\)-dominance:

* The \(\lambda\)-dominance can smoothen the original PF by excluding dominance resistant solutions (DRSs) [16; 38]. DRSs are solutions that are best or close to best on one or several objectives but extremely poor on at least one of the remaining objectives. Such a solution is apparently not desirable but may be regarded as one of the best solutions since there may not exist any other solutions dominating it in the solution set.

* Second, \(\lambda\)-dominance can eliminate some similar non-dominated solutions from the Pareto set, which can be used to adjust the size of Pareto set. When the number of objectives \(M\) is large, it is possible that a majority of past evaluated samples are non-dominated to each other. To balance the number of reference points and remaining samples, we introduce the dominance coefficient \(\lambda\) to sightly reduce the ratio of reference points in \(S_{A}\). This alleviates the situation of extreme imbalance of samples in different ordinal levels (see the division of ordinal levels below).

**Computation of Relation Values.** To quantify ordinal relation values, we first calculate extension coefficients \(ec(\mathbf{x})\) for each \(\mathbf{x}\in S_{A}\). \(ec(\mathbf{x})\) is defined as the minimal coefficient \(ec\geq 1\) to make a solution \(\mathbf{x}\) non-\(\lambda\)-dominated to all solutions \(\mathbf{x}^{\prime}\) in the extended reference:

\[ec(\mathbf{x})=\arg\min_{ec\geq 1}\nexists\mathbf{x}^{\prime}\in S_{RP}:(\mathbf{x}^{ \prime}*ec)\prec_{\lambda}\mathbf{x}. \tag{4}\]

Although extension coefficient \(ec(\mathbf{x})\) quantifies the distance between a solution \(\mathbf{x}\) and reference \(S_{RP}\), it has not been used to train the ordinal regression-based surrogate directly. To generate a stable ordinal regression-based surrogate, solutions in \(S_{A}\) are divided into \(N_{o}=max(n_{o},|S_{A}|/|S_{RP}|)\) ordinal levels, where \(n_{o}\) is a pre-defined parameter denoting the minimal number of ordinal levels. The solutions in \(S_{RP}\) are classified into the non-dominated ordinal level, thus the relation value \(v_{1}\) = 1.0 is assigned to them. Remaining solutions in \(S_{A}\) are sorted by their extension coefficients \(ec(\mathbf{x})\) and then divided into \(N_{o}\)-1 ordinal levels uniformly. The relation value \(v_{i}=1-\frac{i-1}{N_{o}-1}\) will be assigned to the solutions \(\mathbf{x}\) in the \(i^{th}\) ordinal level. Lastly, relation values serve as radial coordinates and a Kriging model is employed to approximate them.

#### 3.2.2 Artificial clustering-based ordinal relations.

When the number of objectives \(M\) is large, most evaluated solutions in archive \(S_{A}\) could be non-dominated solutions, indicating that these solutions will be divided into the same non-dominated ordinal level and thus treated as reference points \(S_{RP}\). This is harmful to the ordinal surrogate modeling due to the extreme imbalance between the numbers of training samples in different ordinal levels. To reduce the ratio of \(S_{RP}\), we use a clustering method to generate \(n\_clusters\) clusters for \(S_{RP}\), where \(n\_clusters\) is the half of the size of \(S_{RP}\). All solutions \(\mathbf{x}\in S_{RP}\) are mapped to the closest cluster centers. The solutions with the shortest projection on each cluster center will be selected as the new \(S_{RP}\), while the remaining solutions will be moved to the next ordinal level. Such artificial ordinal relations greatly reduce the ratio of \(S_{RP}\) in \(S_{A}\). In LORA-MOO, we set a ratio threshold \(rp\_ratio\) for \(S_{RP}\), once the ratio of \(S_{RP}\) is larger than \(rp\_ratio\), artificial ordinal relations will be generated for surrogate modeling. Details are available in Appendix C, Alg. 2 and Fig. 5.

#### 3.2.3 Surrogates for Angular Coordinates.

Given a solution \(\mathbf{x}\in S_{A}\) with Cartesian coordinates \((f_{1}(\mathbf{x}),\ldots,f_{M}(\mathbf{x}))\), The angular coordinates of solution \(\mathbf{x}\) are transformed with the following rules:

\[\varphi_{i}=arccos\frac{f_{i}(\mathbf{x})-z_{i}^{*}}{\sqrt{(f_{i}(\mathbf{x})-z_{i}^{ *})^{2}+\cdots+(f_{M}(\mathbf{x})-z_{M}^{*})^{2}}},i=1,\ldots,M-1, \tag{5}\]

where \(\mathbf{z}^{*}\) is the ideal point. The resulting angular coordinates \((\varphi_{1},\ldots,\varphi_{M-1})\) are used to fit \(M-1\) regression-based surrogates separately. In LORA-MOO, we use the Kriging model to approximate angular coordinates. The introduction and usage of Kriging model is given in Appendix B.

### Sampling: Search and Selection

In this subsection, we describe how to use surrogate \(h_{o}\) to search for candidate solutions and how to use surrogates \(h_{o}\) and \(h_{ai}\) to select optimal ones from candidate solutions for expensive evaluations.

#### 3.3.1 Search: Generation of Candidate Solutions.

An advantage of LORA-MOO is that it searches for candidate solutions on ordinal surrogate \(h_{o}\) only, leaving all angular surrogates \(h_{ai}\) idle in this search procedure. This saves a lot of time from predicting with all surrogates. LORA-MOO employs an optimizer (e.g. PSO [13]) to generate a population of candidate solutions \(P\) (Detailed pseudo-code is available in Appendix C, Alg. 3). The initial population for optimization search consists of two parts. The first half initial solutions are generated randomly from the decision space, while the remaining initial solutions are mutants of current reference points \(S_{RP}\). To ensure the diversity of initial candidate solutions, a KNN clustering method is applied to divide \(S_{RP}\) into several different clusters, from each cluster, an equal number of mutants are generated as initial candidate solutions. The global optimal population \(P\) produced by PSO is the candidate solutions for further environmental selection.

#### 3.3.2 Selection Criteria.

To take both convergence and diversity into consideration, in each iteration, LORA-MOO selects two optimal candidate solutions \(\mathbf{x}_{1}^{*},\mathbf{x}_{2}^{*}\) from \(P\) for objective function evaluations. \(\mathbf{x}_{1}^{*},\mathbf{x}_{2}^{*}\) are sampled on the basis of convergence and diversity, respectively.

**Convergence Criterion** for environmental selection is the expected improvement (EI) [14] of ordinal values, which is similar to many MOBO methods [24, 43]. Since the output of our ordinal surrogate \(h_{o}(\mathbf{x})\) is an 1-D numerical value, the solution with maximal 1-D EI in \(P\) is selected as \(\mathbf{x}_{1}^{*}\).

**Diversity Criterion** to sample \(\mathbf{x}_{2}^{*}\) from \(P\) is defined as angles \(d_{ang}\) between candidate solutions and reference points \(S_{RP}\). Firstly, the minimal degree between each candidate solution and \(S_{RP}\) is measured. Among these minimal degrees \(md_{ang}\), the solution with max(\(md_{ang}\)) is selected as \(\mathbf{x}_{2}^{*}\) (Detailed pseudo-code is available in Appendix C, Alg. 4).

## 4 Experiments

To evaluate the optimization performance of LORA-MOO on expensive MOOPs, we conduct experiments to compare LORA-MOO with other SAEAs on different MOOPs, including a series of scalable multi-/many-objective benchmark optimization problems DTLZ [11], WFG [19], and a real-world network architecture search (NAS) problem.

### Experimental Setups

**Optimization Problem Setup.** To ensure a fair comparison, the following optimization problem setup is the same as the setup that has been widely used in the literature [5, 31, 34, 17]. In our experiments, initial datasets of size \(FE_{init}\) = 11 \(D\) - 1 are used to initialize surrogates, while the maximum number of allowed evaluations \(FE_{max}\) is 300. The statistical results are obtained from 30 independent runs. For each run, different comparison algorithms share the same initial dataset.

**Comparison Algorithms.** We compare LORA-MOO with 6 state-of-the-art SAEAs, some of them also known as MOBO methods. These comparison algorithms can be classified into three categories:

* Regression-based MOO methods: ParEGO [24], K-RVEA [5], and KTA2 [34]. ParEGO is a classic regression-based SAEA and also a MOBO, which serves as a baseline. K-RVEA is a typical SAEA which uses reference vector to guide the diversity maintenance. KTA2 is a newly proposed algorithm to use an independent archive to keep solution diversity.
* Classification-based MOO methods: CSEA [31], REMO [17]. CSEA is a classic classification-based SAEA which serves as a baseline. REMO is a newly proposed SAEA which represents the state-of-the-art performance of classification-based SAEAs.
* Ordinal-regression-based MOO method: OREA [40] is a new category of SAEA that is different from common regression-based and classification-based SAEAs. We compare with it since it is directly related to our radial surrogate.

Note that some classic SAEAs and MOBO methods such as MOEA/D-EGO [43] and CPS-MOEA [44] are not compared in our experiments as they failed to outperform other comparison algorithms on any DTLZ problem [17]. Some HV-based MOBO methods are not compared as they are failed to solve many objectives.

**Parameter Setup.** For the surrogate modeling, the Kriging models used in all comparison algorithms are implemented using DACE [32], just as [24] suggested. For regression-based Kriging surrogates, the range of hyper-parameter \(\theta\in[10^{-5},100]\). And for the neural networks in CSEA and REMO, the parameters are the same as suggested in the literature. In the sampling strategy, the mutation operator used to initialize candidate solutions is polynomial mutation [9], the mutation probability \(p_{m}=1/d\)and mutation index \(\eta_{m}=20\), as recommended in [34; 17]. The size of offspring population is 100. The settings of the PSO optimizer are the range of hyper-parameter in the ordinal-regression-based surrogate are the same as suggested in [40].

For the specific parameters exist in LORA-MOO, such as the dominance coefficient \(\lambda\) and the threshold ratio of reference points to introduce clustering-based ordinal relations \(rp\_ratio\). As there is no relevant study in the literature for their setups, we conducted ablation studies to investigate the effect of these parameters on the performance of LORA-MOO. The results are summarized in Section 4.2 and reported in Appendix F. The source code of LORA-MOO 2 will be available online.

Footnote 2: The link of code and data will be released here once the paper is accepted.

**Performance Indicator.** To have a comprehensive estimation of optimization performance, we use three different performance indicators in our experiments: The inverted generational distance (IGD) [4], the inverted generational distance plus (IGD+) [20], and the Hypervolume (HV) [45]. IGD and IGD+ use a set of truth Pareto front to measure the quality of a set of non-dominated solutions in terms of convergence and diversity. A smaller IGD or IGD+ value indicates better MOO performance. HV use a reference point to calculate the area covered by a set of non-dominated solutions, a large HV value is preferable to MOO. See Appendix D for details and setups about performance indicators.

### Ablation Studies

We conduct ablation studies on DTLZ and WFG benchmark problems with \(D\) = 10 variables and \(M\)={3, 6, 10} objectives. LHS [30] is used to sample initial dataset. The effects of four parameters are investigated: They are the minimal number of ordinal levels \(n_{o}\), the dominance coefficient \(\lambda\), the ratio threshold of reference points \(rp\_ratio\), and the clustering number for reproduction \(n_{c}\). Three representative results obtained on the WFG5 problem with 3 and 10 objectives are depicted in Fig. 1. Complete results and statistical analysis of ablation studies are reported in Appendix F.

As shown in Fig. 1 (left), when \(M\) = 10, a large \(n_{o}\) results in poor optimization performance. This is because the ratio of non-dominated solutions in the archive tends to be large when \(M\) is large, hence, setting a large \(n_{o}\) will lead to a lack of training samples in each dominated ordinal levels, which is detrimental to the performance of surrogate modeling. As such, \(n_{o}\) in LORA-MOO is set to 4.

The result in Fig. 1 (middle) shows that using \(\lambda\)-dominance to sightly modify the original dominance relations is beneficial to the effectiveness of LORA-MOO. When \(\lambda=0\), no \(\lambda\)-dominance would be used and the corresponding LORA-MOO variant has the worst performance among all the variants. In addition, setting a large \(\lambda\) could cause severe damage to the original dominance relations. Therefore, we set \(\lambda\) to 0.2.

The effect of introducing artificial ordinal relations via clustering is demonstrated in Fig. 1 (right). When the ratio threshold of reference points \(rp\_ratio\) is 1 and \(M\) = 10, no artificial ordinal relations are introduced to further divide ordinal levels for plenty of non-dominated solutions in the archive. Consequently, the imbalance of sample numbers in different ordinal levels leads to poor optimization performance. However, dominance relations are preferable to artificial ordinal relations when \(M\) = 3 and the size of ordinal levels are well balanced. Hence, we set \(rp\_ratio\) = 0.5.

### Optimization on Benchmark Problems

The optimization performance of LORA-MOO is evaluated on DTLZ and WFG benchmark problems with \(D\) = 10 variables and \(M\)={3, 4, 6, 8, 10} objectives. The IGD values obtained on DTLZ

Figure 1: IGD curves averaged over 15 runs on the WFG5 problem instances for LORA-MOO with different parameter setups (shaded area is \(\pm\) std of the mean).

[MISSING_PAGE_FAIL:8]

### Real-World Network Architecture Search Problem

Further comparison is conducted on a real-world network architecture search (NAS) problem, the best three algorithms listed in Table 1 are compared: LORA-MOO, KTA2, and KRVEA. The NAS problem tested is the NASbench201 implemented in EvoXBench [29], it has 6 variables and 5 objectives. Details of this NAS problem is provided in Appendix E. Considering NASbench201 is a real-world application and we do not know its exact PF, we use HV to evaluate optimization performance since HV can be calculated without the exact PF. In practice, \(log(HV_{\text{diff}})\) is employed to amplify the visual difference of the obtained HV values:

\[log(HV_{\text{diff}})=log(HV_{\text{max}}-HV)\]

where \(HV_{\text{max}}\) is the maximal HV value on this problem that is provided in EvoXBench.

Fig. 3 plots the result. As can be seen in the figure, LORA-MOO outperforms KTA2 and KRVEA on this NAS problem. Although KTA2 and KRVEA have quicker convergence rate than LORA-MOO at the beginning of the optimization, both of them slow down their convergence speed as the number of evaluations increases. Particularly, KTA2 is trapped on local optima and thus fails to reach better results. In comparison, LORA-MOO reaches better NAS results when the evaluation number is larger than 250.

### Runtime Comparison

We compare the runtime on benchmark problems for all the comparison algorithms to investigate the relation between their optimization efficiency and the number of objectives \(M\).

Fig. 4 illustrates how the runtime of each comparison algorithm varies as the \(M\) increases. It can be observed that the runtime of KTA2 increases exactly in the same rate as \(M\) increases. In comparison, the runtime of LORA-MOO increases slightly when \(M\) increases. This demonstrates that using angular surrogates only at the end of environmental selection process is beneficial to the optimization efficiency of LORA-MOO. In addition, the runtimes of ParEGO, CSEA, REMO, and OREA do not increase significantly with \(M\) since they do not maintain specific surrogates to manage the diversity of non-dominated solutions. Consequently, their overall performance reported in Table 1 is not desirable. Overall, LORA-MOO finds a good trade-off between optimization efficiency and optimization results.

## 5 Conclusion

In this paper, we propose an efficient MOO method, LORA-MOO, to solve expensive MOOPs. Different from existing surrogate modeling approaches, our LORA-MOO learns surrogate models from ordinal relations and spherical coordinates. Only one ordinal surrogate is used in the model-based search, which hugely improve the efficiency of optimization. Our empirical studies have demonstrated that our LORA-MOO significantly outperforms other state-of-the-art efficient MOO methods, including SAEAs and MOBO methods.

Figure 4: Comparison of runtime averaged over 30 runs on benchmark problems \(D\) = 10 variables and \(M\) = 3, 4, 6, 8, and 10 objectives for the comparison algorithms. For each algorithm, its runtimes are normalized by the runtime it costed on 3-objective problems.

Figure 3: \(Log(HV_{\text{diff}})\) curves averaged over 30 runs on the NAS problem for the comparison algorithms.

## References

* [1] Alaleh Ahmadianshalchi, Syrine Belakaria, and Janardhan Rao Doppa. Pareto front-diverse batch multi-objective Bayesian optimization. In _Proceedings of the 38th AAAI Conference on Artificial Intelligence (AAAI'24)_, pages 10784-10794, 2024.
* [2] Syrine Belakaria, Aryan Deshwal, and Janardhan Rao Doppa. Max-value entropy search for multi-objective Bayesian optimization. In _Advances in Neural Information Processing Systems 32 (NeurIPS'19)_, pages 7825-7835, 2019.
* [3] Syrine Belakaria, Aryan Deshwal, Nitthilan Kannappan Jayakodi, and Janardhan Rao Doppa. Uncertainty-aware search framework for multi-objective Bayesian optimization. In _Proceedings of the 34th AAAI Conference on Artificial Intelligence (AAAI'20)_, pages 10044-10052, 2020.
* [4] Peter AN Bosman and Dirk Thierens. The balance between proximity and diversity in multiobjective evolutionary algorithms. _IEEE Transactions on Evolutionary Computation_, 7(2):174-188, 2003.
* [5] Tinkle Chugh, Yaochu Jin, Kaisa Miettinen, Jussi Hakanen, and Karthik Sindhya. A surrogate-assisted reference vector guided evolutionary algorithm for computationally expensive many-objective optimization. _IEEE Transactions on Evolutionary Computation_, 22(1):129-142, 2016.
* [6] Samuel Daulton, Maximilian Balandat, and Eytan Bakshy. Differentiable expected hypervolume improvement for parallel multi-objective Bayesian optimization. In _Advances in Neural Information Processing Systems 33 (NeurIPS'20)_, pages 9851-9864, 2020.
* [7] Samuel Daulton, Maximilian Balandat, and Eytan Bakshy. Parallel Bayesian optimization of multiple noisy objectives with expected hypervolume improvement. In _Advances in Neural Information Processing Systems 34 (NeurIPS'21)_, pages 2187-2200, 2021.
* [8] Samuel Daulton, David Eriksson, Maximilian Balandat, and Eytan Bakshy. Multi-objective Bayesian optimization over high-dimensional search spaces. In _Proceedings of the 38th Conference on Uncertainty in Artificial Intelligence (UAI'22)_, pages 507-517, 2022.
* [9] Kalyanmoy Deb and Mayank Goyal. A combined genetic adaptive search (GeneAS) for engineering design. _Computer Science and Informatics_, 26(4):30-45, 1996.
* [10] Kalyanmoy Deb and Himanshu Jain. An evolutionary many-objective optimization algorithm using reference-point-based nondominated sorting approach, part I: solving problems with box constraints. _IEEE Transactions on Evolutionary Computation_, 18(4):577-601, 2013.
* [11] Kalyanmoy Deb, Lothar Thiele, Marco Laumanns, and Eckart Zitzler. Scalable test problems for evolutionary multiobjective optimization. In _Evolutionary Multiobjective Optimization_, pages 105-145. Springer, London, U.K., 2005.
* [12] Xuanyi Dong and Yi Yang. Nas-bench-201: Extending the scope of reproducible neural architecture search. In _Proceedings of the 8th International Conference on Learning Representations (ICLR'20)_, 2020.
* [13] Russell Eberhart and James Kennedy. Particle swarm optimization. In _Proceedings of the 1995 IEEE International Conference on Neural Networks (ICNN'95)_, pages 1942-1948, 1995.
* [14] Michael TM Emmerich, Kyriakos C Giannakoglou, and Boris Naujoks. Single-and multiobjective evolutionary optimization assisted by Gaussian random field metamodels. _IEEE Transactions on Evolutionary Computation_, 10(4):421-439, 2006.
* [15] Ahsanul Habib, Hemant Kumar Singh, Tinkle Chugh, Tapabrata Ray, and Kaisa Miettinen. A multiple surrogate assisted decomposition-based evolutionary algorithm for expensive multi/many-objective optimization. _IEEE Transactions on Evolutionary Computation_, 23(6):1000-1014, 2019.
* [16] Thomas Hanne. On the convergence of multiobjective evolutionary algorithms. _European Journal of Operational Research_, 117(3):553-564, 1999.

* Hao et al. [2022] Hao Hao, Aimin Zhou, Hong Qian, and Hu Zhang. Expensive multiobjective optimization by relation learning and prediction. _IEEE Transactions on Evolutionary Computation_, 26(5):1157-1170, 2022.
* Huang et al. [2024] Xiaobin Huang, Lei Song, Ke Xue, and Chao Qian. Stochastic Bayesian optimization with unknown continuous context distribution via kernel density estimation. In _Proceedings of the 38th AAAI Conference on Artificial Intelligence (AAAI'24)_, pages 12635-12643, 2024.
* Huband et al. [2006] Simon Huband, Philip Hingston, Luigi Barone, and Lyndon While. A review of multiobjective test problems and a scalable test problem toolkit. _IEEE Transactions on Evolutionary Computation_, 10(5):477-506, 2006.
* Ishibuchi et al. [2015] Hisao Ishibuchi, Hiroyuki Masuda, Yuki Tanigaki, and Yusuke Nojima. Modified distance calculation in generational distance and inverted generational distance. In _Proceedings of the 8th International Conference on Evolutionary Multi-criterion Optimization (EMO'15)_, pages 110-125, 2015.
* Janga Reddy and Kumar [2021] M. Janga Reddy and D. Nagesh Kumar. Evolutionary algorithms, swarm intelligence methods, and their applications in water resources engineering: A state-of-the-art review. _H2Open Journal_, 3(1):135-188, 2021.
* Jin [2005] Yaochu Jin. A comprehensive survey of fitness approximation in evolutionary computation. _Soft Computing_, 9(1):3-12, 2005.
* Jones et al. [1998] Donald R. Jones, Matthias Schonlau, and William J. Welch. Efficient global optimization of expensive black-box functions. _Journal of Global Optimization_, 13(4):455-492, 1998.
* Knowles [2006] Joshua Knowles. ParEGO: A hybrid algorithm with on-line landscape approximation for expensive multiobjective optimization problems. _IEEE Transactions on Evolutionary Computation_, 10(1):50-66, 2006.
* Li et al. [2014] Ke Li, Kalyanmoy Deb, Qingfu Zhang, and Sam Kwong. An evolutionary many-objective optimization algorithm based on dominance and decomposition. _IEEE Transactions on Evolutionary Computation_, 19(5):694-716, 2014.
* Lin and Gen [2018] Lin Lin and Mitsuo Gen. Hybrid evolutionary optimisation with learning for production scheduling: State-of-the-art survey on algorithms and applications. _International Journal of Production Research_, 56(1-2):193-223, 2018.
* Lin et al. [2022] Xi Lin, Zhiyuan Yang, Xiaoyuan Zhang, and Qingfu Zhang. Pareto set learning for expensive multi-objective optimization. In _Advances in Neural Information Processing Systems 35 (NeurIPS'22)_, pages 19231-19247, 2022.
* Liu et al. [2022] Zhuo Liu, Xiaolin Xiao, Feng-Feng Wei, and Wei-Neng Chen. A classification-assisted level-based learning evolutionary algorithm for expensive multiobjective optimization problems. In _Proceedings of the 24th Annual Conference on Genetic and Evolutionary Computation (GECCO'22)_, pages 547-555, 2022.
* Lu et al. [2023] Zhichao Lu, Ran Cheng, Yaochu Jin, Kay Chen Tan, and Kalyanmoy Deb. Neural architecture search as multiobjective optimization benchmarks: Problem formulation and performance assessment. _IEEE Transactions on Evolutionary Computation (Early Access)_, 2023.
* McKay et al. [2000] Michael D. McKay, Richard J. Beckman, and William J. Conover. A comparison of three methods for selecting values of input variables in the analysis of output from a computer code. _Technometrics_, 42(1):55-61, 2000.
* Pan et al. [2018] Linqiang Pan, Cheng He, Ye Tian, Handing Wang, Xingyi Zhang, and Yaochu Jin. A classification-based surrogate-assisted evolutionary algorithm for expensive many-objective optimization. _IEEE Transactions on Evolutionary Computation_, 23(1):74-88, 2018.
* Sacks et al. [1989] Jerome Sacks, William J. Welch, Toby J. Mitchell, and Henry P. Wynn. Design and analysis of computer experiments. _Statistical Science_, 4(4):409-423, 1989.

* [33] Palwasha W. Shaikh, Mohammed El-Abd, Mounib Khanafer, and Kaizhou Gao. A review on swarm intelligence and evolutionary algorithms for solving the traffic signal control problem. _IEEE Transactions on Intelligent Transportation Systems_, 23(1):48-63, 2020.
* [34] Zhenshou Song, Handing Wang, Cheng He, and Yaochu Jin. A Kriging-assisted two-archive evolutionary algorithm for expensive many-objective optimization. _IEEE Transactions on Evolutionary Computation_, 25(6):1013-1027, 2021.
* [35] Lei Song, Ke Xue, Xiaobin Huang, and Chao Qian. Monte Carlo tree search based variable selection for high dimensional Bayesian optimization. In _Advances in Neural Information Processing Systems 35 (NeurIPS'22)_, pages 28488-28501, 2022.
* [36] Michael L. Stein. _Interpolation of Spatial Data: Some Theory for Kriging_. Springer Science & Business Media, New York, NY, 1999.
* [37] Shinya Suzuki, Shion Takeno, Tomoyuki Tamura, Kazuki Shitara, and Masayuki Karasuyama. Multi-objective Bayesian optimization using Pareto-frontier entropy. In _Proceedings of the 37th International Conference on Machine Learning (ICML'20)_, pages 9279-9288, 2020.
* [38] Zhenkun Wang, Yew-Soon Ong, and Hisao Ishibuchi. On scalable multiobjective test problems with hardly dominated boundaries. _IEEE Transactions on Evolutionary Computation_, 23(2):217-231, 2018.
* [39] Christopher KI Williams and Carl Edward Rasmussen. _Gaussian Processes for Machine Learning_. MIT press, Cambridge, MA, 2006.
* [40] Xunzhao Yu, Xin Yao, Yan Wang, Ling Zhu, and Dimitar Filev. Domination-based ordinal regression for expensive multi-objective optimization. In _Proceedings of the 2019 IEEE Symposium Series on Computational Intelligence (SSCI'19)_, pages 2058-2065, 2019.
* [41] Xunzhao Yu, Ling Zhu, Yan Wang, Dimitar Filev, and Xin Yao. Internal combustion engine calibration using optimization algorithms. _Applied Energy_, 305:117894, 2022.
* [42] Yuan Yuan and Wolfgang Banzhaf. Expensive multi-objective evolutionary optimization assisted by dominance prediction. _IEEE Transactions on Evolutionary Computation_, 26(1):159-173, 2022.
* [43] Qingfu Zhang, Wudong Liu, Edward Tsang, and Botond Virginas. Expensive multiobjective optimization by MOEA/D with gaussian process model. _IEEE Transactions on Evolutionary Computation_, 14(3):456-474, 2010.
* [44] Jinyuan Zhang, Aimin Zhou, and Guixu Zhang. A classification and pareto domination based multiobjective evolutionary algorithm. In _Proceedings of the 17th IEEE Congress on Evolutionary Computation (CEC'15)_, pages 2883-2890, 2015.
* a comparative case study. In _Proceedings of the 5th International Conference on Parallel Problem Solving from Nature (PPSN V)_, pages 292-301, 1998.
* [46] Marcela Zuluaga, Andreas Krause, et al. \(\epsilon\)-pal: An active learning approach to the multi-objective optimization problem. _Journal of Machine Learning Research_, 17(104):1-32, 2016.

Background of Many-Objective Optimization

We consider minimization problems and many-objective optimization problems (MOOPs) can be formulated as follows:

**Definition 2**.: _(Expensive Many-Objective Optimization Problem) Given \(M\) expensive objective functions \(f_{1},\ldots,f_{M}\) and an evaluation budget \(FE_{max}\), obtain the Pareto set for the following many-objective optimization problem:_

\[\operatorname*{argmin}_{\mathbf{x}\in X}f(\mathbf{x})=(f_{1}(\mathbf{x}),\ldots,f_{M}(\bm {x}))\]

_where \(X\subseteq\mathbb{R}^{D}\) is the decision space of the problem._

The Pareto set is defined through the following definitions: Pareto set and Pareto front are defined as follows:

**Definition 3**.: _Pareto dominance: A solution \(\mathbf{x}^{1}\) is said to dominate another solution \(\mathbf{x}^{2}\) (denoted by \(\mathbf{x}^{1}\prec\mathbf{x}^{2}\)) if and only if:_

\[\forall k\in\{1,2,\ldots,M\}:f_{k}(\mathbf{x}^{1})\leq f_{k}(\mathbf{x}^{2})\wedge\]

\[\exists k\in\{1,2,\ldots,M\}:f_{k}(\mathbf{x}^{1})<f_{k}(\mathbf{x}^{2})\]

**Definition 4**.: _Non-dominated solution: A non-dominated solution \(\mathbf{x}^{\star}\) in the decision space \(X\) is a solution that cannot be dominated by any other solutions in \(X\):_

\[\nexists\mathbf{x}\in X:\mathbf{x}\prec\mathbf{x}^{\star}\]

**Definition 5**.: _Pareto set: Pareto set \(S_{ps}\) is the set of all non-dominated solutions in the decision space \(X\):_

\[S_{ps}=\{\mathbf{x}^{\star}\in X|\nexists\mathbf{x}\in X:\mathbf{x}\prec\mathbf{x}^{\star}\}\]

**Definition 6**.: _Pareto front: Pareto front \(S_{pf}\) is the corresponding unique set of the Pareto set in the objective space:_

\[S_{pf}=\{f(\mathbf{x})|\mathbf{x}\in S_{ps}\}\]

## Appendix B Kriging Model

Kriging model, also known as Gaussian process model [23] or design and analysis of computer experiments (DACE) model [32], is a stochastic process model used to approximate an unknown objective function. LORA-MOO uses Kriging models to implement angular surrogates and the radial surrogate, to avoid potential confusion and help the understanding of our algorithm, the working mechanism of the Kriging model is described below.

A common way to approximate an unknown objective function with \(n\) observations is linear regression:

\[y(\mathbf{x}^{i})=\sum_{k=1}^{N}\beta_{k}f_{k}(\mathbf{x}^{i})+\epsilon^{i}, \tag{6}\]

where \(\mathbf{x}^{i}\) is the \(i^{th}\) sample point observed from the objective function. \(f_{k}(\mathbf{x}^{i})\), \(\beta_{k}\) are a linear or nonlinear function of \(\mathbf{x}^{i}\) and its coefficient, respectively. \(N\) is the number of functions \(f(\mathbf{x})\). \(\epsilon^{i}\) is an independent error term, which is normally distributed with mean zero and variance \(\sigma^{2}\).

However, a stochastic process model such as Kriging does not assume that the error terms \(\epsilon\) are independent. Hence, an error term \(\epsilon^{i}\) is rewritten as \(\epsilon(\mathbf{x}^{i})\). Moreover, these error terms are assumed to be related or correlated to each other. The correlation between two error terms \(\epsilon(\mathbf{x}^{i})\) and \(\epsilon(\mathbf{x}^{j})\) is inversely proportional to the distance between the corresponding points [23]. The correlation function in the Kriging model is defined as:

\[Corr(\epsilon(\mathbf{x}^{i}),\epsilon(\mathbf{x}^{j}))=exp[-dis(\mathbf{x}^{i},\mathbf{x}^{j })], \tag{7}\]

where the distance between two points \(\mathbf{x}^{i}\) and \(\mathbf{x}^{j}\) are measured using the special weighted distance formula shown below:

\[dis(\mathbf{x}^{i},\mathbf{x}^{j})=\sum_{k=1}^{D}\theta_{i}|x^{i}_{k}-x^{j}_{k}|^{p_{ k}}, \tag{8}\]where \(D\) is the number of decision variables, \(\mathbf{\theta}\in\mathbb{R}_{\geq 0}^{D}\) and \(\textbf{p}\in[1,2]^{D}\) are parameters of the Kriging model. It can be seen from Eq.(7) that the correlation is ranged within \((0,1]\) and is increasing as the distance between two points decreases. Particularly, in Eq.(8), the parameter \(\theta_{k}\) can be explained as the importance of the decision variable \(x_{k}\), and the parameter \(p_{k}\) can be interpreted as the smoothness of the correlation function in the \(k^{th}\) coordinate direction.

Due to the effectiveness of correlation modelling, the regression model in Eq.(6) can be simplified without degrading modelling performance [23]. Clearly, all regression terms are replaced with a constant term, thus the Kriging regression model can be rewritten as follows:

\[y(\mathbf{x}^{i})=\mu+\epsilon(\mathbf{x}^{i}), \tag{9}\]

where \(\mu\) is the mean of this stochastic process, \(\epsilon(\mathbf{x}^{i})\sim\mathcal{N}(0,\sigma^{2})\).

### Training the Kriging model

To train the Kriging model and estimate the parameters \(\mathbf{\theta},\textbf{p}\) in Eq.(8), the following likelihood function is maximised:

\[\frac{1}{(2\pi)^{n/2}(\sigma^{2})^{n/2}|\textbf{R}|^{1/2}}exp[-\frac{(\textbf {y}-\textbf{1}\mu)^{T}\textbf{R}^{-1}(\textbf{y}-\textbf{1}\mu)}{2\sigma^{2} }], \tag{10}\]

where \(|\textbf{R}|\) is the determinant of the correlation matrix, each element in the matrix is obtained using Eq.(7). **y** is the \(n\)-dimensional vector of dependent variables that observed from the objective function. The mean value \(\mu\) and variance \(\sigma^{2}\) in Eq.(9) and Eq.(10) can be estimated by:

\[\hat{\mu}=\frac{\textbf{1}^{T}\textbf{R}^{-1}\textbf{y}}{\textbf{1}^{T}\textbf {R}^{-1}\textbf{1}}, \tag{11}\]

\[\hat{\sigma}=\frac{1}{n}(\textbf{y}-\textbf{1}\hat{\mu})^{T}\textbf{R}^{-1}( \textbf{y}-\textbf{1}\hat{\mu}). \tag{12}\]

### Prediction with the Kriging model

For a new solution \(\mathbf{x}^{*}\), the Kriging model predicts the approximation of \(\hat{y}(\mathbf{x}^{*})\) and the uncertainty \(\hat{s}^{2}(\mathbf{x}^{*})\) as follows:

\[\hat{y}(\mathbf{x}^{*})=\hat{\mu}+\textbf{r}^{\prime}\textbf{R}^{-1}(\textbf{y}- \textbf{1}\hat{\mu}), \tag{13}\]

\[\hat{s}^{2}(\mathbf{x}^{*})=\hat{\sigma}^{2}(1-\textbf{r}^{\prime}\textbf{R}^{-1} \textbf{r}), \tag{14}\]

where **r** is a \(n\)-dimensional vector of correlations between \(\epsilon(\mathbf{x}^{*})\) and the error terms at the training data, which can be calculated via Eq.(7).

Further details and a comprehensive description of the Kriging model and Gaussian Process can be found in [39]. In this paper, all regression-based Kriging models have \(\mathbf{\theta}\in[10^{-5},100]^{D}\), **p** = \(2^{D}\).

## Appendix C Additional Description of LORA-MOO

This section describes LORA-MOO with more details.

### Quantification of Ordinal Relations

In order to learn the ordinal landscape of MOOPs, we need to quantify the ordinal relations between solutions into numerical values. Alg. 2 illustrates the pseudocode of quantifying ordinal relations3, it describes line 4 in Alg. 1 of the main file. It can be seen that Alg. 2 is mainly working on the quantification of dominance-based ordinal relations. Artificial ordinal relations will not be added unless the ratio of reference points is larger than ratio threshold \(rp_{ratio}\) (line 5).

Footnote 3: Symbol ‘\(\leftarrow\)’ indicates the result of a function, Symbol ‘\(=\)’ indicates an assignment operation.

An illustration of artificial clustering-based ordinal relations is given in Fig. 5. By using clustering methods, artificial ordinal relations are generated for training ordinal regression surrogates. Picking one solution from each cluster ensures the diversity of non-dominated solutions in the first ordinal level \(L_{1}\). Meanwhile, the selection within each cluster is based on the projection length on cluster center, which is beneficial to the convergence of non-dominated solutions.

```
0:\(S_{A}\): Archive of evaluated solutions; \(rp\_ratio\): Ratio threshold of reference points in \(S_{A}\); \(n_{o}\): Minimal number of ordinal levels. Procedure:
1:\(S_{RP}\leftarrow\) Non-dominated solutions in \(S_{A}\) that are non-\(\lambda\)-dominated to any other solution in \(S_{A}\).
2: Non-dominated level (The first ordinal level) \(L_{1}\gets S_{RP}\).
3: The number of non-dominated ordinal levels \(n_{ndl}\) = 1.
4: Ratio of reference points \(ratio=\frac{|S_{RP}|}{|S_{A}|}\).
5:if\(ratio>rp_{ratio}\)then
6:\(n_{ndl}\) = \(n_{ndl}\) + 1. /* Add Artificial Ordinal Relations. */
7: Divide \(S_{RP}\) into \(\frac{|S_{RP}|}{2}\) clusters via KNN clustering.
8: For \(\mathbf{x}\) in each cluster, calculate the projection length of \(\mathbf{x}\) on the corresponding cluster center.
9:\(L_{1}\leftarrow\) Solutions \(\mathbf{x}\) with the shortest projection on each cluster.
10:\(L_{2}\leftarrow\) Remaining \(\frac{|S_{RP}|}{2}\) solutions in \(S_{RP}\).
11:endif
12: Calculate extension coefficient \(ec(\mathbf{x})\) for all \(\mathbf{x}\in S_{A}\).
13: The number of ordinal levels \(N_{o}=\text{max}(n_{o},\frac{|S_{A}|}{|S_{RP}|})\).
14:\(L_{i}\leftarrow\) According to the order of \(ec(\mathbf{x})\), uniformly divide solutions \(\mathbf{x}\in(S_{A}-S_{RP})\) into \(N_{o}\) - \(n_{ndl}\) levels.
15: Ordinal relation value \(v_{i}=1-\frac{i-1}{N_{o}-1}\) for \(\mathbf{x}\in L_{i}\). Output: An ordinal training set \(S_{o}\) consisting of ordinal relation values \(v_{i}\).
```

**Algorithm 2** Quantify Ordinal Relations for LORA-MOO
diversity selection does not require extra parameters for generating guidance vectors, it selects the candidate solution that is mostly deviate from solutions in \(S_{RP}\). Note that all angular surrogates are only used to evaluate one population \(P\) during the whole reproduction and environmental selection procedures. Therefore, although LORA-MOO fits \(M\) surrogates in total (one ordinal surrogate and \(M\)-1 angular surrogates), its runtime cost is less than other SAEAs which fit \(M\) surrogates from Cartesian coordinates.

## Appendix D Details of Performance Indicators Used in Our Experiments

In our experiments, we use IGD [4], IGD+ [20], and HV [45] to measure the performance of many objective optimization. Both IGD and IGD+ require a subset of Pareto front as reference points. In our experiments, the number of IGD/IGD+ reference points is set to 5000 for 3-, 4-, and 6-objective optimization problems, as widely used in the literature [40]. Considering the large objective space,we set the number of IGD/IGD+ reference points to 10000 for 8- and 10-objective optimization problems to achieve a more accurate estimation of optimization performance. The method proposed in [25] is employed to generate well-distributed IGD/IGD+ reference points.

In comparison, the calculation of HV values does not require a subset of Pareto front as reference points. For a set of non-dominated solutions, its HV is the volume in the objective space it dominates from the set to a single reference point. Table 2 lists the reference point used for calculating HV values. All HV values are calculated using the reference point and the normalized solutions. A solution \(\mathbf{x}\) is normalize by the upper bound and lower bound of Pareto front:

\[\frac{\mathbf{x}-lb_{pf}}{ub_{pf}-lb_{pf}}, \tag{15}\]

where \(ub_{pf}\), \(lb_{pf}\) are the upper bound and lower bound of Pareto front, respectively.

## Appendix E Details of the NASBench201 Problem

NASbench201 [12] are discrete optimization problems that aim to identify the optimal architecture for neural networks. The search space is defined by a cell with 4 nodes inside, forming a directed acyclic graph as illustrated in Fig. 6.

The decision variables are 6 edges, each edge is associated with an operation selected from a predefined operation set {zeroize, skip-connect, 1x1 convolution, 3x3 convolution, 3x3 average pool}. Therefore, a network architecture can be encoded into a 6-dimensional decision vector with 5 discrete numbers. In total, there are \(5^{6}\)=15,625 different candidates for neural architecture search.

The optimization objectives in NASbench201 varies in different optimization problems. In this paper, our NASbench201 problem consider 5 objectives, including the accuracy in CI-FAR10 dataset, groundtruth floating point operations (FLOPs), the number of parameters, latency, and energy cost. All these objectives are normalized to [0, 1] in the optimization. The optimization problem can be formulated as

\[F(\mathbf{x})=\{f_{acc}(\mathbf{x}),f_{FLOPs}(\mathbf{x}),f_{param}(\mathbf{x}),f_{latency}( \mathbf{x}),f_{energy}(\mathbf{x})\}, \tag{16}\]

where decision vector \(\mathbf{x}\in\{0,1,2,3,4\}^{6}\).

## Appendix F Complete Results of Ablation Studies

In this section, we report complete results of our ablation studies that are not displayed in the main paper. We conduct four ablation studies to investigate the effect of the following four parameters on the optimization performance of LORA-MOO.

1. \(n_{o}\): The minimal number of ordinal levels. A parameter in the modeling of our ordinal-regression-based surrogate \(h_{o}\).

\begin{table}
\begin{tabular}{|c|c|} \hline Problem & Reference Points \\ \hline DTLZ & (1,0, \(\dots\), 1.0) \(\in\mathbb{R}^{M}\) \\ \hline WFG & (1,0, \(\dots\), 1.0) \(\in\mathbb{R}^{M}\) \\ \hline NASBench201 & (1.0, 1.0, 1.0, 1.0, 1.0) \\ \hline \end{tabular}
\end{table}
Table 2: The HV reference points for all problems in this work.

Figure 6: Diagram of a network architecture in NASbench201.

2. \(\lambda\): The dominance coefficient. A parameter in the modeling of our ordinal-regression-based surrogate \(h_{o}\).
3. \(rp_{ratio}\): The ratio threshold of reference points \(S_{RP}\). A parameter to determine whether to introduce artificial ordinal relations via clustering.
4. \(n_{c}\): The number of clusters generated from reference points \(S_{RP}\) to initialize PSO population. A parameter in the generation of candidate solutions.

**Setup of Ablation Studies.** Our ablation studies are conducted on 7 DTLZ and 9 WFG benchmark optimization problems. These benchmark problems have different features, such as unimodal, multimodal, scaled, degenerated, and discontinuous. Therefore, the effect of four parameters can be investigated comprehensively. Considering our paper focuses on many-objective optimization instead of scalable optimization, we are interested in the optimization performance under different numbers of objectives \(M\) rather than the performance under different numbers of decision variables \(D\). Hence, we set \(D\) = 10 for all benchmark optimization problems, as suggested in literature [5; 31; 34; 17]. In comparison, we set \(M\) = \(\{3,6,10\}\) to observe the optimization performance with different objectives. Other setups are the same as described in Section 4.1 of the main file.

### Influence of Minimal Number of Ordinal Levels \(n_{o}\).

This subsection investigates the influence of minimal number of ordinal levels \(n_{o}\) on the optimization performance. We set \(n_{o}\) = {10, 8, 6, 4, 3} to generate five LORA-MOO variants. For all variants, in this ablation study, we tentatively set \(\lambda\) = 0.2, \(rp_{ratio}\) = 2/3, \(n_{c}\) = 5 for a fair comparison. The IGD+ values obtained by five LORA-MOO variants with different \(n_{o}\) are reported in Table 3.

In the last five rows of Table 3, the summary of statistical test results shows that \(n_{o}\) = 4 is the optimal parameter setup for LORA-MOO, because it is the only variant that is significantly superior to or equivalent to all other variants. In comparison, the LORA-MOO variant with \(n_{o}\) = 10, 8, 6, 3 are significantly inferior to other 4, 1, 1, 2 LORA-MOO variants, respectively.

### Influence of Dominance Coefficient \(\lambda\).

In this subsection, we analyze the influence of \(\lambda\)-dominance coefficient \(\lambda\) on the optimization performance. We set \(\lambda\) = {0, 0.1, 0.2, 0.3} to generate four LORA-MOO variants. As determined in the previous ablation study, we set \(n_{o}\) = 4 for all variants. The remaining two parameters \(rp_{ratio}\) and \(n_{c}\) are set to 2/3 and 5, respectively. The IGD+ values obtained by four LORA-MOO variants with different \(\lambda\) are reported in Table 4.

The last four rows of Table 4 shows that \(\lambda\) = 0.2 is the optimal parameter setup for LORA-MOO. The variant of \(\lambda\) = 0.2 is significantly superior to both the variants of \(\lambda\) = 0 and \(\lambda\) = 0.1, and it is equivalent to the variant of \(\lambda\) = 0.3. We note that the variant of \(\lambda\) = 0.3 is also significantly superior to both the variants of \(\lambda\) = 0 and \(\lambda\) = 0.1. However, this variant wins/ties/losses 30/105/9 statistical tests in total, while the variant of \(\lambda\) = 0.2 wins/ties/losses 32/109/3 statistical tests in total. Therefore, setting \(\lambda\) = 0.2 is preferable to setting \(\lambda\) = 0.3.

Note that all other LORA-MOO variants outperform the variant of \(\lambda\) = 0, this implies that excluding some samples from the set of non-dominated solutions is beneficial to the performance of ordinal regression. The effectiveness of using our \(\lambda\)-dominance approach in LORA-MOO is demonstrated.

### Influence of Ratio Threshold \(rp_{ratio}\)

In this subsection, we investigate the influence of ratio threshold \(rp_{ratio}\) on the optimization performance. \(rp_{ratio}\) is the threshold to determine when to add artificial ordinal relations for the training of ordinal surrogate \(h_{o}\). We set \(rp_{ratio}\) = {1, 2/3, 1/2, 1/3} to generate four LORA-MOO variants. For all variants, we set \(n_{o}\), \(\lambda\) to 4, 0.2, respectively, which are consistent with our conclusions in previous ablation studies. Parameter \(n_{c}\) is tentatively set to 5. The IGD+ values obtained by four LORA-MOO variants with different \(rp_{ratio}\) are reported in Table 5. It should be noted that, when the number of objectives \(M\) = 3, the results of \(rp_{ratio}\) = 1 are the same as the results of \(rp_{ratio}\) = 2/3, because the ratio of reference points in archive \(S_{A}\) is always lower than 2/3. Consequently, when \(M\) = 3, setting ratio threshold \(rp_{ratio}\) to either 1 or 2/3 makes no difference to the optimization process of LORA-MOO. Similarly, the results of \(rp_{ratio}\) = 1/3 on some problems are the same as the resultsobtained by setting \(rp_{ratio}\) to 1/2, because on these problems, the ratio of reference points in \(S_{A}\) is always higher than 1/2.

As shown in Table 5, the variant of \(rp_{ratio}\) = 1/2 outperforms other variants and achieves the optimal behavior. Therefore, we set \(rp_{ratio}\) = 1/2 for LORA-MOO. In comparison, the variants of \(rp_{ratio}\) = 2/3 and \(rp_{ratio}\) = 1/3 have competitive performance, both of them are inferior to the variant of \(rp_{ratio}\) = 1/2 but significantly superior to the variant of \(rp_{ratio}\) = 1.

Setting \(rp_{ratio}\) = 1 indicates this LORA-MOO variant will never introduce artificial ordinal relations for the learning of the ordinal surrogate. The ordinal surrogate in this variant is trained completely on

\begin{table}
\begin{tabular}{l l l l l l l} \hline Problems & M & \(n_{n}\)=10 & \(n_{n}\)=8 & \(n_{n}\)=6 & \(n_{n}\)=4 & \(n_{n}\)=3 \\ \hline DTLZ1 & 3 & 4.63e(1.160e+1) & 4.64e+1(1.23e+1) & 5.61e+1(2.04e+1) & 4.84e+1(1.34e+1) & 4.58e+1(1.55e+1) \\  & 6 & 1.35e+1(7.10e+0) & 1.77e+1(5.08e+0) & 1.87e+1(6.85e+0) & 1.64e+1(3.24e+0) & 1.50e+1(7.84e+0) \\  & 10 & 1.56e-1(3.58e-2) & 1.60e-1(3.60e-2) & 1.63e-1(6.95e-2) & 1.60e-1(2.67e-2) & 1.63e-1(3.51e-2) \\ \hline DTLZ2 & 3 & 4.50e-2(3.90e-3) & 4.54e-2(4.16e-3) & 4.38e-2(2.61e-3) & 4.35e-2(4.72e-3) & 4.39e-2(3.88e-3) \\  & 6 & 2.67e-1(1.47e-2) & 2.73e-1(1.93e-2) & 2.64e-1(1.67e-2) & 2.75e-1(1.91e-2) & 2.51e-1(2.20e-2) \\  & 10 & 3.04e-1(1.55e-2) & 2.97e-1(1.63e-2) & 2.94e-1(1.24e-2) & 3.00e-1(1.31e-2) & 3.11e-1(1.78e-2) \\ \hline DTLZ3 & 3 & 1.50e+2(4.72e+1) & 1.60e+2(4.92e+1) & 1.55e+2(3.05e+1) & 1.48e+2(4.21e+1) & 1.45e+2(4.10e+1) \\  & 6 & 5.34e+1(8.15e+1) & 5.65e+1(1.99e+1) & 6.92e+1(2.39e+1) & 6.68e+1(6.16e+1) & 6.24e+1(2.34e+1) \\  & 10 & 4.51e-1(4.40e-2) & 4.68e-1(6.10e-2) & 4.35e-1(3.71e-2) & 4.72e-1(5.45e-2) & 4.85e-1(7.87e-2) \\ \hline DTLZ4 & 3 & 1.05e-1(2.28e-1) & 8.77e-2(1.30e-1) & 9.10e-2(2.15e-1) & 1.05e-1(2.17e-1) & 1.15e-1(1.33e-1) \\  & 6 & 1.74e-1(3.62e-2) & 1.60e-1(3.35e-2) & 1.84e-1(3.79e-2) & 1.75e-1(3.75e-2) & 1.68e-1(1.12e-2) \\  & 10 & 2.29e-1(0.5e-2) & 2.29e-1(9.43e-3) & 2.36e-1(1.27e-2) & 2.38e-1(1.35e-2) & 2.42e-1(1.71e-2) \\ \hline DTLZ5 & 3 & 8.65e+1(3.39e-3) & 8.76e-1(3.53e-3) & 9.03e-1(6.73e-3) & 9.26e-1(3.23e-3) & 9.26e-1(3.23e-3) \\  & 6 & 3.43e-2(7.07e-3) & 3.28e-2(7.73e-3) & 3.24e-2(7.73e-3) & 3.25e-2(8.28e-3) & 3.33e-2(9.38e-3) \\  & 10 & 4.06e-3(6.52e-4) & 3.99e-3(4.47e-4) & 3.94e-3(4.04e-4) & 3.97e-3(9.34e-4) & 4.02e-3(1.10e-3) \\ \hline DTLZ6 & 3 & 5.09e-2(5.72e-2) & 1.05e-1(5.75e-1) & 2.45e-2(8.80e-3) & 4.67e-2(4.92e-2) & 3.12e-2(1.58e-2) \\  & 6 & 9.45e-1(1.13e+0) & 5.16e-1(6.72e-1) & 5.42e-1(8.28e-1) & 7.52e-1(9.50e-1) & 1.34e-1(0.04e-4) \\  & 10 & 4.48e-2(39e-2) & 2.50e-2(7.35e-3) & 5.14e-2(4.26e-2) & 4.18e-2(4.66e-2) & 4.72e-2(4.57e-2) \\ \hline DTLZ7 & 3 & 1.19e-1(1.00e-1) & 9.47e-2(1.15e-1) & 1.16e-1(7.80e-2) & 1.61e-1(7.71e-1) & 1.46e-1(1.27e-1) \\  & 6 & 1.90e+0(9.89e-1) & 1.72e-0(6.52e-1) & 1.77e-0(6.35e-1) & 1.25e-0(4.72e-1) & 1.54e-0(8.80e-1) \\  & 10 & 1.19e+0(9.00e-2) & 1.18e+0(9.32e-1) & 1.17e+0(8.41e-2) & 1.17e+0(8.79e-2) & 1.22e+0(1.13e-1) \\ \hline WFG1 & 3 & 1.65e+0(5.78e-2) & 1.65e+0(3.73e-2) & 1.64e+0(3.86e-2) & 1.67e+0(4.67e-2) & 1.65e+0(5.96e-2) \\  & 6 & 2.24e+0(5.47e-2) & 2.20e+0(6.93e-2) & 2.23e+0(4.37e-2) & 2.22e+0(6.80e-2) & 2.21e+0(5.52e-2) \\  & 10 & 2.62e+0(8.72e-2) & 2.58e+0(7.39e-2) & 2.59e+0(7.81e-2) & 2.62e+0(8.92e-2) & 2.58e+0(1.16e-1) \\ \hline WFG2 & 3 & 2.39e-1(3.16e-2) & 2.49e-1(4.94e-2) & 2.68e-1(4.81e-2) & 2.52e-1(4.94e-2) & 2.66e-1(4.58e-2) \\  & 6 & 5.91e-1(1.79e-1) & 5.85e-1(9.10e-2) & 5.61e+1(1.29e-1) & 5.43e-1(1.51e-1) & 5.67e-1(1.07e-1) \\  & 10 & 1.50e+0(3.53e-1) & 1.41e+0(2.62e-1) & 1.42e-0(3.21e-1) & 1.47e+0(4.44e-1) & 1.39e+0(2.82e-1) \\ \hline WFG3 & 3 & 2.42e-1(4.10e-2) & 2.66e-1(3.75e-2) & 2.57e-1(3.28e-2) & 2.41e-1(3.21e-2) & 2.56e-1(5.04e-2) \\  & 6 & 6.19e-1(8.08e-2) & 6.28e-1(6.58e-2) & 6.15e-1(9.32e-2) & 5.92e-1(7.43e-2) & 6.19e-1(1.12e-1) \\  & 10 & 6.24e-1(9.78e-2) & 6.07e-1(8.67e-2) & 6.18e-1(8.74e-2) & 6.06e-1(8.00e-2) & 6.61e-1(8.08e-2) \\ \hline WFG4 & 3 & 2.26e-1(5.18e-2) & 2.52e-1(1.99e-2) & 2.51e-1(1.27e-2) & 2.48e-1(10.14e-2) & 2.38e-1(6.09e-3) \\  & 6 & 1.41e+0(2.17e-1) & 1.34e+0(1.96e-1) & 1.27e+0(2.31e-1) & 1.30e+0(2.41e-1) & 1.58e+0(4.08e-1) \\  & 10 & 4.42e+0(5.64e-3) & 3.65e-0(4.36e-3) & 3.55e-0(5.7e-1) & 3.99e+0(7.21e-1) & 4.08e+0(7.57e-1) \\ \hline WFGS & 3 & 2.39e-1(4.46e-2) & 2.39e-1(5.58e-2) & 2.39e-1(7.16e-2) & 3.10e-1(5.06e-2) & 3.19e-1(9.79e-2) \\  & 6 & 1.69e+0(8.33e-2) & 1.72e+0(8.16e-2) & 1.66e+0(9.57e-2) & 1.69e+0(1.53e-1) & 1.83e+0(1.34e-1) \\  & 4 & 4.76e+0(2.87e-1) & 4.57e+0(3.19e-1) & 4.10e+0(3.07e-1) & 3.71e+0(3.87e-1) & 3.71e+0(4.39e-1) \\ \hline WFG6 & 3 & 4.6e-

[MISSING_PAGE_EMPTY:20]

[MISSING_PAGE_EMPTY:21]

also significantly inferior to two other variants. The variant of \(n_{c}\) = 1 reaches the worst optimization results as it is significantly inferior to all other variants. In addition, considering that the variant of \(n_{c}\) = 7 wins/ties/losses 2/45/1 statistical tests when compared with the variant of \(n_{c}\) = 5, we set \(n_{c}\) = 7 for LORA-MOO.

The result of this ablation study demonstrates the influence of population initialization on the optimization results. By clustering the evaluated solutions into several clusters and sampling the same amount of initial solutions from each cluster, the solutions in the initial population are distributed in a more diverse way than the solutions sampled from the set of reference points \(S_{RP}\) directly.

\begin{table}
\begin{tabular}{l l l l l l l} \hline Problems & M & \(n_{c,\text{s}}\) & \(n_{c,\text{s}}\) & \(n_{c,\text{s}}\) & \(n_{c,\text{s}}\)=7 & \(n_{c}\)=10 \\ \hline DTLZ1 & 3 & 6.45e+1(1.31e+1) & 5.77e+1(1.23e+1) & 4.75e+1(1.54e+1) & 4.02e+1(1.46e+1) & 3.91e+1(1.53e+1) \\  & 6 & 2.22e+1(5.99e+0) & 1.67e+1(4.35e+0) & 1.35e+1(6.23e+0) & 1.55e+1(5.29e+0) & 1.56e+1(7.51e+0) \\  & 10 & 1.52e-1(3.01e-2) & 1.67e-1(4.03e-2) & 1.58e-1(2.81e-2) & 1.58e-1(3.11e-2) & 1.64e-1(3.19e-2) \\ \hline DTLZ2 & 3 & 4.40e-3(.30e-3) & 4.38e-2(4.17e-3) & 4.37e-2(3.41e-3) & 4.38e-2(3.31e-3) & 4.29e-2(4.38e-3) \\  & 6 & 1.84e-1(1.50e-2) & 1.79e-1(1.02e-2) & 1.80e-1(1.17e-2) & 1.79e-1(9.20e-3) & 1.80e-1(1.04e-2) \\  & 10 & 2.89e-1(1.00e-2) & 2.97e-1(1.40e-2) & 2.87e-1(1.71e-2) & 2.90e-1(1.22e-2) & 2.85e-1(1.09e-2) \\ \hline DTLZ3 & 3 & 1.89e+2(4.68e+1) & 1.64e-2(3.71e-1) & 1.54e+2(4.39e+1) & 1.58e+2(4.25e+1) & 1.57e+2(3.17e+1) \\  & 6 & 7.44e+1(2.34e+1) & 6.06e+1(1.32e+1) & 6.01e+1(2.61e+1) & 6.65e+1(2.14e+1) & 6.44e+1(2.63e+1) \\  & 10 & 4.65e-1(1.12e-1) & 4.70e-1(8.67e-2) & 4.84e-1(5.71e-2) & 4.92e-1(1.38e-1) & 4.61e-1(4.94e-2) \\ \hline DTLZ4 & 3 & 8.60e-1(2.25e-1) & 1.35e-1(1.04e-1) & 1.06e-1(1.32e-1) & 8.82e-1(2.16e-1) & 1.04e-1(1.28e-1) \\  & 6 & 1.69e-1(2.02e-2) & 8.10e-1(3.27e-2) & 1.79e-1(4.06e-2) & 1.81e-1(4.7e-2) & 1.79e-1(7.28e-2) \\  & 10 & 2.29e-1(1.15e-2) & 2.30e-1(1.06e-2) & 2.38e-1(1.56e-2) & 2.37e-1(2.00e-2) & 2.37e-1(1.88e-2) \\ \hline DTLZ5 & 3 & 9.75e-2(.19e-3) & 8.93e-1(6.17e-3) & 8.98e-1(6.73e-3) & 9.13e-1(5.38e-3) & 8.80e-1(1.44e-3) \\  & 6 & 3.12e-2(9.30e-3) & 2.98e-1(2.02e-2) & 3.31e-2(7.84e-3) & 2.72e-2(7.3e-3) & 3.00e-2(1.05e-2) \\  & 10 & 5.60e-3(1.76e-3) & 3.92e-3(6.78e-4) & 4.85e-3(1.78e-3) & 5.65e-3(2.12e-3) & 6.02e-3(1.70e-3) \\ \hline DTLZ6 & 3 & 4.87e-2(2.65e-2) & 4.28e-2(2.73e-2) & 6.38e-2(7.62e-2) & 9.93e-2(2.14e-1) & 5.04e-2(3.71e-2) \\  & 6 & 1.09e-4(1.9e+0) & 1.11e+0(1.07e-0) & 7.28e-1(1.00e-1) & 1.04e-1(1.14e-0) & 8.36e-1(1.16e+0) \\  & 10 & 2.25e-2(7.14e-3) & 2.60e-2(5.11e-2) & 3.92e-2(3.62e-2) & 3.51e-2(3.23e-2) & 4.42e-42e-40e-2) \\ \hline DTLZ7 & 3 & 6.96e-2(3.03e-2) & 7.83e-2(5.28e-2) & 1.36e-1(1.32e-1) & 1.28e-1(1.31e-1) & 9.71e-2(5.24e-2) \\  & 6 & 6.96e-2(2.65e-1) & 1.68e-0(8.29e-1) & 1.21e+0(7.32e-1) & 1.16e+0(3.36e-1) & 1.74e-0(8.02e-1) \\  & 10 & 1.24e+0(1.54e-1) & 1.20e+0(9.84e-2) & 1.23e+0(1.33e-1) & 1.20e+0(9.32e-2) & 1.25e+0(1.08e-1) \\ \hline WFG1 & 3 & 1.67e+0(4.91e-2) & 1.64e+0(5.90e-2) & 1.67e+0(4.86e-2) & 1.62e+0(3.43e-2) & 1.61e+0(4.98e-2) \\  & 6 & 2.27e+0(5.70e-2) & 2.24e+0(5.05e-2) & 2.21e+0(4.69e-2) & 2.21e+0(4.73e-2) & 2.20e+0(6.16e-2) \\  & 10 & 2.67e+0(8.46e-2) & 2.56e+0(1.07e-2) & 2.55e+0(1.15e-2) & 2.64e-0(7.62e-2) & 2.61e+0(3.86e-2) \\ \hline WFG2 & 3 & 2.63e-1(3.41e-2) & 2.63e-1(3.89e-2) & 2.48e-1(5.57e-2) & 2.47e-1(4.40e-2) & 2.44e-1(5.40e-2) \\  & 6 & 5.17e-1(1.03e-1) & 5.43e-1(3.15e-1) & 5.35e-1(9.4e-2) & 5.24e-1(1.26e-1) & 5.09e-1(1.49e-1) \\  & 10 & 3.94e+0(3.47e-1) & 3.94e-0(7.17e-1) & 1.36e-0(3.13e-1) & 1.40e-0(27e-1) & 1.38e-0(3.33e-1) \\ \hline WFG3 & 3 & 2.57e-1(3.61e-2) & 2.64e-1(7.85e-2) & 2.51e-1(3.82e-2) & 2.78e-1(6.66e-2) & 2.48e-1(2.96e-2) \\  & 6 & 6.25e-1(1.13e-1) & 5.89e-1(6.72e-2) & 5.83e-1(8.20e-2) & 5.80e-1(7.49e-2) & 2.65e-1(1.04e-1) \\  & 10 & 6.67e-1(8.95e-2) & 6.93e-1(9.45e-2) & 6.93e-1(1.22e-1) & 7.03e-1(9.06e-2) & 7.47e-1(8.54e-2) \\ \hline WFG4 & 3 & 2.56e-1(3.72e-2) & 2.49e-1(2.04e-2) & 2.49e-1(2.16e-2) & 2.48e-1(7.5e-2) & 2.24e-1(1.77e-2) \\  & 6 & 1.30e+0(1.91e-1) & 1.34e+0(2.28e-1) & 1.35e+0(3.15e-1) & 1.20e+0(2.33e-1) & 1.38e+0(2.88e-1) \\  & 10 & 8.88e+0(6.78e-1) & 8.87e(0.96e-1) & 3.86e+0(6.30e-1) & 3.83e+0(7.38e-1) & 3.85e+0(3.90e-1) \\ \hline WFG5 & 3 & 3.17e-1(2.12e-1) & 3.70e-1(7.10e-1) & 3.06e-1(1.03e-3) & 3.12e-1(7.25e-1) & 3.29e-1(7.28e-1) \\  & 6 & 1.78e+0(9.49e-2) & 1.76e+0(1.11e-1) & 1.72e+0(1.26e-1) & 1.73e+0(9.61e-2) & 1.74e+0(1.33e-1) \\  & 10 & 3.79e+0(2.92e-1) & 3.59e-0(2.81e-3) & 3.63e+0(4.80e-1) & 3.87e+0(30.13e-1) & 3.79e+0(2.71e-1) \\ \hline WFG6 & 3 & 4.48e-1(10.10e-1) & 5.42e-1(10.18e-1) & 4.87e-1(1Consequently, all variants of \(n_{c}>1\) have achieved better optimization results than the variant of \(n_{c}\) = 1.

## Appendix G Solution Distribution

The solution distribution we obtained on some 3-objective DTLZ problems are plotted.

## Appendix H Complete Results of Benchmark Optimization

In Section 4.3 of the main file, we display the optimization results of comparison algorithms on DTLZ problems in terms of IGD values. In this section, we provide detailed IGD results on WFG problems and more results on IGD+ and HV values. In addition, the optimization results on DTLZ problems with different scales, such as \(D\) = 5 and 20, are reported.

### IGD Results on WFG Optimization Problems

Table 7 shows the optimization results on WFG problems in terms of IGD values. The last row summarizes the results of statistical tests, which has reported at the end of Table 1 in the main file. It can be seen that LORA-MOO outperforms all comparison algorithms, followed by KTA2 and

Figure 8: Distribution of obtained non-dominated solutions on DTLZ4 with 10 variables and 3 objectives.

Figure 7: Distribution of obtained non-dominated solutions on DTLZ2 with 10 variables and 3 objectives.

[MISSING_PAGE_EMPTY:24]

[MISSING_PAGE_FAIL:25]

[MISSING_PAGE_FAIL:26]

[MISSING_PAGE_FAIL:27]

[MISSING_PAGE_EMPTY:28]

[MISSING_PAGE_FAIL:29]

* The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.
* The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.
* The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.
* If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.
* While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [NA] Justification: Not applicable. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: Experimental setups are described in detail. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.
* While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [No] Justification: Will release our code after acceptation, or we can provide the code if any reviewers are interested in it during the review process. Anyway, the details about the code have already described in the paper. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines ([https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy)) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines ([https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy)) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: We have described all the details about of experiments. Guidelines: ** The answer NA means that the paper does not include experiments.
* The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them.
* The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: We have conducted statistical tests in our experiments, error bars are plotted in figures. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors). * It should be clear whether the error bar is the standard deviation or the standard error of the mean. * It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified. * For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). * If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: A runtime comparison experiment is reported in the end of our experiment section. We did not provide information about compute workers and memory since our experiments do not have specific requirements on memory or other computation resource. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics [https://neurips.cc/public/EthicsGuidelines?](https://neurips.cc/public/EthicsGuidelines?)Answer: [NA] Justification: Not applicable. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [No] Justification: Our algorithm has no potential negative social impacts. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. * If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [No] Justification: Code will be released after acceptation, it would be open access, no safeguards are required. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. ** We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
* **Licensees for existing assets*
* Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: We have cited the existing assets we used in our paper. Guidelines:
* The answer NA means that the paper does not use existing assets.
* The authors should cite the original paper that produced the code package or dataset.
* The authors should state which version of the asset is used and, if possible, include a URL.
* The name of the license (e.g., CC-BY 4.0) should be included for each asset.
* For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.
* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: We did not introduce any new assets. Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: We do not have any experiments or research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: We do not have any experiments or research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.